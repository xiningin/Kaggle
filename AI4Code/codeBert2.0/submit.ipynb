{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import sparse\n",
    "from tqdm import tqdm\n",
    "\n",
    "pd.options.display.width = 180\n",
    "pd.options.display.max_colwidth = 120\n",
    "data_dir = Path('../')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Test NBs: 100%|██████████| 4/4 [00:00<00:00, 181.79it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[         cell_type                                                                                                                   source              id\n",
       " cell_id                                                                                                                                                    \n",
       " ddfd239c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...  0009d135ece78d\n",
       " c6cd22db      code                                              df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf  0009d135ece78d\n",
       " 1372ae9b      code  numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...  0009d135ece78d\n",
       " 90ed07ab      code  def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...  0009d135ece78d\n",
       " 7f388a41      code  # Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...  0009d135ece78d\n",
       " 2843a25a      code  # Scaling Data\\nscaler = StandardScaler()\\nscaler.fit(numerical_data)\\n# print(scaled_data)\\n\\n# Assigning Variables...  0009d135ece78d\n",
       " 06dbf8cf      code  # 3. Implementing PCA on X (green for benign; red for malignant)\\n##################################################...  0009d135ece78d\n",
       " f9893819  markdown                                                             # Scaling Data ⚖\\nLet's scale the data so PCA can be applied  0009d135ece78d\n",
       " ba55e576  markdown                                                             ## Testing Plots >w>\\nLet's these mystery soliving plots! :O  0009d135ece78d\n",
       " 39e937ec  markdown                                          ## Plotting PCA 📊\\nThus, the sun boils down to this, the PCA is hence plotted 😮  0009d135ece78d\n",
       " e25aa9bd  markdown    # Functions 🎉\\nNot in real life functions, but these functions hold the key to unravel the mystery of making plots :O  0009d135ece78d\n",
       " 0a226b6a  markdown                                        # Importing Liberaries 📚\\nLet's first import some cool liberaries to work with :D  0009d135ece78d\n",
       " 8cb8d28a  markdown                                         # Reading Data 👓\\nHere is everyone, reading and observing the data carefully >o>  0009d135ece78d,\n",
       "          cell_type                                                                                                                   source              id\n",
       " cell_id                                                                                                                                                    \n",
       " 54c7cab3      code  %reset -f \\n\\nif 1:\\n    # https://www.kaggle.com/nbroad/deberta-v2-3-fast-tokenizer\\n    import shutil\\n    from pa...  0010483c12ba9b\n",
       " fe66203e      code  #config \\n\\ndiscourse_marker_to_label = {\\n    'O': 0,\\n    'B-Lead': 1,\\n    'I-Lead': 2,\\n    'B-Position': 3,\\n  ...  0010483c12ba9b\n",
       " 7844d5f8      code  #data\\n\\ndf_text=[]\\nfor id in valid_id:\\n    text_file = text_dir +'/%s.txt'%id\\n    with open(text_file, 'r') as f...  0010483c12ba9b\n",
       " 5ce8863c      code  #net\\n\\nfrom bigbird_base_model import Net as BidBirdBaseNet\\nfrom longformer_base_model import Net as LongformerBas...  0010483c12ba9b\n",
       " 4a0777c4      code  #processing\\n\\ndef text_to_word(text):\\n    word = text.split()\\n    word_offset = []\\n\\n    start = 0\\n    for w in...  0010483c12ba9b\n",
       " 4703bb6d      code  ## main submission function !!!!\\n\\n\\ndef run_submit():\\n    if is_debug: print(\"THIS IS DEBUG #####################...  0010483c12ba9b\n",
       " 4a32c095      code  #check function\\ndef run_check_dataset():\\n\\n    tokenizer = net[0].get_tokenizer()\\n    dataset = FeedbackDataset(d...  0010483c12ba9b\n",
       " 865ad516      code  # '''\\n# cross validation results \\n# WITHOUT SORTED TEXT INPUT #############################################\\n# ../...  0010483c12ba9b\n",
       " 02a0be6d      code                                                                                       #run_check_dataset()\\nrun_submit()  0010483c12ba9b\n",
       " 7f270e34  markdown  This notebook illustrate how to speedup inference by :\\n\\n    - sort input text from decreasing length\\n    \\n    - ...  0010483c12ba9b,\n",
       "          cell_type                                                                                                                   source              id\n",
       " cell_id                                                                                                                                                    \n",
       " aafc3d23      code  \\n# Essential\\nimport numpy as np\\nimport pandas as pd\\n\\n# Data Visualization\\nimport seaborn as sns\\nimport matplo...  0010a919d60e4f\n",
       " 80e077ec      code  train_data = pd.read_csv('../input/titanic/train.csv')\\n# train_data['Survived'] = train_data['Survived'].astype(int...  0010a919d60e4f\n",
       " b190ebb4      code                                                                                                    train_data.describe()  0010a919d60e4f\n",
       " ed415c3c      code                                               print('Number of rows ',len(train_data))\\nprint(train_data.isnull().sum())  0010a919d60e4f\n",
       " 322850af      code  full_data['FamilyMembers'] = full_data['SibSp'] + full_data['Parch']\\ntrain_data['FamilyMembers'] = train_data['SibS...  0010a919d60e4f\n",
       " ...            ...                                                                                                                      ...             ...\n",
       " d2f722a5  markdown  ## Conclusion\\nI tried to do a little bit of everything on this notebook, so there's a lot of details I omitted, but...  0010a919d60e4f\n",
       " 8a0842b8  markdown                                                                             Good, now we can look at the updated dataset  0010a919d60e4f\n",
       " 03cb1feb  markdown  To correctly choose the right model for our task, we need to evaluate each model. We will use cross-validation durin...  0010a919d60e4f\n",
       " 83514fa3  markdown  As we probably expected, `Sex` is the most important feature, after that we have `Pclass`, `Family_Survival` and `Fa...  0010a919d60e4f\n",
       " d3f5c397  markdown                                                    We have 177 rows with missing `Age` and 687 rows with missing `Cabin`  0010a919d60e4f\n",
       " \n",
       " [62 rows x 3 columns],\n",
       "          cell_type                                                                                                                   source              id\n",
       " cell_id                                                                                                                                                    \n",
       " 012c9d02      code                                                                  sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size  0028856e09c5b7\n",
       " d22526d1      code   types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...  0028856e09c5b7\n",
       " 3ae7ece3      code  #correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....  0028856e09c5b7\n",
       " eb293dfc  markdown  automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...  0028856e09c5b7]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def read_notebook(path):\n",
    "    return (\n",
    "        pd.read_json(\n",
    "            path,\n",
    "            dtype={'cell_type': 'category', 'source': 'str'})\n",
    "        .assign(id=path.stem)\n",
    "        .rename_axis('cell_id')\n",
    "    )\n",
    "\n",
    "paths_test = list((data_dir / 'test').glob('*.json'))\n",
    "notebooks_test = [\n",
    "    read_notebook(path) for path in tqdm(paths_test, desc='Test NBs')\n",
    "]\n",
    "notebooks_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_id</th>\n",
       "      <th>cell_type</th>\n",
       "      <th>source</th>\n",
       "      <th>rank</th>\n",
       "      <th>pred</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c</td>\n",
       "      <td>code</td>\n",
       "      <td>import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0.142857</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>c6cd22db</td>\n",
       "      <td>code</td>\n",
       "      <td>df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf</td>\n",
       "      <td>1</td>\n",
       "      <td>0.285714</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>1372ae9b</td>\n",
       "      <td>code</td>\n",
       "      <td>numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...</td>\n",
       "      <td>2</td>\n",
       "      <td>0.428571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>90ed07ab</td>\n",
       "      <td>code</td>\n",
       "      <td>def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...</td>\n",
       "      <td>3</td>\n",
       "      <td>0.571429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>7f388a41</td>\n",
       "      <td>code</td>\n",
       "      <td># Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...</td>\n",
       "      <td>4</td>\n",
       "      <td>0.714286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>d3f5c397</td>\n",
       "      <td>markdown</td>\n",
       "      <td>We have 177 rows with missing `Age` and 687 rows with missing `Cabin`</td>\n",
       "      <td>34</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02</td>\n",
       "      <td>code</td>\n",
       "      <td>sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size</td>\n",
       "      <td>0</td>\n",
       "      <td>0.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>86</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>d22526d1</td>\n",
       "      <td>code</td>\n",
       "      <td>types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...</td>\n",
       "      <td>1</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>87</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>3ae7ece3</td>\n",
       "      <td>code</td>\n",
       "      <td>#correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....</td>\n",
       "      <td>2</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>eb293dfc</td>\n",
       "      <td>markdown</td>\n",
       "      <td>automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>89 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                id   cell_id cell_type                                                                                                                   source  rank      pred\n",
       "0   0009d135ece78d  ddfd239c      code  import numpy as np # linear algebra\\nimport pandas as pd # data processing,\\nimport matplotlib.pyplot as plt\\nfrom s...     0  0.142857\n",
       "1   0009d135ece78d  c6cd22db      code                                              df = pd.read_csv('/kaggle/input/breast-cancer-wisconsin-data/data.csv')\\ndf     1  0.285714\n",
       "2   0009d135ece78d  1372ae9b      code  numerical_data = df.loc[:, ~df.columns.isin(['id', \"diagnosis\"])]\\n\\nlabels = df[\"diagnosis\"].factorize(['B','M'])[0...     2  0.428571\n",
       "3   0009d135ece78d  90ed07ab      code  def comparison_plot_maker(data_1, data_2, name, column_name_1, column_name_2):\\n    # Scaling Data for testing\\n    ...     3  0.571429\n",
       "4   0009d135ece78d  7f388a41      code  # Ploting data with different columns\\n#####################################\\ncomparison_plot_maker(numerical_data[\"...     4  0.714286\n",
       "..             ...       ...       ...                                                                                                                      ...   ...       ...\n",
       "84  0010a919d60e4f  d3f5c397  markdown                                                    We have 177 rows with missing `Age` and 687 rows with missing `Cabin`    34  1.000000\n",
       "85  0028856e09c5b7  012c9d02      code                                                                  sns.set()\\nsns.pairplot(data1, 2.5)\\nplt.show(); = size     0  0.333333\n",
       "86  0028856e09c5b7  d22526d1      code   types----------\")\\n# is uniques----------\")\\n#  plt\\nimport         mis_val +\\n = #https://pandas.pydata.org/pandas...     1  0.666667\n",
       "87  0028856e09c5b7  3ae7ece3      code  #correlation avoid map\\nf,ax verbose 20), 18))\\nsns.heatmap(data1.corr(), the annot=True, ; informations bins=50, '....     2  1.000000\n",
       "88  0028856e09c5b7  eb293dfc  markdown  automated to with data [Future you Sales code, will for References¶\\nI [universal sales by I [Step [Predict share be...     0  1.000000\n",
       "\n",
       "[89 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df = (\n",
    "    pd.concat(notebooks_test)\n",
    "    .set_index('id', append=True)\n",
    "    .swaplevel()\n",
    "    .sort_index(level='id', sort_remaining=False)\n",
    ").reset_index()\n",
    "test_df[\"rank\"] = test_df.groupby([\"id\", \"cell_type\"]).cumcount()\n",
    "test_df[\"pred\"] = test_df.groupby([\"id\", \"cell_type\"])[\"rank\"].rank(pct=True)\n",
    "test_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "# 清洗\n",
    "def clean_code(cell):\n",
    "    cleaned_code = re.sub(r\"^#.*\\n\" , \" \" , str(cell) , flags=re.MULTILINE) #第一次去除 #类注释\n",
    "    cleaned_code = re.sub(r'\"\"\".+\"\"\"', ' ', cleaned_code) # 去除 “”“”“”类型注释\n",
    "    cleaned_code = re.sub(r' +', ' ', cleaned_code) # 去除多个空格那类型\n",
    "    cleaned_code.replace(\"\\\\n\" , \" \")\n",
    "    cleaned_code = cleaned_code.replace(\"\\n\" , \" \") # 去除换行符\n",
    "    return cleaned_code\n",
    "\n",
    "# 从所有数据中取样cell\n",
    "def sample_cells(cells , n):\n",
    "    \"\"\"\n",
    "        cells: 所有cell，一般是code cell\n",
    "        n: 筛选n个cell数据\n",
    "    \"\"\"\n",
    "    cells = [clean_code(cell) for cell in cells]\n",
    "    if n >= len(cells):\n",
    "        return [cell[:200] for cell in cells]\n",
    "    else:\n",
    "        results = []\n",
    "        step = len(cells) / n # 步长\n",
    "        idx = 0\n",
    "        while int(np.round(idx)) < len(cells):\n",
    "            results.append(cells[int(np.round(idx))])\n",
    "            idx += step\n",
    "        assert cells[0] in results #触发严重错误时报异常\n",
    "        # 避免np.round的时候有点误差，把最后一个设置为cells中的最后一个元素\n",
    "        if cells[-1] not in results:\n",
    "            results[-1] = cells[-1]\n",
    "        return results\n",
    "\n",
    "# 获取一个notebook中的概括性特征\n",
    "def get_features(df):\n",
    "    features = dict()\n",
    "    df = df.sort_values(\"rank\").reset_index(drop=True)\n",
    "    for idx , sub_df in tqdm(df.groupby(\"id\")):\n",
    "        features[idx] = dict()\n",
    "        num_of_markdown = sub_df[sub_df[\"cell_type\"] == \"markdown\"].shape[0]\n",
    "        code_sub_df = sub_df[sub_df[\"cell_type\"] == \"code\"]\n",
    "        num_of_code = code_sub_df.shape[0]\n",
    "        codes = sample_cells(code_sub_df[\"source\"].values , 20) # 取样20条code cell\n",
    "        features[idx][\"num_of_code\"] = num_of_code\n",
    "        features[idx][\"num_of_markdown\"] = num_of_markdown\n",
    "        features[idx][\"codes\"] = codes\n",
    "    return features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4/4 [00:00<00:00, 571.08it/s]\n"
     ]
    }
   ],
   "source": [
    "test_fts = get_features(test_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "import torch.nn as nn\n",
    "import torch\n",
    "from transformers import AutoModel\n",
    "\n",
    "class MarkdownModel(nn.Module):\n",
    "    def __init__(self , model_path):\n",
    "        super(MarkdownModel , self).__init__()\n",
    "        self.model = AutoModel.from_pretrained(model_path)\n",
    "        self.top = nn.Linear(769 , 1)\n",
    "    def forward(self , ids , mask , fts):\n",
    "        print(\"fts: \" , fts)\n",
    "        x = self.model(ids , mask)[0]\n",
    "        print(\"x after model : \" , x , \"\\ndim:\" , x.size())\n",
    "        x = torch.cat((x[: , 0 , :] , fts) , 1)\n",
    "        print(\"x after cat : \" , x , \"\\ndim:\" , x.size())\n",
    "        x = self.top(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader , Dataset\n",
    "import torch\n",
    "from transformers import AutoTokenizer\n",
    "\n",
    "class MarkdownDataset(Dataset):\n",
    "    def __init__(self , df , model_name_or_path , total_max_len , markdown_max_len , features):\n",
    "        super().__init__()\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.markdown_max_len = markdown_max_len\n",
    "        self.total_max_len = total_max_len\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(model_name_or_path)\n",
    "        self.features = features\n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.iloc[index]\n",
    "        inputs = self.tokenizer.encode_plus(\n",
    "            row[\"source\"],\n",
    "            add_special_tokens=True,\n",
    "            max_length=self.markdown_max_len,\n",
    "            padding=\"max_length\",\n",
    "            return_token_type_ids=True,\n",
    "            truncation=True\n",
    "        )\n",
    "        code_inputs = self.tokenizer.batch_encode_plus(\n",
    "            [str(x) for x in self.features[row.id][\"codes\"]],\n",
    "            add_special_tokens=True,\n",
    "            max_length=23,\n",
    "            padding=\"max_length\",\n",
    "            truncation=True\n",
    "        )\n",
    "        num_markdown = self.features[row.id][\"num_of_markdown\"]\n",
    "        num_code = self.features[row.id][\"num_of_code\"]\n",
    "        if num_markdown + num_code == 0:\n",
    "            markdown_rate = torch.Tensor([0])\n",
    "        else:\n",
    "            markdown_rate = torch.FloatTensor([num_markdown / (num_code + num_markdown)])\n",
    "        \n",
    "        # 准备input_ids\n",
    "        \"\"\"\n",
    "            末尾追加code cell翻译的inputs ， 由于encode的时候设置了“add_specical_tokens=True”，所以自带<s>\n",
    "            最后形成<s> Markdown content <s> Code content 1 <s> Code content 2 <s> ... <s> Code content 20 <s>\n",
    "        \"\"\"\n",
    "        ids = inputs['input_ids']\n",
    "        for x in code_inputs['input_ids']:\n",
    "            ids.extend(x[:-1]) \n",
    "        ids = ids[:self.total_max_len]\n",
    "        if len(ids) != self.total_max_len:\n",
    "            ids = ids + [self.tokenizer.pad_token_id ,] * (self.total_max_len - len(ids)) # 添加<padding>补齐到total_max_len\n",
    "        ids = torch.LongTensor(ids)\n",
    "\n",
    "        # 准备attention_mask,这个步骤需要与上面那个同步的\n",
    "        mask = inputs['attention_mask']\n",
    "        for x in code_inputs['attention_mask']:\n",
    "            mask.extend(x[:-1])\n",
    "        mask = mask[:self.total_max_len]\n",
    "        if len(mask) != self.total_max_len:\n",
    "            mask = mask + [self.tokenizer.pad_token_id, ] * (self.total_max_len - len(mask))\n",
    "        mask = torch.LongTensor(mask)\n",
    "\n",
    "        assert len(ids) == self.total_max_len\n",
    "        assert len(mask) == self.total_max_len\n",
    "\n",
    "        return ids , mask , markdown_rate , torch.FloatTensor([row.pct_rank])\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys , os\n",
    "\n",
    "def read_data(data):\n",
    "    return tuple(d.cuda() for d in data[:-1]), data[-1].cuda()\n",
    "\n",
    "\n",
    "def validate(model, val_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    tbar = tqdm(val_loader, file=sys.stdout)\n",
    "    \n",
    "    preds = []\n",
    "    labels = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for idx, data in enumerate(tbar):\n",
    "            inputs, target = read_data(data)\n",
    "            print(\"inputs: \" , inputs)\n",
    "            print(\"*inputs :\" , *inputs)\n",
    "            pred = model(*inputs)\n",
    "\n",
    "            preds.append(pred.detach().cpu().numpy().ravel())\n",
    "            labels.append(target.detach().cpu().numpy().ravel())\n",
    "    \n",
    "    return np.concatenate(labels), np.concatenate(preds)\n",
    "\n",
    "def predict(model_path, ckpt_path):\n",
    "    model = MarkdownModel(model_path)\n",
    "    model = model.cuda()\n",
    "    model.eval()\n",
    "    model.load_state_dict(torch.load(ckpt_path))\n",
    "    BS = 32\n",
    "    MAX_LEN = 64\n",
    "    test_df[\"pct_rank\"] = 0\n",
    "    test_ds = MarkdownDataset(test_df[test_df[\"cell_type\"] == \"markdown\"].reset_index(drop=True), markdown_max_len=64,total_max_len=512, model_name_or_path=model_path, features=test_fts)\n",
    "    test_loader = DataLoader(test_ds, batch_size=BS, shuffle=False,\n",
    "                              pin_memory=False, drop_last=False)\n",
    "    _, y_test = validate(model, test_loader)\n",
    "    return y_test"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Predict-demo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/2 [00:00<?, ?it/s]inputs:  (tensor([[    0, 10431,  2741,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 25980,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 39154,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 48342, 44457,  ...,     1,     1,     1],\n",
      "        [    0,   170,    40,  ...,     1,     1,     1],\n",
      "        [    0,   170,    67,  ...,     1,     1,     1]], device='cuda:0'), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), tensor([[0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.1000],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645]], device='cuda:0'))\n",
      "*inputs : tensor([[    0, 10431,  2741,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 25980,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 39154,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0, 48342, 44457,  ...,     1,     1,     1],\n",
      "        [    0,   170,    40,  ...,     1,     1,     1],\n",
      "        [    0,   170,    67,  ...,     1,     1,     1]], device='cuda:0') tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') tensor([[0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.1000],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645]], device='cuda:0')\n",
      "fts:  tensor([[0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.4615],\n",
      "        [0.1000],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645]], device='cuda:0')\n",
      "x after model :  tensor([[[-0.2722, -0.0190,  0.0774,  ..., -0.2671, -0.2140,  0.2010],\n",
      "         [-0.2724, -0.0190,  0.0774,  ..., -0.2670, -0.2142,  0.2011],\n",
      "         [-0.2724, -0.0191,  0.0773,  ..., -0.2670, -0.2141,  0.2012],\n",
      "         ...,\n",
      "         [-0.2725, -0.0190,  0.0774,  ..., -0.2669, -0.2142,  0.2013],\n",
      "         [-0.2725, -0.0190,  0.0774,  ..., -0.2669, -0.2142,  0.2013],\n",
      "         [-0.2725, -0.0190,  0.0774,  ..., -0.2669, -0.2142,  0.2013]],\n",
      "\n",
      "        [[-0.2726, -0.0185,  0.0775,  ..., -0.2669, -0.2137,  0.2020],\n",
      "         [-0.2727, -0.0185,  0.0775,  ..., -0.2668, -0.2138,  0.2020],\n",
      "         [-0.2728, -0.0185,  0.0773,  ..., -0.2667, -0.2137,  0.2022],\n",
      "         ...,\n",
      "         [-0.2729, -0.0185,  0.0776,  ..., -0.2667, -0.2138,  0.2022],\n",
      "         [-0.2729, -0.0185,  0.0776,  ..., -0.2667, -0.2138,  0.2022],\n",
      "         [-0.2729, -0.0185,  0.0776,  ..., -0.2667, -0.2138,  0.2022]],\n",
      "\n",
      "        [[-0.2713, -0.0198,  0.0781,  ..., -0.2663, -0.2149,  0.2015],\n",
      "         [-0.2715, -0.0198,  0.0781,  ..., -0.2662, -0.2150,  0.2015],\n",
      "         [-0.2717, -0.0198,  0.0780,  ..., -0.2660, -0.2151,  0.2017],\n",
      "         ...,\n",
      "         [-0.2716, -0.0198,  0.0782,  ..., -0.2660, -0.2150,  0.2017],\n",
      "         [-0.2716, -0.0198,  0.0782,  ..., -0.2660, -0.2150,  0.2017],\n",
      "         [-0.2716, -0.0198,  0.0782,  ..., -0.2660, -0.2150,  0.2017]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2487, -0.0570,  0.0990,  ..., -0.2588, -0.2392,  0.2024],\n",
      "         [-0.2487, -0.0570,  0.0989,  ..., -0.2588, -0.2392,  0.2023],\n",
      "         [-0.2487, -0.0576,  0.0987,  ..., -0.2591, -0.2388,  0.2026],\n",
      "         ...,\n",
      "         [ 0.0234, -0.0905,  0.0698,  ..., -0.1401, -0.1225,  0.1615],\n",
      "         [ 0.0234, -0.0905,  0.0698,  ..., -0.1401, -0.1225,  0.1615],\n",
      "         [ 0.0234, -0.0905,  0.0698,  ..., -0.1401, -0.1225,  0.1615]],\n",
      "\n",
      "        [[-0.2485, -0.0637,  0.0999,  ..., -0.2570, -0.2410,  0.2039],\n",
      "         [-0.2487, -0.0642,  0.0996,  ..., -0.2565, -0.2408,  0.2044],\n",
      "         [-0.2486, -0.0641,  0.0997,  ..., -0.2571, -0.2410,  0.2041],\n",
      "         ...,\n",
      "         [ 0.0083, -0.1398,  0.0298,  ...,  0.0410, -0.1687,  0.2870],\n",
      "         [ 0.0083, -0.1398,  0.0298,  ...,  0.0410, -0.1687,  0.2870],\n",
      "         [ 0.0083, -0.1398,  0.0298,  ...,  0.0410, -0.1687,  0.2870]],\n",
      "\n",
      "        [[-0.2493, -0.0556,  0.0979,  ..., -0.2566, -0.2398,  0.2034],\n",
      "         [-0.2495, -0.0561,  0.0979,  ..., -0.2562, -0.2398,  0.2039],\n",
      "         [-0.1336,  0.0326,  0.4681,  ..., -0.0420, -0.1979,  0.2753],\n",
      "         ...,\n",
      "         [ 0.0205, -0.0877,  0.0730,  ..., -0.0967, -0.1196,  0.1322],\n",
      "         [ 0.0205, -0.0877,  0.0730,  ..., -0.0967, -0.1196,  0.1322],\n",
      "         [ 0.0205, -0.0877,  0.0730,  ..., -0.0967, -0.1196,  0.1322]]],\n",
      "       device='cuda:0') \n",
      "dim: torch.Size([32, 512, 768])\n",
      "x after cat :  tensor([[-0.2722, -0.0190,  0.0774,  ..., -0.2140,  0.2010,  0.4615],\n",
      "        [-0.2726, -0.0185,  0.0775,  ..., -0.2137,  0.2020,  0.4615],\n",
      "        [-0.2713, -0.0198,  0.0781,  ..., -0.2149,  0.2015,  0.4615],\n",
      "        ...,\n",
      "        [-0.2487, -0.0570,  0.0990,  ..., -0.2392,  0.2024,  0.5645],\n",
      "        [-0.2485, -0.0637,  0.0999,  ..., -0.2410,  0.2039,  0.5645],\n",
      "        [-0.2493, -0.0556,  0.0979,  ..., -0.2398,  0.2034,  0.5645]],\n",
      "       device='cuda:0') \n",
      "dim: torch.Size([32, 769])\n",
      " 50%|█████     | 1/2 [00:01<00:01,  1.20s/it]inputs:  (tensor([[    0,   970,    18,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 20891,  ...,     1,     1,     1],\n",
      "        [    0, 48342,  1437,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,  1620,    52,  ...,     1,     1,     1],\n",
      "        [    0,   170,    33,  ...,     1,     1,     1],\n",
      "        [    0,  4255,  1075,  ...,     1,     1,     1]], device='cuda:0'), tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0'), tensor([[0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.2500]], device='cuda:0'))\n",
      "*inputs : tensor([[    0,   970,    18,  ...,     1,     1,     1],\n",
      "        [    0, 48342, 20891,  ...,     1,     1,     1],\n",
      "        [    0, 48342,  1437,  ...,     1,     1,     1],\n",
      "        ...,\n",
      "        [    0,  1620,    52,  ...,     1,     1,     1],\n",
      "        [    0,   170,    33,  ...,     1,     1,     1],\n",
      "        [    0,  4255,  1075,  ...,     1,     1,     1]], device='cuda:0') tensor([[1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        ...,\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1],\n",
      "        [1, 1, 1,  ..., 1, 1, 1]], device='cuda:0') tensor([[0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.2500]], device='cuda:0')\n",
      "fts:  tensor([[0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.5645],\n",
      "        [0.2500]], device='cuda:0')\n",
      "x after model :  tensor([[[-0.2498, -0.0597,  0.0982,  ..., -0.2570, -0.2403,  0.2041],\n",
      "         [-0.2499, -0.0598,  0.0982,  ..., -0.2569, -0.2404,  0.2043],\n",
      "         [-0.0947,  0.0939,  0.1671,  ..., -0.2191, -0.2491,  0.1565],\n",
      "         ...,\n",
      "         [ 0.0967, -0.0918,  0.0826,  ...,  0.0948, -0.1524,  0.2211],\n",
      "         [ 0.0967, -0.0918,  0.0826,  ...,  0.0948, -0.1524,  0.2211],\n",
      "         [ 0.0967, -0.0918,  0.0826,  ...,  0.0948, -0.1524,  0.2211]],\n",
      "\n",
      "        [[-0.2463, -0.0613,  0.1003,  ..., -0.2604, -0.2414,  0.2038],\n",
      "         [-0.2463, -0.0614,  0.1000,  ..., -0.2604, -0.2411,  0.2036],\n",
      "         [-0.2022, -0.1087,  0.1001,  ..., -0.1245, -0.2707,  0.2262],\n",
      "         ...,\n",
      "         [ 0.0245, -0.1660,  0.0867,  ..., -0.1670, -0.1742,  0.1568],\n",
      "         [ 0.0245, -0.1660,  0.0867,  ..., -0.1670, -0.1742,  0.1568],\n",
      "         [ 0.0245, -0.1660,  0.0867,  ..., -0.1670, -0.1742,  0.1568]],\n",
      "\n",
      "        [[-0.2479, -0.0614,  0.0993,  ..., -0.2595, -0.2419,  0.2027],\n",
      "         [-0.2479, -0.0613,  0.0991,  ..., -0.2595, -0.2417,  0.2026],\n",
      "         [-0.2480, -0.0615,  0.0992,  ..., -0.2594, -0.2419,  0.2027],\n",
      "         ...,\n",
      "         [ 0.0198, -0.2078,  0.1312,  ..., -0.1704, -0.1981,  0.1761],\n",
      "         [ 0.0198, -0.2078,  0.1312,  ..., -0.1704, -0.1981,  0.1761],\n",
      "         [ 0.0198, -0.2078,  0.1312,  ..., -0.1704, -0.1981,  0.1761]],\n",
      "\n",
      "        ...,\n",
      "\n",
      "        [[-0.2483, -0.0581,  0.0990,  ..., -0.2574, -0.2411,  0.2034],\n",
      "         [-0.2489, -0.0597,  0.0969,  ..., -0.2598, -0.2398,  0.2042],\n",
      "         [-0.2484, -0.0582,  0.0989,  ..., -0.2573, -0.2411,  0.2035],\n",
      "         ...,\n",
      "         [ 0.0325, -0.0975,  0.0734,  ..., -0.0466, -0.1195,  0.1788],\n",
      "         [ 0.0325, -0.0975,  0.0734,  ..., -0.0466, -0.1195,  0.1788],\n",
      "         [ 0.0325, -0.0975,  0.0734,  ..., -0.0466, -0.1195,  0.1788]],\n",
      "\n",
      "        [[-0.2456, -0.0623,  0.1023,  ..., -0.2590, -0.2426,  0.2051],\n",
      "         [-0.2458, -0.0625,  0.1021,  ..., -0.2587, -0.2425,  0.2054],\n",
      "         [-0.2459, -0.0626,  0.1020,  ..., -0.2588, -0.2426,  0.2053],\n",
      "         ...,\n",
      "         [ 0.0128, -0.0586,  0.0663,  ...,  0.2158, -0.1298,  0.2572],\n",
      "         [ 0.0128, -0.0586,  0.0663,  ...,  0.2158, -0.1298,  0.2572],\n",
      "         [ 0.0128, -0.0586,  0.0663,  ...,  0.2158, -0.1298,  0.2572]],\n",
      "\n",
      "        [[-0.2739, -0.0153,  0.0755,  ..., -0.2698, -0.2108,  0.2003],\n",
      "         [-0.2746, -0.0152,  0.0756,  ..., -0.2695, -0.2112,  0.2007],\n",
      "         [-0.2744, -0.0153,  0.0754,  ..., -0.2695, -0.2111,  0.2004],\n",
      "         ...,\n",
      "         [-0.2745, -0.0152,  0.0756,  ..., -0.2695, -0.2112,  0.2006],\n",
      "         [-0.2745, -0.0152,  0.0756,  ..., -0.2695, -0.2112,  0.2006],\n",
      "         [-0.2745, -0.0152,  0.0756,  ..., -0.2695, -0.2112,  0.2006]]],\n",
      "       device='cuda:0') \n",
      "dim: torch.Size([11, 512, 768])\n",
      "x after cat :  tensor([[-0.2498, -0.0597,  0.0982,  ..., -0.2403,  0.2041,  0.5645],\n",
      "        [-0.2463, -0.0613,  0.1003,  ..., -0.2414,  0.2038,  0.5645],\n",
      "        [-0.2479, -0.0614,  0.0993,  ..., -0.2419,  0.2027,  0.5645],\n",
      "        ...,\n",
      "        [-0.2483, -0.0581,  0.0990,  ..., -0.2411,  0.2034,  0.5645],\n",
      "        [-0.2456, -0.0623,  0.1023,  ..., -0.2426,  0.2051,  0.5645],\n",
      "        [-0.2739, -0.0153,  0.0755,  ..., -0.2108,  0.2003,  0.2500]],\n",
      "       device='cuda:0') \n",
      "dim: torch.Size([11, 769])\n",
      "100%|██████████| 2/2 [00:01<00:00,  1.23it/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0.45040798, 0.44999337, 0.45102197, 0.4510573 , 0.45111072,\n",
       "       0.4496126 , 0.44323465, 0.47450334, 0.47357708, 0.47483248,\n",
       "       0.4729226 , 0.47534183, 0.4742913 , 0.4745975 , 0.47512558,\n",
       "       0.47534359, 0.47370237, 0.47505045, 0.47321275, 0.47482842,\n",
       "       0.4749407 , 0.4749471 , 0.47602025, 0.47424853, 0.47575235,\n",
       "       0.47485822, 0.47630787, 0.4760728 , 0.4762965 , 0.47409356,\n",
       "       0.47583067, 0.47426465, 0.4737188 , 0.47446513, 0.47490484,\n",
       "       0.47491616, 0.47488385, 0.47325808, 0.47649592, 0.47631967,\n",
       "       0.4753911 , 0.47637933, 0.44393614], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_path = 'microsoft/codebert-base'\n",
    "ckpt_path = \"./output/model_demo.bin\"\n",
    "y_test_2 = predict(model_path, ckpt_path)\n",
    "y_test_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>cell_order</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0009d135ece78d</td>\n",
       "      <td>ddfd239c c6cd22db 1372ae9b 8cb8d28a ba55e576 f9893819 39e937ec e25aa9bd 0a226b6a 90ed07ab 7f388a41 2843a25a 06dbf8cf</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0010483c12ba9b</td>\n",
       "      <td>54c7cab3 fe66203e 7844d5f8 7f270e34 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0010a919d60e4f</td>\n",
       "      <td>aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 bd8fbd76 0e2529e8 1345b8b2 cdae286f bac960d3...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0028856e09c5b7</td>\n",
       "      <td>012c9d02 eb293dfc d22526d1 3ae7ece3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               id                                                                                                               cell_order\n",
       "0  0009d135ece78d     ddfd239c c6cd22db 1372ae9b 8cb8d28a ba55e576 f9893819 39e937ec e25aa9bd 0a226b6a 90ed07ab 7f388a41 2843a25a 06dbf8cf\n",
       "1  0010483c12ba9b                                54c7cab3 fe66203e 7844d5f8 7f270e34 5ce8863c 4a0777c4 4703bb6d 4a32c095 865ad516 02a0be6d\n",
       "2  0010a919d60e4f  aafc3d23 80e077ec b190ebb4 ed415c3c 322850af c069ed33 868c4eae 80433cf3 bd8fbd76 0e2529e8 1345b8b2 cdae286f bac960d3...\n",
       "3  0028856e09c5b7                                                                                      012c9d02 eb293dfc d22526d1 3ae7ece3"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test = y_test_2\n",
    "test_df.loc[test_df[\"cell_type\"] == \"markdown\", \"pred\"] = y_test\n",
    "sub_df = test_df.sort_values(\"pred\").groupby(\"id\")[\"cell_id\"].apply(lambda x: \" \".join(x)).reset_index()\n",
    "sub_df.rename(columns={\"cell_id\": \"cell_order\"}, inplace=True)\n",
    "sub_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df.to_csv(\"submission_demo.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "vscode": {
   "interpreter": {
    "hash": "7ba16f7f762d5b311474ec35f4a483dfe0d5dc90d971e372f99206f52d61f7db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
