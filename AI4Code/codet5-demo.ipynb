{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import RobertaTokenizer , T5ForConditionalGeneration"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 定义Tokenizer和Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c3aacf26a7c4b5c99b6ae9ecf1b37f1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/703k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "e:\\PyCharm\\python3.9.6\\lib\\site-packages\\huggingface_hub\\file_download.py:123: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\Administrator\\.cache\\huggingface\\hub. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to see activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a14709d24c784d04b228180538cd0756",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/294k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "503179d7cd6d489694fa2ffee44f65a0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/2.00 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c12ce265cd4c38b95eed65d2601472",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/12.5k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "a1e7edc487e449378e4c9e44a054d5a2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/1.48k [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "17c1c4145d73478d9dd1556d1ac53604",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/902 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "608026a6582a4a56b493aa15cc30446c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading:   0%|          | 0.00/892M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tokenizer = RobertaTokenizer.from_pretrained('Salesforce/codet5-base-multi-sum')\n",
    "model = T5ForConditionalGeneration.from_pretrained('Salesforce/codet5-base-multi-sum')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "T5Config {\n",
       "  \"_name_or_path\": \"Salesforce/codet5-base-multi-sum\",\n",
       "  \"architectures\": [\n",
       "    \"T5ForConditionalGeneration\"\n",
       "  ],\n",
       "  \"bos_token_id\": 1,\n",
       "  \"d_ff\": 3072,\n",
       "  \"d_kv\": 64,\n",
       "  \"d_model\": 768,\n",
       "  \"decoder_start_token_id\": 0,\n",
       "  \"dense_act_fn\": \"relu\",\n",
       "  \"dropout_rate\": 0.1,\n",
       "  \"eos_token_id\": 2,\n",
       "  \"feed_forward_proj\": \"relu\",\n",
       "  \"id2label\": {\n",
       "    \"0\": \"LABEL_0\"\n",
       "  },\n",
       "  \"initializer_factor\": 1.0,\n",
       "  \"is_encoder_decoder\": true,\n",
       "  \"is_gated_act\": false,\n",
       "  \"label2id\": {\n",
       "    \"LABEL_0\": 0\n",
       "  },\n",
       "  \"layer_norm_epsilon\": 1e-06,\n",
       "  \"model_type\": \"t5\",\n",
       "  \"n_positions\": 512,\n",
       "  \"num_decoder_layers\": 12,\n",
       "  \"num_heads\": 12,\n",
       "  \"num_layers\": 12,\n",
       "  \"output_past\": true,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"relative_attention_max_distance\": 128,\n",
       "  \"relative_attention_num_buckets\": 32,\n",
       "  \"task_specific_params\": {\n",
       "    \"summarization\": {\n",
       "      \"early_stopping\": true,\n",
       "      \"length_penalty\": 2.0,\n",
       "      \"max_length\": 256,\n",
       "      \"min_length\": 1,\n",
       "      \"no_repeat_ngram_size\": 3,\n",
       "      \"num_beams\": 5\n",
       "    }\n",
       "  },\n",
       "  \"transformers_version\": \"4.26.0.dev0\",\n",
       "  \"use_cache\": true,\n",
       "  \"vocab_size\": 32100\n",
       "}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PreTrainedTokenizer(name_or_path='Salesforce/codet5-base-multi-sum', vocab_size=32100, model_max_len=512, is_fast=False, padding_side='right', truncation_side='right', special_tokens={'bos_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'eos_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'unk_token': AddedToken(\"<unk>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'sep_token': AddedToken(\"</s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'pad_token': AddedToken(\"<pad>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'cls_token': AddedToken(\"<s>\", rstrip=False, lstrip=False, single_word=False, normalized=True), 'mask_token': AddedToken(\"<mask>\", rstrip=False, lstrip=True, single_word=False, normalized=True), 'additional_special_tokens': [AddedToken(\"<extra_id_99>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_98>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_97>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_96>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_95>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_94>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_93>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_92>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_91>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_90>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_89>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_88>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_87>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_86>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_85>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_84>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_83>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_82>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_81>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_80>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_79>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_78>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_77>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_76>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_75>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_74>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_73>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_72>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_71>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_70>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_69>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_68>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_67>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_66>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_65>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_64>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_63>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_62>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_61>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_60>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_59>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_58>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_57>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_56>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_55>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_54>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_53>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_52>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_51>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_50>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_49>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_48>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_47>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_46>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_45>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_44>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_43>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_42>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_41>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_40>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_39>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_38>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_37>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_36>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_35>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_34>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_33>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_32>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_31>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_30>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_29>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_28>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_27>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_26>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_25>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_24>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_23>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_22>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_21>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_20>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_19>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_18>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_17>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_16>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_15>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_14>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_13>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_12>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_11>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_10>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_9>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_8>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_7>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_6>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_5>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_4>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_3>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_2>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_1>\", rstrip=False, lstrip=True, single_word=False, normalized=True), AddedToken(\"<extra_id_0>\", rstrip=False, lstrip=True, single_word=False, normalized=True)]})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#乱写一个函数名字，防止偷偷提醒\n",
    "text_code = \"\"\"\n",
    "def aa(list, target):\n",
    "\tleft = 0\n",
    "\tright = len(list) - 1  \n",
    "\twhile left <= right:\n",
    "\t\tmid = (right + left) // 2\n",
    "\t\tif list[mid] == target:\n",
    "\t\t\treturn mid\n",
    "\t\telif target > list[mid]\n",
    "\t\t\tleft = mid + 1\n",
    "\t\telse:  #target < list[mid]\n",
    "\t\t\tright = mid - 1\n",
    "\treturn -1\n",
    "\n",
    "\"\"\"\n",
    "inputs_ids = tokenizer(text_code , return_tensors=\"pt\")[\"input_ids\"]\n",
    "generated_ids = model.generate(inputs_ids , max_length=30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'input_ids': tensor([[    1,   203,   536, 12391,    12,  1098,    16,  1018,  4672,   203,\n",
       "           202,  4482,   273,   374,   203,   202,  4083,   273,   562,    12,\n",
       "          1098,    13,   300,   404, 21281,   202, 17523,  2002,  1648,  2145,\n",
       "            30,   203,   202,   202, 13138,   273,   261,  4083,   397,  2002,\n",
       "            13,   368,   576,   203,   202,   202,   430,   666,    63, 13138,\n",
       "            65,   422,  1018,    30,   203,  1082,   202,  2463,  7501,   203,\n",
       "           202,   202,   292,   430,  1018,   405,   666,    63, 13138,    65,\n",
       "           203,  1082,   202,  4482,   273,  7501,   397,   404,   203,   202,\n",
       "           202, 12107,    30,   225,   468,  3299,   411,   666,    63, 13138,\n",
       "            65,   203,  1082,   202,  4083,   273,  7501,   300,   404,   203,\n",
       "           202,  2463,   300,    21,   203,   203,     2]]), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
       "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]])}"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer(text_code , return_tensors=\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    1,   203,   536, 12391,    12,  1098,    16,  1018,  4672,   203,\n",
       "           202,  4482,   273,   374,   203,   202,  4083,   273,   562,    12,\n",
       "          1098,    13,   300,   404, 21281,   202, 17523,  2002,  1648,  2145,\n",
       "            30,   203,   202,   202, 13138,   273,   261,  4083,   397,  2002,\n",
       "            13,   368,   576,   203,   202,   202,   430,   666,    63, 13138,\n",
       "            65,   422,  1018,    30,   203,  1082,   202,  2463,  7501,   203,\n",
       "           202,   202,   292,   430,  1018,   405,   666,    63, 13138,    65,\n",
       "           203,  1082,   202,  4482,   273,  7501,   397,   404,   203,   202,\n",
       "           202, 12107,    30,   225,   468,  3299,   411,   666,    63, 13138,\n",
       "            65,   203,  1082,   202,  4083,   273,  7501,   300,   404,   203,\n",
       "           202,  2463,   300,    21,   203,   203,     2]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[    0,     1,    37, 12788,   445,   358,  1104,   326,   770,   434,\n",
       "           326,  1122,   733,   316,   666,   716,   353,  3959,   358,  1018,\n",
       "           263,     2]])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generated_ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'A utility function to find the index of the first object in list that is equal to target.'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(generated_ids[0], skip_special_tokens=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6 (tags/v3.9.6:db3ff76, Jun 28 2021, 15:26:21) [MSC v.1929 64 bit (AMD64)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "7ba16f7f762d5b311474ec35f4a483dfe0d5dc90d971e372f99206f52d61f7db"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
