{"cell_type":{"ede4241f":"code","36b989a3":"code","b91fc1a4":"code","97c1bb21":"code","148274fd":"code","7f40f579":"code","92a7ccd5":"code","a791bdcd":"code","306b0be1":"code","d8d2abf4":"code","b122e92a":"code","390c150b":"code","2d6044e1":"code","2bf63bd6":"code","5fd00228":"code","6710b0fd":"code","2a41b7f3":"code","75b0b441":"code","66d62f97":"code","91e43770":"code","59ae1c6e":"code","0cef05ac":"code","4690689e":"code","de3ba6af":"code","fd0f892f":"code","f23f0ad1":"code","84cf30fd":"code","a32f9f9a":"code","a3e03a94":"markdown","8e68c8ad":"markdown","ddb2e134":"markdown","2fa559cb":"markdown","214cb737":"markdown","80819fb3":"markdown","ba54a747":"markdown","70797d62":"markdown","649083d4":"markdown","935f0d9d":"markdown","9ed48867":"markdown","1123f1d0":"markdown","b2668a1c":"markdown","fb42ece2":"markdown","cba57056":"markdown","e15b5c5e":"markdown","c83a7c28":"markdown"},"source":{"ede4241f":"import pandas as pd\nimport numpy as np","36b989a3":"## Function to reduce the DF size\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","b91fc1a4":"train = pd.read_csv(\"\/kaggle\/input\/bdg2-class-competition\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/bdg2-class-competition\/test.csv\")\nwtrain = pd.read_csv(\"\/kaggle\/input\/bdg2-class-competition\/weather_train.csv\")\nwtest = pd.read_csv(\"\/kaggle\/input\/bdg2-class-competition\/weather_test.csv\")\nmetadata = pd.read_csv(\"\/kaggle\/input\/bdg2-class-competition\/metadata.csv\")","97c1bb21":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)\nwtrain = reduce_mem_usage(wtrain)\nwtest = reduce_mem_usage(wtest)\nmetadata = reduce_mem_usage(metadata)","148274fd":"metadata.info()","7f40f579":"train.info()","92a7ccd5":"wtrain.info()","a791bdcd":"metadata.isna().sum()*100 \/ len(metadata)","306b0be1":"# Select columns with more than 50% missing values\nmissing = metadata.isna().sum()*100 \/ len(metadata)\nto_drop = missing[missing > 50].index\n\n# Drop\nmetadata.drop(to_drop, axis=1, inplace=True)","d8d2abf4":"metadata.head()","b122e92a":"from sklearn.preprocessing import OrdinalEncoder","390c150b":"# Select object columns\nmetadata_object_cols = metadata.select_dtypes(include=['object']).columns\nmetadata_object_cols","2d6044e1":"# This returns an array\nencoder_bdg_id = OrdinalEncoder()\nencoded_building_id = encoder_bdg_id.fit_transform(metadata[[\"building_id\"]])\nencoded_building_id_train = encoder_bdg_id.transform(train[[\"building_id\"]])\nencoded_building_id_test = encoder_bdg_id.transform(train[[\"building_id\"]])\n\nencoder_site_id = OrdinalEncoder()\nencoded_site_id = encoder_site_id.fit_transform(metadata[[\"site_id\"]])\nencoded_site_id_train = encoder_site_id.transform(wtrain[[\"site_id\"]])\nencoded_site_id_test = encoder_site_id.transform(wtest[[\"site_id\"]])\n\nencoder_puse = OrdinalEncoder()\nencoded_puse = encoder_puse.fit_transform(metadata[[\"primaryspaceusage\"]])\n\nencoder_spuse = OrdinalEncoder()\nencoded_spuse = encoder_spuse.fit_transform(metadata[[\"sub_primaryspaceusage\"]])\n\nencoder_timezone = OrdinalEncoder()\nencoded_timezone = encoder_timezone.fit_transform(metadata[[\"timezone\"]])\n\nencoder_meter = OrdinalEncoder()\nencoded_meter_train = encoder_meter.fit_transform(train[[\"meter\"]])\nencoded_meter_test = encoder_meter.transform(test[[\"meter\"]])\n\n\n# We can convert it to a dataframe\nencoded_building_id = pd.DataFrame(encoded_building_id)\nencoded_site_id = pd.DataFrame(encoded_site_id)\nencoded_puse = pd.DataFrame(encoded_puse)\nencoded_spuse = pd.DataFrame(encoded_spuse)\nencoded_timezone = pd.DataFrame(encoded_timezone)\n\nencoded_meter_train = pd.DataFrame(encoded_meter_train)\nencoded_meter_test = pd.DataFrame(encoded_meter_test)\nencoded_building_id_train = pd.DataFrame(encoded_building_id_train)\nencoded_building_id_test = pd.DataFrame(encoded_building_id_test)\n\nencoded_site_id_train = pd.DataFrame(encoded_site_id_train)\nencoded_site_id_test = pd.DataFrame(encoded_site_id_test)\n\n# And replace it in your data\nmetadata[\"building_id\"] = encoded_building_id\nmetadata[\"site_id\"] = encoded_site_id\nmetadata[\"primaryspaceusage\"] = encoded_puse\nmetadata[\"sub_primaryspaceusage\"] = encoded_spuse\nmetadata[\"timezone\"] = encoded_timezone\n\ntrain[\"meter\"] = encoded_meter_train\ntrain[\"building_id\"] = encoded_building_id_train\ntest[\"meter\"] = encoded_meter_test\ntest[\"building_id\"] = encoded_building_id_test\n\nwtrain[\"site_id\"] = encoded_site_id_train\nwtest[\"site_id\"] = encoded_site_id_test","2bf63bd6":"metadata.head()","5fd00228":"train.head()","6710b0fd":"wtrain.head()","2a41b7f3":"train1 = pd.merge(train, metadata, how=\"left\", on=\"building_id\")\ntest1 = pd.merge(test, metadata, how=\"left\", on=\"building_id\")","75b0b441":"train1 = pd.merge(train1, wtrain, how=\"left\", on=[\"timestamp\",\"site_id\"])\ntest1 = pd.merge(test1, wtest, how=\"left\", on=[\"timestamp\",\"site_id\"])","66d62f97":"train1.head()","91e43770":"test1.head()","59ae1c6e":"del(metadata)\ndel(wtrain, wtest)\ndel(test,train)","0cef05ac":"from sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor","4690689e":"X_train = train1.drop(\"meter_reading\", axis=1).set_index(\"timestamp\")\ny_train = train1.meter_reading","de3ba6af":"X_test = test1.drop([\"row_id\", \"timestamp\"], axis=1)","fd0f892f":"# Model\nlgbmr = LGBMRegressor(n_estimators=50, random_state=55)\n\n# Train\nlgbmr.fit(X_train, y_train)","f23f0ad1":"prediction = lgbmr.predict(X_test)","84cf30fd":"sub = pd.DataFrame({\"row_id\": test1.row_id, \"meter_reading\": prediction})","a32f9f9a":"sub.to_csv(\"submission.csv\", index=False)","a3e03a94":"Always remember to delete your -now- useless data, will free up some memory.","8e68c8ad":"And it's all encoded. We only encoded these columns to get rid of the string data type but **if you want to train a model that actually predicts you should use one hot encoding**.","ddb2e134":"First, split in `X`, the training data, and `y` the target data. Also, remember to set the `timestamp` column as index, this data type cannot be handle by the model.","2fa559cb":"## Load data","214cb737":"We have to encode the above columns. Notice that the column `building_id` is also present in energy data and the column `site_id` is in weather data. We also have to encode the column `meter` from energy data sets.","80819fb3":"And for the test data set we have an extra  column `row_id` that is needed for the submission. Remember to remove for the prediction (you will add it again after that).","ba54a747":"# Sample submission\n\nThis notebooks is an example on how to make a submission to the competition. Steps to be performed are:\n- Simple preprocessing, just to make the data work with the model.\n- A simple LightGBM model, with the default parameters.\n- Predict `test` data with that model.\n- Submission\n\nFirst, import the basic libraries to load the data. Other libraries needed will be imported ahead.","70797d62":"## Merge\nNow we have to merge all the data to train our model.","649083d4":"And -if you want- use the function defined before to reduce memory usage:","935f0d9d":"Once you save a version of your notebook you will see a *Data* tab in your notebook page. From there you can submit your prediction with the button *Submit*.\n\n[![sample-sub.png](https:\/\/i.postimg.cc\/nz5fq8z5\/sample-sub.png)]","9ed48867":"## Missing values\nWe are going to drop the columns from `metadata` that have over 50% of missing values. Remember, this is just for a sample submission, you can input those missings to train your model.","1123f1d0":"## Model\nFinally, we can train a model.","b2668a1c":"And to create the submission you will need a dataframe with two columns: `row_id` and `meter_reading` (the prediction).","fb42ece2":"The following function helps reduce the memory usage, it was taken from [this amazing notebook](https:\/\/www.kaggle.com\/caesarlupum\/ashrae-start-here-a-gentle-introduction). You don't really need to use it, but when you start playing around with feature engineering you will notice that for each column you add the data set gets heavier and heavier. You always have to keep some memory free to train your model (which is a high memory consuming process) so keep this function handy in case you need it. Looks difficult but it just convert the current data types to one lighter.","cba57056":"Now we can predict:","e15b5c5e":"And let's train the model. This is a super basic model, parameters tunning is and important part of machine learning and we are skipping that step here.","c83a7c28":"## Encoding\nTo be used in a machine learning model the `object` columns (i.e., strings) have to be encoded as numbers. We are going to use *OrdinalEncoder* from *SciKitLearn*."}}