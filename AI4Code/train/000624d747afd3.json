{"cell_type":{"bbdeb43f":"code","fd65ce23":"code","9f08dd38":"code","8601e3b0":"code","1ad2d212":"code","296862c5":"code","ac95ae9c":"code","8d2df64a":"code","a07f8cf0":"code","7527cb70":"code","f3deebf8":"code","2c01e760":"code","f27b5e59":"code","dee9baa0":"code","c1f3c3f1":"code","d0b1b18a":"code","8435366f":"code","0319e373":"code","294aa174":"code","9416121e":"code","ffc38261":"code","f3123de4":"code","ee4874a9":"code","2ea24302":"code","e2633290":"code","df2b46e0":"markdown","5e8c349b":"markdown","d04d2f63":"markdown","41741968":"markdown","a2a0f190":"markdown","f254f6fd":"markdown","ac0e5da7":"markdown","d3a1e7e5":"markdown","8de85e7b":"markdown","ad0f92c8":"markdown","002e57d8":"markdown","a9584e4f":"markdown","e3359ac5":"markdown","27d29d73":"markdown","43957940":"markdown","ce72e39f":"markdown","a77d13be":"markdown","587ae493":"markdown"},"source":{"bbdeb43f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# other imports\nimport sys\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fd65ce23":"!pip install scikit-allel","9f08dd38":"import allel\nallel.__version__","8601e3b0":"#callset = allel.read_vcf('..\/input\/end-als\/end-als\/genomics-data\/AnswerALS_subset_annovar.hg38_anno_and_geno.no_intergenic.vcf')","1ad2d212":"#sorted(callset.keys())","296862c5":"#callset['samples']","ac95ae9c":"import numpy as np\nnp.__version__","8d2df64a":"!pip install zarr","a07f8cf0":"import zarr\nzarr.__version__","7527cb70":"!pip install numcodecs","f3deebf8":"import numcodecs\nnumcodecs.__version__","2c01e760":"vcf_path = '..\/input\/end-als\/end-als\/genomics-data\/AnswerALS_subset_annovar.hg38_anno_and_geno.no_intergenic.vcf'\n!ls -lh {vcf_path}","f27b5e59":"zarr_path = '..\/input\/end-als\/end-als\/genomics-data\/AnswerALS_subset_annovar.hg38_anno_and_geno.no_intergenic.vcf'","dee9baa0":"#The original snippet used data from chromosome 22. End ALS didn't mention any chromossome in the file\n#Trying to make it work, I removed the group and the fields. Unfortunately, it didn't work.\n\n#allel.vcf_to_zarr(vcf_path, zarr_path, group='22', fields='*', log=sys.stdout, overwrite=True)","c1f3c3f1":"allel.vcf_to_zarr(vcf_path, zarr_path, group='*', fields='*', log=sys.stdout, overwrite=True)","d0b1b18a":"callset = zarr.open_group(zarr_path, mode='r')\ncallset.tree(expand=True)","8435366f":"gt_zarr = callset['22\/calldata\/GT']\ngt_zarr.info","0319e373":"pos = allel.SortedIndex(callset['22\/variants\/POS'])\npos","294aa174":"loc_region = pos.locate_range(20000000, 20100000)\nloc_region","9416121e":"gt_region = allel.GenotypeArray(gt_zarr[loc_region])\ngt_region","ffc38261":"multi_allelic = callset['22\/variants\/MULTI_ALLELIC'][:]\nmulti_allelic","f3123de4":"gt = allel.GenotypeArray(gt_zarr)\ngt","ee4874a9":"gt_variant_selection = gt.compress(loc_variant_selection, axis=0)\ngt_variant_selection","2ea24302":"gt_dask = allel.GenotypeDaskArray(gt_zarr)\ngt_dask","e2633290":"gt_variant_selection = gt_dask.compress(loc_variant_selection, axis=0).compute()\ngt_variant_selection","df2b46e0":"#That snippet above took so long (more than 15 minutes to read a VCF) and is consuming My RAM.\nThen I commented it.","5e8c349b":"#Extract data and convert to Zarr format, use the `vcf_to_zarr`() function from scikit-allel.\nThat conversion will make life easier downstream.","d04d2f63":"#I hope to learn a little bit how to work with vcf files, scikit-allel and BioInformatics.","41741968":"#Code by Alistair Miles  http:\/\/alimanfoo.github.io\/2018\/04\/09\/selecting-variants.html","a2a0f190":"#The \u2018samples\u2019 array contains sample identifiers extracted from the header line in the VCF file.","f254f6fd":"#Loading data for a gene","ac0e5da7":"#The callset object returned by read_vcf() is a Python dictionary (dict). It contains several NumPy arrays, each of which can be accessed via a key. Here are the available keys:","d3a1e7e5":"#After FSPathExistNotDir: path exists but is not a directory: %r  Everything went wrong.\n\n#Maybe anyone can fix it.","8de85e7b":"#Use Dask if data is larger and\/or your computer doesn\u2019t have much RAM","ad0f92c8":"![](https:\/\/image.slidesharecdn.com\/karenfent-191031210734\/95\/enabling-biobankscale-genomic-processing-with-spark-sql-53-638.jpg?cb=1572556092)slideshare.net","002e57d8":"#Extract genotypes for the selection","a9584e4f":"#Extract data from a VCF","e3359ac5":"#Open the Zarr data ","27d29d73":"#Filtering variants","43957940":"#Extract genotype data for these variants","ce72e39f":"#Variant Call Format (VCF)","a77d13be":"#Apply the selection, using almost the same syntax, except that when working via Dask we need to call the compute() method to get the final result:","587ae493":"#Start with the scikit-allel function read_vcf()"}}