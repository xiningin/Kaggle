{"cell_type":{"9ae35818":"code","f1dee85b":"code","00e71412":"code","5bcfa9ad":"code","f417baab":"code","edbdda80":"code","7cad9d0d":"code","623bc581":"code","ed004065":"code","bf9dfedf":"code","91546299":"code","1da4fc3a":"code","1f863c2d":"code","d366f175":"markdown","cf43b3ce":"markdown","fe0ef161":"markdown","1a484d84":"markdown","b46c9016":"markdown","48f90daf":"markdown","e8c01594":"markdown","2844b16f":"markdown","0a48baf7":"markdown","dd060c99":"markdown","3ec4ab79":"markdown","7bfe7649":"markdown","883db462":"markdown","be38feb5":"markdown"},"source":{"9ae35818":"import os\nimport time\nimport requests\n\nimport jax\nimport jax.numpy as jnp\nfrom jax import jit, grad, random\n\nfrom jax.config import config\n%config IPCompleter.use_jedi = False","f1dee85b":"def apply_activation(x):\n    return jnp.maximum(0.0, x)\n\ndef get_dot_product(W, X):\n    return jnp.dot(W, X)","00e71412":"# Always use a seed\nkey = random.PRNGKey(1234)\nW = random.normal(key=key, shape=[1000, 10000], dtype=jnp.float32)\n\n# Never reuse the key\nkey, subkey = random.split(key)\nX = random.normal(key=subkey, shape=[10000, 20000], dtype=jnp.float32)\n\n# JIT the functions we have\ndot_product_jit  = jit(get_dot_product)\nactivation_jit = jit(apply_activation)\n\nfor i in range(3):\n    start = time.time()\n    # Don't forget to use `block_until_ready(..)`\n    # else you will be recording dispatch time only\n    Z = dot_product_jit(W, X).block_until_ready()\n    end = time.time()\n    print(f\"Iteration: {i+1}\")\n    print(f\"Time taken to execute dot product: {end - start:.2f} seconds\", end=\"\")\n    \n    start = time.time()\n    A = activation_jit(Z).block_until_ready()\n    print(f\", activation function: {time.time()-start:.2f} seconds\")","5bcfa9ad":"# Make jaxpr for the activation function\nprint(jax.make_jaxpr(activation_jit)(Z))","f417baab":"# Make jaxpr for the activation function\nprint(jax.make_jaxpr(dot_product_jit)(W, X))","edbdda80":"# We know that `print` introduces but impurity but it is\n# also very useful to print values while debugging. How does\n# jaxprs interpret that?\n\ndef number_squared(num):\n    print(\"Received: \", num)\n    return num ** 2\n\n# Compiled version\nnumber_squared_jit = jit(number_squared)\n\n# Make jaxprs\nprint(jax.make_jaxpr(number_squared_jit)(2))","7cad9d0d":"# Subsequent calls to the jitted function\nfor i, num in enumerate([2, 4, 8]):\n    print(\"Iteration: \", i+1)\n    print(\"Result: \", number_squared_jit(num))\n    print(\"=\"*50)","623bc581":"squared_numbers = []\n\n# An impure function (using a global state)\ndef number_squared(num):\n    global squared_numbers\n    squared = num ** 2\n    squared_numbers.append(squared)\n    return squared\n\n# Compiled verison\nnumber_squared_jit = jit(number_squared)\n\n# Make jaxpr\nprint(jax.make_jaxpr(number_squared_jit)(2))","ed004065":"# Subsequent calls to the jitted function\nfor i, num in enumerate([4, 8, 16]):\n    print(\"Iteration: \", i+1)\n    print(\"Result: \", number_squared_jit(num))\n    print(\"=\"*50)\n    \n# What's in the list?\nprint(\"\\n Results in the global list\")\nsquared_numbers","bf9dfedf":"# Calling the two functions into a single function\n# so that we can jit this function instead of jitting them\ndef forward_pass(W, X):\n    Z = get_dot_product(W, X)\n    A = apply_activation(Z)\n    return Z, A\n\n\n\n# Always use a seed\nkey = random.PRNGKey(1234)\n\n# We will use much bigger array this time\nW = random.normal(key=key, shape=[2000, 10000], dtype=jnp.float32)\n\n# Never reuse the key\nkey, subkey = random.split(key)\nX = random.normal(key=subkey, shape=[10000, 20000], dtype=jnp.float32)\n\n# JIT the functions we have individually\ndot_product_jit  = jit(get_dot_product)\nactivation_jit = jit(apply_activation)\n\n# JIT the function that wraps both the functions\nforward_pass_jit = jit(forward_pass)\n\nfor i in range(3):\n    start = time.time()\n    # Don't forget to use `block_until_ready(..)`\n    # else you will be recording dispatch time only\n    Z = dot_product_jit(W, X).block_until_ready()\n    end = time.time()\n    print(f\"Iteration: {i+1}\")\n    print(f\"Time taken to execute dot product: {end - start:.2f} seconds\", end=\"\")\n    \n    start = time.time()\n    A = activation_jit(Z).block_until_ready()\n    print(f\", activation function: {time.time()- start:.2f} seconds\")\n    \n    # Now measure the time with a single jitted function that calls\n    # the other two functions\n    Z, A = forward_pass_jit(W, X)\n    Z, A = Z.block_until_ready(), A.block_until_ready()\n    print(f\"Time taken by the forward pass function: {time.time()- start:.2f} seconds\")\n    print(\"\")\n    print(\"=\"*50)","91546299":"def square_or_cube(x):\n    if x % 2 == 0:\n        return x ** 2\n    else:\n        return x * x * x\n\n\n# JIT transformation\nsquare_or_cube_jit = jit(square_or_cube)\n\n# Run the jitted version on some sample data\ntry:\n    val = square_or_cube_jit(2)\nexcept Exception as ex:\n    print(type(ex).__name__, ex)","1da4fc3a":"def multiply_n_times(x, n):\n    count = 0\n    res = 1\n    while count < n:\n        res = res * x\n        count +=1 \n    return x\n\n\ntry:\n    val = jit(multiply_n_times)(2, 5)\nexcept Exception as ex:\n    print(type(ex).__name__, ex)","1f863c2d":"# Jitting the expensive computational part\ndef multiply(x, i):\n    return x * i\n\n# Specifying the static args\nmultiply_jit = jit(multiply, static_argnums=0)\n\n# Leaving it as it as\ndef multiply_n_times(x, n):\n    count = 0\n    res = 1\n    while count < n:\n        res = multiply_jit(x, res)\n        count += 1\n    return res\n\n\n%timeit multiply_n_times(2, 5)","d366f175":"We will take one more example to appreciate the beauty of `jaxprs` before moving on to JIT again","cf43b3ce":"Simlar to above, here:\n1. The first line is telling that the function receives two input variables `a` and `b`, corresponding to our `W` and `X`\n2. The second line is an XLA call where we perform the dot operation. (Check the dimesions numbers used for dot product)\n3. The last line is the result to be returned denoted by `c` \n\n\nLet's take another interesting example","fe0ef161":"If the computation inside the loop is pretty expensive, you can still jit some part of the function body. Let's see it in action","1a484d84":"# Caching\n\nWhen you `jit` a function, it gets compiled on the first call. Any subsequent calls to the jitted function reuse the cached code. You pay the price once! \n\nIf we need to JIT a function that has a condition on the value of an input, we can tell JAX to make a less abstract tracer for a particular input by specifying `static_argnums`. The cost of this is that the resulting jaxpr is less flexible, so JAX will have to re-compile the function for every new value of the specified input. It is only a good strategy if the function is guaranteed to get limited different values. \n\n\n<div class=\"alert alert-warning\">\n    <strong>Warning: Don't do this!<\/strong>\n<\/div>\n\n\n\n\n```python\ndef multiply(x, i):\n    return x * i\n\ndef multiply_n_times(x, n):\n    count = 0\n    res = 1\n    while count < n:\n        res = jit(multiply)(x, res)\n        count += 1\n    return res\n\n\nprint(multiply_n_times(2, 5))\n\n```\n\nDoing that effectively creates a new jit transformed object at each call that will get compiled each time instead of reusing the same cached function.\n\n**Note:** If the shape of your input changes, recompilation happens in that case as well. For example, if your batch size changes, then it will recompile the function in that case. Thanks to [Cristian](https:\/\/twitter.com\/cgarciae88?lang=en) for pointing this out\n\n\nThat's it for Part-7! More in the next tutorial!","b46c9016":"Which approach to follow? That's up to you. Also, I don't have a confirmation whether the second approach always works but a Twitter user, who is a heavy JAX user, pointed this out.\n\n\n# JIT and Python Control Flow\n\nA natural question that comes to mind at this stage is `Why don't we just JIT everything? That would give a massive gain in terms of execution`. Though true in some sense, you can't jit everything. There are certain scenarios where jitting wouldn't work out of the box. Let's take a few examples to understand this","48f90daf":"A few things to notice:\n1. The first line stats as usual and shows that we have an input variable `a`, corresponding to the `num` argument\n2. The second line is an XLA call that squares the input number.\n3. The last line returns the results of the XLA call denoted by `b`\n\n**The side effect isn't captured by jaxpr**. jaxpr depends on **`tracing`**. The behavior of any transformed function is dependent on the traced values. You may notice the side effect on the first run but not necessarily on the subsequent calls. Hence jaxpr isn't even bothered about the global list in this case. \n\n**Note:** One more important thing to note is the `device` value in the jaxprs. Although this argument is there unless you specify the device during jit transform like this `jit(fn_name, device=)`, no device would be listed here. This can be confusing sometimes because your computation would be running on some accelerator but here the device name won't be reflected. The logic behind this is that jaxpr is just an expression, independent of the logic where it is going to run. It is more concerned about the layout of the representation for XLA rather than the device on which the expression will be made to run  ","e8c01594":"Notice how the `num` inside the print statement is traced. Nothing stops you from running an impure function but you should be ready to encounter such side effects. The fact that the print statement is traced on the first call but may not be on the subsequent calls is because your python code will run at least once. Let's see that in action as well","2844b16f":"**Update - 23rd Dec, 2021**\n\nWe have completed the TF-JAX tutorials series. 10 notebooks that covers every fundamental aspect of both TensorFlow and JAX. Here are the links to the notebooks along with the Github repo details:\n\n### TensorFlow Notebooks:\n\n* [TF_JAX_Tutorials - Part 1](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part1)\n* [TF_JAX_Tutorials - Part 2](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part2)\n* [TF_JAX_Tutorials - Part 3](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part3)\n\n### JAX Notebooks:\n\n* [TF_JAX_Tutorials - Part 4 (JAX and DeviceArray)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-4-jax-and-devicearray)\n* [TF_JAX_Tutorials - Part 5 (Pure Functions in JAX)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-5-pure-functions-in-jax\/)\n* [TF_JAX_Tutorials - Part 6 (PRNG in JAX)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-6-prng-in-jax\/)\n* [TF_JAX_Tutorials - Part 7 (JIT in JAX)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-7-jit-in-jax)\n* [TF_JAX_Tutorials - Part 8 (Vmap and Pmap)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-8-vmap-pmap)\n* [TF_JAX_Tutorials - Part 9 (Autodiff in JAX)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-9-autodiff-in-jax)\n* [TF_JAX_Tutorials - Part 10 (Pytrees in JAX)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-10-pytrees-in-jax)\n\n### Github Repo with all notebooks in one place\nhttps:\/\/github.com\/AakashKumarNain\/TF_JAX_tutorials\n\n---\n\n<img src=\"https:\/\/raw.githubusercontent.com\/google\/jax\/main\/images\/jax_logo_250px.png\" width=\"300\" height=\"300\" align=\"center\"\/><br>\n\nWelcome to another JAX tutorial. I hope you all have been enjoying the JAX Tutorials so far. We have already completed three tutorials on JAX each of which introduced an important concept. \n\nIn the first tutorial, we discussed **DeviceArray**, the core Data Structure in JAX. In the second tutorial, we looked into **Pure Functions** and their pros and cons. In the third tutorial, we looked into **Pseudo-Random Number Generation** in JAX, and how they are different from Numpy's PRNG. If you haven't gone through the previous tutorials, I highly suggest going through them. Here are the links:\n\n1. [TF_JAX_Tutorials - Part 1](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part1)\n2. [TF_JAX_Tutorials - Part 2](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part2)\n3. [TF_JAX_Tutorials - Part 3](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part3)\n4. [TF_JAX_Tutorials - Part 4 (JAX and DeviceArray)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-4-jax-and-devicearray)\n5. [TF_JAX_Tutorials - Part 5 (Pure Functions in JAX)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-5-pure-functions-in-jax\/)\n6. [TF_JAX_Tutorials - Part 6 (PRNG in JAX)](https:\/\/www.kaggle.com\/aakashnain\/tf-jax-tutorials-part-6-prng-in-jax\/)\n\n\nToday we will look into another important concepts: **Just In Time Compilation (JIT)** in JAX","0a48baf7":"You might be wondering that if the side effect was to appear on the first call, why there are two traced values in the global list. The reason is that the side effect may or may not appear on the subsequent calls. It is an unpredictable behavior.\n\n# How much to JIT?\n\nBefore diving into the nuances related to JIT, let's assume that you have two functions that can be jitted with no problems, for example, our `get_dot_product(...)` and `apply_activation(..)` functions. Should you jit them both or should you use them into one function or module and jit that function\/module? Le's see that in action","dd060c99":"So why this code didn't work? Let's break down the whole process of JIT once again, including the one we have here\n\n1. When we `jit` a function, we aim to get a compiled version of that function, so that we can cache and reuse the compiled code for different values of the arguments. \n2. To achieve this, JAX traces it on abstract values that represent sets of possible inputs\n3. There are [different levels of abstractions](https:\/\/github.com\/google\/jax\/blob\/main\/jax\/_src\/abstract_arrays.py) that are used during tracing, and the kind of abstraction used for a particular function tracing depends on the kind of transformation is done. \n4. By default, jit traces your code on the **`ShapedArray`** abstraction level, where each abstract value represents the set of all array values with a fixed shape and dtype. For example, if we trace using the abstract value ShapedArray((3,), jnp.float32), we get a view of the function that can be reused for any concrete value in the corresponding set of arrays. That means we can save on compile time.\n\nComing to the above code and why it failed, in this case, the value of `x` isn't concrete while tracing. As a result when we hit a line like `if x % 2 == 0`, the expression `x % 2` evaluates to an abstract `ShapedArray((), jnp.bool_)` that represents the set {True, False}. **When Python attempts to coerce that to a concrete True or False, we get an error: we don\u2019t know which branch to take, and can\u2019t continue tracing!** \n\nLet's take one more example, this time involving a loop","3ec4ab79":"Let's break down the above example into steps to know in detail what happened under the hood.\n\n1. We defined two functions namely, `get_dot_product(...)` that does a dot product of weights and the inputs, and `apply_activation(...)` that applies `relu` on the previous result.\n2. We then defined two transformations using `jit(function_name)`, and got the **compiled** versions of our functions\n3. When you call the compiled function for the first time with the specified arguments, the execution time is pretty high. Why? Because the first call serves as the `warmup` phase. The warmup phase is nothing but the time taken by JAX **tracing**. Depending on the inputs, the tracers convert the code into an intermediate language, **`jaxprs`** (we will talk about this in a bit) which, is then compiled for execution in XLA\n4. The subsequent calls run the compiled version of the code\n\n**Note:** If you are benchmarking `jit` version of your function with something else, do a warmup first for a fair comparison else you will include the compilation time in the benchmarks\n\nBefore continuing further on JIT transformations, we will take a break here and try to understand the concept of **`jaxprs`** first","7bfe7649":"# Jaxprs\n\nJaxpr is an intermediate language for representing the normal Python functions. When you transform a function the function is first converted to simple statically-typed intermediate expressions by Jaxpr language, then the transformations are directly applied on these jaxprs. \n\n1. A jaxpr instance represents a function with one or more typed parameters (input variables) and one or more typed results\n2. The inputs and outputs have `types` and are represented as abstract values\n3. Not all Python programs can be represented by jaxprs but many scientific computations and machine learning programs can\n\n\n## Should you learn about Jaxprs?\n\nEvery transformation in JAX materializes to some form of `jaxpr`. If you want to understand how JAX works internally, or if you want to understand the result of JAX tracing, then yes, it is useful to understand jaxprs.\n\n\nLet's take a few examples of how jaxpr works. We will first see how the functions we defined above are expressed by jaxpr","883db462":"# What is Just In Time (JIT) Compilation?\n\nIf we go by the [definition](https:\/\/en.wikipedia.org\/wiki\/Just-in-time_compilation) of JIT, then JIT is a way of compiling your code during the execution. A system implementing a JIT compiler typically continuously analyses the code being executed and identifies parts of the code where the speedup gained from compilation or recompilation would outweigh the overhead of compiling that code.\n\n\n# JIT in JAX\n\nAs we discussed in the first chapter that JAX uses XLA for compilation. The `jax.jit(...)` transform does the just-in-time compilation and **transforms** your normal JAX Python functions so that they can be executed **more efficiently** in XLA. \nLet's see a few examples of it before discussing the details","be38feb5":"How to interpret this jaxpr?\n\n1. The first line tells you that the function receives one argument `a`\n2. The second line tells you that this is what would be executed on XLA, the max of (0, `a`)\n3. The last line tells you the output being returned\n\nLet's look at the jaxpr of our function that applies dot product"}}