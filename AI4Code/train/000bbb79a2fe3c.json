{"cell_type":{"a4bbc1c5":"code","d704e24b":"code","d15fa32d":"code","b9d50475":"code","023c33c1":"code","87803755":"code","9b070230":"code","d8b6fe17":"code","276f2b9e":"code","6771e64c":"code","bd5ddaeb":"code","3d422aed":"code","3246ab7c":"code","75c24ec7":"code","751a6526":"code","f8928e9d":"code","6c7f792a":"code","5c0a609e":"code","518a50b3":"code","9528e754":"code","30594051":"code","3f442927":"code","14b401d8":"code","fe65d4c0":"code","a128e741":"markdown","76514857":"markdown","6bba4213":"markdown","ba4365e4":"markdown","b086d2af":"markdown","759f7884":"markdown","4f605e15":"markdown"},"source":{"a4bbc1c5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d704e24b":"#Read the data\ndf = pd.read_csv('\/kaggle\/input\/fake-news\/train.csv')\ndf.head()","d15fa32d":"df = df.dropna()","b9d50475":"X = df.drop('label', axis=1)\ny = df['label']\nX.shape, y.shape","023c33c1":"import tensorflow as tf","87803755":"from tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Dense","9b070230":"### Define vocabulary size\nvoc_size = 5000\n","d8b6fe17":"messages = X.copy()\nmessages.reset_index(inplace=True)","276f2b9e":"### Data Preprocessing\n# Remove stopwords\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\nimport re\nfrom nltk.corpus import stopwords\nnltk.download('stopwords')","6771e64c":"corpus = []\nfor i in range(len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)\n\n","bd5ddaeb":"corpus[:5]","3d422aed":"# One hot representation\nonehot = [one_hot(words, voc_size) for words in corpus]\nonehot[:5]","3246ab7c":"max([len(vec) for vec in onehot])","75c24ec7":"# Pad the sentences, make fixed length\nmax_length = 50\nembedded_docs = pad_sequences(onehot, padding = 'pre', maxlen = max_length)\nembedded_docs[:5]","751a6526":"embedding_features_length = 40\nfrom tensorflow.keras.layers import Dropout\nmodel = Sequential()\nmodel.add(Embedding(voc_size, embedding_features_length, input_length = max_length))\nmodel.add(Dropout(0.4))\nmodel.add(LSTM(100))\nmodel.add(Dropout(0.4))\nmodel.add(Dense(1, activation = 'sigmoid'))","f8928e9d":"#Compile the model\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nprint(model.summary())\n","6c7f792a":"import numpy as np\nX_final = np.array(embedded_docs)\ny_final = np.array(y)","5c0a609e":"X_final.shape, y_final.shape","518a50b3":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size = 0.2, random_state = 40)\nX_train.shape, X_test.shape, y_train.shape, y_test.shape","9528e754":"# Fit the model\n# Now we fit the model\nmodel.fit(X_train, y_train, validation_data = (X_test, y_test), epochs = 5, batch_size = 64)\n","30594051":"y_pred = model.predict_classes(X_test)","3f442927":"from sklearn.metrics import confusion_matrix","14b401d8":"confusion_matrix(y_test, y_pred)","fe65d4c0":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","a128e741":"Import tensorflow","76514857":"Model","6bba4213":"#### We use just the titles","ba4365e4":"Fit the model","b086d2af":"## One hot representation","759f7884":"Split into train\/test layer","4f605e15":"# LSTM Practice Using Keras\n### About the dataset:\nThis dataset is about news, classified into real and fake news."}}