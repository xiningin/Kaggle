{"cell_type":{"01404588":"code","497c16da":"code","d5266670":"code","666b6cbd":"code","ee09125e":"code","6d7facd6":"code","2646ff99":"code","357dc7e2":"code","c8956b74":"code","d53eeb36":"code","cc949bec":"code","e8159c12":"code","46541b5b":"code","abc4b109":"code","511527ed":"code","34793191":"code","0dd3dc1c":"code","15793de8":"code","7e8db20c":"code","44c133a7":"code","eaa7e47c":"code","3a540d70":"code","7cae6ce5":"code","a6574ede":"code","e7fb0356":"code","c0697b03":"code","5507eaea":"code","2e613b29":"code","33dfd197":"code","05a2262c":"code","b9f0b0fa":"code","65542386":"code","370b912d":"code","3558d33e":"code","a5d29583":"code","d63341ab":"code","c4429bc0":"code","5474eedd":"code","91d0cc36":"code","c9d7f3f3":"code","16b40bf1":"code","7a2d344f":"code","d7a0466a":"code","bb9cbc40":"code","35cc74f8":"code","9dc1d8c0":"code","9b20f932":"code","a03b5b24":"code","d83e72f5":"code","98b91990":"code","eb79ad34":"code","0f7c1c9e":"code","3a1f79d6":"code","be4429df":"code","1be2b432":"code","8a9233db":"code","a8d41ac9":"code","6192c822":"code","4b743b92":"code","b9fc1fcd":"code","3ae91ae9":"code","893996f1":"code","9ce8c77a":"code","7b5fa2ca":"code","6f8a255b":"code","2014566a":"code","fb9c452c":"code","2576544a":"code","ad58c9a4":"code","a41459ea":"code","9a2c827d":"code","bd617df4":"code","42d728be":"code","637b8925":"code","7bdafafe":"code","1c88aed1":"code","bc93a3d1":"code","6e6478d3":"code","88183887":"code","8b0abf1e":"code","d1bcd1d3":"code","67046557":"code","3646e906":"code","d970e26f":"code","2fb8b342":"code","9374fdbb":"code","24cf18ff":"code","40bb5df0":"code","ed9726e6":"code","3746323a":"code","510d26dd":"code","4119aefe":"code","6a509a56":"code","4e6d3367":"code","ed67deee":"code","e1d75d8f":"code","d1ced312":"code","225ae880":"code","dd409043":"code","debcf055":"code","ec41085e":"code","d5ba395c":"code","f491c67d":"code","2947b2ef":"code","0e4ad941":"code","cf1b74c2":"code","964ed3c3":"code","0515063e":"code","c5ae43e3":"code","017944c8":"code","a9554b99":"code","b98d7aa5":"code","89887597":"markdown","8a95a3a4":"markdown","9cc8f538":"markdown","05153a3d":"markdown","39ca0cb4":"markdown","8401fe8d":"markdown","0a1542b8":"markdown","9f9e21f7":"markdown","9a8a57fd":"markdown","45f2c5c3":"markdown","921685c7":"markdown","7fa2429e":"markdown","406a7a29":"markdown","183521ed":"markdown","028b28e9":"markdown","da58ddd0":"markdown","b1debf64":"markdown","80171351":"markdown","b786bd49":"markdown","dcd6f4a8":"markdown","e5e0f21e":"markdown","ebeec975":"markdown","3e4df1a9":"markdown","7c0f936a":"markdown","fc2eeec8":"markdown","54cb6293":"markdown","51d85e2f":"markdown","2c7be1a5":"markdown","61a16d77":"markdown","10042534":"markdown","905482bb":"markdown","7a3f8241":"markdown","5109ce6b":"markdown","a6db3c43":"markdown","292ff4c4":"markdown","3b0e3937":"markdown","4106b07c":"markdown","c17b63b4":"markdown"},"source":{"01404588":"\nimport numpy as np \nimport pandas as pd \n\n","497c16da":"path = \"..\/input\/eda-for-biginner-updated-to-english-ver\"","d5266670":"traindf = pd.read_csv(path+\"\/traindf.csv\")\ntraindf","666b6cbd":"tmp = traindf[traindf[\"landmark_id\"]==7]\ntmp","ee09125e":"import cv2\nimport matplotlib.pyplot as plt","6d7facd6":"for a in tmp[\"path\"]:\n    img = cv2.imread(a)\n    plt.figure()\n    plt.imshow(img)","2646ff99":"dfcnt = pd.read_csv(path+\"\/dfcnt.csv\")\ndfcnt","357dc7e2":"plt.scatter(dfcnt[\"id\"],dfcnt[\"count\"])","c8956b74":"traindf","d53eeb36":"dfcnt","cc949bec":"tmp1 = dfcnt[\"id\"].iloc[0]\ntmp1","e8159c12":"tmpdf1 = traindf[traindf[\"landmark_id\"]==tmp1]\ntmpdf1","46541b5b":"tlist = []\nvlist = []","abc4b109":"tlist.append(tmpdf1.iloc[0].values)\ntlist","511527ed":"vlist.append(tmpdf1.iloc[1].values)","34793191":"# \u3053\u308c\u3092\u7e70\u308a\u8fd4\u3059","0dd3dc1c":"from tqdm import tqdm","15793de8":"import os\nos.path.exists(\".\/tdf.csv\")","7e8db20c":"tlist = []\nvlist = []","44c133a7":"if os.path.exists(\".\/tdf.csv\")==False:\n    \n\n    \n\n    tmp1 = dfcnt[\"id\"].values #.values\u3067numpy. for\u6587\u306fnumpy\u306e\u307b\u3046\u304c\u65e9\u3044\u3068\u304d\u304c\u3042\u308b\u3002\n\n    for a in tqdm(range(len(dfcnt))):\n\n        tmpdf1 = traindf[traindf.landmark_id.values==tmp1[a]]\n        tlist.append(tmpdf1.iloc[0].values)\n        vlist.append(tmpdf1.iloc[1].values)","eaa7e47c":"tdf = pd.DataFrame(tlist,columns=tmpdf1.columns)\ntdf[\"repair_id\"]=np.arange(0,len(tdf),1)\ntdf","3a540d70":"vdf = pd.DataFrame(vlist,columns=tmpdf1.columns)\nvdf[\"repair_id\"]=np.arange(0,len(vdf),1)\nvdf","7cae6ce5":"if os.path.exists(\".\/tdf.csv\"):\n    tdf = pd.read_csv(\".\/tdf.csv\")\n    vdf = pd.read_csv(\".\/vdf.csv\")","a6574ede":"tdf.to_csv(\"tdf.csv\",index=False)\nvdf.to_csv(\"vdf.csv\",index=False)","e7fb0356":"tdf2 = tdf.iloc[:10,:]\nvdf2 = vdf.iloc[:10,:]","c0697b03":"tdf2","5507eaea":"vdf2","2e613b29":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn, optim\nfrom torch.nn import functional as F\nfrom torchvision.models import resnet18\nfrom albumentations import Normalize, Compose\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nfrom tqdm.notebook import tqdm\nfrom sklearn.model_selection import train_test_split\nimport os\nimport glob\nimport multiprocessing as mp\n\n\n\nif torch.cuda.is_available():\n    device = 'cuda:0'\n    torch.set_default_tensor_type('torch.cuda.FloatTensor')\nelse:\n    device = 'cpu'\nprint(f'Running on device: {device}')","33dfd197":"preprocess = Compose([\n    Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225], p=1)\n])\n\n# resnext\u306a\u3069\u306epre-train\u30e2\u30c7\u30eb\u306f\u5168\u3066\u3001\u540c\u3058\u65b9\u6cd5\u3067\u6b63\u898f\u5316\u3055\u308c\u305f\u5165\u529b\u753b\u50cf\u3092\u4f7f\u7528\u3057\u306a\u3051\u308c\u3070\u306a\u3089\u306a\u3044\u3002\u305d\u308c\u306e\u5909\u63db\u3092\u3053\u306e\u95a2\u6570\u3067\u884c\u3046\u3002\u5024\u306fdefault\u3002\n# Compose\u306f\u4eca\u56de\u3042\u307e\u308a\u3001\u610f\u5473\u3092\u306a\u3055\u306a\u3044\n# https:\/\/betashort-lab.com\/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9\/albumentations%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81\/ \u306b\u8a73\u7d30\u306f\u66f8\u3044\u3066\u3042\u308b","05a2262c":"# \u753b\u50cf\u3092\u3069\u308c\u3060\u3051\u5c0f\u3055\u304f\u3059\u308b\u304b\u306e\u51e6\u7406\nROWS = 32\nCOLS = 32","b9f0b0fa":"class GLDataset(Dataset):\n    \n    def __init__(self,img_pass,labels,preprocess=None):\n        self.img_pass = img_pass\n        self.labels = labels\n        self.preprocess = preprocess\n        \n    def __len__(self):\n        return len(self.img_pass)\n    \n    def __getitem__(self,idx):\n        \n        # \u3053\u3053\u304b\u3089dataset\u306b\u98df\u308f\u305b\u308b\u524d\u306e\u524d\u51e6\u7406\u306e\u8a18\u8ff0\u3002\n        \n        img_pass = self.img_pass[idx]\n        label = self.labels[idx]\n        \n        land = cv2.imread(img_pass)\n        land = cv2.resize(land,(ROWS,COLS),interpolation = cv2.INTER_CUBIC)\n        land = cv2.cvtColor(land,cv2.COLOR_BGR2RGB) # augment\u3092\u4f7f\u3046\u3068\u304d\u306bBGR\u304b\u3089RGB\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u304b\u3082\u3057\u308c\u306a\u3044\u3002\n        \n        if self.preprocess is not None: # \u3053\u3053\u3067\u3001\u524d\u51e6\u7406\u3092\u5165\u308c\u3066normalization\u3057\u3066\u3044\u308b\u3002\n                augmented = self.preprocess(image=land) # preprocess\u306eimage\u3092face\u3067\u8aad\u3080\n                land = augmented['image'] # https:\/\/betashort-lab.com\/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9\/albumentations%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81\/\u3000\u306b\u66f8\u3044\u3066\u3042\u308b\n                \n        return {'landmarks': land.transpose(2, 0, 1), 'label': np.array(label, dtype=int)}  # pytorch\u306fchannnl, x, y\u306e\u5f62\u3002\u3053\u308c\u306f\u8f9e\u66f8\u578b\u3067\u8fd4\u3057\u3066\u3044\u308b\u3002(\u6271\u3044\u3084\u3059\u3044\u3068\u3044\u3046\u3060\u3051\u304b\u3082\u3002)\n        \n        \n        \n        \n        \n        \n        \n        ","65542386":"land = cv2.imread(tdf2[\"path\"].iloc[0])","370b912d":"plt.imshow(land)","3558d33e":"land = cv2.resize(land,(ROWS,COLS),interpolation = cv2.INTER_CUBIC)","a5d29583":"plt.imshow(land)","d63341ab":"land = cv2.cvtColor(land,cv2.COLOR_BGR2RGB) # augment\u3092\u4f7f\u3046\u3068\u304d\u306bBGR\u304b\u3089RGB\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u304b\u3082\u3057\u308c\u306a\u3044\u3002","c4429bc0":"plt.imshow(land)","5474eedd":"augmented = preprocess(image=land) # preprocess\u306eimage\u3092face\u3067\u8aad\u3080\nland = augmented['image']","91d0cc36":"plt.imshow(land)","c9d7f3f3":"land.shape","16b40bf1":"land=land.transpose(2, 0, 1)","7a2d344f":"land.shape","d7a0466a":"# instance\u5316\ntrain_dataset = GLDataset(\n    img_pass=tdf2[\"path\"],\n    labels=tdf2[\"repair_id\"].to_numpy(),\n    preprocess=preprocess\n)\n\nval_dataset = GLDataset(\n    img_pass=vdf2[\"path\"],\n    labels=vdf2[\"repair_id\"].to_numpy(),\n    preprocess=preprocess\n)","bb9cbc40":"print(train_dataset[0])","35cc74f8":"BATCH_SIZE = 2\n\n#NUM_WORKERS = mp.cpu_count()\nNUM_WORKERS = mp.cpu_count() # \u3053\u3053\u30920\u306b\u3057\u306a\u3044\u3068\u52d5\u304b\u306a\u3044\u3002cpu\u306e\u4ed5\u69d8\u500b\u6570\u3002\u2190\u5b9f\u306f\u52d5\u304f\u3053\u3068\u304c\u5224\u660e\u3002class\u306e\u4e2d\u8eab\u6b21\u7b2c\uff01","9dc1d8c0":"#NUM_WORKERS = mp.cpu_count()\n#NUM_WORKERS","9b20f932":"## DataLoader\u306fimport torch.utils.data.Dataset\u3067import\u6e08\u307f\u306e\u3082\u306e\ntrain_dataloader = DataLoader(\n    train_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False, #https:\/\/schemer1341.hatenablog.com\/entry\/2019\/01\/06\/024605 \u3092\u53c2\u8003. id\u304c\u308f\u304b\u3089\u306a\u304f\u306a\u308b\n    num_workers=NUM_WORKERS\n)\nval_dataloader = DataLoader(\n    val_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False,\n    num_workers=NUM_WORKERS\n)","a03b5b24":"class PytorchDataSet():\n    \n    def __init__(self,Dataset,train_imgpath,train_label,val_imgpath,val_label,batch_size,num_workers,shuffle=True):\n        \n        self.Dataset = Dataset\n        self.train_imgpath = train_imgpath\n        self.train_label = train_label\n        self.val_imgpath = val_imgpath\n        self.val_label = val_label\n        \n        self.batch_size = batch_size\n        self.num_workers = num_workers\n        self.shuffle = shuffle\n               \n               \n        self.train_dataset = self.Dataset(\n            img_pass=self.train_imgpath,\n            labels=self.train_label.to_numpy(),\n            preprocess=preprocess\n)\n        \n        self.val_dataset = self.Dataset(\n            img_pass=self.val_imgpath,\n            labels=self.val_label.to_numpy(),\n            preprocess=preprocess\n        )\n        \n                ## DataLoader\u306fimport torch.utils.data.Dataset\u3067import\u6e08\u307f\u306e\u3082\u306e\n        self.train_dataloader = DataLoader(\n            self.train_dataset,\n            batch_size=self.batch_size,\n            shuffle=self.shuffle, #https:\/\/schemer1341.hatenablog.com\/entry\/2019\/01\/06\/024605 \u3092\u53c2\u8003. id\u304c\u308f\u304b\u3089\u306a\u304f\u306a\u308b\n            num_workers=self.num_workers\n        )\n        self.val_dataloader = DataLoader(\n            self.val_dataset,\n            batch_size=self.batch_size,\n            shuffle=self.shuffle,\n            num_workers=self.num_workers\n        )\n        ","d83e72f5":"# example\nbase = PytorchDataSet(GLDataset,tdf2[\"path\"],tdf2[\"repair_id\"],vdf2[\"path\"],vdf2[\"repair_id\"],BATCH_SIZE,NUM_WORKERS)","98b91990":"# \u3053\u3046\u3057\u3066\u304a\u304f\u3068\u3001\u4f8b\u3048\u3070\u3001\u5168\u90e8\u306e\u753b\u50cf\u3067\u3084\u308b\u3068\u304d\u306b\u4fbf\u5229\u3002\n# \u5168\u90e8\u306e\u753b\u50cf\u3067\u3084\u308b\u3068\u304d\n# base = PytorchDataSet(GLDataset,tdf[\"path\"],tdf[\"repair_id\"],vdf[\"path\"],vdf[\"repair_id\"],BATCH_SIZE,NUM_WORKERS)","eb79ad34":"# example\nfor a in base.train_dataloader:\n    print(a)","0f7c1c9e":"encoder = resnet18(pretrained=True) #  pretrained = True\u306fimagenet\u304b\u3089pre-train\u30e2\u30c7\u30eb\u3092\u4f7f\u3046","3a1f79d6":"class LandmarkClassifier(nn.Module): # nn.Module\u304c\u5165\u3063\u3066\u3044\u308b\u306e\u304c\u3001\u30e2\u30c7\u30eb\u306e\u5b9a\u7fa9\u3063\u307d\u3044\n    \n    def __init__(self, encoder, in_channels=3, num_classes=len(dfcnt)): \n        \n        super(LandmarkClassifier, self).__init__() # nn.Module\u306e__init__\u3092\u7d99\u627f\u3002https:\/\/blog.codecamp.jp\/python-class-2\n        \n        self.encoder = encoder\n        \n        # Modify input layer. # \u5165\u53e3\u306e\u30c1\u30e3\u30f3\u30cd\u30eb\u6570\u3092\u5408\u308f\u305b\u308b\u3002default\u306eResnet\u306eclass\u306f64 channel\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001\u305d\u308c\u3092in_channels\u306b\u3059\u308b\u3002\n        # \u3053\u3053\u306e\u8a18\u8ff0\u304cencoder\u3054\u3068\u306b\u4ee3\u308f\u308b\u306e\u3067\u3001efficientnet\u4f7f\u3046\u3068\u304d\u306f\u5909\u3048\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\n        \n        self.encoder.conv1 = nn.Conv2d(\n            in_channels,\n            64,\n            kernel_size=7,\n            stride=2,\n            padding=3,\n            bias=False\n        )\n        \n        # Modify output layer.# \u51fa\u53e3\u306e\u500b\u6570\u3082\u5408\u308f\u305b\u308b\u3002default\u306eResnet\u306e\u51fa\u53e3\u306f\u30011000\u306b\u306a\u3063\u3066\u3044\u308b\u306e\u3067\u3001num_classes\u306b\u5909\u66f4\n        # \u3053\u3053\u306e\u8a18\u8ff0\u304cencoder\u3054\u3068\u306b\u4ee3\u308f\u308b\u306e\u3067\u3001efficientnet\u4f7f\u3046\u3068\u304d\u306f\u5909\u3048\u306a\u3051\u308c\u3070\u3044\u3051\u306a\u3044\n        \n        self.encoder.fc = nn.Linear(512 * 1, num_classes)\n\n    def forward(self, x): # \u547c\u3073\u51fa\u3055\u308c\u305f\u3068\u304d\u306b\u3001x\u306e\u5f15\u6570\u304c\u3042\u308b\u3068\u3001sigmoid\u3067\u8fd4\u3059\u3002ex) \u5f8c\u307b\u3069\u306eclassifier(sample_batched[\"landmark\"]) \u307f\u305f\u3044\u306a\u3068\u3053\u308d\u3002\n        \n        # sigmoid\u3067\u8fd4\u3059\u3068\u304d\u306f\u4ee5\u4e0b\u306e\u611f\u3058\u3000https:\/\/aidiary.hatenablog.com\/entry\/20180203\/1517629555\n        # return torch.sigmoid(self.encoder(x))\n        \n        # \u591a\u5024\u554f\u984c\u3067\u3082\u3001softmax\u306f\u3053\u3053\u3067\u306f\u4f7f\u308f\u306a\u3044\u3002nn.CrossEntropy\u306b\u65e2\u306b\u5165\u3063\u3066\u3044\u308b\u305f\u3081\n        return self.encoder(x)\n    \n    \n    \n    \n    \n    ### \u4ee5\u4e0b\u3001\u3069\u3053\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc\u3092\u6700\u9069\u5316\u3059\u308b\u304b\u3002\u7c21\u6613\u30c6\u30b9\u30c8\u7528\u306f\u771f\u3093\u4e2d\u3002\u30d5\u30eb\u30aa\u30d7\u30b7\u30e7\u30f3\u306f\u4e0b\u3002\u3053\u3053\u306f\u3054\u53c2\u8003\u3002###\n    \n    def freeze_all_layers(self):# \u4e2d\u9593\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc(\u91cd\u307f\u3065\u3051)\u3092\u5168\u90e8\u5909\u3048\u306a\u3044\u3002\n        for param in self.encoder.parameters():\n            param.requires_grad = False\n\n    def freeze_middle_layers(self):\n        self.freeze_all_layers()\n        \n        for param in self.encoder.conv1.parameters():# \u6700\u521d\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc(\u91cd\u307f\u3065\u3051)\u3092\u5909\u3048\u308b\u3002\n            param.requires_grad = True\n            \n        for param in self.encoder.fc.parameters():# \u6700\u5f8c\u306e(\u91cd\u307f\u3065\u3051)\u3092\u5909\u3048\u308b\u3002\n            param.requires_grad = True\n\n    def unfreeze_all_layers(self):# \u4e2d\u9593\u5c64\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u30fc(\u91cd\u307f\u3065\u3051)\u3092\u5168\u90e8\u5909\u3048\u308b\u3002\n        for param in self.encoder.parameters():\n            param.requires_grad = True","be4429df":"\nclassifier = LandmarkClassifier(encoder=encoder, in_channels=3, num_classes=len(dfcnt)) # classifier\u306fDeepfakeClassifier\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316\n\n# classifier.to(device) # \u3053\u3053\u304cKeras\u3068\u306f\u9055\u3046\u3068\u3053\u308d\u3002GPU\u306b\u9001\u308a\u307e\u3059\u3088\u30fc\u3068\u3044\u3046\u610f\u5473\u3002\u4eca\u56de\u306fcpu\u306a\u306e\u3067\u3001pass.\n\nclassifier.train() # \u3053\u3053\u304cKeras\u3068\u306f\u9055\u3046\u3068\u3053\u308d\u3002 \u8a13\u7df4\u30e2\u30fc\u30c9\u306e\u5834\u5408 classifier.train() , \u63a8\u8ad6\u306e\u5834\u5408 classifier.eval() \u3068\u66f8\u304f\u3002Normalize\u306e\u30d7\u30ed\u30bb\u30b9\u306a\u3069\u304c\u9055\u3046\u3089\u3057\u3044\u3002","1be2b432":"# \u4eca\u56de\u306f\u5168\u90e8\u6700\u9069\u5316\nclassifier.unfreeze_all_layers()","8a9233db":"criterion = nn.CrossEntropyLoss()\n# \u591a\u5024\u5206\u985e\u306fcrossentropy","a8d41ac9":"#optimizer = optim.Adam(filter(lambda p: p.requires_grad, classifier.parameters()),lr=1e-5)\noptimizer = optim.Adam(classifier.parameters(),lr=1e-6)\n#optimizer = optim.SGD(classifier.parameters(),lr=1e-5)\n\n# conv\u5c64(model.features)\u306e\u30d1\u30e9\u30e1\u30fc\u30bf\u3092\u56fa\u5b9a\u3057\u3001\u5168\u7d50\u5408\u5c64(model.classifier)\u306e\u307f\u3092finetune\u3059\u308b\u8a2d\u5b9a\u3067\u3059\u3002\n# \u5168\u5c64\u306e\u3046\u3061\u3001requires_grad\u304cTrue\u306e\u5c64\u306e\u307f\u3092finetune\u3059\u308b\u3068\u3044\u3046\u610f\u5473\u3067\u3059\u3002\n# lr : \u5b66\u7fd2\u7387","6192c822":"classifier.train()","4b743b92":"train_dataloader[0]","b9fc1fcd":"# \u8aad\u3081\u306a\u3044\u306e\u3067\u3001\u4ee5\u4e0b\u3067\u78ba\u8a8d\u3002\nfor a in train_dataloader:\n    print(a)\n","3ae91ae9":"for a in train_dataloader:\n    y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n    print(y_pred)\n    ","893996f1":"y_pred","9ce8c77a":"len(y_pred[0])","7b5fa2ca":"for a in train_dataloader:\n    y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n    label = a[\"label\"]\n    \n    loss = criterion(y_pred, label)\n    print(loss)","6f8a255b":"for a in train_dataloader:\n    y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n    label = a[\"label\"]\n    \n    loss = criterion(y_pred, label)\n    print(loss.item())","2014566a":"for a in train_dataloader:\n    y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n    label = a[\"label\"]\n    \n    loss = criterion(y_pred, label)\n    print(loss.item())\n    \n    # Zero gradients, perform a backward pass, and update the weights.\n    optimizer.zero_grad() # \u304a\u304d\u307e\u308a\u3002\u521d\u671f\u5316\u3002\n    loss.backward() # \u5f8c\u65b9\u306b\u30d0\u30c3\u30af\n    optimizer.step() # \u91cd\u307f\u3065\u3051\u306e\u6700\u9069\u5316","fb9c452c":"classifier.train()\ntrainloss = []\n\nfor a in train_dataloader:\n    y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n    \n    \n    label2 = a[\"label\"]\n    \n    loss = criterion(y_pred, label2)\n    print(loss.item()) # item\u306f0\u6b21\u5143tensor\u304b\u3089\u6574\u6570\u3092\u51fa\u3059\u5834\u5408\u3002\n    \n    # Zero gradients, perform a backward pass, and update the weights.\n    optimizer.zero_grad() # \u304a\u304d\u307e\u308a\u3002\u521d\u671f\u5316\u3002\n    loss.backward() # \u5f8c\u65b9\u306b\u30d0\u30c3\u30af\n    optimizer.step() # \u91cd\u307f\u3065\u3051\u306e\u6700\u9069\u5316\n    \ntrainloss.append(loss.item())","2576544a":"def trainmodel(train_dataloader):\n    classifier.train()\n    \n    for a in train_dataloader:\n        y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n        label = a[\"label\"]\n\n        loss = criterion(y_pred, label)\n\n        # Zero gradients, perform a backward pass, and update the weights.\n        optimizer.zero_grad() # \u304a\u304d\u307e\u308a\u3002\u521d\u671f\u5316\u3002\n        loss.backward() # \u5f8c\u65b9\u306b\u30d0\u30c3\u30af\n        optimizer.step() # \u91cd\u307f\u3065\u3051\u306e\u6700\u9069\u5316\n        \n    return(loss.item())\n    \n    ","ad58c9a4":"classifier.eval() # \u3053\u3053\u304c\u63a8\u8ad6\u306a\u306e\u3067\u3001\u5909\u3048\u306a\u304d\u3083\u30c0\u30e1\u3002","a41459ea":"classifier.eval() # \u3053\u3053\u304c\u63a8\u8ad6\u306a\u306e\u3067\u3001\u5909\u3048\u306a\u304d\u3083\u30c0\u30e1\u3002\nval_loss = []\n\nfor a in val_dataloader:\n    y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n    \n   \n    label = a[\"label\"]\n    \n    lossval = criterion(y_pred, label)\n    print(lossval.item()) # item\u306f0\u6b21\u5143tensor\u304b\u3089\u6574\u6570\u3092\u51fa\u3059\u5834\u5408\u3002\n\nval_loss.append(lossval.item())\n    \n","9a2c827d":"def valmodel(val_dataloader):\n    \n    classifier.eval()\n    \n    for a in val_dataloader:\n\n        y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n        label = a[\"label\"]\n\n        loss = criterion(y_pred, label)\n        \n    return(loss.item())\n    \n    ","bd617df4":"epochs = 10","42d728be":"\"\"\"\n\ntrainloss = []\nvalloss = []\n\n\nfor epoch in range(epochs):\n    \n    tloss_tmp =[]\n    vloss_tmp =[]\n\n    \n    ####### train #######\n    classifier.train()\n    \n\n    for a in train_dataloader:\n        y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n        \n        # y_pred = torch.sigmoid(y_pred) \u672c\u6765\u9055\u3046\u306e\u3060\u3051\u3069\u306a\u305c\u304b\u3053\u308c\u3092\u5165\u308c\u305f\u65b9\u304c\u30b9\u30b3\u30a2\u304c\u826f\u3044\n\n        y_pred2 = y_pred.squeeze(dim=-1)\n        label2 = a[\"label\"].squeeze(dim=-1)\n\n        loss = criterion(y_pred2, label2)\n        tloss_tmp.append(loss.item())\n        # print(loss.item()) # item\u306f0\u6b21\u5143tensor\u304b\u3089\u6574\u6570\u3092\u51fa\u3059\u5834\u5408\u3002\n\n        # Zero gradients, perform a backward pass, and update the weights.\n        optimizer.zero_grad() # \u304a\u304d\u307e\u308a\u3002\u521d\u671f\u5316\u3002\n        loss.backward() # \u5f8c\u65b9\u306b\u30d0\u30c3\u30af\n        optimizer.step() # \u91cd\u307f\u3065\u3051\u306e\u6700\u9069\u5316\n\n    trainloss.append(tloss_tmp[-1])\n    \n    #######validation#######\n    \n    classifier.eval() # \u3053\u3053\u304c\u63a8\u8ad6\u306a\u306e\u3067\u3001\u5909\u3048\u306a\u304d\u3083\u30c0\u30e1\u3002\n    \n\n    for a in val_dataloader:\n        y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n        \n        # y_pred = torch.sigmoid(y_pred) \u672c\u6765\u9055\u3046\u306e\u3060\u3051\u3069\u306a\u305c\u304b\u3053\u308c\u3092\u5165\u308c\u305f\u65b9\u304c\u30b9\u30b3\u30a2\u304c\u826f\u3044\n\n\n        y_pred2 = y_pred.squeeze(dim=-1)\n        label2 = a[\"label\"].squeeze(dim=-1)\n\n        lossval = criterion(y_pred2, label2)\n        vloss_tmp.append(lossval.item())\n        # print(lossval.item()) # item\u306f0\u6b21\u5143tensor\u304b\u3089\u6574\u6570\u3092\u51fa\u3059\u5834\u5408\u3002\n\n    valloss.append(vloss_tmp[-1])\n    \n    print(str(epoch) + \"_end\")\n\n    \n\n\"\"\"","637b8925":"trainloss = []\nvalloss = []\n\n\nfor epoch in range(epochs):\n    \n    trainloss.append(trainmodel(train_dataloader))\n    valloss.append(valmodel(val_dataloader))\n    \n    print(str(epoch) + \"_end\")\n\n    ","7bdafafe":"x = np.arange(epochs)\nplt.scatter(x,trainloss)","1c88aed1":"plt.figure()\nplt.scatter(x,valloss)","bc93a3d1":"savename=\"resnet18.pth\"","6e6478d3":"trainloss = []\nvalloss = []\n\nbestloss = None\n\nfor epoch in range(epochs):\n    \n    trainloss.append(trainmodel(train_dataloader))\n    valloss.append(valmodel(val_dataloader))\n    \n    print(str(epoch) + \"_end\")\n    \n    #######model\u3092save#######\n    \n    if bestloss is None:\n        bestloss = valloss[-1]\n        state = {\n                'state_dict': classifier.state_dict(),\n                'optimizer_dict': optimizer.state_dict(),\n                \"bestloss\":bestloss,\n            }\n\n        torch.save(state, savename)\n        \n        print(\"save the first model\")\n    \n    elif valloss[-1] < bestloss:\n        \n        bestloss = valloss[-1]\n        state = {\n                'state_dict': classifier.state_dict(),\n                'optimizer_dict': optimizer.state_dict(),\n            \"bestloss\":bestloss,\n            }\n\n        torch.save(state, savename)\n        \n        print(\"found a better point\")\n    \n    else:\n        pass\n\n    ","88183887":"def savemodel(bestloss,valloss):\n    \n    #######model\u3092save#######\n    \n    if bestloss is None:\n        bestloss = valloss[-1]\n        state = {\n                'state_dict': classifier.state_dict(),\n                'optimizer_dict': optimizer.state_dict(),\n                \"bestloss\":bestloss,\n            }\n\n        torch.save(state, savename)\n        \n        print(\"save the first model\")\n    \n    elif valloss[-1] < bestloss:\n        \n        bestloss = valloss[-1]\n        state = {\n                'state_dict': classifier.state_dict(),\n                'optimizer_dict': optimizer.state_dict(),\n                \"bestloss\":bestloss,\n            }\n\n        torch.save(state, savename)\n        \n        print(\"found a better point\")\n    \n    else:\n        pass\n    \n    return bestloss\n","8b0abf1e":"trainloss = []\nvalloss = []\n\nbestloss = None\n\nfor epoch in range(epochs):\n    \n    trainloss.append(trainmodel(train_dataloader))\n    valloss.append(valmodel(val_dataloader))\n    \n    print(str(epoch) + \"_end\")\n    \n    bestloss= savemodel(bestloss,valloss)\n    \n    print(bestloss)\n    \n    \n    ","d1bcd1d3":"plt.scatter(x,trainloss)\nplt.scatter(x,valloss)","67046557":"class MakingModel():\n    \n    def __init__(self,train_dataloader,val_dataloader,epochs,savename,bestloss=None):\n        \n        self.train_dataloader = train_dataloader\n        self.val_dataloader = val_dataloader\n        self.epochs = epochs\n        \n        if bestloss is None:\n            self.bestloss = bestloss\n        else:\n            self.bestloss = None\n            \n        self.savename = savename\n\n        self.trainloss=[]\n        self.valloss=[]\n        \n        self.makemodel()\n        \n    \n    \n    def trainmodel(self):\n        \n        classifier.train()\n\n        for a in self.train_dataloader:\n            y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n            label = a[\"label\"]\n\n            loss = criterion(y_pred, label)\n\n            # Zero gradients, perform a backward pass, and update the weights.\n            optimizer.zero_grad() # \u304a\u304d\u307e\u308a\u3002\u521d\u671f\u5316\u3002\n            loss.backward() # \u5f8c\u65b9\u306b\u30d0\u30c3\u30af\n            optimizer.step() # \u91cd\u307f\u3065\u3051\u306e\u6700\u9069\u5316\n\n        return(loss.item())\n    \n    \n    def valmodel(self):\n        classifier.eval()\n\n        for a in self.val_dataloader:\n            y_pred = classifier(a['landmarks']) # onenote\u3067\u3044\u3046output = model(train_x)\n            label = a[\"label\"]\n\n            loss = criterion(y_pred, label)\n\n\n        return(loss.item())\n    \n    \n    \n    def savemodel(self):\n    \n        #######model\u3092save#######\n\n        if self.bestloss is None:\n            self.bestloss = self.valloss[-1]\n            state = {\n                    'state_dict': classifier.state_dict(),\n                    'optimizer_dict': optimizer.state_dict(),\n                    \"bestloss\":self.bestloss,\n                }\n\n            torch.save(state, self.savename)\n\n            print(\"save the first model\")\n\n        elif self.valloss[-1] < self.bestloss:\n\n            self.bestloss = self.valloss[-1]\n            state = {\n                    'state_dict': classifier.state_dict(),\n                    'optimizer_dict': optimizer.state_dict(),\n                    \"bestloss\":self.bestloss,\n                }\n\n            torch.save(state, self.savename)\n\n            print(\"found a better point\")\n\n        else:\n            pass\n\n        return self.bestloss\n    \n    \n    def makemodel(self):\n\n        for epoch in range(self.epochs):\n\n            self.trainloss.append(self.trainmodel())\n            self.valloss.append(self.valmodel())\n\n            print(str(epoch) + \"_end\")\n\n            self.bestloss= self.savemodel()\n\n            print(self.bestloss)\n\n\n\n\n    \n    \n        \n        ","3646e906":"tmp = MakingModel(train_dataloader,val_dataloader,epochs,\"test.pth\",bestloss=None)","d970e26f":"x = np.arange(tmp.epochs)\nplt.scatter(x,tmp.trainloss)\nplt.scatter(x,tmp.valloss)","2fb8b342":"tmp.savename","9374fdbb":"test_path = []\n\nimport os\nfor dirname, _, filenames in os.walk('..\/input\/landmark-recognition-2020\/test'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        test_path.append(os.path.join(dirname, filename))","24cf18ff":"test_path[:10]","40bb5df0":"testid = [s.split(\"\/\")[-1] for s in test_path]\ntestid = [s.split(\".\")[0] for s in testid]\ntestid[:10]","ed9726e6":"testdf = pd.DataFrame()\ntestdf[\"id\"] = testid\ntestdf[\"path\"] = test_path\ntestdf","3746323a":"class GLDataset_inf(Dataset):\n    \n    def __init__(self,testid,img_pass,preprocess=None):\n        self.testid = testid\n        self.img_pass = img_pass\n        self.preprocess = preprocess\n        \n    def __len__(self):\n        return len(self.img_pass)\n    \n    def __getitem__(self,idx):\n        \n        # \u3053\u3053\u304b\u3089dataset\u306b\u98df\u308f\u305b\u308b\u524d\u306e\u524d\u51e6\u7406\u306e\u8a18\u8ff0\u3002\n        \n        img_id = self.testid[idx]\n        \n        img_pass = self.img_pass[idx]\n        \n        land = cv2.imread(img_pass)\n        land = cv2.resize(land,(ROWS,COLS),interpolation = cv2.INTER_CUBIC)\n        land = cv2.cvtColor(land,cv2.COLOR_BGR2RGB) # augment\u3092\u4f7f\u3046\u3068\u304d\u306bBGR\u304b\u3089RGB\u306b\u3059\u308b\u5fc5\u8981\u304c\u3042\u308b\u306e\u304b\u3082\u3057\u308c\u306a\u3044\u3002\n        \n        if self.preprocess is not None: # \u3053\u3053\u3067\u3001\u524d\u51e6\u7406\u3092\u5165\u308c\u3066normalization\u3057\u3066\u3044\u308b\u3002\n                augmented = self.preprocess(image=land) # preprocess\u306eimage\u3092face\u3067\u8aad\u3080\n                land = augmented['image'] # https:\/\/betashort-lab.com\/%E3%83%87%E3%83%BC%E3%82%BF%E3%82%B5%E3%82%A4%E3%82%A8%E3%83%B3%E3%82%B9\/albumentations%E3%81%AE%E3%81%BE%E3%81%A8%E3%82%81\/\u3000\u306b\u66f8\u3044\u3066\u3042\u308b\n                \n        return {\"id\":img_id,'landmarks': land.transpose(2, 0, 1)}  # pytorch\u306fchannnl, x, y\u306e\u5f62\u3002\u3053\u308c\u306f\u8f9e\u66f8\u578b\u3067\u8fd4\u3057\u3066\u3044\u308b\u3002(\u6271\u3044\u3084\u3059\u3044\u3068\u3044\u3046\u3060\u3051\u304b\u3082\u3002)\n        \n        \n        \n        \n        \n        \n        \n        ","510d26dd":"testdf2 = testdf.iloc[:10,:]","4119aefe":"test_dataset = GLDataset_inf(\n    testdf2[\"id\"],\n    testdf2[\"path\"],\n    preprocess=preprocess\n)","6a509a56":"## DataLoader\u306fimport torch.utils.data.Dataset\u3067import\u6e08\u307f\u306e\u3082\u306e\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False, #https:\/\/schemer1341.hatenablog.com\/entry\/2019\/01\/06\/024605 \u3092\u53c2\u8003. id\u304c\u308f\u304b\u3089\u306a\u304f\u306a\u308b\n    num_workers=0\n)","4e6d3367":"MODEL_PATH = \"resnet18.pth\"\n\nencoder = resnet18(pretrained=False) # \u5b66\u7fd2\u6e08\u307f\u30e2\u30c7\u30eb\u3092\u30a4\u30f3\u30bf\u30fc\u30cd\u30c3\u30c8\u304b\u3089\u3072\u3063\u3071\u308b\u308f\u3051\u3058\u3083\u306a\u3044\u306e\u3067\u3001false\nclassifier = LandmarkClassifier(encoder=encoder, in_channels=3, num_classes=len(dfcnt)) # classifier\u306fDeepfakeClassifier\u306e\u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316\n\n# classifier.to(device) # \u3053\u3053\u304cKeras\u3068\u306f\u9055\u3046\u3068\u3053\u308d\u3002GPU\u306b\u9001\u308a\u307e\u3059\u3088\u30fc\u3068\u3044\u3046\u610f\u5473\n\nstate = torch.load(MODEL_PATH, map_location=lambda storage, loc: storage)\nclassifier.load_state_dict(state['state_dict'])\n\nclassifier.eval() # \u63a8\u8ad6\u306a\u306e\u3067\u3001eval","ed67deee":"presub = []\n\nfor a in tqdm(test_dataloader):\n    y_pred = classifier(a['landmarks'])\n    cnt = F.softmax(y_pred).cpu().detach().numpy()\n    \n    y_pred = y_pred.cpu().detach().numpy()\n    \n    \n    for b in range(len(y_pred)):\n        tmp = np.argmax(y_pred[b])\n        conf = cnt[b][tmp]\n        \n        presub.append([a[\"id\"][b],tmp,conf])\n    \n    \n    \n        ","e1d75d8f":"presubdf = pd.DataFrame(presub,columns=[\"id\",\"landid\",\"conf\"])","d1ced312":"presubdf","225ae880":"test_dataset = GLDataset_inf(\n    testdf[\"id\"],\n    testdf[\"path\"],\n    preprocess=preprocess\n)\n\n## DataLoader\u306fimport torch.utils.data.Dataset\u3067import\u6e08\u307f\u306e\u3082\u306e\ntest_dataloader = DataLoader(\n    test_dataset,\n    batch_size=BATCH_SIZE,\n    shuffle=False, #https:\/\/schemer1341.hatenablog.com\/entry\/2019\/01\/06\/024605 \u3092\u53c2\u8003. id\u304c\u308f\u304b\u3089\u306a\u304f\u306a\u308b\n    num_workers=NUM_WORKERS\n)","dd409043":"presub = []\n\nfor a in tqdm(test_dataloader):\n    y_pred = classifier(a['landmarks'])\n    cnt = F.softmax(y_pred).cpu().detach().numpy()\n    \n    y_pred = y_pred.cpu().detach().numpy()\n    \n    \n    for b in range(len(y_pred)):\n        tmp = np.argmax(y_pred[b])\n        conf = cnt[b][tmp]\n        \n        presub.append([a[\"id\"][b],tmp,conf])\n    \n\n       ","debcf055":"presubdf = pd.DataFrame(presub,columns=[\"testid\",\"repair_id\",\"conf\"])\npresubdf","ec41085e":"tdf","d5ba395c":"mdf = pd.merge(presubdf,tdf,on=\"repair_id\",how=\"left\")\nmdf","f491c67d":"sub = []\n\nfor a in range(len(mdf)):\n    \n    tmp = str(mdf[\"landmark_id\"].iloc[a]) + \" \" + str(mdf[\"conf\"].iloc[a])\n    sub.append(tmp)\n\nmdf[\"submission\"]=sub\n    ","2947b2ef":"submissiondf = mdf[[\"testid\",\"submission\"]]\nsubmissiondf","0e4ad941":"submissiondf.columns=[\"id\",\"landmarks_pytorch\"]\nsubmissiondf","cf1b74c2":"# sample submission\u306e\u5f62\u5f0f\u306b\u3002","964ed3c3":"sample = pd.read_csv(\"..\/input\/landmark-recognition-2020\/sample_submission.csv\")","0515063e":"sample","c5ae43e3":"submission = pd.merge(sample,submissiondf,on=\"id\",how=\"left\")\nsubmission","017944c8":"submission[\"landmarks\"] = submission[\"landmarks_pytorch\"]\nsubmission","a9554b99":"submission = submission.iloc[:,:2]\nsubmission","b98d7aa5":"submission.to_csv(\"submission.csv\")","89887597":"# \u3053\u306e\u6642\u70b9\u3067\u3001landmark id\u306e\u7a2e\u985e\u306f\u5168\u90e8\u306781313\u500b\u3001\u6700\u5c0f\u679a\u6570\u306f2\u679a\u3067\u3042\u308b\u3053\u3068\u304c\u308f\u304b\u308b(\u524d\u56de\u306f138982\u304c6272\u500b\u306b\u6ce8\u76ee\u3057\u3066\u305f)\u306e\u3067\u3001\n# \u5404landmark id\u3054\u3068\u306b1\u679a\u8a13\u7df4\u30c7\u30fc\u30bf(traindata)\u3001\uff11\u679a\u691c\u8a3c\u30c7\u30fc\u30bf(validation)\u306b\u3057\u3066pytorch\u3067\u30e2\u30c7\u30eb\u3092\u4f5c\u6210\u3059\u308b\u3053\u3068\u3092\u8003\u3048\u308b\u3002","8a95a3a4":"# reference) class\u5316\u3057\u3066\u3059\u3063\u304d\u308a\u3059\u308b","9cc8f538":"## 1\u30641\u3064\u8ffd\u3063\u3066\u3001\u4f55\u3084\u3063\u3066\u3044\u308b\u304b\u3092\u898b\u3066\u3044\u304f\u3002","05153a3d":"# Dataset\u306einstance\u5316","39ca0cb4":"# Dataloader\u5316","8401fe8d":"# \u521d\u65e5\u306f\u3053\u3053\u307e\u3067\u304b\u306a\u30fb\u30fb\u30fb","0a1542b8":"# \u304f\u3063\u3064\u3051\u3066epoch\u3092\u56de\u3059","9f9e21f7":"## \u52b9\u7387\u7684\u306a\u3084\u308a\u65b9\n## Process 1 : Simple\u306b\u3057\u3066\u3067\u304d\u308b\u3068\u3053\u308d\u304b\u3089\u3084\u308b\u3002\u4f8b\u3048\u30701\u3064\u3060\u3051\u3084\u308b\n## Process 2 : \u3044\u3063\u305f\u3093\u307e\u3068\u3081\u3066\u307f\u308b\n## Process 3 : for\u6587\u306b\u3057\u3066\u56de\u3057\u3066\u307f\u308b\n## Process 4 : \u6c4e\u7528\u6027\u3092\u6301\u305f\u305b\u308b (\u6570\u5b57 \u2192 \u6587\u5b57\u5316)\n## Process 5 : \u3055\u3089\u306b\u6c4e\u7528\u6027\u3092\u6301\u305f\u305b\u308b (\u95a2\u6570\u5316)\n## Process 6 : class\u5316\u3059\u308b","9a8a57fd":"# \u30e2\u30c7\u30eb\u306e\u6700\u9069\u5316\u306f\u8907\u96d1\u306a\u306e\u3067\u30011epoch\u3054\u3068\u306b\u30011\u30641\u3064\u898b\u3066\u3044\u304f\n# \u307e\u305a\u306ftrain","45f2c5c3":"# 1. transform\u306e\u5b9a\u7fa9","921685c7":"# \u95a2\u6570\u5316","7fa2429e":"# \u3053\u3053\u304b\u3089pytorch","406a7a29":"# \u30a4\u30f3\u30b9\u30bf\u30f3\u30b9\u5316(\u3068\u308a\u3042\u3048\u305a10\u679a)","183521ed":"# \u95a2\u6570\u5316\u3057\u305f\u7248","028b28e9":"# repairid\u306e\u88dc\u6b63","da58ddd0":"# 3. DataLoader","b1debf64":"# \u304a\u3055\u3089\u30442\u3000import collection\u3092\u4f7f\u3063\u3066\u3001\u5404id\u306e\u500b\u6570\u3092\u6570\u3048\u305f\u3002\u305d\u308c\u3092count\u6570\u3054\u3068\u306b\u4e26\u3079\u305f\u306e\u304c\u3001dfcnt","80171351":"# memo : \u30e1\u30e2\u30ea\u304c\u8db3\u308a\u306a\u304f\u3066\u3001\u5168\u90e8\u5b66\u7fd2\u3067\u304d\u306a\u3044\u3002\n# memo2 : \u5b66\u7fd2\u6e08\u307fresnet 18\u306finternet on\u3060\u3068\u5b9f\u884c\u3067\u304d\u306a\u3044\u3002\u2192\u3000\u3084\u308a\u65b9\u306f\u3042\u308b\u304c\u3001\n# \u30e2\u30c7\u30eb\u69cb\u7bc9\u3068\u3001\u63a8\u8ad6\u306fnotebook\u3092\u5206\u3051\u3066\u3082\u3088\u3044\u3002","b786bd49":"# torch\u30e2\u30c7\u30eb\u306eload \u203b \u304a\u305d\u3089\u304f\u5fc5\u8981\u306a\u3044\u304c\u3001notebook\u308f\u3051\u305f\u3068\u304d\u3088\u3046\u306b\u3002","dcd6f4a8":"# \u3053\u3053\u304b\u3089Deep learning\u306e\u8a2d\u5b9a","e5e0f21e":"# \u95a2\u6570\u5316","ebeec975":"test\u306epass\u3092\u51fa\u3059","3e4df1a9":"## dfcnt\u306eid\u3067filtering\u3057\u3066\u3001\u4e00\u756a\u4e0a\u306b\u304d\u305f\u3084\u3064\u3092train data, \u4e0a\u304b\u30892\u3064\u76ee\u3092validation\u3068\u3059\u308b\n## \u308f\u304b\u308a\u3084\u3059\u304f\u3059\u308b\u305f\u3081\u3001\uff11\u500b\u3067\u8aac\u660e","7c0f936a":"#\u5168\u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u3067\u5b9f\u884c","fc2eeec8":"# \u5168\u90e8\u3084\u3063\u3066\u3082\u826f\u3044\u304c\u3001\u81ea\u5206\u3067\u4f5c\u6210\u3059\u308b\u3068\u304d\u306f10\u679a\u304f\u3089\u3044\u3067\u30c6\u30b9\u30c8\u3059\u308b\u307b\u3046\u304c\u52b9\u7387\u7684","54cb6293":"## This notebook is just for test.\n## This cannot make a complete model because of memory error.\n## Thank you.","51d85e2f":"# 1.\u524d\u56de\u30c7\u30fc\u30bf\u306e\u78ba\u8a8d","2c7be1a5":"# validationloss\u304c\u4e0b\u304c\u3063\u305f\u3089\u3001\u30e2\u30c7\u30eb\u3092save\u3059\u308b\u8a18\u8ff0\u3092\u8ffd\u52a0\u3002","61a16d77":"# \u3053\u306e\u3042\u3068\u3001epoch\u3054\u3068\u306b\u307e\u3068\u3081\u308b\u3053\u3068\u3092\u8003\u3048\u308b\u3068\u3001loss.item\u306e\u4e00\u756a\u6700\u5f8c\u3092\u4fdd\u5b58\u3002","10042534":"# \u304a\u3055\u3089\u3044","905482bb":"# \u3053\u3053\u304b\u3089\u306f\u63a8\u8ad6","7a3f8241":"# \u3053\u306e\u30b5\u30a4\u30c8\u304c\u3068\u3066\u3082\u5206\u304b\u308a\u3084\u3059\u304f\u66f8\u3044\u3066\u304f\u308c\u3066\u3044\u308b\u306e\u3067\u3001\u8ff7\u3063\u305f\u3089\u3053\u3053\u3092\u898b\u308b\nhttps:\/\/qiita.com\/takurooo\/items\/e4c91c5d78059f92e76d","5109ce6b":"# validation\u3092\u540c\u69d8\u306b\u4f5c\u308b\u3002","a6db3c43":"# 2. Dataset","292ff4c4":"# \u57fa\u672c\u306f\u3001model\u4f5c\u6210\u3068\u540c\u3058\u3060\u304c\u3001\u30e9\u30d9\u30eb\u304c\u306a\u3044\u306e\u3067\u3001\u305d\u308c\u3088\u3046\u306eclass\u3092\u4f5c\u308b","3b0e3937":"# loss\u3092\u7b97\u51fa (crossentropyloss)","4106b07c":"# Reference : \u3053\u3053\u307e\u3067\u3092class\u5316\u3057\u3066\u3059\u3063\u304d\u308a\u3059\u308b\u2192\u6c4e\u7528\u6027\u3092\u3082\u305f\u305b\u308b","c17b63b4":"# \u95a2\u6570\u5316"}}