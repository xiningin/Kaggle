{"cell_type":{"c289aa69":"code","a90dd013":"code","663637c5":"code","8fc13ce3":"code","7c16654b":"code","390da637":"code","dfa019e9":"code","2a4e2c42":"code","c9b65248":"code","c5526002":"code","2767953d":"code","3824e01e":"code","68c81e13":"code","d7a90231":"code","27d04a6f":"code","865c0af6":"code","fb0410cf":"code","0b98cf80":"code","851e4857":"markdown","7315e86f":"markdown","a37d3620":"markdown","ff8b3d59":"markdown","a5ee3e23":"markdown"},"source":{"c289aa69":"# basic library\nimport numpy as np\nimport pandas as pd\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# visulization library\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# keras and tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\n\n# preprocessing library\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","a90dd013":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nsubmission = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')","663637c5":"print(f'train shape : {train.shape}')\nprint(f'test shape : {test.shape}')","8fc13ce3":"X_train = train.drop(['label'], axis=1)\ny_train = train['label']","7c16654b":"# label histogram\nsns.countplot(x='label', data=train)","390da637":"X_train \/= 255.0\ntest \/= 255.0","dfa019e9":"X_train1 = X_train.values.reshape(-1, 28, 28, 1)\ntest = test.values.reshape(-1, 28, 28, 1)","2a4e2c42":"from keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train, num_classes=10)","c9b65248":"X_train, X_val , y_train, y_val = train_test_split(X_train1, y_train, test_size=0.2)","c5526002":"plt.imshow(X_train[1][:,:,0], cmap='binary')","2767953d":"model = keras.models.Sequential()\n\nmodel.add(keras.layers.Conv2D(filters = 64, kernel_size=(5,5), padding='same', activation='relu', input_shape=(28, 28, 1)))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Conv2D(filters = 64, kernel_size=(5,5), padding='same', activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(keras.layers.Dropout(0.5))\n\nmodel.add(keras.layers.Conv2D(filters = 64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.Conv2D(filters = 64, kernel_size=(3,3), padding='same', activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\n\nmodel.add(keras.layers.MaxPool2D(pool_size=(2,2)))\nmodel.add(keras.layers.Dropout(0.5))\n\nmodel.add(keras.layers.Flatten())\nmodel.add(keras.layers.Dense(256, activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Dropout(0.5))\n\nmodel.add(keras.layers.Dense(256, activation='relu'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.Dropout(0.5))\n\nmodel.add(keras.layers.Dense(10, activation='softmax'))","3824e01e":"model.summary()","68c81e13":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=[\"accuracy\"])","d7a90231":"history = model.fit(X_train, y_train, epochs=25, validation_data=(X_val, y_val))","27d04a6f":"fig, ax = plt.subplots(2,1)\nax[0].plot(history.history['loss'], color='b', label=\"Training loss\")\nax[0].plot(history.history['val_loss'], color='r', label=\"validation loss\",axes =ax[0])\nlegend = ax[0].legend(loc='best', shadow=True)\n\nax[1].plot(history.history['accuracy'], color='b', label=\"Training accuracy\")\nax[1].plot(history.history['val_accuracy'], color='r',label=\"Validation accuracy\")\nlegend = ax[1].legend(loc='best', shadow=True)","865c0af6":"y_pred = model.predict(test)","fb0410cf":"results = np.argmax(y_pred,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")","0b98cf80":"submission['Label'] = results\nsubmission.to_csv('submission.csv', index=False)","851e4857":"### **UPVOTE** kernel if you found it useful.","7315e86f":"### Reshape","a37d3620":"### import Data","ff8b3d59":"### Normalization","a5ee3e23":"### Model Building\n#### Convolutional Neural Network"}}