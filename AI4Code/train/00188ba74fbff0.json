{"cell_type":{"9ebfe7ac":"code","bc09b855":"code","b3b7c9b3":"code","b2c1746f":"code","e62d928a":"code","46a52a5f":"code","d54f9ab1":"code","ac9f4481":"code","8b349bee":"code","348618bc":"code","d4023822":"code","fbd3f3e1":"code","9d860f40":"code","dc71c8f5":"code","f0532d7b":"code","8b713611":"code","906a8599":"code","01bc8c66":"code","493cb4c0":"code","312e4ac4":"code","7210895f":"code","6ed761e9":"code","1d687c36":"code","daba76b3":"code","9f4437ad":"code","33ec9d1a":"code","239af45a":"code","f075fab3":"code","bf6bb81a":"code","4c6166ca":"code","2a15a294":"code","9dda6d05":"code","0334a254":"code","bf7bf6cc":"code","90d06bab":"code","8dca67ec":"code","b8454223":"code","4bcb9b67":"code","a9c97fc9":"code","7232873e":"code","aa8047ab":"code","05702a21":"code","b92d4278":"code","f5ea0c64":"code","2d9e8ad4":"markdown","c9f33fc6":"markdown"},"source":{"9ebfe7ac":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.dummy import DummyRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom pathlib import Path\nfrom shutil import copyfile\nimport glob\nimport os, sys\nimport pathlib\nimport PIL","bc09b855":"import matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport PIL\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\n","b3b7c9b3":"random_state = 42\ntest_size = 0.2","b2c1746f":"train = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/train.csv\", index_col=\"Id\")\ntest = pd.read_csv(\"..\/input\/petfinder-pawpularity-score\/test.csv\", index_col=\"Id\")\ntarget_column = set(train.columns) - set(test.columns)\n\ny = pd.DataFrame(train[target_column])\nX = train.drop(columns=target_column)","e62d928a":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state)","46a52a5f":"dummy_regr = DummyRegressor(strategy=\"mean\", constant=None, quantile=None)\ndummy_regr.fit(X_train, y_train)\n\nmean_squared_error(y_true=y_test, y_pred=dummy_regr.predict(X_test), squared=False)","d54f9ab1":"targets = {}\nfor i in range(1, 100, 10):\n    target = f\"seg_{i}_{i+9}\"\n    target_path = \"pets\/\" + target\n    try:\n        Path(target_path).mkdir(parents=True, exist_ok=True)\n    except FileExistsError:\n        break\n    selected_bin = y_train[(y_train[\"Pawpularity\"] >= i) & (y_train[\"Pawpularity\"] <= i+9)]\n    targets.update({target: selected_bin.mean()})\n    files_index = selected_bin.index\n    for data_file in files_index:\n        copyfile(f\"..\/input\/petfinder-pawpularity-score\/train\/{data_file}.jpg\", f\"{target_path}\/{data_file}.jpg\")\n\n        \ndata_dir = pathlib.Path(\"pets\")\n        \nassert len(list(data_dir.glob('*\/*.jpg'))) == len(y_train)\ntargets","ac9f4481":"seg_1_10 = list(data_dir.glob('seg_1_10\/*'))\nPIL.Image.open(str(seg_1_10[0]))\n","8b349bee":"batch_size = 32\nimg_height = 180\nimg_width = 180","348618bc":"train_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"training\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","d4023822":"val_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  validation_split=0.2,\n  subset=\"validation\",\n  seed=123,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","fbd3f3e1":"class_names = train_ds.class_names\nprint(class_names)","9d860f40":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in train_ds.take(1):\n  for i in range(9):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(images[i].numpy().astype(\"uint8\"))\n    plt.title(class_names[labels[i]])\n    plt.axis(\"off\")","dc71c8f5":"for image_batch, labels_batch in train_ds:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break\n","f0532d7b":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain_ds = train_ds.cache().shuffle(1000).prefetch(buffer_size=AUTOTUNE)\nval_ds = val_ds.cache().prefetch(buffer_size=AUTOTUNE)\n","8b713611":"normalization_layer = layers.Rescaling(1.\/255)\n","906a8599":"normalized_ds = train_ds.map(lambda x, y: (normalization_layer(x), y))\nimage_batch, labels_batch = next(iter(normalized_ds))\nfirst_image = image_batch[0]\n# Notice the pixel values are now in `[0,1]`.\nprint(np.min(first_image), np.max(first_image))\n","01bc8c66":"num_classes = 10\n\nmodel = Sequential([\n  layers.Rescaling(1.\/255, input_shape=(img_height, img_width, 3)),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n","493cb4c0":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n","312e4ac4":"model.summary()","7210895f":"epochs=10\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)\n","6ed761e9":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n","1d687c36":"data_augmentation = keras.Sequential(\n  [\n    layers.RandomFlip(\"horizontal\",\n                      input_shape=(img_height,\n                                  img_width,\n                                  3)),\n    layers.RandomRotation(0.1),\n    layers.RandomZoom(0.1),\n  ]\n)\n","daba76b3":"plt.figure(figsize=(10, 10))\nfor images, _ in train_ds.take(1):\n  for i in range(9):\n    augmented_images = data_augmentation(images)\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n    plt.axis(\"off\")\n","9f4437ad":"model = Sequential([\n  data_augmentation,\n  layers.Rescaling(1.\/255),\n  layers.Conv2D(16, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(32, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Conv2D(64, 3, padding='same', activation='relu'),\n  layers.MaxPooling2D(),\n  layers.Dropout(0.2),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])\n","33ec9d1a":"model.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])\n","239af45a":"model.summary()\n","f075fab3":"epochs = 15\nhistory = model.fit(\n  train_ds,\n  validation_data=val_ds,\n  epochs=epochs\n)\n","bf6bb81a":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()","4c6166ca":"target_path = \"pets_test\/\"\ntry:\n    Path(target_path).mkdir(parents=True, exist_ok=True)\nexcept FileExistsError:\n    pass\nfiles_index = y_test.index\nfor data_file in files_index:\n    copyfile(f\"..\/input\/petfinder-pawpularity-score\/train\/{data_file}.jpg\", f\"{target_path}\/{data_file}.jpg\")","2a15a294":"assert len(list(pathlib.Path(target_path).glob('*.jpg'))) == len(y_test)\n","9dda6d05":"from tqdm.notebook import trange, tqdm","0334a254":"files = []\nresults = []\nfor image_path in tqdm(list(pathlib.Path(target_path).glob('*.jpg'))):\n#     print(image_path)\n    img = tf.keras.utils.load_img(\n        image_path, target_size=(img_height, img_width)\n    )\n    img_array = tf.keras.utils.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0) # Create a batch\n\n    predictions = model.predict(img_array)\n    score = tf.nn.softmax(predictions[0])\n\n    files.append(image_path.stem)\n    results.append(class_names[np.argmax(score)])\n#     break\n#     print(\n#         \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n#         .format(class_names[np.argmax(score)], 100 * np.max(score))\n#     )\n","bf7bf6cc":"results_df = pd.DataFrame({\"Id\": files, \"result\": results})\nresults_df.set_index([\"Id\"], inplace=True)\nresults_df.sort_index(inplace=True)\ny_test.sort_index(inplace=True)\n\nassert (results_df.index == y_test.index).all","90d06bab":"results_df.replace({\"result\": targets}, inplace=True)","8dca67ec":"mean_squared_error(y_true=y_test, y_pred=results_df[\"result\"], squared=False)","b8454223":"for i in range(1, 100, 10):\n    target = f\"seg_{i}_{i+9}\"\n    target_path = \"pets_full\/\" + target\n    try:\n        Path(target_path).mkdir(parents=True, exist_ok=True)\n    except FileExistsError:\n        break\n    selected_bin = y[(y[\"Pawpularity\"] >= i) & (y[\"Pawpularity\"] <= i+9)]\n    files_index = selected_bin.index\n    for data_file in files_index:\n        copyfile(f\"..\/input\/petfinder-pawpularity-score\/train\/{data_file}.jpg\", f\"{target_path}\/{data_file}.jpg\")\n\n        \ndata_dir = pathlib.Path(\"pets_full\")\n        \nassert len(list(data_dir.glob('*\/*.jpg'))) == len(y)\ntargets","4bcb9b67":"full_train_ds = tf.keras.utils.image_dataset_from_directory(\n  data_dir,\n  image_size=(img_height, img_width),\n  batch_size=batch_size)","a9c97fc9":"epochs = 15\nhistory = model.fit(\n  full_train_ds,\n  epochs=epochs\n)","7232873e":"files = []\nresults = []\nfor image_path in tqdm(list(pathlib.Path(\"..\/input\/petfinder-pawpularity-score\/test\/\").glob('*.jpg'))):\n#     print(image_path)\n    img = tf.keras.utils.load_img(\n        image_path, target_size=(img_height, img_width)\n    )\n    img_array = tf.keras.utils.img_to_array(img)\n    img_array = tf.expand_dims(img_array, 0) # Create a batch\n\n    predictions = model.predict(img_array)\n    score = tf.nn.softmax(predictions[0])\n\n    files.append(image_path.stem)\n    results.append(class_names[np.argmax(score)])","aa8047ab":"results_df = pd.DataFrame({\"Id\": files, \"Pawpularity\": results})\n\nassert len(results_df) == len(list(pathlib.Path(\"..\/input\/petfinder-pawpularity-score\/test\/\").glob('*.jpg')))","05702a21":"results_df.replace({\"Pawpularity\": targets}, inplace=True)\nresults_df.to_csv(\"submission.csv\", index=False)","b92d4278":"results_df","f5ea0c64":"!rm -rf pets*","2d9e8ad4":"# Prepare submission","c9f33fc6":"# Retrain on all"}}