{"cell_type":{"4e28b975":"code","2bbbbbee":"code","704fe71c":"code","dee51629":"code","d13b2c47":"code","c28ddda6":"code","144e523c":"code","08384be0":"code","4428e117":"code","8e75f3cc":"code","51df2671":"code","745b5f83":"code","7c2f3a0f":"code","0fee28c7":"code","70e03a49":"code","ac6323d2":"code","6f202204":"code","7542fe0b":"code","9f717bc0":"code","7e26a05c":"code","bca59f38":"code","f625ef3e":"code","bb70875f":"code","0ac9bc46":"code","795c011e":"code","87676bad":"code","75fdbe78":"code","78b73265":"code","76a5d24a":"code","4f617fae":"code","ec59259d":"code","d576564e":"code","1c0b4fea":"code","e9531a73":"code","06b5a440":"code","110dbb6a":"code","cb02dd8f":"code","24177c2c":"code","fee7b0dd":"code","66c51d72":"code","4f0d7f4a":"code","dd1689a5":"code","5ce21d52":"code","8be33439":"markdown","4b0496aa":"markdown","7cefbeb0":"markdown","1867ba4a":"markdown","317fa68e":"markdown","e6b3db08":"markdown","e947d50b":"markdown","deae1dfa":"markdown","b7ea42ab":"markdown","21945712":"markdown","8b15ccbe":"markdown","c65bcf4d":"markdown","88e72c57":"markdown","99e9ec32":"markdown","c27149a8":"markdown","c8610335":"markdown","08dc0501":"markdown","1f478aec":"markdown","51241517":"markdown","c98c0605":"markdown","1792fa35":"markdown","c2299a63":"markdown","21d5dc2c":"markdown","e069a1bd":"markdown","facf2a67":"markdown","472a4a4e":"markdown","9d8acf22":"markdown","dc6df4a9":"markdown","b5ee18e7":"markdown","8c853bb9":"markdown","0019e077":"markdown","ab9aeccc":"markdown","95b0a703":"markdown","63e55e44":"markdown","ef6927bc":"markdown","1694888b":"markdown","f0f91d03":"markdown","bbf7fb0c":"markdown","cfbde17f":"markdown","4a198bef":"markdown","fd60d12d":"markdown","394381f5":"markdown","8ecf9992":"markdown","25b8f04f":"markdown","9d52affc":"markdown","8cf1e167":"markdown","42fad1cd":"markdown","670fc4ce":"markdown","2aeef625":"markdown","853287a7":"markdown","9734426d":"markdown","ecde58d6":"markdown","4200dde7":"markdown","647774ae":"markdown","1e4cf19f":"markdown","d7992578":"markdown","d7deda3b":"markdown","e84496d8":"markdown"},"source":{"4e28b975":"import os\n\nimport warnings\nwarnings.simplefilter(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport missingno as msno\n\nimport plotly.express as px\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\n!pip install pywaffle\nfrom pywaffle import Waffle\n\nfrom bokeh.layouts import column, row\nfrom bokeh.models.tools import HoverTool\nfrom bokeh.models import ColumnDataSource, Whisker\nfrom bokeh.plotting import figure, output_notebook, show\n\noutput_notebook()\n\nfrom IPython.display import IFrame\n\npd.set_option('display.max_columns', None)","2bbbbbee":"YouTube_df=pd.read_csv(\"..\/input\/chai-time-data-science\/YouTube Thumbnail Types.csv\")\nprint(\"No of Datapoints : {}\\nNo of Features : {}\".format(YouTube_df.shape[0], YouTube_df.shape[1]))\nYouTube_df.head()","704fe71c":"Anchor_df=pd.read_csv(\"..\/input\/chai-time-data-science\/Anchor Thumbnail Types.csv\")\nprint(\"No of Datapoints : {}\\nNo of Features : {}\".format(Anchor_df.shape[0], Anchor_df.shape[1]))\nAnchor_df.head()","dee51629":"IFrame('https:\/\/anchor.fm\/chaitimedatascience', width=800, height=450)","d13b2c47":"Des_df=pd.read_csv(\"..\/input\/chai-time-data-science\/Description.csv\")\nprint(\"No of Datapoints : {}\\nNo of Features : {}\".format(Des_df.shape[0], Des_df.shape[1]))\nDes_df.head()","c28ddda6":"def show_description(specific_id=None, top_des=None):\n    \n    if specific_id is not None:\n        print(Des_df[Des_df.episode_id==specific_id].description.tolist()[0])\n        \n    if top_des is not None:\n        for each_des in range(top_des):  \n            print(Des_df.description.tolist()[each_des])\n            print(\"-\"*100)\n","144e523c":"show_description(\"E1\")","08384be0":"show_description(top_des=3)","4428e117":"Episode_df=pd.read_csv(\"..\/input\/chai-time-data-science\/Episodes.csv\")\nprint(\"No of Datapoints : {}\\nNo of Features : {}\".format(Episode_df.shape[0], Episode_df.shape[1]))\nEpisode_df.head()","8e75f3cc":"msno.matrix(Episode_df)","51df2671":"\n\ntemp=Episode_df.isnull().sum().reset_index().rename(columns={\"index\": \"Name\", 0: \"Count\"})\ntemp=temp[temp.Count!=0]\n\nSource=ColumnDataSource(temp)\n\ntooltips = [\n    \n    (\"Feature Name\", \"@Name\"),\n    (\"No of Missing entites\", \"@Count\")\n]\n\nfig1 = figure(background_fill_color=\"#ebf4f6\", plot_width = 600, plot_height = 400,tooltips=tooltips, x_range = temp[\"Name\"].values, title = \"Count of Missing Values\")\nfig1.vbar(\"Name\", top = \"Count\", source = Source, width = 0.4, color = \"#76b4bd\", alpha=.8)\n\nfig1.xaxis.major_label_orientation = np.pi \/ 8\nfig1.xaxis.axis_label = \"Features\"\nfig1.yaxis.axis_label = \"Count\"\n\nfig1.grid.grid_line_color=\"#feffff\"\n\n\nshow(fig1)","745b5f83":"Episode_df[Episode_df.heroes.isnull()]","7c2f3a0f":"temp=[id for id in Episode_df.episode_id if id.startswith('M')]\nfastai_df=Episode_df[Episode_df.episode_id.isin(temp)]\nEpisode_df=Episode_df[~Episode_df.episode_id.isin(temp)]","0fee28c7":"dummy_df=Episode_df[(Episode_df.episode_id!=\"E0\") & (Episode_df.episode_id!=\"E69\")]","70e03a49":"msno.matrix(dummy_df)","ac6323d2":"temp=dummy_df.isnull().sum().reset_index().rename(columns={\"index\": \"Name\", 0: \"Count\"})\ntemp=temp[temp.Count!=0]\n\nSource=ColumnDataSource(temp)\n\ntooltips = [\n    (\"Feature Name\", \"@Name\"),\n    (\"No of Missing entites\", \"@Count\")\n]\n\nfig1 = figure(background_fill_color=\"#ebf4f6\", plot_width = 600, plot_height = 400,tooltips=tooltips, x_range = temp[\"Name\"].values, title = \"Count of Missing Values\")\nfig1.vbar(\"Name\", top = \"Count\", source = Source, width = 0.4, color = \"#76b4bd\", alpha=.8)\n\nfig1.xaxis.major_label_orientation = np.pi \/ 4\nfig1.xaxis.axis_label = \"Features\"\nfig1.yaxis.axis_label = \"Count\"\n\nfig1.grid.grid_line_color=\"#feffff\"\n\nshow(fig1)","6f202204":"parent=[]\nnames =[]\nvalues=[]\ntemp=dummy_df.groupby([\"category\"]).heroes_gender.value_counts()\nfor k in temp.index:\n    parent.append(k[0])\n    names.append(k[1])\n    values.append(temp.loc[k])\n\ndf1 = pd.DataFrame(\n    dict(names=names, parents=parent,values=values))\n\n\nparent=[]\nnames =[]\nvalues=[]\ntemp=dummy_df.groupby([\"category\",\"heroes_gender\"]).heroes_kaggle_username.count()\nfor k in temp.index:\n    parent.append(k[0])\n    names.append(k[1])\n    values.append(temp.loc[k])\n\ndf2 = pd.DataFrame(\n    dict(names=names, parents=parent,values=values))\n\n\nfig = px.sunburst(df1, path=['names', 'parents'], values='values', color='parents',hover_data=[\"names\"], title=\"Heroes associated with Categories\")\nfig.update_traces( \n                 textinfo='percent entry+label',\n                 hovertemplate = \"Industry:%{label}: <br>Count: %{value}\"\n                )\nfig.show()\n\n\nfig = px.sunburst(df2, path=['names', 'parents'], values='values', color='parents', title=\"Heroes associated with Categories having Kaggle Account\")\nfig.update_traces( \n                 textinfo='percent entry+label',\n                 hovertemplate = \"Industry:%{label}: <br>Count: %{value}\"\n                )\nfig.show()","7542fe0b":"gender = Episode_df.heroes_gender.value_counts()\n\nfig = plt.figure(\n    FigureClass=Waffle, \n    rows=5,\n    columns=12,\n    values=gender,\n    colors = ('#20639B', '#ED553B'),\n    title={'label': 'Gender Distribution', 'loc': 'left'},\n    labels=[\"{}({})\".format(a, b) for a, b in zip(gender.index, gender) ],\n    legend={'loc': 'lower left', 'bbox_to_anchor': (0, -0.4), 'ncol': len(Episode_df), 'framealpha': 0},\n    font_size=30, \n    icons = 'child',\n    figsize=(12, 5),  \n    icon_legend=True\n)","9f717bc0":"dummy_df[dummy_df.apple_listeners.isnull()]","7e26a05c":"fig = go.Figure([go.Pie(labels=Episode_df.flavour_of_tea.value_counts().index.to_list(),values=Episode_df.flavour_of_tea.value_counts().values,hovertemplate = '<br>Type: %{label}<\/br>Count: %{value}<br>Popularity: %{percent}<\/br>', name = '')])\nfig.update_layout(title_text=\"What Host drinks everytime ?\", template=\"plotly_white\", title_x=0.45, title_y = 1)\nfig.data[0].marker.line.color = 'rgb(255, 255, 255)'\nfig.data[0].marker.line.width = 2\nfig.update_traces(hole=.4,)\nfig.show()","bca59f38":"temp=dummy_df.isnull().sum().reset_index().rename(columns={\"index\": \"Name\", 0: \"Count\"})\ntemp=temp[temp.Count!=0]\n\nSource=ColumnDataSource(temp)\n\ntooltips = [\n    (\"Feature Name\", \"@Name\"),\n    (\"No of Missing entites\", \"@Count\")\n]\n\nfig1 = figure(background_fill_color=\"#ebf4f6\", plot_width = 600, plot_height = 400,tooltips=tooltips, x_range = temp[\"Name\"].values, title = \"Count of Missing Values\")\nfig1.vbar(\"Name\", top = \"Count\", source = Source, width = 0.4, color = \"#76b4bd\", alpha=.8)\n\nfig1.xaxis.major_label_orientation = np.pi \/ 4\nfig1.xaxis.axis_label = \"Features\"\nfig1.yaxis.axis_label = \"Count\"\n\nfig1.grid.grid_line_color=\"#feffff\"\n\nshow(fig1)","f625ef3e":"Episode_df.release_date = pd.to_datetime(Episode_df.release_date)\nSource = ColumnDataSource(Episode_df)\nfastai_df.release_date = pd.to_datetime(fastai_df.release_date)\nSource2 = ColumnDataSource(fastai_df)\n\ntooltips = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Episode Title\", \"@episode_name\"),\n    (\"Hero Present\", \"@heroes\"),\n    (\"CTR\", \"@youtube_ctr\"),\n    (\"Category\", \"@category\"),\n    (\"Date\", \"@release_date{%F}\"),\n    ]\n\ntooltips2 = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Episode Title\", \"@episode_name\"),\n    (\"Hero Present\", \"@heroes\"),\n    (\"Subscriber Gain\", \"@youtube_subscribers\"),\n    (\"Category\", \"@category\"),\n    (\"Date\", \"@release_date{%F}\"),\n    ]\n\n\nfig1 = figure(background_fill_color=\"#ebf4f6\",plot_width = 600, plot_height = 400, x_axis_type = \"datetime\", title = \"CTR Per Episode\")\nfig1.line(\"release_date\", \"youtube_ctr\", source = Source, color = \"#03c2fc\", alpha = 0.8, legend_label=\"youtube_ctr\")\nfig1.varea(source=Source, x=\"release_date\", y1=0, y2=\"youtube_ctr\", alpha=0.2, fill_color='#55FF88', legend_label=\"youtube_ctr\")\nfig1.line(\"release_date\", Episode_df.youtube_ctr.mean(), source = Source, color = \"#f2a652\", alpha = 0.8,line_dash=\"dashed\", legend_label=\"Youtube CTR Mean : {:.3f}\".format(Episode_df.youtube_ctr.mean()))\nfig1.circle(x=\"release_date\", y=\"youtube_ctr\", source = Source2, color = \"#5bab37\", alpha = 0.8, legend_label=\"M0-M8 Series\")\n\nfig1.add_tools(HoverTool(tooltips=tooltips,formatters={\"@release_date\": \"datetime\"}))\nfig1.xaxis.axis_label = \"Release Date\"\nfig1.yaxis.axis_label = \"Click Per Impression\"\n\nfig1.grid.grid_line_color=\"#feffff\"\n\nfig2 = figure(background_fill_color=\"#ebf4f6\", plot_width = 600, plot_height = 400, x_axis_type = \"datetime\", title = \"Subscriber Gain Per Episode\")\nfig2.line(\"release_date\", \"youtube_subscribers\", source = Source, color = \"#03c2fc\", alpha = 0.8, legend_label=\"Subscribers\")\nfig2.varea(source=Source, x=\"release_date\", y1=0, y2=\"youtube_subscribers\", alpha=0.2, fill_color='#55FF88', legend_label=\"Subscribers\")\nfig2.circle(x=\"release_date\", y=\"youtube_subscribers\", source = Source2, color = \"#5bab37\", alpha = 0.8, legend_label=\"M0-M8 Series\")\n\n\nfig2.add_tools(HoverTool(tooltips=tooltips2,formatters={\"@release_date\": \"datetime\"}))\nfig2.xaxis.axis_label = \"Release Date\"\nfig2.yaxis.axis_label = \"Subscriber Count\"\n\nfig2.grid.grid_line_color=\"#feffff\"\n\nshow(column(fig1, fig2))","bb70875f":"Source = ColumnDataSource(Episode_df)\nSource2 = ColumnDataSource(fastai_df)\n\ntooltips = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Hero Present\", \"@heroes\"),\n    (\"Impression Views\", \"@youtube_impression_views\"),\n    (\"Non Impression Views\", \"@youtube_nonimpression_views\"),\n    (\"Category\", \"@category\"),\n    (\"Date\", \"@release_date{%F}\"),\n    ]\n\ntooltips2 = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Hero Present\", \"@heroes\"),\n    (\"Subscriber Gain\", \"@youtube_subscribers\"),\n    (\"Category\", \"@category\"),\n    (\"Date\", \"@release_date{%F}\"),\n    ]\n\n\nfig1 = figure(background_fill_color=\"#ebf4f6\", plot_width = 600, plot_height = 400, x_axis_type = \"datetime\", title = \"Impression-Non Impression Views Per Episode\")\nfig1.line(\"release_date\", \"youtube_impression_views\", source = Source, color = \"#03c2fc\", alpha = 0.8, legend_label=\"Impression Views\")\nfig1.line(\"release_date\", \"youtube_nonimpression_views\", source = Source, color = \"#f2a652\", alpha = 0.8, legend_label=\"Non Impression Views\")\nfig1.varea(source=Source, x=\"release_date\", y1=0, y2=\"youtube_impression_views\", alpha=0.2, fill_color='#55FF88', legend_label=\"Impression Views\")\nfig1.varea(source=Source, x=\"release_date\", y1=0, y2=\"youtube_nonimpression_views\", alpha=0.2, fill_color='#e09d53', legend_label=\"Non Impression Views\")\nfig1.circle(x=\"release_date\", y=\"youtube_impression_views\", source = Source2, color = \"#5bab37\", alpha = 0.8, legend_label=\"M0-M8 Series Impression Views\")\nfig1.circle(x=\"release_date\", y=\"youtube_nonimpression_views\", source = Source2, color = \"#2d3328\", alpha = 0.8, legend_label=\"M0-M8 Series Non Impression Views\")\n\n\n\nfig1.add_tools(HoverTool(tooltips=tooltips,formatters={\"@release_date\": \"datetime\"}))\nfig1.xaxis.axis_label = \"Release Date\"\nfig1.yaxis.axis_label = \"Total Views\"\n\nfig2 = figure(background_fill_color=\"#ebf4f6\", plot_width = 600, plot_height = 400, x_axis_type = \"datetime\", title = \"Subscriber Gain Per Episode\")\nfig2.line(\"release_date\", \"youtube_subscribers\", source = Source, color = \"#03c2fc\", alpha = 0.8, legend_label=\"Subscribers\")\nfig2.varea(source=Source, x=\"release_date\", y1=0, y2=\"youtube_subscribers\", alpha=0.2, fill_color='#55FF88', legend_label=\"Subscribers\")\nfig2.circle(x=\"release_date\", y=\"youtube_subscribers\", source = Source2, color = \"#5bab37\", alpha = 0.8, legend_label=\"M0-M8 Series\")\n\n\nfig2.add_tools(HoverTool(tooltips=tooltips2,formatters={\"@release_date\": \"datetime\"}))\nfig2.xaxis.axis_label = \"Release Date\"\nfig2.yaxis.axis_label = \"Subscriber Count\"\n\n\nshow(column(fig1, fig2))","0ac9bc46":"data1={\n      \"Youtube Impressions\":Episode_df.youtube_impressions.sum(), \n      \"Youtube Impression Views\": Episode_df.youtube_impression_views.sum(), \n      \"Youtube NonImpression Views\" : Episode_df.youtube_nonimpression_views.sum()\n     }\n\ntext=(\"Youtube Impressions\",\"Youtube Impression Views\",\"Youtube NonImpression Views\")\n\nfig = go.Figure(go.Funnelarea(\n    textinfo= \"text+value\",\n    text =list(data1.keys()),\n    values = list(data1.values()),\n    title = {\"position\": \"top center\", \"text\": \"Youtube and Views\"},\n      name = '', showlegend=False,customdata=['Video Thumbnail shown to Someone', 'Views From Youtube Impressions', 'Views without Youtube Impressions'], hovertemplate = '%{customdata} <br>Count: %{value}<\/br>'\n  ))\nfig.show()","795c011e":"colors = [\"red\", \"olive\", \"darkred\", \"goldenrod\"]\n\nindex={\n    0:\"YouTube default image\",\n    1:\"YouTube default image with custom annotation\",\n    2:\"Mini Series: Custom Image with annotations\",\n    3:\"Custom image with CTDS branding, Title and Tags\"\n}\n\np = figure(background_fill_color=\"#ebf4f6\", plot_width=600, plot_height=300, title=\"Thumbnail Type VS CTR\")\n\nbase, lower, upper = [], [], []\n\nfor each_thumbnail_ref in index:\n    if each_thumbnail_ref==2:\n        temp = fastai_df[fastai_df.youtube_thumbnail_type==each_thumbnail_ref].youtube_ctr \n    else:\n        temp = Episode_df[Episode_df.youtube_thumbnail_type==each_thumbnail_ref].youtube_ctr\n    mpgs_mean = temp.mean()\n    mpgs_std = temp.std()\n    lower.append(mpgs_mean - mpgs_std)\n    upper.append(mpgs_mean + mpgs_std)\n    base.append(each_thumbnail_ref)\n\n    source_error = ColumnDataSource(data=dict(base=base, lower=lower, upper=upper))\n    p.add_layout(\n        Whisker(source=source_error, base=\"base\", lower=\"lower\", upper=\"upper\")\n    )\n\n    tooltips = [\n        (\"Episode Id\", \"@episode_id\"),\n        (\"Hero Present\", \"@heroes\"),\n        ]\n\n    color = colors[each_thumbnail_ref % len(colors)]\n    p.circle(y=temp, x=each_thumbnail_ref, color=color, legend_label=index[each_thumbnail_ref])\n    print(\"Mean CTR for Thumbnail Type {} : {:.3f} \".format(index[each_thumbnail_ref], temp.mean()))\nshow(p)","87676bad":"a=Episode_df[[\"episode_id\", \"episode_duration\", \"youtube_avg_watch_duration\"]]\na[\"percentage\"]=(a.youtube_avg_watch_duration\/a.episode_duration)*100\n\nb=fastai_df[[\"episode_id\", \"episode_duration\", \"youtube_avg_watch_duration\"]]\nb[\"percentage\"]=(b.youtube_avg_watch_duration\/b.episode_duration)*100\n\ntemp=a.append(b).reset_index().drop([\"index\"], axis=1)\n\nSource = ColumnDataSource(temp)\n\ntooltips = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Episode Duration\", \"@episode_duration\"),\n    (\"Youtube Avg Watch_duration Views\", \"@youtube_avg_watch_duration\"),\n    (\"Percentage of video watched\", \"@percentage\"),\n    ]\n\n\nfig1 = figure(background_fill_color=\"#ebf4f6\", plot_width = 1000, plot_height = 400, x_range  = temp[\"episode_id\"].values, title = \"Percentage of Episode Watched\")\nfig1.line(\"episode_id\", \"percentage\", source = Source, color = \"#03c2fc\", alpha = 0.8)\nfig1.line(\"episode_id\", temp.percentage.mean(), source = Source, color = \"#f2a652\", alpha = 0.8,line_dash=\"dashed\", legend_label=\"Mean : {:.3f}\".format(temp.percentage.mean()))\n\nfig1.add_tools(HoverTool(tooltips=tooltips))\nfig1.xaxis.axis_label = \"Episode Id\"\nfig1.yaxis.axis_label = \"Percentage\"\n\nfig1.xaxis.major_label_orientation = np.pi \/ 3\nshow(column(fig1))","75fdbe78":"colors = [\"red\", \"olive\", \"darkred\", \"goldenrod\"]\n\nindex={\n    0:\"YouTube default playlist image\",\n    1:\"CTDS Branding\",\n    2:\"Mini Series: Custom Image with annotations\",\n    3:\"Custom image with CTDS branding, Title and Tags\"\n}\n\np = figure(background_fill_color=\"#ebf4f6\", plot_width=600, plot_height=300, title=\"Thumbnail Type VS Anchor Plays\")\n\nbase, lower, upper = [], [], []\n\nfor each_thumbnail_ref in index:\n    if each_thumbnail_ref==2:\n        temp = fastai_df[fastai_df.youtube_thumbnail_type==each_thumbnail_ref].anchor_plays \n    else:\n        temp = Episode_df[Episode_df.youtube_thumbnail_type==each_thumbnail_ref].anchor_plays\n    mpgs_mean = temp.mean()\n    mpgs_std = temp.std()\n    lower.append(mpgs_mean - mpgs_std)\n    upper.append(mpgs_mean + mpgs_std)\n    base.append(each_thumbnail_ref)\n\n    source_error = ColumnDataSource(data=dict(base=base, lower=lower, upper=upper))\n    p.add_layout(\n        Whisker(source=source_error, base=\"base\", lower=\"lower\", upper=\"upper\")\n    )\n\n    tooltips = [\n        (\"Episode Id\", \"@episode_id\"),\n        (\"Hero Present\", \"@heroes\"),\n        ]\n\n    color = colors[each_thumbnail_ref % len(colors)]\n    p.circle(y=temp, x=each_thumbnail_ref, color=color, legend_label=index[each_thumbnail_ref])\n    print(\"Mean Anchor Plays for Thumbnail Type {} : {:.3f} \".format(index[each_thumbnail_ref], temp.mean()))\nshow(p)","78b73265":"Episode_df.release_date = pd.to_datetime(Episode_df.release_date)\nSource = ColumnDataSource(Episode_df)\n\ntooltips = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Episode Title\", \"@episode_name\"),\n    (\"Hero Present\", \"@heroes\"),\n    (\"Anchor Plays\", \"@anchor_plays\"),\n    (\"Category\", \"@category\"),\n    (\"Date\", \"@release_date{%F}\"),\n    ]\n\ntooltips2 = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Episode Title\", \"@episode_name\"),\n    (\"Hero Present\", \"@heroes\"),\n    (\"Spotify Starts Plays\", \"@spotify_starts\"),\n    (\"Spotify Streams\", \"@spotify_streams\"),\n    (\"Spotify Listeners\", \"@spotify_listeners\"),\n    (\"Category\", \"@category\"),\n    (\"Date\", \"@release_date{%F}\"),\n    ]\n\n\nfig1 = figure(background_fill_color=\"#ebf4f6\", plot_width = 600, plot_height = 400, x_axis_type = \"datetime\", title = \"Anchor Plays Per Episode\")\nfig1.line(\"release_date\", \"anchor_plays\", source = Source, color = \"#03c2fc\", alpha = 0.8, legend_label=\"Anchor Plays\")\nfig1.line(\"release_date\", Episode_df.anchor_plays.mean(), source = Source, color = \"#f2a652\", alpha = 0.8, line_dash=\"dashed\", legend_label=\"Anchor Plays Mean : {:.3f}\".format(Episode_df.youtube_ctr.mean()))\n\n\nfig1.add_tools(HoverTool(tooltips=tooltips,formatters={\"@release_date\": \"datetime\"}))\nfig1.xaxis.axis_label = \"Release Date\"\nfig1.yaxis.axis_label = \"Anchor Plays\"\n\nfig2 = figure(background_fill_color=\"#ebf4f6\", plot_width = 600, plot_height = 400, x_axis_type = \"datetime\", title = \"Performance on Spotify Per Episode\")\nfig2.line(\"release_date\", \"spotify_starts\", source = Source, color = \"#03c2fc\", alpha = 0.8, legend_label=\"Spotify Starts Plays\")\nfig2.line(\"release_date\", \"spotify_streams\", source = Source, color = \"#f2a652\", alpha = 0.8, legend_label=\"Spotify Streams\")\nfig2.line(\"release_date\", \"spotify_listeners\", source = Source, color = \"#03fc5a\", alpha = 0.8, legend_label=\"Spotify Listeners\")\n\n\nfig2.add_tools(HoverTool(tooltips=tooltips2,formatters={\"@release_date\": \"datetime\"}))\nfig2.xaxis.axis_label = \"Release Date\"\nfig2.yaxis.axis_label = \"Total Plays\"\n\n\nshow(column(fig1,fig2))","76a5d24a":"temp=Episode_df.groupby([\"heroes_location\", \"heroes\"])[\"heroes_nationality\"].value_counts()\n\nparent=[]\nnames =[]\nvalues=[]\nheroes=[]\nfor k in temp.index:\n    parent.append(k[0])\n    heroes.append(k[1])\n    names.append(k[2])\n    values.append(temp.loc[k])\n\ndf = pd.DataFrame(\n    dict(names=names, parents=parent,values=values, heroes=heroes))\ndf[\"World\"] = \"World\"\n\nfig = px.treemap(\n    df,\n    path=['World', 'parents','names','heroes'], values='values',color='parents')\n\nfig.update_layout( \n    width=1000,\n    height=700,\n    title_text=\"Distribution of Heores by Country and Nationality\")\nfig.show()","4f617fae":"a=Episode_df.release_date\nb=(a-a.shift(periods=1, fill_value='2019-07-21')).astype('timedelta64[D]')\nd = {'episode_id':Episode_df.episode_id, 'heroes':Episode_df.heroes, 'release_date': Episode_df.release_date, 'day_difference': b}\ntemp = pd.DataFrame(d)\n\nSource = ColumnDataSource(temp)\n\ntooltips = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Hero Present\", \"@heroes\"),\n    (\"Day Difference\", \"@day_difference\"),\n    (\"Date\", \"@release_date{%F}\"),\n    ]\n\nfig1 = figure(background_fill_color=\"#ebf4f6\", plot_width = 1000, plot_height = 400, x_axis_type  = \"datetime\", title = \"Day difference between Each Release Date\")\nfig1.line(\"release_date\", \"day_difference\", source = Source, color = \"#03c2fc\", alpha = 0.8)\n\nfig1.add_tools(HoverTool(tooltips=tooltips,formatters={\"@release_date\": \"datetime\"}))\nfig1.xaxis.axis_label = \"Date\"\nfig1.yaxis.axis_label = \"No of Days\"\n\nfig1.xaxis.major_label_orientation = np.pi \/ 3\nshow(column(fig1))","ec59259d":"def show_script(id):\n    return pd.read_csv(\"..\/input\/chai-time-data-science\/Cleaned Subtitles\/{}.csv\".format(id))","d576564e":"df = show_script(\"E1\")\ndf","1c0b4fea":"# feature engineer the transcript features\ndef conv_to_sec(x):\n    \"\"\" Time to seconds \"\"\"\n\n    t_list = x.split(\":\")\n    if len(t_list) == 2:\n        m = t_list[0]\n        s = t_list[1]\n        time = int(m) * 60 + int(s)\n    else:\n        h = t_list[0]\n        m = t_list[1]\n        s = t_list[2]\n        time = int(h) * 60 * 60 + int(m) * 60 + int(s)\n    return time\n\n\ndef get_durations(nums, size):\n    \"\"\" Get durations i.e the time for which each speaker spoke continuously \"\"\"\n\n    diffs = []\n    for i in range(size - 1):\n        diffs.append(nums[i + 1] - nums[i])\n    diffs.append(30)  # standard value for all end of the episode CFA by Sanyam\n    return diffs\n\n\ndef transform_transcript(sub, episode_id):\n    \"\"\" Transform the transcript of the given episode \"\"\"\n\n    # create the time second feature that converts the time into the unified qty. of seconds\n    sub[\"Time_sec\"] = sub[\"Time\"].apply(conv_to_sec)\n\n    # get durations\n    sub[\"Duration\"] = get_durations(sub[\"Time_sec\"], sub.shape[0])\n\n    # providing an identity to each transcript\n    sub[\"Episode_ID\"] = episode_id\n    sub = sub[[\"Episode_ID\", \"Time\", \"Time_sec\", \"Duration\", \"Speaker\", \"Text\"]]\n\n    return sub\n\n\ndef combine_transcripts(sub_dir):\n    \"\"\" Combine all the 75 transcripts of the ML Heroes Interviews together as one dataframe \"\"\"\n\n    episodes = []\n    for i in range(1, 76):\n        file = \"E\" + str(i) + \".csv\"\n        try:\n            sub_epi = pd.read_csv(os.path.join(sub_dir, file))\n            sub_epi = transform_transcript(sub_epi, (\"E\" + str(i)))\n            episodes.append(sub_epi)\n        except:\n            continue\n    return pd.concat(episodes, ignore_index=True)\n\n\n# create the combined transcript dataset\nsub_dir = \"..\/input\/chai-time-data-science\/Cleaned Subtitles\"\ntranscripts = combine_transcripts(sub_dir)\ntranscripts.head()","e9531a73":"temp = Episode_df[[\"episode_id\",\"youtube_avg_watch_duration\"]]\ntemp=temp[(temp.episode_id!=\"E0\") & (temp.episode_id!=\"E4\")]\n\nintro=[]\n\nfor i in transcripts.Episode_ID.unique():\n    intro.append(transcripts[transcripts.Episode_ID==i].iloc[0].Duration)\ntemp[\"Intro_Duration\"]=intro\ntemp[\"diff\"]=temp.youtube_avg_watch_duration-temp.Intro_Duration\n\nSource = ColumnDataSource(temp)\n\ntooltips = [\n    (\"Episode Id\", \"@episode_id\"),\n    (\"Youtube Avg Watch_duration Views\", \"@youtube_avg_watch_duration\"),\n    (\"Intro Duration\", \"@Intro_Duration\"),\n    (\"Avg Duration of Content Watched\", \"@diff\"),\n    ]\n\n\nfig1 = figure(background_fill_color=\"#ebf4f6\", plot_width = 1000, plot_height = 600, x_range  = temp[\"episode_id\"].values, title = \"Impact of Intro Durations\")\nfig1.line(\"episode_id\", \"youtube_avg_watch_duration\", source = Source, color = \"#03c2fc\", alpha = 0.8, legend_label=\"Youtube Avg Watch_duration Views\")\nfig1.line(\"episode_id\", \"Intro_Duration\", source = Source, color = \"#f2a652\", alpha = 0.8, legend_label=\"Intro Duration\")\nfig1.line(\"episode_id\", \"diff\", source = Source, color = \"#03fc5a\", alpha = 0.8, legend_label=\"Avg Duration of Content Watched\")\n\n\nfig1.add_tools(HoverTool(tooltips=tooltips))\nfig1.xaxis.axis_label = \"Episode Id\"\nfig1.yaxis.axis_label = \"Percentage\"\n\nfig1.xaxis.major_label_orientation = np.pi \/ 3\nshow(column(fig1))","06b5a440":"print(\"{:.2f} % of Episodes have Avg Duration of Content Watched less than 5 minutes\".format(len(temp[temp[\"diff\"]<300])\/len(temp)*100))\nprint(\"{:.2f} % of Episodes have Avg Duration of Content Watched less than 4 minutes\".format(len(temp[temp[\"diff\"]<240])\/len(temp)*100))\nprint(\"{:.2f} % of Episodes have Avg Duration of Content Watched less than 3 minutes\".format(len(temp[temp[\"diff\"]<180])\/len(temp)*100))\nprint(\"{:.2f} % of Episodes have Avg Duration of Content Watched less than 2 minutes\".format(len(temp[temp[\"diff\"]<120])\/len(temp)*100))\nprint(\"In {} case, Viewer left in the Intro Duration\".format(len(temp[temp[\"diff\"]<0])))","110dbb6a":"host_text = []\nhero_text = []\nfor i in transcripts.Episode_ID.unique():\n    host_text.append([i, transcripts[(transcripts.Episode_ID==i) & (transcripts.Speaker==\"Sanyam Bhutani\")].Text])\n    hero_text.append([i, transcripts[(transcripts.Episode_ID==i) & (transcripts.Speaker!=\"Sanyam Bhutani\")].Text])\n\ntemp_host={}\ntemp_hero={}\nfor i in range(len(transcripts.Episode_ID.unique())):\n    host_text_count = len(host_text[i][1])\n    hero_text_count = len(hero_text[i][1])\n    temp_host[hero_text[i][0]]=host_text_count\n    temp_hero[hero_text[i][0]]=hero_text_count\n    \ndef getkey(dict): \n    list = [] \n    for key in dict.keys(): \n        list.append(key)          \n    return list\n\ndef getvalue(dict): \n    list = [] \n    for key in dict.values(): \n        list.append(key)          \n    return list","cb02dd8f":"Source = ColumnDataSource(data=dict(\n    x=getkey(temp_host),\n    y=getvalue(temp_host),\n    a=getkey(temp_hero),\n    b=getvalue(temp_hero),\n))\n\ntooltips = [\n    (\"Episode Id\", \"@x\"),\n    (\"No of Times Host Speaks\", \"@y\"),\n    (\"No of Times Hero Speaks\", \"@b\"),\n]\n\nfig1 = figure(background_fill_color=\"#ebf4f6\",plot_width = 1000, tooltips=tooltips,plot_height = 400, x_range = getkey(temp_host), title = \"Who Speaks More ?\")\nfig1.vbar(\"x\", top = \"y\", source = Source, width = 0.4, color = \"#76b4bd\", alpha=.8, legend_label=\"No of Times Host Speaks\")\nfig1.vbar(\"a\", top = \"b\", source = Source, width = 0.4, color = \"#e7f207\", alpha=.8, legend_label=\"No of Times Hero Speaks\")\n\nfig1.xaxis.axis_label = \"Episode\"\nfig1.yaxis.axis_label = \"Count\"\n\nfig1.grid.grid_line_color=\"#feffff\"\nfig1.xaxis.major_label_orientation = np.pi \/ 4\n\nshow(fig1)","24177c2c":"ques=0\ntotal_ques={}\nfor episode in range(len(transcripts.Episode_ID.unique())):\n    for each_text in range(len(host_text[episode][1])):\n        ques += host_text[episode][1].reset_index().iloc[each_text].Text.count(\"?\")\n    total_ques[hero_text[episode][0]]= ques\n    ques=0","fee7b0dd":"from statistics import mean \nSource = ColumnDataSource(data=dict(\n    x=getkey(total_ques),\n    y=getvalue(total_ques),\n))\n\ntooltips = [\n    (\"Episode Id\", \"@x\"),\n    (\"No of Questions\", \"@y\"),\n]\n\nfig1 = figure(background_fill_color=\"#ebf4f6\",plot_width = 1000, plot_height = 400,tooltips=tooltips, x_range = getkey(temp_host), title = \"Questions asked Per Episode\")\nfig1.vbar(\"x\", top = \"y\", source = Source, width = 0.4, color = \"#76b4bd\", alpha=.8, legend_label=\"No of Questions asked Per Episode\")\nfig1.line(\"x\", mean(getvalue(total_ques)), source = Source, color = \"#f2a652\", alpha = 0.8,line_dash=\"dashed\", legend_label=\"Average Questions : {:.3f}\".format(mean(getvalue(total_ques))))\n\nfig1.xaxis.axis_label = \"Episode\"\nfig1.yaxis.axis_label = \"No of Questions\"\n\nfig1.legend.location = \"top_left\"\n\nfig1.grid.grid_line_color=\"#feffff\"\nfig1.xaxis.major_label_orientation = np.pi \/ 4\n\nshow(fig1)","66c51d72":"import re\nimport nltk\nfrom statistics import mean \nfrom collections import Counter\nimport string\n\ndef clean_text(text):\n    '''Make text lowercase, remove text in square brackets,remove links,remove punctuation\n    and remove words containing numbers.'''\n    text = text.lower()\n    text = re.sub('\\[.*?\\]', '', text)\n    text = re.sub('https?:\/\/\\S+|www\\.\\S+', '', text)\n    text = re.sub('<.*?>+', '', text)\n    text = re.sub('[%s]' % re.escape(string.punctuation), '', text)\n    text = re.sub('\\n', '', text)\n    text = re.sub('\\w*\\d\\w*', '', text)\n    return text\n\n\ndef text_preprocessing(text):\n    \"\"\"\n    Cleaning and parsing the text.\n\n    \"\"\"\n    tokenizer = nltk.tokenize.RegexpTokenizer(r'\\w+')\n    nopunc = clean_text(text)\n    tokenized_text = tokenizer.tokenize(nopunc)\n    #remove_stopwords = [w for w in tokenized_text if w not in stopwords.words('english')]\n    combined_text = ' '.join(tokenized_text)\n    return combined_text","4f0d7f4a":"transcripts['Text'] = transcripts['Text'].apply(str).apply(lambda x: text_preprocessing(x))","dd1689a5":"def get_data(speakername=None):\n    label=[]\n    value=[]\n\n    text_data=transcripts[(transcripts.Speaker==speakername)].Text.tolist()\n    temp=list(filter(lambda x: x.count(\" \")<10 , text_data)) \n\n    freq=nltk.FreqDist(temp).most_common(7)\n    for each in freq:\n        label.append(each[0])\n        value.append(each[1])\n        \n        \n    Source = ColumnDataSource(data=dict(\n        x=label,\n        y=value,\n    ))\n\n    tooltips = [\n        (\"Favourite Text\", \"@x\"),\n        (\"Frequency\", \"@y\"),\n    ]\n\n    fig1 = figure(background_fill_color=\"#ebf4f6\",plot_width = 600, tooltips=tooltips, plot_height = 400, x_range = label, title = \"Favourite Text\")\n    fig1.vbar(\"x\", top = \"y\", source = Source, width = 0.4, color = \"#76b4bd\", alpha=.8)\n\n    fig1.xaxis.axis_label = \"Text\"\n    fig1.yaxis.axis_label = \"Frequency\"\n\n\n    fig1.grid.grid_line_color=\"#feffff\"\n    fig1.xaxis.major_label_orientation = np.pi \/ 4\n\n    show(fig1)\n","5ce21d52":"get_data(speakername=\"Sanyam Bhutani\")","8be33439":"* Excluding Few Episodes, Ratio between No of Times One Speaks is quite mantained\n* E69 was AMA episode. That's why there is no Hero","4b0496aa":"\nSo, We have description for every episode. Let's have a close look what we have here","7cefbeb0":"<div>\n<b><font id=\"0\" size=\"5\">Importing Necessary Libraries<\/font><\/b>\n<\/div>\n\n<a href=\"#toc\"><span class=\"label label-info\">Go back to our Guide<\/span><\/a>\n","1867ba4a":"<b>\ud83d\udccc Observations :<\/b>\n\n* **Masala Chai (count=16)** and **Ginger Chai (count=16)** seems to be **favourite Chai** of our Host **followed by Herbal Tea (count=11) and Sulemani Chai (count=11)**\n\n* Also, Our Host seems to be **quite experimental with Chai**. He has varities of flavour in his belly\n\nOh Man ! This time you win. You're a real Chai lover\n\n\n<b>Now, One Question arises..\u2753<\/b>\n\n<b>So, Host drinking any specific Chai at specific time have any relation with other factors or success of CTDS?<\/b>\n\n<b>\ud83e\udde0 My Cessation: <\/b>\n\n* Thinking practically, **I don't think** drinking Chai at any specific time can have **any real impact** for the show.\n* Believing on such things is an **example of superstition**. \n* No doubt, as per the data it **may have some relation** with other factors. But to support any statement here, I would like to quote a **famous sentence used in statistics** i.e. \n\n<img src=\"https:\/\/miro.medium.com\/max\/420\/1*lYw_nshU1qg3dqbqgpWoDA.png\" width=400 height=400>\n<br>\n\n<div class=\"alert-block alert-info\">  \n    <b>Correlation<\/b> does not imply <b>Causation<\/b>   \n<\/div>","317fa68e":"<div>\n<b><font id=\"3\" size=\"5\">Credits<\/font><\/b>\n<\/div>\n<br>\nThanks everyone for these amazing photos. A Small shoutout to all of you\n\n* https:\/\/miro.medium.com\/max\/1400\/0*ovcHbNV5470zvsH5.jpeg\n<br>\n* https:\/\/api.breaker.audio\/shows\/681460\/episodes\/55282147\/image?v=0987aece49022c8863600c4cf5b67eb8&width=400&height=400\n<br>\n* https:\/\/external-preview.redd.it\/VVHgy7UiRHOUfs6v91tRSDgvvUIXlJvyiD822RG4Fhg.png?auto=webp&s=d6fb054c1f57ec09b5b45bcd7ee0e821b53449c9\n<br>\n* https:\/\/memegenerator.net\/img\/instances\/64277502.jpg\n<br>\n* https:\/\/miro.medium.com\/max\/420\/1*lYw_nshU1qg3dqbqgpWoDA.png\n<br>\n* https:\/\/eatrealamerica.com\/wp-content\/uploads\/2018\/05\/Fishy-Smell.png\n<br>\n* https:\/\/i.imgflip.com\/2so1le.jpg\n<br>\n* https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQf6ziN-7WH50MIZZQtJbO0Czsll5wTud7E3Q&usqp=CAU\n<br>\n* https:\/\/imgmediagumlet.lbb.in\/media\/2018\/07\/5b5712e41d12b6235f1385a4_1532433124061.jpeg?w=750&h=500&dpr=1\n<br>","e6b3db08":"<b>\ud83d\udccc Observations :<\/b>\n\n* On an average, **13.065%** of Episode is watched by Viewers\n* But **most Episode** haave watched percentage **less** than this threshold. \n\n<b> How does it make sense \u2753<\/b>\n* That's because we have **some outliers** like E0 and M series that has watched percentage over **20%**. \n\n<b> But Why such outliers occured \u2753<\/b>\n* That's because they have **low Episode Duration**\n\nIn this fast moving world, Humans get **bored** of things very **easily**. E0 and M Series having **low Episode Duration** made viewers to **watch more**.\n\nIf they'll subscribe to the channel or not that's a different thing. That depends on the content.\n\n<b>In order to give more to Viewers and Community, Short lengthed Episodes can be a big step <\/b>","e947d50b":"<b>\ud83d\udccc Observations :<\/b>\n\nFrom the Graphs, We can see :\n* On an average, CTDS episodes had **2.702 CTR**\n* **38 out of 76 (50% exact)** have CTRs above the average\n* Episode **E1, E27 and E49 seems to be lucky** for CTDS in terms of **Subscriber Count**\n* Episode E19 had the **best CTR (8.460)** which is self explanatory from the Episode Title. Everyone loves to know about MOOC(s) and ML Interviews in Industries\n \n<b>\ud83e\udd16 M0-M8 Series :<\/b>\n* Despite related to Fast.ai, M0-M7 **doesn't perform** that well as compared to other vides related to fast.ai\n* **M0 and M1 though received a good amount of CTR** but other M Series quite below the average CTR\n* **M0 and M1 has better impact on subscriber gain** as compared to other M series but overall series doesn't perform well on Subscriber gain\n* All M0-M8 series were released on the **same day**, which can be the reason for this incident. M0-M1 despite having good CTR **fails to hold the viewers interest on M series** \n \n<b>\ud83d\udcad Interestingly..<\/b>, \n* Episode **E19 despite of having best CTR** till now (8.460), **didn't contributed much** in Subscriber Count (only 7 Subscriber Gained) \n\nBut Why \u2753\n* CTR **doen't mean that person likes the content**, or **he\/she will be watching that video** for long or will be **subscribing to the channel**\n* Maybe that video was **recommended on his newsfeed and he\/she clicked on it** just to check the video\n* Maybe he\/she **doesn't liked the content** \n* Maybe he\/she **accidently clicked** on the video\n\nThere's an huge possibility of such cases. But in conclusion, We can say high CTR reflect cases like :\n* People clicked on the video maybe because of the **Thumbnail, or Title was soothing**. Maybe he\/she clicked because of the **hero mentioned in Title\/Thumbnail**\n\n\ud83d\udcc3 I don't know how Youtube algorithm works. But for the sake of answering exceptional case of E19, My hypothetical answer will be:\n* Title contains the word **\"MOOC\"**. Since now a days everyone wanna **break into DataScience**, Youtube algorithm may have **suggested **that video to people looking for MOOCs\n* Most of other episodes have similar kind of Titles stating **\"Interview with\"** or have some terms that **are't that begineer friendly**. Resulting in **low CTR** \n* Supporting my hypothesis, observe **E27** (having fast.ai in Title that is a famous MOOC), **E38**(Title with Youngest Grandmaster may have attracted people to click),**E49** (Getting started in Datascience), **E60**(Terms like NLP and Open Source Projects) and **E75**(again fast.ai)\n* You can **argue for E12** which has the word \"Freelancing\" in the Title. Well **exceptions** will be there\n\nOkay What's about organic reach of channel or reach via Heroes?","deae1dfa":"<b>\ud83d\udccc Observations :<\/b>\n    \n* Heores associated with \"Category\" **Kaggle** are expected to have a **Kaggle account**\n* Ignoring the counts from \"Category\" Kaggle (74-31=43), **Out of 43 only 15 Heroes have Kaggle account**.\n* This **explains all Missing 28 Values** from our CSV\n* Similarly We have **8 Heroes who don't have twitter handle**. It's okay. Even I don't have a twitter handle :D\n\n<div>\n<b><font size=\"3\">Wanna know a fun fact ?<\/font><\/b>\n<\/div>\n<br>\n\n> Because of this Kaggle platform, Now I've aprox **42%** chance of becoming a CTDS Hero :) ...\n<img src=\"https:\/\/i.imgflip.com\/2so1le.jpg\" width=224 height=224> \n<br>\n    \nAhem Ahem... Focus [RsTaK](https:\/\/www.kaggle.com\/rahulgulia) Focus.. Let's get back to our work.\n    \nWait? Guess I missed something.. \nWhat's that gender ratio?","b7ea42ab":"<b>\u2692\ufe0f About the Function :<\/b> \n\nIn order to explore our Descriptions, I just wrote a small script. It has two options:\n* Either You provide specific episode id(specific_id) to have a look at that particular description\n* Or you can provide a number(top_des) and this script will display description for top \"x\" numbers that you provided in top_des\n\n","21945712":"<div>\n<b><font id=\"1.4.4\" size=\"3\">Time for a Chai Break<\/font><\/b>\n<\/div>\n<img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcQf6ziN-7WH50MIZZQtJbO0Czsll5wTud7E3Q&usqp=CAU\" width=400 height=400>\n<br> \n\nWhile having a sip of my Chai (Tea), I'm just curious **Why this show is named \"Chai Time Data Science\"?** <br><br>\nWell, I **don't have a solid answer** for this but maybe its just **because our Host loves Chai?** Hmmm.. So You wanna say our Host is more Hardcore Chai Lover than me?\n\nHey ! Hold my Chai..\n    \n","8b15ccbe":"<div>\n<b><font id=\"1.4.10\" size=\"3\">Distribution of Heores by Country and Nationality<\/font><\/b>\n<\/div>","c65bcf4d":"<div>\n<b><font id=\"1.1\" size=\"4\">Exploring YouTube Thumbnail Types.csv<\/font><\/b>\n<\/div>\n\n<a href=\"#toc\"><span class=\"label label-info\">Go back to our Guide<\/span><\/a>\n\nAs per our knowledge, This file consists of the description of Anchor\/Audio thumbnail of the episodes. Let's explore more about it...\n","88e72c57":"<div class=\"alert alert-block alert-danger\">  \n<b>Note :<\/b>  Sometimes, Plotly Graphs fails to render with the Kernel. Please restart the page in that case\n<\/div>\n\n","99e9ec32":"Jokes apart, We can't give any strong statement over this. \n\nBut yea, I'm hoping for more Female Heroes :D\n\n<b>\ud83e\udde0 My Cessation: <\/b>\n\nI won't talk much about relation of gender with other features because :\n* Gender feature is highly biased towards one category\n\nSo, We can not conclude any relation with other features. \n* If we had a good gender ratio, then we could have talked about impact of gender  \n\nEven if we somehow observe any positive conclusion for Female gender then I would say it will be just a coincidence. There are other factors apart from gender that may have resulted in positive conclusion for Female gender.\n\nWith such a biased and small sample size for Female, We can not comment any strong statement on that","c27149a8":"<b>\ud83d\udccc Observations :<\/b>\n\nFew things to note here :\n    \n* Well, I havn't cracked Youtube Algorithm, but it seems Youtube has its blessing over CTDS\n* CTDS Episodes is only able to convert **2.84%** of **Youtube Impressions into Viewers**\n* **65.12%** of CTDS views are **Non Impression views**\n    \nSeems It's clear Youtube Thumbnail, Video Title are the important factor for deciding whether a person will click on the video or not. \n\nWait, You want some figures?","c8610335":"<div>\n<b><font id=\"1.4.8\" size=\"3\">Performance on Other Platforms<\/font><\/b>\n<\/div>","08dc0501":"<div>\n<b><font id=\"1.3\" size=\"4\">Exploring Description.csv<\/font><\/b>\n<\/div>\n\n<a href=\"#toc\"><span class=\"label label-info\">Go back to our Guide<\/span><\/a>\n\nThis file consists of the descriptions texts from YouTube and Audio\n","1f478aec":"<div>\n<b><font id=\"1\" size=\"5\">A Closer look to our Directories<\/font><\/b>\n<\/div>\n\n<a href=\"#toc\"><span class=\"label label-info\">Go back to our Guide<\/span><\/a>\n\nLet's dive into each and every aspect of our Dataset step by step in order to get every inches out of it...\n","51241517":"<div>\n<b><font id=\"1.4.11\" size=\"3\">How much Viewers wanna watch?<\/font><\/b>\n<\/div>\n<br>\nEpisodes have different duration.\n\nIn order to get a significant insight, I'll calculate the **percentage of each Episode watched**..","c98c0605":"<b>\ud83d\udccc Observations :<\/b>\n* Okay, Yeah seems to be favourite words of [Sanyam Bhutani](https:\/\/www.kaggle.com\/init27)\n* Well He has some different laughs for different scenario I guess \ud83d\ude04\n* We have all the Transcript where [Sanyam Bhutani](https:\/\/www.kaggle.com\/init27) speaks. So, It's common that you'll find words with good frequency for [Sanyam Bhutani](https:\/\/www.kaggle.com\/init27) only.\n* But you can still try. Who knows I might be missing something interesting \ud83d\ude04\n\n<div class=\"alert-block alert-info\">  \n    <b>Tip:<\/b> Pass your favourite hero name in function get_data() and you're good to go\n<\/div>","1792fa35":"Now, That's much better.. \n\nBut We still have a lots of Missing Values","c2299a63":"<div>\n<b><font id=\"1.2\" size=\"4\">Exploring Anchor Thumbnail Types.csv<\/font><\/b>\n<\/div>\n\n<a href=\"#toc\"><span class=\"label label-info\">Go back to our Guide<\/span><\/a>\n\nSo, This file contains the statistics of the Anchor\/Audio thumbnail","21d5dc2c":"<div>\n<b><font id=\"1.4\" size=\"4\">Exploring Episodes.csv<\/font><\/b>\n<\/div>\n\n<a href=\"#toc\"><span class=\"label label-info\">Go back to our Guide<\/span><\/a>\n\nThis file contains the statistics of all the Episodes of the Chai Time Data Science show.\n\nOkay ! So, it's the big boy itself .. \n","e069a1bd":"   \n* It's 2020 and Seems now-a-days people aren't not much into podcasts and Audios","facf2a67":"* On an Average, around 30 Questions are asked by Host\n* E69 being AMA Episode justifies the reason of having such high no of Questions","472a4a4e":"<div>\n<b><font id=\"1.5.3\" size=\"3\">Who Speaks More ?<\/font><\/b>\n<\/div>\n<br>","9d8acf22":"Also, ignoring \"E0\" and \"E69\" for right now ...","dc6df4a9":"<div>\n<b><font id=\"1.5.4\" size=\"3\">Frequency of Questions Per Episode <\/font><\/b>\n<\/div>\n<br>","b5ee18e7":"Wew ! That's a lot of features. \n\nI'm sure We'll gonna explore some interesting insights from this Metadata \nIf you reached till here, then please bare me for couple of minutes more.. <br><br>\nNow, We'll gonna have a big sip of our \"Chai\" :) \n\n<img align=\"center\" src=\"https:\/\/external-preview.redd.it\/VVHgy7UiRHOUfs6v91tRSDgvvUIXlJvyiD822RG4Fhg.png?auto=webp&s=d6fb054c1f57ec09b5b45bcd7ee0e821b53449c9\" height=400 width=600>","8c853bb9":"<b>\ud83d\udccc Observations :<\/b>\n    \nFollowing our analysis, We realized :\n* CTDS had an episode with **Tuatini Godard, episode_id : \"E12\" exclusively for Youtube**. Although it was an **Audio Only video**(if it makes sense :D ) released on Youtube\n* If it was an Audio Only Version, then **Why it wasn't released on other platforms** ? Hmmm... interesting. Well, I think Mr. [Sanyam Bhutani](https:\/\/www.kaggle.com\/init27) can answer this well. \n* Similarly, CTDS had an **episode with Rachel Thomas released at every platform expect for Apple**\n    \nWith this, We have solved all the mysteries related to the Missing Data. Now we can finally explore other aspects of this CSV  \n\nBut before that..","0019e077":"<div>\n<b><font id=\"2\" size=\"5\">End Notes<\/font><\/b>\n<\/div>\n<br>\n\n    \nWith this, I end my analysis on this Dataset named [Chai Time Data Science | CTDS.Show](https:\/\/www.kaggle.com\/rohanrao\/chai-time-data-science) provided by Mr. [Vopani](https:\/\/www.kaggle.com\/rohanrao) and Mr. [Sanyam Bhutani](https:\/\/www.kaggle.com\/init27).<br><br>\nIt was a wonderfull experience for me<br><br>\nSomehow if my Analysis\/Way of StoryTelling hurted any sentiments then I apologize for that <br><br>\nAnd yea Congraulations to [Chai Time Data Science | CTDS.Show](https:\/\/www.kaggle.com\/rohanrao\/chai-time-data-science) for completing a successfull 1 Year journey.<br><br>\n    \nNow I can finally enjoy my Chai break in a peace\n\n<img src=\"https:\/\/imgmediagumlet.lbb.in\/media\/2018\/07\/5b5712e41d12b6235f1385a4_1532433124061.jpeg?w=750&h=500&dpr=1\" width=400 height=400>\n    \n","ab9aeccc":"<div>\n<b><font id=\"1.4.2\" size=\"3\">M0-M8 Episodes<\/font><\/b>\n<\/div>\n<br>\n\n* Looking around for a while, I realized M0-M8 was a small mini-series based on fast.ai summaries and the Things Jeremy says to do that were released on same date.\n\n<b>\ud83e\udde0 My Cessation: <\/b>\n\n* Well for the sake of our analysis, I'll treat them as outlier for the current CSV and will analyise them seperately. So, I'm gonna remove them from this CSV, storing seperately for later analysis\n    \n","95b0a703":"It's just similar to Youtube Thumbnail Types. \n\nIf you are wondering What's anchor then it's a free platform for podcast creation","63e55e44":"<b>\ud83d\udccc Observations :<\/b>\n    \n* **55.40%** of the Anchor Thumbnail have **CTDS Branding**\n* But on an Average, **Podcasts with YouTube default playlist** image performs **better** in terms of Anchor Plays","ef6927bc":"<div>\n<b><font id=\"1.5\" size=\"4\"> Exploring Raw \/ Cleaned Substitles<\/font><\/b>\n<\/div>\n<a href=\"#toc\"><span class=\"label label-info\">Go back to our Guide<\/span><\/a>\n\n<br>\n\nSo, We have 2 directories here :\n* Raw Subtitles : Tanscript in Text format\n* Cleaned Subtitles : Tanscript in CSV format with Timestamp\n","1694888b":"<b>\ud83e\udde0 My Cessation: <\/b>\n* Observing the graph and stats, it's clear it's a high time\n* We don't have Transcript of M Series where the Percentage of Episode Watched i.e. Episode had small Duration.\n* Concluding from analysis We can now strongly comment, Episode with shorter length will definitely help\n\nThere's lots of things to improve.\n\n* Shorter Duration Videos can be delivered highlighting the important aspects of the Shows\n* Short Summaries can be provided in the description. Maybe after reading them, Viewers could devote for a longer Show (depending on the interest on the topic reflected in summery)\n* Full length Show can be provided as Podcast in Apple, Spotify, Anchor. If Viewer after shorter duration videos and summeries wishes to have a full show, they can have it from there\n\nWith 45.95% of Episodes having Avg Duration of Content Watched less than 3 minutes, We can hardly gain any useful insight or can comment on quality of Content delivered.\n\nBut Okay! We can have some fun though \ud83d\ude04","f0f91d03":"<div>\n<b><font id=\"1.4.9\" size=\"3\">Is it a Gender Biased Show?<\/font><\/b>\n<\/div>","bbf7fb0c":"\n* Most of our Heroes lives in USA but There's quite range of Diversity in Heroes Nationality within a country which is good to know ","cfbde17f":"<b>\ud83d\udccc Observations :<\/b>\n* Seems 2020 made Sanyam a bit consistant on his Release Date having a difference of 3 or 4 days between each release till 18th July","4a198bef":"<div>\n<b><font id=\"1.4.1\" size=\"3\">Missing Values<\/font><\/b>\n<\/div>\n<br>\n\nBefore diving into our analysis, Let's have check  for Missing Values in our CSV..\n\nFor this purpose, I'm gonna use this library named [missingno](https:\/\/github.com\/ResidentMario\/missingno).\n\nJust use this line :\n>import missingno as msno\n\n[missingno](https:\/\/github.com\/ResidentMario\/missingno) helps us to deal with missing values in a dataset with the help of visualisations. With over 2k stars on github, this library is already very popular.","fd60d12d":"So, Basically [CTDS](https:\/\/chaitimedatascience.com) uses **4 types of Thumbnails** in their Youtube videos. Its 2020 and people still uses YouTube default image as thumbnail ! \n\nHmm... a Smart decision or just a blind arrow, We'll figure it out in our futher analysis ...","394381f5":"Aah shit ! Here We go again..\n<img src=\"https:\/\/memegenerator.net\/img\/instances\/64277502.jpg\" height=224 width=224>\n\n<b>\ud83d\udccc Observations :<\/b>\n* We can clearly see that **heroes_kaggle_username**, **heroes_twitter_handle** have **lots of missing values**\n* We can observe **bunch of data missing** from column name **heroes to heroes_twitter_handle** in a **continous way(that big block region)** which shows a **specific reason** of data missing at those points\n* **Few datapoints** are too **missing** in **anchor**, **spotify** and **apple** section i.e. missing data in **podcasts**\n\nThere is also a chart on the right side of plot.It summarizes the general shape of the data completeness and points out the rows with the maximum and minimum nullity in the dataset.\n\nWell, Before giving any False Proclaim Let's explore more about it..","8ecf9992":"<div>\n<b><font id=\"1.5.2\" size=\"3\">Intro is Bad for CTDS ?<\/font><\/b>\n<\/div>\n<br>\nFrom our previous analysis, We realised Majority of the Episodes have quite less watch time i.e. less than 13.065% of the total Duration. \n\nIn such case, How much CTDS intro hurts itself in terms of intro duration.\n\nLet's find out...","25b8f04f":"<div>\n<b><font id=\"1.4.12\" size=\"3\">Any Relation between Release Date of Epiosdes?<\/font><\/b>\n<\/div>","9d52affc":"<b>\ud83d\udccc Observations :<\/b>\n* Mostly Non Impression Views are **greater than Impression views**. CTDS seems to have a **loyal fan base** that's sharing his videos, producing more Non Impression Views\n* In some cases, there's sharp increase in views and **big difference** between Impression and Non Impression Views. \n* People **love to see specific Heroes**. Hero choice do matter\n* Total Views(especially Non Impression Views) definately plays role in Subscriber Gain\n* Though M series doesn't have good performance, but if you watch carefully, you'll realise **M series has better Impression Views than Non Impression Views**","8cf1e167":"<div>\n<b><font id=\"1.4.6\" size=\"3\">Youtube Favors CTDS?<\/font><\/b>\n<\/div>","42fad1cd":"<div>\n<b><font id=\"1.4.5\" size=\"3\">How to get More Audience?<\/font><\/b>\n<\/div>\n<br>\n    \nWell, rewarding for your victory in that Chai Lover Challenge, I'll try to assist CTDS on how to get more Audience \ud83d\ude04 \n* Ofcourse CTDS.Shows are a kind of gem, fully informative, covering interviews with some successfull people\n* But talking Statistically here, We'll gonna define Success of an Episode by amount of Audience it gathered\n","670fc4ce":"<div>\n<b><font id=\"1.5.5\" size=\"3\">Favourite Text ?<\/font><\/b>\n<\/div>\n<br>\n\n<b>\u2692\ufe0f About the Function :<\/b> \n\nWell, I'm gonna write a small function. You can pass a Hero Name and it will create a graph about 7 most common words spoken by that person \n\n\nBut before that I would like to give a small Shoutout to [Parul Pandey](https:\/\/www.kaggle.com\/parulpandey) for providing a text cleaning script in her [Kernel](https:\/\/www.kaggle.com\/parulpandey\/how-to-explore-the-ctds-show-data).","2aeef625":"<b>\ud83d\udccc Observations :<\/b>\n* Columns from **heroes** to **heroes_nationality** has same about of missing data. Seems We can find a **reasonable relation** between them\n* About **45.88% (85-39)** and **22.35% (85-19)** of Data missing in column name **heroes_kaggle_username** and **heroes_twitter_handle** respectively\n* We have just **1 missing value** in **anchor** and **spotify**, **2 missing values** in **apple section** that is quite easy to handle\n\n<br>\n\n<b>\ud83e\udde0 My Cessation: <\/b>\n* Come-on. I don't understand. Chai Time Data Science show is about interviews with our Heroes. \nSo, How do we have **11 missing values in Feature \"heroes\"**\n\n<img src=\"https:\/\/eatrealamerica.com\/wp-content\/uploads\/2018\/05\/Fishy-Smell.png\">\n<br>\nLet's find out..","853287a7":"<div>\n<b><font id=\"1.4.7\" size=\"3\">Do Thumbnails really matter ?<\/font><\/b>\n<\/div>","9734426d":"<div>\n<b><font id=\"1.5.1\" size=\"3\">A Small Shoutout to Ramshankar Yadhunath<\/font><\/b>\n<\/div>\n<br>\n\nI would like to give a small shoutout to [Ramshankar Yadhunath](https:\/\/www.kaggle.com\/thedatabeast) for providing a feature engineering script in his [Kernel](https:\/\/www.kaggle.com\/thedatabeast\/making-perfect-chai-and-other-tales). \n\nHey Guys, If you followed me till here, then dont forget to check out his [Kernel](https:\/\/www.kaggle.com\/thedatabeast\/making-perfect-chai-and-other-tales) too.","ecde58d6":"<div>\n<b><font id=\"1.4.13\" size=\"3\">Do I know about Release of anniversary interview episode?<\/font><\/b>\n<\/div>\n<br>\nBecause of time shortage, I didn't scraped new data myself.\n\nThough I visited his Youtube Channel and manually examined his Release Patterns\n\n\n| Episode Id    |      Release      |    Day Difference   |\n|----------|:-------------:|:-------------:|\n| E75 |  2020-06-18 |  4 |\n| E76 |  2020-06-21 |  3 |\n| E77 |  2020-06-28 |  7 |\n| E78 |  2020-07-02 |  4 |\n| E79 |  2020-07-09 |  7 |\n| E80 |  2020-07-12 |  3 |\n\nMaybe He's experimenting with a new pattern\n\n<b> Can We pin-point when 1 year anniversary interview episode\u2753<\/b>\n**Actually No!**\n\nThough a small pattern can be observed in Release dates, He has bit **odd recording pattern** :\n* Who knows He may have 3-4 videos already recorded and ready to be released. \n* Even if He records anniversary interview episode today, We can not say when He'll gonna release that Episode\n\nAs per his Release pattern, He's been releasing his Episodes **after 3 or 4 days**. \n\n* Considering **E77 and E79 as exception**, He'll more probably release **E81** on **2020-07-16** or **2020-07-15**\n* If He's experimenting with a new pattern (**7 day difference after one video**), then E81 will be released on **2020-07-19** followed by **E82** on **2020-07-22** or **2020-07-23**\n\nIf I'm correct then Mr. [Sanyam Bhutani](https:\/\/www.kaggle.com\/init27), Please don't forget to give a small shoutout to me \ud83d\ude04","4200dde7":"<b>\ud83d\udccc Observations :<\/b>\n\nFrom above Box-Plot : \n* It seems Type of Thumbnail do have **some impact on CTR**\n* Despite of using **YouTube default image for maximum of time**, it's average CTR is **lowest** as compared to CTR from other Youtube Thumbnail\n* Since **Count of other YouTube thumbnails are less**, We can't say What's the best Thumbnail\n* CTR depends on other factors too like Title, Hero featured in the Episode etc. Still we can **confidently** say that **Thumbnails other than YouTube default image attracts** more Users to click on the Video \n* As We talked about M series, M0-M1 failed to keep interest of people in the series. \n* Although their Mean CTR is lowest yet we can observe M0-M1 has a **better CTR as compared to majority of Episodes with Youtube default thumbnails**. \n\nIn short, Don't use **Default Youtube Image for Thumbnail**\n","647774ae":"<div align=\"center\">\n    <font size=\"6\">Solving the Mystery of Chai Time Data Science<\/font>\n<\/div>\n<br>\n<div align=\"center\">\n    <font size=\"4\">A Data Science podcast series by Sanyam Bhutani<\/font>\n<\/div>\n\n---\n\n<img src=\"https:\/\/miro.medium.com\/max\/1400\/0*ovcHbNV5470zvsH5.jpeg\" alt=\"drawing\"\/>\n\n---\n<div>\n    <font size=\"5\">Mr. RsTaK, Where are we?<\/font>\n<\/div>\n<br>\n\n\n    \nHello my dear Kagglers. As you all know I love Kaggle and its community. I spend most of my time surfing my Kaggle feed, scrolling over discussion forms, appreciating the efforts put on by various Kagglers via their unique \/ interesting way of Storytelling. <br><br>\nSo, this morning when i was following my usual routine in Kaggle, I came across this Dataset named [Chai Time Data Science | CTDS.Show](https:\/\/www.kaggle.com\/rohanrao\/chai-time-data-science) provided by Mr. [Vopani](https:\/\/www.kaggle.com\/rohanrao) and Mr. [Sanyam Bhutani](https:\/\/www.kaggle.com\/init27). \nAt first glance, I was like what's this? How they know I'm having a tea break? \nOh no buddy! I was wrong. It's [CTDS.Show](https:\/\/chaitimedatascience.com) :)\n\n\n\n---\n\n<div>\n    <font size=\"5\">Chai Time Data Science (CTDS.Show)<\/font>\n<\/div>\n<img align=\"right\" src=\"https:\/\/api.breaker.audio\/shows\/681460\/episodes\/55282147\/image?v=0987aece49022c8863600c4cf5b67eb8&width=400&height=400\" height=600 width=400>\n<br>\n\n\n    \nChai Time Data Science show is a [Podcast](https:\/\/anchor.fm\/chaitimedatascience) + [Video](https:\/\/www.youtube.com\/playlist?list=PLLvvXm0q8zUbiNdoIazGzlENMXvZ9bd3x) + [Blog](https:\/\/sanyambhutani.com\/tag\/chaitimedatascience\/) based show for interviews with Practitioners, Kagglers & Researchers and all things Data Science.\n\n[CTDS.Show](https:\/\/chaitimedatascience.com), driven by the community under the supervision of Mr. [Sanyam Bhutani](https:\/\/www.kaggle.com\/init27) gonna  complete its 1 year anniversary on **21st June, 2020** and to celebrate this achievement they decided to run a **Kaggle contest** around the dataset with all of the **75+ ML Hero interviews** on the series.\n\nAccording to our Host, The competition is aimed at articulating insights from the Interviews with ML Heroes. Provided a dataset consists of detailed Stats, Transcripts of CTDS.Show, the goal is to use these and come up with interesting insights or stories based on the 100+ interviews with ML Heroes.\n\nWe have our Dataset containing :\n* **Description.csv** : This file consists of the **descriptions texts** from YouTube and Audio\n\n* **Episodes.csv** : This file contains the **statistics of all the Episodes** of the Chai Time Data Science show.\n\n* **YouTube Thumbnail Types.csv** : This file consists of the **description of Anchor\/Audio thumbnail of the episodes**\n\n* **Anchor Thumbnail Types.csv** : This file contains the **statistics of the Anchor\/Audio thumbnail**\n\n* **Raw Subtitles** : Directory containing **74 text files** having raw subtitles of all the episodes\n\n* **Cleaned Subtitles** : Directory containing cleaned subtitles (in CSV format)     \n \nHmm.. Seems we have some stories to talk about..\n\nCongratulating [CTDS.Show](https:\/\/chaitimedatascience.com) for their **1 year anniversary**, Let's get it started :)\n\n---\n\n**<font id=\"toc\">Btw This gonna be a long kernel. So, Hey! Looking for a guide :) ?<\/font>**\n<br><br>\n&emsp;&emsp;<b><a href=\"#0\">0. Importing Necessary Libraries<\/a><br><\/b>\n\n&emsp;&emsp;<b><a href=\"#1\">1. A Closer look to our Dataset<\/a><br><\/b>\n\n&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.1\">1.1. Exploring YouTube Thumbnail Types.csv<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.2\">1.2. Exploring Anchor Thumbnail Types.csv<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.3\">1.3. Exploring Description.csv<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4\">1.4. Exploring Episodes.csv<\/a><br><\/b>\n\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.1\">1.4.1. Missing Values ?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.2\">1.4.2. M0-M8 Episodes<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.3\">1.4.3. Solving the Mystery of Missing Values<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.9\">1.4.4. Is it a Gender Biased Show?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.4\">1.4.5. Time for a Chai Break<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.5\">1.4.6. How to get More Audience?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.6\">1.4.7. Youtube Favors CTDS?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.7\">1.4.8. Do Thumbnails really matter?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.11\">1.4.9. How much Viewers wanna watch?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.8\">1.4.10. Performance on Other Platforms<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.10\">1.4.11. Distribution of Heores by Country and Nationality<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.12\">1.4.12. Any Relation between Release Date of Epiosdes?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.4.13\">1.4.13. Do I know about Release of anniversary interview episode?<\/a><br><\/b>\n\n\n&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.5\">1.5. Exploring Raw \/ Cleaned Substitles<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.5.1\">1.5.1. A Small Shoutout to Ramshankar Yadhunath<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.5.2\">1.5.2. Intro is Bad for CTDS ?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.5.3\">1.5.3. Who Speaks More ?<\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.5.4\">1.5.4. Frequency of Questions Per Episode <\/a><br><\/b>\n&emsp;&emsp;&emsp;&emsp;&emsp;&emsp;<b><a href=\"#1.5.5\">1.5.5. Favourite Text ? <\/a><br><\/b>\n\n&emsp;&emsp;<b><a href=\"#2\">2. End Notes<\/a><br><\/b>\n\n&emsp;&emsp;<b><a href=\"#3\">3. Credits<\/a><br><\/b>\n","1e4cf19f":"Now, We have some Data to work with. \n\nThanking [Ramshankar Yadhunath](https:\/\/www.kaggle.com\/thedatabeast) once again, Let's get it started ..\n\n<div class=\"alert alert-block alert-warning\">  \n<b>Note :<\/b> Transcript for E0 and E4 is missing\n<\/div>\n","d7992578":"<b>\ud83d\udcad Interesting..<\/b>\n* episode_id \"E0\" was all about Chai Time Data Science Launch Announcement\n* episode_id \"E69\" was Birthday Special\nIt make sense why there's no hero for the following episodes\n\nBut What are these M0-M8 episodes .. ?\n\n","d7deda3b":"<div>\n<b><font id=\"1.4.3\" size=\"3\">Solving the Mystery of Missing Values<\/font><\/b>\n<\/div>","e84496d8":"<div class=\"alert alert-block alert-warning\">  \n<b>Advice :<\/b> Feel free to play with the function \"show_description()\" to have a look over various descriptions provided in a go\n<\/div>\n\n<br>\n\n<b>\ud83e\udde0 My Cessation: <\/b>   \n* Although I went through some description and realized it just contains **URL**, **Necessary links** for social media sites with a **little description** of the current show and some **announcements regarding future releases**\n* I'm **not gonna put stress** in this area because **I don't think there's much to scrap in them**. Right now, let's move ahead. \n    \n"}}