{"cell_type":{"07b7b3a8":"code","9f03cd0d":"code","5e5b8c61":"code","698b2ed5":"code","97fd94dd":"code","0f115c86":"code","aa486bd0":"code","acca015c":"code","1b77c461":"code","57a1f851":"code","cae8f57e":"code","511bfc18":"code","ac6b4338":"code","bf8200c3":"code","f62dc0fc":"code","4d4a56bd":"code","9ddb093c":"code","744c785d":"code","7c59d055":"code","25b06f6f":"code","dd64a658":"code","0adfac8b":"code","fdc95d1f":"code","616f8c45":"code","e67d34fc":"code","69f2857a":"code","841340f5":"markdown"},"source":{"07b7b3a8":"import os\nimport cv2\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport json\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Flatten, Activation, Dropout, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import optimizers, applications\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler, TensorBoard, EarlyStopping\nfrom keras import backend as K ","9f03cd0d":"train_df = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/train.csv\")\ntrain_df[\"attribute_ids\"]=train_df[\"attribute_ids\"].apply(lambda x:x.split(\" \"))\ntrain_df[\"id\"]=train_df[\"id\"].apply(lambda x:x+\".png\")\ntrain_df.head()","5e5b8c61":"label_df = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/labels.csv\")\nprint(label_df.shape)\nlabel_df.head()","698b2ed5":"# Example of images with tags\n\ni = 1\nplt.figure(figsize=[30,30])\nfor img_name in os.listdir(\"..\/input\/imet-2019-fgvc6\/train\/\")[5:10]:   \n    img = cv2.imread(\"..\/input\/imet-2019-fgvc6\/train\/%s\" % img_name)[...,[2, 1, 0]]\n    plt.subplot(5, 1, i)\n    plt.imshow(img)\n    ids = train_df[train_df[\"id\"] == img_name][\"attribute_ids\"]\n    title_val = []\n    for tag_id in ids.values[0]:\n        att_name = label_df[label_df['attribute_id'].astype(str) == tag_id]['attribute_name'].values[0]\n        title_val.append(att_name)\n    plt.title(title_val)\n    i += 1\n    \nplt.show()","97fd94dd":"nb_classes = 1103\nbatch_size = 300\nimg_size = 80\nnb_epochs = 30","0f115c86":"lbls = list(map(str, range(nb_classes)))","aa486bd0":"%%time\n\ntrain_datagen=ImageDataGenerator(\n    rescale=1.\/255, \n    validation_split=0.25,\n    horizontal_flip = True,    \n    zoom_range = 0.3,\n    width_shift_range = 0.3,\n    height_shift_range=0.3\n    )\n\ntrain_generator=train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"..\/input\/imet-2019-fgvc6\/train\",\n    x_col=\"id\",\n    y_col=\"attribute_ids\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",\n    classes=lbls,\n    target_size=(img_size,img_size),\n    subset='training')\n\nvalid_generator=train_datagen.flow_from_dataframe(\n    dataframe=train_df,\n    directory=\"..\/input\/imet-2019-fgvc6\/train\",\n    x_col=\"id\",\n    y_col=\"attribute_ids\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",    \n    classes=lbls,\n    target_size=(img_size,img_size),\n    subset='validation')","acca015c":"# Loss\n\ngamma = 2.0\nepsilon = K.epsilon()\ndef focal_loss(y_true, y_pred):\n    pt = y_pred * y_true + (1-y_pred) * (1-y_true)\n    pt = K.clip(pt, epsilon, 1-epsilon)\n    CE = -K.log(pt)\n    FL = K.pow(1-pt, gamma) * CE\n    loss = K.sum(FL, axis=1)\n    return loss","1b77c461":"# Metric\n\ndef f2_score(y_true, y_pred):\n    beta = 2\n    true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)), axis=1)\n    predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)), axis=1)\n    possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)), axis=1)\n    \n    precision = true_positives \/ (predicted_positives + K.epsilon())\n    recall = true_positives \/ (possible_positives + K.epsilon())\n    \n    return K.mean(((1+beta**2)*precision*recall) \/ ((beta**2)*precision+recall+K.epsilon()))","57a1f851":"model = applications.Xception(weights=None, \n                          include_top=False, \n                          input_shape=(img_size, img_size, 3))\nmodel.load_weights('..\/input\/xception-weight\/xception_weights_tf_dim_ordering_tf_kernels_notop (1).h5')","cae8f57e":"for layer in model.layers[:-5]:\n    layer.trainable = False","511bfc18":"# Freeze some layers\n# for layer in model.layers[:-4]:\n#     layer.trainable = False","ac6b4338":"#Adding custom layers \nx = model.output\nx = Flatten()(x)\nx = Dense(1024, activation=\"relu\")(x)\nx = Dropout(0.5)(x)\npredictions = Dense(nb_classes, activation=\"softmax\")(x)\nmodel_final = Model(input = model.input, output = predictions)\n\nmodel_final.compile(optimizers.rmsprop(lr=0.001, decay=1e-6),loss=focal_loss,metrics=[f2_score])","bf8200c3":"# model_final.summary()","f62dc0fc":"# Callbacks\n\ncheckpoint = ModelCheckpoint(\"model_1.h5\", monitor='val_loss', verbose=1, save_best_only=True, save_weights_only=False, mode='auto', period=1)\nearly = EarlyStopping(monitor='val_loss', min_delta=0, patience=5, verbose=1, mode='auto')","4d4a56bd":"%%time\nhistory = model_final.fit_generator(generator=train_generator,                   \n                                    steps_per_epoch=500,\n                                    validation_data=valid_generator,                    \n                                    validation_steps=200,\n                                    epochs=nb_epochs,\n                                    callbacks = [checkpoint, early],\n                                    max_queue_size=16,\n                                    workers=2,\n                                    use_multiprocessing=True,\n                                    verbose=1)","9ddb093c":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['f2_score', 'val_f2_score']].plot()","744c785d":"sam_sub_df = pd.read_csv('..\/input\/imet-2019-fgvc6\/sample_submission.csv')\nsam_sub_df[\"id\"]=sam_sub_df[\"id\"].apply(lambda x:x+\".png\")\nprint(sam_sub_df.shape)\nsam_sub_df.head()","7c59d055":"%%time\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_datagen.flow_from_dataframe(  \n        dataframe=sam_sub_df,\n        directory = \"..\/input\/imet-2019-fgvc6\/test\",    \n        x_col=\"id\",\n        target_size = (img_size,img_size),\n        batch_size = 1,\n        shuffle = False,\n        class_mode = None\n        )","25b06f6f":"%%time\ntest_generator.reset()\npredict = model_final.predict_generator(test_generator, steps = len(test_generator.filenames))","dd64a658":"len(predict)","0adfac8b":"%%time\nimport operator\npredicted_class_indices_3=[]\nfor i in range(len(predict)):         \n    d = {}\n    for index, value in enumerate(predict[i]):               \n        if value > 0.03:            \n            d[index] = value \n    sorted_d = sorted(d.items(), key=operator.itemgetter(1), reverse=True)\n    \n    # Take only first 10 items\n    predicted_class_indices_3.append([i[0] for i in sorted_d[:10]])","fdc95d1f":"%%time\npredictions_3=[]\n\nfor i in range(len(predicted_class_indices_3)):\n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predictions = [labels[k] for k in predicted_class_indices_3[i]]\n    predictions_3.append(predictions)","616f8c45":"predict_3 = []\nfor i in range(len(predictions_3)):\n    str3 = \" \".join(predictions_3[i])\n    predict_3.append(str3)","e67d34fc":"filenames=test_generator.filenames\nresults=pd.DataFrame({\"id\":filenames,\n                      \"attribute_ids\":predict_3})\nresults['id'] = results['id'].map(lambda x: str(x)[:-4])\nresults.to_csv(\"submission.csv\",index=False)","69f2857a":"results.head()","841340f5":"**Transfer learning from pretrained model using Keras.**\n* Loss: Focal loss\n* Metrics: f2_score"}}