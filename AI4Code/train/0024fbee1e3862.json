{"cell_type":{"2ba19792":"code","73e08105":"code","c1db0531":"code","6f7899d2":"code","33aabf43":"code","d1aa38f8":"code","d7d7a91e":"code","ba03cad1":"code","8d57135c":"code","4dc25360":"code","6a6e69db":"code","248e22bc":"code","76b107c5":"code","a9e93711":"code","2ac664c0":"code","f82a1fb7":"code","723027cd":"code","d2d97113":"code","7fc89b28":"code","b31fdf51":"code","6206862c":"code","4f99ed19":"code","1aead396":"code","041fb47a":"markdown","ed211e47":"markdown","fca9ffa6":"markdown","1853eb74":"markdown","eaefd65d":"markdown"},"source":{"2ba19792":"import pandas as pd\nimport numpy as np\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import mean_squared_error\n\nfrom catboost import CatBoostRegressor,cv,Pool\nimport lightgbm as lgb\nimport xgboost as xgb\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","73e08105":"train = pd.read_csv('..\/input\/janta-hack\/train_file (1).csv')\ntest = pd.read_csv('..\/input\/janta-hack\/test_file (1).csv')","c1db0531":"train.head()","6f7899d2":"test.head()","33aabf43":"#Count the number of unique values in the dataset\ntrain.nunique()","d1aa38f8":"#Imputing the values of electricity_consumption in test data to 0\ntest['electricity_consumption'] = 0","d7d7a91e":"train['datetime'] = pd.to_datetime(train['datetime'],format='%Y-%m-%d %H:%M')\ntest['datetime'] = pd.to_datetime(test['datetime'],format='%Y-%m-%d %H:%M')","ba03cad1":"df = pd.merge(train,test,on=['ID','datetime','temperature','var1','pressure','windspeed','var2','electricity_consumption'],how='outer')\ndf.sort_values(by='datetime',inplace=True)\ndf.head()","8d57135c":"df.fillna(0,inplace=True)\nscaler = StandardScaler()\ndf['pressure'] = scaler.fit_transform(df['pressure'].values.reshape(-1,1))\ndf['windspeed'] = scaler.fit_transform(df['windspeed'].values.reshape(-1,1))","4dc25360":"#Extracting date and time features from the dataset\ndf['hour'] = df.datetime.dt.hour\ndf['day'] = df.datetime.dt.day\ndf['month'] = df.datetime.dt.month\ndf['year'] = df.datetime.dt.year","6a6e69db":"df.drop('ID',axis=1,inplace=True)\ndf.set_index('datetime',inplace=True)","248e22bc":"plt.rcParams['figure.figsize'] = 12,6","76b107c5":"#Visualising the values of temperature,var1,pressure and windspeed wrt time\nfig,axs = plt.subplots(4,1,sharex=True)\ndf['temperature'].plot(figsize=(10,5),title='temp',ax=axs[0])\ndf['var1'].plot(figsize=(10,5),title='var1',ax=axs[1])\ndf['pressure'].plot(figsize=(10,5),title='press',ax=axs[2])\ndf['windspeed'].plot(figsize=(10,5),title='wind',ax=axs[3])\nplt.show()","a9e93711":"for i in ['temperature','pressure','var1']:\n  df[f'cosine_{i}'] = df[i].apply(lambda x: np.cos(x))\n  df[f'sine_{i}'] = df[i].apply(lambda x: np.sin(x))","2ac664c0":"def feature_gen(data):\n  for i in ['day','month','year']:\n    group = data[['temperature','var1','pressure','windspeed','electricity_consumption',i]].groupby(i).agg(['mean','min','max','std'])\n    group.columns = ['_'.join(x)+f'_{i}' for x in group.columns.ravel()]\n    data = pd.merge(data,group,on=i,how='left')\n  return data","f82a1fb7":"df = feature_gen(df)\n\ndf['log_wind'] = np.log1p(df['windspeed'])\n\ngroup = df[['temperature','var1','pressure','windspeed','var2','day','month','year']].groupby('var2').agg({\n    'temperature':['mean','min','max','std'],\n    'var1':['mean','min','max','std'],\n    'pressure':['mean','min','max','std'],\n    'windspeed':['mean','min','max','std'],\n    'day':['count'],\n    'month':['count'],\n    'year':['count']})\ngroup.columns = ['_'.join(x)+'_var2' for x in group.columns.ravel()]\ndf = pd.merge(df,group,on='var2',how='left')\n\ndf['temp_diff_var1'] = abs(df['temperature']) - abs(df['var1'])\ndf.head()","723027cd":"le = LabelEncoder()\ndf['var2'] = le.fit_transform(df['var2'])\ndf['year'] = le.fit_transform(df['year'])","d2d97113":"X = df[df['electricity_consumption'] > 0]\nX_valid = df[df['electricity_consumption'] == 0]","7fc89b28":"#XGBRegressor Model\n#After cross validation we got the optimum number of trees as 3534\nxgbr2 = xgb.XGBRegressor(\n learning_rate =0.1,\n n_estimators=3534,\n max_depth=5,\n min_child_weight=1,\n gamma=0,\n subsample=0.8,\n colsample_bytree=0.8,\n nthread=4,\n scale_pos_weight=1,\n seed=27,\n objective='reg:squarederror')\n\nmodel_xgbr2 = xgbr2.fit(X.drop(['electricity_consumption'],axis=1),X['electricity_consumption'])\ny_pred_xgbr2 = xgbr2.predict(X_valid.drop(['electricity_consumption'],axis=1))\n\ntest_res = test[['ID']]\ntest_res = pd.concat([test_res,pd.DataFrame(y_pred_xgbr2,columns=['electricity_consumption'])],axis=1)\ntest_res.set_index('ID',inplace=True)\ntest_res.to_csv('sub_xgbr.csv')","b31fdf51":"#CatBoost Model cross validation\nctr = CatBoostRegressor(iterations=4000,learning_rate=0.1,depth=5,loss_function='RMSE',od_wait=100,od_type='Iter')\n\n#categorical features declaration\ncat_feat = np.where(X.drop(['electricity_consumption'],axis=1).dtypes != np.float)[0]\n\nmodel_ctr = ctr.fit(X.drop(['electricity_consumption'],axis=1),X['electricity_consumption'])\ny_pred_ctr = ctr.predict(X_valid.drop(['electricity_consumption'],axis=1))\n\ntest_res = test[['ID']]\ntest_res = pd.concat([test_res,pd.DataFrame(y_pred_ctr,columns=['electricity_consumption'])],axis=1)\ntest_res.set_index('ID',inplace=True)\ntest_res.to_csv('sub_ctr.csv')","6206862c":"#Feature Importance plot from CatBoost model\nimportance = ctr.feature_importances_\nfi = pd.Series(index = X.drop(['electricity_consumption'],axis=1).columns, data = importance)\nfi.sort_values(ascending=False)[0::][::-1].plot(kind = 'barh',figsize=(10,15))","4f99ed19":"#LightGBM Model\nparams = {'num_leaves':31,'max_depth':5,'learning_rate':0.1,'n_estimators':4000,'metric':'mse'}\n\nlgbr1 = lgb.LGBMRegressor(num_leaves=31,max_depth=5,learning_rate=0.1,n_estimators=4000,random_state=27,metric='mse')\n\n#Categorical feature declaration\ncat_feat = np.where(X.drop(['electricity_consumption'],axis=1).dtypes != np.float)[0]\n\n#Training data\ndtrain = lgb.Dataset(X.drop(['electricity_consumption'],axis=1),label=X['electricity_consumption'])\n\nmodel_lgbr1 = lgbr1.fit(X.drop(['electricity_consumption'],axis=1),X['electricity_consumption'])\ny_pred_lgbr1 = lgbr1.predict(X_valid.drop(['electricity_consumption'],axis=1))\n\ntest_res = test[['ID']]\ntest_res = pd.concat([test_res,pd.DataFrame(y_pred_lgbr1,columns=['electricity_consumption'])],axis=1)\ntest_res.set_index('ID',inplace=True)\ntest_res.to_csv('sub_lgbr.csv')","1aead396":"lgb.plot_importance(booster=lgbr1,figsize=(10,10))","041fb47a":"### Model Training","ed211e47":"This notebook is related to the Time Series Janta Hack organised by Analytics Vidhya. The competition was about the prediction of the electricity consumption of a user for the end week of every month. An hourly data of electricity consumption along with other variables was provided for 1st to 24th of every month as training data and similar observations for all other variables, except electricity consumption, were provided for 24th to 30th or 31st of every month as testing data. The data can be accessed from [here](https:\/\/datahack.analyticsvidhya.com\/contest\/janatahack-time-series-forecasting\/#About).\n<br>\n<br>The metric for evaluation was root mean square error.\n<br>\n<br>Various ensemble techniques like XGBoost, LightGBM and CatBoost have been used here.","fca9ffa6":"Out of all the models, the **CatBoost** model gave the best rmse score for the validation data.\n<br>\n<br>Before applying feature engineering on the 'electricity_consumption' column, our model performed better and gave the following results.<br>The model results were as follows:(public score,private score)\n- XGBoost: 81.7951,99.1029\n- LightGBM: 91.88575,98.4433\n- CatBoost: 75.6317, 97.9808","1853eb74":"### Feature Engineering","eaefd65d":"We also tried creating datetime features like quarter of year,weekday or weekend, day of week but they increased the model rmse score."}}