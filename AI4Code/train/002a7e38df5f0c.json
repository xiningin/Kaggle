{"cell_type":{"88a3ccfa":"code","8fd20728":"code","f2d60012":"code","9c6b916b":"code","a04f9bb2":"code","4c8744cc":"code","03c8789e":"code","92f20957":"code","cae1081d":"markdown","c34d7df9":"markdown","242cff79":"markdown","d7716524":"markdown","a11bb1a0":"markdown","ebbbd36a":"markdown","38f9e48f":"markdown","2d318aa0":"markdown"},"source":{"88a3ccfa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8fd20728":"data1 = pd.read_json('\/kaggle\/input\/yelp-dataset\/yelp_academic_dataset_business.json', lines=True)","f2d60012":"data1.head()","9c6b916b":"data2 = pd.read_json('\/kaggle\/input\/yelp-dataset\/yelp_academic_dataset_checkin.json', lines=True)","a04f9bb2":"data2.head()","4c8744cc":"from sqlalchemy import create_engine\n!pip install PyMySql\nimport pymysql","03c8789e":"engine = create_engine('mysql+pymysql:\/\/team:password@badm-database.cte4bvaqxbgn.us-east-2.rds.amazonaws.com\/team')","92f20957":"data2.to_sql(name = \"Checkin\", con = engine, if_exists='replace',chunksize=100, index=True)","cae1081d":"# Now explore the data set and understand the structure of JSON data files. Pay particular attention to the time period for which you have data and the scope of the data(location\/category etc). Document all code and metadata in the Kaggle Notebook.","c34d7df9":"# After this, to write the data into the MySQL server databases on AWS, you can refer the following example. ","242cff79":"# Here's how to use the to_sql method: https:\/\/pandas.pydata.org\/docs\/reference\/api\/pandas.DataFrame.to_sql.html","d7716524":"# Now you are all set to query the database and execute the Business Value of this exercise (setup a new restaurant)","a11bb1a0":"# In the next code cell, do not forget to select your database at the end. The name of the database is your team name. \n# create_engine('mysql+pymysql:\/\/username:password@server_name\/database_name')","ebbbd36a":"# Other resources: https:\/\/towardsdatascience.com\/build-solid-foundations-for-your-data-science-projects-with-aws-rds-and-sqlalchemy-da8388e1e209","38f9e48f":"# To install third party Python packages, you need to verify your phone number in the settings option. Once the verification is complete, switch on the toggle for Internet.","2d318aa0":"### Note: Table- Review and Table- User will take some time to load becuase of its size. If Kaggle crashes, limit the number of rows using the 'nrows' argument. For example,\n# data1 = pd.read_json('\/kaggle\/input\/yelp-dataset\/yelp_academic_dataset_business.json', lines=True, nrows=100000)"}}