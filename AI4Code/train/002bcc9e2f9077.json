{"cell_type":{"b437301e":"code","a127110f":"code","a8c42629":"code","94679249":"code","dead433d":"code","9fbe6800":"code","134e3b58":"code","5bdc5bd9":"code","f8c15bb7":"code","3dd3baaa":"code","a84a775f":"code","4f0ddac2":"code","40a65e2b":"code","77cd9ed2":"code","1ff73c1d":"code","2c196598":"code","e6989e98":"code","41b804d2":"code","6ed1f27a":"markdown","485ce160":"markdown","0f61026e":"markdown","298c7f9d":"markdown","52f3a775":"markdown","75882ee6":"markdown","6bb45576":"markdown","c5c6a0a5":"markdown","cffa684c":"markdown"},"source":{"b437301e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a127110f":"import warnings\nwarnings.filterwarnings('ignore')","a8c42629":"!pip install recordlinkage","94679249":"import recordlinkage\nfrom recordlinkage.datasets import load_febrl1","dead433d":"# Loading and using the in-built dataset \ndf = load_febrl1()\ndf.head()","9fbe6800":"list(df.columns)","134e3b58":"separator = recordlinkage.BlockIndex(on='given_name')\npairs = separator.index(df)\nprint(len(pairs))","5bdc5bd9":"pairs","f8c15bb7":"# Comparing every field with every field of each pair - similarity scores\n# We can see that the given name has 1 similarity \n# As given name is our blocking field\nrlc = recordlinkage.Compare()\nrlc.string('given_name', 'given_name',method='jarowinkler',label='given_name')\nrlc.string('surname', 'surname', method='jarowinkler',label='surname')\nrlc.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\nrlc.exact('suburb', 'suburb', label='suburb')\nrlc.exact('state', 'state', label='state')\nrlc.string('address_1', 'address_1',method='jarowinkler',label='address_1')\nfeatures = rlc.compute(pairs, df)\nfeatures.sample(5)","3dd3baaa":"# Select all features except blocking key\ndf_f = features.drop(['given_name'], axis=1)\ndf_f.head()","a84a775f":"ecm = recordlinkage.ECMClassifier()\npreds = ecm.learn((df_f).astype(int), return_type='series')\npreds[:20]","4f0ddac2":"from recordlinkage.datasets import load_febrl4\ndf1, df2 = load_febrl4()\ndf1.head()","40a65e2b":"df2.head()","77cd9ed2":"# Proceeding with blocking\nblocks = recordlinkage.BlockIndex(on='given_name')\npairs = blocks.index(df1, df2)","1ff73c1d":"# Proceeding with calculating similarity scores\nrcl = recordlinkage.Compare()\nrcl.string('given_name', 'given_name',method='jarowinkler',label='given_name')\nrcl.string('surname', 'surname', method='jarowinkler',label='surname')\nrcl.exact('date_of_birth', 'date_of_birth', label='date_of_birth')\nrcl.exact('suburb', 'suburb', label='suburb')\nrcl.exact('state', 'state', label='state')\nrcl.string('address_1', 'address_1',method='jarowinkler',label='address_1')\nfeatures = rcl.compute(pairs, df1, df2)\nfeatures.head(10)","2c196598":"# Predict matching records using ECM\ndf_f1 = features.drop(['given_name'], axis=1)\ndf_f1.head()","e6989e98":"ecm = recordlinkage.ECMClassifier()\nresult_ecm = ecm.learn((df_f1).astype(int),return_type ='series')","41b804d2":"# We can see it successfully recognized the original \n# and duplicate records\n# Eg - rec-2371-org and rec-2371-dup-0 gives 1\nresult_ecm[:20]","6ed1f27a":"<h2>Predicting record matching using an unsupervised ECM-classifier","485ce160":"Taking an example, we can see that\n`rec-122-dup-0` and `rec-122-org` match with value 1\nIt proves that our model works successfully.\n\nWe can see from the output what records are matching with each other, and can be removed out\/linked to one `global_id`. This has allowed us to do de-duplicaiton: identifying multiple records of the same user from individual tables.","0f61026e":"Through this, we can create a rich data lake mapped with global IDs and consistent data across multiple tables. It is an important pre-processing step and can help in perform ing statistical analysis in the future.","298c7f9d":"We may face some challenges\n* Huge records that require linkage, stiching or duplication\n* Records that come from different tables with various schemas\n\nWe may not have a global key or ID to merge, we can take two routes:\n* We have multiple records of the same cusotmer in the same table and we want to de-duplicate\n* Records of same customers from multiple tables need merging\n\nWe will work through these problems step by step:","52f3a775":"<h2>De-dpulication with multiple tables<\/h2>","75882ee6":"<h2>1. De-duplication in a table<\/h2>","6bb45576":"<h2>1.1 Blocking<\/h2>\n\nWe will first make our process efficient by minimizing the total comparison window. If we have a huge dataset, like 100 million, we can have about 10^16 possible pairs. We need a method to cut down so many pairs without losing too many matches. This can be done with a \"blocking key\".\n\nExample:\n* Record: first name: Mark, last name: Fleming, address: 312 Street-2 RS 10011\n* Blocking key: first name: Mark\n* This record will be paired with: Mark Johnson.....\n* Not paired with: Christian....\n* We will generate pairs only for the records that are in the same block.\n\nWe will proceed with blocking, through the Soundex value of the surname column (the soundex library is covered in my Phonetics NLP notebook). We can use various other techniques such as Canopy clustering, Sorted neighbourhood etc. ","c5c6a0a5":"<h1>Introduction<\/h1>\n\nThis notebook will cover various data stiching and text similarity techniques. We will work with a database with multiple tables. There may be a common `ID` or `KEY` but it may be absent as well. We can have scenarios like:\n\n* Customer information scattered across multiple tables\n* No global key to link them all together\n* A lot of variations in names and addresses\n\n\n**How do we solve these problems** - We can apply similarity functions on various demographic columns like the first & last name, address etc. We can look at the similarity scores and judge whether the records match or not.","cffa684c":"<h2>1.2 Similarity matching and scoring<\/h2>\n\nNow we will compute the similarity scored on the pairs generated in the previous step. The `jarowinkler` computer is being used for the process but we can use other similarity metrics as well:"}}