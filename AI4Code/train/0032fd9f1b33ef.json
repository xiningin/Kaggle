{"cell_type":{"78014fe4":"code","ea19bd2d":"code","0bfc8ba4":"code","d2c5d7c0":"code","5af77a7d":"code","c5fa3714":"code","f7e4f47a":"code","afa6207e":"code","d97bb309":"code","8cf65a2a":"code","cae93df6":"code","fbcfea6a":"code","4958f204":"code","55ed471d":"code","8f5c8191":"code","4eca7fa2":"code","5e287cd4":"code","46e05309":"code","a4b366f9":"code","92a9172b":"code","26ad18c2":"code","55b1bbe9":"code","06e19d55":"code","5bebbd1d":"code","7108186f":"code","cdc13ec2":"code","651863dc":"code","b2ca9ee9":"code","e651920c":"code","6c85329d":"code","2cbfe2f9":"code","3de5557e":"code","f45094eb":"code","7aa96c53":"code","589f3600":"code","be8da837":"code","17df60b5":"code","f5ba9fad":"code","ff336468":"code","b2a2e1b8":"code","21bd2a6d":"code","7afa482e":"code","813e8e78":"code","df723ce7":"code","b35d0a0b":"code","b0139da0":"code","a2e1dd7e":"code","b193000c":"code","1e3a57b8":"code","63b3bc8e":"code","a8333b26":"code","0c9c74c0":"code","1506f2da":"code","e018ce5a":"code","c4d096b3":"code","64df9b4b":"code","ced25e85":"code","c1cf8a21":"code","30395b66":"markdown","82d198d2":"markdown","1e8fefa5":"markdown","6c7bc2ec":"markdown","55a16de3":"markdown","202c8b26":"markdown","8ba311ac":"markdown","234d4de6":"markdown","19244791":"markdown","b6a894e7":"markdown","0f209b4f":"markdown","61f7e992":"markdown","f7112ece":"markdown","9bf8d906":"markdown","3bd2fbb7":"markdown"},"source":{"78014fe4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom fancyimpute import KNN\nfrom scipy.stats import chi2_contingency\nfrom random import randrange, uniform\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n% matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ea19bd2d":"df = pd.read_excel(\"..\/input\/Absenteeism_at_work_Project.xls\")","0bfc8ba4":"df.shape","d2c5d7c0":"df.head()","5af77a7d":"df.columns","c5fa3714":"type(df.ID)","f7e4f47a":"df.dtypes","afa6207e":"df['ID'] = df['ID'].astype('category')\n\ndf['Reason for absence'] = df['Reason for absence'].replace(0,20)\ndf['Reason for absence'] = df['Reason for absence'].astype('category')\n\ndf['Month of absence'] = df['Month of absence'].replace(0,np.nan)\ndf['Month of absence'] = df['Month of absence'].astype('category')\n\ndf['Day of the week']  = df['Day of the week'].astype('category')\ndf['Seasons'] = df['Seasons'].astype('category')\ndf['Disciplinary failure'] = df['Disciplinary failure'].astype('category')\ndf['Education'] = df['Education'].astype('category')\ndf['Son'] = df['Son'].astype('category')\ndf['Social drinker'] = df['Social drinker'].astype('category')\ndf['Social smoker'] = df['Social smoker'].astype('category')\ndf['Pet'] = df['Pet'].astype('category')","d97bb309":"df.dtypes","8cf65a2a":"#making copy of reordered data\nordered_data = df.copy()","cae93df6":"#separating continous and categrocal variables\ncontinuous_variables = [\"Transportation expense\", \"Distance from Residence to Work\", \n                          \"Service time\" , \"Age\" , \"Work load Average\/day \" ,\n                          \"Hit target\", \"Weight\" , \"Height\", \"Body mass index\",\n                          \"Absenteeism time in hours\"\n                        ]\n\ncategorical_variables = [ \"ID\", \"Reason for absence\", \"Month of absence\", \"Day of the week\",\n                           \"Seasons\", \"Disciplinary failure\", \"Education\", \"Son\",                \n                           \"Social drinker\",  \"Social smoker\", \"Pet\"\n                          ]","fbcfea6a":"#craeating separate dataframe with misssing valuse\nmissing_val = pd.DataFrame(df.isnull().sum())\nmissing_val = missing_val.reset_index()\nmissing_val = missing_val.rename(columns = {'index' :'Variables',0:'missing_perc'})\nmissing_val","4958f204":"missing_val['missing_perc'] = (missing_val['missing_perc']\/len(df))*100\nmissing_val = missing_val.sort_values('missing_perc', ascending=False).reset_index(drop = True)\nmissing_val.to_csv(\"missing_val.csv\", index=False)\n","55ed471d":"#Actual Value = 29\n#Mean = 26\n#Median = 25\n#KNN = 27\n\n#print(df['Body mass index'].iloc[9])\n#df['Body mass index'].iloc[9] = np.nan","8f5c8191":"#Mean\n#df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].median())\n\n#Median\n#df['Body mass index'] = df['Body mass index'].fillna(df['Body mass index'].median())\n\n#KNN\ndf = pd.DataFrame(KNN(k = 5).fit_transform(df), columns = df.columns)","4eca7fa2":"df.isnull().sum()\n#df.columns","5e287cd4":"#Rounding the values of categorical variables\n\nfor i in categorical_variables:\n    df.loc[:,i] = df.loc[:,i].round()\n    df.loc[:,i] = df.loc[:,i].astype('category')","46e05309":"sns.set_style(\"whitegrid\")\nsns.factorplot(data=df, x='Reason for absence', kind= 'count',size=3,aspect=2)\nsns.factorplot(data=df, x='Seasons', kind= 'count',size=3,aspect=2)\nsns.factorplot(data=df, x='Education', kind= 'count',size=3,aspect=2)\nsns.factorplot(data=df, x='Disciplinary failure', kind= 'count',size=3,aspect=2)","a4b366f9":"df.columns\n","92a9172b":"#Checking Outliers in  data using boxplot\nsns.boxplot(data=df[['Hit target','Age','Service time','Transportation expense',]])\nfig=plt.gcf()\nfig.set_size_inches(8,8)\n\n","26ad18c2":"#Checking Outliers in  data using boxplot\nsns.boxplot(data=df[['Absenteeism time in hours','Body mass index','Height','Weight',]])\nfig=plt.gcf()\nfig.set_size_inches(8,8)","55b1bbe9":"sns.boxplot(data=df[['Work load Average\/day ','Distance from Residence to Work',]])\nfig=plt.gcf()\nfig.set_size_inches(8,8)","06e19d55":"#Detecting outliers using boxplot and replacing with NA\nfor i in continuous_variables:\n    q75, q25 = np.percentile(df[i],[75,25])\n    \n    # Calculating Interquartile range\n    iqr = q75 - q25\n    \n    #calculating upper and lower fences\n    minimum = q25 - (iqr*1.5)\n    maximum = q75 + (iqr*1.5)\n    \n    #Replace all the outliers with NA\n    df.loc[df[i]<minimum,i] = np.nan\n    df.loc[df[i]>maximum,i] = np.nan\n    \n","5bebbd1d":"#Check for missing values\ndf.isnull().sum()","7108186f":"#Impute missing values withb knn\ndf = pd.DataFrame(KNN(k=3).fit_transform(df), columns = df.columns)","cdc13ec2":"#Check for missing values after applying KNN\ndf.isnull().sum()","651863dc":"#checking once again for outliers in the data after applying KNN \nsns.boxplot(data=df[['Absenteeism time in hours','Body mass index','Height','Weight',]])\nfig=plt.gcf()\nfig.set_size_inches(8,8)","b2ca9ee9":"#checking once again for outliers in the data after applying KNN \nsns.boxplot(data=df[['Hit target','Age','Service time','Transportation expense',]])\nfig=plt.gcf()\nfig.set_size_inches(8,8)","e651920c":"#checking once again for outliers in the data after applying KNN \nsns.boxplot(data=df[['Work load Average\/day ','Distance from Residence to Work',]])\nfig=plt.gcf()\nfig.set_size_inches(8,8)","6c85329d":"##Correlation analysis\n#Correlation plot\ndf_cor = df.loc[:,continuous_variables]","2cbfe2f9":"#Check for multicollinearity using corelation graph\n#Set the width and hieght of the plot\nf, ax = plt.subplots(figsize=(10,10))\n\n#Generate correlation matrix\ncor_mat = df_cor.corr()\n\n#Plot using seaborn library\nsns.heatmap(cor_mat, mask=np.zeros_like(cor_mat, dtype=np.bool), cmap=sns.diverging_palette(220, 10, as_cmap=True),\n            square=True, ax=ax)\nplt.plot()","3de5557e":"#Getting copy of the data\ndf_old = df.copy()","f45094eb":"df_old.shape","7aa96c53":"#Variable reduction\ndf_new = df.drop(['Body mass index'], axis = 1)","589f3600":"df_new.shape","be8da837":"#Check for Columns\ndf_new.columns","17df60b5":"continuous_variables","f5ba9fad":"#Updating columns in Continous_variable\ncontinuous_variables.remove('Body mass index')\ncontinuous_variables.remove('Absenteeism time in hours')","ff336468":"continuous_variables","b2a2e1b8":"#Make a copy of cleaned data\ndf_cleaned_data = df_new.copy()\n#df_new = df_cleaned_data.copy()\ndf_cleaned_data.shape","21bd2a6d":"df_new.shape","7afa482e":"#Normality Check\nfor i in continuous_variables:\n    plt.hist(df_new[i],bins='auto')\n    plt.title(\"Checking Distribution for Variable \"+str(i))\n    plt.ylabel(\"Density\")\n    plt.xlabel(i)\n    plt.show()","813e8e78":"#Normalization of continous variables\nfor i in continuous_variables:\n    \n    df_new[i] = (df_new[i] - min(df_new[i]))\/(max(df_new[i]) - min(df_new[i]))\n","df723ce7":"df_new['Age'].describe()","b35d0a0b":"#Dummy Variable creation for categorical variables\ndf_new = pd.get_dummies(data = df_new,columns=categorical_variables)","b0139da0":"df_new.shape","a2e1dd7e":"#create a copy of dataframe\ndf_new_dummies = df_new.copy()","b193000c":"df_new_dummies.shape","1e3a57b8":"#Splitting data into train and test data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, Y_train, Y_test = train_test_split(df_new.iloc[:,df_new.columns != 'Absenteeism time in hours' ],df_new.iloc[:, 8],test_size = 0.20, random_state = 1) ","63b3bc8e":"#------------------Decision Tree------------------------#\n#Importing libraries for Decision tree regressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n#create a model decision tree using DecisionTreeRegressor\nmodel_DT = DecisionTreeRegressor(random_state = 1).fit(X_train,Y_train)\n\n#Predict for the test data\npredictions_DT = model_DT.predict(X_test)\n\n#Create separate dataframe for actual and predicted data\ndf_new_dt_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_DT})\n\nprint(df_new_dt_pred.head())\n\n#Function to create to RMSE\ndef RMSE(y_actual,y_predicted):\n    rmse = np.sqrt(mean_squared_error(y_actual,y_predicted))\n    return rmse\n#Calculate RMSE and R-Squared Value\nprint(\"RMSE: \"+str(RMSE(Y_test, predictions_DT)))\nprint(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_DT)))","a8333b26":"#--------------------Random Forest------------------------#\n#Impoorting libraries for Random Forest\nfrom sklearn.ensemble import RandomForestRegressor\n\n#create a model Random forest using RandomForestRegressor\nmodel_RF = RandomForestRegressor(n_estimators = 500, random_state = 1).fit(X_train,Y_train)\n\n#predict for test data\npredictions_RF = model_RF.predict(X_test)\n\n#craete a dataframe for actual and predicted data\ndf_new_rf_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_RF})\nprint(df_new_rf_pred.head())\n\n#calculate RMSE and RSquared values\nprint(\"RMSE: \"+str(RMSE(Y_test, predictions_RF)))\nprint(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_RF)))","0c9c74c0":"#-----------------------------Linear Regression----------------------------#\n#Import libraries for Linear Regression\nfrom sklearn.linear_model import LinearRegression\n\n#Create model Linear Regression using LinearRegression\nmodel_LR = LinearRegression().fit(X_train,Y_train)\n\n#Predict for the test cases\npredictions_LR = model_LR.predict(X_test)\n\n#Create a separate dataframee for the actual and predicted data\ndf_new_lr_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_LR})\n\nprint(df_new_lr_pred.head())\n\n#Calculate RMSE and RSquared values\nprint(\"RMSE: \"+str(RMSE(Y_test, predictions_LR)))\nprint(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_LR)))\n","1506f2da":"#Get a target variable\ntarget_variable = df_new['Absenteeism time in hours']\ndf_new.shape","e018ce5a":"#import library for PCA\nfrom sklearn.decomposition import PCA\n\n#Converting data into numpy array\nX = df_new.values\n\npca = PCA(n_components = 115)\npca.fit(X)\n\n#Proportion of variance\nvar = pca.explained_variance_ratio_\n\n#Calculate Screen plot\nvar1 = np.cumsum(np.round(pca.explained_variance_ratio_,decimals=4)*100)\n\n#Draw the plot\nplt.plot(var1)\nplt.show()","c4d096b3":"#Selecting 45 Components since it explains almost 95+ % data variance\npca = PCA(n_components=45)\n\n#Fitting the selected components to the data\npca.fit(X)\n\n#Splitting data into train and test\nX_train, X_test, Y_train, Y_test = train_test_split(X,target_variable, test_size=0.2, random_state = 1)\n","64df9b4b":"#------------------Decision Tree------------------------#\n#Importing libraries for Decision tree regressor\nfrom sklearn.tree import DecisionTreeRegressor\n\n#create a model decision tree using DecisionTreeRegressor\nmodel_DTP = DecisionTreeRegressor(random_state = 1).fit(X_train,Y_train)\n\n#Predict for the test data\npredictions_DTP = model_DTP.predict(X_test)\n\n#Create separate dataframe for actual and predicted data\ndf_new_dtp_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_DTP})\n\nprint(df_new_dtp_pred.head())\n\n#Function to create to RMSE\ndef RMSE(y_actual,y_predicted):\n    rmse = np.sqrt(mean_squared_error(y_actual,y_predicted))\n    return rmse\n\n#Calculate RMSE and R-Squared Value\nprint(\"RMSE: \"+str(RMSE(Y_test, predictions_DTP)))\nprint(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_DTP)))","ced25e85":"#--------------------Random Forest------------------------#\n#Impoorting libraries for Random Forest\nfrom sklearn.ensemble import RandomForestRegressor\n\n#create a model Random forest using RandomForestRegressor\nmodel_RFP = RandomForestRegressor(n_estimators = 500, random_state = 1).fit(X_train,Y_train)\n\n#predict for test data\npredictions_RFP = model_RFP.predict(X_test)\n\n#craete a dataframe for actual and predicted data\ndf_new_rfp_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_RFP})\nprint(df_new_rfp_pred.head())\n\n#calculate RMSE and RSquared values\nprint(\"RMSE: \"+str(RMSE(Y_test, predictions_RFP)))\nprint(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_RFP)))","c1cf8a21":"#-----------------------------Linear Regression----------------------------#\n#Import libraries for Linear Regression\nfrom sklearn.linear_model import LinearRegression\n\n#Create model Linear Regression using LinearRegression\nmodel_LRP = LinearRegression().fit(X_train,Y_train)\n\n#Predict for the test cases\npredictions_LRP = model_LRP.predict(X_test)\n\n#Create a separate dataframee for the actual and predicted data\ndf_new_lrp_pred = pd.DataFrame({'actual':Y_test,'predicted':predictions_LRP})\n\nprint(df_new_lrp_pred.head())\n\n#Calculate RMSE and RSquared values\nprint(\"RMSE: \"+str(RMSE(Y_test, predictions_LRP)))\nprint(\"R-Squared Value: \"+str(r2_score(Y_test, predictions_LRP)))\n","30395b66":"**Model Creation after Principal Componet Analysis**","82d198d2":"**Decision Tree                                                                                               \nRMSE: 0.07939996345382828                                                                                     \nR-Squared Value: 0.9994795641369799**","1e8fefa5":"**Machine Learning Models**","6c7bc2ec":"**Random Forest                                                                                               \nRMSE: 0.05554332987415368                                                                                     \nR-Squared Value: 0.99974532258328**","55a16de3":"**Random Forest                                                                                               \nRMSE: 2.725268748784219                                                                                       \nR-Squared Value: 0.386880282274243**","202c8b26":"**Linear Regression                                                                                               \nRMSE: 16390064550.910776                                                                                       \nR-Squared Value: -2.2176241320666194e+19**","8ba311ac":"**Outlier Analysis**","234d4de6":"**Dimension Reduction using PCA**","19244791":"**Future Selection**","b6a894e7":"**Linear Regression                                                                                               \nRMSE: 0.0004365935184874104                                                                                   \nR-Squared Value: 0.9999999842644771**","0f209b4f":"**Future Scaling**","61f7e992":"**Decision Tree                                                                                               \nRMSE: 3.7141966443496677                                                                                       \nR-Squared Value: -0.13882343999361768**","f7112ece":"**Missing value analysis**","9bf8d906":"**Exploratory Data Analysis**","3bd2fbb7":"**Visualization of Distributed data by graphs**"}}