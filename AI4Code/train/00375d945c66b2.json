{"cell_type":{"6ed7f115":"code","f1e20a7f":"code","b1e6b951":"code","b0786a95":"code","f8bfb8b7":"code","4a0c19de":"code","40633d34":"code","1fa70657":"code","86fac0e3":"code","28ad00b8":"code","56274c56":"code","692fba8d":"markdown","3bb6e158":"markdown","12b098a0":"markdown","64b81f0f":"markdown","921a74c1":"markdown","0f1486e8":"markdown","b5ba31d6":"markdown","5b66e91a":"markdown","ed942e88":"markdown"},"source":{"6ed7f115":"# importing the package needed\nfrom __future__ import unicode_literals, print_function\nfrom pathlib import Path\nfrom tqdm import tqdm\nfrom spacy.util import minibatch, compounding\nimport pandas as pd\nimport numpy as np\nimport spacy\nimport plac\nimport random","f1e20a7f":"df_train = pd.read_csv(\"..\/input\/scl-2021-ds\/train.csv\")\n \n# split POI and street\ndf_train['poi'] = df_train['POI\/street'].apply(lambda x: x.split(\"\/\")[0])\ndf_train['street'] = df_train['POI\/street'].apply(lambda x: x.split(\"\/\")[1])\ndf_train.drop('POI\/street',axis=1, inplace=True)\n \n# find the starting and ending index of the POI\ndf_train['poi_start'] = df_train.apply(lambda x: x[1].find(x[2]),axis=1)\ndf_train['poi_end'] = df_train.apply(lambda x: x[4] + len(x[2]),axis=1)\n\n# find the starting and ending index of the street\ndf_train['street_start'] = df_train.apply(lambda x: x[1].find(x[3]),axis=1)\ndf_train['street_end'] = df_train.apply(lambda x: x[6] + len(x[3]),axis=1)\ndf_train\n\ndf_train","b1e6b951":"# change to the SpaCy train data format\nTRAIN_DATA = []\nfor i in range(len(df_train)):\n    if (df_train['poi'].values[i] != '' and df_train['poi_start'].values[i] != -1):\n        TRAIN_DATA.append((df_train['raw_address'].values[i], {'entities': [(df_train['poi_start'].values[i], df_train['poi_end'].values[i], 'POI')]}))\n    if (df_train['street'].values[i] != '' and df_train['street_start'].values[i] != -1):\n        TRAIN_DATA.append((df_train['raw_address'].values[i], {'entities': [(df_train['street_start'].values[i], df_train['street_end'].values[i], 'STREET')]}))\nTRAIN_DATA[:5]","b0786a95":"# train using GPU\nspacy.prefer_gpu()\n\n# make a empty model\nnlp = spacy.blank(\"id\")\n\n# create ner for the model\nif 'ner' not in nlp.pipe_names:\n    ner = nlp.create_pipe('ner')\n    nlp.add_pipe(ner, last=True)\nelse:\n    ner = nlp.get_pipe('ner')","f8bfb8b7":"# number of iteration for training\nn_iter = 40\n\n# add all the label (POI, STREET) to the ner\nfor _, annotations in TRAIN_DATA:\n    for ent in annotations.get('entities'):\n        ner.add_label(ent[2])\n\n# other pipes other than ner\nother_pipes = [pipe for pipe in nlp.pipe_names if pipe != 'ner']\n\n# start training\nwith nlp.disable_pipes(*other_pipes):  # only train NER\n    optimizer = nlp.begin_training()\n    sizes = compounding(4.0, 32.0, 1.001)\n    for itn in range(n_iter):\n        random.shuffle(TRAIN_DATA)\n        losses = {}\n        # use a small batch to train \n        batches = minibatch(TRAIN_DATA, size=sizes)\n        for batch in batches:\n            texts, annotations = zip(*batch)\n            nlp.update(\n                texts,  \n                annotations,  \n                drop=0.35,  # by using drop to prevent overfit \n                sgd=optimizer,\n                losses=losses)\n        print(losses)","4a0c19de":"# save the model to use next time\noutput_dir = Path('.\/')\nnlp.to_disk(output_dir)","40633d34":"# to load the saved model\noutput_dir = Path('..\/input\/spacy-training-from-scratch')\nnlp = spacy.load(output_dir)","1fa70657":"df_test = pd.read_csv(\"..\/input\/scl-2021-ds\/test.csv\")\ndf_test","86fac0e3":"# predict using test data\nresult = []\nfor i in range(len(df_test)):\n    # each test data is predicted\n    poi = ''\n    street = ''\n    doc = nlp(df_test['raw_address'][i])\n    for ent in doc.ents:\n        # if the label is POI or STREET, it will add to the poi or street \n        if ent.label_ == 'POI':\n            poi = ent.text\n        if ent.label_ == 'STREET':\n            street = ent.text\n    # the result is append according to the format \n    result.append(poi + '\/' + street)","28ad00b8":"# make a submission DataFrame \nsubmission = pd.DataFrame({\n    'id':df_test['id'],\n    'POI\/street': result\n    })\nsubmission","56274c56":"# output submission to csv\nsubmission.to_csv('submission.csv', header=True, index=False)","692fba8d":"# Setup env","3bb6e158":"The format of the SpaCy `TRAIN_DATA` what we wanted is \n\n`('<train data>',{'entities': [(<start index>, <end index>, '<label>')]})`\n\nFor example:\n```\n[\n    ('jl kapuk timur delta sili iii lippo cika 11 a cicau cikarang pusat',{'entities': [(0, 40, 'STREET')]}),\n    ('setu siung 119 rt 5 1 13880 cipayung', {'entities': [(5, 10, 'STREET')]}),\n    ('toko dita, kertosono', {'entities': [(0, 9, 'POI')]})\n    .\n    .\n]\n```\nSo, we append the data with the format to the `TRAIN_DATA`","12b098a0":"# submit","64b81f0f":"Reference:\nhttps:\/\/www.machinelearningplus.com\/nlp\/training-custom-ner-model-in-spacy\/","921a74c1":"# Prepare Train Data\nWe first seperate the `'POI\/street'` column using `.split()`\n\nThen, we find the start index of the POI\/street using `.find()`, the length of the POI\/street is added to find the end index which will be use to make the `TRAIN_DATA`","0f1486e8":"# Train SpaCy model","b5ba31d6":"Feel Free to upvote if you find this useful! :D\n\nIf you have any question, feel free to ask me down below!","5b66e91a":"This is the part where I reference from https:\/\/www.machinelearningplus.com\/nlp\/training-custom-ner-model-in-spacy\/ \n\n> It first call a empty model and create ner for the model. \n> \n> Then, the label is added to the ner. \n> \n> Finally, it will start train for the times of the iteration with shuffled data. \n\nFor more detail infomation on the parameters, you can refer to the link above.","ed942e88":"For the training result please refer to the 9th version\nThe best version we did is using `n_iter=55` and `drop=0.35`"}}