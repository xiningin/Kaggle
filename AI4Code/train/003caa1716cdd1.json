{"cell_type":{"9ea590c8":"code","f2cc05d0":"code","a4ce7f3b":"code","80da956c":"code","301ffabc":"code","e036621f":"code","54e33e05":"code","f5da8a88":"code","88278f22":"code","7acf9507":"code","eec19859":"code","72e2f843":"code","9f91f582":"code","67e47d21":"code","56845514":"code","c9c201fc":"code","c8aca083":"code","b0da7b49":"code","c7a7da9e":"code","54f58388":"code","ed509adc":"code","6ec9a7c7":"code","e90e36d5":"code","e66c0fd9":"code","68774bee":"code","d93086ec":"code","45a0c38b":"code","7d51046b":"code","d560882f":"code","49137dde":"code","0ad872ff":"code","ef6c0626":"code","1b4abd0e":"code","e64da5f8":"code","eb4c9c72":"code","d6b78337":"code","0b58186d":"code","ee8bb097":"code","3f8f0f4b":"code","ccdcba0c":"code","91a6028b":"code","1f9d3677":"code","87d4d4f0":"code","b4611b1e":"code","da0ab129":"code","36af3f13":"code","bbb85e58":"code","1f7f06fd":"code","d9c2e345":"code","66ea963e":"code","05ff432a":"code","5450bf46":"code","ce55374a":"code","edc37e11":"code","5455ae13":"code","5a79d65f":"code","3345fed1":"code","139079f5":"code","e22358c1":"code","e1ff09eb":"code","c121ce72":"code","54598c12":"code","49d61756":"code","64007ca0":"code","24649cc4":"code","3d2fe06c":"code","f42003f4":"code","e83cc321":"code","d4ae0308":"code","af489204":"code","2e098812":"code","e5daff78":"code","eba7b407":"code","2b2d156f":"code","bda159e8":"code","37a637ff":"code","d0cc3e1d":"code","640d33d4":"code","ea4e2da7":"code","e8dd37d7":"code","9b74e6e6":"code","749b3725":"code","29bad699":"markdown","db9519ed":"markdown","369aaf8a":"markdown","a1420c9f":"markdown","05ced5cf":"markdown","04f1d14a":"markdown","7cff7ba0":"markdown","0bf674ef":"markdown","c6403cad":"markdown","752da988":"markdown","619c6135":"markdown","7ac6d224":"markdown","b8fc2047":"markdown","4b433851":"markdown","383d81b2":"markdown","8c24111c":"markdown","9f19a72c":"markdown","505e0b07":"markdown","c9133c52":"markdown","66111f68":"markdown","37fac759":"markdown","f828df17":"markdown","1d55ef5a":"markdown","e9e5115a":"markdown","dbb45341":"markdown","2356fbc2":"markdown","60ee7847":"markdown","bfad9b63":"markdown","70a5ca7a":"markdown","a4b37236":"markdown","651075a1":"markdown","17e209a4":"markdown","27eddb4a":"markdown","40dceadf":"markdown","f215c42e":"markdown","c1c3e659":"markdown","be5039f9":"markdown","af88da81":"markdown","d5ee62c4":"markdown","fbc6422b":"markdown","533c436b":"markdown","2cf81754":"markdown","95a34f01":"markdown","65436022":"markdown","03a89c86":"markdown","ea5b23a6":"markdown","edbe0951":"markdown","7ad51e1f":"markdown","b8b66f8b":"markdown","66950dbd":"markdown","f65216ca":"markdown","e4229679":"markdown","83473e5d":"markdown","0bc97eb4":"markdown","7df8d402":"markdown","889c99f6":"markdown","b7c4f8d8":"markdown","a4c24993":"markdown","90a7574d":"markdown","1a2c1844":"markdown","88cb4d73":"markdown","a057ac46":"markdown","c05e7d3c":"markdown","5d474aa3":"markdown"},"source":{"9ea590c8":"# Import packages\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nsns.set(style=\"white\", font_scale=1.2)\n","f2cc05d0":"df_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')","a4ce7f3b":"df_train.head()","80da956c":"df_train.tail()","301ffabc":"df_test.head()","e036621f":"# Info to see rows, columns and missing values\n\ndf_train.info()","54e33e05":"df_test.info()","f5da8a88":"df_train.describe()","88278f22":"df_train.describe()","7acf9507":"df_train.describe(include='O')\n","eec19859":"#import pandas_profiling\n#pandas_profiling.ProfileReport(df_train)","72e2f843":"df_train.isnull().sum()","9f91f582":"df_test.isnull().sum()","67e47d21":"# Heatmap of missing values in train and test dataframes\n\nfig, axes = plt.subplots(1, 2, figsize=(12,4))\n# Train\nsns.heatmap(df_train.isnull(), cmap='viridis', cbar=False, yticklabels=False, ax=axes[0])\naxes[0].set_title('TRAIN DF')\n\n#Test\nsns.heatmap(df_test.isnull(), cmap='viridis', cbar=False, yticklabels=False, ax=axes[1])\naxes[1].set_title('TEST DF')","56845514":"def check_missing_values(df, df_name=None):\n    print(f'{df_name} - Missing values:')\n    print('-'*30)\n    columns = df.columns\n\n    for column in columns:\n        count_missing_values = df[column].isnull().sum()\n        missing_values = (count_missing_values \/ len(df[column])) * 100\n    \n        if missing_values !=0:\n            print(f'{column} --> {count_missing_values} values | {missing_values:.2f}%')","c9c201fc":"check_missing_values(df_train, 'TRAIN')","c8aca083":"check_missing_values(df_test, 'TEST')","b0da7b49":"# Drop PasserngerId, Cabin and Ticket\n# Drop Name also (maybe latter I can fix this and try to use Name)\ndf_train.drop(['PassengerId', 'Cabin', 'Ticket'], axis=1, inplace=True)\n\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = df_test['PassengerId']\ndf_test.drop(['PassengerId', 'Cabin', 'Ticket'], axis=1, inplace=True)","c7a7da9e":"print('df_train shape:',df_train.shape)\nprint('df_test shape:',df_test.shape)","54f58388":"df_train.head()","ed509adc":"df_train.hist(bins=15, figsize=(10, 7))\nplt.tight_layout()","6ec9a7c7":"fig, axes = plt.subplots(1, 4, figsize=(20,5))\n\nsns.distplot(df_train['Age'].dropna(), kde=False, bins=30, ax=axes[0])\naxes[0].set_title('Age Distribution overall')\n\nsns.distplot(df_train[df_train['Sex']=='male']['Age'].dropna(),\n             kde=False, color='blue', bins=30, ax=axes[1])\naxes[1].set_title('Age Distribution (Male)')\n\nsns.distplot(df_train[df_train['Sex']=='female']['Age'].dropna(),\n             kde=False, color='orange', bins=30, ax=axes[2])\naxes[2].set_title('Age Distribution (Female)')\n\nsns.kdeplot(df_train[df_train['Sex']=='male']['Age'].dropna(),\n            color='blue', ax=axes[3])\nsns.kdeplot(df_train[df_train['Sex']=='female']['Age'].dropna(),\n            color='orange', ax=axes[3])","e90e36d5":"fig, axes = plt.subplots(1, 2, figsize=(12,5))\n\nsns.countplot(x='Sex', data=df_train, ax=axes[0])\naxes[0].set_title('Number of males and females')\n\nsns.countplot(x='Sex', hue='Survived', data=df_train, ax=axes[1], palette='Set3')\naxes[1].set_title('Survival by sex')\naxes[1].set_ylabel('')","e66c0fd9":"fig, axes = plt.subplots(1, 3, figsize=(16,5))\n\nsns.countplot(x='Pclass', data=df_train, ax=axes[0], palette='Set1')\naxes[0].set_title('Number of people in each Pclass')\n\nsns.countplot(x='Pclass', hue='Sex', data=df_train, ax=axes[1])\naxes[1].set_title('Sex by Pclass')\naxes[1].set_ylabel('')\n\nsns.countplot(x='Pclass', hue='Survived', data=df_train, ax=axes[2], palette='Set3')\naxes[2].set_title('Survival by Pclass')\naxes[2].set_ylabel('')\n\nplt.tight_layout()","68774bee":"fig, axes = plt.subplots(1, 3, figsize=(16,5))\n\nsns.countplot(x='Embarked', data=df_train, ax=axes[0], palette='Set1')\naxes[0].set_title('Number of people in each Embarkation')\n\nsns.countplot(x='Embarked', hue='Sex', data=df_train, ax=axes[1])\naxes[1].set_title('Sex by Embarcation')\naxes[1].set_ylabel('')\n\nsns.countplot(x='Embarked', hue='Survived', data=df_train, ax=axes[2], palette='Set3')\naxes[2].set_title('Survival by Embarcation')\naxes[2].set_ylabel('')\n\nplt.tight_layout()","d93086ec":"fig, axes = plt.subplots(1, 3, figsize=(14,5))\n\nsns.pointplot(x ='Sex', y=\"Survived\", data=df_train, ax=axes[0])\naxes[0].set_title('Survival by Sex')\n\nsns.pointplot(x ='Pclass', y=\"Survived\", data=df_train, ax=axes[1])\naxes[1].set_title('Survival by Pclass')\naxes[1].set_ylabel('')\n\nsns.pointplot(x ='Embarked', y=\"Survived\", data=df_train, ax=axes[2])\naxes[2].set_title('Survival by Embarkation')\naxes[2].set_ylabel('')\n\nfor ax in axes:\n    ax.set_yticks(np.arange(0, 1.1, 0.1))\n\nplt.tight_layout()","45a0c38b":"sns.boxplot(x='Survived', y='Age', data=df_train, palette='Set3')\nplt.title('Survival by Age')","7d51046b":"sns.boxplot(x='Survived', y='Fare', data=df_train)\nplt.title('Survival by Fare')","d560882f":"df_train.corr()['Survived']","49137dde":"plt.figure(figsize=(8,8))\n\nsns.heatmap(df_train.corr(), annot=True, cmap='magma', square=True,\n            linecolor=\"white\", linewidths=0.1)\nplt.title('Correlations between variables')","0ad872ff":"check_missing_values(df_train, 'DF TRAIN')","ef6c0626":"check_missing_values(df_test, 'DF TEST')","1b4abd0e":"df_train['Familysize'] = df_train['SibSp'] + df_train['Parch']\n\ndf_test['Familysize'] = df_test['SibSp'] + df_test['Parch']","e64da5f8":"# 1 if is alone, 0 if has family members\ndf_train['Alone'] = df_train['Familysize'].apply(lambda x: 1 if x == 0 else 0)\n\ndf_test['Alone'] = df_test['Familysize'].apply(lambda x: 1 if x == 0 else 0)","eb4c9c72":"df_train[df_train['Embarked'].isnull()]","d6b78337":"fig, axes = plt.subplots(2, 2, figsize=(16,8))\n\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=df_train, ax=axes[0,0])\n\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Sex\", data=df_train, ax=axes[0,1])\n\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Survived\", data=df_train, ax=axes[1,0])\n\nsns.boxplot(x=\"Embarked\", y=\"Fare\", hue=\"Alone\", data=df_train, ax=axes[1,1])\n\nplt.tight_layout()","0b58186d":"df_train['Embarked'] = df_train['Embarked'].fillna('C')","ee8bb097":"df_test[df_test['Fare'].isnull()]","3f8f0f4b":"median_fare = df_test[(df_test['Pclass'] == 3) & (df_test['Embarked'] == 'S') & (df_test['Alone'] == 1)]['Fare'].median()\n\nmedian_fare","ccdcba0c":"df_test['Fare'] = df_test['Fare'].fillna(median_fare)","91a6028b":"plt.figure(figsize=(12, 7))\n\ntestPlot = sns.boxplot(x='Pclass', y='Age', hue='Sex', data=df_train)\n\nm1 = df_train.groupby(['Pclass', 'Sex'])['Age'].median().values\nmL1 = [str(np.round(s, 2)) for s in m1]\n\nind = 0\nfor tick in range(len(testPlot.get_xticklabels())):\n    testPlot.text(tick-.2, m1[ind+1]+1, mL1[ind+1],  horizontalalignment='center',  color='w', weight='semibold')\n    testPlot.text(tick+.2, m1[ind]+1, mL1[ind], horizontalalignment='center', color='w', weight='semibold')\n    ind += 2\n\n# Display median values from: https:\/\/stackoverflow.com\/questions\/45475962\/labeling-boxplot-with-median-values\/45476485","1f9d3677":"# Get median value for Age based on Pclass and Sex (Not having survive\/die in account, for now)\n\ndef get_age(cols):\n    age = cols[0]\n    pclass = cols[1]\n    sex = cols[2]\n    \n    if pd.isnull(age):\n\n        if pclass == 1:\n            if sex == 'male':\n                return 40\n            else:\n                return 35\n\n        elif pclass == 2:\n            if sex == 'male':\n                return 30\n            else:\n                return 28\n\n        else:\n            if sex == 'male':\n                return 25\n            else:\n                return 21.5\n            \n    else:\n        return age","87d4d4f0":"df_train['Age'] = df_train[['Age','Pclass', 'Sex']].apply(get_age, axis=1)\n\ndf_test['Age'] = df_test[['Age','Pclass', 'Sex']].apply(get_age, axis=1)","b4611b1e":"def get_title(name):\n    for string in name.split():\n        if '.' in string:\n            return string[:-1]","da0ab129":"df_train['Title'] = df_train['Name'].apply(lambda x: get_title(x))\n\ndf_test['Title'] = df_test['Name'].apply(lambda x: get_title(x))","36af3f13":"df_train['Title'].value_counts()","bbb85e58":"df_train.drop('Name', axis=1, inplace=True)\ndf_test.drop('Name', axis=1, inplace=True)","1f7f06fd":"for dataframe in [df_train, df_test]:\n    \n    dataframe['Title'] = dataframe['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', \n                                                 'Major', 'Rev', 'Sir', 'Dona', 'Countess', 'Jonkheer'], 'Other')\n\n    dataframe['Title'] = dataframe['Title'].replace('Mlle', 'Miss')\n    dataframe['Title'] = dataframe['Title'].replace('Ms', 'Miss')\n    dataframe['Title'] = dataframe['Title'].replace('Mme', 'Mrs')","d9c2e345":"sex = pd.get_dummies(df_train['Sex'], prefix='Sex', drop_first=True)\nembarked = pd.get_dummies(df_train['Embarked'], prefix='Embarked', drop_first=True)\npclass = pd.get_dummies(df_train['Pclass'], prefix='Pclass', drop_first=True)\ntitle = pd.get_dummies(df_train['Title'], prefix='Title', drop_first=True)\n\ndf_train.drop(['Sex', 'Embarked', 'Pclass', 'Title'], axis=1, inplace=True)\n\ndf_train = pd.concat([df_train, sex, embarked, pclass, title], axis=1)","66ea963e":"print('df_train shape:',df_train.shape)\ndf_train.head()","05ff432a":"sex = pd.get_dummies(df_test['Sex'], prefix='Sex', drop_first=True)\nembarked = pd.get_dummies(df_test['Embarked'], prefix='Embarked',drop_first=True)\npclass = pd.get_dummies(df_test['Pclass'], prefix='Pclass',drop_first=True)\ntitle = pd.get_dummies(df_test['Title'], prefix='Title', drop_first=True)\n\ndf_test.drop(['Sex', 'Embarked', 'Pclass', 'Title'], axis=1, inplace=True)\n\ndf_test = pd.concat([df_test, sex, embarked, pclass, title], axis=1)","5450bf46":"print('df_test shape:',df_test.shape)\ndf_train.head()","ce55374a":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ndf_train[['Age', 'Fare']] = scaler.fit_transform(df_train[['Age', 'Fare']])\n\ndf_test[['Age', 'Fare']] = scaler.transform(df_test[['Age', 'Fare']])","edc37e11":"df_train.corr()['Survived'].sort_values()[:-1]","5455ae13":"df_train.corr()['Survived'].sort_values()[:-1].plot.bar()","5a79d65f":"from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score, make_scorer","3345fed1":"X = df_train.drop('Survived', axis=1)\ny = df_train['Survived']","139079f5":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=1)","e22358c1":"# Dictionary with each prediction\npredictions = {}","e1ff09eb":"from sklearn.linear_model import LogisticRegression","c121ce72":"logreg = LogisticRegression(random_state=121)\n\nlogreg.fit(X_train, y_train)\n\ny_pred = logreg.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\n\nprint('Accuracy:', accuracy)","54598c12":"logreg = LogisticRegression(random_state=121)\n\nparam_grid = {\n    'penalty': ['l1', 'l2', 'elasticnet'],\n    'C': [0.01, 0.05, 0.1, 0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1,2,3,4,5,6,7,8,9,10,12,13,14,15,16,16.5,17,18],\n    'solver': ['liblinear','saga']}","49d61756":"model = GridSearchCV(logreg, param_grid=param_grid, scoring='accuracy', cv=10, n_jobs=-1)\n\nmodel.fit(X_train, y_train)\n\nprint('Best Params:', model.best_params_)","64007ca0":"best_lr = LogisticRegression(C=0.9, penalty='l1', solver='liblinear')\nbest_lr.fit(X_train, y_train)\ny_pred = best_lr.predict(X_test)","24649cc4":"print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\nprint('-'*55)\nprint(classification_report(y_test, y_pred))\nprint('-'*55)\nprint(confusion_matrix(y_test, y_pred))","3d2fe06c":"from sklearn.neighbors import KNeighborsClassifier","f42003f4":"error_rate = []\n\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    \n    pred_i = knn.predict(X_test)\n    \n    error_rate.append(np.mean(pred_i != y_test))","e83cc321":"# Plot Error rate vs Number of neighbors\nplt.figure(figsize=(10,6))\nplt.plot(range(1,40), error_rate,\n         color='blue', ls='--',\n         marker='o', markerfacecolor='red', markersize=10)\nplt.xlabel('Neighbors')\nplt.ylabel('Error rate')\nplt.title('Error rate vs Number of neighbors')","d4ae0308":"knn = KNeighborsClassifier(n_neighbors=25)\nknn.fit(X_train, y_train)\n\ny_pred = knn.predict(X_test)","af489204":"print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\nprint('-'*55)\nprint(classification_report(y_test, y_pred))\nprint('-'*55)\nprint(confusion_matrix(y_test, y_pred))","2e098812":"from sklearn.ensemble import RandomForestClassifier","e5daff78":"rf = RandomForestClassifier(random_state=121)\n\nrf.fit(X_train, y_train)\n\ny_pred = rf.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","eba7b407":"#rf = RandomForestClassifier(random_state=121)\n#param_grid = {\n#    'criterion':['giny', 'entropy'],\n#    'n_estimators':[50, 100, 500, 750, 1000],\n#    'max_depth':[5, 8, 15, 25, 30],\n#    'min_samples_split':[2, 5, 10, 15, 100],\n#    'min_samples_leaf':[1, 5, 10]}","2b2d156f":"#model = GridSearchCV(rf, param_grid=param_grid, cv=5, n_jobs=-1)\n\n#model.fit(X_train, y_train)\n\n#print('Best Params:', model.best_params_)","bda159e8":"best_rf = RandomForestClassifier(random_state=121, criterion='entropy', max_depth=15, min_samples_leaf=5, min_samples_split=2, n_estimators=50)\n\nbest_rf.fit(X_train, y_train)\n\ny_pred = best_rf.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)","37a637ff":"print(f'Accuracy: {accuracy_score(y_test, y_pred)*100:.2f}%')\nprint('-'*55)\nprint(classification_report(y_test, y_pred))\nprint('-'*55)\nprint(confusion_matrix(y_test, y_pred))","d0cc3e1d":"from xgboost import XGBClassifier","640d33d4":"xgb = XGBClassifier(random_state=121)\n\nxgb.fit(X_train, y_train)\n\ny_pred = xgb.predict(X_test)\n\naccuracy = accuracy_score(y_test, y_pred)\nprint('Accuracy:', accuracy)","ea4e2da7":"classifiers = [('Logistic Regression', best_lr),\n               ('KNN', knn),\n               ('Random Forest', best_rf),\n               ('Xgboost', xgb)]\n\nfor name_clf, clf in classifiers:\n    y_pred = clf.predict(X_test)\n    acc = accuracy_score(y_test, y_pred)\n    print(f'{name_clf} accuracy: {round(acc, 3)}%')","e8dd37d7":"from sklearn.ensemble import VotingClassifier","9b74e6e6":"vc = VotingClassifier(estimators=classifiers)\n\nvc.fit(X_train, y_train)\n\ny_pred = vc.predict(X_test)\n\nacc_vc = accuracy_score(y_test, y_pred)\n\nprint(f'Ensembler Accuracy: {round(acc_vc, 3)}%')","749b3725":"vc.fit(X, y)\nprediction = vc.predict(df_test)\n\nsubmission['Survived'] = prediction\n\nsubmission.to_csv('Submission.csv', index=False)","29bad699":"**Base line**","db9519ed":"#### Pclass","369aaf8a":"#### Fare","a1420c9f":"#### Distrubution of each variable","05ced5cf":"#### Age distribution","04f1d14a":"#### Embarked","7cff7ba0":"**TEST DF**","0bf674ef":"### KNN","c6403cad":"### XGBOOST","752da988":"df.describe(include=['O'])). To select pandas categorical columns","619c6135":"### Function to check missing values in each dataframe","7ac6d224":"#### Handle Title","b8fc2047":"### Numerical variables","4b433851":"Fit the ensembler with the full dataset, to make prediction in the test dataset","383d81b2":"#### Extract Title from Name","8c24111c":"Best Params: {'C': 0.9, 'penalty': 'l1', 'solver': 'liblinear'}","9f19a72c":"## Algorithms","505e0b07":"**Tunned parameters**","c9133c52":"- There are more males than females\n\n- Males tend to die, Females tend to survive","66111f68":"# Titanic - Clasification Problem","37fac759":"### Logistic Regression","f828df17":"**Base Line**","1d55ef5a":"#### Survival rates","e9e5115a":"**Base Line**","dbb45341":"Based on the median values of the plots seems likely to be 'C' > 'S', definitely is not Q. I'll go with C since Pclass, Sex and Survived point to that.","2356fbc2":"- More people in third class\n- Higher ratio Survive:Die in third class\n- More men than women die indepentedly of the class","60ee7847":"- The distributions by sex are similar\n\n- There are extreme values (outliers?)","bfad9b63":"### Summary of Variables and what to do with each one\n\n* **PassengerId**: Unique identification of the passenger. -> _Delete_\n* **Survived**: Survival (0 = No, 1 = Yes). -> _Ready_\n* **Pclass**: Ticket class (1 = 1st, 2 = 2nd, 3 = 3rd). -> _Encode (categorical)_\n* **Name**: Name of the passenger. -> _Still don't know_\n* **Sex**: Sex. -> _Encode (categorical)_\n* **Age**: Age in years. -> _Fill missing values in an easy way and maybe group in intervals_\n* **SibSp**: # of siblings \/ spouses aboard the Titanic. -> _Ready_\n* **Parch**: # of parents \/ children aboard the Titanic. -> _Ready_\n* **Ticket**: Ticket number. -> _Delete?_\n* **Fare**: Passenger fare. -> _Maybe group in intervals_\n* **Cabin**: Cabin number. -> _Delete_\n* **Embarked**: Port of Embarkation. _Encode (categorical)_","70a5ca7a":"**Drop Name**","a4b37236":"**Tuned parameters**","651075a1":"- Age and Fare on different scale","17e209a4":"#### Fill Age values","27eddb4a":"![titanic-records-1512578589.jpg](attachment:titanic-records-1512578589.jpg)\n\nhttps:\/\/hips.hearstapps.com\/hmg-prod.s3.amazonaws.com\/images\/titanic-records-1512578589.jpg","40dceadf":"### Check dataframes","f215c42e":"## Submision","c1c3e659":"## Data Visualization","be5039f9":"### Correlations","af88da81":"#### Fill Embarked values (df_train)","d5ee62c4":"### Import Libraries and Data","fbc6422b":"### Drop useless variables","533c436b":"#### Fill Fare value (df_test)","2cf81754":"#### Sex","95a34f01":"## Ensemble","65436022":"I tried with 3, 5 and 25 neighbors and **25** was the best on the submission.","03a89c86":"- Create **Family size** (Family = SibSp + Parch) and **Alone** if doesn't have family members\n\n- Fill all the missing values of **Age** in both dataframes (with mean based on Sex and Pclass) -> Maybe use some algorithm to predict them, in a future project.\n\n- Fill 2 values of **Emarked** from df_train with the most common one or check in relation with other variables\n\n- Fill 1 value of **Fare** from df_test","ea5b23a6":"### First look visualizations","edbe0951":"- Pclass and Fare are the most correlated, but not much.","7ad51e1f":"#### Create variable: Familysize","b8b66f8b":"## Data manipulation","66950dbd":"**Tunned parameters**","f65216ca":"We can see that both missing values share the variables: Fare, Pclass, Sex, Survived, Alone.","e4229679":"#### Create variable: Alone","83473e5d":"### Scaling Age and Fare variables","0bc97eb4":"#### Age","7df8d402":"### Categorical Variables","889c99f6":"### Random Forest ","b7c4f8d8":"**TRAIN DF**","a4c24993":"**Choosing best K value**","90a7574d":"## Results","1a2c1844":"# The Challenge\nThe sinking of the Titanic is one of the most infamous shipwrecks in history.\n\nOn April 15, 1912, during her maiden voyage, the widely considered \u201cunsinkable\u201d RMS Titanic sank after colliding with an iceberg. Unfortunately, there weren\u2019t enough lifeboats for everyone onboard, resulting in the death of 1502 out of 2224 passengers and crew.\n\nWhile there was some element of luck involved in surviving, it seems some groups of people were more likely to survive than others.\n\nIn this challenge, we ask you to build a predictive model that answers the question: \u201cwhat sorts of people were more likely to survive?\u201d using passenger data (ie name, age, gender, socio-economic class, etc).","88cb4d73":"### Checking missing values","a057ac46":"Best Params: {'criterion': 'entropy', 'max_depth': 15, 'min_samples_leaf': 5, 'min_samples_split': 2, 'n_estimators': 50}","c05e7d3c":"### Encoding variables (Dummies)","5d474aa3":"In a first view we see that:\n\n- Cabin contain too many values in the train and test dataframes, so we'll delete that variable.\n\n- There are many Age values missing, we'll deal with them later. Around 20% in each dataframe\n\n- 2 Embarked  missing in TRAIN DF\n\n- 1 Fare missing in TEST DF"}}