{"cell_type":{"53de59b2":"code","cff664f4":"code","9b3be3e9":"code","73db81a0":"code","d672cbfc":"code","adcc5e8e":"code","b47f44e9":"code","367f90c2":"code","53955d73":"code","0cf413a6":"code","86091159":"code","360dbc93":"code","9f910bd3":"code","e13e431d":"code","67d93c88":"code","fa4e83b8":"markdown"},"source":{"53de59b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cff664f4":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nimport warnings\nwarnings.filterwarnings('ignore')","9b3be3e9":"import matplotlib.pyplot as plt","73db81a0":"train = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/test.csv')","d672cbfc":"x_data = train.drop(['id', 'target'], axis=1)\ny_data = train.target\n\nx_test = test.drop('id', axis=1)","adcc5e8e":"x_train, x_val, y_train, y_val = train_test_split(x_data, y_data)","b47f44e9":"from torch.autograd import Variable\nimport torch.nn.functional as F","367f90c2":"import torch\nimport torchvision\nfrom torch import nn","53955d73":"class Net(nn.Module):\n    def __init__(self,input_size,output_size):\n        super(Net,self).__init__()\n        self.f1 = nn.Linear(input_size, 300)\n        self.f2 = nn.Linear(300, output_size)\n\n    def forward(self,x):\n        x = self.f1(x)\n        x = F.relu(x)\n        x = self.f2(x)\n        return  torch.sigmoid(x)\n","0cf413a6":"batch_size = 500\nbatch_no = len(x_train) \/\/ batch_size\n","86091159":"def generate_batches(X, y, batch_size):\n    assert len(X) == len(y)\n    np.random.seed(42)\n    X = np.array(X)\n    y = np.array(y)\n    perm = np.random.permutation(len(X))\n\n    for i in range(len(X)\/\/batch_size):\n        if i + batch_size >= len(X):\n            continue\n        ind = perm[i*batch_size : (i+1)*batch_size]\n        yield (X[ind], y[ind])\n","360dbc93":"input_dim = x_train.shape[1]\noutput_dim = 2\nlearning_rate = 0.0001\nmodel = Net(input_dim,output_dim)\nerror = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\nloss_list = []\nroc_list = []\niteration_number = 150\n\nfor iteration in range(iteration_number):\n    batch_loss = 0\n    batch_roc = 0\n    size = 0\n\n    for (x, y) in generate_batches(x_train, y_train, batch_size):\n        inputs = Variable(torch.from_numpy(x)).float()\n        labels = Variable(torch.from_numpy(y))\n            \n        optimizer.zero_grad() \n        results = model(inputs)\n        loss = error(results, labels)\n\n        batch_loss += loss.data\n        \n        loss.backward()\n        optimizer.step()\n        \n        batch_roc += roc_auc_score(labels.detach().numpy(), results[:, 1].detach().numpy())\n        size += 1\n    \n    loss_list.append(batch_loss\/batch_no)\n    roc_list.append(batch_roc\/size)\n    \n    if (iteration % 50 == 0):\n        print('Epoch {}: loss {}, ROC {}'.format(iteration, batch_loss \/ batch_no, batch_roc \/ size))\n\n","9f910bd3":"plt.plot(range(iteration_number), loss_list)\nplt.xlabel(\"Number of Iterations\")\nplt.ylabel(\"Loss\")\nplt.show()\nplt.plot(range(iteration_number), roc_list)\nplt.xlabel(\"Number of Iterations\")\nplt.ylabel(\"ROC\")\nplt.show()","e13e431d":"x_test = Variable(torch.FloatTensor(x_test.values), requires_grad=False) \ny_test = model(x_test)\n","67d93c88":"submission = pd.read_csv('..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')\nsubmission.target = y_test[:, 1].detach().numpy()\nsubmission.to_csv('submission.csv', index=False)","fa4e83b8":"refer to https:\/\/www.kaggle.com\/lordozvlad\/tps-nov-logistic-regression-with-pytorch"}}