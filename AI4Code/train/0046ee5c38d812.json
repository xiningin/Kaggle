{"cell_type":{"03a565a9":"code","8e6d910d":"code","b8b709f1":"code","166880cf":"code","25c1cb72":"code","46fb0a83":"code","8aa705cd":"code","4b99d2bf":"code","7a6e090c":"code","1beddc2b":"code","084977fa":"code","0499fc1f":"code","22a6e1d6":"code","24b7a167":"code","aa86bf87":"code","39a774c1":"code","a11d43c2":"code","164c5229":"code","7682e9fc":"markdown","96b37b3e":"markdown","080fb98f":"markdown","aa7639f1":"markdown","4ecc96c9":"markdown","3a6f1bef":"markdown","64c56b55":"markdown"},"source":{"03a565a9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e6d910d":"from keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Activation, Dropout, Flatten, Dense\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport matplotlib.pyplot as plt\nfrom PIL import Image \nfrom glob import glob","b8b709f1":"train_path = '..\/input\/fruits\/fruits-360\/Training\/'\ntest_path = '..\/input\/fruits\/fruits-360\/Test\/'","166880cf":"img = load_img(train_path + \"Apple Braeburn\/0_100.jpg\", target_size=(100,100))\nplt.imshow(img)\nplt.axis(\"off\")\nplt.show()\n","25c1cb72":"images = ['Orange', 'Banana', 'Cauliflower', 'Cactus fruit', 'Eggplant', 'Avocado', 'Blueberry','Lemon', 'Kiwi']\n","46fb0a83":"import matplotlib.pyplot as plt\nimport numpy as np\n\nfig = plt.figure(figsize =(15,5))\nfor i in range(9):\n    ax = fig.add_subplot(3,3,i+1,xticks=[],yticks=[])\n    #fig.patch.set_facecolor('#E53090')\n    #Above code adds a background color for subplots you can change the hex color code as you wish\n    plt.title(images[i])\n    plt.axis(\"off\")\n    ax.imshow(load_img(train_path + images[i] +\"\/0_100.jpg\", target_size=(100,100)))","8aa705cd":"x = img_to_array(img)\nprint(x.shape)","4b99d2bf":"className = glob(train_path + '\/*')\nnumber_of_class = len(className)\nprint(number_of_class)","7a6e090c":"model = Sequential()\nmodel.add(Conv2D(32, (3,3), input_shape= x.shape))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(32, (3,3),))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Conv2D(64, (3,3),))\nmodel.add(Activation(\"relu\"))\nmodel.add(MaxPooling2D())\n\nmodel.add(Flatten())\nmodel.add(Dense(1024))\nmodel.add(Activation(\"relu\"))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(number_of_class))#output\nmodel.add(Activation(\"softmax\"))\n","1beddc2b":"model.compile(loss = \"categorical_crossentropy\",\n             optimizer = \"rmsprop\",\n             metrics = [\"accuracy\"])","084977fa":"model.summary()","0499fc1f":"batch_size = 32","22a6e1d6":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                  shear_range = 0.3,\n                  horizontal_flip=True,\n                  vertical_flip=False,\n                  zoom_range = 0.3\n                  )\ntest_datagen  = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(train_path,\n                                                    target_size=x.shape[:2],\n                                                    batch_size = batch_size,\n                                                    color_mode= \"rgb\",\n                                                    class_mode = \"categorical\")\ntest_generator = test_datagen.flow_from_directory(test_path,\n                                                    target_size=x.shape[:2],\n                                                    batch_size = batch_size,\n                                                    color_mode= \"rgb\",\n                                                    class_mode = \"categorical\")","24b7a167":"hist = model.fit_generator(generator = train_generator, \n                   steps_per_epoch = 1600 \/\/ batch_size,\n                   epochs = 50,\n                   validation_data = test_generator,\n                   validation_steps = 800 \/\/ batch_size)","aa86bf87":"#model.save_weights(\"example.h5\")","39a774c1":"print(hist.history.keys())","a11d43c2":"plt.plot(hist.history[\"loss\"], label = \"Train Loss\")\nplt.plot(hist.history[\"val_loss\"], label = \"Validation Loss\")\nplt.legend()\nplt.show()","164c5229":"plt.plot(hist.history[\"accuracy\"], label = \"Train Accuracy\")\nplt.plot(hist.history[\"val_accuracy\"], label = \"Validation Accuracy\")\nplt.legend()\nplt.show()","7682e9fc":"# Cnn Model","96b37b3e":"* rescale ----> rescaling factor. Defaults to None.\n* shear_range ----> 'Shear' means that the image will be distorted along an axis, mostly to create or rectify the perception angles.\n* horizontal_flip ----> Boolean. Randomly flip inputs horizontally.\n* vertical_flip ----> Boolean. Randomly flip inputs vertically.\n* zoom_range ----> Float or [lower, upper]. Range for random zoom\n\nOTHER FUNCTIONS OF ImageDataGenerator\n\n* featurewise_center: Boolean. Set input mean to 0 over the dataset, feature-wise.\n* samplewise_center: Boolean. Set each sample mean to 0.\n* featurewise_std_normalization: Boolean. Divide inputs by std of the dataset, feature-wise.\n* samplewise_std_normalization: Boolean. Divide each input by its std.\n* zca_epsilon: epsilon for ZCA whitening. Default is 1e-6.\n* zca_whitening: Boolean. Apply ZCA whitening.\n* rotation_range: Int. Degree range for random rotations.\nwidth_shift_range: \nheight_shift_range: \n* brightness_range: Tuple or list of two floats. Range for picking a brightness shift value from.\n* channel_shift_range: Float. Range for random channel shifts.\n* fill_mode: One of {\"constant\", \"nearest\", \"reflect\" or \"wrap\"}. Default is 'nearest'.\n* cval: Float or Int. Value used for points outside the boundaries when fill_mode = \"constant\".\n* validation_split: Float. Fraction of images reserved for validation (strictly between 0 and 1).\n* dtype: Dtype to use for the generated arrays.\n* preprocessing_function: function that will be applied on each input. \n* data_format: Image data format, either \"channels_first\" or \"channels_last\".\n\n\nSource: https:\/\/keras.io\/api\/preprocessing\/image\/","080fb98f":"![fpsyg-08-01745-g001.jpg](attachment:fpsyg-08-01745-g001.jpg)","aa7639f1":"# Train-Validation Accuracy","4ecc96c9":"# Train-Validation Loss","3a6f1bef":"# Data Augmentation","64c56b55":"# Thank you for reading\n\n\n# If you enjoyed my work, please consider upvoting\n\n\n# More of my work:\n\n**Stroke EDA and Classification(%94.60 Accuracy)**\n\n- https:\/\/www.kaggle.com\/umutalpaydn\/stroke-eda-and-classification-94-60-accuracy\n\n**Heart-Disease Analysis & Classification**\n\n- https:\/\/www.kaggle.com\/umutalpaydn\/heart-disease-analysis-classification\n\n**VideoGameSales EDA**\n\n- https:\/\/www.kaggle.com\/umutalpaydn\/videogamesales-eda\n\n**Iris Classification KNN & Logistic Regression**\n\n- https:\/\/www.kaggle.com\/umutalpaydn\/iris-classification-knn-logistic-regression\n\n"}}