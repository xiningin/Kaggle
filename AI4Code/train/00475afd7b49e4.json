{"cell_type":{"a37ff42b":"code","ae099361":"code","9377301c":"code","01b86b9a":"code","18b269c7":"code","54e47d1e":"code","e5740ebf":"code","57d39f1b":"code","4dfcd5fa":"code","9978f526":"code","23787e37":"code","e6fe5436":"code","c65780d2":"code","30808752":"code","4a4f1982":"code","b4c84b90":"code","b551be7c":"code","c08a179d":"code","5901afcf":"code","9c5a5ee4":"code","0313f7af":"code","9ca48138":"code","e2eb8323":"code","6dd9f1c1":"code","e52f1637":"code","2dd6d6ed":"code","1c2f4a59":"code","b8feed54":"code","6f8c60c5":"code","a34758b6":"code","e6ac60da":"markdown","d8867f93":"markdown","78449b84":"markdown","0841f446":"markdown","b207b4ed":"markdown","7c45c07a":"markdown","ff35dd56":"markdown","09c4cb96":"markdown"},"source":{"a37ff42b":"import os\nimport re\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS\n\nplt.style.use('fivethirtyeight')","ae099361":"# globals\nDATA_DIR = os.path.join(os.pardir, 'input', 'urbandictionary')\n\nCOL_NAMES = ['character', 'browsing_page_url', 'word_url', 'word', 'definition', 'sentence']","9377301c":"file_paths = []\nfor root, dirs, files in os.walk(os.path.join(DATA_DIR, 'Urban')):\n    for f in files:\n        if f.endswith('.csv') and f.startswith('urban_data'):\n            file_paths.append(os.path.join(root, f))","01b86b9a":"df_urban = pd.concat([pd.read_csv(f, names=COL_NAMES) for f in file_paths])","18b269c7":"df_urban.shape","54e47d1e":"df_urban.reset_index(inplace=True, drop=True)\ndf_urban.head()","e5740ebf":"# all unique character are present check\nprint(sorted(df_urban['character'].unique()))","57d39f1b":"# null values check\ndf_nulls = df_urban[(df_urban.isnull().any(axis=1)) | (df_urban.isna().any(axis=1))]\ndf_nulls.shape","4dfcd5fa":"# random samples check (some may contain harsh language)\ndf_sample = df_urban[['word', 'definition', 'sentence']].sample(1)\n\nfor i in df_sample.values:\n    i[1] = re.sub('\\r', ' ', i[1])\n    i[2] = re.sub('\\r', ' ', i[2])\n    print(\"Word: \", i[0])\n    print(\"Meaning: \", i[1])\n    print(\"Sentence: \", i[2])\n    print(\"---\"*20)","9978f526":"# drop nulls\ndf_urban = df_urban.drop(df_nulls.index)\ndf_urban.shape","23787e37":"# histogram simple helper function\ndef plot_hist(vals, bins, title, xlabel, ylabel):\n    plt.figure(figsize=(12,8))\n    sns.distplot(vals, kde=False, bins=bins)\n    plt.title(title)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show();","e6fe5436":"df_urban['word_chars_num'] = df_urban['word'].apply(lambda x: len(x))\ndf_urban['word_words_num'] = df_urban['word'].apply(lambda x: len(x.split()))","c65780d2":"plot_hist(df_urban.word_chars_num, bins=70,\n          title='Characters length in Word\/Phrase\/Slang',\n          xlabel='Length',\n          ylabel='Count')","30808752":"df_urban['word_chars_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","4a4f1982":"plot_hist(df_urban.word_words_num, bins=50,\n          title='Length of Words in Word\/Phrase\/Slangs',\n          xlabel='Length',\n          ylabel='Count')","b4c84b90":"df_urban['word_words_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","b551be7c":"# curiosity: what are some slangs with more than 3 words?\ndf_urban[df_urban.word_words_num > 3].sample(5)['word'].values","c08a179d":"df_urban['defn_chars_num'] = df_urban['definition'].apply(lambda x: len(x))\ndf_urban['defn_words_num'] = df_urban['definition'].apply(lambda x: len(x.split()))","5901afcf":"plot_hist(df_urban.defn_chars_num, bins=80,\n          title='Characters length in Definition',\n          xlabel='Length',\n          ylabel='Count')","9c5a5ee4":"df_urban['defn_chars_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","0313f7af":"plot_hist(df_urban.defn_words_num, bins=80,\n          title='Length of Words in Definition',\n          xlabel='Length',\n          ylabel='Count')","9ca48138":"df_urban['defn_words_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","e2eb8323":"df_urban['sent_chars_num'] = df_urban['sentence'].apply(lambda x: len(x))\ndf_urban['sent_words_num'] = df_urban['sentence'].apply(lambda x: len(x.split()))","6dd9f1c1":"plot_hist(df_urban.sent_chars_num, bins=80,\n          title='Characters length in Sentence',\n          xlabel='Length',\n          ylabel='Count')","e52f1637":"df_urban['sent_chars_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","2dd6d6ed":"df_urban[df_urban.sent_chars_num > 1000].shape","1c2f4a59":"plot_hist(df_urban.sent_words_num, bins=200,\n          title='Length of Words in Sentence',\n          xlabel='Length',\n          ylabel='Count')","b8feed54":"df_urban['sent_words_num'].quantile([0.1, 0.3, 0.5, 0.6, 0.7, 0.8, 0.9, 0.95, 0.99, 0.999])","6f8c60c5":"import os\nimport re\nimport pandas as pd\nfrom tqdm.auto import tqdm\n\n# set globals\nDATA_DIR = os.path.join(os.pardir, 'input', 'urbandictionary')\nCOL_NAMES = ['character', 'browsing_page_url', 'word_url', 'word', 'definition', 'sentence']\n\ndef replace_special(string):\n    \"\"\"Replace special \\r character from text.\"\"\"\n    new_str = re.sub('\\r', ' ', string)\n    return new_str\n\ndef replace_space_before_punct(string):\n    \"\"\"Remove all existing spaces before punctuation.\"\"\"\n    new_str = re.sub(r\"\\b\\s+\u2019\\b\", r\"'\", string)\n    new_str = re.sub(r\"\\\"\\s\\b\", r'\"', new_str)\n    new_str = re.sub(r\"\\b\\s+,\\s*\\b\", r', ', new_str)\n    new_str = re.sub(r'\\s([?.!\"](?:\\s|$))', r'\\1', new_str)\n    return new_str\n\ndef replace_double_spaces(string):\n    \"\"\"Replace all more than one spaces to single space.\"\"\"\n    return ' '.join(string.split())\n\ndef remove_emoji(string):\n    \"\"\"Replace emojis from text\n    Source: https:\/\/stackoverflow.com\/a\/49146722\/330558\"\"\"\n\n    emoji_pattern = re.compile(\"[\"\n                          u\"\\U0001F600-\\U0001F64F\"  # emoticons\n                          u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n                          u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n                          u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n                          u\"\\U00002702-\\U000027B0\"\n                          u\"\\U000024C2-\\U0001F251\"\n                          \"]+\", flags=re.UNICODE)\n\n    return emoji_pattern.sub(r'', string)\n\ndef eda_based_cleaning(df):\n    \"\"\"Filter data based off observations from EDA.\"\"\"\n\n    df['word_chars_num'] = df['word'].apply(lambda x: len(x))\n    df['word_words_num'] = df['word'].apply(lambda x: len(x.split()))\n    df['defn_chars_num'] = df['definition'].apply(lambda x: len(x))\n    df['defn_words_num'] = df['definition'].apply(lambda x: len(x.split()))\n    df['sent_chars_num'] = df['sentence'].apply(lambda x: len(x))\n    df['sent_words_num'] = df['sentence'].apply(lambda x: len(x.split()))\n\n    df = df[~((df.word_chars_num > 17) | (df.word_words_num > 3))]\n    print(\"After filtering based on word length: \", df.shape[0])\n    df = df[~((df.defn_chars_num > 190) | (df.defn_words_num > 38))]\n    print(\"After filtering based on definition length: \", df.shape[0])\n    df = df[~((df.sent_chars_num > 155) | (df.sent_words_num > 25))]\n    print(\"After filtering based on sentence length: \", df.shape[0])\n\n    print(\"New dataframe shape: \", df.shape)\n\n    return df\n\ndef final_clean(text):\n    \"\"\"Main function to apply all cleaning functions.\"\"\"\n    cleaned_text = replace_special(text)\n    cleaned_text = replace_space_before_punct(cleaned_text)\n    cleaned_text = replace_double_spaces(cleaned_text)\n    cleaned_text = remove_emoji(cleaned_text)\n\n    return cleaned_text\n\nif __name__ == \"__main__\":\n    print(\"-\"*50)\n    print(\"Loading data...\")\n    file_paths = []\n    for root, dirs, files in os.walk(os.path.join(DATA_DIR, 'Urban')):\n        for f in files:\n            if f.endswith('.csv') and f.startswith('urban_data'):\n                file_paths.append(os.path.join(root, f))\n\n    df_urban = pd.concat([pd.read_csv(f, names=COL_NAMES) for f in file_paths])\n    print(\"Data loaded.\")\n    print(\"Data shape: \", df_urban.shape)\n    df_urban.reset_index(inplace=True)\n    print(\"-\"*50)\n\n    df_nulls = df_urban[(df_urban.isnull().any(axis=1)) | (df_urban.isna().any(axis=1))]\n    print(\"Records with at least one column null: \", df_nulls.shape[0])\n    print(\"Dropping nulls.\")\n    df_urban = df_urban.drop(df_nulls.index)\n    df_urban.reset_index(inplace=True)\n    print(\"New data shape: \", df_urban.shape)\n    print(\"-\"*50)\n\n    print(\"Applying transformation based off EDA.\")\n    df_urban_new = eda_based_cleaning(df_urban)\n    print(\"-\"*50)\n\n    print(\"Cleaning texts...\")\n    df_urban_new['word'] = df_urban_new['word'].apply(lambda x: final_clean(x))\n    df_urban_new['definition'] = df_urban_new['definition'].apply(lambda x: final_clean(x))\n    df_urban_new['sentence'] = df_urban_new['sentence'].apply(lambda x: final_clean(x))\n    print(\"Data shape: \", df_urban_new.shape)\n    print(\"-\"*50)\n\n    print(\"Success!\")","a34758b6":"df_sample = df_urban_new[['word', 'definition', 'sentence']].sample(1)\n\nfor i in df_sample.values:\n    i[1] = re.sub('\\r', ' ', i[1])\n    i[2] = re.sub('\\r', ' ', i[2])\n    print(\"Word: \", i[0])\n    print(\"Meaning: \", i[1])\n    print(\"Sentence: \", i[2])\n    print(\"---\"*20)","e6ac60da":"## Cleaning\n\nThese are the cleaning steps I believe needed to be done based on the data:\n\n- Remove any row with nulls or nans. \u2705\n\n- Replace \\r with single white space in a string. \u2705\n\n- Remove trailing white spaces at the end. \u2705\n\n- Remove word \/ meaning \/ sentence that are empty strings. (None of them have empty strings) \u2705\n\n- Replace all spaces that exist before a period symbol or punctuation at the end. \u2705\n\n- Replace double or more spaces with single space. \u2705\n\n- Remove emojis. \u2705\n\n- Apply transformations based off EDA. \u2705\n\n*I had it as a script so some steps are repetitive.*","d8867f93":"You can choose to remove all the words, definitions and sentences with extreme lengths.","78449b84":"#### By Definition Analysis","0841f446":"## Reading Data","b207b4ed":"#### By Word\/Phrase\/Slang analysis","7c45c07a":"#### By Sentence Analysis","ff35dd56":"## Very Simple EDA\n\n- Number of words per character\n\n- Length of words, meaning, sentence\n\n- Number of characters in word, meaning, sentence\n\n- Frequent special characters used","09c4cb96":"#### New pre-processed data samples"}}