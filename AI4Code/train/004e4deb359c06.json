{"cell_type":{"70dc0cbd":"code","549065b2":"code","888eec7f":"code","e4f2f48a":"code","53bd76d1":"code","f7add67c":"code","b7cf4a64":"code","2edcb81e":"code","f16fa5cb":"code","e05139cb":"code","80b01461":"code","dbd74000":"code","41e48777":"code","5db1a1ff":"code","6d944266":"code","2ced9800":"code","9bf0ee71":"code","43ed55d5":"markdown","d5b50b63":"markdown","0a4a1050":"markdown","146c7871":"markdown","f18c18bc":"markdown","11dee554":"markdown","534f9438":"markdown","1044c526":"markdown","52b61039":"markdown"},"source":{"70dc0cbd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","549065b2":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain.shape, test.shape # check dimensions","888eec7f":"x_train = np.array(train.drop('label', axis = 1)).reshape(-1,28,28,1)\ny_train = np.array(train['label'])\n\nx_test = np.array(test).reshape(-1,28,28,1)","e4f2f48a":"x_train = x_train.astype('float32') \/ 255.0\nx_test = x_test.astype('float32') \/ 255.0","53bd76d1":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimage = x_train[0].reshape((28,28))\nplt.imshow(image)\nplt.gray()","f7add67c":"# importing keras\nfrom keras import backend as K\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Input, Reshape, Conv2DTranspose, BatchNormalization","b7cf4a64":"# building autoencoder and encoder\ninp = Input((28, 28,1))\ne = Conv2D(32, (3, 3), activation='relu')(inp)\ne = MaxPooling2D((2, 2))(e)\ne = Conv2D(64, (3, 3), activation='relu')(e)\ne = MaxPooling2D((2, 2))(e)\ne = Conv2D(64, (3, 3), activation='relu')(e)\nl = Flatten()(e)\nlatent = Dense(49, activation='softmax')(l) #\n\nd = Reshape((7,7,1))(latent)\nd = Conv2DTranspose(64,(3, 3), strides=2, activation='relu', padding='same')(d)\nd = BatchNormalization()(d)\nd = Conv2DTranspose(64,(3, 3), strides=2, activation='relu', padding='same')(d)\nd = BatchNormalization()(d)\nd = Conv2DTranspose(32,(3, 3), activation='relu', padding='same')(d)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(d)\n\n\nencoder = Model(inp, latent)\nautoencoder = Model(inp, decoded)\nautoencoder.summary()","2edcb81e":"autoencoder.compile(optimizer = 'adam', loss = 'mse')","f16fa5cb":"autoencoder.fit(x_train, x_train,\n                epochs=5,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test, x_test))","e05139cb":"image = x_test[3].reshape((28,28))\nplt.imshow(image)\nplt.gray()","80b01461":"decoded_imgs = autoencoder.predict(x_test)","dbd74000":"test_img = decoded_imgs[3].reshape((28,28))\nplt.imshow(test_img)\nplt.gray()","41e48777":"train_vectors = encoder.predict(x_train)\ntest_vectors = encoder.predict(x_test)","5db1a1ff":"from sklearn.svm import SVC\nclf = SVC()\nclf.fit(train_vectors, y_train)","6d944266":"pred = clf.predict(test_vectors)\npred = pd.Series(pred,name=\"Label\")","2ced9800":"submission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),pred],axis = 1)\nsubmission.head()","9bf0ee71":"submission.to_csv('submission.csv', index = False)","43ed55d5":"Now, let's get the latent vectors, which we will use for classification","d5b50b63":"We will build convolutional autoencoder and then predict latent vector for each image from train and test datasets","0a4a1050":"Let's plot some digit","146c7871":"This method gives 0.97592 score on default SVC parametrs, so we can conclude, that the low-dimensional latent vectors are the good representation of original images :)","f18c18bc":"And make submission","11dee554":"Fit the SVM classifier","534f9438":"They are pretty similar :)","1044c526":"First, let's load the dataset","52b61039":"Let's plot the original digit and one, predicted by autoencoder"}}