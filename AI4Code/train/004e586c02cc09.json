{"cell_type":{"5cacef1f":"code","85d239e8":"code","b3657b79":"code","348cddbe":"code","0b32b756":"code","33957cdd":"code","4031a5ef":"code","4f4dfcdd":"code","c89fb8fa":"code","d1058b02":"code","e34ee8fb":"code","94e48531":"code","baf8aeac":"code","54b4c0f6":"code","a08f2a60":"code","9b782fde":"code","5e4f1780":"markdown","d681f6c6":"markdown","48112488":"markdown","db056ce5":"markdown","501920c0":"markdown","654b088b":"markdown","9cb52873":"markdown","f7039dba":"markdown","a4dea83f":"markdown","054021d2":"markdown","3a53d863":"markdown"},"source":{"5cacef1f":"# General imports\nimport numpy as np\nimport pandas as pd\nimport os, sys, gc, warnings, random, datetime\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.gridspec as gridspec\n%matplotlib inline\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split, KFold, GroupKFold\nfrom sklearn.preprocessing import LabelEncoder\n\nimport lightgbm as lgb\nfrom tqdm import tqdm\n\nimport math\nwarnings.filterwarnings('ignore')\n\nos.chdir('\/kaggle\/input\/ieeefewithpreprocessing') # Set working directory\nprint(os.listdir('\/kaggle\/input\/ieeefewithpreprocessing'))","85d239e8":"# Helpers\n\n# Seeder\n# :seed to make all processes deterministic     # type: int\ndef seed_everything(seed=0):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    \n# Memory Reducer\n# :df pandas dataframe to reduce size             # type: pd.DataFrame()\n# :verbose                                        # type: bool\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","b3657b79":"# Data Load\n\ntrain_df = reduce_mem_usage(pd.read_pickle('train_df.pkl'))\ntest_df = reduce_mem_usage(pd.read_pickle('test_df.pkl'))\n\nremove_features = pd.read_pickle('remove_features.pkl')\nremove_features = list(remove_features['features_to_remove'].values)\n\nprint('Load Data')\nprint('Shape control:', train_df.shape, test_df.shape)","348cddbe":"# Vars\nSEED = 42\nseed_everything(SEED)\ntarget = 'isFraud'\nN_SPLITS = 5\nSTART_DATE = datetime.datetime.strptime('2017-11-30', '%Y-%m-%d')","0b32b756":"# Model params\nlgb_params = {\n                    'objective':'binary',\n                    'boosting_type':'gbdt',\n                    'metric':'auc',\n                    'n_jobs':-1,\n                    'learning_rate':0.01,\n                    'num_leaves': 2**8,\n                    'max_depth':-1,\n                    'tree_learner':'serial',\n                    'colsample_bytree': 0.7,\n                    'subsample_freq':1,\n                    'subsample':0.7,\n                    'n_estimators':20000,\n                    'max_bin':255,\n                    'verbose':-1,\n                    'seed': SEED,\n                    'early_stopping_rounds':100, \n                } ","33957cdd":"# Final features list\nfeatures_columns = [col for col in list(train_df) if col not in remove_features]","4031a5ef":"# Model Train\n   \nfolds = KFold(n_splits=N_SPLITS, shuffle=True, random_state=SEED)\n\nX,y = train_df[features_columns], train_df[target]    \nP = test_df[features_columns]  \n\npredictions = np.zeros(len(test_df))\noof = np.zeros(len(train_df))","4f4dfcdd":"del train_df, test_df, features_columns\ngc.collect()","c89fb8fa":"for fold_, (trn_idx, val_idx) in enumerate(folds.split(X, y)):\n    print('Fold:',fold_+1)\n    tr_x, tr_y = X.iloc[trn_idx,:], y[trn_idx]\n    vl_x, vl_y = X.iloc[val_idx,:], y[val_idx]\n            \n    print(len(tr_x),len(vl_x))\n    tr_data = lgb.Dataset(tr_x, label=tr_y)\n    vl_data = lgb.Dataset(vl_x, label=vl_y)  \n\n    estimator = lgb.train(\n        lgb_params,\n        tr_data,\n        valid_sets = [tr_data, vl_data],\n        verbose_eval = 1000,\n    )   \n        \n    pp_p = estimator.predict(P)\n    predictions += pp_p\/N_SPLITS\n        \n    oof_preds = estimator.predict(vl_x)\n    oof[val_idx] = (oof_preds - oof_preds.min())\/(oof_preds.max() - oof_preds.min())\n        \n    del tr_x, tr_y, vl_x, vl_y, tr_data, vl_data\n    gc.collect()","d1058b02":"print('OOF AUC:', metrics.roc_auc_score(y, oof))","e34ee8fb":"print(metrics.confusion_matrix(y, oof.round()))","94e48531":"print(metrics.classification_report(y, oof.round()))","baf8aeac":"feature_imp = pd.DataFrame(sorted(zip(estimator.feature_importance(),X.columns)), columns=['Value','Feature'])\nplt.figure(figsize=(20, 10))\nsns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", ascending=False).iloc[:50])\nplt.title('LGBM with cross validation Most Important Features')\nplt.tight_layout()\nplt.show()","54b4c0f6":"submission = pd.read_csv('sample_submission.csv', index_col='TransactionID')\nsubmission.isFraud = predictions\nsubmission.head()","a08f2a60":"plt.hist(submission.isFraud,bins=100)\nplt.ylim((0,5000))\nplt.title('LGBM with cross validation submission')\nplt.show()","9b782fde":"submission.to_csv('\/kaggle\/working\/lgbm_cv_submission.csv')","5e4f1780":"# <a style=\"color:#6699ff\"> I. Reduce Memory Usage for Big Data<\/a>","d681f6c6":"**Feature importance for LGBM with cross validation**","48112488":"# <a style=\"color:#6699ff\"> III. Run LGBM Classifier with Cross Validation<\/a>","db056ce5":"<h1 align=\"center\" style=\"color:#6699ff\"> DataCamp IEEE Fraud Detection <\/h1>","501920c0":"**Eleventh submission for LGBM with cross validation**","654b088b":"<img src=\"https:\/\/github.com\/DataCampM2DSSAF\/suivi-du-data-camp-equipe-tchouacheu-niang-chokki\/blob\/master\/img\/credit-card-fraud-detection.png?raw=true\" width=\"800\" align=\"center\">","9cb52873":"## LGBM classifier with cross validation","f7039dba":"**Import package**","a4dea83f":"# <a style=\"color:#6699ff\"> II. Load Data<\/a>","054021d2":"# <a style=\"color:#6699ff\">  Table of Contents<\/a> \n\n<a style=\"color:#6699ff\"> I. Reduce Memory Usage for Big Data<\/a>\n\n<a style=\"color:#6699ff\"> II. Load Data<\/a>\n\n<a style=\"color:#6699ff\"> III. Run LGBM Classifier with Cross Validation<\/a>","3a53d863":"#  <a style=\"color:#6699ff\"> Team <\/a>\n- <a style=\"color:#6699ff\">Mohamed NIANG <\/a>\n- <a style=\"color:#6699ff\">Fernanda Tchouacheu <\/a>\n- <a style=\"color:#6699ff\">Hypolite Chokki <\/a>"}}