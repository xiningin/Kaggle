{"cell_type":{"486b3f00":"code","8c71b19d":"code","f081334a":"code","c24f012f":"code","e8d4f2ee":"code","e85cb469":"code","827cf5b3":"code","443c4c0f":"code","95003723":"code","a36ae32e":"code","4ac21444":"code","3841f984":"code","5fa1b867":"code","bbbd3a6c":"code","cf515e94":"code","8bba11c6":"code","9652728f":"code","329e050d":"code","bcf96e81":"code","56c0946b":"code","eb245552":"code","94aee4f4":"code","9dc59c7f":"code","41d328fa":"code","7037e6ea":"code","3149a73a":"code","f4608408":"code","d3fc4535":"code","1de18ccc":"code","36e3a96c":"markdown","a4c2c53d":"markdown","f3a3e3ea":"markdown","4d7bffd4":"markdown","6a02ba1c":"markdown","4c59c180":"markdown","d149a36d":"markdown","4d5604d8":"markdown","d5e6b81e":"markdown","45e8f0cf":"markdown","b389c56e":"markdown","a44cffa1":"markdown"},"source":{"486b3f00":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nimport missingno as msno\n\n# Let's be rebels and ignore warnings for now\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, label_binarize\n\n# Machine learning\nimport catboost\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import model_selection, tree, preprocessing, metrics, linear_model\nfrom sklearn.svm import LinearSVC\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier, Pool, cv\n\n\npd.set_option('display.max_rows',None)\npd.set_option('display.max_columns',None)","8c71b19d":"train=pd.read_csv('..\/input\/forest-cover-type-prediction\/train.csv')\ntest=pd.read_csv('..\/input\/forest-cover-type-prediction\/test.csv')\ntest1=pd.read_csv('..\/input\/forest-cover-type-prediction\/test3.csv')\nsubmission=pd.read_csv('..\/input\/forest-cover-type-prediction\/sampleSubmission.csv')","f081334a":"train.head()","c24f012f":"train.describe()","e8d4f2ee":"# By the Below figure we can understand that there are no Null Values\nfig=plt.figure(figsize=(20,5))\nsns.heatmap(train.isna())\nplt.show()","e85cb469":"# Need to figure out the difference between test and test1\nprint(train.shape)\nprint(test.shape)\nprint(test1.shape)","827cf5b3":"test1.head()","443c4c0f":"numerical_features=[feature for feature in train.columns if train[feature].dtype!='O' and 'Soil' not in feature and 'Wilderness' not in feature]\n# All are numerical variables\nprint(numerical_features) \nprint(len(numerical_features))\nprint(train.shape)","95003723":"train.drop('Id',axis=1,inplace=True)\nnumerical_features=numerical_features[1:]","a36ae32e":"fig=plt.figure(figsize=(20,5))\nsns.heatmap(train[numerical_features].corr(),annot=True)\nplt.show()","4ac21444":"# Feature Distribution of the training data set.\ni=0\nfig=plt.figure(figsize=(20,20))\nfor feature in numerical_features:\n    i+=1\n    plt.subplot(5, 3, i)\n    sns.distplot(train[feature])\nplt.show()\n    \n    ","3841f984":"train.skew()","5fa1b867":"train.kurtosis()","bbbd3a6c":"def fit_ml_algo(algo,x_train,y_train,cv):\n    \n    model=algo.fit(x_train,y_train)\n    \n    acc=round(model.score(x_train,y_train)*100,2)\n    \n    train_pred = model_selection.cross_val_predict(algo,x_train,y_train,cv=cv,n_jobs=-1)\n    \n    acc_cv=round(metrics.accuracy_score(y_train,train_pred)*100,2)\n    \n    return(train_pred, acc, acc_cv)","cf515e94":"x_train.head()","8bba11c6":"y_train=train['Cover_Type']\nx_train.drop(columns=['Cover_Type'],axis=1,inplace=True)","9652728f":"x_train=train[numerical_features]\nx_train.drop(columns=['Cover_Type'],axis=1,inplace=True)","329e050d":"x_train.head()","bcf96e81":"train_pred_log, acc_log, acc_cv_log =  fit_ml_algo( LogisticRegression(), x_train, y_train, 10)\n\nprint(\"Accuracy: \"+str(acc_log))\n\nprint(\"Accuracy CV 10-Fold: \"+str(acc_cv_log))","56c0946b":"train_pred_knn, acc_knn, acc_cv_knn =  fit_ml_algo( KNeighborsClassifier(), x_train, y_train, 10)\n\nprint(\"Accuracy: \"+str(acc_knn))\n\nprint(\"Accuracy CV 10-Fold: \"+str(acc_cv_knn))","eb245552":"train_pred_nb, acc_nb, acc_cv_nb =  fit_ml_algo( GaussianNB(), x_train, y_train, 10)\n\nprint(\"Accuracy: \"+str(acc_nb))\n\nprint(\"Accuracy CV 10-Fold: \"+str(acc_cv_nb))","94aee4f4":"train_pred_svc, acc_svc, acc_cv_svc =  fit_ml_algo( LinearSVC(), x_train, y_train, 10)\n\nprint(\"Accuracy: \"+str(acc_svc))\n\nprint(\"Accuracy CV 10-Fold: \"+str(acc_cv_svc))","9dc59c7f":"train_pred_sgd, acc_sgd, acc_cv_sgd=fit_ml_algo(SGDClassifier(),x_train,y_train,10)\n\nprint('Accuracy: '+str(acc_sgd))\n\nprint('Accuracy CV 10-Fold: '+str(acc_cv_sgd))","41d328fa":"train_pred_dt, acc_dt, acc_cv_dt=fit_ml_algo(DecisionTreeClassifier(),x_train,y_train,10)\n\nprint('Accuracy: '+str(acc_dt))\n\nprint('Accuracy CV 10-Fold: '+str(acc_cv_dt))","7037e6ea":"train_pred_gbt, acc_gbt, acc_cv_gbt=fit_ml_algo(GradientBoostingClassifier(),x_train,y_train,10)\n\nprint('Accuracy: '+str(acc_gbt))\n\nprint('Accuracy CV 10-Fold: '+str(acc_cv_gbt))","3149a73a":"numerical_features.remove('Cover_Type')\ntest[numerical_features].head()","f4608408":"gb_clf2 = GradientBoostingClassifier(n_estimators=20, learning_rate=0.5, max_features=2, max_depth=2, random_state=0)\ngb_clf2.fit(x_train, y_train)\npredictions = gb_clf2.predict(test[numerical_features])\npredictions","d3fc4535":"submission = pd.DataFrame()\nsubmission['Id'] = test['Id']\nsubmission['Cover_Type'] = predictions # our model predictions on the test dataset\nsubmission.head()","1de18ccc":"submission.to_csv('submission1.csv', index=False)","36e3a96c":"## All numerical Variables","a4c2c53d":"## Decision Tree Classifier","f3a3e3ea":"## Logistic Regression","4d7bffd4":"### Distribution Of Numerical Features","6a02ba1c":"## Stochastic Gradient Descent","4c59c180":"# Data Analysis\n\n1. Missing Values (There are no missing values)\n2. All The Numerical Variables\n3. Distribution of the Numerical Variables\n4. Categorical Variables\n5. Cardinality of Categorical Variables\n6. Outliers\n7. Relationship between independent and dependent feature(Cover_Type)","d149a36d":"## Gradient Boost Trees","4d5604d8":"## Linear Support Vector Machine ","d5e6b81e":"### Relationship between features and Cover_Type","45e8f0cf":"## KNN","b389c56e":"## Missing Values (There are no missing Values)","a44cffa1":"## Gaussian Naive Bayes"}}