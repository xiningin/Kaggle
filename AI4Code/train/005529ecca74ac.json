{"cell_type":{"0a124a47":"code","c6c80502":"code","6c7db4c0":"code","bd1366fd":"code","228472f4":"code","c5c9329e":"code","31301c69":"code","73abb994":"code","d9f8abce":"markdown","1f0ac59b":"markdown"},"source":{"0a124a47":"from IPython.display import clear_output\n\n!pip install https:\/\/github.com\/pandas-profiling\/pandas-profiling\/archive\/master.zip\n\nclear_output()","c6c80502":"import pandas as pd\nimport numpy as np\nimport warnings\nfrom pandas_profiling import ProfileReport\nfrom collections import Counter\nfrom xgboost import XGBClassifier\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, classification_report\nfrom imblearn.over_sampling import SMOTE\n\nwarnings.filterwarnings(\"ignore\")","6c7db4c0":"df = pd.read_csv('..\/input\/diabetes-health-indicators-dataset\/diabetes_012_health_indicators_BRFSS2015.csv')\n\nprofile = ProfileReport(df, title='Diabetes Health Indicators Dataset Profiling Report')\nprofile.to_notebook_iframe()","bd1366fd":"#Data pre-processing\nnum_attribs = ['BMI', 'MentHlth', 'PhysHlth']\n\ncat_attribs = list(df.columns[~df.columns.isin(['BMI', 'MentHlth', 'AnyHealthcare',\n                                                'PhysHlth', 'Diabetes_012'])])\n\ndf[cat_attribs] = df[cat_attribs].astype('category')\ndf.Diabetes_012 = df.Diabetes_012.astype('int')\n\n#Normalize continuous variables\nfor num in num_attribs: \n    df[num] = (df[num] - df[num].min()) \/ (df[num].max() - df[num].min()) \n\nlabel_map = {0:0, 1:1, 2:1}\n\ndf['Diabetes_012'] = df['Diabetes_012'].map(label_map)\n\ny = df.Diabetes_012\n\nattribs = df[num_attribs + cat_attribs]\n\nX = pd.get_dummies(attribs, drop_first=True)\n\n#Data Split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, stratify=y, random_state=33)\n\neval_set = [(X_val, y_val)]\n\n# summarize the class distribution of the training dataset\ncounter = Counter(y_train)\nprint(counter)","228472f4":"# transform the training dataset\noversample = SMOTE(random_state=33)\nX_train, y_train = oversample.fit_resample(X_train, y_train)\n\n# summarize the new class distribution of the training dataset\ncounter = Counter(y_train)\nprint(counter)","c5c9329e":"params = {\n    'objective': 'binary:logistic',\n    'tree_method':'gpu_hist',\n    'n_estimators': 400,\n    'max_depth': 4,\n    'learning_rate': 0.2,\n    'reg_alpha': 0.5,\n    'subsample': 0.5,\n    'colsample_bytree': 0.8,\n    'random_state': 33,\n    'use_label_encoder':False\n        }\n\nxgb = (\n    XGBClassifier(**params)\n    .fit(X_train, y_train, \n         eval_set=eval_set, \n         eval_metric='error', \n         verbose=False,\n         early_stopping_rounds=10)\n)\n\nprint('Model name: XGBoost Classifier')\nprint('Accuracy: ', '{}%'.format(round((accuracy_score(y_val, xgb.predict(X_val)) * 100), 2)))","31301c69":"#Classification Report\nprint(classification_report(y_val, xgb.predict(X_val), target_names=['no_diabetes', 'prediabetes_or_diabetes']))","73abb994":"#Feature Importances Analysis\ntable = pd.DataFrame(list(zip(X.columns,xgb.feature_importances_)), \n                                      columns=['Feature', 'Importance (%)'])\n\ntable['Importance (%)'] = (table['Importance (%)']\n                           .apply(lambda row: round((row * 100),2)))\n\ndef condense(row): return row.split('_')[0]\n\ntable['Feature'] = table['Feature'].apply(lambda row: condense(row))\n\ntable.groupby(['Feature'], as_index=False).sum().sort_values(by=['Importance (%)'], ascending=False)","d9f8abce":"**Notes:**\n* Based on the above profiling report health care coverage is weakly correlated to diabetes thus will be excluded from the model features. \n* All model features are categorical except Body Mass Index (BMI), Mental Health (MENTHLTH) and Physical Health (PHYSHLTH).","1f0ac59b":"**Note:** Target class has an uneven distribution of observations (imbalanced data)."}}