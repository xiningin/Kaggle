{"cell_type":{"229edbd1":"code","3063147e":"code","d60d3a5a":"code","6065659c":"code","9a3846c5":"code","d49fc3d9":"code","1e87c909":"code","ca851498":"markdown","35ec0cde":"markdown","5f6df0b6":"markdown","38a769c5":"markdown","0caf3c5d":"markdown","5fcd0218":"markdown","9f53b404":"markdown","4dc6ac50":"markdown"},"source":{"229edbd1":"import cv2\nfrom itertools import zip_longest\nimport json\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport pandas as pd\nfrom pathlib import Path\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam\nfrom torch.utils.data import Dataset, DataLoader","3063147e":"RUN_EVALUATION = False\nDO_PLOT = True\nNUM_ITERS = 20\nN_EPOCHS = 300\nEMBEDDING_DIM = 128\nLR = 0.003\nEPSILON = 0.01\nROT_AUG = False\nFLIP_AUG = False\nIO_CONSISTENCY_CHECK = True\nTESTTIME_FLIP_AUG = False\nBACKGROUND = 0\n\nBASIC_PATH = Path('..\/input\/abstraction-and-reasoning-challenge\/')\nSUBMISSION_PATH = Path('..\/input\/abstraction-and-reasoning-challenge\/')\n\nTRAIN_PATH = BASIC_PATH \/ 'training'\nEVAL_PATH = BASIC_PATH \/ 'evaluation'\nTEST_PATH = BASIC_PATH \/ 'test'\nSAMPLE_SUBMISSION_PATH = SUBMISSION_PATH \/ 'sample_submission.csv'\nSUBMISSION_PATH = 'submission.csv'\n\nif RUN_EVALUATION:\n    train_task_files = sorted(os.listdir(TRAIN_PATH))\n    train_tasks = []\n    for task_file in train_task_files:\n        with open(str(TRAIN_PATH \/ task_file), 'r') as f:\n            task = json.load(f)\n            train_tasks.append(task)\n\n    eval_task_files = sorted(os.listdir(EVAL_PATH))\n    eval_tasks = []\n    for task_file in eval_task_files:\n        with open(str(EVAL_PATH \/ task_file), 'r') as f:\n            task = json.load(f)\n            eval_tasks.append(task)\n    eval_tasks = eval_tasks[:100]\n\ntest_task_files = sorted(os.listdir(TEST_PATH))\ntest_tasks = []\nfor task_file in test_task_files:\n    with open(str(TEST_PATH \/ task_file), 'r') as f:\n        task = json.load(f)\n        test_tasks.append(task)","d60d3a5a":"cmap = colors.ListedColormap(\n    ['#000000', '#0074D9', '#FF4136', '#2ECC40', '#FFDC00',\n     '#AAAAAA', '#F012BE', '#FF851B', '#7FDBFF', '#870C25'])\ncnorm = colors.Normalize(vmin=0, vmax=9)\n\ndef flattener(pred):\n    str_pred = str([row for row in pred])\n    str_pred = str_pred.replace(', ', '')\n    str_pred = str_pred.replace('[[', '|')\n    str_pred = str_pred.replace('][', '|')\n    str_pred = str_pred.replace(']]', '|')\n    return str_pred\n\ndef make_one_hot(labels, C=2):\n    one_hot = torch.Tensor(labels.size(0), C, labels.size(2), labels.size(3)).zero_().float().to(labels.device)\n    target = one_hot.scatter_(1, labels.data, 1)\n    return target\n\ndef img2tensor(img):\n    correct_img = img.copy() # do this because of the occasional neagtive strides in the numpy array\n    return torch.tensor(correct_img, dtype=torch.long)[None,None,:,:]\n\ndef resize(images, size):\n    if images.shape[2:] == size:\n        return images\n\n    new_images = []\n    for i in range(images.shape[0]):\n        image = images[i,0,:,:].cpu().numpy()\n        image = cv2.resize(image, size[::-1], interpolation=cv2.INTER_NEAREST)\n        image = img2tensor(image)\n        new_images.append(image)\n    return torch.cat(new_images)\n\ndef collate(batch):\n    tensors = list(zip(*batch))\n    batch = (torch.cat(t) for t in tensors)\n    return batch\n\ndef rot_aug(task):\n    rotated_datasets = []\n    for tt in task['train']:\n        for k in range(1,4):\n            it = np.rot90(np.array(tt['input']), k).tolist()\n            ot = np.rot90(np.array(tt['output']), k).tolist()\n            rotated_datasets.append({'input': it, 'output': ot})\n    \n    task['train'].extend(rotated_datasets)\n    return task\n\ndef check_consistency(task):\n    cons_colors = [True] * 10\n    for tt in task['train']:\n        inp = np.array(tt['input'])\n        out = np.array(tt['output'])\n        if inp.shape[0] != out.shape[0] or inp.shape[1] != out.shape[1]:\n            return False, False\n        for i in range(10):\n            if np.any(out[inp==i] != i):\n                cons_colors[i] = False\n    return cons_colors\n\ndef copy_bg_fg(pred, input, colors):\n    for i in range(len(colors)):\n        if colors[i]:\n            pred[input==i] = i\n    \n    return pred\n\ndef visualize_results_transformer(states, in_states, labels=[]):\n    if DO_PLOT:\n        out_states = states.detach()\n        if len(states.shape) == 4:\n            out_states = out_states[:,:10,:,:]\n            out_states = torch.argmax(out_states, dim=1)\n        in_states = in_states[:,:10,:,:]\n\n        n_rows = 2 if labels == [] else 3\n        fig, axes = plt.subplots(n_rows, len(states), squeeze=False)\n        for c, zi in enumerate(zip_longest(out_states, in_states, labels)):\n            o, i, l = zi\n            viz_in_sample = torch.argmax(i, dim=0).cpu()\n            axes[0,c].imshow(o.cpu(), cmap=cmap, norm=cnorm)\n            axes[1,c].imshow(viz_in_sample, cmap=cmap, norm=cnorm)\n            if n_rows > 2:\n                axes[2,c].imshow(l.cpu(), cmap=cmap, norm=cnorm)\n        plt.show()","6065659c":"output_size = None # this is used to store the most likely output size of the test dataset\nclass ARCDataset(Dataset):\n    def __init__(self, task, mode='train'):\n        '''We use GA predictions also to predict the shape of the output'''\n        self.task = task\n        self.mode = mode\n\n    def __len__(self):\n        if self.mode == 'train':\n            return len(self.task['train'])\n        else:\n            return len(self.task['test'])\n    \n    def __getitem__(self, idx):\n        global output_size\n        if self.mode == 'train':\n            in_out = [(self.task['train'][idx]['input'], self.task['train'][idx]['output'])]\n        elif self.mode == 'eval':\n            in_out = [(self.task['test'][idx]['input'], self.task['test'][idx]['output'])]\n        else:\n            in_out = [(self.task['test'][idx]['input'], [])]\n\n        image = torch.cat([img2tensor(img[0]) for img in in_out])\n\n        if self.mode == 'train' or self.mode == 'eval':\n            label = torch.cat([img2tensor(img[1]) for img in in_out])\n\n            # save size to use it for test set\n            if self.mode == 'train':\n                output_size = label.shape[2:]\n\n            if FLIP_AUG: # flip augmentation\n                label_fh = label.clone().flip(2)\n                label_fv = label.clone().flip(3)\n                label = torch.cat([label, label_fh, label_fv], dim=0)\n\n        else:\n            n_labels = 3*image.shape[0] if FLIP_AUG else image.shape[0]\n            label = torch.tensor([]).view(1,1,1,-1) # no label for testing\n            label = label.expand((n_labels,-1,-1,-1))\n\n        image = resize(image, size=output_size)\n\n        if FLIP_AUG: # flip augmentation\n            image_fh = image.clone().flip(2)\n            image_fv = image.clone().flip(3)\n            image = torch.cat([image, image_fh, image_fv], dim=0)\n\n        image = make_one_hot(image, C=10).float()\n\n        label = label.squeeze(1)\n        return image.cuda(), label.cuda()\n\n\nclass CAModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n\n        # embedding calculated from input\n        self.embed_in = nn.ModuleList([nn.Conv2d(10, EMBEDDING_DIM, 3, padding=1) for _ in range(3)])\n\n        self.embed_out = nn.ModuleList([nn.Conv2d(EMBEDDING_DIM, 10, 1) for _ in range(3)])\n        for i in range(3):\n            nn.init.constant_(self.embed_out[i].weight, 0.0)\n            nn.init.constant_(self.embed_out[i].bias, 0.0)\n\n        self.dropout = nn.Dropout2d(p=0.1)\n        self.norm1 = nn.InstanceNorm2d(EMBEDDING_DIM)\n\n        self.squeeze = nn.AdaptiveAvgPool2d(1)\n        self.excite = nn.Conv2d(EMBEDDING_DIM, EMBEDDING_DIM, 1)\n\n    def forward(self, state_grid, n_iters):\n        color_grid = state_grid[:,:10,:,:]\n        for it in range(n_iters): # iterate for random number of iterations\n            update_grid = self.embed_in[0](color_grid)\n            update_grid = F.relu(update_grid)\n            if update_grid.shape[2] > 1 or update_grid.shape[3] > 1:\n                update_grid = self.norm1(update_grid)\n            update_grid = self.dropout(update_grid)\n\n            # SENet\n            squeezed = self.squeeze(update_grid)\n            squeezed = self.excite(squeezed)\n            squeezed = torch.sigmoid(squeezed)\n\n            update_grid = update_grid * squeezed\n\n            update_grid = self.embed_out[0](update_grid)\n            update_grid = self.dropout(update_grid)\n\n            color_grid = color_grid + update_grid\n\n        return color_grid","9a3846c5":"def train_task_st(task, test_if_solved=False):\n    if IO_CONSISTENCY_CHECK: # we check if the background or foreground stays the same in input and target\n        cons_colors = check_consistency(task)\n\n    if ROT_AUG: # perform rotation augmentation; for each training dataset, rotate it by 90 degrees\n        task = rot_aug(task)\n\n    train_set = ARCDataset(task, mode='train')\n    train_loader = DataLoader(train_set, batch_size=1, num_workers=0, collate_fn=collate)\n\n    test_mode = 'eval' if test_if_solved else 'test'\n    test_set = ARCDataset(task, mode=test_mode)\n    test_loader = DataLoader(test_set, batch_size=1, num_workers=0, collate_fn=collate)\n\n    model = CAModel().cuda()\n\n    print('Training...')\n    model.train()\n    optimizer = Adam(model.parameters(), lr=LR)\n    loss_fn = nn.CrossEntropyLoss()\n\n    for epoch in range(N_EPOCHS):\n        for i, train_batch in enumerate(train_loader):\n            in_states, labels = train_batch\n\n            optimizer.zero_grad()\n\n            states = in_states.clone().detach()\n            states = model(states, NUM_ITERS)\n            total_loss = loss_fn(states, labels)\n\n            # predict output from output to improve stability\n            labels_oh = make_one_hot(labels.unsqueeze(1), C=10)\n            labels_oh = model(labels_oh, NUM_ITERS)\n            stability_loss = loss_fn(labels_oh, labels)\n            total_loss += 2 * stability_loss\n\n            total_loss.backward()\n            optimizer.step()\n\n        if (epoch+1) % 100 == 0:\n            print(\"Epoch: {0}: Loss: {1:3f}\".format(epoch, total_loss.cpu().item()))\n\n        if (epoch+1) % N_EPOCHS == 0:\n            visualize_results_transformer(states[:10], in_states[:10], labels[:10])\n\n\n    print('Testing...')\n    is_solved = True\n    output_samples = []\n\n    model.eval()\n    for test_batch in test_loader:\n        in_states, labels = test_batch\n        label = labels[0]\n\n        states = in_states.clone()\n        states = model(states, NUM_ITERS)\n\n        if TESTTIME_FLIP_AUG: # revert augmentations\n            states[1] = states[1].flip(1)\n            states[2] = states[2].flip(2)\n            out_state = torch.mean(states[:,:10,:,:], dim=0)\n        else:\n            out_state = states[0,:10,:,:]\n        \n        in_state = in_states[0,:10,:,:]\n        out_state_am = torch.argmax(out_state, dim=0)\n\n        if IO_CONSISTENCY_CHECK:\n            out_state_am = copy_bg_fg(out_state_am, torch.argmax(in_state, dim=0), cons_colors)\n\n        visualize_results_transformer(out_state_am.unsqueeze(0), in_state.unsqueeze(0))\n        if test_if_solved and not torch.equal(label, out_state_am):\n            is_solved = False\n        \n        output_samples.append(out_state_am.cpu().tolist())\n\n    return output_samples, is_solved","d49fc3d9":"if RUN_EVALUATION:\n    # make predictions on training set\n    #n_solved = 0\n    #for idx, task in enumerate(train_tasks):\n    #    print(\"TRAIN TASK \" + str(idx + 1))\n    #    is_solved = False\n    #    _, is_solved = train_task_st(task, test_if_solved=True)\n\n    #    if is_solved:\n    #        print('Solved training task {0}'.format(idx+1))\n    #    n_solved += int(is_solved)\n\n    #print('Solved {0} training tasks'.format(n_solved))\n\n    # make predictions on evaluation set\n    n_solved = 0\n    for idx, task in enumerate(eval_tasks):\n        print(\"EVAL TASK \" + str(idx + 1))\n        is_solved = False\n        _, is_solved = train_task_st(task, test_if_solved=True)\n\n        if is_solved:\n            print('Solved evaluation task {0}'.format(idx+1))\n        n_solved += int(is_solved)\n\n    print('Solved {0} evaluation tasks'.format(n_solved))","1e87c909":"if not RUN_EVALUATION:\n    # make predictions on test set\n    test_predictions = []\n    for idx, task in enumerate(test_tasks):\n        print(\"TASK \" + str(idx + 1))\n        test_predictions.extend(train_task_st(task)[0])\n        \n    # Make submission\n    str_test_predictions = []\n    for idx, pred in enumerate(test_predictions):\n        pred = flattener(pred)\n        str_test_predictions.append(pred)\n        \n    sample_sub = pd.read_csv(SAMPLE_SUBMISSION_PATH, index_col='output_id')\n    sample_sub[\"output\"] = str_test_predictions\n\n    sample_sub.to_csv('submission.csv')","ca851498":"# Helpers","35ec0cde":"# Basic setup","5f6df0b6":"# Dataset and model","38a769c5":"# Run training-testing loop on test files","0caf3c5d":"# Training loop function","5fcd0218":"# Run training-testing loop on training and evaluation files","9f53b404":"# Introduction\n\nGiven the idea of (neural and continuous) cellular automatons seems to have generated a lot of interest in this challenge, I decided to try and see how far we could push it. I created a rather simple neural network using 10 recurrent iterations and some hidden layers. The main ideas of the network include:\n* resizing the input to the expected output size (the expected output size is calculated from the training data,\n* using Squeeze-and-Excitation networks (https:\/\/arxiv.org\/abs\/1709.01507) to capture global properties,\n* using a stability loss to encourage the network to stop evolving on the correct solution,\n* using dropout to encourage generalization,\n* using instance normalization to improve training (this probably had the biggest impact),\n* initializing the output layer of the network to all zeros (to emphasize the fact that we just want to make small changes to the image grid at every step.\n\nUsing these ideas, I was able to solve:\n* 195\/400 training problems.\n* 145\/400 evaluation problems.\n* 0\/100 LB problems.\n\nWhile I can definitely imagine some people getting better results using deep learning, I would expect that you need far more sophistication to at least solve 10 LB examples. I have the feeling that the network struggles especially hard on problems which involve different shapes during training and testing (I expect most LB problems to exhibit this behavior).","4dc6ac50":"# Includes"}}