{"cell_type":{"2e9909e4":"code","a84ed96b":"code","cd004307":"code","c3dcf20e":"code","5cc99107":"code","6bc80b83":"code","7a5303b3":"code","197ddc2b":"code","20ea6fb6":"code","27c954b4":"code","0e461a84":"code","881b7969":"code","aa5dc6e2":"code","8545776d":"code","63581501":"code","0d5de86f":"code","e2fabfe1":"code","5cc39a7f":"code","0b14dca3":"code","344eb41b":"markdown","2802d281":"markdown","1e938386":"markdown","87cefeba":"markdown","ed79fb00":"markdown","7ab90af5":"markdown","b8e63060":"markdown","05a97273":"markdown","272df5ca":"markdown","04f553cf":"markdown","9b88a3d0":"markdown","9b762e02":"markdown","9441b327":"markdown","578093d0":"markdown","53dcdf8e":"markdown","20c31221":"markdown"},"source":{"2e9909e4":"# dependencies\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nimport tensorflow as tf","a84ed96b":"# where the data is located\ndata_dir = '..\/input\/garbage-classification\/Garbage classification\/Garbage classification\/'","cd004307":"# review number of files and directories in the dataset\ntotal_dir = len(os.listdir(data_dir))\ntotal_files = 0\n\nfor dirname, _, filenames in os.walk(data_dir):\n    print('counting:', dirname)\n    files_counter = 0\n    for file in filenames:\n        files_counter += 1\n    total_files += files_counter\n    print('total files in dir:', files_counter)\n\nprint('--------')\nprint('total number of files',total_files)\nprint('total number of directories',total_dir)","c3dcf20e":"# create datasets\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.2,\n    subset='training',\n    seed=100\n)\n\nvalidation_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    validation_split=0.2,\n    subset='validation',\n    seed=100\n)","5cc99107":"# get class names\nclass_names = train_ds.class_names\nprint(class_names)","6bc80b83":"# view some images from the train_ds\nplt.figure(figsize=(16, 16))\nfor images, labels in train_ds.take(1):\n    for i in range(12):\n        ax = plt.subplot(4, 4, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","7a5303b3":"# view some images from the validation_ds\nplt.figure(figsize=(16, 16))\nfor images, labels in validation_ds.take(1):\n    for i in range(12):\n        ax = plt.subplot(4, 4, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(class_names[labels[i]])\n        plt.axis(\"off\")","197ddc2b":"# inspect the train_ds\ntrain_batch = train_ds.as_numpy_iterator().next()\n\nprint('total of batches:',len(train_ds))\nprint('images batch shape:',train_batch[0].shape)\nprint('labels batch shape:',train_batch[1].shape)","20ea6fb6":"# inspect the validation_ds\nvalidation_batch = validation_ds.as_numpy_iterator().next()\n\nprint('total of batches:',len(validation_ds))\nprint('images batch shape:',validation_batch[0].shape)\nprint('labels batch shape:',validation_batch[1].shape)","27c954b4":"# instantiate the base model\ninput_shape = (256,256,3)\nbase_model = tf.keras.applications.ResNet50V2(include_top=False, input_shape=input_shape)\n\n# make the layers of the model trainable to fine-tunning\nbase_model.trainable = True","0e461a84":"# review the base model architecture\nbase_model.summary()","881b7969":"# find the tunning layer and its index\ntuning_layer_name = 'conv5_block1_preact_bn'\ntuning_layer = base_model.get_layer(tuning_layer_name)\ntuning_index = base_model.layers.index(tuning_layer)\n\n# freeze all the layers before the tuning layer\nfor layer in base_model.layers[:tuning_index]:\n    layer.trainable =  False","aa5dc6e2":"# create a data augmentation stage with horizontal and vertical flipping, rotations and zooms\ndata_augmentation = tf.keras.Sequential([\n    tf.keras.layers.experimental.preprocessing.Rescaling(1.\/127.5, offset= -1), \n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n    tf.keras.layers.experimental.preprocessing.RandomRotation(0.2),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(0.2)\n], name='data_augmentation')","8545776d":"# create the neural network architecture\nmodel = tf.keras.Sequential([\n    data_augmentation,\n    base_model,\n    tf.keras.layers.GlobalAveragePooling2D(),\n    tf.keras.layers.Dense(6, activation='softmax')\n])\n\nlearning_rate = 0.00001\nmodel.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer=tf.keras.optimizers.Adam(lr=learning_rate),\n    metrics=['accuracy']\n)","63581501":"# train the model\nhistory = model.fit(\n    train_ds,\n    validation_data=validation_ds,\n    epochs=15\n)","0d5de86f":"# visualize the training history\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# plot accuracy\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy')\n\n# plot loss\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss')\nplt.xlabel('epoch')\nplt.show()","e2fabfe1":"# verify the performance of the model\nloss, accuracy = model.evaluate(validation_ds)\nprint('Test accuracy :', accuracy)\nprint('Test loss:', loss)","5cc39a7f":"# get a batch from validation_ds to do some inference\nimage_batch, label_batch = validation_ds.as_numpy_iterator().next()\n\n# inference\ninference = model.predict_on_batch(image_batch)\n\n# show imgs and labels\nplt.figure(figsize=(18, 18))\nfor i in range(12):\n    ax = plt.subplot(4, 4, i + 1)\n    plt.imshow(image_batch[i].astype(\"uint8\"))\n    plt.title('Inference:{}, {:.2f}% Confidence\\nReal Label:{}'\n              .format(class_names[np.argmax(inference[i])], 100 * np.max(inference[i]), class_names[label_batch[i]]))\n    plt.axis(\"off\")","0b14dca3":"# define some urls for testing with the respective labels\ntest_urls = [\n    'https:\/\/uploads.ifdesign.de\/award_img_121\/oex_large\/31983_01_4078_basket.jpg',\n    'https:\/\/www.antique-bottles.net\/attachments\/image-jpg.201847\/',\n    'https:\/\/inzanetimes.files.wordpress.com\/2013\/04\/canterbury41313016.jpg',\n    'https:\/\/live.staticflickr.com\/66\/167934943_f61a850d96_b.jpg',\n    'https:\/\/cdnimg.webstaurantstore.com\/images\/products\/large\/407128\/1501927.jpg',\n    'https:\/\/dy6g3i6a1660s.cloudfront.net\/6n3yAQDV3zPhUIdvbTC-uwPUAoo\/orig.jpg'\n]\ntest_labels = [3, 1, 2, 4, 0, 5]\n\n# create a test dataset\ntest_ds = []\nimage_size = (256, 256)\nfor i in range(len(test_urls)):\n    path = tf.keras.utils.get_file(str(i), origin=test_urls[i])\n    img = tf.keras.preprocessing.image.load_img(path, target_size=image_size)\n    test_ds.append(tf.keras.preprocessing.image.img_to_array(img))\ntest_ds = np.array(test_ds)\n\n# inference\ntest_inference = model.predict_on_batch(test_ds)\n\n# show imgs and labels\nplt.figure(figsize=(16, 16))\nfor i in range(6):\n    ax = plt.subplot(3, 3, i + 1)\n    plt.imshow(test_ds[i].astype(\"uint8\"))\n    plt.title('Inference:{}, {:.2f}% Confidence\\nReal Label:{}'\n              .format(class_names[np.argmax(test_inference[i])], 100 * np.max(test_inference[i]), class_names[test_labels[i]]))\n    plt.axis(\"off\")","344eb41b":"## **Conclusion**\n* The model reaches approx 90% of accuracy.\n* Data Augmentation and Transfer Learning were used to increase the data and improve the features used to train the model.\n* The model is a bit overfitted in the training data, the validation loss is higher than the training loss, also the training set relatively small.\n* In the inference section can be seen that most of the images are well classified, but not all, for example, the banana peel didn't get a correct inference.\n* In general the model does pretty well, but it can do better, there is some work that can be done to improve the data, and also fine-tune the neural network architecture to improve the model.","2802d281":"**Note:** The data is considered as _'known data'_ because it was involved during the training,  used for validation.","1e938386":"## **3. Model Evaluation**","87cefeba":"### **1.2. Conclusion:** \nThere is a lot of work that we can do to improve the data, but the one that we have can help us to have a starting point.","ed79fb00":"**Notes:**\n* Transfer learning is used for the classification task.\n* The model used is **ResNet50V2**, which is instantiated with the weights trained on **ImageNet**.\n* We instantiate the model with the default values, check the [docs](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/applications\/ResNet50V2) for more info.\n* The `base_model` layers are trainable, some weights of some layers will be trained, doing that, the _\"generic\"_ features of the `base_model` will be tuned with the features in the dataset.","7ab90af5":"**Notes:**\n* The `base_model` was reviewed to identify a tuning layer.\n* The _'conv5_block1_preact_bn'_ layer is selected as the tuning layer, it has a nice input size, number of parameters, and it's well located in the architecture.\n* All the layers above the tuning layer will be freeze to avoid affecting their weights during training. \n* The layers below the tuning layer will be trainable, during training their weights will be tunned with the features in the `training_ds`.\n","b8e63060":"### **4.1. Inference Using Known Data**","05a97273":"### **4.2. Inference Using New Data**","272df5ca":"**Remember:** A good practice is to create a `test_ds` for this step and use data that wasn't used during training.","04f553cf":"## **4. Inference**","9b88a3d0":"**Notes:** \n* Images were resized using the `image_size` argument of `image_dataset_from_directory()`. The resizing logic can be included in the model, using a resizing layer instead, or add it to a preprocessing group of layers as was done with the rescaling logic.\n* The pixel values of our images were rescaled to be in _[-1,1]_ range that is what our base model expects.","9b762e02":"**Note:** The datasets were created with the default values of the `image_dataset_from_directory()` method mostly, the image size is _256x256_ and the batch size is _32_, check the [docs](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/preprocessing\/image_dataset_from_directory) to review the default values.","9441b327":"## **2. Building The Neural Network And Training The Model**","578093d0":"### **1.1. About The Data And Datasets:**\n* The total number of images in the dataset is 2572.\n* The dataset has 6 different classes.\n* **The number of images in each class varies**. \n* The _\"paper\"_ class has 594 images, having the most.\n* The  _\"trash\"_ class has 137 images, having the fewest.\n* **The dataset is imbalanced**, each class has a different number of images, as can be noticed the difference from the class with most and fewer images is considerable.\n* The quality of images in the dataset can be improved, some images in _\"paper\"_ and _\"cardboard\"_ are basically the same, the same happens with _\"plastic\"_ and _\"glass\"_, **we can recollect more representative data**.\n* **The dataset contains some outliers and mislabeled data.** There is some plastic labeled as _\"paper\"_.\n* The `training_ds` contains 64 batches of 32 images each, each image of size 256x256 colored, the total number of images in the `training_ds` is 2022. It use the default values of `image_dataset_from_directory()` method.\n* The `validation_ds` contains 16 batches of 32 images each, each image of size 256x256 colored, the total number of images in the `validation_ds` is 505. We use the default values of `image_dataset_from_directory()` method.","53dcdf8e":"# **Classifying Recycling Material: A Multi-class Single-label Classification Problem**\nThe objective of the notebook is to build a model that helps to classify recycling material, basically, solve a **multi-class single-label classification problem**.","20c31221":"## **1. Review The Data And Create The Datasets**"}}