{"cell_type":{"76e978c3":"code","64a477ac":"code","5f273572":"code","47eb654b":"code","ad4fce37":"code","9b0bbf7d":"code","fc1a65fa":"code","fb1a4504":"code","e2ed7a56":"code","efaa3315":"code","53c68d7d":"code","42f9fae4":"code","e081e0fa":"code","5cb0521c":"code","3d418d0c":"code","c25735d2":"code","74142ce9":"code","fc967a0d":"code","22d35f46":"code","70ff35fe":"code","6e260251":"code","077bdf26":"code","1c006c98":"code","c9295231":"code","e43944f0":"code","f7c14824":"code","fea20f1a":"code","8bd8a31d":"code","bccd5770":"code","285a51b9":"code","66a3f5a6":"code","e016e181":"code","d293ceab":"code","e30495b5":"code","021c67fa":"code","29342424":"code","f596a8a5":"code","469ba7b6":"code","6c777c54":"code","f8523d86":"code","0203cb48":"code","b2745805":"code","61d20357":"code","9fdc50be":"code","c694a1d6":"code","eeff9150":"code","1bc489dd":"code","7c812cc8":"code","e8e8567b":"code","38b5df7b":"code","31b521bb":"code","401b6496":"code","1404e3b1":"code","eb560560":"code","9bf2dee4":"code","f7f0ac25":"code","fbf12153":"code","6569c633":"code","336935b0":"code","85e007da":"markdown","e770a046":"markdown","fb757c1d":"markdown","b11e38a2":"markdown","d6d3fb66":"markdown","0b6076db":"markdown","b350086c":"markdown","f907cbbe":"markdown","311ca479":"markdown","bb8d5196":"markdown","96f2229e":"markdown","6e532851":"markdown","0e3ac895":"markdown","b5f4a154":"markdown","6f12ddeb":"markdown","13dc061b":"markdown","92ac7810":"markdown","be391e32":"markdown","e638e038":"markdown","2d948530":"markdown","aad6d82c":"markdown","a2baf3be":"markdown","1baec1b9":"markdown","fe8138eb":"markdown","2f092d7f":"markdown","464c61f2":"markdown","472998d5":"markdown","28a10a87":"markdown","d6809dea":"markdown","d21281d2":"markdown","72eb9e67":"markdown","cab4cac7":"markdown","f14e43c0":"markdown","449c5236":"markdown","4096f955":"markdown","79b75719":"markdown","d35b5596":"markdown","f78f366d":"markdown","f0b58fcd":"markdown"},"source":{"76e978c3":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy.stats import norm\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom sklearn.preprocessing import StandardScaler\nfrom scipy import stats\n%matplotlib inline\n\n# Ignore useless warnings\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","64a477ac":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","5f273572":"train.head()\n","47eb654b":"train['SalePrice'].describe()","ad4fce37":"print(train['SalePrice'].skew())\nprint(train['SalePrice'].kurt())","9b0bbf7d":"#histogram and normal probability plot\nsns.distplot(train['SalePrice'], fit=norm);\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)","fc1a65fa":"train['SalePrice'] = np.log(train['SalePrice'])","fb1a4504":"sns.distplot(train['SalePrice'], fit=norm);\n\nfig = plt.figure()\nres = stats.probplot(train['SalePrice'], plot=plt)","e2ed7a56":"# correlation matrix\nfig, ax = plt.subplots(figsize=(12,9))\nsns.heatmap(train.corr(),square=True)","efaa3315":"# zoomed heatmap - selected variables\ncols = train.corr().nlargest(10, 'SalePrice').index","53c68d7d":"plt.subplots(figsize=(10,10))\nsns.set(font_scale=1.25)\nsns.heatmap(train[cols].corr(),square=True, annot=True)","42f9fae4":"cols","e081e0fa":"sns.pairplot(train[cols])","5cb0521c":"var = 'GrLivArea'\nplt.scatter(x=train[var], y=train['SalePrice'])","3d418d0c":"train[train['GrLivArea'] > 4500].index","c25735d2":"var = 'GarageArea'\nplt.scatter(x=train[var], y=train['SalePrice'])","74142ce9":"train[train['GarageArea'] > 1220].index","fc967a0d":"var = 'TotalBsmtSF'\nplt.scatter(x=train[var], y=train['SalePrice'])","22d35f46":"train[train['TotalBsmtSF'] > 5000].index","70ff35fe":"var = '1stFlrSF'\nplt.scatter(x=train[var], y=train['SalePrice'])","6e260251":"train[train['TotalBsmtSF'] > 4000].index","077bdf26":"var = 'OverallQual'\nplt.subplots(figsize=(10,6))\nsns.boxplot(x=train[var], y=train['SalePrice'])","1c006c98":"var = 'YearBuilt'\nfig, ax = plt.subplots(figsize=(15,6))\nfig = sns.boxplot(x=train[var], y=train['SalePrice'])","c9295231":"train = train.drop([523, 581, 1061, 1190, 1298])","e43944f0":"\"\"\"train.drop(train[(train['OverallQual']<5) & (train['SalePrice']>200000)].index, inplace=True)\ntrain.drop(train[(train['OverallQual']==8) & (train['SalePrice']>500000)].index, inplace=True)\ntrain.drop(train[(train['OverallQual']==9) & (train['SalePrice']>500000)].index, inplace=True)\ntrain.drop(train[(train['OverallQual']==10) & (train['SalePrice']>700000)].index, inplace=True)\"\"\"\ntrain.reset_index(drop=True, inplace=True)","f7c14824":"#Split train and labes\ny_train = train['SalePrice'].reset_index(drop=True)\ntrain = train.drop(['SalePrice'], axis=1)","fea20f1a":"#Delete ID\ntrain.drop(['Id'], axis=1, inplace=True)\ntest.drop(['Id'], axis=1, inplace=True)","8bd8a31d":"#concatenate train and test\nall_features = pd.concat((train,test)).reset_index(drop=True)\nall_features.shape","bccd5770":"# missing values\ntotal = all_features.isnull().sum().sort_values(ascending=False)\npercent = (all_features.isnull().sum()\/all_features.isnull().count()).sort_values(ascending=False)\nmissing_data = pd.concat([total,percent], axis=1, keys=['Total','Percent'])\nmissing_data.head(40)","285a51b9":"all_features['MSSubClass'] = all_features['MSSubClass'].apply(str)\nall_features['YrSold'] = all_features['YrSold'].apply(str)\nall_features['MoSold'] = all_features['MoSold'].apply(str)","66a3f5a6":"# Some features have only a few missing value. Fill up using most common value\ncommon_vars = ['Exterior1st','Exterior2nd','SaleType','Electrical','KitchenQual']\nfor var in common_vars:\n    all_features[var] = all_features[var].fillna(all_features[var].mode()[0])\n\nall_features['MSZoning'] = all_features.groupby('MSSubClass')['MSZoning'].transform(lambda x: x.fillna(x.mode()[0]))\n# data description says NA means typical\nall_features['Functional'] = all_features['Functional'].fillna('Typ')","e016e181":"col_str = ['GarageType', 'GarageFinish', 'GarageQual', 'GarageCond','BsmtQual',\n            'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2',\"PoolQC\"\n           ,'Alley','Fence','MiscFeature','FireplaceQu','MasVnrType','Utilities']\nfor col in col_str:\n    all_features[col] = all_features[col].fillna('None')","d293ceab":"# Replacing missing data with 0 (Since No garage = no cars in such garage.)\ncol_num = ['GarageYrBlt','GarageArea','GarageCars','MasVnrArea','BsmtFinSF1','BsmtFinSF2'\n           ,'BsmtFullBath','BsmtHalfBath','FullBath','HalfBath','BsmtUnfSF','TotalBsmtSF']\nfor col in col_num:\n    all_features[col] = all_features[col].fillna(0)\n    \n# group by neighborhood and fill in missing value by the median LotFrontage of all the neighborhood\nall_features['LotFrontage'] = all_features.groupby('Neighborhood')['LotFrontage'].transform(lambda x: x.fillna(x.median()))","e30495b5":"# Check if there is still missing value\nall_features.isnull().sum().sort_values(ascending=False).head(5)","021c67fa":"# Find all numerical features\nnum_features = all_features.select_dtypes(exclude='object').columns","29342424":"# Create box plots for all numeric features\nsns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(8, 12))\nax.set_xscale(\"log\")\nax = sns.boxplot(data=all_features[num_features], orient=\"h\", palette=\"Set1\")\nax.xaxis.grid(False)\nax.set(ylabel=\"Feature names\")\nax.set(xlabel=\"Numeric values\")\nax.set(title=\"Numeric Distribution of Features\")\nsns.despine(trim=True, left=True)","f596a8a5":"# Find skewed numerical features\nskewness = all_features[num_features].apply(lambda x: skew(x)).sort_values(ascending=False)\nhigh_skewness = skewness[abs(skewness) > 0.5]\n\nprint(\"There are {} numerical features with Skew > 0.5 :\".format(high_skewness.shape[0]))\nhigh_skewness.sort_values(ascending=False)","469ba7b6":"high_skewness.index","6c777c54":"from scipy.special import boxcox1p\nskewed_features = high_skewness.index\nfor feat in skewed_features:\n    all_features[feat] = boxcox1p(all_features[feat], boxcox_normmax(all_features[feat] + 1))","f8523d86":"new_skewness = all_features[num_features].apply(lambda x: skew(x)).sort_values(ascending=False)\nnew_high_skewness = new_skewness[abs(new_skewness) > 0.5]\nprint(\"There are {} skewed numerical features after Box Cox transform\".format(new_high_skewness.shape[0]))\nprint(\"Mean skewnees: {}\".format(np.mean(new_high_skewness)))\nnew_high_skewness.sort_values(ascending=False)","0203cb48":"#  Adding total sqfootage feature \nall_features['TotalSF']=all_features['TotalBsmtSF'] + all_features['1stFlrSF'] + all_features['2ndFlrSF']\n#  Adding total bathrooms feature\nall_features['Total_Bathrooms'] = (all_features['FullBath'] + (0.5 * all_features['HalfBath']) +\n                               all_features['BsmtFullBath'] + (0.5 * all_features['BsmtHalfBath']))\n#  Adding total porch sqfootage feature\nall_features['Total_porch_sf'] = (all_features['OpenPorchSF'] + all_features['3SsnPorch'] +\n                              all_features['EnclosedPorch'] + all_features['ScreenPorch'] +\n                              all_features['WoodDeckSF'])\n\nall_features['haspool'] = all_features['PoolArea'].apply(lambda x: 1 if x > 0 else 0)\nall_features['hasgarage'] = all_features['GarageArea'].apply(lambda x: 1 if x > 0 else 0)\nall_features['hasbsmt'] = all_features['TotalBsmtSF'].apply(lambda x: 1 if x > 0 else 0)\nall_features['hasfireplace'] = all_features['Fireplaces'].apply(lambda x: 1 if x > 0 else 0)\n\n\n# Not normaly distributed can not be normalised and has no central tendecy\nall_features = all_features.drop(['MasVnrArea', 'OpenPorchSF', 'WoodDeckSF', 'BsmtFinSF1','2ndFlrSF'], axis=1)","b2745805":"all_features = pd.get_dummies(all_features).reset_index(drop=True)\nall_features.shape","61d20357":"X = all_features.iloc[:len(y_train), :]\nX_test = all_features.iloc[len(y_train):, :]\nX.shape, y_train.shape, X_test.shape","9fdc50be":"# Removes colums where the threshold of zero's is (> 99.95), means has only zero values \noverfit = []\nfor i in X.columns:\n    counts = X[i].value_counts()\n    zeros = counts.iloc[0]\n    if zeros \/ len(X) * 100 > 99.95:\n        overfit.append(i)\n\noverfit = list(overfit)\noverfit.append('MSZoning_C (all)')\n\nX = X.drop(overfit, axis=1).copy()\nX_test = X_test.drop(overfit, axis=1).copy()\n\nprint(X.shape,y_train.shape,X_test.shape)","c694a1d6":"from datetime import datetime\nfrom sklearn.preprocessing import RobustScaler\nfrom sklearn.model_selection import KFold, cross_val_score\nfrom sklearn.metrics import mean_squared_error, make_scorer\nfrom sklearn.linear_model import ElasticNetCV, LassoCV, RidgeCV\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.linear_model import LinearRegression\n\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.svm import SVR\nfrom mlxtend.regressor import StackingCVRegressor\nfrom sklearn.linear_model import LinearRegression\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor","eeff9150":"# setup cross validation folds\nkfolds = KFold(n_splits=16, shuffle=True, random_state=42)\n\n# define error metrics\ndef cv_rmse(model, X=X):\n    rmse = np.sqrt(-cross_val_score(model, X, y_train, scoring=\"neg_mean_squared_error\", cv=kfolds))\n    return (rmse)\n\ndef rmsle(y, y_pred):\n    return np.sqrt(mean_squared_error(y, y_pred))","1bc489dd":"# LightGBM regressor\nlightgbm = LGBMRegressor(objective='regression', \n                       num_leaves=4,\n                       learning_rate=0.01, \n                       n_estimators=9000,\n                       max_bin=200, \n                       bagging_fraction=0.75,\n                       bagging_freq=5, \n                       bagging_seed=7,\n                       feature_fraction=0.2,\n                       feature_fraction_seed=7,\n                       min_sum_hessian_in_leaf = 11,\n                       verbose=-1,\n                       random_state=42)\n\n# XGBoost Regressor\n\"\"\"xgboost = XGBRegressor(learning_rate=0.01,\n                       n_estimators=6000,\n                       max_depth=4,\n                       min_child_weight=0,\n                       gamma=0.6,\n                       subsample=0.7,\n                       colsample_bytree=0.7,\n                       objective='reg:linear',\n                       nthread=-1,\n                       scale_pos_weight=1,\n                       seed=27,\n                       reg_alpha=0.00006,\n                       random_state=42)\"\"\"\n\n\"\"\"gbr = GradientBoostingRegressor(n_estimators=6000,\n                                learning_rate=0.01,\n                                max_depth=4,\n                                max_features='sqrt',\n                                min_samples_leaf=15,\n                                min_samples_split=10,\n                                loss='huber',\n                                random_state=42)  \n\"\"\"\n\n# setup models hyperparameters using a pipline\n# This is a range of values that the model considers each time in runs a CV\nridge_alpha = [14.5, 14.6, 14.7, 14.8, 14.9, 15, 15.1, 15.2, 15.3, 15.4, 15.5]\nlasso_alpha = [5e-05, 0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007, 0.0008]\n\nelastic_alpha = [0.0001, 0.0002, 0.0003, 0.0004, 0.0005, 0.0006, 0.0007]\ne_l1ratio = [0.8, 0.85, 0.9, 0.95, 0.99, 1]\n\n# Ridge Regression: robust to outliers using RobustScaler\nridge = make_pipeline(RobustScaler(), RidgeCV(alphas=ridge_alpha, cv=kfolds))\n\n# Lasso Regression: \nlasso = make_pipeline(RobustScaler(), LassoCV(max_iter=1e7, \n                    alphas=lasso_alpha,random_state=42, cv=kfolds))\n\n# Elastic Net Regression:\nelasticnet = make_pipeline(RobustScaler(), ElasticNetCV(max_iter=1e7, \n                         alphas=elastic_alpha, cv=kfolds, l1_ratio=e_l1ratio))\n\n# Support Vector Regression\nsvr = make_pipeline(RobustScaler(), SVR(C= 20, epsilon= 0.008, gamma=0.0003))\n\n# Stack up all the models above\nstack_gen = StackingCVRegressor(regressors=(ridge, lasso, elasticnet, svr, lightgbm),\n                                meta_regressor=elasticnet,\n                                use_features_in_secondary=True)","7c812cc8":"# Store scores of each model\nscores = {}\n\nscore = cv_rmse(lightgbm)\nprint(\"lightgbm: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['lightgbm'] = (score.mean(), score.std())","e8e8567b":"score = cv_rmse(ridge)\nprint(\"ridge: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['ridge'] = (score.mean(), score.std())","38b5df7b":"score = cv_rmse(lasso)\nprint(\"lasso: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['lasso'] = (score.mean(), score.std())","31b521bb":"score = cv_rmse(elasticnet)\nprint(\"elasticnet: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['elasticnet'] = (score.mean(), score.std())","401b6496":"score = cv_rmse(svr)\nprint(\"svr: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['svr'] = (score.mean(), score.std())","1404e3b1":"\"\"\"score = cv_rmse(gbr)\nprint(\"gbr: {:.4f} ({:.4f})\".format(score.mean(), score.std()))\nscores['gbr'] = (score.mean(), score.std())\"\"\"","eb560560":"print('----START Fit----',datetime.now())\nprint('Elasticnet')\nelastic_model = elasticnet.fit(X, y_train)\nprint('Lasso')\nlasso_model = lasso.fit(X, y_train)\nprint('Ridge')\nridge_model = ridge.fit(X, y_train)\nprint('lightgbm')\nlgb_model = lightgbm.fit(X, y_train)\nprint('svr')\nsvr_model = svr.fit(X, y_train)\n\nprint('stack_gen')\nstack_gen_model = stack_gen.fit(np.array(X), np.array(y_train))","9bf2dee4":"def blend_predictions(X):\n    return ((0.12  * elastic_model.predict(X)) + \\\n            (0.12 * lasso_model.predict(X)) + \\\n            (0.12 * ridge_model.predict(X)) + \\\n            (0.22 * lgb_model.predict(X)) + \\\n            (0.1 * svr_model.predict(X)) + \\\n            (0.32 * stack_gen_model.predict(np.array(X))))","f7f0ac25":"# Get final precitions from the blended model\nblended_score = rmsle(y_train, blend_predictions(X))\nscores['blended'] = (blended_score, 0)\nprint('RMSLE score on train data:')\nprint(blended_score)","fbf12153":"# Plot the predictions for each model\nsns.set_style(\"white\")\nfig = plt.figure(figsize=(24, 12))\n\nax = sns.pointplot(x=list(scores.keys()), y=[score for score, _ in scores.values()], markers=['o'], linestyles=['-'])\nfor i, score in enumerate(scores.values()):\n    ax.text(i, score[0] + 0.002, '{:.6f}'.format(score[0]), horizontalalignment='left', size='large', color='black', weight='semibold')\n\nplt.ylabel('Score (RMSE)', size=20, labelpad=12.5)\nplt.xlabel('Model', size=20, labelpad=12.5)\nplt.tick_params(axis='x', labelsize=13.5)\nplt.tick_params(axis='y', labelsize=12.5)\n\nplt.title('Scores of Models', size=20)\n\nplt.show()","6569c633":"submission = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv\")\nsubmission.iloc[:,1] = np.floor(np.expm1(blend_predictions(X_test)))","336935b0":"submission.to_csv(\"submission.csv\", index=False)","85e007da":"## Blend the models","e770a046":"# Submission","fb757c1d":"## Split train and test sets","b11e38a2":"The rest string features can be filled with None.","d6d3fb66":"# Train a model","0b6076db":"## Heat map of correlations","b350086c":"## Find the best model","f907cbbe":"Let't check the skewness after transformation.","311ca479":"# Importing data","bb8d5196":"## Defining models","96f2229e":"# Importing libraries","6e532851":"There are still a lot of skewness. They will be dealt with later.","0e3ac895":"## Dealing with missing values\n### Overview of missing values","b5f4a154":"## Set up cross validation","6f12ddeb":"# Exploring numerical features","13dc061b":"We can find that there are two outliers at the bottom right. Let's locate them.","92ac7810":"This notebook begins with some exploratory data analysis and follows with feature engineering. Several simple regression models were applied and finally a stacked model built based on those simple models. It should be a great place to start if you are a beginner. Feel free to use this kernel, please upvote if you find this is helpful and share your comment. Great thanks to the following kernels:\n\nhttps:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python\n\nhttps:\/\/www.kaggle.com\/shaygu\/house-prices-begginer-top-7 \n\nhttps:\/\/www.kaggle.com\/lavanyashukla01\/how-i-made-top-0-3-on-a-kaggle-competition","be391e32":"## Creating new features","e638e038":"## Transforming skewed numerical features","2d948530":"### String features","aad6d82c":"Let's closely take a look at several features.","a2baf3be":"# Table of Contents\n1. [Importing libraries](#Importing libraries)\n2. [Importing data](#Importing data)\n3. [Exploring predicted variable](#Exploring predicted variable)\n4. [Exploring numerical features](#Exploring numerical features)\n5. [Features](#Features)\n6. [Train a model](#Train a model)\n7. [Submission](#Submission)","1baec1b9":"The sale price was not normally distributed. We can tranform it using log function.","fe8138eb":"## Encode categorical features","2f092d7f":"# Features","464c61f2":"Get cross validation score for each model.","472998d5":"Next step, we can use Box Cox transformation on skewed data.","28a10a87":"## Remove outliers","d6809dea":"## Training models","d21281d2":"Some of the non-numeric features are stored as numbers. They should be converted to strings.","72eb9e67":"### Numerical features","cab4cac7":"Now there is no missing value in the whole dataset.","f14e43c0":"## Drop ID and combine train\/test","449c5236":"The missing values of numerical features can be filled with 0 or median.","4096f955":"From the above heat map, we can find some of the features have higher correlations with sale price. Let's find the top ten highest correlation and plot the zoomed heat map.","79b75719":"# Exploring predicted variable","d35b5596":"## Fitting the models","f78f366d":"Remove outliers.","f0b58fcd":"They will be deleted later."}}