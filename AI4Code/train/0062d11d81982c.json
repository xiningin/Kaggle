{"cell_type":{"ac8d2700":"code","953f67a4":"code","266294b6":"code","8b80257f":"code","9459ba32":"code","f3066b1f":"code","35c77e2d":"code","e0463ff3":"code","8daeb3fe":"code","430fce5b":"code","6d9e4980":"code","dc7f81aa":"code","c21649a9":"code","decc2ce9":"code","1395525c":"code","1e330cda":"code","1486a3a7":"code","065b25f2":"code","39556598":"code","0bb790af":"code","16fb16ae":"code","06ff9884":"code","0a0d4972":"code","79d94aca":"code","19ad5275":"code","207e0f4a":"code","55044cfe":"code","5ab18e74":"code","8f64ae09":"code","fc60aa63":"code","b82d71fa":"code","1919c7d9":"code","0d02829e":"code","42c44703":"code","b5ddc370":"code","6ef70b9d":"code","27cb01dc":"code","32af6968":"code","d8fa503f":"code","a9d0dc35":"code","c0afab69":"code","fb955805":"code","519af0e3":"code","44bdcb74":"code","bdb9fd01":"markdown","f4172477":"markdown","0a8ba478":"markdown","195d1098":"markdown","7000feb6":"markdown","ebe6c863":"markdown","656abc2a":"markdown","a5cd58a2":"markdown","9c5e1bcc":"markdown","62dd7b3d":"markdown","a3f7c6c2":"markdown","a23ed370":"markdown","0ee84f54":"markdown","0d034548":"markdown","ea8d6715":"markdown","fc3f7e33":"markdown","28748fed":"markdown","a3a03bff":"markdown","57473e41":"markdown","23029326":"markdown","72bfb6ba":"markdown","4d17b4ba":"markdown"},"source":{"ac8d2700":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","953f67a4":"from warnings import filterwarnings\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom nltk.corpus import stopwords\nfrom nltk.sentiment import SentimentIntensityAnalyzer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import cross_val_score, GridSearchCV, cross_validate\nfrom sklearn.preprocessing import LabelEncoder\nfrom textblob import Word, TextBlob\nfrom wordcloud import WordCloud","266294b6":"filterwarnings('ignore')\npd.set_option('display.max_columns', None)\npd.set_option('display.width', 200)\npd.set_option('display.float_format', lambda x: '%.2f' % x)","8b80257f":"df = pd.read_csv(\"..\/input\/reviews\/Restaurant_Reviews.tsv\",delimiter=\"\\t\")","9459ba32":"df.head()","f3066b1f":"df.info()","35c77e2d":"df.shape","e0463ff3":"df['Review'] = df['Review'].str.lower()","8daeb3fe":"df.head()","430fce5b":"df['Review'] = df['Review'].str.replace('[^\\w\\s]', '')","6d9e4980":"df['Review'] = df['Review'].str.replace('\\d', '')","dc7f81aa":"sw = stopwords.words('english')\ndf['Review'] = df['Review'].apply(lambda x: \" \".join(x for x in str(x).split() if x not in sw))","c21649a9":"drops = pd.Series(' '.join(df['Review']).split()).value_counts()[-250:]\ndf['Review'] = df['Review'].apply(lambda x: \" \".join(x for x in x.split() if x not in drops))","decc2ce9":"df[\"Review\"].apply(lambda x: TextBlob(x).words).head()","1395525c":"df['Review'] = df['Review'].apply(lambda x: \" \".join([Word(word).lemmatize() for word in x.split()]))","1e330cda":"df[\"Review\"].head()","1486a3a7":"tf = df[\"Review\"].apply(lambda x: pd.value_counts(x.split(\" \"))).sum(axis=0).reset_index()","065b25f2":"tf.columns = [\"words\", \"tf\"]\ntf.head()","39556598":"tf.shape","0bb790af":"tf[\"words\"].nunique()","16fb16ae":"tf[\"tf\"].describe([0.05, 0.10, 0.25, 0.50, 0.75, 0.80, 0.90, 0.95, 0.99]).T","06ff9884":"tf.sort_values(\"tf\", ascending = False)","0a0d4972":"tf[tf[\"tf\"] > 25].plot.bar(x=\"words\", y=\"tf\")\nplt.show()","79d94aca":"text = \" \".join(i for i in df.Review)\nwordcloud = WordCloud().generate(text)\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\n\nwordcloud = WordCloud(max_font_size=50,\n                      max_words=100,\n                      background_color=\"white\").generate(text)\nplt.figure()\nplt.imshow(wordcloud, interpolation=\"bilinear\")\nplt.axis(\"off\")\nplt.show()\n\nwordcloud.to_file(\"wordcloud.png\")","19ad5275":"sia = SentimentIntensityAnalyzer()\nsia.polarity_scores(\"The food was awesome\")","207e0f4a":"df[\"Review\"].apply(lambda x: x.upper())","55044cfe":"df[\"Review\"][0:10].apply(lambda x: sia.polarity_scores(x))","5ab18e74":"df[\"polarity_score\"] = df[\"Review\"].apply(lambda x: sia.polarity_scores(x)[\"compound\"])","8f64ae09":"df.head()","fc60aa63":"df[\"Review\"][0:10].apply(lambda x: \"pos\" if sia.polarity_scores(x)[\"compound\"] > 0 else \"neg\")","b82d71fa":"df[\"sentiment_label\"] = df[\"Review\"].apply(lambda x: \"pos\" if sia.polarity_scores(x)[\"compound\"] > 0 else \"neg\")\ndf.head(20)","1919c7d9":"df.groupby(\"sentiment_label\")[\"Liked\"].mean()","0d02829e":"df[\"sentiment_label\"] = LabelEncoder().fit_transform(df[\"sentiment_label\"])","42c44703":"X = df[\"Review\"]\ny = df[\"sentiment_label\"]","b5ddc370":"from sklearn.feature_extraction.text import CountVectorizer\nvectorizer = CountVectorizer()\nX_count = vectorizer.fit_transform(X)\n\nvectorizer.get_feature_names()[10:15]\nX_count.toarray()[10:15]","6ef70b9d":"from sklearn.feature_extraction.text import TfidfVectorizer\ntf_idf_word_vectorizer = TfidfVectorizer()\nX_tf_idf_word = tf_idf_word_vectorizer.fit_transform(X)","27cb01dc":"tf_idf_ngram_vectorizer = TfidfVectorizer(ngram_range=(2, 3))\nX_tf_idf_ngram = tf_idf_word_vectorizer.fit_transform(X)","32af6968":"log_model = LogisticRegression().fit(X_tf_idf_word, y)\n\ncross_val_score(log_model,\n                X_tf_idf_word,\n                y, scoring=\"accuracy\",\n                cv=5).mean()","d8fa503f":"random_review = pd.Series(df[\"Review\"].sample(1).values)\nrandom_review","a9d0dc35":"new_comment = CountVectorizer().fit(X).transform(random_review)\nlog_model.predict(new_comment)","c0afab69":"rf_model = RandomForestClassifier().fit(X_count, y)\nprint(cross_val_score(rf_model, X_count, y, cv=5, n_jobs=-1).mean())","fb955805":"rf_model = RandomForestClassifier().fit(X_tf_idf_word, y)\nprint(cross_val_score(rf_model, X_tf_idf_word, y, cv=5, n_jobs=-1).mean())","519af0e3":"rf_model = RandomForestClassifier().fit(X_tf_idf_ngram, y)\nprint(cross_val_score(rf_model, X_tf_idf_ngram, y, cv=5, n_jobs=-1).mean())","44bdcb74":"rf_model = RandomForestClassifier(random_state=17)\n\nrf_params = {\"max_depth\": [5, 8, None],\n             \"max_features\": [5, 7, \"auto\"],\n             \"min_samples_split\": [2, 5, 8, 20],\n             \"n_estimators\": [100, 200, 500]}\n\nrf_best_grid = GridSearchCV(rf_model,\n                            rf_params,\n                            cv=5,\n                            n_jobs=-1,\n                            verbose=True).fit(X_count, y)\n\nrf_best_grid.best_params_\n\nrf_final = rf_model.set_params(**rf_best_grid.best_params_, random_state=17).fit(X_count, y)\n\ncv_results = cross_validate(rf_final, X_count, y, cv=3, scoring=[\"accuracy\", \"f1\", \"roc_auc\"])\n\ncv_results['test_accuracy'].mean()\ncv_results['test_f1'].mean()\ncv_results['test_roc_auc'].mean()","bdb9fd01":"Calculate the term frequencies","f4172477":"Create the target","0a8ba478":"**Hyperparameter Optimization**","195d1098":"Barplot","7000feb6":"***Random Forests***","ebe6c863":"***TF-IDF***\n\nIt is the weight factor calculated with the statistical method that shows the importance of a term in the document.","656abc2a":"> **4. Sentiment Modeling**","a5cd58a2":"Wordcloud","9c5e1bcc":"***Rarewords***\n\nWe drop words according to their frequencies.","62dd7b3d":"***Normalizing Case Folding***","a3f7c6c2":"> **1. Text Preprocessing**","a23ed370":"> **3. Sentiment Analysis**","0ee84f54":"> **2. Text Visualization**","0d034548":"***Tokenization***\n\nbreak sentences into parts","ea8d6715":"***Logistic Regression***","fc3f7e33":"Apply for all data","28748fed":"*TF-IDF Word-Level*","a3a03bff":"***Punctuations***","57473e41":"***Count Vectors***\n\nconverts text to a term count vector.","23029326":"***Stopwords*** \n\nIt allows us to get rid of commonly used words.","72bfb6ba":"***Lemmatization \/ Stemming***\n\nis the process of separating words by root","4d17b4ba":"**1. Text Preprocessing**\n\n**2. Text Visualization**\n\n**3. Sentiment Analysis**\n\n**4. Sentiment Modeling**\n"}}