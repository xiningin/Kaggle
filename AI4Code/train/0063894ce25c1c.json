{"cell_type":{"113948aa":"code","c206ccce":"code","f5dab6e2":"code","8150860b":"code","0959c8fd":"code","ec2f7813":"code","fafa21c7":"code","a13a662d":"code","7fb564fc":"code","82ac43aa":"code","e3490ae0":"code","bf3fef5f":"code","1561b76b":"code","0401dd03":"code","f5ef8900":"code","1c190f9c":"code","7a609491":"code","7c8dc911":"code","4560c6a6":"code","86033fae":"code","404cf70f":"code","040fbcfc":"code","0172cb04":"code","3bc5262b":"code","36f22d4a":"code","f718f576":"code","a3884fd6":"code","fba2e8d7":"code","af1bb80e":"code","11592ace":"code","063d0906":"code","1bc8cdd3":"code","2f1ba6e6":"code","6b990c3c":"code","a84fa845":"code","1511df23":"code","9de32609":"code","e8ed2d4f":"code","a7cfc959":"code","ea30e89c":"code","a3b2f324":"code","f8853093":"code","292d9037":"code","a0144daa":"code","aa6ad20e":"code","9cb35a41":"code","4453a7bd":"markdown","5ed84390":"markdown","7027ab66":"markdown","d40f37c7":"markdown","e2edc336":"markdown","9dbad8af":"markdown","af1075f3":"markdown","2b5b34f4":"markdown","b30596ab":"markdown","5789e01a":"markdown","b677c37b":"markdown","074f9a81":"markdown","59e49289":"markdown","15ea1f71":"markdown","7171ad15":"markdown","b41e5925":"markdown","b63c2edf":"markdown","db4beeb9":"markdown","780fef4a":"markdown","90b70d4e":"markdown","d933cfa5":"markdown","6dc1a9f2":"markdown"},"source":{"113948aa":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, plot_confusion_matrix, plot_roc_curve","c206ccce":"plt.style.use('fivethirtyeight')","f5dab6e2":"filename = '\/kaggle\/input\/bank-marketing-dataset\/bank.csv'\ndf = pd.read_csv(filename)","8150860b":"df.head()","0959c8fd":"df.tail()","ec2f7813":"df.shape","fafa21c7":"df.duplicated().any()","a13a662d":"df.info()","7fb564fc":"df.dtypes.value_counts()","82ac43aa":"df.describe()","e3490ae0":"for col in df.select_dtypes(include='object').columns: \n    print(col, \"column\")\n    print(\"Number of unique:\", df[col].nunique())\n    print(df[col].value_counts(), '\\n')","bf3fef5f":"print('number of pdays with -1:', (df['pdays']==-1).sum())\nprint('number of poutcome with unknown:', (df['poutcome']=='unknown').sum())","1561b76b":"i = df[(df['poutcome']=='unknown') & (df['pdays']!=-1)].index\ndf.iloc[i]","0401dd03":"df['poutcome'].iloc[i] = 'failure'\ndf.iloc[i]","f5ef8900":"df['poutcome'].replace({'other':'failure'}, inplace=True)\n\nnp.random.seed(42)\ni = df[df['contact'] == 'unknown'].index\ndf['contact'].iloc[i] = np.random.choice(a=['cellular', 'telephone'], size=len(i), p=(.774, .226))\n\n","1c190f9c":"# final review\nfor col in df.select_dtypes(include='object').columns: \n    print(col, \"column\")\n    print(\"Number of unique:\", df[col].nunique())\n    print(df[col].value_counts(), '\\n')","7a609491":"labels = df['deposit'].unique()\nfig1, ax1 = plt.subplots(figsize=(12, 7))\nexp = [0,.05]\nax1.pie(df['deposit'].value_counts(ascending=True), explode=exp, labels=labels, autopct='%1.1f%%', pctdistance=0.6,\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.show()","7c8dc911":"plt.figure(figsize=(12,7))\nsns.countplot(data=df, x='job', order = df['job'].value_counts().index, hue='deposit')\nplt.xticks(rotation=90)\nplt.title(\"plot of campaign outcome by job\")\n\nplt.show()","4560c6a6":"fig = plt.figure(figsize=(12, 7))\n\nfig.add_subplot(121)\nsns.histplot(data=df, x='age', bins=20, kde=True)\n\nfig.add_subplot(122)\nsns.boxplot(data=df, x='deposit', y='age', showmeans=True)\nfig.suptitle('comparing campaign outcome by age')\nplt.show()","86033fae":"plt.figure(figsize=(12,7))\nsns.countplot(data=df, x='education', order = df['education'].value_counts().index, hue='deposit')\n#plt.xticks(rotation=90)\nplt.title(\"plot of campaign outcome by education\")\n\nplt.show()","404cf70f":"plt.figure(figsize=(12,7))\nsns.countplot(data=df, x='poutcome', order = df['poutcome'].value_counts().index, hue='deposit')\n#plt.xticks(rotation=90)\nplt.title(\"plot of campaign outcome by previous outcome\")\n\nplt.show()","040fbcfc":"plt.figure(figsize=(12,7))\nsns.countplot(data=df, x='month', order = df['month'].value_counts().index, hue='deposit')\nplt.xticks(rotation=90)\nplt.title(\"plot of campaign outcome by month\")\n\nplt.show()","0172cb04":"plt.figure(figsize=(12,7))\nsns.histplot(data=df, x='duration', hue='deposit', kde=True)\nplt.title('comparing deposit by duration of call')\n\nplt.show()","3bc5262b":"plt.figure(figsize=(12,7))\nsns.countplot(data=df, x='campaign', hue='deposit')\nplt.title('comparing deposit by number of contacts performed')\n\nplt.show()","36f22d4a":"#processing and scaling numerical data columns\nscaler = StandardScaler()\nnum_df = df.select_dtypes(include=np.number)\nnum_df_arr = scaler.fit_transform(num_df)\nnum_df = pd.DataFrame(num_df_arr, columns=num_df.columns)\nnum_df","f718f576":"# apply ordinal label to ordinal categorical data\ncat_df = df.select_dtypes(include='object')\n\nbinary_dict = {'yes':1, 'no':0}\ncalendar_dict = {'jan':1, 'feb':2, 'mar':3, 'apr':4, 'may':5, 'jun':6, \n                 'jul':7, 'aug':8, 'sep':9, 'oct':10, 'nov':11, 'dec':12}\neducation_dict = {'unknown':0, 'primary':1, 'secondary':2, 'tertiary':3}\n\ncat_df['deposit'].replace(binary_dict, inplace=True)\ncat_df['default'].replace(binary_dict, inplace=True)\ncat_df['housing'].replace(binary_dict, inplace=True)\ncat_df['loan'].replace(binary_dict, inplace=True)\ncat_df['month'].replace(calendar_dict, inplace=True)\ncat_df['education'].replace(education_dict, inplace=True)\n\ncat_df","a3884fd6":"# new dataset with scaled numerical data and ordinal categorical features\ndf2 = pd.concat([cat_df, num_df], axis=1)\ndf2","fba2e8d7":"mask = np.triu(np.ones_like(df2.corr(), dtype=bool))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\nplt.figure(figsize=(12,12))\nsns.heatmap(df2.corr(), mask=mask, annot=True, fmt='.1g', cmap=cmap, cbar=False)\nplt.show()","af1bb80e":"# apply one hot encoding to the rest of the categorical features\ndf2 = pd.get_dummies(df2, drop_first=True)\ndf2","11592ace":"X = df2.drop(columns='deposit')\nX","063d0906":"y = df2['deposit']\ny","1bc8cdd3":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, stratify=y, random_state=42)","2f1ba6e6":"# logistic regression\nlogreg = LogisticRegression().fit(X_train, y_train)\nypred_logreg = logreg.predict(X_test)","6b990c3c":"# SVM.svc\nsvc= SVC(probability=True).fit(X_train, y_train)\nypred_svc = svc.predict(X_test)","a84fa845":"# naive bayes\ngauss = GaussianNB().fit(X_train, y_train)\nypred_gauss = gauss.predict(X_test)","1511df23":"print('Logistic Regression\\n', classification_report(y_test, ypred_logreg))\nprint('Support Vector Machine\\n', classification_report(y_test, ypred_svc))\nprint('Naive Bayes\\'s Classifier\\n', classification_report(y_test, ypred_gauss))","9de32609":"fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(15, 15))\nplot_confusion_matrix(logreg, X_test, y_test, ax=ax1)\nax1.grid(False)\nax1.set_xlabel(\"\")\nax1.set_title('logistic regression')\n\nplot_confusion_matrix(svc, X_test, y_test, ax=ax2)\nax2.grid(False)\nax2.set_xlabel(\"\")\nax2.set_title('svc')\n\nplot_confusion_matrix(gauss, X_test, y_test, ax=ax3)\nax3.grid(False)\nax3.set_title('gauss nb')\n\nplt.show()","e8ed2d4f":"fig, ax = plt.subplots(figsize=(8,8))\nplot_roc_curve(logreg, X_test, y_test, ax=ax)\nplot_roc_curve(svc, X_test, y_test, ax=ax)\nplot_roc_curve(gauss, X_test, y_test, ax=ax)\nplt.plot([0, 1], [0, 1], color = 'black', linestyle = '--')\nplt.xlim(-.01, 1.01)\nplt.ylim(-.01, 1.01)\n\nplt.show()","a7cfc959":"# dropping duration and campaign columns\nX2 = X.drop(columns=['duration', 'campaign'])\nX2","ea30e89c":"X2_train, X2_test, y_train, y_test = train_test_split(X2, y, test_size=.2, random_state=42)","a3b2f324":"logreg = LogisticRegression().fit(X2_train, y_train)\nypred_logreg = logreg.predict(X2_test)\n","f8853093":"svc = SVC(probability=True).fit(X2_train, y_train)\nypred_svc = svc.predict(X2_test)\n","292d9037":"gauss = GaussianNB().fit(X2_train, y_train)\nypred_gauss = gauss.predict(X2_test)","a0144daa":"print(classification_report(y_test, ypred_logreg))\nprint(classification_report(y_test, ypred_svc))\nprint(classification_report(y_test, ypred_gauss))","aa6ad20e":"fig, (ax1, ax2, ax3) = plt.subplots(nrows=3, ncols=1, figsize=(15, 15))\nplot_confusion_matrix(logreg, X2_test, y_test, ax=ax1)\nax1.grid(False)\nax1.set_xlabel(\"\")\nax1.set_title('logistic regression')\n\nplot_confusion_matrix(svc, X2_test, y_test, ax=ax2)\nax2.grid(False)\nax2.set_xlabel(\"\")\nax2.set_title('svc')\n\nplot_confusion_matrix(gauss, X2_test, y_test, ax=ax3)\nax3.grid(False)\nax3.set_title('gauss nb')\n\nplt.show()","9cb35a41":"fig, ax = plt.subplots(figsize=(8, 8))\nplot_roc_curve(logreg, X2_test, y_test, ax=ax)\nplot_roc_curve(svc, X2_test, y_test, ax=ax)\nplot_roc_curve(gauss, X2_test, y_test, ax=ax)\n\nplt.plot([0, 1], [0, 1], color = 'black', linestyle = '--')\nplt.xlim(-.01, 1.01)\nplt.ylim(-.01, 1.01)\n\nplt.show()","4453a7bd":"Assume **poutcome** values with 'other' to be 'failure', since model is a binary classifier.\n\nContacts cannot be unknown since it is telemarketing campaign. They need to be contacted by some means. Hence populate randomly with celluar and telephone","5ed84390":"Let's take a look at the numeric features with the describe() method. \n\nThe values have pretty high variance and we will likely apply normalisation of the data so that the large values will not affect our machine learining model later. \n\nThe minimum of *balance* is negative, which is possible due to overdrawn accounts.\nThe minimum of *pdays* is negative, which is possible as it indicates that the customer is a fresh lead.\n","7027ab66":"Check for duplicated observations and review general information","d40f37c7":"Check the head, tail and overall shape","e2edc336":"Revise **poutcome** values for discrepency to 'failure'","9dbad8af":"# Preprocessing data\n- Normalise numeric features\n- Apply ordinal encoding where possible for catetorical data\n- Otherise apply one hot encoding ","af1075f3":"# Bank Dataset\nMy first attempt at putting up a machine learning model on Kaggle","2b5b34f4":"Numeric data for the features are not on the same scale. Normalisation of the data needs to be applied before applying machine learning model later\n\nNext review categorical featues, their unique values and their counts","b30596ab":"Review numeric features","5789e01a":"## Graphical EDA","b677c37b":"## Applying Machine learning models\n1. Models to be applied\n* Logistic Regression, Support Vector Machine, Naive Bayes' Classifier\n2. Metrics to study - \n* Quantitative - Accuracy score, Recall, Precision\n* Visual - Confusion matrix, ROC curve","074f9a81":"Although results look promising, this is an unfair model. **campaign** and **duration** must be dropped to have a fair predictive model. This unfair model will only be used for benchmarking purpose","59e49289":"# Summary of features\n\n##### Input variables:\n1. age (numeric)\n2. job : type of job (categorical) \n3. marital : marital status (categorical: \"married\",\"divorced\",\"single\"; note: \"divorced\" means divorced or widowed)\n4. education (categorical: \"unknown\",\"secondary\",\"primary\",\"tertiary\")\n5. default: has credit in default? (binary: \"yes\",\"no\")\n6. balance: average yearly balance, in euros (numeric) \n7. housing: has housing loan? (binary: \"yes\",\"no\")\n8. loan: has personal loan? (binary: \"yes\",\"no\")\n9. contact: contact communication type (categorical: \"unknown\",\"telephone\",\"cellular\") \n10. day: last contact day of the month (numeric)\n11. month: last contact month of year (categorical: \"jan\", \"feb\", \"mar\", ..., \"nov\", \"dec\")\n12. duration: last contact duration, in seconds (numeric)\n13. campaign: number of contacts performed during this campaign and for this client (numeric, includes last contact)\n14. pdays: number of days that passed by after the client was last contacted from a previous campaign (numeric, -1 means client was not previously contacted)\n15. previous: number of contacts performed before this campaign and for this client (numeric)\n16. poutcome: outcome of the previous marketing campaign (categorical: \"unknown\",\"other\",\"failure\",\"success\")\n\n##### Output variable (desired target):\n17. deposit: has the client subscribed a term deposit? (binary: \"yes\",\"no\")\n\n##### Reference\n- S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014\n    - https:\/\/core.ac.uk\/download\/pdf\/55631291.pdf\n    - https:\/\/archive.ics.uci.edu\/ml\/datasets\/bank+marketing\n","15ea1f71":"Dataset has over 11,100 observations and 17 features\n\nNext, check for duplicated observations and review general information (data types, shape, null values)","7171ad15":"##### Preparing and splitting training and test data","b41e5925":"**pdays** with '-1' values and **poutcome** with 'unknown' should be consistent to identify as new leads","b63c2edf":"can potentially merge some of the columns for improving model later. ie (blue-collar and technician, self-employed and entrepreneur)","db4beeb9":"Checking for correlation","780fef4a":"**Note**\n1. While **duration** and **deposit** may show correlation, **duration** should not be used in final predictive model. Reason being that we can never have this information before a telemarketing campaign begins. (Reminder: **duration** refers to the total time spent during current campaign talking to customer)\n2. Hence the same can be applied for **campaign**, which is the number contacts made with the customer during this campaign\n3. **previous** and **pdays**, appears to have some correlation. As we are assuming independence of features, one of them can be removed later in the feature selection\/engineering step. ","90b70d4e":"Dataset is pretty balanced. Baseline accuracy at 47.4%","d933cfa5":"**Summary of processes**\n1. Review dataframe\n* head, tail, shape\n* duplicates, info, dtypes\n* review each feature (column name)\n2. Clean Data\n* check for discrepencies\n* fill unknown\/null values\n3. Visual EDA\n4. Data Preprocessing","6dc1a9f2":"number of counts show discrepencies"}}