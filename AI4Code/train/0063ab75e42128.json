{"cell_type":{"c740e7ca":"code","4c9cfaba":"code","eb23f7c3":"code","d50452ff":"code","6a4423db":"code","6cc6708f":"code","f373065e":"code","789c4891":"code","0e6072ba":"code","55347e6f":"code","e6ec99b0":"code","c6208871":"code","0f1f0a78":"code","017e47f2":"code","fda9840a":"code","6ac57178":"code","9b88d098":"code","60aa1833":"markdown","91c8e3f7":"markdown","4c59f384":"markdown","24a2d410":"markdown"},"source":{"c740e7ca":"!pip install -qq tf-nightly","4c9cfaba":"import numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.regularizers import l2\nimport matplotlib.pyplot as plt\n%matplotlib inline\nprint(\"Tensorflow version: \", tf.__version__)","eb23f7c3":"seed = 1234\nnp.random.seed(seed)\ntf.random.set_seed(seed)","d50452ff":"# Training parameters\nbatch_size = 128\nepochs = 100\nnum_classes = 10\n\n# The data, split between train and test sets:\n(x_train, y_train), (x_test, y_test) = keras.datasets.cifar10.load_data()\n\nprint(\"x_train shape:\", x_train.shape)\nprint(x_train.shape[0], \"train samples\")\nprint(x_test.shape[0], \"test samples\")\n\n# convert class vectors to binary class matrices\ny_train = keras.utils.to_categorical(y_train, num_classes)\ny_test = keras.utils.to_categorical(y_test, num_classes)","6a4423db":"# ResNet20 config\nn = 2\ndepth = n * 9 + 2\nversion = 2\ninput_shape = (32, 32, 3)\n\n# Model name, depth and version\nmodel_type = 'ResNet%dv%d' % (depth, version)","6cc6708f":"data_augmentation = keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n        layers.experimental.preprocessing.RandomRotation(0.1),\n        layers.experimental.preprocessing.RandomContrast(0.25),\n        layers.experimental.preprocessing.RandomCrop(32, 32)\n    ]\n)","f373065e":"# Use tf.data.Dataset for improved performance\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train))\nvalid_dataset = tf.data.Dataset.from_tensor_slices((x_test, y_test))\n\ntrain_dataset = train_dataset.batch(batch_size).shuffle(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\nvalid_dataset = valid_dataset.batch(batch_size).shuffle(batch_size).prefetch(tf.data.experimental.AUTOTUNE)","789c4891":"# Plot some sample images\nplt.figure(figsize=(10, 10))\nfor images, labels in train_dataset.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(tf.argmax(labels[i], axis=-1)))\n        plt.axis(\"off\")","0e6072ba":"# Let's check if our augmentation pipeline is wokring or not\nplt.figure(figsize=(10, 10))\nfor images, _ in train_dataset.take(1):\n    for i in range(9):\n        augmented_images = data_augmentation(images)\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(augmented_images[0].numpy().astype(\"uint8\"))\n        plt.axis(\"off\")","55347e6f":"def resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation=\"relu\",\n                 kernel_initializer=\"he_uniform\",\n                 batch_normalization=True,\n                 conv_first=True):\n    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n\n    # Arguments\n        inputs (tensor): input tensor from input image or previous layer\n        num_filters (int): Conv2D number of filters\n        kernel_size (int): Conv2D square kernel dimensions\n        strides (int): Conv2D square stride dimensions\n        activation (string): activation name\n        batch_normalization (bool): whether to include batch normalization\n        conv_first (bool): conv-bn-activation (True) or\n            bn-activation-conv (False)\n\n    # Returns\n        x (tensor): tensor as input to the next layer\n    \"\"\"\n    conv = layers.Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer=kernel_initializer,\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = layers.BatchNormalization()(x)\n        if activation is not None:\n            if activation == \"relu\":\n                x = layers.Activation(activation)(x)\n            else:\n                x = activation(x)\n    else:\n        if batch_normalization:\n            x = layers.BatchNormalization()(x)\n        if activation is not None:\n            if activation == \"relu\":\n                x = layers.Activation(activation)(x)\n            else:\n                x = activation(x)\n        x = conv(x)\n    return x\n\n\ndef resnet_v2(input_shape, depth, num_classes=10, act=\"relu\"):\n    \"\"\"ResNet Version 2 Model builder [b]\n\n    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n    bottleneck layer\n    First shortcut connection per layer is 1 x 1 Conv2D.\n    Second and onwards shortcut connection is identity.\n    At the beginning of each stage, the feature map size is halved (downsampled)\n    by a convolutional layer with strides=2, while the number of filter maps is\n    doubled. Within each stage, the layers have the same number filters and the\n    same filter map sizes.\n    Features maps sizes:\n    conv1  : 32x32,  16\n    stage 0: 32x32,  64\n    stage 1: 16x16, 128\n    stage 2:  8x8,  256\n\n    # Arguments\n        input_shape (tensor): shape of input image tensor\n        depth (int): number of core convolutional layers\n        num_classes (int): number of classes (CIFAR10 has 10)\n\n    # Returns\n        model (Model): Keras model instance\n    \"\"\"\n    if (depth - 2) % 9 != 0:\n        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n    # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) \/ 9)\n\n    inputs = layers.Input(shape=input_shape)\n    x = data_augmentation(inputs)\n    x = layers.experimental.preprocessing.Rescaling(1.\/255)(x)\n    \n    x = resnet_layer(inputs=x,\n                     num_filters=num_filters_in,\n                     activation=act,\n                     conv_first=True)\n\n    # Instantiate the stack of residual units\n    for stage in range(3):\n        for res_block in range(num_res_blocks):\n            activation = act\n            batch_normalization = True\n            strides = 1\n            if stage == 0:\n                num_filters_out = num_filters_in * 4\n                if res_block == 0:  # first layer and first stage\n                    activation = None\n                    batch_normalization = False\n            else:\n                num_filters_out = num_filters_in * 2\n                if res_block == 0:  # first layer but not first stage\n                    strides = 2    # downsample\n\n            # bottleneck residual unit\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters_in,\n                             kernel_size=1,\n                             strides=strides,\n                             activation=activation,\n                             batch_normalization=batch_normalization,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_in,\n                             activation=activation,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_out,\n                             kernel_size=1,\n                             activation=activation,\n                             conv_first=False)\n            if res_block == 0:\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters_out,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = layers.add([x, y])\n\n        num_filters_in = num_filters_out\n\n    # Add classifier on top.\n    # v2 has BN-ReLU before Pooling\n    x = layers.BatchNormalization()(x)\n    if act==\"relu\":\n        x = layers.Activation('relu')(x)\n    else:\n        x = tf.math.sin(x)\n    x = layers.AveragePooling2D(pool_size=8)(x)\n    x = layers.Flatten()(x)\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(num_classes,\n                            activation='softmax',\n                            kernel_initializer='he_uniform')(x)\n\n    # Instantiate model.\n    model = keras.models.Model(inputs=inputs, outputs=outputs, name=model_type)\n    return model","e6ec99b0":"model = resnet_v2(input_shape=input_shape, depth=depth)\nmodel.summary()","c6208871":"def lr_schedule(epoch):\n    \"\"\"Learning Rate Schedule\n\n    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n    Called automatically every epoch as part of callbacks during training.\n\n    # Arguments\n        epoch (int): The number of epochs\n\n    # Returns\n        lr (float32): learning rate\n    \"\"\"\n    lr = 1e-3\n    if epoch > 50:\n        lr *= 1e-3\n    elif epoch > 20:\n        lr *= 1e-2\n    elif epoch > 10:\n        lr *= 1e-1\n    print('Learning rate: ', lr)\n    return lr","0f1f0a78":"callbacks = keras.callbacks.EarlyStopping(patience=10)\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=keras.optimizers.Adam(lr_schedule(0)),\n              metrics=['accuracy'])\nmodel.fit(train_dataset, epochs=epochs,validation_data=valid_dataset, callbacks=[callbacks])","017e47f2":"loss1, acc1 = model.evaluate(valid_dataset, verbose=0)\nprint(\"Validation accuracy: \", acc1)\nprint(\"Validation loss: \", loss1)","fda9840a":"model = resnet_v2(input_shape=input_shape, depth=depth, act=tf.math.sin)\nmodel.summary()","6ac57178":"model.compile(loss='categorical_crossentropy',\n              optimizer=keras.optimizers.Adam(lr_schedule(0)),\n              metrics=['accuracy'])\nmodel.fit(train_dataset, epochs=epochs,validation_data=valid_dataset, callbacks=[callbacks])","9b88d098":"loss2, acc2 = model.evaluate(valid_dataset, verbose=0)\nprint(\"Validation accuracy: \", acc2)\nprint(\"Validation loss: \", loss2)","60aa1833":"### ResNet20_v2 with sine activation","91c8e3f7":"## Augmentations","4c59f384":"## Resnet20_v2 with ReLU","24a2d410":"This is the second experiment related to SIREN. You can check out the first experiement [here](https:\/\/www.kaggle.com\/aakashnain\/siren\/).\nIn this experiment, we will be using [`ResNet20_v2`](https:\/\/keras.io\/examples\/cifar10_resnet\/) architecture and will compare the performance of `relu` and `sin` activation. \n\nThe other thing you will learn in this notebook is how to make `data augmnetation` pipeline a part of the model itself."}}