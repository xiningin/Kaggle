{"cell_type":{"2d19bafd":"code","804ac9dd":"code","e3290b2e":"code","40a2cdc4":"code","28c27206":"code","28b742e2":"code","ece4b740":"code","85b060c7":"code","8cecf072":"code","0e79c264":"code","77e7d797":"code","eeae97a9":"code","7169fdef":"code","ee367bff":"code","1a2bbda0":"code","4f220ee7":"code","cd66a911":"code","e4a7121c":"code","daf2094e":"code","84b9f38c":"code","19eca720":"code","09125694":"code","4ed462a1":"code","1e56b24c":"code","439e3dc2":"code","51ffa1eb":"code","9420a8ea":"code","ca144845":"code","2367bc84":"code","ceee31d7":"code","6b600b11":"code","d4670aa4":"code","9ae6f5ec":"markdown","80a6df3d":"markdown","41cdc7e3":"markdown","7c2a3b04":"markdown","d31caeb9":"markdown","626e82ac":"markdown","5256ca70":"markdown","2cc75ae9":"markdown","03611e92":"markdown","32f43ddd":"markdown","ddfec330":"markdown","016734f7":"markdown","fae6cc8b":"markdown","1f2020ac":"markdown","2a16c08b":"markdown","5e70381a":"markdown","7cf1eba2":"markdown","ada5a377":"markdown","916dea6e":"markdown","e76c3efd":"markdown","9975ef39":"markdown","8b5d550a":"markdown"},"source":{"2d19bafd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","804ac9dd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline","e3290b2e":"df = pd.read_csv('..\/input\/montcoalert\/911.csv')\ndf.head()","40a2cdc4":"df.info()","28c27206":"df['zip'].value_counts().head()","28b742e2":"df['twp'].value_counts().head()","ece4b740":"df['title'].nunique()","85b060c7":"df['Reason']=df['title'].apply(lambda title:title.split(':')[0])","8cecf072":"df['Reason'].value_counts()","0e79c264":"sns.countplot(x='Reason',data=df,palette='viridis')","77e7d797":"type(df['timeStamp'].iloc[0])","eeae97a9":"df['timeStamp']=pd.to_datetime(df['timeStamp'])\n","7169fdef":"df['Hour']=df['timeStamp'].apply(lambda time: time.hour)\ndf['Month']=df['timeStamp'].apply(lambda time: time.month)\ndf['Day of week']=df['timeStamp'].apply(lambda time: time.dayofweek)","ee367bff":"dmap = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}\ndf['Day of week']=df['Day of week'].map(dmap)","1a2bbda0":"sns.countplot(x='Day of week',data=df,hue='Reason')\nplt.legend(bbox_to_anchor=(1,1),loc=2)","4f220ee7":"sns.countplot(x='Month',data=df,hue='Reason')\nplt.legend(bbox_to_anchor=(1,1),loc=2)","cd66a911":"plt.figure(figsize=(10,6))\nsns.countplot(x='Hour',data=df,hue='Reason')\nplt.legend(bbox_to_anchor=(1,1),loc=2)","e4a7121c":"byM=df.groupby('Month').count()\nbyM.head()","daf2094e":"#could be any column\nbyM['twp'].plot()","84b9f38c":"data=byM.reset_index()\ndata","19eca720":"sns.lmplot(x='Month',y='twp',data=data)","09125694":"df['Date']=df['timeStamp'].apply(lambda t:t.date())","4ed462a1":"plt.figure(figsize=(12,6))\ndf.groupby('Date').count()['twp'].plot()\nplt.tight_layout()","1e56b24c":"plt.figure(figsize=(12,6))\ndf[df['Reason']=='Traffic'].groupby('Date').count()['twp'].plot()\nplt.title('Traffic')\nplt.tight_layout","439e3dc2":"plt.figure(figsize=(12,6))\ndf[df['Reason']=='EMS'].groupby('Date').count()['twp'].plot()\nplt.title('EMS')\nplt.tight_layout","51ffa1eb":"plt.figure(figsize=(12,6))\ndf[df['Reason']=='Fire'].groupby('Date').count()['twp'].plot()\nplt.title('EMS')\nplt.tight_layout","9420a8ea":"dayHour = df.groupby(by=['Day of week','Hour']).count()['Reason'].unstack()\ndayHour.head()","ca144845":"plt.figure(figsize=(12,6))\nsns.heatmap(dayHour,cmap='magma')","2367bc84":"sns.clustermap(dayHour,cmap='cividis')","ceee31d7":"dayMonth = df.groupby(by=['Day of week','Month']).count()['Reason'].unstack()\ndayMonth.head()","6b600b11":"plt.figure(figsize=(12,6))\nsns.heatmap(dayMonth,cmap='plasma')","d4670aa4":"sns.clustermap(dayMonth,cmap='viridis')","9ae6f5ec":"Now recreate this plot but create 3 separate plots with each plot representing a Reason for the 911 call","80a6df3d":" In the titles column there are \"Reasons\/Departments\" specified before the title code. These are EMS, Fire, and Traffic. Use .apply() with a custom lambda expression to create a new column called \"Reason\" that contains this string value\n \n \n \n For example, if the title column value is EMS: BACK PAINS\/INJURY , the Reason column value would be EMS. ","41cdc7e3":" Now create a simple plot off of the dataframe indicating the count of calls per month","7c2a3b04":"Create a new column called 'Date' that contains the date from the timeStamp column. You'll need to use apply along with the .date() method","d31caeb9":"Use pd.to_datetime to convert the column from strings to DateTime objects","626e82ac":" Most common Reason for a 911 call based off of this new column","5256ca70":"Same for Month","2cc75ae9":"# Top five zip codes for 911 calls","03611e92":"Same for Hour","32f43ddd":"Now create a HeatMap using this new DataFrame.","ddfec330":"# Top 5 townships (twp) for 911 calls","016734f7":"Now see if you can use seaborn's lmplot() to create a linear fit on the number of calls per month. Keep in mind you may need to reset the index to a column.","fae6cc8b":"Use seaborn to create a countplot of the Day of Week column with the hue based off of the Reason column. ","1f2020ac":" Use seaborn to create a countplot of 911 calls by Reason.","2a16c08b":"# Unique title columns","5e70381a":"Use the .map() with this dictionary to map the actual string names to the day of the week: \n\ndmap = {0:'Mon',1:'Tue',2:'Wed',3:'Thu',4:'Fri',5:'Sat',6:'Sun'}","7cf1eba2":" Now let's move on to creating heatmaps with seaborn and our data. We'll first need to restructure the dataframe so that the columns become the Hours and the Index becomes the Day of the Week. There are lots of ways to do this, but I would recommend trying to combine groupby with an unstack method. Reference the solutions if you get stuck on this!","ada5a377":"Did you notice something strange about the Plot? \n\n It is missing some months! 9,10, and 11 are not there.\n You should have noticed it was missing some Months, let's see if we can maybe fill in this information by plotting the information in another way, possibly a simple line plot that fills in the missing months, in order to do this, we'll need to do some work with pandas\n\n Now create a gropuby object called byMonth, where you group the DataFrame by the month column and use the count() method for aggregation. Use the head() method on this returned DataFrame.","916dea6e":"Now create a clustermap using this DataFrame.","e76c3efd":"What is the data type of the objects in the timeStamp column?","9975ef39":" Now repeat these same plots and operations, for a DataFrame that shows the Month as the column. ","8b5d550a":"Use .apply() to create 3 new columns called Hour, Month, and Day of Week. You will create these columns based off of the timeStamp column, reference the solutions if you get stuck on this step."}}