{"cell_type":{"acee57e3":"code","017707a1":"code","b058b64e":"code","82ac48e2":"code","69c95e2f":"code","1c66c13c":"code","6e927d5e":"code","340b0a53":"code","948a7924":"code","c3dd411b":"code","569a4f83":"code","abcc9263":"code","af70727e":"code","e0a1bf84":"code","b2da5709":"code","b5eaf5d0":"code","95474d94":"code","7b748145":"code","2182b667":"code","06599d50":"code","cd30c887":"code","3defc47d":"code","bf2bb70b":"code","9c795fbb":"code","8f471e44":"code","ee08cd6d":"code","4dd41fe4":"code","ccb17605":"code","71e66676":"code","9b142cf5":"code","dc8732f3":"code","f54e406a":"code","b875d289":"code","0b83f28b":"code","75fa464c":"code","3ed82616":"code","b09e36bc":"code","6d51eb63":"code","97bcf288":"code","ef3a88fa":"code","9a1885e0":"code","c8074581":"code","633b94d0":"code","c154477f":"code","3fe2af63":"code","1adbcd06":"code","ceb4a1ab":"code","5d98ce18":"code","57b8762d":"code","f64aab81":"code","6ffea0f1":"code","0bc72d94":"code","45e00614":"code","e0e8f0e4":"code","e4d2d6dc":"code","3f7e2b33":"code","2851885f":"code","33b59344":"code","bad68b83":"code","4b2b6f0b":"code","4ec26701":"code","cea453ef":"code","d32e83b9":"code","7f71478f":"code","df47496d":"code","0b6ba351":"code","124b44c2":"code","231526c9":"code","5d541119":"code","4eb2b734":"code","5dd86ea6":"code","40229bbd":"code","bd086f7b":"code","e5239bd9":"code","3a2d885a":"code","1cfc9c1e":"code","26fcef1d":"code","0d643fb0":"code","7f1fcee3":"code","0fef018c":"code","fe11fae7":"code","5825750d":"code","1a79d019":"code","25715c62":"code","58e0ae93":"code","f02048ad":"code","6cd3b3c8":"code","dd1fc8bc":"code","58888745":"code","55c3caa3":"code","758dded0":"code","e69ab81b":"code","44c7a9ec":"code","ef73bf5f":"code","f3383140":"code","3e952d35":"markdown","68ed7bff":"markdown","4c976978":"markdown","dda161c7":"markdown","4993fda1":"markdown","0442aaa1":"markdown","e60516b3":"markdown","d6dd781e":"markdown","577124f8":"markdown","bc317f13":"markdown","e11939c2":"markdown","9dbffc74":"markdown","f87dc84c":"markdown","2b1bd804":"markdown","63aead1e":"markdown","c8954465":"markdown","f1758b3d":"markdown","8472833a":"markdown","bfcabf0c":"markdown","68b3f25c":"markdown","9382a48e":"markdown","7ec747d2":"markdown","28b3da89":"markdown","5fdf16e5":"markdown","7561a96d":"markdown","13ad6823":"markdown","84067027":"markdown","6eba65d5":"markdown","87a3df9b":"markdown","62cca148":"markdown","c72e1e74":"markdown","0b5e99dc":"markdown","34dd884b":"markdown","68311c07":"markdown","80b3a493":"markdown","38058a80":"markdown","746cfbbe":"markdown","e2a1291a":"markdown","416844a8":"markdown","9f75f305":"markdown","91eb00e1":"markdown","937875e7":"markdown","9b43a45e":"markdown","53bd3a16":"markdown","aa50f56e":"markdown","47ba63b5":"markdown","a8caf38d":"markdown","b302f0d5":"markdown","817cc048":"markdown","3282cf84":"markdown","4d3bd7ef":"markdown","49c8bbec":"markdown","bf612dab":"markdown","826bd666":"markdown","76fd54f0":"markdown","2c1c62af":"markdown","c1515dcb":"markdown","681b3f43":"markdown","53f7175f":"markdown","f9a1c0f5":"markdown","63eaec2f":"markdown","04a18be6":"markdown","42fecf93":"markdown","d15fd58b":"markdown","db2cbc8a":"markdown","05d40761":"markdown"},"source":{"acee57e3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","017707a1":"# Read data\nimport numpy as np                           # Linear Algebra (calculate the mean and standard deviation)\nimport pandas as pd                          # manipulate data, data processing, load csv file I\/O (e.g. pd.read_csv)\n\n# Visualization\nimport matplotlib.pyplot as plt              # Visualization using matplotlib\n%matplotlib inline\nimport seaborn as sns                        # Visualization using seaborn\n\n# style\nplt.style.use(\"fivethirtyeight\")             # Set Graphs Background style using matplotlib\nsns.set_style(\"darkgrid\")                    # Set Graphs Background style using seaborn\n\nimport warnings                              # To ignore any warnings\nwarnings.filterwarnings(\"ignore\")","b058b64e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\nfrom mlxtend.plotting import plot_decision_regions\nfrom sklearn.decomposition import PCA\n\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report","82ac48e2":"df = pd.read_csv(\"\/kaggle\/input\/iris\/Iris.csv\")","69c95e2f":"import pandas_profiling as pp\npp.ProfileReport(df)","1c66c13c":"# import first & last 5 rows\ndisplay(df.head())\ndisplay(df.tail())","6e927d5e":"# Displaying the number of rows randomly\ndf.sample(10)","340b0a53":"# checking dimension (num of rows and columns) of dataset\nprint(\"iris data shape (Rows, Columns):\", df.shape)","948a7924":"# check dataframe structure like columns and its counts, datatypes & Null Values\ndisplay(df.info())","c3dd411b":"df.columns.tolist()","569a4f83":"df.describe()","abcc9263":"print('Iris-setosa')\nsetosa = df['Species'] == 'Iris-setosa'\nprint(df[setosa].describe())\n\nprint('\\nIris-versicolor')\nversicolor = df['Species'] == 'Iris-versicolor'\nprint(df[versicolor].describe())\n\nprint('\\nIris-virginica')\nvirginica = df['Species'] == 'Iris-virginica'\nprint(df[virginica].describe())","af70727e":"df['SepalLengthCm'].nunique()","e0a1bf84":"df['SepalLengthCm'].value_counts().to_frame()","b2da5709":"plt.figure(figsize=(25,15))\n\nsns.countplot(df['SepalLengthCm'])\n\nplt.xlabel('SepalLengthCm', fontsize=25, fontweight='bold')\nplt.ylabel('count', fontsize=25, fontweight='bold')\n\nplt.title('SepalLengthCm Vs Count', fontsize=30, fontweight='bold')\n\nplt.xticks(fontsize=20)\nplt.yticks(fontsize=20)\nplt.show()","b5eaf5d0":"df['SepalWidthCm'].nunique()","95474d94":"plt.figure(figsize=(10,8))\nprint(df['SepalWidthCm'].value_counts().to_frame())\ndf['SepalWidthCm'].value_counts().plot.bar()\nplt.show()","7b748145":"df['PetalLengthCm'].nunique()","2182b667":"plt.figure(figsize=(13,10))\nprint(df['PetalLengthCm'].value_counts().to_frame())\ndf['PetalLengthCm'].value_counts().plot.bar()\nplt.show()","06599d50":"df['PetalWidthCm'].nunique()","cd30c887":"plt.figure(figsize=(13,10))\nprint(df['PetalWidthCm'].value_counts().to_frame())\ndf['PetalWidthCm'].value_counts().plot.bar()\nplt.show()","3defc47d":"df['Species'].nunique()","bf2bb70b":"df['Species'].unique().tolist()","9c795fbb":"plt.figure(figsize=(20, 6))\n\ncols = ['yellowgreen', 'lightcoral','gold']\nplt.subplot(1,2,1)\nsns.countplot('Species',data=df, palette='Set1')\nplt.title('Iris Species Count',fontweight=\"bold\", size=25)\nplt.xticks(size=18)\nplt.yticks(size=18)\nplt.xlabel('Species', fontsize=20, fontweight='bold')\nplt.ylabel('Count', fontsize=20, fontweight='bold')\n\nplt.subplot(1,2,2)\ndf['Species'].value_counts().plot.pie(explode=[0.05,0.05,0.1],autopct='%1.1f%%',shadow=True, colors=cols)\nplt.title('Iris Species Count',fontweight=\"bold\", size=25)\n\nplt.show()","8f471e44":"df_Species = df.groupby(df['Species']).mean()","ee08cd6d":"plt.figure(figsize=(10,8))\ndf_Species.plot.bar()\nplt.title('Iris Data')\nplt.show()","4dd41fe4":"df.drop(\"Id\", axis=1, inplace=True)","ccb17605":"df.isnull().sum()","71e66676":"df[df.duplicated()]","9b142cf5":"df.duplicated().value_counts()","dc8732f3":"df.drop_duplicates(inplace=True)\ndf.shape","f54e406a":"df.duplicated().any()","b875d289":"# Pearson Correlation\nplt.figure(figsize=(10,8))\nsns.heatmap(df.corr(method='pearson'), cbar=False, annot=True, fmt='.2f', linewidth=0.2);","0b83f28b":"# Spearman Correlation\nplt.figure(figsize=(10,8))\nsns.heatmap(df.corr(method='spearman'), cbar=False, annot=True, fmt='.2f', linewidth=0.2);","75fa464c":"# kendall\nfig, ax = plt.subplots(1, 3, figsize=(17 , 5))\n\nfeature_lst = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\n\ncorr = df[feature_lst].corr()\n\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n\nfor idx, method in enumerate(['pearson', 'kendall', 'spearman']):\n    sns.heatmap(df[feature_lst].corr(method=method), ax=ax[idx],\n            square=True, annot=True, fmt='.2f', center=0, linewidth=2,\n            cbar=False, cmap=sns.diverging_palette(240, 10, as_cmap=True),\n            mask=mask\n           ) \n    ax[idx].set_title(f'{method.capitalize()} Correlation', loc='left', fontweight='bold')     \n\nplt.show()","3ed82616":"df.corr()['PetalWidthCm']","b09e36bc":"a = df.drop('Species', axis=1)\na.corrwith(df['PetalWidthCm']).plot(kind='bar', grid=True, figsize=(10,8), color='salmon')\nplt.title(\"Correlation with target\", fontweight='bold', size=20)\nplt.xticks(size=15, rotation=90)\nplt.yticks(size=15)\nplt.show()","6d51eb63":"plt.figure(figsize=(10,8))\nsns.boxplot(data=df, orient='h', palette='Set2');","97bcf288":"df.skew().sort_values(ascending=True)","ef3a88fa":"sns.distplot(df.SepalWidthCm, color = 'red')\nplt.show()","9a1885e0":"plt.figure(figsize = (15,10))\nfeature = df.columns[0:4]\nfor i in enumerate(feature):\n    plt.subplot(3,2, i[0]+1)\n    sns.distplot(df[i[1]], color='crimson')","c8074581":"plt.figure(figsize = (13, 9)) \ndf.boxplot()\nplt.show()","633b94d0":"# Setting color palette\ncolors = ['#D32F2F','#1976D2','#689F38']\nsns.palplot(sns.color_palette(colors))","c154477f":"plt.figure(figsize=(12,10))\nsns.scatterplot(x=\"SepalLengthCm\", y=\"SepalWidthCm\", hue=\"Species\", data=df, palette=colors, marker=\"X\")\nplt.show()","3fe2af63":"plt.figure(figsize=(9,7))\nsns.boxplot(data=df, x='Species', y='SepalLengthCm')\nplt.show()","1adbcd06":"plt.figure(figsize=(12,5))\nsns.barplot(x=df['Species'],y=df['SepalLengthCm'],data=df)\nplt.show()","ceb4a1ab":"plt.figure(figsize=(12,5))\nsns.barplot(x=df['Species'],y=df['SepalWidthCm'],data=df)\nplt.show()","5d98ce18":"plt.figure(figsize=(12,5))\nsns.barplot(x=df['Species'],y=df['PetalLengthCm'],data=df)\nplt.show()","57b8762d":"plt.figure(figsize=(12,5))\nsns.barplot(x=df['Species'],y=df['PetalWidthCm'],data=df)\nplt.show()","f64aab81":"# Boxplot    \nplt.figure(figsize=(15,10))    \nplt.subplot(2,2,1)    \nsns.boxplot(x='Species', y='SepalLengthCm', data=df)    \nplt.subplot(2,2,2)    \nsns.boxplot(x='Species', y='SepalWidthCm', data=df)    \nplt.subplot(2,2,3)    \nsns.boxplot(x='Species', y='PetalLengthCm', data=df)    \nplt.subplot(2,2,4)    \nsns.boxplot(x='Species', y='PetalWidthCm', data=df)\nplt.show()","6ffea0f1":"df.boxplot(by=\"Species\", figsize=(12, 6))\nplt.show()","0bc72d94":"# Pairplot\nsns.pairplot(df, hue='Species')\nplt.show()","45e00614":"# Pairplot\nsns.pairplot(df, hue='Species', corner=True)\nplt.show()","e0e8f0e4":"plt.figure(figsize=(15,11));\nplt.subplot(2,2,1)\nsns.violinplot(x='Species', y='SepalLengthCm', data=df)\nplt.subplot(2,2,2)\nsns.violinplot(x='Species', y='SepalWidthCm', data=df)\nplt.subplot(2,2,3)\nsns.violinplot(x='Species', y='PetalLengthCm', data=df)\nplt.subplot(2,2,4)\nsns.violinplot(x='Species', y='PetalWidthCm', data=df);","e4d2d6dc":"fig=plt.gcf()\nfig.set_size_inches(10,7)\nfig=sns.boxplot(x='Species', y='SepalLengthCm',data=df)\nfig=sns.stripplot(x='Species', y='SepalLengthCm',data=df, jitter=True, edgecolor='gray')","3f7e2b33":"# independent variable\nx = df.drop(['Species'],axis=1)\n\n# dependent variable\ny = df['Species']","2851885f":"from category_encoders import OrdinalEncoder\n\nencoder = OrdinalEncoder()\nencoder.fit(y)\ndf['Species'] = encoder.transform(y)\ndf['Species'].head()","33b59344":"# split the data into train and test data\nfrom sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,random_state=0,test_size=0.2)","bad68b83":"print(x_train.shape, x_test.shape, y_train.shape, y_test.shape)","4b2b6f0b":"list_1=[]\nfor i in range(1,21):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    preds = knn.predict(x_test)\n    scores = accuracy_score(y_test,preds)\n    list_1.append(scores)","4ec26701":"# lets plot the decisoin boundary for the kneighbors classifier\n\nknn = KNeighborsClassifier(n_neighbors=3)\npca = PCA(n_components = 2)\nX_train2 = pca.fit_transform(x_train)\n\nknn.fit(X_train2, y_train)\n\n#plt.figure(figsize=(12,5))\n#plot_decision_regions(X_train2, y_train.values, clf=knn, legend=2)\n\n#plt.xlabel(df.columns[0], size=14)\n#plt.ylabel(df.columns[1], size=14)\n#plt.title('k neighbors decision boundary', size=16)\n\n#plt.show()","cea453ef":"# Creates a confusion matrix\ncm = confusion_matrix(y_test, preds)\n\ncm_df = pd.DataFrame(cm,\n                     index = ['setosa','versicolor','virginica'], \n                     columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True)\nplt.title('KNN \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, preds)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","d32e83b9":"print(accuracy_score(y_test, preds))\nprint('\\n')\nprint(confusion_matrix(y_test, preds))\nprint('\\n')\nprint(classification_report(y_test, preds)) ","7f71478f":"svn = svm.SVC()    \nsvn.fit(x_train, y_train)    \npredictions = svn.predict(x_test)","df47496d":"print(accuracy_score(y_test, predictions))\nprint('\\n')\nprint(confusion_matrix(y_test, predictions))\nprint('\\n')\nprint(classification_report(y_test, predictions)) ","0b6ba351":"# Creates a confusion matrix\ncm = confusion_matrix(y_test, predictions)\n\ncm_df = pd.DataFrame(cm,\n                     index = ['setosa','versicolor','virginica'], \n                     columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True)\nplt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, preds)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","124b44c2":"logreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nprint('Test Accuracy for Scikit-Learn model:', accuracy_score(y_test, y_pred)* 100,'%')","231526c9":"# get importance\nimportance = logreg.coef_[0]\n\n# summarize feature importance\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","5d541119":"print(accuracy_score(y_test, y_pred))\nprint('\\n')\nprint(confusion_matrix(y_test, y_pred))\nprint('\\n')\nprint(classification_report(y_test, y_pred))","4eb2b734":"# Creates a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\ncm_df = pd.DataFrame(cm,\n                     index = ['setosa','versicolor','virginica'], \n                     columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True)\nplt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","5dd86ea6":"# initialize\nclf = RandomForestClassifier()\n\n# train the classifier using the training data\nclf.fit(x_train, y_train)","40229bbd":"# get importance\nimportance = clf.feature_importances_\n\n# summarize feature importance\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","bd086f7b":"y_pred = clf.predict(x_test)","e5239bd9":"print(accuracy_score(y_test, y_pred))\nprint('\\n')\nprint(confusion_matrix(y_test, y_pred))\nprint('\\n')\nprint(classification_report(y_test, y_pred))","3a2d885a":"# Creates a confusion matrix\ncm = confusion_matrix(y_test, y_pred)\n\ncm_df = pd.DataFrame(cm,\n                     index = ['setosa','versicolor','virginica'], \n                     columns = ['setosa','versicolor','virginica'])\n\nplt.figure(figsize=(8,6))\nsns.heatmap(cm_df, annot=True)\nplt.title('SVM Linear Kernel \\nAccuracy:{0:.3f}'.format(accuracy_score(y_test, y_pred)))\nplt.ylabel('True label')\nplt.xlabel('Predicted label')\nplt.show()","1cfc9c1e":"DCT = DecisionTreeClassifier(criterion='gini', max_depth=3)\nDCT.fit(x_train, y_train)\n\ny_pred_DCT = DCT.predict(x_test)\n\nprint('Test Accuracy for DCT model:', accuracy_score(y_test, y_pred_DCT)* 100,'%')","26fcef1d":"# get importance\nimportance = DCT.feature_importances_\n\n# summarize feature importance\nfor i,v in enumerate(importance):\n    print('Feature: %0d, Score: %.5f' % (i,v))\n\n# plot feature importance\nplt.bar([x for x in range(len(importance))], importance)\nplt.show()","0d643fb0":"DCT.classes_","7f1fcee3":"DCT.feature_importances_","0fef018c":"plt.tight_layout()\nplt.title(\"Feature importances\")\nplt.barh(x.columns, DCT.feature_importances_, 1)","fe11fae7":"pip install pydotplus","5825750d":"# Import necessary libraries for graph viz\nfrom six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\nimport graphviz\n\n# Visualize the graph\ndot_data = StringIO()\nexport_graphviz(DCT, out_file=dot_data, feature_names=x.columns,  \n                filled=True, rounded=True,\n                special_characters=True)\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \nImage(graph.create_png())","1a79d019":"# import H2O and AutoML package\nimport h2o\nfrom h2o.automl import H2OAutoML","25715c62":"# Initialize h2o\nh2o.init(\n    nthreads=-1,     # number of threads when launching a new H2O server\n    max_mem_size='16G'  # in gigabytes\n)","58e0ae93":"data = h2o.import_file('\/kaggle\/input\/iris\/Iris.csv')","f02048ad":"# Identify predictors and response\nx = ['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']\ny = 'Species'","6cd3b3c8":"# Split the data in 80:20 ratio for training and testing\ntrain, test = data.split_frame(ratios=[0.8])","dd1fc8bc":"data.head()","58888745":"# Run AutoML for 20 base models (limited to 1 hour max runtime by default)\naml = H2OAutoML(max_models=30, seed=47, max_runtime_secs=300)\naml.train(x=x, y=y, training_frame=data)","55c3caa3":"# Binary classification, the default ranking metric is Area Under the ROC Curve (AUC).\n# View the AutoML Leaderboard\nlb = aml.leaderboard\nlb.head()","758dded0":"# Get leaderboard with `extra_columns` = 'ALL'\nlb = h2o.automl.get_leaderboard(aml, extra_columns = 'ALL')\nlb","e69ab81b":"# To generate predictions on a test set, you can make predictions\n# directly on the `\"H2OAutoML\"` object or on the leader model\n# object directly\npreds = aml.predict(test)","44c7a9ec":"print (preds)","ef73bf5f":"# Print all rows instead of default (10 rows)\n# Entire leaderboard\nlb.head(rows=lb.nrows)","f3383140":"# The leader model is stored here\naml.leader","3e952d35":"- **setosa** has the **longer** Sepalwidth and **Versicolor** has **shorter** Sepalwidth","68ed7bff":"- **setosa** has the **shorter** Petallength and **Virginica** has **longer** Petallength","4c976978":"- In this case we are plotting the frequency of the three species in the Iris Dataset\n\n- We can see that there are 50 samples each of all the Iris Species in the data set.","dda161c7":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\">2. Loading Data <\/h1>","4993fda1":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> c) Loading Data <\/h1>","0442aaa1":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 15px 50px;\"> If you like the kernal.... Don't forget to upvote!!!!!!!!!!!!!!!!!!!!!! <\/h1>","e60516b3":"- After graphing the features in a pair plot, it is clear that the relationship between pairs of features of a **iris-setosa (in blue)** is distinctly different from those of the other **two species**.\n\n- There is some **overlap** in the pairwise relationships of the other two species, **iris-versicolor (brown) and iris-virginica (green)**.","d6dd781e":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\">1) Introduction <\/h1>","577124f8":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> e) PetalWidthCm <\/h1>","bc317f13":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> b. Bivariate Analysis <\/h1>","e11939c2":"- Clearly, the DeepLearning algorithm has got the maximum score.","9dbffc74":"#### Print the final ensemble constructed by auto-sklearn\nprint(cls.show_models())","f87dc84c":"- **setosa** has the **shorter** Petalwidth and **Virginica** has **longer** Petalwidth","2b1bd804":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:170%; text-align:left; \"> c) Logistic Regression <\/h1>","63aead1e":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> b) SepalLengthCm <\/h1>","c8954465":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \">Decision Tree Visualization <\/h1>","f1758b3d":"### Table Content\n\n- 1) Introduction\n\n- 2) Loading Data\n\n- 3) EDA(Exploratory Data Analysis)\n\n - i) Understand the data\n \n   - a) Pandas Profiling (Auto-EDA)\n   - b) SepalLengthCm\n   - c) SepalWidthCm\n   - d) PetalLengthCm\n   - e) PetalWidthCm\n   - f) Species\n   \n - ii) Clean the data\n \n   - a) Drop unwanted features\n   - b) Missing Values\n   - c) Identify Duplicate Values\n   \n - iii) Analysis of Relationship between variables\n \n   - a. Correlation between features\n   \n    - i) The correlation between the continuos variables\n     - Pearson Correlation\n     - Spearman Correlation\n     - Kendall Correlation\n     \n    - ii)The correlation between continuos features and target\n    \n   - b. Outliers\n   - c. Skewness and Kurtsis\n   \n - iv) Data Visualisation\n   - a. Univariate Analysis\n   - b. Bivariate Analysis\n   - c. MultiVariate Analysis\n   \n\n- 4) Modeling\n\n - a) KNN (K Nearest Neighbors)\n - b) SVM (Support Vector Machine)\n - c) Logistic Regression\n - d) Random Forest Classifier\n - e) Decision Tree Classifier\n \n\n- 5) Auto-ML (Automated Machine Learning)\n - a) Auto-Sklearn\n - b) H20-AutoML","8472833a":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> h) Printing Result <\/h1>","bfcabf0c":"import autosklearn\nprint(autosklearn.__version__)","68b3f25c":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> b. Outliers <\/h1>","9382a48e":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:180%; text-align:left;\"> i) Understand the data <\/h1>","7ec747d2":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> f) Printing the Leaderboard <\/h1>\n\n- When the AutoML processing completes, it creates a leaderboard ranking all the 30 algorithms that it has evaluated. To see the first 10 records of the leaderboard, use the following code","28b3da89":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> a) Drop unwanted features <\/h1>","5fdf16e5":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> a. Univariate Analysis <\/h1>","7561a96d":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> ii) The correlation between continuos features and target <\/h1>","13ad6823":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> d) PetalLengthCm <\/h1>","84067027":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> c) SepalWidthCm <\/h1>","6eba65d5":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> e) Applying AutoML <\/h1>\n\n- Now, we are all set for applying AutoML on our dataset. The AutoML will run for a fixed amount of time set by us and give us the optimized model. We set up the AutoML using the following statement\n - The first parameter specifies the number of models that we want to evaluate and compare\n - The second parameter specifies the time for which the algorithm runs","87a3df9b":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:170%; text-align:left; \"> d) Random Forest Classifier <\/h1>","62cca148":"<h1 style=\"background-color:green; font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 15px 50px;\">2) H20-AutoML <\/h1>","c72e1e74":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:170%; text-align:left;\"> iv. Data Visualization <\/h1>","0b5e99dc":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\">3. EDA(Exploratory Data Analysis) <\/h1>","34dd884b":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\">a. Correlation between features <\/h1>","68311c07":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 15px 50px;\">Auto-ML (Automated Machine Learning) <\/h1>","80b3a493":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:180%; text-align:left;\"> ii) Clean the data <\/h1>","38058a80":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> a) Importing AutoML <\/h1>\n\n- First import H2O and AutoML package into the project","746cfbbe":"- from above figure **setosa** has the **shorter** sepal lenght and virginica has **longer**","e2a1291a":"!pip install auto-sklearn","416844a8":"------------------------","9f75f305":"## 1. Auto-Sklearn\n## 2. H20-AutoML","91eb00e1":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> b) Initialize H2O <\/h1>","937875e7":"- We can see that Sepal Length and Sepal Width columns are normally distributed. And Petal Length and Petal Width columns have skewness in the data.\n\n- We will use Petal_length and petal_width for cluster profiling.","9b43a45e":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> c. Multivariate Analysis <\/h1>","53bd3a16":"-----------------------","aa50f56e":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> b) Missing Values <\/h1>","47ba63b5":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> g) Predicting on Test Data <\/h1>\n\n- Now, you have the models ranked, you can see the performance of the top-rated model on your test data. To do so, run the following code statement","a8caf38d":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> d) Preparing Dataset <\/h1>\n\n- We need to decide on the features and the prediction columns. We use the same features and the predication column","b302f0d5":"from sklearn.metrics import accuracy_score\ny_pred = cls.predict(x_test)","817cc048":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:180%; text-align:left;\"> iii) Analysis of Relationship between variables <\/h1>","3282cf84":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> c) Identify Duplicate Values <\/h1>","4d3bd7ef":"import autosklearn.classification\ncls = autosklearn.classification.AutoSklearnClassifier(\n    time_left_for_this_task=10*60,\n    per_run_time_limit=60,\n    n_jobs=-1)\ncls.fit(x_train, y_train)","49c8bbec":"<h1 style=\"background-color:green; font-family:newtimeroman; font-size:250%; text-align:center; border-radius: 15px 50px;\">1) Auto-Sklearn <\/h1>","bf612dab":"<h1 style=\"background-color:magenta; font-family:newtimeroman; font-size:200%; text-align:center; border-radius: 15px 50px;\">3. Modeling <\/h1>","826bd666":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:170%; text-align:left; \">b) SVM (Support Vector Machine) <\/h1>","76fd54f0":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> f) Species <\/h1>","2c1c62af":"score = accuracy_score(y_test, y_pred)\nscore","c1515dcb":"### The 4 features are\n\n- SepalLengthCm\n- SepalWidthCm\n- PetalLengthCm\n- PetalWidthCm\n\n### The target class\n\nThe flower species type is the target class and it having 3 types\n\n- Setosa\n- Versicolor\n- Virginica","681b3f43":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\"> a) Pandas Profiling (Auto-EDA) <\/h1>","53f7175f":"- **Iris dataset** is the Hello World for the Data Science, so if you have started your career in Data Science and Machine Learning you will be practicing basic ML algorithms on this famous dataset. Iris dataset contains five columns such as Petal Length, Petal Width, Sepal Length, Sepal Width and Species Type.\n\n- Iris is a flowering plant, the researchers have measured various features of the different iris flowers and recorded digitally\n\n\n- The iris dataset contains the following data\n \n - 50 samples of 3 different species of iris (150 samples total)\n \n - There are 50 observations of each species for a total of 150 observations with 4 features each (sepal length, sepal width, petal length, petal width).\n\n\n- Measurements: sepal length, sepal width, petal length, petal width\n \n - The format for the data: (sepal length, sepal width, petal length, petal width)","f9a1c0f5":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:150%; text-align:left;\">i) The correlation between the continuos variables <\/h1>","63eaec2f":"<h1 style=\"background-color:LimeGreen; font-family:newtimeroman; font-size:200%; text-align:left; \"> i) Printing the Ranking for All <\/h1>\n\n- If you want to see the ranks of all the tested algorithms, run the following code statement","04a18be6":"<h1 style=\"background-color:DeepPink; font-family:newtimeroman; font-size:170%; text-align:left;\"> c. Skewness and Kurtsis <\/h1>","42fecf93":"###   i) Model Building\n###  ii) Prediction\n### iii) Leaderboard","d15fd58b":"#### a. Pearson Correlation\n\n#### b. Spearman Correlation\n\n#### c. kendall","db2cbc8a":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:180%; text-align:left; \"> a) KNN (K Nearest Neighbors) <\/h1>","05d40761":"<h1 style=\"background-color:orange; font-family:newtimeroman; font-size:170%; text-align:left; \"> e) Decision Tree Classifier <\/h1>"}}