{"cell_type":{"020077cd":"code","1069f8e5":"code","b0aedf00":"code","d821a938":"code","021254cb":"code","73d786dc":"code","c2083644":"code","85fca738":"code","18b65a33":"code","e8e4714e":"code","60bb9fd0":"code","07779b0d":"code","e582231b":"code","2a43240c":"code","c30f02a0":"code","396aa2b9":"code","a0adb50f":"code","4142b6cb":"code","8334d17e":"code","b1a32bf1":"code","55dc1cc1":"code","249100f4":"code","181ba9ab":"code","20221c21":"code","0608dabd":"code","121192da":"code","876e7611":"code","4de5b689":"code","d05dbdc2":"code","46099b2b":"code","c9182f1b":"code","d7e6ae4a":"code","392df0cc":"code","cd57a89b":"code","fc7d5cc2":"code","c69fa384":"code","84d93662":"markdown","5db059b3":"markdown","40609c48":"markdown","c4b448e2":"markdown","f7810741":"markdown","ea9f9ba6":"markdown","4b0e6471":"markdown","f4ba1fa9":"markdown","c3f5f157":"markdown","601cd0e9":"markdown","a83b1d2f":"markdown","b1b82842":"markdown","660497be":"markdown","ddd486ac":"markdown","5cf9b286":"markdown","e7e0d11e":"markdown","55430548":"markdown","2ecd983f":"markdown","906f07c2":"markdown","bc2c0017":"markdown","c3149957":"markdown","2cd1cf1f":"markdown","e663abd3":"markdown","d68c912d":"markdown"},"source":{"020077cd":"\nimport numpy as np \nimport pandas as pd \nimport os\nprint(os.listdir(\"..\/input\"))\nimport seaborn as sns\nsns.set(rc={'figure.figsize':(18,10)})\n","1069f8e5":"data=pd.read_csv('..\/input\/heart.csv')","b0aedf00":"data.head()","d821a938":"sns.set(rc={'figure.figsize':(18,10)})\nequilibre=data['target'].value_counts()\nax=equilibre.plot.bar(title='target_count')\nax.set(xlabel='Notrhing\/heart_disease', ylabel='Count')\nprint(equilibre)\n","021254cb":"sns.set(rc={'figure.figsize':(18,10)})\nimport matplotlib as plt\ncorr=data.corr()\nax = sns.heatmap(corr,cmap='coolwarm')\n","73d786dc":"import lifelines\nfrom lifelines import KaplanMeierFitter\nfrom lifelines import CoxPHFitter","c2083644":"sns.set(rc={'figure.figsize':(18,10)})\nkmf = KaplanMeierFitter()\nkmf.fit(data['age'], data['target'], label=\"kmf.plot()\")\nax=kmf.plot()\nax.set(xlabel='Age', ylabel='Probability_nothing')","85fca738":"cph = CoxPHFitter()\ncph.fit(data, duration_col='age',  event_col='target')\n\nestimation=cph.baseline_survival_\n \nhazard=cph.baseline_cumulative_hazard_\nprint(cph.score_)\nprint(cph.summary)","18b65a33":"sns.set(rc={'figure.figsize':(18,10)})\nhazard['curve']=estimation.values\nhazard['curve1']=hazard['curve']+(hazard['baseline hazard']\/100)\nhazard['curve2']=hazard['curve']-(hazard['baseline hazard']\/100)\n\nax=hazard['curve'].plot(color='r',label='main_curve')\nhazard['curve1'].plot(color='b',alpha=0.5,ax=ax,label='error_sup')\nhazard['curve2'].plot(color='b',alpha=0.5,ax=ax,label='error_inf')\nax.set(xlabel='Age', ylabel='Probability_nothing')\nax.legend()","e8e4714e":"sns.set(rc={'figure.figsize':(18,10)})\ncph.plot()","60bb9fd0":"sns.set(rc={'figure.figsize':(18,10)})\ntotal_1=data['fbs'].loc[data['target']==0].value_counts()\ntotal_2=data['fbs'].loc[data['target']==1].value_counts()\ndf=pd.DataFrame({'nothing':total_2,'heart_disease':total_1})\nax=df.plot.bar(title='Target functiun of fbs',colormap='Accent')\nax.set(xlabel='Fbs', ylabel='Count')","07779b0d":"sns.set(rc={'figure.figsize':(18,10)})\ntotal_1=data['exang'].loc[data['target']==0].value_counts()\ntotal_2=data['exang'].loc[data['target']==1].value_counts()\ndf=pd.DataFrame({'Nothing':total_2,'Heart_diseases':total_1})\n\na=df.plot.pie(subplots=True,colormap='Set1',autopct='%.0f%%',label='',title='angina')\n","e582231b":"total_1=data['slope'].loc[data['target']==0].value_counts()\ntotal_2=data['slope'].loc[data['target']==1].value_counts()\ndf=pd.DataFrame({'Nothing':total_2,'Heart_diseases':total_1})\nsns.set(rc={'figure.figsize':(18,10)})\na=df.plot.pie(subplots=True,colormap='Set1',autopct='%.0f%%',label='',title ='slope')\n","2a43240c":"total_1=data['sex'].loc[data['target']==0].value_counts()\ntotal_2=data['sex'].loc[data['target']==1].value_counts()\ndf=pd.DataFrame({'nothing':total_2,'Heart_diseases':total_1})\n\nax=df.plot.bar(colormap='Accent',label='',title ='male vs female')\nax.set(xlabel='male\/female', ylabel='Count')","c30f02a0":"total_1=data[['sex','age','target']].loc[data['sex']==0]\ntotal_2=data[['sex','age','target']].loc[data['sex']==1]\n\nkmf = KaplanMeierFitter()\nkmf.fit(total_1['age'], total_1['target'], label=\"kmf.plot()\")\nax=kmf.plot(label='female')\n\nkmf = KaplanMeierFitter()\nkmf.fit(total_2['age'], total_2['target'], label=\"kmf.plot()\")\nkmf.plot(color='g',title='male vs female',ax=ax,label='male')\n\nax.set(xlabel='age', ylabel='Probability of good health')","396aa2b9":"\ntotal=data[['age','sex']].loc[data['target']==1]\ntotal_1=data['age'].loc[data['sex']==0].value_counts()\ntotal_2=data['age'].loc[data['sex']==1].value_counts()\nsns.set(rc={'figure.figsize':(20,12)})\n\n\ndf=pd.DataFrame({'Male':total_2,'Female':total_1})\ndf.plot.bar(title='Distribution')\n#total_2=data[['age','target']].loc[data['sex']==1]\n#group1=total_2.groupby('age').size()\n#group1.plot.bar(colormap='Accent',label='',title ='male and female by age',ax=ax,color='r',stack=True)\nax.set(xlabel='age', ylabel='Count')","a0adb50f":"data.head()\nme=np.array([24,1,0,130,170,0,0,120,0,0.62,1,0,3,0])\ndata.loc[-1] = me","4142b6cb":"cph = CoxPHFitter()\ncph.fit(data, duration_col='age',  event_col='target')\ncensored_subjects = data.loc[data['target'] == 0]","8334d17e":"unconditioned_sf = cph.predict_survival_function(censored_subjects)\nprint(unconditioned_sf.head())","b1a32bf1":"ax=unconditioned_sf[-1].plot(label='me')\nunconditioned_sf[167].plot(color='r',ax=ax,label='random')\nax.set(xlabel='age', ylabel='probability of good health')\nax.legend()","55dc1cc1":"from lifelines.utils import median_survival_times, qth_survival_times\npredictions_75 = qth_survival_times(0.75, unconditioned_sf)\npredictions_25 = qth_survival_times(0.25, unconditioned_sf)\npredictions_50 = median_survival_times(unconditioned_sf)\n","249100f4":"import matplotlib.pyplot as plt\n\nax=unconditioned_sf[-1].plot(label='me')\nunconditioned_sf[167].plot(color='y',label='random',ax=ax)\n\nplt.axvline((predictions_75[-1].values), 0,1,color='g',label='75%')\nplt.axvline((predictions_50[-1].values), 0,1,color='b',label='50%')\nplt.axvline((predictions_25[-1].values), 0,1,color='r',label='25%')\nax.set(xlabel='age', ylabel='probability of good health')\nax.legend()","181ba9ab":"data_train=(data.loc[data['target']==1]).copy()\ndata_train.drop(['target'],1,inplace=True)\nfeature=[c for c in data_train.columns if c not in ['age']]\ntarget=['age']\n\ndata_train.head()","20221c21":"train=data_train[:130]\nval=data_train[130:]","0608dabd":"from keras.layers import Activation, Dense, Dropout\nfrom sklearn.metrics import mean_absolute_error\nfrom keras.models import Sequential\n\nNN_model = Sequential()\nNN_model.add(Dense(32, kernel_initializer='normal'))\nNN_model.add(Dense(1, kernel_initializer='normal'))    \nNN_model.add(Activation('linear'))\nNN_model.compile(loss='mean_absolute_error', optimizer='adam', metrics=['mean_absolute_error'])\n\nhistory=NN_model.fit(train[feature].values, train[target].values, epochs=19, batch_size=10)\n\n\npreds = NN_model.predict(val[feature].values) \nscore = mean_absolute_error(val[target].values, preds)\nprint(score)","121192da":"fig2, ax_loss = plt.subplots()\nplt.xlabel('Epoch')\nplt.ylabel('Loss')\nplt.title('Model- Loss')\nplt.legend(['Training', 'Validation'], loc='upper right')\nplt.plot(history.history['loss'])\nplt.plot(history.history['mean_absolute_error'])\nplt.show()","876e7611":"me=np.array([1,0,130,170,0,0,120,0,0.62,1,0,3,0])\ndata_test=(data.loc[data['target']==0]).copy()\ndata_test.drop(['target'],1,inplace=True)\ndata_test.loc[-1] = me\nestimation = NN_model.predict(data_test[feature].values)\n","4de5b689":"estimation[-1]\nprint(\"A heart diseases will append at the age of: {}\".format(estimation[-1]))","d05dbdc2":"import lightgbm as lgb\nfeature=[c for c in data_train.columns if c not in ['target']]\ntarget=data['target']","46099b2b":"from sklearn.model_selection import StratifiedKFold\nfolds = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\npredict = np.zeros(len(data))\nfeature_importance_df = pd.DataFrame()","c9182f1b":"param={\n       'bagging_fraction': 0.33,\n       'boost_from_average':'false',\n       'boost': 'gbdt',\n       'max_depth': -1,\n       'metric':'auc',\n       'objective': 'binary',\n       'verbosity': 1\n    }\n","d7e6ae4a":"from sklearn.metrics import roc_auc_score\nfor fold_, (trn_idx, val_idx) in enumerate(folds.split(data.values, target.values)):\n    print(\"Fold {}\".format(fold_))\n    trn_data = lgb.Dataset(data.iloc[trn_idx][feature], label=target.iloc[trn_idx])\n    val_data = lgb.Dataset(data.iloc[val_idx][feature], label=target.iloc[val_idx])\n\n    num_round = 500\n    clf = lgb.train(param, trn_data, num_round, valid_sets = [trn_data, val_data], verbose_eval=1000, early_stopping_rounds = 50)\n    predict[val_idx] = clf.predict(data.iloc[val_idx][feature], num_iteration=clf.best_iteration)\n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = feature\n    fold_importance_df[\"importance\"] = clf.feature_importance()\n    fold_importance_df[\"fold\"] = fold_ + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    \n    \n\nprint(\"CV score: {:<8.5f}\".format(roc_auc_score(target, predict)))","392df0cc":"feature_importance_df.head()","cd57a89b":"try1=feature_importance_df.groupby(['Feature'],as_index=False).mean()\ntry1.drop(['fold'],1,inplace=True)","fc7d5cc2":"\nsns.barplot(x=\"importance\", y=\"Feature\", data=try1.sort_values(by=\"importance\", ascending=False))\nplt.title('LightGBM Features (average_for_all_fold)')","c69fa384":"me=np.array([[24,1,0,130,170,0,0,120,0,0.62,1,0,3]])\nrandom=data.iloc[1][feature]\ndisease_me=clf.predict(me,num_iteration=clf.best_iteration)\ndisease_random=clf.predict(random,num_iteration=clf.best_iteration)\nprint(\"Your result is: {}\".format(disease_me))\nprint(\"other result is: {}\".format(disease_random))","84d93662":"I don't find yet the meaning of the value 0,1,2(i will investigate later). But it's clear that the factor 1 change.It is a factor of risk for heart diseases. ","5db059b3":"here i'm surpised, i thinked women had less probabilit to contract heart diseases than men, but these curves say the contrary. I need to investigate more. I will watch the distribution per age of men and women because i have the intuition women leave older and that why they have higher probability to contract heart diseases.","40609c48":"In this part i will train a very simple NN to predict my age when i will have a heart diseases. \nI want to compare this result with my previous ones ( 65 years old)","c4b448e2":"Here you can see the 'survival curve'. It represent the propability you stay in good health in function of the time. This is a simple estimation based only on the age. To continue i will train a model to predict in how much time you risk to have  heart diseases. This one will be based on CoxPH fitter. The main advantage is the fact this fitter will take many arguments and is able to give us some weight of features . I will use this weight as a base of my analysis.","f7810741":"**Predict if someone have heart diseases**","ea9f9ba6":"we see a difference between the two class for fbs : if fbs< 120 mg\/dl you have more chance to avoid heart diseases. The ratio is near one when you are higher than 120 mg\/dl.  It can be consider as a huge augmentation of the risk.  i have search a little and 120 mg\/dl represent the limit you don't want to exceed. So it's seem logic.","4b0e6471":"I have heard that female are more resistant than men. I want with this graph investigate this myth. In the graph, this myth seems to be a reality, but i want to go further. ","f4ba1fa9":"I see that Fbs seems to be a huge factor. I will start with this one. ","c3f5f157":"**Neural network to predict my heart diseases**","601cd0e9":"Hello Kaggle,nice to meet you.This is my first kernel and i want to try the lifelines library.Don't hesitate to give me some advice if you found mistakes. This will not be a convantionnal approach in kaggle because it's not really machine learning or deep learning approach. Next i will use a  NN to compare the two aproach.  And then i will stop focussing on age and i will predict my survivability with lightgbm.","a83b1d2f":"I'm going to start with a simple model with no attribute. The model just estimate the percentage you stay in good health based on your age. (It's the Kaplan Meir fitter. I will try to made a more complex model after this one). ","b1b82842":"angina also known as angina pectoris, is the chest pain or pressure, usually due to not enough blood flow for the heart muscle. Th is is the variable i study here\nThe ratio of angina in heart_diseases ( grey part) is as expected higher than when you have nothin.  You multiplied by 4 the risk to have something if you have an angina.  If i have one advice when i see this graph, angina have not to take lightly!\n","660497be":"here i underlign that i have more old women than men old men .It can explain the previous curve. Due to the fact women leave older, they have more probability to have a diseases. ","ddd486ac":"I started this project to predict what is the probability you will have heart diseases. I want to test the lifelines library for survival analysis. I will start with a simple model. Next i will use a more complete model in order to extract the weight of variable. Then i will  extract weight as bases of my analyze.At the end i will try to predict when i will have an heart disease!!","5cf9b286":"i have lose some years with this NN!! ","e7e0d11e":"1. **Problem and approach**\n2. **Create Survival model**\n3. **Predict my survivability**\n4. **Neural network to predict the age my heart diseases**\n5. **Lightgbm to predict if someone have heart diseases **\n\n\n\n\n","55430548":" **Problem and approach**","2ecd983f":"Here you can see the survival curve. In red you have the estimation and in blue the confidence interval.This curve is based on all  different variables. like the previous curve it is the average with all values. Just under i will extract the hazard rates ( what i call weight of the variables). For instance :  in a study, men receiving the same treatment may suffer a certain complication ten times more frequently per unit time than women, giving a hazard ratio of 10.","906f07c2":"**Create Survival model**","bc2c0017":"here i see that i have a big probabilitie to contract a heart disease near my 65 year old. Not the best news for me ! . My random friend seems to be luckier than me. \n","c3149957":"**Predict my survivability**","2cd1cf1f":"Blue curve  is my survival curve. The red one is another random one for exemple. Mine seems not so cool but i have used random value in some variable. I hope it come from that !!!  in the next one i will take some threshold to define when my heart will have problem. ","e663abd3":"Don't hesitate to leave a comment if you don't like or like my kernel. (a little upvote if you are fan is welcome )","d68c912d":"I will try to predict my survivability. i'm a young man with no real health problem. the vector will be this one:\n01. age: 24\n02. sex=1 male\n03. chest pain=0\n04. trestbps=130\n05. chol=170 ( i take an average value)\n06. fbs=0 (<120)\n07. restecg=0 ( don't really know the meaning of 0 and 1 here)\n08. thalach=120\n09. exang=0 (no)\n10. oldpeak=0.62\n11. slope=1 (random value don't know what it is)\n12. ca=0\n13. thal=3"}}