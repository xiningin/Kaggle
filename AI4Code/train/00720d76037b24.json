{"cell_type":{"902f83f7":"code","4e322e4f":"code","83a07f08":"code","c42ec743":"code","a7ec086c":"code","f6c986c7":"code","6e3bc22e":"code","7eb71b05":"code","8cab4cd3":"code","9b16faf2":"code","d40cf71d":"code","55c84474":"code","6e00418f":"code","2ae25582":"code","5f39b8a9":"code","1062eac6":"code","369e25da":"code","3df97885":"code","b43f10eb":"code","1705b63a":"code","79f9a085":"code","b1fa6fee":"code","ce8f1f19":"code","0a045b63":"code","b9031763":"code","042049c0":"code","c19906ef":"code","b6181f70":"code","e8b30531":"code","de6ae2ec":"code","1b5c002e":"code","f7e3271a":"code","74b4f433":"code","b539f6ed":"code","b2c1f06d":"code","1728b80e":"code","5914bd38":"code","5a26dc4e":"code","8b95a464":"code","43aa8754":"code","0e538ad7":"code","9cc82854":"code","7765f328":"code","13ce44d5":"code","0fc0788f":"code","b2822a74":"code","b6042c0b":"code","874aa03d":"code","a0092d20":"code","9e65f917":"code","a5dd85ec":"code","3fc51bdb":"code","0c36e252":"code","ab41ff35":"code","a2da3140":"code","1fb188a2":"code","d291268d":"code","9f5f4f7e":"code","c370d09b":"code","a78366d6":"markdown","66bdaa2e":"markdown","97792d0b":"markdown","629d32eb":"markdown","2b2d490e":"markdown","b74db34e":"markdown","4c871179":"markdown","4f81ec7b":"markdown","5cafeb02":"markdown","097cb861":"markdown","822252a5":"markdown","ade335db":"markdown","5175966a":"markdown","3c4a582e":"markdown"},"source":{"902f83f7":"import numpy as np \nimport pandas as pd\nimport matplotlib.pylab as plt\nimport os\nfrom os import listdir\nfrom os.path import isfile, join","4e322e4f":"# Resized images directory\ndir_2019_images = \"\/kaggle\/input\/resizedsiimisic\/train_resized\/\"\nimages_2019 = [f for f in listdir(dir_2019_images) if isfile(join(dir_2019_images, f))]\n\n# CSV file\ntrain_df = pd.read_csv('\/kaggle\/input\/resizedsiimisic\/train.csv')","83a07f08":"train_df.head()","c42ec743":"print(\"Train shape:\", train_df.shape)","a7ec086c":"train_df.target.value_counts().rename_axis('Tipo').reset_index(name='Total de muestras')","f6c986c7":"benign = train_df.loc[train_df['target'] == 0]\nbenign.head()","6e3bc22e":"from PIL import Image \n\ndef save_images_jpg(dir_original_images, df, file):\n    dir_images = '\/kaggle\/working\/' + file + \"\/\" \n    try:\n        os.mkdir('\/kaggle\/working\/' + file)\n        print(\"Directory\", file, \"created\") \n    except FileExistsError:\n        print(\"Directory\", file, \"already exists\")\n        \n    print(\"Saving images...\")\n    total_images = len(df['image_name'])\n    total_images_saved = 0\n    \n    for image in df['image_name'].values:\n        img = Image.open(dir_original_images + image)\n        img.save(dir_images + image)\n        total_images_saved += 1\n        percentage_saved = (total_images_saved \/ total_images) * 100\n        # Every 1000 images saved, print progress\n        if total_images_saved % 1000 == 0:\n            print(\"Images saved\", percentage_saved, \"%\")\n    print(\"Images saved\")\n    \n    return df","7eb71b05":"benign = save_images_jpg(dir_2019_images, benign, \"train_resized\")","8cab4cd3":"malignant = train_df.loc[train_df['target'] == 1]\nmalignant.head()","9b16faf2":"from numpy import expand_dims\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndir_images = '\/kaggle\/working\/train_resized\/'\ntotal_images = len(malignant['image_name'])*4\ntotal_images_saved = 0\n\nfor image in malignant['image_name'].values:\n    # Load the image and convert to numpy array\n    img = load_img(dir_2019_images + image)\n    data = img_to_array(img)\n    samples = expand_dims(data, 0)\n    \n    # Get row\n    df_row = malignant[malignant['image_name'] == image]\n    # Delete old row\n    malignant = malignant.drop(malignant.loc[malignant['image_name'] == image].index)\n    \n    # Create image data augmentation generator\n    datagen = ImageDataGenerator(horizontal_flip=True, \n                                 vertical_flip=True, \n                                 rotation_range=90)\n    # Prepare iterator\n    it = datagen.flow(samples, batch_size=1)\n    \n    # Generate samples and save augmented images\n    for i in range(4):\n        batch = it.next()\n        image_aug = batch[0].astype('uint8')\n        \n        # Change image_name_i\n        image_ = image[:len(image) - 4] + '_' + str(i) + \".jpg\"\n        df_row['image_name'] = image_\n        # Append to dataframe\n        malignant = malignant.append(df_row)\n                \n        # Save augmented image\n        im = Image.fromarray(image_aug)\n        filename = str(dir_images + image_)\n        im.save(filename)\n        \n        # Every 1000 images saved, print progress\n        total_images_saved += 1\n        percentage_saved = (total_images_saved \/ total_images) * 100\n        if total_images_saved % 1000 == 0:\n            print(\"Images saved\", percentage_saved, \"%\")\n\nprint(\"Images saved\")","d40cf71d":"malignant.head()","55c84474":"new_train_df = pd.concat([benign, malignant], ignore_index=False)\nnew_train_df = new_train_df.reset_index()\n\nnew_train_df.head()","6e00418f":"new_train_df.target.value_counts().rename_axis('Tipo').reset_index(name='Total de muestras')","2ae25582":"from collections import Counter\nfrom sklearn.model_selection import train_test_split\n\nX = new_train_df\ny = new_train_df['target']","5f39b8a9":"# Split into train, validation test and calibration sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.2, \n                                                    stratify=y,\n                                                    random_state=42)\n\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, \n                                                  test_size=0.2,\n                                                  stratify=y_train,\n                                                  random_state=42)\n\nX_test, X_calib, y_test, y_calib = train_test_split(X_test, y_test, \n                                                    test_size=0.4,\n                                                    stratify=y_test,\n                                                    random_state=42)\n\n\nprint(\"Conjunto de train:\", X_train.shape)\nprint(\"Conjunto de validacion:\", X_val.shape)\nprint(\"Conjunto de prueba:\", X_test.shape)\nprint(\"Conjunto de calibracion:\", X_calib.shape)\nprint(\"-----------------------\")\nprint('Distribucion de train ->', Counter(y_train))\nprint('Distribucion de validacion ->', Counter(y_val))\nprint(\"Distribucion de prueba ->\", Counter(y_test))\nprint(\"Distribucion de calibracion ->\", Counter(y_calib))","1062eac6":"X_train.to_csv('\/kaggle\/working\/train.csv', index=False)\nX_val.to_csv('\/kaggle\/working\/val.csv', index=False)\nX_calib.to_csv('\/kaggle\/working\/calib.csv', index=False)\nX_test.to_csv('\/kaggle\/working\/test.csv', index=False)","369e25da":"X_train[\"target\"] = X_train['target'].astype(str)\nX_val[\"target\"] = X_val['target'].astype(str)\nX_calib[\"target\"] = X_calib['target'].astype(str)\nX_test[\"target\"] = X_test['target'].astype(str)","3df97885":"import tensorflow as tf\nfrom tensorflow.keras.layers.experimental import preprocessing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import DenseNet121\nfrom tensorflow.keras.layers import Input, Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.metrics import TruePositives, FalsePositives, TrueNegatives, FalseNegatives, AUC\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import BinaryCrossentropy\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.models import Model","b43f10eb":"datagen = ImageDataGenerator(rescale=1.\/255.)\n\ntrain_generator = datagen.flow_from_dataframe(\n    dataframe=X_train,\n    directory=dir_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"binary\"\n)\n\nvalid_generator = datagen.flow_from_dataframe(\n    dataframe=X_val,\n    directory=dir_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"binary\"\n)\n\ncalib_generator = datagen.flow_from_dataframe(\n    dataframe=X_calib,\n    directory=dir_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=True,\n    class_mode=\"binary\"\n)\n\ntest_generator = datagen.flow_from_dataframe(\n    dataframe=X_test,\n    directory=dir_images,\n    x_col=\"image_name\",\n    y_col=\"target\",\n    batch_size=32,\n    seed=42,\n    shuffle=False,\n    class_mode=\"binary\"\n)\n\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VALID = valid_generator.n\/\/valid_generator.batch_size\nSTEP_SIZE_CALIB = calib_generator.n\/\/calib_generator.batch_size\nSTEP_SIZE_TEST = test_generator.n\/\/test_generator.batch_size","1705b63a":"encoder = DenseNet121(input_shape=(None,None,3), \n                      include_top=False, \n                      weights='imagenet')","79f9a085":"inputs = Input(shape=(None, None, 3))\nx = encoder(inputs, training=False)\nx = GlobalAveragePooling2D()(x)\npredictions = Dense(1, activation='sigmoid')(x)\nmodel_oversampling = Model(inputs=inputs, outputs=predictions)","b1fa6fee":"model_oversampling.summary()","ce8f1f19":"METRICS = [\n      TruePositives(name='tp'),\n      FalsePositives(name='fp'),\n      TrueNegatives(name='tn'),\n      FalseNegatives(name='fn'),\n      AUC(name='auc')\n]","0a045b63":"checkpoint_filepath = '\/kaggle\/working\/oversampling_model.h5'\nmodel_checkpoint_callback = ModelCheckpoint(filepath=checkpoint_filepath,\n                                            monitor='val_auc',\n                                            mode='max',\n                                            verbose=1,\n                                            save_best_only=True)","b9031763":"model_oversampling.compile(\n    optimizer=Adam(),\n    loss=BinaryCrossentropy(),\n    metrics=METRICS\n)","042049c0":"history = model_oversampling.fit(train_generator,  \n                                 validation_data =valid_generator,\n                                 steps_per_epoch=STEP_SIZE_TRAIN, \n                                 validation_steps=STEP_SIZE_VALID,\n                                 callbacks=[model_checkpoint_callback],\n                                 epochs = 100)","c19906ef":"plt.plot(history.history['auc'], \n         label='Training AUC (area = {:.3f})'.format(history.history['auc'][-1]))\nplt.plot(history.history['val_auc'], \n         label='Validation AUC (area = {:.3f})'.format(history.history['val_auc'][-1]))\nplt.title('Model oversampling')\nplt.ylabel('AUC')\nplt.xlabel('epoch')\nplt.grid()\nplt.legend(loc='best')\n\nplt.show()","b6181f70":"plt.plot(history.history['loss'], label='Training loss (loss = {:.3f})'.format(history.history['loss'][-1]))\nplt.plot(history.history['val_loss'], label='Validation loss (loss = {:.3f})'.format(history.history['val_loss'][-1]))\nplt.title('Model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.grid()\nplt.legend(loc='best')\n\nplt.show()","e8b30531":"eval_metrics = model_oversampling.evaluate(test_generator,\n                                           steps=STEP_SIZE_TEST,\n                                           return_dict=True,\n                                           use_multiprocessing=False,\n                                           verbose=1)","de6ae2ec":"true_labels = test_generator.classes\npredict = model_oversampling.predict(test_generator, \n                                     verbose=1)","1b5c002e":"from sklearn import metrics\nimport scikitplot as skplt\n\nfpr, tpr, tr = metrics.roc_curve(true_labels,predict)\nauc = metrics.roc_auc_score(true_labels, predict)\nplt.plot(fpr,tpr,'b',label=\"AUC=\"+str(auc))\nplt.plot([0,1],[0,1],'k--')\nplt.title('Test evaluation')\nplt.grid()\nplt.legend(loc='best')\nplt.show()","f7e3271a":"import seaborn as sns\n\ncm = [eval_metrics['tn'],eval_metrics['fp'],eval_metrics['fn'],eval_metrics['tp']]\n\ngroup_names = ['True Neg','False Pos','False Neg','True Pos']\ngroup_counts = [\"{0:0.0f}\".format(value) for value in cm]\ngroup_percentages = [\"{0:.2%}\".format(value) for value in cm\/np.sum(cm)]\nlabels = [f\"{v1}\\n{v2}\\n{v3}\" for v1, v2, v3 in zip(group_names,group_counts,group_percentages)]\nlabels = np.asarray(labels).reshape(2,2)\n\nsns.heatmap([[cm[0], cm[1]], [cm[2], cm[3]]], annot=labels, fmt='', cmap='Blues')","74b4f433":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.isotonic import IsotonicRegression\nfrom sklearn.metrics import brier_score_loss, log_loss\n!pip install ml_insights\nimport ml_insights as mli\n!pip install betacal\nfrom betacal import BetaCalibration","b539f6ed":"true_labels_test = y_test\npredict_oversampling_test = model_oversampling.predict(test_generator, verbose=1)\n\ntrue_labels_calib = y_calib\npredict_oversampling_calib = model_oversampling.predict(calib_generator, verbose=1)","b2c1f06d":"print('Calibracion Brier Score:', brier_score_loss(true_labels_calib, predict_oversampling_calib))\nprint(\"-----------------------\")\nprint('Test Brier Score:', brier_score_loss(true_labels_test, predict_oversampling_test))","1728b80e":"def plot_reliability_diagram(true_labels, predict_labels):\n    plt.figure(figsize=(15,5))\n    rd = mli.plot_reliability_diagram(true_labels, predict_labels, show_histogram=True)\n    return rd","5914bd38":"rd = plot_reliability_diagram(np.array(true_labels_calib), predict_oversampling_calib.ravel())\nplt.title('Reliability Diagram on Calibration Data')","5a26dc4e":"rd = plot_reliability_diagram(np.array(true_labels_test), predict_oversampling_test.ravel())\nplt.title('Reliability Diagram on Test Data')","8b95a464":"# Fit Platt scaling (logistic calibration)\nlr = LogisticRegression(C=99999999999, solver='lbfgs')\nlr.fit(predict_oversampling_calib.reshape(-1,1), np.array(true_labels_calib))","43aa8754":"calibset_platt_probs = lr.predict_proba(predict_oversampling_calib.reshape(-1,1))[:,1]\ntestset_platt_probs = lr.predict_proba(predict_oversampling_test.reshape(-1,1))[:,1]","0e538ad7":"iso = IsotonicRegression(out_of_bounds = 'clip')\niso.fit(predict_oversampling_calib.ravel(), np.array(true_labels_calib))","9cc82854":"calibset_iso_probs = iso.predict(predict_oversampling_calib.ravel())\ntestset_iso_probs = iso.predict(predict_oversampling_test.ravel())","7765f328":"# Fit three-parameter beta calibration\nbc = BetaCalibration()\nbc.fit(predict_oversampling_calib.ravel(), np.array(true_labels_calib))","13ce44d5":"calibset_bc_probs = bc.predict(predict_oversampling_calib.ravel())\ntestset_bc_probs = bc.predict(predict_oversampling_test.ravel())","0fc0788f":"# Define SplineCalib object\nsplinecalib = mli.SplineCalib()\nsplinecalib.fit(predict_oversampling_calib.ravel(), np.array(true_labels_calib))","b2822a74":"calibset_splinecalib_probs = splinecalib.predict(predict_oversampling_calib.ravel())\ntestset_splinecalib_probs = splinecalib.predict(predict_oversampling_test.ravel())","b6042c0b":"mli.plot_reliability_diagram(np.array(true_labels_test), predict_oversampling_test.ravel())\nplt.title('Reliability Diagram on Test Data\\n before Platt Calibration')","874aa03d":"mli.plot_reliability_diagram(np.array(true_labels_test), testset_platt_probs)\nplt.title('Reliability Diagram on Test Data\\n after Platt Calibration')","a0092d20":"mli.plot_reliability_diagram(np.array(true_labels_calib), predict_oversampling_calib.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, iso.predict(tvec), label='Isotonic')\nplt.title('Isotonic Calibration Curve on Calibration Data')","9e65f917":"mli.plot_reliability_diagram(np.array(true_labels_test), predict_oversampling_test.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, iso.predict(tvec), label='Isotonic')\nplt.title('Isotonic Calibration Curve on Test Data')","a5dd85ec":"mli.plot_reliability_diagram(np.array(true_labels_test), testset_iso_probs)\nplt.title('Reliability Diagram on Test Data\\n after Isotonic Calibration')","3fc51bdb":"mli.plot_reliability_diagram(np.array(true_labels_calib), predict_oversampling_calib.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, bc.predict(tvec))\nplt.title('Beta Calibration Curve on Calibration Set')","0c36e252":"mli.plot_reliability_diagram(np.array(true_labels_test), predict_oversampling_test.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, bc.predict(tvec))\nplt.title('Beta Calibration Curve on Test Set')","ab41ff35":"mli.plot_reliability_diagram(np.array(true_labels_test), testset_bc_probs)\nplt.title('Reliability Diagram on Test Data\\n after Beta Calibration')","a2da3140":"mli.plot_reliability_diagram(np.array(true_labels_calib), predict_oversampling_calib.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, splinecalib.predict(tvec))\nplt.title('SplineCalib Calibration Curve on Calibration Set')","1fb188a2":"mli.plot_reliability_diagram(np.array(true_labels_test), predict_oversampling_test.ravel())\n#tvec = np.linspace(.01, .99, 99)\n#plt.plot(tvec, splinecalib.predict(tvec))\nplt.title('SplineCalib Calibration Curve on Test Set')","d291268d":"mli.plot_reliability_diagram(np.array(true_labels_test), testset_splinecalib_probs)\nplt.title('Reliability Diagram on Test Data\\n after SplineCalib Calibration')","9f5f4f7e":"print('Uncalibrated log_loss = {}'.format(log_loss(true_labels_test, predict_oversampling_test.ravel())))\nprint('Platt calibrated log_loss = {}'.format(log_loss(true_labels_test, testset_platt_probs)))\nprint('Isotonic calibrated log_loss = {}'.format(log_loss(true_labels_test, testset_iso_probs)))\nprint('Beta calibrated log_loss = {}'.format(log_loss(true_labels_test, testset_bc_probs)))\nprint('Spline calibrated log_loss = {}'.format(log_loss(true_labels_test, testset_splinecalib_probs)))","c370d09b":"print('Uncalibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, predict_oversampling_test.ravel())))\nprint('Platt calibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, testset_platt_probs)))\nprint('Isotonic calibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, testset_iso_probs)))\nprint('Beta calibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, testset_bc_probs)))\nprint('Spline calibrated Brier Score = {}'.format(brier_score_loss(true_labels_test, testset_splinecalib_probs)))","a78366d6":"## <font color=red>1. <\/font>Cargar las im\u00e1genes y los datos tabulares","66bdaa2e":"## <font color=red>3. <\/font>Crear y entrenar el modelo","97792d0b":"#### M\u00e9todo 4: SplineCalib","629d32eb":"## <font color=red>5. <\/font>Calibraci\u00f3n del modelo","2b2d490e":"#### M\u00e9todo 2: Isotonic Regression","b74db34e":"## <font color=red>4. <\/font>Evaluar el modelo","4c871179":"#### M\u00e9todo 1: Platt Scaling","4f81ec7b":"#### Comparaci\u00f3n de los m\u00e9todos de calibraci\u00f3n","5cafeb02":"#### Finalmente, se observa la curva ROC-AUC y la matriz de confusi\u00f3n.","097cb861":"#### M\u00e9todo 3: Beta Calibration","822252a5":"## <font color=red>2. <\/font>Sobremuestreo de las im\u00e1genes minoritarias","ade335db":"# Modelo de sobremuestreo","5175966a":"#### Se obtiene las predicciones y las etiquetas del conjunto de prueba.","3c4a582e":"#### M\u00e9tricas"}}