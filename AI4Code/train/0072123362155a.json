{"cell_type":{"c20cf85a":"code","ae6fa325":"code","55b2a684":"code","44c48213":"code","bb755a3b":"code","ef113ec9":"code","26d1810c":"code","61a76b1b":"code","c08d5e6d":"code","7094bb25":"code","55137199":"code","8d4f7a53":"code","3341b857":"code","486b2e8d":"code","5b40b1f3":"code","f05e80b1":"code","b28ba8ba":"code","109eb0ab":"code","11f5118d":"code","417ad2d9":"code","b55f6d3e":"code","f966efa0":"code","43f213fd":"code","7159f25c":"code","4a43558c":"code","a850933d":"code","451c0241":"code","30be770c":"code","fd22ecd8":"code","a70e93b8":"code","19f400fb":"markdown","29cd6cc6":"markdown","8c63ede5":"markdown","5f3666fd":"markdown","3991e0e1":"markdown","69fff615":"markdown","edc33179":"markdown","56e337fd":"markdown","eb79133d":"markdown","f5c8c84e":"markdown","4cf8f385":"markdown","6936a859":"markdown","a3458fc5":"markdown","7382d9cc":"markdown","150d658b":"markdown","3e3b5ada":"markdown","98872fe7":"markdown","c2403f4b":"markdown","086c823d":"markdown","9eb38eb6":"markdown","ec4bab3d":"markdown","a7804a32":"markdown","82bc81f2":"markdown","b6d2ebeb":"markdown","3af4cb7e":"markdown"},"source":{"c20cf85a":"# standard libs\nimport os\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport re\nimport json\n\n# plotting libs\nimport seaborn as sns\n\n# geospatial libs\nfrom mpl_toolkits.basemap import Basemap\nfrom shapely.geometry import Polygon\nimport geopandas as gpd\nimport folium\nimport plotly.graph_objects as go\nimport plotly_express as px\n\n# set in line plotly \nfrom plotly.offline import init_notebook_mode;\ninit_notebook_mode(connected=True)\n\nprint(os.getcwd())","ae6fa325":"# import corporate response data\ncc_df = pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Corporations\/Corporations Responses\/Climate Change\/2019_Full_Climate_Change_Dataset.csv')\nws_df = pd.read_csv('..\/input\/cdp-unlocking-climate-solutions\/Corporations\/Corporations Responses\/Water Security\/2019_Full_Water_Security_Dataset.csv')","55b2a684":"# import cities response df\ncities_df = pd.read_csv(\"..\/input\/cdp-unlocking-climate-solutions\/Cities\/Cities Responses\/2020_Full_Cities_Dataset.csv\")","44c48213":"# external data - import CDC social vulnerability index data - census tract level\nsvi_df = pd.read_csv(\"..\/input\/cdp-unlocking-climate-solutions\/Supplementary Data\/CDC Social Vulnerability Index 2018\/SVI2018_US.csv\")","bb755a3b":"# cities metadata - lat,lon locations for US cities\ncities_meta_df = pd.read_csv(\"..\/input\/cdp-unlocking-climate-solutions\/Supplementary Data\/Simple Maps US Cities Data\/uscities.csv\")\n\n# cities metadata - CDP metadata on organisation HQ cities\ncities_cdpmeta_df = pd.read_csv(\"..\/input\/cdp-unlocking-climate-solutions\/Supplementary Data\/Locations of Corporations\/NA_HQ_public_data.csv\")","ef113ec9":"def list_dedupe(x):\n    \"\"\"\n    Convert list to dict and back to list to dedupe\n    \n    Parameters\n    ----------\n    x: list\n        Python list object\n        \n    Returns\n    -------\n    dictionary:\n        dictionary object with duplicates removed\n        \n    \"\"\"\n    return list(dict.fromkeys(x))","26d1810c":"cities_6_2 = cities_df[cities_df['Question Number'] == '6.2']\\\n    .rename(columns={'Organization': 'City'})\n\ncities_6_2['Response Answer'] = cities_6_2['Response Answer'].fillna('No Response')\n\ncities_6_2.head()","61a76b1b":"# state abbreviation dictionary\nus_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\n# map dict to clean full state names to abbreviations\ncities_cdpmeta_df['state'] = cities_cdpmeta_df['address_state'].map(us_state_abbrev)\n\n# infill non-matched from dict\ncities_cdpmeta_df['state'] = cities_cdpmeta_df['state'].fillna(cities_cdpmeta_df['address_state'])\ncities_cdpmeta_df['state'] = cities_cdpmeta_df['state'].replace({'ALBERTA':'AB'})\ncities_cdpmeta_df['address_city'] = cities_cdpmeta_df['address_city'].replace({'CALGARY':'Calgary'})\ncities_cdpmeta_df= cities_cdpmeta_df.drop(columns=['address_state'])\n\n# create joint city state variable\ncities_cdpmeta_df['city_state'] = cities_cdpmeta_df['address_city'].str.cat(cities_cdpmeta_df['state'],sep=\", \")\n\ncities_cdpmeta_df","c08d5e6d":"cities_count = cities_cdpmeta_df[['organization', 'address_city', 'state', 'city_state']]\\\n        .groupby(['address_city', 'state', 'city_state']).count().\\\n            sort_values(by = ['organization'],ascending = False)\\\n                .reset_index()\\\n                    .rename(columns={'organization' : 'num_orgs'})\ncities_count.head()","7094bb25":"# convert indexes to columns'\ncities_count.reset_index(inplace=True)\ncities_count = cities_count.rename(columns = {'index':'city_id'})\ncities_df.reset_index(inplace=True)\ncities_df = cities_df.rename(columns = {'index':'city_org_id'})\n\n# convert id and city label columns into lists\ncity_id_no = list_dedupe(cities_count['city_id'].tolist())\ncity_name = list_dedupe(cities_count['address_city'].tolist())\n\ncity_org_id_no = list_dedupe(cities_df['city_org_id'].tolist())\ncity_org_name = list_dedupe(cities_df['Organization'].tolist())\n\n# remove added index column in cities df\ncities_df.drop('city_org_id', inplace=True, axis=1)\ncities_count.drop('city_id', inplace=True, axis=1)\n\n# zip to join the lists and dict function to convert into dicts\ncity_dict = dict(zip(city_id_no, city_name))\ncity_org_dict = dict(zip(city_org_id_no, city_org_name))","55137199":"# compare dicts - matching when city name appears as a substring in the full city org name\ncity_names_df = pd.DataFrame(columns=['City ID No.','address_city', 'City Org ID No.','City Org', 'Match']) # initiate empty df\n\nfor ID, seq1 in city_dict.items():\n    for ID2, seq2 in city_org_dict.items():\n        m = re.search(seq1, seq2) # match string with regex search \n        if m:\n            match = m.group()\n            # Append rows in Empty Dataframe by adding dictionaries \n            city_names_df = city_names_df.append({'City ID No.': ID, 'address_city': seq1, 'City Org ID No.': ID2, 'City Org': seq2, 'Match' : match}, ignore_index=True)\n            \n# subset for city to city org name matches\ncity_names_df = city_names_df.loc[:,['address_city','City Org']]\n\ncity_names_df.head()","8d4f7a53":"cities_count  = pd.merge(cities_count, city_names_df, on='address_city', how='left')\ncities_count.head()","3341b857":"cities_6_2 = cities_6_2[['City', 'Response Answer']].rename(columns={'City' : 'City Org'})\ncities_count = pd.merge(left=cities_count, right=cities_6_2, how='left', \n                        on ='City Org').rename(columns={'Response Answer' : 'Sustainability Project Collab.'})\n\ncities_count['Sustainability Project Collab.'] = cities_count['Sustainability Project Collab.'].fillna('No Response')","486b2e8d":"cities_count_50 = cities_count.iloc[0:40,:]\n\nplt.figure(figsize=(15,8))\nax = sns.barplot(\n    x=\"city_state\", y=\"num_orgs\",\n    hue = \"Sustainability Project Collab.\",\n    data=cities_count_50 ,\n    palette=\"OrRd_r\"\n)\n\nplt.xticks(\n    rotation=45, \n    horizontalalignment='right',\n    fontweight='light',\n    fontsize='medium'  \n)\n","5b40b1f3":"# subset for lat, lng cities data\ncities_meta_df = cities_meta_df[['city', 'state_id', 'lat','lng']].rename(columns={'city' : 'address_city', 'state_id' : 'state'})\ncities_meta_df.head()","f05e80b1":"# join coordinates to cities count\ncities_count = pd.merge(left=cities_count, right=cities_meta_df, how='left', on=['address_city', 'state'])\n\n# convert text response to question 6.2 to an integar encoding \nresp_int_df = cities_count[[\"Sustainability Project Collab.\"]]\nresp_int_df= resp_int_df.rename(columns={'Sustainability Project Collab.' : 'resp_int'})\n\nlabels = resp_int_df['resp_int'].unique().tolist()\nmapping = dict( zip(labels,range(len(labels))) )\nresp_int_df.replace({'resp_int': mapping},inplace=True)\n\nresp_list = resp_int_df['resp_int'].tolist()\ncities_count['resp_int'] = resp_list \ncities_count.head()","b28ba8ba":"# plot spatial bubble map\ncities_count['text'] = cities_count['address_city'] + '<br>Number of Orgs: ' + (cities_count['num_orgs']).astype(str) +\\\n    '<br>Sustainability Project Colloboration: ' + (cities_count['Sustainability Project Collab.']).astype(str)\nlimits = [(0,20),(21,40),(41,60),(61,80),(81,100)]\ncities = []\nscale = 5\n\nfig = go.Figure()\n\nfor i in range(len(limits)):\n    lim = limits[i]\n    fig.add_trace(go.Scattergeo(\n        locationmode = 'USA-states',\n        lon = cities_count['lng'],\n        lat = cities_count['lat'],\n        text = cities_count['text'],\n        marker = dict(\n            size = cities_count['num_orgs']*scale,\n            color = cities_count['resp_int'],\n            line_color='rgb(40,40,40)',\n            line_width=0.5,\n            sizemode = 'area'\n        ),\n        name = '{0} - {1}'.format(lim[0],lim[1])))\n\nfig.update_layout(\n        title_text = '2019 CDP Climate Change Corporate Responders (Public) by City',\n        showlegend = False,\n        geo = dict(\n            scope = 'usa',\n            landcolor = 'rgb(217, 217, 217)',\n        )\n    )\n\nfig.show()","109eb0ab":"cc_2_4a = cc_df[cc_df['question_number'] == 'C2.4a']","11f5118d":"cities_cdpmeta_join = cities_cdpmeta_df[[\"account_number\", 'survey_year', 'address_city']]\ncc_2_4a = pd.merge(left=cc_2_4a, right=cities_cdpmeta_join,  left_on=['account_number','survey_year'], right_on = ['account_number','survey_year'])","417ad2d9":"cc_nyc = cc_2_4a[(cc_2_4a['address_city'] =='New York')]","b55f6d3e":"cities_6_2['City Org'] = cities_6_2['City Org'].replace({'New York City':'New York'})\ncc_nyc = pd.merge(left=cc_nyc, right= cities_6_2,  left_on=['address_city'], right_on = ['City Org']).rename(columns={'Response Answer' : 'sustain_collab'})\ncc_nyc.head()","f966efa0":"nyc_svi_df = svi_df[svi_df['STCNTY'].isin([36005, 36047, 36061, 36081, 36085])]\nnyc_svi_df['City'] = 'New York'\nprint(nyc_svi_df.shape)\nnyc_svi_df.head()","43f213fd":"# import shapefile of NYC census tracts\ngeodf = gpd.read_file('..\/input\/cdp-unlocking-climate-solutions\/Supplementary Data\/NYC CDP Census Tract Shapefiles\/nyu_2451_34505.shp')\n\n# join geospatial data to SVI unemployment rates ('E_UNEMP')\ngdf_join = geodf[['tractid', 'geometry']].to_crs('+proj=robin')\nnyc_join =  nyc_svi_df[['E_UNEMP', 'FIPS']]\ngdf_join[\"tractid\"] = pd.to_numeric(geodf[\"tractid\"])\ngdf_nyc = pd.merge(left=gdf_join, right=nyc_join, how='left', left_on='tractid', right_on = 'FIPS')\ngdf_nyc.head()","7159f25c":"# plot unemployment rate variation across NYC\ncolors = 5\ncmap = 'RdPu'\nfigsize = (16, 10)\nax = gdf_nyc.dropna().plot(column='E_UNEMP', cmap=cmap, figsize=figsize, scheme='equal_interval', k=colors, legend=True)\nax.set_title('CDV SVI Civilian (age 16+) unemployed estimate by NYC Census Tract', fontdict={'fontsize': 16}, loc='center')\nax.get_legend().set_bbox_to_anchor((.40, .8))","4a43558c":"del cc_df \ndel cities_df \ndel svi_df\ndel cities_meta_df \ndel cities_cdpmeta_df\ndel cities_6_2\ndel cities_count\ndel cc_2_4a","a850933d":"# subset for Bronx\nbb_df = nyc_svi_df[(nyc_svi_df.COUNTY =='Bronx')]\n\n# join to city and climate change response data\nprint(cc_nyc.shape)\ncc_nyc = cc_nyc.rename(columns={'City Org' : 'City'})\nnyc_df = pd.merge(cc_nyc,bb_df,on='City',how='outer')\nprint(nyc_df.shape)","451c0241":"nyc_df.head()","30be770c":"ws_df_4_1c = ws_df[ws_df['question_number'] == 'W4.1c']\nws_df_4_1c = ws_df_4_1c[ws_df_4_1c['response_value'].notnull()]\nws_df_4_1c.head()         ","fd22ecd8":"# pivot data\nws_df_4_1c_wide = ws_df_4_1c.pivot_table(index=['account_number', 'organization', 'row_number'],\n                                     columns='column_name', \n                                     values='response_value',\n                                     aggfunc=lambda x: ' '.join(x)).reset_index()\n# identify orgs with facilities within the Hudson river basin\nws_df_4_1c_wide = ws_df_4_1c_wide[ws_df_4_1c_wide['W4.1c_C2River basin'].str.contains('Hudson', na=False)]\nws_df_4_1c_wide.head()","a70e93b8":"ws_df.head()","19f400fb":"Subset SVI data for NYC Counties from Federal Information Processing Standard (FIPS) codes\n\n* The Bronx is Bronx County (ANSI \/ FIPS 36005)\n* Brooklyn is Kings County (ANSI \/ FIPS 36047)\n* Manhattan is New York County (ANSI \/ FIPS 36061)\n* Queens is Queens County (ANSI \/ FIPS 36081)\n* Staten Island is Richmond County (ANSI \/ FIPS 36085)\n\n(source: https:\/\/guides.newman.baruch.cuny.edu\/nyc_data)","29cd6cc6":"Spatial plot of cities and organisation mapping\n\n[Example bubble map with plotting with plotly](https:\/\/plotly.com\/python\/bubble-maps\/)","8c63ede5":"### Modelling\n\n#### What next?\n\nSuggested analysis and modelling techniques that you can be apply as you tackle the [competitions problem statement](https:\/\/www.kaggle.com\/c\/cdp-unlocking-climate-solutions\/overview\/description).\n\nSuggestions below are **only** a guide. You are not limited to these approaches -  use your imagination and publically available data to tackle this challenge from any angle you can dream of! \n\n\n**NLP principles to investigate the social-environmental overlap between Corporations and Cities Climate Change 'Readiness'**\n\n- Utilise pythons NLP capabilities and tokenization approaches such as [Term Frequency\u2013inverse Document Frequency (TF-IDF)](https:\/\/medium.com\/analytics-vidhya\/getting-started-with-nlp-tokenization-document-term-matrix-tf-idf-2ea7d01f1942) (1) to construct a Document Term Matrix (DTM) from questionnaire responses, highlighting key terms in free text answers to aid in topic identification\n\n        - e.g. summarise city 'readiness' for climate change and the hazards they anticipate (Cities Question 2.1)\n        - e.g outline the future adaptations cities must implement to prepare for environmental challenges (City Question 3.0)\n        - e.g. find common topics in examples of colloboration between cities and business on sustainability projects (City Question 6.2a)\n\n- Apply [sentiment analysis](https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC6267440\/) to detect whether a city sees opportunity (positive sentiment\/polarity) (Cities Question 6.0) or concern (negative sentiment\/polarity) (City Question 2.2) over future climate scenarios\n\n\n- Combine DTM and Sentiment analysis to build a combined KPI that incorporates measures of sentiment and susceptibility into one metric, identifying cities with high levels of percieved risk who may be open to colloboration with business as they foster climate resilience.\n\n        - e.g. Sentiment x Susceptibility  = Climate Risk Sensitivity Score\n\n\n\n**Social Accounting with Water Shadow Price Modeling**\n\nUsing external datasets and water-related risks identified by Corporations (Water Security Question W4.2), build a 'Shadow Price' of water for Corporations operating in a selection of North American cities. \n\n- A [shadow price](https:\/\/www.fir-pri-awards.org\/wp-content\/uploads\/MasterThesis_Chisem.pdf) (3) can attempt to account for the total cost of a Corporations water use, estimating all internal and external costs ,as well as exposure to water stress. \n\n- The shadow price coefficient can be combined within volumetric withdrawal data (Water Security Question W5.1a) to assign a Water Risk Cost per company, weighting corporate activties with a measure of the inersection between environmental risks and social impact.\n\n    - e.g. Water risk cost for Company  = Shadow price for Company  * Water withdrawal volume for Company \n\n\n\n**References**\n\n1. Mu\u00f1oz (2020). Getting started with NLP: Tokenization, Document-Term Matrix, TF-IDF. Medium. https:\/\/medium.com\/analytics-vidhya\/getting-started-with-nlp-tokenization-document-term-matrix-tf-idf-2ea7d01f1942\n\n2. Reyes-Menendez A, Saura JR, Alvarez-Alonso C. Understanding #WorldEnvironmentDay User Opinions in Twitter: A Topic-Based Sentiment Analysis Approach. Int J Environ Res Public Health. 2018;15(11):2537. Published 2018 Nov 13. doi:10.3390\/ijerph15112537. https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC6267440\/\n\n3. FIR-PRI. Portfolio Analysis Using Water Shadow Pricing: How Valuing Water Risk Can Reduce Carbon Emissions. https:\/\/www.fir-pri-awards.org\/wp-content\/uploads\/MasterThesis_Chisem.pdf","5f3666fd":"Reshape data\n\n- Climate change and water response datasets are often presented in long format in the CDP datasets.\n- These data sets will become more useful when widened on the 'column_name' variable, enabling you to derive measurable metrics and KPIs from questionnaire response data","3991e0e1":"Join Neighbourhood level SVI data to Corporate and City level CDP Response Data for NYC\n\ne.g for the Bronx","69fff615":"Join city_org names to city-org count table\n","edc33179":"### Helpers","56e337fd":"####  Build NYC City Specific Dataset\n\nCombine SVI dataset with CDP City Questionnaire and Organisation level 2019 Climate Change questionnaire response data\n\nE.g. :\n- Identify which organisations located within NYC see climate-related opportunities within their operations\n- Match organisations with areas of the city that suffer from high unemployment rates\n- Pinpoint areas of NYC that present an opportunity for corporate collobaration and therefore an uplift in social equity metrics","eb79133d":"City name conversion\n\n- Align City names in CDP City questionnaire response data ('City Org') with common city names that may be present in external data sets\n- e.g. 'City of Boulder' -> Boulder\n\n*Note* This data quality control step can also be addressed by using the 'City' column in the 2019_Cities_Disclosing_to_CDP.csv dataset","f5c8c84e":"#### Water Responses\n\nIdentify organisations with facilities oeprating in the Hudson river basin, flagging companies who's operations may impact NYC's major fresh water resource\n","4cf8f385":"## Data\n\n### Import Data","6936a859":"Subset for NYC HQ Cities\n","a3458fc5":"Join City Linked C2.4a response data to citys question 6.2 response data frame, matching NYC city level responses to NYC organisation level climate change questionnaire responses\n","7382d9cc":"Subset climate change questionnaire response data for question C2.4a\n\n*C2.4a Provide details of opportunities identified with the potential to have a substantive financial or strategic impact on your business.*\n\n(see [CDP Climate Change questionnaire guidance](https:\/\/guidance.cdp.net\/en\/guidance?cid=13&ctype=theme&idtype=ThemeID&incchild=1&microsite=0&otype=Questionnaire&tags=TAG-646%2CTAG-605%2CTAG-600))","150d658b":"# CDP Competition Starter Notebook\nExample data mapping, EDA and data wrangling pipeline to relate CDP Corporate response data to CDP Cities data and external data sets containing social equity data.\n\n#### Parameters\n\n#### Input\n\n**CDP Corporate Questionnaire response data sets**\n- **2019_Full_Climate_Change_Dataset.csv** = 2019 Climate Change publically disclosed questionnaire responses for North America\n- **2019_Full_Water_Security_Dataset.csv** = 2019 Water Security publically disclosed questionnaire responses for North America\n\n**CDP Cities Questionnaire response data sets**\n- **2020_-_Full_Cities_Dataset.csv** = Full 2020 Cities Questionnaire response data set\n\n**CDP Cities Meta data sets**\n- **NA_HQ_public_data.csv** = CDP curated Organisations metadata, mapping publically disclosed North American organisations to HQ city and state\n\n**External Non-CDP data sets**\n- **SVI2018_US.csv** = US Centers for Disease Control and Prevention (CDC) Social Vulnerability Index (SVI) Data for 2018 (*Census tract level*) - available publicly  bat https:\/\/www.atsdr.cdc.gov\/placeandhealth\/svi\/data_documentation_download.html\n- **SVI2018_US_COUNTY.csv** = US Centers for Disease Control and Prevention (CDC) Social Vulnerability Index (SVI) Data for 2018 (*County level*) - available publicly at https:\/\/www.atsdr.cdc.gov\/placeandhealth\/svi\/data_documentation_download.html\n- **uscities.csv** = metadata for United States cities and towns, with information such as populations size, median age and lat,lng location coordinates - available publicly at https:\/\/simplemaps.com\/data\/us-cities.\n\nSVI 2018 Documentation and Data Dictionary https:\/\/www.atsdr.cdc.gov\/placeandhealth\/svi\/documentation\/SVI_documentation_2018.html\n\n#### Output\n\nEDA and Visualisations to begin investigating the CDP competition data sets, environmental performance indicators and social-equity KPIs.\n","3e3b5ada":"Spatial Plotting\n\n- Choropleth Map of NYC SVI Data, displaying unemployment rates across NYC","98872fe7":"Plot cities containing the highest proportion of organisations disclosing to CDP\n\n- Highlight number of disclosing orgnanisations with a HQ in the city\n- Highlight the city's response to question 6.2 as bar colour\n","c2403f4b":"- Highlight number of disclosing orgnanisations with a HQ in the city via bubble size\n- Highlight city's response to question 6.2 as bubble colour and highlight in hover box","086c823d":"### Set up and Parameters","9eb38eb6":"## Calculations\n\n### Data Cleaning & EDA\n\n#### Extract City Questionnaire Response and map Cities to Organisations\n\n- Extract city response data for question *6.2 Does your city collaborate in partnership with businesses in your city on sustainability projects?*\n- Map cities to organisations who are headquartered within that city, using the NA_HQ_public_data.csv meta data file\n\n(see [CDP Cities questionnaire guidance](https:\/\/guidance.cdp.net\/en\/guidance?cid=16&ctype=theme&idtype=ThemeID&incchild=1&microsite=0&otype=Questionnaire&tags=TAG-637%2CTAG-570%2CTAG-13013%2CTAG-13002%2CTAG-13009%2CTAG-13010))\n","ec4bab3d":"Join Count of Disclosing Organisations in HQ Cities with Question 6.2 Response dataframe\n\n- Label the response variable as a city's current Sustainability Project Collaboration","a7804a32":"Summarise the cities metadata to count the number organisations (HQ) per city ","82bc81f2":"## Imports","b6d2ebeb":"Join 2019 corporate responses with organisation HQ metadata, matching climate change questionnaire organisations to their HQ city\n\n","3af4cb7e":"Clean Organisation City HQ Metadata"}}