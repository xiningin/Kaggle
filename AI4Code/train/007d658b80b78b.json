{"cell_type":{"7850a8b9":"code","da580067":"code","11bc8685":"code","f0505e66":"code","b2da562a":"code","f1499ef8":"code","88a0c95d":"code","6e4ccb4e":"code","28b38075":"code","4c102534":"code","1ee7b080":"code","c5fdb7dc":"code","7a00094e":"code","5d6efef7":"code","25e09804":"code","de483df2":"code","36f4cc5a":"code","c4d12d18":"code","2bcff9c7":"code","0ea9d723":"code","477b321d":"code","50a94ede":"code","84f95e1e":"code","cdd64d37":"code","4348c83b":"code","ffcc06e7":"code","f5c6f55f":"code","cc549fe0":"code","cf539748":"code","2570ee19":"markdown","ba745625":"markdown","36d67f67":"markdown","fe43ce15":"markdown","0cd879e3":"markdown","7db03f40":"markdown","45800bc9":"markdown","80f58567":"markdown","a11328e4":"markdown","d8f17291":"markdown","3c9127fa":"markdown","57cee4a4":"markdown","4e41c3cb":"markdown","bc7c3ebd":"markdown","e1aa139d":"markdown","6c7324d9":"markdown","337b3dbe":"markdown","8bb8c493":"markdown","c067870f":"markdown","3ce8a16d":"markdown","a68ede13":"markdown","6a52445b":"markdown","7b464b6b":"markdown","cb05d21e":"markdown"},"source":{"7850a8b9":"#Import needed libraries\nimport pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom scipy import stats\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, confusion_matrix\nimport lightgbm as lgb\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings('ignore')\n","da580067":"#Input data\ndf = pd.read_csv('..\/input\/voice.csv')","11bc8685":"df.head()","f0505e66":"#Check ratio of classes in dependent variable\ngender_dict = {'male': 0,'female': 1}\ngender_list = [gender_dict[item] for item in df.label]\n\nprint('Ratio between two classes is:', np.mean(gender_list))","b2da562a":"#Lets check the distribution of meanfreq (mean vs women)\nplt.figure()\nsns.kdeplot(df['meanfreq'][df['label']=='male'], shade=True);\nsns.kdeplot(df['meanfreq'][df['label']=='female'], shade=True);\nplt.xlabel('meanfreq value')\nplt.show()","f1499ef8":"#Print mean of each category\nprint('Male mean frequency:', np.mean(df['meanfreq'][df['label']=='male']))\nprint('Female mean frequency:', np.mean(df['meanfreq'][df['label']=='female']))","88a0c95d":"#Run the student's t-test\nmale_df = df[df['label']=='male']\nfemale_df = df[df['label']=='female']\nt2, p2 = stats.ttest_ind(male_df['meanfreq'], female_df['meanfreq'])\n\nprint('P-value:', p2)","6e4ccb4e":"#Check the distribution of meanfun (mean vs women)\nplt.figure()\nsns.kdeplot(df['meanfun'][df['label']=='male'], shade=True);\nsns.kdeplot(df['meanfun'][df['label']=='female'], shade=True);\nplt.show()","28b38075":"#Lets construct a heatmap to see which variables are very correlated\nno_label_data = df.drop(['label'], axis = 1)\ncors = no_label_data.corr()\n\nplt.figure(figsize=(12,7))\nsns.heatmap(cors, linewidths=.5, annot=True)\nplt.show()","4c102534":"plt.figure(figsize=(8,7))\nsns.boxplot(x=\"label\", y=\"dfrange\", data=df)\nplt.show()","1ee7b080":"plt.figure(figsize=(8,7))\nsns.violinplot(x=\"label\", y=\"meanfun\", data=df)\nplt.show()","c5fdb7dc":"sns.lmplot( x=\"sfm\", y=\"meanfreq\", data=df, fit_reg=False, hue='label', legend=False)\nplt.show()","7a00094e":"#Lets select fewer variables\nno_label_data_red = no_label_data[['median', 'skew', 'kurt', 'sp.ent', \n                                   'sfm', 'centroid', 'dfrange', 'modindx']]\nsns.pairplot(no_label_data_red)\nplt.show()","5d6efef7":"sns.jointplot(x=df[\"centroid\"], y=df[\"sfm\"], kind='scatter',\n              color='m', edgecolor=\"skyblue\", linewidth=1)\n\nplt.show()","25e09804":"#Jointplot alternative: 'hex'. Easily identify the area where two variables are forming a 'cloud' (the peak of their distributions)\nsns.jointplot(x=df[\"centroid\"], y=df[\"sfm\"], kind='hex',\n              color='m', edgecolor=\"skyblue\", linewidth=1)\n\nplt.show()","de483df2":"#Shuffle data \ndf = df.sample(frac=1, random_state = 42)","36f4cc5a":"#Check missing \ndf.isnull().sum().sum()","c4d12d18":"#Replace zeros with null\ndf.replace(0, np.nan, inplace=True)","2bcff9c7":"#Now lets count nulls again \ndf_null = df.isnull().sum()","0ea9d723":"plt.figure(figsize=(8,7))\ng = sns.barplot(df_null.index, df_null.values)\nlocs, labels = plt.xticks()\nplt.setp(labels, rotation=45)\nplt.ylabel('No of missing values')\nplt.show()","477b321d":"#Convert text target variable to number\ngender_dict = {'male': 0,'female': 1}\ngender_list = [gender_dict[item] for item in df.label]\n\ndf_final = df.copy() \ndf_final['label'] = gender_list","50a94ede":"#Split in train and test\ntrain_df, test_df = train_test_split(df_final, test_size=0.2, random_state = 14)","84f95e1e":"#Get input and output variables\ntrain_x = train_df.drop(['label'], axis = 1)\ntrain_y = train_df['label']\n\ntest_x = test_df.drop(['label'], axis = 1)\ntest_y = test_df['label']","cdd64d37":"#LGB model\nlgb_train = lgb.Dataset(train_x, train_y)\n\n# Specify hyper-parameters as a dict\nparams = {\n    'task': 'train',\n    'boosting_type': 'gbdt',\n    'objective': 'binary',\n    'metric': 'auc',\n    'num_leaves': 16,\n    'max_depth': 6,\n    'learning_rate': 0.1,\n    #'feature_fraction': 0.95,\n    #'bagging_fraction': 0.8,\n    #'bagging_freq': 5,\n    #'reg_alpha': 0.1,\n    #'reg_lambda': 0.1,\n    #'is_unbalance': True,\n    #'num_class': 1,\n    #'scale_pos_weight': 3.2,\n    'verbose': 1,\n}\n\n# Train LightGBM model\nprint('Start training...')\ngbm = lgb.train(params,\n                lgb_train,\n                num_boost_round=90,\n                #valid_sets= lgb_valid,\n                #early_stopping_rounds=40,\n                verbose_eval=20\n                )","4348c83b":"# Plot Importances\nprint('Plot feature importances...')\nimportances = gbm.feature_importance(importance_type='gain')  # importance_type='split'\nmodel_columns = pd.DataFrame(train_x.columns, columns=['features'])\nfeat_imp = model_columns.copy()\nfeat_imp['importance'] = importances\nfeat_imp = feat_imp.sort_values(by='importance', ascending=False)\nfeat_imp.reset_index(inplace=True)\n\nplt.figure()\nplt.barh(np.arange(feat_imp.shape[0] - 1, -1, -1), feat_imp.importance)\nplt.yticks(np.arange(feat_imp.shape[0] - 1, -1, -1), (feat_imp.features))\nplt.title(\"Feature Importances\")\nplt.ylabel('Feature')\nplt.tight_layout()\nplt.show()","ffcc06e7":"pred_lgb = gbm.predict(test_x,num_iteration=50)\npred_01 = np.where(pred_lgb > 0.5, 1, 0)","f5c6f55f":"recall_pred = recall_score(test_y, pred_01)\nprecision_pred = precision_score(test_y, pred_01)\naccuracy_pred = accuracy_score(test_y, pred_01)","cc549fe0":"print('Recall score: %0.2f' %recall_pred)\nprint('Precision score: %0.2f' %precision_pred)\nprint('Overall Accuracy: %0.2f' %accuracy_pred)","cf539748":"confusion_matrix(test_y, pred_01)","2570ee19":"### I enjoyed that! Lets run another one!","ba745625":"Highly negative correlation between average of fundamental frequency and spectral flatness. ","36d67f67":"### Violinplot: a 'modern' alternative to boxplots that better describes the data distribution","fe43ce15":"# Part 2. Modelling","0cd879e3":"### Pairplots: a quick and easily digestible way to dive into your numerical data","7db03f40":"Many outliers there outside the top whisker for males. That means that there quite many male persons that sound female-like, since they have high frequency ranges.","45800bc9":"### A quick statistical test: Student's t-test for mean equality","80f58567":"### Heatmaps for correlation visualization","a11328e4":"Missing value count says there are no missing values. But you gotta be smarter than that! Maybe another value is where null should have been.  A carefull examination of the dataset and u will see that absolute zeros should actually pertain to missing values that have been filled in. So lets replace them back to nulls and lets leave them that way since we are going to use boosted trees that can handle this situation. If we were using some other algorithm(SVMs or Neural Nets for example) we would have to fill them in properly (perhaps with median or some other technique)","d8f17291":"There is a great difference between the medians of the two distributions thus is fair to believe that meanfun will be a very powerful explanatory variable. ","3c9127fa":"The p-value is really close to zero which provides evidence against our null hypothesis of mean equality. This probably means that this feature will have explanatory power on our dependent variable","57cee4a4":"I wonder if these two means are statistically different....Lets check this out. We are going to use Student's t-test for this goal. The null hypothesis here is that the two means are equal. If the p-value of the test falls below a significance level (say 5%) we reject the null hypothesis in favor of the alternative.","4e41c3cb":"Hmm, in this case the dissimilarity between means is eye-catching; no need for statistical tests. I bet this variable will have great importance on our model!","bc7c3ebd":"### Jointplots: check data correlation and distribution in one chart","e1aa139d":"It looks like by far the most important variable is meanfun which corresponds to how high the frequency of the voice is to us people. This is expectable both from analysis but also intuitively: we expect men to have thicker, fatter voices and women thinner, high frequency voices. Lets see how that performs in new data: ","6c7324d9":"## Part 1. Visuallization ","337b3dbe":"## Part 1. Data importation and basic info","8bb8c493":"# Part 3. Conclusion \n\nFrom a quick and simple LightGBM model we got amazing results! All metrics reach levels close to 99%! The confusion matrix shows that we missclassified only 3 men as women and 5 women as men. By going through a parameter fine-tuning process (e.g. gridsearch) we might have done even better than that! \n\nI hope that you enjoyed this kernel, learnt something new and that the visuals here are useful at your own work!","c067870f":"All right, so our data set contains 50% men and 50% women. A balanced dataset is always a nice thing that makes our life easier when modelling.  ","3ce8a16d":"Now thats more like it. Mode seems to have the most missing values with about 250 values. Anyway still very little comared to our data so it should not make a great difference.","a68ede13":"### Scatterplot: all-time classic way of depicting the relation between two numerical variables","6a52445b":"# Goal of the kernel \n\nI built this kernel for three main reasons: 1) to dust my vizualization skills while waiting for a Deep Neural Network to finish training, 2) because I thought that the particular dataset is really interesting for further inclusion in cognitive systems, and 3) to show to early-stage aspiring data scientists the power of visuals in telling a story. \n\nI then performed some basic modelling to see if I could reach already accomplished accuracy levels. \n\nEnjoy and keep those thumbs up! ","7b464b6b":"### Boxplots are also nice because they contain SO much info","cb05d21e":"### kde plots - a nice alternative to histograms"}}