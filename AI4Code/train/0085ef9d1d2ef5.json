{"cell_type":{"19bc36a1":"code","78a54461":"code","c3fa88cf":"code","250fddda":"code","2005ef81":"code","9bad5b76":"code","9a027472":"code","8eac9522":"code","13f99eb4":"code","b0933a23":"code","e3779afd":"code","6a3ca295":"code","41d6381c":"code","09c279a8":"code","c863405c":"code","931861c2":"code","de3bbdfe":"code","b729c85b":"code","9998a2be":"code","0a7800e9":"code","1a46ae7e":"code","f77cac3c":"code","274a77e4":"code","dcd94b11":"code","bd43c719":"code","edc63cbc":"code","58d7e448":"code","c736a5e8":"code","80ad1830":"code","d4f9232e":"code","170574d4":"code","4da4cc0e":"code","56b66297":"code","885defaf":"code","c628d973":"markdown","191af2e1":"markdown","83a09f66":"markdown","7fb3736c":"markdown","26a9fadc":"markdown","96fd7fe7":"markdown","3baaf45d":"markdown","c6841a6b":"markdown","07e0042f":"markdown","a1f12384":"markdown","d5ca57e1":"markdown","226903fc":"markdown","9b021791":"markdown","04868e62":"markdown"},"source":{"19bc36a1":"!pip install scikit-gstat","78a54461":"# Work with Data - the main Python libraries\nimport numpy as np\nimport pandas as pd\nfrom scipy.interpolate import Rbf, interp2d\nimport datetime\n\n# For import data\nimport os\n\n# Geostatistical analysis\nimport skgstat as skg\nfrom skgstat import Variogram, OrdinaryKriging\n\n# Visualization\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.simplefilter('ignore')","c3fa88cf":"indicator_name = 'PM2.5' # 'PM2.5' or 'PM10'\ntime_interval='H' # 'H' (hour) or D' (day)\ntype_agg='max' # 'mean' or 'max'","250fddda":"#datetime_analysis = '2021-11-16 10:00:00'\ndatetime_analysis = '2021-11-27 09:00:00'  # maximum value after 2021-11-16\n#datetime_analysis = '2021-11-12 18:00:00'\n#datetime_analysis = '2021-01-23 18:00:00'  # maximum value","2005ef81":"# Import files with data from Kaggle dataset\ndataset_files = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        dataset_files.append(os.path.join(dirname, filename))\ndataset_files","9bad5b76":"len(dataset_files)","9a027472":"# Data from SaveEcoBot\nstations_about = pd.read_csv('..\/input\/air-quality-monitoring\/saveecobot_city_about_stations.csv', header=0, sep=';')\nstations_about = stations_about[stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\nstations_about","8eac9522":"def get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    # Transform indicator to SaveEcoBot variants\n    if indicator_name=='PM2.5':\n        indicator_name = 'pm25'\n    elif indicator_name=='PM10':\n        indicator_name = 'pm10'\n    \n    # Get codes station\n    id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = stations_about.loc[num,'id_ecocity']\n    if not np.isnan(id_station_ecocity):\n        id_station_ecocity = int(id_station_ecocity)\n        id_station = \"EcoCity_\" + str(id_station_ecocity)\n    else: id_station = \"SaveEcoBot_\" + str(id_station_saveecobot)\n    #print(num, id_station_saveecobot, id_station_ecocity, id_station)\n        \n    df = pd.read_csv(f\"..\/input\/air-quality-monitoring\/data_saveecobot_{id_station_saveecobot}.csv\")\n    #display(df.head())\n    df = df[df['indicator_code']==indicator_name]\n    #display(df.head())\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    #df = df.dropna().reset_index(drop=True)\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    #display(df.head())\n    # Data processing - converting data to average or maximum values per given time_interval\n    #df = df.resample('H').mean()\n    if type_agg == 'mean':\n        df = df.resample(time_interval).mean()\n    else:\n        # type_agg == 'max'\n        df = df.resample(time_interval).max()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n\n    if df.shape[1] > 1:\n        # Resample is successfull\n        #display(df.head())\n        df['network'] = str(stations_about.loc[num,'network'])\n        df['id_station'] = id_station\n        df['lat'] = float(stations_about.loc[num,'lat'])\n        df['lng'] = float(stations_about.loc[num,'lng'])\n        print(f\"Number of data for {num}th station #{id_station} is {len(df)}\")\n        #display(df)\n        #print(df.info())   \n    else:\n        print(f\"Data for {num}th station #{id_station} is bad\")\n        df = pd.DataFrame()\n    return df","13f99eb4":"%%time\ndf = pd.DataFrame()\nln = 0\nfor i in range(len(stations_about)):\n    df_i = get_data_for_indicator_of_station_from_saveecobot(stations_about, indicator_name, i)\n    #df_i.info()\n    if len(df) > 0:\n        #ln += len(df_i)\n        #print('\\n',ln)\n        df = pd.concat([df, df_i], ignore_index=True)\n    else: df = df_i\ndf = df.dropna().reset_index(drop=True)\ndf","b0933a23":"df.info()","e3779afd":"# Data from SaveEcoBot\necocity_stations_about = pd.read_csv('..\/input\/air-quality-monitoring-from-ecocity\/ecocity_about_stations_2021.csv', header=0, sep=';')\necocity_stations_about","6a3ca295":"ecocity_stations_about_region = ecocity_stations_about[ecocity_stations_about['locality']=='Vinnytsia city'].reset_index(drop=True)\necocity_stations_about_region['id_ecocity'] = ecocity_stations_about_region['id_ecocity'].astype('int')\necocity_stations_about_region","41d6381c":"def get_data_for_indicator_of_station_from_ecocity(stations_about, indicator_name, num):\n    # Get data for given indicator_name for station in num-th row in the dataframe saveecobot files\n    # with parameters about stations from the dataframe stations_about\n    \n    #id_station_saveecobot = int(stations_about.loc[num,'id_saveecobot'])\n    id_station_ecocity = int(stations_about.loc[num,'id_ecocity'])\n    \n    # Find file name\n    for i in range(len(dataset_files)):\n        if dataset_files[i].find(str(id_station_ecocity))>0:\n            file_name = dataset_files[i]\n    \n    df = pd.read_csv(file_name)\n    #display(df)\n    df = df[df['indicator_name']==indicator_name]\n    df['ds'] = pd.to_datetime(df['datetime'], format='%Y-%m-%d %H:%M:%S', errors='ignore')\n    df = df[['ds', 'value']]\n    df.index = df['ds']\n    df = df.drop(columns=['ds'])\n    df = df.resample('H').mean()\n    df = df.reset_index(drop=False)\n    df = df.dropna().reset_index(drop=True)\n    df['network'] = str(stations_about.loc[num,'network'])\n    #df['id_station_ecocity'] = id_station_ecocity\n    df['id_station'] = \"EcoCity_\" + str(id_station_ecocity)\n    df['lat'] = float(stations_about.loc[num,'lat'])\n    df['lng'] = float(stations_about.loc[num,'lng'])\n    #print(f\"Number of data for {num}th station #{id_station_saveecobot} in SaveEcoBot and #{id_station_ecocity} in EcoCity is {len(df)}\")\n    #display(df)\n    return df","09c279a8":"%%time\ndf2 = pd.DataFrame()\nfor i in range(len(ecocity_stations_about_region)):\n    df_i = get_data_for_indicator_of_station_from_ecocity(ecocity_stations_about_region, indicator_name, i)\n    if len(df2) > 0:\n        df2 = pd.concat([df2, df_i], ignore_index=True)\n    else: df2 = df_i\ndf2","c863405c":"df2.info()","931861c2":"# Drop data on stations of the EcoCity network from SaveEcoBot \n# with datetime which equal datetime of data from EcoCity\nif len(df)>0:\n    len_before = len(df)\n    for id_station in df2['id_station'].unique().tolist():\n        print(id_station)\n        ds_list = df2[df2['id_station']==id_station]['ds'].tolist()\n        df = df.drop(df[(df.id_station == id_station) & (df.ds.isin(ds_list))].index)\n    len_after = len(df)\n    print(f\"Number of data before the dropping duplicates - {len_before}, after - {len_after}\")","de3bbdfe":"if len(df)>0:\n    df = pd.concat([df, df2], ignore_index=True)\nelse: df = df2\ndf","b729c85b":"df.info()","9998a2be":"df.describe()","0a7800e9":"print('Download data via API of the Center for Hydrometeorology in Vinnytsia region (http:\/\/meteo.vn.ua\/api\/api.php)....under development')\n# myfile = requests.get('http:\/\/meteo.vn.ua\/api\/api')\n# open('filename', 'wb').write(myfile.content)\n# data_meteo = pd.read_json('filename')\n# data_meteo.tail(5)","1a46ae7e":"# Selection data for interpolation\nif type_agg == 'mean':\n    data = df[df['ds']==datetime.datetime.fromisoformat(datetime_analysis)].reset_index(drop=True)\nelse:\n    # type_agg == 'max':\n    datetime_analysis = 'all time'  \n    data = df[['value', 'id_station']].groupby(by=['id_station']).max()\n    data = data.reset_index(drop=False)\n    data = pd.merge(data, df[['id_station', 'lat', 'lng', 'network']], how = 'left', on = 'id_station').drop_duplicates().reset_index(drop=True)\n    \nx = data.lng.values\ny = data.lat.values\nz = data.value.values\nfig = plt.figure()\nplt.scatter(x, y)\nplt.title(f'Stations in Vinnytsia region with data for {indicator_name} in {datetime_analysis}')\ndisplay(data)\nplt.show()","f77cac3c":"data","274a77e4":"df = data[['lat', 'lng', 'value']]\ndf.columns = ['x', 'y', 'z']\ndf","dcd94b11":"%%time\n# Calculation variogram\nV = skg.Variogram(coordinates=df[['x', 'y']].values, values=df['z'].values)\nprint(V)","bd43c719":"# Variogram visualization\nV.plot()\nplt.close","edc63cbc":"# Visualization of the variogram with others parameters\nV.n_lags = 1\nV.maxlag = 5\nV.bin_func = 'kmeans'\nV.plot()\nplt.close()","58d7e448":"# Visualization of the variograms for different models\nfig, _a = plt.subplots(2,3, figsize=(18, 10), sharex=True, sharey=True)\naxes = _a.flatten()\nfor i, model in enumerate(('spherical', 'exponential', 'gaussian', 'matern', 'stable', 'cubic')):\n    V.model = model\n    V.plot(axes=axes[i], hist=False, show=False)\n    axes[i].set_title('Model: %s; RMSE: %.2f' % (model, V.rmse))","c736a5e8":"V.model = 'stable'\nok = OrdinaryKriging(V, min_points=3, max_points=5, mode='estimate')\nxx, yy = np.mgrid[0:99:100j, 0:99:100j]\nfield = ok.transform(xx.flatten(), yy.flatten()).reshape(xx.shape)\ns2 = ok.sigma.reshape(xx.shape)\n\nfig, axes = plt.subplots(1, 2, figsize=(16, 8))\nart = axes[0].matshow(field.T, origin='lower', cmap='plasma')\naxes[0].set_title('Interpolation')\naxes[0].plot(df.x, df.y, '+k')\naxes[0].set_xlim((0,100))\naxes[0].set_ylim((0,100))\nplt.colorbar(art, ax=axes[0])\nart = axes[1].matshow(s2.T, origin='lower', cmap='YlGn_r')\naxes[1].set_title('Kriging Error')\nplt.colorbar(art, ax=axes[1])\naxes[1].plot(df.x, df.y, '+w')\naxes[1].set_xlim((0,100))\naxes[1].set_ylim((0,100));","80ad1830":"def interpolate(V, ax):\n    # Thanks to https:\/\/scikit-gstat.readthedocs.io\/en\/latest\/tutorials\/02_variogram_models.html\n    \n    xx, yy = np.mgrid[0:99:100j, 0:99:100j]\n    ok = OrdinaryKriging(V, min_points=5, max_points=15, mode='exact')\n    field = ok.transform(xx.flatten(), yy.flatten()).reshape(xx.shape)\n    art = ax.matshow(field, origin='lower', cmap='plasma')\n    ax.set_title('%s model' % V.model.__name__)\n    plt.colorbar(art, ax=ax)\n    return field","d4f9232e":"fields = []\nfig, _a = plt.subplots(2,3, figsize=(18, 12), sharex=True, sharey=True)\naxes = _a.flatten()\nfor i, model in enumerate(('spherical', 'exponential', 'gaussian', 'matern', 'stable', 'cubic')):\n    V.model = model\n    fields.append(interpolate(V, axes[i]))","170574d4":"# Data interpolation\nf = interp2d(x, y, z, kind='linear')  # \u2018linear\u2019, \u2018cubic\u2019, \u2018quintic\u2019\nf","4da4cc0e":"# Calculation of values for a regular network of points\nmarginx = 0.001\nmarginy = 0.0001\nX = np.linspace(data.lng.min()*(1-marginx), data.lng.max()*(1+marginx), 100)\nY = np.linspace(data.lat.min()*(1-marginy), data.lat.max()*(1+marginy), 100)\nZ = f(X, Y)\nZ[0]","56b66297":"# Coordinates of stations - from EcoCity or no\nxseb = data[data['network']!=\"Eco-City\"]['lng'].values\nyseb = data[data['network']!=\"Eco-City\"]['lat'].values\nnumseb = data[data['network']!=\"Eco-City\"]['id_station'].astype('str').values\nxeco = data[data['network']==\"Eco-City\"]['lng'].values\nyeco = data[data['network']==\"Eco-City\"]['lat'].values\nnumeco = data[data['network']==\"Eco-City\"]['id_station'].astype('str').values","885defaf":"# Visualization\nfig = plt.figure(figsize=(12,10))\nplt.contourf(X, Y, Z)\n\nplt.scatter(xseb, yseb, c='gray', s=100, label='SaveEcoBot')\nfor i in range(len(xseb)):\n    plt.annotate(\"  \"+numseb[i], xy=(xseb[i], yseb[i]), textcoords='data')\n    \nplt.scatter(xeco, yeco, c='k', s=100, label='EcoCity')\nplt.colorbar()\nfor i in range(len(xeco)):\n    plt.annotate(\"  \"+numeco[i], xy=(xeco[i], yeco[i]), textcoords='data')\n\nplt.axis()\ntype_agg_str = 'average' if type_agg=='mean' else 'maximum'\ntime_agg_str = 'hour' if time_interval=='H' else 'D'\nplt.title(f'Stations in Vinnytsia region with {type_agg_str} data per {time_agg_str} for {indicator_name} in {datetime_analysis} (maximum value = {round(data.value.max(),2)})')\nplt.legend(loc='best')\nplt.grid()\nplt.show()","c628d973":"### 2.2 Download data from EcoCity<a class=\"anchor\" id=\"2.2\"><\/a>\n\n[Back to Table of Contents](#0.1)","191af2e1":"## 3. Geostatistical analysis with SciKit-GStat<a class=\"anchor\" id=\"3\"><\/a>\n\n[Back to Table of Contents](#0.1)","83a09f66":"**Thanks to https:\/\/www.kaggle.com\/vbmokin\/geostatistical-analysis-with-scikit-gstat**","7fb3736c":"<a class=\"anchor\" id=\"0.1\"><\/a>\n## Table of Contents\n\n1. [Import libraries](#1)\n1. [Download data](#2)\n   - [Download data from SaveEcoBot](#2.1)\n   - [Download data from EcoCity](#2.2)\n   - [Download data from the Center for Hydrometeorology in Vinnytsia region (under development)](#2.3)\n   - [Selection data for interpolation](#2.4)   \n1. [Geostatistical analysis with SciKit-GStat](#3)\n1. [Linear interpolation with scipy.interpolate.interp2d](#4)","26a9fadc":"## 2. Download data<a class=\"anchor\" id=\"2\"><\/a>\n\n[Back to Table of Contents](#0.1)","96fd7fe7":"## 4. Linear interpolation with scipy.interpolate.interp2d<a class=\"anchor\" id=\"4\"><\/a>\n\n[Back to Table of Contents](#0.1)","3baaf45d":"### 2.1 Download data from SaveEcoBot<a class=\"anchor\" id=\"2.1\"><\/a>\n\n[Back to Table of Contents](#0.1)","c6841a6b":"<a class=\"anchor\" id=\"0\"><\/a>\n# Air Quality City - 2D Analysis for Vinnytsia city with:\n* Geostatistical analysis with SciKit-GStat\n* Interpolation scipy.interpolate.interp2d","07e0042f":"## Acknowledgements\n\n### Geostatistical analysis with SciKit-GStat from the [Tutorial](https:\/\/scikit-gstat.readthedocs.io\/en\/latest\/tutorials\/tutorials.html) from \n\n**Mirko M\u00e4licke, Egil M\u00f6ller, Helge David Schneider, & Sebastian M\u00fcller. (2021, May 28).**\n\n    mmaelicke\/scikit-gstat: A scipy flavoured geostatistical variogram analysis toolbox (Version v0.6.0). Zenodo. \n\nhttp:\/\/doi.org\/10.5281\/zenodo.4835779\n\n\n### Notebooks:\n* [Geostatistical analysis with SciKit-GStat](https:\/\/www.kaggle.com\/vbmokin\/geostatistical-analysis-with-scikit-gstat)\n* [Air Quality in City - 2D Analysis](https:\/\/www.kaggle.com\/vbmokin\/air-quality-in-city-2d-analysis)\n* [Air Quality in Region - 2D Analysis](https:\/\/www.kaggle.com\/vbmokin\/air-quality-in-region-2d-analysis)\n* [Data Science for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/data-science-for-tabular-data-advanced-techniques)\n* [EDA for tabular data: Advanced Techniques](https:\/\/www.kaggle.com\/vbmokin\/eda-for-tabular-data-advanced-techniques)\n* [COVID in UA: Prophet with 4, Nd seasonality](https:\/\/www.kaggle.com\/vbmokin\/covid-in-ua-prophet-with-4-nd-seasonality)\n\n### Kaggle Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)\n\n### Other open data:\n* [Open data of the Vinnytsia City Council](https:\/\/opendata.gov.ua\/dataset\/pibehb-3a6pydhehocti-test)\n* [API of the Center for Hydrometeorology in Vinnytsia region](http:\/\/meteo.vn.ua\/api\/api.php)","a1f12384":"I hope you find this notebook useful and enjoyable.\n\nYour comments and feedback are most welcome.\n\n[Go to Top](#0)","d5ca57e1":"### 2.3 Download data from the Center for Hydrometeorology in Vinnytsia region (under development)<a class=\"anchor\" id=\"2.3\"><\/a>\n\n[Back to Table of Contents](#0.1)","226903fc":"### 2.4 Selection data for interpolation<a class=\"anchor\" id=\"2.4\"><\/a>\n\n[Back to Table of Contents](#0.1)","9b021791":"# Datasets:\n* [Air Quality Monitoring from EcoCity](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring-from-ecocity)\n* [Air Quality Monitoring](https:\/\/www.kaggle.com\/vbmokin\/air-quality-monitoring)","04868e62":"## 1. Import libraries<a class=\"anchor\" id=\"1\"><\/a>\n\n[Back to Table of Contents](#0.1)"}}