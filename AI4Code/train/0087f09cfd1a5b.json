{"cell_type":{"21b3bdfa":"code","c6bcbd64":"code","44179f82":"code","0ad96eef":"code","0dfec2c2":"code","505f1cc2":"code","9e54ee42":"code","e427bc35":"code","f4057ba2":"code","d3c1e4cc":"code","18e7b47d":"code","0bed5857":"code","27363265":"code","df30df56":"code","cf741345":"code","bf1f467b":"code","d58a4711":"code","455acf68":"code","ee15b4a4":"code","c2a8def9":"code","3e73082f":"code","842f6c66":"code","221978af":"code","52924252":"code","7161b98f":"code","5a0d6329":"code","91417d81":"code","f61f2878":"code","dcaafd3d":"code","6535e35b":"code","52315451":"code","f622447d":"code","edbe83df":"code","892d0051":"code","1589a818":"code","725349f1":"code","aef8b5e4":"code","f91485f2":"code","ac0c2ecf":"code","dba49359":"code","236e9672":"code","06ff51b0":"code","13fc64e5":"code","0ecb8ab2":"code","a4cd8a88":"code","67b8a195":"code","b6a2f639":"code","2a7f0658":"code","c569aa3f":"code","c80b1d3d":"code","55d58be3":"code","fb8bcdd9":"code","5b175097":"code","df6de556":"code","7911f284":"code","ba419881":"code","c3e2bfa4":"code","6a90b42f":"code","7a213a9a":"code","a36595d8":"markdown","8f0183a9":"markdown","766a04c2":"markdown","6b6c8bb5":"markdown","311635f8":"markdown","1a8aaf29":"markdown","314ab18a":"markdown","0c9c7347":"markdown","cd7063de":"markdown","9fa0e5c4":"markdown","eaf9baf7":"markdown","58a16d33":"markdown","9fc4737e":"markdown","aea40aaa":"markdown","c47d1365":"markdown","aa65c85b":"markdown","e97b2110":"markdown","02d6f0e2":"markdown","64f97b43":"markdown","12aef839":"markdown","0a83bb0b":"markdown","737c7c14":"markdown","0be44daa":"markdown","c2aefbf2":"markdown","b9fada65":"markdown","d2859f5f":"markdown","15cf60b3":"markdown","690b0ca4":"markdown","b7b1fda3":"markdown","ccca5324":"markdown","30131e6b":"markdown","63602cc3":"markdown","2a2ba000":"markdown","29f77f71":"markdown","987b1a6f":"markdown","ebe756aa":"markdown","c6ce9761":"markdown","271bdf4e":"markdown","6c9d0445":"markdown","efad2728":"markdown","cf7f530e":"markdown","4f863bc6":"markdown"},"source":{"21b3bdfa":"from sklearn.preprocessing import OneHotEncoder, LabelEncoder, MinMaxScaler, LabelBinarizer\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression, RidgeClassifierCV\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.svm import LinearSVC, SVC\n\nfrom mlxtend.classifier import StackingClassifier\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom lightgbm import LGBMClassifier\n\nimport plotly.express as px\nfrom matplotlib import pyplot as plt\nimport scikitplot as skplt\nimport missingno as msno\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nimport re\n\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)\npd.set_option('display.width', 1000)","c6bcbd64":"cm = [\"#273176\",\"#3B61A3\",\"#76A4AC\",\"#BFD4B2\",\"#DAD8A1\"]\ngradient = [\"#292F55\",\"#273176\",\"#223A92\",\"#3B61A3\",\"#76A4AC\",\"#BFD4B2\",\"#DAD8A1\",\"#C7B679\",\"#957447\"]\nprint(\"Gradient from the picture for this notebook\")\nsns.palplot(gradient)","44179f82":"path = \"\/kaggle\/input\/titanic\/\"\ndf_tr = pd.read_csv(f\"{path}train.csv\").set_index(\"PassengerId\", drop=True)\ndf_ts = pd.read_csv(f\"{path}test.csv\").set_index(\"PassengerId\", drop=True)\ndf = pd.concat([df_tr, df_ts], axis=0)\ndf.head(10).style.background_gradient(cmap='Blues')","0ad96eef":"msno.bar(df, figsize=(30,2), color=gradient)","0dfec2c2":"df[\"Deck\"] = df[\"Cabin\"].str[:1]\ndf[\"Deck\"] = df[\"Deck\"].replace(np.nan,\"N\/A\")\nprint(\"All Deck descriptors:\")\nprint(set(df[\"Deck\"].values))","505f1cc2":"dfplt = df.copy(deep=True)\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\ndfplt = dfplt[dfplt[\"Deck\"]!=\"N\/A\"]\nfig = px.histogram(dfplt, x=\"Deck\",color=\"Survived\",\n                   color_discrete_sequence=cm)\nfig.show()","9e54ee42":"df.loc[df[\"Deck\"]=='T',\"Deck\"] = 'N\/A'","e427bc35":"replaces = {'B51 B53 B55': 'B55', 'B52 B54 B56': 'B56', 'B57 B59 B63 B66': 'B66', 'B58 B60': 'B60', \n            'B82 B84': 'B84', 'B96 B98': 'B98', 'C22 C26': 'C26', 'C23 C25 C27': 'C27', 'C55 C57': 'C57',\n            'C62 C64': 'C64', 'D10 D12': 'D12', 'E39 E41': 'E41', 'F E46': 'E46', 'F E57': 'E57',\n            'F E69': 'E69', 'F G63': 'G63', 'F G73': 'G73', 'F': None, 'D': None, ' ': None, 'T': None, np.nan: None}\ndf[\"Cabin\"] = df[\"Cabin\"].replace(replaces)\ndf[\"Cabin\"] = df.fillna(np.nan)[\"Cabin\"].str[1:].astype(float)","f4057ba2":"dfplt = df.copy(deep=True)\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\nfig = px.histogram(dfplt, x=\"Cabin\",color=\"Survived\", height=300,\n                   color_discrete_sequence=cm)\nfig.show()","d3c1e4cc":"df[\"Side\"] = df[\"Cabin\"]\ndf.loc[df[\"Side\"]!=0,\"Side\"] = (df[\"Cabin\"][df[\"Cabin\"]!=0]%2-0.5)*2\n\ns = df[df[\"Side\"]==1]\nprint(f'Survived for side 1\\t {len(s[s[\"Survived\"]==1])\/len(s)}')\ns = df[df[\"Side\"]==-1]\nprint(f'Survived for side -1\\t {len(s[s[\"Survived\"]==1])\/len(s)}')","18e7b47d":"for i in set(df[\"Deck\"].values):\n    v = df[df[\"Deck\"]==i][\"Cabin\"]\/\/2\n    df.loc[df[\"Deck\"]==i, \"Cabin\"]= v\n    df.loc[(df[\"Deck\"]==i) & (df[\"Cabin\"]==0),\"Cabin\"] = np.median(v)\n    \ndf.loc[df[\"Cabin\"].isna(),\"Cabin\"]=-1\ndf[\"Cabin\"] = df[\"Cabin\"].astype(int)","0bed5857":"dfplt = df.copy(deep=True)\ndfplt = dfplt[~dfplt[\"Survived\"].isna()]\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\nfig = px.scatter_3d(dfplt, x=\"Cabin\", y=\"Side\", z= \"Deck\", color=\"Survived\",\n                    color_discrete_sequence=cm, size_max=6, width=1000, height=1000)\nfig.show()","27363265":"df[\"Side\"] = df[\"Side\"].fillna(0)\nmsno.bar(df, figsize=(30,2), color=cm)","df30df56":"lin_rep = lambda x: x.replace({'LINE':\"370160\"})\ndf = lin_rep(df)","cf741345":"prefixes = []\nnums, prefs = [],[]\nfor i in df[\"Ticket\"].values:   \n    if not i.isdigit():\n        nums.append(int(re.search('.* {1}([0-9]+)', i).groups()[0]))\n        prefix = re.search('(.*)( {1})[0-9]+', i).groups()[0]\n        prefs.append(prefix.replace(\".\",\"\").replace(\" \", \"\").replace(\"\/\",\"\")) # Needed to put in one group such prefixes as \"A\/5\", \"A\/5.\", \"A.5\" etc.\n    else:\n        nums.append(int(i))\n        prefs.append(\"\")\ndf[\"Ticket\"] = nums\ndf[\"Ticket_p\"] = prefs","bf1f467b":"dfplt = df.copy(deep=True)\nfig = px.scatter(dfplt.astype(str), x=\"Ticket_p\", y=\"Name\", color= \"Survived\",\n                 color_discrete_sequence=cm, size_max=6,width=1200, height=500)\nfig.show()","d58a4711":"drop = [\"SP\", \"SOP\", \"Fa\", \"SCOW\", \"PPP\", \"AS\", \"CASOTON\", \"SWPP\", \"SCAHBasle\", \"SCA3\", \"STONOQ\", \"AQ4\", \"A2\", \"LP\", \"AQ3\", \"\"]\ndf = df.replace(drop, 'N\/A')","455acf68":"dfplt = df.copy(deep=True)\ndfplt= dfplt[dfplt[\"Ticket_p\"] != \"N\/A\"]\nfig = px.scatter(dfplt.astype(str), x=\"Ticket_p\", y=\"Name\", color= \"Survived\",\n                 color_discrete_sequence=cm, size_max=6,width=1200, height=500)\nfig.show()","ee15b4a4":"df[[\"Surname\",\"Name\"]] = [i.split(\",\") for i in df[\"Name\"].values]","c2a8def9":"a = df.groupby(\"Surname\")[\"Surname\"].count()\nfam_list = a[a>1].index.values\ndf.loc[~df[\"Surname\"].isin(fam_list),\"Surname\"] = \"Other\"","3e73082f":"dfplt = df.copy(deep=True)\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\ndfplt = dfplt[dfplt[\"Surname\"]!=\"Other\"]\nfig = px.histogram(dfplt, x=\"Surname\",color=\"Survived\",color_discrete_sequence=cm)\nfig.show()","842f6c66":"df[\"Namesakes\"] = 1\ndf.loc[df[\"Surname\"]==\"Other\",\"Namesakes\"] = 0","221978af":"not_imp_s = [\"Braund\",\"Allen\",\"Moran\",\"Meyer\",\"Holverson\",\"Turpin\",\"Arnold-Franchi\",\"Panula\",\"Harris\",\"Skoog\",\"Kantor\",\"Petroff\",\"Gustafsson\",\"Zabour\",\n             \"Jussila\",\"Attalah\",\"Baxter\",\"Hickman\",\"Nasser\",\"Futrelle\",\"Navratil\",\"Calic\",\"Bourke\",\"Strom\",\"Backstrom\",\"Ali\",\"Jacobsohn\",\"Larsson\",\n             \"Carter\",\"Lobb\",\"Taussig\",\"Johnson\",\"Abelson\",\"Hart\",\"Graham\",\"Pears\",\"Barbara\",\"O'Brien\",\"Hakkarainen\",\"Van Impe\",\"Flynn\",\"Silvey\",\"Hagland\",\n             \"Morley\",\"Renouf\",\"Stanley\",\"Penasco y Castellana\",\"Webber\",\"Coleff\",\"Yasbeck\",\"Collyer\",\"Thorneycroft\",\"Jensen\",\"Newell\",\"Saad\",\"Thayer\",\"Hoyt\",\n             \"Andrews\",\"Lam\",\"Harper\",\"Nicola-Yarred\",\"Doling\",\"Hamalainen\",\"Beckwith\",\"Mellinger\",\"Bishop\",\"Hippach\",\"Richards\",\"Baclini\",\"Goldenberg\",\n             \"Beane\",\"Duff Gordon\",\"Tylor\",\"Dick\",\"Chambers\",\"Moor\",\"Snyder\", \"Howard\", \"Jefferys\", \"Franklin\",\"Abelseth\",\"Straus\",\"Khalil\",\"Dyker\",\"Stengel\",\n             \"Foley\",\"Buckley\",\"Zakarian\",\"Peacock\",\"Mahon\",\"Clark\",\"Pokrnic\",\"Ware\",\"Gibson\",\"Taylor\"]\ndf = df.replace(not_imp_s,'Other')","52924252":"df[(df[\"Surname\"]==\"Other\") & (df[\"Namesakes\"]==True)].head(10).style.background_gradient(cmap=\"Blues\")","7161b98f":"s = df[df[\"Namesakes\"]==0]\nprint(f'Have no Namesakes \\t {len(s[s[\"Survived\"]==1])\/len(s)}')\ns = df[df[\"Namesakes\"]==1]\nprint(f'Have Namesakes \\t\\t {len(s[s[\"Survived\"]==1])\/len(s)}')","5a0d6329":"dfplt = df.copy(deep=True)\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\ndfplt = dfplt[dfplt[\"Surname\"]!=\"Other\"]\nfig = px.histogram(dfplt, x=\"Surname\",color=\"Survived\",color_discrete_sequence=cm)\nfig.show()","91417d81":"drop = [\"Abbott\",\"Keane\",\"Minahan\",\"Crosby\",\"Hocking\",\"Dean\",\"Mallet\",\"\"]\ndf = df.replace(drop,'Other')","f61f2878":"df[\"Title\"] = pd.DataFrame(df[\"Name\"].str.strip().str.split(\".\").tolist()).set_index(df.index).iloc[:,0]\ndf[\"Title\"] = df[\"Title\"].fillna(\"Others\")","dcaafd3d":"dfplt = df.copy(deep=True)\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\nfig = px.histogram(dfplt, x=\"Title\",color=\"Survived\",color_discrete_sequence=cm)\nfig.show()","6535e35b":"rename = {\"Miss\":\"Ms\",\n          \"Mrs\": \"Mme\",\n          \"Others\": [\"Don\",\"Rev\",\"Dr\",\"Lady\",\"Sir\",\"Mlle\",\"Col\",\"the Countess\",\"Mme\",\"Major\",\"Capt\",\"Jonkheer\",\"Dona\"]}\nfor k in rename:\n    df[\"Title\"] = df[\"Title\"].replace(rename[k],k)","52315451":"dfplt = df.copy(deep=True)\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\nfig = px.histogram(dfplt, x=\"Title\",color=\"Survived\",color_discrete_sequence=cm)\nfig.show()","f622447d":"dfplt = df.copy(deep=True)\ndfplt = dfplt[~dfplt[\"Survived\"].isna()]\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\nfig = px.scatter(dfplt, x=\"Age\", y=\"Parch\", color = \"Survived\", size_max=6\n                 ,color_discrete_sequence=cm,width=1200, height=500)\nfig.show()","edbe83df":"df[(df[\"Age\"]==5) & (df[\"Parch\"]==0)]\n# 5 y.o child traveling by hereself?","892d0051":"#df.loc[df[\"Name\"]==\"Emanuel, Miss. Virginia Ethel\",\"Parch\"]=1\n#df.loc[df[\"Name\"]==\"Dowdell, Miss. Elizabeth\",\"Parch\"]=1\n\n#df.loc[df[\"Name\"]==\"Albimona, Mr. Nassef Cassem\",\"Parch\"]=1\n#df.loc[df[\"Name\"]==\"Hassan, Mr. Houssein G N\",\"Parch\"]=1\n\n#df.loc[df[\"Name\"]=='Watt, Mrs. James (Elizabeth \"Bessie\" Inglis Milne)',\"Parch\"]=1\n#df.loc[df[\"Name\"]==\"Watt, Miss. Bertha J\",\"Parch\"]=1","1589a818":"df[\"Kid\"]=0\ndf.loc[(df[\"Age\"]<18),\"Kid\"]=1\nprint(f'Kids survived koeff:\\t{len(df[(df[\"Kid\"]==1) & (df[\"Survived\"]==0)])\/len(df[(df[\"Kid\"]==1) & (df[\"Survived\"]==1)])}')\nprint(f'Others survived koeff:\\t{len(df[(df[\"Kid\"]==0) & (df[\"Survived\"]==0)])\/len(df[(df[\"Kid\"]==0) & (df[\"Survived\"]==1)])}')","725349f1":"df[\"Old\"]=0\ndf.loc[(df[\"Age\"]>60),\"Old\"]=1\nprint(f'Elder survived koeff:\\t{len(df[(df[\"Old\"]==1) & (df[\"Survived\"]==0)])\/len(df[(df[\"Old\"]==1) & (df[\"Survived\"]==1)])}')\nprint(f'Others survived koeff:\\t{len(df[(df[\"Old\"]==0) & (df[\"Survived\"]==0)])\/len(df[(df[\"Old\"]==0) & (df[\"Survived\"]==1)])}')","aef8b5e4":"df[\"Alone\"] = 0\ndf.loc[(df[\"Parch\"]==0) & (df[\"SibSp\"]==0),\"Alone\"]=1\nprint(f'Alone survived koeff:\\t\\t{len(df[(df[\"Alone\"]==1) & (df[\"Survived\"]==0)])\/len(df[(df[\"Alone\"]==1) & (df[\"Survived\"]==1)])}')\nprint(f'Not Alone survived koeff:\\t{len(df[(df[\"Alone\"]==0) & (df[\"Survived\"]==0)])\/len(df[(df[\"Alone\"]==0) & (df[\"Survived\"]==1)])}')","f91485f2":"msno.bar(df, figsize=(30,2), color=gradient)","ac0c2ecf":"print(df[(df[\"Pclass\"]==1) & (df[\"Sex\"]==\"female\")][\"Age\"].median())\nprint(df[(df[\"Pclass\"]==1) & (df[\"Sex\"]==\"male\")][\"Age\"].median())\nprint(df[(df[\"Pclass\"]==2) & (df[\"Sex\"]==\"female\")][\"Age\"].median())\nprint(df[(df[\"Pclass\"]==2) & (df[\"Sex\"]==\"male\")][\"Age\"].median())\nprint(df[(df[\"Pclass\"]==3) & (df[\"Sex\"]==\"female\")][\"Age\"].median())\nprint(df[(df[\"Pclass\"]==3) & (df[\"Sex\"]==\"male\")][\"Age\"].median())","dba49359":"from itertools import *\nl1, l2 = [1,2,3], [\"female\",\"male\"]\nfor c,s in product(l1,l2):\n    msk = (df[\"Pclass\"]==c) & (df[\"Sex\"]==s)\n    df.loc[msk,\"Age\"] = df[msk][\"Age\"].fillna(df[msk][\"Age\"].median())","236e9672":"dfplt = df.copy(deep=True)\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\nfig = px.scatter(dfplt, x=\"Age\", y=\"Name\", color = \"Survived\", size_max=6,\n                 width=1200, height=500,color_discrete_sequence=cm)\nfig.show()","06ff51b0":"print(df.loc[1044])\ndf.loc[1044,\"Fare\"] = df[df[\"Pclass\"]==3][\"Fare\"].mean()","13fc64e5":"df[\"Fare\"] = df[\"Fare\"].rank(method='max')","0ecb8ab2":"dfplt = df.copy(deep=True)\ndfplt[\"Survived\"] = dfplt[\"Survived\"].astype(str)\nfig = px.scatter(dfplt, x=\"Fare\", y=\"Name\", color = \"Survived\", size_max=6,\n                 width=1200, height=500,color_discrete_sequence=cm)\nfig.show()","a4cd8a88":"df[df[\"Embarked\"].isna()]","67b8a195":"df.loc[df[\"Embarked\"].isna(),\"Embarked\"] = \"S\"","b6a2f639":"onehot_df = pd.DataFrame(index=df.index)\n\nfor c in [\"Pclass\",\"Sex\",\"Embarked\",\"Deck\",\"Ticket_p\",\"Surname\",\"Title\"]:\n    encoded = OneHotEncoder().fit_transform(df[c].to_numpy().reshape(-1,1)).toarray()\n    columns = [f\"{c}_{i}\" for i in range(encoded.shape[1])]\n    _df =pd.DataFrame(data=encoded, columns=columns, index=df.index)\n    onehot_df = pd.concat([_df,onehot_df], axis=1)\n    \nonehot_df = pd.concat([onehot_df,df[[\"Survived\",\"Age\",\"SibSp\",\"Parch\",\"Fare\",\"Cabin\",\"Namesakes\",\"Kid\",\"Alone\",\"Side\"]]], axis=1)\n\nfor c in [\"Age\",\"Fare\",\"Cabin\",\"SibSp\",\"Parch\"]:\n    onehot_df[c] = MinMaxScaler().fit_transform(onehot_df[c].to_numpy().reshape(-1,1))","2a7f0658":"onehot_df.head(10).style.background_gradient(cmap=\"Blues\")","c569aa3f":"df_train = onehot_df.copy(deep=True)\nmask = df_train[\"Survived\"].isna()\ntrain, deploy = df_train[~mask], df_train[mask]\ndeploy = deploy.drop(\"Survived\", axis=1)\ntrain.loc[:,\"Survived\"] = train.loc[:,\"Survived\"].astype(bool)\nx_train, y_train = train.drop(\"Survived\", axis=1), train[\"Survived\"].astype(int)","c80b1d3d":"deploy_acc, train_acc, models_dict= {},{},{}\n\ndef baseline(name, model, verbose=True):\n    models_dict[name] = model\n    models_dict[name].fit(x_train,y_train)\n    y_train_hat = models_dict[name].predict(x_train)\n    train_acc[name] = accuracy_score(y_train,y_train_hat)\n    if verbose:\n        skplt.metrics.plot_confusion_matrix(y_train, y_train_hat, normalize=True, figsize=(5,5))\n    submition = pd.DataFrame(models_dict[name].predict(deploy), index= deploy.index,columns = [\"Survived\"]).astype(int)\n    submition.to_csv(f'{name}.csv')","55d58be3":"params = {\"penalty\":\"l2\",\"solver\": \"liblinear\",\"C\":0.2,}\nname, model = \"lr_baseline\", LogisticRegression(**params)\nbaseline(name, model, verbose=False)\n\nname, model = \"svm_baseline\", SVC(**{'C': 5, 'degree': 2, 'gamma': 0.1, 'kernel': 'poly'})\nbaseline(name, model, verbose=False)\n\nparams = {\"eta\":0.1,\"gamma\":0,\"max_depth\":6,\"lambda\":0.1,\"alpha\":10}\nname, model = \"xg_baseline\", XGBClassifier(**params)\nbaseline(name, model, verbose=False)\n\nparams = {\"rsm\":0.1, \"learning_rate\":0.005,\"iterations\":500,\"l2_leaf_reg\":5,\"verbose\":False}\nname, model = \"cb_baseline\", CatBoostClassifier(**params)\nbaseline(name, model, verbose=False)","fb8bcdd9":"fig = plt.figure(figsize=(35,10))\ncount=1\nfor k in models_dict:\n    ax = fig.add_subplot(1,len(models_dict),count)\n    count+=1\n    skplt.metrics.plot_confusion_matrix(y_train, models_dict[k].predict(x_train), normalize=True, figsize=(5,5),ax=ax, cmap=\"Blues\")\n    ax.set_title(k)\nplt.show()","5b175097":"deploy_acc[\"lr_baseline\"]  = 0.79904\ndeploy_acc[\"svm_baseline\"] = 0.80382\ndeploy_acc[\"xg_baseline\"]  = 0.78947\ndeploy_acc[\"cb_baseline\"]  = 0.79425 \nprint(\"Accuracy on the deployment set:\")\nfor k in deploy_acc:\n    print(f\"{k}\\t:\\t{deploy_acc[k]}\")","df6de556":"print(\"Accuracy on the training set:\")\nfor k in train_acc:\n    print(f\"{k}\\t:\\t{train_acc[k]}\")","7911f284":"name, model = \"ensemble\", StackingClassifier(classifiers=(models_dict[\"svm_baseline\"],models_dict[\"lr_baseline\"],\n                                                                    models_dict[\"xg_baseline\"], models_dict[\"cb_baseline\"]),\n                                               meta_classifier=LogisticRegression(**{\"penalty\":\"l2\",\"solver\": \"liblinear\",\"C\":0.2,}),\n                                               use_features_in_secondary=True)\nbaseline(name, model, verbose=False)","ba419881":"deploy_acc[\"ensemble\"]  = 0.80622","c3e2bfa4":"ens_train, ens_deploy = {}, {}\nfor k in models_dict:\n    ens_train[k] = models_dict[k].predict(x_train) * deploy_acc[k]\n    ens_deploy[k] = models_dict[k].predict(deploy) * deploy_acc[k]\nx_train = pd.concat([pd.DataFrame(ens_train, index=x_train.index),x_train], axis=1)        \ndeploy = pd.concat([pd.DataFrame(ens_deploy, index=deploy.index),deploy], axis=1)","6a90b42f":"model = SVC()\nmodel.fit(x_train,y_train)\nsubmition = pd.DataFrame({\"PassengerId\":deploy.index,\"Survived\":model.predict(deploy)}).astype(int)","7a213a9a":"submition.to_csv(\"mixture.csv\",index=False) #0.81100","a36595d8":"### <a class=\"anchor\" id=\"1.3.2_bullet\" style=\"color:#3B61A3\">  1.3.2 Parch and Age\nThis features may have crucial effect on the target. Parants was saving there children befor them, and many other connections may be inside of the just two attributes","8f0183a9":"## <a class=\"anchor\" id=\"3.1_bullet\" style=\"color:#3B61A3\">  3.1 Models baselines","766a04c2":"### <a class=\"anchor\" id=\"2.1.3_bullet\" style=\"color:#3B61A3\">  2.1.3 Filling \"Embarked\" feature\nWe have two passangers, whose \"Embarked\" information is unknown","6b6c8bb5":"For the \"Age\" feature we just can replace None values with some mean value, but we gonna do it in a bit more complex way.\nWe will locate some groups, based on Sex and Pclass - lets check the difference in ages in several groups.","311635f8":"## <a class=\"anchor\" id=\"1.2_bullet\" style=\"color:#3B61A3\">  1.2 Groups and family bonds analisys\nSome groups of passangers, should be connected via ticket numbers, surnames, classP and etc. We will try to put the data into the shape in which our model will detect such connections\n### <a class=\"anchor\" id=\"1.2.1_bullet\" style=\"color:#3B61A3\">  1.2.1 Ticket numbers analisys","1a8aaf29":"We will manually set two more features:\n* \"Kid\" feature - for less then 18 y.o passangers - there survival rate is higher \n* 'Alone' feature - for those who was travalling alone (>18 e.o, Parch & SibSp ==0). \n* 'Old' feature - elder people died more often. I took 60 y.o as a treashold, after checking several and chooseing the one","314ab18a":"## <a class=\"anchor\" id=\"2.2_bullet\" style=\"color:#3B61A3\">  2.2 Encoding features and droping unnecessary","0c9c7347":"### <a class=\"anchor\" id=\"1.1.2_bullet\" style=\"color:#3B61A3\"> 1.1.2 Cabin numbers analisys\nSome of the passangers have shared several cabins - thay may have the same cabin number or leave in 3 of 4 cabins at the same time (families). But actually not only families or reletives shared cabins, but some collegues, friends etc. In this case i will try to create a features, which will describe the location of passangers, linked to there Cabin number.\n\nSome of the cabins has ambiquouse values - i will hardcode them - giving maximum values to multiple cabins \nfor a passanger. Or just rename them is several other ways, according to the Deck plans from https:\/\/www.encyclopedia-titanica.org\/titanic-deckplans\/","cd7063de":"We do not know much about the meaning of this prefixes, but there are some dependencies:\n* No passangers survived with the prefix A4\n* Most of the passangers with WC prefix - died","9fa0e5c4":"We can try to apply OneHot encoder for all columns to see how spars will be the matrix","eaf9baf7":"# <a class=\"anchor\" id=\"2_bullet\" style=\"color:#292F55\">  2. Data preparation\n## <a class=\"anchor\" id=\"2.1_bullet\" style=\"color:#3B61A3\">  2.1 Filling None values\n### <a class=\"anchor\" id=\"2.1.1_bullet\" style=\"color:#3B61A3\">  2.1.1 Filling \"Age\" None values","58a16d33":"As we can see - passangers survived more often, living on the 1, then on the side -1\n\nTo fill the missing values for \"Cabin\", we will put median values for all passangers in specific Decks.\nBefore this, we will devide number of the Cabin by two - because the \"side\" location has been already taken from the data.\nIf Deck number is unknown - we will just mark Cabin as -1 - mwaning \"Unknown\"","9fc4737e":"Lets visualize Surviving rates for families:","aea40aaa":"# <a class=\"anchor\" id=\"3_bullet\" style=\"color:#292F55\">  3. Model development","c47d1365":"![Upvote!](https:\/\/img.shields.io\/badge\/Upvote-If%20you%20like%20my%20work-07b3c8?style=for-the-badge&logo=kaggle)","aa65c85b":"### <a class=\"anchor\" id=\"2.1.2_bullet\" style=\"color:#3B61A3\">  2.1.2 Filling \"Fare\" feature\nI will manually fill None value with the mean value for passanger class.\nAfter that we can replace Fare with a rank, because i assume that the value of difference is not important.","e97b2110":"<h1 style=\"font-size:250%;color:#292F55\"> Titanic - Machine Learning from Disaster<\/h1>\n\n*Top 3% Titanic solution - For this last version best model score is 0.81100*.\n![](https:\/\/pbs.twimg.com\/media\/EVkwSjCWsAA3xjV.jpg)","02d6f0e2":"The same thing as in (*) we gonna do for those Surnames who do not exist in test set.\nAgain, i gonna do it manually, cause i dont wanna work with automatization here =)\n\nBut just before this we will put some extra feature which mean \"Has any namesakes\" to determin if the person in som relatio-like group. It may look the same as SibSp, but guess, that som connections between people is hidden.","64f97b43":"According to https:\/\/www.encyclopedia-titanica.org\/titanic-survivor\/amelia-icard.html we can fill nan values with \"S\"","12aef839":"We can see that there is no accurate dependency between Cabin number and the Survival in general - maby it can work on connection with some other features. Some extra information we can take from the Cabin number - is the Side of the ship (left or right) ,according to the even or odd number of it. The side of the ship can effect much on the serviving rate.","0a83bb0b":"Some of the tickets contains several prefixes refering for some specific sale policies - maby it may be usefull for the model (we will save it into Ticket_p) but at the same time wew will clear our ticket number from umbiques information (It may be some hidden connections in the ticket numbers).","737c7c14":"### <a class=\"anchor\" id=\"1.2.2_bullet\" style=\"color:#3B61A3\">  1.2.2 Names, surnames and status feature\nTo get more information about the family bonds - we will extract surnames instead of Names, and put them into features list\/","0be44daa":"We will define the method, which fits the given model and puts all the neccesery data into different structures to use them further:\n\n* deploy_acc  - model accuracy for deploy dataset\n* train_acc   - model accuracy after the validation\n* models_dict - dictionary of the models\n","c2aefbf2":"What we can see from such graphs:\n*     Only one PassengerId have been on the Deck T - and he is in train set, so we can drop the \"T\" value\n*     There ara some dependancies between surviving rate and the Deck number:\n\n|deck|died|survived|ratio|\n|:--:|:--:|:------:|:---:|\n|C   |24  |35      |0.4  |\n|G   |2   |2       |0.5  |\n|D   |8   |25      |0.24 |\n|A   |8   |7       |0.53 |\n|B   |12  |35      |0.26 |\n|F   |5   |8       |0.38 |\n|E   |8   |24      |0.25 |\n        \nIn this case - we can put such new features into the model and encode them.","b9fada65":"## <a class=\"anchor\" id=\"1.3_bullet\" style=\"color:#3B61A3\">  1.3 Personal features analisys\n### <a class=\"anchor\" id=\"1.3.1_bullet\" style=\"color:#3B61A3\">  1.3.1 Title features\nPassangers with different Titles may hav different survival rate (may be connected to so some position on groups, status of inner features)","d2859f5f":"### <a class=\"anchor\" id=\"3.2_bullet\" style=\"color:#3B61A3\"> 3.2 Ensemble models","15cf60b3":"I've tried several Gridsearches for CVs with Kfold. And after a bunch of deploys, i chose those models.\nI chose models which gave me the best deploy accuracy. This models gonna be not \"Best model for Survival prediction\" , but \"The best model to predict the test set\", which is not the exect solution for the task.","690b0ca4":"**\"LINE\" tickets:**\nAll Tickets number contains some numbers, except \"LINE\" tickets www.encyclopedia-titanica.org\nPhiladelphia's westbound voyage was cancelled, and several shipmates forced to travel aboard Titanic as passengers (Some of them have LINE ticket number):\n - August Johnson (Johnson, Mr. Alfred) - **LINE** - 370160\n - William Cahoone Jr. Johnson - **LINE** - 370160\n - William Henry T\u00f6rnquist - **LINE** - 370160\n - Andrew John Shannon (Lionel Leonard) - **LINE** - 370160\n\nWe will not analize them much, in this part, but we should take it into account","b7b1fda3":"Now we gonna plot some developed \"coordinates\" of the passangers, to find some patterns in survival.","ccca5324":"### <a class=\"anchor\" id=\"1.1.1_bullet\" style=\"color:#3B61A3\"> 1.1.1 Survival for different Deck numbers\nDeck descriptors are coded inside of the Cabin numbers\nWe will extract them as a new feature.\nUnknowns we will mark as \"N\/A\"","30131e6b":"We can see some patterns in the data:\n  - For example, all of the passangers on the \"1\" side of the Deck D survived.\n  - For only some of decks the \"closer\" location to zero may cause the better survival (maby those passangers was closer to the ladders)","63602cc3":"<a style=\"font-size:200%;color:#292F55\">Table Of Content\n* [<a style=\"font-size:150%;color:#292F55\">1. EDA & Feature Engeneering](#1_bullet)\n    * [<a style=\"font-size:130%;color:#3B61A3\"> 1.1 Passengers location analisys](#1.1_bullet) - Survival for different Deck \/ Cabin numbers\n    * [<a style=\"font-size:130%;color:#3B61A3\"> 1.2 Groups and family bonds analisys](#1.2_bullet) - Ticket numbers analisys, Names \/ Surnames\n    * [<a style=\"font-size:130%;color:#3B61A3\"> 1.3 Personal features analisys](#1.3_bullet) - Age \/ Status analisys\n* [<a style=\"font-size:150%;color:#292F55\">2. Data preparation](#2_bullet)\n    * [<a style=\"font-size:130%;color:#3B61A3\"> 2.1 Filling None values](#2.1_bullet)\n    * [<a style=\"font-size:130%;color:#3B61A3\"> 2.2 Encoding features and droping unnecessary](#2.2_bullet)\n* [<a style=\"font-size:150%;color:#292F55\">3. Model development](#3_bullet)\n    * [<a style=\"font-size:130%;color:#3B61A3\"> 2.1 Catboost baseline](#2.1_bullet)\n    \n","2a2ba000":"We will get all same-surname groups into one list, to put some feature for it\nAll others will be marked with \"Other\".(*)","29f77f71":"In the end i desided not to fix it, cause if takes some extra information about the data, and it is kind of cheating.\nBut i will leave it there just in case someone will need it","987b1a6f":"Now we will delete all the Families, for which number of Survived equel to not Survived (Again ill do it manually)","ebe756aa":"## <a class=\"anchor\" id=\"1.1_bullet\" style=\"color:#3B61A3\"> 1.1 Passengers location analisys \n\nI assume, that the location of passengers at the moment of the disaster may affect on the surviving rate.\n\nFor this case we will try to analyze such location, referring to the time of the disaster - 23:40. It means that some passengers may already have been in their cabins, some of them was hanging on some restaurants and \"bars\" (linked to there Pclass and maby cabin location) etc.\n\nAnyway, we do not know their location at that moment, but we can create some feature to describe it somehow to help our model.\n\nOffcourse, we have smth like 80% None values in \"Cabin\" feature - but still some useful information can be extracted + we need to be careful with filling the gaps.","c6ce9761":"We see, that all 5 models has different sepations on the data (even on the trains set)\nNow we gonna combine this models into peculiar ensemble.\nWe gonna put som waights, according to there deploy results.","271bdf4e":"# <a class=\"anchor\" id=\"1_bullet\" style=\"color:#292F55\"> 1. Exploratory Data Analysis (EDA)","6c9d0445":"We can see that some of prefixes appear only one time or only in train dataset. Lets clean them in order not to confuse our model.\n\nWe wil do it manualy - couse it is not much off them, and we gonna check them, if maby there is some sintax mistakes.","efad2728":"In the end - we have to fillna for \"Side\" feature with 0 - refering to unknown side of the ship","cf7f530e":"Resulting matrix looks like too spars, because of Surnames features, which should provide us some groups of survivals.\nNow we gonna try to use it for the baseline. In the next versions, i'll try some other configurations","4f863bc6":"I desided to delete values with low frequancy - for our model not to be messed up."}}