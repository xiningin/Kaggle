{"cell_type":{"4dd79677":"code","25a62ba1":"code","b2395d76":"code","253dac71":"code","6470684d":"code","99473d9b":"code","192bde7f":"code","bcdc28ba":"code","e28c33e7":"code","700d5c8c":"code","0190ccd8":"code","2f03e2d1":"code","efe261ae":"code","f723f3b2":"code","03164097":"code","a406e889":"code","f5f38f45":"code","1fa8f16b":"code","0706e4b3":"code","1506aa3e":"code","d9d44faf":"code","4d8280d7":"code","3ac4df26":"code","d1dba65c":"code","effb08ea":"code","0d783986":"code","ff090d78":"code","0552c18e":"code","630af43f":"code","b280f25c":"code","7f38b21c":"code","187ac726":"code","9ed39cde":"code","05eae05b":"code","1d7b466f":"code","d2234c3e":"code","bad0e91e":"code","1cad193f":"code","bcb500cb":"code","3dc8392f":"code","314215fa":"code","dda5d053":"code","7f954ff7":"code","412247c0":"code","21bcf93d":"code","9003f6c2":"code","fa6b1c3d":"code","ebf8741f":"code","ea7fe8cf":"code","2e19ecd8":"code","60b818d0":"code","ca76d73a":"code","55796bfe":"code","f531af92":"code","a41e52ae":"code","68eb9d0d":"code","8ce687fe":"code","9fbaf61c":"code","5aaa770c":"code","bab86d40":"code","d55f59cd":"code","7de288f8":"code","bf9a39ab":"code","3d575d79":"code","ea192a76":"code","84f9b373":"code","f4d18287":"code","ea50610c":"code","7bf353b4":"code","96be3f12":"code","8b6e2e39":"code","4ab5d4ec":"code","9c115960":"code","b576c2cd":"code","d8f2ef10":"code","33f0be2f":"code","fa9fc69b":"code","a777d6d2":"code","f2a003d3":"code","9bdfd9f5":"code","05f630e0":"code","6f54daca":"code","b2caa9aa":"code","bc8348cf":"code","83e8ef13":"code","9bfa81d5":"code","87713d37":"code","4de55418":"code","c7facc96":"code","590da467":"code","1f5d9255":"code","d918192d":"code","5393d6e2":"code","94fd2124":"code","54dd58e4":"code","879c57bc":"code","64071b99":"code","04889785":"code","134c0658":"code","63eb310f":"code","4d9d76ad":"code","bc5442ad":"code","e3fa1910":"code","3453058f":"code","5ee01c41":"code","e355796e":"code","89fb3e87":"code","8e6d6ff4":"code","0dd9f133":"code","50ebdf10":"code","b55761f8":"code","637064fa":"code","ce4f2e52":"code","3a00ccc7":"code","6a1bc765":"code","d7e991f3":"code","25f0fac5":"code","ecb6e82e":"code","163ee014":"code","2936f57b":"code","e12a1a3c":"code","883dfe9f":"code","65ebc7e1":"code","258e4d13":"code","230b6c0a":"code","110d420e":"code","92f65ec0":"code","eaceff4a":"code","2cec53dd":"code","589de9aa":"code","cb38aef7":"code","413a09b2":"code","d3659e33":"code","8a4e3968":"code","fdbec7a8":"code","85dcedda":"code","7eae5c19":"code","48954df4":"code","3a29d984":"code","555c112d":"code","1a126c39":"code","d24cc21b":"markdown","f74999dd":"markdown","98f9b19d":"markdown","0f0aa3bc":"markdown","e1926a09":"markdown","c185508c":"markdown","d6652ed5":"markdown","2014e29f":"markdown","b8ccbac7":"markdown","34ba21f4":"markdown","06fa120c":"markdown","c2700781":"markdown","111e8c18":"markdown","3a4ab8fd":"markdown","bec51817":"markdown","f1adda37":"markdown","b420a0c8":"markdown","dd9273d9":"markdown","a93aa8ea":"markdown","c764e4a2":"markdown","1d3bfee4":"markdown","5fbaea8b":"markdown","5f2dfb94":"markdown","08d671a1":"markdown","2000d1df":"markdown","3aa1fef2":"markdown","182882d9":"markdown","75fa65c9":"markdown","1ae8c06e":"markdown","4a34d4e5":"markdown","872b4203":"markdown","46aa53c6":"markdown","65604f9a":"markdown","767d3508":"markdown","86956955":"markdown","de3a081c":"markdown","e701313a":"markdown","9cc32ea9":"markdown","26bfc269":"markdown","57e0cbd3":"markdown","ea620b09":"markdown","cce236b3":"markdown","617ff293":"markdown","b7748d19":"markdown","3bfbea90":"markdown","2639b209":"markdown","da65a557":"markdown","b12dcfe5":"markdown","b635978b":"markdown","bfbc635c":"markdown","5ddfd5ec":"markdown","a05bd61e":"markdown","f5db6772":"markdown","b4217113":"markdown","350a4ecb":"markdown","b16fcf74":"markdown","56457509":"markdown","ccd86876":"markdown","b46223c9":"markdown","5edc0632":"markdown","e8ef6e29":"markdown","f22b3665":"markdown","78152467":"markdown","29d37006":"markdown","41d6df1a":"markdown","32603379":"markdown","9f850f76":"markdown","638da0dd":"markdown","7c50a7c3":"markdown","3dc1b57f":"markdown","109dda6a":"markdown","2fe2a490":"markdown","73f3c220":"markdown","e374926a":"markdown","7bd52f72":"markdown","799b15c7":"markdown","48c9d2e9":"markdown","b04fe0ce":"markdown","d3292a7d":"markdown","c154c321":"markdown","3d98bb8d":"markdown","fb079407":"markdown","4c7d16a5":"markdown","bb0f0f12":"markdown","56f91d81":"markdown","8b585dcf":"markdown","5a25dcce":"markdown","a5c63a80":"markdown","ff0173ca":"markdown","fe59b07d":"markdown","e6afa033":"markdown","28a36907":"markdown","9c2d13ad":"markdown","6aa199ea":"markdown","fe480edb":"markdown","42a8c5de":"markdown","ca58bef4":"markdown","536e1b70":"markdown","fe8ba724":"markdown","5a6bf4dd":"markdown","372db1ee":"markdown","084c52eb":"markdown","4976bec1":"markdown","cb0d91b7":"markdown","c2abc031":"markdown","6f47d858":"markdown","be367bfa":"markdown","26fffec1":"markdown","5f8ca4c9":"markdown","540d946a":"markdown","53e760e4":"markdown","ab8c752a":"markdown","458e1df7":"markdown","9a6b3dbb":"markdown","f112b2fd":"markdown","7ffdc27c":"markdown","4e07e78f":"markdown","07ac833d":"markdown","d516f78e":"markdown","442fbf55":"markdown","f3755168":"markdown","f1b3a696":"markdown","03bf9c14":"markdown","4f6fbadb":"markdown","d6a7c9a5":"markdown","9fb4067e":"markdown","253f3509":"markdown","90218e77":"markdown"},"source":{"4dd79677":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","25a62ba1":"# df = pd.read_excel(\"Online Retail.xlsx\")\n# df.to_csv('Online_Retail.csv')","b2395d76":"df=pd.read_csv('..\/input\/online-retail-customer-clustering\/OnlineRetail.csv')\ndf.head()","253dac71":"def explain(attribute):\n    features= {'InvoiceNo': \"Invoice number. Nominal, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation.\",\n    'StockCode': 'Product (item) code. Nominal, a 5-digit integral number uniquely assigned to each distinct product.',\n    'Description': 'Product (item) name. Nominal.',\n    'Quantity': 'The quantities of each product (item) per transaction. Numeric.',\n    'InvoiceDate': 'Invice Date and time. Numeric, the day and time when each transaction was generated.',\n    'UnitPrice': 'Unit price. Numeric, Product price per unit in sterling.',\n    'CustomerID': 'Customer number. Nominal, a 5-digit integral number uniquely assigned to each customer.',\n    'Country': 'Country name. Nominal, the name of the country where each customer resides.'}\n    return features[attribute]\n","6470684d":"df.duplicated().value_counts()","99473d9b":"df=df.drop_duplicates()","192bde7f":"df.shape","bcdc28ba":"df.info()","e28c33e7":"df.isnull().sum()","700d5c8c":"df.describe()\n# df.describe(include=['O'])","0190ccd8":"# Alternate\ndef summary(df, pred=None):\n    obs = df.shape[0]\n    Types = df.dtypes\n    Counts = df.apply(lambda x: x.count())\n    Min = df.min()\n    Max = df.max()\n    Uniques = df.apply(lambda x: x.unique().shape[0])\n    Nulls = df.apply(lambda x: x.isnull().sum())\n    print('Data shape:', df.shape)\n\n    if pred is None:\n        cols = ['Types', 'Counts', 'Uniques', 'Nulls', 'Min', 'Max']\n        str = pd.concat([Types, Counts, Uniques, Nulls, Min, Max], axis = 1, sort=True)\n\n    str.columns = cols\n    print('___________________________\\nData Types:')\n    print(str.Types.value_counts())\n    print('___________________________')\n    return str\n\ndisplay(summary(df).sort_values(by='Nulls', ascending=False))","2f03e2d1":"# counts of the negative values in the Quantity\ndf[df['Quantity'] <0].shape[0]","efe261ae":"# counts of the negative values in the UnitPrice\ndf[df['UnitPrice'] < 0].shape[0]","f723f3b2":"df[df['UnitPrice'] < 0]","03164097":"df[df['Quantity'] <0].head()","a406e889":"explain('InvoiceNo')","f5f38f45":"df['cancellation']=df.InvoiceNo.str.extract('([C])').fillna(0).replace({'C':1})\ndf['cancellation'].value_counts()","1fa8f16b":"df[(df.cancellation==1) & (df.Quantity>0)]","0706e4b3":"df['cancellation'].value_counts()","1506aa3e":"# Proportion of the customers canceled their order\ndf[df.cancellation==1]['CustomerID'].nunique() \/ df['CustomerID'].nunique()*100","d9d44faf":"# Proportion of the canceled order\ndf[df.cancellation==1]['InvoiceNo'].nunique() \/df[['InvoiceNo']].nunique()*100","4d8280d7":"df[df.cancellation==1]['CustomerID'].value_counts(dropna=False).head(5)","3ac4df26":"# Drop CustomerID with null value\ndf = df[df.CustomerID.notnull()]","d1dba65c":"# Drop Quantity and UnitPrice with negative value\ndf = df[(df.Quantity > 0) & (df.UnitPrice > 0)]","effb08ea":"details = summary(df)\ndisplay(details.sort_values(by='Uniques', ascending=False))","0d783986":"df[df.cancellation==1]","ff090d78":"df=df.drop('cancellation',axis=1)","0552c18e":"df","630af43f":"# Her musterinin siparis sayisi\ndf.groupby('CustomerID')['InvoiceNo'].nunique().sort_values(ascending=False)","b280f25c":"# Her bir musterinin her siparisteki unique products sayisinin ortalamasi\nmean_of_unique_items= round(df.groupby(['CustomerID',\n                      'InvoiceNo']).agg({'StockCode':lambda x:x.nunique()}).groupby('CustomerID')['StockCode'].mean(),\n                      1).sort_values(ascending=False)\nmean_of_unique_items","7f38b21c":"# Her musterinin satin aldigi unique product sayisi\nnum_of_unique_product= pd.DataFrame(df.groupby('CustomerID').StockCode.nunique()).rename(columns={'StockCode':'num_of_unique_product'})\n\n# Her musterinin siparis sayisi\nnum_of_order = df.groupby('CustomerID').InvoiceNo.nunique()","187ac726":"pd.concat([mean_of_unique_items,\n           num_of_order,\n           num_of_unique_product],\n           axis=1).rename(columns={'StockCode': \"mean_of_unique_items\",\n                                   'InvoiceNo': 'num_of_order'}).sort_values('num_of_order', ascending=False)","9ed39cde":"df","05eae05b":"df['TotalPrice'] = df['UnitPrice']*df['Quantity']","1d7b466f":"df2=pd.DataFrame(df.groupby('Country').TotalPrice.sum().apply(lambda x: round(x,2))).sort_values('TotalPrice',ascending=False)\n# df2=df.groupby('Country').agg({'TotalPrice': lambda x: x.sum()}).sort_values('TotalPrice',ascending=False)\n\ndf2['perc_of_TotalPrice']=round(df2.TotalPrice\/df2.TotalPrice.sum()*100,2)\ndf2","d2234c3e":"df2['customer_num']=df.groupby('Country').CustomerID.nunique()\ndf2['customer_rate']=round(df2.customer_num\/df2.customer_num.sum()*100,2)\ndf2.head(5)","bad0e91e":"plt.figure(figsize=(15,5))\nsns.barplot(y=df2.index, x=df2.customer_num.sort_values(ascending=False));","1cad193f":"plt.figure(figsize=(15,10))\nsns.barplot(y=df2.iloc[1:].index, x=df2.iloc[1:].customer_num.sort_values(ascending=False));","bcb500cb":"plt.figure(figsize=(15,10))\nsns.barplot(y=df2.iloc[1:].index, x=df2.iloc[1:].TotalPrice.sort_values(ascending=False));","3dc8392f":"df_uk=df[df.Country=='United Kingdom']\ndf_uk.head()","314215fa":"pd.DataFrame(df_uk.StockCode.value_counts().head(10))","dda5d053":"from datetime import datetime as dt\nimport warnings\nwarnings.filterwarnings('ignore')\nwarnings.warn(\"this will not show\")","7f954ff7":"df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\n\ndf_uk=df[df.Country=='United Kingdom']\ndf_uk.head()","412247c0":"# a point of reference date \n\nref_date = max(df['InvoiceDate'])\nref_date","21bcf93d":"df_uk['Date']=df_uk['InvoiceDate'].apply(lambda x: x.date())\ndf_uk.head(3)","9003f6c2":"df_uk['Last_Purchase_Date']=df_uk.groupby(['CustomerID'])['Date'].transform(max)\n# df_uk.groupby('CustomerID').agg({'Date': lambda x:x.max()})\ndf_uk.head(5)","fa6b1c3d":"df_uk['Recency']=df_uk.groupby('CustomerID')['Last_Purchase_Date'].apply(lambda x:ref_date.date() - x)\ndf_uk['Recency']=df_uk.agg({'Recency':lambda x:x.astype('timedelta64[D]')})\n\n# df_uk.groupby('CustomerID').agg({'Date': lambda x: (today.date() - x.max()).days})\ndf_uk.head()","ebf8741f":"df_uk.Recency.value_counts().sort_index()","ea7fe8cf":"df_uk = df_uk.drop('Last_Purchase_Date',axis=1)","2e19ecd8":"plt.subplots(figsize=(15, 5))\nsns.distplot(df_uk.groupby('CustomerID')['Recency'].max(), kde=False, bins=80)\nplt.title('Recency Value Distribution', fontsize = 15)\nplt.xlabel('Recency')\nplt.ylabel('Count');","60b818d0":"df_uk=df_uk.drop_duplicates()","ca76d73a":"df_uk['Frequency'] = df_uk.groupby('CustomerID').InvoiceNo.transform('nunique')","55796bfe":"plt.figure(figsize=(15, 5))\nsns.distplot(df_uk.groupby('CustomerID')['Frequency'].max(), kde=False, bins=200)\nplt.title('Frequency Value Distribution', fontsize = 15)\nplt.xlim(-10, 60)\nplt.xlabel('Frequency')\nplt.ylabel('Count');","f531af92":"df_uk['Monetary'] = df_uk.groupby('CustomerID').TotalPrice.transform('sum')","a41e52ae":"plt.subplots(figsize=(15, 5))\nsns.distplot(df_uk.groupby('CustomerID')['Monetary'].max(), kde=False, bins=400)\nplt.title('Monetary Value Distribution', fontsize = 15)\nplt.xlim(-10000, 40000)\nplt.xlabel('Monetary')\nplt.ylabel('Count');","68eb9d0d":"df_rfm = df_uk[['Recency','Frequency','Monetary']].drop_duplicates().rename(index=df_uk['CustomerID'])\ndf_rfm.sort_index()","8ce687fe":"# Alternative\n\n# RECENCY (R): Time since last purchase\n# FREQUENCY (F): Total number of purchases\n# MONETARY VALUE (M): Total monetary value\n\n#df_uk=df[df.Country=='United Kingdom']\n\n# data_x = df_uk.groupby('CustomerID').agg({'InvoiceDate': lambda x: (ref_date - x.max()).days})\n\n# data_y = df_uk.groupby('CustomerID').agg({'InvoiceNo': lambda x: len(x)})\n\n# data_z = df_uk.groupby('CustomerID').agg({'TotalPrice': lambda x: x.sum()})\n\n# df_rfm= pd.merge(data_x, data_y, on='CustomerID').merge(data_z, on='CustomerID').rename(columns= {'InvoiceDate': 'Recency',\n#                                                                                                   'InvoiceNo': 'Frequency',\n#                                                                                                   'TotalPrice': 'Monetary'})\n\n# df_rfm.sort_index()","9fbaf61c":"quantiles = df_rfm.quantile(q=[0.25,0.50,0.75])\nquantiles","5aaa770c":"# Arguments (x = value, p = recency, monetary_value, frequency, d = quartiles dict)\n\ndef R_Point(x,p,d):\n    if x <= d[p][0.25]:\n        return 4\n    elif x <= d[p][0.50]:\n        return 3\n    elif x <= d[p][0.75]: \n        return 2\n    else:\n        return 1","bab86d40":"# Arguments (x = value, p = recency, monetary_value, frequency, d = quartiles dict)\n\ndef FM_Point(x,p,d):\n    if x <= d[p][0.25]:\n        return 1\n    elif x <= d[p][0.50]:\n        return 2\n    elif x <= d[p][0.75]: \n        return 3\n    else:\n        return 4","d55f59cd":"df_rfm['R_Quartile'] = df_rfm['Recency'].apply(R_Point, args=('Recency',quantiles))\ndf_rfm['F_Quartile'] = df_rfm['Frequency'].apply(FM_Point, args=('Frequency',quantiles))\ndf_rfm['M_Quartile'] = df_rfm['Monetary'].apply(FM_Point, args=('Monetary',quantiles))","7de288f8":"df_rfm","bf9a39ab":"df_rfm['RFM_Scores'] = df_rfm.R_Quartile.apply(str) + df_rfm.F_Quartile.apply(str) + df_rfm.M_Quartile.apply(str)\ndf_rfm","3d575d79":"label = list(np.zeros(len(df_rfm)))\n\nfor i in range(len(df_rfm)):\n    if df_rfm['RFM_Scores'].iloc[i] =='444': label[i] = \"1-Best Customers\"  \n    elif df_rfm['RFM_Scores'].iloc[i][1]=='4': label[i] = \"2-Loyal Customers\"\n    elif df_rfm['RFM_Scores'].iloc[i][2]=='4': label[i] = \"3-Big Spenders\"\n    elif df_rfm['RFM_Scores'].iloc[i]=='244' : label[i] = \"4-Almost Lost\"\n    elif df_rfm['RFM_Scores'].iloc[i]=='144' : label[i] = \"5-Lost Customers\"\n    elif df_rfm['RFM_Scores'].iloc[i] =='111' : label[i] = \"6-Lost Cheap Customers\"       \n        \ndf_rfm['RFM_Scores_Segments'] = label\ndf_rfm","ea192a76":"df_rfm.RFM_Scores_Segments.value_counts()","84f9b373":"Loyal_Customers=['433']\nBig_Spenders=['413','432','423']\nAlmost_Lost=['333','233','422','331','313','431','323']\nLost_Customers=['222','311','322','223','332','411','133','132','312','131','123','213','113','421','412','231','321','232']\nLost_Cheap_Customers=['122','211','112','121','212','221']","f4d18287":"for i in range(len(df_rfm)):\n    if df_rfm['RFM_Scores'].iloc[i] in Loyal_Customers : label[i] = \"2-Loyal Customers\"\n    elif df_rfm['RFM_Scores'].iloc[i] in Big_Spenders : label[i] = \"3-Big Spenders\"\n    elif df_rfm['RFM_Scores'].iloc[i] in Almost_Lost : label[i] = \"4-Almost Lost\"\n    elif df_rfm['RFM_Scores'].iloc[i] in Lost_Customers : label[i] = \"5-Lost Customers\"\n    elif df_rfm['RFM_Scores'].iloc[i] in Lost_Cheap_Customers  : label[i] = \"6-Lost Cheap Customers\"       \n        \ndf_rfm['RFM_Scores_Segments'] = label\ndf_rfm","ea50610c":"df_rfm.RFM_Scores_Segments.value_counts().sort_index()","7bf353b4":"df_rfm.groupby('RFM_Scores_Segments').agg({'Recency': ['mean','median','min','max'],\n                                           'Frequency': ['mean','median','min','max'],\n                                           'Monetary': ['mean','median','min','max','count']}).round(1)","96be3f12":"df_rfm['RFM_Points'] = df_rfm[['R_Quartile', 'F_Quartile', 'M_Quartile']].sum(axis=1).astype('float')\n# df_rfm['RFM_Points'] = df_rfm['R_Quartile'] + df_rfm['F_Quartile'] + df_rfm['M_Quartile']\ndf_rfm.head()","8b6e2e39":"label = list(np.zeros(len(df_rfm)))\n\nfor i in range(len(df_rfm)):\n    if df_rfm['RFM_Points'].iloc[i] ==12: label[i] = \"1-Best Customers\"  \n    elif df_rfm['RFM_Points'].iloc[i] ==11: label[i] = \"2-Loyal Customers\"\n    elif df_rfm['RFM_Points'].iloc[i] >= 9 : label[i] = \"3-Big Spenders\"\n    elif df_rfm['RFM_Points'].iloc[i] >= 7 : label[i] = \"4-Almost Lost\"\n    elif df_rfm['RFM_Points'].iloc[i] >= 5 : label[i] = \"5-Lost Customers\"\n    else : label[i] = \"6-Lost Cheap Customers\"       \n        \ndf_rfm['RFM_Points_Segments'] = label\ndf_rfm","4ab5d4ec":"df_rfm.groupby('RFM_Points').agg({'Recency': ['mean','median','min','max'],\n                                 'Frequency': ['mean','median','min','max'],\n                                 'Monetary': ['mean','median','min','max','count']}).round(1)","9c115960":"avg_RFM_Points = df_rfm.groupby('RFM_Points_Segments').RFM_Points.mean().apply(lambda x:round(x,1))\nsize_RFM_Points = df_rfm['RFM_Points_Segments'].value_counts()\nsummary= pd.concat([avg_RFM_Points, size_RFM_Points], axis=1).rename(columns={\"RFM_Points\": \"avg_RFM_Points\", \n                                                                   \"RFM_Points_Segments\": \"size_RFM_Points\"}).sort_values('avg_RFM_Points',\n                                                                                                           ascending=False)\nsummary","b576c2cd":"df_rfm.groupby('RFM_Points_Segments').agg({'Recency': ['mean','median','min','max'],\n                                           'Frequency': ['mean','median','min','max'],\n                                           'Monetary': ['mean','median','min','max'],\n                                           'RFM_Points': ['mean','median','min','max','count']}).round(1)","d8f2ef10":"df_rfm.head()","33f0be2f":"pd.crosstab(df_rfm['RFM_Scores_Segments'],df_rfm['RFM_Points_Segments'])","fa9fc69b":"labels = list(df_rfm.RFM_Scores_Segments.value_counts().sort_index().index)\nRFM_Scores_Segments = list(df_rfm.RFM_Scores_Segments.value_counts().sort_index().values)\nRFM_Points_Segments = list(df_rfm.RFM_Points_Segments.value_counts().sort_index().values)\n\nx = np.arange(len(labels))  # the label locations\nwidth = 0.35  # the width of the bars\n\nfig, ax = plt.subplots(figsize=(10,6))\nrects1 = ax.bar(x - width\/2, RFM_Scores_Segments, width, label='RFM_Scores_Segments')\nrects2 = ax.bar(x + width\/2, RFM_Points_Segments, width, label='RFM_Points_Segments')\n\n# Add some text for labels, title and custom x-axis tick labels, etc.\nax.set_ylabel('Total Number of Segment')\nax.set_title('RFM Segmentation by Scores and Points')\nax.set_xticks(x)\nax.set_xticklabels(labels, rotation = 45)\nax.legend()\n\n\ndef autolabel(rects):\n    \"\"\"Attach a text label above each bar in *rects*, displaying its height.\"\"\"\n    for rect in rects:\n        height = rect.get_height()\n        ax.annotate('{}'.format(height),\n                    xy=(rect.get_x() + rect.get_width() \/ 2, height),\n                    xytext=(0, 3),  # 3 points vertical offset\n                    textcoords=\"offset points\",\n                    ha='center', va='bottom')\n\n\nautolabel(rects1)\nautolabel(rects2)\n\n\nfig.tight_layout()\n\nplt.show()\n","a777d6d2":"fig, ax = plt.subplots()\nsummary.size_RFM_Points.plot(ax=ax,color='b',label='Size',kind='bar',width=0.3)\nplt.legend(bbox_to_anchor=(0.0, 0.90), loc=2, borderaxespad=0.)\n\nax2 = ax.twinx()\nsummary.avg_RFM_Points.plot(ax=ax2,color='r',label='Average', marker='o')\nplt.legend(bbox_to_anchor=(0.0, 0.80), loc=2, borderaxespad=0.)\nax.grid()","f2a003d3":"# # Alternative\n# fig, ax = plt.subplots()\n# ax=sns.barplot(x=summary.index, y=summary.size_RFM_Points)\n\n# ax2 = ax.twinx()\n# ax2=sns.lineplot(x=summary.index, y=summary.avg_RFM_Points)","9bdfd9f5":"plt.figure(figsize=(6,6))\n\n# explode = [0.01,0.01,0.1]\nplt.pie(df_rfm['RFM_Points_Segments'].value_counts().sort_index(),autopct='%1.1f%%',shadow=True,startangle=0)\nplt.legend(df_rfm['RFM_Points_Segments'].value_counts().sort_index().index,bbox_to_anchor=(1.45,0.5),loc='center right')\nplt.title('Customer Segmentation Distribution')\nplt.axis('off')\nplt.show()","05f630e0":"plt.figure(figsize=(15,15))\ndf_rfm=df_rfm.sort_values('RFM_Points_Segments')\nsns.pairplot(df_rfm[['Recency', 'Frequency', 'Monetary','RFM_Points_Segments']],hue='RFM_Points_Segments')","6f54daca":"plt.figure(figsize=(20,20))\n# df_rfm=df_rfm.sort_values('RFM_Points_Segments')\nsns.pairplot(df_rfm[['R_Quartile', 'F_Quartile', 'M_Quartile','RFM_Points_Segments']],\n             hue='RFM_Points_Segments',plot_kws={\"s\": 200})","b2caa9aa":"plt.figure(figsize=(15,5))\n# df_rfm=df_rfm.sort_values('RFM_Points_Segments')\n\nplt.subplot(1,3,1)\nsns.boxplot(df_rfm['RFM_Points_Segments'], df_rfm['Recency'])\nplt.xticks(rotation=90)\n\nplt.subplot(1,3,2)\nsns.boxplot(df_rfm['RFM_Points_Segments'], df_rfm['Frequency'])\nplt.xticks(rotation=90)\n\nplt.subplot(1,3,3)\nsns.boxplot(df_rfm['RFM_Points_Segments'], df_rfm['Monetary'])\nplt.xticks(rotation=90)\nplt.show()","bc8348cf":"plt.figure(figsize=(15,5))\n\nplt.subplot(1,3,1)\nsns.stripplot(df_rfm['RFM_Points_Segments'], df_rfm['Recency'])\nplt.xticks(rotation=90)\n\nplt.subplot(1,3,2)\nsns.stripplot(df_rfm['RFM_Points_Segments'], df_rfm['Frequency'])\nplt.xticks(rotation=90)\n\nplt.subplot(1,3,3)\nsns.stripplot(df_rfm['RFM_Points_Segments'], df_rfm['Monetary'])\nplt.xticks(rotation=90)\nplt.show()","83e8ef13":"plt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nsns.distplot(df_rfm.Recency,bins=100)\nplt.title('Recency Distribution')\nplt.xlabel('Recency')\nplt.ylabel('Count')\n\nplt.subplot(1,3,2)\nsns.distplot(df_rfm['Frequency'],color='red',bins=150)\nplt.title('Frequency Distribution')\nplt.xlabel('Frequency')\nplt.ylabel('')\nplt.xlim(-10, 50)\n\nplt.subplot(1,3,3)\nsns.distplot(df_rfm['Monetary'],color='green',bins=300)\nplt.title('Monetary Distribution')\nplt.xlabel('Monetary')\nplt.ylabel('')\nplt.xlim(-5000, 10000)\nplt.show()","9bfa81d5":"plt.figure(figsize=(15,5))\nplt.subplot(1,3,1)\nsns.kdeplot(x='Recency',data=df_rfm,hue=\"RFM_Points_Segments\",shade=True)\nplt.title('Recency Distribution')\nplt.xlabel('Recency')\nplt.ylabel('Count')\nplt.ylim(0, 0.008)\n\nplt.subplot(1,3,2)\nsns.kdeplot(x='Frequency',data=df_rfm,hue=\"RFM_Points_Segments\",shade=True)\nplt.title('Frequency Distribution')\nplt.xlabel('Frequency')\nplt.ylabel('')\nplt.xlim(-1, 10)\nplt.ylim(0, 0.5)\n\nplt.subplot(1,3,3)\nsns.kdeplot(x='Monetary',data=df_rfm,hue=\"RFM_Points_Segments\",shade=True)\nplt.title('Monetary Distribution')\nplt.xlabel('Monetary')\nplt.ylabel('')\nplt.xlim(-5000, 5000)\nplt.ylim(0, 0.0005)\nplt.show()","87713d37":"plt.figure(figsize=(15,12))\n\nplt.subplot(3,1,1)\nplt.title('R_Quartile Distribution')\nsns.countplot(x='R_Quartile', hue='RFM_Points_Segments', data=df_rfm)\nplt.xlabel('')\n\nplt.subplot(3,1,2)\nplt.title('F_Quartile Distribution')\nsns.countplot(x='F_Quartile',  hue='RFM_Points_Segments', data=df_rfm)\nplt.xlabel('')\n\nplt.subplot(3,1,3)\nplt.title('M_Quartile Distribution')\nsns.countplot(x='M_Quartile',  hue='RFM_Points_Segments', data=df_rfm)\nplt.xlabel('')\nplt.show()","4de55418":"df_rfm.RFM_Points_Segments.value_counts().sort_index()","c7facc96":"df_uk.head()","590da467":"df_uk['InvoicePeriod']=pd.to_datetime(df_uk['InvoiceDate']).apply(lambda x: x.to_period('M'))\ndf_line=pd.DataFrame(df_uk.groupby('InvoicePeriod').CustomerID.nunique())\ndf_line['TotalPrice']=df_uk.groupby('InvoicePeriod').TotalPrice.sum()","1f5d9255":"fig, ax = plt.subplots()\ndf_line.CustomerID.plot(ax=ax,color='b',label='Unique Customers', marker='o')\nplt.legend(bbox_to_anchor=(0.0, 0.90), loc=2, borderaxespad=0.)\n\nax2 = ax.twinx()\ndf_line.TotalPrice.plot(ax=ax2,color='r',label='TotalPrice',linestyle='--', marker='o')\nplt.legend(bbox_to_anchor=(0.0, 0.80), loc=2, borderaxespad=0.)\nplt.gcf().axes[1].yaxis.get_major_formatter().set_scientific(False) # remove scientific notation\nax.grid()","d918192d":"life_span=pd.DataFrame(df.groupby('CustomerID').InvoiceDate.apply(lambda x:max(x).date() - min(x).date()))\nlife_span=life_span.agg({'InvoiceDate':lambda x:x.astype('timedelta64[D]')}).rename(columns= {'InvoiceDate':'life_span'})","5393d6e2":"df_kmeans=df_rfm[['Recency', 'Frequency', 'Monetary']]\ndf_kmeans['life_span']=life_span\ndf_kmeans","94fd2124":"plt.figure(figsize=(10,7))\nsns.heatmap(df_kmeans.corr(),annot=True, cmap=\"coolwarm\");","54dd58e4":"def col_plot(df,col_name,iqr=1.5):\n    plt.figure(figsize=(15,5))\n    \n    plt.subplot(141) # 1 satir x 4 sutun dan olusan ax in 1. sutununda calis\n    plt.hist(df[col_name], bins = 20)\n    f=lambda x:(np.sqrt(x) if x>=0 else -np.sqrt(-x))\n    \n    # \u00fc\u00e7 sigma aralikta(verinin %99.7 sini icine almasi beklenen bolum) iki kirmizi cizgi arasinda\n    plt.axvline(x=df[col_name].mean() + 3*df[col_name].std(),color='red')\n    plt.axvline(x=df[col_name].mean() - 3*df[col_name].std(),color='red')\n    plt.xlabel(col_name)\n    plt.tight_layout\n    plt.xlabel(\"Histogram \u00b13z\")\n    plt.ylabel(col_name)\n\n    plt.subplot(142)\n    plt.boxplot(df[col_name], whis = iqr)\n    plt.xlabel(f\"IQR={iqr}\")\n\n    plt.subplot(143)\n    plt.boxplot(df[col_name].apply(f), whis = iqr)\n    plt.xlabel(f\"ROOT SQUARE - IQR={iqr}\")\n\n    plt.subplot(144)\n    plt.boxplot(np.log(df[col_name]+1), whis = iqr)\n    plt.xlabel(f\"LOGARITMIC - IQR={iqr}\")\n    plt.show()","879c57bc":"for i in df_kmeans:\n    col_plot(df_kmeans,i,2)","64071b99":"features=[\n#           'Recency', \n          'Frequency', \n          'Monetary', \n#           'life_span',\n         ]","04889785":"df_log=df_kmeans.copy()\nfor i in features:\n    df_log[i]=np.log(df_log[i]+1)","134c0658":"def detect_outliers(df:pd.DataFrame, col_name:str, p=1.5) ->int:\n    ''' \n    this function detects outliers based on 3 time IQR and\n    returns the number of lower and uper limit and number of outliers respectively\n    '''\n    first_quartile = np.percentile(np.array(df[col_name].tolist()), 25)\n    third_quartile = np.percentile(np.array(df[col_name].tolist()), 75)\n    IQR = third_quartile - first_quartile\n                      \n    upper_limit = third_quartile+(p*IQR)\n    lower_limit = first_quartile-(p*IQR)\n    outlier_count = 0\n                      \n    for value in df[col_name].tolist():\n        if (value < lower_limit) | (value > upper_limit):\n            outlier_count +=1\n    return lower_limit, upper_limit, outlier_count","63eb310f":"iqr=2\nprint(f\"Number of Outliers for {iqr}*IQR after Logarithmed\\n\")\n\ntotal=0\nfor col in features:\n    if detect_outliers(df_log, col)[2] > 0:\n        outliers=detect_outliers(df_log, col, iqr)[2]\n        total+=outliers\n        print(\"{} outliers in '{}'\".format(outliers,col))\nprint(\"\\n{} OUTLIERS TOTALLY\".format(total))","4d9d76ad":"df_log.shape","bc5442ad":"iqr=2\nfor i in ['Frequency','Monetary']:\n    lower,upper,_=detect_outliers(df_log,i,iqr)\n    df_log=df_log[(df_log[i]>lower)&(df_log[i]<upper)]","e3fa1910":"df_log.shape","3453058f":"from sklearn.preprocessing import StandardScaler\n\ndf_scaled = pd.DataFrame(StandardScaler().fit_transform(df_log),\n                         columns=df_kmeans.columns,index=df_log.index)\ndf_scaled.head()","5ee01c41":"plt.figure(figsize=(15,15))\nsns.pairplot(df_scaled[['Recency', 'Frequency', 'Monetary','life_span']]);","e355796e":"!pip install pyclustertend","89fb3e87":"from sklearn.cluster import KMeans\nfrom pyclustertend import hopkins\nfrom sklearn.metrics import silhouette_score","8e6d6ff4":"hopkins(df_scaled,df_scaled.shape[0])","0dd9f133":"ssd = []\nK = range(2,10)\nfor k in K:\n    kmeans = KMeans(n_clusters = k).fit((df_scaled))\n    ssd.append(kmeans.inertia_)","50ebdf10":"plt.figure(figsize=(8,4))\nplt.plot(K, ssd, \"bo-\")\nplt.xlabel(\"Different k values\")\nplt.ylabel(\"inertia-error\")\nplt.title(\"Elbow Method\")\nplt.grid()\nplt.show()","b55761f8":"from yellowbrick.cluster import KElbowVisualizer\nkmeans = KMeans()\nvisu = KElbowVisualizer(kmeans, k = (2,10))\nvisu.fit(df_scaled)\nvisu.show();","637064fa":"ssd =[]\n\nK = range(2,10)\n\nfor k in K:\n    model = KMeans(n_clusters=k)\n    model.fit(df_scaled)\n    ssd.append(model.inertia_)\n    print(f'Silhouette Score for {k} clusters: {silhouette_score(df_scaled, model.labels_)}')","ce4f2e52":"kmeans = KMeans(n_clusters = 4).fit(df_scaled)\nlabels = kmeans.labels_\ndf_scaled['Kmeans_Label_ID']=labels","3a00ccc7":"keys=df_scaled.groupby('Kmeans_Label_ID').Frequency.mean().sort_values().index\nvalues=['Bronze','Silver','Gold','Diamond']\ndictionary = dict(zip(keys, values))\n\ndf_scaled['Kmeans_Label']=df_scaled.Kmeans_Label_ID.apply(lambda x:dictionary[x] )\ndf_scaled","6a1bc765":"df_scaled.Kmeans_Label.value_counts().sort_index()","d7e991f3":"df_scaled.Kmeans_Label.value_counts().plot.bar(width=0.3)\nplt.title('Distribution of Clustering Based on K-Means');","25f0fac5":"f, (ax1, ax2) = plt.subplots(1, 2, sharey=True,figsize=(14,6)) # sharey=True ile y eksen labels lari ortak kullanirlar.\nax1.set_title('Recency-Frequency')\nax1.set_xlabel('Recency')\nax1.set_ylabel('Frequency')\nax1.scatter(df_scaled.iloc[:,0],df_scaled.iloc[:,1],c=kmeans.labels_,cmap=\"rainbow\")\nax1.scatter(kmeans.cluster_centers_[:, 0], kmeans.cluster_centers_[:, 1], s=300,alpha=0.9, label = 'Centroids')\n\nax2.set_title(\"Frequency-Monetary\")\nax2.set_xlabel('Frequency')\nax2.set_ylabel('Monetary')\nax2.scatter(df_scaled.iloc[:,1],df_scaled.iloc[:,2],c=kmeans.labels_,cmap=\"rainbow\")\nax2.scatter(kmeans.cluster_centers_[:, 1], kmeans.cluster_centers_[:, 2], s=300,alpha=0.9, label = 'Centroids');\n","ecb6e82e":"plt.figure(figsize=(15,15))\nsns.pairplot(df_scaled[['Recency', 'Frequency', 'Monetary','life_span','Kmeans_Label']],hue='Kmeans_Label');","163ee014":"plt.figure(figsize=(20,10))\n\nplt.subplot(2,2,1)\nsns.stripplot(df_scaled['Kmeans_Label'], df_scaled['Recency'])\n\nplt.subplot(2,2,2)\nsns.stripplot(df_scaled['Kmeans_Label'], df_scaled['Frequency'])\n\nplt.subplot(2,2,3)\nsns.stripplot(df_scaled['Kmeans_Label'], df_scaled['Monetary'])\n\nplt.subplot(2,2,4)\nsns.stripplot(df_scaled['Kmeans_Label'], df_scaled['life_span'])\nplt.show()","2936f57b":"plt.figure(figsize=(15,6))\n\nplt.subplot(1,3,1)\nsns.boxplot(df_scaled['Kmeans_Label'], df_scaled['Recency'])\n\nplt.subplot(1,3,2)\nsns.boxplot(df_scaled['Kmeans_Label'], df_scaled['Frequency'])\n\nplt.subplot(1,3,3)\nsns.boxplot(df_scaled['Kmeans_Label'], df_scaled['Monetary'])\nplt.show()","e12a1a3c":"RFM_Points_Segments=['1-Best Customers','2-Loyal Customers', '3-Big Spenders', '4-Almost Lost', '5-Lost Customers', '6-Lost Cheap Customers']\nKmeans_Label=['Diamond','Gold', 'Silver', 'Bronze']\npd.crosstab(df_scaled['Kmeans_Label'],df_rfm['RFM_Points_Segments'])[RFM_Points_Segments].loc[Kmeans_Label]","883dfe9f":"df['InvoiceDate'] = pd.to_datetime(df['InvoiceDate'])\ndf.head(2)","65ebc7e1":"def extract_ym(df):\n    # Extract year and month from the the column. strftim convert datetime to string \n    return df.apply(lambda x: x.strftime('%Y-%m')).astype('datetime64[ns]')","258e4d13":"extract_ym(df.InvoiceDate)","230b6c0a":"# Alternative\nf=lambda x:pd.to_datetime(x).dt.to_period('M')\nf(df['InvoiceDate'])","110d420e":"def get_date_int(df, column):\n    years = df[column].dt.year\n    months = df[column].dt.month\n    return years, months","92f65ec0":"# Alternative\n# df['InvoiceMonth']=extract_ym(df.InvoiceDate)","eaceff4a":"# Apply function to invoice date to invoice month column\ndf['InvoiceMonth'] = df['InvoiceDate'].apply(lambda x: dt(x.year, x.month, 1) )\ndf['cohort_date'] = df.groupby('CustomerID')['InvoiceMonth'].transform('min')","2cec53dd":"cohort_year, cohort_month = get_date_int(df, 'cohort_date')\ninvoice_year, invoice_month = get_date_int(df, 'InvoiceDate')","589de9aa":"years_diff = invoice_year - cohort_year\nmonths_diff = invoice_month - cohort_month","cb38aef7":"df['CohortIndex'] = years_diff * 12 + months_diff + 1\ndf.head()","413a09b2":"# Count monthly active customers from each cohort\ngrouping_count = df.groupby(['cohort_date', 'CohortIndex'])\ncohort_data = grouping_count['CustomerID'].apply(pd.Series.nunique)\ncohort_data = cohort_data.reset_index()\ncohort_counts = cohort_data.pivot(index='cohort_date',\n                                  columns='CohortIndex',\n                                  values='CustomerID')\ncohort_counts","d3659e33":"# --Calculate Retention Rate--\ncohort_sizes = cohort_counts.iloc[:,0]\nretention = cohort_counts.divide(cohort_sizes, axis=0).apply(lambda x: round(x,2))\nretention.index = retention.index.strftime('%m-%Y')","8a4e3968":"retention.round(3) * 100 #to show the number as percentage ","fdbec7a8":"retention.T.columns","85dcedda":"plt.figure(figsize=(15, 6))\nplt.title('Retention rates')\nsns.heatmap(data = retention, annot = True, fmt = '.0%',vmin = 0.0,vmax = 0.5,cmap = 'BuGn')\nplt.show()","7eae5c19":"plt.figure(figsize=(15,6))\n# retention[list(range(1,14))].plot(figsize=(10,5))\nretention.loc[['12-2010', '02-2011', '04-2011','01-2011'],:].T.plot(figsize=(10,5))\n# retention.iloc[:,:].T.plot(figsize=(10,5))\nplt.title('Cohorts: Retention')\nplt.xlim(1,12)\nplt.ylim(0,0.6)\nplt.xlabel('Cohort Period')\nplt.ylabel('% of Cohort Purchasing')","48954df4":"# --Calculate Average Quantity--\ngrouping_qty = df.groupby(['cohort_date', 'CohortIndex'])\ncohort_data_qty = grouping_qty['Quantity'].mean()\ncohort_data_qty = cohort_data_qty.reset_index()\naverage_quantity = cohort_data_qty.pivot(index='cohort_date',\n                                     columns='CohortIndex',\n                                     values='Quantity')\naverage_quantity.index = average_quantity.index.strftime('%m-%Y')","3a29d984":"# Plot average quantity\nplt.figure(figsize=(15, 6))\nplt.title('Average Quantity')\nsns.heatmap(data = average_quantity, annot=True, cmap='Blues')\nplt.show()","555c112d":"# --Calculate Average Price--\ngrouping_price = df.groupby(['cohort_date', 'CohortIndex'])\ncohort_data_price = grouping_price['TotalPrice'].mean()\ncohort_data_price = cohort_data_price.reset_index()\naverage_price = cohort_data_price.pivot(index='cohort_date',\n                                     columns='CohortIndex',\n                                     values='TotalPrice')\naverage_price.index = average_price.index.strftime('%m-%Y')","1a126c39":"# Plot average sales\nplt.figure(figsize=(15, 6))\nplt.title('Average Price')\nsns.heatmap(data = average_price, annot=True, cmap='Blues')\nplt.show()","d24cc21b":"### v. Monetary: Total amount of money spent\n\nThe monetary value is calculated by adding together the cost of the customers' purchases.\n","f74999dd":"![indir%20%281%29.png](attachment:indir%20%281%29.png)","98f9b19d":"### vii. Explore the UK Market\n","0f0aa3bc":"**Explanation:**\n* We can say: Distribution of Clustering Based on RFM_Points is more successful. It is closer to normal distribution, even through left skewed.\n* We will continue with the visualization of Distribution of Clustering Based on RFM_Points","e1926a09":"### ii. Model Fitting","c185508c":"1. Create two functions, one for Recency and one for Frequency and Monetary. For Recency, customers in the first quarter should be scored as 4, this represents the highest Recency value. Conversely, for Frequency and Monetary, customers in the last quarter should be scored as 4, representing the highest Frequency and Monetary values.","d6652ed5":"1. What's the total revenue per country?","2014e29f":"2. Plot RFM distributions","b8ccbac7":"### iii. Data Normalization","34ba21f4":"### i. Creating the RFM Segmentation Table\n","06fa120c":"**Annotation:**\n\nLimitations of K-means clustering:\n\n1. There is no assurance that it will lead to the global best solution.\n2. Can't deal with different shapes(not circular) and consider one point's probability of belonging to more than one cluster.\n\nThese disadvantages of K-means show that for many datasets (especially low-dimensional datasets), it may not perform as well as you might hope.","c2700781":"### vi. Explore Customers by Country","111e8c18":"6. Plot RFM distributions","3a4ab8fd":"## Create the 3rd Cohort: Average Sales\n","bec51817":"**Explanation:**\n* There is no so clear meaningful pattern in this graph. It needs scaling.","f1adda37":"We see that there are negative values in the Quantity and UnitPrice columns. These are possibly canceled and returned orders. Let's check it out.","b420a0c8":"2. Score customers from 1 to 4 by applying the functions you have created. Also create separate score column for each value. ","dd9273d9":"### v. Explore the Orders\n","a93aa8ea":"Now we will use the function created above to convert all the invoice dates into respective month date format.","c764e4a2":"If the invoice number starts with the letter \"C\", it means the order was cancelled. Or those who abandon their order.","1d3bfee4":"### iv. Frequency: Number of purchases\n\nTo calculate how many times a customer purchased something, we need to count how many invoices each customer has. To calculate the frequency values, follow these steps in order:","5fbaea8b":"When we filter canceled orders by Quantity> 0 or filter non-canceled orders by Quantity <0 nothing returns, this confirms that negative values mean the order was canceled. So lets find out how many orders were cancelled?","5f2dfb94":"1. Choose a date as a point of reference to evaluate how many days ago was the customer's last purchase.","08d671a1":"1. You can use the logarithm method to normalize the values in a column.","2000d1df":"2. Create a new column called Date which contains the invoice date without the timestamp","3aa1fef2":"In the age of the internet and e-commerce, companies that do not expand their businesses online or utilize digital tools to reach their customers will run into issues like scalability and a lack of digital precsence. An important marketing strategy e-commerce businesses use for analyzing and predicting customer value is customer segmentation. Customer data is used to sort customers into group based on their behaviors and preferences.\n\n**[RFM](https:\/\/www.putler.com\/rfm-analysis\/) (Recency, Frequency, Monetary) Analysis** is a customer segmentation technique for analyzing customer value based on past buying behavior. RFM analysis was first used by the direct mail industry more than four decades ago, yet it is still an effective way to optimize your marketing.\n<br>\n<br>\nOur goal in this Notebook is to cluster the customers in our data set to:\n - Recognize who are our most valuable customers\n - Increase revenue\n - Increase customer retention\n - Learn more about the trends and behaviors of our customers\n - Define customers that are 5-Lost Customers\n\nWe will tart with **RFM Analysis** and then compliment our findings with predictive analysis using **K-Means Clustering Algorithms.**\n\n- RECENCY (R): Time since last purchase\n- FREQUENCY (F): Total number of purchases\n- MONETARY VALUE (M): Total monetary value\n\n\n\n\nBenefits of RFM Analysis\n\n- Increased customer retention\n- Increased response rate\n- Increased conversion rate\n- Increased revenue\n\nRFM Analysis answers the following questions:\n - Who are our best customers?\n - Who has the potential to be converted into more profitable customers?\n - Which customers do we need to retain?\n - Which group of customers is most likely to respond to our marketing campaign?\n ","182882d9":"1. Divide the df_rfm into quarters","75fa65c9":"### i. Define the Optimal Number of Clusters","1ae8c06e":"**Note**:For better detail, the data can be assigned to more clusters, we will cluster them in 6 different levels.","4a34d4e5":"1. Create df_uk DataFrame","872b4203":"### i. Take a look at relationships between InvoiceNo, Quantity and UnitPrice columns.","46aa53c6":"**Explanation:**\n* Her ay icin musteri yogunlugu ve dolayisiyla toplam satis farklilik gosterdigi goruluyor. O halde bir musterinin sistemdeki 'life sapan' ini de dikkate almamiz gereken bir parametredir diyebiliriz.","65604f9a":"[Silhouette Coefficient](http:\/\/scikit-learn.org\/stable\/auto_examples\/cluster\/plot_kmeans_silhouette_analysis.html)\n* her veri i\u00e7in iki uzakl\u0131\u011f\u0131 baz al\u0131r. Bu uzakl\u0131klardan ilki verinin bulundu\u011fu k\u00fcmeye ait di\u011fer verilere olan uzakl\u0131klar\u0131n ortalamas\u0131d\u0131r. \n* \u0130kincisi veriye en yakin komsu k\u00fcmenin tum verilerine olan uzakl\u0131klar\u0131n ortalamas\u0131d\u0131r.\n* S de\u011feri ile ifade edilir, s, 1\u2019e yakinsa high clustering, -1e yakinsa low clustering e\u011filimi gosterir.","767d3508":"Businesses have this ever-lasting urge to understand their customers. The better you understand the customer, the better you serve them, and the higher the financial gain you receive from that customer. Since the dawn of trade, this process of understanding customers for a strategic gain has been there practiced and this task is known majorly as [Customer Segmentation](https:\/\/clevertap.com\/blog\/rfm-analysis\/).\nWell as the name suggests, Customer Segmentation could segment customers according to their precise needs. Some of the common ways of segmenting customers are based on their Recency-Frequency-Monatory values, their demographics like gender, region, country, etc, and some of their business-crafted scores. You will use Recency-Frequency-Monatory values for this case.\n\nIn this section, you will create an RFM Segmentation Table where you segment your customers by using the RFM table. For example, you can label the best customer as \"Big Spenders\" and the lost customer as \"Lost Customer\".","86956955":"## K-Means Implementation\n\nFor k-means, you have to set k to the number of clusters you want, but figuring out how many clusters is not obvious from the beginning. We will try different cluster numbers and check their [silhouette coefficient](http:\/\/scikit-learn.org\/stable\/auto_examples\/cluster\/plot_kmeans_silhouette_analysis.html). The silhouette coefficient for a data point measures how similar it is to its assigned cluster from -1 (dissimilar) to 1 (similar). \n<br>\n<br>\n**Note**: K-means is sensitive to initializations because they are critical to qualifty of optima found. Thus, we will use smart initialization called \"Elbow Method\".","de3a081c":"### Descriptive Analysis","e701313a":"5. Drop Last_Purchase_Date since we don't need it anymore","9cc32ea9":"### i. Extract the Month of the Purchase\nFirst we will create a function, which takes any date and returns the formatted date with day value as 1st of the same month and Year.","26bfc269":"# #Project Structures\n\n- Data Cleaning & Exploratory Data Analysis\n- RFM Analysis\n- Customer Segmentation\n- Applying K-Means Clustering\n- Create Cohort and Conduct Cohort Analysis","57e0cbd3":"2. How many customers do we have in each segment?","ea620b09":"2. Visualize number of customer per country","cce236b3":"# #Determines\n\nUsing the [Online Retail dataset](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Online+Retail) from the UCI Machine Learning Repository for exploratory data analysis, ***Customer Segmentation***, ***RFM Analysis***, ***K-Means Clustering*** and ***Cohort Analysis***.\n\nThis is a transnational data set which contains all the transactions occurring between 01\/12\/2010 and 09\/12\/2011 for a UK-based and registered non-store online retail. The company mainly sells unique all-occasion gifts. Many customers of the company are wholesalers.\n\nFeature Information:\n\n**InvoiceNo**: Invoice number. *Nominal*, a 6-digit integral number uniquely assigned to each transaction. If this code starts with letter 'c', it indicates a cancellation. \n<br>\n**StockCode**: Product (item) code. *Nominal*, a 5-digit integral number uniquely assigned to each distinct product.\n<br>\n**Description**: Product (item) name. *Nominal*. \n<br>\n**Quantity**: The quantities of each product (item) per transaction. *Numeric*.\n<br>\n**InvoiceDate**: Invoice Date and time. *Numeric*, the day and time when each transaction was generated.\n<br>\n**UnitPrice**: Unit price. *Numeric*, Product price per unit in sterling.\n<br>\n**CustomerID**: Customer number. *Nominal*, a 5-digit integral number uniquely assigned to each customer.\n<br>\n**Country**: Country name. *Nominal*, the name of the country where each customer resides.\n\n\n---\n\n\nFirst of all, to observe the structure of the data and missing values, you can use exploratory data analysis and data visualization techniques.\n\nYou must do descriptive analysis. Because you must understand the relationship of the features to each other and clear the noise and missing values in the data. After that, the data set will be ready for RFM analysis.\n\nBefore starting the RFM Analysis, you will be asked to do some analysis regarding the distribution of *Orders*, *Customers* and *Countries*. These analyzes will help the company develop its sales policies and contribute to the correct use of resources.\n\nYou will notice that the UK not only has the most sales revenue, but also the most customers. So you will continue to analyze only UK transactions in the next RFM Analysis, Customer Segmentation and K-Means Clustering topics.\n\nNext, you will begin RFM Analysis, a customer segmentation technique based on customers' past purchasing behavior. \n\nBy using RFM Analysis, you can enable companies to develop different approaches to different customer segments so that they can get to know their customers better, observe trends better, and increase customer retention and sales revenues.\n\nYou will calculate the Recency, Frequency and Monetary values of the customers in the RFM Analysis you will make using the data consisting of UK transactions. Ultimately, you have to create an RFM table containing these values.\n\nIn the Customer Segmentation section, you will create an RFM Segmentation Table where you segment your customers by using the RFM table. For example, you can label the best customer as \"Big Spenders\" and the lost customer as \"Lost Customer\".\n\nWe will segment the customers ourselves based on their recency, frequency, and monetary values. But can an **unsupervised learning** model do this better for us? You will use the K-Means algorithm to find the answer to this question. Then you will compare the classification made by the algorithm with the classification you have made yourself.\n\nBefore applying K-Means Clustering, you should do data pre-processing. In this context, it will be useful to examine feature correlations and distributions. In addition, the data you apply for K-Means should be normalized.\n\nOn the other hand, you should inform the K-means algorithm about the number of clusters it will predict. You will also try the *** Elbow method *** and *** Silhouette Analysis *** to find the optimum number of clusters.\n\nAfter the above operations, you will have made cluster estimation with K-Means. You should visualize the cluster distribution by using a scatter plot. You can observe the properties of the resulting clusters with the help of the boxplot. Thus you will be able to tag clusters and interpret results.\n\nFinally, you will do Cohort Analysis with the data you used at the beginning, regardless of the analysis you have done before. Cohort analysis is a subset of behavioral analytics that takes the user data and breaks them into related groups for analysis. This analysis can further be used to do customer segmentation and track metrics like retention, churn, and lifetime value.\n","617ff293":"### iii. Handling Missing Values","b7748d19":"### ii. Visualize Feature Distributions\n\nTo get a better understanding of the dataset, you can costruct a scatter matrix of each of the three features in the RFM data.","3bfbea90":"[The Elbow Method](https:\/\/en.wikipedia.org\/wiki\/Elbow_method_(clustering) \n* aciklanan varyans(Sum of squared distances) ve k\u00fcme sayisi(k) arasindaki ili\u015fkiye dayanarak cozum geli\u015ftiren bir y\u00f6ntem, \n* yani aciklanan varyans, k\u00fcme sayisinin fonksiyonu olarak \u00e7izilir, grafikte dirse\u011fin kirildigi nokta, k nin optimal degeridir\n* minimum k ile minimum hatanin alindigi optimum noktayi baz alacagiz. Keskin dususun en son bittigi yeri alacagiz. ","2639b209":"### ii. Review df_uk DataFrame","da65a557":"## Import Modules, Load Data & Data Review","b12dcfe5":"1. Make a copy of df_uk and drop duplicates","b635978b":"3. Visualize total cost per country","bfbc635c":"**Explanation**\n* There is no special meaning of 'A' and 'B' letter at the end fo some StockCodes","5ddfd5ec":"### iv. Assign the Label","a05bd61e":"**Insights:**\n* we can see from the above chart that more users tend to purchase as time goes on.\n* The 12-2010 cohort is the strongest. The 02-2011 and 04-2011 cohort are the weaknest cohort.","f5db6772":"2. What are the most popular products that are bought in the UK?","b4217113":"1. Create your plot and resize it.","350a4ecb":"### i. Import Libraries","b16fcf74":"**Explanation**\n* If you have binary values, discrete attributes or categorial attributes, stay away from k-means. K-means needs to compute means, and the mean value is not meaningful on this kind of data.\n\n**Scaling:**\n* If you have attributes with a well-defined meaning. Say, latitude and longitude, then you should not scale your data, because this will cause distortion.\n\n* If you have mixed numerical data, where each attribute is something entirely different (say, shoe size and weight), has different units attached (lb, tons, m, kg ...) then these values aren't really comparable anyway;scaling them is a best-practise to give equal weight to them.","56457509":"2. Calculate the frequency of purchases","ccd86876":"# #Tasks\n\n#### 1. Data Cleaning & Exploratory Data Analysis\n\n- Import Modules, Load Data & Data Review\n- Follow the Steps Below\n\n    *i. Take a look at relationships between InvoiceNo, Quantity and UnitPrice columns.*\n    \n    *ii. What does the letter \"C\" in the invoiceno column mean?*\n    \n    *iii. Handling Missing Values*\n    \n    *iv. Clean the Data from the Noise and Missing Values*\n    \n    *v. Explore the Orders*\n    \n    *vi. Explore Customers by Country*\n    \n    *vii. Explore the UK Market*\n    \n#### 2. RFM Analysis\n\n- Follow the steps below\n\n   *i. Import Libraries*\n   \n   *ii. Review \"df_uk\" DataFrame (the df_uk what you create at the end of the Task 1)*\n   \n   *iii. Calculate Recency*\n   \n   *iv. Calculate Frequency*\n   \n   *v. Calculate Monetary Values*\n   \n   *vi. Create RFM Table*\n\n#### 3. Customer Segmentation with RFM Scores\n- Calculate RFM Scoring\n\n    *i. Creating the RFM Segmentation Table*\n \n- Plot RFM Segments\n\n#### 4. Applying K-Means Clustering\n- Data Pre-Processing and Exploring\n\n    *i. Define and Plot Feature Correlations*\n \n    *ii. Visualize Feature Distributions*\n \n    *iii. Data Normalization*\n\n- K-Means Implementation\n\n    *i. Define Optimal Cluster Number (K) by using \"Elbow Method\" and \"Silhouette Analysis\"*\n \n    *ii. Visualize the Clusters*\n \n    *iii. Assign the label*\n \n    *iv. Conclusion*\n \n#### 5. Create Cohort and Conduct Cohort Analysis\n- Future Engineering\n\n    *i. Extract the Month of the Purchase*\n \n    *ii. Calculating time offset in Months i.e. Cohort Index*\n \n- Create 1st Cohort: User Number & Retention Rate \n\n    *i. Pivot Cohort and Cohort Retention*\n \n    *ii. Visualize analysis of cohort 1 using seaborn and matplotlib*\n\n- Create 2nd Cohort: Average Quantity Sold \n\n    *i. Pivot Cohort and Cohort Retention*\n \n    *ii. Visualize analysis of cohort 2 using seaborn and matplotlib*\n\n- Create 3rd Cohort: Average Sales\n\n    *i. Pivot Cohort and Cohort Retention*\n \n    *ii. Visualize analysis of cohort 3 using seaborn and matplotlib*\n    \n- **Note: There may be sub-tasks associated with each task, you will see them in order during the course of the work.**\n","b46223c9":"# WELCOME!","5edc0632":"### ii. Calculating time offset in Months i.e. Cohort Index:\nCalculating time offset for each transaction will allows us to report the metrics for each cohort in a comparable fashion.\nFirst, you will create 4 variables that capture the integer value of years, months for Invoice and Cohort Date using the get_date_int() function which you'll create it below.","e8ef6e29":"**Outlier Detection**","f22b3665":"**Explanations:**\n* \"1-Best Customers\" >> {444}\n* \"2-Loyal Customers\"\n* \"3-Big Spenders\"\n* \"4-Almost Lost\"\n* \"5-Lost Customers\"\n* \"6-Lost Cheap Customers\" >> {111}","78152467":"3. Plot RFM distributions","29d37006":"**Explanation:**","41d6df1a":"Since we will be performing Cohort Analysis based on transaction records of customers, the columns we will be dealing with mainly:\n- Invoice Data\n- CustomerID\n- Price\n- Quantity\n\nThe following steps will performed to generate the Cohort Chart of Retention Rate:\n- Month Extraction from InvioceDate column\n- Assigning Cohort to Each Transaction\n- Assigning Cohort Index to each transaction\n- Calculating number of unique customers in each Group of (ChortDate,Index)\n- Creating Cohort Table for Retention Rate\n- Creating the Cohort Chart using the Cohort Table\n\nThe Detailed information about each step is given below:","32603379":"### vi. Create RFM Table\nMerge the recency, frequency and motetary dataframes","9f850f76":"**Conclusion**\n","638da0dd":"1. Create a scatter plot and select cluster centers","7c50a7c3":"**Method-1**","3dc1b57f":"You will use this function to extract the integer values for Invoice as well as Cohort Date in 3 seperate series for each of the two columns","109dda6a":"**Evaluations:**\n* According to Hopkins Score, we can say our dataframe tends to clustering too much.","2fe2a490":"### ii. Visualize analysis of cohort 3 using seaborn and matplotlib modules","73f3c220":"# 3. Customer Segmentation with RFM Scores","e374926a":"**Drop Outliers**","7bd52f72":"### v. Conclusion\n\nDiscuss your final results. Compare your own labels from the Customer Segmentation with the labels found by K-Means.","799b15c7":"Use the variables created above to calcualte the difference in days and store them in cohort Index column.","48c9d2e9":"3. Let's see how this compares to the number of unique products per customer.","b04fe0ce":"**Method-2**","d3292a7d":"**Evaluations:**\n* `The CustomerID` and `Description` fields have null values.\n* `Quantity` and `UnitPrice` should have a value >= 0, but from the summary above there are negative values for the two columns.","c154c321":"1. Find the unique number of InvoiceNo  per customer","3d98bb8d":"# 1. Data Cleaning & Exploratory Data Analysis","fb079407":"Using customer segmentation categories found [here](http:\/\/www.blastam.com\/blog\/rfm-analysis-boosts-sales) we can formulate different marketing strategies and approaches for customer engagement for each type of customer.\n\nNote: The author in the article scores 1 as the highest and 4 as the lowest","4c7d16a5":"3. Group by CustomerID and check the last date of purchase","bb0f0f12":"#### The UK not only has the most sales revenue, but also the most customers. Since the majority of this data set contains orders from the UK, we can explore the UK market further by finding out what products the customers buy together and any other buying behaviors to improve our sales and targeting strategy.","56f91d81":"**Comparison of the Two Methods**","8b585dcf":"# 5. Create Cohort & Conduct Cohort Analysis\n[Cohort Analysis](https:\/\/medium.com\/swlh\/cohort-analysis-using-python-and-pandas-d2a60f4d0a4d) is specifically useful in analyzing user growth patterns for products. In terms of a product, a cohort can be a group of people with the same sign-up date, the same usage starts month\/date, or the same traffic source.\nCohort analysis is an analytics method by which these groups can be tracked over time for finding key insights. This analysis can further be used to do customer segmentation and track metrics like retention, churn, and lifetime value.\n\nFor e-commerce organizations, cohort analysis is a unique opportunity to find out which clients are the most valuable to their business. by performing Cohort analysis you can get the following answers to the following questions:\n\n- How much effective was a marketing campaign held in a particular time period?\n- Did the strategy employ to improve the conversion rates of Customers worked?\n- Should I focus more on retention rather than acquiring new customers?\n- Are my customer nurturing strategies effective?\n- Which marketing channels bring me the best results?\n- Is there a seasonality pattern in Customer behavior?\n- Along with various performance measures\/metrics for your organization.","5a25dcce":"## Data Pre-Processing and Exploring","a5c63a80":"4. Define RFM_Points function that tags customers by using RFM_Scores and Create a new variable RFM_Scores_Segment","ff0173ca":"> Interquartel range (IQR) e gore 4 grup ta clustering yapacagiz","fe59b07d":"## Calculate RFM Scoring\n\nThe simplest way to create customer segments from an RFM model is by using **Quartiles**. We will assign a score from 1 to 4 to each category (Recency, Frequency, and Monetary) with 4 being the highest\/best value. The final RFM score is calculated by combining all RFM values. For Customer Segmentation, you will use the df_rfm data set resulting from the RFM analysis.\n<br>\n<br>","e6afa033":"### ii. What does the letter \"C\" in the InvoiceNo column mean?","28a36907":"# 2. RFM Analysis","9c2d13ad":"## Plot RFM Segments","6aa199ea":"### i. Pivot Cohort and Cohort Retention","fe480edb":"How we want to continue this analysis depends on how the business plans to use the results and the level of granularity the business stakeholders want to see in the clusters. We can also ask what range of customer behavior from high to low value customers are the stakeholders interested in exploring. From those answers, various methods of clustering can be used and applied on RFM variable or directly on the transaction data set.","42a8c5de":"Since the customer ID's are missing, lets assume these orders were not made by the customers already in the data set because those customers already have ID's. \n\nWe also don't want to assign these orders to those customers because this would alter the insights we draw from the data. \n","ca58bef4":"**Explanation:**\n* Iptal edilen faturalarin quantity degerleri, o faturaya en yakin tarihli gecmis ozdes faturadan cikarilarak data sette duzeltme yapilmalidir. Bu duzeltme bir sonraki versiyonda yapilacaktir. Bu versiyonda yalniz pozitif degerli quantityler ile analize devam edildi.","536e1b70":"* If RFM_Points == 12, then \"1-Best Customers\"\n* If RFM_Points == 11, then \"2-Loyal Customers\"\n* If  9 <= RFM_Points <=10, then \"3-Big Spenders\"\n* If  7 <= RFM_Points <=8, then \"4-Almost Lost\"\n* If  4 <= RFM_Points <=6, then \"5-Lost Customers\"\n* If 3 == RFM_Points, \"6-Lost Cheap Customers\"","fe8ba724":"**Explanation:**\n* It is exceptional to have Negative Quantity and Unit Price. We cannot use these rows for the analysis. Therefore we will drop them.","5a6bf4dd":"[Hopkins Test](https:\/\/en.wikipedia.org\/wiki\/Hopkins_statistic)\n* Null Hypothesis(Ho) ve Alternative Hypothesis(Ha) temeline dayaniyor.\n* Null Hypothesis(Ho): Uniform dagilim var, anlamli k\u00fcmeleme yok.\n* Alternative Hypothesis(Ha): Veri, ratsgele veri noktalarindan olu\u015fur. Yani Kumeleme vardir.\n* [0,1] araliginda bir score verir. score, 0\u2019a yakla\u015ft\u0131k\u00e7a veri uniform degil,yani clusteringe meyilli\n* 1\u2019e yakla\u015ft\u0131k\u00e7a uniform yapi var, 0.5 gecmedikce k\u00fcmelenebilir olarak ifade edilir. pratikte 0.3 sinir alinir.","372db1ee":"## Future Engineering","084c52eb":"### ii. Visualize analysis of cohort 2 using seaborn and matplotlib modules","4976bec1":"**Explanation:**\n* Repetitive rows should be dropped as this will manipulate the analysis.","cb0d91b7":"1. Calculate sum total cost by customers and named \"Monetary\"","c2abc031":"### iii. Visualize the Clusters","6f47d858":"### i. Pivot Cohort and Cohort Retention","be367bfa":"5. Calculate average values for each RFM_Points, and return a size of each segment ","26fffec1":"### iii. Recency: Days since last purchase\nTo calculate the recency values, follow these steps in order:\n\n1. To calculate recency, we need to choose a date as a point of reference to evaluate how many days ago was the customer's last purchase.\n2. Create a new column called Date which contains the invoice date without the timestamp\n3. Group by CustomerID and check the last date of purchase\n4. Calculate the days since last purchase\n5. Drop Last_Purchase_Date since we don't need it anymore\n6. Plot RFM distributions","5f8ca4c9":"### ii. Visualize analysis of cohort 1 using seaborn and matplotlib modules","540d946a":"# 3. Applying K-Means Clustering","53e760e4":"## Create 1st Cohort: User number & Retention Rate","ab8c752a":"### We will continue analyzing the UK transactions with customer segmentation.","458e1df7":"2. Visualize Cluster Id vs Recency, Cluster Id vs Frequency and Cluster Id vs Monetary using Box plot. Also evaluate the results. ","9a6b3dbb":"### i. Pivot Cohort and Cohort Retention","f112b2fd":"Now that we have our customers segmented into 6 different categories, we can gain further insight into customer behavior by using predictive models in conjuction with out RFM model.\nPossible algorithms include **Logistic Regression**, **K-means Clustering**, and **K-nearest Neighbor**. We will go with [K-Means](https:\/\/towardsdatascience.com\/understanding-k-means-clustering-in-machine-learning-6a6e67336aa1) since we already have our distinct groups determined. K-means has also been widely used for market segmentation and has the advantage of being simple to implement.","7ffdc27c":"3. Now that scored each customer, you'll combine the scores for segmentation.","4e07e78f":"Welcome to \"RFM Customer Segmentation & Cohort Analysis Project\". This is the first project of the Capstone Project Series, which consists of 4 different project that contain different scenarios.\n\nThis is a project which you will learn what is RFM? And how to apply RFM Analysis and Customer Segmentation using K-Means Clustering. Also you will improve your Data Cleaning, Data Visualization and Exploratory Data Analysis capabilities. On the other hand you will create Cohort and Conduct Cohort Analysis. \n\nBefore diving into the project, please take a look at the determines and project structure.\n\n- **NOTE:** This tutorial assumes that you already know the basics of coding in Python and are familiar with the theory behind K-Means Clustering.\n\n","07ac833d":"For e-commerce organisations, cohort analysis is a unique opportunity to find out which clients are the most valuable to their business. by performing Cohort analysis you can get answers to following questions:\n\n- How much effective was a marketing campaign held in a particular time period?\n- Did the strategy employed to improve the conversion rates of Customers worked?\n- Should I focus more on retention rather than acquiring new customers?\n- Are my customer nurturing strategies effective?\n- Which marketing channels bring me the best results?\n- Is there a seasoanlity pattern in Customer behahiour?","d516f78e":"#### 9288 or about 36% of the orders were cancelled. Looking deeper into why these orders were cancelled may prevent future cancellations. Now let's find out what a negative UnitPrice means.\n","442fbf55":"Create Heatmap and evaluate the results ","f3755168":"### iv. Clean the Data from the Noise and Missing Values","f1b3a696":"4. Calculate the days since last purchase","03bf9c14":"**Evaluations:**\n* we can say, if cancellation = 1, quantity < 0","4f6fbadb":"Fit the K-Means Algorithm with the optimal number of clusters you decided and save the model to disk.","d6a7c9a5":"* If RFM_Scores == '444', then \"1-Best Customers\"\n* If RFM_Scores == 'X4X', then \"2-Loyal Customers\"\n* If RFM_Scores == 'XX4', then \"3-Big Spenders\"\n* If RFM_Scores == '244', then \"4-Almost Lost\"\n* If RFM_Scores == '144', then \"5-Lost Customers\"\n* If RFM_Scores == '111', then \"6-Lost Cheap Customers\"","9fb4067e":"2. What's the average number of unqiue items per order or per customer?","253f3509":"## Create the 2nd Cohort: Average Quantity Sold","90218e77":"2. Plot normalized data with scatter matrix or pairplot. Also evaluate results."}}