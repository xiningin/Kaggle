{"cell_type":{"ae597ce7":"code","0cf78755":"code","5a226b9d":"code","f1c25eea":"code","53d7cc8c":"code","44a881f6":"code","468ff6e4":"code","b02857a4":"code","574ce099":"code","4fbd8cf9":"code","b22ec991":"code","0cd57018":"code","16abda22":"code","0576be2d":"code","659a6d2e":"code","9245da38":"code","f14617b0":"code","0a11c229":"code","5fea632c":"code","613c0ba5":"code","cbb8e6fa":"code","27ddf3e5":"code","439c36c2":"code","e2953690":"code","a75494ee":"code","263b29d0":"code","c5103778":"code","08576aa0":"code","2584c942":"code","f6e300bb":"code","efb46c67":"code","3a944196":"code","5dc1231d":"code","4bf300aa":"code","e486e5f5":"code","64cc27d0":"code","f98c4823":"code","ed236999":"code","655dad97":"code","149c5342":"code","0552e38e":"code","2e1d3370":"code","483dc1e4":"code","40a17e26":"code","c32c698d":"code","65568831":"code","d73b94c4":"code","de07e8ca":"code","64a8218a":"code","cc0fec9f":"code","f9185ffa":"code","08b22f61":"code","f158e903":"code","8464afba":"code","aca4af16":"code","9bd0eca5":"code","9b4574b7":"code","3cccfc57":"code","bcc052a7":"code","86175a83":"code","af912abc":"code","f27f76de":"code","e5f867d9":"code","322ac907":"code","fb9a8f61":"code","c5a0ee8a":"code","9f4447a9":"code","e9eadc75":"code","d936d141":"code","faa8d00a":"code","0290970e":"code","3df71c7c":"code","368a2a6c":"code","93ae822e":"code","381d44b9":"code","828d4ae8":"code","233a623f":"code","2c35d44d":"code","116823af":"code","7472f76f":"code","317c3107":"code","47060c03":"code","104ae2e5":"code","845d3325":"code","7bb94ca9":"code","0d3e1dd1":"code","ef7226ea":"code","0e31cdf8":"code","cb9a6432":"code","29ec0d90":"code","d8e055b9":"code","48d9e0ab":"code","59f612b9":"code","11f8109c":"code","e9049d7f":"code","5c593353":"code","62739cc6":"code","808dfbea":"code","8a524f11":"code","9a251e62":"code","a1e2877a":"code","6b3f8f58":"code","c8bc0f3f":"code","2f34b418":"code","e402b50e":"code","ad560cbe":"code","17438011":"code","800040c7":"code","600f25dc":"code","bcd1ca97":"code","393f1917":"code","e64c2c8b":"code","c5a9a3d6":"code","358166a4":"code","a4dc5917":"code","15c0be12":"code","52b404af":"code","30b22724":"code","512c800d":"code","4963ef03":"code","ee143cfe":"code","8d0f5323":"code","434bd449":"code","9a6ad432":"code","14c3bd05":"code","eaf9d081":"code","191a53a1":"code","94aafdd3":"code","2f49986a":"code","f084dd4b":"code","e1bbfbd6":"code","b3ce5863":"code","3cab4a3a":"code","0a584067":"code","30c72c28":"code","80c52339":"code","0f275c27":"code","a73d30e5":"code","9ae98b13":"code","1b622c19":"code","53e3f3d3":"code","d961b6f5":"code","2698c987":"code","d079005d":"code","fab9ca48":"code","bed16f1a":"code","651297d0":"code","8be00fd9":"code","88eafc69":"code","2bb6f4f8":"code","9a2ec4b2":"code","a16f5e5b":"code","3001af44":"code","4d35aab1":"code","b5a11c5e":"code","907f910c":"code","40780c79":"code","5622c2eb":"code","62630cc0":"code","02c86708":"code","ee6ccf23":"code","6c0d9408":"code","681e71e2":"code","291a9617":"code","4288bf6a":"code","0f3c7b49":"code","1c58f500":"code","6f9d9b4c":"code","35997f82":"code","3487a80f":"code","191d6710":"code","cf68eaf5":"code","4497c6eb":"code","1a69d0d1":"code","4e9f8f1e":"code","bf777b24":"code","0463b95e":"markdown","3f5c3d5a":"markdown","bd2d4131":"markdown","63c1a751":"markdown","a961a5a1":"markdown","f9a617db":"markdown","f825f288":"markdown","fc6f1c30":"markdown","0c04f7ea":"markdown","dc97dd0d":"markdown","f2667297":"markdown","5f4e98f8":"markdown","ab45af8c":"markdown","6197a105":"markdown","2ed4a19e":"markdown","c9f7f550":"markdown","9fa5106c":"markdown","e34a9173":"markdown","5362fbd9":"markdown","f9ba2a15":"markdown","9a2af265":"markdown","b900256b":"markdown","307f9bd5":"markdown","c0627b21":"markdown","9fdacd8f":"markdown","4297a5c1":"markdown","cf90ae8e":"markdown","1f52c008":"markdown","7fbaad68":"markdown","ae2d23d3":"markdown","f1e885d2":"markdown","ada093ea":"markdown","9e224a80":"markdown","ad7bcd4e":"markdown","ffa7ccb4":"markdown","1540ec7d":"markdown","b5cb7885":"markdown","8a723021":"markdown","9d645e14":"markdown","bbfb46b4":"markdown","d9d45b7e":"markdown","12d125aa":"markdown","ffbe1492":"markdown","e35962f1":"markdown","7c6b985a":"markdown","3411075a":"markdown","9850a539":"markdown","9906695b":"markdown","eab05b57":"markdown","17b00cae":"markdown","65e613e6":"markdown","8fb9cd54":"markdown","4f916f48":"markdown","733fb370":"markdown","a6eff900":"markdown","3d6ee6f0":"markdown","3e283aba":"markdown","51fed592":"markdown","cb0d7147":"markdown","ed6d8e63":"markdown","64c115e0":"markdown","95d26ea1":"markdown","d94ff31e":"markdown","4b1f87b3":"markdown","11a24a54":"markdown","2164ac4c":"markdown","0101db96":"markdown","90cc96da":"markdown","0bd117c5":"markdown","4068a954":"markdown","6d7127fd":"markdown","95d89b69":"markdown","6ec1e271":"markdown","bd7fa99e":"markdown","05af63a3":"markdown","9d35aa1e":"markdown","9d19aee9":"markdown","195c9382":"markdown","1cf2f8e9":"markdown","ac136e4e":"markdown","f57825ab":"markdown","b8c9c856":"markdown","32338397":"markdown","d3d03104":"markdown","8095be77":"markdown","a109402a":"markdown","832f0282":"markdown","c0488508":"markdown","6c678908":"markdown","55601281":"markdown","29f133bc":"markdown","65f4d46d":"markdown","58b37fa3":"markdown","229ebd8c":"markdown","681e7dfb":"markdown","c062b8b4":"markdown","908db80c":"markdown","739dc98f":"markdown","9eecd12f":"markdown","37a58976":"markdown","6caa91db":"markdown","fb82446f":"markdown","91063591":"markdown","b69cc891":"markdown","1c13008f":"markdown","2b617fcf":"markdown","8538c32e":"markdown","ad570810":"markdown","542c9193":"markdown","3f3ee1de":"markdown","a816b2b1":"markdown","bfa52b7e":"markdown","15739fcd":"markdown","390f40fd":"markdown","ea5abc2d":"markdown","d3f7add9":"markdown","21fae960":"markdown","f575a584":"markdown","9651c46b":"markdown","184010ec":"markdown","e16e0479":"markdown","044e593c":"markdown","bbc39ab7":"markdown","ea735789":"markdown","de249c5e":"markdown","5a4f48ee":"markdown","ccde2352":"markdown","977c4145":"markdown","751b02b3":"markdown","d1bb7d3e":"markdown","50f130cd":"markdown","906f73d3":"markdown","0f45b2ff":"markdown","303a5cde":"markdown","9da22ab6":"markdown","3fe86086":"markdown","31a862a9":"markdown","2331a9c3":"markdown","92aaef33":"markdown","47f9155b":"markdown","abd22cbd":"markdown","1ca2f787":"markdown","57d76a2b":"markdown","8bdd8a5f":"markdown","0232ada7":"markdown","aaefa7a5":"markdown","9d8f6662":"markdown","b0b4b4d2":"markdown","6cfa536b":"markdown","fea525a3":"markdown","67d464b6":"markdown","474217ee":"markdown","2f1a93a2":"markdown","47d011b4":"markdown","4f2dc106":"markdown","02f3e40e":"markdown","12e99903":"markdown","ba5c64af":"markdown","7421a8e2":"markdown","bb664706":"markdown","0bce5f0e":"markdown","87c94098":"markdown","eacca7db":"markdown"},"source":{"ae597ce7":"import warnings\nwarnings.filterwarnings('ignore')\n\n#import sidetable as stb\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n\nprint('numpy version : ',np.__version__)\nprint('pandas version : ',pd.__version__)\nprint('seaborn version : ',sns.__version__)","0cf78755":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5a226b9d":"df = pd.read_csv('\/kaggle\/input\/hotel-booking\/hotel_booking.csv')\ndf.head(3)","f1c25eea":"df.info()","53d7cc8c":"#Numeric\nnumerical = df.loc[:, (df.dtypes == int) | (df.dtypes == float)].columns.tolist()\nnumerical","44a881f6":"#Categorical\ncategorical = df.loc[:, (df.dtypes != int) & (df.dtypes != float)].columns.tolist()\ncategorical","468ff6e4":"df.sample(5)","b02857a4":"df[numerical].describe()","574ce099":"df[categorical].describe()","4fbd8cf9":"for col in categorical:\n    print(f'''Value count kolom {col}:''')\n    print('-' * 50)\n    print(df[col].value_counts())\n    print()","b22ec991":"df_clean = df.copy()","0cd57018":"data_missing_value = df_clean.isnull().sum().reset_index()\ndata_missing_value.columns = ['feature','missing_value']\ndata_missing_value['percentage'] = round((data_missing_value['missing_value']\/len(df_clean))*100,3)\ndata_missing_value = data_missing_value.sort_values('percentage', ascending=False).reset_index(drop=True)\ndata_missing_value = data_missing_value[data_missing_value['percentage']>0]\ndata_missing_value","16abda22":"#Remove rows that have no children data\ndf_clean.dropna(subset=['children'], inplace=True)","0576be2d":"#Change value company to 0 and 1\ndf_clean['company'] = df_clean['company'].apply(lambda x: 0 if pd.isnull(x) else 1)\ndf_clean['company'].value_counts()","659a6d2e":"#Change value agent to 0 and 1\ndf_clean['agent'] = df_clean['agent'].apply(lambda x: 0 if pd.isnull(x) else 1)\ndf_clean['agent'].value_counts()","9245da38":"#Fill NaN value in country with the value of mode\ndf_clean['country'].fillna(df_clean['country'].mode()[0], inplace = True)\ndf_clean['country'].value_counts()","f14617b0":"df_clean.isna().sum()","0a11c229":"df_clean['adr'].describe()","5fea632c":"df_clean[df_clean.adr < 0]","613c0ba5":"df_clean.drop(df_clean[df_clean['adr'] < 0].index, inplace = True)","cbb8e6fa":"df_clean['adr'].describe()","27ddf3e5":"df_clean['adults'].describe()","439c36c2":"df_clean.drop(df_clean[df_clean['adults'] < 1].index, inplace = True)","e2953690":"df_clean['adults'].describe()","a75494ee":"# Changing children to integer type: \ndf_clean['children'] = df_clean['children'].astype(int)\n\n# Changing reservation status date to datetime type: \ndf_clean['reservation_status_date'] = pd.to_datetime(df['reservation_status_date'])\n\n# Changing agent to integer type: \ndf_clean['agent'] = df_clean['agent'].astype(int)\n\n# Changing company to integer type: \ndf_clean['company'] = df_clean['company'].astype(int)","263b29d0":"df_clean.info()","c5103778":"df_clean['total_stays'] = df_clean['stays_in_weekend_nights'] + df_clean['stays_in_week_nights']\ndf_clean.head()","08576aa0":"df_clean['total_guests'] = df_clean['adults'] + df_clean['children'] + df_clean['babies']\ndf_clean.head()","2584c942":"df_clean['kids'] = df_clean['children'] + df_clean['babies']\ndf_clean.head()","f6e300bb":"df_clean['guest_location'] = df_clean['country'].apply(lambda x: 'Local' if x == 'PRT' else 'International')\ndf_clean['guest_location'].value_counts()","efb46c67":"df_clean.duplicated().sum()","3a944196":"df_clean.duplicated(subset=['name', 'email', 'phone-number', 'credit_card']).sum()","5dc1231d":"df_clean[['name', 'email', 'phone-number', 'credit_card']].head()","4bf300aa":"#Delete 'name', 'email', 'phone-number', 'credit_card' attributes\ndf_clean.drop(['name', 'email', 'phone-number', 'credit_card'], axis = 1, inplace=True)","e486e5f5":"#Delete 'stays_in_weekend_nights', 'stays_in_week_nights', 'children', 'babies' attributes\ndf_clean.drop(['stays_in_weekend_nights', 'stays_in_week_nights', 'children', 'babies'], axis = 1, inplace=True)","64cc27d0":"df_clean.info()","f98c4823":"#Numeric\nnumerical = df_clean.loc[:, (df_clean.dtypes == int) | (df_clean.dtypes == float)].columns.tolist()\nnumerical","ed236999":"#Categorical\ncategorical = df_clean.loc[:, (df_clean.dtypes != int) & (df_clean.dtypes != float)].columns.tolist()\ncategorical","655dad97":"df_clean.describe()","149c5342":"df_clean.describe(include='O')","0552e38e":"plt.figure(figsize=(10, 20))\nfor i in range(0, len(numerical)):\n    plt.subplot(4, int(len(numerical)\/3), i+1)\n    sns.boxplot(y=df_clean[numerical[i]], color='gray', orient='v')\n    plt.tight_layout()","2e1d3370":"plt.figure(figsize=(15, 25))\nfor i in range(0, len(numerical)):\n    plt.subplot(10, int(len(numerical)\/9), i+1)\n    sns.distplot(df_clean[numerical[i]], color='gray')\n    plt.tight_layout()","483dc1e4":"plt.figure(figsize=(25, 25))\nfor i in range(0, len(categorical)):\n    plt.subplot(7, len(categorical)\/6, i+1)\n    sns.countplot(df_clean[categorical[i]])\n    plt.tight_layout()","40a17e26":"!pip install dython","c32c698d":"from dython.nominal import associations\n\nassociations(df_clean, figsize = (40, 20))\nplt.show()","65568831":"plt.figure(figsize=(15, 15))\nsns.pairplot(df_clean[numerical], diag_kind='kde')\nplt.show()","d73b94c4":"fig = plt.figure(figsize=(25, 25))\nfor i in range(0, len(categorical)): \n    ax = fig.add_subplot(7, int(len(categorical)\/6), i+1) \n    sns.stripplot(ax=ax, data=df_clean, x=categorical[i], y='is_canceled') \n    plt.tight_layout()","de07e8ca":"df_clean.drop(df_clean[df_clean['adr'] > 5000].index, inplace = True)","64a8218a":"df_clean['previous_cancellations'] = df_clean['previous_cancellations'].apply(lambda x: 0 if x == 0 else 1)\ndf_clean['previous_cancellations'].value_counts()","cc0fec9f":"df_clean['booking_changes'] = df_clean['booking_changes'].apply(lambda x: 0 if x == 0 else 1)\ndf_clean['booking_changes'].value_counts()","f9185ffa":"from sklearn.preprocessing import MinMaxScaler\n\ndf_clean['lead_time_norm'] = MinMaxScaler().fit_transform(df_clean['lead_time'].values.reshape(len(df_clean), 1))\ndf_clean['adr_norm'] = MinMaxScaler().fit_transform(df_clean['adr'].values.reshape(len(df_clean), 1))\ndf_clean['required_car_parking_spaces_norm'] = MinMaxScaler().fit_transform(df_clean['required_car_parking_spaces'].values.reshape(len(df_clean), 1))\ndf_clean['total_of_special_requests_norm'] = MinMaxScaler().fit_transform(df_clean['total_of_special_requests'].values.reshape(len(df_clean), 1))\ndf_clean['total_stays_norm'] = MinMaxScaler().fit_transform(df_clean['total_stays'].values.reshape(len(df_clean), 1))\ndf_clean['total_guests_norm'] = MinMaxScaler().fit_transform(df_clean['total_guests'].values.reshape(len(df_clean), 1))","08b22f61":"encode_cat = ['hotel',\n 'meal',\n 'market_segment',\n 'distribution_channel',\n 'deposit_type',\n 'customer_type',\n 'guest_location']","f158e903":"for cat in encode_cat:\n    onehots = pd.get_dummies(df_clean[cat], prefix=cat)\n    df_clean = df_clean.join(onehots)","8464afba":"df_clean.columns = df_clean.columns.str.replace(' ', '')","aca4af16":"df_clean.columns = df_clean.columns.str.replace('\/', '')","9bd0eca5":"df_clean","9b4574b7":"df_clean['is_canceled'].value_counts()","3cccfc57":"plt.figure(figsize=(5, 6))\ncancel_ax = sns.countplot(df_clean['is_canceled'])\n\nfor p in cancel_ax.patches:\n    cancel_ax.annotate(format(p.get_height(), '.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points')\n\nplt.show()","bcc052a7":"df_insight = df_clean.copy()","86175a83":"labels = ['Confirmed Booking',  'Cancelled Booking']\nmyexplode = [0.2, 0]\ncancel_fig, cancel_ax = plt.subplots(figsize=[10,6])\ncancel_ax.pie(df_insight['is_canceled'].value_counts(), autopct='%1.1f%%',\n        shadow=True, startangle=90, explode = myexplode, textprops={'color':\"black\", 'fontsize':20}, labels=labels)\ncancel_ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\nplt.show()","af912abc":"adr_median = df_insight['adr'].median()\nsns.distplot(df_insight['adr'])\nplt.title('Distribution of ADR\\n(July 2015 - August 2017)', fontsize=20, pad=30)\nplt.axvline(adr_median, color='red', linestyle='dashed', linewidth=3, label='Median: ' + str(round(adr_median, 2))) \nplt.xlabel('ADR', fontsize=12)\nplt.legend(fontsize=15)\nplt.show()","f27f76de":"df_insight['arrival_date'] = df_insight['arrival_date_year'].astype(str) + \"-\" + df_insight['arrival_date_month'].map({'January':1, 'February':2, 'March':3, 'April':4, 'May':5, 'June':6, 'July':7, 'August':8, 'September':9, 'October':10, 'November':11, 'December':12}).astype(str) + \"-\" + df_insight['arrival_date_day_of_month'].astype(str)","e5f867d9":"df_insight['arrival_date'] = pd.to_datetime(df_insight['arrival_date'], format=\"%Y-%m-%d\")\ndf_insight['reservation_status_date'] = pd.to_datetime(df_insight['reservation_status_date'], format=\"%Y-%m-%d\")","322ac907":"df_insight['cancel_or_stay_length'] = abs((df_insight['arrival_date'] - df_insight['reservation_status_date']).dt.days)","fb9a8f61":"l_median = df_insight['cancel_or_stay_length'][(df_insight.is_canceled == 1)].median()\nplt.figure(figsize=(8, 8))\nsns.boxplot(df_insight['cancel_or_stay_length'][(df_insight.is_canceled == 1)])\nplt.axvline(l_median, color='red', linestyle='dashed', linewidth=3, label='Median: ' + str(round(l_median, 2)))   \nplt.xlabel('Cancellation Interval', fontsize=12)\nplt.title('Number of Days Between\\nCancellation Date and Expected Arrival Date', fontsize=20, pad=30)\nplt.legend(fontsize=20)\nplt.show()","c5a0ee8a":"plt.figure(figsize=(8, 8))\nlead_time_ax = sns.boxplot(x='is_canceled', y='lead_time', data=df_insight, palette='Paired')\nlead_time_ax.set_xticklabels(['No', 'Yes'])\nplt.ylabel('Lead Time', fontsize=12)\nplt.xlabel('Is Canceled', fontsize=12)\nplt.title('Distribution of Lead Time', fontsize=20, pad=30)\nmedians = df_insight.groupby(['is_canceled'])['lead_time'].median()\nvertical_offset = df_insight['lead_time'].median() * 0.05\nfor xtick in lead_time_ax.get_xticks():\n    lead_time_ax.text(xtick,medians[xtick] + vertical_offset,medians[xtick], \n            horizontalalignment='center',fontsize=25,color='w',weight='semibold')\n\nplt.show()","9f4447a9":"df_lead_time = df_insight.copy()\ndf_lead_time['lead_time_month'] = df_lead_time['lead_time'] \/\/ 30\ndf_lead_time = df_lead_time.groupby(['lead_time_month','is_canceled']).agg({'hotel':'count'}).reset_index()\ndf_lead_time = df_lead_time.rename(columns={'hotel':'total'})\ndf_lead_time['total_guests'] = df_lead_time.groupby(['lead_time_month'])['total'].transform('sum')","e9eadc75":"df_lead_time_plot = df_lead_time.copy()\ndf_lead_time_plot['cancel_percentage'] = (df_lead_time_plot['total'] \/ df_lead_time_plot['total_guests']) * 100\ndf_lead_time_plot = df_lead_time_plot.sort_values('cancel_percentage', ascending=False)\n\ndf_lead_time_plot = df_lead_time_plot.pivot_table(index='lead_time_month', columns='is_canceled', values='cancel_percentage')\n\nlead_time_ax = df_lead_time_plot.plot(kind='barh', stacked=True, figsize=(12,8))\nplt.legend(bbox_to_anchor=(1.01, 1), title='Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\nplt.title('Cancellation Percentage by Lead Time Month', fontsize=20, pad=30)\nplt.xlabel('Percentage (%)', fontsize=12)\nplt.ylabel('Lead Time (Month)', fontsize=12)\nplt.axvline(50, color='red', linestyle='dashed', linewidth=3, label='50%')\nplt.annotate(s='',xy=(100,8), xytext=(110,8), arrowprops=dict(arrowstyle='<-', color='black'))\nplt.text(110, 7, 'Cancellation Ratio > 50%\\nFor Lead Times\\nStarting From 8 Months', horizontalalignment='left', size='medium', color='black')\nlead_time_ax.set_xticks([50])\nplt.show()","d936d141":"df_lead_time_pop = df_lead_time.copy()\ndf_lead_time_pop = df_lead_time_pop.drop_duplicates('lead_time_month', keep='first')\nplt.figure(figsize=(12, 10))\nlead_time_pop_ax = sns.barplot(df_lead_time_pop['lead_time_month'], df_lead_time_pop['total_guests'])\nfor p in lead_time_pop_ax.patches:\n    lead_time_pop_ax.annotate(format(p.get_height(), '.0f'), \n                   (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                   ha = 'center', va = 'center', \n                   xytext = (0, 9), \n                   textcoords = 'offset points', fontsize=10)\nplt.xlabel('Lead Time Month', fontsize=12)\nplt.ylabel('Total Booking', fontsize=12)\nplt.title('Total Booking by Lead Time Month', fontsize=20, pad=30)\nplt.show()","faa8d00a":"deposit_ax = pd.crosstab(df_insight['deposit_type'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n\nj = 1    \nfor p in deposit_ax.patches:\n    if j != 2:\n      width, height = p.get_width(), p.get_height()\n      x, y = p.get_xy() \n      deposit_ax.text(x+width\/2, \n              y+height\/2, \n              '{:.2f} %'.format(height*100), \n              horizontalalignment='center', \n              verticalalignment='center',\n              color='white', fontsize=15)\n    j += 1\n    \nplt.title('Cancellation Rate by Deposit Type', fontsize=20, pad=30)  \nplt.xticks(rotation=360)  \nplt.xlabel('Deposit Type', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","0290970e":"plt.figure(figsize=(8, 8))\ndeposit_ax2 = sns.boxplot(x='deposit_type', y='lead_time', data=df_insight, palette='Paired')\nplt.ylabel('Lead Time', fontsize=12)\nplt.xlabel('Deposit Type', fontsize=12, labelpad=15)\nplt.title('Distribution of Lead Time by Deposit Type', fontsize=20, pad=30)\nplt.show()","3df71c7c":"previous_ax = pd.crosstab(df_insight['previous_cancellations'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n    \nfor p in previous_ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    previous_ax.text(x+width\/2, \n            y+height\/2, \n            '{:.2f} %'.format(height*100), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Previous Cancellation', fontsize=20, pad=30)   \nprevious_ax.set_xticklabels(['No','Yes'], rotation=360) \nplt.xlabel('Previous Cancellation', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","368a2a6c":"hotel_ax = pd.crosstab(df_insight['hotel'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n    \nfor p in hotel_ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    hotel_ax.text(x+width\/2, \n            y+height\/2, \n            '{:.2f} %'.format(height*100), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Hotel Type', fontsize=20, pad=30)    \nplt.xticks(rotation=360)\nplt.xlabel('Hotel Type', fontsize=12)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","93ae822e":"plt.figure(figsize=(8, 8))\nsns.boxplot(x='hotel', y='lead_time', data=df_insight, palette='Paired')\nplt.ylabel('Lead Time', fontsize=12)\nplt.xlabel('Hotel Type', fontsize=12)\nplt.title('Distribution of Lead Time by Hotel Type', fontsize=20, pad=30)\nplt.show()","381d44b9":"hotel_ax2 = sns.countplot(df_insight['hotel'])\nfor p in hotel_ax2.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    hotel_ax2.text(x+width\/2, \n            y+height\/2, \n            '{:.0f}'.format(height), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white',\n            fontsize=15)\n\nplt.title('Total Booking by Hotel Type', fontsize=20, pad=30)    \nplt.xlabel('Hotel Type', fontsize=12)\nplt.ylabel('Total Booking', fontsize=12)\nplt.show()","828d4ae8":"guest_ax = pd.crosstab(df_insight['guest_location'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n    \nfor p in guest_ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    guest_ax.text(x+width\/2, \n            y+height\/2, \n            '{:.2f} %'.format(height*100), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Guest Origin', fontsize=20, pad=30)   \nplt.xticks(rotation=360) \nplt.xlabel('Guest Origin', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","233a623f":"plt.figure(figsize=(8, 8))\nsns.boxplot(x='guest_location', y='lead_time', data=df_insight, palette='Paired')\nplt.ylabel('Lead Time', fontsize=12)\nplt.xlabel('Guest Origin', fontsize=12)\nplt.title('Distribution of Lead Time by Guest Origin', fontsize=20, pad=30)\nplt.show()","2c35d44d":"guest_ax2 = pd.crosstab(df_insight['guest_location'], df_insight['deposit_type'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Deposit Type', fontsize=12, title_fontsize=12)\n\nj = 1\nfor p in guest_ax2.patches:\n    if j == 1 or j == 2 or j == 4:\n      width, height = p.get_width(), p.get_height()\n      x, y = p.get_xy() \n      guest_ax2.text(x+width\/2, \n              y+height\/2, \n              '{:.2f} %'.format(height*100), \n              horizontalalignment='center', \n              verticalalignment='center',\n              color='white',\n              fontsize=15)\n    j += 1\n\nplt.title('Deposit Type by Guest Origin', fontsize=20, pad=30)   \nplt.xticks(rotation=360) \nplt.xlabel('Guest Origin', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","116823af":"guest_ax3 = pd.crosstab(df_insight['guest_location'], df_insight['previous_cancellations'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Previous Cancellations', fontsize=12, title_fontsize=12, labels=['No', 'Yes'])\n\nj = 1\nfor p in guest_ax3.patches:\n    if j == 1 or j == 2 or j == 4:\n      width, height = p.get_width(), p.get_height()\n      x, y = p.get_xy() \n      guest_ax3.text(x+width\/2, \n              y+height\/2, \n              '{:.2f} %'.format(height*100), \n              horizontalalignment='center', \n              verticalalignment='center',\n              color='white',\n              fontsize=15)\n    j += 1\n\nplt.title('Previous Cancellations by Guest Origin', fontsize=20, pad=30)  \nplt.xticks(rotation=360)  \nplt.xlabel('Guest Origin', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","7472f76f":"repeat_ax = pd.crosstab(df_insight['is_repeated_guest'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n    \nfor p in repeat_ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    repeat_ax.text(x+width\/2, \n            y+height\/2, \n            '{:.2f} %'.format(height*100), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Repeated Guest', fontsize=20, pad=30)    \nrepeat_ax.set_xticklabels(['No', 'Yes'], rotation=360)\nplt.xlabel('Is Repeated Guest', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","317c3107":"market_ax = pd.crosstab(df_insight['market_segment'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(15,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n    \nfor p in market_ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    market_ax.text(x+width\/2, \n            y+height\/2, \n            '{:.2f} %'.format(height*100), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white', fontsize=10)\n    \nplt.title('Cancellation Rate by Market Segment', fontsize=20, pad=30)    \nplt.xticks(rotation=360)\nplt.xlabel('Market Segment', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","47060c03":"plt.figure(figsize=(15, 8))\nsns.boxplot(x='market_segment', y='lead_time', data=df_insight, palette='Paired')\nplt.ylabel('Lead Time', fontsize=12)\nplt.xlabel('Market Segment', fontsize=12)\nplt.title('Distribution of Lead Time by Market Segment', fontsize=20, pad=30)\nplt.show()","104ae2e5":"customer_ax = pd.crosstab(df_insight['customer_type'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(15,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n    \nfor p in customer_ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    customer_ax.text(x+width\/2, \n            y+height\/2, \n            '{:.2f} %'.format(height*100), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Customer Type', fontsize=20, pad=30)    \nplt.xticks(rotation=360)\nplt.xlabel('Customer Type', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","845d3325":"booking_ax = pd.crosstab(df_insight['booking_changes'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n    \nfor p in booking_ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    booking_ax.text(x+width\/2, \n            y+height\/2, \n            '{:.2f} %'.format(height*100), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Booking Changes', fontsize=20, pad=30)   \nbooking_ax.set_xticklabels(['No', 'Yes'], rotation=360)\nplt.xlabel('Booking Changes', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","7bb94ca9":"request_ax = pd.crosstab(df_insight['total_of_special_requests'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(15,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n    \nfor p in request_ax.patches:\n    width, height = p.get_width(), p.get_height()\n    x, y = p.get_xy() \n    request_ax.text(x+width\/2, \n            y+height\/2, \n            '{:.2f} %'.format(height*100), \n            horizontalalignment='center', \n            verticalalignment='center',\n            color='white', fontsize=15)\n    \nplt.title('Cancellation Rate\\n by Total of Special Request', fontsize=20, pad=30)    \nplt.xticks(rotation=360)\nplt.xlabel('Total of Special Requests', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","0d3e1dd1":"parking_ax = pd.crosstab(df_insight['required_car_parking_spaces'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(15,8))\nplt.legend(loc='center left', bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n\nj = 1    \nfor p in parking_ax.patches:\n    if j < 7:\n      width, height = p.get_width(), p.get_height()\n      x, y = p.get_xy() \n      parking_ax.text(x+width\/2, \n              y+height\/2, \n              '{:.2f} %'.format(height*100), \n              horizontalalignment='center', \n              verticalalignment='center',\n              color='white', fontsize=15)\n    j += 1\n    \nplt.title('Cancellation Rate\\n by Required Car Parking Spaces', fontsize=20, pad=30)    \nplt.xticks(rotation=360)\nplt.xlabel('Required Car Parking Spaces', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","ef7226ea":"meal_ax = pd.crosstab(df_insight['meal'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(15,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n   \nfor p in meal_ax.patches:\n      width, height = p.get_width(), p.get_height()\n      x, y = p.get_xy() \n      meal_ax.text(x+width\/2, \n              y+height\/2, \n              '{:.2f} %'.format(height*100), \n              horizontalalignment='center', \n              verticalalignment='center',\n              color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Meal Type', fontsize=20, pad=30) \nplt.xticks(rotation=360)   \nplt.xlabel('Meal Type', fontsize=12, labelpad=30)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","0e31cdf8":"plt.figure(figsize=(10, 8))\nmeal_ax2 = sns.countplot(df_insight['meal'])\n\nfor p in meal_ax2.patches:\n      width, height = p.get_width(), p.get_height()\n      x, y = p.get_xy() \n      meal_ax2.text(x+width\/2, \n              y+height, \n              '{:.0f}'.format(height*100), \n              horizontalalignment='center', \n              color = 'black', \n              fontsize=15)\n      \nplt.title('Total Booking by Meal Type', fontsize=20, pad=30)    \nplt.xlabel('Meal Type', fontsize=12)\nplt.ylabel('Total Booking', fontsize=12)\nplt.show()","cb9a6432":"meal_ax3 = pd.crosstab(df_insight['meal'], df_insight['deposit_type'], normalize = 'index').plot.bar(stacked=True, figsize=(15,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Deposit Type', fontsize=12, title_fontsize=12)\n\nj = 1\nfor p in meal_ax3.patches:\n      if j < 9 or j == 10: \n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        meal_ax3.text(x+width\/2, \n                y+height\/2, \n                '{:.2f} %'.format(height*100), \n                horizontalalignment='center', \n                verticalalignment='center',\n                color='white',\n                fontsize=15)\n      j += 1\n\nplt.title('Deposit Type by Meal Type', fontsize=20, pad=30)    \nplt.xticks(rotation=360)\nplt.xlabel('Meal Type', fontsize=12, labelpad=30)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","29ec0d90":"distribution_ax = pd.crosstab(df_insight['distribution_channel'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(15,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n\nj = 1   \nfor p in distribution_ax.patches:\n      if j != 10:\n        width, height = p.get_width(), p.get_height()\n        x, y = p.get_xy() \n        distribution_ax.text(x+width\/2, \n                y+height\/2, \n                '{:.2f} %'.format(height*100), \n                horizontalalignment='center', \n                verticalalignment='center',\n                color='white', fontsize=15)\n      j += 1\n    \nplt.title('Cancellation Rate by Distribution Channel', fontsize=20, pad=30)    \nplt.xticks(rotation=360)\nplt.xlabel('Distribution Channel', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","d8e055b9":"agent_ax = pd.crosstab(df_insight['agent'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n   \nfor p in agent_ax.patches:\n      width, height = p.get_width(), p.get_height()\n      x, y = p.get_xy() \n      agent_ax.text(x+width\/2, \n              y+height\/2, \n              '{:.2f} %'.format(height*100), \n              horizontalalignment='center', \n              verticalalignment='center',\n              color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Agent', fontsize=20, pad=30)    \nagent_ax.set_xticklabels(['No', 'Yes'], rotation=360)\nplt.xlabel('Agent', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","48d9e0ab":"company_ax = pd.crosstab(df_insight['company'], df_insight['is_canceled'], normalize = 'index').plot.bar(stacked=True, figsize=(8,8))\nplt.legend(bbox_to_anchor=(1.01, 0.5), title='Is Canceled', fontsize=12, title_fontsize=12, labels=['No','Yes'])\n   \nfor p in company_ax.patches:\n      width, height = p.get_width(), p.get_height()\n      x, y = p.get_xy() \n      company_ax.text(x+width\/2, \n              y+height\/2, \n              '{:.2f} %'.format(height*100), \n              horizontalalignment='center', \n              verticalalignment='center',\n              color='white', fontsize=15)\n    \nplt.title('Cancellation Rate by Company', fontsize=20, pad=30) \ncompany_ax.set_xticklabels(['No', 'Yes'], rotation=360)   \nplt.xlabel('Company', fontsize=12, labelpad=15)\nplt.ylabel('Percentage (%)', fontsize=12)\nplt.show()","59f612b9":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import confusion_matrix, classification_report\n\ndef eval_classification(model, pred, xtrain, ytrain, xtest, ytest):\n    print(\"Accuracy (Test Set): %.2f\" % accuracy_score(ytest, pred))\n    print(\"Precision (Test Set): %.2f\" % precision_score(ytest, pred))\n    print(\"Recall (Test Set): %.2f\" % recall_score(ytest, pred))\n    print(\"F1-Score (Test Set): %.2f\" % f1_score(ytest, pred))\n    \n    fpr, tpr, thresholds = roc_curve(ytest, pred, pos_label=1) # pos_label: label yang kita anggap positive\n    print(\"AUC: %.2f\" % auc(fpr, tpr))\n\ndef show_best_hyperparameter(model, hyperparameters):\n    for key, value in hyperparameters.items() :\n        print('Best '+key+':', model.get_params()[key])\n\ndef show_cmatrix(ytest, pred):\n    # Creating confusion matrix \n    cm = confusion_matrix(ytest, pred)\n\n    # Putting the matrix a dataframe form  \n    cm_df = pd.DataFrame(cm, index=['Actually Not Canceled', 'Actually Canceled'],\n                 columns=['Predicted Not Canceled', 'Predicted Canceled'])\n    \n    # visualizing the confusion matrix\n    sns.set(font_scale=1.2)\n    plt.figure(figsize=(10,4))\n        \n    sns.heatmap(cm, annot=True, fmt='g', cmap=\"Blues\",xticklabels=cm_df.columns, yticklabels=cm_df.index, annot_kws={\"size\": 20})\n    plt.title(\"Confusion Matrix\", size=20)\n    plt.xlabel('Predicted Class')\n    plt.ylabel('True Class');\n\ndef show_feature_importance(model):\n  feat_importances = pd.Series(model.feature_importances_, index=X.columns)\n  ax = feat_importances.nlargest(20).plot(kind='barh', figsize=(10, 8))\n  ax.invert_yaxis()\n\n  plt.xlabel('score')\n  plt.ylabel('feature')\n  plt.title('feature importance score')","11f8109c":"# Split Feature and Label\nX = df_clean[['is_repeated_guest', 'previous_cancellations', 'booking_changes', 'lead_time_norm', 'adr_norm',\n       'required_car_parking_spaces_norm', 'total_of_special_requests_norm',\n       'total_stays_norm', 'total_guests_norm', 'agent', 'company',\n       'hotel_CityHotel', 'hotel_ResortHotel', 'meal_BB', 'meal_FB', 'meal_HB', 'meal_SC',\n       'meal_Undefined', 'market_segment_Aviation',\n       'market_segment_Complementary', 'market_segment_Corporate',\n       'market_segment_Direct', 'market_segment_Groups',\n       'market_segment_OfflineTATO', 'market_segment_OnlineTA',\n       'distribution_channel_Corporate', 'distribution_channel_Direct',\n       'distribution_channel_GDS', 'distribution_channel_TATO',\n       'distribution_channel_Undefined',\n       'deposit_type_NoDeposit', 'deposit_type_NonRefund',\n       'deposit_type_Refundable', 'customer_type_Contract',\n       'customer_type_Group', 'customer_type_Transient',\n       'customer_type_Transient-Party', 'guest_location_International',\n       'guest_location_Local']]\n\ny = df_clean['is_canceled'] # target \/ label\n\n#Splitting the data into Train and Test\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","e9049d7f":"!pip install ipython-autotime\n\n%load_ext autotime","5c593353":"import time","62739cc6":"from sklearn.linear_model import LogisticRegression\n\nlr_model = LogisticRegression(solver='liblinear')\n\ntic = time.time()\nlr_model.fit(X_train, y_train)\ntoc = time.time()\n\ny_pred_lr = lr_model.predict(X_test)\n\nlr_time = toc - tic","808dfbea":"eval_classification(lr_model, y_pred_lr, X_train, y_train, X_test, y_test)","8a524f11":"print('Train score: ' + str(lr_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(lr_model.score(X_test, y_test))) #accuracy","9a251e62":"recall_lr = recall_score(y_test, y_pred_lr)\nacc_lr = accuracy_score(y_test, y_pred_lr)\nprecision_lr = precision_score(y_test, y_pred_lr)\nf1_lr = f1_score(y_test, y_pred_lr)\nacc_lr_train = lr_model.score(X_train, y_train)","a1e2877a":"show_cmatrix(y_test, y_pred_lr)","6b3f8f58":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_model = KNeighborsClassifier()\n\ntic = time.time()\nknn_model.fit(X_train, y_train)\ntoc = time.time()\n\ny_pred_knn = knn_model.predict(X_test)\n\nknn_time = toc - tic","c8bc0f3f":"eval_classification(knn_model, y_pred_knn, X_train, y_train, X_test, y_test)","2f34b418":"print('Train score: ' + str(knn_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(knn_model.score(X_test, y_test))) #accuracy","e402b50e":"recall_knn = recall_score(y_test, y_pred_knn)\nacc_knn = accuracy_score(y_test, y_pred_knn)\nprecision_knn = precision_score(y_test, y_pred_knn)\nf1_knn = f1_score(y_test, y_pred_knn)\nacc_knn_train = knn_model.score(X_train, y_train)","ad560cbe":"show_cmatrix(y_test, y_pred_knn)","17438011":"from sklearn.tree import DecisionTreeClassifier\n\ndt_model = DecisionTreeClassifier()\n\ntic = time.time()\ndt_model.fit(X_train,y_train)\ntoc = time.time()\n\ny_pred_dt = dt_model.predict(X_test)\n\ndt_time = toc - tic","800040c7":"eval_classification(dt_model, y_pred_dt, X_train, y_train, X_test, y_test)","600f25dc":"print('Train score: ' + str(dt_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(dt_model.score(X_test, y_test))) #accuracy","bcd1ca97":"recall_dt = recall_score(y_test, y_pred_dt)\nacc_dt = accuracy_score(y_test, y_pred_dt)\nprecision_dt = precision_score(y_test, y_pred_dt)\nf1_dt = f1_score(y_test, y_pred_dt)\nacc_dt_train = dt_model.score(X_train, y_train)","393f1917":"show_cmatrix(y_test, y_pred_dt)","e64c2c8b":"from sklearn.ensemble import RandomForestClassifier\n\nrf_model = RandomForestClassifier()\n\ntic = time.time()\nrf_model.fit(X_train,y_train)\ntoc = time.time()\n\ny_pred_rf = rf_model.predict(X_test)\n\nrf_time = toc - tic","c5a9a3d6":"eval_classification(rf_model, y_pred_rf, X_train, y_train, X_test, y_test)","358166a4":"print('Train score: ' + str(rf_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(rf_model.score(X_test, y_test))) #accuracy","a4dc5917":"recall_rf = recall_score(y_test, y_pred_rf)\nacc_rf = accuracy_score(y_test, y_pred_rf)\nprecision_rf = precision_score(y_test, y_pred_rf)\nf1_rf = f1_score(y_test, y_pred_rf)\nacc_rf_train = rf_model.score(X_train, y_train)","15c0be12":"show_cmatrix(y_test, y_pred_rf)","52b404af":"from xgboost import XGBClassifier\nxg_model = XGBClassifier(verbosity = 0)\n\ntic = time.time()\nxg_model.fit(X_train, y_train)\ntoc = time.time()\n\ny_pred_xg = xg_model.predict(X_test)\n\nxg_time = toc - tic","30b22724":"eval_classification(xg_model, y_pred_xg, X_train, y_train, X_test, y_test)","512c800d":"print('Train score: ' + str(xg_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(xg_model.score(X_test, y_test))) #accuracy","4963ef03":"recall_xg = recall_score(y_test, y_pred_xg)\nacc_xg = accuracy_score(y_test, y_pred_xg)\nprecision_xg = precision_score(y_test, y_pred_xg)\nf1_xg = f1_score(y_test, y_pred_xg)\nacc_xg_train = xg_model.score(X_train, y_train)","ee143cfe":"show_cmatrix(y_test, y_pred_xg)","8d0f5323":"\nevaluation_summary = {\n    'Logistic Regression': [acc_lr, recall_lr, precision_lr, f1_lr],\n    'KNN':[acc_knn, recall_knn, precision_knn, f1_knn],\n    'Decision Tree':[acc_dt, recall_dt, precision_dt, f1_dt],\n    'Random Forest':[acc_rf, recall_rf, precision_rf, f1_rf],\n    'XGBoost':[acc_xg, recall_xg, precision_xg, f1_xg]\n}\n\neva_sum = pd.DataFrame(data = evaluation_summary, index = ['Accuracy', 'Recall', 'Precision', 'F1 Score'])\neva_sum\n","434bd449":"evaluation_sum_train_test = {\n    \"Train\" : [acc_lr_train, acc_knn_train, acc_dt_train, acc_rf_train, acc_xg_train],\n    \"Test\": [acc_lr, acc_knn, acc_dt, acc_rf, acc_xg]\n}\n\neva_sum_train_test = pd.DataFrame(data = evaluation_sum_train_test, index = ['Logistic Regression', 'KNN', 'Decision Tree', 'Random Forest', 'XGBoost'])\neva_sum_train_test","9a6ad432":"evaluation_time = {\n    \"Time\" : [round(lr_time, 2), round(knn_time, 2), round(dt_time, 2), round(rf_time, 2), round(xg_time, 2)]\n}\n\neva_time = pd.DataFrame(data = evaluation_time, index = ['Logistic Regression', 'KNN', 'Decision Tree', 'Random Forest', 'XGBoost'])\nprint(\"Total data: \", len(X_test))\neva_time","14c3bd05":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\n\npenalty = ['l2','l1','elasticnet']\nC = [0.0001, 0.001, 0.002] # Inverse of regularization strength; smaller values specify stronger regularization.\nhyperparameters = dict(penalty=penalty, C=C)\n\nlr_tuned = LogisticRegression()\nlr_tuned_model = RandomizedSearchCV(lr_tuned, hyperparameters, cv=5, scoring='accuracy')\nlr_tuned_model.fit(X_train, y_train)\n\ny_pred_lr_tuned = lr_tuned_model.predict(X_test)","eaf9d081":"show_best_hyperparameter(lr_tuned_model.best_estimator_, hyperparameters)","191a53a1":"eval_classification(lr_tuned_model, y_pred_lr_tuned, X_train, y_train, X_test, y_test)","94aafdd3":"print('Train score: ' + str(lr_tuned_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(lr_tuned_model.score(X_test, y_test))) #accuracy","2f49986a":"recall_lr_tuned = recall_score(y_test, y_pred_lr_tuned)\nacc_lr_tuned = accuracy_score(y_test, y_pred_lr_tuned)\nprecision_lr_tuned = precision_score(y_test, y_pred_lr_tuned)\nf1_lr_tuned = f1_score(y_test, y_pred_lr_tuned)\nacc_lr_tuned_train = lr_tuned_model.score(X_train, y_train)","f084dd4b":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom scipy.stats import uniform\n\nn_neighbors = list(range(1,30))\np=[1,2]\nalgorithm = ['auto', 'ball_tree', 'kd_tree', 'brute']\nweights = ['uniform','distance']\nhyperparameters = dict(n_neighbors=n_neighbors, p=p, algorithm=algorithm, weights=weights)\n\nknn_tuned = KNeighborsClassifier()\nknn_tuned_model = RandomizedSearchCV(knn_tuned, hyperparameters, cv=5, scoring='accuracy')\nknn_tuned_model.fit(X_train, y_train)\n\ny_pred_knn_tuned = knn_tuned_model.predict(X_test)","e1bbfbd6":"show_best_hyperparameter(knn_tuned_model.best_estimator_, hyperparameters)","b3ce5863":"eval_classification(knn_tuned_model, y_pred_knn_tuned, X_train, y_train, X_test, y_test)","3cab4a3a":"print('Train score: ' + str(knn_tuned_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(knn_tuned_model.score(X_test, y_test))) #accuracy","0a584067":"recall_knn_tuned = recall_score(y_test, y_pred_knn_tuned)\nacc_knn_tuned = accuracy_score(y_test, y_pred_knn_tuned)\nprecision_knn_tuned = precision_score(y_test, y_pred_knn_tuned)\nf1_knn_tuned = f1_score(y_test, y_pred_knn_tuned)\nacc_knn_tuned_train = knn_tuned_model.score(X_train, y_train)","30c72c28":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom scipy.stats import uniform\nimport numpy as np\n\nmax_depth = [int(x) for x in np.linspace(1, 110, num = 30)] # Maximum number of levels in tree\nmin_samples_split = [2, 5, 10, 100] # Minimum number of samples required to split a node\nmin_samples_leaf = [1, 2, 4, 10, 20, 50] # Minimum number of samples required at each leaf node\nmax_features = ['auto', 'sqrt'] # Number of features to consider at every split\n\nhyperparameters = dict(max_depth=max_depth, \n                       min_samples_split=min_samples_split, \n                       min_samples_leaf=min_samples_leaf,\n                       max_features=max_features\n                      )\n\ndt_tuned = DecisionTreeClassifier()\ndt_tuned_model = RandomizedSearchCV(dt_tuned, hyperparameters, cv=5, scoring='accuracy')\ndt_tuned_model.fit(X_train, y_train)\n\ny_pred_dt_tuned = dt_tuned_model.predict(X_test)","80c52339":"show_best_hyperparameter(dt_tuned_model.best_estimator_, hyperparameters)","0f275c27":"eval_classification(dt_tuned_model, y_pred_dt_tuned, X_train, y_train, X_test, y_test)","a73d30e5":"print('Train score: ' + str(dt_tuned_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(dt_tuned_model.score(X_test, y_test))) #accuracy","9ae98b13":"recall_dt_tuned = recall_score(y_test, y_pred_dt_tuned)\nacc_dt_tuned = accuracy_score(y_test, y_pred_dt_tuned)\nprecision_dt_tuned = precision_score(y_test, y_pred_dt_tuned)\nf1_dt_tuned = f1_score(y_test, y_pred_dt_tuned)\nacc_dt_tuned_train = dt_tuned_model.score(X_train, y_train)","1b622c19":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nimport numpy as np\n\nhyperparameters = dict(\n                       n_estimators = [int(x) for x in np.linspace(start = 100, stop = 2000, num = 20)], #\n                       bootstrap = [True], \n                       criterion = ['gini','entropy'],\n                       max_depth = [int(x) for x in np.linspace(10, 110, num = 11)], \n                       min_samples_split = [int(x) for x in np.linspace(start = 2, stop = 10, num = 5)],\n                       min_samples_leaf = [int(x) for x in np.linspace(start = 1, stop = 10, num = 5)], \n                       max_features = ['auto', 'sqrt', 'log2'], \n                       n_jobs = [-1],\n                      )\n\nrf_tuned = RandomForestClassifier()\nrf_tuned_model = RandomizedSearchCV(rf_tuned, hyperparameters, cv=5, scoring='accuracy')\nrf_tuned_model.fit(X_train,y_train)\n\ny_pred_rf_tuned = rf_tuned_model.predict(X_test)","53e3f3d3":"show_best_hyperparameter(rf_tuned_model.best_estimator_, hyperparameters)","d961b6f5":"eval_classification(rf_tuned_model, y_pred_rf_tuned, X_train, y_train, X_test, y_test)","2698c987":"print('Train score: ' + str(rf_tuned_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(rf_tuned_model.score(X_test, y_test))) #accuracy","d079005d":"recall_rf_tuned = recall_score(y_test, y_pred_rf_tuned)\nacc_rf_tuned = accuracy_score(y_test, y_pred_rf_tuned)\nprecision_rf_tuned = precision_score(y_test, y_pred_rf_tuned)\nf1_rf_tuned = f1_score(y_test, y_pred_rf_tuned)\nacc_rf_tuned_train = rf_tuned_model.score(X_train, y_train)","fab9ca48":"from xgboost import XGBClassifier\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom hyperopt import STATUS_OK, Trials, fmin, hp, tpe\nimport numpy as np\n\nhyperparameters = {\n                    'max_depth' : [int(x) for x in np.linspace(10, 110, num = 11)],\n                    'min_child_weight' : [int(x) for x in np.linspace(1, 20, num = 11)],\n                    'gamma' : [float(x) for x in np.linspace(0, 1, num = 11)],\n                    'tree_method' : ['auto', 'exact', 'approx', 'hist'],\n\n                    'colsample_bytree' : [float(x) for x in np.linspace(0, 1, num = 11)],\n                    'eta' : [float(x) for x in np.linspace(0, 1, num = 100)],\n\n                    'lambda' : [float(x) for x in np.linspace(0, 1, num = 11)],\n                    'alpha' : [float(x) for x in np.linspace(0, 1, num = 11)]\n                    }\n\nxg_tuned = XGBClassifier()\nxg_tuned_model = RandomizedSearchCV(xg_tuned, hyperparameters, cv=5, scoring='accuracy')\nxg_tuned_model.fit(X_train,y_train)\n\ny_pred_xg_tuned = xg_tuned_model.predict(X_test)","bed16f1a":"show_best_hyperparameter(xg_tuned_model.best_estimator_, hyperparameters)","651297d0":"eval_classification(xg_tuned_model, y_pred_xg_tuned, X_train, y_train, X_test, y_test)","8be00fd9":"print('Train score: ' + str(xg_tuned_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(xg_tuned_model.score(X_test, y_test))) #accuracy","88eafc69":"recall_xg_tuned = recall_score(y_test, y_pred_xg_tuned)\nacc_xg_tuned = accuracy_score(y_test, y_pred_xg_tuned)\nprecision_xg_tuned = precision_score(y_test, y_pred_xg_tuned)\nf1_xg_tuned = f1_score(y_test, y_pred_xg_tuned)\nacc_xg_tuned_train = xg_tuned_model.score(X_train, y_train)","2bb6f4f8":"evaluation_summary_tuned = {\n    'Logistic Regression Tuned': [acc_lr_tuned, recall_lr_tuned, precision_lr_tuned, f1_lr_tuned],\n    'KNN Tuned':[acc_knn_tuned, recall_knn_tuned, precision_knn_tuned, f1_knn_tuned],\n    'Decision Tree Tuned':[acc_dt_tuned, recall_dt_tuned, precision_dt_tuned, f1_dt_tuned],\n    'Random Forest Tuned':[acc_rf_tuned, recall_rf_tuned, precision_rf_tuned, f1_rf_tuned],\n    'XGBoost Tuned':[acc_xg_tuned, recall_xg_tuned, precision_xg_tuned, f1_xg_tuned]\n}\n\neva_sum_tuned = pd.DataFrame(data = evaluation_summary_tuned, index = ['Accuracy', 'Recall', 'Precision', 'F1 Score'])\neva_sum_tuned\n","9a2ec4b2":"evaluation_sum_tuned_train_test = {\n    \"Train\" : [acc_lr_tuned_train, acc_knn_tuned_train, acc_dt_tuned_train, acc_rf_tuned_train, acc_xg_tuned_train],\n    \"Test\": [acc_lr_tuned, acc_knn_tuned, acc_dt_tuned, acc_rf_tuned, acc_xg_tuned]\n}\n\neva_sum_tuned_train_test = pd.DataFrame(data = evaluation_sum_tuned_train_test, index = ['Logistic Regression Tuned', 'KNN Tuned', 'Decision Tree Tuned', 'Random Forest Tuned', 'XGBoost Tuned'])\neva_sum_tuned_train_test","a16f5e5b":"show_feature_importance(xg_model)","3001af44":"# Top 7 Feature Importance (XGBoost)\n# Split Feature and Label\nX = df_clean[['deposit_type_NonRefund', 'market_segment_OnlineTA', 'required_car_parking_spaces_norm',\n              'guest_location_International', 'previous_cancellations', 'total_of_special_requests_norm', 'customer_type_Transient']]\n\ny = df_clean['is_canceled'] # target \/ label\n\n#Splitting the data into Train and Test\nfrom sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","4d35aab1":"from sklearn.linear_model import LogisticRegression\n\nlr_fi_model = LogisticRegression(solver='liblinear')\nlr_fi_model.fit(X_train, y_train)\n\ny_pred_lr_fi = lr_fi_model.predict(X_test)","b5a11c5e":"eval_classification(lr_fi_model, y_pred_lr_fi, X_train, y_train, X_test, y_test)","907f910c":"print('Train score: ' + str(lr_fi_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(lr_fi_model.score(X_test, y_test))) #accuracy","40780c79":"recall_lr_fi = recall_score(y_test, y_pred_lr_fi)\nacc_lr_fi = accuracy_score(y_test, y_pred_lr_fi)\nprecision_lr_fi = precision_score(y_test, y_pred_lr_fi)\nf1_lr_fi = f1_score(y_test, y_pred_lr_fi)\nacc_lr_fi_train = lr_fi_model.score(X_train, y_train)","5622c2eb":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_fi_model = KNeighborsClassifier()\nknn_fi_model.fit(X_train, y_train)\n\ny_pred_knn_fi = knn_fi_model.predict(X_test)","62630cc0":"eval_classification(knn_fi_model, y_pred_knn_fi, X_train, y_train, X_test, y_test)","02c86708":"print('Train score: ' + str(knn_fi_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(knn_fi_model.score(X_test, y_test))) #accuracy","ee6ccf23":"recall_knn_fi = recall_score(y_test, y_pred_knn_fi)\nacc_knn_fi = accuracy_score(y_test, y_pred_knn_fi)\nprecision_knn_fi = precision_score(y_test, y_pred_knn_fi)\nf1_knn_fi = f1_score(y_test, y_pred_knn_fi)\nacc_knn_fi_train = knn_fi_model.score(X_train, y_train)","6c0d9408":"from sklearn.tree import DecisionTreeClassifier\n\ndt_fi_model = DecisionTreeClassifier()\ndt_fi_model.fit(X_train,y_train)\n\ny_pred_dt_fi = dt_fi_model.predict(X_test)","681e71e2":"eval_classification(dt_fi_model, y_pred_dt_fi, X_train, y_train, X_test, y_test)","291a9617":"print('Train score: ' + str(dt_fi_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(dt_fi_model.score(X_test, y_test))) #accuracy","4288bf6a":"recall_dt_fi = recall_score(y_test, y_pred_dt_fi)\nacc_dt_fi = accuracy_score(y_test, y_pred_dt_fi)\nprecision_dt_fi = precision_score(y_test, y_pred_dt_fi)\nf1_dt_fi = f1_score(y_test, y_pred_dt_fi)\nacc_dt_fi_train = dt_fi_model.score(X_train, y_train)","0f3c7b49":"from sklearn.ensemble import RandomForestClassifier\n\nrf_fi_model = RandomForestClassifier()\nrf_fi_model.fit(X_train,y_train)\n\ny_pred_rf_fi = rf_fi_model.predict(X_test)","1c58f500":"eval_classification(rf_fi_model, y_pred_rf_fi, X_train, y_train, X_test, y_test)","6f9d9b4c":"print('Train score: ' + str(rf_fi_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(rf_fi_model.score(X_test, y_test))) #accuracy","35997f82":"recall_rf_fi = recall_score(y_test, y_pred_rf_fi)\nacc_rf_fi = accuracy_score(y_test, y_pred_rf_fi)\nprecision_rf_fi = precision_score(y_test, y_pred_rf_fi)\nf1_rf_fi = f1_score(y_test, y_pred_rf_fi)\nacc_rf_fi_train = rf_fi_model.score(X_train, y_train)","3487a80f":"from xgboost import XGBClassifier\nxg_fi_model = XGBClassifier(verbosity = 0)\nxg_fi_model.fit(X_train, y_train)\n\ny_pred_xg_fi = xg_fi_model.predict(X_test)","191d6710":"eval_classification(xg_fi_model, y_pred_xg_fi, X_train, y_train, X_test, y_test)","cf68eaf5":"print('Train score: ' + str(xg_fi_model.score(X_train, y_train))) #accuracy\nprint('Test score:' + str(xg_fi_model.score(X_test, y_test))) #accuracy","4497c6eb":"recall_xg_fi = recall_score(y_test, y_pred_xg_fi)\nacc_xg_fi = accuracy_score(y_test, y_pred_xg_fi)\nprecision_xg_fi = precision_score(y_test, y_pred_xg_fi)\nf1_xg_fi = f1_score(y_test, y_pred_xg_fi)\nacc_xg_fi_train = xg_fi_model.score(X_train, y_train)","1a69d0d1":"evaluation_summary_fi = {\n    'Logistic Regression FI': [acc_lr_fi, recall_lr_fi, precision_lr_fi, f1_lr_fi],\n    'KNN FI':[acc_knn_fi, recall_knn_fi, precision_knn_fi, f1_knn_fi],\n    'Decision Tree FI':[acc_dt_fi, recall_dt_fi, precision_dt_fi, f1_dt_fi],\n    'Random Forest FI':[acc_rf_fi, recall_rf_fi, precision_rf_fi, f1_rf_fi],\n    'XGBoost FI':[acc_xg_fi, recall_xg_fi, precision_xg_fi, f1_xg_fi]\n}\n\neva_sum_fi = pd.DataFrame(data = evaluation_summary_fi, index = ['Accuracy', 'Recall', 'Precision', 'F1 Score'])\neva_sum_fi","4e9f8f1e":"evaluation_sum_fi_train_test = {\n    \"Train\" : [acc_lr_fi_train, acc_knn_fi_train, acc_dt_fi_train, acc_rf_fi_train, acc_xg_fi_train],\n    \"Test\": [acc_lr_fi, acc_knn_fi, acc_dt_fi, acc_rf_fi, acc_xg_fi]\n}\n\neva_sum_fi_train_test = pd.DataFrame(data = evaluation_sum_fi_train_test, index = ['Logistic Regression FI', 'KNN FI', 'Decision Tree FI', 'Random Forest FI', 'XGBoost FI'])\neva_sum_fi_train_test","bf777b24":"show_cmatrix(y_test, y_pred_xg)","0463b95e":"## Customer Type and Cancellation","3f5c3d5a":"## K-Nearest Neighbor (Feature Importance)","bd2d4131":"### Sampling to Understand Data With df.sample()","63c1a751":"* Column `children` because only 4 rows of data are missing, it will be dropped\n* Column `agent` and `company` because they are the ID of the agent and company, the value will be set to `0` for data that does not have an ID and `1` for data that has an ID\n* Column `country` because the majority of the values are `PRT` and the missing value ratio is small, then the missing value will be filled with the mode value `PRT`","a961a5a1":"### K-Nearest Neighbor Evaluation","f9a617db":"## Special Request and Cancellation","f825f288":"# Modelling\n","fc6f1c30":"Some observations:\n\n* Our target, `is_cancelled`, is of type int64 and appears to have a value in the range 0-1, where 1 indicates a canceled hotel booking\n* Columns `name`, `email`, `phone-number`, `credit_card` appear to have no pattern, probably not very useful for classification","0c04f7ea":"## Evaluation Summary (Feature Importance)","dc97dd0d":"## Redefine Numeric and Categorical Feature","f2667297":"# Data Pre-Processing Part II","5f4e98f8":"# Tuned Modelling ","ab45af8c":"### Decision Tree Tuned Evaluation","6197a105":"## Logistic Regression Tuned","2ed4a19e":"**Key takeways:**\n\n* Customers who make changes to booking details have a smaller cancellation rate than those who don't","c9f7f550":"By using 7 features from feature importance information, the best performance results and not experiencing overfit\/underfit conditions is the XGBoost model. However, overall it is still below the performance of the XGBoost model (default parameter) with the features in the previous stage\n\nSo the XGBoost model (default parameter) with the features in the previous stage is still used, with the following performance:\n\nMetrics|XGBoost\n-------|----------|\nAccuracy|0.857067\nRecall|0.759864\nPrecision|0.839289\nF1 Score|0.797604","9fa5106c":"# Project\n\n**Hotel Booking Cancellation Prediction**<br><br>\n**Description**<br>\n* Predict whether hotel bookings are included in the category to be canceled or not, based on the available features<br>\n\n","e34a9173":"**Key takeways:**\n\n* The longer the lead time, the greater the possibility that the customer will cancel the hotel booking\n\n* It makes sense that if the number of days between when the booking is made and the estimated date of arrival increases, customers have more time to cancel reservations and more time for unforeseen circumstances that could derail travel plans","5362fbd9":"## Random Forest (Feature Importance)","f9ba2a15":"## Decision Tree","9a2af265":"## Number of Days Between Cancelation Date and Expected Arrival Date","b900256b":"**Key takeways:**\n\n* Customers who do not have a request for car parking are 40% likely to cancel their hotel booking\n","307f9bd5":"## Guest Location and Cancellation","c0627b21":"### Statistical summary dengan `df.describe()`","9fdacd8f":"Feature name  | Type | Description\n-------------------|------------------|-------------\nADR|Float|Average Daily Rate. Calculated by dividing the sum of all lodging transactions by the total number of staying nights.\nAdults|Integer|Number of adults.\nAgent|Float|ID of the travel agency that made the booking.\nArrivalDateDayOfMonth|Integer|Day of the month of the arrival date.\nArrivalDateMonth|Object|Month of arrival date with 12 categories: \u201cJanuary\u201d to \u201cDecember\u201d.\nArrivalDateWeekNumber|Integer|Week number of the arrival date.\nArrivalDateYear|Integer|Year of arrival date.\nAssignedRoomType|Object|Code for the type of room assigned to the booking. Sometimes the assigned room type differs from the reserved room type due to hotel operation reasons (e.g. overbooking) or by customer request. Code is presented instead of designation for anonymity reasons.\nBabies|Integer|Number of babies.\nBookingChanges|Integer|Number of changes\/amendments made to the booking from the moment the booking was entered on the Property Management System until the moment of check-in or cancellation. Calculated by adding the number of unique iterations that change some of the booking attributes, namely: persons, arrival date, nights, reserved room type or meal.\nChildren|Float|Number of children. Sum of both payable and non-payable children.\nCompany|Float|ID of the company\/entity that made the booking or responsible for paying the booking. ID is presented instead of designation for anonymity reasons.\nCountry|Object|Country of origin. Categories are represented in the International Standards Organization (ISO) 3155\u20133:2013 format.\nCreditCard|Object|Customer credit card number. Artificially created.\nCustomerType|Object|Type of booking, assuming one of four categories: Contract (when the booking has an allotment or other type of contract associated to it), Group (when the booking is associated to a group), Transient (when the booking is not part of a group or contract, and is not associated to other transient booking), and Transient-party (when the booking is transient, but is associated to at least other transient booking).\nDaysInWaitingList|Integer|Number of days the booking was in the waiting list before it was confirmed to the customer. Calculated by subtracting the date the booking was confirmed to the customer from the date the booking entered on the Property Management System.\nDepositType|Object|Indication on if the customer made a deposit to guarantee the booking. This variable can assume three categories: No Deposit (no deposit was made), Non Refund (a deposit was made in the value of the total stay cost), and Refundable (a deposit was made with a value under the total cost of stay). Value calculated based on the payments identified for the booking in the transaction (TR) table before the booking\u05f3s arrival or cancellation date. In case no payments were found the value is \u201cNo Deposit\u201d. If the payment was equal or exceeded the total cost of stay, the value is set as \u201cNon Refund\u201d. Otherwise the value is set as \u201cRefundable\u201d.\nDistributionChannel|Object|Booking distribution channel. The term \u201cTA\u201d means \u201cTravel Agents\u201d and \u201cTO\u201d means \u201cTour Operators\u201d.\nEmail|Object|Customer email. Artificially created.\nHotel|Object|Type of hotel. Categories are presented in City Hotel and Resort Hotel\nIsCanceled|Integer|Value indicating if the booking was canceled (1) or not (0).\nIsRepeatedGuest|Integer|Value indicating if the booking name was from a repeated guest (1) or not (0). Variable created by verifying if a profile was associated with the booking customer. If so, and if the customer profile creation date was prior to the creation date for the booking on the Property Management System database it was assumed the booking was from a repeated guest.\nLeadTime|Integer|Number of days that elapsed between the entering date of the booking into the Property Management System and the arrival date. Calculated by subtracting the entering date from the arrival date.\nMarketSegment|Object|Market segment designation. In categories, the term \u201cTA\u201d means \u201cTravel Agents\u201d and \u201cTO\u201d means \u201cTour Operators\u201d.\nMeal|Object|Type of meal booked. Categories are presented in standard hospitality meal packages: Undefined\/SC (no meal package), BB (Bed & Breakfast), HB (Half board: breakfast and one other meal \u2013 usually dinner), and FB (Full board: breakfast, lunch and dinner).\nName|Object|Customer name. Artificially created.\nPhoneNumber|Object|Customer phone number. Artificially created.\nPreviousBookingsNotCanceled|Integer|Number of previous bookings not canceled by the customer prior to the current booking. In case there was no customer profile associated with the booking, the value is set to 0. Otherwise, the value is the number of bookings with the same customer profile created before the current booking and not canceled.\nPreviousCancellations|Integer|Number of previous bookings that were canceled by the customer prior to the current booking. In case there was no customer profile associated with the booking, the value is set to 0. Otherwise, the value is the number of bookings with the same customer profile created before the current booking and canceled.\nRequiredCarParkingSpaces|Integer|Number of car parking spaces required by the customer.\nReservationStatus|Object|Reservation last status, assuming one of three categories: Canceled (booking was canceled by the customer), Check-Out (customer has checked in but already departed), No-Show (customer did not check-in and did inform the hotel of the reason why).\nReservationStatusDate|Object|Date at which the last status was set. This variable can be used in conjunction with the\u00a0ReservationStatus\u00a0to understand when was the booking canceled or when did the customer checked-out of the hotel.\nReservedRoomType|Object|Code of room type reserved. Code is presented instead of designation for anonymity reasons.\nStaysInWeekendNights|Integer|Number of weekend nights (Saturday or Sunday) the guest stayed or booked to stay at the hotel. Calculated by counting the number of weekend nights from the total number of nights.\nStaysInWeekNights|Integer|Number of week nights (Monday to Friday) the guest stayed or booked to stay at the hotel. Calculated by counting the number of week nights from the total number of nights.\nTotalOfSpecialRequests|Integer|Number of special requests made by the customer (e.g. twin bed or high floor).\n","4297a5c1":"From the pair plot above, we can also see something similar:\n* Column `total_guests` has a linear correlation with `adults`, because it is a column obtained from the calculation results of the two columns. One of the columns will be used for the modelling","cf90ae8e":"In terms of the category plot between the categorical columns and the target column, no significant correlation was found","1f52c008":"Because the number of `country` values is very large in this dataset, we will condense the values to *Local* or *International*\n\nTo determine the value based on the following criteria, because this hotel dataset is located in Portugal, customers from Portugal will be set to *Local* and in addition to *International*","7fbaad68":"### Total Stays","ae2d23d3":"## Initialize df_insight","f1e885d2":"### Box Plot","ada093ea":"From the *association heatmap* above, it can be seen that:\n\n* Our target `is_cancelled` has a weak positive correlation with `deposit_type`, `lead_time` as well as `guest_location` or `country`\n* Then the target `is_cancelled` very clearly has a strong positive correlation with `reservation_status`, because indeed the reservation status indicates the status of the hotel booking is canceled or not\n* Column `total_guests` has a strong positive correlation with `adults` and `kids` because it is a column obtained from the calculation results of the two columns. Will use column `total_guest`\n* The `market_segment`, `distribution_channel`, `agent` and `company` columns have a strong positive correlation, possibly redundant. One will use\n* The `reserved_room_type` and `assigned_room_type` columns also have a strong positive correlation. Probably won't be used","9e224a80":"**Key takeways:**\n\n* 50% of customers cancel 54 days (1.8 months) before arrival date","ad7bcd4e":"## Evaluation Summary","ffa7ccb4":"## XGBoost","1540ec7d":"## Random Forest","b5cb7885":"## Adjust Data Type","8a723021":"## Data Definition","9d645e14":"### Random Forest Tuned Evaluation","bbfb46b4":"### EDA Conclusion","d9d45b7e":"### Guest Location","12d125aa":"Ensure observations regarding the categorical columns above with value counting","ffbe1492":"Some observations from the statistical summary of the categorical column above:\n* The majority of data are City Hotels (top column for `hotel` is `City Hotel` with a frequency of 79330)\n* Most customers come from Portugal, because this dataset is a hotel dataset located in Portugal\n* Column `country` seems to have a lot of unique values, looks like it needs to be reduced\n* As per previous observation, the `name`, `email`, `phone-number`, `credit_card` columns have a large number of unique values. There is a possibility that it is not very useful for classification\n* No Deposit here may have a reason why cancellation is high (because the customer has nothing to lose in this no deposit case)\n* Seen from the `reserved_room_type` and `assigned_room_type` columns have different unique numbers, the hotel may have rooms that are not for sale to the public\n* For other columns, certain values are dominated by certain values","e35962f1":"## Decision Tree (Feature Importance)","7c6b985a":"### Category Plot","3411075a":"# Exploratory Data Analysis (EDA)","9850a539":"From the boxplot visualization, the most important thing we should pay attention to is the presence of outliers:\n* The majority of numeric columns still have outlier values. But it looks like these outlier values can provide a lot of useful information, so we're not doing outlier data cleaning, but rather feature engineering or creating new columns and hopefully we can extract more information by doing that\n* The outlier to be removed is in the `adr` column because it appears to have one very different value\n* From the boxplot, it can be seen that the majority of columns have a *skewed* distribution, except for the columns `arrival_date_day_of_month`, `arrival_date_week_number`","9906695b":"## Multivariate Analysis","eab05b57":"Some of the things we found from this EDA dataset are:\n* The data looks valid and there are no defects.\n* The majority of numeric columns have a skewed distribution, this must be remembered if we want to do something or use a model that requires the assumption of a normal distribution.\n* For outliers to be removed only outliers in column `adr`. For the majority of other columns that have outliers, they are not removed because they can provide a lot of useful information, but feature engineering will be carried out or create a new column that is expected to extract more information by doing so.\n* Our target `is_cancelled` has a weak positive correlation with `deposit_type`, `lead_time` as well as `guest_location` or `country`\n* There are features that have a strong correlation, one of them will be used","17b00cae":"# Data Pre-Processing Part I","65e613e6":"## K-Nearest Neighbor Tuned","8fb9cd54":"### Pair Plot","4f916f48":"**Key takeways:**\n\n* Local customers have a higher cancellation rate than international customers\n\n* If you look for the relationship with other attributes:\n   - Non-refundable deposit type for local customers is higher than international guests\n   - Rates of previously canceled hotel bookings are higher for local customers than international customers\n   - The median lead time does not look much different\n","733fb370":"It can be seen that the data is in accordance with previous observations","a6eff900":"**Key takeways:**\n\n* 50% ADR on this dataset is worth 95 Euros","3d6ee6f0":"### Logistic Regression Evaluation","3e283aba":"## Distribution Channel & Cancellation","51fed592":"## Distribution of ADR","cb0d7147":"**Key takeways:**\n\n* Hotel bookings with a lead time of more than 7 months have more than 50% chance of cancellation","ed6d8e63":"**Key takeways:**\n\n* The market segment group has the highest cancellation rate, reaching 61%. It can be concluded because it has the longest median lead time\n* The direct market segment has the lowest cancellation rate (other than complementary)","64c115e0":"From the tuning results, it can be seen that there is an increase in accuracy, but the majority have overfit conditions.\n\nSo, the **XGBoost** model in the previous stage is still selected","95d26ea1":"### Total Guests","d94ff31e":"Finally, we display a category plot for each pair of categorical columns with target column as below","4b1f87b3":"## XGBoost (Feature Importance)","11a24a54":"For the categorical column, the highest number of unique values is owned by the `country` column. However, we have condensed the value in the `guest_location` . column","2164ac4c":"### Random Forest (Feature Importance) Evaluation","0101db96":"### Decision Tree (Feature Importance) Evaluation","90cc96da":"## Duplicate Values","0bd117c5":"## Feature Engineering","4068a954":"## Random Forest Tuned","6d7127fd":"## Remove Irrelevant Features","95d89b69":"Overfit","6ec1e271":"Having looked at each column individually, we will now look at the relationships between the columns. Knowing the relationships between columns can help us select the most important features and exclude redundant ones.","bd7fa99e":"## Evaluation Summary (Tuned)\n\n\n","05af63a3":"## Remove Outlier","9d35aa1e":"From the `adults`, `children` and `babies` columns, we can get information on the total number of people staying overnight","9d19aee9":"## Market Segment and Cancellation","195c9382":"**Key takeways:**\n\n* Customer type transient has the highest cancellation rate, reaching 40.78%\n* Customer type group has the lowest cancellation rate","1cf2f8e9":"### K-Nearest Neighbor (Feature Importance) Evaluation","ac136e4e":"### XGBoost Evaluation","f57825ab":"### Adults","b8c9c856":"**Key takeways:**\n\n* The biggest cancellation rate is on the Travel Agent\/ Tour Operator distribution channel\n* Distribution channel direct has the smallest cancellation rate\n* For undefined we do not consider","32338397":"## Decision Tree Tuned","d3d03104":"From most booking sites, usually there are only guest and child categories (under 17 years old), so we can combine the values of `children` and `babies` into the `kids` column","8095be77":"## Lead Time (Month) and Cancellation","a109402a":"### Random Forest Evaluation","832f0282":"# Load and Describe Data","c0488508":"Data that has `adr` < 0 is 1 row and because the value is random, it is deleted from the dataset","6c678908":"Column `name`, `email`, `phone-number`, `credit_card` is a column that does not have a pattern, so we can just delete the column","55601281":"### XGBoost Tuned Evaluation","29f133bc":"### XGBoost (Feature Importance) Evaluation","65f4d46d":"**Key takeways:**\n\n* Hotel booking with FB meal has the highest cancellation rate compared to other meals.\n\n* It can be concluded because hotel bookings with meal FB have a higher non-refund type deposit ratio. From the previous analysis, non-refund has a high cancellation rate","58b37fa3":"### Decision Tree Evaluation","229ebd8c":"## Initialize df_clean","681e7dfb":"### Checking Columns and Missing Values With `df.info()`","c062b8b4":"### Count Plot","908db80c":"## Previous Cancellations and Cancellation","739dc98f":"## Univariate Analysis","9eecd12f":"## Repeated Guest and Cancellation","37a58976":"**Key takeways:**\n\n* The more customers request special requests, the smaller the cancellation rate","6caa91db":"## Booking Changes and Cancellation","fb82446f":"# Insight","91063591":"# Modelling with Feature Importance","b69cc891":"### Kids","1c13008f":"## Hotel Type and Cancellation","2b617fcf":"## Parking Space and Cancellation","8538c32e":"Change value for `booking_changes` to 0 and 1.<br>\n\n* 0 -> no booking changes\n* 1 -> booking changes > 0","ad570810":"## XGBoost Tuned","542c9193":"## Logistic Regression","3f3ee1de":"### ADR","a816b2b1":"### K-Nearest Neighbor Tuned Evaluation","bfa52b7e":"## K-Nearest Neighbor","15739fcd":"Remove outlier in `adr` with value > 5000","390f40fd":"No redundant data","ea5abc2d":"**Key takeways:**\n\n* City hotels have a higher cancellation rate than resort hotels\n\n* When viewed from another point of view:\n   - City hotels have a higher number of bookings than Resort hotels, it can be concluded that the more hotel bookings, the higher the cancellation rate\n   - The median lead time does not look much different","d3f7add9":"## Handle Incorrect Value","21fae960":"Overfit","f575a584":"## Handle Missing Value","9651c46b":"Focusing metrics towards **accuracy** for the following reasons:\n* Class balance\n* All classes are equally important\n\n\nSummary:\n* From the evaluation results of modeling with default parameters, it is found that the best is in the **XGBoost** model, with an accuracy of 85%. This model is neither overfit nor underfit\n\n* For Random Forest has the best performance. However, the model is still in the overfit category","184010ec":"# Initialized Data ","e16e0479":"## Deposit Type and Cancellation","044e593c":"**Key takeways:**\n\n* The proportion between classes looks balanced (63% : 37%)","bbc39ab7":"## Numeric Approach","ea735789":"## Logistic Regression (Feature Importance)","de249c5e":"From the `stays_in_weekend_nights` and `stays_in_week_nights` columns, we can get the total number of days of stay","5a4f48ee":"## Cancellation Rate","ccde2352":"**Key takeways:**\n\n* Hotel bookings with non-refundable deposit types have the largest cancellation rates, reaching 99% compared to other deposit types.\n\n* One of the reasons is because hotel bookings with non-refundable deposit types have the highest median lead time","977c4145":"# Import Libraries","751b02b3":"## Lead Time and Cancellation","d1bb7d3e":"Finally, let's look at the *count plot* for each categorical column:\n* In accordance with previous observations, the majority of the data are *City Hotel*\n* Most customers make hotel bookings for the months *July* and *August* (summer)\n* Most customers are from international customers\n* Most customers choose to book at hotels with the *No Deposit* type\n* Most market segments or distribution channels come from Travel Agents\n* Most selected room types are *A*\n* Column `country` has many unique values\n* From the `reservation_status` column, it can be seen that the proportion of data is balanced between canceled and not hotel bookings\n* Column `reservation_status_date` has many values because it is date data\n* For other columns it looks dominated by certain values","50f130cd":"Change value for `previous_cancellations` to 0 and 1.<br>\n* 0 -> no previous cancellations\n* 1 -> previous cancellations > 0","906f73d3":"Deleting data that has adult data below 1, because generally bookings must be made by at least 1 adult","0f45b2ff":"In proportion, the comparison between classes is still in a balanced proportion. So there is no need to do undersampling or oversampling","303a5cde":"### Distribution Plot","9da22ab6":"After that we do the encoding for the categorical columns that will be used for modeling using One Hot Encoding","3fe86086":"### Value Counting","31a862a9":"## Class imbalance ","2331a9c3":"**Key takeways:**\n\nFrom the visualization above, the following information is obtained:\n* Repeated guests are less likely to cancel compared to non-repeated guests\n* Cancellation rate of non-repeated guest is 2.5 x greater than repeated guest\n","92aaef33":"### Logistic Regression (Feature Importance) Evaluation","47f9155b":"The `stays_in_weekend_nights` and `stays_in_week_nights` columns are removed because there is already a `total_stays` column <br>\nThe `children` and `babies` columns were removed because there was already a `kids` column","abd22cbd":"**Key takeways:**\n\n* Customers who make a booking through a travel agency are 39% likely to cancel. Higher than non-travel agencies","1ca2f787":"## Reformatting Feature","57d76a2b":"### Logistic Regression Tuned Evaluation","8bdd8a5f":"# Conclusion:\n\n* Identifies **XGBoost** (default parameter) as the best performing model\n\n* This model classifies whether the order will be canceled or not with an accuracy of up to **85%**\n\n* As a result, this model allows hotels to estimate their occupancy rates more measurably, manage their business appropriately, and further increase their revenue.\n\nThe risks of this model are as follows:\n* 5.3% chance that the hotel does not suspect guests, there is a risk of overbooking.\n* 8.9% chance of a hotel allocating their resources to a reservation that will go wrong (cancelled booking)\n\nAgain, the hotel also needs to be responsive and proactive in anticipating this possibility\n\n<br>\n\nAccording to the EDA, several factors affect whether a hotel booking is canceled or not:\n1. **Lead Time**\n  - The longer the lead time, the higher the cancellation rate\n2. **Deposit Type**\n  - Cancellation rate for non-refundable deposit types reaches 99%\n3. **Previous Cancellations**\n  - Customers who have canceled previous hotel bookings are 92% likely to cancel again\n4. **Market Segment**\n  - Cancellation rate in the market segment group reaches 61%\n5. **Guest Location Local**\n  - Cancellation rate for local customers reaches 57%\n6. **Required Car Parking Space**\n  - Customers who ask for the need for a car park tend not to cancel the hotel booking\n7. **Special Request**\n  - Customers who ask for a special request are 95% likely to not cancel the hotel booking\n8. **Repeated Guest**\n  - Repeated guest 85% chance of not canceling hotel booking\n9. **Booking Changes**\n  - Customers who make changes to booking details are 84% likely to not cancel the hotel booking\n\n<br>\n\nBased on Feature Importance, top 5 factors that affect hotel bookings being canceled or not:\n1. Deposit Type - Non Refund\n2. Market Segment - Online TA\n3. Required Car Parking Space\n4. Guest Location\/Origin - International\n5. Previous Cancellations\n\n\nThe majority of the features are still coherent with the results of EDA insights\n<br>\n\nBusiness Recommendations:\n1. For hotel bookings with a lead time of more than 7 months, it is necessary to apply a non-refundable deposit type\n2. The hotel can use the reference 54 days before the customer's arrival date as the first step in interacting with customers who are predicted by the model to cancel the booking (for hotel booking lead time > 54 days)\n3. Implement non-refundable deposit types or advance payments for group bookings or customers who have a history of cancellations\n4. Increase hotel booking transactions through direct distribution channels. Can be given special offer","0232ada7":"## Meal Type & Cancellation","aaefa7a5":"## Load Data","9d8f6662":"As previously observed, the majority of columns have a *skewed* distribution (mean <> median)","b0b4b4d2":"## Feature Encoding","6cfa536b":"## Agent and Cancellation","fea525a3":"It can be seen in the information above, which features have the most influence on the model in predicting which hotel bookings will be canceled or not.\n\nThe majority of the features are still coherent with the results of EDA insights","67d464b6":"# Feature Importance","474217ee":"There are 4 columns that have missing values:<br>\n\n* `children`\n* `country`\n* `agent`\n* `company`","2f1a93a2":"**Key takeways:**\n\n* Hotel bookings booked or paid for by the company have a lower cancellation rate than those not","47d011b4":"## Setup Train Test Data","4f2dc106":"## Company and Cancellation","02f3e40e":"## Remove Redundant Column","12e99903":"Some observations from the statistical summary of the numeric column above:\n* For numeric columns, the majority appear to have a skewed distribution (Mean <> Median). There may be outliers\n* For column `adr` which is a value to measure the average rental income earned for rooms occupied per day, there is a minus value. It is not normal for the ADR value to be below zero. This data needs to be removed\n* For `adults` column there is a value of 0, need to look again, because it is not possible to place an order with 0 adults","ba5c64af":"### Correlation\/Associations Heatmap","7421a8e2":"**Key takeways:**\n\n* Customers who have canceled previous hotel bookings are 92% likely to cancel again","bb664706":"From the data type information:\n* For column `children` because it is the number of children data, the appropriate data type should be `int64` not `float64` <br>\n* For `agent` and `company` columns are ID data. Ideally for ID, the data type can be either `int64` or `object`. But in this case, it is more suitable to use the `int64` . data type\n* For column `reservation_status_date` it should have data type `datetime`\n\nFor data type adjustments, it will be carried out in the *Adjust Data Type* stage.\n\nThen we can see that:\n* The dataframe has a total of 119390 rows and 36 columns.\n* Dataframe still has *null* values in `children`, `country`, `agent`, `company` columns\n* The classification target seems to be an `is_cancelled` column with data type `int64`.\n* Columns other than `is_cancelled` are *features*.\n\nFrom the information above, we can separate the categorical and numerical columns as follows:","0bce5f0e":"XGBoost Confusion Matrix:","87c94098":"## Normalization","eacca7db":"For the *distribution plot*, the main thing to note is the shape of the distribution:\n* As we suspected in the *box plot*, most of the columns have a *skewed* distribution\n* Means that there is a possibility that we will need to do something with those columns later"}}