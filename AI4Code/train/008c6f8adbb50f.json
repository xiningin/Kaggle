{"cell_type":{"e376a7f4":"code","99a49612":"code","0674e669":"code","3d5d00f7":"code","03c93c18":"code","7423401c":"code","434289be":"code","48db74ca":"code","9c73f24b":"code","a13c9e8c":"code","c339db8c":"code","cdb31c0c":"code","cd845875":"code","26264730":"code","1c4253bd":"code","9ce155ff":"code","f94d6f68":"code","6eaf61e1":"code","755dc25a":"code","383dec33":"code","1b005e53":"code","665337e6":"code","4d3e8763":"code","f79eec0a":"code","19ec3e53":"code","b54ec0b7":"code","7c0203e3":"code","5e7106ea":"markdown","1c70c091":"markdown","029b2299":"markdown","8e9f9461":"markdown","9ec14b8a":"markdown","b217f300":"markdown","9433a742":"markdown","034e0467":"markdown","31a5dba5":"markdown"},"source":{"e376a7f4":"# define the required path\nTRAIN_PATH = '..\/input\/chest-xray-pneumonia\/chest_xray\/train'\nVAL_PATH = '..\/input\/chest-xray-pneumonia\/chest_xray\/val'\nTEST_PATH = '..\/input\/chest-xray-pneumonia\/chest_xray\/test'","99a49612":"# load the required modules\nimport torch\nfrom torch.utils.data import Dataset\nfrom torchvision.datasets import ImageFolder\nimport torchvision.transforms as tt\nimport torch.nn as nn\n\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport os\nimport random\nfrom PIL import Image, ImageOps\nfrom sklearn.preprocessing import LabelEncoder","0674e669":"# visualize the image\nimage_path = TRAIN_PATH + '\/NORMAL\/IM-0115-0001.jpeg'\nimage = plt.imread(image_path)\nprint(f\"Image Shape: {image.shape}\")\nplt.imshow(image, cmap='gray');","3d5d00f7":"# create the augmentation\naugmentation = tt.Compose([\n    tt.Resize((250, 350)),\n    tt.Grayscale(num_output_channels=1),\n    tt.RandomCrop((250, 350)),\n    tt.ToTensor(),\n])","03c93c18":"train_folder = ImageFolder(TRAIN_PATH, transform=augmentation)\nvalid_folder = ImageFolder(VAL_PATH, transform=augmentation)\ntest_folder = ImageFolder(TEST_PATH, transform=augmentation)","7423401c":"# create the dataloader\ntrain_dl = torch.utils.data.DataLoader(train_folder, batch_size=16, shuffle=True, pin_memory=True, num_workers=8)\nval_dl = torch.utils.data.DataLoader(valid_folder, batch_size=16, shuffle=True, pin_memory=True, num_workers=8)\ntest_dl = torch.utils.data.DataLoader(test_folder, batch_size=16, pin_memory=True, num_workers=8)","434289be":"classes = ['NORMAL', 'PNEUMONIA']","48db74ca":"plt.figure(figsize=(10, 10))\nfor i in range(25):\n    ax = plt.subplot(5, 5, i+1)\n    index = random.randint(0, 5216)\n    plt.imshow((train_folder[index][0]).permute(1, 2, 0))\n    plt.title(classes[train_folder[index][1]])\n    plt.axis(\"off\")","9c73f24b":"def label_counts(label, title):\n    value_count = pd.DataFrame(label).value_counts()\n    plt.bar(['Pneumonia', 'Normal'], value_count)\n    plt.title(title)\n    plt.xlabel('Classes')\n    plt.ylabel('Frequency')\n    plt.show();","a13c9e8c":"train_target = [x[1] for x in train_folder]\nvalid_target = [x[1] for x in valid_folder]\ntest_target = [x[1] for x in test_folder]","c339db8c":"label_counts(train_target, 'Train Label Count')","cdb31c0c":"label_counts(valid_target, 'Validation Label Count')","cd845875":"label_counts(test_target, 'Test Label Count')","26264730":"class ClassificationModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.model = nn.Sequential(\n            nn.Conv2d(1, 32, padding=1, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(2), # 125x175\n            nn.ReLU(),\n            nn.Conv2d(32, 32, padding=1, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(2), # 62x87\n            \n            nn.Conv2d(32, 64, padding=1, kernel_size=3),\n            nn.ReLU(),\n            nn.Conv2d(64, 128, padding=1, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(2), # 31x43\n            nn.ReLU(),\n            nn.Conv2d(128, 128, padding=1, kernel_size=3),\n            nn.ReLU(),\n            nn.MaxPool2d(2), # 15x21\n            \n            nn.Flatten(),\n            nn.Linear(128*15*21, 1024),\n            nn.Dropout(0.4),\n            nn.ReLU(),\n            nn.Linear(1024, 512),\n            nn.ReLU(),\n            nn.Linear(512, 128),\n            nn.ReLU(),\n            nn.Linear(128, 2)\n        )\n    \n    def forward(self, image):\n        return self.model(image)","1c4253bd":"model = ClassificationModel()\nmodel","9ce155ff":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\ndevice","f94d6f68":"def to_device(data, device):\n    if isinstance(data, (list, tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader:\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        for x in self.dl:\n            yield to_device(x, self.device)","6eaf61e1":"model = model.to(device)\ntrain_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\ntest_dl = DeviceDataLoader(test_dl ,device)","755dc25a":"def accuracy(pred, true_label):\n    _, output = torch.max(pred, dim=1)\n    return torch.tensor(torch.sum(output == true_label).item()\/len(pred))\n\ndef validation_step(val_dl, model, loss_fn):\n    for image, label in val_dl:\n        pred = model(image)\n        loss = loss_fn(pred, label)\n        acc = accuracy(pred, label)\n        return {\"val_loss\": loss, \"val_acc\": acc}\n\ndef fit(model, train_dl, val_dl, loss_fn, optimizer, epochs):\n    history = []\n    for epoch in range(epochs):\n        for image, label in train_dl:\n            output = model(image)\n            loss = loss_fn(output, label)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n            \n        val_pred = validation_step(val_dl, model, loss_fn)\n        data = {\"loss\": loss, \"val_loss\": val_pred['val_loss'], \"val_acc\": val_pred['val_acc']}\n        history.append(data)\n        print(f\"Epoch: {epoch+1}\/{epochs} => loss: {loss}, val_loss: {val_pred['val_loss']}, val_acc: {val_pred['val_acc']}\")\n    return history","383dec33":"EPOCHS=10\nOPTIMIZER = torch.optim.Adam(model.parameters(), lr=0.001)\nLOSS_FN = nn.CrossEntropyLoss()","1b005e53":"history = fit(model=model, train_dl=train_dl, val_dl=val_dl, loss_fn=LOSS_FN, optimizer=OPTIMIZER, epochs=EPOCHS)","665337e6":"train_loss = [x['loss'].item() for x in history]\nval_loss = [x['val_loss'].item() for x in history]\nval_acc = [x['val_acc'].item() for x in history]","4d3e8763":"plt.plot(np.arange(10), train_loss)\nplt.plot(np.arange(10), val_loss)\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Train and Valid Loss\")\nplt.legend(['Train', 'Valid']);","f79eec0a":"plt.plot(np.arange(10), val_acc)\nplt.title(\"Valid Accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\");","19ec3e53":"def test_eval(train_dl):\n    for image, label in train_dl:\n        output = model(image)\n        break\n    return output","b54ec0b7":"def plot_test_image():\n    plt.figure(figsize=(10, 10))\n    for i in range(16):\n        for image, label in test_dl:\n            plt.subplot(4, 4, i+1)\n            plt.imshow(image[i].permute(1, 2, 0).to('cpu'))\n            pred = test_eval(test_dl)\n            _, output = torch.max(pred, dim=1)\n            color = 'green' if label[i] == output.to('cpu').numpy()[i] else 'red'\n            plt.title(classes[output.to('cpu').numpy()[i]], color=color)\n            break","7c0203e3":"plot_test_image()","5e7106ea":"# Create a Model","1c70c091":"# Train the Model","029b2299":"# Prepare the Dataset","8e9f9461":"# Evaluation","9ec14b8a":"# Load the Dataset","b217f300":"# Plot the results","9433a742":"# Chest X-Ray (Pneumonia) Prediction \ud83c\udfe5\nIn this notebook, we are going to predict the `pneumonia disease` using the X-Ray that are divided into three different section i.e. train, val and test. There are total 5,863 images in the `JPEG` format with two different categories i.e. `Pneumonia` and `Normal`.\n\nWe are going to create an `Deep Neural Network` which help us to predict the test dataset and divide the images into the above mention categories. We also first perform the analysis on the train dataset and check which category have more number of images, what is the shape of the image and perform the required `data augmentation` technique to make our dataset ready to train our neural network.","034e0467":"# Visualize the data with labels","31a5dba5":"# Visualize the number of different classes"}}