{"cell_type":{"8d2b0423":"code","5cc9d92b":"code","000ed0d6":"code","217a1365":"code","96f3c3aa":"code","f8d6b30a":"code","78b1a3d1":"code","9a9789e5":"code","6c5639ef":"code","58bd6add":"markdown","8cfd2ed7":"markdown","c2b3dece":"markdown"},"source":{"8d2b0423":"from customdatasets import TrainDataset, TestDataset","5cc9d92b":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom types import SimpleNamespace\nimport matplotlib.pyplot as plt\nimport csv\nimport librosa\nimport scipy as sc","000ed0d6":"# Hyperparameters\nargs = SimpleNamespace(batch_size=64, test_batch_size=64, epochs=3,\n                       lr=0.01, momentum=0.5, seed=1, log_interval=200)\ntorch.manual_seed(args.seed)\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device('cuda' if use_cuda else 'cpu')","217a1365":"import numpy as np\n\ntoFloat = transforms.Lambda(lambda x: x \/ np.iinfo(np.int16).max)\n\ntrainDataset = TrainDataset(\"..\/input\/oeawai\/train\/kaggle-train\", transform=toFloat)\nprint(len(trainDataset))\n\ntestDataset = TestDataset(\"..\/input\/oeawai\/kaggle-test\/kaggle-test\", transform=toFloat)\nprint(len(testDataset))\n\ntrain_loader = torch.utils.data.DataLoader(trainDataset,\n    batch_size=args.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(testDataset,\n        batch_size=args.test_batch_size, shuffle=False) #Shuffle should be false!","96f3c3aa":"def logMagStft(numpyArray, sample_rate, n_fft):\n    f, t, sx = sc.signal.stft(numpyArray, fs=sample_rate, nperseg=n_fft, noverlap=n_fft\/\/2) \n    return np.log(np.abs(sx)+np.e**-10)\n\nsample_rate = 16000\nnumber_of_examples_to_plot = 8\nn_fft = 510\nspectrograms = np.zeros((number_of_examples_to_plot, n_fft\/\/2+1, int(2*64000\/n_fft)+2))\nfor samples, instrumentsFamily in train_loader:\n    for index in range(number_of_examples_to_plot):\n        spectrograms[index] = logMagStft(samples[index].numpy(), sample_rate, n_fft)\n    family = trainDataset.transformInstrumentsFamilyToString(instrumentsFamily.numpy().astype(int))\n    break # SVM is only fitted to a fixed size of data\n\nimport matplotlib.pyplot as plt\n    \nfor i in range(number_of_examples_to_plot):\n    print(spectrograms[i].shape)\n    plt.imshow(spectrograms[i])\n    print(family[i])\n    plt.colorbar()\n    plt.show()","f8d6b30a":"\nimport torch\nfrom torch import nn\n\n__author__ = 'Andres'\n\n\nclass LogConv(nn.Module):\n    def __init__(self, log_size, in_channels, out_channels, kernel_size, stride, padding):\n        super().__init__()\n        self._log_size = log_size\n        self._in_channels = in_channels\n        self._out_channels = out_channels\n        self._kernel_size = kernel_size\n        self._stride = stride\n        self._padding = padding\n\n        self._ins, self._fins = self.ins_fins_for(self._log_size)\n        self.logconv = nn.ModuleDict()\n\n        for octave in range(len(self._ins)):\n            self.logconv[\"octave_%d\" % octave] = nn.utils.weight_norm(nn.Conv2d(in_channels=in_channels, out_channels=out_channels,\n                                                   kernel_size=kernel_size, stride=stride, padding=padding))\n\n    def split_sigs(self, x, ins, fins):\n        xs = []\n        for i, j in zip(ins, fins):\n            xs.append(x[:, :, i:j, :])\n        return xs\n\n    def merge_sigs(self, x, ins, fins):\n        device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\n        bs, ch, _, ts = x[0].shape\n        m = torch.zeros([bs, ch, torch.max(torch.tensor(fins)), ts]).to(device)\n        for d, i, j in zip(x, ins, fins):\n            m[:, :, i:j, :] += d\n        return m \/ 2\n\n    def ins_fins_for(self, n=256):\n        n = torch.tensor(n).long()\n        ins = []\n        fins = []\n        ins.append(0)\n        ins.append(0)\n        fins.append(3)\n        fins.append(6)\n\n        for i in range(2, int(torch.log2(n.float())) + 1):\n            iin = torch.tensor(2 ** i - 2 ** (i - 2))\n            l = torch.tensor(2 ** (i + 1) + 2 ** (i - 2))\n            ifin = iin + l\n            ins.append(iin)\n            fins.append(torch.min(ifin, n))\n        return ins, fins\n\n    def forward(self, x):\n        results = []\n        for octave, (ins, fins) in enumerate(zip(self._ins, self._fins)):\n            results.append(self.logconv[\"octave_%d\" % octave](x[:, :, ins:fins, :]))\n\n        return self.merge_sigs(results, self._ins, self._fins)\n# NN architecture (three conv and two fully connected layers)\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.first_conv = LogConv(256, 1, 10, 5, 1, 2)\n        self.second_conv = LogConv(64, 10, 20, 5, 1, 2)\n        self.third_conv = LogConv(16, 20, 50, 5, 1, 2)\n        self.fc1 = nn.Linear(50*4*4, 500)\n        self.fc2 = nn.Linear(500, 10)\n\n    def forward(self, x):\n        n_fft = 510\n    \n        spectrograms = np.zeros((len(x), n_fft\/\/2+1, int(2*64000\/n_fft)+2))\n        for index, audio in enumerate(x.cpu().numpy()):\n            spectrograms[index] = logMagStft(audio, 16000, n_fft)\n        \n        x = torch.from_numpy(spectrograms[:, np.newaxis, :, :]).to(device).float()\n        x = nn.functional.pad(input=x, pad=(2, 2, 0, 0), mode='constant', value=0)\n        # x.size is (batch_size, 1, 256, 252)\n        x = F.relu(self.first_conv(x))\n        x = F.max_pool2d(x, 4)\n        x = F.relu(self.second_conv(x))\n        x = F.max_pool2d(x, 4)\n        x = F.relu(self.third_conv(x))\n        x = F.max_pool2d(x, 4)\n        # x.size is (batch_size, 50, 6, 6)\n        x = x.view(-1, 4*4*50)\n\n        x = F.relu(self.fc1(x))\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)","78b1a3d1":"# This function trains the model for one epoch\ndef train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.item()))","9a9789e5":"# This function evaluates the model on the test data\ndef test(args, model, device, test_loader, epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        familyPredictions = np.zeros(len(test_loader.dataset), dtype=np.int)\n        for index, samples in enumerate(test_loader):\n            samples = samples.to(device)\n            familyPredictions[index*len(samples):(index+1)*len(samples)] = model(samples).max(1)[1].cpu() # get the index of the max log-probability\n    \n    familyPredictionStrings = trainDataset.transformInstrumentsFamilyToString(familyPredictions.astype(int))\n\n    with open('NN-submission-' +str(epoch)+'.csv', 'w', newline='') as writeFile:\n        fieldnames = ['Id', 'Predicted']\n        writer = csv.DictWriter(writeFile, fieldnames=fieldnames, delimiter=',',\n                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n        writer.writeheader()\n        for index in range(len(testDataset)):\n            writer.writerow({'Id': index, 'Predicted': familyPredictionStrings[index]})\n    print('saved predictions')","6c5639ef":"# Main\nmodel = Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=args.lr, \n                      momentum=args.momentum)\n\nfor epoch in range(1, args.epochs + 1):\n    train(args, model, device, train_loader, optimizer, epoch)\n    test(args, model, device, test_loader, epoch)\n","58bd6add":"# Example CNN solution for the challenge\n\nFor this example, I started the CNN example notebook provided on the [summer's school github](https:\/\/github.com\/WolfgangWaltenberger\/oeawai\/blob\/master\/CNN\/CNN_example.ipynb), and adapted it to our challenge. It doesn't perform great, but it should be a good starting point for anyone wanting to tackle the challenge with a CNN.\n\nThis time we will need to use kaggle's GPU. On the right under settings you can turn the GPU on. ","8cfd2ed7":"# Data preprocessing\n\nLet's define a way to transform the time-domain audio signals into time-frequency domain. It is always a good idea to plot the data to make sure the preprocessing is doing what we want it to do. ","c2b3dece":"# Net\n\nIn this class, you can modify the network's structure to try to improve the performance. "}}