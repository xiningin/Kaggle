{"cell_type":{"7dcec375":"code","ad906c29":"code","20cad4fe":"code","dad80386":"code","648224d7":"code","d39b8c4a":"code","c0bf893a":"code","fca4ee29":"code","ff08c68a":"code","f7074084":"code","5f274901":"code","82479206":"code","3c808786":"code","a34d927c":"code","00fee830":"code","cc44c93c":"code","12263301":"code","922c6432":"code","a9bb4a59":"code","4da044dc":"code","6246d071":"markdown","dba689fe":"markdown","dc94f682":"markdown","66861fab":"markdown","f0505b9e":"markdown","5a03d61c":"markdown","a1d655ba":"markdown","662fec1f":"markdown","b7588ded":"markdown","d629022b":"markdown"},"source":{"7dcec375":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os \n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport seaborn as sns\nsns.set(color_codes=True)\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Any results you write to the current directory are saved as output.","ad906c29":"os.path.abspath('..\/input\/wine.data')\nos.getcwd()","20cad4fe":"working_dir='\/kaggle\/input\/wine.data'\ndataset=pd.read_csv(working_dir)\n","dad80386":"#getting X and Y(target) from data\nX=dataset.iloc[:,1:14].values\ny=dataset.iloc[:,0].values","648224d7":"dataset.head()","d39b8c4a":"Col_name=['Customer_Segment','Malic_Acid','Ash','Ash_Alcanity','Magnesium','Total_Phenols','Flavanoids','Nonflavanoid_Phenols','Proanthocyanins','Color_Intensity','Hue','OD280','Proline','Alcohol']","c0bf893a":"dataset.columns=Col_name","fca4ee29":"dataset.head(10)","ff08c68a":"dataset.describe()","f7074084":"plt.figure(figsize=(16,10))\nsns.heatmap(dataset.corr(),annot=True)\nplt.show()","5f274901":"dataset.info()","82479206":"\nfrom sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test=train_test_split(X,y ,test_size=0.2,random_state=0) \n","3c808786":"\n\nfrom sklearn.preprocessing import StandardScaler\nsc=StandardScaler()\nX_train=sc.fit_transform(X_train)\nX_test=sc.transform(X_test)","a34d927c":"from sklearn.decomposition import PCA\npca = PCA(n_components = 2)\nX_train = pca.fit_transform(X_train)\nX_test = pca.transform(X_test)\nexplained_variance = pca.explained_variance_ratio_\nprint(explained_variance)","00fee830":"\nfrom sklearn.ensemble import RandomForestClassifier\nclassifier =RandomForestClassifier (n_estimators=10,criterion='entropy',random_state = 0)\nclassifier.fit(X_train, y_train)\n","cc44c93c":"y_pred = classifier.predict(X_test)\n","12263301":"\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_test, y_pred)","922c6432":"from sklearn.metrics import accuracy_score\naccuracy=accuracy_score(y_test, y_pred)\nprint(accuracy)","a9bb4a59":"from matplotlib.colors import ListedColormap\nX_set, y_set = X_train, y_train\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\nplt.title('Random Forest classifier (Training set)')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.legend()\nplt.show()","4da044dc":"# Visualising the Test set results\nfrom matplotlib.colors import ListedColormap\nX_set, y_set = X_test, y_test\nX1, X2 = np.meshgrid(np.arange(start = X_set[:, 0].min() - 1, stop = X_set[:, 0].max() + 1, step = 0.01),\n                     np.arange(start = X_set[:, 1].min() - 1, stop = X_set[:, 1].max() + 1, step = 0.01))\nplt.contourf(X1, X2, classifier.predict(np.array([X1.ravel(), X2.ravel()]).T).reshape(X1.shape),\n             alpha = 0.75, cmap = ListedColormap(('red', 'green', 'blue')))\nplt.xlim(X1.min(), X1.max())\nplt.ylim(X2.min(), X2.max())\nfor i, j in enumerate(np.unique(y_set)):\n    plt.scatter(X_set[y_set == j, 0], X_set[y_set == j, 1],\n                c = ListedColormap(('red', 'green', 'blue'))(i), label = j)\nplt.title('random forest classifier(Test set)')\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.legend()\nplt.show()\n\n","6246d071":"# Making the Confusion Matrix","dba689fe":" # Predicting the Test set results","dc94f682":"# Calculating Accuracy","66861fab":"# Applying Princinpal Component Analysis","f0505b9e":" # splitting the dataset into the Training set and Test set","5a03d61c":"# Visualizing","a1d655ba":"# Import Wine Dataset","662fec1f":" # As i was facing  file not found error so i get current working directory and absolute path of file","b7588ded":"# Feature Scaling","d629022b":"# Fitting RandomForst Classifier to the Training set"}}