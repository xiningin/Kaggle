{"cell_type":{"5aaed558":"code","f6a3497e":"code","0ca922c2":"code","0e071664":"code","338dc9bb":"code","e663dfd5":"code","dfb53711":"code","f37b2357":"code","6b44d5d0":"code","0b8e5f1c":"code","a629be87":"code","480b0f66":"code","31531a87":"code","fc720fd0":"code","07fc5c0f":"code","f6628b23":"code","3b204c84":"code","8d89fbe7":"code","ea566733":"code","d709b4eb":"code","0749b6b7":"code","f26d27af":"code","15284a41":"code","48ae808b":"code","0d27fe1f":"code","a5cd9ee1":"code","dfe8e96e":"markdown","a15c0b76":"markdown","0a72dcff":"markdown","afb8b007":"markdown","96e83735":"markdown","f779c8ba":"markdown","cf4085aa":"markdown","b6f2ebed":"markdown"},"source":{"5aaed558":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f6a3497e":"# importing the modulus\nfrom keras.preprocessing.image import ImageDataGenerator,img_to_array,load_img\nfrom keras.models import Sequential\nfrom keras.layers import Dropout, Flatten, Dense  , Activation\nfrom keras import applications\nimport re","0ca922c2":"import matplotlib.pyplot as plt\nfig,axes=plt.subplots(nrows=1,ncols=2)\n\nimg1=load_img('..\/input\/dogs-vs-cats-redux-kernels-edition\/train\/dog.1.jpg',target_size=(150,150))\naxes[0].imshow(img1)\naxes[0].set_title(\"Cat\")\nimg2=load_img('..\/input\/dogs-vs-cats-redux-kernels-edition\/train\/cat.1.jpg',target_size=(150,150))\naxes[1].imshow(img2)\naxes[1].set_title(\"Dog\")","0e071664":"# Setting the parameters \nimg_width = 150\nimg_height = 150\nTRAIN_DIR = '..\/input\/dogs-vs-cats-redux-kernels-edition\/train\/'\nTEST_DIR = '..\/input\/dogs-vs-cats-redux-kernels-edition\/test\/'\ntrain_images_dogs_cats = [TRAIN_DIR+i for i in os.listdir(TRAIN_DIR)] # use this for full dataset\ntest_images_dogs_cats = [TEST_DIR+i for i in os.listdir(TEST_DIR)] ","338dc9bb":"# images in directory path\ntrain_images_dogs_cats[:5]","e663dfd5":"def atoi(text):\n    return int(text) if text.isdigit() else text\n\ndef natural_keys(text):\n    return [ atoi(c) for c in re.split('(\\d+)', text) ]","dfb53711":"#Natural sorting on training data\ntrain_images_dogs_cats.sort(key=natural_keys)","f37b2357":"# After sorting directory\ntrain_images_dogs_cats[:5]","6b44d5d0":"# dog images starts from index 12500\ntrain_images_dogs_cats[12500:12505]","0b8e5f1c":"train_images_dogs_cats = train_images_dogs_cats[0:3000] + train_images_dogs_cats[12500:15500] ","a629be87":"# natural sorting the test images\ntest_images_dogs_cats.sort(key=natural_keys)","480b0f66":"def prepare_data(list_of_images):\n    \"\"\"\n    Returns a array of images\n    \n    \"\"\"\n    x = [] # images as arrays\n    for image in list_of_images:\n        x.append(img_to_array(load_img(image,target_size=(img_width,img_height))))\n    return x","31531a87":"X=prepare_data(train_images_dogs_cats)\nX=np.array(X)\ny=np.array([0]*3000 + [1]*3000)","fc720fd0":"# Spliting the data in training and validation data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=1) ","07fc5c0f":"# Shape of training data\nprint('Shape of training data {}'.format(X_train.shape))","f6628b23":"nb_train=len(X_train)\nnb_validation=len(X_val)\nbatch_size=16","3b204c84":"datagen = ImageDataGenerator(rescale=1. \/ 255)\n\n# build the VGG16 network\nmodel_vgg16 = applications.VGG16(include_top=False, weights='..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n    \n# creating a train generator \ngenerator = datagen.flow(X_train,y_train, batch_size=batch_size,shuffle=False)\n    \n# getting training data bottle neck features from  VGG16 model\nbottleneck_features_train = model_vgg16.predict_generator(generator, nb_train \/\/ batch_size ,verbose=1 ) ","8d89fbe7":"# validation generator\ngenerator = datagen.flow(X_val,y_val,batch_size=batch_size,shuffle=False)\n    \n# getting validation data bottle neck features from VGG16 model\nbottleneck_features_validation = model_vgg16.predict_generator(\n        generator, nb_validation \/\/ batch_size , verbose =1 ) ","ea566733":"# shape of bottleneck features\nprint(\"Shape of training bottleneck feature {}\".format(bottleneck_features_train.shape))","d709b4eb":"model = Sequential()\n#input layer\nmodel.add(Flatten(input_shape=bottleneck_features_train.shape[1:]))\n\n# first hidden layer\nmodel.add(Dense(units=256,activation='relu'))\nmodel.add(Dropout(0.4))\n\n# Second hidden layer\nmodel.add(Dense(units=126,activation='relu'))\nmodel.add(Dropout(0.4))\n\n#output layer\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.compile(optimizer='rmsprop',\n                  loss='binary_crossentropy', metrics=['accuracy'])\n\n#fitting the model\nhistory=model.fit(x=bottleneck_features_train,y=y_train,\n                  epochs=10,\n                  batch_size=batch_size,\n                  validation_data=(bottleneck_features_validation,y_val))\n\nmodel.save('TL_model.h5')","0749b6b7":"# visualizing the model\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.plot(history.history['acc'],label='Train_acc')\nplt.plot(history.history['val_acc'],label='val_acc')\nplt.xlabel('number of epochs')\nplt.ylabel('accuracy')\nplt.title('Model Accuracy Graph')\nplt.legend()\nplt.show()","f26d27af":"# predicting result of test data\nX_test = prepare_data(test_images_dogs_cats)\nX_test=np.array(X_test)\nprint('Shape of test data {}'.format(X_test.shape))","15284a41":"nb_test=len(X_test)\nbatch_size=20","48ae808b":"# test data generator\ntest_datagen = ImageDataGenerator(rescale=1. \/ 255)\ntest_generator = test_datagen.flow( X_test, batch_size=batch_size,shuffle=False)\n\nmodel_vgg16 = applications.VGG16(include_top=False, weights='..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\n#bottle neck features of our test data\nbottleneck_feature_test_data=model_vgg16.predict_generator(test_generator,nb_test\/\/batch_size,verbose=1)\n\n# predicting probablities\nprediction_probabilities = model.predict(bottleneck_feature_test_data,verbose=1) ","0d27fe1f":"# Visualizing the result of prediction.\nfor i in range(10):\n    if prediction_probabilities[i][0] > 0.5:\n        print(\"I am {a:.2%} sure I am Dog\".format(a=prediction_probabilities[i][0]))\n    else:\n        print(\"I am {a:.2%} sure I am Cat\".format(a=(1-prediction_probabilities[i][0])))\n    plt.imshow(load_img(test_images_dogs_cats[i],target_size=(150,150)))\n    plt.show()","a5cd9ee1":"# creating a submission file\ncounter = range(1, len(test_images_dogs_cats) +1 )\nsolution = pd.DataFrame({\"id\": counter, \"label\":list(prediction_probabilities)})\ncols = ['label']\n\nfor col in cols:\n    solution[col] = solution[col].map(lambda x: str(x).lstrip('[').rstrip(']')).astype(float)\n\nsolution.to_csv(\"dogsVScats.csv\", index = False)","dfe8e96e":"### Sorting the images in their directory by number in image name.\nHelper function for natural Sorting the images of dog and cat in their directory.                                                                                             \nIn a classical alphanumerical sort we will have something like : 1 10 11 12 2 20 21 3 4 5 6 7                                                                           \nIf you're using Natural ordering, it will be :1 2 3 4 5 6 7 10 11 12 20 21","a15c0b76":"Preparing data and generating their labels","0a72dcff":"Visualizing a image of both cat and dog","afb8b007":"## Chosing a subset of training images.\nThe dataset consist of 25000 images of both cat and dog i.e 12500 images of each dog and cat.                                                               \nWe will be using 3000 images of  cat and dog each . A total of which is 6000 images combined dog and cat.                                         \nCat images ranges from index 0 to 12499 and dog images ranges from index 12500 to 25499\nSo, selecting first 3000 images which are cat .\nDog images start from index 12500 and goes to 15500 for 3000 images of dog.","96e83735":"**Data Preprocessing** converting images to array","f779c8ba":"# Predicting the result of test data                                                                                                                                                            \n Here first we calculate the bottle neck features of our test data and give this features to input to top model to get the predictions.","cf4085aa":"# Building the top model","b6f2ebed":"# Using the bottleneck features of a pre-trained network                                                                                                                       \nA more refined approach would be to leverage a network pre-trained on a large dataset. Such a network would have already learned features that are useful for most computer vision problems, and leveraging such features would allow us to reach a better accuracy than any method that would only rely on the available data.\n\nWe will use the VGG16 architecture, pre-trained on the ImageNet dataset --a model previously featured on this blog. Because the ImageNet dataset contains several \"cat\" classes (persian cat, siamese cat...) and many \"dog\" classes among its total of 1000 classes, this model will already have learned features that are relevant to our classification problem. In fact, it is possible that merely recording the softmax predictions of the model over our data rather than the bottleneck features would be enough to solve our dogs vs. cats classification problem extremely well. However, the method we present here is more likely to generalize well to a broader range of problems, including problems featuring classes absent from ImageNet.\n\nOur strategy will be as follow: we will only instantiate the convolutional part of the model, everything up to the fully-connected layers. We will then run this model on our training and validation data once, recording the output (the \"bottleneck features\" from th VGG16 model: the last activation maps before the fully-connected layers) in two numpy arrays. Then we will train a small fully-connected model on top of the stored features.                                                                                                                                                    Check VGG16 model here **\n[https:\/\/gist.github.com\/baraldilorenzo\/07d7802847aaad0a35d3](http:\/\/)"}}