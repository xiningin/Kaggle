{"cell_type":{"daa5ba1a":"code","f438f8a3":"code","4fde87a8":"code","8a195207":"code","1c83b32a":"code","8290e927":"code","cda2226d":"code","e2d20ce1":"code","c6082ddf":"code","ea912a8e":"code","04f6cd03":"code","008d625e":"code","d0b4f05e":"code","55a9ec40":"code","21e76d8f":"code","4dda5312":"code","75f5971a":"code","7909f3a3":"code","5acbc171":"code","10315709":"code","abecb3b5":"code","4b174a12":"markdown","7eb03832":"markdown","38729914":"markdown","30c3ced2":"markdown","e7f48841":"markdown","5a76795f":"markdown","1b2d46a6":"markdown","dba1d89e":"markdown"},"source":{"daa5ba1a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f438f8a3":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport nltk\nimport sklearn\n\n\nfrom tensorflow import keras\nfrom keras.preprocessing.text import text_to_word_sequence\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import wordnet\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import svm\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n","4fde87a8":"dataset = pd.read_csv('..\/input\/learn-ai-bbc\/BBC News Train.csv')\ntest_set = pd.read_csv(\"..\/input\/learn-ai-bbc\/BBC News Test.csv\")\n","8a195207":"dataset.head()","1c83b32a":"target_category = dataset['Category'].unique()\nprint(target_category)","8290e927":"dataset['categoryId'] = dataset['Category'].factorize()[0]\ndataset.head()","cda2226d":"category = dataset[[\"Category\",\"categoryId\"]].drop_duplicates().sort_values('categoryId')\ncategory","e2d20ce1":"dataset.groupby('Category').categoryId.count()","c6082ddf":"dataset.groupby('Category').categoryId.count().plot.bar(ylim=0)","ea912a8e":"text = dataset[\"Text\"] \ntext.head()","04f6cd03":"category = dataset[\"Category\"]\ncategory.head()","008d625e":"def preprocessDataset(train_text):\n       \n    #word tokenization using text-to-word-sequence\n    train_text= str(train_text)\n    tokenized_train_set = text_to_word_sequence(train_text,filters='!\"#$%&()*+,-.\/:;<=>?@[\\\\]^_`{|}~\\t\\n',lower=True,split=\" \")\n        \n    #stop word removal\n    stop_words = set(stopwords.words('english'))\n    stopwordremove = [i for i in tokenized_train_set if not i in stop_words]\n        \n     \n    #join words into sentence\n    stopwordremove_text = ' '.join(stopwordremove)\n        \n        \n    #remove numbers\n    numberremove_text = ''.join(c for c in stopwordremove_text if not c.isdigit())\n       \n        \n    #--Stemming--\n    stemmer= PorterStemmer()\n\n    stem_input=nltk.word_tokenize(numberremove_text)\n    stem_text=' '.join([stemmer.stem(word) for word in stem_input])\n        \n        \n    lemmatizer = WordNetLemmatizer()\n\n    def get_wordnet_pos(word):\n        \"\"\"Map POS tag to first character lemmatize() accepts\"\"\"\n        tag = nltk.pos_tag([word])[0][1][0].upper()\n        tag_dict = {\"J\": wordnet.ADJ,\n                \"N\": wordnet.NOUN,\n                \"V\": wordnet.VERB,\n                \"R\": wordnet.ADV}\n\n        return tag_dict.get(tag, wordnet.NOUN)\n\n    lem_input = nltk.word_tokenize(stem_text)\n    lem_text= ' '.join([lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in lem_input])\n        \n    return lem_text\n\n","d0b4f05e":"dataset['Text'] = dataset['Text'].apply(preprocessDataset)\ntext = dataset['Text']\ncategory = dataset['Category']\ntext.head()","55a9ec40":"X_train, X_test, Y_train, Y_test = train_test_split(text,category, test_size = 0.3, random_state = 60,shuffle=True, stratify=category)\n\nprint(len(X_train))\nprint(len(X_test))","21e76d8f":"nb = Pipeline([('tfidf', TfidfVectorizer()),\n               ('clf', MultinomialNB()),\n              ])\nnb.fit(X_train,Y_train)\n\ntest_predict = nb.predict(X_test)\n\ntrain_accuracy = round(nb.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\n\nprint(\"Naive Bayes Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"Naive Bayes Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))\n","4dda5312":"dt = Pipeline([('tfidf', TfidfVectorizer()),\n                ('dt', DecisionTreeClassifier()),\n               ])\n\ndt.fit(X_train, Y_train)\n\ntest_predict = dt.predict(X_test)\n\ntrain_accuracy = round(dt.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"Decision Tree Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"Decision Tree Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))","75f5971a":"rfc = Pipeline([('tfidf', TfidfVectorizer()),\n                ('rfc', RandomForestClassifier(n_estimators=100)),\n               ])\n\nrfc.fit(X_train, Y_train)\n\ntest_predict = rfc.predict(X_test)\n\ntrain_accuracy = round(rfc.score(X_train,Y_train)*100)\ntest_accuracy =round(accuracy_score(test_predict, Y_test)*100)\n\nprint(\"K-Nearest Neighbour Train Accuracy Score : {}% \".format(train_accuracy ))\nprint(\"K-Nearest Neighbour Test Accuracy Score  : {}% \".format(test_accuracy ))\nprint()\nprint(classification_report(test_predict, Y_test, target_names=target_category))","7909f3a3":"test_set.head()","5acbc171":"test_set['Text'] = test_set['Text'].apply(preprocessDataset)\n\ntest_id = test_set['ArticleId']\ntest_text = test_set['Text']\ny_prdict = nb.predict(test_text)\n\n","10315709":"#submission = pd.DataFrame(test_id)\nsubmission = pd.DataFrame(list(zip(test_id, y_prdict)),\n               columns =['ArticleId', 'Category'])\nsubmission.head(20)","abecb3b5":"submission.to_csv('submission.csv', index=False)","4b174a12":"# Multinomial Naive Bayes","7eb03832":"# Test Set","38729914":"# Train with Naive Bayes","30c3ced2":"# Data Visualization","e7f48841":"# Decision Tree","5a76795f":"# Random Forest Classifier","1b2d46a6":"# Split train set","dba1d89e":"# Data Preprocessing"}}