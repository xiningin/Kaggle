{"cell_type":{"04d98335":"code","b5306512":"code","b2b75ce7":"code","f21f3f7d":"code","b39cc01f":"code","21634f74":"code","be1861be":"code","991e398b":"code","822d6e61":"code","f179a8fb":"code","ac1e0b50":"code","0a17b22b":"code","77744ad9":"code","b64324bb":"code","17791b99":"code","863b5871":"code","d04c780c":"code","6d58fe29":"code","c076edc8":"code","ddfbe763":"code","197063b3":"code","60c53783":"code","5166da8f":"code","3575b758":"code","f3129eab":"code","2200ff9d":"code","cf947d42":"code","4716be5a":"code","193849db":"code","a8de9773":"code","72d28a07":"code","e0462052":"code","e8d3945b":"code","d7ff6473":"code","ea8cfff8":"code","c081875b":"code","76afb567":"code","ad2f1fec":"code","9c201b90":"code","5559ff71":"code","ca589cae":"code","d2a8c218":"code","9f0ec545":"code","8a1a49b3":"code","ee1df2a4":"code","addad8fd":"code","c0b88572":"code","658c32b1":"markdown","59db1014":"markdown","094dd6b6":"markdown","1821fd43":"markdown","6204418f":"markdown","da3766ec":"markdown","567e5a27":"markdown","8462dd7f":"markdown"},"source":{"04d98335":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","b5306512":"train = pd.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\n\ntest = pd.read_csv(\"..\/input\/digit-recognizer\/test.csv\")","b2b75ce7":"train.shape","f21f3f7d":"test.shape","b39cc01f":"train.head()","21634f74":"train.info()","be1861be":"train.isnull().sum().any()","991e398b":"sns.countplot(train[\"label\"])","822d6e61":"labels = list(range(10))","f179a8fb":"labels","ac1e0b50":"f, ax = plt.subplots(2,5, figsize=(15,15))\nl = 0\n\n\nfor i in range(2):\n    for j in range(5):\n        img = train.loc[train[\"label\"] == l].sample().values[0][1:].reshape(28,28)\n        ax[i,j].imshow(img, cmap=\"gray\")\n        l += 1\n    plt.tight_layout()","0a17b22b":"X = train.drop(\"label\", axis=1).values\ny = train[\"label\"].values","77744ad9":"from sklearn.model_selection import train_test_split","b64324bb":"X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=10)","17791b99":"X_test = test.values","863b5871":"y_train.shape","d04c780c":"from keras.utils import to_categorical","6d58fe29":"y_train = to_categorical(y_train)\ny_val_true = y_val.copy()\ny_val = to_categorical(y_val)","c076edc8":"y_train.shape","ddfbe763":"X_train.max()","197063b3":"X_train.min()","60c53783":"X_train = X_train\/255\nX_val = X_val\/255\nX_test = X_test\/255","5166da8f":"X_train.shape","3575b758":"X_train = X_train.reshape(-1, 28, 28, 1)\nX_val = X_val.reshape(-1, 28, 28, 1)\nX_test = X_test.reshape(-1, 28, 28, 1)","f3129eab":"X_train.shape","2200ff9d":"X_val.shape","cf947d42":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","4716be5a":"image_gen = ImageDataGenerator(rotation_range=10,\n                               width_shift_range=0.1,\n                               height_shift_range=0.1,\n                               shear_range=0.1,\n                               zoom_range=0.1,\n                               horizontal_flip=False,\n                               vertical_flip=False,\n                              )","193849db":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPool2D, Flatten, Dense, Dropout, BatchNormalization","a8de9773":"model = Sequential()\n\n\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), input_shape=(28, 28, 1), padding=\"same\", activation=\"relu\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=32, kernel_size=(5,5), input_shape=(28, 28, 1), padding=\"same\", activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters=64, kernel_size=(5,5), input_shape=(28, 28, 1), padding=\"same\", activation=\"relu\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(filters=64, kernel_size=(5,5), input_shape=(28, 28, 1), padding=\"same\", activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\n\nmodel.add(Conv2D(filters=128, kernel_size=(5,5), input_shape=(28, 28, 1), padding=\"same\", activation=\"relu\"))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(pool_size=(2, 2)))\n#model.add(Dropout(0.25))\n\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation=\"relu\"))\nmodel.add(BatchNormalization())\n#model.add(Dropout(0.25))\n\nmodel.add(Dense(10, activation=\"softmax\"))\n\nmodel.compile(loss='categorical_crossentropy', optimizer=\"adam\", metrics=[\"accuracy\"])","72d28a07":"model.summary()","e0462052":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau","e8d3945b":"check_point = ModelCheckpoint(\"best_model.h5\", monitor=\"val_accuracy\", verbose=1, save_best_only=True)","d7ff6473":"reduce_lr = ReduceLROnPlateau(monitor=\"val_accuracy\", patience=3, verbose=1, factor=0.5, min_lr=0.0001)","ea8cfff8":"#model.fit(X_train, y_train, epochs=100, validation_data=(X_val,y_val), callbacks=[check_point,reduce_lr])","c081875b":"history = model.fit_generator(image_gen.flow(X_train,y_train, batch_size=64),\n                              epochs = 50, validation_data = (X_val,y_val),\n                              verbose = 1,\n                              callbacks=[check_point, reduce_lr])","76afb567":"losses = pd.DataFrame(model.history.history)","ad2f1fec":"losses.head()","9c201b90":"losses[[\"accuracy\", \"val_accuracy\"]].plot()","5559ff71":"losses[[\"loss\", \"val_loss\"]].plot()","ca589cae":"print(\"Accuracy on validation data: {:.4f}\".format(losses[\"val_accuracy\"].max()))","d2a8c218":"from keras.models import load_model","9f0ec545":"saved_model = load_model('best_model.h5')","8a1a49b3":"predictions = saved_model.predict_classes(X_test)","ee1df2a4":"submission = pd.Series(predictions, name=\"Label\")","addad8fd":"submission = pd.concat([pd.Series(range(1,28001), name =\"ImageId\"), submission], axis = 1)","c0b88572":"submission.to_csv(\"submission.csv\", index=False)","658c32b1":"# **Reshaping the Data**","59db1014":"# **Evaluation**","094dd6b6":"# **Data**","1821fd43":"# **Model**","6204418f":"# **Scaling the Data**","da3766ec":"# **Training**","567e5a27":"# **Train Validation Test Split**","8462dd7f":"# **Image Generation**"}}