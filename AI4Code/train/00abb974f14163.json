{"cell_type":{"d6556a15":"code","4c3fa9e5":"code","8d676185":"markdown","590917e0":"markdown"},"source":{"d6556a15":"import pandas as pd\n\npd.read_parquet('\/kaggle\/input\/binance-full-history\/BNB-USDT.parquet').to_csv('BNB-USDT.csv')","4c3fa9e5":"# for filename in os.listdir('\/kaggle\/input\/binance-full-history\/'):\n#     pairname = filename.split('.')[0]\n#     pd.read_parquet(filename).to_csv(f'{pairname}.csv')","8d676185":"One-liner to convert a specific pair from `.parquet` to `.csv`:","590917e0":"One could also imagine doing this in a for-loop with all the files in the dataset. Note however they are in this file format for a reason; in this case writing to an (uncompressed) csv file roughly increases the storage size by a factor 5.\n\nSome more info on Parquet's compression technique can be found in [its docs](https:\/\/parquet.apache.org\/documentation\/latest\/)."}}