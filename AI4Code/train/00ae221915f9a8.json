{"cell_type":{"78dcb78f":"code","1762a949":"code","5e38f28d":"code","0c2fef8c":"code","121f57d9":"code","3d86732c":"code","9c8c7958":"code","a7249b55":"code","209b2100":"code","64cbe46c":"code","872a7c25":"code","b6cc146d":"code","7ccfcfec":"code","1359f7c7":"code","be5095ba":"code","841a6cc0":"markdown","347262d2":"markdown","36e22d21":"markdown","1a7c172a":"markdown","5f19a914":"markdown","9753ccd2":"markdown","87942268":"markdown","2ac5a909":"markdown"},"source":{"78dcb78f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1762a949":"# Imports\n\nimport numpy as ny\nimport pandas as ps\nimport plotly.express as plex\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objects as go\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tflow\nfrom tensorflow import keras\nfrom tensorflow.keras.callbacks import EarlyStopping","5e38f28d":"train_set = ps.read_csv(\"..\/input\/digit-recognizer\/train.csv\")\ntest_set = ps.read_csv(\"..\/input\/digit-recognizer\/test.csv\")\n\n# Verifying shapes and values\n\nprint(\" \\n Length of train_set is :\", len(train_set),\" and shape is: \",train_set.shape)\nprint(\" \\n Length of test_set is :\", len(test_set),\" and shape is: \",test_set.shape)","0c2fef8c":"# Confirm images represented as numeric dataframes from both train and test sets.\n\ntrain_set.head(10)","121f57d9":"test_set.head(10)","3d86732c":"train_set.describe()","9c8c7958":"# Examining % spread of digit labels.\n\npie1 = plex.pie(train_set, names = \"label\",title = \"<b> Digit Labels <\/b>\",hole = 0.4, template = \"ggplot2\",width=1200, height=600)\npie1.show()","a7249b55":"# Examining counts on a bar plot.\n\nvalue_counts = train_set['label'].value_counts()\n\nbar3 = plex.bar(x=value_counts.index,y=value_counts.values,template='gridon', title=\"Value counts of digits\",pattern_shape_sequence=[\".\"])\nbar3.show()","209b2100":"# Splitting X and y from the train_set.\n\ny_train = train_set['label']\nX_train = train_set.drop(columns=['label'])\nX_test = test_set.copy()\n\nprint(\" \\n X_train shape is: \",X_train.shape)\nprint(\" \\n X_test shape is: \",X_test.shape)\nprint(\" \\n y_train shape is: \",y_train.shape)\n\n# Shapes are good. Onto normalizing the data. \n# Normalizing the color values from minimum 0 ( Black) to maximum 255 ( White)\n\nX_train = X_train \/ 255 \nX_test = X_test \/ 255","64cbe46c":"# Defining early stopping parameters for epochs.\n\nearly_stopper = EarlyStopping( patience=10,\n                              min_delta=0.001,\n                              restore_best_weights=True)\n\nfirst_nn = keras.Sequential([\n    keras.layers.Dense(28,input_shape=[784]),\n    keras.layers.Dense(392, activation='relu'),\n    keras.layers.Dense(28, activation='relu'),\n    keras.layers.Dense(10,activation='sigmoid')\n])\n\nfirst_nn.compile(optimizer='adam',\n                loss='sparse_categorical_crossentropy',\n                metrics='accuracy')\n\nfirst_nn.fit(X_train,y_train,\n             epochs=30,               \n             callbacks=[early_stopper]) ","872a7c25":"# Predicting manually -  Given a random number, select a number(index) from the X_train_input array.\n\nX_train_array = ny.array(X_train)\n\nX_train_input = X_train_array.reshape(X_train_array.shape[0], 28, 28)\n\nplex.imshow(X_train_input[32])","b6cc146d":"y_pred = first_nn.predict(X_train)\ny_pred[32]","7ccfcfec":"print(\"\\n Number predicted is: \", ny.argmax(y_pred[32]) ) # Did the number match the image ?","1359f7c7":"# Actual predictions on X_test\n\npredictions = ny.argmax(first_nn.predict(X_test), axis=1)\n\n# reading submission file.\ndigits_submission = ps.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\ndigits_submission.head()","be5095ba":"digits_submission['Label']  = predictions\ndigits_submission.to_csv('submission.csv',index=False)\ndigits_submission.head()","841a6cc0":"# Introduction\n\n**Purpose of this notebook is to give insights into the dataset, build a Nueral network to identify digits from images in the MNIST dataset**\n\n**Tasks:**\n\n1. To understand datasets( train and test), variables, clean(if needed) the data and visualize important use-cases.\n\n2. Consider 'label' as the independent variable from the train_set.\n\n3. Train a Neural network for a given train-test-split peices, examine epochs, accuracy, re-tune NN's parameters(if needed).\n\n4. Manully predict a few images and record history-plots.\n\n5. Upload the submission.","347262d2":"![](https:\/\/miro.medium.com\/max\/1400\/1*ee5sr4o6lAJ6qcdKXhGoFg.png)","36e22d21":"# 4. Observations\n\n1. Building a Neural network without scaling the color values was easy but loss % change was low. Below are scores:\n\nEpoch 14\/15\n1313\/1313 [==============================] - 2s 1ms\/step - loss: 4.5935 - accuracy: 0.9004\n\nEpoch 15\/15\n1313\/1313 [==============================] - 2s 1ms\/step - loss: 4.7254 - accuracy: 0.8979\n\n\n2. After scaling the dataframe scores seemed better:\n\nEpoch 14\/15\n1313\/1313 [==============================] - 2s 1ms\/step - loss: 0.2308 - accuracy: 0.9340\n\nEpoch 15\/15\n1313\/1313 [==============================] - 2s 1ms\/step - loss: 0.2282 - accuracy: 0.9354\n\n\n3. With just one layer with 784 inputs and 10 outputs(units) the above scores were generated. Added 2 dense layers with half of input_shape.\n\nEpoch 29\/30\n1313\/1313 [==============================] - 3s 2ms\/step - loss: 0.0151 - accuracy: 0.9947\n\nEpoch 30\/30\n1313\/1313 [==============================] - 3s 2ms\/step - loss: 0.0156 - accuracy: 0.9955\n\n\n4. Suggestions and comments are welcome !\n\n\n**Thank you for your time !**","1a7c172a":"# 1. Primary checks and EDA.","5f19a914":"**Plotting a few use-cases:**","9753ccd2":"# 3. Building a NN","87942268":"# 2. Preprocessing Data","2ac5a909":"# 3.1 Predict Manually"}}