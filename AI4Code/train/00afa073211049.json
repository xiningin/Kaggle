{"cell_type":{"5c35d317":"code","e1602fce":"code","f3516b02":"code","3255492f":"code","aeebe58a":"code","e6a42ca1":"code","b176c55a":"code","4f6a360c":"code","646ff145":"code","ceddaaa0":"code","dd1abd2d":"code","1183c5a6":"code","277fc0b6":"code","484d29a1":"code","a9d92752":"code","b3ef1084":"code","566c7a0d":"code","681ef84d":"code","47db473c":"code","75d27000":"markdown","f97a361e":"markdown","1d8722b5":"markdown","203e7108":"markdown","18c196e9":"markdown","8e42290a":"markdown","54cd8250":"markdown","6a867210":"markdown","bad4c2d8":"markdown","9cdf6e40":"markdown","f93e51e3":"markdown","08d2c2df":"markdown"},"source":{"5c35d317":"import numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom tqdm import tqdm\nfrom sklearn.utils import shuffle\nfrom sklearn.utils import class_weight\nfrom sklearn.preprocessing import minmax_scale\nimport random\nimport cv2\nfrom imgaug import augmenters as iaa\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Input, BatchNormalization, GlobalAveragePooling2D\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.experimental import CosineDecay\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.applications import EfficientNetB3\nfrom tensorflow.keras.layers.experimental.preprocessing import RandomCrop,CenterCrop, RandomRotation","e1602fce":"training_folder = '..\/input\/cassava-leaf-disease-classification\/train_images\/'","f3516b02":"samples_df = pd.read_csv(\"..\/input\/cassava-leaf-disease-classification\/train.csv\")\nsamples_df = shuffle(samples_df, random_state=42)\nsamples_df[\"filepath\"] = training_folder+samples_df[\"image_id\"]\nsamples_df.head()\n","3255492f":"training_percentage = 0.8\ntraining_item_count = int(len(samples_df)*training_percentage)\nvalidation_item_count = len(samples_df)-int(len(samples_df)*training_percentage)\ntraining_df = samples_df[:training_item_count]\nvalidation_df = samples_df[training_item_count:]\n","aeebe58a":"batch_size = 8\nimage_size = 512\ninput_shape = (image_size, image_size, 3)\ndropout_rate = 0.4\nclasses_to_predict = sorted(training_df.label.unique())","e6a42ca1":"training_data = tf.data.Dataset.from_tensor_slices((training_df.filepath.values, training_df.label.values))\nvalidation_data = tf.data.Dataset.from_tensor_slices((validation_df.filepath.values, validation_df.label.values))","b176c55a":"def load_image_and_label_from_path(image_path, label):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    return img, label\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\n\ntraining_data = training_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\nvalidation_data = validation_data.map(load_image_and_label_from_path, num_parallel_calls=AUTOTUNE)\n\n\ntraining_data_batches = training_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)\nvalidation_data_batches = validation_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)","4f6a360c":"adapt_data = tf.data.Dataset.from_tensor_slices(training_df.filepath.values)\ndef adapt_mode(image_path):\n    img = tf.io.read_file(image_path)\n    img = tf.image.decode_jpeg(img, channels=3)\n    img = layers.experimental.preprocessing.Rescaling(1.0 \/ 255)(img)\n    return img\n\nadapt_data = adapt_data.map(adapt_mode, num_parallel_calls=AUTOTUNE)\nadapt_data_batches = adapt_data.shuffle(buffer_size=1000).batch(batch_size).prefetch(buffer_size=AUTOTUNE)","646ff145":"data_augmentation_layers = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomCrop(height=image_size, width=image_size),\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        layers.experimental.preprocessing.RandomRotation(0.25),\n        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n    ]\n)","ceddaaa0":"efficientnet = EfficientNetB3(weights=\"..\/input\/keras-efficientnetb3-no-top-weights\/efficientnetb3_notop.h5\", \n                              include_top=False, \n                              input_shape=input_shape, \n                              drop_connect_rate=dropout_rate)\n\ninputs = Input(shape=input_shape)\naugmented = data_augmentation_layers(inputs)\nefficientnet = efficientnet(augmented)\npooling = layers.GlobalAveragePooling2D()(efficientnet)\ndropout = layers.Dropout(dropout_rate)(pooling)\noutputs = Dense(len(classes_to_predict), activation=\"softmax\")(dropout)\nmodel = Model(inputs=inputs, outputs=outputs)\n    \nmodel.summary()","dd1abd2d":"epochs = 20","1183c5a6":"\ndecay_steps = int(round(len(training_df)\/batch_size))*epochs\ncosine_decay = CosineDecay(initial_learning_rate=1e-4, decay_steps=decay_steps, alpha=0.3)\n\ncallbacks = [ModelCheckpoint(filepath='best_model.h5', monitor='val_loss', save_best_only=True)]\n\nmodel.compile(loss=\"sparse_categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(cosine_decay), metrics=[\"accuracy\"])","277fc0b6":"\nhistory = model.fit(training_data_batches,\n                  epochs = epochs, \n                  validation_data=validation_data_batches,\n                  callbacks=callbacks)","484d29a1":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Loss over epochs')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Validation'], loc='best')\nplt.show()\n","a9d92752":"model.load_weights(\".\/best_model.h5\")","b3ef1084":"def scan_over_image(img_path, crop_size=512):\n    '''\n    Will extract 512x512 images covering the whole original image\n    with some overlap between images\n    '''\n    \n    img = Image.open(img_path)\n    img_height, img_width = img.size\n    img = np.array(img)\n    \n    y = random.randint(0,img_height-crop_size)\n    x = random.randint(0,img_width-crop_size)\n\n    x_img_origins = [0,img_width-crop_size]\n    y_img_origins = [0,img_height-crop_size]\n    img_list = []\n    for x in x_img_origins:\n        for y in y_img_origins:\n            img_list.append(img[x:x+crop_size , y:y+crop_size,:])\n  \n    return np.array(img_list)\n\n\n\ndef display_samples(img_path):\n    '''\n    Display all 512x512 images extracted from original images\n    '''\n    \n    img_list = scan_over_image(img_path)\n    sample_number = len(img_list)\n    fig = plt.figure(figsize = (8,sample_number))\n    for i in range(0,sample_number):\n        ax = fig.add_subplot(2, 4, i+1)\n        ax.imshow(img_list[i])\n        ax.set_title(str(i))\n    plt.tight_layout()\n    plt.show()\n\ndisplay_samples(\"..\/input\/cassava-leaf-disease-classification\/train_images\/3412658650.jpg\")\n\ntest_time_augmentation_layers = tf.keras.Sequential(\n    [\n        layers.experimental.preprocessing.RandomFlip(\"horizontal_and_vertical\"),\n        layers.experimental.preprocessing.RandomZoom((-0.2, 0)),\n        layers.experimental.preprocessing.RandomContrast((0.2,0.2))\n    ]\n)","566c7a0d":"def predict_and_vote(image_filename, folder, TTA_runs=4):\n    '''\n    Run the model over 4 local areas of the given image,\n    before making a decision depending on the most predicted\n    disease.\n    '''\n    \n    #apply TTA to each of the 4 images and sum all predictions for each local image\n    localised_predictions = []\n    local_image_list = scan_over_image(folder+image_filename)\n    for local_image in local_image_list:\n        duplicated_local_image = tf.convert_to_tensor(np.array([local_image for i in range(TTA_runs)]))\n        augmented_images = test_time_augmentation_layers(duplicated_local_image)\n        \n        predictions = model.predict(augmented_images)\n        localised_predictions.append(np.sum(predictions, axis=0))\n    \n    #sum all predictions from all 4 images and retrieve the index of the highest value\n    global_predictions = np.sum(np.array(localised_predictions),axis=0)\n    final_prediction = np.argmax(global_predictions)\n    \n    return final_prediction\n\n\n\ndef run_predictions_over_image_list(image_list, folder):\n    predictions = []\n    with tqdm(total=len(image_list)) as pbar:\n        for image_filename in image_list:\n            pbar.update(1)\n            predictions.append(predict_and_vote(image_filename, folder))\n    return predictions\n\n\n\n# validation_df[\"results\"] = run_predictions_over_image_list(validation_df[\"image_id\"], training_folder)\n\ntest_folder = '..\/input\/cassava-leaf-disease-classification\/test_images\/'\nsubmission_df = pd.DataFrame(columns={\"image_id\",\"label\"})\nsubmission_df[\"image_id\"] =  os.listdir(test_folder)\nsubmission_df[\"label\"] = run_predictions_over_image_list(submission_df[\"image_id\"], test_folder)\n# result = run_predictions_over_image_list(submission_df[\"image_id\"], test_folder)\n# submission_df[\"label\"] = result","681ef84d":"submission_df","47db473c":"submission_df.to_csv(\"submission.csv\", index=False) ","75d27000":"# \ud83d\udcf2CallBacks","f97a361e":"# Data Augmentation \n\nData Augmenetation is used to increase the amount of train data so that we have enough data for training the model","1d8722b5":"# Plotting our loss \ud83d\udcc8\ud83d\udcca","203e7108":"# ***Adding filepath to the csv file***","18c196e9":"# Importing Libraries\/Packages. \ud83d\udce6","8e42290a":"Displaying Sample Images","54cd8250":"# Rescaling the image by dividing each pixel by 255\ud83d\udccf","6a867210":"<div><h2> \ud83d\udccc Please Upvote the notebook \ud83d\udc4d\ud83d\udc4d and write your suggestions\u270d.<\/h2> <\/div>","bad4c2d8":"# \ud83d\ude9a Importing our model \ud83d\ude9b","9cdf6e40":"# Predicting for test data \ud83d\udcc0\ud83d\udcbf","f93e51e3":"# Training Model \ud83d\udc68\u200d\ud83c\udfeb","08d2c2df":"#  Using <code>tf.data<\/code> to import images \ud83c\udf9e\ud83d\udcf8"}}