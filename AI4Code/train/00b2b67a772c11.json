{"cell_type":{"48c73ac7":"code","5a04774d":"code","ed70caf4":"code","4c8c6456":"code","0c1ddf6f":"code","75638261":"code","1c37d610":"code","dd371884":"code","2cbabeca":"code","8c0eb5db":"code","30aaae04":"markdown","ff136771":"markdown","5433fbe9":"markdown","e0b3ba3a":"markdown","e00de80c":"markdown"},"source":{"48c73ac7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5a04774d":"pip install torch==1.10.1+cu102 torchvision==0.11.2+cu102 torchaudio===0.10.1+cu102 -f https:\/\/download.pytorch.org\/whl\/cu102\/torch_stable.html","ed70caf4":"import torch\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch import nn\nfrom transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup, GPT2Tokenizer, GPT2Model, MT5EncoderModel, T5Tokenizer","4c8c6456":"torch.__version__","0c1ddf6f":"class HyperboleDataset(Dataset):\n    def __init__(self, test_index, flag):\n        self.text, self.labels = self.data_process(test_index, flag)\n\n    def __len__(self):\n        return len(self.text)\n\n    def __getitem__(self, index):\n        return {\"text\": self.text[index], \"label\": self.labels[index]}\n\n    def data_process(self, test_index, flag):\n        text = []\n        labels = []\n        if flag == \"train\":\n            for index in range(1, 11):\n                if index == test_index:\n                    continue\n                with open(f'\/kaggle\/input\/rhetorical-dataset\/{index}.txt', encoding='utf-8') as f:\n                    for line in f.readlines():\n                        label = []\n                        line = line.strip().split('\\t')\n                        text.append(line[0])\n#                         label.append(int(line[1]))\n                        label.append(int(line[2]))\n                        label.append(int(line[3]))\n                        labels.append(label)\n        elif flag == \"test\":\n            with open(f'\/kaggle\/input\/rhetorical-dataset\/{test_index}.txt', encoding='utf-8') as f:\n                for line in f.readlines():\n                    label = []\n                    line = line.strip().split('\\t')\n                    text.append(line[0])\n#                     label.append(int(line[1]))\n                    label.append(int(line[2]))\n                    label.append(int(line[3]))\n                    labels.append(label)\n        return text, labels","75638261":"class BertClassificationCollator(object):\n    def __init__(self, tokenizer, max_seq_len=None):\n        self.tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n\n    def __call__(self, sequences):\n        texts = [sequence['text'] for sequence in sequences]\n        labels = [sequence['label'] for sequence in sequences]\n        inputs = self.tokenizer(text=texts,\n                                return_tensors='pt',\n                                add_special_tokens=True,\n                                padding='max_length',\n                                truncation=True,\n                                max_length=self.max_seq_len)\n        inputs.update({'labels': torch.tensor(labels)})\n        return inputs\n\nclass GPTClassificationCollator(object):\n    def __init__(self, tokenizer, max_seq_len=None):\n        self.tokenizer = tokenizer\n        self.max_seq_len = max_seq_len\n\n    def __call__(self, sequences):\n        texts = [sequence['text'] for sequence in sequences]\n        labels = [sequence['label'] for sequence in sequences]\n        inputs = self.tokenizer(text=texts,\n                                return_tensors='pt',\n                                padding='max_length',\n                                truncation=True,\n                                max_length=self.max_seq_len)\n        inputs.update({'labels': torch.tensor(labels)})\n        return inputs","1c37d610":"class BertTextClassification(nn.Module):\n    def __init__(self):\n        super(BertTextClassification, self).__init__()\n        self.bert = BertModel.from_pretrained(\"bert-base-uncased\")\n        self.tokenizer = BertTokenizer.from_pretrained(\"bert-base-uncased\", do_lower_case=True)\n        self.dense = nn.Linear(768, 2)\n\n    def forward(self, inputs):\n        outputs = self.bert(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n        last_hidden_states = outputs.last_hidden_state\n        out = self.dense(last_hidden_states[:, 0, :])\n        return out\n\nclass GPT2TextClassification(nn.Module):\n    def __init__(self):\n        super(GPT2TextClassification, self).__init__()\n        self.gpt = GPT2Model.from_pretrained(\"gpt2\")\n        self.tokenizer = GPT2Tokenizer.from_pretrained(\"gpt2\")\n        self.tokenizer.padding_side = \"left\"  # \u5728\u53e5\u5b50\u5de6\u8fb9\u586b\u5145\n        self.tokenizer.pad_token = self.tokenizer.eos_token\n        self.gpt.resize_token_embeddings(len(self.tokenizer))\n        self.gpt.config.pad_token_id = self.gpt.config.eos_token_id\n        self.dense = nn.Linear(768, 3)\n\n    def forward(self, inputs):\n        outputs = self.gpt(input_ids=inputs['input_ids'], attention_mask=inputs['attention_mask'])\n        last_hidden_states = outputs.last_hidden_state\n        out = self.dense(last_hidden_states[:, -1, :])\n        return out\n\nclass MT5TextClassification(torch.nn.Module):\n    def __init__(self, hidden_size=768, num_classes=3, max_seq_len=39):\n        super(MT5TextClassification, self).__init__()\n        self.mt5 = MT5EncoderModel.from_pretrained(\"google\/mt5-base\")\n        self.tokenizer = T5Tokenizer.from_pretrained(\"google\/mt5-base\")\n        self.dense = nn.Linear(hidden_size * max_seq_len, num_classes)\n\n    def forward(self, inputs):\n        outputs = self.mt5(input_ids=inputs['input_ids'])\n        hidden_state = outputs.last_hidden_state  # [batch_size, seq_len, hidden_size]\n        hidden_state = hidden_state.view(hidden_state.size(0), -1) # [batch_size, hidden_size * seq_len]\n        logits = self.dense(hidden_state)  # [batch_size, hidden_size * seq_len] -> [batch_size, num_classes]\n        return logits","dd371884":"def train(model, data_loader, epochs, criterion, optimizer, scheduler, device):\n    model.train()\n\n    for epoch in range(epochs):\n        total_loss = []\n        predict_labels = []\n        true_labels = []\n\n        for batch in data_loader:\n            batch = {k: v.type(torch.long).to(device) for k, v in batch.items()}\n            true_labels += batch['labels'].cpu().flatten().numpy().tolist()\n            logits = model(batch)  # shape (batch_size, num_labels)\n            logits = sigmoid(logits)\n            loss = criterion(logits, batch['labels'].float())\n\n            total_loss.append(loss.item())\n\n            optimizer.zero_grad()\n            loss.backward()\n            torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)  # prevent exploding gradient\n\n            optimizer.step()\n            scheduler.step()\n\n            predict_labels += torch.where(logits > 0.5, 1, 0).cpu().flatten().numpy().tolist()\n        # metaphor_acc, hyperbole_acc, sarcasm_acc, total_acc = acc(predict_labels, true_labels)\n#         print(f'epoch: {epoch+1} train_loss: {torch.tensor(total_loss).mean():.4f} metaphor_acc: {metaphor_acc:.4f} '\n#               f'hyperbole_acc: {hyperbole_acc:.4f} sarcasm_acc: {sarcasm_acc:.4f} total_acc: {total_acc:.4f}')\n        print(f'epoch: {epoch+1} train_loss: {torch.tensor(total_loss).mean():.4f}')\n\n\ndef evaluate(model, data_loader, device):\n    model.eval()\n    total_loss = []\n    predict_labels = []\n    true_labels = []\n\n    with torch.no_grad():\n        for batch in data_loader:\n            batch = {k: v.type(torch.long).to(device) for k, v in batch.items()}\n            true_labels += batch['labels'].cpu().flatten().numpy().tolist()\n            logits = model(batch)\n            logits = sigmoid(logits)\n            predict_labels += torch.where(logits > 0.5, 1, 0).cpu().flatten().numpy().tolist()\n            loss = criterion(logits, batch['labels'].float())\n            total_loss.append(loss.item())\n        # metaphor_acc, hyperbole_acc, sarcasm_acc, total_acc = acc(predict_labels, true_labels, mode=\"evaluate\")\n\n#         total_metaphor_acc.append(metaphor_acc)\n#         total_hyperbole_acc.append(hyperbole_acc)\n#         total_sarcasm_acc.append(sarcasm_acc)\n#         total_all_acc.append(total_acc)\n\n#         print(f'test_loss: {torch.tensor(total_loss).mean():.4f} metaphor_acc: {metaphor_acc:.4f} '\n#               f'hyperbole_acc: {hyperbole_acc:.4f} sarcasm_acc: {sarcasm_acc:.4f} total_acc: {total_acc:.4f}')\n        print(f'test_loss: {torch.tensor(total_loss).mean():.4f}')\n    return np.array(predict_labels).reshape(-1, 2), np.array(true_labels).reshape(-1, 2)\n\n\ndef acc(predict_labels, true_labels, mode=\"train\"):\n    predict_labels = np.array(predict_labels).flatten()\n    true_labels = np.array(true_labels).flatten()\n    total = len(predict_labels) \/ 3\n    metaphor_correct = 0\n    hyperbole_correct = 0\n    sarcasm_correct = 0\n    total_correct = 0\n\n    cnt = 0\n    label = [0, 0, 0]\n    for i, predict in enumerate(predict_labels):\n        label[cnt % 3] = predict_labels[i]\n        cnt += 1\n        if cnt % 3 == 0:\n            if true_labels[i] == label[2] and true_labels[i-1] == label[1] and true_labels[i-2] == label[0]:\n                total_correct += 1\n                if mode == \"evaluate\":\n                    if label == [1, 0, 0]:\n                        total_metaphor_correct.append(1)\n                    elif label == [0, 1, 0]:\n                        total_hyperbole_correct.append(1)\n                    elif label == [0, 0, 1]:\n                        total_sarcasm_correct.append(1)\n                    elif label == [1, 1, 0]:\n                        total_metaphor_hyperbole_correct.append(1)\n                    elif label == [0, 1, 1]:\n                        total_hyperbole_sarcasm_correct.append(1)\n                    elif label == [1, 0, 1]:\n                        total_metaphor_sarcasm_correct.append(1)\n                    elif label == [1, 1, 1]:\n                        total_metaphor_hyperbole_sarcasm_correct.append(1)\n\n        if predict == true_labels[i]:\n            if i % 3 == 0:\n                metaphor_correct += 1\n            elif i % 3 == 1:\n                hyperbole_correct += 1\n            elif i % 3 == 2:\n                sarcasm_correct += 1\n    return metaphor_correct\/total, hyperbole_correct\/total, sarcasm_correct\/total, total_correct\/total","2cbabeca":"device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\nepochs = 50\nbatch_size = 64\nlr = 1e-4","8c0eb5db":"if __name__ == '__main__':\n#     file_line = {'metaphor': 224, \"hyperbole\": 310, \"sarcasm\": 350,\n#                  \"metaphor_hyperbole\": 310, \"metaphor_sarcasm\": 20, \"hyperbole_sarcasm\": 465,\n#                  \"metaphor_hyperbole_sarcasm\": 149}\n    test_folds = range(1, 11)\n#     total_metaphor_acc = []\n#     total_hyperbole_acc = []\n#     total_sarcasm_acc = []\n#     total_all_acc = []\n    \n#     total_metaphor_correct = []\n#     total_hyperbole_correct = []\n#     total_sarcasm_correct = []\n#     total_metaphor_hyperbole_correct = []\n#     total_metaphor_sarcasm_correct = []\n#     total_hyperbole_sarcasm_correct = []\n#     total_metaphor_hyperbole_sarcasm_correct = []\n    \n    for test_fold in test_folds:\n        model = BertTextClassification()\n        # model = GPT2TextClassification()\n        # model = MT5TextClassification()\n        model.to(device)\n        tokenizer = model.tokenizer\n\n        train_dataset = HyperboleDataset(test_fold, \"train\")\n        test_dataset = HyperboleDataset(test_fold, \"test\")\n        \n        text = np.array([item['text'] for item in test_dataset])\n        \n        classificationCollator = BertClassificationCollator(tokenizer, 39)\n        # classificationCollator = GPTClassificationCollator(tokenizer, 39)\n        train_loader = DataLoader(train_dataset, batch_size, shuffle=True, pin_memory=True,\n                                      collate_fn=classificationCollator)\n        test_loader = DataLoader(test_dataset, batch_size, shuffle=False, pin_memory=True,\n                                     collate_fn=classificationCollator)\n        \n        optimizer = AdamW(model.parameters(), lr=lr)\n        sigmoid = torch.nn.Sigmoid()\n        criterion = nn.CrossEntropyLoss()\n        total_steps = len(train_loader) * epochs\n        lr_scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=total_steps)\n\n        print(f\"test_fold: {test_fold}\")\n        train(model, train_loader, epochs, criterion, optimizer, lr_scheduler, device)\n        predict_labels, true_labels = evaluate(model, test_loader, device)\n\n        submission = pd.DataFrame()\n        submission['text'] = text\n        # submission['metaphor'] = true_labels[:, 0]\n        # submission['metaphor_predict'] = predict_labels[:, 0]\n\n        submission['hyperbole'] = true_labels[:, 0]\n        submission['hyperbole_predict'] = predict_labels[:, 0]\n\n        submission['sarcasm'] = true_labels[:, 1]\n        submission['sarcasm_predict'] = predict_labels[:, 1]\n        submission.to_csv(f'\/kaggle\/working\/bert_hs_{test_fold}.csv', index=False)\n        \n    # print(f'avg_metaphor_acc: {torch.tensor(total_metaphor_acc).mean():.4f}')\n    # print(f'avg_hyperbole_acc: {torch.tensor(total_hyperbole_acc).mean():.4f}')\n    # print(f'avg_sarcasm_acc: {torch.tensor(total_sarcasm_acc).mean():.4f}')\n    # print(f'avg_total_acc: {torch.tensor(total_all_acc).mean():.4f}')\n    \n    # print('metaphor_acc: ', round(len(total_metaphor_correct)\/file_line['metaphor'], 4), len(total_metaphor_correct))\n    # print('hyperbole_acc: ', round(len(total_hyperbole_correct)\/file_line['hyperbole'], 4), len(total_hyperbole_correct))\n    # print('sarcasm_acc: ', round(len(total_sarcasm_correct)\/file_line['sarcasm'], 4), len(total_sarcasm_correct))\n    # print('metaphor_hyperbole_acc: ', round(len(total_metaphor_hyperbole_correct)\/file_line['metaphor_hyperbole'], 4), len(total_metaphor_hyperbole_correct))\n    # print('metaphor_sarcasm_acc: ', round(len(total_metaphor_sarcasm_correct)\/file_line['metaphor_sarcasm'], 4), len(total_metaphor_sarcasm_correct))\n    # print('hyperbole_sarcasm_acc: ', round(len(total_hyperbole_sarcasm_correct)\/file_line['hyperbole_sarcasm'], 4), len(total_hyperbole_sarcasm_correct))\n    # print('metaphor_hyperbole_sarcasm_acc: ', round(len(total_metaphor_hyperbole_sarcasm_correct)\/file_line['metaphor_hyperbole_sarcasm'], 4), len(total_metaphor_hyperbole_sarcasm_correct))","30aaae04":"# Model","ff136771":"# Dataset","5433fbe9":"# Collator","e0b3ba3a":"# **Pipeline**","e00de80c":"# HyperParameters"}}