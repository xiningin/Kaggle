{"cell_type":{"d8f7f845":"code","6257710b":"code","30ae7c91":"code","0957807f":"code","ac190243":"code","8bc358eb":"code","c996ea55":"code","781bf869":"code","70f001e6":"code","e691f1c5":"code","ba82e558":"code","616dabac":"code","9ec07c3a":"code","0504993f":"code","e204d84b":"code","7c9471bb":"code","918ef875":"code","9f004d29":"code","10f59ffc":"code","b0f9067b":"code","2122a506":"markdown","54be6bcd":"markdown","8d3a983b":"markdown","15c62c32":"markdown","aadb86ab":"markdown","98fdaab9":"markdown","58e44dad":"markdown","64cc5854":"markdown","f50dab9d":"markdown"},"source":{"d8f7f845":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n\nimport matplotlib.pyplot as plt\nimport seaborn as sb\n\nimport matplotlib.mlab as mlab","6257710b":"from scipy.signal import resample_poly, firwin, windows\n\nfrom multiprocessing import sharedctypes, Pool\nimport gc\n\n#load the target array just because\ntraining_df = pd.read_csv('\/kaggle\/input\/g2net-gravitational-wave-detection\/training_labels.csv')\n\n#record the number of samples\nno_samples = len(training_df)\n\n#the amount of signals we`re going to use to record the frequency spectrum (there are a lot of signals ok?)\nno_spectral_samples = 250000\n\n#just to thest everything with one signal, load one\ntest_ts = np.load('\/kaggle\/input\/g2net-gravitational-wave-detection\/train\/0\/0\/0\/00000e74ad.npy')\n\n#resample by the factor of 3 and apply a high pass filter at 20Hz\nresampling_frac = 3\nresample_test = resample_poly(test_ts, 1, resampling_frac,axis=-1, window=firwin(5, cutoff=20,pass_zero='highpass', fs=test_ts.shape[1]\/2))\n\n\n#okay, we`re ready, create aresult array to fill in the loaded samples\ntarget_array = np.zeros((no_spectral_samples, 3, resample_test.shape[1]))\nprint(f'Target-Array-Size: {(target_array.size * target_array.itemsize)\/(1024**3)}')\n\n#make it a shared c type array for multiprocessing\ntarget_array = np.ctypeslib.as_ctypes(target_array)\ntarget_array = sharedctypes.RawArray(target_array._type_, target_array)\n","30ae7c91":"#a function to load signals into the array with downsampling\ndef gather_raw_samples(i):\n    #i is the index in the training df\n    filename = training_df['id'][i]\n    \n    #load the signal from the file\n    data_array = np.load(f'\/kaggle\/input\/g2net-gravitational-wave-detection\/train\/{filename[0]}\/{filename[1]}\/{filename[2]}\/{filename}.npy')\n    #resample\n    data_array = resample_poly(data_array, 1, resampling_frac,axis=-1, window=firwin(7, cutoff=20,pass_zero='highpass', fs=test_ts.shape[1]\/2))\n    \n    #idk we have to pull this hack cuz the data array was strided, which is not supported by shared c types...\n    non_strided = np.ones_like(data_array)\n    non_strided[:,:] = data_array\n    \n    #put into into the target array\n    data_array = np.ctypeslib.as_ctypes(non_strided)\n    target_array[i] = data_array","0957807f":"#load them with multiprocessing\nidxs = np.arange(no_spectral_samples)\npool = Pool(processes=4)\n\na= pool.map(gather_raw_samples, idxs, chunksize=1024)","ac190243":"target_array = np.ctypeslib.as_array(target_array)\ngc.collect()\n\ntarget_array.shape","8bc358eb":"signal_timesteps = target_array.shape[2]\nsampling_freq = signal_timesteps\/2\n\nNfft = signal_timesteps\ntukey_window = windows.tukey(Nfft, alpha=0.25)\n\n\nPxx0, freqs0 = mlab.psd(target_array[:,0,:].reshape(target_array.shape[0]*target_array.shape[2]),Fs=sampling_freq, NFFT=Nfft, window=tukey_window)\nPxx1, freqs1 = mlab.psd(target_array[:,1,:].reshape(target_array.shape[0]*target_array.shape[2]),Fs=sampling_freq, NFFT=Nfft, window=tukey_window)\nPxx2, freqs2 = mlab.psd(target_array[:,2,:].reshape(target_array.shape[0]*target_array.shape[2]),Fs=sampling_freq, NFFT=Nfft, window=tukey_window)\n","c996ea55":"from scipy.interpolate import interp1d\npsd_0 = interp1d(freqs0, Pxx0)\npsd_1 = interp1d(freqs1, Pxx1)\npsd_2 = interp1d(freqs2, Pxx2)","781bf869":"f_min = 20.\nf_max = 2000\n\nfig, ax= plt.subplots(nrows=2, ncols=3, figsize=(16,9))\n\nax[0][0].loglog(freqs0, np.sqrt(Pxx0), label='raw', alpha=0.7)\nax[0][0].axis([f_min, f_max, 4e-24, 1e-22])\n\nax[0][1].loglog(freqs1, np.sqrt(Pxx1), label='raw', alpha=0.7)\nax[0][1].axis([f_min, f_max, 4e-24, 1e-22])\n\nax[0][2].loglog(freqs2, np.sqrt(Pxx2), label='raw', alpha=0.7)\nax[0][2].axis([f_min, f_max, 4e-24, 1e-22])\n\nf_min = 20.\nf_max = 300\n\nax[1][0].loglog(freqs0, np.sqrt(Pxx0), label='raw', alpha=0.7, basex=2)\nax[1][0].axis([f_min, f_max, 4e-24, 1e-22])\n\nax[1][1].loglog(freqs1, np.sqrt(Pxx1), label='raw', alpha=0.7, basex=2)\nax[1][1].axis([f_min, f_max, 4e-24, 1e-22])\n\nax[1][2].loglog(freqs2, np.sqrt(Pxx2), label='raw', alpha=0.7, basex=2)\nax[1][2].axis([f_min, f_max, 4e-24, 1e-22])\n\n\n\nplt.show()","70f001e6":"from scipy.interpolate import interp1d\nfrom scipy.signal import savgol_filter,butter, sosfilt\n\n#lets test it with a single signal\n\n#some parameters:\nresampling_frac = 3\nband = [35,340]\n\n#resample\nresample_test = resample_poly(test_ts, 1, resampling_frac,axis=-1, window=firwin(5, cutoff=20,pass_zero='highpass', fs=test_ts.shape[1]\/2))\n\nresampled_steps = resample_test.shape[-1]\nresampled_sampling_freq = 2\/resampled_steps\n\n#do the fft\nfft_test = np.fft.rfft(resample_test)\n\n#record the frequencies of the decomposition\nwhitening_fft_freqs = np.fft.rfftfreq(resampled_steps, resampled_sampling_freq)\n\nwhitener = np.zeros((3,fft_test.shape[1]))\nwhitener[:,:] = 1.\/np.sqrt(1.\/(resampled_sampling_freq*2))\n\nspectrum_0 = psd_0(whitening_fft_freqs)\nspectrum_1 = psd_1(whitening_fft_freqs)\nspectrum_2 = psd_2(whitening_fft_freqs)\n\nwhitener[0,:] \/= np.sqrt(spectrum_0)\nwhitener[1,:] \/= np.sqrt(spectrum_1)\nwhitener[2,:] \/= np.sqrt(spectrum_2)\n\n\n#whiten the test\nwhitened_test = fft_test * whitener\nwhitened_signal = np.fft.irfft(whitened_test)\n\n#filter\nsos = butter(4, band, btype='band', output='sos', fs=whitened_signal.shape[1]\/2)\nfiltered_signal = sosfilt( sos, whitened_signal)\n\n","e691f1c5":"\nfig, ax = plt.subplots(nrows=4, ncols=1, figsize=[22,14])\n\nax[0].set_title(f'Original Signal')\nax[0].plot(test_ts[0].T, alpha=0.3)\n\nax[1].set_title(f'Resampled and Filtered')\nax[1].plot(resample_test[0].T, alpha=1, linewidth=0.5)\n\nax[2].set_title(f'Whitened')\nax[2].plot(whitened_signal[0].T, alpha=1, linewidth=0.5)\n\nax[3].set_title(f'Bandpassed')\nax[3].plot(filtered_signal[0].T, alpha=1, linewidth=0.5)\n\nplt.show()\n","ba82e558":"#Now apply all of this processing to the entire dataset\n\n#generate a results array\ntarget_array = np.zeros((no_samples, 3, resample_test.shape[1]), dtype=np.float32)\nprint(f'Target-Array-Size: {(target_array.size * target_array.itemsize)\/(1024**3)}')\n\ntarget_array = np.ctypeslib.as_ctypes(target_array)\ntarget_array = sharedctypes.RawArray(target_array._type_, target_array)\n","616dabac":"gc.collect()","9ec07c3a":"# a function that takes an index in training_df and does all the processing\n\ndef whiten_signal(i):\n    \n    #load the signal\n    filename = training_df['id'][i]\n    data_array = np.load(f'\/kaggle\/input\/g2net-gravitational-wave-detection\/train\/{filename[0]}\/{filename[1]}\/{filename[2]}\/{filename}.npy')\n    \n    #resample\n    data_array = resample_poly(data_array, 1, resampling_frac,axis=-1, window=firwin(7, cutoff=20,pass_zero='highpass', fs=test_ts.shape[1]))\n    \n    #rfft\n    fft_data = np.fft.rfft(data_array)\n    \n    #whiten\n    fft_data *= whitener\n    \n    #inverse fft\n    data_array = np.fft.irfft(fft_data).real.astype(np.float32)\n    \n    #filter again\n    data_array = sosfilt(sos, data_array).astype(np.float32)\n\n    #write into the results\n    data_array = np.ctypeslib.as_ctypes(data_array)\n    target_array[i] = data_array","0504993f":"#prepare multiprocessing\nidxs = np.arange(no_samples)\npool = Pool(processes=3)","e204d84b":"#this takes about half an hour\na= pool.map(whiten_signal, idxs, chunksize=1024)","7c9471bb":"gc.collect()","918ef875":"# save it to disk after all the work\ntarget_array = np.ctypeslib.as_array(target_array)\ngc.collect()\n\nnp.save('cleared_signals.npy', target_array)","9f004d29":"plt.plot(target_array[0].T, alpha=0.3)\nplt.show()\nplt.plot(target_array[100000].T, alpha=0.3)\nplt.show()\nplt.plot(target_array[500000].T, alpha=0.3)\nplt.show()\n","10f59ffc":"test_samples = 10000\n\nNfft = target_array.shape[2]\nsampling_freq = 2\/Nfft\ntukey_window = windows.tukey(Nfft)\n\nPxx0, freqs0 = mlab.psd(target_array[:test_samples,0,:].reshape(test_samples*target_array.shape[2]),Fs=sampling_freq, NFFT=Nfft, window=tukey_window)\nPxx1, freqs1 = mlab.psd(target_array[:test_samples,1,:].reshape(test_samples*target_array.shape[2]),Fs=sampling_freq, NFFT=Nfft, window=tukey_window)\nPxx2, freqs2 = mlab.psd(target_array[:test_samples,2,:].reshape(test_samples*target_array.shape[2]),Fs=sampling_freq, NFFT=Nfft, window=tukey_window)\n","b0f9067b":"f_min = 20.\nf_max = 2000\n\nfig, ax= plt.subplots(nrows=2, ncols=3, figsize=(16,9))\n\nax[0][0].loglog(freqs0, np.sqrt(Pxx0), label='raw', alpha=0.7)\nax[0][0].axis([f_min, f_max, 4e-24, 1e-22])\n\nax[0][1].loglog(freqs1, np.sqrt(Pxx1), label='raw', alpha=0.7)\nax[0][1].axis([f_min, f_max, 4e-24, 1e-22])\n\nax[0][2].loglog(freqs2, np.sqrt(Pxx2), label='raw', alpha=0.7)\nax[0][2].axis([f_min, f_max, 4e-24, 1e-22])\n\nf_min = 20.\nf_max = 300\n\nax[1][0].loglog(freqs0, np.sqrt(Pxx0), label='raw', alpha=0.7, basex=2)\nax[1][0].axis([f_min, f_max, 4e-24, 1e-22])\n\nax[1][1].loglog(freqs1, np.sqrt(Pxx1), label='raw', alpha=0.7, basex=2)\nax[1][1].axis([f_min, f_max, 4e-24, 1e-22])\n\nax[1][2].loglog(freqs2, np.sqrt(Pxx2), label='raw', alpha=0.7, basex=2)\nax[1][2].axis([f_min, f_max, 4e-24, 1e-22])\n\n\n\nplt.show()","2122a506":"# Signal Whitening\n## Intro\nObviously, their Detector mostly measures Noise from all sorts of sources. Who knows. However, we are not intrested in all the noise that's constantly going through the detector, we are intrested in very special events that happen rarely. A good way to downweigh the Noise is through a spectral analysis. Basically, we are going to perform a Fourier Transformation\/Analysis to record the frequency of occurence of signals with different frequencies.  Then, we are going to downway the more common frequencies by 'making them more silent' and make all the frequencies equally likely to occur (ie Gaussian with mean = 0 and std=1). This way, if something relevant happens, we can easily see an irregular spike in the different frequencies and make signals much more easy to detect.\nImagine a Picture taken through a red window. Obviously, the picture is going to contain to much red and if we are looking for the stuff behind the window, we are going to downway the red pixels and make them less bright to be able to see more detail in the 'signal' behind the widow.","54be6bcd":"Once again, I'm really not sure, if everything went well. Please let me know, if you find an error.","8d3a983b":"### Results\nThe red crosses are the different values for the frequencies while red line is just a simple moving average of them","15c62c32":"## Revisit the average power spectrograms in Order to find out if we have been successful.","aadb86ab":"Yess, we have converted all the signals to these weird looking signals.","98fdaab9":"### Whitening of the Signal\nThe Preprocessing that we are going to do is fairly simple: Resample the signal down, apply a tukey filter, decompose the signal using a fft, downweigh the common frequencies according to the spectrum and reconstruct the timeseries using an inverse Fourier transform. Then, apply a bandpass filter so we are just going to keep frequencies between 35 and 350 Hz (which, apparently are the only relevant signals).","58e44dad":"# Signal Preprocessing: Whitening + Bandpass Filter\n### Introduction\nWelcome to my Signal Preprocessing Notebook. The point of this notebook is to get the signal preprocessing out of the way and arrive at a usable big array containing all the preprocessed signals in this Competition. Since I\u00b4m not so experienced, please let me know about possible improvements and errors, which need to be fixed.  \n\nSo: What are we going to do? Basically, we\u00b4re trying to remove the brunt of noise and downsample the 70gb of data to make all of the information usable.  \nIn Terms of preprocessing we\u00b4re trying to follow this publication about signal preprocessing at the LIGO and VIRGO observatories: https:\/\/iopscience.iop.org\/article\/10.1088\/1361-6382\/ab685e (Chapter 3 & 4).  \nIn Short, they downsample their data (with a high pass filter at 20Hz), then whiten their Signal and bandpass filter to get most stuff away except for the relevant irregularities between 35 and 350 Hz.  \nHuge Shoutout to https:\/\/www.kaggle.com\/allunia for her work.","64cc5854":"## Implementation\n### Recording the Spectrum\nWe need to record the spectrum of the Data first, so we loaded a fraction of 50000 samples from their files, downsampled them with a highpass filter at 20Hz and now we're going to perform a fourier transformation of all signals. Because Fourier Analysis has problems with the shap edges of a signal we are going to apply a tukey filter, which is going to let the signals to a cosine decay at the ends. Then the ends are padded with zeros and the FFT (Fast Fourier Transform) is applied.  \nWe will get the weighing factors for certain frequencies in the sample and average over all the samples to get the power spectrum.","f50dab9d":"### This is a sample in the same range as the upper plot\n![grafik.png](attachment:a5e06307-26ce-4aa9-8675-82d1f2543811.png)\n\nThis is a sample from the authors of the paper (in the range of the lower plot, which is the most important).  \n![grafik.png](attachment:072ed55f-f4b2-4b10-9105-118fa1394a37.png)\n\nThese look really quite similar, but if you have any idea wher there is room for improvement let me know!"}}