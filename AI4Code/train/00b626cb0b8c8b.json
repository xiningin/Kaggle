{"cell_type":{"d1c11cf8":"code","71eb330c":"code","55774f8c":"code","1210a9ec":"code","875fbde8":"code","546293a2":"code","8aa67c07":"code","41a456ee":"code","7d0cf82e":"code","b7501e07":"code","9cd612b8":"markdown","30a81ada":"markdown","8afcb029":"markdown"},"source":{"d1c11cf8":"import pandas as pd\nimport numpy as np\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, cross_val_score, train_test_split, KFold\nimport tensorflow as tf","71eb330c":"csv_train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2022\/train.csv')\ncsv_test = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2022\/test.csv')\ncsv_submission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-feb-2022\/sample_submission.csv')\n\nlbl_coder = LabelEncoder()\nlbl_coder.fit(csv_train.target)\n\ncsv_train['target'] = lbl_coder.transform(csv_train.target)","55774f8c":"feature_columns = {x for x in csv_train.columns}.difference({'row_id', 'target'})\ntarget = 'target'","1210a9ec":"hists = []\nfor i, (train_idx, val_idx) in enumerate(KFold().split(csv_train)):\n    print(f'Fold #{i}')\n    _csv_train = csv_train.iloc[train_idx]\n    _csv_val = csv_train.iloc[val_idx]\n    \n    model = tf.keras.models.Sequential([\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(32, activation='relu' ),\n        tf.keras.layers.Dense(32, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(16, activation='relu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dense(10, activation='softmax'),\n    ])\n\n    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.005), loss=tf.keras.losses.CategoricalCrossentropy(), metrics=[tf.keras.metrics.CategoricalAccuracy()])\n\n    x = _csv_train[feature_columns].to_numpy()\n    y = tf.one_hot(_csv_train[target], 10)\n\n    x_val = _csv_val[feature_columns].to_numpy()\n    y_val = tf.one_hot(_csv_val[target], 10)\n\n    save_cb = tf.keras.callbacks.ModelCheckpoint(f'.\/best_val_{i}', save_best_only=True, monitor='val_loss', save_weights_only=True)\n\n    class LearningRateReducerCb(tf.keras.callbacks.Callback):\n        def on_epoch_end(self, epoch, logs={}):\n            old_lr = self.model.optimizer.lr.read_value()\n            new_lr = old_lr * 0.99\n            self.model.optimizer.lr.assign(new_lr)\n\n    h = model.fit(x, y, validation_data=(x_val, y_val), epochs=20, batch_size=256, verbose=0, callbacks=[save_cb, LearningRateReducerCb()])\n    hists.append(h)","875fbde8":"scores = []\n\nsplits = list(KFold().split(csv_train))\n\nfor i in range(5):\n    model.load_weights(f'.\/best_val_{i}')\n    val_idx = splits[i][1]\n    \n    _csv_val = csv_train.iloc[val_idx]\n    \n    x_val = _csv_val[feature_columns].to_numpy()\n    y_val = tf.one_hot(_csv_val[target], 10)\n    \n    acc = model.evaluate(x_val, y_val)[1]\n    scores.append(acc)\n    \nprint(f'CV score: {np.mean(scores)}')","546293a2":"predictions = []\nfor i in range(5):\n    model.load_weights(f'.\/best_val_{i}')\n    test_pred = np.argmax(model.predict(csv_test[feature_columns]), axis=-1)\n    predictions.append(test_pred)","8aa67c07":"from collections import Counter\n \ndef most_frequent(List):\n    occurence_count = Counter(List)\n    return occurence_count.most_common(1)[0][0]","41a456ee":"pred_matrix = np.stack(predictions)","7d0cf82e":"pred_maj = []\n\nfor i in range(pred_matrix.shape[1]):\n    pred_maj.append(most_frequent(pred_matrix[:, i]))","b7501e07":"test_pred_str = lbl_coder.inverse_transform(pred_maj)\ncsv_submission['target'] = test_pred_str\ncsv_submission.to_csv('.\/submission.csv', index=False)","9cd612b8":"# Basic model baseline","30a81ada":"# Load dataset","8afcb029":"# Define feature columns\n\nIt would be easy to slice input features and targets using predefined column names. Even more - we are aware of column positions by accesing features by column names"}}