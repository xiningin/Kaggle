{"cell_type":{"95e557ea":"code","ca9cd596":"code","cb9f6a9a":"code","01cdb7c7":"code","28c677f2":"code","c838cfae":"code","e57ccb95":"code","7f31c6d8":"code","3af5f45a":"code","09c30992":"code","db7da8c6":"code","59e79734":"code","5e1dbd80":"code","d8ead745":"markdown"},"source":{"95e557ea":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ca9cd596":"import pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.metrics import log_loss, roc_auc_score\n\nimport re\nimport sklearn\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom sklearn.svm import SVC, NuSVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.gaussian_process.kernels import RBF\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import neural_network\n\nfrom sklearn.calibration import CalibratedClassifierCV\nimport gc","cb9f6a9a":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline","01cdb7c7":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import roc_auc_score, log_loss\nfrom scipy.sparse import coo_matrix, vstack, hstack","28c677f2":"def predict_one_class_tf(tfidfed, tfidfed_test, y, model, n_splits=5):\n    \n    skf = StratifiedKFold(n_splits=n_splits, shuffle=True, random_state=42)\n#    skf = StratifiedShuffleSplit(n_splits=n_splits, random_state=42, train_size=0.8, test_size=0.2)\n    to_check = train.copy()\n    to_check[f'predict_proba'] = np.zeros(to_check.shape[0])\n    pred = np.zeros(len(test))\n    metrics = []\n    \n    for i, (train_index, valid_index) in enumerate(skf.split(tfidfed, y)):\n        print(f'fold_{i}')\n        \n        X_train = tfidfed[train_index]\n\n    \n        y_train = list(y.loc[train_index])\n\n        \n        X_valid = tfidfed[valid_index]\n        y_valid = list(y.loc[valid_index])\n        \n        \n        \n        best_model_skf = model\n#        best_model_skf = LogisticRegression(**params)\n        \n        best_model_skf.fit(\n       X_train, y_train,\n    #   cat_features=new_cat_features,\n    #   verbose=False,\n    #   eval_set=(X_valid, y_valid),\n    #   logging_level='Silent',\n    #   plot=plot\n        )\n        \n        prediction_skf = best_model_skf.predict_proba(tfidfed_test)[:,1]\n        pred += prediction_skf \/ skf.n_splits  \n        \n        prediction = best_model_skf.predict_proba(X_valid)[:,1]\n        to_check.loc[valid_index, f'predict_proba'] = prediction\n        print(f'log_loss_{i}: {log_loss(y_valid, prediction)}')\n        metrics.append(log_loss(y_valid, prediction))\n        \n        print()\n        print('_' * 100)\n        print()\n    \n    local_logloss = log_loss(y, to_check[f'predict_proba'])\n    print(f\"log_loss_oof: {local_logloss}\")\n    print(f\"log_loss_mean: {np.mean(metrics)}\")\n    print(f\"metric_std: {np.std(metrics, dtype=np.float64)}\")\n    \n    print(f\"AUC_oof: {roc_auc_score(y, to_check[f'predict_proba'])}\")\n    \n    print()\n    print('*' * 100)\n    print()\n    \n    return pred, local_logloss, to_check","c838cfae":"sample_sub = pd.read_csv('\/kaggle\/input\/made-ml-2019-hw1\/products_sentiment_sample_submission.csv')\ntrain = pd.read_csv('\/kaggle\/input\/made-ml-2019-hw1\/products_sentiment_train.tsv', sep='\\t', header=None)\ntrain.columns = ['text', 'y']\ntest = pd.read_csv('\/kaggle\/input\/made-ml-2019-hw1\/products_sentiment_test.tsv', sep='\\t')\ntest = test.drop(['Id'], axis=1)\ntest['y'] = -1\ntest.columns = train.columns\n\ntraintest = pd.concat([train, test]).reset_index(drop=True)","e57ccb95":"traintest.head()","7f31c6d8":"params = {\n    \"count_vectorizer_params\": \n    {\n       # \"max_df\": 1000,\n        \"ngram_range\": [3, 10],\n        'min_df': 1,\n        'binary': False,\n        'analyzer': 'char',\n        'lowercase': True,\n      #  'max_features': 3000\n      #  'stop_words': 'english',\n        \n    }, \n    \"tfidf_transformer_params\": {\n        'norm': 'l2',\n        'use_idf': True,\n        'smooth_idf': False,\n        'sublinear_tf': True\n    }, \n    \"logistic_regression_params\": {\n        \"random_state\": 1337,\n        \"penalty\": \"l2\",\n        \"C\": 4.65,\n        'max_iter': 100,\n        'class_weight': 'balanced',\n        'solver': 'liblinear',\n        'multi_class': 'ovr',\n     #   'n_jobs': -1\n    }\n}","3af5f45a":"%%time\n\nvectorizer_no_stop_train_test = CountVectorizer(**params['count_vectorizer_params'])\n\nword_count_vector_no_stop_train_test = vectorizer_no_stop_train_test.fit_transform(traintest['text'])\n\ntfidf_no_stop_train_test = TfidfTransformer(**params['tfidf_transformer_params'])\n\ntfidfed_no_stop_train_test = tfidf_no_stop_train_test.fit_transform(word_count_vector_no_stop_train_test)","09c30992":"model_lr = LogisticRegression(**params['logistic_regression_params'])\nclf_isotonic = CalibratedClassifierCV(model_lr, cv=10, method='isotonic')\nclf_sigmoid = CalibratedClassifierCV(model_lr, cv=10, method='sigmoid')","db7da8c6":"%%time\n\npred_tf_no_stop, local_logloss_tf_no_stop, to_check_tf_no_stop = predict_one_class_tf(tfidfed_no_stop_train_test[:len(train)], tfidfed_no_stop_train_test[len(train):], train['y'], model_lr, n_splits=10)","59e79734":"%%time\n\npred_tf_no_stop, local_logloss_tf_no_stop, to_check_tf_no_stop = predict_one_class_tf(tfidfed_no_stop_train_test[:len(train)], tfidfed_no_stop_train_test[len(train):], train['y'], clf_sigmoid, n_splits=10)","5e1dbd80":"sub = sample_sub.copy()\nsub['y'] = pred_tf_no_stop\nsub.to_csv('lr_3-10_char_check_10splits_everywhere.csv', index=False)","d8ead745":"\u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043b\u044f \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f \u043d\u0430 \u0442\u0435\u0441\u0442:"}}