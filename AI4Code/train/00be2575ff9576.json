{"cell_type":{"d18914c5":"code","ce3d6881":"code","3b62ab65":"code","c09b1f99":"code","1011daed":"code","1de7a750":"code","71dd8876":"code","2ad68327":"code","3ca8d977":"code","4ec354e2":"code","07e64ed3":"code","b6c10da4":"code","555b984a":"code","462bf313":"code","542ea16c":"code","4d639cab":"code","f11a03f1":"code","4fb1cbfa":"code","c20baa13":"code","fe00e5ac":"code","27c25d79":"code","1021efc2":"code","d8b7f816":"code","ded5579d":"code","ffc14480":"code","9e949ba0":"code","1cde1947":"code","1d3f34e5":"code","7cbe46dc":"code","1ac13729":"code","c10c4ca7":"code","cd64ccfa":"code","3c48f456":"code","8d3feb52":"code","5e10e60f":"code","8fd46f72":"code","ebd85e9e":"code","196057a7":"code","82b5e62c":"code","27b28477":"code","ebbe0bb4":"code","6c85b082":"code","57ce4d9d":"code","1ce5436f":"code","3429170b":"code","bb98689d":"code","f6e18c37":"code","f4d39328":"code","07b9cdbf":"code","5db4a273":"code","89adc286":"code","a7c86ad6":"code","0ec975cd":"code","9f7d42d3":"code","5293eb06":"code","2f1892ed":"code","ae27d390":"code","782d3b42":"code","7166c50f":"code","01518356":"code","0a17f953":"code","6772d503":"code","8931a3e9":"code","5a27ec6a":"code","e504d8f1":"code","dc312a2a":"code","6130b4b6":"code","cc274bcf":"code","2efb8ab9":"code","cb34b587":"code","9e4fe4a3":"code","8c19db24":"code","2e75b942":"code","0d1ad73b":"code","8a14b6d3":"code","64d2b1f1":"code","50cfc19b":"code","7d863338":"code","f76c02e4":"code","acaec941":"code","2c36eadb":"markdown","c06ad945":"markdown","9c50ee81":"markdown","f1942a9c":"markdown","d5c058e0":"markdown","9c88c3f5":"markdown","a7573eb7":"markdown","40a36a7b":"markdown","5740f491":"markdown","aa14479b":"markdown","eb9f8adb":"markdown","c6ea0af2":"markdown","8ecf8f3c":"markdown"},"source":{"d18914c5":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport sys\nimport time\nimport copy\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torchvision import models\nfrom torch.utils.data import Dataset, random_split, DataLoader","ce3d6881":"batch_size = 64\nn_iters = 30\nepochs  = 10#int( n_iters \/ (len(train_dl) \/ batch_size))\ninput_dim = 784\noutput_dim = 10\nlr_rate  = 0.001","3b62ab65":"def get_default_device():\n    \"\"\"Pick GPU if available, else CPU\"\"\"\n    if torch.cuda.is_available():\n        return torch.device('cuda')\n    else:\n        return torch.device('cpu')\n    \ndef to_device(data, device):\n    \"\"\"Move tensor(s) to chosen device\"\"\"\n    if isinstance(data, (list,tuple)):\n        return [to_device(x, device) for x in data]\n    return data.to(device, non_blocking=True)\n\nclass DeviceDataLoader():\n    \"\"\"Wrap a dataloader to move data to a device\"\"\"\n    def __init__(self, dl, device):\n        self.dl = dl\n        self.device = device\n        \n    def __iter__(self):\n        \"\"\"Yield a batch of data after moving it to device\"\"\"\n        for b in self.dl: \n            yield to_device(b, self.device)\n\n    def __len__(self):\n        \"\"\"Number of batches\"\"\"\n        return len(self.dl)","c09b1f99":"device = get_default_device()\ndevice","1011daed":"from torchvision.utils import make_grid\n\ndef show_batch(dl):\n    for images, labels in dl:\n        fig, ax = plt.subplots(figsize=(12, 6))\n        ax.set_xticks([]); ax.set_yticks([])\n        ax.imshow(make_grid(images, nrow=16).permute(1, 2, 0))\n        break","1de7a750":"transform = transforms.Compose(\n    [transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))]\n)\n\n\ntrainset = torchvision.datasets.ImageFolder(root=\"\/kaggle\/input\/100-bird-species\/train\/\", transform=transform)\ntrain_dl = DataLoader(trainset, batch_size=batch_size, num_workers=3, shuffle=True)\n\ntestset = torchvision.datasets.ImageFolder(root=\"\/kaggle\/input\/100-bird-species\/test\/\", transform=transform)\nval_dl = DataLoader(testset, batch_size=batch_size, num_workers=3, shuffle=False)\n\ndataloaders = {\n    \"train\": train_dl,\n    \"test\": val_dl\n}\ndatasizes = {\n    \"train\": len(trainset),\n    \"test\": len(testset)\n}\nCLASSES = list(trainset.class_to_idx.keys())","71dd8876":"##we are creating the dataset without transform\n\ntransform = transforms.Compose(\n    [transforms.ToTensor(),\n#     transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n    ]\n)\n\n\ntrainset_no_t = torchvision.datasets.ImageFolder(root=\"\/kaggle\/input\/100-bird-species\/train\/\", transform=transform) \ntrain_dl_no_t = DataLoader(trainset_no_t, batch_size=batch_size, num_workers=3, shuffle=True)\n\ntestset_no_t = torchvision.datasets.ImageFolder(root=\"\/kaggle\/input\/100-bird-species\/test\/\", transform=transform)\nval_dl_no_t = DataLoader(testset_no_t, batch_size=batch_size, num_workers=3, shuffle=False)\n\ndataloaders_no_t = {\n    \"train\": trainset_no_t,\n    \"test\": val_dl_no_t\n}\ndatasizes_no_t = {\n    \"train\": len(trainset_no_t),\n    \"test\": len(train_dl_no_t)\n}\nCLASSES = list(trainset.class_to_idx.keys())","2ad68327":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs');","3ca8d977":"def plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs');","4ec354e2":"def accuracy(outputs, labels):\n    _, preds = torch.max(outputs, dim=1)\n    return torch.tensor(torch.sum(preds == labels).item() \/ len(preds))\n\nclass ImageClassificationBase(nn.Module):\n    def training_step(self, batch):\n        images, labels = batch \n        out = self(images)                  # Generate predictions\n        loss = F.cross_entropy(out, labels) # Calculate loss\n        return loss\n    \n    def validation_step(self, batch):\n        images, labels = batch \n        out = self(images)                    # Generate predictions\n        loss = F.cross_entropy(out, labels)   # Calculate loss\n        acc = accuracy(out, labels)           # Calculate accuracy\n        return {'val_loss': loss.detach(), 'val_acc': acc}\n        \n    def validation_epoch_end(self, outputs):\n        batch_losses = [x['val_loss'] for x in outputs]\n        epoch_loss = torch.stack(batch_losses).mean()   # Combine losses\n        batch_accs = [x['val_acc'] for x in outputs]\n        epoch_acc = torch.stack(batch_accs).mean()      # Combine accuracies\n        return {'val_loss': epoch_loss.item(), 'val_acc': epoch_acc.item()}\n    \n    def epoch_end(self, epoch, result):\n        print(\"Epoch [{}], train_loss: {:.4f}, val_loss: {:.4f}, val_acc: {:.4f}\".format(\n            epoch, result['train_loss'], result['val_loss'], result['val_acc']))","07e64ed3":"class BirdClassifierCnnModel(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(3, 12, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(12, 32, 5)\n        self.fc1 = nn.Linear(32*53*53, 512)\n        self.fc3 = nn.Linear(512, len(CLASSES))\n        \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n        x = x.view(-1, 32*53*53)\n        x = F.relu(self.fc1(x))\n        x = self.fc3(x)\n        return x","b6c10da4":"##data without normalization\nshow_batch(train_dl_no_t)","555b984a":"##data with normalization\nshow_batch(train_dl)","462bf313":"model = BirdClassifierCnnModel()\nmodel","542ea16c":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef fit(epochs, lr, model, train_loader, val_loader, opt_func=torch.optim.SGD):\n    history = []\n    optimizer = opt_func(model.parameters(), lr)\n    for epoch in tqdm(range(epochs)):\n        # Training Phase \n        model.train()\n        train_losses = []\n        for batch in train_loader:\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['model'] = 'CNN-model'\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","4d639cab":"opt_func = torch.optim.Adam\nlr = 0.001","f11a03f1":"train_dl_no_t = DeviceDataLoader(train_dl_no_t, device)\nval_dl_no_t = DeviceDataLoader(val_dl_no_t, device)\nto_device(model, device);","4fb1cbfa":"evaluate(model, val_dl_no_t)","c20baa13":"%%time\nhistory = fit(epochs, lr, model, train_dl_no_t, val_dl_no_t, opt_func)","fe00e5ac":"plot_accuracies(history)","27c25d79":"plot_losses(history)","1021efc2":"!pip install jovian --upgrade --quiet","d8b7f816":"import jovian","ded5579d":"hyperparams = {\n    'arch_name': 'cnn',\n    'Wall time': '11 min',\n    'lr': lr,\n    'batch_size' : 64,\n    'n_iters': 30,\n    'epochs' : 10,#int( n_iters \/ (len(train_dl) \/ batch_size))\n    'input_dim' : 784,\n    'output_dim' : 10\n}\njovian.log_hyperparams(hyperparams)","ffc14480":"##save the metrics\n# epoch_count = 0\n# for h in history:\n#     h['epoch'] = epoch_count\n#     jovian.log_metrics(h)\n#     epoch_count+=1","9e949ba0":"h = history[-1]\nprint(h)","1cde1947":"jovian.log_metrics(h)","1d3f34e5":"jovian.commit(project='bird-classifier', environment=None)","7cbe46dc":"train_dl = DeviceDataLoader(train_dl, device)\nval_dl = DeviceDataLoader(val_dl, device)\nto_device(model, device);","1ac13729":"evaluate(model, val_dl)","c10c4ca7":"%%time\nhistory = fit(epochs, lr, model, train_dl, val_dl, opt_func)","cd64ccfa":"plot_accuracies(history)","3c48f456":"plot_losses(history)","8d3feb52":"hyperparams = {\n    'arch_name': 'cnn_with_data_normalization',\n    'Wall time': '12min',\n    'lr': lr,\n    'batch_size' : 64,\n    'epochs' : 10,#int( n_iters \/ (len(train_dl) \/ batch_size))\n    'input_dim' : 784,\n    'output_dim' : 10\n}\njovian.log_hyperparams(hyperparams)","5e10e60f":"##save the metrics\n# epoch_count = 0\n# for h in history:\n#     h['epoch'] = epoch_count\n#     h['model'] = 'cnn_with_data_normalization'\n#     jovian.log_metrics(h)\n#     epoch_count+=1","8fd46f72":"h = history[-1]\nh['model'] = 'cnn_with_data_normalization'\nprint(h)","ebd85e9e":"jovian.log_metrics(h)","196057a7":"jovian.commit(project='bird-classifier', environment=None)","82b5e62c":"class PreTrainedClassifier(ImageClassificationBase):\n    def __init__(self):\n        super().__init__()\n        # Use a pretrained model\n        self.network = models.resnet34(pretrained=True)\n        # Replace last layer\n        num_ftrs = self.network.fc.in_features\n        self.network.fc = nn.Linear(num_ftrs, len(CLASSES))\n    \n    def forward(self, xb):\n        return torch.sigmoid(self.network(xb))\n    \n    def freeze(self):\n        # To freeze the residual layers\n        for param in self.network.parameters():\n            param.require_grad = False\n        for param in self.network.fc.parameters():\n            param.require_grad = True\n    \n    def unfreeze(self):\n        # Unfreeze all layers\n        for param in self.network.parameters():\n            param.require_grad = True","27b28477":"@torch.no_grad()\ndef evaluate(model, val_loader):\n    model.eval()\n    outputs = [model.validation_step(batch) for batch in val_loader]\n    return model.validation_epoch_end(outputs)\n\ndef get_lr(optimizer):\n    for param_group in optimizer.param_groups:\n        return param_group['lr']\n\ndef fit_one_cycle(epochs, max_lr, model, train_loader, val_loader, \n                  weight_decay=0, grad_clip=None, opt_func=torch.optim.SGD):\n    torch.cuda.empty_cache()\n    history = []\n    \n    # Set up cutom optimizer with weight decay\n    optimizer = opt_func(model.parameters(), max_lr, weight_decay=weight_decay)\n    # Set up one-cycle learning rate scheduler\n    sched = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr, epochs=epochs, \n                                                steps_per_epoch=len(train_loader))\n    \n    for epoch in range(epochs):\n        # Training Phase \n        model.train()\n        train_losses = []\n        lrs = []\n        for batch in tqdm(train_loader):\n            loss = model.training_step(batch)\n            train_losses.append(loss)\n            loss.backward()\n            \n            # Gradient clipping\n            if grad_clip: \n                nn.utils.clip_grad_value_(model.parameters(), grad_clip)\n            \n            optimizer.step()\n            optimizer.zero_grad()\n            \n            # Record & update learning rate\n            lrs.append(get_lr(optimizer))\n            sched.step()\n        \n        # Validation phase\n        result = evaluate(model, val_loader)\n        result['train_loss'] = torch.stack(train_losses).mean().item()\n        result['lrs'] = lrs\n        result['model'] = 'pre-trained-model'\n        model.epoch_end(epoch, result)\n        history.append(result)\n    return history","ebbe0bb4":"model = to_device(PreTrainedClassifier(), device)","6c85b082":"history = [evaluate(model, val_dl)]\nhistory","57ce4d9d":"model.freeze()","1ce5436f":"max_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","3429170b":"%%time\nhistory += fit_one_cycle(int(epochs\/2), max_lr, model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","bb98689d":"model.unfreeze()","f6e18c37":"%%time\nhistory += fit_one_cycle(int(epochs\/2), 0.001, model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","f4d39328":"plot_accuracies(history)","07b9cdbf":"plot_losses(history)","5db4a273":"hyperparams = {\n    'arch_name': 'cnn_with_pre_trained_models_and_varying_lr',\n    'Wall time': '15min',\n    'lr': lr,\n    'batch_size' : 64,\n    'epochs' : 10,#int( n_iters \/ (len(train_dl) \/ batch_size))\n    'input_dim' : 784,\n    'output_dim' : 10\n}\njovian.log_hyperparams(hyperparams)","89adc286":"h = history[-1]\nh['model'] = 'cnn_with_pre_trained_models_and_varying_lr'\n# print(h)","a7c86ad6":"jovian.log_metrics(h)","0ec975cd":"# ##save the metrics\n# epoch_count = 0\n# for h in history:\n#     h['model'] = 'cnn_with_pre_trained_models_and_varying_lr'\n#     jovian.log_metrics(h)\n#     epoch_count+=1","9f7d42d3":"jovian.commit(project='bird-classifier', environment=None)","5293eb06":"epochs = 20","2f1892ed":"%%time\nhistory = fit(epochs, lr, model, train_dl_no_t, val_dl_no_t, opt_func)","ae27d390":"plot_accuracies(history)","782d3b42":"plot_losses(history)","7166c50f":"hyperparams = {\n    'arch_name': 'cnn',\n    'Wall time': '20min',\n    'lr': lr,\n    'batch_size' : 64,\n    'epochs' : 20,#int( n_iters \/ (len(train_dl) \/ batch_size))\n    'input_dim' : 784,\n    'output_dim' : 10\n}\njovian.log_hyperparams(hyperparams)","01518356":"h = history[-1]\nh['model'] = 'cnn'\nprint(h)","0a17f953":"jovian.log_metrics(h)","6772d503":"jovian.commit(project='bird-classifier', environment=None)","8931a3e9":"%%time\nhistory = fit(epochs, lr, model, train_dl, val_dl, opt_func)","5a27ec6a":"plot_accuracies(history)","e504d8f1":"plot_losses(history)","dc312a2a":"hyperparams = {\n    'arch_name': 'cnn_with_data_normalization',\n    'Wall time': '17min',\n    'lr': lr,\n    'batch_size' : 64,\n    'epochs' : 20,#int( n_iters \/ (len(train_dl) \/ batch_size))\n    'input_dim' : 784,\n    'output_dim' : 10\n}\njovian.log_hyperparams(hyperparams)","6130b4b6":"h = history[-1]\nh['model'] = 'cnn_with_data_normalization'\nprint(h)","cc274bcf":"jovian.log_metrics(h)","2efb8ab9":"jovian.commit(project='bird-classifier', environment=None)","cb34b587":"model.freeze()","9e4fe4a3":"max_lr = 0.01\ngrad_clip = 0.1\nweight_decay = 1e-4\nopt_func = torch.optim.Adam","8c19db24":"%%time\nhistory += fit_one_cycle(int(epochs\/2), max_lr, model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","2e75b942":"model.unfreeze()","0d1ad73b":"%%time\nhistory += fit_one_cycle(int(epochs\/2), 0.001, model, train_dl, val_dl, \n                         grad_clip=grad_clip, \n                         weight_decay=weight_decay, \n                         opt_func=opt_func)","8a14b6d3":"plot_accuracies(history)","64d2b1f1":"plot_losses(history)","50cfc19b":"hyperparams = {\n    'arch_name': 'cnn_with_pre_trained_models_and_varying_lr',\n    'Wall time': '15min',\n    'lr': lr,\n    'batch_size' : 64,\n    'epochs' : 20,#int( n_iters \/ (len(train_dl) \/ batch_size))\n    'input_dim' : 784,\n    'output_dim' : 10\n}\njovian.log_hyperparams(hyperparams)","7d863338":"h = history[-1]\nh['model'] = 'cnn_with_pre_trained_models_and_varying_lr'\n# print(h)","f76c02e4":"jovian.log_metrics(h)","acaec941":"jovian.commit(project='bird-classifier', environment=None)","2c36eadb":"Data with Transformation","c06ad945":"## Train the data with transform","9c50ee81":"## Train the data without data transform","f1942a9c":"## Use Pre-trained model","d5c058e0":"### log the results to jovian","9c88c3f5":"As we can see, we did not get a good accuracy at all and will not get a good one from this model, because model is not upto the mark to do classification of 200 classes.\n\nSo we will use a pretrained model and edit its last fully connected layer and train ONLY that last layer.\nWe will use generic model training function form pytorch documentation (because its all we need, no changes at all)","a7573eb7":"## Simple classification using pytorch\n\nIn this notebook I will try to demonstate usage of pytorch for simple image classfication task. We will create a simple CNN and then try transfer learning using a pretrained model(ResNet18)\n\n","40a36a7b":"No Transformation","5740f491":"### log the results to jovian","aa14479b":"### Save the notebook","eb9f8adb":"Pre-trained models","c6ea0af2":"### Lets try with 20 epoch","8ecf8f3c":"### Pretrained Results\n\nIn only 4-5 epochs we crossed 94% accuracy , without even breaking a sweat.\nWe can improve it further by \n1. More data augmentation and transformation while loading like Rotating image randomly, or Cropped selection and Scaled to make model more scale and rotate invariant\n2. Fine tune model by playing with learning rate, and number of epochs\netc"}}