{"cell_type":{"a0aa3729":"code","da799163":"code","b7684c2d":"code","0d867767":"code","6bec96fa":"code","ddc40580":"code","51004367":"code","2779272d":"code","e4726267":"code","96cec9af":"code","97dee2d7":"code","b22a1a7f":"code","16644a14":"code","1939430b":"code","2a6444b6":"code","e45cc8a8":"code","72b35ce3":"code","6146b697":"code","31406e24":"code","f65b1297":"code","fa48a141":"code","c9e2feb4":"code","be84fa58":"code","20277919":"code","f6d127e9":"code","a3364858":"code","22750849":"code","72827700":"code","854b3745":"code","d856065f":"code","2bba5c66":"code","4830e453":"code","8df092f9":"code","ca1167d3":"code","24100454":"code","2d5342f0":"code","59a03ffd":"code","07266155":"code","f0afda97":"code","0fdc462e":"code","f9d37d7d":"code","f6a48d0d":"code","aced1daf":"code","28d5458c":"code","80c72b57":"code","56e70498":"markdown","3c70ab14":"markdown","d53b84df":"markdown","e7b83923":"markdown","49a167c3":"markdown","7551f0f2":"markdown","b30cb189":"markdown","589e63b2":"markdown","1eb53153":"markdown","3bdee92f":"markdown","93b56713":"markdown","80f06470":"markdown","fbdad44b":"markdown","925a527b":"markdown","3cc0bd37":"markdown","9f8f33b5":"markdown","d46357ef":"markdown","a360d2d9":"markdown","167cb886":"markdown","c3d99da8":"markdown","f05875dc":"markdown","60890c33":"markdown","63baa63e":"markdown","e666e5dd":"markdown","8f20ecea":"markdown","45acb0be":"markdown","77690123":"markdown","8355d85a":"markdown","2c341812":"markdown","476aa385":"markdown","30f5e9c0":"markdown","b7af83d6":"markdown","f32d55e4":"markdown","04540ecc":"markdown","f4b37443":"markdown","bbd8828d":"markdown","f0728f4f":"markdown","1cf8292b":"markdown","0b35cd77":"markdown","349e4e63":"markdown","9dcb791f":"markdown","9864a4f3":"markdown","0a9aa5b0":"markdown","e65c84b1":"markdown","9738a1bd":"markdown","c1278f9e":"markdown","241843cb":"markdown","9370f503":"markdown","0e5c1262":"markdown","b1caf9e0":"markdown","c9944162":"markdown","141019a3":"markdown","545ad649":"markdown","fa56eee0":"markdown"},"source":{"a0aa3729":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","da799163":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom scipy import stats\nfrom scipy.stats import norm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, r2_score\n\n# display settings\npd.set_option(\"display.max_rows\", None)\npd.set_option(\"display.max_columns\", None)\n\n# filter warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b7684c2d":"# reading from csv and creating dataframe\ndf = pd.read_csv(\"\/kaggle\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv\")","0d867767":"# dimensions of the dataframe\nprint(\"No. of rows: {}\\t\\tNo. of columns: {}\".format(*df.shape))","6bec96fa":"# columns info\ndf.info()","ddc40580":"# printing first 5 rows\ndf.head()","51004367":"# printing last 5 rows\ndf.tail()","2779272d":"# dropping the Serial No. column\ndf.drop(columns=['Serial No.'], inplace=True)","e4726267":"# descriptive statistics\ndf.describe().T","96cec9af":"# column names\nlist(df.columns)","97dee2d7":"# removing the trailing spaces in column names\ndf.rename(columns={'LOR ':'LOR',\n                  'Chance of Admit ':'Chance of Admit'}, inplace=True)","b22a1a7f":"# % of missing values in each column\n(df.isna().sum() \/ df.shape[0]) * 100","16644a14":"# observing for skew or non-linearness\nprint(\"Acceptable skew range -1 to 1:\", df['Chance of Admit'].skew())\n\n# deviation of data from normal distribution using QQ plot\nfig, ax = plt.subplots(1,2, figsize=(15,6))\n\nmu, sigma = norm.fit(df['Chance of Admit'])\nsns.distplot(df['Chance of Admit'], fit=norm, ax=ax[0])\nres = stats.probplot(df['Chance of Admit'], plot=ax[1])\nplt.show()","1939430b":"print(df['GRE Score'].describe())\n\nplt.subplots(1,2, figsize=(15,5))\n\n# checking for outliers\nplt.subplot(1,2,1)\nsns.boxplot(df['GRE Score'])\nplt.title(\"Boxplot to identify the outliers\")\n\n# checking the distribution\nplt.subplot(1,2,2)\nsns.distplot(df['GRE Score'])\nplt.title(\"Distplot to check the skewness\")\n\nplt.show()","2a6444b6":"print(df['TOEFL Score'].describe())\n\nplt.subplots(1,2, figsize=(15,5))\n\n# checking for outliers\nplt.subplot(1,2,1)\nsns.boxplot(df['TOEFL Score'])\nplt.title(\"Boxplot to identify the outliers\")\n\n# checking the distribution\nplt.subplot(1,2,2)\nsns.distplot(df['TOEFL Score'])\nplt.title(\"Distplot to check the skewness\")\n\nplt.show()","e45cc8a8":"print(df['University Rating'].describe())\n\nplt.subplots(1,2, figsize=(15,5))\n\n# checking for outliers\nplt.subplot(1,2,1)\nsns.boxplot(df['University Rating'])\nplt.title(\"Boxplot to identify the outliers\")\n\n# checking the distribution\nplt.subplot(1,2,2)\nsns.distplot(df['University Rating'])\nplt.title(\"Distplot to check the skewness\")\n\nplt.show()","72b35ce3":"print(df['SOP'].describe())\n\nplt.subplots(1,2, figsize=(15,5))\n\n# checking for outliers\nplt.subplot(1,2,1)\nsns.boxplot(df['SOP'])\nplt.title(\"Boxplot to identify the outliers\")\n\n# checking the distribution\nplt.subplot(1,2,2)\nsns.distplot(df['SOP'])\nplt.title(\"Distplot to check the skewness\")\n\nplt.show()","6146b697":"print(df['LOR'].describe())\n\nplt.subplots(1,2, figsize=(15,5))\n\n# checking for outliers\nplt.subplot(1,2,1)\nsns.boxplot(df['LOR'])\nplt.title(\"Boxplot to identify the outliers\")\n\n# checking the distribution\nplt.subplot(1,2,2)\nsns.distplot(df['LOR'])\nplt.title(\"Distplot to check the skewness\")\n\nplt.show()","31406e24":"# removing outliers\nQ1 = df['LOR'].quantile(0.25); Q3 = df['LOR'].quantile(0.75); IQR = Q3 - Q1\ndf['LOR'].loc[((df['LOR'] < Q1-1.5*IQR) | (df['LOR'] > Q3+1.5*IQR))] = np.NaN\n\n# filling missing values\ndf['LOR'] = df['LOR'].fillna(df['LOR'].median())","f65b1297":"print(df['CGPA'].describe())\n\nplt.subplots(1,2, figsize=(15,5))\n\n# checking for outliers\nplt.subplot(1,2,1)\nsns.boxplot(df['CGPA'])\nplt.title(\"Boxplot to identify the outliers\")\n\n# checking the distribution\nplt.subplot(1,2,2)\nsns.distplot(df['CGPA'])\nplt.title(\"Distplot to check the skewness\")\n\nplt.show()","fa48a141":"print(df['Research'].describe())\n\nplt.subplots(1,2, figsize=(15,5))\n\n# checking for outliers\nplt.subplot(1,2,1)\nsns.boxplot(df['Research'])\nplt.title(\"Boxplot to identify the outliers\")\n\n# checking the distribution\nplt.subplot(1,2,2)\nsns.distplot(df['Research'])\nplt.title(\"Distplot to check the skewness\")\n\nplt.show()","c9e2feb4":"# checking the variables info at the end of data pre-processing and cleaning\ndf.info()","be84fa58":"# creating a class for top 75% of students\nQ3 = df['Chance of Admit'].quantile(0.75)\ndf['High Chance'] = df['Chance of Admit'].apply(lambda x: 1 if x > Q3 else 0)\n\ndf['High Chance'].value_counts()","20277919":"# checking variables info at the end of feature engineering\ndf.info()","f6d127e9":"# statistical summary\nprint(\"Statistical summary:\\n\", df['GRE Score'].describe())\n\n# distribution of data\nfig, ax = plt.subplots(1,2, figsize=(15,6))\nsns.distplot(df['GRE Score'], bins=150, ax=ax[0])\nax[0].set_title(\"GRE Score\")\n\n# distribution of data of top 25% of students w.r.t. chance of admit\nsns.distplot(df[df[\"High Chance\"] == 1]['GRE Score'], bins=100, ax=ax[1])\nax[1].set_title(\"GRE Score of top 25%\")\nplt.show()","a3364858":"# statistical summary\nprint(\"Statistical summary:\\n\", df[\"TOEFL Score\"].describe())\n\n# distribution of data\nfig, ax = plt.subplots(1,2, figsize=(15,6))\nsns.distplot(df[\"TOEFL Score\"], bins=150, ax=ax[0])\nax[0].set_title(\"TOEFL Score\")\n\n# distribution of data of top 25% of students w.r.t. chance of admit\nsns.distplot(df[df[\"High Chance\"] == 1][\"TOEFL Score\"], bins=100, ax=ax[1])\nax[1].set_title(\"TOEFL Score of top 25% of students\")\nplt.show()","22750849":"# count plot of each rating\nfig, ax = plt.subplots(1,2, figsize=(15,6))\nsns.countplot(df['University Rating'], ax=ax[0])\nax[0].set_title(\"Count plot per Rating\")\n\n# percentage proportions\nax[1].pie(df['University Rating'].value_counts(), labels=df['University Rating'].value_counts().index, autopct='%1.1f',\n         explode=[0,0,0,0.1,0])\nax[1].set_title(\"Percentage proportion of each Rating\")\nplt.show()","72827700":"# count plot of each SOP rating\nfig, ax = plt.subplots(1,2, figsize=(15,6))\nsns.countplot(df[\"SOP\"], ax=ax[0])\nax[0].set_title(\"Count plot of SOP ratings\")\n\n# count of SOP rating for top 25% of students w.r.t. chance of admit\nsns.countplot(df[df[\"High Chance\"] == 1][\"SOP\"], ax=ax[1])\nax[1].set_title(\"Count plot of SOP ratings of top 25% students\")\nplt.show()","854b3745":"# count plot of each LOR rating\nfig, ax = plt.subplots(1,2, figsize=(15,6))\nsns.countplot(df[\"LOR\"], ax=ax[0])\nax[0].set_title(\"Count plot of LOR ratings\")\n\n# count of LOR rating for top 25% of students w.r.t. chance of admit\nsns.countplot(df[df[\"High Chance\"] == 1][\"LOR\"], ax=ax[1])\nax[1].set_title(\"Count plot of LOR ratings of top 25% students\")\nplt.show()","d856065f":"# statistical summary\nprint(\"Statistical summary:\\n\", df[\"CGPA\"].describe())\n\n# distribution of data\nfig, ax = plt.subplots(1,2, figsize=(15,6))\nsns.distplot(df[\"CGPA\"], bins=75, ax=ax[0])\nax[0].set_title(\"CGPA\")\n\n# distribution of data of top 25% of students w.r.t. chance of admit\nsns.distplot(df[df[\"High Chance\"] == 1][\"CGPA\"], bins=75, ax=ax[1])\nax[1].set_title(\"CGPA of top 25% of students\")\nplt.show()","2bba5c66":"# no. of observations\nprint(df[\"Research\"].value_counts())\n\n# count plot of each obersations\nfig, ax = plt.subplots(1,3, figsize=(18,6))\nsns.countplot(df[\"Research\"], ax=ax[0])\nax[0].set_title(\"No. of students with and without research\")\n\n# pie chart of percentage proportion\nax[1].pie(df[\"Research\"].value_counts(), labels=df[\"Research\"].value_counts().index, autopct=\"%1.1f\")\nax[1].set_title(\"Percentage proportion\")\n\n# pie chart of percentage proportion for top 25% students w.r.t. chance of admit\nax[2].pie(df[df[\"High Chance\"] == 1][\"Research\"].value_counts(), labels=df[df[\"High Chance\"] == 1][\"Research\"].value_counts().index,\n         autopct=\"%1.1f\", explode=[0,0.1])\nax[2].set_title(\"Percentage proportion of top 25% students\")\nplt.show()","4830e453":"# heat map\nplt.figure(figsize=(10,8))\nsns.heatmap(df.corr(), annot=True, cmap=\"coolwarm\", mask=np.triu(df.corr(), 1))\nplt.show()","8df092f9":"# pair plot\nsns.pairplot(df, hue=\"High Chance\")\nplt.show()","ca1167d3":"# scatter plots\nfig, ax = plt.subplots(3,1, figsize=(8,20))\nsns.scatterplot(data=df, x=\"CGPA\", y=\"Chance of Admit\", hue=\"High Chance\", ax=ax[0])\nax[0].set_title(\"GRE Score vs Chance of Admit\")\n\nsns.scatterplot(data=df, x=\"GRE Score\", y=\"Chance of Admit\", hue=\"High Chance\", ax=ax[1])\nax[0].set_title(\"GRE Score vs Chance of Admit\")\n\nsns.scatterplot(data=df, x=\"TOEFL Score\", y=\"Chance of Admit\", hue=\"High Chance\", ax=ax[2])\nax[0].set_title(\"GRE Score vs Chance of Admit\")\n\nplt.show()","24100454":"# violin plots\nfig, ax = plt.subplots(1,2, figsize=(15,6))\nsns.violinplot(data=df, x=\"SOP\", y=\"Chance of Admit\", hue=\"High Chance\", split=True, ax=ax[0])\nax[0].set_title(\"SOP vs Chance of Admit\")\n\nsns.violinplot(data=df, x=\"LOR\", y=\"Chance of Admit\", hue=\"High Chance\", split=True, ax=ax[1])\nax[1].set_title(\"LOR vs Chance of Admit\")\n\nplt.show()","2d5342f0":"# proportional plot\nct_highchance_research = pd.crosstab(df[\"High Chance\"], df[\"Research\"], normalize=0)\nprint(ct_highchance_research)\n\n# stacked bar chart to show the proportion of students with and without reasearch experience  \nfig, ax = plt.subplots(1,2, figsize=(12,6))\nct_highchance_research.plot.bar(stacked=True, ax=ax[0])\nax[0].set_title(\"Stacked bar chart\")\n\n# bar plot with mean value of Chance of Admit for each research category\nsns.barplot(data=df, x=\"Research\", y=\"Chance of Admit\", ax=ax[1])\nax[1].set_title(\"Bar plot with mean value of Chance of Admit\")\n\nplt.show()","59a03ffd":"# columns info\ndf.info()","07266155":"# creating dependent variable\ny = df[\"Chance of Admit\"]\n\n# creating independent variables\nX = df.drop(columns=[\"Chance of Admit\",\"High Chance\"])\n\nX.head()","f0afda97":"# creating list of categorical \nlist_categorical_columns = [\"Research\"]\nprint(\"Categorical variables:\\t\", list_categorical_columns)\n\n# creating list of numeric variable\nlist_numeric_columns = list(X.drop(columns=\"Research\").columns)\nprint(\"Numeric variables:\\t\", list_numeric_columns)","0fdc462e":"# getting the unique values for categorical variables\nfor col in list_categorical_columns:\n    print(col)\n    print(df[col].value_counts())\n    print()","f9d37d7d":"# changing the datatype to uint8\nX[\"Research\"] = X[\"Research\"].astype(\"uint8\")","f6a48d0d":"# splititng my data into 80:20 split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","aced1daf":"# initializing scaler and fitting with train data\nss = StandardScaler().fit(X_train[list_numeric_columns])\n\n# transforming train data\nX_train[list_numeric_columns] = ss.transform(X_train[list_numeric_columns])\n\n# transforming test data\nX_test[list_numeric_columns] = ss.transform(X_test[list_numeric_columns])","28d5458c":"# initializing and fitting the model\nmodel_lr = LinearRegression().fit(X_train,y_train)\n\n# predicting using training data\ny_pred_train = model_lr.predict(X_train)\n\n# predicting using test data\ny_pred_test = model_lr.predict(X_test)","80c72b57":"# lets compare model performance on trainig and test data to check for overfitting\nprint(\"Train vs Test model performance results:\")\npd.DataFrame(zip([np.sqrt(mean_squared_error(y_pred_train,y_train)), np.sqrt(mean_squared_error(y_pred_test,y_test))],\n                 [r2_score(y_pred_train,y_train), r2_score(y_pred_test,y_test)]), columns=[\"RMSE\", \"R-squared\"], index=[\"Train\",\"Test\"])","56e70498":"## Splitting into train and test datasets","3c70ab14":"# Data pre-processing","d53b84df":"### Chance of Admit vs Research\n* The mean value of Chance of Admit for students with research experience is greater than the mean value of those without research experience.\n* Proportion of students with research experience among top 25% of student w.r.t Chance of Admit is far greater than those without any research experience.","e7b83923":"**Observations:**\n\n* Dropping Serial No. column as it does not help us to determine the dependant variable.","49a167c3":"**Observations:**\n* No outliers are found.\n* No missing are found.","7551f0f2":"# Exploratory Data Analysis\n\nLet's dive into our data to find some interesting insights.","b30cb189":"### Research\n* No. of students with research experience is 280, and is more than no. of students without research experience 220.\n* Among top 25% of students w.r.t chance of admit, 95% of the students are having research experience.","589e63b2":"## Let's scale the data","1eb53153":"# Graduate Admission Analysis\n\n![image.png](attachment:image.png)\n\n## Problem statement\n\nApplying for a master's program is a very expensive and intensive work. Often students either underestimate their profile and miss the opportunity to study in a better university or overestimate their profile and waste their money by applying for highly ambitious universities.\n\nOur goal is to help students with shortlisting universities with their profiles by a predicted output which gives them a fair idea about their chances for a particular university.\n\nWe would like to have a model that will take the parameters which describe the student profile and are considered important during application evaluation by the admission committee and predict the chance of getting admission at a university, so that it will aid the aspiring students in either not letting them miss good opportunities or avoid wasting their money.","3bdee92f":"**Observations:**\n* No outliers are found.\n* No missing are found.","93b56713":"## Variable information\n\n- **GRE Scores:** Score out of 340.\n- **TOEFL Scores:** Score out of 120.\n- **University Rating:** Rating out of 5.\n- **Statement of Purpose:** Rating out of 5.\n- **Letter of Recommendation:** Rating out of 5.\n- **Undergraduate GPA:** Score out of 10.\n- **Research Experience:** Either 0 or 1.[](http:\/\/) 0 - no, 1 - yes.\n- **Chance of Admit:** Ranging from 0 to 100. This is the target variable which we will have to predict.","80f06470":"## Splitting dataframe into dependent and independent variables\n\n- Dependent variable: `Chance of Admit`\n- Independent variables: `GRE Score`, `TOEFL Score`, `University Rating`, `SOP`, `LOR`, `CGPA`, `Research`","fbdad44b":"### University Rating\n* Rating 3 is in highest proportion, Rating 1 is in least proportion.","925a527b":"# Data cleaning\n\nLet's groom our data.","3cc0bd37":"### University Rating\n\nCategorical variable.","9f8f33b5":"**Removing outliers:**\n* Variable type: Categorical\n* Method: IQR\n    \n**Filling missing values:**\n* Variable type: Categorical\n* No. of outliers: 1\/500, very few\n* Method: Median imputation","d46357ef":"## Importing data","a360d2d9":"**Observations:**\n\n- There are no missing values.","167cb886":"### Research\n\nCategorical variable.","c3d99da8":"# Feature engineering\n\nLet's create a few new variables which makes our data analysis more interesting and help us find few additional insights.","f05875dc":"**Observations:**\n\n- There are some trailing spaces in column names of LOR and Chance of Admit, lets remove the trailing spaces.","60890c33":"### Chance of Admit\n\nWe can turn this continuous variable into categorical variable to get more insights. I'm categorizing values above 75th pecentile as 1 and the rest as 0.","63baa63e":"## Encoding categorical variables\n\nSince we will be using regression model, we will use 1_hot encoding for categorical variables.","e666e5dd":"### SOP\n\nCategorical variable.","8f20ecea":"## Univariate data analysis\n\nVisualizing one variable at a time.","45acb0be":"## Linear regression model","77690123":"## Bivariate data analysis\n\nLet's understand the chemistry between any two variables.","8355d85a":"**Observations:**\n* No outliers are found.\n* No missing are found.","2c341812":"### CGPA\n* Min CGPA is 6.8, Max CGPA is 9.92, Avg CGPA is 8.6.\n* Most of the observations are in 8.1-9.0 range.\n* Avg CGPA of top 25% of students w.r.t. chance of admit is around 9.1.","476aa385":"## Model evaluation","30f5e9c0":"### GRE Score\n* Min score is 290, Max score is 340, Avg score is 316.\n* Most of the observations are concentrated in 310-330 range.\n* The average score of top 25% of students w.r.t. chance of admit is around 330.","b7af83d6":"**Observations:**\n- Since we have only one categorical variable and also the variable is having two classes, 0 and 1, we need not do any encoding.\n- We will change the datatype of the variable from int to uint8.","f32d55e4":"## Independant variables\n\nWe first treat for outliers and then treat for missing values.","04540ecc":"### Chance of Admit vs (SOP and LOR)\n* Chance of Admit is higher for higher SOP and LOR ratings.","f4b37443":"**Observations:**\n* No outliers are found.\n* No missing are found.","bbd8828d":"### TOEFL Score\n\nContinuous variable.","f0728f4f":"### Chance of Admit\n\nSince, we do not have any missing values in our data set, we do not drop any rows.","1cf8292b":"### LOR\n\nCategorical variable.","0b35cd77":"## Dependant variable\n\nWe need to treat the missing values in our dependant variable before going for independant variables.","349e4e63":"### LOR\n* LOR rating of 3.0 is the observation of highest frequency.\n* More no. of top 25% of students w.r.t. chance of admit are having LOR rating of 4.5 and above.","9dcb791f":"### CGPA\n\nContinuous variable.","9864a4f3":"### SOP\n* SOP rating of 4.0 is the observation of highest frequency.\n* Top 25% of students w.r.t. chance of admit are having SOP rating of 4.0 and above.","0a9aa5b0":"## Understanding the dataframe dimensions","e65c84b1":"# Model building\n\nLet's build a regression model since the data in simple.","9738a1bd":"**Observations:**\n* No outliers are found.\n* No missing are found.","c1278f9e":"### Correlation maps\n* Chance of Admit is having high positive correlation with CGPA, GRE Score and TOEFL Score.\n* Also, CGPA is having high positive correlation with GRE Score and TOEFL Score.","241843cb":"**Observations:**\n* No outliers are found.\n* No missing are found.","9370f503":"### GRE Score\nContinuous variable.","0e5c1262":"**Observations:**  \n  * Skew is less, is within acceptable range.\n  * Distribution of values is near to normal distribution, are deviating near right tail.\n  * No transformation is required to be applied on dependant variable.","b1caf9e0":"**Observations:**\n- There is no significant difference between model performance on training and test data, suggesting there is no overfitting of the model.\n- Hence, we keep the above model as the final one.","c9944162":"# Reading and understanding data\n\nWondering what's this data about? Let's find it out!","141019a3":"### TOEFL Score\n* Min score is 92, Max score is 120, Avg score is 107.\n* Most of the observations are in 103-112 range.\n* Avg score of top 25% of students w.r.t. chance of admit is around 112.","545ad649":"## Identifying continuous and categorical variables\n\nOnly Research is categorical variable, rest all are numeric variables (CGPA, GRE Score and TOEFL Score are continuous, others are ordinal).","fa56eee0":"### Chance of Admit vs (CGPA, GRE Score and TOEFL Score)\n* Chance of Admit increases as CGPA, GRE Score and TOEFL Score increase."}}