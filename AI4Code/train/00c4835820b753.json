{"cell_type":{"ff518e2d":"code","b97a687a":"code","e0148dcd":"code","02671ea1":"code","d8c1e310":"code","17c05e9b":"code","c527205a":"code","93771fb1":"code","9023c61b":"code","044330bf":"code","96f94dcd":"code","1aec9843":"code","05103b61":"code","4204a8a4":"code","5b353b55":"code","b7ef951d":"code","64bb8b6c":"code","bb35bc59":"code","17ac9e50":"code","2189fd54":"code","4e4ebc06":"code","481863c5":"code","7659a1d7":"code","82bd1f8d":"code","076a0ffc":"code","3bbcfca5":"code","cb676b54":"code","cf92e38b":"code","5a185f7e":"code","c72f3ffa":"code","842ae7f8":"code","3f4f65ee":"markdown","1e785a9b":"markdown","94563df7":"markdown","b814195a":"markdown","8e9b27a7":"markdown","28d0cf59":"markdown","d89cec67":"markdown","88182100":"markdown","3e2d4365":"markdown","b6f8514c":"markdown","70663a0e":"markdown","4aca66ce":"markdown","60b64d81":"markdown","ee527996":"markdown","2491d7d9":"markdown","48292199":"markdown"},"source":{"ff518e2d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport statsmodels.api as sm\nimport os","b97a687a":"df_brain = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/train.csv\")\ndf_brain.shape","e0148dcd":"print(df_brain['time_step'].iloc[:240:80])","02671ea1":"df_brain.pop(\"id\")\n#df_brain.pop(\"time_step\")\ndf_brain.pop('breath_id')\ndf_brain.isnull().sum()","d8c1e310":"print(df_brain.min(),df_brain.max())","17c05e9b":"from sklearn.preprocessing import MinMaxScaler\n\nsc = MinMaxScaler()\ny_train = df_brain['pressure']\ndf_brain.pop(\"pressure\")\nsc_y = MinMaxScaler()\ny_train = sc_y.fit_transform(np.array(y_train).reshape(-1,1))\ndf_brain[df_brain.columns] = sc.fit_transform(df_brain)\ndf_brain['pressure'] = y_train.reshape(-1)\ndf_brain.head()","c527205a":"def num_batches(dataset,batch_size,time_steps):\n    if len(dataset) % batch_size == 0:\n        return len(dataset) \/\/ (batch_size*time_steps)\n    else:\n        return  len(dataset) \/\/ (batch_size*time_steps) +1\n    \n\n#### generating data of one timestep\n### step no starts with 0\ndef step(dataset,time_steps,step_no):\n    sample_in = dataset.iloc[time_steps*step_no:time_steps*step_no + time_steps,:-1].values\n    sample_out = dataset.iloc[time_steps*step_no:time_steps*step_no + time_steps,-1].values\n    \n    return sample_in,sample_out\n    \n\n#### This is a generator function below Input should be a pandas dataframe\n\ndef data_gen(dataset,time_steps,batch_size,features):\n    isValid = len(dataset) % batch_size == 0\n    batches = num_batches(dataset,batch_size,time_steps)\n    print(batches)\n    while True:\n       \n        \n        for batch in range(batches):\n            \n            if batch < batches -1 or isValid:\n                samples_in = np.zeros((batch_size,time_steps,features))\n                samples_out = np.zeros((batch_size,time_steps))\n                \n                for i in range(batch_size):\n                    sample_in, sample_out = step(dataset,time_steps,batch*batch_size +i)\n                    #print(sample_in.shape,batch*batch_size*time_steps +i)                       \n                    samples_in[i,:,:] = sample_in\n                    samples_out[i,:] = sample_out\n               \n                yield  samples_in,samples_out\n            \n            else:\n                \n                bs = (len(dataset) % (batch_size*time_steps))\/\/time_steps\n                print(bs)\n                samples_in = np.zeros((bs,time_steps,features))\n                samples_out = np.zeros((bs,time_steps))\n                for i in range(bs):\n                    sample_in, sample_out = step(dataset,time_steps,bs*batch +i)\n                    samples_in[i,:,:] = sample_in\n                    samples_out[i,:] = sample_out\n                yield  samples_in,samples_out","93771fb1":"df_test = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/test.csv\")\ndf_test.shape","9023c61b":"gen = data_gen(df_brain,80,90,5)\n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import LSTM,GRU,Dense,Dropout,TimeDistributed\n","044330bf":"model = Sequential()\nmodel.add(LSTM(512,input_shape=(80,5),return_sequences=True))\nmodel.add(LSTM(1024,return_sequences=True))\nmodel.add(Dropout(0.2))\nmodel.add(TimeDistributed(Dense(1,activation='relu',kernel_initializer='normal')))","96f94dcd":"import tensorflow as tf\nmodel.compile(optimizer='adam',loss='mean_absolute_error')\nmodel.summary()","1aec9843":"model.fit(gen,steps_per_epoch=839,epochs=10)","05103b61":"sample = df_brain.iloc[2*80: 2*80+80,:5]\nsample","4204a8a4":"predictions = model.predict(np.array(sample).reshape(1,80,5))","5b353b55":"l = (predictions.reshape(-1) - df_brain.iloc[2*80: 2*80+80]['pressure'])\nl.min()","b7ef951d":"plt.figure(figsize=(10,6))\nplt.subplot(1,2,1)\nplt.plot(range(predictions.shape[1]),predictions.reshape(-1))\nplt.title(\"Predicted\")\nactual =  df_brain.iloc[2*80: 2*80+80]['pressure']\nplt.subplot(1,2,2)\nplt.plot(actual.index,actual)\nplt.title(\"Actual\")","64bb8b6c":"df_test = df_test.drop(['id','breath_id'],axis=1)\n\ndf_test[df_test.columns] = sc.transform(df_test)","bb35bc59":"def shape_test_data(data,timesteps):\n    steps = data.shape[0]\/\/timesteps\n    data_in = np.zeros((steps,timesteps,data.shape[1]))\n    for i in range(steps):\n        data_in[i,:,:] = data.iloc[timesteps*i: timesteps*i + timesteps,:]\n    return data_in","17ac9e50":"test_data = shape_test_data(df_test,80)\ntest_data.shape","2189fd54":"predictions = model.predict(test_data)","4e4ebc06":"y_test = sc_y.inverse_transform(predictions.reshape(-1,1)).reshape(-1)\n\ndf_submissions = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/test.csv\")\ndf_submissions = df_submissions[['id']]\ndf_submissions['pressure'] = y_test","481863c5":"df_submissions.to_csv(\".\/submissions.csv\",index=False)","7659a1d7":"model_1 = Sequential([\n    GRU(512,input_shape=(80,4),return_sequences=True),\n    GRU(1024,return_sequences=True),\n    TimeDistributed(Dense(1,activation='relu',kernel_initializer='normal'))\n])\n\nmodel_1.compile(optimizer='adam',loss='mean_absolute_error')\nmodel_1.summary()","82bd1f8d":"train_data = df_brain.drop(\"time_step\",axis=1)\ndata = data_gen(train_data,80,90,4)\nhistory = model_1.fit(data,steps_per_epoch=839,epochs=15)","076a0ffc":"test_data_1 = shape_test_data(df_test.drop('time_step',axis=1),80)\n","3bbcfca5":"predictions = model_1.predict(np.array(df_brain.iloc[240:320].loc[:,['R','C','u_in','u_out']]).reshape(1,80,4))\nplt.plot(range(80),sc_y.inverse_transform(predictions[0,:,:]).reshape(-1))","cb676b54":"predictions = model_1.predict(test_data_1)","cf92e38b":"predictions = sc_y.inverse_transform(predictions.reshape(-1,1))","5a185f7e":"df_submissions['pressure'] = predictions.reshape(-1)\ndf_submissions.head()","c72f3ffa":"df_submissions.to_csv(\"submissions.csv\",index=False)","842ae7f8":"train_data","3f4f65ee":"## Let us see the test data","1e785a9b":"### Lets try a model with timestep in input vector","94563df7":"### After exploring the data it is a time series of 80 timesteps\n- The printed output gives better intution","b814195a":"### Let us compile the model","8e9b27a7":"### After the predictions making submissions","28d0cf59":"#### ","d89cec67":"### Let us check for the null values in the data set","88182100":"### Predicting the Data","3e2d4365":"### Let us submit","b6f8514c":"plt.plot(range(80),df_brain.iloc[240:320]['pressure'])","70663a0e":"### Actual and predicted doing good job on train set","4aca66ce":"## Building a generator","60b64d81":"### The data is clean and let us prepare IID data\n- Every Time Series set is IID\n- Let us create numpy array out of it\n- generators are good for large data","ee527996":"### Let us shape test data properly for prediction","2491d7d9":"### Both are IID data\n- Let us import keras for Neural network","48292199":"### We will have to scale the data as output has negative values If we do MinMax Scaling to keep values from 0 to 1\n- If we use neural network we can use Either Relu or Sigmoid as activation functions to handle valuses below 0"}}