{"cell_type":{"76999db4":"code","3a41eb82":"code","d0d6dafc":"code","9e567dd6":"code","aa62cc65":"code","6470906a":"code","d92bed28":"code","b43fd3c9":"code","14d6b223":"code","3d11896e":"code","50688f08":"code","abffb540":"code","528ead21":"code","d08c9853":"code","008a299a":"code","bfd9c7df":"code","4431fa40":"code","6b77f6b3":"code","573fd8e0":"code","5f219ced":"code","6564fb5e":"code","ef010e72":"code","e6d63c00":"code","b013929c":"code","600d937f":"code","84869fd6":"code","97e1cdaf":"code","54861c2b":"code","53cf0ee3":"code","52033bb4":"code","db710d39":"code","07c52a27":"code","1c126439":"code","ed8339ef":"code","b480bf13":"code","8a52317f":"code","7b4e5c04":"code","54df4557":"code","2f919d77":"code","97a577f3":"code","46b0fcce":"code","0db5d44b":"code","c70b97c7":"code","bf12e261":"code","0a590cb0":"code","2b4b245c":"code","e58c691a":"code","4ec5f4ae":"code","87e05809":"code","ca703eb8":"code","cb7d05a1":"code","32aa8552":"code","273ce933":"markdown","f412015f":"markdown","40fc5b4b":"markdown","b5be0bdd":"markdown","8cbc346d":"markdown","7ee90f20":"markdown","614a1f01":"markdown","177acfe8":"markdown","32c09f6c":"markdown","d044a87f":"markdown","9c014459":"markdown","f23c0cd3":"markdown","d31d1695":"markdown","f1541263":"markdown","b824b435":"markdown","acba531c":"markdown","5fd8da7b":"markdown","6935e700":"markdown","cfcb3198":"markdown","43c77a63":"markdown","80a40e93":"markdown","5a2f1caa":"markdown","77d9c81c":"markdown","7c4e0499":"markdown","99fd3571":"markdown","027de704":"markdown","eb639107":"markdown","45d95dca":"markdown","6b55a6d5":"markdown"},"source":{"76999db4":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as st\nimport os\n%matplotlib inline","3a41eb82":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d0d6dafc":"df = pd.read_csv('..\/input\/cancer-dataset-aggregated\/cancer_reg.csv',encoding='latin-1')","9e567dd6":"df.shape","aa62cc65":"df.head()","6470906a":"df.info()","d92bed28":"df['binnedInc']=df['binnedInc'].str.replace('(','')\ndf['binnedInc']=df['binnedInc'].str.replace('[','')\ndf['binnedInc']=df['binnedInc'].str.replace(']','')","b43fd3c9":"x=df['binnedInc'].str.split(',',expand=True).astype(float)","14d6b223":"x=df['binnedInc'].str.split(',',expand=True).astype(float)\ny=(x[0]+x[1])\/2\ndf['binnedInc']=y\ndf.head()","3d11896e":"df.describe()","50688f08":"for i in df:\n    if (i=='Geography'):\n        continue\n    else:\n        plt.figure()\n        df.boxplot(column=[i])","abffb540":"print('count of outliers below lower whisker is :',(df['TARGET_deathRate']<df['TARGET_deathRate'].quantile(0.25)-(1.5*(st.iqr(df['TARGET_deathRate'])))).sum())","528ead21":"print('count of outliers above upper whisker is :',(df['TARGET_deathRate']>df['TARGET_deathRate'].quantile(0.75)+(1.5*(st.iqr(df['TARGET_deathRate'])))).sum())","d08c9853":"# since target variable has outliers less then 10% of the data, drop the outliers\ndf1=df[(df['TARGET_deathRate']>df['TARGET_deathRate'].quantile(0.25)-(1.5*(st.iqr(df['TARGET_deathRate']))))&(df['TARGET_deathRate']<df['TARGET_deathRate'].quantile(0.75)+(1.5*(st.iqr(df['TARGET_deathRate']))))]","008a299a":"df1.shape","bfd9c7df":"df1.isna().sum()","4431fa40":"#since 'PctEmployed16_Over' have missing value less then 10% it is imputed with median\ndf1['PctEmployed16_Over']=df1['PctEmployed16_Over'].fillna(df1['PctEmployed16_Over'].median())\n","6b77f6b3":"for i in df1.columns:\n    if (i=='Geography' or i=='PctSomeCol18_24' or i=='PctPrivateCoverageAlone'):\n        continue\n    else:\n        plt.figure()\n        sns.distplot(df1[i],kde=False,color='g',bins=10,rug=True)","573fd8e0":"# corr matrix\ndf1.corr()","5f219ced":"plt.figure(figsize=(30,15))\nsns.heatmap(df1.corr(),annot=True)","6564fb5e":"import warnings \nwarnings.filterwarnings('ignore')\nimport statsmodels.api as sm\n#drop the 'geography' ,'pctsomecol18_24' ,'pctprivatecoveragealone' as they have the most missing values.\n# drop the dependent variable \nx=df1.drop(['Geography' ,'PctSomeCol18_24','PctPrivateCoverageAlone','TARGET_deathRate'],axis=1)\nx_constant = sm.add_constant(x)\ny=df1['TARGET_deathRate']\ny1=list(y)","ef010e72":"model = sm.OLS(y1,x_constant).fit()\nmodel.summary()","e6d63c00":"from statsmodels.stats.outliers_influence import variance_inflation_factor\nvif = [variance_inflation_factor(x_constant.values, i) for i in range(x_constant.shape[1])]\npd.DataFrame({'vif': vif[1:]}, index=x.columns)","b013929c":"# features which has highly multicollinarity\nvif_=pd.DataFrame({'vif': vif[1:]}, index=x.columns)\nvif_[vif_['vif']>10]","600d937f":"features=[]\na=model.pvalues\nfor i in range(a.shape[0]):\n    if  a[i]<0.05:\n        features.append(a.index[i])\n    else:\n        continue\nprint(features)","84869fd6":"X=df1[[ 'avgAnnCount', 'avgDeathsPerYear', 'incidenceRate', 'popEst2015', 'MedianAgeMale', 'PercentMarried', 'PctHS18_24', 'PctHS25_Over', 'PctBachDeg25_Over', 'PctEmployed16_Over', 'PctPrivateCoverage', 'PctEmpPrivCoverage', 'PctOtherRace', 'PctMarriedHouseholds', 'BirthRate']]","97e1cdaf":"for i in X.columns:\n    plt.figure()\n    sns.scatterplot(x=df1['TARGET_deathRate'],y=i,data=df1)","54861c2b":"for i in X.columns:\n        plt.figure()\n        sns.kdeplot(X[i])","53cf0ee3":"nor=[]\nfor i in  X.columns:\n    if st.shapiro(X[i])[1]<0.05:\n        nor.append(i)\n    else:\n        continue\nprint(nor)","52033bb4":"to_t=X[['avgAnnCount', 'avgDeathsPerYear', 'incidenceRate', 'popEst2015', 'MedianAgeMale', 'PercentMarried', 'PctHS18_24', 'PctHS25_Over', 'PctBachDeg25_Over', 'PctEmployed16_Over', 'PctPrivateCoverage', 'PctEmpPrivCoverage', 'PctOtherRace', 'PctMarriedHouseholds', 'BirthRate']]","db710d39":"right=[]\nleft=[]\nfor i in  to_t.columns:\n    if st.skew(to_t[i])>0.5:\n        right.append(i)\n    elif st.skew(to_t[i])<-0.5:\n            left.append(i)\n    else:\n        continue\nprint('right skwed :\\n ', right,'\\n\\nleft skwed :\\n ',left)","07c52a27":"to_t['avgDeathsPerYear']=np.log((to_t['avgDeathsPerYear']))\nto_t['avgAnnCount']=np.log((to_t['avgAnnCount']))\nto_t['popEst2015']=np.log((to_t['popEst2015']))\nto_t['PctBachDeg25_Over']=np.log((to_t['PctBachDeg25_Over']))\nto_t['PctOtherRace']=(np.log((to_t['PctOtherRace'])+1))\nto_t['BirthRate']=np.sqrt((to_t['BirthRate']))\nto_t['PercentMarried']=((to_t['PercentMarried'])**2)\nto_t['PctMarriedHouseholds']=((to_t['PctMarriedHouseholds'])**2)","1c126439":"for i in to_t:\n    a=st.skew(to_t[i])\n    print(i,':  ',a)","ed8339ef":"for i in to_t.columns:\n        plt.figure()\n        sns.kdeplot(to_t[i])","b480bf13":"# data split into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test , y_train, y_test = train_test_split(to_t,y1, test_size = 0.30, random_state = 20)","8a52317f":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression()\nlin_reg.fit(X_train, y_train)","7b4e5c04":"# r2 for the train data\nprint('r2 score for train data :',lin_reg.score(X_train, y_train))","54df4557":"# r2 for the test data\nprint('r2 score for train data :',lin_reg.score(X_test, y_test))","2f919d77":"#  y predict for test data\ny_predict=lin_reg.predict(X_test)","97a577f3":"#rmse score\nfrom sklearn.metrics import mean_squared_error as ms\nprint('rmse score :',np.sqrt(ms(y_predict,y_test)))","46b0fcce":"sns.scatterplot(y_predict,y_test)\nplt.xlabel('y_predict')\nplt.ylabel('y_test')\nplt.show()","0db5d44b":"#distribution of 'y_predict-y_test'\na=y_predict-y_test\nsns.kdeplot(np.array(a))\nplt.xlabel('y_predict-y_test')\nplt.show()","c70b97c7":"from sklearn.preprocessing import PolynomialFeatures\npoly = PolynomialFeatures(degree = 2) \nX_poly = poly.fit_transform(to_t) \n  \nX_train, X_test , y_train, y_test = train_test_split(X_poly,y1, test_size = 0.30, random_state = 207)","bf12e261":"lin2 = LinearRegression() \nlin2.fit(X_train,y_train) ","0a590cb0":"#r2 for the train data\nprint('r2 score for train data :',lin2.score(X_train, y_train))","2b4b245c":"#r2 for the test data\nprint('r2 score for test data :',lin2.score(X_test, y_test))","e58c691a":"# predict y\ny_predict=lin2.predict(X_test)","4ec5f4ae":"#  rmse score\nprint('rmse score :',np.sqrt(ms(y_predict,y_test)))","87e05809":"sns.scatterplot(y_predict,y_test)\nplt.xlabel('y_predict')\nplt.ylabel('y_test')\nplt.show()","ca703eb8":"a=y_predict-y_test\nsns.kdeplot(np.array(a))\nplt.xlabel('y_predict-y_test')\nplt.show()","cb7d05a1":"from sklearn.model_selection import cross_val_score\nscores1 = cross_val_score(lin2,X=X_train,y=y_train, cv=10)\nprint ('Cross-validated scores:', scores1)","32aa8552":"print('score_mean',scores1.mean(),': score_std',scores1.std())","273ce933":"OBSERVATION:\n\n:Durbin-Watson score is 1.789 which indicates there lies no autocorrelation between the dependent features\n\n\n","f412015f":"# conclusion\n\nThe r2 value for the model is shown to be 86% with std of 3.6%","40fc5b4b":"## cross validation score","b5be0bdd":"# transformation","8cbc346d":"# ditribution of after transformation","7ee90f20":"# import the dataset","614a1f01":"observation:\n\nthe distribution of features looks highly hightly right\/left skwed","177acfe8":"# implementation of quadratic equation","32c09f6c":"# distribution before transformation ","d044a87f":"# multicolliniarity with VIF","9c014459":"# summary stats for the features","f23c0cd3":"Observation:\n\nAll the variables including dependent variable 'target_deathrate' has outliers ","d31d1695":"# Mean of feature binnedinc as it is Median income per capita binned by decile (b)","f1541263":"# features which as passed the statistical test","b824b435":"# distribution of the features","acba531c":"# feature which are not normally distributed","5fd8da7b":"observation:\n\nfrom the heatmap it becomes clear that there lies a multicollinarity  between the variables","6935e700":"# shape of the dataset","cfcb3198":"# Scatter plot to check the linear relation with dependent feature","43c77a63":"# checking the outliers","80a40e93":"# droping outliers from dependent variable","5a2f1caa":"# dtype of the dataset","77d9c81c":"# null values","7c4e0499":"# model building","99fd3571":"# perform ols test to check the significant features ","027de704":"# skewness after transformation","eb639107":"# segregating the right\/left skewed features","45d95dca":"# corr between the features","6b55a6d5":"obsevation:\n\nAll the above graph shows the reduction in the skwness and look mostly normal distributed expect PctOtherRace."}}