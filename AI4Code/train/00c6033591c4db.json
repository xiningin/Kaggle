{"cell_type":{"866a63f2":"code","89ff23db":"code","d6c50aa2":"code","3f48fee3":"code","7a1cc2ca":"code","f62da254":"code","4d68bda7":"code","3bc1c565":"code","b3e000f2":"code","b6e9a01c":"code","5027ef44":"code","f010aa38":"code","76324595":"code","3e3591a9":"code","90b69827":"code","7115a37f":"code","bc376c33":"code","22fca503":"markdown","e8682923":"markdown","34b90666":"markdown","6d3f05fb":"markdown","e8b60afe":"markdown","58cef152":"markdown","afb61989":"markdown","692d1680":"markdown","a1b3712d":"markdown","ed3f283a":"markdown","4b0811e0":"markdown","8dfacc87":"markdown","395899ef":"markdown","5b4d7318":"markdown","ee43b34e":"markdown","a78c1ba3":"markdown","d602fc5e":"markdown","e199004d":"markdown","47f64a4e":"markdown","13cba2e3":"markdown","2477ea7e":"markdown","e7138a71":"markdown","4a584d08":"markdown","4f27672a":"markdown","36b08faf":"markdown","7283b285":"markdown","615eb522":"markdown"},"source":{"866a63f2":"# Import the dependencies\nimport numpy as np\nfrom scipy.linalg import toeplitz, cholesky, sqrtm, inv\n# import scipy.linalg as la\nfrom scipy import signal\nfrom scipy.integrate import odeint\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"white\")\nprint(\"Imports done\")","89ff23db":"def g_gp(x,v):\n    \"\"\"\n    Generative process, equation of sensory mapping: g_gp(x,v) at point x    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Hidden causal state, in this example not used\n        \n    OUTPUT:\n        g_gp(x,v) - Temperature in degrees celsius\n        \n    \"\"\"\n\n    t0=25\n    return t0 -16 \/ (1 + np.exp(5-x\/5))\n\ndef dg_gp(x,v):\n    \"\"\"\n    Partial derivative of generative process towards x, equation of sensory mapping: g'_gp(x,v) at point x    \n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g'_gp(x,v) - first partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return -16\/5 * np.exp(5-x\/5) \/ (1+np.exp(5-x\/5))**2\n\ndef ddg_gp(x,v):\n    \"\"\"\n    Double partial derivative of generative process towards x, equation of sensory mapping: g''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g''_gp(x,v) - second partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return (32*np.exp((2*x)\/5+5))\/(25*(np.exp(x\/5)+np.exp(5))**3)-(16*np.exp(x\/5+5))\/(25*(np.exp(x\/5)+np.exp(5))**2)\n\ndef dddg_gp(x,v):\n    \"\"\"\n    3rd partial derivative of generative process towards x, equation of sensory mapping: g'''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g'''_gp(x,v) - third partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return -16*np.exp(x\/5+5)*(np.exp((2*x)\/5)-4*np.exp(x\/5+5)+np.exp(10))\/(125*(np.exp(x\/5)+np.exp(5))**4)\n\ndef ddddg_gp(x,v):\n    \"\"\"\n    4th partial derivative of generative process towards x, equation of sensory mapping: g''''_gp(x) at point x  \n    Needed to calculate the sensory signal in generalised motions\n   \n    INPUTS:\n        x       - Position in centimetres    \n        \n    OUTPUT:\n        g''''_gp(x,v) - 4th partial derivative of generative process towards x\n        \n    \"\"\"\n    \n    return (16*np.exp(x\/5+5)*(np.exp((3*x)\/5)-11*np.exp((2*x)\/5+5)+11*np.exp(x\/5+10)-np.exp(15)))\/(625*(np.exp(x\/5)+np.exp(5))**5)\n\n# in case you wondered how to calculated all the derivatives in an easy way: https:\/\/www.derivative-calculator.net\/\n\n# Show the temperature curve\nx_show = np.arange (-0,50,0.01)\ny_show = g_gp(x_show,0)\ndy_show = dg_gp(x_show,0)\nplt.plot(y_show, x_show)\n#plt.plot(dy_show, x_show)\nplt.ylabel('Depth (centimeters)')\nplt.xlabel('Temperature (\u00b0 C)')\nplt.gca().invert_yaxis()\nplt.vlines(17, 50, 25, colors='r', linestyles='dashed')\nplt.hlines(25, 10,17, colors='r', linestyles='dashed')\nplt.text(17.3,27,\"temparature 17\u00b0 C\")\nplt.show;\n\nprint('Temperature at 25 centimetres is: ', g_gp(25,0), ' degrees celsius')","d6c50aa2":"a_gp=0\nb_gp=1\ndef f_gp(x, v, u):\n    \"\"\"\n    Generative process, equation of motion: f_gp(x,u)    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Causal state\n        u       - Control signal\n        \n    OUTPUT:\n        f_gp(x,v,u) - motion (speed) of the hidden state (depth) \n        \n    \"\"\"\n    return a_gp*x + b_gp*u +v\n\ndef df_gp(x, v, u):\n    \"\"\"\n    Partial derivative of generative process towards x, equation of motion: f'_gp(x,v,u) at point x    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Causal state\n        u       - Control signal\n        \n    OUTPUT:\n        df_gp(x, u) - first derivative of the equation of motion towards x\n        \n    \"\"\"\n    return a_gp\n        ","3f48fee3":"# Setting up the time data:\ndt = 0.005; # integration step, average neuron resets 200 times per second\nT = 10+dt; # maximum time considered\nt = np.arange(0,T,dt)\nN= t.size #Amount of data points\nprint ('Amount of data points: ', N)\nprint ('Starting with', t[0:5])\nprint ('Ending with', t[N-5:N])\nprint ('Data elements', np.size(t))","7a1cc2ca":"# Support functions for generalised coordinates of motion\n\ndef makeNoise(C,s2,t):\n    \"\"\"\n    Generate random noise series with temporal smoothness with desired covariance matrix\n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        C       - desired covariance matrix\n        s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n                  - s2 <= 1e-5 -> produces white noise\n        t       - timeline \n        \n    OUTPUT:\n        ws       - noise sequence with temporal smoothness\n    \"\"\"\n    \n    if np.size(C)== 1:\n        n = 1\n    else:\n        n = C.shape[1]  # dimension of noise\n        \n    # Create the white noise with correct covariance\n    N = np.size(t)      # number of elements\n    L =cholesky(C, lower=True)  #Cholesky method\n    w = np.dot(L,np.random.randn(n,N))\n    \n    if s2 <= 1e-5: # return white noise\n        return w\n    else: \n        # Create the noise with temporal smoothness\n        P = toeplitz(np.exp(-t**2\/(2*s2)))\n        F = np.diag(1.\/np.sqrt(np.diag(np.dot(P.T,P))))\n        K = np.dot(P,F)\n        ws = np.dot(w,K)\n        return ws\n\ndef temporalC(p,s2):\n    \"\"\"\n    Construct the temporal covariance matrix S for noise with embedding order p and smoothness parameter s\n    \n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        p       - embedding order (>0)\n        s2      - smoothness parameter (>0), variance of the filter (sigma^2)\n        \n    OUTPUT:\n        S       - temporal covariance matrix ((p+1) x (p+1))\n    \"\"\" \n\n    q = np.arange(p+1)\n    \n    r = np.zeros(1+2*(p))\n    r[2*q] = np.cumprod(1-2*q)\/(2*s2)**(q)    \n    \n    S = np.empty([0,p+1])\n\n    for i in range(p+1):\n        S = np.vstack([S,r[q+i]])\n        r = -r\n           \n    return S \n\ndef derivativeD(p):\n    \"\"\"\n    Construct derivative operator with embedding order p \n    Shifts all variables of a vector up by one and adds a zero at the bottom \n    \n    Code by Sherin Grimbergen (V1 2019) and Charel van Hoof (V2 2020)\n    \n    INPUTS:\n        p       - embedding order (>0)\n        \n    OUTPUT:\n        D       - derivative matrix ((p+1) x (p+1))\n    \"\"\" \n    D = toeplitz(np.zeros([1,p+1]),np.append(np.array([0,1]),np.zeros([1,p-1])))\n           \n    return D\n\ndef generalize_extend(y,p):\n    \"\"\"\n    Construct generalised value with embedding order p \n    By [y,0,0...]\n    \n    INPUTS:\n        y       - Input sensory signal\n        p       - embedding order (>0)\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')    \n    \n    if np.shape(y)==(p+1, 1):\n        # Generalised value, use it\n        y_tilde=y;\n        return y_tilde\n    \n    # Generalize sensory observation by adding zero's\n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y\n\n    return y_tilde\n\ndef sensor_generalize_exact(y,p,x,v,u):\n    \"\"\"\n    Construct generalised sensory observations with embedding order p \n    Generalize sensory observation by calculating the exact value \n    \n    For this example it has been calculated upto 3 derivatives\n\n    INPUTS:\n        y       - Input sensory signal\n        p       - embedding order (>0)\n        x       - Hidden state, needed to calculate the exact higher derivatives\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')       \n\n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y\n    if p>=1:\n        y_tilde[1] = dg_gp(x,v)*f_gp(x,v,u) \n    if p>=2:\n        y_tilde[2] = ddg_gp(x,v)*f_gp(x,v,u)**2 + dg_gp(x,v)*df_gp(x,v,u)*f_gp(x,v,u)\n    if p>=3:\n        y_tilde[3] = dddg_gp(x,v)*f_gp(x,v,u)**3 + 2*ddg_gp(x,v)*f_gp(x,v,u)**2*df_gp(x,v,u) + df_gp(x,v,u)*(ddg_gp(x,v)*f_gp(x,v,u)**2 + dg_gp(x,v)*df_gp(x,v,u)*f_gp(x,v,u))\n    \n    return y_tilde\n\ndef sensor_generalize_backward(y,i,p):\n    \"\"\"\n    Construct generalised sensory observations with embedding order p \n    Generalize sensory observation by approximating the derivaties from past observations\n    \n    For this example it has been calculated upto 4 derivatives\n    \n    INPUTS:\n        y       - Input sensory signal (array including all history thus far)\n        i       - Current timestamp, so y[i] is the current non-generalised sensory signal\n        p       - embedding order (>=0)\n        \n    OUTPUT:\n        y_tilde - Generalised sensory signal\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order < 0')    \n    \n    y_tilde = np.zeros((p+1,1))\n    y_tilde[0] = y[i]\n    if p>=1:\n        y_tilde[1] = (y[i]-y[i-1])\/dt\n        #print('Generalise backward input : ', y[i],' + ',y[i-1])\n    if p>=2 and i>=2:\n        y_tilde[2] = (y[i]-2*y[i-1]+y[i-2])\/dt**2\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2])\n    if p>=3 and i>=3:\n        y_tilde[3] = (y[i]-3*y[i-1]+3*y[i-2]-y[i-3])\/dt**3\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2],' + ',y[i-3])\n    if p>=4 and i>=4:\n        y_tilde[4] = (y[i]-4*y[i-1]+6*y[i-2]-4*y[i-3]+y[i-4])\/dt**4\n        #print('Generalise backward input : ', y[i],' + ',y[i-1],' + ',y[i-2],' + ',y[i-3],' + ',y[i-4])\n          \n    return y_tilde\n\ndef standard_vec(p):\n    x = np.zeros((p+1,1))\n    x[0] = 1\n    return x\n\ndef standard_vec_inv(p):\n    x = np.ones((p+1,1))\n    x[0] = 0\n    return x\n\ndef ones_vec(p):\n    x = np.ones((p+1,1))\n    return x\n\ndef fwd_model(p,x,v,u,fwd_method):\n    \"\"\"\n    Construct the forward model embedding order p \n    \n    For this example it has been calculated upto 3 derivatives\n\n    INPUTS:\n        p          - embedding order (>0)\n        x          - Hidden state\n        v          - Hidden cause\n        u          - Control signal\n        fwd_method - Method\n        \n    OUTPUT:\n        fwd - Forward model, note: for this specific notebook example\n    \"\"\" \n    if p<0:\n        # unknown embedding order, error\n        raise ValueError('Embedding order forward model < 0')       \n    if fwd_method == 'sign':\n        fwd = -1 * np.ones((p+1,1))\n    elif fwd_method == 'exact':        \n        fwd = np.zeros((p+1,1))\n        if p>=1:\n            fwd[1] = b_gp*dg_gp(x,v)\n        if p>=2:\n            fwd[2] = 2*b_gp*f_gp(x,v,u)*ddg_gp(x,v) +b_gp*df_gp(x,v,u)*dg_gp(x,v)\n        if p>=3:\n            fwd[3] = 3*b_gp*f_gp(x,v,u)**2*dddg_gp(x,v)+4*df_gp(x,v,u)*b_gp*f_gp(x,v,u)*dg_gp(x,v)+2*df_gp(x,v,u)*b_gp*f_gp(x,v,u)*ddg_gp(x,v)+df_gp(x,v,u)**2*b_gp*dg_gp(x,v)\n    elif fwd_method == 'sign+':        \n        fwd = np.zeros((p+1,1))\n        if p>=1:\n            fwd[1] = np.sign(dg_gp(x,v))\n        if p>=2:\n            fwd[2] = np.sign(ddg_gp(x,v))\n        if p>=3:\n            fwd[3] = np.sign(dddg_gp(x,v))\n    else:\n        raise ValueError('Unknown method to create forward model')     \n\n    return fwd  ","f62da254":"class ai_capsule():\n    \"\"\"\n        Class that constructs a group of neurons that perform Active Inference for one hidden state, one sensory input, one prior\n        In neurology it could e.g. represent a (micro) column or a neuron assembly\n\n        Version 0.3 including generalised coordinates of motion and action\n    \"\"\"\n    def __init__(self, dt, mu_x_init, p, Sigma_w, Sigma_z, a_mu, a_u, s2_w, s2_z, fwd_method, actiontime):  \n        \n        self.dt = dt    # integration step\n        self.mu_x= mu_x_init # initializing the hidden state, in generalised coordinates of motion\n        self.u = 0      # initialize the control signal as 0, no action\n        self.p = p      # embedding order, number of derevatives in generalised coordinates of motion\n        self.Sigma_w = Sigma_w # Estimated variance of the hidden state equals variance of the prior\n        self.Sigma_z = Sigma_z # Estimated variance of the sensory observation \n        self.s2_w = s2_w # Estimated variance of the Gaussian filter used to create the smoothened noise w\n        self.s2_z = s2_z # Estimated variance of the Gaussian filter used to create the smoothened noise z\n        self.alpha_mu = a_mu # perception learning rate\n        self.alpha_u = a_u # action learning rate \n        self.D = derivativeD(self.p)\n        self.I = np.identity(self.p+1)\n        self.Iv = np.ones((p+1,1))\n        self.Pi_w = inv(np.kron(temporalC(self.p,self.s2_w),self.Sigma_w)) # precision matrix of smoothened noise w\n        self.Pi_z = inv(np.kron(temporalC(self.p,self.s2_z),self.Sigma_z)) # precision matrix of smoothened noise z\n        self.std_vec_inv=standard_vec_inv(p)\n        self.std_vec=standard_vec(p)\n        self.fwd_method = fwd_method\n        self.actiontime = actiontime\n        \n        # Generative model parameters\n        self.a=-1 # generative model function of motion is -mu_x + mu_v, hence a = -1\n        self.b=1 # generative model function of motion is -mu_x + mu_v, hence b = 1\n        self.c=1 # generative model function op sensory mapping = mu_x, hence c = 1\n        #self.Ctilde= self.c * self.I # uncomment in case you want to tst a linear model for sensory observations\n    \n    def g(self,x,v):\n        \"\"\"\n            equation of sensory mapping of the generative model: g(x,v) at point x \n            Given as input for this example equal to cx\n        \"\"\"\n        return self.c*x\n    \n    def dg(self, x,v):\n        \"\"\"\n            Partial derivative of the equation of sensory mapping of the generative model towards x: g'(x,v) at point x \n            Given as input for this example equal to c\n        \"\"\"\n        return self.c\n    \n    def f(self,x,v):\n        \"\"\"\n            equation of motion of the generative model: f(x,v) at point x \n            f(x,v) = a* mu_x + b* mu_v, where a = -1, b=1\n        \"\"\"\n        return self.a*x + self.b*v\n    \n    def df(self,x,v):\n        \"\"\"\n            Partial derivative of equation of motion of the generative model: f'(x,v) at point x \n        \"\"\"\n        return self.a\n    \n    def ai_step (self, i, mu_v, y):\n        \"\"\"\n        Perform active inference step   \n\n        INPUTS:\n            i       - tic, timestamp\n            mu_v    - Hierarchical prior input signal (mean) at timestamp,  in generalized coordinates of motion\n            y       - sensory input signal at timestamp, in generalized coordinates of motion\n\n        INTERNAL:\n            mu_x      - Belief or hidden state estimation, in generalized coordinates of motion\n\n        \"\"\"\n\n        #-------------------------------#\n        #                               #\n        #           Prediction          #\n        #                               #\n        #-------------------------------#\n        \n        # Note that the predictions are in generalized coordinates of motion  \n        mu_x_hat = self.std_vec*self.f(self.mu_x[0],mu_v[0]) + self.std_vec_inv * self.df(self.mu_x[0],mu_v[0]) * self.mu_x\n        mu_y_hat = self.std_vec*self.g(self.mu_x[0],mu_v[0]) + self.std_vec_inv * self.dg(self.mu_x[0],mu_v[0]) * self.mu_x\n        \n        #-------------------------------#\n        #                               #\n        #        Prediction Error       #\n        #                               #\n        #-------------------------------#\n\n        # Note that the predictions erros are in generalized coordinates of motion \n        \n        eps_x = self.D.dot(self.mu_x) - mu_x_hat  # prediction error hidden state\n        eps_y = y - mu_y_hat #prediction error sensory observation  \n        \n        # In case a linear state space model is used the below calculation is equivalent\n        #eps_x = (self.D-self.Atilde).dot(self.mu_x) - mu_v  # prediction error hidden state\n        #eps_y = y - self.Ctilde.dot(self.mu_x) #prediction error sensory observation\n\n        #-------------------------------#\n        #                               #\n        # Prediction Error minimization #\n        #                               #\n        #-------------------------------#            \n     \n        # Calculate Free Energy to report out\n        F= 0.5*( eps_x.T.dot(self.Pi_w).dot(eps_x) + eps_y.T.dot(self.Pi_z).dot(eps_y)).item(0) \n        # Note, the item(0) is needed to translate the python matrix result to a scaler, e.g. [[1]] to 1\n        \n        # Gradient descent inference\/perception \n        # Note that in this example the function of motion is linear and hence can be calculated as below\n        Atilde=self.a * self.I\n        dFdmu_x = (self.D-Atilde).T.dot(self.Pi_w).dot(eps_x) - (self.dg(self.mu_x[0],mu_v[0]) * self.I ).T.dot(self.Pi_z).dot(eps_y)\n        dmu_x = np.dot(self.D,self.mu_x) - self.alpha_mu * dFdmu_x  \n        self.mu_x = self.mu_x + self.dt * dmu_x\n        \n        # In case a linear state space model is used with linear equation of sensory mapping the below calculation is equivalent\n        #Ctilde=self.c * self.I\n        #dFdmu_x = (self.D-Atilde).T.dot(self.Pi_w).dot(self.eps_x) - Ctilde.T.dot(self.Pi_z).dot(self.eps_y)\n        \n        # Gradient descent action \n        if i>self.actiontime:\n            fwd=fwd_model(self.p, self.mu_x[0], mu_v[0], self.u, self.fwd_method)          \n            dFdu = fwd.T.dot(self.Pi_z).dot(eps_y).item(0)\n            du = -self.alpha_u * dFdu  \n            self.u = self.u + self.dt * du\n        else:\n            self.u=0\n        \n\n        return self.u, F, self.mu_x[0] , self.g(self.mu_x[0],mu_v[0])\n    \n","4d68bda7":"class ai_capsule_ng():\n    \"\"\"\n        Class that constructs a group of neurons that perform Active Inference for one hidden state, one sensory input, one prior\n        In neurology it could eg represent a (micro) column\n        \n        Version 0.3a, without generalized coordinates of motion \n    \"\"\"\n    def __init__(self,dt, mu_x_init, Sigma_w, Sigma_z, a_mu, a_u, actiontime):   \n        self.dt = dt    # integration step\n        self.mu_x = mu_x_init   # initializing the best guess of hidden state by the hierarchical prior\n        self.u = 0      #initial no action\n        self.Sigma_w = Sigma_w #Estimated variance of the hidden state \n        self.Sigma_z = Sigma_z # Estimated variance of the sensory observation \n        self.alpha_mu = a_mu # Learning rate of the gradient descent mu (hidden state)\n        self.alpha_u = a_u # action learning rate \n        self.actiontime = actiontime\n    \n    def g(self,x,v):\n        \"\"\"\n            equation of sensory mapping of the generative model: g(x,v) at point x \n            Given as input for this example equal to the true generative process g_gp(x)\n        \"\"\"\n        return g_gp(x,v)\n    \n    def dg(self, x,v):\n        \"\"\"\n            Partial derivative of the equation of sensory mapping of the generative model towards x: g'(x) at point x \n            Given as input for this example equal to the true derivative of generative process dg_gp(x)\n        \"\"\"\n        return dg_gp(x,v)\n    \n    def f(self,x,v):\n        \"\"\"\n            equation of motion of the generative model: f(x,v) at point x \n            Given as input for this example equal to the prior belief v\n        \"\"\"\n        return v\n    \n    # def df(self,x): Derivative of the equation of motion of the generative model: f'(x) at point x\n    # not needed in this example \n  \n    def ai_step (self, i, mu_v, y):\n        \"\"\"\n        Perceptual inference    \n\n        INPUTS:\n            i       - tic, timestamp\n            mu_v    - Hierarchical prior input signal (mean) at timestamp\n            y       - sensory input signal at timestamp\n\n        INTERNAL:\n            mu      - Belief or hidden state estimation\n\n        \"\"\"\n        #-------------------------------#\n        #                               #\n        #           Prediction          #\n        #                               #\n        #-------------------------------#\n        \n        mu_x_hat = self.f(self.mu_x, mu_v)\n        mu_y_hat = self.g(self.mu_x, mu_v)\n        \n        #-------------------------------#\n        #                               #\n        #        Prediction Error       #\n        #                               #\n        #-------------------------------#\n        \n\n        eps_x = self.mu_x - mu_x_hat  # prediction error hidden state\n        eps_y = y - mu_y_hat #prediction error sensory observation\n        \n        \n        #-------------------------------#\n        #                               #\n        # Prediction Error minimization #\n        #                               #\n        #-------------------------------#   \n        \n        # Calculate Free Energy to report out\n        F = 0.5 * ((eps_x**2 \/ self.Sigma_w + eps_y**2 \/ self.Sigma_z)) #+ np.log(self.Sigma_w * self.Sigma_z) ))\n        \n        # Gradient descent inference\/perception \n        dFdmu_x = eps_x\/self.Sigma_w - self.dg(self.mu_x,mu_v) * eps_y\/self.Sigma_z\n        # Perception dynamics\n        dmu_x   = 0 - self.alpha_mu*dFdmu_x  # Note that this is an example without generalised coordinates of motion hence dmu_x'=0\n        # motion of mu_x \n        self.mu_x = self.mu_x + self.dt * dmu_x\n        \n        # Gradient descent action \n        if i>self.actiontime:\n            fwd = -1         \n            dFdu = fwd * eps_y\/self.Sigma_z\n            du = -self.alpha_u * dFdu  \n            self.u = self.u + self.dt * du\n        else:\n            self.u=0\n        \n        return self.u, F, self.mu_x , self.g(self.mu_x,mu_v)","3bc1c565":"def simulation (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\n    \"\"\"\n    Simulation for perceptual inference in a dynamic environment with generalised coordinates     \n   \n    INPUTS:\n        v             - Hydars actual desired depth, used in generative model\n        mu_v          - Hydars prior belief\/hypotheses of the desired depth (time series)\n        x_init        - Hydars actual starting depth, used in generative model\n        Sigma_w       - Variance of the hidden state \n        Sigma_z       - Variance of the sensory observation \n        noise_method  - white, smooth or none\n        a_mu          - Learning rate for mu\n        a_u           - Learning rate for u\n        p             - Embedding order of generalised motions of the generative model\n        gen_y_method  - Method to generalize the sensory observations: exact, backward, extend\n        fwd_method    - Method for the foward model: exact, sign \n    VARIABLES:\n        s2_w          - The variance of the Gaussian filter used to create the smoothened noise w\n        s2_z          - The variance of the Gaussian filter used to create the smoothened noise z\n        \n    \"\"\"\n    \n    # Init tracking\n    mu_x = np.zeros(N) # Belief or estimation of hidden state \n    F = np.zeros(N) # Free Energy of AI neuron\n    mu_y = np.zeros(N) # Belief or prediction of sensory signal\n    u = np.zeros(N) # control signal\n\n\n    # Construct noise signals with temporal smoothness:\n    np.random.seed(42)\n    if noise_method == 'white':\n        s2_w= 1e-5\n        s2_z= 1e-5\n    elif noise_method == 'smooth':\n        s2_w= 1\/2000\n        s2_z= 1\/2000\n        # And generate the smooth noise\n        w = makeNoise(Sigma_w,s2_w,t)\n        z = makeNoise(Sigma_z,s2_z,t)\n    else: #no noise\n        s2_w= 1\/64\n        s2_z= 1\/64\n    \n    # Init the generalised process\n    x = np.zeros(N) # True hidden state\n    y = np.zeros(N) # Sensory signal as input to AI neuron\n    x[0] = x_init\n    if noise_method == 'white':\n        y[0]=g_gp(x[0],v) + np.random.randn(1) * Sigma_z\n    elif noise_method == 'smooth':\n        y[0]=g_gp(x[0],v)+ z[0,0] \n    else: #no noise\n        y[0]=g_gp(x[0],v)\n\n    # Create active inference neuron\n    \n    if p==0:\n        # Not generalised, use the basic version\n        # initializing the initial hidden state by Hydars best guess: hierarchical prior\n        mu_x_init=mu_v[0]\n        capsule = ai_capsule_ng(dt, mu_x_init, Sigma_w, Sigma_z, a_mu, a_u, actiontime) \n    else:\n        # Generalised\n        # initializing the initial hidden state by Hydars best guess: hierarchical prior\n        mu_x_init_tilde = generalize_extend(mu_v[0],p) # generalize the prior\n        capsule = ai_capsule(dt, mu_x_init_tilde, p, Sigma_w, Sigma_z, a_mu, a_u, s2_w, s2_z, fwd_method, actiontime) \n\n    ssim = time.time() # start sim\n    \n    # Simulation\n\n    for i in np.arange(1,N):\n        # Generative process\n        if noise_method == 'white':\n            x_dot= f_gp(x[i-1],v, u[i-1]) + np.random.randn(1) * Sigma_w\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v) + np.random.randn(1) * Sigma_z\n        elif noise_method == 'smooth':\n            x_dot= f_gp(x[i-1],v,u[i-1]) + w[0,i]\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v) + z[0,i]\n        else: #no noise\n            x_dot=f_gp(x[i-1],v,u[i-1])\n            x[i]= x[i-1] + dt*x_dot\n            y[i] = g_gp(x[i],v)\n\n\n        if p==0:\n            ; # Not generalised, no need to generalize sensory observations\n        else:\n            # Create generalize sensory observations \n            if gen_y_method=='exact':\n                y_tilde = sensor_generalize_exact(y[i],p,x[i],v,u[i-1])\n                #print(y_tilde)\n            elif gen_y_method=='backward':\n                y_tilde = sensor_generalize_backward(y,i,p)\n            elif gen_y_method=='extend':\n                y_tilde = generalize_extend(y[i],p)\n            else:\n                raise ValueError('Unknown method to create sensory observation in generalised coordinates of motion')     \n        \n        # Active inference step       \n        if p==0:\n            u[i], F[i], mu_x[i], mu_y[i] = capsule.ai_step(i,mu_v[i],y[i])\n        else: \n            mu_v_tilde=generalize_extend(mu_v[i],p)\n            u[i], F[i], mu_x[i], mu_y[i] = capsule.ai_step(i,mu_v_tilde,y_tilde)\n\n    \n    # Print the results\n    tsim = time.time() - ssim\n    #print('Simulation time: ' + \"%.2f\" % tsim + ' sec' )\n\n    return F, mu_x, mu_y, x, y, u","b3e000f2":"x_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\nv = 0 \nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nactiontime=0.2\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,50,1,'exact','exact', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/64),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/64),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n","b6e9a01c":"x_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\nv = 0 \nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nactiontime=0.2\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,1,1,'exact','sign', actiontime*N) # \nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,50,1,'exact','sign', actiontime*N) # \nF3, mu_x3, mu_y3, x3, y3, u3 = simulation(v,mu_v,x_init,0.1,0.1,'no noise',1,1000,1,'exact','sign', actiontime*N) # \n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 50');\naxes[0].plot(t[1:],x2[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y2[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y2[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u2[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F2[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1000');\naxes[0].plot(t[1:],x3[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y3[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y3[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u3[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F3[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n","5027ef44":"x_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\nv = 0 \nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nactiontime=0.0\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1,1,'exact','sign', actiontime*N) # \nF2, mu_x2, mu_y2, x2, y2, u2 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,50,1,'exact','sign', actiontime*N) # \nF3, mu_x3, mu_y3, x3, y3, u3 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1000,1,'exact','sign', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 50');\naxes[0].plot(t[1:],x2[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y2[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y2[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u2[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F2[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1000');\naxes[0].plot(t[1:],x3[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y3[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y3[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u3[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F3[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n","f010aa38":"x_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\nv = 0 \nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nactiontime=0.0\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1000,1,'exact','sign+', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n","76324595":"x_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\nv = 0 \nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nactiontime=0.0\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1000,1,'backward','sign+', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","3e3591a9":"x_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\nv = 0 \nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nactiontime=0.0\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1000,1,'extend','sign+', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","90b69827":"# Note: a different generative process including motion towards causal state v\na_gp=-1 \nv = 40 \nx_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nactiontime=.50\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,1000,1,'backward','sign+', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","7115a37f":"# Note: a different generative process including motion towards causal state v and a swaying motion\nglobal tic # Apologies for the quick \"hack\"\ntic=0\ndef f_gp(x, v, u):\n    \"\"\"\n    Generative process, equation of motion: f_gp(x,u)    \n   \n    INPUTS:\n        x       - Hidden state, depth position in centimetres\n        v       - Causal state\n        u       - Control signal\n        \n    OUTPUT:\n        f_gp(x,v,u) - motion (speed) of the hidden state (depth) \n        \n    \"\"\"\n    global tic\n    \n    tic=tic+1\n    return a_gp*x + b_gp*u +v + 15*np.sin(tic*3\/360)\n\n\na_gp=-1\nv = 40 \nx_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\n\nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nactiontime=.50\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.1,'smooth',1,2500,1,'backward','sign+', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);","bc376c33":"a_gp=-1\nv = 40 \nx_init = 30.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\n\nmu_v = np.ones(N) * 17.0 # generative model, Hydars prior belief of the (target) temperature\nbump = signal.gaussian(800, std=120)*5\nmu_v[1000:1800]=17-bump\n\nactiontime=.20\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\nF1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.1,0.2,'smooth',3,9500,1,'backward','sign+', actiontime*N) # \n\nprint('w covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\nprint('z covariance matrix = ')\nprint(np.kron(temporalC(1,1\/2000),0.1) )\n\n# Plot results:\nfig, axes = plt.subplots(4, 1, sharex='col');\nfig.suptitle('Active Inference with action LR 1');\naxes[0].plot(t[1:],x1[1:],label='Generative process', color='m');\naxes[0].set_ylabel('Depth');\naxes[0].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[0].ticklabel_format(useOffset=False)\naxes[0].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[0].grid(1);\n\naxes[1].plot(t[1:],y1[1:],label='Generative process', color='m');\naxes[1].plot(t[1:],mu_y1[1:],label='belief');\naxes[1].plot(t[1:],mu_v[1:],label='Prior belief', color='black')\naxes[1].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[1].set_ylabel('Temp');\naxes[1].ticklabel_format(useOffset=False)\naxes[1].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[1].grid(1);\n\naxes[2].plot(t[1:],u1[1:],label='Control signal u');\naxes[2].set_ylabel('Control');\naxes[2].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[2].ticklabel_format(useOffset=False)\naxes[2].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[2].grid(1);\n\n#axes[3].semilogy(t[1:],F3[1:],label='p=3');\naxes[3].plot(t[1:],F1[1:],label='Free Energy');\naxes[3].axvline(x=actiontime*T, color='r', linestyle='--')\naxes[3].set_xlabel('time [s]');\naxes[3].set_ylabel('FE');\naxes[3].legend(bbox_to_anchor=(1.05, 1), loc='upper left', borderaxespad=0.)\naxes[3].grid(1);\n\n\n\n\n#x_init = 25.0 # generative process initial depth Hydar, 30 centimeters corresponds to 13.3 degrees\n#v = 0 # in this example v is not used\n#mu_v =  17 + np.sin(t)*3# generative model, Hydars prior belief of the (target) temperature\n#actiontime=0.2\n# simulation parameters (v, mu_v, x_init, Sigma_w, Sigma_z, noise_method, a_mu, a_u, p, gen_y_method, fwd_method, actiontime):\n#F1, mu_x1, mu_y1, x1, y1, u1 = simulation(v,mu_v,x_init,0.03,1,'no noise',1,1000,1,'backward','sign+', actiontime*N) # \n\n","22fca503":"## Generative model\n \n\nThe generative model (the model in the Hydra brain to encode a probabilistic model of the environment\/world in which it is immersed) is kept as simple as possible (in terms of the function of motion and function of sensory mapping). As usual, it is expressed in generalized coordinates of motion.: \n\n$$ \\mathcal{D} \\tilde \\mu_x = \\tilde f(\\tilde \\mu_x, \\tilde \\mu_v) + \\tilde w   \\\\\n \\tilde y = \\tilde g (\\tilde \\mu_x, \\tilde \\mu_v) + \\tilde z$$  \n\nwhere\n* Often also written as e.g. $\\tilde f(\\tilde x, \\tilde v)$ but selected here the notation form $\\tilde f(\\tilde \\mu_x, \\tilde \\mu_v)$ to highlight these are brain estimates.\n* The function of motion  $\\tilde f(\\tilde \\mu_x, \\tilde \\mu_v)$ is shorthand for $\\begin{bmatrix} f(\\mu_x,\\mu_v), \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}', \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}''  , \\partial_{\\mu_x}f(\\mu_x,\\mu_v)\\cdot{\\mu_x}'''... \\end{bmatrix}$, \n     * where $f(x,v)$ of this example is given as input (assumed already learned by Hydar) and defined as  \n     \n     $$f(\\mu_x,\\mu_v)=-\\mu_x+\\mu_v$$  \n     \n     In the Software implemented as $f(\\mu_x,\\mu_v)=a\\mu_x+b\\mu_v$ with $a=-1$; $b=1$. In short, Hydar beliefs it is moving towards its top-down hierarchical prior $\\mu_v$\n* The function of sensory mapping $\\tilde g(\\tilde \\mu_x, \\tilde \\mu_v)$ is shorthand for $\\begin{bmatrix} g(\\mu_x,\\mu_v), \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}', \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}''  , \\partial_{\\mu_x}g(\\mu_x,\\mu_v)\\cdot{\\mu_x}'''... \\end{bmatrix}$,\n    * where $g(\\mu_x,\\mu_v)$ is given as input (assumed already learned by Hydar) and defined as  \n    \n    $$g(\\mu_x,\\mu_v)=\\mu_x$$  \n    \n    In the Software implemented as $g(\\mu_x,\\mu_v)=c\\mu_x$ with $c=1$.\n\n\n## Generalized Free Energy\nAs explained in the [second active inference notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2), the Free Energy for one active inference capsule in generalized coordinates of motion (applying the Laplace\/mean-field approximation) is:\n$$\\mathcal{F}(\\tilde y, \\mu) = \\frac{1}{2}\\tilde\\varepsilon^T \\tilde\\Pi \\tilde\\varepsilon - \\frac{1}{2} ln\\begin{vmatrix}\n\\tilde\\Pi\n\\end{vmatrix} = \\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y}) - \\frac{1}{2} ln\\begin{vmatrix}\n\\tilde\\Pi\n\\end{vmatrix}$$\nWhere\n* $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) $  is the the motion prediction error.\n* $\\tilde{ \\varepsilon}_y =  \\tilde y - \\tilde g (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) $ is the sensory prediction error. \n* In this notebook, we assume noise levels are constant during action and inferencing and the Free Energy calculated (because $-\\frac{1}{2} ln\\begin{vmatrix}\\tilde \\Pi\\end{vmatrix}$ is constant with respect to finding the optimum $\\tilde \\mu_x$ or $u$) as:\n\n$$\\mathcal{F}(\\tilde y, \\mu) =\\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y})$$\n\n\n\n\n## Inference by gradient descent\nInference by gradient descent is exactly the same as explained in the [second code notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2), the code is re-used.  \nThe gradient descent can be compactly written in matrix notation as: \n$$    \\dot{\\tilde{\\mu}}_x = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x}  $$\n\nand the partial derivative of the Free energy for this example can be written as:\n$$\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} =\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$$\n\nwere\n\n* generalized motion prediction error $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde{ \\mu}_v) =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde A \\tilde{ \\mu}_x - [b\\cdot\\mu_v,0,0,..]^T  $ and $\\tilde A = a \\cdot I_{p+1}$\n* generalized sensory prediction error $\\tilde{ \\varepsilon}_y= \\tilde y -\\begin{bmatrix}g({\\mu}_x,{\\mu}_v)\\\\ 0\\\\ 0\\\\ .\\\\ .\\end{bmatrix}-\\begin{bmatrix}0\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}''\\\\ .\\\\ .\\end{bmatrix}  = \\tilde y - \\begin{bmatrix}\\mu_x\\\\ \\mu_x'\\\\ \\\\ \\mu_x''\\\\ .\\\\ .\\end{bmatrix}=\\tilde y - \\tilde C \\tilde{ \\mu}_x$ where $\\tilde C = c \\cdot I_{p+1}$  \n* $\\tilde \\Pi_w$: the precision matrix of the generalised noise $\\tilde w$ expresses the amount of uncertainty in the prediction error $\\varepsilon_{x}$ at all orders of motion and is calculated as:\n$$\\tilde \\Pi_w= {\\tilde \\Sigma_w}^{-1}= (S(s_w^2) \\otimes \\Sigma_w )^{-1}  $$\n* $\\tilde \\Pi_z$: the precision matrix of the generalised noise $\\tilde z$ expresses the amount of uncertainty in the prediction error $\\varepsilon_{y}$ at all orders of motion and is calculated as:\n$$\\tilde \\Pi_w= {\\tilde \\Sigma_z}^{-1}= (S(s_z^2) \\otimes \\Sigma_z )^{-1}  $$\n","e8682923":"### Notes\nHydar is still able to survive and get to the temperature set by the prior, nice.  \nPlaying around with the action learning rate: \n+ LR 1: the temperature is a rigged line due to the noise, the depth line is smooth but Hydar overshoots and needs an oscillation to reach the depth corresponding to 17 degrees.\n+ LR 50 or 1000: strong sharp-peaked actions that overshoot with some quick oscillations to reach the target depth. The depth line is very jagged almost as if Hydar is very fast reacting to the noise and therefore constantly correcting.\n\n\n","34b90666":"## Generalized sensory observations\nThe generative model of Hydar expects sensory observations in generalized coordinates of motion ($\\tilde y$). This is done exactly the same as explained in the [second code notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2) and also used in the [fourth code notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-4), the code is re-used.  \n\nWhat we need to calculate is $\\tilde y=\\begin{bmatrix} y, y', y'', y''', ...\\end{bmatrix}^T$. In this notebook, as usual there are 3 possibilities to create these types of sensory signals. The experiments start with the exact generalized coordinates of motion of the sensory signal, but we will try if Hydar can also survive with simple backward estimates.\n* Expand, the simplest method by adding zeros for all higher orders of motion, e.g. 42 in generalized coordinates of motion order p=3 becomes $[42,0,0,0]^T$. \n* Exact, calculate the generalized coordinates of motion of the sensory signal by the exact differential equations of the generative process. See the [second code book](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-2) for an explanation how these are calculated.\n* Backward, calculate the higher-order motions by using the backward [Taylor expansion](https:\/\/en.wikipedia.org\/wiki\/Taylor_series), using the previous sensory values to provide a first-order numerical approximation of the higher-order derivatives. e.g. $speed=\\frac{position_{(t)} - position_{(t-1)}}{dt}$. I opted here to only use past sensory observations (hence I called it backward) and not future ones since Hydar cannot predict the future (especially because in this notebook the future sensory reading are impacted by Hydars actions).","6d3f05fb":"## Experiment 5.02 - With a simplified forward model\nThe same as experiment 5.01 but simplified even further with the fwd model estimated by a simple sign: -1  ","e8b60afe":"## Notes\n\nYes, Hydar is able to move as it desires, even with sway in the water, with noise, with a very basic generative and forward model, with only a few neurons needed for a simple active inference capsule!\n+ Note that I had to tweak the learning rates and ration $\\sigma_w$-$\\sigma_z$to get above performance. Especially because  following its prior (get deeper to get to its food) has a time-lag. (the purple temperature is shifting in time compared to the black prior belief)\n\nDespite complex generative processes in the environment, Hydar can still take action to get to its desired temperature, even with a very simple generative model. Interesting!","58cef152":"### Notes\nHydar is still able to move and get to its desired temperature even with estimating the higher-order sensory observations based on the past observation by Hydar, even when the sensory observations are noisy. Hydar is estimation speed, acceleration, etc based on its own sensory observations. (In fact, the embedding order = 1 by design to keep the brain of Hydar as simple as possible, so it is only estimation the speed.)","afb61989":"## Experiment 5.08 - moving water - 2\nWhat if the generic process is not linear? Below an experiment with a swaying motion in the water that causes hydar to move up and down.","692d1680":"## Experiment 5.06 - simplified generalized noise estimation - 2\nCan we make the estimation of the generalized sensory signal as simple as [y,0,0,..]?","a1b3712d":"## Experiment 5.03 - Colored noise\nNow let's add noise to the generative process and see if Hydar is still able to move to its preferred temperature.","ed3f283a":"## Experiment 5.07 - moving water\nUntil now, in all experiments, including the ones of the previous code notebook, the movement was caused by the control signal of Hydar. But what if the water is moving, could Hydar still survive?  \nIn this experiment, Hydar will sink to 40 centimeters if no action is taken.","4b0811e0":"## Action by gradient descent\nAs explained in the [fifth notebook](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-5) the gradient descent for a single active inference capsule in generalized coordinates of motion can be compactly written as: \nThus gradient descent can be compactly written as:\n\u200b\n$$    \\dot{u}  = -  \\frac{\\partial \\tilde{y}}{\\partial u}^\\top \\tilde\\Pi_z \\tilde\\varepsilon_y $$\n\u200b\nwhere $ \\frac{\\partial \\tilde{y} }{\\partial u}^\\top$ is the forward dynamic model and defined as $\\begin{bmatrix}\\frac{\\partial y}{\\partial u}, \\frac{\\partial y'}{\\partial u}, \\frac{\\partial y''}{\\partial u}, . .\\end{bmatrix}$  thus the change in all the derivatives of the sensory input with respect to the control actions (model of how sensory data changes with actions).  \n\nIn this notebook, we will a forward dynamic model approximated by sign (+1, or -1) because we want to see if Hydar can survive with the most simple generative model. \n","8dfacc87":"## Experiment 5.05 - simplified generalized noise estimation\nOne more simplification, until now the generalized sensory observations were exactly calculated based on the actual generative process. Since we are experimenting to have an elementary prehistoric imaginary aquatic ancestor, it can't have access to the actual generative process and can only estimate the higher-order motions (e.g. speed, acceleration) based on its position over time. Let's see if Hydar can still survive with a backward method to estimate the higher-order sensory signals.\n","395899ef":"## Notes\nThe oscillations are gone.\nIn experiment 5.03 both position and speed are in the equations but the position is divided by 0.1 and speed divided by 100. So the position error is a factor 1000 stronger, hence the position error is determining. With a high learning rate, you get this typical behavior of overshooting (similar to a [PID controller](https:\/\/www.youtube.com\/watch?v=XfAt6hNV8XM&t=1s) without the \"ID\" with high gains)\nIn this experiment the sign+ forward model is used, so the position is not in the equation and the higher-order (speed) estimations determines the prediction error. (similar to a PID controller with the Integrator and Derivative information in the mix)\n\n","5b4d7318":"## How the brain might function - code example 5\n### Free Energy Principle tutorial without a PhD\n  \n<img src=\"https:\/\/cdn.pixabay.com\/photo\/2018\/05\/08\/08\/44\/artificial-intelligence-3382507_960_720.jpg\" width=500>\n<center>Image by <a href=\"https:\/\/pixabay.com\/users\/geralt-9301\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Gerd Altmann<\/a> from <a href=\"https:\/\/pixabay.com\/?utm_source=link-attribution&amp;utm_medium=referral&amp;utm_campaign=image&amp;utm_content=3382507\">Pixabay<\/a> <\/center>   \n<br>\n\nWelcome to my notebook on Kaggle. I did record my notes with examples so it might help others in their journey to understand **Active Inference** minimizing the underlying **Free Energy**. Neuroscience has produced a candidate which suggests that several global brain theories might be unified within a free-energy framework: [Free Energy Principle](https:\/\/en.wikipedia.org\/wiki\/Free_energy_principle) (FEP) by [Karl Friston](https:\/\/en.wikipedia.org\/wiki\/Karl_J._Friston): The free-energy principle is an attempt to explain the structure and function of the brain, starting from the very fact that we exist.\n\nThis is a code example notebook and it belongs to a series of notebooks on the Free Energy Principle tutorial without a PhD. If you are interested to have a deep understanding of this code please read the \"Free Energy Principle tutorial without a PhD\" series ([part 1](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-1), [part 2](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-2), [part 3](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-3), [part 4](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-4)). There is a lot to explain but I promise you an excellent journey into something that might hold the key to human-level AI.","ee43b34e":"### Notes\n\nInterestingly, with the simplest generative model, Hydar is steering itself to the desired temperature. I guess it is a good sign for an elementary aquatic animal to be able to survive with a few neurons.\n\nIt is also interesting to compare this result to experiment 4.01 of the previous code notebook. Both times Hydar starts at 30 centimeter depth and moves to 25 centimeter depth. Although here Hydar does not have the generative model to translate temperature to depth (function of sensory mapping g) the result is still that Hydar moves to 17 degrees and thus 25 centimeter depth. Both experiments around 5 seconds, with quite similar control signals. In other words, in the previous notebook 4.01 the hidden state was depth in centimeters and the prior was set as the desired depth. In the notebook, the hidden state is temperature and the prior is set in the desired temperature. The ratio temperature-depth is not explicit coded anymore in the active inference neuron but apparently also not needed to steer the control signal to get to the desired temperature.","a78c1ba3":"## Notes\nNo, we can't. By not estimating the higher-order sensory signal (e.g. speed) and simply set it to zero does not work (as expected). Hydar cannot move or maintain its desired temperature. With the [0,-1] forward model the speed prediction error is the key steering signal and since the error is calculated by comparing it to 0 it doesn't work. Interesting temperature graph though.  \nIt could work by selecting a [-1, -1] forward model since the speed is a factor 1000 less in the weighting (see notes experiment 5.04), so almost ignored.","d602fc5e":"## Experiment 5.01 - The first with a simplified generative model\nIn this example, Hydar is getting cold. Its temperature is 13.3 degrees and it wants to move to a comfortable temperature of 17 degrees. Its generative model is encoding a most simple model:  \n$f(\\mu_x,\\mu_v)=\\mu_v -\\mu_x$ In short, Hydar beliefs it is moving towards its top-down hierarchical prior $\\mu_v$ (17 degrees).  \n$g(\\mu_x,\\mu_v)=\\mu_x$  In short, the hidden state Hydar is inferring is the temperature.\n\nFor this example, there is no noise in the generative process yet (although the generative model expects noise to be present) to best see how the belief develops.","e199004d":"# Generative process\n\nThe generative process (the simulation environment simulating the external environment\/world generating the sensory states in this example) is the same as in the [fourth code example notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-4\/) and is defined by :\n\n$$ \\begin{align*} \\dot x = f_{gp}(x,v,u) + w &\\Rightarrow  \\dot x = a_{gp}x + b_{gp}u + v+ w \\\\\ny = g_{gp}(x,v)+z &\\Rightarrow y = t_0 -\\frac{16}{1+e^{5-\\frac{x}{5}}}+ z \\: \\:; t_0=25 \\end{align*}$$   \n  \nwhere\n* $x$ is the position (depth in centimeters) and $\\dot x$ expresses the motion of $x$\n* $y$ is the temperature (degrees Celsius)\n* $v$ is the causal state of the generative process(e.g. a certain depth)\n* u  is the control signal, the action that can be performed on the environment.\n* The function of motion $f_{gp}(x,v,u)$ of this example is linear and more generic implemented as  $a_{gp}x+b_{gp}u + v$. For example, in the first experiments  $a_{gp}=0$ and $b_{gp}=1$, basically Hydra can set its own speed $\\dot x = u + random fluctuations$. Later experiments $a_{gp}$ and $v$ also get values to simulate moving water.\n* The function of sensory mapping  $g_{gp}(x,v)$  of this example is the same as in previous examples (non-linear function representing a thermocline)","47f64a4e":"To recap all you need to perform active inference in the table below:\n\nWhat| Symbol | Description |\n--- | --- | --- |\nposition | $x$  | Generative process; The depth of Hydar in centimetres | \nStarting position | $x_{init}$  | The initial depth of Hydar in the generative process | \nprior | $v$  | Hidden cause in the generative process | \ntemperature | $\\tilde \\mu_x$  | Hydars belief or estimation of the temperature, the hidden state it tries to infer |\nbody temperature sensor | $\\tilde y$  | single sensory observation, in this case the temperature.  | \nprior | $\\tilde \\mu_v$  | Hydars prior belief of the desired temperature | \ncontrol signal | u | actions, control signal, The action that can be performed by Hydar on the environment|\nfunction of sensory mapping| $g(\\mu_x,\\mu_v)$  | Given as input, <br>$g(\\mu_x,\\mu_v) = \\mu_x$   | \nderivative function of sensory mapping| $g'(\\mu_x,\\mu_v)$  | Given as input and is equal to 1  | \nfunction of motion | $f(\\mu_x,\\mu_v)$  | Given as input <br>$f(\\mu_x,\\mu_v) = a*\\mu_x + b*\\mu_v $ where a=-1 and b = 1|\nderivative of function of motion | $f'(\\mu_x,\\mu_v)$  | Given as input $f'(\\mu_x) = a $ |\nFree Energy | $\\mathcal{F}(y,\\mu)$  | $\\mathcal{F}(\\tilde y, \\mu) = \\frac{1}{2}\\tilde\\varepsilon^T \\tilde\\Pi \\tilde\\varepsilon=\n\\frac{1}{2}(\\tilde\\varepsilon_{x}^T \\tilde\\Pi_{w} \\tilde\\varepsilon_{x}+\\tilde\\varepsilon_{y}^T \\tilde\\Pi_{z} \\tilde\\varepsilon_{y})$ |\nsensory prediction error | $\\tilde \\varepsilon_y$  | $\\tilde{ \\varepsilon}_y =  \\tilde y - \\tilde g (\\tilde{ \\mu}_x, \\tilde\\mu_v) $ |\nmotion prediction error | $\\tilde \\varepsilon_x$  | $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde f (\\tilde{ \\mu}_x,\\tilde\\mu_v) $ |\nDerivative Free Energy | $\\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x}$  | $\\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y$ |","13cba2e3":"### Notes\nHydar is still able to move and get to its desired temperature despite the movement caused by the generative process, go Hydar!\n+ Hydar sinks to 40 centimeters depth by the generative process in the first part where it cannot take action.\n+ Halfway through the experiment, Hydar is enabled to take action and it drives towards the desired temperature.\n+ After reaching 17 degrees Hydar needs to keep taking action to remain at the desired temperature (else it will go down again)","2477ea7e":"## Experiment 5.04 - Colored noise alternative\nThe same experiment as 5.03 but now with the sign+ forward model. In the previous experiment the forward model is [-1, -1] so both position and speed taken into account. In this experiment the forward model is [0, -1] so no position prediction error is in the calculations.","e7138a71":"# Experiments\nLet's see the theory in action and showcase active inference in our simulation environment. In these examples, Hydar can influence its body temperature because it the capability to move up and down into warmer or colder water. It will do so by minimizing the Free Energy of its biased generative model. It is biased because Hydar believes it is moving towards its hierarchical prior $\\mu_v$.\n","4a584d08":"## Experiment 5.09 - Dynamic prior\nSuppose Hydar needs to move to colder water to get food but it cannot stay too long because it gets too cold. So, it moves down to feed and needs to get back to warmer water. In the experiment below the water is moving, and Hydar has dynamic priors (ove down to feed and back up again) causing it to move as well. Is the elementary being equipped with only one active inference neuron still able to move as it desires?","4f27672a":"### Notes\nHydar is still able to get to the desired temperature.  \nPlaying around with the action learning rate: \n+ if the learning rate decreases it starts to look like experiment 5.01; see above example with LR 1\n+ If the learning is kept the same as previous experiment, e.g. 50, the control signal gets a sharper peak, much stronger initial reaction compared to 5.01. But it \"overshoots\" and has some fast oscilations to \"get into the curve\". This is because compared to experiment 5.01 in the estimated fwd model of -1 also the prediction error of the position is taken into account in the forward model, hence a higher prediction error and thus stronger control signal. \n+ if the learning rate increases the initial control signal peak becomes sharper and sharper, and with higher learning rates the oscilations are not visible anymore in the graph.\n\n\n","36b08faf":"## Notes\nHydar is still able to move to its desired temperature of 17 degrees even with a non-linear generative process causing Hydar to float up and down.\n\n+ Hydar sinks to the depth and moves with the sway up and down as dictated by the generative process in the first part where it cannot take action. \n+ Halfway through the experiment, it is enabled to take action and Hydar drives towards the desired temperature\n+ After reaching 17 degrees Hydar needs to keep taking action to remain at the desired temperature (else it will start following the sway again)","7283b285":"# Active inference code version 0.5\nThe flow diagram \"prediction -> prediction error -> prediction error minimization\" as explained in the notebook [learn by example active inference in the brain 5](https:\/\/www.kaggle.com\/charel\/learn-by-example-active-inference-in-the-brain-5) is implemented in the code in this notebook.  \n\u200b\n<img src=\"https:\/\/i.imgur.com\/0BZMMDR.jpg\" width=900>\n\u200b\nWhere the 2 predictions errors are:\n  * $\\tilde{ \\varepsilon}_x =  \\mathcal{D} \\tilde{ \\mu}_x - \\tilde A \\tilde{ \\mu}_x - \\tilde \\mu_v  $ where $\\tilde A = a \\cdot I_{p+1}$\n  * $\\tilde{ \\varepsilon}_y= \\tilde y -\\begin{bmatrix}g({\\mu}_x,{\\mu}_v)\\\\ 0\\\\ 0\\\\ .\\\\ .\\end{bmatrix}-\\begin{bmatrix}0\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}'\\\\ \\partial_{\\mu_x}g({\\mu}_x,{\\mu}_v)\\cdot{{\\mu}_x}''\\\\ .\\\\ .\\end{bmatrix} = \\tilde y - \\begin{bmatrix}\\mu_x\\\\ \\mu_x'\\\\ \\\\ \\mu_x''\\\\ .\\\\ .\\end{bmatrix}=\\tilde y - \\tilde C \\tilde{ \\mu}_x$ where $\\tilde C = c \\cdot I_{p+1}$\n  \nAnd the prediction error minimization is done by\n* $    \\dot{\\tilde{\\mu}}_x = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\frac{\\partial \\mathcal{F}(\\tilde y,\\mu)}{\\partial \\tilde{\\mu}_x} = \\mathcal{D}\\tilde{\\mu}_x -  \\frac{\\partial \\tilde{\\varepsilon}^{\\top}}{\\partial \\tilde{\\mu}_x} \\tilde\\xi = \\mathcal{D}\\tilde{\\mu}_x - \\alpha_x \\left( \\left( \\mathcal{D} - \\tilde A \\right)^T\\tilde{\\Pi}_{{w}}\\tilde{\\varepsilon}_x + \\left( - \\frac{g({\\mu}_x,{\\mu}_v)}{\\partial{\\mu}_x}  \\cdot I_{p+1} \\right)^T\\tilde\\Pi_{{z}}\\tilde\\varepsilon_y \\right) $\n* $    \\dot{u}  = -  \\frac{\\partial \\tilde{y}}{\\partial u}^\\top \\tilde\\Pi_z \\tilde\\varepsilon_y $\n* Where the [forward Euler method](https:\/\/en.wikipedia.org\/wiki\/Euler_method) is used to execute the motion of $\\dot\\mu_x$ and $\\dot u$.  \n\u200b","615eb522":"# Scope code example 5\nThe experiment in this notebook is the same as the previous [fourth code example notebook](https:\/\/www.kaggle.com\/charel\/active-inference-code-by-example-4\/). However, since Hydar is an elementary prehistoric imaginary aquatic ancestor, I have experimented in this notebook with the most simple generative models to see if Hydar can still survive. It goes back to the argument of evolutionary plausible. The function of sensory mapping is in the notebook a simple 1:1 mapping of the hidden state. In other words, the hidden state Hydar is estimating, and sensing, is the temperature. Action to reach the desired temperature moves Hydar up and down.\n\n<img src=\"https:\/\/i.imgur.com\/SKdleI9.jpg\" width=800>\n\nAnd as you can see in this notebook, despite complex generative processes in the environment, Hydar can still take action to get to its desired temperature, even with a very simple generative model. Interesting!\n\nScope of the example: \n* One active inference capsule (single hidden state x, single sensory channel y, and single hierarchical prior v) \n* With the capability to act upon the environment\n* With generalized coordinates of motion  \n* Dynamic environment\n* The generative model $\\mu_\\theta$ and expected precision of uncertainty $\\mu_\\lambda$ are invariant during the process and for this example given as input. Remember ${\\mu}_x$ is estimated by fast neuronal states while $\\mu_\\theta$ and $\\mu_\\lambda$ adapt on slower timescales (e.g. synaptic efficacy) so invariant during action and perceptual inference. We simply assume the generative model \/ noise estimation has already been learned and is known (so, the function of motion and sensory mapping are given as input).   \n* The brain estimate for the hierarchical prior ($\\mu_v)$ is given as input, which is the prior in this context\n* Active inference by minimizing the Free Energy for one active inference capsule:   \n\n$$\\tilde \\mu_x=\\underset{\\tilde \\mu_x }{Argmin}\\:  \\mathcal{F}( \\tilde y,\\mu) \\: \\: \\: \\:  \\: \\: \\: \\: u=\\underset{\\tilde u }{Argmin}\\:  \\mathcal{F}( \\tilde y,\\mu)$$ \n* by iteratively taking steps proportional to the negative of the partial derivative of the Free Energy with respect to $\\mu_x$ resp $u$.\n"}}