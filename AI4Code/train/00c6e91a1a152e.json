{"cell_type":{"86edd9cd":"code","aff0ef47":"code","7508a69a":"code","a32caf2c":"code","46f300cb":"code","6d5690bb":"code","3c396c32":"code","48cb6c6b":"code","d11428f2":"code","caafa917":"code","4aec3f5e":"code","bf5e19e7":"code","5445705a":"code","df1d9553":"code","03ca828a":"code","99e4bcd0":"code","5da2de65":"code","4ce9b5ae":"code","af23c8fb":"code","760eb176":"code","710ce6e2":"code","5c508d5c":"code","7a12b527":"code","2c523b5f":"code","657506cb":"code","bd1c7b06":"code","9700ff04":"code","b148b8c4":"code","9bc2540f":"code","c0e78f64":"code","10b19dc0":"markdown","b95f3a20":"markdown","a59d54e8":"markdown","d21817b1":"markdown","2dc66f11":"markdown","097f5559":"markdown","456d99ad":"markdown","2341d948":"markdown","8db5d929":"markdown","0f3b4f3e":"markdown","00a0eb6a":"markdown","79205dd3":"markdown","cc916836":"markdown","9f9888e4":"markdown","41bf0343":"markdown","421cc45c":"markdown","23af0a9d":"markdown","e70f3073":"markdown","1a0b5065":"markdown","a4d09bf7":"markdown","2ea5d65a":"markdown","779317c4":"markdown","a4c5f720":"markdown","1cb4c36a":"markdown","529db6ee":"markdown","1279cb36":"markdown","1b80b9be":"markdown"},"source":{"86edd9cd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","aff0ef47":"FILE_PATH = '\/kaggle\/input\/digit-recognizer\/'","7508a69a":"train_data_all = pd.read_csv(FILE_PATH + 'train.csv')\ntest_data_all = pd.read_csv(FILE_PATH + 'test.csv')\n\nprint(train_data_all.shape, test_data_all.shape)","a32caf2c":"train_data_all.head()","46f300cb":"test_data_all.head()","6d5690bb":"print('List of unique labels: ' + str(sorted(train_data_all['label'].unique())))\nprint('Counts of unique labels:')\ntrain_data_all['label'].value_counts().sort_index()","3c396c32":"x = train_data_all.drop(\"label\", axis = 1)\ny = train_data_all[\"label\"]\n\nprint(x.shape)\nprint(y.shape)\n\nprint(type(x), type(y))","48cb6c6b":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.3, random_state = 1)\n\nprint(x_train.shape, y_train.shape)\nprint(x_val.shape, y_val.shape)","d11428f2":"x_train_reshaped = np.array(x_train).astype('float64').reshape(-1, 28, 28, 1)\nx_val_reshaped = np.array(x_val).astype('float64').reshape(-1, 28, 28, 1)\n\nprint(x_train_reshaped.shape)\nprint(x_val_reshaped.shape)\n\nprint(x_train_reshaped[0].dtype)\nprint(x_val_reshaped[0].dtype)","caafa917":"fig = plt.figure(figsize = (15, 10))\n\nfor i in range(12):\n    plt.subplot(4, 3, i+1)\n    plt.imshow(x_train_reshaped[i])\n\nplt.show()","4aec3f5e":"x_train_reshaped = x_train_reshaped \/ 255.0\nx_val_reshaped = x_val_reshaped \/ 255.0\n\nx_train_reshaped[0].shape","bf5e19e7":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, Flatten, BatchNormalization","5445705a":"model = Sequential()\n\nmodel.add(Conv2D(64, kernel_size = 3, activation = \"relu\", padding=\"same\", input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, kernel_size = 3, activation = \"relu\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, kernel_size = 5, strides=2, activation = \"relu\", padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, kernel_size = 3, activation = \"relu\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, kernel_size = 3, activation = \"relu\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, kernel_size = 5, strides=2, activation = \"relu\", padding=\"same\"))\nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.4))\n\nmodel.add(Conv2D(64, kernel_size = 4, activation = \"relu\"))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.3))\n\nmodel.add(Dense(units = 10, activation = \"softmax\"))","df1d9553":"model.summary()","03ca828a":"from keras.utils import plot_model\nfrom IPython.display import Image\n\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\nImage(\"model.png\")","99e4bcd0":"model.compile(optimizer = \"adam\", loss = \"sparse_categorical_crossentropy\", metrics = [\"accuracy\"])","5da2de65":"from keras.callbacks import ReduceLROnPlateau\n\nreduce_lr = ReduceLROnPlateau(monitor='val_acc', factor=0.5,\n                              patience=2, min_lr=0.00001)","4ce9b5ae":"from tensorflow.keras.callbacks import LearningRateScheduler\n\ncallback = LearningRateScheduler(lambda x: 1e-3 * 0.95 ** x)","af23c8fb":"from keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(\n        featurewise_center=False,\n        samplewise_center=False,\n        featurewise_std_normalization=False,\n        samplewise_std_normalization=False,\n        zca_whitening=False,\n        rotation_range=10,\n        zoom_range = 0.1,\n        width_shift_range=0.2,\n        height_shift_range=0.2,\n        horizontal_flip=False,\n        vertical_flip=False)\n\ndatagen.fit(x_train_reshaped)","760eb176":"history = model.fit(datagen.flow(x_train_reshaped,y_train, batch_size=64),\n                         epochs=50, validation_data=(x_val_reshaped,y_val),\n                         callbacks=[reduce_lr, callback],\n                         verbose=2, steps_per_epoch=x_train_reshaped.shape[0] \/\/ 64)","710ce6e2":"for metric in ['accuracy', 'loss']:\n    plt.plot(history.history[metric])\n    plt.plot(history.history['val_'+metric])\n    plt.title('training '+metric+' plot', fontsize=18)\n    plt.legend(['train', 'validation'])\n    plt.xlabel('epochs', fontsize=14)\n    plt.ylabel(metric, fontsize=14)\n    plt.show()","5c508d5c":"x_test_reshaped_normalized = np.array(test_data_all.copy()).astype('float64').reshape(-1, 28, 28, 1) \/ 255.0\n\nprint(x_test_reshaped_normalized.shape)\nprint(x_test_reshaped_normalized[0].dtype)","7a12b527":"x_test_predictions = model.predict(x_test_reshaped_normalized)","2c523b5f":"print(x_test_predictions[0])","657506cb":"fig_test = plt.figure(figsize = (5, 5))\nplt.imshow(x_test_reshaped_normalized[0]*255.0)\nplt.show()","bd1c7b06":"submission = pd.DataFrame({'ImageId':test_data_all.index.values+1, 'Label':np.argmax(x_test_predictions, axis=1)})\nsubmission","9700ff04":"submission.to_csv('submission.csv', index=False)","b148b8c4":"%ls","9bc2540f":"model.save('MNIST_digit_classifier_model')","c0e78f64":"# preexisting_model = keras.models.load_model(\"MNIST_digit_classifier_model\")","10b19dc0":"In this notebook, we will analyze the MNIST dataset of handwritten digits and classify each image as a digit from 0-9. We will use deep learning specifically a convolutional neural network. Our goal is to get the correct label on as many images as possible.","b95f3a20":"Dataset: The MNIST (Modified National Institute of Standards and Technology) dataset is a collection of images that are 28x28px (784px each image). Each pixel in an image is a number from 0-255 indicating the intensity of the pixel. Each image sample can be though of as a row vector of 785 values, where the first value is the label and the rest are the pixels of the image.","a59d54e8":"Let us preview our labels.","d21817b1":"Before we send our data to the model, we will normalize it. Normalization of data can be thought of as shrinking all of our features (in this case pixels) proportionally so that they fall in between a certain range, often times with a mean of 0 and standard deviation of 1. This will help prevent our model from generating weight values that are too far apart and also help our model converge during training (gradient descent). Here, we will simply divide our pixel values by 255, which is the maximum intensity for a pixel.","2dc66f11":"# Visualization of our ConvNet architecture.\n\nKeras has built in tools to help us visualize our models.","097f5559":"# Recap and last steps\n\nReview of the training process and our model. We will generate plots of the accuracy and loss over the training process.","456d99ad":"Now, we will build our model. We will develop our ConvNet with the Tensorflow and Keras packages.","2341d948":"And we see that we are correct! Now let us save our submission.","8db5d929":"Now we will train our model using the fit method. The history object contains data about the training process.","0f3b4f3e":"Now we will turn our data into numpy arrays and reshape them into images of 28x28 so that they can be fed to our model.","00a0eb6a":"Thank you very much for checking out this notebook. If you like what you see, please give this an upvote so I can provide more content in the future! You may also follow me on twitter [@leoyuguanall38](https:\/\/twitter.com\/leoyuguanall38) and [GitHub](https:\/\/github.com\/leoyuguanall38).","79205dd3":"Now we will use Scikit Learn's train_test_split function to separate our training set into training and validation sets. ","cc916836":"Let us peak at what our images look like using MatPlotLib.","9f9888e4":"Submission file: Our submission will be a .csv file in which the first row is the headers ImageID, Label. For each subsequent line, the first number will be the image ID, followed by a comma and then our predicted label.\n\nImageID, Label  \n1,8  \n2,6  \n...","41bf0343":"# Compiling and training our model","421cc45c":"To load the model, use the following.","23af0a9d":"We see that each entry is an array of 10 numbers, corresponding to digits 0-9 in this case. Each number represents the probability that the image represents that digit. The 3rd entry has a value of 1.00, which means the first picture should be the digit 2.","e70f3073":"Now we will use our model to generate predictions on the testing data and save those predictions for submission. Please note that before we can feed the test data to the model, we have to format it in the same way we did our training data. ","1a0b5065":"Learning rate scheduler. https:\/\/keras.io\/api\/callbacks\/learning_rate_scheduler\/","a4d09bf7":"# Preview our data","2ea5d65a":"It looks like we have a good distribution of image samples for each of the labels. Now let us prepare our training data by separating the images and the labels.","779317c4":"We are using the ImageDataGenerator class provided by Keras to augment our dataset. https:\/\/keras.io\/api\/preprocessing\/image\/","a4c5f720":"Let's peek at our predictions.","1cb4c36a":"Reduce learning rate when a particular metric has stopped improving.(https:\/\/keras.io\/api\/callbacks\/reduce_lr_on_plateau\/)","529db6ee":"Go ahead and download the submission file and submit to the competition. Let us save our model so we may use it in the future.","1279cb36":"# Import required packages","1b80b9be":"# MNIST Digit Recognizer Starter Notebook"}}