{"cell_type":{"f4b1565e":"code","aa67baf0":"code","9f8e274c":"code","39353ec5":"code","aafa25be":"code","4ece0c30":"code","8a3bad5c":"code","191bff97":"code","b491d1ad":"code","7bd2432a":"code","d8293d9e":"code","46a8b262":"code","6bd6e6e1":"code","1b5dcc9c":"code","4a8fe3cf":"code","d712ae1c":"code","499298ef":"code","48de2fa6":"code","332ccc2d":"code","a8d17e16":"code","4deefda2":"code","da65a459":"code","2833b32a":"code","c7d49257":"code","6f6f5eda":"code","c31066e4":"code","d9e02540":"code","47b391ab":"code","1f3990db":"code","0ee4b337":"code","c6804b5a":"code","445bb525":"code","37b9e847":"code","021365ee":"code","b72a8bb2":"code","94be3154":"code","08479b81":"code","a885dd76":"code","61a61c1d":"code","86d1facb":"code","fe75a4b9":"code","4943872f":"code","33e9aafb":"markdown","f001f607":"markdown","ff68f4fb":"markdown","45652e59":"markdown","6dbec1f2":"markdown","e760b14b":"markdown","6ec44b13":"markdown","d125c3a5":"markdown","35b823ca":"markdown","44932b5c":"markdown","fb1298b9":"markdown","fa2e458b":"markdown","17c6a6cf":"markdown","20cef4a8":"markdown","21e08b19":"markdown","d6b03a4f":"markdown","0d209f89":"markdown","f323897e":"markdown","8e99d441":"markdown","a42bb3a3":"markdown","cc75fbf1":"markdown","7d6ad581":"markdown","a75e8d1d":"markdown","a14afe16":"markdown","2fbefdb3":"markdown","d827cfc7":"markdown","cfbdedd9":"markdown","466b18a3":"markdown","f285bc30":"markdown","fe648e0a":"markdown","6633622d":"markdown","e6066a73":"markdown","046fd588":"markdown","f83bb0c9":"markdown","502c821d":"markdown","824cd9b8":"markdown","8a87f305":"markdown","24341a90":"markdown","5c5f9993":"markdown","9263929e":"markdown","741446cf":"markdown","d7929c77":"markdown","c9d7dc87":"markdown","3be3985d":"markdown","01d260db":"markdown","8dcbeb5b":"markdown","5dd44627":"markdown","edd560b4":"markdown","1ecf3ae9":"markdown","b931ddf3":"markdown","ab1a867f":"markdown","bf82a070":"markdown","c6c4840e":"markdown","943c23de":"markdown","6dee1828":"markdown","ff5fb702":"markdown","8dc2e9cc":"markdown"},"source":{"f4b1565e":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.tokenize import word_tokenize\nfrom nltk.corpus import stopwords\nfrom sklearn.model_selection import train_test_split\nfrom nltk.stem import SnowballStemmer\nimport string\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom mlxtend.plotting import plot_confusion_matrix","aa67baf0":"df=pd.read_csv('\/kaggle\/input\/yelp-reviews-dataset\/yelp.csv')","9f8e274c":"df.head(5)","39353ec5":"df.shape","aafa25be":"df.columns","4ece0c30":"df.info()","8a3bad5c":"df.isnull().sum()","191bff97":"df=df.drop(['business_id','date','review_id','type','user_id','cool','useful','funny'],axis=1)","b491d1ad":"df.head(5)","7bd2432a":"#lets make some text analysis and calculate the the length of each review\nlist_review=[]\nfor i in df['text']:\n    list_review.append(len(i))","d8293d9e":"df['text_length']=list_review","46a8b262":"df.head(5)","6bd6e6e1":"plt.figure(figsize=(12,5))\ndf['stars'].value_counts().plot(kind='bar',alpha=0.5,color='green',label='ratings')\nplt.legend()\nplt.show()","1b5dcc9c":"import matplotlib.pyplot as plt\nimport seaborn as sns\nplt.figure(figsize=(12,5))\ndf[df['stars']==1]['text_length'].plot(bins=35,alpha=0.5,kind='hist',color='red',label='rating 1')\nplt.legend()\nplt.xlabel('text_length')\nplt.show()","4a8fe3cf":"plt.figure(figsize=(12,5))\ndf[df['stars']==2]['text_length'].plot(bins=35,kind='hist',color='yellow',alpha=0.5,label='2 ratings')\nplt.xlabel('text length')\nplt.legend()\nplt.show()","d712ae1c":"plt.figure(figsize=(12,5))\ndf[df['stars']==3]['text_length'].plot(bins=35,kind='hist',color='brown',alpha=0.5,label='3 ratings')\nplt.xlabel('text length')\nplt.legend()\nplt.show()","499298ef":"plt.figure(figsize=(12,5))\ndf[df['stars']==4]['text_length'].plot(bins=35,kind='hist',color='orange',alpha=0.5,label='4 ratings')\nplt.xlabel('text length')\nplt.legend()\nplt.show()","48de2fa6":"plt.figure(figsize=(12,5))\ndf[df['stars']==5]['text_length'].plot(bins=35,kind='hist',color='pink',alpha=0.5,label='5 ratings')\nplt.xlabel('text length')\nplt.legend()\nplt.show()","332ccc2d":"df['stars']=np.where(df['stars']>3,1,0)","a8d17e16":"sns.countplot(df['stars'])","4deefda2":"positive=[]\nnegative=[]\npositive_reviews=df[df['stars']==1]['text']\nnegative_reviews=df[df['stars']==0]['text']","da65a459":"def extract_positive(positive_reviews):\n    global positive\n    words = [word.lower() for word in word_tokenize(positive_reviews) if word.lower() not in stopwords.words(\"english\") and word.lower().isalpha()]\n    positive=positive+words","2833b32a":"def extract_negative(negative_reviews):\n    global negative\n    words = [word.lower() for word in word_tokenize(negative_reviews) if word.lower() not in stopwords.words(\"english\") and word.lower().isalpha()]\n    negative=negative+words","c7d49257":"positive_reviews.apply(extract_positive)\nnegative_reviews.apply(extract_negative)","6f6f5eda":"from wordcloud import WordCloud\npos_review_cloud=WordCloud(width=600,height=400).generate(\" \".join(positive_reviews))\nplt.figure(figsize=(10,8),facecolor='k')\nplt.imshow(pos_review_cloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","c31066e4":"neg_review_cloud=WordCloud(width=600,height=400,background_color='white').generate(\" \".join(negative_reviews))\nplt.figure(figsize=(10,8),facecolor='k')\nplt.imshow(neg_review_cloud)\nplt.axis('off')\nplt.tight_layout(pad=0)\nplt.show()","d9e02540":"stemmer = SnowballStemmer(\"english\")\n\ndef ReadyText(message):\n    \n    message = message.translate(str.maketrans('', '', string.punctuation))\n    words = [stemmer.stem(word) for word in message.split() if word.lower() not in stopwords.words(\"english\")]\n    \n    return \" \".join(words)\n\ndf[\"text\"] = df[\"text\"].apply(ReadyText)\ndf.head(n = 10)    ","47b391ab":"y=df['stars']\nx=df['text']","1f3990db":"x_train,x_test,y_train,y_test=train_test_split(x,y,random_state=0,test_size=0.2)","0ee4b337":"print(\"x_train shape :\",x_train.shape)\nprint(\"x_test shape  :\",x_test.shape)\nprint(\"y_train shape :\",y_train.shape)\nprint(\"y_tets shape  :\",y_test.shape)","c6804b5a":"cv=CountVectorizer()\nlr=LogisticRegression(max_iter=10000)\nx_train=cv.fit_transform(x_train)\nlr.fit(x_train,y_train)\npred_1=lr.predict(cv.transform(x_test))\nscore_1=accuracy_score(y_test,pred_1)","445bb525":"print(score_1*100)","37b9e847":"print(lr.predict(cv.transform(['Thats a very good dish,I like it'])))","021365ee":"cm = confusion_matrix(y_test, pred_1)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Logistic Regression Model - Confusion Matrix\")\nplt.xticks(range(2), [\"Positve Review\",\"Negative Review\"], fontsize=16)\nplt.yticks(range(2), [\"Positive Review\",\"Negative Review\"], fontsize=16)\nplt.show()","b72a8bb2":"nb=MultinomialNB()\nnb.fit(x_train,y_train)\npred_2=nb.predict(cv.transform(x_test))\nscore_2=accuracy_score(y_test,pred_2)","94be3154":"print(score_2*100)","08479b81":"print(nb.predict(cv.transform(['the dish is just ok'])))","a885dd76":"cm = confusion_matrix(y_test, pred_2)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Naive Bayes - Confusion Matrix\")\nplt.xticks(range(2), [\"Positve Review\",\"Negative Review\"], fontsize=16)\nplt.yticks(range(2), [\"Positive Review\",\"Negative Review\"], fontsize=16)\nplt.show()","61a61c1d":"svm=SVC()\nsvm.fit(x_train,y_train)\npred_3=svm.predict(cv.transform(x_test))\nscore_3=accuracy_score(y_test,pred_3)","86d1facb":"print(score_3*100)","fe75a4b9":"print(svm.predict(cv.transform(['I love this place'])))","4943872f":"cm = confusion_matrix(y_test, pred_3)\nplt.figure()\nplot_confusion_matrix(cm, figsize=(12,8), hide_ticks=True, cmap=plt.cm.Blues)\nplt.title(\"Support Vector Machine - Confusion Matrix\")\nplt.xticks(range(2), [\"Positve Review\",\"Negative Review\"], fontsize=16)\nplt.yticks(range(2), [\"Positive Review\",\"Negative Review\"], fontsize=16)\nplt.show()","33e9aafb":"##### From this figure we can observe that mostly of 1 star reviews are length bw 0-2000","f001f607":"# Section 1-Data Analysis and Visualizations","ff68f4fb":"### Checking for Null Values","45652e59":"# Section 2 :Data Cleaning and Preprocessing","6dbec1f2":"#### So far so good.It correctly predicted the seniment i.e Neagtive","e760b14b":"### Predicted Correctly again!","6ec44b13":"##### Here we calulated the lenth of each review and stored in a list","d125c3a5":"#### In This Notebook we have to extract the sentiments from the yelp reviews dataset.We have divided our work into three parts i.e Data Visualization and analysis ,Data Cleaning and Modelling","35b823ca":"#### The extract_postive function will do following things:\n#### 1-It will tokenize the text from positive reviews\n#### 2-Remove the stopwords\n#### 3-Convert into lowercase","44932b5c":"### In this section we have spliited our dataset into training set and test test with a ratio of 0.2.The model will be trained  on training set and will be evaluated on the unseen data i.e test set","fb1298b9":"### Importing the modules and libraries required","fa2e458b":"## Conclusion  ","17c6a6cf":"### In this section we have created two list for extracting the positive(1-class) and negative reviews(0-class) ","20cef4a8":"## Now to understand the data more deeply we have to some analysis and visualizations","21e08b19":"### Confusion Matrix:Naive Bayes","d6b03a4f":"#### 1:Logistic Regression","0d209f89":"### Making Predictions :Logistic Regression","f323897e":"### Applying the above two functions on positive and negative reviews","8e99d441":"#### Similar functionality but for negative reviews","a42bb3a3":"#### In this section of code we have checked the length of reviews which are of rating star 1 .We plotted a histogram for that","cc75fbf1":"### Confusin Matrix:Support Vector Machine","7d6ad581":"### Accuracy Score:Naive Bayes","a75e8d1d":"### In this section we have crated a function ReadyText for making data ready for model building","a14afe16":"### Here we will build models using three classification algorithms \n","2fbefdb3":"### Information about the data","d827cfc7":"### Shape of dataset","cfbdedd9":"### Predcitons:Naive Bayes","466b18a3":"#### For Negative Reviews","f285bc30":"# Section:3 Modelling","fe648e0a":"##### Here is our desired dataset in which text will act as a feature variable and starts will act as a  taeget varibale which we have to predict","6633622d":"##### In this case the frequency of reviews increases bw length 0-1000 i.e More than 200 ","e6066a73":"### As we know that nachine learning algorithms don't accept as text as input so we have to convert into vectors .For this  we have used CountVectorizer for converting the text into vectors","046fd588":"# Please upvote if you found this notebook helpful","f83bb0c9":"#### Since for our task we only require columns  reviews and star ,So we have to delete all the other unnecessary columns","502c821d":"##### If we look carefully we can observe that as the rating increases the length of the reviews decreases.From above plot we can see that there are very few reviews whose text length is greater than 3000","824cd9b8":"##### Here is the changed senario","8a87f305":"##### Here we are using numpy's where clause to convert reviews into two-class i.e 0 and 1","24341a90":"### WordCloud are used to highlight the most important and frequent words that appear in our dataset","5c5f9993":"### Predictions:Support Vector Machine","9263929e":"### Confusion Matrix :Logistic Regression","741446cf":"##### From the above analysis we can conclude that reviews with rating 1-3 shows almost a similar trend as compare to of ratings 4-5.The reviews with in rating 1-3 are  may be the criticism , suggestion or could be detailed complaints, thats why some reviews also have a length of 3000-5000 words.Where as reviews having 4-5 ratings could be the appreciation,good talks or something positive","d7929c77":"##### Reading the dataset usign pandas ","c9d7dc87":"### Now we have to divide our data into dependent vairable i.e X and independent vairable Y","3be3985d":"### Navie Bayes:","01d260db":"### Accuracy Score:Support Vector Machine","8dcbeb5b":"### From the above analysis we are summing up it into two class classification problem ,where reviews with rating 1-3 are classified as 0 and reviews with in range 4-5 are classfied as 1","5dd44627":"##### Pandas for data mining\n##### Numpy for mathematical calulations\n##### Matplotlib ans seaborn for data visualizations\n##### NLTK for Text Mining\n##### SKlearn for Modelling","edd560b4":"##### Clearly we can observe that pattern here too on the 5 star ratings","1ecf3ae9":"###### Creating a new columns text_length for reviews","b931ddf3":"##### From the above figure we can observe that there is almost  similar senario with 2 star ratings","ab1a867f":"### Columns in the dataset","bf82a070":"#### Some mixed words like better,good ,try could be a part of some suggestion or negative review","c6c4840e":"##### Similarly we will check for all the ratings ","943c23de":"### Support Vetor Machines:","6dee1828":"### Accuracy Score :Logistic Regression","ff5fb702":"#### As we can clearly observe that there are postive words like good,great,amazing etc","8dc2e9cc":"#### It predicted as a positive review.So our model is working Fine"}}