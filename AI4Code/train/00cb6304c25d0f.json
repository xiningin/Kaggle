{"cell_type":{"1b8eb08c":"code","3cbb8abd":"code","c162cb96":"code","d6d2ebd8":"code","0d8d1431":"code","7e3bcf7e":"code","5a610c79":"code","799aee08":"code","855c8fb1":"code","4f5c1364":"code","6f879656":"code","dbca7aae":"code","859276a6":"code","4338221b":"code","a670597a":"code","6f703648":"code","86979dc9":"markdown","20b08988":"markdown"},"source":{"1b8eb08c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n#Set numpy and Tensorflow random seed to mask sure experiment reproducible(only works in CPU mode).\nfrom numpy.random import seed\nseed(123)\nfrom tensorflow import set_random_seed\nset_random_seed(123)\n\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport imageio\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","3cbb8abd":"image_path = '..\/input\/dataa\/dataA\/CameraRGB\/'\nmask_path = '..\/input\/dataa\/dataA\/CameraSeg\/'\nimage_list = os.listdir(image_path)\nmask_list = os.listdir(mask_path)\nimage_list = [image_path+i for i in image_list]\nmask_list = [mask_path+i for i in mask_list]","c162cb96":"N = 1\nimg = imageio.imread(image_list[N])\nmask = imageio.imread(mask_list[N])\nmask = np.array([max(mask[i, j]) for i in range(mask.shape[0]) for j in range(mask.shape[1])]).reshape(img.shape[0], img.shape[1])\n\nfig, arr = plt.subplots(1, 2, figsize=(14, 10))\narr[0].imshow(img)\narr[0].set_title('Image')\narr[1].imshow(mask, cmap='Paired')\narr[1].set_title('Segmentation')","d6d2ebd8":"road = np.zeros((600, 800))\nroad[np.where(mask==7)[0], np.where(mask==7)[1]]=1\nplt.imshow(road)","0d8d1431":"from tqdm import tqdm","7e3bcf7e":"height, width = 600, 800\nimages = np.zeros((len(image_list), height, width, 3), dtype=np.int16)\nmasks = np.zeros((len(image_list), height, width, 1), dtype=np.int8)\n\nfor n in tqdm(range(len(image_list))):\n    img = imageio.imread(image_list[n])\n    \n    mask = imageio.imread(mask_list[n])\n    mask_road = np.zeros((600, 800, 1), dtype=np.int8)\n    mask_road[np.where(mask==7)[0], np.where(mask==7)[1]]=1\n    \n    images[n] = img\n    masks[n] = mask_road","5a610c79":"plt.imshow(images[1].reshape(600, 800, 3))","799aee08":"np.random.seed(123)\nshuffle_ids = np.array([i for i in range(len(masks))])\nnp.random.shuffle(shuffle_ids)\ntrain_ids = shuffle_ids[:int(len(masks)*0.8)]\nval_ids = shuffle_ids[int(len(masks)*0.8):int(len(masks)*0.8+100)]\ntest_ids = shuffle_ids[int(len(masks)*0.8+100):]","855c8fb1":"train_images, train_masks = images[train_ids], masks[train_ids]\nval_images, val_masks = images[val_ids], masks[val_ids]\ntest_images, test_masks = images[test_ids], masks[test_ids]","4f5c1364":"train_images.shape, val_images.shape, test_images.shape","6f879656":"from keras.models import Model, load_model\nfrom keras.layers import Input\nfrom keras.layers.core import Lambda, RepeatVector, Reshape\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K","dbca7aae":"# Build U-Net model\ninput_img = Input((height, width, 3), name='img')\n\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (input_img)\nc1 = Conv2D(8, (3, 3), activation='relu', padding='same') (c1)\np1 = MaxPooling2D((2, 2)) (c1)\n\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (p1)\nc2 = Conv2D(16, (3, 3), activation='relu', padding='same') (c2)\np2 = MaxPooling2D((2, 2)) (c2)\n\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (p2)\nc3 = Conv2D(32, (3, 3), activation='relu', padding='same') (c3)\np3 = MaxPooling2D((2, 2)) (c3)\n\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (p3)\nc4 = Conv2D(64, (3, 3), activation='relu', padding='same') (c4)\n\nu5 = Conv2DTranspose(64, (2, 2), strides=(2, 2), padding='same') (c4)\nu5 = concatenate([u5, c3])\nc6 = Conv2D(32, (3, 3), activation='relu', padding='same') (u5)\nc6 = Conv2D(32, (3, 3), activation='relu', padding='same') (c6)\n\nu7 = Conv2DTranspose(32, (2, 2), strides=(2, 2), padding='same') (c6)\nu7 = concatenate([u7, c2])\nc7 = Conv2D(16, (3, 3), activation='relu', padding='same') (u7)\nc7 = Conv2D(16, (3, 3), activation='relu', padding='same') (c7)\n\nu8 = Conv2DTranspose(16, (2, 2), strides=(2, 2), padding='same') (c7)\nu8 = concatenate([u8, c1])\nc8 = Conv2D(8, (3, 3), activation='relu', padding='same') (u8)\nc8 = Conv2D(8, (3, 3), activation='relu', padding='same') (c8)\n\noutputs = Conv2D(1, (1, 1), activation='sigmoid') (c8)\n\nmodel = Model(inputs=[input_img], outputs=[outputs])\nmodel.compile(optimizer='adam', loss='binary_crossentropy') #, metrics=[mean_iou]) # The mean_iou metrics seens to leak train and test values...\nmodel.summary()","859276a6":"callbacks = [\n    EarlyStopping(patience=12, verbose=1),\n    ReduceLROnPlateau(patience=3, verbose=1),\n    ModelCheckpoint('model-sdc-seg-v2.h5', verbose=1, save_best_only=True)\n]\n\nresults = model.fit(train_images, train_masks, batch_size=16, epochs=100, callbacks=callbacks,\n                    validation_data=(val_images, val_masks))","4338221b":"model.save('final-road-seg-model-v2.h5')","a670597a":"NUMBER = 0\nmy_preds = model.predict(np.expand_dims(test_images[NUMBER], 0))\nmy_preds = my_preds.flatten()\nmy_preds = np.array([1 if i >= 0.5 else 0 for i in my_preds])\nfig, ax = plt.subplots(nrows=1, ncols=2)\nax[0].imshow(my_preds.reshape(600, 800))\nax[0].set_title('Prediction')\nax[1].imshow(test_masks[NUMBER].reshape(600, 800))\nax[1].set_title('Ground truth')","6f703648":"NUMBER += 1\nmy_preds = model.predict(np.expand_dims(test_images[NUMBER], 0))\nmy_preds = my_preds.flatten()\nmy_preds = np.array([1 if i >= 0.5 else 0 for i in my_preds])\nfig, ax = plt.subplots(nrows=1, ncols=2)\nax[0].imshow(my_preds.reshape(600, 800))\nax[0].set_title('Prediction')\nax[1].imshow(test_masks[NUMBER].reshape(600, 800))\nax[1].set_title('Ground truth')","86979dc9":"## Build U-Net with subtle changes","20b08988":"## Limited by RAM, just do <font color=red>road<\/font> segmentation(mask == 7)."}}