{"cell_type":{"7d1c8576":"code","738b0f54":"code","a6dce9b9":"code","376aad08":"code","9f0126d9":"code","e211ccd3":"code","4c352cf8":"code","b0be9cfe":"code","7ddf928d":"code","1d0e5bea":"code","d4da1e9a":"code","19296e4b":"code","15fbddb4":"code","d7d03292":"code","a89ef570":"code","78df0e79":"code","62feb68f":"code","edadd91d":"code","3841cbe2":"code","59cd5f27":"code","d6da107b":"code","22f42ebd":"code","ce81aa58":"code","55ccf062":"code","c618d6a1":"code","a45adab8":"markdown","4ed6e4d4":"markdown","1cde3729":"markdown","c3620b74":"markdown","27e1ffe5":"markdown","2fb8f056":"markdown","28ee67eb":"markdown","975252da":"markdown","dbdaf1d2":"markdown","af4bef21":"markdown","2d715765":"markdown","83329310":"markdown","ce364bd1":"markdown","6d1c0369":"markdown","193c6a22":"markdown","5ae83058":"markdown"},"source":{"7d1c8576":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nplt.style.use('fivethirtyeight')","738b0f54":"pjme = pd.read_csv('..\/input\/PJME_hourly.csv', index_col=[0], parse_dates=[0])","a6dce9b9":"color_pal = [\"#F8766D\", \"#D39200\", \"#93AA00\", \"#00BA38\", \"#00C19F\", \"#00B9E3\", \"#619CFF\", \"#DB72FB\"]\n_ = pjme.plot(style='.', figsize=(15,5), color=color_pal[0], title='PJM East')","376aad08":"split_date = '01-Jan-2015'\npjme_train = pjme.loc[pjme.index <= split_date].copy()\npjme_test = pjme.loc[pjme.index > split_date].copy()","9f0126d9":"_ = pjme_test \\\n    .rename(columns={'PJME_MW': 'TEST SET'}) \\\n    .join(pjme_train.rename(columns={'PJME_MW': 'TRAINING SET'}), how='outer') \\\n    .plot(figsize=(15,5), title='PJM East', style='.')","e211ccd3":"def create_features(df, label=None):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X","4c352cf8":"X_train, y_train = create_features(pjme_train, label='PJME_MW')\nX_test, y_test = create_features(pjme_test, label='PJME_MW')","b0be9cfe":"reg = xgb.XGBRegressor(n_estimators=1000)\nreg.fit(X_train, y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)],\n        early_stopping_rounds=50,\n       verbose=False) # Change verbose to True if you want to see it train","7ddf928d":"_ = plot_importance(reg, height=0.9)","1d0e5bea":"pjme_test['MW_Prediction'] = reg.predict(X_test)\npjme_all = pd.concat([pjme_test, pjme_train], sort=False)","d4da1e9a":"_ = pjme_all[['PJME_MW','MW_Prediction']].plot(figsize=(15, 5))","19296e4b":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='01-01-2015', upper='02-01-2015')\nax.set_ylim(0, 60000)\nplot = plt.suptitle('January 2015 Forecast vs Actuals')","15fbddb4":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='01-01-2015', upper='01-08-2015')\nax.set_ylim(0, 60000)\nplot = plt.suptitle('First Week of January Forecast vs Actuals')","d7d03292":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_ylim(0, 60000)\nax.set_xbound(lower='07-01-2015', upper='07-08-2015')\nplot = plt.suptitle('First Week of July Forecast vs Actuals')","a89ef570":"mean_squared_error(y_true=pjme_test['PJME_MW'],\n                   y_pred=pjme_test['MW_Prediction'])","78df0e79":"mean_absolute_error(y_true=pjme_test['PJME_MW'],\n                   y_pred=pjme_test['MW_Prediction'])","62feb68f":"def mean_absolute_percentage_error(y_true, y_pred): \n    \"\"\"Calculates MAPE given y_true and y_pred\"\"\"\n    y_true, y_pred = np.array(y_true), np.array(y_pred)\n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100","edadd91d":"mean_absolute_percentage_error(y_true=pjme_test['PJME_MW'],\n                   y_pred=pjme_test['MW_Prediction'])","3841cbe2":"pjme_test['error'] = pjme_test['PJME_MW'] - pjme_test['MW_Prediction']\npjme_test['abs_error'] = pjme_test['error'].apply(np.abs)\nerror_by_day = pjme_test.groupby(['year','month','dayofmonth']) \\\n    .mean()[['PJME_MW','MW_Prediction','error','abs_error']]","59cd5f27":"# Over forecasted days\nerror_by_day.sort_values('error', ascending=True).head(10)","d6da107b":"# Worst absolute predicted days\nerror_by_day.sort_values('abs_error', ascending=False).head(10)","22f42ebd":"# Best predicted days\nerror_by_day.sort_values('abs_error', ascending=True).head(10)","ce81aa58":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(10)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_ylim(0, 60000)\nax.set_xbound(lower='08-13-2016', upper='08-14-2016')\nplot = plt.suptitle('Aug 13, 2016 - Worst Predicted Day')","55ccf062":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(10)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_ylim(0, 60000)\nax.set_xbound(lower='10-03-2016', upper='10-04-2016')\nplot = plt.suptitle('Oct 3, 2016 - Best Predicted Day')","c618d6a1":"f, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(10)\n_ = pjme_all[['MW_Prediction','PJME_MW']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_ylim(0, 60000)\nax.set_xbound(lower='08-13-2016', upper='08-14-2016')\nplot = plt.suptitle('Aug 13, 2016 - Worst Predicted Day')","a45adab8":"# Hourly Time Series Forecasting using XGBoost\n\n[If you haven't already first check out my previous notebook forecasting on the same data using Prophet](https:\/\/www.kaggle.com\/robikscube\/hourly-time-series-forecasting-with-prophet)\n\nIn this notebook we will walk through time series forecasting using XGBoost. The data we will be using is hourly energy consumption.","4ed6e4d4":"This one is pretty impressive. SPOT ON!","1cde3729":"# Up next?\n- Add Lag variables\n- Add holiday indicators.\n- Add weather data source.","c3620b74":"# Plotting some best\/worst predicted days","27e1ffe5":"The best predicted days seem to be a lot of october (not many holidays and mild weather) Also early may","2fb8f056":"# Error Metrics On Test Set\nOur RMSE error is 13780445  \nOur MAE error is 2848.89  \nOur MAPE error is 8.9%","28ee67eb":"# Create Time Series Features","975252da":"# Look at Worst and Best Predicted Days","dbdaf1d2":"# Create XGBoost Model","af4bef21":"# Look at first month of predictions","2d715765":"# Data\nThe data we will be using is hourly power consumption data from PJM. Energy consumtion has some unique charachteristics. It will be interesting to see how prophet picks them up.\n\nPulling the `PJM East` which has data from 2002-2018 for the entire east region.","83329310":"Notice anything about the over forecasted days? \n- #1 worst day - July 4th, 2016 - is a holiday. \n- #3 worst day - December 25, 2015 - Christmas\n- #5 worst day - July 4th, 2016 - is a holiday.   \nLooks like our model may benefit from adding a holiday indicator.","ce364bd1":"I like using mean absolute percent error because it gives an easy to interperate percentage showing how off the predictions are.\nMAPE isn't included in sklearn so we need to use a custom function.","6d1c0369":"# Forecast on Test Set","193c6a22":"# Train\/Test Split\nCut off the data after 2015 to use as our validation set.","5ae83058":"## Feature Importances\nFeature importance is a great way to get a general idea about which features the model is relying on most to make the prediction. This is a metric that simply sums up how many times each feature is split on.\n\nWe can see that the day of year was most commonly used to split trees, while hour and year came in next. Quarter has low importance due to the fact that it could be created by different dayofyear splits."}}