{"cell_type":{"a19725b8":"code","0211fcc5":"code","669154b0":"code","d8479a0f":"code","fcd34c62":"code","7f755628":"code","26321414":"code","12563faf":"markdown","d7c1247d":"markdown","dc8835c3":"markdown","5139e438":"markdown","0044ebcc":"markdown"},"source":{"a19725b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport re\nfrom bs4 import BeautifulSoup\nimport nltk\nfrom nltk.corpus import stopwords","0211fcc5":"train = pd.read_csv('..\/input\/word2vec-nlp-tutorial\/labeledTrainData.tsv.zip',header=0,delimiter=\"\\t\",quoting=3)\ntrain.head()","669154b0":"test = pd.read_csv('..\/input\/word2vec-nlp-tutorial\/testData.tsv.zip',delimiter='\\t',quoting=3,header=0)\ntest.head()","d8479a0f":"def review_to_words(raw_review):\n    example1 = BeautifulSoup(raw_review,features='lxml')\n\n\n    letters_only = re.sub(\"[^a-zA-Z]\",\" \",example1.get_text())\n\n    lower_case = letters_only.lower()\n    words = lower_case.split()\n\n\n    stops = set(stopwords.words('english'))\n    words = [w for w in words if  w not in stops]\n    return \" \".join(words)\n\nnum_reviews = train['review'].size\nclean_train_review = []\nfor i in range(0,num_reviews):\n    clean_train_review.append(review_to_words(train['review'][i]))","fcd34c62":"from sklearn.feature_extraction.text import CountVectorizer\n\nvectorizer = CountVectorizer(analyzer='word',preprocessor=None,tokenizer=None,stop_words=None,max_features=5000)\ntrain_data_features = vectorizer.fit_transform(clean_train_review)\n\ntrain_data_features = train_data_features.toarray()","7f755628":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(n_estimators=100)\nrf.fit(train_data_features,train['sentiment'])\n\nclean_test_review = []\nfor i in range(0,test['review'].size):\n    clean_test_review.append(review_to_words(test['review'][i]))\ntest_data_features = vectorizer.transform(clean_test_review).toarray()","26321414":"result = rf.predict(test_data_features)\n\nres = pd.DataFrame({'id':test['id'],'sentiment':result})\nres.to_csv(\"submission.csv\", index=False, quoting=3)","12563faf":"\u041f\u0430\u0440\u0441\u0438\u043c \u0434\u0430\u043d\u043d\u044b\u0435","d7c1247d":"\u041e\u0447\u0438\u0449\u0430\u0435\u043c \u0434\u0430\u043d\u043d\u044b\u0435 \u043e\u0442 \u043b\u0438\u0448\u043d\u0438\u0445 \u0441\u0438\u043c\u0432\u043e\u043b\u043e\u0432","dc8835c3":"\u0412\u044b\u043f\u043e\u043b\u043d\u044f\u0435\u043c \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u044f","5139e438":"\u0421\u0442\u0440\u043e\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c RandomForest","0044ebcc":"\u0421\u043e\u0431\u0438\u0440\u0430\u0435\u043c \u0432\u0435\u043a\u0442\u043e\u0440\u0430 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432"}}