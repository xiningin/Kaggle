{"cell_type":{"7e9e132e":"code","4ba3a40a":"code","19a24755":"code","947e1d55":"code","0f28ba46":"code","975f3409":"code","12ce444b":"code","2d0a8aa7":"code","27b95a90":"code","806b5b64":"code","09e023a4":"code","f838b288":"code","07bc8e4a":"code","d8c9684d":"code","3cfc3e69":"code","ccf724e2":"code","fa9f04d4":"code","497f3821":"code","e81422a3":"code","0388b23b":"markdown","1e6fca63":"markdown","d679c92a":"markdown","d98b2701":"markdown","aff5161b":"markdown","060ebc40":"markdown","b1c4ddd9":"markdown","50c92de2":"markdown","02fa89f4":"markdown","f8bb619a":"markdown","cda64e1b":"markdown","e20ea7dc":"markdown","ae1a04ce":"markdown","9b7945cc":"markdown","a7224ac9":"markdown"},"source":{"7e9e132e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4ba3a40a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc # garbage collector\n\n%matplotlib inline","19a24755":"project_dir = '\/kaggle\/input\/bengaliai-cv19\/'","947e1d55":"import glob\ncsv_files = [file for file in glob.glob(project_dir+\"*.csv\")]\ntrain_parquet_files =  [file for file in glob.glob(project_dir+\"train*.parquet\")]\ntest_parquet_files =  [file for file in glob.glob(project_dir+\"test*.parquet\")]","0f28ba46":"csv_files","975f3409":"sample_submission = '\/kaggle\/input\/bengaliai-cv19\/sample_submission.csv'\nclass_maps = '\/kaggle\/input\/bengaliai-cv19\/class_map.csv'\ntest = '\/kaggle\/input\/bengaliai-cv19\/test.csv'\ntrain = '\/kaggle\/input\/bengaliai-cv19\/train.csv'\n\n# For some strange reason, when I commit csv_files order is changing\n\n# sample_submission = csv_files[0]\n# class_maps = csv_files[1]\n# test = csv_files[2]\n# train = csv_files[3]","12ce444b":"def csv_overview(csv_file, name='', head=3, tail=3, columns=False, describe=False, info=True):\n    print('file :', csv_file)\n    df = pd.read_csv(csv_file)\n    print('{} Shape : '.format(name),df.shape)\n    print('-'*36)\n    if columns:\n        print('{} Columns : '.format(name),df.columns)\n        print('-'*36)\n    if describe:\n        print('{} Distribution :\\n'.format(name),df.describe().T)\n        print('-'*36)\n    if info:\n        print('{} Summary :\\n'.format(name))\n#         print(df.info())\n        df.info()\n        print('-'*36)\n    print('{} Unique values :\\n'.format(name),df.nunique())\n    print('-'*36)\n    print('Sample data')\n    print('-'*12)\n    print('head')\n    print(df.head(head))\n    print('-'*12)\n    print('tail')\n    print(df.tail(tail))","2d0a8aa7":"csv_overview(train, 'train_df', columns=True)","27b95a90":"csv_overview(test, 'test_df', head=5, tail=5, columns=True)","806b5b64":"csv_overview(class_maps, 'Class Maps', columns=True)","09e023a4":"csv_overview(sample_submission, 'Sample Submissions', head=5, columns=True)","f838b288":"def explore_parquet(file, name='', head=3, tail=3, columns=False, describe=False, unique=False, info=True):\n    print('file : {}'.format(file))\n    df = pd.read_parquet(file)\n    print('{} Shape : '.format(name),df.shape)\n    print('-'*36)\n    if columns:\n        print('{} Columns : '.format(name),df.columns)\n        print('-'*36)\n    if describe:\n        print('{} Distribution :\\n'.format(name),df.describe().T)\n        print('-'*36)\n    if info:\n        print('{} Summary :\\n'.format(name))\n#         print(df.info())\n        df.info()\n        print('-'*36)\n    if unique:\n        print('{} Unique values :\\n'.format(name),df.nunique())\n        print('-'*36)\n    print('Sample data')\n    print('-'*12)\n    print('head')\n    print(df.head(head))\n    print('-'*12)\n    print('tail')\n    print(df.tail(tail))\n","07bc8e4a":"def visualize_parquet(file, shape=(137, 236), cmap=None):\n    # shape - (height, width)\n    df = pd.read_parquet(file)\n    df1 = df.head(25)\n    labels, images = df1.iloc[:, 0], df1.iloc[:, 1:].values.reshape(-1, *shape) \n    \n    f, ax = plt.subplots(5, 4, figsize=(20, 20))\n    ax = ax.flatten()\n    f.suptitle(file) #super title\n    \n    for i in range(20):\n        ax[i].set_title(labels[i])\n        ax[i].imshow(images[i], cmap=cmap)","d8c9684d":"train_parquet_files","3cfc3e69":"for file in train_parquet_files:\n    explore_parquet(file)\n    print('==='*18)","ccf724e2":"for file in train_parquet_files:\n    visualize_parquet(file, cmap='Blues')","fa9f04d4":"test_parquet_files","497f3821":"for file in test_parquet_files:\n    explore_parquet(file)\n    print('==='*18)\n        ","e81422a3":"shape=(137, 236)\nfor file in test_parquet_files:\n    print('file', file)\n    df = pd.read_parquet(file)\n    labels, images = df.iloc[:, 0], df.iloc[:, 1:].values.reshape(-1, *shape) \n\n    f, ax = plt.subplots(1, 3, figsize=(10, 10))\n    ax = ax.flatten()\n#     f.suptitle(file) #super title\n\n    for i in range(3):\n        ax[i].set_title(labels[i])\n        ax[i].imshow(images[i], cmap='Blues')","0388b23b":"Each images seems to have 3 dedicated rows to it each for different type of component.\n\nGiven test.csv only have test data for 12 images compared to train.csv with over ~200K images. These shall be used only for sample submission.\n\n> Goal would be to predict the component given its corresponding row_id and\/or image_id\n\n---\n","1e6fca63":"We can see that each parquet file has ~50k images of the total 200K train images.\n\nOut of 32333 columns\n\n- First column is the Foriegn key for the image from train.csv\n- The next 32332 columns are pixels of the flattend image of size 137x236","d679c92a":"#### Overview :\nThere are total of 200840 (~200K images) and each image has \n- grapheme_root\n- vowel_diacritic\n- consonant_diacritic\n- and grapheme (which is combination of above three), is the bengali character in image\n\n> Task at hand is to identify the compoments which makeup the grapheme\n\n#### Summary :\n\nFrom train.csv, we can observe\n\n-  168 unique grapheme_root \n-  11 unique vowel_diacritic\n-  7 unique consonant_diacritic\n-  1295 unique graphemes \n\nImages are identified using image_id col(Train_image-no) which are likely to be foreign keys in paraquet files\n\n> There are doesn't seem to be any null values\n\n\n---","d98b2701":"### test.csv","aff5161b":"\nThis kernel is an attempt at understanding what we have. This is the first of the series of kernels. \n\n1. [Exploring csv files](#Exploring-CSV-files)\n    - [train.csv](#train.csv)\n    - [test.csv](#test.csv)\n    - [class_maps.csv](#class_maps.csv)\n    - [sample_submission.csv](#sample_submission.csv)\n2. [Exploring parquet files](#Exploring-parquet-files)\n\n","060ebc40":"Each test parquet file has 3 images - flattened along with the image_id**","b1c4ddd9":"Submission should have only 2 columns, one for image and component identification and the other for its label\n\n---","50c92de2":"### Test parquet files","02fa89f4":"### class_maps.csv","f8bb619a":"### sample_submission.csv","cda64e1b":"---\n\n## Exploring CSV files\n","e20ea7dc":"### train.csv","ae1a04ce":"### Train parquet files","9b7945cc":"## Exploring parquet files","a7224ac9":"Each component type (represented by a unique label) is mapped to the font\/visualization\n\nwe have a total of 168+11+7 -> 186 components\n\n---"}}