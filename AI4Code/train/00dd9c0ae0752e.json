{"cell_type":{"ede34a87":"code","70a60790":"code","6fb09311":"code","53dbffa7":"code","5fa9167b":"code","618296cf":"code","fab58958":"code","bb873ca1":"code","acab40df":"code","bba48084":"code","674014a5":"code","5b22b2f9":"code","9c088096":"code","446ae7cc":"code","54e8b105":"code","5eed1847":"code","e5a8b3e8":"code","ef0caad9":"code","a4ff9d05":"code","dbd7ef53":"code","d4a2bf65":"code","a4e71fc7":"code","c9b7284d":"code","04bdf049":"code","cebb0847":"code","a83254cd":"code","a82bd39f":"code","602da902":"code","1390a318":"code","2e7f6518":"code","0d65b8b7":"code","5bf110fb":"code","23f941da":"markdown","0c45772d":"markdown","28d55242":"markdown","50fc8a0e":"markdown","eee5d82c":"markdown"},"source":{"ede34a87":"!dpkg -i ..\/input\/python3gdcm\/build_1-1_amd64.deb\n!apt-get install -f","70a60790":"!cp \/usr\/local\/lib\/gdcm.py \/opt\/conda\/lib\/python3.7\/site-packages\/.\n!cp \/usr\/local\/lib\/gdcmswig.py \/opt\/conda\/lib\/python3.7\/site-packages\/.\n!cp \/usr\/local\/lib\/_gdcmswig.so \/opt\/conda\/lib\/python3.7\/site-packages\/.\n!cp \/usr\/local\/lib\/libgdcm* \/opt\/conda\/lib\/python3.7\/site-packages\/.\n!ldconfig","6fb09311":"import os\nimport cv2\nimport sys\nimport random\nimport pickle\nimport glob\nimport gc\nfrom tqdm.notebook import tqdm\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm.auto import tqdm\nimport gdcm\nimport pydicom\n\nimport scipy.ndimage as ndimage\nfrom scipy.ndimage import zoom\nfrom scipy.stats import kurtosis\nfrom scipy.stats import skew\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data.dataset import Dataset\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","53dbffa7":"sys.path.append('..\/input\/efficientnet-pytorch\/EfficientNet-PyTorch-master\/')\nsys.path.append('..\/input\/pretrainedmodels\/pretrainedmodels-0.7.4\/')\nsys.path.append('..\/input\/segmentation-models-pytorch\/')","5fa9167b":"import segmentation_models_pytorch as smp","618296cf":"#INPUT = '.\/input' #local\nINPUT = '\/kaggle\/input\/osic-pulmonary-fibrosis-progression' #kaggle\n#WORKING = .\/output #local\nWORKING = '\/kaggle\/working' #kaggle","fab58958":"def get_dicom_df(path: str)->pd.DataFrame:\n    Patient_ids = os.listdir(path)\n    n_dicom_dict = {\"Patient\":[],\"n_dicom\":[],\"list_dicom\":[], \"height\": [], \"width\": []}\n\n    for Patient_id in Patient_ids:\n        dicom_id_path = glob.glob(path + Patient_id + \"\/*\")\n        n_dicom_dict[\"n_dicom\"].append(len(dicom_id_path))\n        n_dicom_dict[\"Patient\"].append(Patient_id)\n        list_dicom_id = sorted([int(i.split(\"\/\")[-1][:-4]) for i in dicom_id_path])\n        n_dicom_dict[\"list_dicom\"].append(list_dicom_id)\n        \n        rows = []\n        cols = []\n        for patient_dicom_id_path in dicom_id_path:\n            dicom = pydicom.dcmread(patient_dicom_id_path)\n            #print(dicom.Rows, dicom.Columns)\n            rows = dicom.Rows\n            cols = dicom.Columns\n            break\n        n_dicom_dict[\"height\"].append(rows)\n        n_dicom_dict[\"width\"].append(cols)\n\n    dicom_df = pd.DataFrame(n_dicom_dict)\n    return dicom_df","bb873ca1":"train_dicom_path = f'{INPUT}\/train\/'\ntest_dicom_path = f'{INPUT}\/test\/'","acab40df":"train_dicom_df =  get_dicom_df(train_dicom_path)\n#train_dicom_df.head()","bba48084":"test_dicom_df =  get_dicom_df(test_dicom_path)\n#test_dicom_df.head()","674014a5":"if 0:    \n    print(f\"num dicom: {len(train_dicom_df)}\\n\\\n    min dicom number is {min(train_dicom_df['n_dicom'])}\\n\\\n    max dicom number is {max(train_dicom_df['n_dicom'])}\")\n\n    plt.hist(train_dicom_df['n_dicom'], bins=20)\n    plt.title('Number of dicom per patient');","5b22b2f9":"if 0:\n    print(f\"num dicom: {len(test_dicom_df)}\\n\\\n    min dicom number is {min(test_dicom_df['n_dicom'])}\\n\\\n    max dicom number is {max(test_dicom_df['n_dicom'])}\")\n\n    plt.hist(test_dicom_df['n_dicom'], bins=20)\n    plt.title('Number of dicom per patient');","9c088096":"def mark_reshape(df: pd.DataFrame, size: int)->pd.DataFrame:\n    reshape_df = df.loc[(df.height!=size) | (df.width!=size),:]\n    reshape_df = reshape_df.reset_index(drop=True)\n    \n    crop_id = list(df[df.height!=df.width][\"Patient\"])\n    reshape_df['resize_type'] = 'resize'\n    reshape_df.loc[reshape_df.Patient.isin(crop_id),'resize_type'] = 'crop'\n    \n    return reshape_df","446ae7cc":"reshape_dicom_pd = mark_reshape(train_dicom_df, 512)\n#reshape_dicom_pd.head(10)","54e8b105":"train_dicom_df['resize_type'] = 'no'\nfor idx,i in enumerate(reshape_dicom_pd['Patient']):\n    train_dicom_df.loc[train_dicom_df.Patient==i,'resize_type'] = reshape_dicom_pd.loc[idx,'resize_type']\n#train_dicom_df.head()","5eed1847":"reshape_dicom_pd = mark_reshape(test_dicom_df, 512)\n#reshape_dicom_pd.head(10)","e5a8b3e8":"test_dicom_df['resize_type'] = 'no'\nfor idx,i in enumerate(reshape_dicom_pd['Patient']):\n    test_dicom_df.loc[test_dicom_df.Patient==i,'resize_type'] = reshape_dicom_pd.loc[idx,'resize_type']\n#test_dicom_df.head()","ef0caad9":"del reshape_dicom_pd","a4ff9d05":"#merge\/not merge with tabular data\nif 0:\n    train_df = pd.read_csv(f'{INPUT}\/train.csv')\n    temp_df = pd.DataFrame(columns=train_df.columns)\n    for i in range(len(train_dicom_df)):\n        patient_df = train_df[train_df.Patient==train_dicom_df.iloc[i].Patient]\n        zeroweek = patient_df['Weeks'].min()\n        #if sum(patient_pd.Weeks==zeroweek)>1:\n        #    print(pd.unique(patient_pd.Patient))\n        temp_df = temp_df.append(patient_df[patient_df.Weeks==zeroweek].iloc[0])\n    train_dicom_df = pd.merge(train_dicom_df, temp_df, on=['Patient'])\n    train_dicom_df.head()","dbd7ef53":"def load_scan(path,resize_type='no'):\n    \"\"\"\n    Loads scans from a folder and into a list.\n    \n    Parameters: path (Folder path)\n    \n    Returns: slices (List of slices)\n    \"\"\"\n    slices = [pydicom.read_file(path + '\/' + s) for s in os.listdir(path)]\n    slices.sort(key = lambda x: int(x.InstanceNumber))\n    \n    try:\n        slice_thickness = abs(slices[-1].ImagePositionPatient[2] - slices[0].ImagePositionPatient[2])\/(len(slices))\n    except:\n        try:\n            slice_thickness = abs(slices[-1].SliceLocation - slices[0].SliceLocation)\/(len(slices))\n        except:\n            slice_thickness = slices[0].SliceThickness\n        \n    for s in slices:\n        s.SliceThickness = slice_thickness\n        if resize_type == 'resize':\n            s.PixelSpacing = s.PixelSpacing*(s.Rows\/512)  \n    return slices","d4a2bf65":"def transform_to_hu(slices):\n    \"\"\"\n    transform dicom.pixel_array to Hounsfield.\n    Parameters: list dicoms\n    Returns:numpy Hounsfield\n    \"\"\"\n    \n    images = np.stack([file.pixel_array for file in slices])\n    images = images.astype(np.int16)\n\n    # convert ouside pixel-values to air:\n    # I'm using <= -1000 to be sure that other defaults are captured as well\n    #images[images <= -1000] = 0\n    \n    # convert to HU\n    for n in range(len(slices)):\n        \n        intercept = slices[n].RescaleIntercept\n        slope = slices[n].RescaleSlope\n        \n        if slope != 1:\n            images[n] = slope * images[n].astype(np.float64)\n            images[n] = images[n].astype(np.int16)\n            \n        images[n] += np.int16(intercept)\n    \n    return np.array(images, dtype=np.int16)","a4e71fc7":"def crop_image(img: np.ndarray):\n    edge_pixel_value = img[0, 0]\n    mask = img != edge_pixel_value\n    return img[np.ix_(mask.any(1),mask.any(0))]\n\ndef resize_image(img: np.ndarray,reshape=(512,512)):\n    img = cv2.resize(img,(512,512))\n    return img\n\ndef preprocess_img(img,resize_type):\n    if resize_type == 'resize':\n        img = [resize_image(im) for im in img]\n    if resize_type == 'crop':\n        img = [crop_image(im) for im in img]\n        \n    return np.array(img, dtype=np.int64)","c9b7284d":"class Test_Generate(Dataset):\n    def __init__(self,imgs_dicom,resize_type='no'):\n        self.imgs_dicom = imgs_dicom\n        self.resize_type = resize_type\n        \n    def __getitem__(self,index):\n        \n        slice_img = self.imgs_dicom[index].pixel_array\n        slice_img = (slice_img-slice_img.min())\/(slice_img.max()-slice_img.min())\n        slice_img = (slice_img*255).astype(np.uint8)\n        if self.resize_type == 'crop':\n            slice_img = crop_image(slice_img)\n        elif self.resize_type == 'resize':\n            slice_img = cv2.resize(slice_img,(512,512))\n            \n        slice_img = slice_img[None,:,:]\n        slice_img = (slice_img\/255).astype(np.float32)\n        return slice_img\n        \n    def __len__(self):\n        return len(self.imgs_dicom)","04bdf049":"#the model has been trained from [this](https:\/\/www.kaggle.com\/hfutybx\/unet-densenet121-lung-of-segmentation)\ndevice =  torch.device('cuda:0')\nmodel = smp.Unet('densenet121', classes=1, in_channels=1,activation='sigmoid',encoder_weights=None).to(device)\nmodel.load_state_dict(torch.load(f'\/kaggle\/input\/2020osic\/best_lung_Unet_densenet121.pth'))\nbatch = 8\n\ndef Unet_mask(model: nn.Module, dataloader: DataLoader):\n    model.eval()\n    outs = []\n    for idx, sample in enumerate(dataloader):\n        image = sample\n        image = image.to(device)\n        with torch.no_grad():\n            out = model(image)\n        out = out.cpu().data.numpy()\n        out = np.where(out>0.5,1,0)\n        out = np.squeeze(out,axis=1)\n        outs.append(out)\n\n    outs = np.concatenate(outs)\n    return outs","cebb0847":"def caculate_lung_volume(patient_scans,patient_masks):\n    \"\"\"\n    caculate volume of lung from mask\n    Parameters: list dicom scans,list patient CT Mask\n    Returns: volume cm\u00b3\u3000(float)\n    \"\"\"\n    lung_volume = 0\n    for i in range(len(patient_masks)):\n        \n        pixel_spacing = patient_scans[i].PixelSpacing\n        slice_thickness = patient_scans[i].SliceThickness\n        lung_volume += np.count_nonzero(patient_masks[i])*pixel_spacing[0]*pixel_spacing[1]*slice_thickness\n        \n    return lung_volume*0.001","a83254cd":"def caculate_histgram_statistical(patient_images,patient_masks,thresh = [-600,0]):\n    \"\"\"\n    caculate hisgram kurthosis of lung hounsfield\n    Parameters: list patient CT image 512*512,thresh divide lung\n    Returns: histgram statistical characteristic(Mean,Skew,Kurthosis)\n    \"\"\"\n    statistical_characteristic = dict(Mean=0,Skew=0,Kurthosis=0)\n    num_slices = len(patient_images)\n    \n    #patient_images = patient_images[int(num_slices*0.1):int(num_slices*0.9)]\n    #patient_masks = patient_masks[int(num_slices*0.1):int(num_slices*0.9)]\n    patient_images = patient_masks*patient_images\n    patient_images_nonzero = patient_images[np.nonzero(patient_images)]\n    \n    s_pixel = patient_images_nonzero.flatten()\n    s_pixel = s_pixel[np.where((s_pixel>thresh[0])&(s_pixel<thresh[1]))]\n    \n    statistical_characteristic['Mean'] = np.mean(s_pixel)\n    statistical_characteristic['Skew'] = skew(s_pixel)\n    statistical_characteristic['Kurthosis'] = kurtosis(s_pixel)\n    \n    return statistical_characteristic","a82bd39f":"def extract_ct_features(dicom_path: str, dicom_df: pd.DataFrame)->pd.DataFrame:\n    lung_stat_pd = pd.DataFrame(columns=['Patient','Volume','Mean','Skew','Kurthosis'])\n\n    for i in tqdm(range(len(dicom_df))):\n        path = os.path.join(dicom_path, dicom_df.iloc[i].Patient)\n        lung_stat_pd.loc[i,'Patient'] = dicom_df.iloc[i].Patient\n        patient_scans = load_scan(path)\n\n        ds = Test_Generate(patient_scans, dicom_df.iloc[i].resize_type)\n        loader = DataLoader(ds, batch_size=batch, shuffle=False, num_workers=4)\n        masks = Unet_mask(model, loader)\n\n\n        patient_images = transform_to_hu(patient_scans)\n        patient_images = preprocess_img(patient_images, dicom_df.loc[i,'resize_type'])\n\n        lung_stat_pd.loc[i,'Volume'] = caculate_lung_volume(patient_scans,masks)                           \n        #patient_images = resize_image(patient_images) if dicom_pd.iloc[i].resize_type=='resize' else patient_images\n        #patient_images = resize_image(patient_masks) if dicom_pd.iloc[i].resize_type=='resize' else patient_images\n\n        statistical_characteristic = caculate_histgram_statistical(patient_images,masks)\n        lung_stat_pd.loc[i,'Mean'] = statistical_characteristic['Mean']\n        lung_stat_pd.loc[i,'Skew'] = statistical_characteristic['Skew']\n        lung_stat_pd.loc[i,'Kurthosis'] = statistical_characteristic['Kurthosis']\n        \n    return lung_stat_pd","602da902":"train_feature = extract_ct_features(train_dicom_path, train_dicom_df)\ntrain_dicom_feature = pd.merge(train_dicom_df, train_feature, on=['Patient'])\ntrain_dicom_feature = train_dicom_feature.drop(['list_dicom', 'height','width','resize_type','n_dicom'], axis=1)\n#train_dicom_feature.head()","1390a318":"train_dicom_feature.to_csv(f'{WORKING}\/CT_feature-train.csv',index=False)","2e7f6518":"#merge\/not merge with tabular data\nif 0:\n    test_df = pd.read_csv(f'{INPUT}\/test.csv')\n    temp_df = pd.DataFrame(columns=test_df.columns)\n    for i in range(len(test_dicom_df)):\n        patient_df = test_df[test_df.Patient==test_dicom_df.iloc[i].Patient]\n        zeroweek = patient_df['Weeks'].min()\n        #if sum(patient_pd.Weeks==zeroweek)>1:\n        #    print(pd.unique(patient_pd.Patient))\n        temp_df = temp_df.append(patient_df[patient_df.Weeks==zeroweek].iloc[0])\n    test_dicom_df = pd.merge(test_dicom_df, temp_df, on=['Patient'])\n    test_dicom_df.head()","0d65b8b7":"test_feature = extract_ct_features(test_dicom_path, test_dicom_df)\ntest_dicom_feature = pd.merge(test_dicom_df, test_feature, on=['Patient'])\ntest_dicom_feature = test_dicom_feature.drop(['list_dicom', 'height','width','resize_type','n_dicom'], axis=1)\n#test_dicom_feature.head()","5bf110fb":"test_dicom_feature.to_csv(f'{WORKING}\/CT_feature-test.csv',index=False)","23f941da":"# References:\n1. https:\/\/www.kaggle.com\/hfutybx\/osic-feature-extract-from-ct\n2. https:\/\/www.kaggle.com\/allunia\/pulmonary-fibrosis-dicom-preprocessing\n3. https:\/\/www.kaggle.com\/aadhavvignesh\/lung-segmentation-by-marker-controlled-watershed\n4. https:\/\/www.kaggle.com\/currypurin\/osic-image-shape-eda-and-preprocess\n5. https:\/\/kaggle.com\/kugane\/lazy-lung-cropping\/notebook","0c45772d":"## Background\nThis work is a fork from great notebook:\nhttps:\/\/www.kaggle.com\/hfutybx\/osic-feature-extract-from-ct\n\nI am just refactoring the code for me to make it easier to extract features from both train and test dicom. The output is just extracted features (volume, mean, skew and kurthosis) without merging tabular data.\nI also optionally remove \/ remark visualization with the purpose this notebook can be integrated later to model training and inference.","28d55242":"![image.png](attachment:image.png)","50fc8a0e":"## CT Image Preprocessing\n\nThe size of the images are not uniform, need to unify them to 512*512","eee5d82c":"Volume is 3000~4000ml is normal"}}