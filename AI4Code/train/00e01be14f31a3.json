{"cell_type":{"25f55159":"code","09f9a818":"code","635db9bf":"code","9711a38a":"code","4d30fbc0":"code","47afe8f8":"code","17623202":"code","51837951":"markdown","a100e628":"markdown","471eb4ea":"markdown","cafbf51e":"markdown","8ba4255b":"markdown","22925308":"markdown","48a5d59a":"markdown","bbf91938":"markdown","ca489cce":"markdown"},"source":{"25f55159":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nimport sklearn.preprocessing as preprocessing\nimport sklearn.model_selection as model_selection \nimport matplotlib.pyplot as plt","09f9a818":"races = pd.read_csv(r\"..\/input\/hkracing\/races.csv\", delimiter=\",\", header=0, index_col='race_id')\nraces_data = races[['venue', 'race_no', 'config', 'surface', 'distance', 'going', 'horse_ratings', 'race_class']]\nruns = pd.read_csv(r\"..\/input\/hkracing\/runs.csv\", delimiter=\",\", header=0)\nruns_data = runs[['race_id', 'result', 'won', 'horse_age', 'horse_country', 'horse_type', 'horse_rating',\n                  'declared_weight', 'actual_weight', 'draw', 'win_odds', 'trainer_id', 'jockey_id']]\ndata = runs_data.join(races_data, on='race_id')\n# drop race_id after join because it's not a feature\ndata = data.drop(columns=['race_id'])\nprint(data.head())","635db9bf":"# remove rows with NaN\nprint('data shape before drop NaN rows', data.shape)\ndata.dropna(inplace=True)\ndata.reset_index(drop=True, inplace=True)\nprint('data shape after drop NaN rows', data.shape)\n\n# encode ordinal columns\nencoder = preprocessing.OrdinalEncoder()\ndata['config'] = encoder.fit_transform(data['config'].values.reshape(-1, 1))\ndata['going'] = encoder.fit_transform(data['going'].values.reshape(-1, 1))\ndata['horse_ratings'] = encoder.fit_transform(data['horse_ratings'].values.reshape(-1, 1))\n\n# encode nominal columns\nhorse_countries = sorted(data['horse_country'].unique())\nhorse_types = sorted(data['horse_type'].unique())\ntrainer_ids = sorted(data['trainer_id'].unique())\njockey_ids = sorted(data['jockey_id'].unique())\nvenues = sorted(data['venue'].unique())\nonehot = preprocessing.OneHotEncoder(dtype=np.int, sparse=True)\nnominal_columns = ['horse_country', 'horse_type', 'venue', 'trainer_id', 'jockey_id']\nnominals = pd.DataFrame(onehot.fit_transform(data[nominal_columns]).toarray(),\n                        columns=np.concatenate((horse_countries, horse_types, venues, trainer_ids, jockey_ids)))\ndata = data.drop(columns=nominal_columns)\n\ndata = pd.concat([data, nominals], axis=1)\nprint('numberic data frame', data.shape)\nprint(data.head())","9711a38a":"# result and won are outputs, the rest are inputs\nX = data.drop(columns=['result', 'won'])\ny = data['won']\n#y = pd.DataFrame(np.where(data['result'] <= 3, 1, 0), columns=['top_3'])\n\n# standardize the inputs to similar scale\nss = preprocessing.StandardScaler()\nX = pd.DataFrame(ss.fit_transform(X),columns = X.columns)\nprint(X.head())\n\n# split data into train and test sets\nX_train, X_test, y_train, y_test = model_selection.train_test_split(X, y, train_size=0.8, test_size=0.2, random_state=1)\nprint('X_train', X_train.shape)\nprint('y_train', y_train.shape)\nprint('X_test', X_test.shape)\nprint('y_test', y_test.shape)","4d30fbc0":"model = tf.keras.Sequential([\n    tf.keras.layers.Dense(120, activation='relu', input_shape=(402,)),\n    tf.keras.layers.Dense(80, activation='relu'),\n    tf.keras.layers.Dense(8, activation='relu'),\n    tf.keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(optimizer=tf.keras.optimizers.Adam(1e-4),\n              loss='binary_crossentropy',\n              metrics=[tf.keras.metrics.Precision(name='precision')])\n\nprint(model.summary())","47afe8f8":"dataset = tf.data.Dataset.from_tensor_slices((X_train.values, y_train.values))\ntrain_dataset = dataset.shuffle(len(X_train)).batch(1000)\ndataset = tf.data.Dataset.from_tensor_slices((X_test.values, y_test.values))\nvalidation_dataset = dataset.shuffle(len(X_test)).batch(1000)\n\nprint(\"Start training..\\n\")\nhistory = model.fit(train_dataset, epochs=200, validation_data=validation_dataset)\nprint(\"Done.\")","17623202":"precision = history.history['precision']\nval_precision = history.history['val_precision']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(1, len(precision) + 1)\n\nplt.plot(epochs, precision, 'b', label='Training precision')\nplt.plot(epochs, val_precision, 'r', label='Validation precision')\nplt.title('Training and validation precision')\nplt.legend()\nplt.figure()\n\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\nplt.show()","51837951":"## Plot results","a100e628":"## Build the NN model\n- 3 hidden layers\n- output layer","471eb4ea":"## Import packages\nVery common packages to be used, e.g. pandas, numpy, tensorflow, sklearn.","cafbf51e":"## Classification with Deep Learning for Hong Kong Horse Racing\nFirst of all, I'd like to thank Graham for providing such an interesting dataset. It's really fun for me to explore the data that is related to my living place, Hong Kong.\n\nI think horse racing is predictable given all the feature parameters. It's different from Mark-6, which is totally random. I am going to train a Deep Neural Network to predict whether a horse can win a race. Deep Neural Network is able to learn any function within the massive data, which is not possible for a human to calculate manually or even with an excel.\n\nLet's see what we can find.","8ba4255b":"## Data preprocessing - prepare train\/test data\n- prepare X and y\n- standardization\n- split to train\/test sets","22925308":"## Data preprocessing - encoding\n- Deal with missing values, I simply dropped them because it's not much, just 2 rows was dropped.\n- Encode ordinal columns: config, going, horse_ratings.\n- Encode nominal columns: horse_country, horse_type, venue, trainer_id, jorkey_id.","48a5d59a":"## Conclusion\n\nWith the 4-layer Deep Neural Network, training looked normal. Training loss decreased all the way, while validation loss decreased first then increased, which meant **overfitting** happened. \n\nI chose `precision` as an evaluation parameter because it's our interest to bet on win.\n\n$ precision = \\frac{TP}{TP + FP} $\n\nIf `precision = 0.2`, it mean we bet for winning horse 10 times and only 2 times is correct.\n\nAt the end, we could reach validation precision around 0.26. I am not sure `precision = 0.26` will let us win the market or not. However, the network generalizes poorly from Machine Learning point of view. \n\nI'd like to hear from you.\n\nThank you.","bbf91938":"## Train","ca489cce":"## Data preprocessing - read inputs\nHere, I am going to select some features that I think useful. I will also join runs.csv and races.csv because they are related and each includes some features for the classification."}}