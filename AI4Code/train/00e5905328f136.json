{"cell_type":{"85c2a8ee":"code","e7c1a5bf":"code","476235db":"code","fa27cb4e":"code","68285a5b":"code","7a8aa6b1":"code","ed32a7b6":"code","88f3e84f":"code","1cbe35a2":"code","9790b1fe":"code","b790c851":"code","ac6badca":"code","1a42ab93":"code","7cb18b3b":"code","d8fe0068":"code","af6856da":"code","1f3602c0":"code","ffd1fce8":"code","04a8d96a":"code","86c84670":"code","c3fff04f":"code","ce352420":"code","1dd6ad68":"code","fce45d40":"code","0e1e7f29":"code","e46fe0d9":"code","cb218f85":"code","ab49c88f":"code","85de9b9d":"code","2454ee50":"markdown","913491ab":"markdown"},"source":{"85c2a8ee":"import os\nimport gc\nimport sys\nimport time\nimport json\nimport glob\nimport random\nfrom pathlib import Path\nimport pandas as pd\n\nfrom PIL import Image\nimport cv2\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom imgaug import augmenters as iaa\nfrom collections import ChainMap\n\nimport itertools\nfrom tqdm import tqdm","e7c1a5bf":"input_dir = '\/kaggle\/input'\noutput_dir = '\/kaggle\/working'\ncategory_list = [\"pivot\"]\nNUM_CATS = len(category_list)\nIMAGE_SIZE = 512","476235db":"train_df = pd.read_csv(input_dir + '\/train.csv')\ntrain_df = train_df.dropna()\ntrain_df.head()","fa27cb4e":"train_dict = {}\ntrain_class_dict = {}\nfor idx, row in train_df.iterrows():\n    image_filename, class_name = row.Image_Label.split(\"_\")\n    \n    class_id = category_list.index(class_name)\n    if train_dict.get(image_filename):\n        train_dict[image_filename].append(row.EncodedPixels)\n        train_class_dict[image_filename].append(class_id)\n    else:\n        train_dict[image_filename] = [row.EncodedPixels]\n        train_class_dict[image_filename] = [class_id]","68285a5b":"df = pd.DataFrame(columns=[\"image_id\",\"EncodedPixels\",\"CategoryId\",\"Width\",\"Height\"])\nfor key, value in train_dict.items():\n    df = df.append({\"image_id\": key, \"EncodedPixels\": value, \"CategoryId\": train_class_dict[key], \"Width\": IMAGE_SIZE, \"Height\": IMAGE_SIZE},ignore_index=True)\n\ndf.head()","7a8aa6b1":"!git clone https:\/\/www.github.com\/saraivaufc\/Mask_RCNN.git\nos.chdir('Mask_RCNN')\n\n!rm -rf .git\n!rm -rf images assets","ed32a7b6":"sys.path.append('..\/Mask_RCNN')\nfrom mrcnn.config import Config\n\nfrom mrcnn import utils\nimport mrcnn.model as modellib\nfrom mrcnn import visualize\nfrom mrcnn.model import log","88f3e84f":"!wget --quiet https:\/\/github.com\/matterport\/Mask_RCNN\/releases\/download\/v2.0\/mask_rcnn_coco.h5\n!ls -lh mask_rcnn_coco.h5\n\nCOCO_WEIGHTS_PATH = 'mask_rcnn_coco.h5'","1cbe35a2":"def resize_image(image_path):\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    return img","9790b1fe":"class Dataset(utils.Dataset):\n\n    def __init__(self, df):\n        super().__init__(self)\n        \n        # Add classes\n        for i, name in enumerate(category_list):\n            self.add_class(\"dataset\", i+1, name)\n        \n        # Add images \n        for i, row in df.iterrows():\n            self.add_image(\"dataset\", \n                           image_id=row.name, \n                           path=input_dir + '\/train_images\/'+str(row.image_id), \n                           labels=row['CategoryId'],\n                           annotations=row['EncodedPixels'], \n                           height=row['Height'], width=row['Width'])\n\n    def image_reference(self, image_id):\n        info = self.image_info[image_id]\n        return info['path'], [category_list[int(x)] for x in info['labels']]\n    \n    def load_image(self, image_id):\n        return resize_image(self.image_info[image_id]['path'])\n\n    def load_mask(self, image_id):\n        info = self.image_info[image_id]\n                \n        mask = np.zeros((IMAGE_SIZE, IMAGE_SIZE, len(info['annotations'])), dtype=np.uint8)\n        labels = []\n        \n        for m, (annotation, label) in enumerate(zip(info['annotations'], info['labels'])):\n            \n            sub_mask = np.full(info['height']*info['width'], 0, dtype=np.uint8)\n            annotation = [int(x) for x in annotation.split(' ')]\n            \n            for i, start_pixel in enumerate(annotation[::2]):\n                try:\n                    sub_mask[start_pixel: start_pixel+annotation[2*i+1]] = 1\n                except Exception:\n                    pass\n\n            sub_mask = sub_mask.reshape((info['height'], info['width']), order='F')\n            sub_mask = cv2.resize(sub_mask, (IMAGE_SIZE, IMAGE_SIZE), interpolation=cv2.INTER_NEAREST)\n            \n            sub_mask = np.rot90(sub_mask, 1)\n            \n            mask[:, :, m] = sub_mask\n            labels.append(int(label)+1)\n            \n        return mask, np.array(labels)\ntraining_percentage = 0.9\n\ntraining_set_size = int(training_percentage*len(df))\nvalidation_set_size = int((1-training_percentage)*len(df))\n\ntrain_dataset = Dataset(df[:training_set_size])\ntrain_dataset.prepare()\n\nvalid_dataset = Dataset(df[training_set_size:training_set_size+validation_set_size])\nvalid_dataset.prepare()\n\nfor i in range(3):\n    image_id = random.choice(train_dataset.image_ids)\n    print(train_dataset.image_reference(image_id))\n    \n    image = train_dataset.load_image(image_id)\n    mask, class_ids = train_dataset.load_mask(image_id)\n    visualize.display_top_masks(image, mask, class_ids, train_dataset.class_names, limit=NUM_CATS)","b790c851":"LR = 1e-4\nEPOCHS = [5,10]\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")","ac6badca":"class DatasetConfig(Config):\n    NAME = \"dataset\"\n    NUM_CLASSES = NUM_CATS + 1 # +1 for the background class\n    \n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 4 #That is the maximum with the memory available on kernels\n    \n    BACKBONE = 'resnet50'\n    \n    IMAGE_MIN_DIM = IMAGE_SIZE\n    IMAGE_MAX_DIM = IMAGE_SIZE    \n    IMAGE_RESIZE_MODE = 'none'\n\n    STEPS_PER_EPOCH = 1000\n    \n    RPN_ANCHOR_SCALES = (16, 32, 64, 128, 256)\n    \nconfig = DatasetConfig()\nconfig.display()","1a42ab93":"augmentation = iaa.Sequential([\n    iaa.Fliplr(0.5),\n    iaa.Flipud(0.5)\n], random_order=True)","7cb18b3b":"model = modellib.MaskRCNN(mode='training', config=config, model_dir=output_dir)\n\nmodel.load_weights(COCO_WEIGHTS_PATH, by_name=True, exclude=[\n    'mrcnn_class_logits', 'mrcnn_bbox_fc', 'mrcnn_bbox', 'mrcnn_mask'])","d8fe0068":"%%time\nmodel.train(train_dataset, valid_dataset,\n            learning_rate=LR*2,\n            epochs=EPOCHS[0],\n            layers='heads',\n            augmentation=None)\n\nhistory = model.keras_model.history.history","af6856da":"%%time\nmodel.train(train_dataset, valid_dataset,\n            learning_rate=LR,\n            epochs=EPOCHS[1],\n            layers='all',\n            augmentation=augmentation)\nnew_history = model.keras_model.history.history","1f3602c0":"for k in new_history: history[k] = history[k] + new_history[k]","ffd1fce8":"epochs = range(EPOCHS[-1])\n\nplt.figure(figsize=(18, 6))\n\nplt.subplot(131)\nplt.plot(epochs, history['loss'], label=\"train loss\")\nplt.plot(epochs, history['val_loss'], label=\"valid loss\")\nplt.legend()\nplt.subplot(132)\nplt.plot(epochs, history['mrcnn_class_loss'], label=\"train class loss\")\nplt.plot(epochs, history['val_mrcnn_class_loss'], label=\"valid class loss\")\nplt.legend()\nplt.subplot(133)\nplt.plot(epochs, history['mrcnn_mask_loss'], label=\"train mask loss\")\nplt.plot(epochs, history['val_mrcnn_mask_loss'], label=\"valid mask loss\")\nplt.legend()\n\nplt.show()","04a8d96a":"best_epoch = np.argmin(history[\"val_loss\"]) + 1\nprint(\"Best epoch: \", best_epoch)\nprint(\"Valid loss: \", history[\"val_loss\"][best_epoch-1])","86c84670":"class InferenceConfig(DatasetConfig):\n    GPU_COUNT = 1\n    IMAGES_PER_GPU = 1\n\ninference_config = InferenceConfig()\n\nmodel = modellib.MaskRCNN(mode='inference', \n                          config=inference_config,\n                          model_dir=output_dir)","c3fff04f":"glob_list = glob.glob(f'{output_dir}\/dataset*\/mask_rcnn_dataset_{best_epoch:04d}.h5')\nmodel_path = glob_list[0] if glob_list else ''\nmodel.load_weights(model_path, by_name=True)","ce352420":"# Fix overlapping masks\ndef refine_masks(masks, rois):\n    areas = np.sum(masks.reshape(-1, masks.shape[-1]), axis=0)\n    mask_index = np.argsort(areas)\n    union_mask = np.zeros(masks.shape[:-1], dtype=bool)\n    for m in mask_index:\n        masks[:, :, m] = np.logical_and(masks[:, :, m], np.logical_not(union_mask))\n        union_mask = np.logical_or(masks[:, :, m], union_mask)\n    for m in range(masks.shape[-1]):\n        mask_pos = np.where(masks[:, :, m]==True)\n        if np.any(mask_pos):\n            y1, x1 = np.min(mask_pos, axis=1)\n            y2, x2 = np.max(mask_pos, axis=1)\n            rois[m, :] = [y1, x1, y2, x2]\n    return masks, rois","1dd6ad68":"sample_df = pd.read_csv(f'{input_dir}\/test.csv')\nsample_df.head()","fce45d40":"test_df = pd.DataFrame(columns=[\"image_id\",\"EncodedPixels\",\"CategoryId\"])\nfor idx,row in sample_df.iterrows():\n    image_filename = row.Image_Label.split(\"_\")[0]\n    test_df = test_df.append({\"image_id\": image_filename},ignore_index=True)\ntest_df = test_df.drop_duplicates()\ntest_df.head()","0e1e7f29":"for i in range(8):\n    image_id = test_df.sample()[\"image_id\"].values[0]\n    image_path = str(f'{input_dir}\/test_images\/'+image_id)\n    img = cv2.imread(image_path)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    \n    result = model.detect([resize_image(image_path)])\n    r = result[0]\n    \n    if r['masks'].size > 0:\n        masks = np.zeros((img.shape[0], img.shape[1], r['masks'].shape[-1]), dtype=np.uint8)\n        for m in range(r['masks'].shape[-1]):\n            masks[:, :, m] = cv2.resize(r['masks'][:, :, m].astype('uint8'), \n                                        (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n        \n        y_scale = img.shape[0]\/IMAGE_SIZE\n        x_scale = img.shape[1]\/IMAGE_SIZE\n        rois = (r['rois'] * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n        \n        masks, rois = refine_masks(masks, rois)\n    else:\n        masks, rois = r['masks'], r['rois']\n        \n    visualize.display_instances(img, rois, masks, r['class_ids'], \n                                ['bg']+category_list, r['scores'],\n                                title=image_id, figsize=(12, 12))","e46fe0d9":"def rle_encoding(x):\n    dots = np.where(x.T.flatten() == 1)[0]\n    run_lengths = []\n    prev = -2\n    for b in dots:\n        if (b>prev+1): run_lengths.extend((b + 1, 0))\n        run_lengths[-1] += 1\n        prev = b\n    return ' '.join([str(x) for x in run_lengths])","cb218f85":"submission_df = sample_df.copy()\nsubmission_df[\"EncodedPixels\"] = \"\"\nwith tqdm(total=len(test_df)) as pbar:\n    for i,row in test_df.iterrows():\n        pbar.update(1)\n        image_id = row[\"image_id\"]\n        image_path = str(f'{input_dir}\/test_images\/'+image_id)\n        img = cv2.imread(image_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        result = model.detect([resize_image(image_path)])\n        r = result[0]\n\n        if r['masks'].size > 0:\n            masks = np.zeros((img.shape[0], img.shape[1], r['masks'].shape[-1]), dtype=np.uint8)\n            for m in range(r['masks'].shape[-1]):\n                masks[:, :, m] = cv2.resize(r['masks'][:, :, m].astype('uint8'), \n                                            (img.shape[1], img.shape[0]), interpolation=cv2.INTER_NEAREST)\n\n            y_scale = img.shape[0]\/IMAGE_SIZE\n            x_scale = img.shape[1]\/IMAGE_SIZE\n            rois = (r['rois'] * [y_scale, x_scale, y_scale, x_scale]).astype(int)\n            masks, rois, class_ids = r['masks'], r['rois'], r['class_ids']\n\n            #The following piece of code is creating rectangular masks from\n            # the ROIs instead of using the masks drawn by the MaskRCNN.\n            # It also removes any missing area from the imagery from the predicted masks.\n            # Everything is added directly to the submission dataframe.\n            rectangular_masks = []\n            mask_dict = dict(ChainMap(*list(map(lambda x: {x: []}, category_list))))\n            \n            for roi, class_id in zip(rois, class_ids):\n                rectangular_mask = np.zeros((512,512))\n                rectangular_mask[roi[0]:roi[2], roi[1]:roi[3]] = 255\n                img = cv2.resize(img, dsize=(512,512), interpolation = cv2.INTER_LINEAR)\n                cropped_img = img[roi[0]:roi[2], roi[1]:roi[3]]\n                \n                kernel = np.ones((5,5),np.uint8)\n                missing_data = np.where(cropped_img[:,:,0]==0,255,0).astype('uint8')\n                contour_mask = np.zeros(missing_data.shape)\n                opening = cv2.morphologyEx(missing_data.astype('uint8'), cv2.MORPH_OPEN, kernel)\n                contours= cv2.findContours(opening,cv2.RETR_TREE,cv2.CHAIN_APPROX_SIMPLE)\n                if len(contours[0])>0:\n                    largest_contour = max(contours[0], key = cv2.contourArea)\n                    cv2.fillPoly(contour_mask, pts =[largest_contour], color=(255))\n                    kernel = np.ones((5,5),np.uint8)\n                    opening = cv2.morphologyEx(contour_mask, cv2.MORPH_OPEN, kernel)\n                    fixed_mask = np.where(opening[:,:]==255,0,255)\n                    rectangular_mask[roi[0]:roi[2], roi[1]:roi[3]] = fixed_mask.copy()\n                    \n                if mask_dict[category_list[class_id-1]]==[]:\n                    mask_dict[category_list[class_id-1]] = rectangular_mask\n                else:\n                    previous_mask = mask_dict[category_list[class_id-1]].copy()\n                    #prevents a bug where the mask is in int64\n                    previous_mask = previous_mask.astype('float64')\n                    boolean_mask = np.ma.mask_or(previous_mask, rectangular_mask)\n                    merged_mask = np.where(boolean_mask, 255, 0)\n                    mask_dict[category_list[class_id-1]] = merged_mask\n\n            \n            #Going through the masks per category and create a md mask in RLE\n            for cloud_category in mask_dict.keys():\n                if mask_dict[cloud_category]!=[]:\n                    #resizing for submission\n                    resized_mask = cv2.resize((mask_dict[cloud_category]\/255).astype('uint8'), dsize=(525,350), interpolation = cv2.INTER_LINEAR)\n                    rle_str = rle_encoding(resized_mask)\n                    image_label = \"{}_{}\".format(image_id,cloud_category)\n                    submission_df.loc[submission_df['Image_Label']==image_label,'EncodedPixels'] = rle_str\n        else:\n            masks, rois = r['masks'], r['rois']","ab49c88f":"submission_df.query(\"EncodedPixels!=''\").head()","85de9b9d":"submission_df.to_csv(f'{output_dir}\/submission.csv',index=False)","2454ee50":"# Imports","913491ab":"# Settings"}}