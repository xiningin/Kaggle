{"cell_type":{"1b03f0bf":"code","3b0556f9":"code","7383cf35":"code","8c7e749f":"code","5676b973":"code","b6d69b8e":"code","139c65d3":"code","f12dc6f2":"code","0dd5e738":"code","61221d67":"code","3281f2f9":"markdown"},"source":{"1b03f0bf":"import numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom keras.utils.np_utils import to_categorical\nfrom tensorflow.keras.optimizers.schedules import ExponentialDecay\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom sklearn.model_selection import train_test_split","3b0556f9":"# Read the data\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv').to_numpy()\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv').to_numpy()","7383cf35":"# Separate the images from their labels\nX = train[:, 1:]\ny = train[:, 0]\n\n# Normalize the image data\nX = X \/ 255\ntest = test \/ 255","8c7e749f":"X = X.reshape(42000, 28, 28, 1) # Set the data to be the right shape for the NN\nyh = to_categorical(y, 10) # One-hot encode the labels","5676b973":"# Add data augmentation\nidg = ImageDataGenerator(rotation_range=15, width_shift_range=4, height_shift_range=4)\nidg.fit(X)","b6d69b8e":"ensemble = []\n# Make 15 CNNs.\n# The CNNs consist of 6 convolutional layers, 2 of which (with strides=2) perform downsampling. These are followed by a fully-connected layer and an output layer.\n# They use ReLU as the activation function (except for the output layer). The CNNs also use batch normalization and dropout for regularization.\nfor i in range(15):    \n    cnn = keras.Sequential()\n\n    cnn.add(layers.Conv2D(filters=32, kernel_size=3, activation='relu', input_shape=(28, 28, 1)))\n    cnn.add(layers.BatchNormalization())\n    \n    cnn.add(layers.Conv2D(filters=32, kernel_size=3, activation='relu'))\n    cnn.add(layers.BatchNormalization())\n    \n    cnn.add(layers.Conv2D(filters=32, kernel_size=5, strides=2, activation='relu'))\n    cnn.add(layers.BatchNormalization())\n    cnn.add(layers.Dropout(0.25))\n\n    cnn.add(layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n    cnn.add(layers.BatchNormalization())\n    \n    cnn.add(layers.Conv2D(filters=64, kernel_size=3, activation='relu'))\n    cnn.add(layers.BatchNormalization())\n    \n    cnn.add(layers.Conv2D(filters=64, kernel_size=5, strides=2, activation='relu'))\n    cnn.add(layers.BatchNormalization())\n    cnn.add(layers.Dropout(0.25))\n\n    cnn.add(layers.Flatten())\n    cnn.add(layers.Dense(256, activation='relu'))\n    cnn.add(layers.BatchNormalization())\n    cnn.add(layers.Dropout(0.5))\n\n    cnn.add(layers.Dense(10, activation='softmax'))\n    \n    ensemble.append(cnn)   ","139c65d3":"steps = np.ceil(len(X) \/ 32) # Calculate the number of steps in an epoch (using batches of size 32)\n\n# Train the CNNs (this might take several hours)\nfor i in range(15):\n    \n    # Exponential decay schedule for the learning rate. Values for initial_learning_rate and decay_rate were found using grid search.\n    opt = keras.optimizers.Adam(learning_rate=ExponentialDecay(initial_learning_rate=0.003, decay_steps=steps, decay_rate=0.9))\n\n    ensemble[i].compile(optimizer=opt, loss='categorical_crossentropy', metrics=['accuracy'])\n\n    ensemble[i].fit(idg.flow(X, yh), epochs=30, verbose=0)\n    \n    print(str(i+1) + 'th NN trained')","f12dc6f2":"probs = np.zeros((28000, 10))\n# Add up predictions (probabilities) from all the CNNs\nfor i in range(15):\n    probs += ensemble[i].predict(test.reshape(28000, 28, 28, 1))","0dd5e738":"y_hat = np.argmax(probs, axis=1) # Make the predictions","61221d67":"# Generate the submission output\nsub = pd.DataFrame(y_hat, index=list(range(1, 28001)), columns=['Label'])\nsub.index.name = 'ImageId'\nsub.to_csv('sub.csv')","3281f2f9":"# Using a committee of 15 Convolutional Neural Networks to classify handwritten digits\n"}}