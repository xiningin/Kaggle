{"cell_type":{"2f53c16f":"code","c79bb4b4":"code","0b8e3b90":"code","3151d6ee":"code","517985e6":"code","24b6f620":"code","4c316519":"code","fd82ff23":"code","dada6f65":"code","c0019618":"code","e615ac7c":"code","a98ebc77":"code","f334f019":"code","f6a68623":"code","d3ff021e":"code","47c5ec4f":"code","51bcec58":"code","bb0a58a6":"code","ec242960":"code","217c25bb":"code","5b41a29c":"code","d6f833be":"code","21e97c43":"code","19904fb2":"code","6ac42f19":"code","eb5966ab":"code","ab35ed2d":"code","16824809":"code","8fec4df9":"markdown","713a960b":"markdown","32afdf6e":"markdown","36220816":"markdown","10270d07":"markdown","54c6fffa":"markdown","231e93b0":"markdown","24e91389":"markdown","b46a5094":"markdown","de371897":"markdown","5ceda7f7":"markdown","27e75b65":"markdown","2e61901a":"markdown","9d1b4003":"markdown","30a82da0":"markdown","5e73eed7":"markdown","53c1f4e2":"markdown","e5c82b86":"markdown","e00aebb2":"markdown","38ed7802":"markdown","021bbcc5":"markdown","e16cf093":"markdown","7eac4b71":"markdown","e548bcf2":"markdown","8fff489f":"markdown","f4ec5622":"markdown","be752de3":"markdown","52e8a210":"markdown","09a5dc32":"markdown","0db7ce4a":"markdown","6e321050":"markdown","d605aee9":"markdown"},"source":{"2f53c16f":"#importing libraries\n\nimport numpy as np \nimport pandas as pd \nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c79bb4b4":"train=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nresult=pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","0b8e3b90":"train.shape #shape of the data","3151d6ee":"train.info()","517985e6":"train.describe()","24b6f620":"for col in train.columns:\n    print(col,\":\",len(train[col].unique()))","4c316519":"!pip install pandas-profiling","fd82ff23":"%%javascript\nIPython.OutputArea.prototype._should_scroll = function(lines) {\n    return false;\n}","dada6f65":"%%capture\nimport pandas_profiling as pp","c0019618":"pp.ProfileReport(train)","e615ac7c":"!pip install pycaret","a98ebc77":"from pycaret.classification import *","f334f019":"clf = setup(data = train, target = 'Survived',train_size=0.7,numeric_imputation='mean',categorical_imputation='mode',feature_selection=True)","f6a68623":"compare_models()","d3ff021e":"gradientboost_model=create_model('gbc')","47c5ec4f":"tuned_model=tune_model(gradientboost_model)","51bcec58":"# ensemble tuned Gradient Boost model \nensembled_gbm = ensemble_model(tuned_model,method='Boosting')","bb0a58a6":"plot_model(ensembled_gbm,plot='learning')","ec242960":"plot_model(ensembled_gbm,plot='confusion_matrix')","217c25bb":"plot_model(ensembled_gbm,plot='class_report')","5b41a29c":"plot_model(ensembled_gbm,plot='boundary')","d6f833be":"plot_model(ensembled_gbm,plot='auc')","21e97c43":"plot_model(ensembled_gbm,plot='error')","19904fb2":"plot_model(ensembled_gbm,plot='vc')","6ac42f19":"evaluate_model(ensembled_gbm)","eb5966ab":"predict_model(ensembled_gbm,data=test)","ab35ed2d":"predictions = predict_model(ensembled_gbm, data=test)\npredictions.head()","16824809":"result['Survived'] = round(predictions['Score']).astype(int)\nresult.to_csv('Submission.csv',index=False)\nresult.head()","8fec4df9":"# Let's Predict it","713a960b":"# Understanding the Data","32afdf6e":"## pandas_profiling for simple and fast exploratory data analysis","36220816":"# Decision Boundary","10270d07":"# Ensemble Model","54c6fffa":"# Compare the Models","231e93b0":"## let's install pycaret !\n","24e91389":"**Parameters:**\n\n\ndata:  dataframe\narray-like, sparse matrix, shape (n_samples, n_features) where n_samples is the number of samples and n_features is the number of features.\n\ntarget: string\nName of the target column to be passed in as a string. The target variable could be binary or multiclass. In case of a multiclass target, all estimators are wrapped\nwith a OneVsRest classifier.\n\ntrain_size: float, default = 0.7\nSize of the training set. By default, 70% of the data will be used for training and validation. The remaining data will be used for a test \/ hold-out set.\n\n\ncategorical_features: string, default = None\nIf the inferred data types are not correct, categorical_features can be used to overwrite the inferred type. If when running setup the type of \u2018column1\u2019 is inferred as numeric instead of categorical, then this parameter can be used to overwrite the type by passing categorical_features = [\u2018column1\u2019].\n\ncategorical_imputation: string, default = \u2018constant\u2019\nIf missing values are found in categorical features, they will be imputed with a constant \u2018not_available\u2019 value. The other available option is \u2018mode\u2019 which imputes the missing value using most frequent value in the training dataset.\n\n\nnumeric_imputation: string, default = \u2018mean\u2019\nIf missing values are found in numeric features, they will be imputed with the mean value of the feature. The other available option is \u2018median\u2019 which imputes the value using the median value in the training dataset.\n\n\nfeature_selection: bool, default = False\nWhen set to True, a subset of features are selected using a combination of various permutation importance techniques including Random Forest, Adaboost and Linear correlation with target variable. The size of the subset is dependent on the feature_selection_param. Generally, this is used to constrain the feature space in order to improve efficiency in modeling. When polynomial_features and feature_interaction are used, it is highly recommended to define the feature_selection_threshold param with a lower value.\n","b46a5094":"## Quick Introduction to PyCaret - An open source low-code ML library","de371897":"<center><h1> New Approach to Titanic <sup><b>with Pycaret<\/b><\/sup><\/h1><\/center>","5ceda7f7":"## Import Whole Classification","27e75b65":"# Confusion Matrix","2e61901a":"This function ensembles the trained base estimator using the method defined in \u2018method\u2019 param (default = \u2018Bagging\u2019). The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1 and Kappa by fold (default = 10 Fold)","9d1b4003":"# let's create a Gradient Boost  Model","30a82da0":"**Setup()**-This function initializes the environment in pycaret and creates the transformation pipeline to prepare the data for modeling and deployment. setup() must called before executing any other function in pycaret. It takes two mandatory parameters: dataframe {array-like, sparse matrix} and name of the target column. All other parameters are optional.","5e73eed7":"# Evaluate Model\n\n\nThis function displays a user interface for all of the available plots for a given estimator. It internally uses the plot_model() function.","53c1f4e2":"This function creates a model and scores it using Stratified Cross Validation.The output prints a score grid that shows Accuracy, AUC, Recall, Precision, F1, Kappa and MCC by fold (default = 10 Fold). This function returns a trained model object","e5c82b86":"# Setting up the Environment","e00aebb2":"# Titanic Data Report","38ed7802":"You can reach pycaret website and documentation from https:\/\/pycaret.org\n\nPyCaret is an open source, low-code machine learning library in Python that allows you to go from preparing your data to deploying your model within seconds in your choice of notebook environment.\n\nPyCaret being a low-code library makes you more productive. With less time spent coding, you and your team can now focus on business problems.\n\nPyCaret is simple and easy to use machine learning library that will help you to perform end-to-end ML experiments with less lines of code.\n\nPyCaret is a business ready solution. It allows you to do prototyping quickly and efficiently from your choice of notebook environment.","021bbcc5":"This function tunes the hyperparameters of a model and scores it using Stratified Cross Validation. The output prints a score grid that shows Accuracy, AUC, Recall Precision, F1, Kappa, and MCCby fold (by default = 10 Folds). This function returns a trained model object.","e16cf093":"## loading data files","7eac4b71":"## Unique values\n","e548bcf2":"<img src=\"https:\/\/www.usnews.com\/dims4\/USNEWS\/4f3cd50\/2147483647\/thumbnail\/970x647\/quality\/85\/?url=http%3A%2F%2Fmedia.beam.usnews.com%2F0e%2Fe187dd2f8f1fe5be9058fa8eef419e%2F7018FE_DA_080929titanic.jpg\" width=1200 \/>","8fff489f":"# AUC Curve","f4ec5622":"## Let's tune it!","be752de3":"# Class Prediction Error","52e8a210":"# Classification Report","09a5dc32":"# Validation Curve","0db7ce4a":"<img src=\"https:\/\/pycaret.org\/wp-content\/uploads\/2020\/04\/thumbnail.png\"\/>","6e321050":"We can clearly see that accuracy for Gradient Boosting classifier is higher than other models","d605aee9":"# Learning Curve"}}