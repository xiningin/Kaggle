{"cell_type":{"4eb82bb9":"code","e1592e8f":"code","ac0523cf":"code","fdc344b7":"code","486539b5":"code","f9c6c51b":"code","2587210a":"code","9c80c168":"code","a8ff120e":"code","6349bfb7":"code","347bf4de":"code","901e0342":"markdown","64a6e1d2":"markdown","8e3b37b7":"markdown"},"source":{"4eb82bb9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=Warning)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e1592e8f":"df = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/5802.csv\", low_memory=False)\nprint(df.shape)\ndf.head().style.set_properties(**{'background-color':'black',\n                                     'color': '#03e8fc'})","ac0523cf":"#Code by Parul Pandey  https:\/\/www.kaggle.com\/parulpandey\/a-guide-to-handling-missing-values-in-python\n\n\nfrom sklearn.impute import SimpleImputer\ndf_most_frequent = df.copy()\n#setting strategy to 'mean' to impute by the mean\nmean_imputer = SimpleImputer(strategy='most_frequent')# strategy can also be mean or median \ndf_most_frequent.iloc[:,:] = mean_imputer.fit_transform(df_most_frequent)","fdc344b7":"df_most_frequent.isnull().sum()","486539b5":"#!pip install -U imbalanced-learn","f9c6c51b":"conda install -c conda-forge imbalanced-learn","2587210a":"!pip install dabl\nimport dabl","9c80c168":"dabl.detect_types(df)","a8ff120e":"dabl.plot(df, target_col=\"lp_id\");","6349bfb7":"dabl.plot(df, target_col=\"pct_access\");","347bf4de":"dabl.plot(df, target_col=\"engagement_index\");","901e0342":"#To make Dabl works I had to add that conda snippet","64a6e1d2":"<h1><span class=\"label label-default\" style=\"background-color:black;border-radius:100px 100px; font-weight: bold; font-family:Garamond; font-size:20px; color:#03e8fc; padding:10px\">dabl, the Data Analysis Baseline Library<\/span><\/h1><br>\n\ndabl, the Data Analysis Baseline Library\n\n\nThis project tries to help make supervised machine learning more accessible for beginners, and reduce boiler plate for common tasks.\n\nThis library is in very active development, so it\u2019s not recommended for production use.\n\nDevelopment at github.com\/amueller\/dabl.\n\nhttps:\/\/amueller.github.io\/dabl\/dev\/","8e3b37b7":"For now, that is all with dabl, the Data Analysis Baseline Library."}}