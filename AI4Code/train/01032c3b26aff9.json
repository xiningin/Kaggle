{"cell_type":{"61e469a0":"code","b2b93e5c":"code","30cbf56f":"code","e407083d":"code","1438425c":"code","6ef6a2ea":"code","446a5b99":"code","8db63958":"code","268e5aa2":"code","e55303e8":"code","fdda0c7a":"code","71d4ef57":"code","76f139bb":"code","59f25ca9":"code","bda630ca":"code","43cb5707":"code","85434cda":"code","ac17bd78":"code","8b28cbc8":"markdown","2f868e39":"markdown","2604c169":"markdown","f5112158":"markdown","0ddde167":"markdown","3a5d77ec":"markdown","107b3152":"markdown","210b0fe7":"markdown","543f802d":"markdown","63c02077":"markdown","9a742290":"markdown","6896f24b":"markdown","4992d693":"markdown","52d6bf37":"markdown","e1873179":"markdown","85d5ea95":"markdown","c9d51e4e":"markdown","a3595e70":"markdown","7a36d73c":"markdown","6e99cc22":"markdown","e3a259d5":"markdown","8b5e40c6":"markdown","a58be3cc":"markdown","e01450df":"markdown","54d80ffb":"markdown","97ed1bef":"markdown","20679354":"markdown","13bfb3c1":"markdown","a5a27a1f":"markdown","84286c2d":"markdown","33fbe72c":"markdown","9553cb16":"markdown","def75a1a":"markdown","7bfff588":"markdown","2137b78f":"markdown","a8fa3280":"markdown","02a5cec2":"markdown"},"source":{"61e469a0":"!pip install textstat\n!pip install pyspellchecker","b2b93e5c":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport textstat\nfrom spellchecker import SpellChecker\nfrom termcolor import colored\n\nplt.style.use('ggplot')","30cbf56f":"# read data into dataframes\ntrain_df = pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')\ntext_files = os.listdir('\/kaggle\/input\/feedback-prize-2021\/train')\n\n# read each text file's data into text column\ntexts = []\nfor file in text_files:\n    with open(f'\/kaggle\/input\/feedback-prize-2021\/train\/{file}') as f:\n        lines = f.readlines()\n    texts.append({'id': file[:-4], 'text': ''.join(lines)})\ntrain_text_df = pd.DataFrame(texts)","e407083d":"train_df.info()","1438425c":"print(f'Total number of text files in train folder => {len(text_files)}')","6ef6a2ea":"train_df.head()","446a5b99":"# discourse value counts\ndiscourse_type_freq_df = train_df.discourse_type.value_counts()\n\nplt.figure(figsize=(10, 6))\nplt.barh(discourse_type_freq_df.index, discourse_type_freq_df.values, label='', color = \"#0096FF\", ec=\"black\")\nplt.xlabel('count')\nplt.yticks(discourse_type_freq_df.index, rotation = 0)\nplt.title('Count of discourse elements')\nplt.show()","8db63958":"# discourse type frequency\ndiscourse_type_freq_df = train_df.discourse_type_num.value_counts()\n\nplt.figure(figsize=(12, 12))\nplt.barh(discourse_type_freq_df.index, discourse_type_freq_df.values, label='', color = \"#0096FF\", ec=\"black\")\nplt.xlabel('count')\nplt.title('Count of discourse type elements')\nplt.show()","268e5aa2":"# extract features using textstat library\ntrain_text_df['char_count'] = train_text_df.text.apply(lambda essay: textstat.char_count(str(essay), ignore_spaces=False))\ntrain_text_df['word_count'] = train_text_df.text.apply(lambda essay: textstat.lexicon_count(str(essay)))\ntrain_text_df['sentence_count'] = train_text_df.text.apply(lambda essay: textstat.sentence_count(str(essay)))\n\nfig = plt.figure(figsize=(14,10))\n\nax1 = fig.add_subplot(221)\nax1.hist(train_text_df.word_count, bins=30, label='less toxic wc', color = \"#0096FF\")\nax1.set_title('Word count distribution')\n\nax2 = fig.add_subplot(222)\nax2.hist(train_text_df.sentence_count, bins=30, label='less toxic wc', color = \"#0096FF\")\nax2.set_title('Sentence count distribution')\n\nax3 = fig.add_subplot(223)\nax3.boxplot(train_text_df.word_count, vert=False, notch=True, widths=0.35,\n            patch_artist=True,  boxprops=dict(facecolor=\"#0096FF\"))\n\nax4 = fig.add_subplot(224)\nax4.boxplot(train_text_df.sentence_count, vert=False, notch=True, widths=0.35,\n            patch_artist=True,  boxprops=dict(facecolor=\"#0096FF\"))\n\nplt.show()","e55303e8":"discourse_count_df = pd.DataFrame(columns=['id', 'Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement', 'Counterclaim', 'Rebuttal'])\n\n# prepping train_text_df\nfor group_id, group_df in train_df.groupby('id'):\n    discourse_dict = group_df.discourse_type.value_counts().to_dict()\n    discourse_dict['id'] = group_id\n    discourse_count_df = discourse_count_df.append(discourse_dict, ignore_index=True)\n\ndiscourse_count_df = discourse_count_df.fillna(0)\ntrain_text_df = train_text_df.merge(discourse_count_df, how='left', on='id')\n\nplt.figure(figsize=(9, 7))\nplt.title('Correlation among all discourses')\ncorr_df = train_text_df.drop(['id', 'text', 'sentence_count', 'word_count'], axis=1).corr(method='pearson')\nmask = np.triu(np.ones_like(corr_df))\nhmap=sns.heatmap(corr_df,cmap=\"Spectral\")\nplt.show()","fdda0c7a":"train_df['len_discourse'] = train_df['discourse_end'] - train_df['discourse_start']\ndisc_prop_dict = dict((k, []) for k in ['Lead', 'Position', 'Evidence', 'Claim', 'Concluding Statement', 'Counterclaim', 'Rebuttal'])\n\nfor group_id, group_df in train_df.groupby('id'):\n    # for each essay\n    # get length of each essay\n    essay_len = int(train_text_df[train_text_df['id']==group_id]['char_count'].iloc[0])\n    char_count = train_text_df[train_text_df['id']==group_id].char_count.iloc[0]\n    \n    group_df['discourse_proportion'] = group_df['len_discourse']\/char_count\n    disc_agg_series = group_df.groupby('discourse_type')['discourse_proportion'].agg('sum').round(2)\n    for discourse, discourse_proportion in disc_agg_series.items():\n        disc_prop_dict[discourse].append(discourse_proportion)\n","71d4ef57":"new_disc_prop_dict = {}\nfor disc, arr in disc_prop_dict.items():\n    new_disc_prop_dict[disc] = round(sum(arr)\/len(arr), 2)\nnew_disc_prop_dict = dict(sorted(new_disc_prop_dict.items(), key=lambda kv: kv[1]))\n\nplt.figure(figsize=(16,9))\nplt.title('Discourse propotion in essays')\ncolors = sns.color_palette(\"Paired\")\nplt.pie(x= new_disc_prop_dict.values(), labels = new_disc_prop_dict.keys(), colors = colors,\n        explode= [0.1]*len(new_disc_prop_dict.keys()) ,autopct='%.0f%%', shadow = True)\nplt.show()","76f139bb":"start_proportion = []\nfor i,row in train_df.iterrows():\n    essay_len = int(train_text_df[train_text_df['id']==row.id]['char_count'].iloc[0])\n    start_proportion.append(row.discourse_start\/essay_len)\n\ntrain_df['start_proportion'] = start_proportion\n\ndisc_start_proportion = {}\nfor discourse, disc_group_df in train_df.groupby('discourse_type'):\n    disc_start_proportion[discourse] = disc_group_df.start_proportion.to_list()","59f25ca9":"reorder_list = ['Lead', 'Position', 'Claim', 'Evidence',  'Counterclaim', 'Rebuttal',  'Concluding Statement']\ndisc_start_proportion = {k: disc_start_proportion[k] for k in reorder_list}\nlabels, data = disc_start_proportion.keys(), disc_start_proportion.values()\n\nplt.figure(figsize=(14,9))\nplt.title('Distribution of discourses in essays')\nplt.boxplot(data, notch=True, patch_artist=True,  boxprops=dict(facecolor=\"#0096FF\"))\nplt.xticks(range(1, len(labels) + 1), labels)\nplt.show()","bda630ca":"spell = SpellChecker()\n\ndef spell_check(text):\n    word_list=text.split()\n    incorrect_word_count = len(list(spell.unknown(word_list)))\n    return incorrect_word_count\n\nincorrect_spelling_df = pd.DataFrame(columns=['total_word_count', 'incorrect_word_count'])\nfor i, row in train_text_df.sample(n = 1000, replace = False).iterrows():\n    incorrect_spelling_df = incorrect_spelling_df.append({\n        \"total_word_count\": row.word_count,\n        \"incorrect_word_count\": spell_check(row.text)\n    }, ignore_index=True)\n\nplt.figure(figsize=(12,7))\nplt.title('Total words vs incorrect word count in essays')\nsns.scatterplot(data = incorrect_spelling_df, x = \"incorrect_word_count\", y = \"total_word_count\")\nplt.show()","43cb5707":"# code credits: https:\/\/www.kaggle.com\/ilialar\/feedback-prize-simple-eda\n\ndef color_text(text_id, train_df, color_scheme = None):\n    if not color_scheme:\n        color_scheme = {\n        'Lead': 'red',\n        'Position': 'green',\n        'Claim': 'blue',\n        'Counterclaim': 'magenta',\n        'Rebuttal': 'yellow',\n        'Evidence': 'cyan',\n        'Concluding Statement': 'yellow'\n    } \n    with open(f'\/kaggle\/input\/feedback-prize-2021\/train\/{text_id}.txt') as f:\n        lines = f.readlines()\n    text = ''.join(lines)\n    \n    annot_df = train_df[train_df.id == text_id]\n    blocks = [(int(row['discourse_start']),int(row['discourse_end']), color_scheme[row['discourse_type']]) for k, row in annot_df.iterrows()]\n    blocks.sort()\n    i = 0\n    last_symbol = -1\n    while i < len(blocks):\n        if blocks[i][0] > last_symbol + 1:\n            blocks.insert(i, (last_symbol+1, blocks[i][0] - 1, None))\n        last_symbol = blocks[i][1]\n        i += 1\n    if last_symbol < len(text):\n        blocks.append((last_symbol+1, len(text) - 1, None))\n\n    colored_text = ''.join([colored(text[x[0]:x[1]+1], x[2]) for x in blocks])\n    return colored_text","85434cda":"print(color_text('423A1CA112E2', train_df))","ac17bd78":"print(color_text('0000D23A521A', train_df))","8b28cbc8":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","2f868e39":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","2604c169":"### ***The graph shows the proportion of discourses if they are present in the essay. Evidence takes the largest proportion making upto almost half the essay. Claim, concluding statement and lead make up more or less similar percentages in an essay.***","f5112158":"### ***Cool, hoomans make mistakes***. ***Let's find out if there are spelling mistakes in the essays***","0ddde167":"# Import Libraries","3a5d77ec":"###  ***Next, let's plot to see the count for each type of discourse element***","107b3152":"### ***Thanks for giving it a read.***","210b0fe7":"###  ***Let's take a peek into the data***","543f802d":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","63c02077":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","9a742290":"### ***Next, let's try to answer the question - If all the discourses were to be present in the sentence, how much would each discourse make up in the sentence?***","6896f24b":"###  ***There is no missing data which is great! There are 144293 entries with 8 columns***","4992d693":"###  ***There are 15594 text files in train folder***\n\n###  ***So in summary, there are around 16K text files and 144K annotated lines.***","52d6bf37":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","e1873179":"###  ***So, around 50K clamins have been made and 45K evidences have been provided in 16K text files! However, it is clear that not all essay's have a lead and a concluding statement.***","85d5ea95":"###  ***Let's start by importing all libraries needed here***","c9d51e4e":"###  ***Next, let's have a look at the text files.***\n###  ***We'll start with word counts and sentence counts in the essays***","a3595e70":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","7a36d73c":"###  ***Load all data into Dataframes***","6e99cc22":"### ***The essays have a median of around 400 words and a median of 17 sentences per essay.***","e3a259d5":"### ***Further, we'll look at the correlation among all dicourses***","8b5e40c6":"# Load dataset","a58be3cc":"### ***There are good few spelling mistakes in the essays. The above graph is from sample of 1000 text files.***\n### ***A simple scatter plot shows the obvious relation between number number of incorrect words and total words in the essays. There are words in the essays such as Generic_name or student_name that are also counted in this. Well, the point is we'll have to correct these mistakes before processing any text.***","e01450df":"### ***Alright, now let's see where in an essay are the discourses most likey to be found.***","54d80ffb":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","97ed1bef":"### ***Takeaways***\n### ***- The highest correlation is between Rebuttal(an opposing argument or debate) and Counterclaim which maskes sense.***\n### ***- The next highest correlation was between Claim and Evidence - the 2 most common discourses.***\n### ***- Looking at the correlation between character count and all features, Evidence, Claim and Lead tend to occur the most when it is a bigger essay.***","20679354":"### ***This plot depicts the distribution of start position of a discourse in an essay with start to end of an essay being 0 to 1.***\n\n### - ***Lead ususally is the first thing you would see in an essay and probably explains what the essay is going to be about.*** \n### - ***Position is the overall stance that the writer of an essay takes in answering the question or on the issue\/topic at hand. The meadian from it's boxplot depicts it usually follows Lead but with so many outliers it also means it can be distributed throughout the essay.***\n### - ***Next, the essay structure is followed by Claim, Evidence, Counterclaim and Rebuttal.***\n### - ***Concuding statement is often the last sentence in an essay but there are quite a few conclusions made along the way as well.***\n","13bfb3c1":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","a5a27a1f":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","84286c2d":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","33fbe72c":"<div style=\"background-color:#dee3e3; padding: 10px 50px 10px 50px;\">\n<h1 style=\"font-family: Arial, Helvetica, sans-serif;text-shadow: grey 0px 0px 3px; font-weight: bold; font-size: 230%;\"><center>Feedback Prize<\/center><\/h1>\n\n<p style=\"font-size: 110%;font-style: italic;\" >This notebook attempts to take a look at various discourses and their distibution in essays. <\/p>\n<\/div>","9553cb16":"# Exploratory Data Analysis","def75a1a":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","7bfff588":"### ***Finally, let's look at some sample texts in different colours to understand the structure.***","2137b78f":"###  ***Quite interesting! There are as far as 12 evidences or 12 claims made in some essays!***","a8fa3280":"<div style=\"\">\n<p id=\"lib\" style=\"color: white; text-shadow: black 0px 0px 3px; font-weight: bold; font-size: 150%; font-family: Arial, Helvetica, sans-serif;\n          padding: 1px 0px; background-color: #f2843a; border-radius: 5px;\">\n    <b> <\/b>\n<\/p> \n<\/div>","02a5cec2":"### ***That is all for this notebook!***"}}