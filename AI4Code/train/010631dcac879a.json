{"cell_type":{"b70ee258":"code","cb817a42":"code","df4087b2":"code","a1a9aad9":"code","5b8fbf3b":"code","63e35dc9":"code","a4343e89":"code","2a181250":"code","92bcca5d":"code","226fb985":"code","ae26b37a":"code","90f8d2c7":"code","ec4a45e0":"code","3c72af85":"code","284322c9":"code","d378c5a8":"code","bf07887a":"code","ba28118e":"code","b1914cea":"code","40b4fa10":"code","a4967027":"code","8e905433":"code","022f4ece":"code","195c7349":"code","a2ba80f3":"code","9951603b":"code","2faf5425":"code","2902432b":"code","be1c9d8f":"code","d2bf2722":"code","7026e7f3":"code","0396869a":"code","a82b9139":"code","4567dd40":"code","019bccc7":"code","21eefba5":"code","5f8e722c":"markdown","6565572e":"markdown","e7f63947":"markdown","259eb0a8":"markdown","0c296887":"markdown","33e24398":"markdown","022eb834":"markdown","6bb75466":"markdown","7f5860fb":"markdown","e4a7fb8e":"markdown","d34c77e5":"markdown","fcb03e8f":"markdown","809201a3":"markdown","0243c77d":"markdown","f1924208":"markdown","1cb764ef":"markdown","009aacbc":"markdown"},"source":{"b70ee258":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras import initializers, layers\n\nfrom sklearn.model_selection import train_test_split","cb817a42":"seed = 18\nnp.random.seed(seed)","df4087b2":"import warnings\nwarnings.filterwarnings('ignore') # ignore warnings","a1a9aad9":"tf.test.gpu_device_name() # testing gpu","5b8fbf3b":"dig_mnist = pd.read_csv(\"..\/input\/Kannada-MNIST\/Dig-MNIST.csv\")\nsample_submission = pd.read_csv(\"..\/input\/Kannada-MNIST\/sample_submission.csv\")\ntest = pd.read_csv(\"..\/input\/Kannada-MNIST\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/Kannada-MNIST\/train.csv\")","63e35dc9":"train.head()","a4343e89":"train.shape","2a181250":"# Extracting label from training set\nx = train.iloc[:,1:].values\ny = train.label.values","92bcca5d":"sns.countplot(y) # Checking if it is homogenous","226fb985":"test.head()","ae26b37a":"x_test = test.drop(\"id\", axis=1).iloc[:,:].values","90f8d2c7":"dig_mnist.head()","ec4a45e0":"x_dig = dig_mnist.drop('label', axis=1).iloc[:,:].values\ny_dig = keras.utils.to_categorical(dig_mnist.label)","3c72af85":"x.shape","284322c9":"x = x.reshape(x.shape[0], 28, 28, 1)\ny = keras.utils.to_categorical(y, 10) # and transform y into vectors","d378c5a8":"x.shape","bf07887a":"x_test = x_test.reshape(x_test.shape[0], 28, 28, 1)\nx_dig = x_dig.reshape(x_dig.shape[0], 28, 28, 1)","ba28118e":"x_train, x_val, y_train, y_val = train_test_split(x, y, test_size = 0.1, random_state = seed)","b1914cea":"# This values can change and were inspired by those used in other submissions.\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255.,\n                                   rotation_range = 10,\n                                   width_shift_range = 0.25,\n                                   height_shift_range = 0.25,\n                                   shear_range = 10,\n                                   zoom_range = 0.1,\n                                   horizontal_flip = False)","40b4fa10":"# We also need to create one for the validation data set, but this will only rescale the image\nval_datagen = ImageDataGenerator(rescale=1.\/255.)","a4967027":"# Different models were tested and inspired by other submissions\nmodel = tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(64, (3,3), padding=\"same\", input_shape=(28,28,1)),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(64, (3,3), padding=\"same\"),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(128, (3,3), padding='same'),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n   \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Conv2D(256, (3,3), padding=\"same\"),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.Conv2D(256, (3,3), padding=\"same\"),\n    tf.keras.layers.BatchNormalization(momentum=0.9, epsilon=1e-5, gamma_initializer=\"uniform\"),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    \n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(256),\n    tf.keras.layers.LeakyReLU(alpha=0.1),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.Dense(10, activation=\"softmax\")\n])","8e905433":"# Let's check our model\nmodel.summary()","022f4ece":"initial_learningrate=0.001\nbatch_size = 1024\nepochs = 50","195c7349":"optimizer = RMSprop(learning_rate=initial_learningrate,\n                   momentum=0.1,\n                   centered=True,\n                   name=\"RMSprop\")","a2ba80f3":"model.compile(loss=\"categorical_crossentropy\", # We will use categorial crossentropy as usual \n              optimizer=optimizer,\n              metrics=['accuracy'])","9951603b":"learning_rate_reduction = ReduceLROnPlateau(monitor=\"loss\",\n                                            patience=5,\n                                            verbose=1,\n                                            factor=0.2,\n                                            min_lr=0.00001)\n\nes = EarlyStopping(monitor=\"val_loss\", mode=\"min\", verbose=1, patience=20, restore_best_weights=True)","2faf5425":"history = model.fit_generator(\n    train_datagen.flow(x_train, y_train, batch_size=batch_size),\n    steps_per_epoch=len(x_train)\/\/batch_size,\n    epochs=epochs,\n    validation_data=val_datagen.flow(x_val, y_val),\n    validation_steps=50,\n    callbacks=[learning_rate_reduction, es])","2902432b":"accuracy = history.history['accuracy']\nval_accuracy = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(accuracy))\nplt.plot(epochs, accuracy, 'b', label='Training accuracy')\nplt.plot(epochs, val_accuracy, 'r', label='Validation accuracy')\nplt.title('Accuracy')\nplt.legend()\nplt.show()","be1c9d8f":"plt.figure()\nplt.plot(epochs, loss, 'b', label='Training loss')\nplt.plot(epochs, val_loss, 'r', label='Validation loss')\nplt.title('Loss')\nplt.legend()\nplt.show()","d2bf2722":"x_dig = x_dig\/255\nx_dig = x_dig.reshape(x_dig.shape[0],28,28,1)","7026e7f3":"model.evaluate(x_dig,y_dig,verbose=2)","0396869a":"submission = pd.read_csv('..\/input\/Kannada-MNIST\/sample_submission.csv')","a82b9139":"predictions = model.predict_classes(x_test\/255.)","4567dd40":"submission['label'] = predictions","019bccc7":"submission.head()","21eefba5":"submission.to_csv(\"submission.csv\",index=False)","5f8e722c":"### Submission","6565572e":"We can just remove the \"id\" columns","e7f63947":"# Kannada MNIST: Simple CNN","259eb0a8":"### Training preparation","0c296887":"### Model","33e24398":"We can now define our optimizer and compile the model.","022eb834":"* 28x28 dimension flatten into 784 columns\n* 60000 examples in training\n* First column is the label","6bb75466":"We will also define 2 callbacks, one for reducing LR and another for early stopping, both when val_loss is no longer improving.","7f5860fb":"We also need to split our training set into true training and validation. We will use 10% of our dataset as validation.  ","e4a7fb8e":"We will use data augmentation to try to increase the performance of our model out of sample. ","d34c77e5":"We now need to reshape the data from the 784 flat to the 28x28x1.","fcb03e8f":"We are now ready to run our model.","809201a3":"It is homogenous, so no need to augment specific labels","0243c77d":"### Import Modules","f1924208":"Same process that was used in the training set.","1cb764ef":"### The data","009aacbc":"### Model evaluation"}}