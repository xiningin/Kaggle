{"cell_type":{"85723a78":"code","491dcdae":"code","aba432c8":"code","2bec9677":"code","9229246b":"code","999a2953":"code","4fd70563":"code","eb617ecf":"code","81e7ba02":"code","9fb93c26":"code","ffada5b4":"code","8dd5960d":"code","2e9715b8":"code","13dcf599":"code","b2249266":"code","43b8ba8a":"code","9f02aa30":"code","5bd71017":"code","2ec263b5":"code","66b3a129":"code","41d62267":"code","be20a5fe":"code","332f9c1c":"code","fac8ad2d":"code","f89eb6a9":"code","29e96330":"code","28d3c91a":"code","a161157c":"code","e8f6cdfd":"code","2e844299":"code","49ff6023":"code","62d638a3":"code","a31606aa":"code","e7a74121":"code","887b4647":"code","0628751e":"code","22389fa7":"code","9477aafb":"code","72064937":"code","78388bb2":"code","592d1881":"code","f40ffbc8":"code","ee673d7c":"code","30ba739b":"code","e8bdd4f0":"code","73f2a7ee":"code","427ed999":"code","d4092c92":"code","a44a6482":"code","7bfd3b9d":"markdown"},"source":{"85723a78":"%pip install turicreate","491dcdae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","aba432c8":"import turicreate as tc\nfrom datetime import datetime\nfrom sklearn.model_selection import train_test_split\nfrom tqdm import tqdm\ntqdm.pandas()","2bec9677":"input_dir = '\/kaggle\/input\/grsnailie\/'\noutput_dir = '\/kaggle\/working\/'","9229246b":"consumers = pd.read_csv(input_dir + 'consumer.csv')\nconsumers.info()","999a2953":"providers = pd.read_csv(input_dir + 'provider.csv')\nproviders.info()","4fd70563":"interactions = pd.read_csv(input_dir + 'provider_interaction.csv')\ninteractions = interactions.merge(consumers[['consumer_id']], on='consumer_id')\ninteractions = interactions.merge(providers[['provider_id']], on='provider_id')\ninteractions.info()","eb617ecf":"consumer_data = tc.SFrame(consumers)\nprovider_data = tc.SFrame(providers)\ninteraction_data = tc.SFrame(interactions)","81e7ba02":"def get_days(frame):\n    days = datetime.now() - frame.str_to_datetime()\n    return days\/3600\/\/24","9fb93c26":"consumer_data['created'] = get_days(consumer_data['created'])\nprovider_data['created'] = get_days(provider_data['created'])\ninteraction_data['created'] = get_days(interaction_data['created'])","ffada5b4":"def fillna(frame, val):\n    result = frame.copy()\n    for column in frame.column_names():\n        result = result.fillna(column, val)\n    return result","8dd5960d":"consumer_input = fillna(consumer_data, 0)\nprovider_input = fillna(provider_data, 0)\ninteraction_input = fillna(interaction_data, 0)","2e9715b8":"interaction_input = interaction_input.sort(['created'], ascending=False)[['consumer_id', 'provider_id', 'created']]\ninteraction_input","13dcf599":"def cnt(frame):\n#     result = frame.groupby(['consumer_id', 'provider_id'], {'created': tc.aggregate.COUNT})\n#     result['created'] = np.log10(result['created'])\n    column_list = ['consumer_id', 'provider_id']\n    result = frame.sort('created')[column_list].drop_duplicates(column_list)\n    return result","b2249266":"interaction_input = cnt(interaction_input)\ninteraction_input","43b8ba8a":"train_pivot = int(len(interaction_input) * .8)\ntest_pivot = int(len(interaction_input) * .9)\nprint(train_pivot, test_pivot - train_pivot)","9f02aa30":"interaction_train = interaction_input[:train_pivot].copy()\ninteraction_dev = interaction_input[train_pivot:test_pivot].copy()\ninteraction_valid = interaction_input[test_pivot:].copy()","5bd71017":"# interaction_train = cnt(interaction_train)\n# interaction_dev = cnt(interaction_dev)\n# interaction_valid = cnt(interaction_valid)","2ec263b5":"model = tc.ranking_factorization_recommender.create(\n    num_factors=32, num_sampled_negative_examples=8, max_iterations=25,\n    observation_data=interaction_train,# target='created',\n    user_id='consumer_id', item_id='provider_id',\n    user_data=consumer_input, item_data=provider_input,\n    solver='auto', verbose=True,\n    regularization=1e-9,\n#     ranking_regularization=0.1,\n    linear_regularization=1e-8,\n    random_seed=42)","66b3a129":"results = model.evaluate_precision_recall(interaction_dev)","41d62267":"eval_result = results['precision_recall_by_user']\neval_result","be20a5fe":"K = 10\ncaller = {'precisionK': tc.aggregate.MEAN('precision'),\n          'recallK': tc.aggregate.MEAN('recall'),\n          'f1K': tc.aggregate.MEAN('f1'),\n         }","332f9c1c":"eval_result['f1'] = 1\/(1\/eval_result['precision'] + 1\/eval_result['recall'])\nprint(sorted(eval_result['cutoff'].unique()))\neval_result","fac8ad2d":"eval_result[(eval_result['cutoff'] == K) & (eval_result['f1'] > 0)].show()","f89eb6a9":"eval_result[eval_result['cutoff'] == K].show()","29e96330":"metricsK = eval_result[eval_result['cutoff'] <= K].groupby('consumer_id', operations=caller)\nmetricsK.show()","28d3c91a":"result = interaction_valid.copy()\nresult['score'] = model.predict(interaction_valid)\nresult.show()","a161157c":"coef = model.__getattribute__('coefficients')\nside_data = coef['side_data'].to_dataframe()\nprovider_col = [True if '.1' in feat_col else False for feat_col in side_data['feature']]\nconsumer_col = [False if col else True for col in provider_col]\nsides = {'provider_id': side_data[provider_col], 'consumer_id': side_data[consumer_col]}\nsides['provider_id']['feature'] = sides['provider_id']['feature'].apply(lambda feat: feat[:-2])\nsides['provider_id']","e8f6cdfd":"def construct(user, user_type, user_dict):\n    user_id = user_type + '_id'\n    \n    current_dict = {}\n        \n    current_dict['linear'] = user['linear_terms']\n    current_dict[user_type + '_factors'] = np.asarray(user['factors'])\n    current_dict['feat_factors'] = 0\n    \n    def process(feat):\n        feat_id = feat['feature']\n        feat_val = user[feat_id]\n        feat_factors = feat_val * np.asarray(feat['factors'])\n        \n        current_dict['feat_factors'] += feat_factors\n        feat_linear = feat_val * feat['linear_terms'] - (feat_factors ** 2).sum() \/ 2\n        current_dict['linear'] += feat_linear\n    \n    sides[user_id].apply(process, axis=1)\n    current_dict['linear'] += (current_dict['feat_factors'] ** 2).sum() \/ 2\n    user_dict[user[user_id]] = current_dict","2e844299":"provider_dict = {}\nprovider_feat = provider_input.to_dataframe()\nprovider_norm = provider_feat.drop('provider_id', axis=1)\nprovider_norm = (provider_norm - provider_norm.mean()) \/ provider_norm.std().apply(lambda val: max(val, 1))\nprovider_feat.iloc[:, 1:] = provider_norm\nprovider_feat = provider_feat.merge(coef['provider_id'].to_dataframe(), on='provider_id')\nprovider_feat.describe()","49ff6023":"consumer_dict = {}\nconsumer_feat = consumer_input.to_dataframe()\nconsumer_norm = consumer_feat.drop('consumer_id', axis=1)\nconsumer_norm = (consumer_norm - consumer_norm.mean()) \/ consumer_norm.std().apply(lambda val: max(val, 1))\nconsumer_feat.iloc[:, 1:] = consumer_norm\nconsumer_feat = consumer_feat.merge(coef['consumer_id'].to_dataframe(), on='consumer_id')\nconsumer_feat.describe()","62d638a3":"provider_feat.progress_apply(lambda provider: construct(provider, 'provider', provider_dict), axis=1)","a31606aa":"consumer_feat.progress_apply(lambda consumer: construct(consumer, 'consumer', consumer_dict), axis=1)","e7a74121":"prov_pos = 124\ncons_pos = 128\nprov_id = list(provider_dict.keys())[prov_pos]\ncons_id = list(consumer_dict.keys())[cons_pos]\npair = tc.SFrame({'provider_id': [prov_id], 'consumer_id': [cons_id]})","887b4647":"model.predict(pair)","0628751e":"prov_data = coef['provider_id'][coef['provider_id']['provider_id'] == prov_id]\ncons_data = coef['consumer_id'][coef['consumer_id']['consumer_id'] == cons_id]\nprint(prov_data)\nprint(cons_data)","22389fa7":"temp = coef['intercept']\nprint(temp)","9477aafb":"cur = prov_data['linear_terms'] + cons_data['linear_terms']\ntemp += cur[0]\nprint(temp, cur)","72064937":"cur = (np.asarray(prov_data['factors']) * np.asarray(cons_data['factors'])).sum()\ntemp += cur\nprint(temp, cur)","78388bb2":"cur1 = provider_feat[provider_feat['provider_id'] == prov_id].T.reset_index(drop=False)\ncur1 = cur1.rename(columns={'index': 'feature', prov_pos: 'val'}).merge(sides['provider_id'], on='feature')\ncur = sum(cur1['val'].values * cur1['linear_terms'].values)\ntemp += cur\nprint(temp, cur)","592d1881":"cur2 = consumer_feat[consumer_feat['consumer_id'] == cons_id].T.reset_index(drop=False)\ncur2 = cur2.rename(columns={'index': 'feature', cons_pos: 'val'}).merge(sides['consumer_id'], on='feature')\ncur = sum(cur2['val'].values * cur2['linear_terms'].values)\ntemp += cur\nprint(temp, cur)","f40ffbc8":"curt = pd.concat([cur1, cur2])\nxv_acc = curt['val'].values.dot(np.asarray(curt['factors'].tolist()))\ncur = 0\ncurt.reset_index(drop=True, inplace=True)\nfor i in range(len(curt)):\n    fac = np.asarray(curt.loc[i, 'factors'])\n    cur += ((curt.loc[i, 'val'] * fac) ** 2).sum()\n    \ntemp -= cur \/ 2\nprint(temp, cur)","ee673d7c":"cur = xv_acc.dot(xv_acc) \/ 2\ntemp += cur\nprint(temp, cur)","30ba739b":"import math\n1 \/ (1 + math.exp(-temp))","e8bdd4f0":"curn = provider_dict[prov_id]['linear'] + consumer_dict[cons_id]['linear']\ntempn = curn\nprint(tempn, curn)","73f2a7ee":"curn = sum(provider_dict[prov_id]['provider_factors'] * consumer_dict[cons_id]['consumer_factors'])\ntempn += curn\nprint(tempn, curn)","427ed999":"curn = sum(provider_dict[prov_id]['feat_factors'] * consumer_dict[cons_id]['feat_factors'])\ntempn += curn\nprint(tempn, curn)","d4092c92":"curn = coef['intercept']\ntempn += curn\nprint(tempn, curn)","a44a6482":"1 \/ (1 + math.exp(-tempn))","7bfd3b9d":"result.export_csv(output_dir + 'provider_score.csv')\nresult.print_rows(20*K)"}}