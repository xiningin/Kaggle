{"cell_type":{"56a9c608":"code","fa4f3319":"code","58713fc8":"code","d8778640":"code","b66f22b2":"code","13f777f3":"code","40912f03":"code","389edf34":"code","1f34d37c":"code","de248586":"code","e8246a26":"code","605daa9a":"code","b4ddb303":"code","22e21bb3":"code","f3f711e7":"code","ef3cd3dd":"code","9bb57c7f":"code","442ed1b2":"code","bfba3462":"markdown","53a44aba":"markdown","f7a122ca":"markdown","7393e734":"markdown","1757fdcf":"markdown","7e4ee7fa":"markdown"},"source":{"56a9c608":"!nvidia-smi","fa4f3319":"import torch\nimport torchvision\nimport matplotlib.pyplot as plt\nimport numpy as np","58713fc8":"n_epochs = 3\nbatch_size_train = 64\nbatch_size_test = 1000\nlearning_rate = 0.01\nmomentum = 0.5\nlog_interval = 10\n\nrandom_seed = 1\ntorch.backends.cudnn.enabled = False\ntorch.manual_seed(random_seed)","d8778640":"train_loader = torch.utils.data.DataLoader(\n  torchvision.datasets.MNIST('\/files\/', train=True, download=True,\n                             transform=torchvision.transforms.Compose([\n                               torchvision.transforms.ToTensor(),\n                               torchvision.transforms.Normalize(\n                                 (0.1307,), (0.3081,))\n                             ])),\n  batch_size=batch_size_train, shuffle=True)\n\ntest_loader = torch.utils.data.DataLoader(\n  torchvision.datasets.MNIST('\/files\/', train=False, download=True,\n                             transform=torchvision.transforms.Compose([\n                               torchvision.transforms.ToTensor(),\n                               torchvision.transforms.Normalize(\n                                 (0.1307,), (0.3081,))\n                             ])),\n  batch_size=batch_size_test, shuffle=True)","b66f22b2":"examples = enumerate(test_loader)\nbatch_idx, (example_data, example_targets) = next(examples)","13f777f3":"example_data.shape","40912f03":"fig = plt.figure()\nfor i in range(6):\n  plt.subplot(2,3,i+1)\n  plt.tight_layout()\n  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n  plt.title(\"Ground Truth: {}\".format(example_targets[i]))\n  plt.xticks([])\n  plt.yticks([])\nfig","389edf34":"import torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","1f34d37c":"class Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x)","de248586":"network = Net()\noptimizer = optim.SGD(network.parameters(), lr=learning_rate, momentum=momentum)","e8246a26":"train_losses = []\ntrain_counter = []\ntest_losses = []\ntest_counter = [i*len(train_loader.dataset) for i in range(n_epochs + 1)]","605daa9a":"def train(epoch):\n  network.train()\n  for batch_idx, (data, target) in enumerate(train_loader):\n    optimizer.zero_grad()\n    output = network(data)\n    loss = F.nll_loss(output, target)\n    loss.backward()\n    optimizer.step()\n    if batch_idx % log_interval == 0:\n      print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n        epoch, batch_idx * len(data), len(train_loader.dataset),\n        100. * batch_idx \/ len(train_loader), loss.item()))\n      train_losses.append(loss.item())\n      train_counter.append(\n        (batch_idx*64) + ((epoch-1)*len(train_loader.dataset)))\n      torch.save(network.state_dict(), 'model.pth')\n      torch.save(optimizer.state_dict(), 'optimizer.pth')","b4ddb303":"def test():\n  network.eval()\n  test_loss = 0\n  correct = 0\n  with torch.no_grad():\n    for data, target in test_loader:\n      output = network(data)\n      test_loss += F.nll_loss(output, target, size_average=False).item()\n      pred = output.data.max(1, keepdim=True)[1]\n      correct += pred.eq(target.data.view_as(pred)).sum()\n  test_loss \/= len(test_loader.dataset)\n  test_losses.append(test_loss)\n  print('\\nTest set: Avg. loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n    test_loss, correct, len(test_loader.dataset),\n    100. * correct \/ len(test_loader.dataset)))","22e21bb3":"for epoch in range(1, 30):\n  train(epoch)","f3f711e7":"len(test_losses)","ef3cd3dd":"fig = plt.figure(figsize = (8, 8))\nplt.plot(train_counter, train_losses, color='blue')\n#plt.scatter(test_counter, test_losses, color='red')\nplt.legend(['Train Loss', 'Test Loss'], loc='upper right')\nplt.xlabel('number of training examples seen')\nplt.ylabel('negative log likelihood loss')","9bb57c7f":"with torch.no_grad():\n  output = network(example_data)","442ed1b2":"fig = plt.figure()\nfor i in range(10):\n  plt.subplot(2,5,i+1)\n  plt.tight_layout()\n  plt.imshow(example_data[i][0], cmap='gray', interpolation='none')\n  plt.title(\"Prediction: {}\".format(\n    output.data.max(1, keepdim=True)[1][i].item()))\n  plt.xticks([])\n  plt.yticks([])","bfba3462":"## Evaluating the Model's Performance","53a44aba":"## Prediction","f7a122ca":"## Reference: \"MNIST Handwritten Digit Recognition in PyTorch\" by Gregor Koehler\nSource: https:\/\/nextjournal.com\/gkoehler\/pytorch-mnist","7393e734":"## Setting up the Environment","1757fdcf":"## Building a network","7e4ee7fa":"# MNIST Handwritten Digit Recognition in PyTorch"}}