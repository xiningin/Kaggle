{"cell_type":{"b9d50c60":"code","6672c192":"code","bd0fca20":"code","d1e6c354":"code","c0a5d9a1":"code","1cd9ee7c":"code","b72fa29a":"code","61b8641d":"code","0f4306c1":"code","f530b65c":"code","7036b69d":"code","1e9130ce":"code","d1361d76":"code","c1a9ee2f":"code","9e4636d3":"code","656b3ee1":"code","88503e89":"code","8efba7de":"code","386726b6":"code","0243ee0a":"code","6bb06485":"code","69bce58c":"code","9ac44dc9":"code","094ef146":"code","3a218237":"code","8134d59b":"code","68eef4dc":"code","0d806a42":"code","9ff27424":"code","30601361":"code","630228c2":"code","8964087e":"code","5f2e4593":"code","6ffd7fd5":"code","95035e20":"code","47124d90":"code","f8ac27f0":"code","e97cb90b":"markdown","39486398":"markdown","6eb667ad":"markdown","a8454960":"markdown","7a312772":"markdown","297e144e":"markdown","fef4ae21":"markdown","63746621":"markdown","68c7ef31":"markdown","79ae381f":"markdown","dbb2fcfc":"markdown","dcb9e953":"markdown","4afde214":"markdown","2d1d805a":"markdown","a28520d2":"markdown","978407b6":"markdown","e61e7c74":"markdown","316edccb":"markdown","3990a396":"markdown","433f8c07":"markdown","1557c91d":"markdown","8e69a329":"markdown","39e838f9":"markdown","8514a1c3":"markdown","aa3c5041":"markdown"},"source":{"b9d50c60":"import numpy as np # linear algebra\nimport os # accessing directory structure\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom math import sqrt\n\nimport gc\nimport time\n\nfrom sklearn.preprocessing import MinMaxScaler\n\nimport tensorflow as tf\nfrom tensorflow import keras\n\n","6672c192":"import geojson\nimport geopandas as gpd\nfrom fiona.crs import from_epsg\nimport os, json\nfrom shapely.geometry import shape, Point, Polygon, MultiPoint\nfrom geopandas.tools import sjoin\nimport matplotlib.cm as cm\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns; sns.set()\n\nfrom IPython.display import Image\n\nimport folium\n\nfrom branca.colormap import  linear\nimport json\nimport branca.colormap as cm","bd0fca20":"from numpy.random import seed\n\n# Reproducability\ndef set_seed(seed=31415):\n    \n    np.random.seed(seed)\n    tf.random.set_seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    os.environ['TF_DETERMINISTIC_OPS'] = '1'\n    \nset_seed(31415)","d1e6c354":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c0a5d9a1":"df_belgium = gpd.read_file('\/kaggle\/input\/belgium-obu\/Belgium_streets.json')\n\nm = folium.Map([50.85045, 4.34878], zoom_start=9, tiles='cartodbpositron')\nfolium.GeoJson(df_belgium).add_to(m)\nm","1cd9ee7c":"# BXL_timeseries_kaggle.csv may have more rows in reality, but we are only loading\/previewing the first 1000 rows\nnew_table = pd.read_csv('..\/input\/obu-data-preprocessing\/Flow_BEL_street_30min.csv')\nnRow, nCol = new_table.shape\nprint(f'There are {nRow} rows and {nCol} columns')","b72fa29a":"mean_value = 10","61b8641d":"table_index = new_table.iloc[:,1:]\nALL_STREETS = list(table_index.columns.values)\n\nmean_flow =[]\nnew_street=[]\n\n\nfor street in ALL_STREETS:\n    single_street=table_index[street]\n    mean = np.mean(single_street)\n    mean_flow.append(mean)\n    new_street.append(street)\n    \n    \ndf_mean_flow = pd.DataFrame({'street_index':new_street, 'mean_flow': mean_flow})\nprint('')\nprint(df_mean_flow.head())\nprint('')\n\nSTREETS = df_mean_flow[(df_mean_flow['mean_flow']>= mean_value)] \nSTREETS = STREETS.sort_values(by=['street_index'])\nSTREETS = list(STREETS.street_index)\n\nprint('considering a average traffic flow of ' + str(mean_value)+' per street')\nprint('')\nprint('mean traffic flow '+str(mean_value)+ ' ---> number of street segments: ' + str(len(STREETS)))\n","0f4306c1":"new_table['Datetime'] = pd.to_datetime(new_table['datetime'])\n\nDATAFRAME = new_table\nDATAFRAME = DATAFRAME.drop(['datetime'],axis=1) \nDATAFRAME = DATAFRAME[DATAFRAME.columns.intersection(STREETS)]\n\n# Auxiliary\n\nDATAFRAME['minutes'] = new_table['Datetime'].dt.minute\nDATAFRAME['hour'] = new_table['Datetime'].dt.hour\n\nDATAFRAME['hour_x']=np.sin(DATAFRAME.hour*(2.*np.pi\/23))\nDATAFRAME['hour_y']=np.cos(DATAFRAME.hour*(2.*np.pi\/23))\n\nDATAFRAME['day'] = new_table['Datetime'].dt.day\n\nDATAFRAME['DayOfWeek'] = new_table['Datetime'].dt.dayofweek\nDATAFRAME['WorkingDays'] = DATAFRAME['DayOfWeek'].apply(lambda y: 2 if y < 5 else y)\nDATAFRAME['WorkingDays'] = DATAFRAME['WorkingDays'].apply(lambda y: 1 if y == 5 else y)\nDATAFRAME['WorkingDays'] = DATAFRAME['WorkingDays'].apply(lambda y: 0 if y == 6 else y)\n\nDATAFRAME = DATAFRAME.drop(['minutes','hour','day'],axis=1)\n\n# temporal features = 4\nfeat_time = 4\n\nDATAFRAME.head()\n\n","f530b65c":"STREETS = [int(float(s)) for s in STREETS]\n\n\ndf_belgium = df_belgium[df_belgium.index.isin(STREETS)]\ndf_belgium['Trucks_Flow'] =  DATAFRAME.iloc[2182,:-4].astype(float).values\n\nnbh_count_colormap = linear.YlOrRd_09.scale(0,200)\n\ncolormap_dept = cm.StepColormap(\n    colors=['#00ae53', '#86dc76', '#daf8aa',\n            '#ffe6a4', '#ff9a61', '#ee0028'],\n    vmin = 0,\n    vmax = 200,\n    index=[0, 20, 50, 80, 110, 150, 180])\n\npolygons = df_belgium\nm = folium.Map([50.85045, 4.34878], zoom_start= 9, tiles='cartodbpositron')\n\nstyle_function = lambda x: {\n    'fillColor': colormap_dept(x['properties']['Trucks_Flow']),\n    'color': colormap_dept(x['properties']['Trucks_Flow']),\n    'weight': 1.5,\n    'fillOpacity': 1\n}\nfolium.GeoJson(polygons,\n    style_function=style_function).add_to(m)\n\n\ncolormap_dept.caption = 'Traffic Flow (N#Trucks\/30min) at (not real) 12:00 a.m.'\ncolormap_dept.add_to(m)\n\nm","7036b69d":"Image(\"\/kaggle\/input\/image-lstm\/MATRIX.jpg\")","1e9130ce":"test_step = 168*2*2 # 1 WEEK\n\n# ATTENTION: anything you learn and is not known in advance, must be learnt only from training data!\nscaler = MinMaxScaler(feature_range=(0, 1))\nscaler_aux = MinMaxScaler(feature_range=(0, 1))\n\n# TRAINING --- (scaler\/scaler_aux).fit_transform()\n# TESTING --- (scaler\/scaler_aux).transform()\n\n# TRAINING SET\nTRAIN = DATAFRAME[: -test_step ]\ntrain_feat = scaler.fit_transform(TRAIN.values[:,:-feat_time])\n\n\n# TESTING SET\nTEST = DATAFRAME[-test_step:]\ntest_feat = scaler.transform(TEST.values[:,:-feat_time])\n\n\n# AUX are known in advance\nAUX = scaler_aux.fit_transform(DATAFRAME.values[:,-feat_time:])\ntrain_aux = AUX[: -test_step ]\ntest_aux = AUX[-test_step:]\n\n\n# concate final results\ntrain_feat = np.hstack([train_feat, train_aux])\ntest_feat = np.hstack([test_feat, test_aux])","d1361d76":"def inverse_transform(forecasts, scaler):\n    # invert scaling\n    inv_pred = scaler.inverse_transform(forecasts)\n    return inv_pred","c1a9ee2f":"nRow, nCol = DATAFRAME.shape\n\nplt.figure(figsize=(20,10))\nplt.plot(np.mean(TEST.iloc[:,:-feat_time],axis=1))\nplt.title('TESTING SET')\nplt.show()\n\nprint(f'Consider {nRow} instances (rows) and {nCol} streets segments (columns)')\nprint('')\nprint('TRAIN SIZE: '+ str(TRAIN.shape))\nprint('')\nprint('TEST SIZE: '+ str(TEST.shape))\n\n","9e4636d3":"Image(\"\/kaggle\/input\/image-lstm\/Direct.png\")","656b3ee1":"Image(\"\/kaggle\/input\/image-lstm\/DATAPREP.png\")","88503e89":"def prep_data(dataframe, INPUT, BATCH):\n    \n    OUTPUT = INPUT\n    TOTAL = INPUT + OUTPUT\n    \n    dataset = tf.data.Dataset.from_tensor_slices(dataframe)\n\n    # features\n    feat = dataset.window(INPUT,  shift=1,  stride=1,  drop_remainder=True)\n    feat = feat.flat_map(lambda window: window.batch(INPUT))\n\n    # targets\n    label = dataset.window(OUTPUT, shift=1,  stride=1,  drop_remainder=True).skip(INPUT)\n    label = label.flat_map(lambda window: window.batch(OUTPUT))\n    \n    dataset = tf.data.Dataset.zip((feat, label))\n    dataset = dataset.batch(BATCH).cache().prefetch(tf.data.experimental.AUTOTUNE) #,  drop_remainder=True\n\n    return dataset","8efba7de":"total_features = len(DATAFRAME.columns) \n\nsize_input = 12\nbatch_size = 128\nbatch_train = batch_size\nbatch_test = 1\n\n\nwindowed_train = prep_data(train_feat, size_input, batch_train)\nwindowed_test = prep_data(test_feat, size_input, batch_test)\n\nlatent_dim = 100 #356\n","386726b6":"Image(\"\/kaggle\/input\/image-lstm\/The-structure-of-the-LSTM-unit.png\")","0243ee0a":"Image(\"\/kaggle\/input\/image-lstm\/LSTM.jpg\")","6bb06485":"# stateless both for training and testing\n\nstateful_train = False\n\nstateful_test = False","69bce58c":"from tensorflow.keras import regularizers\n\nclass LSTM(tf.keras.Model):\n    \n    def __init__(self, units, sz_input, tot_feat, state):\n        \n        super(LSTM, self).__init__()\n        self.tot_feat = tot_feat\n        self.units = units\n        self.state = state\n        self.inp = sz_input\n        \n        \n        self.cell = tf.keras.layers.LSTMCell(self.units, \n                                        kernel_initializer='glorot_uniform',\n                                        recurrent_initializer='glorot_uniform',\n                                        kernel_regularizer=regularizers.l2(0.001),\n                                        bias_initializer='zeros')\n        \n        \n        self.lstm = tf.keras.layers.RNN(self.cell, return_sequences = False, stateful= self.state)\n        \n        \n#         self.lstm = tf.compat.v1.keras.layers.CuDNNLSTM(self.units, \n#                                         kernel_initializer='glorot_uniform',\n#                                         recurrent_initializer='glorot_uniform',\n#                                         kernel_regularizer=regularizers.l2(0.001),\n#                                         bias_initializer='zeros', return_sequences = False, stateful= self.state)\n\n        \n#         self.conc = tf.keras.layers.Concatenate(axis=2)\n        \n        self.dense_0 = tf.keras.layers.Dense(150,\n                                             activation='relu',\n                                             kernel_regularizer=regularizers.l2(0.001))\n        \n        self.drop = tf.keras.layers.Dropout(0.0)\n        \n        \n        self.dense = tf.keras.layers.Dense(self.tot_feat * self.inp,\n                                           kernel_regularizer=regularizers.l2(0.001))\n        \n        self.reshape = tf.keras.layers.Reshape([self.inp, self.tot_feat])\n        \n        \n    def call(self, x):\n        \n        output_lstm = self.lstm(x)\n        \n        output_dense_0 = self.dense_0(output_lstm)\n        \n        dropout_0 = self.drop(output_dense_0)\n        \n        output_dense = self.dense(dropout_0)\n        \n        output = self.reshape(output_dense)\n        \n                \n        return output\n","9ac44dc9":"# input for LSTM\ninputs = tf.keras.Input(batch_shape=(batch_size, size_input, total_features), name='inputs')\nprint(' INPUT SHAPE for LSTM: { batch size, input sequence, features size}')\ninputs","094ef146":"lstm = LSTM(latent_dim, size_input, total_features, stateful_train)\noutput = lstm(inputs)\nprint('-----------')\nprint('Model Summary')\nprint('-----------')\nlstm.summary()\n\n\nprint(' OUTPUT SHAPE for LSTM: { batch size, output sequence, features size}')\noutput\nprint('----')\n\n\n","3a218237":"optimizer = tf.keras.optimizers.Adam( lr = 0.0001) \n\n# comment for now\n# checkpoint_dir = '.\/training_checkpoints'\n# checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt\")\n# checkpoint = tf.train.Checkpoint(optimizer = optimizer, lstm = lstm )","8134d59b":"loss_object = tf.keras.losses.MeanAbsoluteError()\n\n\ndef loss_function(real, pred):\n\n    \n    loss_ = loss_object(real, pred)\n\n\n    return tf.reduce_mean(loss_)","68eef4dc":"\n@tf.function\ndef train_step(inp, targ):\n\n    loss = 0\n\n    with tf.GradientTape() as tape:\n        \n        predictions = lstm(inp, training=True)\n\n        loss += loss_function(targ, predictions)\n   \n    batch_loss = loss \n    \n    variables = lstm.trainable_variables \n\n    gradients = tape.gradient(loss, variables)\n\n    optimizer.apply_gradients(zip(gradients, variables))\n    \n    return batch_loss","0d806a42":"EPOCHS = 200\n\nsteps_per_epoch = len(TRAIN) \/\/ batch_size\n\n# Keep results for plotting\ntrain_loss_results = []\ntrain_rmse_accuracy_results = []\n\nprint('')\nprint('TRAINING')\nprint('')\n\nfor epoch in range(EPOCHS):\n    \n    start = time.time()\n    \n    # resetting the hidden state at the start of every epoch if state_train = True\n#     lstm.reset_states()\n    \n    epoch_loss_avg = tf.keras.metrics.Mean()\n    epoch_rmse = tf.keras.metrics.MeanSquaredError()\n\n    total_loss = 0\n\n    for (batch, (inp, targ)) in enumerate(windowed_train.take(steps_per_epoch)):\n        \n\n        batch_loss = train_step(inp, targ)\n\n        # Track progress\n        epoch_loss_avg.update_state(batch_loss)  # Add current batch loss\n        epoch_rmse.update_state(targ, lstm(inp)) #, training=True))\n        \n    # End epoch\n    train_loss_results.append(epoch_loss_avg.result())\n    train_rmse_accuracy_results.append(epoch_rmse.result())\n    \n    \n\n    if epoch % 10 == 0:\n        print(\"Epoch {}: Loss MAE: {:.3f}, Accuracy RMSE: {:.3f}\".format(epoch,\n                                                                epoch_loss_avg.result(),\n                                                                epoch_rmse.result()))\n\n          \n          \nprint('Time taken for 1 epoch {} sec\\n'.format(time.time() - start))","9ff27424":"fig, axes = plt.subplots(2, sharex=True, figsize=(12, 8))\nfig.suptitle('Training Metrics')\n\naxes[0].set_ylabel(\"Loss (MAE)\", fontsize=14)\naxes[0].plot(train_loss_results)\n\naxes[1].set_ylabel(\"Accuracy (RMSE)\", fontsize=14)\naxes[1].set_xlabel(\"Epoch\", fontsize=14)\naxes[1].plot(train_rmse_accuracy_results)\nplt.show()","30601361":"# input for LSTM\ninputs_test = tf.keras.Input(batch_shape=(batch_test, size_input, total_features), name='inputs')\nprint(' INPUT SHAPE for LSTM: { batch size, input sequence, features size}')\ninputs_test\n","630228c2":"lstm_pred = LSTM(latent_dim, size_input, total_features, stateful_test)\noutput_test = lstm_pred(inputs_test)\nlstm_pred.summary()","8964087e":"for a, b in zip(lstm_pred.variables, lstm.variables):\n    a.assign(b)  # copies the variables of model_b into model_a","5f2e4593":"def evaluate_forecasts(targets, forecasts, n_seq):\n    \n    list_rmse = []\n    list_mae = []\n    \n    for i in range(n_seq):\n        true = np.vstack([target[i] for target in targets])\n        predicted = np.vstack([forecast[i] for forecast in forecasts])\n        \n        rmse = np.sqrt((np.square(true - predicted)).mean(axis=0))\n        mae = np.absolute(true - predicted).mean(axis=0)\n        \n        list_rmse.append(rmse)\n        list_mae.append(mae)\n        \n    list_rmse = np.vstack(list_rmse)\n    list_mae = np.vstack(list_mae)\n    \n    return list_rmse, list_mae","6ffd7fd5":"forecasts = []\ntargets = []\n\nrmse_list = []\nmae_list = []\n\n    \nfor (step, (inp, targ)) in enumerate(windowed_test):\n\n        pred  = lstm_pred(inp, training = False)\n        \n        truth = inverse_transform(targ[0][:,:-feat_time],  scaler)\n        pred = inverse_transform(pred[0][:,:-feat_time],  scaler)\n        \n        forecasts.append(pred)\n        targets.append(truth)\n        \n        rmse, mae = evaluate_forecasts(targets, forecasts, 12)\n           \n        rmse_list.append(rmse)\n        mae_list.append(mae)\n           \n        plt.plot(np.mean(pred, axis=1), label='Prediction') \n        plt.plot(np.mean(truth, axis=1), label='Truth') \n        plt.ylim(-1, 150)\n        plt.title('Average Prediction on all highways in Belgium')\n        plt.legend()\n        plt.show()\n        \n        print('* Time step '+str(step))\n        print('* Prediction Accuracy (MAE) '+ str(np.absolute(truth - pred).mean()))\n        print('----')\n        print('* After prediction UPDATE model with new streets observations')\n        \n        new_instance = test_feat[step,:].reshape(1,-1)\n    \n        train_feat = np.vstack([train_feat, new_instance])\n    \n        windowed_new = prep_data(train_feat, size_input, batch_size) \n\n        update_steps_per_epoch = len(train_feat)\/\/batch_size\n        \n        UPDATE = 2\n        \n        for epoch in range(UPDATE):\n            \n            # resetting the hidden state at the start of every epoch if state_train = True\n#             lstm.reset_states()\n            \n            for (batch, (inp_new, targ_new)) in enumerate(windowed_new.take(update_steps_per_epoch )):\n\n                batch_loss = train_step(inp_new, targ_new)\n\n                # Track progress\n                epoch_loss_avg.update_state(batch_loss)  # Add current batch loss\n                epoch_rmse.update_state(targ_new, lstm(inp_new)) #, training=True))\n                \n            # End epoch\n            train_loss_results.append(epoch_loss_avg.result())\n            train_rmse_accuracy_results.append(epoch_rmse.result())\n\n\n            if epoch % UPDATE == 0:\n                print(\"UPDATE - Epoch {}: Loss MAE: {:.3f}, Accuracy RMSE: {:.3f}\".format(epoch,\n                                                                        epoch_loss_avg.result(),\n                                                                        epoch_rmse.result()))\n                \n        for a, b in zip(lstm_pred.variables, lstm.variables):\n            a.assign(b)  # copies the variables of model_b into model_a\n                \n                \n","95035e20":"RMSE_MEAN = np.mean(rmse_list,axis=0).mean(axis=1)\nRMSE_STD =  np.std(rmse_list,axis=0).std(axis=1)\n\nfor i in range(len(RMSE_MEAN)):\n    print('t+'+str(i+1)+' RMSE MEAN ' +str(np.round(RMSE_MEAN[i],3))+' +- '+str(np.round(RMSE_STD[i],3)))\n    print('')","47124d90":"MAE_MEAN = np.mean(mae_list,axis=0).mean(axis=1)\nMAE_STD =  np.std(mae_list,axis=0).std(axis=1)\n\nfor i in range(len(MAE_MEAN)):\n    print('t+'+str(i+1)+' MAE MEAN ' +str(np.round(MAE_MEAN[i],3))+' +- '+str(np.round(MAE_STD[i],3)))\n    print('')","f8ac27f0":"import pickle\n\n# Saving the objects:\nwith open('save_predictions_results.pkl', 'wb') as f:  # Python 3: open(..., 'wb')\n    pickle.dump([rmse_list, mae_list], f)","e97cb90b":"# Visualize Traffic Flow at particular time","39486398":"## Direct Approach","6eb667ad":"## General Import","a8454960":"### SEED","7a312772":"# TEST and UPDATE MODEL","297e144e":"### Define Stateful\/Stateless","fef4ae21":"## DATA PREPARATION\n### * {BATCH_SIZE, INPUT_SEQUENCE (OUTPUT), FEATURES_SIZE}","63746621":"# Visualize Streets Network","68c7ef31":"## PARAMETERS","79ae381f":"# ADD Auxiliary Temporal Features","dbb2fcfc":"# TRAIN MODEL","dcb9e953":"## LSTM Architecture","4afde214":"### - *@tf.function decorator* - to speed-up training","2d1d805a":"# copies the variables of 'lstm' into 'lstm_pred'\n\nthe LSTM model for training and the LSTM for testing share the same parameters\n","a28520d2":"### optimizer","978407b6":"# SELECT STREETS BASED ON AVERAGE TRAFFIC FLOW","e61e7c74":"### Define LSTM for prediction\n\nwe define the same lstm model for prediction: the only difference here is the size, batch_test = 1","316edccb":"# Traffic Flow Predictions with LSTM model\n\n## The goal is to predict traffic flow for multiple steps ahead for all the highways in Belgium","3990a396":"### loss function","433f8c07":"# Plot Training Progress","1557c91d":"# LSTM model - Multivariate Multiple-step ahead Prediction Model","8e69a329":"# SPLITTING Training\/Testing","39e838f9":"## LSTM Cell","8514a1c3":"### Define LSTM for training\n\nthe batch size for training the lstm model is 32. (different from testing as we will see below)","aa3c5041":"## Check files"}}