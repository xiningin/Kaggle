{"cell_type":{"56fb9f42":"code","0248f4d1":"code","fdc715aa":"code","7c8da2a4":"code","66603407":"code","bc3dfcc9":"code","af4ef89e":"code","c2e385b3":"code","e17d99a9":"code","a4b10c9c":"code","d28d10ea":"code","cbfc2c00":"code","0db9e759":"code","0e3d5fb2":"code","700e6623":"code","dd995fea":"code","65ec2e74":"code","730f36dd":"code","cc21ad13":"code","43a1a9f1":"markdown","800d4e96":"markdown","fd6c7f9e":"markdown","1429fff0":"markdown","ba32e21f":"markdown","8fd333fa":"markdown","e19861d3":"markdown","38813978":"markdown","4cf413fe":"markdown","953a146b":"markdown","bc790a77":"markdown","d3bf1712":"markdown"},"source":{"56fb9f42":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import classification_report\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0248f4d1":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\", index_col=\"PassengerId\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\", index_col=\"PassengerId\")","fdc715aa":"train.head()","7c8da2a4":"test.head()","66603407":"train.isna().sum()","bc3dfcc9":"test.isna().sum()","af4ef89e":"train.describe(include=\"all\")","c2e385b3":"train.hist(figsize=(12, 9))\nplt.show()","e17d99a9":"test.hist(figsize=(12, 9))\nplt.show()","a4b10c9c":"train['Age'].fillna(train['Age'].mean(), inplace=True)\ntest['Age'].fillna(test['Age'].mean(), inplace=True)\ntrain['Embarked'].fillna(\"S\", inplace=True)\ntest['Fare'].fillna(test['Fare'].mean(), inplace=True)\ntrain.describe(include=\"all\")","d28d10ea":"train['Sex_Male'] = (train['Sex'] == \"male\").astype(int)\ntrain['Embarked_S'] = (train['Embarked'] == \"S\").astype(int)\ntest['Sex_Male'] = (test['Sex'] == \"male\").astype(int)\ntest['Embarked_S'] = (test['Embarked'] == \"S\").astype(int)\ntrain.describe(include=\"all\")","cbfc2c00":"X = train[['Pclass', 'Sex_Male', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_S']].values\ny = train['Survived'].values","0db9e759":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2)","0e3d5fb2":"candidate_models = {\n    \"Logistic Regression\": LogisticRegression(max_iter=1000000),\n    \"Naive Bayes\": GaussianNB(),\n    \"Decision Tree\": DecisionTreeClassifier(),\n    \"Random Forest\": RandomForestClassifier(),\n    \"Support Vector Machine\": SVC()\n}","700e6623":"for name, model in candidate_models.items():\n    print(name)\n    model.fit(X_train, y_train)\n    print(classification_report(y_valid, model.predict(X_valid)))","dd995fea":"rf = RandomForestClassifier(n_estimators=200, min_samples_split=10)\nrf.fit(X_train, y_train)\nprint(classification_report(y_valid, rf.predict(X_valid)))","65ec2e74":"final_rf = RandomForestClassifier(n_estimators=200, min_samples_split=10)\nfinal_rf.fit(X, y)","730f36dd":"X_test = test[['Pclass', 'Sex_Male', 'Age', 'SibSp', 'Parch', 'Fare', 'Embarked_S']].values\ny_pred = final_rf.predict(X_test)","cc21ad13":"df_submit = pd.DataFrame({'PassengerId': test.index, 'Survived': y_pred})\ndisplay(df_submit.head())\ndf_submit.to_csv(\"\/kaggle\/working\/submission.csv\", header=True, index=False)","43a1a9f1":"## Get a brief overview and visualization","800d4e96":"## Train the final model","fd6c7f9e":"## Try a new version of Random Forest","1429fff0":"## Handle categorical variables\n\n`Sex` column is binary and can be encoded with 1 for male and 0 for female easily. `Embarked` column has 3 different values: since \"S\" is the predominant, so encode 1 for \"S\" and 0 for not \"S\".","ba32e21f":"## Try some candidate classification models","8fd333fa":"## Split into training set and validation set","e19861d3":"## Examine missing values","38813978":"There are some missing values in `Age` column and few in `Embarked` and `Fare` columns, which need to be handled later for the feature variables. There are too many missing values in `Cabin` column, so this will not be included in the features.","4cf413fe":"## Load datasets","953a146b":"## Fill in missing values\n\n`Age` and `Fare` column is filled with average value; `Embarked` column is filled with the most frequent value \"S\".","bc790a77":"### Random Forest has the best performance.","d3bf1712":"## Get feature and target variables"}}