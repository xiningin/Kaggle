{"cell_type":{"f1d22728":"code","4629d9ef":"code","0829f417":"code","1511d30c":"code","b2c126ed":"code","32b7d11d":"code","95117eff":"code","96fa154f":"code","0554832b":"code","1e845433":"code","7a7a9e0f":"code","b87d94f0":"code","0104ff43":"markdown"},"source":{"f1d22728":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4629d9ef":"# load and read your data\nfile_path = \"..\/input\/glass\/glass.csv\"\ndf = pd.read_csv(file_path)\ndf.head()","0829f417":"df.shape","1511d30c":"# target value\ntarget_col = 'Type'\nprint(\"Unique target Values: \")\nprint(df[target_col].unique())\nprint('-'*30)\nprint(\"Counting Target Values Classification: \")\nprint(df[target_col].value_counts())\nprint('-'*30)\nprint(\"Data Type for all Columns:\")\nprint(df.dtypes)\nprint('-'*30)\n# missing data\nprint(\"Missing Sum for all columns: \")\nprint(df.isna().sum())","b2c126ed":"y = df[target_col]\nX = df.drop(target_col, axis = 1)","32b7d11d":"\n# split data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y)","95117eff":"#paramter\npars = list(range(3,12,2))\nprint(pars)\n\n","96fa154f":"\n# import some libaray\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, accuracy_score, f1_score\n","0554832b":"results = {}\n# train_test\nfor n in pars:\n    print(\"pars=\", n)\n    model = KNeighborsClassifier(n_neighbors=n)\n    model.fit(X_train, y_train)\n    preds = model.predict(X_test)\n    accu = accuracy_score(y_test, preds)\n    f1 = f1_score(y_test, preds, average='micro')\n    print(classification_report(y_test, preds))\n    print('-'*20)\n    results[n] = f1","1e845433":"# plot results\nimport matplotlib.pylab as plt\nlists = sorted(results.items()) # sorted by key, return a list of tuples\npar, acc = zip(*lists) # unpack a list of pairs into two tuples\nplt.plot(par, acc)\nplt.show()","7a7a9e0f":"# get best para\nbest_para = max(results, key=results.get)\nprint(\"best para is: \", best_para)\nprint(\"Value: \", results[best_para])","b87d94f0":"# final modle\nfmodel = KNeighborsClassifier(n_neighbors=best_para)\n# training in all data\nfmodel.fit(X,y)","0104ff43":"# load and read your data"}}