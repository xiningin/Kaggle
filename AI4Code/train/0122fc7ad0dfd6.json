{"cell_type":{"5eb1087b":"code","e985738f":"code","2bd5bb53":"code","5bca8505":"code","6d0e815f":"code","cc1038a2":"code","caecec66":"code","950a3663":"code","550e8770":"code","9a634003":"code","3336285c":"code","684dab17":"code","b5442dad":"code","58735e98":"code","dbfa3988":"code","336ffb71":"code","186c9a88":"code","7db0d9bd":"code","7ab3b896":"code","482f35a2":"code","1e8944cc":"code","4e115950":"code","3ae4da00":"code","b3531354":"code","b6f30b70":"code","6749e62a":"code","e7173a01":"code","6b6a548b":"markdown","3bf3b762":"markdown","678b7afb":"markdown","0dc49f43":"markdown","486f23ba":"markdown","55db8077":"markdown","3406e34c":"markdown","94066df1":"markdown","ca1d8aeb":"markdown","a7a2e73e":"markdown","1a7e94d1":"markdown","dc6bb1d1":"markdown","36f9441a":"markdown","6819f45a":"markdown","586f1caa":"markdown"},"source":{"5eb1087b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e985738f":"train_data = pd.read_csv(\"\/kaggle\/input\/life-insurance-dataset\/self_train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/life-insurance-dataset\/self_test_wo_response.csv\")","2bd5bb53":"# display first 5 rows of train data\ntrain_data.head()","5bca8505":"y_train = train_data['Response']\ntrain_data.drop(['Response'],inplace=True,axis=1)","6d0e815f":"train_data.info()","cc1038a2":"train_data['Product_Info_2'].value_counts()","caecec66":"train_data.shape","950a3663":"train_data.isnull().sum().sum()","550e8770":"# printing only those variables where there are missing values\nfor i in train_data.columns:\n    val = train_data[i].isnull().sum()\n    if (val != 0):\n        print(\"Number of null values in column\",i,\"are:\",val)","9a634003":"train = train_data.drop(['Id',\n                        'Insurance_History_5',\n                        'Family_Hist_2',\n                        'Family_Hist_3',\n                        'Family_Hist_4',\n                        'Family_Hist_5',\n                        'Medical_History_10',\n                        'Medical_History_15',\n                        'Medical_History_24',\n                        'Medical_History_32'],axis=1)\ntrain.head()","3336285c":"# printing only those variables where there are missing values\nfor i in train.columns:\n    val = train[i].isnull().sum()\n    if (val != 0):\n        print(\"Number of null values in column\",i,\"are:\",val)","684dab17":"plt.subplot(2,2,1)\nplt.scatter(train['Employment_Info_1'],y_train)\nplt.title(\"Employment_Info_1\")\n\nplt.subplot(2,2,2)\nplt.scatter(train['Employment_Info_4'],y_train)\nplt.title(\"Employment_Info_4\")\n\nplt.subplot(2,2,3)\nplt.scatter(train['Employment_Info_6'],y_train)\nplt.title(\"Employment_Info_6\")\n\nplt.subplot(2,2,4)\nplt.scatter(train['Medical_History_1'],y_train)\nplt.title(\"Medical_History_1\")\n\nplt.tight_layout()\nplt.show()","b5442dad":"one_hot_encoded_data = pd.get_dummies(train, columns = ['Product_Info_2'])\none_hot_encoded_data","58735e98":"from sklearn.impute import SimpleImputer\nimp = SimpleImputer(missing_values=np.nan, strategy='mean')\ntrain_new = imp.fit_transform(one_hot_encoded_data)\ntrain_new","dbfa3988":"X_train = train_new.copy()","336ffb71":"y_train","186c9a88":"sns.countplot(x=y_train)\nplt.show()","7db0d9bd":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier(random_state=0,max_depth=12)\n#clf = DecisionTreeClassifier(random_state=0)\nclf.fit(X_train,y_train)","7ab3b896":"y_pred_dt = clf.predict(X_train)","482f35a2":"# evaluating models\nfrom sklearn.metrics import accuracy_score, classification_report\nprint(\"Accuracy:\",accuracy_score(y_train,y_pred_dt))\nprint(classification_report(y_train,y_pred_dt))","1e8944cc":"def preprocess(data):\n    \n    # step1 - drop columns\n    train = data.drop(['Id','Insurance_History_5',\n                        'Family_Hist_2',\n                        'Family_Hist_3',\n                        'Family_Hist_4',\n                        'Family_Hist_5',\n                        'Medical_History_10',\n                        'Medical_History_15',\n                        'Medical_History_24',\n                        'Medical_History_32'],axis=1)\n    \n    # step2 - one hot encoding \n    one_hot_encoded_data = pd.get_dummies(train, columns = ['Product_Info_2'])\n    \n    # step3 - imputation\n    train_new = imp.fit_transform(one_hot_encoded_data)\n    \n    # step4 - return data\n    return train_new","4e115950":"test_data_preprocessed = preprocess(train_data)","3ae4da00":"y_pred_test = clf.predict(test_data_preprocessed)\ny_pred_test","b3531354":"test_data['Id']","b6f30b70":"data = pd.DataFrame(zip(test_data['Id'],y_pred_test),columns=['Id','Response'])\ndata.to_csv(\"submission.csv\",index=False)","6749e62a":"data","e7173a01":"data['Response'].value_counts()","6b6a548b":"### Taking out information about dataset","3bf3b762":"Now the path of files are obtained, let's store them into some variable","678b7afb":"### Checking for null values","0dc49f43":"### Dropping columns where missing values are more than 10,000","486f23ba":"### Split into X and y","55db8077":"### Checking shape of dataset","3406e34c":"### Training Phase","94066df1":"### Imputation","ca1d8aeb":"#### Decision Tree Classifier","a7a2e73e":"### Visualizing class distribution","1a7e94d1":"### Making csv","dc6bb1d1":"### OneHotEncoding","36f9441a":"### Working on testing data now","6819f45a":"There is class imbalance, so we need to use models that don't get much affected by class imbalance","586f1caa":"### Graphs for Missing valued-columns"}}