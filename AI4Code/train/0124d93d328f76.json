{"cell_type":{"94b3564a":"code","550f6bfa":"code","427be29e":"code","0f7d9244":"code","6775ae7d":"code","c336f5b7":"code","af684ddd":"code","6e40123e":"code","be8f104f":"code","1cf3c1b4":"code","bc47316d":"code","9c54404b":"code","877c2e04":"code","b3cac384":"code","a3050e03":"code","d2614e38":"code","e90a9845":"code","34e23a43":"code","1d2a9f63":"code","32bc27ca":"code","f7257e19":"code","e5ef32b9":"code","5f922853":"code","d3a76579":"code","301c1c00":"code","ff891d43":"code","3c71be41":"code","9c82341b":"code","f0551926":"code","618d0d53":"code","0fdcfbd6":"code","2e2947ba":"code","0308e695":"code","fe454ef8":"code","beae8849":"code","b24616f2":"code","d61d5393":"code","4be3ccaa":"code","87c15512":"code","f1949c36":"code","f48d5d14":"code","9724704b":"code","6e8f9a3f":"code","9ccbacd7":"code","6399663d":"code","26e5604a":"code","64cd44cf":"code","a9d9c0f6":"code","f3166c75":"code","5f49d7e1":"code","cc7c0da5":"code","7ecabd44":"code","22fe180c":"code","14adb7ad":"code","bf8e5c07":"code","011e6b92":"code","06318ceb":"code","faf70d89":"code","f159ca87":"code","55ba4e21":"markdown","9ad22f21":"markdown","b27dd310":"markdown","c3dcda6c":"markdown","55380095":"markdown","0342f2ca":"markdown","e9a83e5a":"markdown","4a3ba169":"markdown"},"source":{"94b3564a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","550f6bfa":"pip install Kneed","427be29e":"import numpy as np\nimport pandas as pd\nfrom sklearn.datasets import make_blobs\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\nfrom sklearn.mixture import GaussianMixture #GMM\nfrom sklearn.pipeline import make_pipeline \nfrom sklearn.preprocessing import StandardScaler\nimport warnings\nwarnings.filterwarnings('ignore')\nimport argparse\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans\nfrom kneed import KneeLocator\nimport plotly.graph_objects as go \nfrom plotly.subplots import make_subplots\nsns.set()","0f7d9244":"data = pd.read_csv(\"..\/input\/company-bankruptcy-prediction\/data.csv\")","6775ae7d":"data.head()","c336f5b7":"data.info()","af684ddd":"data.isnull().sum() ","6e40123e":"data.size ","be8f104f":"data1 = data.copy()","1cf3c1b4":"data1.columns=data1.columns.str.strip()","bc47316d":"data1.info()","9c54404b":"data1.plot(kind='box',subplots=True, layout=(10,10), sharex=False, sharey=False)\nsns.set(rc={'figure.figsize':(50,50)})\nplt.show()","877c2e04":"data1[[\"After-tax net Interest Rate\",\"Non-industry income and expenditure\/revenue\",\"Continuous interest rate (after tax)\",\"Operating Expense Rate\", \"Research and development expense rate\", \"Cash flow rate\",\"Interest-bearing debt interest rate\",\"Tax rate (A)\"]].plot(kind='hist',subplots=True, layout=(4,4), sharex=False, sharey=False)\nsns.set(rc={'figure.figsize':(18,18)})\nplt.show()","b3cac384":"data1.groupby('Bankrupt?').size().plot(kind = 'pie') \nsns.set(rc={'figure.figsize':(5,5)}) \nplt.show()","a3050e03":"data1.describe()","d2614e38":"data2 = data1.iloc[:,[0,1,6,25,29,34,45,46,48,71,74,81,86,89,90,95]]   # Vamos a tomar algunas caracteristicas que representan ratios de Liquidez, Solvencia y  Rentabilidad, \n                                                                   # as\u00ed como el indicador de la income flag","e90a9845":"data2.head(2)","34e23a43":"data2.corr()","1d2a9f63":"cor_matrix = data2.corr().abs()   # esta versi\u00f3n permite colorear aquellas correlaciones que nos llaman la atenci\u00f3n tanto positivas como negativas\ncor_matrix.style.background_gradient(sns.light_palette('green', as_cmap=True)) ","32bc27ca":"f,ax = plt.subplots(figsize=(12,12))\nsns.heatmap(data2.corr(method='spearman'),annot=True,vmin=-1, vmax=1, center= 0)\nplt.show()","f7257e19":"import seaborn as sns\nsns.pairplot(data1, hue='Bankrupt?', vars=['ROA(C) before interest and depreciation before interest', 'Operating Profit Rate', 'Quick Ratio'])   \n2\nsns.set(rc={'figure.figsize':(18,18)})\nplt.show()","e5ef32b9":"X = data2 ","5f922853":"# Normalizando dataframe\nscaler = StandardScaler()\nX_std = scaler.fit_transform(X)","d3a76579":"pca = PCA()\npca.fit(X_std)","301c1c00":"evr = pca.explained_variance_ratio_\nevr","ff891d43":"fig = plt.figure(figsize=(8,8))\nplt.plot(range(1, len(X.columns)+1), evr.cumsum(), marker='o', linestyle=':')\nplt.xlabel('Numero de Componentes', fontsize=18)\nplt.ylabel('Varianza Acumulada Explicada',fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.show()","3c71be41":"for i, exp_var in enumerate(evr.cumsum()):\n    if exp_var >= 0.8:\n        n_comps = i + 1\n        break\nprint(\"Numero de Componentes Optimos:\", n_comps)\npca = PCA(n_components=n_comps)\npca.fit(X_std)\nscores_pca = pca.transform(X_std)","9c82341b":"wcss = []\nmax_clusters = 21\nfor i in range(1, max_clusters):\n    kmeans_pca = KMeans(i, init='k-means++', random_state=42)\n    kmeans_pca.fit(scores_pca)\n    wcss.append(kmeans_pca.inertia_)\nn_clusters = KneeLocator([i for i in range(1, max_clusters)], wcss, curve='convex', direction='decreasing').knee\nprint(\"Numero de Clusters Optimos:\", n_clusters)","f0551926":"fig = plt.figure(figsize=(8,8))\nplt.plot(range(1, 21), wcss, marker='o', linestyle=':')\nplt.vlines(KneeLocator([i for i in range(1, max_clusters)], wcss, curve='convex', \n                       direction='decreasing').knee, ymin=min(wcss), ymax=max(wcss), linestyles='dashed')\nplt.xlabel('Numero de Clusters', fontsize=18)\nplt.ylabel('Dentro del cluster [Suma de cuadrados] (WCSS)', fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.show()","618d0d53":"kmeans_pca = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\nkmeans_pca.fit(scores_pca);","0fdcfbd6":"df_seg_pca_kmeans = pd.concat([pd.DataFrame(X.reset_index(drop=True)), pd.DataFrame(scores_pca)], axis=1)\ndf_seg_pca_kmeans.columns.values[(-1*n_comps):] = [\"Component \" + str(i+1) for i in range(n_comps)]\ndf_seg_pca_kmeans['Cluster'] = kmeans_pca.labels_\ndf_seg_pca_kmeans.head()","2e2947ba":"x = df_seg_pca_kmeans['Component 2']\ny = df_seg_pca_kmeans['Component 1']\nfig = plt.figure(figsize=(10, 8))\nsns.scatterplot(x, y, hue=df_seg_pca_kmeans['Cluster'], palette = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:cyan', 'tab:pink', 'tab:gray', 'tab:olive'])\nplt.title('Clusters vistos con PCA', fontsize=20)\nplt.xlabel(\"Componente 2\", fontsize=18)\nplt.ylabel(\"Componente 1\", fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.show();","0308e695":"# Importando bibliotecas\nfrom pandas import read_csv \nimport pandas as pd #manejo y estructuracion de datos y su manipulaci\u00f3n\nfrom pandas.plotting import scatter_matrix #diagramas de correlacci\u00f3n\nfrom matplotlib import pyplot #Hacer gr\u00e1ficos en python\nfrom sklearn.model_selection import train_test_split #lograr dividir las muestras\nfrom sklearn.model_selection import cross_val_score #validaci\u00f3n cruzada score \nfrom sklearn.model_selection import StratifiedKFold #validacion cruzada \nfrom sklearn.metrics import classification_report \nfrom sklearn.metrics import confusion_matrix #matriz de confusi\u00f3n\nfrom sklearn.metrics import accuracy_score #score de validaci\u00f3n cruzada ","fe454ef8":"# Modelos de ML con que se va a trabajar\nfrom sklearn.metrics import accuracy_score #score de validaci\u00f3n cruzada \nfrom sklearn.linear_model import LogisticRegression #regresion log\u00edstica\nfrom sklearn.tree import DecisionTreeClassifier #arboles de decision\nfrom sklearn.neighbors import KNeighborsClassifier #KNN\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis #An\u00e1lisis discriminante lineal \nfrom sklearn.naive_bayes import GaussianNB #Gauss Bayesiana\nfrom sklearn.svm import SVC # Maquinas de Soporte Vectorial\nfrom sklearn.model_selection import train_test_split","beae8849":"data2.head(2)","b24616f2":"array = data2.values #los datos ahora se transforman en un arreglo\n\nX = array[:,1:15]  # se toman los datos, sin la clase de clasificaci\u00f3n, son 4 posiciones, por eso 4\ny = array[:,0] # se toman los datos despu\u00e9s de la posici\u00f3n 4, en este caso las clases.\n\n# Se dividen los datos en conjunto de entrenamiento y prueba, se utiliza random_state = 0 para que no d\u00e9\n# resultados diferentes si se vuelve a correr. \nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.20, random_state=0) ","d61d5393":"models = []\nmodels.append(('LR', LogisticRegression(solver='liblinear', multi_class='ovr')))\nmodels.append(('LDA', LinearDiscriminantAnalysis()))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('CART', DecisionTreeClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVC', SVC()))","4be3ccaa":"import warnings\nwarnings.filterwarnings('ignore')\n\nresultados = []\nnames = []\n\n\n# Si se necesita tanto el \u00edndice o nombre, as\u00ed como el elemento, se usa for indice, elemento en lista\nfor name, model in models:\n    kfold = StratifiedKFold(n_splits=10, random_state=1, shuffle=True) # Declaracion de la validaci\u00f3n cruzada, las caracter\u00edsticas\n    cv_resultados = cross_val_score(model, X_train, Y_train, cv=kfold, scoring='accuracy') # genera la precisi\u00f3n de la validaci\u00f3n cruzada y la guarda en la variable cv_resultados en lista\n    resultados.append(cv_resultados)  # genera la precisi\u00f3n de la validaci\u00f3n cruzada y la guarda en la variable cv_resultados en matrices, esto para hacer el boxplot.\n    names.append(name) # names en matrices\n    print('%s: %f (%f)' % (name, cv_resultados.mean(), cv_resultados.std()))","87c15512":"model = SVC()\nmodel.fit(X_train, Y_train)\nprediccion = model.predict(X_test)","f1949c36":"mc =pd.DataFrame(confusion_matrix(Y_test, prediccion, labels=[0,1]), \n                 index = [0,1],  \n                 columns = [0,1])  \n \n# Evaluando Predicciones\nprint(\"ROC:\", accuracy_score(Y_test, prediccion),sep='\\n')\nprint(\"\")\nprint(\"Matriz de Confusi\u00f3n:\", mc,sep='\\n')","f48d5d14":"data2.plot(kind='box')    # vamos a limpiar los atipicos sin afectar materialmente (no quitar de m\u00e1s) el contenido de los datos en este dataset\nsns.set(rc={'figure.figsize':(7,7)})\nplt.show()","9724704b":"data2 = data2.rename(columns={'Current Asset Turnover Rate':'Current_Asset_Turnover_Rate'})","6e8f9a3f":"data2['Current_Asset_Turnover_Rate'].plot(kind='box')\nsns.set(rc={'figure.figsize':(7,7)})\nplt.show()","9ccbacd7":"quantiles = np.percentile(data2['Current_Asset_Turnover_Rate'], [25,50,75])\nquantiles","6399663d":"median = quantiles[1]\nIQR = quantiles[2]-quantiles[0]\nsigma = 0.75*IQR","26e5604a":"data2 = data2.query(\"(Current_Asset_Turnover_Rate> @median - 1*@sigma) & (Current_Asset_Turnover_Rate < @median + 1*@sigma)\")","64cd44cf":"data2['Current_Asset_Turnover_Rate'].plot(kind='box')\nsns.set(rc={'figure.figsize':(7,7)})\nplt.show()","a9d9c0f6":"data2.plot(kind='box',subplots=True, layout=(4,4), sharex=False, sharey=False)\nsns.set(rc={'figure.figsize':(20,20)})\nplt.show()","f3166c75":"X = data2 ","5f49d7e1":"scaler = StandardScaler()\nX_std = scaler.fit_transform(X)","cc7c0da5":"pca = PCA()\npca.fit(X_std)","7ecabd44":"evr = pca.explained_variance_ratio_\nevr","22fe180c":"fig = plt.figure(figsize=(8,8))\nplt.plot(range(1, len(X.columns)+1), evr.cumsum(), marker='o', linestyle=':')\nplt.xlabel('Numero de Componentes', fontsize=18)\nplt.ylabel('Varianza Acumulada Explicada',fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.show()","14adb7ad":"for i, exp_var in enumerate(evr.cumsum()):\n    if exp_var >= 0.8:\n        n_comps = i + 1\n        break\nprint(\"Numero de Componentes Optimos:\", n_comps)\npca = PCA(n_components=n_comps)\npca.fit(X_std)\nscores_pca = pca.transform(X_std)","bf8e5c07":"wcss = []\nmax_clusters = 21\nfor i in range(1, max_clusters):\n    kmeans_pca = KMeans(i, init='k-means++', random_state=42)\n    kmeans_pca.fit(scores_pca)\n    wcss.append(kmeans_pca.inertia_)\nn_clusters = KneeLocator([i for i in range(1, max_clusters)], wcss, curve='convex', direction='decreasing').knee\nprint(\"Numero de Clusters Optimos:\", n_clusters)","011e6b92":"fig = plt.figure(figsize=(8,8))\nplt.plot(range(1, 21), wcss, marker='o', linestyle=':')\nplt.vlines(KneeLocator([i for i in range(1, max_clusters)], wcss, curve='convex', \n                       direction='decreasing').knee, ymin=min(wcss), ymax=max(wcss), linestyles='dashed')\nplt.xlabel('Numero de Clusters', fontsize=18)\nplt.ylabel('Dentro del cluster [Suma de cuadrados] (WCSS)', fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.show()","06318ceb":"kmeans_pca = KMeans(n_clusters=n_clusters, init='k-means++', random_state=42)\nkmeans_pca.fit(scores_pca);","faf70d89":"df_seg_pca_kmeans = pd.concat([pd.DataFrame(X.reset_index(drop=True)), pd.DataFrame(scores_pca)], axis=1)\ndf_seg_pca_kmeans.columns.values[(-1*n_comps):] = [\"Component \" + str(i+1) for i in range(n_comps)]\ndf_seg_pca_kmeans['Cluster'] = kmeans_pca.labels_\ndf_seg_pca_kmeans.head()","f159ca87":"x = df_seg_pca_kmeans['Component 2']\ny = df_seg_pca_kmeans['Component 1']\nfig = plt.figure(figsize=(10, 8))\nsns.scatterplot(x, y, hue=df_seg_pca_kmeans['Cluster'], palette = ['tab:blue', 'tab:orange', 'tab:green', 'tab:red', 'tab:purple', 'tab:pink','tab:olive','goldenrod'])\nplt.title('Clusters vistos con PCA', fontsize=20)\nplt.xlabel(\"Componente 2\", fontsize=18)\nplt.ylabel(\"Componente 1\", fontsize=18)\nplt.xticks(fontsize=16)\nplt.yticks(fontsize=16)\nplt.show();","55ba4e21":"# EDA","9ad22f21":"# What is required to analyze in a company \nQu\u00e9 se requiere analizar en una empresa para determinar la salud o liquidez financiera?\n\nSeg\u00fan la informaci\u00f3n brindada se puede inferir si una empresa puede o no caer en bancarrota?","b27dd310":"# Outliers Treatment","c3dcda6c":"# Machine Learning","55380095":"![image.png](attachment:29891913-c8d3-4d41-a033-60205ba2d71d.png)","0342f2ca":"![image.png](attachment:3523bcd4-8945-4f99-b26a-a7247b16ade1.png)","e9a83e5a":"# Confusion Matrix","4a3ba169":"# Supervised learning"}}