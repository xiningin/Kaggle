{"cell_type":{"92225e56":"code","ee3234e4":"code","33cab580":"code","e1208a07":"code","d0823ad4":"code","dbf43ea7":"code","7815f278":"code","f3c3489e":"code","e7bc9336":"code","15d2976a":"code","11cf13e5":"code","5b1c28fe":"code","43b7a07b":"code","a0f9864d":"code","843fa1be":"code","88fbdb9b":"code","ebdf98d9":"code","f3aaaa80":"code","1c149fb8":"code","98067beb":"code","11576e4b":"code","149badba":"code","7f40707a":"code","d0cef576":"code","c5fdde6e":"code","5a06bbc4":"code","e5437910":"code","8b4b50e0":"code","1886332f":"code","470939ce":"code","4773ef30":"code","4825cd01":"code","4cd9fd24":"code","d9d57afd":"code","417f93ea":"code","bfcd81ff":"code","1117af5b":"code","ff9c46bd":"code","109b2922":"code","66bb948d":"code","4e5156bd":"code","f37035fb":"code","33c0ab60":"code","be83a9d9":"code","a243f92d":"code","89c9ebfe":"code","dfa7583e":"code","5452b91b":"code","e3809c5e":"code","9a5e09c9":"code","e8a209d6":"code","1d0ab0d0":"code","b89bbed6":"code","7c86dc2b":"code","35653658":"code","9ebb33c4":"code","f352d46f":"code","5c5d4afe":"code","ea026b56":"code","643958d1":"code","d4d7a7b9":"code","71f26fd2":"code","1d076264":"code","39e8edd4":"code","475c0494":"code","cde577d6":"code","00d20c5d":"code","8b43b232":"markdown","7bfd7157":"markdown","6e2a9b5e":"markdown","1b458269":"markdown","736ff179":"markdown","a8b38c2d":"markdown","1a1773d7":"markdown","2c418a8b":"markdown","8f1c8b79":"markdown","6fbc738e":"markdown","be3d736e":"markdown","2088f537":"markdown","073a4dde":"markdown","8da75af7":"markdown","e3a8dcaa":"markdown","ef6bd50f":"markdown","cd221d88":"markdown","416abbba":"markdown","0bbe7cb4":"markdown","65f95957":"markdown","991728f1":"markdown","701ea1ec":"markdown"},"source":{"92225e56":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Data Visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Regular Expression\nimport re\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee3234e4":"# Reading the dataset\ndf = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","33cab580":"# Let's check the first 5 records\ndf.head()","e1208a07":"# Let's check the dimension of the dataset\ndf.shape","d0823ad4":"# Let's get the info about the dataset\ndf.info()","dbf43ea7":"# Make the default settings of seaborn visualization\nsns.set(style='whitegrid')","7815f278":"sns.countplot(x='Pclass', data=df)","f3c3489e":"sns.countplot(x='Sex', data=df)","e7bc9336":"plt.hist(x='Age', data=df)\nplt.xlabel('Age')\nplt.ylabel('Age Frequency')","15d2976a":"sns.countplot(x='SibSp', data=df)","11cf13e5":"sns.countplot(x='Parch', data=df)","5b1c28fe":"plt.hist(x='Fare', data=df)\nplt.xlabel('Fare')\nplt.ylabel('Frequency')","43b7a07b":"sns.countplot(x='Embarked', data=df)","a0f9864d":"plt.figure(figsize=(12,6))\nsns.boxenplot(x='Survived', y='Age', data=df)\n#g.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1, title='Pclass')","843fa1be":"sns.stripplot(x='Survived', y='Fare', data=df)","88fbdb9b":"sns.countplot(x='Survived', hue='Pclass', data=df)","ebdf98d9":"plt.figure(figsize=(12,4))\ng = sns.countplot(x='Survived', hue='SibSp', data=df)\ng.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1, title='SibSp')","f3aaaa80":"plt.figure(figsize=(12,4))\ng = sns.countplot(x='Survived', hue='Parch', data=df)\ng.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1, title='Parch')","1c149fb8":"sns.countplot(x='Survived', hue='Embarked', data=df)","98067beb":"sns.FacetGrid(row='Survived', col='Pclass', hue='Embarked', data=df, size=4).map(sns.countplot, 'Sex').add_legend()","11576e4b":"plt.figure(figsize=(8,6))\ng = sns.boxplot(x='Survived', y ='Fare', hue='Sex', data=df)\ng.legend(loc='center right', bbox_to_anchor=(1.25, 0.5), ncol=1, title='Parch')","149badba":"df.corr()","7f40707a":"df.info()","d0cef576":"plt.figure(figsize=(12,5))\nsns.heatmap(data=df.isnull(), cbar=False, yticklabels=False)","c5fdde6e":"# Checking the missing values in the test dataset\nplt.figure(figsize=(12,5))\nsns.heatmap(data=test_df.isnull(), cbar=False, yticklabels=False)","5a06bbc4":"plt.figure(figsize=(12,6))\nsns.boxplot(y='Age', x='Pclass', data=test_df)","e5437910":"# Define a function to impute the missing values in Age column\ndef impute_test_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if(pd.isnull(Age)):\n        if(Pclass==1):\n            return 42\n        elif(Pclass==2):\n            return 27\n        else:\n            return 25\n    else:\n        return Age","8b4b50e0":"# Impute the missing values in Age varaible from the test dataset\ntest_df['Age'] = test_df[['Age', 'Pclass']].apply(impute_test_age, axis=1)","1886332f":"# Drop the Cabin column\ndf.drop(columns=['Cabin'], axis=1, inplace=True)\ntest_df.drop(columns=['Cabin'], axis=1, inplace=True)","470939ce":"plt.figure(figsize=(12,6))\nsns.boxplot(y='Age', x='Pclass', data=df)","4773ef30":"# Define a function to impute the missing values in Age column\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    if(pd.isnull(Age)):\n        if(Pclass==1):\n            return 37\n        elif(Pclass==2):\n            return 29\n        else:\n            return 24\n    else:\n        return Age","4825cd01":"df['Age'] = df[['Age', 'Pclass']].apply(impute_age, axis=1)","4cd9fd24":"df['Embarked'].isnull().sum()","d9d57afd":"df.dropna(inplace=True)","417f93ea":"test_df['Fare'].fillna(test_df['Fare'].median(), inplace=True)","bfcd81ff":"# The values of Sex column will replaced by numbers\ndf['Sex'] = df['Sex'].apply(lambda data : 0 if(data=='male') else 1)\ntest_df['Sex'] = test_df['Sex'].apply(lambda data : 0 if(data=='male') else 1)","1117af5b":"# Extract the titles from Name variable\ndef extract_title(name):\n    title = re.search('([A-Za-z]+)\\.', name)\n    return title[1]","ff9c46bd":"df['Title'] = df['Name'].apply(extract_title)\ntest_df['Title'] = test_df['Name'].apply(extract_title)","109b2922":"title_dict = {'Mr': 0, 'Miss': 1, 'Mrs': 2, 'Master': 3, 'Dr': 4, 'Rev': 5, 'Mlle': 6, 'Col': 7, 'Major': 8,\n             'Mme': 9, 'Sir': 10, 'Jonkheer': 11, 'Capt': 12, 'Ms': 13, 'Countess': 14, 'Lady': 15, 'Don': 16}","66bb948d":"df['Title'] = df['Title'].map(title_dict)\ntest_df['Title'] = test_df['Title'].map(title_dict)","4e5156bd":"test_df['Title'].fillna(0, inplace=True)","f37035fb":"# Dropping Ticket and Name variables\ndf.drop(columns=['Ticket', 'Name'], axis=1, inplace=True)\ntest_df.drop(columns=['Ticket', 'Name'], axis=1, inplace=True)","33c0ab60":"def is_alone(cols):\n    SibSp = cols[0]\n    Parch = cols[1]\n    total_family = SibSp + Parch\n    if(total_family == 0):\n        return 1\n    else:\n        return 0","be83a9d9":"df['IsAlone'] = df[['SibSp', 'Parch']].apply(is_alone, axis=1)\ntest_df['IsAlone'] = test_df[['SibSp', 'Parch']].apply(is_alone, axis=1)","a243f92d":"embark_dict = {'S': 0, 'C': 1, 'Q': 2}\ndf['Embarked'] = df['Embarked'].map(embark_dict)\ntest_df['Embarked'] = test_df['Embarked'].map(embark_dict)","89c9ebfe":"# Create the dummy variables from the categorical variables\npclass_df = pd.get_dummies(data=df['Pclass'], prefix='Pclass', drop_first=True)\npclass_testdf = pd.get_dummies(data=test_df['Pclass'], prefix='Pclass', drop_first=True)","dfa7583e":"new_df = pd.concat([df, pclass_df], axis=1)\nnew_testdf = pd.concat([test_df, pclass_testdf], axis=1)","5452b91b":"#Let's perform the scaling on the data using StandardScaler\nfrom sklearn.preprocessing import StandardScaler","e3809c5e":"numerical_cols = ['Age', 'Fare']","9a5e09c9":"X = new_df.drop(columns=['Survived'], axis=1)\ny = new_df['Survived']","e8a209d6":"scaler = StandardScaler().fit(X[numerical_cols])","1d0ab0d0":"X[numerical_cols] = scaler.transform(X[numerical_cols])","b89bbed6":"# Feature scaling for the test dataset\ntest_scaler = StandardScaler().fit(new_testdf[numerical_cols])\nnew_testdf[numerical_cols] = test_scaler.transform(new_testdf[numerical_cols])","7c86dc2b":"# Dropping the PassengerId variable and Pclass as it is not required\nX.drop(columns=['PassengerId', 'Pclass'], axis=1, inplace=True)\nnew_testdf.drop(columns=['Pclass'], axis=1, inplace=True)","35653658":"# Splitting the dataset into train and test\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, train_size=0.7, random_state=1)","9ebb33c4":"from sklearn.svm import SVC\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix","f352d46f":"from sklearn.model_selection import GridSearchCV","5c5d4afe":"svc_model = SVC()","ea026b56":"svc_model.fit(X_train, y_train)","643958d1":"svc_predict = svc_model.predict(X_test)","d4d7a7b9":"accuracy_score(y_test, svc_predict)","71f26fd2":"# Tune the hyperparameters\nparam_grid = {'C': [0.1, 1, 10, 100], 'gamma': [1, 0.1, 0.01, 0.001], 'kernel': ['rbf']}","1d076264":"grid_svc = GridSearchCV(estimator=SVC(), param_grid=param_grid, refit=True, verbose=4)","39e8edd4":"grid_svc.fit(X_train, y_train)","475c0494":"grid_svc.best_params_","cde577d6":"test_data = new_testdf.drop(\"PassengerId\", axis=1).copy()\ngrid_svc_prediction = grid_svc.predict(test_data)","00d20c5d":"submission = pd.DataFrame({\n        \"PassengerId\": new_testdf[\"PassengerId\"],\n        \"Survived\": grid_svc_prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","8b43b232":"**Key Analysis**\n- Half of the passengers who do not have siblings or spouse were alive when compared to the non-survived. Most of these passengers were travelled in the third class. It was difficult to get access to the life boat.\n- The passengers who had travelled with the family member of more than 2 were dead. The life boat was limited at that time. Only few of the families were rescued.\n- The ratio of alive\/dead for the family with single spouse or sibling were same.","7bfd7157":"## Data Cleaning and Data Preparation","6e2a9b5e":"**Key Analysis**\n\n**Non-Survived (Survived=0)**\n- There is no first class passengers from Queenstown were travelled in the ship.\n- There are equal proportion of first class women passengers from Southampton and Cherbourg were not survived.\n- Few of the second class men passengers from Southampton were died and most of the women were large in number were died. Few of them from Cherbourg. There is no passengers from Queenstown.\n- All the third class passengers were from Southampton and Queenstown. There are 70:30 women passengers were died respectively from Southampton and Queenstown.\n- Nearly 50 third class men passengers were died.\n- Majority of the women passengers were not survived from all classes.\n\n**Survived (Survived=1)**\n- Most of the richest passengers were onboarded from Cherbourg and very few from Southampton. There are nearly 30 men passengers were survived from Southampton and Cherbourg.\n- Majority of the second class passengers were from Southampton. Few women and men passengers were from Cherbourg and Queenstown.\n- There are equal number of men and women passengers were alive. Most of the women were onboarded from Queenstown and Southampton.\n- The passengers who onboarded from Queenstown mostly without family members.","1b458269":"### Bivariate Analysis","736ff179":"**Key Analysis**\n- More than 400 passengers were not survived and they do not have parents or children on board. They were not consider as important for the rescue operation.\n- Around 220 passengers were alive and they do not have parents or children. Most of the passengers might be women and first class passengers.\n- The family with more than 2 were not alive. The passenger with one or two family member(s) were almost got same numbers in both alive\/dead. But the passengers who survived might have children and senior citizens.","a8b38c2d":"**Key Analysis**\n- The passengers from Southampton were more in number in both alive and dead. Most of the third class passengers might have onboarded from this location.\n- Majority of the passengers from Cherbourg were survived.\n- More passengers from Queenstown were died.","1a1773d7":"### Multivariate Analysis","2c418a8b":"### Feature Scaling","8f1c8b79":"**Key Analysis**\n- Fare and Parch are positively correlated with Survived\n- Pclass, Age and SibSp are negatively correlated with Survived","6fbc738e":"## Feature Engineering","be3d736e":"**Key Analysis**\n- The average age of the first class passengers are higher than second and third class passengers.\n- Need to impute the missing values in Age variable.","2088f537":"**Key Analysis**\n- The mean age of the passengers in both survived and non-survived are almost similar.\n- Majority of the children and teenagers were survived.","073a4dde":"## Exploratory Data Analysis","8da75af7":"- Cabin and Age has the missing values in the dataset.\n- Cabin has more missing values. Hence, we are dropping the column.","e3a8dcaa":"**Key Analysis**\n- Majority of the first class passengers were survived. They might have access to the life boat.\n- Many of the third class passengers were died and around 100 of them were alive.\n- The rate of alive and died for the second class passengers are nearly same.","ef6bd50f":"### Impute Missing Values","cd221d88":"**Key Analysis**\n- The average age of first class passengers is higher than other 2 class passengers.\n- Need to impute the age values based on the passenger classes.","416abbba":"- Cabin and Age has the missing values in the dataset.\n- Cabin has more missing values. Hence, we are dropping the column.","0bbe7cb4":"**Key Analysis**\n- There are high rich passengers (VIP) from both men and women sides were survived.\n- Most of the women passengers were survived when compared to men.\n- Second class men passengers got a tough chance to survive when compare to women passengers in the same class.","65f95957":"## Model Building","991728f1":"### Univariate Analysis","701ea1ec":"**Key Analysis**\n- Few of the richest passengers were survived.\n- The passengers who paid fare between 100 and 200 were survived. Most of them might be women."}}