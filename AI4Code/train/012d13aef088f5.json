{"cell_type":{"2d433266":"code","ba936afe":"code","ff51ee85":"code","739e62f5":"code","824e9843":"code","e0b18104":"code","e9955684":"code","0a0e0fd4":"code","a50ebe2b":"code","1199cfdc":"code","f5667a33":"code","370a6abf":"code","74f24a6e":"code","7a2df5e1":"code","78b2a379":"code","e28c2f4c":"code","4978aa38":"code","19cc797e":"code","8b77f532":"code","ec9a5a33":"code","7d2a16f7":"code","e49df63b":"code","b21ca893":"code","c52cab7e":"code","0735c85d":"markdown","d1264145":"markdown","572a2865":"markdown","b209d2bb":"markdown","3febdc9a":"markdown"},"source":{"2d433266":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ba936afe":"import matplotlib.pyplot as plt\ndf=pd.read_csv('\/kaggle\/input\/loan-predication\/train_u6lujuX_CVtuZ9i (1).csv')\ndf.head(10)","ff51ee85":"df.shape","739e62f5":"df.isnull().sum()","824e9843":"df1=df.dropna()\ndf1.shape","e0b18104":"\n\ndf2 = df1.replace(to_replace = ['Yes','No'],value = ['1','0'])\ndf2.head()","e9955684":"df2 = df1.replace(to_replace = ['Y','N'],value = ['1','0'])\ndf2.head()","0a0e0fd4":"X = df2[['ApplicantIncome','CoapplicantIncome','LoanAmount','Loan_Amount_Term']]\ny=df2.Loan_Status\n\n","a50ebe2b":"y=df2.Loan_Status\ny.head()","1199cfdc":"from sklearn.model_selection import train_test_split\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.3,random_state=0)","f5667a33":"#RandomForestClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nClassifier=RandomForestClassifier(n_estimators=20)\nClassifier.fit(X_train,y_train)","370a6abf":"Classifier.score(X_test,y_test)","74f24a6e":"y_predicted= Classifier.predict(X_test)\ny_predicted\n","7a2df5e1":"plt.figure(figsize=(10,7))\nfeat_importances= pd.Series(Classifier.feature_importances_,index=X_train.columns)\nfeat_importances.nlargest(7).plot(kind='barh');","78b2a379":"import pickle\npickle_out=open('classifier.pkl','wb')\npickle.dump(Classifier,pickle_out)\npickle_out.close()\n","e28c2f4c":"Classifier.predict([[4000,6000,120,120]])","4978aa38":"#DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n# define the model\nTreeClassifier = DecisionTreeClassifier()\n# fit the model\nTreeClassifier.fit(X_train,y_train)\nTreeClassifier.score(X_test,y_test)\n#score = accuracy_score(y_test,y_pred)\n#score\n","19cc797e":"y_pred = TreeClassifier.predict(X_test)\ny_pred","8b77f532":"plt.figure(figsize=(10,7))\nfeat_importances= pd.Series(TreeClassifier.feature_importances_,index=X_train.columns)\nfeat_importances.nlargest(7).plot(kind='barh');","ec9a5a33":"#XGBClassifier\nfrom xgboost import XGBClassifier\n# define the model\nxgclassifier = XGBClassifier()\n# fit the model\nxgclassifier.fit(X_train,y_train)\nxgclassifier.score(X_test,y_test)\n#score = accuracy_score(y_test,y_pred)\n#score","7d2a16f7":"y_pred = xgclassifier.predict(X_test)\ny_pred","e49df63b":"plt.figure(figsize=(10,7))\nfeat_importances= pd.Series(xgclassifier.feature_importances_,index=X_train.columns)\nfeat_importances.nlargest(7).plot(kind='barh');","b21ca893":"#KNeighborsClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\n# define the model\nknClassifier = KNeighborsClassifier()\n# fit the model\nknClassifier.fit(X_train,y_train)\nknClassifier.score(X_test,y_test)\n#score = accuracy_score(y_test,y_pred)\n#score","c52cab7e":"y_pred = knClassifier.predict(X_test)\ny_pred","0735c85d":"# XGBClassifier","d1264145":"# RandomForestClassifier","572a2865":"# DecisionTreeClassifier","b209d2bb":"its very important to know the type of Data to decide which Machine learning algorthim you have to use.There are three types of Data:\n* Categorical Data\n* Numerical Data\n* Ordinal Data\n\nIn this tutorial, I will present different types of Machine learning classifier\n1. Data Prepration\n1. RandomForestClassifier\n1. DecisionTreeClassifier\n1. XGBClassifier\n1. KNeighborsClassifier\n\nI will apply feature_importances_ on different Machine learning classifier models\n","3febdc9a":"# KNeighborsClassifier"}}