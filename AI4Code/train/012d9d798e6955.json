{"cell_type":{"23d5e49c":"code","a6ba3d84":"code","918633f6":"code","845dfed8":"code","5df6d7b9":"code","d6ebe28d":"code","1901cc50":"code","d31fd497":"code","d880bf0b":"code","8bdbc453":"code","4b4e5788":"code","bb13cabd":"markdown","75ae3d02":"markdown","fd6e061b":"markdown","25d4905a":"markdown","105e4256":"markdown","3a556f79":"markdown","ac8a1e66":"markdown"},"source":{"23d5e49c":"# import libraries \n\nfrom bs4 import BeautifulSoup\nimport requests\nimport time\nimport datetime\n\nimport smtplib","a6ba3d84":"#connecting to a website\n\nurl = 'https:\/\/www.amazon.in\/PS4-God-of-War\/dp\/B07YQ73Y8T\/ref=sr_1_2?keywords=ps4%2Bgame&qid=1642854585&sr=8-2'\nheader = {\"User-Agent\": \"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/97.0.4692.99 Safari\/537.36\"}","918633f6":"#getting the data from the website\npage = requests.get(url, headers=header)\n\ns1 = BeautifulSoup(page.content,'html.parser')\ns2 = BeautifulSoup(s1.prettify(),'html.parser')\n\ntitle = s2.find('span','a-size-large product-title-word-break').get_text()\nprint(title)\nprice = s2.find('span', 'a-offscreen').get_text()\nprint(price)","845dfed8":"#removing the rupee sign from the price\n\nprice = price.strip()[1:]\ntitle = title.strip()\n\nprint(title,price)","5df6d7b9":"today = datetime.date.today()\nprint(today)","d6ebe28d":"#saving the data from the amazon website into a csv file\nimport csv \n\nh1 = ['Title','Price','Date']\ndata = [title,price,today]\n\nwith open('Scrapper_file.csv','w',newline='',encoding='UTF8') as f:\n    writer = csv.writer(f)\n    writer.writerow(h1)\n    writer.writerow(data)","1901cc50":"#import pandas\n\n#df = pd.read_csv('\/Users\/digi\/Desktop\/Data-Analytics\/web-scrapper\/Scrapper_file.csv')\n\n#df.head(10)","d31fd497":"#checking if the apending works\n\nwith open('Scrapper_file.csv','a+',newline='',encoding='UTF8') as f:\n        writer = csv.writer(f)\n        writer.writerow(data)","d880bf0b":"#automating the process\n\ndef automate():\n    url = 'https:\/\/www.amazon.in\/PS4-God-of-War\/dp\/B07YQ73Y8T\/ref=sr_1_2?keywords=ps4%2Bgame&qid=1642854585&sr=8-2'\n    header = {\"User-Agent\": \"Mozilla\/5.0 (Macintosh; Intel Mac OS X 10_15_7) AppleWebKit\/537.36 (KHTML, like Gecko) Chrome\/97.0.4692.99 Safari\/537.36\"}\n\n    page = requests.get(url, headers=header)\n\n    s1 = BeautifulSoup(page.content,'html.parser')\n    s2 = BeautifulSoup(s1.prettify(),'html.parser')\n\n    title = s2.find('span','a-size-large product-title-word-break').get_text()\n    price = s2.find('span', 'a-offscreen').get_text()\n    price = price.strip()[1:]\n    title = title.strip()\n    \n    import datetime\n    today = datetime.date.today()\n\n    import csv \n\n    h1 = ['Title','Price','Date']\n    data = [title,price,today]\n\n    with open('Scrapper_file.csv','a+',newline='',encoding='UTF8') as f:\n        writer = csv.writer(f)\n        writer.writerow(data)\n    #if (price < 900):\n     #   send_mail()\n\n\n\n    ","8bdbc453":"#loop that keeps the process running after a defined interval\n#note here time.sleep() is in seconds\n#while(True):\n#    automate()\n#    time.sleep(1) #unit is seconds","4b4e5788":"#sending a mail if the product gets available or there is a price drop\n\ndef send_mail():\n    server = smtplib.SMTP_SSL('smtp.gmail.com',465)\n    server.ehlo()\n    #server.starttls()\n    server.ehlo()\n    server.login('enter email','@@@@@')\n    \n    subject = \"Price Drop Alert!\"\n    body = \"God of War-PS4 just dropped in price might want to have a look\"\n   \n    msg = f\"Subject: {subject}\\n\\n{body}\"\n    \n    server.sendmail(\n        'enter email',\n        msg\n     \n    )","bb13cabd":"**Common error\/problem faced**\n\nThis is the part which took away a lot of my time, not something I expected because it seems pretty straightforward. Well the problem was according to the source which I was refering too they use div tags id to reference anything to get the data but if I tried to do the same it kept on throwing \"no attributes error\". However later I realized that I need to reference the span tags and class name. Maybe the reason could be that Amazon's site has been updated but very silly error to be stuck on.","75ae3d02":"**Automation**\n\nThis function basically automates the entire process and keeps on updating the csv file on its on.","fd6e061b":"**Thank you for reading**","25d4905a":"**Introduction**\n\nHello all this is web scrapping code written using python in jupyter notebook. \n\n**What is Web scrapping?**\n\nIt is the automated procedure of extracting the large amount of data from websites. \nThe data available on the websites which is unstructured can be converted to structured data using Web Scrapping.\n\nThere are different ways to scrape websites such as Online Services, APIs or writing your own code.\n\n**Purpose**\n\nThe main purpose behind this was to automate the data collecting process and also to be aware about the sudden price changes through email.\n\nOne another cool use of it is to be notified instantly of some products which donot stay in stock for a long time such as PS5.","105e4256":"**Function to send Mail to yourself**\n\nI tried to send mail to myself while doing the project and at first it doesn\u2019t work because google won't allow unauthorised app to access your mail so for the first time you will have to allow it manually after that it seems to work fine.","3a556f79":"**Motivation and future plan**\n\nInitially I wanted to do the following project on PS5 but it is not available online atleast not on Amazon India. So main goal was to constantly keep checking availability of PS5 and the moment it gets available order it but since there is no product item named PS5 on amazon I had to go with ps4 disc, the basics remain the same with little tweak in code we would be able to use this as PS5 scrapper(if you can't beat them join them Xd!)\n","ac8a1e66":"**Loop to keep the scrapper running**\n\nHere I have used just 1 second gap inorder to get the data and validate it fastly you can use any time interval but take note that the time is in seconds"}}