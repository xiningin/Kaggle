{"cell_type":{"2315f268":"code","d593cd6f":"code","0bdc6229":"code","4c5c81e2":"code","ea3670a7":"code","62ffee0c":"code","a3831440":"code","995864f1":"code","b42e8651":"code","40f707b6":"code","4d9c6cce":"code","46337841":"code","d36e09bd":"code","05a92cfc":"code","e6d0f856":"code","a83e460d":"code","2c960de3":"code","9900e935":"code","d65d07ef":"code","e7fdc7b6":"code","47ae1023":"code","08c7f07d":"code","16586f73":"code","74b32f4d":"code","9da707f9":"code","66d59b29":"code","4cc4f376":"code","a57ff489":"code","b6023d0c":"code","f68ef8f1":"code","775c83a2":"code","c145bc5a":"code","ce5adaca":"code","6dc68395":"code","207dbf10":"code","242a52a3":"code","7d373503":"code","38c0978a":"code","f6842593":"code","08804eb9":"code","fbaf9303":"code","235a83d9":"code","ae10b869":"code","95303395":"code","cd6c9f89":"code","6be5235c":"code","94d2f29b":"code","55cd0806":"code","a0c7b037":"code","de6da66e":"code","b4357320":"code","ad92659e":"code","5df7ccf0":"code","1458f798":"code","25981e77":"code","477bed91":"code","58be8b6f":"code","d13eccc8":"code","60c8faa5":"code","6a56071a":"code","3cd1a592":"code","101c33e9":"code","e543cd09":"code","85d0e18c":"code","0e3fd457":"code","98d08ed0":"code","488bd019":"code","abf28d7b":"code","d0010f07":"code","ab28e799":"code","5753f278":"code","4040aa2e":"code","feb7414c":"code","9fdc8f50":"code","ee5cabb5":"code","3cbb32f0":"code","da36d0af":"code","325a794d":"code","6c45b8a5":"code","abfdde05":"code","5a99bc7a":"code","9a4201e9":"code","0c6d2527":"code","75e4c725":"code","b6b8f4a8":"code","dc062405":"code","87eb9d19":"code","9438010e":"code","d123e9b3":"code","efe2a724":"code","1752bf89":"code","5b104d74":"code","337c0257":"code","04530d24":"code","487dc2ce":"code","9dc43d28":"code","37cdbc6c":"code","2cdb23b6":"code","fc4e3541":"code","43e03c37":"code","622b2287":"code","d15e0fd4":"code","ffce6a4e":"code","2768406a":"markdown","543de2e1":"markdown","764fffe4":"markdown","6ecc002c":"markdown","7fad7ea5":"markdown","c55c9939":"markdown","6158ee2b":"markdown","b21df1d1":"markdown","1e348983":"markdown","20876e75":"markdown","22af4b31":"markdown","ea2b8606":"markdown","b51b9650":"markdown","239d3148":"markdown","4132cddc":"markdown","c20fa8cf":"markdown","26787e01":"markdown","f241563d":"markdown","e34aa4cd":"markdown","11060b72":"markdown","ee753762":"markdown","0febc876":"markdown","e490195e":"markdown","0ba7f427":"markdown","bdb88494":"markdown","f120bc65":"markdown","3b07de78":"markdown","09c4598a":"markdown","1180a7d5":"markdown","3ab1e34f":"markdown","72b9f4bb":"markdown","eae3ca65":"markdown","0313b266":"markdown","0de994ec":"markdown","3ee35d27":"markdown","5554e034":"markdown","8a26b8cb":"markdown"},"source":{"2315f268":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","d593cd6f":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","0bdc6229":"# copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","4c5c81e2":"train.head()","ea3670a7":"test.head()","62ffee0c":"train.info()","a3831440":"train.describe().T","995864f1":"train['Pclass'].value_counts()","b42e8651":"train['Sex'].value_counts()","40f707b6":"train['SibSp'].value_counts()","4d9c6cce":"train['Parch'].value_counts()","46337841":"train['Ticket'].value_counts()","d36e09bd":"train['Cabin'].value_counts()","05a92cfc":"train['Embarked'].value_counts()","e6d0f856":"sns.barplot(x = 'Pclass', y = 'Survived', data = train);","a83e460d":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","2c960de3":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","9900e935":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","d65d07ef":"train.head()","e7fdc7b6":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","47ae1023":"train = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\ntrain.head()","08c7f07d":"train.describe().T","16586f73":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","74b32f4d":"Q1 = train['Fare'].quantile(0.05)\nQ3 = train['Fare'].quantile(0.95)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","9da707f9":"# observations with Fare data higher than the upper limit:\n\ntrain['Fare'] > (upper_limit)","66d59b29":"train.sort_values(\"Fare\", ascending=False).head()","4cc4f376":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \ntrain['Fare'] = train['Fare'].replace(512.3292, 300)","a57ff489":"train.sort_values(\"Fare\", ascending=False).head()","b6023d0c":"test.sort_values(\"Fare\", ascending=False)","f68ef8f1":"test['Fare'] = test['Fare'].replace(512.3292, 300)","775c83a2":"test.sort_values(\"Fare\", ascending=False)","c145bc5a":"train.isnull().sum()","ce5adaca":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","6dc68395":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","207dbf10":"train.isnull().sum()","242a52a3":"test.isnull().sum()","7d373503":"train.isnull().sum()","38c0978a":"test.isnull().sum()","f6842593":"train[\"Embarked\"].value_counts()","08804eb9":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","fbaf9303":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","235a83d9":"train.isnull().sum()","ae10b869":"test.isnull().sum()","95303395":"test[test[\"Fare\"].isnull()]","cd6c9f89":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","6be5235c":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","94d2f29b":"test[\"Fare\"].isnull().sum()","55cd0806":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","a0c7b037":"train.head()","de6da66e":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","b4357320":"train.head()","ad92659e":"train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","5df7ccf0":"train.head()","1458f798":"train['Title'] = train['Title'].replace(['Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')","25981e77":"test['Title'] = test['Title'].replace(['Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","477bed91":"train.head()","58be8b6f":"test.head()","d13eccc8":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","60c8faa5":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","6a56071a":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","3cd1a592":"train.isnull().sum()","101c33e9":"test['Title'] = test['Title'].map(title_mapping)","e543cd09":"test.head()","85d0e18c":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","0e3fd457":"train.head()","98d08ed0":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['1', '2', '3', '4', '5', '6', '7']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)","488bd019":"train.head()","abf28d7b":"#dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","d0010f07":"train.head()","ab28e799":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])\n","5753f278":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","4040aa2e":"train.head()","feb7414c":"train.head()","9fdc8f50":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","ee5cabb5":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","3cbb32f0":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","da36d0af":"train.head()","325a794d":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","6c45b8a5":"test.head()","abfdde05":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")","5a99bc7a":"train.head()","9a4201e9":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")","0c6d2527":"test.head()","75e4c725":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")","b6b8f4a8":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","dc062405":"train.head()","87eb9d19":"test.head()","9438010e":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","d123e9b3":"x_train.shape","efe2a724":"x_test.shape","1752bf89":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","5b104d74":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","337c0257":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","04530d24":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","487dc2ce":"xgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","9dc43d28":"xgb_cv_model.fit(x_train, y_train)","37cdbc6c":"xgb_cv_model.best_params_","2cdb23b6":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","fc4e3541":"xgb_tuned =  xgb.fit(x_train,y_train)","43e03c37":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","622b2287":"test","d15e0fd4":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = logreg.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","ffce6a4e":"output.head()","2768406a":"## Random Forest","543de2e1":"#### Pclass vs survived:","764fffe4":"# Deployment","6ecc002c":"### Basic summary statistics about the numerical data","7fad7ea5":"## Spliting the train data","c55c9939":"# Data Understanding (Exploratory Data Analysis)","6158ee2b":"## Analysis and Visualization of Numeric and Categorical Variables","b21df1d1":"### Embarked","1e348983":"### AgeGroup","20876e75":"#### Parch vs survived:","22af4b31":"### Fare","ea2b8606":"# Business Understanding \/ Problem Definition","b51b9650":"## Missing Value Treatment","239d3148":"### Fare","4132cddc":"### Classes of some categorical variables","c20fa8cf":"## Outlier Treatment","26787e01":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","f241563d":"### Pclass","e34aa4cd":"### Family Size","11060b72":"## Feature Engineering","ee753762":"## Importing Librarires","0febc876":"### Sex","e490195e":"#### Sex vs survived:","0ba7f427":"## Gradient Boosting Classifier","bdb88494":"## Loading Data","f120bc65":"### Name - Title","3b07de78":"### Embarked","09c4598a":"### Embarked & Title","1180a7d5":"# Modeling, Evaluation and Model Tuning","3ab1e34f":"### Visualization","72b9f4bb":"## Variable Transformation","eae3ca65":"## Logistic Regression","0313b266":"### Ticket & Cabin","0de994ec":"### Age","3ee35d27":"# Data Preparation","5554e034":"## Deleting Unnecessary Variables","8a26b8cb":"#### SibSp vs survived:"}}