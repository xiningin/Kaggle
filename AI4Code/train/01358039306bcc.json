{"cell_type":{"603b9782":"code","ab316176":"code","8c0e0287":"code","c62ded8e":"code","a7a8f4e0":"code","c99881bf":"code","f2a90d11":"code","6419357b":"code","dc63c6c5":"code","dd846759":"code","07ebe53d":"code","2ae41f11":"code","7d587baa":"code","fa1d6439":"code","172c3896":"code","54f8d793":"code","d0040505":"code","0f77b68f":"code","aff993d4":"code","c79090d2":"code","73d8e242":"code","f4899d06":"code","791e8fa2":"code","4d9dbb9b":"code","2cbc5756":"code","6acfece0":"code","df99a5c2":"code","c1a6f8f4":"code","9574d602":"code","0f4705c4":"code","35bd0fd9":"code","d6f3036c":"code","e66716a0":"code","d75b0f8c":"code","7e1ebc80":"code","c6b57fa2":"code","08fe7268":"code","264750c7":"code","bdbf6af4":"code","094272e5":"code","af5a4536":"code","104767dc":"code","3ab859f2":"code","0a305833":"code","30a3cfe8":"code","c05f1a18":"code","31447123":"code","08f3286d":"code","2c5d47bf":"code","0e910d4e":"code","99b88a17":"code","de81889e":"code","633230ca":"code","64a80e6b":"code","5bed248a":"code","a420dcd7":"code","8addf77c":"code","0bfba360":"code","d60ff5cb":"code","0e985062":"code","4cc62e5b":"markdown","8bc5e994":"markdown","c7ab08af":"markdown","d42ad486":"markdown","a243bbba":"markdown","2e3303fc":"markdown","8bb05362":"markdown","412f9bf5":"markdown","f132d3ac":"markdown","f528e8f4":"markdown","3c451092":"markdown","4585c767":"markdown","0b70fb77":"markdown","86219550":"markdown","4c77bcdb":"markdown","ca0a9872":"markdown","a98768e1":"markdown","c55cca5a":"markdown","279aa093":"markdown","70ab74f9":"markdown","b815c0df":"markdown","594990c5":"markdown","1386bee7":"markdown","03e1516e":"markdown","02207b85":"markdown","5f6ab914":"markdown","6911319d":"markdown","467b7713":"markdown","fa75aaad":"markdown","5d333e2e":"markdown","6102e692":"markdown","ba507cb3":"markdown","ec41c0f7":"markdown","cc63bbde":"markdown","79ff915c":"markdown","5700b6f2":"markdown"},"source":{"603b9782":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom sklearn import set_config\nset_config(display='diagram')\nimport warnings\nwarnings.filterwarnings('ignore')\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport sklearn\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import PowerTransformer, FunctionTransformer, PolynomialFeatures\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.linear_model import LinearRegression, SGDRegressor, ElasticNet\nfrom sklearn.svm import SVR\nfrom sklearn.decomposition import PCA\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor, ExtraTreesRegressor, GradientBoostingRegressor, StackingRegressor, BaggingRegressor\nfrom sklearn.metrics import r2_score\nfrom sklearn.pipeline import Pipeline\nimport missingno\nfrom xgboost import XGBRegressor\nfrom matplotlib import rcParams\nimport pickle\n\n","ab316176":"dataset = pd.read_csv('..\/input\/yeh-concret-data\/Concrete_Data_Yeh.csv')\ndataset.head()","8c0e0287":"dataset.rename(columns={'csMPa': 'strength'}, inplace=True)\nprint(dataset.shape)\ndataset.head()","c62ded8e":"plt.rcParams.update({'font.size': 30})\nmissingno.matrix(dataset, figsize = (30,10));\nplt.title(\"No missing values\");","a7a8f4e0":"X = dataset.iloc[:,:-1]\ny = dataset.iloc[:,-1] ","c99881bf":"X_train, X_test, y_train, y_test = train_test_split(X.values, y.values, test_size = 0.2, random_state=15)","f2a90d11":"X_train.shape","6419357b":"temp = y_test\ntemp.shape=(206,1)\ntestcsv = np.concatenate((X_test,temp),axis=1)\ntestcsv = pd.DataFrame(testcsv,columns=dataset.columns)\ntestcsv.head()","dc63c6c5":"#testcsv.to_csv('concrete_strength_testing.csv', index=False)","dd846759":"df = pd.DataFrame(X_train, columns = X.columns)\ndf.head()","07ebe53d":"plt.rcParams.update({'font.size': 18})\nfig, ax = plt.subplots(figsize=(15,15))\nsns.heatmap(dataset.corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm', ax=ax);","2ae41f11":"model = ExtraTreesRegressor()\nmodel.fit(X_train, y_train)","7d587baa":"fig = plt.figure(figsize=(10,7))\nplt.style.use('fivethirtyeight')\nfeature_imps = pd.Series(model.feature_importances_, index = df.columns)\nfeature_imps.nlargest(8).plot(kind='barh')\nplt.grid(True)\nplt.title(\"Feature Selection\", pad=50)\nplt.xlabel('Feature Importance')\nplt.show()","fa1d6439":"plt.figure(figsize=(7,5))\npca_dummy = PCA(n_components=None)\nX_dummy = X_train\nX_dummy = pca_dummy.fit_transform(X_dummy)\nplt.plot(np.cumsum(pca_dummy.explained_variance_ratio_))\nplt.axhline(y = 0.99, c='r', linewidth =1, linestyle='--')\nplt.axvline(x=5, c='r', linestyle = '--', linewidth =1)\nplt.axhline(y = 0.95, c='g', linewidth =1, linestyle='--' )\nplt.axvline(x=3.7, c='g', linestyle = '--', linewidth =1)\nplt.axhline(y = 0.90, c='m', linewidth =1, linestyle='--' )\nplt.axvline(x=3.3, c='m', linestyle = '--', linewidth =1)\nplt.margins(0.1)\nplt.title('Number of feature to select : 5', pad=30)\nplt.plot()","172c3896":"plt.rcParams.update({'font.size': 15})\nfig, ax = plt.subplots(figsize=(12,10))\nsns.heatmap(dataset[['cement','slag','water','superplasticizer','age','strength']].corr(), annot = True, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm', ax=ax);","54f8d793":"df = df[['cement', 'slag', 'water', 'superplasticizer', 'age']]","d0040505":"columns=list(df.columns)\ncolumns","0f77b68f":"plt.figure(figsize=(17,45))\nfor i in enumerate(columns):\n    plt.style.use('fivethirtyeight')\n    plt.subplot(8,2,(2*i[0])+1)\n    plt.hist(df[i[1]],alpha=0.75,edgecolor='black',linewidth=2)\n    plt.title(f'{i[1]} frequency distribution plot',fontsize=25)\n    plt.xlabel(f'{i[1]} kg\/m3',fontsize=15)\n    plt.ylabel('Count',fontsize=15)\n    plt.tight_layout(pad=5.0)\n    plt.grid(False)\n    \n    plt.subplot(8,2,(2*i[0])+2)\n\n    sns.boxplot(df[i[1]],color='tab:orange',linewidth=1)\n    plt.title(f'{i[1]} box plot',fontsize=25)\n    plt.tight_layout(pad=5.0)","aff993d4":"# Setting upper limit and lower limit for cement\np25_cement = df.cement.quantile(0.25)\np75_cement = df.cement.quantile(0.75)\niqr_cement = p75_cement - p25_cement\nupper_cement = p75_cement + 1.5*iqr_cement\nlower_cement = 0\n\n# Setting upper limit and lower limit for slag\np25_slag = df.slag.quantile(0.25)\np75_slag = df.slag.quantile(0.75)\niqr_slag = p75_slag - p25_slag\nupper_slag = p75_slag + 1.5*iqr_slag\nlower_slag = 0\n\n# Setting upper limit and lower limit for flyash\n#p25_flyash = df.flyash.quantile(0.25)\n#p75_flyash = df.flyash.quantile(0.75)\n#iqr_flyash = p75_flyash - p25_flyash\n#upper_flyash = p75_flyash + 1.5*iqr_flyash\n#lower_flyash = 0\n\n# Setting upper limit and lower limit for water\np25_water = df.water.quantile(0.25)\np75_water = df.water.quantile(0.75)\niqr_water = p75_water - p25_water\nupper_water = p75_water + 1.5*iqr_water\nlower_water = p25_water - 1.5*iqr_water\n\n\n# Setting upper limit and lower limit for superplasticizer\np25_sup = df.superplasticizer.quantile(0.25)\np75_sup = df.superplasticizer.quantile(0.75)\niqr_sup = p75_sup - p25_sup\nupper_superplasticizer = p75_sup + 1.5*iqr_sup\nlower_superplasticizer = 0\n\n\n# Setting upper limit and lower limit for courseaggregate\n#p25_coarseaggregate = df.coarseaggregate.quantile(0.25)\n#p75_coarseaggregate = df.coarseaggregate.quantile(0.75)\n#iqr_coarseaggregate = p75_coarseaggregate - p25_coarseaggregate\n#upper_coarseaggregate = p75_coarseaggregate + 1.5*iqr_coarseaggregate\n#lower_coarseaggregate = p25_coarseaggregate - 1.5*iqr_coarseaggregate\n\n\n# Setting upper limit and lower limit for fineaggregate\n#p25_fa = df.fineaggregate.quantile(0.25)\n#p75_fa = df.fineaggregate.quantile(0.75)\n#iqr_fa = p75_fa - p25_fa\n#upper_fineaggregate = p75_fa + 1.5*iqr_fa\n#lower_fineaggregate = p25_fa - 1.5*iqr_fa\n\n# Setting upper limit and lower limit for age\np25_age = df.age.quantile(0.25)\np75_age = df.age.quantile(0.75)\niqr_age = p75_age - p25_age\nupper_age = p75_age + 1.5*iqr_age\nlower_age = 0\n","c79090d2":"print(upper_water, lower_water)","73d8e242":"print(df[df.water > upper_water].shape)\ndf[df.water > upper_water]","f4899d06":"print(df[df.water < lower_water].shape)\ndf[df.water < lower_water]","791e8fa2":"df.water = np.where(df.water>upper_water, upper_water, np.where(df.water<lower_water,lower_water,df.water))","4d9dbb9b":"df[df.water > upper_water]","2cbc5756":"df[df.water < lower_water]","6acfece0":"print(upper_superplasticizer, lower_superplasticizer)","df99a5c2":"print(df[df.superplasticizer > upper_superplasticizer].shape)\ndf[df.superplasticizer > upper_superplasticizer]","c1a6f8f4":"print(df[df.superplasticizer < lower_superplasticizer].shape)\ndf[df.superplasticizer < lower_superplasticizer]","9574d602":"df.superplasticizer = np.where(df.superplasticizer>upper_superplasticizer, upper_superplasticizer, df.superplasticizer)","0f4705c4":"df[df.superplasticizer > upper_superplasticizer]","35bd0fd9":"#print(upper_fineaggregate, lower_fineaggregate)","d6f3036c":"#print(df[df.fineaggregate > upper_fineaggregate].shape)\n#df[df.fineaggregate > upper_fineaggregate]","e66716a0":"#print(df[df.fineaggregate < lower_fineaggregate].shape)\n#df[df.fineaggregate < lower_fineaggregate]","d75b0f8c":"#df.fineaggregate = np.where(df.fineaggregate>upper_fineaggregate, upper_fineaggregate, df.fineaggregate)","7e1ebc80":"#df[df.fineaggregate > upper_fineaggregate]","c6b57fa2":"print(upper_age, lower_age)","08fe7268":"print(df[df.age > upper_age].shape)\ndf[df.age > upper_age]","264750c7":"print(df[df.age < lower_age].shape)\ndf[df.age < lower_age]","bdbf6af4":"df.age = np.where(df.age>upper_age, upper_age, df.age)","094272e5":"df[df.age > upper_age]","af5a4536":"plt.figure(figsize=(17,45))\nfor i in enumerate(columns):\n    plt.style.use('fivethirtyeight')\n    plt.subplot(8,2,(2*i[0])+1)\n    plt.hist(df[i[1]],alpha=0.75,edgecolor='black',linewidth=2)\n    plt.title(f'{i[1]} frequency distribution plot',fontsize=25)\n    plt.xlabel(f'{i[1]} kg\/m3',fontsize=15)\n    plt.ylabel('Count',fontsize=15)\n    plt.tight_layout(pad=5.0)\n    plt.grid(False)\n    \n    plt.subplot(8,2,(2*i[0])+2)\n\n    sns.boxplot(df[i[1]],color='tab:orange',linewidth=1)\n    plt.title(f'{i[1]} box plot',fontsize=25)\n    plt.tight_layout(pad=5.0)","104767dc":"X_train = df.iloc[:,:]\nX_train_processed = X_train","3ab859f2":"pt = PowerTransformer()\nX_train = pt.fit_transform(X_train)","0a305833":"df = pd.DataFrame(X_train, columns = columns)\ndf.head()","30a3cfe8":"plt.figure(figsize=(17,45))\nfor i in enumerate(columns):\n    plt.style.use('fivethirtyeight')\n    plt.subplot(8,2,(2*i[0])+1)\n    plt.hist(df[i[1]],alpha=0.75,edgecolor='black',linewidth=2)\n    plt.title(f'{i[1]} frequency distribution plot',fontsize=25)\n    plt.xlabel(f'{i[1]} kg\/m3',fontsize=15)\n    plt.ylabel('Count',fontsize=15)\n    plt.tight_layout(pad=5.0)\n    plt.grid(False)\n    \n    plt.subplot(8,2,(2*i[0])+2)\n\n    sns.boxplot(df[i[1]],color='tab:orange',linewidth=1)\n    plt.title(f'{i[1]} box plot',fontsize=25)\n    plt.tight_layout(pad=5.0)","c05f1a18":"lr = LinearRegression()\nsgd = SGDRegressor()\nen = ElasticNet()","31447123":"print(cross_val_score(lr, X_train, y_train, cv =5, scoring = 'r2').mean())\nprint(cross_val_score(sgd, X_train, y_train, cv =5, scoring = 'r2').mean())\nprint(cross_val_score(en, X_train, y_train, cv =5, scoring = 'r2').mean())","08f3286d":"poly_reg = PolynomialFeatures(degree=4)\nX_poly= poly_reg.fit_transform(X_train)\nprint(cross_val_score(lr, X_poly, y_train, cv =5, scoring = 'r2').mean())","2c5d47bf":"svr = SVR(kernel='rbf',C=70)\nprint(cross_val_score(svr, X_train, y_train, cv =5, scoring = 'r2').mean())","0e910d4e":"dt = DecisionTreeRegressor(max_depth=8)\nprint(cross_val_score(dt, X_train, y_train, cv=5, scoring = 'r2').mean())","99b88a17":"rf = RandomForestRegressor(n_estimators=100, max_depth=10)\nprint(cross_val_score(rf, X_train, y_train, cv=5, scoring = 'r2').mean())","de81889e":"et = ExtraTreesRegressor(n_estimators=100,max_depth=None)\nprint(cross_val_score(et, X_train, y_train, cv=5, scoring = 'r2').mean())","633230ca":"gbr = GradientBoostingRegressor(learning_rate=0.25, n_estimators=100, max_depth=3)\nprint(cross_val_score(gbr, X_train, y_train, cv=5, scoring = 'r2').mean())","64a80e6b":"xgbr = XGBRegressor(learning_rate=0.25)\nprint(cross_val_score(xgbr, X_train, y_train, cv=5, scoring = 'r2').mean())","5bed248a":"sr = StackingRegressor(estimators=[\n    ('et', et),\n    ('gbr', gbr),\n    ('xgbr',xgbr)\n])\nprint(cross_val_score(sr, X_train, y_train, cv=5, scoring = 'r2').mean())","a420dcd7":"\n# It expects input in form of [[a,b,c,d,e]]\n# It returns output in the form of [[a,b,c,d,e]]\ndef preprocessor(arr):\n    temp_df = pd.DataFrame(arr, columns=columns)\n    temp_df.cement = np.where(temp_df.cement>upper_cement, upper_cement, np.where(temp_df.cement<lower_cement,lower_cement,temp_df.cement))\n    temp_df.slag = np.where(temp_df.slag>upper_slag, upper_slag, np.where(temp_df.slag<lower_slag,lower_slag,temp_df.slag))\n    temp_df.water = np.where(temp_df.water>upper_water, upper_water, np.where(temp_df.water<lower_water,lower_water,temp_df.water))\n    temp_df.superplasticizer = np.where(temp_df.superplasticizer>upper_superplasticizer, upper_superplasticizer, np.where(temp_df.superplasticizer<lower_superplasticizer,lower_superplasticizer,temp_df.superplasticizer))\n    temp_df.age = np.where(temp_df.age>upper_age, upper_age, np.where(temp_df.age<lower_age,lower_age,temp_df.age))\n    X=temp_df.iloc[:,:].values\n    return X\n","8addf77c":"estimator = StackingRegressor(estimators=[\n    ('et', ExtraTreesRegressor(n_estimators=100,max_depth=None)),\n    ('gbr', GradientBoostingRegressor(learning_rate=0.25, n_estimators=100, max_depth=3)),\n    ('xgbr', XGBRegressor(learning_rate=0.25))\n])","0bfba360":"df_test = pd.DataFrame(X_test, columns = X.columns)\ndf_test=df_test[['cement', 'slag', 'water', 'superplasticizer', 'age']]\nX_test = df_test.iloc[:,:].values\nX_test_processed = preprocessor(X_test)\nX_test_transformed=pt.transform(X_test_processed)\nestimator.fit(X_train, y_train)\ny_pred = estimator.predict(X_test_transformed)\nscore = r2_score(y_test,y_pred)\nprint(f'The test set accuracy for the concrete compressive strength prediction is {score*100 :.2f}%')","d60ff5cb":"#pickle_out = open('transformer.pkl',\"wb\") # Open pickle file in write byte mode\n#pickle.dump(pt, pickle_out)\n#pickle_out.close()","0e985062":"#pickle_out = open('estimator.pkl',\"wb\") # Open pickle file in write byte mode\n#pickle.dump(estimator, pickle_out)\n#pickle_out.close()","4cc62e5b":"### ***We select cement, slag, water, superplasticizer and age. Hence we eliminate flyash, fine aggregate and coarse aggregate***","8bc5e994":"# Feature Selection","c7ab08af":"### Gradient Boosting","d42ad486":"### Random Forest","a243bbba":"### Outliers in water column","2e3303fc":"### Outliers in Superplasticizer column","8bb05362":"# Splitting dataset into training set and test set","412f9bf5":"#### Now our data is ready for the Machine Learning algorithms","f132d3ac":"#### We still need to transform the data into nearly normal distribution","f528e8f4":"### Stacking Regressor","3c451092":"## Ensemble Methods\n\n- Bagging\n- Boosting\n- Stacking","4585c767":"# Imports","0b70fb77":"# Concrete Compressive Strength Prediction\n\n*Dataset :* [link](https:\/\/www.kaggle.com\/maajdl\/yeh-concret-data)","86219550":"## Distribution\/Shape of data after Feature Transformation","4c77bcdb":"# Any missing values ?","ca0a9872":"### Extreme gradient boosting","a98768e1":"### Outliers in Age column","c55cca5a":"# Exporting binary file for production (*test environment*)","279aa093":"### Polynomial linear model","70ab74f9":"# Dealing with Outliers","b815c0df":"# How many features to extract\/select ?","594990c5":"### Outliers in Fine aggregate column","1386bee7":"## Distribution\/Shape of data after dealing with outliers","03e1516e":"### Extra Trees","02207b85":"## Data Attributes Information:\n\nGiven are the variable name, variable type, the measurement unit and a brief description. The concrete compressive strength is the regression problem. The order of this listing corresponds to the order of numerals along the rows of the database.\n\nName -- Data Type -- Measurement -- Description\n\n- Cement (component 1) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Blast Furnace Slag (component 2) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Fly Ash (component 3) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Water (component 4) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Superplasticizer (component 5) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Coarse Aggregate (component 6) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Fine Aggregate (component 7) -- quantitative -- kg in a m3 mixture -- Input Variable\n- Age -- quantitative -- Day (1~365) -- Input Variable\n- Concrete compressive strength -- quantitative -- MPa -- Output Variable","5f6ab914":"<img src=\"https:\/\/5.imimg.com\/data5\/AA\/OA\/DS\/SELLER-41794075\/pvc-y-pipe-fitting-500x500.jpg\"> <\/img>","6911319d":"# ***Plan of attack***\n\n***- Imputation***\n\n***- Feature Selection***\n\n***- Dimensionality Reduction***\n\n***- Exploratory Data Analysis***\n\n***- Dealing with outliers***\n\n***- Feature Transformation*** (Standardization\/Normalization)\n\n***- Model Building*** (Iterative process)\n\n***- Cross Validating*** (Iterative process)\n\n***- Builing secure deployment ready pipelines***\n\n***- Exporting binary file for production*** (Testing Environment)","467b7713":"# Feature Transformation","fa75aaad":"# Exploratory Data Analysis","5d333e2e":"# ML Modelling","6102e692":"### Linear Models","ba507cb3":"### Kernel based model","ec41c0f7":"# Pipeline steps for testing environment\n\n1. Outlier detection and dealing with them.\n2. Feature transformation\n3. Dimensionality Reduction\n4. Passing data down to the estimator","cc63bbde":"## Abstract:\n- Concrete is the most important material in civil engineering.\n- The concrete compressive strength is a highly nonlinear function of age and ingredients.","79ff915c":"## ***Inferences from EDA***\n\n- The data is very much skewed. We need to transform it to nearly normal distribution.\n- Water, Superplasticizer and Age columns have some outliers. We need to fix them before feature transformation","5700b6f2":"### Tree based model"}}