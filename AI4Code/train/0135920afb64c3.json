{"cell_type":{"6103c1c7":"code","6faab911":"code","6a5445ed":"code","4219aad7":"code","36634cc1":"code","8c425294":"code","7c6db41e":"code","5d5198d6":"code","b6e303cd":"code","cfbb1588":"code","7484c889":"code","670c7c21":"code","219e3845":"code","79f5df48":"code","af31cbd0":"code","fda2a3ec":"code","3dd9b791":"code","7d278ad7":"code","b4c5fd0e":"code","e01092b7":"code","2284ce7a":"code","4a81bc99":"code","9c4bd5a7":"code","3f8d6cda":"code","91c9c5c1":"code","2d420927":"code","8238e981":"code","8cd671d9":"code","c98137db":"code","bcd98458":"code","0e2c4a97":"code","13439f91":"code","2861fc99":"code","ebcdc16b":"code","5dee49ab":"code","24b8601c":"code","f81a3e49":"code","dcb8062f":"code","bc7fb2eb":"code","059d876a":"code","40471967":"code","4325b1cb":"code","3c357ea9":"code","0f1a0c5e":"code","c115891c":"code","5d9677c1":"code","eb73865d":"code","f85046d9":"code","2dea21ac":"code","0d6f5ffc":"code","320477b4":"code","1b822ae7":"code","aa51726c":"code","632d2ded":"code","6517aa92":"code","a07acd6f":"code","8d8e13c7":"code","ed347306":"code","e4ab82c1":"code","c7993de5":"code","2edd8f35":"code","5c8f22a1":"code","315a5904":"code","41e766c3":"code","a510ad73":"code","02da3e74":"code","1572ec96":"code","c927cc7e":"code","fdd1403b":"code","e8f46f6e":"markdown","56998540":"markdown","e1d0126f":"markdown","514c1e08":"markdown","b5db004b":"markdown","74cf5322":"markdown","3f5fb21b":"markdown","db797845":"markdown","3596e343":"markdown","c16eda14":"markdown","9826c3be":"markdown","9cbf48d1":"markdown","d919bffd":"markdown","0956996b":"markdown","7c4ef738":"markdown","8548d036":"markdown","fa924907":"markdown","9ee2557c":"markdown","762d633d":"markdown","60294be8":"markdown","bc75bb8d":"markdown","b2649cf0":"markdown","fce4db7a":"markdown","70b8000f":"markdown","10c46c39":"markdown","9a661b6c":"markdown"},"source":{"6103c1c7":"# import libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport cv2\nimport tensorflow as tf\nimport string\nfrom tensorflow.keras import regularizers, models, layers, optimizers\nfrom sklearn.model_selection import train_test_split\nfrom keras.preprocessing.image import ImageDataGenerator\n\nseed = 1234\nnp.random.seed(seed)\ntf.random.set_seed(seed)\n\nfrom google.colab import drive\ndrive.mount('\/content\/drive')","6faab911":"images = np.load('\/content\/drive\/MyDrive\/Colab Notebooks\/mds-misis-dl-captcha\/data\/images.npy')\nlabels = np.load('\/content\/drive\/MyDrive\/Colab Notebooks\/mds-misis-dl-captcha\/data\/labels.npy')\nimages_pred = np.load('\/content\/drive\/MyDrive\/Colab Notebooks\/mds-misis-dl-captcha\/data\/images_sub.npy')","6a5445ed":"DIMENSIONS = len(set(labels)) # num of classes\nBATCH_SIZE = 48\n\ncharacters = set(labels)\nletters = list(string.ascii_lowercase)\ntranslit = {key : value for key, value in zip(characters, letters)}\n\n\ndef to_one_hot(labels, dimension: int = DIMENSIONS):\n    result = np.zeros((len(labels),dimension))\n    for i, label in enumerate(labels):\n        result[i,label] = 1.\n    return result\n\n\ndef visualize(images_array, nimgs: int) -> object :#, translit: dict, y=False, y_labels=None)  :\n  ncols = int(nimgs \/ 2)\n  _,ax = plt.subplots(nrows=2, ncols=ncols, figsize=(10,3))\n  for i in range(nimgs):\n      img = images_array[i]\n      ax[i\/\/ncols, i%ncols].imshow(img, cmap='gray')\n      ax[i\/\/ncols, i%ncols].axis('off')\n      # if y:\n      #   ax.set_title('Label: {}'.format(translit.get(y_labels[i],)))\n  plt.show()\n\n\ndef show_loss_graph(history, metric: str):\n  #metric - accuracy or loss\n  metr = history.history[f'{metric}']\n  val_metr = history.history[f'val_{metric}']\n  epochs = range(1, len(metr) + 1)\n\n  plt.plot(epochs, metr, 'bo', label=f'Training {metric}')\n  plt.plot(epochs, val_metr, 'b', label=f'Validation {metric}')\n  plt.title(f'Training and validation {metric}')\n  plt.legend()\n\n  plt.show()\n\n\ndef generator_visualize(generator, num_imgs: int, batch_size: int =BATCH_SIZE) -> object:\n  n_rows = 2\n  n_cols = num_imgs \/\/ n_rows\n  try:\n    fig2, axes2 = plt.subplots(n_rows, n_cols, figsize=(1.5*n_cols,2*n_rows))\n    for X, Y in generator:\n        for i in range(0, batch_size):\n              ax = axes2[i\/\/n_cols, i%n_cols]\n              ax.imshow(X[i].reshape(48,48,3), cmap='gray_r')\n              #ax.set_title('Label: {}'.format(int(Y[i])))\n        break\n    plt.tight_layout()\n    plt.show()\n  except IndexError:\n    pass\n\n\ndef to_black_white(x_array, separator: float):\n  #test = x_array.copy()\n  #separator = 1.2 # 255 \/ 0.8 \/ 2 * 3 \/ 255 \n  x_array = x_array \/ 255\n  all_black = np.zeros((48,48,3))\n  all_white = np.ones((48,48,3))\n\n  for img_num, img in enumerate(x_array):\n    for w_num, w in enumerate(img):\n      for h_num, h in enumerate(w):\n        if sum(h) > separator:\n          x_array[img_num,w_num,h_num] = [1., 1., 1.]\n        else:\n          x_array[img_num,w_num,h_num] = [0., 0., 0.]\n\n  a = []\n  for img_num, img in enumerate(x_array):\n    if np.logical_and(img == all_black, all_black == img).all():\n      a.append(img_num)\n    if np.logical_and(img == all_white, all_white == img).all():\n      a.append(img_num)\n\n  x_array = np.delete(x_array, a, axis=0)\n\n  return x_array\n\n\ndef make_standard(array):\n  return (array \/ 255).astype(np.float32)\n\n\ndef make_noise(array):\n  return make_standard(array) - np.random.normal(0, 0.2, array.shape)","4219aad7":"# We are to predict the following examples. \nvisualize(images_pred, 16)","36634cc1":"# Let's take a look at some samples first. \nvisualize(images, 16)","8c425294":"print(f\"All possible classes of characters in CAPTCHAs: {characters}.\")\nprint(f\"Letters in CAPTCHAs by class: {letters}.\")","7c6db41e":"print(f\"Dataset shape: {images.shape}\")\nprint(f\"Labels shape: {labels.shape}\")\n#print(f\"Prediction data shape: {images_pred.shape}\")","5d5198d6":"# Get train, test, validate\n# _data include train and validation\n\nx_data, x_test, y_data, y_test = train_test_split(images, labels,\n                                                   stratify=labels,\n                                                   shuffle=True,\n                                                   test_size=0.1)\nx_train, x_valid, y_train, y_valid = train_test_split(x_data, y_data,\n                                                   stratify=y_data,\n                                                   shuffle=True,\n                                                   test_size=0.15)","b6e303cd":"y_train_one_hot = to_one_hot(y_train).astype('float32')\ny_test_one_hot = to_one_hot(y_test).astype('float32')\ny_valid_one_hot = to_one_hot(y_valid).astype('float32')","cfbb1588":"model = models.Sequential([\n\n    # first conv block                     \n    layers.Conv2D(32, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  kernel_regularizer=regularizers.l2(l2=0.01), \n                  input_shape=(48,48,3)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # second conv block  \n    layers.Conv2D(64, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  ),\n    #layers.BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    layers.Flatten(),\n    layers.Dropout(0.3),\n    layers.Dense(512, activation='relu'),\n    # Classes\n    layers.Dense(DIMENSIONS,\n              activation='softmax',)\n])\n\nmodel.summary()","7484c889":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        width_shift_range=0.2,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        \n        zoom_range=[0.8,1.2],\n        brightness_range=(0.5,1.5),\n        channel_shift_range=0.5,\n        horizontal_flip=False,    \n    )\n\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow(\n        x_train, y_train_one_hot,\n        batch_size=BATCH_SIZE)\n\nvalidation_generator = valid_datagen.flow(\n        x_valid, y_valid_one_hot,\n        batch_size=BATCH_SIZE)","670c7c21":"generator_visualize(train_generator, 16, )","219e3845":"model.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","79f5df48":"EPOCHS = 150\nCHECKPOINT_NAME = '\/content\/drive\/MyDrive\/Colab Notebooks\/Capcha_model.hdf5'\n\n# # Save weights only for best model\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = CHECKPOINT_NAME, \n                               verbose = 2, \n                               save_best_only = True)\n\n# Reduce learning rate when a metric has stopped improving\nlr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', #'val_loss'\n                                 patience=10, \n                                 verbose=2, \n                                 factor=.75)\n\n# If score doesn't improve during patience=20 epochs, stop learning\nestopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', #'val_loss'\n                          patience=20, \n                          verbose=2)\n\n# # Training\n\nhistory = model.fit(train_generator,\n                        # x_train, y_train_one_hot,\n                        #batch_size = BATCH_SIZE,\n                        steps_per_epoch=len(x_train) \/ BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n                        #validation_data = (x_test, y_test_one_hot),\n                        validation_data = validation_generator,\n                        validation_steps=len(x_valid) \/ BATCH_SIZE,\n                        callbacks = [checkpointer, lr_reduction, estopping]\n)","af31cbd0":"loss, acc = model.evaluate((x_test \/ 255).astype(np.float32), y_test_one_hot, verbose=2)\nprint('Restored model, accuracy: {:5.2f}%'.format(100 * acc))","fda2a3ec":"# Accuracy\n\nshow_loss_graph(history, 'accuracy')","3dd9b791":"# Loss\n\nshow_loss_graph(history, 'loss')","7d278ad7":"X = np.concatenate((x_train, x_valid, x_test), axis=0)\nY_one_hot = np.concatenate((y_train_one_hot, y_valid_one_hot, y_test_one_hot), axis=0)","b4c5fd0e":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        width_shift_range=0.2,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        \n        zoom_range=[0.8,1.2],\n        brightness_range=(0.5,1.5),\n        channel_shift_range=0.5,\n        horizontal_flip=False,    \n    )\n\ntrain_generator = train_datagen.flow(\n        X, Y_one_hot,\n        batch_size=BATCH_SIZE)","e01092b7":"# # Training\nmodel = models.Sequential([\n\n    # first conv block                     \n    layers.Conv2D(32, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  kernel_regularizer=regularizers.l2(l2=0.01), \n                  input_shape=(48,48,3)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # second conv block  \n    layers.Conv2D(64, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  ),\n    #layers.BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    layers.Flatten(),\n    layers.Dropout(0.3),\n    layers.Dense(512, activation='relu'),\n    # Classes\n    layers.Dense(DIMENSIONS,\n              activation='softmax',)\n])\n\nmodel.summary()\nmodel.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n\nEPOCHS = 100\nCHECKPOINT_NAME = 'Capcha_model1_1.hdf5'\n\n# # Save weights only for best model\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = CHECKPOINT_NAME, \n                               verbose = 2, \n                               save_best_only = True)\n\n# Reduce learning rate when a metric has stopped improving\nlr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', #'val_loss'\n                                 patience=5, \n                                 verbose=2, \n                                 factor=.75)\n\n# If score doesn't improve during patience=20 epochs, stop learning\nestopping = tf.keras.callbacks.EarlyStopping(monitor='loss', #'val_loss'\n                          patience=20, \n                          verbose=2)\n\nres = model.fit(train_generator,\n                        # x_train, y_train_one_hot,\n                        #batch_size = BATCH_SIZE,\n                        steps_per_epoch=len(X) \/ BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n                callbacks = [checkpointer, lr_reduction, estopping]\n        )\nmodel.save('my_model1.h5')\nmodel.save('my_model_1.hdf5')","2284ce7a":"# Model 2\n\nmodel2 = models.Sequential([\n\n    # first conv block                     \n    layers.Conv2D(32, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  kernel_regularizer=regularizers.l2(l2=0.01), \n                  input_shape=(48,48,3)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # second conv block  \n    layers.Conv2D(64, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  ),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    layers.Flatten(),\n    layers.Dropout(0.3),\n    layers.Dense(512, activation='relu'),\n    # Classes\n    layers.Dense(DIMENSIONS,\n              activation='softmax',)\n])\n\nmodel2.summary()","4a81bc99":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        width_shift_range=0.2,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        \n        zoom_range=[0.8,1.2],\n        brightness_range=(0.5,1.5),\n        channel_shift_range=0.5,\n        horizontal_flip=False,    \n    )\n\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow(\n        x_train, y_train_one_hot,\n        batch_size=BATCH_SIZE)\n\nvalidation_generator = valid_datagen.flow(\n        x_valid, y_valid_one_hot,\n        batch_size=BATCH_SIZE)","9c4bd5a7":"model2.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","3f8d6cda":"EPOCHS = 300\nCHECKPOINT_NAME = '\/content\/drive\/MyDrive\/Colab Notebooks\/Capcha_model_2.hdf5'\n\n# # Save weights only for best model\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = CHECKPOINT_NAME, \n                               verbose = 2, \n                               save_best_only = True)\n\n# Reduce learning rate when a metric has stopped improving\nlr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', #'val_loss'\n                                 patience=10, \n                                 verbose=2, \n                                 factor=.75)\n\n# If score doesn't improve during patience=20 epochs, stop learning\nestopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', #'val_loss'\n                          patience=20, \n                          verbose=2)\n\n# # Training\n\nhistory2 = model2.fit(train_generator,\n                        # x_train, y_train_one_hot,\n                        #batch_size = BATCH_SIZE,\n                        steps_per_epoch=len(x_train) \/ BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n                        #validation_data = (x_test, y_test_one_hot),\n                        validation_data = validation_generator,\n                        validation_steps=len(x_valid) \/ BATCH_SIZE,\n                        callbacks = [checkpointer, lr_reduction, estopping]\n)","91c9c5c1":"loss, acc = model2.evaluate((x_test \/ 255).astype(np.float32), y_test_one_hot, verbose=2)\nprint('Restored model, accuracy: {:5.2f}%'.format(100 * acc))","2d420927":"# Accuracy\n\nshow_loss_graph(history2, 'accuracy')","8238e981":"# Loss\n\nshow_loss_graph(history2, 'loss')","8cd671d9":"X = np.concatenate((x_train, x_valid, x_test), axis=0)\nY_one_hot = np.concatenate((y_train_one_hot, y_valid_one_hot, y_test_one_hot), axis=0)","c98137db":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        width_shift_range=0.2,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        \n        zoom_range=[0.8,1.2],\n        brightness_range=(0.5,1.5),\n        channel_shift_range=0.5,\n        horizontal_flip=False,    \n    )\n\ntrain_generator = train_datagen.flow(\n        X, Y_one_hot,\n        batch_size=BATCH_SIZE)","bcd98458":"# # Training\nmodel = models.Sequential([\n\n    # first conv block                     \n    layers.Conv2D(32, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  kernel_regularizer=regularizers.l2(l2=0.01), \n                  input_shape=(48,48,3)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # second conv block  \n    layers.Conv2D(64, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  ),\n    #layers.BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    layers.Flatten(),\n    layers.Dropout(0.3),\n    layers.Dense(512, activation='relu'),\n    # Classes\n    layers.Dense(DIMENSIONS,\n              activation='softmax',)\n])\n\nmodel.summary()\nmodel.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\n\n\nEPOCHS = 100\nCHECKPOINT_NAME = 'Capcha_model1_1.hdf5'\n\n# # Save weights only for best model\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = CHECKPOINT_NAME, \n                               verbose = 2, \n                               save_best_only = True)\n\n# Reduce learning rate when a metric has stopped improving\nlr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='loss', #'val_loss'\n                                 patience=5, \n                                 verbose=2, \n                                 factor=.75)\n\n# If score doesn't improve during patience=20 epochs, stop learning\nestopping = tf.keras.callbacks.EarlyStopping(monitor='loss', #'val_loss'\n                          patience=20, \n                          verbose=2)\n\nres = model.fit(train_generator,\n                        # x_train, y_train_one_hot,\n                        #batch_size = BATCH_SIZE,\n                        steps_per_epoch=len(X) \/ BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n                callbacks = [checkpointer, lr_reduction, estopping]\n        )\nmodel.save('my_model1.h5')\nmodel.save('my_model_1.hdf5')","0e2c4a97":"images = np.load('\/content\/drive\/MyDrive\/Colab Notebooks\/mds-misis-dl-captcha\/data\/images.npy')\nlabels = np.load('\/content\/drive\/MyDrive\/Colab Notebooks\/mds-misis-dl-captcha\/data\/labels.npy')\nimages_pred = np.load('\/content\/drive\/MyDrive\/Colab Notebooks\/mds-misis-dl-captcha\/data\/images_sub.npy')","13439f91":"visualize(make_noise(images), 16)","2861fc99":"del images_noise","ebcdc16b":"# Get train, test, validate\n# To check if model is better we should use the same train_val_test split\n\nx_train_noise = make_noise(x_train)\n\n# Concatenate togeter the normalized train (than test) set with noise and the one without noise\n\nx_train_with_noise = np.concatenate((make_standard(x_train), x_train_noise), axis=0)\ny_train_for_noisedx = np.concatenate((y_train, y_train), axis=0)\n\ny_train_one_hot_for_noisedx = to_one_hot(y_train_for_noisedx).astype('float32')\n\nprint(x_train_with_noise.shape)\nprint(y_train_one_hot_for_noisedx.shape)","5dee49ab":"model_noised = models.Sequential([\n\n    # first conv block                     \n    layers.Conv2D(32, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  kernel_regularizer=regularizers.l2(l2=0.01), \n                  input_shape=(48,48,3)),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # second conv block  \n    layers.Conv2D(64, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  ),\n    #layers.BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    layers.Flatten(),\n    layers.Dropout(0.3),\n    layers.Dense(512, activation='relu'),\n    # Classes\n    layers.Dense(DIMENSIONS,\n              activation='softmax',)\n])\n\nmodel_noised.summary()","24b8601c":"train_datagen = ImageDataGenerator(\n#        rescale=1.\/255, #alredy standartized\n        width_shift_range=0.2,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        \n        zoom_range=[0.8,1.2],\n        #brightness_range=(0.5,1.5),\n        channel_shift_range=0.5,\n        horizontal_flip=False,    \n    )\n\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow(\n        x_train_with_noise, y_train_one_hot_for_noisedx,\n        batch_size=BATCH_SIZE)\n\nvalidation_generator = valid_datagen.flow(\n        x_valid, y_valid_one_hot,\n        batch_size=BATCH_SIZE)","f81a3e49":"generator_visualize(train_generator, 16, )","dcb8062f":"model_noised.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","bc7fb2eb":"EPOCHS = 300\nCHECKPOINT_NAME = '\/content\/drive\/MyDrive\/Colab Notebooks\/Capcha_noised.hdf5'\n\n# # Save weights only for best model\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = CHECKPOINT_NAME, \n                               verbose = 2, \n                               save_best_only = True)\n\n# Reduce learning rate when a metric has stopped improving\nlr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', #'val_loss'\n                                 patience=6, \n                                 verbose=2, \n                                 factor=.75)\n\n# If score doesn't improve during patience=20 epochs, stop learning\nestopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', #'val_loss'\n                          patience=20, \n                          verbose=2)\n\n# # Training\n\nhistory_noised_2 = model_noised.fit(train_generator,\n                        # x_train, y_train_one_hot,\n                        #batch_size = BATCH_SIZE,\n                        steps_per_epoch=len(x_train_with_noise) \/ BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n                        #validation_data = (x_test, y_test_one_hot),\n                        validation_data = validation_generator,\n                        validation_steps=len(x_valid) \/ BATCH_SIZE,\n                        callbacks = [checkpointer, lr_reduction, estopping]\n)","059d876a":"loss, acc = model_noised.evaluate((x_test \/ 255).astype(np.float32), y_test_one_hot, verbose=2)\nprint('Restored model, accuracy: {:5.2f}%'.format(100 * acc))","40471967":"# Accuracy\n\nshow_loss_graph(history_noised_2, 'accuracy')","4325b1cb":"# Loss\n\nshow_loss_graph(history_noised_2, 'loss')","3c357ea9":"X_train = np.concatenate((x_train, x_valid), axis=0)\nY_train_one_hot = np.concatenate((y_train_one_hot, y_valid_one_hot), axis=0)","0f1a0c5e":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        width_shift_range=0.2,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        \n        zoom_range=[0.8,1.2],\n        brightness_range=(0.5,1.5),\n        channel_shift_range=0.5,\n        horizontal_flip=False,    \n    )\n\ntrain_generator = train_datagen.flow(\n        X_train, Y_train_one_hot,\n        batch_size=BATCH_SIZE)","c115891c":"# # Training\n\nres = model.fit(train_generator,\n                        # x_train, y_train_one_hot,\n                        #batch_size = BATCH_SIZE,\n                        steps_per_epoch=len(x_train) \/ BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n        )","5d9677c1":"model2_noised = models.Sequential([\n\n    # first conv block                     \n    layers.Conv2D(32, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  kernel_regularizer=regularizers.l2(l2=0.01), \n                  input_shape=(48,48,3)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # second conv block  \n    layers.Conv2D(64, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  kernel_initializer='he_normal',\n                  ),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    # third conv block  \n    layers.Conv2D(128, kernel_size=(3,3), \n                  activation='relu', \n                  padding='same', \n                  ),\n    layers.BatchNormalization(),\n    layers.MaxPooling2D(pool_size=(2, 2)),\n\n    layers.Flatten(),\n    layers.Dropout(0.3),\n    layers.Dense(512, activation='relu'),\n    # Classes\n    layers.Dense(DIMENSIONS,\n              activation='softmax',)\n])\n\nmodel2_noised.summary()","eb73865d":"train_datagen = ImageDataGenerator(\n#        rescale=1.\/255, #alredy standartized\n        width_shift_range=0.2,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        \n        zoom_range=[0.8,1.2],\n        #brightness_range=(0.5,1.5),\n        channel_shift_range=0.5,\n        horizontal_flip=False,    \n    )\n\nvalid_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntrain_generator = train_datagen.flow(\n        x_train_with_noise, y_train_one_hot_for_noisedx,\n        batch_size=BATCH_SIZE)\n\nvalidation_generator = valid_datagen.flow(\n        x_valid, y_valid_one_hot,\n        batch_size=BATCH_SIZE)","f85046d9":"model2_noised.compile(optimizer='adam', loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","2dea21ac":"EPOCHS = 300\nCHECKPOINT_NAME = '\/content\/drive\/MyDrive\/Colab Notebooks\/Capcha_noised_2.hdf5'\n\n# # Save weights only for best model\ncheckpointer = tf.keras.callbacks.ModelCheckpoint(filepath = CHECKPOINT_NAME, \n                               verbose = 2, \n                               save_best_only = True)\n\n# Reduce learning rate when a metric has stopped improving\nlr_reduction = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', #'val_loss'\n                                 patience=6, \n                                 verbose=2, \n                                 factor=.75)\n\n# If score doesn't improve during patience=20 epochs, stop learning\nestopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', #'val_loss'\n                          patience=20, \n                          verbose=2)\n\n# # Training\n\nhistory2_noised = model2_noised.fit(train_generator,\n                        # x_train, y_train_one_hot,\n                        #batch_size = BATCH_SIZE,\n                        steps_per_epoch=len(x_train_with_noise) \/ BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n                        #validation_data = (x_test, y_test_one_hot),\n                        validation_data = validation_generator,\n                        validation_steps=len(x_valid) \/ BATCH_SIZE,\n                        callbacks = [checkpointer, lr_reduction, estopping]\n)","0d6f5ffc":"loss, acc = model2_noised.evaluate((x_test \/ 255).astype(np.float32), y_test_one_hot, verbose=2)\nprint('Restored model, accuracy: {:5.2f}%'.format(100 * acc))","320477b4":"# Accuracy\n\nshow_loss_graph(history2_noised, 'accuracy')","1b822ae7":"# Loss\n\nshow_loss_graph(history2_noised, 'loss')","aa51726c":"loss, acc = model.evaluate((x_test \/ 255).astype(np.float32), y_test_one_hot, verbose=2)\nprint('Restored model without noise, accuracy: {:5.2f}%'.format(100 * acc))\n\nloss, acc = model_noised.evaluate((x_test \/ 255).astype(np.float32), y_test_one_hot, verbose=2)\nprint('Restored model with noise, accuracy: {:5.2f}%'.format(100 * acc))\n\nloss, acc = model2.evaluate((x_test \/ 255).astype(np.float32), y_test_one_hot, verbose=2)\nprint('Restored model without noise, accuracy: {:5.2f}%'.format(100 * acc))\n\nloss, acc = model2_noised.evaluate((x_test \/ 255).astype(np.float32), y_test_one_hot, verbose=2)\nprint('Restored model with noise, accuracy: {:5.2f}%'.format(100 * acc))","632d2ded":"X_train = np.concatenate((x_train, x_valid), axis=0)\nY_train_one_hot = np.concatenate((y_train_one_hot, y_valid_one_hot), axis=0)","6517aa92":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        width_shift_range=0.2,\n        height_shift_range=0.1,\n        shear_range=0.2,\n        \n        zoom_range=[0.8,1.2],\n        brightness_range=(0.5,1.5),\n        channel_shift_range=0.5,\n        horizontal_flip=False,    \n    )\n\ntrain_generator = train_datagen.flow(\n        X_train, Y_train_one_hot,\n        batch_size=BATCH_SIZE)","a07acd6f":"# # Training\n\nres = model.fit(train_generator,\n                        # x_train, y_train_one_hot,\n                        #batch_size = BATCH_SIZE,\n                        steps_per_epoch=len(x_train) \/ BATCH_SIZE,\n                        epochs = EPOCHS,\n                        verbose = 1,\n        )","8d8e13c7":"# Load model\nmodel = tf.keras.models.load_model('\/content\/drive\/MyDrive\/Colab Notebooks\/Capcha_model.hdf5')\nmodel1 = tf.keras.models.load_model('\/content\/drive\/MyDrive\/Colab Notebooks\/Capcha_model_2.hdf5')\nmodel_noise = tf.keras.models.load_model('\/content\/drive\/MyDrive\/Colab Notebooks\/Capcha_noised.hdf5')\nmodel_noise2 = tf.keras.models.load_model('\/content\/drive\/MyDrive\/Colab Notebooks\/Capcha_noised_2.hdf5')\n\n# Check its architecture\n# model.summary()","ed347306":"# Check the accuracy on test\n# loss, acc = new_model.evaluate(make_standard(x_test), y_test_one_hot, verbose=2)\n# print('Restored model, accuracy: {:5.2f}%'.format(100 * acc))","e4ab82c1":"images_pred = make_standard(images_pred)","c7993de5":"pred = model_noise2.predict_classes(images_pred)\npred2 = model_noise.predict_classes(images_pred)\npred3 = model.predict_classes(images_pred)\npred4 = model1.predict_classes(images_pred)","2edd8f35":"for id, subm in enumerate([pred,pred2,pred3,pred4]):\n  submission = pd.DataFrame({'Id': list(range(len(pred))), 'Category': subm})\n  submission.to_csv(f'\/content\/drive\/MyDrive\/Colab Notebooks\/capcha_mod{id+1}.csv', index=False)","5c8f22a1":"sub1 = pd.read_csv('\/content\/drive\/MyDrive\/Colab Notebooks\/capcha_mod1.csv')\nsub2 = pd.read_csv('\/content\/drive\/MyDrive\/Colab Notebooks\/capcha_mod2.csv')\nsub3 = pd.read_csv('\/content\/drive\/MyDrive\/Colab Notebooks\/capcha_mod3.csv')\nsub4 = pd.read_csv('\/content\/drive\/MyDrive\/Colab Notebooks\/capcha_mod4.csv')","315a5904":"similar = 0\ndifferent = 0\n\nfor el1, el2, el3, el4 in zip(sub1['Category'],sub2['Category'],sub3['Category'],sub4['Category']):\n  if el1 == el2 == el3 == el4:\n    similar += 1\n  else:\n    different += 1\n\nprint(f'Submissions are similar in {similar} cases and different - in {different} cases.')","41e766c3":"import operator\n\nsubm = []\n\nfor el1, el2, el3, el4 in zip(sub1['Category'],sub2['Category'],sub3['Category'],sub4['Category']):\n  if el1 == el2 == el3 == el4:\n    subm.append(el1)\n  else:\n    possible_decision = {}\n    for el in [el1,el2,el3,el4]:\n      if possible_decision.get(el) == None:\n        possible_decision[el] = 1\n      else:\n        possible_decision[el] = possible_decision.get(el) + 1\n    decision = max(possible_decision, key=lambda k: possible_decision[k])\n    subm.append(decision)","a510ad73":"submission = pd.DataFrame({'Id': list(range(len(subm))), 'Category': subm})\nsubmission.to_csv(f'\/content\/drive\/MyDrive\/Colab Notebooks\/capcha_mod_agg.csv', index=False)","02da3e74":"#[translit.get(label) for label in submission.Category.to_list()[:16]]\n[translit.get(label) for label in subm[:32]]","1572ec96":"visualize(images_array=images_pred, nimgs=32)\n\n# # # We are to predict the following examples. \n# _,ax = plt.subplots(nrows=2, ncols=4, figsize=(5,3))\n# for i in range(8):\n#     img = images_pred[i]\n#     ax[i\/\/4, i%4].imshow(img, cmap='gray')\n#     ax[i\/\/4, i%4].axis('off')\n#     ax.set_title('Label: {}'.format(translit.get(y_labels[i],)))\n# plt.show()","c927cc7e":"images_agg = images[0:16] #* 255\n\n# # Edge Detection1 NO\n# identity = np.array([[0, -1, 0],\n#               [-1, 4, -1],\n#               [0, -1, 0]])\n# Edge Detection2 NO\n# identity = np.array([[-1, -1, -1],\n#               [-1, 8, -1],\n#               [-1, -1, -1]])\n# Bottom Sobel Filter MB\nidentity = np.array([[-1, -2, -1],\n              [0, 0, 0],\n              [1, 2, 1]])\n# Top Sobel Filter MB\n# identity = np.array([[1, 2, 1],\n#               [0, 0, 0],\n#               [-1, -2, -1]])\n# # Left Sobel Filter NO\n# identity = np.array([[1, 0, -1],\n#               [2, 0, -2],\n#               [1, 0, -1]])\n# Right Sobel Filter NO\n# identity = np.array([[-1, 0, 1],\n#                     [-2, 0, 2],\n#                     [-1, 0, 1]])\n\n# Sharpen NO\n# identity = np.array([[0, -1, 0],\n#                     [-1, 4, -1],\n#                     [0, -1, 0]])\n# # Emboss MB\n# identity =  np.array([[-1, -1, 0],\n#                      [-1,  1, 1],\n#                      [ 0,  1, 1]])\n\ntest = np.dot(images_agg,identity)\n\n# Let's take a look at some samples first. \nvisualize(test,16)","fdd1403b":"separator=0.5\nvisualize(to_black_white(test,separator),len(to_black_white(test, separator))) # embos with 0.5 #edge detection 1 with 0.5","e8f46f6e":"##### Learning with validation to fecth the architecture","56998540":"#### Loss visualization","e1d0126f":"#### Modelling #1","514c1e08":"#### Learning with validation to fecth the architecture","b5db004b":"## MODELLING ONLY BASIC IMAGES","74cf5322":"#### Data transformation","3f5fb21b":"##### Learning with validation to fecth the architecture","db797845":"#### Learning with validation to fecth the architecture","3596e343":"#### Modelling #2","c16eda14":"#### Learning on the whole data","9826c3be":"#### Learning on the whole data","9cbf48d1":"## Some functions and variables needed","d919bffd":"## Make prediction","0956996b":"##### Learning on the whole data","7c4ef738":"### Make noise","8548d036":"##### Loss visualization","fa924907":"###### It seems that leraning on data added with noisy images looks great!","9ee2557c":"##### Learning on the whole data","762d633d":"### Modelling #2","60294be8":"##### Loss visualization","bc75bb8d":"## MODELLING NOISED IMAGES","b2649cf0":"#### Loss visualization","fce4db7a":"### Data transformation","70b8000f":"### Modelling #1","10c46c39":"## Extra info about data","9a661b6c":"## MODELLING FILTERED IMAGES (In progress, not ready yet)"}}