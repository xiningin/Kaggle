{"cell_type":{"40073d35":"code","4717957b":"code","32b47c37":"code","6d5352df":"code","cb4152e6":"code","a3e6f1b9":"code","456befb9":"code","4acecc85":"code","67cbf5e0":"code","98c2b946":"code","f081da47":"code","46fe1e3a":"code","d4653f56":"code","337ca43d":"code","60ce88f6":"code","008bcd0e":"code","fffd3dca":"code","02d5e011":"code","dd04e352":"code","c07ee196":"code","d6c96fdf":"code","c7c3046a":"markdown","d10aa8dd":"markdown","4e62cd7e":"markdown","5d94cf26":"markdown","07b4234b":"markdown"},"source":{"40073d35":"!pip install timm","4717957b":"import math\nimport random\nimport time\nimport warnings\nimport os\nimport numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport transformers as T\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom torch.utils.data import DataLoader, Dataset\nfrom tqdm.notebook import tqdm\n\nimport torch\nimport torch.nn as nn\nimport pandas as pd\nimport torchvision.models as models\nimport timm\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.cuda.manual_seed_all(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed = 2021\nseed_torch(seed)","32b47c37":"train_df = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/petfinder-pawpularity-score\/test.csv')\n","6d5352df":"class Create_Model(nn.Module):\n    def __init__(self):\n        super(Create_Model,self).__init__()\n        self.swin = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True,num_classes=0, in_chans=3)\n        num_features = self.swin.num_features\n        self.fc = nn.Sequential(\n            nn.Dropout(0.5), nn.Linear(num_features, 1)\n        )\n    def forward(self,x,xx):\n        x = self.swin(x)\n        x = self.fc(x)\n        return x","cb4152e6":"import torch.nn.functional as F\nimport torchvision.models as models\nclass Pawpularity_Net(nn.Module):\n    def __init__(self):\n        super(Pawpularity_Net , self).__init__()\n        self.model = timm.create_model('swin_tiny_patch4_window7_224', pretrained=True,num_classes=0, in_chans=3)\n        num_features = self.model.num_features\n        #self.model   = nn.Sequential(*list(model.children())[:-1])\n        #self.layer_1 = nn.Linear(12,100)\n        #self.bn1     = nn.BatchNorm1d(100)\n        #self.layer_2 = nn.Linear(100,100)\n        #self.bn2     = nn.BatchNorm1d(100)\n        #self.layer_3 = nn.Linear(2148 , 500)\n        #self.bn3     = nn.BatchNorm1d(500)\n        self.last_layer = nn.Linear(num_features, 1)\n    \n    def forward(self,x1,x2):\n        x1 = self.model(x1)\n        #x1 = x1.view(x1.shape[0],-1)\n        #x2 = F.relu(self.layer_1(x2))\n        #x2 = F.relu(self.layer_2(x2))\n        #x = torch.cat([x1,x2],dim = 1)\n        #x = F.relu(self.layer_3(x))\n        #x = self.last_layer(x)\n        x = self.last_layer(F.relu(x1))\n        \n        return x","a3e6f1b9":"from torch.utils.data import DataLoader, Dataset\nfrom PIL import Image \nimport torchvision.transforms as T\nfrom tqdm import tqdm\n\ndef get_transforms(key):\n    transforms = {'train':T.Compose([\n                            T.RandomHorizontalFlip(),\n                            T.RandomVerticalFlip(),\n                            T.RandomAffine(15, translate=(0.1, 0.1), scale=(0.9, 1.1)),\n                            T.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1),\n                            T.Resize(256),\n                            T.CenterCrop(224),\n                            T.ToTensor(),\n                            T.Normalize(\n                                mean=[0.485, 0.456, 0.406],\n                                std=[0.229, 0.224, 0.225])\n                            ]),\n                           'val':T.Compose([\n                            T.Resize(256),\n                            T.CenterCrop(224),\n                            T.ToTensor(),\n                            T.Normalize(\n                                mean=[0.485, 0.456, 0.406],\n                                std=[0.229, 0.224, 0.225])\n                            ])}\n    \n    return transforms[key]\n\n\n\n        \nclass CustomDataSet(Dataset):\n    def __init__(self,df,img_pth,is_test=False,now = 'val'):\n        self.img_list =  torch.load(img_pth)\n        self.table_list = df[df.columns[1:13]]\n        self.label_list = df[df.columns[-1]].to_list()\n        self.preprocess = get_transforms(now)\n        self.is_test = is_test\n        \n\n            \n    def __getitem__(self,idx):\n        \n        #if self.is_test is not True:\n        #    path = \"\/kaggle\/input\/petfinder-pawpularity-score\/train\/\"+self.img_list[idx]+'.jpg'\n        #else:\n        #    path = \"\/kaggle\/input\/petfinder-pawpularity-score\/test\/\"+self.img_list[idx]+'.jpg'\n        t1 = time.time()\n        #img = Image.open(path).convert('RGB')\n        img = self.img_list[idx]\n        t2 = time.time()\n        #print(f'\u8aad\u307f\u51fa\u3057:{t2 - t1}')\n        read_time = t2 - t1\n        t1 = time.time()\n        \n        #img = self.preprocess(img)\n        t2 = time.time()\n        \n        \n        #print(f'\u5909\u63db:{t2 - t1}')\n        trans_time = t2 - t1\n        \n        t1 = time.time()\n        tbl = torch.tensor(list(self.table_list.iloc[idx])).to(torch.float32)\n        t2 = time.time()\n        \n        tbl_time = t2 - t1\n        \n        #print(f'\u30c6\u30fc\u30d6\u30eb\u5909\u63db:{t2 - t1}')\n        t1 = time.time()\n        label = torch.tensor(self.label_list[idx]\/100).to(torch.float32)\n        t2 = time.time()\n        #print(f'\u30e9\u30d9\u30eb:{t2 - t1}')\n        label_time = t2 - t1\n        \n        sum_time = read_time + trans_time + tbl_time + label_time\n        \n        #print(f'\u753b\u50cf\u8aad\u307f\u51fa\u3057\uff1a{read_time\/sum_time*100} \u753b\u50cf\u5909\u63db:{trans_time\/sum_time*100} \u30c6\u30fc\u30d6\u30eb\u5909\u63db:{tbl_time\/sum_time*100} \u30e9\u30d9\u30eb\u5909\u63db:{label_time\/sum_time*100} \u5408\u8a08\u6642\u9593:{sum_time}')\n        \n        if self.is_test is not True:\n            return img,tbl,label\n        else:\n            return img,tbl\n    def __len__(self):\n        return len(self.img_list)\n\n    def __del__(self):\n        del self.img_list \n        del self.table_list\n        del self.label_list\n        del self.preprocess\n        del self.is_test \n    ","456befb9":"def get_img_list(img_list,types='train'):\n    preprocess = get_transforms('val')\n    print('make dataset...')\n    tensor_block = [preprocess(Image.open(f\"\/kaggle\/input\/petfinder-pawpularity-score\/{types}\/\"+img_list[i]+'.jpg').convert('RGB')) for i in range(len(img_list))]\n    \n    return tensor_block\n    \n            ","4acecc85":"FOLD_NUM = 5","67cbf5e0":"\nfrom sklearn.model_selection import KFold\nimport torch.optim as opt\nimport numpy as np\nimport time\nimport gc\n\nkf = KFold(n_splits=FOLD_NUM, random_state=None, shuffle=False)\n\nBATCH_SIZE = 96\nEPOCH = 50\nDEVICE = 'cuda'\nSTOP_NUM = 3\ncriterion_mse = nn.MSELoss()\ncriterion_bce = nn.BCEWithLogitsLoss()\n\nval_dataset = None\ntrain_dataset = None\ntrain_loader = None\nval_loader = None\ndel train_dataset\ndel val_dataset\ndel train_loader\ndel val_loader\n\ngc.collect()\n\nfor k,(train_index, test_index) in enumerate(kf.split(train_df['Id'])):\n    print(f\"========={k+1}-FOLD=========\")\n    model = Create_Model().to(DEVICE)\n    val_dataset = None\n    train_dataset = None\n    train_loader = None\n    val_loader = None\n    \n    train_dataset = CustomDataSet(train_df.loc[train_index],f\"..\/input\/petfinder-fold-dataset\/{k+1}_fold_train.pth\")\n    val_dataset = CustomDataSet(train_df.loc[test_index],f\"..\/input\/petfinder-fold-dataset\/{k+1}_fold_val.pth\")\n    train_loader = DataLoader(train_dataset,batch_size = BATCH_SIZE,shuffle = True,num_workers = 8)\n    val_loader = DataLoader(val_dataset,batch_size = BATCH_SIZE,shuffle = False,num_workers = 8)\n   \n\n    \n    optimizer = opt.AdamW(params = model.parameters(),lr = 1e-5)\n    scheduler = opt.lr_scheduler.CosineAnnealingWarmRestarts(optimizer , 100 , eta_min=1e-4)\n    best_loss = 99999\n    stop_counter = 0\n    \n    for e in range(EPOCH):\n        model.train()\n        train_total_loss = 0\n        train_score = 0\n        counter = 0\n        \n        for n,(img,tbl,label) in enumerate(train_loader):\n            img = img.to(DEVICE)\n            tbl = tbl.to(DEVICE)\n            label = label.to(DEVICE)\n            optimizer.zero_grad()\n            \n            output = model(img,tbl)[:,0]\n            \n            loss = criterion_bce(output , label)\n            score = criterion_mse(F.sigmoid(output)*100 , label*100).detach()\n            \n            \n            train_total_loss = (train_total_loss * n + loss.detach().item())\/(n+1)\n            train_score =  (train_score * counter + score.item()*output.shape[0])\/(counter + output.shape[0])\n            \n            counter += output.shape[0]\n            loss.backward()\n            optimizer.step()\n            print('\\rTRAIN EPOCH[{:03}\/{:03}] ITR[{:04}\/{:04}] LOSS:{:.5} SCORE:{:.5}'.format(e+1,EPOCH,n+1,len(train_loader),train_total_loss,np.sqrt(train_score)),end = \"\")\n        scheduler.step()\n        print()\n        val_total_loss = 0\n        val_score = 0\n        counter = 0\n        model.eval()\n        with torch.no_grad():\n            for n,(img,tbl,label) in enumerate(val_loader):\n                img = img.to(DEVICE)\n                tbl = tbl.to(DEVICE)\n                label = label.to(DEVICE)\n            \n                output = model(img,tbl)[:,0]\n\n                loss = criterion_bce(output , label)\n                score = criterion_mse(F.sigmoid(output)*100 , label*100).detach()\n                \n                \n                val_total_loss = (val_total_loss * n + loss.item())\/(n+1)\n                \n                val_score =  (val_score * counter + score.item()*output.shape[0])\/(counter + output.shape[0])\n                \n                counter += output.shape[0]\n                print('\\rVAL   EPOCH[{:03}\/{:03}] ITR[{:04}\/{:04}] LOSS:{:.5} SCORE:{:.5}'.format(e+1,EPOCH,n+1,len(val_loader),val_total_loss,np.sqrt(val_score)),end = \"\")\n        print()\n        if(best_loss > val_total_loss):\n            best_loss = val_total_loss\n            model_path = f'{k+1}-fold.pth'\n            torch.save(model.state_dict(), model_path)\n            stop_counter = 0\n        else:\n            stop_counter += 1\n        if stop_counter >= STOP_NUM:\n            break\n    \n    del train_dataset\n    del val_dataset\n    del train_loader\n    del val_loader\n    \n    gc.collect()","98c2b946":"import sys\n\nprint(\"{}{: >25}{}{: >10}{}\".format('|','Variable Name','|','Memory','|'))\nprint(\" ------------------------------------ \")\nfor var_name in dir():\n    if not var_name.startswith(\"_\"):\n        print(\"{}{: >25}{}{: >10}{}\".format('|',var_name,'|',sys.getsizeof(eval(var_name)),'|'))\ngc.collect()","f081da47":"train_dataset = None\nval_dataset = None","46fe1e3a":"\"\"\"\ntest_dataset = CustomDataSet(test_df,is_test = True)\ntest_loader = DataLoader(test_dataset,batch_size = 2,shuffle = False)\nwith torch.no_grad():\n    fold_output = [[] for x in range(FOLD_NUM)]\n    for k in range(FOLD_NUM):\n        model = Pawpularity_Net().to(DEVICE)\n        model_path = f'{k+1}-fold.pth'\n        model.load_state_dict(torch.load(model_path))\n        for n,(img,tbl) in enumerate(test_loader):\n            img = img.to(DEVICE)\n            tbl = tbl.to(DEVICE)\n            output = model(img,tbl).cpu()[:,0]\n            fold_output[k].append(F.sigmoid(output)*100)\n            print('\\r TEST FOLD[{:02}\/{:02}]  ITR[{:03}\/{:03}]'.format(k+1,FOLD_NUM,n+1,len(test_loader)),end = \"\")\n\"\"\"","d4653f56":"\"\"\"\nfor k in range(len(fold_output)):\n    fold_output[k] = torch.cat(fold_output[k],dim = 0).numpy()\n\"\"\"","337ca43d":"#list(np.mean(np.array(fold_output),axis = 0))","60ce88f6":"#df_result = pd.DataFrame({f'Pawpularity_{i}':fold_output[i] for i in range(len(fold_output))})","008bcd0e":"#df_result","fffd3dca":"#df_sub = pd.concat([train_df['Id'] , df_result],axis=1)","02d5e011":"#df_sub.to_csv('submission.csv', index=False)","dd04e352":"\"\"\"\nfrom sklearn.model_selection import KFold\nimport torch.optim as opt\nimport numpy as np\n\n\nkf = KFold(n_splits=FOLD_NUM, random_state=None, shuffle=False)\n\nBATCH_SIZE = 256\nEPOCH = 5\nDEVICE = 'cuda'\n\n\ntest_dataset = CustomDataSet(train_df)\ntest_loader = DataLoader(test_dataset,batch_size = BATCH_SIZE,shuffle = False,num_workers=2)\nwith torch.no_grad():\n    fold_output = [[] for x in range(FOLD_NUM)]\n    for k in range(FOLD_NUM):\n        model = Pawpularity_Net().to(DEVICE)\n        model_path = f'..\/input\/bceleaningresult\/{k+1}-fold.pth'\n        model.load_state_dict(torch.load(model_path))\n        for n,(img,tbl,label) in enumerate(test_loader):\n            img = img.to(DEVICE)\n            tbl = tbl.to(DEVICE)\n            output = model(img,tbl).cpu()[:,0]\n            fold_output[k].append(F.sigmoid(output)*100)\n            print('\\r TEST FOLD[{:02}\/{:02}]  ITR[{:03}\/{:03}]'.format(k+1,FOLD_NUM,n+1,len(test_loader)),end = \"\")\n\"\"\"","c07ee196":"\"\"\"\nfrom sklearn.model_selection import KFold\nimport torch.optim as opt\nimport numpy as np\nfrom tqdm import tqdm\nimport time\n\nFOLD_NUM = 5\nBATCH_SIZE = 32\nEPOCH = 5\nDEVICE = 'cuda'\nkf = KFold(n_splits=FOLD_NUM, random_state=None, shuffle=False)\n\n\ncriterion_mse = nn.MSELoss(reduction = 'mean' )\ncriterion_bce = nn.BCEWithLogitsLoss()\n\nfor k,(train_index, test_index) in enumerate(kf.split(train_df['Id'])):\n    train_dataset = CustomDataSet(train_df.loc[train_index])\n    train_loader = DataLoader(train_dataset,batch_size = BATCH_SIZE,shuffle = True,num_workers=2)\n    print(f\"========={k}-FOLD=========len:{len(train_loader)}\")\n    print(f\"Datanum:{BATCH_SIZE*len(train_loader)}\")\n    start = time.time()\n    for n,(img,tbl,label) in enumerate(tqdm(train_loader)):\n        pass\n    end = time.time()\n    print(end -start)\n\"\"\"","d6c96fdf":"#torch.load(\"..\/input\/petfinder-fold-dataset\/1_fold_train.pth\")","c7c3046a":"## \u640d\u5931\u95a2\u6570\u3092MSELoss\u304b\u3089nn.BCEWithLogitsLoss\u306b\u5909\u66f4\n\u6700\u5f37\u3089\u3057\u3044","d10aa8dd":"## Model\u306e\u69cb\u7bc9\nResNet\u3092\u57fa\u790e\u3068\u3057\u3066\u5229\u7528","4e62cd7e":"## DatasetLoader\u306e\u901f\u5ea6\u78ba\u8a8d","5d94cf26":"## Train\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u4e88\u6e2c\u7d50\u679c\u3092\u51fa\u529b","07b4234b":"# CNN\u3068\u8868\u3092\u7d44\u307f\u5408\u308f\u305b\u3066\u8003\u3048\u3089\u308c\u306a\u3044\u304b\uff1f\n\nMobileNet\u3068\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u3092\u6700\u5f8c\u306e\u5c64\u3067\u7d50\u5408\u3059\u308b\u3053\u3068\u3067\u554f\u984c\u306e\u89e3\u7b54\u3092\u5b9f\u73fe\u3059\u308b\u8a66\u307f"}}