{"cell_type":{"44cb48b9":"code","ef8a6578":"code","1314bf90":"code","8444575d":"code","c00e60a5":"code","e46aad35":"code","5ea203a3":"code","0fccd046":"code","935a6d6d":"code","c4c6f5e4":"code","25cbf785":"code","4393c6e9":"code","f3fb68c0":"code","4ccce43f":"code","d15f23aa":"code","dd39070c":"code","92bba21e":"code","d849d792":"code","020594a9":"code","9aa7fb8d":"code","85eed99c":"code","2e37a600":"code","fa34381f":"markdown","4335bf1f":"markdown","7310da9f":"markdown","fa15afc5":"markdown","ecb18ea6":"markdown","c2e5e577":"markdown","08a3c717":"markdown","799d645a":"markdown","76700249":"markdown"},"source":{"44cb48b9":"import numpy as np\nimport pandas as pd\nimport sklearn\nimport nltk","ef8a6578":"csv = pd.read_csv('..\/input\/sms-spam-collection-dataset\/spam.csv', encoding=\"ISO-8859-1\")\ndf = pd.DataFrame(csv)","1314bf90":"# check class distribution\nclasses = df[df.columns[0]]\nprint(classes.value_counts())","8444575d":"# convert class labels to binary values, 0 = ham  1 = spam\n\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\nY = encoder.fit_transform(classes)\n\n# quick check\nprint(classes[:10])\nprint(Y[:10])","c00e60a5":"# store SMS message data\ntext_messages = df[df.columns[1]]\nprint(text_messages[:10])","e46aad35":"# expressions can be found at https:\/\/regexlib.com\/\n# use regular expressions to replace email addresses, urls, phone numbers, etc.\n\n# replace email addresses with 'emailaddr\nprocessed = text_messages.str.replace(r'^\\w+@[a-zA-Z_]+?\\.[a-zA-Z]{2,3}$', 'emailaddr')\n\n# replace urls with 'webaddress'\nprocessed = processed.str.replace(r'^http\\:\/\/[a-zA-Z0-9\\-\\.]+\\.[a-zA-Z]{2,3}(\/\\S*)?$','webaddress')\n# replace money symbols with 'moneysymb'\nprocessed = text_messages.str.replace(r'\u00a3|\\$', 'moneysymb')\n\n# replace 10 digit phone numbers with 'phonenum'\nprocessed = text_messages.str.replace(r'^[2-9]\\d{2}-\\d{3}-\\d{4}$', 'phonenum')\n\n# replace normal numbers with 'num'\nprocessed = text_messages.str.replace(r'\\d+(\\.\\d+)?', 'num')","5ea203a3":"# remove punctuation\nprocessed = processed.str.replace(r'[^\\w\\d\\s]', ' ')\n\n# replace whitespace between terms with a single space\nprocessed = processed.str.replace(r'\\s+', ' ')\n\n# remove leading and trailing whitespace\nprocessed = processed.str.replace(r'^\\s+|\\s+?$', '')","0fccd046":"# change all words to lower case\nprocessed = processed.str.lower()\nprocessed.head()","935a6d6d":"from nltk.corpus import stopwords\n\n# remove stop words from text messages\n# stop words are basically a set of commonly used words in any language such as i, me, to, it, etc.\n\nstop_words = set(stopwords.words('english'))\n\nprocessed = processed.apply(lambda x: ' '.join(\n    term for term in x.split() if term not in stop_words))","c4c6f5e4":"# remove word stems using a Porter stemmer\n# stemming is the process of reducing a word to its word stem such as removing -ing\nps = nltk.PorterStemmer()\n\nprocessed = processed.apply(lambda x: ' '.join(\n    ps.stem(term) for term in x.split()))\n\nprocessed.head()","25cbf785":"from nltk.tokenize import word_tokenize\n\n# create bag-of-words\nall_words = []\n\nfor message in processed:\n    words = word_tokenize(message)\n    for w in words:\n        all_words.append(w)\n\n# FreqDist class is used to encode \u201cfrequency distributions\u201d, which count the number of times that each outcome of an experiment occurs\n\nall_words = nltk.FreqDist(all_words)","4393c6e9":"# print the total number of words and the 15 most common words\nprint('Number of words: {}'.format(len(all_words)))\nprint('Most common words: {}'.format(all_words.most_common(10)))","f3fb68c0":"# use the 1500 most common words as features\nword_features = list(all_words.keys())[:1500]","4ccce43f":"# find_features function will determine which of the 1500 word features are contained in the email\/message\ndef find_features(message):\n    words = word_tokenize(message)\n    features = {}\n    for word in word_features:\n        features[word] = (word in words)\n\n    return features\n\n# example\nfeatures = find_features(processed[0])\nfor key, value in features.items():\n    if value == True:\n        print(key)","d15f23aa":"# do it for all the messages\nmessages = list(zip(processed, Y))\n\n# define a seed for reproducibility\nseed = 1\nnp.random.seed = seed\nnp.random.shuffle(messages)\n\n# call find_features function for each SMS message\nfeaturesets = [(find_features(text), label) for (text, label) in messages]","dd39070c":"from sklearn import model_selection\n\n# split the data into training and testing datasets\ntraining, testing = model_selection.train_test_split(featuresets, test_size = 0.25, random_state=seed)","92bba21e":"print('Training:',len(training))\nprint('Testing:',len(testing))","d849d792":"from nltk.classify.scikitlearn import SklearnClassifier\nfrom sklearn.svm import SVC\n\nmodel = SklearnClassifier(SVC(kernel = 'linear'))\n\n# train the model on the training data\nmodel.train(training)\n\n# and test on the testing dataset!\naccuracy = nltk.classify.accuracy(model, testing)*100\nprint(\"SVC Accuracy: {}\".format(accuracy))","020594a9":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\n# define models to train\nnames = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\"]\n\nclassifiers = [\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    LogisticRegression()\n]\n\nmodels = zip(names, classifiers)\n\nfor name, model in models:\n    nltk_model = SklearnClassifier(model)\n    nltk_model.train(training)\n    accuracy = nltk.classify.accuracy(nltk_model, testing)*100\n    print(\"{} Accuracy: {}\".format(name, accuracy))","9aa7fb8d":"# ensemble methods - Voting classifier\nfrom sklearn.ensemble import VotingClassifier\n\nnames = [\"K Nearest Neighbors\", \"Decision Tree\", \"Random Forest\", \"Logistic Regression\"]\n\nclassifiers = [\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    LogisticRegression()\n]\n\nmodels = list(zip(names, classifiers))\n\nnltk_ensemble = SklearnClassifier(VotingClassifier(estimators = models, voting = 'hard', n_jobs = -1))\nnltk_ensemble.train(training)\naccuracy = nltk.classify.accuracy(nltk_model, testing)*100\nprint(\"Voting Classifier: Accuracy: {}\".format(accuracy))","85eed99c":"# class label prediction for testing set\ntxt_features, labels = zip(*testing)\n\nprediction = nltk_ensemble.classify_many(txt_features)","2e37a600":"# print a confusion matrix and a classification report\nprint(classification_report(labels, prediction))\n\npd.DataFrame(\n    confusion_matrix(labels, prediction),\n    index = [['actual', 'actual'], ['ham', 'spam']],\n    columns = [['predicted', 'predicted'], ['ham', 'spam']])","fa34381f":"## Import Data","4335bf1f":"Data exploration\/data cleaning","7310da9f":"## Import Libraries","fa15afc5":"# Spam Classification using NLP","ecb18ea6":"The above words are key words that were saved as apart of the features (aka most common words) list that were found in the very first message.","c2e5e577":"Split data into testing and training sets.","08a3c717":"## Algorithms\n## Scikit-Learn Classifiers with NLTK","799d645a":"## Preprocess the Data","76700249":"## Tokenization"}}