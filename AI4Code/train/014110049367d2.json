{"cell_type":{"3b4e4677":"code","1f865879":"code","54002619":"code","eabff62e":"code","014ac0e0":"code","c6c98d5d":"code","0f478b69":"code","1d0fccb8":"code","67af296e":"code","ed2d0316":"code","a2b016b7":"code","f9c85f80":"code","5fe48a52":"markdown","9910d6db":"markdown","cdfa9f04":"markdown","8d129ff1":"markdown","c6d9f9eb":"markdown","635d9bde":"markdown","fbc08920":"markdown","21c254e7":"markdown","6b093c1b":"markdown"},"source":{"3b4e4677":"import os\nimport numpy as np\nimport pandas as pd\nimport tensorflow as tf\nfrom scipy.io import loadmat\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(\"ignore\")","1f865879":"mnist_train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nmnist_test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","54002619":"labels = mnist_train[\"label\"]\nfeatures = mnist_train.drop(labels = [\"label\"],axis = 1)","eabff62e":"features = features\/255.0\nmnist_test = mnist_test\/255.0","014ac0e0":"features = features.values.reshape(-1,28,28,1)\nmnist_test = mnist_test.values.reshape(-1,28,28,1)\nlabels = to_categorical(labels, num_classes=10)","c6c98d5d":"mnist_test.shape","0f478b69":"labels.shape","1d0fccb8":"def _bytes_feature(value):\n    if isinstance(value, type(tf.constant(0))): # if value ist tensor\n        value = value.numpy() # get value of tensor\n    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n\ndef _float_feature(value):\n    return tf.train.Feature(float_list=tf.train.FloatList(value=[value]))\n\ndef _int64_feature(value):\n    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n\ndef serialize_array(array):\n    array = tf.io.serialize_tensor(array)\n    return array","67af296e":"def parse_single_image(image, label=None):\n    if label is None:\n            data = {\n                'height' : _int64_feature(image.shape[0]),\n                'width' : _int64_feature(image.shape[1]),\n                'depth' : _int64_feature(image.shape[2]),\n                'raw_image' : _bytes_feature(serialize_array(image))\n    }\n    else:\n        data = {\n                'height' : _int64_feature(image.shape[0]),\n                'width' : _int64_feature(image.shape[1]),\n                'depth' : _int64_feature(image.shape[2]),\n                'raw_image' : _bytes_feature(serialize_array(image)),\n                'label' : _bytes_feature(serialize_array(label))\n        }\n    out = tf.train.Example(features=tf.train.Features(feature=data))\n\n    return out","ed2d0316":"def convert_to_tfr(images, labels=None, filename:str='images'):\n    filename = filename+'.tfrecords'\n    writer = tf.io.TFRecordWriter(filename)\n    count = 0 \n    \n    for index in range(len(images)):\n        if labels is None:\n            current_image = images[index]\n            out = parse_single_image(image = current_image)\n        else:\n            current_image = images[index]\n            current_label = labels[index]\n            out = parse_single_image(image = current_image, label = current_label)\n        writer.write(out.SerializeToString())\n        count +=1\n    writer.close()\n    print(f\"Wrote {count} elements to TFRecord\")","a2b016b7":"convert_to_tfr(features, labels, filename=\"train_data\")","f9c85f80":"convert_to_tfr(mnist_test, filename=\"test_data\")","5fe48a52":"## Normalize the dataset\n\nThe inputs with the large integer values can slow down the learning process,so it's a good practice to normalize the pixel values with values between 0 and 1.\n","9910d6db":"## Serializing and Writing \n\nNow, we'll create a dictionary to store the actual image, height, width and depth of the image and the label where we first serialize the array and then convert it to a bytes_feature.  All these `key:value` mappings make up the features for one Example.","cdfa9f04":"## What are TPUs?\nThe Tensor Processing Unit (TPU) is a custom integrated chip, designed specifically to accelerate the process of training machine learning models. \n\n## TPUs for free at Kaggle\n**You can use up to 30 hours per week of TPUs and up to 9h at a time in a single session.**\n**For more info you can visit [here](https:\/\/www.kaggle.com\/docs\/tpu).**\n\n## Why do we need TFRecord format?\nThe TFRecord format is tensorflow's custom data format which is simple for storing a sequence of binary records. The advantages of using TFRecords are amazingly more efficient storage, fast I\/O, self-contained files, etc. The main advantage of TPUs are faster I\/O which results in faster model training.\n\nFor understanding the basics of TFRecords, please visit Ryan Holbrook notebook: [TFRecords Basics](https:\/\/www.kaggle.com\/ryanholbrook\/tfrecords-basics).\n\n## Useful resources which helped me:\n* https:\/\/www.tensorflow.org\/tutorials\/load_data\/tfrecord\n* https:\/\/www.kaggle.com\/mgornergoogle\/five-flowers-with-keras-and-xception-on-tpu\n* https:\/\/towardsdatascience.com\/a-practical-guide-to-tfrecords-584536bc786c\n* https:\/\/cloud.google.com\/blog\/products\/ai-machine-learning\/what-makes-tpus-fine-tuned-for-deep-learning\n* https:\/\/pub.towardsai.net\/writing-tfrecord-files-the-right-way-7c3cee3d7b12\n\n**In this notebook you will learn how to convert private dataset into TFRecord format.**","8d129ff1":"## Feature Creation functions\n\nThe following functions can be used to convert a value to a type compatible which takes a scalar input values and returns a tf.train.Feature.","c6d9f9eb":"## Writing to the TFRecord files\n\nThis function write our dataset to the TFRecord files using the `TFRecordWriter`","635d9bde":"## Load the data\n\nWe'll be using MNIST dataset which consists of handwritten digits, 70,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image. \n\nIn this notebook, we'll be converting the [Digit Recognizer](https:\/\/www.kaggle.com\/c\/digit-recognizer) competition data, and will use it for model training using TPUs in the next notebook.","fbc08920":"Extracting the labels and features from the train dataset","21c254e7":"## Resize the dataset and one-hot encode labels\n\nBy using one-hot encoding, we are converting each categorical values into new categorical column with binary values of 1 or 0.","6b093c1b":"## Imports"}}