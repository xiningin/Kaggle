{"cell_type":{"662076a4":"code","8c98ef72":"code","bb6987c0":"code","50b17da0":"code","8dc28c48":"code","d5b6d91b":"code","5ae8fb9c":"code","05af9131":"code","e2a2c37e":"code","6d21d56d":"code","3955ee87":"code","f2dc21ed":"code","33c81f53":"code","f47ee1a8":"code","1409c7a5":"code","eea6bebc":"code","6b41c308":"code","75b7fcab":"code","f06d4416":"code","25b955e0":"code","4d081ee5":"code","0286dba8":"code","38089611":"code","dfa34173":"code","576a6139":"code","31c6f069":"code","08fb6d63":"markdown","ea6d9f33":"markdown","405cfe9f":"markdown","743acd68":"markdown","aa534f47":"markdown","054774d4":"markdown","5d54961f":"markdown","5ae0f4ef":"markdown","9280e404":"markdown","2bae6bc7":"markdown","da649d68":"markdown","8ac2faa1":"markdown","63d89794":"markdown","f08790e7":"markdown","008f8792":"markdown","23982fde":"markdown","17017388":"markdown","c00f8d7a":"markdown","fa7dab30":"markdown","904a5df9":"markdown"},"source":{"662076a4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8c98ef72":"from keras.layers import Input, Dense\nfrom keras.models import Model","bb6987c0":"encoding_dim = 32 # \u7de8\u78bc\u5668\u7dad\u5ea6\ninput_img = Input(shape=(784, ))\n# \u8f38\u5165\u7de8\u78bc\u8868\u793a\nencoded = Dense(encoding_dim, activation='relu')(input_img)\n# \u8f38\u5165\u7684\u6709\u640d\u91cd\u69cb\ndecoded = Dense(784, activation='sigmoid')(encoded)\n\nautoencoder = Model(input_img, decoded)","50b17da0":"autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\nautoencoder.summary()","8dc28c48":"from keras.datasets import mnist","d5b6d91b":"(x_train, _), (x_test, _) = mnist.load_data()","5ae8fb9c":"print(x_train.shape)\nprint(x_test.shape)","05af9131":"x_train = x_train.astype('float32')\nx_test = x_test.astype('float32')","e2a2c37e":"x_train \/= 255\nx_test \/= 255","6d21d56d":"autoencoder_x_train = x_train.reshape((len(x_train), np.prod(x_train.shape[1:])))\nautoencoder_x_test = x_test.reshape((len(x_test), np.prod(x_test.shape[1:])))\nprint(autoencoder_x_train.shape)\nprint(autoencoder_x_test.shape)","3955ee87":"cnn_autoencoder_x_train = np.reshape(x_train, (len(x_train),28, 28, 1))\ncnn_autoencoder_x_test = np.reshape(x_test, (len(x_test), 28, 28, 1))\nprint(cnn_autoencoder_x_train.shape)\nprint(cnn_autoencoder_x_test.shape)","f2dc21ed":"noise_factor = 0.5\nx_train_noisy = x_train + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_train.shape) \nx_test_noisy = x_test + noise_factor * np.random.normal(loc=0.0, scale=1.0, size=x_test.shape) \nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)\nprint(x_train_noisy.shape)\nprint(x_test_noisy.shape)","33c81f53":"autoencoder.fit(autoencoder_x_train, autoencoder_x_train, epochs = 50, batch_size = 256, shuffle = True, validation_data = (autoencoder_x_test, autoencoder_x_test))","f47ee1a8":"# \u63d0\u53d6\u7f16\u7801\u5c42\nencoder = Model(inputs = input_img, outputs = encoded)\nencoded_input = Input(shape=(encoding_dim, ))\n\n# \u63d0\u53d6\u89e3\u7801\u5c42\ndecoder_layer = autoencoder.layers[-1]\ndecoder = Model(inputs=encoded_input, outputs=decoder_layer(encoded_input))\n\nencoded_imgs = encoder.predict(autoencoder_x_test)\ndecoded_imgs = decoder.predict(encoded_imgs)","1409c7a5":"import matplotlib.pyplot as plt","eea6bebc":"n = 10  # \u6253\u5370\u7684\u56fe\u7247\u6570\u91cf\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    # \u663e\u793a\u539f\u6765\u56fe\u50cf\n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(autoencoder_x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n\n    # \u663e\u793a\u91cd\u6784\u540e\u7684\u56fe\u50cf\n    ax = plt.subplot(2, n, i + 1 + n)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","6b41c308":"from keras.layers import Input, Dense, Conv2D, MaxPooling2D, UpSampling2D\nfrom keras.models import Model\nfrom keras import backend as K","75b7fcab":"input_img = Input(shape=(28, 28, 1))  #\u8f93\u5165\u56fe\u50cf\u5f62\u72b6\n#\u7f16\u7801\u5668\nx = Conv2D(16, (3, 3), activation='relu', padding='same')(input_img)\n#\u5377\u79ef\u5c42\nx = MaxPooling2D((2, 2), padding='same')(x)#\u7a7a\u57df\u4e0b\u91c7\u6837\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)","f06d4416":"#\u89e3\u7801\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)#\u4e0a\u91c7\u6837\u5c42\nx = Conv2D(8, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(16, (3, 3), activation='relu')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)\nautoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')#\u7f16\u8bd1\nautoencoder.summary()","25b955e0":"autoencoder.fit(cnn_autoencoder_x_train, cnn_autoencoder_x_train,\n                epochs=50,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(cnn_autoencoder_x_test, cnn_autoencoder_x_test),)","4d081ee5":"cnn_decoded_imgs = autoencoder.predict(cnn_autoencoder_x_test)\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    \n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    \n    ax = plt.subplot(2, n, i + n + 1)\n    plt.imshow(cnn_decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","0286dba8":"n = 10\nplt.figure(figsize=(20, 2))\nfor i in range(n):\n    ax = plt.subplot(1, n, i+1)\n    plt.imshow(x_test_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","38089611":"input_img = Input(shape=(28, 28, 1)) \n\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(input_img)\nx = MaxPooling2D((2, 2), padding='same')(x)\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nencoded = MaxPooling2D((2, 2), padding='same')(x)\n\n\n\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(encoded)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(1, (3, 3), activation='sigmoid', padding='same')(x)\n\nautoencoder = Model(input_img, decoded)","dfa34173":"autoencoder.compile(optimizer='adadelta', loss='binary_crossentropy')\nautoencoder.summary()","576a6139":"autoencoder.fit(x_train_noisy, x_train,\n                epochs=100,\n                batch_size=128,\n                shuffle=True,\n                validation_data=(x_test_noisy, x_test),)","31c6f069":"decoded_imgs = autoencoder.predict(x_test)\n\nn = 10\nplt.figure(figsize=(20, 4))\nfor i in range(n):\n    \n    ax = plt.subplot(2, n, i + 1)\n    plt.imshow(x_test_noisy[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\n    \n    \n    ax = plt.subplot(2, n, i + n + 1)\n    plt.imshow(decoded_imgs[i].reshape(28, 28))\n    plt.gray()\n    ax.get_xaxis().set_visible(False)\n    ax.get_yaxis().set_visible(False)\nplt.show()","08fb6d63":"## \u6253\u5370\u5716\u7247","ea6d9f33":"## \u642d\u5efa\u81ea\u7de8\u78bc\u6a21\u578b","405cfe9f":"#### \u52a0\u5165\u566a\u8072\u7684\u6578\u64da","743acd68":"#### \u5377\u7a4d\u81ea\u52d5\u7de8\u78bc\u5668\u7684\u8f38\u5165","aa534f47":"### \u5c07\u6578\u64da\u8f49\u63db\u6210\u6d6e\u9ede\u6578","054774d4":"## \u7de8\u8b6f\u6a21\u578b\u4e26\u5370\u51fa\u6982\u8ff0","5d54961f":"## \u8a13\u7df4\u6a21\u578b","5ae0f4ef":"### \u91cd\u5851\u8cc7\u6599\n\n#### \u81ea\u52d5\u7de8\u78bc\u5668\u7684\u8f38\u5165","9280e404":"## \u7de8\u8b6f\u6a21\u578b\u4e26\u5370\u51fa\u6a21\u578b\u6982\u8ff0","2bae6bc7":"### \u628a\u539f\u56fe\u7247\u52a0\u5165\u9ad8\u65af\u566a\u58f0\n\n\u8f09\u5165\u6578\u64da\u96c6\u90a3\u584a\u5b9a\u7fa9\u4e86 `x_train_noisy`\uff0c\u5c07\u5716\u7247\u52a0\u5165\u9ad8\u65af\u566a\u8072\u3002","da649d68":"### \u6578\u64da\u6b63\u898f\u5316\n\n\u77e9\u9663\u88e1\u7684\u7070\u5ea6\u7528 0\\~255 \u7684\u6578\u5b57\u8868\u793a\uff0c\u70ba\u4e86\u65b9\u4fbf\u904b\u7b97\uff0c\u8981\u5c07\u7070\u5ea6\u6b78\u4e00\u5316\u6210 0\\~1 \u7684\u6578\u503c\u3002","8ac2faa1":"## \u91cd\u69cb\u8f38\u51fa\u548c\u539f\u672c\u5716\u50cf\u5c0d\u6bd4","63d89794":"## \u6784\u5efa\u81ea\u7f16\u7801\u5668","f08790e7":"## \u6253\u5370\u5716\u50cf","008f8792":"## \u8a13\u7df4\u53bb\u566a\u81ea\u52d5\u7de8\u78bc\u5668","23982fde":"## \u642d\u5efa\u5377\u79ef\u81ea\u7f16\u7801\u5668","17017388":"## \u6578\u64da\u9810\u8655\u7406","c00f8d7a":"## \u8a13\u7df4\u5377\u7a4d\u81ea\u7de8\u78bc\u5668\u6a21\u578b","fa7dab30":"## \u83b7\u5f97\u53bb\u566a\u81ea\u52a8\u7f16\u7801\u5668","904a5df9":"## \u8f09\u5165\u624b\u5beb\u5716\u7247\u6578\u64da\u96c6"}}