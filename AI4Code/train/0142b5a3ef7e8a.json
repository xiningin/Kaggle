{"cell_type":{"9fb58ade":"code","b93c0134":"code","4b83c2a8":"code","88c23c08":"code","debf6c67":"code","a8121a4a":"code","180b6c86":"code","8900a796":"code","9053fecd":"code","30314828":"code","bab4a4b9":"code","4f2c0322":"code","17226231":"code","69f48dc8":"code","9684c45f":"code","b313ef8c":"code","23593262":"code","632e290c":"code","953fe176":"code","edc58f9e":"code","bf32ddc0":"code","f8c64345":"code","de7eed1b":"code","7f9436ae":"markdown","2b854214":"markdown","23d20901":"markdown","52a63fa2":"markdown","8dbf26f0":"markdown","1c76db3d":"markdown","144e2a0f":"markdown","422b5aa8":"markdown","50617fc7":"markdown","0e35216d":"markdown","ace38d97":"markdown","151ce4ba":"markdown","c10902d6":"markdown"},"source":{"9fb58ade":"import spacy\nfrom spacy import displacy\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.svm import LinearSVC\nimport string\n# Importing Dataset from the Github Repository.\n!git clone https:\/\/github.com\/laxmimerit\/NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset","b93c0134":"# Loading Spacy small model as nlp\nnlp = spacy.load(\"en_core_web_sm\")","4b83c2a8":"# Gathering all the stopwords\nfrom spacy.lang.en.stop_words import STOP_WORDS\nstopwords = list(STOP_WORDS)\nprint(len(stopwords))","88c23c08":"# Loading yelp dataset\ndata_yelp = pd.read_csv('..\/working\/NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset\/datasets\/yelp_labelled.txt',\n                        sep='\\t', header= None)\ndata_yelp.head()","debf6c67":"# Adding column names to the dataframe\ncolumnName = ['Review','Sentiment']\ndata_yelp.columns = columnName\ndata_yelp.head()","a8121a4a":"print(data_yelp.shape)","180b6c86":"# Adding Amazon dataset and adding its column name\ndata_amz = pd.read_csv(\"..\/working\/NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset\/datasets\/amazon_cells_labelled.txt\",\n                        sep='\\t', header= None)\ndata_amz.columns = columnName\ndata_amz.head()","8900a796":"print(data_amz.shape)","9053fecd":"# Adding IMdB dataset and adding its column name\ndata_imdb = pd.read_csv(\"..\/working\/NLP-Tutorial-8---Sentiment-Classification-using-SpaCy-for-IMDB-and-Amazon-Review-Dataset\/datasets\/imdb_labelled.txt\",\n                        sep='\\t', header= None)\ndata_imdb.columns = columnName\ndata_imdb.head()","30314828":"print(data_imdb.shape)","bab4a4b9":"# Merging all the three dataframes\ndata = data_yelp.append([data_amz, data_imdb], ignore_index=True)\nprint(data.shape)","4f2c0322":"# Sentiment ditribution in the dataset\ndata.Sentiment.value_counts()","17226231":"# Getting information regarding the null entries in the dataset\ndata.isnull().sum()","69f48dc8":"punct = string.punctuation\nprint(punct)","9684c45f":"def dataCleaning(sentence):\n  doc = nlp(sentence)\n  tokens = []\n  for token in doc:\n    if token.lemma_ != '-PRON-':\n      temp = token.lemma_.lower().strip()\n    else:\n      temp = token.lower_\n    tokens.append(temp)\n  clean_tokens = []\n  for token in tokens:\n    if token not in punct and token not in stopwords:\n      clean_tokens.append(token)\n  return clean_tokens","b313ef8c":"dataCleaning(\"Today we are having heavy rainfall, We recommend you to stay at your home and be safe, Do not start running here and there\")\n# All the useful words are returned, no punctuations no stop words and in the lemmatized form","23593262":"# Spillting the train and test data\nX = data['Review']\ny = data['Sentiment']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2)\nprint(X_train.shape,y_test.shape)","632e290c":"# Creating the model and pipeline\ntfidf = TfidfVectorizer(tokenizer = dataCleaning)\nsvm = LinearSVC()\nsteps = [('tfidf',tfidf),('svm',svm)]\npipe = Pipeline(steps)","953fe176":"# Training the model\npipe.fit(X_train,y_train)","edc58f9e":"# Testing on the test dataset\ny_pred = pipe.predict(X_test)","bf32ddc0":"# Printing the classification report and the confusion matrix\nprint(classification_report(y_test,y_pred))\nprint(\"\\n\\n\")\nprint(confusion_matrix(y_test,y_pred))","f8c64345":"# Testing on random inputs\npipe.predict([\"Wow you are an amazing person\"])","de7eed1b":"pipe.predict([\"you suck\"])","7f9436ae":"## Gathering all the Stop words which does not convey much meaning in the Sentiment","2b854214":"### Footnotes\nhttps:\/\/towardsdatascience.com\/natural-language-processing-feature-engineering-using-tf-idf-e8b9d00e7e76\n\nhttps:\/\/towardsdatascience.com\/a-simple-example-of-pipeline-in-machine-learning-with-scikit-learn-e726ffbb6976\n","23d20901":"## Appending all the Datasets","52a63fa2":"## Loading SpaCy's small english model","8dbf26f0":"## Here after passing a particular sentence in dataCleaning method we are returned with relevant words which contribute to the sentiments","1c76db3d":"**Here '0' represent that input is negative sentiment**","144e2a0f":"To get more details regarding SpaCy models check here : https:\/\/spacy.io\/usage\/models","422b5aa8":"\n\n```\nHere in the reviews we will find many stop words which do not add any meaning to the review.\nAlso punctuations will be encountered in the review which which will be considered as a seperate token by our model\nSo removing all the stop words and punctuation so that our model can train efficiently\n```\n\n","50617fc7":"## Preparing Model","0e35216d":"**Here '1' represent that the input is positive sentiment**","ace38d97":"## Testing on the Random Manual Examples","151ce4ba":"### Importing Necessary Libraries\n\n","c10902d6":"## So here we can deduce that Sentiment 1 is Positive and 0 is negative"}}