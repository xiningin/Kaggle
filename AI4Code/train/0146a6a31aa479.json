{"cell_type":{"acae0fa7":"code","b0c40836":"code","d205f2a4":"code","69bf46c6":"code","4e3557f8":"code","37c78014":"code","3a0ae0d0":"code","a05b97d6":"code","e95a479e":"code","f4560e1c":"code","bf7461db":"code","a848d55f":"code","91fa0af8":"code","43bc7e96":"code","ad071c64":"code","9ca99a63":"code","04cce5a5":"code","4e0340c6":"code","2151a2d2":"code","91b49e8f":"markdown","48edb5a8":"markdown","eb1e2f0d":"markdown","460ca957":"markdown","8d91cfd0":"markdown","a84905ff":"markdown","130cffc0":"markdown","f1194be4":"markdown","60971db4":"markdown","6f9cd741":"markdown","28fa5733":"markdown","bbf17c83":"markdown","d6edb030":"markdown","a21b76ef":"markdown","c87521f0":"markdown","1b050614":"markdown","f4308169":"markdown","b19c1d15":"markdown","59d83cce":"markdown","2f687568":"markdown","70166411":"markdown","0de955b2":"markdown","6aaa6208":"markdown","08e1cff7":"markdown","30f44016":"markdown","8a4d8719":"markdown","62130ca9":"markdown","5e60c495":"markdown","309b9119":"markdown","94eeff13":"markdown","84cb47ed":"markdown","b8092ae8":"markdown","98748cdc":"markdown","cd59ce2c":"markdown","56a78c6e":"markdown"},"source":{"acae0fa7":"import warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nimport numpy as np\nimport pandas as pd\nfrom pandas.io.json import json_normalize\nfrom datetime import datetime\n\nimport json\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom plotly import tools\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly.offline as py\nimport plotly.graph_objs as go","b0c40836":"%%time\n\ndef load_df(csv_path='..\/input\/train_v2.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n    df = pd.DataFrame([])\n    for chunk in pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str'},\n                     chunksize=nrows):\n\n        chunk = chunk.drop(['customDimensions','hits'], axis=1)\n        df = df.append(chunk, ignore_index=True)\n        print(df.shape[0])\n    print(\"Dataframe assembled; Working on JSON columns...\")\n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    print(\"Done!\")\n    return df\n\ntrain = load_df('..\/input\/train_v2.csv', 100000)\ntrain[\"totals.transactionRevenue\"] = train[\"totals.transactionRevenue\"].astype('float')","d205f2a4":"print(\"Colunms in dataset: \" + str(train.shape[1]))\nprint(\"Rows in dataset: \" + str(train.shape[0]))\ntrain[:10]","69bf46c6":"na_counts = pd.DataFrame(train.isnull().sum())\nna_counts.columns = ['na_counts']\nna_counts['%na'] = round(na_counts['na_counts'] \/ train.shape[0], 4) * 100\nuniq_counts = pd.DataFrame(train.nunique(dropna=False))\nuniq_counts.columns = ['uniq_counts']\nna_uniq_counts = na_counts.join(uniq_counts, how='outer').sort_values(by='na_counts', ascending=False)\n\nprint(\"There are \"+str(len(na_uniq_counts.loc[na_uniq_counts[\"na_counts\"] > 0]))+\" columns with na values\")\nconst_cols = [c for c in train.columns if train[c].nunique(dropna=False)==1 ]\nprint(\"There are \"+str(len(const_cols))+\" colunms with only one unique value\")\n\nna_uniq_counts\n# train = train.drop(const_cols, axis=1)","4e3557f8":"plt.figure(figsize=[40,20])\n\nfontdict = {'fontsize': 30, 'fontweight' : 'bold'}\n\nplt.subplot(231)\nplt.scatter(range(train.shape[0]), np.sort(train['totals.transactionRevenue'].values))\nplt.title(\"Revenue Range\", fontdict=fontdict)\nplt.tick_params(axis='both', which='major', labelsize=10)\nplt.xlabel('')\nplt.ylabel('')\n\nplt.subplot(232)\nsns.distplot( np.log(train[train['totals.transactionRevenue'] > 0][\"totals.transactionRevenue\"]), bins=60, kde=True)\nplt.title(\"Distribution of Revenue\", fontdict=fontdict)\nplt.tick_params(axis='both', which='major', labelsize=10)\nplt.xlabel('')\nplt.ylabel('')\nplt.show()","37c78014":"print(\"In the dataset of \"+str(train.shape[0])+\" visits there are...\")\nprint(\"Number of unique visitors: \"+str(train[\"fullVisitorId\"].nunique()))\nprint(\"Presentage of visits that bought something: %\"+str(train.loc[train[\"totals.transactionRevenue\"] > 0].shape[0]\/train.shape[0]*100))\n\ntrain_first_visit = train.loc[train[\"visitNumber\"] == 1]\nprint(\"Percentage of visits that were for the first time: %\"+str(train_first_visit.shape[0]\/train.shape[0]*100))\nprint(\"Presentage of first time visitors that bought something: %\"+str(train_first_visit.loc[train_first_visit[\"totals.transactionRevenue\"] > 0].shape[0]\/train.shape[0]*100))","3a0ae0d0":"plt.figure(figsize=[20,16])\n\ndef create_countplot(column, title, plt_n, df=train, mean_ch = False):\n    labels = list(df[column].value_counts().index.unique())\n\n    fontdict = {'fontsize': 10, 'fontweight' : 'bold'}\n    plt.subplot(plt_n)\n    if mean_ch:\n        sns.barplot(x = column, y=\"totals.transactionRevenue\", data=df, order = labels[:10])\n    else:\n        sns.countplot(x = column, data=df, order = labels[:10])\n    plt.xticks(np.arange(0, len(labels[:10]), 1), labels, rotation=-80)\n    plt.title(title, fontdict=fontdict)\n    plt.tick_params(axis='both', which='major', labelsize=10)\n    plt.xlabel('')\n    plt.ylabel('')\n    \ncreate_countplot( 'device.deviceCategory', 'Device Used in Visits', 231)\ncreate_countplot( 'device.deviceCategory', 'Device Used in Visits with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_countplot( 'device.deviceCategory', 'Device Used in Visits with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)","a05b97d6":"plt.figure(figsize=[20,16])\n\ncreate_countplot( 'device.browser', 'Browser Used in Visits', 231)\ncreate_countplot( 'device.browser', 'Browser Used in Visits with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_countplot( 'device.browser', 'Browser Used in Visits with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)","e95a479e":"plt.figure(figsize=[20,16])\n\ncreate_countplot( 'device.operatingSystem', 'Operating System Used in Visits', 231)\ncreate_countplot( 'device.operatingSystem', 'Operating System Used in Visits with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_countplot( 'device.operatingSystem', 'Operating System Used in Visits with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)","f4560e1c":"plt.figure(figsize=[20,16])\n\ncreate_countplot( 'geoNetwork.networkDomain', 'Network Domain in Visits', 231)\ncreate_countplot( 'geoNetwork.networkDomain', 'Network Domain Used in Visits with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_countplot( 'geoNetwork.networkDomain', 'Network Domain in Visits with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)","bf7461db":"plt.figure(figsize=[20,16])\n\ncreate_countplot( 'geoNetwork.continent', 'Continent in Visits', 231)\ncreate_countplot( 'geoNetwork.continent', 'Continent in Visits with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_countplot( 'geoNetwork.continent', 'Continent in Visits with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)","a848d55f":"plt.figure(figsize=[20,16])\n\ncreate_countplot( 'geoNetwork.subContinent', 'Sub Continent in Visits', 231)\ncreate_countplot( 'geoNetwork.subContinent', 'Sub Continent in Visits with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_countplot( 'geoNetwork.subContinent', 'Sub Continent in Visits with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)","91fa0af8":"plt.figure(figsize=[20,16])\n\ncreate_countplot( 'trafficSource.source', 'Traffic Source in Visits', 231)\ncreate_countplot( 'trafficSource.source', 'Traffic Source in Visits with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_countplot( 'trafficSource.source', 'Traffic Source in Visits with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)","43bc7e96":"plt.figure(figsize=[20,16])\n\ncreate_countplot( 'trafficSource.medium', 'Traffic Medium in Visits', 231)\ncreate_countplot( 'trafficSource.medium', 'Traffic Medium in Visits with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_countplot( 'trafficSource.medium', 'Traffic Medium in Visits with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)","ad071c64":"def time_stamp_features(df):\n    df[\"date\"] = pd.to_datetime(df[\"date\"], format=\"%Y%m%d\") # seting the column as pandas datetime\n    df[\"weekday\"] = df['date'].dt.weekday #extracting week day\n    df[\"day\"] = df['date'].dt.day # extracting day\n    df[\"month\"] = df['date'].dt.month # extracting day\n    df[\"year\"] = df['date'].dt.year # extracting day\n    df[\"hour\"] = (df['visitStartTime'].apply(lambda x: str(datetime.fromtimestamp(x).hour))).astype(int)\n    return df\ntime_train = time_stamp_features(train)\np_time_train = time_train.loc[time_train[\"totals.transactionRevenue\"] > 0]\n\ndef create_timeplot(var, title, xlabel, ylabel, labels = []):\n    plt.figure(figsize=[40,16])\n    \n    df_count = time_train[var].value_counts().to_frame().reset_index().sort_values('index') \n    df_sum = df_count[var].sum()\n\n    sns.lineplot(x = \"index\", y = var, data = df_count, estimator=lambda x: x \/ df_sum * 100, label=\"%Visits\")\n\n    df_count = p_time_train[var].value_counts().to_frame().reset_index().sort_values('index')\n    df_sum = df_count[var].sum()\n\n    sns.lineplot(x = \"index\", y = var, data = df_count, color=\"Orange\", estimator=lambda x: x \/ df_sum * 100, label=\"%Visits with Purchase\")\n\n    fontdict = {'fontsize': 40, 'fontweight' : 'bold'}\n\n    plt.title(title, fontdict=fontdict)\n    plt.tick_params(axis='both', which='major', labelsize=30)\n    if labels != []:\n        plt.xticks(np.arange(0, len(labels), 1), labels)\n    plt.xlabel(xlabel, fontdict=fontdict)\n    plt.ylabel(ylabel, fontdict=fontdict)\n    plt.legend(fontsize=30)\n    plt.show()","9ca99a63":"create_timeplot(\"hour\",\"Visits by Hour of the Day\",\"Hour of the Day\", \"% of Visits\")","04cce5a5":"create_timeplot(\"date\",\"Visits by Date\",\"Date\", \"% of Visits\")","4e0340c6":"create_timeplot(\"weekday\",\"Visits by Weekday\",\"Weekday\", \"% of Visits\", [\"Monday\",\"Tuesday\",\"Wendsday\", \"Thursday\", \"Friday\", \"Saturday\", \"Sunday\"])","2151a2d2":"train['totals.pageviews'] = train['totals.pageviews'].astype(\"float\")\ntrain['totals.hits'] = train['totals.hits'].astype(\"float\")\n\nplt.figure(figsize=[20,16])\ndef create_viewplot(column, title, plt_n, df=train, mean_ch = False):\n    df = df.loc[df[column] <= 60].sort_values(column) \n    labels = np.arange(0, 60, step=5)\n    fontdict = {'fontsize': 10, 'fontweight' : 'bold'}\n    plt.subplot(plt_n)\n    if mean_ch:\n        sns.barplot(x = column, y=\"totals.transactionRevenue\", data=df)\n    else:\n        sns.countplot(x = column, data=df)\n    plt.xticks(np.arange(-1, 60, step=5),labels, rotation=-80)\n    plt.title(title, fontdict=fontdict)\n    plt.tick_params(axis='both', which='major', labelsize=10)\n    plt.xlabel('')\n    plt.ylabel('')\n\ncreate_viewplot( 'totals.pageviews', '# of Page Views in Visit', 231)\ncreate_viewplot( 'totals.pageviews', '# of Page Views in Visit with Purchase', 232, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_viewplot( 'totals.pageviews', '# of Page Views in Visit with Purchase (Mean)', 233, train.loc[train[\"totals.transactionRevenue\"] > 0], True)\n\ncreate_viewplot( 'totals.hits', '# of hits in Visit', 234)\ncreate_viewplot( 'totals.hits', '# of hits in Visit with Purchase', 235, train.loc[train[\"totals.transactionRevenue\"] > 0])\ncreate_viewplot( 'totals.hits', '# of hits in Visit with Purchase (Mean)', 236, train.loc[train[\"totals.transactionRevenue\"] > 0], True)\n\nplt.show()","91b49e8f":"# Continent: Exploration","48edb5a8":"# Transaction Revenue: Exploration","eb1e2f0d":"# Page Views and Hits: Exploration","460ca957":"# Operating System: Exploration","8d91cfd0":"## Traffic Medium: What We Learned\n\n- Unsurprisingly, organic traffic is very high. Since this traffic typically comes from search engines and Google owns the most popular one. \n\n- The high number of referral visits suggests social media success. Agian not that surpising considering Googles strong brand.","a84905ff":"#  Device Category: Exploration","130cffc0":"## Weekday: What We Learned\n\n- There are more visits and purchases on the site during weekdays and less on the weekends. This explains the wavey data in the visits by date chart.","f1194be4":"# Hour of the Day: Exploration","60971db4":"# Looking at Na\/Unique Values","6f9cd741":"## Weekday: What We Learned\n\n- The Page Views and Hits charts are all very similar and there are no real notable differences. This is likely because they are so strongly correlated with each other and only have slightly different meanings.\n\n- Purchase visits max around 15-20 page view\/hits and follow a right-skewed distribution.\n\n- While the means revenue graphs have some spikes throughout the charts, the low confidence rates and scattered occurrences suggest that this is likely just from small subsample sizes. \n\n- That being said, there might still be some evidence that single page\/hit visitors make larger purchases, on the rare chance that they do, since both means graphs show rather large spikes at 1 visit hits. This *might* be true because they might have been following direct links to the site and already had their purchase in mind with no interest in browsing.\n","28fa5733":"## Hour of the Day: What We Learned\n\n- Even though people visit the site from all over the world, there is a clear difference in visit at different times during the day. This is likely because the vast majority of visits and purchases are from america and the more active hours for the site are during the afternoon-night in america.\n\n- While both lines follow the same trend, the visits with purchase line is much more pronounced. Noting again that these lines follow american time zones, we can also infer that while people might still visit the site different hours of the day, few people seem less inclined to make purchases during late night\/early morning hours and are more likely to actually pull out their credit cards and make a purchase in the evening.\n","bbf17c83":"# Visitors: Exploration","d6edb030":"## Continent: What We Learned\n\n- Americas are the most likely visitors and overwhelmingly the most likely to make a purchase. In fact, almost every purchase was made in the Americas.\n\n- Despite the abnormal spike in africa mean purchase, that comparison is unusable due to the small subsample sizes of non-Americas purchases.\n","a21b76ef":"# Date: Exploration","c87521f0":"## Device Category: What We Learned\n\n- Most visits are from a desktop computer, next mobile phones and very few from tablets.\n\n- Desktop visits are also more likely to make a purchase and spend more when they do. This intuitively makes sense, as most people use their phones on the go and are more likely to be casually browsing perhaps even saving purchases for when they are at a computer.\n\n- While mobile visitor are more common, mobile and tablet visitors seem to have similar behavior. \n","1b050614":"# First Impressions","f4308169":"## Looking at Na\/Unique Values: What We Learned\n\n- There are 19 columns with only one unique value. These are worthless for data prediction and can be dropped immediatly. Some of these are due to the demo version of google analytics so might have value with the full version.\n\n- 18 columns have na values. Of these 10 are more than 95% na values.","b19c1d15":"# Date: What We Learned\n\n- The data has very clear regular waves for both Visits and Visits with Purchase. This is likely due to regular weekly tendencies in visitor behavior.\n\n- There are 2 anomalous spikes in the data: a blue one at the end of 2017 and an orange one around 2018-04. This is probably just noise since they are short blips unless there was some event, like a one day sale, that might have triggered them.\n","59d83cce":"## Traffic Source: What We Learned\n\n- Most visitors come from google, youtube.com, or a direct link.\n\n- visitors that followed a direct link were way more likely to make a purchase. In contrast, those that came from google were likely just browsing.\n\n- Surprisingly, despite a large portion of overall visitors coming by way of youtube.com, almost none of them made a purchase.\n","2f687568":"# Introduction\n\n### Competition Objective\n\n*In this competition, you\u2019re challenged to analyze a Google Merchandise Store (also known as GStore, where Google swag is sold) customer dataset to predict revenue per customer. Hopefully, the outcome will be more actionable operational changes and a better use of marketing budgets for those companies who choose to use data analysis on top of GA data.*\n\nThis is exploritory data analysis for the Google Analytics Customer Revenue Prediction Competion on Kaggle. The competition ended on November 30th 2018 and the results are evaluated on future data compiled between December 1st 2018 to January 31st 2019.","70166411":"# About in the Data\n\n### Data Fields\n\n**fullVisitorId** - A unique identifier for each user of the Google Merchandise Store.\n\n**channelGrouping** - The channel via which the user came to the Store.\n\n**date** - The date on which the user visited the Store.\n\n**device** - The specifications for the device used to access the Store. (JSON format)\n\n**geoNetwork** - This section contains information about the geography of the user. (JSON format)\n\n**socialEngagementType** - Engagement type, either \"Socially Engaged\" or \"Not Socially Engaged\".\n\n**totals** - This section contains aggregate values across the session. (JSON format)\n\n**trafficSource** - This section contains information about the Traffic Source from which the session originated. (JSON format)\n\n**visitId** - An identifier for this session. This is part of the value usually stored as the _utmb cookie. This is only unique to the user. For a completely unique ID, you should use a combination of fullVisitorId and visitId.\n\n**visitNumber** - The session number for this user. If this is the first session, then this is set to 1.\n\n**visitStartTime** - The timestamp (expressed as POSIX time).\n\n**hits** - This row and nested fields are populated for any and all types of hits. Provides a record of all page visits.\n\n**customDimensions** - This section contains any user-level or session-level custom dimensions that are set for a session. This is a repeated field and has an entry for each dimension that is set.\n\n**totals** - This set of columns mostly includes high-level aggregate data.\n\n\n### Timeframe\n\nThe training data we are using is from August 2016 to May 2018.\n\n### Size and Format\n\nThe version 2 of the training data is fairly large at ~1.7 million rows. While in a csv file, many of the columns are in JSON format. \n\n# Read in the Data\n\nThe 1.7 million rows will need to be read in chunks of 100K to not overload memory. **customDimensions** and **hits** columns are extremely large and don't help much in an EDA so they are dropped to save space.  The JSON format columns need to also be processed into additional columns. This block takes around 8 minutes to complete.","0de955b2":"# Weekday: Exploration","6aaa6208":"## Transaction Revenue: What We Learned\n\n- The vast majority of visits had no revenue. In other words, no items were purchased during those visits.\n\n- The distribution of revenue looks normally distributed.\n","08e1cff7":"## Sub Continent: What We Learned\n\n- These charts parrots the results of the last ones, but narrows down the area to just Northern America. Unsurprisingly, purchases in South America are about as insignificant as all other non-North America sub continents.","30f44016":"## Network Domains: What We Learned\n\n- Most network domains are (not set) or unknown.unknown. Unfortunately, this means that we cannot get much useful information from this from a simple EDA. A careful machine learning model might still make use of this column.\n\n- The one small bit of information we can see is that comcastbusiness.net has much higher mean purchases than the other network domains. The subsample size is small but, even with the low confidence, the difference is still large enough to say that this is probably true.\n","8a4d8719":"# Traffic Medium: Exploration","62130ca9":"# Date and Time: Explorations","5e60c495":"## Device Browser: What We Learned\n\n- Most visits and visits with purchase are from Chrome browser. Makes sense as Chrome is a Google product and users are probably more likely to be Google fans.\n\n- Firefox seems to have larger purchases. However, the confidence is very low due to the small sample of Firefox purchases so this could very well be a fluke. Other than that, Chrome is confidently higher than the others besides Firefox.","309b9119":"## First Impressions: What We Learned\n\n- Separating out the JSON columns balloons the columns up to 58. A lot of these will be useful, but many will not.\n\n- Many columns seem full of NaN values and many others have almost NaN equivalent strings like \"not available in demo dataset\" and \"(not set)\"\n","94eeff13":"# Sub Continent: Exploration","84cb47ed":"## Operating System: What We Learned\n\n- Windows is the most common operating system used to visit. In fact, the operating system used seems to just follow the most common models.\n\n- Despite this, Macintosh users were much much more likely than windows users in visits with purchase. Perhaps because Macintosh users tend to be considered more \"tech savvy\" and may have more interest in tech based swag.\n\n- Chrome OS, despite it rarity, is more likely to purchase something which makes sense since it is made by google.\n\n- Mobile operating systems tend to purchase less often and spend less when they do. This is consistent with the hypothesis that visitor tend to commit to purchase more at a desktop computer than on their phones.\n","b8092ae8":"# Traffic Source: Exploration","98748cdc":"# Device Browser: Exploration","cd59ce2c":"# Network Domains: Exploration","56a78c6e":"## Visitors: What We Learned\n\n- Only ~1.1% of visits result in a sale.\n\n- Most of the visits to the site are from people visiting for the first time.\n\n- First time visitors are much less likely to purchase anything than returning visitors.\n"}}