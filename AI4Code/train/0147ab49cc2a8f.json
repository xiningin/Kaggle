{"cell_type":{"3b577bcd":"code","a7547a1d":"code","c8cb36b1":"code","323269ca":"code","a490b4a5":"code","24511e94":"code","e033fd08":"code","1b4d6982":"code","41ee1cb9":"code","68c0791b":"code","fb8f97d0":"code","42a26594":"code","dc49a6b3":"markdown","de194e03":"markdown","9092f5a3":"markdown","051a0448":"markdown","5b6d33cd":"markdown","8f36245b":"markdown","3fe1d2d7":"markdown","deedd97c":"markdown","3b9f88bf":"markdown","7f36bf34":"markdown","2eec255b":"markdown","fe05c0c9":"markdown","4668bc94":"markdown","cd18b4e9":"markdown"},"source":{"3b577bcd":"#!pip install imutils\nimport keras\nimport tensorflow\nimport os\nfrom keras.layers import Input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.layers import Flatten, Dense, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Flatten\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Input\nfrom keras.layers import BatchNormalization\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom imutils import paths\nimport matplotlib.pyplot as plt\nfrom keras.models import Model\nfrom sklearn.utils import shuffle\nfrom cv2 import imread\nimport numpy as np\nimport pandas as pd","a7547a1d":"data = []\nlabels = []\nwidth,height=150,150\n\nimagePaths = list(paths.list_images('..\/input\/diabetic-retinopathy-224x224-gaussian-filtered\/gaussian_filtered_images\/gaussian_filtered_images'))\ndata = []\nlabels = []\n\nfor imagePath in imagePaths:\n    label = imagePath.split(os.path.sep)[-2]\n    #print(imagePath)\n    image = load_img(imagePath, target_size=(width, height))\n    image = img_to_array(image)\n    data.append(image)\n    labels.append(label)\n\ndata = np.array(data, dtype=\"float32\")\nlabels = np.array(labels)\n\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)\n#labels = to_categorical(labels)\n\ndata, labels = shuffle(data, labels)\n\nprint(data.shape)\nprint(labels.shape)","c8cb36b1":"test_ratio = 0.25\n\n# train is now 75% of the entire data set\nx_train, x_test, y_train, y_test = train_test_split(data, labels, test_size=test_ratio)\n\nprint(\"Train images:\",x_train.shape)\nprint(\"Test images:\",x_test.shape)\nprint(\"Train label:\",y_train.shape)\nprint(\"Test label:\",y_test.shape)","323269ca":"INIT_LR = 1e-4\nEPOCHS = 25\nBS = 32\n\ncnn_model=Sequential()\ncnn_model.add(Conv2D(16, (3, 3),activation='relu',input_shape=(150, 150, 3)))\ncnn_model.add(MaxPooling2D(2,2))\ncnn_model.add(Conv2D(32, (3, 3),activation='relu'))\ncnn_model.add(MaxPooling2D(2,2))\ncnn_model.add(Conv2D(64, (3, 3),activation='relu'))\ncnn_model.add(MaxPooling2D(2,2))\ncnn_model.add(Conv2D(128, (3, 3), activation='relu'))\ncnn_model.add(MaxPooling2D(2,2))\ncnn_model.add(Conv2D(256, (3, 3), activation='relu'))\ncnn_model.add(MaxPooling2D(2,2))\ncnn_model.add(BatchNormalization())\ncnn_model.add(Flatten())   #Features Are Extracted From this Layer\ncnn_model.add(Dropout(0.2))\ncnn_model.add(Dense(1024, activation='relu'))\ncnn_model.add(Dense(5, activation='sigmoid'))\n\nopt = Adam(learning_rate=INIT_LR)\ncnn_model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\ncnn_model.summary()\n","a490b4a5":"# train the head of the network\nprint(\"[INFO] training head..\")\nh = cnn_model.fit(x_train,y_train,epochs=EPOCHS)\nprint(\"Done !!\")","24511e94":"#!pip install scikit-plot\nfrom sklearn.metrics import classification_report\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport scikitplot as skplt\nfrom sklearn.metrics import accuracy_score\nimport numpy as np\nfrom sklearn import metrics\n\nprint(\"[INFO] evaluating network...\")\npredIdxs = cnn_model.predict(x_test, batch_size=BS)\npredIdxs = np.argmax(predIdxs, axis=1)\n\ntrainpredIdxs = cnn_model.predict(x_train, batch_size=BS)\ntrainpredIdxs = np.argmax(trainpredIdxs, axis=1)\n\ntrainCNNScore=accuracy_score(trainpredIdxs,y_train.argmax(axis=1))*100\nCNNScore=accuracy_score(predIdxs,y_test.argmax(axis=1))*100\n\nprint(\"\\nTrainig Accuracy Score:-\",trainCNNScore)\nprint(\"\\nTesting Accuracy Score:-\",CNNScore)\nprint(\"\\nTraning Graph:- \\n \")\n\n# plot the training loss and accuracy\nN = EPOCHS\nplt.style.use(\"ggplot\")\nplt.figure()\nplt.plot(np.arange(0, N), h.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), h.history[\"accuracy\"], label=\"train_acc\")\nplt.title(\"Training Loss and Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"lower left\",)\nplt.show()","e033fd08":"extractCNN = Model(cnn_model.inputs, cnn_model.layers[-4].output)\n\n#del(data)\n#del(labels)\nfeat_trainCNN  = extractCNN.predict(x_train)  \nfeat_testCNN = extractCNN.predict(x_test)      \n\nprint(feat_trainCNN.shape)","1b4d6982":"from sklearn.svm import SVC\n\nsvm = SVC(kernel='linear')\nsvm.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n\nTrainSVMScoreCNN=svm.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\nprint(\"SVM Training Accuracy Score:-\",TrainSVMScoreCNN)\n\nTestSVMScoreCNN=svm.score(feat_testCNN,np.argmax(y_test,axis=1))*100\nprint(\"\\nSVM Testing Accuracy Score:-\",TestSVMScoreCNN)","41ee1cb9":"from sklearn.tree import DecisionTreeClassifier\n\nclf = DecisionTreeClassifier(random_state=0)\nclf = clf.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n\nTrainDecisionScoreCNN=clf.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\nprint(\"Decision Tree Training Accuracy Score:-\",TrainDecisionScoreCNN)\n\n\nTestDecisionScoreCNN=clf.score(feat_testCNN,np.argmax(y_test,axis=1))*100\nprint(\"\\nDecision Tree Testing Accuracy Score:-\",TestDecisionScoreCNN)","68c0791b":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors=5)\nknn.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n\nTrainKNNScoreCNN=knn.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\nprint(\"KNN Training Accuracy Score:-\",TrainKNNScoreCNN)\n\nTestKNNScoreCNN=knn.score(feat_testCNN,np.argmax(y_test,axis=1))*100\nprint(\"\\nKNN Testing Accuracy Score:-\",TestKNNScoreCNN)","fb8f97d0":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(feat_trainCNN,np.argmax(y_train,axis=1))\n\nTrainNBScoreCNN=gnb.score(feat_trainCNN,np.argmax(y_train,axis=1))*100\nprint(\"\\nGaussianNaive Bayes Training Accuracy Score:-\",TrainNBScoreCNN)\n\nTestNBScoreCNN=gnb.score(feat_testCNN,np.argmax(y_test,axis=1))*100\nprint(\"\\nGaussianNaive Bayes Testing Accuracy Score:-\",TestNBScoreCNN)","42a26594":"print(\"--Training Accuracy..\")\nprint(\"CNN Accuracy:- {:.2f} %\".format(trainCNNScore))\nprint(\"CNN-SVM Accuracy:- {:.2f} %\".format(TrainSVMScoreCNN))\nprint(\"CNN-DT Accuracy:- {:.2f} %\".format(TrainDecisionScoreCNN))\nprint(\"CNN-KNN Accuracy:- {:.2f} %\".format(TrainKNNScoreCNN))\nprint(\"CNN-NB Accuracy:- {:.2f} %\".format(TrainNBScoreCNN))\n\nprint(\"\\n--Testing Accuracy..\")\nprint(\"CNN Accuracy:- {:.2f} %\".format(CNNScore))\nprint(\"CNN-SVM Accuracy:- {:.2f} %\".format(TestSVMScoreCNN))\nprint(\"CNN-DT Accuracy:- {:.2f} %\".format(TestDecisionScoreCNN))\nprint(\"CNN-KNN Accuracy:- {:.2f} %\".format(TestKNNScoreCNN))\nprint(\"CNN-NB Accuracy:- {:.2f} %\".format(TestNBScoreCNN))","dc49a6b3":"<a id=\"1\"><\/a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\">Extracting Features<\/p>","de194e03":"<a id=\"2\"><\/a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\">Import Libraries<\/p>","9092f5a3":"<a id=\"3\"><\/a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\">Load Data and Split<\/p>","051a0448":"### Gaussian Naive Bayes","5b6d33cd":"### K-Nearest Neighbor(KNN)","8f36245b":"<a id=\"1\"><\/a>\n# <p style=\"background-color:#000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\">Introduction<\/p>\n\n\n> ### Aim of this work is to demonstrate how we can combine CNN and ML using detiatic retinopathy dataset.\n> ### We are going to extract the features using CNN flatten layer and pass those features to some ML classifier.\n> ### Each model will be evaluate based on Testing Accuracy.","3fe1d2d7":"<a id=\"1\"><\/a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\">Training Machine Learning Classifier<\/p>","deedd97c":"> ### CNN-KNN model shows highest accuarcy followed closely by CNN-SVM and CNN.\n> ### Gaussian Naive Bayes has lowest accuacy because It is not sutaible for this type data or task.","3b9f88bf":"<a id=\"1\"><\/a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\">CNN-ML Model<\/p>\n![CNNSVM architecture c.jpg](attachment:7651851b-0389-46f4-86b3-f5601c2e67b0.jpg)\n\n\n> * ### CNN layers extracting the features and Pass 3D features to Flatten Layer.\n> * ### Flatten Layer Convert 3D features to 1D features.\n> * ###  Pass those 1D features to Machine Learning Classifier.","7f36bf34":"### Decision Tree","2eec255b":"<p style=\"font-size:220%;text-align:center\"> If you find this notebook interesting, please do upvote :) <\/p>\n\n# <p style=\"text-align:center\"> <img src=\"https:\/\/media.giphy.com\/media\/3oEdva9BUHPIs2SkGk\/giphy.gif\"> <\/p>\n<p style=\"font-size:120%;text-align:center\">Next, I'm planing to do combine pretrained model like VGG with ML algorithm.<\/p>","fe05c0c9":"### Support Vector Machine (SVM)","4668bc94":"<a id=\"1\"><\/a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\">Training CNN<\/p>","cd18b4e9":"<a id=\"1\"><\/a>\n# <p style=\"background-color:#000000;font-family:newtimeroman;color:#fff;font-size:120%;text-align:center;border-radius:20px 80px;\">Summary<\/p>"}}