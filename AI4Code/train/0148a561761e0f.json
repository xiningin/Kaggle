{"cell_type":{"b09b360e":"code","2663a5e9":"code","47b4d889":"code","de119636":"code","4d5779b0":"code","48a50486":"code","75491d28":"code","2c12f964":"code","f0607ea8":"code","cd1ba0f0":"code","97fca3f4":"code","851c253f":"code","afe289fe":"code","ed98da16":"code","a4d4c4d3":"code","9f8dd608":"code","27e539a2":"code","11ff5386":"code","e0e77b26":"code","4c671365":"code","e8fab114":"code","4cae01ed":"code","04b7ba36":"code","0635614b":"code","fec4ff4a":"code","725665ea":"code","efdea4e6":"code","deed09c4":"code","63f95d16":"code","36eb4d46":"code","19b336e7":"code","f67887d6":"code","92eede57":"code","bcb8d644":"code","647e4ff3":"code","1948e6fa":"code","7c4cdbab":"code","7a8a2384":"code","018a2779":"code","36578c6d":"code","8b1ba6db":"code","7ee142b3":"code","620420a3":"code","22883768":"code","e26501da":"code","b2d47288":"code","b4999697":"code","735fdea7":"code","c75068c4":"code","9c66ed6a":"code","faf72ea5":"code","98a07f39":"code","9fdb569a":"code","9ebaf235":"code","e092a225":"code","5416174d":"code","2f5db554":"code","d8b862ee":"code","dd3a7426":"code","08fd5ba3":"code","cfbaf868":"code","8332c085":"code","5b9cc004":"code","e638b4e6":"code","9edac3d3":"code","3b038487":"code","7e34ab4c":"code","07016f0b":"code","89fc460f":"code","5d79e66e":"code","a33c9b47":"code","15ed720b":"code","042f09b5":"code","f54862be":"code","22199d21":"code","c3e03801":"code","25969e48":"code","87cb0654":"code","1254d73b":"code","b41b8f6b":"code","23b3542b":"code","9d700c57":"markdown","d7d4ef75":"markdown","f072f872":"markdown","d5cccc19":"markdown","044af4ad":"markdown","cb97113d":"markdown","405f1df1":"markdown","0dfe9e32":"markdown","15596fcd":"markdown","aa65c611":"markdown","52b3bfec":"markdown","648fa492":"markdown","b38c63f1":"markdown","d773fca0":"markdown","5858792c":"markdown","1fe714ae":"markdown","39fee36f":"markdown","de05903f":"markdown","41a28a4a":"markdown","b11decbc":"markdown","b8263486":"markdown","7f33267d":"markdown","a1d12559":"markdown","8df6a8ee":"markdown","a44d95f4":"markdown"},"source":{"b09b360e":"import numpy as np\nimport pandas as pd","2663a5e9":"train = pd.read_csv('..\/input\/train.csv')","47b4d889":"NUM_TRAIN = train.shape[0]\nNUM_TRAIN","de119636":"test = pd.read_csv('..\/input\/test.csv')","4d5779b0":"combined = train.drop('Survived', axis=1).append(test)\ncombined.reset_index(inplace=True)\ncombined.drop('index', axis=1, inplace=True)","48a50486":"combined.isnull().sum()","75491d28":"combined.drop(['Cabin', 'PassengerId', 'Ticket'], axis=1, inplace=True)","2c12f964":"combined[combined['Fare'].isnull()]","f0607ea8":"combined[\n    (combined['Pclass'] == 3) &\n    (combined['Sex'] == 'male') &\n    (combined['Embarked'] == 'S') &\n    (combined['Age'] > 50) &\n    (combined['Fare'].notnull())\n]['Fare'].mean()","cd1ba0f0":" combined.loc[1043,'Fare'] = 7.45","97fca3f4":"combined[combined['Embarked'].isnull()]","851c253f":"train.loc[[61,829], 'Survived']","afe289fe":"combined[\n    (combined['Sex'] == 'female') &\n    (combined['Pclass'] == 1) &\n    (combined['Embarked'].notnull())\n]['Embarked'].value_counts()","ed98da16":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","a4d4c4d3":"sns.boxplot(data = combined[\n    (combined['Sex'] == 'female') &\n    (combined['Pclass'] == 1) &\n    (combined['Embarked'].notnull())\n], x='Embarked', y='Age')","9f8dd608":"combined.loc[61, 'Embarked'] = 'C'\ncombined.loc[829, 'Embarked'] = 'S'","27e539a2":"combined.isnull().sum()","11ff5386":"import re","e0e77b26":"combined['Title'] = combined['Name'].apply(lambda x: re.findall('([A-Za-z]+)\\.', x)[0])","4c671365":"combined['Title'].value_counts()","e8fab114":"combined['Title'].replace(['Mr', 'Mrs', 'Miss', 'Master', 'Don', 'Rev', 'Dr', 'Mme', 'Ms',\n       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Countess',\n       'Jonkheer', 'Dona'], ['Mr', 'Mrs', 'Miss', 'Master', 'Other', 'Other', 'Other', 'Miss', 'Miss',\n       'Other', 'Other', 'Other', 'Miss', 'Other', 'Other', 'Other',\n       'Other', 'Other'], inplace=True)","4cae01ed":"combined['Title'].value_counts()","04b7ba36":"combined.drop('Name', axis=1, inplace=True)","0635614b":"combined['Age'].isnull().sum()","fec4ff4a":"grouped_for_age = combined.dropna().groupby(['Pclass','Embarked', 'Title']).median()['Age'].reset_index()","725665ea":"grouped_for_age","efdea4e6":"grouped_for_age[\n    (grouped_for_age['Pclass'] == 1) &\n    (grouped_for_age['Embarked'] == 'C') &\n    (grouped_for_age['Title'] == 'Master') \n]['Age'].values[0]","deed09c4":"combined['Age'] = combined[['Pclass', 'Embarked', 'Title']].apply(lambda x: grouped_for_age[\n    (grouped_for_age['Pclass'] == x[0]) &\n    (grouped_for_age['Embarked'] == x[1]) &\n    (grouped_for_age['Title'] == x[2]) \n]['Age'].values[0], axis=1)","63f95d16":"combined.isnull().sum()","36eb4d46":"combined['Familysize'] = combined['Parch'] + combined['SibSp'] + 1","19b336e7":"combined.drop(['Parch', 'SibSp'], axis=1, inplace=True)","f67887d6":"combined.info()","92eede57":"combined = pd.get_dummies(combined, columns=['Sex', 'Embarked', 'Title'], drop_first=True)","bcb8d644":"combined.head()","647e4ff3":"combined_1 = combined.drop('Fare', axis=1)","1948e6fa":"combined_2 = combined.copy()","7c4cdbab":"pd.qcut(combined['Age'], 5).unique()","7a8a2384":"combined_3 = combined.copy()\ndef bucket_age(row):\n    age = row['Age']\n    if age > 39: return 5\n    elif age > 30: return 4\n    elif age > 26: return 3\n    elif age > 23.5: return 2\n    else: return 1\n\ncombined_3['Age'] = combined_3.apply(bucket_age, axis=1)","018a2779":"pd.qcut(combined['Fare'], 5).unique()","36578c6d":"def bucket_fare(row):\n    fare = row['Fare']\n    if fare > 41.579: return 5\n    elif fare > 21.558: return 4\n    elif fare > 10.5: return 3\n    elif fare > 7.854: return 2\n    else: return 1\n\ncombined_3['Fare'] = combined_3.apply(bucket_fare, axis=1)","8b1ba6db":"combined_1.head()","7ee142b3":"combined_2.head()","620420a3":"combined_3.head()","22883768":"from sklearn.preprocessing import StandardScaler","e26501da":"scaled_combined_1 = pd.DataFrame(StandardScaler().fit_transform(combined_1),\n                                 index=combined_1.index,\n                                 columns=combined_1.columns)\nscaled_combined_1.head()","b2d47288":"scaled_combined_2 = pd.DataFrame(StandardScaler().fit_transform(combined_2),\n                                 index=combined_2.index,\n                                 columns=combined_2.columns)\nscaled_combined_2.head()","b4999697":"scaled_combined_3 = pd.DataFrame(StandardScaler().fit_transform(combined_3),\n                                 index=combined_3.index,\n                                 columns=combined_3.columns)\nscaled_combined_3.head()","735fdea7":"sns.heatmap(scaled_combined_1.corr(), annot=True, cmap='coolwarm')","c75068c4":"sns.heatmap(scaled_combined_2.corr(), annot=True, cmap='coolwarm')","9c66ed6a":"sns.heatmap(scaled_combined_3.corr(), annot=True, cmap='coolwarm')","faf72ea5":"def train_test_target(df):\n    train_ = df[:NUM_TRAIN]\n    test_ = df[NUM_TRAIN:]\n    target_ = train['Survived']\n    return train_, test_, target_","98a07f39":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report, roc_curve, auc","9fdb569a":"X_1, test_1, y_1 = train_test_target(scaled_combined_1)","9ebaf235":"X_train_1, X_test_1, y_train_1, y_test_1 = train_test_split(X_1, y_1, test_size=0.3, random_state=42)","e092a225":"logmodel_1 = LogisticRegression(solver='liblinear')\nlogmodel_1.fit(X_train_1, y_train_1)","5416174d":"predictions_1 = logmodel_1.predict(X_test_1)","2f5db554":"print(classification_report(y_test_1, predictions_1))","d8b862ee":"sns.heatmap(confusion_matrix(y_test_1, predictions_1), annot=True, cmap='coolwarm')","dd3a7426":"y_score_1 = logmodel_1.decision_function(X_test_1)\nFPR_1, TPR_1, _ = roc_curve(y_test_1, y_score_1)\nROC_AUC_1 = auc(FPR_1, TPR_1)","08fd5ba3":"plt.plot(FPR_1, TPR_1, label=f'ROC curve {ROC_AUC_1}')\nplt.plot([0,1], [0,1], 'k--')\nplt.xlim([0,1])\nplt.ylim([0,1.05])\nplt.legend()","cfbaf868":"logmodel_1.fit(X_1, y_1)\n\nsubmission = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': logmodel_1.predict(test_1)\n})\nsubmission.to_csv('submission_1.csv', index=False)","8332c085":"X_2, test_2, y_2 = train_test_target(scaled_combined_2)\nX_train_2, X_test_2, y_train_2, y_test_2 = train_test_split(X_2, y_2, test_size=0.3, random_state=42)\nlogmodel_2 = LogisticRegression(solver='liblinear')\nlogmodel_2.fit(X_train_2, y_train_2)\npredictions_2 = logmodel_2.predict(X_test_2)","5b9cc004":"X_3, test_3, y_3 = train_test_target(scaled_combined_3)\nX_train_3, X_test_3, y_train_3, y_test_3 = train_test_split(X_3, y_3, test_size=0.3, random_state=42)\nlogmodel_3 = LogisticRegression(solver='liblinear')\nlogmodel_3.fit(X_train_3, y_train_3)\npredictions_3 = logmodel_3.predict(X_test_3)","e638b4e6":"print(classification_report(y_test_2, predictions_2))","9edac3d3":"print(classification_report(y_test_3, predictions_3))","3b038487":"fig, ax = plt.subplots(1, 3, figsize=(15, 4))\nsns.heatmap(confusion_matrix(y_test_1, predictions_1), annot=True, cmap='coolwarm', ax=ax[0])\nsns.heatmap(confusion_matrix(y_test_2, predictions_2), annot=True, cmap='coolwarm', ax=ax[1])\nsns.heatmap(confusion_matrix(y_test_3, predictions_3), annot=True, cmap='coolwarm', ax=ax[2])","7e34ab4c":"y_score_2 = logmodel_2.decision_function(X_test_2)\nFPR_2, TPR_2, _ = roc_curve(y_test_2, y_score_2)\nROC_AUC_2 = auc(FPR_2, TPR_2)\n\ny_score_3 = logmodel_3.decision_function(X_test_3)\nFPR_3, TPR_3, _ = roc_curve(y_test_3, y_score_3)\nROC_AUC_3 = auc(FPR_3, TPR_3)","07016f0b":"plt.plot(FPR_1, TPR_1, label=f'ROC curve 1 {ROC_AUC_1}', color='red')\nplt.plot(FPR_2, TPR_2, label=f'ROC curve 2 {ROC_AUC_2}', color='blue')\nplt.plot(FPR_3, TPR_3, label=f'ROC curve 3 {ROC_AUC_3}', color='green')\nplt.plot([0,1], [0,1], 'k--')\nplt.xlim([0,1])\nplt.ylim([0,1.05])\nplt.legend()","89fc460f":"logmodel_2.fit(X_2, y_2)\nsubmission_2 = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': logmodel_2.predict(test_2)\n})\nsubmission_2.to_csv('submission_2.csv', index=False)\n\nlogmodel_3.fit(X_3, y_3)\nsubmission_3 = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': logmodel_3.predict(test_3)\n})\nsubmission_3.to_csv('submission_3.csv', index=False)","5d79e66e":"from sklearn.model_selection import cross_val_score","a33c9b47":"cv_score = cross_val_score(LogisticRegression(solver='liblinear'), X_2, y_2, cv=5, scoring='accuracy')\nprint(cv_score, np.mean(cv_score))","15ed720b":"from sklearn.model_selection import GridSearchCV, StratifiedKFold","042f09b5":"%%time\nif False:\n    C_values = [0.1, 0.2, 0.3, 0.4, 0.5, 0.8, 1.0, 2.0, 5.0, 10.0, 20.0]\n    # New (Second) param grid\n    param_grid = [{\n        'penalty': ['l2'],\n        'C': C_values,\n        'solver': ['lbfgs', 'newton-cg', 'sag']\n    }, {\n        'penalty': ['l1', 'l2'],\n        'C': C_values,\n        'solver': ['liblinear', 'saga']\n    }, {\n        'penalty': ['none'],\n        'solver': ['lbfgs', 'newton-cg', 'saga', 'sag']\n    }, {\n        'penalty': ['elasticnet'],\n        'C': C_values,\n        'l1_ratio': [0, 0.2, 0.5, 0.8, 1.0],\n        'solver': ['saga']\n    }]\n    #     # Previous (First) param grid\n    #     param_grid = [{\n    #         'penalty': ['l2'],\n    #         'C': C_values,\n    #         'solver': ['lbfgs', 'newton-cg']\n    #     }, {\n    #         'penalty': ['l1', 'l2'],\n    #         'C': C_values,\n    #         'solver': ['liblinear']\n    #     }, {\n    #         'penalty': ['none'],\n    #         'solver': ['lbfgs', 'newton-cg']\n    #     }]\n    grid = GridSearchCV(estimator=LogisticRegression(max_iter=5000),\n                       param_grid=param_grid,\n                       scoring='accuracy',\n                       cv=StratifiedKFold(n_splits=5))\n    grid.fit(X_2, y_2)\n    print(f'Best Score: {grid.best_score_}')\n    print(f'Best Parameters: {grid.best_params_}')\n    print(f'Best Estimator: {grid.best_estimator_}')\n    ","f54862be":"roc_auc_params = {'C': 0.4, 'penalty': 'l2', 'solver': 'liblinear', 'max_iter':5000}\naccuracy_params = {'C': 0.2, 'penalty': 'l1', 'solver': 'liblinear', 'max_iter':5000}\n\nlogmodel_roc_auc = LogisticRegression(**roc_auc_params)\nlogmodel_roc_auc.fit(X_2, y_2)\nsubmission_2_roc_auc = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': logmodel_roc_auc.predict(test_2)\n})\nsubmission_2_roc_auc.to_csv('submission_2_roc_auc.csv', index=False)\n\nlogmodel_accuracy = LogisticRegression(**accuracy_params)\nlogmodel_accuracy.fit(X_2, y_2)\nsubmission_2_accuracy = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': logmodel_accuracy.predict(test_2)\n})\nsubmission_2_accuracy.to_csv('submission_2_accuracy.csv', index=False)","22199d21":"roc_auc_params_new = {'C': 0.3, 'l1_ratio': 0.8, 'penalty': 'elasticnet', 'solver': 'saga', 'max_iter': 5000}\naccuracy_params_new = {'C': 0.8, 'penalty': 'l1', 'solver': 'saga', 'max_iter': 5000}\n\nlogmodel_roc_auc_new = LogisticRegression(**roc_auc_params_new)\nlogmodel_roc_auc_new.fit(X_2, y_2)\nsubmission_2_roc_auc_new = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': logmodel_roc_auc_new.predict(test_2)\n})\nsubmission_2_roc_auc_new.to_csv('submission_2_roc_auc_new.csv', index=False)\n\nlogmodel_accuracy_new = LogisticRegression(**accuracy_params_new)\nlogmodel_accuracy_new.fit(X_2, y_2)\nsubmission_2_accuracy_new = pd.DataFrame({\n    'PassengerId': test['PassengerId'],\n    'Survived': logmodel_accuracy_new.predict(test_2)\n})\nsubmission_2_accuracy_new.to_csv('submission_2_accuracy_new.csv', index=False)\n","c3e03801":"logmodel_2","25969e48":"intr_1 = pd.DataFrame(index=X_2.columns, data=logmodel_2.coef_[0], columns=['Slope'])\nintr_1.iloc[intr_1['Slope'].abs().argsort()[::-1]]","87cb0654":"logmodel_accuracy","1254d73b":"intr_2 = pd.DataFrame(index=X_2.columns, data=logmodel_accuracy.coef_[0], columns=['Slope'])\nintr_2.iloc[intr_2['Slope'].abs().argsort()[::-1]]","b41b8f6b":"logmodel_roc_auc_new","23b3542b":"intr_3 = pd.DataFrame(index=X_2.columns, data=logmodel_roc_auc_new.coef_[0], columns=['Slope'])\nintr_3.iloc[intr_3['Slope'].abs().argsort()[::-1]]","9d700c57":"**Familysize**","d7d4ef75":"**With New param_grid (Comprising all solvers)**  \nroc_auc: `{'C': 0.3, 'l1_ratio': 0.8, 'penalty': 'elasticnet', 'solver': 'saga'}`  \naccuracy: `{'C': 0.8, 'penalty': 'l1', 'solver': 'saga'}`\n","f072f872":"This is kind of final data. But, I want to check this data on three conditions:\n1. Without Fare (because, Pclass might have redundant information)\n2. As it is Age and Fare\n3. Bucketing Age and Fare","d5cccc19":"# Cross Validation Score","044af4ad":"# Logistic Regression Model","cb97113d":"**One hot encoding**","405f1df1":"Both port C and S seems to have approximately equal number of females from Pclass 1. From the boxplot, putting age 38 to pclass 'C' and age 62 to pclass 'S'.","0dfe9e32":"# Data Cleaning & Feature Engineering","15596fcd":"**logmodel_2**","aa65c611":"**Embarked**  \nIt has two missing data","52b3bfec":"**Fare**  \nIt has one null data.","648fa492":"# Feature Correlation","b38c63f1":"**logmodel_roc_auc_new**","d773fca0":"1. For data analysis, follow [this (Exploratory Data Analysis)](https:\/\/www.kaggle.com\/sabbiu\/exploratory-data-analysis)\n2. *[Current]* Logistic Regression\n3. [Playing with pipeline](https:\/\/www.kaggle.com\/sabbiu\/playing-with-sklearn-pipeline)","5858792c":"Let's drop Cabin (as it has so many null data)\nAlso, dropping PassengerId (as it is not a useful feature)","1fe714ae":"**Fitting model to other data**","39fee36f":"These are the model accuracies I got.\n\n| | Submission Score | CV Accuracy | CV ROC AUC |\n|-|-|-|-|\n| *Before Hyperparameter Tuning* ||||\n|1 (removing fare feature)| 0.78947 | 0.82159 | 0.86572 |\n|2 (all features)| **0.79425** | **0.82385** | 0.86866 |\n|3 (bucketing age and fare) | 0.78468 | 0.81151 | **0.86908** |\n| *After Hyperparameter Tuning (Data 2)* ||||\n|First Param Grid (scoring=accuracy)| **0.80382** | 0.82496 | 0.86880 |\n|First Param Grid (scoring=roc_auc)| 0.79904 | 0.82272 | 0.86883 |\n|Second Param Grid (scoring=accuracy)| 0.79904 | **0.82609** | 0.86815 |\n|Second Param Grid (scoring=roc_auc)| **0.80382** | 0.82383 | **0.86888** |\n\n*Note: The CV Accuracy and CV ROC AUC are obtained by providing necessary parameters in Cross Validation Section.*\n\nAfter performing hyperparameter tuning, models have comparatively higher accuracy (~0.80).\n\nKnow about different types of solver from here, https:\/\/stackoverflow.com\/a\/52388406\/6892277","de05903f":"**Name**  \nLet's first extract out title from name. Then, we can deal with age.","41a28a4a":"# Interpretation and Conclusion","b11decbc":"**Age**","b8263486":"# Hyperparameter Tuning and Optimization using GridSearchCV","7f33267d":"It seems, performance of model is in the order: 2 > 1 > 3.  \nLet's perform all the works from now onwards on model 2.","a1d12559":"**logmodel_accuracy**","8df6a8ee":"**With Previous param_grid**  \nWith scoring `accuracy`: `{'C': 0.2, 'penalty': 'l1', 'solver': 'liblinear'}`  \nWith scoring `roc_auc`: `{'C': 0.4, 'penalty': 'l2', 'solver': 'liblinear'}`","a44d95f4":"Here, we can notice the following things:\n\nFrom [EDA](https:\/\/www.kaggle.com\/sabbiu\/exploratory-data-analysis), we concluded the following:  \n* **Pclass:** Passenger Class 1 have higher rate of survival.\n  * Pclass has higher negative slope, which means, higher the value of Pclass, lower is the chance of survival.\n* **Age:** Children (age lower than ~9) have higher rate of survival.\n  * Age also has negative slope.\n* **Sex:** Females have higher rate of survival.\n  * Title_Mr and Sex_male, both have negative slope. While, Title_Mrs has positive slope.\n  * But, from logmodel_2, Title_Miss has negative slope. This means, Title_Miss has lower chance of survival. From our analysis in EDA, this is not the case. It might be because, Title_Mr, and Sex_male might have captured most of the Survivor of Title_Miss.\n* **Sex and Pclass:** Females of upper passenger class (1 and 2) have higher rate of survival.\n* **Embarked:** People who embarked from *C* have comparatively higher rate of survival.\n  * Embarked_C has been dropped.\n* **Embarked and Pclass:** People who embarked from port *S* into class 3 have comparatively low survival rate. Very few poeple embarked from port *Q* went to class 1 and 2.\n* **Family Size (Parch + SibSp + 1):** Highest chance of survival are for those families who have family size of 4.\n  * Negative slope indicates that, larger families have lower chance of survival.\n* **Family Size and Sex:** Females having family size less than 5 have higher rate of survival.\n\n**Regularization**\n\nWhen regularization is l2, also known as ridge regression, there is a very small slope associated with less useful features. And, for l1 regularization, also known as lasso regression, less useful features have 0 slope value, i.e, they are discarded.\n![Lasso_Ridge](https:\/\/i.stack.imgur.com\/A8qcK.png)"}}