{"cell_type":{"2fa2c849":"code","ef568e17":"code","d004f5a4":"code","a195d2b7":"code","eb664605":"code","5ae34129":"code","e8626aca":"code","02a46fce":"code","37856d46":"code","036d3d7e":"code","6ceba054":"code","0ee5056e":"code","c5bd5070":"code","6b22f16e":"code","11856f97":"code","737d416b":"code","14daa544":"code","709aeb57":"code","46cd2d06":"code","23b393cd":"code","1ea7d121":"code","abeb871d":"code","299eecce":"code","c10fa825":"code","d144025a":"code","74b43141":"code","79037bdd":"code","6405bb71":"code","bec6f6af":"code","c3525190":"code","78205741":"code","4f816c9f":"code","583340f2":"code","496e9c72":"code","cbc8d333":"code","59995846":"code","1edd0537":"code","bcf51e44":"code","fc90b065":"code","a18af760":"code","67c7afff":"code","fbd2c789":"code","781b4891":"code","0538fb44":"code","4033f3f2":"code","12aa28a2":"code","799b2621":"code","912cb003":"code","7631670d":"code","1c20d172":"code","33b73df3":"code","b7ee93b5":"code","6d8134fb":"code","8b3d3b4d":"code","7e7397a6":"code","d83fbb4d":"code","aebc1a97":"code","587c232e":"code","c1a71649":"code","7e6f06b8":"code","7d65eb38":"code","a170af32":"code","5485d1e4":"code","7f0f4e00":"code","23485c3c":"code","ca36277d":"code","f11bc7e1":"code","042bd27e":"code","c4674337":"code","d3840d20":"code","01d89af0":"code","7fe50c62":"code","dd0c9b40":"markdown","49c1453e":"markdown","357669f7":"markdown","620733ab":"markdown","8664d457":"markdown","425bfd1b":"markdown","2185dd75":"markdown","b67a74c6":"markdown","1f897d4f":"markdown","3c588609":"markdown","d35b5ce0":"markdown","da9eaf68":"markdown","b561396a":"markdown","0804adbc":"markdown","0e2e2627":"markdown","82b1b071":"markdown","c5d6774e":"markdown","d53279c6":"markdown","28763192":"markdown","123b6811":"markdown","f55cc47d":"markdown","6c233c2f":"markdown","6d84c37f":"markdown","947b654f":"markdown","a90fd0bb":"markdown","890d8f67":"markdown","3b7cc045":"markdown","602649cc":"markdown","4b3c8897":"markdown","50ba1ab6":"markdown","aec5d95d":"markdown","b27e4c2f":"markdown","9d487948":"markdown","a9d37483":"markdown","8cfe966e":"markdown","667fcbd7":"markdown"},"source":{"2fa2c849":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport tensorflow as tf \nimport sklearn\nimport os \nimport pathlib\nfrom PIL import Image\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import StratifiedShuffleSplit\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.feature_selection import RFE\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import BaggingClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.metrics import confusion_matrix \nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import average_precision_score, roc_auc_score\nfrom sklearn.metrics import classification_report","ef568e17":"data_path = \"..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv\"\n\ndata = pd.read_csv(data_path)","d004f5a4":"data.head()","a195d2b7":"print(\"The shape of data: {}\".format(data.shape))","eb664605":"#NO missing values\ndata.info()","5ae34129":"# 5 categorical variables\ncat_variables = ['anaemia', 'diabetes', 'high_blood_pressure', 'sex', 'smoking'] \n\nfor variable in cat_variables:\n    data[variable] = data[variable].astype('category')","e8626aca":"data.info()","02a46fce":"# 6 numerical variables\nnumerical_variables = ['age', 'creatinine_phosphokinase',\n                        'platelets', 'serum_creatinine',\n                        'serum_sodium', 'time']","37856d46":"data[numerical_variables].describe().T","036d3d7e":"# no duplicated rows\ndata.duplicated().sum()","6ceba054":"data[\"DEATH_EVENT\"].value_counts()","0ee5056e":"print(\"{:.2F} of the data is a negative class and {:.2F} is positive\".format(203\/299, 69\/299))","c5bd5070":"unscaled_dataset_version = data","6b22f16e":"unscaled_dataset_version.head()","11856f97":"x_unscaled_version = unscaled_dataset_version.drop('DEATH_EVENT', axis=1)\ny_unscaled_version = unscaled_dataset_version[['DEATH_EVENT']]","737d416b":"x_unscaled_version_np = np.array(x_unscaled_version)\ny_unscaled_version_np = np.array(y_unscaled_version).reshape(-1)","14daa544":"#spliting the unscaled data\nx_train_unscaled, x_test_unscaled, y_train_unscaled, y_test_unscaled = train_test_split(x_unscaled_version_np,\n                                                                                       y_unscaled_version_np,\n                                                                                       test_size=0.2,\n                                                                                       shuffle=True,\n                                                                                       random_state=0)","709aeb57":"#extracting polynomial features\n#scaling the data\n#selecting the best 12 features\nnum_pipeline = Pipeline([(\"polynomial\", PolynomialFeatures(degree=2, include_bias=False)),\n                         (\"scaler\", StandardScaler()),\n                         (\"feature_selection\", SelectFromModel(LogisticRegression(max_iter=1000), max_features=12))])","46cd2d06":"# Scaling and One_Hot encoding the data\ndata_prep_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, numerical_variables),\n    ('cat', OneHotEncoder(), cat_variables)\n])","23b393cd":"x_preprocessed_data = data_prep_pipeline.fit_transform(x_unscaled_version, y_unscaled_version_np)\ny_preprocessed_data = np.array(y_unscaled_version).reshape(-1)","1ea7d121":"x_preprocessed_data.shape","abeb871d":"#spliting the scaled data\nx_train_preprocessed, x_test_preprocessed, y_train_preprocessed, y_test_preprocessed = train_test_split(x_preprocessed_data,\n                                                                                           y_preprocessed_data,\n                                                                                           test_size=0.2,\n                                                                                           shuffle=True,\n                                                                                           random_state=0)","299eecce":"#using the unprocessed data\nkn_model = KNeighborsClassifier()\nkn_model.fit(x_train_unscaled , y_train_unscaled)\nkn_train_score = kn_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"KNeighbors Classifier Training Score: {:.3F}\".format(kn_train_score))","c10fa825":"#using the processed data\nkn_model = KNeighborsClassifier()\nkn_model.fit(x_train_preprocessed , y_train_preprocessed)\nkn_train_score = kn_model.score(x_train_preprocessed , y_train_preprocessed)\n\nprint(\"KNeighbors Classifier Training Score: {:.3F}\".format(kn_train_score))\n\n\n# KNeighborsClassifier evaluated using shuffle-split cross-validation \nkn_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nkn_val_scores = cross_val_score(kn_model, x_train_preprocessed , y_train_preprocessed, cv=kn_shuffle_split)\nprint(\"KNeighbors Classifier Cross validation Score: {:.3F}\".format(np.mean(kn_val_scores)))","d144025a":"lr_model = LogisticRegression(max_iter=1000, random_state=0)\nlr_model.fit(x_train_unscaled , y_train_unscaled)\nlr_train_score = lr_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"Logistic Regression Training Score: {:.3F}\".format(lr_train_score))\n\n\n# LogisticRegression evaluated using shuffle-split cross-validation \nlr_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nlr_val_scores = cross_val_score(lr_model, x_unscaled_version , y_unscaled_version_np, cv=lr_shuffle_split)\nprint(\"Logistic Regression Cross validation Score: {:.3F}\".format(np.mean(lr_val_scores)))","74b43141":"# SVMs are sensitive to the feature scale so I will use the scaled data\nliniar_svc_model = LinearSVC(max_iter=10000, random_state=0)\nliniar_svc_model.fit(x_train_preprocessed , y_train_preprocessed)\nLinear_svc_train_score = liniar_svc_model.score(x_train_preprocessed , y_train_preprocessed)\n\nprint(\"LinearSVC Training Score: {:.3F}\".format(Linear_svc_train_score))\n\n\n# LinearSVC evaluated using shuffle-split cross-validation \nLinear_svc_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nLinear_svc_val_scores = cross_val_score(liniar_svc_model, x_train_preprocessed , y_train_preprocessed, cv=Linear_svc_shuffle_split)\nprint(\"LinearSVC Cross validation Score: {:.3F}\".format(np.mean(Linear_svc_val_scores)))","79037bdd":"poly_kernel_svc_model = SVC(kernel='poly', degree=2, coef0=0.01, C=1, random_state=0)\npoly_kernel_svc_model.fit(x_train_preprocessed , y_train_preprocessed)\npoly_kernel_train_score = poly_kernel_svc_model.score(x_train_preprocessed , y_train_preprocessed)\n\nprint(\"SVC Training Score: {:.3F}\".format(poly_kernel_train_score))\n\n\n# polynomial kernel svc evaluated using shuffle-split cross-validation \npoly_kernel_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\npoly_kernel_val_scores = cross_val_score(poly_kernel_svc_model,\n                                         x_train_preprocessed ,\n                                         y_train_preprocessed,\n                                         cv=poly_kernel_shuffle_split)\n\nprint(\"LinearSVC Cross validation Score: {:.3F}\".format(np.mean(poly_kernel_val_scores)))","6405bb71":"rbf_kernel_svc_model = SVC(kernel='rbf', gamma=6, C=5, random_state=0)\nrbf_kernel_svc_model.fit(x_train_preprocessed , y_train_preprocessed)\nrbf_kernel_train_score = rbf_kernel_svc_model.score(x_train_preprocessed , y_train_preprocessed)\n\nprint(\"SVC Training Score: {:.3F}\".format(rbf_kernel_train_score))\n\n\n# RBF kernel svc evaluated using shuffle-split cross-validation \nrbf_kernel_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nrbf_kernel_val_scores = cross_val_score(rbf_kernel_svc_model,\n                                         x_train_preprocessed ,\n                                         y_train_preprocessed,\n                                         cv=rbf_kernel_shuffle_split)\n\nprint(\"LinearSVC Cross validation Score: {:.3F}\".format(np.mean(rbf_kernel_val_scores)))\n\n#This model is overfitting ","bec6f6af":"#DecisionTreeClassifier does not require feature scaling\n#This model is overfitting\n\ndt_model = DecisionTreeClassifier(random_state=0)\ndt_model.fit(x_train_unscaled , y_train_unscaled)\ndt_train_score = dt_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"DecisionTree Classifier Training Score: {:.3F}\".format(dt_train_score))\n\n\n# DecisionTreeClassifier evaluated using shuffle-split cross-validation \ndt_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\ndt_val_scores = cross_val_score(dt_model, x_unscaled_version , y_unscaled_version_np, cv=dt_shuffle_split)\nprint(\"DecisionTree Classifier Cross validation Score: {:.3F}\".format(np.mean(dt_val_scores)))","c3525190":"rf_model = RandomForestClassifier(n_estimators=100,\n                                 max_leaf_nodes=15,\n                                 bootstrap=False,\n                                 max_samples=100,\n                                 n_jobs=-1,\n                                 random_state=0)\n\nrf_model.fit(x_train_unscaled , y_train_unscaled)\nrf_train_score = rf_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"Random Forest Training Score: {:.3F}\".format(rf_train_score))\n\n\n# RandomForestClassifier evaluated using shuffle-split cross-validation \nrf_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nrf_val_scores = cross_val_score(rf_model, x_train_unscaled , y_train_unscaled, cv=rf_shuffle_split)\nprint(\"Random Forest Cross validation Score: {:.3F}\".format(np.mean(rf_val_scores)))","78205741":"# Hard Voting \nv_log_clf = LogisticRegression(max_iter=1000, random_state=0)\nv_random_forest = RandomForestClassifier()\nv_svc = SVC(probability=True)\n\n\nhard_voting_model = VotingClassifier(estimators=[(\"lr\",v_log_clf),\n                                            (\"rf\",v_random_forest),\n                                            (\"svc\",v_svc)],\n                               voting='hard')\n\nhard_voting_model.fit(x_train_preprocessed , y_train_preprocessed)\nhard_voting_train_score = hard_voting_model.score(x_train_preprocessed , y_train_preprocessed)\n\nprint(\"Hard Voting Classifiers Training Score: {:.3F}\".format(hard_voting_train_score))\n\n\n# VotingClassifier evaluated using shuffle-split cross-validation \nhard_voting_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nhard_voting_val_scores = cross_val_score(hard_voting_model, x_train_preprocessed , y_train_preprocessed, cv=hard_voting_shuffle_split)\nprint(\"Hard Voting Classifiers Cross validation Score: {:.3F}\".format(np.mean(hard_voting_val_scores)))","4f816c9f":"# Soft Voting\nv_log_clf = LogisticRegression(max_iter=1000, random_state=0)\nv_random_forest = RandomForestClassifier()\nv_svc = SVC(probability=True)\n\n\nsoft_voting_model = VotingClassifier(estimators=[(\"lr\",v_log_clf),\n                                            (\"rf\",v_random_forest),\n                                            (\"svc\",v_svc)],\n                               voting='soft')\n\nsoft_voting_model.fit(x_train_preprocessed , y_train_preprocessed)\nsoft_voting_train_score = soft_voting_model.score(x_train_preprocessed , y_train_preprocessed)\n\nprint(\"Soft Voting Classifiers Training Score: {:.3F}\".format(soft_voting_train_score))\n\n\n# VotingClassifier evaluated using shuffle-split cross-validation \nsoft_voting_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nsoft_voting_val_scores = cross_val_score(soft_voting_model, x_train_preprocessed , y_train_preprocessed, cv=soft_voting_shuffle_split)\nprint(\"Soft Voting Classifiers Cross validation Score: {:.3F}\".format(np.mean(soft_voting_val_scores)))","583340f2":"lr_bagging_model = BaggingClassifier(base_estimator=LogisticRegression(max_iter=1000),\n                                     n_estimators=500,\n                                     bootstrap=True,\n                                     max_samples=100,\n                                     n_jobs=-1,\n                                     random_state=0)\n\nlr_bagging_model.fit(x_train_unscaled , y_train_unscaled)\nlr_bagging_train_score = lr_bagging_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"LogisticRegression Bagging Classifier Training Score: {:.3F}\".format(lr_bagging_train_score))\n\n\n# BaggingClassifier evaluated using shuffle-split cross-validation \nlr_bagging_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nlr_baggign_val_scores = cross_val_score(lr_bagging_model, x_train_unscaled , y_train_unscaled, cv=lr_bagging_shuffle_split)\nprint(\"LogisticRegression Bagging Classifier Cross validation Score: {:.3F}\".format(np.mean(lr_baggign_val_scores)))","496e9c72":"rf_bagging_model = BaggingClassifier(base_estimator=RandomForestClassifier(),\n                                     n_estimators=100,\n                                     bootstrap=True,\n                                     max_samples=100,\n                                     n_jobs=-1,\n                                     random_state=0)\n\nrf_bagging_model.fit(x_train_unscaled , y_train_unscaled)\nrf_bagging_train_score = rf_bagging_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"RandomForest Bagging Classifier Training Score: {:.3F}\".format(rf_bagging_train_score))\n\n\n# BaggingClassifier evaluated using shuffle-split cross-validation \nrf_bagging_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nrf_baggign_val_scores = cross_val_score(rf_bagging_model, x_train_unscaled , y_train_unscaled, cv=rf_bagging_shuffle_split)\nprint(\"RandomForest Bagging Classifier Cross validation Score: {:.3F}\".format(np.mean(rf_baggign_val_scores)))","cbc8d333":"rf_pasting_model = BaggingClassifier(base_estimator=RandomForestClassifier(max_depth=8,\n                                                                             max_leaf_nodes=10,\n                                                                             n_estimators=100,\n                                                                             n_jobs=-1,\n                                                                             random_state=0),\n                                     n_estimators=100,\n                                     bootstrap=False,\n                                     max_samples=100,\n                                     n_jobs=-1,\n                                     random_state=0)\n\nrf_pasting_model.fit(x_train_unscaled , y_train_unscaled)\nrf_pasting_train_score = rf_pasting_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"RandomForest pasting Classifier Training Score: {:.3F}\".format(rf_pasting_train_score))\n\n\n# BaggingClassifier evaluated using shuffle-split cross-validation \nrf_pasting_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nrf_pasting_val_scores = cross_val_score(rf_pasting_model, x_train_unscaled , y_train_unscaled, cv=rf_pasting_shuffle_split)\nprint(\"RandomForest pasting Classifier Cross validation Score: {:.3F}\".format(np.mean(rf_pasting_val_scores)))","59995846":"lr_pasting_model = BaggingClassifier(base_estimator=LogisticRegression(max_iter=1000),\n                                     n_estimators=100,\n                                     bootstrap=False,\n                                     max_samples=100,\n                                     n_jobs=-1,\n                                     random_state=0)\n\nlr_pasting_model.fit(x_train_preprocessed , y_train_preprocessed)\nlr_pasting_train_score = lr_pasting_model.score(x_train_preprocessed , y_train_preprocessed)\n\nprint(\"RandomForest Pasting Classifier Training Score: {:.3F}\".format(lr_pasting_train_score))\n\n\n# BaggingClassifier evaluated using shuffle-split cross-validation \nlr_pasting_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nlr_pasting_val_scores = cross_val_score(lr_pasting_model, x_train_preprocessed , y_train_preprocessed, cv=lr_pasting_shuffle_split)\nprint(\"RandomForest Pasting Classifier Cross validation Score: {:.3F}\".format(np.mean(lr_pasting_val_scores)))","1edd0537":"lr_adaboost_model = AdaBoostClassifier(base_estimator=LogisticRegression(max_iter=1000),\n                                   n_estimators=100,\n                                   learning_rate=0.1,\n                                   algorithm='SAMME.R',\n                                   random_state=0)\n\nlr_adaboost_model.fit(x_train_unscaled , y_train_unscaled)\nlr_adaboost_train_score = lr_adaboost_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"LogisticRegression AdaBoost Classifier Training Score: {:.3F}\".format(lr_adaboost_train_score))\n\n\n# AdaBoostClassifier evaluated using shuffle-split cross-validation \nlr_adaboost_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nlr_adaboost_val_scores = cross_val_score(lr_adaboost_model, x_train_unscaled , y_train_unscaled, cv=lr_adaboost_shuffle_split)\nprint(\"LogisticRegression AdaBoost Classifier Cross validation Score: {:.3F}\".format(np.mean(lr_adaboost_val_scores)))","bcf51e44":"rf_adaboost_model = AdaBoostClassifier(base_estimator=RandomForestClassifier(max_depth=5,\n                                                                             max_leaf_nodes=10,\n                                                                             n_estimators=100,\n                                                                             n_jobs=-1,\n                                                                             random_state=0),\n                                       \n                                       n_estimators=100,\n                                       learning_rate=0.1,\n                                       algorithm='SAMME.R',\n                                       random_state=0)\n\nrf_adaboost_model.fit(x_train_preprocessed , y_train_preprocessed)\nrf_adaboost_train_score = rf_adaboost_model.score(x_train_preprocessed , y_train_preprocessed)\n\nprint(\"RandomForestClassifier AdaBoost Classifier Training Score: {:.3F}\".format(rf_adaboost_train_score))\n\n\n# AdaBoostClassifier evaluated using shuffle-split cross-validation \nrf_adaboost_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\nrf_adaboost_val_scores = cross_val_score(rf_adaboost_model, x_train_preprocessed , y_train_preprocessed, cv=rf_adaboost_shuffle_split)\nprint(\"RandomForestClassifier AdaBoost Classifier Cross validation Score: {:.3F}\".format(np.mean(rf_adaboost_val_scores)))","fc90b065":"g_boosting_model = GradientBoostingClassifier(n_estimators=500,\n                                             learning_rate=0.01,\n                                             random_state=0,\n                                             max_depth=5)\n\ng_boosting_model.fit(x_train_unscaled , y_train_unscaled)\ng_boosting_train_score = g_boosting_model.score(x_train_unscaled , y_train_unscaled)\n\nprint(\"Gradient Boosting Classifier Training Score: {:.3F}\".format(g_boosting_train_score))\n\n\n# GradientBoostingClassifier evaluated using shuffle-split cross-validation \ng_boosting_shuffle_split = StratifiedShuffleSplit(train_size=0.8, test_size=0.2, n_splits=3, random_state=0)\ng_boosting_val_scores = cross_val_score(g_boosting_model, x_train_unscaled , y_train_unscaled, cv=g_boosting_shuffle_split)\nprint(\"Gradient Boosting Classifier Cross validation Score: {:.3F}\".format(np.mean(g_boosting_val_scores)))\n\n# overfitting","a18af760":"cross_val_scores = [kn_val_scores, lr_val_scores,\n                    Linear_svc_val_scores, poly_kernel_val_scores,\n                    rbf_kernel_val_scores, dt_val_scores,\n                    rf_val_scores, hard_voting_val_scores,\n                    soft_voting_val_scores, lr_baggign_val_scores,\n                    rf_baggign_val_scores, rf_pasting_val_scores,\n                    lr_pasting_val_scores, lr_adaboost_val_scores,\n                    rf_adaboost_val_scores, g_boosting_val_scores]","67c7afff":"mean_cross_val_scores = []\n\nfor i in cross_val_scores:\n    mean_cross_val_scores.append(np.mean(i))","fbd2c789":"models = pd.DataFrame({\n    'Model': ['KNeighbors Classifier', 'Logistic Regression',\n             'Linear SVC', 'SVC polynomial kernel', 'SVC RBF kernel',\n             'Decision Tree Classifier', 'Random Forest',\n             'Hard Voting Classifiers', 'Soft Voting Classifiers',\n             'Bagging Classifier using LogisticRegression',\n             'Bagging Classifier using RandomForestClassifier',\n             'Pasting Classifier using RandomForestClassifier',\n             'Pasting Classifier using LogisticRegression',\n             'AdaBoost Classifier using LogisticRegression',\n             'AdaBoost Classifier using RandomForestClassifier',\n             'Gradient Boosting Classifier'],\n    \n    \n    'Training Accuracy': [kn_train_score, lr_train_score,\n                         Linear_svc_train_score, poly_kernel_train_score,\n                         rbf_kernel_train_score, dt_train_score,\n                         rf_train_score, hard_voting_train_score,\n                         soft_voting_train_score, lr_bagging_train_score,\n                         rf_bagging_train_score, rf_pasting_train_score,\n                         lr_pasting_train_score, lr_adaboost_train_score,\n                         rf_adaboost_train_score, g_boosting_train_score],\n    \n    \n    'Cross Validation Accuracy': mean_cross_val_scores})\n\n\nmodels","781b4891":"average_precision_score, roc_auc_score","0538fb44":"Bagging_Classifier_using_RandomForestClassifier_test_acc =  rf_bagging_model.score(x_test_unscaled, y_test_unscaled)\nprint(\"Bagging Classifiernusing RandomForestClassifier Testing Accuracy: {:.3F}\".format(Bagging_Classifier_using_RandomForestClassifier_test_acc))","4033f3f2":"confusion_matrix(y_test_unscaled, rf_bagging_model.predict(x_test_unscaled))","12aa28a2":"True_Positive = 1\nTrue_Negative = 36\nFalse_Positive = 15\nFalse_Negative = 8","799b2621":"Bagging_Classifiernusing_RandomForestClassifier_Precision_score = precision_score(y_test_unscaled,\n                                                                                  rf_bagging_model.predict(x_test_unscaled))\n\nprint(\"Bagging Classifiernusing RandomForestClassifier Precision score: {}\".format(Bagging_Classifiernusing_RandomForestClassifier_Precision_score))","912cb003":"Bagging_Classifiernusing_RandomForestClassifier_Recall_score = recall_score(y_test_unscaled,\n                                                                            rf_bagging_model.predict(x_test_unscaled))\n\nprint(\"Bagging Classifiernusing RandomForestClassifier Recall score: {}\".format(Bagging_Classifiernusing_RandomForestClassifier_Recall_score))","7631670d":"Bagging_Classifiernusing_RandomForestClassifier_F1_score = f1_score(y_test_unscaled,\n                                                                    rf_bagging_model.predict(x_test_unscaled))\n\nprint(\"Bagging Classifiernusing RandomForestClassifier F1 score: {}\".format(Bagging_Classifiernusing_RandomForestClassifier_F1_score))","1c20d172":"Bagging_Classifiernusing_RandomForestClassifier_Average_Precision_score = average_precision_score(y_test_unscaled,\n                                                                                    rf_bagging_model.predict_proba(x_test_unscaled)[:,1])\n\nprint(\"Bagging Classifiernusing RandomForestClassifier Average Precision score: {}\".format(Bagging_Classifiernusing_RandomForestClassifier_Average_Precision_score))","33b73df3":"Bagging_Classifiernusing_RandomForestClassifier_ROC_AUC_score = roc_auc_score(y_test_unscaled,\n                                                                                rf_bagging_model.predict_proba(x_test_unscaled)[:,1])\n\nprint(\"Bagging Classifiernusing RandomForestClassifier ROC AUC Score: {}\".format(Bagging_Classifiernusing_RandomForestClassifier_ROC_AUC_score))","b7ee93b5":"soft_Voting_Classifiers_test_acc =  soft_voting_model.score(x_test_preprocessed, y_test_preprocessed)\nprint(\"Soft Voting Classifiers Testing Accuracy: {:.3F}\".format(soft_Voting_Classifiers_test_acc))","6d8134fb":"confusion_matrix(y_test_preprocessed, soft_voting_model.predict(x_test_preprocessed))","8b3d3b4d":"True_Positive = 15\nTrue_Negative = 35\nFalse_Positive = 2\nFalse_Negative = 8","7e7397a6":"Soft_Voting_Classifiers_Precision_score = precision_score(y_test_preprocessed,\n                                                          soft_voting_model.predict(x_test_preprocessed))\n\nprint(\"Soft Voting Classifiers Precision score: {}\".format(Soft_Voting_Classifiers_Precision_score))","d83fbb4d":"Soft_Voting_Classifiers_Recall_score = recall_score(y_test_preprocessed,\n                                                    soft_voting_model.predict(x_test_preprocessed))\n\nprint(\"Soft Voting Classifiers Recall score: {}\".format(Soft_Voting_Classifiers_Recall_score))","aebc1a97":"Soft_Voting_Classifiers_F1_score = f1_score(y_test_preprocessed,\n                                            soft_voting_model.predict(x_test_preprocessed))\n\nprint(\"Soft Voting Classifiers F1 score: {}\".format(Soft_Voting_Classifiers_F1_score))","587c232e":"Soft_Voting_Classifiers_Average_Precision_score = average_precision_score(y_test_preprocessed,\n                                                                   soft_voting_model.predict_proba(x_test_preprocessed)[:,1])\n\nprint(\"Soft Voting Classifiers Average Precision score: {}\".format(Soft_Voting_Classifiers_Average_Precision_score))","c1a71649":"Soft_Voting_Classifiers_ROC_AUC_score = roc_auc_score(y_test_preprocessed,\n                                                      soft_voting_model.predict_proba(x_test_preprocessed)[:,1])\n\nprint(\"Soft Voting Classifiers ROC AUC Score: {}\".format(Soft_Voting_Classifiers_ROC_AUC_score))","7e6f06b8":"AdaBoost_Classifier_using_RandomForestClassifier_test_acc =  rf_adaboost_model.score(x_test_preprocessed, y_test_preprocessed)\nprint(\"AdaBoost Classifier using RandomForestClassifier Testing Accuracy: {:.3F}\".format(AdaBoost_Classifier_using_RandomForestClassifier_test_acc))","7d65eb38":"confusion_matrix(y_test_preprocessed, rf_adaboost_model.predict(x_test_preprocessed))","a170af32":"True_Positive = 14\nTrue_Negative = 34\nFalse_Positive = 3\nFalse_Negative = 9","5485d1e4":"AdaBoost_Classifier_using_RandomForestClassifier_Precision_score = precision_score(y_test_preprocessed,\n                                                                              rf_adaboost_model.predict(x_test_preprocessed))\n\nprint(\"AdaBoost Classifier using RandomForestClassifier Precision score: {}\".format(AdaBoost_Classifier_using_RandomForestClassifier_Precision_score))","7f0f4e00":"AdaBoost_Classifier_using_RandomForestClassifier_Recall_score = recall_score(y_test_preprocessed,\n                                                                            rf_adaboost_model.predict(x_test_preprocessed))\n\nprint(\"AdaBoost Classifier using RandomForestClassifier Recall score: {}\".format(AdaBoost_Classifier_using_RandomForestClassifier_Recall_score))","23485c3c":"AdaBoost_Classifier_using_RandomForestClassifier_F1_score = f1_score(y_test_preprocessed,\n                                                                   rf_adaboost_model.predict(x_test_preprocessed))\n\nprint(\"AdaBoost Classifier using RandomForestClassifier F1 score: {}\".format(AdaBoost_Classifier_using_RandomForestClassifier_F1_score))","ca36277d":"AdaBoost_Classifier_using_RandomForestClassifier_Average_Precision_score = average_precision_score(y_test_preprocessed,\n                                                                   rf_adaboost_model.predict_proba(x_test_preprocessed)[:,1])\n\nprint(\"AdaBoost Classifier using RandomForestClassifier Average Precision score: {}\".format(AdaBoost_Classifier_using_RandomForestClassifier_Average_Precision_score))","f11bc7e1":"AdaBoost_Classifier_using_RandomForestClassifier_ROC_AUC_score = roc_auc_score(y_test_preprocessed,\n                                                         rf_adaboost_model.predict_proba(x_test_preprocessed)[:,1])\n\n\nprint(\"AdaBoost Classifier using RandomForestClassifier ROC AUC Score: {}\".format(AdaBoost_Classifier_using_RandomForestClassifier_ROC_AUC_score))","042bd27e":"models = pd.DataFrame({\n    'Model': ['Soft Voting Classifiers', \n             'Bagging Classifier using RandomForestClassifier',\n             'AdaBoost Classifier using RandomForestClassifier'],\n    \n    'Testset Accuracy': [soft_Voting_Classifiers_test_acc,\n                        Bagging_Classifier_using_RandomForestClassifier_test_acc,\n                        AdaBoost_Classifier_using_RandomForestClassifier_test_acc],\n    \n    \n    'Precision Score': [Soft_Voting_Classifiers_Precision_score,\n                       Bagging_Classifiernusing_RandomForestClassifier_Precision_score,\n                       AdaBoost_Classifier_using_RandomForestClassifier_Precision_score],\n    \n    \n    'Recall': [Soft_Voting_Classifiers_Recall_score,\n              Bagging_Classifiernusing_RandomForestClassifier_Recall_score,\n              AdaBoost_Classifier_using_RandomForestClassifier_Recall_score],\n\n\n    'F1 score':[Soft_Voting_Classifiers_F1_score,\n               Bagging_Classifiernusing_RandomForestClassifier_F1_score,\n               AdaBoost_Classifier_using_RandomForestClassifier_F1_score],\n    \n\n    'Average Precision Score':[Soft_Voting_Classifiers_Average_Precision_score,\n                              Bagging_Classifiernusing_RandomForestClassifier_Average_Precision_score,\n                              AdaBoost_Classifier_using_RandomForestClassifier_Average_Precision_score],\n    \n\n    'ROC AUC Score': [Soft_Voting_Classifiers_ROC_AUC_score,\n                     Bagging_Classifiernusing_RandomForestClassifier_ROC_AUC_score,\n                     AdaBoost_Classifier_using_RandomForestClassifier_ROC_AUC_score]})\n\n\nmodels","c4674337":"print(classification_report(y_test_unscaled,\n                           rf_bagging_model.predict(x_test_unscaled)))","d3840d20":"print(classification_report(y_test_unscaled,\n                           rf_bagging_model.predict_proba(x_test_unscaled)[:,1] > 0.15))","01d89af0":"confusion_matrix(y_test_unscaled, rf_bagging_model.predict_proba(x_test_unscaled)[:,1] > 0.15)","7fe50c62":"Bagging_Classifier_using_RandomForestClassifier_test_acc =  rf_bagging_model.score(x_test_unscaled, rf_bagging_model.predict_proba(x_test_unscaled)[:,1] > 0.6)\nprint(\"Bagging Classifiernusing RandomForestClassifier Testing Accuracy: {:.3F}\".format(Bagging_Classifier_using_RandomForestClassifier_test_acc))","dd0c9b40":"### RBF kernel","49c1453e":"## 2- Soft Voting Classifiers","357669f7":"And by tweking the threshold we get a 88.3% testset accuracy!!!","620733ab":"# preparing the data","8664d457":"### see  https:\/\/www.kaggle.com\/general\/253592\n### to understand the Ensemble Learning","425bfd1b":"## 1- KNeighbors Classifier","2185dd75":"# Prediction models training and evaluation","b67a74c6":"### Voting Classifiers","1f897d4f":"## 6- Ensemble Methods","3c588609":"Setting the threshold to 0.15 give us 100% Recall and every infected  in correctly classified but \n14 uninfected  persons incorrecltly classified as infected its ok in this kind of projects they will go \nthought more tests.\n\nBut if these more test is expensive, you can make a trade off between the precision  and the recall by\nchanging the threshold.","d35b5ce0":"## 2-  Logistic Regression","da9eaf68":"## 4- SVC","b561396a":"# Choosing the metrics","0804adbc":"## 3- LinearSVC","0e2e2627":"# Bagging Classifier using RandomForestClassifier, Soft Voting Classifiers, AdaBoost Classifier using RandomForestClassifier, will used for more testing ","82b1b071":"## 5- DecisionTree Classifier","c5d6774e":"#### pasting","d53279c6":"As we can see the numeric data form some classifiers  such as the SVC needs to be scaled\nso I will prepare tow versions of the dataset one with scaled dataset and one hot encode \nthe categorical variables and the other version is not ","28763192":"## 3- AdaBoost Classifier using RandomForestClassifier","123b6811":"### AdaBoost","f55cc47d":"## Boosting","6c233c2f":"If we choose the accuracy to be our metric it will give us optimistic results even if the classifier doesn't work well\nI will use the `confusion matrics`, `ROC`, `average_precision`, and `ROC_AUC` to evaluat the performance of the clasifier\nafter trying different classification algorithms on accuracy.  ","6d84c37f":"# Choosing the best Classifiers and manipulating threshold ","947b654f":"### - I did not used python for loops, functions, or classes Because If someone wants to read this notebook and he\/she is a beginner  in python  it will be easy for him\/her to understand. There will be a repeated code for each model.\n\n\n### - I used full name for variables to make this notebook more readable and to facilitate the follow-up of the sequence of modeling.","a90fd0bb":"## Unscaled data","890d8f67":"## 1- Bagging Classifier using RandomForestClassifier","3b7cc045":"### see https:\/\/www.kaggle.com\/general\/253378 \n### to learn how to deal with Imbalanced Dataset Metrics in binary classification problems","602649cc":"#### bagging","4b3c8897":"### Random Forest","50ba1ab6":"# take a look at the data","aec5d95d":"## Scaled data","b27e4c2f":"### bagging and Pasting","9d487948":"### polynomial kernel","a9d37483":"# summarizing the models Accuracies","8cfe966e":"### GradientBoostingClassifier","667fcbd7":"In this kind of projects we want all the infected persons to be correctly classified \neven if the uninfected persons classified as infected  they will go through more tests."}}