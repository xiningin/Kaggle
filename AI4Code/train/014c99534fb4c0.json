{"cell_type":{"22e7a8ca":"code","daab15b7":"code","3a8be1e9":"code","145f9b10":"code","ef071475":"code","60adbd3b":"code","fecf7f69":"code","efaf2b87":"code","88c53036":"code","e5b9e12f":"code","0f343ae0":"code","eefd1dd4":"code","75b36324":"code","d94041a0":"code","7b1a72d0":"code","7ce57c20":"code","caeafadc":"code","04245659":"code","b8fb989e":"code","5140639f":"code","b9188b33":"code","0990e841":"code","ac6fe048":"code","fdeec5c4":"code","d9f665e6":"code","4d2aa191":"code","e13dea96":"code","98b86f3b":"code","9cf362f5":"code","5d81e5fe":"code","0dd07a96":"code","40d99b93":"code","8df7f001":"code","b84e9680":"code","7ed55786":"code","1d77eda5":"code","d70cc57a":"code","6983fe5b":"code","b0430562":"code","d1e587d5":"code","3831f0f5":"code","da83ad0f":"code","2575f5f7":"markdown","7efe1341":"markdown","d9d6ff0a":"markdown","ef52b793":"markdown","c4afadcf":"markdown","c39bf0a6":"markdown","a93214f2":"markdown","1bae1b32":"markdown","85cac6f3":"markdown","b8da6706":"markdown","64c53551":"markdown"},"source":{"22e7a8ca":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","daab15b7":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","3a8be1e9":"train = pd.read_csv(\"..\/input\/metro-bike-share-trip-data.csv\")","145f9b10":"print ('There are',len(train.columns),'columns:')\nfor x in train.columns:\n    print(x+' ',end=',')","ef071475":"train.head()","60adbd3b":"train.tail()","fecf7f69":"print(\"Number of columns (features) in the given dataset is :\",train.shape[1])\nprint(\"Number of rows (entries) in the given dataset is :\",train.shape[0])","efaf2b87":"train.info()","88c53036":"train_na = (train.isnull().sum()*100)\/len(train)\nprint(\"Percentage of Missing Data in each feature:\")\ntrain_na.sort_values(ascending=False)","e5b9e12f":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","0f343ae0":"train = train.dropna()","eefd1dd4":"fig, ax = plt.subplots()\nax.scatter(train['Passholder Type'], train['Duration'])\nplt.ylabel('Duration (in seconds)', fontsize=13)\nplt.xlabel('PassHolder Type', fontsize=13)\nplt.show()","75b36324":"l = []\nimport math \ndegrees_to_radians = math.pi\/180.0\ndef distance_on_unit_sphere(lat1, long1, lat2, long2):\n    phi1 = (90.0 - lat1)*degrees_to_radians\n    phi2 = (90.0 - lat2)*degrees_to_radians\n    \n    theta1 = long1*degrees_to_radians\n    theta2 = long2*degrees_to_radians\n    \n    a = ((math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2)) +(math.cos(phi1)*math.cos(phi2)))\n    if a>1:\n        a=0.999999\n    dis = math.acos( a )\n    return dis*6373\nfor i in range(97825):\n    l.append(distance_on_unit_sphere(train['Starting Station Latitude'].iloc[i],\n                                     train['Starting Station Longitude'].iloc[i],\n                                     train['Ending Station Latitude'].iloc[i],\n                                     train['Ending Station Longitude'].iloc[i]))","d94041a0":"temp = pd.DataFrame(data=[train['Duration'],\n                               train['Starting Station Latitude'],\n                               train['Starting Station Longitude'],\n                               train['Ending Station Latitude'],\n                               train['Ending Station Longitude'],\n                               train['Plan Duration']],\n                               index=['Duration',\n                                      'Starting Station Latitude',\n                                      'Starting Station Longitude',\n                                      'Ending Station Latitude',\n                                      'Ending Station Longitude',\n                                      'Plan Duration'])","7b1a72d0":"distance = pd.DataFrame({'Distance':l})","7ce57c20":"new_train = temp.T","caeafadc":"print(\"Shape of new train \",new_train.shape)\nprint (\"Shape of distance \",distance.shape)","04245659":"new_train = new_train.reset_index(drop=True)","b8fb989e":"new_train = pd.concat([distance,\n                       new_train,\n                       pd.get_dummies(data=train['Passholder Type']).reset_index(),\n                       pd.get_dummies(data=train['Trip Route Category'],drop_first=True).reset_index()],\n                       axis=1)","5140639f":"new_train = new_train.drop('index',axis=1)\nnew_train.info()","b9188b33":"print(\"There are 3 different types of Passholder : \")\ntrain['Passholder Type'].value_counts()","0990e841":"X1 = new_train.drop('Walk-up',axis=1)\ny1 = new_train['Walk-up']","ac6fe048":"X_train,X_test,y_train,y_test = train_test_split(X1,y1,test_size=0.33)","fdeec5c4":"lr = LogisticRegression()","d9f665e6":"lr.fit(X_train,y_train)","4d2aa191":"pred1 = lr.predict(X_test)","e13dea96":"print(classification_report(y_test,pred1))","98b86f3b":"print(confusion_matrix(y_test,pred1))","9cf362f5":"X2 = new_train.drop('Monthly Pass',axis=1)\ny2 = new_train['Monthly Pass']\nX_train,X_test,y_train,y_test = train_test_split(X2,y2,test_size=0.33)","5d81e5fe":"from sklearn.ensemble import RandomForestClassifier","0dd07a96":"clf = RandomForestClassifier()","40d99b93":"clf.fit(X_train,y_train)","8df7f001":"pred2 = clf.predict(X_test)\n# pred2 = clf2.predict(X_test)","b84e9680":"print(classification_report(y_test,pred2))","7ed55786":"print(confusion_matrix(y_test,pred2))","1d77eda5":"X3 = new_train.drop('Flex Pass',axis=1)\ny3 = new_train['Flex Pass']\nX_train,X_test,y_train,y_test = train_test_split(X3,y3,test_size=0.33)","d70cc57a":"from sklearn.tree import DecisionTreeClassifier","6983fe5b":"clf2 = DecisionTreeClassifier()","b0430562":"clf2.fit(X_train,y_train)","d1e587d5":"pred3 = clf2.predict(X_test)","3831f0f5":"print(classification_report(y_test,pred3))","da83ad0f":"print(confusion_matrix(y_test,pred3))","2575f5f7":"# DATA EXPLORATION","7efe1341":"# LOADING LA METRO-BIKE-SHARE-TRIP-DATASET","d9d6ff0a":"# IMPORTING LIBRARIES","ef52b793":"# USING LOGISTIC REGRESSION TO PREDICT WHETHER PASSHOLDER TYPE IS \"Walk-up\" OR \"Not\"","c4afadcf":"Creating a new dataframe distance having the newly calculated distances under the Distance column","c39bf0a6":"# USING RANDOM FOREST CLASSIFIER TO PREDICT WHETHER THE PASSHOLDER TYPE IS \"Monthly Pass\" OR \"Not\"","a93214f2":"# USING DECISION TREE CLASSIFIER TO PREDICT WHETHER THE PASSHOLDER TYPE IS \"Flex Pass\" OR \"Not\"","1bae1b32":"At Last our models are 100% correct in predicting the type of PassHolders.\nLogisticRegression for Walk-up type , RandomForestClassifier for Monthly Pass and DecisionTreeClassifier for FlexPass models  predicted all the correct values for the type of pass.\nPlease help me in adding some data visualization part by forking the notebook..\nIf you find the notebook worthy then please do upvote it.","85cac6f3":"# DISTANCE CALCULATION\nUsing the Starting Station Latitude and Longitude and Ending Station Latitude and Longitude we can calculate the distance travelled by the user. This extra feature calculated can be used to fit into the model as it can help in improving the predicting ability of the model.","b8da6706":"Adding all the important features to a temporary dataframe temp ","64c53551":"# DROPPING NULL VALUES.\nSince the dataset features such as Starting Station ID,Starting Station Latitude,Starting Station Longitude,Ending Station ID,Ending Station Latitude ,Ending Station Longitude,Bike ID ,Plan Duration,Starting Lat-Long,Ending Lat-Long contains some null values. So before moving on further with the dataset we need to drop null values so that these null values can create problems while moving forward."}}