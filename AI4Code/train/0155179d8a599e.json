{"cell_type":{"5d160e5b":"code","e001adc2":"code","a4e35d87":"code","7d43fabf":"code","c012f351":"code","48c33935":"code","19908035":"code","9e5eed37":"code","1fe9874c":"code","a2670d34":"code","d77b2831":"code","79b989e0":"code","765b38db":"code","21ff1a89":"code","19218baf":"code","f1d8a9e4":"code","bac8d2e3":"code","66f35102":"code","b51dc226":"code","caeb4865":"code","0ed95cd1":"code","d7547106":"code","974170c2":"code","49855e96":"code","ee32e61d":"code","bb887423":"code","d7538ee4":"code","2e2a8074":"code","c442410d":"markdown","fce9ca0a":"markdown"},"source":{"5d160e5b":"import os\nimport cv2\nimport random\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","e001adc2":"train_dir = '..\/input\/train\/'\ntest_dir = '..\/input\/test\/'","a4e35d87":"train_images = [train_dir + i for i in os.listdir(train_dir)]\ntrain_cats = [train_dir + i for i in os.listdir(train_dir) if 'cat' in i]\ntrain_dogs = [train_dir + i for i in os.listdir(train_dir) if 'dog' in i]\n\ntest_images =  [test_dir + i for i in os.listdir(test_dir)]","7d43fabf":"print('the number of total train images:',len(train_images))\nprint('the number of train cats images:',len(train_cats))\nprint('the number of train dogs images:',len(train_dogs))\nprint('the number of total test images:',len(test_images))","c012f351":"random.seed(100)\n\noriginal_train_images = train_dogs[:12000] + train_cats[:12000]\n\nevaluation_images = train_dogs[12000:12500] + train_cats[12000:12500]\n\nrandom.shuffle(evaluation_images)\nrandom.shuffle(original_train_images)\n\nsection = int(len(original_train_images) * 0.75)\n\ntrain_images = original_train_images[:section]\nvalidation_images = original_train_images[section:]","48c33935":"print(len(train_images))\nprint(len(validation_images))","19908035":"# imgsize = 150\n# channels = 3\n\n# def read_images(one_img):\n#     img = cv2.imread(one_img,cv2.IMREAD_ANYCOLOR)\n#     img_arr = cv2.resize(img,(imgsize,imgsize),interpolation=cv2.INTER_CUBIC)\n#     img_arr = img_arr \/ 255.0\n#     return img_arr","9e5eed37":"# im = read_images(tr_images[0])\n# plt.imshow(im)","1fe9874c":"\n# def pre_data(images):\n#     lens = len(images)\n#     data = np.ndarray((lens,imgsize,imgsize,channels), dtype=np.uint8)\n    \n#     for i, img_file in enumerate(images):\n#         image = read_images(img_file)\n#         label = np.where('dog' in tr_images[i],1,0)\n#         data[i] = image\n        \n#     return data","a2670d34":"from keras.preprocessing import image\n\nimgsize = 150\nchannels = 3\n\ndef prep_data(images):\n    count = len(images)\n    X = np.ndarray((count, imgsize, imgsize, channels), dtype=np.float32)\n    y = np.zeros((count,), dtype=np.float32)\n    \n    for i, image_file in enumerate(images):\n        img = image.load_img(image_file, target_size=(imgsize, imgsize))\n        X[i] = image.img_to_array(img)\n        if 'dog' in image_file:\n            y[i] = 1.\n        if i%1000 == 0: print('Processed {} of {}'.format(i, count))\n    \n    return X, y","d77b2831":"X_train, y_train = prep_data(train_images)","79b989e0":"print(\"Train shape: \",X_train.shape)\nprint(\"Train shape: \",y_train.shape)","765b38db":"X_validation, y_validation = prep_data(validation_images)","21ff1a89":"train_datagen = image.ImageDataGenerator(\n    rescale=1.\/255,\n    rotation_range=40,\n    width_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True,)\n\nvalidation_datagen = image.ImageDataGenerator(rescale=1.\/255)","19218baf":"BATCH_SIZE = 128\n\ntrain_generator = train_datagen.flow(\n    X_train,\n    y_train,\n    batch_size=BATCH_SIZE)\n\nvalidation_generator = validation_datagen.flow(\n    X_validation,\n    y_validation,\n    batch_size=BATCH_SIZE)","f1d8a9e4":"from keras.layers import Dense,Conv2D,MaxPooling2D,Dropout,Flatten\nfrom keras.optimizers import RMSprop\nfrom keras.models import Sequential\n\nmodel = Sequential()\n\nmodel.add(Conv2D(32,(3,3),activation = 'relu',input_shape = (imgsize,imgsize,channels)))\nmodel.add(MaxPooling2D((2,2)))\n\n\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1, activation='sigmoid'))\n\nmodel.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])\n","bac8d2e3":"# model = Sequential()\n\n# model.add(Conv2D(32, (3, 3), activation='relu', input_shape=train.shape[1:]))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.5))\n\n# model.add(Conv2D(64, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.5))\n\n# model.add(Conv2D(128, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.5))\n\n# model.add(Conv2D(256, (3, 3), activation='relu'))\n# model.add(MaxPooling2D(pool_size=(2, 2)))\n# model.add(Dropout(0.5))\n\n# model.add(Flatten())\n# model.add(Dense(512, activation='relu'))\n# model.add(Dropout(0.5))\n\n# model.add(Dense(1, activation='sigmoid'))\n\n# model.compile(optimizer=RMSprop(lr=1e-4), loss='binary_crossentropy', metrics=['accuracy'])","66f35102":"model.summary()","b51dc226":"train_steps = len(train_images)\/BATCH_SIZE\nvalidation_steps = len(validation_images)\/BATCH_SIZE\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_steps,\n    epochs=100,\n    validation_data=validation_generator,\n    validation_steps=validation_steps,\n    verbose=1)","caeb4865":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nval_acc = history.history['val_acc']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1,len(acc)+1)\nplt.plot(epochs,acc,'bo',label = 'Training acc')\nplt.plot(epochs,val_acc,'b',label = 'Validation acc')\nplt.title('Training and Validation accuracy')\nplt.xlabel('epoch')\nplt.ylabel('accuracy')\nplt.legend()\n\nplt.figure()\n\nepochs = range(1,len(acc)+1)\nplt.plot(epochs,loss,'bo',label = 'Training loss')\nplt.plot(epochs,val_loss,'b',label = 'Validation loss')\nplt.title('Training and Validation loss')\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.legend()\n\nplt.show()","0ed95cd1":"model.save('dogs-v-cat-data-1.h5')","d7547106":"import json\nwith open('dogs-v-cat-data-1.h5-history.json', 'w') as f:\n    json.dump(history.history, f)","974170c2":"X_evaluation, y_evaluation = prep_data(evaluation_images)\nX_evaluation \/= 255","49855e96":"evaluation = model.evaluate(X_evaluation, y_evaluation)","ee32e61d":"evaluation","bb887423":"X_test, _ = prep_data(test_images)\nX_test \/= 255.","d7538ee4":"predictions = model.predict(X_test)","2e2a8074":"for i in range(0,10):\n    if predictions[i, 0] >= 0.5: \n        print('I am {:.2%} sure this is a Dog'.format(predictions[i][0]))\n    else: \n        print('I am {:.2%} sure this is a Cat'.format(1-predictions[i][0]))\n        \n    plt.imshow(image.array_to_img(X_test[i]))\n    plt.show()","c442410d":"**Model**","fce9ca0a":"Prepare data"}}