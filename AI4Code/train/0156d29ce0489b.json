{"cell_type":{"7f3636a5":"code","77a30199":"code","6d441377":"code","47eb56fa":"code","18ba9a31":"code","2d78641d":"code","b7c1a21a":"code","c5c71bcf":"code","da7a5944":"code","2b563f44":"code","87a54749":"code","f0bfa510":"code","d4330f36":"code","bb098cd8":"code","efd258d7":"code","0e275bc6":"code","3a6e5d47":"code","d8ac4431":"code","a60d0caf":"code","1a3ca17c":"code","d998fd0e":"code","823788e1":"code","7c9db0c9":"code","ffb9e232":"code","0fa23472":"code","2b5bb528":"code","6e1e29ea":"code","31c91b98":"code","d4f09a56":"code","a5c832ea":"code","b4425ecc":"code","c35e0634":"code","12260c3c":"code","de6f36bd":"code","542d9c72":"code","27b3680f":"code","4044da72":"code","f3e7b5c5":"code","3e19be17":"code","66de7f8d":"code","004a2d72":"code","54f0b97b":"code","c1f3cccd":"code","91cbcc8e":"code","aa58b81d":"code","a29b2018":"code","03095fe2":"code","9679c0c3":"code","8b28dd41":"code","63372264":"code","555e98af":"code","d0e40c23":"code","6a7bff51":"code","c843be9f":"code","44003a88":"code","f5553342":"code","ea2be8af":"code","58b83840":"code","d763a526":"code","80fe99d7":"code","0e40e3fb":"code","3f6f03bb":"code","5dccd5f8":"code","13cfb2a8":"code","ba419a2d":"code","a65c30dd":"code","779d097a":"code","bb27c86c":"code","f153cb8e":"code","481fca15":"code","055a731c":"code","0b4d5d3d":"code","ff23f59c":"code","5b0d8385":"code","7178fc3d":"code","40d38494":"code","4346629d":"code","cb58705d":"code","7ab4c8d7":"code","4ecf4b79":"code","e4693507":"code","c8841766":"code","4123f525":"code","9ec33095":"code","ee2b12b2":"code","cbdf4210":"code","ebc61454":"code","a9f05ab4":"code","d58d3d4a":"code","9756e1a4":"code","9b86df1c":"code","ac0d5125":"code","da39dc68":"code","fa110808":"code","2bbfb343":"code","dae39d74":"code","fd4380fc":"code","2878b02f":"code","bd6549ae":"code","83805294":"code","dfb876ba":"code","89b13b73":"code","9db01bfd":"code","81d2f8f0":"code","65689a62":"code","ff8a84f4":"code","28eb21b9":"code","2dae1c4a":"code","0c2cb942":"code","1007e9d3":"code","8aded9dc":"code","98be30cc":"code","43f065c6":"code","393a0f06":"code","bef39853":"code","9bc8c4d8":"code","a9ac70d4":"code","6278fe61":"code","8f16c2e0":"code","7c5409a1":"code","d26fa018":"code","b7b39a0c":"code","ce076975":"code","24f2e3a6":"code","05382168":"code","e32ef8ea":"code","f43d017a":"code","c77528cd":"code","d2bbbac0":"code","6545606f":"code","c837dc60":"code","744269e4":"code","45407805":"code","5b199a95":"code","2ef30ce1":"code","f40d1768":"code","2ee09a78":"code","24d2e949":"code","4effea77":"code","12d8d95c":"code","b9d9b517":"code","5ef2258f":"code","48a3f1ec":"code","22c7c385":"code","be8c9c83":"code","80a3e83d":"code","44187b05":"code","bd4361a0":"code","95785312":"code","65fee009":"code","e64004d6":"code","7fc0787b":"code","5d36a9d5":"code","b14058b1":"code","e9dbb156":"code","62aa9c3b":"code","e5ce8219":"code","f786c22d":"code","f472d858":"code","49b615af":"code","2af78f81":"code","6ca8cbdc":"code","95a46163":"code","36a7603d":"code","5ce1a735":"code","25baceb2":"code","9468a5fd":"code","ee047e9f":"code","1e3038ce":"code","0b6d2bdb":"code","e92e9ef1":"code","594fb327":"code","ce6345bb":"code","16278e4f":"code","ef44eab7":"code","e054b81a":"markdown","04ba4946":"markdown","ef7e2599":"markdown","2b379da9":"markdown","2f4455b1":"markdown","c5e54019":"markdown","391bbc2c":"markdown","6bbb7d6a":"markdown","1986d2e3":"markdown","91e8759b":"markdown","ea7dd214":"markdown","59ca445e":"markdown","c5bcffb7":"markdown","7484097d":"markdown","455a939e":"markdown","15bac8ac":"markdown","e4dcba35":"markdown","10284ea0":"markdown","832e24cf":"markdown","d2c9444a":"markdown","aa905f4c":"markdown","db09a4af":"markdown","cdc58e8a":"markdown","1a64ed3c":"markdown","a79ccbea":"markdown","230c6ef1":"markdown","1811505a":"markdown","b2a6ef46":"markdown","e3ceb458":"markdown","50b3fbbd":"markdown","182102a0":"markdown","55740aae":"markdown","d4a4e2a0":"markdown","576bf148":"markdown","0b977994":"markdown","9ab0803a":"markdown","4aec2057":"markdown","3e5f2651":"markdown","1b196788":"markdown","dae2a673":"markdown","21928d41":"markdown","74258f18":"markdown","4a30468b":"markdown","cd530c3c":"markdown","bd5b2df1":"markdown","1b53d149":"markdown","05e64091":"markdown","13663962":"markdown","1f75b2f5":"markdown","87581108":"markdown","a5127f0a":"markdown","fffbf70d":"markdown","dc48ea57":"markdown","645ab36b":"markdown","1303ff29":"markdown","6bfe679d":"markdown","84d1e0ca":"markdown","f8a4cbd2":"markdown","83603c62":"markdown","e25696b4":"markdown","b3ce8c90":"markdown","451504c2":"markdown","16e9e7d8":"markdown","8803f7d7":"markdown","88d98933":"markdown","934a0b48":"markdown","0d2ab6f9":"markdown","3b258ca7":"markdown","948dd4d3":"markdown","ad861251":"markdown","94c0041e":"markdown","a5323bd1":"markdown","dbced1d6":"markdown","c0d57b5e":"markdown","eee37a04":"markdown","03d933e5":"markdown","a9fca727":"markdown","a3c60b96":"markdown","ca3cc8ef":"markdown","8b16ead9":"markdown","af80d3a8":"markdown","9e28ae19":"markdown","da6c5588":"markdown","6853789f":"markdown","86ee94d1":"markdown","84f3a4e6":"markdown","be815dfa":"markdown","cf2a441d":"markdown","42f3cb89":"markdown","1badd9dc":"markdown","e3960aee":"markdown","757a1179":"markdown","35c34f49":"markdown","998b5091":"markdown","b2fc03cd":"markdown","c6007048":"markdown","c2807201":"markdown","2ac10e20":"markdown","54c6c697":"markdown","bb777492":"markdown","77522fdf":"markdown","cc0f046a":"markdown","4aedf2ca":"markdown","01340fd0":"markdown","d8dcf77f":"markdown","ab108212":"markdown","3a706c36":"markdown","3856d8e6":"markdown","3c55b413":"markdown","306824ed":"markdown","b79a079c":"markdown","39addcac":"markdown","427b3324":"markdown","c7b8c804":"markdown","3860f1fa":"markdown","cba475f9":"markdown","ded720e8":"markdown","965c2a6b":"markdown","caad0996":"markdown","bb950198":"markdown","a1893bf9":"markdown","97d8bf26":"markdown","8f1eeb5a":"markdown","db799f62":"markdown","db66620c":"markdown","7c829636":"markdown","93decbd1":"markdown","f1e6bfe8":"markdown","ec3c1353":"markdown","5abc6615":"markdown","535cbf23":"markdown"},"source":{"7f3636a5":"import os\nimport re\nimport sys\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\n# import poltly.io as pio\nimport plotly.express as px\nimport plotly.figure_factory as ff\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nfrom plotly.offline import init_notebook_mode, iplot\n# init_notebook_mode(connected=True)\n# pio.templates.default = \"none\"\n","77a30199":"# Loading Original Data\nkag_surv_2021 = pd.read_csv('..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv')\n\n\n# Making copy of original data\ndata = kag_surv_2021.copy()","6d441377":"data.head()","47eb56fa":"data.tail()","18ba9a31":"df = data.copy().drop(0, axis = 0)\n\n# Stripping Whitespaces\nfor col in df.columns:\n    df[col] = df[col].str.strip()\n","2d78641d":"\ndef clean(data,Question,n):\n    \"\"\"\n    Get counts of Attributes from features and returns Dataframe with Counts\n    \"\"\"\n    x = []\n    for i in range(1,n):\n        x.append(Question+str(i))\n    x.append(str('Q7_OTHER'))\n\n    ddict = {}\n    for i in x:\n        ddict[data[i].value_counts().keys()[0]]=data[i].value_counts()[0]\n    re = pd.DataFrame(ddict.items())\n    re.iloc[:,-1] = re.iloc[:,-1].astype('int32')\n    re.columns = ['Tools','Counts']\n    return re\n","b7c1a21a":"def counts(df):\n    \n    \"\"\" \n    Combines all columns in dataframe.\n    Strip Whitespaces from from both edges and also removes internal whitespaces.\n    then Counts words from string.\n    \n    return Dataframe.\n    \"\"\"\n    # Joining the columns as one\n    new_df = df.where(df.ne('nan')).fillna('').agg(' '.join, axis = 1).to_frame('Tools')\n    \n    # Removing Whitespaces from Edges\n    new_df['Tools'] = new_df['Tools'].str.strip()\n    \n    # Replacing internal whitespaces with ','\n    new_df['Tools'] = new_df['Tools'].apply(lambda x: re.sub('\\s+', ', ', x))\n    \n    # Replacing '' with 'None'\n    new_df['Tools'] = new_df['Tools'].replace('', 'None')\n    \n    # Counting strings\n    new_df['Counts'] = new_df['Tools'].apply(lambda n: len(n.split(', ')))\n    \n    # Droping None values from \"Feature\"\n    new_df = new_df[new_df['Tools']!= 'None']\n    \n    return new_df\n","c5c71bcf":"def RemoveSpaceBetStrings(df):\n    \n    \"\"\"\n    Replace whitespaces between two words with \"_\"\n    \"\"\"\n    for col in df.columns:\n        df[col] = df[col].str.strip().str.replace(\" \/ \", \"_\")\n        df[col] = df[col].str.strip().str.replace(\" \", \"_\")\n    \n    return df","da7a5944":"age_val = round(df['Q1'].value_counts(normalize= False)*100,2).reset_index().rename(\n                                    index=str,columns={'index': 'Age_Group', 'Q1':'Frequency'}\n).sort_values(by = 'Age_Group')\n\n# Age Group Pie Chart\nfig = px.pie(age_val, values='Frequency', names='Age_Group', title='Kagglian Age Group Distribution')\nfig.show()","2b563f44":"gen = round(df['Q2'].value_counts(normalize= False)*100,2).reset_index().rename(\n                                    index=str,columns={'index': 'Gender', 'Q2':'Frequency'})#.sort_values(by = 'Age_Group')\n\n# Gender Distribution Pie Chart\nfig = px.pie(gen, values='Frequency', names='Gender', title='Kagglian Gender Status')\nfig.show()","87a54749":"country = round(df['Q3'].value_counts(normalize= True)*100,2).reset_index().rename(\n                                    index=str,columns={'index': 'Country', 'Q3':'%'})#.sort_values(by = 'Age_Group')\n\ncountry['Country'] = country['Country'].replace(['Iran, Islamic Republic of...', 'United Kingdom of Great Britain and Northern Ireland', 'Viet Nam']\n                                                ,['Iran', 'UK', 'Vietnam', ])","f0bfa510":"fig = px.bar(country, y='%', x='Country', title=\"Kagglian's Country\")\nfig.show()\n","d4330f36":"q3 = pd.DataFrame(df['Q3']).rename(columns= {\"Q3\": \"Country\"})\n\nq3['Continent'] = q3[\"Country\"] # Making Copy of Country Column as Continent","bb098cd8":"# Replacing Countries with Continents\n\n# #Asia\nq3['Continent'] = q3['Continent'].replace(\n    to_replace=['India','Japan', 'China', 'Pakistan','Indonesia', 'Turkey','South Korea','Taiwan', 'Israel','Bangladesh'\n                ,'Viet Nam','Singapore','Thailand', 'United Arab Emirates', 'Iran, Islamic Republic of...','Malaysia','Philippines','Sri Lanka',\n                'Saudi Arabia','Hong Kong (S.A.R.)', 'Nepal','Kazakhstan','Iraq']\n    ,value = 'Asia')\n\n# #North America\nq3['Continent'] = q3['Continent'].replace(\n    to_replace=['United States of America', 'Canada','Mexico']\n    ,value = 'North_America')\n\n# #South America\nq3['Continent'] = q3['Continent'].replace(\n    to_replace=['Colombia','Argentina','Peru', 'Chile', 'Ecuador', 'Brazil']\n    ,value = 'South_America')\n\n# #Africa\nq3['Continent'] = q3['Continent'].replace(\n    to_replace=['Nigeria', 'Kenya', 'South Africa', 'Morocco', 'Tunisia', 'Ghana','Uganda','Algeria', 'Ethiopia', 'Egypt']\n    ,value = 'Africa')\n\n# #Europe\nq3['Continent'] = q3['Continent'].replace(\n    to_replace=['Russia', 'United Kingdom of Great Britain and Northern Ireland','Germany', 'Spain','Italy','Poland', 'Ukraine','Netherlands','Portugal'\n                ,'Greece','Ireland','Sweden', 'Switzerland','Belgium','Czech Republic', 'Romania', 'Austria'\n                ,'Belarus','Denmark', 'Norway', 'France'] \n    ,value = 'Europe')\n\n# Replacing 'Other', 'I do not wish to disclose my location' with \"Other\"\nq3['Continent'] = q3['Continent'].replace(\n    to_replace=['Other', 'I do not wish to disclose my location'] \n    ,value = 'Other')","efd258d7":"# Creating DataFrame for value counts\nval = q3['Continent'].value_counts(normalize=False).reset_index().rename(\n                                    index=str,columns={'index': 'Continent', 'Continent':'Frequency'})\n\nfig = px.pie(val, values='Frequency', names='Continent', title=\"Continent-wise Kagglian\")\nfig.show()","0e275bc6":"q4 = pd.DataFrame(df['Q4'])\nq4['Q4'].unique()","3a6e5d47":"# Replacing Some values\nrep = {\n   'Some college\/university study without earning a bachelor\u2019s degree': 'Non-Bachelor\u2019s degree'\n    , 'Professional doctorate' : 'Doctoral degree'\n    ,'I prefer not to answer':'None\/HighScool'\n    , 'No formal education past high school' : 'None\/HighScool'\n}\n\nq4['Q4'] = q4['Q4'].replace(rep)","d8ac4431":"# Creating Dataframe for Value counts\nedu_val = q4['Q4'].value_counts(normalize=False, dropna=False)\\\n.reset_index()\\\n.rename(index = str, columns = {'index': 'Education Level', 'Q4':'Frequency'})\n\n\nfig = px.pie(edu_val, values= 'Frequency', names = 'Education Level', title = \"Kagglian's Educational Level\")\nfig.show()","a60d0caf":"df['Q5'].unique()","1a3ca17c":"val = df['Q5'].value_counts(normalize = True, dropna = False)\\\n.reset_index()\\\n.rename(index = str, columns = {'index': 'Professional Level', 'Q5':'%'})\n\nval['%'] = val['%']*100\n\n\nfig = px.bar(val, y = 'Professional Level', x = '%', title = \"Kagglian's Profession\")\nfig.show()","d998fd0e":"code_years = df['Q6'].value_counts(normalize = True, dropna = False)\\\n.reset_index()\\\n.rename(index = str, columns = {'index' : 'Years_Coding', 'Q6':'Percentage'})\n\ncode_years['Percentage'] = code_years['Percentage']*100","823788e1":"fig = px.bar(code_years, x = 'Percentage', y = 'Years_Coding', title = \"Years of Coding of Participant\")\nfig.show()","7c9db0c9":"# Question 7 - Programming Languages used Regular Basis.\nq7 = df.iloc[:, 7:20].drop('Q7_Part_12', axis = 1)\n\npro_languages = counts(q7).rename(columns = {'Tools': 'No_Programming_Lang'})\n\n# All Counts \"more than 6\" are replaced by 6 and considered as \"Programming Languages used more than 6\"\npro_languages['Counts'] = pro_languages['Counts'].replace([6,  7,  8,  9, 11, 10, 12], 6)","ffb9e232":"# pro_lang = pro_languages[pro_languages['Programing_Languages']!='None']\n# # pro_lang['Programing_Languages'].value_counts() \n\nlang_val = pro_languages['Counts'].value_counts().reset_index()\\\n.rename(index = str ,columns = {'index': 'No_Programming_Lang', 'Count_Programing_Languages' :'Counts'})\\\n","0fa23472":"fig = px.bar(lang_val, x = 'No_Programming_Lang', y = 'Counts'\n             ,title = 'Number of Programming Languages used Regularly')\n\nfig.show()","2b5bb528":"# Programing Languages Regularly Used by Participants\npro_lang = clean(data,'Q7_Part_',12).sort_values(by = 'Counts').rename(columns = {\"Tools\":\"Programing Languages\"})","6e1e29ea":"fig = px.bar(pro_lang, x = 'Counts', y = 'Programing Languages', title = 'Proramming Languages used Regularly')\nfig.show()","31c91b98":"df['Q8'].unique()","d4f09a56":"q8 = df['Q8'].value_counts(normalize = False).reset_index()\\\n.rename(index = str, columns = {'index':'Programming Languages', 'Q8' : 'Frequency'})\n\n\nfig = px.bar(q8, x = 'Frequency', y='Programming Languages', title = 'Languages used for Data Science')\nfig.show()","a5c832ea":"q9_vis = clean(df, 'Q9_Part_', 12).sort_values(by = 'Counts', ascending = False).rename(columns = {'Tools':'IDEs'})","b4425ecc":"q9_vis['IDEs'] = q9_vis['IDEs'].str.strip()\nq9_vis['IDEs'].unique()","c35e0634":"replacer = {\n    'Jupyter (JupyterLab, Jupyter Notebooks, etc)' : 'Jupyter'\n    ,'Jupyter Notebook':'Jupyter'\n    ,'Visual Studio Code (VSCode)': 'VSCode'\n    ,'Visual Studio':'VSCode'\n}\n\nq9_vis['IDEs'] = q9_vis['IDEs'].replace(replacer)\n\nq9_vis['IDEs'].unique()","12260c3c":"fig = px.bar(q9_vis, x = 'Counts', y = 'IDEs', title = 'Recommened IDEs for Data Science')\nfig.show()","de6f36bd":"# Question 9 - Recommened IDE for Data Science.\nq9 = df.iloc[:, 21:34].drop(\"Q9_Part_12\", axis = 1)","542d9c72":"# Combining Similar value Columns\nq9['Q9_Part_1+11'] = q9[['Q9_Part_1','Q9_Part_11']].where(q9[['Q9_Part_1','Q9_Part_11']].ne('nan')\n                                        ).fillna('').agg(' '.join, axis = 1)\n\nq9['Q9_Part_3+4'] = q9[['Q9_Part_3','Q9_Part_4']].where(q9[['Q9_Part_3','Q9_Part_4']].ne('nan')\n                                        ).fillna('').agg(' '.join, axis = 1)\n\nq9 = q9.drop(['Q9_Part_1', 'Q9_Part_3', 'Q9_Part_4', 'Q9_Part_11'], axis = 1)","27b3680f":"# Replacing Some similar Values\n\nq9['Q9_Part_1+11'] = q9['Q9_Part_1+11'].replace(to_replace=[\n    ' Jupyter Notebook',\n    'Jupyter (JupyterLab, Jupyter Notebooks, etc) Jupyter Notebook',\n    'Jupyter (JupyterLab, Jupyter Notebooks, etc) ']\n                                                , value= 'Jupyter')\n\n\nq9['Q9_Part_3+4'] = q9['Q9_Part_3+4'].replace(to_replace=['Visual Studio Visual Studio Code (VSCode)'\n                                                          ,' Visual Studio Code (VSCode)', 'Visual Studio ']\n                                              , value= 'VSCode')\n\nq9['Q9_Part_9'] = q9['Q9_Part_9'].replace('Vim \/ Emacs', 'Vim_Emacs')","4044da72":"q9['Q9_Part_1+11'].unique()","f3e7b5c5":"ide_recomm = counts(q9).rename(columns = {'Tools' : 'Recommened IDEs for Data Science'})\nide_recomm","3e19be17":"val = ide_recomm['Counts'].value_counts().reset_index()\\\n.rename(index = str,columns= {'index': 'No_IDEs'})\\\n.sort_values(by = 'No_IDEs')\n\nval","66de7f8d":"fig = px.pie(val, values = 'Counts', names = 'No_IDEs', title = 'Number of IDEs Used by Participants')\nfig.show()","004a2d72":"q10_com = clean(df, 'Q10_Part_', 17).rename(columns = {'Tools':'Host Notebooks'})\\\n.sort_values(by = 'Counts', ascending=False)\\\n.reset_index()\\\n.drop('index', axis = 1)\n\n\nq10_com","54f0b97b":"fig = px.bar(q10_com\n             ,x = 'Counts'\n             ,y = 'Host Notebooks'\n             ,title = 'Hosted Notebook used Regularly')\n\nfig.show()","c1f3cccd":"q10 = df.iloc[:, 34:51]","91cbcc8e":"RemoveSpaceBetStrings(q10) ","aa58b81d":"q10['Q10_Part_4'].unique()","a29b2018":"freq = counts(q10)\n\nfreq['Counts'] = freq['Counts'].replace([6,7,8,9,10,11,14,15,16], 6) # Hosted Notebooks Used 6 and more than 6","03095fe2":"val = freq['Counts'].value_counts().reset_index().rename(columns = {'index' : 'No of Hosted Notebooks'\n                                                                    })\nval","9679c0c3":"fig = px.bar(val, x = 'No of Hosted Notebooks', y = 'Counts',title = \"Number of Hosted Notebooks Used Regularly\")\nfig.show()","8b28dd41":"workstation = df['Q11'].value_counts().reset_index().rename(columns = {'index': 'Workstations', 'Q11':'Counts'})\nworkstation","63372264":"fig = px.pie(workstation, values='Counts', names = 'Workstations', title = 'Workstations used for Data Science Purpose')\nfig.show()","555e98af":"q12 = df.iloc[:, 52:58]\nq12","d0e40c23":"gpus = counts(q12)\ngpus","6a7bff51":"val = clean(df, 'Q12_Part_', 6).rename(columns = {'Tools':'DL_Hardware', 'values':'Counts'})\nval.sort_values(by = 'Counts',ascending=False)","c843be9f":"fig = px.bar(val, x = 'DL_Hardware', y = 'Counts', title = 'Special Type of Hardware used Regularly')\nfig.show()","44003a88":"q13_val = df['Q13'].value_counts().reset_index().rename(index = str, columns = {'index' : 'TPU Used', 'Q13' :'Counts'})\nq13_val","f5553342":"fig = px.pie(q13_val, values='Counts', names = 'TPU Used', title = 'TPU Used Times')\nfig.show()","ea2be8af":"data_viz_packages = clean(df, 'Q14_Part_', 12).rename(columns = {'Tools':'Visualization Libraries','values':'Counts'})\ndata_viz_packages","58b83840":"fig = px.bar(data_viz_packages, x = 'Visualization Libraries', y = 'Counts', \n             title = \"Data Visualization Tools Used Regularly\")\n\nfig.show()","d763a526":"q14 = df.iloc[:, 59:71].drop('Q14_Part_11', axis = 1)\nq14.head(3)","80fe99d7":"# Replace '\/' with \"_\"\n\nq14['Q14_Part_3'] = q14['Q14_Part_3'].replace(' Plotly \/ Plotly Express ', 'Plotly(PX)')\nq14['Q14_Part_4'] = q14['Q14_Part_4'].replace(' Ggplot \/ ggplot2 ', 'Ggplot(ggplot2)')\nq14['Q14_Part_10'] = q14['Q14_Part_10'].replace(' Leaflet \/ Folium ', 'Leaflet\/Folium')","0e40e3fb":"count_val = counts(q14).rename(columns = {'Feature': 'Visualization Tools'})\ncount_val","3f6f03bb":"plt.figure(figsize=(9, 7))\nsns.countplot(count_val['Counts'])\nplt.xlabel('Number of Data Visualization Tool Counts')\nplt.title(\"Number of Data Visualization Tools used by Participants\", )","5dccd5f8":"df['Q15'].value_counts()","13cfb2a8":"df['Q15'].value_counts().plot.barh(figsize = (8, 7), title = 'Since When ML Methods are Used ?')","ba419a2d":"ml_frame = clean(df, 'Q16_Part_', 18).rename(columns = {'Tools' : 'ML Frameworks'\n                                             ,'values':'Counts'}).sort_values(by = 'Counts', ascending = False)\n\nml_frame","a65c30dd":"px.bar(ml_frame, x = 'ML Frameworks', y = 'Counts', title = 'Machine Learning Fremeworks used Regulary by Participants')","779d097a":"q16 = df.iloc[:, 72:90].drop('Q16_Part_17', axis = 1) # Dropping 'Q16_Part_17' because it hase \"None\" value\nq16","bb27c86c":"ml_pac = counts(q16)\nml_pac","f153cb8e":"ml_pac['Counts'].value_counts().plot.bar(figsize = (8, 7), title = 'No. of ML Frameworks used Regulary')","481fca15":"ml_algo = clean(df, \"Q17_Part_\", 12).rename(columns = {'Tools':\"ML Algorithms\"})\\\n.sort_values(by = 'Counts', ascending = False)\n\nml_algo","055a731c":"fig = px.bar(ml_algo, x = 'Counts', y = 'ML Algorithms', title = 'Machine Learning Algorithm used Regularly')\nfig.show()","0b4d5d3d":"q17 = df.iloc[:, 90:102].drop('Q17_Part_11', axis = 1)\nq17.head(3)","ff23f59c":"# Replace ' ' with '_' between Strings\n\nq17['Q17_Part_1'] = q17['Q17_Part_1'].replace('Linear or Logistic Regression', 'Linear\/Logistic_Regression')\nq17['Q17_Part_2'] = q17['Q17_Part_2'].replace('Decision Trees or Random Forests', 'Decision_Trees\/Random_Forests')\nq17['Q17_Part_3'] = q17['Q17_Part_3'].replace('Gradient Boosting Machines (xgboost, lightgbm, etc)'\n                                              ,'Gradient_Boosting_Machines(xgboost_lightgbm_etc)')\n\nq17['Q17_Part_4'] = q17['Q17_Part_4'].replace('Bayesian Approaches','Bayesian_Approaches')\nq17['Q17_Part_5'] = q17['Q17_Part_5'].replace('Evolutionary Approaches', 'Evolutionary_Approaches')\nq17['Q17_Part_6'] = q17['Q17_Part_6'].replace('Dense Neural Networks (MLPs, etc)'\n                                              ,'Dense_Neural_Networks(MLPs_etc)')\n\nq17['Q17_Part_7'] = q17['Q17_Part_7'].replace('Convolutional Neural Networks','Convolutional_Neural_Networks')\nq17['Q17_Part_8'] = q17['Q17_Part_8'].replace('Generative Adversarial Networks','Generative_Adversarial_Networks')\nq17['Q17_Part_9'] = q17['Q17_Part_9'].replace('Recurrent Neural Networks','Recurrent_Neural_Networks')\nq17['Q17_Part_10'] = q17['Q17_Part_10'].replace('Transformer Networks (BERT, gpt-3, etc)'\n                                                ,'Transformer_Networks(BERT_gpt-3_etc)')","5b0d8385":"ml_algo_counts  = counts(q17).rename(columns = {'Feature':\"Machine Learning Algorithms\"})\nml_algo_counts\n","7178fc3d":"ml_algo_counts['Counts'].value_counts().plot.bar(figsize = (10,7), title = 'No. of Machine Learning Algo. Used Regularly')\nplt.xlabel('No. Of ML Algorithms')\nplt.ylabel('Frequency')","40d38494":"cv_methods = clean(df, 'Q18_Part_', 7)\ncv_methods['Tools'] = cv_methods['Tools']\\\n.replace('Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)'\n         ,'Image classification and other(VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)') ","4346629d":"cv_methods['Tools'].unique()","cb58705d":"fig = px.bar(cv_methods, x = 'Counts', y = 'Tools', title = 'Computer Vision Methods used Regularly')\nfig.show()","7ab4c8d7":"q18 = df.iloc[:, 102:109].drop('Q18_Part_6', axis = 1)\nq18.head()","4ecf4b79":"q18['Q18_Part_5'].unique()","e4693507":"q18['Q18_Part_1'] = q18['Q18_Part_1'].replace('General purpose image\/video tools (PIL, cv2, skimage, etc)'\n                                              ,'General_purpose_image\/video_tools(PIL\/cv2\/skimage\/etc.)')\n\n\nq18['Q18_Part_2'] = q18['Q18_Part_2'].replace('Image segmentation methods (U-Net, Mask R-CNN, etc)'\n                                              ,'Image_segmentation_methods(U-Net\/Mask_R-CNN\/etc.)')\n\nq18['Q18_Part_3'] = q18['Q18_Part_3'].replace('Object detection methods (YOLOv3, RetinaNet, etc)'\n                                              ,'Object_detection_methods(YOLOv3_RetinaNet\/etc.)')\n\nq18['Q18_Part_4'] = q18['Q18_Part_4']\\\n.replace('Image classification and other general purpose networks (VGG, Inception, ResNet, ResNeXt, NASNet, EfficientNet, etc)'\n         ,'Image_classification_and_other_general_purpose_networks(VGG\/Inception\/ResNet\/ResNeXt\/NASNet\/EfficientNet\/etc.)')\n                                              \nq18['Q18_Part_5'] = q18['Q18_Part_5'].replace('Generative Networks (GAN, VAE, etc)', 'Generative_Networks(GAN\/VAE\/etc.)')\n","c8841766":"cnt = counts(q18)\ncnt.head()","4123f525":"cnt['Counts'].value_counts(normalize=True).plot(kind = 'barh', figsize = (9, 7))\nplt.title(\"No. of Computer Vision Methods used Regularly\")\nplt.xlabel('No. of CV Methods')\nplt.ylabel('Counts')\n","9ec33095":"nlp_meth = clean(df, 'Q19_Part_', 6).rename(columns = {'Tools':'NLP_methods'})\nnlp_meth","ee2b12b2":"fig = px.pie(nlp_meth, values = 'Counts', names = 'NLP_methods', title = \"NLP Methods used Regularly\")\nfig.show()","cbdf4210":"q19 = df.iloc[:, 109:115].drop('Q19_Part_5', axis = 1)\nq19","ebc61454":"# Replace \" \" with \"_\" in strings\n\nq19['Q19_Part_1'] = q19['Q19_Part_1'].replace('Word embeddings\/vectors (GLoVe, fastText, word2vec)'\n                                              ,'Word_Embeddings\/Vectors')\n\nq19['Q19_Part_2'] = q19['Q19_Part_2'].replace('Encoder-decorder models (seq2seq, vanilla transformers)'\n                                              ,'Encoder-Decorder_Models')\nq19['Q19_Part_3'] = q19['Q19_Part_3'].replace('Contextualized embeddings (ELMo, CoVe)', 'Contextualized_Embeddings')\nq19['Q19_Part_4'] = q19['Q19_Part_4'].replace('Transformer language models (GPT-3, BERT, XLnet, etc)'\n                                              ,'Transformer_Language_Models')","a9f05ab4":"count_q19 = counts(q19).rename(columns = {'Tools':\"No_NLP_methods\"})\ncount_q19.head()","d58d3d4a":"count_q19['Counts'].value_counts(normalize = True).plot.bar(figsize = (9, 5), title = 'No. of NLP Methods Used Regularly')\nplt.xlabel('No. of NLP Methods Used')\nplt.ylabel(\"Counts\")","9756e1a4":"df['Q20'].value_counts()","9b86df1c":"df['Q20'].value_counts(normalize=True).plot.barh(figsize = (12,8), title = \"Current Employer's Industries\")","ac0d5125":"df['Q21'].value_counts()","da39dc68":"df['Q21'].value_counts(normalize=True).plot.barh(figsize = (9, 5), title = \"Size of the Company\")\nplt.xlabel('percentages')\nplt.ylabel(\"Size of the Company\")","fa110808":"df['Q22'].value_counts(normalize=True)","2bbfb343":"df['Q22'].value_counts(normalize=True).plot.barh(figsize = (9, 5), title = 'No. of Individuals Responsible for DS Works')\nplt.xlabel(\"percentage\")\nplt.ylabel('Size of DS Workloads')","dae39d74":"# Replacing Values with Small Values\n\nrep = {\n    'No (we do not use ML methods)' : 'No, Do not use ML'\n    \n    ,'We are exploring ML methods (and may one day put a model into production)' : \"Exploring ML Methods\"\n    \n    ,'We use ML methods for generating insights (but do not put working models into production)':\\\n    \"Using ML Methods for Insights(not production)\"\n    \n    ,'We have well established ML methods (i.e., models in production for more than 2 years)' :\\\n    \"Established ML Methods for > 2years(production)\"\n    \n    ,'We recently started using ML methods (i.e., models in production for less than 2 years)':\\\n    \"Started ML Methods fro < 2years(production)\"\n}\n\ndf[\"Q23\"] = df[\"Q23\"].replace(rep)","fd4380fc":"df['Q23'].value_counts(normalize=True,dropna=False)","2878b02f":"df['Q23'].value_counts(normalize=True,dropna=False).plot.barh(figsize = (9, 5))\nplt.title(\"Current Employer Incorporate ML Methods\")\nplt.xlabel(\"percentage\")\nplt.ylabel(\"Incorporate ML Methods\")","bd6549ae":"df['Q24_Part_1'] = df['Q24_Part_1'].replace('Analyze and understand data to influence product or business decisions'\n                                            ,'Analyze_and_Understand_Data')\n\ndf['Q24_Part_2'] = df['Q24_Part_2']\\\n.replace('Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data'\n        ,'Build_and\/or_Run_the_Data_Infrastructure')\n\ndf['Q24_Part_3'] = df['Q24_Part_3'].replace('Build prototypes to explore applying machine learning to new areas'\n                                            ,'Build_Prototypes')\n\ndf['Q24_Part_4'] = df['Q24_Part_4']\\\n.replace('Build and\/or run a machine learning service that operationally improves my product or workflows'\n         ,'Build_and\/or_run_ML_service')\n\ndf['Q24_Part_6'] = df['Q24_Part_6'].replace('Do research that advances the state of the art of machine learning'\n                                            ,'Research_to_advances_ML')\n\ndf['Q24_Part_5'] = df['Q24_Part_5'].replace('Experimentation and iteration to improve existing ML models'\n                                            ,'Improve_Existing_ML_Models')\n\n\ndf['Q24_Part_7'] = df['Q24_Part_7'].replace('None of these activities are an important part of my role at work'\n                                            ,'None_of_these_activities')\n","83805294":"q24 = df.iloc[:, 119:127].drop('Q24_Part_7', axis = 1)\nq24","dfb876ba":"imp_tasks = clean(df, 'Q24_Part_', 8).rename(columns = {'Tools' : 'Imp. Tasks as part of Works'})\nimp_tasks","89b13b73":"fig = px.bar(imp_tasks\n             ,x = 'Counts'\n             ,y = 'Imp. Tasks as part of Works'\n             ,title = 'Important Tasks as Part of Works')\n\nfig.show()","9db01bfd":"tasks = counts(q24)","81d2f8f0":"tasks.Counts.value_counts(normalize = True).plot.bar(figsize = (9, 5)\n                                                    ,title = 'No. of tasks performed')\nplt.xlabel('No. of tasks performed in Works')\nplt.ylabel('percentage')","65689a62":"data['Q26'].unique()","ff8a84f4":"val = df[\"Q26\"].value_counts()\n\n# Pie Chart\nfig = px.pie(val\n             ,values = val.values\n             ,names = val.index\n             ,title = \"Money Spent on ML \/ Clould At Home in last 5Years\")\n\nfig.show()","28eb21b9":"data['Q27_A_Part_1'].unique(), data['Q27_B_Part_1'].unique()","2dae1c4a":"# Q27_A and Q27_B\ncld_plt = clean(df, 'Q27_A_Part_', 11).rename(columns = {'Tools':'Cloud Platforms'}).sort_values(by= \"Counts\"\n                                                                                                 ,ascending=False)\ncld = clean(df, \"Q27_B_Part_\", 12).rename(columns = {\"Tools\":\"Cloud_Platforms\"}).sort_values(by= \"Counts\"\n                                                                                             ,ascending=False)\n\n# Sub-Bar Charts\ntitle = 'Cloud Computing Platforms: Present-use vs Future-wish'\n\nfig = make_subplots(rows=1, cols=2, \n                    horizontal_spacing = 0.3,\n                    shared_yaxes=False,\n                   )\n\nfig.add_trace(go.Bar(y=cld_plt['Cloud Platforms'],\n                     x=cld_plt[\"Counts\"],\n                     orientation= 'h',\n                     name=\"Present\",\n                     marker_color='lightseagreen',\n                     opacity =0.6\n                    ),row=1, col=1,\n             )\n\nfig.add_trace(go.Bar(y = cld['Cloud_Platforms'],\n                     x = cld['Counts'],\n                     orientation= 'h',\n                     name=\"Future\",\n                     marker_color='gold',\n                     opacity =0.6\n                    ),row=1, col=2,\n             )\n\nfig.update_traces(marker_line_color='black',\n              marker_line_width=1.5)\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.2,\n                  height=450, width=950,\n                  barmode='group',\n                  titlefont={'size': 28},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=1, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              ).update_yaxes(categoryorder='total ascending')\n                 \n\nfig.update_layout(xaxis_title='Count',yaxis_linewidth=0,\nautosize=False,\nmargin=dict(\n    l=210, r=150, b=100, t=70,\n),\n)\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","0c2cb942":"q27A = df.iloc[:, 129:141].drop('Q27_A_Part_11', axis = 1)\nq27B = df.iloc[:, 268:280].drop('Q27_B_Part_11', axis = 1)\n\n# Applying RemoveSpaceBetStrings function to replace internal whitespaces between words\nRemoveSpaceBetStrings(q27A)\nRemoveSpaceBetStrings(q27B)\n\n# Cloud Platform counts uses by participants\nplt_cld = counts(q27A).rename(columns = {\"Tools\":\"Cloud_Platform\"})\nplt = counts(q27B).rename(columns = {\"Tools\":\"Cloud_Platform\"})","1007e9d3":"val_A = plt_cld['Counts'].value_counts()\nval_B = plt['Counts'].value_counts()","8aded9dc":"# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,specs=[[{'type':'domain'}\n                             ,{'type':'domain'}]]\n                    ,subplot_titles=['Present'\n                                     ,'Future']\n                   )\n\nfig.add_trace(go.Pie(labels=val_A.index\n                     ,values=val_A.values\n                     ,name=\"Present\")\n              ,row=1\n              ,col=1)\n\nfig.add_trace(go.Pie(labels=val_B.index\n                     ,values=val_B.values\n                     ,name=\"Future\")\n              ,row=1\n              ,col=2)\n\nfig.update_layout(title=\"Cloud Platforms Counts : Present vs. Future\"\n              ,font_family=\"San Serif\"\n              ,height=500, width=975\n              ,titlefont={'size': 28}\n              ,template='simple_white'\n              ,paper_bgcolor='#F5F5F5'\n              ,plot_bgcolor='#F5F5F5'\n            ).update_yaxes(categoryorder='total ascending')","98be30cc":"# import plotly.graph_objects as go\n\n# # pull is given as a fraction of the pie radius\n# fig = go.Figure(data=[go.Pie(labels=labels, values=values, pull=[0, 0, 0.2, 0])])\n# fig.show()","43f065c6":"# Creating dataframe using counts from \"value_counts\" function\n\n# large = plt_cld.groupby(\"Counts\").filter(lambda x: len(x) == 16)\n# large","393a0f06":"data['Q28'].unique()","bef39853":"# Stripping Whitespaces\ndf['Q28'] = df['Q28'].str.strip()\n\n# Checking Changes made or not\ndf.Q28.unique()","9bc8c4d8":"df['Q28'].isna().sum()","a9ac70d4":"val_q28 = df['Q28'].value_counts().sort_values()\n\n\nfig = px.bar(val_q28\n             ,y = val_q28.index\n             ,x = val_q28.values\n             ,title = \"Enjoyable Cloud Platforms\"\n             ,labels={\"index\" : \"Cloud Platforms\"\n                      ,\"x\":\"frequencies\"}\n            )\nfig.show()","6278fe61":"data[\"Q29_A_Part_1\"].unique(), data[\"Q29_B_Part_1\"].unique()","8f16c2e0":"# Q29_A and Q29_B\ncc_plt = clean(df, 'Q29_A_Part_', 5).rename(columns = {'Tools':'Cloud Platforms'}).sort_values(by= \"Counts\"\n                                                                                                 ,ascending=False)\nccp = clean(df, \"Q29_B_Part_\", 5).rename(columns = {\"Tools\":\"Cloud_Platforms\"}).sort_values(by= \"Counts\"\n                                                                                             ,ascending=False)","7c5409a1":"# Sub-Bar Charts\ntitle = 'Cloud Computing Platforms: Present-use vs Future-wish'\n\nfig = make_subplots(rows=1, cols=2, \n                    horizontal_spacing = 0.3,\n                    shared_yaxes=False,\n                   )\n\nfig.add_trace(go.Bar(y=cc_plt['Cloud Platforms'],\n                     x=cc_plt[\"Counts\"],\n                     orientation= 'h',\n                     name=\"Present-Use\",\n                     marker_color='lightseagreen',\n                     opacity =0.6\n                    ),row=1, col=1,\n             )\n\nfig.add_trace(go.Bar(y = ccp['Cloud_Platforms'],\n                     x = ccp['Counts'],\n                     orientation= 'h',\n                     name=\"In Next 2 years\",\n                     marker_color='gold',\n                     opacity =0.6\n                    ),row=1, col=2,\n             )\n\nfig.update_traces(marker_line_color='black',\n              marker_line_width=1.5)\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.2,\n                  height=450, width=950,\n                  barmode='group',\n                  titlefont={'size': 28},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=1, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              ).update_yaxes(categoryorder='total ascending')\n                 \n\nfig.update_layout(xaxis_title='Count',yaxis_linewidth=0,\nautosize=False,\nmargin=dict(\n    l=210, r=150, b=100, t=70,\n),\n)\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","d26fa018":"# Creating New Dataframe for Q29-A and Q29-B\nq29A = df.iloc[:, 142:147].drop('Q29_A_Part_4', axis = 1)\nq29B = df.iloc[:, 280:285].drop('Q29_B_Part_4', axis = 1)\n\n# Applying RemoveSpaceBetStrings function to replace internal whitespaces between words\nRemoveSpaceBetStrings(q29A)\nRemoveSpaceBetStrings(q29B)\n\n# Cloud Platform counts uses by participants\nccp_a = counts(q29A).rename(columns = {\"Tools\":\"Cloud_Computing_Platform\"})\nccp_b = counts(q29B).rename(columns = {\"Tools\":\"Cloud_Computing_Platform\"})","b7b39a0c":"val_29A = ccp_a['Counts'].value_counts()\nval_29b = ccp_b['Counts'].value_counts()\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,specs=[[{'type':'domain'}\n                             ,{'type':'domain'}]]\n                    ,subplot_titles=['Present'\n                                     ,'Future']\n                   )\n\nfig.add_trace(go.Pie(labels=val_29A.index\n                     ,values=val_29A.values\n                     ,name=\"Present Use\")\n              ,row=1\n              ,col=1)\n\nfig.add_trace(go.Pie(labels=val_29b.index\n                     ,values=val_29b.values\n                     ,name=\"In Next 2 years\")\n              ,row=1\n              ,col=2)\n\nfig.update_layout(title=\"Total Cloud Computing Platforms per Participants : Present vs. Future\"\n              ,font_family=\"San Serif\"\n              ,height=500, width=975\n              ,titlefont={'size': 28}\n              ,template='simple_white'\n              ,paper_bgcolor='#F5F5F5'\n              ,plot_bgcolor='#F5F5F5'\n            ).update_yaxes(categoryorder='total ascending')","ce076975":"data['Q30_B_Part_1'].unique(), data['Q30_B_Part_1'].unique()","24f2e3a6":"data_stg_A = clean(df, \"Q30_A_Part_\", 8).rename(columns = {\"Tools\" : \"Data_Storage_Product\"}).sort_values(by = \"Counts\")\n# data_stg_B = clean(df, \"Q30_B_Part_\", 8).rename(columns = {\"Tools\" : \"Data_Storage_Product\"}).sort_values(by = \"Counts\")","05382168":"fig = px.bar(data_stg_A, y= \"Data_Storage_Product\", x = \"Counts\")\nfig.show()","e32ef8ea":"q30A = df.iloc[:, 147:155].drop('Q30_A_Part_7', axis = 1)\n\n# Removing whitespaces\nRemoveSpaceBetStrings(q30A)\n\nd_store = counts(q30A).rename(columns = {\"Tools\":\"Data_Storage_Counts\"})","f43d017a":"d_store_cnt = d_store['Counts'].value_counts()\n\n# Pie Chart\nfig = px.pie(d_store_cnt\n             ,names = d_store_cnt.index\n             ,values = d_store_cnt.values\n             ,title = \"Data Storeage Counts used regularly by Participants\"\n             )\n\nfig.show()","c77528cd":"data['Q31_A_Part_1'].unique(), data['Q31_B_Part_1'].unique()","d2bbbac0":"ml_pro_A = clean(df, \"Q31_A_Part_\", 10).rename(columns = {\"Tools\": \"Managed_ML_Products\"})\nml_pro_B = clean(df, \"Q31_B_Part_\", 10).rename(columns = {\"Tools\": \"Managed_ML_Products\"})","6545606f":"# Sub-Bar Charts\ntitle = 'Managed Machine Learning Products : Present-use vs Future-wish'\n\nfig = make_subplots(rows=1, cols=2, \n                    horizontal_spacing = 0.3,\n                    shared_yaxes=False,\n                   )\n\nfig.add_trace(go.Bar(y=ml_pro_A['Managed_ML_Products'],\n                     x=ml_pro_A[\"Counts\"],\n                     orientation= 'h',\n                     name=\"Present-Use\",\n                     marker_color='lightseagreen',\n                     opacity =0.6\n                    ),row=1, col=1,\n             )\n\nfig.add_trace(go.Bar(y = ml_pro_B['Managed_ML_Products'],\n                     x = ml_pro_B['Counts'],\n                     orientation= 'h',\n                     name=\"In Next 2 years\",\n                     marker_color='gold',\n                     opacity =0.6\n                    ),row=1, col=2,\n             )\n\nfig.update_traces(marker_line_color='black',\n              marker_line_width=1.5)\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.2,\n                  height=450, width=950,\n                  barmode='group',\n                  titlefont={'size': 28},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=1, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              ).update_yaxes(categoryorder='total ascending')\n                 \n\nfig.update_layout(xaxis_title='Count',yaxis_linewidth=0,\nautosize=False,\nmargin=dict(\n    l=210, r=150, b=100, t=70,\n),\n)\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","c837dc60":"q31A = df.iloc[:, 155:165].drop(\"Q31_A_Part_9\", axis = 1)\nq31B = df.iloc[:, 293:303].drop(\"Q31_B_Part_9\", axis = 1)\n\n\n# Removing Whitespaces\nRemoveSpaceBetStrings(q31A)\nRemoveSpaceBetStrings(q31B)\n\n# Applying counts function\nml_prod_cnt_A = counts(q31A).rename({\"Tools\" :\"Managed_ML_Products\"})\nml_prod_cnt_B = counts(q31B).rename({\"Tools\" :\"Managed_ML_Products\"})\n\n\n# Taking value counts of \"Counts\" of both dataframes\n\nmml_val_a = ml_prod_cnt_A['Counts'].value_counts()\nmml_val_b = ml_prod_cnt_B['Counts'].value_counts()","744269e4":"# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,specs=[[{'type':'domain'}\n                             ,{'type':'domain'}]]\n                    ,subplot_titles=['Present'\n                                     ,'Future']\n                   )\n\nfig.add_trace(go.Pie(labels=mml_val_a.index\n                     ,values=mml_val_a.values\n                     ,name=\"Present Use\")\n              ,row=1\n              ,col=1)\n\nfig.add_trace(go.Pie(labels=mml_val_b.index\n                     ,values=mml_val_b.values\n                     ,name=\"In Next 2 years\")\n              ,row=1\n              ,col=2)\n\nfig.update_layout(title=\"Total Managed ML Products : Present vs. Future\"\n              ,font_family=\"San Serif\"\n              ,height=500, width=975\n              ,titlefont={'size': 28}\n              ,template='simple_white'\n              ,paper_bgcolor='#F5F5F5'\n              ,plot_bgcolor='#F5F5F5'\n            ).update_yaxes(categoryorder='total ascending')","45407805":"data['Q32_A_Part_1'].unique(), data['Q32_B_Part_1'].unique()","5b199a95":"big_data_A = clean(df, \"Q32_A_Part_\", 21).rename(columns = {\"Tools\" : \"Big_Data_Products\"})\nbig_data_B = clean(df, \"Q32_B_Part_\", 21).rename(columns = {\"Tools\" : \"Big_Data_Products\"})","2ef30ce1":"# Sub-Bar Charts\ntitle = 'BigData Products : Present-use vs Future-wish'\n\nfig = make_subplots(rows=1, cols=2, \n                    horizontal_spacing = 0.3,\n                    shared_yaxes=False,\n                   )\n\nfig.add_trace(go.Bar(y=big_data_A['Big_Data_Products'],\n                     x=big_data_A[\"Counts\"],\n                     orientation= 'h',\n                     name=\"Present-Use\",\n                     marker_color='lightseagreen',\n                     opacity =0.6\n                    ),row=1, col=1,\n             )\n\nfig.add_trace(go.Bar(y = big_data_B['Big_Data_Products'],\n                     x = big_data_B['Counts'],\n                     orientation= 'h',\n                     name=\"In Next 2 years\",\n                     marker_color='gold',\n                     opacity =0.6\n                    ),row=1, col=2,\n             )\n\nfig.update_traces(marker_line_color='black',\n              marker_line_width=1.5)\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.2,\n                  height=600, width=950,\n                  barmode='group',\n                  titlefont={'size': 28},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=1, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              ).update_yaxes(categoryorder='total ascending')\n                 \n\nfig.update_layout(xaxis_title='Count',yaxis_linewidth=0,\nautosize=False,\nmargin=dict(\n    l=210, r=150, b=100, t=70,\n),\n)\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","f40d1768":"q32A = df.iloc[:, 165:186].drop(\"Q32_A_Part_20\", axis = 1)\nq32B = df.iloc[:, 303:324].drop(\"Q32_B_Part_20\", axis = 1)\n\n\n# Removes Whitespaces\nRemoveSpaceBetStrings(q32A)\nRemoveSpaceBetStrings(q32B)\n\n# Applying \"counts function\"\nbd_cnt_a = counts(q32A).rename({\"Tools\" :\"BigData Products\"})\nbd_cnt_b = counts(q32B).rename({\"Tools\" :\"BigData Products\"})\n\n# Replacing 14, 15, 17 and 18 with \"14\" \n# bd_cnt_a['Counts'] = bd_cnt_a['Counts'].replace([14, 15, 17,18], 14)\n# bd_cnt_a['Counts'] = bd_cnt_a['Counts'].replace([14, 15, 17,18], 14)\n\n# taking value counts for \"Counts\" attribute from both dataframes\nbd_val_a = bd_cnt_a['Counts'].value_counts().sort_values()\nbd_val_b = bd_cnt_b['Counts'].value_counts().sort_values()","2ee09a78":"# Sub-Bar Charts\ntitle = 'Total BigData Products Counts per Participants : Present-use vs Future-wish'\n\nfig = make_subplots(rows=1, cols=2, \n                    horizontal_spacing = 0.3,\n                    shared_yaxes=False,\n                   )\n\nfig.add_trace(go.Bar(y=bd_val_a.index,\n                     x=bd_val_a.values,\n                     orientation= 'h',\n                     name=\"Present-Use\",\n                     marker_color='lightseagreen',\n                     opacity =0.6\n                    ),row=1, col=1,\n             )\n\nfig.add_trace(go.Bar(y = bd_val_b.index,\n                     x = bd_val_b.values,\n                     orientation= 'h',\n                     name=\"In Next 2 years\",\n                     marker_color='gold',\n                     opacity =0.6\n                    ),row=1, col=2,\n             )\n\nfig.update_traces(marker_line_color='black',\n              marker_line_width=1.5)\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.2,\n                  height=700, width=950,\n                  barmode='group',\n                  titlefont={'size': 28},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=1, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              ).update_yaxes(categoryorder='total ascending')\n                 \n\nfig.update_layout(xaxis_title='Count',yaxis_linewidth=0,\nautosize=False,\nmargin=dict(\n    l=210, r=150, b=100, t=70,\n),\n)\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","24d2e949":"data['Q33'].unique()","4effea77":"val = df['Q33'].value_counts(dropna=True).sort_values()\n\nfig = px.bar(val\n             ,x = val.values\n             ,y = val.index\n             ,title = \"Big Data Prodcuts use most often\"\n             ,labels={\n                 \"x\" : \"frequency\"\n                 ,\"index\": \"Big Data Products\"\n             }\n            )\n\nfig.show()","12d8d95c":"data['Q34_A_Part_1'].unique(), data['Q34_B_Part_1'].unique()","b9d9b517":"bi_A = clean(df, \"Q34_A_Part_\", 17).rename(columns = {\"Tools\":\"BI_Tools\"})\nbi_B = clean(df, \"Q34_A_Part_\", 17).rename(columns = {\"Tools\":\"BI_Tools\"})","5ef2258f":"# Sub-Bar Charts\ntitle = 'Business Intelligence Tools : Present-use vs Future-wish'\n\nfig = make_subplots(rows=1, cols=2, \n                    horizontal_spacing = 0.3,\n                    shared_yaxes=False,\n                   )\n\nfig.add_trace(go.Bar(y=bi_A['BI_Tools'],\n                     x=bi_B['Counts'],\n                     orientation= 'h',\n                     name=\"Present-Use\",\n                     marker_color='lightseagreen',\n                     opacity =0.6\n                    ),row=1, col=1,\n             )\n\nfig.add_trace(go.Bar(y = bi_B[\"BI_Tools\"],\n                     x = bi_B[\"Counts\"],\n                     orientation= 'h',\n                     name=\"In Next 2 years\",\n                     marker_color='gold',\n                     opacity =0.6\n                    ),row=1, col=2,\n             )\n\nfig.update_traces(marker_line_color='black',\n              marker_line_width=1.5)\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.2,\n                  height=500, width=950,\n                  barmode='group',\n                  titlefont={'size': 28},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=1, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              ).update_yaxes(categoryorder='total ascending')\n                 \n\nfig.update_layout(xaxis_title='Count',yaxis_linewidth=0,\nautosize=False,\nmargin=dict(\n    l=210, r=150, b=100, t=70,\n),\n)\n\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=False)\nfig.show()","48a3f1ec":"q34A = df.iloc[:, 187:204].drop('Q34_A_Part_16', axis = 1)\nq34B = df.iloc[:, 324:341].drop('Q34_B_Part_16', axis = 1)\n\n# Removing Whitespaces\nRemoveSpaceBetStrings(q34A)\nRemoveSpaceBetStrings(q34B)\n\n# Applying counts functions\nbi_cnt_a = counts(q34A).rename(columns = {\"Tools\" : \"Total_BI_Tools\"})\nbi_cnt_b = counts(q34B).rename(columns = {\"Tools\" : \"Total_BI_Tools\"})\n\n# Taking value counts\nbi_val_a = bi_cnt_a['Counts'].value_counts()\nbi_val_b = bi_cnt_b['Counts'].value_counts()","22c7c385":"# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,specs=[[{'type':'domain'}\n                             ,{'type':'domain'}]]\n                    ,subplot_titles=['Present'\n                                     ,'Future']\n                   )\n\nfig.add_trace(go.Pie(labels=bi_val_a.index\n                     ,values=bi_val_a.values\n                     ,name=\"Present Use\")\n              ,row=1\n              ,col=1)\n\nfig.add_trace(go.Pie(labels=bi_val_b.index\n                     ,values=bi_val_b.values\n                     ,name=\"In Next 2 years\")\n              ,row=1\n              ,col=2)\n\nfig.update_layout(title=\"Total BI Tools use per Participants : Present vs. Future\"\n              ,font_family=\"San Serif\"\n              ,height=500, width=975\n              ,titlefont={'size': 28}\n              ,template='simple_white'\n              ,paper_bgcolor='#F5F5F5'\n              ,plot_bgcolor='#F5F5F5'\n            ).update_yaxes(categoryorder='total ascending')","be8c9c83":"data['Q35'].unique()","80a3e83d":"bi_tool_val = df['Q35'].value_counts().sort_values()\n\nfig = px.bar(bi_tool_val\n             ,x = bi_tool_val.values\n             ,y = bi_tool_val.index\n             ,labels={\n                 \"x\" : \"frequencies\"\n                 ,\"y\" : \"BI_Tools\"\n             }\n             ,title = \"Business Intelligence Tools use most often\"\n            )\n\nfig.show()","44187b05":"data[\"Q36_A_Part_7\"].unique(), data[\"Q36_B_Part_7\"].unique()","bd4361a0":"df['Q36_A_Part_7'] = df['Q36_A_Part_7'].replace('No \/ None', 'None')","95785312":"auto_ml_36a = clean(df, \"Q36_A_Part_\", 8).rename(columns = {\"Tools\":\"Auto ML Tools\"})#.sort_values(by = \"Counts\", ascending = True)\nauto_ml_36b = clean(df, \"Q36_B_Part_\", 8).rename(columns = {\"Tools\":\"Auto ML Tools\"})","65fee009":"# Sub-Plots\ntitle = \"Automated Machine Learning Tools: Present-use vs Future-plan\"\n\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,horizontal_spacing=0.3\n                    ,shared_yaxes=True)\n\nfig.add_trace(go.Bar(y = auto_ml_36a['Auto ML Tools']\n                     ,x = auto_ml_36a['Counts']\n                     ,orientation='h'\n                     ,name=\"Present\"\n                     ,marker_color = \"lightseagreen\"\n                     ,opacity=0.5\n                    )\n              ,row=1\n              ,col=1\n             )\n\nfig.add_trace(go.Bar(y = auto_ml_36b['Auto ML Tools']\n                     ,x = auto_ml_36b['Counts']\n                     ,orientation ='h'\n                     ,name = \"Next_2Yr\"\n                     ,marker_color = \"gold\"\n                     ,opacity=0.5\n                    )\n              ,row=1\n              ,col=2\n             )\n\nfig.update_traces(marker_line_color = \"black\"\n                  ,marker_line_width = 1.5\n                 )\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.15,\n                  height=450, width=950,\n                  barmode='group',\n                  titlefont={'size': 24},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=0.75, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              ).update_yaxes(categoryorder='total ascending')\n\nfig.update_layout(xaxis_title = \"Counts\"\n                  ,yaxis_linewidth = 0\n                  ,autosize = False\n                  ,margin = dict(l = 100\n                                 ,r = 75\n                                 ,b = 70\n                                 ,t = 70\n                                )\n                 )\n\nfig.update_xaxes(showgrid = False)\nfig.update_yaxes(showgrid = False)\nfig.show()","e64004d6":"q36A = df.iloc[:, 205:213].drop(\"Q36_A_Part_7\", axis = 1)\nq36B = df.iloc[:, 341:349].drop(\"Q36_B_Part_7\", axis = 1)\n\n# Removing Whitespaces\nRemoveSpaceBetStrings(q36A)\nRemoveSpaceBetStrings(q36B)\n\n# Applying counts functions\nautoml_a_cnt = counts(q36A).rename(columns = {\"Tools\" : \"Auto_ML_Tools\"})\nautoml_b_cnt = counts(q36B).rename(columns = {\"Tools\" : \"Auto_ML_Tools\"})\n\n# Taking value counts\nautoml_val_a = automl_a_cnt['Counts'].value_counts()\nautoml_val_b = automl_b_cnt['Counts'].value_counts()","7fc0787b":"# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,specs=[[{'type':'domain'}\n                             ,{'type':'domain'}]]\n                    ,subplot_titles=['Present'\n                                     ,'Future']\n                   )\n\nfig.add_trace(go.Pie(labels=automl_val_a.index\n                     ,values=automl_val_a.values\n                     ,name=\"Present\")\n              ,row=1\n              ,col=1)\n\nfig.add_trace(go.Pie(labels=automl_val_b.index\n                     ,values=automl_val_b.values\n                     ,name=\"Next_2years\")\n              ,row=1\n              ,col=2)\n\nfig.update_layout(title=\"Total Auto-ML Tools per Participants : Present vs. Future\"\n              ,font_family=\"San Serif\"\n              ,height=500, width=975\n              ,titlefont={'size': 28}\n            ).update_yaxes(categoryorder='total ascending')","5d36a9d5":"df['Q37_A_Part_7'].unique(), df['Q37_B_Part_7'].unique()","b14058b1":"# Replacing 'No \/ None' with 'None'\ndf['Q37_A_Part_7'] = df['Q37_A_Part_7'].replace('No \/ None', 'None')\n\n# Applying \"clean function\" on respective columns\nspc_automl_37A = clean(df, \"Q37_A_Part_\"\n                       ,8).rename(columns = {\"Tools\":\"Specific_AutoML_Tools\"}).sort_values(by = 'Specific_AutoML_Tools')\nspc_automl_37B = clean(df, \"Q37_B_Part_\"\n                       ,8).rename(columns = {\"Tools\":\"Specific_AutoML_Tools\"}).sort_values(by = 'Specific_AutoML_Tools')","e9dbb156":"# Sub-Plots\ntitle = \"Specific Automated-ML Tools: Present-use vs Future-plan\"\n\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,horizontal_spacing=0.1\n                    ,shared_yaxes=False)\n\nfig.add_trace(go.Bar(y = spc_automl_37A['Specific_AutoML_Tools']\n                     ,x = spc_automl_37A['Counts']\n                     ,orientation='h'\n                     ,name=\"Present\"\n                     ,marker_color = \"lightseagreen\"\n                     ,opacity=0.5\n                    )\n              ,row=1\n              ,col=1\n             )\n\nfig.add_trace(go.Bar(y = spc_automl_37B['Specific_AutoML_Tools']\n                     ,x = spc_automl_37B['Counts']\n                     ,orientation ='h'\n                     ,name = \"Next_2Yr\"\n                     ,marker_color = \"gold\"\n                     ,opacity=0.5\n                    )\n              ,row=1\n              ,col=2\n             )\n\nfig.update_traces(marker_line_color = \"black\"\n                  ,marker_line_width = 1.5\n                 )\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.15,\n                  height=450, width=950,\n                  barmode='group',\n                  titlefont={'size': 24},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=0.75, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              )\n\nfig.update_layout(margin = dict(l = 150\n                                 ,r = 150\n                                 ,b = 70\n                                 ,t = 100\n                                )\n                 )\n\nfig.show()","62aa9c3b":"q37A = df.iloc[:, 213:221].drop(\"Q37_A_Part_7\", axis = 1)\nq37B = df.iloc[:, 349:357].drop(\"Q37_B_Part_7\", axis = 1)\n\n# Removing Whitespaces\nRemoveSpaceBetStrings(q37A)\nRemoveSpaceBetStrings(q37B)\n\n# Applying counts functions\nspc_automl_a = counts(q37A).rename(columns = {\"Tools\" : \"Auto_ML_Tools\"})\nspc_automl_b = counts(q37B).rename(columns = {\"Tools\" : \"Auto_ML_Tools\"})\n\n# Taking value counts\nspc_a_val = spc_automl_a['Counts'].value_counts()\nspc_b_val = spc_automl_b['Counts'].value_counts()","e5ce8219":"# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,specs=[[{'type':'domain'}\n                             ,{'type':'domain'}]]\n                    ,subplot_titles=['Present'\n                                     ,'Future']\n                   )\n\nfig.add_trace(go.Pie(labels=spc_a_val.index\n                     ,values=spc_a_val.values\n                     ,name=\"Present\")\n              ,row=1\n              ,col=1)\n\nfig.add_trace(go.Pie(labels=spc_b_val.index\n                     ,values=spc_b_val.values\n                     ,name=\"Next_2years\")\n              ,row=1\n              ,col=2)\n\nfig.update_layout(title=\"Total Specific Auto-ML Tools : Present vs. Future\"\n              ,font_family=\"San Serif\"\n              ,height=500, width=975\n              ,titlefont={'size': 28}\n            ).update_yaxes(categoryorder='total ascending')","f786c22d":"data['Q38_A_Part_11'].unique(), data['Q38_B_Part_11'].unique()","f472d858":"# Replacing \"No \/ None\" with \"None\"\ndf[\"Q38_A_Part_11\"] = df[\"Q38_A_Part_11\"].replace('No \/ None', \"None\")\n\n# Applying \"clean Function\" on respective questions\nmanage_ml_A = clean(df, \"Q38_A_Part_\"\n                    ,12).rename(columns = {\"Tools\":\"ML Managing Tools\"}).sort_values(by = \"Counts\", ascending = False)\n\nmanage_ml_B = clean(df, \"Q38_B_Part_\"\n                    ,12).rename(columns = {\"Tools\":\"ML Managing Tools\"}).sort_values(by = \"Counts\", ascending = False)","49b615af":"# Sub-Plots\ntitle = \"Tools to Manage ML Experiments: Present-use vs Future-plan\"\n\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,horizontal_spacing=0.1\n                    ,shared_yaxes=False)\n\nfig.add_trace(go.Bar(y = manage_ml_A['ML Managing Tools']\n                     ,x = manage_ml_A['Counts']\n                     ,orientation='h'\n                     ,name=\"Present\"\n                     ,marker_color = \"lightseagreen\"\n                     ,opacity=0.5\n                    )\n              ,row=1\n              ,col=1\n             )\n\nfig.add_trace(go.Bar(y = manage_ml_B['ML Managing Tools']\n                     ,x = manage_ml_B['Counts']\n                     ,orientation ='h'\n                     ,name = \"Next_2Yr\"\n                     ,marker_color = \"gold\"\n                     ,opacity=0.5\n                    )\n              ,row=1\n              ,col=2\n             )\n\nfig.update_traces(marker_line_color = \"black\"\n                  ,marker_line_width = 1.5\n                 )\n\nfig.update_layout(title=title, \n                  font_family=\"San Serif\",\n                  bargap=0.15,\n                  height=450, width=950,\n                  barmode='group',\n                  titlefont={'size': 24},\n                  template='simple_white',\n                  paper_bgcolor='#F5F5F5',\n                  plot_bgcolor='#F5F5F5',\n                  legend=dict(orientation=\"v\", \n                              y=1, \n                              yanchor=\"top\", \n                              x=1.250, \n                              xanchor=\"right\",)                 \n              )\n\nfig.update_layout(margin = dict(l = 150\n                                 ,r = 150\n                                 ,b = 70\n                                 ,t = 100\n                                )\n                 )\n\nfig.show()","2af78f81":"q38A = df.iloc[:, 221:233].drop(\"Q38_A_Part_11\", axis = 1)\nq38B = df.iloc[:, 357:].drop(\"Q38_B_Part_11\", axis = 1)\n\n# Removing whitespaces\nRemoveSpaceBetStrings(q38A)\nRemoveSpaceBetStrings(q38B)\n\n# Applying counts function\nml_exp_tools_a = counts(q38A).rename(columns = {\"Tools\":\"ML Experiment Managing Tools\"})\nml_exp_tools_b = counts(q38B).rename(columns = {\"Tools\":\"ML Experiment Managing Tools\"})","6ca8cbdc":"ml_exp_cnt_a = ml_exp_tools_a['Counts'].value_counts()\nml_exp_cnt_b = ml_exp_tools_b['Counts'].value_counts()\n\n\n# Create subplots: use 'domain' type for Pie subplot\nfig = make_subplots(rows=1\n                    ,cols=2\n                    ,specs=[[{'type':'domain'}\n                             ,{'type':'domain'}]]\n                    ,subplot_titles=['Present'\n                                     ,'Future']\n                   )\n\nfig.add_trace(go.Pie(labels=ml_exp_cnt_a.index\n                     ,values=ml_exp_cnt_a.values\n                     ,name=\"Present\")\n              ,row=1\n              ,col=1)\n\nfig.add_trace(go.Pie(labels=ml_exp_cnt_b.index\n                     ,values=ml_exp_cnt_b.values\n                     ,name=\"Next_2years\")\n              ,row=1\n              ,col=2)\n\nfig.update_layout(title=\"Total ML Experiment Tools : Present vs. Future\"\n              ,font_family=\"San Serif\"\n              ,height=500, width=975\n              ,titlefont={'size': 28}\n            ).update_yaxes(categoryorder='total ascending')","95a46163":"data['Q39_Part_1'].unique()","36a7603d":"data_anal_platform = clean(df, \"Q39_Part_\"\n                           ,10).rename(columns = {\"Tools\":\"DA\/ML Application Sharing Platforms\"}).sort_values(by = \"Counts\")\ndata_anal_platform","5ce1a735":"fig = px.bar(data_anal_platform\n             ,x = \"Counts\"\n             ,y = \"DA\/ML Application Sharing Platforms\"\n             ,title = \"Data Analysis \/ ML App. Sharing Platforms\"\n             ,\n            )\nfig.show()","25baceb2":"q39 = df.iloc[:, 233:243]\n\n# Removing Whiteshpaces from columns\nRemoveSpaceBetStrings(q39)\n\n# Applying \"CountsFunction\"\ntrans_39 = counts(q39).rename(columns = {\"Tools\": 'Total DA\/ML App Sharing Platforms'})\n\napp_sh_cnt = trans_39['Counts'].value_counts()","9468a5fd":"# Pie Chart\n\nfig = px.pie(app_sh_cnt\n             ,names=app_sh_cnt.index\n             ,values=app_sh_cnt.values\n             ,title=\"Total DA \/ ML Application Sharing Platforms used by participants\"\n            )\n\nfig.show()","ee047e9f":"data['Q40_Part_1'].unique()","1e3038ce":"online_course = clean(df, \"Q40_Part_\"\n                      ,12).rename(columns = {\"Tools\":\"Online_Course_Platforms\"}).sort_values(by = 'Counts')\n\n\n# Bar Plot \nfig = px.bar(online_course\n             ,x = \"Counts\"\n             ,y = \"Online_Course_Platforms\"\n             ,title = \"Online Courses Platorms used to Learn Data Science\"\n            )\n\nfig.show()","0b6d2bdb":"q40 = df.iloc[:, 243:255].drop('Q40_Part_11', axis = 1)\n\n# Applying RemoveSpaceBetStrings function on dataframe\nRemoveSpaceBetStrings(q40)\n\n# Applying \"counts function\" on dataframe\nonl_course = counts(q40).rename(columns = {\"Tools\":\"Total Online Platforms used to Learn DS\"})\n\nonl_curs_cnt = onl_course['Counts'].value_counts()\n\n\n# Pie Chart\nfig = px.pie(onl_curs_cnt\n             ,names=onl_curs_cnt.index\n             ,values=onl_curs_cnt.values\n             ,title = \"Total Online Courses Platforms used by Learners\"\n            )\n\nfig.show()","e92e9ef1":"data['Q41'].unique()","594fb327":"q41_val = df['Q41'].value_counts().sort_values()\n\n# Bar Chart\nfig = px.bar(q41_val\n             ,x = q41_val.values\n             ,y = q41_val.index\n             ,title=\"Primary Tools used to Analyze Data at Work or School\"\n             ,labels={\"x\" : \"frequencies\"\n                      ,\"index\" : \"Primary Tools used for Analyze Data\"\n                     }\n            )\n\nfig.show()","ce6345bb":"data[\"Q42_Part_11\"].unique()","16278e4f":"ds_report_src = clean(df, \"Q42_Part_\"\n                      ,11).rename(columns={\"Tools\":\"DS Report Source\"}).sort_values(by = 'Counts')\n\n# Bar Chart\nfig = px.bar(ds_report_src\n             ,x = \"Counts\"\n             ,y = \"DS Report Source\"\n             ,title = \"Data Science Report Source\"\n            )\n\nfig.show()","ef44eab7":"q42 = df.iloc[:, 256:268].drop(\"Q42_Part_11\", axis = 1)\n\n# Applying RemoveSpaceBetStrings function dataframe\nRemoveSpaceBetStrings(q42)\n\n# Applying \"counts\" function on dataframe\nsrc_report_ds = counts(q42).rename(columns = {\"Tools\":\"Total DS Source Reports\"})\n\nsrc_rt_val = src_report_ds['Counts'].value_counts()\n\n\n# Pie Chart\nfig = px.pie(src_rt_val\n             ,names = src_rt_val.index\n             ,values = src_rt_val.values\n             ,title = \"Total DS Source Reports used by Data Scientist\"\n            )\nfig.show()","e054b81a":"**Facts -**\n\n- **79%** kagglian are **Man**, while only **19** kagglian are **Woman**.\n\n\n**Observation -**\n- Looks like we have more **Man** participants in kaggles as compare to their counter part.\n- **Woman** participants may be lacking or hesititate to participats.\n- Their also some participants who perfer not to disclouse their gender are consists **2%**.","04ba4946":"## **Q25**","ef7e2599":"- **30.5%** recommend **1 IDE**, followed by **2** and **3** with **29.3%** and **21.2%** respectively.\n\n\n**81%** participants uses 1 to 3 IDEs. And remaining uses more than 3 IDEs.","2b379da9":"## **Q4 - What is the highest level of formal education do you have?**","2f4455b1":"**Observations -**\n\n- **Students** are more active on Kaggle than other profession with **around 26%**.\n- followed by **Data Scientist** with **around 14%**.\n\n\n- We can say that, on Kaggle **Students** and **Data Scientists** are more active and frequently contributing towards community.","c5e54019":"# **Q24**\n\n**What activities that makes an important part of your role at work?**","391bbc2c":"# **27 - Cloud Computing Platforms**\n\n\n- **Present** - Q27-A - Which Cloud Computing Platforms do you use on a regular basis?\n- **Future** - Q27-B - Which Cloud Computing Platforms do you hope to become more familiar with in the next 2 years?","6bbb7d6a":"explode = (0, 0, 0, 0,0.25, 0.35, 0.45, 0.55, 0.65, 0.75, 0.85)\ncolors = ['#191970', '#001CF0', '#0038E2', '#0055D4', '#0071C6', '#008DB8', '#00AAAA',\n          '#00C69C', '#00E28E', '#00FF80', ]\n\ncld_platforms_counts['Counts'].value_counts().plot(kind='pie'\n                                                   ,autopct='%.1f'\n                                      ,figsize = (12, 8)\n                                      ,fontsize=10\n                                      ,colors=colors\n                                      ,explode=explode\n                                      ,title = \"No. of Cloud Platforms used Regularly\"\n                                      )\nplt.axis('equal')\nplt.ylabel('')\nplt.legend(labels=val.index, loc=\"best\")\nplt.show()","1986d2e3":"# **Q23**\n\n**Does your current employer incorporate machine learning methods into their business?**","91e8759b":"**Facts -**","ea7dd214":"**Facts -**\n\n- **67.4%** participants has **NEVER** used TPUs.\n- while **14%** participants has used TPUs **2-5 times**.\n- and **12.2%** participants has used TPU only **ONCE**.\n\n\n**Observation -**\n- Most participants prefer **not to depend on TPUs** or they don't know how to use TPU in particalur projects.","59ca445e":"## **Q8**","c5bcffb7":"**Facts -**\n\n- Most data scientiest has **a Laptop** as **1st** preferance as workstations **65.7%** .\n- followed by **a Personal Computer \/ Desktop** as another mean of workstations **along with 19.9%**.\n- **Cloud Computing Platforms** as **3rd** preference with **9.42%**\n\n\n**A Laptop** and **A Personal Computer \/ Desktop** both are favorite workstations for Data Scientiest as well as **Cloud Computing Platform** also used but those are chargeable. \n\nA **Deep Learning Workstations** are also used but not to solve regular problem solving but in **Deep Learning** or **Advance Deep Learning** problems for large dataset or large featured datasets.","7484097d":"**Facts -**\n\n- **around 17,500** participants uses **Matplotlib**.\n- followed by **Seaborn** and **Plotly\/Plotly Express** with around **12,500** and **5750** participants respectively.\n\n\n**Observations -**\n\nAs usual **Matplotlib** are most favourite data visualization tools in Data Science field. Other most favourite visualization tools are **Seaborn** and **Plotly**. These visualization tools are easy to uses and faster to visualize the data.\n\n","455a939e":"## **Q29**\n\n#### **Present - Q29_A - Do you use any of the following cloud computing products on a regular basis?**\n\n#### **Future - Q29_B - In the next 2 years, do you hope to become more familiar with any of these specific cloud computing products?**","15bac8ac":"### **Total Visualization Libraries used regularly per Participants**","e4dcba35":"## **Q1 - What is your age group?**","10284ea0":"### **Total DA or ML Application Sharing Platforms**","832e24cf":"## **Q31 -**\n\n\n#### **Present** - **Q31 A - Do you use any of the following managed machine learning products on a regular basis?**\n\n\n#### **Future** - **Q31 B - In the next 2 years, do you hope to become more familiar with any of these managed machine learning products?**","d2c9444a":"**Facts -**\n\n- **9100** individuals works on **Analyze and Understand Data**\n- **5100** individuals works on **Building Prototypes for Machine Learning models**\n- **4500** individuals works on **Build and\/or run the Data Infrastructure**\n- **around 4000** individuals works on **Improve existing ML Models**\n","aa905f4c":"- **Python** is widely used programming language for Data Science purpose\n- Followed by **R** and **SQL** are also used for data science.","db09a4af":"### **Total Computer Vision Methods used regularly per Participants**","cdc58e8a":"#### **Total Host Notebooks used regularly per Participants**","1a64ed3c":"## **Q10** - **Host Notebooks used on Regular Basis**","a79ccbea":"**Facts -**","230c6ef1":"**Facts -**\n\n- In Present,\n  - Any **1** Cloud Computing platorm are used by **3352** participants which are **75.5%**\n  - Any **2** Cloud Computing platorm are used by **785** participants which are **17.7%**\n  - Any **3**  Cloud Computing platorm are used by **299** participants which are **6.74%**\n  \n\n- In next 2Years, \n  - Any **1**  Cloud Computing platorm are used by **3367** participants which are **36%**\n  - Any **3**  Cloud Computing platorm are used by **3359** participants which are **35.9%**\n  - Any **2**  Cloud Computing platorm are used by **2621** participants which are **28%**\n  \n  \n**Observation -**\n\n**In present**, many participants are using any **1** to **3** cloud computing platforms either in their companies or for practicing purpose. **In next 2 years**, many participants are willing to learn any **1** to **3** cloud computing platforms either **to enter in Data Science field** or **Upskill existing skills**","1811505a":"# **Q11**","b2a6ef46":"# **Q12**\n\n**`GPUs` Used Regular Basis**","e3ceb458":"**Facts -**\n\n\n- **31%** participants are from **0-49 employees** companies.\n- **21%** participants are from **10,000 or more employees** companies\n- **19%** participants are from **1000-9,999 employees** companies\n\n\nMost participants are from **Start-up Companies** followed by **Large Companies or MNCs**. We can say that, Start-Up Companies and MNCs are using Data Science more frequently rather other companies. ","50b3fbbd":"**Facts -**\n\n- **836** participants enjoys **Amazon Web Services**(AWS).\n- followed by **Google Cloud Platform**(GCP) and **Microsoft Azure** with **738** and **454** participants.\n\n\n**Observation -**\n\nDevelopers enjoys **AWS**, **GCP** and **Microsoft Azure** cloud service platforms more than other cloud platforms. These cloud providers are having amazing services which works from **IaaS** to **SaaS**. And thses platforms comes in handy in modern Industries.","182102a0":"### **Total Business Intelligence Counts per Participants**","55740aae":"## **Q39**\n\n\n**Where do you publicly share your data analysis or machine learning applications?**","d4a4e2a0":"### **Total Managed Machine Learning Products Count used or desired to work by Participants**","576bf148":"**Observation -**\n\n- In present, from any 1 BigData to any 3 BigData products are used by users simultaneously.\n- In next 2 years, from any 1 to any 4 Bigdata products are learning plans of users.","0b977994":"**Observations -**\n\n- **MySQL** is **SQL** BigData product and it is high in demands from most industries.\n- followed by **PostgreSQL** and **Microsoft SQL Server**\n- **MongoDB** is **NoSQL** BigData product and also used widely in most industries for **NoSQL**.","9ab0803a":"# **Q18**\n\n**Which categories of computer vision methods do you use on a regular basis ?**","4aec2057":"- **Colab Notebooks** is used by **around 9,750** participants regularly.\n- Followed by **Kaggle Notebooks** is used by **around 9,500** participants regulary.\n\n\nAs we can see above Bar Chart, we can conclude that **around 19,000** participants frequently using either **Colab Notebooks** or **Kaggle Notebooks** due to these host notebooks might has pre-installed dependencies and faster than other host notebooks.","3e5f2651":"### **Total Cloud Computing Platforms Use per Participants**","1b196788":"#### **Total Integreated Development Environments used regularly per Participants**","dae2a673":"**Facts -**","21928d41":"#### **Total Programing Languages used regularly per Participants**","74258f18":"### **Total NLP Methods used regularly per Participants**","4a30468b":"**Facts -**","cd530c3c":"## **Q30 -**\n\n\n#### **Present** - Q30A **Do you use any of the following data storage products on a regular basis?**\n#### **Future** - Q30B **In the next 2 years, do you hope to become more familiar with any of these specific data storage products?** \n\n\n**Note -** Q30-B consists as **`np.nan`**. As it does not has any value in it. So we can not compare it with present values.","bd5b2df1":"### **Total Machine Learning Frameworks used regularly per Participants**","1b53d149":"## **Q28 - the Cloud Platforms that you are familiar with, which has the best developer experience?**","05e64091":"## **Q6**","13663962":"**Facrts -**\n\n- **In Present -**\n  - **2575** participants are using **Other Cloud Platforms**\n  - **2270** participants are using **Amazon Elastic Compute Cloud** (**EC2**)\n  - **1960** participants are using **Google Cloud Compute Engine**\n  - **1503** participants are using **Microsoft Azure Virtual Machines**\n  \n\n- **In next 2_Years -**\n  - **7497** participants wants to learn **Google Cloud Compute Engine**\n  - **5793** participants wants to learn **Microsoft Azure Virtual Machines**\n  - **5373** participants wants to learn **Amazon Elastic Compute Cloud**\n  - **2575** participants wants to learn **Other Cloud Platforms\n  \n  \n  \n**Observation -**\n\nAs we can see from above Bar charts, \n- **In Present**, **EC2 (Amazon)**, **Google Cloud Compute Engine**, **Microsoft Azure Virtual Machines** are used mostly and the reason for their use is either these platforms are **Easy and User Friendly** or **Widely Used in Industries**.\n\n\n- **In Next 2 years**, same 3 cloud compute platforms are using but **EC2** of Amazon are given 3rd Priority to learn than other 2 cloud compute. And also we can say, **in next 2 years** **Google Cloud Compute Engine** will more preferred over **Amzon's EC2**, and followed by **Microsoft Azure Virtual Machine**","1f75b2f5":"# **Q15**\n\n**How many years you are using `Machine Learning` methods?**","87581108":"**Observations -**\n\n- In present, any **1** managed ML products are used by **68.5%** users. Followed by any **2** or **3** ML products.\n  - Here, we can say any **1** or **2** or **3** managed ML products are used most users to work on Machine Learning in cloud.","a5127f0a":"**Facts -**\n- in **Presently using Regular Basis**\n  - **Amazon Web Services (AWS)** used by **around 3721** participants regularly\n  - followed by **Google Cloud Platform (GCP)** and **Microsoft Azure** ysed by around **3142** and **2450** respectively on regular basis.\n  - Other cloud service providers also used reglarly as -\n    - **IBM Cloud \/ Red Hat** used by **572**\n    - **Oracle Cloud** used by **454**\n    - **VMware Cloud** used by **390** and so on.\n  \n- In **Future** [in next 2 years] -\n  - **7494** participants are planing to work in **Amazon Web Services (AWS)**.\n  - followed by **Google Cloud Platform (GCP)** with **7484** and **Microsoft Azure** with **5648** participants respectively planning to work in those Cloud Platforms.\n  \n  \n\n**Observation -**\n\nFrom **Present Bar Chart** and **Future Bar Charts**, we can see **AWS** is widely used regularly in present as well as 1st priority to work in future in cloud service and it might be having large services and has high demands to. Followed by **GCP** and **Microsoft Azure**.","fffbf70d":"**Facts -**\n\n- Most frequently **1** machine learning fremework is used by around **4500** participants.\n- followed by **3** and **2** machine learning fremeworks are used by around **3600** and **3500** participants respectively.\n\n**Observations -**\n\nMost participants uses **1** ML fremework to **4** ML fremeworks on regular basis.","dc48ea57":"# **Q16** \n\n**Which `Machine Learning Frameworks` do you use on a regular basis?**","645ab36b":"**Around 80%** individuals works on either one or more tasks simultaneously for any tasks from below -\n\n- **Analyze and Understand Data**\n- **Builduing Prototypes for Machine Learning**\n- **Build and\/or run the Data Infrastructure**\n- **Improve Existing ML Models**\n- **Build and\/or run ML Services**","1303ff29":"Most of coders are either **1-3 years** or **< 1 years** of coding experience. Both of it consists **around 53%** of all participants. We can say thses participants are either students or learners too.\n\n\nWe can also see some participants **Never Coded** are about to **4%**.","6bfe679d":"## **Q3 - Which country do you currently reside?**","84d1e0ca":"**Facts -**\n\n- **atleast 1** hosted notebook are used regularly by **more than 9000** data scientist.\n- **2** hosted notbook are used regularly by **around 5750** data scientis.\n\nIn data science upto 2 hosted notebooks are used regularly by data scientiest. These hosted notebooks might have good speed and may has pre-install dependencies, so during work data scientiest doesn't have to install required dependecies. Most data scientists uses **2 Hosted Notebooks** are either **Colab** or **Kaggle Notebook**. These 2 are widely used.","f8a4cbd2":"### **Total Machine Learning Algorithms used regularly per Participants**","83603c62":"**Facts -**\n\n- **around 7500** participants uses **2** visualization tools at a time.\n- **around 5500** participants uses only **1** visualization tool at a time.\n- **around 4400** participants uses **3** visualization tools at a time.\n\n\n**Observations -**\n\nParticipants likes to use 1 to 3 data visualization tools \/ libraries to visualize data at same time.","e25696b4":"### **Total Auto-Machine Learning Tools used per participants**","b3ce8c90":"**Reusable Functions**","451504c2":"**Facts -**\n\n- **Around 56%** kagglians are belongs to **Under 30** age.\n- **around 23%** kagglians are belong to **Under 40** age.\n\n\n**Observations -**\n\n- Most of Kagglians are either college students or early mid-age participants.\n- We also has some participants from **Above 50** years age also, they might be exicited to learn new things.","16e9e7d8":"## **Q2 - What is your Gender?**","8803f7d7":"**Facts -**","88d98933":"**Observations -**\n\n\n- **In Present,**\n  - **MySQL** are most favorite **BigData** products.\n  - followed by **PostgreSQL**, **Microsoft SQL Server**, **MongoDB**, these BigData products are most widely used by participants in present, and these BigData products are even widely used in Industries also.\n\n- **In Next 2 years,**\n   - **MySQL** are most favorite to leaners and at top priority.\n   - followed by **MongoDB**, **PostgreSQL**, **Google Cloud SQL** and **Microsoft SQL Server**\n   \n   \n   \nWe can say that, in most industries **MySQL** are used more than other **SQL**s and **MongoDB** are used more than other **NoSQL**s. And these skill sets are having ampale of demands than other SQL or NoSQL BigData products.","934a0b48":"### **Total Specific Auto-ML Use per participants**","0d2ab6f9":"**Facts -**\n\n- **25%** participants are employed in **Computers\/Technology** Industry.\n- **19.50%** participants are employed in **Academics\/Education** Industry.\n- **9%** participants are employed in **Accounting \/ Finance** Industry.\n\n\n- Participants from **Hospitality\/Entertainments\/Sports**, **Military\/Security\/Defence**, **Online Business\/Internet-based Sales** and **Non-Profit\/Service** Industries are employed **Less than 2%** data scientists.","3b258ca7":"## **Q33** \n\n- **Which of the following big data products (relational database, data warehouse, data lake, or similar) do you use most often?**","948dd4d3":"**Facts -**\n\n- **1** computer vision methods are used **around 32%** data scientists on regular basis.\n- **2** computer vision methods are used **around 29%** data scientists on regular basis.\n- **3** computer vision methods are used **around 21%** data scientists on regular basis.\n\n\n**Upto 82%** Data Scientists uses either **1** or **2** or **3** Computer vision methods on regular basis.It might be either one or multiple of following -\n   - **Image Classification**\n   - **Image Segmentation**\n   - **Object Detection**\n   - **General Purpose Image \/ Video Tools**\n    \n   ","ad861251":"**Facts -**","94c0041e":"### Total DS Source Reports used by Data Scientist","a5323bd1":"## **Q32 -**\n\n\n#### **Present** - **Q32 A - Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you use on a regular basis?**\n\n\n\n#### **Future** - **Q32 B - Which of the following big data products (relational databases, data warehouses, data lakes, or similar) do you hope to become more familiar with in the next 2 years?**","dbced1d6":"### **Total use**","c0d57b5e":"**Facts -**\n\n- **Around 13000** Data scientists used **None** Deep learning Hardwares, which accumulate **around 45%**\n- **8000** Data Scientiests uses **NVIDIA GPUs** .\n- **around 3750** data scientiest uses **Google Cloud TPUs**.\n\n\n**NVIDIA GPUs** are most famouse and highly used and recommended by data scientiests and data science communities too. And it is bulid-in with PCs \/ Laptops\n\nAnd for using **Google Cloud TPUs**, **AWS Trainium Chips** and **AWS Inferentia Chips** are cloud based GPUs \/ TPUs. And less popular for Data Science.","eee37a04":"**Facts -**\n\n- **2776** participants using any **1** Data Storage with **59.3%**\n- **1327** participants using any **2** Data Storage with **28.4%**\n- **346** participants using any **3** Data Storage with **7.39%**\n- **129** participants using any **4** Data Storage with **2.76%**\n- **67** participants using any **6** Data Storage with **1.43%**\n- **34** participants using any **5** Data Storage with **0.727%**\n\n\n**Observation -**\n\nData Storage users using any **1** or **2** data storage services providers. These data storage are either widely used or high in demand.","03d933e5":"**Facts -**\n\n- **22.5%** companies has **1-2** individuals whose are responsible for Data science workloads.\n- **22%** companies has **20+** individuals whose are responsible for Data science workloads.\n- **19%** companies has **0** individual responsible for Data science workloads, \n    - **Either these companies not has Data Science Department or these companies don't want to disclose this.**\n    \n    \n- **16%** companies has **3-4** individuals whose are responsible for data science workloads.\n\n\n\nIn **38.5%** companies might has **1 to 4** individuals, whose are actually responsible for complate data science workloads. These companies are either **Small Companies** or **Start-Up Companies**. While where **20+** individuals are responsible for data science workloads are might be **Large Companies or MNCs**.\n\n","a9fca727":"# Changing Data type of Time Duration columns.\ndf['Time from Start to Finish (seconds)'] = df['Time from Start to Finish (seconds)'].astype('int')\n\n# Converting Seconds into minutes\ndf[\"duration_mintues\"] = round(df['Time from Start to Finish (seconds)'].apply(lambda x: x\/\/60))\n\n# Substracting Total minutes (seconds) from Total Seconds\ndf[\"duration_remain_sec\"] = df['Time from Start to Finish (seconds)'] - df[\"duration_mintues\"]*60","a3c60b96":"- **Jupyter Nootbook** and **Jupyter** are recommended by around **21,700** participants\n- followed by **Visual Studio Code** and **Visual Studio** are recommended by around **14,000** participants.\n- followed by **PyCharm** also recommended by around **7,500** participants\n\n\n- These two IDEs, i.e., **Jupyter** and **VS Code** are looks most popular in Data Science, followed by **PyCharm**.","ca3cc8ef":"**Facts -**\n\n- **2575** participants using **Other** Data Storage products regularly.\n- **2308** participants using **Amazon Simple Storage Service (S3)** Data Storage products regularly.\n- **1950** participants using **Google Cloud Storage (GCS)** Data Storage products regularly.\n- **908** participants using **Microsoft Azure DataLake Storage** Data Storage products regularly.\n- **841** participants using **Microsoft Azure Disk Storage** Data Storage products regularly.\n- **772** participants using **Google Cloud Filestore** Data Storage products regularly.\n- **685** participants using **Amazon Elastic File System (EFS)** Data Storage products regularly.\n\n\n**Observation -**\n\nAs we can see from above Bar chart, If we combine **Data Storage Products** provided by **Companies**. We can see **Amazon Data Storage** products are in high demands and used widely in industries, which consists **Amazon Simple Storage Service** (**S3**) and **Amazon Elastic File System** (**EFS**). Followed by **Google Data Storage** products, which consists **Google Cloud Stoarage** (**GCS**) and **Google Cloud Filestore**, and **Microsoft Azure Data Storage** products, which consists **Microsoft Azure Data Lake Storage** and **Microsoft Azure Disk Storage**.\n\n\nThese **3 Cloud Companies** cloud data storage are highly and widely used in many industries to store data and they provide separate data storage facility on the basis of **Pay as You Use**, it means we only have to pay as we use till date.","8b16ead9":"### **Total BigData Products Counts Per Participants**","af80d3a8":"**Facts -**\n\n- **more than 9000** participants are using ML methods are lies in **Under 1 year**\n- **around 4700** participants are using ML methods are lies in **1-2 years**.\n- **around 3900** participants **Never used ML methods** but they might starting or planning to use ML methods now onwards.\n\n\n**Observation -**\n\nThose who are using ML methods **more than 2 years** are *Less active on Kaggle*. But those who are using ML methods **upto 2 years** are *Very active on Kaggle*. Even some participants never used ML methods before those are also active on Kaggle and willing to use ML methods in futures.","9e28ae19":"## **Q35 - Which of the following business intelligence tools do you use most often?**","da6c5588":"**Facts -**","6853789f":"### **Total Cloud Computing Platforms Use per Participants**","86ee94d1":"**Facts -**\n\n- **around 36%** data scientists are using any **1** NLP method regularly.\n- **around 34%** data scientists are using any **2** NLP methods regularly.\n- **around 20%** data scientists are using any **3** NLP methods regularly.\n\n\n**Around 90%** data scientists are using any **1** to **3** NLP methods on regular basis. Either one or multiple out-off following -\n  \n  - Image Classification\n  - Image Segmentation\n  - Object Detection\n  - Genral Purpose Images \/ Videos","84f3a4e6":"**Facts -**\n\n- **13%** companies are just **Exploring ML Methods**.\n- **12.5%** companies are **Not Using ML Methods**.\n- **around 25%** companies are **Using ML Methods** are either one  of -\n   - **Established and using more than 2 years in productions** or\n   - **Started and using less than 2 years in productions** or\n   - **Using for Understanding Patterns**\n   \n   \n - **around 39%** has Missing values.","be815dfa":"# **Q19**\n\n**Which Natural Language Processing (NLP) Methods used on a regular basis?**","cf2a441d":"## **Q5**","42f3cb89":"Looks **Scikit-Learn** is most favourite and popular ML framework among other frameworks. **Around 14000** participants uses scikit-learn framework for ML. Followed by **TensorFlow** and **Keras** these two frameworks used in advance ML application, i.e., **`Deep Learning`**, with around **9300** and **8000** participants  respectively.\n\nTheir are also some other ML frameworks such as **PyTorch** and **XGBoost** with **around 6000** participants in each frameworks.\n\nThese 5 frameworks are used frequently in Machine Learning.","1badd9dc":"**Facts -**\n\n- **Image Classification and Other** Computer vision methods are used regularly by **around 4250** data Scientiests.\n- followed by **Image Segementation** and **Object Detection** methods are used frequently by **around 2700** each.\n- **General Purpose image \/ video tools** are also used by **below 2700**.\n\n\n\n**Image Classifiaction and Other** and **Image Segmentation** methods are used more frequently and widly used computer vision method. Followed by **Object Detection** methods are also used regularly.","e3960aee":"**Converting Time from Minutes and Seconds**","757a1179":"### **Total Online Course Platforms used to Learn Data Science**","35c34f49":"**Facts -**","998b5091":"# Data Exploration\n\n**Checking Head and Tail Records**","b2fc03cd":"# **Q14**\n\n**Which `Data Visualization` tool or libraries used on regular basis**","c6007048":"**Facts -**\n\n- **39%** of Kagglian are holding Master's Degree.\n- while **38%** are holding Bachelor's Degree and **12%** are  holding Doctoral Degree.\n\n\n**Observation -**\n**Master's Degree** holders participats more frequent as compared with other degrees. Followed by **Bachelor's Degree** and **Doctoral's Degree**. ","c2807201":"## **Q40**\n\n\n**On which platforms have you begun or completed data science courses?**","2ac10e20":"**Facts -**","54c6c697":"**Facts -**","bb777492":"**Facts -**\n- **2 programming languages** are used regularly by **7000** participants,\n- **1 programming language** is used regularly by **6000** participants,\n- **3 programming languages** are used regularly by **5600** participants. \n\n\n\nMost data scienties are use 1 to 3 different languages on regular basis.\n","77522fdf":"**Facts -**\n- In **Present**\n  - **3892** participants are using any **1** cloud service provider which are **55.3%**\n  - **1945** participants are using any **2** cloud service providers which are **27.7%**\n  - **827** participants are using any **3** cloud service providers which are **11.8%**\n  - **368** particpicants are using **4 or more than 4** cloud services regluarly which are **5.2**.\n\n\n- In **Future**\n   - **3207** participants are planning to use any **1** cloud service provider which are **28.5%**\n   - **2998** participants are planning to use any **2** cloud service providers which are **26.6%**\n   - **2685** participants are planning to use any **3** cloud service providers which are **23.9%**\n   - **1319** participants are planning to use any **4** cloud service providers which are **11.7%**\n   - **1047** participants are planning to use **5+** cloud service providers which are **9.3%**\n\n\n**Observations -**\n\n- **Around 95%** participants are using from **1** to **3** cloud service providers on regular basis. And thse cloud providers are might has ample of services and widely used in Industries too.\n\n- **Around 90%** participants are planning to use from **1** to **4** cloud providers in next **2 years** as their future requirements.","cc0f046a":"# **Q42**\n\n**Who\/what are your favorite media sources that report on data science topics?**","4aedf2ca":"### **Total Tasks Performed by Participants Regularly**","01340fd0":"## **Q36**\n\n\n- **Present -** **Q36 A** Do you use any automated machine learning tools (or partial AutoML tools) on a regular basis?\n- **Future -** **Q36 B** Which categories of automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?","d8dcf77f":"**Facts -**\n\n- **Upto 13900** participants uses **Linear or Logistic Regression** regularly.\n- **Upto 11900** participants uses **Decision Trees or Random Forests** regularly.\n- **Gradient Boosting Machines** and **Convolutional Neaural Networks** are also used regularly by around **7500** and **7400** respectively.\n\n\n**Observation -**\n\n> - **Linear or Logistic Regression** and **Decision Tree or Random Forests** are highly popular Machine Learning algorithms and widely used algorithms in solving Supervised Machine Learning problems. These algorithms are fast and less complicated.\n> - **Gradient Boosting Algorithms** also used to provide boost to base estimator algorithms. **CNN** [Convolutional Neaural Networks] is used more frequently in Deep Learning problems.\n> - We can see **Supervised Machine Learning** algorithms are used more frequently than **Unsupervised Machine Learning** algorithms. And these algorithms also very popular not only in Kaggle but also in solving Real Time problem. ","ab108212":"## **Q7 - Which Programming Languages you used on regular basis?**","3a706c36":"# Loading Required Packages","3856d8e6":"**Facts -**\n\n\n- **Around 29%** kagglian are from only from **India**.\n- followed by **United States of Nation** with **10%**.\n\n\n**Observations -**\n- Indian contributes more in kaggle as compared to other countries.\n","3c55b413":"## **Q26**\n\n\n**Approximately how much money have you (or your team) spent on machine learning and\/or cloud computing services at home (or at work) in the past 5 years (approximate USD)?**","306824ed":"# **Q41**\n\n\n**What is the primary tool that you use at work or school to analyze data?**","b79a079c":"- **Python** is most regularly used language followed by **SQL**.\n- **Julia** and **Swift** are less regularly used languages.\n\n- ","39addcac":"### **Continent -**","427b3324":"**Facts -**\n\n- **51%** kagglian are only from **Asia**.\n- where **Europe**, **North America** and **Africa** contributes around **16.7%**, **12.6%**, and **8%** respectively\n\n**Observation -**\n- Asian participants more active and frequently using kaggle as compare to other continents participants.","c7b8c804":"# Loading dataset","3860f1fa":"**Facts -**\n\nIn present,\n  - **6381** participats does not use any manage machine learning systems.\n  \n  \n  - **Amazon SageMaker** are used regularly by **991** participants.\n  - **Azure Machine Learning Studio** are used regularly by **945** participants.\n  - **Databricks** are used regularly by **825** participants.\n  - **Google Cloud Vertex AI** are used regularly by **714** participants.\n  - **DataRobot** are used regularly by **332** participants.\n  - **Rapidminer** are used regularly by **293** participants.\n  \n  \nIn Next 2years,\n- **Google Cloud Vertex AI** are planned to use by **5304** participants.\n- **Azure Machine Learning Studio** are planned to use by **5029** participants.\n- **Amazon SageMaker** are planned to use by **3649** participants.\n- **Databricks** are planned to use by **2202** participants.\n\n\n**Observations -**\n\nCurrently, we can see in above bar chart, cloud based Machine Learning are less used by Machine Learners. But in next 2 years, more people will use it regularly as compared to present.","cba475f9":"**Facts -**\n\n- **3 ML Algorithms** are used regulary by around **4500** participants.\n- follopwed by **2** and **1 ML Algorithms** are used regularly by around **3750** and **2900** participants respectively.\n- **4 ML Algorithms** used regularly by around **2750** participants.\n\n\n**Observations -**\n\n**3 ML** algorithms are used mostly by participants and followed by **2**, **1** and **4** algorithms are also used. We can say, in most Machine Learning problems upto **4 ML Algorithms** are used in real time or those are the final Machine Learning algorithms.","ded720e8":"# **Q13**\n\n**`TPU` Uses**","965c2a6b":"**Facts -**\n\n- **Word-Embeddings\/Vectors** NLP method is used by **22.6%** data scientists on regular.\n- **Transformer Language Models** NLP method is used by **20.1%** data scientists on regular.\n- **Encoder-Decoder Models** NLP method is used by **17.3%** data scientists on regular.\n- **Other** NLP method is used by **22.1%** data scientists on regular.\n\n\n**Word-Embeddings\/Vectors**, **Transformer Language Models** and **Encoder-Decoder Models** are highly used Natural Language Processing methods which are used regularly by many data scientists.","caad0996":"Hey Hi,\n\nWelcome to my first Competition Notebook as well as my first notebook published on Kaggle.com\n\nAs **Kaggle** is one of the most favorite Data Science practice and compete with other fellow Data Scientists. \n\nIn 09\/01\/2021 to 10\/04\/2021 an survey was conducted on **Kaggle.com** by **Kaggle**. The survey was about **conduct an industry-wide survey** that present comprehensive view of the **state of data science and machine learning**.\n\nThe purpose of this note book is to **provide Story of Data Science and Machine Learning**, I tried my best to give insights on each and every **Question** through Visualization of every questions mmentioned in **Supplements** as well as **Dataset**.\n\nGothrough it and if you find this notebook useful please **UpVote** and you like my code please try yourself. \n\nAnd if their is something is missing please give your insights by commenting....\n","bb950198":"df[\"Q25\"].value_counts()","a1893bf9":"**Facts -**\n\n- **5903** participants spend **0 USD** in last 5 years.\n- **2534** participants spend **100-999 USD** in last 5 years.\n- **2491** participants spend **1000-9999 USD** in last 5 years.\n- **1929** participants spend **1-99 USD** in last 5 years.\n- **1309** participants spend **10,000 - 99,9999 USD** in last 5 years.\n- **1017** participants spend **100,000 or more USD** in last 5 years.\n\n\n**Observations -**\n\n**39%** participants used those cloud platform services or machine learning at their home which either **Free** or **One year free subscription** in last 5 years.These participants either **College Students** or **New Skill Learners**. \n\n\n**17%** participants used those cloud platforms which charges **less than 1000USD** either these participants are **FreeLancers** or **Counsultants**","97d8bf26":"# **Q22**\n\n**Approx. how many individuals are responsible for data science workloads at your place of business?**","8f1eeb5a":"# **Q20** \n\n**In which industry your current employer\/contract works**","db799f62":"**Facts -**","db66620c":"### Total Data Storage Counts per participants","7c829636":"## **Q37**\n\n- **Present -** **Q37 A** Which of the following automated machine learning tools (or partial AutoML tools) do you use on a regular basis?\n- **Future -** **Q37 B** Which specific automated machine learning tools (or partial AutoML tools) do you hope to become more familiar with in the next 2 years?","93decbd1":"# **Q17**\n\n**Which `ML Algorithms` do you use on a regular basis?**","f1e6bfe8":"## **Q9**","ec3c1353":"# **Q21**\n\n**What is the size of the company where you are employed?**","5abc6615":"## **Q34**\n\n- **Present** - **Which of the following business intelligence tools do you use on a regular basis?**\n- **Future** - **Which of the following business intelligence tools do you hope to become more familiar with in the next 2 years?**","535cbf23":"## **Q38**\n\n- **Present -** **Q38 A** Do you use any tools to help manage machine learning experiments?\n- **Future -** **Q38 B** In the next 2 years, do you hope to become more familiar with any of these tools for managing ML experiments?"}}