{"cell_type":{"14f7d18a":"code","effc7e89":"code","c15d3188":"code","e6fafbbb":"code","8f5f2441":"code","7aeb273b":"code","c0b5285a":"code","8fd063a9":"code","2b7ef664":"code","94f21744":"code","fd22284e":"code","17e69b98":"code","fb1896ed":"code","dc8a69e9":"code","c004247f":"code","dc7d3ff2":"code","1ab2b524":"markdown","78f3f18f":"markdown","e8a2f4f2":"markdown","1600584a":"markdown"},"source":{"14f7d18a":"%matplotlib inline\nimport numpy as np\nimport pandas as pd\nfrom glob import glob\nimport os\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nhelen_dir = '..\/input\/'\ndef read_annot_file(in_path):\n    with open(in_path, 'r') as f:\n        file_id = f.readline().strip()\n    out_df = pd.read_csv(in_path, skiprows=1, header=None)\n    out_df.columns = ['x', 'y']\n    out_df['file_id'] = file_id\n    return out_df","effc7e89":"annot_df = pd.concat([\n    read_annot_file(c_path).reset_index()\n    for c_path in \n    glob(os.path.join(helen_dir, 'annotation', '*', '*'))\n])\nannot_df.sample(3)","c15d3188":"all_image_dict = {os.path.splitext(f)[0]: os.path.join(p, f) \n              for p, _, files in os.walk(helen_dir) \n              for f in files if f.upper().endswith('JPG')}","e6fafbbb":"annot_df['path'] = annot_df['file_id'].map(all_image_dict.get)\nannot_df.dropna(inplace=True)","8f5f2441":"fig, m_axs = plt.subplots(3, 3, figsize = (15, 15))\nfor c_ax, (c_path, c_rows) in zip(m_axs.flatten(), \n                                  annot_df.groupby('path')):\n    img = imread(c_path)\n    c_ax.imshow(img)\n    c_ax.plot(c_rows['x'], c_rows['y'], 'r.')","7aeb273b":"fig, m_axs = plt.subplots(3, 3, figsize = (30, 30))\nmarker_id = ['face', 'nose', 'mouth_inner', 'mouth_outer', 'r_eye', 'l_eye', 'r_eyebrow', 'l_eyebrow']\nmarker_split = np.cumsum([0, 41, 17, 28, 28, 20, 20, 20, 20])\nmarker_dict = {marker_id[i]: (marker_split[i], marker_split[i+1]) for i in range(len(marker_split)-1)}\nfor c_ax, (c_path, c_rows) in zip(m_axs.flatten(), \n                                  annot_df.groupby('path')):\n    img = imread(c_path)\n    c_ax.imshow(img)\n    for label, (start, end) in marker_dict.items():\n        n_rows = c_rows.query(f'index>={start} and index<={end}')\n        c_ax.plot(n_rows['x'], n_rows['y'], '.', label=label)\n    c_ax.legend()","c0b5285a":"point_map = {i: [k for k, (n,x) in marker_dict.items() if n<=i<x] \n for i in range(annot_df['index'].max()+1) }\nannot_df['body_part'] = annot_df['index'].map(lambda x: point_map.get(x)[0])\nannot_df['body_part'].value_counts()","8fd063a9":"x_pad, y_pad = 35, 25","2b7ef664":"fig, m_axs = plt.subplots(2, 15, figsize = (30, 4))\nfilt_df = annot_df[annot_df['body_part'].isin(['l_eye', 'r_eye'])]\nfor c_axs, ((c_path, c_id), c_rows) in zip(m_axs.T, \n                                  filt_df.groupby(['path', 'file_id'])):\n    img = imread(c_path)\n    for c_ax, (body_part, n_rows) in zip(c_axs, c_rows.groupby('body_part')):\n        x_min = int(n_rows['x'].min()-x_pad)\n        x_max = int(n_rows['x'].max()+x_pad)\n        y_min = int(n_rows['y'].min()-y_pad)\n        y_max = int(n_rows['y'].max()+y_pad)\n        roi = img[y_min:y_max, x_min:x_max]\n        \n        c_ax.imshow(roi)\n        c_ax.set_title(f'{body_part}-{roi.shape[:2]}')\n        c_ax.axis('off')","94f21744":"from tqdm import tqdm_notebook\nall_rois = []\nfor ((c_path, c_id), c_rows) in tqdm_notebook(filt_df.groupby(['path', 'file_id'])):\n    img = imread(c_path)\n    for (body_part, n_rows) in c_rows.sort_values('body_part').groupby('body_part'):\n        x_min = int(n_rows['x'].min()-x_pad)\n        x_max = int(n_rows['x'].max()+x_pad)\n        y_min = int(n_rows['y'].min()-y_pad)\n        y_max = int(n_rows['y'].max()+y_pad)\n        all_rois += [img[y_min:y_max, x_min:x_max]]","fd22284e":"pd.DataFrame([{'size': c_roi.shape[0]\/c_roi.shape[1]} for c_roi in all_rois])['size'].hist()","17e69b98":"pd.DataFrame([{'x': c_roi.shape[0], 'y': c_roi.shape[1]} for c_roi in all_rois]).describe()","fb1896ed":"from PIL import Image\nout_shape = (128, 64)\nfig, m_axs = plt.subplots(5, 5, figsize = (10, 10))\nfor c_ax, c_roi in zip(m_axs.flatten(), all_rois):\n    k = Image.fromarray(c_roi)\n    c_ax.imshow(k.resize(out_shape, resample=Image.BICUBIC))","dc8a69e9":"import h5py\nwith h5py.File('eye_balls_rgb.h5', 'w') as f:\n    out_image = f.create_dataset('image', \n                                 shape=(len(all_rois), out_shape[1], out_shape[0], 3), \n                                chunks=(1, out_shape[1], out_shape[0], 3), \n                                 dtype=np.uint8,\n                                compression=8)\n    for i, c_roi in enumerate(tqdm_notebook(all_rois)):\n        out_image[i, :, :, :] = Image.fromarray(c_roi).resize(out_shape, resample=Image.BICUBIC)","c004247f":"!ls -lh *.h5","dc7d3ff2":"with h5py.File('eye_balls_rgb.h5', 'r') as f:\n    print(f['image'].shape)\n    print(f['image'].value.mean(), f['image'].value.std())","1ab2b524":"# Load in all the annotations","78f3f18f":"# Overview\n- Read in the images and annotations\n- Extract the different parts of the annotation\n- Display overlays with each part\n- Extract ROIs for the eyes\n- Packages and resize all of the eyes to be the same shape","e8a2f4f2":"The data uses the FUT standard\n```\n-a face outline (41 points),\n-a nose outline (17 points),\n-eyes outlines (20 points each),\n-eyebrows outlines (20 points each),\n-mouth outlines (inner and outer - 28 points each). \n```","1600584a":"# Collect All the Balls\nHere we grab all the ROIs and but them into one massive ragged array"}}