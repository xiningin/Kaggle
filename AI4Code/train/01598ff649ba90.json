{"cell_type":{"d49c7638":"code","ec410db5":"code","ff5d5c15":"code","5bb2ef4a":"code","497dcd65":"code","a2080ed3":"code","170eda37":"code","8410d6a2":"code","48f7349d":"code","800c9e3c":"code","9c6ec467":"markdown","7bf1b9ed":"markdown","41d1660a":"markdown","10ca92ef":"markdown","ef511bfd":"markdown","7500019f":"markdown"},"source":{"d49c7638":"!pip install torchsummary\n!pip install runx\n!pip install tqdm","ec410db5":"import os\nfrom glob import glob\n\nimport numpy as np\nimport pandas as pd\nimport torch\nfrom torch import nn\nfrom torch import optim\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import models, transforms\nfrom torchsummary import summary\nfrom PIL import Image\nfrom runx.logx import logx\nfrom tqdm.notebook import tqdm\n","ff5d5c15":"print(\"torch version {}\".format(torch.__version__))\n!nvidia-smi","5bb2ef4a":"# data split\nnp.random.seed(2020)\ndf_raw = pd.read_csv(\"..\/input\/jiangnan2020\/train.csv\", encoding=\"utf8\")\nsample_index = np.arange(len(df_raw))\nnp.random.shuffle(sample_index)\nimages, labels = df_raw.values[:, 0][sample_index], df_raw.values[:, 1][sample_index]\ndata_size = len(df_raw)\n\n\ndef get_one_ds():\n    train_size = int(data_size * 0.8)\n    train_images, valid_images = images[:train_size], images[train_size:]\n    train_labels, valid_labels = labels[:train_size], labels[train_size:]\n    pd.DataFrame({'id': train_images, 'label': train_labels}).to_csv(\".\/new_train.csv\", index=False)\n    pd.DataFrame({'id': valid_images, 'label': valid_labels}).to_csv(\".\/new_valid.csv\", index=False)\n    print(\"dataset split ok\")\n\nget_one_ds()","497dcd65":"class TrainDataset(Dataset):\n\n    def __init__(self, desc_file, data_folder, transform=None):\n        self.all_data = pd.read_csv(desc_file).values\n        self.data_folder = data_folder\n        self.transform = transform\n\n    def __getitem__(self, index):\n        filename, label = self.all_data[index, 0], self.all_data[index, 1]\n        img = Image.open(os.path.join(self.data_folder, str(filename)+\".jpg\")).convert('RGB')\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, label\n\n    def __len__(self):\n        return len(self.all_data)\n\n\nclass TestDataset(Dataset):\n\n    def __init__(self, desc_file, data_folder, transform=None):\n        self.all_data = pd.read_csv(desc_file).values\n        self.data_folder = data_folder\n        self.transform = transform\n\n    def __getitem__(self, index):\n        filename = self.all_data[index, 0]\n        img = Image.open((os.path.join(self.data_folder, str(filename) + \".jpg\"))).convert('RGB')\n        if self.transform is not None:\n            img = self.transform(img)\n        return img, filename\n\n    def __len__(self):\n        return len(self.all_data)\n    \n\ndef get_transforms(image_size):\n    normMean = [0.59610313, 0.45660403, 0.39085752]\n    normStd = [0.25930294, 0.23150486, 0.22701606]\n    train_tfms = transforms.Compose(\n        [\n            transforms.Resize((image_size, image_size)),\n            transforms.RandomAffine((0, 0), (0.05, 0.05)),\n            transforms.RandomHorizontalFlip(p=0.5),\n            transforms.RandomGrayscale(),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=normMean, std=normStd)\n        ]\n    )\n    test_tfms = transforms.Compose(\n        [\n            transforms.Resize((image_size, image_size)),\n            transforms.ToTensor(),\n            transforms.Normalize(mean=normMean, std=normStd)\n        ]\n    )\n    return train_tfms, test_tfms","a2080ed3":"def get_model():\n    model = models.resnet34(pretrained=False)\n    model.fc = nn.Linear(512, 2)\n    return model\nmodel = get_model()\nmodel = model.to(\"cuda:0\")\nsummary(model, (3, 200, 200))","170eda37":"# hyper params\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\nIMG_SIZE = 200\nBATCH_SIZE = 64\nEPOCH = 50\nLR = 0.001\nstart_epoch = 0\n","8410d6a2":"# data\ndesc_train = os.path.join('.\/new_train.csv')\ndesc_valid = os.path.join('.\/new_valid.csv')\n\n\ntransform_train, transform_test = get_transforms(IMG_SIZE)\n\n\ntrain_data = TrainDataset(desc_train, data_folder=os.path.join('..\/input\/jiangnan2020\/train\/train\/'), transform=transform_train)\nvalid_data = TrainDataset(desc_valid, data_folder=os.path.join('..\/input\/jiangnan2020\/train\/train\/'), transform=transform_test)\n\n# construct DataLoader\ntrain_loader = DataLoader(dataset=train_data, batch_size=BATCH_SIZE, shuffle=True)\nvalid_loader = DataLoader(dataset=valid_data, batch_size=BATCH_SIZE, shuffle=False)\n\n\nnet = get_model()\nnet.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(net.parameters(), lr=LR, momentum=0.9, weight_decay=0.001)\nscheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, last_epoch=start_epoch-1, T_max=EPOCH, eta_min=1e-10)\n\n\ndef train(epoch):\n    net.train()\n    train_loss = 0.0\n    correct = 0.0\n    total = 0.0\n    for step, data in enumerate(train_loader):\n        x, y = data\n        x, y = x.to(device), y.to(device)\n        out = net(x)\n        loss = criterion(out, y)\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n\n        _, pred = torch.max(out.data, 1)\n        total += y.size(0)\n        correct += (pred == y).squeeze().sum().cpu().numpy()\n        train_loss += loss.item()\n\n        if step % 100 == 0:\n            print(\"epoch\", epoch, \"step\", step, \"loss\", loss.item())\n\n    train_acc = correct \/ total\n    print(\"epoch {} train accuracy {}\".format(epoch, train_acc))\n\n\ndef valid(epoch):\n    net.eval()\n    valid_loss = 0.0\n    correct = 0.0\n    total = 0.0\n\n    with torch.no_grad():\n        for step, data in enumerate(valid_loader):\n            x, y = data\n            x, y = x.to(device), y.to(device)\n            out = net(x)\n            loss = criterion(out, y)\n\n            _, pred = torch.max(out.data, 1)\n            valid_loss += loss.item()\n            total += y.size(0)\n            correct += (pred == y).squeeze().sum().cpu().numpy()\n    valid_acc = correct \/ total\n    print(\"epoch {} valid accuracy {}\".format(epoch, valid_acc))\n    return valid_acc\n\nlogx.initialize(logdir=\".\/runs\/\")\n\nfor i in range(start_epoch, start_epoch + EPOCH):\n    train(i)\n    scheduler.step()\n    valid_acc = valid(i)\n    logx.save_model({'state_dict': net.state_dict(), 'last_epoch': i}, metric=valid_acc, epoch=i, higher_better=True, delete_old=True)","48f7349d":"!ls runs\/","800c9e3c":"# load best model in metric acc\nfinal_model = get_model()\npth_file = glob(\".\/runs\/best_*.pth\")[0]\nfinal_model.load_state_dict(torch.load(pth_file)['state_dict'])\nfinal_model.to(device)\nfinal_model.eval()\n\n_, test_tfms = get_transforms(IMG_SIZE)\ndesc_test = os.path.join('..\/input\/jiangnan2020\/test.csv')\nvalid_data = TestDataset(desc_test, data_folder=os.path.join(\"..\/input\/jiangnan2020\/test\/test\/\"), transform=test_tfms)\ntest_loader = DataLoader(dataset=valid_data, batch_size=BATCH_SIZE, shuffle=False)\n\nrst = []\nfiles = []\nfor x, y in tqdm(test_loader):\n    with torch.no_grad():\n        x, filename = x.cuda(), y\n        out = net(x)\n        _, pred = torch.max(out.data, 1)\n        rst.extend(list(pred.cpu().numpy()))\n        files.extend(list(filename.numpy()))\n\nsubmit = pd.DataFrame({'id': files, 'label': rst})\nsubmit.to_csv(\"submit.csv\", encoding=\"utf8\", index=False)","9c6ec467":"## model","7bf1b9ed":"## inference","41d1660a":"\n## data prepare","10ca92ef":"# a simple baseline with resnet34 \n\n> this is a simple baseline for this taask, i got score online for public is ..., you can contact me by QQ(1695735420) for any question\n\n> run this notebook, you need open GPU and Internet","ef511bfd":"## package","7500019f":"## train"}}