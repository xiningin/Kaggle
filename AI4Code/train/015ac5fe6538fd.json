{"cell_type":{"453f7eb1":"code","5f808fa2":"code","0ec7dda2":"code","762cd8d6":"code","eecf54bc":"code","7c9731e1":"code","7f8f7bab":"code","ca837632":"code","5e6016ae":"code","71c6a349":"code","2494a39f":"code","d8c448cf":"code","c9ebd661":"code","fb4716c8":"code","b70ec75c":"code","2101434d":"code","a2cd7d4d":"code","553818ec":"code","4e4df23b":"code","4f8f98a2":"code","08900fc8":"code","e80402c4":"code","5d5737d3":"code","0daf068b":"code","8b642005":"code","fa930dd7":"code","dbfad9eb":"code","35c84e51":"code","fe4614fd":"code","c5182fb2":"code","19c24c89":"code","6cc39e4f":"code","2a26c5f0":"code","e2146ca9":"code","f14b458b":"code","02a6d0a4":"code","bfb8a601":"code","3f7130c5":"code","95c39019":"code","7b111a59":"code","3c0555a8":"code","ae6098ba":"code","a8bf0531":"code","d852a671":"code","100d93bc":"code","0bbd1f3f":"code","22d7712a":"code","be28c7e1":"code","e35e1881":"code","9f20ed3f":"code","8e45485d":"code","52347ca3":"code","b6903196":"code","9e7b14d1":"code","5aea5c7f":"code","eef82ccb":"code","e4dd653f":"code","27c6a22e":"code","49bad718":"code","19d6bfbc":"code","0856fac0":"code","e205e209":"code","53f90760":"code","596fd5f5":"code","5cedeff7":"code","38b52b73":"code","f4fd2890":"code","b40b20c9":"code","31981329":"code","3ee7b905":"code","e62ca34f":"code","6485ae00":"code","1f1cceb0":"code","961b2eeb":"code","add0af8d":"code","adf65144":"code","031fe28e":"code","8c7d66b1":"code","615dc14b":"code","3288ac6a":"code","690333f3":"code","5bd3cd4b":"code","d90c8370":"code","8fb29ce3":"code","173e9d15":"code","8690aa56":"code","cbc9f2af":"code","ada730f5":"code","93ddf75c":"code","17aee337":"code","4930dd86":"code","764915c6":"code","5ef4f90d":"code","fb8146bf":"code","bd0db47f":"code","10de7cf1":"code","1bcdb3e5":"code","e4a0ea0a":"code","ba76d72c":"code","fcc4fc56":"code","b2796f4f":"code","51594b77":"code","89970dd7":"code","3cda1c5e":"code","0c8213a0":"code","726694bf":"code","84d43017":"code","8e79a412":"code","dafbde6c":"code","7102affe":"code","ee458f8f":"code","d6b05a9e":"code","e9bc58e6":"code","f70e4de5":"code","7b90090e":"code","810a7f6c":"code","0eeb27c5":"code","795090b3":"code","2704558b":"code","6f7ea818":"code","9f026a97":"code","4ab18b7f":"code","4335f5a1":"code","59bb2993":"code","d901327f":"code","8879921b":"code","33068772":"code","78797b56":"markdown","8c35a358":"markdown","fb19fb1f":"markdown","346eb6f3":"markdown","a659efd4":"markdown","2c443b04":"markdown","a2c6044f":"markdown","b28af2f2":"markdown","e9fde230":"markdown","7b44b3ed":"markdown","40dda628":"markdown","da81cdef":"markdown","5e84f907":"markdown","d5f54e5a":"markdown","d658c5bd":"markdown","b158104a":"markdown","bc661c55":"markdown","7399fdff":"markdown","8daaba6d":"markdown","abcfcf62":"markdown","23276b6f":"markdown","57371fb2":"markdown","c43461e5":"markdown","d8ebdbe2":"markdown","f9bb3d1e":"markdown","db8184a3":"markdown","15d99368":"markdown","ca0fa7b6":"markdown","56e6e3d7":"markdown","6db6b2a1":"markdown","3dce51e0":"markdown","fdf02f6f":"markdown","b69005c2":"markdown","96144175":"markdown","d45ac5ae":"markdown","01201759":"markdown","a88c9fcd":"markdown","8d334e1e":"markdown","9899e07a":"markdown","c3a8e4e2":"markdown","9889e8a0":"markdown","d1048069":"markdown","af41ccd9":"markdown","0c01ef11":"markdown","be519bdb":"markdown","c8eb8921":"markdown","4277263f":"markdown","dae0f0da":"markdown","1a5391c5":"markdown","4dc59bca":"markdown"},"source":{"453f7eb1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\nimport os\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\"):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n# Any results you write to the current directory are saved as output.","5f808fa2":"#data = pd.read_csv('\/kaggle\/input\/pokemon.csv')\n#data.head()","0ec7dda2":"data = pd.read_csv('..\/input\/pokemon.csv')\ndata.head()","762cd8d6":"data.info()\n#dataya genel bir bak\u0131\u015f","eecf54bc":"data.corr()\n#datadaki kolerasyon tablosu","7c9731e1":"#annot=true ---> grafikteki yazan say\u0131lar\u0131n g\u00f6z\u00fckmesi i\u00e7in\n#heatmap \u015fekilde g\u00f6stermemiz i\u00e7in. sns de \u00e7a\u011f\u0131rd\u0131\u011f\u0131m\u0131z seaborn k\u00fct\u00fcphanesi\n#linewidths 0,5 ise linelar aras\u0131 kal\u0131nl\u0131k incelik\n#fmt = '.1f' ise \u015fekilde 0 dan sonra yazd\u0131raca\u011f\u0131 1 de\u011fer olsun demek.\n#subplot 18,18 yazarsak fig\u00fcr\u00fcm\u00fcz\u00fcn de\u011ferini b\u00fcy\u00fctmek istememiz.\n#correlation map\nf,ax = plt.subplots(figsize=(18, 18))\nsns.heatmap(data.corr(), annot=True, linewidths=.5, fmt= '.1f',ax=ax)\nplt.show()","7f8f7bab":"data.head(10)\n#datadaki ilk 10 veriyi g\u00f6sterir","ca837632":"data.columns\n#datadaki feature columns de\u011ferlerini g\u00f6sterir","5e6016ae":"#En kolay ve basic plotlar line, scatter ve histogram plotlar\u0131d\u0131r.\n\n#e\u011fer x (ekseni) axis'imiz zaman ise line plot kullanmam\u0131z iyidir\n\n#e\u011fer iki feature aras\u0131nda coleration var m\u0131 yok mu ya bak\u0131yorsak scatter plot kullanmak iyidir.\n\n#e\u011fer bir data distribution(yani bir feature\u0131n s\u0131kl\u0131\u011f\u0131, veri tekrar\u0131 pokemonlar da hp 80 80 iki tane olmas\u0131 gibi) varsa histogram kullanmam\u0131z iyi olur**","71c6a349":"#A\u00c7IKLAMASI:\n#x ekseni pokemonlar y ekseni ise speed ve defanslar\u0131\n#%% kind k\u0131sm\u0131 plot \u00e7e\u015fidi i\u00e7in. alpha saydaml\u0131k(0 ile 1 aras\u0131 oluyo). grid arka plan kareler. linestyle: \u00e7ubuklar iki nokta \n#\u015feklinde olsun. linewidth=1 yani line plotunun kal\u0131nl\u0131\u011f\u0131.\n#plt.legend(loc='upper right')  bu kod ise histogram\u0131 olusturuyor\n\n# Line Plot\n# color = color, label = label, linewidth = width of line, alpha = opacity, grid = grid, linestyle = sytle of line\ndata.Speed.plot(kind = 'line', color = 'g',label = 'Speed',linewidth=1,alpha = 0.5,grid = True,linestyle = ':')\ndata.Defense.plot(color = 'r',label = 'Defense',linewidth=1, alpha = 0.5,grid = True,linestyle = '-.')\nplt.legend(loc='upper right')     # legend = puts label into plot\nplt.xlabel('x axis')              # label = name of label\nplt.ylabel('y axis')\nplt.title('Line Plot')            # title = title of plot\nplt.show()","2494a39f":"#Scatter Plot\n#Amac\u0131m\u0131z iki tane feature yada variable aras\u0131ndaki correlition \u0131 bulmak\n# Bu grafikten anlayaca\u011f\u0131m\u0131z \u015fey;\n#yo\u011funlu\u011fun oldu\u011fu yere bakarsak tam k\u00f6\u015feden do\u011frusal bir line \u00e7izebiliriz ve \n#genelde atak art\u0131yorsa defans\u0131nda artt\u0131\u011f\u0131n\u0131 yorumlayabiliriz.\n\n##t\u00fcm bu kodu ayn\u0131 \u015fekilde \u015f\u00f6yle tek de yazabilirdik. Ama title ba\u015fl\u0131klar\u0131 olmazd\u0131 detay olmazd\u0131.\n##(plt.scatter(data.Attack,data.Defense,color= 'red',alpha=0.5) #\n# Scatter Plot \n# x = attack, y = defense\ndata.plot(kind='scatter', x='Attack', y='Defense',alpha = 0.5,color = 'red')\nplt.xlabel('Attack')              # label = name of label\nplt.ylabel('Defence')\nplt.title('Attack Defense Scatter Plot')            # title = title of plot","d8c448cf":"# ATTACK - ATTACK SPEED SCATTER PLOT (MY F\u0130RST PLOT)\n#Scatter Plot\n#Amac\u0131m\u0131z iki tane feature yada variable aras\u0131ndaki correlition \u0131 bulmak\n#x=atack y=defense\ndata.plot(kind='scatter',x = 'Attack',y = 'Sp. Atk',alpha = 0.5, color= 'red')\nplt.xlabel('Attack')\nplt.ylabel('Sp. Atk')\nplt.title('Attack - Sp. Atk Scatter Plot')\nplt.show()\n# Bu grafikten anlayaca\u011f\u0131m\u0131z \u015fey;\n#yo\u011funlu\u011fun oldu\u011fu yere bakarsak tam k\u00f6\u015feden do\u011frusal bir line \u00e7izebiliriz ve \n#genelde atak art\u0131yorsa defans\u0131nda artt\u0131\u011f\u0131n\u0131 yorumlayabiliriz.\n\n##t\u00fcm bu kodu ayn\u0131 \u015fekilde \u015f\u00f6yle tek de yazabilirdik. Ama title ba\u015fl\u0131klar\u0131 olmazd\u0131 detay olmazd\u0131.\n##(plt.scatter(data.Attack,data.Defense,color= 'red',alpha=0.5) #","c9ebd661":"# bins = number of bar in figure\n#bins = Barlar\u0131n say\u0131s\u0131n\u0131 veriyor yani 50 tane bar olsun. #figsize ise boyutu k\u00fc\u00e7\u00fclt\u00fcp b\u00fcy\u00fct\u00fcyor.\n#A\u00c7IKLAMA: \n#X ekseni diyebilece\u011fimiz k\u0131s\u0131m pokemonlar\u0131n h\u0131z de\u011ferleri\n# Y ekseni diyece\u011fimiz k\u0131s\u0131m ise \u00f6rne\u011fin; 50 h\u0131z\u0131na sahip pokemonlardan ka\u00e7 tane var ? \n# Y ekseni de bize bunun bilgisini sa\u011fl\u0131yor.\n# Histogram\n# bins = number of bar in figure\ndata.Speed.plot(kind = 'hist',bins = 50,figsize = (12,12))\nplt.show()","fb4716c8":"# data.Speed.plot(kind = 'hist', bins = 50, figsize = (12,12))\n# Ortaya \u00e7\u0131kard\u0131\u011f\u0131m\u0131z plot'u yok etmek istersek\n# plt.clf() komutunu kullanabiliriz\n# plt.show() komutu ise notebookta \u00e7al\u0131\u015ft\u0131rd\u0131\u011f\u0131m\u0131z \u00e7\u0131kan siyah konsolu g\u00f6stermemeye yar\u0131yor.\n\n# clf() = cleans it up again you can start a fresh\ndata.Speed.plot(kind = 'hist',bins = 50)\nplt.clf()\n# We cannot see plot due to clf()","b70ec75c":"# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(10)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","2101434d":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\ndata3.index = range(100,900,1)\ndata3.head()","a2cd7d4d":"#Dictionaryler Listlerden Daha H\u0131zl\u0131\n# Deep Learning e\u011fitiminde olduk\u00e7a i\u015fimize yarayacak\n#create dictionary and look its keys and values\ndictionary = {'spain' : 'madrid','usa' : 'vegas'}\nprint(dictionary.keys())\nprint(dictionary.values())","553818ec":"# Keys have to be immutable objects like string, boolean, float, integer or tubles\n# List is not immutable ( Listeler De\u011fi\u015febilir)\n# Keys are unique\ndictionary['spain'] = \"barcelona\"    # update existing entry\nprint(dictionary)\ndictionary['france'] = \"paris\"       # Add new entry\nprint(dictionary)\ndel dictionary['spain']              # remove entry with key 'spain'\nprint(dictionary)\nprint('france' in dictionary)        # check include or not\ndictionary.clear()                   # remove all entries in dict\nprint(dictionary)\n","4e4df23b":"# i\u00e7i bo\u015f olan dictionary nin haf\u0131zadan yer kaplamas\u0131n istersek delete deriz ve yok olur\n# In order to run all code you need to take comment this line\n#del dictionary         # delete entire dictionary     \nprint(dictionary)       # it gives error because dictionary is deleted\n","4f8f98a2":"data = pd.read_csv('..\/input\/pokemon.csv')\n","08900fc8":"series = data['Defense']        # data['Defense'] = series\nprint(type(series))\ndata_frame = data[['Defense']]  # data[['Defense']] = data frame\nprint(type(data_frame))\n","e80402c4":"#Pandasa devam etmeden \u00f6nce;\n#logic = mant\u0131k \n#control flow = ak\u0131\u015f\n#filtering = filtre \n# print(3!=2) ---> False \u00e7evirecektir. ! i\u015fareti 'not' yani olumsuzluk anlam\u0131 kat\u0131yor.\n","5d5737d3":"# Comparison operator\nprint(3 > 2)\nprint(3!=2)\n# Boolean operators\nprint(True and False)\nprint(True or False)","0daf068b":"# 1 - Filtering Pandas data frame\nx = data['Defense'] > 200 #Normalde buras\u0131 bize boolean upuzun bir seri \u00e7\u0131kart\u0131r\n\ndata[x]       #AMA B\u0130Z BURDA BU \u015eEK\u0130LDE X E E\u015e\u0130TLEY\u0130P\n              # X \u0130 \u0130\u00c7\u0130NE YAZARSAK FALSE DURUMLARI <200 LER\u0130 YAN\u0130 YOK EDER. VE TRUELAR YAZAR.\n            # KEND\u0130 \u00c7IKARIMIM OLARAK D\u0130REK BUNU \u015e\u00d6YLE DE YAZAB\u0130L\u0130RD\u0130K\n            #data[data['Defense'] > 200] D\u0130REK AYNI SONUCU CALISTIRIR","8b642005":"# 2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 2oo and higher attack value than 100\ndata[np.logical_and(data['Defense']>200, data['Attack']>100 )]","fa930dd7":"#KEND\u0130 \u00c7ALI\u015eMAM\nb = data['Type 2'] == 'Rock'\ndata[b]    #Bu \u015fekilde type 2 Rock olan T\u00fcm pokemonlar\u0131 g\u00f6rebiliriz. E\u011fer tek = yaparsak hepsini\n             #de\u011fi\u015ftirmi\u015f oluyoruz dikkat :)","dbfad9eb":"#KEND\u0130 \u00c7ALI\u015eMAM\nf = data['Legendary'] == True\ndata[f]    #e\u011fer len() fonksiyonunu kullan\u0131rsak ka\u00e7 tane efsanevi pokemon oldu\u011funu g\u00f6rebiliriz.","35c84e51":"# This is also same with previous code line. Therefore we can also use '&' for filtering.\n# 2 - Filtering pandas with logical_and\n# There are only 2 pokemons who have higher defence value than 2oo and higher attack value than 100\n# BURADA VE BA\u011eLACI \u0130LE ARAMA YAPIYORUZ. (TRUE AND TRUE = TRUE DEMEKT\u0130R)\n# >200 VE >100 KO\u015eULLARININ \u0130K\u0130S\u0130N\u0130NDE SA\u011eLANMASINI \u0130STED\u0130\u011e\u0130M\u0130Z \u0130\u00c7\u0130N LOG\u0130CAL KOMUTUNU KULLANIYORUZ\n# NP NUMPY L\u0130B'\u0130N KOMUTU OLDU\u011eU \u0130\u00c7\u0130N\n# BU F\u0130LTRELED\u0130\u011e\u0130M\u0130Z KO\u015eULU data[] \u0130\u00c7\u0130NDE YAZDI\u011eIMIZ \u0130\u00c7\u0130N D\u0130REK B\u0130ZE EXCEL TABLOSU G\u0130B\u0130 \u00c7IKTI VER\u0130YOR\n# AND KOMUTU YER\u0130NE LOG\u0130CAL_OR DA YAZAB\u0130L\u0130RD\u0130K AMA TAB\u0130 VEYA SONUCUNU GET\u0130R\u0130RD\u0130\ndata[np.logical_and(data['Defense']>200, data['Attack']>100 )]\n\n# YA DA T\u00dcM BUNU DAHA KISA YAZMAMIZ DA M\u00dcMK\u00dcN\n\n# data[(data['Defense']>200 & data['Attack']>100 )]       #   & ve ba\u011flac\u0131 sayesinde","fe4614fd":"# YA DA T\u00dcM BUNU DAHA KISA YAZMAMIZ DA M\u00dcMK\u00dcN        # & AND VE \u0130\u015eARET\u0130 SAYES\u0130NDE\n#PARANTEZLERE D\u0130KKAT KO\u015eULLARI AYRI AYRI PARANTEZLEMEK GEREK\u0130YOR VE YAZMAYA BA\u015eLARKEN BA\u015eTA BO\u015eLUK OLMAMALI\n \ndata[(data['Defense']>200) & (data['Attack']>100)]","c5182fb2":"#i e\u015fit de\u011fil 5 oluncaya kadar print yapt\u0131r ve bunu 1 artt\u0131r.\n# En son i yi 5 != 5 bize false d\u00f6nd\u00fcr\u00fcr ve while d\u00f6ng\u00fcs\u00fcn\u00fcn d\u0131\u015f\u0131na \u00e7\u0131kar.sonuncu printe ge\u00e7er.\n# Stay in loop if condition( i is not equal 5) is true\ni = 0\nwhile i != 5 :\n    print('i is: ',i)\n    i +=1\n\n    print(i,' is equal to 5')","19c24c89":"#FOR D\u00d6NG\u00dcS\u00dcN\u00dcN L\u0130ST, D\u0130CT\u0130ONARY, PANDAS  TA NASIL KULLANILDI\u011eINA BAKALIM\n# Stay in loop if condition( i is not equal 5) is true\nlis = [1,2,3,4,5]\nfor i in lis:\n    print('i is: ',i)\nprint('')\n\n# Enumerate index and value of list\n## Enumerate(Listenin i\u00e7indeki hem indexleri ve hem value lar\u0131 i\u00e7in kullan\u0131lan func) index and value of list\n# index : value = 0:1, 1:2, 2:3, 3:4, 4:5\nfor index, value in enumerate(lis):\n    print(index,\" : \",value)\nprint('')   \n\n# For dictionaries\n# We can use for loop to achive key and value of dictionary. We learnt key and value at dictionary part.\ndictionary = {'spain':'madrid','france':'paris'}\nfor key,value in dictionary.items():\n    print(key,\" : \",value)\nprint('')\n\n# For pandas we can achieve index and value\nfor index,value in data[['Attack']][0:1].iterrows():\n    print(index,\" : \",value)\n\n","6cc39e4f":"#docstring fonksiyonun alt\u0131nda ne i\u015fe yarad\u0131\u011f\u0131n\u0131 tan\u0131mlad\u0131\u011f\u0131m\u0131z comment\n# tuple = (1,2,3,4) gibi\n# tuple \u0131n g\u00fczel yan\u0131 \u015fu a,b,c gibi \u00fc\u00e7 farkl\u0131 de\u011fere e\u015fitleyebiliyoruz.\n# a = 1 b= 2 c=3 diyebiliyoruz.\n#tuple da ileride kullanmak istemedigmiz de\u011ferler olucak onun i\u00e7in tuple gerekecek\n# ileride a,b = yap() gibi bir fonksiyon i\u00e7in\n# b de\u011ferini kullanmak istemezsek : a,_ = yap()\n\n# example of what we learn above\ndef tuple_ex():\n    \"\"\" return defined t tuple\"\"\"\n    t = (1,2,3)\n    return t\na,b,c = tuple_ex()\nprint(a,b,c)","2a26c5f0":"# guess prints what\nx = 2                   #BU SATIRDAK\u0130 x global scopedur\ndef f():\n    x = 3               #Bu sat\u0131rdaki x local scopedur. E\u011fer func i\u00e7in de xlocal func yoksa x global al\u0131r.\n    return x\nprint(x)      # x = 2 global scope         #global scope'\u0131 al\u0131r\nprint(f())    # x = 3 local scope","e2146ca9":"# What if there is no local scope( E\u011fer local scope umuz yoksa...)\nx = 5\ndef f():\n    y = 2*x        # there is no local scope x\n    return y\nprint(f())         # it uses global scope x  \n# First local scope searched, then global scope searched, if two of them cannot be found lastly built in scope searched.\n#E\u011fer hem global hem local scope lar yoksa built in scopelar\u0131 varm\u0131 yok mu diye bak\u0131l\u0131yor.","f14b458b":"# How can we learn what is built in scope\nimport builtins\ndir(builtins)","02a6d0a4":"#nested function\n#\u0130\u00e7 \u0130\u00e7e ge\u00e7mi\u015f fonksiyonlar\n#square of = kare almak\n#nested function\ndef square():\n    \"\"\" return square of value \"\"\"\n    def add():\n        \"\"\" add two local variable \"\"\"\n        x = 2\n        y = 3\n        z = x + y\n        return z\n    return add()**2\nprint(square())    ","bfb8a601":"# default arguments\ndef f(a, b = 1, c = 2):\n    y = a + b + c\n    return y\nprint(f(5))\n# what if we want to change default arguments\nprint(f(5,4,3))","3f7130c5":"# flexible arguments *args\n#Fonksiyonlar\u0131n i\u00e7ine tek tek 1-2-3 gibi de\u011ferler yollamakk yerine tekte f(1,2,3,4) yollamam\u0131za yard\u0131mc\u0131\n#oluyor *argslar\n# flexible arguments *args\ndef f(*args):\n    for i in args:\n        print(i)\nf(1)\nprint(\"\")\nf(1,2,3,4)\n# flexible arguments **kwargs that is dictionary\ndef f(**kwargs):\n    \"\"\" print key and value of dictionary\"\"\"\n    for key, value in kwargs.items():               # If you do not understand this part turn for loop part and look at dictionary in for loop\n        print(key, \" \", value)\nf(country = 'spain', capital = 'madrid', population = 123456)","95c39019":"# lambda function\nsquare = lambda x: x**2     # where x is name of argument\nprint(square(4))\ntot = lambda x,y,z: x+y+z   # where x,y,z are names of arguments\nprint(tot(1,2,3))","7b111a59":"#ANONYMOUS FUNCT\u0130ON\n#Like lambda function but it can take more than one arguments.\n#map fonksiyonu number list i\u00e7indeki de\u011ferlerini lambda func \u0131n i\u00e7ine s\u0131rayla uyguluyor.!!\n# ve bunu y i\u00e7inde tutuyor\nnumber_list = [1,2,3]\ny = map(lambda x:x**2,number_list)\nprint(list(y))","3c0555a8":"#list ,string, ve dictionaries bir iterable object\n#iterable (tekrarlanabilir, yinelemeler anlam\u0131 ta\u015f\u0131yan bir kelime )\n# for d\u00f6ng\u00fcs\u00fcyle i\u00e7ine girdiklerimiz iterable objelerimizdir \n\n\n# iteration example\nname = \"ronaldo\"      #iter(name) name'i iterable objeye \u00e7eviriyoruz\nit = iter(name) \nprint(next(it))    # print next iteration = yapt\u0131\u011f\u0131m\u0131z zaman bana r \u00e7\u0131kt\u0131s\u0131n\u0131 veriyor\nprint(*it)         # print remaining iteration# iteration example = yapt\u0131\u011f\u0131m\u0131z zamanda kalan harfleri \n                    #bo\u015fluklu bir \u015fekilde yazd\u0131r\u0131yor. Bu konuda \u00e7ok fazla detaya gerek yok. for while yeterli\n\n","ae6098ba":"# zip example\nlist1 = [1,2,3,4]   #bu listeyi index gibi d\u00fc\u015f\u00fcnelim\nlist2 = [5,6,7,8]    # bu listeyle de indexleri birle\u015ftirmek isteyelim. \u00f6rne\u011fin 1.index 5 2.index 6 gibi\nz = zip(list1,list2)\nprint(z) #burada obje yaratm\u0131\u015f oluyoruz.Ve bu objeyi listelemek istiyoruz list() \u015feklinde\nz_list = list(z)\nprint(z_list)","a8bf0531":"#Zip ile birle\u015ftirdiklerimizi unzip yapmak istersek\nun_zip = zip(*z_list)   \nun_list1,un_list2 = list(un_zip) # unzip returns tuple  #unzip yapt\u0131\u011f\u0131m \u015fey yine bir obje old i\u00e7in list()\nprint(un_list1)      #unzip yaparken python tuple a \u00e7eviriyor\nprint(un_list2)\nprint(type(un_list2)) #o y\u00fczden bunu kullan\u0131yoruz tekrar","d852a671":"# Example of list comprehension\n#num1 burda iterable objemizi biz bunu for d\u00f6ng\u00fcs\u00fcyle yani iterator ile iteration yap\u0131yoruz.!!!\n#pandasta da \u00e7ok s\u0131k kullanaca\u011f\u0131z\n\nnum1 = [1,2,3]\nnum2 = [i + 1 for i in num1 ] #bu bizim list comprehension \u0131m\u0131z oluyor\nprint(num2)\nnum1 = [1,2,3]\nnum2 = [i + 1 for i in num1 ]\nprint(num2)","100d93bc":"# \u00c7ok kullan\u0131\u015fl\u0131 ve \u00e7ok \u00f6nemli bir nokta bununla ilgili 3-4 al\u0131\u015ft\u0131rma yap\u0131lmal\u0131\n# Conditionals on iterable\nnum1 = [5,10,15]\nnum2 = [i**2 if i == 10 else i-5 if i < 7 else i+5 for i in num1] #yazmaya sonundan ba\u015fl\u0131yoruz for i in..\nprint(num2)                   #Tam bu noktan\u0131n \u00fcst\u00fc else if asl\u0131nda elif \u015feklinde kullan\u0131l\u0131yor\n                           #E\u011fer say\u0131n 10 a e\u015fitse kare al, !(i<7 ise i-5 yap)! hi\u00e7biri de\u011filse i+5 yap","0bbd1f3f":"# lets return pokemon csv and make one more list comprehension example\n# lets classify pokemons whether they have high or low speed. Our threshold is average speed.\n# Bu \u00e7ok \u00f6nemli bir \u00e7al\u0131\u015fma. Pokemon veri setimizdeki ortalama h\u0131z\u0131 bulup for d\u00f6ng\u00fcs\u00fc ile\n#e\u011fer bu pokemonlar\u0131n h\u0131z\u0131 ortalama h\u0131zdan b\u00fcy\u00fckse high yazd\u0131r e\u011fer k\u00fc\u00e7\u00fckse low yazd\u0131r\u0131yoruz ve yeni bir\n# speed_level columns eklemi\u015f oluyoruz\n#threshold burda ortalamam\u0131z oluyor\nthreshold = sum(data.Speed)\/len(data.Speed)\ndata[\"speed_level\"] = [\"high\" if i > threshold else \"low\" for i in data.Speed]\ndata.loc[:10,[\"speed_level\",\"Speed\"]] # we will learn loc more detailed later","22d7712a":"#Diagnose = te\u015fhis etmek\n#datada baz\u0131 unclean olan \u015feyleri clean etmemiz laz\u0131m\n#b\u00fcy\u00fck k\u00fc\u00e7\u00fck d\u00fczensiz harfler (upper lower case problemleri ve buna unclean data denir)\n# Space between in words \n# \u00d6rne\u011fin data.Type 1 yapt\u0131\u011f\u0131m\u0131z zaman hata al\u0131yoruz \u00e7\u00fcnk\u00fc bu isim aras\u0131nda bo\u015fluk var !\n#O y\u00fczden \u015f\u00f6yle \u00e7a\u011f\u0131rabiliriz\n# data['Type 1'] \u015feklinde yapabiliriz!\n#missing data ise \u00f6rne\u011fin baz\u0131 de\u011ferlerin olmamas\u0131 - \u015feklinde ya da nan \u015feklinde\n#farkl\u0131 dillerden kaynakl\u0131 da datalar\u0131 anlamam\u0131z ve \u00e7\u00f6z\u00fcm bulmam\u0131z laz\u0131m different language problem\n#We will use head, tail, columns, shape and info methods to diagnose data\n#Yine ayn\u0131 \u015fekilde ba\u015flayaca\u011f\u0131z\n#data.info() komutu ile un null olan ve olmayan verileri anlayabiliriz\n","be28c7e1":"data = pd.read_csv('..\/input\/pokemon.csv')\ndata.head()  # head shows first 5 rows","e35e1881":"# tail shows last 5 rows\ndata.tail()","9f20ed3f":"# columns gives column names of features\ndata.columns","8e45485d":"# shape gives number of rows and columns in a tuble\ndata.shape","52347ca3":"# info gives data type like dataframe, number of sample or row, number of feature or column, feature types and memory usage\ndata.info()","b6903196":"# 1,4,5,6,8,9,11,12,13,14,15,16,17\n#outliers : ayr\u0131k, ayk\u0131r\u0131 anlam\u0131na gelir. Bir istatisti\u011fe g\u00f6re bir datadaki di\u011fer datadalardan \u00e7ok ayk\u0131r\u0131\n# \u00e7ok y\u00fcksek ya da \u00e7ok az olan dataya outlier diyoruz.\n#peki outlier\u0131n s\u0131n\u0131r\u0131 nedir?\n###Lets say value at 75% is Q3 and value at 25% is Q1.\n#Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n#form\u00fcl \u015feklinde bu buldu\u011fumuz alt ve \u00fcst outlierlar\u0131m\u0131zd\u0131r.\n#median ortadaki say\u0131y\u0131 bulur. 11  Ortalama de\u011fil!!! (quantile %50 de median demek)\n#mean ortalama al\u0131r.\n#lower quantile ise median ile en k\u00fc\u00e7\u00fck say\u0131n\u0131n ortas\u0131 1 ile 11 aras\u0131ndaki medyan oluyor yni 6\n#lower quantile = Q1= 25% \u015feklinde de ifade edilebiliyor\n#upper quantile ise median ile en b\u00fcy\u00fck say\u0131n\u0131n ortas\u0131  11 ile 17 aras\u0131 yani 14\n#upper quantile = Q3 = 75% olarak da ifade edilir\n#outlier haricindeki her\u015feyi data.describe() \u015feklinde hesaplatabiliriz. Ve bu bize sadece numericleri hesaplar\n#true false i\u00e7erenleri yoksayar\n#%50 ile g\u00f6sterilen tam ortas\u0131 oluyor yani median\u0131. ORTALAMASI DE\u011e\u0130L D\u0130KKAT.","9e7b14d1":"#Neden median de\u011ferlerine ihtiyac duyar\u0131z mean de\u011feri varken ?\n# 1, 1 , 1 ,1 ,1000 \u015feklinde maa\u015flar\u0131 olan \u00e7al\u0131\u015fanlar d\u00fc\u015f\u00fcnelim. Zam yap\u0131lacak olursa e\u011fer \n#Burada ortalamas\u0131 200 gibi bir de\u011fer olur yakla\u015f\u0131k olarak ve bu biraz yan\u0131lt\u0131c\u0131 \u00e7\u00fcnk\u00fc \u00e7ok y\u00fcksektir\n#bir de\u011fer olabilir\n#fakat e\u011fer biz burda median de\u011ferine bakarsak 1 gibi bir de\u011fer yakalar\u0131z\n# \u00d6yleyse \u015firketin %50 si 1 den az maa\u015f al\u0131yor deriz. Ve zam yapmaya karar verebiliriz.","5aea5c7f":"#value_counts() = Frequency count etmeye yarar. Yani\n#Type 1 i\u00e7inde mesela ka\u00e7 tane su pokemonu var gibi bize bilgiler \u00e7\u0131kart\u0131yor.\n#\u00c7ok kullan\u0131lan bir method value_counts()\n#\n#For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon\n# For example lets look frequency of pokemom types\nprint(data['Type 1'].value_counts(dropna =False))  # if there are nan values that also be counted\n# As it can be seen below there are 112 water pokemon or 70 grass pokemon","eef82ccb":"1,2,3,4,200","e4dd653f":"# For example max HP is 255 or min defense is 5\ndata.describe() #ignore null entries","27c6a22e":"#g\u00f6rsel bir \u015fekilde data inceleme ve analiz etme methodunu kullaca\u011f\u0131z \n#box plotu g\u00f6rece\u011fiz\n#ayk\u0131r\u0131 de\u011ferler, min max, 25 50 75 quantiles lar\u0131 buluruz\n#Pokemonlar\u0131n ata\u011f\u0131n\u0131 legendary olup olmamas\u0131na g\u00f6re box plot ettiriyoruz\n#gri daire ile i\u015faretliler outlierlar\u0131m\u0131z\n#bu outlierlar atacktaki bu de\u011ferler biraz abart\u0131 gibi yani ne kadar do\u011fru de\u011ferler bunlar\u0131 sorgulat\u0131yor?\n#do\u011fru da olabilir \u00f6yleyse ba\u015fka bunun gibi de\u011ferler olursa bu data ne kadar de\u011fi\u015fr o zaman bunu d\u00fc\u015f\u00fcnmeliyiz?\n#bu dogrultuda bu outlier lara ne kadar dikkate almal\u0131y\u0131z gibi sorular sormal\u0131y\u0131z kendimize ?\n\n# For example: compare attack of pokemons that are legendary  or not\n# Black line at top is max\n# Blue line at top is 75%\n# Green line is median (50%)\n# Blue line at bottom is 25%\n# Black line at bottom is min\n# There are no outliers\ndata.boxplot(column='Attack',by = 'Legendary')","49bad718":"# Firstly I create new data from pokemons data to explain melt nore easily.\ndata_new = data.head()    # I only take 5 rows into new data\ndata_new","19d6bfbc":"#melt pandas k\u00fct\u00fcphanesi fonskiyonudur\n#melt yapmak, bu datadan belli ba\u015fl\u0131 yeni featurelar \u00e7\u0131kartarak datay\u0131 farkl\u0131 bir de\u011ferleri sabitt kalaca\n#\u015fekilde farkl\u0131 bir yap\u0131ya b\u00fcr\u00fcnd\u00fcrmek.\n#frame neyi melt yapmak istiyorsak\n#id_Vars = name ise benim bu datada neyin de\u011fi\u015fmemesini de\u011fi\u015fmeden kals\u0131n istiyorsam onu yaz\u0131yorum\n#melted data yine name kalacak\n#pokemon ismine g\u00f6re melt edece\u011fiz b\u00f6ylece\n#attack ve defense de\u011ferlerinden ortaya \u00e7\u0131kacak \n#ilk feature m\u0131z variable ikincisi ise value\n#balbasar\u0131n ata\u011f\u0131n\u0131 al benim ata\u011f\u0131m variable yani column bunun de\u011feri ney 49\n#balbasar\u0131n variablena attack value suna 49 yapm\u0131\u015f oldum\n#b\u00f6ylece melt yapm\u0131\u015f olduk o k\u0131sm\u0131\n#variable ve value columnlar\u0131 default olarak melt fonksiyonunun atad\u0131\u011f\u0131 de\u011ferler\n#istersek de\u011fi\u015ftirebiliriz\n#biz bunu neden yap\u0131yoruz?\n#seaborn k\u00fct\u00fcphanesinde g\u00f6rselle\u015ftirme yapmak i\u00e7in melt yapmam\u0131z gerekiyor\n#pandas ile seaborn aras\u0131nda bir k\u00f6pr\u00fc gibi d\u00fc\u015f\u00fcnebiliriz\n\n# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted\n# lets melt\n# id_vars = what we do not wish to melt\n# value_vars = what we want to melt\nmelted = pd.melt(frame=data_new,id_vars = 'Name', value_vars= ['Attack','Defense'])\nmelted","0856fac0":"##pivoting data ise melted datay\u0131 eski haline getirmek\n# Index is name\n# I want to make that columns are variable\n# Finally values in columns are value\nmelted.pivot(index = 'Name', columns = 'variable',values='value')","e205e209":"#pd.concat ile vertical yani yukardan asag\u0131ya axis=0 \u015feklinde\n#ignore_index = dedi\u011fimiz zaman onlar\u0131n kendi indexini bo\u015fverip yeni \u015fekilde s\u0131ralamas\u0131n\u0131 istiyoruz\n#\n# Firstly lets create 2 data frame\ndata1 = data.head()\ndata2= data.tail()\nconc_data_row = pd.concat([data1,data2],axis =0,ignore_index =True) # axis = 0 : adds dataframes in row\nconc_data_row","53f90760":"#Biz bunu horizontal yani yatay bir \u015fekilde birle\u015ftiredebiliriz\n#attack ve defense ilk 5 leri birle\u015ftirebiliyoruz\n#bir machine learning yaparken bu data formlar\u0131n\u0131 \u00e7ok iyi bilmemiz gerekli\ndata1 = data['Attack'].head()\ndata2= data['Defense'].head()\nconc_data_col = pd.concat([data1,data2],axis =1) # axis = 1 : adds dataframes in column\nconc_data_col","596fd5f5":"#5 tane standart data type var. obj=string ,boolean, integer, float ve categorical\n#categorical machine learning i\u00e7in \u00e7ok \u00f6nemli","5cedeff7":"data.dtypes","38b52b73":"#int64 olan speed i float verisine \u00e7evirebiliyoruz\n#string yani object olan columns de\u011ferlerini category ye \u00e7evirmi\u015f oluyoruz\n#\u00e7ok s\u0131k kullan\u0131lan metodlardan biri\n#a\u015fa\u011f\u0131daki kod blo\u011fundan sonra data.dtypes yazd\u0131\u011f\u0131m\u0131zda de\u011fi\u015fti\u011fini g\u00f6rece\u011fiz\n# lets convert object(str) to categorical and int to float.\ndata['Type 1'] = data['Type 1'].astype('category')\ndata['Speed'] = data['Speed'].astype('float')","f4fd2890":"# As you can see Type 1 is converted from object to categorical\n# And Speed ,s converted from int to float\ndata.dtypes","b40b20c9":"#missing data bir datada daha \u00f6nce tan\u0131mlanmam\u0131\u015f ve de\u011feri olmayan \u015feylerdir. NaN de\u011ferler\n# Charmender type 2 NaN\n#Burda iki soru sormam\u0131z gerek charmender\u0131n type 2 si yok mu yoksa tan\u0131mlanmam\u0131\u015f m\u0131 ?\n#\u015fuan i\u00e7in \u00f6nemli de\u011fil fakat ileride \u00f6nemli olabilecek bir durum\n#peki ne yapmal\u0131 ?\n#1)leave as is = onu \u00f6ylece b\u0131rakabiliriz. \u015euan oldugu gibi\n#2) ya da onu komple data setten \u00e7\u0131kartabiliriz drop them with dropna()\n#3) fill missing value with fillna() mesela bo\u015f yerler varsa biz onlar\u0131 bu \u015fekilde NaN olarak doldurabilriz\n#4) missing value say\u0131sal bir veri olsayd\u0131. di\u011fer de\u011ferlere bak\u0131p onu bulmaya \u00e7al\u0131sabilirdik istatikle\n#4) fill missing values with test statistics like mean\n#Assert statement: check that you can turn on or turn off when you are done with your testing of the program\n# burda s\u00f6ylemek istedi\u011fi bi i\u015flem yapacaks\u0131n\u0131z ve a\u00e7 kapa yapt\u0131ktan sonra g\u00f6receksiniz","31981329":"#386 tane bo\u015f ttype2 si bo\u015f olan pokemon var demek ki\n# Lets look at does pokemon data have nan value\n# As you can see there are 800 entries. However Type 2 has 414 non-null object so it has 386 null object.\ndata.info()","3ee7b905":"#burada dropna=false dedi\u011fimiz zaman NaN olanlar\u0131 da say ve g\u00f6ster diyoruz\n# Lets chech Type 2\ndata[\"Type 2\"].value_counts(dropna =False)\n# As you can see, there are 386 NAN value","e62ca34f":"#data1=data tan\u0131m\u0131nda normalde bu tarz de\u011fi\u015fiklikler yapmam\u0131z do\u011fru de\u011fil \u00e7\u00fcnk\u00fc\n#bu e\u015fitlikten sonra bir\u015fey de\u011fi\u015fti\u011fi zaman di\u011feri de de\u011fi\u015fir hale geliyor. Ama burda s\u0131k\u0131nt\u0131 olmam\u0131\u015f\n#burda type 2 si olmayan pokemonlar\u0131 .dropna ile listeden at\u0131yoruz. \n#inplace=True ise bu \u00e7\u0131kartt\u0131klar\u0131m\u0131zdan sonra bunu data1 e kaydet diyoruz\n# Lets drop nan values\ndata1=data   # also we will use data to fill missing value so I assign it to data1 variable\ndata1[\"Type 2\"].dropna(inplace = True)  # inplace = True means we do not assign it to new variable. Changes automatically assigned to data\n# So does it work ?","6485ae00":"#bu yapt\u0131klar\u0131m\u0131z i\u015fe yarad\u0131 m\u0131 kontrol etmek i\u00e7in bu \u015fekilde 1=1 ise\n#burada 1==1 i kontrol ediyoruz ve zaten do\u011fru oldu\u011fu i\u00e7in hi\u00e7 bir \u00e7\u0131kt\u0131 alm\u0131yoruz\n\n#  Lets check with assert statement\n# Assert statement:\nassert 1==1 # return nothing because it is true","1f1cceb0":"#Ama burada yanl\u0131\u015f oldu\u011fu i\u00e7in error al\u0131yoruz\n# In order to run all code, we need to make this line comment\n# assert 1==2 # return error because it is false","961b2eeb":"#burda da kendi kontrol\u00fcm\u00fcz\u00fc yap\u0131yoruz.\n#type 2 de notnull m\u0131 all yani hepsi diye soruyoruz hi\u00e7 bir cevap vermedi\u011fi i\u00e7in do\u011fru oluyor\n#type2 si NaN olanlar\u0131 listeden atm\u0131\u015f\u0131z\nassert  data['Type 2'].notnull().all() # returns nothing because we drop nan values","add0af8d":"#datam\u0131z\u0131n type2 sini empty ile dolduruyoruz\ndata[\"Type 2\"].fillna('empty',inplace = True)\n","adf65144":"#burda sonra tekrar kontrol ediyoruz. \nassert  data['Type 2'].notnull().all() # returns nothing because we do not have nan values","031fe28e":"# # With assert statement we can check a lot of thing. For example\n# assert data.columns[1] == 'Name'\n# assert data.Speed.dtypes == np.int","8c7d66b1":"# data frames from dictionary\ncountry = [\"Spain\",\"France\"]\npopulation = [\"11\",\"12\"]\nlist_label = [\"country\",\"population\"]\nlist_col = [country,population]\nzipped = list(zip(list_label,list_col))\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf","615dc14b":"# Add new columns\ndf[\"capital\"] = [\"madrid\",\"paris\"]\ndf","3288ac6a":"# Broadcasting\ndf[\"income\"] = 0 #Broadcasting entire column\ndf","690333f3":"# Plotting all data \ndata1 = data.loc[:,[\"Attack\",\"Defense\",\"Speed\"]]\ndata1.plot()\n# it is confusing","5bd3cd4b":"# subplots\ndata1.plot(subplots = True)\nplt.show()","d90c8370":"# scatter plot  \ndata1.plot(kind = \"scatter\",x=\"Attack\",y = \"Defense\")\nplt.show()","8fb29ce3":"#range y eksenimiz oluoyr\n#normed true dedigimiz de frekans\u0131n normalize edilmi\u015f halini yap\u0131yor\n#0 ile 1 aras\u0131nda normalize etmek oluyor false yaparsak de\u011fi\u015fiyor\n\n# hist plot  \ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True)","173e9d15":" #k\u00fcm\u00fclatifte toplana toplana gidiyor grafik\n#  histogram subplot with non cumulative and cumulative\n#k\u00fcm\u00fclatif plotlar\u0131 g\u00f6rece\u011fiz istatistikle ilgili\n# histogram subplot with non cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"Defense\",bins = 50,range= (0,250),normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","8690aa56":"data.describe()","cbc9f2af":"#ayn\u0131 str gibi bir obj\n#bu konuyu inceyebilmek i\u00e7in pokemon datas\u0131na \u00f6nce datetime eklemeliyiz. Biz normal bir \u015fekilde str olarak dateleri ekliyorz\ntime_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however we want it to be datetime object\ndatetime_object = pd.to_datetime(time_list) #Ama buradan sonra biz onu datetime obj \u00e7evirebiliyoruz\nprint(type(datetime_object))","ada730f5":"# close warning\nimport warnings\nwarnings.filterwarnings(\"ignore\") #burdaki uyar\u0131y\u0131 kapatmak i\u00e7in eklenmi\u015f bir b\u00f6l\u00fcm \u00e7ok da \u015fuan i\u00e7in \u00f6nemli de\u011fil\n# In order to practice lets take head of pokemon data and add it a time list\ndata2 = data.head()\n#\u00f6nce datelist i datetime a \u00e7eviriyoruz. Daha sonra yeni column olarak ekliyoruz\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","93ddf75c":"# Now we can select according to our date index\n#Art\u0131k bizim time series li bir datam\u0131z var\nprint(data2.loc[\"1993-03-16\"])\nprint(data2.loc[\"1992-03-10\":\"1993-03-16\"]) # bu \u015fekilde iki date aras\u0131nda \u00e7ekebiliyoruz","17aee337":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean() #A harfi burda y\u0131l\u0131 kastediyor y\u0131la g\u00f6re resampling yap ortalama al","4930dd86":"#Burda da aylara g\u00f6re resample yap\u0131yoruz\n# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan because data2 does not include all months","764915c6":"#interpole etmek aras\u0131n\u0131 doldurmak demek \n#yani do\u011frusal artan bir dizi de ki eksik eleman\u0131 di\u011ferlerine g\u00f6re doldurabiliriz bu \u015fekilde\n# In real life (data is real. Not created from us like data2) we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")","5ef4f90d":"#meanleri ayn\u0131 olacak \u015fekilde de interpolate yapabiliriz\n# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","fb8146bf":"#burada datan\u0131n s\u0131f\u0131rdan ba\u015flayan indexini \"#\" column de\u011ferine g\u00f6re de\u011fi\u015ftirebiliyoruz\n# read data\ndata = pd.read_csv('..\/input\/pokemon.csv')\ndata= data.set_index(\"#\")\ndata.head()","bd0db47f":"# indexing using square brackets\ndata[\"HP\"][1]","10de7cf1":"# using column attribute and row label\ndata.HP[1]","1bcdb3e5":"# using loc accessor\ndata.loc[1,[\"HP\"]]","e4a0ea0a":"# Selecting only some columns\ndata[[\"HP\",\"Attack\"]]","ba76d72c":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"HP\"]))     # series\nprint(type(data[[\"HP\"]]))   # data frames","fcc4fc56":"# Slicing and indexing series\ndata.loc[1:10,\"HP\":\"Defense\"]   # 10 and \"Defense\" are inclusive","b2796f4f":"# Reverse slicing \ndata.loc[10:1:-1,\"HP\":\"Defense\"] ","51594b77":"# From something to end\ndata.loc[1:10,\"Speed\":] ","89970dd7":"# Creating boolean series\nboolean = data.HP > 200\ndata[boolean]","3cda1c5e":"# Combining filters\nfirst_filter = data.HP > 150\nsecond_filter = data.Speed > 35\ndata[first_filter & second_filter]","0c8213a0":"# Filtering column based others\ndata.HP[data.Speed<15]","726694bf":"#datadaki bir column de\u011ferlerine istedi\u011fimiz \u015fekilde bir fonksiyon i\u015flemi uygulatabiliriz\n# Plain python functions\ndef div(n):\n    return n\/2\ndata.HP.apply(div)","84d43017":"#bu da daha h\u0131zl\u0131 hali\n# Or we can use lambda function\ndata.HP.apply(lambda n : n\/2)","8e79a412":"#Farkl\u0131 columnlardan yeni bir column de\u011feri olu\u015fturabiliriz\n# Defining column using other columns\ndata[\"total_power\"] = data.Attack + data.Defense\ndata.head()","dafbde6c":"#datam\u0131z\u0131n indexinin i\u015faretine veya index ad\u0131n\u0131 \u00f6\u011freniyoruz\n# our index name is this:\nprint(data.index.name)\n# lets change it\n#datam\u0131z\u0131n index ad\u0131n\u0131 de\u011fi\u015ftirebiliyoruz bu sayede\ndata.index.name = \"index_name\"\ndata.head()","7102affe":"\n# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just example\n#tamamen bize g\u00f6re mesela indeximizin 100 den ba\u015flamas\u0131n\u0131 da isteyebiliriz\ndata3.index = range(100,900,1)\ndata3.head()","ee458f8f":"#Datam\u0131za bir column da index olarak verebiliriz. Mesela \"#\" isimli column de\u011ferimizi index olarak yapm\u0131\u015ft\u0131k\n# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this\n# data= data.set_index(\"#\")\n# also you can use \n# data.index = data[\"#\"]","d6b05a9e":"# lets read data frame one more time to start from beginning\ndata = pd.read_csv('..\/input\/pokemon.csv')\ndata.head()\n# As you can see there is index. However we want to set one or more column to be index","e9bc58e6":"#ilk yazd\u0131\u011f\u0131m\u0131z bizim ilk indeximiz oluyor. yani outer\n#ikincisi ise inner indexi oluyor\n# Setting index : type 1 is outer type 2 is inner index\ndata1 = data.set_index([\"Type 1\",\"Type 2\"]) \ndata1.head(100)\n# data1.loc[\"Fire\",\"Flying\"] # howw to use indexes","f70e4de5":"#Bizim eski feature column olarak kulland\u0131\u011f\u0131m\u0131z isimlere art\u0131k bir value ile yapacca\u011f\u0131z\ndic = {\"treatment\":[\"A\",\"A\",\"B\",\"B\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"response\":[10,45,5,9],\"age\":[15,4,72,65]}\ndf = pd.DataFrame(dic)\ndf","7b90090e":"#yeni index imiz treatment olsun yani a ve b gibi\n#column lar\u0131m\u0131zda genderlar\u0131m\u0131z yani F  M  olsun diyoruz. ve bunlar\u0131n de\u011ferleri de response olsun\n\n# pivoting\ndf.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")","810a7f6c":"df1 = df.set_index([\"treatment\",\"gender\"])\ndf1\n# lets unstack it\n#yani birden fazla indexe sahip dataframeleri unstack yap\u0131yor. Yani indexlerinden birisinden kurtuluyor gibi","0eeb27c5":"# level determines indexes\n#0. indexi indexlikten c\u0131kart\u0131yor\ndf1.unstack(level=0)","795090b3":"df1.unstack(level=1)\n#bu seferde gender\u0131 c\u0131kart\u0131yor","2704558b":"# change inner and outer level index position\n#index yerlerini degistirebiliyor muyuzz df1 datas\u0131n\u0131n\ndf2 = df1.swaplevel(0,1)\ndf2","6f7ea818":"df","9f026a97":"#treatment sabit kals\u0131n geri kalan featurelar\u0131n yerine default olarak variable ve value ekler. \n#value_vars=[\"age\",\"response\"] bunu yazd\u0131g\u0131m\u0131z i\u00e7in default \u00f6zelli\u011fi \u00e7al\u0131\u015fmad\u0131\n# df.pivot(index=\"treatment\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"treatment\",value_vars=[\"age\",\"response\"])","4ab18b7f":"# We will use df\ndf","4335f5a1":"#Bir\u015feye g\u00f6re gruplamak. Gruplay\u0131p ona g\u00f6re istatiksel method uyguluyoruz\n# according to treatment take means of other features\ndf.groupby(\"treatment\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std,max or min","59bb2993":"# we can only choose one of the feature\ndf.groupby(\"treatment\").age.max() ","d901327f":"# Or we can choose multiple features\ndf.groupby(\"treatment\")[[\"age\",\"response\"]].min() ","8879921b":"df.info()\n# as you can see gender is object\n# However if we use groupby, we can convert it categorical data. \n# Because categorical data uses less memory, speed up operations like groupby\n#df[\"gender\"] = df[\"gender\"].astype(\"category\")\n#df[\"treatment\"] = df[\"treatment\"].astype(\"category\")\n#df.info()\n","33068772":"def s(x, y = 2):\n\n    c = 2\n\n    for i in range(y):\n\n        c = c + x\n\n    return c\ns(2)","78797b56":"<a id=\"34\"><\/a> <br>\n### SLICING DATA FRAME\n* Difference between selecting columns\n    * Series and data frames\n* Slicing and indexing series\n* Reverse slicing \n* From something to end","8c35a358":"<a id=\"36\"><\/a> <br>\n### TRANSFORMING DATA\n* Plain python functions\n* Lambda function: to apply arbitrary python function to every element\n* Defining column using other columns","fb19fb1f":"<a id=\"16\"><\/a> <br>\n# 3.CLEANING DATA","346eb6f3":"<a id=\"18\"><\/a> <br>\n### EXPLORATORY DATA ANALYSIS\nvalue_counts(): Frequency counts\n<br>outliers: the value that is considerably higher or lower from rest of the data\n* Lets say value at 75% is Q3 and value at 25% is Q1. \n* Outlier are smaller than Q1 - 1.5(Q3-Q1) and bigger than Q3 + 1.5(Q3-Q1). (Q3-Q1) = IQR\n<br>We will use describe() method. Describe method includes:\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry\n\n<br> What is quantile?\n\n* 1,4,5,6,8,9,11,12,13,14,15,16,17\n* The median is the number that is in **middle** of the sequence. In this case it would be 11.\n\n* The lower quartile is the median in between the smallest number and the median i.e. in between 1 and 11, which is 6.\n* The upper quartile, you find the median between the median and the largest number i.e. between 11 and 17, which will be 14 according to the question above.","a659efd4":"<a id=\"35\"><\/a> <br>\n### FILTERING DATA FRAMES\nCreating boolean series\nCombining filters\nFiltering column based others","2c443b04":"<a id=\"20\"><\/a> <br>\n### TIDY DATA\nWe tidy data with melt().\nDescribing melt is confusing. Therefore lets make example to understand it.\n","a2c6044f":"<a id=\"3\"><\/a> <br>\n### DICTIONARY\nWhy do we need dictionary?\n* It has 'key' and 'value'\n* Faster than lists\n<br>\nWhat is key and value. Example:\n* dictionary = {'spain' : 'madrid'}\n* Key is spain.\n* Values is madrid.\n<br>\n<br>**It's that easy.**\n<br>Lets practice some other properties like keys(), values(), update, add, check, remove key, remove all entries and remove dicrionary.","b28af2f2":"<a id=\"33\"><\/a> <br>\n### INDEXING DATA FRAMES\n* Indexing using square brackets\n* Using column attribute and row label\n* Using loc accessor\n* Selecting only some columns","e9fde230":"<a id=\"15\"><\/a> <br>\n### LIST COMPREHENS\u0130ON\n**One of the most important topic of this kernel**\n<br>We use list comprehension for data analysis often. \n<br> list comprehension: collapse for loops for building lists into a single line\n<br>Ex: num1 = [1,2,3] and we want to make it num2 = [2,3,4]. This can be done with for loop. However it is  unnecessarily long. We can make it one line code that is list comprehension.","7b44b3ed":"<a id=\"9\"><\/a> <br>\n### SCOPE\nWhat we need to know about scope:\n* global: defined main body in script\n* local: defined in a function\n* built in scope: names in predefined built in scope module such as print, len\n<br><br>Lets make some basic examples","40dda628":"<a id=\"22\"><\/a> <br>\n### CONCATENATING DATA\nWe can concatenate two dataframe (#Yani biz iki farkl\u0131 datay\u0131 birle\u015ftirebiliriz)","da81cdef":"<a id=\"40\"><\/a> <br>\n### STACKING and UNSTACKING DATAFRAME\n* deal with multi label indexes\n* level: position of unstacked index\n* swaplevel: change inner and outer level index position","5e84f907":"<a id=\"41\"><\/a> <br>\n### MELTING DATA FRAMES\n* Reverse of pivoting","d5f54e5a":"<a id=\"14\"><\/a> <br>\n### ITERATORS\n* iterable is an object that can return an iterator\n* iterable: an object with an associated iter() method\n<br> example: list, strings and dictionaries\n* iterator: produces next value with next() method","d658c5bd":"<a id=\"27\"><\/a> <br>\n### BUILDING DATA FRAMES FROM SCRATCH\n* We can build data frames from csv as we did earlier.\n* Also we can build dataframe from dictionaries\n    * zip() method: This function returns a list of tuples, where the i-th tuple contains the i-th element from each of the argument sequences or iterables.\n* Adding new column\n* Broadcasting: Create new column and assign a value to entire column","b158104a":"# Turkish Course Notes and New Comments Data Scientist Tutorial for Beginners\n\n# DATA SCIENTIST\n\n### *Bu Notebook e\u011fitmenin ders anlat\u0131m\u0131ndaki T\u00fcrk\u00e7e Ders Notlar\u0131 ve Yeni A\u00e7\u0131klamalar i\u00e7in olu\u015fturuldu*\nhttps:\/\/www.kaggle.com\/kanncaa1\n\n### *This notebook created for my own Turkish course notes and new comments .* \n\n### The original link : https:\/\/www.kaggle.com\/kanncaa1\/data-sciencetutorial-for-beginners\n \n### Neredeyse t\u00fcm kod bloklar\u0131 i\u00e7in derste ge\u00e7en gerekli a\u00e7\u0131klamalar\u0131, not olarak yazd\u0131m\n\n\n\n**In this tutorial, I only explain you what you need to be a data scientist neither more nor less.**\n\nData scientist need to have these skills:\n\n1. Basic Tools: Like python, R or SQL. You do not need to know everything. What you only need is to learn how to use **python**\n1. Basic Statistics: Like mean, median or standart deviation. If you know basic statistics, you can use **python** easily. \n1. Data Munging: Working with messy and difficult data. Like a inconsistent date and string formatting. As you guess, **python** helps us.\n1. Data Visualization: Title is actually explanatory. We will visualize the data with **python** like matplot and seaborn libraries.\n1. Machine Learning: You do not need to understand math behind the machine learning technique. You only need is understanding basics of machine learning and learning how to implement it while using **python**.\n\n### As a summary we will learn python to be data scientist !!!\n\n**Content:**\n1. [Introduction to Python:](#1)\n    1. [Matplotlib](#2)\n    1. [Dictionaries ](#3)\n    1. [Pandas](#4)\n    1. [Logic, control flow and filtering](#5)\n    1. [Loop data structures](#6)\n1. [Python Data Science Toolbox:](#7)\n    1. [User defined function](#8)\n    1. [Scope](#9)\n    1. [Nested function](#10)\n    1. [Default and flexible arguments](#11)\n    1. [Lambda function](#12)\n    1. [Anonymous function](#13)\n    1. [Iterators](#14)\n    1. [List comprehension](#15)\n1. [Cleaning Data](#16)\n    1. [Diagnose data for cleaning](#17)\n    1. [Exploratory data analysis](#18)\n    1. [Visual exploratory data analysis](#19)\n    1. [Tidy data](#20)\n    1. [Pivoting data](#21)\n    1. [Concatenating data](#22)\n    1. [Data types](#23)\n    1. [Missing data and testing with assert](#24)\n1. [Pandas Foundation](#25)\n    1. [Review of pandas](#26)\n    1. [Building data frames from scratch](#27)\n    1. [Visual exploratory data analysis](#28)\n    1. [Statistical explatory data analysis](#29)\n    1. [Indexing pandas time series](#30)\n    1. [Resampling pandas time series](#31)\n1. [Manipulating Data Frames with Pandas](#32)\n    1. [Indexing data frames](#33)\n    1. [Slicing data frames](#34)\n    1. [Filtering data frames](#35)\n    1. [Transforming data frames](#36)\n    1. [Index objects and labeled data](#37)\n    1. [Hierarchical indexing](#38)\n    1. [Pivoting data frames](#39)\n    1. [Stacking and unstacking data frames](#40)\n    1. [Melting data frames](#41)\n    1. [Categoricals and groupby](#42)\n1. Data Visualization\n    1. Seaborn: https:\/\/www.kaggle.com\/kanncaa1\/seaborn-for-beginners\n    1. Bokeh 1: https:\/\/www.kaggle.com\/kanncaa1\/interactive-bokeh-tutorial-part-1\n    1. Rare Visualization: https:\/\/www.kaggle.com\/kanncaa1\/rare-visualization-tools\n    1. Plotly: https:\/\/www.kaggle.com\/kanncaa1\/plotly-tutorial-for-beginners\n1. Machine Learning\n    1. https:\/\/www.kaggle.com\/kanncaa1\/machine-learning-tutorial-for-beginners\/\n1. Deep Learning\n    1. https:\/\/www.kaggle.com\/kanncaa1\/deep-learning-tutorial-for-beginners\n1. Time Series Prediction\n    1. https:\/\/www.kaggle.com\/kanncaa1\/time-series-prediction-tutorial-with-eda\n1. Statistic\n    1. https:\/\/www.kaggle.com\/kanncaa1\/basic-statistic-tutorial-for-beginners\n1. Deep Learning with Pytorch\n    1. Artificial Neural Network: https:\/\/www.kaggle.com\/kanncaa1\/pytorch-tutorial-for-deep-learning-lovers\n    1. Convolutional Neural Network: https:\/\/www.kaggle.com\/kanncaa1\/pytorch-tutorial-for-deep-learning-lovers\n    1. Recurrent Neural Network: https:\/\/www.kaggle.com\/kanncaa1\/recurrent-neural-network-with-pytorch","bc661c55":"<a id=\"25\"><\/a> <br>\n# 4. PANDAS FOUNDATION ","7399fdff":"<a id=\"2\"><\/a> <br>\n### MATPLOTLIB\nMatplot is a python library that help us to plot data. The easiest and most basic plots are line, scatter and histogram plots.\n* Line plot is better when x axis is time.\n* Scatter is better when there is correlation between two variables\n* Histogram is better when we need to see distribution of numerical data.\n* Customization: Colors,labels,thickness of line, title, opacity, grid, figsize, ticks of axis and linestyle  ","8daaba6d":"<a id=\"21\"><\/a> <br>\n### PIVOTING DATA\nReverse of melting.","abcfcf62":"<a id=\"39\"><\/a> <br>\n### PIVOTING DATA FRAMES\n* pivoting: reshape tool\n#Reshape tool demek\nBizim eski feature column olarak kulland\u0131\u011f\u0131m\u0131z isimlere art\u0131k bir value ile yapaca\u011f\u0131z","23276b6f":"<a id=\"42\"><\/a> <br>\n### CATEGORICALS AND GROUPBY","57371fb2":"Up to now, you learn \n* User defined function \n* Scope\n* Nested function\n* Default and flexible arguments\n* Lambda function\n*  Anonymous function\n*  Iterators\n* List comprehension\n","c43461e5":"<a id=\"17\"><\/a> <br>\n### DIAGNOSE DATA for CLEANING\nWe need to diagnose and clean data before exploring.\n<br>Unclean data:\n* Column name inconsistency like upper-lower case letter or space between words\n* missing data\n* different language\n\n<br> We will use head, tail, columns, shape and info methods to diagnose data\n","d8ebdbe2":"<a id=\"32\"><\/a> <br>\n# MANIPULATING DATA FRAMES WITH PANDAS","f9bb3d1e":"<a id=\"19\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Box plots: visualize basic statistics like outliers, min\/max or quantiles","db8184a3":"<a id=\"23\"><\/a> <br>\n### DATA TYPES\nThere are 5 basic data types: object(string),boolean, integer, float and categorical.\n<br> We can make conversion data types like from str to categorical or from int to float\n<br> Why is category important: \n* make dataframe smaller in memory \n* can be utilized for anlaysis especially for sklearn(we will learn later)","15d99368":"<a id=\"4\"><\/a> <br>\n### PANDAS\nWhat do we need to know about pandas?\n* CSV: comma - separated values\n\n","ca0fa7b6":"# CONCLUSION\nThank you for your votes and comments\n<br> **MACHINE LEARNING ** https:\/\/www.kaggle.com\/kanncaa1\/machine-learning-tutorial-for-beginners\/\n<br> **DEEP LEARNING** https:\/\/www.kaggle.com\/kanncaa1\/deep-learning-tutorial-for-beginners\n<br> **STATISTICAL LEARNING** https:\/\/www.kaggle.com\/kanncaa1\/statistical-learning-tutorial-for-beginners\n<br>**If you have any question or suggest, I will be happy to hear it.**","56e6e3d7":"[i + 1 for i in num1 ]: list of comprehension\n<br> i +1: list comprehension syntax\n<br> for i in num1: for loop syntax\n<br> i: iterator\n<br> num1: iterable object","6db6b2a1":"<a id=\"11\"><\/a> <br>\n### DEFAULT and FLEXIBLE ARGUMENTS\n* Default argument example:\n<br> def f(a, b=1):\n        \"\"\" b = 1 is default argument\"\"\"\n* Flexible argument example:\n<br> def f(*args):\n       \"\"\" *args can be one or more\"\"\"\n<br>def f(** kwargs)\n       \"\"\" **kwargs is a dictionary\"\"\"\n       \n<br><br> lets write some code to practice  ","3dce51e0":"<a id=\"12\"><\/a> <br>\n### LAMBDA FUNCTION\nFaster way of writing function","fdf02f6f":"<a id=\"10\"><\/a> <br>\n### NESTED FUNCTION\n* function inside function.\n* There is a LEGB rule that is search local scope, enclosing function, global and built in scopes, respectively.","b69005c2":"<a id=\"28\"><\/a> <br>\n### VISUAL EXPLORATORY DATA ANALYSIS\n* Plot\n* Subplot\n* Histogram:\n    * bins: number of bins\n    * range(tuble): min and max values of bins\n    * normed(boolean): normalize or not\n    * cumulative(boolean): compute cumulative distribution","96144175":"**WARNING - UYARI**\n* If you run the code above, if it outputs like in the picture, you need to put the \".csv\" path in pd.read_csv () (as in the picture).\n* Yukar\u0131daki kod blo\u011funu run edince sonu\u00e7 ne veriyorsa read_csv i\u00e7erisine onu yazman\u0131z gerekli.\n* Mesela, e\u011fer yukar\u0131 bulunan kodu \u00e7al\u0131\u015ft\u0131rd\u0131\u011f\u0131n\u0131zda, resimdeki gibi bir output veriyorsa pd.read_csv() i\u00e7erisine resimdeki \".csv\" yolunu koyman\u0131z gerekli (resimde oldu\u011fu gibi). Yukar\u0131da kod blo\u011funu run edince ne \u00e7\u0131k\u0131yorsa onu yazman\u0131z laz\u0131m mesela a\u015fa\u011f\u0131daki gibi.\n<a href=\"https:\/\/ibb.co\/Hg0QX2h\"><img src=\"https:\/\/i.ibb.co\/ZT3CNJ2\/sil.png\" alt=\"sil\" border=\"0\"><\/a>\n* read_csv i\u00e7erisine yukar\u0131da \u00e7\u0131kan .csv dosyalar\u0131 yaz\u0131lmal\u0131.","d45ac5ae":"<a id=\"38\"><\/a> <br>\n### HIERARCHICAL INDEXING\n* Setting indexing","01201759":"<a id=\"13\"><\/a> <br>\n### ANONYMOUS FUNCT\u0130ON\nLike lambda function but it can take more than one arguments.\n* map(func,seq) : applies a function to all the items in a list\n","a88c9fcd":"<a id=\"24\"><\/a> <br>\n### MISSING DATA and TESTING WITH ASSERT\nIf we encounter with missing data, what we can do:\n* leave as is\n* drop them with dropna()\n* fill missing value with fillna()\n* fill missing values with test statistics like mean\n<br>Assert statement: check that you can turn on or turn off when you are done with your testing of the program","8d334e1e":"<a id=\"31\"><\/a> <br>\n### RESAMPLING PANDAS TIME SERIES\n* Datan\u0131n i\u00e7inden elde etti\u011fimiz yeni sample lara resampling denir\n* \u00d6rne\u011fin 1992 y\u0131l\u0131ndaki speed column de\u011ferlerini ortalamaas\u0131n\u0131 al\n* Resampling: statistical method over different time intervals(M harfini kullanarak t\u00fcm aylar\u0131 resample yapabilirz) (A harfi ile de aylar\u0131)\n    * Needs string to specify frequency like \"M\" = month or \"A\" = year\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019 \n    * https:\/\/pandas.pydata.org\/pandas-docs\/stable\/generated\/pandas.Series.interpolate.html\n","9899e07a":"<a id=\"30\"><\/a> <br>\n### INDEXING PANDAS TIME SERIES\n* datetime = object\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","c3a8e4e2":"<a id=\"8\"><\/a> <br>\n### USER DEFINED FUNCTION\nWhat do we need to know about functions:\n* docstrings: documentation for functions. Example:\n<br>for f():\n    <br>\"\"\"This is docstring for documentation of function f\"\"\"\n* tuple: sequence of immutable python objects. \n<br>cant modify values\n<br>tuple uses paranthesis like tuble = (1,2,3)\n<br>unpack tuple into several variables like a,b,c = tuple\n    ","9889e8a0":"<a id=\"6\"><\/a> <br>\n### WHILE and FOR LOOPS\nWe will learn the most basic while and for loops","d1048069":"<a id=\"37\"><\/a> <br>\n### INDEX OBJECTS AND LABELED DATA\nindex: sequence of label\n","af41ccd9":"In this part, you learn:\n* Diagnose data for cleaning\n* Exploratory data analysis\n* Visual exploratory data analysis\n* Tidy data\n* Pivoting data\n* Concatenating data\n* Data types\n* Missing data and testing with assert","0c01ef11":"In this part, you learn:\n* how to import csv file\n* plotting line,scatter and histogram\n* basic dictionary features\n* basic pandas features like filtering that is actually something always used and main for being data scientist\n* While and for loops","be519bdb":"<a id=\"29\"><\/a> <br>\n### STATISTICAL EXPLORATORY DATA ANALYSIS\nI already explained it at previous parts. However lets look at one more time.\n* count: number of entries\n* mean: average of entries\n* std: standart deviation\n* min: minimum entry\n* 25%: first quantile\n* 50%: median or second quantile\n* 75%: third quantile\n* max: maximum entry","c8eb8921":"zip(): zip lists#\u00c7ok kullan\u0131lan Methodlardan birisi!","4277263f":"<a id=\"5\"><\/a> <br>\nBefore continuing with pandas,   we need to learn **logic, control flow** and **filtering.**\n<br>Comparison operator:  ==, <, >, <=\n<br>Boolean operators: and, or ,not\n<br> Filtering pandas","dae0f0da":"<a id=\"7\"><\/a> <br>\n# 2. PYTHON DATA SCIENCE TOOLBOX","1a5391c5":"<a id=\"1\"><\/a> <br>\n# 1. INTRODUCTION TO PYTHON","4dc59bca":"<a id=\"26\"><\/a> <br>\n### REV\u0130EW of PANDAS\nAs you notice, I do not give all idea in a same time. Although, we learn some basics of pandas, we will go deeper in pandas.\n* single column = series\n* NaN = not a number\n* dataframe.values = numpy\n"}}