{"cell_type":{"ffd6901f":"code","95ac23b3":"code","7e34f71e":"code","0e1caa63":"code","0c94c168":"code","458bd47c":"code","7e2ef049":"code","51ce55ae":"code","60b01311":"code","7ddd8c44":"code","cb881061":"code","72858c83":"code","94e9a9d0":"code","c3dd9c25":"code","c2950f89":"code","8ef719fa":"code","43845336":"code","bda08299":"code","f18490b4":"code","04a28b80":"code","f8e4931f":"code","4198657f":"code","8b27c795":"code","8ca87f36":"code","b012e7b5":"code","c79f8b5d":"code","bacaee09":"code","09225190":"markdown","dbdd2774":"markdown","27b1461f":"markdown","50b240ac":"markdown","d2781dd6":"markdown","2dee408c":"markdown","478283dd":"markdown"},"source":{"ffd6901f":"def c_log(x):\n    if x==0:\n        return -200\n    else:\n        return np.log(x)","95ac23b3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nimport seaborn as sns\nfrom scipy import stats\nimport seaborn as sns\nimport math\nimport re\nregex = '[A-Z]'\nscaler = MinMaxScaler()\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n####################################################################################################################\n####################################################################################################################\n####Preparing the Data#####\ndata = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')#----->Loading Data\ndata['Cabin'] = data.apply(lambda row: 0 if pd.isnull(row['Cabin']) else row['Cabin'],axis=1)\ndata['Cabin'] = data.apply(lambda row: re.findall(regex,row['Cabin'])[0] if row['Cabin']!=0 else 0, axis=1)\ndata['Cabin'] = data.apply(lambda row: np.mean(data[data['Cabin']==row['Cabin']]['Age']),axis=1)\n#data = data.drop(['Cabin'],axis=1)#------------------------>Too many missing values\ndata = data.dropna(subset =['Embarked'], how = 'any')#----->Drop 2 rows\n#data = data[data['Fare']<500]\n####Imputing the Age Column######\nlist_age = list(data['Age'])\nlower = 0\nupper = 100\nmu = data['Age'].mean()\nsigma = data['Age'].std()\nfor i in range(len(data)):\n    if math.isnan(list_age[i]):\n        list_age[i]=stats.truncnorm.rvs((lower-mu)\/sigma,(upper-mu)\/sigma,loc=mu,scale=sigma)        \ndata['Age'] = list_age#------------------------------------>Impute Data for Age\n#data['Child'] = data.apply(lambda row:1 if row['Age']<=12 else 0, axis=1)\n#data['Litter'] = data.apply(lambda row: 1 if row['SibSp']>=2 else 0, axis=1)\n#data['LC'] = data.apply(lambda row:1 if (row['Child']==1)&(row['Litter']==0) else 0, axis=1)\n#data = data.drop(['Child','Litter'],axis=1)\n\n#####Drop columns, and make one hot encoding for categorical variables#######\ndummy1 = pd.get_dummies(data['Sex'])#---------------------->Create one hot encoding\ndata = pd.concat([data,dummy1],axis=1)\ndata = data.drop(['Sex','male'],axis=1)\ndata['Litter'] = data.apply(lambda row: 1 if (row['SibSp']>=2)&(row['female']==0) else 0, axis=1)\n#data['Cheap'] = data.apply(lambda row:1 if row['Fare']<40 else 0,axis=1)\n#data['unfort_fem'] = data.apply(lambda row:1 if (row['Cheap']==1 and row['female']==1) else 0,axis=1)\ndata['log(fare\/age)'] = data.apply(lambda row:row['Fare']\/row['Age'],axis=1)\ndata['log(fare\/age)'] = data.apply(lambda row:1 if row['log(fare\/age)']>20 else 0, axis=1)\ndata['company'] = data.apply(lambda row:row['SibSp']+row['Parch'],axis=1)\n#data = data.drop(['SibSp','Parch'],axis=1)\n#dummy2 = pd.get_dummies(data['Pclass'])\n#data = pd.concat([data,dummy2],axis=1)\n#data = data.drop(['Pclass',1,2],axis=1)\ndata['Pclass'] = data.apply(lambda row:np.mean(np.array(data[(data['Pclass']==row['Pclass'])&(data['Embarked']==row['Embarked'])]['Fare'])),axis=1)\ndata = data.drop(['PassengerId','Name','Ticket','Embarked'],axis=1)\nlabels = data['Survived']\ntrain = data.drop('Survived',axis=1)#---------------------->Create train data and labels\n#train = pd.DataFrame(scaler.fit_transform(train), columns=train.columns)","7e34f71e":"survived_males = data[(data['female']==0)&(data['Survived']==1)]\nmales = data[(data['female']==0)&(data['Litter']==0)]","0e1caa63":"males.sort_values(['Survived','Pclass','Fare'],ascending=False).head(50)","0c94c168":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train, labels, test_size = 0.2, random_state = 5)","458bd47c":"# Create the model with 100 trees\nmodel_RF = RandomForestClassifier(n_estimators=3000, \n                               bootstrap = True,\n                               max_features = 'sqrt',max_depth=10)\n\nfrom sklearn.linear_model import LogisticRegression\nmodel_log = LogisticRegression(solver='newton-cg')\n\nfrom xgboost import XGBClassifier\nmodel_xg = XGBClassifier(n_estimators=3000)\n\nfrom sklearn.neighbors import KNeighborsClassifier\nmodel_knn = KNeighborsClassifier(n_neighbors=10)\n","7e2ef049":"model_RF.fit(X_train, y_train)\nmodel_log.fit(X_train,y_train)\nmodel_xg.fit(X_train,y_train)\nmodel_knn.fit(X_train,y_train)","51ce55ae":"def generate_cr(model,X_test,y_test):\n    y_true = y_test\n    y_pred = model.predict(X_test)\n    from sklearn.metrics import classification_report\n    #print(classification_report(y_true,y_pred))\n    cr = classification_report(y_true,y_pred)\n    model_pred = pd.DataFrame({'model_pred':y_pred})\n    df = pd.concat([X_test,model_pred],axis=1)\n    return cr,df\n\ndef generate_cm(model,X_test,y_test):\n    y_true = y_test\n    y_pred = model.predict(X_test)\n    from sklearn.metrics import confusion_matrix \n    #print(classification_report(y_true,y_pred))\n    #cr = classification_report(y_true,y_pred)\n    cm = confusion_matrix(y_true, y_pred) \n    model_pred = pd.DataFrame({'model_pred':y_pred})\n    df = pd.concat([X_test,model_pred],axis=1)\n    return cm,df","60b01311":"model_list = [model_RF,model_log,model_xg,model_knn]\ng = lambda model:generate_cr(model,X_test,y_test)\ncr_list = list(map(g,model_list)) ","7ddd8c44":"print(cr_list[0][0])","cb881061":"import warnings\nwarnings.filterwarnings(\"ignore\")\n#test_df = pd.concat([X_test,y_test],axis=1)\ny_pred = pd.DataFrame(model_RF.predict(X_test))\nX_test['pred'] = X_test.apply(lambda row:model_RF.predict(np.array(row).reshape(1, -1))[0],axis=1)\ntest_df = pd.concat([X_test.reset_index(drop=True),y_test.reset_index(drop=True)],axis=1)\n'''\ntest_df['MCtest'] = test_df.apply(lambda row: 1 if (row['female']==0)&(row['Cabin']==1)&(row[3]==0)&('SibSp'!=0) else 0,axis=1)\ntest_df['PCtest'] = test_df.apply(lambda row: 1 if (row['MCtest']==1)&(row['SibSp']==0)&(row['Parch']!=0) else 0, axis=1)\ntest_df['npred'] = test_df.apply(lambda row:1-row['pred'] if row['MCtest']==1 else row['pred'],axis=1)\ntest_df['npred'] = test_df.apply(lambda row:1-row['npred'] if row['PCtest']==1 else row['npred'],axis=1)\n#test_df['FNCtest'] = test_df.apply(lambda row: 1 if (row['female']==1)&(row['Cabin']==0)&(row[3]==1) else 0,axis=1) \n#test_df['npred'] = test_df.apply(lambda row:1-row['pred'] if row['FNCtest']==1 else row['pred'],axis=1)\n\n\nfrom sklearn.metrics import classification_report\ncr = classification_report(test_df['Survived'],test_df['npred'])\nprint(cr)\n'''","72858c83":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n\ndef spl_predict(model,df):\n    df['pred'] = model.predict(df)\n    df['MCtest'] = df.apply(lambda row: 1 if (row['female']==0)&(row['Cabin']==1)&(row[3]==0)&(row['SbSp']!=0) else 0,axis=1) \n    df['PCtest'] = df.apply(lambda row: 1 if (row['MCtest']==1)&(row['SibSp']==0)&(row['Parch']!=0) else 0, axis=1)\n    df['npred'] = df.apply(lambda row:int(1-row['pred']) if row['MCtest']==1 else int(row['pred']),axis=1)\n    df['npred'] = df.apply(lambda row:1-row['npred'] if row['PCtest']==1 else row['npred'],axis=1)\n    return list(df['npred'])\n","94e9a9d0":"wrong_df = test_df[test_df['pred']!=test_df['Survived']]\nwrong_df['Wrong'] = wrong_df.apply(lambda row:1,axis=1)\nright_df = test_df[test_df['pred']==test_df['Survived']].reset_index(drop=True)\nright_df['Wrong'] = right_df.apply(lambda row:0,axis=1)\nright_wrong = pd.concat([pd.DataFrame(wrong_df),pd.DataFrame(right_df)],ignore_index=True)\n#right_wrong['MCtest'] = right_wrong.apply(lambda row: 1 if (row['female']==0)&(row['Cabin']==1)&(row[3]==0) else 0,axis=1) \nright_wrong['age\/fare'] = right_wrong.apply(lambda row:(row['Age']+0.01)\/(row['Fare']+0.01),axis=1)\n#right_wrong = right_wrong[right_wrong['MCtest']==1]\nwrong = right_wrong['Wrong']\n#right_wrong = right_wrong.drop(['pred','Wrong','age\/fare','SibSp','Parch','company','log(fare\/age)'],axis=1)\nlut = dict(zip(wrong.unique(), \"rb\"))\nrow_colors = wrong.map(lut)\ng = sns.clustermap(right_wrong, row_colors=row_colors,standard_scale=1)","c3dd9c25":"wrong_df[wrong_df['female']==0].sort_values('Fare').reset_index(drop=True)","c2950f89":"test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\npassid = test['PassengerId']\nprint(list(test))\n####Imputing the Age Column######\nlist_age = list(test['Age'])\nlower = 0\nupper = 100\nmu = data['Age'].mean()\nsigma = data['Age'].std()\nfor i in range(len(test)):\n    if math.isnan(list_age[i]):\n        list_age[i]=stats.truncnorm.rvs((lower-mu)\/sigma,(upper-mu)\/sigma,loc=mu,scale=sigma)        \ntest['Age'] = list_age#------------------------------------>Impute Data for Age\n\ntest['Fare'] = test.apply(lambda row:get_fare_pclass(test,row['Pclass']) if pd.isnull(row['Fare']) else row['Fare'],axis=1)\n#test['Cabin'] = test.apply(lambda row: 0 if pd.isnull(row['Cabin']) else 1,axis=1)\ntest['Cabin'] = test.apply(lambda row: 0 if pd.isnull(row['Cabin']) else row['Cabin'],axis=1)\ntest['Cabin'] = test.apply(lambda row: re.findall(regex,row['Cabin'])[0] if row['Cabin']!=0 else 0, axis=1)\ntest['Cabin'] = test.apply(lambda row: np.mean(data[data['Cabin']==row['Cabin']]['Age']),axis=1)\n\n\n\n#test = test.drop('Cabin',axis=1)\n\n#####Drop columns, and make one hot encoding for categorical variables#######\ntest = test.drop(['PassengerId','Name','Ticket','Embarked'],axis=1)\ndummy1 = pd.get_dummies(test['Sex'])#---------------------->Create one hot encoding\ntest = pd.concat([test,dummy1],axis=1)\ntest = test.drop(['Sex','male'],axis=1)\n#dummy2 = pd.get_dummies(test['Embarked'])\n#test = pd.concat([test,dummy2],axis=1)\n#test = test.drop(['Embarked','S'],axis=1)\n#test['Cheap'] = test.apply(lambda row:1 if row['Fare']<40 else 0,axis=1)\n#test['unfort_fem'] = test.apply(lambda row:1 if (row['Cheap']==1 and row['female']==1) else 0,axis=1)\ntest['age>fare'] = test.apply(lambda row:c_log(row['Fare']\/row['Age']),axis=1)\ndummy2 = pd.get_dummies(test['Pclass'])\ntest = pd.concat([test,dummy2],axis=1)\ntest = test.drop(['Pclass',1,2],axis=1)\nprint(list(test))\n#labels = test['Survived']\n#train = test.drop('Survived',axis=1)#---------------------->Create train data and labels","8ef719fa":"data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')#----->Loading Data\ndata['Cabin'] = data.apply(lambda row: 0 if pd.isnull(row['Cabin']) else row['Cabin'],axis=1)\ndata['Cabin'] = data.apply(lambda row: re.findall(regex,row['Cabin'])[0] if row['Cabin']!=0 else 0, axis=1)\ndata['Cabin'] = data.apply(lambda row: np.mean(data[data['Cabin']==row['Cabin']]['Age']),axis=1)\n#data = data.drop(['Cabin'],axis=1)#------------------------>Too many missing values\ndata = data.dropna(subset =['Embarked'], how = 'any')#----->Drop 2 rows\n#data = data[data['Fare']<500]\n####Imputing the Age Column######\nlist_age = list(data['Age'])\nlower = 0\nupper = 100\nmu = data['Age'].mean()\nsigma = data['Age'].std()\nfor i in range(len(data)):\n    if math.isnan(list_age[i]):\n        list_age[i]=stats.truncnorm.rvs((lower-mu)\/sigma,(upper-mu)\/sigma,loc=mu,scale=sigma)        \ndata['Age'] = list_age#------------------------------------>Impute Data for Age\n#data['Child'] = data.apply(lambda row:1 if row['Age']<=12 else 0, axis=1)\n#data['Litter'] = data.apply(lambda row: 1 if row['SibSp']>=2 else 0, axis=1)\n#data['LC'] = data.apply(lambda row:1 if (row['Child']==1)&(row['Litter']==0) else 0, axis=1)\n#data = data.drop(['Child','Litter'],axis=1)\n\n#####Drop columns, and make one hot encoding for categorical variables#######\ndummy1 = pd.get_dummies(data['Sex'])#---------------------->Create one hot encoding\ndata = pd.concat([data,dummy1],axis=1)\ndata = data.drop(['Sex','male'],axis=1)\ndata['Litter'] = data.apply(lambda row: 1 if (row['SibSp']>=2)&(row['female']==0) else 0, axis=1)\n#data['Cheap'] = data.apply(lambda row:1 if row['Fare']<40 else 0,axis=1)\n#data['unfort_fem'] = data.apply(lambda row:1 if (row['Cheap']==1 and row['female']==1) else 0,axis=1)\ndata['log(fare\/age)'] = data.apply(lambda row:row['Fare']\/row['Age'],axis=1)\ndata['log(fare\/age)'] = data.apply(lambda row:1 if row['log(fare\/age)']>20 else 0, axis=1)\ndata['company'] = data.apply(lambda row:row['SibSp']+row['Parch'],axis=1)\n#data = data.drop(['SibSp','Parch'],axis=1)\n#dummy2 = pd.get_dummies(data['Pclass'])\n#data = pd.concat([data,dummy2],axis=1)\n#data = data.drop(['Pclass',1,2],axis=1)\ndata['Pclass'] = data.apply(lambda row:np.mean(np.array(data[(data['Pclass']==row['Pclass'])&(data['Embarked']==row['Embarked'])]['Fare'])),axis=1)\ndata = data.drop(['PassengerId','Name','Ticket','Embarked'],axis=1)\n\n","43845336":"submission1 = pd.DataFrame({'PassengerId':list(passid),'Survived':spl_predict(model_RF,test)})","bda08299":"submission.to_csv('submission20200611-1.csv',index=False)","f18490b4":"na_dict = {col:test[col].isna().sum() for col in test.columns}","04a28b80":"na_dict","f8e4931f":"submission2 = pd.DataFrame({'PassengerId':list(passid),'Survived':model_RF.predict(test)})","4198657f":"print(submission1)","8b27c795":"def get_prob_fare(fare_invest,fare,tol):\n    relevant_rows = fare_invest[(fare_invest['Age']>fare-tol) & (fare_invest['Age']<fare+tol)]\n    num = len(relevant_rows[relevant_rows['Survived']==1])\n    den = len(relevant_rows)\n    try:\n        prob = num\/den\n    except:\n        prob = 0\n    return prob\n\ndef get_fare_pclass(df,pclass):\n    relevant_df = df[df['Pclass']==pclass]\n    m = np.mean(relevant_df['Fare'])\n    return m","8ca87f36":"get_fare_pclass(train,3)","b012e7b5":"get_prob_fare(data,36,5)","c79f8b5d":"age_sur = [get_prob_fare(data[data['female']==0],i,4) for i in range(70)]","bacaee09":"sns.lineplot(list(range(70)),age_sur)\n","09225190":"# Declare a model","dbdd2774":"If you are a male with a spouse, are you more likely to die?","27b1461f":"# Fit the model on the train data","50b240ac":"# Some exploratory functions","d2781dd6":"# Split the data into train and test","2dee408c":"# How does your sex affect your chances of survival?\n\n## 74% of females survived\n## 18% of males survived\n### What was special about the 109 males who survived?\nMales with a high fare\/age ration tend to survive.","478283dd":"# Generate Classification Report"}}