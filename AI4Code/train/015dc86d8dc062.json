{"cell_type":{"bd00e5b7":"code","22492899":"code","326107da":"code","9bc252b5":"code","bf1b226f":"code","0fa2ef75":"code","ff4f3793":"code","25b38299":"code","9b55750f":"code","a0ed5b16":"code","51c2d1bd":"code","e008dfae":"code","2c0e8ed4":"code","c9058163":"code","887f04b9":"code","0bad6d8b":"code","96ba6826":"code","36a6b132":"code","d8965d8e":"code","233f6294":"code","ac5f1ad8":"code","43252273":"code","c30c0c43":"code","79dc3448":"code","8f3a6caf":"code","73f90e0c":"code","85529a47":"code","f07a494d":"code","37e02203":"code","0fe89e7b":"code","15427a15":"code","9fa16812":"code","46230271":"code","7b7785c7":"code","38d19b6d":"code","d443db7a":"code","97265d96":"code","c43e5fb0":"markdown","01bf62b7":"markdown","f73124ed":"markdown","13ae650a":"markdown","1b54d79b":"markdown","fa263cb5":"markdown","a6d50189":"markdown","488a98fd":"markdown","b4924060":"markdown","99ab52cd":"markdown","4790259a":"markdown","efbdcd0c":"markdown","29074d48":"markdown"},"source":{"bd00e5b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","22492899":"!pip install download","326107da":"from __future__ import absolute_import,division,print_function,unicode_literals\n\nimport matplotlib as mpl\nimport os\nfrom datetime import datetime\n\nimport pandas as pd\n\nfrom download import download\n\nmpl.rcParams['figure.figsize'] = (8,6)\nmpl.rcParams['axes.grid'] = False","9bc252b5":"path = download('https:\/\/archive.ics.uci.edu\/ml\/machine-learning-databases\/00501\/PRSA2017_Data_20130301-20170228.zip','\/kaggle\/temp',replace=True, kind=\"zip\")","bf1b226f":"df = pd.read_csv('\/kaggle\/temp\/PRSA_Data_20130301-20170228\/PRSA_Data_Dingling_20130301-20170228.csv', encoding='ISO-8859-1')","0fa2ef75":"df.head()","ff4f3793":"def convert_to_date(x):\n    return datetime.strptime(x, '%Y %m %d %H')","25b38299":"a_df = pd.read_csv('\/kaggle\/temp\/PRSA_Data_20130301-20170228\/PRSA_Data_Dingling_20130301-20170228.csv', \n                    parse_dates = [['year', 'month', 'day', 'hour']],date_parser=convert_to_date)","9b55750f":"a_df.head()","a0ed5b16":"a_df.info()","51c2d1bd":"a_df.describe()","e008dfae":"a_df.isnull().sum()","2c0e8ed4":"a_df.query('TEMP!=TEMP')","c9058163":"a_df.query('TEMP!=TEMP').count()","887f04b9":"a_df[a_df['PM2.5'].isnull()]","0bad6d8b":"a_df[a_df['PM2.5'].isnull()].count()","96ba6826":"import plotly.express as px\n\nfig = px.line(a_df, x='year_month_day_hour', y='PM2.5', title='PM2.5 with Slider')\n\nfig.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=2, label=\"2y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=3, label=\"3y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ])\n    )\n)\nfig.show()","36a6b132":"fig = px.line(a_df, x='year_month_day_hour', y='TEMP', title='TEMP with Slider')\n\nfig.update_xaxes(\n    rangeslider_visible=True,\n    rangeselector=dict(\n        buttons=list([\n            dict(count=1, label=\"1y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=2, label=\"2y\", step=\"year\", stepmode=\"backward\"),\n            dict(count=3, label=\"3y\", step=\"year\", stepmode=\"backward\"),\n            dict(step=\"all\")\n        ])\n    )\n)\nfig.show()","d8965d8e":"a_df=a_df.set_index('year_month_day_hour')","233f6294":"a_df.head()","ac5f1ad8":"a_df.loc['2015-02-02':'2015-02-04']","43252273":"a_dfna=a_df.copy()\n\na_dfna=a_dfna.dropna()","c30c0c43":"pd.plotting.autocorrelation_plot(a_dfna['2014':'2016']['TEMP'])","79dc3448":"a_df['2015-02-21 10':'2015-02-21 20']","8f3a6caf":"a_df_imp=a_df['2015-02-21 10':'2015-02-21 23'][['TEMP']]","73f90e0c":"a_df_imp","85529a47":"a_df_imp['TEMP_FILL']=a_df_imp['TEMP'].fillna(method='ffill')","f07a494d":"a_df_imp","37e02203":"a_df_imp['Temp_bfill']=a_df_imp['TEMP'].fillna(method='bfill')","0fe89e7b":"a_df_imp","15427a15":"a_df_imp['Temp_roll']=a_df_imp['TEMP'].rolling(window=2,min_periods=1).mean()","9fa16812":"a_df_imp","46230271":"a_df.loc[a_df_imp.index+pd.offsets.DateOffset(years=-1)]['TEMP']","7b7785c7":"a_df_imp.index","38d19b6d":"a_df_imp=a_df_imp.reset_index()","d443db7a":"a_df_imp['Temp_prev']=a_df_imp.apply(lambda x:a_df.loc[x['year_month_day_hour']-pd.offsets.DateOffset(years=-1)]['TEMP'] \n                                     if pd.isna(x['TEMP']) else x['TEMP'],axis=1)","97265d96":"a_df_imp","c43e5fb0":"**There are three missing values in the temp field within the specified range**","01bf62b7":"# Backward filling","f73124ed":"# Forward filling","13ae650a":"**Going to impute the missing values with the previous values**","1b54d79b":"**Taking the data of same date and hour of the previous year**","fa263cb5":"**Imputing the data before 2 hours and 1 hour if not that data available**","a6d50189":"**The previous type of imputation is handy while trying to impute data in week ends of year end or festival sales**","488a98fd":"# Handling Missing values","b4924060":"# Rolling window","99ab52cd":"# Imputing previous year data","4790259a":"**While going closer, we can able to see some of the missing values**","efbdcd0c":"**Thus the temperature is at peak at every year , tells that the data is correlated every year**","29074d48":"**Every year, there is seasonality in temperature data**"}}