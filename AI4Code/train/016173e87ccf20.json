{"cell_type":{"0a90236a":"code","42c0281e":"code","d88e2514":"code","71d9bdfd":"code","ef6df8bf":"code","0439876f":"code","99eacddf":"code","afa6488b":"code","4a920e99":"code","0032207b":"code","4c222600":"code","a9dd2bb2":"code","06189671":"code","b9dfb04b":"code","5eb3ab59":"code","7b72857c":"code","a173ed95":"code","10feab3a":"markdown","21dabcb6":"markdown","d98dde1a":"markdown","694e82dc":"markdown","770b7e04":"markdown"},"source":{"0a90236a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","42c0281e":"import pandas as pd\nimport scipy.io\nfrom array import *\nimport numpy as np\nimport re\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport re, string\nimport nltk\nfrom nltk import word_tokenize, sent_tokenize\nfrom nltk.corpus import stopwords\nfrom nltk.stem import LancasterStemmer, WordNetLemmatizer\nnltk.download('stopwords')\nnltk.download('wordnet')\nnltk.download('vader_lexicon')\nimport string\nfrom string import digits\nSTOPWORDS = set(stopwords.words('english'))","d88e2514":"train = pd.read_csv(\"\/kaggle\/input\/tweet-sentiment-extraction\/train.csv\", dtype=str)\ntest = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/test.csv', dtype=str)\nsub = pd.read_csv('\/kaggle\/input\/tweet-sentiment-extraction\/sample_submission.csv')","71d9bdfd":"train.head()","ef6df8bf":"test.head()","0439876f":"sub.head()","99eacddf":"def clean_text(text):\n    ## Remove puncuation\n    #text = text.translate(string.punctuation)\n    text = str(text)\n    text= text.lower()\n    ## Convert words to lower case and split them\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    text= url.sub(r'',text)\n    html=re.compile(r'<.*?>')\n    text= html.sub(r'',text)\n    remove_digits = str.maketrans('', '', digits)\n    text = text.translate(remove_digits)\n    ## Remove stop words\n    #text=\" \".join([word for word in str(text).split() if word not in STOPWORDS])\n    return text","afa6488b":"train[\"text\"]=train[\"text\"].apply(clean_text)\ntest[\"text\"]=test[\"text\"].apply(clean_text)","4a920e99":"train.head()","0032207b":"def choosing_selectedword(df_process):\n    train_text = df_process['text']\n    train_sentiment = df_process['sentiment']\n    selected_text_processed = []\n    analyser = SentimentIntensityAnalyzer()\n    for j in range(0 , len(train_text)):\n        text = str(train_text.iloc[j])\n        # For Neutral append the full sentence\n        if(train_sentiment.iloc[j] == \"neutral\"):\n            selected_text_processed.append(str(text))\n        #For positive take only words with positive polarity\n        if(train_sentiment.iloc[j] == \"positive\"):\n            token = re.split(' ', text)\n            ss_arr = \"\"\n            polar = 0\n            for word in token:\n                score = analyser.polarity_scores(word)\n                if score['compound'] >polar:\n                    polar = score['compound']\n                    ss_arr = ss_arr + \" \"+word\n            if len(ss_arr) != 0:\n                selected_text_processed.append(ss_arr)   \n            if len(ss_arr) == 0:\n                selected_text_processed.append(text)\n        #for negative take words with negative polarity \n        if(train_sentiment.iloc[j] == \"negative\"):\n            token = re.split(' ', text)\n            ss_arr = \"\"\n            polar = 0\n            for word in token:\n                score = analyser.polarity_scores(word)\n                if score['compound'] <polar:\n                    polar = score['compound']\n                    ss_arr = ss_arr + \" \" + word\n            if len(ss_arr) != 0:\n                selected_text_processed.append(ss_arr)   \n            if len(ss_arr) == 0:\n                selected_text_processed.append(text)  \n    return selected_text_processed","4c222600":"train[\"predicted\"]=choosing_selectedword(train)","a9dd2bb2":"train.head()","06189671":"test[\"selected_text\"]= choosing_selectedword(test)\nsub[\"selected_text\"]= choosing_selectedword(test)","b9dfb04b":"sub.head()","5eb3ab59":"def jaccard(str1, str2): \n    a = set(str1.lower().split()) \n    b = set(str2.lower().split())\n    c = a.intersection(b)\n    return float(len(c)) \/ (len(a) + len(b) - len(c))","7b72857c":"average = 0\nfor i in range(0,train.shape[0]):\n    jaccard_score = jaccard(str(train[\"selected_text\"][i]),str(train[\"predicted\"][i]))\n    average += jaccard_score \nprint('Training Data average jaccard score is ', average\/len(train[\"selected_text\"]))","a173ed95":"sub.to_csv('submission.csv', index = False)","10feab3a":"Text Extraction based on Polarity","21dabcb6":"# NLP M3 \nB.Tech Data Science  \nJ007 - Amrusha Buddhiraju  \nJ031- Sanika Mhadgut  \nJ046- Gayathri Shrikanth","d98dde1a":"Reading the Dataset","694e82dc":"Cleaning the Dataset","770b7e04":"Jaccard score on train set"}}