{"cell_type":{"ad12dbbe":"code","a00d446a":"code","df30dd77":"code","2cfca46f":"code","41885718":"code","2ab604d5":"code","c778e627":"code","c053d8b4":"code","0a393e79":"code","8a1b3cb3":"code","d710e602":"code","4b6a033a":"code","d788ae82":"code","898cb8e7":"code","42cfa02f":"code","a5c26bdb":"code","f71b56c2":"code","182042b8":"code","f43d5129":"code","1d13fa03":"code","3be5f0af":"code","153cad8e":"code","5be51c36":"code","44178deb":"code","d857db5c":"code","b2e0affd":"code","3fa4fcf9":"code","4db57768":"code","1b9c0fc3":"code","bcaffe4e":"code","a2a0dfeb":"code","89b912d3":"code","d0ebc0f1":"code","d23e196e":"code","3c9d15ff":"code","6f77c4e0":"code","9be9a99f":"code","e62aed98":"markdown","94b318a6":"markdown","daeaf2db":"markdown","c9f81724":"markdown","cadfaaea":"markdown","410df73a":"markdown","dc91ae6e":"markdown","407da1a0":"markdown","728c0783":"markdown","61b7f8a6":"markdown","82fcce51":"markdown","87169a00":"markdown","2bfd8eee":"markdown","4e7cacf8":"markdown","1d10700b":"markdown","f20caad8":"markdown","af9d2eb0":"markdown","0d640b3b":"markdown","7217e16c":"markdown","d120e277":"markdown","02a70ee9":"markdown","53e7f456":"markdown","0e05efe3":"markdown","b5312adc":"markdown","ee415ac3":"markdown","e218a4f4":"markdown","8c84ba8b":"markdown"},"source":{"ad12dbbe":"import numpy as np # linear algebra\nimport pandas as pd\nfrom tqdm import tqdm\nfrom glob import glob\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.utils import *\nimport numpy as np\nimport os","a00d446a":"normal = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/train_Normal_128.npy')\nviral = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/train_Virus_128.npy')\nbacterial = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/train_bacteria_128.npy')","df30dd77":"normal.shape, viral.shape, bacterial.shape","2cfca46f":"label_normal = np.zeros(len(normal))\nlabel_bacterial = np.ones(len(bacterial))\nlabel_viral = np.full(len(viral),2, dtype = int)","41885718":"train_data = np.concatenate((normal,bacterial,viral),axis=0)\ntrain_label = np.concatenate((label_normal,label_bacterial,label_viral),axis=0)","2ab604d5":"train_label.shape, train_data.shape","c778e627":"import matplotlib.pyplot as plt","c053d8b4":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(normal[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","0a393e79":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(viral[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","8a1b3cb3":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(bacterial[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","d710e602":"test_normal = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/test_Normal_128.npy')\ntest_viral = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/test_Virus_128.npy')\ntest_bacterial = np.load('..\/input\/pneumonia-chest-xray-npy\/Array128\/Array128\/test_bacteria_128.npy')","4b6a033a":"test_normal.shape, test_viral.shape , test_bacterial.shape","d788ae82":"label_test_normal = np.zeros(len(test_normal))\nlabel_test_bacterial = np.ones(len(test_bacterial))\nlabel_test_viral = np.full(len(test_viral),2, dtype = int)","898cb8e7":"test_data = np.concatenate((test_normal, test_bacterial, test_viral),axis=0)\ntest_label = np.concatenate((label_test_normal,label_test_bacterial,label_test_viral),axis=0)","42cfa02f":"test_data.shape","a5c26bdb":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(test_normal[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","f71b56c2":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(test_viral[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","182042b8":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(test_bacterial[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","f43d5129":"from sklearn.utils import class_weight\n \n \nclass_weights = class_weight.compute_class_weight('balanced',\n                                                 np.unique(train_label),\n                                                 train_label)\nclass_weights","1d13fa03":"def Residual_Unit(input_tensor, nb_of_input_channels, max_dilation, number_of_units):\n    \n  for i in range(number_of_units):\n    x1 = Conv2D(nb_of_input_channels*2, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(input_tensor)\n    x1 = BatchNormalization()(x1)\n  \n    a = []\n\n    for i in range(1, max_dilation+1):\n      temp = DepthwiseConv2D( kernel_size=(3,3), dilation_rate = (i,i), padding = 'same', activation= 'relu')(x1)\n      temp = BatchNormalization()(temp)\n      a.append(temp)\n\n    x = Concatenate(axis= -1)(a)\n    x = Conv2D(nb_of_input_channels, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    x = Add()([x, input_tensor])\n\n    input_tensor = x\n  \n  return x\n","3be5f0af":"# Shifter Unit:\n\ndef Shifter_Unit(input_tensor, nb_of_input_channels, max_dilation):\n    x1 = Conv2D(nb_of_input_channels*4, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(input_tensor)\n    x1 = BatchNormalization()(x1)\n\n    a = []\n\n    for i in range(1, max_dilation+1):\n      temp = DepthwiseConv2D( kernel_size=(3,3), dilation_rate = (i,i), padding = 'same', activation= 'relu')(x1)\n      temp = MaxPool2D(pool_size=(2,2))(temp)\n      temp = BatchNormalization()(temp)\n      a.append(temp)\n\n    x = Concatenate(axis= -1)(a)\n\n    x = Conv2D(nb_of_input_channels*2, kernel_size = (1,1), strides = (1,1), padding='same', dilation_rate= (1,1), activation='relu')(x)\n    x = BatchNormalization()(x)\n\n    return x","153cad8e":"from keras.optimizers import Adam","5be51c36":"#Network:\n  \ndef Network128(input_shape, nb_class, depth):\n  xin = Input(shape= input_shape)\n\n  x = Conv2D(16, kernel_size = (5,5), strides= (1,1), padding = 'same', activation='relu')(xin)\n  x = BatchNormalization()(x)\n\n  x = Conv2D(32, kernel_size = (3,3), strides= (2,2), padding = 'same', activation='relu')(x)\n  x = BatchNormalization()(x)\n  \n##Max Dilation rate will be vary in the range (1,5). \n\n# Max Dilation rate is 5 for tensor (64x64x32)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=32, max_dilation=5, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=32, max_dilation=5)\n\n\n# Max Dilation rate is 4 for (32x32x64)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=64, max_dilation=4, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=64, max_dilation=4)\n\n# Max Dilation rate is 3 for (16x16x128)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=128, max_dilation=3, number_of_units=depth)\n  x = Shifter_Unit(input_tensor=x, nb_of_input_channels=128, max_dilation=3)\n\n# Max Dilation rate is 2 for (8x8x256)\n  x = Residual_Unit(input_tensor=x, nb_of_input_channels=256, max_dilation=2, number_of_units=depth)\n\n  x = GlobalAveragePooling2D()(x)\n\n  x = Dense(128, activation='relu')(x)\n  x = Dense(64, activation='relu')(x)\n\n  x = Dense(nb_class, activation= 'softmax')(x)\n\n  model = Model(xin, x)\n\n  model.compile(loss='categorical_crossentropy', optimizer = Adam(lr = 1e-4), metrics = ['accuracy'])\n\n  return model","44178deb":"# plot confusion matrix\n\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix\nimport pandas.util.testing as tm\nfrom sklearn import metrics\nimport seaborn as sns\nsns.set()\n\nplt.rcParams[\"font.family\"] = 'DejaVu Sans'\n\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues,\n                          save = False):\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.grid(b=False)\n    if save == True:\n      plt.savefig('Confusion Matrix.png', dpi = 300)","d857db5c":"# test model performance\nfrom datetime import datetime\nimport matplotlib.pyplot as plt\nfrom keras.utils import to_categorical\n\n\ndef test_model(model, test_generator, y_test, class_labels, cm_normalize=True, \\\n                 print_cm=True):\n    \n    # BS = 16\n    results = dict()\n    \n    # n = len(testy)\/\/ BS\n\n    # testX = testX[:BS*n]\n    # testy = testy[:BS*n]\n#     steps = y_test.shape[0]\/batch_size\n#     y_test = y_test[:steps*batch_size]\n\n    print('Predicting test data')\n    test_start_time = datetime.now()\n    y_pred_original = model.predict_generator(test_generator, verbose=1)\n    # y_pred = (y_pred_original>0.5).astype('int')\n\n    y_pred = np.argmax(y_pred_original, axis = 1)\n    # y_test = np.argmax(testy, axis= 1)\n    #y_test = np.argmax(testy, axis=-1)\n    \n    test_end_time = datetime.now()\n    print('Done \\n \\n')\n    results['testing_time'] = test_end_time - test_start_time\n    print('testing time(HH:MM:SS:ms) - {}\\n\\n'.format(results['testing_time']))\n    results['predicted'] = y_pred\n    y_test = y_test.astype(int) # sparse form not categorical\n    \n\n    # balanced_accuracy\n    from sklearn.metrics import balanced_accuracy_score\n    balanced_accuracy = balanced_accuracy_score(y_true=y_test, y_pred=y_pred)\n    print('---------------------')\n    print('| Balanced Accuracy  |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(balanced_accuracy))\n\n    \n    # calculate overall accuracty of the model\n    accuracy = metrics.accuracy_score(y_true=y_test, y_pred=y_pred)\n    # store accuracy in results\n    results['accuracy'] = accuracy\n    print('---------------------')\n    print('|      Accuracy      |')\n    print('---------------------')\n    print('\\n    {}\\n\\n'.format(accuracy))\n    \n\n    # get classification report\n    print('-------------------------')\n    print('| Classifiction Report |')\n    print('-------------------------')\n    classification_report = metrics.classification_report(y_test, y_pred)\n    # store report in results\n    results['classification_report'] = classification_report\n    print(classification_report)\n\n\n    \n    # confusion matrix\n    cm = metrics.confusion_matrix(y_test, y_pred)\n    results['confusion_matrix'] = cm\n    if print_cm: \n        print('--------------------')\n        print('| Confusion Matrix |')\n        print('--------------------')\n        print('\\n {}'.format(cm))\n        \n    # plot confusin matrix\n    plt.figure(figsize=(6,4))\n    plt.grid(b=False)\n    plot_confusion_matrix(cm, classes=class_labels, normalize=True, title='Normalized confusion matrix')\n    plt.show()\n    \n\n    from sklearn.metrics import roc_curve, auc\n\n    # create plot\n    fig, c_ax = plt.subplots(1,1, figsize = (7, 7))\n    for (i, label) in enumerate(class_labels):\n        fpr, tpr, thresholds = roc_curve(to_categorical(y_test, 3)[:,i].astype(int), y_pred_original[:,i])\n        c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (label, auc(fpr, tpr)))\n\n    # Set labels for plot\n    c_ax.legend()\n    c_ax.set_xlabel('False Positive Rate')\n    c_ax.set_ylabel('True Positive Rate')\n    c_ax.set_title('Roc AUC Curve')\n    plt.show()\n\n\n    \n    # add the trained  model to the results\n    results['model'] = model\n    \n    return\n\n\nfrom keras.callbacks import Callback\nclass MyLogger(Callback):\n  \n  def __init__(self, test_generator, y_test, class_labels):\n    super(MyLogger, self).__init__()\n    self.test_generator = test_generator\n    self.y_test = y_test\n    self.class_labels = class_labels\n    \n  def on_epoch_end(self, epoch, logs=None):\n    test_model(self.model, self.test_generator, self.y_test, self.class_labels)","b2e0affd":"from keras.utils import to_categorical\ntrain_label = to_categorical(train_label, num_classes= 3)\ntest_label  = to_categorical(test_label, num_classes = 3)","3fa4fcf9":"from keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.models import load_model\nfrom keras.callbacks import *\n\n\ntrain_datagen = ImageDataGenerator(rescale = 1\/255,\n                                  width_shift_range = 0.1,\n                                  height_shift_range = 0.1,\n                                  fill_mode = 'constant',\n                                  zoom_range = 0.1,\n                                  rotation_range = 20)\n\nval_datagen = ImageDataGenerator(rescale = 1\/255)\n\ntrain_generator = train_datagen.flow(train_data,\n                                     train_label, \n                                     batch_size = 32, \n                                     shuffle = True)\n\nval_generator = val_datagen.flow(test_data,\n                                 test_label,\n                                 batch_size = 32,\n                                 shuffle = False)","4db57768":"images, labels = train_generator.next()","1b9c0fc3":"n_row = 3\nn_col = 5\n\nfig, ax = plt.subplots(n_row, n_col, figsize = (n_col*3, n_row*3), constrained_layout = True)\n\nfor row in tqdm(range(n_row)):\n    \n    for col in range(n_col):\n        \n        ax[row][col].imshow(images[row*n_col + col,:,:,0], cmap = 'bone')\n        ax[row][col].set_xticks([])\n        ax[row][col].set_yticks([])","bcaffe4e":"os.mkdir('Model')\nos.mkdir('History')","a2a0dfeb":"def get_callbacks():\n    \n    filepath = 'Model\/best_model_multiclass_128.h5'\n    callback1 = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n    callback2 = MyLogger(val_generator, \n                         y_test = np.argmax(test_label, axis = 1),\n                         class_labels = ['Normal', 'Viral', 'Bacterial'])\n    \n    callback3 = CSVLogger('History\/Multiclass_Log_128.csv')\n\n    return [callback1 ,callback2, callback3]","89b912d3":"model = Network128(input_shape = (128, 128, 1), nb_class = 3, depth = 5)\nmodel.summary() ","d0ebc0f1":"plot_model(model, show_shapes=True)","d23e196e":"history = model.fit_generator(train_generator,\n                              steps_per_epoch = len(train_data) \/\/ train_generator.batch_size,\n                              validation_data=val_generator,\n                              validation_steps= len(test_data)\/\/ val_generator.batch_size,\n                              class_weight =class_weights,\n                              epochs = 70,\n                              callbacks = get_callbacks(),\n                              verbose = 1\n                              )","3c9d15ff":"from keras.models import load_model\nbest_model = load_model('\/kaggle\/working\/Model\/best_model_multiclass_128.h5')","6f77c4e0":"test_model(best_model, \n           val_generator,\n           y_test = np.argmax(test_label, axis = 1),\n           class_labels = ['Normal', 'Viral', 'Bacterial'])","9be9a99f":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nacc = model.history.history['accuracy']\nval_acc = model.history.history['val_accuracy']\nloss = model.history.history['loss']\nval_loss = model.history.history['val_loss']\n\nepochs = range(0,len(acc))\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\n\nplt.plot(epochs, acc, 'r', label='Training accuracy',marker = \"o\")\nplt.plot(epochs, val_acc, 'b', label='Validation accuracy',marker = \"o\")\nplt.title('Training and validation accuracy')\nplt.xticks(np.arange(0, len(acc), 10))\nplt.legend(loc=0)\nplt.figure()\n\nfig = plt.gcf()\nfig.set_size_inches(16, 8)\nplt.plot(epochs, loss, 'r', label='Training Loss',marker = \"o\")\nplt.plot(epochs, val_loss, 'b', label='Validation Loss',marker = \"o\")\nplt.title('Training and validation Loss')\nplt.xticks(np.arange(0, len(acc), 10))\nplt.legend(loc=0)\n#plt.savefig('Multiclass Model .png')\nplt.figure()\nplt.show()\n","e62aed98":"## Shifter Unit","94b318a6":"# **Loading Training Files**","daeaf2db":"# Best Model Performance","c9f81724":"# One Hot Encoding the labels","cadfaaea":"## Bacterial","410df73a":"# Plotting EpochPlot","dc91ae6e":"## Bacterial","407da1a0":"# Viral","728c0783":"# ImageDataGenerator","61b7f8a6":"# Vizualization After Augmentation","82fcce51":"# Loading Best Model","87169a00":"# Plotting Model","2bfd8eee":"### Normal","4e7cacf8":"## Residual Unit","1d10700b":"# Custom Callback","f20caad8":"## Viral","af9d2eb0":"## Normal","0d640b3b":"## Visualization","7217e16c":"# Dealing with Class Imbalance","d120e277":"# Network128","02a70ee9":"# Callback","53e7f456":"# Loading Test Data","0e05efe3":"I have converted all images to numpy array to boost speed","b5312adc":"## Visualization","ee415ac3":"# [CovXNet: A multi-dilation convolutional neural network for automatic COVID-19 and other pneumonia detection from chest X-ray images with transferable multi-receptive feature optimization](https:\/\/www.sciencedirect.com\/science\/article\/pii\/S0010482520302250)\n\n#### Code:[here](https:\/\/github.com\/Perceptron21\/CovXNet)\n## Residual & Shifter Unit:\n![Residual & Shifter Unit](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S0010482520302250-gr2.jpg)\n\n## Model:\n![Model](https:\/\/ars.els-cdn.com\/content\/image\/1-s2.0-S0010482520302250-gr4.jpg)\n","e218a4f4":"# Grad-CAM and Saliency Map \ncoming soon....","8c84ba8b":"# Training"}}