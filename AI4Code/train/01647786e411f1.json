{"cell_type":{"b6abaa5b":"code","65a3620c":"code","09887798":"code","6bf854d7":"code","d130e185":"code","04187455":"code","43f15a0e":"code","35d37dd1":"code","35256939":"code","a3a9f31c":"code","5a05e66a":"code","c0b5588b":"code","993abafa":"code","f8403cbe":"markdown","06ae72b6":"markdown","b095e070":"markdown","6085de51":"markdown"},"source":{"b6abaa5b":"import cv2\nimport pandas as pd\nimport numpy as np\nimport os\nfrom tqdm import tqdm, tqdm_notebook\n\ntrain_df = pd.read_csv('..\/input\/train\/train.csv')\nimg_size = 256\nbatch_size = 16","65a3620c":"pet_ids = train_df['PetID'].values\nn_batches = len(pet_ids) \/\/ batch_size + 1","09887798":"from keras.applications.densenet import preprocess_input, DenseNet121","6bf854d7":"def resize_to_square(im):\n    old_size = im.shape[:2] # old_size is in (height, width) format\n    ratio = float(img_size)\/max(old_size)\n    new_size = tuple([int(x*ratio) for x in old_size])\n    # new_size should be in (width, height) format\n    im = cv2.resize(im, (new_size[1], new_size[0]))\n    delta_w = img_size - new_size[1]\n    delta_h = img_size - new_size[0]\n    top, bottom = delta_h\/\/2, delta_h-(delta_h\/\/2)\n    left, right = delta_w\/\/2, delta_w-(delta_w\/\/2)\n    color = [0, 0, 0]\n    new_im = cv2.copyMakeBorder(im, top, bottom, left, right, cv2.BORDER_CONSTANT,value=color)\n    return new_im\n\ndef load_image(path, pet_id):\n    image = cv2.imread(f'{path}{pet_id}-1.jpg')\n    new_image = resize_to_square(image)\n    new_image = preprocess_input(new_image)\n    return new_image","d130e185":"from keras.models import Model\nfrom keras.layers import GlobalAveragePooling2D, Input, Lambda, AveragePooling1D\nimport keras.backend as K\ninp = Input((256,256,3))\nbackbone = DenseNet121(input_tensor = inp, include_top = False)\nx = backbone.output\nx = GlobalAveragePooling2D()(x)\nx = Lambda(lambda x: K.expand_dims(x,axis = -1))(x)\nx = AveragePooling1D(4)(x)\nout = Lambda(lambda x: x[:,:,0])(x)\n\nm = Model(inp,out)","04187455":"features = {}\nfor b in tqdm_notebook(range(n_batches)):\n    start = b*batch_size\n    end = (b+1)*batch_size\n    batch_pets = pet_ids[start:end]\n    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n    for i,pet_id in enumerate(batch_pets):\n        try:\n            batch_images[i] = load_image(\"..\/input\/train_images\/\", pet_id)\n        except:\n            pass\n    batch_preds = m.predict(batch_images)\n    for i,pet_id in enumerate(batch_pets):\n        features[pet_id] = batch_preds[i]","43f15a0e":"train_feats = pd.DataFrame.from_dict(features, orient='index')","35d37dd1":"train_feats.to_csv('train_img_features.csv')\ntrain_feats.head()","35256939":"test_df = pd.read_csv('..\/input\/test\/test.csv')","a3a9f31c":"pet_ids = test_df['PetID'].values\nn_batches = len(pet_ids) \/\/ batch_size + 1","5a05e66a":"features = {}\nfor b in tqdm_notebook(range(n_batches)):\n    start = b*batch_size\n    end = (b+1)*batch_size\n    batch_pets = pet_ids[start:end]\n    batch_images = np.zeros((len(batch_pets),img_size,img_size,3))\n    for i,pet_id in enumerate(batch_pets):\n        try:\n            batch_images[i] = load_image(\"..\/input\/test_images\/\", pet_id)\n        except:\n            pass\n    batch_preds = m.predict(batch_images)\n    for i,pet_id in enumerate(batch_pets):\n        features[pet_id] = batch_preds[i]","c0b5588b":"test_feats = pd.DataFrame.from_dict(features, orient='index')","993abafa":"test_feats.to_csv('test_img_features.csv')\ntest_feats.head()","f8403cbe":"In this kernel I want to demonstrate how to extract features from the pet images using a pretrained network. Since there are often none or multiple images of different resoltuions and aspect ratio I make the following preprocessing steps:\n\n- Take only profile picture (if existing else black)\n- pad to square aspect ratio\n- resize to 256\n","06ae72b6":"Lets define our model for feature extraction. Normally DenseNet121 would output 1024 features after GlobalAveragePooling. To further narrow it down, I again pool 4 features each.","b095e070":"We save the features as a csv to disk, so others can link and join the data frame with their train.csv","6085de51":"and repeat the procedure again for test images"}}