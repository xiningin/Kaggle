{"cell_type":{"74844680":"code","b5e08254":"code","2653a5aa":"code","d39fa152":"code","d6f9df21":"code","7db7e213":"code","80e3ea24":"code","761294f0":"code","0d562c14":"code","2f4cdc6f":"code","c430e708":"code","790df048":"code","c70eaf8e":"code","8ab3dcaa":"code","9551bb5e":"code","c9b7f268":"code","5daa131f":"code","2221932b":"code","e206d21b":"code","6ab880ef":"code","37ccd356":"code","3a247b1a":"code","f50caf53":"code","5bfb0e69":"code","b91a280e":"code","7a1917eb":"code","36ab6a9e":"code","dc58c615":"code","ca7b850c":"code","ce960b99":"code","476888ed":"code","09de30b0":"code","675ff2bb":"code","c675dea7":"code","4d7ade21":"code","72e11f62":"code","f36109f7":"code","14d10f71":"code","b6277057":"code","0f88a82b":"code","4eaeeb48":"code","c3d47ae8":"code","a1a3d4f1":"code","4398ce66":"code","319e70fd":"code","aa847dcd":"code","4cb44f86":"code","5eee4477":"code","aada0edb":"code","fc9319a6":"code","d0b4845d":"code","ac427b70":"code","5a714024":"code","aad14d3a":"code","ffa92600":"code","6f7faf27":"markdown","eaaa1ab6":"markdown","04674c17":"markdown","861b900a":"markdown","4fdcebc4":"markdown","f24c4266":"markdown","99dfcaea":"markdown","d272b6c8":"markdown","77def1d8":"markdown","fd62fea3":"markdown","4c6d1ef5":"markdown","57fba228":"markdown","decc9a6f":"markdown","f30a5513":"markdown","0c7879ca":"markdown","7a872332":"markdown","402129fd":"markdown","de7b385e":"markdown","09cc5bf4":"markdown","d91d72aa":"markdown","633010c5":"markdown","2ddb76b4":"markdown","25ecc32f":"markdown","83f19895":"markdown","a4788b1d":"markdown","abddc8ee":"markdown"},"source":{"74844680":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b5e08254":"df = pd.read_csv('..\/input\/stock-exchange-data\/indexProcessed.csv',index_col = 1,parse_dates=True)","2653a5aa":"df.info()","d39fa152":"df.describe()","d6f9df21":"df.head()","7db7e213":"df = df.drop('Close',axis='columns')","80e3ea24":"df.Index.unique()","761294f0":"plt.figure(figsize=(10,10))\ndf.Index.value_counts().plot.pie(autopct='%1.1f%%',shadow=True)","0d562c14":"NYA = df.groupby(df.Index).get_group('NYA')","2f4cdc6f":"sns.boxplot(data=NYA)\nplt.xticks(rotation=\"90\")\nplt.show()","c430e708":"NYA.Volume","790df048":"upper_lim = NYA.Volume.mean() +3*NYA.Volume.std()  ## Removing the outliers\nlower_lim = NYA.Volume.mean() -3*NYA.Volume.std()","c70eaf8e":"NYA = NYA[(NYA.Volume > lower_lim) & (NYA.Volume < upper_lim)]","8ab3dcaa":"fig, ax = plt.subplots(figsize=(4, 4))\nax =sns.kdeplot(NYA['CloseUSD'], shade=True, color=\"b\")","9551bb5e":"ax = sns.kdeplot(NYA['Volume'], shade=True, color=\"r\")","c9b7f268":"plt.figure(figsize=(10,10))\nsns.heatmap(NYA.corr(), cmap='YlGnBu', annot = True)","5daa131f":"fig,ax = plt.subplots(figsize = (10,10))\nax.plot(NYA['CloseUSD'])","2221932b":"NYA = NYA.drop(['Index'], axis = 'columns')","e206d21b":"y = NYA['CloseUSD']\nX = NYA.drop('CloseUSD',axis = 'columns')","6ab880ef":"from sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split","37ccd356":"mmc = MinMaxScaler()\nscaled_NYA = mmc.fit_transform(NYA)\nscaled_NYA = pd.DataFrame(scaled_NYA , columns = ['Open','High','Low','Adj Close','Volume','CloseUSD'])","3a247b1a":"scaled_NYA","f50caf53":"train1 = scaled_NYA.iloc[:int(len(NYA)*0.8)]\ntest1 = scaled_NYA.iloc[int(len(NYA)*0.8):]","5bfb0e69":"fig,ax = plt.subplots(figsize=(10,10))\nax.plot(train1.CloseUSD)\nax.plot(test1.CloseUSD)","b91a280e":"X_train1,X_test1,y_train1,y_test1 = train1.drop('CloseUSD',axis='columns'),test1.drop(['CloseUSD'],axis='columns'),train1['CloseUSD'],test1['CloseUSD']","7a1917eb":"from tensorflow import keras ","36ab6a9e":"def build_model(hp):\n    model = keras.Sequential()\n    model.add(keras.layers.Flatten(input_shape=(5, 1)))\n\n    hp_units = hp.Int('units', min_value = 32, max_value = 512, step = 16)\n    model.add(keras.layers.Dense(units = hp_units, activation = 'relu'))\n    model.add(keras.layers.Dense(10))\n\n    hp_learning_rate = hp.Choice('learning_rate', values = [1e-1,1e-2, 1e-3, 1e-4,1e-5]) \n\n    model.compile(optimizer = keras.optimizers.Adam(learning_rate = hp_learning_rate),\n                loss = keras.losses.MeanAbsoluteError(), \n                metrics = ['accuracy'])\n\n    return model","dc58c615":"import keras_tuner as kt\ntuner = kt.Hyperband(build_model,\n                         objective = 'val_loss', \n                         max_epochs = 10,\n                         factor = 3,)\n\ntuner.search(X_train1, y_train1, epochs = 10, validation_data = (X_test1, y_test1))                     ","ca7b850c":"best_hps=tuner.get_best_hyperparameters(num_trials=1)[0]","ce960b99":"model = tuner.hypermodel.build(best_hps)\nmodel.fit(X_train1, y_train1, epochs=50, validation_split=0.2)","476888ed":"predicted = model.predict(X_test1)\ny_test1_np = np.asarray(y_test1)","09de30b0":"predicted.shape","675ff2bb":"mean_predicted = []\nfor i in range(len(predicted)-1):\n    value = predicted[i].mean()\n    mean_predicted.append(value)","c675dea7":"fig,ax = plt.subplots(figsize=(10,10))\nax.plot(mean_predicted,label = 'Predicted Value')\nax.plot(y_test1_np,label = 'Real Value')\nplt.legend(loc=\"upper left\")","4d7ade21":"from statsmodels.tsa.stattools import adfuller\nimport statsmodels.api as sm","72e11f62":"arima_df = NYA['CloseUSD']\narima_df_filt = NYA['CloseUSD'].resample('MS').mean()","f36109f7":"adfuller(arima_df_filt)[1]","14d10f71":"arima_df1 = arima_df_filt.diff(12).dropna()","b6277057":"adfuller(arima_df1)[1]","0f88a82b":"arima_df1.plot()","4eaeeb48":"from statsmodels.graphics.tsaplots import plot_acf,plot_pacf","c3d47ae8":"plot_acf((arima_df1))","a1a3d4f1":"plot_pacf((arima_df1))","4398ce66":"train_arima, test_arima = arima_df1[0:int(len(arima_df1)*0.8)], arima_df1[int(len(arima_df1)*0.8):len(arima_df1)]","319e70fd":"predictions_sarimax = []\nupdating_list_sarimax = [z for z in test_arima]","aa847dcd":"for y in range(len(test_arima)):\n    sarimax_model = sm.tsa.statespace.SARIMAX(updating_list_sarimax,order=(1,1,1),seasonal_order=(1,1,1,12))    \n    model_fit = sarimax_model.fit()\n    preds = model_fit.forecast()\n    pred = list(preds)\n    predictions_sarimax.append(pred)\n    val = test_arima[y]\n    updating_list_sarimax.append(val)","4cb44f86":"fig,ax = plt.subplots(figsize=(10,10))\nax.plot(predictions_sarimax,label = 'Predicted Value')\nax.plot(np.array(test_arima),label = 'Real Value')\nplt.legend(loc=\"upper left\")\nplt.show()","5eee4477":"from sklearn.metrics import mean_absolute_error","aada0edb":"error = mean_absolute_error(test_arima, predictions_sarimax)\nprint('Test error is {}'.format(error))","fc9319a6":"from statsmodels.tsa.arima.model import ARIMA","d0b4845d":"predictions_arima = []\nupdating_list_arima = [z1 for z1 in test_arima]","ac427b70":"for r in range(len(test_arima)):\n    arima_model = ARIMA(updating_list_arima,order=(1,1,1))    \n    model_fit = arima_model.fit()\n    preds = model_fit.forecast()\n    pred = list(preds)\n    predictions_arima.append(pred)\n    val_ = test_arima[r]\n    updating_list_arima.append(val_)","5a714024":"fig,ax = plt.subplots(figsize=(10,10))\nax.plot(predictions_arima,label = 'Predicted Value')\nax.plot(np.array(test_arima),label = 'Real Value')\nplt.legend(loc=\"upper left\")","aad14d3a":"error = mean_absolute_error(test_arima, predictions_arima)\nprint('Test error is {}'.format(error))","ffa92600":"fig,ax = plt.subplots(figsize=(10,10))\nax.plot(predictions_arima,label = 'Predicted ARIMA Value')\nax.plot(np.array(test_arima),label = 'Real Value')\nax.plot(predictions_sarimax,label = 'Predicted SARIMAX Value')\nplt.legend(loc=\"upper left\")","6f7faf27":"<h5>Index - Stock Indexes <\/h5>\n<h5>Open - Opening values of the stock<\/h5>\n<h5>High - Highest value of the stock in a day<\/h5>\n<h5>Low\t- Lowest values of the stock in a day<\/h5>\n<h5>Close - Closing values of the stock (in domestic currency)<\/h5>\n<h5>Adj Close  - Adjusted Closing values of the stock (After a dividend is announced)<\/h5>\n<h5>Volume - Volume of stocks traded<\/h5>\n<h5>CloseUSD - Closing values of the stock in USD<\/h5>","eaaa1ab6":"<h4> Unless p-value is not less than 0.05, we cannot reject the null hypothesis. Therefore we keep differencing until the data is stationary (preferably seasonal difference)","04674c17":"<h3>Fitting the model and forecating the results - <\/h3>","861b900a":"<h4>It is crucial to scale our dataset since, the units of Volume and CloseUSD are evidently different.","4fdcebc4":"<h4>Importing the neccesary libraries<\/h4>","f24c4266":"<h3>Our objective is to load a stock market dataset and observe patterns and seasonality in the data and train the model in order to forecast future prices accurately. Finally, we will compare the model built on neural networks with ARIMA\/SARIMAX models.","99dfcaea":"<h4>Using the Dickey Fuller test to determine if the series is stationary, ","d272b6c8":"<h2>SARIMAX MODEL<\/h2>","77def1d8":"<h4>Since the P-Value is less then 0.05 , we can reject the null hypothesis and say that our series is staionary","fd62fea3":"<h3>Combined plot - <\/h3>","4c6d1ef5":"<h4>Using the best hyperparameters to train the model,","57fba228":"<h4>Loading the dataset<\/h4>","decc9a6f":"<h5>Fitting the model with (p,d,q) = (1,1,1) ","f30a5513":"<h4>There are plenty of outliers in the 'Volume' column. \nWe can get rid of them by log transformation or by simply considering 3 x (standard deviation) data from the mean.","0c7879ca":"ARIMA and SARIMAX perform reasonably well but not in comparison to ANN. However, it is to be noted that ARIMA is an Auto-Regressive Model , these models can forecast without the help of other features (ex - Volume, Open, High). \nAnd thus, these models can be helpful in forecasting future stock prices, weather conditions etc. (data that follows a seasonal trend)","7a872332":"<h3>Fitting the model and forecating the results - <\/h3>","402129fd":"<h2>ARIMA MODEL<\/h2>","de7b385e":"<h4>Values equal to absolute zero exist in the 'Volume' column, therefore log transformation isn't feasible. ","09cc5bf4":"<h3>All features show strong correlation.<\/h3>","d91d72aa":"<h5> Since we have closing values listed in USD, we can drop the 'Close' column <\/h5>","633010c5":"<h5>Since, maximum data is available for NYA,<\/h5>\n<h5>We'll predict closing values for NYA Index<\/h5>","2ddb76b4":"<h4>Since the last layer had 10 neurons, we take the mean of all the outputs, ","25ecc32f":"<h4>Splliting our dataset into training and testing samples,","83f19895":"<h4>Our model has accurately predicted the closing values, given the independent variables<\/h4>\n<h4>However the independent variables are not always available, in such a case we resort to time-series forecasting (works for this example)<\/h4>\n<h4>ARIMA and SARIMAX model are some of the examples, and are used to find patterns in the time-series.<\/h4>","a4788b1d":"<h4> In order to determine the values of the parameters in ARIMA and SARIMAX, we take a look at the autocorrelation and partial autocorrelation plots","abddc8ee":"<h4>Time to build the model, we first define a custom made function (build_model) which will look for the optimum no. of layers and find the best hyperparameters using Hyperband."}}