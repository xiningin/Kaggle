{"cell_type":{"82182f2a":"code","89dfc3ba":"code","eac14331":"code","0e181971":"code","7ad73131":"code","96871de5":"code","5ec7061f":"code","b80d1cfb":"code","6af40117":"code","bca84cd3":"code","03effd84":"code","4d8807a0":"code","ea851bf6":"code","1e14a8c8":"code","2dbc1567":"code","445a4849":"code","09abcb1b":"code","f2bec2ab":"code","e12fe84e":"code","84f1bbf2":"code","25d76553":"code","82e783c0":"code","01c70d37":"code","d5fbb1dc":"code","09f5844c":"code","e97f8722":"code","732db073":"code","763db4c8":"code","3b3dd63c":"code","086f1d21":"code","f3259a69":"code","4cc26fe8":"code","b4801cbb":"code","60472a54":"code","c7de0b50":"code","3459732e":"code","b445a1e3":"code","6c5c31d2":"code","96fc8ba1":"code","cf067179":"code","81bba47a":"code","7e6f644a":"code","862baa9a":"code","139b0ba1":"code","1588632d":"code","7a62ae12":"code","0b15f6d5":"code","a5748284":"code","9dd99ba0":"code","630aca75":"code","a48b6683":"code","66febf4a":"code","8238211e":"code","0982e711":"code","afc4bcda":"code","0f0a31f7":"markdown","0e7cb09a":"markdown","c3267978":"markdown","045c7f7d":"markdown","40c86364":"markdown","c0d7db10":"markdown","a1726c99":"markdown","96da0923":"markdown","544096c2":"markdown","f5b82fe8":"markdown","4e349f0a":"markdown","1b57ed2c":"markdown","575d4dc9":"markdown","c96e9b00":"markdown","cff12f85":"markdown","d57d99e4":"markdown","6532a7c1":"markdown","57793ba9":"markdown","9e3f8a86":"markdown","0faaeeca":"markdown","d5353064":"markdown","464e461e":"markdown","c610c690":"markdown","835d1608":"markdown","71ce0a17":"markdown","4d5b71f4":"markdown","b9cd70e3":"markdown","938a8264":"markdown","fcc7f894":"markdown","d784ce53":"markdown","e4d063d7":"markdown","37727011":"markdown","c30db93d":"markdown","49438373":"markdown","8db9748c":"markdown","c812bf42":"markdown","4c87df00":"markdown","1cc129d4":"markdown","a6ec8b49":"markdown","6c7def82":"markdown","39e4095b":"markdown","0e0b81e9":"markdown","ffe3e986":"markdown","639f5e56":"markdown","749ca45a":"markdown","5540d5d6":"markdown","5588470b":"markdown"},"source":{"82182f2a":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\nimport re\nfrom collections import Counter\nfrom statistics import mode\nfrom sklearn.model_selection import KFold\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.ensemble import GradientBoostingRegressor\n\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","89dfc3ba":"# Reading data\ntrain = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\n\n# Storing Passenger Id for submission\nId = test.PassengerId","eac14331":"train.head()","0e181971":"test.head()","7ad73131":"train.shape","96871de5":"test.shape","5ec7061f":"train.dtypes","b80d1cfb":"train.hist(figsize=(14,14), color='maroon', bins=20)\nplt.show()","6af40117":"fig = plt.figure(figsize=(10,10))\nsns.countplot(train['Survived'], data=train)","bca84cd3":"fig = plt.figure(figsize=(10,10))\n\nsns.barplot(x=\"Sex\", y=\"Survived\", data=train)\n\n#print percentages of females vs. males that survive\nprint(\"Percentage of females who survived:\", train[\"Survived\"][train[\"Sex\"] == 'female'].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of males who survived:\", train[\"Survived\"][train[\"Sex\"] == 'male'].value_counts(normalize = True)[1]*100)","03effd84":"fig = plt.figure(figsize=(10,10))\n\n\n#draw a bar plot of survival by Pclass\nsns.barplot(x=\"Pclass\", y=\"Survived\", data=train)\n\n#print percentage of people by Pclass that survived\nprint(\"Percentage of Pclass = 1 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 2 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 2].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of Pclass = 3 who survived:\", train[\"Survived\"][train[\"Pclass\"] == 3].value_counts(normalize = True)[1]*100)","4d8807a0":"fig = plt.figure(figsize=(10,10))\n\n\n#draw a bar plot for SibSp vs. survival\nsns.barplot(x=\"SibSp\", y=\"Survived\", data=train)\n\n#I won't be printing individual percent values for all of these.\nprint(\"Percentage of SibSp = 0 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 0].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 1 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 1].value_counts(normalize = True)[1]*100)\n\nprint(\"Percentage of SibSp = 2 who survived:\", train[\"Survived\"][train[\"SibSp\"] == 2].value_counts(normalize = True)[1]*100)","ea851bf6":"fig = plt.figure(figsize=(10,10))\n\n\nsns.barplot(x=\"Parch\", y=\"Survived\", data=train)\nplt.show()","1e14a8c8":"dataset = pd.concat([train, test], sort=False, ignore_index=True)","2dbc1567":"dataset.isnull().mean().sort_values(ascending=False)","445a4849":"# Checking correlations with Heatmap\n\nfig, axs = plt.subplots(nrows=1, figsize=(13, 13))\nsns.heatmap(dataset.corr(), annot=True, square=True, cmap='YlGnBu', linewidths=2, linecolor='black', annot_kws={'size':12})","09abcb1b":"dataset['Fare'].fillna(dataset['Fare'].mean(), inplace=True)\n","f2bec2ab":"dataset['Embarked'] = dataset['Embarked'].fillna('S')","e12fe84e":"dataset.head()","84f1bbf2":"dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand = False)\ndataset['Title'].unique().tolist()","25d76553":"# This shows the percentage of occurrences for each title. 'Mr' occurs the most often.\n\ndataset['Title'].value_counts(normalize=True)*100","82e783c0":"dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\ndataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')\n    \ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\n\ndataset['Title'] = dataset['Title'].map(title_mapping)\n\n# Imputing missing values with 0\ndataset['Title'] = dataset['Title'].fillna(0)","01c70d37":"dataset.head()","d5fbb1dc":"# Filling the missing values in Age with the medians of Sex and Pclass groups\ndataset['Age'].fillna(dataset['Age'].mean(), inplace=True)","09f5844c":"dataset.drop(['Ticket'], axis=1, inplace=True)","e97f8722":"dataset.drop(['Name'], axis=1, inplace=True)","732db073":"dataset.drop(['Cabin'], axis=1, inplace=True)","763db4c8":"dataset['SibSp'].corr(dataset['Parch'])","3b3dd63c":"dataset['Parch'].corr(dataset['SibSp'])","086f1d21":"g  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=dataset, size = 8)\ng = g.set_ylabels(\"Survival Percentage\")","f3259a69":"g  = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=dataset, size = 8)\ng = g.set_ylabels(\"Survival Percentage\")","4cc26fe8":"# Family Size = # of Siblings + # of Parents + You\ndataset['FamSize'] = dataset['SibSp'] + dataset['Parch'] + 1","b4801cbb":"g  = sns.factorplot(x=\"FamSize\",y=\"Survived\",data=dataset, size = 8)\ng = g.set_ylabels(\"Survival Percentage\")","60472a54":"dataset.isnull().sum()","c7de0b50":"dataset.head()","3459732e":"label = LabelEncoder()","b445a1e3":"for col in ['Sex', 'Embarked']:\n    dataset[col] = label.fit_transform(dataset[col])","6c5c31d2":"dataset.head()","96fc8ba1":"# Splitting dataset into train\ntrain = dataset[:len(train)]\n\n# Splitting dataset into test\ntest = dataset[len(train):]\n\n# Drop labels 'Survived' because there shouldn't be a Survived column in the test data\ntest.drop(labels=['Survived'], axis=1, inplace=True)","cf067179":"train.head()","81bba47a":"test.head()","7e6f644a":"train.head()","862baa9a":"train['Survived'] = train['Survived'].astype(int)","139b0ba1":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB \nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\ny=train.Survived\nX=train.drop('Survived', axis=1)\n","1588632d":"cross_val_score(LogisticRegression(), X, y).mean()","7a62ae12":"cross_val_score(SVC(), X, y).mean()","0b15f6d5":"cross_val_score(RandomForestClassifier(), X, y).mean()","a5748284":"cross_val_score(GaussianNB(), X, y).mean()","9dd99ba0":"cross_val_score(DecisionTreeClassifier(), X, y).mean()","630aca75":"cross_val_score(GradientBoostingClassifier(), X, y).mean()","a48b6683":"# Using train_test_split we split the data into train and validation data for testing\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.2, random_state = 2)","66febf4a":"# Our final model\nfinal_model = RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n                       criterion='gini', max_depth=12, max_features='auto',\n                       max_leaf_nodes=None, max_samples=None,\n                       min_impurity_decrease=0.0, min_impurity_split=None,\n                       min_samples_leaf=1, min_samples_split=5,\n                       min_weight_fraction_leaf=0.0, n_estimators=200,\n                       n_jobs=None, oob_score=False, random_state=None,\n                       verbose=0, warm_start=False)\n\n\n\n# Train final_model with train data\nfinal_model.fit(X_train, y_train)\n\n# Predict final_model\npredictions = final_model.predict(X_val)\n\n# Print out score\nprint('Accuracy: ', accuracy_score(predictions, y_val))","8238211e":"test.head()","0982e711":"final_predictions = final_model.predict(test)\n\noutput = pd.DataFrame({'PassengerId': Id, 'Survived':final_predictions})\noutput.to_csv('submission.csv', index=False)","afc4bcda":"output.head()","0f0a31f7":"<font size=\"+3.7\" color=\"darkblue\"><b><center>\ud83d\udea2 Titanic Predictions: Survived or Deceased?<\/center><\/b><\/font><br>\n<font color='blue' size='+2'><b><center>June 2020<\/center><\/b><\/font>\n\n<hr>","0e7cb09a":"### 3.1 Sex Visualization","c3267978":"- According to their factorplots, they are both relatively weak features alone\n- They are highly correlated to each other so we decide to combine them for a feature representing Family Size","045c7f7d":"We now use GradientBoostingClassifier for training and predictions","40c86364":"- Split dataset back into train and test variables.","c0d7db10":"### 4.3 Title Feature","a1726c99":"<font color='blue' size='+2'><b>The End! If you found this helpful please upvote! Also if you have any suggestions or questions leave them down below!","96da0923":"### 4.8 Cabin Feature","544096c2":"- There isn't a clear correlation but in general people with more siblings\/spouses were less likely survive. Also people with no siblings\/spouses were less likely to survive than people with one or two siblings\/spouses.","f5b82fe8":"<font size=\"+3\" color=\"green\"><b>6 - Submission<\/b><\/font><br><a id=\"6\"><\/a>","4e349f0a":"We fill in Embarked feature's missing value with the mode which is the value 'S'","1b57ed2c":"- We are basically creating a new column 'Title' and extracting the Title from the 'Name' column","575d4dc9":"<font size=\"+3\" color=\"green\"><b>2 - Read Data <\/b><\/font><br><a id=\"2\"><\/a>","c96e9b00":"### 3.4 Parch Visualization","cff12f85":"### 4.7 Name Feature","d57d99e4":"At the start of every notebook you must import necessary libraries in order to simply do Data Science.","6532a7c1":"In this section we view each feature's survival rate using barplots and factorplots. Using the visualizations we make assumptions and find correlations between different features.","57793ba9":"In this section we read in the data and check the data we are working with. As we check the data we can clearly see the data's dimensions and it's features.","9e3f8a86":"We can see that overall most passengers didn't survive","0faaeeca":"- Columns 'SibSp' and 'Parch' are very similar to each other in meaning and in correlation. ","d5353064":"<font size=\"+3\" color=\"green\"><b>1 - Import Libraries<\/b><\/font><br><a id=\"1\"><\/a>","464e461e":"We find correlations between features and impute missing values using the correlations. For categorical features we map the feature so it becomes a numerical feature. Using Feature Engineering we are able to create new features 'Title' and 'FamSize' which will overall improve our model performance.","c610c690":"- Too many missing values, will drop this feature","835d1608":"- Females have a much higher chance of Survival than men","71ce0a17":"- Again, no clear correlation but people with no parents were less likely to survive than those with 1-3 parents\/children.","4d5b71f4":"<font size=\"+3\" color=\"green\"><b>4 - Data Preparation<\/b><\/font><br><a id=\"4\"><\/a>","b9cd70e3":"- 'Sex' is a categorical feature, therefore we will Label-Encode it later on","938a8264":"### 4.2 Embarked Feature","fcc7f894":"### 4.6 Sex Feature","d784ce53":"- We are planning to impute missing values in the column 'Age'. 'Pclass' and 'Sex' are correlated to 'Age', so we group them with 'Age' to find the median.\n- We then categorize age because there is a correlation between age and survival. \n\nCredit: https:\/\/www.kaggle.com\/vincentdion\/reach-0-80-as-a-noob","e4d063d7":"### 3.3 SibSp Visualization","37727011":"- 'Ticket' is a pretty useless feature so we decide to drop it","c30db93d":"<font size=\"+3\" color=\"green\"><b>5 - Modeling<\/b><\/font><br><a id=\"5\"><\/a>","49438373":"Observations for Imputing Missing Values:\n- Cabin is missing 77.4%  of its values. We will remove this column\n- Age is missing about 20% of its values. These are imputable therefore we probably will keep this column.\n- Embarked and Fare are missing less than 1% of their values. We are definitely keeping these columns.","8db9748c":"- Some of the titles above are quite unfamiliar, so we decide to replace these titles with more familiar titles which organizes our categories. After replacing these titles we only end up with 5 distinct titles.","c812bf42":"- We see that Survived is a 'float' type, so we must change it to an 'int' type.","4c87df00":"### 4.5 Ticket Feature","1cc129d4":"Submission to the contest","a6ec8b49":"Lets view each feature with histograms","6c7def82":"<hr>\n<img src='https:\/\/i.pinimg.com\/originals\/c6\/f4\/c2\/c6f4c2c3e2d8c69a444fa3d9cb41a87b.jpg' style='height: 400px'>\n<hr>\n\n\n# Table of Contents:\n* Step 1 - Import Libraries\n    * We need to import the necessary libraries for many things\n    * For Ex: In order to use a prewritten algorithm then we must import a library.\n* Step 2 - Read Data \n    * Read in the train and test data \n    * Check data\n* Step 3 - Data Visualization\n    * Graph and visualize each column to see if there is a clear correlation or similarities\n* Step 4 - Data Preparation \n    * For the columns with missing values impute them\n    * Create new features 'Title' and 'FamSize'\n    * Drop certain features which are useless or have too many missing values\n* Step 5 - Modelling\n    * Select features to keep\n    * Split dataset back into train and test\n    * Use GradientBoostingClassifier for our model\n    * Use \"accuracy_score\" to print out score \n* Step 6 - Submission \n    * Submit to Competition","39e4095b":"- People who had a better class were more likely to Survive","0e0b81e9":"### 4.1 Fare Feature","ffe3e986":"### 4.4 Age Feature","639f5e56":"- We already used the 'Name' feature for making the 'Title' column, so we do not need it anymore.","749ca45a":"### 3.2 Pclass Visualization","5540d5d6":"<font size=\"+3\" color=\"green\"><b>3 - Data Visualization<\/b><\/font><br><a id=\"3\"><\/a>","5588470b":"### 4.9 Family Size Feature (Created)"}}