{"cell_type":{"59d3bde3":"code","f557112d":"code","deecc703":"code","bfe1c53a":"code","94c231ed":"code","3aaafbf2":"code","8b065f54":"code","5a661c3b":"code","c68ff24d":"code","3e5b69da":"code","102baaa1":"code","6df1ad3c":"code","98193f41":"markdown","7009084b":"markdown","7eef87a8":"markdown","2799111a":"markdown","967ac269":"markdown","f58b1e0b":"markdown"},"source":{"59d3bde3":"import tensorflow as tf\nimport tensorflow.keras as keras\nimport numpy as np\nimport pandas as pd\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.layers import Input, Dropout, Dense, Activation, Flatten, Conv2D, AveragePooling2D, MaxPooling2D\nfrom tensorflow.keras.models import Model, load_model, Sequential\nfrom tensorflow.keras.utils import to_categorical\nimport matplotlib.pyplot as plt","f557112d":"X_train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nX_test  = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\n\ny_train = X_train['label']\nX_train = X_train.drop('label', axis = 1)\n","deecc703":"final_Xtrain = []\nfinal_Xtest  = []\n\nfor i in range(len(X_train)):\n    final_Xtrain.append(X_train.iloc[i].values.reshape(28,28))\n\nfor j in range(len(X_test)):\n    final_Xtest.append(X_test.iloc[j].values.reshape(28,28))","bfe1c53a":"final_Xtrain = np.array(final_Xtrain)\nfinal_Xtest  = np.array(final_Xtest)\n\nfinal_Xtrain = final_Xtrain.reshape(final_Xtrain.shape[0], 28, 28, 1)\nfinal_Xtest  = final_Xtest.reshape(final_Xtest.shape[0], 28, 28, 1)","94c231ed":"final_Xtrain = final_Xtrain \/ 255\nfinal_Xtest  = final_Xtest  \/ 255\n\ny_train = y_train \/ 255\nfinal_ytrain = to_categorical(y_train.values, 10)","3aaafbf2":"model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), activation='relu', input_shape=(28,28,1))) \nmodel.add(Conv2D(32, (3, 3), activation='relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation='softmax'))","8b065f54":"training_loss = []\nnum_of_epochs = 10 \nbatch_size = 30\n\n#model = Net(input_shape=(28, 28,1))\nopt = keras.optimizers.Adam()\nloss_function = keras.losses.CategoricalCrossentropy()\nmodel.compile(optimizer=opt, loss=loss_function, metrics=['accuracy'])\n\n#model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath = 'model.h5', save_weights_only= True,monitor='training_loss',mode='min',save_best_only=True)\n\nhistory = model.fit(final_Xtrain, final_ytrain, epochs = num_of_epochs, batch_size = batch_size, verbose = 1)\n\ntraining_loss = history.history['loss']\n","5a661c3b":"plt.plot(history.history['loss'])\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.title('Training Loss')\nplt.show()\nplt.close()\n","c68ff24d":"prediction = model.predict(final_Xtest)\npredictions = []\n\nfor i in range(len(prediction)):\n    predictions.append(np.argmax(prediction[i,:]))","3e5b69da":"final_predictions = pd.DataFrame(predictions, columns = ['Label'])\nfinal_predictions = final_predictions.reset_index()\nfinal_predictions.columns = ['ImageId','Label']\nfinal_predictions['ImageId'] = final_predictions['ImageId'].apply(lambda x:x+1)","102baaa1":"final_predictions","6df1ad3c":"final_predictions.to_csv('..\/Predictions.csv', index = False)","98193f41":"# Model","7009084b":"# Data Normalizing","7eef87a8":"# Data Reshaping","2799111a":"# Training","967ac269":"# Data Reading","f58b1e0b":"# Predictions"}}