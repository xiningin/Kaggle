{"cell_type":{"cfb9a472":"code","142d7ac9":"code","16cdf6b8":"code","a2c337c5":"code","6d3ef76c":"code","aff125fe":"code","19a7f04b":"code","7b1adcb9":"code","261f29d0":"code","246b6be1":"code","f5481060":"code","70779dfb":"code","cfa7426e":"markdown","946871bc":"markdown","cc35b473":"markdown","dca353c7":"markdown","f123acbe":"markdown","6288f551":"markdown","be225a4b":"markdown","c2a80154":"markdown","c7a73775":"markdown","73141362":"markdown"},"source":{"cfb9a472":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","142d7ac9":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics.pairwise import pairwise_distances\n\ndataset = pd.read_csv('\/kaggle\/input\/caravan-insurance-challenge\/caravan-insurance-challenge.csv')","16cdf6b8":"#Correlation\ncorr = dataset.corr()\ncmap=sns.diverging_palette(5, 250, as_cmap=True)\n\ndef magnify():\n    return [dict(selector=\"th\",\n                 props=[(\"font-size\", \"7pt\")]),\n            dict(selector=\"td\",\n                 props=[('padding', \"0em 0em\")]),\n            dict(selector=\"th:hover\",\n                 props=[(\"font-size\", \"12pt\")]),\n            dict(selector=\"tr:hover td:hover\",\n                 props=[('max-width', '200px'),\n                        ('font-size', '12pt')])\n]\n\ncorr.style.background_gradient(cmap, axis=1)    .set_properties(**{'max-width': '80px', 'font-size': '10pt'})    .set_caption(\"Hover to magify\")    .set_precision(2)    .set_table_styles(magnify())","a2c337c5":"#$MOSHOOFD\/MOSTYPE, $MFWEKIND\/MGEMOMV, $MRELOV\/ MFALLEEN, MGODGE\/ $MGODPR, $MRELOV\/MRELGE, MOPLLAAG\/$MOPLMIDD, $MOPLHOOG\/MSKA, $MAUT0\/MAUT1, \n\n#PWAPART,PWABEDR,PWALAND,PPERSAUT,PBESAUT,PMOTSCO,PVRAAUT,PAANHANG,PTRACTOR,PWERKT,PBROM,PLEVEN,PPERSONG,PGEZONG,PWAOREG,PBRAND,PZEILPL,PPLEZIER,PFIETS,PINBOED,PBYSTAND\n\ndataset1 = dataset.drop(['MOSHOOFD','MFWEKIND','MRELOV','MGODPR','MRELOV','MOPLMIDD','MOPLHOOG','MAUT0','PWAPART','PWABEDR','PWALAND','PPERSAUT','PBESAUT','PMOTSCO','PVRAAUT','PAANHANG','PTRACTOR','PWERKT','PBROM','PLEVEN','PPERSONG','PGEZONG','PWAOREG','PBRAND','PZEILPL','PPLEZIER','PFIETS','PINBOED','PBYSTAND'],axis=1)\n","6d3ef76c":"#Histograms\ndataset1.hist(figsize=(16,12));","aff125fe":"# ABESAUT, AGEZONG, AINBOED, APERSONG, APLEZIER, AVRAAUT, AWAOREG, AWERKT, AZEILPL\ndataset2 = dataset1.drop(['ABESAUT', 'AGEZONG', 'AINBOED', 'APERSONG', 'APLEZIER', 'AVRAAUT', 'AWAOREG', 'AWERKT', 'AZEILPL'],axis=1)\ndataset2.head()","19a7f04b":"#This column states which rows should be used for training and testing. But, We don't need this column as our ploblem is unsupervised.\ndataset2.drop('ORIGIN',axis=1,inplace=True)","7b1adcb9":"df = pd.get_dummies(data=dataset2, columns=['MOSTYPE'])\ndf.head()","261f29d0":"user_similarity = pairwise_distances(df, metric='cosine')\nuser_similarity.shape","246b6be1":"#List of Policies, which we can recommend.\npoliciescolumnlist = ['AWAPART', 'AWABEDR', 'AWALAND', 'APERSAUT', 'AMOTSCO','AAANHANG', 'ATRACTOR','ABROM', 'ALEVEN','ABRAND','AFIETS', 'ABYSTAND', 'CARAVAN']\n","f5481060":"user_index=0\n\n#extracting the list of policies which current user doesn't have\navailablecollist=[]\nfor item in policiescolumnlist:\n    if df.loc[user_index,item]==0:\n        availablecollist.append(item)","70779dfb":"no_of_policies=3 #you can set this variable value as min number of policies you want to recommend.\noutput=dict()\ni=1\nwhile i < 20:\n    opdf=df.iloc[user_similarity[user_index].argsort()[(i-1)*10:i*10], 35:48] #list of indexes of row\n    tempoutput=dict(opdf[availablecollist].sum().sort_values()[opdf[availablecollist].sum().sort_values()>0])\n    output.update(tempoutput)\n    if len(output)>=no_of_policies:\n        break\n    i+=1\n    if i>50:\n        print(\"There are no products, as per top 200 similar people\")\n        break\noutput","cfa7426e":"### Using Cosine Similarity to find similar kind of users.","946871bc":"### Removing features which are highly correlated. Here,threshold is 0.70","cc35b473":"# Methodology :\n### Here,we are going to find top 10 similar users and will recommend product. accordingly.\n### We have fixed minimum number of policy 3. So if it doesn't get min 3 policy from top 10 similar users, Then it will go for next 10 similar users.\n### This code will check upto 200 similar user to get min no of products for recommendation.\n### But If it still does not able to find any product, then it will give msg \"There are no products, as per top 200 similar people\".","dca353c7":"### Plotting correlation graph to understand collinearity among features.","f123acbe":"# Result :\n### Above 4 are the recommended products for user with index 0. And number mentioned in front of them can be taken as weightage for each product. \n### For e.g :- There are more chances that user will purchase 'AWAPART' product than other products.","6288f551":"### Importing Libraries and reading dataset","be225a4b":"This data set used in the CoIL 2000 Challenge contains information on customers of an insurance company. The data consists of 86 variables and includes product usage data and socio-demographic data derived from zip area codes. The data was collected to answer the following question: Can you predict who would be interested in buying a caravan insurance policy and give an explanation why?\n![download%20%281%29.jfif](attachment:download%20%281%29.jfif)\n\nIn this kernel, i have not explained data. But you can explore data here, https:\/\/www.kaggle.com\/uciml\/caravan-insurance-challenge\/Data\n\n### On the other hand, In this kernel, i have tried to make a recommendation system by using same dataset.So, this system would answer: what are the other products which can be recommended to existing customer ? \n![recommend.png](attachment:recommend.png)","c2a80154":"### Taking example of user having index 0.","c7a73775":"### Plotting histogram to know more about distribution of each feature","73141362":"### Removing Features with Single class. Because they dont have much impact on result."}}