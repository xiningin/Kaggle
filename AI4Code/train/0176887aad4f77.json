{"cell_type":{"d27e05b4":"code","787e5eb2":"code","733e8fdc":"code","8eff006c":"code","2a4580e5":"code","2b4d9e71":"code","8af9a458":"code","5cbef7e7":"code","031e997e":"code","de4b3457":"code","c2a318b6":"code","def815ab":"code","8ab62ce0":"code","a12b5455":"code","3c387757":"code","c6980f1f":"code","66d3664a":"code","bd8720de":"code","7314d585":"code","ab1a2f98":"code","5a6b11fc":"code","46c9b9c4":"code","ceb1a1c5":"code","e88fc7d6":"code","dd913694":"code","bf132438":"code","88567ceb":"code","75947f60":"code","1f2137ef":"code","7060f9fa":"code","28807193":"code","60619a1b":"code","1cf949a4":"code","52672c6d":"code","7dc51398":"code","db37ce2f":"code","40c8567d":"code","4504089e":"code","c83f6ae5":"code","755c0f62":"code","f3fdfe2f":"code","eec7a685":"code","8daf98e4":"code","e2cdc773":"code","8fda98a3":"code","ed2b691c":"code","577d9680":"code","80321a84":"code","1cacc5db":"markdown","6cc7d189":"markdown","8799bf09":"markdown","f5a5d37b":"markdown","85bfab13":"markdown","a92aee71":"markdown","05348996":"markdown","ee56ef89":"markdown","0eb8ab3e":"markdown","3c1961e6":"markdown","b128e14e":"markdown","2aed476d":"markdown","0257c4d6":"markdown","e2c3a519":"markdown","ef6862f9":"markdown","7c71febe":"markdown","0af80091":"markdown","f2356836":"markdown","7dd86cb0":"markdown","f6a5e00c":"markdown","79e5ce80":"markdown","64496a94":"markdown","42e8996b":"markdown","da61fb6a":"markdown","d2e0bb0a":"markdown","a6ec54ef":"markdown","5d1f7ac7":"markdown","085fe54e":"markdown","160b5176":"markdown","b39bff2f":"markdown","c3a54f71":"markdown","20b16874":"markdown","ff28af00":"markdown"},"source":{"d27e05b4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #for making statistical graphics\nimport matplotlib.pyplot as plt #for ploting graphs\nplt.rcParams.update({'font.size': 14})\n\nimport re\n\nimport plotly.express as px #for ploting graphs\nimport plotly.graph_objects as go #for ploting graphs\nfrom plotly.subplots import make_subplots #for ploting graphs\nimport seaborn as sns\nimport plotly as py\n\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\n\nimport plotly.io as pio\nfrom IPython.display import Image \n\nimport warnings # for ignoring warnings \nwarnings.filterwarnings(\"ignore\")\n\n\n\nimport os\n\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","787e5eb2":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","733e8fdc":"districts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv\")\nproducts_info = pd.read_csv(\"..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv\")\nengagement_sample = pd.read_csv(\"\/kaggle\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data\/5970.csv\")","8eff006c":"\ndistricts_info.head()","2a4580e5":"districts_info.info()","2b4d9e71":"\nproducts_info.head()","8af9a458":"products_info.info()","5cbef7e7":"engagement_sample.head()","031e997e":"engagement_sample.info()","de4b3457":"# how many missing values exist or better still what is the % of missing values in the dataset?\ndef percent_missing(df,name:str):\n    '''df: the dataframe you want to calculate the missing values \n    name: the name of your dataframe '''\n\n    # Calculate total number of cells in dataframe\n    totalCells = np.product(df.shape)\n\n    # Count number of missing values per column\n    missingCount = df.isnull().sum()\n\n    # Calculate total number of missing values\n    totalMissing = missingCount.sum()\n\n    # Calculate percentage of missing values\n    print(name+' has', round(((totalMissing\/totalCells) * 100), 2), \"%\", \"missing values.\")","c2a318b6":"percent_missing( districts_info, 'districts_info')","def815ab":"districts_info.isna().sum()","8ab62ce0":"districts_info = districts_info[districts_info.state.notna()].reset_index(drop=True)\ndistricts_info.shape #shape of new dataframe with all states with NAN removed ","a12b5455":"PATH = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \n\ntemp = []\n\nfor district in districts_info.district_id.unique():\n    df = pd.read_csv(f'{PATH}\/{district}.csv', index_col=None, header=0)\n    df[\"district_id\"] = district\n    temp.append(df)\n    \n    \nengagement = pd.concat(temp)\nengagement = engagement.reset_index(drop=True)","3c387757":"engagement.head()","c6980f1f":"a = engagement.loc[(engagement['engagement_index'].isna()) ]# create a new dataframe with only nan values \nprint('unique values in pct_access column are' ,a['pct_access'].unique()) # finding if they are other values in pct_access which might cause nan values in engagement_index \na.head()","66d3664a":"engagement['engagement_index'] = engagement['engagement_index'].fillna(0)\nengagement.head()","bd8720de":"percent_missing( engagement, 'engagement dataframe ')\nengagement.isna().sum()","7314d585":"engagement = engagement[engagement.lp_id.notnull()] #droping rowa with  lp_id missing values \nengagement['pct_access'] = engagement['pct_access'].fillna(0) #replace pct_access NAN with 0\npercent_missing( engagement, 'engagement dataframe ') #calculating the % of remaining missing values in our dataframe\n","ab1a2f98":"engagement.time = engagement.time.astype('datetime64[ns]')","5a6b11fc":"products_info['primary_function_main'] = products_info['Primary Essential Function'].apply(lambda x: x.split(' - ')[0] if x == x else x)\nproducts_info['primary_function_sub'] = products_info['Primary Essential Function'].apply(lambda x: x.split(' - ')[1] if x == x else x)\n\n# Synchronize similar values\nproducts_info['primary_function_sub'] = products_info['primary_function_sub'].replace({'Sites, Resources & References' : 'Sites, Resources & Reference'})\nproducts_info.drop(\"Primary Essential Function\", axis=1, inplace=True)\nproducts_info.head()","46c9b9c4":"state_abb = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n\ndistricts_info['state_abb'] = districts_info['state'].map(state_abb)\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"distribution of districts in the available States\",\n    title_font = dict(\n            family = \"monospace\",\n            size = 25,\n            color = \"black\"\n            ),\n    geo_scope = 'usa'\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations = districts_info['state_abb'].value_counts().to_frame().reset_index()['index'],\n        zmax = 1,\n        z = districts_info['state_abb'].value_counts().to_frame().reset_index()['state_abb'],\n        locationmode = 'USA-states',\n        marker_line_color = 'white',\n        geo = 'geo',\n        colorscale = \"cividis\", \n    )\n)\n         \nfig.update_layout(layout)   \nfig.show()","ceb1a1c5":"def plot_bar(df,column:str,title:str,y_label:str,x_label:str):\n    fig = px.bar(df[column].value_counts().reset_index(), x = 'index', y = column,\n            text= df[column].value_counts().to_frame().reset_index()[column],\n            labels={column:y_label,'index':x_label},\n            title=title)\n    fig.update_traces(marker_color='#8CC0FF')\n    fig.show()\n    \ndef plot_count(df,column:str,hue:str,title:str):\n    plt.figure(figsize=(16,9))\n    plt.xticks(rotation=90)\n\n    sns.countplot(data=df, x=column, hue = hue).set(title= title)","e88fc7d6":" plot_bar(districts_info,'state','Number of Districts in the Available States','number of districts','states')","dd913694":"plot_count(districts_info,'state',\"locale\",'distribution of area in available states')","bf132438":" plot_bar(districts_info,'locale','Number of Districts in Each Type of Area','number of districts','Area')","88567ceb":"plot_count(districts_info,'locale',\"pct_black\/hispanic\",'distribution ofpct_black\/hispanic in available Area')","75947f60":"plot_count(districts_info,'locale',\"pct_free\/reduced\",'distribution pct_free\/reduced in available Area')","1f2137ef":"plot_count(districts_info,'locale',\"county_connections_ratio\",'distribution county_connections_ratio in available Area')","7060f9fa":"plot_count(districts_info,'locale',\"pp_total_raw\",'distribution pp_total_raw in available Area')","28807193":"print('we have {} proucts used for studies, let us see the 20 most used in this project '.format(products_info['Product Name'].nunique()))\n","60619a1b":"engagement.rename(columns={\"lp_id\": \"LP ID\"}, inplace=True)\nmerged=pd.merge(engagement, products_info, on= \"LP ID\")\nmerged = pd.merge(merged, districts_info, on = 'district_id')\n# merged.to_csv('submission.csv')\n","1cf949a4":"merged.head()","52672c6d":"a=merged.groupby(\"Product Name\")[\"pct_access\"].mean().sort_values(ascending=False).head(20)\nb=merged.groupby(\"Product Name\")[\"engagement_index\"].sum().sort_values(ascending=False).head(20)\n\n# plot\nplt.figure(figsize=(15,4))\n\nplt.subplot(121)\nplt.bar(a.index, a.values, color=[\"#6930c3\",\"#5e60ce\",\"#0096c7\",\"#48cae4\",\"#ade8f4\",\"#ff7f51\",\"#ff9b54\",\"#ffbf69\"])\nplt.xlabel('Product Name')\nplt.xticks(rotation=90)\nplt.ylabel('Mean percentage of students')\nplt.title(\"top 20 used products per pct_access\")\n\nplt.subplot(122)\nplt.bar(b.index, b.values, color=[\"#4f000b\",\"#720026\",\"#ce4257\",\"#ff7f51\",\"#ff9b54\"])\nplt.xlabel('Product Name')\nplt.xticks(rotation=90)\nplt.ylabel('Page-load per 1000 students')\nplt.title(\"top 20 used products perengagement_index\")","7dc51398":"c=merged.groupby(\"Provider\/Company Name\")[\"pct_access\"].mean().sort_values(ascending=False).head(20)\nd=merged.groupby(\"Provider\/Company Name\")[\"engagement_index\"].sum().sort_values(ascending=False).head(20)\n\n# plot\nplt.figure(figsize=(15,4))\n\nplt.subplot(121)\nplt.bar(a.index, a.values, color=[\"#6930c3\",\"#5e60ce\",\"#0096c7\",\"#48cae4\",\"#ade8f4\",\"#ff7f51\",\"#ff9b54\",\"#ffbf69\"])\nplt.xlabel('Product provider')\nplt.xticks(rotation=90)\nplt.ylabel('Mean percentage of students')\nplt.title(\"top 20 product providers per pct_access\")\n\nplt.subplot(122)\nplt.bar(b.index, b.values, color=[\"#4f000b\",\"#720026\",\"#ce4257\",\"#ff7f51\",\"#ff9b54\"])\nplt.xlabel('Product provider')\nplt.xticks(rotation=90)\nplt.ylabel('Page-load per 1000 students')\nplt.title(\"top 20 product providers per engagement_index\")","db37ce2f":"fig = px.pie(merged.query(\"primary_function_main != 'x'\")['primary_function_main'].value_counts().\n             reset_index().rename(columns = {'primary_function_main': 'count'}), \n             values = 'count', names = 'index', width = 700, height = 700,\n            title=\"Count of Products by primary_function_main\")\nfig.show()\n","40c8567d":"fig = px.pie(merged.query(\"primary_function_sub != 'x'\")['primary_function_sub'].value_counts().\n             reset_index().rename(columns = {'primary_function_sub': 'count'}), \n             values = 'count', names = 'index', width = 700, height = 700,\n            title=\"Count of Products by primary_function_sub\")\nfig.show()\n","4504089e":"plot_bar(products_info,'Sector(s)','Number of products available to each sector','number of products','Sector(s)')","c83f6ae5":"#CODES HAVE BEEN TAKEN FROM :https:\/\/www.kaggle.com\/fumbanibanda\/eda-covid19\nst_ac\u0441ess = merged.groupby(['state', 'time']).agg({'pct_access': 'mean'}).reset_index()\nst_eng = merged.groupby(['state', 'time']).agg({'engagement_index': 'mean'}).reset_index()\nloc_ac\u0441ess = merged.groupby(['locale', 'time']).agg({'pct_access': 'mean'}).reset_index()\nloc_eng = merged.groupby(['locale', 'time']).agg({'engagement_index': 'mean'}).reset_index()\ncat_ac\u0441ess = merged.groupby(['primary_function_main', 'time']).agg({'pct_access': 'mean'}).reset_index()\ncat_eng = merged.groupby(['primary_function_main', 'time']).agg({'engagement_index': 'mean'}).reset_index()\ncat_eng.to_csv('submission.csv')\nfor i in [st_ac\u0441ess, st_eng, loc_ac\u0441ess, loc_eng, cat_ac\u0441ess, cat_eng]:\n    i['day_of_week'] = i['time'].dt.dayofweek\n    \nloc_ac\u0441ess.head(3)","755c0f62":"#This code has bee taken from:\n#https:\/\/www.kaggle.com\/dmitryuarov\/eda-covid-19-impact-on-digital-learning\/notebook\nfig = px.line(st_ac\u0441ess, x=\"time\", y=\"pct_access\", color=\"state\", line_group=\"state\")\n\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of pct_access of all products by states', \n                  title_font_size = 20, title_x = 0.5)\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', linewidth = 2,tickfont_size = 12)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', \n                 showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                 linewidth = 2,tickfont_size = 12)\n\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color=\"red\")\n\nfig.add_annotation(\n        x='2020-03-11',\n        y=2.7,\n        text=\"WHO has declared Covid-19 as pandemic\",\n        showarrow=True,\n        font=dict(\n            family=\"monospace\",\n            size=11,\n            color=\"black\"\n            ),\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax= 130,\n        ay=1\n        )\n\nfig.add_vrect(x0=\"2020-06-01\", x1=\"2020-08-31\", fillcolor=\"yellow\", opacity=0.25, line_width=0)\n\nfig.add_annotation(\n        x='2020-07-15',\n        y=2.25,\n        text=\"Summer holidays\",\n        showarrow=False,\n        font=dict(\n            size=11,\n            )\n        )\n\nfig.update_traces(line_width=1)\n\nfig.show()","f3fdfe2f":"fig = px.line(st_eng, x=\"time\", y=\"engagement_index\", color=\"state\", line_group=\"state\")\n\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of engagement index of all products by states', \n                  title_font_size = 20, title_x = 0.5)\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', linewidth = 2,tickfont_size = 12)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', \n                 showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                 linewidth = 2,tickfont_size = 12)\n\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color=\"red\")\n\nfig.add_annotation(\n        x='2020-03-11',\n        y=1150,\n        text=\"WHO has declared Covid-19 a pandemic\",\n        showarrow=True,\n        font=dict(\n            size=11\n            ),\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax= 130,\n        ay=1\n        )\n\nfig.add_vrect(x0=\"2020-06-01\", x1=\"2020-08-31\", fillcolor=\"yellow\", opacity=0.25, line_width=0)\n\nfig.add_annotation(\n        x='2020-07-15',\n        y=900,\n        text=\"Summer holidays\",\n        showarrow=False,\n        font=dict(\n            size=11,\n            )\n        )\n\nfig.update_traces(line_width=1)\n\nfig.show()","eec7a685":"months_map = {1:\"January\",2:\"February\",3:\"March\",4:\"April\",\n              5:\"May\",6:\"June\",7:\"July\",8:\"August\",9:\"September\",\n              10:\"October\",11:\"November\",12:\"December\"}\n\nfor i in [st_ac\u0441ess, st_eng]:\n    i['state_abb'] = i['state'].map(state_abb)\n    i['month'] = i.time.dt.month.map(months_map)\n\n    fig = px.choropleth(data_frame = i.groupby(['state', 'state_abb', 'month']).agg({i.columns[2]: 'mean'}).reset_index(), locations = \"state_abb\", locationmode = \"USA-states\",\n                    color = i.groupby(['state', 'state_abb', 'month']).agg({i.columns[2]: 'mean'}).reset_index()[i.groupby(['state', 'state_abb', 'month']).agg({i.columns[2]: 'mean'}).reset_index().columns[3]], scope = \"usa\",\n                    color_continuous_scale = \"viridis\", animation_frame = \"month\", hover_name = \"state\")\n    \n    fig.update_layout(title_text = f'Monthly dynamics of {i.columns[2]}', title_font = dict(size = 25,color = \"black\")) \n    \n    fig.show()","8daf98e4":"\nfig = px.line(loc_ac\u0441ess, x=\"time\", y=\"pct_access\", color=\"locale\", line_group=\"locale\")\n\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of pct_access of all sectors', \n                  title_font_size = 20, title_x = 0.5)\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', linewidth = 2,tickfont_size = 12)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', \n                 showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                 linewidth = 2,tickfont_size = 12)\n\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color=\"red\")\n\nfig.add_annotation(\n        x='2020-03-11',\n        y=2.7,\n        text=\"WHO has declared Covid-19 as pandemic\",\n        showarrow=True,\n        font=dict(\n            family=\"monospace\",\n            size=11,\n            color=\"black\"\n            ),\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax= 130,\n        ay=1\n        )\n\nfig.add_vrect(x0=\"2020-06-01\", x1=\"2020-08-31\", fillcolor=\"yellow\", opacity=0.25, line_width=0)\n\nfig.add_annotation(\n        x='2020-07-15',\n        y=2.25,\n        text=\"Summer holidays\",\n        showarrow=False,\n        font=dict(\n            size=11,\n            )\n        )\n\nfig.update_traces(line_width=1)\n\nfig.show()","e2cdc773":"fig = px.line(loc_eng, x=\"time\", y=\"engagement_index\", color=\"locale\", line_group=\"locale\")\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of engagement_index of all sectors', \n                  title_font_size = 20, title_x = 0.5)\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', linewidth = 2,tickfont_size = 12)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', \n                 showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                 linewidth = 2,tickfont_size = 12)\n\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color=\"red\")\n\nfig.add_annotation(\n        x='2020-03-11',\n        y=2.7,\n        text=\"WHO has declared Covid-19 as pandemic\",\n        showarrow=True,\n        font=dict(\n            family=\"monospace\",\n            size=11,\n            color=\"black\"\n            ),\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax= 130,\n        ay=1\n        )\n\nfig.add_vrect(x0=\"2020-06-01\", x1=\"2020-08-31\", fillcolor=\"yellow\", opacity=0.25, line_width=0)\n\nfig.add_annotation(\n        x='2020-07-15',\n        y=2.25,\n        text=\"Summer holidays\",\n        showarrow=False,\n        font=dict(\n            size=11,\n            )\n        )\n\nfig.update_traces(line_width=1)\n\nfig.show()","8fda98a3":"fig = px.line(cat_eng, x=\"time\", y=\"engagement_index\", color=\"primary_function_main\", line_group=\"primary_function_main\")\n\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of engagement_index of all primary_function', \n                  title_font_size = 20, title_x = 0.5)\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', linewidth = 2,tickfont_size = 12)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', \n                 showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                 linewidth = 2,tickfont_size = 12)\n\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color=\"red\")\n\nfig.add_annotation(\n        x='2020-03-11',\n        y=2.7,\n        text=\"WHO has declared Covid-19 as pandemic\",\n        showarrow=True,\n        font=dict(\n            family=\"monospace\",\n            size=11,\n            color=\"black\"\n            ),\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax= 130,\n        ay=1\n        )\n\nfig.add_vrect(x0=\"2020-06-01\", x1=\"2020-08-31\", fillcolor=\"yellow\", opacity=0.25, line_width=0)\n\nfig.add_annotation(\n        x='2020-07-15',\n        y=2.25,\n        text=\"Summer holidays\",\n        showarrow=False,\n        font=dict(\n            size=11,\n            )\n        )\n\nfig.update_traces(line_width=1)\n\nfig.show()","ed2b691c":"\nfig = px.line(cat_ac\u0441ess, x=\"time\", y=\"pct_access\", color=\"primary_function_main\", line_group=\"primary_function_main\")\n\nfig.update_layout(plot_bgcolor = 'white', title = 'Dynamics of pct_access of all primary_function', \n                  title_font_size = 20, title_x = 0.5)\nfig.update_xaxes(showline = True, linecolor = '#f5f2f2', linewidth = 2,tickfont_size = 12)\nfig.update_yaxes(showline = True, linecolor = '#f5f2f2', \n                 showgrid = True, gridwidth = 1, gridcolor = '#f5f2f2',\n                 linewidth = 2,tickfont_size = 12)\n\nfig.add_vline(x = '2020-03-11', line_width = 3, line_color=\"red\")\n\nfig.add_annotation(\n        x='2020-03-11',\n        y=2.7,\n        text=\"WHO has declared Covid-19 as pandemic\",\n        showarrow=True,\n        font=dict(\n            family=\"monospace\",\n            size=11,\n            color=\"black\"\n            ),\n        arrowhead=2,\n        arrowsize=1,\n        arrowwidth=2,\n        arrowcolor=\"#636363\",\n        ax= 130,\n        ay=1\n        )\n\nfig.add_vrect(x0=\"2020-06-01\", x1=\"2020-08-31\", fillcolor=\"yellow\", opacity=0.25, line_width=0)\n\nfig.add_annotation(\n        x='2020-07-15',\n        y=2.25,\n        text=\"Summer holidays\",\n        showarrow=False,\n        font=dict(\n            size=11,\n            )\n        )\n\nfig.update_traces(line_width=1)\n\nfig.show()","577d9680":"cov_imp = pd.DataFrame(st_ac\u0441ess['state'].unique().tolist()).rename(columns = {0: 'state'})\n\n# We have no information about Texas during the start of pandemic\ncov_imp = cov_imp.query(\"state != 'Texas'\").reset_index()\ncov_imp.drop('index', axis = 1, inplace = True)\n\nfor i in ['mean_access', '1w_acess_change%', '2w_acess_change%', 'mean_eng', '1w_eng_change%', '2w_eng_change%']:\n    cov_imp[i] = 0.0\n\nstates = cov_imp['state'].unique().tolist()\n\nfor i in states:\n    cov_imp['mean_access'][states.index(i)] = round(st_ac\u0441ess.query(\"time >= '2020-03-09' & time <= '2020-03-13' & state == @i\")['pct_access'].mean(), 2)\n    cov_imp['1w_acess_change%'][states.index(i)] = round((st_ac\u0441ess.query(\"time >= '2020-03-16' & time <= '2020-03-20' & state == @i\")['pct_access'].mean() \/ cov_imp['mean_access'][states.index(i)] - 1) * 100, 1)\n    cov_imp['2w_acess_change%'][states.index(i)] = round((st_ac\u0441ess.query(\"time >= '2020-03-23' & time <= '2020-03-27' & state == @i\")['pct_access'].mean() \/ st_ac\u0441ess.query(\"time >= '2020-03-16' & time <= '2020-03-20' & state == @i\")['pct_access'].mean() - 1) * 100, 1)\n    cov_imp['mean_eng'][states.index(i)] = round(st_eng.query(\"time >= '2020-03-09' & time <= '2020-03-13' & state == @i\")['engagement_index'].mean(), 1)\n    cov_imp['1w_eng_change%'][states.index(i)] = round((st_eng.query(\"time >= '2020-03-16' & time <= '2020-03-20' & state == @i\")['engagement_index'].mean() \/ cov_imp['mean_eng'][states.index(i)] - 1) * 100, 1)\n    cov_imp['2w_eng_change%'][states.index(i)] = round((st_eng.query(\"time >= '2020-03-23' & time <= '2020-03-27' & state == @i\")['engagement_index'].mean() \/ st_eng.query(\"time >= '2020-03-16' & time <= '2020-03-20' & state == @i\")['engagement_index'].mean() - 1) * 100, 1)\n\ndef color_values(val):\n    color = 'red' if val < 0 else 'green'\n    return 'color: %s' % color\n\nslice_ = ['1w_acess_change%', '2w_acess_change%', '1w_eng_change%', '2w_eng_change%']\nslice_2 = ['mean_access', '1w_acess_change%', '2w_acess_change%']\nslice_3 = ['mean_eng', '1w_eng_change%', '2w_eng_change%']\ncov_imp.style.applymap(color_values, subset = slice_).set_precision(1).set_properties(**{'background-color': '#fafafa'}, subset=slice_2).set_properties(**{'background-color': '#f7f7f7'}, subset=slice_3)","80321a84":"cov_imp2 = pd.DataFrame(loc_ac\u0441ess['locale'].unique().tolist()).rename(columns = {0: 'locale'})\n\nfor i in ['mean_access', '1w_acess_change%', '2w_acess_change%', 'mean_eng', '1w_eng_change%', '2w_eng_change%']:\n    cov_imp2[i] = 0.0\n\nlocales = cov_imp2['locale'].unique().tolist()\n\nfor i in locales:\n    cov_imp2['mean_access'][locales.index(i)] = round(loc_ac\u0441ess.query(\"time >= '2020-03-09' & time <= '2020-03-13' & locale == @i\")['pct_access'].mean(), 2)\n    cov_imp2['1w_acess_change%'][locales.index(i)] = round((loc_ac\u0441ess.query(\"time >= '2020-03-16' & time <= '2020-03-20' & locale == @i\")['pct_access'].mean() \/ cov_imp2['mean_access'][locales.index(i)] - 1) * 100, 1)\n    cov_imp2['2w_acess_change%'][locales.index(i)] = round((loc_ac\u0441ess.query(\"time >= '2020-03-23' & time <= '2020-03-27' & locale == @i\")['pct_access'].mean() \/ loc_ac\u0441ess.query(\"time >= '2020-03-16' & time <= '2020-03-20' & locale == @i\")['pct_access'].mean() - 1) * 100, 1)\n    cov_imp2['mean_eng'][locales.index(i)] = round(loc_eng.query(\"time >= '2020-03-09' & time <= '2020-03-13' & locale == @i\")['engagement_index'].mean(), 1)\n    cov_imp2['1w_eng_change%'][locales.index(i)] = round((loc_eng.query(\"time >= '2020-03-16' & time <= '2020-03-20' & locale == @i\")['engagement_index'].mean() \/ cov_imp2['mean_eng'][locales.index(i)] - 1) * 100, 1)\n    cov_imp2['2w_eng_change%'][locales.index(i)] = round((loc_eng.query(\"time >= '2020-03-23' & time <= '2020-03-27' & locale == @i\")['engagement_index'].mean() \/ loc_eng.query(\"time >= '2020-03-16' & time <= '2020-03-20' & locale == @i\")['engagement_index'].mean() - 1) * 100, 1)\n\ncov_imp2.style.applymap(color_values, subset = slice_).set_precision(1).set_properties(**{'background-color': '#fafafa'}, subset=slice_2).set_properties(**{'background-color': '#f7f7f7'}, subset=slice_3)","1cacc5db":"### ENGANGEMENTS","6cc7d189":"checking if all nan values in engagement_index are caused by o.o or NAN of pct_access ( Percentage of students in the district have at least one page-load event of a given product and on a given day) and this will help us to know how we will handle our missing values in preprocessing\n\nand as it can be seen NON valuesa are due to the lack of students in the district have at least one page-load event of a given product and on a given day","8799bf09":"## data preprocessing ","f5a5d37b":"now let us have a look on how sectors are distributed in our states. we can see that we have many suburb and fue of town and city sectors ","85bfab13":"## DATA VISUALIZATION","a92aee71":"dispalying the first 5 elements of districts.info and we can see that there are some districts with NON values","05348996":"let us check if we are still having unhandled missing values from our engagement dataframe and as result we get 0.01 % missing values from lp_id and pct_access ","ee56ef89":"#### Engagement data\n\nThe engagement data are aggregated at school district level, and each file in the folder engagement_data represents data from one school district. The 4-digit file name represents district_id which can be used to link to district information in district_info.csv. The lp_id can be used to link to product information in product_info.csv.\n\n**Name** Description\n\n**time** date in \"YYYY-MM-DD\"\n\n**lp_id** The unique identifier of the product\n\n**pct_access** Percentage of students in the district have at least one page-load event of a given product and on a given day\n\n**engagement_index** Total page-load events per one thousand students of a given product and on a given day","0eb8ab3e":"#### District information data\n\nThe district file districts_info.csv includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab. In this data set.\n\nThe district file includes information about the characteristics of school districts:\n\n\n**.district_id:** The unique identifier of the school district\n\n**.state:** The state where the district resides in\n\n**.locale:** NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.\npct_black\/hispanic: Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data\n\n**.pct_free\/reduced**: Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data\n\n**.countyconnectionsratio:** ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information.\n\n**.pptotalraw:** Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district.\n","3c1961e6":"#### importing libraries to be used in the project","b128e14e":"#### HANDLING MISSING VALUES ","2aed476d":"to get a dataframe with all handled NAN values let us drop rows with no lp_id and replace pct_access NAN with 0","0257c4d6":"#### Let's have a look of how our datasets look like and try to understand well what is given ","e2c3a519":"In cities there are maximum numer of people who are eleigible for free\/reducded lunch whereas it is opposite in case of rural areas.\nGovt. spends mostly in rural areas for students developement and lowest in towns.\n","ef6862f9":"#### DISTRICS ","7c71febe":"our districts dataframe conatins 7 columns with 233 rows in total","0af80091":"#### Product information data\nThe product file products_info.csv includes information about the characteristics of the top 372 products with most users in 2020. The categories listed in this file are part of LearnPlatform's product taxonomy. Data were labeled by our team. Some products may not have labels due to being duplicate, lack of accurate url or other reasons.\n\n**Name** Description\n\n**LP ID** The unique identifier of the product\n\n**URL** Web Link to the specific product\n\n**Product Name** Name of the specific product\n\n**Provider\/Company Name** Name of the product provider\n\n**Sector(s)** Sector of education where the product is used\n\n**Primary Essential Function** The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled","f2356836":"we can see now that suburbs and rural areas are the ones wth the higest distribution pp_total_raw in available Area","7dd86cb0":"let us merge our remaining districts to their corresponding engagement data in one dataframe by adding the key column district_id to each engagement file\n\n","f6a5e00c":"Cities have highest percenatge of people who cleiam them to be Black\/Hispanic whereas its lowest for towns and rural areas.\n","79e5ce80":"dispalying the first 5 elements of engagement sample (this is one of many engagement datasets we have for each district )","64496a94":"### Kaggle Competition: LearnPlatform COVID-19 Impact on Digital Learning in the United States of America in 2020.\n","42e8996b":"dispalying the first 5 elements of products_info","da61fb6a":"#### PRODUCTS","d2e0bb0a":"change time to datetime64[ns]  for easier handling","a6ec54ef":"In this analytics competition, the work is to uncover trends in digital learning. Accomplish this with data analysis about how engagement with digital learning relates to factors like district demographics, broadband access, and state\/national level policies and events. Then, propose the best solution to these educational inequities.\n\nIn this analytics challenge, we are given multiple .csv files. The districts_info.csv file contains information about each school district and the products_info.csv file contains information about the top 370 tools used for digital learning. For each school district, there is an additional file that contains the engagement for each tool for everyday in 2020. The files can be joined by the key columns district_id and lp_id.","5d1f7ac7":"we can see that we have a large number of districts from Utah(29 districts) and  'Connecticut(30) states=","085fe54e":"we have104 districts from suburb sector, 33 districts are rural sectors, 29 are districts from city sector and 10 are town districts  ","160b5176":"our products dataframe contains 6 columns and 372 rows","b39bff2f":"splitting up the primary essential function into main and sub category","c3a54f71":"all NAN engagement_index values are now replaced by o","20b16874":"Now which column(s) has missing values","ff28af00":"Dropping Districts with NaN States, we are left with a reduced districts_info dataframe with 176 districts "}}