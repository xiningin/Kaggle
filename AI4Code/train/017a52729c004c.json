{"cell_type":{"4d7c988e":"code","9c0796a7":"code","c13a02e6":"code","c23dbc54":"code","6d4377bb":"code","b6a6cf01":"code","2bc90d9e":"code","4c2fa830":"code","13a104a0":"code","043007e0":"code","feb5f9a5":"code","59779eae":"code","22b8a17d":"code","7b314311":"code","7291b010":"code","db93b134":"code","bbffc289":"code","ae0966ec":"code","ee5a7199":"code","e9b56582":"code","c612a297":"code","9eae22ad":"code","5eaaf486":"code","8b2a82e0":"code","1733817f":"markdown","e47ce58d":"markdown","2c30e446":"markdown","a834270d":"markdown","e40e68e7":"markdown"},"source":{"4d7c988e":"import os\nimport re\nfrom datetime import datetime\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport tensorflow as tf\n\nfrom kaggle_datasets import KaggleDatasets","9c0796a7":"from tensorflow.keras.applications.efficientnet import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input as effnet_preprocess_input","c13a02e6":"import tensorflow_datasets as tfds\nimport tensorflow_hub as hub","c23dbc54":"print(\"Tensorflow version \" + tf.__version__)\n\ntry:\n  tpu = tf.distribute.cluster_resolver.TPUClusterResolver()  # TPU detection\n  print('Running on TPU ', tpu.cluster_spec().as_dict()['worker'])\nexcept ValueError:\n  raise BaseException('ERROR: Not connected to a TPU runtime; please see the previous cell in this notebook for instructions!')\n\ntf.config.experimental_connect_to_cluster(tpu)\ntf.tpu.experimental.initialize_tpu_system(tpu)\ntpu_strategy = tf.distribute.TPUStrategy(tpu)","6d4377bb":"GCS_PATH = KaggleDatasets().get_gcs_path('cassava-leaf-disease-classification')","b6a6cf01":"tfrec_fnames = tf.io.gfile.glob(GCS_PATH + '\/train_tfrecords\/ld_train*.tfrec')\nlen(tfrec_fnames)","2bc90d9e":"label_to_disease = pd.read_json(os.path.join(GCS_PATH, 'label_num_to_disease_map.json'), typ='series')","4c2fa830":"train_csv = pd.read_csv(os.path.join(GCS_PATH, 'train.csv'))","13a104a0":"train_csv['disease'] = train_csv['label'].map(label_to_disease)\ntrain_csv.head()","043007e0":"# 75:25 train:valid\ntrain_fnames = tfrec_fnames[:12]\nvalid_fnames = tfrec_fnames[12:]\nprint(len(train_fnames), len(valid_fnames))","feb5f9a5":"early_stop = tf.keras.callbacks.EarlyStopping(monitor = 'val_loss', min_delta = 0.001, \n                                              patience = 5, mode = 'min', verbose = 1,\n                                              restore_best_weights = True)\n\nreduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor = 'val_loss', factor = 0.3, \n                                                 patience = 2, min_delta = 0.001, \n                                                 mode = 'min', verbose = 1)","59779eae":"AUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 16 * tpu_strategy.num_replicas_in_sync\nIMAGE_SIZE = [512, 512]","22b8a17d":"def _parse_function(proto):\n    # feature_description needs to be defined since datasets use graph-execution\n    # - its used to build their shape and type signature\n    feature_description = {\n        'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n        'image_name': tf.io.FixedLenFeature([], tf.string, default_value=''),\n        'target': tf.io.FixedLenFeature([], tf.int64, default_value=-1)\n    }\n\n    parsed_features = tf.io.parse_single_example(proto, feature_description)\n    image = tf.image.decode_jpeg(parsed_features['image'], channels=3)\n    image = tf.cast(image, tf.float32) # :: [0.0, 255.0]\n    image = tf.reshape(image, [*IMAGE_SIZE, 3])\n    target = tf.one_hot(parsed_features['target'], depth=5)\n    return image, target","7b314311":"def load_dataset(tfrecords_fnames):\n    raw_ds = tf.data.TFRecordDataset(tfrecords_fnames, num_parallel_reads=AUTO)\n    parsed_ds = raw_ds.map(_parse_function, num_parallel_calls=AUTO)\n    return parsed_ds","7291b010":"def build_train_ds(train_fnames, with_aug=False):\n    ds = load_dataset(train_fnames)\n\n    def data_augment(image, target):\n        modified = tf.image.random_flip_left_right(image)\n        modified = tf.image.random_flip_up_down(image)\n        modified = tf.image.random_brightness(modified, 0.2)\n        #modified = tf.image.random_contrast(modified, 0.2, 0.5)\n        #modified = tf.image.random_hue(modified, 0.2)\n        modified = tf.image.random_saturation(modified, 5, 10)\n        modified = tf.clip_by_value(modified, 0.0, 255.0)\n        return modified, target\n\n    if with_aug:\n        ds = ds.map(data_augment, num_parallel_calls=AUTO)\n\n    return ds.repeat().shuffle(2048).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTO)","db93b134":"def build_valid_ds(valid_fnames):\n    ds = load_dataset(valid_fnames)\n    ds = ds.batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTO)\n    return ds","bbffc289":"def count_data_items(filenames):\n    n = [int(re.compile(r\"-([0-9]*)\\.\").search(fname).group(1)) for fname in filenames]\n    return np.sum(n)\n\nn_train = count_data_items(train_fnames)\nn_valid = count_data_items(valid_fnames)\ntrain_steps = count_data_items(train_fnames) \/\/ BATCH_SIZE\nprint(\"TRAINING IMAGES:\", n_train, \", STEPS PER EPOCH:\", train_steps)\nprint(\"VALIDATION IMAGES:\", n_valid)","ae0966ec":"def preprocess_fn(image, label):\n    image = image \/ 255.0\n    image = tf.image.resize(image, (224, 224))\n    label = tf.concat([label, [0]], axis=0)\n    return image, label","ee5a7199":"train_fnames = tfrec_fnames[:12]\nvalid_fnames = tfrec_fnames[12:]\n\ntrain_ds = load_dataset(train_fnames)\ntrain_ds = train_ds.map(preprocess_fn, num_parallel_calls=AUTO)\ntrain_ds = train_ds.repeat().shuffle(2048).batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTO)\n\nvalid_ds = load_dataset(valid_fnames)\nvalid_ds = valid_ds.map(preprocess_fn, num_parallel_calls=AUTO)\nvalid_ds = valid_ds.batch(BATCH_SIZE, drop_remainder=True).prefetch(AUTO)\n\ntrain_steps = count_data_items(train_fnames) \/\/ BATCH_SIZE","e9b56582":"img, label = next(iter(train_ds))\nprint(img.numpy().max(), img.shape, img.dtype)","c612a297":"os.environ[\"TFHUB_CACHE_DIR\"] = \"\/kaggle\/working\"\nwith tpu_strategy.scope():\n    load_locally = tf.saved_model.LoadOptions(experimental_io_device='\/job:localhost')\n    cassava = hub.KerasLayer('https:\/\/tfhub.dev\/google\/cropnet\/classifier\/cassava_disease_V1\/2', trainable=True, load_options=load_locally)\n    model = tf.keras.Sequential([tf.keras.Input(shape=(224,224,3)),\n                                 cassava])","9eae22ad":"model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=1e-5),\n              loss=tf.keras.losses.CategoricalCrossentropy(from_logits=False),\n              metrics=['accuracy'])","5eaaf486":"model.fit(train_ds, validation_data=valid_ds,\n          epochs=500, steps_per_epoch=train_steps,\n          callbacks=[reduce_lr, early_stop])","8b2a82e0":"model.save('cassava_model.h5')","1733817f":"### Datasets","e47ce58d":"### Data Prep","2c30e446":"### Callbacks","a834270d":"### Plain Model","e40e68e7":"### Data"}}