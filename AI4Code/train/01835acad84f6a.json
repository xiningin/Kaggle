{"cell_type":{"7ecbe38c":"code","8d562750":"code","6f459a64":"code","3b3dd9b7":"code","b64df21d":"code","08c163f8":"code","378dfbec":"code","a01cb50c":"code","5782c2ce":"code","32eccbe3":"code","0affdfee":"code","ad976d9b":"code","38f76ed7":"code","f8c8b14b":"code","c57ee7d8":"code","9dad8145":"code","c288cec0":"code","aef5c297":"code","3614cf9f":"code","f50f92d3":"code","78ae8adf":"code","54d565ee":"code","562731a4":"code","f07800b5":"code","ee59510b":"code","9525bfb5":"code","9bc147f1":"code","51a3e46b":"code","67164b6c":"code","98842abc":"code","2ffaa7db":"code","b3768156":"code","bf64fe96":"code","7e86ccc7":"code","afdbba64":"code","28716a10":"code","7d1108f3":"code","bb8a0f3d":"code","a3830d62":"code","abdb3cf4":"code","3e76ddf7":"code","694576c4":"code","a96e4acf":"code","099e865b":"code","bd400147":"code","4fa8bf32":"code","a85a70ea":"code","d61e3ee9":"code","5a3af0fc":"code","2116a39a":"code","0f85ed55":"code","eabdb265":"code","893f3f95":"code","3c7745ab":"code","27dced56":"code","8f26a2eb":"code","85fb3570":"code","bec5d96a":"code","6deef90d":"code","c583ce23":"code","8174343c":"code","f53c44b6":"code","99b0e2eb":"code","6967bfd2":"code","9baf6398":"code","d21c9c15":"code","d356cb84":"markdown","2e6563cc":"markdown","f0727004":"markdown"},"source":{"7ecbe38c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d562750":"data = pd.read_csv(\"..\/input\/nasa-cmaps\/CMaps\/train_FD001.txt\", sep=\" \", header=None)","6f459a64":"data.head()","3b3dd9b7":"COLS = [\"ID\", \"Cycle\", \"OpSet1\", \"OpSet2\", \"OpSet3\", \"SensorMeasure1\", \"SensorMeasure2\", \"SensorMeasure3\", \"SensorMeasure4\",\n                \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure7\", \"SensorMeasure8\", \"SensorMeasure9\", \"SensorMeasure10\", \"SensorMeasure11\",\n                \"SensorMeasure12\", \"SensorMeasure13\", \"SensorMeasure14\", \"SensorMeasure15\", \"SensorMeasure16\",\n                \"SensorMeasure17\", \"SensorMeasure18\", \"SensorMeasure19\", \"SensorMeasure20\", \"SensorMeasure21\"]","b64df21d":"# NaN olan s\u00fctunlar\u0131 \u00e7\u0131kar\u0131p ba\u015fl\u0131klar\u0131 ekle\ndata = data[[f for f in range(0, 26)]]\ndata.columns = [\"ID\", \"Cycle\", \"OpSet1\", \"OpSet2\", \"OpSet3\", \"SensorMeasure1\", \"SensorMeasure2\", \"SensorMeasure3\", \"SensorMeasure4\",\n                \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure7\", \"SensorMeasure8\", \"SensorMeasure9\", \"SensorMeasure10\", \"SensorMeasure11\",\n                \"SensorMeasure12\", \"SensorMeasure13\", \"SensorMeasure14\", \"SensorMeasure15\", \"SensorMeasure16\",\n                \"SensorMeasure17\", \"SensorMeasure18\", \"SensorMeasure19\", \"SensorMeasure20\", \"SensorMeasure21\"]","08c163f8":"data","378dfbec":"# Sadece 1 ID'li engine'in bilgileri\ndata[data[\"ID\"]==1]","a01cb50c":"# Her engine'in ka\u00e7 cycle dayand\u0131\u011f\u0131n\u0131n bilgisi\nmax_cycles_df = data.groupby([\"ID\"], sort=False)[\"Cycle\"].max().reset_index().rename(columns={\"Cycle\" : \"MaxCycleID\"})\nmax_cycles_df.head()","5782c2ce":"# Remaining Useful Life (RUL) ile dataseti birle\u015ftir\nFD001_df = pd.merge(data, max_cycles_df, how=\"inner\", on=\"ID\")\nFD001_df[\"RUL\"] = FD001_df[\"MaxCycleID\"] - FD001_df[\"Cycle\"]\nFD001_df","32eccbe3":"# CSV'ye d\u00f6n\u00fc\u015ft\u00fcr\nFD001_df.to_csv(\"FD001.csv\", index=None)","0affdfee":"import matplotlib.pyplot as plt\nfrom sklearn.preprocessing import MinMaxScaler","ad976d9b":"df_mini = FD001_df.copy().drop(columns=[\"ID\", \"Cycle\", \"OpSet1\", \"OpSet2\", \"OpSet3\", \"MaxCycleID\", \"RUL\"], axis=1)\nscaler = MinMaxScaler(feature_range=(0, 1))\nprint(df_mini)\nscaled_df = pd.DataFrame(scaler.fit_transform(df_mini.values))\nscaled_df = FD001_df[[\"ID\", \"Cycle\", \"RUL\"]].join(scaled_df)\nscaled_df.columns = [\"ID\", \"Cycle\",\"RUL\", \"SensorMeasure1\", \"SensorMeasure2\", \"SensorMeasure3\", \"SensorMeasure4\",\n                \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure7\", \"SensorMeasure8\", \"SensorMeasure9\", \"SensorMeasure10\", \"SensorMeasure11\",\n                \"SensorMeasure12\", \"SensorMeasure13\", \"SensorMeasure14\", \"SensorMeasure15\", \"SensorMeasure16\",\n                \"SensorMeasure17\", \"SensorMeasure18\", \"SensorMeasure19\", \"SensorMeasure20\", \"SensorMeasure21\"]","38f76ed7":"df_mini.values","f8c8b14b":"scaled_df","c57ee7d8":"print(\"SCALED\")\nplt.figure()\nscaled_df.plot.scatter(x=\"Cycle\", y=[\"SensorMeasure4\"])\nplt.show()\n\nprint(\"ORIGINAL\")\nplt.figure()\ndata.plot.scatter(x=\"Cycle\", y=[\"SensorMeasure4\"])\nplt.show()","9dad8145":"plt.style.use(\"seaborn\")\nsensor_count = 21\nengine_id = 2\nfor i in range(1, sensor_count+1):\n    y_value = \"SensorMeasure\" + str(i)\n    scaled_df[scaled_df[\"ID\"]==engine_id].plot(x=\"Cycle\", y=y_value)","c288cec0":"scaled_clean_df = scaled_df.drop(columns=[\"SensorMeasure1\", \"SensorMeasure5\", \"SensorMeasure6\", \"SensorMeasure10\",\n                                         \"SensorMeasure16\", \"SensorMeasure18\", \"SensorMeasure19\"])\nscaled_clean_df","aef5c297":"cycle_counts = scaled_clean_df.groupby(\"ID\")[\"Cycle\"].max().reset_index()","3614cf9f":"cycle_counts.plot(x=\"ID\", y=[\"Cycle\"], kind=\"hist\")\ncycle_counts.plot.scatter(x=\"Cycle\", y=[\"ID\"])","f50f92d3":"standart_deviations = scaled_clean_df.groupby(\"ID\").std().reset_index().drop(columns=[\"Cycle\"])\nstandart_deviations","78ae8adf":"engine_id = 1\nstandart_deviations[standart_deviations[\"ID\"]==engine_id].plot(y=[\"SensorMeasure2\",\"SensorMeasure3\",\"SensorMeasure4\",\"SensorMeasure7\",\n                                                                 \"SensorMeasure8\",\"SensorMeasure9\",\"SensorMeasure11\",\"SensorMeasure12\",\n                                                                 \"SensorMeasure13\",\"SensorMeasure14\",\"SensorMeasure15\",\"SensorMeasure17\",\n                                                                 \"SensorMeasure20\",\"SensorMeasure21\"], kind=\"bar\", figsize=(10, 5))","54d565ee":"# Genel g\u00f6r\u00fcnt\u00fc\nsensors = [\"SensorMeasure2\",\"SensorMeasure3\",\"SensorMeasure4\",\"SensorMeasure7\",\n           \"SensorMeasure8\",\"SensorMeasure9\",\"SensorMeasure11\",\"SensorMeasure12\",\n           \"SensorMeasure13\",\"SensorMeasure14\",\"SensorMeasure15\",\"SensorMeasure17\",\n           \"SensorMeasure20\",\"SensorMeasure21\"]\n\nengine_to_check = 1\n\nscaled_clean_df[scaled_clean_df[\"ID\"]==engine_to_check].plot(x=\"Cycle\", y=sensors, figsize=(20, 10))\n\nrul_fixed_df = scaled_clean_df.copy()\nrul_fixed_df.loc[rul_fixed_df[\"RUL\"] < 20, \"RUL\"] = 0\nrul_fixed_df.loc[rul_fixed_df[\"RUL\"] >= 20, \"RUL\"] = 1\nrul_fixed_df\ncol = rul_fixed_df[rul_fixed_df[\"ID\"]==engine_to_check].RUL.map({1:'b', 0:'r'})\nrul_fixed_df[rul_fixed_df[\"ID\"]==engine_to_check].plot.scatter(x=sensors[5], y=[sensors[9]], c=col)\nrul_fixed_df[rul_fixed_df[\"ID\"]==engine_to_check].plot.scatter(x=sensors[2], y=[sensors[6]], c=col)\nrul_fixed_df[rul_fixed_df[\"ID\"]==engine_to_check].plot.scatter(x=sensors[12], y=[sensors[13]], c=col)","562731a4":"import seaborn","f07800b5":"correlation_df = scaled_clean_df.drop(columns=[\"ID\", \"Cycle\", \"RUL\"])\ncorr_default = correlation_df.corr()\ncorr_default","ee59510b":"plt.figure(figsize=(12, 10))\nseaborn.heatmap(corr_default, annot=True, cmap=\"rocket\")","9525bfb5":"correlation_df = scaled_df.drop(columns=[\"ID\", \"Cycle\", \"RUL\"])\ncorr_default = correlation_df.corr()\ncorr_default","9bc147f1":"plt.figure(figsize=(12, 10))\nseaborn.heatmap(corr_default, annot=True, cmap=\"rocket\")","51a3e46b":"S1, S2 = \"SensorMeasure11\", \"SensorMeasure12\"\nfig, axes = plt.subplots(2, 5, figsize=(15, 10))\nfig.tight_layout()\n\nfor i in range(2):\n    for j in range(5):\n        df_used = scaled_clean_df[scaled_clean_df[\"ID\"]==(5*i+j+1)]\n        axes[i][j].plot(df_used[\"Cycle\"], df_used[S1])\n        axes[i][j].plot(df_used[\"Cycle\"], df_used[S2])\n        axes[i][j].title.set_text(\"Engine ID: \" + str(5*i+j+1))\n\nplt.show()","67164b6c":"# Veri k\u00fcmesi boyunca sens\u00f6rlerin de\u011ferleri\n\nfig, axes = plt.subplots(1, 2, figsize=(25, 10))\naxes[0].title.set_text(\"T\u00fcm veri k\u00fcmesi\")\nseaborn.heatmap(scaled_clean_df.copy().drop(columns=[\"ID\", \"Cycle\", \"RUL\"]), ax=axes[0])\n\nengine_id = 1\naxes[1].title.set_text(\"Motor ID: \" + str(engine_id))\nseaborn.heatmap(scaled_clean_df[scaled_clean_df[\"ID\"]==engine_id].copy().drop(columns=[\"ID\", \"Cycle\", \"RUL\"]), ax=axes[1])","98842abc":"# Veri k\u00fcmesinden \u00e7\u0131kard\u0131\u011f\u0131m sens\u00f6rleri geri ekleyince olu\u015fan heatmap\n\nfig, axes = plt.subplots(1, 2, figsize=(30, 10))\naxes[0].title.set_text(\"\u00c7\u0131kar\u0131lan \u00f6zelliklerle t\u00fcm veri k\u00fcmesi\")\nseaborn.heatmap(scaled_df.copy().drop(columns=[\"ID\", \"Cycle\", \"RUL\"]), ax=axes[0])\n\nengine_id = 1\naxes[1].title.set_text(\"\u00c7\u0131kar\u0131lan \u00f6zelliklerle Motor ID: \" + str(engine_id))\nseaborn.heatmap(scaled_df[scaled_df[\"ID\"]==engine_id].copy().drop(columns=[\"ID\", \"Cycle\", \"RUL\"]), ax=axes[1])","2ffaa7db":"class_df = scaled_clean_df.copy()\nclass_df['HS'] = [0 for x in range(len(class_df['RUL']))]\nclass_df.loc[class_df[\"RUL\"] <= 10, \"HS\"] = 'Not Okay'\nclass_df.loc[class_df['RUL'] >= 120, 'HS'] = 'Okay'\nclass_df.loc[(class_df['RUL'] < 120) & (class_df['RUL'] > 10), 'HS'] = 'Degradation'\nclass_df","b3768156":"HS_numeric = class_df.HS.map({'Okay':2, 'Not Okay':0, 'Degradation':1})\ncol = class_df.HS.map({'Okay':'b', 'Not Okay':'r', 'Degradation':'y'})\nclass_df['HS Numeric'] = HS_numeric\nplt.figure()\nclass_df.plot.scatter(x=\"Cycle\", y=[\"HS Numeric\"], color=col)","bf64fe96":"fig, axes = plt.subplots(4, 4, figsize=(15, 15))\nengine = 1\nsensor = \"SensorMeasure9\"\nfor i in range(4):\n    for j in range(4):\n        col = class_df[class_df['ID']==engine].HS.map({'Okay':'b', 'Not Okay':'r', 'Degradation':'y'})\n        plt.figure()\n        axes[i][j].scatter(class_df[class_df[\"ID\"]==engine][\"Cycle\"], class_df[class_df[\"ID\"]==engine][sensor], color=col)\n        axes[i][j].title.set_text(\"Engine: \" + str(engine))\n        engine += 1\n","7e86ccc7":"#dataset \u00f6zeti\nclass_df.info","afdbba64":"#ka\u00e7 tane (target) okey not okey ve degradation var?\nclass_df['HS Numeric'].value_counts()","28716a10":"#feature vect\u00f6r\u00fcn\u00fc ve hedef de\u011fi\u015fkenini bildirelim\nX = class_df.drop([ 'ID','Cycle','RUL','HS','HS Numeric'], axis=1)\n\ny = class_df['HS Numeric']","7d1108f3":"#X ve y'yi e\u011fitim ve test setlerine ay\u0131r\u0131n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)","bb8a0f3d":"#X_train ve x_test in shapeini kontrol edelim\nX_train.shape, X_test.shape","a3830d62":"#X_traindeki datalar\u0131n typelar\u0131na bakal\u0131m\nX_train.dtypes","abdb3cf4":"#all of the values are number\nX_train.head()","3e76ddf7":"# Kategori kodlay\u0131c\u0131lar\u0131n\u0131 import edelim (encoders)\nimport category_encoders as ce","694576c4":"# de\u011fi\u015fkenleri s\u0131ral\u0131 kodlamayla kodlayal\u0131m\n#encoder = ce.OrdinalEncoder(cols=['HS'])\n\n#X_train = encoder.fit_transform(X_train)\n\n#X_test = encoder.transform(X_test)","a96e4acf":"X_train.head()","099e865b":"X_test.head()","bd400147":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.tree import DecisionTreeRegressor","4fa8bf32":"# kriter gini indeksi ile DecisionTreeClassifier modelini somutla\u015ft\u0131ral\u0131m\nclf_gini = DecisionTreeClassifier(criterion='gini', max_depth=10, random_state=0)\n\n\n# fit the model\nclf_gini.fit(X_train, y_train)","a85a70ea":"#Kriter gini indeksi ile Test seti sonu\u00e7lar\u0131n\u0131 tahmin edelim\ny_pred_gini = clf_gini.predict(X_test)","d61e3ee9":"#Kriter gini indeksi ile accuracy score kontrol edin\nfrom sklearn.metrics import accuracy_score\n\nprint('Model accuracy score with criterion gini index: {0:0.4f}'. format(accuracy_score(y_test, y_pred_gini)))","5a3af0fc":"accuracy_score(y_test, y_pred_gini)","2116a39a":"#Train ve test setlerin accuracy lerini kar\u015f\u0131la\u015ft\u0131ral\u0131m\n\ny_pred_train_gini = clf_gini.predict(X_train)\n\ny_pred_train_gini","0f85ed55":"print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_gini)))","eabdb265":"#overfitting ve underfitting i\u00e7in bak\u0131yoruz\n#training ve test setin score lar\u0131n\u0131 print edelim\n\nprint('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))\n\nprint('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))\n\n#ikiside ayn\u0131 overfitting olabilir mi a\u015f\u0131r\u0131 m\u0131 uyumlu sor?","893f3f95":"#karar a\u011fac\u0131n\u0131 \u00e7izelim\n\n#plt.figure(figsize=(12,8))\n\nfrom sklearn import tree\n\n#tree.plot_tree(clf_gini.fit(X_train, y_train))","3c7745ab":"# Karar a\u011fac\u0131 Classifier (Criterion Entropy)\n# DecisionTreeClassifier modelini \u00f6l\u00e7\u00fct entropisi ile somutla\u015ft\u0131r\nclf_en = DecisionTreeClassifier(criterion='entropy', max_depth=10, random_state=0)\n\n\n# fit the model\nclf_en.fit(X_train, y_train)","27dced56":"#test set sonu\u00e7lar\u0131n\u0131 criterion entropy ile tahmin edelim\ny_pred_en = clf_en.predict(X_test)","8f26a2eb":"#Criterion Entrop ile accuracy score u kontrol edelim\nfrom sklearn.metrics import accuracy_score\n\nprint('Model accuracy score with criterion entropy: {0:0.4f}'. format(accuracy_score(y_test, y_pred_en)))","85fb3570":"#Train ve Test setteki accuracy leri kar\u015f\u0131la\u015ft\u0131ral\u0131m\ny_pred_train_en = clf_en.predict(X_train)\n\ny_pred_train_en","bec5d96a":"print('Training-set accuracy score: {0:0.4f}'. format(accuracy_score(y_train, y_pred_train_en)))","6deef90d":"#overfitting ve underfitting kontrol edelim (train ve test sette)\nprint('Training set score: {:.4f}'.format(clf_en.score(X_train, y_train)))\n\nprint('Test set score: {:.4f}'.format(clf_en.score(X_test, y_test)))","c583ce23":"#plt.figure(figsize=(12,8))\n\n#from sklearn import tree\n\n#tree.plot_tree(clf_en.fit(X_train, y_train))","8174343c":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.model_selection import GridSearchCV\n\n# Choose the type of classifier. \nclf = RandomForestClassifier(random_state=42)\n\n# Choose some parameter combinations to try\nparameters = {'n_estimators': [10,20,50], \n              'max_features': ['log2', 'sqrt','auto'], \n              'criterion': ['entropy', 'gini'],\n              'max_depth': [4, 5, 6, 10], \n              \n             }\n\n# Type of scoring used to compare parameter combinations\nacc_scorer = make_scorer(accuracy_score)\n\ngrid_obj = GridSearchCV(estimator= clf, param_grid=parameters, cv= 5)\ngrid_obj.fit(X_train, y_train)\n# Run the grid search\n#grid_obj = GridSearchCV(clf, parameters, scoring=acc_scorer)\n#grid_obj = grid_obj.fit(X_train, y_train)\n\n# Set the clf to the best combination of parameters\nclf = grid_obj.best_estimator_\n\n# Fit the best algorithm to the data. \nclf.fit(X_train, y_train)","f53c44b6":"#predictions = clf.predict(X_test)\n#print(accuracy_score(y_test, predictions))\n","99b0e2eb":"grid_obj.best_params_","6967bfd2":"rfc1=RandomForestClassifier(random_state=42, max_features='log2', n_estimators= 20, max_depth=8, criterion='gini')","9baf6398":"rfc1.fit(X_train, y_train)","d21c9c15":"pred=rfc1.predict(X_train)\nprint(\"Accuracy for Random Forest on data: \",accuracy_score(y_train,pred))","d356cb84":"# **VERILERI SINIFLANDIRMA**","2e6563cc":"**SensorMeasure 1, 5, 6, 10, 16, 18, 19 Gereksiz gibi g\u00f6r\u00fcn\u00fcyor.**","f0727004":"# VER\u0130 NORMAL\u0130ZASYONU VE G\u00d6RSELLE\u015eT\u0130RME"}}