{"cell_type":{"3cca3bc9":"code","b531627d":"code","81ffacd3":"code","3b6826a8":"code","afe54464":"code","a45ef546":"code","3f2de665":"code","37e66c3c":"code","8690644d":"code","a7bbef54":"code","df3d1808":"code","f48968c8":"code","946509fe":"code","5e91376f":"code","168f99d4":"code","2fc9a915":"code","1b292e91":"code","a5e770c6":"code","6bd1b2e9":"code","d6fa3726":"code","66bf8f37":"code","f6efa781":"code","e34f1de7":"code","474d39d6":"code","06d9dd73":"markdown","7bc5e37e":"markdown","e6eeaa7a":"markdown","4116c9e2":"markdown","edac72e5":"markdown","08451916":"markdown","90b3cc3f":"markdown","4d8e2f28":"markdown","ff9369df":"markdown","170819b3":"markdown","261c72c3":"markdown","55ec4372":"markdown","fcb292cc":"markdown","5faec593":"markdown","2f1525fe":"markdown","cb6eb55a":"markdown","4932e06c":"markdown","30c76326":"markdown","161e74b3":"markdown","54b52471":"markdown","24f002a3":"markdown","06c4f34f":"markdown","c7c93d49":"markdown","2a713fd4":"markdown"},"source":{"3cca3bc9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport re\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b531627d":"flipkart_data = pd.read_csv(r\"\/kaggle\/input\/filpkart-onlineorders\/OnlineOrders_of_a_ecommerce_website.csv\")","81ffacd3":"flipkart_data.head()","3b6826a8":"flipkart_data.rename(columns={'crawl_timestamp': 'Timestamp',\n                              'product_name': 'Product_Name',\n                             'product_category_tree': 'Product_Category_Tree',\n                             'retail_price': 'Retail_Price',\n                             'discounted_price': 'Discounted_Price',\n                             'brand': 'Brand'}, inplace=True)","afe54464":"flipkart_data.head()","a45ef546":"flipkart_data['Category'] = flipkart_data['Product_Category_Tree'].apply(lambda x: re.split('\\[]*|\\\"|\\>>|\\,', x)[2])","3f2de665":"flipkart_data.head(5)","37e66c3c":"flipkart_data.drop(['Product_Category_Tree'], axis = 1, inplace= True)","8690644d":"flipkart_data.head()","a7bbef54":"flipkart_data['Timestamp'] = flipkart_data['Timestamp'].apply(lambda x: x.split('+')[0])","df3d1808":"flipkart_data.head()","f48968c8":"# Save the data as csv file\nflipkart_data.to_csv('fkartDataset.csv', index=False)","946509fe":"flkart_data = pd.read_csv('fkartDataset.csv')\nflkart_data.head()","5e91376f":"flkart_data.isnull().sum()","168f99d4":"#Adding the month column\nflkart_data['Month'] = pd.to_numeric(pd.DatetimeIndex(flkart_data['Timestamp']).month)\nflkart_data.head()","2fc9a915":"totalsum = flkart_data.groupby('Month').sum()\ntotalsum ","1b292e91":"months = range(1, 7)\nplt.bar(months, totalsum['Discounted_Price'])\nplt.xticks(months)\nplt.xlabel(\"Months\")\nplt.ylabel('Sales in INR')\nplt.show()","a5e770c6":"flkart_data['Timestamp'] = pd.to_datetime(flkart_data['Timestamp'])","6bd1b2e9":"flkart_data['Hour'] = flkart_data['Timestamp'].dt.hour\nflkart_data['Minute'] = flkart_data['Timestamp'].dt.minute","d6fa3726":"flkart_data.head()","66bf8f37":"hours = [hour for hour, df in flkart_data.groupby('Hour')]\n\nplt.plot(hours, flkart_data.groupby(['Hour']).count())\nplt.xticks(hours)\nplt.xlabel('Hour')\nplt.ylabel('Number of Orders')\nplt.grid()\nplt.show()","f6efa781":"# So our target is to look after duplicates rows\ndups_category = flkart_data.pivot_table(index=['Category'], aggfunc='size')","e34f1de7":"print(dups_category.nlargest(6))\n\nx =list(range(1,7))\n\nfig, ax = plt.subplots()\nbar = sns.barplot(data=flkart_data, x=x , y=dups_category.nlargest(6), edgecolor=\"white\")\nax.set_xticklabels([\"Clothes\", \"Jewel\", 'Mobile&Accessories', 'Home Decor', 'Footwear', 'Tools&Hardware'], rotation=90)\nplt.show();","474d39d6":"# So our target is to look after duplicates rows\ndups_product = flkart_data.pivot_table(index=['Product_Name'], aggfunc='size')\n\nprint(dups_product.nlargest(10))\nitems = range(10)\n\nx =list(range(1,11))\nfig, ax = plt.subplots()\nbar = sns.barplot(data=flkart_data, x=x , y=dups_category.nlargest(10), edgecolor=\"white\")\nplt.show();\n","06d9dd73":"**Read in updated dataframe**","7bc5e37e":"**Removing unnecessary Zero(Milliseconds) from Timestamp**","e6eeaa7a":"**So we successfully added a new column as category**","4116c9e2":"**4. Top 10 product sold most in that six month period?**","edac72e5":"This Dataset content E-Commerce data with the date and time in which they have ordered.\nAs this a simple dataset, It has done to test your skills on pandas and data visualization. As the dataset is a bit messy\nand not smooth, our goal is to make it clean and organized for data visualization. It is the first step to become \na Data Scientist i.e., you have to work on data cleaning","08451916":"So We can observe that we have a Timestamp Column but as per the Question We need months column, So we have the extract months from timestamp","90b3cc3f":"**3. Which category sold most in that six month period?**","4d8e2f28":"As we can see Product Category Tree column is not organised. So first make that\ncolumn as category and extract the category name from it. Also we don't \nwant need the whole information.\n\nAs it have squared barckets and right arrow signs it look complex and confused structure. But break the things and watch carefully, the first word of the string is needed to fulfill our requirment.\n\nSo lets do it ","ff9369df":"**First, Giving proper column names**","170819b3":"**So obviously Clothings and Jewellery are the top categories to sold most.**","261c72c3":"**We don't have any missing value**","55ec4372":"So January month is having more sales. May be due to new year eve","fcb292cc":"**You can do more research and dig into it for more information.**","5faec593":"**So we can conclude that morning and evening are the perfect time to displaying advertisements**","2f1525fe":"**1. What was the best month for sales? How much was earned that months?**","cb6eb55a":"**Loading the Data to Pandas**","4932e06c":"**Removing  Product_Category_Tree Column**","30c76326":"####  Question about this Dataset\n\n##### 1. What was the best month for sales? How much was earned that months?\n##### 2. What time should we display advertisements to maximize the likelihood of purchases? \n##### 3. Which category sold most in that six month period?\n##### 4. Top 10 product sold most in that six month period?","161e74b3":"***************************************************************","54b52471":"As we have converted Timestamp column to datetime field. So we can easily create hour and minute columns","24f002a3":"**So finally our dataset is clean and organized. So save it as CSV file for future use!**","06c4f34f":"**Clean up the missing value**","c7c93d49":"**2.What time should we display advertisements to maximize the likelihood of purchases?**","2a713fd4":"**Here are the top 10 products available respectively**"}}