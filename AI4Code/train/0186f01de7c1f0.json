{"cell_type":{"226620be":"code","83e2145d":"code","2291ba39":"code","9e04e0de":"code","92a6212f":"code","0b59253d":"code","8c7b3323":"code","57f424e3":"code","f42ec6c1":"code","ea734435":"code","1924f775":"code","4c2c67f2":"code","2faa68ad":"code","017f608c":"code","783dc591":"code","145d091f":"code","c9e4e5e3":"code","7b85f3bb":"code","564ae1f5":"code","ded7c386":"code","4bf11f21":"code","71538f9a":"code","0d270f2c":"code","521c1f4a":"code","d3ba71ca":"code","f9533a77":"code","38f6d699":"markdown","09d11234":"markdown","b055aa0e":"markdown","92e86e64":"markdown","678865c6":"markdown","ddb926c5":"markdown","0208a6d0":"markdown","d0bebb14":"markdown","46195953":"markdown","c996682a":"markdown","8f465d39":"markdown","5c89148a":"markdown","b393ef04":"markdown","6437c45d":"markdown","aa10c81b":"markdown"},"source":{"226620be":"import numpy as np \nimport matplotlib.pyplot as plt\nimport sklearn\nimport seaborn as sns\nimport pandas as pd \n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.model_selection import cross_val_score,StratifiedKFold,StratifiedShuffleSplit,cross_val_predict\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.base import clone \nfrom sklearn.pipeline import Pipeline\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier,VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC","83e2145d":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \ntrain_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\n# dimention of given datasets\nprint(\"dimentions of train dataset: {}\".format(train_df.shape))\nprint(\"dimentions of test dataset: {}\".format(test_df.shape))","2291ba39":"# how the data looks like (first 5 rows)\ntrain_df.head() ","9e04e0de":"train_df.info() # column names and datatypes ","92a6212f":"train_df.isnull().sum() # Total number of null values in the training dataset","0b59253d":"train_df.describe() # stastical information of training dataset\n\n# 0 fare is for crew, musicians and employees\n# Pclass: socio-economic status 1st = Upper, 2nd = Middle ,3rd = Lower","8c7b3323":"# histogram to visualize survival on the basis of age \nsurvived = train_df[train_df[\"Survived\"] == 1]\ndied = train_df[train_df[\"Survived\"] == 0]\nsurvived[\"Age\"].plot.hist(alpha=0.5,color='red',bins=50)\ndied[\"Age\"].plot.hist(alpha=0.5,color='blue',bins=50)\nplt.legend(['Survived','Died'])\nplt.show()","57f424e3":"# Survival on the basis of sex\nsex_pivot = train_df.pivot_table(index=\"Sex\",values=\"Survived\")\nsex_pivot.plot.bar()","f42ec6c1":"sns.violinplot(x=\"Pclass\",y=\"Age\",hue=\"Survived\",split=True,data=train_df, palette={0: \"r\", 1: \"g\"})","ea734435":"train_dfclone = train_df.copy() # making a copy of training set to make changes","1924f775":"if any(x in ['Name','Ticket','Cabin','PassengerId'] for x in pd.DataFrame(train_dfclone).columns):\n    train_dfclone = train_dfclone.drop(['Name','Ticket','Cabin','PassengerId'],axis=1)\ntrain_dfclone.head()","4c2c67f2":"train_dfclone = train_dfclone.replace({'Pclass':{1:'Upper',2:'Middle',3:'Lower'}})","2faa68ad":"train_dfclone = pd.get_dummies(train_dfclone)\ntrain_dfclone","017f608c":"# filling the missing values\nimputer = SimpleImputer(strategy= 'median')\nimputer.fit(train_dfclone)\nimputer.statistics_\n\ntrain_dfclone_final = imputer.transform(train_dfclone)\ntrain_dfclone_final = pd.DataFrame(train_dfclone_final,columns=train_dfclone.columns)\ntrain_dfclone_final","783dc591":"correlation = train_dfclone_final.corr()\nprint(correlation['Survived'].sort_values(ascending = False))\n\nfig, ax = plt.subplots(figsize=(12,9))      \nsns.heatmap(correlation,ax=ax)","145d091f":"features = train_dfclone_final.drop(['Survived'],axis =1)\nlabel = train_dfclone_final['Survived']\nlabel","c9e4e5e3":"tree_clf = DecisionTreeClassifier()\nforest_clf = RandomForestClassifier()\nneighbor_clf = KNeighborsClassifier()\nneural_clf = MLPClassifier(max_iter = 600)\nsgd_clf = SGDClassifier()\nprob_clf = GaussianNB()\ngbd_clf = GradientBoostingClassifier()\nada_clf = AdaBoostClassifier()\nsvc_clf = SVC()\nlog_reg = LogisticRegression(max_iter=600)\n\n# vote_clf = VotingClassifier()","7b85f3bb":"forest_param_grid = { \"criterion\" : [\"gini\", \"entropy\"], \"min_samples_leaf\" : [1, 5, 10, 25, 50], \n              \"min_samples_split\" : [2, 4, 10, 12, 16], \n              \"n_estimators\": [100, 400, 700, 1000,1200,1500]}\n\ngbd_param_grid = {'learning_rate':[0.15,0.1,0.05], \n           'n_estimators':[100,250,500,750,1000],'max_depth':[2,3,4,5],\n                 'min_samples_split':[2,4,6,8], 'min_samples_leaf':[1,3,5]}","564ae1f5":"# Random forest estimator\ngd_forest = GridSearchCV(estimator=forest_clf,\n                     param_grid=forest_param_grid,\n                     scoring='accuracy',\n                     cv=5,\n                     n_jobs=-1)\n\ngd_forest.fit(features, label)\nbest_parameters_forest = gd_forest.best_params_\nprint(best_parameters_forest)","ded7c386":"# gradient boost estimator\ngd_gradient = GridSearchCV(estimator=gbd_clf,\n                     param_grid=gbd_param_grid,\n                     scoring='accuracy',\n                     cv=5,\n                     n_jobs=-1)\n\ngd_gradient.fit(features, label)\nbest_parameters_gradient = gd_gradient.best_params_\nprint(best_parameters_gradient)","4bf11f21":"forest_clf = RandomForestClassifier(criterion = 'entropy', min_samples_leaf= 1,\n        min_samples_split= 12, n_estimators= 100)\n\ngbd_clf = GradientBoostingClassifier(learning_rate= 0.1, max_depth= 3,\n                                     min_samples_leaf= 3, min_samples_split=2,\n                                     n_estimators= 250)","71538f9a":"# skfolds = StratifiedKFold(n_splits= 2, random_state = 42,shuffle=True)\n\n# for train_index, test_index in skfolds.split(features,label):\n#     clone_clf = clone(gbd_clf)\n#     X_train_folds = features.loc[train_index]\n#     Y_train_folds = label.loc[train_index]\n#     X_test_folds = features.loc[test_index]\n#     Y_test_folds = label.loc[test_index]\n    \n#     clone_clf.fit(X_train_folds,Y_train_folds)\n#     y_pred = clone_clf.predict(X_test_folds)\n#     n_correct = sum(y_pred==Y_test_folds)\n#     print(n_correct\/ len(y_pred))","0d270f2c":"estimators = [tree_clf,forest_clf,neighbor_clf,\n              neural_clf,sgd_clf,prob_clf,gbd_clf,\n              ada_clf,svc_clf,log_reg]\n\nfor clf in estimators:\n    scores = cross_val_score(clf, features, label, cv=5,scoring='accuracy')\n    print(str(clf)+\": \"+ str(scores.mean()*100))","521c1f4a":"gbd_clf.fit(features,label)\ngbd_clf.score(features,label)","d3ba71ca":"# preprocessing the test dataset\ndef feature_eng(dataset):\n    dataset = dataset.drop(['Name','Ticket','Cabin','PassengerId'],axis=1)\n    dataset = dataset.replace({'Pclass':{1:'Upper',2:'Middle',3:'Lower'}})\n    dataset = pd.get_dummies(dataset)\n    dataset = dataset.fillna(train_df.median())\n    return dataset\n    \ntest_df_final = feature_eng(test_df)\ntest_df_final","f9533a77":"# using gradient boost descent\n\nfinal_predictions = (gbd_clf.predict(test_df_final)).astype(int)\nfinal_predictions= pd.DataFrame(final_predictions,columns=['Survived'])\n\nsubmission_df = pd.DataFrame({'PassengerId':test_df['PassengerId'],\n                           'Survived':final_predictions['Survived']})\nsubmission_df['Survived'].value_counts()","38f6d699":"## Visualizing the dataset","09d11234":"## Cross val score or startifiedKfold","b055aa0e":"### Dropping the *unnecessary features* from the dataset\n* Passenger Id\n* name \n* Ticket\n* Cabin no.","92e86e64":"As we can se Pclass has three values i.e 1,2,3 representing socio-economic status 1st = Upper, 2nd = Middle ,3rd = Lower respectively.","678865c6":"## Filling the null\/missing values in the dataset","ddb926c5":"![](https:\/\/s.yimg.com\/ny\/api\/res\/1.2\/69IrTsq.f0CLf90JJiEJgw--\/YXBwaWQ9aGlnaGxhbmRlcjt3PTk2MDtoPTQ4MS42MTYxNjE2MTYxNjE2\/https:\/\/s.yimg.com\/uu\/api\/res\/1.2\/FlUtbIwqjezZ84cL201vCg--~B\/aD0yOTg7dz01OTQ7YXBwaWQ9eXRhY2h5b24-\/https:\/\/media.zenfs.com\/en\/popular_mechanics_642\/e72b79bbdc59f2bd9e457539c4b37886)","0208a6d0":"### Importing the necessary libraries","d0bebb14":"## Feature Engineering\n","46195953":"### Categorical data into numerical data","c996682a":"## Exploring the training dataset","8f465d39":"## Splitting data into features and labels","5c89148a":"# Final Predictions","b393ef04":"## Correlation of features and label","6437c45d":"## Importing the dataset","aa10c81b":"## Training the ML model"}}