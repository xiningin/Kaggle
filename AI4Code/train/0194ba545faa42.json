{"cell_type":{"74d37154":"code","672339f8":"code","bb61bc69":"code","47b9d0a6":"code","c14d0c0b":"code","6a5ce692":"code","485ed5ac":"code","fb3c6c84":"code","12899590":"code","f5eaf3f2":"code","15fdb52f":"code","dd6427c9":"code","6becf7ae":"code","c242b508":"code","c8fe7cef":"code","fefa4d0c":"code","ee334066":"code","e32cdb49":"code","527a67cf":"code","2838310f":"code","c2867e2c":"code","41508bbe":"code","d48c0b4c":"code","551dea54":"code","e85e2067":"code","0bd2bcf4":"code","237944a6":"code","bcc8de20":"code","6a8e0469":"code","f48506a1":"code","cd8d8492":"code","e3ae0a68":"code","45b15b2d":"code","729c1961":"code","ff48bf98":"code","7f0f4d06":"code","f08b4ed1":"markdown","08dec271":"markdown","0cd4f3c3":"markdown","90548b27":"markdown","a7dc1812":"markdown","97418c14":"markdown","e0bc79a7":"markdown","bc6fc387":"markdown","6b4ea681":"markdown","f7404ed9":"markdown","cf36337d":"markdown","c154f6a3":"markdown","fd807f7c":"markdown","6686abe4":"markdown","b2931f3b":"markdown","019c094e":"markdown","a6f2fd14":"markdown","fdafa9cb":"markdown","b91997aa":"markdown","cdd2c3e4":"markdown","c20e3389":"markdown","2000b525":"markdown","87a92af0":"markdown","84bff48e":"markdown","8354a80d":"markdown","1ceafd95":"markdown","c9a8f1c0":"markdown","97cfbab5":"markdown","f92db6d3":"markdown","f4f9a9c3":"markdown","f34ce7fc":"markdown"},"source":{"74d37154":"import numpy as np                \nimport pandas as pd               \nimport seaborn as sns             \nimport matplotlib.pyplot as plt   \nimport scipy.stats                \nfrom sklearn import preprocessing\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom scipy.cluster.hierarchy import dendrogram, linkage\nimport scipy.cluster.hierarchy as sch\nfrom sklearn.cluster import AgglomerativeClustering\nimport time\nimport warnings\nfrom sklearn import cluster, datasets\nfrom sklearn.preprocessing import StandardScaler\nfrom itertools import cycle, islice\nimport os","672339f8":"lista = os.listdir(\"..\/input\")\nprint(lista)","bb61bc69":"df = pd.read_csv(\"..\/input\/\"+lista[1])\ndf.head(5)","47b9d0a6":"lista2 = [x.replace(\".csv\",\"\") for x in lista ]\nclose = pd.DataFrame([0.0]*len(pd.read_csv(\"..\/input\/\"+lista[1])))\nvol = pd.DataFrame([0.0]*len(pd.read_csv(\"..\/input\/\"+lista[1])))\nchange = pd.DataFrame([0.0]*len(pd.read_csv(\"..\/input\/\"+lista[1])))\n\nfor i in range(len(lista)):\n    a = pd.read_csv(\"..\/input\/\"+lista[i])\n    fecha = pd.DataFrame({\"date\":a.date})    \n    close[lista2[i]] = a.close\n    vol[lista2[i]] = a.volume\n    change[lista2[i]] = a.change\nprint(close.shape == vol.shape == change.shape)\nprint(close.shape)","c14d0c0b":"print(\"Se tienen\", len(lista), \"acciones\")","6a5ce692":"close = close.iloc[:,1:31]\nvol = vol.iloc[:,1:31]\nchange = change.iloc[:,1:31]","485ed5ac":"close.head(5)","fb3c6c84":"sns.clustermap(close.corr(), center=0, cmap=\"vlag\",\n               linewidths=.75, figsize=(13, 13))","12899590":"sns.clustermap(vol.corr(), center=0, cmap=\"vlag\",\n               linewidths=.75, figsize=(13, 13))","f5eaf3f2":"sns.clustermap(change.corr(), center=0, cmap=\"vlag\",\n               linewidths=.75, figsize=(13, 13))","15fdb52f":"df_scale = change.copy()\nscaler = preprocessing.StandardScaler()\ncolumns =change.columns\ndf_scale[columns] = scaler.fit_transform(df_scale[columns])\ndf_scale.head()","dd6427c9":"compl = pd.DataFrame({'Porcentaje de Completitud':df_scale.count()*100\/len(df_scale)}).round(2)\ncompl['indexx'] = compl.index.values.tolist()\ncompl = compl.sort_values(['Porcentaje de Completitud'],ascending=False).reset_index(drop=True)\nplt.figure(figsize=(15,15))\nsns.barplot(x=compl[\"Porcentaje de Completitud\"],y=compl.indexx,palette='Blues_d')\nplt.axvline(x=compl.mean()[0],linestyle='--',color='firebrick',label='Completitud Promedio: Acciones DJI')\nplt.xlabel(\"Porcentaje de Completitud\",fontsize=15)\nplt.ylabel(\"Variable\",fontsize=15)\nplt.title(\"Completitud Promedio: Acciones DJI\",fontsize=15)\nplt.show()","6becf7ae":"a = pd.DataFrame(df_scale.describe()).mean(axis=1)[1]\nprint('La media de los retornos de todas las acciones es:', a)","c242b508":"df_scale = df_scale.fillna(a)\ndf_scale.shape","c8fe7cef":"#Elbow graph\nks = range(1, 6)\ninertias = []\n\nfor k in ks:\n    # Create a KMeans instance with k clusters: model\n    model = KMeans(n_clusters=k)\n    \n    # Fit model to samples\n    model.fit(df_scale.iloc[:,1:])\n    \n    # Append the inertia to the list of inertias\n    inertias.append(model.inertia_)\n    \n# Plot ks vs inertias\nplt.plot(ks, inertias, '-o')\nplt.xlabel('number of clusters, k')\nplt.ylabel('inertia')\nplt.xticks(ks)\nplt.show()","fefa4d0c":"model = KMeans(n_clusters=3)\n\n# Fit model to points\nmodel.fit(df_scale)\n\n# Determine the cluster labels of new_points: labels\ndf_scale['cluster'] = model.predict(df_scale)\n\ndf_scale.head()","ee334066":"# Create PCA instance: model\nmodel_pca = PCA()\n\n# Apply the fit_transform method of model to grains: pca_features\npca_features = model_pca.fit_transform(df_scale)\n\n# Assign 0th column of pca_features: xs\nxs = pca_features[:,0]\n\n# Assign 1st column of pca_features: ys\nys = pca_features[:,1]\n\n# Scatter plot xs vs ys\nsns.scatterplot(x=xs, y=ys, hue=\"cluster\", data=df_scale)","e32cdb49":"centroids = model.cluster_centers_\ndf_scale.groupby(['cluster']).mean()","527a67cf":"cero = []\nuno = []\ndos = []\n\ncero = (df_scale.cluster==0).astype(int)*df_scale.AAPL\nuno = (df_scale.cluster==1).astype(int)*df_scale.AAPL\ndos = (df_scale.cluster==2).astype(int)*df_scale.AAPL\n\nfor i in range(len(cero)):\n    if(cero[i] == 0):\n        cero[i] = np.nan\n    if(uno[i] == 0):\n        uno[i] = np.nan\n    if(dos[i] == 0):\n        dos[i] = np.nan","2838310f":"conf = df_scale.cluster\nsns.set(style =\"dark\")\nax = sns.countplot(x = conf, palette='Blues_d')\nax.set_title(label='Frecuencia', fontsize=20)","c2867e2c":"sns.heatmap(df_scale.groupby(['cluster']).mean(), cmap=\"vlag\")","41508bbe":"plt.figure(figsize=(20,7))\nplt.title('Retornos de APPL seg\u00fan el Reg\u00edmen de Mercado')\nplt.plot(cero,color='g',label=\"0\")\nplt.plot(uno,color='r',label=\"1\")\nplt.plot(dos, color = 'b',label=\"2\")\nplt.legend()\nplt.xticks([])\nplt.yticks([])\nplt.ylim((-6, 6))","d48c0b4c":"df2 = change.copy()\nscaler = preprocessing.StandardScaler()\ncolumns =change.columns\ndf2[columns] = scaler.fit_transform(df2[columns])\ndf2.head()","551dea54":"a = pd.DataFrame(df2.describe()).mean(axis=1)[1]\ndf2 = df2.fillna(a)\ndf2 = df2.values\nprint(df2)","e85e2067":"print(df2.shape)","0bd2bcf4":"X = df2\nplt.figure(figsize=(20,10))\ndendrogram = sch.dendrogram(sch.linkage(X, method = 'complete'))\nplt.title('Dendograma')\nplt.show()","237944a6":"hc = AgglomerativeClustering(n_clusters = 3, \n                    affinity = 'euclidean', \n                    linkage = 'ward')\n\ny_hc = hc.fit_predict(X)","bcc8de20":"plt.scatter(X[y_hc == 0, 0], X[y_hc == 0, 1], s = 10, c = 'red', label = 'Cluster 1')\nplt.scatter(X[y_hc == 1, 0], X[y_hc == 1, 1], s = 10, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_hc == 2, 0], X[y_hc == 2, 1], s = 10, c = 'green', label = 'Cluster 3')\nplt.legend()\nplt.show()","6a8e0469":"clusters = pd.DataFrame({'cluster':y_hc})\nclusters = clusters.cluster.values.tolist()\nconf = clusters\nsns.set(style =\"dark\")\nax = sns.countplot(x = conf, palette='Blues_d')\nax.set_title(label='Frecuencia', fontsize=20)","f48506a1":"df_scale['cluster2'] = clusters\nsns.heatmap(df_scale.groupby(['cluster2']).mean(), cmap=\"vlag\")\ncero = []\nuno = []\ndos = []\n\ncero = (df_scale.cluster2==0).astype(int)*df_scale.AAPL\nuno = (df_scale.cluster2==1).astype(int)*df_scale.AAPL\ndos = (df_scale.cluster2==2).astype(int)*df_scale.AAPL\n\nfor i in range(len(cero)):\n    if(cero[i] == 0):\n        cero[i] = np.nan\n    if(uno[i] == 0):\n        uno[i] = np.nan\n    if(dos[i] == 0):\n        dos[i] = np.nan","cd8d8492":"plt.figure(figsize=(20,7))\nplt.title('Retornos de APPL seg\u00fan el Reg\u00edmen de Mercado: Clustering Jer\u00e1rquico')\nplt.plot(cero,color='g',label=\"0\")\nplt.plot(uno,color='r',label=\"1\")\nplt.plot(dos, color = 'b',label=\"2\")\nplt.legend()\nplt.xticks([])\nplt.yticks([])\nplt.ylim((-6, 6))","e3ae0a68":"df_scale['DJI'] = df_scale.iloc[:,:30].sum(axis=1)","45b15b2d":"cero = []\nuno = []\ndos = []\n\ncero = (df_scale.cluster==0).astype(int)*df_scale.DJI\nuno = (df_scale.cluster==1).astype(int)*df_scale.DJI\ndos = (df_scale.cluster==2).astype(int)*df_scale.DJI\n\nfor i in range(len(cero)):\n    if(cero[i] == 0):\n        cero[i] = np.nan\n    if(uno[i] == 0):\n        uno[i] = np.nan\n    if(dos[i] == 0):\n        dos[i] = np.nan\n        \n        \ncero1 = []\nuno1 = []\ndos1 = []\n\ncero1 = (df_scale.cluster2==0).astype(int)*df_scale.DJI\nuno1 = (df_scale.cluster2==1).astype(int)*df_scale.DJI\ndos1 = (df_scale.cluster2==2).astype(int)*df_scale.DJI\n\nfor i in range(len(cero1)):\n    if(cero1[i] == 0):\n        cero1[i] = np.nan\n    if(uno1[i] == 0):\n        uno1[i] = np.nan\n    if(dos1[i] == 0):\n        dos1[i] = np.nan","729c1961":"plt.figure(figsize=(20,7))\nplt.title('Retornos de DJI seg\u00fan el Reg\u00edmen de Mercado: Clustering K-Means')\nplt.plot(cero,color='g',label=\"0\")\nplt.plot(uno,color='r',label=\"1\")\nplt.plot(dos, color = 'b',label=\"2\")\nplt.legend()\nplt.xticks([])\nplt.yticks([])\n","ff48bf98":"plt.figure(figsize=(20,7))\nplt.title('Retornos de DJI seg\u00fan el Reg\u00edmen de Mercado: Clustering Jer\u00e1rquico')\nplt.plot(cero1,color='g',label=\"0\")\nplt.plot(uno1,color='r',label=\"1\")\nplt.plot(dos1, color = 'b',label=\"2\")\nplt.legend()\nplt.xticks([])\nplt.yticks([])","7f0f4d06":"bla = df2\nplt.figure(figsize=(10,10))\nplt.subplots_adjust(left=.02, right=.98, bottom=.001, top=.96, wspace=.05,\n                    hspace=.01)\nplot_num = 1\n\ndefault_base = {'n_neighbors': 10,\n                'n_clusters': 3}\ndatasets = [\n    (bla, {'n_clusters': 2}),(bla, {'n_clusters': 3}),(bla, {'n_clusters': 4})]\n\nfor i_dataset, (dataset, algo_params) in enumerate(datasets):\n    params = default_base.copy()\n    params.update(algo_params)\n    X, y = dataset, dataset\n    X = StandardScaler().fit_transform(X)\n    ward = cluster.AgglomerativeClustering(\n        n_clusters=params['n_clusters'], linkage='ward')\n    complete = cluster.AgglomerativeClustering(\n        n_clusters=params['n_clusters'], linkage='complete')\n    average = cluster.AgglomerativeClustering(\n        n_clusters=params['n_clusters'], linkage='average')\n    single = cluster.AgglomerativeClustering(\n        n_clusters=params['n_clusters'], linkage='single')\n    clustering_algorithms = (\n        ('Single Linkage', single),\n        ('Average Linkage', average),\n        ('Complete Linkage', complete),\n        ('Ward Linkage', ward),\n    )\n    for name, algorithm in clustering_algorithms:\n        t0 = time.time() \n        with warnings.catch_warnings():\n            warnings.filterwarnings(\n                \"ignore\",\n                message=\"the number of connected components of the \" +\n                \"connectivity matrix is [0-9]{1,2}\" +\n                \" > 1. Completing it to avoid stopping the tree early.\",\n                category=UserWarning)\n            algorithm.fit(X)\n        t1 = time.time()\n        if hasattr(algorithm, 'labels_'):\n            y_pred = algorithm.labels_.astype(np.int)\n        else:\n            y_pred = algorithm.predict(X)\n        plt.subplot(len(datasets), len(clustering_algorithms), plot_num)\n        if i_dataset == 0:\n            plt.title(name, size=9)\n        colors = np.array(list(islice(cycle(['#377eb8', '#ff7f00', '#4daf4a',\n                                             '#f781bf', '#a65628', '#984ea3',\n                                             '#999999', '#e41a1c', '#dede00']),\n                                      int(max(y_pred) + 1))))\n        plt.scatter(X[:, 0], X[:, 1], s=10, color=colors[y_pred])\n        plt.xlim(-2.5, 2.5)\n        plt.ylim(-2.5, 2.5)\n        plt.xticks(())\n        plt.yticks(())\n        plt.text(.99, .01, ('%.2fs' % (t1 - t0)).lstrip('0'),\n                 transform=plt.gca().transAxes, size=15,\n                 horizontalalignment='right')\n        plot_num += 1\nplt.show()","f08b4ed1":"Como era de esperarse, el clustering describe 3 clusters que son correspondientes a los reg\u00edmenes naturales de mercado. Existe un reg\u00edmen dominante, que lo caracteriza en promedio retornos aproximadamente de cero, mientras que el siguiente reg\u00edmen m\u00e1s frecuente es parecido a un estado bullish, ya que trae consigo retornos positivos. Por \u00faltimo el reg\u00edmen menos frecuente en este mercado es el de retornos negativos o bear.","08dec271":"Es necesario tener en cuenta que el clustering se realizo a nivel de mercado y por eso es v\u00e1lido tener las acciones como variables, ya que se quiere identificar los reg\u00edmenes a nivel de mercado, es decir, sobre el comportamiento del Dow Jones. Sin embargo se pueden identificar los reg\u00edmenes de mercado que tan congruentes son con el comportamiento de las diversas acciones.\n\nY para no perder la costumbre de trabajar con la acci\u00f3n que m\u00e1s se ha estudiado en t\u00e9rminos cuantitativos, se realizar\u00e1 un gr\u00e1fico del comportamiento de los retornos de Apple a lo largo de los 5 a\u00f1os de estudio identificando con colores los diversos clusters a lo largo de la trayectoria de los retornos.","0cd4f3c3":"Ahora se esta utilizando otra libreria para realizar el clustering jerarquico. Por lo tanto, ser\u00e1 necesario trabajar con matrices en vez del dataframe de pandas.","90548b27":"Ahora es necesario identificar si ambas metodolog\u00edas de clustering arrojan resultados similares. Para ello graficar\u00e9 ambos resultados asociados al \u00edndice de mercado.","a7dc1812":"Es v\u00e1lido comparar los resultados del clustering realizado previamente con K-Means ahora con un m\u00e9todo de de **clustering** denominado **jerarquico**. Ahora el interrogante es si estos algoritmos detectan de igual forma los reg\u00edmenes del mercado. Para ello se realizar\u00e1 el mismo proceso de estandarizaci\u00f3n y enriquecimiento de los datos.","97418c14":"Al ser el retorno medio tan cercano a cero, se esperar\u00eda que se cumpliera que los retornos son estacionarios con media cero. Ahora se proceder\u00e1 a reemplazar los valores faltantes en SWDP con el retorno medio del mercado.","e0bc79a7":"Se puede observar que el n\u00famero \u00f3ptimo de clusters estar\u00eda entre 2 y 3, bajo mi criterio es \u00f3ptimo abordar el clustering con *k = 3*. Esperar\u00eda que estos tres clusters explicaran los tres posibles reg\u00edmenes de mercado, estable, bull y bear.","bc6fc387":"Se puede observar que la mayor\u00eda de las acciones se encuentran correlacionadas positivamente, mientras que existe un grupo de 4 acciones (WBA, DWDP, XOM e IBM) que se encuentran correlacionadas negativamente con las dem\u00e1s acciones del Dow Jones dentro de esta muestra. \n\nSi se observa el denogr\u00e1ma (margen izquierdo) este grupo de acciones correlacionadas negativamente, las clasificar\u00eda en un cluster aparte de las que se relacionan positivamente. Esto puede ser muy \u00fatil para quienes buscan formular estrategias en trading algoritmico como pairs trading o coberturas.\n\nEn los siguientes dos gr\u00e1ficos (volumen y retornos) no se pueden sacar conclusiones tan claras en terminos de clustering jerarquico. Se puede observar que el criterio de correlaci\u00f3n no es muy diciente ya que no se pueden observar grupos o patrones dentro del mapa de calor.","6b4ea681":"Ahora me gustar\u00eda analizar los resultados del clustering por medio de ambos clustering. Pero en este caso compondre un indice de mercado basado en las 30 acciones, te\u00f3ricamente ser\u00e1 similar a el \u00edndice el Dow Jones pero con pesos iguales todas las acciones. ","f7404ed9":"En esta secci\u00f3n busco crear tres bases de datos, estas son:\n\n* *close*: dataframe donde se encuentran los precios de cierre de las 30 acciones mencionadas previamente.\n* *volume*: dataframe donde se encuentran los vol\u00famenes tranzados de las 30 acciones mencionadas previamente.\n* *change*: dataframe donde se encuentran los retornos d\u00edarios de las 30 acciones mencionadas previamente.\n\nEn cada una de las bases de datos las columnas ser\u00e1n el nombre de las 30 acciones.","cf36337d":"Considero \u00f3ptimo realizar el clustering en t\u00e9rminos de los retornos. El porqu\u00e9 se basa en que al estandarizar la informaci\u00f3n para evitar un sesgo en el proceso de clustering, los precios de cierre se acercar\u00e1n a los retornos y el volumen no me permitir\u00eda tener conclusiones precisas acerca del estado del mercado en t\u00e9rminos agregados.\n\nLa base de datos de los retornos se ver\u00e1 as\u00ed despues del proceso de estandarizaci\u00f3n:","c154f6a3":"Para entender que quiere decir cada cluster es necesario observar el comportamiento promedio de las acciones dentro de cada cluster.","fd807f7c":"La frecuencia de los clusters empieza a mostrar que la distribuci\u00f3n dentro de los clusters es similar al encontrado en K-Means.","6686abe4":"As\u00ed se visualiza la distribuci\u00f3n de los clusters:","b2931f3b":"Ahora quiero saber como se encuentran correlacionadas las acciones con las que se estan trabajando. As\u00ed mismo, este gr\u00e1fico de correlaci\u00f3n ayuda a observar como se llevar\u00eda acabo el proceso de clustering jerarquico teniendo en cuenta que la medida de distancia en este caso ser\u00eda la correlaci\u00f3n.\n\nEste ejercicio ser realizo para las tres bases. A continuaci\u00f3n el mapa de calor de los precios de cierre:","019c094e":"Este es un ejemplo de como vienen las bases de datos de las distintas acciones. En este caso es la informaci\u00f3n correspondiente a el ticker PFE, que es Pfizer:","a6f2fd14":"Al observar el gr\u00e1fico anterior, se puede observar que la \u00fanica acci\u00f3n que tiene problemas de completitud es Dow Chemical Company (DWDP). Por ello se realizar\u00e1 un ejercicio de poblamiento de la acci\u00f3n por medio del retorno promedio del mercado (promedio de toda la base de datos).","fdafa9cb":"Ahora por medio de los componentes principales se busca visualizar la distribuci\u00f3n de los clusters en este caso.","b91997aa":"Ahora quiero saber exactamente cuales son los archivos y los tickers de las acciones que provee IEX Finance en este set de bases de datos.","cdd2c3e4":"Se proceder\u00e1 a realizar el clustering con el mismo n\u00famero de clusters para poder comparar los resultados con la anterior secci\u00f3n. Es decir, se tendr\u00e1n los mismos 3 reg\u00edmenes de mercado en ambos tipos de clustering.","c20e3389":"Se busca tratar de representar la l\u00f3gica del clustering por medio de un denograma, pero la verdad debido a la dimensinalidad del problema, se torna un poco complicado.","2000b525":"Este conjunto de bases de datos posee 30 de las acciones que componen el conocido \u00edndice del mercado estadounidense Dow Jones. \nPosee para cada una de las acciones informaci\u00f3n de los \u00faltimos 5 a\u00f1os con frecuencia d\u00edaria. Los campos de interes para este analisis son:\n\n* *close*: Es el precio de cierre de la acci\u00f3n en la fecha *t*.\n* *volume*: Es el volumen tranzado de la acci\u00f3n en la fecha *t*.\n* *change*: Es el retorno respecto al d\u00eda anterior de la acci\u00f3n en la fecha *t*.","87a92af0":"Como se puede observar, se cuentan con 1258 registros, lo cual equivale a 5 a\u00f1os de informaci\u00f3n d\u00edaria para cada acci\u00f3n.","84bff48e":"Para realizar un clustering eficiente, es necesario identificar que par\u00e1metros me ayudan a explicar mejor los datos bajo cierto modelo.\nPor ello empezar\u00e9 haciendo uso del algoritmo de clustering conocido como K-Means. Para identificar cual es el n\u00famero \u00f3ptimo de clusters (*k*) se construye el diagr\u00e1ma de codo para tratar de visualizar las din\u00e1micas de la *inertia* a medida que se aumentan el n\u00famero de clusters. ","8354a80d":"Se puede concluir que el clustering jerarquico completo ser\u00eda un agrupamiento conservador en t\u00e9rminos de riesgo. Es claro que los retornos que se encuentran alrededor del cero (\"la mitad\") tienen una banda mas amplia en el caso jerarquico, mientras que los outlayers positivos y negativos son clasificados fuera del cluster de retornos de mercado \"estable\".\n\nEl clustering basado en K-Means ser\u00eda un clustering con perfil de riesgo m\u00e1s arriesgado, ya que la banda que comprende los valores de retornos de mercado \"estable\" es menos amplia y considera outlayers un poco m\u00e1s bajos.\n\nEstos clustering pueden ser usados en procesos de trading algor\u00edtmico para formular estrategias basados en los reg\u00edmenes de mercado en que se encuentre el mercado.","1ceafd95":"As\u00ed es la estructura de las bases:","c9a8f1c0":"Para terminar... Me parece v\u00e1lido realizar un ejercicio de eficiencia del clustering jer\u00e1rquico aglomerante. Se realizo el ejercicio para la base de datos de los retornos, iternado el n\u00famero de clusters de 2 a 4 (la primera fila del panel de gr\u00e1ficos es con 2 clusters y aumenta de a un cluster a traves de las filas) y de igual forma se midio el tiempo que requer\u00eda cada proceso.","97cfbab5":"Ahora quiero saber como es la distribuci\u00f3n de los clusters. Como se puede observar en el histograma existe dominancia de un cluster dentro de este mercado.","f92db6d3":"Para verificar que se tengan las mismas dimensiones que el dataframe...","f4f9a9c3":"Para corroborar, es necesario hacer un an\u00e1lisis de completitud de la informaci\u00f3n de las acciones.","f34ce7fc":"En t\u00e9rminos de eficiencia de clustering y tiempo el m\u00e9todo \"complete\" es el m\u00e1s eficiente, aunque la diferencia es marginal."}}