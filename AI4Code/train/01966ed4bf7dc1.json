{"cell_type":{"9365cd54":"code","a77f3718":"code","095ba6ca":"code","f18ec948":"code","d87017c1":"code","55a27ba1":"code","16b8211b":"code","f604a1e6":"code","0be8de8f":"code","84234fc2":"code","561f0ed7":"code","9718cf0b":"code","b6c848bd":"code","1117502a":"code","c17c3d05":"code","897e8f75":"code","16a899c0":"code","e71fca8c":"code","20ac974b":"code","60ffa07a":"code","40e6546c":"code","28cdecee":"code","6bfb381d":"code","288c513f":"code","2b5a3719":"code","b9f96240":"code","f23a78b4":"code","0fe26d0e":"code","f6d38f5c":"code","d0c8dd23":"code","9ccf3b84":"code","dca6f85f":"code","86757800":"code","02b76d28":"code","3faa79cc":"code","71473577":"code","65014ca3":"code","122fbe09":"code","7249aad7":"code","6f0b8685":"code","ba916158":"code","fd0546fb":"code","dbff889e":"code","f06b8716":"code","78496697":"code","7ee84a17":"code","94348c25":"code","96950639":"code","8d486f2e":"code","8efe264b":"code","95f6bc6d":"code","7dbdf4e5":"code","5b8a1bbd":"code","7e785c73":"code","7a5f9a16":"code","ed1c7e94":"code","6855b53c":"code","797565c3":"code","1e572430":"code","920e2cb4":"code","2251ae1b":"code","529a0030":"code","b800b6f1":"code","8004f774":"code","8003222f":"code","59a44b60":"code","60e67237":"code","50ccaadd":"code","7ae4a5df":"code","1a512214":"code","b4312a75":"code","f75a0b45":"code","8915d908":"code","cbb14073":"code","47e03022":"code","c6369c94":"code","1cc16ec9":"code","e0dd8677":"code","dbb742bd":"code","218df21a":"code","d65f8a4a":"code","215b89ab":"code","45369db1":"code","4cf9b481":"code","8503fa96":"code","9565577d":"code","f9ff85f7":"code","0321c7c0":"code","c5dbc894":"code","b80ec998":"code","c09fca6d":"code","42d84688":"code","c0d46af8":"code","c4693056":"code","651c540e":"code","8cc25c5c":"code","d79020a7":"code","76b3515e":"code","787353c5":"markdown","23c92c3c":"markdown","ab40bcaa":"markdown","ac5c2573":"markdown","e9fe6cab":"markdown","ba3cad63":"markdown","bc435984":"markdown","8661db1d":"markdown","172a4fb6":"markdown","8eb66bda":"markdown","24d6906d":"markdown","03c9c5eb":"markdown","d5340c43":"markdown","9a3c52de":"markdown","0d1a0f1e":"markdown","a078bc25":"markdown","086a791d":"markdown","234fc427":"markdown","6cc1c6ae":"markdown","f3a66104":"markdown","186a5b68":"markdown","7c03b098":"markdown","54f0ce7a":"markdown","8330be24":"markdown","6a1574fc":"markdown","956fe5ec":"markdown","8c474287":"markdown","971dda91":"markdown","b8c9bc07":"markdown","50be9ea8":"markdown","1f22c959":"markdown","4a51d371":"markdown","4f9fbe8d":"markdown","d0f6c482":"markdown","5948f076":"markdown","9c353e13":"markdown","aebcdf77":"markdown","4d2eb5fd":"markdown","c2dd90be":"markdown","f3163600":"markdown","90d73ce7":"markdown","224d61d0":"markdown","b061bbdd":"markdown","487baf4b":"markdown","19742674":"markdown","93436b1e":"markdown","f77d8710":"markdown"},"source":{"9365cd54":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a77f3718":"import numpy as np\nimport pandas as pd\nimport random\n\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score as r2\nfrom sklearn.model_selection import KFold, GridSearchCV\n\nfrom datetime import datetime\n\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","095ba6ca":"import warnings\nwarnings.filterwarnings('ignore')","f18ec948":"matplotlib.rcParams.update({'font.size': 14})","d87017c1":"def evaluate_preds(train_true_values, train_pred_values, test_true_values, test_pred_values):\n    print(\"Train R2:\\t\" + str(round(r2(train_true_values, train_pred_values), 3)))\n    print(\"Test R2:\\t\" + str(round(r2(test_true_values, test_pred_values), 3)))\n    \n    plt.figure(figsize=(18,10))\n    \n    plt.subplot(121)\n    sns.scatterplot(x=train_pred_values, y=train_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Train sample prediction')\n    \n    plt.subplot(122)\n    sns.scatterplot(x=test_pred_values, y=test_true_values)\n    plt.xlabel('Predicted values')\n    plt.ylabel('True values')\n    plt.title('Test sample prediction')\n\n    plt.show()","55a27ba1":"TRAIN_DATASET_PATH = '\/kaggle\/input\/real-estate-price-prediction-moscow\/train.csv'\nTEST_DATASET_PATH = '\/kaggle\/input\/real-estate-price-prediction-moscow\/test.csv'","16b8211b":"RNDM = 21","f604a1e6":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntrain_df.tail()","0be8de8f":"train_df.dtypes","84234fc2":"test_df = pd.read_csv(TEST_DATASET_PATH)\ntest_df.tail()","561f0ed7":"print('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0440\u0435\u0439\u043d\u0435:', train_df.shape[0])\nprint('\u0421\u0442\u0440\u043e\u043a \u0432 \u0442\u0435\u0441\u0442\u0435', test_df.shape[0])","9718cf0b":"train_df.shape[1] - 1 == test_df.shape[1]","b6c848bd":"train_df.dtypes","1117502a":"train_df['Id'] = train_df['Id'].astype(str)\ntrain_df['DistrictId'] = train_df['DistrictId'].astype(str)","c17c3d05":"plt.figure(figsize = (16, 8))\n\ntrain_df['Price'].hist(bins=30)\nplt.ylabel('Count')\nplt.xlabel('Price')\n\nplt.title('Target distribution')\nplt.show()","897e8f75":"train_df.describe()","16a899c0":"df_num_features = train_df.select_dtypes(include=['float64', 'int64'])\ndf_num_features.drop('Price', axis=1, inplace=True)\ndf_num_features.hist(figsize=(16,16), bins=20, grid=False);","e71fca8c":"train_df.select_dtypes(include='object').columns.tolist()","20ac974b":"train_df['DistrictId'].value_counts()","60ffa07a":"train_df['Ecology_2'].value_counts()","40e6546c":"train_df['Ecology_3'].value_counts()","28cdecee":"train_df['Shops_2'].value_counts()","6bfb381d":"train_df.loc[train_df['Square'] < 3, 'Square'] = 3","288c513f":"train_df['Rooms'].value_counts()","2b5a3719":"train_df['Rooms_outlier'] = 0\ntrain_df.loc[(train_df['Rooms'] == 0) | (train_df['Rooms'] >= 6), 'Rooms_outlier'] = 1\ntrain_df.head()","b9f96240":"train_df.loc[train_df['Rooms'] == 0, 'Rooms'] = 1","f23a78b4":"temp_df = train_df.loc[train_df['Rooms'] < 6]\nSquare_Rooms_K = (temp_df['Square'] \/ temp_df['Rooms']).median()\nSquare_Rooms_K","0fe26d0e":"train_df.loc[train_df['Rooms'] >= 6, 'Rooms'] = round(train_df['Square'] \/ Square_Rooms_K)","f6d38f5c":"train_df['Rooms'].value_counts()","d0c8dd23":"train_df['KitchenSquare'].value_counts()","9ccf3b84":"train_df['KitchenSquare'].quantile(.975), train_df['KitchenSquare'].quantile(.025)","dca6f85f":"temp_df = train_df.loc[train_df['KitchenSquare'] < train_df['Square']]\nSquare_KitchenSquare_K = (temp_df['Square'] \/ temp_df['KitchenSquare']).median()\nSquare_KitchenSquare_K","86757800":"condition = (train_df['KitchenSquare'].isna()) \\\n             | (train_df['KitchenSquare'] > train_df['KitchenSquare'].quantile(.975))","02b76d28":"train_df.loc[condition, 'KitchenSquare'] = round(train_df['Square'] \/ Square_KitchenSquare_K)\n\ntrain_df.loc[train_df['KitchenSquare'] < 3, 'KitchenSquare'] = 3","3faa79cc":"train_df['KitchenSquare'].value_counts()","71473577":"train_df['HouseFloor'].sort_values().unique()","65014ca3":"train_df['Floor'].sort_values().unique()","122fbe09":"(train_df['Floor'] > train_df['HouseFloor']).sum()","7249aad7":"train_df['HouseFloor_outlier'] = 0\ntrain_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\ntrain_df.loc[train_df['Floor'] > train_df['HouseFloor'], 'HouseFloor_outlier'] = 1","6f0b8685":"train_df.loc[train_df['HouseFloor'] == 0, 'HouseFloor'] = train_df['HouseFloor'].median()","ba916158":"floor_outliers = train_df.loc[train_df['Floor'] > train_df['HouseFloor']].index\nfloor_outliers","fd0546fb":"# train_df.loc[floor_outliers, 'Floor'] = train_df.loc[floor_outliers, 'HouseFloor']\\\n#                                                 .apply(lambda x: random.randint(1, x))\n# \u0438\u0441\u043f\u0440\u0430\u0432\u0438\u043b \u044d\u0442\u0430\u0436\u043d\u043e\u0441\u0442\u044c, \u0430 \u043d\u0435 \u044d\u0442\u0430\u0436\n\ntrain_df.loc[floor_outliers, 'HouseFloor'] = train_df.loc[floor_outliers, 'Floor']","dbff889e":"(train_df['Floor'] > train_df['HouseFloor']).sum()","f06b8716":"train_df['HouseYear'].sort_values(ascending=False)","78496697":"train_df.loc[train_df['HouseYear'] > 2020, 'HouseYear'] = 2020\ntrain_df.loc[train_df['HouseYear'] < 1900, 'HouseYear'] = 1900","7ee84a17":"train_df.isna().sum()","94348c25":"train_df[['Square', 'LifeSquare', 'KitchenSquare']].head(10)","96950639":"train_df['LifeSquare_nan'] = train_df['LifeSquare'].isna() * 1\n\ncondition = (train_df['LifeSquare'].isna()) \\\n             & (~train_df['Square'].isna()) \\\n             & (~train_df['KitchenSquare'].isna())\n        \ntrain_df.loc[condition, 'LifeSquare'] = train_df.loc[condition, 'Square'] \\\n                                            - train_df.loc[condition, 'KitchenSquare'] - 3","8d486f2e":"train_df.drop('Healthcare_1', axis=1, inplace=True)","8efe264b":"class DataPreprocessing:\n    \"\"\"\u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0438\u0441\u0445\u043e\u0434\u043d\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n    def __init__(self):\n        \"\"\"\u041f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u044b \u043a\u043b\u0430\u0441\u0441\u0430\"\"\"\n        self.medians=None\n        self.kitchen_square_quantile = None\n        self.temp_df = None\n        \n        \n    def fit(self, X):\n        \"\"\"\u0421\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u0438\u0435 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\"\"\"       \n        # \u0420\u0430\u0441\u0447\u0435\u0442 \u043c\u0435\u0434\u0438\u0430\u043d\n        self.medians = X.median()\n        self.kitchen_square_quantile = X['KitchenSquare'].quantile(.975)\n        \n    \n    def transform(self, X):\n        \"\"\"\u0422\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u044f \u0434\u0430\u043d\u043d\u044b\u0445\"\"\"\n\n        # Square\n        X.loc[X['Square'] < 3, 'Square'] = 3\n        \n        # Rooms\n        X['Rooms_outlier'] = 0\n        X.loc[(X['Rooms'] == 0) | (X['Rooms'] >= 6), 'Rooms_outlier'] = 1\n        \n        X.loc[X['Rooms'] == 0, 'Rooms'] = 1\n        \n        self.temp_df = X.loc[X['Rooms'] < 6]\n        Square_Rooms_K = (self.temp_df['Square'] \/ self.temp_df['Rooms']).median()\n        X.loc[X['Rooms'] >= 6, 'Rooms'] = round(X['Square'] \/ Square_Rooms_K)\n                \n        # KitchenSquare\n        self.temp_df = X.loc[X['KitchenSquare'] < X['Square']]\n        Square_KitchenSquare_K = (self.temp_df['Square'] \/ self.temp_df['KitchenSquare']).median()\n        condition = (X['KitchenSquare'].isna()) \\\n                    | (X['KitchenSquare'] > self.kitchen_square_quantile)\n        \n        X.loc[condition, 'KitchenSquare'] = round(X['Square'] \/ Square_KitchenSquare_K)\n        X.loc[X['KitchenSquare'] < 3, 'KitchenSquare'] = 3\n        \n        # HouseFloor, Floor\n        X['HouseFloor_outlier'] = 0\n        X.loc[X['HouseFloor'] == 0, 'HouseFloor_outlier'] = 1\n        X.loc[X['Floor'] > X['HouseFloor'], 'HouseFloor_outlier'] = 1\n        \n        X.loc[X['HouseFloor'] == 0, 'HouseFloor'] = self.medians['HouseFloor']\n        \n        floor_outliers = X.loc[X['Floor'] > X['HouseFloor']].index\n#         X.loc[floor_outliers, 'Floor'] = X.loc[floor_outliers, 'HouseFloor']\\\n#                                             .apply(lambda x: random.randint(1, x))\n        X.loc[floor_outliers, 'HouseFloor'] = X.loc[floor_outliers, 'Floor']\n        \n        # HouseYear\n        current_year = datetime.now().year\n        \n        X['HouseYear_outlier'] = 0\n        X.loc[X['HouseYear'] > current_year, 'HouseYear_outlier'] = 1\n        X.loc[X['HouseYear'] < 1900, 'HouseYear_outlier'] = 1\n        \n        X.loc[X['HouseYear'] > current_year, 'HouseYear'] = current_year\n        X.loc[X['HouseYear'] < 1900, 'HouseYear'] = 1900\n        \n        # Healthcare_1\n        if 'Healthcare_1' in X.columns:\n            X.drop('Healthcare_1', axis=1, inplace=True)\n            \n        # LifeSquare\n        X['LifeSquare_nan'] = X['LifeSquare'].isna() * 1\n        condition = (X['LifeSquare'].isna()) & \\\n                      (~X['Square'].isna()) & \\\n                      (~X['KitchenSquare'].isna())\n        \n        X.loc[condition, 'LifeSquare'] = X.loc[condition, 'Square'] - X.loc[condition, 'KitchenSquare'] - 3\n        \n        \n        X.fillna(self.medians, inplace=True)\n        \n        return X","95f6bc6d":"train_df_corr = train_df.corr()\nimport seaborn as sns\nplt.figure(figsize = (16,8))\nsns.set(font_scale=0.8)\ntrain_df_corr_round = np.round(train_df_corr, 2)\ntrain_df_corr_round[np.abs(train_df_corr) < 0.3] = 0\nsns.heatmap(train_df_corr_round, annot=True, linewidths=.5, cmap='coolwarm')\nplt.show()","7dbdf4e5":"binary_to_numbers = {'A': 0, 'B': 1}\n\ntrain_df['Ecology_2'] = train_df['Ecology_2'].replace(binary_to_numbers)\ntrain_df['Ecology_3'] = train_df['Ecology_3'].replace(binary_to_numbers)\ntrain_df['Shops_2'] = train_df['Shops_2'].replace(binary_to_numbers)","5b8a1bbd":"district_size = train_df['DistrictId'].value_counts().reset_index()\\\n                    .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n\ndistrict_size.head()","7e785c73":"train_df = train_df.merge(district_size, on='DistrictId', how='left')\ntrain_df.head()","7a5f9a16":"(train_df['DistrictSize'] > 100).value_counts()","ed1c7e94":"train_df['IsDistrictLarge'] = (train_df['DistrictSize'] > 100).astype(int)","6855b53c":"med_price_by_district = train_df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                            .rename(columns={'Price':'MedPriceByDistrict'})\n\nmed_price_by_district.head()","797565c3":"train_df = train_df.merge(med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\ntrain_df.head()","1e572430":"def floor_to_cat(X):\n\n    X['floor_cat'] = 0\n\n    X.loc[X['Floor'] <= 3, 'floor_cat'] = 1  \n    X.loc[(X['Floor'] > 3) & (X['Floor'] <= 5), 'floor_cat'] = 2\n    X.loc[(X['Floor'] > 5) & (X['Floor'] <= 9), 'floor_cat'] = 3\n    X.loc[(X['Floor'] > 9) & (X['Floor'] <= 15), 'floor_cat'] = 4\n    X.loc[X['Floor'] > 15, 'floor_cat'] = 5\n\n    return X\n\n\ndef floor_to_cat_pandas(X):\n    bins = [0, 3, 5, 9, 15, X['Floor'].max()]\n    X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n    \n    X['floor_cat'].fillna(-1, inplace=True)\n    return X\n\n\ndef year_to_cat(X):\n\n    X['year_cat'] = 0\n\n    X.loc[X['HouseYear'] <= 1941, 'year_cat'] = 1\n    X.loc[(X['HouseYear'] > 1941) & (X['HouseYear'] <= 1945), 'year_cat'] = 2\n    X.loc[(X['HouseYear'] > 1945) & (X['HouseYear'] <= 1980), 'year_cat'] = 3\n    X.loc[(X['HouseYear'] > 1980) & (X['HouseYear'] <= 2000), 'year_cat'] = 4\n    X.loc[(X['HouseYear'] > 2000) & (X['HouseYear'] <= 2010), 'year_cat'] = 5\n    X.loc[(X['HouseYear'] > 2010), 'year_cat'] = 6\n\n    return X\n\n\ndef year_to_cat_pandas(X):\n    bins = [0, 1941, 1945, 1980, 2000, 2010, X['HouseYear'].max()]\n    X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n    \n    X['year_cat'].fillna(-1, inplace=True)\n    return X","920e2cb4":"bins = [0, 3, 5, 9, 15, train_df['Floor'].max()]\npd.cut(train_df['Floor'], bins=bins, labels=False)","2251ae1b":"bins = [0, 3, 5, 9, 15, train_df['Floor'].max()]\npd.cut(train_df['Floor'], bins=bins)","529a0030":"train_df = year_to_cat(train_df)\ntrain_df = floor_to_cat(train_df)\ntrain_df.head()","b800b6f1":"med_price_by_floor_year = train_df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\nmed_price_by_floor_year.head()","8004f774":"train_df = train_df.merge(med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\ntrain_df.head()","8003222f":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ncolnames = train_df.columns\ntrain_df_scaled = pd.DataFrame(scaler.fit_transform(train_df), columns=colnames)","59a44b60":"train_df_scaled.head()","60e67237":"from sklearn.manifold import TSNE","50ccaadd":"def reduce_dims(df, dims=2, method='pca', perplexity=30):\n    \n    assert method in ['pca', 'tsne'], '\u041d\u0435\u0432\u0435\u0440\u043d\u043e \u0443\u043a\u0430\u0437\u0430\u043d \u043c\u0435\u0442\u043e\u0434'\n    \n    if method=='pca':\n        dim_reducer = PCA(n_components=dims, random_state=42)\n        components = dim_reducer.fit_transform(df)\n    elif method == 'tsne':\n        dim_reducer = TSNE(n_components=dims, learning_rate=250, random_state=42, perplexity=perplexity)\n        components = dim_reducer.fit_transform(df)\n    else:\n        print('Error')\n        \n    colnames = ['component_' + str(i) for i in range(1, dims+1)]\n    return dim_reducer, pd.DataFrame(data = components, columns = colnames) ","7ae4a5df":"def display_components_in_2D_space(components_df, labels=None):\n    components_with_labels_df = pd.concat([components_df, pd.DataFrame(labels)], axis=1)\n\n    figsize = (10, 7)\n    if labels is not None:\n        components_with_labels_df.plot(kind='scatter', x='component_1', y='component_2', \n                                         c=components_with_labels_df.iloc[:, -1], cmap=plt.get_cmap('jet'),\n                                         alpha=0.5, figsize=figsize)\n    else:\n        components_with_labels_df.plot(kind='scatter', x='component_1', y='component_2', alpha=0.5, figsize=figsize)\n\n    plt.xlabel('component_1')\n    plt.ylabel('component_2')\n    plt.title('2D mapping of objects')    \n    plt.show()\n\ndef display_components_in_3D_space(components_df, labels=None):\n    components_with_labels_df = pd.concat([components_df, pd.DataFrame(labels)], axis=1)\n\n    fig = plt.figure(figsize=(10,10))\n    ax = fig.add_subplot(111, projection='3d')\n    \n    if labels is not None:\n        ax.scatter(components_with_labels_df['component_1'], \n                   components_with_labels_df['component_2'], \n                   components_with_labels_df['component_3'], \n                   c=components_with_labels_df.iloc[:, -1], \n                   cmap=plt.get_cmap('jet'), alpha=0.5)\n    else:\n        ax.scatter(components_with_labels_df['component_1'], \n                   components_with_labels_df['component_2'], \n                   components_with_labels_df['component_3'], \n                   alpha=0.5)\n\n    ax.set_xlabel('component_1')\n    ax.set_ylabel('component_2')\n    ax.set_zlabel('component_3')\n    plt.title('3D mapping of objects')\n    plt.show()","1a512214":"from sklearn.cluster import KMeans","b4312a75":"from scipy.spatial.distance import cdist","f75a0b45":"def apply_elbow_method(X):\n    \"\"\"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0434\u043b\u044f \u043c\u0435\u0442\u043e\u0434\u0430 '\u043b\u043e\u043a\u0442\u044f'\"\"\"\n    \n    distortions = []\n    K = range(2,30)\n    for k in K:\n        kmeanModel = KMeans(n_clusters=k, random_state=RNDM).fit(X)\n        distortions.append(sum(np.min(cdist(X, kmeanModel.cluster_centers_, 'euclidean'), axis=1)) \/ X.shape[0])\n\n    plt.figure(figsize=(10, 8))\n    plt.plot(K, distortions, 'bx-')\n    plt.xlabel('k')\n    plt.ylabel('Distortion')\n    plt.title('The Elbow Method showing the optimal k')\n    plt.show()","8915d908":"def display_clusters_distribution(unique_labels, labels_counts):\n    \"\"\"\u0412\u0438\u0437\u0443\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u043f\u043e \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0430\u043c\"\"\"\n    plt.figure(figsize=(8,5))\n\n    plt.bar(unique, counts)\n\n    plt.xlabel('Clusters')\n    plt.xticks(unique)\n    plt.ylabel('Count')\n    plt.title('Clusters distribution')\n    plt.show()","cbb14073":"kmeans_n = KMeans(n_clusters=8, random_state=RNDM)\nlabels_clast_n = kmeans_n.fit_predict(train_df_scaled)\nlabels_clast_n = pd.Series(labels_clast_n, name='clusters_n')\n\nunique, counts = np.unique(labels_clast_n, return_counts=True)\ndisplay_clusters_distribution(unique, counts)","47e03022":"clusters_n_dummies = pd.get_dummies(labels_clast_n, drop_first=True, prefix='clusters')\n\ntrain_df_cluster = pd.concat([train_df_scaled, clusters_n_dummies], axis=1)\ntrain_df_cluster.head()","c6369c94":"class FeatureGenetator():\n    \"\"\"\u0413\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u044f \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447\"\"\"\n    \n    def __init__(self):\n        self.DistrictId_counts = None\n        self.binary_to_numbers = None\n        self.med_price_by_district = None\n        self.med_price_by_floor_year = None\n        self.house_year_max = None\n        self.floor_max = None\n        \n    def fit(self, X, y=None):\n        \n        X = X.copy()\n        \n        # Binary features\n        self.binary_to_numbers = {'A': 0, 'B': 1}\n        \n        # DistrictID\n        self.district_size = X['DistrictId'].value_counts().reset_index() \\\n                               .rename(columns={'index':'DistrictId', 'DistrictId':'DistrictSize'})\n                \n        # Target encoding\n        ## District, Rooms\n        df = X.copy()\n        \n        if y is not None:\n            df['Price'] = y.values\n            \n            self.med_price_by_district = df.groupby(['DistrictId', 'Rooms'], as_index=False).agg({'Price':'median'})\\\n                                            .rename(columns={'Price':'MedPriceByDistrict'})\n            \n            self.med_price_by_district_median = self.med_price_by_district['MedPriceByDistrict'].median()\n            \n        ## floor, year\n        if y is not None:\n            self.floor_max = df['Floor'].max()\n            self.house_year_max = df['HouseYear'].max()\n            df['Price'] = y.values\n            df = self.floor_to_cat(df)\n            df = self.year_to_cat(df)\n            self.med_price_by_floor_year = df.groupby(['year_cat', 'floor_cat'], as_index=False).agg({'Price':'median'}).\\\n                                            rename(columns={'Price':'MedPriceByFloorYear'})\n            self.med_price_by_floor_year_median = self.med_price_by_floor_year['MedPriceByFloorYear'].median()\n        \n\n        \n    def transform(self, X):\n        \n        # Binary features\n        X['Ecology_2'] = X['Ecology_2'].map(self.binary_to_numbers)  # self.binary_to_numbers = {'A': 0, 'B': 1}\n        X['Ecology_3'] = X['Ecology_3'].map(self.binary_to_numbers)\n        X['Shops_2'] = X['Shops_2'].map(self.binary_to_numbers)\n        \n        # DistrictId, IsDistrictLarge\n        X = X.merge(self.district_size, on='DistrictId', how='left')\n        \n        X['new_district'] = 0\n        X.loc[X['DistrictSize'].isna(), 'new_district'] = 1\n        \n        X['DistrictSize'].fillna(5, inplace=True)\n        \n        X['IsDistrictLarge'] = (X['DistrictSize'] > 100).astype(int)\n        \n        # More categorical features\n        X = self.floor_to_cat(X)  # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 floor_cat\n        X = self.year_to_cat(X)   # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 year_cat\n        X = self.last_floor(X)   # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 last_floor\n        X = self.first_floor(X)   # + \u0441\u0442\u043e\u043b\u0431\u0435\u0446 first_floor\n        \n        \n        # Target encoding\n        if self.med_price_by_district is not None:\n            X = X.merge(self.med_price_by_district, on=['DistrictId', 'Rooms'], how='left')\n            X.fillna(self.med_price_by_district_median, inplace=True)\n            \n        if self.med_price_by_floor_year is not None:\n            X = X.merge(self.med_price_by_floor_year, on=['year_cat', 'floor_cat'], how='left')\n            X.fillna(self.med_price_by_floor_year_median, inplace=True)\n            \n            \n        # normalize\n#         scaler = StandardScaler()\n#         colnames = X.columns\n#         X = pd.DataFrame(scaler.fit_transform(X), columns=colnames)\n        # clusters\n        kmeans_n = KMeans(n_clusters=8, random_state=RNDM)\n        labels_clast_n = kmeans_n.fit_predict(X)\n        labels_clast_n = pd.Series(labels_clast_n, name='clusters_n')\n        # dummy clusters\n        clusters_n_dummies = pd.get_dummies(labels_clast_n, drop_first=True, prefix='clusters')\n        X = pd.concat([X, clusters_n_dummies], axis=1)\n        \n        return X\n    \n    def floor_to_cat(self, X):\n        bins = [0, 1, 4, 5, 8, 9, 13, 15, self.floor_max]\n        X['floor_cat'] = pd.cut(X['Floor'], bins=bins, labels=False)\n\n        X['floor_cat'].fillna(-1, inplace=True) \n        return X\n     \n    def year_to_cat(self, X):\n        bins = [0, 1941, 1945, 1980, 2000, 2010, self.house_year_max]\n        X['year_cat'] = pd.cut(X['HouseYear'], bins=bins, labels=False)\n\n        X['year_cat'].fillna(-1, inplace=True)\n        return X\n            \n    def last_floor(self, X):\n        X['last_floor'] = 0\n        X.loc[(X['Floor'] == X['HouseFloor']), 'last_floor'] = 1\n        return X\n    \n    def first_floor(self, X):\n        X['first_floor'] = 0\n        X.loc[(X['Floor'] == 1), 'first_floor'] = 1\n        return X","1cc16ec9":"train_df_cluster.columns.tolist()","e0dd8677":"feature_names = ['DistrictId', 'Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3', \n                 'Helthcare_2', 'Shops_1', 'Shops_2'] \n\nnew_feature_names = ['Rooms_outlier'] \n\ntarget_name = 'Price'","dbb742bd":"train_df = pd.read_csv(TRAIN_DATASET_PATH)\ntest_df = pd.read_csv(TEST_DATASET_PATH)\n\nX = train_df.drop(columns=target_name)\ny = train_df[target_name]","218df21a":"X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.33, shuffle=True, random_state=RNDM)","d65f8a4a":"preprocessor = DataPreprocessing()\npreprocessor.fit(X_train)\n\nX_train = preprocessor.transform(X_train)\nX_valid = preprocessor.transform(X_valid)\ntest_df = preprocessor.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","215b89ab":"features_gen = FeatureGenetator()\nfeatures_gen.fit(X_train, y_train)\n\nX_train = features_gen.transform(X_train)\nX_valid = features_gen.transform(X_valid)\ntest_df = features_gen.transform(test_df)\n\nX_train.shape, X_valid.shape, test_df.shape","45369db1":"X_train = X_train[feature_names + new_feature_names]\nX_valid = X_valid[feature_names + new_feature_names]\ntest_df = test_df[feature_names + new_feature_names]","4cf9b481":"X_train.isna().sum().sum(), X_valid.isna().sum().sum(), test_df.isna().sum().sum()","8503fa96":"%%time\nfrom sklearn.ensemble import GradientBoostingRegressor\n# from sklearn.ensemble import BaggingRegressor\n\ngb = GradientBoostingRegressor(\n                               max_depth=4,\n                               min_samples_leaf=20,\n                               random_state=RNDM,  \n                               n_estimators=150\n                              )\n\n# br = BaggingRegressor(base_estimator=gb, n_estimators=25, random_state=RNDM)\n# br.fit(X_train, y_train)","9565577d":"%%time\nrf = RandomForestRegressor(\n    random_state=RNDM, \n    max_depth=40,  # gridsearch\n    criterion='mse',\n    min_samples_leaf=5,  # gridsearch\n    n_jobs=-1,\n    n_estimators=1000  # gridsearch\n)\n# rf.fit(X_train, y_train)","f9ff85f7":"%%time\nrf2 = RandomForestRegressor(\n    random_state=RNDM, \n    max_depth=17, \n    criterion='mse',\n    max_features=7, \n    n_jobs=-1,\n    n_estimators=200  \n)\n# rf.fit(X_train, y_train)","0321c7c0":"%%time\nrf3 = RandomForestRegressor(\n    max_depth=20,\n    random_state=RNDM, \n)","c5dbc894":"%%time\nrf4 = RandomForestRegressor(\n    random_state=RNDM, \n)","b80ec998":"%%time\nimport xgboost as xgb\n\nxg=xgb.XGBRegressor(\n                  random_state=RNDM,\n                  n_estimators=5, \n                  n_jobs=-1,\n                  subsample=0.5,\n                  colsample_bynode=0.5,\n                  num_parallel_tree=100,\n                  learning_rate=0.5,\n                  max_depth=3\n                  )","c09fca6d":"%%time\nfrom sklearn.ensemble import StackingRegressor\n\nstack = StackingRegressor([\n                           ('rf', rf),\n                           ('rf2', rf2),\n#                            ('rf3', rf3),\n                           ('rf4', rf4),\n                           ('gb', gb), \n                           ('xg', xg),\n                          ],\n                          cv=5,\n                          n_jobs=-1,\n                          final_estimator=GradientBoostingRegressor(\n                               \n                               max_depth=1,\n                               random_state=RNDM,  \n                               n_estimators=85,\n                               \n                          )\n                         )\n                             \nstack.fit(X_train, y_train)","42d84688":"final_model = stack","c0d46af8":"%%time\ny_train_preds = final_model.predict(X_train)\ny_test_preds = final_model.predict(X_valid)\n\nevaluate_preds(y_train, y_train_preds, y_valid, y_test_preds)","c4693056":"test_df.shape, test_df","651c540e":"submit = pd.read_csv('\/kaggle\/input\/real-estate-price-prediction-moscow\/sample_submission.csv')\nsubmit.head()","8cc25c5c":"predictions = final_model.predict(test_df)\npredictions","d79020a7":"submit['Price'] = predictions\nsubmit.head()","76b3515e":"submit.to_csv('rf_submit.csv', index=False)","787353c5":"### 3. \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432  <a class='anchor' id='nan'>","23c92c3c":"\u0414\u043b\u044f \u043d\u0430\u0447\u0430\u043b\u0430 \u043e\u0431\u0440\u0435\u0436\u0435\u043c \u043a\u0432\u0430\u0434\u0440\u0430\u0442\u043d\u044b\u0435 \u043c\u0435\u0442\u0440\u044b","ab40bcaa":"[](http:\/\/)**\u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f**  (\u043e\u0442\u043a\u043b\u044e\u0447\u0438\u043b, \u043e\u043d\u0430 \u0435\u0441\u0442\u044c \u0432 \u0441\u0442\u0435\u043a\u0435 \u0443\u0436\u0435)","ac5c2573":"**KitchenSquare** ","e9fe6cab":"**\u041a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0435\u043d\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435**","ba3cad63":"%%time\ndim_reducer2d_tsne, components_2d_tsne = reduce_dims(train_df_scaled, dims=2, method='tsne', perplexity=50)\ndisplay_components_in_2D_space(components_2d_tsne, train_df['Price'])","bc435984":"### 6. \u0420\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0430 train \u0438 test  <a class='anchor' id='split'>","8661db1d":"### 4. \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043d\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432  <a class='anchor' id='feature'>","172a4fb6":"%%time\n\u041a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u044f (\u043e\u0442\u043a\u043b\u044e\u0447\u0438\u043b, \u043e\u043d\u0430 \u0435\u0441\u0442\u044c \u0432 \u0441\u0442\u0435\u043a\u0435 \u0443\u0436\u0435)\ncv_score = cross_val_score(final_model, X_train, y_train, scoring='r2', cv=KFold(n_splits=3, shuffle=True, random_state=RNDM))\ncv_score, cv_score.mean()","8eb66bda":"%%time\nfrom sklearn.model_selection import GridSearchCV\n\nparams = {'n_estimators':[5, 10, 20, 50, 100, 200, 400, 1000], \n          'max_depth':[3, 5, 7, 10, 20, 40],\n          'min_samples_leaf': [1, 2, 5, 10, 20, 40, 100]\n         }\n\ngs = GridSearchCV(rf, params, \n                  scoring='r2', # \u043c\u0435\u0442\u0440\u0438\u043a\u0430 \n                  cv=KFold(n_splits=5,   # k (\u043a\u043e\u043b-\u0432\u043e \u0440\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0439\/\u0438\u0442\u0435\u0440\u0430\u0446\u0438\u0439) \u0432 \u043a\u0440\u043e\u0441\u0441-\u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438\n                           random_state=RNDM, \n                           shuffle=True),\n                  n_jobs=-1\n                  )\ngs.fit(X_train, y_train)\nres = pd.DataFrame(gs.cv_results_)\nres.head(2), gs.best_params_, gs.best_score_","24d6906d":"### \u041f\u0440\u0438\u0432\u0435\u0434\u0435\u043d\u0438\u0435 \u0442\u0438\u043f\u043e\u0432","03c9c5eb":"apply_elbow_method(train_df_scaled)","d5340c43":"**\u041d\u043e\u043c\u0438\u043d\u0430\u0442\u0438\u0432\u043d\u044b\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u044b\u0435**","9a3c52de":"### 7. \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438  <a class='anchor' id='modeling'>","0d1a0f1e":"#### \u041d\u043e\u0440\u043c\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f","a078bc25":"**DistrictSize, IsDistrictLarge**","086a791d":"### 8. \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435  <a class='anchor' id='prediction'>\n\n1. \u0412\u044b\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u0434\u043b\u044f \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u0442\u0435 \u0436\u0435 \u044d\u0442\u0430\u043f\u044b \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0438 \u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u043d\u0438\u044f\u043d\u0438\u044f \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432\n2. \u041d\u0435 \u043f\u043e\u0442\u0435\u0440\u044f\u0442\u044c \u0438 \u043d\u0435 \u043f\u0435\u0440\u0435\u043c\u0435\u0448\u0430\u0442\u044c \u0438\u043d\u0434\u0435\u043a\u0441\u044b \u043e\u0442 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u043f\u0440\u0438 \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0438 \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u043e\u0432\n3. \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u044b \u0434\u043e\u043b\u0436\u043d\u044b \u0431\u044b\u0442\u044c \u0434\u043b\u044f \u0432\u0441\u0435 \u043f\u0440\u0438\u043c\u0435\u0440\u043e\u0432 \u0438\u0437 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0433\u043e \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 (\u0434\u043b\u044f \u0432\u0441\u0435\u0445 \u0441\u0442\u0440\u043e\u043a)","234fc427":"**Rooms**","6cc1c6ae":"### 2. \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432  <a class='anchor' id='outlier'>\n\u0427\u0442\u043e \u043c\u043e\u0436\u043d\u043e \u0434\u0435\u043b\u0430\u0442\u044c \u0441 \u043d\u0438\u043c\u0438?\n1. \u0412\u044b\u043a\u0438\u043d\u0443\u0442\u044c \u044d\u0442\u0438 \u0434\u0430\u043d\u043d\u044b\u0435 (\u0442\u043e\u043b\u044c\u043a\u043e \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435, \u043d\u0430 \u0442\u0435\u0441\u0442\u0435 \u043d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0432\u044b\u043a\u0438\u0434\u044b\u0432\u0430\u0435\u043c)\n2. \u0417\u0430\u043c\u0435\u043d\u044f\u0442\u044c \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u0440\u0430\u0437\u043d\u044b\u043c\u0438 \u043c\u0435\u0442\u043e\u0434\u0430\u043c\u0438 (\u043c\u0435\u0434\u0438\u0430\u043d\u044b, \u0441\u0440\u0435\u0434\u043d\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f, np.clip \u0438 \u0442.\u0434.)\n3. \u0414\u0435\u043b\u0430\u0442\u044c\/\u043d\u0435 \u0434\u0435\u043b\u0430\u0442\u044c \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u0444\u0438\u0447\u0443\n4. \u041d\u0438\u0447\u0435\u0433\u043e \u043d\u0435 \u0434\u0435\u043b\u0430\u0442\u044c","f3a66104":"**MedPriceByFloorYear**","186a5b68":"## 1. EDA  <a class='anchor' id='eda'>\n\u0414\u0435\u043b\u0430\u0435\u043c EDA \u0434\u043b\u044f:\n- \u0418\u0441\u043f\u0440\u0430\u0432\u043b\u0435\u043d\u0438\u044f \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432\n- \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u044f NaN\n- \u0418\u0434\u0435\u0439 \u0434\u043b\u044f \u0433\u0435\u043d\u0435\u0440\u0430\u0446\u0438\u0438 \u043d\u043e\u0432\u044b\u0445 \u0444\u0438\u0447","7c03b098":"![image.png](attachment:image.png)","54f0ce7a":"**\u0426\u0435\u043b\u0435\u0432\u0430\u044f \u043f\u0435\u0440\u0435\u043c\u0435\u043d\u043d\u0430\u044f**","8330be24":"**Healthcare_1**","6a1574fc":"#### \u043c\u043e\u0436\u043d\u043e \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u0442\u044c \u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c social_1 \u0438\u043b\u0438 social_2 (\u0438\u0437-\u0437\u0430 \u043a\u043e\u0440\u0435\u043b\u044f\u0446\u0438\u0438)","956fe5ec":"%%time\nfrom sklearn.ensemble import BaggingRegressor\n\nbr = BaggingRegressor(\n                       base_estimator=rf, \n                       n_estimators=5, \n                       random_state=RNDM\n                     )\nbr.fit(X_train, y_train)","8c474287":"feature_names = ['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',\n                 'Helthcare_2', 'Shops_1', 'Shops_2']\n\nnew_feature_names = ['Rooms_outlier', 'HouseFloor_outlier', 'HouseYear_outlier', 'LifeSquare_nan', 'DistrictSize',\n                     'new_district', 'IsDistrictLarge',  'MedPriceByDistrict', 'MedPriceByFloorYear',\n#                      'last_floor', 'first_floor',\n#                      'clusters_1','clusters_2','clusters_3', 'clusters_4', 'clusters_5', \n#                      'clusters_6', 'clusters_7'\n                    ]\n\ntarget_name = 'Price'","971dda91":"**MedPriceByDistrict**","b8c9bc07":"![image.png](attachment:image.png)","50be9ea8":"**Square**","1f22c959":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\ntrain_df_scaled = pd.DataFrame(scaler.fit_transform(train_df), columns=['Rooms', 'Square', 'LifeSquare', 'KitchenSquare', 'Floor', 'HouseFloor', 'HouseYear',\n                 'Ecology_1', 'Ecology_2', 'Ecology_3', 'Social_1', 'Social_2', 'Social_3',\n                 'Helthcare_2', 'Shops_1', 'Shops_2'])","4a51d371":"**HouseFloor, Floor**","4f9fbe8d":"\u0432\u044b\u0440\u0430\u0437\u0438\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u043f\u043b\u043e\u0449\u0430\u0434\u0438 \u043a\u0443\u0445\u043d\u0438 \u0447\u0435\u0440\u0435\u0437 \u043e\u0431\u0449\u0443\u044e \u043f\u043b\u043e\u0449\u0430\u0434\u044c","d0f6c482":"### \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445 <a class='anchor' id='load'>","5948f076":"**HouseYear**","9c353e13":"**\u041f\u0443\u0442\u0438 \u043a \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u044f\u043c \u0438 \u0444\u0430\u0439\u043b\u0430\u043c**","aebcdf77":"\u0432\u044b\u0440\u0430\u0437\u0438\u043c \u0432\u044b\u0431\u0440\u043e\u0441\u044b \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u043a\u043e\u043c\u043d\u0430\u0442 \u0447\u0435\u0440\u0435\u0437 \u043e\u0431\u0449\u0443\u044e \u043f\u043b\u043e\u0449\u0430\u0434\u044c","4d2eb5fd":"**Dummies**","c2dd90be":"**\u041f\u043b\u0430\u043d \u0437\u0430\u043d\u044f\u0442\u0438\u044f**\n* [\u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445](#load)\n* [1. EDA](#eda)\n* [2. \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0432\u044b\u0431\u0440\u043e\u0441\u043e\u0432](#outlier)\n* [3. \u041e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u043f\u0440\u043e\u043f\u0443\u0441\u043a\u043e\u0432](#nan)\n* [4. \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043d\u043e\u0432\u044b\u0445 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432](#feature)\n* [5. \u041e\u0442\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432](#feature_selection)\n* [6. \u0420\u0430\u0437\u0431\u0438\u0435\u043d\u0438\u0435 \u043d\u0430 train \u0438 test](#split)\n* [7. \u041f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438](#modeling)\n* [8. \u041f\u0440\u043e\u0433\u043d\u043e\u0437\u0438\u0440\u043e\u0432\u0430\u043d\u0438\u0435 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435](#prediction)","f3163600":"**\u041f\u043e\u0434\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u0435 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a \u0438 \u0441\u043a\u0440\u0438\u043f\u0442\u043e\u0432**","90d73ce7":"### \u0417\u0430\u0434\u0430\u043d\u0438\u0435 \u0434\u043b\u044f \u043a\u0443\u0440\u0441\u043e\u0432\u043e\u0433\u043e \u043f\u0440\u043e\u0435\u043a\u0442\u0430\n\n\u041c\u0435\u0442\u0440\u0438\u043a\u0430:\nR2 - \u043a\u043e\u044d\u0444\u0444\u0438\u0446\u0438\u0435\u043d\u0442 \u0434\u0435\u0442\u0435\u0440\u043c\u0438\u043d\u0430\u0446\u0438\u0438 (sklearn.metrics.r2_score)\n\n\u0421\u0434\u0430\u0447\u0430 \u043f\u0440\u043e\u0435\u043a\u0442\u0430:\n1. \u0421\u043e\u0440\u0435\u0432\u043d\u043e\u0432\u0430\u043d\u0438\u0435 \u0437\u0430\u043a\u0430\u043d\u0447\u0438\u0432\u0430\u0435\u0442\u0441\u044f 02.03.21\n2. \u041f\u0440\u0438\u0441\u043b\u0430\u0442\u044c \u0432 \u0440\u0430\u0437\u0434\u0435\u043b \u0417\u0430\u0434\u0430\u043d\u0438\u044f \u0423\u0440\u043e\u043a\u0430 10 (\"\u0412\u0435\u0431\u0438\u043d\u0430\u0440. \u041a\u043e\u043d\u0441\u0443\u043b\u044c\u0442\u0430\u0446\u0438\u044f \u043f\u043e \u0438\u0442\u043e\u0433\u043e\u0432\u043e\u043c\u0443 \u043f\u0440\u043e\u0435\u043a\u0442\u0443\")\n\u0441\u0441\u044b\u043b\u043a\u0443 \u043d\u0430 \u043d\u043e\u0443\u0442\u0431\u0443\u043a \u0432 github \u0438\u043b\u0438 public kaggle notebook.\n3. \u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043f\u043e\u043b\u0443\u0447\u0438\u0442\u044c R2 > 0.6 \u043d\u0430 Private Leaderboard.\n4. \u0423\u043a\u0430\u0436\u0438\u0442\u0435 \u0441\u0432\u043e\u0439 \u043d\u0438\u043a \u043d\u0430 kaggle \n\n\n\u041f\u0440\u0438\u043c\u0435\u0447\u0430\u043d\u0438\u0435:\n\u0412\u0441\u0435 \u0444\u0430\u0439\u043b\u044b csv \u0434\u043e\u043b\u0436\u043d\u044b \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u044f \u043f\u043e\u043b\u0435\u0439 (header - \u0442\u043e \u0435\u0441\u0442\u044c \"\u0448\u0430\u043f\u043a\u0443\"),\n\u0440\u0430\u0437\u0434\u0435\u043b\u0438\u0442\u0435\u043b\u044c - \u0437\u0430\u043f\u044f\u0442\u0430\u044f. \u0412 \u0444\u0430\u0439\u043b\u0430\u0445 \u043d\u0435 \u0434\u043e\u043b\u0436\u043d\u044b \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c\u0441\u044f \u0438\u043d\u0434\u0435\u043a\u0441\u044b \u0438\u0437 \u0434\u0430\u0442\u0430\u0444\u0440\u0435\u0439\u043c\u0430.\n____________\n\u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0430\u0446\u0438\u0438 \u0434\u043b\u044f \u0444\u0430\u0439\u043b\u0430 \u0441 \u043a\u043e\u0434\u043e\u043c (ipynb):\n1. \u0424\u0430\u0439\u043b \u0434\u043e\u043b\u0436\u0435\u043d \u0441\u043e\u0434\u0435\u0440\u0436\u0430\u0442\u044c \u0437\u0430\u0433\u043e\u043b\u043e\u0432\u043a\u0438 \u0438 \u043a\u043e\u043c\u043c\u0435\u043d\u0442\u0430\u0440\u0438\u0438\n2. \u041f\u043e\u0432\u0442\u043e\u0440\u044f\u044e\u0449\u0438\u0435\u0441\u044f \u043e\u043f\u0435\u0440\u0430\u0446\u0438\u0438 \u043b\u0443\u0447\u0448\u0435 \u043e\u0444\u043e\u0440\u043c\u043b\u044f\u0442\u044c \u0432 \u0432\u0438\u0434\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0439\n3. \u041f\u043e \u0432\u043e\u0437\u043c\u043e\u0436\u043d\u043e\u0441\u0442\u0438 \u0434\u043e\u0431\u0430\u0432\u043b\u044f\u0442\u044c \u0433\u0440\u0430\u0444\u0438\u043a\u0438, \u043e\u043f\u0438\u0441\u044b\u0432\u0430\u044e\u0449\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 (\u043e\u043a\u043e\u043b\u043e 3-5)\n4. \u0414\u043e\u0431\u0430\u0432\u043b\u044f\u0442\u044c \u0442\u043e\u043b\u044c\u043a\u043e \u043b\u0443\u0447\u0448\u0443\u044e \u043c\u043e\u0434\u0435\u043b\u044c, \u0442\u043e \u0435\u0441\u0442\u044c \u043d\u0435 \u0432\u043a\u043b\u044e\u0447\u0430\u0442\u044c \u0432 \u043a\u043e\u0434 \u0432\u0441\u0435 \u0432\u0430\u0440\u0438\u0430\u043d\u0442\u044b \u0440\u0435\u0448\u0435\u043d\u0438\u044f \u043f\u0440\u043e\u0435\u043a\u0442\u0430\n5. \u0421\u043a\u0440\u0438\u043f\u0442 \u043f\u0440\u043e\u0435\u043a\u0442\u0430 \u0434\u043e\u043b\u0436\u0435\u043d \u043e\u0442\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0442\u044c \u043e\u0442 \u043d\u0430\u0447\u0430\u043b\u0430 \u0438 \u0434\u043e \u043a\u043e\u043d\u0446\u0430 (\u043e\u0442 \u0437\u0430\u0433\u0440\u0443\u0437\u043a\u0438 \u0434\u0430\u043d\u043d\u044b\u0445 \u0434\u043e \u0432\u044b\u0433\u0440\u0443\u0437\u043a\u0438 \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u0438\u0439)\n6. \u0412\u0435\u0441\u044c \u043f\u0440\u043e\u0435\u043a\u0442 \u0434\u043e\u043b\u0436\u0435\u043d \u0431\u044b\u0442\u044c \u0432 \u043e\u0434\u043d\u043e\u043c \u0441\u043a\u0440\u0438\u043f\u0442\u0435 (\u0444\u0430\u0439\u043b ipynb).\n7. \u041f\u0440\u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043d\u0438\u0438 \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a (\u0441\u0440\u0435\u0434\u043d\u0435\u0435, \u043c\u0435\u0434\u0438\u0430\u043d\u0430 \u0438 \u0442.\u0434.) \u0432 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432, \u043b\u0443\u0447\u0448\u0435 \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0438\u0445 \u043d\u0430 \u0442\u0440\u0435\u0439\u043d\u0435, \u0438 \u043f\u043e\u0442\u043e\u043c \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0445 \u0438 \u0442\u0435\u0441\u0442\u043e\u0432\u044b\u0445 \u0434\u0430\u043d\u043d\u044b\u0445 \u043d\u0435 \u0441\u0447\u0438\u0442\u0430\u0442\u044c \u0441\u0442\u0430\u0442\u0438\u0441\u0442\u0438\u043a\u0438 \u0437\u0430\u043d\u043e\u0432\u043e, \u0430 \u0431\u0440\u0430\u0442\u044c \u0438\u0445 \u0441 \u0442\u0440\u0435\u0439\u043d\u0430.\n8. \u041f\u0440\u043e\u0435\u043a\u0442 \u0434\u043e\u043b\u0436\u0435\u043d \u043f\u043e\u043b\u043d\u043e\u0441\u0442\u044c\u044e \u043e\u0442\u0440\u0430\u0431\u0430\u0442\u044b\u0432\u0430\u0442\u044c \u0437\u0430 \u0440\u0430\u0437\u0443\u043c\u043d\u043e\u0435 \u0432\u0440\u0435\u043c\u044f (\u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u0435 10 \u043c\u0438\u043d\u0443\u0442), \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u0432 \u0444\u0438\u043d\u0430\u043b\u044c\u043d\u044b\u0439 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 \u043b\u0443\u0447\u0448\u0435 \u043d\u0435 \u0432\u043a\u043b\u044e\u0447\u0430\u0442\u044c GridSearch \u0441 \u043f\u0435\u0440\u0435\u0431\u043e\u0440\u043e\u043c \u0431\u043e\u043b\u044c\u0448\u043e\u0433\u043e \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u0430 \u0441\u043e\u0447\u0435\u0442\u0430\u043d\u0438\u0439 \u043f\u0430\u0440\u0430\u043c\u0435\u0442\u0440\u043e\u0432. ","224d61d0":"**\u041e\u0446\u0435\u043d\u043a\u0430 \u043c\u043e\u0434\u0435\u043b\u0438**","b061bbdd":"**LifeSquare**","487baf4b":"\u0412\u0441\u0435 \u044d\u0442\u043e \u043a\u0440\u0443\u0442\u043e, \u043d\u043e \u043a\u043b\u0430\u0441\u0442\u0435\u0440\u0438\u0437\u0430\u0446\u0438\u044f \u043d\u0435 \u043f\u043e\u043c\u043e\u0433\u043b\u0430","19742674":"**\u041e\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430**\n\n* **Id** - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b\n* **DistrictId** - \u0438\u0434\u0435\u043d\u0442\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0439 \u043d\u043e\u043c\u0435\u0440 \u0440\u0430\u0439\u043e\u043d\u0430\n* **Rooms** - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u043a\u043e\u043c\u043d\u0430\u0442\n* **Square** - \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n* **LifeSquare** - \u0436\u0438\u043b\u0430\u044f \u043f\u043b\u043e\u0449\u0430\u0434\u044c\n* **KitchenSquare** - \u043f\u043b\u043e\u0449\u0430\u0434\u044c \u043a\u0443\u0445\u043d\u0438\n* **Floor** - \u044d\u0442\u0430\u0436\n* **HouseFloor** - \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u044d\u0442\u0430\u0436\u0435\u0439 \u0432 \u0434\u043e\u043c\u0435\n* **HouseYear** - \u0433\u043e\u0434 \u043f\u043e\u0441\u0442\u0440\u043e\u0439\u043a\u0438 \u0434\u043e\u043c\u0430\n* **Ecology_1, Ecology_2, Ecology_3** - \u044d\u043a\u043e\u043b\u043e\u0433\u0438\u0447\u0435\u0441\u043a\u0438\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\n* **Social_1, Social_2, Social_3** - \u0441\u043e\u0446\u0438\u0430\u043b\u044c\u043d\u044b\u0435 \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438\n* **Healthcare_1, Helthcare_2** - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438 \u043c\u0435\u0441\u0442\u043d\u043e\u0441\u0442\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043e\u0445\u0440\u0430\u043d\u043e\u0439 \u0437\u0434\u043e\u0440\u043e\u0432\u044c\u044f\n* **Shops_1, Shops_2** - \u043f\u043e\u043a\u0430\u0437\u0430\u0442\u0435\u043b\u0438, \u0441\u0432\u044f\u0437\u0430\u043d\u043d\u044b\u0435 \u0441 \u043d\u0430\u043b\u0438\u0447\u0438\u0435\u043c \u043c\u0430\u0433\u0430\u0437\u0438\u043d\u043e\u0432, \u0442\u043e\u0440\u0433\u043e\u0432\u044b\u0445 \u0446\u0435\u043d\u0442\u0440\u043e\u0432\n* **Price** - \u0446\u0435\u043d\u0430 \u043a\u0432\u0430\u0440\u0442\u0438\u0440\u044b","93436b1e":"**\u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435**","f77d8710":"### 5. \u041e\u0442\u0431\u043e\u0440 \u043f\u0440\u0438\u0437\u043d\u0430\u043a\u043e\u0432  <a class='anchor' id='feature_selection'>"}}