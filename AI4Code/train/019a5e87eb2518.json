{"cell_type":{"f77a9a6f":"code","bebae7a4":"markdown"},"source":{"f77a9a6f":"# Filename: house_prices_project.R\n# Author: CSC 3220 House Prices Team\n# Date: 11\/16\/2021\n# Purpose: A script to create and evaluate models that predict the final price of homes based on given variables\n\n# -------------------------------------------------\n#                   Prerequisites\n# -------------------------------------------------\n\n# Install libraries\ninstall.packages(\"readr\")\ninstall.packages(\"dplyr\")\ninstall.packages(\"VIM\")\ninstall.packages(\"corrplot\")\ninstall.packages(\"RColorBrewer\")\n\n# Load libraries\nlibrary(readr)\nlibrary(dplyr)\nlibrary(VIM)\nlibrary(corrplot)\nlibrary(RColorBrewer)\n\n# Load data\ntest = read_csv(\"test.csv\")\ntrain = read_csv(\"train.csv\")\n\ny = train$SalePrice\n\n# -------------------------------------------------\n#                   Data Cleaning\n# -------------------------------------------------\n\n# Identify NAs\nsummary(train)\nsummary(test)\n\n# Replace NAs (with classifiers identified on Kaggle)\ntrain$Alley[is.na(train$Alley)] = \"NoAccess\"\ntrain$BsmtQual[is.na(train$BsmtQual)] = \"NB\"          # No Basement\ntrain$BsmtCond[is.na(train$BsmtCond)] = \"NB\"\ntrain$BsmtExposure[is.na(train$BsmtExposure)] = \"NB\"\ntrain$BsmtFinType1[is.na(train$BsmtFinType1)] = \"NB\"\ntrain$BsmtFinType2[is.na(train$BsmtFinType2)] = \"NB\"\ntrain$FireplaceQu[is.na(train$FireplaceQu)] = \"NF\"    # No Fireplace\ntrain$GarageType[is.na(train$GarageType)] = \"NG\"      # No Garage\ntrain$GarageFinish[is.na(train$GarageFinish)] = \"NG\"\ntrain$GarageQual[is.na(train$GarageQual)] = \"NG\"\ntrain$GarageCond[is.na(train$GarageCond)] = \"NG\"\ntrain$PoolQC[is.na(train$PoolQC)] = \"NP\" # No Pool\ntrain$Fence[is.na(train$Fence)] = \"NoFence\"\ntrain$MiscFeature[is.na(train$MiscFeature)] = \"None\"\n\ntest$Alley[is.na(test$Alley)] = \"NoAccess\"\ntest$BsmtQual[is.na(test$BsmtQual)] = \"NB\"\ntest$BsmtCond[is.na(test$BsmtCond)] = \"NB\"\ntest$BsmtExposure[is.na(test$BsmtExposure)] = \"NB\"\ntest$BsmtFinType1[is.na(test$BsmtFinType1)] = \"NB\"\ntest$BsmtFinType2[is.na(test$BsmtFinType2)] = \"NB\"\ntest$FireplaceQu[is.na(test$FireplaceQu)] = \"NF\"\ntest$GarageType[is.na(test$GarageType)] = \"NG\"\ntest$GarageFinish[is.na(test$GarageFinish)] = \"NG\"\ntest$GarageQual[is.na(test$GarageQual)] = \"NG\"\ntest$GarageCond[is.na(test$GarageCond)] = \"NG\"\ntest$PoolQC[is.na(test$PoolQC)] = \"NP\"\ntest$Fence[is.na(test$Fence)] = \"NoFence\"\ntest$MiscFeature[is.na(test$MiscFeature)] = \"None\"\n\n# Replace NAs (kNN Imputation)\nk = round(sqrt(length(train)), 0)\ntrain = kNN(data = train, dist_var = colnames(x = train %>% select(!SalePrice)), k = k, imp_var = FALSE)\ntemp = train %>% select(!SalePrice) # Logic from here is only necessary because we want to perform kNN for the test set based on the train set as to not cause data leakage\ntemp2 = test[rowSums(is.na(test)) > 0, ]\ntemp = rbind(temp, temp2)\ntestNAs = which(is.na(test), arr.ind=TRUE)\ntempNAs = which(is.na(temp), arr.ind=TRUE)\ntemp = kNN(data = temp, dist_var = colnames(temp), k = k, imp_var = FALSE)\nfor(i in 1:(length(testNAs)\/2)) {\n  test[testNAs[i, 1], testNAs[i, 2]] = temp[tempNAs[i, 1], tempNAs[i, 2]]\n}\n\n# Check for remaining NAs in train\nfor(i in 1:length(names(train))) {\n  print(c(i, sum(is.na(train[,i]))))\n}\n\n# Check for remaining NAs in test\nfor(i in 1:length(names(test))) {\n  print(c(i, sum(is.na(test[,i]))))\n}\n\n# We don't need to convert categorical data to factors as this will be done implicitly by lm()\n\n# -------------------------------------------------\n#                       EDA\n# -------------------------------------------------\nsummary(train)\n\n# Note: test and train hists similar; good sign\n\n# Histograms\/boxplots for numerical data\npar(mfrow = c(1,2))\n\nhist(train$Id, main = \"Histogram\")              # Distributed evenly across the tuples, which makes sense as IDs should be unique\nboxplot(train$Id, main = \"Boxplot\")\n\nhist((train$MSSubClass), main = \"Histogram\")    # Right skewed with outliers past 150; no obvious erronous data\nboxplot(train$MSSubClass, main = \"Boxplot\")\n\nhist(train$LotFrontage, main = \"Histogram\")     # Outliers past 300, but these lots are also incredibly large upon closer inspection, so this seems plausible\nboxplot(train$LotFrontage, main = \"Boxplot\")\n\nhist(train$LotArea, main = \"Histogram\")         # Most lots are very small, so there are many outliers but these are within the realm of plausibility\nboxplot(train$LotArea, main = \"Boxplot\")\n\nhist(train$OverallQual, main = \"Histogram\")     # Relatively normal distribution, no notable outliers\nboxplot(train$OverallQual, main = \"Boxplot\")\n\nhist(train$OverallCond, main = \"Histogram\")     # Categorical, slightly right skewed, nothing outside of acceptable range\nboxplot(train$OverallCond, main = \"Boxplot\")\n\nhist(train$YearBuilt, main = \"Histogram\")       # Most houses in Ames seem to have been built recently, with especially old houses actually being an outlier; no values seem erroneous though\nboxplot(train$YearBuilt, main = \"Boxplot\")\n\nhist(train$YearRemodAdd, main = \"Histogram\")    # Two peaks at either end of the spectrum, though no outlying data\nboxplot(train$YearRemodAdd, main = \"Boxplot\")\n\nhist(train$MasVnrArea, main = \"Histogram\")      # Most houses do not have masonry veneers, so it makes sense that this histogram is centered on this value; some erronous data was found based on this\nboxplot(train$MasVnrArea, main = \"Boxplot\")\n\nhist(train$BsmtFinSF1, main = \"Histogram\")      # Right skewed, some outliers past 5000 square feet, but this is still plausible\nboxplot(train$BsmtFinSF1, main = \"Boxplot\")\n\nhist(train$BsmtFinSF2, main = \"Histogram\")      # Similarly right skewed, though even more focused around the lower values; erroneous values in relation to basement type\nboxplot(train$BsmtFinSF2, main = \"Boxplot\")\n\nhist(train$BsmtUnfSF, main = \"Histogram\")       # Right skewed, no obvious erroneous data\nboxplot(train$BsmtUnfSF, main = \"Boxplot\")\n\nhist(train$TotalBsmtSF, main = \"Histogram\")     # Outlier past 5000 square feet, though this is plausible\nboxplot(train$TotalBsmtSF, main = \"Boxplot\")\n\nhist(train$`1stFlrSF`, main = \"Histogram\")      # Relatively normally distributed, outliers past 4000 square feet are plausible\nboxplot(train$`1stFlrSF`, main = \"Boxplot\")\n\nhist(train$`2ndFlrSF`, main = \"Histogram\")      # It would appear that most houses do not have a second floor; moreover, there are erroneous entries that need correcting\nboxplot(train$`2ndFlrSF`, main = \"Boxplot\")\n\nhist(train$LowQualFinSF, main = \"Histogram\")    # Very few houses with low quality square footage sold, which would make sense; those that did likely had other attractive features\nboxplot(train$LowQualFinSF, main = \"Boxplot\")\n\nhist(train$GrLivArea, main = \"Histogram\")       # Relatively normally distributed, no obvious erroneous data\nboxplot(train$GrLivArea, main = \"Boxplot\")\n\nhist(train$BsmtFullBath, main = \"Histogram\")    # All relatively normal amounts\nboxplot(train$BsmtFullBath, main = \"Boxplot\")\n\nhist(train$BsmtHalfBath, main = \"Histogram\")    # Again, all relatively normal amounts\nboxplot(train$BsmtHalfBath, main = \"Boxplot\")\n\nhist(train$FullBath, main = \"Histogram\")        # Relatively normal amounts\nboxplot(train$FullBath, main = \"Boxplot\")\n\nhist(train$HalfBath, main = \"Histogram\")        # Relatively normal amounts\nboxplot(train$HalfBath, main = \"Boxplot\")\n\nhist(train$BedroomAbvGr, main = \"Histogram\")    # Several houses with no bedrooms above ground, though these do have basements so it is plausible\nboxplot(train$BedroomAbvGr, main = \"Boxplot\")\n\nhist(train$KitchenAbvGr, main = \"Histogram\")    # One house with no kitchen above ground, though it does have a basement\nboxplot(train$KitchenAbvGr, main = \"Boxplot\")\n\nhist(train$TotRmsAbvGrd, main = \"Histogram\")    # Relatively normal distribution, no obvious erroneous data\nboxplot(train$TotRmsAbvGrd, main = \"Boxplot\")\n\nhist(train$Fireplaces, main = \"Histogram\")      # Most houses have either no or one fireplace(s), which seems logical; no obvious erroneous data\nboxplot(train$Fireplaces, main = \"Boxplot\")\n\nhist(train$GarageYrBlt, main = \"Histogram\")     # Most garages built recently, which makes sense as most houses are also built recently\nboxplot(train$GarageYrBlt, main = \"Boxplot\")\n\nhist(train$GarageCars, main = \"Histogram\")      # Relatively normal values\nboxplot(train$GarageCars, main = \"Boxplot\")\n\nhist(train$GarageArea, main = \"Histogram\")      # Relatively normal distribution, no obvious erroneous data\nboxplot(train$GarageArea, main = \"Boxplot\")\n\nhist(train$WoodDeckSF, main = \"Histogram\")      # Heavily right-skewed, which would seem to indicate most houses have either no or small decks\nboxplot(train$WoodDeckSF, main = \"Boxplot\")\n\nhist(train$OpenPorchSF, main = \"Histogram\")     # Much the same as the situaton with deck size\nboxplot(train$OpenPorchSF, main = \"Boxplot\")\n\nhist(train$EnclosedPorch, main = \"Histogram\")   # Similar to deck and porch size, except it would seem even less homes have enclosed porches\nboxplot(train$EnclosedPorch, main = \"Boxplot\")\n\nhist(train$`3SsnPorch`, main = \"Histogram\")     # Even less homes have three season porch areas than enclosed porches\nboxplot(train$`3SsnPorch`, main = \"Boxplot\")\n\nhist(train$ScreenPorch, main = \"Histogram\")     # Much the same as enclosed porch size\nboxplot(train$ScreenPorch, main = \"Boxplot\")\n\nhist(train$PoolArea, main = \"Histogram\")        # Most houses have either no or small pools, yielding a histogram where only the bar near 0 is even visible; still, no obvious erroneous data\nboxplot(train$PoolArea, main = \"Boxplot\")\n\nhist(train$MiscVal, main = \"Histogram\")         # Most houses don't have miscellaneous value\nboxplot(train$MiscVal, main = \"Boxplot\")\n\nhist(train$MoSold, main = \"Histogram\")          # Relatively normal distribution, no outliers\nboxplot(train$MoSold, main = \"Boxplot\")\n\nhist(train$YrSold, main = \"Histogram\")          # Fairly evenly distributed (even around the housing crisis, interestingly enough), no outliers\nboxplot(train$YrSold, main = \"Boxplot\")\n\nhist(train$SalePrice, main = \"Histogram\")       # Somewhat right skewed, dependent variable\nboxplot(train$SalePrice, main = \"Boxplot\")\n\npar(mfrow = c(1,1))\n\n# Bar charts for categorical data\nbarplot(table(train$MSZoning), main = \"MSZoning Bar Chart\")\nbarplot(table(train$Street), main = \"Street Bar Chart\")\nbarplot(table(train$Alley), main = \"Alley Bar Chart\")\nbarplot(table(train$LotShape), main = \"LotShape Bar Chart\")\nbarplot(table(train$LandContour), main = \"LandContour Bar Chart\")\nbarplot(table(train$Utilities), main = \"Utilities Bar Chart\")\nbarplot(table(train$LotConfig), main = \"LotConfig Bar Chart\")\nbarplot(table(train$LandSlope), main = \"LandSlope Bar Chart\")\nbarplot(table(train$Neighborhood), main = \"Neighborhood Bar Chart\")\nbarplot(table(train$Condition1), main = \"Condition1 Bar Chart\")\nbarplot(table(train$Condition2), main = \"Condition2 Bar Chart\")\nbarplot(table(train$BldgType), main = \"BldgType Bar Chart\")\nbarplot(table(train$HouseStyle), main = \"HouseStyle Bar Chart\")\nbarplot(table(train$RoofStyle), main = \"RoofStyle Bar Chart\")\nbarplot(table(train$RoofMatl), main = \"RoofMatl Bar Chart\")\nbarplot(table(train$Exterior1st), main = \"Extorior1st Bar Chart\")\nbarplot(table(train$Exterior2nd), main = \"Exterior2nd Bar Chart\")\nbarplot(table(train$MasVnrType), main = \"MasVnrType Bar Chart\")\nbarplot(table(train$ExterQual), main = \"ExterQual Bar Chart\")\nbarplot(table(train$ExterCond), main = \"ExterCond Bar Chart\")\nbarplot(table(train$Foundation), main = \"Foundation Bar Chart\")\nbarplot(table(train$BsmtQual), main = \"BsmtQual Bar Chart\")\nbarplot(table(train$BsmtCond), main = \"BsmtCond Bar Chart\")\nbarplot(table(train$BsmtExposure), main = \"BsmtExposure Bar Chart\")\nbarplot(table(train$BsmtFinType1), main = \"BsmtFinType1 Bar Chart\")\nbarplot(table(train$BsmtFinType2), main = \"BsmtFinType2 Bar Chart\")\nbarplot(table(train$Heating), main = \"Heating Bar Chart\")\nbarplot(table(train$HeatingQC), main = \"HeatingQC Bar Chart\")\nbarplot(table(train$CentralAir), main = \"CentralAir Bar Chart\")\nbarplot(table(train$Electrical), main = \"Electrical Bar Chart\")\nbarplot(table(train$KitchenQual), main = \"KitchenQual Bar Chart\")\nbarplot(table(train$Functional), main = \"Functional Bar Chart\")\nbarplot(table(train$FireplaceQu), main = \"FireplaceQu Bar Chart\")\nbarplot(table(train$GarageType), main = \"GarageType Bar Chart\")\nbarplot(table(train$GarageFinish), main = \"GarageFinish Bar Chart\")\nbarplot(table(train$GarageQual), main = \"GarageQual Bar Chart\")\nbarplot(table(train$GarageCond), main = \"GarageCond Bar Chart\")\nbarplot(table(train$PavedDrive), main = \"PavedDrive Bar Chart\")\nbarplot(table(train$PoolQC), main = \"PoolQC Bar Chart\")\nbarplot(table(train$Fence), main = \"Fence Bar Chart\")\nbarplot(table(train$MiscFeature), main = \"MiscFeature Bar Chart\")\nbarplot(table(train$SaleType), main = \"SaleType Bar Chart\")\n\n# Correlation matrix\npar(cex = 0.6)\ncorrplot(cor(select_if(train, is.numeric)), type=\"lower\", order=\"hclust\", col = brewer.pal(n = 8, name = \"Blues\"))\npar(cex = 1)\n\n# -------------------------------------------------\n#                More Data Cleaning\n# -------------------------------------------------\n\n# Erroneous data removal\n\n# Errors that were found\ntrain$MasVnrArea[train$MasVnrArea > 0 & train$MasVnrType == \"None\"] = 0         # Can't simply do kNN as this could still produce erroneous results\ntrain$MasVnrType[train$MasVnrArea == 0 & train$MasVnrType != \"None\"] = \"None\"   # Opted to use \"None\" here and 0 on the previous line since this is the most common setup for houses in the data set\ntrain$BsmtFinSF2[train$BsmtFinSF2 > 0 & train$BsmtFinType2 == \"None\"] = 0\ntrain$`2ndFlrSF`[train$`2ndFlrSF` > 0 & train$HouseStyle == \"1Story\"] = 0\n\n# Errors that could exist\ntrain$TotalBsmtSF[train$TotalBsmtSF > 0 & train$BsmtQual == \"NB\"] = 0\ntrain$BsmtUnfSF[train$BsmtUnfSF > 0 & train$BsmtQual == \"NB\"] = 0\ntrain$BsmtFinSF1[train$BsmtFinSF1 > 0 & train$BsmtFinType1 == \"None\"] = 0\ntrain$BsmtFinType1[train$BsmtFinSF1 == 0 & train$BsmtFinType1 != \"None\"] = \"None\"\ntrain$BsmtFinType2[train$BsmtFinSF2 == 0 & train$BsmtFinType2 != \"None\"] = \"None\"\ntrain$BsmtFullBath[train$BsmtFullBath > 0 & train$BsmtQual == \"NB\"] = 0\ntrain$BsmtHalfBath[train$BsmtHalfBath > 0 & train$BsmtQual == \"NB\"] = 0\ntrain$GarageCars[train$GarageCars > 0 & train$GarageQual == \"NG\"] = 0\ntrain$GarageArea[train$GarageArea > 0 & train$GarageQual == \"NG\"] = 0\ntrain$PoolArea[train$PoolArea > 0 & train$PoolQC == \"NP\"] = 0\ntrain$PoolQC[train$PoolArea == 0 & train$PoolQC != \"NP\"] = \"NP\"\n\n# Then, do the same for the test set\ntest$MasVnrArea[test$MasVnrArea > 0 & test$MasVnrType == \"None\"] = 0\ntest$MasVnrType[test$MasVnrArea == 0 & test$MasVnrType != \"None\"] = \"None\"\ntest$BsmtFinSF1[test$BsmtFinSF1 > 0 & test$BsmtFinType1 == \"None\"] = 0\ntest$BsmtFinType1[test$BsmtFinSF1 == 0 & test$BsmtFinType1 != \"None\"] = \"None\"\ntest$BsmtFinSF2[test$BsmtFinSF2 > 0 & test$BsmtFinType2 == \"None\"] = 0\ntest$BsmtFinType2[test$BsmtFinSF2 == 0 & test$BsmtFinType2 != \"None\"] = \"None\"\ntest$TotalBsmtSF[test$TotalBsmtSF > 0 & test$BsmtQual == \"NB\"] = 0\ntest$BsmtUnfSF[test$BsmtUnfSF > 0 & test$BsmtQual == \"NB\"] = 0\ntest$BsmtFullBath[test$BsmtFullBath > 0 & test$BsmtQual == \"NB\"] = 0\ntest$BsmtHalfBath[test$BsmtHalfBath > 0 & test$BsmtQual == \"NB\"] = 0\ntest$GarageCars[test$GarageCars > 0 & test$GarageQual == \"NG\"] = 0\ntest$GarageArea[test$GarageArea > 0 & test$GarageQual == \"NG\"] = 0\ntest$`2ndFlrSF`[test$`2ndFlrSF` > 0 & test$HouseStyle == \"1Story\"] = 0\ntest$PoolArea[test$PoolArea > 0 & test$PoolQC == \"NP\"] = 0\ntest$PoolQC[test$PoolArea == 0 & test$PoolQC != \"NP\"] = \"NP\"\n\n# -------------------------------------------------\n#                     Modeling\n# ------------------------------------------------","bebae7a4":"House Prices \u2013 Advanced Regression Techniques \n\n \n\nTeam Members: \n\nHabib Ahmadi \n\nMohamed Diaoune \n\nCherokee Parker \n\nDeepkumar Patel \n\n \n\nProblem Statement and Background (15%)  \n\nAs a resident of Nashville Tennessee, after the Covid-19 pandemic, I have witnessed the real estate market soaring at a constant rate, despite most of the predictions. According to the roofstock, home prices have increased 18.8% over the last year. Regardless of the neighborhood condition or school system, the house prices are increasing at the same rate all over Nashville. So, what criteria or features impact the price of a house, one might ask? When buying a house, the most common criteria that come to our minds are the number of bedrooms, square footage, neighborhood, and school system. Most people think that these characteristics can define the price of a house. Though it is not wrong, many other aspects can influence the price of a property as well. Thus, thorough research is necessary to explore the signs and aspects that are significant for determining the price of a house.  Research and data are needed to dive deep into the housing market fluctuation and its impact on our daily home purchases. So, one could analyze the data and make better decisions while considering homeownership.  \n\nResearch by The National Association of Realtors shows that only in September of this year 6.29 million units have been sold with a median price of $352.800. In addition, the researchers found that this figure indicates a 7% increase in home sales from the previous month. To anticipate the home prices, we need more than statistics.  \n\nThe House Prices dataset takes 79 explanatory variables into consideration that might influence the closing price of a house. The dataset comes from researching aspects and features of residential homes in Ames, Iowa, and its effects on determining the house prices from 2016 to 2010. The dataset includes 1930 observed objects with almost 80 variables which include; 23 normal, 23 ordinals, 14 discrete, and 20 continuous. We might use 5-fold cross-validation to predict the price of a house by training and testing the dataset. This technique is also known as k-fold validation. This technique takes the whole data and arbitrarily divides it into train and validation data set during 5 phases. In the end, we have 5 distinct training and validation data sets to test our model. \n\n \n\nData and Exploratory Analysis (15%) \n\nThe data provided by Kaggle for its \u201cHouse Prices\u201d competition (Dean De Cock\u2019s \u201cAmes Housing dataset\u201d) is the data that we will be using. This data is already separated into two data sets, one for training and one for testing. Each set includes 80 variables for each row in the data set describing the details of residential homes sold in Ames, Iowa from 2006 to 2010. The training set also includes an 81st variable containing the final sale price of the homes. \n\nFor our exploratory analysis and data cleaning, we used the language R and five packages: \u201creadr,\u201d \u201cdplyr,\u201d \u201cVIM,\u201d \u201ccorrplot,\u201d and \u201cRColorBrewer.\u201d \u201creadr\u201d was used to read in our data in an already decently formatted manner. \u201cdplyr\u201d was mostly used for its data frame selection functions and its pipe (\u201c%>%\u201d) operator. \u201cVIM\u201d was used for its k-Nearest Neighbors imputation function. Lastly, \u201ccorrplot\u201d and \u201cRColorBrewer\u201d were used to make a visually appealing correlation plot\/matrix. \n\nBoth data sets exhibited a large amount of missing data. Many of these blanks, though, actually had meanings outlined in the descriptions of the variables provided by Kaggle. For these cases, we simply imputed a new value to represent the meaning previously indicated by a missing value. For example, a missing value under the \u201cAlley\u201d variable indicates that there is no alley access to the home. To represent this, we simply replaced all missing values for this variable with \u201cNoAccess.\u201d In this way, we were able to impute values for most of our missing data. \n\nEven after doing this, however, we still had about 700 missing values across the data sets. Because these values were truly \u201cmissing,\u201d and not just representative of a known label, we decided to impute the remaining missing values using the k-Nearest Neighbors algorithm. To get k, we simply took the square root of the total number of variables for one of the data sets (this would yield the same number regardless, so it does not matter which we used for this). This gave us a k value of 9. Then, we imputed the missing values of the training set using the k-Nearest Neighbors algorithm and our k of 9. Lastly, we imputed the missing values of the test set by applying the k-Nearest Neighbors algorithm to the rows with missing values using the training set to determine the nearest neighbors. From here, all of our missing values were dealt with. \n\nNext, we decided to construct histograms and boxplots for each numerical variable and bar charts for each categorical variable. Only a few notable ones are shown here for the sake of brevity. \n\n \n\n \n\n \n\n \n\nFrom this, we identified a few notable outliers. Even still, we were unable to justify removing these outliers as all were entirely plausible. This is because most of our outliers were generated by variables that do not apply to most of the rows in our data set. For example, take the variable \u201cMasVnrArea\u201d or \u201cPoolArea.\u201d These variables represent the area of a house\u2019s masonry veneer or pool respectively. Since most houses do not have masonry veneer or a pool, the value of these variables will most often be 0, making houses that do have these features appear to be outliers. In reality, these are important values in the data set, and so they should not be removed. Other outliers were generated by exceptionally large homes. For instance, we identified a couple of houses with lot frontages well past 300 ft. Upon closer examination, we discovered that these houses had exceptionally large lots, and so this did not seem to be erroneous data. As such, we decided to keep these entries around for the sake of representing the true diversity of homes in Ames, Iowa. \n\nThere were other inconsistencies in the data that needed to be corrected, however. There were several variables indicative of a certain feature of the house existing where that feature did, in fact, not exist. For example, several rows were identified where the area of the house\u2019s masonry veneer was greater than 0, yet the house had no masonry veneer. This is obviously a contradiction, and we could not simply run k-Nearest Neighbors to fix it. This is because it would still be possible to get an area or label inconsistent with the other value. Instead, we simply looked at the histogram, found the most common value, and replaced the area or label (whichever was inconsistent with this mode) with this value. This needed to be done with several variables that had such relations; moreover, we also ran these tests and replacements on the test set. \n\nTo finish off our first exploration of the data, we decided to create a correlation plot\/matrix between the numeric data of the training data set. \n\n \n\n \n\nThis revealed some relatively strong relations across the board, but since we are mostly interested in what is correlated with the final sale price, only those will be mentioned. Final sale price, based on our correlation matrix, appears to be somewhat strongly related to the square footage of the house\u2019s basement, the square footage of the house\u2019s 1st floor, the car capacity of the house\u2019s garage, the area of the house\u2019s garage, the number of full bathrooms in the house, the year of the house\u2019s construction (and\/or last remodel), and the total number of rooms the house has above ground. The final sale price appears to be even more strongly related to the overall quality and above ground living area square footage of the house. All of these could be potentially important inputs in our final model. "}}