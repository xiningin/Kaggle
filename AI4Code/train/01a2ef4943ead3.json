{"cell_type":{"7dfd48cd":"code","16898e38":"code","8049a152":"code","a1ae60af":"code","229e0871":"code","e0ea35dc":"code","8f492d69":"code","37a7f535":"code","f10866eb":"code","16031345":"code","7fd4d9ef":"code","47c29eb5":"code","826d1dca":"code","fa4aee89":"code","1213d530":"code","1154e25d":"code","8194c1c5":"code","1b4da294":"code","9f91327e":"code","5d40aa1c":"code","8b5bb6ad":"code","113cbfb2":"code","35068e4e":"code","4ada0d65":"code","25a8e7c2":"code","b2102288":"code","570ca558":"code","ad412003":"code","98d60312":"code","a3e46a98":"code","9a6c1f1b":"code","9db4f8e1":"code","5745eb6c":"code","9693647e":"code","b888b36f":"code","b05e9fe2":"code","6ec005da":"code","e70591db":"code","a8716485":"markdown","e26a3d47":"markdown"},"source":{"7dfd48cd":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","16898e38":"email_data = pd.read_csv(\"\/kaggle\/input\/spam-mails-dataset\/spam_ham_dataset.csv\")","8049a152":"print(email_data)","a1ae60af":"email_data","229e0871":"# Checking for null values\n\nemail_data.isnull().sum()","e0ea35dc":"# dropping unwanted columns\nemail_data = email_data.drop(\"Unnamed: 0\", axis = 1)\nemail_data = email_data.drop(\"label_num\", axis = 1)","8f492d69":"email_data","37a7f535":"# Changing type of ham\/ spam to 1\/0 as sklearn library deals with 0 and 1\n\nemail_data['type'] = email_data.label.map({'ham': 1 , 'spam' : 0}) ","f10866eb":"email_data","16031345":"spam_ham_value = email_data.label.value_counts()\nspam_ham_value","7fd4d9ef":"# Calculate the ratio of spam data\nprint(\"Spam % is \",(spam_ham_value[1]\/float(spam_ham_value[0]+spam_ham_value[1]))*100)","47c29eb5":"# Seperate data into variables as X and y, So that we can use Bags of Words Representation to store the data. \nX=email_data.text\ny=email_data.type","826d1dca":"X","fa4aee89":"y","1213d530":"print(X.shape)\nprint(y.shape)","1154e25d":"# splitting into test and train\n\nfrom sklearn.model_selection  import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=1)","8194c1c5":"X_train.head()","1b4da294":"from sklearn.feature_extraction.text import CountVectorizer\n\n# vectorising the text\nvect = CountVectorizer(stop_words='english')","9f91327e":"vect.fit(X_train)","5d40aa1c":"vect.vocabulary_","8b5bb6ad":"vect.get_feature_names()","113cbfb2":"# transform\nX_train_transformed = vect.transform(X_train)\nX_test_tranformed =vect.transform(X_test)","35068e4e":"print(X_test[:1])","4ada0d65":"print(X_test_tranformed)","25a8e7c2":"from sklearn.naive_bayes import BernoulliNB\n\n# instantiate bernoulli NB object\nbnb = BernoulliNB()\n\n# fit \nbnb.fit(X_train_transformed,y_train)\n\n# predict class\ny_pred_class = bnb.predict(X_test_tranformed)\n\n# predict probability\ny_pred_proba =bnb.predict_proba(X_test_tranformed)\n\n# accuracy\nfrom sklearn import metrics\nmetrics.accuracy_score(y_test, y_pred_class)","b2102288":"bnb","570ca558":"metrics.confusion_matrix(y_test, y_pred_class)","ad412003":"confusion = metrics.confusion_matrix(y_test, y_pred_class)\nprint(confusion)\n#[row, column]\nTN = confusion[0, 0]\nFP = confusion[0, 1]\nFN = confusion[1, 0]\nTP = confusion[1, 1]","98d60312":"sensitivity = TP \/ float(FN + TP)\nprint(\"sensitivity\",sensitivity)","a3e46a98":"specificity = TN \/ float(TN + FP)\n\nprint(\"specificity\",specificity)","9a6c1f1b":"precision = TP \/ float(TP + FP)\n\nprint(\"precision\",precision)\nprint(metrics.precision_score(y_test, y_pred_class))","9db4f8e1":"print(\"precision\",precision)\nprint(\"PRECISION SCORE :\",metrics.precision_score(y_test, y_pred_class))\nprint(\"RECALL SCORE :\", metrics.recall_score(y_test, y_pred_class))\nprint(\"F1 SCORE :\",metrics.f1_score(y_test, y_pred_class))","5745eb6c":"y_pred_proba","9693647e":"from sklearn.metrics import confusion_matrix as sk_confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nimport matplotlib.pyplot as plt\nfalse_positive_rate, true_positive_rate, thresholds = roc_curve(y_test, y_pred_proba[:,1])\nroc_auc = auc(false_positive_rate, true_positive_rate)","b888b36f":"print (roc_auc)","b05e9fe2":"import matplotlib.pyplot as plt\n%matplotlib inline  \nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.title('ROC')\nplt.plot(false_positive_rate, true_positive_rate)","6ec005da":"import pickle\n\n# Exporting my model to use in a project \nPkl_Filename = \"SpamOrHam.pkl\"  \n\nwith open(Pkl_Filename, 'wb') as file:  \n    pickle.dump(bnb, file)","e70591db":"# Exporting Counter Vector to get the BOW at Runtime\n# Exporting my model to use in a project \nCV_Pkl_Filename = \"CounterVector.pkl\"  \n\nwith open(CV_Pkl_Filename, 'wb') as file:  \n    pickle.dump(vect, file)","a8716485":"## Reading Data ","e26a3d47":"**This is my Repository For Implementing Naive Bayes Model using Bernoulli Sklearn Model**"}}