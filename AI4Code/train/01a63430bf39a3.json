{"cell_type":{"622b8722":"code","7948fce9":"code","9df6a2c0":"code","c023975a":"code","29ae06a5":"code","97f1b229":"code","09f7d112":"code","52e05a75":"code","a40eb729":"code","1adcffeb":"code","94c61df7":"code","1d09d687":"code","012f42e6":"code","fc75edba":"code","4dff63f3":"code","d2125ea3":"code","42c3a022":"code","d3e34255":"code","63d43b57":"code","292fe452":"code","73acc78b":"code","7bf1f31f":"code","24c5339f":"code","7d193857":"code","c241fa1f":"code","961fb5bc":"code","3eb5abb8":"code","b5e921f3":"code","17fb8135":"code","77f888e1":"code","9a97ee11":"markdown","b0d8392e":"markdown"},"source":{"622b8722":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7948fce9":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport keras\nfrom keras.preprocessing import image\nfrom keras.models import Sequential\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array, smart_resize\nfrom keras.layers import Dense, Dropout, Flatten, BatchNormalization, Activation\nfrom keras.constraints import maxnorm\nfrom keras.layers.convolutional import Conv2D, MaxPooling2D\nfrom tensorflow.keras.optimizers import Adam\nimport cv2\nfrom PIL import Image\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.models import load_model\nfrom keras.metrics import AUC","9df6a2c0":"train_folder = '..\/input\/plant-pathology-2021-fgvc8\/train_images'\ntest_folder =  '..\/input\/plant-pathology-2021-fgvc8\/test_images'","c023975a":"df_train = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/train.csv')\ndf_test = pd.read_csv('..\/input\/plant-pathology-2021-fgvc8\/sample_submission.csv')","29ae06a5":"df_train.describe()","97f1b229":"df_train.head()","09f7d112":"df_train.labels.unique()","52e05a75":"labels = df_train.labels.unique()","a40eb729":"df_train.labels.value_counts()","1adcffeb":"df_train.labels = df_train.labels.astype('category')","94c61df7":"train_datagen  = ImageDataGenerator(\n                    rotation_range = 180,\n                    shear_range = 0.3,\n                    height_shift_range = 0.1,\n                    horizontal_flip = True,\n                    rescale = 1.\/255,\n                    zoom_range = 0.2,\n                    validation_split = 0.2)\ntest_datagen  = ImageDataGenerator(\n                    rescale = 1.\/255,\n                    validation_split = 0.2)","1d09d687":"train_generator = train_datagen.flow_from_dataframe(dataframe = df_train,\n                           directory = train_folder,\n                           target_size = (150,150),\n                           x_col = 'image',\n                           y_col = 'labels',\n                           batch_size = 32,\n                           class_mode = 'categorical',\n                           subset = 'training')\n\nvalidator_generator = test_datagen.flow_from_dataframe(dataframe = df_train,\n                             directory = train_folder,\n                             target_size = (150,150),\n                             x_col = 'image',\n                             y_col = 'labels',\n                             batch_size = 32,\n                             class_mode = 'categorical',\n                             subset = 'validation')","012f42e6":"'''model = Sequential()\n\nmodel.add(Conv2D(32, (3, 3), padding = 'same', input_shape= (150,150,3)))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(64, (3, 3), padding = 'same'))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(128, (3, 3), padding = 'same'))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(12))\nmodel.add(Activation('softmax'))'''","fc75edba":"model = Sequential()\nmodel.add(Conv2D(32,(3,3),padding=\"same\", activation=\"relu\", input_shape=(150,150,3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(64, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Conv2D(128, (3,3), padding=\"same\", activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\nmodel.add(Dense(128,activation=\"relu\"))\nmodel.add(Dense(12, activation=\"softmax\"))\n\nmodel.summary()","4dff63f3":"model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","d2125ea3":"#history = model.fit(train_generator, steps_per_epoch=10, epochs=5, validation_data=validator_generator, validation_steps=50)\n#history = model.fit(train_generator, epochs=25, validation_data=validator_generator) \n#history = model.fit(train_generator, steps_per_epoch=10, epochs=10, validation_data=validator_generator, validation_steps=50)\n#history = model.fit(train_generator, steps_per_epoch=10, epochs=10, validation_data=validator_generator, validation_steps=100)","42c3a022":"model.fit(train_generator, steps_per_epoch=10, epochs=10, validation_data=validator_generator, validation_steps=50)","d3e34255":"scores = model.evaluate(validator_generator, verbose=0)\nprint(\"Accuracy: %.2f%%\" % (scores[1]*100))","63d43b57":"model.save('model.h5')\nmodel.save_weights('weights.h5')","292fe452":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(10)\n\nplt.figure(figsize=(15, 15))\nplt.subplot(2, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\n\nplt.subplot(2, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.show()\n","73acc78b":"\nmodel = '.\/model.h5'\nweight_model = '.\/weights.h5'\n\n\ncnn = load_model(model)\ncnn.load_weights(weight_model)\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe = df_test,\n                             directory = test_folder,\n                             target_size = (150,150),\n                             x_col = 'image',\n                             y_col = 'labels',\n                             batch_size = 32,\n                             class_mode = 'categorical')\n\n\npredictions=(cnn.predict(test_generator))","7bf1f31f":"predictions","24c5339f":"for l in labels:\n    print(l)","7d193857":"max_values = []\npred = []\nfor p in predictions:\n    pred.append(p)\n    max_values.append(max(p))","c241fa1f":"max_values","961fb5bc":"l = []\nfor value in pred:\n    for i, v in enumerate(value):\n        if v in max_values:\n            print(i,v)\n            l.append(i)","3eb5abb8":"label_final = []\nfor i, label in enumerate(labels):\n    for j in l:\n        if i == j:\n            label_final.append(label)\nprint(label_final)","b5e921f3":"df_test['final_label'] = label_final","17fb8135":"df_test.to_csv('submission.csv', index=False)","77f888e1":"df_test","9a97ee11":"cambiar metrica metrics=['accuracy', ADC()]","b0d8392e":"PREDICTIONS"}}