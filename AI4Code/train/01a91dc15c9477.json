{"cell_type":{"4fcd188f":"code","ea8cb5cb":"code","2908095b":"code","0b42b8c2":"code","def5769f":"code","d6baa0ec":"code","7b03a85c":"code","e9e725e7":"code","fc45ff0e":"code","b2cfab81":"code","87c68482":"code","a11ea0f7":"code","5cd5ae85":"code","7d8b2571":"code","d6c51973":"code","abe3c3b3":"code","6dc35b50":"code","4462f088":"code","ce0b1895":"code","1982b8bf":"code","6a6bab02":"code","2e5fbc99":"code","5785af09":"code","79542835":"code","0106e7e3":"code","00d8a4e3":"markdown","05ec3397":"markdown","576428d0":"markdown","278164be":"markdown","f24b5d81":"markdown","89c537a4":"markdown","5c858ec1":"markdown","2d8eb2b7":"markdown","44e396dc":"markdown"},"source":{"4fcd188f":"# importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nimport random\nimport cv2\nimport os\n\nimport warnings\nwarnings.simplefilter('ignore')","ea8cb5cb":"# importing libraries for deep learning\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, Activation\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator, load_img, img_to_array","2908095b":"# specifying dataset directories\ntrain_dir = \"\/kaggle\/input\/dogs-vs-cats\/train\/train\"\ntest_dir = \"\/kaggle\/input\/dogs-vs-cats\/test\/test\"\n\nprint('number of training images - ',len(os.listdir(train_dir)))\nprint('number of testing images - ',len(os.listdir(test_dir)))","0b42b8c2":"IMG_SIZE = 60\n\nCATEGORIES = [\"cat\", \"dog\"]","def5769f":"CATEGORIES.index(\"cat\")","d6baa0ec":"# creating training dataset\ndef create_training_data():\n    training_data  = []\n    images = []\n    labels = []\n    \n    imagefiles = [os.path.join(train_dir,f) for f in os.listdir(train_dir)]\n    for image in imagefiles:\n        category = image.split('\/')[-1].split('.')[0]\n        img_array = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n        training_data .append([new_array, CATEGORIES.index(category)])\n        \n    random.shuffle(training_data)\n    for features,label in training_data:\n        images.append(features)\n        labels.append(label)\n    images = np.array(images).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n    \n    return images, labels","7b03a85c":"images, labels = create_training_data()","e9e725e7":"len(images)","fc45ff0e":"# creating testing data\ndef create_testing_data():\n    test_images  = []\n    \n    imagefiles = [os.path.join(test_dir,f) for f in os.listdir(test_dir)]\n    for image in imagefiles:\n        img_array = cv2.imread(image, cv2.IMREAD_GRAYSCALE)\n        new_array = cv2.resize(img_array, (IMG_SIZE, IMG_SIZE))\n        test_images .append(new_array)\n        \n    random.shuffle(test_images)\n#     test_images = np.array(test_images).reshape(-1, IMG_SIZE, IMG_SIZE, 1)\n    return test_images\n\n\ntest_images = create_testing_data()\nlen(test_images)","b2cfab81":"len(test_images[0])","87c68482":"# standardizing between 0 to 255\nX_train = images \/ 255.0\nX_test = np.array(test_images).reshape(-1, IMG_SIZE, IMG_SIZE, 1) \/ 255.0\n\ny_train = np.array(labels)\n\n# convert from int to float\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')","a11ea0f7":"input_shape = (IMG_SIZE, IMG_SIZE, 1)\nnum_classes = 2","5cd5ae85":"model = Sequential()\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), activation=\"relu\", input_shape=input_shape))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(rate=0.25))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(rate=0.15))\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation=\"relu\"))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(rate=0.1))\nmodel.add(Flatten())\n\nmodel.add(Dense(units=32, activation=\"relu\"))\n\nmodel.add(Dense(units=num_classes, activation=\"softmax\"))","7d8b2571":"# ? model.compile","d6c51973":"model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=['accuracy'])","abe3c3b3":"model.summary()","6dc35b50":"# ? model.fit","4462f088":"batch_size = 256\nsteps = 200\nepochs = 50","ce0b1895":"history = model.fit(X_train, y_train,\n                    batch_size = batch_size,\n                    steps_per_epoch = steps,\n                    epochs = epochs,\n                    validation_split = 0.33,\n                    validation_steps = steps)","1982b8bf":"plt.figure(figsize=(10, 10))\n\nplt.subplot(2, 2, 1)\nplt.plot(history.history['loss'], label='Loss')\nplt.plot(history.history['val_loss'], label='Validation Loss')\nplt.legend()\nplt.title('Training - Loss Function')\n\nplt.subplot(2, 2, 2)\nplt.plot(history.history['accuracy'], label='Accuracy')\nplt.plot(history.history['val_accuracy'], label='Validation Accuracy')\nplt.legend()\nplt.title('Train - Accuracy')","6a6bab02":"model.evaluate(X_train, y_train)","2e5fbc99":"#Get the predictions for the test data\npredicted_classes = model.predict_classes(X_test)\n\n#Let's Visualize some predicted images \nplt.figure(figsize=(10,10))\nrand = np.random.randint(0,1000*2,25)\nfor i in range(len(rand)):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid('off')\n    plt.imshow(test_images[rand[i]], cmap=\"gray\")\n    plt.xlabel(CATEGORIES[predicted_classes[rand[i]]])","5785af09":"model.save(\"cnn_classifier\")\n\nloaded_model = keras.models.load_model(\"cnn_classifier\")\n\nnp.testing.assert_allclose(\n    model.predict(X_test), loaded_model.predict(X_test)\n)\n\nloaded_predicted_classes = loaded_model.predict_classes(X_test)","79542835":"model.evaluate(X_train, y_train)","0106e7e3":"#Let's Visualize some predicted images \nplt.figure(figsize=(10,10))\nrand = np.random.randint(0,1000*2,25)\nfor i in range(len(rand)):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid('off')\n    plt.imshow(test_images[rand[i]], cmap=\"gray\")\n    plt.xlabel(CATEGORIES[loaded_predicted_classes[rand[i]]])","00d8a4e3":"Let us plot the Training Accuracy vs Loss to get a better understanding of the model training.","05ec3397":"## Compiling the model","576428d0":"## Creating Training & Testing Data","278164be":"## Fitting the model","f24b5d81":"## Model Building","89c537a4":"## Saving the model","5c858ec1":"## Reading the datafiles","2d8eb2b7":"## Importing necessary libraries","44e396dc":"## Result"}}