{"cell_type":{"e1ed7e8f":"code","4f96d02a":"code","46e763b2":"code","ce25eefa":"code","6e0ade08":"code","a720b51d":"code","8107082f":"code","55dbfb53":"code","26d53ebe":"code","786f1175":"code","99edbdbd":"code","80e2acfd":"code","d2abcc1e":"code","3bb4db3f":"code","86b4d09f":"code","40875335":"code","24cae730":"code","159078f1":"code","3e18ac55":"code","fb0a5893":"code","2ba507bb":"code","65f6f685":"code","c4a16906":"code","4fb8c918":"code","deae0c5a":"code","972d4d7c":"code","b6ac0cc4":"code","dfb0be4e":"code","3b50025d":"code","c6b5b700":"code","286e1d9b":"code","841df12b":"code","874e0af2":"markdown","6c3dbbf4":"markdown","c4a12ce1":"markdown","e3eeca8d":"markdown","fce5599f":"markdown","a5602c3f":"markdown","a35445f1":"markdown","0e68c413":"markdown","cdf4f591":"markdown","db1991b9":"markdown","851e680a":"markdown","48858a63":"markdown","68e8c092":"markdown","4a468e5d":"markdown","a9f705e8":"markdown"},"source":{"e1ed7e8f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4f96d02a":"df_male=pd.read_csv('..\/input\/names\/names\/male.txt')","46e763b2":"df_male['Aamir']=df_male['Aamir'].str.lower()","ce25eefa":"text=df_male['Aamir'].to_numpy()","6e0ade08":"maxlen = len(max(text, key=len))","a720b51d":"for i in range(len(text)):\n  while len(text[i])<maxlen:\n      text[i] += ' '","8107082f":"chars=set(''.join(text))","55dbfb53":"int2char = dict(enumerate(chars))","26d53ebe":"int2char","786f1175":"import torch\nfrom torch import nn","99edbdbd":"device=torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")","80e2acfd":"char2int = {char: ind for ind, char in int2char.items()}","d2abcc1e":"# Creating lists that will hold our input and target sequences\ninput_seq = []\ntarget_seq = []\n\nfor i in range(len(text)):\n    # Remove last character for input sequence\n  input_seq.append(text[i][:-1])\n    \n    # Remove first character for target sequence\n  target_seq.append(text[i][1:])\n  print(\"Input Sequence: {}\\nTarget Sequence: {}\".format(input_seq[i], target_seq[i]))","3bb4db3f":"for i in range(len(text)):\n    input_seq[i] = [char2int[character] for character in input_seq[i]]\n    target_seq[i] = [char2int[character] for character in target_seq[i]]\n","86b4d09f":"dict_size = len(char2int)\nseq_len = maxlen - 1\nbatch_size = len(text)\n\ndef one_hot_encode(sequence, dict_size, seq_len, batch_size):\n    # Creating a multi-dimensional array of zeros with the desired output shape\n    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n    \n    # Replacing the 0 at the relevant character index with a 1 to represent that character\n    for i in range(batch_size):\n        for u in range(seq_len):\n            features[i, u, sequence[i][u]] = 1\n    return features","40875335":"input_seq = one_hot_encode(input_seq, dict_size, seq_len, batch_size)","24cae730":"input_seq[0]","159078f1":"input_seq = torch.from_numpy(input_seq).to(device)\ntarget_seq = torch.Tensor(target_seq).to(device)","3e18ac55":"class Model(nn.Module):\n    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n        super(Model, self).__init__()\n\n        self.hidden_dim = hidden_dim\n        self.n_layers = n_layers\n\n        self.rnn = nn.GRU(input_size, hidden_dim, n_layers, batch_first=True)   \n        self.fc = nn.Linear(hidden_dim, output_size)\n    \n    def forward(self, x):\n        \n        batch_size = x.size(0)\n\n        hidden = self.init_hidden(batch_size)\n\n        out, hidden = self.rnn(x, hidden.to(device))\n        \n        out = out.contiguous().view(-1, self.hidden_dim)\n        out = self.fc(out)\n        \n        return out, hidden\n    \n    def init_hidden(self, batch_size):\n        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim)\n        hidden.to(device)\n        return hidden","fb0a5893":"model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n\nmodel.to(device)\n# Define hyperparameters\nn_epochs = 25000\nlr=0.01\n\n# Define Loss, Optimizer\ncriterion = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=lr)","2ba507bb":"from sklearn.model_selection import train_test_split","65f6f685":"X=input_seq\nY=target_seq","c4a16906":"X_train,Y_train,X_test,Y_test=train_test_split(X,Y,test_size=0.2)","4fb8c918":"int(X.shape[0]\/mini_batch_size-1)","deae0c5a":"# Training Run\nfor epoch in range(1, n_epochs):\n    mini_batch_size=100\n    for m in range(int(X_train.shape[0]\/mini_batch_size-1)):  \n        optimizer.zero_grad() \n        X_train_mini=X[m*mini_batch_size:(m+1)*mini_batch_size]\n        X_train_mini.to(device)\n        Y_train_mini=Y[m*mini_batch_size:(m+1)*mini_batch_size]\n\n        output, hidden = model(X_train_mini)\n        loss = criterion(output, Y_train_mini.view(-1).long())\n        loss.backward() \n        optimizer.step() \n    print('',end='.')\n    if epoch%1000 == 0:\n            print('\\nEpoch: {}\/{}.............'.format(epoch, n_epochs), end=' ')\n            print(\"Loss: {:.4f}\".format(loss.item()))","972d4d7c":"def predict(model, character):\n    # One-hot encoding our input to fit into the model\n    character = np.array([[char2int[c] for c in character]])\n    character = one_hot_encode(character, dict_size, character.shape[1], 1)\n    character = torch.from_numpy(character).to(device)\n    \n    out, hidden = model(character)\n\n    prob = nn.functional.softmax(out[-1], dim=0).data\n    # Taking the class with the highest probability score from the output\n    char_ind = torch.max(prob, dim=0)[1].item()\n\n    return int2char[char_ind], hidden\n","b6ac0cc4":"def sample(model, out_len, start='hey'):\n    model.eval() # eval mode\n    start = start.lower()\n    # First off, run through the starting characters\n    chars = [ch for ch in start]\n    size = out_len - len(chars)\n    # Now pass in the previous characters and get a new one\n    for ii in range(size):\n        char, h = predict(model, chars)\n        chars.append(char)\n\n    return ''.join(chars)","dfb0be4e":"import string","3b50025d":"alphabet_string=string.ascii_uppercase","c6b5b700":"a=torch.tensor([1,2,3,4,5])","286e1d9b":"for i in alphabet_string.lower():\n    print(sample(model,15,i))","841df12b":"torch.save(model.state_dict(), '\/kaggle\/working\/params.pt')","874e0af2":"Train the model. Longer you train better the results will be","6c3dbbf4":"Predict the output. Note as we have used max it will only generate a particular word for a particular start word","c4a12ce1":"lets read names of male","e3eeca8d":"Import neccerary modules from pytorch","fce5599f":"okay now lets create a dictionary. set helps us to only keep unique letters. ","a5602c3f":"In our model for name generation, we will be providing a intial letter (lets say 'p') and Model shall generate rest of word(like 'patrick').\nso input will be all letters of words except the last one.We dont need to input last letter as it will not have any prediction.similary we dont need first letter as output too.","a35445f1":"A Name Generator using simple rnn network","0e68c413":"One Hotcoding the words","cdf4f591":"lets create a text array which actually stores all are names ","db1991b9":"As Its clear that all names are not of equal length , so lets make them of equal length by giving a padding of ' '.we would require length of longest string","851e680a":"Our input seqeunce looks like this","48858a63":"Create instance of model ","68e8c092":"As i have not sepcified the column name it assumed aamir to be column name. Thats fine we will also assume the same\n","4a468e5d":"Create The model\n\nit is a simple nn with a rnn and a fully connected layer. Note: RNN would require us to pass a initial state for hidden layer h_0 so we generate it using init_hidden function\n","a9f705e8":"As Rnn can only deal with numeric data we will create a dictionary for characters to int and vice versa. Then we will create one hot vector for each character in each name"}}