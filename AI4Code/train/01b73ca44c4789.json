{"cell_type":{"384b81e8":"code","5c0cba60":"code","9b01e48f":"code","62a70b66":"code","38f2aaef":"code","f30d8753":"code","f5bced06":"code","1f9abfdd":"code","e76f95d9":"code","524a5101":"code","4005048f":"code","f9280fb6":"code","4b2a4479":"code","76749f2a":"code","31f540c3":"code","2437eea0":"code","bbaf440d":"code","b5571c72":"code","ed02904c":"code","230ae3c1":"code","bcf98aaf":"code","7e0ea1ea":"code","9cb5f0a5":"code","06148716":"code","2c73e526":"markdown","9b601584":"markdown","33a90d74":"markdown","c9ae0bb6":"markdown","755c6272":"markdown","aa03949f":"markdown","8def2115":"markdown","16911e01":"markdown","636b1eff":"markdown"},"source":{"384b81e8":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5c0cba60":"#import required libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport re\nimport string\nimport math\nimport spacy\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom wordcloud import WordCloud\nfrom textwrap import wrap\nfrom textblob import TextBlob\n","9b01e48f":"pip install textstat","62a70b66":"import textstat","38f2aaef":"# load dataset\n\ntext=pd.read_csv('\/kaggle\/input\/consumer-reviews-of-amazon-products\/1429_1.csv')\ntext.shape","f30d8753":"text.head()","f5bced06":"#Select required features for analysis from the 21 given columns.\n\ntext.columns","1f9abfdd":"#Select the the 4 key columns, product name, review content, users if they recommend the product, and number of people who found the review helpful\ntextdata = text[['name','reviews.text','reviews.doRecommend','reviews.numHelpful']]\ntextdata.head()","e76f95d9":"#Drop null values\ntextdata.dropna(inplace=True)\ntextdata.isna().sum()","524a5101":"textcopy=textdata.copy()\n","4005048f":"#Filter products based on number of reviews\n\ntextdata=textdata.groupby(['name']).filter(lambda x: len(x)>300).reset_index(drop=True)\nprint('Number of products matching the criteria is ',len(textdata['name'].unique()))","f9280fb6":"#convert datatype boolean and float to int\ntextdata['reviews.doRecommend']=textdata['reviews.doRecommend'].astype(int)\ntextdata['reviews.numHelpful']=textdata['reviews.numHelpful'].astype(int)","4b2a4479":"#Cleaning Text data. There are 10 unique product names. Remove unwanted characters from the names.\n\ntextdata['name'].unique()\ntextdata['name']=textdata['name'].apply(lambda x: x.split(',,,')[0])","76749f2a":"#Explore and clean the review text\n\nfor text in enumerate(textdata['reviews.text'][20:30]):\n  print('Review:\\n',text)","31f540c3":"# While developing NLP models capital and lowercase letters are treated differently so its required to convert all words to lowercase, as few words are in capitals in the review text.\n\ntextdata['reviews.text']=textdata['reviews.text'].apply(lambda x: x.lower())","2437eea0":"# Eliminate digits in the text using regular expressions\n\ntextdata['reviews.text']=textdata['reviews.text'].apply(lambda x: re.sub('\\w*\\d\\w*','', x))","bbaf440d":"#Eliminate punctuaitons\n\ntextdata['reviews.text']=textdata['reviews.text'].apply(lambda x: re.sub('[%s]' % re.escape(string.punctuation), '', x))","b5571c72":"\n# use spacy module\nnlp = spacy.load('en_core_web_sm',disable=['parser', 'ner'])\n\n# stopwords removal and lemmatization\ntextdata['reviews.text']=textdata['reviews.text'].apply(lambda x: ' '.join([token.lemma_ for token in list(nlp(x)) if (token.is_stop==False)]))\n\ntextdata=textdata[['name','reviews.text']].groupby(by='name').agg(lambda x:' '.join(x))\ntextdata.head()","ed02904c":"#Generate document term matrix to find most occuring terms in the reviews\n\ncv=CountVectorizer(analyzer='word')\ndata=cv.fit_transform(textdata['reviews.text'])\ntext_dtm = pd.DataFrame(data.toarray(), columns=cv.get_feature_names())\ntext_dtm.index=textdata.index\ntext_dtm.head()","230ae3c1":"def wordcloud(data,title):\n  wc = WordCloud(width=600, height=530, max_words=150,colormap=\"Dark2\").generate_from_frequencies(data)\n  plt.figure(figsize=(10,8))\n  plt.imshow(wc, interpolation='bilinear')\n  plt.axis(\"off\")\n  plt.title('\\n'.join(wrap(title,60)),fontsize=13)\n  plt.show()\n  \ntext_dtm=text_dtm.transpose()\n\nfor index,product in enumerate(text_dtm.columns):\n  wordcloud(text_dtm[product].sort_values(ascending=False),product)\n \n","bcf98aaf":"#Polarity in sentiment analysis refers to identifying sentiment orientation (positive, neutral, and negative) in written or spoken language.\n\ntextdata['emotion']=textdata['reviews.text'].apply(lambda x:TextBlob(x).sentiment.polarity)\n\n ","7e0ea1ea":"product_polarity=pd.DataFrame(textdata.groupby('name')['emotion'].mean().sort_values(ascending=True))\n\nplt.figure(figsize=(16,8))\nplt.xlabel('Emotion')\nplt.ylabel('Products')\nplt.title('Polarity of Product Reviews')\npolarity_graph=plt.barh(np.arange(len(product_polarity.index)),product_polarity['emotion'],color='blue')\n\n\nfor bar,product in zip(polarity_graph,product_polarity.index):\n  plt.text(0.005,bar.get_y()+bar.get_width(),'{}'.format(product),va='center',fontsize=11,color='white')\n\nfor bar,polarity in zip(polarity_graph,product_polarity['emotion']):\n  plt.text(bar.get_width()+0.001,bar.get_y()+bar.get_width(),'%.3f'%polarity,va='center',fontsize=11,color='black')\n  \nplt.yticks([])\nplt.show()","9cb5f0a5":"textcopy['reviews.doRecommend']=textcopy['reviews.doRecommend'].astype(int)\ntextcopy['reviews.numHelpful']=textcopy['reviews.numHelpful'].astype(int)","06148716":"#using textstat package\n\ntextcopy['reading_time']=textcopy['reviews.text'].apply(lambda x: textstat.reading_time(x))\n\nprint('Reading Time of upvoted reviews is',textcopy[textcopy['reviews.numHelpful']>1]['reading_time'].mean())\nprint('Reading Time of not upvoted reviews is',textcopy[textcopy['reviews.numHelpful']<=1]['reading_time'].mean())\n","2c73e526":"**Word cloud helps to quickly understand and visualize the most frequently occuring terms in the reviews. Next we will use sentiment analysis to delve deeper into the reviews for each product. Sentiment analysis is the process of determining the emotional tone behind a series of words, used to gain an understanding of the the attitudes, opinions and emotions expressed within an online mention.* \n**We can check how many reviews are positive and how many are negative in the dataset. **","9b601584":"**Before diving into data exploration it is required to understand the words that are most occuring in the reviews and remove stopwords such as, 'in', 'is'. SpaCy can be used for this purpose, which is a Python library for NLP. **","33a90d74":"# Data Exploration\n\nNow its time to explore the preprocessed and cleaned text reviews. Textual data can be explored using Word Clouds. These are visual representations of the frequency of different words present in text. Importance of words are represented by size of the word. Bigger size represents more frequently occuring words.","c9ae0bb6":"This shows that people prefer reading longer reviews as reading time of upvoted reviews is more when compared to that of not upvoted reviews. People like to read details reviews of products before buying.","755c6272":"# Exploratory data analysis very important for any kind of data as it lays strong foundation for building effective ML algorithms. This kernel walks through steps to analyse textual data, which is very important for any NLP project.\n\nI will explore this data set containing reviews and information for Amazon products, and draw insights through EDA. We will go in steps through the EDA process.","aa03949f":"# Data Preprocessing","8def2115":"**Python package textstat is used to calculate statistics from text to determine readability of texts. We can use this to determine if reading time of reviews upvoted as helpful and non-helpful have any impact.**\n\n","16911e01":"**In this way you can do EDA on text data and get lots of hidden insights from the data. For more information on this refer,**\n\nhttps:\/\/www.analyticsvidhya.com\/blog\/2014\/11\/text-data-cleaning-steps-python\/\n","636b1eff":"**Here first few products have good feedback from the viewers whereas last few products depicted in the bar graph have lesser user ratings.** **This helps in understanding the popularity of products through user reviews.**"}}