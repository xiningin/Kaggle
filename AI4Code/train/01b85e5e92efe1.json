{"cell_type":{"602e025b":"code","5ea38a56":"code","3992c7f8":"code","80ebcb8b":"code","50f11a36":"code","2fda4d7b":"code","5ca046c4":"code","2edef091":"code","a6787262":"code","91f8a6d0":"code","a040068c":"code","2246eadc":"code","b98b9e3f":"code","520ecad5":"code","95a704b5":"code","ebfe7b35":"code","c7e36ac1":"code","ff4f648d":"code","ffbb0c6b":"code","cbbeb294":"code","9524a519":"markdown","375ce605":"markdown","f8b215bc":"markdown","968843ae":"markdown","b4c66c64":"markdown","e6da3da2":"markdown","f58dd5e9":"markdown","1e37a5a7":"markdown","bf0d9457":"markdown","71f571ac":"markdown","42dc2e35":"markdown","11a75932":"markdown","20c2dc8b":"markdown","240f5d3c":"markdown","d0215b5e":"markdown"},"source":{"602e025b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport os\nfrom sklearn.utils import shuffle\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator, img_to_array, load_img\nimport cv2\nfrom scipy.spatial import distance","5ea38a56":"mask_path = \"..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\"\nno_mask_path = \"..\/input\/human-faces\/Humans\"","3992c7f8":"image_mask = []\ntarget_mask = []\nfor i in os.listdir(mask_path):\n    pic = os.path.join(mask_path + \"\/\", i)\n    image_mask.append(pic)\n    target_mask.append(\"mask\")   \n\nimage_no_mask = []\ntarget_no_mask = []\nfor i in os.listdir(no_mask_path):\n    pic = os.path.join(no_mask_path + \"\/\", i)\n    image_no_mask.append(pic)\n    target_no_mask.append(\"without_mask\")\n\nmask = pd.DataFrame()\nmask[\"image\"] = image_mask\nmask[\"target\"] = target_mask\n\nno_mask = pd.DataFrame()\nno_mask[\"image\"] = image_no_mask\nno_mask[\"target\"] = target_no_mask\n\ndata = pd.concat([mask, no_mask], axis = 0, ignore_index = True)\ndata = shuffle(data)\ndata","80ebcb8b":"sns.countplot(data[\"target\"])","50f11a36":"plt.figure(figsize=(12,8))\n\nimg = load_img(mask[\"image\"][8])\nplt.imshow(img)\nplt.title(\"With Mask\", color = \"green\", size = 14)\nplt.grid(color='#999999', linestyle='-')\nplt.show()","2fda4d7b":"plt.figure(figsize=(12,8))\n\nimg = load_img(no_mask[\"image\"][750])\nplt.imshow(img)\nplt.title(\"Without Mask\", color = \"green\", size = 14)\nplt.grid(color='#999999', linestyle='-')\nplt.show()","5ca046c4":"train = data.iloc[0:10000, ]\nval = data.iloc[10001:11001, ]\ntest = data.iloc[11002:, ]","2edef091":"print(\"Train Seti:\",\"\\n\",train[\"target\"].value_counts(),\"\\n\"\"Validation Seti: \",\"\\n\", val[\"target\"].value_counts(), \"\\n\"\n      \"Test Seti: \", \"\\n\",test[\"target\"].value_counts())","a6787262":"train_datagen = ImageDataGenerator(rescale = 1.\/255,\n                                   rotation_range = 40,\n                                   width_shift_range = 0.2,\n                                   height_shift_range = 0.2,\n                                   shear_range = 0.2,\n                                   zoom_range = 0.2,\n                                   horizontal_flip = True,\n                                   fill_mode = \"nearest\")\n\ntrain_generator = train_datagen.flow_from_dataframe(dataframe = train,\n                                                    x_col = \"image\",\n                                                    y_col = \"target\",\n                                                    target_size = (150, 150),\n                                                    batch_size = 32,\n                                                    class_mode = \"binary\")\n\nval_datagen = ImageDataGenerator(rescale = 1.\/255)\n\nval_generator = val_datagen.flow_from_dataframe(dataframe = val,\n                                                x_col = \"image\",\n                                                y_col = \"target\",\n                                                target_size = (150, 150),\n                                                batch_size = 32,\n                                                class_mode = \"binary\")\n\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_generator = test_datagen.flow_from_dataframe(dataframe = test,\n                                                  x_col = \"image\",\n                                                  y_col = \"target\",\n                                                  target_size = (150, 150),\n                                                  class_mode = \"binary\",\n                                                  batch_size = 32)","91f8a6d0":"from keras import layers\nfrom keras import models\nfrom keras import optimizers\nfrom keras.applications.vgg19 import VGG19\nfrom keras.applications.vgg19 import preprocess_input\n\nvgg19 = VGG19(weights='imagenet',include_top=False,input_shape=(128,128,3))\n\nfor layer in vgg19.layers:\n    layer.trainable = False\n    \nmodel = models.Sequential()\nmodel.add(vgg19)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(1,activation='sigmoid'))\nmodel.summary()","a040068c":"model.compile(loss = \"binary_crossentropy\",\n             optimizer = optimizers.RMSprop(lr = 1e-4),\n             metrics = [\"acc\"])","2246eadc":"history = model.fit(train_generator,\n                    steps_per_epoch=len(train_generator)\/\/32,\n                    epochs=50,\n                    validation_data=val_generator,\n                    validation_steps=len(val_generator)\/\/32)","b98b9e3f":"acc = history.history[\"acc\"]\nval_acc = history.history[\"val_acc\"]\nloss = history.history[\"loss\"]\nval_loss = history.history[\"val_loss\"]\n\nepochs = range(1, len(acc) + 1)\n\nplt.figure(figsize = (15, 6))\n\nplt.plot(epochs, acc, \"bo\", label = \"E\u011fitim Ba\u015far\u0131s\u0131\")\nplt.plot(epochs, val_acc, \"b\", label = \"Test Ba\u015far\u0131s\u0131\")\nplt.title(\"E\u011fitim ve Test Ba\u015far\u0131s\u0131\")\nplt.legend()\n\nplt.figure(figsize = (15, 6))\n\nplt.plot(epochs, loss, \"bo\", label = \"E\u011fitim Kayb\u0131\")\nplt.plot(epochs, val_loss, \"b\", label = \"Do\u011frulama Kayb\u0131\")\nplt.legend()\n\nplt.show()","520ecad5":"test_loss, test_acc = model.evaluate(test_generator, steps = 9)\nprint(\"Test ACC: \", round(test_acc, 2))","95a704b5":"face_model = cv2.CascadeClassifier('..\/input\/haarcascades\/haarcascade_frontalface_default.xml')\nimg = cv2.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\/1058.png')\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n\nout_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR)\n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),1)\nplt.figure(figsize=(12,12))\nplt.imshow(out_img)","ebfe7b35":"sample_mask_img = cv2.imread('..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train\/WithMask\/1058.png')\nsample_mask_img = cv2.resize(sample_mask_img,(128,128))\nsample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\nsample_mask_img = sample_mask_img\/255.0\nmodel.predict(sample_mask_img)","c7e36ac1":"mask_label = {0:'OK!',1:'Busted'}\ndist_label = {0:(0,255,0),1:(255,0,0)}\nMIN_DISTANCE = 0\n\nif len(faces)>=1:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(128,128))\n        crop = np.reshape(crop,[1,128,128,3])\/255.0\n        mask_result = model.predict(crop)\n        cv2.putText(new_img,mask_label[round(mask_result[0][0])],(x, y+90), cv2.FONT_HERSHEY_SIMPLEX,0.5,dist_label[label[i]],2)\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n            \nelse:\n    print(\"Y\u00fcz yok!\")","ff4f648d":"img = cv2.imread('..\/input\/human-faces\/Humans\/1 (1093).jpg')\n\nimg = cv2.cvtColor(img, cv2.IMREAD_GRAYSCALE)\n\nfaces = face_model.detectMultiScale(img,scaleFactor=1.1, minNeighbors=4)\n\nout_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) \n\nfor (x,y,w,h) in faces:\n    cv2.rectangle(out_img,(x,y),(x+w,y+h),(0,0,255),1)\nplt.figure(figsize=(12,12))\nplt.imshow(out_img)","ffbb0c6b":"sample_mask_img = cv2.imread('..\/input\/human-faces\/Humans\/1 (1092).jpg')\nsample_mask_img = cv2.resize(sample_mask_img,(128,128))\nsample_mask_img = np.reshape(sample_mask_img,[1,128,128,3])\nsample_mask_img = sample_mask_img\/255.0\nmodel.predict(sample_mask_img)","cbbeb294":"if len(faces)>=1:\n    label = [0 for i in range(len(faces))]\n    for i in range(len(faces)-1):\n        for j in range(i+1, len(faces)):\n            dist = distance.euclidean(faces[i][:2],faces[j][:2])\n            if dist<MIN_DISTANCE:\n                label[i] = 1\n                label[j] = 1\n    new_img = cv2.cvtColor(img, cv2.COLOR_RGB2BGR) #colored output image\n    for i in range(len(faces)):\n        (x,y,w,h) = faces[i]\n        crop = new_img[y:y+h,x:x+w]\n        crop = cv2.resize(crop,(128,128))\n        crop = np.reshape(crop,[1,128,128,3])\/255.0\n        mask_result = model.predict(crop)\n        cv2.putText(new_img,mask_label[round(mask_result[0][0])],(x, y), cv2.FONT_HERSHEY_SIMPLEX,3,dist_label[label[i]],2)\n        cv2.rectangle(new_img,(x,y),(x+w,y+h),dist_label[label[i]],1)\n    plt.figure(figsize=(10,10))\n    plt.imshow(new_img)\n            \nelse:\n    print(\"Y\u00fcz yok!\")","9524a519":"Test do\u011fruluk oran\u0131 yukar\u0131daki \u00e7\u0131kt\u0131.","375ce605":"**MASK DETECT\u0130ON**","f8b215bc":"Datadaki maskeli ve maskesiz foto\u011fraflar\u0131n da\u011f\u0131l\u0131mlar\u0131 a\u015fa\u011f\u0131daki gibidir. Maskesiz insan foto\u011fraflar\u0131 biraz daha y\u00fcksek olsada veride a\u015f\u0131r\u0131 bir dengesizlik bulunmamaktad\u0131r.","968843ae":"\u00d6nce maskeli bir foto\u011fraf ard\u0131nda maskesiz bir foto\u011fraf y\u00fckledim g\u00f6r\u00fcnt\u00fcs\u00fc a\u015fa\u011f\u0131da daha sonra bu g\u00f6rseli modele sokarak test ediliyor.\n\nTest sonucu 0-0.5 aras\u0131 gelmesi maskeli 0.5-1 aras\u0131 gelmesi ise maskesiz oldu\u011fu anlam\u0131na geliyor.\n\nE\u011fer bir ki\u015fi maskeli ise bize **\"OK!**\" cevab\u0131n\u0131 d\u00f6nd\u00fcrecek yok de\u011fil ise **\"BUSTED!\"** cevab\u0131n\u0131 verecek.\n\nVe san\u0131r\u0131m maskeli abimiz t\u00fcrk :) ","b4c66c64":"E\u011fitim sonu\u00e7lar\u0131 a\u015fa\u011f\u0131daki gibi geldi.\n\n15-20 epoktan sonra ba\u015far\u0131 iyile\u015fmenin h\u0131z\u0131 d\u00fc\u015fm\u00fc\u015f validasyon \u00fczerinde ise daha fazla hareketlilik var ba\u015far\u0131 90-95 aras\u0131 gibi g\u00f6z\u00fckmekte kay\u0131plar ise 15-20 aras\u0131nda","e6da3da2":"Modeli e\u011fitip testlerini yap\u0131ld\u0131 \u015fimdi foto\u011fraflar \u00fczerinden g\u00f6rsel olarak sonu\u00e7lar\u0131 g\u00f6relim.\n\nBu g\u00f6rselle\u015ftirme i\u015flemleri i\u00e7in y\u00fcz tespiti kullan\u0131lmakta buradaki y\u00fcz tespiti \"haarcascades\" ile haz\u0131r olarak yap\u0131ld\u0131 grafik i\u015flemleri i\u00e7in [https:\/\/www.kaggle.com\/nageshsingh\/mask-and-social-distancing-detection-using-vgg19\/data](http:\/\/) \u00e7al\u0131\u015fmas\u0131ndan yararland\u0131m g\u00fczel bir \u00e7al\u0131\u015fma tavsiye ederim.","f58dd5e9":"Model kurarken yeni bir model yerine haz\u0131r e\u011fitilmi\u015f VGG19 modeli ald\u0131m yine a\u011f\u0131rl\u0131klar\u0131n\u0131 imagenet olarak verdim.","1e37a5a7":"Modeli validation \u00fczerinden ilk testlerini yap\u0131ld\u0131 art\u0131k test datas\u0131n\u0131 kullanarak sonu\u00e7lar\u0131 g\u00f6rebiliriz.","bf0d9457":"Umar\u0131m \u00e7al\u0131\u015fma sizler i\u00e7in faydal\u0131 olmu\u015ftur, en k\u0131sa s\u00fcrede tam normal olarak g\u00f6r\u00fc\u015fmek \u00fczere :)\n\n#MaskeTak","71f571ac":"Merhaba!\n\nYeniden Tam kapanmaya(!) girdi\u011fimiz bu g\u00fcnlerde g\u00fcn\u00fcn anlam ve \u00f6nemine istinaden akl\u0131ma maske detekt\u00f6r\u00fc yapma fikri geldi.\n\nKaggle'da buna benzer bir \u00e7ok \u00e7al\u0131\u015fman\u0131n mevcut oldu\u011funu g\u00f6rd\u00fcm i\u00e7lerinden baz\u0131lar\u0131 ger\u00e7ekten \u00e7ok ba\u015far\u0131l\u0131yd\u0131, bu \u00e7al\u0131\u015fmada da yine bir\u00e7ok \u00f6rnekte oldu\u011fu gibi maske takan ve maske takmayan insanlar\u0131 birbirlerinden ay\u0131rt etmeye \u00e7al\u0131\u015faca\u011f\u0131m.\n\nBunun i\u00e7in kaggle \u00fczerinden \u00f6nce maske takan insanlar\u0131n oldu\u011fu bir data seti arad\u0131m. Maske takan insanlar i\u00e7in kulland\u0131\u011f\u0131m data seti \"face-mask-12k-images-dataset\" oldu fakat buradak data setinden yaln\u0131zca train ve maskeli olan foto\u011fraflar\u0131 ald\u0131m. Maskesiz insanlar i\u00e7in ise \"human-faces\" isimli data setini kulland\u0131m. Asl\u0131nda sadece \"face-mask-12k-images-dataset\" i\u00e7inde hem maskeli hemde maskesiz insan foto\u011fraflar\u0131 vard\u0131 ama maskesiz foto\u011fraflar\u0131 \u00e7ok be\u011fenmedim (asl\u0131nda maskelilerde pek g\u00fczel de\u011fildi ama neticede maskeli :) ) bu y\u00fczden iki farkl\u0131 data kullanmak istedim.","42dc2e35":"Maskeli ve maskesiz olan foto\u011fraflardan birer \u00f6rne\u011fe g\u00f6z atal\u0131m.","11a75932":"Setlere b\u00f6ld\u00fckten sonra model i\u00e7in resimleri d\u00fczenleme i\u015flemine geldim.\n\nBurada train setine data \u00e7ok b\u00fcy\u00fck olmad\u0131\u011f\u0131 i\u00e7in \u00e7e\u015fitlendirme uygulad\u0131m.","20c2dc8b":"Data haz\u0131r oldu\u011funda data setini train, validation ve test olarak \u00fc\u00e7 ayr\u0131 sete b\u00f6l\u00fcyorum. \n\nDatay\u0131 ilk olu\u015fturdu\u011fumda s\u0131ral\u0131 olarak alm\u0131\u015ft\u0131m fakat son a\u015famada shuffle yapt\u0131\u011f\u0131m i\u00e7in burada iloc yard\u0131m\u0131 ile setlerimi olu\u015fturabilirim. \n\nSetlerimin adetleri de yine a\u015fa\u011f\u0131dad\u0131r.","240f5d3c":"Datalar\u0131 almak i\u00e7in pathleri olu\u015fturdum ard\u0131ndan maskeli ve maskesiz foto\u011fraflar i\u00e7in data frameleri birle\u015ftirdim.","d0215b5e":"train ve validation setlerini e\u011fitim i\u00e7in kulland\u0131m test setini evaluate yaparken kullanaca\u011f\u0131m."}}