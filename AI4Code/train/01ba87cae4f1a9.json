{"cell_type":{"342db185":"code","99497160":"code","2d5858db":"code","9d53182c":"code","ecd71aee":"code","35900a88":"code","f9859077":"code","c2081dd0":"code","ba9cfdf4":"code","3ba7d2d2":"code","d11bb39f":"code","196e2777":"code","3050f9f9":"markdown","ae678192":"markdown","726b2aed":"markdown","06ef71bf":"markdown","53cb919f":"markdown","21ddb091":"markdown","f1de5ead":"markdown","dee03c7b":"markdown","e00e6313":"markdown"},"source":{"342db185":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os","99497160":"# Distribution graphs (histogram\/bar graph) of column data\ndef plotPerColumnDistribution(df, nGraphShown, nGraphPerRow):\n    nunique = df.nunique()\n    df = df[[col for col in df if nunique[col] > 1 and nunique[col] < 50]] # For displaying purposes, pick columns that have between 1 and 50 unique values\n    nRow, nCol = df.shape\n    columnNames = list(df)\n    nGraphRow = (nCol + nGraphPerRow - 1) \/ nGraphPerRow\n    plt.figure(num = None, figsize = (6 * nGraphPerRow, 8 * nGraphRow), dpi = 80, facecolor = 'w', edgecolor = 'k')\n    for i in range(min(nCol, nGraphShown)):\n        plt.subplot(nGraphRow, nGraphPerRow, i + 1)\n        columnDf = df.iloc[:, i]\n        if (not np.issubdtype(type(columnDf.iloc[0]), np.number)):\n            valueCounts = columnDf.value_counts()\n            valueCounts.plot.bar()\n        else:\n            columnDf.hist()\n        plt.ylabel('counts')\n        plt.xticks(rotation = 90)\n        plt.title(f'{columnNames[i]} (column {i})')\n    plt.tight_layout(pad = 1.0, w_pad = 1.0, h_pad = 1.0)\n    plt.show()\n","2d5858db":"df1 = pd.read_csv('..\/input\/ssd-reviews\/ssd_reviews.csv')\nnRow, nCol = df1.shape\nprint(f'There are {nRow} rows and {nCol} columns')\n# df1.drop(columns='Unnamed: 0', axis=1, inplace=True)","9d53182c":"df1.head()","ecd71aee":"df1.info()","35900a88":"df1['date'] = pd.to_datetime(df1['date']) # we can change date column from object to datetime\ndf1.drop(columns='Unnamed: 0', axis=1, inplace=True) # And we can drop this column generated by kaggle","f9859077":"plotPerColumnDistribution(df1, 10, 5)","c2081dd0":"df1['ownership_pariod'].value_counts()   #Look at data_description.txt file for more information","ba9cfdf4":"df1['rating_stars'].value_counts()   #Look at data_description.txt file for more information","3ba7d2d2":"df1['year'].value_counts()   #Look at data_description.txt file for more information","d11bb39f":"df1['month'].value_counts()   #Look at data_description.txt file for more information","196e2777":"df1['day'].value_counts()   #Look at data_description.txt file for more information","3050f9f9":"# Suggestions :","ae678192":"#### Enjoy modeling ..","726b2aed":"<b> Suggestions for modeling: <br>\ncreate two additional columns, the first one contains both (pros and cons) in the same column, and the second column contains (0 and 1), So if the value in the new column (pros and cons) is pros then put 1, And if the value is cons then put 0 <\/b>","06ef71bf":"Let's take a quick look at what the data looks like:","53cb919f":"## A starter code\nTo begin exploratory analysis, first import libraries and define functions for plotting the data","21ddb091":"Distribution graphs (histogram\/bar graph) of sampled columns:","f1de5ead":"### Load ssd_reviews.csv file","dee03c7b":"<b> Since we have pros and cons data, we don't need to add more products to the dataset, Because when we want to do a Sentiment analysis, the pros and cons will be in the same column, So the Sentiment analysis training will consider cons as negative and pros as positive, And from that our model will be balanced.<\/b>","e00e6313":"## Exploratory analysis"}}