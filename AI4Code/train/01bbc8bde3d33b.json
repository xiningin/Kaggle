{"cell_type":{"32ea90d1":"code","1211f422":"code","b10c4203":"code","f48adeb0":"code","40647eb3":"code","8f79e177":"code","9e63dd75":"code","da8024fe":"code","2233d9da":"code","fdc90cb2":"code","68d84b66":"code","2b7f3f54":"code","628cd3c8":"code","a929bba8":"code","16189fb3":"code","d63ed246":"code","c11a6de6":"code","09059e68":"code","af7adc41":"code","41c5883e":"code","55bc9d05":"code","1fc2b5af":"code","f725acc8":"code","349eb17b":"code","bd1a4ed2":"code","2a50b895":"code","ad171c06":"code","3bbade24":"code","2273cbf1":"code","76ae358c":"code","654112ff":"code","0ab65256":"code","a4301646":"code","654fed96":"code","61ef9e56":"code","b13c783f":"code","ecbb2553":"code","6547a331":"code","7ddd48d8":"code","c0cb73fe":"code","6d002ebb":"code","3ab71407":"code","08077533":"code","5930dcf3":"code","a71a3dd2":"code","a75d8743":"code","3176c9ae":"markdown","b531d4fe":"markdown","0ed27f5a":"markdown","60f43593":"markdown","71b585d2":"markdown","cfc187a1":"markdown","6e027a08":"markdown","69a4ce25":"markdown","e49b3384":"markdown","ec882d3a":"markdown","8e077059":"markdown","a91e5bf0":"markdown","17e086a4":"markdown","9c43c112":"markdown","b42c3676":"markdown","b66920a6":"markdown","443da9b9":"markdown","6101ab9d":"markdown","73d8cfcb":"markdown","2dc146d2":"markdown","4f7c78f2":"markdown","c088c9ea":"markdown","d446b82a":"markdown","a71826e0":"markdown","b99e8c71":"markdown","19cb4787":"markdown","f8776092":"markdown","00d28a5f":"markdown","d21e78a7":"markdown","770c0773":"markdown","d92c56d6":"markdown","7fdff2c7":"markdown","b7573dbb":"markdown","3a38db09":"markdown","b18ffbf5":"markdown","993d4203":"markdown","a81900fa":"markdown","55205f75":"markdown","5d14e833":"markdown","e8bc5627":"markdown","87dadf9e":"markdown","2f2a487d":"markdown","e7e4a6ad":"markdown"},"source":{"32ea90d1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1211f422":"#loading required libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n#pd.set_option('display.max_columns', None)\n#%matplotlib inline\n#sns.set_context('notebook')\n#sns.set_style('whitegrid')\n#sns.set_palette('Blues_r')\n\n#turning off warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#importing dataset\ndf=pd.read_csv(\"..\/input\/marketing-data\/marketing_data.csv\")\nprint(df.info())\ndf.head()","b10c4203":"# clean up column names that contain whitespace\ndf.columns = df.columns.str.replace(' ', '')\n\n# transform Income column to a numerical\ndf['Income'] = df['Income'].str.replace('$', '')\ndf['Income'] = df['Income'].str.replace(',', '').astype('float')","f48adeb0":"df.head()","40647eb3":"df.isnull().sum().sort_values(ascending=False)","8f79e177":"#Plotting 'Income' to get an idea of distribution \nsns.histplot(df['Income'],kde=False);","9e63dd75":"sns.boxplot(df['Income']);","da8024fe":"df['Income']=df['Income'].fillna(df['Income'].median())","2233d9da":"df_to_plot=df.drop(columns=['ID','AcceptedCmp1', 'AcceptedCmp2', \n                            'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', \n                            'Response', 'Complain']).select_dtypes(include=np.number)","fdc90cb2":"df_to_plot.plot(subplots=True, layout=(4,4), kind='box', figsize=(12,14), patch_artist=True);\nplt.subplots_adjust(wspace=0.5);","68d84b66":"df=df[df['Year_Birth']>1900].reset_index(drop=True)\nplt.figure(figsize=(3,4))\ndf['Year_Birth'].plot(kind='box', patch_artist=True);","2b7f3f54":"df.info()","628cd3c8":"df['Dt_Customer']=pd.to_datetime(df['Dt_Customer'])","a929bba8":"list(df.columns)","16189fb3":"#performing feature engineering\ndf['Dependents']=df['Kidhome']+df['Teenhome']\n\n#year becoming a customer\ndf['Year_Customer']=pd.DatetimeIndex(df['Dt_Customer']).year\n\n#total amount spend\nmnt_cols= [col for col in df.columns if 'Mnt' in col]\ndf['TotalMnt']=df[mnt_cols].sum(axis=1)\n\n#total purchases\npurchases_cols=[col for col in df.columns if 'Purchase' in col]\ndf['TotalPurchases']=df[purchases_cols].sum(axis=1)\n\n#total campaigns accepted\ncampaigns_cols=[col for col in df.columns if 'Cmp' in col]+['Response']\ndf['TotalCampaignsAcc']=df[campaigns_cols].sum(axis=1)\n\n#view new features, by customer ID\ndf[['ID','Dependents', 'Year_Customer', 'TotalMnt', 'TotalPurchases', 'TotalCampaignsAcc']].head()","d63ed246":"#calculate correlation matrix\ncorrs=df.drop(columns='ID').select_dtypes(include=np.number).corr(method='kendall')\n\nsns.clustermap(corrs, cmap=\"YlGnBu\");","c11a6de6":"sns.lmplot(x='Income', y='TotalMnt', data=df[df['Income']<200000]);\nplt.xticks(rotation=45, horizontalalignment='right');","09059e68":"plt.figure(figsize=(4,4))\nsns.boxplot(x='Dependents', y='TotalMnt', data=df);","af7adc41":"plt.figure(figsize=(4,4))\nsns.boxplot(x='Dependents', y='NumDealsPurchases', data=df);","41c5883e":"plt.figure(figsize=(5.5,4));\nsns.boxplot(x='TotalCampaignsAcc', y='Income', data=df[df['Income']<200000]);","55bc9d05":"plt.figure(figsize=(5.5,4))\nsns.boxplot(x='TotalCampaignsAcc', y='Dependents', data=df);","1fc2b5af":"sns.lmplot(x='NumWebVisitsMonth', y='NumWebPurchases', data=df);","f725acc8":"sns.lmplot(x='NumWebVisitsMonth', y='NumDealsPurchases', data=df);","349eb17b":"sns.countplot(df['NumStorePurchases']);","bd1a4ed2":"#drop unique ID\ndf.drop(columns=['ID', 'Dt_Customer'], inplace=True)","2a50b895":"#one hot encoding for categorical features\nfrom sklearn.preprocessing import OneHotEncoder\n\ncat=df.select_dtypes(exclude=np.number)\nprint(\"Number of unique values per categorical features:\\n\", cat.nunique())\n\n#use one hot encoder\nenc=OneHotEncoder(sparse=False).fit(cat)\ncat_encoded=pd.DataFrame(enc.transform(cat))\ncat_encoded.columns=enc.get_feature_names(cat.columns)\n\n#merge with numeric data\nnum=df.drop(columns=cat.columns)\ndf2=pd.concat([cat_encoded,num],axis=1)\ndf2.head()","ad171c06":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\n\nX=df2.drop(columns='NumStorePurchases')\ny=df2['NumStorePurchases']\n\nX_train,X_test, y_train,y_test=train_test_split(X,y, test_size=0.3, random_state=1)\n\nmodel=LinearRegression()\nmodel.fit(X_train,y_train)\n\npreds=model.predict(X_test)\nprint(\"Linear Regression Model RMSE:\", np.sqrt(mean_squared_error(y_test,preds)))\nprint(\"Median value of target variable:\", y.median())","3bbade24":"import eli5\nfrom eli5.sklearn import PermutationImportance\n\nperm=PermutationImportance(model, random_state=1).fit(X_test,y_test)\neli5.show_weights(perm,feature_names=X_test.columns.tolist(),top=5)","2273cbf1":"import shap\n\n#calculate shap values\nex=shap.Explainer(model, X_train)\nshap_values=ex(X_test)\n\n#plot\nplt.title('SHAP summary for NumStorePurchases',size=16)\nshap.plots.beeswarm(shap_values,max_display=4);","76ae358c":"df.groupby('Country')['TotalPurchases'].sum().sort_values(ascending=False).plot(kind='bar')\nplt.title('Total Number of Purchases by Country', size=16)\nplt.ylabel('Number of purchases');","654112ff":"plt.figure(figsize=(5,4))\ndf.groupby('Country')['TotalMnt'].sum().sort_values(ascending=False).plot(kind='bar')\nplt.title('Total Amount Spent by Country', size=16)\nplt.ylabel('Amount Spent');","0ab65256":"sns.lmplot(x='MntGoldProds', y='NumStorePurchases', data=df);","a4301646":"from scipy.stats import kendalltau\n\nkendall_corr = kendalltau(x=df['MntGoldProds'], y=df['NumStorePurchases'])\n\n# print results\nprint('Kendall correlation (tau): ', kendall_corr.correlation)\nprint('Kendall p-value: ', kendall_corr.pvalue)","654fed96":"#sum the marital status and phd dummy variables-the Married+PhD will have value of 2\ndf2['Married_PhD']=df2['Marital_Status_Married']+df2['Education_PhD']\ndf2['Married_PhD']=df2['Married_PhD'].replace({2:'Married-PhD', 1:'Other', 0:'Other'})\n\nplt.figure(figsize=(2.5,4))\nsns.boxplot(x='Married_PhD', y='MntFishProducts', data=df2);","61ef9e56":"# independent t-test p-value\nfrom scipy.stats import ttest_ind\npval = ttest_ind(df2[df2['Married_PhD'] == 'Married-PhD']['MntFishProducts'], df2[df2['Married_PhD'] == 'Other']['MntFishProducts']).pvalue\nprint(\"t-test p-value: \", round(pval, 3))","b13c783f":"# now drop the married-phD column created above, to include only the original variables in the analysis below\ndf2.drop(columns='Married_PhD', inplace=True)","ecbb2553":"plt.figure(figsize=(8,4))\nsns.distplot(df['MntFishProducts'], kde=False, hist=True, bins=12);\nplt.title('MntFishProducts distribution', size=16)\nplt.ylabel('count');","6547a331":"X=df2.drop(columns='MntFishProducts')\ny=df2['MntFishProducts']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)\n\nmodel=LinearRegression()\nmodel.fit(X_train,y_train)\npreds=model.predict(X_test)\n\n# evaluate model using RMSE\nprint(\"Linear regression model RMSE: \", np.sqrt(mean_squared_error(y_test, preds)))\nprint(\"Median value of target variable: \", y.median())","7ddd48d8":"perm = PermutationImportance(model, random_state=1).fit(X_test, y_test)\neli5.show_weights(perm, feature_names = X_test.columns.tolist(), top=7)","c0cb73fe":"import shap\n\n# calculate shap values \nex = shap.Explainer(model, X_train)\nshap_values = ex(X_test)\n\n# plot\nplt.title('SHAP summary for MntFishProducts', size=16)\nshap.plots.beeswarm(shap_values, max_display=7);","6d002ebb":"# convert country codes to correct nomenclature for choropleth plot\n# the dataset doesn't provide information about country codes\n## ...so I'm taking my best guess about the largest nations that make sense given the codes provided\ndf['Country_code'] = df['Country'].replace({'SP': 'ESP', 'CA': 'CAN', 'US': 'USA', 'SA': 'ZAF', 'ME': 'MEX'})\n\n# success of campaigns by country code\ndf_cam = df[['Country_code', 'AcceptedCmp1', 'AcceptedCmp2', 'AcceptedCmp3', 'AcceptedCmp4', 'AcceptedCmp5', 'Response']].melt(\n    id_vars='Country_code', var_name='Campaign', value_name='Accepted (%)')\ndf_cam = pd.DataFrame(df_cam.groupby(['Country_code', 'Campaign'])['Accepted (%)'].mean()*100).reset_index(drop=False)\n\n# rename the campaign variables so they're easier to interpret\ndf_cam['Campaign'] = df_cam['Campaign'].replace({'AcceptedCmp1': '1',\n                                                'AcceptedCmp2': '2',\n                                                'AcceptedCmp3': '3',\n                                                'AcceptedCmp4': '4',\n                                                'AcceptedCmp5': '5',\n                                                 'Response': 'Most recent'\n                                                })\n\n# choropleth plot\nimport plotly.express as px\n\nfig = px.choropleth(df_cam, locationmode='ISO-3', color='Accepted (%)', facet_col='Campaign', facet_col_wrap=2,\n                    facet_row_spacing=0.05, facet_col_spacing=0.01, width=700,\n                    locations='Country_code', projection='natural earth', title='Advertising Campaign Success Rate by Country'\n                   )\nfig.show()","3ab71407":"cam_success=pd.DataFrame(df[['AcceptedCmp1','AcceptedCmp2','AcceptedCmp3','AcceptedCmp4','AcceptedCmp5','Response']].mean()*100, columns=['Percent']).reset_index()\n\n#plot\nsns.barplot(x=\"Percent\", y='index', data=cam_success.sort_values('Percent'),palette='Blues');\nplt.xlabel('Accepted(%)');\nplt.ylabel('Campaign');\nplt.title('Marketing campaign success rate',size=16);","08077533":"#lists of cols with binary responses\nbinary_cols=[col for col in df.columns if 'Accepted' in col] + ['Response', 'Complain']\n\n#lists of cols for spending\nmnt_cols=[col for col in df.columns if 'Mnt' in col]\n\n#lists of cols for channels\nchannel_cols=[col for col in df.columns if 'Num' in col] + ['TotalPurchases', 'TotalCampaignsAcc']","5930dcf3":"#average customer demographics\ndemographics=pd.DataFrame(round(df.drop(columns=binary_cols+mnt_cols+channel_cols).mean(),1),columns=['Average']).reindex(['Year_Birth','Year_Customer','Income','Dependents','Kidhome','Teenhome', 'Recency'])\n\ndemographics","a71a3dd2":"spending=pd.DataFrame(round(df[mnt_cols].mean(),1), columns=['Average']).sort_values(by='Average').reset_index()\n\n#plot\nax=sns.barplot(x='Average', y='index',data=spending, palette='Blues')\nplt.ylabel('Amount spent on...')\n\n#add text labels for each bar's value\nfor p,q in zip(ax.patches, spending['Average']):\n    ax.text(x=q+40,\n           y=p.get_y()+0.5,\n           s=q,\n           ha='center');","a75d8743":"channels = pd.DataFrame(round(df[channel_cols].mean(), 1), columns=['Average']).sort_values(by='Average').reset_index()\n\n# plot\nax = sns.barplot(x='Average', y='index', data=channels, palette='Blues')\nplt.ylabel('Number of...')\n\n## add text labels for each bar's value\nfor p,q in zip(ax.patches, channels['Average']):\n    ax.text(x=q+0.8,\n            y=p.get_y()+0.5,\n            s=q,\n            ha=\"center\") ;","3176c9ae":"#### The cleaned dataset:","b531d4fe":"#### Is there a significant relationship between geographical regional and success of a campaign?\n* Plot success of campaigns by region:\n* Findings:\n    * The campaign acceptance rates are low overall\n    * The campaign with the highest overall acceptance rate is the most recent campaign (column name: Response)\n    * The country with the highest acceptance rate in any campaign is Mexico\n   ","0ed27f5a":"### Does US fare significantly better than the Rest of the World in terms of total purchase?\n* Plot total number of purchases by country:\n   ","60f43593":"#### Outliers\nIdentifying features that contain outliers","71b585d2":"#### Findings about outliers:\nMultiple features contain outliers as show in the boxplots above but the only one that suggest wrong data-entry is Year_Birth<=1900.\n\nRemoving rows where Year_Birth<=1900.","cfc187a1":"* Findings: \n    * The most successful campaign is the most recent ('Response')","6e027a08":"#### Which marketing campaign is most successful?\n* Plot marketing campaign overall acceptance rates:\n    ","69a4ce25":"* Fit linear regression to training data\n* Evaluate predictions on the test data using RMSE\n    * The RMSE is excedingly small comapared to the median value of the target variable, indicating good model predictions","e49b3384":"#### Fish has Omega 3 fatty acids which are good for the brain. Accordingly, do \"Married PhD candidates\" have a significant relation with amount spent on fish?\n* To check this claim we will compare amount spent on Fish Products (MntFishProducts) between MarriedPhD candidates and all other customer:\n    * Findings: Married PhD candidates spend significantly less on fish products comapared to other customers.","ec882d3a":"* Fit linear regression model on training data (70% of dataset)\n* Evaluate predictions on test data (30% of dataset) using RMSE","8e077059":"#### Findings about the income:\n* Income contains 24 null values\n* It is distributed between `$ 0- $ 100,000` and has some outliers\n\n* Fill null values with the median value to avoid the effect of outliers","a91e5bf0":"#### Are there any Null values or outliers?","17e086a4":"## Conclusion\n#### Recall the overall goal:\nYou're a marketing analyst and you've been told by the Chief Marketing Officer that recent marketing campaigns have not been as effective as they were expected to be. You need to analyze the data set to understand this problem and propose data-driven solutions...\n\n#### Summary of actionable findings to improve advertising campaign success:\n* The most successful advertising campaign was the most recent campaign (column name: Response), and was particularly successful in Mexico (>60% acceptance rate!)\n    * Suggested action: Conduct future advertising campaigns using the same model recently implemented in Mexico.\n* Advertising campaign acceptance is positively correlated with income and negatively correlated with having kids\/teens\n    * Suggested action: Create two streams of targeted advertising campaigns, one aimed at high-income individuals without kids\/teens and another aimed at lower-income individuals with kids\/teens\n* The most successful products are wines and meats (i.e. the average customer spent the most on these items)\n    * Suggested action: Focus advertising campaigns on boosting sales of the less popular items\n* The underperforming channels are deals and catalog purchases (i.e. the average customer made the fewest purchases via these channels)\n* The best performing channels are web and store purchases (i.e. the average customer made the most purchases via these channels)\n    * Suggested action: Focus advertising campaigns on the more successful channels, to reach more customers","9c43c112":"* Identify features that significantly affect the amount spent on fish, using permutation importance:\n    * Significant features:\n        * 'TotalMnt', 'MntWines', 'MntMeatProducts', 'MntGoldProds', 'MntSweetProducts', 'MntFruits'\n    * All other features are not significant","b42c3676":"#### Plots illustrating the positive effect of income and negative effect of having kids & teens on advertising campaign acceptance:\nNOTE: For the purpose of this graph limiting income to < 200,000 to remove outliers","b66920a6":"* Explore the directionality of these effects, using SHAP values:\n    * Findings:\n        * The amount spent on fish increases with higher total amount spent ('TotalMnt')\n        * The amount spent on fish decreases with higher amounts spent on wine, meat, gold, fruit, or sweets ('MntWines', 'MntMeatProducts', 'MntGoldProds', 'MntSweetProducts', 'MntFruits')\n    * Interpretation:\n        * Customers who spend the most on fish are those who spend less on other products (wine, meat, gold, fruit, and sweets)","443da9b9":"#### Plot illustrating negative effect of having dependents (kids & teens) on spending:","6101ab9d":"#### Plot illustrating positive effect of having dependents (kids & teens) on number of deals purchased:","73d8cfcb":"#### Investing Anomaly:\n* Number of web visits is not positively correlated with the number of web purchases.\n* Instead, it is positively correlated with the number of deals purchased.","2dc146d2":"* Findings :\n    * Spain (SP) has the highest number of purchases\n    * US is second to last, therefore the US does not fare better than the Rest of the World in terms of total number of purchases","4f7c78f2":"The variable Dt_Customer represents Date of customer's enrollment with the company so this should be in DateTime format.","c088c9ea":"### Are there any useful variables that we can engineer with the given data?\n* The total number of dependents ('Dependents') can be engineered with the sum of 'Kidhome' and 'Teenhome'\n* Variable 'Year_Customer' which is year of becoming a customer can be engineered from 'Dt_Customer'\n* The total amount spent ('TotalMnt') can be engineered from the sum of all features containing the keyword 'Mnt'\n* Similarly the total purchases ('TotalPurchases') can be engineered from the sum of all features containing the keyword 'Purchases'\n* The total number of campains accepted ('TotalCampaignsAcc') can be engineered from the sum of all features containing the keywords 'Cmp' and 'Response' (the latest campaign)","d446b82a":"* Findings:\n    * The number of store purchases increases with higher number of total purchases\n    * The number of store purchases decreases with higher number of catalog, web or deals purchases\n* Interpretation:\n    * Customers who shop the most in the stores are those who shop less via the catalog, website or special deals","a71826e0":"* Explore the directionality of these effects, using SHAP values:\n","b99e8c71":"### Is there any pattern or anomalies in the data? Can we plot them?\n* To identify paterns, we will first identify feature correlation. We will use the clustermap below for that; where dark blue means positive correlation and white represents negative correlation.\n* From this heatmap we can observe the following clusters of correlated features:\n    * \"**High Income**\" cluster:\n        ** Amount spent ('TotalMnt' and other 'Mnt' features) and number of purchases ('TotalPurchases' and other 'Num...Purchases' features) are positively related with 'Income'.\n        ** Purchasing in store, on the web, or via the catalog ('NumStorePurchases','NumWebPurchases','NumCatalogPurchases') is positively correlated with 'Income'\n   * \"**Dependents**\"cluster:\n       ** Amount spent and number of purchases are negatively correlated with 'Dependents'.\n       ** Purchasing deals ('NumDealsPurchases') is positively correlated with 'Dependents' and negatively correlated with 'Income' \n   * \"**Advertising Campaigns**\" cluster:\n       ** Acceptence of advertising campaigns ('AcceptedCmp' and 'Response') are strongly positively correlated with each other.\n       ** Weak positive correlation of the advertising campaigns is seen with the \"High Income\" cluster, and weak negative correlation is seen with the \"Have Kids & Teens\" cluster\n* Anomalies:\n    * The number of website visits in the last month ('NumWebVisitsMonth') does not correlate with an increased number of web purchases ('NumWebPurchases')\n    * Instead, 'NumWebVisitsMonth' is positively correlated with the number of deals purchased ('NumDealsPurchases'), suggeting that deals are effective way of stiimulating purchase on the website","19cb4787":"* Drop uninformative features:\n    * ID in unique to each customer\n    * Dt_Customer will be dropped in favour of using engineered variable Year_Customer\n* Perform one-hot encoding of categorical features.","f8776092":"Loading the dataset","00d28a5f":"#### Cleaning the dataset and transforming Income to float","d21e78a7":"# Marketing Analytics Exploratory\/ Statistical Analysis\u00a0Task\n\n## Introduction\nAs a marketing analyst and you've been told by the Chief Marketing Officer that recent marketing campaigns have not been as effective as they were expected to be. You need to analyse the data set to understand this problem and propose data-driven solution.\n\n## Section 01: Exploratory Data Analysis\n1. Are there any null values or outliers?\n2. Are there any variables that warrant transformations?\n3. Are there any useful variables that we can engineer with the given data?\n4. Any patterns or anomalies in the data?\n\n## Section 02: Statistical Analysis\nRun statistical tests in the form of regression to answer the questions and propose a data-driven action to the CMO. Interpret the result with non-statistical jargon so that CMO can understand the findings.\n1. What factors are significantly related to the number of store purchases?\n2. Does US fare significantly better than the rest of the world in terms of total purchases?\n3. The supervisor insists that people who buy gold are more conservative. Therefore, people who spent an above average amount on gold in the   last 2 years would have more in store purchases. Justify or refute this statement using an appropriate statistical test.\n4. Fish has Omega 3 fatty acids which are good for the brain. Accordingly do \"Married PhD candidates\" have a significant relation with the amount spend on fish products? What factors are significantly related to amount spend on fish?\n5. Is there a significant relationship between geographical regional and success of a campaign?\n\n## Section 03: Data Visualisation\n1. Which marketing campaign is most successful?\n2. What does the average customer look like for this company?\n3. Which products are performing best?\n4. Which channels are underperforming?","770c0773":"#### Plot illustrating the effect of income on spending\n Note: For the purpose of this plot limiting income to < 200,000 to remove outliers","d92c56d6":"#### Next Task: The supervisor insists that people who buy gold are more conservative. Therefore, people who spent an above average amount on gold in the last 2 years would have more in store purchases. Justify or refute this statement using an appropriate statistical test\n* Plot relationship between amount spent on gold in the last 2 years (MntGoldProds) and number of in store purchases (NumStorePurchases):\n    ","7fdff2c7":"* Findings: There is a positive relationship, but is it statistically significant? \n* Perform Kendall Correlation Analysis (non parametric test since MntGoldProducts is not normally distributed and contains outliers):\n    * Findings: There is a significant positive correlation between the two variables.","b7573dbb":"### What other factors are significantly related to the amount spent on fish?\n* Like the analysis of NumStorePurchases above, we will use Linear Regression model with MntFishProducts as the target variable, and then use machine learning explainability techniques to get insights about which features predict the amount spent on fish.\n* Begin by plotting the target variable:\n","3a38db09":"The RMSE is exceedingly small compared to the median of the target variable, indicating good model predictions","b18ffbf5":"* Interpreting the results using Permutation importance:\n    * Significant feature are:\n        * 'TotalPurchases', 'NumCatalogPurchases', 'NumWebPurchases', 'NumDealsPurchases'\n        * All other features are not significant","993d4203":"### Are there any variables that need transformation?","a81900fa":"### Which products are performing best?\n* The average customer spent...\n    * ` $` 25-50 on Fruits, Sweets, Fish, or Gold products\n    * Over `$` 160 on Meat products\n    * Over `$` 300 on Wines\n    * Over `$` 600 total\n    * Products performing best:\n    * Wines\n    * Followed by meats","55205f75":"* Plot total **amount spent** by country:\n    * Findings:\n        * Spain (SP) has the highest total amount spent on purchases\n        * US is second to last, thus the US does not fare better than the rest of the world in terms of the total amount spent on purchases","5d14e833":"### Which channels are underperforming?\n* Channels: The avereage customer...\n    * Accepted less than 1 advertising campaign\n    * Made 2 deals purchases, 2 catalog purchases, 4 web purchases, and 5 store purchases\n    * Averaged 14 total purchases\n    * Visited the website 5 times\n* Underperforming channels:\n    * Advertising campaigns\n    * Followed by deals, and catalog","e8bc5627":"## Section 02: Statistical Analysis\nRun statistical tests in the form of regression to answer the questions and propose a data-driven action to the CMO. Interpret the result with non-statistical jargon so that CMO can understand the findings.\n\n### What factors are significantly related to the number of store purchases?\n* We will use a Linear Regression model with NumStorePurchases as the target variables, and then use machine learning explainability techniques to get insights about which features predict the number of store purchases\n* Begin by plotting the target variable:","87dadf9e":"## SECTION 3: Data Visualisation\n","2f2a487d":"### What does the average customer look like for the company?\n* Basic demographics:\n    * Born in 1969\n    * Became a customer in 2013\n    * Has an income of around` $ 52,000 per year `\n    * Has 1 dependent (roughly split between kids or teens)\n    * Made a purchase from our company in the last 49 days","e7e4a6ad":"## **SECTION 1: EXPLORATORY DATA ANALYSIS**"}}