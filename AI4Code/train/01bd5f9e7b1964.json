{"cell_type":{"1dbd1e97":"code","65ecde87":"code","2a071c08":"code","2d7c7b30":"code","77425ebf":"code","d2502782":"code","5f3aaabe":"code","7e7bfed0":"code","55a1c36a":"code","a6b37c8d":"code","8f9626d8":"code","84daaf32":"code","928bca5a":"code","e32d86ad":"code","a42f7b3f":"code","6f03e3f3":"code","b71fa120":"code","869c06f7":"code","29a1fc36":"code","19fe1c79":"code","c6be3efc":"code","43604212":"code","245d7f53":"code","3a63a9f1":"code","dc18b28b":"code","ed813df0":"code","145e448f":"code","c9f84583":"code","4dd7a8e2":"code","0e1be074":"code","c7383cf4":"code","0c17525b":"code","8ff639b6":"code","349d69fb":"code","0313082e":"code","5858a87b":"code","2bbbd89f":"code","f2416f59":"code","c1356829":"code","415b833e":"code","b69e80a7":"markdown","95052512":"markdown","19c738c5":"markdown","51646f19":"markdown","6ceb8864":"markdown","19299784":"markdown","619a4b4a":"markdown","dcb799fc":"markdown","0bb4776b":"markdown","a3029d26":"markdown","d9ab2be6":"markdown","a8780adf":"markdown"},"source":{"1dbd1e97":"import os\nimport numpy as np\nimport pandas as pd\nimport glob\nimport matplotlib.pyplot as plt\nimport random\nimport skimage\n\nprint(os.listdir(\"..\/input\"))\nprint(os.listdir(\"..\/input\/chinese-mnist\/\"))","65ecde87":"dataframe = pd.read_csv(\"..\/input\/chinese-mnist\/chinese_mnist.csv\", low_memory = False)\ndataframe.head()","2a071c08":"dataframe.sample(10)","2d7c7b30":"print(\"sample_id:\", dataframe.sample_id.unique())\nprint(\"code:\", dataframe.code.unique())\nprint(\"character:\", dataframe.character.unique()) \nprint(\"suite_id:\", dataframe.suite_id.unique())","77425ebf":"dataframe.isnull().sum()","d2502782":"# how many image files have we got\nprint(\"No. of rows in dataframe:\", dataframe.shape[0]) \nprint(\"No. of Image files we have:\", len(os.listdir(\"..\/input\/chinese-mnist\/data\/data\/\")))\nprint(\"Example file:\", random.choice(os.listdir(\"..\/input\/chinese-mnist\/data\/data\/\")))\nprint(\"The files are named by the order of: input_(suite_id)_(sample_id)_(code).jpg\")","5f3aaabe":"# Matchin image names\ndef file_path_col(df):\n    \n    file_path = f\"input_{df[0]}_{df[1]}_{df[2]}.jpg\" \n    #This will return a column that has the image_file name as the data file, i.e. input_1_1_10.jpg\n    \n    return file_path","7e7bfed0":"# Create file_path column\ndataframe[\"file_path\"] = dataframe.apply(file_path_col, axis = 1)\ndataframe.head()","55a1c36a":"image_files = os.listdir(\"..\/input\/chinese-mnist\/data\/data\/\")","a6b37c8d":"# Check matching files\nfile_paths = list(dataframe.file_path)\nprint(\"Number of matches: {}\".format(len(set(file_paths).intersection(image_files))))\n# Intersection offers the number of similarities between two items. Can be used on dataframe columns\/lists.","8f9626d8":"import skimage.io\nimport skimage.transform\n\n\n# Obtaining the image sizes\ndef read_image_size(file_name):\n    image = skimage.io.imread(\"..\/input\/chinese-mnist\/data\/data\/\" + file_name)\n    return list(image.shape)","84daaf32":"m = np.stack(dataframe.file_path.apply(read_image_size))\ntemp_df = pd.DataFrame(m, columns = [\"width\", \"height\"])\ntemp_df.head(2)","928bca5a":"print(temp_df.shape[0])\ndataframe = pd.concat([dataframe, temp_df], axis = 1, sort = False)\ndataframe.head(5)","e32d86ad":"from sklearn.model_selection import train_test_split\n# 1. Train and Test set\ntrain_df, test_df = train_test_split(dataframe, \n                                     test_size = 0.2,\n                                     random_state = 42,\n                                     shuffle = True,\n                                     stratify = dataframe.code.values)","a42f7b3f":"# 2. Train and Val\ntrain_df, val_df = train_test_split(train_df, \n                                    test_size = 0.2,\n                                    random_state = 42,\n                                    shuffle = True,\n                                    stratify = train_df.code.values)","6f03e3f3":"print(\"Training set observations:\", train_df.shape[0],\n     \"\\nValidation set observations:\", val_df.shape[0],\n     \"\\nTesting set observations:\", test_df.shape[0])","b71fa120":"def read_image(file_paths):\n    image = skimage.io.imread(\"..\/input\/chinese-mnist\/data\/data\/\" + file_paths)\n    image = skimage.transform.resize(image, (64, 64, 1),\n                                     mode = \"reflect\") # THe mode parameter determines how the array borders are handled.\n    \n    return image[:, :, :]\n\n\n#For what exactly does mode do, refer to:\n#https:\/\/github.com\/scikit-image\/scikit-image\/issues\/3294","869c06f7":"image = skimage.io.imread(\"..\/input\/chinese-mnist\/data\/data\/\" + dataframe.file_path[10])\nprint(image.shape)\nimage = skimage.transform.resize(image, (64, 64, 1), mode = \"reflect\")\nprint(image.shape)","29a1fc36":"train_df.head()","19fe1c79":"# One hot encoder, but in 15 classes\ndef character_encoder(df, var = \"character\"):\n    X = np.stack(df[\"file_path\"].apply(read_image))\n    y = pd.get_dummies(df[var], drop_first = False) #drop_first default is already at False fyi\n    # For what pd.get_dummies does, refer: https:\/\/stackoverflow.com\/questions\/36285155\/pandas-get-dummies\n    return X, y","c6be3efc":"X_train, y_train = character_encoder(train_df)\nX_val, y_val = character_encoder(val_df)\nX_test, y_test = character_encoder(test_df)\n\nprint(X_train.shape, \",\", y_train.shape)\nprint(X_val.shape, \",\", y_val.shape)\nprint(X_test.shape, \",\", y_test.shape)","43604212":"from keras.preprocessing.image import ImageDataGenerator,load_img, img_to_array\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Dense, Dropout, Input, Flatten, SeparableConv2D\nfrom keras.layers import GlobalMaxPooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.merge import Concatenate\nfrom keras.models import Model\nfrom keras.optimizers import Adam, SGD, RMSprop\nfrom keras.callbacks import ModelCheckpoint, Callback, EarlyStopping, LearningRateScheduler\nfrom keras.utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom mlxtend.plotting import plot_confusion_matrix\nfrom sklearn.metrics import confusion_matrix\nimport cv2\nfrom keras import backend as K\nimport imgaug as aug\n#color = sns.color_palette()\n%matplotlib inline","245d7f53":"import tensorflow.compat.v1 as tf\ntf.disable_v2_behavior()\n\n# Set the seed for hash based operations in python\nos.environ['PYTHONHASHSEED'] = '0'\n\n# Set the numpy seed\nnp.random.seed(111)\n\n# Disable multi-threading in tensorflow ops\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\n\n# Set the random seed in tensorflow at graph level\ntf.set_random_seed(111)\n\n# Define a tensorflow session with above session configs\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\n\n# Set the session in keras\ntf.keras.backend.set_session(sess)\n\n# Make the augmentation sequence deterministic\naug.seed(111)","3a63a9f1":"def build_model():\n    input_img = Input(shape = (64, 64, 1), name = \"ImageInput\")\n    x = Conv2D(16,kernel_size = (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv1_1\")(input_img)\n    x = Conv2D(16,kernel_size = (3, 3) , activation = \"relu\", padding = \"same\", name = \"Conv1_2\")(x)\n    x = MaxPooling2D((2, 2), name = \"pool1\")(x)\n    \n    x = Conv2D(32, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv2_1\")(x)\n    x = Conv2D(32, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv2_2\")(x)\n    x = MaxPooling2D((2, 2), name = \"pool2\")(x)\n    \n    x = Conv2D(64, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv3_1\")(x)\n    x = BatchNormalization(name = \"bn1\")(x)\n    x = SeparableConv2D(64, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv3_2\")(x)\n    x = BatchNormalization(name = \"bn2\")(x)\n    x = MaxPooling2D((2, 2), name = \"pool3\")(x)\n    \n    x = SeparableConv2D(128, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv4_1\")(x)\n    x = BatchNormalization(name = \"bn3\")(x)\n    x = SeparableConv2D(128, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv4_2\")(x)\n    x = BatchNormalization(name = \"bn4\")(x)\n    x = MaxPooling2D((2, 2), name = \"pool4\")(x)\n    \n    x = Flatten(name = \"flatten\")(x)\n    x = Dense(1024, activation = \"relu\", name = \"fc1\")(x)\n    x = Dropout(0.7, name = \"dp1\")(x)\n    x = Dense(512, activation = \"relu\", name = \"fc2\")(x) \n    x = Dropout(0.5, name = \"dp2\")(x)\n    x = Dense(15, activation = \"softmax\", name = \"fc3\")(x)\n    \n    model = Model(inputs = input_img, outputs = x)\n    return model","dc18b28b":"model = build_model()\nmodel.summary()","ed813df0":"BATCH_SIZE = 32\nNO_EPOCHS = 50\nDROPOUT_RATIO = 0.5\nPATIENCE = 5\nVERBOSE = 1","145e448f":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.99 ** (x + NO_EPOCHS))\nes = EarlyStopping(monitor = \"loss\", patience = PATIENCE, verbose = VERBOSE)\ncp = ModelCheckpoint(\"best_model.h5\", monitor = \"val_accuracy\", verbose = VERBOSE,\n                     save_best_only = True, save_weights_only = True)\nmodel.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=\"adam\")","c9f84583":"history = model.fit(X_train, y_train,\n                   batch_size = BATCH_SIZE,\n                   epochs = NO_EPOCHS,\n                   verbose = 1, \n                   validation_data = (X_val, y_val),\n                   callbacks = [es, cp, annealer])","4dd7a8e2":"import seaborn as sns\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff\nfrom plotly import tools\nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport scipy","0e1be074":"def create_trace(x,y,ylabel,color):\n        trace = go.Scatter(\n            x = x,y = y,\n            name=ylabel,\n            marker=dict(color=color),\n            mode = \"markers+lines\",\n            text=x\n        )\n        return trace\n    \ndef plot_accuracy_and_loss(train_model):\n    hist = train_model.history\n    acc = hist['acc']\n    val_acc = hist['val_acc']\n    loss = hist['loss']\n    val_loss = hist['val_loss']\n    epochs = list(range(1,len(acc)+1))\n    #define the traces\n    trace_ta = create_trace(epochs,acc,\"Training accuracy\", \"Green\")\n    trace_va = create_trace(epochs,val_acc,\"Validation accuracy\", \"Red\")\n    trace_tl = create_trace(epochs,loss,\"Training loss\", \"Blue\")\n    trace_vl = create_trace(epochs,val_loss,\"Validation loss\", \"Magenta\")\n    fig = tools.make_subplots(rows=1,cols=2, subplot_titles=('Training and validation accuracy',\n                                                             'Training and validation loss'))\n    #add traces to the figure\n    fig.append_trace(trace_ta,1,1)\n    fig.append_trace(trace_va,1,1)\n    fig.append_trace(trace_tl,1,2)\n    fig.append_trace(trace_vl,1,2)\n    #set the layout for the figure\n    fig['layout']['xaxis'].update(title = 'Epoch')\n    fig['layout']['xaxis2'].update(title = 'Epoch')\n    fig['layout']['yaxis'].update(title = 'Accuracy', range=[0,1])\n    fig['layout']['yaxis2'].update(title = 'Loss', range=[0,1])\n    #plot\n    iplot(fig, filename='accuracy-loss')\n\nplot_accuracy_and_loss(history)","c7383cf4":"performance = model.evaluate(X_test, y_test, verbose = 0)\nprint(\"Test Loss:\", performance[0])\nprint(\"Test Accuracy:\", performance[1])","0c17525b":"def build_model2():\n    input_img = Input(shape = (64, 64, 1), name = \"ImageInput\")\n    x = Conv2D(16,kernel_size = (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv1_1\")(input_img)\n    x = Conv2D(16,kernel_size = (3, 3) , activation = \"relu\", padding = \"same\", name = \"Conv1_2\")(x)\n    x = MaxPooling2D((2, 2), name = \"pool1\")(x)\n    x = Dropout(0.7, name = \"dp1\")(x)\n    \n    x = Conv2D(32, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv2_1\")(x)\n    x = Conv2D(32, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv2_2\")(x)\n    x = MaxPooling2D((2, 2), name = \"pool2\")(x)\n    \n    x = Conv2D(64, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv3_1\")(x)\n    x = BatchNormalization(name = \"bn1\")(x)\n    x = Conv2D(64, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv3_2\")(x)\n    x = BatchNormalization(name = \"bn2\")(x)\n    x = MaxPooling2D((2, 2), name = \"pool3\")(x)\n    x = Dropout(0.5, name = \"dp2\")(x)\n    \n    x = Conv2D(128, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv4_1\")(x)\n    x = BatchNormalization(name = \"bn3\")(x)\n    x = Conv2D(128, (3, 3), activation = \"relu\", padding = \"same\", name = \"Conv4_2\")(x)\n    x = BatchNormalization(name = \"bn4\")(x)\n    x = MaxPooling2D((2, 2), name = \"pool4\")(x)\n    \n    x = Flatten(name = \"flatten\")(x)\n    x = Dense(1024, activation = \"relu\", name = \"fc1\")(x)\n    #x = Dropout(0.7, name = \"dp1\")(x)\n    x = Dense(512, activation = \"relu\", name = \"fc2\")(x) \n    x = Dropout(0.5, name = \"dp3\")(x)\n    x = Dense(15, activation = \"softmax\", name = \"fc3\")(x)\n    \n    model = Model(inputs = input_img, outputs = x)\n    return model","8ff639b6":"model2 = build_model2()\nmodel2.summary()","349d69fb":"model2.compile(loss='categorical_crossentropy', metrics=['accuracy'], optimizer=\"adam\")\nhistory2 = model2.fit(X_train, y_train,\n                   batch_size = BATCH_SIZE,\n                   epochs = NO_EPOCHS,\n                   verbose = 1, \n                   validation_data = (X_val, y_val),\n                   callbacks = [es, cp, annealer])","0313082e":"plot_accuracy_and_loss(history2)","5858a87b":"score2 = model2.evaluate(X_test, y_test, verbose = 0)\nprint(\"Test Loss:\", score2[0],\n      \"\/nTest accuracy:\", score2[1])","2bbbd89f":"from sklearn import metrics","f2416f59":"def test_accuracy_report(model):\n    predicted = model.predict(X_test)\n    test_predicted = np.argmax(predicted, axis=1)\n    test_truth = np.argmax(y_test.values, axis=1)\n    print(metrics.classification_report(test_truth, test_predicted, target_names=y_test.columns)) \n    test_res = model.evaluate(X_test, y_test.values, verbose=0)\n    print('Loss function: %s, accuracy:' % test_res[0], test_res[1])","c1356829":"test_accuracy_report(model2)","415b833e":"#optimal_model = model2\n#optimal_model.load_weights(\"best_model.h5\")\n#optimal_score = model_optimal.evaluate(X_test, y_test, verbose = 0)\n#print(\"Optimal Loss: \", optimal_score[0],\n     #\"\\nOptimal Accuracy: \", optimal_score[1])","b69e80a7":"## <a id='4'>Data Preparation<\/a>","95052512":"## <a id='1'>Packages<\/a>","19c738c5":"## <a id='3'>Analysis<\/a>","51646f19":"## <a id='5'>Model Structuring<\/a>","6ceb8864":"### Preparing train\/test\/valid set","19299784":"## This is an attempt to classify the chinese characters of 1 to 10, 100s, 1,000s, 10,000s, and millions with TensorFlow Keras. The data is very clean, so there isn't much wrangling to perform, thus I had the extra effort\/time to perform 2 different type of models. One with SeperableConv2D & Conv2D, and another purely Conv2D, mainly to see if the SeperableConv2D actually makes a difference to performance. The final best model is the latter model. Nonetheless, this does not justify that SeperableConv2D does not make any difference, as there are cases where it performed far better. An example would be the application onto Medical Imaging that I have come across on Kaggle.\n\n### Content\n\n- <a href='#1'>Packages<\/a>\n- <a href='#2'>Data Loading<\/a>\n- <a href='#3'>Analysis<\/a>\n- <a href='#4'>Data Preparation<\/a>\n- <a href='#5'>Model Structuring<\/a>\n- <a href='#6'>Model 1: Conv2D & SeperableConv2D with BatchNormalization<\/a>\n- <a href='#7'>Model 2: Conv2D with BatchNormalization<\/a>\n- <a href='#8'>Check Test Accuracy<\/a>","619a4b4a":"code:\n- 1 = \u96f6 = zero\n- 2 = \u4e00 = one\n- 3 = \u4e8c = two\n- 4 = \u4e09 = three\n- 5 = \u56db = four\n- 6 = \u4e94 = five\n- 7 = \u516d = six\n- 8 = \u4e03 = seven\n- 9 = \u516b = eight\n- 10 = \u4e5d = nine\n- 11 = \u5341 = tens\n- 12 = \u767e = hundred\n- 13 = \u5343 = thousand\n- 14 = \u4e07 = million\n- 15 = \u4ebf = billion\n","dcb799fc":"## <a id='2'>Data Loading<\/a>","0bb4776b":"## <a id='8'>Check Test Accuracy for each Class<\/a>\nbelow function is referenced from [here][1]\n\n[1]: https:\/\/www.kaggle.com\/gpreda\/tensorflow-keras-gpu-for-chinese-mnist-prediction#Prepare-the-data-analysis","a3029d26":"![dataset-card.png](attachment:dataset-card.png)\n\n<img height = \"10\">","d9ab2be6":"## <a id='6'>Model 1: Conv2D & SeperableConv2D with BatchNormalization<\/a>\n","a8780adf":"## <a id='7'>Model 2: Conv2D with BatchNormalization<\/a>"}}