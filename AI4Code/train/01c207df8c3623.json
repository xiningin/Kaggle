{"cell_type":{"bc944de2":"code","4bf125cd":"code","8ff7eae6":"code","79297951":"code","b403f71b":"code","20951d25":"code","acbb2e24":"code","fafa9442":"code","455ea832":"code","40eef6a1":"code","64785c7c":"code","3259aec5":"code","c54fde5d":"code","f70da213":"code","ad38da6e":"code","e913c47f":"code","8413d461":"code","a866f766":"code","68f23146":"code","b1104edc":"code","78fb2c4b":"code","378ede55":"code","bfde1e06":"code","e3db3e04":"code","9d7b13c1":"code","0aa1ae8d":"code","2297ef91":"code","2f7cc289":"code","fb3f3174":"code","3b34a97e":"code","0558589d":"code","fc43e7ff":"markdown","37aa1dd1":"markdown","c7e1b4ea":"markdown","c83662d9":"markdown","2350927c":"markdown","5ee2b257":"markdown","b12b5cec":"markdown","6c76ab09":"markdown","778b8a5c":"markdown"},"source":{"bc944de2":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nfrom torchvision import transforms\nimport transformers\n\nimport os\nimport sys\nimport gc\n\nimport math\nimport cv2\nfrom torch.utils.data import DataLoader,Dataset\nfrom tqdm.notebook import tqdm\n\nif torch.cuda.is_available():\n    import cuml\n    import cudf\n    import cupy\n\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport timm\nimport torchvision","4bf125cd":"PATH = \"\/kaggle\/input\/shopee-product-matching\/\"\nos.listdir(PATH)","8ff7eae6":"test = pd.read_csv(PATH + 'test.csv')\nif len(test) > 3:\n    TRAIN = False\nelse:\n    TRAIN = True","79297951":"# Before submitting, you should set TRAIN = False to see whether the notebook can run on test set normally\n\n#TRAIN = False\nDEBUG = False","b403f71b":"def read_dataset(name=\"train\"):\n    df = pd.read_csv('\/kaggle\/input\/shopee-product-matching\/{}.csv'.format(name))\n    df[\"image_path\"] = '\/kaggle\/input\/shopee-product-matching\/{}_images\/'.format(name) + df['image']\n\n    return df","20951d25":"if TRAIN:\n    train = read_dataset(\"train\")\n    label_group_dict = train.groupby(\"label_group\").posting_id.agg(\"unique\").to_dict()\n    train['target'] = train.label_group.map(label_group_dict)\nelse:\n    train = read_dataset(\"test\")\n\nif DEBUG:\n    train = pd.concat([train]*2)   \n\nif torch.cuda.is_available():\n    train_cu = cudf.DataFrame(train)    \n    \ntrain.head()","acbb2e24":"n_classes = len(train[\"label_group\"].unique())\nnum = int(0.15 * n_classes)\nnp.random.seed(1)\ntest_group = np.random.choice(train[\"label_group\"].unique(), num)\ndf_test = train[train[\"label_group\"].isin(test_group)].reset_index(drop=True)\ndf_train = train[~train[\"label_group\"].isin(test_group)].reset_index(drop=True)\nlen(df_train), len(df_test)","fafa9442":"train = df_test\nif torch.cuda.is_available():\n    train_cu = cudf.DataFrame(train)    ","455ea832":"device = torch.device(\"cuda\" if torch.cuda.is_available() else 'cpu')\ndevice","40eef6a1":"def euclidean_dist(x, y, norm=False):\n    m, n = x.size(0), y.size(0)\n    \n    if norm:\n        x = x \/ x.norm(p=2, dim=1, keepdim=True)\n        y = y \/ y.norm(p=2, dim=1, keepdim=True)\n    \n    xx = torch.pow(x, 2).sum(dim=1, keepdim=True).expand(m, n)\n    yy = torch.pow(y, 2).sum(dim=1, keepdim=True).expand(n, m).t()\n    dist = xx + yy\n    dist.addmm_(1, -2, x, y.t())\n    dist = dist.clamp(min=1e-12).sqrt()\n    return dist\n\ndef cosine_dist(x,y):\n    m, n = x.size(0), y.size(0)\n    \n    norm_x = x.norm(p=2, dim=1, keepdim=True).expand(m,n)\n    norm_y = y.norm(p=2, dim=1, keepdim=True).expand(n,m).t()\n    dist = torch.matmul(x, y.t()) \/ (norm_x * norm_y)\n    return dist\n\ndef DistancePredict(features, threshold = 0.9, chunk = 1024, distance_type=\"cosine\"):\n    assert(distance_type in (\"cosine\",\"euclidean\"))\n    \n    predict = []\n    n = (features.size(0) + chunk - 1) \/\/ chunk\n    with torch.no_grad():\n        for i in tqdm(range(n)):\n            a = i*chunk\n            b = (i+1)*chunk\n            b = min(b, features.size(0))\n            x = features[a:b]\n            y = features\n\n            if distance_type ==\"cosine\":\n                distance = cosine_dist(x,y).data.cpu().numpy()\n            elif distance_type == \"euclidean\":\n                distance = euclidean_dist(x,y, norm=True).data.numpy()\n\n            for k in range(b-a):\n                if distance_type == \"euclidean\":\n                    mask = distance[k] < threshold\n                else :\n                    mask = distance[k] > threshold\n                    \n                if np.sum(mask) > 50:\n                    index = np.argwhere(mask == True).flatten()\n                    index_idx = np.argsort(-distance[k, index])[:50]\n                    mask = index[index_idx]\n                    \n                pred = train.posting_id[mask].to_numpy()\n                predict.append(pred)\n            del x,y,distance\n            \n    return predict","64785c7c":"def f1(target, predict):\n    n = len(np.intersect1d(target,predict))\n    return 2*n\/(len(target)+len(predict))\n\ndef precision(target, predict):\n    n = len(np.intersect1d(target,predict))\n    return n \/ len(predict)\n    \ndef recall(target, predict):\n    n = len(np.intersect1d(target,predict))\n    return n \/ len(target)\n\ndef get_metric(target, predict):\n    tmp = pd.DataFrame({\"target\":target.reset_index(drop=True), \"predict\":predict.reset_index(drop=True)})\n    f1_score = tmp.apply(lambda row: f1(row['target'], row[\"predict\"]),axis=1)\n    precision_score = tmp.apply(lambda row: precision(row['target'], row[\"predict\"]),axis=1)\n    recall_score = tmp.apply(lambda row: recall(row['target'], row[\"predict\"]),axis=1)\n    print(\"Mean F1: {:f}\".format(f1_score.mean()))\n    print(\"Mean Precision: {:f}\".format(precision_score.mean()))\n    print(\"Mean Recall: {:f}\".format(recall_score.mean()))","3259aec5":"class ShopeeImageDataset(Dataset):\n    def __init__(self, dataset, transform=None, train=True, resize = 256):\n        self.dataset = dataset\n        self.transform = transform\n        self.train = train\n        self.resize = resize\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, index):\n        image_path = self.dataset.image_path.iloc[index]\n        image = cv2.imread(image_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (self.resize,self.resize))\n        if self.transform:\n            image = self.transform(image)\n        if self.train:\n            label_group = self.dataset.label_group.iloc[index]\n            return image, label_group\n        else:\n            return image","c54fde5d":"transform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n])\n\n\nshopee_image_dataset = ShopeeImageDataset(train, transform = transform, train = TRAIN)\nshopee_image_dataloader =  torch.utils.data.DataLoader(shopee_image_dataset, batch_size=64, shuffle=False, num_workers=2, prefetch_factor = 8)\n\nshopee_swin_dataset = ShopeeImageDataset(train, transform = transform, train = TRAIN, resize = 224)\nshopee_swin_dataloader =  torch.utils.data.DataLoader(shopee_swin_dataset, batch_size=64, shuffle=False, num_workers=2, prefetch_factor = 8)","f70da213":"def get_image_feature(model_name):\n    # load\n    if TRAIN and os.path.exists(\"image_features_{}.pt\".format(model_name)):\n        image_features = torch.load(\"image_features_{}.pt\".format(model_name), map_location = device)\n    else:\n        dataloader = shopee_image_dataloader if \"swin\" not in model_name else shopee_swin_dataloader\n        model = get_model(model_name)\n        image_features = []\n        with torch.no_grad():\n            if TRAIN:\n                for (images, labels) in tqdm(dataloader):\n                    images, labels = images.to(device), labels.to(device)\n                    features = model(images)\n                    image_features.append(features)\n                    del images, labels\n            else:\n                for images in tqdm(dataloader):\n                    images = images.to(device)\n                    features = model(images)\n                    image_features.append(features.data)\n                    del images \n        image_features = torch.cat(image_features, axis=0)\n        # save\n        if TRAIN:\n            torch.save(image_features, \"image_features_{}.pt\".format(model_name))\n        \n        del model\n        gc.collect()\n        torch.cuda.empty_cache()   \n    \n    print(image_features.shape)\n    return image_features","ad38da6e":"class ArcFace(nn.Module):\n    \"\"\" NN module for projecting extracted embeddings onto the sphere surface \"\"\"\n    \n    def __init__(self, in_features, out_features, s=30, m=0.5):\n        super(ArcFace, self).__init__()\n        self.in_features = in_features\n        self.out_features = out_features\n        self.s = s\n        self.m = m\n        self.cos_m = math.cos(m)\n        self.sin_m = math.sin(m)\n        self.arc_min = math.cos(math.pi - m)\n        self.margin_min = math.sin(math.pi - m) * m\n        self.weight = nn.Parameter(torch.FloatTensor(out_features, in_features))\n        nn.init.xavier_uniform_(self.weight)\n\n\n    def forward(self, embedding, label):\n        cos = F.linear(F.normalize(embedding), F.normalize(self.weight))\n        sin = torch.sqrt(1.0 - torch.pow(cos, 2)).clamp(0, 1)\n        phi = cos * self.cos_m - sin * self.sin_m\n        phi = torch.where(cos > self.arc_min, phi, cos - self.margin_min)\n\n        one_hot = torch.zeros(cos.size(), device='cuda')\n        one_hot.scatter_(1, label.view(-1, 1).long(), 1)\n        logits = one_hot * phi + (1.0 - one_hot) * cos\n        logits *= self.s\n        return logits","e913c47f":"class Model(nn.Module):\n    def __init__(self, model_name, n_classes, fc_dim=512):\n        super(Model, self).__init__()\n        print(\"Building Model Backbone for {} model\".format(model_name))\n        \n        if \"eca_nfnet\" in model_name:\n            self.backbone = timm.create_model(model_name)\n            feat_size = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n                \n        elif \"efficientnet\" in model_name:\n            self.backbone = timm.create_model(model_name)\n            feat_size = self.backbone.classifier.in_features\n            self.backbone.classifier = nn.Identity()\n\n        elif \"dm_nfnet\" in model_name:\n            self.backbone = timm.create_model(model_name)\n            feat_size = self.backbone.head.fc.in_features\n            self.backbone.head.fc = nn.Identity()\n        \n        elif \"swin\" in model_name:\n            self.backbone = timm.create_model(model_name)\n            feat_size = self.backbone.head.in_features\n            self.backbone.head = nn.Identity()\n        \n        else:\n            raise ValueError(\"Invalid model name: {}\".format(model_name))\n        \n        self.fc = nn.Linear(feat_size, fc_dim)\n        self.margin = ArcFace(fc_dim, n_classes)\n        \n    def forward(self, x, labels=None):\n        x = self.backbone(x)\n        x = self.fc(x)\n        if labels is not None:\n            return self.margin(x,labels)\n        return F.normalize(x,dim=1)","8413d461":"def get_model(model_name):\n    name = \"_\".join(model_name.split(\"_\")[:-2])\n    if \"swin\" in name:\n        model = Model(name, 9977)\n    else:\n        model = Model(name, 9499)\n    model.load_state_dict(torch.load(\"..\/input\/arcface-pretrained-model\/{}.pt\".format(model_name), map_location=device))\n    model.to(device)\n\n    # eval\n    model.eval()\n    \n    return model","a866f766":"def WeightedEnsemblePredict(model_names, weights = None, threshold = 0.8):\n    n = len(model_names)\n    if not weights:\n        weights = [1\/n] * n\n    \n    weighted_features = None\n    for model_name, weight in zip(model_names, weights):\n        model_features = get_image_feature(model_name)\n        if weighted_features is None:\n            weighted_features = weight * model_features\n        else:\n            weighted_features.add_(weight * model_features)\n    weighted_features \/= sum(weights)\n    print(weighted_features.shape)\n    # predict\n    weighted_pred = DistancePredict(weighted_features, threshold=threshold)\n    del weighted_features\n    gc.collect()\n    torch.cuda.empty_cache()\n    return weighted_pred","68f23146":"\"\"\"MODEL_NAMES = [\"efficientnet-b0_arcface_0015\", \"efficientnet-b4_arcface_0015\"]\nTHRESHOLD = 0.7\n\nweighted_pred = WeightedEnsemblePredict(MODEL_NAMES, threshold = THRESHOLD)\ntrain[\"image_pred\"] = weighted_pred\nif TRAIN:\n    print(\"\\nMODEL: Weighted Ensemble\")\n    get_metric(train[\"target\"], train[\"image_pred\"])\n\"\"\"","b1104edc":"# Union\/Intersect Ensemble\ndef EasyEnsemblePredict(model_names, thresholds, ensemble_type=\"union\"):\n    tmp = pd.DataFrame()\n    for model_name, threshold in zip(MODEL_NAME, THRESHOLD):\n        # extract feature\n        image_features = get_image_feature(model_name)\n\n        # distance-based prediction\n        image_pred = DistancePredict(image_features, threshold=threshold)\n        tmp[\"{}_pred\".format(model_name)] = image_pred\n        \n        del image_features\n        gc.collect()\n        torch.cuda.empty_cache()\n        \n        # metric\n        if TRAIN:\n            print(\"MODEL: {} THRESHOLD: {}\".format(model_name, threshold))\n            get_metric(train[\"target\"], tmp[\"{}_pred\".format(model_name)])\n    # ensemble\n    n = len(model_names)\n    from functools import reduce\n    if ensemble_type == \"union\":\n        ensemble_pred = tmp.apply(lambda row: reduce(np.union1d, row), axis=1)\n    elif ensemble_type == \"intersect\":\n        ensemble_pred = tmp.apply(lambda row: reduce(np.intersect1d, row), axis=1)\n    \n    return ensemble_pred, tmp","78fb2c4b":"\"\"\"MODEL_NAME = [\"eca_nfnet_l0_arcface_7\", \"eca_nfnet_l1_arcface_8\" , \"efficientnet_b4_arcface_13\"]\nTHRESHOLD = [0.5, 0.5, 0.55]\n\nensemble_pred, tmp = EasyEnsemblePredict(MODEL_NAME, THRESHOLD, ensemble_type=\"union\")\ntrain[\"image_pred\"] = ensemble_pred\n    \nif TRAIN:\n    print(\"\\nMODEL:  UnionEnsemble\")\n    get_metric(train[\"target\"], train[\"image_pred\"])\"\"\"","378ede55":"def ConcatEnsemblePredict(model_names, threshold, normalize = True, distance_type=\"cosine\"):\n    concat_features = []\n    for model_name in model_names:\n        image_features = get_image_feature(model_name)\n        concat_features.append(image_features)\n    concat_features = torch.hstack(concat_features)\n    print(concat_features.shape)\n    # normalize\n    if normalize:\n        concat_features = F.normalize(concat_features, dim=1)\n    # predict\n    concat_pred = DistancePredict(concat_features, threshold=threshold, distance_type=distance_type)\n    \n    del concat_features\n    gc.collect()\n    torch.cuda.empty_cache()\n    \n    return concat_pred","bfde1e06":"MODEL_NAME = [\"eca_nfnet_l0_arcface_7\", \"eca_nfnet_l1_arcface_8\" , \"efficientnet_b4_arcface_13\"]\nTHRESHOLD = 0.65\n\nconcat_pred = ConcatEnsemblePredict(MODEL_NAME, THRESHOLD)\ntrain[\"image_pred\"] = concat_pred\n    \nif TRAIN:\n    print(\"\\nMODEL:  ConcatEnsemble THRESHOLD: {}\".format(THRESHOLD))\n    get_metric(train[\"target\"], train[\"image_pred\"])\n\ntorch.cuda.empty_cache()\n\nTHRESHOLD = 0.46\n\nconcat_pred = ConcatEnsemblePredict(MODEL_NAME, THRESHOLD)\ntrain[\"image_pred_wait\"] = concat_pred\n    \nif TRAIN:\n    print(\"\\nMODEL:  ConcatEnsemble THRESHOLD: {}\".format(THRESHOLD))\n    get_metric(train[\"target\"], train[\"image_pred_wait\"])\n\ntorch.cuda.empty_cache()","e3db3e04":"def TFIDFExtractFeature(df, max_features):\n    if torch.cuda.is_available():\n        from cuml.feature_extraction.text import TfidfVectorizer\n    else:\n        from sklearn.feature_extraction.text import TfidfVectorizer\n    \n    model = TfidfVectorizer(stop_words='english', max_features=max_features)\n    model.fit(df.title)\n\n    tfidf_features = model.transform(df.title).toarray()\n    print(tfidf_features.shape)\n    return tfidf_features","9d7b13c1":"MAX_FEATURES = 25000\nTHRESHOLD = 0.75\n\nif torch.cuda.is_available():\n    text_features = TFIDFExtractFeature(train_cu, MAX_FEATURES)\nelse:\n    text_features = TFIDFExtractFeature(train, MAX_FEATURES)\ntext_features = torch.Tensor(text_features).to(device)\ntext_pred = DistancePredict(text_features, threshold = THRESHOLD, distance_type=\"cosine\")\ntrain[\"text_pred\"] = text_pred\n\nif TRAIN:\n    get_metric(train[\"target\"], train[\"text_pred\"])\n\nTHRESHOLD = 0.51\ntext_pred = DistancePredict(text_features, threshold = THRESHOLD, distance_type=\"cosine\")\ntrain[\"text_pred_wait\"] = text_pred\n\nif TRAIN:\n    get_metric(train[\"target\"], train[\"text_pred_wait\"])\n\ndel text_features\ngc.collect()\ntorch.cuda.empty_cache()","0aa1ae8d":"class ShopeeTextDataset(Dataset):\n    def __init__(self, dataset, train):\n        self.dataset = dataset\n        self.train = train\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, index):\n        title = self.dataset.title.iloc[index]\n        if self.train:\n            label_group = self.dataset.label_group.iloc[index]\n            return title, label_group\n        else:\n            return title\n    \nshopee_text_dataset = ShopeeTextDataset(train, train=TRAIN)\nshopee_text_dataloader =  torch.utils.data.DataLoader(shopee_text_dataset, batch_size=64, shuffle=False, num_workers=2)","2297ef91":"class ShopeeTextDataset(Dataset):\n    def __init__(self, dataset, train):\n        self.dataset = dataset\n        self.train = train\n    \n    def __len__(self):\n        return self.dataset.shape[0]\n    \n    def __getitem__(self, index):\n        title = self.dataset.title.iloc[index]\n        if self.train:\n            label_group = self.dataset.label_group.iloc[index]\n            return title, label_group\n        else:\n            return title\n    \nshopee_text_dataset = ShopeeTextDataset(train, train=TRAIN)\nshopee_text_dataloader =  torch.utils.data.DataLoader(shopee_text_dataset, batch_size=64, shuffle=False, num_workers=2)","2f7cc289":"def get_text_feature(model_name, max_length):\n    # load\n    if TRAIN and os.path.exists(\"text_features_{}.pt\".format(model_name)):\n        image_features = torch.load(\"text_features_{}.pt\".format(model_name), map_location = device)\n    else:\n        tokenizer = BertTokenizer.from_pretrained(\"..\/input\/roberta-base\/vocab.json\")\n        #bert = BertModel.from_pretrained(\"..\/input\/roberta-base\/pytorch_model.bin\",\n        #                                 config = \"..\/input\/roberta-base\/config.json\").to(device)\n        model = get_model(model_name) # e.g. roberta-based\n        text_features = []\n        with torch.no_grad():\n            if TRAIN:\n                for (texts, labels) in tqdm(shopee_text_dataloader):\n                    inputs = tokenizer(texts, max_length = max_length, truncation=True, padding=True, return_tensors=\"pt\")\n                    input_ids = inputs[\"input_ids\"].to(device)\n                    token_type_ids = inputs[\"token_type_ids\"].to(device)\n                    attention_mask = inputs[\"attention_mask\"].to(device)\n                    features = model(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n                    text_features.append(features.data)\n                    del inputs, input_ids, token_type_ids, attention_mask\n            else:\n                for texts in tqdm(shopee_text_dataloader):\n                    inputs = tokenizer(texts, max_length = max_length, truncation=True, padding=True, return_tensors=\"pt\")\n                    input_ids = inputs[\"input_ids\"].to(device)\n                    token_type_ids = inputs[\"token_type_ids\"].to(device)\n                    attention_mask = inputs[\"attention_mask\"].to(device)\n                    features = model(input_ids = input_ids, token_type_ids = token_type_ids, attention_mask = attention_mask)\n                    text_features.append(features.data)\n                    del inputs, input_ids, token_type_ids, attention_mask\n        text_features = torch.cat(text_features, axis=0)\n        # save\n        if TRAIN:\n            torch.save(text_features, \"text_features_{}.pt\".format(model_name))\n        \n        del model\n        gc.collect()\n        torch.cuda.empty_cache()   \n    \n    print(text_features.shape)\n    return text_features","fb3f3174":"\"\"\"MAX_LENGTH = 30\nTHRESHOLD = 0.7\ntext_features = get_text_feature(model_name, max_length=MAX_LENGTH) # roberta-based\ntext_pred = DistancePredict(text_features, threshold = THRESHOLD, distance_type=\"cosine\")\n\nif TRAIN:\n    get_metric(train[\"target\"], train[\"text_pred\"])\n    \ndel text_features\ngc.collect()\ntorch.cuda.empty_cache()    \n\"\"\"","3b34a97e":"def union(x,y):\n    return np.union1d(x,y)\n\ndef intersect(x,y):\n    return np.intersect1d(x,y)\n\ntrain[\"pred\"] = train.apply(lambda row: union(row['image_pred'], row[\"text_pred\"]),axis=1)\ntrain[\"wait\"] = train.apply(lambda row: intersect(row['image_pred_wait'], row[\"text_pred_wait\"]),axis=1)\ntrain[\"pred\"] = train.apply(lambda row: union(row['pred'], row[\"wait\"]),axis=1)\n\nif TRAIN:\n    get_metric(train[\"target\"], train[\"pred\"])","0558589d":"def submission(row):\n    return ' '.join(row)\n\ntrain[\"matches\"] = train[\"pred\"].apply(lambda x: submission(x))\n# submit\ntrain[['posting_id','matches']].to_csv('submission.csv',index=False)\nsubmission = pd.read_csv('submission.csv')\nsubmission.head()","fc43e7ff":"### Weighted Ensemble","37aa1dd1":"### Concat Ensemble","c7e1b4ea":"### UnionEnsemble","c83662d9":"### TF-IDF","2350927c":"### Bert","5ee2b257":"## Image","b12b5cec":"# Shopee Product Match","6c76ab09":"## Text","778b8a5c":"## MultiModal Fusion"}}