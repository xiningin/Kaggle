{"cell_type":{"068c0fb7":"code","336ac82b":"code","be4bedb8":"code","1040c4e9":"code","d67a9a1a":"code","94681351":"code","ee6d90fa":"code","ec719fbb":"code","498317fc":"code","fc6f7642":"code","fb521d6d":"code","223204a0":"code","28015be1":"code","56c47984":"code","1003d135":"markdown","6d20983f":"markdown","1362ce72":"markdown"},"source":{"068c0fb7":"import time\nstart_time = time.time()\nfrom sklearn.model_selection import train_test_split\nimport sys, os, re, csv, codecs, numpy as np, pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use(\"fivethirtyeight\")\nnp.random.seed(32)\nos.environ[\"OMP_NUM_THREADS\"] = \"4\"","336ac82b":"# https:\/\/keras.io\/preprocessing\/text\/\nfrom keras.preprocessing.text import Tokenizer\n# https:\/\/keras.io\/preprocessing\/sequence\/#pad_sequences\nfrom keras.preprocessing.sequence import pad_sequences\n# https:\/\/keras.io\/layers\/about-keras-layers\/\nfrom keras.layers import Dense, Input, LSTM, Embedding, Dropout, Activation, Conv1D, GRU\nfrom keras.layers import Bidirectional, GlobalMaxPool1D, MaxPooling1D, Add, Flatten\nfrom keras.layers import GlobalAveragePooling1D, GlobalMaxPooling1D, concatenate, SpatialDropout1D\n# https:\/\/keras.io\/getting-started\/sequential-model-guide\/#getting-started-with-the-keras-sequential-model\nfrom keras.models import Model, load_model\nfrom keras import initializers, regularizers, constraints, optimizers, layers, callbacks\nfrom keras import backend as K\nfrom keras.engine import InputSpec, Layer\n\nimport logging\nfrom sklearn.metrics import roc_auc_score\nfrom keras.callbacks import Callback","be4bedb8":"class RocAucEvaluation(Callback):\n    def __init__(self, validation_data=(), interval=1):\n        super(Callback, self).__init__()\n\n        self.interval = interval\n        self.X_val, self.y_val = validation_data\n\n    def on_epoch_end(self, epoch, logs={}):\n        if epoch % self.interval == 0:\n            y_pred = self.model.predict(self.X_val, verbose=0)\n            score = roc_auc_score(self.y_val, y_pred)\n            print(\"\\n ROC-AUC - epoch: {:d} - score: {:.6f}\".format(epoch+1, score))","1040c4e9":"train = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\ntest = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/test.csv\")\nembedding_path = \"..\/input\/fasttext-crawl-300d-2m\/crawl-300d-2M.vec\"\n#embedding_path = \"..\/input\/glove840b300dtxt\/glove.840B.300d.txt\"\nembed_size = 300\nmax_features = 130000\nmax_len = 220","d67a9a1a":"list_classes = [\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\", \"identity_hate\"]\ny = train[list_classes].values\ntrain[\"comment_text\"].fillna(\"no comment\")\ntest[\"comment_text\"].fillna(\"no comment\")\nX_train, X_valid, Y_train, Y_valid = train_test_split(train, y, test_size = 0.1)","94681351":"raw_text_train = X_train[\"comment_text\"].str.lower()\nraw_text_valid = X_valid[\"comment_text\"].str.lower()\nraw_text_test = test[\"comment_text\"].str.lower()","ee6d90fa":"tk = Tokenizer(num_words = max_features, lower = True)\ntk.fit_on_texts(raw_text_train)\nX_train[\"comment_seq\"] = tk.texts_to_sequences(raw_text_train) #  text_to_word_sequence() function that you can use to split text into a list of words.\nX_valid[\"comment_seq\"] = tk.texts_to_sequences(raw_text_valid)\ntest[\"comment_seq\"] = tk.texts_to_sequences(raw_text_test)","ec719fbb":"X_train = pad_sequences(X_train.comment_seq, maxlen = max_len)\nX_valid = pad_sequences(X_valid.comment_seq, maxlen = max_len)\ntest = pad_sequences(test.comment_seq, maxlen = max_len)","498317fc":"def get_coefs(word,*arr): return word, np.asarray(arr, dtype='float32')\nembedding_index = dict(get_coefs(*o.strip().split(\" \")) for o in open(embedding_path))","fc6f7642":"word_index = tk.word_index\nnb_words = min(max_features, len(word_index))\nembedding_matrix = np.zeros((nb_words, embed_size))\nfor word, i in word_index.items():\n    if i >= max_features: continue\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None: embedding_matrix[i] = embedding_vector","fb521d6d":"from keras.optimizers import Adam, RMSprop\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom keras.layers import GRU, BatchNormalization, Conv1D, MaxPooling1D","223204a0":"file_path = \"best_model.hdf5\"\ncheck_point = ModelCheckpoint(file_path, monitor = \"val_loss\", verbose = 1,\n                              save_best_only = True, mode = \"min\")\nra_val = RocAucEvaluation(validation_data=(X_valid, Y_valid), interval = 1)\nearly_stop = EarlyStopping(monitor = \"val_loss\", mode = \"min\", patience = 5)","28015be1":"def build_model(lr = 0.0, lr_d = 0.0, units = 0, dr = 0.0):\n    inp = Input(shape = (max_len,))\n    x = Embedding(max_features, embed_size, weights = [embedding_matrix], trainable = False)(inp)\n    x1 = SpatialDropout1D(dr)(x)\n\n    x = Bidirectional(GRU(units, return_sequences = True))(x1)\n    x = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(x)\n    \n    y = Bidirectional(LSTM(units, return_sequences = True))(x1)\n    y = Conv1D(64, kernel_size = 2, padding = \"valid\", kernel_initializer = \"he_uniform\")(y)\n    \n    avg_pool1 = GlobalAveragePooling1D()(x)\n    max_pool1 = GlobalMaxPooling1D()(x)\n    \n    avg_pool2 = GlobalAveragePooling1D()(y)\n    max_pool2 = GlobalMaxPooling1D()(y)\n    \n    \n    x = concatenate([avg_pool1, max_pool1, avg_pool2, max_pool2])\n\n    x = Dense(6, activation = \"sigmoid\")(x)\n    model = Model(inputs = inp, outputs = x)\n    model.compile(loss = \"binary_crossentropy\", optimizer = Adam(lr = lr, decay = lr_d), metrics = [\"accuracy\"])\n    history = model.fit(X_train, Y_train, batch_size = 128, epochs = 3, validation_data = (X_valid, Y_valid), \n                        verbose = 1, callbacks = [ra_val, check_point, early_stop])\n    model = load_model(file_path)\n    return model","56c47984":"model = build_model(lr = 1e-4, lr_d = 0, units = 128, dr = 0.2)\npred = model.predict(test, batch_size = 1024, verbose = 1)","1003d135":"## Toxic Comment Classification\n![](https:\/\/cdn-images-1.medium.com\/max\/1200\/1*PIs25RW-zFYGalzlzgdI9A.jpeg)\n\n### Introduction\n* With the rise of social media platforms, online discussion has become integral to people\u2019s experience of the internet. Unfortunately, online discussion is also an avenue for abuse. A 2014 Pew Report highlights that **73% of adult internet users have seen someone harassed online, and 40% have personally experienced it [5].** Platforms combat this with policies concerning such behavior. **For example Wikipedia has a policy of \u201c[Do not make personal attacks anywhere in Wikipedia](https:\/\/en.wikipedia.org\/wiki\/Wikipedia:No_personal_attacks)\u201d** and notes that attacks may be removed and the users who wrote them blocked.\"\n\n\n### Outline\n1. [Read Data](#Read-Data)\n2. [Get Insight](#Get-Insight)","6d20983f":"## 2.Read Data","1362ce72":"## ROC Function"}}