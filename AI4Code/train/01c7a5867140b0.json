{"cell_type":{"e0dae14c":"code","b681aaa5":"code","9126035d":"code","40f6fc0b":"code","d91ade8e":"code","40d44f53":"code","924f594c":"code","3f6769ae":"code","e5d74707":"code","42b01d3a":"code","8e9b8176":"code","6343a0fb":"code","a5ae9cba":"code","b405226a":"code","b8718852":"markdown","e550f80d":"markdown","a226d079":"markdown","e39c61ef":"markdown","3d702486":"markdown","27b54b50":"markdown","c14a6dbe":"markdown"},"source":{"e0dae14c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b681aaa5":"# Importing Tensorflow and the required visualization libraries\nimport tensorflow as tf\ntf.config.experimental_run_functions_eagerly(True)\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n#Loading the Dataset\ntrain = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\n","9126035d":"# Seperating the independent feature as y\ny = train['label']\ntrain = train.drop('label', axis =1)","40f6fc0b":"#Visualizing the Distribution of digits in labels\nsns.countplot(y)","d91ade8e":"#Visualing an example \nimg = train.iloc[10].to_numpy()\nimg = img.reshape((28,28))\nplt.imshow(img,cmap='gray')\nplt.title(y.iloc[10])\nplt.axis(\"off\")\nplt.show()","40d44f53":"#Preprocessing the Data\ntrain=train\/225.0\ntest = test\/225.0\ntrain = np.array(train)\ntest= np.array(test)\ntrain = train.reshape(train.shape[0], 28, 28,1)\ntest = test.reshape(test.shape[0], 28, 28,1)\n\n#Splitting the data into training and validation \nfrom sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(train, y, test_size=0.2)\n\n#Converting the train and validation labels to one-hot encodings\nY_train = tf.keras.utils.to_categorical(Y_train, num_classes=10)\nY_val = tf.keras.utils.to_categorical(Y_val, num_classes=10)","924f594c":"#Preparing a CNN model architecture\nmodel = tf.keras.models.Sequential([\n            tf.keras.layers.Conv2D(32, (5,5), activation='relu', kernel_initializer='he_uniform',input_shape=(28, 28, 1)),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            tf.keras.layers.Dropout(0.2),\n            tf.keras.layers.Conv2D(64, (5,5), activation='relu'),\n            tf.keras.layers.MaxPooling2D(2, 2),\n            \n            \n            tf.keras.layers.Dropout(0.25),\n            tf.keras.layers.Flatten(),\n            tf.keras.layers.Dense(128, activation='relu'),\n            tf.keras.layers.BatchNormalization(),\n            tf.keras.layers.Dense(10, activation='softmax')\n    ])\n","3f6769ae":"#Getting the model framework\/summary \nfrom keras.utils import plot_model\nplot_model(model, to_file='model.png', show_shapes=True, show_layer_names=True)\nfrom IPython.display import Image\nImage(\"model.png\")","e5d74707":"#Compiling the model\nmodel.compile(optimizer= tf.keras.optimizers.SGD(lr=0.1, momentum=0.9), loss='categorical_crossentropy', metrics=['accuracy'])","42b01d3a":"#Data augmentation to prevent overfitting\ndatagen = tf.keras.preprocessing.image.ImageDataGenerator(\n        rotation_range=30, \n        zoom_range = 0.2, \n        width_shift_range=0.1,  \n        height_shift_range=0.1,)  ","8e9b8176":"#Training the model\nhistory = model.fit_generator(datagen.flow(X_train, Y_train,batch_size=64),validation_data=(X_val, Y_val),epochs=15,steps_per_epoch=X_train.shape[0] \/\/ 64)","6343a0fb":"#Comparing losses and accuraries \nplt.plot(history.history['loss'], color='r')\nplt.plot(history.history['val_loss'], color='b')\nplt.show()\nplt.plot(history.history['accuracy'], color='r')\nplt.plot(history.history['val_accuracy'], color='b')\nplt.show()","a5ae9cba":"#Plotting Confusion Matrix\ny_pred1 = model.predict(X_val)\ny_pred1 = np.argmax(y_pred1, axis=1)\ny_true = np.argmax(Y_val, axis=1)\nfrom sklearn.metrics import confusion_matrix\ncm = confusion_matrix(y_true, y_pred1)\nprint(cm)","b405226a":"#Predicting and Saving it as a CSV file\ny_pred = model.predict(test)\ny_pred = np.argmax(y_pred, axis=1)\ny_pred = pd.Series(y_pred, name='Label')\nsub = pd.concat([pd.Series(range(1, 28001), name=\"ImageId\"), y_pred], axis=1)\nsub.to_csv('\/kaggle\/working\/RESULT.csv', index=False)","b8718852":"# Preprocessing Data","e550f80d":"# Loading Datasets and Importing Libraries ","a226d079":"# Saving the Predictions","e39c61ef":"# Visualizing Data","3d702486":"# Building, Compiling and Training model","27b54b50":"# Evaluating Results","c14a6dbe":"# Please do upvote the kernel if you like my work and share your views in the comments.\n\n# Good Day! :)"}}