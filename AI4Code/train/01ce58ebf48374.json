{"cell_type":{"49f68959":"code","3a1a120a":"code","8b4a8f39":"code","ba80a0a3":"code","427ae942":"code","78c2655f":"code","5910da80":"code","bedc72f5":"code","dde2a1e5":"code","f17efbab":"code","d7b6591f":"code","092809bf":"code","ff000480":"code","1c326b15":"code","3b55fa0e":"code","7a40afc4":"markdown","d198890e":"markdown","2f6f871a":"markdown","cec89b0a":"markdown","544de589":"markdown","5ce13564":"markdown","01a4d6a2":"markdown","fd94018f":"markdown","b0732571":"markdown","6e7fdfe1":"markdown","40ee2ba1":"markdown","fc7e46e8":"markdown","50a36f47":"markdown","ccbf6b8d":"markdown","cdf80400":"markdown","812e3d87":"markdown"},"source":{"49f68959":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nimport csv\nimport tensorflow as tf\nfrom tensorflow.keras.callbacks import EarlyStopping,LearningRateScheduler\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,LSTM,Bidirectional,Lambda,Conv1D,Dropout\nfrom tensorflow.keras.optimizers import Adam,SGD\nfrom tensorflow.keras.metrics import mean_absolute_error,mean_squared_error\nfrom tensorflow.keras.losses import Huber\nfrom tensorflow.keras.utils import plot_model","3a1a120a":"time=[]\nsunspots=[]\nwith open(\"..\/input\/sunspots\/Sunspots.csv\") as f:\n    reader = csv.reader(f,delimiter=',')\n    next(reader)\n    for row in reader:\n        time.append(row[0])\n        sunspots.append(row[2])\n\nseries = np.array(sunspots).astype(float)\ntime = np.array(time).astype(int)","8b4a8f39":"#Plot Time vs Series\ndef plot_series(time,series):\n    plt.title(\"Variation of Sunspots with Time\")\n    sns.lineplot(time,series)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\nplt.figure(figsize=(12,6))\nplot_series(time,series)","ba80a0a3":"#Autocorrelation Plot\nfig,ax = plt.subplots(1,2,figsize=(15,6))\nauto = plot_acf(series,ax=ax[0])\npartial = plot_pacf(series,ax=ax[1])\nplt.show()","427ae942":"split_time = 3000\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]\nsplit_time","78c2655f":"#Parameters\nwindow_size = 60\nbatch_size = 100\nshuffle_buffer = 1000","5910da80":"def windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    d = tf.data.Dataset.from_tensor_slices(series)\n    d = d.window(window_size + 1, shift=1, drop_remainder=True)\n    d = d.flat_map(lambda w: w.batch(window_size + 1))\n    d = d.shuffle(shuffle_buffer)\n    d = d.map(lambda w: (w[:-1], w[1:]))\n    d = d.batch(batch_size).prefetch(1)\n    return d","bedc72f5":"def model_forecast(model,series,batch_size,window_size):\n    d = tf.data.Dataset.from_tensor_slices(series)\n    d = d.window(window_size, shift=1, drop_remainder=True)\n    d = d.flat_map(lambda w: w.batch(window_size))\n    d = d.batch(batch_size).prefetch(1)\n    forecast = model.predict(d)\n    return forecast","dde2a1e5":"tf.keras.backend.clear_session()\n\ntrain = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer)\nval = windowed_dataset(x_valid, window_size, batch_size, shuffle_buffer)\n\nmodel = Sequential()\nmodel.add(Lambda(lambda x:tf.expand_dims(x,axis=-1),input_shape=[None]))\nmodel.add(Conv1D(filters=60,kernel_size=5,strides=1,padding='causal',activation='relu'))\nmodel.add(LSTM(120,return_sequences=True))\nmodel.add(LSTM(120,return_sequences=True))\nmodel.add(Dense(60,activation='relu'))\nmodel.add(Dense(30,activation='relu'))\nmodel.add(Dense(1))\nmodel.add(Lambda(lambda x:x*400))\n\nlr_schedule = LearningRateScheduler(lambda epoch : 1e-8 * 10**(epoch \/ 20))\nmodel.compile(loss=Huber(),optimizer=SGD(lr=1e-8,momentum=0.9),metrics=['mae'])\nhistory = model.fit(train, epochs=100,validation_data=val,callbacks=[lr_schedule])","f17efbab":"#Plot for selecting learning rate\nplt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-8, 1e-3, 0, 100])\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")","d7b6591f":"#Final Model with lr=8e-6\n\ntf.keras.backend.clear_session()\n\ntrain = windowed_dataset(x_train,window_size,batch_size,shuffle_buffer)\nval = windowed_dataset(x_valid,window_size,batch_size,shuffle_buffer)\n\nmodel = Sequential()\nmodel.add(Lambda(lambda x:tf.expand_dims(x,axis=-1),input_shape=[None]))\nmodel.add(Conv1D(filters=60,kernel_size=5,strides=1,padding='causal',activation='relu'))\nmodel.add(LSTM(120,return_sequences=True))\nmodel.add(LSTM(120,return_sequences=True))\nmodel.add(Dense(60,activation='relu'))\nmodel.add(Dense(30,activation='relu'))\nmodel.add(Dense(1))\nmodel.add(Lambda(lambda x:x*400))\n\nmodel.compile(loss=Huber(),optimizer=SGD(lr=8e-6,momentum=0.9),metrics=['mae'])\nhistory = model.fit(train, epochs=200,validation_data=val)","092809bf":"#Plotting graphs for mae and loss\ndef plot_graphs(history, string):\n    plt.plot(history.history[string])\n    plt.plot(history.history[\"val_\"+string])\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(string)\n    plt.legend([string,\"val_\"+string])\n    plt.show()\n\nplt.figure(figsize=(12,6))\nplot_graphs(history,'mae')\nplt.figure(figsize=(12,6))\nplot_graphs(history,'loss')\nplt.show()","ff000480":"#Forecast\nforecast = model_forecast(model,series[..., np.newaxis],batch_size,window_size)\nforecast = forecast[split_time - window_size:-1,-1,0]","1c326b15":"#Predicted Plot\nplt.figure(figsize=(12, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, forecast)\nplt.legend([\"Actual\",\"Forecast\"])","3b55fa0e":"print(\"Mean Absolute Error: \",mean_absolute_error(x_valid,forecast).numpy())\nprint(\"Mean Squared Error:\",mean_squared_error(x_valid,forecast).numpy())","7a40afc4":"We have to split our time series into training and validation period. The split time is 3000 means from 0 to 3000 will be for training and 3000 till the end is for validation.","d198890e":"After trainig the model using Learning Rate Scheduler, lets plots the grpah of \"learning rate\" vs \"loss\". This will help us to select the best learning rate of all.","2f6f871a":"**ACF** : It is a auto-correlation function which gives us values of auto-correlation of any series with its lagged values.It describes how well the present value of the series is related with its past values.\nHere ACF is significant for about **30 values**.This means value depends on previous 30 values.<br>\n**PACF** : The \"partial\" correlation between two variables is the amount of correlation between them which is not explained by their mutual correlations with a specified set of other variables.Here PACF is significant for about **6 values.**","cec89b0a":"Lets plot the graph between :\n* \"mae\" vs \"validation mae\"\n* \"loss\" vs \"validation loss\"","544de589":"# Reading Data","5ce13564":"# Time, Series Analysis To Predict Sunspots","01a4d6a2":"**Time Series** is the ordered sequnce of values spaced over equal interval of time.","fd94018f":"We will also define a function to make a forecast based on our model.","b0732571":" From this we select learning rate to be **8e-6**","6e7fdfe1":"# Importing Libraries","40ee2ba1":"Now we will define a function to create a windowed dataset. In a window dataset, the previous n values could be seen as the input features. And the current value with any timestamp is the output label. Window dataset consconsists of fixed window size.","fc7e46e8":"# Result","50a36f47":"# Time Series Prediction Model","ccbf6b8d":"<img src='https:\/\/www.almanac.com\/sites\/default\/files\/styles\/primary_image_in_article\/public\/image_nodes\/sunspots.jpg?itok=6Fx0Px0U' alt='Sunspots' width='500' height='500'>\n<br><br>\n<b>Sunspots<\/b> are areas that appear dark on the surface of the Sun. They appear dark because they are cooler than other parts of the Sun\u2019s surface. The temperature of a sunspot is still very hot though \u2014 around 6,500 degrees Fahrenheit!<br>\nSunspots are used to keep track of the solar cycle. The solar cycle is the cycle that the Sun\u2019s magnetic field goes through approximately every 11 years.","cdf80400":"# Exploratory Data Analysis","812e3d87":"# Preparing Test and Val Data"}}