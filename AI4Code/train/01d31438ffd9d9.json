{"cell_type":{"c2a9e72e":"code","16c45787":"code","2ab5b03e":"code","0fd86687":"code","88e2f4de":"code","1662a658":"code","c479c12d":"code","36fdaa4e":"code","ed89ab69":"code","5195bd76":"code","67bc9ec1":"code","c3e204b1":"code","1bef85fc":"code","f4425d75":"code","81f85c6d":"code","15b9fcda":"code","047983d3":"code","fd1ea46c":"code","2dda3739":"code","b3e57372":"code","293c0a82":"code","284418fa":"code","75a8cb16":"code","686ebd15":"code","84780c2d":"code","3d2672e8":"code","8c90309c":"code","0ecae07c":"code","ad95ad97":"code","6b97ce5a":"code","176b1e13":"code","1aab7fea":"code","46346e7b":"code","b672daa1":"code","336139b7":"code","436b3698":"code","2a650d7a":"code","4992e192":"code","9c38274c":"code","b880eeab":"code","054088ad":"code","16201c7a":"code","e5572fb5":"code","cec40698":"code","d376192a":"code","69038c99":"markdown","b33c62fe":"markdown","58375cc8":"markdown","0617b55c":"markdown","010d88c7":"markdown","5843ba63":"markdown"},"source":{"c2a9e72e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","16c45787":"import seaborn as sns\nimport matplotlib.pyplot as plt\nsns.set()\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.metrics import classification_report\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.utils import resample\n\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping","2ab5b03e":"df = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')","0fd86687":"df.info()","88e2f4de":"df.select_dtypes([object]).columns","1662a658":"df['Attrition_Flag'].unique()","c479c12d":"del df['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1']","36fdaa4e":"del df['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2']","ed89ab69":"del df['CLIENTNUM']","5195bd76":"def perc_chur_cust(feature):\n    '''\n    This function calculates what percentage of people are churned based on just one feature.\n    \n    '''\n    df['x'] = 'a'\n    df['y'] = 'b'\n    a = df.groupby(feature).count()['x'].reset_index()\n    a.columns = [feature,'Total_Customers']\n    b = df.loc[df['Attrition_Flag'] == 'Attrited Customer'].groupby(feature).count()['y'].reset_index()\n    b.columns = [feature,'Total_Churned_Customers']\n    c = pd.merge(a,b)\n    del df['x']\n    del df['y']\n    c['perc_churned'] = c['Total_Churned_Customers'] \/ c['Total_Customers']\n    plt.xticks(rotation=90)\n    sns.barplot(c[feature],c['perc_churned'])\n    return c","67bc9ec1":"perc_chur_cust('Education_Level')","c3e204b1":"perc_chur_cust('Gender')","1bef85fc":"perc_chur_cust('Marital_Status')","f4425d75":"perc_chur_cust('Income_Category')","81f85c6d":"perc_chur_cust('Card_Category')","15b9fcda":"df.select_dtypes(['object']).columns","047983d3":"df = pd.get_dummies(df,columns=['Gender', 'Education_Level', 'Marital_Status','Income_Category', 'Card_Category'])","fd1ea46c":"X = df.drop(columns=['Attrition_Flag'])","2dda3739":"X.columns","b3e57372":"df['Attrition_Flag'] = df['Attrition_Flag'].apply(lambda x: 1 if x=='Attrited Customer' else 0)","293c0a82":"y = df['Attrition_Flag']","284418fa":"x_train,x_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=101)","75a8cb16":"scaler = MinMaxScaler()\nscaler.fit(x_train)\nscaled_x_train = scaler.transform(x_train)\nscaled_x_test = scaler.transform(x_test)","686ebd15":"scaled_x_train.shape","84780c2d":"forest = RandomForestClassifier(n_estimators=1000,random_state=1)","3d2672e8":"forest.fit(x_train,y_train)","8c90309c":"forest_pred_y = forest.predict(x_test)","0ecae07c":"model = Sequential()\n\nmodel.add(Dense(37,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(20,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy')\n\nearlystop = EarlyStopping(patience=25,verbose=1,monitor='val_loss',mode='min')","ad95ad97":"model.fit(scaled_x_train,\n         y_train,\n         batch_size=128,\n         epochs=550,\n         validation_data=(scaled_x_test,y_test),\n         callbacks=[earlystop])","6b97ce5a":"pd.DataFrame(model.history.history).plot()","176b1e13":"ANN_pred_y = model.predict_classes(scaled_x_test)","1aab7fea":"print('Classification Report of RandomForestClassifier')\nprint(classification_report(y_test,forest_pred_y))\nprint('Classification Report of ANN')\nprint(classification_report(y_test,ANN_pred_y))","46346e7b":"df = pd.read_csv('\/kaggle\/input\/credit-card-customers\/BankChurners.csv')","b672daa1":"del df['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_1']\ndel df['Naive_Bayes_Classifier_Attrition_Flag_Card_Category_Contacts_Count_12_mon_Dependent_count_Education_Level_Months_Inactive_12_mon_2']\ndel df['CLIENTNUM']","336139b7":"df.groupby('Attrition_Flag').count()['Customer_Age']","436b3698":"df_minority = df.loc[df['Attrition_Flag'] == 'Attrited Customer']\ndf_majority = df.loc[df['Attrition_Flag'] == 'Existing Customer']\n\ndf_minoriry_upscaled = resample(df_minority,replace=True,\n                               n_samples=8500,\n                               random_state=123)\n\ndf1 = pd.concat([df_minoriry_upscaled,df_majority]).reset_index(drop=True)\n\ndf1.info()","2a650d7a":"df1.select_dtypes('object').columns","4992e192":"df1 = pd.get_dummies(df1,columns=['Gender', 'Education_Level', 'Marital_Status',\n                                  'Income_Category', 'Card_Category'])\n\ndf1['Attrition_Flag'] = df1['Attrition_Flag'].apply(lambda x : 1 if x == 'Attrited Customer' else 0)","9c38274c":"X = df1.drop(columns=['Attrition_Flag'])\ny = df1['Attrition_Flag']\nxtrain,xtest,ytrain,ytest = train_test_split(X,y,test_size=0.3,random_state=101)","b880eeab":"scaler = MinMaxScaler()","054088ad":"scaler.fit(xtrain)\nxtrain_s = scaler.transform(xtrain)\nxtest_s = scaler.transform(xtest)","16201c7a":"model = Sequential()\n\nmodel.add(Dense(37,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(20,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(5,activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy')\n\nearlystop = EarlyStopping(patience=25,verbose=1,monitor='val_loss',mode='min')","e5572fb5":"model.fit(xtrain_s,ytrain,batch_size=128,\n         epochs=600,validation_data=(xtest_s,ytest),callbacks=[earlystop])","cec40698":"pred_y = model.predict_classes(xtest_s)","d376192a":"print(classification_report(ytest,pred_y))","69038c99":"This is an unbalanced dataset thats why forest algorithm is giving us better result.","b33c62fe":"Lets balance this dataset and train another ANN.","58375cc8":"This artificial neural network result is still not better than the forest algorithm but its better then the privious ANN.","0617b55c":"so the bank looses more female customers than male.\nThe bank has 5.8% more female account holders more than male,\nand the bank looses 2.7% more female accounts than male.","010d88c7":"********Well this is an interesting one, so the more educated the person is, the more likely he is to raise an Attrition Flag.","5843ba63":"# Resample and TensorFlow"}}