{"cell_type":{"9a8ea332":"code","899a69b7":"code","a799e8c1":"code","d12275b7":"code","cca13363":"code","275c5855":"code","488c7bc5":"code","02517e77":"code","c7247e18":"code","28046a76":"code","2e4f9ae6":"code","8536ada9":"code","e99681c6":"code","a1fc6d78":"code","bfb252de":"code","d6215318":"code","054b1da0":"code","fad31f0c":"code","9f6a69fc":"code","ff9706fd":"code","1024eb63":"markdown","d82f4f05":"markdown","3c2b5f53":"markdown","44e01861":"markdown","da7ad573":"markdown","27fe6f95":"markdown","bfe5d161":"markdown","727dfe56":"markdown","36ce591e":"markdown","d051f0cc":"markdown","2ebf78a9":"markdown","e70c4a23":"markdown","2cbeb1f2":"markdown","0d22a37e":"markdown","962b2618":"markdown","9a4429a3":"markdown","4b2ff911":"markdown"},"source":{"9a8ea332":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt \nfrom sklearn import manifold, datasets\nfrom sklearn.manifold import TSNE\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nimport seaborn as sns\nimport csv\nimport json\n\n\nsns.set_style('darkgrid') \n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# Any results you write to the current directory are saved as output.\ncredits=pd.read_csv('\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_credits.csv')\nmovies=pd.read_csv('\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv')\n# print(credits.shape) #(4803, 4)\n\ndel credits['title']\ndel movies['id']\nfull=pd.concat([credits,movies],axis=1)\nprint(full.shape) #the size of the dataframe","899a69b7":"full.info()  #show the information","a799e8c1":"full.head() #get the first 5 lines of the dataframe (full)","d12275b7":"sub0=full[['popularity','vote_average','release_date']]\nsub0.release_date=pd.to_datetime(sub0.release_date)\nsub0.release_date=sub0.release_date.dt.year\n#dorp the movies with NaN value of release_date\nsub0 = sub0[~sub0.release_date.isnull()] \nsub0 = sub0[~sub0.popularity.isnull()] \nsub0 = sub0[~sub0.vote_average.isnull()] \n# sub0=sub0[~sub0.popularity.str.isnumeric()]\n\n#float to int \nsub0.release_date = sub0.release_date.apply(int)\n\n\nplt.figure(figsize=(20, 10))\nsns.distplot(sub0.release_date)\nplt.show()","cca13363":"sns.relplot(x=\"release_date\", y=\"vote_average\", data= sub0, hue =\"popularity\",palette=\"ch:r=-.5,l=.75\",alpha=1,height=10)","275c5855":"# print(sub0.popularity.max())\ndelete=[875.581305,418.708552,434.278564,481.098624,514.569956,724.247784]\nsub0_1=sub0[~sub0['popularity'].isin(delete)]\nsns.relplot(x=\"release_date\", y=\"vote_average\", data= sub0_1, hue =\"popularity\",palette=\"ch:r=-.5,l=.75\",alpha=.4,height=10)","488c7bc5":"sub0_2=sub0[sub0['release_date']>= 2000] #after 2000 years\nsub0_2.release_date = sub0_2.release_date.apply(int)\nsns.relplot(x=\"release_date\", y=\"vote_average\", data= sub0_2, hue =\"popularity\",palette='Set3',sizes=(40,1000),alpha=1,height=8)","02517e77":"sub1=full[['budget','revenue','popularity','vote_average']]\nprint(sub1)\nplt.figure(figsize=(10, 10))\nprofit=sub1.revenue.values-sub1.budget.values\nvote_average=sub1.vote_average.values\npopularity=sub1.popularity.values\nprint(profit)\nprint(vote_average)\n# plt.scatter(profit, vote_average)\nplt.scatter(profit,popularity)\n#plt.scatter(sub1.revenue.values,sub1.popularity)\nplt.show()","c7247e18":"\nsub1=sub1[sub1['vote_average']>= 7] #vote>=7\nsns.relplot(x=\"revenue\", y=\"vote_average\", data= sub1,size =\"popularity\",sizes=(40,1000),palette=\"ch:r=-.5,l=.75\",alpha=.4,height=10)","28046a76":" def getcrew_job(x):\n    a=[]\n    for i in x:\n        a.append(i['job'])\n    return a\n\nsub2=full[['crew','vote_average']]\n#crew_dict=json.load(sub2.crew.values)\nprint(type(sub2.crew))\nsub2.crew=sub2.crew.apply(json.loads)\ncrew_job=sub2.crew.apply(getcrew_job)\nresult = crew_job.apply(pd.value_counts) #result is dataframe\nresult=result.fillna(0)  #substitute \"NaN\" to 0\nresult_top10=result.head(10) #just print the first 10 lines\nresult_top10['col_sum'] = result_top10.apply(lambda x: x.sum(), axis=1) #the sum of all crews and save it to col_sum\nprint(result_top10)","2e4f9ae6":"plt.figure(figsize=(50, 30))\nsns.heatmap(result_top10, annot=False, fmt=\".1f\")\nplt.show()","8536ada9":"def get_keywords(x):\n    a=[]\n    for i in x:\n        a.append(i['name'])\n    return a\n\nsub3=full[['keywords']]\nsub3.keywords=sub3.keywords.apply(json.loads)\nkeywords=sub3.keywords.apply(get_keywords)\nresult2 = keywords.apply(pd.value_counts) \n# result2.loc['Row_sum'] = result2.apply(lambda x: x.sum())\nresult2=result2.fillna(0)  #substitute \"NaN\" to 0\nresult2['Col_sum'] = result2.apply(lambda x: x.sum(), axis=1)\nresult_top10_2=result2.head(10)\nprint(result_top10_2)\nprint(result_top10_2.keys()) # get the colomn name","e99681c6":"sub4=full[['crew','keywords']]\nsub4.crew=sub4.crew.apply(json.loads)\nsub4.crew=sub4.crew.apply(getcrew_job)\nsub4.keywords=sub4.keywords.apply(json.loads)\nsub4.keywords=sub4.keywords.apply(get_keywords) # sub4.crew type: series\nresult4 = sub4.crew.apply(pd.value_counts) #result4 type: dataframe\n\nresult4=pd.concat([result4,sub4.keywords.apply(pd.value_counts)]) # combine two dataframes\nresult4=result4.fillna(0)  \nresult_top10_4=result4.head(10)\nprint(result_top10_4)\n","a1fc6d78":"tsne = manifold.TSNE(n_components=2, init='pca', random_state=501)\nresult4_tsne = tsne.fit_transform(result4)\nprint(\"Org data dimension is {}. Embedded data dimension is {}\".format(result4.shape[-1], result4_tsne.shape[-1]))","bfb252de":"print(type(result4_tsne))\nprint(result4_tsne)\nnp.save(\".\/result4_tsne.npy\",result4_tsne) # save as npy file","d6215318":"d=[]\nfor i in range(1,40):   #experiements on different value of k\n    km=KMeans(n_clusters=i,init='k-means++',n_init=10,max_iter=300,random_state=0)\n    km.fit(result4_tsne)\n    d.append(km.inertia_)  #inertia:Sum of squares of errors in clusters\n\nplt.plot(range(1,40),d,marker='o')\nplt.xlabel('number of clusters')\nplt.ylabel('distortions')\nplt.show()","054b1da0":"# kmeas clustering\n#from sklearn import metrics\nresult4_kmeans=KMeans(n_clusters=20,random_state=0)\nresult4_kmeans.fit(result4_tsne)\nresult4_pre=result4_kmeans.predict(result4_tsne)  #predict","fad31f0c":"# visualization of the clustering\ncenters=result4_kmeans.cluster_centers_ \nprint(centers)\ncolors=['#D0505D','#E1929A','#B4D1D9','#6194A7',\n        '#203643','#F6A945','#FEEB90','#Fd8732',\n        '#262F34','#6B3A7F',\"#006B89\",\"#978065\",\n        \"#3A281C\",\"#9b59b6\", \"#3498db\", \"#95a5a6\", \n        \"#e74c3c\", \"#34495e\", \"#2ecc71\",\"#9EC1E0\",'#131B1B']\nplt.figure(figsize=(10, 6))\nfor j in range(20):\n    index_set=np.where(result4_pre==j)\n    cluster=result4_tsne[index_set]\n    plt.scatter(cluster[:,0],cluster[:,1],c=colors[j],marker='.')  \n    plt.plot(centers[j][0],centers[j][1],'o',markerfacecolor=colors[j],markeredgecolor='k',markersize=8)  #\u753b\u7c7b\u522b\u4e2d\u5fc3\nplt.show()","9f6a69fc":"file_npy='.\/result4_tsne.npy'\nnp.load(file_npy)\n#print(np)\n#plt.plot(re[:,0],re[:,1])\n#plt.show()","ff9706fd":"current_palette=sns.color_palette() \n#the parameter is the name of the themes, and seaborn has six default themes(deep,muted,pastel,bright,dark,colorblind)\nsns.palplot(current_palette)\n\n#use your own color\nmycolor=['#D0505D','#E1929A','#B4D1D9','#6194A7',\n        '#203643','#F6A945','#FEEB90','#Fd8732']\nsns.palplot(sns.color_palette(mycolor))\n\nsns.palplot(sns.color_palette(\"Blues\"))\n# reverse:Blues_r \n\nsns.palplot(sns.cubehelix_palette(8))","1024eb63":"We use kmeans to cluster.","d82f4f05":"Then\uff0c we want to explore what is the revenue of the movies influence its popularity and vote_average.","3c2b5f53":"**The keywords of the movies:**","44e01861":"### 1.3 Json Data","da7ad573":"## 1. Data Exploration\n### 1.1 Basic Information","27fe6f95":"### 1.2 Matric Data","bfe5d161":"### 3.1 the color and the style","727dfe56":"First, we can drop the movies with NaN value of release_date, then use Seaborn to visualize the distribution of the movies with release_time.","36ce591e":"## 3. Some usage of Seaborn","d051f0cc":"## 2.Classify the type of movies\nJust combine the crews and the keywords as the features of the classifer.","2ebf78a9":"However, since the number of dimension is large, the heatmap had bad performance on showing the pattern of different types of movies. So we decide to deduce the dimensions.","e70c4a23":"In dataframe \"full\", there are some columns have matric data: movie_id, budget, released date,revenue,runtime,popularity,vote_average and vote_count.In this section, we will do some exploration about these data.","2cbeb1f2":"Then we use scatter diagram how the popularity and vote_average of movies changed according to the generation.","0d22a37e":"**The crews' job of the movies: **","962b2618":"Then we use TSNE to reduce the dimension to two dimension.","9a4429a3":"We explore the crew data and the keywords data, which may decide what type of the movies.\n","4b2ff911":"We narrow the scope to the movies after 2000 years."}}