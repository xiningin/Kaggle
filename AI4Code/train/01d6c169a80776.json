{"cell_type":{"f309b6b9":"code","315d8689":"code","8d91d3db":"code","32c2a92c":"code","97a166f7":"code","40638f59":"code","3802c3b0":"code","e6836f9f":"code","a4c8826f":"code","64481840":"code","20c5e99a":"code","ac017bcb":"code","249799bc":"code","b64ca6bd":"code","ac3745c7":"code","426fca4b":"code","671c136c":"code","f0876535":"code","1efe356a":"code","a6c0efde":"code","f040e1e1":"code","7c2e6107":"code","e2ffbdc1":"code","3c122abf":"code","2fcbd3f5":"code","72629c7a":"code","85b957e5":"code","dfd74493":"markdown","933c863a":"markdown","0617e719":"markdown","8f88ce2f":"markdown","a752f2f9":"markdown","a15014fa":"markdown","398835be":"markdown","01631cf2":"markdown","ab9d56a2":"markdown"},"source":{"f309b6b9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra \nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport datetime\nfrom sklearn import preprocessing\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","315d8689":"train_df = pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/train.csv')\ntest_df = pd.read_csv('..\/input\/seoul-bike-rental-ai-pro-iti\/test.csv')","8d91d3db":"train_df.info()\ntrain_df.shape","32c2a92c":"train_df.head(5)","97a166f7":"train_df.isnull().any()","40638f59":"plt.subplots(figsize=(15,15))\nsns.heatmap(train_df.corr(), mask=np.zeros_like(train_df.corr(), dtype=bool),\n            square=True, annot=True)\nplt.show()","3802c3b0":"i = 1\nplt.figure(figsize = [20, 20], tight_layout = 5)\nfor column in train_df.drop(['y'], axis=1).columns:\n    plt.subplot(6, 4, i)\n    plt.scatter(data = train_df, x = column, y = 'y', c='c', edgecolors='black')\n    plt.xlabel(column)\n    plt.ylabel('Bikes Count')\n    plt.title(column + ' VS ' + 'Bikes Count')\n    i += 1\nplt.show()","e6836f9f":"ig,ax=plt.subplots(figsize=(5,5))\nsns.barplot(data=train_df,x='Seasons',y='y')\nax.set_title('Rented_bikes Vs Seasons')\nplt.show()","a4c8826f":"ig,ax=plt.subplots(figsize=(5,5))\nsns.barplot(data=train_df,x='Functioning Day',y='y')\nax.set_title('Rented_bikes Vs Functioning Day')\nplt.show()","64481840":"ig,ax=plt.subplots(figsize=(5,5))\nsns.barplot(data=train_df,x='Holiday',y='y')\nax.set_title('Rented_bikes Vs Holidays')\nplt.show()","20c5e99a":"# ig,ax=plt.subplots(figsize=(5,5))\n# sns.barplot(data=train_df,x='Year',y='y')\n# ax.set_title('Rented_bikes Vs year')\n# plt.show()","ac017bcb":"train_df.var()","249799bc":"train_df","b64ca6bd":"def clean_data(df):\n    \n# Get Date in seperate columns \n    \n    df[[\"Day\", \"Month\", \"Year\"]] = df['Date'].astype(str).str.split(\"\/\", expand = True)\n    \n   \n   \n #get dummies for the categorical data\n\n    df = pd.get_dummies(df, prefix=['Functioning Day'], columns=['Functioning Day'])\n    \n    df['Seasons'] = df[\"Seasons\"].map({'Spring' :1 , 'Summer':2 , 'Autumn':3 , 'Winter':4}).astype('category')\n    df['Holiday'] = df[\"Holiday\"].map({'No Holiday' : 0, 'Holiday':1})\n\n    \n    df['Day'] = df['Day'].astype(int)\n    df['Month'] = df['Month'].astype(int)\n    df['Year'] = df['Year'].astype(int)\n\n    \n#scale the data \n\n    from sklearn.preprocessing import StandardScaler\n\n    ss = StandardScaler() \n    df['Visibility (10m)']=ss.fit_transform(df['Visibility (10m)'].values.reshape(-1, 1))\n    df['Temperature(\ufffdC)']=ss.fit_transform(df['Temperature(\ufffdC)'].values.reshape(-1, 1))\n    df['Hour']=ss.fit_transform(df['Hour'].values.reshape(-1, 1))\n    df['Day']=ss.fit_transform(df['Day'].values.reshape(-1, 1))\n    df['Month']=ss.fit_transform(df['Month'].values.reshape(-1, 1))\n    df['Humidity(%)']=ss.fit_transform(df['Humidity(%)'].values.reshape(-1, 1))\n    \n#get weekdays\n    \n    df['Date'] = pd.to_datetime(df.Date, format='%d\/%m\/%Y')\n    df['day_of_week'] = df['Date'].dt.dayofweek\n    \n\n#get day and night hourse\n    \n    c=[]\n    for i in df['Hour']:\n\n        if i>= 6 or i<= 18 :\n            c.append(\"Day\")\n        else:\n            c.append(\"Night\")\n    df['DayorNight']=c\n    df['DayorNight']=pd.factorize(df['DayorNight'])[0]\n    c=[]\n    \n    \n    \n#     for dataset in df:\n    \n#         df['Rainfall_bin'] = 0\n#         df.loc[df['Rainfall(mm)'] >0 , 'Rainfall_bin'] = 1\n\n#         df['Snowfall_bin'] = 0\n#         df.loc[df['Snowfall (cm)'] >0 , 'Snowfall_bin'] = 1\n\n    \n# #add wind chill feature\n\n#     df['Wind speed (km\/h)'] = df['Wind speed (m\/s)']\/3.6\n\n#     df['Wind chill']=0\n#     df['Wind chill']=0\n    \n    \n#     index=df.index[(df['Temperature(\ufffdC)']<=0) & (df['Wind speed (km\/h)']>0) & (df['Wind speed (km\/h)']<5)]\n#     for i in index:\n#         df.iloc[i,-1]=df.iloc[i,4] + ((-1.59+0.1345 * df.iloc[i,4])\/5) * df.iloc[i,6]\n    \n   \n    \n    return df","ac3745c7":"final_train = clean_data(train_df)\n\ny_target = np.log1p(train_df['y'])\ny_target = pd.DataFrame(y_target)\n\n\n\ndef from_C_to_F(temp):\n    return ((temp * (9\/5))+32)\n\nfinal_train[\"Dew(F)\"]= final_train[\"Dew point temperature(\ufffdC)\"].apply(from_C_to_F)\nfinal_train[\"temp(F)\"] = final_train[\"Temperature(\ufffdC)\"].apply(from_C_to_F)\n\n\nfinal_train[\"comfort\"] = final_train[\"temp(F)\"]\nfor i in range(len(final_train[\"temp(F)\"])) :\n    if final_train[\"temp(F)\"][i] >= 70 and final_train[\"Dew(F)\"][i]>= 70:\n        final_train[\"comfort\"][i] = 2#\"Uncomfort sticky\"\n        \n    elif 65<= final_train[\"temp(F)\"][i] <= 80 and final_train[\"Dew(F)\"][i] <50:\n        final_train[\"comfort\"][i] = 5 #\"Comfort\"\n        \n    elif final_train[\"temp(F)\"][i] > 80 :\n        final_train[\"comfort\"][i] = 3#\"Uncomfort Hot\"\n        \n    elif final_train[\"temp(F)\"][i] <= 60 :\n        final_train[\"comfort\"][i] = 1#\"Uncomfort cold\"\n        \n    else :\n        final_train[\"comfort\"][i] = 4 #\"normal\"\n\nfrom sklearn.preprocessing import StandardScaler\n\nss = StandardScaler() \nfinal_train['Dew(F)']=ss.fit_transform(final_train['Dew(F)'].values.reshape(-1, 1))\n    \nfinal_train = final_train.drop(['ID' ,'Date','y' , 'Temperature(\ufffdC)' , 'Dew point temperature(\ufffdC)' ,'Dew(F)'],axis=1)\nfinal_train","426fca4b":"plt.subplots(figsize=(15,15))\nsns.heatmap(final_train.corr(), mask=np.zeros_like(final_train.corr(), dtype=bool),\n            square=True, annot=True)\nplt.show()","671c136c":"y_target","f0876535":"final_train.var()","1efe356a":"final_test = clean_data(test_df)\n\n\ndef from_C_to_F(temp):\n    return ((temp * (9\/5))+32)\n\nfinal_test[\"Dew(F)\"]= final_test[\"Dew point temperature(\ufffdC)\"].apply(from_C_to_F)\nfinal_test[\"temp(F)\"] = final_test[\"Temperature(\ufffdC)\"].apply(from_C_to_F)\n\n\nfinal_test[\"comfort\"] = final_test[\"temp(F)\"]\nfor i in range(len(final_test[\"temp(F)\"])) :\n    if final_test[\"temp(F)\"][i] >= 70 and final_test[\"Dew(F)\"][i]>= 70:\n        final_test[\"comfort\"][i] = 2#\"Uncomfort sticky\"\n        \n    elif 65<= final_test[\"temp(F)\"][i] <= 80 and final_test[\"Dew(F)\"][i] <50:\n        final_train[\"comfort\"][i] = 5 #\"Comfort\"\n        \n    elif final_test[\"temp(F)\"][i] > 80 :\n        final_test[\"comfort\"][i] = 3#\"Uncomfort Hot\"\n        \n    elif final_test[\"temp(F)\"][i] <= 60 :\n        final_test[\"comfort\"][i] = 1#\"Uncomfort cold\"\n        \n    else :\n        final_test[\"comfort\"][i] = 4 #\"normal\"\n\n\nfinal_test['Dew(F)']=ss.fit_transform(final_test['Dew(F)'].values.reshape(-1, 1))\n\n\nfinal_test = final_test.drop(['ID','Date', 'Temperature(\ufffdC)' , 'Dew point temperature(\ufffdC)' , 'temp(F)'] ,axis=1)\n\nfinal_test\n","a6c0efde":"final_test.var()","f040e1e1":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(final_train , y_target , train_size=0.5, test_size=0.5, random_state = 42)","7c2e6107":"# ! pip install lazypredict\n# from lazypredict.Supervised import LazyRegressor\n# reg = LazyRegressor(verbose=0, ignore_warnings=False, custom_metric=None)\n# models , predictions = reg.fit(x_train, x_val, y_train, y_val)\n\n# print(models) ","e2ffbdc1":"  \nfrom math import sqrt\ndef RMSLE(y_pred , y_actual):\n    n = y_pred.size \n    RMSLE = sqrt(((np.log(y_pred+1)-np.log(y_actual+1))**2).sum()\/n)\n    return RMSLE\n\n# print(\"The RMSLE on train is : \",RMSLE(y_train,y_train_predicted))\n# print(\"The RMSLE on Validation is : \",RMSLE(y_val,y_valid_predicted))","3c122abf":"from sklearn.ensemble import RandomForestRegressor\n\nRegressor = RandomForestRegressor( max_depth=None, random_state=3)\n\nRegressor = Regressor.fit(x_train, np.log1p(y_train))\n\ny_train_predicted_RG = np.exp(Regressor.predict(x_train)) #predict on train\ny_valid_predicted_RG = np.exp(Regressor.predict(x_val)) #predict on validation\n\ny_train_predicted_RG = y_train_predicted_RG[ : , np.newaxis]\ny_valid_predicted_RG = y_valid_predicted_RG[ : , np.newaxis]\n\n\n\nfrom math import sqrt\ndef RMSLE(y_pred , y_actual):\n    n = y_pred.size \n    RMSLE = sqrt(((np.log(y_pred+1)-np.log(y_actual+1))**2).sum()\/n)\n    return RMSLE\n\nfrom sklearn.metrics import make_scorer\nrmsle = make_scorer(RMSLE, greater_is_better=False)\n\n\n\nprint(\"RMSLE of train :\",RMSLE(y_train_predicted_RG, y_train))\nprint(\"RMSLE of validation:  \",RMSLE(y_valid_predicted_RG, y_val))\n\n","2fcbd3f5":"from sklearn.experimental import enable_hist_gradient_boosting\nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\n\nhgb = HistGradientBoostingRegressor(scoring=rmsle,early_stopping=True ,max_bins=164,learning_rate=0.3372666421413646,\n                                    max_depth=5,max_iter=24,max_leaf_nodes=20,random_state=253)\n\nhgb = hgb.fit(x_train, np.log1p(y_train))\n\n\n\n\ny_1 = np.exp(hgb.predict(x_train))-1\ny_pred_RF = np.exp(hgb.predict(x_val))-1\n\n# print(y_val.shape)\ny_pred_RF = y_pred_RF[ : , np.newaxis]\ny_1 = y_1[ : , np.newaxis]\n\n# print(y_pred_RF.shape)\n\nR = RMSLE(y_pred_RF , y_val)\nR1 = RMSLE(y_1 , y_train)\nprint(\" RMSLE of HGB Regressor TRAIN :\",R)\nprint(\"RMSLE of what model learn validation :\",R1)","72629c7a":"y_pred_test =  np.exp(np.exp(hgb.predict(final_test)))\nsubmission  = pd.DataFrame()\nsubmission['ID']=test_df['ID']\nsubmission[\"y\"]=y_pred_test.astype(int)\nsubmission.to_csv('submission.csv', index=False)","85b957e5":"submission","dfd74493":"**RandomForestRegressor**","933c863a":"**Prepare train data**","0617e719":"# Explore your data ","8f88ce2f":"# **Preprocessing**","a752f2f9":"**Prepare test data**","a15014fa":"##### **Submission**","398835be":"# **Split data**","01631cf2":"**LinearRegression**","ab9d56a2":"# **Model**"}}