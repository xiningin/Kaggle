{"cell_type":{"3beeb2b1":"code","70ec1290":"code","de38b3d5":"code","add8bd50":"code","dbad2e66":"code","644775ce":"code","e302c4bf":"code","e441848d":"code","69b0f7f9":"code","21548675":"code","75413e27":"code","54d67ddb":"code","5b526c98":"code","94089766":"code","39446d4e":"code","cdcd8ecc":"code","98a7a554":"code","e508b93c":"code","cca0ce4a":"code","408d72df":"code","6afb12bf":"code","03c15eb9":"code","45106311":"code","aa934e1b":"code","16183710":"code","b7edd53d":"code","2a00a7f6":"markdown","4dc21647":"markdown","1bde1f22":"markdown","70f39db0":"markdown","9cc900ab":"markdown","a378c3db":"markdown","fc1c5a41":"markdown","0421e658":"markdown","13c8cb32":"markdown","48455f6e":"markdown"},"source":{"3beeb2b1":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import optimizers\nfrom kaggle_datasets import KaggleDatasets","70ec1290":"#TPU Configurations\nAUTO = tf.data.experimental.AUTOTUNE\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    strategy = tf.distribute.get_strategy()\n\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\n\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\nprint(GCS_DS_PATH)","de38b3d5":"IMG_SIZE_h = 760 \nIMG_SIZE_w = 760\nBATCH_SIZE = 8*strategy.num_replicas_in_sync","add8bd50":"#Data Items\npath='..\/input\/plant-pathology-2020-fgvc7\/'\n\ntrain = pd.read_csv(path+'train.csv')\ntrain_id = train['image_id']\ntrain.pop('image_id')\n\ny_train = train.to_numpy().astype('float32')\ncategory_names = ['healthy','multiple_diseases','rust','scab']\nroot = 'images'\n\nimages_paths = [(os.path.join(GCS_DS_PATH,root,idee+'.jpg')) for idee in train_id]","dbad2e66":"#Train Test Split\nfrom sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val = train_test_split(images_paths,y_train,test_size=0.198,shuffle=True) ","644775ce":"def decode_image(filename, label=None, image_size=(IMG_SIZE_h, IMG_SIZE_w)):\n    bits = tf.io.read_file(filename)\n    image = tf.image.decode_jpeg(bits, channels=3)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    image = tf.image.resize(image, image_size)\n    \n    #convert to numpy and do some cv2 staff mb?\n    \n    if label is None:\n        return image\n    else:\n        return image, label\n\ndef data_augment(image, label=None, seed=5050):\n    image = tf.image.random_flip_left_right(image, seed=seed)\n    image = tf.image.random_flip_up_down(image, seed=seed)\n    image = tf.image.random_crop(image,size=[IMG_SIZE_h,IMG_SIZE_w,3],seed=seed )\n    image = tf.image.random_brightness(image,max_delta=0.5, seed=seed )\n           \n    if label is None:\n        return image\n    else:\n        return image, label","e302c4bf":"train_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices((x_train, y_train))\n    .map(decode_image, num_parallel_calls=AUTO)\n    .map(data_augment, num_parallel_calls=AUTO)\n    .repeat()\n    .shuffle(512)\n    .batch(BATCH_SIZE)\n    .prefetch(AUTO)\n    )","e441848d":"val_dataset = (tf.data.Dataset\n               .from_tensor_slices((x_val,y_val))\n               .map(decode_image,num_parallel_calls=AUTO)\n               .batch(BATCH_SIZE)\n               .cache()\n               .prefetch(AUTO)\n              )","69b0f7f9":"import keras.backend as K\nimport tensorflow as tf\n\ndef categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.25,ls=0.1,classes=4.0):\n    \"\"\"\n    Implementation of Focal Loss from the paper in multiclass classification\n    Formula:\n        loss = -alpha*((1-p)^gamma)*log(p)\n        y_ls = (1 - \u03b1) * y_hot + \u03b1 \/ classes\n    Parameters:\n        alpha -- the same as wighting factor in balanced cross entropy\n        gamma -- focusing parameter for modulating factor (1-p)\n        ls    -- label smoothing parameter(alpha)\n        classes     -- No. of classes\n    Default value:\n        gamma -- 2.0 as mentioned in the paper\n        alpha -- 0.25 as mentioned in the paper\n        ls    -- 0.1\n        classes     -- 4\n    \"\"\"\n    def focal_loss(y_true, y_pred):\n        # Define epsilon so that the backpropagation will not result in NaN\n        # for 0 divisor case\n        epsilon = K.epsilon()\n        # Add the epsilon to prediction value\n        #y_pred = y_pred + epsilon\n        #label smoothing\n        y_pred_ls = (1 - ls) * y_pred + ls \/ classes\n        # Clip the prediction value\n        y_pred_ls = K.clip(y_pred_ls, epsilon, 1.0-epsilon)\n        # Calculate cross entropy\n        cross_entropy = -y_true*K.log(y_pred_ls)\n        # Calculate weight that consists of  modulating factor and weighting factor\n        weight = alpha * y_true * K.pow((1-y_pred_ls), gamma)\n        # Calculate focal loss\n        loss = weight * cross_entropy\n        # Sum the losses in mini_batch\n        loss = K.sum(loss, axis=1)\n        return loss\n    \n    return focal_loss","21548675":"import tensorflow as tf\n\ndef outer_product(x):\n    #Einstein Notation  [batch,1,1,depth] x [batch,1,1,depth] -> [batch,depth,depth]\n    phi_I = tf.einsum('ijkm,ijkn->imn',x[0],x[1])\n    \n    # Reshape from [batch_size,depth,depth] to [batch_size, depth*depth]\n    phi_I = tf.reshape(phi_I,[-1,x[0].shape[3]*x[1].shape[3]])\n    \n    # Divide by feature map size [sizexsize]\n    size1 = int(x[1].shape[1])\n    size2 = int(x[1].shape[2])\n    phi_I = tf.divide(phi_I, size1*size2)\n    \n    # Take signed square root of phi_I\n    y_ssqrt = tf.multiply(tf.sign(phi_I),tf.sqrt(tf.abs(phi_I)+1e-12))\n    \n    # Apply l2 normalization\n    z_l2 = tf.nn.l2_normalize(y_ssqrt, axis=1)\n    return z_l2","75413e27":"from keras import backend as K\n\ndef f1(y_true, y_pred):\n    def recall(y_true, y_pred):\n        \"\"\"Recall metric.\n\n        Only computes a batch-wise average of recall.\n\n        Computes the recall, a metric for multi-label classification of\n        how many relevant items are selected.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        possible_positives = K.sum(K.round(K.clip(y_true, 0, 1)))\n        recall = true_positives \/ (possible_positives + K.epsilon())\n        return recall\n\n    def precision(y_true, y_pred):\n        \"\"\"Precision metric.\n\n        Only computes a batch-wise average of precision.\n\n        Computes the precision, a metric for multi-label classification of\n        how many selected items are relevant.\n        \"\"\"\n        true_positives = K.sum(K.round(K.clip(y_true * y_pred, 0, 1)))\n        predicted_positives = K.sum(K.round(K.clip(y_pred, 0, 1)))\n        precision = true_positives \/ (predicted_positives + K.epsilon())\n        return precision\n    precision = precision(y_true, y_pred)\n    recall = recall(y_true, y_pred)\n    return 2*((precision*recall)\/(precision+recall+K.epsilon()))","54d67ddb":"!pip install efficientnet","5b526c98":"import efficientnet.tfkeras as efn\nimport tensorflow as tf, tensorflow.keras.backend as K\nfrom tensorflow.keras.layers import Convolution2D,Activation,MaxPooling2D,Flatten,Dense,Dropout,Input,Reshape,Lambda\nfrom tensorflow.keras.models import Model,Sequential\nfrom tensorflow.keras import optimizers\nfrom keras.utils.vis_utils import plot_model\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau","94089766":"def get_model():\n    \n    input_tensor = Input(shape=(IMG_SIZE_h,IMG_SIZE_w,3))\n    \n    model1 = efn.EfficientNetB4(weights='imagenet', include_top=False, input_tensor=input_tensor,input_shape=(IMG_SIZE_h, IMG_SIZE_w, 3))\n    model2 = efn.EfficientNetB4(weights='noisy-student', include_top=False, input_tensor=input_tensor,input_shape=(IMG_SIZE_h, IMG_SIZE_w, 3))\n    \n    for i, layer in enumerate(model1.layers):\n        layer._name = 'model1_' + layer.name\n\n    last_layer1 = model1.get_layer('model1_top_conv')\n    last_output1 = last_layer1.output\n\n    for i, layer in enumerate(model2.layers):\n        layer._name = 'model2_' + layer.name\n\n    last_layer2 = model2.get_layer('model2_top_conv')\n    last_output2 = last_layer2.output\n    \n    \n    model1_ = Model(inputs=model1.input, outputs=last_output1)\n    model2_ = Model(inputs=model2.input, outputs=last_output2)\n   \n    \n    model1_.compile(Adam(lr=0.0003, decay=1e-3),loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0))\n    model2_.compile(Adam(lr=0.0003, decay=1e-3),loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0))\n    \n    d1=model1_.output\n    d2=model2_.output\n\n    bilinear = Lambda(outer_product, name='outer_product1')([d1,d2])\n    \n    predictions=Dense(4, activation='softmax', name='predictions')(bilinear)\n    model = Model(inputs=model1.input, outputs=predictions)\n\n    return model","39446d4e":"from tensorflow.keras.optimizers import Adam\nopt = Adam(lr=0.0003, decay=1e-3)\n\nwith strategy.scope():\n    model = get_model()\n\nmodel.compile(optimizer=opt, loss=categorical_focal_loss_with_label_smoothing(gamma=2.0, alpha=0.75, ls=0.125, classes=4.0),metrics=[f1,'categorical_accuracy'])","cdcd8ecc":"from tensorflow.keras.utils import plot_model\nplot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)","98a7a554":"history = model.fit(train_dataset,\n                    steps_per_epoch=y_train.shape[0]\/\/BATCH_SIZE,\n                    epochs=30,\n                    verbose=1,\n                    validation_data=val_dataset\n                    )\n#it will take some time to start training","e508b93c":"%matplotlib inline \n\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\n\n\nprint ('Matplotlib version: ', mpl.__version__) # >= 2.0.0\n\nval_f1 = history.history['val_f1']\nf1 = history.history['f1']\nepochs = range(len(f1))\n\ndf_categorical_accuracy = pd.DataFrame(val_f1, columns = ['val_f1']) \ndf_f1 = pd.DataFrame(f1, columns = ['f1'])\n\ndf_categorical_accuracy.to_csv('val_f1.csv')\ndf_f1.to_csv('f1.csv')","cca0ce4a":"f, ax = plt.subplots(figsize=(12,4)) # set the size that you'd like (width, height)\nplt.title('F1 Score')\nplt.ylabel('f1 score')\nplt.xlabel('Epochs')\nplt.plot(epochs,val_f1,label='Validation F1 Score')\nplt.plot(epochs, f1,label='Training F1 Score')\nplt.legend()\nplt.figure()\nplt.savefig('F1.png')\nplt.show()","408d72df":"path='..\/input\/plant-pathology-2020-fgvc7\/'\n\ntest = pd.read_csv(path+'test.csv')\ntest_id = test['image_id']\n\nroot = 'images'\nx_test = [(os.path.join(GCS_DS_PATH,root,idee+'.jpg')) for idee in test_id]","6afb12bf":"test_dataset = (\n    tf.data.Dataset\n    .from_tensor_slices(x_test)\n    .map(decode_image, num_parallel_calls=AUTO)\n    .batch(BATCH_SIZE)\n)","03c15eb9":"y_pred = model.predict(test_dataset,verbose=1)","45106311":"def save_results(y_pred):\n    \n    path='..\/input\/plant-pathology-2020-fgvc7\/'\n    test = pd.read_csv(path + 'test.csv')\n    test_id = test['image_id']\n\n    res = pd.read_csv(path+'train.csv')\n    res['image_id'] = test_id\n  \n    labels = res.keys()\n\n    for i in range(1,5):\n        res[labels[i]] = y_pred[:,i-1]\n\n    res.to_csv('submission.csv',index=False)\n  \n    print(res.head)","aa934e1b":"save_results(y_pred)","16183710":"model_json = model.to_json()\nwith open(\"Model.json\", \"w\") as json_file:\n    json_file.write(model_json)\n# serialize weights to HDF5\nmodel.save_weights(\"Model.h5\")","b7edd53d":"from tensorflow.keras.models import model_from_json\n\n# load json and create model\njson_file = open('Model.json', 'r')\nloaded_model_json = json_file.read()\njson_file.close()\nloaded_model = model_from_json(loaded_model_json)\n# load weights into new model\nloaded_model.load_weights(\"Model.h5\")\n# loaded_model.summary()","2a00a7f6":"#### iii)F1 Score","4dc21647":"### 2. Functions","1bde1f22":"#### i)Focal Loss + Label Smoothing","70f39db0":"### 1. Loading Dependencies and Dataset ","9cc900ab":"### 5. Testing and Saving Model ","a378c3db":"### 4. Training","fc1c5a41":"#### ii) BiLinear Layer (outer_product())","0421e658":"### 3. Model","13c8cb32":"\n## Bilinear EfficientNet with Focal Loss + Label Smoothing\n## Plant Pathology\n\n![Capture.PNG](attachment:Capture.PNG)\n\n---\n### **Problem Objectives:**    \n#### The aim of this challenge is to build a Generalised Model for the task of Image Classification. We have to also deal with Class Imbalance Problem and detect Fine Grained details which differentiates whether the leaf is diseased or Not.  \n \n### **Solution:**  \n    i) Image Classification: EfficientNet\n\n    ii) Class Imbalance and Generalization : Focal Loss + Label Smoothing\n\n    iii) Detect Fine Grain Details: Bilinear CNN  \n ---\n### Model: BiLinear EfficientNet with Focal Loss+ Label Smoothing \n![BiLinearModel.PNG](attachment:BiLinearModel.PNG)\n\n---\n### **Expriments and Results:**  \n    a) Selecting the Best and Efficient CNN Backbone (img size:380x380):\n![models1.png](attachment:models1.png)\n\n    b) Exprimenting with Loss Functions (img size:380x380):  \n![lossCompare.PNG](attachment:lossCompare.PNG)\n\n    c) Bilinear EffcientNet (img size:760x760):\n![LS_1.PNG](attachment:LS_1.PNG)\n![f1scores.png](attachment:f1scores.png)    \n \n---\n**References:**  \n[(1)   EfficientNet: Rethinking Model Scaling for Convolutional Neural Networks](http:\/\/https:\/\/arxiv.org\/abs\/1905.11946)  \n[(2)   Focal Loss for Dense Object Detection](https:\/\/arxiv.org\/abs\/1708.02002)  \n[(3)   Bilinear CNNs for Fine-grained Visual Recognition](https:\/\/arxiv.org\/abs\/1504.07889)  \n[(4)   Focal Loss Implementation](https:\/\/github.com\/aldi-dimara\/keras-focal-loss)  \n[(5)   Label Smoothing Explaination and Formulas](https:\/\/towardsdatascience.com\/what-is-label-smoothing-108debd7ef06)  \n[(6)   BiLinear CNN Implementation](https:\/\/medium.com\/@scorrea92\/bilinear-cnn-models-in-tensorflow-keras-801121cc8c4d)  \n\n---\n   \n**Contents of this Notebook**  \n    1. Loading Dependencies and Dataset  \n    2. Functions:  \n        i. Bilinear Function  \n        ii. Focal Loss + Label Smoothing   \n        iii. F1 Score Metrics  \n    3. Model  \n    4. Training  \n    5. Testing and Saving Model  \n    \n\n>  Note: The main purpose of this notebook is to implement the above mentioned Idea!\n","48455f6e":"This was one of the ideas I have used during my experimentation.  \n  \nApart from this I have tried various other things like:  \nDifferent CNN Models(B0,\u2026.B7),  \nDifferent image sizes,  \ndifferent Focal Loss parameters  \ndifferent Label Smoothing parameters  \nCombination of Focal + LS  \nVarious Augmentations  \nEarly Stopping  \nLate stopping  \nCombination of various CNNs as backbone for BiLinear CNN  \nAnd a combination of everything that worked.  \nFinally I submitted an ensemble of all my solutions which had a public score of greater than 0.970.  \n  \n> Congratulations for reading this far!   \n\n---"}}