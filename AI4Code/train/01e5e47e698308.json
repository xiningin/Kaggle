{"cell_type":{"c0b38af5":"code","fd81af66":"code","1732c65b":"code","83c3a567":"code","13e56f6c":"code","b64e03d7":"code","cbc67b33":"code","8a311e11":"code","e8329c5a":"code","c36bebd4":"code","5110cc43":"code","8c0bacb0":"code","1ece5981":"code","ebb8ab33":"code","071c3dad":"code","ade211d0":"code","2646e1b0":"code","ad6e8de7":"code","15019802":"code","e08339f4":"code","c88b61d1":"code","c65badea":"code","43ae22a6":"code","ab010fa9":"code","65146856":"code","a97e8108":"code","eada63cc":"code","08b9a36a":"markdown","fe1d35e0":"markdown","061f6749":"markdown","55c6b5fa":"markdown","c4440a20":"markdown","15d18a1c":"markdown","1e4a4689":"markdown","ff890bb4":"markdown"},"source":{"c0b38af5":"\nimport numpy as np # linear algebra\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# Comment this if the data visualisations doesn't work on your side\n%matplotlib inline\n\nplt.style.use('bmh')","fd81af66":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.linear_model import Ridge, Lasso\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV","1732c65b":"#data\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntrain=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\nsample=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')","83c3a567":"train.head()","13e56f6c":"train.info()","b64e03d7":"print(train['SalePrice'].describe())\nplt.figure(figsize=(9, 8))\nsns.distplot(train['SalePrice'], color='g', bins=100, hist_kws={'alpha': 0.4});","cbc67b33":"df_num = train.select_dtypes(include = ['float64', 'int64'])\n","8a311e11":"df_num_corr = df_num.corr()['SalePrice'][:-1] # -1 because the latest row is SalePrice\ngolden_features_list = df_num_corr[abs(df_num_corr) > 0.5].sort_values(ascending=False)\nprint(\"There are  {} strong correlated values with SalePrice:\\n{}\".format(len(golden_features_list), golden_features_list))","e8329c5a":"for i in range(0, len(df_num.columns), 5):\n    sns.pairplot(data=df_num,\n                x_vars=df_num.columns[i:i+5],\n                y_vars=['SalePrice'])","c36bebd4":"corr = df_num.drop('SalePrice', axis=1).corr() # \nplt.figure(figsize=(12, 10))\n\nsns.heatmap(corr[(corr >= 0.5) | (corr <= -0.4)], \n            cmap='jet', vmax=1.0, vmin=-1.0, linewidths=0.1,\n            annot=True, annot_kws={\"size\": 8}, square=True);","5110cc43":"quantitative_features_list = ['LotFrontage', 'LotArea', 'MasVnrArea', 'BsmtFinSF1', 'BsmtFinSF2', 'TotalBsmtSF', '1stFlrSF',\n    '2ndFlrSF', 'LowQualFinSF', 'GrLivArea', 'BsmtFullBath', 'BsmtHalfBath', 'FullBath', 'HalfBath',\n    'BedroomAbvGr', 'KitchenAbvGr', 'TotRmsAbvGrd', 'Fireplaces', 'GarageCars', 'GarageArea', 'WoodDeckSF', 'OpenPorchSF', \n    'EnclosedPorch', '3SsnPorch', 'ScreenPorch', 'PoolArea', 'MiscVal', 'SalePrice']\ndf_quantitative_values = train[quantitative_features_list]\ndf_quantitative_values.head()","8c0bacb0":"import operator\n\nindividual_features_df = []\nfor i in range(0, len(df_num.columns) - 1): # -1 because the last column is SalePrice\n    tmpDf = df_num[[df_num.columns[i], 'SalePrice']]\n    tmpDf = tmpDf[tmpDf[df_num.columns[i]] != 0]\n    individual_features_df.append(tmpDf)\n\nall_correlations = {feature.columns[0]: feature.corr()['SalePrice'][0] for feature in individual_features_df}\nall_correlations = sorted(all_correlations.items(), key=operator.itemgetter(1))\n","1ece5981":"golden_features_list = [key for key, value in all_correlations if abs(value) >= 0.5]\nprint(\"There are {} strongly correlated values with SalePrice:\\n{}\".format(len(golden_features_list), golden_features_list))","ebb8ab33":"features_to_analyse = [x for x in quantitative_features_list if x in golden_features_list]\nfeatures_to_analyse.append('SalePrice')","071c3dad":"categorical_features = [a for a in quantitative_features_list[:-1] + train.columns.tolist() if (a not in quantitative_features_list[:-1]) or (a not in train.columns.tolist())]\ndf_categ = train[categorical_features]\n#fetching categorical variables","ade211d0":"df_categ","2646e1b0":"df_not_num = df_categ.select_dtypes(include = ['O'])\nprint('There is {} non numerical features including:\\n{}'.format(len(df_not_num.columns), df_not_num.columns.tolist()))","ad6e8de7":"X_train=train.drop(columns=['SalePrice'])\nY_train=train[['SalePrice']]","15019802":"num_feat=X_train.select_dtypes(include='number').columns.to_list()\ncat_feat=X_train.select_dtypes(exclude='number').columns.to_list()","e08339f4":"!pip install impyute","c88b61d1":"from impyute.imputation.cs import mice\n\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.preprocessing import PolynomialFeatures","c65badea":"num_pipe=Pipeline([\n    ('imputer',SimpleImputer(strategy='mean')),\n    ('scaler', StandardScaler())\n])\n\ncat_pipe=Pipeline([\n    ('imputer',SimpleImputer(strategy='most_frequent')),\n    ('encoder', OneHotEncoder(handle_unknown='ignore'))\n])","43ae22a6":"ct=ColumnTransformer(remainder='drop',\n                    transformers=[\n                        ('numeric', num_pipe, num_feat),\n                        ('categorical', cat_pipe, cat_feat)\n                    ])\nmodel=Pipeline([\n    ('transformer',ct),\n    ('poly',PolynomialFeatures(2)),\n    ('predictor', Lasso())\n])","ab010fa9":"model.fit(X_train, Y_train)\n","65146856":"print(model.score(X_train, Y_train))\n","a97e8108":"def submission(test, model):\n    y_pred=model.predict(test)\n    sample['SalePrice']=y_pred\n    date=pd.datetime.now().strftime(format='%d_%m_%Y_%H-%M_')\n    sample.to_csv(f'\/kaggle\/working\/{date}result.csv',index=False)","eada63cc":"submission(test,model)","08b9a36a":"![](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRVYQKCyIGvHTNjxk4gmbnDI0lezi3oZmsenFKnAYnj15g1qM4z&usqp=CAU)","fe1d35e0":"**Chi square test for categorical varibales ?**","061f6749":"**take time to explore data_description.txt **","55c6b5fa":"**Let's perform some crazy eda**","c4440a20":"> Let's build a heatmap for correlation btw variables","15d18a1c":"**training a pipeline for linear regression as data contains highly correlated data and data follows gaussian distribution**","1e4a4689":"**Predicting sale prices for houses, even stranger ones. And what\u2019s up with that basement?**","ff890bb4":"**getting highlt related variables**"}}