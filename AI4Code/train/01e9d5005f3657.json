{"cell_type":{"471957d1":"code","f5c17221":"code","1a0a4246":"code","dc4dbb3d":"code","65ff8970":"code","455ae97d":"code","87a8b577":"code","5ebcd484":"code","d2b1d110":"code","638dab35":"code","5358b6a3":"code","81ea528b":"code","d118c4b9":"code","466230fe":"code","f8591abe":"code","ade46ea2":"code","1f9cf43a":"code","e0114093":"code","8acdc045":"code","7a1a2b43":"code","b44898e5":"code","50500a7b":"markdown","a416421a":"markdown","a361d16e":"markdown","75842825":"markdown","770151d5":"markdown","704f61ac":"markdown","0739a3a7":"markdown","14413f38":"markdown","01b3284f":"markdown","2a762259":"markdown","e68a4796":"markdown","22851a4f":"markdown","219dc871":"markdown","d31d630b":"markdown","f46cb79b":"markdown","49be45bd":"markdown","bb633cd7":"markdown","b47f2257":"markdown","028fbbf2":"markdown","06c27ac5":"markdown","9ae774d5":"markdown"},"source":{"471957d1":"import numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport matplotlib.pyplot as plt\n%matplotlib inline","f5c17221":"data = pd.read_csv(\"..\/input\/diabetes.csv\")\ndata.head()","1a0a4246":"data.shape","dc4dbb3d":"sns.countplot(x=\"Outcome\", data= data)\nplt.show()","65ff8970":"X = data.drop(\"Outcome\", axis = 1)\ny = data[\"Outcome\"]","455ae97d":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=20, test_size=0.2)","87a8b577":"from sklearn.linear_model import LogisticRegression\n\n# instantiate the model (using the default parameters)\nlogreg = LogisticRegression()\n\n# fit the model with data\nlogreg.fit(X_train,y_train)\n\n# store the predictions\ny_pred=logreg.predict(X_test)","5ebcd484":"from sklearn import metrics\ncf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncf_matrix","d2b1d110":"sns.heatmap(pd.DataFrame(cf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","638dab35":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","5358b6a3":"y_pred_proba = logreg.predict_proba(X_test)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.show()","81ea528b":"from sklearn.feature_selection import RFE\n\n# feature extraction\nmodel = LogisticRegression()\nrfe = RFE(model, 5)\nfit = rfe.fit(X_train, y_train)\nprint(\"Num Features: \", fit.n_features_)\nprint(\"Selected Features: \",  fit.support_)\nprint(\"Feature Ranking: \", fit.ranking_)","d118c4b9":"X_train_f = X_train[[\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"BMI\", \"DiabetesPedigreeFunction\"]]\nX_test_f  = X_test[[\"Pregnancies\", \"Glucose\", \"BloodPressure\", \"BMI\", \"DiabetesPedigreeFunction\"]]\n\n# store the predictions\nlogreg.fit(X_train_f,y_train)\n\n# store the predictions\ny_pred=logreg.predict(X_test_f)","466230fe":"cf_matrix = metrics.confusion_matrix(y_test, y_pred)\ncf_matrix","f8591abe":"sns.heatmap(pd.DataFrame(cf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","ade46ea2":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","1f9cf43a":"y_pred_proba = logreg.predict_proba(X_test_f)[::,1]\nfpr, tpr, _ = metrics.roc_curve(y_test,  y_pred_proba)\nauc = metrics.roc_auc_score(y_test, y_pred_proba)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.show()","e0114093":"#Grid Search\nfrom sklearn.model_selection import GridSearchCV\nclf = LogisticRegression()\ngrid_values = {'penalty': ['l1', 'l2'],'C':[0.001,.009,0.01,.09,1,5,10,25]}\ngrid_clf = GridSearchCV(clf, param_grid = grid_values,scoring = 'recall')\ngrid_clf.fit(X_train, y_train)\n\n#Predict values based on new parameters\ny_pred = grid_clf.predict(X_test)\n\n# New Model Evaluation metrics \nprint('Accuracy Score : ' + str(metrics.accuracy_score(y_test,y_pred)))\nprint('Precision Score : ' + str(metrics.precision_score(y_test,y_pred)))\nprint('Recall Score : ' + str(metrics.recall_score(y_test,y_pred)))","8acdc045":"#Logistic Regression (Grid Search) Confusion matrix\ncf_matrix = metrics.confusion_matrix(y_test,y_pred)\ncf_matrix","7a1a2b43":"sns.heatmap(pd.DataFrame(cf_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\nplt.show()","b44898e5":"fpr, tpr, _ = metrics.roc_curve(y_test,  y_pred)\nauc = metrics.roc_auc_score(y_test, y_pred)\nplt.plot(fpr,tpr,label=\"data 1, auc=\"+str(auc))\nplt.legend(loc=4)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.show()","50500a7b":"**The Recursive Feature Elimination** (or RFE) works by recursively removing attributes and building a model on those attributes that remain.\nIt uses the model accuracy to identify which attributes (and combination of attributes) contribute the most to predicting the target attribute.","a416421a":"**The metric we need to focus on to reduce false negatives is Recall.**","a361d16e":"Let's evaluate the model using model evaluation metrics such as accuracy, precision, and recall.","75842825":"The hyperparameters we tuned are:\n\n    Penalty: l1 or l2 which species the norm used in the penalization.\n    C: Inverse of regularization strength- smaller values of C specify stronger regularization.","770151d5":"**RFE** chose the the top 5 features as Pregnancies, Glucose, BloodPressure, BMI, DiabetesPedigreeFunction.","704f61ac":"### Build Model and prediction","0739a3a7":"### Data exploration","14413f38":"A confusion matrix is a table that is used to evaluate the performance of a classification model. ","01b3284f":"### Recursive Feature Elimination","2a762259":"* Looking at the misclassified instances, we can observe that 27 Diabetes cases have been classified incorrectly as Non-Diabetes (False negatives).\n\n* A false negative is more serious as a disease has been ignored, which can lead to the death of the patient. At the same time, a false positive would lead to an unnecessary treatment\u200a\u2014\u200aincurring additional cost.\n\n* Let\u2019s try to minimize the false negatives by using Grid Search to find the optimal parameters. Grid search can be used to improve any specific evaluation metric.","e68a4796":"Precision: Precision is about being precise, i.e., how accurate your model is. In other words, you can say, when a model makes a prediction, how often it is correct. \n\nRecall: If there are patients who have diabetes in the test set and your Logistic Regression model can identify it 50% of the time.","22851a4f":"* AUC score for this case is **0.7677** with just 5 variables\n* AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier.","219dc871":"* AUC score for the case is **0.766**\n* AUC score 1 represents perfect classifier, and 0.5 represents a worthless classifier.","d31d630b":"### Grid SearchCV","f46cb79b":"### ROC Curve","49be45bd":"## Feature Engineering","bb633cd7":"### Model Evaluation using Confusion Matrix","b47f2257":"### Import data","028fbbf2":"### Import packages","06c27ac5":"**Now the misclassified instances reduce to 24 Diabetes cases that classified incorrectly as Non-Diabetes (False negatives).**","9ae774d5":"### Split the dataset"}}