{"cell_type":{"826f5a81":"code","73d5bbf0":"code","e52762f8":"code","d973b74d":"code","8f9390f9":"code","9ea128fd":"code","cf7378ce":"code","3900e501":"code","ce145a79":"code","3a9cc9f5":"code","87e94b3b":"code","62286bf6":"code","16e38258":"code","59ff0d64":"code","13c71c31":"code","b9a50c33":"code","c5a72067":"code","d0864f2b":"code","08c6bd9d":"code","fa9e5534":"code","030341e4":"markdown"},"source":{"826f5a81":"import numpy as np # linear algebra\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix","73d5bbf0":"from keras.utils.np_utils import to_categorical # convert to one-hot-encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler","e52762f8":"train_file = \"..\/input\/train.csv\"\ntest_file = \"..\/input\/test.csv\"\noutput_file = \"submission.csv\"","d973b74d":"raw_data = np.loadtxt(train_file, skiprows=1, dtype='int', delimiter=',')\nx_train, x_val, y_train, y_val = train_test_split(\n    raw_data[:,1:], raw_data[:,0], test_size=0.1)","8f9390f9":"fig, ax = plt.subplots(2, 1, figsize=(12,6))\nax[0].plot(x_train[0])\nax[0].set_title('784x1 data')\nax[1].imshow(x_train[0].reshape(28,28), cmap='gray')\nax[1].set_title('28x28 data')","9ea128fd":"x_train = x_train.reshape(-1, 28, 28, 1)\nx_val = x_val.reshape(-1, 28, 28, 1)","cf7378ce":"x_train = x_train.astype(\"float32\")\/255.\nx_val = x_val.astype(\"float32\")\/255.","3900e501":"y_train = to_categorical(y_train)\ny_val = to_categorical(y_val)\n#example:\nprint(y_train[0])","ce145a79":"model = Sequential()\nmodel.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='tanh', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Conv2D(filters = 128, kernel_size = (3, 3), activation='tanh', input_shape = (28, 28, 1)))\nmodel.add(BatchNormalization())\nmodel.add(MaxPool2D(strides=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(10, activation='softmax'))\n\nmodel.summary()","3a9cc9f5":"datagen = ImageDataGenerator(zoom_range = 0.1,\n                            height_shift_range = 0.1,\n                            width_shift_range = 0.1,\n                            rotation_range = 10)","87e94b3b":"model.compile(loss='categorical_crossentropy', optimizer = Adam(lr=1e-4), metrics=[\"accuracy\"])","62286bf6":"annealer = LearningRateScheduler(lambda x: 1e-3 * 0.9 ** x)","16e38258":"hist = model.fit_generator(datagen.flow(x_train, y_train, batch_size=16),\n                           steps_per_epoch=500,\n                           epochs=10, #Increase this when not on Kaggle kernel\n                           verbose=2,  #1 for ETA, 0 for silent\n                           validation_data=(x_val[:400,:], y_val[:400,:]), #For speed\n                           callbacks=[annealer])","59ff0d64":"final_loss, final_acc = model.evaluate(x_val, y_val, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_acc))","13c71c31":"plt.plot(hist.history['loss'], color='b')\nplt.plot(hist.history['val_loss'], color='r')\nplt.show()\nplt.plot(hist.history['acc'], color='b')\nplt.plot(hist.history['val_acc'], color='r')\nplt.show()","b9a50c33":"y_hat = model.predict(x_val)\ny_pred = np.argmax(y_hat, axis=1)\ny_true = np.argmax(y_val, axis=1)\ncm = confusion_matrix(y_true, y_pred)\nprint(cm)","c5a72067":"mnist_testset = np.loadtxt(test_file, skiprows=1, dtype='int', delimiter=',')\nx_test = mnist_testset.astype(\"float32\")\nx_test = x_test.reshape(-1, 28, 28, 1)\/255.","d0864f2b":"y_hat = model.predict(x_test, batch_size=64)","08c6bd9d":"y_pred = np.argmax(y_hat,axis=1)","fa9e5534":"with open(output_file, 'w') as f :\n    f.write('ImageId,Label\\n')\n    for i in range(len(y_pred)) :\n        f.write(\"\".join([str(i+1),',',str(y_pred[i]),'\\n']))","030341e4":"## CNN Activation\nIn this book, I design and test all the experimental CNN models. To design my models, I use the python programming language. To perform the experimental review I use three different datasets, those are- Sign Language MNIST, Digit-Recognizer MNIST, and Skin Cancer MNIST. \nI use 10 epochs for the experimental fold. For the experimental purpose, I use one fold for each model. In this experiment, I used a total of twenty-seven similar types of CNN models. \nIn this book, I analyze the performances of the CNN models for the different activation functions. After analyzing the results, I recommend the activation functions based on the performances for the convolutional layer in neural networks. \nThe goal of this experiment is to help the developer to get a clear concept of the activation functions for the convolutional layers of the networks. "}}