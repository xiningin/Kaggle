{"cell_type":{"02cd2c8c":"code","8bbc2cf4":"code","c331d8cb":"code","920d1f43":"code","6c35d8e5":"code","8bd61acb":"code","3cd48f97":"code","494a012f":"code","6a81dcb2":"code","d42b187a":"code","78558aaa":"code","d9f4cdeb":"code","42d35857":"code","c62d754c":"code","cd8030f5":"code","3090a83b":"code","c5b82ab0":"code","21bcf4fb":"markdown","a530d46d":"markdown","2230786c":"markdown","bb1625cf":"markdown","c33f4bfe":"markdown","dd8cdc78":"markdown"},"source":{"02cd2c8c":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","8bbc2cf4":"import numpy as np\nimport pandas as pd\nfrom math import sqrt\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.ensemble import VotingRegressor\nfrom sklearn.feature_selection import VarianceThreshold\nfrom sklearn.metrics import make_scorer, mean_squared_error\nfrom sklearn.model_selection import GridSearchCV, ParameterGrid, train_test_split\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import FunctionTransformer, StandardScaler","c331d8cb":"RANDOM_STATE = 2021\nCROSS_VALIDATION = 3","920d1f43":"data_dir = '\/kaggle\/input\/tabular-playground-series-jan-2021'","6c35d8e5":"df = pd.read_csv(f\"{data_dir}\/train.csv\").set_index('id').convert_dtypes()  #.sample(frac=0.01)\ndisplay(df.shape)\ndf.head(2)","8bd61acb":"X = df.copy()\ny = X.pop('target')\nX_train, X_valid, y_train, y_valid = train_test_split(\n    X, y, train_size=0.8, test_size=0.2, random_state=RANDOM_STATE,\n)","3cd48f97":"preprocessor = Pipeline(steps=[\n    ('imputer', SimpleImputer()),\n    ('log', FunctionTransformer(np.log1p)),\n    ('scaler', StandardScaler()),\n])","494a012f":"pipeline = Pipeline([\n    ('preprocessor', preprocessor),\n    ('variance_drop', VarianceThreshold(threshold=(0.95 * (1 - 0.95)))),\n    ('voting', 'passthrough'),\n])","6a81dcb2":"# For efficency running with minimal parameters.\n# The parameters here is just for an example.\nparameters = [\n    {\n        'voting': [VotingRegressor([\n            ('lgbm', LGBMRegressor(random_state=RANDOM_STATE)),\n            ('xgb', XGBRegressor(random_state=RANDOM_STATE))\n        ])],\n        \n        # LGBM\n        'voting__lgbm__n_estimators': [2000], # range(500, 3000, 1000),\n        'voting__lgbm__max_depth': [12], # range(4, 16, 4),\n        'voting__lgbm__learning_rate': [0.01],\n        'voting__lgbm__num_leaves': [256],\n        'voting__lgbm__min_child_weight': [12],\n        'voting__lgbm__feature_fraction': [0.4],  # np.arange(0.1, 1, 0.1),\n        'voting__lgbm__bagging_fraction': [0.7],  # np.arange(0.1, 1, 0.1),\n        'voting__lgbm__bagging_freq': [5],\n        'voting__lgbm__min_child_samples': [32],\n        'voting__lgbm__lambda_l1':[9],\n        'voting__lgbm__lambda_l2': [0.13],               \n        \n        # XGBM\n        'voting__xgb__n_estimators': [2000],  # range(500, 3000, 1000),\n        'voting__xgb__max_depth': [12],  # range(4, 16, 4),\n        'voting__xgb__learning_rate': [0.01],\n        'voting__xgb__alpha': [5],\n        'voting__xgb__gamma': [3],\n        'voting__xgb__lambda': [3],\n        'voting__xgb__subsample': [0.8],\n        'voting__xgb__colsample_bytree': [0.4],\n    }\n]","d42b187a":"total = CROSS_VALIDATION * len(ParameterGrid(parameters))\ndisplay(f\"Number of combination that will be run by the GridSearch: {total}\")","78558aaa":"custom_scoring = make_scorer(\n    score_func=lambda y, y_pred: mean_squared_error(y, y_pred, squared=False),\n    greater_is_better=False,\n)","d9f4cdeb":"grid_search = GridSearchCV(\n    pipeline,\n    param_grid=parameters,\n    cv=CROSS_VALIDATION,\n    scoring=custom_scoring,\n    n_jobs=-1,\n    verbose=True,\n)","42d35857":"grid_search.fit(X_train, y_train)","c62d754c":"display(abs(grid_search.best_score_))\ndisplay(grid_search.best_params_)","cd8030f5":"preds = grid_search.best_estimator_.predict(X_valid)\nmean_squared_error(y_valid, preds, squared=False)","3090a83b":"X_test = pd.read_csv(f\"{data_dir}\/test.csv\").set_index('id').convert_dtypes()\ndisplay(X_test.shape)\nX_test.head(2)","c5b82ab0":"preds_test = grid_search.best_estimator_.predict(X_test)\noutput = pd.DataFrame(\n    {'Id': X_test.index, 'target': preds_test})\noutput.to_csv(f\"submission.csv\", index=False)","21bcf4fb":"Check our model on the validation data.","a530d46d":"**Create Pipeline with following steps.**  \n**'preprocessor'**: preprocessor pipeline.  \n**'variance_drop'**: removes all low-variance features.  \n**'voting'**: `passthrough` the models will come later on.","2230786c":"**Split the data.**  \n80% for train and 20% for test.","bb1625cf":"**Preprocessor pipeline.**  \n**'imputer'**: filling nan with the default imputer 'mean'.  \n**'log'**: transform all features with log.  \n**'scalar'**: standardize features with z = (x - mean) \/ std.  ","c33f4bfe":"**Prepare parameters for GridSearch**  \n**'voting'**: voting regressor with `LGBM` and `XGB`.  ","dd8cdc78":"# Submission"}}