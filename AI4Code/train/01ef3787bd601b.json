{"cell_type":{"2683a51a":"code","9226e8b5":"code","6de6e45a":"code","06eb3ad5":"code","e8c9d475":"code","205588ee":"code","74c0b951":"code","6f9cf545":"code","6569b485":"code","9cd84306":"code","acac5e01":"code","d1f24b28":"code","269b588e":"code","d163e83b":"markdown","37d67df0":"markdown","1c4458cf":"markdown","ca901d3d":"markdown","ada6b572":"markdown","7e840931":"markdown","c7b1d696":"markdown","15bbd02f":"markdown"},"source":{"2683a51a":"import pandas as pd\nimport numpy as np\nimport json\nimport pyarabic.araby as araby\nimport matplotlib.pyplot as plt\nfrom nltk import word_tokenize\nfrom nltk.stem.isri import ISRIStemmer\nfrom nltk.corpus import stopwords\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.svm import SVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix, classification_report","9226e8b5":"lines = open('..\/input\/arb-egy-cmp-corpus\/ar_arz_wiki_corpus.json').readlines()\nwiki_df = pd.DataFrame([json.loads(line) for line in lines])","6de6e45a":"wiki_df.info()","06eb3ad5":"wiki_df['label'].value_counts().plot(kind='bar', rot=0)","e8c9d475":"labels_encode = {'ar': 0, 'arz': 1}\n\ndef encode_label(label):\n    return labels_encode[label]\n# End Func\n\ndef decode_label(code):\n    return [k for k, v in labels_encode.items() if v == code][0]\n# End Func\n\ndef cleanArabicText(sentence):\n    st = ISRIStemmer()\n    words = word_tokenize(sentence)\n    stopwords_list = stopwords.words('arabic')\n    words = [st.stem(araby.strip_diacritics(w)) for w in words if araby.strip_diacritics(w) not in stopwords_list]\n    return ' '.join(words)\n# End of Func","205588ee":"wiki_df['text_cleaned'] = wiki_df['text'].apply(cleanArabicText)","74c0b951":"X = wiki_df['text_cleaned'].values\ny = wiki_df['label'].apply(encode_label).values","6f9cf545":"tfidf_vec = TfidfVectorizer()\nX_vals = tfidf_vec.fit_transform(X)","6569b485":"X_train, X_test, y_train, y_test = train_test_split(X_vals, y, test_size=0.33, random_state=42)","9cd84306":"clf_nb = MultinomialNB()\nclf_nb.fit(X_train, y_train)\nnb_y_predict = clf_nb.predict(X_test)","acac5e01":"print(f'Accuracy: {accuracy_score(nb_y_predict, y_test)}')\nplot_confusion_matrix(clf_nb, X_test, y_test, display_labels=labels_encode.keys(), values_format='d')\nplt.title('Confusion Matrix')\nplt.show()\nprint(f'Classification Report: \\n{classification_report(nb_y_predict, y_test, target_names=labels_encode.keys())}')","d1f24b28":"clf_svm = SVC()\nclf_svm.fit(X_train, y_train)\nsvm_y_predict = clf_svm.predict(X_test)","269b588e":"print(f'Accuracy: {accuracy_score(svm_y_predict, y_test)}')\nplot_confusion_matrix(clf_svm, X_test, y_test, display_labels=labels_encode.keys(), values_format='d')\nplt.title('Confusion Matrix')\nplt.show()\nprint(f'Classification Report: \\n{classification_report(svm_y_predict, y_test, target_names=labels_encode.keys())}')","d163e83b":"Split the data to train and test","37d67df0":"### Using Naive Bayes","1c4458cf":"Transform the text data using TFIDF","ca901d3d":"Prepare the data for transformation step","ada6b572":"load the text data from the json file","7e840931":"### Using SVM","c7b1d696":"Load the data for modeling phase","15bbd02f":"Check the classes balance for the dataset"}}