{"cell_type":{"aa43dd85":"code","bb5cb234":"code","293c5eb9":"code","9ca2ead7":"code","eec45469":"code","ba77e4ed":"code","4f643fb8":"code","a6953158":"code","3d51addf":"code","772fc28b":"code","ad3cf62f":"code","97b6170c":"code","ef1d4d61":"code","11f8d5fc":"code","130784b8":"markdown","3073c61a":"markdown","d5761b43":"markdown","a7c603eb":"markdown","bf44d663":"markdown","8cc32a67":"markdown","001ad0cb":"markdown","1a37a922":"markdown","ccf555c9":"markdown","62b58c42":"markdown","8d249ecd":"markdown","ae470f2e":"markdown","d5253d23":"markdown"},"source":{"aa43dd85":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns #data visualization\nimport matplotlib.pyplot as plt\n\ndef concat_sets(train_data, test_data):\n    # Returns a concatenated df of training and test set\n    return pd.concat([train_data, test_data], sort=True).reset_index(drop=True)\n\nsns.set_style(\"whitegrid\")\n\ntrain_path = '\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv'\ntest_path = '\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv'\n\ntrain_data = pd.read_csv(train_path,index_col='Id')\ntest_data = pd.read_csv(test_path,index_col='Id')\nall_data = concat_sets(train_data, test_data)\n\ntrain_data.name = 'Training Set'\ntest_data.name = 'Test Set'\nall_data.name = 'All Set' \n\ny = train_data['SalePrice']\n\n# Dataset shape analysis\nprint('Number of Training Examples = {}'.format(train_data.shape[0]))\nprint('Number of Test Examples = {}\\n'.format(test_data.shape[0]))\nprint('Training X Shape = {}'.format(train_data.shape))\nprint('Training y Shape = {}\\n'.format(train_data['SalePrice'].shape[0]))\nprint('Test X Shape = {}'.format(test_data.shape))\nprint('Test y Shape = {}\\n'.format(test_data.shape[0]))\n\n\n# print(train_data.columns)\n# print(test_data.columns)\n\n#get column data types\nprint(train_data.info())\nprint(test_data.info())\n","bb5cb234":"def get_missing(df):\n    missing = []\n    for col in df.columns.tolist():\n        if df[col].isnull().sum() > 0:\n            missing.append({'column':col,'count':df[col].isnull().sum()})\n    return pd.DataFrame(missing)\n\ndfs = [train_data,test_data]\nfor df in dfs:\n    print('{}'.format(df.name))\n    missing = get_missing(df)\n    print(missing.sort_values(by='count',ascending=False))","293c5eb9":"categorical_cols = [cname for cname in train_data.columns if\n                    train_data[cname].nunique() < 10 and \n                    train_data[cname].dtype == \"object\"]\n\nprint(\"Categorical cols:\",categorical_cols)\n\n# Select numerical columns\nnumerical_cols = [cname for cname in train_data.columns if \n                train_data[cname].dtype in ['int64', 'float64']]\n\nprint(\"\\n Numerical cols:\",numerical_cols)","9ca2ead7":"s_min = train_data['SalePrice'].min()\ns_max = train_data['SalePrice'].max()\n\nsns.histplot(data=train_data,x='SalePrice',stat='count',bins=10,kde=True).set_title(\"Sale Price analysis\")","eec45469":"#fig, axes = plt.subplots(nrows=len(numerical_cols),ncols=2)\nfor i,col in enumerate(numerical_cols):\n    if col != 'SalePrice':\n        fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(16,6))\n        ax = sns.regplot(data=train_data,x=col,y='SalePrice',ax=axes[0])\n        ax = sns.histplot(data=train_data,x=col,ax=axes[1],bins=20,kde=True)\n        plt.show()","ba77e4ed":"sns.heatmap(data=train_data.corr()).set_title(\"Numeric variables correlation\")","4f643fb8":"print(train_data['MSZoning'].unique())\nfig, axes = plt.subplots(nrows=1,ncols=2,figsize=(16,6))\nax = sns.countplot(data=train_data,x='MSZoning',order=['RL', 'RM', 'RH','FV', 'C (all)'],ax = axes[0])\nax.set_title(\"Total of houses by Zoning\")\nzone_sp = train_data.groupby('MSZoning').agg(mean_sp=('SalePrice','mean')).reset_index()\nprint(zone_sp)\nax = sns.barplot(data=zone_sp,x='MSZoning',y='mean_sp',order=['RL', 'RM', 'RH','FV', 'C (all)'],ax=axes[1])\nax.set_title(\"Mean of house price by Zoning\")","a6953158":"fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(16,6))\nax = sns.countplot(data=train_data,x='OverallQual',ax = axes[0])\nax.set_title(\"Total of houses by Overall Quality\")\nqual_sp = train_data.groupby('OverallQual').agg(mean_sp=('SalePrice','mean')).reset_index()\nax = sns.barplot(data=qual_sp,x='OverallQual',y='mean_sp',ax=axes[1])\nax.set_title(\"Mean of house price by Overall Quality\")","3d51addf":"fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(16,6))\nax = sns.histplot(data=train_data,x='LotArea',stat='count',bins=10,ax = axes[0],log_scale=True)\nax.set_title(\"Total of houses by Lot Area\")\n\nax = sns.kdeplot(data=train_data,x='LotArea',y='SalePrice',ax=axes[1],shade=True)\nax.set_xlim(-5000,25000)\nax.set_ylim(0,500000)\nax.set_title(\"Mean of house price by Lot Area\")","772fc28b":"fig, axes = plt.subplots(nrows=1,ncols=2,figsize=(16,6))\nax = sns.countplot(data=train_data,x='BldgType',ax = axes[0])\nax.set_title(\"Total of houses by Building Type\")\nbldg_sp = train_data.groupby('BldgType').agg(mean_sp=('SalePrice','mean')).reset_index()\nprint(zone_sp)\nax = sns.barplot(data=bldg_sp,x='BldgType',y='mean_sp',ax=axes[1])\nax.set_title(\"Mean of house price by Building Type\")","ad3cf62f":"print(train_data['ExterCond'].unique())\nfig, axes = plt.subplots(nrows=1,ncols=2,figsize=(16,6))\nax = sns.countplot(data=train_data,x='ExterCond',ax = axes[0],order=['Ex','Gd' ,'TA','Fa','Po'])\nax.set_title(\"Total of houses by External condition\")\nextc_sp = train_data.groupby('ExterCond').agg(mean_sp=('SalePrice','mean')).reset_index()\nprint(zone_sp)\nax = sns.barplot(data=extc_sp,x='ExterCond',y='mean_sp',ax=axes[1],order=['Ex','Gd' ,'TA','Fa','Po'])\nax.set_title(\"Mean of house price by External condition\")","97b6170c":"from sklearn.model_selection import train_test_split\n#Copy to new dataframe\nmy_cols = categorical_cols + numerical_cols\n\nX = train_data[my_cols].copy()\nif 'SalePrice' in my_cols:\n    my_cols.remove('SalePrice')\nX_test = test_data[my_cols].copy()\n\n#Remove target variable\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X[\"SalePrice\"]\nX.drop(['SalePrice'], axis=1, inplace=True)\n\n#train test split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                                train_size=0.8, test_size=0.2,\n                                                                random_state=0)","ef1d4d61":"from sklearn.ensemble import RandomForestRegressor\n\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import mean_absolute_error\n\ndef score_dataset(model, X_train, X_valid, y_train, y_valid,params={}):\n    model.fit(X_train, y_train,**params)\n    preds = model.predict(X_valid)\n    return mean_absolute_error(y_valid, preds)\n\nmodel = RandomForestRegressor(n_estimators=50, max_depth=5, random_state=1)\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))\n])\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', categorical_transformer, categorical_cols)\n    ])\n\nreg = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('model', model)\n                     ])\n\n\nprint('MAE with RF One-hot encoding:', score_dataset(reg,X_train, X_valid,y_train,y_valid))\n\nreg.fit(X, y) \npredictions = reg.predict(X_test)\n\n# output = pd.DataFrame({\"Id\":X_test.index,\"SalePrice\":predictions})\n# output.to_csv('my_submission.csv', index=False) \n# print(\"Your submission was successfully saved!\")\n","11f8d5fc":"## XGBRegressor\nfrom xgboost import XGBRegressor\n\nmy_cols = categorical_cols + numerical_cols\n\nX = train_data[my_cols].copy()\nif 'SalePrice' in my_cols:\n    my_cols.remove('SalePrice')\nX_test = test_data[my_cols].copy()\n\n#Remove target variable\nX.dropna(axis=0, subset=['SalePrice'], inplace=True)\ny = X[\"SalePrice\"]\nX.drop(['SalePrice'], axis=1, inplace=True)\n\n#train test split\nX_train, X_valid, y_train, y_valid = train_test_split(X, y,\n                                                                train_size=0.8, test_size=0.2,\n                                                                random_state=0)\n\n# Keep selected columns only\n\n# One-hot encode the data (to shorten the code, we use pandas)\nX_train = pd.get_dummies(X_train)\nX_valid = pd.get_dummies(X_valid)\nX_test = pd.get_dummies(X_test)\nX_train, X_valid = X_train.align(X_valid, join='left', axis=1)\nX_train, X_test = X_train.align(X_test, join='left', axis=1)\n\nX = concat_sets(X_train,X_valid)\ny = concat_sets(y_train,y_valid)\n\n# Define the model\nmy_model_1 = XGBRegressor(n_estimators=1000,learning_rate=0.05) # Your code here\nprint('MAE with XGBoost:', score_dataset(my_model_1,X_train, X_valid,y_train,y_valid))\n\n\nmy_model_1.fit(X_train, y_train) \npredictions = my_model_1.predict(X_test)\n\noutput = pd.DataFrame({\"Id\":X_test.index,\"SalePrice\":predictions})\noutput.to_csv('my_submission.csv', index=False) \nprint(\"Your submission was successfully saved!\")","130784b8":"## XGBoost","3073c61a":"## Numerical vs Categorical columns\nLet's divide numerical columns from categorical columns and identify the first columns to start the analysis.\n\n","d5761b43":"## Missing values\nMissing values can be justified by the lack of a certain characteristic (Pool, Basement,Garage).\nLet's check it anyway","a7c603eb":"## Quality","bf44d663":"## Numerical columns\nWe can analyze all the numerical columns by plotting them out and using a regression line to find the feature that show a strong positive (or negative) correlation with Sale Price.\nWe can also see how values are distributed using an histogram.\n","8cc32a67":"## Sale Price","001ad0cb":"Here we can see some interesting features:\n* Surface: LotFrontage,LotArea, MasVnrArea, Basement Surface(Unfinished,Finished), Floor Surface(Ground,First,Second) all show a quite strong correlation with Sale Price.\n* Quality: The feature OverallQual is an ordinal feature and shows a strong correlation with Sale Price, while OverallCond does not show a strong trend in a bivariate analysis. This last feature will need a multivariate analysis in order to determine a correlation with SalePrice.\n* Time: The YearBuilt,YearRemodAdd and GarageYrBuilt features show a strong correlation, while the YrSold,MoSold do not show a particular trend.\n* Quantity: features counting the number of rooms, baths, Fireplaces and cars in garage show a strong correlation, but the number of KitchenAbvGrd feature shows a negative correlation! The distribution is highly skewed as few houses have more than one kitchen. This will need a more accurate analysis.","1a37a922":"## Zoning\nThe column MSZoning identifies the general zoning classification of the sale.\n\n* A Agriculture\n* C Commercial\n* FV Floating Village Residential\n* I Industrial\n* RH Residential High Density\n* RL Residential Low Density\n* RP Residential Low Density Park \n* RM Residential Medium Density\n\nLet's see how price changes between these categories\n","ccf555c9":"## Area\nBigger lots should be more expensive,right?\nThe distribution is highly skewed if we go back to the distribution plot, so it is not the best feature to use. ","62b58c42":"## External condition\nExterCond: Evaluates the present condition of the material on the exterior.\nA first impression could always count in the definition of the sale price.\nThis feature could be an ordinal categorical feature\n\n* Ex Excellent\n* Gd Good\n* TA Average\/Typical\n* Fa Fair\n* Po Poor","8d249ecd":"# Data Analysis","ae470f2e":"# Model\nAs a first approach, i will throw at the model all the columns that are reasonably usable using a Random Forest Model.","d5253d23":"## Building Type\nBldgType: Type of dwelling\n\n* 1Fam Single-family Detached\n* 2FmCon Two-family Conversion; originally built as one-family dwelling\n* Duplx Duplex\n* TwnhsE Townhouse End Unit\n* TwnhsI Townhouse Inside Unit"}}