{"cell_type":{"3bb0a413":"code","99d28002":"code","a90cbe6f":"code","d6585d25":"code","937bd2fe":"code","173aa654":"code","eb05e760":"code","037f00fe":"code","e7238181":"code","cd928045":"code","e128a70d":"code","9350d8fd":"code","cf5421ea":"code","2924b532":"code","b76ff3fc":"code","820fbfdc":"code","46ebbf19":"code","6ae9025c":"code","a72c170c":"code","97606dd3":"code","22b8df25":"code","72f9d7c6":"code","416c1e8e":"code","097d3854":"code","32f32c52":"code","f23216f1":"code","e35577a5":"code","ee67c77d":"code","bc506908":"code","a999216d":"code","a6f2d77a":"code","8ec723da":"code","d5ed8062":"markdown","1b2cc257":"markdown","13b292d6":"markdown","9bdd0335":"markdown","fea9207e":"markdown","15d29282":"markdown","d37083e4":"markdown","19aeed5b":"markdown","6ccfb151":"markdown","c895df84":"markdown","b0878248":"markdown","218f264e":"markdown","f98d08f7":"markdown","e5255a64":"markdown","05790811":"markdown","3d6a5d5a":"markdown","32e7dfbe":"markdown","f31d79cd":"markdown","b3897e4d":"markdown","3e28bb83":"markdown","434a2c8e":"markdown","f98fe7bc":"markdown","05a841d1":"markdown","c670860d":"markdown","84fd3e1c":"markdown","b87b0c9e":"markdown","e3642efb":"markdown","7bb88483":"markdown","1f83e05b":"markdown","9af02f98":"markdown","bafb82a9":"markdown","6aedea04":"markdown","eea06358":"markdown","091a0232":"markdown","09a07d59":"markdown","54576736":"markdown","9e9ea0d9":"markdown","3d8eb0e7":"markdown","c0f2f214":"markdown","63a08045":"markdown","b320278d":"markdown","5ce108c0":"markdown","e911f5fd":"markdown","af199025":"markdown","0188c16e":"markdown"},"source":{"3bb0a413":"import numpy as np #Numpy is meant for mathematical operations\nimport pandas as pd #Pandas allows Data Manipulation and analysis \nimport matplotlib.pyplot as plt #Visual representations\nimport seaborn as sns #Another visualization library that is more complex\nfrom sklearn import ensemble, tree, linear_model #Importing algorithms like Ensemble, Trees and Linear Regression\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold #Importing techniques that allow to split the dataset into train and test\nfrom sklearn.metrics import r2_score, mean_squared_error, make_scorer #Importing metrics that will allow to understand how good is our model\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LinearRegression, RidgeCV, LassoCV, ElasticNetCV\nfrom sklearn.utils import shuffle ","99d28002":"House_Data_train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\nHouse_Data_test = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')","a90cbe6f":"House_Data_train.head()","d6585d25":"House_Data_test.head()","937bd2fe":"House_Data_train.set_index('Id', inplace = True)\nHouse_Data_test.set_index('Id', inplace = True)","173aa654":"House_Data_train.shape,House_Data_test.shape","eb05e760":"House_Data_train.info()","037f00fe":"percent_missing = House_Data_train.isna().sum() * 100 \/ House_Data_train.shape[0]\nmissing_value_House_Data_train = pd.DataFrame({'Percent Missing': percent_missing})\n\nmissing_value_House_Data_train.sort_values('Percent Missing', inplace=True, ascending = False)\n\nmissing_value_House_Data_train.head(10)","e7238181":"House_Data_train.describe()","cd928045":"House_Data_train.describe(include='O')","e128a70d":"print(House_Data_train['SalePrice'].describe())\nplt.figure(figsize=(9, 8))\nsns.distplot(House_Data_train['SalePrice'], color='b', bins=100, hist_kws={'alpha': 0.4});","9350d8fd":"House_Data_train.SalePrice = np.log1p(House_Data_train.SalePrice)\ny = House_Data_train.SalePrice","cf5421ea":"plt.figure(figsize = (60,50))\nsns.heatmap(House_Data_train.corr(), annot=True)\nplt.show()","2924b532":"Correlation_Matrix = House_Data_train.corr()\nMost_Correlated_Features = Correlation_Matrix.index[abs(Correlation_Matrix[\"SalePrice\"])>0.5]\nplt.figure(figsize=(10,5))\ng = sns.heatmap(House_Data_train[Most_Correlated_Features].corr(),annot=True)","b76ff3fc":"sns.set()\nCorrelated_Columns = ['SalePrice', 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'GarageCars']\nsns.pairplot(House_Data_train[Correlated_Columns], height = 2)\nplt.show();","820fbfdc":"categorical_features = House_Data_train.select_dtypes(include=['object']).columns\ncategorical_features","46ebbf19":"numerical_features = House_Data_train.select_dtypes(exclude = [\"object\"]).columns\nnumerical_features = numerical_features.drop(\"SalePrice\")\nnumerical_features","6ae9025c":"print(\"Numerical features : \" + str(len(numerical_features)))\nprint(\"Categorical features : \" + str(len(categorical_features)))","a72c170c":"House_Data_train_Num = House_Data_train[numerical_features]\nHouse_Data_train_Cat = House_Data_train[categorical_features]","97606dd3":"House_Data_train_Num = House_Data_train_Num.fillna(House_Data_train_Num.median())","22b8df25":"from scipy.stats import skew \nskewness = House_Data_train_Num.apply(lambda x: skew(x))\nskewness.sort_values(ascending=False)","72f9d7c6":"skewness = skewness[abs(skewness)>1]\nskewness.index","416c1e8e":"skew_features = House_Data_train[skewness.index]","097d3854":"skew_features = np.log1p(skew_features)","32f32c52":"House_Data_train_Cat = pd.get_dummies(House_Data_train_Cat)\nHouse_Data_train_Cat.shape","f23216f1":"House_Data_train_Cat.head()","e35577a5":"House_Data_train = pd.concat([House_Data_train_Cat,House_Data_train_Num],axis=1)\nHouse_Data_train.shape","ee67c77d":"X_train,X_test,y_train,y_test = train_test_split(House_Data_train,y,test_size = 0.3,random_state= 0)","bc506908":"X_train.shape,X_test.shape,y_train.shape,y_test.shape","a999216d":"n_folds = 5\nscorer = make_scorer(mean_squared_error,greater_is_better = False)\ndef rmse_CV_train(model):\n    kf = KFold(n_folds,shuffle=True,random_state=42).get_n_splits(House_Data_train.values)\n    rmse = np.sqrt(-cross_val_score(model,X_train,y_train,scoring =\"neg_mean_squared_error\",cv=kf))\n    return (rmse)\ndef rmse_CV_test(model):\n    kf = KFold(n_folds,shuffle=True,random_state=42).get_n_splits(House_Data_train.values)\n    rmse = np.sqrt(-cross_val_score(model,X_test,y_test,scoring =\"neg_mean_squared_error\",cv=kf))\n    return (rmse)","a6f2d77a":"lr = LinearRegression()\nlr.fit(X_train,y_train)\ntest_pre = lr.predict(X_test)\ntrain_pre = lr.predict(X_train)\nprint('rmse on train',rmse_CV_train(lr).mean())\nprint('rmse on test',rmse_CV_test(lr).mean())","8ec723da":"plt.scatter(train_pre, train_pre - y_train, c = \"blue\",  label = \"Training data\")\nplt.scatter(test_pre,test_pre - y_test, c = \"black\",  label = \"Validation data\")\nplt.title(\"Linear regression\")\nplt.xlabel(\"Predicted values\")\nplt.ylabel(\"Residuals\")\nplt.legend(loc = \"upper left\")\nplt.hlines(y = 0, xmin = 10.5, xmax = 13.5, color = \"red\")\nplt.show()","d5ed8062":"### SalesPrice Distribution","1b2cc257":"In a similar fashion, variables 'TotalBsmtSF' and '1stFlrSF', 'GrLivArea' and 'TotRmsAbvGrd', 'GarageCars' and 'GarageArea' are highly correlated between themselves so we won't be analyzing the ones that have the least correlation with the dependent variable ('TotRmsAbvGrd', 'GarageArea')","13b292d6":"Here we can see that the houses with higher OverallQual tend to have higher sale prices, just like houses with 2 or 3 FullBaths also tend to be more expensive, for example.","9bdd0335":"Getting a first look into the Data:","fea9207e":"Here the same function is defined for the train and test datasets  where through the usage of a K=5 Fold validation where the datasets are partitioned into 5 equal sized subsamples","15d29282":"Missing values exist when there's data that isn't available to be analysed, because, for example a value might have not been captured or because a field might not apply to be answered by a specific customer.\n\nThere are many ways to deal with missing values like using models to understand which value should be inserted, imputing values using the average or mode, but in this case we will be using the median.","d37083e4":"With this it's possible to understand already some facts:\n- YearBuilt explains that the oldest house was built in 1872 and earliest in 2010;\n- The lowest SalePrice was 34.900\u20ac while the most expensive was 755.000\u20ac\n- The house that was sold the earliest was in 2006 and the most recent was in 2010;","19aeed5b":"From this we can understand that, 'OverallQual', 'YearBuilt', 'YearRemodAdd', 'TotalBsmtSF', '1stFlrSF', 'GrLivArea', 'FullBath', 'TotRmsAbvGrd', 'GarageCars', 'GarageArea' are all variables with a high correlation with the SalePrice, meaning that they are the most important features relatively to the target.","6ccfb151":"# EDA","c895df84":"### Importing all the necessary Libraries","b0878248":"Here we can see that both X and Y have the same amount of columns and that train and test have the same amount of observations.","218f264e":"- SalePrice - the property's sale price in dollars - target variable <br>\n- MSSubClass: The building class <br>\n- MSZoning: The general zoning classification <br>\n- LotFrontage: Linear feet of street connected to property <br>\n- LotArea: Lot size in square feet <br>\n- Street: Type of road access <br>\n- Alley: Type of alley access <br>\n- LotShape: General shape of property <br>\n- LandContour: Flatness of the property<br>\n- Utilities: Type of utilities available<br>\n- LotConfig: Lot configuration<br>\n- LandSlope: Slope of property<br>\n- Neighborhood: Physical locations within Ames city limits<br>\n- Condition1: Proximity to main road or railroad<br>\n- Condition2: Proximity to main road or railroad (if a second is present)<br>\n- BldgType: Type of dwelling<br>\n- HouseStyle: Style of dwelling<br>\n- OverallQual: Overall material and finish quality<br>\n- OverallCond: Overall condition rating<br>\n- YearBuilt: Original construction date<br>\n- YearRemodAdd: Remodel date<br>\n- RoofStyle: Type of roof<br>\n- RoofMatl: Roof material<br>\n- Exterior1st: Exterior covering on house<br>\n- Exterior2nd: Exterior covering on house (if more than one material)<br>\n- MasVnrType: Masonry veneer type<br>\n- MasVnrArea: Masonry veneer area in square feet<br>\n- ExterQual: Exterior material quality<br>\n- ExterCond: Present condition of the material on the exterior<br>\n- Foundation: Type of foundation<br>\n- BsmtQual: Height of the basement<br>\n- BsmtCond: General condition of the basement<br>\n- BsmtExposure: Walkout or garden level basement walls<br>\n- BsmtFinType1: Quality of basement finished area<br>\n- BsmtFinSF1: Type 1 finished square feet<br>\n- BsmtFinType2: Quality of second finished area (if present)<br>\n- BsmtFinSF2: Type 2 finished square feet<br>\n- BsmtUnfSF: Unfinished square feet of basement area<br>\n- TotalBsmtSF: Total square feet of basement area<br>\n- Heating: Type of heating<br>\n- HeatingQC: Heating quality and condition<br>\n- CentralAir: Central air conditioning<br>\n- Electrical: Electrical system<br>\n- 1stFlrSF: First Floor square feet<br>\n- 2ndFlrSF: Second floor square feet<br>\n- LowQualFinSF: Low quality finished square feet (all floors)<br>\n- GrLivArea: Above grade (ground) living area square feet<br>\n- BsmtFullBath: Basement full bathrooms<br>\n- BsmtHalfBath: Basement half bathrooms<br>\n- FullBath: Full bathrooms above grade<br>\n- HalfBath: Half baths above grade<br>\n- Bedroom: Number of bedrooms above basement level<br>\n- Kitchen: Number of kitchens<br>\n- KitchenQual: Kitchen quality<br>\n- TotRmsAbvGrd: Total rooms above grade (does not include bathrooms)<br>\n- Functional: Home functionality rating<br>\n- Fireplaces: Number of fireplaces<br>\n- FireplaceQu: Fireplace quality<br>\n- GarageType: Garage location<br>\n- GarageYrBlt: Year garage was built<br>\n- GarageFinish: Interior finish of the garage<br>\n- GarageCars: Size of garage in car capacity<br>\n- GarageArea: Size of garage in square feet<br>\n- GarageQual: Garage quality<br>\n- GarageCond: Garage condition<br>\n- PavedDrive: Paved driveway<br>\n- WoodDeckSF: Wood deck area in square feet<br>\n- OpenPorchSF: Open porch area in square feet<br>\n- EnclosedPorch: Enclosed porch area in square feet<br>\n- 3SsnPorch: Three season porch area in square feet<br>\n- ScreenPorch: Screen porch area in square feet<br>\n- PoolArea: Pool area in square feet<br>\n- PoolQC: Pool quality<br>\n- Fence: Fence quality<br>\n- MiscFeature: Miscellaneous feature not covered in other categories<br>\n- MiscVal: $Value of miscellaneous feature<br>\n- MoSold: Month Sold<br>\n- YrSold: Year Sold<br>\n- SaleType: Type of sale<br>\n- SaleCondition: Condition of sale","f98d08f7":"In this case we can see that we have plenty of variables that observe that phenomena.\n\nThis can be dealt with through the usage of square roots or log(x). The first will do it in a softer way while the latter will have a stronger effect.\n\nIn this case, I've decided to go with a log(x) approach.","e5255a64":"From this analysis it's also possible to know the following:\n- The most common type of Sale what of the type Warranty Deed - Conventional;\n- Most of the Sales were Sales that operated under the Normal Condition;","05790811":"Merging the Categorical and Numerical variables","3d6a5d5a":" Now we have 288 columns which are the combination of the 252 categorical columns and 36 numerical ones","32e7dfbe":"### Variable Description","f31d79cd":"### Dealing with Missing Values","b3897e4d":"With this, we have developed a Linear Regression in which the metric 'Root Mean Squared Error' is for the train dataset of 725 and for test of 0.22.\n\nRoot Mean Squared Error represents the sample standard deviation of differences between predicted values and the observed values, which is used to assess the predictor's performance.","3e28bb83":"### Importing Dataset","434a2c8e":"From this plot we can understand that although the mean (180.921) is very near the median value (163.000) [exhibiting right skewness], there are some clear outliers as we can see that the max value that the distribution assumes can go as far as 755.000\u20ac.","f98fe7bc":"### Dispersion statistics","05a841d1":"### Observing the Data Types of the variables","c670860d":"Since this is barely understandable, we will plot only the variables that have high correlations with the dependent variable:","84fd3e1c":"## Presentation\n\nHello guys, my name is Diogo and this is my first submission in Kaggle, so all feedback is welcome and I'd love if you encouraged me to keep up on practicing :) ","b87b0c9e":"Through plotting the residuals, or in a simpler language, the difference between the predicted value and the actual values, we can see that although there is a convergence of values with approximately 0 residuals (accurately predicted), there's also some  predictions that resulted in different values from the real ones.","e3642efb":"### Observing the relationship between the Most Correlated Features with the Dependent Variable","7bb88483":"### Understanding the amount of columns and observations in the datasets","1f83e05b":"### Grouping Numerical and Categorical Features","9af02f98":"There are a lot of missing values in these variables, but we will be dealing with this in a future step.","bafb82a9":"## Modeling","6aedea04":"As we can see, there are 2 datasets that are made available, one that is called 'train' and another one that is called 'test'.\nThere is a specific purpose of having two separate datasets:\n- With train we will be building the algorithm;\n- With the test dataset we will be able to evaluate the generalization capability of the algorithm that we have developed\n\nIt's also important to bear in mind that sometimes when we inject too much data for the algorithm to learn, it will overfit which will lead to a decrease of the errors made in the training dataset, but will increase the errors in the test dataset.","eea06358":"As we can see, there's 3 float variables, 34 integers and 43 objects","091a0232":"### Creating Dummy Variables","09a07d59":"### Understanding the Skewness","54576736":"The intention of this challenge is to predict the sales price for each house. The evaluation will be done by assessing the RMSE. \n\nI'd like to acknowledge @bsivavenu which has inspired much of the work presented in the notebook.","9e9ea0d9":"As it's possible to observe, there are 1460 observations in the train dataset and 1459 observations in the test dataset and 80 columns (variables) in the train and 79 in test. The difference in the columns is because the test dataset will not have the dependent variable (SalePrice)","3d8eb0e7":"All variables that observe a Skewness above 1 witness High Positive Skewness, meaning that their means are significantly higher than their median.","c0f2f214":"### Spliting the Dataset","63a08045":"### Creating the Target Variable before any data pre-processing","b320278d":"Making the 'Id' variable the index:","5ce108c0":"### Introduction to the Challenge","e911f5fd":"### Understanding Missing Values","af199025":"There are quite a few things that we can observe just by observing these lines of the datasets:\n- The column 'Id' is an unique identifier of each observation, which we can use as an index;\n- There are a lot of 'NaN' values in the datasets, like in 'Alley' and 'Fence' which stands for 'Not a Number'","0188c16e":"As explained previously, the train dataset will be used for building the model while the test will be used to evaluate the algorithm.\nThe X represents all the variables that are used to explain the behavior that is happening in the dependent variable (sale price - Y)\n\nAdditionally, we are using 70% of the dataset for training and 30% for test which is a best practice when we have datasets with low amounts of observations which is the case."}}