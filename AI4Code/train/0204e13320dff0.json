{"cell_type":{"7c2f0e1f":"code","d6d667c6":"code","8b87369e":"code","6d8e6e3d":"code","07be6625":"code","1b05fb95":"code","6553a383":"code","803349d7":"code","d01bf1c8":"code","a4d2045a":"code","ede009e3":"code","ee29bd90":"code","fe866f91":"code","ff6eae89":"code","ab6aed28":"code","bf494704":"code","0c21e19c":"code","be040547":"markdown","e16525b6":"markdown","73e226eb":"markdown","31ae5b60":"markdown","592a31e7":"markdown","ede8fa2a":"markdown","667176e3":"markdown"},"source":{"7c2f0e1f":"import pandas as pd\nimport numpy as np\nfrom skimage.io import imread\nimport matplotlib.pyplot as plt\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import accuracy_score, roc_auc_score\nfrom tqdm import tqdm\n\n# PyTorch libraries and modules\nimport torch\nfrom torch.autograd import Variable\nfrom torch.nn import Linear, ReLU, CrossEntropyLoss, Sequential, Conv2d, MaxPool2d, Module, Softmax, BatchNorm2d, Dropout, BCELoss\nfrom torch.optim import Adam, SGD","d6d667c6":"train = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/train.csv\")\ntest  = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/test.csv\")\ntest_path = '..\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'\ntrain_path = '..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'\nsample_submission = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')","8b87369e":"# loading training images\n\n#train_img = []\n#for img_name in tqdm(train['image_name']):\n    # defining the image path\n   # image_path = train_path + str(img_name) + '.jpg'\n    # reading the image\n  #  img = imread(image_path, as_gray=True)\n    # normalizing the pixel values\n  #  img \/= 255.0\n    # converting the type of pixel to float 32\n  #  img = img.astype('float32')\n    # appending the image into the list\n #   train_img.append(img)\n\n# converting the list to numpy array\n#train_x = np.array(train_img)\n\n# defining the target\ntrain_y = train['target'].values\ntrain_x = np.load((\"..\/input\/x-train\/x_train_32.npy\"))\ntrain_x.shape","6d8e6e3d":"# visualizing images\n\ni = 0\n\nplt.figure(figsize=(10,10))\nplt.subplot(221), plt.imshow(train_x[i])\nplt.subplot(222), plt.imshow(train_x[i+25])\nplt.subplot(223), plt.imshow(train_x[i+50])\nplt.subplot(224), plt.imshow(train_x[i+75])","07be6625":"# create validation set\n\ntrain_x, val_x, train_y, val_y = train_test_split(train_x, train_y, test_size = 0.2)\n(train_x.shape, train_y.shape), (val_x.shape, val_y.shape)","1b05fb95":"train_x = train_x.reshape(26500, 3, 32, 32)\ntrain_x  = torch.from_numpy(train_x)\n\n# converting the target into torch format\ntrain_y = train_y.astype(int);\ntrain_y = torch.from_numpy(train_y)\n\n# shape of training data\ntrain_x.shape, train_y.shape","6553a383":"val_x = val_x.reshape(6626, 3, 32, 32)\n\nval_x  = torch.from_numpy(val_x)\n\n# converting the target into torch format\nval_y = val_y.astype(int);\nval_y = torch.from_numpy(val_y)\n\n# shape of validation data\nval_x.shape, val_y.shape","803349d7":"## Setting the seed\n\nnp.random.seed(42)\ntorch.manual_seed(42)","d01bf1c8":"import torch.nn as nn\nimport torch.nn.functional as F\n\nclass Net(nn.Module):\n \n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(3, 6, 4)\n        self.conv2 = nn.Conv2d(6, 16, 3)\n        self.adapt = nn.AdaptiveMaxPool2d((5,7))\n        self.fc1 = nn.Linear(16*5*7, 120)\n        self.fc2 = nn.Linear(120, 84)\n        self.fc3 = nn.Sequential(nn.Linear(84, 2))\n                \n\n    def forward(self, x):\n        x = F.max_pool2d(F.relu(self.conv1(x.float())), (2, 2))\n        x = self.adapt(F.relu(self.conv2(x.float())))\n        x = x.view(-1, 16*5*7)\n        x = F.relu(self.fc1(x.float()))\n        x = F.relu(self.fc2(x.float()))\n        x = self.fc3(x.float())\n        return x","a4d2045a":"model = Net()\n# defining the optimizer\noptimizer = Adam(model.parameters(), lr=0.07)\n# defining the loss function\ncriterion = CrossEntropyLoss() # nn.BCEWithLogitsLoss()\n# checking if GPU is available\nif torch.cuda.is_available():\n    model = model.cuda()\n    criterion = criterion.cuda()\n    \nprint(model)","ede009e3":"def train(epoch):\n    model.train()\n    tr_loss = 0\n    \n    # getting the training set\n    x_train, y_train = Variable(train_x), Variable(train_y)\n    \n    # getting the validation set\n    x_val, y_val = Variable(val_x), Variable(val_y)\n    \n    # converting the data into GPU format\n    if torch.cuda.is_available():\n        x_train = x_train.cuda()\n        y_train = y_train.cuda()\n        x_val = x_val.cuda()\n        y_val = y_val.cuda()\n\n    # clearing the Gradients of the model parameters\n    optimizer.zero_grad()\n    \n    output_train = model(x_train)\n    output_val = model(x_val)\n\n    # computing the training and validation loss\n    \n    loss_train = criterion(output_train, y_train)\n    loss_val = criterion(output_val, y_val)\n    train_losses.append(loss_train)\n    val_losses.append(loss_val)\n\n    # computing the updated weights of all the model parameters\n    \n    loss_train.backward()\n    optimizer.step()\n    tr_loss = loss_train.item()\n    if epoch%2 == 0:\n        # printing the validation loss\n        print('Epoch : ',epoch+1, '\\t', 'loss :', loss_val)","ee29bd90":"# defining the number of epochs\n\nn_epochs = 11\n# empty list to store training losses\ntrain_losses = []\n# empty list to store validation losses\nval_losses = []\n# training the model\n#for epoch in range(n_epochs):\n #   train(epoch)\n    \n# plotting the training and validation loss\n\n#plt.plot(train_losses, label='Training loss')\n#plt.plot(val_losses, label='Validation loss')\n#plt.legend()\n#plt.show()","fe866f91":"#with torch.no_grad():\noutput = model(train_x)\n    \nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.detach().numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy on training set\nprint(accuracy_score(train_y, predictions))\nprint(roc_auc_score(train_y, predictions))","ff6eae89":"output = model(val_x)\n\nsoftmax = torch.exp(output).cpu()\nprob = list(softmax.detach().numpy())\npredictions = np.argmax(prob, axis=1)\n\n# accuracy on validation set\nprint(accuracy_score(val_y, predictions))\nprint(roc_auc_score(val_y, predictions))","ab6aed28":"# loading test images\n\ntest_img = []\n\n#for img_name in tqdm(test['image_name']):\n    # defining the image path\n #   image_path = test_path + str(img_name) + '.jpg'\n    # reading the image\n  #  img = imread(image_path, as_gray=True)\n    # normalizing the pixel values\n   # img \/= 255.0\n    # converting the type of pixel to float 32\n    #img = img.astype('float32')\n    # appending the image into the list\n    #test_img.append(img)\n\n# converting the list to numpy array\n#test_x = np.array(test_img)\n\ntest_x = np.load((\"..\/input\/x-test-32\/x_test_32.npy\"))\ntest_x.shape","bf494704":"# converting test images into torch format\n\ntest_x = test_x.reshape(10982, 3, 32, 32)\ntest_x  = torch.from_numpy(test_x)\ntest_x.shape","0c21e19c":"# generating predictions for test set\n\noutput = model(test_x)\n\n#softmax = torch.exp(output).cpu()\n#prob = list(softmax.detach().numpy())\n#predictions = np.argmax(prob, axis=1)\n\npreds = F.softmax(output)\npreds = preds[:, 0]\npreds = preds.detach().numpy()\nsample_submission['target'] = preds\nsample_submission.to_csv('sub_05.csv', index=False)","be040547":"### Training accuracy","e16525b6":"### Setting Optimizer and loss criterion","73e226eb":"### Validation accuracy","31ae5b60":"### Same preprocessing as train set ","592a31e7":"### Training the model","ede8fa2a":"### Basic CNN","667176e3":"### Reshaping test set"}}