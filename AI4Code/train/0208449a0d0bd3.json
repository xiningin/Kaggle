{"cell_type":{"4718d74a":"code","11853168":"code","bcd50713":"code","8c4e0172":"code","081de4d6":"code","ad3a6859":"code","647e9659":"code","23942beb":"code","7b44bafb":"code","bacd1bdf":"code","06b71c37":"code","8e159d70":"code","89fe9e47":"code","bfee763e":"code","18d5800c":"code","d9fdb2e2":"code","96edf31b":"code","78b75021":"code","fba5a1dd":"markdown","35b66edb":"markdown","fa747789":"markdown","0aaf1ddd":"markdown","35c430a6":"markdown","fa33541c":"markdown","fdd24df0":"markdown","77bc0215":"markdown","ee731f19":"markdown"},"source":{"4718d74a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))","11853168":"train = pd.read_csv('..\/input\/sales_train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsubmission = pd.read_csv('..\/input\/sample_submission.csv')\nitems = pd.read_csv('..\/input\/items.csv')\nitem_cats = pd.read_csv('..\/input\/item_categories.csv')\nshops = pd.read_csv('..\/input\/shops.csv')","bcd50713":"train.describe()","8c4e0172":"test.describe()","081de4d6":"submission.describe()","ad3a6859":"train.head(50).T","647e9659":"train['date'].describe()","23942beb":"'''\ntrain['date'] = pd.to_datetime(train.date)\ntrain = train.sort_values(by='date')\n'''","7b44bafb":"train.tail(50).T","bacd1bdf":"train_oct2015 = train.loc[train['date_block_num'] == 33]","06b71c37":"train_oct2015.head()","8e159d70":"df_m = train_oct2015.groupby([\"shop_id\", \"item_id\"])\nmonth_sum = df_m.aggregate({\"item_cnt_day\":np.sum}).fillna(0)\nmonth_sum.reset_index(level=[\"shop_id\", \"item_id\"], inplace=True)\nmonth_sum = month_sum.rename(columns={ month_sum.columns[2]: \"item_cnt_month\" })\nmonth_sum.describe()","89fe9e47":"submission.describe()","bfee763e":"month_sum['item_id'].value_counts()","18d5800c":"test['item_id'].value_counts()","d9fdb2e2":"new_submission = pd.merge(month_sum, test, how='right', left_on=['shop_id','item_id'], right_on = ['shop_id','item_id']).fillna(0)\nnew_submission.drop(['shop_id', 'item_id'], axis=1)\nnew_submission = new_submission[['ID','item_cnt_month']]","96edf31b":"new_submission['item_cnt_month'] = new_submission['item_cnt_month'].clip(0,20)\nnew_submission.describe()","78b75021":"new_submission.to_csv('previous_value_benchmark.csv', index=False)","fba5a1dd":"The current score is quite horrible, at 8.53027. Let's try to clip the values within [0,20] as per the tip from the course.","35b66edb":"Seems like the training set and testing set consist of different columns. \n\nThe test set contains only the shop_id and item_id from the training set, and the submission file only contains the monthly item count with ID.\n\nWe need to map the training set shop_id and item_id to the ID number in the test set, add up the daily item counts for just October 2015, and create a similar submission file with ID and item_cnt_month.","fa747789":"### The Benchmark - October 2015 historical sales to predict November 2015\nLet's try to create a predictions benchmark by creating a submissions file with the previous month's sales. \n\nWe will be using October 2015's sales data to predict November 2015's sales, and using the score as a benchmark for the evaluation of our future models.","0aaf1ddd":"I've made a dataframe of just the October 2015 sales data. \n\nNow I will tally up a total item_cnt_month number for each unique shop_id-item_id pair.","35c430a6":"I tried to convert the 'date' column in the training set to datetime objects so I could sort it and split the October data, but it took way too long because there are 2.9 million rows in the data set. \n\nLuckily I noticed there is a date_block_num column that corresponds to the consecutive month of the dataset. ","fa33541c":"I see what's going on. If the total item_cnt_month is 0 then item_id for the corresponding shop_id is not included. \n\nThis could be fixed by simply merging month_sum with the test dataframe and filling the NaNs.\n\nWe will map the shop_id-item_id to ID number in the test set for our next step, and finally make a submission dataframe.","fdd24df0":"The score now is 1.16777 as expected! Awesome. Now we can start trying some models in another kernel. ","77bc0215":"Something doesn't seem right - the number of rows is far less than the submission dataframe.","ee731f19":"## Introduction\n\nHello everyone, this kernel will serve as a starting point for many coming from the Coursera course \"How to Win a Data Science Competition\".\nAs many of you know, this competition \"Predict Future Sales\" by Russian software firm 1C Company is part of the final project for the course. \n\nThe challenge here is to predict the total monthly sales of a product in each individual shop of a store chain, specifically November 2015. We are given the historical daily sales data from January 2013 to October 2015 in the provided file 'sales_train.csv'. From the training data we are to predict the sales numbers using the data given in 'test.csv', and create a submission file in the same format as 'sample_submission.csv'. Three other csv files are provided to give more insight into the data in the training set.\n\nThis kernel serves as the process for one of the exercises given in the course - to simply create a prediction for November 2015 using the exact historical sales data of the previous month, October 2015. The steps taken throughout this kernel may not be the most efficient, but it was my personal workflow of tackling the competition as a beginner data scientist without looking at the other kernels. \n\nIn the future I should do visualizations for my EDA process, but I made some assumptions that the data is relatively clean, haha.\n\nPlease feel free to use this kernel as you like.\n\nWe will begin by importing the necessary libraries and the datasets."}}