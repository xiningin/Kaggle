{"cell_type":{"1f242a7f":"code","c8e5c922":"code","78903bd8":"code","4065e7cf":"code","582e0586":"code","ddaa2ee4":"code","39e0200b":"code","e0ba0c77":"code","2d5bfb2b":"code","d9099703":"code","3b2acd28":"code","4e0f34b4":"code","0f92207c":"code","91cfee76":"code","86167b87":"code","2e51c8ac":"code","4e98f4e2":"code","befca55e":"code","fa9903e2":"code","5236b84e":"code","7458a02b":"code","80da180c":"code","237856d7":"code","ee7e6293":"code","d7d27883":"code","5291b83c":"markdown","c56085a5":"markdown","ca355006":"markdown","a0df4f1a":"markdown","964565ce":"markdown","a4cad713":"markdown","387abf3a":"markdown","4d624274":"markdown","bbc2d3ea":"markdown","30de3e51":"markdown","4a62d472":"markdown","61692502":"markdown","8963dfe6":"markdown","9cf4e65f":"markdown","24486e16":"markdown","6cd838a7":"markdown","e0c8c1e4":"markdown","15e040a6":"markdown","4cea9a5b":"markdown"},"source":{"1f242a7f":"import pandas as pd\n","c8e5c922":"data = pd.read_csv(\"..\/input\/retail-grocery-store-sales-data-from-20162019\/fruithut_data_ordered_csv_file_1_1.csv\")","78903bd8":"data.head()","4065e7cf":"data.shape","582e0586":"storedata = data[-200:]","ddaa2ee4":"storedata.shape","39e0200b":"storedata.head()","e0ba0c77":"storedata.apply(pd.Series.nunique)","2d5bfb2b":"storedata.drop(['TICKET', 'REFERENCE', 'CODE', 'TRANSID'], inplace=True, axis=1)","d9099703":"storedata.head()","3b2acd28":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(7,7))\nsns.set_context(\"poster\")\nsns.scatterplot(data=storedata, x='UNITS', y='PRICE', hue='PAYMENT')","4e0f34b4":"plt.figure(figsize=(7,7))\nsns.scatterplot(data=storedata, x=\"UNITS\", y=\"TOTAL\", hue=\"PAYMENT\")","0f92207c":"from sklearn.preprocessing import StandardScaler, LabelEncoder\n\nencdata = storedata.copy()","91cfee76":"encdata.columns","86167b87":"lab = LabelEncoder()\nfor i in ['NAME', 'PAYMENT', 'CATERGORY']:\n    encdata[i] = lab.fit_transform(encdata[i])","2e51c8ac":"encdata['DATENEW'] = pd.to_datetime(encdata.DATENEW)","4e98f4e2":"encdata['hour'] = encdata['DATENEW'].dt.hour\n\nencdata['day'] = encdata['DATENEW'].dt.day\n\nencdata['month'] = encdata['DATENEW'].dt.month","befca55e":"encdata.drop(['DATENEW'], inplace=True, axis=1)","fa9903e2":"scaled = encdata.copy()\n\nscale = StandardScaler()\n\nscaledata = scale.fit_transform(scaled)","5236b84e":"from sklearn.cluster import KMeans\n\nkms = KMeans(n_clusters=3, init=\"k-means++\")\n\ncluster = pd.DataFrame(kms.fit_predict(scaledata), columns = ['cluster'])","7458a02b":"enc = encdata.reset_index()","80da180c":"df = pd.concat([enc, cluster], axis=1)","237856d7":"plt.figure(figsize=(7,7))\nsns.scatterplot(data=df,x=\"UNITS\",y=\"PRICE\", hue='cluster')","ee7e6293":"for i, word in enumerate(df['cluster']):\n    if word == 0:\n        df['cluster'][i] = 'Small-Scale Buyer'\n        \nfor i, word in enumerate(df['cluster']):\n    if word == 1:\n        df['cluster'][i] = 'Mid-Scale Buyer'\n        \nfor i, word in enumerate(df['cluster']):\n    if word == 2:\n        df['cluster'][i] = 'Large-Size Buyer'","d7d27883":"plt.figure(figsize=(7,7))\nsns.scatterplot(data=df,x=\"UNITS\",y=\"PRICE\", hue='cluster')","5291b83c":"And voila! ","c56085a5":"Lets find the clusters in this data:\n","ca355006":"Okay so it looks like we found our categories:","a0df4f1a":"# Plotting:","964565ce":"Its time to actually preprocess the columns(I promise):","a4cad713":"Checking the cardinality or the number of unique columns in the dataset:","387abf3a":"Standardising the values:","4d624274":"Well, the dataset I would want should be small since I want to use this notebook for processing data in the future with small grocery stores. Lets make it smaller:","bbc2d3ea":"There is a column which seems to represent the time at which the products were bought. Lets make it usable:","30de3e51":"Lets try plotting it again:","4a62d472":"# Reading the Data:","61692502":"# KMeans:","8963dfe6":"Lets plot the data to understand it better:","9cf4e65f":"# Preprocessing:","24486e16":"Everything looks cool! Its time for some data preprocessing now. Firstly, lets delete the useless categorical columns:","6cd838a7":"Checking the dimensions and the new dataset:","e0c8c1e4":"Encoding the categorical columns:","15e040a6":"Lets check the size of the dataset:","4cea9a5b":"Plotting the clusters:"}}