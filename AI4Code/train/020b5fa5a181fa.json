{"cell_type":{"95fa6a85":"code","05cae985":"code","be65571b":"code","75965f24":"code","201ce506":"code","7b92f525":"code","10c1cf8c":"code","476082e5":"code","7e4adad6":"code","d09b4b56":"code","834accb8":"code","1a69c718":"code","aa8d23fc":"code","e66d9765":"code","a82a7dfa":"code","9ccf97a7":"code","3470936b":"code","f30e1e7c":"code","27ef6522":"code","0d81d297":"code","c91dc889":"code","f26048ab":"code","9f7da515":"code","ddaeea09":"code","f6fb533b":"code","69713d14":"code","4f7095ee":"code","b7cb1397":"code","2f456c8d":"code","777bbe97":"code","d2946c49":"code","a672b65f":"code","0f221301":"code","1a44b21a":"code","5fc42f9e":"code","02416322":"code","2bbf00dd":"code","674c8181":"code","6385d841":"code","b2faa890":"code","7f4ae08e":"markdown","0ffc2e87":"markdown","59678852":"markdown","c0874f35":"markdown","294c4a5c":"markdown","ee1b0f44":"markdown","8a6b4eef":"markdown","2ac84bb6":"markdown","705e0396":"markdown"},"source":{"95fa6a85":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","05cae985":"df = pd.read_csv('\/kaggle\/input\/indian-candidates-for-general-election-2019\/LS_2.0.csv')","be65571b":"df.shape","75965f24":"df.head()","201ce506":"df['STATE'].unique()","7b92f525":"Telangana = df[df['STATE']=='Telangana']\nTelangana['CONSTITUENCY'].unique()","10c1cf8c":"df = df.dropna()","476082e5":"df = df[df['CRIMINAL\\nCASES'] != \"Not Available\"]\ndf['CRIMINAL\\nCASES'] = df['CRIMINAL\\nCASES'].astype(int)","7e4adad6":"import matplotlib.pyplot as plt\nimport seaborn as sb","d09b4b56":"plt.figure(figsize=(20,10))\nsb.set(style=\"darkgrid\")\nax = sb.countplot(x='STATE', data=df)\nplt.title('Candidate by State')\nax = ax.set_xticklabels(ax.get_xticklabels(),rotation=90)","834accb8":"Telangana","1a69c718":"df['CONSTITUENCY'].unique()","aa8d23fc":"plt.figure(figsize=(20,10))\nsb.set(style=\"darkgrid\")\nax = sb.countplot(x='PARTY', data=df)\nplt.title('Candidate by Party')\nax = ax.set_xticklabels(ax.get_xticklabels(),rotation=90)","e66d9765":"plt.figure(figsize=(20,10))\nsb.set(style=\"darkgrid\")\nax = sb.distplot(df['AGE'], kde = True)\nplt.title('Candidate by Age')","a82a7dfa":"df.dtypes","9ccf97a7":"df.columns","3470936b":"def categorizing(dat):\n    cat = dat.astype('category').cat.codes\n    return cat","f30e1e7c":"df['STATE'] = categorizing(df['STATE'])\ndf['CONSTITUENCY'] = categorizing(df['CONSTITUENCY'])\ndf['NAME'] = categorizing(df['NAME'])\ndf['PARTY'] = categorizing(df['PARTY'])\ndf['SYMBOL'] = categorizing(df['SYMBOL'])\ndf['GENDER'] = categorizing(df['GENDER'])\ndf['CATEGORY'] = categorizing(df['CATEGORY'])\ndf['EDUCATION'] = categorizing(df['EDUCATION'])\ndf['ASSETS'] = categorizing(df['ASSETS'])\ndf['LIABILITIES'] = categorizing(df['LIABILITIES'])","27ef6522":"df.head()","0d81d297":"y = df['WINNER'].values\nx = df.drop(columns=['WINNER']).values","c91dc889":"from sklearn import preprocessing\n\nminmax_scaler = preprocessing.MinMaxScaler()\nX = minmax_scaler.fit_transform(x)","f26048ab":"y.shape","9f7da515":"X.shape","ddaeea09":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, Y_train, Y_test = train_test_split(X, y, test_size=0.2)\nX_train, X_val, Y_train, Y_val = train_test_split(X_train, Y_train, test_size=0.1)","f6fb533b":"print(X_train.shape, X_val.shape, X_test.shape, Y_train.shape, Y_val.shape, Y_test.shape)","69713d14":"from keras.models import Sequential\nfrom keras.layers import Dense","4f7095ee":"model1 = Sequential()\nmodel1.add(Dense(32,activation = 'relu', input_shape= (18,)))\nmodel1.add(Dense(32,activation = 'relu'))\nmodel1.add(Dense(1, activation = 'sigmoid'))\n\nmodel1.compile(optimizer = 'sgd', loss = 'binary_crossentropy', metrics=['accuracy'])","b7cb1397":"hist1 = model1.fit(X_train, Y_train, \n                  batch_size=32, epochs=200, validation_data=(X_val, Y_val))","2f456c8d":"score = model1.evaluate(X_test,Y_test)\nprint(\"Loss: \", score[0])\nprint(\"Accuracy: \", score[1])","777bbe97":"plt.plot(hist1.history['loss'])\nplt.plot(hist1.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","d2946c49":"model2 = Sequential()\nmodel2.add(Dense(1000, activation='relu', input_shape=(18,)))  \nmodel2.add(Dense(1000, activation='relu'))\nmodel2.add(Dense(1000, activation='relu'))\nmodel2.add(Dense(1000, activation='relu'))\nmodel2.add(Dense(1, activation='sigmoid'))\n\nmodel2.compile(optimizer='nadam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhist2 = model2.fit(X_train, Y_train,\n          batch_size=32, epochs=200,\n          validation_data=(X_val, Y_val))","a672b65f":"plt.plot(hist2.history['loss'])\nplt.plot(hist2.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","0f221301":"model2.evaluate(X_test,Y_test)","1a44b21a":"from keras.layers import Dropout\nfrom keras import regularizers","5fc42f9e":"model3 = Sequential()\nmodel3.add(Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01), input_shape=(18,)))\nmodel3.add(Dropout(0.3))\nmodel3.add(Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel3.add(Dropout(0.3))\nmodel3.add(Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel3.add(Dropout(0.3))\nmodel3.add(Dense(1000, activation='relu', kernel_regularizer=regularizers.l2(0.01)))\nmodel3.add(Dropout(0.3))\nmodel3.add(Dense(1, activation='sigmoid', kernel_regularizer=regularizers.l2(0.01)))","02416322":"model3.compile(optimizer='nadam',\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\nhist3 = model3.fit(X_train, Y_train,\n          batch_size=32, epochs=200,\n          validation_data=(X_val, Y_val))","2bbf00dd":"plt.plot(hist3.history['loss'])\nplt.plot(hist3.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.ylim(top=1.2, bottom=0)\nplt.show()","674c8181":"model3.evaluate(X_test,Y_test)","6385d841":"y_pred_class = model3.predict(X_test)","b2faa890":"Y_test = Y_test[:, np.newaxis]","7f4ae08e":"### The Party","0ffc2e87":"### Then the candidate age","59678852":"## Simple ANN could determine the winner?","c0874f35":"We will drop rows with missing values","294c4a5c":"### Then, we make the overfitted model","ee1b0f44":"### Applying MinMax Scaler","8a6b4eef":"Since every state has different consituency, we will jump to the constituency. ","2ac84bb6":"First, I will assume that the features here are the only measurement from determining the models' winner, and since I am not from India, I didn't know any other relevant information. So, we will fully rely on the features here.","705e0396":"## Preprocess data"}}