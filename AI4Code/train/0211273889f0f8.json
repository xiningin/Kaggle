{"cell_type":{"16319f54":"code","d28622ff":"code","a0d999a3":"code","e6e21c60":"code","f5c31223":"code","ba61a189":"code","f41b5dc5":"code","9027ae3a":"code","f0722f76":"code","aea0107f":"code","44c4ec1b":"code","e98d7e25":"code","f81144d5":"code","cd9a1575":"code","34ac0647":"code","23448fc0":"code","fb55d71e":"markdown","fecd4169":"markdown","48d4f78c":"markdown","3178ef93":"markdown","7752f316":"markdown","8e37e843":"markdown","a7d99202":"markdown","f83c2ace":"markdown","6f4eebab":"markdown","7a488f14":"markdown","bea45059":"markdown","2fddc2a1":"markdown","4aea0f19":"markdown","6da3d51c":"markdown","de9fd4bf":"markdown","d5ecdaf6":"markdown","8eb3cf6e":"markdown","c21cb5a9":"markdown"},"source":{"16319f54":"#importing all the dependencies\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import tree\nfrom sklearn import svm\nfrom sklearn import neighbors\nfrom sklearn import metrics\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\n\nfrom sklearn.metrics import classification_report","d28622ff":"#importing data and storing into dataframe\npath = \"..\/input\/weight-height.csv\"\ndf = pd.read_csv(path)\ndf.head()","a0d999a3":"#Checking if there are any null values in dataframe at all\ndf.isnull().sum().sum()","e6e21c60":"print(df.describe())","f5c31223":"#Checking if data is balanced or not using pie chart for our target variable - gender\nlabels = df.Gender.unique()\nsizes = [(df.Gender == labels[0]).sum(), (df.Gender == labels[1]).sum()]\nplt.pie(sizes, labels = labels, autopct='%1.1f%%', startangle = 90)\nplt.title(\"Checking if data is balanced or not with a pie chart\")\nplt.show()","ba61a189":"#Outliers\nplt.boxplot(df.Weight)\nplt.title('Box-plot for weight')\nplt.show()\n\nplt.boxplot(df.Height)\nplt.title('Box-plot for height')\nplt.show()","f41b5dc5":"#finding relationship between gender and height\nprint(df.groupby('Gender')['Height'].describe())\n","9027ae3a":"#finding relationship between gender and weight\nprint(df.groupby('Gender')['Weight'].describe())\n","f0722f76":"#scatter plot to analyse height vs weight\nweight = df['Weight']\nheight = df['Height']\nplt.scatter(height, weight)\nplt.xlabel('Height')\nplt.ylabel('Weight')\nplt.title(\"Height vs Weight\")\nplt.show()","aea0107f":"#histogram for height\nplt.hist(height, bins = 10)\nplt.xlabel('Bins')\nplt.ylabel('Frequency')\nplt.title('Histogram for height')\nplt.show()\n\n#histogram for weight\nplt.hist(weight, bins = 10)\nplt.xlabel('Bins')\nplt.ylabel('Frequency')\nplt.title('Histogram for weight')\nplt.show()","44c4ec1b":"#model to split data\ntrain, test = train_test_split(df, test_size=0.2)\nprint(\"Test data set\")\nprint(test.head())\nprint()\nprint(\"Train data set\")\nprint(train.head())\nprint('')\nprint(\"No. of data in test:\" +str(len(test)))\nprint(\"No. of data in train:\" +str(len(train)))\n\nprint(train.groupby('Gender').count())\n#creating x and y variables\nfeature_names = ['Height', 'Weight']\nx_train = train[feature_names].values.tolist()\ny_train = train['Gender']\nx_test = test[feature_names].values.tolist()\ny_test = test['Gender']","e98d7e25":"#defining classifiers\nclf1 = tree.DecisionTreeClassifier()\nclf2 = svm.SVC(gamma='auto')\nclf3 = neighbors.KNeighborsClassifier()\nclf4 = GaussianNB()\n\n#fitting data\nclf1 = clf1.fit(x_train,y_train)\nclf2 = clf2.fit(x_train,y_train)\nclf3 = clf3.fit(x_train, y_train)\nclf4 = clf4.fit(x_train, y_train)\n\n#making predictions\nprediction1 = clf1.predict(x_test)\nprediction2 = clf2.predict(x_test)\nprediction3 = clf3.predict(x_test)\nprediction4 = clf4.predict(x_test)","f81144d5":"#checking accuracy\nr1 = accuracy_score(y_test, prediction1)\nr2 = accuracy_score(y_test, prediction2)\nr3 = accuracy_score(y_test, prediction3)\nr4 = accuracy_score(y_test, prediction4)\n\nprint(\"Accuracy score of Model 1: DecisionTreeClassifier is \"+str(r1))\nprint(\"Accuracy score of Model 2: SupportVectorMachine is \"+str(r2))\nprint(\"Accuracy score of Model 3: KNN is \"+str(r3))\nprint(\"Accuracy score of Model 4: GaussianNB is \"+str(r4))\n","cd9a1575":"#finding misclassification rate\nmr1 = (1-metrics.accuracy_score(y_test, prediction1))\nmr2 = (1-metrics.accuracy_score(y_test, prediction2))\nmr3 = (1-metrics.accuracy_score(y_test, prediction3))\nmr4 = (1-metrics.accuracy_score(y_test, prediction4))\nprint(\"Misclassification Rate of Decision Tree: \"+ str(mr1))\nprint(\"Misclassification Rate of SVM: \"+ str(mr2))\nprint(\"Misclassification Rate of KNN: \"+ str(mr3))\nprint(\"Misclassification Rate of Naive Bayes: \"+ str(mr4))","34ac0647":"#confusion matrix\n\n#decision tree\ncm1 = confusion_matrix(y_test, prediction1)\nTP1 = cm1[1,1]\nTN1 = cm1[0,0]\nFP1 = cm1[0,1]\nFN1 = cm1[1,0]\n\n#svm\ncm2 = confusion_matrix(y_test, prediction2)\nTP2 = cm2[1,1]\nTN2 = cm2[0,0]\nFP2 = cm2[0,1]\nFN2 = cm2[1,0]\n\n#knn\ncm3 = confusion_matrix(y_test, prediction3)\nTP3 = cm3[1,1]\nTN3 = cm3[0,0]\nFP3 = cm3[0,1]\nFN3 = cm3[1,0]\n\n#naive-bayes\ncm4 = confusion_matrix(y_test, prediction4)\nTP4 = cm4[1,1]\nTN4 = cm4[0,0]\nFP4 = cm4[0,1]\nFN4 = cm4[1,0]\n\n#sensitivity\nsen1 = TP1 \/ float(FN1 + TP1)\nsen2 = TP2 \/ float(FN2 + TP2)\nsen3 = TP3 \/ float(FN3 + TP3)\nsen4 = TP4 \/ float(FN4 + TP4)\n\n#specificity\nspec1 = TN1 \/ (TN1 + FP1)\nspec2 = TN2 \/ (TN2 + FP2)\nspec3 = TN3 \/ (TN3 + FP3)\nspec4 = TN4 \/ (TN4 + FP4)\n\n#printing\nprint(\"Sensitivity Rate of Decision Tree: \"+ str(sen1))\nprint(\"Sensitivity Rate of SVM: \"+ str(sen2))\nprint(\"Sensitivity Rate of KNN: \"+ str(sen3))\nprint(\"Sensitivity Rate of Naive Bayes: \"+ str(sen4))\nprint()\nprint(\"Specificity Rate of Decision Tree: \"+ str(spec1))\nprint(\"Specificity Rate of SVM: \"+ str(spec2))\nprint(\"Specificity Rate of KNN: \"+ str(spec3))\nprint(\"Specificity Rate of Naive Bayes: \"+ str(spec4))\nprint()\nprint(\"Classification Report: Decision Tree\")\nprint(classification_report(y_test, prediction1))\nprint(\"Classification Report: SVM\")\nprint(classification_report(y_test, prediction2))\nprint(\"Classification Report: KNN\")\nprint(classification_report(y_test, prediction3))\nprint(\"Classification Report: Naive-Bayes\")\nprint(classification_report(y_test, prediction4))","23448fc0":"#Making a prediction for a user\nheight = 71\nweight = 176\nprediction = clf2.predict([[height, weight]])\nprint(\"The classifier predicts that you could be \" +str(prediction[0]))","fb55d71e":"**Distribution of data:** Both height and weight seems to be normally distributed.","fecd4169":"**Relationship between height and weight:**\n<br>\nThere appears to be a positive relationship between weight and height too. Thus, there could be an interaction effect while predicting gender.","48d4f78c":"<h1>Gender classification based on height and weight<\/h1>\n<br>\nHere's my first data analysis on Kaggle. I am currently learning to become data analyst and data scientist. So, please correct me if I have made any mistake in my analysis.\n\nThis is a very basic classification problem where we classify whether a person is male or female given his weight and height. \n\nData Source: https:\/\/www.kaggle.com\/mustafaali96\/weight-height","3178ef93":"<h2>Classifiers<\/h2>\nSince this is a classific binary classification problem, following classifiers have been chosen:\n1. Binary Decision Tree\n2. Support Vector Machine\n3. k-n Neighbours Classifier\n4. Naive Bayes Classifier","7752f316":"Overall:\n1. Decision Tree Classifier is incorrect 12.9% of the times.\n2. SVM is incorrect 8.9% of the times\n3. KNN is incorrect 9.8% of the times\n4. Naive Bayes is incorrect 11.45% of the times  \n\n<br>SVM seems to be a better model.\n\n<h2>3. Sensitivity and Specificity<\/h2>\n","8e37e843":"<h2>Evaluating Model:<\/h2>\n**1. Classification Accuracy**","a7d99202":"There are equal no. of male and female in the dataset. Hence, the data is balanced. So we need not worry about balancing data.","f83c2ace":"Overall:\n1. Decision Tree Classifier is correct 87.1% of the times.\n2. SVM is correct 91% of the times\n3. KNN is correct 90.1% of the times\n4. Naive Bayes is correct 88.55% of the times\n<br>\n<br>\nSeems like SupportVectorMachine has greater accuracy than other classifiers.\n\n<h2>2. Misclassification Rate<\/h2>","6f4eebab":"Well. It predicted my gender correctly. You could give it a try. If it does not predict it, know that the classifier is wrong 8% of the times.\n\n\n<h2>Limitations<\/h2>\n* This is a very basic model that is prediciting gender based on only 2 variables. Other factors such as age, nationality\/race can be important too.","7a488f14":"**Using Tukey's rule for Box-plot:**\nThere is one outlier for weight, and there seems to be multiple outliers for height. However, these outliers are necessary for our analysis as they can impact the gender. Hence, we keep these outliers in the data.","bea45059":"In the entire dataset, there are no null values. So, we do not need to worry about null values.","2fddc2a1":"**Relationship between Gender and Height:**\n<br>\nIt can be seen that the mean of height and standard deviation of height for male and female are different. Hence, there is a meaningful difference between gender and height. Thus, there seems to be a relationship between gender and height.","4aea0f19":"<h2>Descriptive analytics:<\/h2>\n<br>\n(Writing in non-technical terms:)\n***\n**1. Mean:** An average person in the sample data has 66.36 inch height and 161.44 pound weight. \n***\n**2. Minimum and maximum:** The lowest height of the person in the sample is 54.26 inch while the maximum height of the person in the sample is 78.99 inches.The person with the lowest weight weighs 64.7 pounds and the person with the highest weight weights 269.98 pounds in the sample.\n***\n**3. Percentiles:**  25% of the people in the sample has height less than 63.5 inches while 25% of the people in the sample has height more than 69.17 inches. 25% of the people in the sample weights less than 135.81 pounds while 25% of people in the sample weigh more than 187.17 pounds.\n***\n**4. Median:** 50% of the people in the sample has height more or less than 66.31 inches. 50% of the people in the sample weigh more or less than 161.21 pounds.\n***\n**5. Standard deviation:** On average, height of the person varies by 3.84 inches from the average height of person. On average, weight of the person varies by 32.10 pounds from the average weight of person.","6da3d51c":"When the actual value is male:\n1. Decision Tree is correct 90% of the time\n2. SVM is correct 93% of times\n3. KNN is correct 92.42% of the times\n4. Naive Bayes is correct 90% of the times.\n\nWhen the actual value is female:\n1. Decision Tree is correct 86% of the time\n2. SVM is correct 91% of times\n3. KNN is correct 89% of the times\n4. Naive Bayes is correct 87% of the times.\n\nEven here, SVM is a better model.","de9fd4bf":"<h2>Data Analysis<\/h2>\n<h3>Splitting data <\/h3>\nNow, that we have described our data and now that we know the data is clean to analyse, we create test and train data set. The general 80:20 split has been used where 80% of data is split into training set and 20% of data is split into test set.","d5ecdaf6":"The train dataset is more or less balanced too.","8eb3cf6e":"<h2>Describing\/Cleaning Data<\/h2>\n<br>\n****Target Variable:**** Gender (categorical)\n<br>\n****Predictor Variables**:** Height (numerical), Weight (numerical)","c21cb5a9":"**Relationship between Gender and Weight:**\n<br>\nIt can be seen that the mean of weight and standard deviation of weight for male and female are different. Hence, there is a meaningful difference between gender and height. Thus, there seems to be a relationship between gender and height."}}