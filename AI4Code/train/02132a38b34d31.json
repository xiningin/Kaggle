{"cell_type":{"e351fe1e":"code","92a84c61":"code","270722b4":"code","39408405":"code","dd9365b9":"code","78299cd4":"code","f779cfd9":"code","e3eff49f":"code","0db2babf":"code","8734011b":"code","6bf7ff3e":"code","15764c9f":"code","915b4824":"code","28e0790b":"code","c37d527c":"code","4b4f75e2":"code","3ccf8ffe":"code","df22b37a":"code","086a088c":"code","2c0b7d31":"code","65971470":"code","0096a3b6":"code","e43a96ac":"code","a6ab9d30":"code","0aa64635":"code","7e44af4d":"code","94f5bdc0":"markdown","68fd811c":"markdown","e28b72d3":"markdown","900b301f":"markdown","db03ca51":"markdown","60a3cf77":"markdown","6c345ae8":"markdown","36ed3a2c":"markdown"},"source":{"e351fe1e":"import pandas as pd\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport os\nfrom sklearn.metrics import f1_score\n\nfrom fastai import *\nfrom fastai.vision import *\n\nimport torch\nimport torch.nn as nn\nimport torchvision\nimport cv2\n\nfrom tqdm import tqdm\nfrom skmultilearn.model_selection import iterative_train_test_split\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MultiLabelBinarizer\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%load_ext autoreload\n%autoreload","92a84c61":"model_path='.'\npath='..\/input\/'\ntrain_folder=f'{path}train'\ntest_folder=f'{path}test'\ntrain_lbl=f'{path}train_labels.csv'\nORG_SIZE=96\n\nbs=64\nnum_workers=None # Apprently 2 cpus per kaggle node, so 4 threads I think\nsz=96","270722b4":"df_trn=pd.read_csv(train_lbl)","39408405":"tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=.0, max_zoom=.1,\n                      max_lighting=0.05, max_warp=0.)","dd9365b9":"data = ImageDataBunch.from_csv(path,csv_labels=train_lbl,folder='train', ds_tfms=tfms, size=sz, suffix='.tif',test=test_folder,bs=bs);\nstats=data.batch_stats()        \ndata.normalize(stats)","78299cd4":"data.show_batch(rows=5, figsize=(12,9))","f779cfd9":"from sklearn.metrics import roc_auc_score","e3eff49f":"def auc_score(y_pred,y_true,tens=True):\n    score=roc_auc_score(y_true,torch.sigmoid(y_pred)[:,1])\n    if tens:\n        score=tensor(score)\n    else:\n        score=score\n    return score","0db2babf":"from torchvision.models import *","8734011b":"learn = create_cnn(\n    data,\n    densenet201,\n    path='.',    \n    metrics=[auc_score], \n    ps=0.5\n)","6bf7ff3e":"learn.lr_find()\nlearn.recorder.plot()","15764c9f":"lr = 2e-03","915b4824":"learn.fit_one_cycle(1,lr)\nlearn.recorder.plot()\nlearn.recorder.plot_losses()","28e0790b":"learn.unfreeze()\nlearn.lr_find()","c37d527c":"learn.recorder.plot()","4b4f75e2":"learn.fit_one_cycle(1,slice(1e-4,1e-3))","3ccf8ffe":"learn.recorder.plot()","df22b37a":"learn.recorder.plot_losses()","086a088c":"preds,y=learn.get_preds()\npred_score=auc_score(preds,y)\npred_score","2c0b7d31":"preds,y=learn.TTA()\npred_score_tta=auc_score(preds,y)\npred_score_tta","65971470":"preds_test,y_test=learn.get_preds(ds_type=DatasetType.Test)","0096a3b6":"preds_test_tta,y_test_tta=learn.TTA(ds_type=DatasetType.Test)","e43a96ac":"sub=pd.read_csv(f'{path}\/sample_submission.csv').set_index('id')\nsub.head()","a6ab9d30":"clean_fname=np.vectorize(lambda fname: str(fname).split('\/')[-1].split('.')[0])\nfname_cleaned=clean_fname(data.test_ds.items)\nfname_cleaned=fname_cleaned.astype(str)","0aa64635":"sub.loc[fname_cleaned,'label']=to_np(preds_test[:,1])\nsub.to_csv(f'submission_{pred_score}.csv')","7e44af4d":"sub.loc[fname_cleaned,'label']=to_np(preds_test_tta[:,1])\nsub.to_csv(f'submission_{pred_score_tta}.csv')","94f5bdc0":"In Case I want to run quick tests use a subsample:","68fd811c":"Defining a metric so after epoch I get the validation ROC-AUC score","e28b72d3":"### prepare submission\nI now load in the sample submission and put my predictions in the label column and save to a new file.","900b301f":"### Predit the validation data using TTA\nHere for every image we want to predict on, n_augs images are augmented form the original image.\nWe can then compare the predictions on for example the image and the image flipped \/ roated \/ slightly different crop\/ lighting\/stretched etc. \nFor now only the diherdral and rotations are used. THis gives a nice extra percent or two when compared to the auc above after training where not TTA is used. \nI also test if mean or max is better to use on the image and its augments but it can't conclude anything yet.","db03ca51":"### Now predict on test set","60a3cf77":"### Warm up with frozen weight is done on a subset so we dont have to waste an entire epoch","6c345ae8":"## I add the score to the name of the file so I can later plot the leaderboard score versus my validation score\nIn the fastai course Jeremy mentions that if you have a monotonic relation between validation and LB score the way you set up your validation set matches what the test set consists of.","36ed3a2c":"Sometimes its important in which order the ids in the submissions are so to make sure I don't mess up I put them in the same order. My first submission had a 50% score so I somewhere messed up the order oder the matching of id to label.\nsince fname_clean is the id we can just use that as index when adding the correct label in our dataframe. "}}