{"cell_type":{"f814c85b":"code","6a2de818":"code","fe37a5b5":"code","7435adb1":"code","0cf22a53":"code","043329eb":"code","9806e306":"code","5582da85":"code","d28b1a83":"code","cd4551ed":"code","ffaac772":"code","ad4a32e4":"code","3d9920ef":"code","b1f93d81":"code","f9dee20f":"code","be5de3a1":"code","b5a3e3a3":"code","93a92b2b":"code","59f9175d":"code","49a0348b":"code","bb8fb551":"code","6d8e2f1e":"code","eb534a0d":"code","11ec1535":"code","eecc14f9":"code","868ef9b1":"code","93a4ecbf":"code","98e49fe9":"code","3e7e7f3e":"code","1801308d":"code","842f61aa":"code","3999f4a7":"markdown","a8f5a77d":"markdown","e380e08e":"markdown","0b66ea38":"markdown","4235793c":"markdown","63ce8347":"markdown","91213661":"markdown","d6e0fc91":"markdown","c9a77a00":"markdown","d819ff83":"markdown","eec5b410":"markdown","f303e40e":"markdown","66db9a21":"markdown","02bfa144":"markdown","65a91aef":"markdown","8a6919c6":"markdown","2a71f314":"markdown","2f5c214a":"markdown","5be07d26":"markdown","0d92191a":"markdown","568379a1":"markdown"},"source":{"f814c85b":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"darkgrid\")\n\nfrom collections import Counter\n\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.ensemble import VotingClassifier\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\n\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6a2de818":"df = pd.read_csv('\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv')\ndf.head()","fe37a5b5":"df.shape","7435adb1":"describe = df.describe()\ndescribe.T","0cf22a53":"df.isnull().sum()","043329eb":"plt.figure(figsize = (10,8))\nsns.scatterplot(x = \"fixed acidity\", y = \"density\", hue = \"quality\",data = df, alpha = 0.7, palette = \"Set1\")\nplt.title(\"Quality - Fixed Acidity - Density\", size = 12)\nplt.show()","9806e306":"quality = df[\"quality\"].value_counts()\n\nfig = plt.figure(figsize=(12,12))\n\nax1 = plt.subplot2grid((2,2),(0,0))\n\nplt.pie(x= quality, autopct=\"%.2f%%\", labels=quality.keys(), pctdistance=0.6)\nplt.title('Quality', size = 14)\nplt.show()","5582da85":"fig = plt.figure(figsize=(10,10))\nfor index,column in enumerate(list(df.columns[0:4])):\n    plt.subplot(2,2,index+1)\n    sns.boxplot(y = df.loc[:, column], x = df[\"quality\"], linewidth=2.5)\n    plt.title(column, size = 12)\nfig.tight_layout()","d28b1a83":"fig = plt.figure(figsize=(10,10))\nfor index,column in enumerate(list(df.columns[0:4])):\n    plt.subplot(2,2,index+1)\n    sns.distplot(x = df.loc[:, column])\n    plt.title(column, size = 12)\nfig.tight_layout()","cd4551ed":"fig = plt.figure(figsize=(10,10))\nfor index,column in enumerate(list(df.columns[0:4])):\n    plt.subplot(2,2,index+1)\n    sns.violinplot(y = df.loc[:, column], x = df[\"quality\"], linewidth=2.5)\n    plt.title(column, size = 12)\nfig.tight_layout()","ffaac772":"fig = plt.figure(figsize=(10,10))\nfor index,column in enumerate(list(df.columns[4:8])):\n    plt.subplot(2,2,index+1)\n    sns.boxplot(y = df.loc[:, column], x = df[\"quality\"], linewidth=2.5)\n    plt.title(column, size = 12)\nfig.tight_layout()","ad4a32e4":"fig = plt.figure(figsize=(10,10))\nfor index,column in enumerate(list(df.columns[4:8])):\n    plt.subplot(2,2,index+1)\n    sns.distplot(x = df.loc[:, column])\n    plt.title(column, size = 12)\nfig.tight_layout()","3d9920ef":"fig = plt.figure(figsize=(10,10))\nfor index,column in enumerate(list(df.columns[4:8])):\n    plt.subplot(2,2,index+1)\n    sns.violinplot(y = df.loc[:, column], x = df[\"quality\"], linewidth=2.5)\n    plt.title(column, size = 12)\nfig.tight_layout()","b1f93d81":"fig = plt.figure(figsize=(15,5))\nfor index,column in enumerate(list(df.columns[8:11])):\n    plt.subplot(1,3,index+1)\n    sns.boxplot(y = df.loc[:, column], x = df[\"quality\"], linewidth=2.5)\n    plt.title(column, size = 12)\nfig.tight_layout()","f9dee20f":"fig = plt.figure(figsize=(15,5))\nfor index,column in enumerate(list(df.columns[8:11])):\n    plt.subplot(1,3,index+1)\n    sns.distplot(x = df.loc[:, column])\n    plt.title(column, size = 12)\nfig.tight_layout()","be5de3a1":"fig = plt.figure(figsize=(15,5))\nfor index,column in enumerate(list(df.columns[8:11])):\n    plt.subplot(1,3,index+1)\n    sns.violinplot(y = df.loc[:, column], x = df[\"quality\"], linewidth=2.5)\n    plt.title(column, size = 12)\nfig.tight_layout()","b5a3e3a3":"plt.figure()\nsns.pairplot(df,hue = 'quality', palette = \"Set1\")\nplt.show()","93a92b2b":"f,ax=plt.subplots(figsize = (10,10))\nsns.heatmap(df.corr(),annot= True,fmt = \".2f\",\n            vmin = -1,\n            vmax = 1,\n            ax=ax,cmap = 'coolwarm')\nplt.xticks(rotation=90)\nplt.yticks(rotation=0)\nplt.title('Correlation Map', size = 14)\nplt.show()","59f9175d":"def detect_outliers(df,features):\n    outlier_indices = []\n    \n    for c in features:\n        # 1st quartile\n        Q1 = np.percentile(df[c],25)\n        # 3rd quartile\n        Q3 = np.percentile(df[c],75)\n        # IQR\n        IQR = Q3 - Q1\n        # Outlier step\n        outlier_step = IQR * 1.5\n        # detect outlier and their indeces\n        outlier_list_col = df[(df[c] < Q1 - outlier_step) | (df[c] > Q3 + outlier_step)].index\n        # store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers\n\ndf.loc[detect_outliers(df,df.columns[:-1])]","49a0348b":"df = df.drop(detect_outliers(df,df.columns[:-1]),axis = 0).reset_index(drop = True)\ndf.shape","bb8fb551":"bins = (2, 6.5, 8)\n\ngroup_names = ['bad', 'good']\n\ndf['quality'] = pd.cut(df['quality'], bins = bins, labels = group_names)","6d8e2f1e":"label_quality = LabelEncoder()\n\ndf['quality'] = label_quality.fit_transform(df['quality'])\n\ndf.head()","eb534a0d":"x = df.drop('quality', axis = 1)\ny = df['quality']\n\nX_train, X_test, Y_train, Y_test = train_test_split(x, y, test_size = 0.3, random_state = 42)","11ec1535":"sc = StandardScaler()\n\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)","eecc14f9":"sgd = SGDClassifier(penalty=None)\n\nsgd.fit(X_train, Y_train)\n\npred_sgd = sgd.predict(X_test)\n\nprint(classification_report(Y_test, pred_sgd))","868ef9b1":"cm = confusion_matrix(Y_test, pred_sgd)\n\ndf1 = pd.DataFrame(columns=[\"Bad\",\"Good\"], index= [\"Bad\",\"Good\"], data= cm )\n\nf,ax = plt.subplots(figsize=(4,4))\n\nsns.heatmap(df1, annot=True,cmap=\"Reds\", fmt= '.0f',ax=ax,linewidths = 5, cbar = False)\nplt.xlabel(\"Predicted Label\")\nplt.xticks(size = 12)\nplt.yticks(size = 12, rotation = 0)\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\", size = 12)\nplt.show()","93a4ecbf":"random_state = 42\n\nclassifier = [DecisionTreeClassifier(random_state = random_state),\n             SVC(random_state = random_state),\n             RandomForestClassifier(random_state = random_state),\n             LogisticRegression(random_state = random_state),\n             KNeighborsClassifier(),\n             SGDClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nsgdc_param_grid = {\n    \"loss\" : [\"hinge\", \"log\", \"squared_hinge\", \"modified_huber\"],\n    \"alpha\" : [0.0001, 0.001, 0.01, 0.1],\n    \"penalty\" : [\"l2\", \"l1\", \"none\"],\n}\n\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid,\n                   sgdc_param_grid]\n\ncv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i],\n                       param_grid=classifier_param[i],\n                       cv = StratifiedKFold(n_splits = 10),\n                       scoring = \"accuracy\",\n                       n_jobs = -1,\n                       verbose = 1)\n    clf.fit(X_train,Y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","98e49fe9":"best_estimators","3e7e7f3e":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"Models\":[\"DecisionTreeClassifier\", \"SVC\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\",\n             \"SGDClassifier\"]})\nplt.figure(figsize = (10,6))\ng = sns.barplot(\"Cross Validation Means\", \"Models\", data = cv_results, palette = \"Paired\")\ng.set_title(\"Cross Validation Scores\", size = 14)\ng.set_xlabel(\"Mean Accuracy\")\nplt.show()","1801308d":"votingC = VotingClassifier(estimators = [(\"svc\",best_estimators[1]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"knn\",best_estimators[4])])\n\nvotingC = votingC.fit(X_train, Y_train)\n\nvoting_pred = votingC.predict(X_test)\n\nprint(classification_report(Y_test, voting_pred))","842f61aa":"cm = confusion_matrix(Y_test, voting_pred)\n\ndf1 = pd.DataFrame(columns=[\"Bad\",\"Good\"], index= [\"Bad\",\"Good\"], data= cm )\n\nf,ax = plt.subplots(figsize=(4,4))\n\nsns.heatmap(df1, annot=True,cmap=\"Reds\", fmt= '.0f',ax=ax,linewidths = 5, cbar = False)\nplt.xlabel(\"Predicted Label\")\nplt.xticks(size = 12)\nplt.yticks(size = 12, rotation = 0)\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\", size = 12)\nplt.show()","3999f4a7":"<a id = \"20\"><\/a>\n## Stochastic Gradient Descent","a8f5a77d":"<a id = \"22\"><\/a>\n## Hyperparameter Tuning - Grid Search - Cross Validation","e380e08e":"<a id = \"16\"><\/a>\n# Preprocessing\n<a id = \"17\"><\/a>\n## Train Test Split","0b66ea38":"<a id = \"2\"><\/a>\n# Load and Check Data","4235793c":"<a id = \"13\"><\/a>\n# Outlier Detection","63ce8347":"# Red Wine Quality EDA & Classification   \n\n\n![image.png](attachment:c3dfe204-4a97-401c-9a81-1c947f61de74.png)\n\n\n1. [Libraries and Utilities](#1)\n2. [Load and Check Data](#2)\n3. [Descriptive Statistics](#3)\n4. [Missing Values](#4)\n5. [Exploratory Data Analysis](#5)\n    * [Quality - Fixed Acidity - Density](#6)\n    * [Quality](#7)\n    * [Fixed Acidity - Volatile Acidity - Citric Acid - Residual Sugar](#8)\n    * [Chlorides - Free Sulfur Dioxide - Total Sulfur Dioxide - Density](#9)\n    * [pH - Sulphates - Alcohol](#10)\n    * [Pairwise Relationships](#11)\n    * [Correlation Map](#12)\n6. [Outlier Detection](#13)\n7. [Feature Engineering](#14)\n    * [Label Encoding](#15)\n8. [Preprocessing](#16)\n    * [Train Test Split](#17)\n    * [Standardization](#18)\n9. [Models](#19)\n    * [Stochastic Gradient Descent](#20)\n    * [Hyperparameter Tuning - Grid Search - Cross Validation](#22)\n    * [Ensemble Modeling](#23)","91213661":"<a id = \"7\"><\/a>\n## Quality","d6e0fc91":"<a id = \"12\"><\/a>\n## Correlation Map","c9a77a00":"<a id = \"4\"><\/a>\n# Missing Values","d819ff83":"<a id = \"18\"><\/a>\n## Standardization","eec5b410":"<a id = \"3\"><\/a>\n# Descriptive Statistics","f303e40e":"<a id = \"14\"><\/a>\n# Feature Engineering","66db9a21":"<a id = \"19\"><\/a>\n# Models\n\n- Stochastic Gradient Descent Classifier\n- Decision Tree Classifier\n- Support Vector Classifier\n- Random Forest Classifier\n- Logistic Regression Classifier\n- K Neighbors Classifier","02bfa144":"<a id = \"15\"><\/a>\n## Label Encoding","65a91aef":"<a id = \"10\"><\/a>\n## pH - Sulphates - Alcohol","8a6919c6":"<a id = \"5\"><\/a>\n# Exploratory Data Analysis\n<a id = \"6\"><\/a>\n## Quality - Fixed Acidity - Density","2a71f314":"<a id = \"11\"><\/a>\n## Pairwise Relationships","2f5c214a":"<a id = \"8\"><\/a>\n## Fixed Acidity - Volatile Acidity - Citric Acid - Residual Sugar","5be07d26":"<a id = \"9\"><\/a>\n## Chlorides - Free Sulfur Dioxide - Total Sulfur Dioxide - Density","0d92191a":"<a id = \"23\"><\/a>\n## Ensemble Modeling","568379a1":"<a id = \"1\"><\/a>\n# Libraries and Utilities"}}