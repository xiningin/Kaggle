{"cell_type":{"a804dcda":"code","70d35a44":"code","e27486ac":"code","6467d641":"code","9ef52e38":"code","e456074c":"code","5632e9b0":"code","8c4c5333":"code","e7e102dd":"code","f6563cd0":"code","9f05a1c2":"markdown"},"source":{"a804dcda":"import numpy as np\nimport pandas as pd\nimport os","70d35a44":"train = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/train.csv\")\nlabels = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/labels.csv\")\nsub = pd.read_csv(\"..\/input\/imet-2019-fgvc6\/sample_submission.csv\")\n\ntrain[\"id\"] = train.id.map(lambda x: \"{}.png\".format(x))\ntrain[\"attribute_ids\"] = train.attribute_ids.map(lambda x: x.split())\nsub[\"id\"] = sub.id.map(lambda x: \"{}.png\".format(x))\n\ndisplay(sub.head())\ndisplay(train.head())","e27486ac":"batch_size = 32\nimg_size = 64\nnb_epochs = 150\nnb_classes = labels.shape[0]\nlbls = list(map(str, range(nb_classes)))","6467d641":"%%time\n\nfrom keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255, validation_split=0.25)\n\ntrain_generator=train_datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=\"..\/input\/imet-2019-fgvc6\/train\",\n    x_col=\"id\",\n    y_col=\"attribute_ids\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",\n    classes=lbls,\n    target_size=(img_size,img_size),\n    subset='training')\n\nvalid_generator=train_datagen.flow_from_dataframe(\n    dataframe=train,\n    directory=\"..\/input\/imet-2019-fgvc6\/train\",\n    x_col=\"id\",\n    y_col=\"attribute_ids\",\n    batch_size=batch_size,\n    shuffle=True,\n    class_mode=\"categorical\",    \n    classes=lbls,\n    target_size=(img_size,img_size),\n    subset='validation')\n\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntest_generator = test_datagen.flow_from_dataframe(  \n        dataframe=sub,\n        directory = \"..\/input\/imet-2019-fgvc6\/test\",    \n        x_col=\"id\",\n        target_size = (img_size,img_size),\n        batch_size = 1,\n        shuffle = False,\n        class_mode = None\n        )","9ef52e38":"from keras.applications.vgg16 import VGG16\nfrom keras.layers import Dropout\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Flatten\n\nvgg_conv = VGG16(weights=None, include_top=False, input_shape=(img_size, img_size, 3))\nvgg_conv.load_weights('..\/input\/vgg16\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5')\n\nfor layer in vgg_conv.layers[:-4]:\n    layer.trainable = False\n\nmodel = Sequential()\nmodel.add(vgg_conv)\n \nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(nb_classes, activation='softmax'))\n \nmodel.summary()","e456074c":"from keras import optimizers\n\nmodel.compile(optimizers.rmsprop(lr=0.0001, decay=1e-6),loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","5632e9b0":"history = model.fit_generator(\n                    generator=train_generator,\n                    steps_per_epoch=100,\n                    validation_data=valid_generator,\n                    validation_steps=50,\n                    epochs=nb_epochs,\n                    verbose=1)","8c4c5333":"import json\n\nwith open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","e7e102dd":"%%time\n\ntest_generator.reset()\npredict=model.predict_generator(test_generator, steps = len(test_generator.filenames))","f6563cd0":"predicted_class_indices = np.argmax(predict,axis=1)\n\nlabels = (train_generator.class_indices)\nlabels = dict((v,k) for k,v in labels.items())\npredictions = [labels[k] for k in predicted_class_indices]\n\nsub[\"attribute_ids\"] = predictions\nsub['id'] = sub['id'].map(lambda x: str(x)[:-4])\n\nsub.to_csv(\"submission.csv\",index=False)\nsub.head()","9f05a1c2":"I referred this kernel for leaning how to use Keras.\n\n[Keras Starter](https:\/\/www.kaggle.com\/ateplyuk\/keras-starter)"}}