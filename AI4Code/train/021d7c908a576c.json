{"cell_type":{"ba0aef09":"code","7177871b":"code","a7f4a103":"code","2756207f":"code","b8858fe6":"code","74a067e6":"code","02bd23fe":"code","a61bb334":"code","8f45203a":"code","3750d6c7":"code","edb5d1a4":"code","77fec514":"code","a2f5d261":"code","3602008b":"code","cd31350d":"code","c63c854f":"code","a8c6d86a":"code","6adfa17b":"code","bb0b8cda":"code","01a265a9":"code","22299376":"code","cf1e7ae0":"code","52cca9be":"code","d7d7e575":"code","4b5d48f1":"markdown","7e31454c":"markdown","510716b0":"markdown","42e0fd7b":"markdown","0c3048d4":"markdown","7c353572":"markdown"},"source":{"ba0aef09":"from google.colab import drive\ndrive.mount('\/content\/gdrive\/')","7177871b":"# %cd gdrive\/MyDrive\/wazzadu\/dts_img\/valid\n# !gdown --id 1schbXVerH_Vq39oyrgvwk2tpx17UJSQG\n# !unzip dts_img.zip\n\n# %cd gdrive\/MyDrive\/wazzadu\n# ls 'gdrive\/MyDrive\/wazzadu'\n# !gdown --id 1schbXVerH_Vq39oyrgvwk2tpx17UJSQG\n# !unzip dts_img1.zip","a7f4a103":"# Downgrade Pillow to avoid errors\n!pip install Pillow==3.4.2\n\nimport tensorflow as tf\n# import tensorflow.compat.v1 as tf\nfrom keras.applications.vgg19 import VGG19, preprocess_input\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.models import Model\nfrom keras import optimizers \nfrom keras import regularizers\nfrom keras.callbacks import ModelCheckpoint,EarlyStopping,ReduceLROnPlateau\nfrom time import time\n\nfrom numpy.random import seed\nseed(12)\n# from tensorflow import set_random_seed\n# set_random_seed(12)\ntf.random.set_seed(12)\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nnp.random.seed(12)\n\nfrom sklearn.metrics import classification_report, f1_score, accuracy_score\nimport glob\nfrom tqdm import tqdm\nimport warnings\n\nimport os\nos.environ[\"CUDA_VISIBLE_DEVICES\"] = \"0\"","2756207f":"ls 'gdrive\/MyDrive\/wazzadu\/val'","b8858fe6":"# ls 'gdrive\/MyDrive\/Super_AI_Level_2_Links\/week2.2\/\u0e42\u0e08\u0e17\u0e22\u0e4c_DENSO\/data_sets\/croped_classified_dataset'","74a067e6":"ls 'gdrive\/MyDrive\/wazzadu\/val-20210219T043250Z-001.zip'","02bd23fe":"!unzip 'gdrive\/MyDrive\/wazzadu\/val-20210219T043250Z-001.zip' ","a61bb334":"train_dir = \"gdrive\/MyDrive\/wazzadu\/dts_img\/train\"\nval_dir = \"gdrive\/MyDrive\/wazzadu\/dts_img\/valid\"\ntest_dir = \"\/content\/val\"","8f45203a":"test_dir","3750d6c7":"image_size = 224\nnum_class = 24\n\nbatch_size=64\n\ntrain_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_input,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\n \nvalidation_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(224, 224),\n        batch_size=batch_size,\n        class_mode='categorical')\n\nfrom collections import Counter\ncounter = Counter(train_generator.classes)                          \nmax_val = float(max(counter.values()))       \nclass_weights = {class_id : max_val\/num_images for class_id, num_images in counter.items()}     \n \nvalidation_generator = validation_datagen.flow_from_directory(\n        val_dir,\n        target_size=(224,224),\n        batch_size=batch_size,\n        class_mode='categorical')","edb5d1a4":"x, y = train_generator.next()","77fec514":"def f1_score_metric(y_true, y_pred):\n    y_true = tf.cast(y_true, \"int32\")\n    y_pred = tf.cast(tf.round(y_pred), \"int32\") # implicit 0.5 threshold via tf.round\n    y_correct = y_true * y_pred\n    sum_true = tf.reduce_sum(y_true, axis=1)\n    sum_pred = tf.reduce_sum(y_pred, axis=1)\n    sum_correct = tf.reduce_sum(y_correct, axis=1)\n    precision = sum_correct \/ sum_pred\n    recall = sum_correct \/ sum_true\n    f_score = 5 * precision * recall \/ (4 * precision + recall)\n    # f_score = tf.where(tf.is_nan(f_score), tf.zeros_like(f_score), f_score)\n    f_score = tf.where(tf.math.is_nan(f_score), tf.zeros_like(f_score), f_score)\n    return tf.reduce_mean(f_score)","a2f5d261":"base_model = VGG19(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n\nfor layer in base_model.layers:\n    layer.trainable = False\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(1024)(x)\nx = Dropout(0.5)(x)\nx = Dense(512)(x)\nx = Dropout(0.5)(x)\noutput = Dense(num_class, activation='softmax')(x)\n\n# Create  model\nmodel_4 = Model(inputs=base_model.input, outputs=output)\n\nnum_training_img=22098\nnum_validation_img=8097\nstepsPerEpoch = num_training_img\/batch_size\nvalidationSteps= num_validation_img\/batch_size\n\nbase_model_layers = model_4.layers[:23]\nnew_model_layers =  model_4.layers[23:]\n\nbase_model_blocks = {\n    0: base_model_layers[1:3],\n    1: base_model_layers[4:6],\n    2: base_model_layers[7:11],\n    3: base_model_layers[12:16],\n    4: base_model_layers[17:21]\n}","3602008b":"ls 'gdrive\/MyDrive\/wazzadu\/model'","cd31350d":"print(\"\\n--[Phase 1]--: Train only new layers\")\n\nfor layer in base_model_layers:\n    layer.trainable = False\n\n# Callbacks\nreduce_lr = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=10,\n                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n\nearly_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, \n                           patience=25, verbose=0, mode='max')\n\nmodel_4_path = \"gdrive\/MyDrive\/wazzadu\/model\/{}.h5\".format(\"model_4_1\")\n\ncheckpoint = ModelCheckpoint(model_4_path, monitor='val_accuracy', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\ncallbacks_list = [checkpoint,early_stopper,reduce_lr]\n    \nmodel_4.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizers.Adam(lr=0.0001), metrics=[\"accuracy\", f1_score_metric])\n\n# model_4.fit_generator(\n#     train_generator,\n#     steps_per_epoch=stepsPerEpoch,\n#     epochs=50,\n#     callbacks=callbacks_list,\n#     validation_data=validation_generator,\n#     validation_steps=validationSteps,\n#     class_weight=class_weights\n#     )\n\n# model_4.fit_generator(\n#     train_generator,\n#     # steps_per_epoch=stepsPerEpoch,\n#     epochs=50,\n#     callbacks=callbacks_list,\n#     validation_data=validation_generator\n\n#     )","c63c854f":"print(\"\\n--[Phase 2]--: Train every CNN blocks of base model (5 blocks)\")\n\n# model_4_prev_path = \"gdrive\/MyDrive\/wazzadu\/model\/model_4_1.h5\"\nmodel_4_prev_path = \"gdrive\/MyDrive\/wazzadu\/model\/model_4_2_4.h5\"\n\nprint(\"Loading the previous weight from {}.\".format(model_4_prev_path))\nmodel_4.load_weights(model_4_prev_path)\n\nfor layer in new_model_layers:\n    layer.trainable = False\n\nfor idx in range(4, 5):\n    print(idx)\n    # train idx block\n    print(\"[Train block{}]: containing {} layers\".format(idx, len(base_model_blocks[idx])))\n    \n    # Callbacks\n    reduce_lr = ReduceLROnPlateau(monitor='val_accuracy', mode='max', factor=0.1, patience=4,\n                                    verbose=1, min_delta=0.0001, cooldown=2, min_lr=0)\n    \n    early_stopper = EarlyStopping(monitor='val_accuracy', min_delta=0, \n                               patience=10, verbose=0, mode='max')\n\n    model_4_path = f\".\/gdrive\/MyDrive\/wazzadu\/model\/model_4_2_{idx}.h5\"\n    \n    checkpoint = ModelCheckpoint(model_4_path, monitor='val_accuracy', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\n    callbacks_list = [checkpoint,early_stopper,reduce_lr]\n\n    for layer in base_model_layers:\n        if layer in base_model_blocks[idx]:\n            layer.trainable = True\n            print(\"train {}\".format(layer))\n        else:\n            layer.trainable = False\n    model_4.compile(loss=\"categorical_crossentropy\",\n                  optimizer=optimizers.Adam(lr=0.000001), metrics=[\"accuracy\", f1_score_metric])\n    model_4.fit_generator(\n        train_generator,\n        steps_per_epoch=stepsPerEpoch,\n        epochs=50,\n        callbacks=callbacks_list,\n        validation_data=validation_generator,\n        validation_steps=validationSteps,\n        class_weight=class_weights\n    )","a8c6d86a":"print(\"--[Phase 3]--: Train all layers\")\n\nfor layer in model_4.layers:\n    layer.trainable = True\n\n# Callbacks\n\nreduce_lr = ReduceLROnPlateau(monitor='val_f1_score_metric', mode='max', factor=0.1, patience=10,\n                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\n\nearly_stopper = EarlyStopping(monitor='val_f1_score_metric', min_delta=0, \n                           patience=30, verbose=0, mode='max')\n\nmodel_4_path = \"gdrive\/MyDrive\/wazzadu\/model\/{}.h5\".format(\"model_4\")\n\ncheckpoint = ModelCheckpoint(model_4_path, monitor='val_f1_score_metric', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\ncallbacks_list = [checkpoint, early_stopper, reduce_lr]\n\n\nmodel_4.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizers.Adam(lr=0.00001), metrics=[\"accuracy\", f1_score_metric])\n\n\n# Load last epoch model\n\n# pretrined_model_4_path = \"gdrive\/MyDrive\/Super_AI_Level_2_Links\/week2.2\/\u0e42\u0e08\u0e17\u0e22\u0e4c_DENSO\/data_sets\/croped_classified_dataset\/model\/model_4_3.h5\"\n# model_4.load_weights(pretrined_model_4_path)\n\nmodel_4.fit_generator(\n    train_generator,\n    steps_per_epoch=stepsPerEpoch,\n    epochs=50,\n    callbacks=callbacks_list,\n    validation_data=validation_generator,\n    validation_steps=validationSteps,\n    class_weight=class_weights\n)","6adfa17b":"class_to_idx = train_generator.class_indices\nidx_to_class = {v: k for k, v in class_to_idx.items()}","bb0b8cda":"idx_to_class","01a265a9":"# Load the best model\n\nmodel_4_path = \".\/gdrive\/MyDrive\/wazzadu\/model\/{}.h5\".format(\"model_4\")\nmodel_4.load_weights(model_4_path)","22299376":"pred_class_list = []\npred_label_list = []\nfile_list = []\nfor file in glob.glob(\"gdrive\/MyDrive\/wazzadu\/val\/*.jpg\"):\n    inputShape = (image_size,image_size)\n    image = load_img(file, target_size=inputShape)\n    image1 = load_img(file, target_size=inputShape)\n    image = img_to_array(image)\n    image = preprocess_input(image)\n    image = np.expand_dims(image, axis=0)\n\n    preds = model_4.predict(image)\n\n    pred_class = np.argmax(preds)\n    pred_label = idx_to_class[pred_class]\n    pred_label_list.append(pred_label)\n    file_list.append(os.path.splitext(os.path.basename(file))[0])\n\n    title = 'filename : {}, Prediction :{}, confidence : {:.3f}'.format(\n        os.path.basename(file),\n        pred_label,\n        preds[0][pred_class])\n    \n    # print(title)\n    plt.figure(figsize=[3,3])\n    plt.axis('off')\n    plt.title(title)\n    plt.imshow(image1)\n    plt.show()","cf1e7ae0":"import pandas as pd\nb = pd.DataFrame(pred_label_list)\nc = pd.DataFrame(file_list)\n\nresult = pd.concat([c, b], axis=1).reindex(b.index)\nresult.columns = ['id', 'Answer']","52cca9be":"csv = result.sort_values(by=['id'])\ncsv","d7d7e575":"csv.to_csv('.\/VGG16_result.csv')","4b5d48f1":"## Data preprocessing\n\nRead training and validation dataset\n- Data augmentation strategies using ImageDataGenerator","7e31454c":"<details>\n    <summary>SOLUTION HERE!<\/summary>\n    <pre>\n        <code>\n\nfor layer in model_4.layers:\n    layer.trainable = True\n\n# Callbacks\nreduce_lr = ReduceLROnPlateau(monitor='val_f1_score_metric', mode='max', factor=0.1, patience=10,\n                                verbose=1, min_delta=0.0001, cooldown=5, min_lr=0)\nearly_stopper = EarlyStopping(monitor='val_f1_score_metric', min_delta=0, \n                           patience=30, verbose=0, mode='max')\nmodel_4_path = \".\/model\/lab3_1\/{}.h5\".format(\"model_4\")\ncheckpoint = ModelCheckpoint(model_4_path, monitor='val_f1_score_metric', verbose=1,save_best_only=True,save_weights_only=False, mode='max',period=1)\ncallbacks_list = [checkpoint, early_stopper, reduce_lr]\n\nmodel_4.compile(loss=\"categorical_crossentropy\",\n              optimizer=optimizers.Adam(lr=0.00001), metrics=[\"accuracy\", f1_score_metric])\n\n# Load last epoch model\npretrined_model_4_path = \".\/model\/const_models\/lab3_1\/model_4_3.h5\"\nmodel_4.load_weights(pretrined_model_4_path)\n\nmodel_4.fit_generator(\n    train_generator,\n    steps_per_epoch=stepsPerEpoch,\n    epochs=5,\n    callbacks=callbacks_list,\n    validation_data=validation_generator,\n    validation_steps=validationSteps\n)\n        <\/code>\n    <\/pre>\n<\/details>","510716b0":"Define f1_score metric for evaluating model ","42e0fd7b":"## Evaluation\n-  `F-score` is really useful if you want to compare 2 classifiers. It is computed using the harmonic mean of precision and recall, and gives much more weight to low values. As a result of that, the classifier will only get a high F-score, if both recall and precision are high. You can easily compute the F-Score with sklearn.\n- `Micro F1-score` is to calculate metrics globally by counting the total true positives, false negatives and false positives, while \n- `Macro F1-score` is to calculate metrics for each label, and find their unweighted mean. This does not take label imbalance into account.","0c3048d4":"## Model \n- VGG (pre-trained weights) + 2 Dense layers + Output layer\n- use `Chain-thaw` Fine-tuning technique, referenced by [Using millions of emoji occurrences to learn any-domain representations for detecting sentiment, emotion and sarcasm](https:\/\/arxiv.org\/pdf\/1708.00524.pdf).","7c353572":"## Result\nto see how the model perform by testing sample visualized by matplotlib."}}