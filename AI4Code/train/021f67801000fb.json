{"cell_type":{"299400aa":"code","886f6d63":"code","babd6914":"code","f0f5acba":"code","941d6a5f":"code","7f41e1dc":"code","372221d9":"code","516d134e":"code","7db22b61":"code","352d5861":"code","19288fef":"code","2d73e1dd":"code","3e2800ab":"markdown","b4c6cc46":"markdown","be4b61eb":"markdown","af70741a":"markdown","afc02f85":"markdown","9c8b9c64":"markdown"},"source":{"299400aa":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nfrom catboost import CatBoostClassifier\nfrom sklearn.impute import SimpleImputer \nfrom tqdm.notebook import tqdm \nfrom colorama import Fore,Style\nfrom sklearn.metrics import mean_squared_error,roc_auc_score\nfrom sklearn.model_selection import train_test_split,StratifiedKFold","886f6d63":"train = pd.read_csv(\"..\/input\/song-popularity-prediction\/train.csv\")\ntest = pd.read_csv(\"..\/input\/song-popularity-prediction\/test.csv\")","babd6914":"train[\"istest\"] = 0\ntest[\"istest\"] = 1","f0f5acba":"combine_df = pd.concat([train, test]) ","941d6a5f":"imputer = SimpleImputer(strategy='median')\nim_combine = pd.DataFrame(imputer.fit_transform(combine_df))\nim_combine.columns = combine_df.columns","7f41e1dc":"combine_df = im_combine\ncombine_df.isna().sum()","372221d9":"\n# deopping song popularity column and ID column\ncombine_df = combine_df.drop([\"song_popularity\",\"id\"], axis = 1)\n","516d134e":"combine_df","7db22b61":"# splitting for our classifier model \nX_train, X_test, y_train, y_test = train_test_split( combine_df.drop(\"istest\",axis = 1),combine_df[\"istest\"] , test_size=0.33, random_state=42)","352d5861":"X_train.shape, X_test.shape, y_train.shape, y_test.shape","19288fef":"\nauc_score_val = []\nauc_score_test = []\ntargets = combine_df['istest'].values\n# getting stratified k fold \nkf = StratifiedKFold(n_splits = 5, shuffle=True, random_state=42)   \n\n\nfor f, (train_idx, val_idx) in tqdm(enumerate(kf.split(X=X_train, y=y_train)),total = 5):\n        train_data , val_data = X_train.iloc[train_idx] , X_train.iloc[val_idx]\n        train_target, val_target = y_train.iloc[train_idx], y_train.iloc[val_idx]\n        model = CatBoostClassifier(loss_function='CrossEntropy',\n                         verbose = 500 ,\n                        eval_metric='AUC',\n                        iterations=5000)\n        model.fit(\n            train_data, \n            train_target,\n            eval_set=[(val_data, val_target)],\n            early_stopping_rounds=300,\n            verbose=500\n        )\n        oof_temp = model.predict_proba(val_data)[:,1]\n        test_temp = model.predict_proba(X_test)[:,1]\n        val_auc = roc_auc_score(val_target, oof_temp)\n        auc_score_val.append(val_auc)\n        test_auc = roc_auc_score(y_test, test_temp)\n        auc_score_test.append(test_auc)\n        print(Fore.GREEN + f'(CATBOOST) FOLD: {f} ValAUC: {val_auc} ValMeanAUC: {np.mean(auc_score_val)} TestAUC: {test_auc} TestMeanAUC: {np.mean(auc_score_test)}' + Style.RESET_ALL)\n        \n","2d73e1dd":"plt.figure()\nplt.plot(auc_score_val, label = \"auc_score_val\")\nplt.plot(auc_score_test, label = \"auc_score_test\")\nplt.legend()\nplt.xlabel(\"Folds\")\nplt.ylabel(\"AUC score \")","3e2800ab":"# Modeling\n## steps \n1. Filling the NA values with `SimpleImputer`\n2. Training Catboost classifier with label as istest and other columns as features  ","b4c6cc46":"## Creating combined dataframe with train and test combined ","be4b61eb":"# From the above analysis we can see that the AUC values are lieing in 0.49 to 0.510 so we can state that train and test data is quite similar :) ","af70741a":"# Importing required libraries","afc02f85":"# Reading dataframes ","9c8b9c64":"# How similar train data to the test data is? \n## approach: \n* giving the train values as label 0 \n* giving test values as label 1 \n* creating model for determining if the value is train or is it test \n* calculating ROC score \n\n## what does this tell us? \nIf the AUC score is 0.5 then we can say that our model really confused and train data is really similar to the test data "}}