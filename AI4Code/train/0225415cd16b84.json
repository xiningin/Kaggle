{"cell_type":{"f236007c":"code","88d0023f":"code","6daa186a":"code","137ee4ea":"code","9790f766":"code","7785844b":"code","478ef2be":"code","cc6bed71":"code","4f9b7ae2":"code","c7b951f8":"code","d65c979c":"code","1915cba9":"code","29d8936c":"code","3d13d5b7":"code","20232416":"code","81dfd2a8":"code","536e29e1":"code","fea22cb0":"code","f4a58c28":"code","07273b75":"code","cb56c7e6":"code","a9a412c9":"code","b2ec66dd":"code","52367cb9":"code","7383620c":"code","705d0821":"code","34db4d33":"code","bb86737c":"code","23f8bada":"markdown","56ccbb0f":"markdown","e3b5d457":"markdown","b108f9a4":"markdown","e780c5a3":"markdown","38819394":"markdown","386bc050":"markdown","3e7ec055":"markdown","1fd01531":"markdown","1b92f649":"markdown","f781e75e":"markdown","3fe3aa9c":"markdown","a9e78b93":"markdown","65996dbc":"markdown","38753c93":"markdown","2b2e015d":"markdown"},"source":{"f236007c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","88d0023f":"print(\"Size of Spam Data:\", len(os.listdir('\/kaggle\/input\/ham-and-spam-dataset\/hamnspam\/spam\/')))\nprint(\"Size of Ham Data:\", len(os.listdir('\/kaggle\/input\/ham-and-spam-dataset\/hamnspam\/ham\/')))","6daa186a":"path = '\/kaggle\/input\/ham-and-spam-dataset\/hamnspam\/'\nmails = []\nlabels = []\n\nfor label in ['ham\/', 'spam\/']:\n#     filenames = os.listdir(os.path.join(path, label))\n    filenames = os.listdir(path + label)\n    for file in filenames:\n        f = open((path + label + file), 'r', encoding = 'latin-1')\n        bolk = f.read()\n        mails.append(bolk)\n        labels.append(label)\n        \ndf = pd.DataFrame({'emails': mails, 'labels': labels})","137ee4ea":"mails[1]","9790f766":"labels[1]","7785844b":"df","478ef2be":"from sklearn.preprocessing import LabelEncoder\nencoder = LabelEncoder()\ndf['labels'] = encoder.fit_transform(df['labels'])","cc6bed71":"df.isnull().sum()","4f9b7ae2":"df['emails'] = df['emails'].apply(lambda x:x.lower())","c7b951f8":"df","d65c979c":"df['emails'] = df['emails'].apply(lambda x: x.replace('\\n', ' '))\ndf['emails'] = df['emails'].apply(lambda x: x.replace('\\t', ' '))","1915cba9":"df","29d8936c":"import nltk\nimport re\nfrom nltk.stem import PorterStemmer\nfrom nltk.corpus import stopwords","3d13d5b7":"ps = PorterStemmer()","20232416":"corpus = []","81dfd2a8":"for i in range(len(df)):\n    \n    ## Becuase of removed duplicated entries...\n    \n    review = re.sub('[^a-zA-Z]', ' ', df['emails'][i])\n    review = review.split()\n    review = [ps.stem(word) for word in review if word not in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","536e29e1":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features = 2500)\nX = cv.fit_transform(corpus).toarray()\ny = df['labels']","fea22cb0":"from sklearn.model_selection import train_test_split","f4a58c28":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)","07273b75":"from sklearn.naive_bayes import MultinomialNB\nmodel = MultinomialNB()","cb56c7e6":"model.fit(X_train, y_train)","a9a412c9":"y_pred = model.predict(X_test)","b2ec66dd":"from sklearn.metrics import accuracy_score","52367cb9":"accuracy = accuracy_score(y_test, y_pred)","7383620c":"accuracy","705d0821":"from sklearn.metrics import confusion_matrix","34db4d33":"CM = confusion_matrix(y_test, y_pred)","bb86737c":"CM","23f8bada":"# Preparing the raw data and convert into DataFrame format.","56ccbb0f":"# Let's see how many NaNs are there to spoil the data...","e3b5d457":"# Splitting the Data","b108f9a4":"# Corpus is where all the processed data will be stored.","e780c5a3":"# Converting the data into lower case.","38819394":"# Check Accuracy","386bc050":"# Wait.....","3e7ec055":"# Using MultiNomial Naive Bayes as the Model","1fd01531":"# #1 Removing all special charactors and numbers\n# #2 Using Stemming here to reduce the data and make more sensible.\n","1b92f649":"# Using Bag of Words approach for Data Preparation.","f781e75e":"# Check the Confusion Matrix","3fe3aa9c":"## Defining Porter Stemmer for future use.","a9e78b93":"# Converting the labels 'ham\/' and 'spam\/' to 0 and 1.","65996dbc":"# Replacing '\\n' and '\\t' with ' ' for cleaning.","38753c93":"# Sample:","2b2e015d":"# Let's see the size of the distribution of the data."}}