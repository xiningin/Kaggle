{"cell_type":{"48ce54a3":"code","c882367a":"code","8ca7aa13":"code","0f8a5167":"code","89f45fa4":"code","d16725be":"code","3b979c1f":"code","a14b5f5b":"code","62006776":"code","65f0a69c":"code","2fb152fa":"code","c8ef3e36":"code","7d352176":"code","fb463d23":"code","54d4b42a":"code","a87b5a87":"code","598d9906":"code","82b92521":"code","22f176b3":"code","69de4111":"code","b2bd67a1":"code","d4d9b1f2":"code","62254351":"code","f154daf0":"code","cdb794b7":"code","99391473":"code","94fcd1bc":"code","3de58334":"code","2174121a":"code","8eb14b23":"code","a399832e":"code","ddecdb52":"code","b6ef9b7a":"code","ec0a7833":"code","ef5ba4eb":"code","b07c270b":"markdown","c3838922":"markdown","2bfc7abb":"markdown","6af6dc14":"markdown","041eb8fe":"markdown","9e2923ce":"markdown","23def57d":"markdown","32574e79":"markdown","a5d3315d":"markdown","71216136":"markdown","e277ffdc":"markdown","62e3151c":"markdown","f1c64018":"markdown","c2f1ea9a":"markdown"},"source":{"48ce54a3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c882367a":"adult_df = pd.read_csv(\"..\/input\/adult-census-income\/adult.csv\")","8ca7aa13":"adult_df.isnull().sum()","0f8a5167":"adult_df.describe()","89f45fa4":"adult_df.head(10)\n#here we get that null values are represented with \"?\"","d16725be":"adult_df = adult_df.replace(\"?\",np.NaN)","3b979c1f":"adult_df.isnull().sum()","a14b5f5b":"adult_df.info()","62006776":"#Converting object type data to category\nadult_df[['workclass', 'education', 'marital.status','occupation','relationship','race','sex','native.country','income']].apply(lambda x: x.astype('category'))","65f0a69c":"#Category: Missing values imputation using SimpleImputer as Imputer class is deprecated\nfrom sklearn.impute import SimpleImputer\nimputer = SimpleImputer(missing_values = np.nan, strategy=\"most_frequent\")\nadult_df_category = adult_df[['workclass','occupation','native.country']]\nimputer = imputer.fit(adult_df_category[['workclass','occupation','native.country']])\nadult_df_category = imputer.transform(adult_df_category[['workclass','occupation','native.country']])\nadult_df_category = pd.DataFrame(data=adult_df_category , columns=[['workclass','occupation','native.country']])\nadult_df_category.head()","2fb152fa":"#Numeric: Missing values imputation using SimpleImputer as Imputer class is deprecated\nimputer1 = SimpleImputer(missing_values = np.nan, strategy=\"mean\")\nadult_df_numeric = adult_df[['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week']]\nimputer1 = imputer1.fit(adult_df_numeric[['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week']])\nadult_df_numeric = imputer1.transform(adult_df_numeric[['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week']])\nadult_df_numeric = pd.DataFrame(data=adult_df_numeric , columns=[['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week']])","c8ef3e36":"#merging back to original dataframe\nadult_df[['workclass','occupation','native.country']] = adult_df_category[['workclass','occupation','native.country']]\nadult_df[['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week']] = adult_df_numeric[['age','fnlwgt','education.num','capital.gain','capital.loss','hours.per.week']]","7d352176":"import seaborn as sns\ncategorical_attributes = adult_df[['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country', 'income']]\n\nfor i, attribute in enumerate(categorical_attributes):\n    # Set the width and height of the figure\n    plt.figure(figsize=(16,6))\n    plt.figure(i)\n    sns.countplot(categorical_attributes[attribute])\n    plt.xticks(rotation=90)","fb463d23":"X = adult_df.drop(['income'], axis=1)\ny = adult_df['income']\n# here Y variable is binary >=50, <=50","54d4b42a":"y.replace(('<=50K', '>50K'), (0, 1), inplace = True)","a87b5a87":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 0)","598d9906":"from sklearn import preprocessing\ncategorical_variables = ['workclass', 'education', 'marital.status', 'occupation', 'relationship', 'race', 'sex', 'native.country']\nfor feature in categorical_variables:\n        le = preprocessing.LabelEncoder()\n        X_train[feature] = le.fit_transform(X_train[feature])\n        X_test[feature] = le.transform(X_test[feature])","82b92521":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\n\ncols = X_train.columns\n\ntemp_train = X_train.copy()\ntemp_test = X_test.copy()\n\nX_train = pd.DataFrame(scaler.fit_transform(X_train), columns = cols)\nX_test = pd.DataFrame(scaler.fit_transform(X_test), columns = cols)\n\nprint(X_train.head())\nprint(\"----------------------------------------------------------------------------\")\nprint(X_test.head())","22f176b3":"from sklearn.naive_bayes import GaussianNB\ngnb = GaussianNB()\ngnb.fit(X_train, y_train)\ny_pred_gaussian = gnb.predict(X_test)","69de4111":"from sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nprint(\"CONFUSION MATRIX:\\n\")\nprint(confusion_matrix(y_test, y_pred_gaussian),\"\\n\\n\")\nprint(\"Accuracy of gaussian:\\n\")\nprint(accuracy_score(y_test, y_pred_gaussian))","b2bd67a1":"from sklearn.naive_bayes import BernoulliNB\nbnb = BernoulliNB()\nbnb.fit(X_train, y_train)\ny_pred_bernoulli = bnb.predict(X_test)","d4d9b1f2":"print(\"CONFUSION MATRIX:\\n\")\nprint(confusion_matrix(y_test, y_pred_bernoulli),\"\\n\\n\")\nprint(\"Accuracy of gaussian:\\n\")\nprint(accuracy_score(y_test, y_pred_bernoulli))","62254351":"from sklearn.preprocessing import MinMaxScaler\nminmax = MinMaxScaler()\n\nX_train_minmax = pd.DataFrame(minmax.fit_transform(temp_train), columns = X.columns)\n\nX_test_minmax = pd.DataFrame(minmax.transform(temp_test), columns = X.columns)","f154daf0":"from sklearn.naive_bayes import MultinomialNB\nmnb = MultinomialNB()\nmnb.fit(X_train_minmax, y_train)\ny_pred_multinomial = mnb.predict(X_test_minmax)","cdb794b7":"print(\"CONFUSION MATRIX:\\n\")\nprint(confusion_matrix(y_test, y_pred_multinomial),\"\\n\\n\")\nprint(\"Accuracy of gaussian:\\n\")\nprint(accuracy_score(y_test, y_pred_multinomial))","99391473":"# Visualising the Training set results\ndef plot_decisionboundary(classifier_plt, xx, yy):\n    colors = \"rgb\"\n    Z = classifier_plt.predict(np.c_[xx.ravel(), yy.ravel()])\n    pd.DataFrame(Z,columns=['hi'])['hi'].value_counts()\n    Z = Z.reshape(xx.shape)\n    plt.figure(figsize=(10,5))\n    plt.subplot(1,2,1)\n    cs = plt.contourf(xx,yy,  Z, cmap = ListedColormap(('red', 'green', 'blue', 'yellow')))\n    plt.subplot(1,2,2)\n    cs = plt.contourf(xx,yy,  Z, cmap = ListedColormap(('red', 'green', 'blue', 'yellow')))\n\n\n    # Plot also the training points\n    for i, color in zip(classifier_plt.classes_, colors):\n        idx = np.where(y_train == i)\n        plt.subplot(1,2,1)\n        plt.scatter(X_train.values[idx, 0], X_train.values[idx, 1], c=color, label=['0', '1'][i],cmap = ListedColormap(('red', 'green', 'blue', 'yellow')), edgecolor='black', s=20)\n        plt.axis('tight')\n        plt.subplot(1,2,2)\n        idx = np.where(y_test == i)\n        plt.scatter(X_test.values[idx, 0], X_test.values[idx, 1], c=color, label=['0', '1'][i],cmap = ListedColormap(('red', 'green', 'blue', 'yellow')), edgecolor='black', s=20)\n\n    plt.title(\"Plot the decision boundary, visualize training and test results\")\n    plt.legend()","94fcd1bc":"from matplotlib.colors import ListedColormap\n","3de58334":"h = 0.01 # step size in the mesh\nx = 1\n\nx1_min, x1_max = X_train.values[:, 0].min() - x, X_train.values[:, 0].max() + x\ny1_min, y1_max = X_train.values[:, 1].min() - x, X_train.values[:, 1].max() + x\n\nxx1, yy1 = np.meshgrid(np.arange(x1_min, x1_max, h), np.arange(y1_min, y1_max, h))\n","2174121a":"gnb_t = GaussianNB()\ngnb_t.fit(X_train.values[:, :2], y_train)\nplot_decisionboundary(gnb_t, xx1, yy1)","8eb14b23":"bnb_t = BernoulliNB()\nbnb_t.fit(X_train.values[:, [2, 11]], y_train)\nplot_decisionboundary(bnb_t, xx1, yy1)","a399832e":"mnb_t = MultinomialNB()\nmnb_t.fit(X_train_minmax.values[:, :2], y_train)\nplot_decisionboundary(mnb_t, xx1, yy1)","ddecdb52":"y_pred_gaussian.shape","b6ef9b7a":"y_pred_gaussian\ny_pred_bernoulli\ny_pred_multinomial\ny_test.values","ec0a7833":"dataset = pd.DataFrame({'Actual': y_test.values[:,], 'Gaussian_Predicted': y_pred_gaussian[:,], 'Bernoulli_Predicted': y_pred_bernoulli[:, ], 'Multinomial_Predicted': y_pred_multinomial[:, ]})","ef5ba4eb":"dataset.to_csv('\/kaggle\/working\/output_test.csv')","b07c270b":"**1. Import the csv dataset from https:\/\/www.kaggle.com\/uciml\/adult-census-income**","c3838922":"MultinomialNB model does not takes negative values so we are changing the scaling technique to min-max scaling which changes the values to positive, in range [0,1].","2bfc7abb":"<h3>**5(c).MultinomialNB  model**<\/h3>","6af6dc14":"<h3>**5(b).BernoulliNB model**<\/h3>","041eb8fe":"### Create an output .csv file consisting actual Test set values of Y (column name: Actual) and Predictions of Y(column name: Predicted). (1 points)","9e2923ce":"**4. Split the data into training set and testing set**","23def57d":"<h3>**5(a).GaussianNB model**<\/h3>","32574e79":"<h3>**Accuracy and Confusion matrix for BernoulliNB**<\/h3>","a5d3315d":"<h3>**Scaling variables using StandardScalar **<\/h3>","71216136":"**3. Extract X as all columns except the Income column and Y as Income column**","e277ffdc":"**2. Identify the presence of missing values, fill the missing values with mean for numerical attributes and mode value for categorical attributes.**","62e3151c":"**<h2>MODEL BUILDING <\/h2>**","f1c64018":"<h3>**Accuracy and Confusion matrix for GaussianNB**<\/h3>","c2f1ea9a":"<h3>**Feature Engineering**<\/h3>\n\nEncoding Categorical Values"}}