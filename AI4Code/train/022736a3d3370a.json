{"cell_type":{"a0d0b68a":"code","14773335":"code","68998f49":"code","47d85fbc":"code","9f60b713":"code","4a3b9be9":"code","29942915":"code","69c4d752":"code","3b6b34f7":"code","a58695ce":"code","defc9546":"markdown","b7b97a08":"markdown","9fe66864":"markdown","3b311b03":"markdown","b9b2d1b3":"markdown","a5a715a6":"markdown","4e2ff3ef":"markdown","1321a2b5":"markdown","09f4bdfc":"markdown","72804029":"markdown","525d65be":"markdown","e2508990":"markdown","6029ced4":"markdown","f7d859d4":"markdown","5a577902":"markdown","3251d7df":"markdown","58fdc2b6":"markdown"},"source":{"a0d0b68a":"! ls ..\/input\/severstalmodels","14773335":"! python ..\/input\/mlcomp\/mlcomp\/mlcomp\/setup.py","68998f49":"import warnings\nwarnings.filterwarnings('ignore')\nimport os\nimport matplotlib.pyplot as plt\n\nimport numpy as np\nimport cv2\nimport albumentations as A\nfrom tqdm import tqdm_notebook\nimport pandas as pd\n\nimport torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader\nfrom torch.jit import load\n\nfrom mlcomp.contrib.transform.albumentations import ChannelTranspose\nfrom mlcomp.contrib.dataset.classify import ImageDataset\nfrom mlcomp.contrib.transform.rle import rle2mask, mask2rle\nfrom mlcomp.contrib.transform.tta import TtaWrap","47d85fbc":"unet_se_resnext50_32x4d = \\\n    load('\/kaggle\/input\/severstalmodels\/unet_se_resnext50_32x4d.pth').cuda()\nunet_mobilenet2 = load('\/kaggle\/input\/severstalmodels\/unet_mobilenet2.pth').cuda()\nunet_resnet34 = load('\/kaggle\/input\/severstalmodels\/unet_resnet34.pth').cuda()","9f60b713":"class Model:\n    def __init__(self, models):\n        self.models = models\n    \n    def __call__(self, x):\n        res = []\n        x = x.cuda()\n        with torch.no_grad():\n            for m in self.models:\n                res.append(m(x))\n        res = torch.stack(res)\n        return torch.mean(res, dim=0)\n\nmodel = Model([unet_se_resnext50_32x4d, unet_mobilenet2, unet_resnet34])","4a3b9be9":"def create_transforms(additional):\n    res = list(additional)\n    # add necessary transformations\n    res.extend([\n        A.Normalize(\n            mean=(0.485, 0.456, 0.406), std=(0.230, 0.225, 0.223)\n        ),\n        ChannelTranspose()\n    ])\n    res = A.Compose(res)\n    return res\n\nimg_folder = '\/kaggle\/input\/severstal-steel-defect-detection\/test_images'\nbatch_size = 2\nnum_workers = 0\n\n# Different transforms for TTA wrapper\ntransforms = [\n    [],\n    [A.HorizontalFlip(p=1)]\n]\n\ntransforms = [create_transforms(t) for t in transforms]\ndatasets = [TtaWrap(ImageDataset(img_folder=img_folder, transforms=t), tfms=t) for t in transforms]\nloaders = [DataLoader(d, num_workers=num_workers, batch_size=batch_size, shuffle=False) for d in datasets]","29942915":"thresholds = [0.5, 0.5, 0.5, 0.5]\nmin_area = [600, 600, 1000, 2000]\n\nres = []\n# Iterate over all TTA loaders\ntotal = len(datasets[0])\/\/batch_size\nfor loaders_batch in tqdm_notebook(zip(*loaders), total=total):\n    preds = []\n    image_file = []\n    for i, batch in enumerate(loaders_batch):\n        features = batch['features'].cuda()\n        p = torch.sigmoid(model(features))\n        # inverse operations for TTA\n        p = datasets[i].inverse(p)\n        preds.append(p)\n        image_file = batch['image_file']\n    \n    # TTA mean\n    preds = torch.stack(preds)\n    preds = torch.mean(preds, dim=0)\n    preds = preds.detach().cpu().numpy()\n    \n    # Batch post processing\n    for p, file in zip(preds, image_file):\n        file = os.path.basename(file)\n        # Image postprocessing\n        for i in range(4):\n            p_channel = p[i]\n            imageid_classid = file+'_'+str(i+1)\n            p_channel = (p_channel>thresholds[i]).astype(np.uint8)\n            if p_channel.sum() < min_area[i]:\n                p_channel = np.zeros(p_channel.shape, dtype=p_channel.dtype)\n\n            res.append({\n                'ImageId_ClassId': imageid_classid,\n                'EncodedPixels': mask2rle(p_channel)\n            })\n        \ndf = pd.DataFrame(res)\ndf.to_csv('submission.csv', index=False)\t","69c4d752":"df = pd.DataFrame(res)\ndf = df.fillna('')\ndf.to_csv('submission.csv', index=False)","3b6b34f7":"df['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['Class'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[1])\ndf['empty'] = df['EncodedPixels'].map(lambda x: not x)\ndf[df['empty'] == False]['Class'].value_counts()","a58695ce":"%matplotlib inline\n\ndf = pd.read_csv('submission.csv')[:40]\ndf['Image'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[0])\ndf['Class'] = df['ImageId_ClassId'].map(lambda x: x.split('_')[1])\n\nfor row in df.itertuples():\n    img_path = os.path.join(img_folder, row.Image)\n    img = cv2.imread(img_path)\n    mask = rle2mask(row.EncodedPixels, (1600, 256)) \\\n        if isinstance(row.EncodedPixels, str) else np.zeros((256, 1600))\n    if mask.sum() == 0:\n        continue\n    \n    fig, axes = plt.subplots(1, 2, figsize=(20, 60))\n    axes[0].imshow(img\/255)\n    axes[1].imshow(mask*60)\n    axes[0].set_title(row.Image)\n    axes[1].set_title(row.Class)\n    plt.show()","defc9546":"As the competition does not allow commit with the kernel that uses internet connection, we use offline installation","b7b97a08":"### Visualization","9fe66864":"### Install MLComp library(offline version):","3b311b03":"### Import required libraries","b9b2d1b3":"### Models' mean aggregator","a5a715a6":"### Loaders' mean aggregator","4e2ff3ef":"Approach descripton:\n\n1. Segmentation via 3 Unet networks. The predictions are being averaged. \n\n2. Thresholding and removeing small areas. This method gives 0.90672 on public LB.\n\n**Improving**:\n\n1. As many participations have seen, that is the key to remove false positives from your predictions.\n\n2. To cope with that, a classification network may be used. \n\n3. Heng CherKeng posted a classifier here: https:\/\/www.kaggle.com\/c\/severstal-steel-defect-detection\/discussion\/106462#latest-634450 resent34_cls_01, **if you remove false positives with it you should get 0.9117 on LB**","1321a2b5":"This kernel demonstrates:\n\n1. Results of training models with [the training kernel](https:\/\/www.kaggle.com\/lightforever\/severstal-mlcomp-catalyst-train-0-90672-offline) and achieves 0.90672 score on public LB\n\n2. Useful code in MLComp library: TtaWrapp, ImageDataset, ChannelTranspose, rle utilities\n\n3. Output statistics and basic visualization","09f4bdfc":"Catalyst allows to trace models. That is an extremely useful features in Pytorch since 1.0 version: \n\nhttps:\/\/pytorch.org\/docs\/stable\/jit.html\n\nNow we can load models without re-defining them","72804029":"Histogram of predictions","525d65be":"About the libraries:\n\n1. [MLComp](https:\/\/github.com\/catalyst-team\/mlcomp) is a distributed DAG  (Directed acyclic graph)  framework for machine learning with UI. It helps to train, manipulate, and visualize. All models in this kernel were trained offline via MLComp + Catalyst libraries. \n\nYou can control an execution process via Web-site\n\nDags\n![Dags](https:\/\/github.com\/catalyst-team\/mlcomp\/blob\/master\/docs\/imgs\/dags.png?raw=true)\n\nComputers\n![Computers](https:\/\/github.com\/catalyst-team\/mlcomp\/blob\/master\/docs\/imgs\/computers.png?raw=true)\n\nReports\n![Reports](https:\/\/github.com\/catalyst-team\/mlcomp\/blob\/master\/docs\/imgs\/reports.png?raw=true)\n\nCode\n![Code](https:\/\/github.com\/catalyst-team\/mlcomp\/blob\/master\/docs\/imgs\/code.png?raw=true)\n\nPlease follow [the web site](https:\/\/github.com\/catalyst-team\/mlcomp) to get the details.\n\nhttps:\/\/github.com\/catalyst-team\/mlcomp\n\n2. Catalys: High-level utils for PyTorch DL & RL research. It was developed with a focus on reproducibility, fast experimentation and code\/ideas reusing. Being able to research\/develop something new, rather then write another regular train loop. Break the cycle - use the Catalyst!\n\nhttps:\/\/github.com\/catalyst-team\/catalyst\n\nDocs and examples\n- Detailed [classification tutorial](https:\/\/github.com\/catalyst-team\/catalyst\/blob\/master\/examples\/notebooks\/classification-tutorial.ipynb) [![Open In Colab](https:\/\/colab.research.google.com\/assets\/colab-badge.svg)](https:\/\/colab.research.google.com\/github\/catalyst-team\/catalyst\/blob\/master\/examples\/notebooks\/classification-tutorial.ipynb)\n- Comprehensive [classification pipeline](https:\/\/github.com\/catalyst-team\/classification).\n\nAPI documentation and an overview of the library can be found here\n[![Docs](https:\/\/img.shields.io\/badge\/dynamic\/json.svg?label=docs&url=https%3A%2F%2Fpypi.org%2Fpypi%2Fcatalyst%2Fjson&query=%24.info.version&colorB=brightgreen&prefix=v)](https:\/\/catalyst-team.github.io\/catalyst\/index.html)","e2508990":"This is another option to enhance the score on public test dataset - due to a small change of the normalization parameters in the inference kernel (score increased from 0.90672 to 0.90726). It can be considered as an opportunity to increase variability in the choice of two final submissions (who knows...) or as a way to improve mood up to the final deadline at least. :-)","6029ced4":"Save predictions","f7d859d4":"![MLComp](https:\/\/raw.githubusercontent.com\/catalyst-team\/catalyst-pics\/master\/pics\/MLcomp.png)\n![Catalyst](https:\/\/raw.githubusercontent.com\/catalyst-team\/catalyst-pics\/master\/pics\/catalyst_logo.png)","5a577902":"## This is the fork from  https:\/\/www.kaggle.com\/lightforever\/severstal-mlcomp-catalyst-infer-0-90672","3251d7df":"### Load models","58fdc2b6":"### Create TTA transforms, datasets, loaders"}}