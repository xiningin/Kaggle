{"cell_type":{"875328a6":"code","e6bcb0c3":"code","2ea9c7a4":"code","9461feb4":"code","7617a644":"code","ff46f64b":"code","82e733ca":"code","91fcae86":"code","58453b9d":"code","63ad401b":"markdown","39b547a9":"markdown","01344cd9":"markdown","684bff22":"markdown","4f166b13":"markdown","0e554622":"markdown","ff8dff99":"markdown"},"source":{"875328a6":"from keras.models import Model\nfrom keras.layers import Input, LSTM, Dense, Embedding\nfrom keras.optimizers import Adam\nimport numpy as np","e6bcb0c3":"batch_size = 64  \nepochs = 9\nlatent_dim = 256  \nembedding_size = 128\nfile_name = '..\/input\/poetry.txt'","2ea9c7a4":"input_texts = []\ntarget_texts = []\ninput_vocab = set()\ntarget_vocab = set()\nwith open(file_name, 'r', encoding='utf-8') as f:\n    lines = f.readlines()\nfor line in lines:\n    # \u5c06\u8bd7\u53e5\u7528\u9017\u53f7\u5206\u5f00\n    line_sp = line.strip().split('\uff0c')\n    # \u5982\u679c\u8bd7\u4e2d\u4e0d\u542b\u9017\u53f7\uff0c\u8fd9\u53e5\u8bd7\u6211\u4eec\u5c31\u4e0d\u7528\u4e86\n    if len(line_sp) < 2:\n        continue\n    # \u4e0a\u53e5\u4e3ainput_text\uff0c\u4e0b\u53e5\u4e3atarget_text\n    input_text, target_text = line_sp[0], line_sp[1]\n    # \u5728\u4e0b\u53e5\u524d\u540e\u5f00\u59cb\u5b57\u7b26\u548c\u7ed3\u675f\u5b57\u7b26\n    target_text = '\\t' + target_text[:-1] + '\\n'\n    input_texts.append(input_text)\n    target_texts.append(target_text)\n    # \u7edf\u8ba1\u8f93\u5165\u4fa7\u7684\u8bcd\u6c47\u8868\u548c\u8f93\u51fa\u4fa7\u7684\u8bcd\u6c47\u8868\n    for ch in input_text:\n        if ch not in input_vocab:\n            input_vocab.add(ch)\n    for ch in target_text:\n        if ch not in target_vocab:\n            target_vocab.add(ch)\n\n# \u5efa\u7acb\u5b57\u5178\u548c\u53cd\u5411\u5b57\u5178\ninput_vocab = dict([(char, i) for i, char in enumerate(input_vocab)])\ntarget_vocab = dict([(char, i) for i, char in enumerate(target_vocab)])\nreverse_input_char_index = dict((i, char) for char, i in input_vocab.items())\nreverse_target_char_index = dict((i, char) for char, i in target_vocab.items())\n\n# \u8f93\u5165\u4fa7\u8bcd\u6c47\u8868\u5927\u5c0f\nencoder_vocab_size = len(input_vocab)\n# \u6700\u957f\u8f93\u5165\u53e5\u5b50\u957f\u5ea6\nencoder_len = max([len(sentence) for sentence in input_texts])\n# \u8f93\u51fa\u4fa7\u8bcd\u6c47\u8868\u5927\u5c0f\ndecoder_vocab_size = len(target_vocab)\n# \u6700\u957f\u8f93\u51fa\u53e5\u5b50\u957f\u5ea6\ndecoder_len = max([len(sentence) for sentence in target_texts])\n\nprint(encoder_vocab_size)\nprint(encoder_len)\nprint(decoder_vocab_size)\nprint(decoder_len)","9461feb4":"encoder_input_data = np.zeros((len(input_texts), encoder_len), dtype='int')\ndecoder_input_data = np.zeros((len(input_texts), decoder_len), dtype='int')\ndecoder_target_data = np.zeros((len(input_texts), decoder_len, 1), dtype='int')\n\nfor i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n    for t, char in enumerate(input_text):\n        encoder_input_data[i, t] = input_vocab[char]\n    for t, char in enumerate(target_text):\n        decoder_input_data[i, t] = target_vocab[char]\n        if t > 0:\n            decoder_target_data[i, t - 1, 0] = target_vocab[char]\n            \nprint(encoder_input_data.shape)\nprint(decoder_input_data.shape)\nprint(decoder_target_data.shape)","7617a644":"# \u7f16\u7801\u5668\u8f93\u5165\u5c42\nencoder_inputs = Input(shape=(None,))\n# \u7f16\u7801\u5668\u8bcd\u5d4c\u5165\u5c42\nencoder_embedding = Embedding(input_dim=encoder_vocab_size, output_dim=embedding_size, trainable=True)(encoder_inputs)\n# \u7f16\u7801\u5668\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u5c42\nencoder = LSTM(latent_dim, return_state=True)\n# \u7f16\u7801\u5668\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u8f93\u51fa\u662f\u4e00\u4e2a\u4e09\u5143\u7ec4(encoder_outputs, state_h, state_c)\n# encoder_outputs\u662f\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u6bcf\u4e2a\u65f6\u523b\u7684\u8f93\u51fa\u6784\u6210\u7684\u5e8f\u5217\n# state_h\u548cstate_c\u662f\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u9690\u72b6\u6001\u548c\u7ec6\u80de\u72b6\u6001\nencoder_outputs, state_h, state_c = encoder(encoder_embedding)\n# \u6211\u4eec\u4f1a\u628astate_h\u548cstate_c\u4f5c\u4e3a\u89e3\u7801\u5668\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u7684\u521d\u59cb\u72b6\u6001\uff0c\u4e4b\u524d\u6211\u4eec\u6240\u8bf4\u7684\u72b6\u6001\u5411\u91cf\u7684\u4f20\u9012\u5c31\u662f\u8fd9\u6837\u5b9e\u73b0\u7684\nencoder_states = [state_h, state_c]\n\n# \u89e3\u7801\u5668\u7f51\u7edc\u5efa\u6784\n\n# \u89e3\u7801\u5668\u8f93\u5165\u5c42\ndecoder_inputs = Input(shape=(None,))\n# \u89e3\u7801\u5668\u8bcd\u5d4c\u5165\u5c42\ndecoder_embedding = Embedding(input_dim=decoder_vocab_size, output_dim=embedding_size, trainable=True)(decoder_inputs)\n# \u89e3\u7801\u5668\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u5c42\ndecoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n# \u89e3\u7801\u5668\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u7684\u8f93\u51fa\u4e5f\u662f\u4e09\u5143\u7ec4\uff0c\u4f46\u6211\u4eec\u53ea\u5173\u5fc3\u4e09\u5143\u7ec4\u7684\u7b2c\u4e00\u7ef4\uff0c\u540c\u65f6\u6211\u4eec\u5728\u8fd9\u91cc\u8bbe\u7f6e\u4e86\u89e3\u7801\u5668\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u7684\u521d\u59cb\u72b6\u6001\ndecoder_outputs, _, _ = decoder_lstm(decoder_embedding, initial_state=encoder_states)\n# \u89e3\u7801\u5668\u8f93\u51fa\u7ecf\u8fc7\u4e00\u4e2a\u9690\u5c42softmax\u53d8\u6362\u8f6c\u6362\u4e3a\u5bf9\u5404\u7c7b\u522b\u7684\u6982\u7387\u4f30\u8ba1\ndecoder_dense = Dense(decoder_vocab_size, activation='softmax')\n# \u89e3\u7801\u5668\u8f93\u51fa\u5c42\ndecoder_outputs = decoder_dense(decoder_outputs)\n# \u603b\u6a21\u578b\uff0c\u63a5\u53d7\u7f16\u7801\u5668\u548c\u89e3\u7801\u5668\u8f93\u5165\uff0c\u5f97\u5230\u89e3\u7801\u5668\u957f\u77ed\u671f\u8bb0\u5fc6\u7f51\u7edc\u8f93\u51fa\nmodel = Model([encoder_inputs, decoder_inputs], decoder_outputs)\nmodel.compile(optimizer=Adam(lr=0.001), loss='sparse_categorical_crossentropy')\nmodel.summary()","ff46f64b":"model.fit([encoder_input_data, decoder_input_data], decoder_target_data, batch_size=batch_size, epochs=epochs, validation_split=0.2)","82e733ca":"# \u7b2c\u4e00\u4e2a\u9ed1\u76d2\uff0c\u7f16\u7801\u5668\uff0c\u7ed9\u5b9aencoder_inputs\uff0c\u5f97\u5230encoder\u7684\u72b6\u6001\nencoder_model = Model(encoder_inputs, encoder_states)\n# \u7b2c\u4e8c\u4e2a\u9ed1\u76d2\uff0c\u89e3\u7801\u5668\n# \u89e3\u7801\u5668\u63a5\u53d7\u4e09\u4e2a\u8f93\u5165\uff0c\u4e24\u4e2a\u662f\u521d\u59cb\u72b6\u6001\uff0c\u4e00\u4e2a\u662f\u4e4b\u524d\u5df2\u7ecf\u751f\u6210\u7684\u6587\u672c\ndecoder_state_input_h = Input(shape=(latent_dim,))\ndecoder_state_input_c = Input(shape=(latent_dim,))\ndecoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n# \u89e3\u7801\u5668\u4ea7\u751f\u4e09\u4e2a\u8f93\u51fa\uff0c\u4e24\u4e2a\u5f53\u524d\u72b6\u6001\uff0c\u4e00\u4e2a\u662f\u6bcf\u4e2a\u65f6\u523b\u7684\u8f93\u51fa\uff0c\u5176\u4e2d\u6700\u540e\u4e00\u4e2a\u65f6\u523b\u7684\u8f93\u51fa\u53ef\u4ee5\u7528\u6765\u8ba1\u7b97\u4e0b\u4e00\u4e2a\u5b57\ndecoder_outputs, state_h, state_c = decoder_lstm(decoder_embedding, initial_state=decoder_states_inputs)\ndecoder_states = [state_h, state_c]\ndecoder_outputs = decoder_dense(decoder_outputs)\ndecoder_model = Model([decoder_inputs] + decoder_states_inputs, [decoder_outputs] + decoder_states)","91fcae86":"def decode_sequence(input_seq):\n    # \u5148\u628a\u4e0a\u53e5\u8f93\u5165\u7f16\u7801\u5668\u5f97\u5230\u7f16\u7801\u7684\u4e2d\u95f4\u5411\u91cf\uff0c\u8fd9\u4e2a\u4e2d\u95f4\u5411\u91cf\u5c06\u662f\u89e3\u7801\u5668\u7684\u521d\u59cb\u72b6\u6001\u5411\u91cf\n    states_value = encoder_model.predict(input_seq)\n    # \u521d\u59cb\u7684\u89e3\u7801\u5668\u8f93\u5165\u662f\u5f00\u59cb\u7b26'\\t'\n    target_seq = np.zeros((1, 1))\n    target_seq[0, 0] = target_vocab['\\t']\n\n    stop_condition = False\n    decoded_sentence = ''\n    # \u8fed\u4ee3\u89e3\u7801\n    while not stop_condition:\n        # \u628a\u5f53\u524d\u7684\u89e3\u7801\u5668\u8f93\u5165\u548c\u5f53\u524d\u7684\u89e3\u7801\u5668\u72b6\u6001\u5411\u91cf\u9001\u8fdb\u89e3\u7801\u5668\n        # \u5f97\u5230\u5bf9\u4e0b\u4e00\u4e2a\u65f6\u523b\u7684\u9884\u6d4b\u548c\u65b0\u7684\u89e3\u7801\u5668\u72b6\u6001\u5411\u91cf\n        output_tokens, h, c = decoder_model.predict([target_seq] + states_value)\n        # \u91c7\u6837\u51fa\u6982\u7387\u6700\u5927\u7684\u90a3\u4e2a\u5b57\u4f5c\u4e3a\u4e0b\u4e00\u4e2a\u65f6\u523b\u7684\u8f93\u5165\n        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n        sampled_char = reverse_target_char_index[sampled_token_index]\n        decoded_sentence += sampled_char\n        # \u5982\u679c\u91c7\u6837\u5230\u4e86\u7ed3\u675f\u7b26\u6216\u8005\u751f\u6210\u7684\u53e5\u5b50\u957f\u5ea6\u8d85\u8fc7\u4e86decoder_len\uff0c\u5c31\u505c\u6b62\u751f\u6210\n        if (sampled_char == '\\n' or len(decoded_sentence) > decoder_len):\n            stop_condition = True\n        # \u5426\u5219\u6211\u4eec\u66f4\u65b0\u4e0b\u4e00\u4e2a\u65f6\u523b\u7684\u89e3\u7801\u5668\u8f93\u5165\u548c\u89e3\u7801\u5668\u72b6\u6001\u5411\u91cf\n        target_seq = np.zeros((1, 1))\n        target_seq[0, 0] = sampled_token_index\n        states_value = [h, c]\n\n    return decoded_sentence","58453b9d":"for seq_index in range(200, 300):\n    input_seq = encoder_input_data[seq_index: seq_index + 1]\n    decoded_sentence = decode_sequence(input_seq)\n    print('-')\n    print('Input sentence:', input_texts[seq_index])\n    print('Decoded sentence:', decoded_sentence)","63ad401b":"#### \u8bad\u7ec3\u6a21\u578b","39b547a9":"#### \u5982\u679c\u6ca1\u6709\u5b89\u88c5 keras \u548c tensorflow \u5e93\n#### \u8bf7\u4f7f\u7528 pip install keras tensorflow \u5b89\u88c5\n#### \u5982\u679c\u4f7f\u7528conda\u865a\u62df\u73af\u5883\n#### \u8bf7\u4f7f\u7528conda install -c conda-forge keras\n#### conda install -c conda-forge tensorflow ","01344cd9":"#### \u8fd9\u91cc\u53ef\u80fd\u540c\u5b66\u4eec\u4f1a\u5f88\u56f0\u60d1\uff0c\u4e3a\u4ec0\u4e48\u4e0b\u9762\u8fd9\u6bb5\u4ee3\u7801\u53c8\u5728\u6784\u5efa\u6a21\u578b\uff0c\u539f\u56e0\u662fseq2seq\u5728\u8bad\u7ec3\u548c\u751f\u6210\u7684\u65f6\u5019\u5e76\u4e0d\u5b8c\u5168\u76f8\u540c\n#### \u8bad\u7ec3\u7684\u65f6\u5019\uff0c\u89e3\u7801\u5668\u662f\u6709\u9884\u5148\u8f93\u5165\u7684\uff0c\u6211\u4eec\u4f1a\u628a\u6b63\u786e\u7684\u4e0b\u53e5\u4f5c\u4e3a\u8f93\u5165\u6307\u5bfc\u89e3\u7801\u5668\u8fdb\u884c\u5b66\u4e60\uff0c\u5177\u4f53\u6765\u8bf4\uff0c\u4e0d\u7ba1\u4e0a\u4e00\u4e2a\u65f6\u523b\u89e3\u7801\u5668\u7684\u8f93\u51fa\u662f\u4ec0\u4e48\uff0c\u6211\u4eec\u90fd\u7528\u9884\u5148\u7ed9\u5b9a\u7684\u8f93\u5165\u4f5c\u4e3a\u672c\u65f6\u523b\u7684\u8f93\u5165\n#### \u8fd9\u79cd\u8bad\u7ec3\u65b9\u5f0f\u79f0\u4e3aTeacher forcing\n#### \u4f46\u662f\u5728\u751f\u6210\u7684\u65f6\u5019\uff0c\u89e3\u7801\u5668\u662f\u6ca1\u6709\u9884\u5148\u8f93\u5165\u7684\uff0c\u6211\u4eec\u4f1a\u628a\u4e0a\u4e00\u4e2a\u65f6\u523b\u89e3\u7801\u5668\u7684\u8f93\u51fa\u4f5c\u4e3a\u672c\u65f6\u523b\u7684\u8f93\u5165\uff0c\u5982\u6b64\u8fed\u4ee3\u7684\u751f\u6210\u53e5\u5b50\n#### \u8bad\u7ec3\u7684\u65f6\u5019\u6211\u4eec\u7684model\u662f\u4e00\u6574\u4e2aseq2seq\u7684\u6a21\u578b\uff0c\u8fd9\u4e2a\u9ed1\u76d2\u5728\u7ed9\u5b9aencoder_input\u548cdecoder_input\u7684\u60c5\u51b5\u4e0b\u53ef\u4ee5\u4ea7\u751f\u5bf9\u5e94\u7684\u8f93\u51fa\n#### \u4f46\u662f\u751f\u6210\u65f6\u6211\u4eec\u6ca1\u6709decoder_input\uff0c\u6211\u4eec\u5c31\u628a\u9ed1\u76d2\u62c6\u6210\u4e24\u4e2a\u9ed1\u76d2\uff0c\u4e00\u4e2a\u662f\u7f16\u7801\u5668\uff0c\u4e00\u4e2a\u662f\u89e3\u7801\u5668\uff0c\u65b9\u4fbf\u6211\u4eec\u7684\u64cd\u4f5c","684bff22":"#### \u8fd9\u6bb5\u4ee3\u7801\u5c31\u5b9e\u73b0\u4e86\u8fed\u4ee3\u7684\u89e3\u7801\n#### \u5047\u8bbe\u6211\u4eec\u5df2\u7ecf\u751f\u6210\u4e86\u524dn\u4e2a\u5b57\uff0c\u6211\u4eec\u628a\u524dn\u4e2a\u5b57\u4f5c\u4e3a\u8f93\u5165\uff0c\u5f97\u5230\u7b2cn+1\u4e2a\u5b57\uff0c\u518d\u628a\u8fd9n+1\u4e2a\u5b57\u4f5c\u4e3a\u8f93\u5165\uff0c\u5f97\u5230\u7b2cn+2\u4e2a\u5b57\uff0c\u4ee5\u6b64\u7c7b\u63a8","4f166b13":"#### \u4e0b\u9762\u8fd9\u6bb5\u4ee3\u7801\u7528\u4e8e\u5904\u7406\u539f\u59cb\u6570\u636e\n#### seq2seq\u7684\u8bad\u7ec3\u6570\u636e\u662f\u7531\u8f93\u5165\u548c\u76ee\u6807\u7ec4\u6210\u7684\u4e00\u5bf9\uff0c\u5373input\u548ctarget\n#### \u6211\u4eec\u8fd9\u91cc\u5c55\u793a\u7684\u4efb\u52a1\u662f\u5bf9\u8bd7\uff0c\u90a3\u4e48input\u662f\u4e0a\u53e5\u8bd7\uff0ctarget\u5c31\u662f\u4e0b\u53e5\u8bd7\n#### \u6211\u4eec\u9996\u5148\u5efa\u7acb\u6240\u6709\u8f93\u5165\u53e5\u5b50\u7684\u8bcd\u5178input_vocab\u548ctarget_vocab\n#### \u5176\u6b21\uff0c\u89e3\u7801\u7684\u65f6\u5019\u9700\u8981\u8d77\u59cb\u5b57\u7b26<BOS\\>\u548c\u7ed3\u675f\u5b57\u7b26<EOS\\>\uff0c\u8fd9\u91cc\u5206\u522b\u7528\u5236\u8868\u7b26'\\t'\u548c\u56de\u8f66\u7b26'\\n'\u6765\u8868\u793a","0e554622":"#### \u4e0b\u9762\u8fd9\u6bb5\u4ee3\u7801\u7528\u4e8e\u642d\u5efa\u6a21\u578b\n#### ![](https:\/\/docs.chainer.org\/en\/stable\/_images\/seq2seq.png)","ff8dff99":"#### \u4e0b\u9762\u8fd9\u6bb5\u4ee3\u7801\u7528\u4e8e\u6784\u5efa\u8bad\u7ec3\u6570\u636e\n![](https:\/\/docs.chainer.org\/en\/stable\/_images\/seq2seq.png)\n#### \u8bad\u7ec3\u6570\u636e\u7531\u4e09\u90e8\u5206\u6784\u6210\uff0c\u7f16\u7801\u5668\u8f93\u5165\uff0c\u89e3\u7801\u5668\u8f93\u5165\uff0c\u89e3\u7801\u5668\u76ee\u6807\n#### \u5373encoder_input, decoder_input, decoder_target\u3001\n#### \u5728\u6784\u5efa\u7684\u540c\u65f6\u8fd8\u628a\u5b57\u8f6c\u5316\u6210\u4e86\u5b57\u5178\u91cc\u7684\u7f16\u53f7"}}