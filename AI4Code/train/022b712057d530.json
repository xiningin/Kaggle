{"cell_type":{"1011966d":"code","3efac514":"code","f9a7ea74":"code","a74032b6":"markdown","417391f2":"markdown"},"source":{"1011966d":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n# loading dummy submission file\nsub_file = pd.read_csv('..\/input\/santander-customer-transaction-prediction\/submission_blend_1.csv')\n\n# loading data including 16 best scores\ndf_sub = pd.read_csv(r'..\/input\/santander-customer-transaction-prediction\/best_blend_2.csv')\n\n# a rough correlation based visualization of 16 best scores\nplt.figure(figsize=(10,10))\nsns.heatmap(df_sub.corr(), cmap='Spectral')\nplt.ylabel('file index numbers')\nplt.xlabel('file index numbers')\nplt.show()","3efac514":"# basic analysis and visualization of subgroups in different color.\nplt.figure(figsize=(12, 5))\ndf_mean_corr = pd.DataFrame({'mean_corr': df_sub.corr().mean()})\ndf_mean_corr = df_mean_corr.sort_values('mean_corr', ascending=False)\ndf_mean_corr = df_mean_corr.reset_index()\n\nplt.plot(df_mean_corr.index[:8], df_mean_corr['mean_corr'].values[:8], 'o', ms=10)\nplt.plot(df_mean_corr.index[8:13], df_mean_corr['mean_corr'].values[8:13], 'o', ms=10)\nplt.plot(df_mean_corr.index[13:14], df_mean_corr['mean_corr'].values[13:14], 'o', ms=10)\nplt.plot(df_mean_corr.index[14:15], df_mean_corr['mean_corr'].values[14:15], 'o', ms=10)\nplt.plot(df_mean_corr.index[15:16], df_mean_corr['mean_corr'].values[15:16], 'o', ms=10)\n\nplt.xticks([*range(len(df_mean_corr))], df_mean_corr['index'].tolist())\nplt.title('determination of sub_groups')\nplt.ylabel('a correlation ralated index')\nplt.xlabel('file index numbers')\nplt.show()","f9a7ea74":"# a linear combination to achieve much better scores\ndf_sub['weighted_avg'] = abs(1 * (\n    100 * ( 100 * df_sub['0'] + 30 * df_sub['3'] + 20 * df_sub['4'] + 10 * df_sub['5'] +\n           10 * df_sub['7'] + 1 * df_sub['8'] + 1 * df_sub['11'] + 1 * df_sub['13']) \/ 173 +\n\n    5 * ( 50 * df_sub['1'] + 50 * df_sub['2'] + 5 * df_sub['10'] + 5 * df_sub['12'] + 1 * df_sub['14']) \/ 111 +\n    1 * ( 20 * df_sub['6'] + 5 * df_sub['9'] + 1 * df_sub['15']) \/ 26 + 200 * df_sub['16'] ) \/ 306 )\n\n\n# create the final submission file\nsubmission = pd.DataFrame({'ID_code': sub_file.ID_code, 'target': df_sub['weighted_avg'].tolist()})\nsubmission.to_csv(r'submission_file.csv', index=False)","a74032b6":"# Blend Boosting study on dataset of the Santander Customer Transaction Prediction:\n\nHere I share with you a systematic blend boosting study on dataset of the Santander Customer Transaction Prediction (https:\/\/www.kaggle.com\/c\/santander-customer-transaction-prediction). I just collect some submission files (20 distincts, but skip some of them).\n\nBasically, I start to analysis of correlations, then decide to sort them according to their sum of correlation values in between. This lets me divide 16 scores into 3 subgroups. Then I make internal linear calibration in each subgroup by considering their scores on the Kaggle. Finally I make recalling between subgroups to achieve higher scores on the Kaggle by resubmission. Of course, if you spend much more time, you can always achieve betters scores, but I stop it here because it is already highest score on Kaggle ;-).  ","417391f2":"## It gets a 0.92694 AUC as public score, and looks the best score on Kaggle so far ;-)"}}