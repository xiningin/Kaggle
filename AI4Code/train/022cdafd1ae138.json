{"cell_type":{"725752a3":"code","45560d3f":"code","afddfb27":"code","fa949421":"code","18bdb3bf":"code","8ad1f711":"code","01c0c627":"code","12f7db56":"code","49333d55":"code","347d3b3c":"code","e84a9ab4":"code","27340ad5":"code","e2e24dd6":"code","114ed3cd":"code","46f6e9d1":"code","af8d2069":"code","b64a4bf4":"code","d5fc4c28":"code","e8d535ed":"code","e42d3fcf":"code","c7062290":"code","3b0dffdb":"markdown","0457cfbe":"markdown","c8088724":"markdown","973a43e1":"markdown","ab6bfc5d":"markdown","64eeba8e":"markdown","2533d826":"markdown","ec6ecf2e":"markdown","e950e90f":"markdown","af0fd19b":"markdown","b0409581":"markdown","4a5f51e1":"markdown"},"source":{"725752a3":"import os\nimport pandas as pd\nfrom PIL import Image\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport random\nfrom collections import defaultdict\nimport seaborn as sns\nfrom keras.preprocessing.image import ImageDataGenerator\nimport tensorflow as tf","45560d3f":"train_path = \"\/kaggle\/input\/kermany2018\/OCT2017 \/train\"\ntest_path = \"\/kaggle\/input\/kermany2018\/OCT2017 \/test\"\ndir_name = os.listdir(train_path)","afddfb27":"train = defaultdict(list)\ntest = defaultdict(list)\ntrain_label = defaultdict(list)\ntest_label = defaultdict(list)\n\nfrom tqdm import tqdm\nfor i in range(4):\n    path = os.path.join(train_path, dir_name[i])\n    for j in tqdm(os.listdir(path)):\n        im = np.array(Image.open(os.path.join(path, j)))\n        if im.shape == (496, 768):\n            train[str(dir_name[i])].append(os.path.join(path, j))\n            train_label[str(dir_name[i])].append(dir_name[i])\n\nfor i in range(4):\n    path = os.path.join(test_path, dir_name[i])\n    for j in tqdm(os.listdir(path)):\n        im = np.array(Image.open(os.path.join(path, j)))\n        if im.shape == (496, 768):\n            test[str(dir_name[i])].append(os.path.join(path, j))\n            test_label[str(dir_name[i])].append(dir_name[i])","fa949421":"print(\"Train set distribution\")\nfor i in dir_name:\n    print(i,len(train[str(i)]))\nprint(\"Test set distribution\")\nfor i in dir_name: \n    print(i,len(test[str(i)]))","18bdb3bf":"# Assigning equal amount of data per class to both train and test\ntrain_path = []\ntrain_class = []\ntest_path = []\ntest_class = []\n\nfor i in range(3):\n    temp  = list(zip(train[dir_name[i]], train_label[dir_name[i]]))\n    random.shuffle(temp)\n    res1, res2 = zip(*temp)\n    train_path.extend(res1[0:1000])\n    train_class.extend(res2[0:1000])\n    \n    test_path.extend(res1[1000:1200])\n    test_class.extend(res2[1000:1200])\n    \ntrain_path.extend(train[dir_name[3]])\ntrain_class.extend(train_label[dir_name[3]])\ntest_path.extend(test[dir_name[3]])\ntest_class.extend(test_label[dir_name[3]])","8ad1f711":"df_train = pd.DataFrame(list(zip(train_path, train_class)),\n               columns =['image_path', 'label'])\n\ndf_test = pd.DataFrame(list(zip(test_path, test_class)),\n               columns =['image_path', 'label'])","01c0c627":"df = df_train\nlab = df['label']\ndist = lab.value_counts()\nsns.countplot(x = lab)","12f7db56":"df = df_test\nlab = df['label']\ndist = lab.value_counts()\nsns.countplot(x = lab)","49333d55":"train_aug = ImageDataGenerator(\n    rotation_range=0.2,\n    width_shift_range=0.05,\n    height_shift_range=0.05,\n    shear_range=0.05,\n    zoom_range=0.05,\n    rescale = 1.\/255)\n\ntest_aug = ImageDataGenerator(\n    rescale = 1.\/255)\n\ntrain_generator= train_aug.flow_from_dataframe(\ndataframe=df_train,\nx_col=\"image_path\",\ny_col=\"label\",\nbatch_size=32,\ncolor_mode=\"rgb\",\nshuffle = True,\ntarget_size = (224, 224),\nclass_mode=\"categorical\")\n\ntest_generator= test_aug.flow_from_dataframe(\ndataframe=df_test,\nx_col=\"image_path\",\ny_col=\"label\",\ncolor_mode=\"rgb\",\nbatch_size=32,\nshuffle = False, #I set to False for classification report\ntarget_size = (224, 224),\nclass_mode=\"categorical\")","347d3b3c":"import matplotlib.pyplot as plt\nplt.imshow(test_generator[0][0][2])","e84a9ab4":"from sklearn.utils import class_weight\nmap_characters = train_generator.class_indices\nprint(map_characters)\nclass_weights = dict(zip(map_characters.values(), class_weight.compute_class_weight(class_weight='balanced', classes=np.unique(train_class), \n                y=train_class))) \nprint(\"Class Weights: \",class_weights)","27340ad5":"from keras.layers import Activation,Dense, Dropout, Flatten, Conv2D, MaxPool2D,MaxPooling2D,AveragePooling2D, BatchNormalization\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\nfrom keras.applications.inception_v3 import InceptionV3\n\ndef generate_model(pretrained_model = 'vgg16', num_classes = 4):\n    if pretrained_model == 'inceptionv3':\n        weight_path = '..\/input\/keras-pretrained-models\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        base_model = InceptionV3(weights = weight_path, include_top=False, input_shape=(224, 224, 3))\n    else:\n        weight_path = '..\/input\/keras-pretrained-models\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\n        base_model = VGG16(weights = weight_path, include_top=False, input_shape=(224, 224, 3)) # Topless\n    \n    # Add top layer\n    x = base_model.output\n    x = Flatten()(x)\n    predictions = Dense(num_classes, activation='softmax')(x)\n    model = Model(inputs=base_model.input, outputs=predictions)\n    \n    # Train top layer\n    for layer in base_model.layers:\n        layer.trainable = False\n        \n    return model\n\nmodel = generate_model(\"vgg16\", 4)","e2e24dd6":"rlr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n    factor=0.1,\n    patience=4)\n\nearly_stop = tf.keras.callbacks.EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=7, verbose=1)\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=tf.keras.optimizers.Adam(),\n              metrics=['accuracy'])\n\nhistory = model.fit(train_generator, validation_data=test_generator, class_weight = class_weights, epochs = 50, callbacks = [rlr, early_stop])","114ed3cd":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","46f6e9d1":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'val'], loc='upper left')\nplt.show()","af8d2069":"from sklearn import metrics\ny_true = np.array(test_generator.labels)\ny_pred = model.predict(test_generator, verbose = 1)\ny_pred_classes = np.argmax(y_pred,axis = 1)\nclass_labels = list(test_generator.class_indices.keys())   ","b64a4bf4":"print('\\n', metrics.classification_report(y_true, y_pred_classes, target_names=class_labels), sep='')","d5fc4c28":"from sklearn.preprocessing import LabelBinarizer\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\ndef plot_roc_curves(y_true, y_pred, num_classes, class_labels):\n\n    lb = LabelBinarizer()\n    lb.fit(y_true)\n    y_test = lb.transform(y_true)\n\n    # Compute ROC curve and ROC area for each class\n    fpr = dict()\n    tpr = dict()\n    roc_auc = dict()\n    for i in range(num_classes):\n        fpr[i], tpr[i], _ = roc_curve(y_test[:, i], y_pred[:, i])\n        roc_auc[i] = auc(fpr[i], tpr[i])\n\n\n    # Plot all ROC curves\n    for i in range(num_classes):\n        fig, c_ax = plt.subplots(1,1, figsize = (6, 4))\n        c_ax.plot(fpr[i], tpr[i],\n                 label='ROC curve of class {0} (area = {1:0.4f})'\n                 ''.format(class_labels[i], roc_auc[i]))\n        c_ax.set_xlabel('False Positive Rate')\n        c_ax.set_ylabel('True Positive Rate')\n        c_ax.set_title('ROC curve of class {0}'.format(class_labels[i]))\n        c_ax.legend(loc=\"lower right\")\n        plt.show()\n\n    return roc_auc_score(y_test, y_pred)","e8d535ed":"print(\"ROS AUC score:\", plot_roc_curves(y_true, y_pred, 4, class_labels))","e42d3fcf":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (5,5))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","c7062290":"from sklearn.metrics import confusion_matrix\nimport itertools\nconfusion_mtx = confusion_matrix(y_true, y_pred_classes)\nplot_confusion_matrix(confusion_mtx, classes = list(map_characters.keys()))\nplt.show()","3b0dffdb":"### Confusion matrix","0457cfbe":"### Adding Class weights","c8088724":"### Build Model","973a43e1":"### Classification Report","ab6bfc5d":"### Plot Accuracy and Loss Graphs","64eeba8e":"### Training model","2533d826":"# ","ec6ecf2e":"# Transfer Learning on kermany18 OCT dataset using VGG16\n\nWe attempt to perform classification on the RET OCT2017 (kermany18) dataset by leveraging transfer learning using the VGG16 model pretrained on imagenet. We freeze all the layers except the top and train on the dataset using class weights to prevent class imbalance.\n\nDataset consists of 4 classes: CNV, DME, DRUSEN, NORMAL\n\nDue to large amount of data having white patches and unequal sizes, we only extract images without these artifacts. To prevent extreme imbalance we only extract around 1000 images per class for train set and around 200 for test set.\n\nOur observations are that model overfits to the data, giving 85% test set accuracy.\nWe display classification report, accuracy and loss graphs, ros curves for each class and confusion matrix.","e950e90f":"### Data generator, augmentations","af0fd19b":"### ROC Curves","b0409581":"### Train\/Test Distribution","4a5f51e1":"### Loading the dataset"}}