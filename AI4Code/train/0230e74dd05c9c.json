{"cell_type":{"e2bf983a":"code","0e59ae4e":"code","dd1dde15":"code","e286fdd9":"code","299c4dbc":"code","2a2e4d6b":"code","b3f9dca4":"code","1fd79422":"code","659c24f0":"code","b5d4433f":"code","17dc5589":"code","96053c5e":"code","1069b86b":"code","31e1c811":"code","f5691f74":"code","0aa5e63a":"code","77f532f3":"code","6bea27e2":"code","1a40288f":"markdown","a22a5b73":"markdown","cffa1281":"markdown","cf637b74":"markdown","6e731fd0":"markdown","de831e40":"markdown","b019add1":"markdown","2ffb0390":"markdown","cf57a2fb":"markdown","582da9a1":"markdown","766aa4df":"markdown","b3a1d799":"markdown","88d48a13":"markdown","11d0da2b":"markdown","7f8ff22a":"markdown","d81cf31a":"markdown","f6d0fa7f":"markdown"},"source":{"e2bf983a":"import numpy as np\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_breast_cancer","0e59ae4e":"def initialiseNetwork(num_features):\n  W = np.zeros((num_features, 1))\n  b = 0\n  parameters = {\"W\": W, \"b\": b}\n  return parameters","dd1dde15":"def sigmoid(z):\n  a = 1\/(1 + np.exp(-z))\n  return a","e286fdd9":"def forwardPropagation(X, Y, parameters):\n  W = parameters[\"W\"]\n  b = parameters[\"b\"]\n  Z = np.dot(W.T,X) + b\n  A = sigmoid(Z)\n  return A","299c4dbc":"def cost(A, Y, num_samples):\n  cost = -1\/num_samples *np.sum(Y*np.log(A) + (1-Y)*(np.log(1-A)))\n  return cost","2a2e4d6b":"def backPropagration(X, Y, A, num_samples):\n  dZ =   A - Y                        \n  dW =  (np.dot(X,dZ.T))\/num_samples                            #(X dot_product dZ.T)\/num_samples\n  db =    np.sum(dZ)\/num_samples                            #sum(dZ)\/num_samples\n  return dW, db\n  ","b3f9dca4":"def updateParameters(parameters, dW, db, learning_rate):\n  W =  parameters[\"W\"] - (learning_rate * dW)\n  b =  parameters[\"b\"] - (learning_rate * db)\n  return {\"W\": W, \"b\": b}\n  ","1fd79422":"def model(X, Y, num_iter, learning_rate):\n  num_features = X.shape[0]\n  num_samples = X.shape[1]\n  parameters = initialiseNetwork(num_features)                                                    #call initialiseNetwork()\n  for i in range(num_iter):\n    A = forwardPropagation(X, Y, parameters)                                                         # calculate final output A from forwardPropagation()\n    if(i%100 == 0):\n      print(\"cost after {} iteration: {}\".format(i, cost(A, Y, num_samples)))\n    dW, db = backPropagration(X, Y, A, num_samples)                                                 # calculate  derivatives from backpropagation\n    parameters = updateParameters(parameters, dW, db, learning_rate)                                         # update parameters\n  return parameters\n    \n    \n  ","659c24f0":"def predict(W, b, X):\n  Z = np.dot(W.T,X) + b\n  Y = np.array([1 if y > 0.5 else 0 for y in sigmoid(Z[0])]).reshape(1,len(Z[0]))\n  return Y","b5d4433f":"(X_cancer, y_cancer) = load_breast_cancer(return_X_y = True)\n","17dc5589":"X_train, X_test, y_train, y_test = train_test_split(X_cancer, y_cancer,\n                                                   random_state = 25)","96053c5e":"def normalize(data):\n  col_max = np.max(data, axis = 0)\n  col_min = np.min(data, axis = 0)\n  return np.divide(data - col_min, col_max - col_min)","1069b86b":"X_train_n = normalize(X_train)\nX_test_n = normalize(X_test)","31e1c811":"X_trainT = X_train_n.T\nX_testT = X_test_n.T\ny_trainT = y_train.reshape(1,X_train_n.T.shape[1])\ny_testT =  y_test.reshape(1,X_testT.shape[1])","f5691f74":"parameters = model(X_trainT, y_trainT, 4000, 0.75)                 #call the model() function with parametrs mentioned in the above cell","0aa5e63a":"parameters","77f532f3":"yPredTrain = predict(parameters['W'], parameters['b'], X_trainT )   # pass weigths and bias from parameters dictionary and X_trainT as input to the function\nyPredTest = predict(parameters['W'], parameters['b'], X_testT)    # pass the same parameters but X_testT as input data","6bea27e2":"accuracy_train = 100 - np.mean(np.abs(yPredTrain - y_trainT)) * 100\naccuracy_test = 100 - np.mean(np.abs(yPredTest - y_testT)) * 100\nprint(\"train accuracy: {} %\".format(accuracy_train))\nprint(\"test accuracy: {} %\".format(accuracy_test))\nwith open(\"Output.txt\", \"w\") as text_file:\n  text_file.write(\"train= %f\\n\" % accuracy_train)\n  text_file.write(\"test= %f\" % accuracy_test)","1a40288f":"- Import numpy as np and pandas as pd","a22a5b73":"Train the network using X_trainT,y_trainT with number of iterations 4000 and learning rate 0.75","cffa1281":"Run the below cell print the accuracy of model on train and test data.","cf637b74":"Define method forwardPropagation() which implements forward propagtion defined as Z = (W.T dot_product X) + b, A = sigmoid(Z)\n- parameters: X, parameters\n- returns: A\n","6e731fd0":"Define function updateParameters() to update current parameters with its derivatives  \nw = w - learning_rate \\* dw  \nb = b - learning_rate \\* db  \nparameters: parameters,dW,db, learning_rate   \nreturns: dictionary of updated parameters","de831e40":"define function sigmoid for the input z.  \n- parameters: z\n- returns: $1\/(1+e^{(-z)})$","b019add1":"- The code in the below cell loads the breast cancer data set from sklearn.\n- The input variable(X_cancer) is about the dimensions of tumor cell and targrt variable(y_cancer) classifies tumor as malignant(0) or benign(1)","2ffb0390":"Since the dimensions of tumor is not uniform you need to normalize the data before feeding to the network\n- The below function is used to normalize the input data.","cf57a2fb":"Predict the output of test and train data using X_trainT and X_testT using predict() method> Use the parametes returned from the trained model\n","582da9a1":"Define the model for forward propagation  \n- parameters: X,Y, num_iter(number of iterations), learning_rate\n- returns: parameters(dictionary of updated weights and bias)","766aa4df":"- Split the data into train and test set using train_test_split(). Set the random state to 25. Refer the code snippet in topic 4","b3a1d799":"- Transpose X_train_n and X_test_n so that rows represents features and column represents the samples\n- Reshape Y_train and y_test into row vector whose length is equal to number of samples.Use np.reshape()\n\n","88d48a13":"- Run the below cell to define the function to predict the output.It takes updated parameters and input data as function parameters and returns the predicted output","11d0da2b":"- Normalize X_train and X_test and assign it to X_train_n and X_test_n respectively","7f8ff22a":"Define function cost() which calculate the cost given by  \u2212(sum(Y\\*log(A)+(1\u2212Y)\\*log(1\u2212A)))\/num_samples, here * is elementwise product\n- parameters: A,Y,num_samples(number of samples)\n- returns: cost","d81cf31a":"Define method backPropgation() to get the derivatives of weigths and bias\n- parameters: X,Y,A,num_samples\n- returns: dW,db","f6d0fa7f":"Define method initialiseNetwork() initilise weights with zeros of shape(num_features, 1) and also bias b to zero\n- parameters: num_features(number of input features)\n- returns : dictionary of weight vector and bias"}}