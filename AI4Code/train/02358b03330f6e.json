{"cell_type":{"d7067031":"code","3b285387":"code","b80ab069":"code","0b6a90a8":"code","921a9a21":"code","ea004af8":"code","9ff25075":"code","67411060":"code","5fb4773f":"code","60950fcc":"code","2eb30c1c":"code","91ccc8be":"code","bb1a83a9":"code","66d0a0c1":"code","165a014b":"code","8a4b3426":"code","6f61be5e":"code","8a14564b":"code","7b695dc7":"code","8695dc56":"code","b5adcbf8":"code","52b80bda":"code","34eae246":"code","c7c45698":"markdown","d1c1d09c":"markdown","42d88c01":"markdown","82bc1373":"markdown","9e23b562":"markdown","c2bde622":"markdown"},"source":{"d7067031":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\nimport gc\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3b285387":"import tensorflow as tf\nfrom tensorflow.keras import layers as L\n\nfrom matplotlib import pyplot as plt","b80ab069":"train_df = pd.read_csv(\"\/kaggle\/input\/conways-reverse-game-of-life-2020\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/conways-reverse-game-of-life-2020\/test.csv\")\n\nsample_submission = pd.read_csv(\"\/kaggle\/input\/conways-reverse-game-of-life-2020\/sample_submission.csv\")","0b6a90a8":"train_df.head(2)","921a9a21":"start_features = [f for f in train_df.columns if \"start\" in f]\nstop_features = [f for f in train_df.columns if \"stop\" in f]\n\nfeatures_in = stop_features+[\"delta\"]","ea004af8":"idx = 3\n\nfig, (ax1, ax2) = plt.subplots(1, 2)\nfig.suptitle(f'Delta: {train_df.loc[idx, \"delta\"]}')\nax1.imshow(1-(train_df.loc[idx, start_features].values).reshape(25, 25), cmap=\"gray\")\nax1.set_title(\"Start Setting\")\nax2.imshow(1-(train_df.loc[idx, stop_features].values).reshape(25, 25), cmap=\"gray\")\nax2.set_title(\"Stop Setting\")","9ff25075":"bs=1\n\ntr_df = tf.data.Dataset.from_tensor_slices((\n    (train_df[\"delta\"].values, train_df[stop_features].values.reshape(-1, 25, 25, 1).astype(float)), \n    train_df[start_features].values.reshape(-1, 25, 25, 1).astype(float)))\n\ntr_df = tr_df.batch(bs)\n\n\ntst_df = tf.data.Dataset.from_tensor_slices((\n    (test_df[\"delta\"].values, test_df[stop_features].values.reshape(-1, 25, 25, 1).astype(float)), ))\n\ntst_df = tst_df.batch(bs)\n\ngc.collect()","67411060":"tst_df","5fb4773f":"class LifeModel(tf.keras.Model):\n    \n    def __init__(self):\n        super(LifeModel, self).__init__()\n        \n        \n        self.encoder = L.Conv2D(8, kernel_size=(3,3), padding=\"SAME\")\n        self.memory = tf.keras.models.Sequential([\n            L.Conv2D(8, kernel_size=(3,3), padding=\"SAME\"),\n            L.BatchNormalization(),\n            L.ReLU(),\n            \n            L.Conv2D(8, kernel_size=(3,3), padding=\"SAME\"),\n            L.BatchNormalization(),\n            L.ReLU(),\n        ])\n        self.decoder = L.Conv2D(1, kernel_size=(3,3), padding=\"SAME\")\n        \n    def call(self, inputs):\n        \n        #print(inputs)\n        \n        delta = inputs[0]\n        stop_state = inputs[1]\n        \n        print(tf.reshape(delta, (-1,1)))\n        \n        x = self.encoder(stop_state-0.5)\n        x = tf.nn.relu(x)\n        \n        print(x.shape)\n        \n        #TODO: make this custom for each delta in a batch. \n        #Maybe a custom train_step in keras  model\n        stacked = tf.identity(x)\n        for i in range(tf.reduce_max(delta)):\n            x = self.memory(x)        \n        \n        #stacked = L.GlobalAveragePooling2D()(stacked)\n        x = self.decoder(x)\n        #x = tf.nn.relu(x)\n        x = tf.math.sigmoid(x)\n        \n        return x","60950fcc":"model = LifeModel()\nmodel.compile(loss=\"bce\", optimizer=tf.keras.optimizers.Adam(), metrics=[\"accuracy\"])\n\n#ps = model(tr_data[0])\n#ps.shape","2eb30c1c":"model.fit(tr_df, epochs=5)","91ccc8be":"tr_data = next(iter(tr_df))","bb1a83a9":"ps = model(tr_data[0])","66d0a0c1":"ps.shape","165a014b":"idx = 5\n\nfig, (ax1, ax2, ax3) = plt.subplots(1, 3)\nfig.suptitle(\"Delta: \"+str(tr_data[0][0][idx]))\n\nax1.imshow(1-(tr_data[0][1][idx].numpy().reshape(25, 25)), cmap=\"gray\")\nax1.set_title(\"Stop Setting\")\n\nax2.imshow(1-(tr_data[1][idx].numpy().reshape(25, 25)), cmap=\"gray\")\nax2.set_title(\"Start Setting\")\n\nax3.imshow(1-(ps[idx]>=0.5).numpy().reshape(25, 25), cmap=\"gray\")\nax3.set_title(\"Predicted Setting\")","8a4b3426":"ps = model.predict(tst_df, verbose=1)\nplt.imshow(1-(ps[0]>=0.5).reshape(25, 25), cmap=\"gray\")","6f61be5e":"test_df","8a14564b":"THRESH = 0.5\n\nps_=(ps>=THRESH).astype(int).reshape(test_df.shape[0], -1)","7b695dc7":"ps_.shape","8695dc56":"sample_submission","b5adcbf8":"sub = test_df[[\"id\"]].copy()\ntmp = pd.DataFrame(ps_, columns=start_features)\nsub = sub.join(tmp)","52b80bda":"sub.head()","34eae246":"sub.to_csv(\"submission.csv\", index=False)","c7c45698":"### Generating output","d1c1d09c":"### Why LSTMs?\n\nIdea is to somehow encode surrounding information with CNNs and then passing this to a LSTM for encoding the sequence\n\n### Adding a sense of Seqence to the Network\n\nMaybe combine CNN+LSTM or something new","42d88c01":"#### Keras dataset Sequence","82bc1373":"### Let's take some samples","9e23b562":"### Let's plot a sample","c2bde622":"Something like CNN+Sequences or Auto-regressive CNNs with final target"}}