{"cell_type":{"11e7a189":"code","a02cf422":"code","1a153434":"code","2ef300fc":"code","e2f68653":"code","fa6fd9e3":"code","42f75e0b":"code","efb3e50d":"code","781518d0":"code","7d888c38":"code","2a903057":"code","940ef3fb":"code","1c767c48":"code","6a177b8c":"code","5374c83f":"code","74419f58":"code","97a55678":"code","c5b86da3":"code","99d7f21c":"code","3d779220":"code","bb4cb256":"code","0a8fe8f0":"code","7468adbb":"code","3af6a1a7":"code","51fd2f3e":"code","363c5971":"code","acd3116e":"code","4de51717":"code","cbc13e37":"code","193596e0":"code","b675d58b":"code","f6ea871c":"code","6863279b":"code","b0e6efa7":"code","d7f552b5":"code","6e19558f":"markdown","d867b539":"markdown","594b8df8":"markdown","633ca2f5":"markdown","8be05808":"markdown","9172b642":"markdown","63da83e6":"markdown","a527730b":"markdown","ed531e40":"markdown","b68ec209":"markdown","e58cf9d3":"markdown","23339324":"markdown","8830b464":"markdown"},"source":{"11e7a189":"import tensorflow as tf\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\n\nimport PIL\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport cv2\nimport os\nimport random\nimport math\nimport numpy as np\nimport h5py\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom numpy import save\nfrom numpy import load\n\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, Model\n\nfrom tensorflow.keras.layers import Conv2D\nfrom tensorflow.keras.layers import MaxPool2D\nfrom tensorflow.keras.layers import Flatten","a02cf422":"training_path = \"G:\/Desktop\/intel image classification\/seg_train\/seg_train\/\"\ntesting_path = \"G:\/Desktop\/intel image classification\/seg_test\/seg_test\/\"","1a153434":"generator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255,\n                                                           zca_whitening=True,\n                                                           rotation_range=40,\n                                                           width_shift_range=0.15,\n                                                           height_shift_range=0.15,\n                                                           horizontal_flip=True\n                                                           )\ntraining_instances = generator.flow_from_directory(training_path, \n                                                   target_size=(150, 150),\n                                                   batch_size=128)\n\ngenerator = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255)\ntest_instances = generator.flow_from_directory(testing_path,\n                                               target_size=(150, 150),\n                                               batch_size=64)","2ef300fc":"IMG_SHAPE = (150, 150, 3)\n\nbase_model = tf.keras.applications.VGG19(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')","e2f68653":"base_model.trainable = False","fa6fd9e3":"base_model.summary()","42f75e0b":"len(base_model.layers)","efb3e50d":"x = base_model.get_layer('block3_pool').output\nx = tf.keras.layers.Flatten()(x)\n\nx = Dense(512, activation='relu')(x)\nx = Dense(256, activation='relu')(x)\nprediction = Dense(6, activation='softmax')(x)","781518d0":"model = Model(inputs=base_model.input, outputs=prediction)","7d888c38":"model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), metrics=[\"accuracy\"])","2a903057":"model.summary()","940ef3fb":"%%time\nBatch_size=64\ninitial_epochs = 20\nmodel_fit=model.fit(training_instances, \n                    steps_per_epoch=14034 \/\/ Batch_size,\n                    epochs=initial_epochs,\n                    validation_data=test_instances\n                   )","1c767c48":"model.evaluate(test_instances)","6a177b8c":"base_model.trainable = True","5374c83f":"len(base_model.layers)","74419f58":"print(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 7\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","97a55678":"model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"accuracy\"])","c5b86da3":"model.summary()","99d7f21c":"%%time\nfine_tune_epochs = 10\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(training_instances,\n                         epochs=total_epochs,\n                         initial_epoch =  model_fit.epoch[-1],\n                         validation_data=test_instances)","3d779220":"model.evaluate(test_instances)","bb4cb256":"%%time\nfine_tune_epochs1 = 10\ntotal_epochs =  initial_epochs + fine_tune_epochs + fine_tune_epochs1\n\nhistory_fine = model.fit(training_instances,\n                         epochs=total_epochs,\n                         initial_epoch =  history_fine.epoch[-1],\n                         validation_data=test_instances)","0a8fe8f0":"model.evaluate(test_instances)","7468adbb":"base_model.trainable = True","3af6a1a7":"print(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 4\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","51fd2f3e":"model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.0001), metrics=[\"accuracy\"])","363c5971":"model.summary()","acd3116e":"%%time\nfine_tune_epochs2 = 5\ntotal_epochs =  initial_epochs + fine_tune_epochs + fine_tune_epochs1 + fine_tune_epochs2\n\nhistory_fine = model.fit(training_instances,\n                         epochs=total_epochs,\n                         initial_epoch =  history_fine.epoch[-1],\n                         validation_data=test_instances)","4de51717":"model.evaluate(test_instances)","cbc13e37":"base_model.trainable = True","193596e0":"print(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 2\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n    layer.trainable =  False","b675d58b":"model.compile(loss=\"categorical_crossentropy\", optimizer=tf.keras.optimizers.Adam(learning_rate=0.00001), metrics=[\"accuracy\"])","f6ea871c":"model.summary()","6863279b":"%%time\nfine_tune_epochs3 = 10\ntotal_epochs =  initial_epochs + fine_tune_epochs + fine_tune_epochs1 + fine_tune_epochs2 + fine_tune_epochs3\n\nhistory_fine = model.fit(training_instances,\n                         epochs=total_epochs,\n                         initial_epoch =  history_fine.epoch[-1],\n                         validation_data=test_instances)","b0e6efa7":"model.evaluate(test_instances)","d7f552b5":"model.save('G:\/Desktop\/intel image classification\/91%.h5')","6e19558f":"Added fully connected layers with prediction softmax layer.","d867b539":"In the beginning i will fit only top layers. ","594b8df8":"# import libraries","633ca2f5":"After first part fine tuning i will fit again with 18 last layers.","8be05808":"For learning rate set 0.001","9172b642":"I have 14034 images for training, 3000 images for testing.","63da83e6":"Loading pretrained model from internet.\n\nWith include_top=False parameter i get model without fully connected layers and prediction layer.","a527730b":"Hello!\n\nIn this kernel, i will show you my solution using tensorflow. The task is to classify up to 6 class labels. First of all i get low level feature extracter layers from VGG19 pretrained model, then using fine tuning method add several own fully connected layers with prediction layer.","ed531e40":"Data loading and data augmentation using Image data generation\n\n\nI use for augmentation : rotation, shifting to height and width, and flipping images.","b68ec209":"Then i also fit model again with last 20 layers. And each step of fine tuning learning rate value less and less.","e58cf9d3":"Final model accuracy was 91%.","23339324":"I will save model with h5 format","8830b464":"After 20 epoch accuracy equal to 77%.\n\nThen apply fine tuning for last 9 layer.\n\nBut learning rate will 10 time less than previous value. Because, pretrained model weights already will be closer to desired weights."}}