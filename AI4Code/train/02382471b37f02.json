{"cell_type":{"c868ec61":"code","2929cb05":"code","851c9a45":"code","ff61b51a":"code","129ae2ce":"code","cccf75cb":"code","9ca46fab":"code","8558eb17":"code","e78d3df8":"code","a8db8840":"code","d3d9e12d":"code","f3751f71":"code","06f3bc0c":"code","2f9656fe":"code","c98ea83c":"code","83954929":"code","022e1c18":"code","e9f5c209":"code","8b79c6da":"code","7938ca63":"code","a9fcbf27":"code","be067789":"code","acc5bf79":"code","89da2a21":"code","64cdc250":"code","ddffc112":"code","a0459fc4":"code","96639f25":"code","4852acd5":"code","487bbd34":"code","713c034a":"code","6853a646":"code","82f091b1":"code","bd14a433":"code","fc685265":"code","a46f8238":"code","1ceba18c":"code","a938a176":"code","35c09590":"code","8d52b706":"code","8741d3cb":"code","1abf16db":"code","75acf0fe":"code","1af7f3b1":"code","8e0d4d9d":"code","91a0c0b8":"code","aca3b531":"markdown","b071aaf0":"markdown","bc1be453":"markdown","984b95d5":"markdown","a4c12515":"markdown","8d68fdcd":"markdown","61dbd75f":"markdown","dfc74032":"markdown","5a937303":"markdown","9a23241d":"markdown","c2e9d1ca":"markdown","f8c8beb8":"markdown","d7f215a7":"markdown"},"source":{"c868ec61":"#Base\nimport pandas as pd\nimport numpy as np\n\n#Plot\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#Modelos\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier\n\n#Metrics\nfrom sklearn.metrics import make_scorer, accuracy_score\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import cross_val_score\n#Model Select\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import StratifiedKFold\nfrom yellowbrick.model_selection import RFECV\n\nfrom hyperopt import hp, tpe, fmin\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2929cb05":"df_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')","851c9a45":"print('TrainShape is:',df_train.shape,'\\TestShape is:',df_test.shape)","ff61b51a":"df_append = df_train.append(df_test)","129ae2ce":"print('AppendShape is',df_append.shape)","cccf75cb":"df_append.head(2)","9ca46fab":"df_append.isna().sum()","8558eb17":"sns.heatmap(df_append.isnull(), cbar=False)","e78d3df8":"df_append['Age'].describe()","a8db8840":"df_append.groupby('Sex').Age.plot(kind='kde')\nplt.legend()\nplt.show()","d3d9e12d":"df_append.Age.plot(kind='hist')\nplt.legend()\nplt.show()","f3751f71":"facetgrid = sns.FacetGrid(df_append, col=\"Sex\", row=\"Survived\", margin_titles=True)\nfacetgrid.map(plt.hist, \"Age\",color=\"Blue\");","06f3bc0c":"df_append['Age'].fillna(df_append['Age'].median(),inplace=True)\ndf_append['Fare'].fillna(df_append['Fare'].median(),inplace=True)","2f9656fe":"df_append['Embarked'].describe()","c98ea83c":"df_append['Embarked'].fillna('S',inplace=True)","83954929":"df_append['Embarked'].value_counts().plot(kind='bar', alpha=0.75)","022e1c18":"sns.set(font_scale=1)\nfactorplot = sns.factorplot(x=\"Sex\", y=\"Survived\", col=\"Pclass\",\n                    data=df_append, saturation=.8,\n                    kind=\"bar\", ci=None, aspect=.6)\n(factorplot.set_axis_labels(\"\", \"Survival Rate\")\n    .set_xticklabels([\"Men\", \"Women\"])\n    .set_titles(\"{col_name} {col_var}\")\n    .set(ylim=(0, 1))\n    .despine(left=True))  \nplt.subplots_adjust(top=0.8)\nfactorplot.fig.suptitle('Sobreviventes do sexos masc. e femin. por classe');","e9f5c209":"df_append.Age[df_append.Pclass == 1].plot(kind='kde')    \ndf_append.Age[df_append.Pclass == 2].plot(kind='kde')\ndf_append.Age[df_append.Pclass == 3].plot(kind='kde')\n # plots an axis lable\nplt.xlabel(\"Age\")    \nplt.title(\"Age Distribution class\")\n# sets our legend for our graph.\nplt.legend(('1st Class', '2nd Class','3rd Class'),loc='best');","8b79c6da":"plt.figure(figsize=(10, 10))\ncorr = df_append.corr()\nsns.heatmap(corr,square=True,annot=True,cmap='YlGnBu',linecolor=\"white\")\nplt.title('Correlation features');","7938ca63":"df_append.dtypes","a9fcbf27":"df_append['Sex'] = df_append['Sex'].replace('male',0)\ndf_append['Sex'] = df_append['Sex'].replace('female',1)\ndf_append['Embarked'] = df_append['Embarked'].replace('S',0)\ndf_append['Embarked'] = df_append['Embarked'].replace('Q',1)\ndf_append['Embarked'] = df_append['Embarked'].replace('C',2)","be067789":"df_append.head(2)","acc5bf79":"df_append['Title'] = df_append['Name'].str.extract(' ([A-Za-z]+)\\.', expand = False)\ndf_append['Title'].value_counts(normalize=True)*100","89da2a21":"mapping = {'Mlle': 'Miss', 'Major': 'Rare', 'Col': 'Rare', 'Sir': 'Rare', 'Don': 'Rare', 'Mme': 'Mrs',\n           'Jonkheer': 'Rare', 'Lady': 'Rare', 'Capt': 'Rare', 'Countess': 'Rare', 'Ms': 'Miss', 'Dona': 'Mrs', 'Rev':'Rare', 'Dr':'Rare'}\n\ndf_append.replace({'Title': mapping}, inplace=True)\n\ndf_append['Title'].value_counts(normalize=True)*100","64cdc250":"df_append['Title'] = df_append['Title'].map({'Mr':0, 'Miss':1, 'Mrs':2, 'Master':3, 'Rare':4})","ddffc112":"bins = [-1, 0, 18, 25, 35, 60, np.inf]\nlabels = ['Unknown', 'Child', 'Teenager', 'Young Adult', 'Adult', 'Senior']\ndf_append['AgeGroup'] = pd.cut(df_append[\"Age\"], bins, labels = labels)\nage_mapping = {'Unknown': None,'Child': 1, 'Teenager': 2, 'Young Adult': 3, 'Adult': 4, 'Senior': 5}\ndf_append['AgeGroup'] = df_append['AgeGroup'].map(age_mapping)","a0459fc4":"df_append['Family_size'] = df_append['SibSp'] + df_append['Parch'] + 1","96639f25":"df_append['Alone'] = 1\ndf_append['Alone'].loc[df_append['Family_size'] > 1] = 0","4852acd5":"# Cabin\ndf_append.Cabin.fillna('0', inplace=True)\ndf_append.loc[df_append.Cabin.str[0] == 'A', 'Cabin'] = 1\ndf_append.loc[df_append.Cabin.str[0] == 'B', 'Cabin'] = 1\ndf_append.loc[df_append.Cabin.str[0] == 'C', 'Cabin'] = 1\ndf_append.loc[df_append.Cabin.str[0] == 'D', 'Cabin'] = 2\ndf_append.loc[df_append.Cabin.str[0] == 'E', 'Cabin'] = 2\ndf_append.loc[df_append.Cabin.str[0] == 'F', 'Cabin'] = 3\ndf_append.loc[df_append.Cabin.str[0] == 'G', 'Cabin'] = 3\ndf_append.loc[df_append.Cabin.str[0] == 'T', 'Cabin'] = 3","487bbd34":"df_append['Ticket_Frequency'] = df_append.groupby('Ticket')['Ticket'].transform('count')","713c034a":"df_append['Fare_per_person'] = df_append.Fare \/ np.mean(df_append.SibSp + df_append.Parch + 1)","6853a646":"df_append.head(2)","82f091b1":"df_append.isna().sum()","bd14a433":"features = ['Embarked','Fare','Pclass','Sex','Title','AgeGroup','Family_size','Alone','Ticket_Frequency','Fare_per_person']","fc685265":"df_train = df_append[0:891]\ndf_test = df_append[891:]","a46f8238":"X = df_train[features]\ny = df_train['Survived'].astype(int)","1ceba18c":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.2,random_state=78941)","a938a176":"y_train.value_counts()","35c09590":"space = {'eta':hp.uniform('eta', 0.01, 1),\n         'max_depth':hp.uniform('max_depth', 10,600),\n         'n_estimators':hp.uniform('n_estimators', 10, 3000),\n         'learning_rate':hp.uniform('learning_rate', 0.0001,0.95),\n         'colsample_bytree':hp.uniform('colsample_bytree', 0.1, 0.95),\n          'subsample':hp.uniform('subsample',0.1, 1),\n          'min_child_weight':hp.uniform('min_child_weight',1,10)\n        }\n\ndef objective(params):\n    params = {'eta': params['eta'],\n             'max_depth': int(params['max_depth']),\n             'n_estimators': int(params['n_estimators']),\n             'learning_rate': params['learning_rate'],\n             'colsample_bytree': params['colsample_bytree'],\n              'objective':'binary:logistic',\n              'subsample':params['subsample'],\n              'min_child_weight':params['min_child_weight']\n             }\n    cv = StratifiedKFold(n_splits=7, random_state=974411, shuffle=False)\n    xb_a= XGBClassifier(**params)\n    score = cross_val_score(xb_a, X_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1).mean()\n    return -score","8d52b706":"best = fmin(fn= objective, space= space, max_evals=20, rstate=np.random.RandomState(1), algo=tpe.suggest)","8741d3cb":"xb_b = XGBClassifier(random_state=0,\n                        eta=best['eta'], \n                        max_depth= int(best['max_depth']),\n                        n_estimators= int(best['n_estimators']),\n                        learning_rate= best['learning_rate'],\n                        colsample_bytree= best['colsample_bytree'],\n                         objective='binary:logistic',\n                          subsample=best['subsample'],\n                          min_child_weight=best['min_child_weight']\n                       )\n\nxb_b.fit(X_train, y_train);","1abf16db":"preds = xb_b.predict(X_test)\ntarget_names = ['Morreu', 'Sobreviveu']\nprint(classification_report(y_test, preds,target_names=target_names))\nprint(confusion_matrix(y_test, preds))\nprint(accuracy_score(y_test, preds))","75acf0fe":"from yellowbrick.model_selection import RFECV","1af7f3b1":"# Instantiate RFECV visualizer with a linear SVM classifier\ncv = StratifiedKFold(n_splits=7, random_state=974411, shuffle=False)\nvisualizer = RFECV(RandomForestClassifier(),scoring='accuracy',cv=cv)\n\nvisualizer.fit(X_train, y_train)        # Fit the data to the visualizer\nvisualizer.show(); ","8e0d4d9d":"df_test.isna().sum()","91a0c0b8":"preds = visualizer.predict(df_test[features])\nId = df_test.PassengerId\noutput = pd.DataFrame({'PassengerId': Id, 'Survived':preds})\noutput.to_csv('..\/input\/output\/submission.csv', index=False)","aca3b531":"#### 1.2 - Statistical values of the age column and filling in the null values","b071aaf0":"#### 1.3 - Verification of null values and filling in the Shipment column","bc1be453":"### 2.0 Modeling","984b95d5":"## EDA","a4c12515":"#### 1.4 - Checking column types","8d68fdcd":"#### 1.8 Feature Selection","61dbd75f":"#### 1.7 - Creating Group by age\n<p> In this case I will use the age that was provided from our dataset to create the groups to find out if the passenger was a child, youth, adult, etc. In this case we are doing a Feacture Engineer where we transform a column to get another one through it <\/p>","dfc74032":"### 2.3 XGBC","5a937303":"#### 1.6 Extraction with regex\n<p> We will use Regex (Regular expression) to extract people's title based on the name column and thus create a new column <\/p>","9a23241d":"#### 1.1 - Verifica\u00e7\u00e3o de valores nulos","c2e9d1ca":"#### 1.5 - Creating Dummies Variables\n<p> Dummy variable is a categorical variable that has been transformed into numeric. For example the column Gender, we have \"male\" and \"female\" we will transform these variables into numeric. Creating a new column just for Men. and Women, where 1 will be set to positive and 0 to negative <\/p>","f8c8beb8":"<div style=\"text-align:center;\">\n    <h1>Introduction <\/h1>\n    <p>I will try in this notebook to describe step by step the way it was thought to seek a satisfactory result from our model to classify between Survivor and people who died in the Titanic incident, in addition to the code I will try to reference as much information as possible for those who are starting to use as basis for understanding and deepening in the techniques, exemplifying thus being able to take their own hypotheses<\/p>\n<\/div>","d7f215a7":"<div style=\"text-align:center;\">\n    <h1>Summary  <\/h1>\n<\/div>\n<h3>1 - Data Exploration<\/h3>\n<p style=\"text-indent:3em\">1.1 - Verification of null values and column drop that we will not use <\/p>\n<p style=\"text-indent:3em\">1.2 - Statistical values of the age column and filling in the null values <\/p>\n<p style=\"text-indent:3em\">1.3 - Verification of null values and filling in the Shipment column <\/p>\n<p style=\"text-indent:3em\">1.4 - Checking the column types<\/p>\n<p style=\"text-indent:3em\">1.5 - Creation of Dummies variables <\/p>\n<p style=\"text-indent:3em\">1.6 -  Extraction with regex and treatment of the column <\/p>\n<p style=\"text-indent:3em\">1.7 - Creating a group by age<\/p>\n<p style=\"text-indent:3em\">1.8 - Choice of Features <\/p>\n<h3>2 - Modeling <\/h3>\n<p style=\"text-indent:3em\">2.3 - XGBClassifier<\/p>\n\n\n"}}