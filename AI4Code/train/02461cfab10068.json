{"cell_type":{"cdf596aa":"code","cf614876":"code","fe6103de":"code","7b61fca1":"code","d935c827":"code","672e8510":"code","2900ac8c":"code","586774cf":"code","e6ce250e":"code","871dd180":"code","cd0d7967":"code","d00254a8":"code","9987e92d":"code","13fe0c12":"code","7b462647":"code","c5402d98":"code","c57ee0ce":"code","880d3f7a":"code","ee92b286":"code","494683d9":"code","2e65aec5":"code","c20c0bbf":"markdown","970923dc":"markdown","f2d3bb6a":"markdown","6bc3bf1e":"markdown","0a31a181":"markdown","35efc93b":"markdown","c1161b42":"markdown","4b0852be":"markdown","a29366d4":"markdown"},"source":{"cdf596aa":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom pprint import pprint","cf614876":"! cat ..\/input\/feedback-prize-2021\/train\/0000D23A521A.txt","fe6103de":"train_df = pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')\ntrain_df['num_words'] = train_df.predictionstring.apply(lambda s: len(s.split()))\n\ntrain_df.head()","7b61fca1":"print(\"Number of essays:\", train_df.id.nunique())\nprint(\"Number of discourse examples:\", len(train_df))\nprint(\"Number of Discourse Types:\", train_df.discourse_type.nunique())\nprint(\"Number Of Discourse Type Numbers:\", train_df.discourse_type_num.nunique())","d935c827":"train_df.discourse_type.value_counts()","672e8510":"train_df.head(2)","2900ac8c":"data=train_df.groupby('discourse_type')[['num_words']].mean().reset_index().rename(columns={'num_words': 'avg_word_length'})\n\nfig, ax=plt.subplots(1, 3, figsize=(15, 4), sharey=True)\nax[0].set_title(\"Frequency of Discourse types\")\nax[0].set_label('')\n\nax[1].set_title(\"Average discourse type length\")\nax[2].set_title(\"discourse type word count quantile distributions\")\n\nsns.set_style('dark')\nsns.countplot(data=train_df, y='discourse_type',\n              order=train_df.discourse_type.value_counts().index, ax=ax[0])\n\nsns.barplot(data=data.sort_values('avg_word_length', ascending=False),\n            x='avg_word_length',\n            y='discourse_type',\n            order=train_df.discourse_type.value_counts().index,\n            ax=ax[1])\n\nsns.boxplot(data=train_df, y='discourse_type', x='num_words',\n            order=train_df.discourse_type.value_counts().index,\n            ax=ax[2])\nplt.show()","586774cf":"data = train_df.groupby('discourse_type')[['num_words']].agg([min, max]).reset_index()\ndata.columns=['discourse_type', 'Min Words', 'Max Words']\n\n_, ax = plt.subplots(1, 2, sharey=True, figsize=(15, 5))\nsns.barplot(data=data, y='discourse_type', x='Min Words', ax=ax[0])\nsns.barplot(data=data, y='discourse_type', x='Max Words', ax=ax[1])\nplt.show()","e6ce250e":"plt.pie(train_df[train_df.num_words<=2].discourse_type.value_counts(),\n        labels=train_df[train_df.num_words<=2].discourse_type.value_counts().index)\nplt.show()","871dd180":"train_df[train_df.num_words<=2].discourse_type.value_counts()","cd0d7967":"pprint(train_df[(train_df.num_words<=2) & \n         (train_df.discourse_type == 'Claim')\n        ].discourse_text.sample(10).values)","d00254a8":"essay_folder='..\/input\/feedback-prize-2021\/train'\nessay_df = []\nfor filename in os.listdir(essay_folder):\n    filepath = os.path.join(essay_folder, filename)\n    with open(filepath) as file:\n        essay_df.append({\n            'id': filename.replace('.txt', ''),\n            'content': file.read()\n        })\nessay_df = pd.DataFrame.from_dict(essay_df)\nessay_df['total_num_chars'] = essay_df.content.apply(lambda x: len(x))\nessay_df['total_num_words'] = essay_df.content.apply(lambda x: len(x.split()))\n\nessay_df.head()","9987e92d":"position_df = train_df[['id', 'discourse_type', 'discourse_start', 'discourse_end']].copy()\nposition_df = position_df.merge( essay_df )\nposition_df['discourse_start_percentile'] = 100 * position_df.discourse_start.div(position_df.total_num_chars)\nposition_df['discourse_end_percentile'] = 100 * position_df.discourse_end.div(position_df.total_num_chars)\n\nposition_df.head()","13fe0c12":"train_df.discourse_type.unique()","7b462647":"plt.figure(figsize=(15, 5))\nplt.title(\"positions in which discourse type occurs w.r.t Essays\")\nsns.boxplot(data=position_df,\n            x = 'discourse_type',\n            y='discourse_end_percentile',\n            order=['Lead',  'Position',  'Claim',\n                   'Counterclaim', 'Evidence', 'Rebuttal','Concluding Statement',]\n           )\nplt.show()","c5402d98":"essay_df[essay_df.id=='A8445CABFECE'].content.values[0]","c57ee0ce":"for idx, row in train_df[train_df.id =='A8445CABFECE'].iterrows():\n    discourse_type=row.discourse_type\n    discourse_text=row.discourse_text\n    \n    print(discourse_type)\n    print(discourse_text)\n    print()","880d3f7a":"data = train_df.groupby('id')[['num_words']].sum().reset_index()\ndata = data.merge(essay_df[['id', 'total_num_words']].copy())\ndata['coverage'] = data.num_words.div(data.total_num_words)\n\ndata.head()","ee92b286":"_, ax=plt.subplots(1, 3, figsize=(15, 5))\nplt.suptitle(\"Coverage of the Discourse Elements in the essays.\")\nsns.boxplot(data=data, y='coverage', ax=ax[0])\nsns.histplot(data=data, x='coverage', ax=ax[1])\nsns.scatterplot(data=data, x='total_num_words', y='coverage', ax=ax[2])\nplt.show()","494683d9":"print(\"Number of essays with <0.2 coverage:\", len(data[data.coverage<0.7]) )\nprint(\"Percent of essays with <0.2 coverage: {:.4f}\".format( 100 * len(data[data.coverage<0.7])\/len(data) ) )","2e65aec5":"_, ax=plt.subplots(1, 3, figsize=(15, 5))\n\nplt.suptitle(\"Coverage of the Discourse Elements in the essays with >0.7 coverage.\")\nsns.boxplot(data=data[data.coverage>0.7], y='coverage', ax=ax[0])\nsns.histplot(data=data[data.coverage>0.7], x='coverage', ax=ax[1])\nsns.scatterplot(data=data[data.coverage>0.7], x='total_num_words', y='coverage', ax=ax[2])\n\nplt.show()","c20c0bbf":"# discourse type positions","970923dc":"for all the discourse types there are few places where the minimum length is <=2","f2d3bb6a":"# coverage of the discourse elements in essays","6bc3bf1e":"# read Essays ","0a31a181":"of all claims have very less number of words with shorter contexts","35efc93b":"**some of the text from claims**","c1161b42":"**more than 98% of the essays have >70% of discourse type Coverage**\n\n**Based on the Discorse types, can occurs at different positional segments in the essays**\n\n**Training dataset have >70% Coverage with Discourse elements given, so almost always can find the elements in the element set**","4b0852be":"**1. Lead, position occurs mostly at the begining of the essays**\n\n**2. CounterClaim, Evidence, Rebuttal occurs almost at similar positions**\n\n**3. Concluding statemtnt can be obtained at the end of an essay most of times.**","a29366d4":"**mean average length of the discourse segments.**"}}