{"cell_type":{"94503eaf":"code","9f9e9cd2":"code","2737a864":"code","3c7d380e":"code","68bb7490":"code","bc9ff4aa":"code","d8983c3a":"code","8f668846":"code","d33bb033":"code","321b53ad":"code","70cb0bbd":"code","9572c462":"code","1c28d570":"code","6fa46407":"code","18e2f4bf":"code","016b0b11":"code","b9a49f6a":"code","a6f018eb":"markdown"},"source":{"94503eaf":"!git clone https:\/\/github.com\/ultralytics\/yolov5  # clone repo","9f9e9cd2":"!git clone https:\/\/github.com\/tangsanli5201\/DeepPCB.git","2737a864":"import yaml\nimport glob\nimport os\nimport shutil\nfrom tqdm import tqdm\nimport cv2\nimport pandas as pd\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n\n","3c7d380e":"!pip install -q --upgrade wandb\n# Login \nimport wandb\nwandb.login()","68bb7490":"class create_dataset:\n\n    def __init__(self,val_split=0.1,test_split=None,path_ds=\" \",split_from_txt_file=True,train_txt_path=\"\",\n                 test_txt_path=\"\"):   # split default 0.1 for training set\n\n        self.split_from_txt_file=split_from_txt_file\n        self.train_txt_path=train_txt_path\n        self.test_txt_path=test_txt_path\n\n        self.val_split=val_split\n        self.test_split=test_split\n\n\n        self.path_ds=path_ds\n\n        self.df_all = []\n\n        self.train=[]\n        self.train_val = []\n        self.test = []\n        self.val=[]\n\n\n\n\n    def to_csv(self,data):\n        columns = list(data.keys())\n        values = list(data.values())\n        arr_len = len(values)\n        df = pd.DataFrame(np.array(values, dtype=object).reshape(1, arr_len), columns=columns).reset_index()\n        # print(df)\n        return df\n\n    def directory_split(self):\n\n\n        if self.split_from_txt_file:\n            with open(self.test_txt_path) as f:\n                for line in f.readlines():\n                    tmp_list=(line.split(\" \"))\n                    img_path_train,img_name_train=os.path.split(tmp_list[0])\n                    # print(img_name.replace('.jpg','_test.jpg'))\n                    self.test.append(img_name_train.replace('.jpg','_test.jpg'))\n\n            with open(self.train_txt_path) as f1:\n                for line in f1.readlines():\n                    tmp_list = (line.split(\" \"))\n                    img_path_test, img_name_test = os.path.split(tmp_list[0])\n                    # print(img_name.replace('.jpg', '_test.jpg'))\n                    self.train_val.append(img_name_test.replace('.jpg', '_test.jpg'))\n\n\n\n            val_split = int(len(self.train_val) * self.val_split)\n            random.seed(101)\n            random.shuffle(self.train_val)\n            self.train = self.train_val[val_split:]  # create train dataset from train_val text file\n            self.val = self.train_val[:val_split]  # create val dataset from train_val text file\n\n        else:\n\n            label_list = ('dataset\/txt')\n            img_list = ('dataset\/img')\n\n            sample_label = (os.listdir(label_list))\n            sample_img = (os.listdir(img_list))\n\n            print(len(sample_label))\n            print(len(sample_img))\n\n            random.seed(101)\n            random.shuffle(sample_img)\n\n            split_size = int(len(sample_img) * self.test_split)\n\n            self.train_val = sample_img[split_size:]\n            self.test = sample_img[:split_size]\n\n        if self.val_split >0:\n            os.makedirs('tmp\/images\/val', exist_ok=True)\n            os.makedirs('tmp\/labels\/val', exist_ok=True)\n            val_split = int(len(self.train_val) * self.val_split)\n            random.seed(45)\n            random.shuffle(self.train_val)\n            self.train = self.train_val[val_split:]  # create train dataset from train_val text file\n            self.val = self.train_val[:val_split]\n\n        else:\n            self.train=self.train_val\n\n\n        # print(len(self.train))\n        # print((len(self.test)))\n        # print(len(self.val))\n\n        os.makedirs('tmp\/images\/train', exist_ok=True)\n\n        os.makedirs('tmp\/images\/test', exist_ok=True)\n\n        os.makedirs('tmp\/labels\/train', exist_ok=True)\n        os.makedirs('tmp\/labels\/test', exist_ok=True)\n\n        self.datasets = [self.train, self.val, self.test]\n        self.dir_nme = ['train', 'val', 'test']\n\n\n    def one_dir_data_set(self):\n\n        os.makedirs(\"dataset\/img\", exist_ok=True)\n        os.makedirs(\"dataset\/txt\", exist_ok=True)\n        folder_img_dir = glob.glob(path_ds + '\/*\/*',recursive=True)\n\n        for i in tqdm(folder_img_dir):\n            try:\n                img_path = os.listdir(i)\n                for tr_img in img_path:\n                    # print(tr_img)\n                    if 'test' in tr_img:\n                        # print(img_path)\n                        # print(i)\n                        com_path = i + \"\/\" + tr_img\n                        shutil.copy(src=com_path, dst='dataset\/img')\n                        # print(com_path)\n\n                    elif '.txt' in tr_img:\n                        label_path = i + \"\/\" + tr_img\n                        shutil.copy(label_path, 'dataset\/txt')\n            except NotADirectoryError:\n                print(\"Unknown file type ,required JPG or TXT format\")\n\n            except PermissionError:\n                print(\"Permission Error \")\n\n            except:pass\n\n        self.directory_split()\n\n\n    def dataset4yolo(self):\n        for k in tqdm(self.datasets):\n            folder_num = (self.datasets.index(k))\n            for i in tqdm(k):\n                data = {}\n                print_buffer = []\n\n                path_jpg = 'dataset\/img\/' + i\n                # print(path_jpg)\n                head_img, tail_img = os.path.split(path_jpg)\n                img_id = (tail_img.strip('_test.jpg'))\n                #print(img_id)\n                # print(tail+'_test.jpg')\n                img_read = cv2.imread(path_jpg)\n                shutil.copy(path_jpg, 'tmp\/images\/' + str(self.dir_nme[folder_num]))\n\n                os.rename('tmp\/images\/' + str(self.dir_nme[folder_num]) + '\/' + img_id + '_test.jpg',\n                          'tmp\/images\/' + str(self.dir_nme[folder_num]) + '\/' + img_id+ '.jpg')\n\n\n\n                path_txt = 'dataset\/txt\/' + (i.replace('_test.jpg', '.txt'))\n\n                with open(path_txt, 'r') as f:\n                    for line in f.readlines():\n                        annot = (line.strip(\"\\n\").split(\" \"))\n\n                        x_min = int(annot[0])\n                        y_min = int(annot[1])\n                        x_max = int(annot[2])\n                        y_max = int(annot[3])\n                        label = int(annot[4])\n\n                        # Transform the bbox co-ordinates as per the format required by YOLO v5\n                        b_center_x = (x_min + x_max) \/ 2\n                        b_center_y = (y_min + y_max) \/ 2\n                        b_width = (x_max - x_min)\n                        b_height = (y_max - y_min)\n\n                        # Normalise the co-ordinates by the dimensions of the image\n                        image_w, image_h, image_c = img_read.shape\n                        b_center_x \/= image_w\n                        b_center_y \/= image_h\n                        b_width \/= image_w\n                        b_height \/= image_h\n\n                        print_buffer.append(\n                            \"{} {:.3f} {:.3f} {:.3f} {:.3f}\".format(label, b_center_x, b_center_y, b_width, b_height))\n\n                        head_txt, tail_txt = os.path.split(path_txt)\n                        # print(tail_txt)\n\n                        print(\"\\n\".join(print_buffer),\n                              file=open('tmp\/labels\/' + self.dir_nme[folder_num] + '\/' + tail_txt.strip('\\n'), \"w\"))\n\n                        id = tail_txt.strip('.txt')\n\n                        data['id'] = id\n                        data['label'] = label\n                        data['x_min'] = x_min\n                        data['y_min'] = y_min\n                        data['x_max'] = x_max\n                        data['y_max'] = y_max\n                        data['b_center_x'] = b_center_x\n                        data['b_center_y'] = b_center_y\n                        data['b_width'] = b_width\n                        data['b_height'] = b_height\n                        data['image_w'] = image_w\n                        data['image_h'] = image_h\n                        data['split'] = self.dir_nme[folder_num]\n\n                        # Convert Dic data to  dataframe\n\n                        df = self.to_csv(data)\n                        self.df_all.append(df)\n\n\n\n        final_df = pd.concat(self.df_all, ignore_index=True)\n\n        del final_df['index']\n\n        # print(final_df)\n\n        final_df.to_csv('meta.csv', index=False)\n\n        print(\"Data set created Train data:\" ,len(self.train))\n        print(\"++\" * 50)\n        print(\"Data set created Validation data:\", len(self.val))\n        print(\"++\" * 50)\n        print(\"Data set created Test data:\", len(self.test))\n        print(\"++\" * 50)\n        print(\"Meta file create as :meta.csv\")","bc9ff4aa":"path_ds = '.\/DeepPCB\/PCBData'\ntest_txt_path='.\/DeepPCB\/PCBData\/test.txt'\ntrain_val_txt_path='.\/DeepPCB\/PCBData\/trainval.txt'\nrun= create_dataset(val_split=0, test_split=0.33, path_ds=path_ds,split_from_txt_file=True,\n                    train_txt_path=train_val_txt_path,test_txt_path=test_txt_path)\nrun.one_dir_data_set()\nrun.dataset4yolo()","d8983c3a":"%cd yolov5\n%pip install -qr requirements.txt  # install dependencies\n\nimport torch\nfrom IPython.display import Image, clear_output  # to display images\n\nclear_output()\nprint(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")\n","8f668846":"os.listdir('\/kaggle\/working\/yolov5\/data')","d33bb033":"data_yaml=dict(train='\/kaggle\/working\/tmp\/images\/train',\n               #val='\/kaggle\/working\/tmp\/images\/val',\n               val='\/kaggle\/working\/tmp\/images\/test',\n               nc=7,\n               names=[\"background\",\"open\", \"short\", \"mousebite\", \"spur\", \"copper\",  \"pin-hole\"])","321b53ad":"with open (\"\/kaggle\/working\/yolov5\/data\/data.yaml\",'w') as outfile:\n  yaml.dump(data_yaml,outfile,default_flow_style=True)","70cb0bbd":"with open (\"\/kaggle\/working\/yolov5\/data\/data.yaml\",'r') as f:\n  for line in f:\n    print(line)","9572c462":"!python train.py --img 640 \\\n                 --batch 12 \\\n                 --epochs 30 \\\n                 --data data.yaml \\\n                 --weights yolov5l.pt \\\n                 --project PCB_fault_detect ","1c28d570":"# !zip -r '\/kaggle\/working\/output.zip' '\/kaggle\/working\/yolov5'","6fa46407":"weight_dir='\/kaggle\/working\/yolov5\/PCB_fault_detect\/exp\/weights\/best.pt'","18e2f4bf":"!python detect.py --source '\/kaggle\/working\/tmp\/images\/test\/'  \\\n                    --weight {weight_dir} \\\n                    --img 640\\\n                  --conf 0.28 \\\n                  --iou-thres 0.5 \\\n                  --save-txt \\\n                  --save-conf \\\n                  --exist-ok\n                    ","016b0b11":"os.listdir('runs\/detect\/')","b9a49f6a":"import matplotlib.pyplot as plt\nfrom mpl_toolkits.axes_grid1 import ImageGrid\nimport numpy as np\nimport random\nimport cv2\nfrom glob import glob\nfrom tqdm import tqdm\n\nfiles = glob('runs\/detect\/exp\/*')\nfor _ in range(3):\n    row = 4\n    col = 3\n    grid_files = random.sample(files, row*col)\n    images     = []\n    for image_path in tqdm(grid_files):\n        img= cv2.cvtColor(cv2.imread(image_path), cv2.COLOR_BGR2RGB)\n        images.append(img)\n\n    fig = plt.figure(figsize=(col*5, row*5))\n    grid = ImageGrid(fig, 111,  # similar to subplot(111)\n                     nrows_ncols=(col, row),  # creates 2x2 grid of axes\n                     axes_pad=0.05,  # pad between axes in inch.\n                     )\n\n    for ax, im in zip(grid, images):\n        # Iterating over the grid returns the Axes.\n        ax.imshow(im)\n        ax.set_xticks([])\n        ax.set_yticks([])\n    plt.show()","a6f018eb":"# Train model from Yolov5"}}