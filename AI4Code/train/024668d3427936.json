{"cell_type":{"375e97f9":"code","8a90afd2":"code","d7e1a67b":"code","e00bb857":"code","9fb1fce7":"code","bd92331c":"code","f9108c55":"code","a898995c":"code","6c8d5400":"code","2bdda14a":"code","1efde57d":"code","c61d4546":"code","609eb068":"code","e5cdea78":"code","cfb232b5":"code","21fb9dbe":"code","5a7d4b40":"code","4f41d261":"code","bf8f5d05":"code","4955aacb":"code","89b874ff":"code","a75ee134":"code","335c4dd9":"code","fcdd51dd":"code","7e4af8d5":"code","ee2ad3d8":"markdown","f093fcd0":"markdown","67ea563a":"markdown","9e7775e9":"markdown","0b407000":"markdown","df2af103":"markdown","703662d5":"markdown","7bc8384b":"markdown","370bd115":"markdown","229569df":"markdown","f6f1a7e0":"markdown","8a95371d":"markdown","1178765c":"markdown","18cde984":"markdown","f7e42743":"markdown","1d98c56e":"markdown","43288583":"markdown","d1cf345d":"markdown","6a7933c3":"markdown","772d7cba":"markdown"},"source":{"375e97f9":"import warnings\nimport pandas as pd\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.max_rows', 1000)\nfrom sklearn.metrics import mean_absolute_error\nimport seaborn as sns\nfrom sklearn.preprocessing import MinMaxScaler\nfrom scipy.stats import skew\nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\nfrom scipy.stats import boxcox\nfrom scipy.special import inv_boxcox\nfrom sklearn.decomposition import PCA, KernelPCA\nimport numpy as np\nfrom collections import Counter\nimport xgboost as xgb\nfrom sklearn.model_selection import train_test_split, cross_val_score\nfrom sklearn.metrics import mean_absolute_error, r2_score\nimport matplotlib.pyplot as plt\nfrom xgboost import cv\nimport sklearn","8a90afd2":"train = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\nprint(\"Datasets loaded\")","d7e1a67b":"train.describe().T","e00bb857":"#select the number columns for IQR\nnum_col = train.loc[:,'MSSubClass':'SaleCondition'].select_dtypes(exclude=['object']).columns\n\n# Outlier detection \n\ndef detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.7 * IQR ## increased to 1.7\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers \nOutliers_to_drop = detect_outliers(train,2, num_col)\ntrain.loc[Outliers_to_drop] # Show the outliers rows","9fb1fce7":"# Drop outliers\ntrain = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)\nprint('Outliers dropped')","bd92331c":"df = pd.concat((train.loc[:,'MSSubClass':'SaleCondition'], test.loc[:,'MSSubClass':'SaleCondition']))\nprint('Concatenation of train and test datasets finished')","f9108c55":"df[\"numoffeatures\"] = df.count(axis=1)","a898995c":"df['MSZoning'].fillna('N')\ndf['LotFrontage'].fillna(df['LotFrontage'].median(), inplace = True)\ndf['Alley'].fillna('N')\ndf['Exterior1st'].fillna('N')\ndf['Exterior2nd'].fillna('N')\ndf['Utilities'].fillna('N')\ndf['MasVnrType'].fillna('N')\ndf['BsmtFullBath'].fillna(0)\ndf['BsmtHalfBath'].fillna(0)\ndf['FullBath'].fillna(0)\ndf['HalfBath'].fillna(0)\ndf['KitchenQual'].fillna('N')\ndf['Functional'].fillna('N')\ndf['FireplaceQu'].fillna('N')\ndf['GarageType'].fillna('N')\ndf['GarageYrBlt'].fillna(0,inplace=True)\ndf['GarageFinish'].fillna('N')\ndf['GarageCars'].fillna(0)\ndf['GarageArea'].fillna(0,inplace=True)\ndf['GarageQual'].fillna('N')\ndf['GarageCond'].fillna('N')\ndf['BsmtFinSF2'].fillna(0,inplace=True)\ndf['MasVnrArea'].fillna(0,inplace=True)\ndf['BsmtFinSF1'].fillna(0,inplace=True)\ndf['SaleType'].fillna('N')\ndf['BsmtUnfSF'].fillna(0,inplace=True)\ndf['TotalBsmtSF'].fillna(0,inplace=True)\ndf['PoolQC'].fillna('N')\ndf['Fence'].fillna('N')\ndf['MiscFeature'].fillna('N')\ndf['BsmtQual'].fillna('N')\ndf['BsmtCond'].fillna('N')\ndf['BsmtExposure'].fillna('N')\ndf['BsmtFinType1'].fillna('N')\ndf['BsmtFinType2'].fillna('N')\ndf['Electrical'].fillna('N')\ndf[\"AllSF\"] = df[\"GrLivArea\"] + df[\"TotalBsmtSF\"]\ndf['Area'] = df['LotArea']*df['LotFrontage']\ndf['Area_log'] = np.log1p(df['Area'])","6c8d5400":"df[\"LivingAreaRatio\"] = round(df[\"GrLivArea\"]\/df[\"AllSF\"], 2)\ndf[\"StreetAreaRatio\"] = round(df[\"LotFrontage\"]\/df[\"AllSF\"], 2)\ndf[\"HouseAge\"] = df[\"YrSold\"] - df[\"YearBuilt\"]\ndf[\"GarageAlleyRatio\"] = round(df[\"GarageArea\"]\/df[\"LotFrontage\"], 2)","2bdda14a":"def Gar_category(cat):\n    if cat <= 250:\n        return 1\n    elif cat <= 500 and cat > 250:\n        return 2\n    elif cat <= 1000 and cat > 500:\n        return 3\n    return 4\ndf['GarageArea_cat'] = df['GarageArea'].apply(Gar_category)\n\ndef Low_category(cat):\n    if cat <= 1000:\n        return 1\n    elif cat <= 2000 and cat > 1000:\n        return 2\n    elif cat <= 3000 and cat > 2000:\n        return 3\n    return 4\ndf['GrLivArea_cat'] = df['GrLivArea'].apply(Low_category)\n\ndef fl1_category(cat):\n    if cat <= 500:\n        return 1\n    elif cat <= 1000 and cat > 500:\n        return 2\n    elif cat <= 1500 and cat > 1000:\n        return 3\n    elif cat <= 2000 and cat > 1500:\n        return 4\n    return 5\ndf['1stFlrSF_cat'] = df['1stFlrSF'].apply(fl1_category)\ndf['2ndFlrSF_cat'] = df['2ndFlrSF'].apply(fl1_category)\n\ndef bsmtt_category(cat):\n    if cat <= 500:\n        return 1\n    elif cat <= 1000 and cat > 500:\n        return 2\n    elif cat <= 1500 and cat > 1000:\n        return 3\n    elif cat <= 2000 and cat > 1500:\n        return 4\n    return 5\ndf['TotalBsmtSF_cat'] = df['TotalBsmtSF'].apply(bsmtt_category)\n\ndef bsmt_category(cat):\n    if cat <= 500:\n        return 1\n    elif cat <= 1000 and cat > 500:\n        return 2\n    elif cat <= 1500 and cat > 1000:\n        return 3\n    elif cat <= 2000 and cat > 1500:\n        return 4\n    return 5\ndf['BsmtUnfSF_cat'] = df['BsmtUnfSF'].apply(bsmt_category)\n\ndef lot_category(cat):\n    if cat <= 50:\n        return 1\n    elif cat <= 100 and cat > 50:\n        return 2\n    elif cat <= 150 and cat > 100:\n        return 3\n    return 4\ndf['LotFrontage_cat'] = df['LotFrontage'].apply(lot_category)\n\ndef lot_category1(cat):\n    if cat <= 5000:\n        return 1\n    elif cat <= 10000 and cat > 5000:\n        return 2\n    elif cat <= 15000 and cat > 10000:\n        return 3\n    elif cat <= 20000 and cat > 15000:\n        return 4\n    elif cat <= 25000 and cat > 20000:\n        return 5\n    return 6\ndf['LotArea_cat'] = df['LotArea'].apply(lot_category1)\n\ndef year_category(yb):\n    if yb <= 1910:\n        return 1\n    elif yb <= 1950 and yb > 1910:\n        return 2\n    elif yb >= 1950 and yb < 1980:\n        return 3\n    elif yb >= 1980 and yb < 2000:\n        return 4\n    return 5\n\n\n\ndf['YearBuilt_cat'] = df['YearBuilt'].apply(year_category) \ndf['YearRemodAdd_cat'] = df['YearRemodAdd'].apply(year_category)\ndf['GarageYrBlt_cat'] = df['GarageYrBlt'].apply(year_category)\n\ndef vnr_category(cat):\n    if cat <= 250:\n        return 1\n    elif cat <= 500 and cat > 250:\n        return 2\n    elif cat <= 750 and cat > 500:\n        return 3\n    return 4\n\ndf['MasVnrArea_cat'] = df['MasVnrArea'].apply(vnr_category)\n\ndef allsf_category(yb):\n    if yb <= 1000:\n        return 1\n    elif yb <= 2000 and yb > 1000:\n        return 2\n    elif yb >= 3000 and yb < 2000:\n        return 3\n    elif yb >= 4000 and yb < 3000:\n        return 4\n    elif yb >= 5000 and yb < 4000:\n        return 5\n    elif yb >= 6000 and yb < 5000:\n        return 6\n    return 7\n\ndf['AllSF_cat'] = df['AllSF'].apply(allsf_category)\n\n# save an extra copy for feature cross\ndf1 = df.copy()\n\ndummy_col=['OverallQual', 'AllSF_cat', 'MiscVal','OverallCond', 'BsmtFinType2', 'SaleCondition','SaleType', 'YrSold', 'MoSold', 'MiscFeature', 'Fence', 'PoolQC', 'PoolArea', 'PavedDrive', 'GarageCond', 'GarageQual', 'GarageArea_cat', 'GarageCars', 'GarageFinish', 'GarageType', 'FireplaceQu', 'Fireplaces','Functional', 'TotRmsAbvGrd', 'KitchenQual', 'KitchenAbvGr', 'BedroomAbvGr', 'HalfBath', 'FullBath', 'BsmtHalfBath', 'BsmtFullBath','GrLivArea_cat','MSSubClass', 'MSZoning', 'LotFrontage_cat', 'LotArea_cat', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n          'BldgType', 'HouseStyle', 'YearBuilt_cat', 'YearRemodAdd_cat', 'RoofStyle', 'RoofMatl', 'Exterior2nd', 'Exterior1st', 'MasVnrType', 'MasVnrArea_cat', 'ExterQual', 'ExterCond', 'Foundation', \n          'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtUnfSF_cat', 'TotalBsmtSF_cat', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF_cat', '2ndFlrSF_cat']\n\ndf = pd.get_dummies(df, columns=dummy_col, drop_first=False)\n\ndf['LotFrontage_log'] = np.log1p(df['LotFrontage'])\ndf['LotArea_log'] = np.log1p(df['LotArea'])\ndf['BsmtUnfSF_log'] = np.log1p(df['BsmtUnfSF'])\n\ndf['Is_MasVnr'] = [1 if i != 0 else 0 for i in df['MasVnrArea']]\ndf['Is_BsmtFinSF1'] = [1 if i != 0 else 0 for i in df['BsmtFinSF1']]\ndf['Is_BsmtFinSF2'] = [1 if i != 0 else 0 for i in df['BsmtFinSF2']]\ndf['Is_BsmtUnfSF'] = [1 if i != 0 else 0 for i in df['BsmtUnfSF']]\ndf['Is_TotalBsmtSF'] = [1 if i != 0 else 0 for i in df['TotalBsmtSF']]\ndf['Is_2ndFlrSF'] = [1 if i != 0 else 0 for i in df['2ndFlrSF']]\ndf['Is_LowQualFinSF'] = [1 if i != 0 else 0 for i in df['LowQualFinSF']]\ndf['Is_GarageArea'] = [1 if i != 0 else 0 for i in df['GarageArea']]\ndf['Is_WoodDeckSF'] = [1 if i != 0 else 0 for i in df['WoodDeckSF']]\ndf['Is_OpenPorchSF'] = [1 if i != 0 else 0 for i in df['OpenPorchSF']]\ndf['Is_EnclosedPorch'] = [1 if i != 0 else 0 for i in df['EnclosedPorch']]\ndf['Is_3SsnPorch'] = [1 if i != 0 else 0 for i in df['3SsnPorch']]\ndf['Is_ScreenPorch'] = [1 if i != 0 else 0 for i in df['ScreenPorch']]\n\n\n\nprint('finished')","1efde57d":"# before tuning\ndef basic_details(df):\n    b = pd.DataFrame()\n    b['Missing value'] = df.isnull().sum()\n    b['N unique value'] = df.nunique()\n    b['dtype'] = df.dtypes\n    return b\nbasic_details(df)","c61d4546":"def descrictive_stat_feat(df):\n    df = pd.DataFrame(df)\n    dcol= [c for c in df.columns if df[c].nunique()>=10]\n    d_median = df[dcol].median(axis=0)\n    d_mean = df[dcol].mean(axis=0)\n    q1 = df[dcol].apply(np.float32).quantile(0.25)\n    q3 = df[dcol].apply(np.float32).quantile(0.75)\n    \n    #Add mean and median column to data set having more then 10 categories\n    for c in dcol:\n        df[c+str('_median_range')] = (df[c].astype(np.float32).values > d_median[c]).astype(np.int8)\n        df[c+str('_mean_range')] = (df[c].astype(np.float32).values > d_mean[c]).astype(np.int8)\n        df[c+str('_q1')] = (df[c].astype(np.float32).values < q1[c]).astype(np.int8)\n        df[c+str('_q3')] = (df[c].astype(np.float32).values > q3[c]).astype(np.int8)\n    return df\n\ndf = descrictive_stat_feat(df)","609eb068":"X_train = df[:train.shape[0]]\nX_test_fin = df[train.shape[0]:]\ny = train.SalePrice\nX_train['Y'] = y\ndf = X_train\nprint('finished')","e5cdea78":"X = df.drop('Y', axis=1)\ny = df.Y\n\nx_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\nd_test = xgb.DMatrix(X_test_fin)\n\n\nparams = {\n        'objective':'reg:linear',\n        'booster':'gbtree',\n        'max_depth':2,\n        'eval_metric':'rmse',\n        'learning_rate':0.08, \n        'min_child_weight':1,\n        'subsample':0.90,\n        'colsample_bytree':0.81,\n        'seed':45,\n        'reg_alpha':1,#1e-03,\n        'reg_lambda':0,\n        'gamma':0,\n        'nthread':-1\n\n}\n\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\nclf = xgb.train(params, d_train, 2000,  watchlist, early_stopping_rounds=300, maximize=False, verbose_eval=10)\n\np_test = clf.predict(d_test)","cfb232b5":"result = {}\nfor i in np.arange(0.01, 0.11, 0.01):\n    for j in range(2, 6, 1):\n        for k in np.arange(0.1, 1.1, 0.1):\n            params = {\n                    'objective':'reg:linear',\n            #         'n_estimators': 50,\n                    'booster':'gbtree',\n                    'max_depth':j,\n                    'eval_metric':'rmse',\n                    'learning_rate':i, \n                    'min_child_weight':1,\n                    'subsample':k,\n                    'colsample_bytree':0.81,\n                    'seed':45,\n                    'reg_alpha':1,#1e-03,\n                    'reg_lambda':0,\n                    'gamma':0,\n                    'nthread':-1\n\n              }\n            clf_grid = xgb.train(params, d_train, 2000,  watchlist, early_stopping_rounds=300, maximize=False, verbose_eval=10)\n            result[(i, j, k)] = clf_grid.best_score\n            \n#print the result            \nprint('learning_rate: {} \/n max_depth: {} \/n subsample: {}'.format(min(result, key=result.get))","21fb9dbe":"!pip install --quiet optuna","5a7d4b40":"x_train","4f41d261":"import optuna\n\nX_train = df[:train.shape[0]]\nX_test_fin = df[train.shape[0]:]\ny = train.SalePrice\nX_train['Y'] = y\ndf = X_train\n#X = df.drop('Y', axis=1)\nX = df\ny = df.Y\n\nx_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\nd_test = xgb.DMatrix(X_test_fin)\n    \ndef objective(trial):\n    \n    \n    param = {\n        \"objective\": \"reg:linear\",\n        \"eval_metric\": \"rmse\",\n        \"booster\": \"gbtree\",\n        'min_child_weight':1,\n        'colsample_bytree':0.81,\n        'seed':45,\n        'reg_alpha':1,#1e-03,\n        'reg_lambda':0,\n        'nthread':-1,\n    }\n    \n    if param[\"booster\"] == \"gbtree\" or param[\"booster\"] == \"dart\":\n        param[\"max_depth\"] = trial.suggest_int(\"max_depth\", 1, 9)\n#          param[\"eta\"] = trial.suggest_loguniform(\"eta\", 1e-8, 1.0)\n        param[\"gamma\"] = trial.suggest_loguniform(\"gamma\", 1e-8, 1.0)\n        #param[\"grow_policy\"] = trial.suggest_categorical(\"grow_policy\", [\"depthwise\", \"lossguide\"])\n        param[\"learning_rate\"] = trial.suggest_float('learning_rate', 0.01, 0.11)\n        param[\"subsample\"] = trial.suggest_float('subsample', 0.01, 0.11)\n    if param[\"booster\"] == \"dart\":\n        param[\"sample_type\"] = trial.suggest_categorical(\"sample_type\", [\"uniform\", \"weighted\"])\n        param[\"normalize_type\"] = trial.suggest_categorical(\"normalize_type\", [\"tree\", \"forest\"])\n        param[\"rate_drop\"] = trial.suggest_loguniform(\"rate_drop\", 1e-8, 1.0)\n        param[\"skip_drop\"] = trial.suggest_loguniform(\"skip_drop\", 1e-8, 1.0)\n\n    # Add a callback for pruning.\n    pruning_callback = optuna.integration.XGBoostPruningCallback(trial, \"validation-rmse\")\n    bst = xgb.train(param, d_train, evals=[(d_test, \"validation\")], early_stopping_rounds=300,callbacks=[pruning_callback], maximize=False)\n    preds = bst.predict(d_valid)\n    rmse_score = sklearn.metrics.mean_squared_error(y_valid, preds, squared=True)\n    return rmse_score\n    \n\nstudy = optuna.create_study(direction='minimize')\nstudy.optimize(objective, n_trials=100)\n\ntrial = study.best_trial\n\nprint('RMSE: {}'.format(trial.value))\nprint(\"Best hyperparameters: {}\".format(trial.params))","bf8f5d05":"#top 50 important features\nfig, ax = plt.subplots(figsize=(12,18))\nxgb.plot_importance(clf, max_num_features=50, height=0.8, ax=ax)\nplt.show()","4955aacb":"dummy_col=['OverallQual', 'AllSF_cat', 'MiscVal','OverallCond', 'BsmtFinType2', 'SaleCondition','SaleType', 'YrSold', 'MoSold', 'MiscFeature', 'Fence', 'PoolQC', 'PoolArea', 'PavedDrive', 'GarageCond', 'GarageQual', 'GarageArea_cat', 'GarageCars', 'GarageFinish', 'GarageType', 'FireplaceQu', 'Fireplaces','Functional', 'TotRmsAbvGrd', 'KitchenQual', 'KitchenAbvGr', 'BedroomAbvGr', 'HalfBath', 'FullBath', 'BsmtHalfBath', 'BsmtFullBath','GrLivArea_cat','MSSubClass', 'MSZoning', 'LotFrontage_cat', 'LotArea_cat', 'Street', 'Alley', 'LotShape', 'LandContour', 'Utilities', 'LotConfig', 'LandSlope', 'Neighborhood', 'Condition1', 'Condition2',\n          'BldgType', 'HouseStyle', 'YearBuilt_cat', 'YearRemodAdd_cat', 'RoofStyle', 'RoofMatl', 'Exterior2nd', 'Exterior1st', 'MasVnrType', 'MasVnrArea_cat', 'ExterQual', 'ExterCond', 'Foundation', \n          'BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtUnfSF_cat', 'TotalBsmtSF_cat', 'Heating', 'HeatingQC', 'CentralAir', 'Electrical', '1stFlrSF_cat', '2ndFlrSF_cat']\n\ntest_df = df1.copy()\n\n## Feature cross\ntest_df['OverallCond_OverallQual'] = test_df['OverallCond'] + test_df['OverallQual']\ndummy_col.append('OverallCond_OverallQual')\n\ndf = pd.get_dummies(test_df, columns=dummy_col, drop_first=False)\n\ndf['LotFrontage_log'] = np.log1p(df['LotFrontage'])\ndf['LotArea_log'] = np.log1p(df['LotArea'])\ndf['BsmtUnfSF_log'] = np.log1p(df['BsmtUnfSF'])\n\ndf['Is_MasVnr'] = [1 if i != 0 else 0 for i in df['MasVnrArea']]\ndf['Is_BsmtFinSF1'] = [1 if i != 0 else 0 for i in df['BsmtFinSF1']]\ndf['Is_BsmtFinSF2'] = [1 if i != 0 else 0 for i in df['BsmtFinSF2']]\ndf['Is_BsmtUnfSF'] = [1 if i != 0 else 0 for i in df['BsmtUnfSF']]\ndf['Is_TotalBsmtSF'] = [1 if i != 0 else 0 for i in df['TotalBsmtSF']]\ndf['Is_2ndFlrSF'] = [1 if i != 0 else 0 for i in df['2ndFlrSF']]\ndf['Is_LowQualFinSF'] = [1 if i != 0 else 0 for i in df['LowQualFinSF']]\ndf['Is_GarageArea'] = [1 if i != 0 else 0 for i in df['GarageArea']]\ndf['Is_WoodDeckSF'] = [1 if i != 0 else 0 for i in df['WoodDeckSF']]\ndf['Is_OpenPorchSF'] = [1 if i != 0 else 0 for i in df['OpenPorchSF']]\ndf['Is_EnclosedPorch'] = [1 if i != 0 else 0 for i in df['EnclosedPorch']]\ndf['Is_3SsnPorch'] = [1 if i != 0 else 0 for i in df['3SsnPorch']]\ndf['Is_ScreenPorch'] = [1 if i != 0 else 0 for i in df['ScreenPorch']]\n\n\n\nprint('finished')","89b874ff":"X_train = df[:train.shape[0]]\nX_test_fin = df[train.shape[0]:]\ny = train.SalePrice\nX_train['Y'] = y\ndf = X_train\nprint('finished')","a75ee134":"X = df.drop('Y', axis=1)\ny = df.Y\n\nx_train, x_valid, y_train, y_valid = train_test_split(X, y, test_size=0.2, random_state=10)\n\n\n# sc = MinMaxScaler(feature_range=(-1, 1))\n# x_train = sc.fit_transform(x_train)\n# x_valid = sc.fit_transform(x_valid)\n\nd_train = xgb.DMatrix(x_train, label=y_train)\nd_valid = xgb.DMatrix(x_valid, label=y_valid)\nd_test = xgb.DMatrix(X_test_fin)\n\n\n\nparams = {\n        'objective':'reg:squarederror',\n#         'n_estimators': 50,\n        'booster':'gbtree',\n        'max_depth':4,\n        'eval_metric':'rmse',\n        'learning_rate':0.08, \n        'min_child_weight':1,\n        'subsample':0.60,\n        'colsample_bytree':0.81,\n        'seed':45,\n        'reg_alpha':1,#1e-03,\n        'reg_lambda':0,\n        'gamma':0,\n        'nthread':-1\n\n}\n\n\nwatchlist = [(d_train, 'train'), (d_valid, 'valid')]\n\nclf = xgb.train(params, d_train, 2000,  watchlist, early_stopping_rounds=300, maximize=False, verbose_eval=10)\n\np_test = clf.predict(d_test)","335c4dd9":"xgb_cv = cv(dtrain=d_train, params=params, nfold=3,\n                    num_boost_round=50, early_stopping_rounds=300, metrics=\"rmse\", as_pandas=True, seed=123)","fcdd51dd":"sub = pd.DataFrame()\nsub['Id'] = test['Id']\nsub['SalePrice'] = p_test\nsub","7e4af8d5":"sub.to_csv('.\/submission.csv', index=False)","ee2ad3d8":"This notebook is based on https:\/\/www.kaggle.com\/dmkravtsov\/3-2-house-prices\/execution\n\n# Offer some new ideas on feature engineering\n1. Number of Features\n2. Year between house built and sold\n3. The ratio between living area and overall area\n4. the ratio between the street and all area\n5. the ratio between garage area and the street\n\n# Use optuna for hyperparameter tuning\nGrid Search takes > two hours for three features. Optuna takes about 1 min for more than three features.\n(inspired by this medium post https:\/\/medium.com\/optuna\/using-optuna-to-optimize-xgboost-hyperparameters-63bfcdfd3407)","f093fcd0":"Use 3-fold Cross Validation to Verify the Result","67ea563a":"Add Mean and Median as the Feature","9e7775e9":"# Create Submission File","0b407000":"Import libraries","df2af103":"# Feature Cross","703662d5":"# Parameter Tuning","7bc8384b":"Fill NA, Convert to Categorical and Get Dummies","370bd115":"Outlier Detection","229569df":"Load Dataset","f6f1a7e0":"Describe the dataset (Transposed for readbility)","8a95371d":"1. Grid Search","1178765c":"Display the number of Missing Values, Unique Values and Data Type","18cde984":"2. Optuna","f7e42743":"# idea 1: the number of features a house has","1d98c56e":"# # idea 2: the ratio between the living area and all area\n# # idea 3: the ratio between the street and all area\n# # idea 4: the number of years between built and sold\n# # idea 5: the ratio between garage area and the street","43288583":"Create matrices for feature selection","d1cf345d":"Use Feature Importance to identify potential features","6a7933c3":"Learning Rate, Max Depth, Subsample","772d7cba":"Concatenate train and test"}}