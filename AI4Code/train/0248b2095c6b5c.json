{"cell_type":{"514349e4":"code","2d812d00":"code","2a269db5":"code","4a7f1752":"code","af7ed39e":"code","faa524f0":"code","2e613fab":"code","08ba7bbb":"code","0d56352e":"code","625ba6c5":"code","da4bca28":"code","7b0fb9e7":"code","2e279a64":"code","81f54985":"code","2f2cddb0":"code","4fc8fb20":"code","c4e255f2":"code","7bcd59e0":"code","27e6b56c":"code","6bbd69ba":"code","b44d6fc2":"code","e8313dca":"code","a6cf346b":"code","59db68e4":"code","d1eb89d9":"code","b89e3e9e":"code","da3abd2a":"code","c5c8f9be":"code","048a48d7":"code","22062745":"code","2e943165":"code","d23b8f47":"code","0a42fd64":"code","e4f39f09":"markdown","96983b4d":"markdown","58e57704":"markdown","405a88a7":"markdown","b1376347":"markdown","5bdfd5fa":"markdown","5e4a0b24":"markdown","2e1e259b":"markdown"},"source":{"514349e4":"import numpy as np\nimport pandas as pd\n\nimport warnings \nwarnings.filterwarnings('ignore')","2d812d00":"train_data = pd.read_csv('..\/input\/priceofbooks-csv\/Data_Train.csv')\n\ntrain_data.head(20)","2a269db5":"train_data.shape","4a7f1752":"train_data.describe(include='all')","af7ed39e":"train_data.info()","faa524f0":"train_data['Ratings'] = train_data['Ratings'].str[0].astype('float64')\ntrain_data['Reviews'] = train_data['Reviews'].str[0].astype('float64')\n\n\ntrain_data.head()","2e613fab":"train_data.drop(columns=['Title', 'Author', 'Synopsis', 'Genre'], inplace=True)\n\ntrain_data.head()","08ba7bbb":"train_data['Edition type'] = train_data['Edition'].str.split('\u2013').str[0].str.replace(',', '')\ntrain_data['Edition year'] = train_data['Edition'].str.split(' ').str[-1]\n\n\n\ntrain_data.head()","0d56352e":"train_data['Edition type'].value_counts()","625ba6c5":"train_data.drop('Edition', axis=1, inplace=True)\n\ntrain_data.head()","da4bca28":"train_data['BookCategory'].value_counts()","7b0fb9e7":"train_data.dtypes","2e279a64":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(20, 8))\nsns.barplot(x=train_data['BookCategory'], y=train_data['Price'])\nplt.xticks(rotation=90)\nplt.plot()","81f54985":"plt.figure(figsize=(20, 8))\nsns.barplot(x=train_data['Edition type'], y=train_data['Price'])\nplt.xticks(rotation=90)\nplt.plot()","2f2cddb0":"train_data.info()","4fc8fb20":"pd.set_option('display.max_rows', 50)\nx = train_data[train_data['Edition year'].apply(lambda x: str(x).isalpha())]\nx","c4e255f2":"train_data = train_data[train_data['Edition year'].apply(lambda x: str(x).isdigit())]","7bcd59e0":"train_data.shape","27e6b56c":"train_data['Edition year'] = train_data['Edition year'].astype('int64')\n","6bbd69ba":"train_data['Edition year'].corr(train_data.Price)","b44d6fc2":"train_data.corr()","e8313dca":"train_data.head()\ntrain_data = train_data[['Reviews',\t'Ratings',\t'BookCategory',\t'Edition type',\t'Edition year',\t'Price']]\ntrain_data.head(10)","a6cf346b":"train_data['Edition type'].value_counts()","59db68e4":"train_data['Edition type'] = train_data['Edition type'].replace(['Tankobon Softcover',\n                                                                 'Loose Leaf',\n                                                                 'Board book',\n                                                                 'Leather Bound',\n                                                                 'Product Bundle',\n                                                                 'Library Binding'], 'Rare')\ntrain_data['Edition type'] = train_data['Edition type'].replace(['Perfect Paperback',\n                                                                 '(German)Paperback',\n                                                                 '(Kannada)Paperback',\n                                                                 '(French)Paperback',\n                                                                 '(Spanish)Paperback'], 'Paperback')\ntrain_data['Edition type'].value_counts()","d1eb89d9":"print(train_data.dtypes)\n\nfrom sklearn.preprocessing import LabelEncoder\n\nlabelencoder = LabelEncoder()\ntrain_data['BookCategory'] = labelencoder.fit_transform(train_data['BookCategory'])\n\n\ntrain_data['Edition type'] = labelencoder.fit_transform(train_data['Edition type'])\n\n\nprint(train_data.head())","b89e3e9e":"from sklearn.model_selection import train_test_split\n\narray = train_data.values\nX = array[:, 0:5]\nY = array[:, 5]\n\nx_train, x_rem, y_train, y_rem = train_test_split(X, Y, test_size=0.30, random_state=1)\n","da3abd2a":"X_val , X_test,Y_val, Y_test =train_test_split(x_rem, y_rem, test_size=0.30, random_state=1)","c5c8f9be":"from sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import ExtraTreesRegressor\nfrom sklearn.metrics import mean_absolute_error\n\n# Spot check algorithms\nmodels = []\nmodels.append(('LR', LinearRegression()))\nmodels.append(('LA', Lasso()))\nmodels.append(('EN', ElasticNet()))\nmodels.append(('DTR', DecisionTreeRegressor()))\nmodels.append(('KNR', KNeighborsRegressor()))\nmodels.append(('RFR', RandomForestRegressor()))\nmodels.append(('ETR', ExtraTreesRegressor()))\n\nfrom sklearn.metrics import mean_absolute_error\n\n# Evaluate each model\nresults = []\nnames = []\nfor name, model in models:\n  model.fit(x_train, y_train)\n  predictions = model.predict(x_valid)\n  cv_results = mean_absolute_error(y_valid, predictions)\n  results.append(cv_results)\n  names.append(name)\n  msg = '%s : %f '% (name, cv_results)\n  print(msg)","048a48d7":"# Final model\nknn = KNeighborsRegressor()\nknn.fit(x_train, y_train)","22062745":"Y_pre = knn.predict(X_test)","2e943165":"from sklearn.metrics import r2_score, mean_squared_error","d23b8f47":"r2_score(Y_test,Y_pre)","0a42fd64":"mean_squared_error(Y_test,Y_pre)","e4f39f09":"Thus the label encoding of both the object features can be done. ","96983b4d":"#### New train data shape","58e57704":"Therfore there is no missing values.","405a88a7":"Priinting the rows which does not contain digits in the edition year feature.","b1376347":"We cannt drop those instances as we need the output od the same shape.\n\nThefore filling a random values in those instances. ","5bdfd5fa":"Data Cleaning","5e4a0b24":"# Book Price Prediction","2e1e259b":"#### Predict values"}}