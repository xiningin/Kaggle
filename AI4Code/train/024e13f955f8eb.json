{"cell_type":{"5843abec":"code","8f0637fd":"code","d190289b":"code","4f629c71":"code","541836a6":"code","00f5ca8f":"code","ef29b157":"code","70b69c6f":"code","6dd47a4b":"code","0b75f2e3":"code","67b0158a":"code","c350e92f":"code","1385ab9f":"code","fe5fc907":"code","b9b9756a":"markdown","e286c9c5":"markdown","ef58c541":"markdown","9efacab9":"markdown","18b52c52":"markdown","a5058623":"markdown","75487fa8":"markdown","da257199":"markdown","cedbb59c":"markdown","76a956cd":"markdown","59c0657e":"markdown"},"source":{"5843abec":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, experimental, Dropout\nfrom sklearn.model_selection import train_test_split","8f0637fd":"train_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')","d190289b":"train_df.head()","4f629c71":"# Spliting and shuffling our dataset.\ntrain_df, val_df = train_test_split(train_df, test_size=0.2)\n\n# Forming np arrays of labels and features.\n\ntrain_labels = np.array(train_df.pop('label'))\nval_labels = np.array(val_df.pop('label'))\n\ntrain_features=np.array(train_df)\nval_features=np.array(val_df)\ntest_features=np.array(test_df)","541836a6":"height=28\nwidth=28\nnum_classes=10\n\ntrain_features=train_features.reshape(train_features.shape[0],height,width,1)\nval_features=val_features.reshape(val_features.shape[0],height,width,1)\n\ntrain_labels = keras.utils.to_categorical(train_labels, num_classes)\nval_labels = keras.utils.to_categorical(val_labels, num_classes)","00f5ca8f":"print('Training features shape: ',train_features.shape)\nprint('Validation features shape: ',val_features.shape)\n\nprint('Training labels shape: ', train_labels.shape)\nprint('Validation labels shape: ', val_labels.shape)","ef29b157":"plt.imshow(train_features[1].reshape(28, 28))\nplt.title(\"labeled one-hot vector: {}\".format(train_labels[1]))","70b69c6f":"model = Sequential([\n  experimental.preprocessing.Rescaling(1.\/255, input_shape=(train_features.shape[1:])),\n  Conv2D(16, 3, padding='same', activation='relu'),\n  MaxPooling2D(),\n  Conv2D(32, 3, padding='same', activation='relu'),\n  MaxPooling2D(),\n  Conv2D(64, 3, padding='same', activation='relu'),\n  MaxPooling2D(),\n  Flatten(),\n  Dense(128, activation='relu'),\n  Dropout(0.2),\n  Dense(num_classes, activation='softmax')\n])","6dd47a4b":"model.compile(optimizer='adam',\n              loss=keras.losses.categorical_crossentropy,\n              metrics=['accuracy'])","0b75f2e3":"model.summary()","67b0158a":"epochs=20\nbatch_size=32\n\nhistory = model.fit(\n    train_features,\n    train_labels,\n    epochs=epochs,\n    batch_size=batch_size,\n    validation_data=(val_features, val_labels))\n","c350e92f":"test_features=test_features.reshape(test_features.shape[0],height,width,1)\npredictions = np.argmax(model.predict(test_features),axis = 1)","1385ab9f":"predictions","fe5fc907":"submission_dataframe = pd.DataFrame({\"ImageId\" : range(1, test_features.shape[0]+1), \"Label\" : predictions})\nsubmission_dataframe.to_csv(\"submission.csv\", index = False)","b9b9756a":"# Building the model","e286c9c5":"# Using the model on our test dataset and submitting the predictions ","ef58c541":"if you have any question feel free to ask!\nThis was my first Kaggle notebook.\nAn upvote would be appreciatted since i'm beginning. Thank you!","9efacab9":"As expected, each features is an image of shape (28,28,1),\nand each label has is a vector of size 10 (number of classes, 10 since there are 10 digits).\n\nWe can plot of the images used for training, and see its label (one-hot encoded)","18b52c52":"# Data processing","a5058623":"We will split the previous dataframe: 80% for training and 20% for validation.\nThe features used for the training are the 784 pixels of each images, the labels are given by the column 'label'.\nWe will also work with numpy arrays","75487fa8":"The loss used is categorical crossentropy since we are in a classification problem with more that 2 classes.","da257199":"We obtain a validation accuracy of 99.00% after training. Not bad!","cedbb59c":"# Thank you for reading!","76a956cd":"Each images has a shape 28x28x1 (1 because we're working with black and white images), but in the dataframe the pixels are flattened. \nWe would like to reshape them back to their original shape so we can apply them as entries of our convolutional neural network.\n\nWe'll also applying one-hot encoding to our labels.","59c0657e":"It's time to build the model.\nThe first layer we'll used is a preprocessing layer that allow us to normalize the pixels between 0 1. \nWe could do this outside the model but I wanted to try this layer so i opted for that.\nNormalizing our datas help us to train the model faster and reduces the chance of getting stuck in a local optima (example: for the sigmoid function the gradient is close to 0 for high values while it's high close to 0)\n\nWe apply several layers of Conv2D + Maxpooling2D, which help the model identifying visual features while reducing the number of features in input of of dense neural network.\nI used almost the same architecture as a model used to classify flowers: https:\/\/www.tensorflow.org\/tutorials\/images\/classification\n\nI also added a Dropout layer to reduce overfitting. \n"}}