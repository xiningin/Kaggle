{"cell_type":{"4e0e1fb0":"code","bc9b94fe":"code","cc1f993b":"code","51ba7ff1":"code","633d5133":"code","fde98125":"code","a81e49fe":"code","c006d210":"code","570dde15":"code","fec98a2c":"code","b644d985":"code","0d031ae1":"code","09099792":"markdown","50f7479d":"markdown","d26ce343":"markdown","4d8fecd9":"markdown","cb4c6746":"markdown","2dbd226d":"markdown"},"source":{"4e0e1fb0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bc9b94fe":"sales_df = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')","cc1f993b":"sales_df['date'] = pd.to_datetime(sales_df['date'], format = '%d.%m.%Y')\nsales_df['year_month'] = sales_df['date'].dt.to_period('M')","51ba7ff1":"sales_df['revenue'] = sales_df['item_price']*sales_df['item_cnt_day']","633d5133":"monthly_df = sales_df.groupby(['shop_id', 'item_id', 'year_month'], as_index = False).agg({'item_price':'first', 'item_cnt_day':'sum', 'revenue' : 'sum'})","fde98125":"monthly_df","a81e49fe":"def test_ts_frequency(df):\n    \n    # For every shop-item, calculate the time between observations\n    df = df.sort_values(['shop_id', 'item_id'])\n    df['month_start'] = pd.PeriodIndex(df['year_month']).to_timestamp()\n    df['delta'] = df['month_start'] - df.groupby(['shop_id', 'item_id'])['month_start'].shift()\n    \n    # Now, since for every shop-item there must be exactly one observation per month\n    # the differences between observations must be all 28, 30 or 31.\n    \n    # There are shop-items that may appear in a single month. In those cases\n    # delta will be NaT, because there is no second period to compare dates\n    # This is why we'll also filter out rows where delta is NaT\n    result = df.loc[~df['delta'].isna(), 'delta'].dt.days.isin([28, 30, 31]).all()\n    \n    return result","c006d210":"test_ts_frequency(monthly_df) # False. Our time series still has holes in it!","570dde15":"def fix_ts_frequency(df):\n    \n    # For an univariate timeseries (one shop-item)\n    # Create a fixed frequency index that start from the last obsv and ends at the last\n    min_month = df['year_month'].min()\n    max_month = df['year_month'].max()\n    period_range = pd.period_range(start = min_month, end = max_month)\n    period_index = pd.PeriodIndex(period_range, name = 'year_month')\n    \n    # Set the new index\n    df = df.set_index('year_month')\\\n    .reindex(period_index)\\\n    .reset_index()\n    \n    # Fill na values for the new rows that will appear\n    df['item_cnt_day'] = df['item_cnt_day'].fillna(0)\n    df['revenue'] = df['revenue'].fillna(0)\n    df = df.fillna(method = 'ffill')\n    \n    return df\n\n# Apply our function to every time series in the dataframe (every shop-item series)\nfixed_freq_monthly_df = monthly_df.groupby(by = ['shop_id', 'item_id'], as_index = False).apply(fix_ts_frequency)b","fec98a2c":"fixed_freq_monthly_df","b644d985":" test_ts_frequency(fixed_freq_monthly_df) # True","0d031ae1":"fixed_freq_monthly_df.to_csv('monthly_sales.csv', index = False)","09099792":"# Data Loading","50f7479d":"# Saving our work\nFixing the time series take many minutes to run. Hopefully, we want to this a single time.","d26ce343":"# The problem\nThe original dataset provided by the competition has some issues related to the time series frequency.<br>\nFirst of all we need to make montlhy predictions, but the data provided is daily data. So it may by interesting to aggregate the data monthly.<br><br>\n\nBesides that, there are \"holes\" in the dataset. If a given item did not have any sales in a particular shop in a particular day, that line will not appear on the dataset.<br>\nWe may want to fill those holes so that the time series have a fixed frequency.","4d8fecd9":"# Aggregating by monthly data\nFirst we'll do the easy part, that is aggregating the to monthly data","cb4c6746":"# Checking the data for roles\nAggregating the data may have been enough to fill all the holes in the time series. I will write a function to test for that","2dbd226d":"# Fixing the time series frequency\nSince our time series still doesn't have fixed frequency, we are going to have to fix it."}}