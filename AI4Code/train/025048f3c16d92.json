{"cell_type":{"de280f43":"code","6c93c647":"code","250721d5":"code","6c2d1f50":"code","4b303c45":"code","a65f253b":"code","84242f01":"code","d5527374":"code","26b5edf6":"code","5d00333b":"code","f884897e":"code","eaef39ef":"code","ffe805a2":"code","4b93e71a":"code","4bb3c5b0":"code","51431ddd":"markdown"},"source":{"de280f43":"import pandas as pd \nimport numpy as np \nimport scipy as sp \nimport random \nimport matplotlib.pyplot as plt \n\nfrom sklearn.metrics.pairwise import cosine_similarity\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.decomposition import PCA ","6c93c647":"train = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/train.csv\", nrows=3200)\ntest = pd.read_csv(\"..\/input\/ventilator-pressure-prediction\/test.csv\", nrows=3200)\ntrain.head()","250721d5":"\n'''\nOrganize to make the time series of each breath_id common. \nScale processing is also added because we want to reduce the dimension.\n'''\n\n# Creation of serial numbers\ntrain[\"time_step_class\"] = train.groupby(\"breath_id\").cumcount()\ntest[\"time_step_class\"] = test.groupby(\"breath_id\").cumcount()\n\n# pivot table \npiv_train = train.pivot_table(values=\"u_in\", index=\"breath_id\", columns=\"time_step_class\")\npiv_test = test.pivot_table(values=\"u_in\", index=\"breath_id\", columns=\"time_step_class\")\n\n# Scale\nm = MinMaxScaler(feature_range=(0.0, 1.0)).fit(piv_train)\npiv_train = pd.DataFrame(m.transform(piv_train), columns=piv_train.columns, index=piv_train.index)\npiv_test = pd.DataFrame(m.transform(piv_test), columns=piv_test.columns, index=piv_test.index)\n\npiv_train.head()","6c2d1f50":"pca = PCA()\npca.fit(piv_train)\n\nplt.figure(figsize=(15, 6))\nplt.plot(pca.explained_variance_ratio_.cumsum())\nplt.grid()\nplt.xlabel(\"n_components\")\nplt.ylabel(\"explained_variance_ratio_\")\nplt.show()","4b303c45":"pca = PCA(n_components=3, random_state=42).fit(piv_train)\n\npca_train = pca.transform(piv_train)\npca_test = pca.transform(piv_test)\n\npca_train = pd.DataFrame(pca_train, columns=[\"c\"+str(c) for c in range(3)], index=piv_train.index)\npca_test = pd.DataFrame(pca_test, columns=[\"c\"+str(c) for c in range(3)], index=piv_test.index)\n\npca_train.head()","a65f253b":"# concat train, test \ndf = pd.concat([pca_train, pca_test])\n\nlast_train_breath_idx = pca_train.shape[0]","84242f01":"\n\npiv_sparse = sp.sparse.csr_matrix(df.values)\nbreath = cosine_similarity(piv_sparse)\nbreath = pd.DataFrame(breath, columns=df.index, index=df.index)\nbreath = breath.iloc[:last_train_breath_idx, last_train_breath_idx:]\n\nbreath.head()\n\n'''\nindex: train.breath_id \ncolumns: test.breath_id\n\n'''","d5527374":"# helper F \ndef find_similar_breath_id(te_breath, n=10):\n    x = breath[te_breath].sort_values(ascending=False)[:n]\n    return pd.DataFrame({\"similar\": x.values}, index=x.index)\n\n\ndef find_similar_pressure(te_breath):\n    similar = find_similar_breath_id(te_breath, n=1)\n    sim_pressure = train[train.breath_id == similar.index[0]].sort_values(\"time_step\", ascending=True)[\"pressure\"].values\n    return sim_pressure, similar.index[0]","26b5edf6":"random_test_breath_id = np.random.choice(test.breath_id.unique(), 5)\nfind_similar_breath_id(random_test_breath_id[0]).style.background_gradient(cmap=\"Blues\")","5d00333b":"find_similar_breath_id(random_test_breath_id[1]).style.background_gradient(cmap=\"Blues\")","f884897e":"a, _  = find_similar_pressure(random_test_breath_id[0])\na","eaef39ef":"b, _ = find_similar_pressure(random_test_breath_id[1])\nb","ffe805a2":"\n'''\nProcess for all sample test data.\n'''\n\ntest_breath_id = test.breath_id.unique()\n\npredict_list, sim_breath_list = [], []\nfor b in test_breath_id:\n    simlar, sim_breath = find_similar_pressure(b)\n    predict_list.append(simlar)\n    sim_breath_list.append(np.array([sim_breath]*80))\npredict_list = np.concatenate(predict_list)\nsim_breath_list = np.concatenate(sim_breath_list)\n\ntest[\"pressure\"] = predict_list\ntest[\"similar_breath_id\"] = sim_breath_list \ntest.head()","4b93e71a":"\n'''\nDraw the pressure value of the most similar training data from each test data. \nAs it can be read, it captures the general tendency of u_in, \nbut the impression that it strongly reflects the similar relationship after 1.5 seconds in particular.\n'''\n\nfig, axes = plt.subplots(2, 5, figsize=(15, 6))\nax = axes.ravel()\n\nfor i in range(5):\n    x = test[test.breath_id == random_test_breath_id[i]].sort_values(\"time_step\", ascending=True)\n    tr_breath_id = x.similar_breath_id.values[0]\n    xx = train[train.breath_id == tr_breath_id].sort_values(\"time_step\", ascending=True)\n    \n    x[[\"time_step\", \"u_in\", \"u_out\", \"pressure\"]].set_index(\"time_step\").plot(ax=ax[i])\n    xx[[\"time_step\", \"u_in\", \"u_out\", \"pressure\"]].set_index(\"time_step\").plot(ax=ax[i+5])\n    \n    ax[i].set_title(f\"braeth_id={tr_breath_id}\")\n    ax[i+5].set_title(f\"braeth_id={test_breath_id[i]}\")\n    \n    ax[i].set_xlabel(\"\")\n    ax[i+5].set_xlabel(\"\")    \n    ax[i].set_yticks(range(0, 50+1, 10))\n    ax[i].set_ylim(0, 50)\n    ax[i+5].set_yticks(range(0, 50+1, 10))\n    ax[i+5].set_ylim(0, 50)\n    \n    if i == 0:\n        ax[i].set_ylabel(\"Train\", c=\"r\")\n        ax[i+5].set_ylabel(\"Test\", c=\"b\")\nplt.tight_layout()","4bb3c5b0":"\n'''\nHowever, we do not recommend submitting forecasts from this process.\n'''\n\ntest[[\"id\", \"pressure\"]].to_csv(\"submission.csv\", index=False)","51431ddd":"# A simple submission "}}