{"cell_type":{"336d9312":"code","400c703c":"code","5a09f3dc":"code","31f87ecd":"code","ef234be7":"code","13361492":"code","3e46ffc4":"code","888b736a":"code","07733bc6":"code","a03dd382":"code","385c4909":"code","5192516d":"code","fb126918":"markdown","e62bc299":"markdown","370935c4":"markdown","d1fdc65e":"markdown","54b7c5ee":"markdown","dbc1939b":"markdown","1114e830":"markdown","a9143378":"markdown","c2380004":"markdown"},"source":{"336d9312":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","400c703c":"!pip install pyspark","5a09f3dc":"import pyspark\nimport random\n\nfrom sklearn import datasets\nfrom pyspark.sql import SQLContext\nfrom pyspark.ml.linalg import Vectors\nfrom pyspark.ml.feature import VectorSlicer\nfrom pyspark.ml.regression import LinearRegression\nfrom pyspark.ml.tuning import ParamGridBuilder, TrainValidationSplit\nfrom pyspark.ml.evaluation import RegressionEvaluator\nfrom pyspark.mllib.evaluation import RegressionMetrics","31f87ecd":"diabetes = datasets.load_diabetes()\ndiabetes_features= []","ef234be7":"diabetes","13361492":"for feature_list in diabetes.data:\n    temp= [float(i) for i in feature_list]\n    diabetes_features.append(Vectors.dense(temp))\n    \ndiabetes_target = [float(i) for i in diabetes.target]\nfeatures_and_predictions = list(zip(diabetes_target, diabetes_features))\n\nsc = pyspark.SparkContext(appName=\"LinearRegression_Diabetes\")\nsqlContext = SQLContext(sc)\ndf = sqlContext.createDataFrame(features_and_predictions, [\"label\", \"features\"])","3e46ffc4":"lr = LinearRegression(maxIter=10)","888b736a":"paramGrid = ParamGridBuilder()\\\n    .addGrid(lr.regParam, [0.1, 0.01]) \\\n    .addGrid(lr.fitIntercept, [False, True])\\\n    .addGrid(lr.elasticNetParam, [0.0, 0.5, 1.0])\\\n    .build()","07733bc6":"tvs = TrainValidationSplit(estimator=lr,\n                           estimatorParamMaps=paramGrid,\n                           evaluator=RegressionEvaluator(),\n                           # 80% of the data will be used for training, 20% for validation.\n                           trainRatio=0.8)","a03dd382":"LR_model = tvs.fit(df)","385c4909":"LR_model.transform(df)\\\n    .select(\"features\",\"label\", \"prediction\").show()\n\nDataframe = LR_model.transform(df)\\\n    .select(\"label\", \"prediction\")","5192516d":"valuesAndPreds = Dataframe.rdd.map(tuple)\n\n# Instantiate metrics object\nmetrics = RegressionMetrics(valuesAndPreds)\n\n# Squared Error\nprint(\"MSE = %s\" % metrics.meanSquaredError)\nprint(\"RMSE = %s\" % metrics.rootMeanSquaredError)\n\n# R-squared\nprint(\"R-squared = %s\" % metrics.r2)\n\n# Mean absolute error\nprint(\"MAE = %s\" % metrics.meanAbsoluteError)\n\n# Explained variance\nprint(\"Explained variance = %s\" % metrics.explainedVariance)\n\nsc.stop()","fb126918":"## Run TrainValidationSplit, and choose the best set of parameters.","e62bc299":"## Import and clean data. Pyspark uses its own type system and unfortunately it doesn't deal with numpy well. \n## It works with python types though. So you need to manually convert the numpy.float64 to float.","370935c4":"## Spark uses breeze under the hood for high performance Linear Algebra in Scala. In Spark, MLlib and other \n## ML algorithms depends on org.apache.spark.mllib.libalg.Vector type which is rather dense or sparse.","d1fdc65e":"## A TrainValidationSplit requires an Estimator, a set of Estimator ParamMaps, and an Evaluator.","54b7c5ee":"## Metrics object needs to have an RDD of (prediction, observation) pairs.\n## Convert the dataframe object to an RDD\n","dbc1939b":"## Make predictions on test data. model is the model with combination of parameters that performed best.","1114e830":"## Only max iterations is set. We will set parameters for the algorithm after ParamGridSearch","a9143378":"'''\n4> Predicting Diabetes using LinearRegression from MLib (Machine Learning library from Spark) \n\nThis Diabetes dataset downloaded from Sklearn has ten baseline variables, age, sex, body mass index, average blood \npressure, and six blood serum measurements were obtained for each of n = 442 diabetes patients, as well as the \nresponse of interest, a quantitative measure of disease progression one year after baseline.\n\nA fasting blood sugar level less than 100 mg\/dL (5.6 mmol\/L) is normal. A fasting blood sugar level from 100 to \n125 mg\/dL (5.6 to 6.9 mmol\/L) is considered prediabetes. If it's 126 mg\/dL (7 mmol\/L) or higher on two separate \ntests, you have diabetes. Oral glucose tolerance test.\n'''","c2380004":"## We use a ParamGridBuilder to construct a grid of parameters to search over.\n## TrainValidationSplit will try all combinations of values and determine best model using the evaluator."}}