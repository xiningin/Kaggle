{"cell_type":{"af7a7840":"code","4ac21acf":"code","171eb582":"code","46064790":"code","41699561":"code","dc096654":"code","84697d91":"code","66b520cb":"code","17f12629":"code","cc431b13":"code","e695e055":"code","114b3a18":"code","998c9e22":"code","fa736861":"code","8e19a472":"code","5d673459":"code","4d5304ce":"code","e296cda3":"code","d358b5d6":"code","ac6f0289":"code","e1ad49be":"code","be893ce4":"code","cfba8c89":"code","f3157e33":"code","ee655dfb":"code","e73b40a0":"code","f812a108":"code","24217c07":"code","9848ef64":"code","cd70c52d":"code","cf5589ae":"code","21ef892e":"code","7d030328":"code","9fb026d0":"code","f3893929":"code","8ee0f7db":"code","35e85ee7":"code","2730e410":"code","fc346f55":"code","20abada6":"code","2f182969":"code","0b67d2dc":"code","c1a8ce67":"code","afab1f57":"code","65362136":"code","6c5c05ad":"code","f0c9bf0b":"code","c40a8670":"code","58b18d44":"code","27e3557f":"code","b60c9013":"code","15e54660":"code","456a3d0e":"code","d4031582":"code","51cb22f7":"code","b36decb2":"code","9be17348":"code","96343c7a":"code","e4fc4f62":"code","bc1263b5":"code","5648242e":"markdown","cfa00874":"markdown","2b632ee4":"markdown","d831075a":"markdown","c14dd033":"markdown","a06fc03c":"markdown","b7c0d710":"markdown","53c6fd63":"markdown"},"source":{"af7a7840":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4ac21acf":"train_df= pd.read_csv('\/kaggle\/input\/gene-expression\/data_set_ALL_AML_train.csv')","171eb582":"test_df= pd.read_csv('\/kaggle\/input\/gene-expression\/data_set_ALL_AML_independent.csv')","46064790":"# removing all call columns from data frame\ntrain_columns = [col for col in train_df if \"call\" not in col]\n\ntrain_df = train_df[train_columns]\n","41699561":"train_df = train_df.set_index(\"Gene Accession Number\").T","dc096654":"import re","84697d91":"train_d= [col for col in train_df if not re.match(\"^AFFX\", col)]","66b520cb":"train_df = train_df[train_d]","17f12629":"train_df = train_df.drop([\"Gene Description\"])","cc431b13":"train_df.head()","e695e055":"def transformation(df):\n    df_columns = [col for col in df.columns if \"call\" not in col]\n    df = df[df_columns]\n    df = df.set_index(\"Gene Accession Number\").T\n    dftag= [col for col in df if not re.match(\"^AFFX\", col)]\n    df = df[dftag]\n    df = df.drop([\"Gene Description\"])\n    return df\n    \n    ","114b3a18":"test_df= transformation(test_df)","998c9e22":"train_df= train_df.replace(np.inf, np.nan)","fa736861":"train_df.isnull().sum()[train_df.isnull().sum()> 0]","8e19a472":"cancer_types = pd.read_csv('..\/input\/gene-expression\/actual.csv')","5d673459":"# Reset the index. The indexes of two dataframes need to be the same before you combine them\ntrain_df = train_df.reset_index(drop=True)\n\n# Subset the first 38 patient's cancer types\nct_train = cancer_types[cancer_types.patient <= 38].reset_index(drop=True)\n\n# Combine dataframes for first 38 patients: Patient number + cancer type + gene expression values\ntrain_df = pd.concat([ct_train,train_df], axis=1)\n\n\n\n\n","4d5304ce":"train_df.tail()","e296cda3":"def label(df):\n    df= df.reset_index(drop= True)\n    ct_test = cancer_types[cancer_types.patient > 38].reset_index(drop=True)\n    df = pd.concat([ct_train,df], axis=1)\n    return df\n    ","d358b5d6":"train_df.isnull().sum()","ac6f0289":"train_df.dtypes","e1ad49be":"test_df= label(test_df)","be893ce4":"train_df['cancer']= train_df.cancer.map({'ALL': 0, 'AML': 1})","cfba8c89":"test_df['cancer']= test_df.cancer.map({'ALL': 0, 'AML': 1})","f3157e33":"for col in train_df.columns:\n    train_df[col]= pd.to_numeric(train_df[col])\n    ","ee655dfb":"for col in test_df.columns:\n    test_df[col]= pd.to_numeric(test_df[col])\n    ","e73b40a0":"train_df['cancer']= train_df['cancer'].astype('category')","f812a108":"statistic= train_df.groupby('cancer').describe()","24217c07":"zero= train_df[train_df.cancer== 0].describe().T","9848ef64":"zero.columns","cd70c52d":"zero['avg']= zero['std']\/zero['mean']","cf5589ae":"one = train_df[train_df.cancer== 1].describe().T","21ef892e":"one['avg']= one['std']\/one['mean']","7d030328":"kl= (zero['avg']-one['avg']).abs().sort_values(ascending= False)[5:15].index","9fb026d0":"outcomes = train_df.groupby('cancer').size()\noutcomes.plot(kind = 'bar')","f3893929":"x_train = train_df.iloc[:,2:]\ny_train = train_df.iloc[:,1]","8ee0f7db":"x_test = test_df.iloc[:,2:]\ny_test = test_df.iloc[:,1]","35e85ee7":"p1= x_train[kl]","2730e410":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n","fc346f55":"print(plt.style.available)","20abada6":"plt.rcParams['figure.figsize'] = (15, 8)\nsns.heatmap(p1.corr(), cmap = 'Wistia', annot = True)\nplt.title('Heatmap for the Data', fontsize = 20)\nplt.savefig('correlation');","2f182969":"sns.pairplot(p1)\nplt.title('Pairplot for the Data', fontsize = 20)\nplt.savefig('correlation1');","0b67d2dc":"#Group-wise Plotting","c1a8ce67":"p2= pd.concat([train_df[['cancer']], train_df[kl]], axis= 1)\n\np3= p2[p2.cancer== 0]\np4= p2[p2.cancer== 1]\np3= p3.drop('cancer', axis= 1)\np4= p4.drop('cancer', axis= 1)\nk= pd.DataFrame(p3.stack())\nk= k.reset_index()\n\nk.columns= ['patient', 'fields', 'values']\np4= pd.DataFrame(p4.stack())\np4= p4.reset_index()\np4.columns= ['patient', 'fields', 'values']\n\n\n","afab1f57":"sns.factorplot('fields','values',data=p4, size=6, aspect=1.7, legend=False)\n                                                                                                                                                                                                                                                                                                                                                                \nsns.factorplot('fields','values',data=k, size=6, aspect=1.7, legend=False)","65362136":"sns.boxplot(x=\"fields\", y=\"values\", data=p4)\nplt.title('boxplot of control')\nplt.show()\n","6c5c05ad":"plt4= sns.boxplot(x=\"fields\", y=\"values\", data=k)","f0c9bf0b":"#from sklearn import preprocessing\n#scaled = pd.DataFrame(preprocessing.scale(x_train))\n\n","c40a8670":"import matplotlib.pyplot as plt","58b18d44":"# Using the elbow method to find  the optimal number of clusters\nfrom sklearn.cluster import KMeans\nwcss = []\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters=i,init='k-means++',max_iter=300,n_init=10,random_state=0)\n    kmeans.fit(x_train)\n    wcss.append(kmeans.inertia_)\nplt.plot(range(1,11),wcss)\nplt.title('The Elbow Method')\nplt.xlabel('Number of clusters')\nplt.ylabel('WCSS')\nplt.show()\n\n","27e3557f":"# Applying k-means to the cars dataset\nkmeans = KMeans(n_clusters=2,init='k-means++',max_iter=300,n_init=10,random_state=0) \ny_kmeans = kmeans.fit_predict(x_train)\n\nX = (x_train).as_matrix(columns=None)\n","b60c9013":"y_kmeans== 0, 1","15e54660":"y_kmeans","456a3d0e":"# Visualising the clusters\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1],s=100,c='red',label='AML')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1],s=100,c='blue',label='ALL')\n\nplt.scatter(kmeans.cluster_centers_[:,0],kmeans.cluster_centers_[:,1],s=300,c='yellow',label='Centroids')\nplt.title('Clusters of two cancer type (ALL AND AML)')\nplt.legend()\nplt.show()","d4031582":"from sklearn.neighbors import KNeighborsClassifier\ndef knn_pred(train_predictors, train_outcome, k_range, test_predictors):\n    #train_predictors and train_outcome should both be from training split while test_predictors should be from test split\n    y_pred = []\n    for i in k_range:\n        knn = KNeighborsClassifier(n_neighbors = i)\n        knn.fit(train_predictors, train_outcome)\n        y_pred.append(knn.predict(test_predictors))\n    return y_pred","51cb22f7":"from sklearn.metrics import accuracy_score","b36decb2":"#function compares KNN accuracy at different levels of K\ndef knn_accuracy(pred, k_range, test_outcome):\n    #pred represents predicted values while test_outcome represents the values from the test set\n    accuracy_chart = []\n    for i in range(len(k_range)):\n        accuracy_chart.append((accuracy_score(test_outcome, pred[i])))\n    return accuracy_chart","9be17348":"x_test= x_test.fillna(method= 'ffill')","96343c7a":"train_range = range(2, 20, 2)\nsample_pred = knn_pred(x_train, y_train, train_range, x_test)\naccuracy = knn_accuracy(sample_pred, train_range, y_test)\nplt.figure(figsize=(10, 8))\nplt.bar(train_range, accuracy)\nplt.ylim(0,1)\nplt.xlim(0,20)\nplt.locator_params(axis='y', nbins=20)\nplt.locator_params(axis = 'x', nbins = 10)\nplt.ylabel(\"Accuracy\")\nplt.xlabel(\"Number of Neighborhoods\")","e4fc4f62":"x_train.shape","bc1263b5":"from scipy.cluster.hierarchy import linkage, dendrogram\nmerg = linkage(x_train,method=\"complete\", metric= 'cosine')\ndendrogram(merg,leaf_rotation = 90)\nplt.xlabel(\"data points\")\nplt.ylabel(\"euclidean distance\")\nplt.show()","5648242e":"**EDA**","cfa00874":"find tutorial in https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.spatial.distance.pdist.html#scipy.spatial.distance.pdist","2b632ee4":"In observing the data frames we can see that the genes accession numbers are listed as rows while the expression levels of each patient are listed as columns. This is not an ideal form for analysis as rows typically represent samples so the data frame was transposed.","d831075a":"Group-wise Plotting","c14dd033":"In order to test whether the data should be scaled before further model creation it's distribution was analyzed using a histogram as well as a Kernel Density Estimation. The results of this analysis showed that although a large portion of the data was indeed centered at zero it was still right skewed. In order to ramify this a scaled version of the data was used for analysis.","a06fc03c":"**About the data**\nEach row represents a different gene\nColumns 1 and 2 are descriptions about that gene\nEach numbered column is a patient\nEach patient has 7129 gene expression values - i.e each patient has one value for each gene\nThe training data contain gene expression values for patients 1 through 38\nThe test data contain gene expression values for patients 39 through 72","b7c0d710":"In order to see if the data was organized in separate gaussian distributions the data was clustered using K-Nearest Neighbors. The results of this clustering was used to create a model that was fit to the test set. We can see that the ideal number of neighbors is less than 10 and seems to lay at roughly 6.","53c6fd63":"The columns labeled call seem to represent probes used during DNA microarray analysis. These probes don't seem to provide any direct value in analysis and were dropped."}}