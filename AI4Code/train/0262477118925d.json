{"cell_type":{"71880b4f":"code","769ed5a0":"code","6a6174d9":"code","df5c7921":"code","7f9763d5":"code","381f9679":"code","082a3a7d":"code","eb0961e9":"code","558f6858":"code","002a743e":"code","ff86dd6d":"code","287be30e":"code","a4dd1306":"code","d9c9471f":"code","dc13bd38":"code","73656646":"code","fa242a21":"markdown","ff8eb8e9":"markdown","f051b8c8":"markdown","f1e6ae4b":"markdown"},"source":{"71880b4f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","769ed5a0":"from __future__ import absolute_import, division, print_function\nimport tensorflow.compat.v1 as tf\n#import tensorflow as tf\ntf.enable_eager_execution()\n\n\nimport time","6a6174d9":"# Adding file path\nfile_path = '..\/input\/oz-books-from-ruth-plumly-frank-baum\/frank_baum\/the_wonderful_wizard_of_oz.txt'\n\n# Reading the file data, and then decoding to py2 compat.\ntext_data = open(file_path, 'rb').read().decode(encoding='utf-8')","df5c7921":"# The unique characters in the file\nvocab_unique = sorted(set(text_data))\n\n# Unique characters to Indices Mapping\nchar2ind = {u:i for i, u in enumerate(vocab_unique)}\nind2char = np.array(vocab_unique)\n\ntext_to_int = np.array([char2ind[c] for c in text_data])","7f9763d5":"# The maximum length sentence we want for a single input in characters\nseq_len = 50\ntext_for_epoch = len(text_data)\/\/seq_len\n\n# Creating training targets\ntarget_dataset = tf.data.Dataset.from_tensor_slices(text_to_int)\n\nfor i in target_dataset.take(5):\n    print(ind2char[i.numpy()])","381f9679":"sequence = target_dataset.batch(seq_len+1, drop_remainder=True)\n\ndef splitting_target_input(chunk):\n    text_input = chunk[:-1]\n    text_target = chunk[1:]\n    return text_input, text_target\n\ndataset = sequence.map(splitting_target_input)","082a3a7d":"for input_example, target_example in  dataset.take(1):\n    print ('Input data: ', repr(''.join(ind2char[input_example.numpy()])))\n    print ('Target data:', repr(''.join(ind2char[target_example.numpy()])))","eb0961e9":"for i, (input_idx, target_idx) in enumerate(zip(input_example[:5], target_example[:5])):\n    print(\"Step {:4d}\".format(i))\n    print(\"  input: {} ({:s})\".format(input_idx, repr(ind2char[input_idx])))\n    print(\"  expected output: {} ({:s})\".format(target_idx, repr(ind2char[target_idx])))","558f6858":"# Batch size \nBATCH_SIZE = 64\nsteps_per_epoch = text_for_epoch\/\/BATCH_SIZE\nBUFFER_SIZE = 10000\ndataset = dataset.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True)","002a743e":"vocab_size = len(vocab_unique)\nembedding_dim = 256\nrnn_units = 1024\nrnn = tf.keras.layers.CuDNNGRU \n\nmodel = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size, embedding_dim, \n                              batch_input_shape=[BATCH_SIZE, None]),\n    rnn(rnn_units,\n        return_sequences=True, \n        recurrent_initializer='glorot_uniform',\n        stateful=True),\n    tf.keras.layers.Dense(vocab_size)\n  ])\n\nmodel.summary()","ff86dd6d":"#https:\/\/www.kaggle.com\/midouazerty\/introduction-to-natural-language-processing\/notebook\n\n#Gutenberg org, Search by Title then choose \"Plain Text UTF-8\" to find the URL\n\nimport requests\n# this is the url for The Wonderful Wizard of Oz\nresult = requests.get('https:\/\/www.gutenberg.org\/files\/55\/55.txt')\nprint(result.text)","287be30e":"#Code By Paul Mooney\n\nprosody_file = '..\/input\/oz-books-from-ruth-plumly-frank-baum\/frank_baum\/the_wonderful_wizard_of_oz.txt'\nwith open(prosody_file) as f: # The with keyword automatically closes the file when you are done\n    print (f.read(3000))","a4dd1306":"df= pd.read_csv('..\/input\/oz-books-from-ruth-plumly-frank-baum\/frank_baum\/the_wonderful_wizard_of_oz.txt', sep='\\t', error_bad_lines=False)\ndf.head()","d9c9471f":"df['The Project Gutenberg EBook of The Wonderful Wizard of Oz, by L. Frank Baum'].tail()","dc13bd38":"##Code by Taha07  https:\/\/www.kaggle.com\/taha07\/data-scientists-jobs-analysis-visualization\/notebook\n\nfrom wordcloud import WordCloud\nfrom wordcloud import STOPWORDS\nstopwords = set(STOPWORDS)\nwordcloud = WordCloud(background_color = 'green',\n                      height =2000,\n                      width = 2000\n                     ).generate(str(df[\"The Project Gutenberg EBook of The Wonderful Wizard of Oz, by L. Frank Baum\"]))\nplt.rcParams['figure.figsize'] = (12,12)\nplt.axis(\"off\")\nplt.imshow(wordcloud)\nplt.title(\"Project Gutenberg Wonderful Wizard of OZ\")\nplt.show()","73656646":"#Code by Olga Belitskaya https:\/\/www.kaggle.com\/olgabelitskaya\/sequential-data\/comments\nfrom IPython.display import display,HTML\nc1,c2,f1,f2,fs1,fs2=\\\n'#fc03a1','#fc03be','Akronim','Smokum',30,15\ndef dhtml(string,fontcolor=c1,font=f1,fontsize=fs1):\n    display(HTML(\"\"\"<style>\n    @import 'https:\/\/fonts.googleapis.com\/css?family=\"\"\"\\\n    +font+\"\"\"&effect=3d-float';<\/style>\n    <h1 class='font-effect-3d-float' style='font-family:\"\"\"+\\\n    font+\"\"\"; color:\"\"\"+fontcolor+\"\"\"; font-size:\"\"\"+\\\n    str(fontsize)+\"\"\"px;'>%s<\/h1>\"\"\"%string))\n    \n    \ndhtml('Be patient. Mar\u00edlia Prata, @mpwolke was Here.' )","fa242a21":"![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/d\/d2\/Wizard_title_page.jpg\/220px-Wizard_title_page.jpg)en.wikipedia.org","ff8eb8e9":"#Since I got only errors after the snippet above. I changed the approach of this Notebook.","f051b8c8":"#Codes by https:\/\/www.kaggle.com\/anilreddy8989\/word-guess-with-rnn","f1e6ae4b":"#Package Imports"}}