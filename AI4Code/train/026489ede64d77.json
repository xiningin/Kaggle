{"cell_type":{"a705d972":"code","ad3c3189":"code","2b21503b":"code","631032ba":"code","49e5509a":"code","70dea5fd":"code","1dc14768":"code","597369f7":"code","246e0982":"code","329487a3":"code","60c7f71d":"code","6a22416c":"code","9a04090b":"code","c77f97b1":"code","5ad51b9b":"code","aff03beb":"code","da8380d4":"code","41e3ffef":"code","c775b7ab":"code","655be87c":"code","43ffe130":"code","532cc3c9":"code","44b96aff":"code","6c079a57":"markdown","d48ced8f":"markdown","1cf10656":"markdown","f02c95cb":"markdown","bb300172":"markdown","97ee9617":"markdown","5a05dfc4":"markdown","fe5ecb9e":"markdown","6f4370a7":"markdown","e189ea78":"markdown"},"source":{"a705d972":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ad3c3189":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\n\nimport pandas as pd\nimport cv2\nimport matplotlib.pyplot as plt\nfrom torchvision import transforms\nimport torchvision\nimport torchvision.models as models\nfrom PIL import Image\nimport time","2b21503b":"data_path = '\/kaggle\/input\/fashionmnist\/fashion-mnist_train.csv'\nnum_classes = 10","631032ba":"class Dataset(torch.utils.data.Dataset):\n    \n    def __init__(self, path):\n        self.data = pd.read_csv(path)\n    \n    def __len__(self):\n        return self.data.shape[0]\n    \n    def __getitem__(self, idx):\n        image = self.data.iloc[idx][1:].to_numpy().reshape(1,28,28)\n        label = self.data.iloc[idx][0]\n        return image, np.array(label)\n     \ndataset = Dataset(data_path)\n\ntrain_set, val_set = torch.utils.data.random_split(dataset, [int(len(dataset) * 0.8), int(len(dataset) * 0.2)])\n\ntrain_dataloader = torch.utils.data.DataLoader(train_set,\n                                        batch_size = 128,\n                                        shuffle = True)\n\nval_dataloader = torch.utils.data.DataLoader(val_set,\n                                        batch_size = 128)","49e5509a":"class CNNBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(CNNBlock, self).__init__()\n        self.conv = nn.Conv2d(input_dim, output_dim, kernel_size=3, padding = 1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.bn = nn.BatchNorm2d(output_dim)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):    \n        out = self.conv(x)\n        out = self.pool(out)\n        out = self.bn(out)\n        out = self.relu(out)\n        return out\n\nclass CNN(nn.Module):\n    def __init__(self, dims):\n        super(CNN, self).__init__()\n        self.layers = nn.ModuleList([])\n        for i in range(1, len(dims)):\n            self.layers.append(CNNBlock(input_dim = dims[i - 1], output_dim = dims[i]))\n        \n        self.gap = nn.AvgPool2d(kernel_size = 3)\n        self.fc = nn.Linear(dims[-1], num_classes)\n        \n        \n    def forward(self, x):     \n        \n        start = time.time()\n        for layer in self.layers:\n            x = layer(x)\n        end = time.time()\n\n        out = self.gap(x)\n        shape = out.shape\n        out = out.reshape(shape[0], shape[1])\n        out = self.fc(out)\n        return out    ","70dea5fd":"class MobileNetBlock(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super(MobileNetBlock, self).__init__()\n        # to implement depthwise filters you should set both output_dim and groups equal to number of input dimentions\n        self.conv1 = nn.Conv2d(input_dim, input_dim, kernel_size=3, padding = 'same', groups = input_dim)\n        self.conv2 = nn.Conv2d(input_dim, output_dim, kernel_size=1)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.bn = nn.BatchNorm2d(output_dim)\n        self.relu = nn.ReLU()\n        \n    def forward(self, x):    \n        out = self.conv1(x)\n        out = self.conv2(x)\n        out = self.pool(out)\n        out = self.bn(out)\n        out = self.relu(out)\n        return out\n\nclass MobileNet(nn.Module):\n    def __init__(self, dims):\n        super(MobileNet, self).__init__()\n        self.layers = nn.ModuleList([])\n        for i in range(1, len(dims)):\n            self.layers.append(CNNBlock(input_dim = dims[i - 1], output_dim = dims[i]))\n        \n        self.gap = nn.AvgPool2d(kernel_size = 3)\n        self.fc = nn.Linear(dims[-1], num_classes)\n        \n        \n    def forward(self, x):    \n        start = time.time()\n        for layer in self.layers:\n            x = layer(x)\n        end = time.time()\n   \n        out = self.gap(x)\n        shape = out.shape\n        out = out.reshape(shape[0], shape[1])\n        out = self.fc(out)\n        return out    ","1dc14768":"cnn = CNN([1,32,64,128])","597369f7":"mobileNet = MobileNet([1,32,64,128])","246e0982":"dim = 524","329487a3":"epochs = 5\n\ndef train_model(model, epochs):\n    optimizer = torch.optim.Adam(model.parameters(), lr=0.001)\n    criterion = torch.nn.CrossEntropyLoss()\n\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n    model.to(device)\n\n    for epoch in range(epochs):\n        for idx, (data, label) in enumerate(train_dataloader):\n            optimizer.zero_grad()\n            data = data.to(device).float()\n            label = label.to(device).float()\n            pred = model(data)\n            loss = criterion(pred, label.long())\n            loss.backward()\n            optimizer.step()\n            if idx % 100 == 0:\n                y_hat = torch.argmax(pred, dim = 1)\n                correct = (y_hat == label).sum()\n                print(f\"Epoch {epoch} {idx}\/{len(train_dataloader)} Loss = {loss.data:.03f}, acc = {correct \/ label.shape[0]:.02f}\")","60c7f71d":"def eval_model(model):\n    criterion = torch.nn.CrossEntropyLoss()\n\n    device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')    \n    model.to(device)\n    \n    total_correct = 0\n    total = 0\n    for idx, (data, label) in enumerate(val_dataloader):\n        data = data.to(device).float()\n        label = label.to(device).float()\n        pred = model(data)\n            \n        y_hat = torch.argmax(pred, dim = 1)\n        correct = (y_hat == label).sum()\n        total_correct += correct\n        total += label.shape[0]\n            \n    print(f'Accuracy = {total_correct \/ total}')         ","6a22416c":"train_model(cnn, epochs)","9a04090b":"eval_model(cnn)","c77f97b1":"train_model(mobileNet, epochs)","5ad51b9b":"eval_model(mobileNet)","aff03beb":"dimentions = [2 ** i for i in range(11)]\nconvResults = []\ndepthWiseConvResults = []","da8380d4":"def calc_time(block, dim, im_size = 256, batch = 8):\n    start = time.time()\n    block(\n        torch.randn(batch,dim, im_size, im_size)\n    )\n    end = time.time()\n    return (end - start) \/ batch","41e3ffef":"for dim in dimentions:\n    commonConv = nn.Conv2d(dim, dim, 3, padding = 1)\n    dwConv = nn.Sequential(nn.Conv2d(dim, dim, 3, padding = 1, groups = dim),\n                           nn.Conv2d(dim, dim, 1))\n    \n    convResults.append(calc_time(commonConv, dim))\n    depthWiseConvResults.append(calc_time(dwConv, dim))","c775b7ab":"import matplotlib.pyplot as plt","655be87c":"plt.figure(figsize=(8, 6))\nplt.plot(dimentions, convResults, label = 'Common conv layer')\nplt.plot(dimentions, depthWiseConvResults, label = 'Depth-wise conv')\nplt.legend()\nplt.xlabel('# dimentions')\nplt.ylabel('time sec.')\nplt.show()","43ffe130":"k_sizes = [i * 2 + 3 for i in range(5)]\nconvResults = []\ndepthWiseConvResults = []","532cc3c9":"for size in k_sizes:\n    dim = 32\n    padding = int(size \/ 2)\n    commonConv = nn.Conv2d(dim, dim, size, padding = padding)\n    dwConv = nn.Sequential(nn.Conv2d(dim, dim, size, padding = padding, groups = dim),\n                           nn.Conv2d(dim, dim, 1))\n    \n    convResults.append(calc_time(commonConv, dim))\n    depthWiseConvResults.append(calc_time(dwConv, dim))","44b96aff":"plt.figure(figsize=(8, 6))\nplt.plot(k_sizes, convResults, label = 'Common conv layer')\nplt.plot(k_sizes, depthWiseConvResults, label = 'Depth-wise conv')\nplt.legend()\nplt.xlabel('kernel size')\nplt.ylabel('time sec.')\nplt.show()","6c079a57":"As you can see, both network has almost the same accuracy, but MobileNet has much less parameters","d48ced8f":"<h1>Introduction<\/h1>","1cf10656":"<h1>Experiment<\/h1>","f02c95cb":"And how kernel size affects computational speed","bb300172":"In this kernek I'm going to tell about **depthwise separable convolutions**, which are used in MobileNet and allow to significantly reduce the number of parameters in network. Thanks to this, the network firstly takes up much less space in memory, and secondly - it works faster due to fewer necessary calculations.","97ee9617":"![05_1_deepwise_convolutions.png](attachment:4976e264-9bfc-404c-bf03-5643147f21b1.png)","5a05dfc4":"An idea of depthwise separable convolution is to split such layer into 2 stages:\n1. **Depthwise convolution filters** - $M$ filters of size $D_k \\cdot D_k$, each applied for its own input tensor channel\n2. **Pointwise convolution** - $N$ filters of size $1 \\cdot 1$\nThus, number of computation for this layer is:\n$$M \\cdot D_k \\cdot D_k \\cdot D_h \\cdot D_w + N \\cdot M \\cdot D_h \\cdot D_w$$\nSo, this gives us a reduction in computations of:\n$$\\frac{1}{N} + \\frac{1}{D^2_k}$$","fe5ecb9e":"Lets try to implement a simple network using common convolution layers and depthwise separable ones. In this kernel I call network using depthwise separable convolutions as a MobileNet, because MobileNet uses this approach, but I implement only simplified version of it. ","6f4370a7":"Now, lets see how the dimention of the input tensor affects the speed of calculations","e189ea78":"A common comvolution layer has $N$ filters of size $D_k \\cdot D_k \\cdot M$ where $M$ - is a dimention of the input tensor and $D_k$ is a kernel size. So, the overall number of needed computations is \n$$N \\cdot D_k \\cdot D_k \\cdot M \\cdot D_h \\cdot D_w$$\n$D_h$ and $D_w$ - height and weight of the input tensor respectively"}}