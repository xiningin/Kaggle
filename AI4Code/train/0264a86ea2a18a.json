{"cell_type":{"ace247c9":"code","b2c81614":"code","aee09656":"code","09a2e949":"code","ddb78129":"code","3f5f336f":"code","e6aa3d34":"code","2abb2262":"code","8348e054":"code","d9cf0582":"code","61fbde7d":"code","f07e341a":"code","a762c4ee":"code","1c85bc11":"code","a7c6e28d":"code","6dd3a0fe":"code","e21517b7":"code","5e07b8a7":"code","d9e37cdc":"markdown","2421a9e3":"markdown","2817f137":"markdown","81d00b07":"markdown","7ad18bfb":"markdown","a4f0b12f":"markdown","f7d921ff":"markdown","6fec4aa3":"markdown","f02678d6":"markdown","916e8697":"markdown","155a0f06":"markdown","b8a5912c":"markdown","75fa0a5e":"markdown","b837d0cb":"markdown","8f30165d":"markdown","014905dc":"markdown","0b37867c":"markdown","04c02613":"markdown","c4c19df2":"markdown"},"source":{"ace247c9":"import pandas as pd\nimport pylab as pl\nimport numpy as np\nimport scipy.optimize as opt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\n%matplotlib inline \nimport matplotlib.pyplot as plt","b2c81614":"cell_df = pd.read_csv(\"..\/input\/cancer-data\/cell_samples.csv\")\ncell_df.head()","aee09656":"ax = cell_df[cell_df['Class'] == 4][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='DarkBlue', label='malignant');\ncell_df[cell_df['Class'] == 2][0:50].plot(kind='scatter', x='Clump', y='UnifSize', color='Yellow', label='benign', ax=ax);\nplt.show()","09a2e949":"cell_df.dtypes","ddb78129":"cell_df = cell_df[pd.to_numeric(cell_df['BareNuc'], errors='coerce').notnull()]\ncell_df['BareNuc'] = cell_df['BareNuc'].astype('int')\ncell_df.dtypes","3f5f336f":"X = cell_df.iloc[:, 2: 9].values\ny = cell_df.iloc[:, 10].values","e6aa3d34":"print (X)","2abb2262":"print (y)","8348e054":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","d9cf0582":"cell_df.shape","61fbde7d":"print(\"The shape of tranning cell_df is\", X_train.shape)\nprint(\"The shape of test data example is\", X_test.shape)","f07e341a":"from sklearn import svm\nclf = svm.SVC(kernel='rbf')\nclf.fit(X_train, y_train)\n","a762c4ee":"yhat = clf.predict(X_test)\nyhat [0:5]\n","1c85bc11":"from sklearn.metrics import classification_report, confusion_matrix\nimport itertools","a7c6e28d":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","6dd3a0fe":"\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, yhat, labels=[2,4])\nnp.set_printoptions(precision=2)\n\nprint (classification_report(y_test, yhat))\n\n\n# Plot non-normalized confusion matrix\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Benign(2)','Malignant(4)'],normalize= False,  title='Confusion matrix')\n","e21517b7":"from sklearn.metrics import f1_score\nprint(\"Avg F1-score: %.4f\" % f1_score(y_test, yhat, average='weighted')) ","5e07b8a7":"from sklearn.metrics import jaccard_similarity_score\nprint(\"Jaccard score: %.4f\" %jaccard_similarity_score(y_test, yhat))","d9e37cdc":"Lets first look at columns data types:","2421a9e3":"* Field name\tDescription\n* ID\tClump thickness\n* Clump\tClump thickness\n* UnifSize\tUniformity of cell size\n* UnifShape\tUniformity of cell shape\n* MargAdh\tMarginal adhesion\n* SingEpiSize\tSingle epithelial cell size\n* BareNuc\tBare nuclei\n* BlandChrom\tBland chromatin\n* NormNucl\tNormal nucleoli\n* Mit\tMitoses\n* Class\tBenign or malignant","2817f137":"Lets try jaccard index for accuracy:","81d00b07":"We want the model to predict the value of Class (that is, benign (=2) or malignant (=4)). As this field can have one of only two possible values, we need to change its measurement level to reflect this.","7ad18bfb":"Okay, we split our dataset into train and test set:","a4f0b12f":"The SVM algorithm offers a choice of kernel functions for performing its processing. Basically, mapping data into a higher dimensional space is called kernelling. The mathematical function used for the transformation is known as the\u00a0kernel\u00a0function, and can be of different types, such as:\n\n    1.Linear\n    2.Polynomial\n    3.Radial basis function (RBF)\n    4.Sigmoid\nEach of these functions has its characteristics, its pros and cons, and its equation, but as there's no easy way of knowing which function performs best with any given dataset, we usually choose different functions in turn and compare the results. Let's just use the default, RBF (Radial Basis Function) for this lab.","f7d921ff":"You can also easily use the __f1_score__ from sklearn library:","6fec4aa3":"Jaccard score: 0.9416","f02678d6":"It looks like the __BareNuc__ column includes some values that are not numerical. We can drop those rows:","916e8697":"After being fitted, the model can then be used to predict new values:","155a0f06":"<h2 id=\"modeling\">Modeling (SVM with Scikit-learn)<\/h2>","b8a5912c":"<h1 align=center><font size=\"5\"> SVM (Support Vector Machines)<\/font><\/h1>","75fa0a5e":"<h2 id=\"evaluation\">Evaluation<\/h2>","b837d0cb":"## Train\/Test dataset","8f30165d":"you will use SVM (Support Vector Machines) to build and train a model using human cell records, and classify cells to whether the samples are benign or malignant.\n\nSVM works by mapping data to a high-dimensional feature space so that data points can be categorized, even when the data are not otherwise linearly separable. A separator between the categories is found, then the data is transformed in such a way that the separator could be drawn as a hyperplane. Following this, characteristics of new data can be used to predict the group to which a new record should belong.","014905dc":"# P VAISHNAVI\n[Github repo](https:\/\/github.com\/Vaishnavi-Pothugunta\/CancerPrediction_using_SVM)","0b37867c":"### Load Data From CSV File  ","04c02613":"## Data pre-processing and selection","c4c19df2":"The ID field contains the patient identifiers. The characteristics of the cell samples from each patient are contained in fields Clump to Mit. The values are graded from 1 to 10, with 1 being the closest to benign.\n\nThe Class field contains the diagnosis, as confirmed by separate medical procedures, as to whether the samples are benign (value = 2) or malignant (value = 4).\n\nLets look at the distribution of the classes based on Clump thickness and Uniformity of cell size:"}}