{"cell_type":{"ec608a6a":"code","5e566eb6":"code","461491a1":"code","772e4561":"code","7186c2ec":"code","f8326bd7":"code","c94d3802":"code","bd35b75a":"code","4d351e8e":"code","be4403b3":"code","ec671090":"code","f6c8936e":"code","862ddfc6":"code","530ae095":"code","7eb0bc7a":"markdown","a264c0fe":"markdown","f58ad366":"markdown","43f7a368":"markdown"},"source":{"ec608a6a":"# Data processing\n%matplotlib inline\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\n\n# Machine Learning\nimport optuna\nimport xgboost as xgb\nfrom optuna.samplers import TPESampler\nfrom sklearn.preprocessing import RobustScaler, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold\nfrom sklearn.metrics import mean_squared_error\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","5e566eb6":"input_dir = Path('\/kaggle\/input\/30-days-of-ml\/')\ntrain_df = pd.read_csv(input_dir \/ 'train.csv')\ntest_df = pd.read_csv(input_dir \/ 'test.csv')\nsample_submission = pd.read_csv(input_dir \/ 'sample_submission.csv')","461491a1":"train_df.head()","772e4561":"# Check for null values\ntrain_df.isnull().sum()","7186c2ec":"test_df.head()","f8326bd7":"test_df.isnull().sum()","c94d3802":"# Split the target from the data\nX = train_df.drop(['id', 'target'], axis=1).values\ny = train_df['target'].values\nX_test = test_df.drop(['id'], axis=1).values","bd35b75a":"# Encoding categorical data\nfrom sklearn.preprocessing import OrdinalEncoder\ncat_cols = [col for col in train_df.columns if 'cat' in col]\n\nX = train_df.copy()\nX_test = test_df.copy()\nenc = OrdinalEncoder()\nX[cat_cols] = enc.fit_transform(train_df[cat_cols])\nX_test[cat_cols] = enc.transform(test_df[cat_cols])\nX.drop(['target'], axis = 1, inplace = True)\nX.head()","4d351e8e":"# Scaling the Data\nscaler = StandardScaler()\nX = scaler.fit_transform(X)\nX_test = scaler.transform(X_test)","be4403b3":"def my_rmse(y_true, y_hat):\n    return np.sqrt(mean_squared_error(y_true, y_hat, squared=False))","ec671090":"# Optuna objective function\ndef objective(trial):\n    # Split the train data for each trial.\n    X_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size=0.35)\n\n    param_grid = {\n        'max_depth': trial.suggest_int('max_depth',1.99, 10, 4), # Extremely prone to overfitting!\n        'n_estimators': trial.suggest_int('n_estimators', 400, 800, 1200), # Extremely prone to overfitting!\n        'eta': trial.suggest_float('eta', 0.007, 0.013), # Most important parameter - the learning rate!\n        'subsample': trial.suggest_discrete_uniform('subsample', 0.6, 0.9, 0.85),\n        'colsample_bytree': trial.suggest_discrete_uniform('colsample_bytree', 0.6, 0.9, 0.85),\n        'min_child_weight': trial.suggest_int('min_child_weight', 5, 20), # I've had trouble with LB score until tuning this.\n        'reg_lambda': trial.suggest_int('reg_lambda', 30, 35, 50), # L2 regularization\n        'reg_alpha': trial.suggest_int('reg_alpha', 30, 35, 50), # L1 regularization\n        'booster': 'gbtree'\n    } \n    \n    reg = xgb.XGBRegressor(\n        n_jobs=4,\n        **param_grid\n    )\n    \n    reg.fit(X_train, y_train,\n            eval_set=[(X_valid, y_valid)], eval_metric='rmse',\n            verbose=False)\n\n    # Returns the best RMSE for the trial.\n    # Readers may want to try returning a cross validation score here.\n    return my_rmse(y_valid, reg.predict(X_valid))","f6c8936e":"train_time = 1 * 10 * 60 # Train for up to ten minutes.\nstudy = optuna.create_study(direction='minimize', sampler=TPESampler(), study_name='XGBRegressor')\nstudy.optimize(objective, timeout = train_time)\n\nprint('Number of finished trials: ', len(study.trials))\nprint('Best trial:')\ntrial = study.best_trial\n\nprint('\\tValue: {}'.format(trial.value))\nprint('\\tParams: ')\nfor key, value in trial.params.items():\n    print('\\t\\t{}: {}'.format(key, value))","862ddfc6":"# Fetch the best trial parameters and set some settings for the KFold predictions.\nxgb_params = trial.params\nxgb_params['booster'] = 'gbtree'\nxgb_params['n_jobs'] = 4\n\nn_splits = 10\ntest_preds = None\nkf_rmse = []\n\nfor fold, (train_idx, valid_idx) in enumerate(KFold(n_splits=n_splits, shuffle=True).split(X, y)):\n    # Fetch the train-validation indices.\n    X_train, y_train = X[train_idx], y[train_idx]\n    X_valid, y_valid = X[valid_idx], y[valid_idx]\n    \n    # Create and fit a new model using the best parameters.\n    model = xgb.XGBRegressor(**xgb_params)\n    model.fit(X_train, y_train,\n            eval_set=[(X_valid, y_valid)],\n            eval_metric='rmse', verbose=False)\n    \n    # Validation predictions.\n    valid_pred = model.predict(X_valid)\n    rmse = my_rmse(y_valid, valid_pred)\n    print(f'Fold {fold+1}\/{n_splits} RMSE: {rmse:.4f}')\n    kf_rmse.append(rmse)\n    \n    # Use the model trained for 1\/n_splits of the output predictions.\n    if test_preds is None:\n        test_preds = model.predict(X_test)\n    else:\n        # This is kind of naughty for numerical accuracy (may overflow on other problems) but slightly quicker.\n        test_preds += model.predict(X_test)\n\ntest_preds \/= n_splits\nprint(f'Average KFold RMSE: {np.mean(np.array(kf_rmse)):.5f}')","530ae095":"sample_submission['target'] = test_preds\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head()","7eb0bc7a":"# Load and visualize Data\nIn this notebook I'll be doing hyperparameter tuning with optuna library in the XGBoost model","a264c0fe":"# KFolds Modeling","f58ad366":"# Hyperparameter tuning","43f7a368":"We'll use a GPU to train the model and the hyperparameters"}}