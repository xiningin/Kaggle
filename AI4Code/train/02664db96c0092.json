{"cell_type":{"df0ccf11":"code","278abc72":"code","9b85d284":"code","52912ff9":"code","f23cb79f":"code","a68691eb":"code","f10837b8":"code","2e37fea8":"code","a8451401":"code","8ad4b539":"code","a3e0a7cf":"code","0af3646c":"code","df43cd8b":"code","249b8451":"code","fa5dea5a":"code","01e5c7aa":"code","5b28c277":"code","eef92c96":"code","9f3c0df8":"code","429da906":"code","cc095a1f":"code","9bdfda40":"code","5725d263":"markdown","68ad030d":"markdown","c778d7a2":"markdown","379fb9a3":"markdown","68441a31":"markdown","d09a1f1d":"markdown"},"source":{"df0ccf11":"import numpy as np\nimport pandas as pd\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","278abc72":"import matplotlib.pyplot as plt\nimport seaborn as sns","9b85d284":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\ntrain.head()","52912ff9":"print(train.shape)\nprint(test.shape)","f23cb79f":"train['train']  = 1\ntest['train']  = 0\ndf = pd.concat([train, test], axis=0, sort=False)\nprint(df.shape)","a68691eb":"for column in df.columns:\n    if(df[column].isnull().sum() != 0):\n        print('Feature : ', column , ' # No of nulls : ',df[column].isnull().sum(), ' # Per : ',df[column].isnull().sum()*100\/2919)","f10837b8":"df = df.drop(columns=['LotFrontage','Alley','FireplaceQu','PoolQC','Fence','MiscFeature'], axis=1)","2e37fea8":"for column in df.columns:\n    if(df[column].isnull().sum() != 0):\n        print('Feature : ', column , ' # No of nulls : ', df[column].isnull().sum(), ' # Per : ', df[column].isnull().sum()*100\/2919)","a8451401":"df = df.drop(columns=['GarageType', 'GarageYrBlt', 'GarageFinish', 'GarageQual', 'GarageCond', 'BsmtQual', \n                      'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2', 'MasVnrType', 'MasVnrArea'], \n                      axis=1)","8ad4b539":"df.shape","a3e0a7cf":"df['Electrical'] = df['Electrical'].fillna(df['Electrical'].mode()[0])","0af3646c":"#correlation matrix\ncorrmat = df.corr()\nf, ax = plt.subplots(figsize=(20, 20))\n\nsns.set(font_scale=1)\nsns.heatmap(corrmat, vmax=.8, square=True, annot=True);","df43cd8b":"#SalePrice Correlation with following columns is less than 10%. Let's drop these columns.\ndf = df.drop(columns=['MSSubClass', 'OverallCond', 'BsmtHalfBath', 'BsmtUnfSF', 'BsmtFinSF2',\n                      'LowQualFinSF', '3SsnPorch', 'PoolArea', 'MiscVal', \n                      'MoSold', 'YrSold'], axis=1)","249b8451":"#correlation matrix\ncorrmat = df.corr()\nf, ax = plt.subplots(figsize=(20, 20))\n\nsns.set(font_scale=1)\nsns.heatmap(corrmat, vmax=.8, square=True, annot=True);","fa5dea5a":"#Convert categorical variable into dummy\ndf = pd.get_dummies(df)\ndf.head()","01e5c7aa":"df_final = df.drop(['Id'], axis=1)\n\ndf_train = df_final[df_final['train'] == 1]\ndf_train = df_train.drop(['train'], axis=1)\n\n\ndf_test = df_final[df_final['train'] == 0]\ndf_test = df_test.drop(['SalePrice'], axis=1)\ndf_test = df_test.drop(['train'], axis=1)","5b28c277":"print(df_train.shape)\nprint(df_test.shape)","eef92c96":"target= df_train['SalePrice']\ndf_train = df_train.drop(['SalePrice'],axis=1)","9f3c0df8":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(df_train, target, test_size=0.2, random_state=0)","429da906":"from lightgbm import LGBMRegressor\nimport sklearn.metrics as metrics\nimport math\n\nlgbm2 = LGBMRegressor(objective='regression', \n                                       num_leaves=8,\n                                       learning_rate=0.005, \n                                       n_estimators=15000, \n                                       max_bin=200, \n                                       bagging_fraction=0.75,\n                                       bagging_freq=5, \n                                       bagging_seed=7,\n                                       feature_fraction=0.4, \n                                       )\n\nlgbm2.fit(x_train, y_train, eval_metric='rmse')\n\nlgbm2_pred = lgbm2.predict(x_test)\n\nprint('Root Mean Square Error test = ' + str(math.sqrt(metrics.mean_squared_error(y_test, lgbm2_pred))))","cc095a1f":"lgbm2.fit(df_train, target, eval_metric='rmse')\n\nlgbm2_pred_allTest = lgbm2.predict(df_test)","9bdfda40":"submission = pd.DataFrame({\"Id\": test[\"Id\"], \"SalePrice\": lgbm2_pred_allTest})\nsubmission.to_csv('Final_submission_best.csv', index=False)","5725d263":"# **Separating Features and Label**","68ad030d":"# **Models**","c778d7a2":"# **Separating Train and Test Dataset**","379fb9a3":"# **Fitting With all the dataset**","68441a31":"We will drop columns that are having more than 15% Null values","d09a1f1d":"We can see that 'GarageX' variables have the same number of missing data. Since the most important information regarding garages is expressed by 'GarageCars' and considering that we are just talking about 5% of missing data, I'll delete the mentioned 'GarageX' variables. The same logic applies to 'BsmtX' variables.\n\nRegarding 'MasVnrArea' and 'MasVnrType', we can consider that these variables are not essential. Furthermore, they have a strong correlation with 'YearBuilt' which is already considered. Thus, we will not lose information if we delete 'MasVnrArea' and 'MasVnrType'.\n\nFinally, we have one missing observation in 'Electrical'. Since it is just one observation, we'll delete this observation and keep the variable."}}