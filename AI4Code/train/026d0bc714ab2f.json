{"cell_type":{"51f0a388":"code","3d21986b":"code","3aafeb93":"code","636d922f":"code","0311d10c":"code","6d51f992":"code","9377d84b":"code","5c53e620":"code","7372e9d1":"code","4fac6de9":"code","2e9f2f03":"code","164b8acf":"code","80b7e368":"code","35b135ea":"code","d465b39b":"code","6ef320d5":"code","efd91d86":"code","86a1a1fd":"code","ecd7f5fd":"code","62879c59":"code","a0caa046":"code","5b5fe0b8":"code","561ba686":"code","ae1ebc45":"code","74960877":"code","ce6c06cc":"code","31ca1690":"code","2e24b397":"code","38829b88":"code","f6037bf7":"code","08252e91":"code","d1bde943":"code","f3461c39":"code","91e74a1c":"code","7dff0e85":"code","09784acc":"code","84e27274":"code","cf75f14c":"code","0d5fcfd2":"markdown","1a03f8c2":"markdown","b29f2fb1":"markdown","c071170a":"markdown","4210baf0":"markdown","98509c3d":"markdown","ac9f8d5b":"markdown","38bd6d03":"markdown"},"source":{"51f0a388":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3d21986b":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import decomposition","3aafeb93":"from sklearn.model_selection import KFold #for K-fold cross validation\nfrom sklearn.model_selection import cross_val_score #score evaluation\nfrom sklearn.model_selection import cross_val_predict #prediction\nfrom sklearn.metrics import confusion_matrix #for confusion matrix\n\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn import metrics\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn import metrics\nfrom sklearn.metrics import plot_confusion_matrix","636d922f":"# data_trian = pd.read_csv(\"..\/input\/train.csv\")\n# data_test = pd.read_csv(\"..\/input\/test.csv\")\n\ndata_trian = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ndata_test = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","0311d10c":"data_trian['family']=data_trian.SibSp + data_trian.Parch + 1;\ndata_test['family']=data_test.SibSp + data_test.Parch + 1;","6d51f992":"data_trian.Name.str.extract(' ([A-Za-z]+)\\.', expand=False).unique()","9377d84b":"data_trian['passenger_group'] = data_trian.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","5c53e620":"data_test['passenger_group'] = data_test.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)","7372e9d1":"group_age_means = data_trian.groupby('passenger_group')['Age'].mean()\n# Test data age menas\ngroup_age_means_test = data_test.groupby('passenger_group')['Age'].mean()","4fac6de9":"for i_temp in data_trian[data_trian['Age'].isnull()].index.values:\n  if(pd.isnull(data_trian.iloc[i_temp]['Age'])):\n    data_trian.loc[i_temp,'Age'] = group_age_means[data_trian.iloc[i_temp]['passenger_group']]","2e9f2f03":"for i_temp in data_test[data_test['Age'].isnull()].index.values:\n  if(pd.isnull(data_test.iloc[i_temp]['Age'])):\n    data_test.loc[i_temp,'Age'] = group_age_means[data_test.iloc[i_temp]['passenger_group']]","164b8acf":"data_trian['age_bin'] = pd.cut(data_trian['Age'], bins=[0,12,20,40,120], labels=['Children','Teenage','Adult','Elder'])\ndata_test['age_bin'] = pd.cut(data_test['Age'], bins=[0,12,20,40,120], labels=['Children','Teenage','Adult','Elder'])","80b7e368":"data_trian['fare_bin'] = pd.cut(data_trian['Fare'], bins=[0,7.91,14.45,31,120], labels=['Low_fare','median_fare','Average_fare','high_fare'])\n#test data\ndata_test['fare_bin'] = pd.cut(data_test['Fare'], bins=[0,7.91,14.45,31,120], labels=['Low_fare','median_fare','Average_fare','high_fare'])","35b135ea":"data_trian.drop(['Cabin'], axis=1,inplace=True)\ndata_test.drop(['Cabin'], axis=1,inplace=True)","d465b39b":"Q1 = data_trian.quantile(0.25)\nQ3 = data_trian.quantile(0.75)\nIQR = Q3 - Q1","6ef320d5":"def _outlier_info(lcl_data_fr,lcl_feature_name,lcl_q1,lcl_iqr,lcl_q3):\n  print(\"---\"*40)\n  print(\"---\"*40)\n  print(\"Outlier info for the feature \",lcl_feature_name,\":\")\n  #print(\"Feature \",lcl_feature_name,\" \",lcl_data_fr[lcl_feature_name].count())\n  out_count = ((lcl_data_fr[lcl_feature_name] < (lcl_q1[lcl_feature_name] - 1.5 * lcl_iqr[lcl_feature_name])) | (lcl_data_fr[lcl_feature_name] > (lcl_q3[lcl_feature_name] + 1.5 * lcl_iqr[lcl_feature_name]))).sum()  \n  print(\"Count: \",out_count)\n  print(\"Percentage: \",round((out_count\/lcl_data_fr[lcl_feature_name].count())*100),\"%\")","efd91d86":"temp_list_1 = ['Pclass','Fare','Age','SibSp','Parch']\nfor temp_var_1 in temp_list_1:\n  _outlier_info(data_trian,temp_var_1,Q1,IQR,Q3)","86a1a1fd":"Q1 = data_test.quantile(0.25)\nQ3 = data_test.quantile(0.75)\nIQR = Q3 - Q1\ntemp_list_1 = ['Pclass','Fare','Age','SibSp','Parch']\nfor temp_var_1 in temp_list_1:\n  _outlier_info(data_test,temp_var_1,Q1,IQR,Q3)","ecd7f5fd":"filtered_data_2 = data_trian","62879c59":"filtered_data_test = data_test","a0caa046":"selected_data = filtered_data_2.drop(['PassengerId','Ticket','Name','passenger_group'],axis = 1)","5b5fe0b8":"selected_data_test = filtered_data_test.drop(['PassengerId','Ticket','Name','passenger_group'],axis = 1)","561ba686":"selected_data = selected_data.drop(['Fare'], axis = 1)\n#Test data\nselected_data_test = selected_data_test.drop(['Fare'], axis = 1) ","ae1ebc45":"selected_data = pd.concat([selected_data, pd.get_dummies(selected_data['Sex'],prefix=\"gender\")], axis=1);\nselected_data_test = pd.concat([selected_data_test, pd.get_dummies(selected_data_test['Sex'],prefix=\"gender\")], axis=1);","74960877":"selected_data = pd.concat([selected_data, pd.get_dummies(selected_data['Pclass'],prefix=\"Pclass_cabin\")], axis=1);\nselected_data_test = pd.concat([selected_data_test, pd.get_dummies(selected_data_test['Pclass'],prefix=\"Pclass_cabin\")], axis=1);","ce6c06cc":"selected_data = pd.concat([selected_data, pd.get_dummies(selected_data['Embarked'],prefix=\"Embarled_loc\")], axis=1);\nselected_data_test = pd.concat([selected_data_test, pd.get_dummies(selected_data_test['Embarked'],prefix=\"Embarled_loc\")], axis=1);","31ca1690":"selected_data = pd.concat([selected_data, pd.get_dummies(selected_data['age_bin'],prefix=\"Age_type\")], axis=1);\nselected_data_test = pd.concat([selected_data_test, pd.get_dummies(selected_data_test['age_bin'],prefix=\"Age_type\")], axis=1);","2e24b397":"selected_data = pd.concat([selected_data, pd.get_dummies(selected_data['fare_bin'],prefix=\"fare_type\")], axis=1);\nselected_data_test = pd.concat([selected_data_test, pd.get_dummies(selected_data_test['fare_bin'],prefix=\"fare_type\")], axis=1);","38829b88":"#selected_data = selected_data.drop(['Sex','Embarked','Parch','Pclass','fare_bin','Age','age_bin'], axis = 1) \nselected_data = selected_data.drop(['Sex','Embarked','Parch','fare_bin','Age','age_bin'], axis = 1) \n\n#Test data\nselected_data_test = selected_data_test.drop(['Sex','Embarked','Parch','fare_bin','Age','age_bin'], axis = 1) ","f6037bf7":"X = selected_data.drop('Survived',axis=1)\ny = selected_data['Survived']","08252e91":"X_act_test = selected_data_test\n","d1bde943":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","f3461c39":"K_fold = StratifiedKFold(n_splits=10)","91e74a1c":"logistic_model = LogisticRegression()\nlogistic_model.fit(X_train,y_train)\ndefault_score_train = logistic_model.score(X_train,y_train)\ndefault_score_test = logistic_model.score(X_test,y_test)\nlm_pred_test = logistic_model.predict(X_test)\nlm_pred_train = logistic_model.predict(X_train)\nprint(\"-----\"*20)\nprint(\"Logistic regression score with default values for Train data : \",default_score_train)\nprint(\"Logistic regression score with default values for Test data : \",default_score_test)\nprint(\"-----\"*20)\nplot_confusion_matrix(logistic_model, X_test, y_test,display_labels=['Dead','Survived'],values_format='d');\nplt.xlabel('Predicted status');\nplt.ylabel('True status');","7dff0e85":"#lr_param_grid = {\"penalty\" : [\"l2\"],\"tol\" : [0.0001,0.0002,0.0003],\"max_iter\": [100,200,300],\"C\" :[0.01, 0.1, 1, 10, 100],\"intercept_scaling\": [1, 2, 3, 4],\"solver\":['liblinear'],\"verbose\":[1]}\nlr_param_grid = {\"solver\":['newton-cg', 'lbfgs', 'liblinear'],\"penalty\":['l2'],\"C\" :[0.01, 0.1, 1, 10, 100]}\ngrd_srch_lrm = GridSearchCV(LogisticRegression(), param_grid = lr_param_grid,scoring=\"accuracy\", n_jobs= 4, verbose = 1)\nprint(\"-----\"*20)\ngrd_srch_lrm.fit(X_train,y_train)\nprint(\"-----\"*20)\nprint(\"Best parameters\")\nLRM_best = grd_srch_lrm.best_estimator_\nprint(\"-----\"*20)\nprint(grd_srch_lrm.best_estimator_)\nprint(\"-----\"*20)\nprint(\"Grid search best score\")\nprint(grd_srch_lrm.best_score_)\n","09784acc":"print(\"-----\"*20)\nlrm_grd_train = grd_srch_lrm.score(X_train,y_train)\nprint(\"Tunned logistic regression train-data score : \",lrm_grd_train)\nprint(\"-----\"*20)\nlrm_grd_test = grd_srch_lrm.score(X_test,y_test)\nprint(\"Tunned logistic regression test-data score : \",lrm_grd_test)\nprint(\"-----\"*20)\n\ny_pred = grd_srch_lrm.best_estimator_.predict(X_test)\n#classification_report(y_test, y_pred)\nprint(\"-----\"*20)\nprint(\"Confusion matrix\")\nplot_confusion_matrix(grd_srch_lrm, X_test, y_test,display_labels=['Dead','Survived'],values_format='d');\nplt.xlabel('Predicted status');\nplt.ylabel('True status');","84e27274":"y_pred_test = grd_srch_lrm.best_estimator_.predict(X_act_test)","cf75f14c":"temp = pd.DataFrame(data_test['PassengerId'])\ntemp['Survived'] = y_pred_test\ntemp.to_csv(\"..\/working\/submission.csv\", index = False)","0d5fcfd2":"**One hot encoding for the feature Embarked**","1a03f8c2":"# Initial set-up","b29f2fb1":"**One hot encoding for the feature Sex**","c071170a":"**One hot encoding for the Fare feature**","4210baf0":"**Logistic regression with grid serachcv:**\n\nTrain accuracy : 82\n\nTest accuracy : 79\n","98509c3d":"**One hot encoding for the Age feature**","ac9f8d5b":"### Logistic regression with Tunning","38bd6d03":"**One hot encoding for the Pclass**"}}