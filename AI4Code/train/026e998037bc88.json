{"cell_type":{"f931dd74":"code","4e89b6ac":"code","90f0eadc":"code","0a0a6769":"code","0c29ebb8":"code","2d600771":"code","d9dcbf25":"code","03abd1c3":"code","361e71d6":"code","9778c437":"code","d53a7efb":"code","96f7d0a1":"code","3ecfe440":"code","09cf9921":"code","acc14819":"markdown","5f98c116":"markdown","482fd0c6":"markdown","e0218127":"markdown","f8c4b479":"markdown","51355250":"markdown","bc679168":"markdown","a6e4cf36":"markdown","df996170":"markdown","544c4556":"markdown","a4755c77":"markdown","46b1942d":"markdown","746446e1":"markdown","8b7e026c":"markdown","78969e0f":"markdown","8fbc7f5e":"markdown"},"source":{"f931dd74":"import numpy as np # linear algebra\nnp.random.seed(0)\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport math\nimport random as rn\nrn.seed(0)\n\n\ntrain_data_dict = {'Height': [165, 180, 170, 150, 175, 165],\n        'Mass': [64, 90, 65, 65, 95, 78],\n        'Sex': ['F', 'M', 'F', 'F', 'M', 'M']\n        }\n\ntrain_data = pd.DataFrame(train_data_dict, columns = ['Height', 'Mass', 'Sex'])\n\ntrain_data.head()\n        ","4e89b6ac":"train_data.plot.scatter(x = 'Height', y = 'Mass')","90f0eadc":"test_data_dict = {'Height': [168],\n        'Mass': [70]\n        }\n\ntest_data = pd.DataFrame(test_data_dict, columns = ['Height', 'Mass'])\n\ntest_data.head()","0a0a6769":"distance_arr = np.power(train_data['Height'] - test_data['Height'][0] , 2) + np.power(train_data['Mass'] - test_data['Mass'][0], 2)\ndistance_arr = np.sqrt(distance_arr)\n\ntrain_data[\"Euclid_Dist\"] = distance_arr\n\ntrain_data.sort_values(by=['Euclid_Dist'])\n","0c29ebb8":"plt.plot(train_data['Height'], train_data['Mass'], 'o', color='blue');\nplt.plot(test_data['Height'], test_data['Mass'], 'o', color='red');\nplt.xlabel(\"Height\")\nplt.ylabel(\"Mass\")\ncircle = plt.Circle((168, 70), 9, color='r', fill=False)\nplt.gca().add_artist(circle)","2d600771":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d9dcbf25":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic-preprocessed-train-data\/titanic_train_preprocessed.csv\")\ntrain_data.columns\n\ndefault_titanic_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ny = default_titanic_data['Survived']","03abd1c3":"features = [\"PassengerId\", \"Pclass\", \"Sex\", \"Age\", \"SibSp\", \"Parch\", \"Fare\", \"Cabin\", \"Embarked\", \"Family_Size\", \"Travelled_Together\",\n            \"Title\", \"Marry_Status\"]\nX = pd.get_dummies(train_data[features])","361e71d6":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","9778c437":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\n\nX_train = scaler.transform(X_train)\nX_test = scaler.transform(X_test)","d53a7efb":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import accuracy_score\n\nresult = []\nfor i in range(1, 70):\n    classifier = KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',\n           metric_params=None, n_jobs=1, n_neighbors=i, p=2,\n           weights='distance')\n    classifier.fit(X_train, y_train)\n    pred_i = classifier.predict(X_test)\n    result.append(accuracy_score(pred_i, y_test))","96f7d0a1":"plt.figure(figsize=(12, 6))\nplt.plot(range(1, 70), result, color='red', linestyle='dashed', marker='o',\n         markerfacecolor='blue', markersize=10)\nplt.title('Accuracy Score vs k Value')\nplt.xlabel('K Value')\nplt.ylabel('Accuracy Score')","3ecfe440":"for (i, item) in enumerate(result, start=1):\n    print(i, item)","09cf9921":"max(result)","acc14819":"# Let's sort the training data by Euclidian distance;\n\n* For k=1, there is 1 Female so classification result is Female.\n* For k=3, there is 2 Female and 1 Male so classification result is Female.\n* For k=5, there is 3 Female and 2 Male so classification result is Female.\n\n*The value of k is usually chosen as an odd number so that the majority prevails.*","5f98c116":"# 1. kNN Theoretical Description with basic example\n \nIn the kNN estimation method, the nearest k neighbor of the data to be predicted is evaluated. The highest number of classes in k neighbors is considered as the estimation result.\n\nThe distance between the predicted data and the neighboring data is calculated for determine k nearest neighborhood.\n\nDistance measurement methods may be as follows;\n- Euclidian Distance\n    > For points, (x1, y1) and (x2, y2), it is sqrt( (x1-x2)^2  +  (y1-y2)^2 [](http:\/\/))\n- Manhattan Distance\n> For points, (x1, y1) and (x2, y2), it is |x1 - x2| + |y1 - y2|\n","482fd0c6":"**Plot train dataset**","e0218127":"# kNN (k Nearest Neighborhood) Tutorial\n\nThis tutorial include two parts as;\n\n1. kNN Theoretical Description with basic example\n2. kNN Application with using Titanic Dataset","f8c4b479":"Max accuracy of kNN for titanic dataset is 0.8491 for this study when k=18.","51355250":"# 2. kNN Application with using Titanic Dataset","bc679168":"Training and predict for k=1 to 70","a6e4cf36":"Let's find k closest neighbors for example test data.","df996170":"Example:\n\nLets create example train data set for predict Sex of humans according to Height and Mass measures.","544c4556":"Figure out Accuracy Score vs k Value","a4755c77":"I had preprocessed for the titanic data set in [my previous notebook](https:\/\/www.kaggle.com\/fethiye\/titanic-predict-survival-using-ensemble). You can see preprocessing step from this notebook.\n\nI will continue with the preprocessed data set called titanic_train_preprocessed.csv.","46b1942d":"Split data for train and test","746446e1":"**Calculation of Euclidian Distance for Test Data**\n\nForeach train data, Euclidian distance of test data is calculated and added to train data as \"Euclid_Dist\" column. By the way Euclidian distance of the test data can be seen more clearly.","8b7e026c":"One Hot Encoding for categorical features","78969e0f":"For k = 3, choosen points seen in circle. Red point is test data.","8fbc7f5e":"Normalization with Standard Scaler"}}