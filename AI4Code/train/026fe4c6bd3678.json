{"cell_type":{"c9066018":"code","be680a04":"code","627c8c5a":"code","3e679aa7":"code","0333936a":"code","8e1fca25":"code","47b04bf2":"code","90c71a17":"code","27f8997c":"code","f4fb5c7d":"code","6d5dfb64":"code","85cbe960":"code","81b06bdd":"code","b89f9bb7":"code","e343b054":"code","fca6eebe":"code","6e02aa83":"code","94cf129b":"code","3f673ccb":"code","c5c72f58":"code","13754fe1":"code","c5b17b4e":"code","22335332":"code","0eaf5abf":"code","c7cbc169":"code","ee5681b5":"code","8754d519":"code","6fce769f":"code","cde6afc4":"code","fc8c8583":"code","a6da5a2a":"code","ece464a3":"code","d9f5edeb":"code","fb847351":"code","8cebac6d":"code","d5701f6a":"code","84bba72a":"code","9cdd587f":"code","21fe5a50":"code","d4a7127b":"code","43c2001e":"code","24b3b9eb":"code","8a053d72":"code","74a9e97c":"code","4cbc75c9":"code","2cf97700":"code","13cee258":"code","e40cc342":"code","239d5a36":"code","b98a35c6":"code","d6b70337":"code","e26d32e9":"code","95f985e5":"code","ee5cd6c6":"code","48419edf":"code","df2b620c":"code","937bbc19":"code","632e1b35":"code","8f730904":"code","72a63abc":"code","40abc80b":"code","169929ea":"code","12710a83":"code","7deb10d5":"code","3291e6d6":"code","dc92a63c":"code","543918e6":"code","7dfbfc1e":"code","6a00454b":"code","d6b5f697":"code","b15e7ce9":"code","087c02aa":"code","976078c6":"markdown","8d1f8bd2":"markdown","0130fd63":"markdown","079909f4":"markdown","0e56f746":"markdown","31af04f7":"markdown","596a7ed0":"markdown","10730bc6":"markdown","cbca15e0":"markdown","3a331327":"markdown","0b64210c":"markdown","58b0e450":"markdown","b8b6cfc1":"markdown","2c45148a":"markdown","902d1574":"markdown","aa0cb89d":"markdown","5db3c207":"markdown","4114a792":"markdown","68402faf":"markdown","6c1c6e68":"markdown","af20ca9c":"markdown","dfdfc2d6":"markdown","5cc9374e":"markdown","b6cefa40":"markdown","d879dd6d":"markdown","74f011a8":"markdown","c24e87e0":"markdown","3e4052f9":"markdown","aa2697b0":"markdown","d742463b":"markdown","dd0b7b1a":"markdown","408a2e20":"markdown","b9039f3d":"markdown","8280dd02":"markdown","e1d136a1":"markdown","260cccaf":"markdown","6919c5d7":"markdown","7e9b1818":"markdown","0057c992":"markdown","92802d5f":"markdown","58ba14e8":"markdown","ef54776d":"markdown","8c70b408":"markdown","7b504a93":"markdown","0f7d798c":"markdown","5d818217":"markdown","1845c79d":"markdown","7a297597":"markdown","5b900e0e":"markdown","db5eacab":"markdown","28caa8d2":"markdown","28837cf3":"markdown"},"source":{"c9066018":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be680a04":"import numpy as np\nimport pandas as pd\nimport matplotlib as matplotlib\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nmatplotlib.rcParams[\"figure.figsize\"] = (20,10)","627c8c5a":"data = pd.read_csv(\"..\/input\/bengaluru-house-price-data\/Bengaluru_House_Data.csv\")\ndata.head()","3e679aa7":"data.shape","0333936a":"data.columns","8e1fca25":"data.groupby('area_type')['area_type'].agg('count')","47b04bf2":"drop_columns = ['area_type', 'availability', 'society']\ndf = data.drop(drop_columns, axis = 1)\ndf.head()","90c71a17":"df.isnull().sum(), df.shape","27f8997c":"df2 = df.dropna()\ndf2.isnull().sum(), df2.shape","f4fb5c7d":" df2.head()","6d5dfb64":"df2['size'].unique()","85cbe960":"df2['bhk'] = df2['size'].apply(lambda x: (int)(x.split(' ')[0]))","81b06bdd":"df2.head()","b89f9bb7":"df3 = df2.drop(['size'], axis =1)\ndf3.head()","e343b054":"df3['bhk'].unique()","fca6eebe":"df3[df3.bhk > 20]","6e02aa83":"df3['total_sqft'].unique()","94cf129b":"def isFloat(x):\n    try:\n        float(x)\n    except:\n        return False\n    return True\n    ","3f673ccb":"df3[~( df3['total_sqft'].apply(isFloat) )].head(15)","c5c72f58":"def convertSqftToNum(x):\n    values = x.split('-')\n    if len(values)==2:\n        return (float(values[0])+float(values[1]))\/2\n    try:\n        return float(x)\n    except:\n        return None\n    ","13754fe1":"df4 = df3.copy()\ndf4['total_sqft'] = df4['total_sqft'].apply(convertSqftToNum)\ndf4.head(10)","c5b17b4e":"df5 = df4.copy()","22335332":"df5['price_per_sqft'] = df5['price']*100000\/df5['total_sqft']","0eaf5abf":"df5.head()","c7cbc169":"len(df5.location.unique())","ee5681b5":"#Let us first remove the leading white spaces from the location names.\ndf5.location = df5.location.apply(lambda x: x.strip())\n\nlocation_statistics = df5.groupby('location')['location'].agg('count').sort_values(ascending = False)\nlocation_statistics","8754d519":"location_statistics[location_statistics<10]","6fce769f":"len(location_statistics[location_statistics<10])","cde6afc4":"location_less_than_10 = location_statistics[location_statistics<10]\nlen(df5.location.unique())","fc8c8583":"df5.location = df5.location.apply(lambda x: 'other' if x in location_less_than_10 else x)\nlen(df5.location.unique())","a6da5a2a":"df5.head(20)","ece464a3":"df5.groupby('balcony')['balcony'].agg('count')","d9f5edeb":"df5.shape","fb847351":"\ndf5[(df5.total_sqft\/df.balcony < 300)]","8cebac6d":"\ndf6 = df5[~(df5.total_sqft\/df5.balcony < 300)]\ndf6.shape","d5701f6a":"df6[df6.total_sqft\/df5.bhk < 300]","84bba72a":"df7 = df6[~(df6.total_sqft\/df5.bhk < 300)]\ndf7.shape","9cdd587f":"df7.price_per_sqft.describe()","21fe5a50":"def remove_extremes(df):\n    df_out = pd.DataFrame()\n    for key, dff in df.groupby('location'):\n        m = np.mean(dff.price_per_sqft)\n        sd = np.std(dff.price_per_sqft)\n        reduced_df = dff[(dff.price_per_sqft>(m-sd)) & (dff.price_per_sqft<=(m+sd))]\n        df_out = pd.concat([df_out, reduced_df], ignore_index=True)\n    return df_out\n    \ndf8 = remove_extremes(df7)\ndf8.shape","d4a7127b":"df8.head()","43c2001e":"df8.groupby('location')['location'].describe()\n","24b3b9eb":"pd.concat([df8[df8.bhk==2], df8[df8.bhk==3]], ignore_index= True)[35:70]\n#df6[df6.total_sqft\/df5.bhk < 300]","8a053d72":"def plot_scatter_chart(df, location):\n    bhk2 = df[(df.location == location) & (df.bhk == 2)]\n    bhk3 = df[(df.location == location) & (df.bhk == 3)]\n    matplotlib.rcParams['figure.figsize'] = (15,10)\n    plt.scatter(bhk2.total_sqft, bhk2.price, marker='*', color='red', label='2 bhk', s=50)\n    plt.scatter(bhk3.total_sqft, bhk3.price, marker='+', color='black', label='3 bhk', s=50)\n    plt.xlabel(\"Total Square Feet Area\")\n    plt.ylabel(\"Price in Lakhs\")\n    plt.title(location)\n    plt.legend()\n    \nplot_scatter_chart(df8,\"Rajaji Nagar\")","74a9e97c":"plot_scatter_chart(df8,\"Kanakpura Road\")","4cbc75c9":"def remove_bhk_outliers(df):\n    exclude_indices = np.array([])\n    for location, location_df in df.groupby('location'):\n        bhk_stats={}\n        \n        for bhk, bhk_df in location_df.groupby('bhk'):\n            bhk_stats[bhk] = {\n                'mean': np.mean(bhk_df.price_per_sqft),\n                'std': np.std(bhk_df.price_per_sqft),\n                'count': bhk_df.shape[0]\n            }\n            \n        for bhk, bhk_df in location_df.groupby('bhk'):\n            stats = bhk_stats.get(bhk-1)\n            if stats and stats['count']>5:\n                exclude_indices = np.append(exclude_indices, bhk_df[bhk_df.price_per_sqft<(stats['mean'])].index.values)\n    \n    return df.drop(exclude_indices, axis='index')\n\n\ndf9 = remove_bhk_outliers(df8)\ndf9.shape\n            ","2cf97700":"plot_scatter_chart(df9,\"Rajaji Nagar\")","13cee258":"plot_scatter_chart(df9,\"Kanakpura Road\")","e40cc342":"matplotlib.rcParams['figure.figsize'] = (20,10)\nplt.hist(df9.price_per_sqft, rwidth = 0.75)\nplt.xlabel('Price per Square Feet')\nplt.ylabel('Count')","239d5a36":"df9.bath.unique()","b98a35c6":"df9[df9.bath>=10]","d6b70337":"plt.hist(df9.bath, rwidth=0.75)\nplt.xlabel('Number of Bathrooms')\nplt.ylabel('Count')","e26d32e9":"df9[df9.bath>df9.bhk+2]","95f985e5":"df10 = df9[df9.bath<df9.bhk+2]\ndf10.shape","ee5cd6c6":"df11 = df10.drop(['price_per_sqft'], axis = 'columns')\ndf11.head(), df11.shape","48419edf":"dummy = pd.get_dummies(df11.location)\ndummy.head(10)","df2b620c":"df12 = pd.concat([df11, dummy], axis='columns')\ndf12.head(10)","937bbc19":"df13 = df12.drop(['other'], axis = 1)\ndf13.head(10)","632e1b35":"df14 = df13.drop(['location'], axis = 1)\ndf14.head()\n","8f730904":"df14.shape","72a63abc":"X = df14.drop(['price'], axis = 'columns')\nX.head()","40abc80b":"y = df13.price\ny.head()","169929ea":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 10)","12710a83":"from sklearn.linear_model import LinearRegression\nlrm = LinearRegression()\nlrm.fit(X_train, y_train)\nlrm.score(X_test, y_test)","7deb10d5":"from sklearn.model_selection import ShuffleSplit\nfrom sklearn.model_selection import cross_val_score\n\ncv = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 0)\ncross_val_score(LinearRegression(), X, y, cv = cv)","3291e6d6":"from sklearn.model_selection import GridSearchCV\n\nfrom sklearn.linear_model import Lasso\nfrom sklearn.tree import DecisionTreeRegressor\n\ndef find_optimum_model(X,y):\n    algos = {\n        'linear regression' : {\n            'model' : LinearRegression(),\n            'params' : {\n                'normalize' : [True, False]\n            }\n        },\n        \n        'lasso': {\n            'model' : Lasso(),\n            'params' : {\n                'alpha' : [1, 2],\n                'selection' : ['random', 'cyclic']\n            }\n        },\n        \n        'decision_tree' : {\n            'model' : DecisionTreeRegressor(),\n            'params' : {\n                'criterion' : ['mse', 'friedman_mse'],\n                'splitter' : ['best', 'random']\n            }\n        }\n        \n    }\n    \n    scores = []\n    cv  = ShuffleSplit(n_splits = 5, test_size = 0.2, random_state = 0)\n    for algo_name, config in algos.items():\n        gs = GridSearchCV(config['model'], config['params'], cv = cv, return_train_score = False)\n        gs.fit(X,y)\n        \n        scores.append(\n            {\n            'model' : algo_name,\n            'best_score' : gs.best_score_,\n            'best_params' : gs.best_params_\n        }\n        )\n        \n    return pd.DataFrame(scores, columns = ['model', 'best_score', 'best_params'])\n\n\n\nfind_optimum_model(X,y)        \n        ","dc92a63c":"def predict(location, sqft, bath, balcony, bhk):\n    location_index = np.where(X.columns == location)[0][0]\n    \n    x = np.zeros(len(X.columns))\n    x[0] = sqft\n    x[1] = bath\n    x[2] = balcony\n    x[3] = bhk\n    \n    if location_index >= 0:\n        x[location_index] = 1\n        \n    return lrm.predict([x])[0]","543918e6":"predict('1st Phase JP Nagar', 1200, 2, 1, 3)","7dfbfc1e":"predict('1st Phase JP Nagar', 1200, 3, 1, 4)","6a00454b":"predict('Indira Nagar', 1200, 2, 1, 3)","d6b5f697":"predict('Indira Nagar', 1200, 3, 1, 4)","b15e7ce9":"import pickle\nwith open('Bangalore_House_Prices_Model.pickle', 'wb') as f:\n    pickle.dump(lrm, f)","087c02aa":"import json\ncolumns = {\n    'data_columns' : [col.lower() for col in X.columns]\n}\nwith open(\"columns.json\", \"w\") as f:\n    f.write(json.dumps(columns))","976078c6":"### Now let us explore the column 'location' and see how many unique locations are present in our dataset and how many estates are in a particular location.","8d1f8bd2":"#  ***FEATURE ENGINEERING***","0130fd63":"### Since we have 13,320 rows we can safely drop the rows having null values. ","079909f4":"## Typically, one should try a couple of different models with different parameters to come up with the best optimal model for prediction of price.","0e56f746":"### Now let us plot a histogram to observe the number of estates in a particular range of price per sq ft.","31af04f7":"### Now let us look at the columns 'bath' and 'balcony' and filter out the anomalies related to them.","596a7ed0":"### And we are also going to do the same.","10730bc6":"### Now if we observe the column 'size' we see that some values have values in 'x BHK' while some like 'x Bedroom'. Let us see how data entries in this column behave.","cbca15e0":"### We can see that some of the estate have as many as 43 bedrooms in it which clearly indicates it as an outlier. Let us observe more about these type of outliers.","3a331327":"### Also let us explore the bathroom feature or column 'bath' in our dataset.","0b64210c":"### Let us first try running our model on **Linear Regression algorithm** and see how the results pan out.","58b0e450":"### Now let us first examine our first feature that is \"area_type\".","b8b6cfc1":"### We can see that the majority of the time, we get a score of more than 80%.","2c45148a":"### So let's remove these anomalies by taking the mean of the range and also check for other abnormalities. We will do that by checking whether the data entry can be converted into float type or not.","902d1574":"### We will be printing the count of data samples in each of the categories of the area_type feature.","aa0cb89d":"### Now we can drop our column 'price_per_sqft' feature as we have exhausted its use. We used it to detect the outliers and did some data cleaning with its help. Now the column has no use for us and hence we can drop it.","5db3c207":"## Since we can see from the above comparison, linear regression is giving the best and optimum results. So we will use linear regression only for the prediction of price for unknown data.","4114a792":"### One of the ways to convert a text column into a numerical column is 'ONE-HOT ENCODING'. It is also called dummies method.","68402faf":"### We can see that sometimes we don't get a single value but a range of values like '1133 - 1384' which can be seen above.","6c1c6e68":"### Now we all know that in the real estate business, price per sq ft of the estate is of utmost significance.","af20ca9c":"# ***DATA CLEANING PROCESS***","dfdfc2d6":"### Therefore, we need to improvise again and remove such anomalies from our dataset. But first let's look at a scatter plot per location based on this ambiguity to identify which points are to be removed.","5cc9374e":"### Also we can drop the column 'size' as it is of no use to us right now.","b6cefa40":"### Now, if we see there are no NULL values which can be seen above. Also we see the size of the new dataset obtained after dropping the NULL values.","d879dd6d":"### But if we will consider all the locations,then we will be having more than 1250 columns, which will not be convenient. This increases the dimensionality too much, and hence we need to reduce the dimensions.","74f011a8":"### Also if we look into our dataset we will find that some of the 2 bhk estates have more price than 3 bhk estates where total sq_ft area for both of them is same. It is a anomaly which we need to fix.\n","c24e87e0":"### So in order to tackle this problem, we will be creating a new column called 'bhk', which will show how many bedrooms are present in the house.","3e4052f9":"### After balcony and bath, let us now look at 'price_per_sqft' in detail. ","aa2697b0":"### Hence, we will be adding a new feature 'price_per_sqft' to observe our dataset into more details and also it will help us in cleansing our dataset of outliers and other anomalies.","d742463b":"### Now we are here proceeding for a simple model and hence we will drop some of the features we think don't have any effect on the price, which is our target variable.","dd0b7b1a":"### Also we can see that the 'location' column of our dataset has a textual representaion and since it is categorical we can convert it into a numerical column.","408a2e20":"### We can see apart from the range we also have other types of data entries, such as 34.46Sq. Meter in row 410 and so on.","b9039f3d":"### Now mean and standard deviation will be calculated per location as some locations will have low prices while some will have higher prices.","8280dd02":"### Therefore we will be removing these extreme values on the basis of mean and standard deviation.","e1d136a1":"### So what we will do is that we will define a 'other' column, which will include all those locations where the data entries are only '1' and '2'.","260cccaf":"## So we will be using Grid search CV method for using other regression techniques. It's an API from sklearn which can be used to run our model on different regressors and get the optimal algorithm for prediction.","6919c5d7":"### As we can see that the estate with 43 bedrooms has an area of 2400 sq. ft. which is absurd.","7e9b1818":"## We will first use a k-fold cross validation method for prediction.","0057c992":"### We can see that with the new dataset the anomalies have reduced to a very minimal value.","92802d5f":"### So we can see that the minimum and the maximum values for the column 'price_per_sqft' can be safely classified as outliers.","58ba14e8":"* ##  Handling the null values.","ef54776d":"### We can see from the above graph that price of 2bhk estate is higher than 3bhk when area is about 1700 sq ft.","8c70b408":"### To look more into these type of errors, let us explore the column 'total_sqft' into detail.","7b504a93":"### In the index 63 and 64, 2 bhk has a price of 65 lakhs while 3 bhk has a price of 60 lakhs and total area sq_ft of both the estates are almost same.","0f7d798c":"### This is a very large number for locations. Now we convert the textual data in numerical by using 'ONE-HOT ENCODING'.","5d818217":"### So in order to handle these non uniformities in data, we will be taking the mean if the entry is of range type and for any other type of entry in this column we will just simply drop the corresponding row.","1845c79d":"### Now we can see that a new column has been added in our dataset.","7a297597":"### Now plotting the same scatter plot which we plotted above but this time with the new dataset.","5b900e0e":"### We also see that when we run Linear Regression on five full cross validation, we get a decent score. But we should also try other regression techniques.","db5eacab":"### Thus, we are going to drop 'area_type', 'society' and 'availability'. We will assume that these features will not be having any effect on our target variable.","28caa8d2":"### Since our price was given in lakhs, thus we have multiplied 100000 in the price of each state, which can be seen above.","28837cf3":"# Exporting our model"}}