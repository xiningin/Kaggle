{"cell_type":{"34697779":"code","01ee15db":"code","f5353601":"code","133dc76c":"code","a698649e":"code","4fc3bda0":"code","5f268f33":"code","e3de906d":"code","7c3d341c":"code","06bd728e":"code","ad394cf4":"code","73248a6e":"code","197e2445":"code","36c66daf":"code","85b2b5cf":"code","0b351365":"code","abf16019":"code","50180efe":"code","fa521a30":"code","221e4b34":"code","b2b26296":"code","6c9cf37f":"code","82024a52":"code","3aac2893":"code","d2917763":"code","cf5f4ae2":"code","e7b745ee":"code","7568b473":"code","0b201135":"code","bb3acf22":"code","aa3a4d5e":"code","efc4cfe5":"code","9cb59868":"code","73881e27":"markdown","eb3bd386":"markdown","8086f882":"markdown","4da9650e":"markdown","05d032e6":"markdown","24e5c40f":"markdown","399132de":"markdown","0561006c":"markdown","8270c2eb":"markdown","a1b22eb3":"markdown","127b577b":"markdown","63f79187":"markdown","f13660fc":"markdown"},"source":{"34697779":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","01ee15db":"import pandas as pd\nimport sklearn\nimport matplotlib.pyplot as plt\nimport seaborn as sns\npd.set_option(\"expand_frame_repr\", True)\nimport numpy as np","f5353601":"dadosTreino = pd.read_csv(\"..\/input\/adult-pmr3508\/train_data.csv\",\n        index_col=[\"Id\"],\n        na_values=\"?\")","133dc76c":"workclass_sub = dadosTreino.loc[:, 'workclass'].mode()[0]\nnativecountry_sub = dadosTreino.loc[:, 'native.country'].mode()[0]\n\ndadosTreino.loc[:, 'workclass'].fillna(workclass_sub, inplace = True)\ndadosTreino.loc[:, 'native.country'].fillna(nativecountry_sub, inplace = True)","a698649e":"dadosTreino = dadosTreino.dropna()","4fc3bda0":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndadosTreino['income'] = le.fit_transform(dadosTreino['income'])","5f268f33":"dadosTreino = dadosTreino.drop([\"fnlwgt\", \"native.country\", \"education\"], axis=1)","e3de906d":"colunasNumeradas = [\"workclass\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\", \"occupation\", \"race\", \"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"]\nCodificador = {column: pd.Categorical(dadosTreino[column]).categories for column in colunasNumeradas}\n\ndadosTreinoNum = dadosTreino.copy()\nfor column in colunasNumeradas:\n    if (column in dadosTreino.columns):\n        dadosTreinoNum[column] = pd.Categorical(dadosTreino[column], Codificador[column]).codes","7c3d341c":"dadosTreinoNum.head()","06bd728e":"xTreino = dadosTreinoNum[[\"workclass\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\", \"occupation\", \"race\", \"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"]]\nyTreino = dadosTreinoNum.income","ad394cf4":"from sklearn.model_selection import cross_val_score\nfrom sklearn.svm import SVC","73248a6e":"svc = SVC(random_state=42, probability=True)","197e2445":"resultado_cv = cross_val_score(svc, xTreino, yTreino, cv = 4, scoring=\"accuracy\")\nprint(\"Acur\u00e1cia com cross validation:\", resultado_cv.mean())","36c66daf":"from skopt import BayesSearchCV\nfrom skopt.space import Integer, Real","85b2b5cf":"svc_bayes_cv = BayesSearchCV(estimator = svc,\n                              search_spaces = {'C': Real(1e-2, 20),\n                                               'gamma': ['scale', 'auto'],},\n                              cv = 2,\n                              n_iter = 15, n_jobs=-1, random_state=42).fit(xTreino, yTreino)\n\nprint('Melhor acur\u00e1cia: {}'.format(round(svc_bayes_cv.best_score_,5)))","0b351365":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state=42)","abf16019":"rfc_bayes_cv = BayesSearchCV(estimator = rfc, \n                              search_spaces = {\"n_estimators\": list(range(100, 500)),\n                \"criterion\": [\"gini\", \"entropy\"],\n                \"max_depth\": list(range(1, 50))},\n                              cv =3, \n                n_jobs = -1, \n                random_state = 42, \n                              n_iter = 20, verbose = 1).fit(xTreino, yTreino)\n\nprint(\"Melhor Acur\u00e1cia: \", rfc_bayes_cv.best_score_)","50180efe":"from sklearn.neural_network import MLPClassifier\nfrom scipy.stats import loguniform as sp_loguniform\nfrom sklearn.model_selection import RandomizedSearchCV","fa521a30":"mlp = MLPClassifier(random_state=42, early_stopping=True)","221e4b34":"mlp_random_cv = RandomizedSearchCV(mlp, {'hidden_layer_sizes': [(2 ** i, 2 ** j) for j in np.arange(5, 8) for i in np.arange(4, 7)],\n               'alpha': sp_loguniform(1e-10, 1e-1),\n               'learning_rate': ['constant','adaptive']}, scoring='accuracy', n_iter=25, cv=3, n_jobs=-1, random_state=42)\n%timeit -n 1 -r 1 mlp_random_cv.fit(xTreino, yTreino)\n\nprint('Acur\u00e1cia: {}'.format(round(mlp_random_cv.best_score_,5)))","b2b26296":"from xgboost import XGBClassifier","6c9cf37f":"xTreinoXGB = xTreino.loc[:,~xTreino.columns.duplicated()]","82024a52":"xgb = XGBClassifier(objective='binary:logistic', eval_metric='error', use_label_encoder=False)\nbestscores = cross_val_score(xgb, xTreinoXGB, yTreino)\n\n\nprint('Acur\u00e1cia: {}'.format(round(bestscores.mean(),5)))","3aac2893":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import accuracy_score","d2917763":"svc_auc = roc_auc_score(le.fit_transform(yTreino), svc_bayes_cv.predict_proba(xTreino)[:,1])\nsvc_acc = accuracy_score(yTreino, svc_bayes_cv.predict(xTreino))\n\nprint('AUC - Classificador SVC: {:.5f}'.format(svc_auc))\nprint('Acur\u00e1cia - Classificador SVC: {:.5f}'.format(svc_acc))","cf5f4ae2":"rfc_auc = roc_auc_score(le.fit_transform(yTreino), rfc_bayes_cv.predict_proba(xTreino)[:,1])\nrfc_acc = accuracy_score(yTreino, rfc_bayes_cv.predict(xTreino))\n\nprint('AUC - Classificador Random Forest: {:.5f}'.format(rfc_auc))\nprint('Acur\u00e1cia - Classificador Random Forest: {:.5f}'.format(rfc_acc))\n","e7b745ee":"print('Acur\u00e1cia - Classificador Extreme Boosting: {:.5f}'.format(bestscores.mean()))","7568b473":"mlp_auc = roc_auc_score(le.fit_transform(yTreino), mlp_random_cv.predict_proba(xTreino)[:,1])\nmlp_acc = accuracy_score(yTreino, mlp_random_cv.predict(xTreino))\n\nprint('AUC - Classificador Rede Neural: {:.5f}'.format(mlp_auc))\nprint('Acur\u00e1cia - Classificador Rede Neural: {:.5f}'.format(mlp_acc))","0b201135":"dadosTeste = pd.read_csv(\"..\/input\/adult-pmr3508\/test_data.csv\",\n        index_col=[\"Id\"],\n        na_values=\"?\")","bb3acf22":"xTeste = dadosTeste[[\"workclass\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\", \"occupation\", \"race\", \"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"]]\ncolunasTesteNumeradas = dadosTeste[[\"workclass\",\"education.num\",\"marital.status\",\"occupation\",\"relationship\", \"occupation\", \"race\", \"sex\",\"capital.gain\",\"capital.loss\",\"hours.per.week\"]]\nCodificadorTeste = {column: pd.Categorical(dadosTeste[column]).categories for column in colunasTesteNumeradas}\n\nxTesteNum = xTeste.copy()\nfor column in colunasTesteNumeradas:\n    if (column in dadosTreino.columns):\n        xTesteNum[column] = pd.Categorical(xTeste[column], CodificadorTeste[column]).codes","aa3a4d5e":"yTeste = svc_bayes_cv.predict(xTesteNum)\n\ndecodif = {0: \"<=50K\", 1: \">50K\"}\nyTestePred = np.array([decodif[i] for i in yTeste], dtype=object)","efc4cfe5":"yTestePred","9cb59868":"yTestePred = pd.DataFrame(yTestePred, columns=['income'])\nyTestePred.to_csv('submission.cv', index = True, index_label = 'Id')","73881e27":"**Classificador Rede Neural**","eb3bd386":"Para melhorar os resultados, pode-se utilizar modelos de otimiza\u00e7\u00e3o de hiperpar\u00e2metros; desse modo, vamos utilizar o Bayes Search para melhorar a acur\u00e1cia.","8086f882":"**Submiss\u00e3o e tratamento dos dados de teste**","4da9650e":"Para comparar os classificadores, usaremos os valores da acur\u00e1cia e do AUC da curva ROC.","05d032e6":"**Importa\u00e7\u00e3o e tratamento dos dados**","24e5c40f":"Novamente, vamos otimizar os hiperpar\u00e2metros; dessa vez, ser\u00e1 usado o Random Search.","399132de":"Nesse modelo, o classificador Support Vector Machine obteve os melhores resultados para AUC e acur\u00e1cia. Logo, vamos utiliz\u00e1-lo para a predi\u00e7\u00e3o dos testes.","0561006c":"**Classificador Random Forest**","8270c2eb":"**Classificador Support Vector Machine**","a1b22eb3":"Do mesmo modo; utilizaremos o Bayes search para otimizar os hiperpar\u00e2metros e, por consequ\u00eancia, melhorar a acur\u00e1cia.","127b577b":"Por fim, vamos fazer os tratamentos dos dados de teste e utilizar o Classificador SVM para predizer o resultado final. Ent\u00e3o, vamos submeter os resultados","63f79187":"**Classificador Extreme Gradient Boosting**","f13660fc":"**Compara\u00e7\u00e3o entre classificadores**"}}