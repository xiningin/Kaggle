{"cell_type":{"45e370a6":"code","08e76728":"code","faa9e87b":"code","261b2082":"code","d46b933a":"code","9989ef4e":"code","8ca218f0":"code","c9b5d634":"code","dc176b54":"code","c5388fc2":"code","e4fb47bd":"code","31119a4c":"code","4f604c91":"code","546a3e18":"code","d48f5b59":"code","7227fbb4":"code","ccefc997":"code","393fbfda":"code","6b1951e0":"code","bafe8753":"code","9c006c11":"code","68c3a854":"code","8c8e0dbc":"code","7ec5c29d":"code","18d1605e":"code","4efc1f66":"code","b4c5315e":"code","028cdcb2":"code","57b985f1":"code","5cde3d25":"code","2f28634b":"code","06e52881":"code","c2790570":"code","b71a9538":"code","0278f544":"code","d44fe66e":"code","bec21be8":"code","a2c5b01d":"code","e6307a90":"code","2fc8ec40":"code","0fbed3e5":"code","b6fa55f2":"code","24a15750":"code","0e071edd":"code","bd854df9":"code","ac6f980b":"code","f2b50496":"code","e3c462f0":"code","93857bc0":"code","82c90bca":"code","bbb70dbb":"code","cfc64a11":"code","3832249f":"code","b969337c":"code","d5d06bde":"code","04a460ef":"code","cfaaa5cd":"code","2395f889":"code","d2e9a541":"code","75b64c02":"code","cd45ec54":"code","4d27f07f":"code","53773f63":"code","601ad0ae":"code","30a05572":"code","74e84df0":"code","e70783da":"code","dbca8a4a":"code","ab13d72e":"code","a22b08ea":"code","17ae7fb3":"code","9028f804":"code","568cc46c":"code","0c2ff02a":"code","34b4f3fe":"code","4a7a2e57":"code","3d7b3320":"code","115f5135":"code","00ee9418":"code","6e691f2f":"code","1e281c95":"code","da6863d6":"code","77cc6ee9":"code","476aa6e7":"code","bc9046ce":"code","23dc02dd":"code","b61d5c34":"code","e6f1eeef":"code","2e755062":"code","c99c8d4b":"code","25771988":"code","481f1ff9":"code","bc2f9515":"code","8d239c97":"code","335a0502":"code","f1fbe58b":"code","f004d178":"code","83dc09fc":"code","7a872b4b":"code","e47dcc8f":"code","110b90f1":"code","4b395780":"code","5dfc0536":"code","762575c6":"code","ce166c62":"code","99635e77":"code","5b6cd571":"code","ae7396f3":"code","f9252969":"code","79932775":"code","cc4c19b4":"code","d5593719":"code","e42b50de":"code","acf26862":"code","885be7a8":"code","c4df62cf":"code","656b0890":"code","375c4082":"code","cfed09b2":"code","a72c01e0":"code","36049223":"code","6ec343d5":"code","8ccc0ba0":"code","6d7d5870":"code","0b11ae4d":"code","090c0867":"code","5da45b0f":"code","a85520e2":"code","4056d58c":"code","50828a77":"code","6cd01d5c":"code","49625198":"code","06c546ab":"code","e10a25de":"code","c710f607":"code","36847dc8":"code","641965ae":"code","c1590d98":"code","7be6b704":"code","ae91fd2d":"code","d09291ba":"code","02477145":"code","5ead79c3":"code","a936b6af":"code","b3e2c0e3":"code","bb574b21":"code","aeb97653":"code","d3b60a15":"code","f506ada3":"code","49a68f8b":"code","0e09a0da":"code","1ffc7a60":"code","3529b3bf":"code","badba323":"code","f422e637":"code","7074628f":"code","13e5ede5":"code","8ba5a2dc":"code","11ccec35":"code","efe55570":"markdown","95d6c2d9":"markdown","c669c468":"markdown","f110c311":"markdown","7209a93c":"markdown","8782df58":"markdown","18638403":"markdown","2cca92a9":"markdown","1a169162":"markdown","3231351c":"markdown","f90ff3df":"markdown","250208f8":"markdown","ed807cd8":"markdown","c926694c":"markdown","d7b9f0cd":"markdown","11e3733f":"markdown","3e541c7f":"markdown","cdd0bb15":"markdown","8a0bb9e1":"markdown","40564de9":"markdown","0ca6235e":"markdown","072d3271":"markdown","15b05d4b":"markdown","145e236f":"markdown","7adda93b":"markdown","a152124d":"markdown","d7e52a63":"markdown","e340a60f":"markdown","354206c3":"markdown","f7f41fd0":"markdown","c98d7557":"markdown","3298e093":"markdown","9920cf2c":"markdown","ab949559":"markdown","4222811d":"markdown","1a87d29b":"markdown","0bc71ebe":"markdown","4e2fe01e":"markdown","27ef1797":"markdown","3fc8c0de":"markdown","94bb63b4":"markdown","19a795df":"markdown","99c90713":"markdown","ad347918":"markdown","247775ba":"markdown","dff8225e":"markdown","21dbd1b4":"markdown","d73ce014":"markdown","0b208499":"markdown","ef6774d4":"markdown","1a67abe9":"markdown","5f6f03df":"markdown","c8f67958":"markdown","08021ec8":"markdown","7e985c7f":"markdown","ad0c87cb":"markdown","59f447f9":"markdown","d6528487":"markdown","f7675fdc":"markdown","de1dc2fc":"markdown","cad7192a":"markdown","1a52a62f":"markdown","58bf8f68":"markdown","6bd14404":"markdown","bd784a4e":"markdown","659d1b4c":"markdown","567c5198":"markdown","3145082b":"markdown","f3a6cf8c":"markdown","8bc9ebcf":"markdown","4cec6b28":"markdown","08ecda11":"markdown","cc783b90":"markdown","ac00ce2a":"markdown","5c77d96f":"markdown","96552c72":"markdown","52c733fb":"markdown","b4df856e":"markdown","f06e2fe0":"markdown","5739f335":"markdown","a628759c":"markdown","abb39b1e":"markdown","3494afbc":"markdown","6fcf5b51":"markdown","711f65c5":"markdown","e755ccab":"markdown","bef9877c":"markdown","bd17f5cb":"markdown","d6f5a6d7":"markdown","979c1061":"markdown"},"source":{"45e370a6":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport string\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk import word_tokenize\nfrom nltk.tokenize import WhitespaceTokenizer \nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score","08e76728":"df_real=pd.read_csv('..\/input\/fakenewsnet\/BuzzFeed_real_news_content.csv')","faa9e87b":"df_real.shape","261b2082":"df_fake=pd.read_csv('..\/input\/fakenewsnet\/BuzzFeed_fake_news_content.csv')","d46b933a":"df_fake.shape","9989ef4e":"df=pd.concat([df_real,df_fake],axis=0)","8ca218f0":"df.shape","c9b5d634":"df['news_type']=df['id'].apply(lambda x: x.split('_')[0])","dc176b54":"df.head(2)","c5388fc2":"df.shape","e4fb47bd":"df.info()","31119a4c":"df.describe()","4f604c91":"df.drop(['id','url', 'top_img','authors','publish_date','canonical_link','meta_data'],axis=1, inplace=True)","546a3e18":"df.isnull().sum()","d48f5b59":"(df.isnull().sum())\/(df.shape[0])*100","7227fbb4":"df['contain_movies']=df['movies'].apply(lambda x: 0 if str(x)=='nan' else 1)","ccefc997":"df['contain_images']=df['images'].apply(lambda x: 0 if str(x)=='nan' else 1)","393fbfda":"df.drop(['movies','images'],axis=1,inplace=True)","6b1951e0":"df.head(2)","bafe8753":"real_order=df[df['news_type']=='Real']['source'].value_counts().sort_values(ascending=False).index","9c006c11":"plt.figure(figsize=(10,6))\nsns.countplot(y='source', data=df[df['news_type']=='Real'],order=real_order,palette='summer')\nplt.xlabel('Count',fontsize=12)\nplt.ylabel('Source',fontsize=12)\nplt.title('Sources of Real News',fontsize=15)\nplt.show()","68c3a854":"fake_order=df[df['news_type']=='Fake']['source'].value_counts().sort_values(ascending=False).index","8c8e0dbc":"plt.figure(figsize=(10,6))\nsns.countplot(y='source',data=df[df['news_type']=='Fake'],order=fake_order,palette='autumn')\nplt.xlabel('Count',fontsize=12)\nplt.ylabel('Source',fontsize=12)\nplt.title('Sources of Fake News',fontsize=20)\nplt.show()","7ec5c29d":"new=[]\nfor x in df[df['news_type']=='Fake']['source'].unique():\n    if x in df[df['news_type']=='Real']['source'].unique():\n        new.append(x)\nprint(new)","18d1605e":"df['common']=df['source'].apply(lambda x: x if x in new else 0)","4efc1f66":"df1=df[df['common']!=0]","b4c5315e":"plt.figure(figsize=(10,6))\nsns.countplot(y='common',data=df1,hue='news_type',palette='viridis')\nplt.xlabel('Count',fontsize=12)\nplt.ylabel('Source',fontsize=12)\nplt.legend(loc='best', title='News Type',fontsize=10)\nplt.title('Common Sources of Real and Fake News',fontsize=20)\nplt.show()","028cdcb2":"df.head(2)","57b985f1":"plt.figure(figsize=(10,6))\nsns.countplot(x='contain_movies', data=df, hue='news_type', palette='PuBuGn_r')\nplt.xlabel('Movies Linked to News',fontsize=12)\nplt.ylabel('Count',fontsize=12)\nplt.legend(loc='best', title='News Type',fontsize=10)\nplt.title('Number of Different News Type Versus Linked Movies',fontsize=18)\nplt.show()","5cde3d25":"plt.figure(figsize=(10,6))\nsns.countplot(x='contain_images', data=df, hue='news_type', palette='PuBuGn_r')\nplt.xlabel('Images Linked to News',fontsize=12)\nplt.ylabel('Count',fontsize=12)\nplt.legend(loc='upper left', title='News Type',fontsize=10)\nplt.title('Number of Different News Type Versus Linked Images',fontsize=18)\nplt.show()","2f28634b":"ps=PorterStemmer()\nwst= WhitespaceTokenizer() \n\n##### 1. Converting text to lower case\ndef lower_func (x):\n    return x.lower()\n\n\n##### 2. Removing Numbers from the text corpus\ndef remove_number_func (x): \n    new=\"\"\n    for a in x:\n        if a.isdigit()==False:\n            new=new+a\n    return new\n\n\n##### 3. Removing punctuation \ndef remove_punc_func(x):\n    new=''\n    for a in x:\n        if a not in string.punctuation:\n            new=new+a\n    return new\n\n##### 4. Removing special characters\ndef remove_spec_char_func(x):\n    new=''\n    for a in x:\n        if (a.isalnum()==True) or (a==' '):\n            new=new+a\n    return(new)\n\n##### 5. Removing english stopwords\ndef remove_stopwords(x):\n    new=[]\n    for a in x.split():\n        if a not in stopwords.words('english'):\n            new.append(a)\n    return \" \".join(new)\n\n##### 6. Stemming words to root words\ndef stem_func(x):\n    wordlist = word_tokenize(x)\n    psstem = [ps.stem(a) for a in wordlist]\n    return ' '.join(psstem)\n\n##### 7. Removing extra whitespaces \ndef remove_whitespace_func(x):\n    return(wst.tokenize(x))\n\ndef compose(f, g):\n    return lambda x: f(g(x))\n\nfinal=compose(compose(compose(compose(compose(compose(remove_whitespace_func,stem_func),remove_stopwords),remove_spec_char_func),remove_punc_func),remove_number_func),lower_func)","06e52881":"df_fake=df[df['news_type']=='Fake']","c2790570":"cv1 = CountVectorizer(analyzer=final)\ncv1.fit(df_fake['title'])\nbow1=cv1.transform(df_fake['title'])","b71a9538":"pd.DataFrame(bow1.todense()).shape","0278f544":"new1=[]\nfor x in range(0,459):\n    new1.append(cv1.get_feature_names()[x])","d44fe66e":"matrix1=pd.DataFrame(bow1.todense(),columns=new1)","bec21be8":"sm1=[]\nfor x in new1:\n    sm1.append(matrix1[x].sum())","a2c5b01d":"trans1=matrix1.transpose()","e6307a90":"trans1['sum']=sm1","2fc8ec40":"top1=trans1.sort_values(by='sum', ascending=False).head(20)","0fbed3e5":"df_real=df[df['news_type']=='Real']","b6fa55f2":"cv2 = CountVectorizer(analyzer=final)\ncv2.fit(df_real['title'])\nbow2=cv2.transform(df_real['title'])","24a15750":"pd.DataFrame(bow2.todense()).shape","0e071edd":"new2=[]\nfor x in range(0,436):\n    new2.append(cv2.get_feature_names()[x])","bd854df9":"matrix2=pd.DataFrame(bow2.todense(),columns=new2)","ac6f980b":"sm2=[]\nfor x in new2:\n    sm2.append(matrix2[x].sum())","f2b50496":"trans2=matrix2.transpose()","e3c462f0":"trans2['sum']=sm2","93857bc0":"top2=trans2.sort_values(by='sum', ascending=False).head(20)","82c90bca":"top1.drop(list(range(0,91)),axis=1,inplace=True)","bbb70dbb":"top1['type']=['Fake']*20","cfc64a11":"top2.drop(list(range(0,91)),axis=1,inplace=True)","3832249f":"top2['type']=['Real']*20","b969337c":"conc1=pd.concat([top1,top2])","d5d06bde":"plt.figure(figsize=(12,10))\nsns.barplot(y=conc1.index,x='sum',data=conc1,hue='type',palette='viridis')\nplt.xticks(rotation=90)\nplt.xlabel('Term Frequency of Words',fontsize=12)\nplt.ylabel('Top Words in Titles',fontsize=12)\nplt.legend(title='News Type',fontsize=12)\nplt.title('Frequency of Words in the Title of News',fontsize=20)\nplt.show()","04a460ef":"cv3 = CountVectorizer(analyzer=final)\ncv3.fit(df_fake['text'])\nbow3=cv3.transform(df_fake['text'])","cfaaa5cd":"pd.DataFrame(bow3.todense()).shape","2395f889":"new3=[]\nfor x in range(0,4958):\n    new3.append(cv3.get_feature_names()[x])","d2e9a541":"matrix3=pd.DataFrame(bow3.todense(),columns=new3)","75b64c02":"sm3=[]\nfor x in new3:\n    sm3.append(matrix3[x].sum())","cd45ec54":"trans3=matrix3.transpose()","4d27f07f":"trans3['sum']=sm3","53773f63":"top3=trans3.sort_values(by='sum', ascending=False).head(30)","601ad0ae":"cv4 = CountVectorizer(analyzer=final)\ncv4.fit(df_real['text'])\nbow4=cv4.transform(df_real['text'])","30a05572":"pd.DataFrame(bow4.todense()).shape","74e84df0":"new4=[]\nfor x in range(0,6529):\n    new4.append(cv4.get_feature_names()[x])","e70783da":"matrix4=pd.DataFrame(bow4.todense(),columns=new4)","dbca8a4a":"sm4=[]\nfor x in new4:\n    sm4.append(matrix4[x].sum())","ab13d72e":"trans4=matrix4.transpose()","a22b08ea":"trans4['sum']=sm4","17ae7fb3":"top4=trans4.sort_values(by='sum', ascending=False).head(30)","9028f804":"top3.drop(list(range(0,91)),axis=1,inplace=True)","568cc46c":"top3['type']=['Fake']*30","0c2ff02a":"top4.drop(list(range(0,91)),axis=1,inplace=True)","34b4f3fe":"top4['type']=['Real']*30","4a7a2e57":"conc2=pd.concat([top3,top4])","3d7b3320":"plt.figure(figsize=(12,10))\nsns.barplot(y=conc2.index,x='sum',data=conc2,hue='type',palette='viridis')\nplt.xticks(rotation=90)\nplt.xlabel('Term Frequency of Words',fontsize=12)\nplt.ylabel('Top Words in Texts',fontsize=12)\nplt.legend(title='News Type',fontsize=12,loc='lower right')\nplt.title('Frequency of Words in the Text of News',fontsize=20)\nplt.show()","115f5135":"df['title_length']=df['title'].apply(lambda x: len(x))","00ee9418":"plt.figure(figsize=(10,6))\nsns.kdeplot(df[df['news_type']=='Real']['title_length'])\nsns.kdeplot(df[df['news_type']=='Fake']['title_length'])\nplt.xlabel('Title Length',fontsize=12)\nplt.ylabel('Density',fontsize=12)\nplt.legend(title='News Type',fontsize=10,labels=['Real','Fake'])\nplt.title('Distribuiton of Title Length for Real and Fake News',fontsize=15)\nplt.show()","6e691f2f":"X1=df['text']\ny1=df['news_type']","1e281c95":"X1_train, X1_test, y1_train, y1_test = train_test_split(X1, y1, test_size=0.3, random_state=42)","da6863d6":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',RandomForestClassifier())\n    ])","77cc6ee9":"pp.fit(X1_train,y1_train)","476aa6e7":"predictions1=pp.predict(X1_test)","bc9046ce":"print(confusion_matrix(y1_test, predictions1))\nprint('\\n')\nprint(classification_report(y1_test, predictions1))","23dc02dd":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',RandomForestClassifier())\n    ])","b61d5c34":"pp.fit(X1_train,y1_train)","e6f1eeef":"predictions2=pp.predict(X1_test)","2e755062":"print(confusion_matrix(y1_test, predictions2))\nprint('\\n')\nprint(classification_report(y1_test, predictions2))","c99c8d4b":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n    ])","25771988":"pp.fit(X1_train,y1_train)","481f1ff9":"predictions3=pp.predict(X1_test)","bc2f9515":"print(confusion_matrix(y1_test, predictions3))\nprint('\\n')\nprint(classification_report(y1_test, predictions3))","8d239c97":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n    ])","335a0502":"pp.fit(X1_train,y1_train)","f1fbe58b":"predictions4=pp.predict(X1_test)","f004d178":"print(confusion_matrix(y1_test, predictions4))\nprint('\\n')\nprint(classification_report(y1_test, predictions4))","83dc09fc":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',PassiveAggressiveClassifier())\n    ])","7a872b4b":"pp.fit(X1_train,y1_train)","e47dcc8f":"predictions5=pp.predict(X1_test)","110b90f1":"print(confusion_matrix(y1_test, predictions5))\nprint('\\n')\nprint(classification_report(y1_test, predictions5))","4b395780":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',PassiveAggressiveClassifier())\n    ])","5dfc0536":"pp.fit(X1_train,y1_train)","762575c6":"predictions6=pp.predict(X1_test)","ce166c62":"print(confusion_matrix(y1_test, predictions6))\nprint('\\n')\nprint(classification_report(y1_test, predictions6))","99635e77":"X2=df['title']\ny2=df['news_type']","5b6cd571":"X2_train, X2_test, y2_train, y2_test = train_test_split(X2, y2, test_size=0.3, random_state=42)","ae7396f3":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',RandomForestClassifier())\n    ])","f9252969":"pp.fit(X2_train,y2_train)","79932775":"predictions7=pp.predict(X2_test)","cc4c19b4":"print(confusion_matrix(y2_test, predictions7))\nprint('\\n')\nprint(classification_report(y2_test, predictions7))","d5593719":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',RandomForestClassifier())\n    ])","e42b50de":"pp.fit(X2_train,y2_train)","acf26862":"predictions8=pp.predict(X2_test)","885be7a8":"print(confusion_matrix(y2_test, predictions8))\nprint('\\n')\nprint(classification_report(y2_test, predictions8))","c4df62cf":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n    ])","656b0890":"pp.fit(X2_train,y2_train)","375c4082":"predictions9=pp.predict(X2_test)","cfed09b2":"print(confusion_matrix(y2_test, predictions9))\nprint('\\n')\nprint(classification_report(y2_test, predictions9))","a72c01e0":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n    ])","36049223":"pp.fit(X2_train,y2_train)","6ec343d5":"predictions10=pp.predict(X2_test)","8ccc0ba0":"print(confusion_matrix(y2_test, predictions10))\nprint('\\n')\nprint(classification_report(y2_test, predictions10))","6d7d5870":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',PassiveAggressiveClassifier())\n    ])","0b11ae4d":"pp.fit(X2_train,y2_train)","090c0867":"predictions11=pp.predict(X2_test)","5da45b0f":"print(confusion_matrix(y2_test, predictions11))\nprint('\\n')\nprint(classification_report(y2_test, predictions11))","a85520e2":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',PassiveAggressiveClassifier())\n    ])","4056d58c":"pp.fit(X2_train,y2_train)","50828a77":"predictions12=pp.predict(X2_test)","6cd01d5c":"print(confusion_matrix(y2_test, predictions12))\nprint('\\n')\nprint(classification_report(y2_test, predictions12))","49625198":"df['title_text']=df['title']+': ' +df['text']","06c546ab":"X3=df['title_text']\ny3=df['news_type']","e10a25de":"X3_train, X3_test, y3_train, y3_test = train_test_split(X3, y3, test_size=0.3, random_state=42)","c710f607":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',RandomForestClassifier())\n    ])","36847dc8":"pp.fit(X3_train,y3_train)","641965ae":"predictions13=pp.predict(X3_test)","c1590d98":"print(confusion_matrix(y3_test, predictions13))\nprint('\\n')\nprint(classification_report(y3_test, predictions13))","7be6b704":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',RandomForestClassifier())\n    ])","ae91fd2d":"pp.fit(X3_train,y3_train)","d09291ba":"predictions14=pp.predict(X3_test)","02477145":"print(confusion_matrix(y3_test, predictions14))\nprint('\\n')\nprint(classification_report(y3_test, predictions14))","5ead79c3":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n    ])","a936b6af":"pp.fit(X3_train,y3_train)","b3e2c0e3":"predictions15=pp.predict(X3_test)","bb574b21":"print(confusion_matrix(y3_test, predictions15))\nprint('\\n')\nprint(classification_report(y3_test, predictions15))","aeb97653":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',MultinomialNB())\n    ])","d3b60a15":"pp.fit(X3_train,y3_train)","f506ada3":"predictions16=pp.predict(X3_test)","49a68f8b":"print(confusion_matrix(y3_test, predictions16))\nprint('\\n')\nprint(classification_report(y3_test, predictions16))","0e09a0da":"pp=Pipeline([\n    ('bow',CountVectorizer(analyzer=final)),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',PassiveAggressiveClassifier())\n    ])","1ffc7a60":"pp.fit(X3_train,y3_train)","3529b3bf":"predictions17=pp.predict(X3_test)","badba323":"print(confusion_matrix(y3_test, predictions17))\nprint('\\n')\nprint(classification_report(y3_test, predictions17))","f422e637":"pp=Pipeline([\n    ('bow',CountVectorizer()),\n    ('tfidf',TfidfTransformer()),\n    ('classifier',PassiveAggressiveClassifier())\n    ])","7074628f":"pp.fit(X3_train,y3_train)","13e5ede5":"predictions18=pp.predict(X3_test)","8ba5a2dc":"print(confusion_matrix(y3_test, predictions18))\nprint('\\n')\nprint(classification_report(y3_test, predictions18))","11ccec35":"print('Text_Random Forest Classifier_With Text Preprocessing: ', round(100*accuracy_score(y1_test,predictions1)))\nprint('Text_Random Forest Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y1_test,predictions2)))\nprint('Text_Naive Bayes Classifier_With Text Preprocessing: ', round(100*accuracy_score(y1_test,predictions3)))\nprint('Text_Naive Bayes Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y1_test,predictions4)))\nprint('Text_Passive Aggressive Classifier_With Text Preprocessing: ', round(100*accuracy_score(y1_test,predictions5)))\nprint('Text_Passive Aggressive Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y1_test,predictions6)))\nprint('\\n')\nprint('Title_Random Forest Classifier_With Text Preprocessing: ', round(100*accuracy_score(y2_test,predictions7)))\nprint('Title_Random Forest Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y2_test,predictions8)))\nprint('Title_Naive Bayes Classifier_With Text Preprocessing: ', round(100*accuracy_score(y2_test,predictions9)))\nprint('Title_Naive Bayes Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y2_test,predictions10)))\nprint('Title_Passive Aggressive Classifier_With Text Preprocessing: ', round(100*accuracy_score(y2_test,predictions11)))\nprint('Title_Passive Aggressive Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y2_test,predictions12)))\nprint('\\n')\nprint('Text&Title_Random Forest Classifier_With Text Preprocessing: ', round(100*accuracy_score(y3_test,predictions13)))\nprint('Text&Title_Random Forest Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y3_test,predictions14)))\nprint('Text&Title_Naive Bayes Classifier_With Text Preprocessing: ', round(100*accuracy_score(y3_test,predictions15)))\nprint('Text&Title_Naive Bayes Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y3_test,predictions16)))\nprint('Text&Title_Passive Aggressive Classifier_With Text Preprocessing: ', round(100*accuracy_score(y3_test,predictions17)))\nprint('Text&Title_Passive Aggressive Classifier_Without Text Preprocessing: ', round(100*accuracy_score(y3_test,predictions18)))","efe55570":"#### Passive Aggressive Classifier without Text Preprocessing","95d6c2d9":"The accuracy of Naive Bayes classifier on title with preprocessing is 60%. To improve accuracy, we train we train this model on title without preprocessing.","c669c468":"#### Sources Including Images in the News ","f110c311":"The accuracy of Naive Bayes Classifier is reduced to 64% on the mixture of title and body without preprocessing.To improve accuracy, we train another model.","7209a93c":"#### Passive Aggressive Classifier with Text Preprocessing","8782df58":"#### Sources of Publising Real News","18638403":"#### Random Forest Classifier Without Text Preprocessing","2cca92a9":"The accuracy of Random Forest Classifier on title is 62%. To improve accuracy, we train this model without preprocessing.","1a169162":"#### Passive Aggressive Classifier without Text Preprocessing","3231351c":"#### Analysis of News Body","f90ff3df":"The accuracy of Naive Bayes Classifier on title is reduced to 58% on title without preprocessing.To improve accuracy, we train another model.","250208f8":"**The accuracy of Passive Aggressive Classifier increases to 87% on the mixture of title and body without preprocessing.**","ed807cd8":"#### Analysis of News Title ","c926694c":"#### Naive Bayes Classifier with Text Preprocessing","d7b9f0cd":"* We observe that 87% accuracy is obtained on the test dataset for Passive Aggressive Classifier on combined (body & title) feature matrix without text preprocessing. As 84% accuracy is obtained on the test dataset for Passive Aggressive Classifier on text feature without text preprocessing, it seems that combining titles with body improves the accuracy of the model to 87%. Regarding the preprocessing, it should be mentioned that although some phrases and bigrams should be cleaned and preprocessed, removing stop words and stemming might not be a good idea in this specific dataset as we might loose some langauge information.Therefore, we conclude that Passive Aggressive model on the combined feature matrix without text preprocessing is the best classifcation model in our analysis that can categorize the real and fake news with maximum accuracy.","11e3733f":"<h1>Table of Contents<span class=\"tocSkip\"><\/span><\/h1>\n<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Introduction\" data-toc-modified-id=\"Introduction-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;<\/span>Introduction<\/a><\/span><\/li><li><span><a href=\"#Importing-Libraries\" data-toc-modified-id=\"Importing-Libraries-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;<\/span>Importing Libraries<\/a><\/span><\/li><li><span><a href=\"#Loading-Dataset\" data-toc-modified-id=\"Loading-Dataset-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;<\/span>Loading Dataset<\/a><\/span><\/li><li><span><a href=\"#Data-Cleaning-and-Feature-Engineering\" data-toc-modified-id=\"Data-Cleaning-and-Feature-Engineering-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;<\/span>Data Cleaning and Feature Engineering<\/a><\/span><\/li><li><span><a href=\"#EDA\" data-toc-modified-id=\"EDA-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;<\/span>EDA<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Real-Versus-Fake-News-Source-Analysis\" data-toc-modified-id=\"Real-Versus-Fake-News-Source-Analysis-5.1\"><span class=\"toc-item-num\">5.1&nbsp;&nbsp;<\/span>Real Versus Fake News Source Analysis<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Sources-of-Publising-Real-News\" data-toc-modified-id=\"Sources-of-Publising-Real-News-5.1.1\"><span class=\"toc-item-num\">5.1.1&nbsp;&nbsp;<\/span>Sources of Publising Real News<\/a><\/span><\/li><li><span><a href=\"#Sources-of-Publishing-Maximum-Fake-News\" data-toc-modified-id=\"Sources-of-Publishing-Maximum-Fake-News-5.1.2\"><span class=\"toc-item-num\">5.1.2&nbsp;&nbsp;<\/span>Sources of Publishing Maximum Fake News<\/a><\/span><\/li><li><span><a href=\"#Common-Sources-of-Publishing-Both-Real-and-Fake-News\" data-toc-modified-id=\"Common-Sources-of-Publishing-Both-Real-and-Fake-News-5.1.3\"><span class=\"toc-item-num\">5.1.3&nbsp;&nbsp;<\/span>Common Sources of Publishing Both Real and Fake News<\/a><\/span><\/li><li><span><a href=\"#Sources-Including-Movies-in-the-News\" data-toc-modified-id=\"Sources-Including-Movies-in-the-News-5.1.4\"><span class=\"toc-item-num\">5.1.4&nbsp;&nbsp;<\/span>Sources Including Movies in the News<\/a><\/span><\/li><li><span><a href=\"#Sources-Including-Images-in-the-News\" data-toc-modified-id=\"Sources-Including-Images-in-the-News-5.1.5\"><span class=\"toc-item-num\">5.1.5&nbsp;&nbsp;<\/span>Sources Including Images in the News<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Analysis-of-Title-and-Body-of-News-Articles\" data-toc-modified-id=\"Analysis-of-Title-and-Body-of-News-Articles-5.2\"><span class=\"toc-item-num\">5.2&nbsp;&nbsp;<\/span>Analysis of Title and Body of News Articles<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Preprocessing-Function\" data-toc-modified-id=\"Preprocessing-Function-5.2.1\"><span class=\"toc-item-num\">5.2.1&nbsp;&nbsp;<\/span>Preprocessing Function<\/a><\/span><\/li><li><span><a href=\"#Analysis-of-News-Title\" data-toc-modified-id=\"Analysis-of-News-Title-5.2.2\"><span class=\"toc-item-num\">5.2.2&nbsp;&nbsp;<\/span>Analysis of News Title<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Fake-News\" data-toc-modified-id=\"Fake-News-5.2.2.1\"><span class=\"toc-item-num\">5.2.2.1&nbsp;&nbsp;<\/span>Fake News<\/a><\/span><\/li><li><span><a href=\"#Real-News\" data-toc-modified-id=\"Real-News-5.2.2.2\"><span class=\"toc-item-num\">5.2.2.2&nbsp;&nbsp;<\/span>Real News<\/a><\/span><\/li><li><span><a href=\"#Concatenation\" data-toc-modified-id=\"Concatenation-5.2.2.3\"><span class=\"toc-item-num\">5.2.2.3&nbsp;&nbsp;<\/span>Concatenation<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Analysis-of-News-Body\" data-toc-modified-id=\"Analysis-of-News-Body-5.2.3\"><span class=\"toc-item-num\">5.2.3&nbsp;&nbsp;<\/span>Analysis of News Body<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Fake-News\" data-toc-modified-id=\"Fake-News-5.2.3.1\"><span class=\"toc-item-num\">5.2.3.1&nbsp;&nbsp;<\/span>Fake News<\/a><\/span><\/li><li><span><a href=\"#Real-News\" data-toc-modified-id=\"Real-News-5.2.3.2\"><span class=\"toc-item-num\">5.2.3.2&nbsp;&nbsp;<\/span>Real News<\/a><\/span><\/li><li><span><a href=\"#Concatenation\" data-toc-modified-id=\"Concatenation-5.2.3.3\"><span class=\"toc-item-num\">5.2.3.3&nbsp;&nbsp;<\/span>Concatenation<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Analysis-of-Title-Length\" data-toc-modified-id=\"Analysis-of-Title-Length-5.2.4\"><span class=\"toc-item-num\">5.2.4&nbsp;&nbsp;<\/span>Analysis of Title Length<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Fake\/Real-News-Classification\" data-toc-modified-id=\"Fake\/Real-News-Classification-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;<\/span>Fake\/Real News Classification<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Fake\/Real-News-Detection-Based-on-News-Body\" data-toc-modified-id=\"Fake\/Real-News-Detection-Based-on-News-Body-6.1\"><span class=\"toc-item-num\">6.1&nbsp;&nbsp;<\/span>Fake\/Real News Detection Based on News Body<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Splitting-Data-into-Train-and-Test-Datasets\" data-toc-modified-id=\"Splitting-Data-into-Train-and-Test-Datasets-6.1.1\"><span class=\"toc-item-num\">6.1.1&nbsp;&nbsp;<\/span>Splitting Data into Train and Test Datasets<\/a><\/span><\/li><li><span><a href=\"#Random-Forest-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Random-Forest-Classifier-with-Text-Preprocessing-6.1.2\"><span class=\"toc-item-num\">6.1.2&nbsp;&nbsp;<\/span>Random Forest Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Random-Forest-Classifier-Without-Text-Preprocessing\" data-toc-modified-id=\"Random-Forest-Classifier-Without-Text-Preprocessing-6.1.3\"><span class=\"toc-item-num\">6.1.3&nbsp;&nbsp;<\/span>Random Forest Classifier Without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Naive-Bayes-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Naive-Bayes-Classifier-with-Text-Preprocessing-6.1.4\"><span class=\"toc-item-num\">6.1.4&nbsp;&nbsp;<\/span>Naive Bayes Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Naive-Bayes-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Naive-Bayes-Classifier-without-Text-Preprocessing-6.1.5\"><span class=\"toc-item-num\">6.1.5&nbsp;&nbsp;<\/span>Naive Bayes Classifier without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Passive-Aggressive-Classifier-with-Text-Preprocessing-6.1.6\"><span class=\"toc-item-num\">6.1.6&nbsp;&nbsp;<\/span>Passive Aggressive Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Passive-Aggressive-Classifier-without-Text-Preprocessing-6.1.7\"><span class=\"toc-item-num\">6.1.7&nbsp;&nbsp;<\/span>Passive Aggressive Classifier without Text Preprocessing<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Fake\/Real-News-Detection-Based-on-News-Title\" data-toc-modified-id=\"Fake\/Real-News-Detection-Based-on-News-Title-6.2\"><span class=\"toc-item-num\">6.2&nbsp;&nbsp;<\/span>Fake\/Real News Detection Based on News Title<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Splitting-Data-into-Train-and-Test-Datasets\" data-toc-modified-id=\"Splitting-Data-into-Train-and-Test-Datasets-6.2.1\"><span class=\"toc-item-num\">6.2.1&nbsp;&nbsp;<\/span>Splitting Data into Train and Test Datasets<\/a><\/span><\/li><li><span><a href=\"#Random-Forest-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Random-Forest-Classifier-with-Text-Preprocessing-6.2.2\"><span class=\"toc-item-num\">6.2.2&nbsp;&nbsp;<\/span>Random Forest Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Random-Forest-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Random-Forest-Classifier-without-Text-Preprocessing-6.2.3\"><span class=\"toc-item-num\">6.2.3&nbsp;&nbsp;<\/span>Random Forest Classifier without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Naive-Bayes-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Naive-Bayes-Classifier-with-Text-Preprocessing-6.2.4\"><span class=\"toc-item-num\">6.2.4&nbsp;&nbsp;<\/span>Naive Bayes Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Naive-Bayes-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Naive-Bayes-Classifier-without-Text-Preprocessing-6.2.5\"><span class=\"toc-item-num\">6.2.5&nbsp;&nbsp;<\/span>Naive Bayes Classifier without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Passive-Aggressive-Classifier-with-Text-Preprocessing-6.2.6\"><span class=\"toc-item-num\">6.2.6&nbsp;&nbsp;<\/span>Passive Aggressive Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Passive-Aggressive-Classifier-without-Text-Preprocessing-6.2.7\"><span class=\"toc-item-num\">6.2.7&nbsp;&nbsp;<\/span>Passive Aggressive Classifier without Text Preprocessing<\/a><\/span><\/li><\/ul><\/li><li><span><a href=\"#Fake\/Real-News-Detection-Based-on-Both-Body-and-Title-of-News\" data-toc-modified-id=\"Fake\/Real-News-Detection-Based-on-Both-Body-and-Title-of-News-6.3\"><span class=\"toc-item-num\">6.3&nbsp;&nbsp;<\/span>Fake\/Real News Detection Based on Both Body and Title of News<\/a><\/span><ul class=\"toc-item\"><li><span><a href=\"#Splitting-Data-into-Train-and-Test-Datasets\" data-toc-modified-id=\"Splitting-Data-into-Train-and-Test-Datasets-6.3.1\"><span class=\"toc-item-num\">6.3.1&nbsp;&nbsp;<\/span>Splitting Data into Train and Test Datasets<\/a><\/span><\/li><li><span><a href=\"#Random-Forest-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Random-Forest-Classifier-with-Text-Preprocessing-6.3.2\"><span class=\"toc-item-num\">6.3.2&nbsp;&nbsp;<\/span>Random Forest Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Random-Forest-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Random-Forest-Classifier-without-Text-Preprocessing-6.3.3\"><span class=\"toc-item-num\">6.3.3&nbsp;&nbsp;<\/span>Random Forest Classifier without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Naive-Bayes-Classifier-with-Text-Preprocessing\" data-toc-modified-id=\"Naive-Bayes-Classifier-with-Text-Preprocessing-6.3.4\"><span class=\"toc-item-num\">6.3.4&nbsp;&nbsp;<\/span>Naive Bayes Classifier with Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Naive-Bayes-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Naive-Bayes-Classifier-without-Text-Preprocessing-6.3.5\"><span class=\"toc-item-num\">6.3.5&nbsp;&nbsp;<\/span>Naive Bayes Classifier without Text Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-withText-Preprocessing\" data-toc-modified-id=\"Passive-Aggressive-Classifier-withText-Preprocessing-6.3.6\"><span class=\"toc-item-num\">6.3.6&nbsp;&nbsp;<\/span>Passive Aggressive Classifier withText Preprocessing<\/a><\/span><\/li><li><span><a href=\"#Passive-Aggressive-Classifier-without-Text-Preprocessing\" data-toc-modified-id=\"Passive-Aggressive-Classifier-without-Text-Preprocessing-6.3.7\"><span class=\"toc-item-num\">6.3.7&nbsp;&nbsp;<\/span>Passive Aggressive Classifier without Text Preprocessing<\/a><\/span><\/li><\/ul><\/li><\/ul><\/li><li><span><a href=\"#Conclusion\" data-toc-modified-id=\"Conclusion-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;<\/span>Conclusion<\/a><\/span><\/li><\/ul><\/div>","3e541c7f":"Analyzing text data is more challenging than numeric data. In this project, the following tasks were preformed:\n\n* We performed detailed exploratory data analysis on the real and fake news dataset. We generated multiple plots of all variables for both news categories.\n\n* We determined the most frequent words included in the title or body of the fake news and real news.\n\n* We trained binary classifiers that classify fake news and real news on the basis of words in the title, body, or both title and body of the news articles. We used three different classifiers including Random Forest Classifier, Naive-Bayes Classifier and passive Aggressive Classifier. Passive Aggressive was the best model for this analysis on the combined feature matrix without text preprocessing which predicted fake and reals news with 87% accuracy.","cdd0bb15":"The accuracy of Naive Bayes Classifier on body with preprocessing is 69%. To improve accuracy, we train this model without preprocessing.","8a0bb9e1":"The accuracy of Passive Aggressive Classifier on title with preprocessing is 62%. To improve accuracy, we train this model without preprocessing.","40564de9":"The accuracy of Passive Aggressive Classifier on body with preprocessing is 78%. To improve accuracy, we train this model without preprocessing.","0ca6235e":"# ![4.jpg](attachment:4.jpg)","072d3271":"##### Real News","15b05d4b":"# <center> BuzzFeed News Analysis and Classification <\/center>","145e236f":"The accuracy of Naive Bayes Classifier decreases to 67% on body without preprocessing.To improve accuracy, we train another model.","7adda93b":"#### Splitting Data into Train and Test Datasets ","a152124d":"We will convert this Series to be in term of percentage of the total DataFrame.","d7e52a63":"After the analysis on the words in the title and body of news, we want to know that whether the title length is also a discriminatory feature\/factor between fake and real news category.","e340a60f":"## Loading Dataset","354206c3":"#### Common Sources of Publishing Both Real and Fake News","f7f41fd0":"#### Random Forest Classifier with Text Preprocessing","c98d7557":"#### Random Forest Classifier without Text Preprocessing","3298e093":"#### Preprocessing Function","9920cf2c":"After analyzing the title, we analyze the text body of the news articles. We are interested in finding top 30 representative words in the body of fake news and real news. We perform same steps by calling \"final\" function on the body of the news article, and then select the top 30 most frequent words in the news title for both categories i,e. real news and fake news. We plot the term frequency of such words in both categories i.e., real news and fake news. We plot these words to visualise the high frequency words associated with fake and real news.","ab949559":"The datset does not contain null values in text and news_type columns which are the most important columns for us. We leave the null values in the source column as is. However, we add a new columns to the data frame which show whether the news are accompanied by movies and\/or images or not.","4222811d":"#### Sources Including Movies in the News ","1a87d29b":"## Importing Libraries","0bc71ebe":"### Fake\/Real News Detection Based on News Title","4e2fe01e":"#### Naive Bayes Classifier without Text Preprocessing","27ef1797":"We use 'final' function to process the title of news articles, then select the top 20 most frequent words in the news title for both categories i.e., real news and fake news. We plot the term frequency of these words in both categories.","3fc8c0de":"From the above plot, we notice that words like trump and clinton are the most frequent words in the news body.\nThe term frequency plot shows that some words like clinton, hillari and trump are representative of fake news whereas words like trump, said, clinton are representative of real news.","94bb63b4":"## Conclusion","19a795df":"We will create a Series that displays the total count of missing values per column.","99c90713":"The accuracy of Random Forest Classifier on title is increased to 56% on title without preprocessing.To improve accuracy, we train another model.","ad347918":"The accuracy of Random Forest Classifier on the mixture of title and body without preprocessing is 75%. To improve accuracy, we train another model.","247775ba":"#### Passive Aggressive Classifier without Text Preprocessing","dff8225e":"From the above plot we observe that the politi.co reports maximum real news followed by cnn.it with a count of 32 and 23, respectively.","21dbd1b4":"## Data Cleaning and Feature Engineering","d73ce014":"## Fake\/Real News Classification","0b208499":"The term frequency plot shows that some words like hillari, clinton, freedom and obama are representative of the title of fake news whereas words like trump, clinton, donald and debat are representative of the title of real news.","ef6774d4":"### Real Versus Fake News Source Analysis","1a67abe9":"### Fake\/Real News Detection Based on News Body","5f6f03df":"FakenewsNet is a repository for an ongoing data collection project for fake news research at ASU. The repository consists of comprehensive dataset of Buzzfeed news and politifact which contains two separate datasets of real and fake news. The FakenewsNet consists of multi-dimension information that not only provides signals for detecting fake news but can also be used for researches such as understanding fake news propagation and fake news intervention. However, the repository is very wide and multi-dimensional, In this project, we perform a detailed analysis on Buzzfeed news dataset.\n\nThe Buzzfeed news dataset comprises a complete sample of news published in Facebook from 9 news agencies over a week close to the 2016 U.S. election from September 19 to 23 and September 26 and 27. Every post and the linked article were fact-checked claim-by-claim by 5 BuzzFeed journalists. There are two datsets of Buzzfeed news one dataset of fake news and another dataset of real news in the form of csv files, each have 91 observations and 12 features\/variables.\n\nThe Buzzfeed news dataset consists of two datasets contain the following main features:\n\n- id: the id assigned to the news article webpage Real if the article is real or fake if reported fake.\n\n- title : It refers to the headline that aims to catch the attention of readers and relates well to the major of the news topic.\n\n- text : Text refers to the body of the article, it elaborates the details of news story. Usually there is a major claim which shaped the angle of the publisher and is specifically highlighted and elaborated upon.\n\n- source: It indicates the author or publisher of the news article.\n\n- images: It is an important part of body content of news article, which provides visual cues to frame the story.\n\n- movies: It is also an important part of news article, a link to video or a movie clip included in a article, also provides visual cues to frame the story.\n\nIn this analysis, we do not consider features like url, top_img, authors, publish_date, canonical link and metedata because these usually provide redundant information which we can be obtained from other main variables and do not add more value to our analysis.\n\nThe two main features we care about are the source of the fake news and the language used in the fake news. In particular, we are interested in finding sources which published fake news and finding words that are more associated with one category than other.\n\nThe main purpose of this analysis is to develop methods to analyze fake news versus real news. This project is divided into two parts: (1) Exploratory Data Analysis (2) Classification. The goal of the first part is to analyze the real and fake news datasets to find sources that often published fake news and determine the most frequent words included in the title and body of fake and real news. The goal of the second part is to a classifer that can predict and detect fakenews. We use three different classifiers to classify documents into real\/fake news categories.","c8f67958":"## Introduction","08021ec8":"From the above plot we observe that all the real news sources included images in their articles. We may say that images acts as a proof of thier news. Therefore, this variable reveal that images are an important part of real news articles. The images and movies variables do not give us much details to strenghen our analysis.","7e985c7f":"We define a preprocessing function that performs the following operations:\n\n- Converting text to lower case\n\n- Removing numbers from the text corpus\n\n- Removing punctuation from the text corpus\n\n- Removing special characters such as \u2018<\u2019, \u2018\u2026\u2019 from the text corpus\n\n- Removing english stopwords\n\n- Stemming words to root words\n\n- Removing extra whitespaces from the text corpus","ad0c87cb":"Above plot shows that the rightwingsnews reports maximum fakenews with a count of 17. Also, the number of fake news sources are more than the number of real news sources.","59f447f9":"The accuracy of Passive Aggressive Classifier decreases to 58% on title without preprocessing.","d6528487":"From the above plot, we observe that most of the news are reported without including the movie clips, and there are very little articles which includes movie clips. This variable does not provide much useful information in our analysis.","f7675fdc":"#### Naive Bayes Classifier without Text Preprocessing","de1dc2fc":"#### Naive Bayes Classifier without Text Preprocessing","cad7192a":"##### Real News","1a52a62f":"#### Passive Aggressive Classifier with Text Preprocessing","58bf8f68":"#### Splitting Data into Train and Test Datasets ","6bd14404":"#### Sources of Publishing Maximum Fake News","bd784a4e":"#### Naive Bayes Classifier with Text Preprocessing","659d1b4c":"#### Passive Aggressive Classifier withText Preprocessing","567c5198":"We select variables of our interest only for analysis, including title, text, source, movies, images and news_type, and remove other columns.","3145082b":"#### Splitting Data into Train and Test Datasets ","f3a6cf8c":"The accuracy of Random Forest Classifier on body without preprocessing is 71%. To improve accuracy we train another model.","8bc9ebcf":"##### Concatenation","4cec6b28":"The accuracy of Naive Bayes classifier on the mixture of title and body is 65%. To improve accuracy, we train this model on the mixture of title and body without preprocessing.","08ecda11":"The accuracy of Passive Aggressive Classifier on the mixture of title and body with preprocessing is 76%. To improve accuracy, we train this model without preprocessing.","cc783b90":"In this part, we build three different classifiers that classfies the news as Real or Fake as follows:\n\n- 1. The outcome variable is the news category and the features are terms used in the body of the news article.\n\n- 2. The outcome variable is the news category and the features are terms used in the title of the news article.\n\n- 3. The outcome variable is the news category and the features are combined terms used in the title and body of the news article.","ac00ce2a":"The accuracy of Passive Aggressive Classifier increases to 84% on body without preprocessing.","5c77d96f":"##### Concatenation","96552c72":"The accuracy of Random Forest Classifier on the mixture of title and body is 75%. To improve accuracy, we train this model on the mixture of title and body without preprocessing.","52c733fb":"##### Fake News","b4df856e":"#### Naive Bayes Classifier with Text Preprocessing","f06e2fe0":"### Fake\/Real News Detection Based on Both Body and Title of News ","5739f335":"First, we need to combine these two dataframes into a single dataframe and create a new variable type which contains the news type as real or fake.","a628759c":"##### Fake News","abb39b1e":"There are 7 common sources of real and fake news. This is interesting that the fake news are more reported by these sources as compared to real news. The rightwingnews reports maximum fake news but it also reports some real news. Approximaltely, two third of total news reported by rightwings are fake. On the other hand, the freedomdaily which is the second largest fake news reporting source, barely reports the real news. addictinginfo.org is the only single common source which reports real news more than fake news but the total number of the news it reports is very low.","3494afbc":"### Analysis of Title and Body of News Articles","6fcf5b51":"#### Random Forest Classifier with Text Preprocessing","711f65c5":"#### Random Forest Classifier without Text Preprocessing","e755ccab":"The title length of fake news is slighly larger than the real news. Real news title length distribution is centered with the maximum density at the length of 60, while the center of distribution of title length for fake news is slightly skewed  with the maximum density at the length of 80.","bef9877c":"#### Analysis of Title Length","bd17f5cb":"#### Random Forest Classifier with Text Preprocessing","d6f5a6d7":"The accuracy of Random Forest Classifier on body with preprocessing is only 78% which means that there are only 78% of news in the test dataset that the classifier predicts correctly. To improve accuracy, we train this model on body without preprocessing.","979c1061":"## EDA"}}