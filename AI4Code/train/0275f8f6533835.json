{"cell_type":{"c44d15bf":"code","e64ed093":"markdown"},"source":{"c44d15bf":"f = open(\"..\/input\/submission\/final_5_0.10117320406891336.csv\")\ntem = pd.read_csv(f)\ntem.head(10)\ntem.to_csv('submission.csv', index=False)","e64ed093":"# 0.11701 top 10.57% **ONLY ONE ENTRY**\nAs Genetic Algorithm and Bayesian Optimization have been involved in my project, I've uploaded the code to github.\n\n[Please click here for the code of the whole project](https:\/\/github.com\/mliw\/Kaggle_House_Prices_Advanced_Regression_Techniques_0.11701_top10.6_percent_only_one_entry).\n\n[Please click here for the document of the whole project](https:\/\/mliw.github.io\/Tutorial.pdf).\n\n## 0 Preface\nI used to rank top5% on [Kaggle House Prices Competition](https:\/\/www.kaggle.com\/c\/house-prices-advanced-regression-techniques).\n\n![Public Score with Multiple Entries](https:\/\/github.com\/mliw\/Kaggle_House_Prices_Advanced_Regression_Techniques_0.11701_top10.6_percent_only_one_entry\/blob\/master\/pics\/0.PNG)\n\nHowever, more than 100 entries were made to achieve this score, which means I'm actually tuning my model on the test data set. The problem of data leakage arises when you make submissions more than once.\n\nThis repo aims to tell you how to get a score of 0.11701(top10.57%) with only **ONE ENTRY**. With the help of Genetic Algorithm and Bayesian Optimization(hyperopt), this is not a lucky score achieved randomly, but a certain result we can **ALMOST SURELY** get. The document of this repo is at [here](https:\/\/github.com\/mliw\/Kaggle_House_Prices_Advanced_Regression_Techniques_0.11701_top10.6_percent_only_one_entry\/blob\/master\/doc\/Tutorial.pdf).\n\n![Public Score with One Entries](https:\/\/github.com\/mliw\/Kaggle_House_Prices_Advanced_Regression_Techniques_0.11701_top10.6_percent_only_one_entry\/blob\/master\/pics\/1.PNG)\n\n## 1 Single Models\n8 base models are involved in this repo, and the optimization of these models is involved in files like 1_single_model_svr_2.py. All files start with \"1_\" conduct Genetic Algorithm and Bayesian Optimization(hyperopt) independently.\n\n## 2 Model Stacking\nGreedy algorithm is involved in model stacking(2_stacking.py).\n\n## 3 Result\nResults of stacking are gathered at [here](https:\/\/github.com\/mliw\/Kaggle_House_Prices_Advanced_Regression_Techniques_0.11701_top10.6_percent_only_one_entry\/tree\/master\/stacking).\n\nThe final submission is final_5_0.10117320406891336.csv"}}