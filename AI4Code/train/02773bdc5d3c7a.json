{"cell_type":{"b2471e40":"code","24e19cdc":"code","356bc0c2":"code","685e0c07":"code","70db4e8b":"code","3306be5c":"code","8de9be8f":"code","b3afde4d":"code","f9726bf2":"code","ab37adad":"code","f62eaac2":"markdown","7ca21c26":"markdown","ce482075":"markdown","b505356a":"markdown","53401907":"markdown","c12d4843":"markdown","f06f9e99":"markdown","a6907766":"markdown","ea0c6d73":"markdown","e81be86b":"markdown","4905a68c":"markdown","a9bf3720":"markdown","d69631d2":"markdown","e880b0ce":"markdown"},"source":{"b2471e40":"import numpy as np\nimport pandas as pd \nimport warnings\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.utils import resample\nfrom imblearn.over_sampling import SMOTE\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.preprocessing import MinMaxScaler,StandardScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,classification_report,confusion_matrix, f1_score","24e19cdc":"df = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")\nsns.countplot(df[\"Class\"]);","356bc0c2":"#Check the count of the 2 classes\ndf[\"Class\"].value_counts()","685e0c07":"#scaling the amount column using a standard scaler\nscaler=StandardScaler()\ndf[\"Amount\"]=scaler.fit_transform(np.array(df[\"Amount\"]).reshape(-1,1))\n\n#Dropping the time column\ndf.drop(columns = [\"Time\"], inplace = True)","70db4e8b":"#Checking the Amount column after scaling\ndf[\"Amount\"].head()","3306be5c":"#Create an empty dataframe for storing the performance metrics for multiple algorithms\ndfEval = pd.DataFrame({\"Algorithm\": [\"Logistic Regression\",\"Logistic Regression\",\"Logistic Regression\",\"Logistic Regression\",\n                                    \"Decision Tree\",\"Decision Tree\",\"Decision Tree\",\"Decision Tree\"],\n                       \"Method\" : [ \"Unbalanced\", \"Oversample\", \"Undersample\", \"SMOTE\",\n                                    \"Unbalanced\", \"Oversample\", \"Undersample\", \"SMOTE\"],\n                       \"Accuracy\" : [0,0,0,0,0,0,0,0],\"Precision\" : [0,0,0,0,0,0,0,0],\"Recall\" : [0,0,0,0,0,0,0,0],\n                       \"F1_Score\" : [0,0,0,0,0,0,0,0]})","8de9be8f":"#Checking the evaluation metric dataframe before inserting records in it\ndfEval","b3afde4d":"#Creating a loop that runs 4 times. In each run of the loop, logistic regression as well as decision tree is applied.\n#Run 1 : Original sample without any resampling\n#Run 2 : Minority sample is oversampled\n#Run 3 : Majority sample is undersampled\n#Run 4 : SMOTE(Synthetic Minority Oversampling Technique) is applied. SMOTE uses KNN to generate similar minority samples\n\n#Loop variables for filling the performance metric dataframe\ncnt = 0\n#Logistic Regression Count variable\nLR_cnt = 0 \n#Decision Tree Count variable\nDT_cnt = 4\n\nfor i in range(4):\n    \n    #Creating X and y for storing the regressor and the target variable\n    y = df[\"Class\"].copy()\n    X = df.drop(columns=[\"Class\"]).copy()\n    \n    #Splitting the data into training set and testing set before applying any imbalance handling measures\n    X_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state=42)\n    \n    if i == 0:\n        #DO not perform any imbalance handling measures\n        pass\n    \n    elif (i==1) or (i==2):\n        \n        #Concatenate the regressors and the target variable of the training set and get the fraud and not_fraud records\n        dfTemp = pd.concat([X_train , y_train], axis = 1)\n        fraud = dfTemp[dfTemp[\"Class\"] == 1]\n        not_fraud = dfTemp[dfTemp[\"Class\"] == 0]\n        \n        if i==1:\n            #Oversample minority class to make the number of fraud samples = no of non fraud samples\n            oversampled_fraud = resample(fraud, replace = True, n_samples = len(not_fraud), random_state = 42)\n            data1 = not_fraud\n            data2 = oversampled_fraud\n            \n        else:\n            #Undersample majority class to make the number of non fraud samples = no of fraud samples\n            undersampled_not_fraud = resample(not_fraud, replace = False, n_samples = len(fraud), random_state = 42)\n            data1 = fraud\n            data2 = undersampled_not_fraud\n            \n        #Concatenate the balanced data of fraud and non-fraud cases to get a new dataframe\n        dfNew = pd.concat([data1, data2], axis =0)\n        \n        #Split the balanced data into X_train and y_train datasets\n        y_train = dfNew[\"Class\"].copy()\n        X_train = dfNew.drop(columns = [\"Class\"]).copy()\n        \n        \n    else:\n        #SMOTE method\n        smote = SMOTE(random_state=42, sampling_strategy=1.0, n_jobs=-1)\n        \n        #Create synthetic samples from the training dataset to balance the fraud and non-fraud records by oversampling minority class\n        X_train, y_train = smote.fit_sample(X_train, y_train)\n        \n    \n    #Apply logistic regression and Decision Tree classification for the above 4 cases\n    for j in range(2):\n        if j == 0:\n            \n            #Model for logistic regression\n            model = LogisticRegression()\n            \n            #Incrementing the loop counters\n            cnt = LR_cnt\n            LR_cnt = LR_cnt + 1\n        else:\n            #Model for Decision Tree classification\n            model = DecisionTreeClassifier()\n            \n            #Incrementing the loop counters\n            cnt = DT_cnt\n            DT_cnt = DT_cnt + 1\n        \n        \n        #Fitting the model on the training data\n        model.fit(X_train,y_train)\n        \n        #Getting the predictions for the testing data\n        y_pred = model.predict(X_test)\n        \n        #Filling the performance metrics dataframe with the model values for accuracy, precision, recall and F1 score\n        dfEval.iloc[cnt,2] = round( 100 * model.score(X_test,y_test) , 2)\n        dfEval.iloc[cnt,3] = round( 100 * precision_score(y_test, y_pred) , 2)\n        dfEval.iloc[cnt,4] = round( 100 * recall_score(y_test, y_pred) , 2)\n        dfEval.iloc[cnt,5] = round( 100 * f1_score(y_test, y_pred) , 2)\n        \n        ","f9726bf2":"#Checking the evaluation metric dataframe after the models have been trained and tested\ndfEval","ab37adad":"fig, axes = plt.subplots(nrows=1,ncols=2,figsize = (15,5))\ndfTemp = dfEval[[\"Method\", \"Accuracy\",\"Precision\",\"Recall\",\"F1_Score\"]]\ndfTemp[:4].plot(x=\"Method\", kind = \"line\",legend = True, grid = True, ax = axes[0],\n               title=\"Logistic Regression Scores\")\n\ndfTemp[4:].plot(x=\"Method\", kind = \"line\",legend = True, grid = True, ax = axes[1],\n               title=\"Decision Tree Scores\");","f62eaac2":"*4. Create an empty dataframe for storing the performance metrics for multiple algorithms*","7ca21c26":"*2. Import the data into a dataframe and preview the target column*","ce482075":"*1. Import the required libraries*","b505356a":"    1. By doing nothing and training the algorithm with the data as it is \n    2. By oversampling the minority class in the training dataset \n    3. By undersampling the majority class in the training dataset \n    4. By applying SMOTE(Synthetic Minority Oversampling TEchnique) on the training dataset","53401907":"Here the empty data frame contains:\n    1.  8 rows corresponding to the class imbalance handling techniques\n    2.  6 columns corresponding to algorithm name, method and the 4 performance metrics - Accuracy, Precision, Recall and F1_Score.","c12d4843":"# Outline of the notebook\n\n1. Import the required libraries \n2. Import the data into a dataframe and preview the target column\n3. Remove the time column as time reveals the time after the first transaction and logically should not impact the target column\n4. Create an empty dataframe for storing the performance metrics for multiple algorithms\n5. Split the data into training set and testing set\n6. Deal with problem of class imbalance with the following methods:\n   a) By doing nothing and training the algorithm with the data as it is\n   b) By oversampling the minority class in the training dataset\n   c) By undersampling the majority class in the training dataset\n   d) By applying SMOTE(Synthetic Minority Oversampling TEchnique) on the training dataset\n7. The accuracy, precision, recall and f1 score were compared for all the above methods for 2 algorithms:\n   a) Logistic Regression\n   b) Decision Tree","f06f9e99":"*3. Remove the time column as time reveals the time after the first transaction and logically should not impact the target column*","a6907766":"*5. Split the data into training set and testing set*\n\n*6. Deal with problem of class imbalance with the following methods: *","ea0c6d73":"The following notebook deals with the Credit Card Fraud Detection problem. A cursory glance on the dataset reveals that the data is highly imbalanced and the accuracy score would not suffice as a performance metric. Here's a ouline of what has been done in this notebook.","e81be86b":"![fraud1.jpg](attachment:fraud1.jpg)","4905a68c":"# **Noteworthy points**\n\n1. The data has original columns hidden due to privacy issues and columns available with us are the **28 principal components** of the original columns. As we know that PCA requires data to be scaled before usage hence we can safely *assume* that the 28 columns are already scaled.\n2. Amount column is not scaled and hence we will try to scale it.\n3. Train test split must be done **before** applying any sort of resampling techniques. The reason is as follows:\n\nLet's suppose that you perform oversampling of the minority class before the train test split. What oversampling will do is, it will replicate the minority class records and in our case the 492 records will be replicated to ensure that their count matches that of the majority class i.e. 284315.\n\n> You see the problem here?\n\nAfter oversampling when you perform the train test split, the model will have close to 90% (if not 100%) overlapping of minority class records in the training dataset and testing dataset. Thus, the model already has learnt how to handle the  testing dataset records (from the training dataset) and will pass all the evaluation metrics with flying colours. \n\n> How do we handle this situation?\n\nPerform the train test split first and then apply any resampling techniques. This will ensure that that the minority class records in the training dataset are replicated to form a balanced training dataset. The model will learn to differentiate between the fraud and non-fraud cases using the balanced training dataset and its performance can be efficiently and unbiasedly be evaluated using the unseen testing dataset.","a9bf3720":"# Concluding Remarks\n\nChecking the above plots, we come to know that for this particular problem, Undersampling seems to underperform as compared to other methods. Although, undersampling is giving quite good recall scores, it is doing so at the cost of the precision scores.\nEven, SMOTE gives average performance for the given data and I would place my bets on Oversampling technique in combination with a decision tree model to achieve decent values of precision, recall, accuracy and even F1 score.\n\nLast but not the least, the above techniques are just the ones which I have implemented and there definitely would be room for improvement. \n\nThanks for going through this kernel. Do let me know in the comments if you have any suggestions or doubts.","d69631d2":"# Credit Card Fraud Detection","e880b0ce":"*7. The accuracy, precision, recall and f1 score were compared for all the above methods for 2 algorithms: a) Logistic Regression b) Decision Tree*"}}