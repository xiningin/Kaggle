{"cell_type":{"e84775a2":"code","f4f088b2":"code","1a9b7d44":"code","2f87a4ad":"code","8b1b5945":"code","d1b5be9b":"code","c7c5c317":"code","93a9ff7f":"code","2fd5e864":"code","67a541a1":"code","83c4fae9":"code","45c85876":"code","685d0859":"code","b886158b":"code","6204b7f6":"code","2c0fb149":"markdown","d628dab8":"markdown","4fddc47f":"markdown","3409c80e":"markdown","b877bdf1":"markdown","6cb797dc":"markdown","8db4e028":"markdown","85826b0f":"markdown","5ab2119c":"markdown","f7f7779e":"markdown","9e56a707":"markdown","4389b63f":"markdown","f0a02a1b":"markdown","70226413":"markdown"},"source":{"e84775a2":"# Bread and butter of Machine learning\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# Importing torch libraries\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch\nfrom torch.utils.data import Dataset, DataLoader\n\n# Bread and butter of Machine learning\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# To make waiting look fancy\nfrom tqdm import tqdm","f4f088b2":"train = pd.read_csv('\/kaggle\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/digit-recognizer\/test.csv')\ntrain.head(), test.head()","1a9b7d44":"# train.shape[0] is the number of images in the training data, and test.shape[0] holds the number of images in the test data\ntrain.shape[0], test.shape[0]","2f87a4ad":"def to_tensor(data):\n    return [torch.FloatTensor(point) for point in data]\n\nclass MNISTData(Dataset):\n    def __init__(self, df, X_col, Y_col=None):\n        \"\"\"\n        We're divding the values by 255 to normalize the dataset. \n        It speeds up training. Why 255? because that's the maximum value for a pixel\n        \"\"\"\n        self.features = df[X_col].values\/255\n        self.features = self.features.reshape(len(self.features), 1, 28, 28)\n        self.targets = df[Y_col].values.reshape((-1, 1)) \n        # -1 indicates that the first dimension could be anything\n        \n    \"\"\"\n    To return the length of the dataset\n    \"\"\"\n    def __len__(self):\n        return len(self.targets)\n    \n    \"\"\"\n    This method will get data from the dataframe, based on the index values(idx)\n    \"\"\"\n    def __getitem__(self, idx):\n        return to_tensor([self.features[idx], self.targets[idx]])\n        \n        ","8b1b5945":"# We'll split our data into 90% training and 10% test data \nsplit = int(0.9 * len(train))\nvalid_data = train[split:].reset_index(drop=True)\ntrain_data = train[:split].reset_index(drop=True)\nvalid_data.head()","d1b5be9b":"# Getting features of the image (pixel 0-783, 784 pixels in total for a 28*28 image)\nX_col = list(train.columns[1:])\ny_col = \"label\"\n\ntrain_set = MNISTData(train_data, X_col, y_col)\nvalid_set = MNISTData(valid_data, X_col, y_col)\n\ntrain_loader = DataLoader(train_set, batch_size=64, shuffle=True)\nvalid_loader = DataLoader(valid_set, batch_size=64, shuffle=True)\n\nfor data in train_loader:\n    X_train, y_train = data\n    fig = plt.figure()\n    plt.imshow(X_train[0].reshape(28, 28), cmap='gray')\n    break","c7c5c317":"class dummyModel(nn.Module):\n    def __init__(self):\n        super(dummyModel, self).__init__()\n        \n        \"\"\"\n        In layer 1, which is a convolutional layer, input channels will be 1, \n        since our data consists of graycale images.\n        \n        out_channels is the number of filters, of size 3(kernel_size). \n        out_channels can be whatever we want, so I'm gonna select 4.\n        \n        stride is the number of steps that a filter jumps, from it's previous position.\n        \n        padding is the number of pixels added to both sides of the input data(image), for each dimension.\n        Padding mode is the value of the padding pixels.\n        \"\"\"\n        self.layer1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        \n        #Layer 2\n        self.layer2 = nn.Sequential(\n            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2))\n        self.drop_out = nn.Dropout()\n        \n        #Layer 3\n        # FC layer\n        \n        \n    def forward(self, x):\n        x = self.layer1(x)\n        x = self.layer2(x)\n        return x\n        \n        ","93a9ff7f":"network = dummyModel()\nprint(network)\nnum_epochs = 5\nfor epoch in range(num_epochs):\n    for train_batch in train_loader:\n        train_X, train_y = train_batch\n        # train_X = train_X.reshape(len(train_X), 1, 28, 28)\n        outputs = network.forward(train_X)\n        # To check dimensions of our tensor\n        op = outputs.flatten(start_dim=1, end_dim=-1)\n        break\nprint(outputs.shape)\nprint(op.shape)\n        \n        \n        ","2fd5e864":"class model(nn.Module):\n    def __init__(self):\n        super(model, self).__init__()\n        self.conv1 = nn.Sequential(\n            nn.Conv2d(in_channels=1, out_channels=4, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.BatchNorm2d(4))\n\n        self.conv2 = nn.Sequential(\n            nn.Conv2d(in_channels=4, out_channels=8, kernel_size=3, stride=1, padding=1, padding_mode='replicate'),\n            nn.ReLU(),\n            nn.MaxPool2d(kernel_size=2, stride=2),\n            nn.BatchNorm2d(8))\n\n        self.fc1 = nn.Sequential(\n            nn.Linear(392, 128),\n            nn.Dropout(0.5),\n            nn.ReLU(),\n            nn.BatchNorm1d(128))\n\n        self.fc2 = nn.Sequential(\n            nn.Linear(128, 10))\n            \n    def forward(self, inputs):\n        x = self.conv1(inputs)\n        # print(f\"After conv1, dimensions are: {x.shape}\")\n        x = self.conv2(x)\n        # print(f\"After conv2, dimensions are: {x.shape}\")\n        # Flattening the image\n        x = x.flatten(start_dim=1, end_dim=-1)\n        x = self.fc1(x)\n        # print(f\"After fc1, dimensions are: {x.shape}\")\n        x = self.fc2(x)\n        x = nn.LogSoftmax(dim=1)(x)\n        # print(f\"After fc2, dimensions are: {x.shape}\")\n        return x","67a541a1":"# Before we start training our neural network, we'll define our accuracy function\ndef acc(y_true, y_pred):\n    y_true = y_true.long().squeeze()\n    y_pred = torch.argmax(y_pred, axis=1)\n    return (y_true==y_pred).float().sum()\/len(y_true)","83c4fae9":"network = model()\n# Loss and optimizer\ncriterion = nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(network.parameters())\nloss = []\naccuracy = []\nnum_epochs = 5\nfor i in range(1, num_epochs+1):\n    for data in train_loader:\n        batch_X, batch_Y = data\n        batch_prediction = network.forward(batch_X)\n        #print(batch_prediction[0])\n        \n        batch_Y = batch_Y.long().squeeze()\n        #print(f\"Y_Pred Dimensions: {batch_Y.shape}\\tPrediction Dimensions:{batch_prediction.shape}\")\n        batch_loss = criterion(batch_prediction, batch_Y)\n        batch_acc = acc(batch_Y, batch_prediction)\n    \n        optimizer.zero_grad()\n        batch_loss.backward()\n        optimizer.step()\n        \n        loss.append(batch_loss)\n        accuracy.append(batch_acc)\n    with torch.no_grad():\n        for valid_batch in valid_loader:\n            valid_X, valid_Y = valid_batch\n            valid_Y = valid_Y.long().squeeze()\n            valid_prediction = network.forward(valid_X)\n            valid_loss = criterion(valid_prediction, valid_Y)\n            valid_acc = acc(valid_Y, valid_prediction)\n    print(\"----------------------------------------------------------------------------------------------\")  \n    print(f\"Yo, this is epoch number {i}\")\n    print(f\"Training Accuracy: {batch_acc:.4f}\\tTraining Loss:{batch_loss:.4f}\\nValidation Accuracy: {valid_acc:.4f}\\tValidation Loss: {valid_loss:.4f}\")","45c85876":"# Gotta prepare the test set first\ntest[y_col] = [-1]*len(test)\n\ntest_set = MNISTData(test, X_col, y_col)\ntest_loader = tqdm(DataLoader(test_set, batch_size=1024, shuffle=False))\ntest_pred = []\nwith torch.no_grad():\n    for test_X, _ in test_loader:\n        pred = network.forward(test_X)\n        test_pred.extend(np.argmax(pred, axis=1))","685d0859":"test_X, _ = next(iter(test_loader))\ntest_X = test_X[:36]\nfig, ax = plt.subplots(nrows=6, ncols=6, figsize=(15, 15))\n\nfor i, image in enumerate(test_X):\n    image = image.reshape(28, 28)\n    ax[i\/\/6][i%6].axis('off')\n    ax[i\/\/6][i%6].imshow(image, cmap='gray')\n    ax[i\/\/6][i%6].set_title(test_pred[i].item(), fontsize=20, color='blue')","b886158b":"submissions = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nlabels = [x.item() for x in test_pred]\nsubmissions[\"Label\"] = labels\nsubmissions.head()","6204b7f6":"submissions.to_csv(\"submission.csv\", index=False)","2c0fb149":"> Well, that's pretty accurate!\nLet's submit our predictions\n","d628dab8":"# Training our Neural Network","4fddc47f":"> Oh Man, If you get these numbers for any dataset other than this, it's a major **RED** Flag!","3409c80e":"Our Tensor is in the shape  $(N, C, H, W)$,  where\n  * $N$ = batch size\n  * $C$ = Number of channels\n  * $H$ = Height of the image\n  * $W$ = Width of the image\n  \n![](http:\/\/)Hence, we flatten it to $(N, F)$, where\n* $N$ = batch size\n* $F=C*H*W$\n\n> So we need 392 neurons in the first FC layer after our convolutional layers? Noted.\nHow did we get 392? simple, $8*7*7$","b877bdf1":"# Converting the data in csv files to images\n> Let's convert our data from pixel values in csv to actual images\n\nPytorch has it's own thing to handle data feeding to the neural network. We'll need to create a class and put in methods for data retrieval. I highly recommend using help(Dataset) to get some insight about what it can do. Will hardly take 2 minutes of your time. Do it.","6cb797dc":"> This was my first notebbok using Pytorch. Leave a upvote if you found it helpful!\n\nNote: You can always bump up the number of channels in the convolutional layers, add more layers, to increase accuracy!","8db4e028":"> Let's see our predictions\n","85826b0f":"# Making a Dummy Neural Network\n> So we're gonna define a model with 2 convolutional layers and 2 Fully Connected layers. The thing with pytorch is, we gotta know the dimensions of our data, at the end of our convolutional layers, to be able to connect them to the fully connected layers. So we're just gonna define a dummy model with our convolutional layers,and check the dimensions of the last convolutional layer. Once we know that, we'll define our original model with all the dimensions in place ","5ab2119c":"# Let's make Predictions","f7f7779e":"# Meeting the data","9e56a707":"> All the above data looks like garbage to us. We'll need to convert them to images.","4389b63f":"# Mnist Handwritten Digit dataset with Pytorch (CNN)\n> Hi Everyone, in this notebook we're going to train a neural network for the famous MNIST digit dataset, using Pytorch\nJust a friendly reminder that the MNIST Handwritten digit dataset has 70,000 images of size 28 * 28\n\nReferences: This [notebook](https:\/\/www.kaggle.com\/tarunpaparaju\/mnist-competition-pytorch-nn) from [Tarun Paparaju](https:\/\/www.kaggle.com\/tarunpaparaju)\n","f0a02a1b":"# Training our (Dummy) Convolutional Neural Network","70226413":"# Creating our Model for training\n> Playtime is over, let's get down to business"}}