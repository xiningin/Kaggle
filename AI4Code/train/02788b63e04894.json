{"cell_type":{"02b878b2":"code","54aff3b6":"code","55c5a1a1":"code","2368a0bf":"code","c0c86a45":"code","669033d5":"code","2c1e3e10":"code","5ec84f5e":"code","19181735":"code","e89b2221":"code","66fd467e":"code","9df5cb49":"code","d3d62c31":"code","229275f8":"code","2e3ab6e5":"code","ddf4d6f4":"code","d4bed059":"code","344f8fc2":"code","837f5e10":"code","88f7e588":"code","e7b5e9a0":"code","cf61cc07":"code","2a3e4d8d":"code","9a9fadda":"code","d9d15a77":"code","95029c6e":"code","e3db3168":"code","d1835727":"code","ab99136b":"code","2f2d224d":"code","cf3d2db5":"code","a75db8f1":"code","ed407210":"code","d130860d":"code","efac1cdd":"code","f6097a34":"code","f935bf62":"code","c1a11b0a":"code","c3af21e3":"code","862b8d16":"code","34e9b433":"code","503f556e":"code","a7987da8":"code","233b6286":"code","9ea62563":"code","a9cc6023":"code","e462d68b":"code","25596dc0":"code","3210d78c":"code","341f27cf":"code","7dd4b1d5":"code","09ba04c4":"code","3d6ed42d":"code","59d8f1de":"code","358bad05":"code","f2cb1df1":"code","eebb405e":"code","92df2f1f":"code","977c4086":"code","1a3abe99":"code","4c6cf226":"code","3bd97ef5":"code","478c66f1":"code","be84e245":"code","ef8cee76":"code","61dbc3c2":"code","90643623":"code","fcd0cae2":"code","aa35059d":"code","27b055ca":"code","95eebe95":"code","2b6d6cd9":"code","17101c24":"code","c31024d5":"code","5d0c5961":"code","3cabccc4":"code","63befc11":"markdown","880b4f8a":"markdown","dc4b5e5f":"markdown","57f51718":"markdown","54e8d113":"markdown","09917654":"markdown","356ff6bd":"markdown","35570cc2":"markdown","3c426a53":"markdown","ccfe7d4b":"markdown","4015f27d":"markdown","dda53d15":"markdown","0f9dbb0e":"markdown","f84a231d":"markdown","52a0c35a":"markdown","138c06b9":"markdown","56a55d01":"markdown","f1303725":"markdown","1acc6ad3":"markdown","7fe88dee":"markdown","a7eeedd1":"markdown","4d4db1ca":"markdown","d43d7b14":"markdown","4457c13a":"markdown","3374948a":"markdown","7073647d":"markdown","345431c7":"markdown","bfff32e3":"markdown","902e443a":"markdown","750df669":"markdown","708e57cb":"markdown","bfa598e5":"markdown","35d59e60":"markdown","c9a23fdd":"markdown","d33f0149":"markdown","7a332a4c":"markdown","6921e565":"markdown","6db73e32":"markdown","7e5eea2a":"markdown","d4d601b3":"markdown","f6f7fc9d":"markdown","c5d269ae":"markdown","28810af6":"markdown","39435d20":"markdown","e55ba15d":"markdown","a7fbca7e":"markdown","e81cbb1c":"markdown","e20a1a5c":"markdown"},"source":{"02b878b2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nplt.style.use(\"seaborn-whitegrid\") #Use seaborn-whitegrid style in matplotlib library\nimport seaborn as sns\n\nfrom collections import Counter\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","54aff3b6":"train_dataset = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_dataset = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_passengerid = test_dataset['PassengerId']","55c5a1a1":"train_dataset.head()","2368a0bf":"train_dataset.describe()","c0c86a45":"train_dataset.info()","669033d5":"def bar_plot(variable):\n    \"\"\"\n    input: variable ex: 'Sex'\n    output: bar plot % value count\n    \"\"\"\n    #get feature\n    var = train_dataset[variable]\n    #count number of categorical variable(value\/sample)\n    varValue = var.value_counts() \n    \n    #visulaize\n    plt.figure(figsize=(9,3))\n    plt.bar(varValue.index,varValue)\n    plt.xticks(varValue.index, varValue.index.values)\n    plt.ylabel(\"Frequency\")\n    plt.title(variable)\n    plt.show()\n    print(\"{}:\\n {}\".format(variable,varValue))","2c1e3e10":"category1 = [\"Survived\",\"Sex\",\"Pclass\",\"Embarked\",\"SibSp\",\"Parch\"]\nfor c in category1:\n    bar_plot(c)","5ec84f5e":"category2 = ['Cabin', \"Name\",\"Ticket\"]\nfor c in category2:\n    print(\"{}\\n\".format(train_dataset[c].value_counts()))","19181735":"def plot_hist(variable):\n    plt.figure(figsize = (9,3))\n    plt.hist(train_dataset[variable],bins=50)\n    plt.xlabel(variable)\n    plt.ylabel('Frequency')\n    plt.title(\"{} distribution with histogram\".format(variable))\n    plt.show()","e89b2221":"numericVar = [\"Fare\",\"Age\",\"PassengerId\"]\n\nfor n in numericVar:\n    plot_hist(n)","66fd467e":"### Pclass & Survived\n\ntrain_dataset[['Pclass','Survived']].groupby(['Pclass'],as_index=False).mean().sort_values(by='Survived',ascending=False)","9df5cb49":"### Sex & Survived\n\ntrain_dataset[['Sex','Survived']].groupby(['Sex'],as_index=False).mean().sort_values(by='Survived',ascending=False)","d3d62c31":"### SibSp & Survived\n\ntrain_dataset[['SibSp','Survived']].groupby(['SibSp'],as_index=False).mean().sort_values(by='Survived',ascending=False)","229275f8":"### Parch  & Survived\n\ntrain_dataset[['Parch','Survived']].groupby(['Parch'],as_index=False).mean().sort_values(by='Survived',ascending=False)","2e3ab6e5":"def detect_outlier(df,features):\n    outlier_indices = []\n    \n    \n    for c in features:\n        #1st quartile\n        q1 = np.percentile(df[c],25)\n        \n        #3rd quartile\n        q3 = np.percentile(df[c],75)\n        \n        #IQR\n        iqr = q3-q1\n        \n        #Quartile step\n        outlier_step = iqr * 1.5\n        \n        #detect outlier and their indeces\n        outlier_list_col = df[(df[c] < q1 - outlier_step) | (df[c] > q3 + outlier_step)].index\n        \n        #store indeces\n        outlier_indices.extend(outlier_list_col)\n    \n    outlier_indices = Counter(outlier_indices)\n    multiple_outliers = list(i for i, v in outlier_indices.items() if v > 2)\n    \n    return multiple_outliers ","ddf4d6f4":"#Outliers\n\ntrain_dataset.loc[detect_outlier(train_dataset,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])]","d4bed059":"#Drop Outliers +index reset\n\ntrain_dataset = train_dataset.drop(detect_outlier(train_dataset,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"]), axis = 0).reset_index(drop = True)","344f8fc2":"### Concate Train & Test dataset\ntrain_dataset_len = len(train_dataset)\ntrain_dataset = pd.concat([train_dataset,test_dataset],axis=0).reset_index(drop= True)","837f5e10":"train_dataset.head()","88f7e588":"#columns that include missing values\ntrain_dataset.columns[train_dataset.isnull().any()]","e7b5e9a0":"train_dataset.isnull().sum()","cf61cc07":"train_dataset[train_dataset[\"Embarked\"].isnull()]","2a3e4d8d":"train_dataset.boxplot(column=\"Fare\",by=\"Embarked\")\nplt.show()","9a9fadda":"train_dataset[\"Embarked\"] = train_dataset[\"Embarked\"].fillna(\"C\")","d9d15a77":"train_dataset[train_dataset[\"Fare\"].isnull()]\n#We use Pclass for fill to Fare","95029c6e":"train_dataset[\"Fare\"] =  train_dataset[\"Fare\"].fillna(np.mean(train_dataset[train_dataset[\"Pclass\"]==3][\"Fare\"]))","e3db3168":"list1 = [\"SibSp\",\"Parch\",\"Age\",\"Fare\",\"Survived\"]\nsns.heatmap(train_dataset[list1].corr(), annot= True, fmt = \".2f\");","d1835727":"g = sns.factorplot(x=\"SibSp\", y=\"Survived\", data=train_dataset, kind=\"bar\",size=6)\ng.set_ylabels(\"Survived Probabilty\")\nplt.show()","ab99136b":"g = sns.factorplot(x=\"Parch\", y=\"Survived\", data=train_dataset, kind=\"bar\",size=6)\ng.set_ylabels(\"Survived Probabilty\")\nplt.show()","2f2d224d":"g = sns.factorplot(x=\"Pclass\", y=\"Survived\", data=train_dataset, kind=\"bar\",size=6)\ng.set_ylabels(\"Survived Probabilty\")\nplt.show()","cf3d2db5":"g = sns.FacetGrid(train_dataset,col=\"Survived\")\ng.map(sns.distplot, \"Age\", bins=25)\nplt.show()","a75db8f1":"g = sns.FacetGrid(train_dataset, col=\"Survived\",row=\"Pclass\",size=3)\ng.map(plt.hist, \"Age\",bins=25)\ng.add_legend()\nplt.show()","ed407210":"g = sns.FacetGrid(train_dataset,row=\"Embarked\",size=3)\ng.map(sns.pointplot, \"Pclass\",\"Survived\",\"Sex\")\ng.add_legend()\nplt.show()","d130860d":"g = sns.FacetGrid(train_dataset,row=\"Embarked\",col=\"Survived\",size=2.5)\ng.map(sns.barplot,\"Sex\",\"Fare\")\ng.add_legend()\nplt.show()","efac1cdd":"train_dataset[train_dataset[\"Age\"].isnull()]","f6097a34":"sns.factorplot(x=\"Sex\", y=\"Age\",data=train_dataset,kind=\"box\")\nplt.show()","f935bf62":"sns.factorplot(x=\"Sex\", y=\"Age\",hue = \"Pclass\",data=train_dataset,kind=\"box\")\nplt.show()","c1a11b0a":"sns.factorplot(x=\"Parch\", y=\"Age\",data=train_dataset,kind=\"box\")\nsns.factorplot(x=\"SibSp\", y=\"Age\",data=train_dataset,kind=\"box\")\n\nplt.show()","c3af21e3":"train_dataset[\"Sex\"] = [ 1 if i == \"male\" else 0 for i in train_dataset[\"Sex\"]]","862b8d16":"sns.heatmap(train_dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(), annot = True)\nplt.show()","34e9b433":"index_nan_age = list(train_dataset[\"Age\"][train_dataset[\"Age\"].isnull()].index) \n\nfor i in index_nan_age:\n    age_pred = train_dataset[\"Age\"][((train_dataset[\"SibSp\"]== train_dataset.iloc[i][\"SibSp\"]) &\n                                   (train_dataset[\"Parch\"]== train_dataset.iloc[i][\"Parch\"]) & \n                                   (train_dataset[\"Pclass\"]== train_dataset.iloc[i][\"Pclass\"]))].median()\n    age_median = train_dataset[\"Age\"].median()\n    if not np.isnan(age_pred):\n        train_dataset[\"Age\"].iloc[i] = age_pred\n    else:\n        train_dataset[\"Age\"].iloc[i] = age_median","503f556e":"train_dataset[train_dataset[\"Age\"].isnull()]","a7987da8":"name = train_dataset[\"Name\"]\ntrain_dataset[\"Title\"] = [i.split(\".\")[0].split(\",\")[-1].strip() for i in name]","233b6286":"sns.countplot(x=\"Title\", data=train_dataset)\nplt.xticks(rotation=60)\nplt.show()","9ea62563":"#Convert to categorical Title Features \n\ntrain_dataset[\"Title\"] = train_dataset[\"Title\"].replace([\"Lady\",\"the Countess\",\"Capt\",\"Col\",\"Don\",\"Dr\",\"Major\",\"Rev\",\n                                                        \"Sir\",\"Jonkheer\",\"Dona\"],\"other\")\ntrain_dataset[\"Title\"] = [0 if i == \"Master\" else 1 if i == \"Miss\" or i == \"Ms\" or i == \"Mlle\" or i == \"Mrs\" else 2 if i == \"Mr\" else 3 for i in train_dataset[\"Title\"]]","a9cc6023":"sns.countplot(x=\"Title\", data=train_dataset)\nplt.xticks(rotation=60)\nplt.show()","e462d68b":"g = sns.factorplot(x =\"Title\", y=\"Survived\",data =train_dataset,kind = \"bar\")\ng.set_xticklabels([\"Master\",\"Mrs\",\"Mr\",\"Other\"])\ng.set_ylabels('Survival Probablity')\nplt.show()","25596dc0":"train_dataset.drop(labels=[\"Name\"],axis=1, inplace=True)","3210d78c":"train_dataset.head()","341f27cf":"train_dataset = pd.get_dummies(train_dataset,columns=[\"Title\"])\ntrain_dataset.head()","7dd4b1d5":"train_dataset[\"Fsize\"] = train_dataset[\"SibSp\"] + train_dataset[\"Parch\"] + 1 ","09ba04c4":"g = sns.factorplot(x = \"Fsize\", y = \"Survived\", data = train_dataset, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","3d6ed42d":"train_dataset[\"family_size\"] = [1 if i < 5 else 0 for i in train_dataset[\"Fsize\"]]","59d8f1de":"sns.countplot(x = \"family_size\", data=train_dataset)\nplt.show()","358bad05":"g = sns.factorplot(x = \"family_size\", y = \"Survived\", data = train_dataset, kind = \"bar\")\ng.set_ylabels(\"Survival\")\nplt.show()","f2cb1df1":"train_dataset = pd.get_dummies(train_dataset, columns = [\"family_size\"])\ntrain_dataset.head()","eebb405e":"sns.countplot(x = \"Embarked\", data=train_dataset)\nplt.show()","92df2f1f":"train_dataset = pd.get_dummies(train_dataset, columns=[\"Embarked\"])\ntrain_dataset.head()","977c4086":"train_dataset[\"Ticket\"].head()","1a3abe99":"a = \"A\/5 21171\"\na.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")","4c6cf226":"tickets = []\nfor i in list(train_dataset.Ticket):\n    if not i.isdigit():\n        tickets.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(\" \")[0])\n    else:\n        tickets.append(\"x\")\ntrain_dataset[\"Ticket\"] = tickets","3bd97ef5":"train_dataset[\"Ticket\"].head()","478c66f1":"train_dataset = pd.get_dummies(train_dataset, columns = [\"Ticket\"], prefix= \"T\")\ntrain_dataset.head()","be84e245":"sns.countplot(x=\"Pclass\",data=train_dataset)\nplt.show()","ef8cee76":"train_dataset[\"Pclass\"] = train_dataset[\"Pclass\"].astype(\"category\")\ntrain_dataset = pd.get_dummies(train_dataset, columns = [\"Pclass\"])\ntrain_dataset.head()","61dbc3c2":"train_dataset[\"Sex\"] = train_dataset[\"Sex\"].astype(\"category\")\ntrain_dataset = pd.get_dummies(train_dataset, columns = [\"Sex\"])\ntrain_dataset.head()","90643623":"train_dataset.drop(labels=[\"PassengerId\",\"Cabin\"],axis=1,inplace=True)","fcd0cae2":"from sklearn.model_selection import train_test_split, StratifiedKFold, GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import accuracy_score","aa35059d":"test = train_dataset[train_dataset_len:]\ntest.drop(labels=[\"Survived\"],axis=1,inplace=True)","27b055ca":"train = train_dataset[:train_dataset_len]\nx_train = train.drop(labels=\"Survived\",axis = 1)\ny_train = train[\"Survived\"] \nx_train, x_test, y_train, y_test = train_test_split(x_train,y_train,test_size=0.33,random_state=42)\nprint(\"X_Train\",len(x_train))\nprint(\"X_Test\",len(x_test))\nprint(\"y_Train\",len(y_train))\nprint(\"Y_Test\",len(y_test))\nprint(\"Test\",len(test))","95eebe95":"logreg = LogisticRegression()\nlogreg.fit(x_train,y_train)\nacc_log_train = round(logreg.score(x_train,y_train)*100,2) \nacc_log_test = round(logreg.score(x_test,y_test)*100,2)\nprint(\"Training Accuracy: % {}\".format(acc_log_train))\nprint(\"Test Accuracy: % {}\".format(acc_log_test))","2b6d6cd9":"random_state = 42\nclassifier = [DecisionTreeClassifier(random_state=random_state),SVC(random_state=random_state),\n             RandomForestClassifier(random_state=random_state),LogisticRegression(random_state=random_state),\n             KNeighborsClassifier()]\n\ndt_param_grid = {\"min_samples_split\" : range(10,500,20),\n                \"max_depth\": range(1,20,2)}\n\nsvc_param_grid = {\"kernel\" : [\"rbf\"],\n                 \"gamma\": [0.001, 0.01, 0.1, 1],\n                 \"C\": [1,10,50,100,200,300,1000]}\n\nrf_param_grid = {\"max_features\": [1,3,10],\n                \"min_samples_split\":[2,3,10],\n                \"min_samples_leaf\":[1,3,10],\n                \"bootstrap\":[False],\n                \"n_estimators\":[100,300],\n                \"criterion\":[\"gini\"]}\n\nlogreg_param_grid = {\"C\":np.logspace(-3,3,7),\n                    \"penalty\": [\"l1\",\"l2\"]}\n\nknn_param_grid = {\"n_neighbors\": np.linspace(1,19,10, dtype = int).tolist(),\n                 \"weights\": [\"uniform\",\"distance\"],\n                 \"metric\":[\"euclidean\",\"manhattan\"]}\nclassifier_param = [dt_param_grid,\n                   svc_param_grid,\n                   rf_param_grid,\n                   logreg_param_grid,\n                   knn_param_grid]","17101c24":"cv_result = []\nbest_estimators = []\nfor i in range(len(classifier)):\n    clf = GridSearchCV(classifier[i], param_grid=classifier_param[i], cv = StratifiedKFold(n_splits = 10), scoring = \"accuracy\", n_jobs = -1,verbose = 1)\n    clf.fit(x_train,y_train)\n    cv_result.append(clf.best_score_)\n    best_estimators.append(clf.best_estimator_)\n    print(cv_result[i])","c31024d5":"cv_results = pd.DataFrame({\"Cross Validation Means\":cv_result, \"ML Models\":[\"DecisionTreeClassifier\", \"SVM\",\"RandomForestClassifier\",\n             \"LogisticRegression\",\n             \"KNeighborsClassifier\"]})\n\ng = sns.barplot(\"Cross Validation Means\", \"ML Models\", data = cv_results)\ng.set_xlabel(\"Mean Accuracy\")\ng.set_title(\"Cross Validation Scores\")","5d0c5961":"votingC = VotingClassifier(estimators = [(\"dt\",best_estimators[0]),\n                                        (\"rfc\",best_estimators[2]),\n                                        (\"lr\",best_estimators[3])],\n                                        voting = \"soft\", n_jobs = -1)\nvotingC = votingC.fit(x_train, y_train)\nprint(accuracy_score(votingC.predict(x_test),y_test))","3cabccc4":"test_survived = pd.Series(votingC.predict(test), name = \"Survived\").astype(int)\nresults = pd.concat([test_passengerid, test_survived],axis = 1)\nresults.to_csv(\"titanic.csv\", index = False)","63befc11":"<a id =\"9\"><\/a><br>\n### Find Missing Value","880b4f8a":"<a id =\"11\"><\/a><br>\n## Visualization","dc4b5e5f":"* 1st class passengers are older than 2nd, and 2nd is older than 3rd class.","57f51718":"<a id =\"22\"><\/a><br>\n### Name -- Title","54e8d113":"<a id =\"12\"><\/a><br>\n### Correlation Matris- Sibsp -- Parch -- Age -- Fare -- Survived","09917654":"<a id =\"29\"><\/a><br>\n# Modeling","356ff6bd":"* Having a lot of SibSp have less chance to survive.\n* If SibSp == 0 or 1 or 2, passenger has more chance to survive.\n* We can consider a new feature describing these categories. ","35570cc2":"<a id =\"20\"><\/a><br>\n\n## Fill Missing Value: Age Feature","3c426a53":"<a id =\"25\"><\/a><br>\n### Ticket","ccfe7d4b":"* Female passengers have much better survival rate than males.\n* Males have better survival rate in Pclass 3 in \"C\" \n* Embarked and sex will be used in training.","4015f27d":"<a id =\"8\"><\/a><br>\n## Missing Value\n* Find Missing Value\n* Fill Missing Value","dda53d15":"* Fare feature seems to have correlation with survived feature. (0.26)","0f9dbb0e":"<a id =\"21\"><\/a><br>\n## Feature Engineering\n","f84a231d":"* Age is not correlated with sex but it is correleted with parch, sibsp and pclass. ","52a0c35a":"<a id =\"10\"><\/a><br>\n### Fill Missing Value\n* Embarked has two missing value.\n* Fare has one missing value.","138c06b9":"<a id =\"18\"><\/a><br>\n\n### Embarked -- Sex -- Pclass -- Survived","56a55d01":"<a id =\"5\"><\/a><br>\n\n### Numerical Variable","f1303725":"* Age <= 10 has a high survival rate.\n* Oldest passenger generally survived.\n* Large number of 20 years old did not survive.\n* Most passenger s are in 15-35 age range. \n* Use age feater in training.","1acc6ad3":"<a id =\"19\"><\/a><br>\n### Embarked -- Sex -- Fare -- Survived","7fe88dee":"* SibSp and Parch can be used for new feature extraction with treshold = 3\n* Small familes generally have more chance to survive. \n* There is a standart deviation  in survival of passenger with parch = 3","a7eeedd1":"* Passengers who pay higher fare have better survival.\n* Fare can bu used as categorical for training.","4d4db1ca":"* Sex is not informative for age prediction because age distribution seems to be same.","d43d7b14":"<a id =\"15\"><\/a><br>\n### Pclass -- Survived","4457c13a":"<a id =\"14\"><\/a><br>\n### Parch -- Survived\n","3374948a":"<a id =\"34\"><\/a><br>\n## Prediction and Submission","7073647d":"<a id =\"3\"><\/a><br>\n## Univariate Variable Analysis\n* Categorical Variable: Survived, sex, pclass, embarked, cabin, name, ticket, sibsp and parch\n* Numerical Variable: age, fare, and passengerId","345431c7":"<a id =\"31\"><\/a><br>\n## Simple Logistic Regression","bfff32e3":"* float64(2): Fare & Age\n* int64(5) : Pclass, sibsp, parch, passengerId and survived\n* object(5): Cabin, embarked, name, sex and ticket","902e443a":"<a id =\"2\"><\/a><br>\n## Variable Description \n\n1. PassengerId: Uniqe id number to each passenger \n2. Survived: Passenger survive(1) or died(0)\n3. Pclass: Passenger class\n4. Name: Passenger name\n5. Sex: gender of passenger\n6. Age: age of passenger\n7. SibSp: number of siblings \/ spouses\n8. Parch: number of parents \/ children\n9. Ticket: Ticket number\n10. Fare: Amount of money spent on ticket\n11. Cabin: Cabin category\n12. Embarked: Port of embarkation (C = Cherbourg, Q = Queenstown, S = Southampton)\n","750df669":"<a id =\"13\"><\/a><br>\n\n### SibSp -- Survived","708e57cb":"<a id =\"27\"><\/a><br>\n### Sex","bfa598e5":"<a id =\"28\"><\/a><br>\n### Drop Passinger ID & Cabin","35d59e60":"<a id =\"33\"><\/a><br>\n### Ensemble Modeling","c9a23fdd":"<a id =\"30\"><\/a><br>\n## Train -- Test Split","d33f0149":"<a id =\"4\"><\/a><br>\n\n### Categorical Variable","7a332a4c":"<a id =\"17\"><\/a><br>\n\n### Pclass -- Survived -- Age","6921e565":"* We will use models that have %80 and higher accuracy. (DT, RF, LR)","6db73e32":"<a id =\"23\"><\/a><br>\n### Embarked","7e5eea2a":"* Small families have more chance to survive than large families.","d4d601b3":"<a id =\"32\"><\/a><br>\n### Hyperparameter Tuning -- Grid Search -- Cross Validation\n\n* Comparing 5 ML classifier\n* Evaluating  mean accuracy of each of 5 ML models.\n* Stratifying cross validation \n    * ML Models\n        * Decesion Tree\n        * SVM\n        * Random Forest\n        * KNN\n        * Logistic Regression","f6f7fc9d":"<a id =\"6\"><\/a><br>\n## Basic Data Analysis\n\n* We will examine the relation between two variables.\n\n* Pclass - Survived\n* Sex - Survived\n* SibSp - Survived\n* Parch - Survived","c5d269ae":"* Pclass is important feature for model training.","28810af6":"<a id =\"1\"><\/a><br>\n## Load and Review Dataset","39435d20":"<a id =\"26\"><\/a><br>\n### Pclass","e55ba15d":"<a id =\"24\"><\/a><br>\n### Family Size","a7fbca7e":"<a id =\"16\"><\/a><br>\n## Age -- Survived","e81cbb1c":"<a id =\"7\"><\/a><br>\n## Outlier Detecetion","e20a1a5c":"# Introduction \n\nThe RMS Titanic sank in the early morning hours of 15 April 1912 in the North Atlantic Ocean, four days into her maiden voyage from Southampton to New York City. The largest ocean liner in service at the time, Titanic had an estimated 2,224 people on board when she struck an iceberg at around 23:40 (ship's time) on Sunday, 14 April 1912. Her sinking two hours and forty minutes later at 02:20 on Monday, 15 April, resulted in the deaths of more than 1,500 people, making it one of the deadliest peacetime maritime disasters in history. (Wikipedia)\n\n![image.png](attachment:a0c95528-68fd-4071-a370-70d986d90573.png)<br>\nSource:(Wikipedia)\n\n<font color ='blue'>\n\n## Content:\n\n1. [Load and Review Dataset](#1)\n2. [Variable Description](#2)\n    * [Univariate Variable Analysis](#3)\n        * [Categorical Variable](#4)\n        * [Numerical Variable](#5)\n3. [Basic Data Analysis](#6)\n4. [Outlier Detection](#7)\n5. [Missing Value](#8)\n    * [Find Missing Value](#9)\n    * [Fill Missing Value](#10)\n6. [Visualization](#11)\n    * [Correlation Matris- Sibsp -- Parch -- Age -- Fare -- Survived](#12)\n    * [SibSp -- Survived](#13)\n    * [Parch -- Survived](#14)\n    * [Pclass -- Survived](#15)\n    * [Age -- Survived](#16)\n    * [Pclass -- Survived -- Age](#17)\n    * [Embarked -- Sex -- Pclass -- Survived](#18)\n    * [Embarked -- Sex -- Fare -- Survived](#19)\n    * [Fill Missing Value: Age Feature](#20)\n7. [Feature Engineering](#21)\n    * [Name -- Title](#22)\n    * [Family Size](#23)\n    * [Embarked](#24)\n    * [Ticket](#25)\n    * [Pclass](#26)\n    * [Sex](#27)\n    * [Drop Passenger ID & Cabin](#28)\n8. [Modeling](#29)\n    * [Train -- Test Split](#30)\n    * [Simple Logistic Regression](#31)\n    * [Hyperparameter Tuning -- Grid Search -- Cross Validation](#32)\n    * [Ensemble Modeling](#33)\n    * [Prediction and Submission](#34)"}}