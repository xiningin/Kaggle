{"cell_type":{"6961a26c":"code","ce0c352a":"code","698724ca":"code","12b2c257":"code","dab82188":"code","906ef433":"code","0d41e535":"code","6657ddc0":"code","c60040eb":"code","d44c5d74":"code","0ee45ac7":"code","26e50e4a":"code","c8b672ce":"code","b802eb2b":"markdown","2f9fcea2":"markdown","bec55310":"markdown","a7604c50":"markdown","203c4ece":"markdown","92fd6446":"markdown","20d936fd":"markdown","4573a4d4":"markdown"},"source":{"6961a26c":"import numpy as np\nimport pandas as pd\nimport pandas_profiling as pp\nimport math\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# preprocessing\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nimport sklearn\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, GridSearchCV, StratifiedKFold, learning_curve, ShuffleSplit\nfrom sklearn.model_selection import cross_val_predict as cvp\nfrom sklearn import metrics, pipeline\nfrom sklearn.metrics import r2_score, mean_absolute_error, mean_squared_error, accuracy_score\n\n\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectFromModel\nfrom time import time\n# models\nfrom sklearn.linear_model import LogisticRegression, LogisticRegression, Perceptron, RidgeClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.svm import SVC, LinearSVC, SVR\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, ExtraTreesClassifier \nfrom sklearn.ensemble import BaggingClassifier, AdaBoostClassifier, VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn import metrics\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ce0c352a":"iris=pd.read_csv('\/kaggle\/input\/iris\/Iris.csv')\niris.head()","698724ca":"pp.ProfileReport(iris)","12b2c257":"iris['Species'].value_counts().plot.pie(explode=[0.1,0.1,0.1],autopct='%1.1f%%',shadow=True,figsize=(10,8))\nplt.show()","dab82188":"fig=plt.gcf()\nfig.set_size_inches(10,7)\nfig=sns.boxplot(x='Species',y='PetalLengthCm',data=iris,order=['Iris-virginica','Iris-versicolor','Iris-setosa'],linewidth=2.5,orient='v',dodge=False)","906ef433":"fig=plt.gcf()\nfig.set_size_inches(10,7)\nfig=sns.violinplot(x='Species',y='SepalLengthCm',data=iris)","0d41e535":"plt.figure(figsize=(15,10))\nplt.subplot(2,2,1)\nsns.violinplot(x='Species',y='PetalLengthCm',data=iris)\nplt.subplot(2,2,2)\nsns.violinplot(x='Species',y='PetalWidthCm',data=iris)\nplt.subplot(2,2,3)\nsns.violinplot(x='Species',y='SepalLengthCm',data=iris)\nplt.subplot(2,2,4)\nsns.violinplot(x='Species',y='SepalWidthCm',data=iris)","6657ddc0":"iris.plot.area(y=['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm'],alpha=0.4,figsize=(12, 6));","c60040eb":"def acc_summary(pipeline, X_train, y_train, X_val, y_val):\n    t0 = time()\n    sentiment_fit = pipeline.fit(X_train, y_train)\n    y_pred = sentiment_fit.predict(X_val)\n    train_test_time = time() - t0\n    accuracy = accuracy_score(y_val, y_pred)*100\n    print(\"accuracy : {0:.2f}%\".format(accuracy))\n    print(\"train and test time: {0:.2f}s\".format(train_test_time))\n    print(\"-\"*80)\n    return accuracy, train_test_time","d44c5d74":"names = [ \n        'Logistic Regression',\n        'Perceptron',\n        'Ridge Classifier',\n        'SGD Classifier',\n        'SVC',\n        'Gradient Boosting Classifier', \n        'Extra Trees Classifier', \n        \"Bagging Classifier\",\n        \"AdaBoost Classifier\", \n        \"K Nearest Neighbour Classifier\",\n         \"Decison Tree Classifier\",\n         \"Random Forest Classifier\",\n         'GaussianNB',\n        \"Gaussian Process Classifier\",\n        \"MLP Classifier\",\n        \"XGB Classifier\",\n        \"LGBM Classifier\"\n         ]\nclassifiers = [\n    LogisticRegression(),\n    Perceptron(),\n    RidgeClassifier(),\n    SGDClassifier(),\n    SVC(),\n    GradientBoostingClassifier(),\n    ExtraTreesClassifier(), \n    BaggingClassifier(),\n    AdaBoostClassifier(),\n    KNeighborsClassifier(),\n    DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    GaussianNB(),\n    GaussianProcessClassifier(),\n    MLPClassifier(),\n    XGBClassifier(),\n    LGBMClassifier()\n        ]\n\nzipped_clf = zip(names,classifiers)","0ee45ac7":"def classifier_comparator(X_train,y_train,X_val,y_val,classifier=zipped_clf): \n    result = []\n    for n,c in classifier:\n        checker_pipeline = Pipeline([\n            ('classifier', c)\n        ])\n        print(\"Validation result for {}\".format(n))\n        #print(c)\n        clf_acc,tt_time = acc_summary(checker_pipeline,X_train, y_train, X_val, y_val)\n        result.append((n,clf_acc,tt_time))\n    return result","26e50e4a":"X_train,X_val,y_train,y_val=train_test_split(iris.iloc[:,:-1],iris.iloc[:,-1],test_size=0.1,random_state=2)","c8b672ce":"classifier_comparator(X_train,y_train,X_val,y_val)","b802eb2b":"# Splitting The Data.","2f9fcea2":"# Importing The Libraries.","bec55310":"## Pandas Profiling EDA","a7604c50":"Since the Dataset was pretty small,most models could give a perfect accuracy.But this template might be really useful in other competetions and predictions.","203c4ece":"# Lets Do some manual EDA.","92fd6446":"# Creating a Function To Compare accuracies.","20d936fd":"# Loading The Dataset.","4573a4d4":"# Thankyou For Reading ..."}}