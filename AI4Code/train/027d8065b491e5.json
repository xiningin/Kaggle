{"cell_type":{"edfd352c":"code","8075ec30":"code","7cc93704":"code","58a7131a":"code","3812896d":"code","728c06c2":"code","0d0808cc":"code","fc1cc605":"code","15176a05":"code","6e9da7cc":"code","b69313e0":"code","70ebe2a5":"code","3be1d3f8":"code","a72247b1":"code","58e91578":"code","29235197":"code","59f8223c":"code","a4dbdc2c":"code","83f40e41":"code","e310e9fe":"code","9c9662aa":"code","77a94edc":"code","12605085":"code","74ef3a69":"code","8497129c":"code","9c8cc619":"code","3c6cf0a8":"code","b1728cb6":"code","8145dabb":"code","fe21b973":"code","e4019385":"code","7ab82ca4":"code","467b7d46":"code","d4d038d8":"code","bf34dbfa":"code","3da1e7d2":"code","f6f7ecc7":"code","d6ee7c49":"code","a698487b":"code","96a6fc11":"code","7fbb048a":"code","ed1d0474":"code","c324fee3":"code","e5e01556":"code","fe6bea3b":"code","a4eaf7b4":"code","183890ba":"code","5029f55c":"code","f1f1c957":"code","4f9b8a24":"code","21c0ae50":"code","be8c0963":"markdown","730be97f":"markdown","99499eb9":"markdown","c7ec49ae":"markdown","9469a06d":"markdown","6e4dd0cf":"markdown","1b2e667c":"markdown","aa4f265f":"markdown","3aaf05ac":"markdown","b7ffe580":"markdown","8f00a8ba":"markdown","9cc36e50":"markdown","e5bb2f65":"markdown","5bf2fe46":"markdown","3373fe01":"markdown","35360b45":"markdown","411e81da":"markdown","fc060a50":"markdown","59b89d4e":"markdown","85a6d289":"markdown","93f24619":"markdown","53c51615":"markdown","44ac2833":"markdown","0b463125":"markdown","3212843e":"markdown"},"source":{"edfd352c":"import pandas as pd\n# Import data\ndata = data = pd.read_csv('\/kaggle\/input\/insurance\/insurance.csv')\ndata.shape","8075ec30":"data.head()","7cc93704":"# Check each features datatype and null status \ndata.info()","58a7131a":"# Describe all numerical data (age, bmi, children, charges)\ndata.describe()","3812896d":"import matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action=\"ignore\", category=FutureWarning)","728c06c2":"# Check Gender Feature \n\nsns.countplot(data['sex'])\n\nplt.title('Person by Gender', fontsize='16', fontweight='bold')\nplt.xlabel('Gender', fontsize='14')\nplt.ylabel('Total Persons', fontsize='14')\nplt.show()\n\n## Decision: Male are slightly more than female","0d0808cc":"# Check region feature \n\nsns.countplot(data['region'])\n\nplt.title('Person by Region', fontsize='16', fontweight='bold')\nplt.xlabel('Region Name', fontsize='14')\nplt.ylabel('Total Persons', fontsize='14')\nplt.show()\n\n## Decision: More peoples are lived in \"southeast\" region","fc1cc605":"# Check \"smoker\" feature \n\nsns.countplot(data['smoker'])\n\nplt.title('Person by Smoking Status', fontsize='16', fontweight='bold')\nplt.xlabel('Smoking Status', fontsize='14')\nplt.ylabel('Total Persons', fontsize='14')\nplt.show()\n\n## Decision: Lots of peoples are not smoker ","15176a05":"## Check \"Smoker\" feature \nsns.countplot(data['children'])\n\nplt.title('Person by Having Children', fontsize='16', fontweight='bold')\nplt.xlabel('Number of Children', fontsize='14')\nplt.ylabel('Total Persons', fontsize='14')\nplt.show()\n\n## Decision: Al most 50% of the peoples have not any children. ","6e9da7cc":"## Checking peoples age distribution\nsns.histplot(data['age'], color = 'orange')\n\nplt.title('Person Age Distributions', fontsize='16', fontweight='bold')\nplt.xlabel('Age', fontsize='14')\nplt.ylabel('Total Persons', fontsize='14')\n\nplt.show()\n\n## Almost 200 peoples age in between 1 to 20. And rest of them age around 30 to 35 ","b69313e0":"## Checking peoples \"BMIistribution\nsns.histplot(data['bmi'], color = 'blue')\n\nplt.title('Persons BMI Distributions', fontsize='16', fontweight='bold')\nplt.xlabel('BMI', fontsize='14')\nplt.ylabel('Total Persons', fontsize='14')\nplt.show()\n\n## Decision: Here small number of peoples are in normal BMI(18.5 ~ 24.9) \n## and most of the peoples are in overweight and Obese","70ebe2a5":"## Check peoples 'expense' distrivution\nsns.histplot(data['charges'], color = 'gray')\nplt.title('Distribution of Expense', fontsize='16', fontweight='bold')\nplt.xlabel('Expenses', fontsize='14')\nplt.ylabel('Total Persons', fontsize='14')\nplt.show()\n\n## Decision: Majority peoples health expenses are around 15k. ","3be1d3f8":"import plotly.express as px","a72247b1":"## Comparison of Age with expenses\npx.scatter(data,\n           x = 'age',\n           y = 'charges', \n          marginal_y = 'violin',\n          trendline='ols')\n\n## Decision: Trend line goes bottom to top. So, If peoples \"Age\" are increase then their health \"expenses\" will be increase. ","58e91578":"# # Comparison of Expense with BMI\npx.scatter(data, \n           y = \"charges\", \n           x = \"bmi\", trendline='ols'\n          )\n\n## Decision: Trend line goes bottom to top. So, If peoples \"BMI\" are increase then their health \"expenses\" will be increase. ","29235197":"sns.boxplot(x= data['smoker'], y = data['charges'])\nplt.show()\n\n## Decision: If someone do smoke his health expenses will be 2-3 times increase than a non-smoker. ","59f8223c":"# sns.boxplot(x= data['children'], y = data['charges'])\nsns.catplot(\"children\",\"charges\", data=data, kind=\"bar\")\nplt.show()\n\n## Decision: Thoese Who have 2-4 children made more expense than others ","a4dbdc2c":"px.scatter(data,\n          x='charges',\n          y='age',\n          facet_col = 'region',\n          facet_row = 'children', \n          color= 'smoker',\n          trendline='ols')","83f40e41":"px.scatter(data,\n          x='charges',\n          y='bmi',\n          facet_row = 'children', \n          facet_col = 'region', \n          color= 'smoker',\n          trendline='ols')","e310e9fe":"# # Relation between BMI, Age, Smoker with expenses. \n\npx.scatter(data,\n          x='charges',\n          y='bmi',\n         size='age',\n          color= 'smoker',\n          hover_name = 'charges',\n          size_max = 12)\n\n## Decision: Whatever the BMI is if person do not smoke then is medical cost is decent (aroind 15K). \n## But, If Smoker persons BMI increase then his cost increase dramatically high. ","9c9662aa":"## Relation between Gender, Regoin with expenses \npx.bar_polar(data, \n             r='charges',\n             theta='region', \n             color='sex',\n            template = 'plotly_dark')\n\n# # Females expenses are less then males expense. All of the regoins expeses are same \n## except \"southeast\" where males expenses are two times higher than females expenses. ","77a94edc":"data[['charges', 'region']].groupby(['region']).agg(['min', 'max', 'mean']).style.background_gradient(cmap='ocean')","12605085":"data.head(3)","74ef3a69":"# Check data types\ndata.dtypes\n\n# All object data type features (sex, smoker, region) are categorical feature. \n# We have to encode these feature with numerical data. ","8497129c":"# Encodeing sex. \n# Male are make more expenses than female. So, let, Male = 2 and Female = 1)\ndata.sex.unique()\ndata['sex'] = data['sex'].replace(('female', 'male'), (1, 2))","9c8cc619":"# Encoding 'smoker'\n# smoker = yes makes more expense, so let (yes = 2, no = 1)\ndata['smoker'] = data['smoker'].replace(('yes', 'no'), (2, 1))","3c6cf0a8":"\ndata.region.unique()\n# Southeast region makes highest expense so let region southeast = 2 and others are 1\ndata['region'] = data['region'].replace(('southeast', 'southwest', 'northwest', 'northeast'), (2, 1, 1, 1))","b1728cb6":"data.dtypes\n# Now all of the features have numerical data","8145dabb":"# Complete encoded data \ndata.head(3)","fe21b973":"# Dependent \ny = data['charges']","e4019385":"# Independent \nx = data.drop(['charges'], axis = 1)\nprint(x.shape)\nprint(x.columns)","7ab82ca4":"from sklearn.model_selection import train_test_split","467b7d46":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=.2, random_state=0)\n\nprint('Size of x_train = ', x_train.shape)\nprint('Size of x_test  = ', x_test.shape)\nprint('Size of y_train = ', y_train.shape)\nprint('Size of y_test  = ', y_test.shape)","d4d038d8":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()","bf34dbfa":"x_train = sc.fit_transform(x_train)\nx_test = sc.transform(x_test)","3da1e7d2":"from sklearn.linear_model import LinearRegression ","f6f7ecc7":"model = LinearRegression()\nmodel.fit(x_train, y_train)\n\ny_predict = model.predict(x_test)","d6ee7c49":"# checking model accuracy \nfrom sklearn.metrics import r2_score, mean_squared_error\nimport numpy as np \n\nlr_r2_score = r2_score(y_test, y_predict)\nprint('R square Score = ', round(lr_r2_score, 3))\n\nmse = mean_squared_error(y_test, y_predict)\nrmse = np.sqrt(mse)\nprint('Root Mean Squared Error = ', round(rmse, 3))","a698487b":"from sklearn.ensemble import RandomForestRegressor","96a6fc11":"rf_model = RandomForestRegressor()\nrf_model.fit(x_train, y_train)\n\ny_predict_rf = rf_model.predict(x_test)","7fbb048a":"# checking model accuracy \nfrom sklearn.metrics import r2_score, mean_squared_error\nimport numpy as np \nrf_r2_score = r2_score(y_test, y_predict_rf)\nprint('R square Score = ', round(rf_r2_score, 3))\n\nrf_mse = mean_squared_error(y_test, y_predict_rf)\nrf_rmse = np.sqrt(rf_mse)\nprint('Root Mean Squared Error = ', round(rf_rmse, 3))","ed1d0474":"from sklearn.ensemble import GradientBoostingRegressor","c324fee3":"gb_model = GradientBoostingRegressor(max_depth=2, n_estimators=100, learning_rate =.1)\ngb_model.fit(x_train, y_train)\n\ny_predict_gb = gb_model.predict(x_test)","e5e01556":"# checking model accuracy \nfrom sklearn.metrics import r2_score, mean_squared_error\nimport numpy as np \n\ngb_mse = mean_squared_error(y_test, y_predict_gb)\ngb_rmse = np.sqrt(gb_mse)\nprint('Root Mean Squared Error = ', round(gb_rmse, 3))\n\ngb_r2_score = r2_score(y_test, y_predict_gb)\nprint('R square Score = ', round(gb_r2_score, 3))","fe6bea3b":"# ## Comparison of actual and predicted results \n# df = pd.DataFrame({'Actual': y_test, 'Predicted': y_predict_gb})\n# df.to_csv('Data\/gradient_boosting_result.csv', index=False)\n# print('Your predicted data saved ')","a4eaf7b4":"# # Average three model (Linear Regression, RF and Gradient Boosting)\navg_model = (y_predict + y_predict_rf + y_predict_gb) \/3","183890ba":"# checking model accuracy \nfrom sklearn.metrics import r2_score, mean_squared_error\nimport numpy as np \n\nmse = mean_squared_error(y_test, avg_model)\nrmse = np.sqrt(mse)\nprint('Root Mean Squared Error = ', round(rmse, 3))\n\nr2_score = r2_score(y_test, avg_model)\nprint('R square Score = ', round(r2_score, 3))","5029f55c":"# So, GBM perform best out of three model. THen RF model and last Linear Regression model. \n# Now, create an average weigheted model where GBM is 50%, RF is 40% and LR is 10%. \n\nweighted_avg_model = ((.1 * y_predict) + (.4 * y_predict_rf) + (.5 * y_predict_gb))","f1f1c957":"# checking model accuracy \nfrom sklearn.metrics import r2_score, mean_squared_error\nimport numpy as np \n\nmse = mean_squared_error(y_test, weighted_avg_model)\nrmse = np.sqrt(mse)\nprint('Root Mean Squared Error = ', round(rmse, 3))\n\nr2_score = r2_score(y_test, weighted_avg_model)\nprint('R square Score = ', round(r2_score, 3))","4f9b8a24":"from sklearn.model_selection import cross_val_score \nscore = cross_val_score(gb_model, x, y, cv=5)\nprint(score)\n\n# If the cross validate scores are not fer dirrer from others then the model is pretty good. ","21c0ae50":"import numpy as np\nimport matplotlib.pyplot as plt\n\n\nr2_scores = [lr_r2_score*100, rf_r2_score*100, gb_r2_score*100]\nmodel_names = ['LR', 'RF', 'GBM']\n\ntotal_bar = np.arange(len(model_names))\ncolor = ['#9edd1d', '#3edd1d', '#f7c851']\n\nfig, ax = plt.subplots(figsize=(10, 3))\nbar = plt.bar(model_names, r2_scores, align='center', alpha=.75, color=color)\nplt.xticks(total_bar, model_names)\nplt.ylabel('Accuracy',fontsize=14, color='black')\nplt.xlabel('Model Name',fontsize=14, color='black')\nplt.title('Model (LR, RF, GB) Performance Comparison', fontsize=16, color='black', fontweight='bold')\n\n# # this functions will set data lebel \ndef autolabel(bar):\n    for bar in bar:\n        height = int(bar.get_height())\n        ax.text(bar.get_x() + .4, .5*height,\n                height, va='bottom',\n                fontsize=14, color='black')\n        \nautolabel(bar)\n\nplt.show()","be8c0963":"## Feature Scaling\nused to normalize the range of independent variable. ","730be97f":"To validate a linear model is approprieate or not you have to test flowing four assumption. \nAssumptions:\n1. Linearity: Relationship between dependent and independent variable must be linear. Which means trend of two variables must be increasing or decreasing. \n2. Homoscedasticity: In statistical terms, the variance of all the variabes msut be same. \n3. Independence: All the observations must be independent on each other. \n4. Normality: All the variables must flow a normal distribution.","99499eb9":"So, If this model will predict any result it will be between actual value with plus of minus 4282 For that, this model will gain around 88% accuracy. ","c7ec49ae":"# Gradient Boosting Regressor Model\n","9469a06d":"### R square (r2) Score: \nIt is generally used to determine how good is the model. ( Correlation between independent and dependent as target feature)","6e4dd0cf":"## Bivariate Analysis\nInvolves with two variables relationships between them ","1b2e667c":"# Applying Linear Regression Model\nFind the relationship between with dependent variable with one or more independent variables","aa4f265f":"So, If this model will predict any result it will be between actual value with plus of minus 5663. For that, this model will gain around 79% accuracy. ","3aaf05ac":"# Data Preparation for ML model\nAll categorical should be Numorical","b7ffe580":"So, If this model will predict any result it will be between actual value with plus of minus 4448 For that, this model will gain around 87% accuracy. ","8f00a8ba":"After that, accuracy is 89%. Also, In here again GBM is winner. ","9cc36e50":"# Random Forest ","e5bb2f65":"### Model Accuracy Comparison","5bf2fe46":"# ****Medical Cost Prediction****","3373fe01":" ## Dependent & Independent Feature \n Seperating dependent ( charges) feature with independent (rest of the feature) ","35360b45":"### Root Mean Squared Error(RMSE)\nIt is the squared root of the mean of the difference between actual and the predicted values. ","411e81da":"So, If this model will predict any result it will be between actual value with plus of minus 4063 For that, this model will gain around 89% accuracy. ","fc060a50":"### Distribution Analysis","59b89d4e":"# Ensembles of Model\nIt is a process where multiple diverse models are applied to obtain the better predictive performance. ","85a6d289":"#### We have 4 numerical feature ( age, bmi, children, charges) and 2 categorical feature (sex, region) and no null data ","93f24619":"## Univarient Analysis\nOnly one feature at a time","53c51615":"## Multivariate Analysis","44ac2833":"### Decision Lists Again \n1. If peoples age are increase then their medical expenses will increase dramatically. \n2. Males medical ecpenses are larger than females. \n3. majority peoples BMI are under or getter than normal BMI. So, they are in thin, overweight and Obese stage. Each stage peoples expenses are more than normal BMI peoples. \n4. Southeast reajon peopes are doing more expense than other regions. \n5. Thoese Who have 2-4 children made more expense than others. \n6. If a person is not smoker then your medical cost will normal. \n7. If Smoker persons BMI increase then his cost increase dramatically high.","0b463125":"# Cross Validation\nIt is a resampling procedure wich is used to evaluate the machine learning models on limited data samples. Its goal is to predict new data that is that is not tested before. It has a single parameter called K. ","3212843e":"## Spliting Train & Test Data "}}