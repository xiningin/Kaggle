{"cell_type":{"0930e789":"code","dd08b918":"code","673e0375":"code","457dc14c":"code","097fcec7":"code","be125722":"code","9060fa32":"code","80d7c358":"code","82354c73":"code","e3c852f7":"code","d4ec510d":"code","f1aadcc0":"code","1668d98f":"code","cee1263e":"code","2fa65f9b":"code","a576822e":"code","fac02c31":"code","4442dc8f":"code","71e91aeb":"code","af48d827":"code","a47b0a03":"code","913b7ec1":"code","1abd4f0c":"code","1e32e4ec":"code","151022c5":"code","dd6290c3":"code","a16e01f2":"code","f9ff4138":"code","01ee61df":"code","44f9a69f":"code","12df2ddb":"code","3af4c31a":"code","17c70945":"code","ebd088f3":"markdown","d7fde002":"markdown","727df86e":"markdown","3842fce3":"markdown","64f46539":"markdown","6cb873c1":"markdown","94466fcc":"markdown","75dc321d":"markdown","61378cfd":"markdown","fb3e9b60":"markdown","0f5ca1f2":"markdown"},"source":{"0930e789":"import numpy as np\nimport tensorflow as tf\nimport keras as k\nimport matplotlib.pyplot as plt","dd08b918":"def import_data(dataset = \"mnist\", fully_connected = True, show_info = True, noise = False):\n    \n    if(dataset == \"mnist\"):\n        (x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()\n    if(dataset == \"fashion\"):\n        from keras.datasets import fashion_mnist\n        (x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n        \n    \n        \n    #some data exploration\n    if(show_info == True):\n        print('***** Log import_data *****')\n        print('Train data shape', x_train.shape)\n        print('Test data shape', x_test.shape)\n        print('Number of training samples', x_train.shape[0])\n        print('Number of testing samples', x_test.shape[0])\n        \n        for i in range(25):\n            plt.subplot(5,5,i+1)    #Add a subplot as 5 x 5 \n            plt.xticks([])          #get rid of labels\n            plt.yticks([])          #get rid of labels\n            plt.imshow(x_test[i], cmap=\"gray\")\n        plt.show()\n        print('***** ***** *****  *****')\n    \n    #Para o caso em que sejam as MLP\n    if(fully_connected == True):\n        \n        #Check if it is a RGB scale image\n        if(len(x_train.shape) == 4):\n            x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]*x_train.shape[3]).astype('float32')\n            x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]*x_test.shape[3]).astype('float32')\n        #Gray Scale image\n        else:\n            #reshape the input to have a list of self.batch_size by 28*28 = 784; and normalize (\/255)\n            x_train = x_train.reshape(x_train.shape[0], x_train.shape[1]*x_train.shape[2]).astype('float32')\n            x_test = x_test.reshape(x_test.shape[0], x_test.shape[1]*x_test.shape[2]).astype('float32')\n            #reserve 5000 samples for validation\n    \n    else:\n        #Check if it is a gray scale image or a RGB scale image\n        #(images,dimensio,dimension,channels)\n        if(len(x_train.shape) == 3):\n            x_train = x_train.reshape(x_train.shape[0], x_train.shape[1],x_train.shape[2],1).astype('float32')\n            x_test = x_test.reshape(x_test.shape[0], x_test.shape[1],x_test.shape[2],1).astype('float32')\n    \n    #Normalization\n    x_train = x_train\/255\n    x_test = x_test\/255\n    \n    if( noise == True):\n        x_train = x_train + np.random.normal(loc=0.0, scale=0.5, size= x_train.shape)\n        x_train = np.clip(x_train, 0., 1.) #para podar os valores menores do que\n        x_test = x_test + np.random.normal(loc=0.0, scale=0.5, size= x_test.shape)\n        x_test = np.clip(x_test, 0., 1.)\n    \n    \n    return x_train, y_train, x_test, y_test","673e0375":"x_train, y_train, x_test, y_test = import_data(dataset = \"mnist\", fully_connected = True, show_info = True)","457dc14c":"def show_history(history):\n    print(history.history.keys())\n\n    plt.subplot(1, 2, 1)\n    # summarize history for accuracy\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')    \n        \n    plt.subplot(1, 2, 2)\n    # summarize history for loss\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()","097fcec7":"from keras.models import Model\nfrom keras import Input\nfrom keras.layers import Dense","be125722":"def create_AutoEncoder():\n    \n    input_image = Input(shape=(784,))\n    \n    encoded = Dense(32, activation = 'relu')(input_image)\n    \n    decoded = Dense(784,activation = 'sigmoid')(encoded)\n    \n    encoder = Model(inputs = input_image, outputs = encoded)\n    \n    auto_encoder = Model(inputs = input_image, outputs = decoded)\n    \n    return auto_encoder, encoder\n\n(auto_encoder, encoder) = create_AutoEncoder()\n\nprint(\"\\n############### ENCODER #################\")\nencoder.summary()\nprint(\"\\n############### ENCODER + DECODER #################\")\nauto_encoder.summary()","9060fa32":"!pip install livelossplot\nfrom livelossplot import PlotLossesKeras\n\n(auto_encoder, encoder) = create_AutoEncoder()\nauto_encoder.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\nhistory = auto_encoder.fit(x_train, x_train, epochs = 50, shuffle = True, batch_size = 200, validation_split = 0.2, callbacks = [PlotLossesKeras()])","80d7c358":"def visualize_predictions(encoder,autoencoder,X_test):\n    \n    encoded_images = encoder.predict(X_test)\n    predicted_images = autoencoder.predict(X_test)\n    \n    # Original Images\n    print(\"Original Images - first 10 images of X_test\")\n    plt.figure(figsize=(30, 1))\n    for i in range(10):\n        ax = plt.subplot(1, 20, i + 1)\n        plt.imshow(X_test[i].reshape(28, 28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n    \n    # display Encoded Images (latent space)\n    print(\"Encoded Images - first 10 images of X_test\")\n    plt.figure(figsize=(30, 1))\n    for i in range(10):\n        ax = plt.subplot(1, 20, i + 1)\n        plt.imshow(encoded_images[i].reshape(8,4))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n        \n    # display Decoded Images\n    print(\"Decoded Images - first 10 images of X_test\")\n    plt.figure(figsize=(30, 1))\n    for i in range(10):\n        ax = plt.subplot(1, 20, i+ 1)\n        plt.imshow(predicted_images[i].reshape(28, 28))\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n        \nvisualize_predictions(encoder,auto_encoder,x_test)","82354c73":"def create_AutoEncoder():\n    \n    input_image = Input(shape=(784,))\n    \n    encoded = Dense(128, activation = 'relu')(input_image)\n    \n    encoded = Dense(64, activation = 'relu')(encoded)\n    \n    encoded = Dense(32, activation = 'relu')(encoded)\n    \n    decoded = Dense(64,activation = 'relu')(encoded)\n    \n    decoded = Dense(128,activation = 'relu')(decoded)\n    \n    decoded = Dense(784,activation = 'sigmoid')(decoded)\n    \n    encoder = Model(inputs = input_image, outputs = encoded)\n    \n    auto_encoder = Model(inputs = input_image, outputs = decoded)\n    \n    return auto_encoder, encoder\n\n(auto_encoder, encoder) = create_AutoEncoder()\n\nprint(\"\\n############### ENCODER #################\")\nencoder.summary()\nprint(\"\\n############### ENCODER + DECODER #################\")\nauto_encoder.summary()","e3c852f7":"from livelossplot import PlotLossesKeras\n\n(auto_encoder, encoder) = create_AutoEncoder()\nauto_encoder.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\nhistory = auto_encoder.fit(x_train, x_train, epochs = 50, shuffle = True, batch_size = 200, validation_split = 0.2, callbacks = [PlotLossesKeras()])","d4ec510d":"visualize_predictions(encoder,auto_encoder,x_test)","f1aadcc0":"x_train, y_train, x_test, y_test = import_data(dataset = \"mnist\", fully_connected = True, show_info = False, noise = True)","1668d98f":"from livelossplot import PlotLossesKeras\n\n(auto_encoder, encoder) = create_AutoEncoder()\nauto_encoder.compile(optimizer=\"adam\", loss = \"binary_crossentropy\", metrics = [\"accuracy\"])\nhistory = auto_encoder.fit(x_train, x_train, epochs = 50, shuffle = True, batch_size = 200, validation_split = 0.2, callbacks = [PlotLossesKeras()])","cee1263e":"visualize_predictions(encoder,auto_encoder,x_test)","2fa65f9b":"x_train, y_train, x_test, y_test = import_data(dataset = \"mnist\", fully_connected = False, show_info = False, noise = False)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","a576822e":"from keras.layers import Conv2D, Reshape, Flatten, Conv2DTranspose","fac02c31":"def create_encoder():\n    input_image= Input(shape=(28, 28, 1)) #imagens do MNIST\n    encoded1 = Conv2D(32, 3, padding='same', activation='relu')(input_image)\n    encoded2 = Conv2D(64, 3, padding='same', activation='relu', strides=(2, 2))(encoded1)\n    encoded3 = Conv2D(64, 3, padding='same', activation='relu')(encoded2)\n    encoded4 = Conv2D(64, 3, padding='same', activation='relu')(encoded3)\n    encoded5 = Flatten()(encoded4)\n    encoded6 = Dense(32, activation='relu')(encoded5)\n    t_mean = Dense(2)(encoded6) #o 2 refere-se a\u0300 dimensa\u0303o do latent space\n    t_log_var = Dense(2)(encoded6)\n    #ver documentac\u0327a\u0303o do keras:\n    #Output of the created model are the sufficient statistics\n    #of the variational distriution q(t|x;phi), mean and log variance.\n    encoder = Model(inputs=input_image, outputs=[t_mean, t_log_var], name='encoder')\n    return encoder\n                                                                                \n\ndef create_decoder():\n    decoder_input = Input(shape=(2,)) #o 2 refere-se a\u0300 dimensa\u0303o do latent space (samplin\n    decoded1 = Dense(12544, activation='relu')(decoder_input) #12544 = 14*14*64\n    decoded2 = Reshape((14, 14, 64))(decoded1)\n    decoded3 = Conv2DTranspose(32, 3, padding='same', activation='relu', strides=(2, 2))(decoded2)\n    decoded4 = Conv2D(1, 3, padding='same', activation='sigmoid')(decoded3)\n    #Outputs sa\u0303o imagens com shape (28, 28, 1) onde o valor de cada pixel corresponde a\u0300\n    decoder = Model(inputs=decoder_input, outputs=decoded4, name='decoder')\n    return decoder          \n                                                                                \nencoder = create_encoder()\ndecoder = create_decoder()\nprint(\"\\n############### ENCODER #################\")\nencoder.summary()\nprint(\"\\n############### DECODER #################\")\ndecoder.summary()","4442dc8f":"#co\u0301digo baseado no exemplo da documentac\u0327a\u0303o do keras\nfrom keras.backend import sqrt, exp, random_normal, shape\n\ndef sample(args):\n    '''\n    Draws samples from a standard normal and scales the samples with\n    standard deviation of the variational distribution and shifts them by the mean.\n    Args: sufficient statistics of the variational distribution.\n    Returns: Samples from the variational distribution.\n    '''\n    \n    t_mean, t_log_var = args\n    t_sigma = sqrt(exp(t_log_var))\n    epsilon = random_normal(shape= shape(t_mean), mean=0., stddev=1.)\n    return t_mean + t_sigma * epsilon\n    ","71e91aeb":"#Lambda layers in Keras help you to implement layers or functionality that is not prebuid\n#and which do not require trainable weights.\n\nfrom keras.layers import Lambda\n\ndef create_sampler(): #Creates a sampling layer.\n    return Lambda(sample, name='sampler') #Lambda refer-se ao layer.Lambda\n\nsampler = create_sampler()\n    \ndef create_vae():\n    input_image = Input(shape=(28, 28, 1))\n    t_mean, t_log_var = encoder(input_image) # mean and variance\n    t = sampler([t_mean, t_log_var]) #novo layer para fazer o sampling\n    t_decoded = decoder(t)\n    vae = Model(inputs = input_image, outputs = t_decoded, name='vae')\n    \n    return vae, t_mean, t_log_var\n\nvae,t_mean, t_log_var = create_vae()\nprint(\"\\n############### VARIATIONAL AUTOENCODER #################\")\nvae.summary()\n","af48d827":"from keras.backend import sum,binary_crossentropy,batch_flatten, mean,square\n\n#ver documentac\u0327a\u0303o do keras (variational autoencoders)\ndef neg_variational_lower_bound(input_image, t_decoded):\n    '''\n    Negative variational lower bound used as loss function\n    for training the variational auto-encoder.\n    Args:  input_image: input images\n    t_decoded: reconstructed images\n    '''\n    # Reconstruction loss\n    rc_loss = sum(binary_crossentropy(batch_flatten(input_image), batch_flatten(t_decoded)))\n    \n    # Regularization term (KL divergence)\n    kl_loss = -0.5 * sum(1 + t_log_var - square(t_mean) - exp(t_log_var), axis=-1)\n    \n    # Average over mini-batch\n    return mean(rc_loss + kl_loss)","a47b0a03":"vae,t_mean, t_log_var = create_vae()\nvae.compile(optimizer=\"adam\", loss = neg_variational_lower_bound, metrics = [\"accuracy\"])\nhistory = vae.fit(x_train, x_train, epochs = 50, shuffle = True, batch_size = 500, validation_data = (x_test,x_test), callbacks = [PlotLossesKeras()])","913b7ec1":"def plot_t_test(t_test,y_test):\n    # grafico do latent vector t_test colorido pelos valores dos digitos nas imagens de\n    plt.figure(figsize=(8, 6))\n    plt.scatter(t_test[:, 0], t_test[:, 1], marker='x', s=6.0, c=y_test,  cmap='brg')\n    plt.colorbar();\n    plt.show()","1abd4f0c":"def plot2_t_test(t_test,y_test):\n    plt.figure(figsize=(8, 6))\n    plt.scatter(t_test[:, 0], t_test[:, 1],s=0.2, c=y_test, cmap='brg')\n    plt.colorbar();\n    #plt.set_xticks(())\n    #plt.set_yticks(())\n    count=0;\n    plt.tight_layout()\n    plt.suptitle(\"Isomap para digitos do MNIST\")\n    for label , x, y in zip(y_test, t_test[:, 0], t_test[:, 1]):\n        #anotar na imagem cada 1 em 300 amostras\n        if count % 350 == 0:\n            plt.annotate(str(int(label)),xy=(x,y), color='black', weight='normal',size=10)\n            count = count + 1\n            #plt.savefig(\"mnist_pca.png\")\n            plt.show()","1e32e4ec":"#vae = load_model('model_vae_v1.h5') #na\u0303o funciona pois o layers de sampling na\u0303o e\u0301 do k\n#vae.load_weights('best_weights.hdf5')\n\n# Generar os latent vectors dos test set\nprint(\"X_test:\",x_test.shape)\ntt_test = encoder.predict(x_test, batch_size=100)#[0]\nt_mean_test=tt_test[0]\nt_log_var_test=tt_test[1]\nprint(\"t_mean_test:\",t_mean_test.shape)\nprint(\"t_log_var_test:\",t_log_var_test.shape)\nplot_t_test(t_mean_test,y_test)\nplot_t_test(t_log_var_test,y_test)\n#plot2_t_test(t_mean_test,y_test)\n\n","151022c5":"from scipy.stats import norm\n\ndef generate_images():\n    # Numero de amostras por dimensa\u0303o\n    n = 15\n    batch_size=100\n    # Construir uma matriz de valores para as latent variable\n    # Amostras com intervalo de confianc\u0327a de 90% da distribuic\u0327a\u0303o Gaussiana\n    # com densidade de amostragem proporcional a\u0300 densidade probabilistica\n    grid_x = norm.ppf(np.linspace(0.05, 0.95, n)) #lista com n=15 elementos\n    grid_y = norm.ppf(np.linspace(0.05, 0.95, n)) #lista com n=15 elementos\n    print(\"   grid_x     --      grid_y\")\n    for i in range(len(grid_x)):\n        print(\" %f  --    %f\"%(grid_x[i],grid_y[i]))\n    \n    digit_size = 28\n    figure = np.zeros((digit_size * n, digit_size * n)) #matriz para n=15*28 por n=15*28\n    # fazer o decode para cada elemento da grelha\n    \n    for i, yi in enumerate(grid_x): #vai dar tuplos (0,-1.64485363e+00) (1,...)...\n        for j, xi in enumerate(grid_y): #vai dar tuplos (0,-1.64485363e+00) (1,...)...\n            t_amostra = np.array([[xi, yi]])\n            t_amostra = np.tile(t_amostra, batch_size).reshape(batch_size, 2)\n            t_decoded = decoder.predict(t_amostra, batch_size=100)\n            digit = t_decoded[0].reshape(digit_size, digit_size)\n            figure[i*digit_size:(i+1)*digit_size , j*digit_size:(j+1)*digit_size] = digit\n    plt.figure(figsize=(10, 10))\n    plt.imshow(figure, cmap='Greys_r');","dd6290c3":"generate_images()","a16e01f2":"def generate_digit(x,y):\n    \n    digit_size = 28\n    figure = np.zeros((digit_size, digit_size)) #matriz para n=15*28 por n=15*28\n    amostra=np.array([[x, y]])\n    t_decoded = decoder.predict(amostra)\n    digit = t_decoded[0].reshape(digit_size, digit_size)\n    plt.figure(figsize=(5, 5))\n    plt.imshow(digit, cmap='Greys_r');","f9ff4138":"generate_digit(10,0)","01ee61df":"x_train, y_train, x_test, y_test = import_data(dataset = \"fashion\", fully_connected = False, show_info = True, noise = False)\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)\nprint(y_test.shape)","44f9a69f":"vae,t_mean, t_log_var = create_vae()\nvae.compile(optimizer=\"adam\", loss = neg_variational_lower_bound, metrics = [\"accuracy\"])\nhistory = vae.fit(x_train, x_train, epochs = 50, shuffle = True, batch_size = 500, validation_data = (x_test,x_test), callbacks = [PlotLossesKeras()])","12df2ddb":"#vae = load_model('model_vae_v1.h5') #na\u0303o funciona pois o layers de sampling na\u0303o e\u0301 do k\n#vae.load_weights('best_weights.hdf5')\n\n# Generar os latent vectors dos test set\nprint(\"X_test:\",x_test.shape)\ntt_test = encoder.predict(x_test, batch_size=100)#[0]\nt_mean_test=tt_test[0]\nt_log_var_test=tt_test[1]\n\nprint(\"t_mean_test:\",t_mean_test.shape)\nprint(\"t_log_var_test:\",t_log_var_test.shape)\nplot_t_test(t_mean_test,y_test)\nplot_t_test(t_log_var_test,y_test)\n#plot2_t_test(t_mean_test,y_test)","3af4c31a":"generate_images()","17c70945":"generate_digit(4,3)","ebd088f3":"### Second, a deeper MLP AutoEncoder for Mnist Dataset\n\n> Architecture :  Image(784 pixeis) -> Dense(128) -> Dense(64) -> Dense(32) -> Dense(64) -> Dense(128) -> Dense(784 pixeis)","d7fde002":"# Lets see the Variational Auto Encoder in the Mnist Fashion","727df86e":"## Third, the same MLP AutoEncoder for Mnist Dataset, but now we add some noise to the images\n\nArchitecture : Image(784 pixeis) -> Dense(128) -> Dense(64) -> Dense(32) -> Dense(64) -> Dense(128) -> Dense(784 pixeis)","3842fce3":"### The beauty in this algorithm, is that an AutoEncoder can detect the noise in this images because when we use a network to classify an image, the images have a noise and a pattern, the auto-encoder finds the pattern in is latent space, our Dense(32), and because of that, the decoder part of the auto-encoder can generalize the image without noise.","64f46539":"> Function to import the dataset\n\n    1. fully_connected if we use an MLP, otherwise it's for a CNN\n    2. show_info to check the dataset\n    3. noise = False, if you want to add noise to the input, noise = True","6cb873c1":"## As we can expect, the accuracy will go down, since the images have some noise now","94466fcc":"> Function to plot the accuracy and loss of model","75dc321d":"## Importing all the packages needed","61378cfd":"# Variational autoencoder with encoder\/decoder Conv2D\n\n## Convolutional Architecture:\n> Encoder: Conv2D(32 filters) -> Conv2D(64) -> Conv2D(64) -> Conv2D(64) -> Flatten() -> Dense(32) -> Latent Space\n\n> Latent Space is composed by tow Denses with 2 neurons representing the mean and the variance\n\n> Decoder: Latent Space -> Dense(12544) -> Reshape -> Conv2DTranspose(32) -> Con2D(1)\n\n> The last Conv2D have 1 filter to represent the image (28,28,1) \n\n> Check the summary of the model","fb3e9b60":"> Como podemos observar pelo gr\u00e1fico, a accuuracy n\u00e3o varia nada em compara\u00e7\u00e3o com o outro modelo, ou seja, este modelo apesar de ser mais complexo (\"deep\") n\u00e3o \u00e9 o modelo adequado para este tipo de problema.","0f5ca1f2":"### First, a simple AutoEncoder for Mnist Dataset\n\n> Architecture :  Image(784 pixeis) -> Dense(32) -> Dense(784)"}}