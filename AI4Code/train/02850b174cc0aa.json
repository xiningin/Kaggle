{"cell_type":{"effb54e3":"code","6d4b83d5":"code","58999870":"code","5fc1f3a8":"code","76896b90":"code","19f34c57":"code","a09280e4":"code","09d8e7c5":"code","a48293ff":"code","ea5fd6ef":"code","b9178797":"code","6e8e4000":"code","e5e40b2f":"code","e191c9dd":"code","04e82191":"code","d24d77c0":"code","16a9ab47":"code","cad9d8e2":"code","2a485b3a":"code","be7b9b7d":"code","ca8f47ff":"code","5015e825":"code","5e74b815":"code","0c402d65":"code","67bacce0":"code","c0e4d7e7":"code","a194c339":"code","a4b2299d":"code","7b42e879":"code","12d2502b":"code","08306fcb":"code","0d14ca78":"code","99ead110":"code","6b933a57":"code","bc70d2a9":"code","1a4399e6":"code","f6c7f621":"code","72e3bdc0":"code","79d443e4":"code","4e1a8a10":"code","9080ee4a":"code","39babb7e":"code","6b087057":"code","3fe924d3":"markdown","caff3cd1":"markdown","fedc8914":"markdown","b501f421":"markdown","373425e0":"markdown","add7d174":"markdown","d9cd5d22":"markdown","2956b4ef":"markdown","2e5df506":"markdown","1d18f8d9":"markdown","e716d67b":"markdown","d47dbc08":"markdown","6a94e42f":"markdown","d651cb25":"markdown","9029f9a5":"markdown","71cce8a5":"markdown","d783b063":"markdown","bad39d2d":"markdown","c7731512":"markdown"},"source":{"effb54e3":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport math\n\n# List all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6d4b83d5":"grouped = 100","58999870":"# Healthy gearbox\n# ---------------\nh30hz0  = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz0.csv\")\nh30hz10 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz10.csv\")\nh30hz20 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz20.csv\")\nh30hz30 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz30.csv\")\nh30hz40 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz40.csv\")\nh30hz50 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz50.csv\")\nh30hz60 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz60.csv\")\nh30hz70 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz70.csv\")\nh30hz80 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz80.csv\")\nh30hz90 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/Healthy\/h30hz90.csv\")\n","5fc1f3a8":"# Broken gearbox\n# --------------\nb30hz0  = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz0.csv\")\nb30hz10 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz10.csv\")\nb30hz20 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz20.csv\")\nb30hz30 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz30.csv\")\nb30hz40 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz40.csv\")\nb30hz50 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz50.csv\")\nb30hz60 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz60.csv\")\nb30hz70 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz70.csv\")\nb30hz80 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz80.csv\")\nb30hz90 = pd.read_csv(\"..\/input\/gearbox-fault-diagnosis\/BrokenTooth\/b30hz90.csv\")","76896b90":"b30hz50","19f34c57":"# This function computes the standard deviation for a sample, where:\n##  - df:        the dataset, one variable per column\n##  - grouped:   the number of consecutive points (rows) in the time series to compute the standard deviation\n##  - outcome:   column added to the dataset representing healthy(=1) or failure (=0)\n##  RETURNS a dataset (df_result) where each column is the time serie of every variable\n\ndef stdev_features(df, grouped, load, outcome):\n    #### Create empty dataframe with columns a1,a2,a3,a4\n    df_result = pd.DataFrame( [ np.zeros(len(df.columns)-2) ],columns= df.columns[:-2])\n\n    #### Aggregate in groups of nrows computing the standard deviation\n    # Remove load & failure columns, keeping only a1,a2,a3,a4\n    stdev_lenght=len(df.columns)-2\n    \n    #### Compute number of rows of the aggregated dataframe\n    nrows_raw = len(df.index)\n    nrows = math.floor(nrows_raw \/ grouped)\n    nrows_dropped = nrows_raw - nrows*grouped\n    print(\"nrows_raw=\", nrows_raw, \"   nrows=\", nrows, \"   Number of dropped rows of grouped= \", nrows_dropped\/grouped*100,\"%\\n\")\n    \n    # Iterate every 'grouped' rows and compute stdev per column\n    for i in range(nrows):\n      df_group = df.iloc[i*grouped:i*grouped+grouped,:]\n      df_stdev = pd.DataFrame(df_group.std()).transpose()\n      # Remove load & failure columns\n      df_stdev=df_stdev.iloc[:,:stdev_lenght]\n      # Add row of calculated stdev\n      df_result = df_result.append(df_stdev, ignore_index=True)\n\n      #print (\"i*grouped TO i*grouped+grouped\", i*grouped, i*grouped+grouped)\n      #print (\"row, df_stdev=\\n\", row, df_stdev.iloc[:,:])\n      #print (\"df_result=\\n\", df_result)\n      #print(\"row\", i, \"\\n\", df_group)\n\n\n    # Remove the first row (it was the seed of zeros for initializing df_result)\n    #print(df_result)\n    df_result = df_result.iloc[1:,:]\n    # Add the column for 'load'\n    df_result['load'] = load*np.ones((nrows,1))\n\n    # Add the column for 'failure'\n    failure = np.ones((nrows,1))\n    df_result['failure'] = outcome\n    print(df_result)\n    \n    return df_result\n    ","a09280e4":"b30hz0.describe()","09d8e7c5":"# [H.0] DATASET BROKEN, 0% LOAD\nload = 0\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz0['load'] = load*np.ones((len(b30hz0.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz0.index),1))\nb30hz0['failure'] = failureArray\n#b30hz0.describe()\n\nb30hz0_stdev= stdev_features (df = b30hz0, grouped= grouped, load= load, outcome= failure)\n#b30hz0_stdev.describe()","a48293ff":"# [H.0] DATASET HEALTHY, 0% LOAD\nload = 0\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz0['load'] = load*np.ones((len(h30hz0.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz0.index),1))\nh30hz0['failure'] = failureArray\n\nh30hz0_stdev= stdev_features (df = h30hz0, grouped= grouped, load= load, outcome= failure)\n#b30hz0_stdev.describe()","ea5fd6ef":"b30hz10.describe()","b9178797":"# [H.1] DATASET BROKEN, 10% LOAD\nload = 10\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz10['load'] = load*np.ones((len(b30hz10.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz10.index),1))\nb30hz10['failure'] = failureArray\n#b30hz10.describe()\n\nb30hz10_stdev= stdev_features (df = b30hz10, grouped= grouped, load= load, outcome= failure)\n#b30hz10_stdev.describe()","6e8e4000":"h30hz10.describe()","e5e40b2f":"# [H.1] DATASET HEALTHY, 10% LOAD\nload = 10\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz10['load'] = load*np.ones((len(h30hz10.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz10.index),1))\nh30hz10['failure'] = failureArray\n\nh30hz10_stdev= stdev_features (df = h30hz10, grouped= grouped, load= load, outcome= failure)\n#b30hz10_stdev.describe()","e191c9dd":"# [H.2] DATASET BROKEN, 20% LOAD\nload = 20\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz20['load'] = load*np.ones((len(b30hz20.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz20.index),1))\nb30hz20['failure'] = failureArray\n#b30hz20.describe()\n\nb30hz20_stdev= stdev_features (df = b30hz20, grouped= grouped, load= load, outcome= failure)\n#b30hz20_stdev.describe()","04e82191":"# [H.2] DATASET HEALTHY, 20% LOAD\nload = 20\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz20['load'] = load*np.ones((len(h30hz20.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz20.index),1))\nh30hz20['failure'] = failureArray\n\nh30hz20_stdev= stdev_features (df = h30hz20, grouped= grouped, load= load, outcome= failure)\n#b30hz20_stdev.describe()","d24d77c0":"# [H.3] DATASET BROKEN, 30% LOAD\nload = 30\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz30['load'] = load*np.ones((len(b30hz30.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz30.index),1))\nb30hz30['failure'] = failureArray\n#b30hz30.describe()\n\nb30hz30_stdev= stdev_features (df = b30hz30, grouped= grouped, load= load, outcome= failure)\n#b30hz30_stdev.describe()","16a9ab47":"# [H.3] DATASET HEALTHY, 30% LOAD\nload = 30\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz30['load'] = load*np.ones((len(h30hz30.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz30.index),1))\nh30hz30['failure'] = failureArray\n\nh30hz30_stdev= stdev_features (df = h30hz30, grouped= grouped, load= load, outcome= failure)\n#b30hz30_stdev.describe()","cad9d8e2":"# [H.4] DATASET BROKEN, 40% LOAD\nload = 40\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz40['load'] = load*np.ones((len(b30hz40.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz40.index),1))\nb30hz40['failure'] = failureArray\n#b30hz40.describe()\n\nb30hz40_stdev= stdev_features (df = b30hz40, grouped= grouped, load= load, outcome= failure)\n#b30hz40_stdev.describe()","2a485b3a":"# [H.4] DATASET HEALTHY, 40% LOAD\nload = 40\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz40['load'] = load*np.ones((len(h30hz40.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz40.index),1))\nh30hz40['failure'] = failureArray\n\nh30hz40_stdev= stdev_features (df = h30hz40, grouped= grouped, load= load, outcome= failure)\n#b30hz40_stdev.describe()","be7b9b7d":"# [H.5] DATASET BROKEN, 50% LOAD\nload = 50\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz50['load'] = load*np.ones((len(b30hz50.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz50.index),1))\nb30hz50['failure'] = failureArray\n#b30hz50.describe()\n\nb30hz50_stdev= stdev_features (df = b30hz50, grouped= grouped, load= load, outcome= failure)\n#b30hz50_stdev.describe()","ca8f47ff":"# [H.5] DATASET HEALTHY, 50% LOAD\nload = 50\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz50['load'] = load*np.ones((len(h30hz50.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz50.index),1))\nh30hz50['failure'] = failureArray\n\nh30hz50_stdev= stdev_features (df = h30hz50, grouped= grouped, load= load, outcome= failure)\n#b30hz50_stdev.describe()","5015e825":"# [H.6] DATASET BROKEN, 60% LOAD\nload = 60\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz60['load'] = load*np.ones((len(b30hz60.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz60.index),1))\nb30hz60['failure'] = failureArray\n#b30hz60.describe()\n\nb30hz60_stdev= stdev_features (df = b30hz60, grouped= grouped, load= load, outcome= failure)\n#b30hz60_stdev.describe()","5e74b815":"# [H.6] DATASET HEALTHY, 60% LOAD\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz60['load'] = load*np.ones((len(h30hz60.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz60.index),1))\nh30hz60['failure'] = failureArray\n\nh30hz60_stdev= stdev_features (df = h30hz60, grouped= grouped, load= load, outcome= failure)\n#b30hz60_stdev.describe()","0c402d65":"# [H.7] DATASET BROKEN, 70% LOAD\nload = 70\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz70['load'] = load*np.ones((len(b30hz70.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz70.index),1))\nb30hz70['failure'] = failureArray\n#b30hz70.describe()\n\nb30hz70_stdev= stdev_features (df = b30hz70, grouped= grouped, load= load, outcome= failure)\n#b30hz70_stdev.describe()","67bacce0":"# [H.7] DATASET HEALTHY, 70% LOAD\nload = 70\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz70['load'] = load*np.ones((len(h30hz70.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz70.index),1))\nh30hz70['failure'] = failureArray\n\nh30hz70_stdev= stdev_features (df = h30hz70, grouped= grouped, load= load, outcome= failure)\n#b30hz70_stdev.describe()","c0e4d7e7":"# [H.8] DATASET BROKEN, 80% LOAD\nload = 80\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz80['load'] = load*np.ones((len(b30hz80.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz80.index),1))\nb30hz80['failure'] = failureArray\n#b30hz80.describe()\n\nb30hz80_stdev= stdev_features (df = b30hz80, grouped= grouped, load= load, outcome= failure)\n#b30hz80_stdev.describe()","a194c339":"# [H.8] DATASET HEALTHY, 80% LOAD\nload = 80\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz80['load'] = load*np.ones((len(h30hz80.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz80.index),1))\nh30hz80['failure'] = failureArray\n\nh30hz80_stdev= stdev_features (df = h30hz80, grouped= grouped, load= load, outcome= failure)\n#b30hz80_stdev.describe()","a4b2299d":"# [H.9] DATASET BROKEN, 90% LOAD\nload = 90\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nb30hz90['load'] = load*np.ones((len(b30hz90.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\n##   0 is healthy\n##   1 is broken\nfailure = 1\nfailureArray = np.ones((len(b30hz90.index),1))\nb30hz90['failure'] = failureArray\n#b30hz90.describe()\n\nb30hz90_stdev= stdev_features (df = b30hz90, grouped= grouped, load= load, outcome= failure)\n#b30hz90_stdev.describe()","7b42e879":"# [H.9] DATASET HEALTHY, 90% LOAD\nload = 90\n\n# CREATE THE COLUMN FOR 'load'\n## Expressed as %\nh30hz90['load'] = load*np.ones((len(h30hz90.index),1))\n\n# CREATE THE COLUMN FOR 'failure'\nfailure = 0\nfailureArray = np.ones((len(h30hz90.index),1))\nh30hz90['failure'] = failureArray\n\nh30hz90_stdev= stdev_features (df = h30hz90, grouped= grouped, load= load, outcome= failure)\n#b30hz90_stdev.describe()","12d2502b":"print(\"Load 0%\")\nprint(\"-------\")\nstdev_bhz0 = pd.DataFrame(b30hz0_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz0 = pd.DataFrame(h30hz0_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz0)\nprint(\"Healthy:\\n\", stdev_hhz0)","08306fcb":"print(\"Load 10%\")\nprint(\"--------\")\nstdev_bhz10 = pd.DataFrame(b30hz10_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz10 = pd.DataFrame(h30hz10_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz10)\nprint(\"Healthy:\\n\", stdev_hhz10)","0d14ca78":"print(\"Load 20%\")\nprint(\"--------\")\nstdev_bhz20 = pd.DataFrame(b30hz20_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz20 = pd.DataFrame(h30hz20_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz20)\nprint(\"Healthy:\\n\", stdev_hhz20)","99ead110":"print(\"Load 30%\")\nprint(\"--------\")\nstdev_bhz30 = pd.DataFrame(b30hz30_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz30 = pd.DataFrame(h30hz30_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz30)\nprint(\"Healthy:\\n\", stdev_hhz30)","6b933a57":"print(\"Load 40%\")\nprint(\"--------\")\nstdev_bhz40 = pd.DataFrame(b30hz40_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz40 = pd.DataFrame(h30hz40_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz40)\nprint(\"Healthy:\\n\", stdev_hhz40)","bc70d2a9":"print(\"Load 50%\")\nprint(\"--------\")\nstdev_bhz50 = pd.DataFrame(b30hz50_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz50 = pd.DataFrame(h30hz50_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz50)\nprint(\"Healthy:\\n\", stdev_hhz50)","1a4399e6":"print(\"Load 60%\")\nprint(\"--------\")\nstdev_bhz60 = pd.DataFrame(b30hz60_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz60 = pd.DataFrame(h30hz60_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz60)\nprint(\"Healthy:\\n\", stdev_hhz60)","f6c7f621":"print(\"Load 70%\")\nprint(\"--------\")\nstdev_bhz70 = pd.DataFrame(b30hz70_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz70 = pd.DataFrame(h30hz70_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz70)\nprint(\"Healthy:\\n\", stdev_hhz70)","72e3bdc0":"print(\"Load 80%\")\nprint(\"--------\")\nstdev_bhz80 = pd.DataFrame(b30hz80_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz80 = pd.DataFrame(h30hz80_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz80)\nprint(\"Healthy:\\n\", stdev_hhz80)","79d443e4":"print(\"Load 90%\")\nprint(\"--------\")\nstdev_bhz90 = pd.DataFrame(b30hz90_stdev.iloc[:,:-2].mean()).transpose()\nstdev_hhz90 = pd.DataFrame(h30hz90_stdev.iloc[:,:-2].mean()).transpose()\nprint(\"Broken:\\n\", stdev_bhz90)\nprint(\"Healthy:\\n\", stdev_hhz90)","4e1a8a10":"b30hz_stdev = pd.concat([b30hz0_stdev, b30hz10_stdev, b30hz20_stdev, b30hz30_stdev,b30hz40_stdev,b30hz50_stdev,b30hz60_stdev,b30hz70_stdev,b30hz80_stdev,b30hz90_stdev], axis=0)\nb30hz_stdev.describe()","9080ee4a":"b30hz_stdev.to_csv('\/kaggle\/working\/b30hz_stdev.csv', index = False)","39babb7e":"h30hz_stdev = pd.concat([h30hz0_stdev, h30hz10_stdev, h30hz20_stdev, h30hz30_stdev,h30hz40_stdev,h30hz50_stdev,h30hz60_stdev,h30hz70_stdev,h30hz80_stdev,h30hz90_stdev], axis=0)\nh30hz_stdev.describe()","6b087057":"h30hz_stdev.to_csv('\/kaggle\/working\/h30hz_stdev.csv', index = False)","3fe924d3":"## Load= 20%","caff3cd1":"## Load= 30%","fedc8914":"## Load= 10%","b501f421":"### INPUT Number of rows for aggregated dataset","373425e0":"# Read datasets\n## Healthy gearbox","add7d174":"## Load= 60%","d9cd5d22":"## Export HEALTHY dataframe as CSV","2956b4ef":"# Stacked HEALTHY dataframe","2e5df506":"# Compute aggregated datasets\n## Function to compute aggregated features: standard deviation","1d18f8d9":"# Stacked BROKEN dataframe","e716d67b":"## Load= 80%","d47dbc08":"## Export BROKEN dataframe as CSV","6a94e42f":"# Broken gearbox","d651cb25":"## Load= 90%","9029f9a5":"# Compare stdev of acceleration traversing % load","71cce8a5":"## Load= 0%","d783b063":"## Load= 40%","bad39d2d":"## Load= 70%","c7731512":"## Load= 50%"}}