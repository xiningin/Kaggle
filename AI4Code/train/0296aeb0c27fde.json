{"cell_type":{"43c90672":"code","7f4197a0":"code","f449fc1a":"code","424687ef":"code","df394cd9":"code","14ad7143":"code","369cda35":"code","047e033f":"code","bdce9da4":"code","33d378de":"code","5d843cc5":"code","2a46f7c6":"code","b6c44de2":"code","4eabd172":"code","e91d23ab":"code","974a9761":"code","8fd06ec6":"code","a7348250":"code","c34db2c4":"code","d43a18c3":"code","9e8c9c09":"code","c21e845f":"code","fe60c43e":"code","5fb8ded2":"code","ca108df1":"code","2f0e9547":"code","4aabf5d2":"code","ba4d36f9":"code","8eeebdf4":"code","82aa40e8":"code","ffc2e055":"code","f48ea5e9":"code","651774ad":"code","70844fad":"code","118ff846":"code","a2b6b10b":"code","37299f36":"code","9ea02231":"code","9c350ba7":"code","b2b63205":"code","adf68634":"code","5bf698b8":"code","a765fa4c":"code","28a7a9d0":"code","112602f5":"code","8a090a1d":"code","bed81479":"code","9d356a11":"code","393135eb":"code","1cd1e2b5":"markdown","5de7b5e9":"markdown","92f3d9d7":"markdown","78bafba5":"markdown","b3300170":"markdown","2d8e3655":"markdown","e82af9c9":"markdown","41fe094c":"markdown","2d7a540d":"markdown","42832010":"markdown","97870cdb":"markdown","198cdbcb":"markdown","c20849c9":"markdown","61f591da":"markdown","873441c0":"markdown","f65d4b97":"markdown","c01bf38c":"markdown","2f6bf3cd":"markdown","c62f86cb":"markdown","7d202a39":"markdown"},"source":{"43c90672":"import warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn.datasets import load_boston\nfrom sklearn import preprocessing\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom prettytable import PrettyTable\nfrom sklearn.linear_model import SGDRegressor\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom numpy import random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import load_boston\nimport os\nfrom matplotlib import cm\nfrom matplotlib.ticker import LinearLocator, FormatStrFormatter\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils import resample\nfrom sklearn.metrics import r2_score\nimport timeit\nprint(\"DONE\")","7f4197a0":"def make_X_matrix_new(x,y,n):\n    x = x.ravel()\n    y = y.ravel()\n    if len(x) != len(y):\n        print(\"x and y needs to have the same length!\")\n        \n    X = np.ones(len(x)).reshape(len(x),1)\n    for i in range(n):\n        if i == 0:\n            X_temp = np.hstack(((x**(i+1)).reshape(len(x),1) , (y**(i+1)).reshape(len(y),1)))\n            X = np.concatenate((X,X_temp),axis=1)\n        else:\n            X_temp = np.hstack(((x**(i+1)).reshape(len(x),1) , (y**(i+1)).reshape(len(y),1),((x**i) * (y**i)).reshape(len(y),1) ))\n            X = np.concatenate((X,X_temp),axis=1)\n\n    return X","f449fc1a":"def predict_new(x,y,n,beta):\n    pred = beta[0]\n    for i in range(n):\n        if i == 0:\n            pred = pred + beta[1] * x + beta[2] * y\n        else:\n            pred = pred + beta[i*3] *(x**(i+1)) + beta[(i*3)+1]*(y**(i+1)) + beta[(i*3)+2]*((x**i) * (y**i))\n    return pred","424687ef":"def FrankeFunction(x,y):\n    term1 = 0.75*np.exp(-(0.25*(9*x-2)**2) - 0.25*((9*y-2)**2))\n    term2 = 0.75*np.exp(-((9*x+1)**2)\/49.0 - 0.1*(9*y+1))\n    term3 = 0.5*np.exp(-(9*x-7)**2\/4.0 - 0.25*((9*y-3)**2))\n    term4 = -0.2*np.exp(-(9*x-4)**2 - (9*y-7)**2)\n    noise = np.random.normal(0, 0.1, len(x)*len(x)) \n    noise = noise.reshape(len(x),len(x))\n    return term1 + term2 + term3 + term4 + noise\n\ndef xy_data(n):\n    x = np.linspace(0,1,n)\n    y = np.linspace(0,1,n)\n    x,y = np.meshgrid(x,y)\n    return x,y","df394cd9":"# This function calculates beta for OLS\ndef calc_beta(X,y):\n    beta=np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y)\n    return beta","14ad7143":"# K fold algorithm inspired by:\n# https:\/\/machinelearningmastery.com\/implement-resampling-methods-scratch-python\/\n\nfrom random import seed\nfrom random import randrange\n \n# Split a dataset into k folds\ndef cross_validation_split(dataset, folds=10):\n    dataset_split = list()\n    dataset_copy = list(dataset)\n    fold_size = int(len(dataset) \/ folds)\n    for i in range(folds):\n        fold = list()\n        while len(fold) < fold_size:\n            index = randrange(len(dataset_copy))\n            fold.append(dataset_copy.pop(index))\n        dataset_split.append(fold)\n    return dataset_split","369cda35":"# Make data set\nn = 40\nx,y = xy_data(n)\nz = FrankeFunction(x,y)\n\n\n# number of k-folds\nk_folds = 10\n\n# Polynomial fit\npolynomial = 25\n\n# Stacking x and y \nx_and_y=np.hstack((x.ravel().reshape(x.ravel().shape[0],1),y.ravel().reshape(y.ravel().shape[0],1)))\n\n# Scaling data\nscaler = StandardScaler()\nscaler.fit(x_and_y)\nx_and_y_scaled = scaler.transform(x_and_y)\n\n# Make list and arrays to store results\nall_r2_ols_cv=[]\nmean_r2_ols_cv=[]\nerror = np.zeros(polynomial)\nbias = np.zeros(polynomial)\nvariance = np.zeros(polynomial)\npolydegree = np.zeros(polynomial)\ntrain_error = np.zeros(polynomial)\n\n\nfor poly in range(polynomial):\n    # Make list and arrays to store results\n    r2_ = []\n    \n    #Make array to store predictions\n    pred_test = np.empty((int(z.ravel().shape[0]*(1\/k_folds)), k_folds))\n    pred_train = np.empty((int(z.ravel().shape[0]*(1-(1\/k_folds))), k_folds))\n    \n    # Stacking x , y (X) and z \n    #data = np.hstack((x_and_y_scaled,z.ravel().reshape(n**2,1)))\n    data = np.hstack((x_and_y_scaled,z.ravel().reshape(z.shape[0]*z.shape[1],1)))\n    \n    #Make folds \n    folds = cross_validation_split(data, k_folds)\n    for i in range(k_folds):\n        #Make train and test data using the i'th fold\n        n_fold = folds.copy()\n        test_data = n_fold.pop(i)\n        test_data= np.asarray(test_data)\n        train_data = np.vstack(n_fold)\n        \n        #split z and X\n        z_train = train_data[:,-1]\n        xy_train = train_data[:,0:-1]\n        z_test = test_data[:,-1]\n        xy_test = test_data[:,0:-1]\n        \n        # Fit training data\n        X_train = make_X_matrix_new(xy_train.T[0],xy_train.T[1],poly+1)\n        #A = np.transpose(X_train) @ X_train\n        #A = X_train.T.dot(X_train)\n        #X_XT=SVDinv(A)\n        \n        #np.linalg.inv(X.T.dot(X)).dot(X.T).dot(y\n        beta = calc_beta(X_train, z_train)\n        #beta=np.transpose(X_train).dot(np.linalg.inv(X_XT)).dot(z_train)\n        \n        #n, p = X_train.shape\n        #sigma_inv = np.zeros((p, n))\n\n        #u, sigma, vt = np.linalg.svd(X_train)\n        #sigma_inv[:min(n, p), :min(n, p)] = np.diag(1 \/ sigma)\n        #beta = (vt.T @ sigma_inv @ u.T) @ z_train\n        \n        # Do prediction on test and train data\n        z_pred_test=predict_new(xy_test.T[0],xy_test.T[1],poly+1,beta)\n        z_pred_train=predict_new(xy_train.T[0],xy_train.T[1],poly+1,beta)\n        pred_test[:,i]=predict_new(xy_test.T[0],xy_test.T[1],poly+1,beta)\n        pred_train[:,i]=predict_new(xy_train.T[0],xy_train.T[1],poly+1,beta)\n        \n        # Append results to arrays and lists\n        r2_.append(r2_score(z_test,z_pred_test))\n        \n    train_error[poly] = np.mean( np.mean((z_train.reshape(z_train.shape[0],1) - pred_train)**2, axis=1, keepdims=True) )   \n    error[poly] = np.mean( np.mean((z_test.reshape(z_test.shape[0],1) - pred_test)**2, axis=1, keepdims=True) )\n    bias[poly] = np.mean( (z_test.reshape(z_test.shape[0],1) - np.mean(pred_test, axis=1, keepdims=True))**2 )\n    variance[poly] = np.mean( np.var(pred_test, axis=1, keepdims=True) )\n\n    print('Polynomial degree:', poly+1)\n    print('Error:', error[poly])\n    print('Bias^2:', bias[poly])\n    print('Var:', variance[poly])\n    print('{} >= {} + {} = {}'.format(error[poly], bias[poly], variance[poly], bias[poly]+variance[poly]))\n        \n    #plotting prediction based on all data \n    \n    z_pred_for_plot = predict_new(x_and_y_scaled.T[0],x_and_y_scaled.T[1],poly+1,beta)\n    fig = plt.figure(figsize=(32,12))\n    ax = fig.gca(projection ='3d')\n    surf = ax.plot_surface(x,y,z_pred_for_plot.reshape(n,n),cmap=cm.coolwarm, linewidth = 0, antialiased=False)\n    ax.set_zlim(-0.10,1.40)\n    ax.zaxis.set_major_locator(LinearLocator(10))\n    ax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\n    fig.colorbar(surf,shrink=0.5, aspect=5)\n    fig.suptitle(\"A {} degree polynomial fit of Franke function using OLS and K-fold crossval\".format(poly+1) ,fontsize=\"40\", color = \"black\")\n    fig.show()\n        \n    all_r2_ols_cv.append(r2_)\n    mean_r2_ols_cv.append(np.mean(r2_))","047e033f":"!pip install neurokit2","bdce9da4":"import neurokit2 as nk\nfrom scipy.io import loadmat\nimport wfdb\n\n# This function loads ECG recordings and meta data given a specific recording number\ndef load_challenge_data(filename):\n    x = loadmat(filename)\n    data = np.asarray(x['val'], dtype=np.float64)\n    new_file = filename.replace('.mat','.hea')\n    input_header_file = os.path.join(new_file)\n    with open(input_header_file,'r') as f:\n        header_data=f.readlines()\n    return data, header_data","33d378de":"# This piece of code searches through all data, in 1 out of the 2 ECG databases, after patients with LVH diagnose. \n#Then the second heartbeat in every record is added to a new list and interpolated to a 12 x 500 matrix \n\nfrom scipy import interpolate\nlvh_data = []\nstarttime = timeit.default_timer()\nprint(\"The start time is :\",starttime)\nfor i in sorted(os.listdir(\"\/kaggle\/input\/china-12lead-ecg-challenge-database\/Training_2\/\")):\n    if i.endswith(\".mat\"):\n        data, header_data = load_challenge_data(\"\/kaggle\/input\/china-12lead-ecg-challenge-database\/Training_2\/\"+i)\n        diagnose = header_data[15][5:-1]\n        diagnose = diagnose.split(\",\")\n        diagnose = np.asarray(diagnose)\n        if pd.Series('164873001').isin(diagnose).any():\n            _, rpeaks = nk.ecg_peaks(data[1], sampling_rate=int(header_data[0].split(\" \")[2]))\n            split_num = int(((np.diff(rpeaks['ECG_R_Peaks'])[0]+np.diff(rpeaks['ECG_R_Peaks'])[1])\/2)\/2)\n            data = data\/int(header_data[1].split(\" \")[2].split(\"\/\")[0])\n            ecg3d_lvh=[]\n            for i in range(data.shape[0]):\n                ecg3d_lvh.append(data[i][rpeaks['ECG_R_Peaks'][1]-split_num:rpeaks['ECG_R_Peaks'][1]+split_num])\n            ecg3d_lvh = np.asarray(ecg3d_lvh)\n            x=np.arange(ecg3d_lvh.shape[1])\n            y=np.arange(ecg3d_lvh.shape[0])\n            #x,y = np.meshgrid(x, y)\n            f = interpolate.interp2d(x, y, ecg3d_lvh, kind='cubic')\n            xnew = np.linspace(0,len(x),500)\n            ynew = np.arange(len(y))\n            #xnew,ynew = np.meshgrid(xnew, ynew)\n            znew = f(xnew, ynew)\n            lvh_data.append(znew)\n            print(\"Time after adding first patient data is :\", timeit.default_timer() - starttime)\n            print(len(lvh_data))\n        else:\n            pass\nlvh_data = np.asarray(lvh_data)","5d843cc5":"# This piece of code searches through all data, in 1 out of the 2 ECG databases, after patients with normal sinus rythm. \n#Then the second heartbeat in every record is added to a new list and interpolated to a 12 x 500 matrix \n\nnorm_data = []\nstarttime = timeit.default_timer()\nfor i in sorted(os.listdir(\"\/kaggle\/input\/china-physiological-signal-challenge-in-2018\/Training_WFDB\/\")):\n    if i.endswith(\".mat\"):\n        data, header_data = load_challenge_data(\"\/kaggle\/input\/china-physiological-signal-challenge-in-2018\/Training_WFDB\/\"+i)\n        diagnose = header_data[15][5:-1]\n        diagnose = diagnose.split(\",\")\n        diagnose = np.asarray(diagnose)\n        if pd.Series('426783006').isin(diagnose).any():\n            _, rpeaks = nk.ecg_peaks(data[1], sampling_rate=int(header_data[0].split(\" \")[2]))\n            split_num = int(((np.diff(rpeaks['ECG_R_Peaks'])[0]+np.diff(rpeaks['ECG_R_Peaks'])[1])\/2)\/2)\n            data = data\/int(header_data[1].split(\" \")[2].split(\"\/\")[0])\n            ecg3d_norm=[]\n            for i in range(data.shape[0]):\n                ecg3d_norm.append(data[i][rpeaks['ECG_R_Peaks'][1]-split_num:rpeaks['ECG_R_Peaks'][1]+split_num])\n            ecg3d_norm = np.asarray(ecg3d_norm)\n            x=np.arange(ecg3d_norm.shape[1])\n            y=np.arange(ecg3d_norm.shape[0])\n            #x,y = np.meshgrid(x, y)\n            f = interpolate.interp2d(x, y, ecg3d_norm, kind='cubic')\n            xnew = np.linspace(0,len(x),500)\n            ynew = np.arange(len(y))\n            #xnew,ynew = np.meshgrid(xnew, ynew)\n            znew = f(xnew, ynew)\n            norm_data.append(znew)\n            print(\"Time after adding first patient data is :\", timeit.default_timer() - starttime)\n            print(len(norm_data))\n        else:\n            pass\nnorm_data = np.asarray(norm_data)","2a46f7c6":"z = np.mean(norm_data[:100],axis=0)\nx = np.arange(500)\ny = np.arange(12)\nx,y=np.meshgrid(x,y)","b6c44de2":"fig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,z,cmap=cm.bone, linewidth = 0, antialiased=False)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.view_init(20, 75)\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\n#fig.suptitle(\"A {} degree polynomial fit of ECG data using Ridge with lambda {}\".format(int(np.where(mean_r2 == np.amax(mean_r2))[0])+1,LAMBDA[int(np.where(mean_r2 == np.amax(mean_r2))[1])]) ,fontsize=\"40\", color = \"black\")\n#fig.savefig(\"Franke_function_{}deg_reg.png\".format(degree))\nfig.show()","4eabd172":"n = 40\nm = 40\nx,y = xy_data(n)\nz = FrankeFunction(x,y)\n\npol=10\n\nX=make_X_matrix_new(x,y,pol)\ntheta = np.random.randn(X.shape[1],1)\n\n\neta = 0.001\nNiterations = 10000\n\n\nfor iter in range(Niterations):\n    gradients = 2.0\/m*X.T @ ((X @ theta)-z.ravel().reshape(z.ravel().shape[0],1))\n    theta -= eta*gradients\nprint(\"theta from own gd\")\nprint(theta)","e91d23ab":"zpredict_ols = X.dot(theta)","974a9761":"print(\"MSE:\",mean_squared_error(z.ravel(),zpredict_ols))\nprint(\"R2-score:\",r2_score(z.ravel(),zpredict_ols))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,zpredict_ols.reshape(x.shape[0],y.shape[1]),cmap=cm.coolwarm, linewidth = 0, antialiased=False)\nax.set_zlim(-0.10,1.40)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\nfig.suptitle(\"A {} degree polynomial fit of Franke function using OLS and K-fold crossval\".format(pol) ,fontsize=\"40\", color = \"black\")\nfig.show()","8fd06ec6":"def calc_beta_ridge(X,y, alpha):\n    beta=np.linalg.inv(X.T.dot(X)+alpha * np.identity(X.shape[1])).dot(X.T).dot(y)\n    return beta","a7348250":"n = 40\nm = 60\nx,y = xy_data(n)\nz = FrankeFunction(x,y)\n\npol=20\nlmbda = 0.0001\n\nX=make_X_matrix_new(x,y,pol)\ntheta = np.random.randn(X.shape[1],1)\n\n\neta = 0.001\nNiterations = 10000\n\n\nfor iter in range(Niterations):\n    gradients = 2.0\/m*X.T @ (X @ (theta)-z.ravel().reshape(z.ravel().shape[0],1))+2*lmbda*theta\n    theta -= eta*gradients\nprint(\"theta from own gd\")\nprint(theta)","c34db2c4":"zpredict_ridge = X.dot(theta)","d43a18c3":"print(\"MSE:\",mean_squared_error(z.ravel(),zpredict_ridge))\nprint(\"R2-score:\",r2_score(z.ravel(),zpredict_ridge))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,zpredict_ridge.reshape(x.shape[0],y.shape[1]),cmap=cm.coolwarm, linewidth = 0, antialiased=False)\nax.set_zlim(-0.10,1.40)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\nfig.suptitle(\"A {} degree polynomial fit of Franke function using OLS and K-fold crossval\".format(pol) ,fontsize=\"40\", color = \"black\")\nfig.show()","9e8c9c09":"z = np.mean(norm_data[:100],axis=0)\nx = np.arange(500)\ny = np.arange(12)\nx,y=np.meshgrid(x,y)\n\nm = 10\npol=1\n\nX=make_X_matrix_new(x,y,pol)\ntheta = np.random.randn(X.shape[1],1)\n\n\neta = 0.000000001\nNiterations = 100\n\n\nfor iter in range(Niterations):\n    gradients = 2.0\/m*X.T @ ((X @ theta)-z.ravel().reshape(z.ravel().shape[0],1))\n    theta -= eta*gradients\nprint(\"theta from own gd\")\nprint(theta)","c21e845f":"zpredict_ols_ecg = X.dot(theta)","fe60c43e":"print(\"MSE:\",mean_squared_error(z.ravel(),zpredict_ols_ecg))\nprint(\"R2-score:\",r2_score(z.ravel(),zpredict_ols_ecg))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,zpredict_ols_ecg.reshape(x.shape[0],y.shape[1]),cmap=cm.bone, linewidth = 0, antialiased=False)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.view_init(20, 75)\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\n#fig.suptitle(\"A {} degree polynomial fit of ECG data using Ridge with lambda {}\".format(int(np.where(mean_r2 == np.amax(mean_r2))[0])+1,LAMBDA[int(np.where(mean_r2 == np.amax(mean_r2))[1])]) ,fontsize=\"40\", color = \"black\")\n#fig.savefig(\"Franke_function_{}deg_reg.png\".format(degree))\nfig.show()","5fb8ded2":"z = np.mean(norm_data[:100],axis=0)\nx = np.arange(500)\ny = np.arange(12)\nx,y=np.meshgrid(x,y)\n\nm = 60\n\npol=1\nlmbda = 0.0001\n\nX=make_X_matrix_new(x,y,pol)\ntheta = np.random.randn(X.shape[1],1)\n\n\neta = 0.0000000001\nNiterations = 10\n\n\nfor iter in range(Niterations):\n    gradients = 2.0\/m*X.T @ (X @ (theta)-z.ravel().reshape(z.ravel().shape[0],1))+2*lmbda*theta\n    theta -= eta*gradients\nprint(\"theta from own gd\")\nprint(theta)","ca108df1":"zpredict_ridge_ecg = X.dot(theta)","2f0e9547":"print(\"MSE:\",mean_squared_error(z.ravel(),zpredict_ridge_ecg))\nprint(\"R2-score:\",r2_score(z.ravel(),zpredict_ridge_ecg))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,zpredict_ridge_ecg.reshape(x.shape[0],y.shape[1]),cmap=cm.bone, linewidth = 0, antialiased=False)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.view_init(20, 75)\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\n#fig.suptitle(\"A {} degree polynomial fit of ECG data using Ridge with lambda {}\".format(int(np.where(mean_r2 == np.amax(mean_r2))[0])+1,LAMBDA[int(np.where(mean_r2 == np.amax(mean_r2))[1])]) ,fontsize=\"40\", color = \"black\")\n#fig.savefig(\"Franke_function_{}deg_reg.png\".format(degree))\nfig.show()","4aabf5d2":"x,y = xy_data(n)\nz = FrankeFunction(x,y)\n\nx_and_y=np.hstack((x.ravel().reshape(x.ravel().shape[0],1),y.ravel().reshape(y.ravel().shape[0],1)))\n\nscaler = StandardScaler()\nscaler.fit(x_and_y)\nx_and_y_scaled = scaler.transform(x_and_y)\n\nfrom sklearn.linear_model import SGDRegressor\nsgdreg = SGDRegressor(max_iter = 50, penalty=None, eta0=0.1)\nsgdreg.fit(x_and_y_scaled,z.ravel())\nprint(sgdreg.intercept_, sgdreg.coef_)","ba4d36f9":"SK_pred=sgdreg.predict(x_and_y_scaled)","8eeebdf4":"print(\"MSE:\",mean_squared_error(z.ravel(),SK_pred))\nprint(\"R2-score:\",r2_score(z.ravel(),SK_pred))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,SK_pred.reshape(x.shape[0],y.shape[1]),cmap=cm.coolwarm, linewidth = 0, antialiased=False)\nax.set_zlim(-0.10,1.40)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\nfig.suptitle(\"A {} degree polynomial fit of Franke function using OLS and K-fold crossval\".format(pol) ,fontsize=\"40\", color = \"black\")\nfig.show()","82aa40e8":"n=40\nx,y = xy_data(n)\nz = FrankeFunction(x,y)\n\nm = 1\nn_iter = n**2\npol=10\nn_epochs = 50\nt0, t1 = 5, 50\ndef learning_schedule(t):\n    return t0\/(t+t1)\n\nX=make_X_matrix_new(x,y,pol)\ntheta = np.random.randn(X.shape[1],1)","ffc2e055":"for epoch in range(n_epochs):\n    for i in range(n_iter):\n        random_index = np.random.randint(n_iter)\n        xi = X[random_index:random_index+1]\n        zi = z.ravel()[random_index:random_index+1]\n        gradients = 2.0\/m * xi.T @ ((xi @ theta)-zi)\n        eta = learning_schedule(epoch*n_iter+i)\n        theta = theta - eta*gradients\nprint(\"theta from own sdg\")\nprint(theta)","f48ea5e9":"ypredict = X.dot(theta)","651774ad":"print(\"MSE:\",mean_squared_error(z.ravel(),ypredict))\nprint(\"R2-score:\",r2_score(z.ravel(),ypredict))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,ypredict.reshape(x.shape[0],y.shape[1]),cmap=cm.coolwarm, linewidth = 0, antialiased=False)\nax.set_zlim(-0.10,1.40)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\nfig.suptitle(\"A {} degree polynomial fit of Franke function using OLS and K-fold crossval\".format(pol) ,fontsize=\"40\", color = \"black\")\nfig.show()","70844fad":"n=40\nx,y = xy_data(n)\nz = FrankeFunction(x,y)\n#x_and_y=np.hstack((x.ravel().reshape(x.ravel().shape[0],1),y.ravel().reshape(y.ravel().shape[0],1)))\n\nm = 1\nn_iter = n**2\npol=10\nlmbda = 0.001\nn_epochs = 100\nt0, t1 = 5, 50\ndef learning_schedule(t):\n    return t0\/(t+t1)\n\n#scaler = StandardScaler()\n#scaler.fit(x_and_y)\n#x_and_y_scaled = scaler.transform(x_and_y)\nX=make_X_matrix_new(x,y,pol)\ntheta = np.random.randn(X.shape[1],1)","118ff846":"for epoch in range(n_epochs):\n    for i in range(n_iter):\n        random_index = np.random.randint(n_iter)\n        xi = X[random_index:random_index+1]\n        zi = z.ravel()[random_index:random_index+1]\n        gradients = 2.0\/m * xi.T @ ((xi @ theta)-zi)+2*lmbda*theta\n        eta = learning_schedule(epoch*n_iter+i)\n        theta = theta - eta*gradients\nprint(\"theta from own sdg\")\nprint(theta)","a2b6b10b":"ypredict = X.dot(theta)","37299f36":"print(\"MSE:\",mean_squared_error(z.ravel(),ypredict))\nprint(\"R2-score:\",r2_score(z.ravel(),ypredict))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,ypredict.reshape(x.shape[0],y.shape[1]),cmap=cm.coolwarm, linewidth = 0, antialiased=False)\nax.set_zlim(-0.10,1.40)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\nfig.suptitle(\"A {} degree polynomial fit of Franke function using OLS and K-fold crossval\".format(pol) ,fontsize=\"40\", color = \"black\")\nfig.show()","9ea02231":"z = np.mean(norm_data[:100],axis=0)\nx = np.arange(500)\ny = np.arange(12)\nx,y=np.meshgrid(x,y)\n\n\nm = 1\nn_iter = 10\npol=3\nn_epochs = 10\nt0, t1 = 0.00001, 50\ndef learning_schedule(t):\n    return t0\/(t+t1)\n\nX=make_X_matrix_new(x,y,pol)\ntheta = np.random.randn(X.shape[1],1)","9c350ba7":"for epoch in range(n_epochs):\n    for i in range(n_iter):\n        random_index = np.random.randint(n_iter)\n        xi = X[random_index:random_index+1]\n        zi = z.ravel()[random_index:random_index+1]\n        gradients = 2.0\/m * xi.T @ ((xi @ theta)-zi)\n        eta = learning_schedule(epoch*n_iter+i)\n        theta = theta - eta*gradients\nprint(\"theta from own sdg\")\nprint(theta)","b2b63205":"ypredict = X.dot(theta)","adf68634":"print(\"MSE:\",mean_squared_error(z.ravel(),ypredict))\nprint(\"R2-score:\",r2_score(z.ravel(),ypredict))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,ypredict.reshape(x.shape[0],y.shape[1]),cmap=cm.bone, linewidth = 0, antialiased=False)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.view_init(20, 75)\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\n#fig.suptitle(\"A {} degree polynomial fit of ECG data using Ridge with lambda {}\".format(int(np.where(mean_r2 == np.amax(mean_r2))[0])+1,LAMBDA[int(np.where(mean_r2 == np.amax(mean_r2))[1])]) ,fontsize=\"40\", color = \"black\")\n#fig.savefig(\"Franke_function_{}deg_reg.png\".format(degree))\nfig.show()","5bf698b8":"z = np.mean(norm_data[:100],axis=0)\nx = np.arange(500)\ny = np.arange(12)\nx,y=np.meshgrid(x,y)\n\nm = 1\nn_iter =10\npol=3\nlmbda = 0.000000001\nn_epochs = 50\nt0, t1 = 0.0001, 50\ndef learning_schedule(t):\n    return t0\/(t+t1)\n\nX=make_X_matrix_new(x,y,pol)\ntheta = np.random.randn(X.shape[1],1)","a765fa4c":"for epoch in range(n_epochs):\n    for i in range(n_iter):\n        random_index = np.random.randint(n_iter)\n        xi = X[random_index:random_index+1]\n        zi = z.ravel()[random_index:random_index+1]\n        gradients = 2.0\/m * xi.T @ ((xi @ theta)-zi)+2*lmbda*theta\n        eta = learning_schedule(epoch*n_iter+i)\n        theta = theta - eta*gradients\nprint(\"theta from own sdg\")\nprint(theta)","28a7a9d0":"ypredict = X.dot(theta)","112602f5":"print(\"MSE:\",mean_squared_error(z.ravel(),ypredict))\nprint(\"R2-score:\",r2_score(z.ravel(),ypredict))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,ypredict.reshape(x.shape[0],y.shape[1]),cmap=cm.bone, linewidth = 0, antialiased=False)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.view_init(20, 75)\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\n#fig.suptitle(\"A {} degree polynomial fit of ECG data using Ridge with lambda {}\".format(int(np.where(mean_r2 == np.amax(mean_r2))[0])+1,LAMBDA[int(np.where(mean_r2 == np.amax(mean_r2))[1])]) ,fontsize=\"40\", color = \"black\")\n#fig.savefig(\"Franke_function_{}deg_reg.png\".format(degree))\nfig.show()","8a090a1d":"z = np.mean(norm_data[:100],axis=0)\nx = np.arange(500)\ny = np.arange(12)\nx,y=np.meshgrid(x,y)\nx_and_y=np.hstack((x.ravel().reshape(x.ravel().shape[0],1),y.ravel().reshape(y.ravel().shape[0],1)))\n\nm = 1\nn_iter =1000\npol=8\nlmbda = 0.001\nn_epochs = 10\nt0, t1 = 0.001, 50\ndef learning_schedule(t):\n    return t0\/(t+t1)\n\nscaler = StandardScaler()\nscaler.fit(x_and_y)\nx_and_y_scaled = scaler.transform(x_and_y)\n\nX=make_X_matrix_new(x_and_y_scaled.T[0],x_and_y_scaled.T[1],pol)\ntheta = np.random.randn(X.shape[1],1)","bed81479":"for epoch in range(n_epochs):\n    for i in range(n_iter):\n        random_index = np.random.randint(n_iter)\n        xi = X[random_index:random_index+1]\n        zi = z.ravel()[random_index:random_index+1]\n        gradients = 2.0\/m * xi.T @ ((xi @ theta)-zi)+2*lmbda*theta\n        eta = learning_schedule(epoch*n_iter+i)\n        theta = theta - eta*gradients\nprint(\"theta from own sdg\")\nprint(theta)","9d356a11":"ypredict = X.dot(theta)","393135eb":"print(\"MSE:\",mean_squared_error(z.ravel(),ypredict))\nprint(\"R2-score:\",r2_score(z.ravel(),ypredict))\nfig = plt.figure(figsize=(32,12))\nax = fig.gca(projection ='3d')\nsurf = ax.plot_surface(x,y,ypredict.reshape(x.shape[0],y.shape[1]),cmap=cm.bone, linewidth = 0, antialiased=False)\nax.zaxis.set_major_locator(LinearLocator(10))\nax.view_init(20, 75)\nax.zaxis.set_major_formatter(FormatStrFormatter('%.02f'))\nfig.colorbar(surf,shrink=0.5, aspect=5)\n#fig.suptitle(\"A {} degree polynomial fit of ECG data using Ridge with lambda {}\".format(int(np.where(mean_r2 == np.amax(mean_r2))[0])+1,LAMBDA[int(np.where(mean_r2 == np.amax(mean_r2))[1])]) ,fontsize=\"40\", color = \"black\")\n#fig.savefig(\"Franke_function_{}deg_reg.png\".format(degree))\nfig.show()","1cd1e2b5":"## <center> Prediction using data from Franke's function using Ridge and SDG<\/center>","5de7b5e9":"## <center>Prediction using Ridge and SDG on ECG data <\/center>","92f3d9d7":"# <center>Stochastic Gradient Decent<\/center>","78bafba5":"# <center> Gradient Decent algorithm <\/center>","b3300170":"## <center>Prediction using OLS and SDG on ECG data <\/center>","2d8e3655":"## <center> Franke's function using OLS <\/center>","e82af9c9":"### <center> An algorithm to make infinite large X matrixes <\/center>","41fe094c":"## <center>Prediction using Ridge and SDG on ECG data with scaling<\/center>","2d7a540d":"## <center> Prediction using data from Franke's function using OLS and SDG <\/center>","42832010":"## <center> ECG data using Ridge<\/center>","97870cdb":"## <center>Prediction using data from Franke's function using SKlearn<\/center>","198cdbcb":"# Building my own Neural Network","c20849c9":"# <center> Classification and regression, from linear and logitic regression to neural networks<\/center>","61f591da":"### <center> An algorithm to handle infinite large $\\beta$ - vectors <\/center>","873441c0":"Nice article about this topic:\n\nhttps:\/\/medium.com\/@nikhilparmar9\/simple-sgd-implementation-in-python-for-linear-regression-on-boston-housing-data-f63fcaaecfb1","f65d4b97":"## <center> ECG data using OLS<\/center>","c01bf38c":"### <center> Test the new algorithm using OLS on Franke's function <\/center>","2f6bf3cd":"## <center> Download ECG data <\/center>","c62f86cb":"## <center> Franke's function using Ridge<\/center>","7d202a39":"## <center> Some improvement since https:\/\/www.kaggle.com\/bjoernjostein\/linear-polynomial-fitting-of-franke-s-function\/edit\/run\/44436576 <\/center>"}}