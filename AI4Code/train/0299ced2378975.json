{"cell_type":{"022d2ad3":"code","806aee3a":"code","7c94d4e3":"code","06399d45":"code","4db834ab":"code","516bcaa3":"code","b754e0c0":"code","51937289":"code","8805d116":"code","07280bf6":"code","dc546e5a":"code","4143933a":"code","353787a0":"code","661389bd":"code","5563a983":"code","899a1146":"code","1a1e9a27":"code","efc80e3f":"code","8a6d0a96":"code","2ab90245":"code","87bd5747":"code","2d38b1df":"markdown"},"source":{"022d2ad3":"import warnings\nwarnings.filterwarnings('always')\nwarnings.filterwarnings('ignore')\nimport tensorflow as tf\nimport random as rn\nimport itertools\nimport cv2                  \nimport numpy as np         \nimport os      \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib import style\nimport seaborn as sns\n%matplotlib inline  \nstyle.use('fivethirtyeight')\nsns.set(style='whitegrid',color_codes=True)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import accuracy_score,precision_score,recall_score,confusion_matrix,roc_curve,roc_auc_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import backend as K\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam,SGD,Adagrad,Adadelta,RMSprop\nfrom keras.utils import to_categorical\nfrom keras.layers import Dropout, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D, BatchNormalization             \nfrom random import shuffle  \nfrom zipfile import ZipFile\nfrom PIL import Image\nfrom tqdm import tqdm ","806aee3a":"TRAIN_DIR = '..\/input\/train'\nTEST_DIR = '..\/input\/test'\nIMG_SIZE=100","7c94d4e3":"def label_img(img):\n    word_label = img.split('.')[0]\n    return word_label","06399d45":"def create_train_data():\n    training_data = []\n    for img in tqdm(os.listdir(TRAIN_DIR)):\n        label=label_img(img)\n        path = os.path.join(TRAIN_DIR,img)\n        img_num = img.split('.')[0]\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        training_data.append([np.array(img),str(label)])\n        \n    shuffle(training_data)\n    return training_data","4db834ab":"train_data=create_train_data()\ntrain_data=np.array(train_data)\nprint(train_data.shape)\nX= np.array([i[0] for i in train_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)\nY= np.array([i[1] for i in train_data])","516bcaa3":"fig,ax=plt.subplots(6,2)\nfig.set_size_inches(15,15)\nfor i in range(6):\n    for j in range (2):\n        k=rn.randint(0,len(Y))\n        ax[i,j].imshow(X[k])\n        ax[i,j].set_title('Pet: '+Y[k])\n        \nplt.tight_layout()","b754e0c0":"sns.countplot(Y)\nplt.title('Categories')","51937289":"l =[]\nfor i in range(25000):\n    if Y[i]==\"dog\":\n                   l.append(1)\n    elif Y[i]==\"cat\":\n                   l.append(0)","8805d116":"X_train, X_test, y_train, y_test = train_test_split(X, l, shuffle=True, test_size =0.3, random_state = 32)","07280bf6":"model = tf.keras.models.Sequential()\n\nmodel.add(tf.keras.layers.Conv2D(128, (3,3), input_shape=(100,100,3), activation = tf.nn.relu, padding = \"valid\"))\nmodel.add(tf.keras.layers.MaxPool2D( pool_size = (3,3), strides = None ))\n\nmodel.add(tf.keras.layers.Conv2D(128, (3,3), activation = tf.nn.relu, padding = \"same\"))\nmodel.add(tf.keras.layers.MaxPool2D( pool_size = (3,3), strides = None ))\n\nmodel.add(tf.keras.layers.Conv2D(128, (3,3), activation = tf.nn.relu, padding = \"same\"))\nmodel.add(tf.keras.layers.MaxPool2D( pool_size = (3,3), strides = None ))\n\nmodel.add(tf.keras.layers.Flatten())\n\nmodel.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\nmodel.add(tf.keras.layers.Dropout(0.25))\n\nmodel.add(tf.keras.layers.Dense(128, activation = tf.nn.relu))\nmodel.add(tf.keras.layers.Dropout(0.25))\nmodel.add(tf.keras.layers.Dense(2, activation = tf.nn.softmax))","dc546e5a":"model.summary() #Architecture of Network","4143933a":"model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])","353787a0":"Model= model.fit(X_train, y_train,\n                 validation_split=0.1,\n                 epochs=13,\n                 batch_size=32)","661389bd":"score = model.evaluate(X_test, y_test, verbose=0)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","5563a983":"plt.plot(Model.history['acc'])\nplt.plot(Model.history['val_acc'])\nplt.title('Model Accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Validation set'], loc='upper left')\nplt.show()","899a1146":"plt.plot(Model.history['val_loss'])\nplt.plot(Model.history['loss'])\nplt.title('Model Loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Training set', 'Test set'], loc='upper left')\nplt.show()","1a1e9a27":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n\ny_pred = model.predict(X_test)\ny_pred_classes = np.argmax(y_pred,axis = 1) \nconfusion_mtx = confusion_matrix(y_test, y_pred_classes) \nplot_confusion_matrix(confusion_mtx, classes = range(2)) ","efc80e3f":"def create_test_data():\n    testing_data = []\n    for img in tqdm(os.listdir(TEST_DIR)):\n        path = os.path.join(TEST_DIR,img)\n        img_num = img.split('.')[0]\n        img = cv2.imread(path,cv2.IMREAD_COLOR)\n        img = cv2.resize(img, (IMG_SIZE,IMG_SIZE))\n        testing_data.append([np.array(img)])\n        \n    shuffle(testing_data)\n    return testing_data","8a6d0a96":"test_data=create_test_data()\ntest_data=np.array(test_data)\nprint(test_data.shape)\ntest= np.array([i[0] for i in test_data]).reshape(-1,IMG_SIZE,IMG_SIZE,3)","2ab90245":"pred=model.predict(test)","87bd5747":"imageid=[]\nprob=[]\nfor i in range(12500):\n    imageid.append(i+1)\n    prob.append(pred[i,1])\n   \nd={'id':imageid,'label':prob}\nans=pd.DataFrame(d)\nans.to_csv('prediction.csv',index=False)","2d38b1df":"Accuracy attained on this model is more than 84% in just 13 epochs.\nLoss is arround 0.3765, modifications to this code can be made to attain greater accuracy in prediction. Since my GPU is off for this analysis I can't made any further increment in accuracy. I'm not using GPU becuase the cv2.resize function is throwing an error. If you have some suggestions please let me know in the comments. \n"}}