{"cell_type":{"ba35262f":"code","305fc8b1":"code","764886cd":"code","90e8d5f6":"code","2ee7cbce":"code","fc0569bc":"code","4e26d0ca":"code","a6aeec20":"code","383082b6":"code","3ab71f7d":"code","adfd9aed":"code","9be523fc":"code","af1bbe83":"code","67a98f18":"code","de7b8aeb":"code","f6549245":"code","1c8b033f":"code","d62711f6":"code","7936d915":"code","d8a72e4e":"code","2b43f564":"code","b9d99440":"code","a1bda153":"markdown","4369bf9c":"markdown","87bf31a3":"markdown","4e01d27f":"markdown","576489e0":"markdown","6cd891fb":"markdown","5e6afe7c":"markdown","927a5b7e":"markdown","6e15828e":"markdown","75e31c42":"markdown"},"source":{"ba35262f":"from sklearn.utils import Bunch\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.preprocessing import MinMaxScaler\nimport pickle\nfrom sklearn import metrics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os","305fc8b1":"flat_data = '..\/input\/golfdb-entire-image\/flat_dat.npy'\ntarget = '..\/input\/golfdb-entire-image\/target.npy'\ntarget_names = '..\/input\/golfdb-entire-image\/target_names.npy'\nimages = '..\/input\/golfdb-entire-image\/images.npy'\nDESCR = '..\/input\/golfdb-entire-image\/descr.npy'","764886cd":"swing_image_dataset = Bunch()\nswing_image_dataset['data'] = np.load(flat_data)\nswing_image_dataset['target'] = np.load(target)\nswing_image_dataset['target_names'] = np.load(target_names)\nswing_image_dataset['images'] = np.load(images)\nswing_image_dataset['DESCR'] = np.load(DESCR)","90e8d5f6":"X = MinMaxScaler().fit_transform(swing_image_dataset.data)","2ee7cbce":"from sklearn.discriminant_analysis import LinearDiscriminantAnalysis as LDA\n\nlda = LDA(n_components=7)\nX = lda.fit(X, swing_image_dataset.target).transform(X)","fc0569bc":"plt.figure(figsize=(20,15))\nfor  i, target_name in zip([ 0, 1, 2, 3, 4, 5, 6, 7], swing_image_dataset.target_names):\n    plt.scatter(X[swing_image_dataset.target == i, 0], X[swing_image_dataset.target== i, 1], label=target_name)\nplt.legend(fontsize=25)\nplt.title('LDA of GolfDB dataset')\n\nplt.show()","4e26d0ca":"rseed=42","a6aeec20":"# 80:20 train:test split \nX_train, X_test, y_train, y_test = train_test_split(X, swing_image_dataset.target, test_size=0.2, random_state=rseed)","383082b6":"accuracy = []\nf1_score = []\nprecision_score = []\nrecall_score = []","3ab71f7d":"from sklearn.svm import LinearSVC\nlinearsvm = LinearSVC(random_state=rseed, C=10, multi_class='crammer_singer')\nlinearsvm.fit(X_train, y_train)\ny_pred = linearsvm.predict(X_test)\n\n\nprint(metrics.classification_report(y_test, y_pred, target_names=swing_image_dataset.target_names, digits=3))\naccuracy_linearsvm = metrics.accuracy_score(y_test, y_pred)\nf1_linearsvm = metrics.f1_score(y_test, y_pred, average='weighted')\nprecision_linearsvm = metrics.precision_score(y_test, y_pred, average='weighted')\nrecall_linearsvm = metrics.recall_score(y_test, y_pred, average='weighted')\nprint(\"Accuracy\", accuracy_linearsvm*100)\naccuracy.append(accuracy_linearsvm*100)\nf1_score.append(f1_linearsvm*100)\nprecision_score.append(precision_linearsvm*100)\nrecall_score.append(recall_linearsvm*100)","adfd9aed":"from sklearn.metrics import ConfusionMatrixDisplay\ncm = metrics.confusion_matrix(y_test, y_pred)\ncm_display = ConfusionMatrixDisplay(cm, display_labels=swing_image_dataset.target_names)\ncm_display.plot(xticks_rotation = 'vertical', cmap='binary')","9be523fc":"from catboost import CatBoostClassifier\ncat_clf = CatBoostClassifier(random_state=rseed,\n                        depth =4, \n                        bagging_temperature = 1.5, \n                        learning_rate = 0.03, \n                        l2_leaf_reg = 7, \n                         eval_metric='Accuracy', \n                         task_type=\"GPU\", \n                        use_best_model = True,\n                            verbose= False)\n\ncat_clf.fit(X_train, y_train, eval_set=(X_test, y_test))\n\ny_pred_cat = cat_clf.predict(X_test)\nprint(metrics.classification_report(y_test, y_pred_cat, target_names=swing_image_dataset.target_names, digits=3))\naccuracy_cat = metrics.accuracy_score(y_test, y_pred_cat)\nf1_cat = metrics.f1_score(y_test, y_pred_cat, average='weighted')\nprecision_cat = metrics.precision_score(y_test, y_pred_cat, average='weighted')\nrecall_cat = metrics.recall_score(y_test, y_pred_cat, average='weighted')\nprint(\"Accuracy\", accuracy_cat*100)\naccuracy.append(accuracy_cat*100)\nf1_score.append(f1_cat*100)\nprecision_score.append(precision_cat*100)\nrecall_score.append(recall_cat*100)","af1bbe83":"from sklearn.metrics import ConfusionMatrixDisplay\ncm = metrics.confusion_matrix(y_test, y_pred_cat)\ncm_display = ConfusionMatrixDisplay(cm, display_labels=swing_image_dataset.target_names)\ncm_display.plot(xticks_rotation = 'vertical', cmap='Greys')","67a98f18":"from sklearn import tree\nclf_dt = tree.DecisionTreeClassifier(min_samples_leaf=5, min_samples_split=3, random_state=rseed)\n\nclf_dt.fit(X_train, y_train)\ny_pred_dt = clf_dt.predict(X_test)\naccuracy_dt = metrics.accuracy_score(y_test, y_pred_dt)\nf1_dt = metrics.f1_score(y_test, y_pred_dt, average='weighted')\nprecision_dt = metrics.precision_score(y_test, y_pred_dt, average='weighted')\nrecall_dt = metrics.recall_score(y_test, y_pred_dt, average='weighted')\nprint(metrics.classification_report(y_test, y_pred_dt, target_names=swing_image_dataset.target_names, digits=3))\nprint(\"Accuracy\", accuracy_dt*100)\naccuracy.append(accuracy_dt*100)\nf1_score.append(f1_dt*100)\nprecision_score.append(precision_dt*100)\nrecall_score.append(recall_dt*100)","de7b8aeb":"from sklearn.ensemble import RandomForestClassifier \nclf_rf = RandomForestClassifier(min_samples_leaf=3, min_samples_split=3, random_state=rseed)\n\nclf_rf.fit(X_train, y_train)\ny_pred_rf = clf_rf.predict(X_test)\n\naccuracy_rf = metrics.accuracy_score(y_test, y_pred_rf)\nf1_rf = metrics.f1_score(y_test, y_pred_rf, average='weighted')\nprecision_rf = metrics.precision_score(y_test, y_pred_rf, average='weighted')\nrecall_rf = metrics.recall_score(y_test, y_pred_rf, average='weighted')\nprint(metrics.classification_report(y_test, y_pred_rf, target_names=swing_image_dataset.target_names, digits=3))\nprint(\"Accuracy\", accuracy_rf*100)\naccuracy.append(accuracy_rf*100)\nf1_score.append(f1_rf*100)\nprecision_score.append(precision_rf*100)\nrecall_score.append(recall_rf*100)","f6549245":"from sklearn.neighbors import KNeighborsClassifier\nclf_knn = KNeighborsClassifier(n_neighbors=7, p=2)\n\nclf_knn.fit(X_train, y_train)\ny_pred_knn = clf_knn.predict(X_test)\n\naccuracy_knn = metrics.accuracy_score(y_test, y_pred_knn)\nf1_knn = metrics.f1_score(y_test, y_pred_knn, average='weighted')\nprecision_knn = metrics.precision_score(y_test, y_pred_knn, average='weighted')\nrecall_knn = metrics.recall_score(y_test, y_pred_knn, average='weighted')\nprint(metrics.classification_report(y_test, y_pred_knn, target_names=swing_image_dataset.target_names, digits=3))\nprint(\"Accuracy\", accuracy_knn*100)\naccuracy.append(accuracy_knn*100)\nf1_score.append(f1_knn*100)\nprecision_score.append(precision_knn*100)\nrecall_score.append(recall_knn*100)","1c8b033f":"import os\nos.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras import Input\nfrom keras.applications.vgg16 import VGG16\nfrom keras.callbacks import EarlyStopping\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder","d62711f6":"\nfrom keras.optimizer_v2.adam import Adam\nfrom keras.models import Sequential\nfrom keras.layers import BatchNormalization\nfrom keras.layers.convolutional import Conv2D\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras.layers.core import Activation\nfrom keras.layers.core import Flatten\nfrom keras.layers.core import Dropout\nfrom keras.layers.core import Dense\n\n\ndef create_mini_vgg(input_shape=(32, 32, 1), cnum=10, dropout_rate=0.25, neurons=32, include_top=True, weights='imagenet'):\n\n    model = Sequential()\n\n    # first CONV => RELU => CONV => RELU => POOL layer set\n    model.add(Conv2D(neurons, (3, 3), padding=\"same\", input_shape=input_shape))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=-1))\n    model.add(Conv2D(neurons, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=-1))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(dropout_rate))\n\n    # second CONV => RELU => CONV => RELU => POOL layer set\n    model.add(Conv2D(neurons * 2, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=-1))\n    model.add(Conv2D(neurons * 2, (3, 3), padding=\"same\"))\n    model.add(Activation(\"relu\"))\n    model.add(BatchNormalization(axis=-1))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(dropout_rate))\n\n    # first (and only) set of FC => RELU layers, second fc2 doesn't help\n    model.add(Flatten())\n    model.add(Dense(neurons ** 2))\n    model.add(Activation(\"relu\"))  # added?\n    model.add(BatchNormalization())\n    model.add(Dropout(dropout_rate))\n\n    # softmax classifier\n    model.add(Dense(cnum))\n    model.add(Activation(\"softmax\"))\n\n    # return the constructed network architecture\n    return model\n\nX_keras = swing_image_dataset.images\ncnum = len(np.unique(swing_image_dataset.target))\nprint(cnum)\nle = LabelEncoder()\nlabels = le.fit_transform(swing_image_dataset.target)\nlabels = to_categorical(labels)\nINPUT_SHAPE = [30, 30, 3]\nimage_input = Input(shape=(30, 30, 3))\nEPOCHS = 200\nLR = 0.0001 # as low as possible, local minima and time permitting\nBS = 8 # 8 gives great results for these kinds of datasets but is super slow. larger the batch the fastest but more mem\nX_train, X_test, y_train, y_test = train_test_split(np.float32(X_keras), labels, test_size=0.2, random_state=rseed)\nprint(X_train.shape)\n\nX_train = X_train.reshape(X_train.shape[0], *INPUT_SHAPE)\nX_test = X_test.reshape(X_test.shape[0], *INPUT_SHAPE)\n\n# load model without output layer (because golfdb dataset has different labels to imagenet)\n# also input_tensor so that you can specify the resolution and channels (stick to colour)\n# No time to check why this doesn't work so rather just gonna create own mini vgg\n# model = VGG16(input_tensor=image_input, include_top=False, pooling='avg', classes=cnum)\n\nmodel = create_mini_vgg(input_shape=INPUT_SHAPE, cnum=y_train.shape[1], dropout_rate=0.1, neurons=32)\nmodel.compile(optimizer=Adam(learning_rate=LR, decay=LR \/ EPOCHS), loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])\nprint(model.summary())\n# with earlystopping to prevent overtraining\ncallbacks = [\n    EarlyStopping(monitor='val_accuracy', mode='max', patience=10, restore_best_weights=True, verbose=1)\n]\n# With data augmentation to prevent overfitting\ngen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        # rotation_range=15,  # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.05, # Randomly zoom image 0.05\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ntrain_gen = gen.flow(X_train, y_train, batch_size=BS)\n# without augmentation (achieves same as SVM and CATB):\n# H = model.fit(X_train, y_train, batch_size=BS, epochs=EPOCHS, verbose=2, validation_data=(X_test, y_test), callbacks=callbacks)\n# with augmentation\nH = model.fit(train_gen, batch_size=BS, epochs=EPOCHS, verbose=2, validation_data=(X_test, y_test), callbacks=callbacks)\n\ny_pred = model.predict(X_test)\ny_test, y_pred = np.argmax(y_test, axis=-1), np.argmax(y_pred, axis=1) #magical fix\n\nprint(metrics.classification_report(y_test, y_pred, target_names=swing_image_dataset.target_names, digits=3))\naccuracy_cnn = metrics.accuracy_score(y_test, y_pred)\nf1_cnn = metrics.f1_score(y_test, y_pred, average='weighted')\nprecision_cnn = metrics.precision_score(y_test, y_pred, average='weighted')\nrecall_cnn = metrics.recall_score(y_test, y_pred, average='weighted')\nprint(\"Accuracy\", accuracy_cnn * 100)\naccuracy.append(accuracy_cnn * 100)\nf1_score.append(f1_cnn * 100)\nprecision_score.append(precision_cnn * 100)\nrecall_score.append(recall_cnn * 100)\n# copy pasta ends here","7936d915":"!pip install keract\nfrom keract import get_activations, display_heatmaps, display_activations\nkeract_inputs = X_test[0:1]\nkeract_targets = y_test[0:1]\nactivations = get_activations(model, keract_inputs)\ndisplay_activations(activations, cmap=\"gray\", directory='Activations\/', fig_size=(9, 9), save=True)\ndisplay_heatmaps(activations, keract_inputs, directory='Heatmaps\/', save=True)","d8a72e4e":"\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(20,15))\n# plt.plot( H.history[\"loss\"], label = [\"train_loss\"])\n# plt.plot( H.history[\"val_loss\"], label = [\"val_loss\"])\nplt.plot( H.history[\"accuracy\"], label = \"Training accuracy\", color='blue', linewidth=4)\nplt.plot( H.history[\"val_accuracy\"], label = \"Validation accuracy\", color='red', linewidth=4)\n\n# plt.title(\"Training loss and Accuracy\")\nplt.ylim((0,1))\nplt.xlabel(\"Epochs\", fontsize=35)\nplt.ylabel(\"Accuracy\", fontsize=35)\n# plt.legend()\nplt.legend(fontsize=35)\nplt.tick_params(labelsize=35)\nplt.savefig(\"pruned_VGGNet_without_cropping.png\")\n\n","2b43f564":"print(accuracy)\nprint(f1_score)\nprint(precision_score)\nprint(recall_score)","b9d99440":"import matplotlib.pyplot as plt\nfig = plt.figure(figsize=(20, 10))\ndata = [accuracy, f1_score]\nkey = ['Accuracy', 'F1-Score']\nlabels = ['LinearSVM', 'CatBoost', 'Decision Tree', 'Random Forest', 'KNN', 'CNN']\nbp_dict = plt.bar( labels, list(map(float, data[0])), align='edge', width=-0.2, color=['green'])\nbp_dict = plt.bar( labels, list(map(float, data[1])), align='edge', width=0.2, color=['blue'])\nplt.ylabel(\"Score(%)\", fontsize=30)\nplt.xlabel(\"Classification Model\", fontsize=30)\nplt.legend(key, fontsize=26)\nplt.title(\"Experiment 2: Accuracy and F1 Scores\", fontsize=34)\nplt.ylim((60,100))\nplt.tick_params(labelsize=26)\nplt.grid()\nplt.show()\nplt.savefig(\"Exp2_results.jpg\")","a1bda153":"### Visualise Results","4369bf9c":"#### CNN","87bf31a3":"#### Decision Tree Classifier","4e01d27f":"#### KNN","576489e0":"### Dimensionality Reduction \n#### LDA using 7 components","6cd891fb":"### Load Dataset of cropped golfers","5e6afe7c":"#### CatBoost","927a5b7e":"### Classification Models\n#### LinearSVM","6e15828e":"### Experiment 2 used the entire uncropped swing event images to perform final classification using the following models: \n* LinearSVM\n* CatBoost\n* Decision Tree Classifier \n* Random Forests\n* K-Nearest Neighbor\n\nLinearDiscriminantAnalysis dimensionality reduction is applied using 7 components. ","75e31c42":"#### Random Forests"}}