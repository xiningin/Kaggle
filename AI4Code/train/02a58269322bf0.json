{"cell_type":{"28265f29":"code","ac26283f":"code","2ebd59d4":"code","a78528da":"code","6b0ca92e":"code","ef7dbdeb":"code","66ea5404":"code","548798e4":"code","9466a5c6":"code","551b7aa5":"code","5f451e0a":"code","29e4a69f":"code","2fb9b811":"code","47aae042":"code","1e6d6881":"code","2e61c9c0":"code","0439bb5e":"code","c1e745e0":"code","dfa82841":"code","87d6dfea":"code","d1e73504":"code","07184f91":"code","486e94cc":"code","4da6d3f4":"code","8466d544":"code","f68f49cb":"markdown","9961a21f":"markdown","fd4799a9":"markdown","6d2d2848":"markdown","6a8fccdd":"markdown","b66adcd9":"markdown","b3d92ee2":"markdown","756e7210":"markdown","e9c0ad54":"markdown","9e2b099b":"markdown","281be502":"markdown","4fd2e7d3":"markdown","44d6c65b":"markdown","90625f3a":"markdown"},"source":{"28265f29":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt","ac26283f":"test=pd.read_csv('..\/input\/test.csv').set_index('PassengerId')\ntrain=pd.read_csv('..\/input\/train.csv').set_index('PassengerId')","2ebd59d4":"train.drop(columns=['Ticket', 'Cabin', 'Name'], inplace=True, errors='ignore')\ntest.drop(columns=['Ticket', 'Cabin', 'Name'], inplace=True, errors='ignore')","a78528da":"train['Sex']=train['Sex'].apply(lambda d: 1 if d=='female' else 0)\ntest['Sex']=test['Sex'].apply(lambda d: 1 if d=='female' else 0)","6b0ca92e":"train['Embarked'].value_counts()","ef7dbdeb":"train['EmbarkedS']=train['Embarked'].apply(lambda d: 1 if d=='S' else 0)\ntrain['EmbarkedC']=train['Embarked'].apply(lambda d: 1 if d=='C' else 0)\ntrain['EmbarkedQ']=train['Embarked'].apply(lambda d: 1 if d=='Q' else 0)\ntrain.drop(columns='Embarked', inplace=True)","66ea5404":"test['EmbarkedS']=test['Embarked'].apply(lambda d: 1 if d=='S' else 0)\ntest['EmbarkedC']=test['Embarked'].apply(lambda d: 1 if d=='C' else 0)\ntest['EmbarkedQ']=test['Embarked'].apply(lambda d: 1 if d=='Q' else 0)\ntest.drop(columns='Embarked', inplace=True)","548798e4":"train.fillna(train.mean(), inplace=True)\ntest.fillna(test.mean(), inplace=True)","9466a5c6":"X_train=train.drop(columns='Survived')\ny_train=train['Survived']","551b7aa5":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis","5f451e0a":"modelos = [('neigh',KNeighborsClassifier()),\n           ('svc',SVC()),\n           ('Gauss',GaussianProcessClassifier()),\n           ('dTree',DecisionTreeClassifier()),\n           ('forest',RandomForestClassifier(n_estimators=100)),\n           ('adaBoost',AdaBoostClassifier()),\n           ('gaussNB',GaussianNB()),\n           ('QDA',QuadraticDiscriminantAnalysis()),\n           ('neural',MLPClassifier(activation='tanh', solver='lbfgs', alpha=0.001, learning_rate='adaptive', learning_rate_init=0.01))]","29e4a69f":"model_scores = {}","2fb9b811":"from sklearn.model_selection import cross_val_score","47aae042":"for modelo in modelos:\n    score = abs(cross_val_score(modelo[1], X_train, y_train, cv=10, scoring='neg_mean_squared_error', n_jobs=-1)).mean()\n    model_scores[modelo[0]]=score","1e6d6881":"%matplotlib inline\nlst = sorted(model_scores.items())\nx, y = zip(*lst)\nplt.plot(x,y)\nplt.show()","2e61c9c0":"forest=RandomForestClassifier(n_estimators=100)\nadaBoost=AdaBoostClassifier()\nneural=MLPClassifier(activation='tanh', solver='lbfgs', alpha=0.001, learning_rate='adaptive', learning_rate_init=0.01)","0439bb5e":"forest.fit(X_train, y_train);\nadaBoost.fit(X_train, y_train);\nneural.fit(X_train, y_train);","c1e745e0":"forestp=forest.predict(test)\nadap=adaBoost.predict(test)\nneuralp=neural.predict(test)","dfa82841":"predicciones=pd.DataFrame(data={'PassengerId':test.index, 'forest':forestp, 'ada':adap, 'neural':neuralp}).set_index('PassengerId')","87d6dfea":"predicciones['Survived']=predicciones.apply(lambda s: round(s.mean()), axis=1)","d1e73504":"predicciones.drop(columns=['forest', 'ada', 'neural'], inplace=True)","07184f91":"importance_features = pd.DataFrame({'Ada Boost':adaBoost.feature_importances_,\n                                    'Random Forest':forest.feature_importances_}, index=X_train.columns)","486e94cc":"plt.barh(importance_features.sort_values(by='Ada Boost').index, importance_features['Ada Boost'].sort_values())\nplt.title('Ada Boost')\nplt.show()","4da6d3f4":"plt.barh(importance_features.sort_values(by='Random Forest').index, importance_features['Random Forest'].sort_values())\nplt.title('Random Forest')\nplt.show()","8466d544":"predicciones.to_csv('pred.csv')","f68f49cb":"Podemos hacer una tabla con los resultados, y para que nuestros resultados sean mejores, vamos a sacar el promedio de las tres predicciones.","9961a21f":"# Predicciones de sobrevivientes en el Titanic","fd4799a9":"Solamente para agregar un poco m\u00e1s, podemos ver cu\u00e1les son las caracter\u00edsticas m\u00e1s importantes que tuvieron cada uno de los modelos. \n\n*Nota: En la red neuronal, esto no se puede hacer.*","6d2d2848":"## Aprendizaje de m\u00e1quina","6a8fccdd":"Y por \u00faltimo vamos a regresar la tabla de predicciones para Kaggle.","b66adcd9":"Primero vamos a importar todas las las librerias necesarias para limpiar los datos. Vamos a utilizar principalmente Pandas para manejar todas las tablas y matplotlib para las gr\u00e1ficas.","b3d92ee2":"En la columna \"Embarked\" existen tres diferentes valores: S, C y Q. Para poder utilizar esto vamos a utilizar una t\u00e9cnica llamada One Hot Encoding, esto va a hacer tres nuevas columnas con valores booleanos, para que el algoritmo de ML pueda utilizar esta feature.","756e7210":"Para comenzar a limpiar los datos, vamos a quitar las columnas que no son necesarias: el n\u00famero de ticket, el n\u00famero de cabina y el nombre del pasajero.","e9c0ad54":"Por \u00faltimo, es importante llenar los valores que no existen con algo. En este caso llenaremos esos valores con el promedio de la columna.","9e2b099b":"Despu\u00e9s, tenemos que empezar a cambiar los valores a booleanos. En el sexo, podemos poner un 0 para los hombre y un 1 para las mujeres.","281be502":"Viendo que los mejores modelos son Random Forest, Ada Boost y la red neuronal, utilizaremos esos tres m\u00e9todos para hacer las predicciones.","4fd2e7d3":"Utilizaremos una t\u00e9cnica llamada cross validation para ver qu\u00e9 algoritmo funciona mejor con los d\u00e1tos. Lo que hace esta t\u00e9cnica es dividir los datos en dos partes, una para entrenar y una para probar sus prediciones, hace esto varias veces, y da los el error que tiene el modelo. Para que sea m\u00e1s f\u00e1cil, veremos el error promedio de las 10 veces que ha a entrenar al modelo y probarlo. Despu\u00e9s vamos a graficar los diferentes modelos para ver cu\u00e1l es el mejor.","44d6c65b":"Para saber qu\u00e9 algoritmo es mejor se pueden probar todos, porque el dataset no es muy grande y no debe de tardar mucho entrenar a todos los modelos.\n\nEn este caso, utilizaremos nueve diferentes clasificadores, de los cuales elegiremos a los tres mejores para las predicciones reales.","90625f3a":"## Limpieza de d\u00e1tos"}}