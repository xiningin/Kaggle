{"cell_type":{"826455ef":"code","15e0ef4f":"code","e6273f31":"code","050a3815":"code","af1ab934":"code","d9f5d2fc":"code","397125b9":"code","ad290c3a":"code","52056456":"code","c028c228":"code","797f9db1":"code","c57b562f":"code","0abea89c":"code","c78cb25e":"code","622afb35":"code","a75ca7f6":"code","57e99d26":"code","2c458491":"code","6837a39d":"code","9a07438b":"code","4178d9af":"code","4d7af292":"code","0cded8d1":"code","7e0e47e5":"code","0aa35324":"code","6ac0686d":"code","3e1d8171":"code","22b72564":"code","7a4ff7a7":"code","9a7b8cb0":"code","faf79130":"code","6351fbf3":"code","6d45f69b":"markdown","693b5f4b":"markdown","f21988ca":"markdown","29a15f8b":"markdown","67624cee":"markdown","e4b0e962":"markdown","780c02cc":"markdown","6f2246af":"markdown","779c98da":"markdown","b77b5c54":"markdown","1da519b3":"markdown","18a14928":"markdown"},"source":{"826455ef":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt","15e0ef4f":"# machine learning\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","e6273f31":"exemplo=pd.read_csv('\/kaggle\/titanic\/gender_submission.csv')\ndata=pd.read_csv('\/home\/manu\/Programacion\/kaggle\/titanic\/train.csv',index_col='PassengerId')\ndataTest=pd.read_csv('\/home\/manu\/Programacion\/kaggle\/titanic\/test.csv',index_col='PassengerId')\ndata.head(5)","050a3815":"data.describe(), data.info()","af1ab934":"data.drop(['Cabin'],axis=1,inplace=True)\ndataTest.drop(['Cabin'],axis=1,inplace=True)\ndata.drop(['Ticket'],axis=1,inplace=True)\ndataTest.drop(['Ticket'],axis=1,inplace=True)\ndata.drop(['Name'],axis=1,inplace=True)\ndataTest.drop(['Name'],axis=1,inplace=True)","d9f5d2fc":"g = sns.FacetGrid(data, col='Pclass',row='Sex',hue='Survived')\ng.map(plt.hist, 'Age', alpha=0.5)\nplt.legend()","397125b9":"data.Sex=data.Sex.map(lambda x:1 if x=='female' else 0)\ndataTest.Sex=dataTest.Sex.map(lambda x:1 if x=='female' else 0)","ad290c3a":"#para train_df\nfor sexo in range(2):\n    for clase in range(3):\n        idade=data[(data.Sex==sexo) & (data.Pclass==clase+1)].Age.dropna()\n        mediana=idade.median()\n        print(\"\\n sexo: \"+str(sexo)+\" clase= \"+str(clase+1)+\" -> Mediana:\"+str(mediana))\n        data.loc[(data.Age.isnull()) & (data.Sex == sexo) \n                    & (data.Pclass == clase+1),'Age']=mediana\ndata.Age=data.Age.astype(int)\n\nprint(\"_________________________\")\n#para test_df\nfor sexo in range(2):\n    for clase in range(3):\n        idade=dataTest[(dataTest.Sex==sexo) & (dataTest.Pclass==clase+1)].Age.dropna()\n        mediana=idade.median()\n        print(\"\\n sexo: \"+str(sexo)+\" clase= \"+str(clase+1)+\" -> Mediana:\"+str(mediana))\n        dataTest.loc[(dataTest.Age.isnull()) & (dataTest.Sex == sexo) \n                    & (dataTest.Pclass == clase+1),'Age']=mediana                \ndataTest.Age=dataTest.Age.astype(int)","52056456":"data['AgeBand'] = pd.cut(data['Age'], 5)\ndata[['AgeBand', 'Survived']].groupby(['AgeBand'], \n                              as_index=False).mean().sort_values(by='AgeBand', ascending=True)\n","c028c228":"data.Age=data.Age.map(lambda x:0 if x<=16 else 1 if x<=32 \n                      else 2 if x<=48 else 3 if x <= 64 else 4)\ndata.drop(['AgeBand'],axis=1,inplace=True)\n\ndataTest['AgeBand'] = pd.cut(dataTest['Age'], 5)\ndataTest.Age=dataTest.Age.map(lambda x:0 if x<=16 else 1 if x<=32 \n                      else 2 if x<=48 else 3 if x <= 64 else 4)\ndataTest.drop(['AgeBand'],axis=1,inplace=True)","797f9db1":"data.head()","c57b562f":"data['ViaxaSo']=data['SibSp']+data['Parch']\ndata.ViaxaSo=data.ViaxaSo.map(lambda x:1 if x==0 else 0)\ndataTest['ViaxaSo']=dataTest['SibSp']+dataTest['Parch']\ndataTest.ViaxaSo=dataTest.ViaxaSo.map(lambda x:1 if x==0 else 0)\ndata.drop(['SibSp','Parch'],axis=1,inplace=True)\ndataTest.drop(['SibSp','Parch'],axis=1,inplace=True)","0abea89c":"g = sns.FacetGrid(data, col='ViaxaSo')\ng.map(plt.hist, 'Survived', alpha=0.5)\n","c78cb25e":"g = sns.FacetGrid(data, col='Survived')\ng.map(plt.hist, 'Embarked', alpha=0.5)\n","622afb35":"data.loc[data.Embarked.isnull(),'Embarked']='C'\ndataTest.loc[dataTest.Embarked.isnull(),'Embarked']='C'\ndata['Embarked'] = data['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)\ndataTest['Embarked'] = dataTest['Embarked'].map( {'S': 0, 'C': 1, 'Q': 2} ).astype(int)","a75ca7f6":"data['Fare']=data['Fare'].fillna(data['Fare'].dropna().median())\ndata['FareBands']=pd.qcut(data['Fare'],4)\ndataTest['Fare']=dataTest['Fare'].fillna(dataTest['Fare'].dropna().median())\ndataTest['FareBands']=pd.qcut(dataTest['Fare'],4)\ndata.head(5)","57e99d26":"data.FareBands.value_counts()","2c458491":"data.Fare=data.Fare.map(lambda x:0 if x<=7.91 else 1 if x<=14.454 \n                      else 2 if x<=31.0 else 3 )\ndata.drop(['FareBands'],axis=1,inplace=True)\n\ndataTest.Fare=dataTest.Fare.map(lambda x:0 if x<=7.91 else 1 if x<=14.454 \n                      else 2 if x<=31.0 else 3 )\ndataTest.drop(['FareBands'],axis=1,inplace=True)\ndata.head(5)","6837a39d":"g=sns.FacetGrid(data,col='Survived',row='Pclass')\ng.map(plt.hist,'Fare')","9a07438b":"X_train = data.drop(\"Survived\", axis=1)\nY_train = data[\"Survived\"]\nX_test  = dataTest\nX_train.shape, Y_train.shape, X_test.shape","4178d9af":"# Logistic Regression\n\nlogreg = LogisticRegression()\nlogreg.fit(X_train, Y_train)\nY_pred = logreg.predict(X_test)\nacc_log = round(logreg.score(X_train, Y_train) * 100, 2)\nacc_log","4d7af292":"coeff_df = pd.DataFrame(data.columns.delete(0))\ncoeff_df.columns = ['Feature']\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","0cded8d1":"# Support Vector Machines\n\nsvc = SVC()\nsvc.fit(X_train, Y_train)\nY_pred = svc.predict(X_test)\nacc_svc = round(svc.score(X_train, Y_train) * 100, 2)\nacc_svc","7e0e47e5":"knn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(X_train, Y_train)\nY_pred = knn.predict(X_test)\nacc_knn = round(knn.score(X_train, Y_train) * 100, 2)\nacc_knn","0aa35324":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(X_train, Y_train)\nY_pred = gaussian.predict(X_test)\nacc_gaussian = round(gaussian.score(X_train, Y_train) * 100, 2)\nacc_gaussian","6ac0686d":"# Perceptron\n\nperceptron = Perceptron()\nperceptron.fit(X_train, Y_train)\nY_pred = perceptron.predict(X_test)\nacc_perceptron = round(perceptron.score(X_train, Y_train) * 100, 2)\nacc_perceptron","3e1d8171":"# Linear SVC\n\nlinear_svc = LinearSVC()\nlinear_svc.fit(X_train, Y_train)\nY_pred = linear_svc.predict(X_test)\nacc_linear_svc = round(linear_svc.score(X_train, Y_train) * 100, 2)\nacc_linear_svc","22b72564":"# Stochastic Gradient Descent\n\nsgd = SGDClassifier()\nsgd.fit(X_train, Y_train)\nY_pred = sgd.predict(X_test)\nacc_sgd = round(sgd.score(X_train, Y_train) * 100, 2)\nacc_sgd","7a4ff7a7":"# Decision Tree\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(X_train, Y_train)\nY_pred = decision_tree.predict(X_test)\nacc_decision_tree = round(decision_tree.score(X_train, Y_train) * 100, 2)\nacc_decision_tree","9a7b8cb0":"# Random Forest\n\nrandom_forest = RandomForestClassifier(n_estimators=1000, max_depth=20)\nrandom_forest.fit(X_train, Y_train)\nY_pred = random_forest.predict(X_test)\nrandom_forest.score(X_train, Y_train)\nacc_random_forest = round(random_forest.score(X_train, Y_train) * 100, 2)\nacc_random_forest","faf79130":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', 'Perceptron', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree'],\n    'Score': [acc_svc, acc_knn, acc_log, \n              acc_random_forest, acc_gaussian, acc_perceptron, \n              acc_sgd, acc_linear_svc, acc_decision_tree]})\nmodels.sort_values(by='Score', ascending=False)","6351fbf3":"submit=pd.DataFrame({'Survived':Y_pred}, index=dataTest.index)\nsubmit.to_csv('\/home\/manu\/Programacion\/kaggle\/titanic\/TreeRandomForestFinal.csv')","6d45f69b":"Before, we need to make numerical the sex var (male=0, female=1)","693b5f4b":"Divide in 5 bands the age var","f21988ca":"# Titanic Competition","29a15f8b":"I will fill the nan age with the median of the age of each pclass and sex group ","67624cee":"Embarked var is correlated? YES:","e4b0e962":"## Upgrade of my works based in this notebook: \nhttps:\/\/www.kaggle.com\/startupsci\/titanic-data-science-solutions\/notebook ","780c02cc":"Fare is correlated? YES","6f2246af":"Choose in:\n\nLogistic Regression\nKNN or k-Nearest Neighbors\nSupport Vector Machines\nNaive Bayes classifier\nDecision Tree\nRandom Forrest\nPerceptron\nArtificial neural network\nRVM or Relevance Vector Machine","779c98da":"There are three evident features for the survival: Pclass, Sex and Age, but the age has a lot of nan \nCabin var has a lot of nan and has to be dropped (not correlated with survival)\nTicket is very irregular and will be dropped too.\nName will be dropped, although title can be important (but i suppose that is in age and sex var)\n","b77b5c54":"## Model, predict and solve\u00b6","1da519b3":"Columns SibSp and Parch talk about a familiar relationship.\nWe can sum them, and if a row is zero then the passanger travel alone","18a14928":"Last, we cur the Fare var in 4 bands"}}