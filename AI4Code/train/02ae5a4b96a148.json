{"cell_type":{"fdfdd0d1":"code","dabf853c":"code","1259d857":"code","c1d7462f":"code","b048e956":"code","96f6e9ac":"code","b8ccc9eb":"code","983b2ad6":"code","0c7b380b":"code","b4d72a01":"code","39ee4388":"code","43900445":"code","1fea5c04":"code","22a0caba":"code","340537b3":"code","d75412a8":"code","42bf5b10":"code","7f843540":"code","68399376":"code","8dc7b4a8":"code","dcb8daf7":"code","1a094c80":"code","3e1c3cec":"code","aa7b5b2d":"code","b9320a86":"code","6b003356":"code","30881558":"code","aae49d07":"code","e461cd12":"code","cef3bf7f":"code","a331f0ee":"code","6ff04e8e":"code","0a17a423":"code","666c772a":"code","1c42f2b6":"code","1cee2694":"code","01fe722a":"code","7414347d":"code","509d6f42":"code","8935463f":"code","b430c5d2":"code","e2cb03a5":"code","b1e5e0bb":"code","46de0b60":"code","bfe6ce19":"code","3a336baa":"code","6d337508":"code","56eeca64":"code","b46e1c5e":"code","370984d7":"code","ba5f119d":"code","fc4127e0":"code","bfb9633c":"code","e460dd81":"code","cd0bbc02":"code","3b72d928":"code","c6d1901c":"code","9cbdf54b":"code","19aef073":"code","d336b354":"code","d15cd926":"markdown","810edf6a":"markdown","5b9969b5":"markdown","7691af77":"markdown","7a93e632":"markdown","79278d18":"markdown","939e247b":"markdown","091b077c":"markdown","9362ebca":"markdown","89a08ca7":"markdown","36402d03":"markdown","e848361d":"markdown","8e20eb3e":"markdown","0f225943":"markdown","283fc0e0":"markdown","dca90edd":"markdown","96ab443e":"markdown","24a98bcf":"markdown","3b5a1cbc":"markdown","5f67b13e":"markdown","d3c60006":"markdown","d4a75aa5":"markdown","ce0cbe46":"markdown","32da16d4":"markdown","4e6f8e1e":"markdown","e15d1227":"markdown","0928fff8":"markdown","da255e72":"markdown","4d22f902":"markdown","38c3ec08":"markdown","0d9ab921":"markdown","5995c194":"markdown","5bd8ef66":"markdown","be860608":"markdown","eb774728":"markdown","9773b92a":"markdown","1a052a06":"markdown","bd01bfbb":"markdown","505cdeef":"markdown","593d6200":"markdown"},"source":{"fdfdd0d1":"import pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sb\nimport os\n\nprint(\"Version Pandas\", pd.__version__)\nprint(\"Version Matplotlib\", matplotlib.__version__)\nprint(\"Version Numpy\", np.__version__)\nprint(\"Version Seaborn\", sb.__version__)\n\nos.listdir('..\/input\/tabular-playground-series-apr-2021\/')","dabf853c":"BASE_DIR = '..\/input\/tabular-playground-series-apr-2021\/'\ntrain = pd.read_csv(BASE_DIR + 'train.csv')\ntest = pd.read_csv(BASE_DIR + 'test.csv')\nsample_submission = pd.read_csv(BASE_DIR + 'sample_submission.csv')\n\ntrain.shape, test.shape, sample_submission.shape","1259d857":"train.head()","c1d7462f":"test.head()","b048e956":"sample_submission.head()","96f6e9ac":"frames= [train, test]\ntotal_df=pd.concat(frames, sort=False)\nprint('total data shape: ', total_df.shape)\ntotal_df.head()","b8ccc9eb":"total_df.describe(include=[object])","983b2ad6":"total_df.describe(include=[object])","0c7b380b":"total_df.info()","b4d72a01":"total_df_na=total_df.isna().sum()\ntrain_na=train.isna().sum()\ntest_na=test.isna().sum()\n\npd.concat([train_na, test_na, total_df_na], axis=1, sort=False, keys=['Train NA','Test NA','Total NA'])","39ee4388":"total_df.describe()","43900445":"plt.figure(figsize=(6, 4.5))\n\nax= sb.countplot(x='Survived', data=total_df, palette=['#4287f5','#7cd91e'])\n\nplt.xticks(np.arange(2), ['Drowned','Survived'])\nplt.title('Overall survival', fontsize=14)\nplt.xlabel('Survived vs Drowned')\nplt.ylabel('Number of Passendgers')\n\nlabels=(total_df['Survived'].value_counts())\n\nfor i,v in enumerate(labels):\n    ax.text(i, v-40, str(v), horizontalalignment='center', size=14, color='w', fontweight='bold')\n    \nplt.show()","1fea5c04":"total_df['Survived'].value_counts(normalize=True)","22a0caba":"plt.figure(figsize=(15,3))\n\nsb.distplot(total_df[(total_df['Age']>0)].Age, kde_kws={'lw':3}, bins=50)\n\nplt.title('Distribution of passengers age (total data)', fontsize=14)\nplt.xlabel('Age')\nplt.ylabel('Frequency')\n\nplt.tight_layout()","340537b3":"age_distr= pd.DataFrame(total_df['Age'].describe())\nage_distr.transpose()","d75412a8":"plt.figure(figsize=(15,3))\n\nsb.boxplot(y='Survived', x='Age', data=train, palette=['#4287f5','#7cd91e'], fliersize=0, orient='h')\n\nsb.stripplot(y='Survived',x='Age', data=train, linewidth=0.6, palette=['#4287f5','#7cd91e'], orient='h')\nplt.yticks(np.arange(2), ['Drowned','Survived'])\nplt.title('Age distribution grouped by survivng status (train data)', fontsize=14)\nplt.ylabel('Passengers status after the tragedy')\nplt.tight_layout()","42bf5b10":"pd.DataFrame(total_df.groupby('Survived')['Age'].describe())","7f843540":"plt.figure(figsize=(20,6))\n\npalette=sb.cubehelix_palette(5, start=3)\n\nplt.subplot(1,2,1)\nsb.boxplot(x='Pclass', y='Age', data=total_df, palette=palette, fliersize=0)\n\nplt.xticks(np.arange(3), ['1st class','2nd class','3rd class'])\nplt.title('Age distribution grouped by ticket class (total data)', fontsize=16)\nplt.xlabel('Ticket class')\n\nplt.subplot(1,2,2)\n\nage_1_class = total_df[(total_df['Age']>0)&(total_df['Pclass']==1)]\nage_2_class = total_df[(total_df['Age']>0)&(total_df['Pclass']==2)]\nage_3_class = total_df[(total_df['Age']>0)&(total_df['Pclass']==3)]\n\n# Ploting the 3 variables that we create\nsb.kdeplot(age_1_class[\"Age\"], shade=True, color='#eed4d0', label = '1st class')\nsb.kdeplot(age_2_class[\"Age\"], shade=True,  color='#cda0aa', label = '2nd class')\nsb.kdeplot(age_3_class[\"Age\"], shade=True,color='#a2708e', label = '3rd class')\nplt.title('Age distribution grouped by ticket class (total data)',fontsize= 16)\nplt.xlabel('Age')\nplt.xlim(0, 90)\nplt.tight_layout()\nplt.show()","68399376":"pd.DataFrame(total_df.groupby('Pclass')['Age'].describe())","8dc7b4a8":"plt.figure(figsize=(20, 5))\npalette = \"Set3\"\n\nplt.subplot(1, 3, 1)\nsb.boxplot(x = 'Sex', y = 'Age', data = age_1_class,\n     palette = palette, fliersize = 0)\n#sb.stripplot(x = 'Sex', y = 'Age', data = age_1_class,linewidth = 0.6, palette = palette)\nplt.title('1st class Age distribution by Sex',fontsize= 14)\nplt.ylim(-5, 80)\n\nplt.subplot(1, 3, 2)\nsb.boxplot(x = 'Sex', y = 'Age', data = age_2_class,\n     palette = palette, fliersize = 0)\n#sb.stripplot(x = 'Sex', y = 'Age', data = age_2_class,linewidth = 0.6, palette = palette)\nplt.title('2nd class Age distribution by Sex',fontsize= 14)\nplt.ylim(-5, 80)\n\nplt.subplot(1, 3, 3)\nsb.boxplot(x = 'Sex', y = 'Age',  data = age_3_class,\n     order = ['female', 'male'], palette = palette, fliersize = 0)\n#sb.stripplot(x = 'Sex', y = 'Age', data = age_3_class,order = ['female', 'male'], linewidth = 0.6, palette = palette)\nplt.title('3rd class Age distribution by Sex',fontsize= 14)\nplt.ylim(-5, 80)\n\nplt.show()","dcb8daf7":"age_1_class_stat = pd.DataFrame(age_1_class.groupby('Sex')['Age'].describe())\nage_2_class_stat = pd.DataFrame(age_2_class.groupby('Sex')['Age'].describe())\nage_3_class_stat = pd.DataFrame(age_3_class.groupby('Sex')['Age'].describe())\n\npd.concat([age_1_class_stat, age_2_class_stat, age_3_class_stat], axis=0, sort = False, keys = ['1st', '2nd', '3rd'])","1a094c80":"total_df['Cabin']=total_df['Cabin'].str.split('',expand=True)[1]\ntotal_df.loc[total_df['Cabin'].isna(), 'Cabin']='X'","3e1c3cec":"fig = plt.figure(figsize=(20, 5))\n\nax1 = fig.add_subplot(131)\nsb.countplot(x = 'Cabin', data = total_df, palette = \"hls\", order = total_df['Cabin'].value_counts().index, ax = ax1)\nplt.title('Passengers distribution by Cabin',fontsize= 16)\nplt.ylabel('Number of passengers')\n\nax2 = fig.add_subplot(132)\nCabin_by_class = total_df.groupby('Cabin')['Pclass'].value_counts(normalize = True).unstack()\nCabin_by_class.plot(kind='bar', stacked='True',color = ['#eed4d0', '#cda0aa', '#a2708e'], ax = ax2)\nplt.legend(('1st class', '2nd class', '3rd class'), loc=(1.04,0))\nplt.title('Proportion of classes on each Cabin',fontsize= 16)\nplt.xticks(rotation = False)\n\nax3 = fig.add_subplot(133)\nCabin_by_survived = total_df.groupby('Cabin')['Survived'].value_counts(normalize = True).unstack()\nCabin_by_survived = Cabin_by_survived.sort_values(by = 1, ascending = False)\nCabin_by_survived.plot(kind='bar', stacked='True', color=[\"#3f3e6fd1\", \"#85c6a9\"], ax = ax3)\nplt.title('Proportion of survived\/drowned passengers by Cabin',fontsize= 16)\nplt.legend(( 'Drowned', 'Survived'), loc=(1.04,0))\nplt.xticks(rotation = False)\nplt.tight_layout()\n\nplt.show()\n","aa7b5b2d":"total_df['Family_size']=total_df['SibSp']+total_df['Parch']+1\nfamily_size=total_df['Family_size'].value_counts()\nprint('Family size and number of passengers:')\nprint(family_size)","b9320a86":"fig = plt.figure(figsize = (12,4))\n\nax1 = fig.add_subplot(121)\nax = sb.countplot(total_df['Family_size'], ax = ax1)\n\n# calculate passengers for each category\nlabels = (total_df['Family_size'].value_counts())\n# add result numbers on barchart\nfor i, v in enumerate(labels):\n    ax.text(i, v+6, str(v), horizontalalignment = 'center', size = 10, color = 'black')\n    \nplt.title('Passengers distribution by family size')\nplt.ylabel('Number of passengers')\n\nax2 = fig.add_subplot(122)\nd = total_df.groupby('Family_size')['Survived'].value_counts(normalize = True).unstack()\nd.plot(kind='bar', color=[\"#3f3e6fd1\", \"#85c6a9\"], stacked='True', ax = ax2)\nplt.title('Proportion of survived\/drowned passengers by family size (train data)')\nplt.legend(( 'Drowned', 'Survived'), loc=(1.04,0))\nplt.xticks(rotation = False)\n\nplt.tight_layout()","6b003356":"total_df['Family_size_group']=total_df['Family_size'].map(lambda x: 'f_single' if x ==1\n                                                         else('f_usual' if 6>x>=2\n                                                             else('f_big' if 10>x>=6\n                                                                 else('f_large'))))","30881558":"fig = plt.figure(figsize = (14,5))\n\nax1 = fig.add_subplot(121)\nd = total_df.groupby('Family_size_group')['Survived'].value_counts(normalize = True).unstack()\nd = d.sort_values(by = 1, ascending = False)\nd.plot(kind='bar', stacked='True', color = [\"#3f3e6fd1\", \"#85c6a9\"], ax = ax1)\nplt.title('Proportion of survived\/drowned passengers by family size')\nplt.legend(( 'Drowned', 'Survived'), loc=(1.04,0))\n_ = plt.xticks(rotation=False)\n\n\nax2 = fig.add_subplot(122)\nd2 = total_df.groupby('Family_size_group')['Pclass'].value_counts(normalize = True).unstack()\nd2 = d2.sort_values(by = 1, ascending = False)\nd2.plot(kind='bar', stacked='True', color = ['#eed4d0', '#cda0aa', '#a2708e'], ax = ax2)\nplt.legend(('1st class', '2nd class', '3rd class'), loc=(1.04,0))\nplt.title('Proportion of 1st\/2nd\/3rd ticket class in family group size')\n_ = plt.xticks(rotation=False)\n\nplt.tight_layout()","aae49d07":"ax = sb.countplot(total_df['Pclass'], palette = ['#eed4d0', '#cda0aa', '#a2708e'])\n# calculate passengers for each category\nlabels = (total_df['Pclass'].value_counts(sort = False))\n# add result numbers on barchart\nfor i, v in enumerate(labels):\n    ax.text(i, v+2, str(v), horizontalalignment = 'center', size = 12, color = 'black', fontweight = 'bold')\n    \n    \nplt.title('Passengers distribution by Pclass')\nplt.ylabel('Number of passengers')\nplt.tight_layout()","e461cd12":"fig = plt.figure(figsize=(14, 5))\n\nax1 = fig.add_subplot(121)\nsb.countplot(x = 'Pclass', hue = 'Survived', data = total_df, palette=[\"#3f3e6fd1\", \"#85c6a9\"], ax = ax1)\nplt.title('Number of survived\/drowned passengers by class (train data)')\nplt.ylabel('Number of passengers')\nplt.legend(( 'Drowned', 'Survived'), loc=(1.04,0))\n_ = plt.xticks(rotation=False)\n\nax2 = fig.add_subplot(122)\nd = total_df.groupby('Pclass')['Survived'].value_counts(normalize = True).unstack()\nd.plot(kind='bar', stacked='True', ax = ax2, color =[\"#3f3e6fd1\", \"#85c6a9\"])\nplt.title('Proportion of survived\/drowned passengers by class (train data)')\nplt.legend(( 'Drowned', 'Survived'), loc=(1.04,0))\n_ = plt.xticks(rotation=False)\n\nplt.tight_layout()","cef3bf7f":"sb.catplot(x = 'Pclass', hue = 'Survived', col = 'Sex', kind = 'count', data = total_df , palette=[\"#3f3e6fd1\", \"#85c6a9\"])\n\nplt.tight_layout()","a331f0ee":"fig = plt.figure(figsize = (15,4))\n\nax1 = fig.add_subplot(131)\npalette = sb.cubehelix_palette(5, start = 2)\nax = sb.countplot(total_df['Embarked'], palette = palette, order = ['C', 'Q', 'S'], ax = ax1)\nplt.title('Number of passengers by Embarked')\nplt.ylabel('Number of passengers')\n\n# calculate passengers for each category\nlabels = (total_df['Embarked'].value_counts())\nlabels = labels.sort_index()\n# add result numbers on barchart\nfor i, v in enumerate(labels):\n    ax.text(i, v+10, str(v), horizontalalignment = 'center', size = 10, color = 'black')\n    \n\nax2 = fig.add_subplot(132)\nsurv_by_emb = total_df.groupby('Embarked')['Survived'].value_counts(normalize = True)\nsurv_by_emb = surv_by_emb.unstack().sort_index()\nsurv_by_emb.plot(kind='bar', stacked='True', color=[\"#3f3e6fd1\", \"#85c6a9\"], ax = ax2)\nplt.title('Proportion of survived\/drowned passengers by Embarked (train data)')\nplt.legend(( 'Drowned', 'Survived'), loc=(1.04,0))\n_ = plt.xticks(rotation=False)\n\n\nax3 = fig.add_subplot(133)\nclass_by_emb = total_df.groupby('Embarked')['Pclass'].value_counts(normalize = True)\nclass_by_emb = class_by_emb.unstack().sort_index()\nclass_by_emb.plot(kind='bar', stacked='True', color = ['#eed4d0', '#cda0aa', '#a2708e'], ax = ax3)\nplt.legend(('1st class', '2nd class', '3rd class'), loc=(1.04,0))\nplt.title('Proportion of clases by Embarked')\n_ = plt.xticks(rotation=False)\n\nplt.tight_layout()","6ff04e8e":"sb.catplot(x=\"Embarked\", y=\"Fare\", kind=\"violin\", inner=None,\n            data=total_df, height = 6, palette = palette, order = ['C', 'Q', 'S'])\nplt.title('Distribution of Fare by Embarked')\nplt.tight_layout()","0a17a423":"pd.DataFrame(total_df.groupby('Embarked')['Fare'].describe())","666c772a":"fig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sb.distplot(total_df['Fare'], color='r', label='Skewness : {:.2f}'.format(total_df['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","1c42f2b6":"fare_map = total_df[['Fare', 'Pclass']].dropna().groupby('Pclass').median().to_dict()\ntotal_df['Fare'] = total_df['Fare'].fillna(total_df['Pclass'].map(fare_map['Fare']))\n\ntotal_df['Fare'] = total_df['Fare'].map(lambda i: np.log(i) if i > 0 else 0)\nfig, ax = plt.subplots(1, 1, figsize=(8, 8))\ng = sb.distplot(total_df['Fare'], color='b', label='Skewness : {:.2f}'.format(total_df['Fare'].skew()), ax=ax)\ng = g.legend(loc='best')","1cee2694":"total_df.isna().sum()","01fe722a":"fig, ax=plt.subplots(1, 3, figsize=(17,5))\nfeature_lst=['Pclass','Age','Fare','Sex','Family_size']\n\ncorr=total_df[feature_lst].corr()\n\nmask=np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)]=True\n\nfor idx, method in enumerate(['pearson','kendall','spearman']):\n    sb.heatmap(total_df[feature_lst].corr(method=method), ax=ax[idx],\n              square=True, annot=True, fmt='.2f', center=0, linewidth=2,\n              cbar=False, cmap=sb.diverging_palette(240, 10, as_cmap=True),\n        mask=mask)\n    ax[idx].set_title(f'{method.capitalize()} Correlation', loc='left', fontweight='bold')\n    \nplt.show()","7414347d":"age_map= total_df[['Age','Pclass']].dropna().groupby('Pclass').median().to_dict()\ntotal_df['Age']=total_df['Age'].fillna(total_df['Pclass'].map(age_map['Age']))","509d6f42":"print('Embarked has ', sum(total_df['Embarked'].isnull()), ' Null values')","8935463f":"total_df['Embarked'] = total_df['Embarked'].fillna('S')","b430c5d2":"total_df","e2cb03a5":"total_df['Name'] = total_df['Name'].map(lambda x: x.split(',')[0])","b1e5e0bb":"total_df['Ticket'] = total_df['Ticket'].fillna('X').map(lambda x:str(x).split()[0] if len(str(x).split()) > 1 else 'X')","46de0b60":"total_df","bfe6ce19":"total_df.drop(['PassengerId','Name','Family_size_group','Family_size'], axis=1, inplace=True)\ntotal_df.shape","3a336baa":"total_df['Sex']=total_df['Sex'].map({'female':0, 'male':1})\ntotal_df=pd.get_dummies(total_df, columns=['Embarked'], prefix='Embarked')\ntotal_df=pd.get_dummies(total_df, columns=['Cabin'], prefix='Cabin')\ntotal_df=pd.get_dummies(total_df, columns=['Ticket'], prefix='Ticket')\n#total_df=pd.get_dummies(total_df, columns=['Family_size_group'], prefix='Family_size_group')","6d337508":"total_df","56eeca64":"X = total_df[:train.shape[0]]\nprint(\"X Shape is:\", X.shape)\ny = X['Survived']\nX.drop(['Survived'], axis=1, inplace=True)\ntest_data = total_df[train.shape[0]:].drop(columns=['Survived'])\ntest_data.info()","b46e1c5e":"from sklearn.model_selection import train_test_split\n\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3, random_state=42)\n#_train, X_valid, y_train, y_valid = train_test_split(X, y, test_size = 0.3, stratify = X[['Pclass']], random_state=42)\nX_train.shape, X_valid.shape, y_train.shape, y_valid.shape","370984d7":"!pip install catboost","ba5f119d":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import accuracy_score,roc_auc_score, f1_score\nfrom catboost import CatBoostClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import model_selection","fc4127e0":"gbc_params = {\n    'max_depth': int(round(7.18465375161774)),\n  'max_features': 0.4861929134696539,\n  'min_samples_leaf': int(round(113.13022692803058)),\n  'min_samples_split': int(round(8.386778166939953))\n}\n\nlgbm_params = {\n    'colsample_bytree': 0.6283725788215941,\n  'max_bin': int(round(15.826197551963968)),\n  'max_depth': int(round(39.32209311790955)),\n  'min_child_weight': 44.95339851660889,\n  'min_split_gain': 0.04358718365142237,\n  'num_leaves': int(round(24.715504910160405)),\n  'reg_alpha': 0.4127198530404361,\n  'reg_lambda': 0.0006949333245371281,\n  'subsample': 0.7192205961769677,\n  'subsample_freq': int(round(13.984681107001574))\n}\n\ncb_params  = {\n    'bagging_temperature': 534.445170361156,\n  'border_count': int(round(230.32755580650806)),\n  'depth': int(round(5.969930611242375)),\n  'learning_rate': 0.01966964700090523,\n  'min_data_in_leaf': 2.208728103621775\n}\n\nxgb_params  = {\n    'colsample_bynode': 0.2816652230511576,\n   'colsample_bytree': 0.6123746062455153,\n   'learning_rate': 0.04706823512500192,\n   'max_bin': int(round(118.8222831831757)),\n   'max_depth': int(round(6.3341943151448135)),\n   'min_child_weight': 25.890720015058704,\n   'subsample': 0.9115493169826735\n}","bfb9633c":"gbc = GradientBoostingClassifier(**gbc_params)\nlgbm = LGBMClassifier(**lgbm_params)\ncb = CatBoostClassifier(**cb_params)\nxgb = XGBClassifier(**xgb_params)\n\nmlr= LogisticRegression()","e460dd81":"from mlens.ensemble import BlendEnsemble","cd0bbc02":"X_train.info()","3b72d928":"%%time\nblend= BlendEnsemble(n_jobs=-1, test_size=0.5, random_state=17)\nbaseModels=[lgbm, gbc, cb]\nblend.add(baseModels)\n\nblend.add_meta(mlr)\nprint(\"Fitting Blending ...\")\ndisplay(blend.fit(X_train, y_train))\nprint(\"done.\")","c6d1901c":"#test= test.drop('Name', axis=1)\n#test.info()","9cbdf54b":"pred= blend.predict(test_data).astype(int)\npred_df=pd.DataFrame(pred)\npred_df[0]","19aef073":"sklearn_submission = pd.read_csv(BASE_DIR + 'sample_submission.csv')\nsklearn_submission['Survived']= pred_df[0]\nsklearn_submission","d336b354":"sklearn_submission.to_csv('Scikit Learn Submission.csv', index=False)\nsklearn_submission.head()","d15cd926":"# Feature Engineering","810edf6a":"### 5) Embarked","5b9969b5":"# Scikit Learn","7691af77":"### 6) Drop\n- PassengerId, Name, SibSp, Parch, Cabin","7a93e632":"### 1-3) Age vs Pclass vs Sex","79278d18":"### 2) Age\n- \uac01 \ud074\ub798\uc2a4\ub9c8\ub2e4 \ub098\uc774\uc758 \ud3c9\uade0\uc744 \uac01 \ud074\ub798\uc2a4\ub9c8\ub2e4\uc758 null \uac12\uc5d0 \ub123\uc5b4\uc8fc\uc5c8\ub2e4. ","939e247b":"Age, Fare -> numeric variables\\\nPclass -> integer but in fact 'categorical variable'","091b077c":"### File submission - Scikit Learn","9362ebca":"## Split data","89a08ca7":"- 1\ub4f1\uae09 \ud074\ub798\uc2a4\uc758 \ub0a8\uc131 \uc2b9\uac1d\ub4e4\uc758 \ub300\ubd80\ubd84\uc740 \uc0b4\uc544\ub0a8\uc9c0 \ubabb\ud558\uc600\uace0 \uc5ec\uc131\ub4e4\uc740 \ub300\ubd80\ubd84 \uc0b4\uc544\ub0a8\uc558\ub2e4. \n- 3\ub4f1\uae09 \ud074\ub798\uc2a4\uc758 \uc5ec\uc131\uc758 \uc808\ubc18 \uc774\uc0c1\uc740 \uc0b4\uc544\ub0a8\uc558\ub2e4. ","36402d03":"### 1-2. Blending Model\n> *references*\n> - [https:\/\/www.kaggle.com\/eraaz1\/a-comprehensive-guide-to-titanic-machine-learning](https:\/\/www.kaggle.com\/eraaz1\/a-comprehensive-guide-to-titanic-machine-learning)","e848361d":"- \uac00\uc7a5 \ub9ce\uc740 \uc2b9\uac1d\uc774 \ud0c4 3\ub4f1\uae09 \uc784\uc5d0\ub3c4 \ubd88\uad6c\ud558\uace0 \uc0dd\uc874\uc728\uc740 \uac00\uc7a5 \uc801\uc740 \uc2b9\uac1d\uc774 \ud0d1\uc2b9\ud55c 1\ub4f1\uae09\uc5d0 \ube44\ud574 \ub354 \uc801\uc740 \uc0dd\uc874\uc728\uc744 \ubcf4\uc778\ub2e4. ","8e20eb3e":"### 4) Name","0f225943":"### 6) Fare","283fc0e0":"### 5) Ticket","dca90edd":"#### 2) Cabin\n- \uccab\ubc88\uc9f8 \ucf54\ub4dc\ub9cc \ucd94\ucd9c\ud568\n- A: lst class\n- B\n- C: 3rd class\n- D: walking area\n- E: 1st and 2nd class\n- F: 2nd class, 2rd class\n- G: boiler room\n- T: boat deck\n- U: Unknown","96ab443e":"### 1-1) Age by surviving status","24a98bcf":"2nd \ud074\ub798\uc2a4\ub294 1st, 3rd \ud074\ub798\uc2a4\uc5d0 \ube44\ud574 \ub354 \ub113\uc740 \ubd84\ud3ec\ub97c \uac00\uc9c4\ub2e4. \ub610\ud55c \uac70\uc758 \ub300\uce6d \uc801\uc774\ub2e4.\\\n\uac00\uc7a5 \ub098\uc774\uac00 \uc801\uc740 passenger\uc740 1,2,3 \ub4f1\uae09 \ub3d9\uc77c\ud55c \ub098\uc774\uc778 0.08\uc138\uc774\ub2e4. \\\n\uac00\uc7a5 \ub098\uc774\uac00 \ub9ce\uc740 passenger\uc740 2nd \ud074\ub798\uc2a4\uc758 87\uc138\uc774\ub2e4.\n\n3rd \ud074\ub798\uc2a4 mean age= 30.2\uc138\\\n2nd \ud074\ub798\uc2a4 mean age= 36.9\uc138\\\n1st \ud074\ub798\uc2a4 mean age= 40.7\uc138","3b5a1cbc":"- Null values \ud655\uc778","5f67b13e":"### 4-1) Pclass vs Surviving vs Sex","d3c60006":"<a id='data_import'><\/a>\n### (1) Data Import","d4a75aa5":"- family size\uac00 15\uba85\uc778 \uadf8\ub8f9\uc740 \ubaa8\ub450 \uc0b4\uc544\ub0a8\uc9c0 \ubabb\ud558\uc600\ub2e4. \n- \ub300\ubd80\ubd84\uc740 \ud63c\uc790 \uc5ec\ud589\ud558\ub294 \uc0ac\ub78c\ub4e4\uc774\uc600\uace0, \uc0dd\uc874\uc728\uc740 40% \uc815\ub3c4 \uc774\ub2e4. \n- \uac00\uc7a5 \ub192\uc740 \uc0dd\uc874\uc728\uc744 \ubcf4\uc774\ub294 family size\ub294 2,3 \uc815\ub3c4\uc774\ub2e4. \n- 4\uac1c\uc758 category\ub85c family size group\uc744 \ub098\ub204\uc5b4\ubcf4\uaca0\ub2e4.\n- single\n- usual(sizes 2,3,4,5)\n- big(6,7,8,9)\n- large(all bigger then 10)","ce0cbe46":"## 1. Modeling\n> *references*\n> - [https:\/\/www.kaggle.com\/j2hoon85\/tps-april-sklearn-pycaret-for-newbies](https:\/\/www.kaggle.com\/j2hoon85\/tps-april-sklearn-pycaret-for-newbies)\n> - [https:\/\/www.kaggle.com\/remekkinas\/ensemble-learning-meta-classifier-for-stacking](https:\/\/www.kaggle.com\/remekkinas\/ensemble-learning-meta-classifier-for-stacking)","32da16d4":"0.08\uc138 ~ 87\uc138\uae4c\uc9c0 \ub2e4\uc591\ud558\uac8c \ub098\uc774\ub300\uac00 \uc788\uc73c\uba70 mean=34.46\uc138 \uc774\ub2e4. ","4e6f8e1e":"### 3) Family\n- Family size = Sib + Parch +1","e15d1227":"<a id=\"survived\"><\/a>\n### (1) Survived\n- train set\uc5d0\uc11c survived\uc758 0,1 \ubd84\ud3ec\uac00 \uc5b4\ub5a4\uc9c0 \ud655\uc778\ud574\ubcf4\uaca0\uc2b5\ub2c8\ub2e4. \n- \ubd84\ud3ec\uc5d0 \ub530\ub77c \ubaa8\ub378\uc758 \ud3c9\uac00 \ubc29\ubc95\uc774 \ub2ec\ub77c\uc9c8 \uc218 \uc788\uc2b5\ub2c8\ub2e4. ","0928fff8":"#### 4) Pclass","da255e72":"- \ub300\ubd80\ubd84\uc758 \uc2b9\uac1d(140981)\ub4e4\uc740 S \ud56d\uad6c\uc5d0\uc11c \ucd9c\ubc1c\ud558\uc600\uace0 S \ud56d\uad6c\uc5d0\uc11c \ucd9c\ubc1c\ud55c \uc2b9\uac1d\ub4e4\uc758 \uc0dd\uc874\uc728\uc740 \uac00\uc7a5 \ub0ae\uc558\ub2e4. \ub610\ud55c 3\ub4f1\uae09 \ud074\ub798\uc2a4 \uc0ac\ub78c\ub4e4\uc774 \ub300\ubd80\ubd84\uc774\ub2e4. \n- C\ud56d\uad6c\uc5d0\uc11c \ucd9c\ubc1c\ud55c \uc2b9\uac1d\ub4e4\uc740 75% \uc774\uc0c1\uc758 \uc0dd\uc874\uc728\uc744 \ubcf4\uc778\ub2e4. \n- \uac00\uc7a5 \uc801\uc740 \uc2b9\uac1d\ub4e4\uc774 \ud0d1\uc2b9\ud55c Q\ud56d\uad6c\uc5d0\ub294 \uac00\uc7a5 \ub9ce\uc740 l\ub4f1\uae09 \ud074\ub798\uc2a4\uc758 \uc2b9\uac1d\ub4e4\uc774 \ud0d1\uc2b9\ud558\uc600\ub2e4. ","4d22f902":"> \uc885\uc18d\ubcc0\uc218\n> - **Survived(\uc0dd\uc874\uc5ec\ubd80)**: target label (1,0) -> integer \n\n> \ub3c5\ub9bd\ubcc0\uc218\n> - **PassengerId**: 10000\uba85\n> - **Pclass(\ud2f0\ucf13\uc758 \ud074\ub798\uc2a4)**: Upper(1), Middle(2), Lower(3) -> categorical -> integer\n> - **Name(\uc774\ub984)**: \ud0d1\uc2b9\uc790 \uc131\uba85\ub4e4 \n> - **Sex(\uc131\ubcc4)**: Male, Female -> binary -> string\n> - **Age(\ub098\uc774)**: continuous -> integer\n> - **SibSp(\ud568\uaed8 \ud0d1\uc2b9\ud55c \ud615\uc81c\uc640 \ubc30\uc6b0\uc790\uc758 \uc218)**: quantitative -> integer \n> - **Parch(\ud568\uaed8 \ud0d1\uc2b9\ud55c \ubd80\ubaa8, \uc544\uc774\uc758 \uc218)**: quantitative -> integer\n> - **Ticket(\ud2f0\ucf13 \ubc88\ud638)**: alphabet + integer -> string\n> - **Fare(\ud0d1\uc2b9\ub8cc)**: continous -> float\n> - **Cabin(\uac1d\uc2e4 \ubc88\ud638)**: alphabet + integer -> string\n> - **Embarked(\ud0d1\uc2b9\ud56d\uad6c)**: C(Cherbourg), Q(Queenstown), S(Southhampton) -> string\n\n*references*\n- [https:\/\/kaggle-kr.tistory.com\/17](https:\/\/kaggle-kr.tistory.com\/17)","38c3ec08":"missing data\ub97c handling\ud558\uae30 \uc704\ud574\uc11c EDA\uc5d0\uc11c\ub294 dataset\uc744 \ud569\ucce4\uc9c0\ub9cc, ML\uc5d0\uc11c\ub294 'data leakage'\ub97c \ud53c\ud558\uae30 \uc704\ud574\uc11c \uc624\uc9c1 train data set\ub9cc \uc0ac\uc6a9\ud560 \uac83\uc774\ub2e4. ","0d9ab921":"## 1) Data Correlation","5995c194":"<a id=\"eda\"><\/a>\n## EDA(Exploratory Data Analysis)\n> *references*\n> [https:\/\/www.kaggle.com\/demidova\/titanic-eda-tutorial](https:\/\/www.kaggle.com\/demidova\/titanic-eda-tutorial)\n> [https:\/\/www.kaggle.com\/demidova\/titanic-logistic-regression-random-forest-xgboost?scriptVersionId=46567425]\n\n![titanic](https:\/\/ww.namu.la\/s\/1cc50931b5875401a9465ba06eaaf3d357ebfeabdf50346cd03636ab60ef0a9783a060b2c9cc7808148cd2a075699fa0f094e7f34df4a69fd5fdeb31137a37ef6e3a6c57a0b629606097a954052b7abba6a51a1a32ed5be9a92174b2ada23080602e6277fd7f0a200ddffcbd5b581746)\n- [https:\/\/namu.wiki\/jump\/9AGb4mj%2Bgar2D116rRySHULPcuF9aQA9dU1%2FKaQlJabHnX1Bwo7dW3QKZZU5EDX7tyS7%2BeKInzFlBX0PyH2gvmr0xlEeT19AQhYRU4yv8erx25eqVyS5NlWU2pDAk3mhBaO4i%2BaABck5vAWwFaAE0g%3D%3D](https:\/\/namu.wiki\/jump\/9AGb4mj%2Bgar2D116rRySHULPcuF9aQA9dU1%2FKaQlJabHnX1Bwo7dW3QKZZU5EDX7tyS7%2BeKInzFlBX0PyH2gvmr0xlEeT19AQhYRU4yv8erx25eqVyS5NlWU2pDAk3mhBaO4i%2BaABck5vAWwFaAE0g%3D%3D)","5bd8ef66":"### 1-2) Age by Pclass","be860608":"- [First look](#first_look)\n    - [(1) Check data for NA](#check_na)\n    \n- [EDA(Exploratory Data Analysis)](#eda)\n    - [(1) Survived](#survived)\n    - [(2) Age](#age)\n    - [(3) Cabin](#cabin)\n    - [(3) Family](#family)\n    - [(3) Pclass](#pclass)\n    - [(3) Sex](#sex)\n    - [(3) Embarked](#embarked)\n    - [(3) Fare](#fare)\n\n","eb774728":"<a id=\"check_na\"><\/a>\n### (2) Check data for NA\n- dataset\uc758 feature\ub4e4\uc744 \uc0b4\ud3b4\ubcf4\uace0, null data\uc758 \uc5ec\ubd80\ub97c \uccb4\ud06c\ud574\ubcf4\uc790","9773b92a":"### 1-1. Hyper Parameter Tuning - Baysian Optimization\n> *references*\n> - [https:\/\/www.kaggle.com\/elon4773\/titanic-visualization-bayesian-optimization](https:\/\/www.kaggle.com\/elon4773\/titanic-visualization-bayesian-optimization)","1a052a06":"- \ub300\ubd80\ubd84\uc758 passengers\ub294 Cabin code\uac00 \uc5c6\ub2e4. \n- Cabin code\uac00 \ub098\uc640\uc788\ub294 \uc2b9\uac1d\ub4e4 \uc911 \uac00\uc7a5 \ub9ce\uc740 \uc218\ub97c \ucc28\uc9c0\ud558\ub294 deck\uc740 'C'\uc774\uba70 lst class ticket\uc774\ub2e4. 'C' deck\uc740 \uc0b4\uc544\ub0a8\uc740 \uc2b9\uac1d\ub4e4 \uc911 4\ubc88\uc9f8\uc774\ub2e4. \n- \uac00\uc7a5 \ub9ce\uc740 \uc0dd\uc874\ub960\uc744 \uac00\uc9c4 deck\uc740 'F'\uc774\ub2e4. \n- 'A' deck\uc740 lifeboats\uc640 \uac00\uc7a5 \uac00\uae4c\uc6b4 deck\uc774\uc600\uc9c0\ub9cc \uc0dd\uc874\ub960\uc740 \uac00\uc7a5 \ub0ae\uc740 \ud655\ub960\uc744 \ubcf4\uc774\uace0 \uc788\ub2e4. ","bd01bfbb":"### 3) Embarked","505cdeef":"<a id=\"independent_variables\"><\/a>\n### (2) Independent Variables \n> *references*\n> - [https:\/\/wikidocs.net\/75068](https:\/\/wikidocs.net\/75068)","593d6200":"#### 1) Age\n6779 : age missing values\n- 3292 : train dataset\n- 3487 : test dataset"}}