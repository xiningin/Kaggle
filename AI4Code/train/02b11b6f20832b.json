{"cell_type":{"a97f4eb3":"code","37416f41":"code","02ba2843":"code","9f5cd934":"code","84d3366e":"code","6a4d026a":"code","0dd584fd":"code","ae937e23":"code","48d93530":"code","e6441161":"code","9953305a":"code","12893070":"code","90b102f9":"code","3a7aa51c":"code","f412ef64":"code","dfa0c881":"code","c7f85dec":"code","d8348d62":"code","3c1b3f48":"code","9745cd9f":"markdown","25b83492":"markdown","116ca981":"markdown","1ff087ee":"markdown","f27daf33":"markdown","c8fa0094":"markdown","04a9e96d":"markdown"},"source":{"a97f4eb3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","37416f41":"%pip install mglearn","02ba2843":"pip install -q kaggle","9f5cd934":"from sklearn.model_selection import train_test_split\nimport mglearn\nfrom sklearn.preprocessing import RobustScaler\nimport seaborn as sns\nimport matplotlib.pyplot as plt","84d3366e":"df = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\n\n# Class\u5217\u306e\u6570\u306e\u78ba\u8a8d\ndf['Class'].value_counts()","6a4d026a":"# Get summary statistics (mean, standard deviation, etc.) for each column in pandas by describe\n\ndf.describe().transpose()","0dd584fd":"# get mean and std\n\ntrain_stats = df.describe()\ntrain_stats.pop(\"Class\")\ntrain_stats = train_stats.transpose()\n\n# Class standadization is not necessary.\ny = df.pop('Class')\n\n\n# standardize\n\nnormed_df = df.apply(lambda x: (x - train_stats['mean']) \/ train_stats['std'], axis=1)\n\ndf = pd.concat([normed_df, y], axis=1)","ae937e23":"df.describe().transpose()","48d93530":"# I very much appreciate for \"Credit Card Fraud team\". They give me the hint \"MSMOTE to handle imbalanced data\", https:\/\/www.kaggle.com\/sondosomar\/credit-card-fraud-team .\n\nimport imblearn\nfrom imblearn.over_sampling import SMOTE\n\nX = df.drop('Class', axis=1)\ny = df['Class']\n\noversample = SMOTE()\nX, y = oversample.fit_resample(X, y)\nsns.countplot(y)\n\ndf_ovr = pd.concat([X,y], axis=1)\ndf_ovr['Class'].value_counts()","e6441161":"X = df_ovr.drop('Class', axis=1)\ny = df_ovr['Class']\nX_train, X_test, y_train, y_test = train_test_split(X,y,random_state=0, stratify=y)\n\n# X and y are overwritten by the original data\n\nX = df.drop('Class', axis=1)\ny = df['Class']\n\nprint('oversampling y_train : {}'.format(sum(y_train==1)))\nprint('oversampling y_test : {}'.format(sum(y_test==1)))\nprint('original y : {}'.format(sum(y==1)))","9953305a":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report\nimport matplotlib.pyplot as plt\nimport numpy as np\n\nlogreg = LogisticRegression(C=1.2, max_iter=1000).fit(X_train, y_train)\n\ny_pred = logreg.predict(X_test)\n \ncf = confusion_matrix(y_test, y_pred, labels=[0, 1])\n\nprint('0 = Negative, 1 = Positive    Positive = {}pcs'.format(sum(y_test == 1)))\nprint('----------------------------------')\nprint('Training set score: {:.3f}'.format(logreg.score(X_train, y_train)))\nprint('Test set score: {:.3f}'.format(logreg.score(X_test, y_test)))\nprint('precision score: {:.3f}'.format(precision_score(y_test, y_pred)))\nprint('recall score: {:.3f}'.format(recall_score(y_test, y_pred)))\nprint('----------------------------------')\nprint('True Positive:{}'.format(cf[1][1]))\nprint('False Negative:{}'.format(cf[1][0]))\nprint('True Negative:{}'.format(cf[0][0]))\nprint('False Positive:{}'.format(cf[0][1]))\nprint(classification_report(y_test, y_pred))","12893070":"# trained by oversampling data and tested by original data\n\ny_pred = logreg.predict(X)\n \ncf = confusion_matrix(y, y_pred)\n\nprint('0 = Negative, 1 = Positive    Positive = {}pcs'.format(sum(y == 1)))\nprint('----------------------------------')\nprint('Test set score: {:.3f}'.format(logreg.score(X, y)))\nprint('precision score: {:.3f}'.format(precision_score(y, y_pred)))\nprint('recall score: {:.3f}'.format(recall_score(y, y_pred)))\nprint('----------------------------------')\nprint('True Positive:{}'.format(cf[1][1]))\nprint('False Negative:{}'.format(cf[1][0]))\nprint('True Negative:{}'.format(cf[0][0]))\nprint('False Positive:{}'.format(cf[0][1]))\nprint(classification_report(y, y_pred))","90b102f9":"import tensorflow as tf\nfrom tensorflow.keras import Sequential, optimizers\nfrom tensorflow.keras.layers import Dense, Dropout, Activation\nfrom sklearn.metrics import precision_score, recall_score, confusion_matrix, classification_report\n\nmodel = Sequential()\nmodel.add(Dense(128, activation='relu', input_shape=[X.shape[1],]))\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(optimizer='adam', \n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nprint(model.summary())\n\nexample_batch = X[:10]\nexample_result = model.predict(example_batch)\nprint(example_result)","3a7aa51c":"EPOCHS = 30\n\nhistory = model.fit(X_train, y_train, epochs=EPOCHS, validation_data=(X_test, y_test), verbose=2)\n\nhist = pd.DataFrame(history.history)\nhist['epoch'] = history.epoch","f412ef64":"# result of oversampling data\n\ny_pred = model.predict(X_test)\n\ncf = confusion_matrix(y_test, [np.argmax(x) for x in y_pred])\n\nprint('0 = Negative, 1 = Positive    Positive = {}pcs'.format(sum(y_test == 1)))\nprint('----------------------------------')\nprint('precision score: {:.3f}'.format(precision_score(y_test, [np.argmax(x) for x in y_pred])))\nprint('recall score: {:.3f}'.format(recall_score(y_test, [np.argmax(x) for x in y_pred])))\nprint('----------------------------------')\nprint('True Positive:{}'.format(cf[1][1]))\nprint('False Negative:{}'.format(cf[1][0]))\nprint('True Negative:{}'.format(cf[0][0]))\nprint('False Positive:{}'.format(cf[0][1]))\nprint(classification_report(y_test, [np.argmax(x) for x in y_pred]))","dfa0c881":"# trained by oversampling data and tested by original data\n\ny_pred = model.predict(X)\n \ncf = confusion_matrix(y, [np.argmax(x) for x in y_pred])\n\nprint('0 = Negative, 1 = Positive    Positive = {}pcs'.format(sum(y == 1)))\nprint('----------------------------------')\nprint('precision score: {:.3f}'.format(precision_score(y, [np.argmax(x) for x in y_pred])))\nprint('recall score: {:.3f}'.format(recall_score(y, [np.argmax(x) for x in y_pred])))\nprint('----------------------------------')\nprint('True Positive:{}'.format(cf[1][1]))\nprint('False Negative:{}'.format(cf[1][0]))\nprint('True Negative:{}'.format(cf[0][0]))\nprint('False Positive:{}'.format(cf[0][1]))\nprint(classification_report(y, [np.argmax(x) for x in y_pred]))","c7f85dec":"fig = plt.figure(figsize=(20,6))\nax1 = fig.add_subplot(1,4,1)\nax2 = fig.add_subplot(1,4,2)\n\n\nax1.plot(hist.index, hist['loss'].values, color = 'blue')\nax1.plot(hist.index, hist['val_loss'].values, color = 'red')\nax2.plot(hist.index, hist['accuracy'].values, color = 'blue')\nax2.plot(hist.index, hist['val_accuracy'].values, color = 'red')\n\nax1.legend(['loss', 'val_loss'])\nax2.legend(['accuracy', 'val_accuracy'])","d8348d62":"# result of oversampling data\n\nfrom sklearn.neural_network import MLPClassifier\n\nmlp = MLPClassifier(solver='lbfgs', alpha = 0.00001, random_state = 0, hidden_layer_sizes=(200,), verbose=0).fit(X_train, y_train)\n\ny_pred = mlp.predict(X_test)\n \ncf = confusion_matrix(y_test, y_pred)\n\n\nprint('0 = Negative, 1 = Positive    Positive = {}pcs'.format(sum(y_test == 1)))\nprint('----------------------------------')\nprint('True Positive:{}'.format(cf[1][1]))\nprint('False Negative:{}'.format(cf[1][0]))\nprint('True Negative:{}'.format(cf[0][0]))\nprint('False Positive:{}'.format(cf[0][1]))\nprint('----------------------------------')\nprint(classification_report(y_test, y_pred))","3c1b3f48":"# trained by oversampling data and tested by original data\n\ny_pred = model.predict(X)\n \ncf = confusion_matrix(y, [np.argmax(x) for x in y_pred])\n\nprint('0 = Negative, 1 = Positive    Positive = {}pcs'.format(sum(y == 1)))\nprint('----------------------------------')\nprint('precision score: {:.3f}'.format(precision_score(y, [np.argmax(x) for x in y_pred])))\nprint('recall score: {:.3f}'.format(recall_score(y, [np.argmax(x) for x in y_pred])))\nprint('----------------------------------')\nprint('True Positive:{}'.format(cf[1][1]))\nprint('False Negative:{}'.format(cf[1][0]))\nprint('True Negative:{}'.format(cf[0][0]))\nprint('False Positive:{}'.format(cf[0][1]))\nprint(classification_report(y, [np.argmax(x) for x in y_pred]))","9745cd9f":"# Tensorflow","25b83492":"# Logistic Regression","116ca981":"# MLPClassifier","1ff087ee":"# Standardize","f27daf33":"same results as Tensorflow's","c8fa0094":"## test by original data","04a9e96d":"recall is not so bad but precision no good."}}