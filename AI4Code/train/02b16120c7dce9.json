{"cell_type":{"2b7b1fe9":"code","12364a1d":"code","75ac36c2":"code","43ba0295":"code","33a89879":"code","9217b517":"code","a6bb7ffc":"code","e6784720":"code","68cef96a":"code","f5813523":"code","be2fb10c":"code","54fdc9e4":"code","cdf77705":"code","e627f010":"code","d320c23a":"code","12067525":"code","a7af404d":"code","8ee068c5":"code","345e2913":"code","5bb39a4b":"code","c1269fac":"code","e46fa620":"code","ef2b733d":"code","c100bf98":"code","930f638a":"code","6a15cf39":"code","b3ddad99":"code","39eb2d37":"code","c734fdd8":"code","8f3f753a":"code","d3d9f35b":"code","10c43b52":"code","ecd35b02":"code","ebb97515":"code","049b67ff":"code","cd85ebf5":"code","6601b144":"code","c10417c5":"code","8a5af4e6":"code","d73b37a5":"code","7ce08f29":"code","4c38f78b":"code","1a78e8bd":"code","8a83ccfc":"code","16fc7817":"code","6395edc2":"code","e8d58c4a":"code","cb652d5d":"code","7963b59a":"code","78005093":"code","d09b8d0b":"code","214dfc03":"code","5e2dbd3a":"code","57022dac":"code","5aa73494":"code","e50e1b7e":"code","ef6d7b07":"code","64ff7253":"code","f9275568":"code","18e800ad":"code","ef7ef39c":"code","a1f72726":"code","2a6f2c18":"code","b0b7fa53":"code","eb175baa":"code","45d94c1b":"code","77208e66":"code","799fc96e":"code","2f3b22cc":"code","e23ece9e":"code","a03f1b8d":"code","800523f9":"code","8c425eb5":"code","a0a9291a":"code","1409710c":"markdown","5f9f2c23":"markdown","1a15adfc":"markdown","00f0ccba":"markdown","8be2c470":"markdown","4b9b74bd":"markdown","8ffa9300":"markdown","cad31373":"markdown","ae9b174d":"markdown","3189c202":"markdown","1187ad51":"markdown","19b85f35":"markdown","64771763":"markdown","d4c868e7":"markdown","3550d18b":"markdown"},"source":{"2b7b1fe9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","12364a1d":"from sklearn.preprocessing import LabelEncoder\nimport matplotlib.pyplot as plt\n# from sklearn.preprocessing import StandardScaler\n# from sklearn.feature_selection import SelectKBest, f_classif, f_regression\nimport seaborn as sns\n# from sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.preprocessing import StandardScaler\n\nimport xgboost\nimport joblib\n\nimport time","75ac36c2":"plt.rcParams['figure.figsize'] = (11,8)","43ba0295":"tr=pd.read_csv('\/kaggle\/input\/black-friday-sales-prediction\/train.csv')\ntr.head()","33a89879":"tr.columns","9217b517":"sns.heatmap(tr.isnull(), cbar=False)","a6bb7ffc":"tr.shape","e6784720":"sorted(tr['Product_Category_1'].unique())","68cef96a":"sns.barplot(x=tr['Product_Category_1'],y=tr['Purchase'],hue=tr['Gender'])","f5813523":"sns.barplot(x=tr['Gender'],y=tr['Purchase'])","be2fb10c":"sns.barplot(x=tr['City_Category'],y=tr['Purchase'])","54fdc9e4":"sns.barplot(x=tr['Occupation'],y=tr['Purchase'],estimator=np.sum)","cdf77705":"sns.barplot(x=tr['Age'],y=tr['Purchase'],estimator=np.sum)","e627f010":"sns.barplot(x=tr['Age'],y=tr['Purchase'])","d320c23a":"plt.pie(tr['Gender'].value_counts(),labels=tr['Gender'].value_counts().index,autopct='%.2f%%')","12067525":"plt.pie(tr['Age'].value_counts(),labels=tr['Age'].value_counts().index,autopct='%.2f%%')","a7af404d":"sns.boxplot(tr['Purchase'])","8ee068c5":"sns.distplot(tr['Purchase'])","345e2913":"df = tr.copy()","5bb39a4b":"df_ = df.copy()","c1269fac":"df_ = df_.merge(pd.get_dummies(df.City_Category, prefix=\"City\"), left_index=True, right_index=True)\ndf_ = df_.drop('City_Category', axis=1)\n\ndf_ = df_.merge(pd.get_dummies(df.Age, prefix=\"AgeGroup\"), left_index=True, right_index=True)\ndf_ = df_.drop('Age', axis=1)\n\ndf_ = df_.merge(pd.get_dummies(df.Occupation, prefix=\"Occu\"), left_index=True, right_index=True)\ndf_ = df_.drop('Occupation', axis=1)\n\ndf_","e46fa620":"le=LabelEncoder()\n# le.fit(df_[i])\nfor i in ['Gender', 'Stay_In_Current_City_Years', 'Product_ID']:\n    df_[i]=le.fit_transform(df_[i])\ndf_.head()","ef2b733d":"df_.columns","c100bf98":"from sklearn.experimental import enable_iterative_imputer\nfrom sklearn.impute import IterativeImputer\n\nii = IterativeImputer(random_state=0)\nii.fit(df_.drop(['Purchase'], axis=1))\n\n# ii.fit(df_.drop(['Purchase', 'Product_Category_3'], axis=1))\n# df2 = ii.transform(df_.drop(['Purchase', 'Product_Category_3'], axis=1))\n\ndf2 = ii.transform(df_.drop(['Purchase'], axis=1))\n\ndf2 = pd.DataFrame(df2).rename(columns={0  : 'User_ID',\n                                        1  : 'Product_ID',\n                                        2  : 'Gender',\n                                        3  : 'Stay_In_Current_City_Years',\n                                        4  : 'Marital_Status',\n                                        5  : 'Product_Category_1',\n                                        6  : 'Product_Category_2',\n                                        7  : 'Product_Category_3',\n                                        8  : 'City_A',\n                                        9  : 'City_B',\n                                        10 : 'City_C',\n                                        11 : 'AgeGroup_0-17',\n                                        12 : 'AgeGroup_18-25',\n                                        13 : 'AgeGroup_26-35',\n                                        14 : 'AgeGroup_36-45',\n                                        15 : 'AgeGroup_46-50',\n                                        16 : 'AgeGroup_51-55',\n                                        17 : 'AgeGroup_55+',\n                                        18 : 'Occu_0',\n                                        19 : 'Occu_1',\n                                        20 : 'Occu_2',\n                                        21 : 'Occu_3',\n                                        22 : 'Occu_4',\n                                        23 : 'Occu_5',\n                                        24 : 'Occu_6',\n                                        25 : 'Occu_7',\n                                        26 : 'Occu_8',\n                                        27 : 'Occu_9',\n                                        28 : 'Occu_10',\n                                        29 : 'Occu_11',\n                                        30 : 'Occu_12',\n                                        31 : 'Occu_13',\n                                        32 : 'Occu_14',\n                                        33 : 'Occu_15',\n                                        34 : 'Occu_16',\n                                        35 : 'Occu_17',\n                                        36 : 'Occu_18',\n                                        37 : 'Occu_19',\n                                        38 : 'Occu_20'})\n\n# df2 = df2.merge(df.Product_Category_3.fillna(df['Product_Category_3'].mode()[0]), left_index=True, right_index=True)\ndf2 = df2.merge(df.Purchase, left_index=True, right_index=True)\n\n# df2 = df2.astype(int)\n\ndf2","930f638a":"sns.heatmap(df2.isnull(), cbar=False)","6a15cf39":"df2.columns","b3ddad99":"sc = StandardScaler()\nscaler = sc.fit(df2.drop(['Purchase'], axis=1))\ndf2 = sc.transform(df2.drop(['Purchase'], axis=1))","39eb2d37":"sc.n_features_in_","c734fdd8":"df2 = pd.DataFrame(df2).rename(columns={0  : 'User_ID',\n                                        1  : 'Product_ID',\n                                        2  : 'Gender',\n                                        3  : 'Stay_In_Current_City_Years',\n                                        4  : 'Marital_Status',\n                                        5  : 'Product_Category_1',\n                                        6  : 'Product_Category_2',\n                                        7  : 'Product_Category_3',\n                                        8  : 'City_A',\n                                        9  : 'City_B',\n                                        10 : 'City_C',\n                                        11 : 'AgeGroup_0-17',\n                                        12 : 'AgeGroup_18-25',\n                                        13 : 'AgeGroup_26-35',\n                                        14 : 'AgeGroup_36-45',\n                                        15 : 'AgeGroup_46-50',\n                                        16 : 'AgeGroup_51-55',\n                                        17 : 'AgeGroup_55+',\n                                        18 : 'Occu_0',\n                                        19 : 'Occu_1',\n                                        20 : 'Occu_2',\n                                        21 : 'Occu_3',\n                                        22 : 'Occu_4',\n                                        23 : 'Occu_5',\n                                        24 : 'Occu_6',\n                                        25 : 'Occu_7',\n                                        26 : 'Occu_8',\n                                        27 : 'Occu_9',\n                                        28 : 'Occu_10',\n                                        29 : 'Occu_11',\n                                        30 : 'Occu_12',\n                                        31 : 'Occu_13',\n                                        32 : 'Occu_14',\n                                        33 : 'Occu_15',\n                                        34 : 'Occu_16',\n                                        35 : 'Occu_17',\n                                        36 : 'Occu_18',\n                                        37 : 'Occu_19',\n                                        38 : 'Occu_20'})\n\ndf2 = df2.merge(df.Purchase, left_index=True, right_index=True)\ndf2","8f3f753a":"df2.to_csv(\"BF_preprocessed_input.csv\")","d3d9f35b":"os.listdir(\"\/kaggle\/input\/\")","10c43b52":"df2 = pd.read_csv(\"..\/input\/black-friday-preprocessed\/BF_preprocessed_input.csv\")\ndf2.head()","ecd35b02":"Q1=df2['Purchase'].quantile(0.25)\nQ3=df2['Purchase'].quantile(0.75)\nIQR=Q3-Q1\nprint(Q1, Q3, IQR, sep='\\n')\nLL=Q1-(1.5*IQR)\nUL=Q3+(1.5*IQR)\nprint(LL,UL)\n\noutliers = df2.loc[np.where(df2['Purchase']>UL)]\nprint(len(outliers))\n\ndf3 = df2.loc[np.where(df2['Purchase']<UL)]","ebb97515":"sns.heatmap(df3.corr(),cmap='PuRd',annot=True)","049b67ff":"sns.heatmap(df2.corr(),cmap='PuRd',annot=True)","cd85ebf5":"from sklearn import svm\nfrom sklearn.model_selection import GridSearchCV\n\nparameters = {'kernel':('linear', 'rbf'), 'degree':[1, 10]}\nsvr = svm.SVR()\nreg = GridSearchCV(svr, parameters)\nreg.fit(df2.drop(['User_ID', 'Purchase'], axis=1), df2.Purchase)\n\n\nsorted(reg.cv_results_.keys())","6601b144":"X=df3.drop(['User_ID', 'Purchase'], axis=1)\nY=df3['Purchase']\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.3, random_state=42)","c10417c5":"print(X.shape, Y.shape, X_train.shape, X_test.shape, Y_train.shape, Y_test.shape)","8a5af4e6":"lr=LinearRegression()\nlr.fit(x_train,y_train)\nlr_pred=lr.predict(x_test)\nprint(mean_squared_error(y_test, lr_pred, squared=False))","d73b37a5":"time.time()","7ce08f29":"param_grid = { \n    'n_estimators': [30, 100, 300],\n    'max_features': ['auto', 'sqrt', 'log2'],\n#     'criterion' :['gini', 'entropy'],\n    'max_leaf_nodes' : [40, 80],\n    'max_depth' : [5,8,12]\n}","4c38f78b":"rfr=RandomForestRegressor(random_state=42, n_jobs=-1, verbose=True)","1a78e8bd":"start_time = time.time()\n\nCV_rfr = GridSearchCV(estimator=rfr, param_grid=param_grid, cv=2)\nCV_rfr.fit(X_train, Y_train)\n\nprint(\"--- %s min ---\" % ((time.time() - start_time)\/60))","8a83ccfc":"CV_rfr.best_params_","16fc7817":"start_time = time.time()\nrfr=RandomForestRegressor(n_estimators=300, verbose=True, max_leaf_nodes=80, max_depth=12, random_state=42, n_jobs=-1)\nrfr.fit(X_train, Y_train)\nrfr_pred=rfr.predict(X_test)\nmse = mean_squared_error(Y_test, rfr_pred, squared=False)\nprint(\"--- %s min ---\" % ((time.time() - start_time)\/60))\nprint(\"mse =\", mse)","6395edc2":"# joblib.dump(rfr, \"rfr_150_400_50_err2745.sav\")","e8d58c4a":"# joblib.load()","cb652d5d":"start_time = time.time()\n\nxgb = xgboost.XGBRegressor(learning_rate = 0.1,\n                           n_estimators = 1000,\n                           max_depth = 10,\n                           min_samples_split = 10,\n                           min_samples_leaf = 10,\n                           warm_start = True,\n                           verbose = 2)\n# learning_rate=1.02, max_depth=10, min_child_weight=40, seed=0,\n\nxgb.fit(X_train, Y_train)\nxgb_pred = xgb.predict(X_test)\nmse = mean_squared_error(Y_test, xgb_pred, squared=False)\n\nprint(\"--- %s min ---\" % ((time.time() - start_time)\/60))\nprint(\"mse =\", mse)","7963b59a":"# import joblib\n# joblib.dump(xgb, \"xgb_500_8_0.1_err2607.sav\")","78005093":"# xgb = joblib.load(\"xgb_500_8_0.1_err2604.sav\")","d09b8d0b":"knn = KNeighborsRegressor(n_neighbors=10, weights='distance', leaf_size=10)\nknn.fit(x_train, y_train)\nknn_pred = knn.predict(x_test)\nmean_squared_error(y_test, knn_pred, squared=False)","214dfc03":"mean_squared_error(y_test, knn_pred, squared=False)","5e2dbd3a":"from sklearn.neural_network import MLPRegressor\nmlpr = MLPRegressor(learning_rate='adaptive', \n                    learning_rate_init=0.001, \n                    max_iter=500,\n                    random_state=42, \n                    warm_start = True,\n                    verbose=True)\n# solver='sgd'\n\nmlpr.fit(x_train, y_train)\ny_pred = mlpr.predict(x_test)\nmean_squared_error(y_test, y_pred, squared=False)","57022dac":"mean_squared_error(y_test, y_pred, squared=False)","5aa73494":"from sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor(max_depth = 10,\n                                n_estimators = 1000,\n                                learning_rate = 0.2,\n#                                 warm_start = True,\n#                                 tol = 1e-4,\n                                verbose = 2)\ngbr.fit(X_train, Y_train)\nY_pred = gbr.predict(X_test)\nprint(mean_squared_error(Y_test, Y_pred, squared=False))","e50e1b7e":"print(mean_squared_error(Y_test, Y_pred, squared=False))","ef6d7b07":"print(mean_squared_error(Y_test, Y_pred, squared=False))","64ff7253":"test_score = np.zeros(xgb.get_params()['n_estimators'], dtype=np.float64)\nfor i, Y_pred in enumerate(xgb.staged_predict(X_test)):\n    test_score[i] = w.loss_(Y_test, Y_pred)\n\nfig = plt.figure(figsize=(6, 6))\nplt.subplot(1, 1, 1)\nplt.title('Deviance')\nplt.plot(np.arange(xgb.get_params()['n_estimators']) + 1, xgb.train_score_, 'b-',\n         label='Training Set Deviance')\nplt.plot(np.arange(xgb.get_params()['n_estimators']) + 1, test_score, 'r-',\n         label='Test Set Deviance')\nplt.legend(loc='upper right')\nplt.xlabel('Boosting Iterations')\nplt.ylabel('Deviance')\nfig.tight_layout()\nplt.show()","f9275568":"import joblib\njoblib.dump(GBR, \"GBR_model_800_8.sav\")","18e800ad":"gbr = joblib.load(\"GBR_model_800_8.sav\")","ef7ef39c":"import torch","a1f72726":"test=pd.read_csv('..\/input\/black-friday-sales-prediction\/test.csv')\ntest.isnull().sum()","2a6f2c18":"t2 = test.copy()","b0b7fa53":"for i in ['Gender','Stay_In_Current_City_Years', 'Product_ID']:\n    test[i]=le.fit_transform(test[i])","eb175baa":"test = test.merge(pd.get_dummies(test.City_Category, prefix=\"City\"), left_index=True, right_index=True)\ntest = test.drop('City_Category', axis=1)\n\ntest = test.merge(pd.get_dummies(test.Age, prefix=\"AgeGroup\"), left_index=True, right_index=True)\ntest = test.drop('Age', axis=1)\n\ntest = test.merge(pd.get_dummies(test.Occupation, prefix=\"Occu\"), left_index=True, right_index=True)\ntest = test.drop('Occupation', axis=1)\n\ntest","45d94c1b":"test2 = ii.transform(test)\n\ntest2 = pd.DataFrame(test2).rename(columns={0  : 'User_ID',\n                                            1  : 'Product_ID',\n                                            2  : 'Gender',\n                                            3  : 'Stay_In_Current_City_Years',\n                                            4  : 'Marital_Status',\n                                            5  : 'Product_Category_1',\n                                            6  : 'Product_Category_2',\n                                            7  : 'Product_Category_3',\n                                            8  : 'City_A',\n                                            9  : 'City_B',\n                                            10 : 'City_C',\n                                            11 : 'AgeGroup_0-17',\n                                            12 : 'AgeGroup_18-25',\n                                            13 : 'AgeGroup_26-35',\n                                            14 : 'AgeGroup_36-45',\n                                            15 : 'AgeGroup_46-50',\n                                            16 : 'AgeGroup_51-55',\n                                            17 : 'AgeGroup_55+',\n                                            18 : 'Occu_0',\n                                            19 : 'Occu_1',\n                                            20 : 'Occu_2',\n                                            21 : 'Occu_3',\n                                            22 : 'Occu_4',\n                                            23 : 'Occu_5',\n                                            24 : 'Occu_6',\n                                            25 : 'Occu_7',\n                                            26 : 'Occu_8',\n                                            27 : 'Occu_9',\n                                            28 : 'Occu_10',\n                                            29 : 'Occu_11',\n                                            30 : 'Occu_12',\n                                            31 : 'Occu_13',\n                                            32 : 'Occu_14',\n                                            33 : 'Occu_15',\n                                            34 : 'Occu_16',\n                                            35 : 'Occu_17',\n                                            36 : 'Occu_18',\n                                            37 : 'Occu_19',\n                                            38 : 'Occu_20'})\n\ntest2","77208e66":"sc.n_features_in_","799fc96e":"test2 = sc.transform(test2)","2f3b22cc":"# test = ii.transform(test.drop(['Product_Category_3'], axis=1))\n\ntest2 = pd.DataFrame(test2).rename(columns={0  : 'User_ID',\n                                           1  : 'Product_ID',\n                                           2  : 'Gender',\n                                           3  : 'Stay_In_Current_City_Years',\n                                           4  : 'Marital_Status',\n                                           5  : 'Product_Category_1',\n                                           6  : 'Product_Category_2',\n                                           7  : 'Product_Category_3',\n                                           8  : 'City_A',\n                                           9  : 'City_B',\n                                           10 : 'City_C',\n                                           11 : 'AgeGroup_0-17',\n                                           12 : 'AgeGroup_18-25',\n                                           13 : 'AgeGroup_26-35',\n                                           14 : 'AgeGroup_36-45',\n                                           15 : 'AgeGroup_46-50',\n                                           16 : 'AgeGroup_51-55',\n                                           17 : 'AgeGroup_55+',\n                                           18 : 'Occu_0',\n                                           19 : 'Occu_1',\n                                           20 : 'Occu_2',\n                                           21 : 'Occu_3',\n                                           22 : 'Occu_4',\n                                           23 : 'Occu_5',\n                                           24 : 'Occu_6',\n                                           25 : 'Occu_7',\n                                           26 : 'Occu_8',\n                                           27 : 'Occu_9',\n                                           28 : 'Occu_10',\n                                           29 : 'Occu_11',\n                                           30 : 'Occu_12',\n                                           31 : 'Occu_13',\n                                           32 : 'Occu_14',\n                                           33 : 'Occu_15',\n                                           34 : 'Occu_16',\n                                           35 : 'Occu_17',\n                                           36 : 'Occu_18',\n                                           37 : 'Occu_19',\n                                           38 : 'Occu_20'})\n\n# test = test.merge(df.Product_Category_3.fillna(df['Product_Category_3'].mode()[0]), left_index=True, right_index=True)\n# test = test.astype(int)\n\ntest2","e23ece9e":"sns.heatmap(test2.isnull(), cbar=False)","a03f1b8d":"# output=pd.DataFrame(rfr.predict(test.drop(['User_ID'], axis=1)))\noutput = pd.read_csv('..\/input\/black-friday-sales-prediction\/test.csv',usecols=['User_ID','Product_ID'])\noutput['Purchase'] = rfr.predict(test2.drop(['User_ID'], axis=1))","800523f9":"my_output = pd.read_csv('..\/input\/black-friday-sales-prediction\/test.csv',usecols=['User_ID','Product_ID'])\nmy_output['Purchase'] = xgb.predict(test2.drop(['User_ID'], axis=1))","8c425eb5":"output.to_csv('StandardScaler_IterativeImputer_rfr_40_40_30.csv')\nmy_output.to_csv('StandardScaler_IterativeImputer_xgb_1000_8.csv')","a0a9291a":"os.listdir()","1409710c":"<hr>\n\n# Linear Regression","5f9f2c23":"<hr>\n\n# **Missing value Imputation**","1a15adfc":"<hr>\n\n# GridSearchCV","00f0ccba":"<hr>\n<hr>\n<hr>\n\n# PyTorch","8be2c470":"<hr>\n\n## Building Train-Test splits","4b9b74bd":"<hr>\n\n## Scaling Down","8ffa9300":"<hr>\n\n# Neural Networks | Multi-Layer Perceptron Regression","cad31373":"## **One hot encoding**","ae9b174d":"<hr>\n\n# Prediction","3189c202":"<hr>\n\n# XGBoost Regression","1187ad51":"<hr>\n\n## Load preprocessed dataset","19b85f35":"<hr>\n\n# Random Forest Regression","64771763":"<hr>\n\n## Outlier Treatment","d4c868e7":"<hr>\n\n# Gradient Boosting Regression","3550d18b":"<hr>\n\n# K-Nearest Neighbors Regression"}}