{"cell_type":{"84381b13":"code","dd4eb38f":"code","8bf825ee":"code","2cd771d0":"code","b776e65e":"code","7db4a33c":"code","2ecd5bc4":"code","1286954c":"code","7b87ef78":"code","2c3ff9bb":"code","54a24d9f":"code","b0d03533":"code","ac6212dd":"code","836c3eee":"code","75dfa5dc":"code","7731b2e7":"code","40b6939b":"code","da02dabd":"code","b304f3ab":"code","1dd58cdb":"code","ea8be08f":"code","876a138b":"code","f7059c20":"code","2969c777":"code","e01839c7":"code","33af4ac9":"code","00f18ef8":"code","4a2c8810":"markdown","66021bb4":"markdown","a3e11c66":"markdown","624a316c":"markdown","a39f366b":"markdown","f5ec12c2":"markdown","3e9fb2a9":"markdown","67bcb2b4":"markdown","7f540296":"markdown","13b97a5a":"markdown","98b510f9":"markdown","84e7d20b":"markdown","7577fa07":"markdown","a400323e":"markdown"},"source":{"84381b13":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom collections import Counter\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dd4eb38f":"pd.set_option('display.max_rows', 1000)\npd.set_option('display.max_columns', 1000)","8bf825ee":"%%time\ntrain_err = pd.read_csv(\"\/kaggle\/input\/dacon-lg\/train_err_data.csv\")\ntrain_qual = pd.read_csv(\"\/kaggle\/input\/dacon-lg\/train_quality_data.csv\")\ntrain_prb = pd.read_csv(\"\/kaggle\/input\/dacon-lg\/train_problem_data.csv\")\ntest_err = pd.read_csv(\"\/kaggle\/input\/dacon-lg\/test_err_data.csv\")\ntest_qual = pd.read_csv(\"\/kaggle\/input\/dacon-lg\/test_quality_data.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/dacon-lg\/sample_submission.csv\")","2cd771d0":"train_err.head(100)","b776e65e":"print(train_err.shape)\nprint(train_qual.shape)\nprint(train_prb.shape)\nprint('\\n')\nprint(test_err.shape)\nprint(test_qual.shape)\nprint(sample_submission.shape)","7db4a33c":"%%time\ntrain_err['time'] = pd.to_datetime(train_err['time'], format=\"%Y%m%d%H%M%S\")\ntrain_qual['time'] = pd.to_datetime(train_qual['time'], format=\"%Y%m%d%H%M%S\")\ntrain_prb['time'] = pd.to_datetime(train_prb['time'], format=\"%Y%m%d%H%M%S\")","2ecd5bc4":"for var in list(map(lambda x: 'quality_'+ x, [str(i) for i in range(13)])):\n    train_qual[var] = train_qual[var].apply(lambda x: float(x.replace(\",\",\"\")) if type(x) == str else x)","1286954c":"dat = train_err.groupby('user_id',as_index=False).agg({'time':[np.min, np.max, len]})\ndat = dat.merge(train_prb, on='user_id', how='left')\ndat = dat[~dat['time'].isnull()]\npct = (dat['time'] - dat[('time','amin')]) \/ (dat[('time','amax')] - dat[('time','amin')])\nsns.distplot(pct[(pct<2)&(pct>0)])","7b87ef78":"print(sum(pct>2))\nprint(sum(dat[pct>2]['user_id'].isin(dat[pct<2]['user_id'])))\nprint('\\n')\nprint(sum(pct<0))\nprint(sum(dat[pct<0]['user_id'].isin(dat[pct>=0]['user_id'])))","2c3ff9bb":"dat = train_err.copy()\ndat['is_complain'] = dat['user_id'].isin(train_prb['user_id'])\ncomplain = dat[dat['is_complain']==True]\nno_complain = dat[dat['is_complain']==False]","54a24d9f":"def countplot(var, rotation=False, ylim=None):\n    f, ax = plt.subplots(1,2, figsize=(25,5))\n    sns.countplot(complain[var], ax=ax[0])\n    sns.countplot(no_complain[var], ax=ax[1])\n    ax[0].set_title('complain')\n    ax[1].set_title('no_complain')\n    if ylim is not None:\n        ax[0].set_ylim(0,ylim)\n        ax[1].set_ylim(0,ylim)\n    if rotation:\n        ax[0].set_xticklabels(labels = sorted(dat[var].unique()), rotation=45)\n        ax[1].set_xticklabels(labels = sorted(dat[var].unique()), rotation=45)\n        \ncountplot('errtype', ylim=1.4e+6)","b0d03533":"countplot('fwver', True)","ac6212dd":"countplot('model_nm', True)","836c3eee":"com_dic = sorted([(k, v) for (k, v) in Counter(complain['errcode']).items()],key=lambda x: -x[1])\nno_com_dic = sorted([(k, v) for (k, v) in Counter(no_complain['errcode']).items()],key=lambda x: -x[1])\n\nf, ax = plt.subplots(1,2, figsize=(25,5))\nthreshold=10\nsns.barplot(x=list(map(lambda x:x[0], com_dic[:threshold])), y=list(map(lambda x:x[1], com_dic[:threshold])), ax=ax[0])\nsns.barplot(x=list(map(lambda x:x[0], no_com_dic[:threshold])), y=list(map(lambda x:x[1], no_com_dic[:threshold])), ax=ax[1])\n_= ax[0].set_xticklabels(labels = list(map(lambda x:x[0], com_dic[:threshold])), rotation=45)\n_= ax[1].set_xticklabels(labels = list(map(lambda x:x[0], no_com_dic[:threshold])), rotation=45)\n_= ax[0].set_title('complain')\n_= ax[1].set_title('no_complain')","75dfa5dc":"n_comp = complain.groupby('user_id')['user_id'].count()\nn_no_comp = no_complain.groupby('user_id')['user_id'].count()\n\nf, ax = plt.subplots(1,2, figsize=(25,5))\nthreshold=5000\nsns.distplot(n_comp[n_comp<threshold], ax=ax[0], kde=False)\nsns.distplot(n_no_comp[n_no_comp<threshold], ax=ax[1], kde=False)\nax[0].set_title('Complain')\nax[1].set_title('No Complain')\nax[0].set_xlabel('# of errs')\nax[1].set_xlabel('# of errs')\nprint(\"# of Complainer Over {} Err: {}\".format(threshold, sum(n_comp>=threshold)))\nprint(\"# of Non-Complainer Over {} Err: {}\".format(threshold, sum(n_no_comp>=threshold)))","7731b2e7":"complain['prior_time'] = complain.groupby('user_id')['time'].shift()\ndiff = complain['time'] - complain['prior_time']\ncom_diff = diff[~diff.isnull()].astype('timedelta64[s]').astype(int)\n\nno_complain['prior_time'] = no_complain.groupby('user_id')['time'].shift()\ndiff2 = no_complain['time'] - no_complain['prior_time']\nno_com_diff = diff2[~diff2.isnull()].astype('timedelta64[s]').astype(int)","40b6939b":"f, ax = plt.subplots(1,2, figsize=(25,5))\nthreshold=600\nsns.distplot(com_diff[com_diff<threshold], ax=ax[0], kde=False)\nsns.distplot(no_com_diff[no_com_diff<threshold], ax=ax[1], kde=False)\nax[0].set_title('Complain (Second)')\nax[1].set_title('No Complain (Second)')\n# ax[0].set_ylim(0,5e+6)\n# ax[1].set_ylim(0,5e+6)\nprint(\"# of Complainer Over {} Err: {}\".format(threshold, sum(com_diff>=threshold)))\nprint(\"# of Non-Complainer Over {} Err: {}\".format(threshold, sum(no_com_diff>=threshold)))","da02dabd":"train_qual.groupby('user_id').count()","b304f3ab":"train_qual.groupby(['user_id', 'time', 'fwver']).count()","1dd58cdb":"train_qual.groupby(['user_id', 'time', 'fwver']).count().mean(axis=0)","ea8be08f":"test_qual.groupby(['user_id', 'time', 'fwver']).count().mean(axis=0)","876a138b":"train_qual.groupby(['user_id', 'time']).count().mean(axis=0)","f7059c20":"train_qual[list(map(lambda x: 'quality_'+ x, [str(i) for i in range(13)]))].sum(axis=0)","2969c777":"corr = train_qual[list(map(lambda x: 'quality_'+ x, [str(i) for i in [0,1,2,5,6,7,8,9,10,11,12] ]))].corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nf, ax = plt.subplots(figsize=(11, 9))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n            square=True, linewidths=.1, cbar_kws={\"shrink\": .5})","e01839c7":"corr","33af4ac9":"corr = test_qual[list(map(lambda x: 'quality_'+ x, [str(i) for i in [0,1,2,3,4,5,6,7,8,9,10,11,12] ]))].corr()\nmask = np.triu(np.ones_like(corr, dtype=bool))\nf, ax = plt.subplots(figsize=(11, 9))\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\nsns.heatmap(corr, mask=mask, cmap=cmap, center=0,\n            square=True, linewidths=.1, cbar_kws={\"shrink\": .5})","00f18ef8":"test_qual","4a2c8810":"- \uc2e0\uace0\uc790\uc758 \uc5d0\ub7ec\ud69f\uc218\uac00 \ud6e8\uc52c \ub9ce\ub2e4","66021bb4":"### \uc2e0\uace0\uc790\uc758 \uc5d0\ub7ec \ud69f\uc218\ub294?","a3e11c66":"- complain\uc774 \uc798 \ub4e4\uc5b4\uc624\ub294 model : model2, model4, \n- complain\uc774 \uc798 \uc548\ub4e4\uc5b4\uc624\ub294 model : model3, model5","624a316c":"### 1. \ubcf4\ud1b5 \uccab\uc5d0\ub7ec ~ \ub9c8\uc9c0\ub9c9\uc5d0\ub7ec \uad6c\uac04 \uc911 \uc5b4\ub290\ub54c\uc5d0 \uc2e0\uace0\uac00 \ubc1c\uc0dd\ud560\uae4c?","a39f366b":"- complain \uc798\ub4e4\uc5b4\uc624\ub294 errcode: connection timeout\n- complain \uc798 \uc548\ub4e4\uc5b4\uc624\ub294 errcode: 0","f5ec12c2":"- complain\uc774 \uc798 \ub4e4\uc5b4\uc624\ub294 err_type : 10,22, 23, 27,28 34\n- complain\uc774 \uc798 \uc548\ub4e4\uc5b4\uc624\ub294 err_type : 4, 15, 16, 26\n","3e9fb2a9":"- complain\uc774 \uc798 \ub4e4\uc5b4\uc624\ub294 fwver : 03.11.1149,   04.16.3345,   04.22.1442\n- complain\uc774 \uc798 \uc548\ub4e4\uc5b4\uc624\ub294 fwver : 03.11.1141,   04.16.2641,   04.16.3439,   04.22.1684\n","67bcb2b4":"- \uad6c\uac04\uc740 \ub2e4\uc591\ud558\ub2e4\n- \uc7ac\ubc0c\ub294\uac74 \uccab\uc5d0\ub7ec\uac00 \ub728\uae30 \uc804\ubd80\ud130, \ud639\uc740 \ub9c8\uc9c0\ub9c9 \uc5d0\ub7ec\uac00 \ub728\uace0\ub098\uc11c \ub9e4\uc6b0 \ud55c\ucc38 \uc788\ub2e4\uac00 \ubd88\ub9cc\uc811\uc218\ub97c \ud558\ub294 \uacbd\uc6b0\ub3c4 \uc874\uc7ac\ud55c\ub2e4.","7f540296":"- \uc2e0\uace0\uc790\uc758 \uc5d0\ub7ec\uac04 \ube48\ub3c4 \uc2dc\uac04\ucc28\ub294 \ud070 \ucc28\uc774\uac00 \uc5c6\ub2e4.","13b97a5a":"### Quality \ubd84\ud3ec","98b510f9":"- \uc0c1\uad00\uacc4\uc218 \ub192\uc740 \uc9dd: 0-9, 0-2, 1-8, 1-11, 2-9, 5-10, 6-7 ","84e7d20b":"\n### \uc2e0\uace0\uc790\uac00 \uc8fc\ub85c \uacaa\ub294 \uc5d0\ub7ec\ucf54\ub4dc, \ud0c0\uc785, fwver, model\uc740?","7577fa07":"- userid, time\uc73c\ub85c \ubb36\uc73c\uba74 \uce74\uc6b4\ud2b8 \uc218\ub294 \uac70\uc758 12\uc774\ub2e4","a400323e":"### \uc2e0\uace0\uc790\uc758 \uc5d0\ub7ec \ube48\ub3c4\uac04 \uc2dc\uac04\uaca9\ucc28"}}