{"cell_type":{"3e76fe9b":"code","02b7b595":"code","9e5d9c52":"code","0b87d627":"code","3d334e1e":"code","14af02f4":"code","40ce8c7b":"code","7ec9613b":"code","dd677d76":"code","b8576698":"code","ef2a69d6":"code","62e1229b":"code","045e48f1":"code","d9d1cbdc":"code","639e82e2":"code","ec9e3b82":"code","52b02fc5":"code","9b51b520":"code","96d4ac74":"code","d93cd087":"code","65149710":"code","cba97d7c":"code","6af8a4c7":"code","977cd452":"code","b4975f63":"markdown","ae1eba1d":"markdown","386161fb":"markdown","0ebcb859":"markdown"},"source":{"3e76fe9b":"#Importando Bibliotecas\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom sklearn.ensemble import RandomForestClassifier\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","02b7b595":"# Carregando os dados\ndf = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/costa-rican-household-poverty-prediction\/test.csv')\n\ndf.shape, test.shape","9e5d9c52":"# Juntando os dataframes\ndf_all = df.append(test)\n\ndf_all.shape","0b87d627":"# Verificando tamanhos e tipos\ndf_all.info()","3d334e1e":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","14af02f4":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","40ce8c7b":"# Analisando os dados da coluna edjefa\ndf_all['edjefa'].value_counts()","7ec9613b":"# Analisando os dados da coluna edjefe\ndf_all['edjefe'].value_counts()","dd677d76":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# nas colunas edjefa e edjefe\nmapeamento = {'yes': 1, 'no': 0}\n\ndf_all['edjefa'] = df_all['edjefa'].replace(mapeamento).astype(int)\ndf_all['edjefe'] = df_all['edjefe'].replace(mapeamento).astype(int)","b8576698":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","ef2a69d6":"# Olhando a coluna dependency\ndf_all['dependency'].value_counts()","62e1229b":"# Vamos transformar 'yes' em 1 e 'no' em 0\n# na coluna dependency\ndf_all['dependency'] = df_all['dependency'].replace(mapeamento).astype(float)","045e48f1":"# Quais colunas do dataframe s\u00e3o do tipo object\ndf_all.select_dtypes('object').head()","d9d1cbdc":"# Visualizando do comando info\ndf_all.info()","639e82e2":"# Verificando os valores nulos\ndf_all.isnull().sum()","ec9e3b82":" # Verificando os valores de aluguel (v2a1) para os chefes\/as de familia (parentesco1 = 1)\ndf_all[df_all['parentesco1'] == 1]['v2a1'].isnull().sum()","52b02fc5":"# Qual a cara dos dados de v18q\ndf_all['v18q'].value_counts()","9b51b520":"# Prenchendo com -1 os valores nulos de v2a1\ndf_all['v2a1'].fillna(-1, inplace=True)","96d4ac74":"# Prenchendo com 0 os valores nulos de v18q1\ndf_all['v18q1'].fillna(0, inplace=True)","d93cd087":"# Verificando os valores nulos\ndf_all.isnull().sum().sort_values()","65149710":"# Prenchendo com -1 os valores nulos de SQBmeaned, meaneduc e rez_esc\ndf_all['SQBmeaned'].fillna(-1, inplace=True)\ndf_all['meaneduc'].fillna(-1, inplace=True)\ndf_all['rez_esc'].fillna(-1, inplace=True)","cba97d7c":"# Separando as colunas para treinamento\nfeats = [c for c in df_all.columns if c not in ['Id', 'idhogar', 'Target']]","6af8a4c7":"# Separar os dataframes\ntrain, test = df_all[~df_all['Target'].isnull()], df_all[df_all['Target'].isnull()]\n\ntrain.shape, test.shape","977cd452":"# Modifica\u00e7\u00e3o 01\n\n#Realizei um ajuste mais fino no n\u00famero de \u00e1rvores e consegui subir um pouco a pontua\u00e7\u00e3o.\n\n#Pontua\u00e7\u00e3o - 43746  \n\n\n\nrf1 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=701,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n\nrf1.fit(train[feats], train['Target'])\n\ntest['Target'] = rf1.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","b4975f63":"# Copiando do campe\u00e3o\n\n# Pontua\u00e7\u00e3o - 0.43687\n\n\nrf = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=700,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2,\n                            verbose=0, class_weight='balanced')\n\nrf.fit(train[feats], train['Target'])\n\ntest['Target'] = rf.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","ae1eba1d":"# Modifica\u00e7\u00e3o 03\n\n#Ajustei o valor do par\u00e2metro min_impurity_decrease, que divide um n\u00f3, caso essa divis\u00e3o reduza a impureza, baseado no valor setado. Com isso consegui subir a pontua\u00e7\u00e3o\n\n#Pontua\u00e7\u00e3o - 0.44049\n\n\n\nrf3 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=701,\n                            min_impurity_decrease=0.0007, min_samples_leaf=2, min_samples_split=5,\n                            verbose=0, class_weight='balanced')\n\nrf3.fit(train[feats], train['Target'])\n\ntest['Target'] = rf3.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","386161fb":"# Modifica\u00e7\u00e3o 02\n\n#Adcionei o par\u00e2metro min_samples_split, que seta um n\u00famero de amostras m\u00ednimas para divis\u00e3o de um n\u00f3, e consegui subir a pontua\u00e7\u00e3o.\n\n#Pontua\u00e7\u00e3o - 0.43821  \n\n\n\nrf2 = RandomForestClassifier(max_depth=None, random_state=42, n_jobs=4, n_estimators=701,\n                            min_impurity_decrease=1e-3, min_samples_leaf=2, min_samples_split=5,\n                            verbose=0, class_weight='balanced')\n\nrf2.fit(train[feats], train['Target'])\n\ntest['Target'] = rf2.predict(test[feats]).astype(int)\ntest[['Id', 'Target']].to_csv('submission.csv', index=False)","0ebcb859":"# IESB - Graduacao - CIA028 - Costa Rica"}}