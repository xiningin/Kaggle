{"cell_type":{"3e312be2":"code","18444239":"code","0a795aad":"code","230353e5":"code","77f75248":"code","9b16f5cb":"code","ab121f4c":"code","49cdd85f":"code","546a5151":"code","757a7cc5":"code","bfb44714":"code","6d6a3249":"code","24ee2739":"code","67492223":"code","0b506e02":"code","11dd4998":"code","0ce9c0db":"code","5e7d2119":"code","6405846b":"code","dcdf9b3a":"code","7f59e7dd":"code","e3ce428d":"code","0a01fcd9":"code","e4a27d0d":"markdown","c48cdf5f":"markdown","3c1cf044":"markdown","878a4bdf":"markdown","c90b13e8":"markdown","2943246f":"markdown","d98762ec":"markdown"},"source":{"3e312be2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18444239":"import tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport os\nimport re\nfrom PIL import Image\nimport shutil\nfrom sklearn.model_selection import train_test_split\nimport random\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook\n\nimport numpy as np\nimport pandas as pd\nfrom scipy import ndimage\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\nfrom tqdm import tqdm\nimport os\nimport PIL\nfrom PIL import ImageOps, ImageFilter, ImageDraw, Image\n\nfrom tqdm import tqdm\nfrom scipy import ndimage\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img\n\n\nprint(tf.__version__)\nprint(keras.__version__)","0a795aad":"os.listdir('\/kaggle\/input\/kaggle-oxford-dataset-rgh\/KAGGLE\/train\/basset_hound')\n# Kaggle -> Input\uc774\ub77c\ub294 \ud3f4\ub354\uc5d0 \ub4e4\uc5b4\uc788\ub294 \ub370\uc774\ud130 \ub9ac\uc2a4\ud2b8\ub97c \ucd9c\ub825","230353e5":"# \uc9c1\uc811 \ud558\uc704 \ud3f4\ub354\uae4c\uc9c0 \ub4e4\uc5b4\uac00\ubcf4\uc138\uc694","77f75248":"#=== \uc774\ubbf8\uc9c0\ub97c \ucd9c\ub825\ud574\uc11c \ud655\uc778\ud574\ubcf4\uc790 ===#\nimage = Image.open('\/kaggle\/input\/kaggle-oxford-dataset-rgh\/KAGGLE\/train\/basset_hound\/basset_hound_150.jpg')   # \uc774\ubbf8\uc9c0\ub97c Open\ud574\uc90c\nimage = np.array(image)   # \uc774\ubbf8\uc9c0\ub97c array\ub85c \ubc14\uafd4\uc90c\nprint(image.shape)        # 333(\ud589), 500(\uc5f4), 3(Channel RGB)","9b16f5cb":"#=== \uc704\uc5d0\uc11c \ubd88\ub7ec\uc628 \uc774\ubbf8\uc9c0 \ucd9c\ub825 ===#\nplt.imshow(image)\nplt.show()","ab121f4c":"# Train \ud3f4\ub354\uc5d0 \uac01 \uc774\ubbf8\uc9c0 Class \ubcc4\ub85c \ub610\ub2e4\ub978 \ud3f4\ub354\uac00 \uc788\uc74c, \uadf8 \ud3f4\ub354\uc18d\uc5d0 \uc774\ubbf8\uc9c0\uac00 \ub4e4\uc5b4\uc788\uc74c\n# \uc804\uccb4 \ub9ac\uc2a4\ud2b8\ub97c \uc5bb\uae30 \uc704\ud574\uc11c\ub294 \uac01 \ud3f4\ub354\uc758 \ub9ac\uc2a4\ud2b8\ub4e4\uc744 \ubd88\ub7ec\uc11c \ud558\ub098\uc758 \ub9ac\uc2a4\ud2b8\ub85c \ud569\uccd0\uc918\uc57c \ud568\n# Train \ud3f4\ub354 > Class \ud3f4\ub354 > \uc774\ubbf8\uc9c0\n\ntrain_files_path = os.path.join('\/kaggle\/input\/kaggle-oxford-dataset-rgh\/KAGGLE\/train')   # \ud3f4\ub354 \uacbd\ub85c\ub97c \uc785\ub825\ntrain_files = os.listdir(train_files_path)                                                # \ud574\ub2f9 \ud3f4\ub354 \uacbd\ub85c\uc5d0 \ub4e4\uc5b4\uc788\ub294 \ub370\uc774\ud130 \ub9ac\uc2a4\ud2b8\ub97c \uc9d1\uc5b4\ub123\uc74c\n\ntrain_all_list = []                                          # \ube44\uc5b4\uc788\ub294 List\ub97c \ub9cc\ub4e6\n\nfor train_file in train_files:                               # \uc704\uc5d0 Train \ud3f4\ub354\uc758 \ub4e4\uc5b4\uc788\ub294 Class \ud3f4\ub354 \ub9ac\uc2a4\ud2b8\ub97c For\ubb38\uc73c\ub85c \ub3cc\ub9bc\n    temp_path = os.path.join(train_files_path,train_file)    # Train\ud3f4\ub354 \uacbd\ub85c + Class \ud3f4\ub354\uba85\uc73c\ub85c \uc0c8\ub85c\uc6b4 \uacbd\ub85c\ub97c \ub9cc\ub4e6\n    for i in os.listdir(temp_path):                          # \uc0c8\ub85c\uc6b4 Class \ud3f4\ub354 \uacbd\ub85c\ub0b4\uc5d0 \ud3f4\ub354\ub4e4\uc758 \ub9ac\uc2a4\ud2b8\ub97c For\ubb38\uc73c\ub85c \ub3cc\ub9bc\n        train_all_list.append(i)                             # Class \ud3f4\ub354\ub0b4\uc5d0 \ud30c\uc77c\ub4e4\uc744 \ub9ac\uc2a4\ud2b8\uc5d0 \ucd94\uac00\uc2dc\ud0b4 --> Class \ud3f4\ub354\ub97c \ub3cc\uba70 \ubc18\ubcf5\n        \ntrain_all_list[:10]   # \uac01\uac01\uc758 Class\uc5d0 \uc788\ub294 \ud30c\uc77c\ub4e4\uc744 \ud558\ub098\uc758 \ub9ac\uc2a4\ud2b8\ub85c \ub9cc\ub4e6","49cdd85f":"# \uc704\uc640 \uac19\uc740 \uc774\uc720\ub85c Valid \ud3f4\ub354\ub0b4\uc758 Class \ud3f4\ub354\ub0b4\uc758 \uc774\ubbf8\uc9c0\ub4e4\uc758 \ub9ac\uc2a4\ud2b8\ub974 \ub9cc\ub4e6\n# Valid \ud3f4\ub354 > Class \ud3f4\ub354 > \uc774\ubbf8\uc9c0\n\nvalid_files_path = os.path.join('\/kaggle\/input\/kaggle-oxford-dataset-rgh\/KAGGLE\/valid')\nvalid_files = os.listdir(valid_files_path)\n\nvalid_all_list = []\n\nfor valid_file in valid_files:\n    temp_path = os.path.join(valid_files_path,valid_file)\n    for i in os.listdir(temp_path):\n        valid_all_list.append(i)\n        \nimage_files = train_all_list + valid_all_list\nprint(len(train_all_list), len(valid_all_list), '-->',len(image_files))\nimage_files","546a5151":"# \uc55e\uc5d0\uc11c \ub9cc\ub4e0 \uc2e4\uc81c \ud30c\uc77c\uba85 \ub9ac\uc2a4\ud2b8\uc5d0\uc11c \uc774\ub984\ub9cc \ubf51\uc544\ub0b4\uc11c List\ub85c \ub9cc\ub4e4\uc5b4\uc90c\n\nclass_list = []   # \ube44\uc5b4\uc788\ub294 \ub9ac\uc2a4\ud2b8\ub97c \ub9cc\ub4e6\n\nfor image_file in image_files:\n    file_name = os.path.splitext(image_file)[0]    # '.'\uc744 \uae30\uc900\uc73c\ub85c \ub098\ub204\uace0 0\ubc88\uc9f8, havanese_48.jpg -> havanese_48\n    \n#     print(class_name)   \n#     raise RuntimeError                           # \uace0\uc758\ub85c \uc5d0\ub7ec\ub97c \ubc1c\uc0dd\uc2dc\ucf1c For\ubb38\uc744 \uba48\ucd94\uac8c \ud568, For\ubb38 \ub0b4\uc5d0 \ud568\uc218\ub4e4\uc774 \uc5b4\ub5a4 Output\uc744 \ub0b4\ub294\uc9c0 \ud655\uc778\ud560 \ub54c \uc720\uc6a9\n\n    class_name = re.sub('_\\d+', '', file_name)     # \uc815\uaddc\uc2dd \ucc98\ub9ac\ubc29\ubc95\uc774\ub77c \ud568, '_'\uc774\ud6c4\uc758 \uc22b\uc790\ub4e4\uc744 \uc9c0\uc6cc\uc90c(\uc27d\uc9c0 \uc54a\uc74c)  https:\/\/greeksharifa.github.io\/%EC%A0%95%EA%B7%9C%ED%91%9C%ED%98%84%EC%8B%9D(re)\/2018\/08\/04\/regex-usage-05-intermediate\/\n\n    class_list.append(class_name)\n\nclass_list = list(set(class_list))                 # set\ud568\uc218\ub97c \uc0ac\uc6a9\ud558\uba74, list\ub4e4\uc911 \uc911\ubcf5\ub41c \uac12\uc744 \uc9c0\uc6cc\uc90c(set\ud615\ud0dc\ub85c \ubcc0\ud615\ub428) -> \ub2e4\uc2dc List\ub85c \ubc14\uafd4\uc918\uc57c\ud568 \nclass_list.sort()                                  # list\ub97c \uc624\ub984\ucc28\uc21c\uc73c\ub85c \uc815\ub82c\uc2dc\ucf1c\uc90c\nclass_list","757a7cc5":"class_list[3]    # Class List\uc5d0 \uc22b\uc790\ub97c \ub123\uc5b4\uc8fc\uba74 ","bfb44714":"#=== Hyper Parameters ===#\nn_train = 0\n\nN_CLASS = len(class_list)\nN_EPOCHS = 50                                      # Training \uc2dc\ud0ac \ud68c\uc218\ub97c \uc870\uc815, \uc804\uccb4 \ub370\uc774\ud130\uac00 5920\uac1c\uba74 5920\uac1c\ub97c 50\ubc88 \ubc18\ubcf5\ud55c\ub2e4\nN_BATCH = 40                                       # \uc5bc\ub9c8\ub098 \ub9ce\uc740 \uc774\ubbf8\uc9c0\ub97c \ubaa8\ub378\uc5d0 \ub3d9\uc2dc\uc5d0 \ub123\uc744\uc9c0 \uc124\uc815\ud568(\ud55c\ubc88\uc5d0 40\uac1c\uc529 \ud559\uc2b5\ud568 -> 5920\/40\ud68c \ud559\uc2b5\ud55c\ub2e4\uace0 \ubcf4\uba74\ub428)\n\nN_TRAIN = len(train_all_list)                      # Train \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc758 \uac1c\uc218\nN_VAL = len(valid_all_list)                        # Valid \uc774\ubbf8\uc9c0 \ub370\uc774\ud130\uc758 \uac1c\uc218\n\nIMG_SIZE = 224                                     # \uc774\ubbf8\uc9c0\ub97c Resize \uc2dc\ud0ac \uc0ac\uc774\uc988 \uc124\uc815 (\ud574\ub2f9 \uc0ac\uc774\uc988\ub85c \uac00\ub85c \ubc0f \uc138\ub85c\uac00 \ubcc0\ud615\ub428)\nlearning_rate = 0.0001                             # \ud559\uc2b5 \ud3ed(?) \ub9d0\uadf8\ub300\ub85c learing rate\nsteps_per_epoch = N_TRAIN \/ N_BATCH                # \ud55c epoch\uc5d0\uc11c \uc5bc\ub9c8\ub098 \uc6c0\uc9c1\uc77c\uc9c0(?) \uc2a4\ud15d\uc218\ub97c \uc815\ud574\uc90c\nvalidation_steps = int(np.ceil(N_VAL \/ N_BATCH))   # Valid \uac1c\uc218\uac00 506\uac1c\uc778\ub370, 40 Batch\ub85c \ub098\ub204\uba74, Step\uc774 12.65\uac1c\uac00 \ub428, \uac00\uae09\uc801 \ub0a8\uc740\uac83\ub3c4 \ub2e4 \uc4f0\uace0\uc790 \uc62c\ub9bc(np.ceil)\ud574\uc90c","6d6a3249":"from keras.preprocessing.image import ImageDataGenerator\n\n#=== Train \uc774\ubbf8\uc9c0\ub97c \ubcc0\ud615\uc2dc\ud0ac \ub0b4\uc6a9\uc744 ImageDataGenerator\uc5d0 \uc791\uc131\ud574\uc90c ===#\ntrain_datagen = ImageDataGenerator(rescale=1. \/ 255,\n#                                    rotation_range=40,\n#                                    width_shift_range=0.2,     # \uac00\ub85c \ubc29\ud5a5\uc73c\ub85c \uc774\ub3d9\n#                                    height_shift_range=0.2,    # \uc138\ub85c \ubc29\ud5a5\uc73c\ub85c \uc774\ub3d9\n#                                    shear_range=0.2,           # \uc774\ubbf8\uc9c0 \uad74\uc808\n#                                    zoom_range=0.2,            # \uc774\ubbf8\uc9c0 \ud655\ub300\n#                                    horizontal_flip=True,      # \ud6a1\ubc29\ud5a5\uc73c\ub85c \uc774\ubbf8\uc9c0 \ubc18\uc804\n#                                    fill_mode='nearest'\n                                  )      \n\n#=== \uc704\uc5d0\uc11c \ub9cc\ub4e0 ImageDataGenerator(\ubcc0\ud615)\uc744 \uc0ac\uc6a9\ud574\uc11c Batch \ubcc4\ub85c \ucd9c\ub825\ub420 \uc218 \uc788\uac8c train_generator\ub97c \ub9cc\ub4e6 ===#\ntrain_generator = train_datagen.flow_from_directory(train_files_path, \n                                                    batch_size=N_BATCH,\n                                                    target_size=(224, 224),\n                                                    class_mode='categorical',     # binary \/ categorical\n                                                    )","24ee2739":"\n#=== valid \uc774\ubbf8\uc9c0\ub97c \ubcc0\ud615\uc2dc\ud0ac \ub0b4\uc6a9\uc744 ImageDataGenerator\uc5d0 \uc791\uc131\ud574\uc90c, Valid \ub370\uc774\ud130\ub294 \uac00\uae09\uc801 \ubcc0\ud615\uc5c6\uc774 \ub123\ub294\uac8c \uc88b\uc74c  ===#\nvalid_datagen = ImageDataGenerator(rescale=1. \/ 255)      \n\n#=== \uc704\uc5d0\uc11c \ub9cc\ub4e0 ImageDataGenerator(\ubcc0\ud615)\uc744 \uc0ac\uc6a9\ud574\uc11c Batch \ubcc4\ub85c \ucd9c\ub825\ub420 \uc218 \uc788\uac8c valid_generator\ub97c \ub9cc\ub4e6 ===#\nvalid_generator = valid_datagen.flow_from_directory(valid_files_path, \n                                                    batch_size=N_BATCH,\n                                                    target_size=(224, 224),\n                                                    class_mode='categorical',     # binary \/ categorical\n                                                    )","67492223":"#=== import Pretrained Model\uc744 \ubd88\ub7ec\uc634 ===#\nfrom tensorflow.keras.applications.densenet import DenseNet121   # \uc880\ub354 \uc88b\uc740 \ubaa8\ub378\ub85c Training \uc2dc\ucf1c\ubcf4\uc790\nfrom tensorflow.keras import models\nfrom tensorflow.keras.layers import Conv2D, ReLU, MaxPooling2D, Dense, BatchNormalization, GlobalAveragePooling2D\n\ndensenet = DenseNet121(weights='imagenet', include_top=False, input_shape=(IMG_SIZE, IMG_SIZE, 3))\n","0b506e02":"#=== \ubaa8\ub378\uc744 \uc124\uacc4\ud568(\ud568\uc218\ub85c \ub9cc\ub4e4\uc5b4\uc11c) ===#\ndef create_dense_model():\n    model = models.Sequential()\n    model.add(densenet)                # \uc704\uc5d0\uc11c \ubd88\ub7ec\uc628 pretrained Densenet\uc744 \ubd88\ub7ec\uc634\n    model.add(GlobalAveragePooling2D())\n    model.add(Dense(256))\n    model.add(BatchNormalization())\n    model.add(ReLU())\n    model.add(Dense(N_CLASS, activation='softmax'))\n    return model","11dd4998":"#=== \uc704\uc5d0\uc11c \uc124\uacc4\ud55c \ubaa8\ub378\uc744 \ubd88\ub7ec\uc634 \ubaa8\ub378\uc744 \ub9cc\ub4e4\uc5b4 \uc90c ===#\nmodel = create_dense_model()","0ce9c0db":"#=== Learning Rate\ub97c \uc81c\uc5b4\ud558\ub294 \ud568\uc218(\uc800\ub3c4 \uc798 \ubaa8\ub984) ===#\nLR_INIT = 0.000001\nLR_MAX = 0.0002\nLR_MIN = LR_INIT\nRAMPUP_EPOCH = 4\nEXP_DECAY = 0.9\n\ndef lr_schedule_fn(epoch):\n    if epoch < RAMPUP_EPOCH:\n        lr = (LR_MAX - LR_MIN) \/ RAMPUP_EPOCH * epoch + LR_INIT\n    else:\n        lr = (LR_MAX - LR_MIN) * EXP_DECAY**(epoch - RAMPUP_EPOCH)\n    return lr\n\nlr_callback = keras.callbacks.LearningRateScheduler(lr_schedule_fn)","5e7d2119":"#=== \uc704\uc5d0\uc11c \ub9cc\ub4e0 \ubaa8\ub378\uc5d0 Optimizer, loss, metric\uc744 \uc124\uc815(compile)\ud574 \uc90c ===#\nmodel.compile(optimizer=tf.keras.optimizers.Adam(LR_INIT),\n              loss=tf.keras.losses.CategoricalCrossentropy(label_smoothing=0.1),\n              metrics=['accuracy'])\n","6405846b":"#=== \ub9cc\ub4e0 \ubaa8\ub378\uc744 \ubd88\ub7ec\uc640\ubd04 ===#\nmodel.summary()","dcdf9b3a":"#=== Training the Model ===#\nhistory = model.fit(train_generator,\n                    epochs=N_EPOCHS,\n                    steps_per_epoch=steps_per_epoch,\n                    validation_data=valid_generator,\n                    validation_steps=validation_steps,\n                    callbacks=[lr_callback]\n                    )","7f59e7dd":"#=== Save Trained-Model ===#\nmodel.save('Densenet121_model.h5')\n","e3ce428d":"#=== Load Trained Model ===#\nnew_model = keras.models.load_model('Densenet121_model.h5')","0a01fcd9":"#=== \uc678\ubd80 \uc774\ubbf8\uc9c0\ub97c \uac00\uc838\ub2e4\uac00 Inferencing ===#\nimg_list = []\nimg_folder_list = [i for i in os.listdir('\/kaggle\/input\/') if i != 'kaggle-oxford-dataset-rgh']\n\nfor img_folder in img_folder_list:\n    img_folder_path = os.path.join('\/kaggle\/input\/',img_folder)\n    for img in os.listdir(img_folder_path):\n        img_list.append(os.path.join('\/kaggle\/input\/',img_folder,img))\n    \n\nfor img_path in img_list:\n\n    #=== Image upload \ud6c4 \uc2e4\ud589 ===#\n    image = Image.open(img_path)   # \uad6c\uae00\uc5d0\uc11c \ub2e4\uc6b4\ubc1b\uc544\uc11c raw directory \ud3f4\ub354\uc5d0 \ub123\uace0 \ub3cc\ub9ac\uba74 \ub428\n    image = image.resize((224, 224))\n    image = np.array(image)\n    image = image\/255.\n\n    plt.imshow(image)\n    plt.show()\n    print(image.shape)\n\n    image = np.reshape(image, (1, 224, 224, 3))   # CNN\uc740 4\ucc28\uc6d0\uc758 \ub370\uc774\ud130\ub97c \ubc1b\uc73c\ub2c8\uae4c, \uc55e\uc5d0 1\ucc28\uc6d0\ub3c4 \uaef4\uc90c\n\n\n    #=== Predict ===#\n    prediction = new_model.predict(image)\n    pred_class = np.argmax(prediction, axis=-1)   # argmax\ub97c \ud558\uba74 \uc55e\uc5d0\uc11c OHE\ub85c \ub098\uc628 \ud655\ub960\uc5d0 \ub300\ud55c class\uac00 \ub098\uc634\n    print(pred_class)\n    print(class_list[int(pred_class)])    # Chihauhau!! \uc3d8\ub9ac\uc9c8\ub7ec!!\n","e4a27d0d":"# Inferencing","c48cdf5f":"# Save trained model","3c1cf044":"# Prepare the image class\n\n- \ud5a5\ud6c4 argmax\ub97c \uc704\ud55c Class \uc815\ub9ac\ub97c \ud574\uc57c\ud568\n- \ub525\ub7ec\ub2dd \ub9c8\uc9c0\ub9c9\uc5d0 Softmax\ud568\uc218\ub97c \ud1b5\ud574 Class\ubcc4\ub85c \ud655\ub960\uc801\uc73c\ub85c \uac12\uc774 \ub098\uc634 -> \uadf8\uac78 Argmax\ub97c \ud1b5\uacfc\ud558\uba74 \uba87\ubc88\uc9f8 Class\uc778\uc9c0 \ucd9c\ub825\ub428 -> \ucd9c\ub825\ub41c Class\uac00 \uc5b4\ub5a4 \uac12\uc778\uc9c0 \uc54c\uae30 \uc704\ud574 Mapping table\uc744 \uac70\uce68 -> \uac15\uc544\uc9c0 \uc774\ub984 \ucd9c\ub825\n- example) \uc774\ubbf8\uc9c0 -> \ub525\ub7ec\ub2dd(CNN) -> Softmax -> Output1: [0.01, 0.01, 0.13, 0.6, 0.12, ... ] -> Argmax -> Output2: Class[3] -> 'shiba_inu'\n","878a4bdf":"# Make the Model","c90b13e8":"# Model Training","2943246f":"# Check Image File","d98762ec":"# Load Trained Model"}}