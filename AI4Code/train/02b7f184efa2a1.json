{"cell_type":{"42383eab":"code","ec1b3461":"code","18cee88a":"code","752ccb13":"code","723ae30c":"code","bcca83a1":"code","2e5d96c5":"code","de1c828e":"code","7a943749":"code","200dea1a":"code","0f95a409":"code","13a71003":"code","1e16a082":"code","7fdc1c7a":"code","1be589d2":"code","528bd8a6":"code","1fec0755":"code","c75bc071":"code","0fbf1cb6":"code","7548de6d":"code","bd1d820c":"code","764bf839":"code","5d541058":"code","d75c393f":"code","1cbbd501":"markdown","d566665f":"markdown","04ed7876":"markdown","52e52bec":"markdown","6acc2763":"markdown","d4eda742":"markdown","37f9bf6d":"markdown","ac6233e5":"markdown","c855df61":"markdown","a2765623":"markdown","00faaa31":"markdown","78d6c2fc":"markdown","339e8bd6":"markdown","8f69dbe2":"markdown","564ae8b3":"markdown"},"source":{"42383eab":"!pip install --upgrade wandb\n# !pip install python-box timm pytorch-lightning==1.4.0 grad-cam ttach\n!pip install grad-cam\n!pip install ttach","ec1b3461":"import os\nimport cv2\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","18cee88a":"train = pd.read_csv('..\/input\/petfinder-pawpularity-score\/train.csv')\ntest = pd.read_csv('..\/input\/petfinder-pawpularity-score\/test.csv')\n\ndef get_train_file_path(image_id):\n    return \"..\/input\/petfinder-pawpularity-score\/train\/{}.jpg\".format(image_id)\n\ndef get_test_file_path(image_id):\n    return \"..\/input\/petfinder-pawpularity-score\/test\/{}.jpg\".format(image_id)\n\ntrain['file_path'] = train['Id'].apply(get_train_file_path)\ntest['file_path'] = test['Id'].apply(get_test_file_path)\n\ndisplay(train.head())\ndisplay(test.head())","752ccb13":"train['Pawpularity'].hist()","723ae30c":"plt.figure(figsize=(20, 20))\nrow, col = 5, 5\nfor i in range(row * col):\n    plt.subplot(col, row, i+1)\n    image = cv2.imread(train.loc[i, 'file_path'])\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    target = train.loc[i, 'Pawpularity']\n    plt.imshow(image)\n    plt.title(f\"target: {target}\")\nplt.show()","bcca83a1":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","2e5d96c5":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    apex=True\n    debug=False\n    print_freq=10\n    num_workers=5\n    size=380\n    model_name='tf_efficientnet_b4_ns'\n    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    epochs=4\n    #factor=0.2 # ReduceLROnPlateau\n    #patience=4 # ReduceLROnPlateau\n    #eps=1e-6 # ReduceLROnPlateau\n    T_max=3 # CosineAnnealingLR\n    #T_0=3 # CosineAnnealingWarmRestarts\n    lr=1e-4\n    min_lr=1e-6\n    batch_size=32\n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=42\n    target_size=1\n    target_col='Pawpularity'\n    n_fold=5\n    trn_fold=[0, 1, 2, 3, 4]\n    train=True\n    grad_cam=False\n    \nif CFG.debug:\n    CFG.epochs = 1\n    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)","de1c828e":"# ====================================================\n# Library\n# ====================================================\nimport os\nimport gc\nimport sys\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nfrom pytorch_grad_cam.utils.image import show_cam_on_image\nfrom pytorch_grad_cam import GradCAM, ScoreCAM, GradCAMPlusPlus, AblationCAM, XGradCAM, EigenCAM\n\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","7a943749":"# ====================================================\n# wandb\n# ====================================================\nfrom kaggle_secrets import UserSecretsClient\nuser_secrets = UserSecretsClient()\nwandb_api = \"6c6e401793e8b7ca65e102c2218de61138550547\"\n\nimport wandb\nwandb.login(key=wandb_api)\n\ndef class2dict(f):\n    return dict((name, getattr(f, name)) for name in dir(f) if not name.startswith('__'))\n\nrun = wandb.init(project=\"PetFinder-Public\",\n                 entity='ppchkall86',\n                 name=CFG.model_name,\n                 config=class2dict(CFG),\n                 group=CFG.model_name,\n                 job_type=\"train\")","200dea1a":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = mean_squared_error(y_true, y_pred, squared=False) # RMSE\n    return score\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=42):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","0f95a409":"num_bins = int(np.floor(1 + np.log2(len(train))))\ntrain[\"bins\"] = pd.cut(train[CFG.target_col], bins=num_bins, labels=False)\n\nFold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(train, train[\"bins\"])):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\ndisplay(train.groupby(['fold', \"bins\"]).size())","13a71003":"train.to_pickle(OUTPUT_DIR+'train.pkl')","1e16a082":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        file_path = self.file_names[idx]\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        if self.transform:\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image, label\n\n    \nclass GradCAMDataset(Dataset):\n    def __init__(self, df):\n        self.df = df\n        self.image_ids = df['Id'].values\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = get_transforms(data='valid')\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_id = self.image_ids[idx]\n        file_path = self.file_names[idx]\n        image = cv2.imread(file_path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        vis_image = cv2.resize(image, (CFG.size, CFG.size)).copy()\n        if self.transform:\n            image = self.transform(image=image)['image']\n        label = torch.tensor(self.labels[idx]).float()\n        return image_id, image, vis_image, label","7fdc1c7a":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            A.RandomResizedCrop(CFG.size, CFG.size, scale=(0.85, 1.0)),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n#             A.RandomBrightness(p=1),\n#             A.InvertImg(p=1),\n#             A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit= 20, val_shift_limit=20, p=1.0),\n            #OneOf\u306f\u3069\u3061\u3089\u304b\u4e00\u65b9\u3068\u3044\u3046\u610f\u5473\u3002\u4ee5\u4e0b\u306e\u4f8b\u306f\u3001HueSaturationValue\u3001RandomBrightnessContrast\u306e\u3069\u3061\u3089\u304b\u3092\u9078\u629e\u3059\u308b\u3068\u3044\u3046\u610f\u5473\n            A.OneOf([\n                A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, val_shift_limit=0.2, p=0.7),\n                A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n            ],p=0.7),\n            A.OneOf([\n                A.HorizontalFlip(p=0.7),\n                A.VerticalFlip(p=0.7)\n            ],p=0.7),\n            A.ShiftScaleRotate(shift_limit=0.5, rotate_limit=20, p=0.5),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            A.Normalize(\n                mean=[0.485, 0.456, 0.406],\n                std=[0.229, 0.224, 0.225],\n            ),\n#             A.HueSaturationValue(val_shift_limit=(30, 30), p=1),\n#             A.RandomBrightness(p=1),\n#             A.InvertImg(p=1),\n#             A.HueSaturationValue(hue_shift_limit=20, sat_shift_limit= 20, val_shift_limit=20, p=1.0),\n            #OneOf\u306f\u3069\u3061\u3089\u304b\u4e00\u65b9\u3068\u3044\u3046\u610f\u5473\u3002\u4ee5\u4e0b\u306e\u4f8b\u306f\u3001HueSaturationValue\u3001RandomBrightnessContrast\u306e\u3069\u3061\u3089\u304b\u3092\u9078\u629e\u3059\u308b\u3068\u3044\u3046\u610f\u5473\n#             A.OneOf([\n#                 A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit= 0.2, val_shift_limit=0.2, p=0.7),\n#                 A.RandomBrightnessContrast(brightness_limit=0.2, contrast_limit=0.2, p=0.7),\n#             ],p=0.7),\n            ToTensorV2(),\n        ])","1be589d2":"train_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(5):\n    plt.figure(figsize=(4, 4))\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show() ","528bd8a6":"# ====================================================\n# MODEL\n# ====================================================\nclass CustomModel(nn.Module):\n    def __init__(self, cfg, pretrained=False):\n        super().__init__()\n        self.cfg = cfg\n        self.model = timm.create_model(self.cfg.model_name, pretrained=pretrained)\n        self.n_features = self.model.classifier.in_features\n        self.model.classifier = nn.Identity()\n        self.fc = nn.Linear(self.n_features, self.cfg.target_size)\n\n    def feature(self, image):\n        feature = self.model(image)\n        return feature\n        \n    def forward(self, image):\n        feature = self.feature(image)\n        output = self.fc(feature)\n        return output","1fec0755":"# ====================================================\n# Loss\n# ====================================================\nclass RMSELoss(nn.Module):\n    def __init__(self, eps=1e-6):\n        super().__init__()\n        self.mse = nn.MSELoss()\n        self.eps = eps\n\n    def forward(self, yhat, y):\n        loss = torch.sqrt(self.mse(yhat, y) + self.eps)\n        return loss","c75bc071":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    model.train()\n    if CFG.apex:\n        scaler = GradScaler()\n    losses = AverageMeter()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        if CFG.apex:\n            with autocast():\n                y_preds = model(images)\n                loss = criterion(y_preds.view(-1), labels)\n        else:\n            y_preds = model(images)\n            loss = criterion(y_preds.view(-1), labels)\n        # record loss\n        losses.update(loss.item(), batch_size)\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        if CFG.apex:\n            scaler.scale(loss).backward()\n        else:\n            loss.backward()\n        grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n        if (step + 1) % CFG.gradient_accumulation_steps == 0:\n            if CFG.apex:\n                scaler.step(optimizer)\n                scaler.update()\n            else:\n                optimizer.step()\n            optimizer.zero_grad()\n            global_step += 1\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n            print('Epoch: [{0}][{1}\/{2}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  'Grad: {grad_norm:.4f}  '\n                  'LR: {lr:.6f}  '\n                  .format(epoch+1, step, len(train_loader), \n                          remain=timeSince(start, float(step+1)\/len(train_loader)),\n                          loss=losses,\n                          grad_norm=grad_norm,\n                          lr=scheduler.get_lr()[0]))\n        wandb.log({f\"[fold{fold}] loss\": losses.val,\n                   f\"[fold{fold}] lr\": scheduler.get_lr()[0]})\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    model.eval()\n    losses = AverageMeter()\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds.view(-1), labels)\n        losses.update(loss.item(), batch_size)\n        # record accuracy\n        preds.append(y_preds.to('cpu').numpy())\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        end = time.time()\n        if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n            print('EVAL: [{0}\/{1}] '\n                  'Elapsed {remain:s} '\n                  'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                  .format(step, len(valid_loader),\n                          loss=losses,\n                          remain=timeSince(start, float(step+1)\/len(valid_loader))))\n    predictions = np.concatenate(preds)\n    return losses.avg, predictions","0fbf1cb6":"def get_grad_cam(model, device, x_tensor, img, label, plot=False):\n    result = {\"vis\": None, \"img\": None, \"pred\": None, \"label\": None}\n    with torch.no_grad():\n        pred = model(x_tensor.unsqueeze(0).to(device))\n    pred = np.concatenate(pred.to('cpu').numpy())[0]\n    target_layer = model.model.conv_head\n    cam = GradCAM(model=model, target_layer=target_layer, use_cuda=torch.cuda.is_available())\n    output = cam(input_tensor=x_tensor.unsqueeze(0).to(device))\n    try:\n        vis = show_cam_on_image(img \/ 255., output[0])\n    except:\n        return result\n    if plot:\n        fig, axes = plt.subplots(figsize=(8, 8), ncols=2)\n        axes[0].imshow(vis)\n        axes[0].set_title(f\"pred={pred:.4f}\")\n        axes[1].imshow(img)\n        axes[1].set_title(f\"target={label}\")\n        plt.show()\n    result = {\"vis\": vis, \"img\": img, \"pred\": pred, \"label\": label}\n    torch.cuda.empty_cache()\n    return result","7548de6d":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_col].values\n\n    train_dataset = TrainDataset(train_folds, transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, transform=get_transforms(data='train'))\n\n    train_loader = DataLoader(train_dataset,\n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = CustomModel(CFG, pretrained=True)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    criterion = RMSELoss()\n\n    best_score = np.inf\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(fold, train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds = valid_fn(valid_loader, model, criterion, device)\n        \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n        wandb.log({f\"[fold{fold}] epoch\": epoch+1, \n                   f\"[fold{fold}] avg_train_loss\": avg_loss, \n                   f\"[fold{fold}] avg_val_loss\": avg_val_loss,\n                   f\"[fold{fold}] score\": score})\n\n        if score < best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth')\n    \n    valid_folds['preds'] = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth', \n                                      map_location=torch.device('cpu'))['preds']\n\n    return valid_folds","bd1d820c":"# ====================================================\n# main\n# ====================================================\ndef main():\n\n    \"\"\"\n    Prepare: 1.train \n    \"\"\"\n\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.4f}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(train, fold)\n                oof_df = pd.concat([oof_df, _oof_df])\n                LOGGER.info(f\"========== fold: {fold} result ==========\")\n                get_result(_oof_df)\n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)\n    \n    if CFG.grad_cam:\n        wandb_table = wandb.Table(columns=[\"Id\", \"Pawpularity\", \"pred\", \"image\", \"grad_cam_image\"])\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                # load model\n                model = CustomModel(CFG, pretrained=False)\n                state = torch.load(OUTPUT_DIR+f'{CFG.model_name}_fold{fold}_best.pth', \n                                   map_location=torch.device('cpu'))['model']\n                model.load_state_dict(state)\n                model.to(device)\n                model.eval()\n                # load oof\n                oof = pd.read_csv(OUTPUT_DIR+'oof_df.csv')\n                oof['diff'] = abs(oof['Pawpularity'] - oof['preds'])\n                oof = oof[oof['fold'] == fold].reset_index(drop=True)\n                # grad-cam (oof ascending=False)\n                count = 0\n                oof = oof.sort_values('diff', ascending=False)\n                valid_dataset = GradCAMDataset(oof)\n                for i in range(len(valid_dataset)):\n                    image_id, x_tensor, img, label = valid_dataset[i]\n                    result = get_grad_cam(model, device, x_tensor, img, label, plot=True)\n                    if result[\"vis\"] is not None:\n                        count += 1\n                        wandb_table.add_data(image_id, \n                                             result[\"label\"], \n                                             result[\"pred\"], \n                                             wandb.Image(result[\"img\"]), \n                                             wandb.Image(result[\"vis\"]))\n                    if count >= 5:\n                        break\n                # grad-cam (oof ascending=True)\n                count = 0\n                oof = oof.sort_values('diff', ascending=True)\n                valid_dataset = GradCAMDataset(oof)\n                for i in range(len(valid_dataset)):\n                    image_id, x_tensor, img, label = valid_dataset[i]\n                    result = get_grad_cam(model, device, x_tensor, img, label, plot=True)\n                    if result[\"vis\"] is not None:\n                        count += 1\n                        wandb_table.add_data(image_id, \n                                             result[\"label\"], \n                                             result[\"pred\"], \n                                             wandb.Image(result[\"img\"]), \n                                             wandb.Image(result[\"vis\"]))\n                    if count >= 5:\n                        break\n        wandb.log({'grad_cam': wandb_table})\n    \n    wandb.finish()","764bf839":"if __name__ == '__main__':\n    main()","5d541058":"# model = CustomModel(CFG, pretrained=False)","d75c393f":"# model","1cbbd501":"# Transforms","d566665f":"# Helper functions","04ed7876":"# About this notebook\n- PyTorch efficientnet_b0 with W&B starter code\n- Pytorch W&B Usage Examples from https:\/\/docs.wandb.ai\/guides\/integrations\/pytorch\n\nIf this notebook is helpful, feel free to upvote :)","52e52bec":"# MODEL","6acc2763":"# CFG","d4eda742":"![](https:\/\/www.petfinder.my\/images\/cuteness_meter.jpg)","37f9bf6d":"# Directory settings","ac6233e5":"# Loss","c855df61":"# Library","a2765623":"# Dataset","00faaa31":"# Utils","78d6c2fc":"# CV split","339e8bd6":"# Train loop","8f69dbe2":"# Quick EDA","564ae8b3":"# Data Loading"}}