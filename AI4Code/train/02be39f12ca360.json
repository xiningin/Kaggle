{"cell_type":{"cb99d9ec":"code","dec84d0b":"code","3d9a6da7":"code","8f70f79a":"code","622aff5e":"code","07e124ff":"code","6885e9b4":"code","1fb6dbcf":"code","a9eda2c5":"code","3c95074a":"code","064a8012":"code","9353f1dc":"code","d4592057":"code","c7639cf9":"code","27eefece":"code","2ec3f2ea":"code","008f6e6d":"code","943468fc":"code","e4c5372b":"code","e60f7017":"code","b5a86193":"code","4a512e39":"markdown","7c9d2e50":"markdown","bb6dffa2":"markdown","5e3f4bd7":"markdown","9f67931e":"markdown","35404948":"markdown","418a74a6":"markdown","90b6ed58":"markdown","ee978896":"markdown","0394f8b9":"markdown"},"source":{"cb99d9ec":"# Basic libraries\nimport pandas as pd\nimport numpy as np\nimport os\n\n# Plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# SKlearn related libraries\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, zero_one_loss, hamming_loss\n\n# Boosting technique algorithm\nimport xgboost as xgb\n","dec84d0b":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3d9a6da7":"# Dataset path\nDATA_PATH = \"\/kaggle\/input\/wineuci\/Wine.csv\"\n\ncolumns = ['class','alcohol', 'malic_acid', 'ash', 'alcalinity_of_ash', 'magnesium',\n    'total_phenols', 'flavanoids', 'nonflavanoid_phenols',\n    'proanthocyanins', 'color_intensity', 'hue',\n    'od280\/od315_of_diluted_wines', 'proline']\n\nwine_data = pd.read_csv(DATA_PATH, names=columns, header=0)\n\nwine_data.info()\nprint(\"==\"*40)\nwine_data.head()","8f70f79a":"# transform the label into 0, 1, 2\ndef trans_class(class_label):\n    return int(class_label) - 1","622aff5e":"wine_data['class'] = wine_data['class'].apply(trans_class)","07e124ff":"np.unique(wine_data['class'])","6885e9b4":"wine_data.describe().T","1fb6dbcf":"print(f\"Is there any null values : {wine_data.isnull().sum().any()}\")","a9eda2c5":"sns.set(style='whitegrid', palette='muted')\n\n# Pairplot to see the attribute comparison\nfig, ax = plt.subplots(1,2,figsize=(12,6))\n\nsns.distplot(wine_data['alcohol'], kde=True, hist=True, ax=ax[0])\n\nsns.distplot(wine_data['malic_acid'], kde=True, hist=True, ax=ax[1])\n\nplt.show()\n\ng = sns.jointplot(x=wine_data['alcohol'], y=wine_data['malic_acid'], color='r')\n","3c95074a":"wine_data['class'].value_counts().plot.bar()","064a8012":"# Making X and Y data from the dataset\nX = wine_data.loc[:, wine_data.columns != 'class'].values\ny = wine_data['class'].values","9353f1dc":"print(f\"Train shape : {X.shape}, Label : { y.shape}\")","d4592057":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(f\"Train shape : {X_train.shape}, Label : { y_train.shape}\")","c7639cf9":"dm_train = xgb.DMatrix(data=X_train, label=y_train)\ndm_test = xgb.DMatrix(data=X_test)","27eefece":"# Key parameters\nparams = {\n    'max_depth': 6,\n    'min_child_weight':1,\n    'objective': 'multi:softmax',\n    'subsample':1,\n    'colsample_bytree':1,\n    'num_class': 3,\n    'n_gpus': 0\n}","2ec3f2ea":"xgb_clf = xgb.train(params, dm_train) # Train the model with dataset\n","008f6e6d":"# Prediction\npredictions = xgb_clf.predict(dm_test)","943468fc":"predictions","e4c5372b":"print(\"Classification Report \\n {}\".format(classification_report(y_test, predictions)))","e60f7017":"print(\"Misclassification rate {}\".format(zero_one_loss(y_test, predictions, normalize=False)))","b5a86193":"print(\"Hamming rate {:.2f}\".format(hamming_loss(y_test, predictions)))","4a512e39":"## 3.Exploratory Data Analysis","7c9d2e50":"## 5. Model","bb6dffa2":"### Misclassification Rate\n\nIn multilabel classification, the zero_one_loss function corresponds to the subset zero-one loss: for each sample, the entire set of labels must be correctly predicted, otherwise the loss for that sample is equal to one.\n\nIf normalize is True, return the fraction of misclassifications (float), else it returns the number of misclassifications (int). The best performance is 0.","5e3f4bd7":"### DMatrix\n\nXGB algorithm expects the data in 'DMatrix' form. We will use the data to construct Dmatrix object.","9f67931e":" # Multiclass Classification - Ensemble Method\n \n ## Introduction\n \nThese data are the results of a chemical analysis of **wines grown** in the same region in Italy but derived from three different cultivars. \nThe analysis determined the quantities of 13 constituents found in each of the three types of wines.\n \n ","35404948":"## 4. Prepare dataset","418a74a6":"## 6. Evaluation","90b6ed58":"## 2.Load the dataset","ee978896":"## 1. Import dependent libraries","0394f8b9":"## Hamming Loss\n\nIn multiclass classification, the Hamming loss corresponds to the Hamming distance between y_true and y_pred which is equivalent to the subset zero_one_loss function, when normalize parameter is set to True."}}