{"cell_type":{"956d541d":"code","1244187f":"code","f1d65909":"code","7a4ed763":"code","c183361f":"code","04e5b6aa":"code","a73717ad":"code","ea14e625":"code","c559d2f5":"code","1b461df6":"code","b7f5613a":"code","08f849e1":"code","7259cde6":"code","fa85ecae":"code","f5a4569f":"code","8d52527f":"code","3751e709":"code","031809fd":"code","183573f8":"code","67244390":"code","00c24d1a":"code","5d86b33c":"code","e24e8cc8":"code","fb641661":"code","2406544f":"code","f5ea37cc":"code","706d8780":"code","b68e0a12":"code","0ce230c5":"code","eae776b3":"code","d77293b0":"code","131a6500":"code","e7da6a59":"code","435f2bcc":"code","869c36dd":"code","fbeb89aa":"code","53105b08":"code","3c4e4dbc":"code","19320630":"code","e059028a":"code","08dcb0f5":"code","c6b53bd3":"code","a3faf5c0":"code","bde2cc1f":"code","b2d10f15":"code","367b621c":"code","06323d34":"code","202aa91c":"code","cfdbe1af":"code","ca7a5118":"code","847e4005":"code","ab53f79d":"code","a243d674":"code","90142fdb":"code","12b494a8":"markdown","ab015c07":"markdown"},"source":{"956d541d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1244187f":"import tensorflow as tf\nimport tensorflow_hub as hub\n\nprint(tf.__version__)\nprint(hub.__version__)","f1d65909":"labels = pd.read_csv('\/kaggle\/input\/dog-breed-identification\/labels.csv')\nlabels.head()","7a4ed763":"train_path = '\/kaggle\/input\/dog-breed-identification\/train\/'","c183361f":"filenames = [train_path + fname + \".jpg\" for fname in labels['id']]","04e5b6aa":"len(filenames)","a73717ad":"import os\nlen(os.listdir(train_path))","ea14e625":"from IPython.display import display, Image","c559d2f5":"Image(filenames[420])","1b461df6":"Image(filenames[69])","b7f5613a":"labels = labels['breed'].to_numpy()","08f849e1":"labels[:5]","7259cde6":"unique_breed = np.unique(labels)","fa85ecae":"boolean_labels = [label==unique_breed for label in labels]","f5a4569f":"boolean_labels[:2]","8d52527f":"X = filenames\ny = boolean_labels","3751e709":"NUM_IMAGES = 1000","031809fd":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X[:NUM_IMAGES], y[:NUM_IMAGES], test_size=0.2)","183573f8":"len(X_train), len(y_train), len(X_val), len(y_val)","67244390":"IMG_SIZE = 224\n\ndef process_image(image_path):\n    image = tf.io.read_file(image_path)\n    image = tf.image.decode_jpeg(image, channels=3)\n    image = tf.image.convert_image_dtype(image, tf.float32)\n    image = tf.image.resize(image, size=[IMG_SIZE, IMG_SIZE])\n    return image","00c24d1a":"#to return image tuple and use that to create batches of data \ndef get_image_label(image_path, label):\n    image = process_image(image_path)\n    return image, label","5d86b33c":"BATCH_SIZE = 32\n\ndef create_data_batches(x, y=None, batch_size=BATCH_SIZE, valid_data=False, test_data=False):\n    #if test data we dont have y(labels)\n    if test_data:\n        print(\"Creating test data batches\")\n        #this basically converts the x and y that we input into tensors\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(x)))\n        #in this we map it to preprocessing function that we wrote and create batches\n        data_batch = data.map(process_image).batch(BATCH_SIZE)\n        return data_batch\n    elif valid_data:\n        #no need to shuffle\n        print(\"Creating validation data batches\")\n        \n        data = tf.data.Dataset.from_tensor_slices((tf.constant(x), tf.constant(y)))\n        data_batch = data.map(get_image_label).batch(BATCH_SIZE)\n        return data_batch\n    else:\n        #train data so shuffle\n        data = tf.data.Dataset.from_tensor_slices((tf.constant(x), tf.constant(y)))\n        data = data.shuffle(buffer_size = len(x))\n        data = data.map(get_image_label)\n        data_batch = data.batch(BATCH_SIZE)\n        \n    return data_batch\n        \n        ","e24e8cc8":"train_data = create_data_batches(X_train, y_train)\nval_data = create_data_batches(X_val, y_val, valid_data=True)","fb641661":"train_data.element_spec, val_data.element_spec","2406544f":"import matplotlib.pyplot as plt","f5ea37cc":"def show_25_images(images, labels):\n    plt.figure(figsize=(10, 10))\n    \n    for i in range(25):\n        ax = plt.subplot(5, 5, i+1)\n        plt.imshow(images[i])\n        plt.title(unique_breed[labels[i].argmax()])\n        plt.axis('off')","706d8780":"train_images, train_labels = next(train_data.as_numpy_iterator())\nshow_25_images(train_images, train_labels)","b68e0a12":"INPUT_SHAPE = [None, IMG_SIZE, IMG_SIZE, 3]\nOUTPUT_SHAPE = len(unique_breed)\n\n# Setup model URL from TensorFlow Hub\nMODEL_URL = \"https:\/\/tfhub.dev\/google\/imagenet\/mobilenet_v2_130_224\/classification\/4\"","0ce230c5":"def create_model(input_shape = INPUT_SHAPE, output_shape = OUTPUT_SHAPE, model_url=MODEL_URL):\n    \n    model = tf.keras.Sequential([\n        hub.KerasLayer(model_url),\n        tf.keras.layers.Dense(units = output_shape, activation='softmax')\n    ])\n    \n    model.compile(\n        loss = tf.keras.losses.CategoricalCrossentropy(),\n        optimizer = tf.keras.optimizers.Adam(),\n        metrics = ['accuracy']\n    )\n    \n    model.build(INPUT_SHAPE)\n    return model","eae776b3":"model = create_model()\nmodel.summary()","d77293b0":"%load_ext tensorboard","131a6500":"import datetime\n\ndef create_tensorboard_callback():\n    logdir = os.path.join(\"logs\",\n                         datetime.datetime.now().strftime(\"%Y%m%d-%H%M%S\"))\n    return tf.keras.callbacks.TensorBoard(logdir)","e7da6a59":"early_stopping = tf.keras.callbacks.EarlyStopping(monitor = 'val_accuracy',\n                                                  patience=3)","435f2bcc":"NUM_EPOCHS = 100","869c36dd":"def train_model():\n    model = create_model()\n    tensorboard = create_tensorboard_callback()\n    \n    model.fit(x = train_data,\n              epochs = NUM_EPOCHS,\n              validation_data = val_data,\n              validation_freq=1,\n              callbacks=[tensorboard, early_stopping])\n    return model","fbeb89aa":"model = train_model()","53105b08":"%tensorboard --logdir logs","3c4e4dbc":"predictions = model.predict(val_data, verbose=True)","19320630":"def get_pred_label(prediction_probabilities):\n    return unique_breed[np.argmax(prediction_probabilities)]","e059028a":"get_pred_label(predictions[0])","08dcb0f5":"def unbatchify(data):\n    images = []\n    labels = []\n    \n    for image, label in data.unbatch().as_numpy_iterator():\n        images.append(image)\n        labels.append(unique_breed[np.argmax(label)])\n    return image, labels","c6b53bd3":"val_images, val_labels = unbatchify(val_data)\nval_images[0], val_labels[0]","a3faf5c0":"full_data = create_data_batches(X, y)","bde2cc1f":"full_model = create_model()","b2d10f15":"full_model_tensorboard = create_tensorboard_callback()\nfull_model_early_stopping = tf.keras.callbacks.EarlyStopping(monitor='accuracy',\n                                                             patience = 3)","367b621c":"full_model.fit(x = full_data,\n               epochs = NUM_EPOCHS,\n               callbacks = [full_model_tensorboard,\n                            full_model_early_stopping])","06323d34":"preds_df = pd.DataFrame(columns=['id'] + list(unique_breed))\npreds_df.head()","202aa91c":"test_path = '\/kaggle\/input\/dog-breed-identification\/test\/'","cfdbe1af":"preds_df['id'] = [os.path.splitext(path)[0] for path in os.listdir(test_path)]\npreds_df.head()","ca7a5118":"test_path = \"..\/input\/dog-breed-identification\/test\/\"\ntest_filenames = [test_path + fname for fname in os.listdir(test_path)]\n\ntest_filenames[:10]","847e4005":"test_data = create_data_batches(test_filenames, test_data=True)","ab53f79d":"test_prediction = full_model.predict(test_data, verbose=1)","a243d674":"preds_df[list(unique_breed)] = test_prediction\npreds_df.head()","90142fdb":"preds_df.to_csv('submission.csv', index=False)","12b494a8":"**This the notebook I did mine from please check this one out**\nhttps:\/\/www.kaggle.com\/mrdbourke\/tensorflow-2-x-tensorflow-hub-end-to-end-example\n\nhis name is Daniel Brouke go subscribe to his yt.","ab015c07":"Train on full data"}}