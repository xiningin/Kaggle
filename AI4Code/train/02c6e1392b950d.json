{"cell_type":{"419f5961":"code","ebc5a33a":"code","be290b80":"code","5b6b580e":"code","2e1a310b":"code","19a1f237":"code","a331a266":"code","c87fdb37":"code","f1c02d0e":"code","473226c6":"code","3a66f158":"code","257e3e72":"code","046042f5":"code","62cc3dc8":"code","9aa0f321":"code","88ea0d4d":"code","b6446159":"code","50d30fec":"code","f8233020":"code","ec75b085":"code","0a3a4a9b":"code","9f6b7341":"code","a33dfb59":"code","c5b66263":"markdown"},"source":{"419f5961":"import warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)\n\nimport os\nfrom tqdm.notebook import tqdm\nimport numpy as np\nimport pandas as pd \nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import accuracy_score, classification_report\n\nimport torch\nimport torchvision.transforms as transforms\nfrom torchvision.datasets import ImageFolder\n\nimport torch.optim as optim\nfrom torch.utils.data import DataLoader\nfrom torch.utils.data import random_split\n\nimport torch.nn as nn\nimport torch.nn.functional as F\n\n# !pip install torchsummary\n# from torchsummary import summary\n\n%matplotlib inline","ebc5a33a":"# Checking device: cuda or cpu\ntorch.cuda.is_available()\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\n# device\n# torch.cuda.get_device_name(0)","be290b80":"data_dir_train = '..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Training'\ndata_dir_test = '..\/input\/fruits\/fruits-360_dataset\/fruits-360\/Test'","5b6b580e":"size_pictures = 100\ndata_transforms = transforms.Compose([transforms.Resize((size_pictures, size_pictures)),transforms.ToTensor()])","2e1a310b":"data_train = ImageFolder(root=data_dir_train,transform=data_transforms)\ndata_test = ImageFolder(root=data_dir_test,transform=data_transforms)\nprint(\"Train data length:{}\\nTest data length:{}\".format(len(data_train), len(data_test)))","19a1f237":"LABELS = os.listdir(data_dir_train)\nprint(\"Label length:{}\".format(len(LABELS)))","a331a266":"# plot class distributions of whole train data_train\ncounts = {}\nfor l in LABELS:\n    counts[l] = len(os.listdir(os.path.join(data_dir_train, l)))\n\n    \nplt.figure(figsize=(30, 5))\nplt.bar(range(len(counts)), list(counts.values()), align='center')\nplt.xticks(range(len(counts)), list(counts.keys()), fontsize=12, rotation=90)\nplt.xlabel('class label', fontsize=13)\nplt.ylabel('class size', fontsize=13)\nplt.title('Fruits Class Distribution (TRAIN DATA)', fontsize=15);","c87fdb37":"# plot class distributions of whole test data_test\ncounts = {}\nfor l in LABELS:\n    counts[l] = len(os.listdir(os.path.join(data_dir_test, l)))\n    \nplt.figure(figsize=(30, 5))\nplt.bar(range(len(counts)), list(counts.values()), align='center')\nplt.xticks(range(len(counts)), list(counts.keys()), fontsize=12, rotation=90)\nplt.xlabel('class label', fontsize=13)\nplt.ylabel('class size', fontsize=13)\nplt.title('Fruits Class Distribution (TEST DATA)', fontsize=15);","f1c02d0e":"def show_random_image():\n    index = np.random.randint(0,len(data_train))\n    return data_train[index]\nimg, label = show_random_image()","473226c6":"fig = plt.figure(figsize=(15,45));\nfor i in range(1,11):\n    plt.subplot(1,10, i,)\n    plt.title(data_train.classes[label])\n    img, label = show_random_image()\n    plt.imshow(img.permute(1, 2, 0));\n    plt.xticks([]);\n    plt.yticks([]);","3a66f158":"train_size = int(0.8 * len(data_train)) \nval_size = len(data_train) - train_size\ntrain_ds, val_ds = random_split(data_train, [train_size, val_size])\nprint(\"Train data length:{}\\nValidation data length:{}\".format(len(train_ds), len(val_ds)))","257e3e72":"class NeuralNetwork(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv1 = nn.Conv2d(in_channels=3, out_channels=7, kernel_size=3, padding=1) # (batch_size,7,100,100)\n        self.act1 = nn.ReLU()\n        self.pool1 = nn.AvgPool2d(kernel_size=2, stride=2) # (batch_size,7,50,50)\n        \n        self.conv2 = nn.Conv2d(in_channels=7, out_channels=10, kernel_size=5, padding=2) # (batch_size,10,50,50)\n        self.act2 = nn.ReLU()\n        self.pool2 = nn.AvgPool2d(kernel_size=2, stride=2) # (batch_size,10,25,25)\n        \n#         self.conv3 = nn.Conv2d(in_channels=10, out_channels=12, kernel_size=5, padding=2) # (batch_size,12,25,25) h\u0131zland\u0131rmak i\u00e7in network k\u0131salt\u0131ld\u0131.\n#         self.act3 = nn.ReLU()\n#         self.pool3 = nn.AvgPool2d(kernel_size=2, stride=2) # (batch_size,12,12,12)\n        \n#         self.fc1 = nn.Linear(1728,  1048)\n#         self.act4 = nn.ReLU()\n        \n        self.fc1 = nn.Linear(6250,  1048)\n        self.act4 = nn.ReLU()\n        \n        self.fc2 = nn.Linear(1048,  524)\n        self.act5 = nn.ReLU()\n        \n        self.fc3 = nn.Linear(524, 262)\n        self.act6 = nn.Sigmoid()\n        \n        self.fc4 = nn.Linear(262, 131)\n        \n        \n    def forward(self, x):\n        x = self.conv1(x)\n        x = self.act1(x)\n        x = self.pool1(x)\n\n        x = self.conv2(x)\n        x = self.act2(x)\n        x = self.pool2(x)\n        \n#         x = self.conv3(x)\n#         x = self.act3(x)\n#         x = self.pool3(x)\n        \n        x = x.view(x.size(0), x.size(1) * x.size(2) * x.size(3))\n        x = self.fc1(x)\n        x = self.act4(x)\n        \n        x = self.fc2(x)\n        x = self.act5(x)\n        \n        x = self.fc3(x)\n        x = self.act6(x)\n        \n        x = self.fc4(x)\n        return x","046042f5":"model = NeuralNetwork()\nprint(model)\n# summary = summary(model,(3, 100, 100)) # torch.Size([256, 3, 100, 100])","62cc3dc8":"model = NeuralNetwork()\nmodel = model.to(device)\nloss = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters(),  lr = 10 **(-3))\nepoch = 10  # 10\nbatch_size = 256","9aa0f321":"acc = []\ndef training(model, batch_size, epochs, loss, optimizer):\n    for epoch in range(1, epochs + 1):\n        model.train()\n        dataloader = DataLoader(dataset=train_ds, batch_size=batch_size, shuffle=True)\n        for (X_batch,y_batch) in tqdm(dataloader): \n            optimizer.zero_grad()\n            \n            X_batch = X_batch.to(device)\n            y_batch = y_batch.to(device)\n\n            preds = model.forward(X_batch)\n            \n            loss_value = loss(preds, y_batch.long())\n            loss_value.backward()            \n            optimizer.step()\n        \n        dataloader_test = DataLoader(dataset=val_ds, batch_size=256)\n        model.eval()\n        with torch.no_grad():\n            summa = 0\n            for (X_batch,y_batch) in tqdm(dataloader_test):\n                X_batch = X_batch.to(device)\n                y_batch = y_batch.to(device)\n                preds = model.forward(X_batch)\n                preds = torch.max(F.softmax(preds, dim=1), dim=1)\n                correct= torch.eq(preds[1], y_batch)\n                summa += torch.sum(correct).item() \n                \n            acc.append(summa \/ len(val_ds))\n            print(f'epoch: {epoch}, acc:{acc[-1]:.2%}')","88ea0d4d":"%%time\ntraining(model, batch_size, epoch, loss, optimizer)","b6446159":"def plot_accuracies(history):\n    accuracies = [x['val_acc'] for x in history]\n    plt.plot(accuracies, '-x')\n    plt.xlabel('epoch')\n    plt.ylabel('accuracy')\n    plt.title('Accuracy vs. No. of epochs')\n    plt.show()\n    \n    \ndef plot_losses(history):\n    train_losses = [x.get('train_loss') for x in history]\n    val_losses = [x['val_loss'] for x in history]\n    plt.plot(train_losses, '-bx')\n    plt.plot(val_losses, '-rx')\n    plt.xlabel('epoch')\n    plt.ylabel('loss')\n    plt.legend(['Training', 'Validation'])\n    plt.title('Loss vs. No. of epochs')\n    plt.show()\n\n# plot_accuracies(history)\n# plot_losses(history)    ","50d30fec":"acc_max = max(acc)\ny_acc_max = acc.index(max(acc))\nplt.title('Accuracy', fontsize = 15 );\nplt.xticks(np.arange(1, epoch));\nplt.scatter( y_acc_max, acc_max, color='darkred', label = f'max_value:{acc_max:.2%}');\nplt.plot(acc, color='red', );\nplt.grid()\nplt.legend(fontsize = 12);","f8233020":"dataloader_test = DataLoader(dataset=data_test, batch_size=256)\nsumma = 0\ny_true = []\ny_pred = []\nfor (X_batch,y_batch) in tqdm(dataloader_test):\n    X_batch = X_batch.to(device)\n    y_batch = y_batch.to(device)\n    preds = model.forward(X_batch)\n    val_predict_class = preds.argmax(dim=-1)\n\n    y_pred.extend([predict_class.item() for predict_class in val_predict_class])\n    y_true.extend([val_label.item() for val_label in y_batch])","ec75b085":"print(f'acc:{accuracy_score(y_true, y_pred):.2%}')","0a3a4a9b":"cl_report = classification_report(y_true, y_pred,output_dict=True, target_names=data_train.classes)","9f6b7341":"report_df = pd.DataFrame(cl_report).T.sort_values(by=['precision', 'recall', 'f1-score'], ascending=False)\nreport_df.drop(['support'], axis=1, inplace=True)\nreport_df","a33dfb59":"max_values = report_df.head(20)\nmin_values = report_df.tail(20)\n\nplt.figure(figsize=(17, 5))\n\n\nplt.subplot(1, 2, 1);\nplt.title('Precision_max');\nmax_values['precision'].plot.bar();\n\nplt.subplot(1, 2, 2);\nplt.title('Precision_min');\nmin_values['precision'].plot.bar();","c5b66263":"# https:\/\/www.kaggle.com\/aleksandrmogilevskiy\/pytorch-conv-layer-96-acc"}}