{"cell_type":{"4376e731":"code","2bb863f2":"code","7bdcd913":"code","5fe619cc":"code","0fb40d37":"code","8a101076":"code","1ccdbc97":"code","b3ad3420":"code","56adf332":"code","75401cdd":"code","b2c26d44":"code","f5492480":"code","d4ef910a":"code","fbe268aa":"code","1105bff0":"code","253a2a60":"code","2b4f4e73":"code","741223a7":"code","7fb21e30":"code","18b0dac5":"code","3ce53db7":"code","701f0873":"code","bca906bc":"code","417ef440":"code","22ddfabd":"code","05166f8f":"code","1533cfa4":"code","b7b8ae8f":"code","c9ae33d9":"code","ffef1029":"code","694a98b7":"code","7d56f7a6":"code","ef8206e4":"code","b60112c6":"code","0355473f":"code","40722434":"code","a6ff97f6":"code","92d9f86e":"code","181e0332":"code","8740a03b":"markdown","1a10d6a4":"markdown","d27ca960":"markdown","4de4703a":"markdown","694799d5":"markdown","20c6c509":"markdown","ac1f5c89":"markdown","2701a54d":"markdown","0d5408cc":"markdown","97272f23":"markdown","dfbd8fe6":"markdown","6b5c1c31":"markdown","ea2b9d42":"markdown","3c2716f4":"markdown"},"source":{"4376e731":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(action=\"ignore\")","2bb863f2":"train = pd.read_csv(\"\/kaggle\/input\/black-friday-predictions\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/black-friday-predictions\/test.csv\")","7bdcd913":"print(train.shape)\nprint(test.shape)\n","5fe619cc":"train.head()","0fb40d37":"sns.distplot(train['Purchase'])\nprint(\"Skewness : {}\".format(train['Purchase'].skew()))\nprint(\"Kurtosis : {}\".format(train.Purchase.kurt()))","8a101076":"# The distribution is moderately skewed","1ccdbc97":"print(train['Purchase'].describe())\nprint(train[train['Purchase'] == train['Purchase'].min()].shape[0])\nprint(train[train['Purchase'] == train['Purchase'].max()].shape[0])","b3ad3420":"train.isnull().sum()","56adf332":"test.isnull().sum()","75401cdd":"# Let's analyse the missing value\n# Only this predictors Product_Category_2 & Product_Category_3 has missing values this might be due to that products did not fall under these two categories\ntrain[train['Product_Category_2'].isnull()]['Product_ID'].value_counts()","b2c26d44":"# We analyse firt two top products\nprint(train[train['Product_ID']=='P00255842']['Product_Category_2'].value_counts(dropna=False))\nprint(train[train['Product_ID']=='P00278642']['Product_Category_2'].value_counts(dropna=False))","f5492480":"train[train['Product_Category_3'].isnull()]['Product_ID'].value_counts()","d4ef910a":"# We analyse firt two top products\nprint(train[train['Product_ID']=='P00265242']['Product_Category_3'].value_counts(dropna=False))\nprint(train[train['Product_ID']=='P00058042']['Product_Category_3'].value_counts(dropna=False))","fbe268aa":"# Our guess is correct that product doesn't fall under these categories, so it is safe to fill 0\ntrain['Product_Category_2'].fillna(0,inplace=True)\ntest['Product_Category_2'].fillna(0,inplace=True)\ntrain['Product_Category_3'].fillna(0,inplace=True)\ntest['Product_Category_3'].fillna(0,inplace=True)","1105bff0":"# we remove '+' character\ntrain['Stay_In_Current_City_Years'] = train['Stay_In_Current_City_Years'].replace(\"4+\",\"4\")\ntest['Stay_In_Current_City_Years'] = test['Stay_In_Current_City_Years'].replace(\"4+\",\"4\")\n\ntrain['Age'] = train['Age'].replace('55+','56-100')\ntest['Age'] = test['Age'].replace('55+','56-100')","253a2a60":"# Product ID has so many unique values that won't help us but there is a pattern on product formation. We will split first 4 \n# characters this might be some sellers name or for some identification they kept on it","2b4f4e73":"train['Product_Name'] = train['Product_ID'].str.slice(0,4)\ntest['Product_Name'] = test['Product_ID'].str.slice(0,4)","741223a7":"sns.countplot(train['Product_Name'])","7fb21e30":"train.groupby('Product_Name')['Purchase'].describe().sort_values('count',ascending=False)","18b0dac5":"# Items which are only fall under Product_Category_1 list\npd_cat_1_purchase = train[(train['Product_Category_2'] == 0) & (train['Product_Category_3']==0)]['Purchase']\nprint(\"Total no. of Sold Items in Product_Category_1 {}\".format(pd_cat_1_purchase.shape[0]))\nprint(\"Mean value {}\".format(pd_cat_1_purchase.mean()))\nprint(\"Median value {}\".format(pd_cat_1_purchase.median()))\n\n","3ce53db7":"# Items which are available in any two category\npd_cat_2_purchase = train[np.logical_xor(train['Product_Category_2'],train['Product_Category_3'])]['Purchase']\nprint(\"Total no. of Sold Items in Product_Category_1 & any one of the other two category {}\".format(pd_cat_2_purchase.shape[0]))\nprint(\"Mean value is {}\".format(pd_cat_2_purchase.mean()))\nprint(\"Median value is {}\".format(pd_cat_2_purchase.median()))","701f0873":"# Items which are available in all category\npd_cat_all_purchase = train[(train['Product_Category_2'] != 0) & (train['Product_Category_3']!=0)]['Purchase']\nprint(\"Total no. of Sold Items in all Category {}\".format(pd_cat_all_purchase.shape[0]))\nprint(\"Mean value is {}\".format(pd_cat_all_purchase.mean()))\nprint(\"Median value is {}\".format(pd_cat_all_purchase.median()))","bca906bc":"train['Category_Weight'] = 0\ntrain.loc[pd_cat_1_purchase.index,'Category_Weight'] = 1\ntrain.loc[pd_cat_2_purchase.index,'Category_Weight'] = 2\ntrain.loc[pd_cat_all_purchase.index,'Category_Weight'] = 3\n","417ef440":"# Each user has purchased atleast 6 items.\n# Based on the count  we'll create a new variable called Frequent_Buyers which holds 1 for Users who purchased more than 100 items\n# and 0 for less than 100 items","22ddfabd":"train['Frequent_Buyers'] = train.groupby('User_ID')['User_ID'].transform(lambda x : 1 if x.count() > 100 else 0)\ntest['Frequent_Buyers'] = test.groupby('User_ID')['User_ID'].transform(lambda x : 1 if x.count() > 100 else 0)","05166f8f":"train.drop(['Product_ID','User_ID'],inplace=True,axis=1)\ntest.drop(['Product_ID','User_ID'],inplace=True,axis=1)","1533cfa4":"train['Age'].value_counts()","b7b8ae8f":"sns.barplot(train['Age'],train['Age'].value_counts().values)","c9ae33d9":"# We'll create a new feature for Student\ntrain['IsStudent'] = 1 * (train['Age']=='0-17')\ntest['IsStudent'] = 1 * (test['Age']=='0-17')","ffef1029":"# Based on our income we spend more, so we'll order occupation by mean value of the purchase and we use the same order for test data also.\norder_occupation_by_purchase = train.groupby('Occupation')['Purchase'].describe().sort_values('mean',ascending=False)['mean'].index","694a98b7":"train['Occupation']","7d56f7a6":"map_occupation = {k: v for v, k in enumerate(order_occupation_by_purchase)}\nmap_occupation","ef8206e4":"train['Occupation'] = train['Occupation'].apply(lambda x: map_occupation[x])\ntest['Occupation'] = test['Occupation'].apply(lambda x: map_occupation[x])","b60112c6":"corrIndex = train.corr().nlargest(10,'Purchase')['Purchase'].index\ncorr = train[corrIndex].corr()","0355473f":"plt.figure(figsize=(16,8))\nax = sns.heatmap(corr,annot=True,cmap=\"YlGnBu\")\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)\nplt.show()","40722434":"# There is no satisifactory correlation feature so we will avoid using Linear model.","a6ff97f6":"f,ax = plt.subplots(1,2,figsize=(10,6))\nsns.countplot(train['Gender'],ax=ax[0])\nsns.barplot('Gender','Purchase',data=train,ax=ax[1])","92d9f86e":"f,ax = plt.subplots(1,2,figsize=(10,6))\nsns.countplot(train['City_Category'],ax=ax[0])\nsns.barplot('City_Category','Purchase',data=train,ax=ax[1])\n","181e0332":"# Customer from city B has purchased more items.\n# Customer from city C has spent higher Amount Eventhough B has purchased more items.","8740a03b":"\nMore data beats clever algorithms, but better data beats more data\n-Peter Norvig","1a10d6a4":"#### Extraordinary Data Analysis","d27ca960":"### Problem Description : \n   A retail company \u201cABC Private Limited\u201d wants to understand the customer purchase behaviour(specifically, purchase amount) \nagainst various products of different categories. They have shared purchase summary of various customers for selected \nhigh volume products from last month.\n\n   The data set also contains customer demographics (age, gender, marital status, city_type, stay_in_current_city), \nproduct details (product_id and product category) and Total purchase_amount from last month.\n\n   Now, they want to build a model to predict the purchase amount of customer against various products which will help \nthem to create personalized offer for customers against different products.","4de4703a":"Men was the most shown interest on black friday sales. On plot 2, Eventhough women are less in count but they spent almost equal money spent by men","694799d5":"#### Goal\n    Our Goal is to predict the purchase amount a client is expected to spend on this day.","20c6c509":"* teenagers or student shows more interest than other ages\n* 72% of \"0-17\" doing the same occupation(probably they are student)","ac1f5c89":"### Data Cleaning","2701a54d":"#### Feature Creation","0d5408cc":"Observations : \n* Minimum price of the Item is 12 and max to 23961.\n* Median value (8047) is lower than mean value (9263) \n\n","97272f23":"##### We'll check purchase of the items based on the available category. My assumption is that if an item available in all the category, there are very high chances that the item is more visible to the user. Let's analys this fact","dfbd8fe6":"you can see that in all category split where the median is greater than mean. That means most of the richer people purchased the product which comes falls all category. So We'll create a new feature for category split and assign a weight to that. ","6b5c1c31":"#### Observations\n- Occupation , Product_Category_1 , Product_Category_2, Product_Category_3 values are masked\n- No information about stores\n- Few information related to products which are product id and the product that falls under different product category\n- We have some information related to the Customer such as Age,Gender,Occupation and Maritial_status\n","ea2b9d42":"#### Assumptions\n- We make some assumptions before start,We'll analyse the given features that influence amount spend by customer\n- <b>Occupation<\/b> - People with higher income spend more \n- <b>Marital_Status<\/b> - People who are single spend more\n- <b>City_Category<\/b> - People from urban city or top tier city spend more because of their higher income level\n- <b>Age<\/b> - People who are below 30 years spend more on gadgets and other electronics stuff","3c2716f4":"#### Feature Transformation"}}