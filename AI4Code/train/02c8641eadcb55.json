{"cell_type":{"cda71845":"code","d5b33342":"code","d2569e77":"code","7cb00a10":"code","e1047519":"code","4cf01cf8":"code","64841eec":"code","0c69e7a3":"code","2b8d15ea":"code","0c70b19c":"code","9cc215ae":"code","3fd67efc":"code","add6c011":"code","58785cbc":"code","5ef7fb2a":"code","6f79ee5e":"code","d3f0f00e":"markdown","157da1b2":"markdown"},"source":{"cda71845":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\nimport torch\nfrom torch import nn, optim\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms\nfrom torchvision.utils import save_image\n\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom fastai.vision import *\nfrom fastai.vision.gan import *","d5b33342":"path ='..\/input\/all-dogs\/'","d2569e77":"trfm = get_transforms(do_flip=False, flip_vert=False, max_rotate=8.0, \n                      max_lighting=0.2, max_warp=0.2, p_affine=0.75, p_lighting=0.75,\n                      xtra_tfms=[contrast(scale=(1, 2), p=0.75),rand_zoom(scale =(1.0,1.2)),crop_pad(size=64, row_pct=(0,1), col_pct=(0,1))]\n                )\ntrfm1 = get_transforms(do_flip=False, flip_vert=False,xtra_tfms=[crop_pad(size=64, row_pct=(0,1), col_pct=(0,1))])","7cb00a10":"def get_data(bs, size):\n    return (GANItemList.from_folder(path, noise_sz=100)\n               .split_none()\n               .label_from_func(noop)\n#               .transform(tfms=[[crop_pad(size=size, row_pct=(0,1), col_pct=(0,1))], []], size=size, tfm_y=True)\n               .transform(trfm,size=size,tfm_y=True)\n               .databunch(bs=bs)\n               .normalize(stats = [torch.tensor([0.5,0.5,0.5]), torch.tensor([0.5,0.5,0.5])], do_x=False, do_y=True))\n\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","e1047519":"data = get_data(64, 64)","4cf01cf8":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","64841eec":"generator = basic_generator(in_size=64, n_channels=3, n_extra_layers=1).to(device)\ncritic    = basic_critic   (in_size=64, n_channels=3, n_extra_layers=1).to(device)\nlearn = GANLearner.wgan(data, generator, critic, switch_eval=False,\n                        opt_func = partial(optim.Adam, betas = (0.,0.99)), wd=0.)","0c69e7a3":"learn.fit(100,5e-4)","2b8d15ea":"learn.gan_trainer.switch(gen_mode=True)\nlearn.show_results(ds_type=DatasetType.Train, rows=16, figsize=(16,16))","0c70b19c":"preds,_ = learn.get_preds(ds_type=DatasetType.Train)","9cc215ae":"img1=preds.numpy()[1]","3fd67efc":"img1.shape","add6c011":"%matplotlib inline ","58785cbc":"img1tran =np.transpose(img1, (2, 1, 0))","5ef7fb2a":"if not os.path.exists('..\/output_images'):\n    os.mkdir('..\/output_images')\nim_batch_size = 50\nn_images=10000\nfor i_batch in range(0, n_images, im_batch_size):\n    gen_z = torch.randn(im_batch_size, 100, 1, 1, device=device)\n    gen_images = generator(gen_z)\n    images = gen_images.to(\"cpu\").clone().detach()\n    images = images.numpy().transpose(0, 2, 3, 1)\n    for i_image in range(gen_images.size(0)):\n        save_image(gen_images[i_image, :, :, :], os.path.join('..\/output_images', f'image_{i_batch+i_image:05d}.png'))\n\n\nimport shutil\nshutil.make_archive('images', 'zip', '..\/output_images')","6f79ee5e":"images.shape","d3f0f00e":"# Generator and Discriminator","157da1b2":"## Parameters of GAN"}}