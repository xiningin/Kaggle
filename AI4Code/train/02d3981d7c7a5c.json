{"cell_type":{"90015849":"code","f627e026":"code","5e7f6afa":"code","8b52ee56":"code","95353c5f":"code","39f0fc39":"code","b31be361":"code","ecc6573c":"code","b5b6c505":"code","17577054":"code","7fa562af":"code","fd3c72de":"code","d26bb08d":"code","97e066ac":"code","70c2103d":"code","06451e0d":"code","d48ee03a":"code","99e759dd":"code","412878ed":"code","e0cf0e91":"code","3c1943ed":"code","2140e31f":"code","2c64af4b":"code","282102dd":"code","8c4d596a":"code","c05bfd98":"code","415ca184":"code","c8b473a4":"code","ba626859":"code","dca13e4b":"code","827f4d62":"markdown","2deb03ac":"markdown","c3603092":"markdown","d0f840ee":"markdown","000dd8ec":"markdown","90c801d2":"markdown","4fd12373":"markdown","0ccd83bd":"markdown","3238719f":"markdown"},"source":{"90015849":"#We start with importing the required packages for data processing and visualising\nimport numpy as np   ## linear algebra\nimport random         \nimport pandas as pd    # data processing, CSV file I\/O \nfrom pandas.tools import plotting   #visualization\nimport seaborn as sns                #visualization\nimport matplotlib.pyplot as plt    #visualization\n%matplotlib inline\n\nimport plotly.offline as py         #visualization\nfrom plotly.offline import init_notebook_mode, iplot\nimport plotly.graph_objs as go\nfrom plotly import tools\ninit_notebook_mode(connected=True)  \nimport plotly.figure_factory as ff\n#For importing the classification models\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom lightgbm import LGBMClassifier\nfrom sklearn.metrics import  accuracy_score\n\nimport xgboost as xgb\nimport lightgbm as  lgb\nfrom xgboost.sklearn import XGBClassifier\nfrom catboost import CatBoostClassifier\n\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\n# auxiliary function\nfrom sklearn.preprocessing import LabelEncoder\ndef random_colors(number_of_colors):\n    color = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)])\n                 for i in range(number_of_colors)]\n    return color\n\nimport warnings\nwarnings.filterwarnings('ignore')","f627e026":"#Loading the dataset\ndf = pd.read_csv('..\/input\/Iris.csv')\ndf.head()\n","5e7f6afa":"table = ff.create_table(df.head())\npy.iplot(table,filename='jupyter-table1')","8b52ee56":"py.iplot(ff.create_table(df.describe()),filename='jupyter-table1')","95353c5f":"df.info()","39f0fc39":"#Types of  Species\nSpecies = df['Species'].unique()\nSpecies","b31be361":"#Andrew Curves\nfrom matplotlib import cm\nplt.subplots(figsize = (10,8))\ncmap = cm.get_cmap('rainbow')\nplotting.andrews_curves(df.drop(\"Id\", axis=1), \"Species\",colormap=cmap)","ecc6573c":"#STRIP PLOT\nfig=plt.gcf()\nfig.set_size_inches(10,7)\nfig=sns.stripplot(x='Species',y='SepalLengthCm',data=df,jitter=True,edgecolor='gray',size=8,palette='summer',orient='v')","b5b6c505":"#Statistical Summary of the data\ndf.describe().plot(kind = \"area\",fontsize=27, figsize = (20,8), table = True,colormap=\"rainbow\")\nplt.xlabel('Statistics',)\nplt.ylabel('Value')\nplt.title(\"General Statistics of Iris Dataset\")","17577054":"# Histograms\ndf.hist(edgecolor='red', linewidth=1.4)","7fa562af":"#pie plot\ndf['Species'].value_counts().plot.pie(explode=[0.1,0.1,0.1],autopct='%1.1f%%',shadow=True,figsize=(10,8))\nplt.show()","fd3c72de":"#SCATTERPPLOT(or pair plot)\nsns.pairplot(df,hue='Species')","d26bb08d":"x = df[['SepalLengthCm','SepalWidthCm','PetalLengthCm','PetalWidthCm']]\ny = df['Species']","97e066ac":"encoder = LabelEncoder()\ny = encoder.fit_transform(y)\ny","70c2103d":"#Splitting the dataset into training and testing dataset\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.3, random_state = 101)","06451e0d":"#LOGISTIC REGRESSION\nmodel = LogisticRegression()\nmodel.fit(x_train,y_train)\npredict =model.predict(x_test)\nprint('Accuracy score of Logistic Regression - ',accuracy_score(predict,y_test))","d48ee03a":"#NAIVE BAYES\nmodel = GaussianNB()\nmodel.fit(x_train,y_train)\npredict =model.predict(x_test)\nprint('Accuracy score of Naive bayes - ',accuracy_score(predict,y_test))","99e759dd":"#SUPPORT VECTOR MACHINE\nsvm_model = SVC(kernel='linear')\nsvm_model.fit(x_train,y_train)\nsvc_predict = svm_model.predict(x_test)\nprint('Accuracy score of SVM - ',accuracy_score(svc_predict,y_test))","412878ed":"#DECISION TREE\ndt_model = DecisionTreeClassifier(max_leaf_nodes=3)\ndt_model.fit(x_train,y_train)\ndt_predict = dt_model.predict(x_test)\nprint('Accuracy score of Decision Tree - ',accuracy_score(dt_predict,y_test))","e0cf0e91":"#RANDOM FOREST\nrfc_model = RandomForestClassifier(max_depth=3)\nrfc_model.fit(x_train,y_train)\nrfc_predict = rfc_model.predict(x_test)\nprint('Accuracy score of Random Forest - ',accuracy_score(rfc_predict,y_test))","3c1943ed":"#KNN \nknn_model = KNeighborsClassifier(n_neighbors=3)\nknn_model.fit(x_train,y_train)\nknn_predict = knn_model.predict(x_test)\nprint('Accuracy score of knn - ',accuracy_score(knn_predict,y_test))","2140e31f":"#XGBoost\nxg_model = xgb.XGBClassifier()\nxg_model = xg_model.fit(x_train,y_train)\nxg_model.score(x_test, y_test)","2c64af4b":"#TRAINING THE MODEL\n#Importing packages for Deep Learning\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense","282102dd":"from sklearn.preprocessing import StandardScaler, LabelBinarizer\nX = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\ny = df['Species']\n\nX = StandardScaler().fit_transform(X)\ny = LabelBinarizer().fit_transform(y)","8c4d596a":"#Splitting the dataset into training and testing set in the ration of 7:3\nfrom sklearn.preprocessing import StandardScaler, LabelBinarizer\nX = df[['SepalLengthCm', 'SepalWidthCm', 'PetalLengthCm', 'PetalWidthCm']]\ny = df['Species']\n\nX = StandardScaler().fit_transform(X)\ny = LabelBinarizer().fit_transform(y)\n","c05bfd98":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 101)","415ca184":"#SHALLOW Deep Learning\nshallow_model = Sequential()\nshallow_model.add(Dense( 4, input_dim=4, activation = 'relu'))\nshallow_model.add(Dense( units = 10, activation= 'relu'))\nshallow_model.add(Dense( units = 3, activation= 'softmax'))\nshallow_model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])","c8b473a4":"shallow_history = shallow_model.fit(x_train, y_train, epochs = 150, validation_data = (x_test, y_test))","ba626859":"plt.plot(shallow_history.history['acc'])\nplt.plot(shallow_history.history['val_acc'])\nplt.title(\"Accuracy\")\nplt.legend(['train', 'test'])\nplt.show()","dca13e4b":"plt.plot(shallow_history.history['loss'])\nplt.plot(shallow_history.history['val_loss'])\nplt.plot('Loss')\nplt.legend(['Train','Test'])\nplt.show()","827f4d62":"We will using the Classification Models as:\n\n1.Logistic regression\n2.Decision tree\n3.KNN\n4.SVM\n5.Naive Bayes Classification\n6.Random forest\n7.XGBoost\n8.LightGBM","2deb03ac":"Lets look at the output we want to predict.\nWe want to predict the given sepal and petal dimensions follows to which type of species.\nWe will convert those species names to a categorical values using label encoding.","c3603092":"Hello everyone.\nThis kernel notebook has Iris Species Data Visualisation,Data Analysis using all Classification models and Deep Learning Models in Python.","d0f840ee":"Visualization :","000dd8ec":"Thank you for reading my notebook!  Hope it will be useful for the beginner.Please upvote it ,if you found it useful.","90c801d2":"Description:\n\nThe Iris dataset was used in R.A. Fisher's classic 1936 paper, The Use of Multiple Measurements in Taxonomic Problems, and can also be found on the UCI Machine Learning Repository.\n\nIt includes three iris species with 50 samples each as well as some properties about each flower. One flower species is linearly separable from the other two, but the other two are not linearly separable from each other.\n\nThe columns in this dataset are:\n\nId\nSepalLengthCm\nSepalWidthCm\nPetalLengthCm\nPetalWidthCm\nSpecies","4fd12373":"DEEP LEARNING:\n","0ccd83bd":"Objective:- Classify a new flower as belonging to one of the 3 classes given in the dataset.\n\nAbout the notebook:\nIn this notebook we will look into iris dataset , we will analyse the dataset with plotly library which is very interactive library in python then later we will apply different macine learning algorithms and see the best accuracy.\n\nHere we start.\n","3238719f":"We have seen that  Iris-setosa ,Iris-versicolor and  Iris-virginica are converted to 0, 1, 2 respectively\n\nNow ,we are splitting the data set into training data and testing data which is 7:3 ratio"}}