{"cell_type":{"d2e4a6aa":"code","2826467a":"code","61a9ef5e":"code","439de0b9":"code","79b2bb08":"code","3cc2533f":"code","acc0c362":"code","2839ed5f":"code","1ab76dfb":"code","aa199fcb":"code","9588fdd9":"code","410d3e16":"code","4261f8a3":"markdown","c9a717fa":"markdown","1f5a181a":"markdown","eec7ba20":"markdown","dd17cb70":"markdown"},"source":{"d2e4a6aa":"from __future__ import print_function\n\nimport torch\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\n\nimport os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline","2826467a":"file_path = '..\/input\/digit-recognizer'\ntrain_df = pd.read_csv(os.path.join(file_path,'train.csv'))\ntest_df = pd.read_csv(os.path.join(file_path,'test.csv'))\n\nprint('Number of training samples: {0}'.format(len(train_df)))\nprint('Number of test samples: {0}'.format(len(test_df)))\nprint('Training sample columns: {0}'.format(train_df.columns.values))\nprint('Test sample columns: {0}'.format(test_df.columns.values))","61a9ef5e":"print('Number of classes: {0}'.format(len(set(train_df['label']))))\n\nplt.rcParams['figure.figsize'] = (8, 5)\nplt.bar(train_df['label'].value_counts().index, train_df['label'].value_counts())\nplt.xticks(np.arange(len(set(train_df['label']))))\nplt.xlabel('Class', fontsize=16)\nplt.ylabel('Count', fontsize=16)\nplt.grid('on', axis='y')","439de0b9":"class mnist(Dataset):\n    def __init__(self, file_path, is_train=True, transform=transforms.Compose([transforms.ToPILImage(), transforms.ToTensor(), transforms.Normalize(mean=(0.5,), std=(0.5,))])):\n        \n        self.transform = transform\n\n        if is_train:\n            train_path = os.path.join(file_path, 'train.csv')\n            train = pd.read_csv(train_path)\n            self.X = train.iloc[:,1:].values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = torch.from_numpy(train.iloc[:,0].values)\n        else:\n            test_path = os.path.join(file_path, 'test.csv')\n            test = pd.read_csv(test_path)\n            self.X = test.values.reshape((-1,28,28)).astype(np.uint8)[:,:,:,None]\n            self.y = None\n    \n    def __len__(self):\n        return len(self.X)\n        \n    def __getitem__(self, index):\n        if self.y is not None:\n            return self.transform(self.X[index]), self.y[index]\n        else:\n            return self.transform(self.X[index])","79b2bb08":"import torch.nn.functional as F\nimport torch.nn as nn\n\nclass cnn(nn.Module):\n    def __init__(self):\n        super(cnn, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n        # Spatial transformer localization-network\n        self.localization = nn.Sequential(\n            nn.Conv2d(1, 8, kernel_size=7),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True),\n            nn.Conv2d(8, 10, kernel_size=5),\n            nn.MaxPool2d(2, stride=2),\n            nn.ReLU(True)\n        )\n\n        # Regressor for the 3 * 2 affine matrix\n        self.fc_loc = nn.Sequential(\n            nn.Linear(10 * 3 * 3, 32),\n            nn.ReLU(True),\n            nn.Linear(32, 3 * 2)\n        )\n\n        # Initialize the weights\/bias with identity transformation\n        self.fc_loc[2].weight.data.zero_()\n        self.fc_loc[2].bias.data.copy_(torch.tensor([1, 0, 0, 0, 1, 0], dtype=torch.float))\n\n    # Spatial transformer network forward function\n    def stn(self, x):\n        xs = self.localization(x)\n        xs = xs.view(-1, 10 * 3 * 3)\n        theta = self.fc_loc(xs)\n        theta = theta.view(-1, 2, 3)\n\n        grid = F.affine_grid(theta, x.size())\n        x = F.grid_sample(x, grid)\n\n        return x\n\n    def forward(self, x):\n        # transform the input\n        x = self.stn(x)\n\n        # Perform the usual forward pass\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)","3cc2533f":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nbatch_size = 64\n\ntrain_dataset = mnist(file_path, is_train=True)\ntest_dataset = mnist(file_path,is_train=False)\n\ntrain_loader = DataLoader(dataset=train_dataset, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(dataset=test_dataset, batch_size=batch_size, shuffle=False)","acc0c362":"import torch.optim as optim\n\nmodel = cnn().to(device)\noptimizer = optim.Adam(model.parameters(), lr=0.001)\ncriterion = nn.CrossEntropyLoss()\ncriterion = criterion.to(device)\n\ndef train(epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n\n        optimizer.zero_grad()\n        output = model(data)\n        # loss = F.nll_loss(output, target)\n        loss = criterion(output, target)\n\n        loss.backward()\n        optimizer.step()\n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * (batch_idx + 1) \/ len(train_loader), loss.item()))","2839ed5f":"def evaluate():\n    with torch.no_grad():\n        model.eval()\n        test_loss = 0\n        correct = 0\n        for data, target in train_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n\n            # sum up batch loss\n            test_loss += F.nll_loss(output, target, reduction='sum').item()\n            # get the index of the max log-probability\n            pred = output.max(1, keepdim=True)[1]\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n        test_loss \/= len(train_loader.dataset)\n        print('\\nTrain set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.4f}%)\\n'\n              .format(test_loss, correct, len(train_loader.dataset),\n                      100. * correct \/ len(train_loader.dataset)))","1ab76dfb":"for epoch in range(1, 10):\n    train(epoch)\n    evaluate()","aa199fcb":"def prediciton():\n    with torch.no_grad():\n        model.eval()\n        test_pred = torch.LongTensor()\n        for i, data in enumerate(test_loader):\n            data = data.to(device)\n            output = model(data)\n\n            pred = output.cpu().data.max(1, keepdim=True)[1]\n            test_pred = torch.cat((test_pred, pred), dim=0)\n    return test_pred","9588fdd9":"test_pred = prediciton()\nout_df = pd.DataFrame(np.c_[np.arange(1, len(test_dataset)+1)[:,None], test_pred.numpy()],columns=['ImageId', 'Label'])\nout_df.head()","410d3e16":"out_df.to_csv('submission.csv', index=False)","4261f8a3":"## Training and Evaluation\n\nLoading the data","c9a717fa":"check data details","1f5a181a":"## STN Spatial Transformer Network\n\nI augmented CNN using a visual attention mechanism called spatial transformer networks. You can read more about the spatial transformer networks in the [DeepMind paper](https:\/\/arxiv.org\/abs\/1506.02025)","eec7ba20":"# Spatial Transformer Network with Pytorch\n\n***\n\nThis is the implementation of pytorch that I learned from official tutorual, more details [here](https:\/\/pytorch.org\/tutorials\/intermediate\/spatial_transformer_tutorial.html)\n\nThanks for *Ryan Chang*'s [previous work](https:\/\/www.kaggle.com\/juiyangchang\/cnn-with-pytorch-0-995-accuracy) for guidance.\n\n**requirement:**\n\n* python == 3.6\n* pytorch == 1.3.1\n* numpy == 1.17.4\n* pandas == 0.25.3\n* matplotlib == 3.1.1\n\nimport necessary package","dd17cb70":"### Create mnist class\n\noverride torch.utils.data.Dataset"}}