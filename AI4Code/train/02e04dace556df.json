{"cell_type":{"ac1f9550":"code","631c5894":"code","950033ef":"code","d385f925":"code","464139b9":"code","41ec249e":"code","6e0cbb5a":"code","742ce470":"code","ccadc31c":"code","6b0528c9":"code","16ec695e":"code","25ef5938":"code","4356a868":"code","068befeb":"code","9f4dd954":"code","a75261f2":"code","eb6c67a3":"code","13871061":"code","9cfc32f3":"code","3fea35df":"markdown","810ec7f8":"markdown","aa6a8235":"markdown","831b5b70":"markdown","b200f160":"markdown","a10233d2":"markdown","832a4b9f":"markdown","adec0870":"markdown","9821c5b4":"markdown"},"source":{"ac1f9550":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","631c5894":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error\nimport category_encoders as ce","950033ef":"data = pd.read_csv('\/kaggle\/input\/real-time-advertisers-auction\/Dataset.csv')","d385f925":"data['date'] = pd.to_datetime(data['date'])","464139b9":"data.head()","41ec249e":"data.describe()","6e0cbb5a":"def weird_division(n, d):\n    return n \/ d if d else 0\n\ndata['CPM'] = data.apply(lambda x: weird_division(((x['total_revenue']*100)),x['measurable_impressions'])*1000 , axis=1)","742ce470":"data_train = data[data.date < pd.to_datetime(\"2019-06-22\")]\ndata_test = data[data.date >= pd.to_datetime(\"2019-06-22\")]\n\ndata_train = data_train[data_train['CPM'] >= 0]\ndata_test = data_test[data_test['CPM'] >= 0]","ccadc31c":"train_95_percentile = np.percentile(data_train['CPM'], 95)\ntest_95_percentile = np.percentile(data_test['CPM'], 95)\nprint(f'95 percentile train: {train_95_percentile:0.2f} test: {test_95_percentile:0.2f}')","6b0528c9":"data_train = data_train[data_train['CPM'] <= train_95_percentile]\ndata_test= data_test[data_test['CPM'] <= test_95_percentile]","16ec695e":"X_train = data_train.drop(['CPM', 'total_revenue', 'measurable_impressions', 'viewable_impressions', 'revenue_share_percent', 'total_impressions'], axis=1).copy()\ny_train = data_train['CPM'].copy()\n\nX_test = data_test.drop(['CPM', 'total_revenue', 'measurable_impressions', 'viewable_impressions', 'revenue_share_percent', 'total_impressions'], axis=1).copy()\ny_test = data_test['CPM'].copy()","25ef5938":"for col in X_train.columns:\n    X_train[col] = X_train[col].astype(str)\n    X_test[col] = X_test[col].astype(str)","4356a868":"encoder = ce.cat_boost.CatBoostEncoder()\nencoder.fit(X_train, y_train)","068befeb":"X_train_transformed = encoder.transform(X_train)\nX_test_transformed = encoder.transform(X_test)","9f4dd954":"lr = LinearRegression()\nlr.fit(X_train_transformed, y_train)","a75261f2":"y_pred = lr.predict(X_test_transformed)\nprint(f'Linear regressor MSE on test: {mean_squared_error(y_pred, y_test):0.2f}')","eb6c67a3":"from catboost import CatBoostRegressor","13871061":"model = CatBoostRegressor()\nmodel.fit(X_train_transformed, y_train)","9cfc32f3":"y_pred = model.predict(X_test_transformed)\nprint(f'CatBoostRegressor MSE on test: {mean_squared_error(y_pred, y_test):0.2f}')","3fea35df":"### MSE is lower than 4850 (threshold) :-)","810ec7f8":"## 5) Use label encoding from CatBoost","aa6a8235":"## 4) Remove outliers separately from train and test data","831b5b70":"## 6) Linear Regressor from sklearn (without tuning)","b200f160":"## 1) Load data","a10233d2":"## 7) Let's go further and use CatBoostRegressor","832a4b9f":"## 2) Let's calculate CPM (https:\/\/www.kaggle.com\/akshaypaliwal709)","adec0870":"## 3) Split data to train and test. Also remove all negative CPM values","9821c5b4":"### MSE is lower than 4850 (threshold) :-)"}}