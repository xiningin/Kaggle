{"cell_type":{"7c7b94b9":"code","c0a300a8":"code","4d711e4c":"code","64a5040c":"code","aaeb697d":"code","6cd5bd11":"code","a9debbdc":"code","dbd332f7":"code","17847e6c":"code","f6c99b40":"code","06621663":"code","9848ed29":"code","6c473ceb":"code","890fa663":"code","dcc77837":"code","ac680f0e":"code","95a80567":"code","070f60eb":"code","d2285d2f":"code","13f2b08a":"code","9740266a":"code","2f248468":"code","8e1942bf":"code","3a39ec0b":"code","ef9fe5fb":"code","e642e664":"code","86166e72":"code","5e1199a5":"code","a07e7df4":"code","5c0f4907":"code","07575481":"markdown","9ccfa97c":"markdown","c20290a8":"markdown","cfede2e5":"markdown","a5bc2806":"markdown"},"source":{"7c7b94b9":"! pip install skorch==0.8.0\n! pip install lofo-importance","c0a300a8":"import pandas as pd\nfrom sklearn.model_selection import KFold\nfrom lofo import LOFOImportance, Dataset, plot_importance, FLOFOImportance\nfrom sklearn.model_selection import StratifiedKFold, StratifiedShuffleSplit, train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMRegressor\nfrom sklearn.metrics import log_loss\nimport numpy as np\n%matplotlib inline","4d711e4c":"train = pd.read_csv('..\/input\/lish-moa\/test_features.csv')\ntrain = train[train.cp_type!='ctl_vehicle']\ntrain_labels = pd.read_csv('..\/input\/lish-moa\/train_targets_scored.csv')","64a5040c":"gene_cols = [col for col in train.columns if 'g-' in col]\nlabels = train_labels.columns.difference(['sig_id']).tolist()\ntrain_df = train.drop(['sig_id'], axis=1)[gene_cols+['cp_time']]","aaeb697d":"label_df = train_labels[labels]","6cd5bd11":"df = pd.concat([train_df,label_df],axis=1).dropna().reset_index(drop=True)","a9debbdc":"l = 79\nlabel_df.iloc[:,l].value_counts()","dbd332f7":"sss = StratifiedShuffleSplit(n_splits=2,test_size=0.28, random_state=42)\nsp1,sp2 = sss.split(df[[labels[l]]+['cp_time']].values,df[[labels[l]]+['cp_time']].values)","17847e6c":"train_df = df.iloc[list(sp1[0]),:].reset_index(drop=True)\nval_df = df.iloc[list(sp1[1]),:].reset_index(drop=True)","f6c99b40":"rf = RandomForestClassifier(n_jobs=-1, max_depth=6)\nrf.fit(train_df[gene_cols],train_df[labels[l]])","06621663":"lofo_imp = FLOFOImportance(trained_model=rf, validation_df=val_df,features=gene_cols,target=labels[l],scoring='neg_log_loss',n_jobs=-1)","9848ed29":"imps = lofo_imp.get_importance()","6c473ceb":"plot_importance(imps[:40])","890fa663":"plot_importance(imps[-40:])","dcc77837":"label = label_df.columns[l]","ac680f0e":"X,y = df[gene_cols], df[label]","95a80567":"skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1881).split(y,y)\nscores = []\n\nfor i, (tr_ix, vl_ix) in enumerate(skf):\n    print(f'================Fold-{i+1}===================')\n    \n    train_X, train_y = X.iloc[tr_ix], y.iloc[tr_ix]\n    valid_X, valid_y = X.iloc[vl_ix], y.iloc[vl_ix]\n    \n    model = RandomForestClassifier(max_depth=6, n_jobs=-1, n_estimators=300)\n    \n    model.fit(train_X, train_y)\n    \n    preds = model.predict_proba(valid_X)[:,1]\n    \n    score = log_loss(valid_y, preds)\n    \n    scores.append(score)\n    \nprint(np.mean(scores))","070f60eb":"elim = 40\nreduced_feats = imps.feature.values[:elim].tolist()","d2285d2f":"X,y = df[reduced_feats], df[label]","13f2b08a":"skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1881).split(y,y)\nscores = []\n\nfor i, (tr_ix, vl_ix) in enumerate(skf):\n    print(f'================Fold-{i+1}===================')\n    \n    train_X, train_y = X.iloc[tr_ix], y.iloc[tr_ix]\n    valid_X, valid_y = X.iloc[vl_ix], y.iloc[vl_ix]\n    \n    model = RandomForestClassifier(max_depth=6, n_jobs=-1, n_estimators=300)\n    \n    model.fit(train_X, train_y)\n    \n    preds = model.predict_proba(valid_X)[:,1]\n    \n    score = log_loss(valid_y, preds)\n    \n    scores.append(score)\n    \nprint(np.mean(scores))","9740266a":"import torch\nimport torch.nn as nn\nfrom torch.utils.data import DataLoader, Dataset\n\nimport skorch\nfrom skorch import NeuralNetBinaryClassifier","2f248468":"class Net(nn.Module):\n    def __init__(self, input_size):\n        super(Net, self).__init__()\n        self.input_size = input_size\n        \n        self.input = nn.Linear(self.input_size, 512)\n        self.relu = nn.ReLU()\n        self.dropout = nn.Dropout(0.4)\n        self.hidden1 = nn.Linear(512,256)\n        self.hidden2 = nn.Linear(256,128)\n        self.out = nn.Linear(128,1)\n        self.bn1 = nn.BatchNorm1d(512)\n        self.bn2 = nn.BatchNorm1d(256)\n        self.bn3 = nn.BatchNorm1d(128)\n        self.sig = nn.Sigmoid()\n        \n    def forward(self, X):\n        \n        x = self.input(X)\n        x = self.relu(x)\n        x = self.bn1(x)\n        x = self.dropout(x)\n        \n        x = self.hidden1(x)\n        x = self.relu(x)\n        x = self.bn2(x)\n        x = self.dropout(x)\n        \n        x = self.hidden2(x)\n        x = self.relu(x)\n        x = self.bn3(x)\n        x = self.dropout(x)\n        \n        x = self.out(x)\n        out = self.sig(x)\n        \n        return out\n        \n        ","8e1942bf":"X,y = df[gene_cols], df[label]","3a39ec0b":"skorch.__version__","ef9fe5fb":"skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1881)\nmodel = NeuralNetBinaryClassifier(Net(X.shape[1]),\n                                      optimizer=torch.optim.Adam,\n                                      train_split=skorch.dataset.CVSplit(skf),\n                                      max_epochs=10,\n                                      criterion=torch.nn.modules.loss.BCELoss)","e642e664":"model.fit(torch.Tensor(X.values),torch.Tensor(y.values))","86166e72":"elim = 40\nreduced_feats = imps.feature.values[:elim].tolist()","5e1199a5":"X,y = df[reduced_feats], df[label]","a07e7df4":"skf = StratifiedKFold(n_splits=4, shuffle=True, random_state=1881)\nmodel = NeuralNetBinaryClassifier(Net(X.shape[1]),\n                                      optimizer=torch.optim.Adam,\n                                      train_split=skorch.dataset.CVSplit(skf),\n                                      max_epochs=10,\n                                      criterion=torch.nn.modules.loss.BCELoss)","5c0f4907":"model.fit(torch.Tensor(X.values),torch.Tensor(y.values))","07575481":"### Experiments with Important Features","9ccfa97c":"#### Full Set","c20290a8":"#### Reduce Features","cfede2e5":"### NN","a5bc2806":"In my last [notebook](https:\/\/www.kaggle.com\/afajohn\/h2o-individual-models-vs-positive-counts) I stated labels with higher number of positive labels contributed negatively to the overall log loss when a model is trained for each label. \n\nIn this notebook I selected one the poor performing labels to see whether label based feature selection on gene columns will improve the results. \n\nThanks to [@aerdem4](https:\/\/www.kaggle.com\/aerdem4) for LOFO Importance library. \n\nBuilding 206 models is a long way to approach to problem, each model with their own search space with hyperparameters and selected features. However for some of the labels single multilabel model predcitions can be \"boosted\" by zooming into some of the labels with single models."}}