{"cell_type":{"6073dbc2":"code","ad72842c":"code","5dd3628d":"code","a985f38a":"code","55906d05":"code","05219b96":"code","c0866709":"code","088a3fb2":"code","be437f41":"code","b0d77d0e":"code","df14074e":"code","ed432ddf":"code","1a46ac08":"code","069fd399":"code","f4c54e69":"code","ebd3e988":"code","d972e058":"code","f3dcd101":"code","f5b3e517":"code","22f1e3c1":"code","8ec6cf2f":"code","15c0c653":"markdown","3c435d9e":"markdown","5c5a8416":"markdown","3bf5aa11":"markdown","cd9d2554":"markdown","32e4c8fa":"markdown","d4d587c3":"markdown","11cbaf45":"markdown","568f36e0":"markdown","752e323b":"markdown","e9c99c03":"markdown","70b577d8":"markdown","2e470bc7":"markdown","751e88bb":"markdown","a092df15":"markdown","47468130":"markdown","19f1b2b1":"markdown","b69e1b75":"markdown"},"source":{"6073dbc2":"import pandas as pd\nimport numpy as np\nfrom datetime import datetime\nimport matplotlib.pyplot as plt","ad72842c":"df_train = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/train.csv')\ndf_train.head()","5dd3628d":"df_asset_details = pd.read_csv('\/kaggle\/input\/g-research-crypto-forecasting\/asset_details.csv')\ndf_asset_details","a985f38a":"btc = df_train[df_train[\"Asset_ID\"]==1].set_index(\"timestamp\") # Asset_ID = 1 for Bitcoin\nbtc_mini = btc.iloc[-200:] # Select recent data rows","55906d05":"import plotly.graph_objects as go\n\nfig = go.Figure(data=[go.Candlestick(x=btc_mini.index, open=btc_mini['Open'], high=btc_mini['High'], low=btc_mini['Low'], close=btc_mini['Close'])])\nfig.show()","05219b96":"btc.info(verbose=True)","c0866709":"btc.isna().sum()","088a3fb2":"#check the time range for Bitcoin and Ethereum data, \n#using the coversion from timestamp to `datetime`\nbeg_btc = btc.index[0].astype('datetime64[s]')\nend_btc = btc.index[-1].astype('datetime64[s]')\n\nprint('BTC data goes from ', beg_btc, 'to ', end_btc)","be437f41":"from datetime import datetime\nbtc = df_train[df_train[\"Asset_ID\"]==1]\nbtc = btc.reindex(range(btc.index[0],btc.index[-1]+60,60),method='pad')\nbtc_index = btc\nbtc_index['timestamp'] = pd.to_datetime(btc_index['timestamp'], unit='s')","b0d77d0e":"import matplotlib.dates as mdates\nbtc_month = btc_index.resample(\"M\", on='timestamp').mean()","df14074e":"fig, ax = plt.subplots(figsize=(10, 6))\nax.xaxis.set_major_formatter(mdates.DateFormatter('%Y-%m-%d %H'))\n#ax.set_xticklabels(btc_hour['timestamp'], rotation=90)\nax.bar(btc_month['2018':].index, btc_month.loc['2018':, \"Volume\"], width=25, align='center')\nfig.autofmt_xdate()","ed432ddf":"import time\nmask = (btc['timestamp'] > '2018-09-21') & (btc['timestamp'] <= '2021-09-21')\nbtc_1821 = btc.loc[mask]","1a46ac08":"import seaborn as sns\nbtc_1821['month'] = btc_1821['timestamp'].dt.strftime('%b')\n#start, end = '2018-01-01 00', '2021-07-01 00'\nfig, axes = plt.subplots(4, 1, figsize=(10, 16), sharex=True)\nfor name, ax in zip(['Open', 'Close', 'High', 'Low'], axes):\n    sns.boxplot(data=btc_1821,x='month', y=name, ax=ax)\n    ax.set_ylabel(\"\")\n    ax.set_title(name)\n    if ax != axes[-1]:\n        ax.set_xlabel('')","069fd399":"btc_month['Volume'].plot(figsize=(8, 6))","f4c54e69":"btc_week = btc_index.resample(\"W\", on='timestamp').mean()\nbtc_day = btc_index.resample(\"D\", on='timestamp').mean()","ebd3e988":"start, end = '2021-01', '2021-08'\nfig, ax = plt.subplots()\nax.plot(btc_day.loc[start:end, 'Volume'], marker='.', linestyle='-', linewidth = 0.5, label='Daily', color='black')\nax.plot(btc_week.loc[start:end, 'Volume'], marker='o', markersize=8, linestyle='-', label='Weekly', color='coral')\nax.set_ylabel(\"Open\")\nax.legend()\nfig.autofmt_xdate()","d972e058":"btc_date = btc_index.set_index(\"timestamp\")","f3dcd101":"btc_date['Change'] = btc_date.Close.div(btc_date.Close.shift())\nbtc_date['Change'].plot(figsize=(20, 8), fontsize = 16)","f5b3e517":"btc_date['2020']['Change'].plot(figsize=(10, 6))","22f1e3c1":"fig, ax = plt.subplots()\nax = btc_date.High.plot(label='High')\nax = btc_date.High.expanding().mean().plot(label='High expanding mean')\nax = btc_date.High.expanding().std().plot(label='High expanding std')\nax.legend()","8ec6cf2f":"from pylab import rcParams\nimport statsmodels.api as sm\nrcParams['figure.figsize'] = 11, 9\ndecomposition = sm.tsa.seasonal_decompose(btc_month['Volume'], model='Additive')\nfig = decomposition.plot()\nplt.show()","15c0c653":"We can see the different features included in the dataset. Specifically, the features included per asset are the following:\n*   **timestamp**: All timestamps are returned as second Unix timestamps (the number of seconds elapsed since 1970-01-01 00:00:00.000 UTC). Timestamps in this dataset are multiple of 60, indicating minute-by-minute data.\n*   **Asset_ID**: The asset ID corresponding to one of the crytocurrencies (e.g. `Asset_ID = 1` for Bitcoin). The mapping from `Asset_ID` to crypto asset is contained in `asset_details.csv`.\n*   **Count**: Total number of trades in the time interval (last minute).\n*   **Open**:\tOpening price of the time interval (in USD).\n*   **High**:\tHighest price reached during time interval (in USD).\n*   **Low**: Lowest price reached during time interval (in USD).\n*   **Close**:\tClosing price of the time interval (in USD).\n*   **Volume**:\tQuantity of asset bought or sold, displayed in base currency USD.\n*   **VWAP**: The average price of the asset over the time interval, weighted by volume. VWAP is an aggregated form of trade data.\n*   **Target**: Residual log-returns for the asset over a 15 minute horizon. \n\nThe first two columns define the time and asset indexes for this data row. The 6 middle columns are feature columns with the trading data for this asset and minute in time. The last column is the prediction target, which we will get to later in more detail.\n\nWe also view the asset information, including the list of all assets, the `Asset_ID` to asset mapping, and the weight of each asset used to weigh their relative importance in the evaluation metric.","3c435d9e":"## preprocessing","5c5a8416":"# <center>DATA FEATURES<\/center> ","3bf5aa11":"We can simply take a specific period and plot to have a clearer look. This is the plot of 2020 only.","cd9d2554":"In the code above, .div() helps to fill up the missing data. Actually, div() means division. df. div(6) will divide each element in df by 6. But here I used \u2018df.Close.shift()\u2019. So, Each element of df will be divided by each element of \u2018df.Close.shift()\u2019. We do this to avoid the null values that are created by the \u2018shift()\u2019 operation","32e4c8fa":"# <center>resample to smooth out the spikes<\/center> \nIn the \u2018Volume\u2019 data we are working on right now, we can observe some big spikes here and there. These types of spikes are not helpful for data analysis or for modeling. normally to smooth out the spikes, resampling to a lower frequency and rolling is very helpful.","d4d587c3":"### method 1","11cbaf45":"The shift function shifts the data before or after the specified amount of time. If I do not specify the time it will shift the data by one day by default. That means you will get the previous day's data. In financial data like this one, it is helpful to see previous day data and today's data side by side. It only plot the previous day data:","568f36e0":"**.reindex() description** \n\nDataFrame.reindex(labels=None, index=None, columns=None, axis=None, method=None, copy=True, level=None, fill_value=nan, limit=None, tolerance=None)\n\nmethod{None, \u2018backfill\u2019\/\u2019bfill\u2019, \u2018pad\u2019\/\u2019ffill\u2019, \u2018nearest\u2019}\nMethod to use for filling holes in reindexed DataFrame. Please note: this is only applicable to DataFrames\/Series with a monotonically increasing\/decreasing index.\n\nNone (default): don\u2019t fill gaps\n\n*pad \/ ffill: Propagate last valid observation forward to next valid.*\n\nbackfill \/ bfill: Use next valid observation to fill gap.\n\nnearest: Use nearest valid observations to fill gap.","752e323b":"### method 2","e9c99c03":"# <center>DECOMPESITION<\/center> \n\nDecomposition will show the observations and these three elements in the same plot:\n*   Trend: Consistent upward or downward slope of a time series.\n*   Seasonality: Clear periodic pattern of a time series\n*   Noise: Outliers or missing values\n\nOriginal observations = Trend + Seasonality + Residuals","70b577d8":"# <center>PLOT THE CHANGE<\/center> ","2e470bc7":"\u2018Volume\u2019 data was too busy in the original dataset. It can be fixed by resampling. Instead of plotting daily data, plotting monthly average will fix this issue to a large extent. I will use the btc_month dataset I prepared already for the bar plot and box plots above for this.","751e88bb":"# <center>BOX PLOT<\/center> \n\nOne way to find seasonality is by using a set of boxplots. Here I am going to make boxplots for each hour. I will use \u2018Open\u2019, \u2018Close\u2019, \u2018High\u2019 and \u2018Low\u2019 data to make this plot.\n\nThe dataset is lack of the market between 2021-09-22 to 2022-01-01, we cut out the records between 2018-01-01 to 2018-09-20, to make sure every month has the same amount of data. ","a092df15":"**The box plots show that prices are usually at their low point in Sep, Oct, Nov, Dec, while at high point in Feb, Mar, Apr.**","47468130":"plot the daily and weekly data in the same plot.","19f1b2b1":"# <center>BAR PLOT<\/center> \n\nHere I am making a bar plot of month data for 2018 to 2021. For the index, I will use [2018:]. Because our dataset contains data until 2021. So, 2018 to end should bring 2018 to 2021.\n\nEach bar represents a month. A huge spike in April 2020. Otherwise, there is no monthly seasonality here.","b69e1b75":"Another way of transformation. It keeps adding the cumulative. For example, if you add an expanding function to the \u2018High\u2019 column first element remains the same. The second element becomes cumulative of the first and second element, the third element becomes cumulative of the first, second, and third element, and so on. You can use aggregate functions like mean, median, standard deviation, etc. on it too."}}