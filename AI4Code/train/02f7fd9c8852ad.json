{"cell_type":{"6ae7f1cc":"code","18d20d05":"code","cd67b470":"code","f40dac48":"code","c1eb4352":"code","11d6e0fb":"code","62cbc8ca":"code","3d54a0d0":"code","a8c6c210":"code","54e8b589":"code","6db26f41":"code","72b345a5":"code","70c0ced6":"code","c8f6d10b":"code","62ff42ab":"code","ee3b4b64":"code","c1f8af18":"code","d4f43c61":"code","084fca43":"code","5ec124ab":"code","d66f0c0b":"code","f0b7584c":"code","25ab616e":"code","a188f540":"code","be0c0e1c":"code","b3e02b99":"code","85b51ae8":"code","7cce5182":"code","c95f5d4d":"code","9393e197":"code","2b21c519":"code","24521f6b":"code","fe99d816":"code","01f6e475":"code","6ecfe764":"code","ee2fb743":"code","48d9f130":"code","42025c0a":"code","84183fa1":"code","4b8bf6c0":"code","809d2d35":"code","c6b86daa":"code","4acb7346":"code","df291f8c":"code","8617d292":"code","2981aa36":"code","c2f8c952":"code","802acaa1":"code","29167856":"code","f5d7abe9":"code","39e25cb2":"code","7ab010f3":"code","5bdae14f":"code","b104fc52":"code","11fa2988":"code","78065a30":"code","3c57de4b":"code","7aa8c80b":"code","0c397a08":"code","39342e25":"code","1c299458":"code","8c532e10":"code","e55a373b":"code","745c25cb":"code","844db4f0":"code","23059541":"code","05b804f5":"code","7f6b5dad":"code","1bf9ea4c":"code","5ecdce36":"code","f0052af6":"code","cbe6bf8e":"code","8827bd38":"code","0984ce1c":"code","e1ef65e8":"code","b5de4c12":"code","10debdca":"code","0a77151b":"code","0704fef9":"code","1d05032f":"code","1f2bfe09":"code","0009cc81":"code","61e1126c":"code","90a3a6ef":"code","16c507cd":"code","497d4935":"code","cacda32f":"code","a39b6555":"code","4bd73e15":"code","1606339e":"code","2c726329":"code","0a189fd2":"code","8146fa7e":"code","2b2f3e3b":"code","ba1ef76e":"code","5810bf8a":"code","6515f848":"code","9b128f9c":"code","c5288193":"code","b131da30":"code","dd46ddf5":"code","a9993c5b":"code","283da986":"code","ab5d9f50":"code","85c9626d":"code","35c148ed":"code","622cc87d":"code","218b105a":"code","2821fc4c":"code","11a008ab":"markdown","dc21e723":"markdown","257cf972":"markdown","f663e401":"markdown","66e307d0":"markdown","2b7beb81":"markdown","afdd7fe9":"markdown","24cb0dc7":"markdown","010c9dc9":"markdown","e3824a9b":"markdown","c6be4b1c":"markdown","314e291a":"markdown","7aaf1434":"markdown","860ea7d8":"markdown","ffffa3b4":"markdown","a794917a":"markdown","eef66e90":"markdown","89286b81":"markdown","22d94872":"markdown","1670e485":"markdown","e02413f4":"markdown","02bab061":"markdown","998b1986":"markdown","51ee5ec4":"markdown","30aa231d":"markdown","0f842745":"markdown","db2626e3":"markdown","1e02fb4e":"markdown","ca36ff2c":"markdown","bb87ba61":"markdown","88097f54":"markdown","075580c2":"markdown","ae7361bf":"markdown","2074b607":"markdown","521a9835":"markdown","9eaaea40":"markdown","d5d23698":"markdown","659101e0":"markdown","ce0290b8":"markdown","f8cf1857":"markdown","60b547d9":"markdown","a134bd7c":"markdown","ec42f7cc":"markdown","e5d29b03":"markdown","8642c37c":"markdown","64ecad7b":"markdown","1f8cc964":"markdown","97002f73":"markdown","262d4afb":"markdown","7beb161f":"markdown","794928c5":"markdown","33282562":"markdown","743c7dad":"markdown","da70eb09":"markdown","8f37149a":"markdown","0f24055d":"markdown","78290229":"markdown","81670e80":"markdown","e658c86f":"markdown","7b154f6f":"markdown","dba5ff7f":"markdown","5cbdc465":"markdown","ce9f998d":"markdown","d3e71582":"markdown","46ed40f3":"markdown","037e2e11":"markdown","010da07c":"markdown","ee30b9ad":"markdown","f4729920":"markdown","83d49b28":"markdown","2e7f8e22":"markdown","53314ada":"markdown","e19a7642":"markdown","9cc4bc3e":"markdown","138cecca":"markdown","77b2d0c6":"markdown","bfc96226":"markdown","5c7fb263":"markdown","4b1b9959":"markdown","7799bd20":"markdown","072ae4ca":"markdown","5bcf05a2":"markdown","26e1fa05":"markdown","08f0e34e":"markdown","f9e50385":"markdown","5a561933":"markdown","715ad2bc":"markdown","59e741f7":"markdown","1e0b30bb":"markdown","84eb8e08":"markdown","51f823b8":"markdown","1c5483b7":"markdown"},"source":{"6ae7f1cc":"# import datasets:\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","18d20d05":"!pip install pdpipe","cd67b470":"import datetime as dt\nimport pdpipe as pdp\nfrom typing import Tuple, List, Dict\nimport glob\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.express as px\nimport plotly.offline\nimport plotly.graph_objs as go\n\nimport re","f40dac48":"us_state_abbrev = {\n    'Alabama': 'AL',\n    'Alaska': 'AK',\n    'American Samoa': 'AS',\n    'Arizona': 'AZ',\n    'Arkansas': 'AR',\n    'California': 'CA',\n    'Colorado': 'CO',\n    'Connecticut': 'CT',\n    'Delaware': 'DE',\n    'District Of Columbia': 'DC',\n    'Florida': 'FL',\n    'Georgia': 'GA',\n    'Guam': 'GU',\n    'Hawaii': 'HI',\n    'Idaho': 'ID',\n    'Illinois': 'IL',\n    'Indiana': 'IN',\n    'Iowa': 'IA',\n    'Kansas': 'KS',\n    'Kentucky': 'KY',\n    'Louisiana': 'LA',\n    'Maine': 'ME',\n    'Maryland': 'MD',\n    'Massachusetts': 'MA',\n    'Michigan': 'MI',\n    'Minnesota': 'MN',\n    'Mississippi': 'MS',\n    'Missouri': 'MO',\n    'Montana': 'MT',\n    'Nebraska': 'NE',\n    'Nevada': 'NV',\n    'New Hampshire': 'NH',\n    'New Jersey': 'NJ',\n    'New Mexico': 'NM',\n    'New York': 'NY',\n    'North Carolina': 'NC',\n    'North Dakota': 'ND',\n    'Northern Mariana Islands':'MP',\n    'Ohio': 'OH',\n    'Oklahoma': 'OK',\n    'Oregon': 'OR',\n    'Pennsylvania': 'PA',\n    'Puerto Rico': 'PR',\n    'Rhode Island': 'RI',\n    'South Carolina': 'SC',\n    'South Dakota': 'SD',\n    'Tennessee': 'TN',\n    'Texas': 'TX',\n    'Utah': 'UT',\n    'Vermont': 'VT',\n    'Virgin Islands': 'VI',\n    'Virginia': 'VA',\n    'Washington': 'WA',\n    'West Virginia': 'WV',\n    'Wisconsin': 'WI',\n    'Wyoming': 'WY'\n}\n","c1eb4352":"products = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/products_info.csv')\nprint('General Information: ')\nprint()\nprint('Shape :',products.shape)\nprint('Information: \\n')\nproducts.info()","11d6e0fb":"products[products['Provider\/Company Name'].isnull()]","62cbc8ca":"products[products['Product Name']=='True North Logic']","3d54a0d0":"products.drop([371],axis=0, inplace=True)","a8c6c210":"products[products['Sector(s)'].isnull()]","54e8b589":"products = products.drop([146,158,174,311,331,354], axis=0)","6db26f41":"products[(products['Provider\/Company Name']=='IXL Learning')]['Sector(s)'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='IXL Learning')]['Sector(s)'].notnull()\nproducts.loc[61,'Sector(s)'] = 'PreK-12'","72b345a5":"# What is the dominant sector at Microsoft?\nproducts[(products['Provider\/Company Name']=='Microsoft')]['Sector(s)'].value_counts(normalize=True)\n# What are the completed and missing values?\nproducts[(products['Provider\/Company Name']=='Microsoft')]['Sector(s)'].notnull()\n# Substitution of missing values by the value of the predominant sector:\nproducts.loc[183,'Sector(s)'] = 'PreK-12; Higher Ed; Corporate'\nproducts.loc[293,'Sector(s)'] = 'PreK-12; Higher Ed; Corporate'","70c0ced6":"# What is the dominant sector?\nproducts[(products['Provider\/Company Name']=='Houghton Mifflin Harcourt')]['Sector(s)'].value_counts(normalize=True)\n# What are the completed and missing values?\nproducts[(products['Provider\/Company Name']=='Houghton Mifflin Harcourt')]['Sector(s)'].notnull()\n# Substitution of missing values by the value of the predominant sector:\nproducts.loc[210,'Sector(s)'] = 'PreK-12'","c8f6d10b":"# What is the dominant sector?\nproducts[(products['Provider\/Company Name']=='ClassDojo, Inc.')]['Sector(s)'].value_counts(normalize=True)\n# What are the completed and missing values?\nproducts[(products['Provider\/Company Name']=='ClassDojo, Inc.')]['Sector(s)'].notnull()\n# Substitution of missing values by the value of the predominant sector:\nc = products[products['Provider\/Company Name']=='ClassDojo, Inc.'].reset_index()\nfor i in c['index']:\n    products.loc[i,'Sector(s)'] = 'PreK-12'","62ff42ab":"# What is the dominant sector?\nproducts[(products['Provider\/Company Name']=='Google LLC')]['Sector(s)'].value_counts(normalize=True)\n# What are the completed and missing values?\nproducts[(products['Provider\/Company Name']=='Google LLC')]['Sector(s)'].notnull().shape\n# Substitution of missing values by the value of the predominant sector:\nd = products[products['Provider\/Company Name']=='Google LLC'].reset_index()\nfor i in d['index']:\n    products.loc[i,'Sector(s)'] = 'PreK-12; Higher Ed; Corporate'","ee3b4b64":"products[(products['Provider\/Company Name']=='Adobe Inc.')]['Sector(s)'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Adobe Inc.')]['Sector(s)'].isnull()\nd = products[products['Provider\/Company Name']=='Adobe Inc.'].reset_index()\nfor i in d['index']:\n    products.loc[i,'Sector(s)'] = 'PreK-12; Higher Ed; Corporate'","c1f8af18":"products[(products['Provider\/Company Name']=='Grammarly')]['Sector(s)'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Grammarly')]['Sector(s)'].isnull()\nproducts.loc[314, 'Sector(s)'] = 'PreK-12; Higher Ed; Corporate'","d4f43c61":"products[(products['Provider\/Company Name']=='Technological Solutions, Inc. (TSI)')]['Sector(s)'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Technological Solutions, Inc. (TSI)')]['Sector(s)'].isnull()\nproducts.loc[352, 'Sector(s)'] = 'PreK-12'","084fca43":"products[(products['Provider\/Company Name']=='Code.org')]['Sector(s)'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Code.org')]['Sector(s)'].isnull()\nproducts.loc[356, 'Sector(s)'] = 'PreK-12'  ","5ec124ab":"products[(products['Provider\/Company Name']=='EDpuzzle Inc.')]['Sector(s)'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='EDpuzzle Inc.')]['Sector(s)'].isnull()\nproducts.loc[370, 'Sector(s)'] = 'PreK-12'  ","d66f0c0b":"products[products['Primary Essential Function'].isnull()]","f0b7584c":"products[products['Provider\/Company Name']=='IXL Learning']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='IXL Learning')]['Primary Essential Function'].isnull()\nproducts.loc[61,'Primary Essential Function'] = 'LC - Digital Learning Platforms' ","25ab616e":"products[products['Provider\/Company Name']=='Microsoft']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Microsoft')]['Primary Essential Function'].isnull()\nproducts.loc[183,'Primary Essential Function'] = 'LC\/CM\/SDO - Other' \nproducts.loc[293,'Primary Essential Function'] = 'LC\/CM\/SDO - Other' ","a188f540":"products[products['Provider\/Company Name']=='Houghton Mifflin Harcourt']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Houghton Mifflin Harcourt')]['Primary Essential Function'].isnull()\nproducts.loc[210,'Primary Essential Function'] = 'LC - Courseware & Textbooks'  ","be0c0e1c":"products[products['Provider\/Company Name']=='ClassDojo, Inc.']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='ClassDojo, Inc.')]['Primary Essential Function'].isnull()\nproducts.loc[237,'Primary Essential Function'] = 'CM - Classroom Engagement & Instruction - Communication & Messaging'  ","b3e02b99":"products[products['Provider\/Company Name']=='Google LLC']['Primary Essential Function'].value_counts(normalize=True)*100\nproducts[(products['Provider\/Company Name']=='Google LLC')]['Primary Essential Function'].isnull().shape\nproducts.loc[248,'Primary Essential Function'] = 'LC\/CM\/SDO - Other'\nproducts.loc[262,'Primary Essential Function'] = 'LC\/CM\/SDO - Other' \nproducts.loc[265,'Primary Essential Function'] = 'LC\/CM\/SDO - Other'","85b51ae8":"products[products['Provider\/Company Name']=='Adobe Inc.']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Adobe Inc.')]['Primary Essential Function'].isnull()\nproducts.loc[305,'Primary Essential Function'] = 'LC - Content Creation & Curation'","7cce5182":"products[products['Provider\/Company Name']=='Grammarly']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Grammarly')]['Primary Essential Function'].isnull()\nproducts.loc[314,'Primary Essential Function'] = 'LC - Study Tools' ","c95f5d4d":"products[products['Provider\/Company Name']=='Technological Solutions, Inc. (TSI)']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Technological Solutions, Inc. (TSI)')]['Primary Essential Function'].isnull()\nproducts.loc[352,'Primary Essential Function'] = 'LC - Sites, Resources & Reference - Games & Simulations'","9393e197":"products[products['Provider\/Company Name']=='Code.org']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='Code.org')]['Primary Essential Function'].isnull()\nproducts.loc[356,'Primary Essential Function'] = 'LC - Digital Learning Platforms'","2b21c519":"products[products['Provider\/Company Name']=='EDpuzzle Inc.']['Primary Essential Function'].value_counts(normalize=True)\nproducts[(products['Provider\/Company Name']=='EDpuzzle Inc.')&(products['Primary Essential Function'].isnull())]\nproducts.loc[370,'Primary Essential Function'] = 'LC - Digital Learning Platforms'","24521f6b":"primary_essential_main = []\nprimary_essential_sub = []\n\nfor s in products[\"Primary Essential Function\"]:\n    if(not pd.isnull(s)):\n        s1 = s.split(\"-\",1)[0].strip()\n        primary_essential_main.append(s1)\n    else:\n        primary_essential_main.append(np.nan)\n    \n    if(not pd.isnull(s)):\n        s2 = s.split(\"-\",1)[1].strip()\n        primary_essential_sub.append(s2)\n    else:\n        primary_essential_sub.append(np.nan)\n\n\nproducts[\"pef_cat\"] = primary_essential_main\nproducts[\"pef\"] = primary_essential_sub","fe99d816":"dis = pd.read_csv('..\/input\/learnplatform-covid19-impact-on-digital-learning\/districts_info.csv')","01f6e475":"print('_'*50)\nprint('General informatio about district.csv')\nprint()\nprint('Shape: ',dis.shape)\nprint()\nprint('Information: ')\ndis.info()\nprint()\nprint('Unique State: ', dis['state'].unique())\nprint('_'*50)","6ecfe764":"print('pp_total_raw = NaN for each state: \\n\\n', list(dis[(dis['pp_total_raw'].isnull()) &\\\n                                                                     (dis['state'].notnull())]['state'].unique()))","ee2fb743":"a = dis[dis['state']=='Connecticut'].reset_index()\nfor i in a['index']:\n    dis.loc[i,'pp_total_raw'] = '[16000, 18000['","48d9f130":"b = dis[dis['state']=='Ohio'].reset_index()\nfor i in b['index']:\n    dis.loc[i,'pp_total_raw'] = '[8000, 10000['","42025c0a":"c = dis[dis['state']=='California'].reset_index()\nfor i in c['index']:\n    dis.loc[i,'pp_total_raw'] = '[12000, 14000['","84183fa1":"d = dis[dis['state']=='Arizona'].reset_index()\nfor i in d['index']:\n    dis.loc[i,'pp_total_raw'] = '[8000, 10000['","4b8bf6c0":"e = dis[dis['state']=='North Dakota'].reset_index()\nfor i in e['index']:\n    dis.loc[i,'pp_total_raw'] = '[12000, 14000['","809d2d35":"# vamos a eliminar New Hampshire\ndis = dis.drop([202,217],axis=0)","c6b86daa":"f = dis[dis['state']=='New York'].reset_index()\nfor i in f['index']:\n    dis.loc[i,'pp_total_raw'] = '[22000, 24000['","4acb7346":"#for i in list(['City','Suburb','Town','Rural']):\n#    for j in list(['[0, 0.2[', '[0.2, 0.4[', '[0.4, 0.6[', '[0.6, 8[', '[0.8, 1[']):\nprint(' '*30, 'Pie chart: locale is City:\\n')\nplt.figtext(0.70, 0.55, 'Case City: Conclusion', fontsize = 15, fontname = 'monospace', color = '#111112')\nplt.subplot(2,3,1)\n#_____________________________________CITY + 'pct_black\/hispanic'=='[0, 0.2['\ndis[(dis['locale']=='City') & (dis['pct_black\/hispanic']=='[0, 0.2[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0,0.2[')\n\n\nplt.subplot(2,3,2)\n#_____________________________________CITY + 'pct_black\/hispanic'=='[0.2, 0.4['\ndis[(dis['locale']=='City') & (dis['pct_black\/hispanic']=='[0.2, 0.4[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0.2,0.4[')\nplt.subplot(2,3,3)\n#_____________________________________CITY + 'pct_black\/hispanic'=='[0.4, 0.6['\ndis[(dis['locale']=='City') & (dis['pct_black\/hispanic']=='[0.4, 0.6[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0.4,0.6[')\n\nplt.subplot(2,3,4)\n#_____________________________________CITY + 'pct_black\/hispanic'=='[0.6, 0.8['\ndis[(dis['locale']=='City') & (dis['pct_black\/hispanic']=='[0.6, 0.8[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0.6,0.8[')\n\nplt.subplot(2,3,5)\n#_____________________________________CITY + 'pct_black\/hispanic'=='[0.8, 1['\ndis[(dis['locale']=='City') & (dis['pct_black\/hispanic']=='[0.8, 1[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0.8, 1[')\n\n#plt.subplot(2,3,6)\n#plt.figtext(0.74, 0.42, 'Conclusion', fontsize = 15, fontname = 'monospace', color = '#111112')\n\nplt.figtext(0.70, 0.20, '''* When pct_black\/hispanic range is \n[0,0.2[, the most commont value \n(60%) of pct_free\/reduced is [0,0.2[.\n\n* When pct_black\/hispanic range is \n[0.2,0.4[, the most commont value (60%) \nof pct_free\/reduced is [0.4,0.6[.\n\n* When pct_black\/hispanic range is \n[0.4,0.6[, the most commont value (50%) \nof pct_free\/reduced is [0.4,0.6[.\n\n* When pct_black\/hispanic range is \n[0.6,0.8[, two value of pct_free\/reduced \nare equal important. \n\n* When pct_black\/hispanic range is \n[0.8,1[, the most commont value (66.7%) \nof pct_free\/reduced is [0.8,1[.''', fontsize = 13, \n            fontname = 'monospace', color = '#111112', ha = 'left')\n\nplt.show()","df291f8c":"print(' '*30, 'Pie chart: locale is Suburb:\\n')\nplt.figtext(0.70, 0.55, 'Case Suburb: Conclusion', fontsize = 15, fontname = 'monospace', color = '#111112')\nplt.subplot(2,3,1)\ndis[(dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0, 0.2[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0,0.2[')\n\n\nplt.subplot(2,3,2)\ndis[(dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0.2, 0.4[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0.2,0.4[')\n\nplt.subplot(2,3,3)\ndis[(dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0.4, 0.6[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0.4,0.6[')\n\nplt.subplot(2,3,4)\ndis[(dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0.6, 0.8[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#c9061b\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0.6,0.8[')\n\nplt.subplot(2,3,5)\ndis[(dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0.8, 1[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#c9061b\",\"#6e6c70\"))\n\nplt.title('Pie chart black\/hispanic [0.8, 1[')\n#plt.subplot(2,3,6)\n#plt.figtext(0.74, 0.42, 'Conclusion', fontsize = 15, fontname = 'monospace', color = '#111112')\n\nplt.figtext(0.70, 0.20, '''* When pct_black\/hispanic range is \n[0,0.2[, the most commont value \n(50.0%) of pct_free\/reduced is [0,0.2[.\n\n* When pct_black\/hispanic range is \n[0.2,0.4[, the most commont value (73.3%) \nof pct_free\/reduced is [0.2,0.4[.\n\n* When pct_black\/hispanic range is \n[0.4,0.6[, the most commont value (55.6%) \nof pct_free\/reduced is [0.4,0.6[.\n\n* When pct_black\/hispanic range is \n[0.6,0.8[, two value of pct_free\/reduced \nare equal important [0.2,0.4[ and [0.6,0.8[. \n\n* When pct_black\/hispanic range is \n[0.8,1[, two value of pct_free\/reduced \nare equal important [0.6,0.8[ and [0.8,1[.''', fontsize = 13, \n            fontname = 'monospace', color = '#111112', ha = 'left')\n\nplt.show()","8617d292":"print(' '*30, 'Pie chart: locale is Town:\\n')\n#plt.figtext(0.70, 0.55, 'Case Town: Conclusion', fontsize = 15, fontname = 'monospace', color = '#111112')\nplt.subplot(1,2,1)\ndis[(dis['locale']=='Town') & (dis['pct_black\/hispanic']=='[0, 0.2[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart Suburb black\/hispanic [0,0.2[')\n\n\nplt.subplot(1,2,2)\ndis[(dis['locale']=='Town') & (dis['pct_black\/hispanic']=='[0.2, 0.4[')]['pct_free\/reduced']\\\n        .value_counts().plot(kind = 'pie',\n                             autopct='%1.1f%%',\n                             figsize=(12, 12),\n                             colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\"))\n\nplt.title('Pie chart Suburb black\/hispanic [0.2,0.4[')\nprint('Case Town: When pct_black\/hispanic range is [0, 0.2,[, the most commont value (66.7%) of pct_free\/reduced is [0.4, 0.6[.') \nprint('When pct_black\/hispanic range is [0.2, 0.4,[, the most commont value (100%) of pct_free\/reduced is [0.8, 1[.') \n\nplt.show()","2981aa36":"print('pct_free\/reduced missing value states are: \\n\\n', list(dis[(dis['pct_free\/reduced'].isnull()) &\\\n                                                                              (dis['state'].notnull())]['state'].unique()))","c2f8c952":"a = dis[(dis['state']=='Massachusetts') & (dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0, 0.2[')].reset_index()\nfor i in a['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0, 0.2['\nb = dis[(dis['state']=='Massachusetts')  & (dis['locale']=='Rural') & (dis['pct_black\/hispanic']=='[0, 0.2[')].reset_index()\nfor i in b['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0.4, 0.6['\nc = dis[(dis['state']=='Massachusetts') & (dis['locale']=='City')  & (dis['pct_black\/hispanic']=='[0, 0.2[')].reset_index()\nfor i in c['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0, 0.2['\nd = dis[(dis['state']=='Massachusetts') & (dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0.2, 0.4[')].reset_index()\nfor i in d['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0.2, 0.4['\ne = dis[(dis['state']=='Massachusetts') & (dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0.4, 0.6[')].reset_index()\nfor i in e['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0.4, 0.6['","802acaa1":"f = dis[(dis['state']=='Ohio') & (dis['locale']=='City') & (dis['pct_black\/hispanic']=='[0.4, 0.6[')].reset_index()\nfor i in f['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0.4, 0.6['","29167856":"g = dis[(dis['state']=='Arizona') & (dis['locale']=='City')].reset_index()\nfor i in g['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0.8, 1['","f5d7abe9":"h = dis[(dis['state']=='Tennessee') & (dis['locale']=='Suburb') & (dis['pct_black\/hispanic']=='[0, 0.2[')].reset_index()\nfor i in h['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0, 0.2['\nii = dis[(dis['state']=='Tennessee') & (dis['locale']=='Rural') & (dis['pct_black\/hispanic']=='[0.2, 0.4[')].reset_index()\nfor i in ii['index']:\n    dis.loc[i,'pct_free\/reduced'] = '[0.8, 1['\n    \ndis.loc[36,'pct_free\/reduced'] = '[0.8, 1['\ndis.loc[50,'pct_free\/reduced'] = '[0.4, 0.6['\ndis.loc[149,'pct_free\/reduced'] = '[0.8, 1['","39e25cb2":"dis['county_connections_ratio'].value_counts(normalize=True).plot(kind='barh')\nplt.title('County connections ratio', size=15)\nplt.ylabel('Options')\nplt.show()","7ab010f3":"dis['county_connections_ratio'] = dis['county_connections_ratio'].replace(np.nan, '[0.18, 1[')","5bdae14f":"dis = dis.dropna(thresh=5)","b104fc52":"dis.info()","11fa2988":"np.where(dis['pct_free\/reduced'].isnull())","78065a30":"dis = dis.reset_index()\ndis.drop(['index'], axis=1, inplace=True)\ndis.loc[36,'pct_free\/reduced'] = '[0.8, 1['\ndis.loc[50,'pct_free\/reduced'] = '[0.4, 0.6['\ndis.loc[149,'pct_free\/reduced'] = '[0.8, 1['","3c57de4b":"def func_plot(df,col1):\n    fig,ax = plt.subplots(1,2,figsize=(14,5))\n    sns.countplot(data=df,y=col1,ax=ax[0],order=df[col1].value_counts().index,orient=\"v\")\n    ax[0].set_title(col1)\n    ax[1].pie(x=df[col1].value_counts(),labels=df[col1].value_counts().index,autopct='%1.0f%%')\n    ax[1].set_title(col1)\n\nfunc_plot(dis,\"pct_black\/hispanic\")\nfunc_plot(dis,\"pct_free\/reduced\")\nfunc_plot(dis,\"county_connections_ratio\") \nfunc_plot(dis,\"pp_total_raw\") ","7aa8c80b":"conec_2 = pd.DataFrame()\nconec_2[['state','25%','50%','75%','range']] = None\nstate = ['Illinois', 'Utah', 'Wisconsin', 'North Carolina', 'Missouri',\n       'Washington', 'Connecticut', 'Massachusetts', 'New York',\n       'Indiana', 'Virginia', 'Ohio', 'New Jersey', 'California',\n       'District Of Columbia', 'Minnesota', 'Arizona', 'Texas',\n       'Tennessee', 'Florida', 'North Dakota', 'Michigan']\nfirst = [0.60,0.78,0.73,0.64,0.57,0.72,0.85,0.83,0.73,0.62,0.59,0.67,0.88,0.79,0.69,0.71,0.72,0.59,0.60,0.66,1.03,0.66]\nsegund = [0.69,0.86,0.77,0.76,0.65,0.83,0.87,0.88,0.78,0.69,0.67,0.74,0.94,0.86,0.73,0.75,0.78,0.69,0.67,0.85,1.05,0.73]\nthird = [0.76,0.89,0.83,0.85,0.74,0.89,0.89,0.92,0.86,0.76,0.77,0.79,0.95,0.92,0.88,0.80,0.85,0.78,0.75,0.94,1.07,0.79]\nrango  = ['[0.6, 0.8[','[0.8, 1[','[0.7, 0.9[','[0.7, 0.9[','[0.6, 0.8[','[0.7, 0.9[','[0.8, 1[','[0.8, 1[','[0.7, 0.9[',\n          '[0.6, 0.8[','[0.6, 0.8[','[0.6, 0.8[','[0.8, 1[','[0.8, 1[','[0.6, 0.8[','[0.7, 0.9[','[0.7, 0.9[','[0.6, 0.8[',\n          '[0.6, 0.8[','[0.7, 0.9[','[1, 2[','[0.6, 0.8[']\n\nconec_2['state'] = state\nconec_2['25%'] = first\nconec_2['50%'] = segund\nconec_2['75%'] = third\nconec_2['range'] = rango\n        \nconec_2.head(2)","0c397a08":"conec_2['range'].value_counts(normalize=True).plot(kind='pie',autopct='%1.1f%%',\n                                                   figsize=(6, 6),\n                                                   colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\",\"#6e6c70\"))\nplt.title('El rango de consumer\/hhs', fontsize=15)\nplt.figtext(0.95, 0.50, '''The 40.9 % of connection ratio is in range [0.6, 0.8[. \nAfter that, 31.8% of connection ratio is in range [0.7, 0.9[''', fontsize = 12, \n            fontname = 'monospace', color = '#111112', ha = 'left')\nplt.show()","39342e25":"fig= plt.figure(figsize=(15,5))\nsns.lineplot(conec_2['state'],conec_2['50%'],color = '#c9061b')\nsns.lineplot(conec_2['state'],conec_2['25%'],color = '#676A6C')\nsns.lineplot(conec_2['state'],conec_2['75%'],color = '#0a0a0a')\nplt.ylabel('Ratio connections', fontsize=13)\nplt.xlabel('States', fontsize=13)\nplt.axvline('North Dakota',color = \"red\", linewidth = 1, linestyle = \"dashed\")\nplt.xticks(rotation=60)\nplt.legend(['50% ratio', '25% ratio','75% ratio'], ncol=3)\nplt.title('Ratio connections for State', fontsize=15)\nplt.show()","1c299458":"dist = pd.merge( dis,conec_2, how='inner', on='state')\ndist.info()","8c532e10":"poverty2 = pd.DataFrame()\npoverty2[['state','pp_total_raw_nerd','pover','error_poverty','#schools','Cardinal_points','type_state']] = None\nstate = ['Illinois', 'Utah', 'Wisconsin', 'North Carolina', 'Missouri',\n       'Washington', 'Connecticut', 'Massachusetts', 'New York',\n       'Indiana', 'Virginia', 'Ohio', 'New Jersey', 'California',\n       'District Of Columbia', 'Minnesota', 'Arizona', 'Texas',\n       'Tennessee', 'Florida', 'North Dakota', 'Michigan']\npp_total_raw_nerd = [12152,8346,12042,10068,10273,14364,14375,16036,22063,11262,9885,9015,16618,12460,20579,\n                     12588,8658,9645,10070,8525,12255,10750]\npover = [15.1,10.0,11.8,18.6,16.0,11.6,14.1,11.3,17.3,15.5,12.8,17.8,12.0,15.3,20.5,10.7,18.4,18.9,19.6,17.5,9.9,17.1]\nerror_poverty=[0.45,0.56,0.66,0.54,0.72,0.45,0.73,0.50,0.41,0.58,0.47,0.53,0.45,0.27,2.39,0.74,0.69,0.32,0.67,0.45,1.63,0.62]\nschools = [3872,1797,2262,2646,2161,2384,1001,1845,4687,1797,3427,1861,2473,10087,231,2362,2029,8641,1752,3611,476,3382]\ncardinalPoints  = ['Midwest','West','Midwest','South','Midwest','West','Northeast','Northeast','Northeast','Midwest','South',\n         'Midwest','Northeast','West','South','Midwest','West','South','South','South','Midwest','Midwest']\ntypes_governor = ['D','R','D','D','R','D','D','R','D','R','D','R','D','D','D','D','R','R','R','R','R','D']\n        \npoverty2['state'] = state\npoverty2['pp_total_raw_nerd'] = pp_total_raw_nerd\npoverty2['pover'] = pover\npoverty2['error_poverty'] = error_poverty\npoverty2['#escuelas'] = schools\npoverty2['Cardinal_points'] = cardinalPoints\npoverty2['type_state'] = types_governor\npoverty2.info()","e55a373b":"poverty2['Cardinal_points'].value_counts().plot(kind='pie', autopct='%1.1f%%',\n                                                   figsize=(12, 12),\n                                                   colors =(\"#c9061b\",\"#6e6c70\",\"#6e6c70\",\"#6e6c70\"))\nplt.show()","745c25cb":"fig, ax = plt.subplots(figsize=(18,12))\nax.errorbar(x = poverty2['state'], y = poverty2['pover'], yerr = poverty2['error_poverty'], marker = 'o', ecolor = 'red')\nax.set_xticklabels(poverty2['state'],rotation=90)\nax.set_title('Poverty State in percent', fontsize=15)\nplt.show()","844db4f0":"path = '..\/input\/learnplatform-covid19-impact-on-digital-learning\/engagement_data' \nfiles = glob.glob(path + \"\/*.csv\")\n\ncsv_list = []\n\nfor filename in files:\n    df = pd.read_csv(filename, index_col=None, header=0)\n    district_id = filename.split(\"\/\")[4].split(\".\")[0]\n    df[\"district_id\"] = district_id\n    csv_list.append(df)\n    \nengagement_data = pd.concat(csv_list)\nengagement_data = engagement_data.reset_index(drop=True)\nengagement_data.head()","23059541":"print('_'*50)\nprint('General informatio about engagement.csv')\nprint()\nprint('Shape: ',engagement_data.shape)\nprint()\nprint('Information: ')\nengagement_data.info()\nprint()\nprint('_'*50)","05b804f5":"eng = engagement_data.copy()","7f6b5dad":"eng = eng.dropna(subset=['lp_id'])\neng = eng.dropna(subset=['pct_access'])\neng = eng.dropna(subset=['engagement_index'])","1bf9ea4c":"merged_data = pd.merge(products, eng, left_on = 'LP ID', right_on = 'lp_id')\nmerged_data['district_id'] = merged_data['district_id'].astype('int64')\ndf_total = pd.merge(merged_data, dist, on = 'district_id')","5ecdce36":"df_total = pd.merge(df_total, poverty2,on = 'state' )","f0052af6":"print('Total School: {}'.format(poverty2[['#escuelas']].sum()))\nprint('Sample School muestra: {}'.format(dist['state'].value_counts().sum()))\nprint('% of total school is: {}'.format((174\/64784)*100))","cbe6bf8e":"dist['state_abbrev'] = dist['state'].replace(us_state_abbrev)","8827bd38":"school_state = dist['state_abbrev'].value_counts().to_frame().reset_index(drop=False)\nschool_state.columns = ['state_abbrev', 'num_districts']\n\nfig = go.Figure()\nlayout = dict(\n    title_text = \"Number of Available School Districts per State\",\n    geo_scope='usa',\n)\n\nfig.add_trace(\n    go.Choropleth(\n        locations=school_state.state_abbrev,\n        zmax=1,\n        z = school_state.num_districts,\n        locationmode = 'USA-states', # set of locations match entries in `locations`\n        marker_line_color='white',\n        geo='geo',\n        colorscale=px.colors.sequential.Teal, \n    )\n)\n            \nfig.update_layout(layout)   \nfig.show()","0984ce1c":"# Temporary Dataframe for Checking the Distribution of Locale in every State\ntemp = pd.crosstab(df_total.state, df_total.locale)\ntemp[\"summation\"] = temp.sum(axis=1)\ntemp[\"city_percent\"] = temp.City*100\/temp.summation\ntemp[\"rural_percent\"] = temp.Rural*100\/temp.summation\ntemp[\"suburb_percent\"] = temp.Suburb*100\/temp.summation\ntemp[\"town_percent\"] = temp.Town*100\/temp.summation\n\n# State and locale Distribution Plot\nfig = go.Figure()\nfig.add_trace(go.Bar(x=temp.index, y=temp.city_percent, name=\"Percentage City\",\n                    marker_color=px.colors.qualitative.Antique[10]))\nfig.add_trace(go.Bar(x=temp.index, y=temp.rural_percent, name=\"Percentage Rural\",\n                    marker_color=px.colors.qualitative.Set2[7]))\nfig.add_trace(go.Bar(x=temp.index, y=temp.suburb_percent, name=\"Percentage Suburb\",\n                    marker_color=px.colors.qualitative.Dark2[5]))\nfig.add_trace(go.Bar(x=temp.index, y=temp.town_percent, name=\"Percentage Town\",\n                    marker_color=px.colors.qualitative.Vivid[0]))\n\n# fig.update_traces(texttemplate='%{text:.2s}')\nfig.update_xaxes(tickfont_size=16, tickangle=270)\nfig.update_layout(font_family='Arial', \n                  title=dict(text=\"<b>Locale Distribution per State\", \n                             font_size=20, x=0.5),\n                  barmode='stack', height=600,\n                  legend=dict(orientation=\"h\",\n                              yanchor=\"bottom\",\n                              y=1.02,xanchor=\"right\",\n                              x=1\n                ))\nfig.show()\ndel temp","e1ef65e8":"#fig, ax = plt.figure(1,2,1)\nplot = poverty2['type_state'].value_counts().plot(colors = (\"#0d0d8c\",\"#e80219\"),\n                                                      kind = 'pie',\n                                                      autopct='%1.1f%%',\n                                                      figsize=(8, 8),\n                                                      startangle=20).legend(loc=\"upper right\");\n\nplt.title('Distribution of government states', size=15)\nplt.axis('off')\nplt.show()\n#fig, ax = plt.figure(1,2,2)\nplot = poverty2['Cardinal_points'].value_counts().plot(colors = (\"#3fab29\",\"#5bab4b\",'#76ad6c','#95b58f'),\n                                                      kind = 'pie',\n                                                      autopct='%1.1f%%',\n                                                      figsize=(8, 8),\n                                                      startangle=20).legend(loc=\"upper right\");\n\nplt.title('Distribution of states cardinal points', size=15)\nplt.axis('off')\nplt.show()","b5de4c12":"#Plotting a Bar Graph to know which is the product that is used by most of the students\n\nplt.figure(figsize=(15,7))\nmost_used_product= sns.countplot(x = \"Product Name\",data= df_total, \n              order=df_total[\"Product Name\"].value_counts().index[:20],palette = 'Spectral')\nfor p in most_used_product.patches:\n    most_used_product.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), \n                               ha='center' ,va='center', color='black', size=11)\nplt.title(\"Top 20 Product Name\", size=15)\nplt.xticks(rotation=90)\nplt.show()","10debdca":"plt.figure(figsize=(10,8))\ncompany= sns.countplot(x = \"Provider\/Company Name\",data= df_total, hue = 'type_state',\n                  order=df_total[\"Provider\/Company Name\"].value_counts(normalize=True).index[:5],\n                       orient='h',palette ='Spectral')\nfor p in company.patches:\n    company.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), \n                                                      ha='center',\n                                                      va='center', \n                                                      color='black', size=14)\nplt.title(\"Top 5 Company Name\", size=15)\nplt.xticks(rotation=90)\nplt.show()","0a77151b":"import re","0704fef9":"temp_sectors = products['Sector(s)'].str.get_dummies(sep=\"; \")\ntemp_sectors.columns = [f\"sector_{re.sub(' ', '', c)}\" for c in temp_sectors.columns]\nproducts_info = df_total.join(temp_sectors)\nproducts_info.drop(\"Sector(s)\", axis=1, inplace=True)\ndel temp_sectors\n\n#After One-Hot Encoding\nproducts_info.head(2)","1d05032f":"plot = df_total['Sector(s)'].value_counts().plot(colors = ('#0ced53',\"#3fab29\",\"#5bab4b\",'#76ad6c','#e3eb05'),\n                                                      kind = 'pie',\n                                                      autopct='%1.1f%%',\n                                                      figsize=(12, 12),\n                                                      startangle=20).legend(loc=\"upper right\");\n\nplt.title('Distribution of Sectors', size=15)\nplt.axis('off')\nplt.show()","1f2bfe09":"#Plotting a Bar Graph to know which is the product that is used by most of the students\nplt.figure(figsize=(10,8))\nmost_used_primary_essential_function= sns.countplot(x = \"Primary Essential Function\",data= df_total, \n              order=(df_total[\"Primary Essential Function\"].value_counts()\/len(df_total)).index[:10],\n                                                    palette = 'Spectral')\nfor p in most_used_primary_essential_function.patches:\n    most_used_primary_essential_function.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), \n                                                  ha='center',\n                                                  va='center', \n                                                  color='black', size=14)\nplt.title(\"Top 10 Primary Essential Function\", size=15)\nplt.xticks(rotation=90)\nplt.show()","0009cc81":"fig, ax = plt.subplots(1,1, figsize=(14,7))\n\n\n#plt.figure(figsize=(10,8))\nmost_used_primary_essential_function= sns.countplot(x = \"pef_cat\",data= df_total, \n              order=df_total[\"pef_cat\"].value_counts().index[:10])\n\nfor p in most_used_primary_essential_function.patches:\n    most_used_primary_essential_function.annotate(f'\\n{p.get_height()}', (p.get_x()+0.4, p.get_height()), \n                                                  ha='center',\n                                                  va='center', \n                                                  color='white', size=15)\nplt.title(\"Principal Categories\", size=15)\nplt.xticks(rotation=90)\nplt.show()\n\ntemp = df_total['pef_cat'].value_counts().reset_index()\ntemp.columns = ['pef_cat', 'percent']\ntemp['percent'] \/= len(df_total)\n\nfig = px.pie(temp, names='pef_cat', values='percent',\n    color_discrete_sequence=px.colors.qualitative.D3,\n    width=700,\n    height=500,\n)\nfig.update_layout(title=dict(text=\"<b>Principal Categories Distribution\", x=0.5, font_size=15))\nfig.show()","61e1126c":"temp = df_total['pef'].value_counts().reset_index()\ntemp.columns = ['pef', 'percent']\ntemp['percent'] \/= len(df_total)\n\nfig = px.pie(temp, names='pef', values='percent',\n    color_discrete_sequence=px.colors.qualitative.D3,\n    width=1000,\n    height=500,\n)\nfig.update_layout(title=dict(text=\"<b>Sub-category wise Products Distribution\", x=0.5, font_size=15))\nfig.show()","90a3a6ef":"temp = df_total.groupby([\"Sector(s)\", \"pef_cat\"])[\"URL\"].count().reset_index()\ntemp.columns = [\"Sector\", \"pef_cat\", \"Counts\"]\n\n#plot for Distribution of Category and Seg_Sub_Catgroy\nfig = px.sunburst(data_frame=temp, path=[\"Sector\", \"pef_cat\"], values=\"Counts\", \n                 color_discrete_sequence=px.colors.qualitative.D3)\nfig.update_layout(font_family=\"Arial\",\n                  title=dict(text=\"<b>Distribution of Categories among various Sectors\", font_size=20, x=0.5),\n                  font_size=16)\nfig.show()\ndel temp\ntemp = df_total.groupby([\"pef_cat\", \"pef\"])[\"URL\"].count().reset_index()\ntemp.columns = [\"pef_cat\", \"pef\", \"Counts\"]\n#plot for Distribution of Category and Seg_Sub_Catgroy\nfig = px.sunburst(data_frame=temp, path=[\"pef_cat\", \"pef\"], values=\"Counts\", \n                 color_discrete_sequence=px.colors.qualitative.D3)\nfig.update_layout(font_family=\"Arial\",\n                  title=dict(text=\"<b>Distribution of Sub Categories among various Categories\",\n                             font_size=20),\n                  font_size=16)\nfig.show()\ndel temp","16c507cd":"grouped_districts = df_total.groupby(by=[\"state\"])[['pct_access','engagement_index']].mean()\n\ndf_total[\"state_code\"] = df_total.state.map(us_state_abbrev)\ngrouped_districts = grouped_districts.reset_index()\ngrouped_districts[\"state_abv\"] = grouped_districts.state.map(us_state_abbrev)\n\ndef map_plot(dataframe, location, color, hover):\n    fig = px.choropleth(data_frame=dataframe, locations=location, locationmode=\"USA-states\",\n                    color=color, scope=\"usa\", hover_name=hover, color_continuous_scale=\"viridis_r\")\n    fig.update_layout(font_family=\"Arial\",)\n    return fig\n\nfig = map_plot(grouped_districts, \"state_abv\", \"pct_access\", \"state\")\nfig.update_layout(title=dict(text=\"<b>Comparison of State's pct access levels\", font_size=20))\nfig.show()\n\nfig = map_plot(grouped_districts, \"state_abv\", \"engagement_index\", \"state\")\nfig.update_layout(title=dict(text=\"<b>Comparison of State's engagement index levels\", font_size=20))\nfig.show()","497d4935":"# Correlation between various Indexes\ntemp = df_total[['pct_access','engagement_index']]\nplt.figure(figsize=(10,8))\nsns.heatmap(temp.corr(), annot=True, cmap=\"viridis_r\")\nplt.xticks(size=12, rotation=0)\nplt.yticks(size=12, rotation=0)\nplt.title(\"Corrleation between pct access & engagement index variables\", size=20)\nplt.show()","cacda32f":"def bar_plot(dataframe, feature1, feature2):\n    if len(feature2)>1:\n        fig = make_subplots(rows=1, cols=len(feature2), subplot_titles=feature2)\n        for i in range(len(feature2)):\n            fig.add_trace(go.Bar(x=dataframe[feature1[0]], y=dataframe[feature2[i]],\n                                 name=feature2[i]), row=1, col=i+1)\n        fig.update_layout(font_family=\"Arial\", showlegend=False, margin=dict(l=0, r=0, t=100, b=50), \n                          height=400)\n        fig.update_traces(marker_color='rgb(158,202,225)', marker_line_color='rgb(8,48,107)',\n                  marker_line_width=1.5, opacity=0.6)\n        return fig\neng[\"week\"] = pd.to_datetime(eng.time).dt.weekofyear\n\n# extracting day of week from time\neng[\"day_of_week\"] = pd.to_datetime(eng.time).dt.dayofweek\n#analysing the affect of day of the week on engagement_index and pct_access \ntemp = eng.groupby(\"day_of_week\")[[\"engagement_index\",\"pct_access\"]].mean().reset_index()\n\n# visulaizing the affect of day of the week on engagement_index and pct_access \nfig = bar_plot(temp, [\"day_of_week\"], [\"engagement_index\",\"pct_access\"])\nfig.update_layout(title=dict(text=\"<b>Day of the WEEK affect<\/b>\", x=0.5, font_size=20))\nfig.show()","a39b6555":"def time_plot(df, factor, label):\n    for i in [\"pct_access\",\"engagement_index\"]:\n        fig = px.line(data_frame=df, x=\"week\", y=i, color=factor)\n        fig.update_layout(font_family=\"Arial\",title=dict(text=\"<b>\"+i+\" - \"+factor+\" wise - \"+label,  \n                                                                 x=0.5, font_size=20), \n                          height=300, margin=dict(b=0))\n        fig.update_xaxes(title=None)\n        fig.update_yaxes(title=None)\n        fig.show()\ndf_total[\"week\"] = pd.to_datetime(df_total.time).dt.weekofyear\n#State wise affect of Covid on Page Load events - best performing states\ntemp = df_total.groupby([\"state\",\"week\"])[[\"pct_access\",\"engagement_index\"]].mean().reset_index()\n#temp = temp[~temp.state.isin([\"Minnesota\",\"North Dakota\"])]           # data is not complete for these states\n\ntop_10_states = temp.groupby([\"state\"])[\"engagement_index\"].sum().reset_index().sort_values(\"engagement_index\",ascending=False).head(10).state.values\n\ntemp = temp[temp.state.isin(top_10_states)]\n\ntime_plot(temp, \"state\", \"Top 10\")","4bd73e15":"import plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\ntemp = eng.groupby(\"time\")[[\"engagement_index\",\"pct_access\"]].mean().reset_index()\n# Plot showing overall enegamenet index and pct _access\nfig = make_subplots(rows=2, cols=1, shared_xaxes=True, vertical_spacing=0.1, \n                    subplot_titles=[\"<b>% Atleast 1 page Load Event <br> \", \n                                    \"<b>Page Loads per 1000 Students <br> \"])\n\nfig.add_trace(go.Scatter(x=temp.time, y=temp.pct_access,marker=dict( color='rgba(055, 056, 150, 0.5)',size=20)), \n              row=1, col=1)\nfig.add_trace(go.Scatter(x=temp.time, y=temp.engagement_index,marker=dict( color='rgba(055, 000, 050, 0.5)',size=20)),\n              row=2, col=1)\n\nfig.add_vrect(x0=\"2020-05-20\", x1=\"2020-08-30\",\n              fillcolor=\"red\", opacity=0.2, line_width=0)\n\nfig.add_vrect(x0=\"2020-03-19\", x1=\"2020-04-07\",\n              fillcolor=\"red\", opacity=0.2, line_width=0)\n\nfig.add_vline(x=\"2020-01-21\", line_dash=\"dot\")\nfig.add_vline(x=\"2020-02-03\", line_dash=\"dot\")\nfig.add_vline(x=\"2020-07-16\", line_dash=\"dot\")\n\n\nfig.add_annotation(x=\"2020-01-21\", y=400, text=\"First Case in USA<br>dated 2020-01-21\", \n                   ax=-40, ay=-50, row=2, col=1, arrowsize=2, arrowhead=2)\n\nfig.add_annotation(x=\"2020-06-25\", y=1, text=\"Summer Break\", row=1, col=1, showarrow=False, font_color=\"green\")\nfig.add_annotation(x=\"2020-06-25\", y=350, text=\"Summer Break\", row=2, col=1, showarrow=False, font_color=\"green\")\nfig.add_annotation(x=\"2020-03-30\", y=480, row=2, col=1, showarrow=False, font_color=\"red\",\n                   text=\"Start of Lockdowns<br>in USA <br>from 2020-03-19 to 2020-04-07\")\nfig.add_annotation(x=\"2020-02-03\", y=1.35, text=\"Public Health Emergency <br>Declared in USA<br> dated 2020-02-03\", \n                   ax=80, ay=-55, row=1, col=1, arrowsize=2, arrowhead=2)\nfig.add_annotation(x=\"2020-07-16\", y=1.5, text=\"New Record of Daily Cases - 76,000<br>in USA dated 2020-07-16\", \n                   ax=40, ay=-40, row=1, col=1, arrowsize=2, arrowhead=2)\n\nfig.update_layout(font_family=\"Arial\", \n                  showlegend=False, margin=dict(l=0, r=0, t=50), height=800)\nfig.show()\ndel temp","1606339e":"temp = df_total.groupby([\"locale\",\"time\"])[[\"pct_access\",\"engagement_index\"]].mean().reset_index()\n\n# pct_access and engagement_index over time among different locale\nfor i in [\"pct_access\",\"engagement_index\"]:\n    fig = px.line(data_frame=temp, x=\"time\", y=i, color=\"locale\")\n    fig.update_layout(font_family=\"Arial\",title=dict(text=\"<b>\"+i+\" over time among Locale\", x=0.5, font_size=20),\n                      height=400, \n                     legend=dict(orientation=\"h\",yanchor=\"bottom\", y=0.95,xanchor=\"right\", x=1))\n    fig.update_xaxes(title=None)\n    fig.update_yaxes(title=None)\n    fig.show()\ndel temp","2c726329":"temp = df_total.groupby([\"pef_cat\",\"week\"])[[\"pct_access\",\"engagement_index\"]].mean().reset_index()\n\n# time plot for pct_access and engagement_index locale wise\ntime_plot(temp, \"pef_cat\",\"All\")","0a189fd2":"agg_digi_learn_df = df_total[df_total[\"Primary Essential Function\"] == 'LC - Digital Learning Platforms']\nagg_engagement_data = agg_digi_learn_df.groupby([\"state\", \"time\"],as_index=False)[\"engagement_index\"].sum().reset_index()\ndef set_size(value):\n    '''\n    Takes the numeric value of a parameter to visualize on a map (Plotly Geo-Scatter plot)\n    Returns a number to indicate the size of a bubble for a country which numeric attribute value \n    was supplied as an input\n    '''\n    result = np.log(1+value\/100)\n    if result < 0:\n        result = 0.001\n    return result\n\npipeline = pdp.PdPipeline([\n    pdp.ApplyByCols('engagement_index', set_size, 'size', drop=False),\n    pdp.MapColVals('state', us_state_abbrev)\n])\n\nagg_engagement_data = pipeline.apply(agg_engagement_data)\nagg_engagement_data = agg_engagement_data.sort_values(by='time', ascending=True)\n\n# Visualization:\nfig = px.scatter_geo(\n    agg_engagement_data, locations=\"state\", locationmode='USA-states',\n    scope=\"usa\",\n    color=\"engagement_index\", \n    size='size', hover_name=\"state\", \n    range_color= [0, 200000], \n    projection=\"albers usa\", animation_frame=\"time\", \n    title='Engagement Index: LC - Digital Learning Platforms', \n    color_continuous_scale=px.colors.sequential.Greys)\n\nfig.show()","8146fa7e":"temp = df_total.groupby([\"Product Name\",\"week\"])[[\"pct_access\",\"engagement_index\"]].mean().reset_index()\n\n# time plot for pct_access and engagement_index locale wise\ntime_plot(temp, \"Product Name\",\"All\")","2b2f3e3b":"temp = df_total.groupby([\"Sector(s)\",\"week\"])[[\"pct_access\",\"engagement_index\"]].mean().reset_index()\n\n# time plot for pct_access and engagement_index locale wise\ntime_plot(temp, \"Sector(s)\",\"All\")","ba1ef76e":"summary_df = df_total.groupby([\n    \"state\",\n    \"locale\",\n    \"pct_black\/hispanic\",\n    \"county_connections_ratio\",\n    \"pct_free\/reduced\",\n    \"time\"],\n    as_index=False)[\"engagement_index\"].sum().reset_index(drop=True)\nsummary_df = summary_df.sort_values(by='time', ascending=True)\nsummary_df.head()","5810bf8a":"fig = px.bar(summary_df,\n             y=\"state\",\n             x=\"engagement_index\",\n             animation_frame=\"time\",\n             orientation='h',\n             color=\"pct_free\/reduced\"\n)\nfig.update_layout(width=800,\n                  height=600,\n                  paper_bgcolor='rgba(0,0,0,0)',\n                  plot_bgcolor='rgba(0,0,0,0)',\n                  title_text='EI by Locale, Ethnicity of School Districs and Date',\n                  showlegend=True)\nfig.update_xaxes(title_text='Egagement Index (EI)')\nfig.show()","6515f848":"conec = pd.read_csv('..\/input\/elisabeth-2\/conec.csv')","9b128f9c":"conec.head()","c5288193":"conec = conec.drop(['Unnamed: 0'],axis=1)","b131da30":"\nconec.info()\n# replace all -9999 by NaN\nconec = conec.replace(-9999, np.nan)\n# we delete the columns we are not interested in\nconec.drop(['non_consumer','all'],axis=1,inplace=True)\n# we delete all NaN values\nconec = conec.dropna()\n# rename column statename by state\nconec = conec.rename(columns = {'statename':'state'})\n# I invoke the district dataset to see the states with connections [1,2[.\ndis[dis['county_connections_ratio'] == '[1, 2['] # North Dakota\na = dis['state'].unique()\na = pd.DataFrame(a, columns=['state'])\n# I remove North Dakota from the list because I want connections up to 1.\naa = a[a['state']!='North Dakota']\naa = aa.dropna()\nconec_ratio_unitario = conec[conec['ratio']<=1.0]\nconec_ratio_unitario = conec_ratio_unitario[conec_ratio_unitario['state']!='North Dakota']\n# Let's look at the results for all selected states.\nfor i in aa['state']:\n    print('_'*15)\n    print(i ,':')\n    print('_'*15)\n    print(conec_ratio_unitario[conec_ratio_unitario['state']==i]['ratio'].describe())\n    sns.boxplot(conec_ratio_unitario[conec_ratio_unitario['state']==i]['ratio'])\n    plt.show()\n    print(':'*50)","dd46ddf5":"print('North Dakota:' )\nprint(conec[(conec['state']=='North Dakota') & (conec['ratio']>1)])\nprint('-'*50)\nconec[(conec['state']=='North Dakota') & (conec['ratio']>1)]['ratio'].describe()\nprint('-'*50)\ndis[dis['state']=='North Dakota']","a9993c5b":"free = pd.read_csv('..\/input\/elisabeth-1\/pct_free.csv', header=None)","283da986":"free = free.drop([0,1],axis=0)\nfree = free.drop([3],axis=0)\nfree = free.drop([1,2,3,4,5,6],axis=1)\nfree.head()","ab5d9f50":"free.columns = ['Race','Total',\n                '0 to 25.0 percent',\n                '25.1 to 50.0 percent',\n                '50.1 to 75.0 percent',\n                'More than 75.0 percent','Missing']\nfree = free.drop([2,4],axis=0)\nfree = free.drop(['Total'],axis=1)\nfree = free.drop([12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29],axis=0)\nfree = free.drop([62,63,64,65,66],axis=0)\nfree = free.reset_index()\nfree = free.drop(['index'],axis=1)\nfree_total = free.loc[0:7]\nfree_city = free.loc[8:15]\nfree_suburn = free.loc[16:23]\nfree_town = free.loc[24:31]\nfree_rural = free.loc[32:37]","85c9626d":"free_total.head(6)","35c148ed":"# Total:\nfree_total.columns = ['Race', '[0,0.25[', '[0.25,0.5[', '[0.5,0.75[', '[0.75,1[','Missing']\nfree_total = free_total.drop(['Missing'],axis=1)\nfree_total= free_total.set_index(['Race'])\nfree_total = free_total.T\nfree_total.columns = ['Total','White','Black','Hispanic','Asian','Pacific Islander',\n                      'American Indian\/Alaska Native','Two or more races']\nfree_total = free_total.drop(['Asian','Pacific Islander','American Indian\/Alaska Native','Two or more races'],axis=1)\n#free_total.drop(['Race'],axis=0, inplace=True)\n\n# City:\nfree_city.columns = ['Race', '[0,0.25[', '[0.25,0.5[', '[0.5,0.75[', '[0.75,1[','Missing']\nfree_city = free_city.drop(['Missing'],axis=1)\nfree_city= free_city.set_index(['Race'])\nfree_city = free_city.T\nfree_city.columns = ['Total','White','Black','Hispanic','Asian','Pacific Islander',\n                      'American Indian\/Alaska Native','Two or more races']\nfree_city = free_city.drop(['Asian','Pacific Islander','American Indian\/Alaska Native','Two or more races'],axis=1)\n#free_city.drop(['Race'],axis=0, inplace=True)\n\n# Suburb:\nfree_suburn.columns = ['Race', '[0,0.25[', '[0.25,0.5[', '[0.5,0.75[', '[0.75,1[','Missing']\nfree_suburn = free_suburn.drop(['Missing'],axis=1)\nfree_suburn= free_suburn.set_index(['Race'])\nfree_suburn = free_suburn.T\nfree_suburn.columns = ['Total','White','Black','Hispanic','Asian','Pacific Islander',\n                      'American Indian\/Alaska Native','Two or more races']\nfree_suburn = free_suburn.drop(['Asian','Pacific Islander','American Indian\/Alaska Native','Two or more races'],axis=1)\n#free_suburn.drop(['Race'],axis=0, inplace=True)\n\n# Town:\nfree_town.columns = ['Race', '[0,0.25[', '[0.25,0.5[', '[0.5,0.75[', '[0.75,1[','Missing']\nfree_town = free_town.drop(['Missing'],axis=1)\nfree_town= free_town.set_index(['Race'])\nfree_town = free_town.T\nfree_town.columns = ['Total','White','Black','Hispanic','Asian','Pacific Islander',\n                      'American Indian\/Alaska Native','Two or more races']\nfree_town = free_town.drop(['Asian','Pacific Islander','American Indian\/Alaska Native','Two or more races'],axis=1)\n#free_town.drop(['Race'],axis=0, inplace=True)\n\n# Rural:\nfree_rural.columns = ['Race', '[0,0.25[', '[0.25,0.5[', '[0.5,0.75[', '[0.75,1[','Missing']\nfree_rural = free_rural.drop(['Missing'],axis=1)\nfree_rural= free_rural.set_index(['Race'])\nfree_rural = free_rural.T\nfree_rural.columns = ['Total','White','Black','Hispanic','Asian','Pacific Islander']\nfree_rural = free_rural.drop(['Asian','Pacific Islander'],axis=1)\n#free_rural.drop(['Race'],axis=0, inplace=True)","622cc87d":"free_total.head()","218b105a":"free_total = free_total.astype('float64')\nfree_city = free_city.astype('float64')\nfree_suburn = free_suburn.astype('float64')\nfree_town = free_town.astype('float64')\nfree_rural = free_rural.astype('float64')","2821fc4c":"#_____________________Generic information:\nplt.subplot(2,4,1)\nfree_total['Total'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14, 14),\n                             colors =(\"#0eed7a\",\"#b51610\",\"#0bbf63\",'#04592d'))\nplt.title('Pie chart Total')\n\nplt.subplot(2,4,2)\nfree_total['White'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14, 14),\n                             colors =(\"#daf0e9\",\"#b51610\",\"#5fedc0\",'#1fe0a3'))\nplt.title('Pie chart Total White')\n\nplt.subplot(2,4,3)\nfree_total['Black'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14, 14),\n                             colors =(\"#d1cdcd\",\"#a19d9d\",\"#a19d9d\",'#b51610'))\nplt.title('Pie chart Total Black')\n\nplt.subplot(2,4,4)\nfree_total['Hispanic'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14, 14),\n                             colors =(\"#fab216\",\"#c48c12\",'#4d3607',\"#b51610\",'#babd28'))\nplt.title('Pie chart Total Hispanic')\nplt.show()\n\n#__________________________City Information:\nplt.subplot(2,4,1)\nfree_city['Total'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14, 14),\n                             colors =(\"#0eed7a\",\"#0bbf63\",'#04592d',\"#b51610\"))\nplt.title('Pie chart Total City')\n\nplt.subplot(2,4,2)\nfree_city['White'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14, 14),\n                             colors =(\"#daf0e9\",\"#b51610\",\"#5fedc0\",'#1fe0a3','#babd28'))\nplt.title('Pie chart City White')\n\nplt.subplot(2,4,3)\nfree_city['Black'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14, 14),\n                             colors =(\"#d1cdcd\",\"#a19d9d\",\"#a19d9d\",'#b51610','#babd28'))\nplt.title('Pie chart City Black')\n\nplt.subplot(2,4,4)\nfree_city['Hispanic'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14, 14),\n                             colors =(\"#fab216\",\"#c48c12\",'#4d3607',\"#b51610\",'#babd28'))\nplt.title('Pie chart City Hispanic')\nplt.show()\n\n#____________________________________Suburb Information:\nplt.subplot(2,4,1) \nfree_suburn['Total'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#b51610\",\"#0eed7a\",\"#0bbf63\",'#04592d','#babd28'))\nplt.title('Pie chart Total Suburb')\n\nplt.subplot(2,4,2)\nfree_suburn['White'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#b51610\",\"#daf0e9\",\"#5fedc0\",'#1fe0a3','#babd28'))\nplt.title('Pie chart Suburb White')\n\nplt.subplot(2,4,3)\nfree_suburn['Black'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#d1cdcd\",\"#a19d9d\",'#b51610',\"#a19d9d\",'#babd28'))\nplt.title('Pie chart Suburb Black')\n\nplt.subplot(2,4,4)\nfree_suburn['Hispanic'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#fab216\",\"#c48c12\",'#4d3607',\"#b51610\",'#babd28'))\nplt.title('Pie chart Suburb Hispanic')\nplt.show()\n\n#_______________________________________Town Information:\nplt.subplot(2,4,1) \nfree_town['Total'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#0eed7a\",\"#0bbf63\",\"#b51610\",'#04592d','#babd28'))\nplt.title('Pie chart Total Town')\n\nplt.subplot(2,4,2)\nfree_town['White'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#daf0e9\",\"#b51610\",\"#5fedc0\",'#1fe0a3','#babd28'))\nplt.title('Pie chart Town White')\n\nplt.subplot(2,4,3)\nfree_town['Black'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#d1cdcd\",\"#a19d9d\",\"#a19d9d\",'#b51610','#babd28'))\nplt.title('Pie chart Town Black')\n\nplt.subplot(2,4,4)\nfree_town['Hispanic'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#fab216\",\"#c48c12\",\"#b51610\",'#4d3607','#babd28'))\nplt.title('Pie chart Town Hispanic')\nplt.show()\n\n#_________________________________________Rural Information:\nplt.subplot(2,4,1) \nfree_rural['Total'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#0eed7a\",\"#b51610\",\"#0bbf63\",'#04592d','#babd28'))\nplt.title('Pie chart Total Rural')\n\nplt.subplot(2,4,2)\nfree_rural['White'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#daf0e9\",\"#b51610\",\"#5fedc0\",'#1fe0a3','#babd28'))\nplt.title('Pie chart Rural White')\n\nplt.subplot(2,4,3)\nfree_rural['Black'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#d1cdcd\",\"#a19d9d\",\"#a19d9d\",'#b51610','#babd28'))\nplt.title('Pie chart Rural Black')\n\nplt.subplot(2,4,4)\nfree_rural['Hispanic'].plot(kind='pie',autopct='%1.1f%%',\n                             figsize=(14,14),\n                             colors =(\"#fab216\",\"#c48c12\",\"#b51610\",'#4d3607','#babd28'))\nplt.title('Pie chart Rural Hispanic')\nplt.show()\n","11a008ab":"- __2.6 Adobe Inc.:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nAdobe Inc. | 3 | PreK-12; Higher Ed; Corporate (100%) | 1 ","dc21e723":"* __2.1 Massachusetts:__\n    + Summary: \n    \nState | locale | pct_black\/hispanic | pp_free\/reduced \n:--------: | :-------: | :-------: | :-------: \nMassachusetts | Suburb | [0, 0.2[ | [0, 0.2[\nMassachusetts | Rural | [0, 0.2[ | [0.4, 0.6[\nMassachusetts | City | [0, 0.2[ | [0, 0.2[\nMassachusetts | Suburb | [0.2, 0.4[ | [0.2, 0.4[\nMassachusetts | Suburb | [0.4, 0.6[ | [0.4, 0.6[","257cf972":"* __2.7 Grammarly:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nGrammarly | 2 | PreK-12; Higher Ed; Corporate (100%) | 1  ","f663e401":"The variation of the two variables can be seen to follow the same pattern. The dominant main category is SDO. It is curious to see, in previous graphs, that students choose products within the LC category but instead there are more downloads from the SDO category. \n\nNow let's look at the main function that students have accessed `LC - Digital Learning Platforms","66e307d0":"__3. country_connections_ratio variables:__\n\nThis variable is very interesting. It represents the broadband connection for fixed residents in a territory divided by the number of households. If the indicator is greater than unity, it would mean that there are more connections than households, which would imply that a household can have two connections. This could very well be the case. However, the majority of states in the selected sample have a value lower than unity. This would imply that not all households have an internet connection. This categorical variable has two possible solutions: [0.18,1[ and [1,2[. I have seen that it is too generic, so searching through the websites recommended by the contest sponsors, I have found some tables for each state where the index can be deduced. This variable will be a great ally for our students to be able to participate in online learning and not be left behind. \n\nBefore proceeding, let's replace the missing NaN values with the predominant value, [0.18,1[. Then we will delete all rows where there are 5 variables that do not have any value. We have tried to find the district_id values in the tables given by the sponsors' websites, but it was not impossible to find out which district_id actually belongs to which locality. An interesting fact that we will see later is that I was able to find out the school in North Dakota. Do you want to see how? \nNow we'll focus on replacing the NaN values with [0.18,1[.","2b7beb81":"With all this in mind, we will change course and analyse all of the above but incorporate new variables:\n\n1. pct_access: % of students in the district have at least one page-load event of a given product and on a given day\n2. engagement_index: Total page-load events per 1000 students of a given product and on a given day\n3. time: el formato es (YY-MM-DD).\n\nFirst we will look at the variations of `pct_access and engagement_index` in the different states according to the `main category` they belong to:","afdd7fe9":"**In which state has the highest poverty rate?**\n\nResponse: DC","24cb0dc7":"We can observe that the vast majority of schools are located in suburbs. However, there are schools in states such as Arizona, California, Texas and Washington where they are mostly located in cities. One fact to note is that there is very little representation of schools located in Town. I leave it to the discretion of the sponsor. ","010c9dc9":"This graph gives an idea of the variation of the pct_free\/reduced variable over time for each state. Of all the temporal evolution, there is one fact to highlight: at the beginning of the spring 2020 academic year, each state had requested different pct_free\/reduced but some were waiting or the value was so small that it did not even appear in the graph. At the end of the course (e.g. 2020-11-09) we can see that all states have asked for their subsidies and in addition many are asking for a 100% reduction of their lunch quota. This means that poverty has increased over this period of time. ","e3824a9b":"* __2.1 IXL Learning__:\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nIXL Learning | 4 | PreK-12 (100%)| 1 ","c6be4b1c":"* __2.8 Technological Solutions, Inc. (TSI):__\n   \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nTSI | 2 | PreK-12 (100%) | 1 ","314e291a":"* __1.5 North Dakota:__\n    + Summary: \n    \nState | NERD: pp_total_raw (mean) dolars | pp_total_raw dolars\n:--------: | :-------: | :--------: \nNorth Dakota | 12255 | [12000, 14000[","7aaf1434":"Geographical map of the distribution of the states and the number of schools in it (with the sample given by the sponsors):","860ea7d8":"Are all variables without missing values?","ffffa3b4":"Author | Date \n:--------: | ------- \nMiquel, Elisabeth | 2021-09-30\n<h1 style=\"font-family:Arial; text-align:center; font-size:36pt\"><br>How has the Covid-19 pandemic impacted traditional schooling? <\/h1>\n\n\n## Abstract: \n<div style=\"text-align: justify\">This paper outlines the educational consequences of the policies adopted in response to the Covid-19 pandemic situation in the USA. We will develop different analyses based on race, reduction in food allowances, online connectivity, where students live, whether the state is Democratic or Republican, time periods (holidays and vacation and school holidays), and poverty rates in each state. \nWe have found some very nourishing findings for future study: \n- The sponsors have used a sample of 0.26% of US schools (2019-2020).\n- Economic poverty, race, location and internet connectivity are the four key factors in a child's determination to advance in school without the frustration created by the social divide. \n- Arizona and North Dakota are the states with the highest pct_acces and engagement_index. \n- In the fall semester of the 2020-2021 academic year, lunch reduction demands increased dramatically (68%) from the previous year. \n- Democratic states implemented an emergency plan to address the non-transmission of Covid-19 than Republican states (Arizona is the exception as it is a pro-online state). There are countries in Spain where this technique is widely used).<\/div>","a794917a":"## Introduction:\n<div style=\"text-align: justify\">The Covid-19 pandemic has negatively affected the lives of people on Earth. The economy, education, the welfare state, politics and the health care system have been altered and suffocated by the pandemic. \nThe first American case was reported on January 20, and President Donald Trump declared the U.S. outbreak a public health emergency on January 31. Restrictions were placed on flights arriving from China,but the initial U.S. response to the pandemic was otherwise slow, in terms of preparing the healthcare system, stopping other travel, and testing.Meanwhile, Trump remained optimistic and was accused by his critics of underestimating the severity of the virus.\nFrom that moment on, President Donald Trump instituted secular policies based on the ideology that democratic states would be the ones affected by the pandemic, because official reports announced that people of colour, indigenous and Hispanic people were the most affected by the pandemic, causing large outbreaks in Seattle and New York (NY). This campaign was fatal to the implementation of containment measures to stop the spread of the virus in the population. However, thanks to the tenth amendment to the US constitution, democratic states began to put in place health and public protection policies before the pandemic was officially declared by the OMS on 2020-03-11. In Washington, for example, schools and universities began to close on 29 February. This was followed by California and NY on 4 and 7 March respectively. This influences the population of each state differently, causing a contrast between states, and a unified chaos. The impact of Covid-19 has been analysed in healthcare, economics, politics, but what about the education of children? To stop the spread of Covid-19, one of the basic regulations was to close schools to stop contagion. Traditional (face-to-face) education was severely affected and a distance and\/or online system had to be quickly put in place to minimise the impact of the education and thus be able to continue their education. The system was not ready, and in many states, a network for online education was not in place. Applications were created and, thanks to various platforms, it was possible to continue the education of children. But at this point new questions arise:\nDo all households have broadband internet, do all households have devices to connect to the internet, does living in the city and in rural areas have an influence? All these questions are the consequence of one irrefutable fact: the social-economic gap will be further accentuated because traditional state-provided education will be directly dependent on the economy of each household. This will stifle the chances of passing courses and will stress family coexistence, especially for the most disadvantaged. Another part included in this reflection will be the aid that parents request from the states for the reduction of the school lunch. In order to answer all these questions we will use three sets of datasets provided by the sponsors of the contest and additional material researched by myself creating additional datasets to complete the information.<\/div>","eef66e90":"We see that there aren't values for District of Columbia. So we will average all the connections and include it in our dataframe. Now let's look at the case of the state: North Dakota.","89286b81":"**\u00bfWhich 10 technologies are the most widely used??**\n\nStudents who have been able to continue their studies online have used a multitude of products to further their studies and finish the school year. All of them have been provided by large multinationals such as Google, Microsoft, Amazon and smaller ones. But all of them have contributed effectively to helping students continue their education. To see the most used 'products', we will see below a graph representing a list of the top 20 most used products:","22d94872":"We will now treat the missing values of the repeating companies in the original dataset with the criteria mentioned above:","1670e485":"* __1.1 Connecticut:__\n    \n    \nState | NERD: pp_total_raw (mean) dolars | pp_total_raw dolars\n:--------: | :-------: | :--------: \nConnecticut | 17375 | [16000, 18000[","e02413f4":"* __3.7 Grammarly:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nGrammarly | 2 | LC - Study Tools      (100%)| 1","02bab061":"We now have the dataset products with no missing values. If we take a look at the description of the Primary essential function variable, we can see that it can be divided into `Categories` (pef_cat) and `Sub-Categories` (pef)","998b1986":"* __2.9 Code.org:__\n  \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nCode.org | 2 | PreK-12 (100%) | 1 ","51ee5ec4":"**Are there more correlations between variables that we have not yet tested?** As we can see from the correlation, there is a strong positive correlation between the two variables. This result is logical because of the definitions of the two variables. To finish this analysis, let's look at the average behaviour of the two variables during a standard week.**On weekends, will students continue studying as they do during the whole week, in order to reinforce the knowledge acquired?**","30aa231d":"The answer to the question is no. Students do not spend as much time at the weekend downloading materials to study. In both variables the proportion of the variables drops by 2\/3. We should also note that the two variables follow a very similar behaviour during the week. \n\nNow we are going to look at the `temporal dependence` with the different variables, to see their evolution throughout the year 2020. These variables are:\n\n**1. State**","0f842745":"* __Treatment for missing values:__\n\nIn order to simplify the information in the simplest and most convenient way we have made these tables, which have information about the Company, the most used product, the number of times it appears in the dataset and the number of missing values. The aim of doing it this way is to waste the least amount of information without changing the overall statistics of each dataset. \n\n__1. Provider\/Company Name variable:__\n\nIn order to deal with the missing values of this variable, we first look at which row the NaN value for the variable Company Name is located. We see that it is the company `True North Logic`. It only appears once in the dataset, so we decide to remove it.","db2626e3":"* __2.10 EDpuzzle Inc.:__\n  \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nEDpuzzle Inc. | 2 | PreK-12 (100%) | 1 ","1e02fb4e":"This graph confirms what was said in **graph number**. without the presence of time. That is, Google Docs and Google Classroom are the two most used products by students in all US states.\n\n**1.3 Sector(s):**","ca36ff2c":"* __3.1 IXL Learning:__\n  \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nIXL Learning | 4 | LC - Digital Learning Platforms (100%) | 1 ","bb87ba61":"**Is the distribution of the location of the states homogeneous?**\n\nResponse: Midwest","88097f54":"Previously, we have seen that we have been able to replace the NaN values of the pp_total_raw variable by ranges of values. This is not random. This is thanks to an elaborate study of the tables provided by the contest sponsors' websites. Then, I have created a new dataframe with the following variables involved: \n\nVariable | Description\n:--------: | :-------: \nstate | State name\npp_total_raw_nerd | The average value of pp_total_raw given by NERD website.\npover | The poverty rate according to the 2018-2019 tables. Poverty is defined as a family of two adults and two children with an annual income of less than 24500 dollars. \nerror_poverty | The standard variation of the poverty variable. \n#schools | The actual number of schools in each state.\nCardinal_points | Where each state is located according to the map of the United States. The options are: NorthEast, MidWest, South, West.\ntype_state | Indicates the political party governing that state in 2019-2020. There are two types: Republicans and Democrats. ","075580c2":"__4. Summary after tractement values:__","ae7361bf":"## Data Preparation:\n<div style=\"text-align: justify\">To analyse the analysis of the change in the learning situation of our students, we have three main datasets: products.csv, district.csv and engagement dataset. Let's look at them all step by step. Let's get started!","2074b607":"These graphs represent by race and locale, the percentage of students requesting the various ranges of discounts on their lunch allowance. They are represented from top to bottom as: generic information provided by Edu Lab 2019-2020, information according to different locale. And from left to right, the race of the student. \n\n<div style=\"text-align: justify\"> Overall, 28.8% of students ask for a reduction of [0.25,0.5[. 37.8% of white students ask for a reduction of [0.25,0.5[, while black and Hispanic students behave similarly. That is, an average of 44.35% ask for a reduction of [0.75,1[. This means that there is a clear economic gap between the races of the students and their annual income. \nOf the 4 localities, City has the highest poverty with 41.4% asking for a reduction of [0.75,1[. If we look at the reasons for this result, it falls on non-white students. New York City, for example, has a high proportion of people of colour. \nIt is noteworthy that white students show a uniformity in lunch fee reductions, ranging from [0.0.25[ (Suburb) to [0.25.5[ (City, Town and Rural). <\/div>","521a9835":"* __1.7 New York:__\n    + Summary: \n    \nState | NERD: pp_total_raw (mean) dolars | pp_total_raw dolars\n:--------: | :-------: | :--------: \nNew York | 22063 | [12000, 14000[","9eaaea40":"* __Treatment for missing values:__\n\nWe see that there are many missing values in three of the five columns. One way to lose the least amount of information is to delete the rows that have 3 of the 5 variables equal to NaN. \n","d5d23698":"According to this graph, it can be seen that the first 4 positions are located within the LC category. The first primary essential function is `LC - Digital Learning Platforms` followed by `Sites, Resources and Reference`. This makes sense as online platforms for study became the main tool for students to continue their studies. In the first 10 positions all primary essential functions are within the 'LC' category. It can be deduced that the category Learning & Curriculum will be the most used by our students. It would be interesting if this category was divided into Learning and Curriculum separately, because due to the pandemic, companies that used to host interns stopped providing this service, so there was not a lot of job or internship searching during that period of time. \n\nThe following graph shows the representation of the different categories:","659101e0":"* __2.4 Tennesse:__\n    + Summary:  \n    \nState | locale | pct_black\/hispanic | pp_free\/reduced \n:--------: | :-------: | :-------: | :-------: \nTennesse | Suburb | [0, 0.2[ | [0, 0.2[\nTennesse | Rural | [0.2, 0.4[ |[0.8, 1[","ce0290b8":"It can be seen that 54.5% of the sample are democratic states. However, the sample is evenly distributed in this respect. Another aspect to take into account is the distribution of states according to cardinal points. Is there homogeneity? It is clear that 36.4% of the chosen states are located in the Midwest. Therefore, the conclusions for this sample are 3:\n1. the sample is not homogeneous in number of schools:\n2. the sample is not homogeneous with respect to its distribution of the cardinal points of the USA.\n3. the sample is homogeneous in the type of governor.\n\nOnce we have a complete map of the overall choice of our sample, we will analyse the essential products, sectors and functionalities used for children to follow their learning online. It is essential to go into this area with the idea that international companies such as Google and Microsoft and services such as Zoom are likely to be at the top of the list. We will see below, if our hypothesis is true:","f8cf1857":"__2. pct_free\/reduced & pct_b\u00f1ack\/hispanic variables:__\n\nAt first glance, by definition of the variables, it would appear that there is a relationship between them. We do not yet know what it might be. Let us first see, in a generic way, the proportions of each variable depending on the locale where they are located. ","60b547d9":"### Annex II: pct_free\/reduced\n\nHere we will see where the data is taken from to derive the table poverty2.\n\nAnother source of data to check if my results regarding the pct_free\/reduced variable were correct is through this table given in LAB. After a series of transformations we can see in red where there is more need to ask for lunch cost reduction and which race is the most disadvantaged.","a134bd7c":"* __2.4 ClassDojo, Inc.__:\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nClassDojo, Inc. | 2 | PreK-12 (100%) | 1  ","ec42f7cc":"* __Treatment for missing values:__\n\n__1. pp_total_raw variable:__\n\nNext, we will fill in the missing values of the pp_total_raw variable. To do this, we have had to go to the NERD$ website, which you have to register to obtain the economic information for each state. Because the information for the state of New Hampshire is not current, we have decided to remove this state. We have made our own dataset with the average pp_total_raw data for each state, the number of schools and the poverty rate.  ","e5d29b03":"* __Variables description:__\n\nVariable | Description | Missing value | Dtype\n:--------: | :-------: | :--------: | -------\nLP ID | The unique identifier of the product. | 0 | int64\nURL | Web Link to the specific product. | 0 | object\nProduct Name | Name of the specific product. | 0 | object\nProvider\/Company Name | Name of the product provider. | 1 | object\nSector(s) | Sector of education where the product is used. | 20 | object\nPrimary Essential Function | The basic function of the product. There are two layers of labels here. Products are first labeled as one of these three categories: LC = Learning & Curriculum, CM = Classroom Management, and SDO = School & District Operations. Each of these categories have multiple sub-categories with which the products were labeled. | 20 | object","8642c37c":"* __2.5 Google LLC:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nGoogle LLC | 30 | PreK-12; Higher Ed; Corporate (85.19%)  PreK-12; Higher Ed (7.41%) PreK-12 (7.41%) | 3  ","64ecad7b":"The initial hypothesis is confirmed. Google is the company most used by our students, followed by Microsoft. **Is there a difference between Republicans and Democrats?** As can be seen, there is a curious peculiarity: Democrats use online companies more than Republicans. However, this conclusion can be reduced by the fact that in the chosen sample there are more Democrats than Republicans. \nThese companies provided different products for different uses, called sectors. Sector of education where the product is used. These uses are three:\n1. PreK-12\n2. Higher Ed\n3. Corporate\n\nOr a combination of all of them. This means that a company can provide a product that serves all 3 sectors of education. An example is 'Amazon.com, Inc.` An interesting question would be: in which sector of education have companies put more effort: prek-12, higher Ed or Corporate?","1f8cc964":"__3. Primary essential function:__\n\nTo deal with missing values of the Primary essential function variable we will use the same reasoning as in the previous section. That is, we will rely on the following two questions and an action:\n- What is the proportion of the dominant value?\n- How many times does it appear in the dataset?\n- Replace the dominant value in the corresponding NaN for each Primary essential function.\n\nSummary: \nThere are 13 missing values in Primary essential function. ","97002f73":"* __2.3 Arizona:__\n    + Summary:  \n    \nState | locale |  pp_free\/reduced \n:--------: | :-------: | :-------:\nArizona | City | [0.8, 1[\n\n(Remember that Arizona only has one school).","262d4afb":"With these two interactive graphs we see the proportions of each main category with respect to its sectors and each sub-category with respect to its main category.","7beb161f":"Below are two graphs providing a visual 'summary' of what has been explained so far.","794928c5":"At this point, we are going to join the two dataframes.","33282562":"One way to deal with missing values is by those where Companies are repeated and those that only appear once in the original dataset. Those that only appear once in the original dataset will be removed because there is no way to find the Sector. For example: `Microsoft` appears 6 times, of which two of them have missing values in the Sector variable. What is done is to look at which Sector of the products offered by `Microsoft` is the predominant one and replace the missing values by the predominant value. In this way we do not affect the statistics. \nThe companies that only appear once in the entire original dataset are:\n`Yelp, Inc, Lea(R)n, Genius Media Group, U.S. News & World Report, L.P., CBS Interactive, Safe YouTube`.","743c7dad":"## Additional References:\n\n[1] https:\/\/www.ncbi.nlm.nih.gov\/pmc\/articles\/PMC7587838\/\n\n[2] https:\/\/nces.ed.gov\/programs\/edge\/Geographic\/LocaleBoundaries#:~:text=A%20locale%20classification%20is%20a,or%20proximity%20to%20populated%20areas.\n\nhttps:\/\/www.cdc.gov\/mmwr\/volumes\/69\/wr\/mm6945a3.htm#_blank\n\nhttps:\/\/www.paradisosolutions.com\/blog\/impact-covid-19-education-untape-potential-e-learning\/\n\nhttps:\/\/nces.ed.gov\/programs\/digest\/2018menu_tables.asp","da70eb09":"In order to relate the different variables of each dataset we have to link the different datasets so that it is easier to manipulate them. Recall that so far we have the following datasets available:\n- products.csv\n- districts.csv\n- engagement.csv\n- poverty2.csv\n","8f37149a":"This graph confirms the three distinctive behaviours that we explain throughout the document. The period of less activity is the summer months because students do not study and the confinement was lifted so there was more life in the streets and trips and night outings were promoted for teenagers and outings to parks and gardens that were closed for children. ","0f24055d":"In this graph you can see that Connecticut has 30 schools followed by 29 in Utah. The criteria for the selection of schools I leave to the sponsor. In my personal opinion, it would have been better to have a more uniform sample to make the results more comparative. But this would be a future exploration. I leave the link to the total number of schools for this future research [1].\nThe states can be classified in different ways: by location, by % presence of people of colour, by % of students requesting a reduction in their lunch allowance.\nA locale classification is a general geographic indicator that describes the type of area where a school is located. NCES classifies[2] all territory in the U.S. into four types - Rural, Town, Suburban, and City.\n[2] \n\nContinuing the thread of the document, states can be classified according to their rulers: Republican (R) or Democrat (D).\n\n","78290229":"In the following, the location of the chosen schools and the number of schools in each state of the above-mentioned sample will be shown.","81670e80":"We see the different combinations of the three education sectors. We can see that most of the companies base their products on Prek-12 (40.7%) and on the combination of the three sectors (40.6%). This means that companies have not distinguished, in general terms, which sector provides the most products. \nIf we recapitulate, we know that:\n1. the company that stands out above the others in offering its products for the online student is `Google` followed by `Microsoft`. \n2. the companies provide their services without much distinction to the three sectors of education.\n\nThe basic functions of each product will be discussed below. There are two layers of labels here. Products are first labeled as one of these three categories:\n1. LC = Learning & Curriculum\n2. CM = Classroom Management \n3. SDO = School & District Operations\n\nEach of these categories have multiple sub-categories with which the products were labelled. In the following we will first analyse the combination of categories and sub-categories and then look at each one separately. \nCategories:","e658c86f":"29.6% of students use products from the sub-category: `Sites, Resources & Reference`. This is followed by 21.1% for `Digital Learning Platform`. This means that the products that students use are mostly for studying and for this they use digital platforms with free software or cloud technology so that, regardless of the memory and hardware they use, they can store and search for their references with the greatest convenience. It is interesting to note that only 2.08% used `Virtual Classroom`. This would indicate that only 2.08% had the option of streaming classes between teacher and student, implying that the continuity of classes simulating face-to-face mode (i.e., that every day they could give the subject as in traditional schools) followed a more complete and dynamic curriculum than the rest of the students.  This implies a lack of daily monitoring by teachers, implying an inequality in the content taught. Next, we could look at the different products that comprise the `Virtual Classroom`. The ones that stand out are `Meet` and `Zoom`. In order to visualise this graph I had to average the variable `pct_access`, which means % of students in the district have at least one page-load event of a given product and on a given day. We got a bit ahead of ourselves, as I first wanted to take a snapshot of each of the variables involved and then we would see how they evolved over time. In order to be able to visualise it better, the weekend periods have been eliminated as there are no virtual classes in streaming. However, it is interesting to see that at the beginning the average pct_acces of Meet did not reach 11%. What does this mean? 11 % of students in the district have at least one page-load event of Zoom or Meet. In the months of July, August there is practically no activity until the school year 2020-2021 autumn semester starts. It can be seen that, due to the abundant outbreaks in the different states due to international and domestic travel, it was again decreed to close the classrooms of all schools, in order to avoid contagion. The schools were more prepared to offer their curriculum online and the homes had been able to prepare a little more to obtain a device so that the student could continue their studies. That is why the pct_access increases to 18% during the autumn semester. ","7b154f6f":"With all this general information, let's analyse which states have pct_free\/reduced as missing values.","dba5ff7f":"### Join all datasets:\n\n","5cbdc465":"## Conclusions:\n\n<div style=\"text-align: justify\"> With all this analysis we have uncovered different points relevant for this study and future analyses.\nDifferent analyses have been done to complete the datasets in the most optimal way. We have searched for information from the links provided by the sponsors of the competition. There are different aspects to take into account. At the beginning of the pandemic, when Donald Trump was still laughing about the situation, there was a considerable increase in the number of cases all over the USA. Cities where there is an index of indigenous, black and Hispanic population were more prone to the disease than the white race. This is a purely economic factor. Non-whites have lower incomes, as their jobs are cheap labour. This means that there will be more fat and carbohydrates than quality protein in their shopping baskets. This virus affects the immune system and the immune system in turn relies on the vitamins and minerals the body has to build up its defences. That is why the virus initially affected more democratic states. This fact led the rulers of these states to apply very restrictive laws and regulations, including school closures. At this time, children could not attend classes in person and this affected their school performance. People of colour and Hispanics were again affected because classes were now held online. This meant that the internet and electronic devices were available for teaching. The lower classes were severely affected. In North America, schools provide 'free\/reduced' food for children to eat. This meant that in the absence of this support, vulnerable family members were increasingly separated from the state of comfort. Thus, race, connectivity, parental income and the availability of electronic devices marked a large social divide that led to frustration and suffocation for many families. Different states, seeing this situation, proposed an 'easier' system for those children with problems in accessing school materials. This made the situation a little easier but it is still too early to see to what extent this little push is effective for the education of our students. ","ce9f998d":"* __3.5 Google LLC:__\n   \nProportions | # times in dataset | # Missing value\n :--------: | :--------: | :--------: \nLC\/CM\/SDO - Other                                                            (22.22%) | 30 |  3\nLC - Content Creation & Curation                                             (18.52%)\nLC - Sites, Resources & Reference                                            (11.11%)\nCM - Virtual Classroom - Video Conferencing & Screen Sharing                  (7.41)\nCM - Classroom Engagement & Instruction - Communication & Messaging           (7.41%)\nLC - Sites, Resources & Reference - Digital Collection & Repository           (7.41%)\nCM - Classroom Engagement & Instruction - Assessment & Classroom Response     (3.70%)\nSDO - Data, Analytics & Reporting - Site Hosting & Data Warehousing           (3.70%)\nLC - Study Tools                                                              (3.70%)\nLC - Sites, Resources & Reference - Streaming Services                        (3.70%)\nSDO - Learning Management Systems (LMS)                                       (3.70%)\nLC - Sites, Resources & Reference - Encyclopedia                              (3.70%)\nCM - Classroom Engagement & Instruction - Classroom Management                (3.70%) ","d3e71582":"### A. Products:\n<div style=\"text-align: justify\"> The product file products_info.csv includes information about the characteristics of the top 372 products with most users in 2020. Here is the basic information:","46ed40f3":"## Anexos:\n\n### Annex I:\n\nHere we will see where the data is taken from to derive the table conec_2.\n","037e2e11":"In the upper map we can see the average pct_access depending on the state and in the lower map, it represents the average engagement_index.\nRegarding the average pct_access:\n- North Dakota (3.77) and Arizona (2.85) have the highest mean pct_access and the lowest value is in North Carolina (0.49).\nRegarding the average engagement_index:\n- Arizona (858.62) and North Dakota (503.88) have the highest mean engagement_index and the lowest value is in Tennessee (117.33).\n\n**Could there be a correlation between the two variables?**","010da07c":"**2. Locale:**","ee30b9ad":"* __3.3 Houghton Mifflin Harcourt:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nHoughton Mifflin Harcourt | 6 | LC - Courseware & Textbooks (60%) \/\/ LC - Study Tools (20%) \/\/ LC - Digital Learning Platforms (20%)| 1 ","f4729920":"* __1.4 Arizona:__\n    + Summary: \n    \nState | NERD: pp_total_raw (mean) dolars | pp_total_raw dolars\n:--------: | :-------: | :--------: \nArizona | 8658 | [8000, 10000[","83d49b28":"* __3.2 Microsoft:__\n   \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nMicrosoft | 6 | LC\/CM\/SDO - Other (50%) \/\/ LC - Sites, Resources & Reference - Games & Simulations (25%) \/\/ LC - Content Creation & Curation (25%)| 2 ","2e7f8e22":"If I compare the data given by the sponsor with the data obtained from the website, we see that the sample school is one of these two possibilities.","53314ada":"* __1.6 New Hampshire:__\n\nDrop it!!","e19a7642":"### C. Engagement:\n\nThe extension collects page load events of over 10K education technology products in our product library, including websites, apps, web apps, software programs, extensions, ebooks, hardwares, and services used in educational institutions. The engagement data have been aggregated at school district level, and each file represents data from one school district.\n\nVariable | Description | Missing value | Dtype\n:--------: | ------- | :--------: | -------\ntime | date in \"YYYY-MM-DD\" | 0 | object\nlp_id | The unique identifier of the product. | 541 | float64\npct_access | Percentage of students in the district have at least one page-load event of a given product and on a given day. | 13447 | float\nengagement_index | Total page-load events per one thousand students of a given product and on a given day | 5378409 | float\ndistrict_id | I've include this variable | 0 | object","9cc4bc3e":"\n\nThis graph confirms what was said without the presence of time. That is, Prek-12; Higher Ed; Corporate is the predominant sector that students have accessed during the pandemic year.\n\n**Final conclusions:** \n1. The variables pct_access and engagement_index have a positive correlation of 0.78.\n2. Arizona is a Republican state that stands out for its high pct_access and engagement_index.\n3. Arizona is a state where online study was already practised in addition to traditional study, so Donald Trump's policies did not influence the education sector.\n4. New York is a democratic state where restrictive policies were implemented to try to tackle the pandemic on 7 March 2020. In the graph it can be seen that in the first months, the two variables have a very small value, but from the beginning of March onwards it shoots up to become the leader of the list.\n5. The three periods described throughout the document are confirmed. National and local holidays should also be taken into account to see the variability of the variables. \n\nOnce we have all this in mind, we will see how the different categorical variables of the dataframe `district` react over time. To do this, we will group all these variables together to improve the performance of the programme:\n\"state\",\n\"locale\",\n\"pct_black\/hispanic\",\n\"county_connections_ratio\",\n\"pct_free\/reduced\",\n\"time\"","138cecca":"* __3.6 Adobe Inc.:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nAdobe Inc | 3 | LC - Content Creation & Curation    (100%)| 1","77b2d0c6":"* __3.4 ClassDojo, Inc.:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nClassDojo, Inc. | 2 | CM - Classroom Engagement & Instruction - Communication & Messaging (100%) | 1 ","bfc96226":"If we look at the graph, we can see that Arizona is the one with the highest value in the pct_access and engagement_index variables. Therefore, it is logical to think that it is the one that will maintain the highest value over the weeks. We can see that there are three common behaviours in all the states shown:\n- The first behaviour is from week 0-23: spring semester academic year 2019-2020.\n- The second behaviour is from week 23-30: summer holidays.\n- The third behaviour is from week 30-52: autumn semester academic year 2020-2021.\nDuring the holidays, it is normal that internet access for study purposes decreases. \nIt is also necessary to take into account different state and local holidays. In Arizona, for example, in week 12-13 there is a significant drop in the variables. The same happens in week 41-42. \nAnother fact to note is that in the state of New York, students started to connect later than students in Arizona, but from week 12 onwards, the variables maintained the same behaviour. \nIf we look at the type of states in the two graphs, we see that: \n- Republicans: Arizona, Indiana, Massachusetts and Ohio.\n- Democrats: Illinois, Wisconsin, Connecticut, New York, New Jersey and D.Columbia.\nThus 40% of the top 10 are Republicans and 60% are Democrats. \nIt is interesting to see these variations because, although Donald Trump applied secular policies to deal with the Covid-19 pandemic, one might think that Arizona's policies were ahead of the possible effects on the education sector. But if we are to be honest, this state was already accustomed to using the internet for study as the first weeks of 2020 stand out from the other states. \nWhere we see a more appropriate behaviour to the events produced by the pandemic is New York. New York is a democratic state that declared tough statewide policies under the tenth amendment of the constitution by closing schools and public places since March 7th. \n\nFirst we will see how the variables evolve over time and then we will add the variables described below:","5c7fb263":"Our hypothesis is confirmed: these two graphs show that the `LC` category is the most used (79.6%). Now it is interesting to look at the sub-categories and their distributions.","4b1b9959":"* __3.9 Code.org:__\n   \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nCode.org | 2 | LC - Digital Learning Platforms      (100%)| 1","7799bd20":"* __1.3 California:__\n    + Summary: \n    \nState | NERD: pp_total_raw (mean) dolars | pp_total_raw dolars\n:--------: | :-------: | :--------: \nCalifornia | 12460 | [12000, 14000[","072ae4ca":"* __1.2 Ohio:__\n    + Summary: \n    \nState | NERD: pp_total_raw (mean) dolars | pp_total_raw dolars\n:--------: | :-------: | :--------: \nOhio | 9015 | [8000, 10000[","5bcf05a2":"* __2.3 Houghton Mifflin Harcourt:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nHoughton Mifflin Harcourt | 6 | PreK-12 (60%) PreK-12; Higher Ed (40%)| 1  ","26e1fa05":"   __2. Sector(s) variable:__\n    \nThe variable Sector(s) is made up of 5 sub-categories: 'PreK-12', 'PreK-12; Higher Ed', 'PreK-12; Higher Ed; Corporate', 'Corporate', 'Higher Ed; Corporate', nan. We can see that the value NaN appears as well. Let's see which Companies have missing values in their Sector. The Sector values of 19 Products with their respective Companies are missing. Products are unique but Companies can be repeated, as a Company can offer different products to its customers. An example is the Company `Google LLC` which is repeated 3 times.","08f0e34e":"* __3.8 Technological Solutions, Inc. (TSI):__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nTSI | 2 | LC - Sites, Resources & Reference - Games & Simulations      (100%)| 1","f9e50385":"Google Docs, Google Drive and Google Classroom stand out from the others. These are products offered by the company 'Google'. Most students have relied on Google products to enable them to continue their online education without being interrupted. Also in the top 10 are Khan Academy, which was kind enough to offer the platform for free school courses, and Wikipedia. It is also amusing to see that our students have taken advantage of this confinement to catch up on films and series (Netflix). This fact is an index of lifestyle modification during the confinement. Netflix provided a section where you could watch a movie with your friends at the same time (as if you were at the cinema or had a date with them) to foster a group feeling. \n\nNext, we will look at which companies are prominent in their product offerings. Surely `Google` is in the first positions seeing the success of the use of their products by our students.","5a561933":"### B.District:\n\nThe district file districts_info.csv includes information about the characteristics of school districts, including data from NCES (2018-19), FCC (Dec 2018), and Edunomics Lab. In this data set, we removed the identifiable information about the school districts.\nIt has 233 rows and 7 columns. \nWe will now proceed similarly to the treatment given to the products.csv dataset.  \n\nVariable | Description | Missing value | Dtype\n:--------: | ------- | :--------: | -------\ndistrict_id | The unique identifier of the school district. | 0 | int64\nstate | The state where the district resides in. | 57 | object\nlocale | NCES locale classification that categorizes U.S. territory into four types of areas: City, Suburban, Town, and Rural. See Locale Boundaries User's Manual for more information.. | 57 | object\npct_black\/hispanic | Percentage of students in the districts identified as Black or Hispanic based on 2018-19 NCES data. | 85 | object\npct_free\/reduced | Percentage of students in the districts eligible for free or reduced-price lunch based on 2018-19 NCES data. | 71 | object\ncounty_connections_ratio | ratio (residential fixed high-speed connections over 200 kbps in at least one direction\/households) based on the county level data from FCC From 477 (December 2018 version). See FCC data for more information. | 71 | object\npp_total_ raw | Per-pupil total expenditure (sum of local and federal expenditure) from Edunomics Lab's National Education Resource Database on Schools (NERD$) project. The expenditure data are school-by-school, and we use the median value to represent the expenditure of a given school district. | 115 | object","715ad2bc":"* __3.10 EDpuzzle Inc.:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nEDpuzzle Inc. | 2 | LC - Digital Learning Platforms      (100%)| 1","59e741f7":"Now let's build a dataFrame which will represent the values of broadband connection per household in each state. I only consider the permanent residents in each state. (This new dataframe is taken from the analysis for _Annex I._) The table has the following variables: \n\nVariable | Description\n:--------: | :-------: \nState | State name\n25% | The 0.25 quartile of people using broadband in each state\n50% | The 0.50 quartile of people using broadband in each state\n75% | The 0.75 quartile of people using broadband in each state\nrange | The range that is compressed the value 50%.\n\nInterestingly, seeing that the contest sponsors have determined that all states except North Dakota have a ratio between [0.18,1[, we have eliminated all connections greater than unity. \nAnother point to note is that we are going to choose the variable 50% as the numerical value of connectivity\/households in each state.","1e0b30bb":"* __2.2 Ohio:__\n    + Summary:  \n    \nState | locale | pct_black\/hispanic | pp_free\/reduced \n:--------: | :-------: | :-------: | :-------: \nOhio | City | [0.4, 0.6[ | [0.4, 0.6[","84eb8e08":"In this graph it can be seen that cities are where there is a higher value of the variables. This result is due to different reasons:\n- Cities have more broadband internet connection so there is more downloading of documents.\n- Cities are more used to having a device to connect to the internet due to modern life.\nHowever, this result contrasts with the fact that cities have the highest poverty rates.\n\n**3. Category:**","51f823b8":"## Exploratory analysis:\n\nIn this document, the sponsors of the competition have chosen 174 schools out of the 64784 schools. In other words, the sample to be studied is 0.27%. It should also be noted that not all states are represented. A total of 23 states have been selected. In the following, different characteristics of the selected schools and states will be shown:\n","1c5483b7":"* __2.2 Microsoft:__\n    \nCompany | # times in dataset | Proportions | # Missing value\n:--------: | :--------: | :--------: | :--------:\nMicrosoft | 6 | PreK-12; Higher Ed; Corporate (75%) PreK-12; Higher Ed (25%)| 2   "}}