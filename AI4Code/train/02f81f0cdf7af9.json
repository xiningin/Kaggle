{"cell_type":{"e4b06e7d":"code","cf720bac":"code","4c5c6d04":"code","55a13a31":"code","e544c965":"code","4342644c":"code","64089cce":"code","15a9eb7b":"markdown","44d89957":"markdown","9d126f18":"markdown","a8498e7a":"markdown","dddcf693":"markdown","f3a28efc":"markdown","427d9f4d":"markdown"},"source":{"e4b06e7d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cf720bac":"# Import helpful libraries\nimport pandas as pd\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OrdinalEncoder\n\n#Importing CSV files\nX_train_full=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/train.csv\")\nX_test_full=pd.read_csv(\"\/kaggle\/input\/home-data-for-ml-course\/test.csv\")\n\n#Check if there are any rows with missing target values, and if so, delete them\nmissing_val_count_by_column = (X_train_full.isnull().sum())\nprint(missing_val_count_by_column[missing_val_count_by_column > 0])\n#X_train_full.dropna(axis=0, subset=['SalePrice'], inplace=True)\n\n#Create y_train,X_train_full\ny_train=X_train_full.SalePrice\nX_train_full.drop(['SalePrice'], axis=1, inplace=True)","4c5c6d04":"#Separate numeric data columns from categorical data columns\nX_train_full_num = X_train_full.select_dtypes(exclude=['object'])\n#X_full_num.shape\nX_train_full_cat = X_train_full.select_dtypes(include=['object'])\n#X_train_full_cat.shape\n#pd.set_option('display.max_columns', 50)\n#X_train_full_cat.head()\nX_test_full_num = X_test_full.select_dtypes(exclude=['object'])\nX_test_full_cat = X_test_full.select_dtypes(include=['object'])\n#print(X_test_full_cat.shape)\n\n","55a13a31":"#Using SimpleImputer for missing values in numeric data\n#missing_val_count_by_column = (X_test_full_num.isnull().sum())\n#print(missing_val_count_by_column[missing_val_count_by_column > 0])\nmy_imputer = SimpleImputer()\nX_train_full_num_imputed = pd.DataFrame(my_imputer.fit_transform(X_train_full_num))\nX_train_full_num_imputed.columns=X_train_full_num.columns\nX_test_full_num_imputed = pd.DataFrame(my_imputer.transform(X_test_full_num))\nX_test_full_num_imputed.columns=X_test_full_num.columns\n#missing_val_count_by_column = (X_test_full_num_imputed.isnull().sum())\n#print(missing_val_count_by_column[missing_val_count_by_column > 0])\n#pd.set_option('display.max_columns', 40)\n#X_train_full_num_imputed.head()\n","e544c965":"#Remove columns with missing values in the category data\ncols_with_missing1 = [col for col in X_train_full_cat.columns if X_train_full_cat[col].isnull().any()] \ncols_with_missing2 = [col for col in X_test_full_cat.columns if X_test_full_cat[col].isnull().any()] \nbad_cat_list=list(set(cols_with_missing1)|set(cols_with_missing2))\nall_cat_list = [col for col in X_train_full_cat.columns]\nnomissing_cat_list=list(set(all_cat_list)-set(bad_cat_list))\nX_train_full_cat_nomissing=X_train_full_cat[nomissing_cat_list]\nX_test_full_cat_nomissing=X_test_full_cat[nomissing_cat_list]\n\n#Ordinal encoding to category data\n#1.Check the number of items in the category data.\nall_cat_list = [col for col in X_train_full_cat_nomissing.columns]\ngood_label_cols = [col for col in X_train_full_cat_nomissing.columns if set(X_test_full_cat_nomissing[col]).issubset(set(X_train_full_cat_nomissing[col]))]\n#print(len(all_cat_list))\n#print(len(good_label_cols))#<-ok\n#If not, use the following code\n#bad_label_cols = list(set(all_cat_list)-set(good_label_cols))\n#X_train_full_cat_nomissing_oknumofitems = X_train_full_cat_nomissing.drop(bad_label_cols, axis=1)\n#X_test_full_cat_nomissing_oknumofitems = X_test_full_cat_nomissing.drop(bad_label_cols, axis=1)\n#2.Ordinal encoding\nordinal_encoder=OrdinalEncoder()\nX_train_full_cat_nomissing[nomissing_cat_list]=ordinal_encoder.fit_transform(X_train_full_cat[nomissing_cat_list])\nX_test_full_cat_nomissing[nomissing_cat_list]=ordinal_encoder.transform(X_test_full_cat[nomissing_cat_list])\n#X_test_full_cat_nomissing.head()\n\n#Here's a warning, but I couldn't figure out how to fix it.","4342644c":"#data merge\nX_train_full_final=pd.concat([X_train_full_num_imputed,X_train_full_cat_nomissing],axis=1)\nX_test_full_final=pd.concat([X_test_full_num_imputed,X_test_full_cat_nomissing],axis=1)\n#pd.set_option('display.max_columns', 60)\n#X_test_full_final.shape\n#missing_val_count_by_column = (X_test_full_final.isnull().sum())\n#print(missing_val_count_by_column[missing_val_count_by_column > 0])\n\n","64089cce":"#fit and predict\n#This model has already been selected as the best one in the first intermediate course\nmodel = RandomForestRegressor(n_estimators=100,criterion='mae', random_state=0)\nmodel.fit(X_train_full_final,y_train)\npreds_test = model.predict(X_test_full_final)\n\n# Save test predictions to file\nX_test_full.head()\noutput = pd.DataFrame({'Id': X_test_full.Id,'SalePrice': preds_test})\noutput.to_csv('submission.csv', index=False)\n","15a9eb7b":"# Explanation of this notebook\n- This code is a simple solution for those who have taken the Intermediate ML courses in Kaggle.\n- This code is not for the explanation of the lecture, but for creating a file for submission.\n- The following steps were used to analyze the data.\n1. Separate numerical data from categorical data.\n2. For numerical data, I used SimpleImputer to fill in the missing values.\n3. On the other hand, I used OrdinalEncoder for the categorical data.\n4. Combine these data sets.\n5. Finally, fit and predict.\n- This code is very simple, but it gave good results.\n- If you find any mistakes or problems with this code, please let me know in the comments!\n","44d89957":"# 5.Finally, fit and predict.","9d126f18":"# 1.Separate numerical data from categorical data.","a8498e7a":"# 3.On the other hand, I used OrdinalEncoder for the categorical data.","dddcf693":"# 4.Combine these data sets.","f3a28efc":"# 0.Data Preparation","427d9f4d":"# 2.For numerical data, I used SimpleImputer to fill in the missing values."}}