{"cell_type":{"1c75fc49":"code","d800a93c":"code","3bfb091d":"code","ccb7e70b":"code","2eb2bfc8":"code","f342a730":"code","3bba76b8":"code","5e6fbda0":"code","5d4402e6":"code","31a1236c":"code","84e6b5fe":"code","e7396459":"code","b1b17a96":"code","ca4c6374":"code","dd366436":"code","1e318005":"code","6ef9bb93":"code","b7c00ace":"markdown","8e4e84bb":"markdown","8f54f5d6":"markdown","b76d0370":"markdown","005bff9a":"markdown","b6ecf310":"markdown","25d46413":"markdown"},"source":{"1c75fc49":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d800a93c":"import tensorflow as tf\nimport numpy as np\nfrom tensorflow import keras\n\nimport os\nimport cv2\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator #\nfrom tensorflow.keras.preprocessing import image\nimport matplotlib.pyplot as plt","3bfb091d":"# Dataset used car-damage-detection\n# link - https:\/\/www.kaggle.com\/anujms\/car-damage-detection\n\n# setting up training and test data path\ntrain_data_path = \"..\/input\/car-damage-detection\/data1a\/training\"\ntest_data_path = \"..\/input\/car-damage-detection\/data1a\/validation\"","ccb7e70b":"# looking into the the data\nimg = plt.imread(os.path.join(train_data_path, \"00-damage\/0008.JPEG\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nprint(\"size of image (h x w)\",height,width)","2eb2bfc8":"img = plt.imread(os.path.join(train_data_path, \"00-damage\/0027.JPEG\"))\nplt.imshow(img)\nheight, width, dim = img.shape\nprint(\"size of image (h x w)\",height,width)","f342a730":"train = ImageDataGenerator(rescale=1\/255)\ntest = ImageDataGenerator(rescale=1\/255)\n\ntrain_dataset = train.flow_from_directory(train_data_path,\n                                          target_size=(150,150),\n                                          batch_size = 32,\n                                          class_mode = 'binary')\n                                         \ntest_dataset = test.flow_from_directory(test_data_path,\n                                          target_size=(150,150),\n                                          batch_size =32,\n                                          class_mode = 'binary')","3bba76b8":"# encoded class labels\ntest_dataset.class_indices","5e6fbda0":"from keras.models import Sequential\nfrom keras.layers import Dense,Activation,Dropout, Conv2D, MaxPool2D\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint","5d4402e6":"# using CNN \nmodel = Sequential()\n\n# Convolutional layer and maxpool layer 1\nmodel.add(Conv2D(32,(3,3),activation='relu',input_shape=(150,150,3)))\nmodel.add(MaxPool2D(2,2))\n\n# Convolutional layer and maxpool layer 2\nmodel.add(Conv2D(64,(3,3),activation='relu'))\nmodel.add(MaxPool2D(2,2))\n\n# Convolutional layer and maxpool layer 3\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPool2D(2,2))\n\n# Convolutional layer and maxpool layer 4\nmodel.add(Conv2D(128,(3,3),activation='relu'))\nmodel.add(MaxPool2D(2,2))\n\n# This layer flattens the resulting image array to 1D array\nmodel.add(keras.layers.Flatten())\n\n# Hidden layer and Rectified Linear Unit activation function \nmodel.add(Dense(512,activation='relu'))\n\n# Output layer with single neuron\n# Using sigmoid so as our model output is between 0 and 1\n# with 0 - damage car & 1 - not damage car\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.summary()","31a1236c":"model.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\nearlystop = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=1, min_delta=0.001)\nmodelcheck = ModelCheckpoint('best_model.hdf5', monitor='val_accuracy',verbose=1,save_best_only=True,mode='max')","84e6b5fe":"history = model.fit(train_dataset, \n                    validation_data=test_dataset,\n                    epochs=20,\n                    callbacks=[earlystop,modelcheck],\n                    batch_size=32)\n","e7396459":"plt.plot(history.history['loss'], label='train') \nplt.plot(history.history['val_loss'], label='test') \nplt.legend()\nplt.show()","b1b17a96":"print('Test accuracy achieved', history.history['val_accuracy'][-2])","ca4c6374":"# Our predict function\ndef predictImage(filename):\n    \n    img = image.load_img(filename,target_size=(150,150))\n    plt.imshow(img)\n    \n    Y = image.img_to_array(img)\n    X = np.expand_dims(Y,axis=0)\n    val = model.predict(X)\n    print(val)\n    if val < 0.5:\n        plt.xlabel(\"Car Damage\",fontsize=30)\n    elif val >= 0.5:\n        plt.xlabel(\"Car Not Damage\",fontsize=30)\n","dd366436":"predictImage(\"..\/input\/car-damage-detection\/data1a\/validation\/01-whole\/0029.jpg\")","1e318005":"predictImage(\"..\/input\/car-damage-detection\/data1a\/validation\/00-damage\/0029.JPEG\")","6ef9bb93":"# saving our model\n# model.save('my_model')","b7c00ace":"# Loading Dependencies","8e4e84bb":"# Data Transformation\nSince all the images in the dataset are of different sizes so we have to resize them, here i am resizing it to 150x150","8f54f5d6":"# Making Prediction","b76d0370":"# Training Model","005bff9a":"# Loading Datasets","b6ecf310":"# Model Building","25d46413":"Here i am using CNN for the binary classification"}}