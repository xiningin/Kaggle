{"cell_type":{"6c23da89":"code","5ceca476":"code","e535672d":"code","b3a3a85b":"code","ec6c352d":"code","f1fb0b28":"code","a540d12c":"markdown"},"source":{"6c23da89":"import tensorflow as tf\nimport numpy as np\nimport pandas as pd\nimport os, shutil\n!pip install -q efficientnet\nimport efficientnet.keras as efn\nimport tensorflow_probability as tfp\ntfd = tfp.distributions\n","5ceca476":"\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nIMG_SIZE = 299\nBATCH_SIZE = 16\nEPOCHS = 7\nFOLDS = 5\nFILES_LIST = tf.io.gfile.glob('..\/input\/cassava-skf-tfrecs-randomly-augmented\/*.tfrecords')\nFILES_LIST.sort()\nFOLDS_LIST=dict()\nSTEPS_PER_EPOCH = dict()\nfor i in range(5):\n    FOLDS_LIST['fold_'+str(i)] = dict({'train':FILES_LIST[:i]+FILES_LIST[i+1:], 'val':FILES_LIST[i]})\n\ntotal_rows = 0\nfor k in FILES_LIST:\n    df = pd.read_csv(k[:-9]+'csv')\n    total_rows += df.shape[0]\n\nSTEPS_PER_EPOCH = int((total_rows*0.8)\/BATCH_SIZE)    \nTFRECS_FORMAT={'image': tf.io.FixedLenFeature([], tf.string),\n                      'image_id': tf.io.FixedLenFeature([], tf.string),\n                      'target': tf.io.FixedLenFeature([], tf.int64)}\n\n","e535672d":"\ndef mixup(entry1,entry2):\n    image1,label1 = entry1\n    image2,label2 = entry2\n    \n    alpha = [0.2]\n    dist = tfd.Beta(alpha, alpha)\n    l = dist.sample(1)[0][0]\n    \n    img = l*image1+(1-l)*image2\n    lab = l*label1+(1-l)*label2\n    \n    return img, lab","b3a3a85b":"def decode_entry(entry):\n    return tf.cast(tf.reshape(tf.io.decode_raw(entry['image'],tf.float16),[299,299,3]),tf.float32),tf.cast(tf.one_hot(int(entry['target']),5),tf.float32) #[batch_size,h,w,3]    \n\n\ndef make_datasets(fold_num):\n    train_TFRecDataset=tf.data.TFRecordDataset(FOLDS_LIST['fold_'+str(fold_num)]['train'])#.batch(self.BATCH_SIZE).prefetch(1)\n    train_Dataset = train_TFRecDataset.map(lambda example:tf.io.parse_example(example,TFRECS_FORMAT))\n    train_Dataset = train_Dataset.map(lambda entry: decode_entry(entry))\n    train_Dataset1 = train_Dataset.shuffle(1024)\n    train_Dataset2 = train_Dataset.shuffle(1024)\n    train_Dataset = tf.data.Dataset.zip((train_Dataset1, train_Dataset2))\n    train_Dataset = train_Dataset.map(lambda entry1,entry2: mixup(entry1,entry2))\n    \n    val_TFRecDataset=tf.data.TFRecordDataset([FOLDS_LIST['fold_'+str(fold_num)]['val']])#.batch(self.BATCH_SIZE).prefetch(1)\n    val_Dataset = val_TFRecDataset.map(lambda example:tf.io.parse_example(example,TFRECS_FORMAT))\n    val_Dataset = val_Dataset.map(lambda entry: decode_entry(entry))\n    \n    return train_Dataset.batch(BATCH_SIZE).repeat().prefetch(AUTOTUNE),val_Dataset.batch(BATCH_SIZE).repeat().prefetch(AUTOTUNE)","ec6c352d":"def make_model():\n    model = tf.keras.Sequential()\n    efn_model = efn.EfficientNetB5(weights='noisy-student',input_shape=(IMG_SIZE,IMG_SIZE,3))\n    base_model = tf.keras.models.Model(inputs=efn_model.input, outputs=efn_model.layers[-3].output)\n    base_model.trainable = True\n#     base_model = tf.keras.applications.Xception(include_top=False,\n#                                             weights=\"imagenet\",\n#                                             input_tensor=None,\n#                                             input_shape=(299,299,3),\n#                                             pooling='max')\n    base_model.trainable = True\n    model.add(tf.keras.Input((299,299,3)))\n    model.add(base_model)\n    model.add(tf.keras.layers.Dropout(0.5))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dense(10,activation='relu'))\n    model.add(tf.keras.layers.BatchNormalization())\n    model.add(tf.keras.layers.Dense(5,activation='softmax'))\n\n    model.compile(optimizer='nadam',\n                 loss=tf.keras.losses.CategoricalCrossentropy(),\n                 metrics=[tf.keras.metrics.CategoricalAccuracy()])\n    return model","f1fb0b28":"for fold_num in range(FOLDS):\n    \n    print('#'*10)\n    print('Training fold ',fold_num)\n    print('#'*10)\n    \n    train_ds,val_ds = make_datasets(fold_num)\n    \n    filepath = \"fold_%i_effnet5_aug.hdf5\"%fold_num\n    save_checkpoint = tf.keras.callbacks.ModelCheckpoint(filepath, monitor='val_loss', verbose=1, save_best_only=True, mode='min')\n    reduce_lr = tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\",\n                                                    factor=0.1,\n                                                    patience=2,\n                                                    verbose=1,)\n\n    \n    model = make_model()\n    \n    model.fit(train_ds,\n             validation_data = val_ds,\n             epochs = EPOCHS,\n             steps_per_epoch = STEPS_PER_EPOCH,\n             validation_steps = STEPS_PER_EPOCH,\n             callbacks = [save_checkpoint],\n             verbose = 1)","a540d12c":"## Cassava GPU preprocessed trainer\n\n### Version history:\n\nVersion 2: Primary commit   \nVersion 4: mixup   \nVersion 5: Xception"}}