{"cell_type":{"81a08e95":"code","dd11bf31":"code","9bb12bd9":"code","3a3a7f8c":"code","8666fed3":"code","b319b27f":"code","7ff48cee":"code","a4596d6e":"code","73ecc441":"code","fa81ac0c":"code","1942d9ff":"code","316e75dd":"code","15e9e83d":"code","f567121e":"code","6e4d4616":"code","5dd1cd0a":"code","f532ef03":"code","f50db0e9":"code","7d8d58c5":"code","a3e9c1e5":"code","5afbdf76":"code","4bfd05ec":"code","375f57a3":"code","1238b1fe":"code","29ef2131":"code","f9a25476":"code","bdabd034":"code","a5299eb7":"code","b6a5459b":"code","093fc9bf":"code","3de24dd8":"code","3720f718":"code","3d832b96":"code","f8cd19e6":"code","6ab4068a":"code","23f8a54d":"code","42729409":"code","41ad7681":"code","328e163d":"code","c4c511cd":"code","7ab28161":"code","4a9e4ac4":"code","e513f4fa":"code","7a13b4ac":"code","81565a9a":"code","11bde797":"code","8e36db50":"code","2d1304e8":"code","9a4bdfc6":"code","837aecea":"code","edf7ba84":"code","6d24e2f9":"code","e6e3e540":"code","ca42f416":"code","2b303a99":"code","febab45b":"code","92976e4a":"code","e58ed186":"code","3956c7b8":"code","69862547":"code","fa617e0f":"code","cf874871":"code","eba4b158":"code","f1b06d77":"markdown","54c04526":"markdown","547b68d3":"markdown","6702b5e9":"markdown","7870b570":"markdown","00f70dbe":"markdown","b263f9d4":"markdown","f680cfce":"markdown","5d972ec6":"markdown","a2de0e54":"markdown"},"source":{"81a08e95":"!pip install forgi","dd11bf31":"# importing libraries\n\nimport pandas as pd\nimport numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport forgi.graph.bulge_graph as fgb\nimport forgi.visual.mplotlib as fvm\n\nimport plotly.express as px\nfrom collections import Counter as count\nfrom collections import Counter","9bb12bd9":"train = pd.read_json('..\/input\/stanford-covid-vaccine\/train.json', lines = True).drop('index' , axis = 1)\ntest = pd.read_json('..\/input\/stanford-covid-vaccine\/test.json' , lines = True).drop('index' , axis = 1)\nsub = pd.read_csv('..\/input\/stanford-covid-vaccine\/sample_submission.csv')","3a3a7f8c":"train.head()","8666fed3":"train.T","b319b27f":"test.head()","7ff48cee":"sub.head()","a4596d6e":"train.columns","73ecc441":"test.columns","fa81ac0c":"print(\"Train data shape: \",train.shape)\nprint(\"Test data shape: \",test.shape)\nprint(\"Sample submission shape: \",sub.shape)","1942d9ff":"fig, ax = plt.subplots(1 , 2 , figsize = (20 , 5))\ntrain['signal_to_noise'].plot.kde(ax = ax[0])\nax[0].set_title('Signal\/Noise')\n\nsns.countplot(data=train,y='SN_filter',ax=ax[1])\nax[1].set_title('SN_filter')\n\nplt.show()","316e75dd":"plt.figure(figsize = (20 , 2))\nsns.boxplot(data = train , x = 'signal_to_noise')\n\nplt.show()","15e9e83d":"print(\"Number of samples with -ev signal\/noise values: \" , train[train['signal_to_noise']<0].shape[0])\n\nQ1 = np.percentile(train['signal_to_noise'] , q = 25)\nQ3 = np.percentile(train['signal_to_noise'] , q = 75)\nIQR = Q3 - Q1\n\nprint(\"Number of samples with too high signal\/noise values\", train[train['signal_to_noise'] > Q3 + 1.5 * IQR].shape[0])","f567121e":"train.seq_length.value_counts()","6e4d4616":"test.seq_length.value_counts()","5dd1cd0a":"fig = px.histogram(\n    train, \n    \"signal_to_noise\", \n    nbins=25, \n    title='signal_to_noise column distribution', \n    width=800,\n    height=500\n)\nfig.show()","f532ef03":"ds = train['SN_filter'].value_counts().reset_index()\nds.columns = ['SN_filter', 'count']\nfig = px.pie(\n    ds, \n    values='count', \n    names=\"SN_filter\", \n    title='SN_filter bar chart', \n    width=500, \n    height=500\n)\nfig.show()\n","f50db0e9":"plt.figure(figsize = (12 , 5))\nn, bins, patches = plt.hist(x = train['signal_to_noise'] , bins = 'auto' , color = '#FFA500' , alpha = 1 , rwidth = 0.80)\nplt.grid(axis='y', alpha = 0.75)\nplt.xlabel('signal_to_noise')\nplt.ylabel('Frequency')\nplt.title('signal_to_noise Histogram')\nplt.text(12, 110, f\"(SN_filter == 1)  : {train['SN_filter'].value_counts()[0]}\", fontsize=15)\nplt.text(12, 85, f\"(SN_filter == 0) : {train['SN_filter'].value_counts()[1]}\", fontsize=15)\nplt.show()","7d8d58c5":"def character_count(row):\n    _dictionary = {'G': 0,'A': 0, 'C': 0, 'U': 0, '.': 0, '(': 0, ')': 0, 'E': 0, 'S': 0, 'H': 0, 'B': 0, 'X': 0,'I': 0,'M':0}\n    _dictionary = {**_dictionary, **dict(Counter(row['sequence']))}\n    _dictionary = {**_dictionary, **dict(Counter(row['structure']))}\n    _dictionary = {**_dictionary, **dict(Counter(row['predicted_loop_type']))}\n    return list(_dictionary.values())","a3e9c1e5":"feature_columns = ['G','A', 'C', 'U', '.', '(', ')', 'E', 'S', 'H', 'B', 'X','I','M']\ntrain[feature_columns] = train.apply(character_count , axis = 1 , result_type = \"expand\")","5afbdf76":"fig, _ax = plt.subplots(nrows = 4 , ncols = 4 , figsize = (20 , 20))\nfig.suptitle(\"Train Data New Features Histograms\", fontsize = 20,)\n\nfor i,_ax in enumerate(_ax.ravel()[:14]):\n    mean_value = train[feature_columns[i]].mean()\n    max_value_index , max_value = Counter(train[feature_columns[i]]).most_common(1)[0]\n    \n    _ax.hist(x=train[feature_columns[i]] , bins = 'auto' , color = '#800000', alpha = 1 , rwidth = 1)\n    _ax.set(ylabel = f\"'{feature_columns[i]}' Frequency\", title= f\"'{feature_columns[i]}' Histogram\")\n    _ax.axvline(x = mean_value , color='#808000' , label= 'Average',linewidth=2)\n    _ax.axvline(x = max_value_index , color = 'y' , label = 'Max', linewidth = 2)\n    _ax.legend([f\"Average : {mean_value:0.2f}\" , f\"Max Frequency : {max_value}\", \"Hist\"] , loc = \"upper right\")\n    \nplt.show()","4bfd05ec":"# Train Data New Features correlation\n\ncorr = train[feature_columns].corr()\nsns.set_context(\"notebook\" , font_scale = 1.0 , rc = {\"lines.linewidth\": 2.5})\nplt.figure(figsize=(13,7))\nplt.title(\"Train Data New Features correlation : \")\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask, 1)] = True\na = sns.heatmap(corr , mask = mask , annot = True , fmt = '.2f' , cmap = \"YlGnBu\")\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","375f57a3":"plt.figure(figsize = (20 , 10))\ncorr = train.corr()\nsns.heatmap(corr , annot = True , fmt = '.2f' , cmap = \"PiYG\")","1238b1fe":"## Test-Data\n\nfeature_columns = ['G','A', 'C', 'U', '.', '(', ')', 'E', 'S', 'H', 'B', 'X','I','M']\ntest[feature_columns] = test.apply(character_count,axis=1,result_type=\"expand\")\nfig, _ax = plt.subplots(nrows=4,ncols=4,figsize=(20,20))\nfig.suptitle(\"Test Data New Features Histograms\", fontsize=20,)\nfor i,_ax in enumerate(_ax.ravel()[:14]):\n    mean_value = test[feature_columns[i]].mean()\n    max_value_index,max_value = Counter(test[feature_columns[i]]).most_common(1)[0]\n    \n    _ax.hist(x=test[feature_columns[i]],bins='auto', color='#808000', alpha=1, rwidth=1)\n    _ax.set(ylabel=f\"'{feature_columns[i]}' Frequency\", title= f\"'{feature_columns[i]}' Histogram\")\n    _ax.axvline(x=mean_value, color='r', label= 'Average',linewidth=2)\n    _ax.axvline(x=max_value_index, color='y', label= 'Max',linewidth=2)\n    _ax.legend([f\"Average : {mean_value:0.2f}\",f\"Max Frequency : {max_value}\", \"Hist\"], loc =\"upper right\")\nplt.show()","29ef2131":"# Test Data New Features correlation\ncorr = test[feature_columns].corr()\nsns.set_context(\"notebook\", font_scale=1.0, rc={\"lines.linewidth\": 2.5})\nplt.figure(figsize=(13,7))\nplt.title(\"Test Data New Features correlation : \")\n\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask, 1)] = True\na = sns.heatmap(corr,mask=mask, annot=True, fmt='.2f' , cmap = 'hot')\n\nrotx = a.set_xticklabels(a.get_xticklabels(), rotation=90)\nroty = a.set_yticklabels(a.get_yticklabels(), rotation=30)","f9a25476":"avg_reactivity = np.array(list(map(np.array,train.reactivity))).mean(axis = 0)\navg_deg_50C = np.array(list(map(np.array,train.deg_50C))).mean(axis = 0)\navg_deg_pH10 = np.array(list(map(np.array,train.deg_pH10))).mean(axis = 0)\navg_deg_Mg_50C = np.array(list(map(np.array,train.deg_Mg_50C))).mean(axis = 0)\navg_deg_Mg_pH10 = np.array(list(map(np.array,train.deg_Mg_pH10))).mean(axis = 0)","bdabd034":"fig , ax = plt.subplots(1 , 3 , figsize = (20 , 4))\n\nsns.kdeplot(avg_reactivity , ax = ax[0])\nax[0].set_title(\"Distribution of Reactivity average over position\" , size = 15)\n\n# Distribution of deg_50C Averaged over position\nsns.kdeplot(avg_deg_50C , ax = ax[1])\nax[1].set_title('Distribution of deg_50C Averaged over position', size = 15)\n\n# Distribution of deg_pH10 Averaged over position\nsns.kdeplot(avg_deg_pH10 , ax = ax[2])\nax[2].set_title('Distribution of deg_pH10 Averaged over position' , size = 15)\n\n\nplt.show()","a5299eb7":"plt.figure(figsize = (20 , 8))\n\nsns.lineplot(x = range(68) , y = avg_reactivity , label = 'reactivity')\nsns.lineplot(x = range(68) , y = avg_deg_50C , label = 'deg_50C')\nsns.lineplot(x = range(68) , y = avg_deg_pH10 , label = 'deg_ph10')\n\nplt.xlabel('Positions')\nplt.xticks(range(0 , 68 , 2))\nplt.ylabel('Values')\nplt.title('Average Target Values (w\/o Mg) V\/S Positions')\n\nplt.show()","b6a5459b":"plt.figure(figsize = (20 , 8))\nsns.regplot(x = avg_deg_50C , y = avg_deg_pH10)\n\nplt.title('Average deg_50C V\/S deg_pH10')\nplt.ylabel('deg_50C')\nplt.xlabel('deg_pH10')\n\nplt.show()","093fc9bf":"print(\"Correlation Coeff between avg_deg_50C & avg_deg_pH10: \",np.corrcoef(avg_deg_50C,avg_deg_pH10)[0][1])","3de24dd8":"plt.figure(figsize = (20 , 8))\nsns.regplot(x = avg_deg_50C , y = avg_deg_Mg_pH10)\n\nplt.title('Average deg_50C V\/S deg_Mg_pH10')\nplt.ylabel('deg_50C')\nplt.xlabel('deg_pH10')\n\nplt.show()","3720f718":"plt.figure(figsize = (20 , 8))\nsns.regplot(x = avg_deg_50C , y = avg_reactivity)\n\nplt.title('Average deg_50C V\/S deg_pH10')\nplt.ylabel('deg_50C')\nplt.xlabel('deg_pH10')\n\nplt.show()","3d832b96":"fig, ax = plt.subplots(1 , 2 , figsize = (20 , 4))\n\n# Distribution of deg_50C Averaged over position\nsns.kdeplot(avg_deg_Mg_50C , ax = ax[0])\nax[0].set_title('Distribution of deg_Mg_50C Averaged over position' , size = 15)\n\n\n# Distribution of deg_pH10 Averaged over position\nsns.kdeplot(avg_deg_Mg_pH10 , ax = ax[1])\nax[1].set_title('Distribution of deg_Mg_pH10 Averaged over position' , size = 15)\n\nplt.show()","f8cd19e6":"plt.figure(figsize = (20 , 8))\n\nsns.lineplot(x = range(68) , y = avg_deg_Mg_50C , label = 'deg_Mg_50C')\nsns.lineplot(x = range(68) , y = avg_deg_Mg_pH10 , label = 'deg_Mg_pH10')\n\nplt.xlabel('Positions')\nplt.xticks(range(0 , 68 , 2))\nplt.ylabel('Values')\nplt.title('Average Target Values (w Mg) V\/S Positions')\n\nplt.show()","6ab4068a":"print(\"Correlation Coeff between avg_deg_Mg_50C & avg_deg_Mg_pH10: \",np.corrcoef(avg_deg_Mg_50C,avg_deg_Mg_pH10)[0][1])","23f8a54d":"pos = np.random.choice(68)\n\nfig, ax = plt.subplots(1,3,figsize=(20,4))\n\n# Distribution of Reactivity at Random position\nsns.kdeplot(np.array(list(map(np.array,train.reactivity)))[:,pos],ax=ax[0])\nax[0].set_title(f'Distribution of Reactivity at position-{pos}',size=15)\n\n# Distribution of deg_50C at Random position\nsns.kdeplot(np.array(list(map(np.array,train.deg_50C)))[:,pos],ax=ax[1])\nax[1].set_title(f'Distribution of deg_50C at position-{pos}',size=15)\n\n# Distribution of deg_pH10 at Random position\nsns.kdeplot(np.array(list(map(np.array,train.deg_pH10)))[:,pos],ax=ax[2])\nax[2].set_title(f'Distribution of deg_pH10 at position-{pos}',size=15)\n\nplt.show()","42729409":"fig, ax = plt.subplots(1,2,figsize=(20,4))\n\n# Distribution of deg_50C at Random position\nsns.kdeplot(np.array(list(map(np.array,train.deg_Mg_50C)))[:,pos],ax=ax[0])\nax[0].set_title(f'Distribution of deg_Mg_50C at position-{pos}',size=15)\n\n\n# Distribution of deg_pH10 at Random position\nsns.kdeplot(np.array(list(map(np.array,train.deg_Mg_pH10)))[:,pos],ax=ax[1])\nax[1].set_title(f'Distribution of deg_Mg_pH10 at position-{pos}',size=15)\n\nplt.show()","41ad7681":"y = ['reactivity_error' , 'deg_error_Mg_pH10' , 'deg_error_pH10' , 'deg_error_Mg_50C' ,'deg_error_50C']\nx = [np.array(list(map(np.array,train[col]))).mean(axis = 0) for col in y]\n\nplt.figure(figsize = (20 , 5))\n\nsns.boxplot(y = y , x = x)\n\nplt.xlabel('Error values')\nplt.title('Average Errors in Calculation of Targets')\n\nplt.show()","328e163d":"plt.figure(figsize = (20 , 8))\n\nfor i in range(len(y)):\n    sns.lineplot(x = range(68) , y = x[i] , label = y[i])\n    \nplt.xlabel('Positions')\nplt.xticks(range(0,68,2))\nplt.ylabel('Error')\nplt.title('Error V\/S Position')\n\nplt.show()","c4c511cd":"pos = np.random.choice(68)\n\ny = ['reactivity_error','deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C','deg_error_50C']\nx = [np.array(list(map(np.array , train[col])))[:,pos] for col in y]\n\nplt.figure(figsize = (20 , 5))\nplt.title(f'Error Distribution at position - {pos}')\nplt.xlabel('Error')\n\nsns.boxplot(y=y,x=x)\n\nplt.show()","7ab28161":"y = ['reactivity_error','deg_error_Mg_pH10', 'deg_error_pH10', 'deg_error_Mg_50C','deg_error_50C']\nx = [np.array(list(map(np.array,train[train.SN_filter == 1][col])))[:,pos] for col in y]\n\nplt.figure(figsize = (20 , 5))\nplt.title(f'(Filtered) Error Distribution at position - {pos}')\nplt.xlabel('Error')\n\nsns.boxplot(y = y , x = x)\n\nplt.show()","4a9e4ac4":"def plot_sample(sample):\n    \n    struct = sample['structure']\n    seq = sample['sequence']\n    bg = fgb.BulgeGraph.from_fasta_text(f'>rna1\\n{struct}\\n{seq}')[0]\n    \n    plt.figure(figsize=(20,8))\n    fvm.plot_rna(bg)\n    plt.title(f\"RNA Structure (id: {sample.id})\")\n    plt.show()","e513f4fa":"sample = train.iloc[np.random.choice(train.shape[0])]\n#plot_sample(sample)\nprint(\"Predicted Loop type: \",sample['predicted_loop_type'])","7a13b4ac":"from collections import defaultdict\n\nreactivity = defaultdict(lambda: [])\ndeg_Mg_50C = defaultdict(lambda: [])\ndeg_Mg_pH10 = defaultdict(lambda: [])\n\nfor i in range(len(sample['reactivity'])):\n    reactivity[sample['structure'][i]].append(float(sample['reactivity'][i]))\n    deg_Mg_50C[sample['structure'][i]].append(float(sample['deg_Mg_50C'][i]))\n    deg_Mg_pH10[sample['structure'][i]].append(float(sample['deg_Mg_pH10'][i]))\n\nplt.figure(figsize = (18 , 5))\nfor key in reactivity.keys():\n    sns.kdeplot(data=reactivity[key],label=key)\n\nplt.title('Structure wise Distribution of Reactivity of a Random Sample')\nplt.show()","81565a9a":"plt.figure(figsize = (20 , 5))\nfor key in reactivity.keys():\n    sns.kdeplot(data = deg_Mg_50C[key] , label = key)\n\nplt.title('Structure wise Distribution of deg_Mg_50C of a Random Sample')\nplt.show()","11bde797":"\nplt.figure(figsize = (20 , 5))\nfor key in reactivity.keys():\n    sns.kdeplot(data = deg_Mg_pH10[key] , label = key)\n\nplt.title('Structure wise Distribution of deg_Mg_pH10 of a Random Sample')\nplt.show()","8e36db50":"reactivityDict = defaultdict(lambda: [])\n\nfor index in range(train.shape[0]):\n    \n    sample = train.iloc[index]\n\n    structure = sample['structure']\n    sequence = sample['sequence']\n    reactivity = sample['reactivity']\n\n    q = []\n\n    for i,s in enumerate(structure[:len(reactivity)]):\n        if s=='.':\n            reactivityDict[sequence[i]].append(reactivity[i])\n        elif s=='(':\n            q.append(i)\n        elif s==')':\n            j = q.pop(0)\n            key = \"-\".join(sorted([sequence[i],sequence[j]]))\n            reactivityDict[key].append(reactivity[i])\n            reactivityDict[key].append(reactivity[j])","2d1304e8":"fig, ax = plt.subplots(len(reactivityDict.keys()) , 1 , figsize = (20 , 2 * len(reactivityDict.keys())) , sharex = True)\n\nfor i, key in enumerate(reactivityDict.keys()):\n    sns.boxplot(x=reactivityDict[key],ax=ax[i])\n    ax[i].set_ylabel(key)\n\nplt.xlabel('Reactivity')\nplt.show()","9a4bdfc6":"pri = test[test.seq_length == 130]\npub = test[test.seq_length == 107]","837aecea":"def read_bpps_mean(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"..\/input\/stanford-covid-vaccine\/bpps\/{mol_id}.npy\").mean(axis=1))\n    return bpps_arr\n\ntrain['bpps_mean'] = read_bpps_mean(train)\npri['bpps_mean'] = read_bpps_mean(pri)\npub['bpps_mean'] = read_bpps_mean(pub)\n\nsns.distplot(np.array(train['bpps_mean'].to_list()).reshape(-1) , color = \"Blue\")\nsns.distplot(np.array(pub['bpps_mean'].to_list()).reshape(-1) , color = \"Green\")\nsns.distplot(np.array(pri['bpps_mean'].to_list()).reshape(-1) , color = \"Red\")","edf7ba84":"\ndef read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"..\/input\/stanford-covid-vaccine\/bpps\/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ntrain['bpps_max'] = read_bpps_max(train)\npri['bpps_max'] = read_bpps_max(pri)\npub['bpps_max'] = read_bpps_max(pub)\n\nsns.distplot(np.array(train['bpps_max'].to_list()).reshape(-1),color = \"#FF0000\")\nsns.distplot(np.array(pub['bpps_max'].to_list()).reshape(-1),color = \"#00FFFF\")\nsns.distplot(np.array(pri['bpps_max'].to_list()).reshape(-1),color = \"#C0C0C0\")","6d24e2f9":"def read_bpps_max(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps_arr.append(np.load(f\"..\/input\/stanford-covid-vaccine\/bpps\/{mol_id}.npy\").max(axis=1))\n    return bpps_arr\n\ntrain['bpps_sum'] = read_bpps_max(train)\npri['bpps_sum'] = read_bpps_max(pri)\npub['bpps_sum'] = read_bpps_max(pub)\n\nsns.distplot(np.array(train['bpps_max'].to_list()).reshape(-1),color = \"#000000\")\nsns.distplot(np.array(pub['bpps_max'].to_list()).reshape(-1),color = \"#0000FF\")\nsns.distplot(np.array(pri['bpps_max'].to_list()).reshape(-1),color = \"#ADD8E6\")","e6e3e540":"def read_bpps_nb(df):\n    bpps_arr = []\n    for mol_id in df.id.to_list():\n        bpps = np.load(f\"..\/input\/stanford-covid-vaccine\/bpps\/{mol_id}.npy\")\n        bpps_nb = (bpps > 0).sum(axis=0) \/ bpps.shape[0]\n        bpps_arr.append(bpps_nb)\n    return bpps_arr \n\ntrain['bpps_nb'] = read_bpps_nb(train)\npri['bpps_nb'] = read_bpps_nb(pri)\npub['bpps_nb'] = read_bpps_nb(pub)\n\nsns.distplot(np.array(train['bpps_nb'].to_list()).reshape(-1),color=\"Blue\")\nsns.distplot(np.array(pub['bpps_nb'].to_list()).reshape(-1),color=\"Green\")\nsns.distplot(np.array(pri['bpps_nb'].to_list()).reshape(-1),color=\"Red\")","ca42f416":"def mk_pair_map(structure, type = 'pm'):\n    pm = np.full(len(structure), -1, dtype=int)\n    pd = np.full(len(structure), -1, dtype=int)\n    queue = []\n    \n    for i, s in enumerate(structure):\n        if s == \"(\":\n            queue.append(i)\n        elif s == \")\":\n            j = queue.pop()\n            pm[i] = j\n            pm[j] = i\n            pd[i] = i-j\n            pd[j] = i-j\n            \n    if type == 'pm':\n        return pm\n    elif type == 'pd':\n        return pd","2b303a99":"train['pair_map'] = train.structure.apply(mk_pair_map, type='pm')\npub['pair_map'] = pub.structure.apply(mk_pair_map, type='pm')\npri['pair_map'] = pri.structure.apply(mk_pair_map, type='pm')\n\ntrain_list = np.array(train['pair_map'].to_list()).reshape(-1)\npub_list = np.array(pub['pair_map'].to_list()).reshape(-1)\npri_list = np.array(pri['pair_map'].to_list()).reshape(-1)\n\nsns.distplot(train_list[~train_list<0],color=\"#800080\")\nsns.distplot(pub_list[~pub_list<0],color=\"#00FF00\")\nsns.distplot(pri_list[~pri_list<0],color=\"#FFFF00\")","febab45b":"\ntrain['pair_dist'] = train.structure.apply(mk_pair_map, type='pd')\npub['pair_dist'] = pub.structure.apply(mk_pair_map, type='pd')\npri['pair_dist'] = pri.structure.apply(mk_pair_map, type='pd')\n\ntrain_list = np.array(train['pair_dist'].to_list()).reshape(-1)\npub_list = np.array(pub['pair_dist'].to_list()).reshape(-1)\npri_list = np.array(pri['pair_dist'].to_list()).reshape(-1)\n\nsns.distplot(train_list[~train_list<0],color=\"#800000\")\nsns.distplot(pub_list[~pub_list<0],color=\"#008000\")\nsns.distplot(pri_list[~pri_list<0],color=\"#E55451\")","92976e4a":"bpps_files = os.listdir('..\/input\/stanford-covid-vaccine\/bpps\/')\nplt.style.use('default')\nfig, axs = plt.subplots(5, 5, figsize=(15, 15))\naxs = axs.flatten()\nfor i, f in enumerate(bpps_files):\n    if i == 25:\n        break\n    example_bpps = np.load(f'..\/input\/stanford-covid-vaccine\/bpps\/{f}')\n    axs[i].imshow(example_bpps)\n    axs[i].set_title(f)\nplt.tight_layout()\nplt.show()","e58ed186":"def get_ngrams_counters(sequences, n=2):\n    output = Counter()\n    for sequence in sequences:\n        output += Counter([sequence[i:i+n] for i in range(len(sequence)-1)])\n        \n    return output","3956c7b8":"train_ngram_sequence = get_ngrams_counters(train.sequence)\ntest_ngram_sequence = get_ngrams_counters(test.sequence)\n\n# Used to sort by frequency.\ntrain_ngram_sequence = dict(train_ngram_sequence.most_common(10000))\ntest_ngram_sequence = dict(test_ngram_sequence.most_common(10000))\n\nplt.figure(figsize=(16, 5))\nplt.subplot(1, 2, 1)\nplt.title(f'Sequence character bigram counts (train) ({len(train_ngram_sequence)} unique bigrams)')\nplt.bar(dict(train_ngram_sequence).keys(), dict(train_ngram_sequence).values())\n\nplt.subplot(1, 2, 2)\nplt.title(f'Sequence character bigram counts (test) ({len(test_ngram_sequence)} unique bigrams)')\nplt.bar(dict(test_ngram_sequence).keys(), dict(test_ngram_sequence).values())\n\nplt.show()","69862547":"train_ngram_sequence = get_ngrams_counters(train.sequence, 3)\ntest_ngram_sequence = get_ngrams_counters(test.sequence, 3)\n\n# Used to sort by frequency.\ntrain_ngram_sequence = dict(train_ngram_sequence.most_common(10000))\ntest_ngram_sequence = dict(test_ngram_sequence.most_common(10000))\n\nplt.figure(figsize=(25, 10))\nplt.title(f'Sequence character trigram (train) ({len(train_ngram_sequence)} unique trigrams)')\nplt.bar(dict(train_ngram_sequence).keys(), dict(train_ngram_sequence).values())\nplt.xticks(rotation=45)\n\nplt.figure(figsize=(25, 10))\nplt.title(f'Sequence character trigram (test) ({len(test_ngram_sequence)} unique trigrams)')\nplt.bar(dict(test_ngram_sequence).keys(), dict(test_ngram_sequence).values())\nplt.xticks(rotation=45)\n\nplt.show()","fa617e0f":"# This function performs some basic statististical analysis on the various labels.\n\ndef do_analysis(df, column_name):\n    all_vals = [y for x in df[column_name] for y in x]\n    print(f\"Analysis across all samples for {column_name}\")\n    print(f'Mean: {np.mean(all_vals)}')\n    print(f'Max: {np.max(all_vals)}')\n    print(f'Min: {np.min(all_vals)}')\n#     print(f'Mode: {mode(all_vals).mode[0]}')\n    print(f'STD: {np.std(all_vals)}')\n    print()\n    \n    plt.hist(all_vals)\n    plt.title(f'Histogram for {column_name} across all samples')\n    plt.show()\n    \n    print(\"Statistics aggregated per sample\")\n    fig, axes = plt.subplots(1, 4, figsize=(15, 5), squeeze=False)\n\n    df[column_name].apply(\n        lambda x: np.mean(x)).plot(\n            kind='hist',\n            bins=50, ax=axes[0,0],\n            title=f'Mean dist {column_name}')\n\n    df[column_name].apply(\n        lambda x: np.max(x)).plot(\n            kind='hist',\n            bins=50, ax=axes[0,1],\n            title=f'Max dist {column_name}')\n\n    df[column_name].apply(\n        lambda x: np.min(x)).plot(\n            kind='hist',\n            bins=50, ax=axes[0,2],\n            title=f'Min dist {column_name}')\n    df[column_name].apply(\n        lambda x: np.std(x)).plot(\n            kind='hist',\n            bins=50, ax=axes[0,3],\n            title=f'Std {column_name}')\n    plt.show()","cf874871":"do_analysis(train, 'reactivity')","eba4b158":"do_analysis(train, 'deg_Mg_pH10')","f1b06d77":"# **Importing Libraries**","54c04526":" #         <h1 align=\"center\">   **OpenVaccine || EDA || Feature Engineering**<\/h1>\n \n![](http:\/\/https:\/\/daslab.stanford.edu\/site_data\/news_img\/openvaccine_lores.png)","547b68d3":"\nWe can see an interesting pattern here. We have high values of errors between postions 0 and 4, but then it starts decreasing constantly as we go ahead Now let's analyse if all samples are contributing to these high values or there are only few smaples which are driving these values","6702b5e9":"We can see high values of Degradation & Reactivity at the beginning of the sequence There is high degradation because of pH10 at the beginning but no such pattern for rest of the positions. We can see some correlation between deg_50C & deg_pH10","7870b570":"# **Reading Data**","00f70dbe":"# **Starting EDA**","b263f9d4":"We can do same analysis for each feauture same way.","f680cfce":"\nVery high values of Errors in deg_error_pH10 & deg_error_50C but maybe we should not worry about these targets because evaluation is not based on these targets Maybe this could be a reason why our models will not be scored on these two targets","5d972ec6":"Hope You like my analysis of Data. By using this feautures we can apply models on top of it and get desired results","a2de0e54":"We can see there are few samples which are having high values of errors Now let's try to filter these samples We can try using SN_filter for this"}}