{"cell_type":{"ee52afe1":"code","747a4f42":"code","7641da39":"code","4bb1e24d":"code","b6b68c4a":"code","88be97fe":"code","98bbcc9c":"code","365d4661":"code","7cdb425a":"code","b35ff526":"code","4e7068b3":"code","1077ab6a":"code","b562ba4e":"code","ef051577":"code","0801c2ec":"code","37f600e5":"code","07b437b2":"code","28e1ff7c":"code","fa0364d1":"code","9c208a01":"code","70019bec":"code","4ed88aa4":"code","e01bfdb4":"markdown","a2441999":"markdown","061ab3b0":"markdown","f360cde2":"markdown","47a0c247":"markdown","d8425178":"markdown","f117e0d8":"markdown","19415e1c":"markdown","1929deed":"markdown","515ca9e5":"markdown","c0e7a439":"markdown","aca25288":"markdown","82631717":"markdown","5b4f34b2":"markdown","76332da4":"markdown","f67b67fd":"markdown","d126076f":"markdown","a4fd4b5d":"markdown","d902fcd8":"markdown","385d006f":"markdown","c3657c57":"markdown","0f9bbcaa":"markdown","b442fa6a":"markdown","f1c916d1":"markdown","922b0a29":"markdown","3fe552b5":"markdown","18a151c9":"markdown","b397a5f2":"markdown","4c7430a1":"markdown","d25eee29":"markdown","83b928e9":"markdown","6e3596dc":"markdown","69824391":"markdown","0dfebfa4":"markdown","2b52a47a":"markdown","5c75628f":"markdown","e0d9a4f7":"markdown","10b17748":"markdown","cac8f60c":"markdown","7a85da25":"markdown","fbeefd12":"markdown","023dbb29":"markdown","93463f80":"markdown"},"source":{"ee52afe1":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nimport geopandas as gpd\nfrom descartes import PolygonPatch\nimport glob\nimport matplotlib.cm as cm\nimport plotly.express as px\nwarnings.filterwarnings('ignore')","747a4f42":"dt = pd.read_csv(\"..\/input\/kaggle-survey-2020\/kaggle_survey_2020_responses.csv\")\ndt_nq = dt.iloc[1:]\n\ndt_nq.Q3 = dt_nq.Q3.replace('Iran, Islamic Republic of...', 'Iran')\ndt_nq.Q3 = dt_nq.Q3.replace('United Kingdom of Great Britain and Northern Ireland', 'United Kingdom')\ndt_nq.Q3 = dt_nq.Q3.replace('Republic of Korea', 'South Korea')\n\ndt_19 = pd.read_csv(\"..\/input\/kaggle-survey-2019\/multiple_choice_responses.csv\")\ndt_nq_19 = dt_19.iloc[1:]\n\ndt_nq_19.Q3 = dt_nq_19.Q3.replace('Iran, Islamic Republic of...', 'Iran')\ndt_nq_19.Q3 = dt_nq_19.Q3.replace('United Kingdom of Great Britain and Northern Ireland', 'United Kingdom')\ndt_nq_19.Q3 = dt_nq_19.Q3.replace('Republic of Korea', 'South Korea')","7641da39":"conts = { 'Asia & Australia' : ['Japan','India','China','Indonesia','Singapore','Pakistan', 'Nepal', 'South Korea', \n                    'Saudi Arabia', 'Taiwan', 'UAE','Viet Nam', 'Thailand',\n                    'Philippines','Turkey','Iran','Republic of Korea', \n                    'Bangladesh','Malaysia','Israel','Sri Lanka', 'Australia'\n                   ],\n         'Europe' : [ 'Germany','Switzerland','Russia','Netherlands','Poland', 'Belarus','Portugal',\n                     'Ukraine', 'Belgium','Italy', 'Spain', 'Ireland', 'Romania','Sweden',\n                     'United Kingdom', 'France', 'Greece',\n                    ],\n         'America' : ['Colombia', 'United States of America', 'Argentina','Brazil', \n                     'Canada','Mexico','Peru','Chile',\n                     ],\n         'Africa' :['South Africa','Egypt','Tunisia','Nigeria','Morocco','Ghana','Kenya', 'Algeria'],\n         \n}\n\ndef getCont(ctr):\n    if ctr in conts['Asia & Australia']:\n        return 'Asia & Australia'\n    elif ctr in conts['Europe']:\n        return 'Europe'\n    elif ctr in conts['America']:\n        return 'America'\n    elif ctr in conts['Africa']:\n        return 'Africa'\n    else:\n        return 'UND'\n    \ndt_nq['Continent'] = dt_nq['Q3'].apply(lambda x: getCont(x))\ndt_nq_19['Continent'] = dt_nq_19['Q3'].apply(lambda x: getCont(x))","4bb1e24d":"m = {'Prefer not to say':'Other', 'Prefer to self-describe':'Other', 'Nonbinary':'Other',\n    'Man': 'Man', 'Woman':'Woman'}\ndt_nq['Q2'] = dt_nq['Q2'].apply(lambda x : m[x])\n\ncolors = cm.Blues(np.linspace(0.4, 1, len(dt_nq['Q2'].unique())))[::-1]\nVC = dt_nq['Q2'].value_counts().plot.pie(subplots=True, figsize=(8, 5), colors=colors,\n                                         autopct='%1.0f%%', pctdistance=1.1, labeldistance=1.3)\n_ = plt.title('Distribution of Gender for Kaggle Survey 2020 Respondents', fontweight ='bold')\nplt.ylabel('')\n_ = plt.legend(bbox_to_anchor=(1.5, 0.8))","b6b68c4a":"dt_gd_ctry = dt_nq.groupby(['Q3','Q2']).size().unstack(level=1, fill_value=0)\n\nfor c in dt_gd_ctry.index:\n    dt_gd_ctry.loc[c] = (dt_gd_ctry.loc[c]\/sum(dt_gd_ctry.loc[c])*100).astype(int)\n\ndt_gd_ctry['Continent'] = list(map(lambda x: getCont(x), list(dt_gd_ctry.index)))","88be97fe":"top15_female = dt_gd_ctry.sort_values('Woman', ascending = False).head(15)['Woman']\n\n# Set position of bar on X axis\n\nbarWidth = 0\nrange_top15 = np.arange(len(top15_female))\n\n# Create Masks for coloring the chart, returning indices when artist-song topped most charts\nmasks = []\n\ntop15_female_countries = top15_female.index\nfor t in conts.keys():\n    masks.append(top15_female.index.isin(conts[t]))\n\ncolors = cm.Blues(np.linspace(0.4, 0.9, len(conts.keys())))[::-1]\n# Make the plot\nf, ax = plt.subplots(figsize=(8, 6))\n\nfor i, mask in enumerate(masks):\n    plt.barh(range_top15[mask], top15_female[mask], color=colors[i],  \\\n            label = list(conts.keys())[i])\n\n# Add xticks on the middle of the group bars\nplt.ylabel('Countries', fontweight='bold')\nplt.xlabel('Percentage of Women Respondents (%)', fontweight='bold')\nplt.yticks([r + barWidth for r in range(len(top15_female))], top15_female.index)\n_ = plt.title('Which Countries Have The Highest Percentange of Women Respondents?', fontweight='bold')\n\nax.legend(handles=ax.lines[::len(conts.keys())+1], labels=conts.keys(), bbox_to_anchor=(1.4, 0.8))\nfor y, x in enumerate(top15_female):\n    plt.annotate(str(x) + \"% \", xy=(x, y), va='center', ha = 'right', fontsize=12, fontweight ='bold', color = 'white')\nplt.gca().invert_yaxis()\nplt.show()","98bbcc9c":"dt_jt_age = dt_nq.groupby('Q1')['Q5'].value_counts().unstack()\n\nfor jt in dt_jt_age.columns:\n    dt_jt_age[jt] = (dt_jt_age[jt]\/sum(dt_jt_age[jt])*100)\ndt_jt_age = dt_jt_age.drop(['Currently not employed'], axis = 1)\n\ncolorz = dict(zip(dt_jt_age.index, cm.Blues(np.linspace(0, 1, len(dt_jt_age.index)))[::-1]))\nax = dt_jt_age.T.plot.barh(stacked=True, figsize=(8, 10), color = colorz, \n                           edgecolor = 'white',width = 0.7)\n\nfirstcol = dt_jt_age.loc['18-21'].values\n\nfor p in ax.patches:\n    left, bottom, width, height = p.get_bbox().bounds\n    if width > 2.0:\n        if np.isin(width, firstcol):\n            ax.annotate(str(int(width)), xy=(left+width\/2, bottom+height\/2), \n                        ha='center', va='center', size = 10, color = 'white')  \n        else:\n            ax.annotate(str(int(width)), xy=(left+width\/2, bottom+height\/2), \n                        ha='center', va='center', size = 10)\n        \nax.legend(title='Age Group', bbox_to_anchor=(1, 0.5))\nax.set_ylabel('Job Title', fontweight = 'bold')\nax.set_xlabel('Portion from the Job Title (%)', fontweight = 'bold')\n\n_ = plt.title('Age Group by Job Title', fontweight = 'bold')","365d4661":"dt_jt_edu = dt_nq.groupby(['Q4','Q5']).size().unstack(level=1, fill_value=0)\ndt_jt_edu = dt_jt_edu.reindex(index =[ 'I prefer not to answer',\n                                     'No formal education past high school',\n                                     'Some college\/university study without earning a bachelor\u2019s degree',\n                                     'Professional degree',\"Bachelor\u2019s degree\", \"Master\u2019s degree\",\n                                     'Doctoral degree'\n                                    ])\n\nfor edu in dt_jt_edu.columns:\n    dt_jt_edu[edu] = (dt_jt_edu[edu]\/sum(dt_jt_edu[edu])*100)\ndt_jt_edu = dt_jt_edu.drop(['Currently not employed'], axis = 1)\n\ncolorz = dict(zip(dt_jt_edu.index,  cm.Blues(np.linspace(0.3, 1, len(dt_jt_edu.index)))[::-1]))\nax = dt_jt_edu.T.plot.barh(stacked=True, figsize=(8, 12), color = colorz, edgecolor='white',width = 0.7)\n\nfirstcol = dt_jt_edu.loc['I prefer not to answer'].values\n\nfor p in ax.patches:\n    left, bottom, width, height = p.get_bbox().bounds\n    if width > 2.0:\n        if (np.isin(width, firstcol)):\n            ax.annotate(str(int(width)), xy=(left+width\/2, bottom+height\/2),ha='center', va='center',\n                       color ='white')   \n        else:\n            ax.annotate(str(int(width)), xy=(left+width\/2, bottom+height\/2),ha='center', va='center')\n        \nax.legend(title='Formal Education', bbox_to_anchor=(1,-0.1))\nax.set_ylabel('Job Title', fontweight = 'bold')\nax.set_xlabel('Portion from the Job Title (%)', fontweight = 'bold')\n_ = plt.title('Formal Education Background by Job Title', fontweight = 'bold')","7cdb425a":"dt_jt_prog = dt_nq.groupby(['Q6','Q5']).size().unstack(level=1, fill_value=0)\ndt_jt_prog = dt_jt_prog.reindex(index =['I have never written code', '< 1 years', '1-2 years',  \n                     '3-5 years', '5-10 years', '10-20 years','20+ years'])\n\nfor jt in dt_jt_prog.columns:\n    dt_jt_prog[jt] = (dt_jt_prog[jt]\/sum(dt_jt_prog[jt])*100)\ndt_jt_prog = dt_jt_prog.drop(['Currently not employed'], axis = 1)\n\ncolorz = dict(zip(dt_jt_prog.index, cm.Blues(np.linspace(0, 1, len(dt_jt_prog.index)))[::-1]))\nax = dt_jt_prog.T.plot.barh(stacked=True, figsize=(8, 10), color = colorz, \n                            edgecolor = 'white',width = 0.7)\n\nfirstcol = dt_jt_prog.loc['I have never written code'].values\nfor p in ax.patches:\n    left, bottom, width, height = p.get_bbox().bounds\n    if width > 1.5:\n        if (np.isin(width, firstcol)):\n            ax.annotate(str(int(width)), xy=(left+width\/2, bottom+height\/2),ha='center', va='center',\n                       color ='white')   \n        else:\n            ax.annotate(str(int(width)), xy=(left+width\/2, bottom+height\/2), \n                        ha='center', va='center')\n\nax.legend(title='Years of Programming', bbox_to_anchor=(1, 0.5))\nax.set_ylabel('Job Title', fontweight = 'bold')\nax.set_xlabel('Portion from the Job Title (%)', fontweight = 'bold')\n_ = plt.title('Experience in Programming by Job Title', fontweight = 'bold')","b35ff526":"dt_jt_ml = dt_nq.groupby(['Q15','Q5']).size().unstack(level=1, fill_value=0)\ndt_jt_ml = dt_jt_ml.reindex(index =['I do not use machine learning methods',\n                                        'Under 1 year', '1-2 years', '2-3 years',\n                                        '3-4 years', '4-5 years',\n                                        '5-10 years', '10-20 years','20 or more years'])\n\nfor jt in dt_jt_ml.columns:\n    dt_jt_ml[jt] = (dt_jt_ml[jt]\/sum(dt_jt_ml[jt])*100)\n\ndt_jt_ml = dt_jt_ml.drop(['Currently not employed'], axis = 1)\n\ncolorz = dict(zip(dt_jt_ml.index, cm.Blues(np.linspace(0, 1, len(dt_jt_ml.index)))[::-1]))\nax = dt_jt_ml.T.plot.barh(stacked=True, figsize=(8, 10), color = colorz, \n                            edgecolor = 'white',width = 0.7)\n\nfirstcol = dt_jt_ml.loc['I do not use machine learning methods'].values\nfor p in ax.patches:\n    left, bottom, width, height = p.get_bbox().bounds\n    if width > 1.5:\n        if (np.isin(width, firstcol)):\n            ax.annotate(str(int(width)), xy=(left+width\/2, bottom+height\/2),ha='center', va='center',\n                       color ='white')   \n        else:\n            ax.annotate(str(int(width)), xy=(left+width\/2, bottom+height\/2), \n                        ha='center', va='center')\n\nax.legend(title='Years of Using ML Methods', bbox_to_anchor=(1, 0.5))\nax.set_ylabel('Job Title', fontweight = 'bold')\nax.set_xlabel('Portion from the Job Title (%)', fontweight = 'bold')\n_ = plt.title('Experience in Using ML Methods by Job Title', fontweight = 'bold')","4e7068b3":"world = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres'))\n\nworld['ML_state'] = 'No Data'\n\nmls_map = {\n    'No Data': 0,\n    'We have well established ML methods (i.e., models in production for more than 2 years)' : 6,\n    'No (we do not use ML methods)' : 2,\n    'We use ML methods for generating insights (but do not put working models into production)' : 4,\n    'We are exploring ML methods (and may one day put a model into production)' : 3,\n    'We recently started using ML methods (i.e., models in production for less than 2 years)' : 5,\n    'I do not know' : 1\n}\n\nfor c in dt_nq.Q3.unique():\n    state = dt_nq.loc[dt_nq.Q3 == c, 'Q22'].value_counts().index[0]\n    world.loc[world['name'] == c, 'ML_state'] = state\n\nworld.ML_state = world.ML_state.map(lambda x: mls_map[x])\n\nfig, ax = plt.subplots(1, figsize = (20,15))\nworld.plot(column='ML_state', ax=ax, categorical=True, cmap = 'Blues',\n             legend_kwds={'bbox_to_anchor':(0.3, 0.5),'fontsize':9,'title':'ML Application'}, \n             legend = True, edgecolor=\"black\")\nax.axis('off')\n\ndef replace_legend_items(legend, mapping):\n    for txt in legend.texts:\n        for k,v in mapping.items():\n            if txt.get_text() == str(k):\n                txt.set_text(v)\nreplace_legend_items(ax.get_legend(), {v: k for k, v in mls_map.items()})\n\nax.set_title('Countries by Most Frequent Current State of ML Application in Companies', fontweight = 'bold')\nplt.tight_layout()","1077ab6a":"#Q22 = ML incorporation\n#Q25 = Budget in ML\/CCS\n\ncols = [col for col in dt_nq if col.startswith('Q22') or col.startswith('Q25') ]\ndt_ent = dt_nq[cols]\ndt_ent = dt_ent.loc[(dt_ent.Q22.notnull()) & (dt_ent.Q25.notnull())]\n\n\ndt_agg_ent = dt_ent.groupby(['Q22'])['Q25'].value_counts().unstack()\ndt_agg_ent = dt_agg_ent[['$0 ($USD)', '$1-$99', '$100-$999','$1000-$9,999',\n                         '$10,000-$99,999', '$100,000 or more ($USD)']]\ndt_agg_ent = dt_agg_ent.reindex(index =[\n    'I do not know', 'No (we do not use ML methods)', \n    'We are exploring ML methods (and may one day put a model into production)',\n    'We use ML methods for generating insights (but do not put working models into production)',\n    'We recently started using ML methods (i.e., models in production for less than 2 years)',\n    'We have well established ML methods (i.e., models in production for more than 2 years)'])\n\nf,ax = plt.subplots(figsize=(8, 5))\nax = sns.heatmap(dt_agg_ent, linewidths=1, linecolor='white', annot = True, fmt='d', cmap = 'Blues') \nax.set_ylabel('ML Incorporation in The Company', fontweight = 'bold')\nax.set_xlabel('Budget Spent for ML\/Cloud Computing', fontweight = 'bold')\n_  = plt.title(\"Budget Spent for ML\/Cloud Computing\\nBased on ML Incorporation in The Company\", fontweight = 'bold')","b562ba4e":"world['DS People'] = 'No Data'\n\nfor c in dt_nq.Q3.unique():  \n    state = dt_nq.loc[dt_nq.Q3 == c, 'Q21'].value_counts().index[0]\n    world.loc[world['name'] == c, 'DS People'] = state\n    \ndsp_map = {'No Data': 0, '20+':7, '0':1, '5-9':4, '1-2':2, '3-4':3, '10-14':5, '15-19':6}\n    \nworld['DS People'] = world['DS People'].map(lambda x: dsp_map[x])\n            \nfig, ax = plt.subplots(1, figsize = (20,15))\nworld.plot(column='DS People', ax=ax, categorical=True,cmap = 'Blues',\n             legend_kwds={'bbox_to_anchor':(.15, .6),'fontsize':9,'title':'No. of Data Science People'}, \n             legend = True, edgecolor=\"black\")\n\nreplace_legend_items(ax.get_legend(), {v: k for k, v in dsp_map.items()})\nax.axis('off')\nax.set_title('Countries by Most Frequent Number of Data Science People in Companies', fontweight = 'bold')\nplt.tight_layout()","ef051577":"map_value = { '$0-999' : 0, '1,000-1,999' : 1 ,'2,000-2,999' : 2,'3,000-3,999' : 3, \n              '4,000-4,999' : 4,'5,000-7,499' : 5, '7,500-9,999' : 6, '10,000-14,999' : 7,\n              '15,000-19,999' : 8 ,'20,000-24,999': 9,'25,000-29,999' : 10,'30,000-39,999' : 11,\n              '40,000-49,999' : 12,'50,000-59,999': 13,'60,000-69,999' : 14,'70,000-79,999' : 15,\n              '80,000-89,999' :16,'90,000-99,999' : 17,'100,000-124,999' :18, '125,000-149,999': 19,\n              '150,000-199,999' :20, '200,000-249,999' : 21,'250,000-299,999' : 22,'300,000-500,000' : 23,\n              '> $500,000' : 25\n}","0801c2ec":"dt_wg = dt_nq.loc[dt_nq['Q24'].notnull()]\ndt_wg['wg_cat'] = dt_wg.Q24.apply(lambda x : map_value[x])\n\njt = []\nmeds_20 = []\n\nfor job in dt_wg.Q5.unique():\n    med_20 = int(dt_wg.loc[dt_wg[\"Q5\"] == job, \"wg_cat\"].median())\n    cat_20 = (list(map_value.keys())[list(map_value.values()).index(med_20)])\n    jt.append(job)\n    meds_20.append(med_20)\n    \n# set width of bar\nbarWidth = 0.8\n \n# Set position of bar on X axis\nr1 = np.arange(len(meds_20))\n\n# Make the plot\nplt.figure(figsize=(8,5))\nplt.barh(r1, meds_20, color='lightblue', height=barWidth, edgecolor='white')\nplt.yticks([r + 0.03 for r in range(len(meds_20))], jt)\nplt.tick_params(\n    axis='x',         \n    which='both',     \n    bottom=False,     \n    top=False,        \n    labelbottom=False)\nplt.title('Global Yearly Compensation for Each Job Title (2020)', fontweight = 'bold')\nplt.xlabel('Yearly Compensation (USD)', fontweight='bold')\nplt.ylabel('Job Title', fontweight='bold')\nfor y, x in enumerate(meds_20):\n    plt.annotate(str(list(map_value.keys())[list(map_value.values()).index(x)]) + ' ', \n                 xy=(x, y), va='center', ha = 'right', fontsize=9, fontweight ='bold')\n\n# plt.show()","37f600e5":"dt_wg_19 = dt_nq_19.loc[dt_nq_19['Q10'].notnull()]\ndt_wg_19['wg_cat'] = dt_wg_19.Q10.apply(lambda x : map_value[x])\n\njt = []\nmeds_19 = []\n\nfor job in dt_wg_19.Q5.unique():\n    med_19 = int(dt_wg_19.loc[dt_wg_19[\"Q5\"] == job, \"wg_cat\"].median())\n    cat_19 = (list(map_value.keys())[list(map_value.values()).index(med_19)])\n    jt.append(job)\n    meds_19.append(med_19)\n    \n# set width of bar\nbarWidth = 0.8\n \n# Set position of bar on X axis\nr1 = np.arange(len(meds_19))\n\n# Make the plot\nplt.figure(figsize=(8,5))\nplt.barh(r1, meds_19, color='lightblue', height=barWidth, edgecolor='white')\nplt.yticks([r + 0.03 for r in range(len(meds_19))], jt)\nplt.tick_params(\n    axis='x',         \n    which='both',     \n    bottom=False,     \n    top=False,        \n    labelbottom=False)\n\nplt.title('Global Yearly Compensation for Each Job Title (2019)', fontweight = 'bold')\nplt.xlabel('Yearly Compensation (USD)', fontweight='bold')\nplt.ylabel('Job Title', fontweight='bold')\nfor y, x in enumerate(meds_19):\n    plt.annotate(str(list(map_value.keys())[list(map_value.values()).index(x)]) + ' ', \n                 xy=(x, y), va='center', ha = 'right', fontsize=9, fontweight ='bold')\n\n# plt.show()","07b437b2":"country = []\nmeds_20 = []\n\nfor ctr in dt_nq.Q3.unique():\n    #get the country list\n    med_20 = int(dt_wg.loc[dt_wg.Q3 == ctr, \"wg_cat\"].median())\n    cat_20 = (list(map_value.keys())[list(map_value.values()).index(med_20)])\n    \n    country.append(ctr)\n    meds_20.append(med_20)\n\ndt_wg_ctry = pd.DataFrame(data = {'Country': country, '2020': meds_20})\ndt_wg_20_sort = dt_wg_ctry[['Country', '2020']].sort_values('2020', ascending = False).head(10)\n\nfig,ax = plt.subplots(figsize=(8,5))\n\nax.barh(dt_wg_20_sort['Country'], dt_wg_20_sort['2020'],color='lightblue')\nax.invert_yaxis()\n\nplt.tick_params(\n    axis='x',          \n    which='both',      \n    bottom=False,      \n    top=False,         \n    labelbottom=False)\nplt.title('Top 10 Countries with Highest Yearly Compensation', fontweight = 'bold')\nplt.xlabel('Yearly Compensation (USD)', fontweight='bold')\nplt.ylabel('Country', fontweight='bold')\n\nfor y, x in enumerate(dt_wg_20_sort['2020']):\n    plt.annotate(str(list(map_value.keys())[list(map_value.values()).index(x)]) + ' ', \n                 xy=(x, y), va='center', ha='right', fontsize=9, fontweight ='bold')","28e1ff7c":"job_task_col = [col for col in dt_nq if col.startswith('Q23') or col.startswith('Q5') ]\ndt_job_task = dt_nq[job_task_col]\n\njob_task_cols = ['Job Title', 'Q23_Part_1', 'Q23_Part_2', 'Q23_Part_3', 'Q23_Part_4',\n       'Q23_Part_5', 'Q23_Part_6', 'Q23_Part_7', 'Q23_OTHER']\n\ndt_job_task.columns = job_task_cols\n\n# Replace NaN with 0, else with 1 (?)\nfor c in job_task_cols[1:-2]:\n    dt_job_task[c] = 1 - dt_job_task[c].isnull().astype(int)\n    \ndt_agg_job_task = dt_job_task[job_task_cols[:-2]].groupby(['Job Title']).agg('sum')\ndt_agg_job_task = dt_agg_job_task.drop(['Currently not employed', 'Student'], axis = 0)\n# Set position of bar on X axis\nbarWidth = 0\n\nx = dt_agg_job_task.index #Job Title \ny = dt_agg_job_task.max(axis = 1) #Total Respondents\nlgds = dt_agg_job_task.idxmax(axis=1) #Most Important Task \nx_idx = np.arange(len(x))\n\n# Create Masks for coloring the chart\nmasks = []\n\nfor l in lgds.unique():\n    masks.append(lgds == l)\n\n\nactivities = ['Analyze and understand data to influence product or business decisions',\n              'Build and\/or run the data infrastructure that my business uses for storing, analyzing, and operationalizing data',\n              'Build prototypes to explore applying machine learning to new areas',\n              'Do research that advances the state of the art of machine learning']\ncolors = cm.Blues(np.linspace(0.4, 1, len(activities)))[::-1]\n\n# Make the plot\nf, ax = plt.subplots(figsize=(8, 6))\n\nfor i, mask in enumerate(masks):\n    plt.barh(x_idx[mask], y[mask], color=colors[i], edgecolor='white', label = activities[i])\n\n# Add xticks on the middle of the group bars\nplt.ylabel('Job Title', fontweight='bold')\nplt.xlabel('Total Respondents', fontweight='bold')\nplt.yticks([r + barWidth for r in range(len(x))], x)\nplt.title('What Role Is Considered The Most Important at Your Work?', fontweight='bold')\n\nfor z, x in enumerate(y):\n    plt.annotate('' + str(x), xy=(x, z), va='center', fontsize=9, fontweight ='bold')\n    \nax.legend(handles=ax.lines[::len(x_idx)+1], labels=activities, fontsize=8, title='Tasks', bbox_to_anchor=(1, -0.1))\nplt.show()","fa0364d1":"pl_col = [col for col in dt_nq if col.startswith('Q7') or col.startswith('Q5') ]\ndt_pl = dt_nq[pl_col]\n\npl_cols = ['Job Title', 'Python', 'R', 'SQL', 'C', 'C++', 'Java',\n       'Javascript', 'Julia', 'Swift', 'Bash', 'MATLAB', 'None', 'Other']\ndt_pl.columns = pl_cols\ndt_pl = dt_pl.drop(['None', 'Other'], axis = 1)\n\n# Replace NaN with 0, else with 1 (?)\nfor c in dt_pl.columns[1:]:\n    dt_pl[c] = 1 - dt_pl[c].isnull().astype(int)\n    \ndt_agg_pl = dt_pl.groupby(['Job Title']).agg('sum')\nfor i in dt_agg_pl.index:\n   dt_agg_pl.loc[i] = dt_agg_pl.loc[i]\/len(dt_pl.loc[dt_pl['Job Title'] == i])\n\ndt_agg_pl = dt_agg_pl.drop(['Currently not employed'], axis = 0)\n\nf,ax = plt.subplots(figsize=(10, 6))\nax = sns.heatmap(dt_agg_pl, linewidths=1, linecolor='white', annot = True, fmt='.0%', cmap = 'Blues') \nax.set_xlabel('Programming Language', fontweight = 'bold')\nax.set_ylabel('Job Title', fontweight = 'bold')\n_  = plt.title(\"Programming Language Regularly Used\\nBased on Job Title\", fontweight = 'bold')","9c208a01":"#Q17 = Algorithm regularly used\n#Q5 = Job Title\n\nalg_job_col = [col for col in dt_nq if col.startswith('Q17') or col.startswith('Q5') ]\ndt_alg_job = dt_nq[alg_job_col]\n\n#Change Col Names\nnew_cols_2 = ['Job', 'Regressions', 'Decision Tress\/Random Forest', 'Gradient Boosting Machines', \n              'Bayesian Approaches', 'Evolutionary Approaches', 'Deep Neural Networks', \n              'Convolutional Neural Networks', 'Generative Adversarial Networks', \n              'Recurrent Neural Network', 'Transformer Networks', 'None', 'Other']\ndt_alg_job.columns = new_cols_2\n\n# Replace NaN with 0, else with 1 (?)\nfor c in new_cols_2[1:-2]:\n    dt_alg_job[c] = 1 - dt_alg_job[c].isnull().astype(int)\n    \ndt_agg_alg_job = dt_alg_job[new_cols_2[:-2]].groupby(['Job']).agg('sum')\n    \nfor c in dt_agg_alg_job.index:\n    dt_agg_alg_job.loc[c] = (dt_agg_alg_job.loc[c]\/len(dt_alg_job.loc[dt_alg_job.Job == c]))\n \ndt_agg_alg_job = dt_agg_alg_job.drop(['Currently not employed'], axis = 0)\n\nf,ax = plt.subplots(figsize=(10, 6))\nax = sns.heatmap(dt_agg_alg_job, linewidths=1, linecolor='white', annot = True, fmt='.0%', cmap = 'Blues') \nax.set_xlabel('ML Algorithms', fontweight = 'bold')\nax.set_ylabel('Job Title', fontweight = 'bold')\n_  = plt.title(\"ML Algorithms Regularly Used\\nBased on Job Title\", fontweight = 'bold')","70019bec":"#Q37 = Online course platform\n#Q5 = Job Title\n\nol_job_col = [col for col in dt_nq if col.startswith('Q37') or col.startswith('Q5') ]\ndt_ol_job = dt_nq[ol_job_col]\n\n#Change Col Names\nnew_cols_3 = ['Job', 'Coursera', 'edX', 'Kaggle Learn Courses', \n              'DataCamp', 'Fast.ai', 'Udacity', \n              'Udemy', 'LinkedIn Learning', \n              'Cloud-certification Programs', 'University Courses', 'None', 'Other']\ndt_ol_job.columns = new_cols_3\n\n# Replace NaN with 0, else with 1 (?)\nfor c in new_cols_3[1:-2]:\n    dt_ol_job[c] = 1 - dt_ol_job[c].isnull().astype(int)\n    \ndt_agg_ol_job = dt_ol_job[new_cols_3[:-2]].groupby(['Job']).agg('sum')\n    \nfor c in dt_agg_ol_job.index:\n    dt_agg_ol_job.loc[c] = (dt_agg_ol_job.loc[c]\/len(dt_ol_job.loc[dt_ol_job.Job == c]))\n \ndt_agg_ol_job = dt_agg_ol_job.drop(['Currently not employed'], axis = 0)\n\nf,ax = plt.subplots(figsize=(10, 6))\nax = sns.heatmap(dt_agg_ol_job, linewidths=1, linecolor='white', annot = True, fmt='.0%', cmap = 'Blues') \nax.set_xlabel('Online Courses', fontweight = 'bold')\nax.set_ylabel('Job Title', fontweight = 'bold')\n_  = plt.title(\"Online Courses Enrolled Based on Job Title\", fontweight = 'bold')","4ed88aa4":"#Q39 = Algorithm regularly used\n#Q5 = Job Title\n\nmed_job_col = [col for col in dt_nq if col.startswith('Q39') or col.startswith('Q5') ]\ndt_med_job = dt_nq[med_job_col]\n\n#Change Col Names\nnew_cols_4 = ['Job','Twitter', 'Email newsletter', 'Reddit', 'Kaggle', \n              'Course Forums', 'YouTube', 'Podcasts', \n              'Blogs', 'Journal Publications', \n              'Slack Communities', 'None', 'Other']\ndt_med_job.columns = new_cols_4\n\n# Replace NaN with 0, else with 1 (?)\nfor c in new_cols_4[1:-2]:\n    dt_med_job[c] = 1 - dt_med_job[c].isnull().astype(int)\n    \ndt_agg_med_job = dt_med_job[new_cols_4[:-2]].groupby(['Job']).agg('sum')\n    \nfor c in dt_agg_med_job.index:\n    dt_agg_med_job.loc[c] = (dt_agg_med_job.loc[c]\/len(dt_med_job.loc[dt_med_job.Job == c]))\n \ndt_agg_med_job = dt_agg_med_job.drop(['Currently not employed'], axis = 0)\n\nf,ax = plt.subplots(figsize=(10, 6))\nax = sns.heatmap(dt_agg_med_job, linewidths=1, linecolor='white', annot = True, fmt='.0%', cmap = 'Blues') \nax.set_xlabel('Media Sources', fontweight = 'bold')\nax.set_ylabel('Job Title', fontweight = 'bold')\n_  = plt.title(\"Preferred Media Sources about Data Science Topic Based on Job Title\", fontweight = 'bold')","e01bfdb4":"### Programming Experience","a2441999":"Most of these data-related job titles consider analyzing and understanding data to influence product or business decisions as the most important part of their job.","061ab3b0":"### Programming Language","f360cde2":"### Formal Education","47a0c247":"It can be insightful to know how much an enterprise has spent their budget in Machine Learning\/Cloud Computing Service depending on their current state of Machine Learning application.","d8425178":"### Budget on Machine Learning and\/or Cloud Computing Services","f117e0d8":"# Care to Prepare","19415e1c":"This part is also using median as the measurement.","1929deed":"### The Most Important Part of The Job","515ca9e5":"### Okay, So Where Can I Be Introduced to These Stuffs?","c0e7a439":"# Know Your (Potential) Co-Workers","aca25288":"Based on the plot above, there are still a lot of employers that have not applied ML methods to their business yet (which might also reflected on their budget for ML\/Cloud computing services). For the employers that have well established ML methods, 410 of them have spent around USD 100,000 or more for ML\/Cloud computing services.","82631717":"### ML Algorithms Regularly Used","5b4f34b2":"==============================================================================","76332da4":"### Age","f67b67fd":"### Gender Representation\n\nFirst, let's explore the gender composition of data-related employees.","d126076f":"As a start, what do the data folks consider as the most important part of their work? ","a4fd4b5d":"Getting involved with data most of the time requires programming to deal with it. Let's see what programming languages are regularly used by the data folks. These numbers were derived from dividing the number of people from each job title selecting that programming language, by total population of each job title.","d902fcd8":"So these methods can help you become more familiar with Data Science","385d006f":"### Highest Paid Countries","c3657c57":"### Experience Using ML Methods","0f9bbcaa":"Data folks use Regression and Decision Trees\/Random Forest the most for any job title. The next mostly used algorithms are the neural network groups, such as DNN, CNN, and RNN. For Machine Learning Engineers, CNN is the second most regularly used ML method.","b442fa6a":"Kaggle, YouTube and Blogs are the most preferred media sources for data science topic for any job title, while Journal Publications are also often referred by Research Scientist.","f1c916d1":"For this part, the measurement is using median. Let's see how much each job title earns for a living, globally.","922b0a29":"### Number of People Responsible for Data Science Workloads in The Company","3fe552b5":"Based in this dataset, most of the data fellows are millenials. For nearly all data-related job titles, you will find these folks are most frequently 22-29 years old, but for Product Manager and Research Scientist positions, they are mostly 25-34 years old.","18a151c9":"### Current State of ML Application in Enterprises","b397a5f2":"Malaysia has the highest percentage of women respondents in 2020 and most of the countries in this list are from Asia. Ireland and Canada, each, is the country with the highest percentage of women respondents from Europe and America, respectively.","4c7430a1":"### Yearly Compensation by Job Title","d25eee29":"So, you now know at a gist about the data folks and current state of your potential employers. What's next? Here are several things that might help you become more ready to roll.","83b928e9":"Generally, 3-5 years is the most frequent period for programming experience, but there are still some people (with big percentage from each job title) have less than 3 years of programming experience. The most frequent period of programming experience for Data Analyst is 1-2 years, while for business analyst is less than 1 year.","6e3596dc":"Machine Learning is now widely used to solve some targets which requires data. These machine learning methods might help to get prepared of what to learn when we are assigned to solve data-related targets. These numbers were also derived from dividing the number of people from each job title selecting that algorithm, by total population of each job title.","69824391":"Respondents from US, Australia & some European countries mostly work in the companies where ML methods have been well established. In Asia, the companies where the respondents work are still in early stage at applying ML methods.","0dfebfa4":"Data Scientists & Data Engineers have the highest median yearly compensation (among the working level with similar job title). \nNow, let's see the yearly compensation in 2019.","2b52a47a":"# Getting to Know Better Your Employers\n\n","5c75628f":"Respondents from US, India, South Africa, and some European countries countries mostly work in the companies that employ 20+ people for data science roles. From this dataset, respondents from other countries work for companies that have smaller data science team.","e0d9a4f7":"In general, less than 1 year is the most frequent value of experience in using ML Methods, except for Data Scientist, Data Engineer, Machine Learning Engineer and Database Engineer. Most of the respondents with the first three job titles have 1-2 years of experience using ML methods, while 30% Database Engineers have not used any ML methods yet.","10b17748":"In 2019, median yearly compensation for Data Scientist is the same as Product\/Project Manager's. The values of yearly compensation in 2019 was higher than in 2020 for nearly every job title.","cac8f60c":"Seen from the plot above, most of the respondents are men, but let's see which countries have the highest proportion of women as the respondents.","7a85da25":"When pursuing an employment in data-related job, one might wonder about the expected compensation as data professionals. Not only that, but information about the state of machine learning\/data science application of the prospective companies also can be insightful for some job seekers.","fbeefd12":"Most of these data-related job titles use Python as the most regulary used programming language. Meanwhile, Statisticians mostly use R and Database Engineers use SQL, and Python is the second most regularly used programming language for both job titles.","023dbb29":"It can be concluded that most of the data folks have earned Master's degree for nearly every job title, while most of the Research Scientists have Doctoral degree.","93463f80":"Data folks relied on Coursera, Kaggle Learn Courses, and Udemy as their online courses to enrich themselves in Data Science."}}