{"cell_type":{"483e7878":"code","5f4217f1":"code","7fb6c94e":"code","fde3528f":"code","854e13f1":"code","fc89dce8":"code","dff17153":"code","2b38919c":"code","4d33c8bd":"code","58ac51bc":"code","8b945d80":"code","c586de7c":"code","b466a6bb":"code","1c53fd7a":"code","c413ca88":"markdown","5ad9a76e":"markdown","0f1018f3":"markdown","92fdb4ed":"markdown","0910c6c6":"markdown","b1fce2d5":"markdown","7589ded7":"markdown","2d680c60":"markdown"},"source":{"483e7878":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport os\nimport gc\nimport time\nimport math\nimport datetime\nfrom math import log, floor\nfrom sklearn.neighbors import KDTree\n\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nfrom sklearn.utils import shuffle\nfrom tqdm.notebook import tqdm as tqdm\n\nimport seaborn as sns\nfrom matplotlib import colors\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import Normalize\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nimport pywt\nfrom statsmodels.robust import mad\n\nimport scipy\nimport statsmodels\nfrom scipy import signal\nimport statsmodels.api as sm\nfrom fbprophet import Prophet\nfrom scipy.signal import butter, deconvolve\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","5f4217f1":"#Using sales_train_evaluation as Dataset instead of sales_train_validation as it contains validation data[d_1914 - d_1941]\nsales = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sales_train_evaluation.csv')\nsales.name = 'sales'\ncalendar = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/calendar.csv')\ncalendar.name = 'calendar'\nprices = pd.read_csv('\/kaggle\/input\/m5-forecasting-accuracy\/sell_prices.csv')\nprices.name = 'prices'","7fb6c94e":"\nd_cols = [c for c in sales.columns if 'd_' in c]\npast_sales = sales.set_index('id')[d_cols] \\\n    .T \\\n    .merge(calendar.set_index('d')['date'],\n           left_index=True,\n           right_index=True,\n            validate='1:1') \\\n    .set_index('date')\n\nstore_list = prices['store_id'].unique()\nmeans = []\nfig = go.Figure()\nfor s in store_list:\n    store_items = [c for c in past_sales.columns if s in c]\n    data = past_sales[store_items].sum(axis=1).rolling(30).mean()\n    means.append(np.mean(past_sales[store_items].sum(axis=1)))\n    fig.add_trace(go.Scatter(x=np.arange(len(data)), y=data, name=s))\n    \nfig.update_layout(yaxis_title=\"Sales\", xaxis_title=\"Time\", title=\"Rolling Average Sales vs. Time (per store)\")","fde3528f":"df = pd.DataFrame(np.transpose([means, store_list]))\ndf.columns = [\"Mean sales\", \"Store name\"]\npx.bar(df, y=\"Mean sales\", x=\"Store name\", color=\"Store name\", title=\"Mean sales vs. Store name\")","854e13f1":"train_dataset = sales[d_cols[-300:-30]]\nval_dataset = sales[d_cols[-30:]]","fc89dce8":"sales.head()","dff17153":"fig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"), showlegend=False,\n               name=\"Original signal\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Train (blue) vs. Validation (orange) sales\")\nfig.show()","2b38919c":"predictions = []\nfor i in range(len(val_dataset.columns)):\n    if i == 0:\n        predictions.append(np.mean(train_dataset[train_dataset.columns[-30:]].values, axis=1))\n    if i < 31 and i > 0:\n        predictions.append(0.5 * (np.mean(train_dataset[train_dataset.columns[-30+i:]].values, axis=1) + \\\n                                  np.mean(predictions[:i], axis=0)))\n    if i > 31:\n        predictions.append(np.mean([predictions[:i]], axis=1))\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\nerror_avg = np.linalg.norm(predictions[:100] - val_dataset.values[:100])\/len(predictions[0])\n#Moving Average not need much time so I can make prediction over 30490 items\n#But to compare error with Prophet, the error will be calculated from the first 100 items","4d33c8bd":"pred_1 = predictions[0]\npred_2 = predictions[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70, 100), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Moving average\")\nfig.show()","58ac51bc":"dates = [\"2016-4-\" + str(i) for i in range(1, 31)]\npredictions = []\n#Prophet take some time to predict so I will predict only first 100 items\nfor row in tqdm(train_dataset[train_dataset.columns[-30:]].values[:100]):\n    df = pd.DataFrame(np.transpose([dates, row]))\n    df.columns = [\"ds\", \"y\"]\n    model = Prophet(daily_seasonality=True)\n    model.fit(df)\n    future = model.make_future_dataframe(periods=30)\n    forecast = model.predict(future)[\"yhat\"].loc[30:].values\n    predictions.append(forecast)\npredictions_prophet = np.array(predictions).reshape((-1, 30))\nerror_prophet = np.linalg.norm(predictions[:100] - val_dataset.values[:100])\/len(predictions[0])","8b945d80":"pred_1 = predictions_prophet[0]\npred_2 = predictions_prophet[1]\npred_3 = predictions[2]\n\nfig = make_subplots(rows=3, cols=1)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(70), mode='lines', y=train_dataset.loc[0].values, marker=dict(color=\"dodgerblue\"),\n               name=\"Train\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=val_dataset.loc[0].values, mode='lines', marker=dict(color=\"darkorange\"),\n               name=\"Val\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=pred_1, mode='lines', marker=dict(color=\"seagreen\"),\n               name=\"Pred\"),\n    row=1, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270), mode='lines', y=train_dataset.loc[1].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=val_dataset.loc[1].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=pred_2, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=2, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270), mode='lines', y=train_dataset.loc[2].values, marker=dict(color=\"dodgerblue\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=val_dataset.loc[2].values, mode='lines', marker=dict(color=\"darkorange\"), showlegend=False),\n    row=3, col=1\n)\n\nfig.add_trace(\n    go.Scatter(x=np.arange(270, 300), y=pred_3, mode='lines', marker=dict(color=\"seagreen\"), showlegend=False,\n               name=\"Denoised signal\"),\n    row=3, col=1\n)\n\nfig.update_layout(height=1200, width=800, title_text=\"Prophet\")\nfig.show()","c586de7c":"error = [error_avg, error_prophet]\nnames = [\"Moving average\", \"Prophet\"]\ndf = pd.DataFrame(np.transpose([error, names]))\ndf.columns = [\"RMSE Loss\", \"Model\"]\npx.bar(df, y=error, x=\"Model\", color=\"Model\", title=\"RMSE Loss vs. Model\",)\n","b466a6bb":"predictions = []\nfor i in range(28):\n    if i == 0:\n        predictions.append(np.mean(sales[sales.columns[-30:]].values, axis=1))\n    if i < 31 and i > 0:\n        predictions.append(0.5 * (np.mean(sales[sales.columns[-30+i:]].values, axis=1) + \\\n                                  np.mean(predictions[:i], axis=0)))\n    if i > 31:\n        predictions.append(np.mean([predictions[:i]], axis=1))\n    \npredictions = np.transpose(np.array([row.tolist() for row in predictions]))\n\ncolumn_name=[f'F{i}' for i in range(1, 29)]\ndf = pd.DataFrame (predictions, columns = [column_name])\ndf.columns = [f'F{i}' for i in range(1, 29)]\nvalidation_ids = sales['id'].values\nevaluation_ids = [i.replace('evaluation', 'validation') for i in validation_ids]\nids = np.concatenate([evaluation_ids,validation_ids])\npredictions = pd.DataFrame(ids, columns=['id'])\ndf = pd.concat([df] * 2).reset_index(drop=True)\npredictions = pd.concat([predictions, df], axis=1)\npredictions.to_csv('submission.csv', index=False)","1c53fd7a":"predictions","c413ca88":"Facebook Prophet capture sales cycle with strong upward trend.","5ad9a76e":"# Submission <a id=\"4\"><\/a>","0f1018f3":"# Modeling <a id=\"3\"><\/a>\n\nI will forcast the sales data using methods, namely: **Moving Average and Prophet**\n\n## Train\/Val split <a id=\"3.1\"><\/a>\n\nTo lower time consumption as the dataset is large. I will use the last 30 days' sales as the validation data and the sales of the 270 days before that as the training data.","92fdb4ed":"The above plot compares the sales distribution for each store in the dataset. The stores in California seem to have the highest variance in sales and also highest mean, which might indicate that some places in California grow significantly faster than others.","0910c6c6":"Moving Average has lower RMSE loss which mean it perform better. Note that Prophet could be improved by using hyperparameter tuning.","b1fce2d5":"# EDA <a id=\"2\"><\/a>","7589ded7":"# Acknowledgements <a id=\"1\"><\/a>\n[Time Series Forecasting-EDA, FE & Modelling](https:\/\/www.kaggle.com\/anshuls235\/time-series-forecasting-eda-fe-modelling) by ANSHUL SHARMA  \n\n[M5 Competition : EDA + Models](https:\/\/www.kaggle.com\/tarunpaparaju\/m5-competition-eda-models\/notebook#Takeaways) by TARUN PAPARAJU","2d680c60":"In the above graph, we can see the large disparity in sales among stores. The sales curves almost never intersect each other. The sales oscillate like a sine wave about a certain mean value, but this mean value has an upward linear trend.\nThis trend is reminiscent of the business cycle, where economies have short-term oscillatory fluctuations but grow linearly in the long run."}}