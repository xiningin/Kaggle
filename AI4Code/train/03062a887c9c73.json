{"cell_type":{"f9268f6b":"code","39832840":"code","9871abc0":"code","38019aca":"code","91d92990":"code","a93858e1":"code","7552568b":"code","55b82710":"code","2afe364e":"code","873366ec":"code","df81243a":"code","6b0b228a":"code","fffd2b60":"code","665934d9":"code","829ab6f1":"code","170faff3":"code","9247ec55":"code","9ec41ec1":"code","cbab809f":"code","39a395f8":"code","eb4d2555":"code","121ec53c":"code","402bf0fe":"code","9387dfca":"code","31192654":"code","01b6259d":"code","81f5912b":"code","646a5efa":"code","96cf21a0":"code","cfc9f2c9":"code","d9e48679":"code","e7dc5576":"markdown","36fec002":"markdown","8862e9ef":"markdown","1e21b83d":"markdown","c7a425df":"markdown","4821213b":"markdown","70ee051e":"markdown","1f088227":"markdown","b39dc1a4":"markdown","09af87e6":"markdown","03e13015":"markdown","226b4160":"markdown","bfddc5fa":"markdown","ea7d1fcd":"markdown","a274b988":"markdown","5aa71ba8":"markdown","df23c50e":"markdown","233de207":"markdown","2fd34f7c":"markdown","42651212":"markdown","c9b1790e":"markdown"},"source":{"f9268f6b":"# 786\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport plotly.express as px\nimport plotly.graph_objs as go\n\nimport plotly as py\nfrom plotly import tools\nfrom plotly.offline import iplot\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","39832840":"dt = pd.read_csv(\"..\/input\/pakistans-largest-ecommerce-dataset\/Pakistan Largest Ecommerce Dataset.csv\", parse_dates=[\"created_at\", \"Working Date\"], low_memory=False)\nprint(\"Data Dimensions are: \", dt.shape)\nprint(\"Columns: \", dt.columns)","9871abc0":"print(dt.info())","38019aca":"dt = dt.iloc[:, :-5]\ndt = dt.dropna(how = 'all') ","91d92990":"dt.rename(columns = {' MV ':'MV'}, inplace = True)\ndt.columns","a93858e1":"dt['Customer ID'] = dt['Customer ID'].astype(str)\ndt['item_id'] = dt['item_id'].astype(str)\ndt['qty_ordered'] = dt['qty_ordered'].astype(int)  \ndt['Year'] = dt['Year'].astype(int)  \ndt['Month'] = dt['Month'].astype(int)  \n# dt['MV'] = dt['MV'].astype(float, errors = 'raise')","7552568b":"dt.tail()","55b82710":"dt.describe()","2afe364e":"dt.describe(include=['object', 'bool'])","873366ec":"dt = dt.sort_values('created_at')","df81243a":"dtg = dt.groupby('created_at')['grand_total'].sum().reset_index()\ndtq = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\ndtd = dt.groupby('created_at')['discount_amount'].sum().reset_index()\n# comput count for non numeric values\ndts = dt.groupby('created_at')['sku'].count().reset_index() \ndtst = dt.groupby('created_at')['status'].count().reset_index()","6b0b228a":"# new data set\np = pd.DataFrame(dtg) \np['qty_ordered'] = dtq['qty_ordered']\np['discount_amount'] = dtd['discount_amount']\np['sku'] = dts['sku']\np['status'] = dtst['status']\n#Cumulative Sum\np['cum_grand_total'] = p['grand_total'].cumsum()\np['cum_qty_ordered'] = p['qty_ordered'].cumsum()\np['cum_discount_amount'] = p['discount_amount'].cumsum()\np['cum_sku_cnt'] = p['sku'].cumsum()\np['cum_status_cnt'] = p['status'].cumsum()\n","fffd2b60":"# Date features\np['Dateofmonth'] = p['created_at'].dt.day\np['Month'] = p['created_at'].dt.month\np['Week'] = p['created_at'].dt.week\np['Dayofweek'] = p['created_at'].dt.dayofweek # 0 = monday.\np['Weekdayflg'] = (p['Dayofweek'] \/\/ 5 != 1).astype(float)\np['Month'] = p['created_at'].dt.month\np['Quarter'] = p['created_at'].dt.quarter\np['Dayofyear'] = p['created_at'].dt.dayofyear","665934d9":"p.head()","829ab6f1":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['grand_total'],\n                    mode='lines+markers',\n                    name='grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['discount_amount'],\n                    mode='lines+markers',\n                    name='discount_amount'))\nfig.show()","170faff3":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['cum_grand_total'],\n                    mode='lines+markers',\n                    name='xcum_grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['cum_discount_amount'],\n                    mode='lines+markers',\n                    name='cum_discount_amount'))\nfig.show()","9247ec55":"n = dt.groupby(['Year' ,'status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"Year\", y=\"grand_total\", color=\"status\", title=\"Long-Form Input\")\nfig.show()","9ec41ec1":"n = dt.groupby(['Year' ,'payment_method'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"Year\", y=\"grand_total\", color=\"payment_method\", title=\"Long-Form Input\")\nfig.show()","cbab809f":"n = dt.groupby(['status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, y='grand_total', x='status', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","39a395f8":"n = dt.groupby(['created_at' ,'status'])['grand_total'].sum().reset_index()\npx.box(n, y=\"grand_total\", color = \"status\")","eb4d2555":"n = dt.groupby(['category_name_1'])['grand_total'].sum().reset_index()\nfig = px.bar(n, y='grand_total', x='category_name_1', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","121ec53c":"n = dt.groupby(['category_name_1','status'])['grand_total'].sum().reset_index()\nfig = px.bar(n, x=\"category_name_1\", y=\"grand_total\",\n             color='status', barmode='group')\nfig.show()","402bf0fe":"n = dt.groupby(['payment_method'])['grand_total'].sum().reset_index()\n\nfig = px.bar(n, y='grand_total', x='payment_method', text='grand_total')\nfig.update_traces(texttemplate='%{text:.2s}', textposition='outside')\nfig.update_layout(uniformtext_minsize=8, uniformtext_mode='hide')\nfig.show()","9387dfca":"ord_cncl_ind = dt[dt['status'] == 'canceled' ].index\ndt.drop(ord_cncl_ind , inplace=True)\ndt.shape","31192654":"dtg = dt.groupby('created_at')['grand_total'].sum().reset_index()\ndtq = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\ndtd = dt.groupby('created_at')['discount_amount'].sum().reset_index()\n# comput count for non numeric values\ndts = dt.groupby('created_at')['sku'].count().reset_index() \ndtst = dt.groupby('created_at')['status'].count().reset_index()\n\n# new data set\np = pd.DataFrame(dtg) \np['qty_ordered'] = dtq['qty_ordered']\np['discount_amount'] = dtd['discount_amount']\np['sku'] = dts['sku']\np['status'] = dtst['status']\n#Cumulative Sum\np['cum_grand_total'] = p['grand_total'].cumsum()\np['cum_qty_ordered'] = p['qty_ordered'].cumsum()\np['cum_discount_amount'] = p['discount_amount'].cumsum()\np['cum_sku_cnt'] = p['sku'].cumsum()\np['cum_status_cnt'] = p['status'].cumsum()\n","01b6259d":"fig = go.Figure()\n\n# Add traces\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['grand_total'],\n                    mode='lines+markers',\n                    name='grand_total'))\nfig.add_trace(go.Scatter(x=p['created_at'], y=p['discount_amount'],\n                    mode='lines+markers',\n                    name='discount_amount'))\nfig.show()","81f5912b":"fig = px.scatter(p, x= 'created_at', y = 'grand_total', trendline = \"ols\")\nfig.show()\nresults = px.get_trendline_results(fig)\nresults","646a5efa":"n = dt.groupby('created_at')['grand_total'].sum().reset_index()\npx.density_contour(n,x=\"created_at\",y=\"grand_total\",marginal_x=\"histogram\",marginal_y=\"histogram\")","96cf21a0":"# Graph for quantity\nn = dt.groupby('created_at')['qty_ordered'].sum().reset_index()\npx.density_contour(n,x=\"created_at\",y=\"qty_ordered\",marginal_x=\"histogram\",marginal_y=\"histogram\", title=\"no of orders\")","cfc9f2c9":"n = dt.groupby(['created_at' ,'category_name_1', 'status'])['qty_ordered'].sum().reset_index()\npx.scatter(n, x=\"created_at\", y=\"qty_ordered\", color=\"status\", size=\"qty_ordered\", hover_data=['category_name_1','status'])\n","d9e48679":"n = dt.groupby(['created_at' ,'status'])['qty_ordered'].sum().reset_index()\npx.line(n, x=\"created_at\", y=\"qty_ordered\", color=\"status\", )","e7dc5576":"## Growth Analysis","36fec002":"## Daily Sales vs. Discount","8862e9ef":"## Payment Methods\n","1e21b83d":"### Density Graph","c7a425df":"**In above graphs we can observe that sales boosted when discount offer initiated.**\n\nBut this can we tempting without looking into item status.","4821213b":"### Order Status","70ee051e":"As we can see above, few columns are not in correct data type. We need to perform casting.","1f088227":"### Cumulative Sums of Grand_Total and discount_amount","b39dc1a4":"The column MV contains leading and trailing space that might cause problem. We will rename it first.","09af87e6":"Data contains 1048574 rows but maximum columns contain 584524 records. \n\nHalf of row are completely empty, so we will drop them. The tricky part is we can't drop all na rows as actual data set  also contain few NA entries. We need to keep them.\nWe will drop NA values where all entries are Null. \n\nAlso, we will drop last 5 empty columns.","03e13015":"To be Continue...\n\n**You can fork this kernel and continue your analysis.**\n\n**Way Forward**\n* Data Cleansing at SKU and Status columns\n* Segregate analysis by dropping Cancel status orders. \n* Quarterly, Monthly, Weekday and Weekend Analysis\n* Seasonality Analysis\n* What are the Trends in Top 10 Categories\n* Weekly Moving Average Analysis","226b4160":"# Exploratory Analysis to Understand Data","bfddc5fa":"## A quick view of Regession model (OLS)","ea7d1fcd":"# Data Loading & Preparation","a274b988":"As we analysed above, we need to drop cancelled orders\n","5aa71ba8":"### Let's look into summary of data\nData Summary of non-numeric data","df23c50e":"Data Summary of non-numeric data","233de207":"### Category Type","2fd34f7c":"### Few new features extracted","42651212":"Recomputing daily figures","c9b1790e":"**In each year order cancellation is high. We need to drop Cancelled items and recheck sales growth**\n\nNote: We will do this after looking into other data points. "}}