{"cell_type":{"f1b5dd11":"code","699a6f84":"code","3691f9ae":"code","09787eb8":"code","0d909a91":"code","a767d4ac":"code","aeafebef":"code","7b1c2586":"code","52c87db7":"code","3eba164d":"code","ebebaf93":"markdown"},"source":{"f1b5dd11":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","699a6f84":"from sklearn.model_selection import train_test_split\nfrom sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\n\n# Import training data\ntrain_data = pd.read_csv('..\/input\/cs-4375-term-project-classification\/train.csv')\nprint(\"Training data shape =\", train_data.shape)\ntrain_data.head()","3691f9ae":"# Slice the dataset into feature set and classification\nX = train_data.iloc[:, :-1]\ny = train_data['Class']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25)\n\n# evaluate a given model using cross-validation\ndef evaluate_model(model, X, y):\n    # define the evaluation procedure\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=0)\n    # evaluate the model and collect the results\n    scores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\n    return scores","09787eb8":"# Classify using k Nearest Neighbors algorithm \nfrom sklearn import neighbors \nn_neighbors = 3\n\nfor weights in ['uniform', 'distance']:\n    # create an instance of K Neighbours Classifier and fit the data.\n    kNN = neighbors.KNeighborsClassifier(n_neighbors, weights=weights)\n    \n    # evaluate the model \n    scores = evaluate_model(kNN, X, y)\n    print(\"{} kNN model accuracy: {}\".format(weights, np.mean(scores)))","0d909a91":"# Classify using Random Forests Learning \nfrom sklearn.ensemble import RandomForestClassifier\n\nrand_forest = RandomForestClassifier(max_depth=2, random_state=0)\n\n# evaluate the model \nscores = evaluate_model(rand_forest, X, y)\nprint(\"Random forest model accuracy: {}\".format(np.mean(scores)))","a767d4ac":"# Classify using Decision Tree Learning \nfrom sklearn import tree\n\ndesc_tree = tree.DecisionTreeClassifier()\n\n# evaluate the model \nscores = evaluate_model(desc_tree, X, y)\nprint(\"Decision tree model accuracy: {}\".format(np.mean(scores)))","aeafebef":"# Classify using Naive Bayes with Gaussian\nfrom sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\n\n# evaluate the model \nscores = evaluate_model(gnb, X, y)\nprint(\"Naive Bayes model accuracy: {}\".format(np.mean(scores)))","7b1c2586":"# # Classify using Gaussian Process\n# from sklearn.gaussian_process import GaussianProcessClassifier\n# from sklearn.gaussian_process.kernels import RBF\n\n# kernel = 1.0 * RBF(1.0)\n# gpc = GaussianProcessClassifier(kernel=kernel, random_state=0).fit(X_train, y_train)\n\n# # evaluate the model \n# y_pred = gpc.predict(X_test)\n# print(\"Gaussian Process model accuracy: {}\".format(metrics.accuracy_score(y_test, y_pred)))","52c87db7":"# Classify using default AdaBoost with Decision Tree\nfrom sklearn.ensemble import AdaBoostClassifier\n\nbase = tree.DecisionTreeClassifier(max_depth=5)\nAB_classifier = AdaBoostClassifier(base_estimator=base, n_estimators=100, random_state=0)\n\n# evaluate the model \nscores = evaluate_model(AB_classifier, X, y)\nprint(\"AdaBoost (Decision Tree) model accuracy: {}\".format(np.mean(scores)))","3eba164d":"# Classify using Gradient Boosting \nfrom sklearn.ensemble import GradientBoostingClassifier\n\nGD_boost = GradientBoostingClassifier(random_state=0)\n\n# evaluate the model \nscores = evaluate_model(GD_boost, X, y)\nprint(\"Gradient Boosting model accuracy: {}\".format(np.mean(scores)))","ebebaf93":"## Classify Using Random Forest Classifier \n[Parameter tuning guide](http:\/\/https:\/\/medium.com\/all-things-ai\/in-depth-parameter-tuning-for-random-forest-d67bb7e920d)"}}