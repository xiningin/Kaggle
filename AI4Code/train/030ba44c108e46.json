{"cell_type":{"c4840bf8":"code","6227ccd2":"code","f7ddba32":"code","252ef54f":"code","2a660b7c":"code","66cef9dc":"code","27f9d836":"code","cb89227f":"code","619f84de":"markdown","375f8b53":"markdown","51710897":"markdown","e7394974":"markdown","e3d05d5c":"markdown"},"source":{"c4840bf8":"import os\nimport cv2\nimport math\n\nimport numpy as np # linear algebra\nfrom PIL import Image\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt","6227ccd2":"label_df = pd.read_csv('..\/input\/train.csv')\nsubmission_df = pd.read_csv('..\/input\/sample_submission.csv')\nlabel_df.head()","f7ddba32":"label_df['category_id'].value_counts()[1:16].plot(kind='bar')","252ef54f":"def display_samples(df, columns=4, rows=3):\n    fig=plt.figure(figsize=(5*columns, 3*rows))\n\n    for i in range(columns*rows):\n        image_path = df.loc[i,'file_name']\n        image_id = df.loc[i,'category_id']\n        img = cv2.imread(f'..\/input\/train_images\/{image_path}')\n        fig.add_subplot(rows, columns, i+1)\n        plt.title(image_id)\n        plt.imshow(img)\n\ndisplay_samples(label_df)","2a660b7c":"def get_pad_width(im, new_shape, is_rgb=True):\n    pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n    t, b = math.floor(pad_diff[0]\/2), math.ceil(pad_diff[0]\/2)\n    l, r = math.floor(pad_diff[1]\/2), math.ceil(pad_diff[1]\/2)\n    if is_rgb:\n        pad_width = ((t,b), (l,r), (0, 0))\n    else:\n        pad_width = ((t,b), (l,r))\n    return pad_width\n\ndef pad_and_resize(image_path, dataset, pad=False, desired_size=32):\n    img = cv2.imread(f'..\/input\/{dataset}_images\/{image_path}.jpg')\n    \n    if pad:\n        pad_width = get_pad_width(img, max(img.shape))\n        padded = np.pad(img, pad_width=pad_width, mode='constant', constant_values=0)\n    else:\n        padded = img\n    \n    resized = cv2.resize(padded, (desired_size,)*2).astype('uint8')\n    \n    return resized","66cef9dc":"%%time\ntrain_resized_imgs = []\ntest_resized_imgs = []\n\nfor image_id in label_df['id']:\n    train_resized_imgs.append(\n        pad_and_resize(image_id, 'train')\n    )\n\nfor image_id in submission_df['Id']:\n    test_resized_imgs.append(\n        pad_and_resize(image_id, 'test')\n    )","27f9d836":"X_train = np.stack(train_resized_imgs)\nX_test = np.stack(test_resized_imgs)\n\ntarget_dummies = pd.get_dummies(label_df['category_id'])\ntrain_label = target_dummies.columns.values\ny_train = target_dummies.values\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)","cb89227f":"# No need to save the IDs of X_test, since they are in the same order as the \n# ID column in sample_submission.csv\nnp.save('X_train.npy', X_train)\nnp.save('X_test.npy', X_test)\nnp.save('y_train.npy', y_train)","619f84de":"## Saving","375f8b53":"## Preprocessing","51710897":"## Exploration","e7394974":"# Reducing Image Sizes to 32x32\n\nI think that some of you will be interested in trying smaller models to get started (e.g. a CNN with only a few connected layers). However, those datasets seem to be really big (150k test images and 195k training images) as well as high resolution. Just trying to create a GPU kernel and preprocessing the images seem to take a while. \n\nTherefore, I created this kernel in order to reduce the image to the smallest usable size (i.e. 32x32, similar to CIFAR10\/100). Please feel free to use this as an output to your exploration models, or to modify this for other image sizes.\n\nLet me know your thoughts!\n\n### References\n* https:\/\/www.kaggle.com\/xhlulu\/exploration-and-preprocessing-for-keras-224x224","e3d05d5c":"## Pad and resize all the images"}}