{"cell_type":{"e5dff918":"code","2329cd7c":"code","600cfc29":"code","4e923334":"code","cc678ed1":"code","0d38fa80":"code","94fcedf8":"code","853d32d2":"code","cb84d927":"code","f4c6d009":"code","b2f96b2c":"code","0ae68f63":"code","99dada1a":"code","625f804f":"code","9b5db7ec":"code","92e51f39":"code","75cc986a":"code","81ef9cbf":"code","3f8af0ae":"code","18f3d2b9":"code","b8496c35":"code","6ca9fea8":"code","e823b790":"code","bc4341fd":"code","c4cb67b2":"code","4065faf9":"code","886ae07e":"code","e33643a7":"code","7b7b5533":"code","b58d42cb":"code","7b74c6fb":"code","207c6030":"code","4800bdae":"code","df241f71":"markdown","5fdee2f2":"markdown","953ff9de":"markdown","223945e8":"markdown","b8468710":"markdown","5ab3ec0b":"markdown","aeee3b99":"markdown","0e984668":"markdown","0101c61a":"markdown","6483d510":"markdown","e20270e8":"markdown","f1d90853":"markdown","c5251bb5":"markdown","1a3cecb3":"markdown","b0822b30":"markdown","3ef686b3":"markdown"},"source":{"e5dff918":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","2329cd7c":"df = pd.read_csv(\"\/kaggle\/input\/fake-news\/train.csv\")\ndf","600cfc29":"## Get the Independent Features\nX=df.drop('label',axis=1)","4e923334":"X.head()","cc678ed1":"## Get the Dependent features\ny=df['label']","0d38fa80":"y.head()","94fcedf8":"df=df.dropna()","853d32d2":"messages=df.copy()","cb84d927":"messages.reset_index(inplace=True)\nmessages.head(10)","f4c6d009":"messages['title'][6]","b2f96b2c":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['title'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    corpus.append(review)","0ae68f63":"corpus[:5]","99dada1a":"messages.shape","625f804f":"y=messages['label']","9b5db7ec":"from sklearn.feature_extraction.text import CountVectorizer\ncv = CountVectorizer(max_features=5000,ngram_range=(1,3))\nX = cv.fit_transform(corpus).toarray()","92e51f39":"X.shape","75cc986a":"X","81ef9cbf":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","3f8af0ae":"cv.get_feature_names()[:10]","18f3d2b9":"cv.get_params()","b8496c35":"from sklearn.naive_bayes import MultinomialNB\nclassifier = MultinomialNB()","6ca9fea8":"from sklearn import metrics\nimport numpy as np\nimport itertools\nimport seaborn as sns","e823b790":"classifier.fit(X_train,y_train)\npred = classifier.predict(X_test)\nscore = metrics.accuracy_score(y_test,pred)\nprint(\"accuracy: %0.4f\" % score)\ncm = metrics.confusion_matrix(y_test,pred)\nsns.heatmap(cm, annot=True,fmt=\"2g\")","bc4341fd":"previous_score=0\nfor alpha in np.arange(0,1,0.1):\n    sub_classifier=MultinomialNB(alpha=alpha)\n    sub_classifier.fit(X_train,y_train)\n    y_pred=sub_classifier.predict(X_test)\n    score = metrics.accuracy_score(y_test, y_pred)\n    if score>previous_score:\n        classifier=sub_classifier\n    print(\"Alpha: {}, Score : {}\".format(alpha,score))","c4cb67b2":"feature_names = cv.get_feature_names()","4065faf9":"sorted(zip(classifier.coef_[0],feature_names), reverse=True)[:10]","886ae07e":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_v=TfidfVectorizer(max_features=5000,ngram_range=(1,3))\nX=tfidf_v.fit_transform(corpus).toarray()","e33643a7":"X.shape","7b7b5533":"X","b58d42cb":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","7b74c6fb":"classifier.fit(X_train,y_train)\npred = classifier.predict(X_test)\nscore = metrics.accuracy_score(y_test,pred)\nprint(\"accuracy: %0.4f\" % score)\ncm = metrics.confusion_matrix(y_test,pred)\nsns.heatmap(cm, annot=True,fmt=\"2g\")","207c6030":"from sklearn.linear_model import PassiveAggressiveClassifier\nlinear_clf = PassiveAggressiveClassifier(max_iter=50)","4800bdae":"linear_clf.fit(X_train,y_train)\npred = linear_clf.predict(X_test)\nscore = metrics.accuracy_score(y_test,pred)\nprint(\"accuracy: %0.4f\" % score)\ncm = metrics.confusion_matrix(y_test,pred)\nsns.heatmap(cm, annot=True,fmt=\"2g\")","df241f71":"![image.png](attachment:image.png)","5fdee2f2":"### We'll check the accuracy for different alphas","953ff9de":"![image.png](attachment:image.png)","223945e8":"![image.png](attachment:image.png)","b8468710":"# TFIDF Vectorizer","5ab3ec0b":"# Stemming","aeee3b99":"## Count Vectorizer","0e984668":"## Passive Aggresive Classifier","0101c61a":"## Let's look at some basic vectorizers","6483d510":"![image.png](attachment:image.png)","e20270e8":"### Find the most \"real\" news","f1d90853":"## Multinomial Naive Bayes","c5251bb5":"## And on the go we'll plot confusion matrices to check accuracy","1a3cecb3":"![image.png](attachment:image.png)","b0822b30":"### It's similar to CountVectorizer but higher weights are given to uncommon words, as they have more influence over classification","3ef686b3":"![image.png](attachment:image.png)"}}