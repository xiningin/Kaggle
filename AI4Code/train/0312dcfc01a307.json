{"cell_type":{"7f6b2e0a":"code","6e747290":"code","848fa712":"code","075aabfb":"code","29d5ed11":"code","cd616599":"markdown","2c1c7dca":"markdown","8a03d963":"markdown","68b7962c":"markdown","095f1d21":"markdown"},"source":{"7f6b2e0a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nimport os\nimport librosa\nimport soundfile as sf","6e747290":"train_f = pd.read_csv(\"..\/input\/rfcx-species-audio-detection\/train_fp.csv\")\ntrain_t = pd.read_csv(\"..\/input\/rfcx-species-audio-detection\/train_tp.csv\")\nsubmit = pd.read_csv(\"..\/input\/rfcx-species-audio-detection\/sample_submission.csv\")","848fa712":"train_df = pd.concat([train_f,train_t]).reset_index(drop=True)","075aabfb":"def MFCC_Extract(path,fs=551, mfcc_dim=20):\n    x , sr = sf.read(path)\n    mfccs = librosa.feature.mfcc(x, n_mfcc=mfcc_dim, sr=fs)\n    return mfccs","29d5ed11":"from tqdm import tqdm\ntrain_MFCC = []\nos.makedirs(\".\/train_mfcc\")\nfor i in tqdm(train_df['recording_id']):\n    audio_path = f\"..\/input\/rfcx-species-audio-detection\/train\/{i}.flac\"\n    mfcc = MFCC_Extract(audio_path)\n    np.save(f\".\/train_mfcc\/{i}.npy\",mfcc)\n    del mfcc","cd616599":"### import packages","2c1c7dca":"### MFCC Extract function\n* we can change fs and mfcc dimention","8a03d963":"## This notebooks shows how to extract MFCC feature\n* Extract features first, reduce pre-process data time.\n* We can use MFCC feature into CNN model.\n* Dataset will public for competitors use.\n* Public MFCC dataset https:\/\/www.kaggle.com\/super13579\/rcsadmfcc\/","68b7962c":"### Data save as npy file","095f1d21":"### Load training data"}}