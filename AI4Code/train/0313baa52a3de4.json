{"cell_type":{"6a08b885":"code","3d77dfb9":"code","4244d912":"code","9c4387ba":"code","7af2e582":"code","64dd59d5":"code","955b812f":"code","b714bd28":"code","539715a6":"code","e2775570":"code","5d4516ef":"code","ae9dd6c3":"code","0ba77e2b":"code","78f797d1":"code","4296de85":"code","c0de15e1":"code","1fad0025":"code","8326c4e7":"code","340a2603":"code","a42e1481":"code","962920e0":"code","1721cff0":"markdown"},"source":{"6a08b885":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import tree\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report,confusion_matrix,roc_curve,auc,precision_score, accuracy_score\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n\n# Any results you write to the current directory are saved as output.","3d77dfb9":"Total_train_records = 0\nTotal_test_records = 0\nTrain_Features = []\nTrain_Features_Type = []\nTrain_Features_records = []\nTrain_NAN_records = []\nTrain_Percentage_NAN = [] \nTest_Features = []\nTest_Features_Type = []\nTest_Features_records = []\nTest_NAN_records = []\nTest_Percentage_NAN = []\n\nTrain_Test_records = 0\nTrain_Test_Features = []\nTrain_Test_Features_Type = []\nTrain_Test_Features_records = []\nTrain_Test_NAN_records = []\nTrain_Test_Percentage_NAN = []\n\nTrain_results = []\nTest_results = []\nDSTree_depth = []\nSamples_split = []\nSamples_leaf = []\nRFTree_depth = []\n    ","4244d912":"def Main():\n    titanic_train, titanic_test = ReadFiles()\n    titanic_train_test = KnowYourData(titanic_train,titanic_test)\n    DataAnalysis(titanic_train_test)\n    titanic_train, titanic_test1 = Preprocessing(titanic_train_test)\n    Correlation(titanic_train)\n    X_train,X_test,Y_train,Y_test,titanic_test1 = Model_Selection(titanic_train,titanic_test1)\n    LogRegression(X_train,X_test,Y_train,Y_test,titanic_test1,titanic_test)\n    DecisionTree(X_train,X_test,Y_train,Y_test)\n    RandomForest(X_train,X_test,Y_train,Y_test,titanic_test1,titanic_test)\n    #XGBoost()","9c4387ba":"def ReadFiles():\n    titanic_train = pd.read_csv(\"..\/input\/train.csv\")\n    titanic_test = pd.read_csv(\"..\/input\/test.csv\")\n    print(\"Shape of the Train Dataset:\", titanic_train.shape)\n    print(\"Shape of the Test Dataset:\", titanic_test.shape)\n    return titanic_train, titanic_test\n\n    ","7af2e582":"def KnowYourData(titanic_train,titanic_test):\n    global Total_train_records,Total_test_records\n    global Train_Features,Train_Features_Type,Train_Features_records,Train_NAN_records,Train_Percentage_NAN\n    global Test_Features,Test_Features_Type,Test_Features_records,Test_NAN_records,Test_Percentage_NAN\n    print(\"Know Your Data\")\n    Total_train_records = len(titanic_train)\n    Total_test_records = len(titanic_test)\n    \n    #Train DataSet\n    for col in titanic_train.columns:\n        Train_Features.append(col)\n        Train_Features_Type.append(titanic_train[col].dtypes)\n        Train_Features_records.append(Total_train_records)\n        Train_NAN_records.append(titanic_train[col].isnull().sum())\n        Train_Percentage_NAN.append((titanic_train[col].isnull().sum() \/ Total_train_records) * 100)\n    \n    \n    #Test DataSet\n    for col in titanic_test.columns:\n        Test_Features.append(col)\n        Test_Features_Type.append(titanic_test[col].dtypes)\n        Test_Features_records.append(Total_test_records)\n        Test_NAN_records.append(titanic_test[col].isnull().sum())\n        Test_Percentage_NAN.append((titanic_test[col].isnull().sum() \/ Total_test_records) * 100)\n    \n    print(\"About Train Data:\")\n    display(pd.DataFrame({\"Features\":Train_Features,\"Features Type\":Train_Features_Type,\"Total Records\": Train_Features_records,\n    \"Total NAN\": Train_NAN_records, \"Percentage of NAN\": Train_Percentage_NAN}).T)\n    \n    Survived_df = pd.DataFrame(titanic_train['Survived'].value_counts().reset_index())\n    Survived_df.rename(columns={\"index\":\"Survived\",\"Survived\":\"Count\"},inplace=True)\n    Survived_df['Percentage'] = Survived_df['Count'].apply(lambda x: (x\/ Survived_df['Count'].sum())*100)\n    display(Survived_df)\n    #display(pd.DataFrame({\"Survived-0\": len(titanic_train['Survived'][0]), \"Survived-1\": len(titanic_train['Survived'][1])}))\n        \n    print(\"About Test Data:\")\n    display(pd.DataFrame({\"Features\":Test_Features,\"Features Type\":Test_Features_Type,\"Total Records\": Test_Features_records,\n    \"Total NAN\": Test_NAN_records, \"Percentage of NAN\": Test_Percentage_NAN}).T)\n    \n    #Total titanic dataset\n    titanic_train_test = pd.concat([titanic_train,titanic_test],sort=False)\n    Train_Test_records = len(titanic_train_test)\n    for col in titanic_train_test.columns:\n        if col != 'Survived':\n            Train_Test_Features.append(col)\n            Train_Test_Features_Type.append(titanic_train_test[col].dtypes)\n            Train_Test_Features_records.append(Train_Test_records)\n            Train_Test_NAN_records.append(titanic_train_test[col].isnull().sum())\n            Train_Test_Percentage_NAN.append((titanic_train_test[col].isnull().sum() \/ Train_Test_records) * 100)\n    \n    print(\"About Total Data:\")\n    display(pd.DataFrame({\"Features\":Train_Test_Features,\"Features Type\":Train_Test_Features_Type,\n                          \"Total Records\": Train_Test_Features_records,\"Total NAN\": Train_Test_NAN_records,\n                          \"Percentage of NAN\": Train_Test_Percentage_NAN}).T)\n    \n    return titanic_train_test\n    \n    \n    \n    \n    ","64dd59d5":"def DataAnalysis(titanic_train_test):\n    print(\"Data Analysis:\")\n    display(titanic_train_test.head(30))\n    display(titanic_train_test[['Pclass','Cabin','Survived']].head(100).T)\n    display(titanic_train_test.groupby(['Pclass','Survived']).count())\n    display(\"Minimum Age by Sex:\",titanic_train_test.groupby('Sex')['Age'].agg(['min','max'],axis=1))\n    display(\"NaN records by Fare : \\n\",titanic_train_test[titanic_train_test['Fare'].isnull()])\n    display(\"Mean Fare by Pclass:\",titanic_train_test.groupby('Pclass')['Fare'].agg(['mean','median'],axis=1))\n    display(\"NaN records by Embarked:\\n\",titanic_train_test[titanic_train_test['Embarked'].isnull()])\n    display(\"Mode of Embarked by Pclass:\",titanic_train_test.groupby('Pclass')['Embarked'].agg(pd.Series.mode))","955b812f":"def Preprocessing(titanic_train_test):\n    print(\"Preprocessing Starts.....\")\n    print(\"Number of duplicated data:\",titanic_train_test.duplicated().sum())\n    titanic_train_test = HandleMissingValues(titanic_train_test)\n    titanic_train_test = IrrelevantFeatures(titanic_train_test)\n    titanic_train_test = Feature_Extraction(titanic_train_test)\n    titanic_train_test = RedunantData(titanic_train_test)\n    titanic_train_test = Transformation(titanic_train_test)\n    #titanic_train_test = PrepareForEncode(titanic_train_test)\n    titanic_train_test = Encoding(titanic_train_test)\n    titanic_train = titanic_train_test.head(891)\n    titanic_test = titanic_train_test.tail(418)\n    display(\"Preprocessing Ends.....\")\n    return titanic_train, titanic_test\n    \n    ","b714bd28":"def HandleMissingValues(titanic_train_test):\n    print(\"Missing Values Phase Starts:\")\n    for col in titanic_train_test.columns:\n        if (titanic_train_test[col].isnull().sum() \/ len(titanic_train_test)) * 100 >= 50:\n            titanic_train_test.drop(col,axis=1,inplace=True)\n    \n    #titanic_train_test[col].fillna(titanic_train_test)\n    print(\"Mean Age by Sex:\\n\",titanic_train_test.groupby('Sex')['Age'].mean())\n    titanic_train_test['Age'] = titanic_train_test['Age'].fillna(titanic_train_test['Age'].mean())\n    print(\"Missing Count After Imputation of Age:\",titanic_train_test['Age'].isnull().sum())\n    titanic_train_test['Fare'] = titanic_train_test['Fare'].fillna(titanic_train_test.groupby('Pclass')['Fare'].mean()[3])\n    print(\"Missing Count After Imputation of Fare:\",titanic_train_test['Fare'].isnull().sum())\n    titanic_train_test['Embarked'] = titanic_train_test['Embarked'].fillna(titanic_train_test.groupby('Pclass')['Embarked'].agg(pd.Series.mode)[1])\n    print(\"Missing Count After Imputation of Embarked:\",titanic_train_test['Embarked'].isnull().sum())\n    display(\"Missing Count in DataFrame:\",titanic_train_test.isnull().sum())\n    print(\"Missing Values Phase Ends:\")\n    return titanic_train_test\n    \n    ","539715a6":"def IrrelevantFeatures(titanic_train_test):\n    print(\"Removing Irrelevant Features Process Starts:\")\n    titanic_train_test.drop(columns=['PassengerId','Name','Ticket'],axis=1,inplace=True)\n    print(\"Removing Irrelevant Features Process Ends:\")\n    display(titanic_train_test.head(5))\n    return titanic_train_test","e2775570":"def Feature_Extraction(titanic_train_test):\n    print(\"Feature Extraction Phase Starts:\")\n    titanic_train_test['From_Embarked'] = titanic_train_test['Embarked'].apply(lambda x: 1 if x == 'C' else (2 if x == 'Q' else 3))\n    titanic_train_test.drop('Embarked',axis=1,inplace=True)\n    print(\"Feature Extraction Phase Ends:\")\n    display(titanic_train_test.head(5))\n    return titanic_train_test\n    ","5d4516ef":"def RedunantData(titanic_train_test):\n    print(\"Redunant Data Phase Starts:\")\n    print(\"Both Pclass and From_Embarked are redunant. Removing From_Embarked feature\")\n    titanic_train_test.drop('From_Embarked',axis=1,inplace=True)\n    print(\"Redunant Data Phase Ends:\")\n    display(titanic_train_test.head(5))\n    return titanic_train_test","ae9dd6c3":"def Transformation(titanic_train_test):\n    print(\"Data Transformation Phase Starts:\")\n    titanic_train_test['Sex'] = titanic_train_test['Sex'].replace({\"female\":1,\"male\":0})\n    titanic_train_test['Age'] = titanic_train_test['Age'].apply(lambda x: 0 if x <= 1  else (1 if x <= 3 else (2 if x <= 12 else (3 if x <= 60 else 4))))\n    print(\"Data Transformation Phase Ends:\")\n    display(titanic_train_test.head(5))\n    return titanic_train_test","0ba77e2b":"def Encoding(titanic_train_test):\n    print(\"Encodeing Phase Starts:\")\n    titanic_train_test_encode = pd.get_dummies(titanic_train_test,prefix_sep='_')\n    display(titanic_train_test_encode)\n    print(\"Encoding Phase Ends\")\n    return titanic_train_test_encode\n    ","78f797d1":"def Correlation(titanic_train):\n    print(\"Correlation Starts:\")\n    display(titanic_train.corr())\n    print(\"Correlation Ends:\")","4296de85":"def Model_Selection(titanic_train,titanic_test):\n    print(\"Model Selection Phase Starts:\")\n    X = titanic_train.drop(\"Survived\",axis=1)\n    Y = titanic_train['Survived']\n    titanic_test = titanic_test.drop('Survived',axis=1)\n    X_train,X_test,Y_train,Y_test = train_test_split(X,Y,test_size=0.3,random_state=10)\n    print(\"Model Selection Phase Ends:\")\n    return X_train,X_test,Y_train,Y_test,titanic_test","c0de15e1":"def LogRegression(X_train,X_test,Y_train,Y_test,titanic_test1,titanic_test):\n    print(\"Logistic Regression Model Starts:\")\n    algo = \"Log\"\n    log_model = LogisticRegression()\n    log_model.fit(X_train,Y_train)\n    Y_train_predict = log_model.predict(X_train)\n    Y_test_predict = log_model.predict(X_test)\n    #titanic_test_predict = log_model.predict(titanic_test1)\n    Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo)\n  #  display(\"titanic_test log\")\n #   display(titanic_test1.head(5))\n#    display(titanic_test.head(5))\n    #display(\"Logistic model accuracy score is high compare to other models and the final result :\")\n    #my_submission = pd.DataFrame({\"PassengerId\": titanic_test.PassengerId,\"Survived\":titanic_test_predict})\n    #my_submission['Survived'] = my_submission['Survived'].apply(lambda x: int(x))\n    #my_submission.to_csv('submission.csv',index=False)\n    #print(\"Final output:\")\n    #display(my_submission)","1fad0025":"def DecisionTree(X_train,X_test,Y_train,Y_test):\n    global DSTree_depth,Train_results,Test_results,Samples_split\n    print(\"Decision Tree Model Starts:\")\n    algo = \"DS\"\n    max_depths = np.linspace(1, 32, 32, endpoint=True)\n    min_samples = np.linspace(0.1, 1.0, 10, endpoint=True)\n    min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n    \n    for depth in max_depths:\n        DSTree_depth.append(depth)\n        ds_model = DecisionTreeClassifier(max_depth=depth)\n        ds_model.fit(X_train,Y_train)\n        Y_train_predict = ds_model.predict(X_train)\n        Y_test_predict = ds_model.predict(X_test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo)\n    pname = \"Tree Depth\"\n    ROCAUC_Curve(Train_results,Test_results, DSTree_depth,pname)\n        \n    for sample in min_samples:\n        Samples_split.append(sample)\n        ds_model = DecisionTreeClassifier(min_samples_split=sample)\n        ds_model.fit(X_train,Y_train)\n        Y_train_predict = ds_model.predict(X_train)\n        Y_test_predict = ds_model.predict(X_test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo)\n    \n    pname = \"Min_Samples_Split\"\n    ROCAUC_Curve(Train_results,Test_results, Samples_split,pname)\n    \n    \n    for leaf in min_samples_leaf:\n        Samples_leaf.append(leaf)\n        ds_model = DecisionTreeClassifier(min_samples_leaf=leaf)\n        ds_model.fit(X_train,Y_train)\n        Y_train_predict = ds_model.predict(X_train)\n        Y_test_predict = ds_model.predict(X_test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo)\n    \n    pname = \"Min_Samples_Leaf\"\n    ROCAUC_Curve(Train_results,Test_results, Samples_leaf,pname)\n    \n    ds_model = DecisionTreeClassifier(max_depth=4, min_samples_split = 0.2,min_samples_leaf=0.30)\n    ds_model.fit(X_train,Y_train)\n    Y_train_predict = ds_model.predict(X_train)\n    Y_test_predict = ds_model.predict(X_test)\n    Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo=\"DSBestFit\")\n    \n    \n    print(\"Decision Tree Model Ends:\")","8326c4e7":"def RandomForest(X_train,X_test,Y_train,Y_test,titanic_test1,titanic_test):\n    global RFTree_depth, Samples_split,Samples_leaf\n    print(\"RandomForest Model Starts:\")\n    algo = \"RF\"\n    max_depths = np.linspace(1, 32, 32, endpoint=True)\n    min_samples = np.linspace(0.1, 1.0, 10, endpoint=True)\n    min_samples_leaf = np.linspace(0.1, 0.5, 5, endpoint=True)\n    \n    \n    for depth in max_depths:\n        RFTree_depth.append(depth)\n        rf_model = RandomForestClassifier(n_estimators = 200,max_depth=depth)\n        rf_model.fit(X_train,Y_train)\n        Y_train_predict = rf_model.predict(X_train)\n        Y_test_predict = rf_model.predict(X_test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo)\n    pname = \"Tree Depth\"\n    ROCAUC_Curve(Train_results,Test_results, RFTree_depth,pname)\n        \n    for sample in min_samples:\n        Samples_split.append(sample)\n        rf_model = RandomForestClassifier(n_estimators = 200,min_samples_split=sample)\n        rf_model.fit(X_train,Y_train)\n        Y_train_predict = rf_model.predict(X_train)\n        Y_test_predict = rf_model.predict(X_test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo)\n    \n    pname = \"Min_Samples_Split\"\n    ROCAUC_Curve(Train_results,Test_results, Samples_split,pname)\n    \n    \n    for leaf in min_samples_leaf:\n        Samples_leaf.append(leaf)\n        rf_model = RandomForestClassifier(n_estimators = 200,min_samples_leaf=leaf)\n        rf_model.fit(X_train,Y_train)\n        Y_train_predict = rf_model.predict(X_train)\n        Y_test_predict = rf_model.predict(X_test)\n        Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo)\n    \n    pname = \"Min_Samples_Leaf\"\n    ROCAUC_Curve(Train_results,Test_results, Samples_leaf,pname)\n    \n    algo = 'RFBest_Fit'\n    rf_model = RandomForestClassifier(n_estimators = 200,min_samples_split=0.6,min_samples_leaf=0.20)\n    rf_model.fit(X_train,Y_train)\n    Y_train_predict = rf_model.predict(X_train)\n    Y_test_predict = rf_model.predict(X_test)\n    titanic_test_predict = rf_model.predict(titanic_test1)\n    Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo)\n    print(\"RandomForest Model Ends:\")\n    \n    display(\"RanfomForest model better than other models and the final result :\")\n    my_submission = pd.DataFrame({\"PassengerId\": titanic_test.PassengerId,\"Survived\":titanic_test_predict})\n    my_submission['Survived'] = my_submission['Survived'].apply(lambda x: int(x))\n    #my_submission.to_csv('submission.csv',index=False)\n    print(\"Final output:\")\n    display(my_submission)","340a2603":"def Measures(Y_train,Y_train_predict,Y_test,Y_test_predict,algo):\n    global Train_results, Test_results, Tree_depth\n    #print(\"Measuring the model phase starts:\")\n            \n    if algo == 'Log':\n        print(\"Logistic Regression Measures:\")\n        print(\"Train dataset accuracy:\")\n        print(accuracy_score(Y_train,Y_train_predict))\n        print(classification_report(Y_train,Y_train_predict))\n        print(\"Test dataset accuracy:\")\n        print(accuracy_score(Y_test,Y_test_predict))\n        print(classification_report(Y_test,Y_test_predict))\n    elif algo == 'DS':\n        #print(\"Decision Tree Classifier Measures:\")\n        #print(\"Train dataset accuracy:\")\n        #print(classification_report(Y_train,Y_train_predict))\n        #print(\"Test dataset accuracy:\")\n        #print(classification_report(Y_test,Y_test_predict))\n        FPR_train,TPR_train,threshold_train = roc_curve(Y_train,Y_train_predict)\n        roc_auc_train = auc(FPR_train,TPR_train)\n        Train_results.append(roc_auc_train)\n        \n        FPR_test,TPR_test,threshold_test = roc_curve(Y_test,Y_test_predict)\n        roc_auc_test = auc(FPR_test,TPR_test)\n        Test_results.append(roc_auc_test)\n        \n    elif algo == 'DSBestFit':\n        \n        print(\"Decision Tree Best Fit Measures:\")\n        print(\"Train dataset accuracy:\")\n        print(accuracy_score(Y_train,Y_train_predict))\n        print(classification_report(Y_train,Y_train_predict))\n        print(\"Test dataset accuracy:\")\n        print(accuracy_score(Y_test,Y_test_predict))\n        print(classification_report(Y_test,Y_test_predict))\n        \n        \n    elif algo == 'RF':\n        \n        FPR_train,TPR_train,threshold_train = roc_curve(Y_train,Y_train_predict)\n        roc_auc_train = auc(FPR_train,TPR_train)\n        Train_results.append(roc_auc_train)\n        \n        FPR_test,TPR_test,threshold_test = roc_curve(Y_test,Y_test_predict)\n        roc_auc_test = auc(FPR_test,TPR_test)\n        Test_results.append(roc_auc_test)\n        \n    else:\n        print(\"Random Forest Classifier Measures:\")\n        print(\"Train dataset accuracy:\")\n        print(accuracy_score(Y_train,Y_train_predict))\n        print(classification_report(Y_train,Y_train_predict))\n        print(\"Test dataset accuracy:\")\n        print(accuracy_score(Y_test,Y_test_predict))\n        print(classification_report(Y_test,Y_test_predict))\n        \n    \n    \n    ","a42e1481":"def ROCAUC_Curve(Train,Test,parameter,pname):\n    global Train_results, Test_results, DSTree_depth, Samples_split, Samples_leaf\n    train = plt.plot(parameter,Train,'b',label=\"Train\")\n    test = plt.plot(parameter,Test,'r',label=\"Test\")\n    plt.legend()\n    plt.xlabel(pname)\n    plt.ylabel(\"AUC-Score\")\n    plt.show()\n    Train_results = []\n    Test_results = []\n    DSTree_depth = []\n    Samples_split = []\n    Samples_leaf = []\n    ","962920e0":"Main()","1721cff0":"Read both the train and test csv files"}}