{"cell_type":{"3afe4106":"code","0e22ef45":"code","f0935435":"code","e369500a":"code","d00053d6":"code","9dc550be":"code","4ae54664":"code","0cfbc814":"code","fbdc4334":"code","c3bad7c3":"code","5070d679":"markdown","988ec48f":"markdown","83030306":"markdown","2c7260e8":"markdown"},"source":{"3afe4106":"import os\nimport cv2\nimport pdb\nimport time\nimport warnings\nimport random\nimport numpy as np\nimport pandas as pd\nfrom tqdm import tqdm_notebook as tqdm\nfrom matplotlib import image\nfrom torch.optim.lr_scheduler import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\n!pip install segmentation-models-pytorch\nimport segmentation_models_pytorch as sm\nimport torchvision.transforms as transforms\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\nimport torch.optim as optim\nimport torch.backends.cudnn as cudnn\nfrom torch.utils.data import DataLoader, Dataset, sampler\nfrom matplotlib import pyplot as plt\n!pip install albumentations\nfrom albumentations import (HorizontalFlip, RandomBrightnessContrast,VerticalFlip, ShiftScaleRotate, Normalize, Resize, Compose, GaussNoise, RandomCrop)\nfrom albumentations.pytorch import ToTensor\nimport albumentations as A\nwarnings.filterwarnings(\"ignore\")\nseed = 69\nrandom.seed(seed)\nos.environ[\"PYTHONHASHSEED\"] = str(seed)\nnp.random.seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","0e22ef45":"#https:\/\/www.kaggle.com\/paulorzp\/rle-functions-run-lenght-encode-decode\ndef mask2rle(img):\n    '''\n    img: numpy array, 1 -> mask, 0 -> background\n    Returns run length as string formated\n    '''\n    pixels= img.T.flatten()\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)\n\ndef make_mask(row_id, df):\n    '''Given a row index, return image_id and mask (256, 1600, 4) from the dataframe `df`'''\n    fname = df.iloc[row_id].name\n    labels = df.iloc[row_id][:4]\n    imgh = df.iloc[row_id].image_height\n    imgw = df.iloc[row_id].image_width\n    masks = np.zeros((imgh, imgw, 4), dtype=np.float32) # float32 is V.Imp\n    # 4:class 1\uff5e4 (ch:0\uff5e3)\n\n    for idx, label in enumerate(labels.values):\n        if label is not np.nan:\n            label = label.split(\" \")\n            positions = map(int, label[0::2])\n            length = map(int, label[1::2])\n            mask = np.zeros(imgh * imgw, dtype=np.uint8)\n            for pos, le in zip(positions, length):\n                mask[pos:(pos + le)] = 1\n            masks[:, :, idx] = mask.reshape(imgh, imgw, order='F')\n    return fname, masks","f0935435":"tdf = pd.read_csv('..\/input\/datathon-challenge\/training.csv')\ndf = tdf.copy()\ndf['ImageId'], df['ClassId'] = zip(*df['filename_class'].str.split('_'))\ndf['ClassId'] = df['ClassId'].apply(lambda x: str(x)[-1]).astype(int)\ndf = df.pivot(index='ImageId',columns='ClassId',values='encoded_mask')\ndf['defects'] = df.count(axis=1)\ndf['image_height'] = tdf.iloc[::4, :]['image_height'].to_list()\ndf['image_width'] = tdf.iloc[::4, :]['image_width'].to_list()","e369500a":"class AnadoluDataset(Dataset):\n    def __init__(self, df, data_folder, mean, std, phase):\n        self.df = df\n        self.root = data_folder\n        self.mean = mean\n        self.std = std\n        self.phase = phase\n        self.transforms = get_transforms(phase, mean, std)\n        self.fnames = self.df.index.tolist()\n\n    def __getitem__(self, idx):\n        image_id, mask = make_mask(idx, self.df)\n        image_path = os.path.join(self.root, image_id+\".jpeg\")\n        img = cv2.imread(image_path)\n        augmented = self.transforms(image=img, mask=mask)\n        img = augmented['image']\n        mask = augmented['mask'] # 1x256x1600x4\n        mask = mask[0].permute(2, 0, 1) # 4x256x1600\n        return img, mask\n\n    def __len__(self):\n        return len(self.fnames)\n\n\ndef get_transforms(phase, mean, std):\n    list_transforms = []\n    normalize = Normalize(mean=mean, std=std)\n    if phase == \"train\":\n        list_transforms.extend(\n            [\n                Resize(512,512),\n                HorizontalFlip(p=0.5),\n                A.augmentations.transforms.RandomSnow(),\n                A.ElasticTransform(),\n                A.RandomRotate90(p=0.5),\n                A.RandomGridShuffle(p=0.5),\n                A.Cutout(num_holes=12, p=0.5),\n            ]\n        )\n    list_transforms.extend(\n        [\n            Resize(512,512),\n            ToTensor(),\n        ]\n    )\n    list_trfms = Compose(list_transforms)\n    return list_trfms\n\ndef provider(\n    data_folder,\n    df_path,\n    phase,\n    mean=None,\n    std=None,\n    batch_size=4,\n    num_workers=4,\n):\n    '''Returns dataloader for the model training'''\n    tdf = pd.read_csv('..\/input\/datathon-challenge\/training.csv')\n    df = tdf.copy()\n    df['ImageId'], df['ClassId'] = zip(*df['filename_class'].str.split('_'))\n    df['ClassId'] = df['ClassId'].apply(lambda x: str(x)[-1]).astype(int)\n    df = df.pivot(index='ImageId',columns='ClassId',values='encoded_mask')\n    df['defects'] = df.count(axis=1)\n    df['image_height'] = tdf.iloc[::4, :]['image_height'].to_list()\n    df['image_width'] = tdf.iloc[::4, :]['image_width'].to_list()\n    \n    train_df, val_df = train_test_split(df, test_size=0.2, stratify=df[\"defects\"], random_state=69)\n    df = train_df if phase == \"train\" else val_df\n    image_dataset = AnadoluDataset(df, data_folder, mean, std, phase)\n    dataloader = DataLoader(\n        image_dataset,\n        batch_size=batch_size,\n        num_workers=num_workers,\n        pin_memory=True,\n        shuffle=True,   \n    )\n\n    return dataloader\n","d00053d6":"#PyTorch\nALPHA = 0.35\nBETA = 0.65\n\nclass TverskyLoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(TverskyLoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1, alpha=ALPHA, beta=BETA):\n        \n        inputs = F.sigmoid(inputs)       \n        \n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        TP = (inputs * targets).sum()    \n        FP = ((1-targets) * inputs).sum()\n        FN = (targets * (1-inputs)).sum()\n       \n        Tversky = (TP + smooth) \/ (TP + alpha*FP + beta*FN + smooth)  \n        \n        return 1 - Tversky\n    \nclass DiceBCELoss(nn.Module):\n    def __init__(self, weight=None, size_average=True):\n        super(DiceBCELoss, self).__init__()\n\n    def forward(self, inputs, targets, smooth=1):\n        \n        inputs = F.sigmoid(inputs)       \n        \n        inputs = inputs.view(-1)\n        targets = targets.view(-1)\n        \n        intersection = (inputs * targets).sum()                            \n        dice_loss = 1 - (2.*intersection + smooth)\/(inputs.sum() + targets.sum() + smooth)  \n        BCE = F.binary_cross_entropy(inputs, targets, reduction='mean')\n        Dice_BCE = 0.75*BCE + 0.25*dice_loss\n        \n        return Dice_BCE\n    \ndef predict(X, threshold):\n    X_p = np.copy(X)\n    preds = (X_p > threshold).astype('uint8')\n    return preds\n\ndef metric(probability, truth, threshold=0.5, reduction='none'):\n    batch_size = len(truth)\n    with torch.no_grad():\n        probability = probability.view(batch_size, -1)\n        truth = truth.view(batch_size, -1)\n        assert(probability.shape == truth.shape)\n\n        p = (probability > threshold).float()\n        t = (truth > 0.5).float()\n\n        t_sum = t.sum(-1)\n        p_sum = p.sum(-1)\n        neg_index = torch.nonzero(t_sum == 0)\n        pos_index = torch.nonzero(t_sum >= 1)\n\n        dice_neg = (p_sum == 0).float()\n        dice_pos = 2 * (p*t).sum(-1)\/((p+t).sum(-1))\n\n        dice_neg = dice_neg[neg_index]\n        dice_pos = dice_pos[pos_index]\n        dice = torch.cat([dice_pos, dice_neg])\n\n        dice_neg = np.nan_to_num(dice_neg.mean().item(), 0)\n        dice_pos = np.nan_to_num(dice_pos.mean().item(), 0)\n        dice = dice.mean().item()\n\n        num_neg = len(neg_index)\n        num_pos = len(pos_index)\n\n    return dice, dice_neg, dice_pos, num_neg, num_pos\n\nclass Meter:\n    def __init__(self, phase, epoch):\n        self.base_threshold = 0.5 # <<<<<<<<<<< here's the threshold\n        self.base_dice_scores = []\n        self.dice_neg_scores = []\n        self.dice_pos_scores = []\n        self.iou_scores = []\n\n    def update(self, targets, outputs):\n        probs = torch.sigmoid(outputs)\n        dice, dice_neg, dice_pos, _, _ = metric(probs, targets, self.base_threshold)\n        self.base_dice_scores.append(dice)\n        self.dice_pos_scores.append(dice_pos)\n        self.dice_neg_scores.append(dice_neg)\n        preds = predict(probs, self.base_threshold)\n        iou = compute_iou_batch(preds, targets, classes=[1])\n        self.iou_scores.append(iou)\n\n    def get_metrics(self):\n        dice = np.mean(self.base_dice_scores)\n        dice_neg = np.mean(self.dice_neg_scores)\n        dice_pos = np.mean(self.dice_pos_scores)\n        dices = [dice, dice_neg, dice_pos]\n        iou = np.mean(self.iou_scores)\n        return dices, iou\n\ndef epoch_log(phase, epoch, epoch_loss, meter, start):\n    dices, iou = meter.get_metrics()\n    dice, dice_neg, dice_pos = dices\n    print(\"dice: %0.4f | dice_neg: %0.4f | dice_pos: %0.4f | IoU: %0.4f\" % (dice, dice_neg, dice_pos, iou))\n    return dice, iou\n\ndef compute_ious(pred, label, classes, ignore_index=255, only_present=True):\n    pred[label == ignore_index] = 0\n    ious = []\n    for c in classes:\n        label_c = label == c\n        if only_present and np.sum(label_c) == 0:\n            ious.append(np.nan)\n            continue\n        pred_c = pred == c\n        intersection = np.logical_and(pred_c, label_c).sum()\n        union = np.logical_or(pred_c, label_c).sum()\n        if union != 0:\n            ious.append(intersection \/ union)\n    return ious if ious else [1]\n\ndef compute_iou_batch(outputs, labels, classes=None):\n    ious = []\n    preds = np.copy(outputs) # copy is imp\n    labels = np.array(labels) # tensor to np\n    for pred, label in zip(preds, labels):\n        ious.append(np.nanmean(compute_ious(pred, label, classes)))\n    iou = np.nanmean(ious)\n    return iou\n","9dc550be":"model = sm.Unet('resnet18', encoder_weights=\"imagenet\", classes=4)","4ae54664":"class Trainer(object):\n    '''This class takes care of training and validation of our model'''\n    def __init__(self, model):\n        self.num_workers = 6\n        self.batch_size = {\"train\": 16, \"val\": 16}\n        self.accumulation_steps = 32 \/\/ self.batch_size['train']\n        self.lr = 5e-4\n        self.num_epochs = 40\n        self.best_loss = float(\"inf\")\n        self.phases = [\"train\", \"val\"]\n        self.device = torch.device(\"cuda:0\")\n        torch.set_default_tensor_type(\"torch.cuda.FloatTensor\")\n        self.net = model\n        self.criterion = DiceBCELoss()\n        self.optimizer = optim.Adam(self.net.parameters(), lr=self.lr)\n        self.scheduler = ReduceLROnPlateau(self.optimizer, mode=\"min\", patience=3, verbose=True)\n        self.net = self.net.to(self.device)\n        cudnn.benchmark = False\n        self.dataloaders = {\n            phase: provider(\n                data_folder=data_folder,\n                df_path=train_df_path,\n                phase=phase,\n                mean=(0.5976, 0.5628, 0.5302),\n                std=(0.1856, 0.1931, 0.2053),\n                batch_size=self.batch_size[phase],\n                num_workers=self.num_workers,\n            )\n            for phase in self.phases\n        }\n        self.losses = {phase: [] for phase in self.phases}\n        self.iou_scores = {phase: [] for phase in self.phases}\n        self.dice_scores = {phase: [] for phase in self.phases}\n        \n    def forward(self, images, targets):\n        images = images.to(self.device)\n        masks = targets.to(self.device)\n        outputs = self.net(images)\n        loss = self.criterion(outputs, masks)\n        return loss, outputs\n\n    def iterate(self, epoch, phase):\n        meter = Meter(phase, epoch)\n        start = time.strftime(\"%H:%M:%S\")\n        print(f\"Starting epoch: {epoch} | phase: {phase} | \u23f0: {start}\")\n        batch_size = self.batch_size[phase]\n        self.net.train(phase == \"train\")\n        dataloader = self.dataloaders[phase]\n        running_loss = 0.0\n        total_batches = len(dataloader)\n        self.optimizer.zero_grad()\n        for itr, batch in enumerate(dataloader): # replace `dataloader` with `tk0` for tqdm\n            images, targets = batch\n            loss, outputs = self.forward(images, targets)\n            loss = loss \/ self.accumulation_steps\n            if phase == \"train\":\n                loss.backward()\n                if (itr + 1 ) % self.accumulation_steps == 0:\n                    self.optimizer.step()\n                    self.optimizer.zero_grad()\n            running_loss += loss.item()\n            outputs = outputs.detach().cpu()\n            meter.update(targets, outputs)\n        epoch_loss = (running_loss * self.accumulation_steps) \/ total_batches\n        dice, iou = epoch_log(phase, epoch, epoch_loss, meter, start)\n        self.losses[phase].append(epoch_loss)\n        self.dice_scores[phase].append(dice)\n        self.iou_scores[phase].append(iou)\n        torch.cuda.empty_cache()\n        return epoch_loss\n\n    def start(self):\n        for epoch in range(self.num_epochs):\n            self.iterate(epoch, \"train\")\n            state = {\n                \"epoch\": epoch,\n                \"best_loss\": self.best_loss,\n                \"state_dict\": self.net.state_dict(),\n                \"optimizer\": self.optimizer.state_dict(),\n            }\n            print(\"ok\")\n            with torch.no_grad():\n                val_loss = self.iterate(epoch, \"val\")\n                self.scheduler.step(val_loss)\n            print(\"ok\")\n            if val_loss < self.best_loss:\n                print(\"******** New optimal found, saving state ********\")\n                state[\"best_loss\"] = self.best_loss = val_loss\n                torch.save(state, \".\/model.pth\")\n            print(\"ok\")\n","0cfbc814":"sample_submission_path = '..\/input\/datathon-challenge\/sample_submission.csv'\ntrain_df_path = '..\/input\/datathon-challenge\/training.csv'\ndata_folder = \"..\/input\/datathon-challenge\/Training_Imgs\/Training_Imgs\"\ntest_data_folder =  \"..\/input\/datathon-challenge\/Testing_Imgs\/Testing_Imgs\"","fbdc4334":"model_trainer = Trainer(model)\nmodel_trainer.start()","c3bad7c3":"# PLOT TRAINING\nlosses = model_trainer.losses\ndice_scores = model_trainer.dice_scores # overall dice\niou_scores = model_trainer.iou_scores\n\ndef plot(scores, name):\n    plt.figure(figsize=(15,5))\n    plt.plot(range(len(scores[\"train\"])), scores[\"train\"], label=f'train {name}')\n    plt.plot(range(len(scores[\"train\"])), scores[\"val\"], label=f'val {name}')\n    plt.title(f'{name} plot'); plt.xlabel('Epoch'); plt.ylabel(f'{name}');\n    plt.legend(); \n    plt.show()\n\n\nplot(losses, \"BCE+Dice loss\")\nplot(dice_scores, \"Dice score\")\nplot(iou_scores, \"IoU score\")","5070d679":"### Define Custom loss functions tversky and 0.25*Dice+0.75*BCE, Metrics","988ec48f":"### Define model trainer function","83030306":"### dataset, transforms and dataloader","2c7260e8":"### Define mask transformations"}}