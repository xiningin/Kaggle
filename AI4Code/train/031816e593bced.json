{"cell_type":{"db46a6bc":"code","e650e31d":"code","5ae864aa":"code","234710ca":"code","3978a802":"code","3847f4d1":"code","3f0ff72b":"code","27048b6a":"code","fa593bf8":"code","b18846fa":"code","36e00d2e":"code","aa64c0a5":"code","3799d5c8":"code","f278f31b":"code","91ba4fcf":"code","8b551c80":"code","8a3fb397":"code","b7cb2fec":"code","bd012a73":"code","5f6cc53c":"code","71072a35":"code","2a8cbe64":"code","92d77e56":"code","d1dcb3b2":"markdown","ab380e7d":"markdown","e976280a":"markdown","6f85b94b":"markdown","308b72ec":"markdown","1330f2a3":"markdown","cebc5fb2":"markdown","f3f9ff38":"markdown","1d985276":"markdown","98b87d7a":"markdown"},"source":{"db46a6bc":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e650e31d":"### NUmpy AND Pandas Already Loaded and others are is going to laod here\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error,r2_score","5ae864aa":"hdi=pd.read_csv('\/kaggle\/input\/human-development-index-hdi\/HDI.csv')\nhdi.head()","234710ca":"hdi.info()","3978a802":"hdi.shape","3847f4d1":"hdi.describe().T","3f0ff72b":"hdi.isnull().sum()","27048b6a":"hdi['HDI Rank']=hdi['HDI Rank'].fillna(round(hdi['HDI Rank'].mean(),1))\nhdi['1990']=hdi['1990'].fillna(round(hdi['1990'].mean(),3))\nhdi['1991']=hdi['1991'].fillna(round(hdi['1991'].mean(),3))\nhdi['1992']=hdi['1992'].fillna(round(hdi['1992'].mean(),3))\nhdi['1993']=hdi['1993'].fillna(round(hdi['1993'].mean(),3))\nhdi['1994']=hdi['1994'].fillna(round(hdi['1994'].mean(),3))\nhdi['1995']=hdi['1995'].fillna(round(hdi['1995'].mean(),3))\nhdi['1996']=hdi['1996'].fillna(round(hdi['1996'].mean(),3))\nhdi['1997']=hdi['1997'].fillna(round(hdi['1997'].mean(),3))\nhdi['1998']=hdi['1998'].fillna(round(hdi['1998'].mean(),3))\nhdi['1999']=hdi['1999'].fillna(round(hdi['1999'].mean(),3))\nhdi['2000']=hdi['2000'].fillna(round(hdi['2000'].mean(),3))\nhdi['2001']=hdi['2001'].fillna(round(hdi['2001'].mean(),3))\nhdi['2002']=hdi['2002'].fillna(round(hdi['2002'].mean(),3))\nhdi['2003']=hdi['2003'].fillna(round(hdi['2003'].mean(),3))\nhdi['2004']=hdi['2004'].fillna(round(hdi['2004'].mean(),3))\nhdi['2005']=hdi['2005'].fillna(round(hdi['2005'].mean(),3))\nhdi['2006']=hdi['2006'].fillna(round(hdi['2006'].mean(),3))\nhdi['2007']=hdi['2007'].fillna(round(hdi['2007'].mean(),3))\nhdi['2008']=hdi['2008'].fillna(round(hdi['2008'].mean(),3))\nhdi['2009']=hdi['2009'].fillna(round(hdi['2009'].mean(),3))\nhdi['2010']=hdi['2010'].fillna(round(hdi['2010'].mean(),3))\nhdi['2011']=hdi['2011'].fillna(round(hdi['2011'].mean(),3))\nhdi['2012']=hdi['2012'].fillna(round(hdi['2012'].mean(),3))\nhdi['2013']=hdi['2013'].fillna(round(hdi['2013'].mean(),3))\nhdi['2014']=hdi['2014'].fillna(round(hdi['2014'].mean(),3))\nhdi['2015']=hdi['2015'].fillna(round(hdi['2015'].mean(),3))\nhdi['2016']=hdi['2016'].fillna(round(hdi['2016'].mean(),3))\n","fa593bf8":"hdi.isnull().sum()","b18846fa":"hdi = hdi.drop(['Coverage','Country'],axis=1)","36e00d2e":"X = hdi.iloc[:,1:]\ny =hdi.iloc[:,:1]\n","aa64c0a5":"print(f'The shape of X is {X.shape}\\n\\nThe shape of y is {y.shape}')","3799d5c8":"X.columns","f278f31b":"y.columns","91ba4fcf":"X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.1,random_state=1)","8b551c80":"model= LinearRegression().fit(X_train,y_train)","8a3fb397":"Pred = model.predict(X_test)\nPred","b7cb2fec":"mean_squared_error(y_test,Pred)","bd012a73":"mean_absolute_error(y_test,Pred)","5f6cc53c":"r2_score(y_test,Pred)","71072a35":"training = model.predict(X_train)\ntraining_data = r2_score(y_train,training)\ntraining_data","2a8cbe64":"testing  = model.predict(X_test)\ntesting_data = r2_score(y_test,testing)\ntesting_data","92d77e56":"input_data=(0.302,0.307,0.316,0.312,0.307,0.331,0.335,0.339,0.344,0.348,0.350,0.353,0.384,0.393,0.409,0.418,0.429,0.447,0.447,0.460,0.472,0.477,0.489,0.496,0.500,0.500,0.502,0.50,0.509,0.511)\n## convert into numpy array\ninput_data_as_numpy_array = np.asarray(input_data)\n\n### reshape a data array as we are predict one instance\n\ninput_data_as_numpy_array=input_data_as_numpy_array.reshape(1,-1)\npredictions =model.predict(input_data_as_numpy_array)\n# print(predictions)\nprint(f'The HDI Rank is {float(predictions)}')","d1dcb3b2":"## Fill all mising values ","ab380e7d":"### Drop unwanted data","e976280a":"## Load Libraries and Analysis ","6f85b94b":"## Model Fitting","308b72ec":"#### Again check for  null values","1330f2a3":"## select data(features) and target(label) ","cebc5fb2":"# Model Evaluation","f3f9ff38":"### Split train test data","1d985276":"##### Load Dataset from kaggle site","98b87d7a":"## Model Prediction "}}