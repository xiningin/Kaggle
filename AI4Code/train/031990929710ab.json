{"cell_type":{"5e0355cb":"code","b80a2eac":"code","527e2629":"code","478ffa70":"code","837aa268":"code","fb770b59":"code","ce73dcff":"code","45a4df5d":"code","a502c902":"code","effbf388":"code","a8c30057":"code","d2b5f18d":"code","64b9c714":"code","0867874f":"code","c53fff6c":"code","1fae54b6":"code","9d955078":"code","0a102a4d":"code","617d6e27":"code","1b88d30a":"code","e363d060":"code","9afa66b9":"code","3fb331c3":"code","07abc137":"code","4b957e3e":"code","7d012094":"code","87b0cfda":"code","3c1fe132":"code","f82b8f54":"code","61e2886c":"code","a2219ea2":"code","78625034":"code","ddc4deef":"code","b20a9745":"code","968709af":"code","57bf8825":"code","30029f04":"code","d75a19eb":"code","ad961073":"markdown","d21be83e":"markdown","503afe69":"markdown","ed606839":"markdown","d67539bb":"markdown","18824823":"markdown","3cc5b3a5":"markdown","8ab1646a":"markdown","4cd3c30a":"markdown","628b1280":"markdown"},"source":{"5e0355cb":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_selection import mutual_info_classif\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import precision_score\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import cross_val_score\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","b80a2eac":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', index_col='PassengerId')\n\ntrain_df.head()","527e2629":"train_df.info()","478ffa70":"plt.figure(figsize=(8,8))\nsns.distplot(a=train_df['Age'], kde=True)\nplt.show","837aa268":"plt.figure(figsize=(8,8))\nsns.stripplot(x=\"Survived\", y=\"Age\", data=train_df)\nplt.show","fb770b59":"plt.figure(figsize=(8,8))\nsns.stripplot(x=\"Survived\", y=\"Fare\", data=train_df)\nplt.show","ce73dcff":"train_df.groupby(\"Embarked\").Survived.count().plot.bar()","45a4df5d":"train_df.groupby('Survived').Pclass.count().plot.bar()","a502c902":"train_df.groupby('SibSp').Survived.count().plot.bar()","effbf388":"df2 = train_df.drop(['Name','Ticket','Cabin'], axis=1)\n\ndf2.head()","a8c30057":"df2.isnull().sum()","d2b5f18d":"df2.Age.fillna(df2.Age.mean(), inplace=True)\ndf2.Embarked.fillna(\"S\", inplace=True)\ndf2.isnull().sum()","64b9c714":"y = df2.Survived\nX  = df2.drop('Survived', axis=1)\n\nfor col in X.columns:\n    if X[col].dtype == 'object':\n        X[col],_= X[col].factorize()\n        \n        \nmi_score = mutual_info_classif(X,y, random_state=1)\n\nmiscore = pd.Series(mi_score*100 , name=\"MI_score\" , index=X.columns)\n\nprint(miscore) ","0867874f":"# splitting dataset into training and validation\nX_train, X_valid, y_train, y_valid = train_test_split(X,y, train_size=0.80, test_size=0.20,random_state=0)\n\n# model object\nmodel = RandomForestClassifier(n_estimators=500, random_state=0)\n\n# fitting model to data\nmodel.fit(X_train,y_train)\n\n# predicting values\n\npreds = model.predict(X_valid)\n\n# accuracy and confusion matrix\n\nacc = accuracy_score(y_valid,preds)\n\nprint(\"accuracy score for classification: \",acc)\n\nconf = confusion_matrix(y_valid,preds)\n\nprint(conf)\n\n# precision score\n\nscore = precision_score(y_valid,preds)\n\nprint(score)\n\n# roc and auc score\n\nrocauc = roc_auc_score(y_valid,preds)\n\nprint(\"ROC and AUC score: \", rocauc)\n\n# roc curve\n\ncurve = roc_curve(y_valid,preds)\nprint(curve)","c53fff6c":"# prediction on test data\n\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv', index_col = 'PassengerId')\n\ntest_df.info()","1fae54b6":"testdf2 = test_df.drop(['Name','Ticket','Cabin'], axis=1)\n\ntestdf2.isnull().sum()\n\ntestdf2.Age.fillna(testdf2.Age.mean(), inplace=True)\ntestdf2.Fare.fillna(testdf2.Fare.mean(), inplace=True)\n\n# factorize object columns\n\nfor col in testdf2.columns:\n    if testdf2[col].dtype == 'object':\n        testdf2[col],_= testdf2[col].factorize()\n\n# prediction on survival\n\nprediction = model.predict(testdf2)\n\n# submission csv\n\nmysub = pd.DataFrame({'PassengerId':testdf2.index,\n                       'Survived': prediction})\n\nmysub.to_csv('mysubmission.csv', index=False)","9d955078":"clf = GradientBoostingClassifier(n_estimators=500,\n                                 learning_rate=0.01, \n                                 max_leaf_nodes=150,\n                                 random_state=1,\n                                 max_depth=4)\n\n\nclf.fit(X_train,y_train)\n\nprediction = clf.predict(X_valid)\n\n# accuracy score\n\naccu = accuracy_score(y_valid, prediction)\n\nprint(\"accuracy score of GBC:\", accu)\n\n# confusion metrix\n\ncon = confusion_matrix(y_valid,prediction)\n\nprint(con)","0a102a4d":"test_pred = clf.predict(testdf2)\n\nsub = pd.DataFrame({'PassengerId':testdf2.index,\n                    'Survived':test_pred})\n\nsub.to_csv('submission.csv', index=False)","617d6e27":"# kmeans clustering \n\ny = df2.Survived\nX2  = X.copy()\n\nX2['Age'] = X2['Age'].map(lambda x: (x - X2['Age'].mean())\/X2['Age'].std())\nX2['Fare'] = X2['Fare'].map(lambda x: (x - X2['Fare'].mean())\/X2['Fare'].std())\n\nkmeans = KMeans(n_clusters=2, n_init=10, max_iter=10, random_state=0)\n\nX2['Cluster'] = kmeans.fit_predict(X2)\nX2['Cluster'] = X2['Cluster'].astype('category')\n\nX2.head()","1b88d30a":"sns.stripplot(x='Cluster', y='Age', data = X2)\nplt.show","e363d060":"df = pd.DataFrame({'age': np.array(X['Age']),\n                   'Cluster': np.array(X2['Cluster']),\n                    'Survived': y})\n\nsns.stripplot(x='Survived', y='age', data=df)\n\nplt.show","9afa66b9":"sns.stripplot(x='Cluster', y='age', data=df)\n\nplt.show","3fb331c3":"# load the dataset again\n\ndata = pd.read_csv('\/kaggle\/input\/titanic\/train.csv', index_col='PassengerId')\n\ndata.head()","07abc137":"# Name and Ticket columns are instances\/individual itself so we can remove from dataframe\n\ndata2 = data.drop(['Name','Ticket'], axis=1)\n\n# EDA on numerical variables and it's releations with our target\n\nnum_col = [col for col in data2.columns if data2[col].dtype in ['int64','float64']]\n\nd3 = data2[num_col]\n\n# average of each variable who survived or not\n\nd3.groupby('Survived').mean()","4b957e3e":"# given the age is availabel or not we have imporance of age feature \n\nd3.groupby(d3['Age'].isnull()).mean()","7d012094":"d3['Age'].fillna(d3['Age'].mean(), inplace=True)\n\nd3.info()","87b0cfda":"# eda on categorical features\n\ncat_features = ['Survived','Pclass','SibSp','Parch','Sex','Cabin','Embarked']\n\ndata2['Age'].fillna(data2['Age'].mean(), inplace=True)\n\ndata2[cat_features]\n\ndata2.info()\n# we are having two variable with missing values","3c1fe132":"for idx, col in enumerate(['Pclass','SibSp','Parch']):\n    plt.figure(idx, figsize=(6,6))\n    sns.catplot(x=col, y='Survived', data=data2, kind='point')","f82b8f54":"data2.pivot_table('Survived', index='Embarked', columns='Pclass')\n\n# since embarkation is not related to survival of passanger as we can see in below table\n#  survival rations are depend on class of ticket","61e2886c":"plt.figure(figsize=(6,6))\nsns.catplot(x='Embarked', y='Survived', data=data2, kind='point')\nplt.show","a2219ea2":"# relations between having cabin or not\n\n# data2.groupby(data2['Cabin'].isnull()).mean()\n\n# where cabin is not available, there we have less survival ratio and this validate by average fair \n#  of the ticket as well\n\ndata2['Cabin_cnt'] = np.where(data2['Cabin'].isnull(), 0,1)","78625034":"for col in data2.columns:\n    if data2[col].isnull().sum() == True:\n        data2.drop(col, axis=1) ","ddc4deef":"sex_arr = np.array(train_df['Sex'].map({'male':0, 'female':1}))","b20a9745":"data2['Sex'] = data2['Sex'].fillna(pd.Series(sex_arr), inplace=True)\n\ndata3 = data2.drop('Sex', axis=1)\ndata3.head()","968709af":"data3['Sex_'] = sex_arr","57bf8825":"data3.head()\n","30029f04":"data3.drop(['Cabin','Embarked'], axis=1)","d75a19eb":"X = data3[['Pclass','Age','SibSp','Parch','Fare','Sex_','Cabin_cnt']]\ny = train_df['Survived']\n\nX_train, X_valid, y_train, y_valid = train_test_split(X,y, train_size=0.8, test_size=0.2,\n                                                       random_state=0)\n\nmymodel = GradientBoostingClassifier(n_estimators=2000,\n                                 learning_rate=0.01, \n                                 max_leaf_nodes=500,\n                                 random_state=0,\n                                 max_depth=2)\n\n\n# fitting model to data\n\nmymodel.fit(X_train,y_train)\n\n# prediction values\n\npredictions = mymodel.predict(X_valid)\n\n# accuracy score\n\nscore = accuracy_score(y_valid,predictions)\n\nprint(\"Accuracy score of the model: \", score)\n\n# confusion matrix\n\nconfusion = confusion_matrix(y_valid,predictions)\n\nprint(confusion)","ad961073":"# Feature engineering and improving accuracy of model","d21be83e":"# Kmeans clustring","503afe69":"# Gradient Boosting classifier model training","ed606839":"> We can see that travellers from uppper class are more likely to survive\n\n> Younger ones are more likely to survive than older age but there are some missing values to consider\n\n> Subsequently we can see that upper class travellers as they are had to pay more to get onboard are more likely to survive\n\n> Above all features can explain our target in some way so we will keep all features","d67539bb":"# Traning model via gradient boosting","18824823":"# Prediciton on test data","3cc5b3a5":"> From above models we can see there's issue of overfiiting, because of that we are not getting desired accuracy of from test data\n\n> Below code tries to solve that problem so we can improve accuracy and avoid overfitting","8ab1646a":"# Prediction on testing data","4cd3c30a":"> from above plots we can say that when siblings\/family members increases survival ratio decreases","628b1280":"# Model training"}}