{"cell_type":{"dade19bf":"code","cf53a548":"code","75ee8d74":"code","0012f183":"code","5d3ee93e":"code","011f7182":"code","54411695":"code","32d35381":"code","e62117ae":"code","7727d473":"code","b595c003":"code","69c880a7":"code","a3e0ed0b":"code","05603cdc":"code","ae16143b":"code","0d03fd40":"code","0d7e79b9":"code","92249b1c":"code","4bf4f4e3":"code","56ba3d0a":"code","815ed1ac":"code","b73eba70":"code","e193a7b4":"code","96fe5de8":"code","f7df2d8d":"code","37482a22":"code","a28f537e":"code","eb2430ef":"code","09564168":"code","c3ff999a":"code","96cad132":"code","373b88b8":"markdown","df78699d":"markdown","5d351d6d":"markdown","8f32ae30":"markdown","7db41436":"markdown","7d5816d4":"markdown"},"source":{"dade19bf":"import os\n\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport pydicom\n\nfrom tqdm.notebook import tqdm","cf53a548":"train = pd.read_csv('..\/input\/osic-pulmonary-fibrosis-progression\/train.csv')\ntrain.head(70)","75ee8d74":"train.Patient[train.SmokingStatus == 'Ex-smoker']","0012f183":"d = pydicom.dcmread('..\/input\/osic-pulmonary-fibrosis-progression\/train\/ID00007637202177411956430\/11.dcm')","5d3ee93e":"plt.figure(figsize = (10,10))\n\nplt.imshow(d.pixel_array)","011f7182":"train_data = {}\nfor p in train.Patient.values:\n    train_data[p] = os.listdir(f'..\/input\/osic-pulmonary-fibrosis-progression\/train\/{p}\/')","54411695":"from tensorflow.keras.utils import Sequence\nimport cv2\n\nclass IGenerator(Sequence):\n    BAD_ID = ['ID00011637202177653955184', 'ID00052637202186188008618']\n    def __init__(self, keys=list(train_data.keys()), train_data=train_data, batch_size=32):\n        self.keys = [k for k in keys if k not in self.BAD_ID]\n        self.train_data = train_data\n        self.batch_size = batch_size\n        \n    def __len__(self):\n        return 1000\n    \n    def __getitem__(self, idx):\n        x = []\n        keys = np.random.choice(self.keys, size = self.batch_size)\n        for k in keys:\n            try:\n                i = np.random.choice(self.train_data[k], size=1)[0]\n                d = pydicom.dcmread(f'..\/input\/osic-pulmonary-fibrosis-progression\/train\/{k}\/{i}')\n                x.append(cv2.resize(d.pixel_array \/ 2**10, (512, 512)))\n            except:\n                print(k, i)\n        x = np.array(x)\n        x = np.expand_dims(x, axis=-1)\n        return x, x","32d35381":"from tensorflow.keras.layers import (\n    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, UpSampling2D, Add, Conv2D, MaxPooling2D, LeakyReLU\n)\n\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import Nadam\n\ndef get_encoder(shape=(512, 512, 1)):\n    def res_block(x, n_features):\n        _x = x\n        x = BatchNormalization()(x)\n        x = LeakyReLU()(x)\n    \n        x = Conv2D(n_features, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n        x = Add()([_x, x])\n        return x\n    \n    inp = Input(shape=shape)\n    \n    # 512\n    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(inp)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    \n    # 256\n    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(2):\n        x = res_block(x, 32)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    \n    # 128\n    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(2):\n        x = res_block(x, 32)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    \n    # 64\n    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(3):\n        x = res_block(x, 64)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    \n    # 32\n    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(3):\n        x = res_block(x, 64)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x)    \n    \n    # 16\n    x = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(3):\n        x = res_block(x, 128)\n    x = MaxPooling2D(pool_size=(2, 2), strides=(2, 2))(x) \n    \n    # 8\n    x = Conv2D(1, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n    return Model(inp, x)\n\n\n\ndef get_decoder(shape=(8, 8, 1)):\n    inp = Input(shape=shape)\n\n    # 8\n    x = UpSampling2D((2, 2))(inp)\n    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    # 16\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    # 32\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    # 64\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    # 128\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(16, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    # 256\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(8, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(1, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n    return Model(inp, x)","e62117ae":"encoder = get_encoder((512, 512, 1))\ndecoder = get_decoder((8, 8, 1))","7727d473":"inp = Input((512, 512, 1))\ne = encoder(inp)\nd = decoder(e)\nmodel = Model(inp, d)","b595c003":"model.compile(optimizer=Nadam(lr=2*1e-3, schedule_decay=1e-5), loss='mse')","69c880a7":"model.summary()","a3e0ed0b":"model.fit_generator(IGenerator(), steps_per_epoch=500, epochs=5)","05603cdc":"keys = [k for k in list(train_data.keys()) if k not in ['ID00011637202177653955184', 'ID00052637202186188008618']]","ae16143b":"emb = {}\nfor k in tqdm(keys, total=len(keys)):\n    x = []\n    for i in train_data[k]:\n        d = pydicom.dcmread(f'..\/input\/osic-pulmonary-fibrosis-progression\/train\/{k}\/{i}')\n        x.append(cv2.resize(d.pixel_array \/ 2**10, (512, 512)))\n    x = np.expand_dims(x, axis=-1)\n    emb[k] = encoder.predict(x)","0d03fd40":"encoder.save('encoder.h5')","0d7e79b9":"del encoder, decoder, model","92249b1c":"del IGenerator","4bf4f4e3":"import gc\n\ngc.collect()","56ba3d0a":"del x\n\ngc.collect()","815ed1ac":"from sklearn.decomposition import PCA","b73eba70":"vec = []\nfor k in emb:\n    vec.extend(emb[k][..., 0].reshape((len(emb[k]), 64)).tolist())\n    \npca = PCA(n_components=3)\npca.fit(vec)\n\ndel vec\ngc.collect()","e193a7b4":"pca.explained_variance_ratio_","96fe5de8":"emb3 = {}\n\nfor k in tqdm(emb):\n    emb3[k] = pca.transform(emb[k][..., 0].reshape((len(emb[k]), 64)).tolist())","f7df2d8d":"plt.figure(figsize=(10,10))\n\nvec = []\nfor k in train.Patient.values:\n    if k in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n        continue\n    vec.extend(emb3[k].tolist())\nvec = np.array(vec)\n\nplt.plot(vec[:, 0], vec[:, 1], '.', alpha=0.05, label='Male')","37482a22":"plt.figure(figsize=(10,10))\n\nvec = []\nfor k in train.Patient[train.Sex == 'Male'].values[:100]:\n    if k in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n        continue\n    vec.extend(emb3[k].tolist())\n\nvec = np.array(vec)\n\nplt.plot(vec[:, 0], vec[:, 1], '.', alpha=0.05, label='Male')\n\n\nvec = []\nfor k in train.Patient[train.Sex == 'Female'].values[:100]:\n    if k in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n        continue\n    vec.extend(emb3[k].tolist())\n\nvec = np.array(vec)\n\nplt.plot(vec[:, 0], vec[:, 1], '.', alpha=0.05, label='Female')\n\nplt.legend()","a28f537e":"plt.figure(figsize=(10,10))\n\nvec = []\nfor k in train.Patient[train.SmokingStatus == 'Ex-smoker'].values[:100]:\n    if k in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n        continue\n    vec.extend(emb3[k].tolist())\n\nvec = np.array(vec)\n\nplt.plot(vec[:, 0], vec[:, 1], '.', alpha=0.05, label='Ex-smoker')\n\n\nvec = []\nfor k in train.Patient[train.SmokingStatus == 'Never smoked'].values[:100]:\n    if k in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n        continue\n    vec.extend(emb3[k].tolist())\n\nvec = np.array(vec)\n\nplt.plot(vec[:, 0], vec[:, 1], '.', alpha=0.05, label='Never smoked')\n\n\nvec = []\nfor k in train.Patient[train.SmokingStatus == 'Currently smokes'].values[:100]:\n    if k in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n        continue\n    vec.extend(emb3[k].tolist())\n\nvec = np.array(vec)\n\nplt.plot(vec[:, 0], vec[:, 1], '.', alpha=0.05, label='Currently smokes')\n\nplt.legend()","eb2430ef":"train['mc1'] = 0\ntrain['sc1'] = 0","09564168":"for k in tqdm(train.Patient.values):\n    if k in ['ID00011637202177653955184', 'ID00052637202186188008618']:\n        continue\n    train.loc[train.Patient == k,'mc1'] = emb3[k][:, 0].max()\n    train.loc[train.Patient == k,'sc1'] = emb3[k][:, 0].std()","c3ff999a":"plt.figure(figsize=(10, 10))\n\nplt.plot(train.mc1, train.FVC, '.')","96cad132":"plt.figure(figsize=(10, 10))\n\nplt.plot(train.mc1, train.Percent, '.')","373b88b8":"## Depend 1 component stats with targets","df78699d":"![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/28\/Autoencoder_structure.png)","5d351d6d":"## Image visualization","8f32ae30":"Pipeline released in this kernel is very simple:\n\n* train encoder and used one for translate image in vector\n* visulize results vectors used PCA decomposition algorithm","7db41436":"## AutoEncoder","7d5816d4":"## Visualization PCA components"}}