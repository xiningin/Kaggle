{"cell_type":{"57cea709":"code","0b81ff46":"code","44760465":"code","c84ecdd9":"code","9520e244":"code","83e13b57":"code","d8835779":"code","2ca42d55":"code","5ae9d556":"code","27fb0f75":"code","d491e9c0":"code","5c609098":"code","8d91e2c8":"code","15726f15":"code","872dde38":"code","451e9c59":"code","00d8d52a":"code","6f5af7f3":"code","3b563f71":"code","41e4ed2f":"code","93fc5cc3":"code","7be97ac1":"code","458a93e2":"code","47dc12b9":"code","2e4420fa":"code","1f0039bd":"code","28e14cf4":"code","776091c7":"code","4e037272":"code","c69a635e":"code","3c263d21":"code","e0904f52":"code","696b6da0":"code","1a115718":"markdown","20a5101b":"markdown","55f4513e":"markdown","8ce71b9e":"markdown","4d4e26dd":"markdown","a86aba91":"markdown","9e54da0f":"markdown","343414b1":"markdown","bdcf20e7":"markdown","f3a94e75":"markdown","85bcbdac":"markdown","1632a5a5":"markdown","67515c84":"markdown","95d7b192":"markdown","baa7a0f4":"markdown","e2ea216e":"markdown","0942cc08":"markdown","df0281a8":"markdown","cc05b1ae":"markdown","0c257690":"markdown","0948f538":"markdown","9202ce1e":"markdown"},"source":{"57cea709":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt \nimport seaborn as sns\nimport tensorflow as tf \nimport tensorflow_datasets as tfds\nimport pathlib\nimport os\nfrom IPython.display import Image\nfrom sklearn.metrics import confusion_matrix","0b81ff46":"training_data_path = pathlib.Path(r\"..\/input\/intel-image-classification\/seg_train\/seg_train\")\ntesting_data_path = pathlib.Path(r\"..\/input\/intel-image-classification\/seg_test\/seg_test\")","44760465":"#This code is taken and modified from a notebook: https:\/\/www.kaggle.com\/saileshnair\/intel-image-classification\n\ndef plot_imgs(item_dir, top=10):\n    all_item_dirs = os.listdir(item_dir)\n    item_files = [os.path.join(item_dir, file) for file in all_item_dirs][100:106]\n  \n    plt.figure(figsize=(10, 10))\n  \n    for idx, img_path in enumerate(item_files):\n        plt.subplot(1, 6, idx+1)        \n        img = plt.imread(img_path)\n        plt.tight_layout() \n        plt.axis('off')\n        plt.imshow(img, cmap='gray')\n        ","c84ecdd9":"img_height = 224\nimg_width = 224\n\ntraining_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=40,\n                                                                    shear_range=0.2,\n                                                                    zoom_range=0.2,\n                                                                    horizontal_flip=True,\n                                                                    vertical_flip=True,\n                                                                    rescale=1\/255.0,\n                                                                    validation_split=0.25)\n\ntrain_generator = training_data_gen.flow_from_directory(training_data_path,\n                                                        target_size=(img_height, img_width),\n                                                        batch_size=64,\n                                                        shuffle=True,\n                                                        class_mode='categorical',\n                                                        subset='training') # set as training data\n\nvalidation_generator = training_data_gen.flow_from_directory(training_data_path, # same directory as training data\n                                                             target_size=(img_height, img_width),\n                                                             batch_size=64,\n                                                             shuffle=True,\n                                                             class_mode='categorical',\n                                                             subset='validation') # set as validation data\n\n#-------------------------------------------------------------------------------------------------------------\n\ntesting_data_gen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1\/255.0)\n\ntest_generator = testing_data_gen.flow_from_directory(testing_data_path,\n                                                      target_size=(img_height, img_width),\n                                                      batch_size=60,\n                                                      seed=0,\n                                                      shuffle=False,\n                                                      class_mode='categorical') ","9520e244":"for k in  test_generator.class_indices.keys():\n    plot_imgs(testing_data_path\/k)","83e13b57":"Image(url='https:\/\/cdn.analyticsvidhya.com\/wp-content\/uploads\/2018\/10\/Screenshot-from-2018-10-17-11-14-10.png',\n      width=750,\n      height=500)","d8835779":"Image(url='https:\/\/miro.medium.com\/max\/2434\/1*_rCyzi7fQzc_Q1gCqSLM1g.png',\n      width=750,\n      height=500)","2ca42d55":"from tensorflow.keras.applications import inception_v3","5ae9d556":"base_model = inception_v3.InceptionV3(weights='imagenet', include_top=False,\n                                     input_shape=(224, 224, 3))","27fb0f75":"for layer in base_model.layers:\n    layer.trainable = False","d491e9c0":"inc_model = tf.keras.models.Sequential()\n\ninc_model .add(base_model)\n\ninc_model.add(tf.keras.layers.Flatten())\ninc_model.add(tf.keras.layers.Dense(256, activation='relu'))\ninc_model.add(tf.keras.layers.BatchNormalization())\ninc_model.add(tf.keras.layers.Dropout(0.4))\n\ninc_model.add(tf.keras.layers.Dense(128, activation='relu'))\ninc_model.add(tf.keras.layers.BatchNormalization())\ninc_model.add(tf.keras.layers.Dropout(0.4))\n\n\ninc_model.add(tf.keras.layers.Dense(6, activation='softmax'))","5c609098":"inc_model.summary()","8d91e2c8":"inc_model.compile(loss='categorical_crossentropy',\n                  optimizer='rmsprop',\n                  metrics=['acc'])","15726f15":"inc_model.fit(train_generator, steps_per_epoch=164, \n              validation_data= validation_generator, validation_steps=54,\n              epochs=10)","872dde38":"base_model.trainable = True \n\nse_trainable = False\n\nfor layer in base_model.layers:\n    if layer.name == \"conv2d_945\":\n        set_trainable = True\n    if se_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","451e9c59":"inc_model.compile(loss='categorical_crossentropy',\n                  optimizer=tf.keras.optimizers.RMSprop(learning_rate=1e-5),\n                  metrics=['acc'])","00d8d52a":"inc_history = inc_model.fit(train_generator, steps_per_epoch=164, \n                            validation_data= validation_generator, validation_steps=54,\n                            epochs=15)","6f5af7f3":"inc_model.evaluate(test_generator)","3b563f71":"# testset model predictions\npredictions = inc_model.predict(test_generator)\n\n# testset model predictions\nready_predictions = []\n\nfor pred in predictions:\n    ready_predictions.append(np.argmax(pred))\nready_predictions = np.array(ready_predictions)\n\n#----------------------------------------------------------------\n\ntest_labels = []\n\nfor i in range(0,50):\n    test_labels.extend(np.array(test_generator[i][1]))\n\n# the True labels\nready_labels = []\n\nfor label in test_labels:\n    ready_labels.append(np.argmax(label))\n    \nready_labels = np.array(ready_labels)\n\n#----------------------------------------------------------------\n\n#boolean array that True = correct classification, False = incorrect classificaition\nis_correct = ready_predictions == ready_labels\nis_correct = pd.Series(is_correct)\n\n#----------------------------------------------------------------\n\ndr_error_analysis = pd.DataFrame([ready_predictions, ready_labels, is_correct]).T\ndr_error_analysis.columns=['Predictions', 'True_Labels', 'Classification']\n\ndr_error_analysis[\"Predictions\"].replace({0: \"buildings\", 1: \"forest\",\n                                         2: \"glacier\", 3: \"mountain\", \n                                         4: \"sea\", 5: \"street\"}, inplace=True)\n\ndr_error_analysis[\"True_Labels\"].replace({0: \"buildings\", 1: \"forest\",\n                                         2: \"glacier\", 3: \"mountain\", \n                                         4: \"sea\", 5: \"street\"}, inplace=True)\n\ndr_error_analysis[\"Classification\"].replace({True: \"correct\", False: \"incorrect\"}, inplace=True)","41e4ed2f":"#This is out dataframe\ndr_error_analysis","93fc5cc3":"incorrect_df = dr_error_analysis[dr_error_analysis['Classification']==\"incorrect\"]","7be97ac1":"incorrect_df[incorrect_df['True_Labels']==\"buildings\"].iloc[30:50]","458a93e2":"incorrect_df[incorrect_df['True_Labels']==\"street\"].iloc[25:50]","47dc12b9":"print(\"There are {} misclassified street images in the test set\".format(len(incorrect_df[incorrect_df['True_Labels']==\"street\"])))","2e4420fa":"print(\"There are {} misclassified building images in the test set\".format(len(incorrect_df[incorrect_df['True_Labels']==\"buildings\"])))","1f0039bd":"for k in  test_generator.class_indices.keys():\n    if k == 'buildings' or k == \"street\":\n        plot_imgs(testing_data_path\/k)","28e14cf4":"incorrect_df[incorrect_df['True_Labels']==\"glacier\"].iloc[40:50]","776091c7":"print(\"There are {} misclassified glacier images in the test set\".format(len(incorrect_df[incorrect_df['True_Labels']==\"glacier\"])))","4e037272":"for k in  test_generator.class_indices.keys():\n    if k == 'glacier' or k == \"mountain\":\n        plot_imgs(testing_data_path\/k)","c69a635e":"incorrect_df[incorrect_df['True_Labels']==\"sea\"].iloc[20:28]","3c263d21":"print(\"There are {} misclassified sea images in the test set\".format(len(incorrect_df[incorrect_df['True_Labels']==\"sea\"])))","e0904f52":"for k in  test_generator.class_indices.keys():\n    if k == 'sea':\n        plot_imgs(testing_data_path\/k)","696b6da0":"cm = confusion_matrix(ready_labels, ready_predictions)\n\ncm_df = pd.DataFrame(cm,\n                     index = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"], \n                     columns = [\"buildings\", \"forest\", \"glacier\", \"mountain\", \"sea\", \"street\"])\n\n#Plotting the confusion matrix\nplt.figure(figsize=(8,8))\nsns.heatmap(cm_df, annot=True, fmt='d')\nplt.title('Confusion Matrix')\nplt.ylabel('Actal Values')\nplt.xlabel('Predicted Values')\nplt.show()","1a115718":"**Thank you for reading, I hope you enjoyed and benefited from it.**\n\n**If you have any questions or notes please leave it in the commont section.**\n\n**If you like this notebook please press upvote and thanks again.**","20a5101b":"The **heat-map** below summarize our discussion about error analysis where: \n    \n- 34 of the building images in the testset classified as street.\n\n- 78 of the glacier images in the testset classified as mountain and 60 of the mountain images classified as glacier.\n\n- 23 of the glacier images in the testset classified as sea.\n\n- 11 of the mountain images in the testset classified as sea","55f4513e":"As we can see from the table above there are a lot of the glacier images classified as mountain, form the figures bellow we can see that most of the tall mountains have snow on them and clouds around them. There is a lot of white in both images which makes it difficult for the classifier to distinguish between them. ","8ce71b9e":"# 2.2 Transfer learning using  GoogLeNet in keras","4d4e26dd":"As we can see from the table above there are a some of the building images classified as street, also \nalot of the street images classified as building. \n\nThe reason for this misclassification is that the street images does not contain just a street, but contain streets and \nbuildings and vice versa alot of the building images contain streets as you can see from the figures below, to solve this problem we need to modify the images \nmaybe we can crop the street images and remove the building from it and aslo crop the building images and remove the streets\nfrom them. ","a86aba91":"First thing we will freeze all the layers to train the classifier. I the first stage I will freeze then because the error \nthat will be propagated through the network will be high se we do not want to harm the pretrained weights. ","9e54da0f":"unfreeze layers from 'conv2d_937' to the end of the network ","343414b1":"**Transfer learning** is the process of transfer the knowledge that the network learned in a dataset to new similar problem.\n\n\nWhen using pretrained network what we are doing is: downloading the netwrok architacture and the weights and \nuse then in the new problem. \n    \n    \nAs we going deeper in the network, filters in the deep layers learn features specific to the data set trained on such \nas eyes, car wheels, ... while the filters in the first layers learn general features such as edges. \n\n\nThe last layers are dense layers used for classification, we will remove these layers and use the rest and fine-tune them. \n\nwe can just use the **pre-trained network** as a **feature extractor**, but since our dataset is very different from imagenet\ndata set we will fine-tune the network. ","bdcf20e7":"# 3- Error Analysis   ","f3a94e75":"# 4- Conclusion ","85bcbdac":"Here I want to understand the errors that the model makes on the test set and why the model makes these errors. \n\nI will make a datafram consists of 3 columns, the first one is the model prediction on the test set and the second column is \nthe true labels of the test set and finally the last column tell us if the prediction is correct or not. ","1632a5a5":"In this notebook I will present the **inception network** briefly, then we will apply it using transfer learning. \n\nThe model will be freezed and a classifier will be added on top of it, the we will train the classifier while the base is freezed and used as a feature extractor, then we will fine tune the final layers of the pretrained network. \n\nSimple **error analysis** will be performed to understand the errors that the model will make. ","67515c84":"Inception Network also called GoogLeNet developed by Google at 2014, they reduce the number of parameters to learn form \n138 million in the VGGNet to just 13 million parameters with a deeper network. \n\nThe idea in GoogLeNet is instead of choosing between Pooling layer, 3x3 conv layer, 5x5 conv layer... we cal apply them all \nin one block. It consist of different parallel layers and the output of them is concatenated at the depth dimention. \n\nin the figure below we can see the inception block. ","95d7b192":"In the block we used \"same\" padding to make the output of the layers same size as the input, so we calconcatenat them. \n\nThey used 1x1 convolutional layer, this kayer is called **reducee layer** because it reduce the depth of the input \nform input_depth to the number of filters this layer has, the goal of using such layer is to reduce the number of \noperations so the computational cost is reduced. This layer preserve the spatial dimentions while reductinf the depth of \nthe image, it also called **Bottleneck layer**\n\n**Inception architecture** is a series of inception models (like the one in the above figure) starting with a conv and maxpooling\nlayers and ending with a fully connected layers (the classifier).","baa7a0f4":"Now since the last layers in the network learned features that specific to the imagenet dataset such as eyes, car parts, etc.. \nwe need to **fine-tune** these layers becasue our data is mountains and building :) ","e2ea216e":"Now we will continue training the model but we will use lower learning rate because we do not want to change the pretrained weights a lot.","0942cc08":"# 2.1 Introduction to GoogLeNet","df0281a8":"As we can see the test set accuracy is 90%","cc05b1ae":"# 2- Understanding GoogLeNet  ","0c257690":"As we can see from the table above there are a some of the sea images classified as mountain or glacier, form the figures above we can see that there are alot of  mountain and glacier images have a blue sky in the background which makes it difficult for the classifier to distinguish between them and the sea images below.","0948f538":"# 1- Image Data Generator ","9202ce1e":"In this notebook we first start with an introduction about the **inception network** that consists of a series of inception blocks, then we apply it using transfer learning by first adding a classifier on top of the freezed weights feature extractor and train the classifier, then we unfreeze the last blocks of the feature extractor and fine-tune it. the accuracy of the model was 90% which is good. \n\n\nFinnaly we apply error analysis to understand the errors that the model makes and the following aspects were observed: \n    \n    1- The model was misclassifying some of the building and street images because building images contain streets and \n    street images contrain buildings. \n    \n    2- the model was misclassifying some of the glacier images and predict them as mountains and vice versa because \n    mountain images contain snow and clouds so a lot of white color in mountain images will confuse the model. \n    \n    3- some of the sea images classified as mountain or glacier there are alot of  mountain and glacier images have a blue \n    sky in the background which makes it difficult for the classifier to distinguish between them and the blow sea"}}