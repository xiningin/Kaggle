{"cell_type":{"a62c03bd":"code","4b8cfc58":"code","0ec9752f":"code","255236af":"code","1328c8d1":"code","7b92552d":"code","5a8c29f5":"code","b712306b":"code","718bd5e3":"code","eedfdb96":"code","4a57a7d3":"code","7d0b9da5":"code","5d84f78e":"markdown","2413749b":"markdown","faf1f111":"markdown","16b65130":"markdown","4a1c3fd0":"markdown"},"source":{"a62c03bd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4b8cfc58":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPool2D,Dense,Flatten,Dropout\n","0ec9752f":"bs=16 # Increase Batch size based on your hardware capacity, if you have powerful GPU try BS=128,256...\ntrain_path=r'..\/input\/bird-species-classification-220-categories\/Train'\ntest_path=r'..\/input\/bird-species-classification-220-categories\/Test'","255236af":"train_gen=ImageDataGenerator(rescale=1.\/255)\nData_train=train_gen.flow_from_directory(train_path,target_size=(150,150),class_mode='categorical',batch_size=bs)\n\ntest_gen=ImageDataGenerator(rescale=1.\/255)\nData_test=test_gen.flow_from_directory(test_path,target_size=(150,150),class_mode='categorical',batch_size=bs)","1328c8d1":"\nmodel=Sequential()\nmodel.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(150,150,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(filters=32,kernel_size=(4,4),input_shape=(150,150,3),activation='relu'))\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(Flatten())\nmodel.add(Dense(512,activation='relu'))\nmodel.add(Dense(200,activation='softmax'))\nmodel.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])","7b92552d":"model.summary()","5a8c29f5":"training_steps = Data_train.samples\/\/Data_train.batch_size\nvalidation_steps=Data_test.samples\/\/Data_test.batch_size\nhistory=model.fit_generator(Data_train,epochs=10,steps_per_epoch=training_steps,validation_data=Data_test,validation_steps=validation_steps)","b712306b":"pd.DataFrame(history.history).plot()","718bd5e3":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nimport os\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n\n# Create an instance of the inception model from the local pre-trained weights\n# local_weights_file = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'","eedfdb96":"pre_trained_model = InceptionV3(\n    input_shape=(150, 150, 3),\n    include_top=False,\n    weights='imagenet'\n)\n\n# Make all the layers in the pre-trained model non-trainable\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n\n# Print the model summary\npre_trained_model.summary()","4a57a7d3":"last_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output\n\nfrom tensorflow.keras.optimizers import RMSprop\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense(1, activation='sigmoid')(x)           \n\nmodel = Model(pre_trained_model.input, x) \n\nmodel.compile(\n    optimizer=RMSprop(lr=0.0001), \n    loss='binary_crossentropy', \n    metrics=['accuracy']\n)\n\nmodel.summary()","7d0b9da5":"training_steps = Data_train.samples\/\/Data_train.batch_size\nvalidation_steps=Data_test.samples\/\/Data_test.batch_size\ninceptionv3_history=model.fit_generator(Data_train,epochs=2,steps_per_epoch=training_steps,validation_data=Data_test,validation_steps=validation_steps)","5d84f78e":"### This is not the behaviour we are expecting. First of all our model overfits, if you see the validation loss increased a lot with each and every epoch. It is due to the below reasons.\n\n1. Our Model is not deep enough, we need to add more layers.\n2. We might need to train model for more number of epochs before it overfits\n3. Add more data, or we can perform image augmentation. \n4. Or we can use pretrained models.","2413749b":"### Between the 1% accuracy and 99.5% accuracy we have lot to explore, we can prepare deep networks and train for more number of epohs or we can generate more data from external sources or we can use the data augmentation. \n\n### Please share your results as new Kernals and if you like my work please upvote. \n\n### Thank you.\n","faf1f111":"### This is amazing, We were strugling to get atleast 1% accuracy using basic network, but with pretrained model we are easily able to acheive 99.5% validation accuracy in 2 epochs. This is majorly due to the fact that the dataset has lot of overlapping with imagenet data, so the pretrained model Inception V3 was able to directly identify the patterns from images.","16b65130":"### Context\n\nThis data set is a multi class classification which is a difficult problem set to classify since these images are close to each other and similarity is very high. This will be intresting to solve, and using pretrained models it might be easy, but in general to train it from scratch is difficult, but we can learn a lot meanwhile.","4a1c3fd0":"## Pretrained Model"}}