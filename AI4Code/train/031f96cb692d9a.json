{"cell_type":{"aae2b78f":"code","304933f1":"code","afec19f4":"code","abde28b1":"code","1b0d59e2":"code","ac1a7899":"code","18aaa9da":"code","bb294b45":"code","c2dabe3d":"code","827b6451":"code","f95efd09":"code","cef30ca2":"code","38cc3999":"code","ba9b3828":"code","3549f7b4":"code","03c33dbc":"code","f3f3f95e":"code","94fc85d7":"code","dd608610":"code","676b3924":"code","b11c5c61":"code","29015202":"code","b7988085":"code","d0549672":"code","7cf3996e":"code","f602d05b":"code","220f3262":"code","0c236117":"code","ca07631a":"code","76904919":"code","b06950a4":"code","32524ac2":"code","db48576f":"code","6e51bb02":"code","3cbc1ac4":"code","b35c4c72":"code","5267ebec":"code","d6718457":"code","f73f98ca":"code","27448728":"code","0dca6d89":"code","a64a7f2d":"code","4cde24fe":"code","3b27a6b6":"code","1230a4d9":"code","27018bce":"code","619fa25b":"code","94180ae2":"code","ca065028":"code","29808eda":"code","db4b822a":"code","6f5972d8":"code","31114840":"code","554140a2":"code","6faae221":"code","0aff671f":"code","65f1881d":"code","f9736909":"code","bfddca93":"code","5e39379c":"code","bd445f57":"code","cfaab805":"code","8c9bfbe5":"code","4eb5a0f3":"code","534f7fb7":"code","f6e2d4d5":"code","6a628f77":"code","ebd7f1a7":"code","f17518dc":"code","c3e16622":"code","93b4031e":"code","e6f4ddbb":"code","1f443a31":"code","d9e4d900":"code","c4dd49e9":"markdown","65112a02":"markdown","eb0e4b7d":"markdown","8c9f0992":"markdown","494f5a0b":"markdown","4fed4f7b":"markdown","1683a9d6":"markdown","567dadcd":"markdown","e9945763":"markdown","5ec6aa98":"markdown","8cf55c00":"markdown","6d52892f":"markdown","cb189af1":"markdown","2d720c60":"markdown","7983df2a":"markdown","d5088388":"markdown","2d882630":"markdown","01976ccd":"markdown","97f829d5":"markdown","13b0475c":"markdown","3669fd15":"markdown","133bc850":"markdown","2ceca068":"markdown","2147a007":"markdown","57704d12":"markdown","3b2b19e6":"markdown","320de23a":"markdown","4d53d449":"markdown"},"source":{"aae2b78f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px","304933f1":"df = pd.read_csv('..\/input\/bankmarketingdatasetbank\/bank.csv')","afec19f4":"import pandas_profiling as pp\npp.ProfileReport(df)","abde28b1":"df.shape","1b0d59e2":"df.info()","ac1a7899":"df.describe()","18aaa9da":"df.describe(include='object')","bb294b45":"categorical_features=[feature for feature in df.columns if ((df[feature].dtypes=='O') & (feature not in ['deposit']))]\ncategorical_features","c2dabe3d":"for feature in categorical_features:\n    print('The feature is {} and number of categories are {}'.format(feature,len(df[feature].unique())))","827b6451":"#check count based on categorical features\nplt.figure(figsize=(15,80), facecolor='white')\nplotnumber =1\nfor categorical_feature in categorical_features:\n    ax = plt.subplot(12,3,plotnumber)\n    sns.countplot(y=categorical_feature,data=df)\n    plt.xlabel(categorical_feature)\n    plt.title(categorical_feature)\n    plotnumber+=1\nplt.show()","f95efd09":"#check target label split over categorical features\n#Find out the relationship between categorical variable and dependent variable\nfor categorical_feature in categorical_features:\n    sns.catplot(x='deposit', col=categorical_feature, kind='count', data= df)\nplt.show()","cef30ca2":"for categorical_feature in categorical_features:\n    print(df.groupby(['deposit',categorical_feature]).size())","38cc3999":"numerical_features = [feature for feature in df.columns if ((df[feature].dtypes != 'O') & (feature not in ['deposit']))]\nprint('Number of numerical variables: ', len(numerical_features))\n\n\ndf[numerical_features].head()","ba9b3828":"discrete_feature=[feature for feature in numerical_features if len(df[feature].unique())<25]\nprint(\"Discrete Variables Count: {}\".format(len(discrete_feature)))","3549f7b4":"continuous_features=[feature for feature in numerical_features if feature not in discrete_feature+['deposit']]\nprint(\"Continuous feature Count {}\".format(len(continuous_features)))","03c33dbc":"plt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor continuous_feature in continuous_features:\n    ax = plt.subplot(12,3,plotnumber)\n    sns.distplot(df[continuous_feature])\n    plt.xlabel(continuous_feature)\n    plotnumber+=1\nplt.show()","f3f3f95e":"plt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor feature in continuous_features:\n    ax = plt.subplot(12,3,plotnumber)\n    sns.boxplot(x=\"deposit\", y= df[feature], data=df)\n    plt.xlabel(feature)\n    plotnumber+=1\nplt.show()","94fc85d7":"print(df.isnull().sum())","dd608610":"plt.figure(figsize=(15, 5))\nsns.countplot(x = \"job\", data = df, label = \"Count\")\nplt.show()","676b3924":"sns.countplot(x = \"marital\", data=df, hue = \"deposit\")\nplt.show()","b11c5c61":"plt.figure(figsize=(15, 5))\nsns.countplot(x = \"education\", data = df, hue = \"deposit\")\nplt.show()\n","29015202":"sns.countplot(x =\"default\", data = df, hue = \"deposit\")\nplt.show()","b7988085":"sns.countplot(x = \"contact\", data = df, hue = \"deposit\")\nplt.show()","d0549672":"sns.countplot(x = \"loan\", data = df,label = \"Count\")\nplt.show()","7cf3996e":"plt.figure(figsize=(15,5))\nsns.heatmap(df.corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")","f602d05b":"sns.countplot(x = \"month\", data = df, hue= \"deposit\")","220f3262":"sns.countplot(x = \"poutcome\", data = df, hue= \"deposit\")\nplt.show()","0c236117":"sns.boxplot(x = \"deposit\", y = \"duration\", data = df)\nplt.show()","ca07631a":"sns.violinplot(x = \"deposit\", y = \"duration\", data = df)\nplt.show()","76904919":"plt.figure(figsize=(20,60), facecolor='white')\nplotnumber =1\nfor numerical_feature in numerical_features:\n    ax = plt.subplot(12,3,plotnumber)\n    sns.boxplot(df[numerical_feature])\n    plt.xlabel(numerical_feature)\n    plotnumber+=1\nplt.show()","b06950a4":"cor_mat=df.corr()\nfig = plt.figure(figsize=(15,7))\nsns.heatmap(cor_mat,annot=True)","32524ac2":"df.dropna(inplace=True)","db48576f":"df.plot.box()\nplt.xticks(list(range(len(df.columns))),df.columns, rotation=\"vertical\")","6e51bb02":"ax = sns.boxplot(x=\"age\" , data=df)","3cbc1ac4":"df2=df.copy()","b35c4c72":"low = 0.01\nhigh = 0.99\nqdf=df2.quantile([low,high])\n","5267ebec":"df2.age= df2.age.apply(lambda v:v if qdf.age[low]< v < qdf.age[high] else np.nan)","d6718457":"ax = sns.boxplot(x=\"age\" , data=df2)","f73f98ca":"#Checki Oultier\ndf2.groupby(['deposit','default']).size()","27448728":"#Removing Outlier\ndf2.drop(['default'],axis=1, inplace=True)","0dca6d89":"#Checki Oultier\ndf2.groupby(['deposit','pdays']).size()","a64a7f2d":"# drop pdays as it has -1 value for around 40%+ \ndf2.drop(['pdays'],axis=1, inplace=True)","4cde24fe":"# remove outliers in feature balance...\ndf2.groupby(['deposit','balance'],sort=True)['balance'].count()\n# these outlier should not be remove as balance goes high, client show interest on deposit","3b27a6b6":"# remove outliers in feature duration...\ndf2.groupby(['deposit','duration'],sort=True)['duration'].count()\n# these outlier should not be remove as duration goes high, client show interest on deposit","1230a4d9":"# remove outliers in feature campaign...\ndf2.groupby(['deposit','campaign'],sort=True)['campaign'].count()","27018bce":"df3 = df2[df2['campaign'] < 33]","619fa25b":"# remove outliers in feature previous...\ndf3.groupby(['deposit','previous'],sort=True)['previous'].count()","94180ae2":"df4 = df3[df3['previous'] < 31]","ca065028":"cat_columns = ['job', 'marital', 'education', 'contact', 'month', 'poutcome']\nfor col in  cat_columns:\n    df4 = pd.concat([df4.drop(col, axis=1),pd.get_dummies(df4[col], prefix=col, prefix_sep='_',drop_first=True, dummy_na=False)], axis=1)","29808eda":"bool_columns = ['housing', 'loan','deposit']\nfor col in  bool_columns:\n    df4[col+'_new']=df4[col].apply(lambda x : 1 if x == 'yes' else 0)\n    df4.drop(col, axis=1, inplace=True)","db4b822a":"df4.head()","6f5972d8":"print(df4.isnull().sum())","31114840":"df4.dropna(inplace=True)","554140a2":"import pandas_profiling as pp\npp.ProfileReport(df)","6faae221":"X = df4.drop(['deposit_new'],axis=1)\ny = df4['deposit_new']\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2, random_state=42)","0aff671f":"len(X_train)","65f1881d":"len(X_test)","f9736909":"from sklearn.preprocessing import StandardScaler\n\nfeatures = ['campaign', 'previous']\n\nx_pca = df4.loc[:, features].values\nx_pca = StandardScaler().fit_transform(x_pca)","bfddca93":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\n\nprincipalComponents = pca.fit_transform(x_pca)\nprincipalDF = pd.DataFrame(data = principalComponents, columns=['PC1', 'PC2'])","5e39379c":"pca.components_","bd445f57":"pca.explained_variance_ratio_\n","cfaab805":"# Concatenation of dataframes\ndf_all = pd.concat([principalDF, df4], axis=1)\nplt.figure(figsize=(15,5))\nsns.heatmap(df_all.corr(), annot=True, fmt = \".2f\", cmap = \"coolwarm\")","8c9bfbe5":"import xgboost as xgb\n\nfrom sklearn.neighbors import KNeighborsClassifier\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, f1_score, confusion_matrix\nfrom sklearn.metrics import r2_score,confusion_matrix, mean_squared_error,accuracy_score, f1_score,classification_report\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.linear_model import LogisticRegression\nfrom xgboost import XGBClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nimport warnings\nfrom sklearn import metrics\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","4eb5a0f3":"rf = RandomForestClassifier() \nrf.fit(X_train, y_train)\nrf_pred = rf.predict(X_test)\n\nprint(round(accuracy_score(y_test, rf_pred),2)*100)","534f7fb7":"RForest=RandomForestClassifier(n_estimators=20)\nRForest.fit(X_train,np.ravel(y_train,order='C'))\nRFPred=RForest.predict(X_test)\n#rint(\"Random Forest Accuracy : \" ,accuracy_score(y_test,RFPred))\n\nprint(\"Cross Valudate Score : \", cross_val_score(RForest,X_test,y_test.values.ravel()))\nprint(\"Confisuon matrix :\", confusion_matrix(y_test,RFPred.ravel()))\nprint(classification_report(y_test,RFPred))","f6e2d4d5":"BayesModel=GaussianNB()\nBayesModel.fit(X_train,y_train.values.ravel())\nbayesPred=BayesModel.predict(X_test)\nprint(\"Bayes Model Accuracy :\", accuracy_score(y_test,bayesPred.ravel()))\nprint(\"Cross val score :\", cross_val_score(BayesModel,X_train,y_train.values.ravel(),cv=10,n_jobs=2,scoring='accuracy').mean())","6a628f77":"#grid={'n_neighbors': np.arange(1,20,1)}\nKnnClass=KNeighborsClassifier(n_neighbors=9)\n#KnnCV=GridSearchCV(KnnClas, grid, cv=10)\nKnnClass.fit(X_train,np.ravel(y_train,order='C'))\n#print(\"Best Parameters : {}\\nBest Score {} \".format(KnnCV.best_params_, KnnCV.best_score_) )","ebd7f1a7":"\nXgboost=XGBClassifier(learning_rate=0.1,max_depth=4, n_estimators=100,verbosity=1)\nXgboost.fit(X_train,np.ravel(y_train,order='C'))\ny_pred=Xgboost.predict(X_test)\nprint(\"Test accuracy with XGBoos: \",accuracy_score(y_test,y_pred))","f17518dc":"grid={'C':[0.0001,0.001,0.01,1] ,'gamma':['auto','scale'],'kernel':['rbf','linear','sigmoid'] , 'max_iter':[10,100]}\nSVCModel=SVC(probability=True)\nSVCGCV=GridSearchCV(SVCModel,grid,cv=10)\nSVCGCV.fit(X_train,np.ravel(y_train, order='C'))\nprint(\"Best Params {} and best score {}\".format(SVCGCV.best_params_, SVCGCV.best_score_))\n#print(SVCModel.score(x_test,np.ravel(y_test, order='C')))","c3e16622":"fig, ax_Array = plt.subplots(nrows = 1,  figsize = (8,6))\n\n# bayes roc\nprobs = BayesModel.predict_proba(X_test)\npreds = probs[:,1]\nfprbayes, tprxbayes, thresholdbayes = metrics.roc_curve(y_test, preds)\nroc_aucbayes = metrics.auc(fprbayes, tprxbayes)\n\n\n# KNN roc\nprobs=KnnClass.predict_proba(X_test)\npredKnn=probs[:,1]\nfprKnn, tprKnn, thresholdKnn=metrics.roc_curve(y_test,predKnn)\nroc_aucknn=metrics.auc(fprKnn,tprKnn)\n\n\n# Random Forest \nprobs=RForest.predict_proba(X_test)\npred_RForest=probs[:,1]\nfprRF,tprRF,thresholfRF= metrics.roc_curve(y_test,pred_RForest)\nroc_aucRF=metrics.auc(fprRF,tprRF)\n\n # SVM model roc\n \nprob=SVCGCV.predict_proba(X_test)\npred_Svm=prob[:,1]\nfprSvm,tprsvm,tresholdSvm=metrics.roc_curve(y_test,pred_Svm)\nroc_aucSvm=metrics.auc(fprSvm,tprsvm) \n\n\n\n\nax_Array.plot(fprSvm,tprsvm, 'b', label='SMV Auc %0.2f' %roc_aucSvm, color=\"green\")\nax_Array.plot(fprRF,tprRF,'b', label=\"RF Auc %0.2f\"%roc_aucRF, color=\"blue\")\nax_Array.plot(fprKnn,tprKnn,'b', label=\"Knn Auc %0.2f\" %roc_aucknn, color=\"red\")\nax_Array.plot(fprbayes,tprxbayes,'b', label='Bayes Auc %0.2f' % roc_aucbayes, color=\"black\")\nax_Array.set_title('Receiver Operating Characteristic LR ',fontsize=10)\nax_Array.set_ylabel('True Positive Rate',fontsize=20)\nax_Array.set_xlabel('False Positive Rate',fontsize=15)\nax_Array.legend(loc = 'lower right', prop={'size': 10})\n\n\n\nplt.subplots_adjust(wspace=1)","93b4031e":"\nfrom sklearn.ensemble import RandomForestRegressor\nrf = RandomForestRegressor(n_estimators=1)\ntrees, train_loss, test_loss = [], [], []\nfor iter in range(20):\n    rf.fit(X_train, y_train)\n    y_train_predicted = rf.predict(X_train)\n    y_test_predicted = rf.predict(X_test)\n    mse_train = mean_squared_error(y_train, y_train_predicted)\n    mse_test = mean_squared_error(y_test, y_test_predicted)\n    #print(\"Iteration: {} Train mse: {} Test mse: {}\".format(iter, mse_train, mse_test))\n    trees += [rf.n_estimators]\n    train_loss += [mse_train]\n    test_loss += [mse_test]\n    rf.n_estimators += 1\nplt.figure(figsize=(8,6))  \nplt.plot(trees, train_loss, color=\"blue\", label=\"MSE on Train data\")\nplt.plot(trees, test_loss, color=\"red\", label=\"MSE on Test data\")\nplt.xlabel(\"# of trees\")\nplt.ylabel(\"Mean Squared Error\");\nplt.legend()","e6f4ddbb":"#rf.fit(X_train, y_train)\n#rf_pred = rf.predict(X_test)\npredict = rf.predict(X_test)\npredict","1f443a31":"real_full=df4['deposit_new']\nreal=real_full[:1000]\n\npred = rf.predict(X_test)\n\ndf4_1=pd.DataFrame({'real': real, 'prediction':pred[:1000]})","d9e4d900":"df4.head()","c4dd49e9":"## Relationship between Categorical Features and Label","65112a02":"## Categorical Data","eb0e4b7d":"## Dataframe Check","8c9f0992":"## Bayes Model","494f5a0b":"##  Convert Categorical into Numeric Form","4fed4f7b":"## Continous Numerical Features","1683a9d6":"## Mean Squared Error","567dadcd":"## Distribution of Continous Numerical Features","e9945763":"## Relation between Continous numerical Features and Labels","5ec6aa98":"## Checking Outliers","8cf55c00":"## **Random Forest, Cross Validation and Confusion Matrix**","6d52892f":"# **Split Dataset into Training set and Test set**","cb189af1":"Logistic Regression","2d720c60":"## Checking outlier of age attribute\n","7983df2a":"If you want, we could integrate \"primary\" and \"secondary\" as they have similar factorial level. But I think the categories are reasonable. We could make the class by number such as 1: primary, 2: secondary, 3: tertiary, however, it is difficult how to classify the \"unknown\". Then it might be treated as the categories separately.","d5088388":"## SVM","2d882630":"## Handleing Outliers","01976ccd":"## Xg Boost Classifier","97f829d5":"# **Feature Engineering**","13b0475c":"## **Predictions**","3669fd15":"## Correlation between numerical features","133bc850":"##  Numerical Features","2ceca068":"## K-Neighbors Classifier","2147a007":"##  Discrete Numerical Features","57704d12":"## Feature Analysis","3b2b19e6":"##  Different Classifiers libraries","320de23a":"## Find Outliers","4d53d449":"# **Data Distribution**"}}