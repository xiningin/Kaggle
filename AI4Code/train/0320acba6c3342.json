{"cell_type":{"010e995e":"code","044f3c8a":"code","2f7b81f8":"code","7f4d38fb":"code","c5c074f7":"code","af1a0825":"code","8b6c9571":"code","4a858b74":"code","c0f20d6b":"code","d645edd3":"code","f771a942":"code","bd354be2":"code","e187a1ba":"code","68f1e27f":"code","7931fc00":"markdown"},"source":{"010e995e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","044f3c8a":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","2f7b81f8":"X_train = train.drop(\"label\",axis=1)\nX_train = X_train.values.reshape(-1,28,28,1)\nX_test = test.values.reshape(-1,28,28,1)\nprint(X_train.shape)\nprint(X_test.shape)","7f4d38fb":"X_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nX_train \/= 255\nX_test \/= 255","c5c074f7":"from tensorflow.keras.utils import to_categorical\ny_train = train.pop(\"label\")\ny_train = y_train.values\nprint(y_train.shape)\ny_train = to_categorical(y_train, num_classes=10)\nprint(y_train.shape)\nprint(y_train[0])","af1a0825":"import tensorflow as tf","8b6c9571":"def squeeze_excite_block(filters,input):                      \n    se = tf.keras.layers.GlobalAveragePooling2D()(input)\n    se = tf.keras.layers.Reshape((1, filters))(se) \n    se = tf.keras.layers.Dense(filters\/\/16, activation='relu')(se)\n    se = tf.keras.layers.Dense(filters, activation='sigmoid')(se)\n    se = tf.keras.layers.multiply([input, se])\n    return se","4a858b74":"def make_model():\n        s = tf.keras.Input(shape=X_train.shape[1:]) \n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(s)\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = squeeze_excite_block(32,x)\n\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = squeeze_excite_block(32,x)\n        x = tf.keras.layers.AveragePooling2D(2)(x)\n\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = squeeze_excite_block(32,x)\n        x = tf.keras.layers.AveragePooling2D(2)(x)        \n\n\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.Conv2D(32,(3,3),activation='relu',padding='same')(x)\n        x = tf.keras.layers.BatchNormalization()(x)\n        x = squeeze_excite_block(32,x)\n        x = tf.keras.layers.AveragePooling2D(2)(x)\n\n\n        x = tf.keras.layers.concatenate([tf.keras.layers.GlobalMaxPooling2D()(x),\n                                         tf.keras.layers.GlobalAveragePooling2D()(x)])\n\n        x = tf.keras.layers.Dense(10,activation='softmax',use_bias=False,\n                                  kernel_regularizer=tf.keras.regularizers.l1(0.00025))(x)\n        return tf.keras.Model(inputs=s, outputs=x)","c0f20d6b":"from tensorflow.keras import optimizers\nmodel=make_model()                \nmodel.compile(optimizer=optimizers.Adam(lr=0.0001), loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()","d645edd3":"model.fit(x=X_train, y=y_train, batch_size=32, epochs=15)","f771a942":"pred = model.predict(X_test,verbose=1)\npredictions = pred.argmax(axis=-1)","bd354be2":"sub = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission = sub['ImageId']","e187a1ba":"pred = pd.DataFrame(data=predictions ,columns=[\"Label\"])\nDT = pd.merge(submission , pred, on=None, left_index= True,\n    right_index=True)\nDT.head()","68f1e27f":"DT.to_csv('submission.csv',index = False)","7931fc00":"#### Here i am using the squeeze and excitation block as proposed in https:\/\/arxiv.org\/pdf\/1709.01507.pdf\n#### Example of the code is taken from https:\/\/github.com\/Matuzas77\/MNIST-0.17 and https:\/\/github.com\/titu1994\/keras-squeeze-excite-network\n![image.png](attachment:image.png)"}}