{"cell_type":{"c15b9a2c":"code","b520dede":"code","e5e3b0f5":"code","e068a153":"code","8aa9e1dd":"code","bd0f14a7":"code","1a30ea09":"code","caafb9a2":"code","31e971fd":"code","789d12f1":"code","a88bfcc6":"code","2e5efcee":"code","c6e3950a":"code","adb91510":"code","9ac20519":"code","9fdfa804":"code","7f7a6567":"code","3c019ffe":"code","5b07ee06":"code","fb88d852":"code","9d9409a0":"code","d357fe3b":"code","24d039bc":"code","ae4e1415":"code","97ec3dbb":"code","f03e493a":"code","45f00b69":"code","19c0fedd":"markdown","122d678b":"markdown","1968e8c9":"markdown","828aacac":"markdown","c855d543":"markdown","2af56feb":"markdown","e6ea9de6":"markdown","931a8a66":"markdown","bde5e613":"markdown","5fe94665":"markdown","0e41daf1":"markdown","0edddb79":"markdown","3a040fa7":"markdown","957ce7b4":"markdown","02cd5ae3":"markdown","fc48264f":"markdown","1df2e9f1":"markdown","2f955669":"markdown","571664f5":"markdown","298585b8":"markdown","e82a9827":"markdown","8bc7019b":"markdown","688ab577":"markdown","84df724a":"markdown"},"source":{"c15b9a2c":"def main(query):\n  all_tickets = []\n  issues, total_jql_results = get_jql_issues(query)\n  issue_count = total_jql_results\n  issues_remaining = issue_count\n  print(f'\\n ---- start ---- there are {issue_count} tickets in this query')\n\n  with open(DATA_FILE, 'w', newline='') as data:\n      writer = csv.DictWriter(data, FIELDNAMES)\n      writer.writeheader()\n\n  for issue in issues:\n    ticketmetrics = {}\n    subtask_counts = {\n      'ios': 0, \n      'tvos': 0,\n      'android': 0,\n      'androidtv': 0,\n      'firetv': 0,\n      'roku': 0,\n      'xbox': 0,\n      'tizen': 0,\n      'design': 0,\n      'config': 0, \n      'store': 0\n    }\n    ticket_data, app_count, counted_subtasks = get_issue_details(issue)\n    subtask_counts.update(counted_subtasks)\n\n    createdDate = ticket_data.createdDate\n\n    ticketmetrics['key'] = ticket_data.key\n    ticketmetrics['created_date'] = createdDate\n    ticketmetrics['num_of_apps'] = app_count\n    try:\n      ticketmetrics['ios'] = subtask_counts['ios']\n      ticketmetrics['tvos'] = subtask_counts['tvos']\n      ticketmetrics['android'] = subtask_counts['android']\n      ticketmetrics['androidtv'] = subtask_counts['androidtv']\n      ticketmetrics['firetv'] = subtask_counts['firetv']\n      ticketmetrics['roku'] = subtask_counts['roku']\n      ticketmetrics['xbox'] = subtask_counts['xbox']\n      ticketmetrics['tizen'] = subtask_counts['tizen']\n      ticketmetrics['design_changes'] = subtask_counts['design']\n      ticketmetrics['config_changes'] = subtask_counts['config']\n      ticketmetrics['store_changes'] = subtask_counts['store']\n    except Exception as e:\n      print(f'ERROR : {e}')\n\n    startDate, completedDate = get_issue_changelog(issue)\n    ticketmetrics['started_date'] = startDate\n    ticketmetrics['completed_date'] = completedDate\n\n    created_datetime = convert_jira_date(createdDate)\n    completed_datetime = convert_jira_date(completedDate)\n    started_datetime = convert_jira_date(startDate)\n\n    total_duration = completed_datetime - created_datetime\n    active_duration = completed_datetime - started_datetime\n\n    ticketmetrics['total_duration'] = total_duration.days\n    ticketmetrics['active_duration'] = active_duration.days\n    \n    print('completed dictionary for', issue, ticketmetrics)\n    all_tickets.append(ticketmetrics)\n    append_to_csv(ticketmetrics)\n    issues_remaining -= 1\n    print(f'\\n{issues_remaining} issues remaining\\n')","b520dede":"class Parent():\n    def __init__(self, response):\n        self.key = response['key']\n        self.priority = response['fields']['priority']['name']\n        self.status = response['fields']['status']['name']\n        self.issueType = response['fields']['issuetype']['name']\n        self.projectKey = response['fields']['project']['key']\n        self.createdDate = response['fields']['created']\n\nclass Changelog():\n    def __init__(self, response): \n        self.self = response['self']\n        self.maxResults = response['maxResults']\n        self.startAt = response['startAt']\n        self.total = response['total']\n        self.isLast = response['isLast']\n        self.values = response['values'] ","e5e3b0f5":"def get_jql_issues(query):\n    all_issues = []\n    max_results = 100\n    encoded_expression = parse.quote(query, safe='=,-')\n    startAt = 0\n    url = f'{VIMEO_DOMAIN}\/rest\/api\/3\/search\/?jql={encoded_expression}&maxResults={max_results}&startAt={startAt}'\n    response = requests.get(url, auth=JIRA_AUTH).json()\n    responseStatus = requests.get(url, auth=JIRA_AUTH)\n    total_jql_results = response['total'] \n    print(responseStatus)\n    print('total JQL results:', total_jql_results)\n\n    if total_jql_results > max_results: \n      total_jql_results_over_max_results = total_jql_results \/ max_results\n      jql_batches_needed = math.ceil(total_jql_results_over_max_results)\n      jql_batch_counter = 0\n      print('batches needed:', jql_batches_needed)\n\n      while jql_batch_counter <= (jql_batches_needed - 1):\n        print('---- starting JQL batch while loop ----')\n        startAt = jql_batch_counter * 100\n        url = f'{VIMEO_DOMAIN}\/rest\/api\/3\/search\/?jql={encoded_expression}&maxResults={max_results}&startAt={startAt}'\n        print('startAt:', startAt)\n        print('request url:', url)\n        response = requests.get(url, auth=JIRA_AUTH).json()\n\n        for issue in response['issues']:\n          all_issues.append(issue['key'])\n        print('length of request:', len(response['issues']))\n        print('length of all_issues:', len(all_issues))\n        jql_batch_counter += 1\n    \n    else: \n      print('JQL batch loop skipped.')\n      for issue in response['issues']:\n          all_issues.append(issue['key'])\n\n    print('final length of all_issues:', len(all_issues))\n    return all_issues, total_jql_results","e068a153":"def get_issue_details(key):\n  print(f'getting details for {key}')\n  url = f'{VIMEO_DOMAIN}\/rest\/api\/3\/issue\/{key}'\n  responseStatus = requests.get(url, auth=JIRA_AUTH)\n  response = requests.get(url, auth=JIRA_AUTH).json()\n  app_count = 0\n  subtask_counts = {}\n\n  ticket_data = Parent(response)\n  print(responseStatus)\n\n  for subtask in response['fields']['subtasks']:\n    summary = subtask['fields']['summary'].lower()\n    ticket_type = subtask['fields']['issuetype']['name']\n    if ticket_type == 'Branded App Launch Subtask':\n      app_count += 1  \n      subtask_type = get_subtask_type(summary)\n      if subtask_type in subtask_counts.keys():\n        print(f'{subtask_type} is in subtask_counts dictionary, increasing count by 1') \n        subtask_counts[subtask_type] += 1\n      else:\n        subtask_counts[subtask_type] = 1\n      # subtask_type.update(get_subtask_type(summary))\n    elif ticket_type == 'Branded App Request Subtask':\n      subtask_type = get_subtask_type(summary)\n      if subtask_type in subtask_counts.keys():\n        subtask_counts[subtask_type] += 1\n      else:\n        print(f'{subtask_type} not in subtask_counts dictionary, adding now')\n        subtask_counts[subtask_type] = 1\n    else:\n        print(f'ERROR : Unable to determine subtask type for {summary}')\n\n  print(f'app platform count: {app_count}')\n  print(f'subtask_counts: {subtask_counts}')\n\n  return ticket_data, app_count, subtask_counts","8aa9e1dd":"def get_issue_changelog(key):\n  url = f'{VIMEO_DOMAIN}\/rest\/api\/3\/issue\/{key}\/changelog'\n  responseStatus = requests.get(url, auth=JIRA_AUTH)\n  response = requests.get(url, auth=JIRA_AUTH).json()\n  \n  log = Changelog(response)\n  changelog_items = log.values\n  log_value_count_initial = 0\n  for value in log.values:\n    log_value_count_initial += 1\n\n  total_over_maxResults = (log.total \/ log.maxResults)\n  num_of_batches = math.ceil(total_over_maxResults)\n  print(f'requried batch count: {num_of_batches}')\n  print(f'changelog results: {log.total}')\n  \n\n  while log.isLast == False:\n      print(f'starting next batch loop - current log.self: {log.self}')\n      next_start = log.startAt + log.maxResults\n      url = url + f'?startAt={next_start}'\n      print(f'new url is {url}')\n\n      response = requests.get(url, auth=JIRA_AUTH).json()\n\n      log = Changelog(response)\n      log_value_count_in_while_loop = 0\n      for value in log.values:\n          log_value_count_in_while_loop += 1\n      print(f'log_value_count_in_while_loop: {log_value_count_in_while_loop}')\n\n      changelog_items += log.values\n\n\n\n  valueCounter = 0\n  for value in changelog_items:\n    valueCounter += 1\n    for item in value['items']:\n      if item['field'] == 'status':\n        if item['toString'] == 'Active': \n          startDate = value['created']\n        elif item['toString'] == 'Mockup Needed':\n          startDate = value['created']\n        elif item['toString'] == 'Build':\n          startDate = value['created']\n        elif item['toString'] == 'Design':\n          startDate = value['created']\n        elif item['toString'] == 'Launched':\n          completedDate = value['created']\n        \n\n  print(f'counted {valueCounter} values on {log.self}')       \n\n  return startDate, completedDate ","bd0f14a7":"def get_subtask_type(summary):\n  subtask_type = None\n\n  if 'ios' in summary:\n    subtask_type = 'ios'\n  elif 'tvos' in summary:\n    subtask_type = 'tvos'\n  elif 'android' in summary:\n    if 'tv' in summary:\n      subtask_type = 'androidtv'\n    else:\n      subtask_type = 'android'\n  elif 'fire' in summary:\n    subtask_type = 'firetv'\n  elif 'roku' in summary:\n    subtask_type = 'roku'\n  elif 'xbox' in summary:\n    subtask_type = 'xbox'\n  elif 'tizen' in summary:\n    subtask_type = 'tizen'\n  elif 'design' in summary:\n     subtask_type = 'design'\n  elif 'configuration' in summary:\n    subtask_type = 'config'\n  elif 'store' in summary:\n    subtask_type = 'store'\n  elif 'domain' in summary:\n    subtask_type = 'config'\n  elif 'metadata' in summary:\n    subtask_type = 'store'\n  elif 'subscription' in summary:\n    subtask_type = 'store'\n  else:\n    print(f'ERROR : Unable to determine subtask type for {summary}')\n  \n  return subtask_type","1a30ea09":"def convert_jira_date(jira_date):\n    converted_date = datetime.strptime(jira_date, JIRA_DATE_FORMAT)\n    return converted_date","caafb9a2":"def append_to_csv(values):\n  with open(DATA_FILE, 'a', newline='') as data:\n      writer = csv.DictWriter(data, FIELDNAMES)\n      writer.writerow(values)\n  return ","31e971fd":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport datetime\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","789d12f1":"all_tickets = pd.read_csv('..\/input\/jiradatav2\/jira_data.csv')\npd.set_option('display.max_columns', 30)\nall_tickets","a88bfcc6":"all_tickets['created_datetime'] = pd.to_datetime(all_tickets['created_date'], utc=True)\nall_tickets['started_datetime'] = pd.to_datetime(all_tickets['started_date'], utc=True)\nall_tickets['completed_datetime'] = pd.to_datetime(all_tickets['completed_date'], utc=True)\n\nall_tickets['created_year'] = all_tickets['created_datetime'].dt.year\nall_tickets['created_month'] = all_tickets['created_datetime'].dt.month\n\nall_tickets['started_year'] = all_tickets['started_datetime'].dt.year\nall_tickets['started_month'] = all_tickets['started_datetime'].dt.month\n\nall_tickets['completed_year'] = all_tickets['completed_datetime'].dt.year\nall_tickets['completed_month'] = all_tickets['completed_datetime'].dt.month","2e5efcee":"all_tickets.dtypes","c6e3950a":"all_tickets.loc[(all_tickets['num_of_apps'] == 0)]\n","adb91510":"all_tickets['num_of_apps'].plot(kind='hist', bins=8);","9ac20519":"to_drop = all_tickets.index[(all_tickets['num_of_apps'] == 0)]\nt = all_tickets.drop(to_drop)\nt.shape","9fdfa804":"t.head(5)","7f7a6567":"t['num_of_apps'].plot(kind='hist', bins=8, title='Frequency of App Count per Project', xlabel='Number of Apps');","3c019ffe":"t[['num_of_apps', 'completed_year']].groupby('completed_year').sum('num_of_apps').plot(kind='bar', xlabel='Year', ylabel='Number of Apps Launched', title='Apps Launched by Year')\nt[['num_of_apps', 'completed_year']].groupby('completed_year').sum('num_of_apps')","5b07ee06":"t[['completed_month', 'key']].groupby('completed_month').count().plot(kind='bar', xlabel='Completed Month', ylabel='Number of Projects Completed', title='Projects Completed by Month');","fb88d852":"nov_dec_non_2021_launches = t[(t.completed_year != 2021) & (t.completed_month >= 11)]\nnov_dec_non_2019_2020_launches_by_month = nov_dec_non_2021_launches[['num_of_apps', 'completed_month', 'completed_year']].groupby(['completed_year','completed_month']).sum('num_of_apps')\nnov_dec_non_2019_2020_launches_by_month.plot(kind='barh', title='Apps Launched In Nov\/Dec', xlabel='Month and Year', ylabel='Apps Launched');","9d9409a0":"nov_launches_2020 = t['num_of_apps'][(t.completed_year == 2020) & (t.completed_month == 11)].sum()\nnov_launches_2019 = t['num_of_apps'][(t.completed_year == 2019) & (t.completed_month == 11)].sum()\n\ndec_launches_2020 = t['num_of_apps'][(t.completed_year == 2020) & (t.completed_month == 12)].sum()\ndec_launches_2019 = t['num_of_apps'][(t.completed_year == 2019) & (t.completed_month == 12)].sum()\n\n\navg_nov_launches_pre_2021 = (nov_launches_2020 + nov_launches_2019) \/ 2\navg_dec_launches_pre_2021 = (dec_launches_2020 + dec_launches_2019) \/ 2\n\nprint(avg_nov_launches_pre_2021, avg_dec_launches_pre_2021)\n\nnov_launches_2021 = t['num_of_apps'][(t.completed_year == 2021) & (t.completed_month == 11)].sum()\n","d357fe3b":"apps_by_ad = t[['num_of_apps', 'total_duration']].groupby('num_of_apps')\napp_nums = t['num_of_apps'].unique()\n\napp_num_groups = t[['total_duration', 'num_of_apps']]\napp_num_groups.groupby('num_of_apps').mean().plot(kind='barh', title='Total Duration by Number of Apps', ylabel='Number of Apps in Project', xlabel='Project Duration');","24d039bc":"t['total_changes'] = t['design_changes'] + t['config_changes'] + t['store_changes']\n\nchanges_vs_total_duration = t[['total_changes', 'total_duration']]\nchanges_vs_total_duration.plot(kind='scatter', x='total_duration', y='total_changes', figsize=(13,8), xlabel='Project Length - Days', ylabel='Number of Changes', title='Client Requested Changes vs Project Length');","ae4e1415":"t['active_duration'].plot(kind='hist', xlabel='Duration',title='Frequency of Durations - Active', bins=10);","97ec3dbb":"t['total_duration'].plot(kind='hist', xlabel='Duration', title='Frequency of Durations - Total', bins=10);","f03e493a":"t_completed_2019 = t[t.completed_year == 2019]\nt_completed_2020 = t[t.completed_year == 2020]\nt_completed_2021 = t[t.completed_year == 2021]\n              \nt_2019_by_completed_month = t_completed_2019[['total_duration', 'completed_month']].groupby('completed_month').mean().round(2)\nt_2020_by_completed_month = t_completed_2020[['total_duration', 'completed_month']].groupby('completed_month').mean().round(2)\nt_2021_by_completed_month = t_completed_2021[['total_duration', 'completed_month']].groupby('completed_month').mean().round(2)\n\n\nmerged_years = t_2019_by_completed_month.merge(t_2020_by_completed_month, on='completed_month', how='outer', suffixes=('_2019', '_2020')).merge(t_2021_by_completed_month, on='completed_month', how='outer', suffixes=('_2020', '_2021'))\n\nmerged_years.rename(columns={'total_duration': '2021', 'total_duration_2020': '2020', 'total_duration_2019': '2019'}, inplace=True)\nmerged_years.sort_values('completed_month').plot(kind='bar', xlabel='Completed Month', ylabel='Average Project Duration', title= 'Average Duration by Month Over Time', figsize=(13,8), color={'2019': 'steelblue', '2020': 'dodgerblue', '2021': 'navy'});\n","45f00b69":"t['duration_per_app'] = (t.total_duration \/ t.num_of_apps).round(3)\nef_filtered = t[(t.completed_datetime > '2019-07-01')]\nef = ef_filtered[['duration_per_app','completed_month', 'completed_year']].groupby(['completed_year', 'completed_month']).mean().round(3)\n\n\nef.plot(kind='line', xlabel='Date Completed', ylabel='Project Duration per App', title='Duration Per App Over Time');","19c0fedd":"# Conclusions\n\nThe process to complete all of these projects involves many people spread out around the globe and has only gotten more complex over time as features are added and new options become available for clients to choose from. We have seen success in some metrics by completing an increasing number of projects year over year but in others we have work to do to make sure that this can be sustainable for everyone on the team. Even though some of the findings were not as rosy as I hoped they would be, I now have a new metric that we can use to measure future changes to our process against which I think is very beneficial. \n\nA major future goal related to this work is to be able to predict project time requirements with a reasonably high confidence and update those estimates as projects progress and variables change in a programmatic way. One constant ask of clients, especially these types of clients that are relying on our output to launch components of their businesses that they may need to be complete before they can earn revenue, is \"how long will this take?\" and the answers are often hard to provide. \n\nBy collecting and organizing the amount of data we have available to us through our project records we can begin to make a model that can provide those answers without requiring significant staff hours or needing to bring out the snake oil routines. ","122d678b":"### Finding a bad record and dropping it\nThat 0 app launch was dropped and a new data frame was made for the rest of this analysis.","1968e8c9":"### Changes compared with project length\nThis chart surprised me a bit since while it does clearly show that clients that submit no changes, which are modifications to components that differ from what they originally indicated they wanted, launch faster than those without, there was less of a spread than I expected. A substantial amount of clients manage to be under 100 days to complete their project even when they have sevearl changes. \n\nNot all clients are equal in their time management abilities.","828aacac":"### Common project groupings\nA clear majority of our clients launch 2 or 6 apps but this initial histogram showed thta there was a 0 app launch which should be filtered out. ","c855d543":"### Duration per app\nA new computed field which looks at how much time is spent in total for projects per the amount of apps they include shows that this is indeed moving in a clear direction and not a good one.","2af56feb":"### Converting data\nFixing date columns from Jira formats to datetime values","e6ea9de6":"### Writing to CSV\nNot much to say other than it does what it says on the label.","931a8a66":"## Then some things looked weird\nSo everything so far seemed to show that things were going really well and we just need to keep it up. However, when looking at how our total project durations by month the project was completed in a worrying trend appeared. We have been consistently taking longer on average for projects in every month. ","bde5e613":"## Gathering the Data\n\n### Main()\nThe main function was responsible for calling all other functions in order, as we learned in class.\n1. Submit query string to the Atlassian (Jira) API and determine how long the list will be\n2. Save the full list of issues to a string\n3. Iterate through the list of issue keys and extract data from each\n4. Convert formats and do some basic math to complete the target amount of data to gather per ticket and write it all to a dictionary\n5. Write that dictionary to a new row in the CSV file\n6. Profit?","5fe94665":"### Duration by project size\nUnsurprisingly the more apps you include in a project, the longer that project will take. Four and five app pairings are interestingly longer than the six app size of project. This is likely due to the efficienies of lauching multiple apps on one platform (Apple with iOS and tvOS and Google with Android and Android TV) which happens often with a total of six apps. ","0e41daf1":"### Converting dates\nJira's native date format needed to be converted before it could be imported into Kaggle, the convert_jira_date() function was called after all information had been assembled and before writing to the CSV. ","0edddb79":"### Up and to the right\nThe pace of launched apps has been steadily increasing, not shown in this data is the total amount of launches completed in 2019 which was 635. 2020 saw a 52% in this amount when the year closed out at 968 launches. ","3a040fa7":"### Project duration categories\n\"Active Duration\" is defined as the amount of time the team was able to actually work on a project, which cuts out the time that the project spent in our system but before we had been provided with all we needed to get started. ","957ce7b4":"### Setting up classes\nClasses were used to format \"parent\" ticket details and their change log values.","02cd5ae3":"### New data frame\nNewly formatted data frame with computed fields","fc48264f":"### Average apps launched during this period in the past\nWe have been averging 63 launches in November and 91 in December the past two years so we can expect to be over 1,300 by the end of the year if that trend continues.  ","1df2e9f1":"### Feelin' good\n2021 is already 19% higher than 2020 at 1,155 apps launched with a month and a half to go until the end of the year.","2f955669":"# Working With The Results\nWith the results now assembled, we can look for insights and make some charts. ","571664f5":"# Extracting and Analyzing Jira Project Data\n\nThis project data comes from a team that is responsible for managing projects for enterprirse clients that typically have a several month timeline on average. These projects involve configuring and publishing streaming video applications for clients to some of the major app platforms such as the Apple App Store, Google Play Store, Amazon Appstore, Roku Channel Store, Microsoft's Xbox platform, and the Samsung Tizen TV store.\n\nJira, an Atlassian product, is used to track this process as it integrates well with the engineering and product teams across the company. However, Jira's ability to showcase more complicated historical leaves much to be desired. \n\nA goal of this project was to create a proof of concept that can be used to extra data and then make it contextual to the operations team since their needs are often different from the charting needs of development teams which Jira has more features for. \n\nGitHub Repository - https:\/\/git.generalassemb.ly\/bfeltault\/final-project-jira-extractor\n","298585b8":"### Getting the subtask type\nFor each parent ticket there were subtickets or \"subtasks\" that represented the real work that needed to be completed for the overall project. Each of these subtasks followed a specific naming convention which could be checked to determine more detail beyond the ticket type alone. ","e82a9827":"### Getting changelog details\nThe changelog for a specific issue contained the information about when each ticket transitioned through different statuses in our workflow. The get_issue_changelog() function was used to determine the amount of time spent on the ticket overall and when certain milestones were reached. ","8bc7019b":"### Getting the parent ticket details\nThe main query resulted in a list of parent ticket keys that then need to have data extracted from them. The get_issue_details() function looks at a single parent ticket at at time and extracts and formats the specific data that I wanted to include in my analysis and stores it into a dictionary for writing to the CSV when complete. ","688ab577":"### Getting the issues\nThe get_jql_issues() function sent an initial query for a list of results, with a maximum of 100 results per page. Included in the response was a value that said how long the entire query was so that the query can be iterated on to gather all results. \n\nThe query used for this project included 717 issues which took 8 batches of results to fully assemble. ","84df724a":"## Running the script\nAfter many false starts where just about every part of the script failed in many frustrating and comical ways it finally was able to complete a full run through the intended query and save all the results into the CSV. \n\n\n\n### Script runtime : 32 mins\n\n### Total issues in query : 717\n\n### Number of apps analyzed : 2,551\n\n### Number of changes analyzed : 1,368"}}