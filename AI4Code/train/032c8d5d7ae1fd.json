{"cell_type":{"469f12f9":"code","d96b76c6":"code","6ae53724":"code","fb881a70":"code","bebfc9bf":"code","39b1c4c9":"code","1b2d2b92":"code","551280cb":"code","eedf4274":"code","7fb00d46":"code","db4b9c7d":"code","d95fc6fa":"code","6619fe9a":"code","cc9c2c15":"code","2848d755":"markdown","724f3fe8":"markdown","c691f63a":"markdown","0c85df47":"markdown","700835a6":"markdown","217e7409":"markdown","3e93321c":"markdown","8c1ecec8":"markdown","21aa497c":"markdown","5848c65f":"markdown","d47f6d4d":"markdown","2a635880":"markdown","2b48519b":"markdown","7c6f1b2a":"markdown","3474668d":"markdown"},"source":{"469f12f9":"import numpy as np \nimport pandas as pd \nimport seaborn as sns","d96b76c6":"\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) \n","6ae53724":"\ntrain=pd.read_csv(\"..\/input\/train.csv\")\ntest=pd.read_csv(\"..\/input\/test.csv\")\n","fb881a70":"#correlations\ncorrelations = train.corr()\ncorrelations = correlations[\"SalePrice\"].sort_values(ascending=False)\nfeatures = correlations.index[1:6]\n\n#find missing data\ntrain_null = pd.isnull(train).sum()\ntest_null = pd.isnull(test).sum()\n\n#merge missing data\nnull = pd.concat([train_null, test_null], axis=1, keys=[\"Train\", \"Test\"])\n\n#null data multiplicity test\nnull_many = null[null.sum(axis=1) > 200]  #a lot of missing values\nnull_few = null[(null.sum(axis=1) > 0) & (null.sum(axis=1) < 200)]  #not as much missing values\nprint(null_many)\nprint(null_few)\n\n#correction of meaning mess between na and none\nnull_has_meaning = [\"Alley\", \"BsmtQual\", \"BsmtCond\", \"BsmtExposure\", \"BsmtFinType1\", \"BsmtFinType2\", \"FireplaceQu\", \"GarageType\", \"GarageFinish\", \"GarageQual\", \"GarageCond\", \"PoolQC\", \"Fence\", \"MiscFeature\"]\n\nfor i in null_has_meaning:\n    train[i].fillna(\"None\", inplace=True)\n    test[i].fillna(\"None\", inplace=True)\n    \n#complete missing data\nfrom sklearn.preprocessing import Imputer\nimputer = Imputer(strategy=\"median\")\ntrain_null = pd.isnull(train).sum()\ntest_null = pd.isnull(test).sum()\n\n#again correction of meaning mess between na and none\nnull = pd.concat([train_null, test_null], axis=1, keys=[\"Train\", \"Test\"])\nnull_many = null[null.sum(axis=1) > 200]  #a lot of missing values\nnull_few = null[(null.sum(axis=1) > 0) & (null.sum(axis=1) < 200)]  #few missing values\nnull_many\n\n#data extraction\ntrain.drop(\"LotFrontage\", axis=1, inplace=True)\ntest.drop(\"LotFrontage\", axis=1, inplace=True)\nnull_few\n\n#filling missing places with median\ntrain[\"GarageYrBlt\"].fillna(train[\"GarageYrBlt\"].median(), inplace=True)\ntest[\"GarageYrBlt\"].fillna(test[\"GarageYrBlt\"].median(), inplace=True)\ntrain[\"MasVnrArea\"].fillna(train[\"MasVnrArea\"].median(), inplace=True)\ntest[\"MasVnrArea\"].fillna(test[\"MasVnrArea\"].median(), inplace=True)\ntrain[\"MasVnrType\"].fillna(\"None\", inplace=True)\ntest[\"MasVnrType\"].fillna(\"None\", inplace=True)\n\n#split data types integer or object for train\n\ntypes_train = train.dtypes \nnum_train = types_train[(types_train == int) | (types_train == float)] \ncat_train = types_train[types_train == object]\n\n#we do the same for the test \ntypes_test = test.dtypes\nnum_test = types_test[(types_test == int) | (types_test == float)]\ncat_test = types_test[types_test == object]\n\n#we should convert num_train and num_test to a list to make it easier to work with\n\nnumerical_values_train = list(num_train.index)\nnumerical_values_test = list(num_test.index)\n\nfill_num = []\n\nfor i in numerical_values_train:\n    if i in list(null_few.index):\n        fill_num.append(i)\n\nfor i in fill_num:\n    train[i].fillna(train[i].median(), inplace=True)\n    test[i].fillna(test[i].median(), inplace=True)\n    \ncategorical_values_train = list(cat_train.index)\ncategorical_values_test = list(cat_test.index)\n\n\nfill_cat = []\n\nfor i in categorical_values_train:\n    if i in list(null_few.index):\n        fill_cat.append(i)\n        \n\n\ndef most_common_term(lst):\n    lst = list(lst)\n    return max(set(lst), key=lst.count)\n\n#most_common_term finds the most common term in a series\n\nmost_common = [\"Electrical\", \"Exterior1st\", \"Exterior2nd\", \"Functional\", \"KitchenQual\", \"MSZoning\", \"SaleType\", \"Utilities\", \"MasVnrType\"]\n\ncounter = 0\nfor i in fill_cat:\n    most_common[counter] = most_common_term(train[i])\n    counter += 1\nmost_common_dictionary = {fill_cat[0]: [most_common[0]], fill_cat[1]: [most_common[1]], fill_cat[2]: [most_common[2]], fill_cat[3]: [most_common[3]],\n                          fill_cat[4]: [most_common[4]], fill_cat[5]: [most_common[5]], fill_cat[6]: [most_common[6]], fill_cat[7]: [most_common[7]],\n                          fill_cat[8]: [most_common[8]]}\n\ncounter = 0\nfor i in fill_cat:  \n    train[i].fillna(most_common[counter], inplace=True)\n    test[i].fillna(most_common[counter], inplace=True)\n    counter += 1\n\ntrain_null = pd.isnull(train).sum()\ntest_null = pd.isnull(test).sum()\n\nnull = pd.concat([train_null, test_null], axis=1, keys=[\"Training\", \"Testing\"])\nnull[null.sum(axis=1) > 0]\nsns.distplot(train[\"SalePrice\"])\nsns.distplot(np.log(train[\"SalePrice\"]))\ntrain[\"TransformedPrice\"] = np.log(train[\"SalePrice\"])\ncategorical_values_train = list(cat_train.index)\ncategorical_values_test = list(cat_test.index)\n\n\nfor i in categorical_values_train:\n    feature_set = set(train[i])\n    for j in feature_set:\n        feature_list = list(feature_set)\n        train.loc[train[i] == j, i] = feature_list.index(j)\n\nfor i in categorical_values_test:\n    feature_set2 = set(test[i])\n    for j in feature_set2:\n        feature_list2 = list(feature_set2)\n        test.loc[test[i] == j, i] = feature_list2.index(j)\n","bebfc9bf":"        \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import Ridge\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.metrics import r2_score, mean_squared_error\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score \n\n\n\nX_train = train.drop([\"Id\", \"SalePrice\", \"TransformedPrice\"], axis=1).values\ny_train = train[\"TransformedPrice\"].values\nX_test = test.drop(\"Id\", axis=1).values\n\nfrom sklearn.model_selection import train_test_split #to create validation data set\n\nX_training, X_valid, y_training, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0) #X_valid and y_valid are the validation sets","39b1c4c9":"linreg = LinearRegression()\nparameters_lin = {\"fit_intercept\" : [True, False], \"normalize\" : [True, False], \"copy_X\" : [True, False]}\ngrid_linreg = GridSearchCV(linreg, parameters_lin, verbose=1 , scoring = \"r2\")\ngrid_linreg.fit(X_training, y_training)\n\nprint(\"Best LinReg Model: \" + str(grid_linreg.best_estimator_))\nprint(\"Best Score: \" + str(grid_linreg.best_score_))\n\nlinreg = grid_linreg.best_estimator_\nlinreg.fit(X_training, y_training)\nlin_pred = linreg.predict(X_valid)\nr2_lin = r2_score(y_valid, lin_pred)\nrmse_lin = np.sqrt(mean_squared_error(y_valid, lin_pred))\nprint(\"R^2 Score: \" + str(r2_lin))\nprint(\"RMSE Score: \" + str(rmse_lin))\n\nscores_lin = cross_val_score(linreg, X_training, y_training, cv=10, scoring=\"r2\")\nprint(\"Cross Validation Score: \" + str(np.mean(scores_lin)))","1b2d2b92":"lasso = Lasso()\nparameters_lasso = {\"fit_intercept\" : [True, False], \"normalize\" : [True, False], \"precompute\" : [True, False], \"copy_X\" : [True, False]}\ngrid_lasso = GridSearchCV(lasso, parameters_lasso, verbose=1, scoring=\"r2\")\ngrid_lasso.fit(X_training, y_training)\n\nprint(\"Best Lasso Model: \" + str(grid_lasso.best_estimator_))\nprint(\"Best Score: \" + str(grid_lasso.best_score_))\n\nlasso = grid_lasso.best_estimator_\nlasso.fit(X_training, y_training)\nlasso_pred = lasso.predict(X_valid)\nr2_lasso = r2_score(y_valid, lasso_pred)\nrmse_lasso = np.sqrt(mean_squared_error(y_valid, lasso_pred))\nprint(\"R^2 Score: \" + str(r2_lasso))\nprint(\"RMSE Score: \" + str(rmse_lasso))\n\nscores_lasso = cross_val_score(lasso, X_training, y_training, cv=10, scoring=\"r2\")\nprint(\"Cross Validation Score: \" + str(np.mean(scores_lasso)))","551280cb":"ridge = Ridge()\nparameters_ridge = {\"fit_intercept\" : [True, False], \"normalize\" : [True, False], \"copy_X\" : [True, False], \"solver\" : [\"auto\"]}\ngrid_ridge = GridSearchCV(ridge, parameters_ridge, verbose=1, scoring=\"r2\")\ngrid_ridge.fit(X_training, y_training)\n\nprint(\"Best Ridge Model: \" + str(grid_ridge.best_estimator_))\nprint(\"Best Score: \" + str(grid_ridge.best_score_))\n\nridge = grid_ridge.best_estimator_\nridge.fit(X_training, y_training)\nridge_pred = ridge.predict(X_valid)\nr2_ridge = r2_score(y_valid, ridge_pred)\nrmse_ridge = np.sqrt(mean_squared_error(y_valid, ridge_pred))\nprint(\"R^2 Score: \" + str(r2_ridge))\nprint(\"RMSE Score: \" + str(rmse_ridge))\n\nscores_ridge = cross_val_score(ridge, X_training, y_training, cv=10, scoring=\"r2\")\nprint(\"Cross Validation Score: \" + str(np.mean(scores_ridge)))","eedf4274":"dtr = DecisionTreeRegressor()\nparameters_dtr = {\"criterion\" : [\"mse\", \"friedman_mse\", \"mae\"], \"splitter\" : [\"best\", \"random\"], \"min_samples_split\" : [2, 3, 5, 10], \n                  \"max_features\" : [\"auto\", \"log2\"]}\ngrid_dtr = GridSearchCV(dtr, parameters_dtr, verbose=1, scoring=\"r2\")\ngrid_dtr.fit(X_training, y_training)\n\nprint(\"Best DecisionTreeRegressor Model: \" + str(grid_dtr.best_estimator_))\nprint(\"Best Score: \" + str(grid_dtr.best_score_))\n\ndtr = grid_dtr.best_estimator_\ndtr.fit(X_training, y_training)\ndtr_pred = dtr.predict(X_valid)\nr2_dtr = r2_score(y_valid, dtr_pred)\nrmse_dtr = np.sqrt(mean_squared_error(y_valid, dtr_pred))\nprint(\"R^2 Score: \" + str(r2_dtr))\nprint(\"RMSE Score: \" + str(rmse_dtr))\n\nscores_dtr = cross_val_score(dtr, X_training, y_training, cv=10, scoring=\"r2\")\nprint(\"Cross Validation Score: \" + str(np.mean(scores_dtr)))","7fb00d46":"rf = RandomForestRegressor()\nparemeters_rf = {\"n_estimators\" : [5, 10, 15, 20], \"criterion\" : [\"mse\" , \"mae\"], \"min_samples_split\" : [2, 3, 5, 10], \n                 \"max_features\" : [\"auto\", \"log2\"]}\ngrid_rf = GridSearchCV(rf, paremeters_rf, verbose=1, scoring=\"r2\")\ngrid_rf.fit(X_training, y_training)\n\nprint(\"Best RandomForestRegressor Model: \" + str(grid_rf.best_estimator_))\nprint(\"Best Score: \" + str(grid_rf.best_score_))\n\nrf = grid_rf.best_estimator_\nrf.fit(X_training, y_training)\nrf_pred = rf.predict(X_valid)\nr2_rf = r2_score(y_valid, rf_pred)\nrmse_rf = np.sqrt(mean_squared_error(y_valid, rf_pred))\nprint(\"R^2 Score: \" + str(r2_rf))\nprint(\"RMSE Score: \" + str(rmse_rf))\n\nscores_rf = cross_val_score(rf, X_training, y_training, cv=10, scoring=\"r2\")\nprint(\"Cross Validation Score: \" + str(np.mean(scores_rf)))","db4b9c7d":"from xgboost import XGBRegressor\nXGB = XGBRegressor(max_depth = 5, learning_rate = 0.05, n_estimators = 1500, reg_alpha = 0.001,\n                reg_lambda = 0.000001, n_jobs = -1, min_child_weight = 3)\n\nXGB.fit(X_train,y_train)\n","d95fc6fa":"model_performances = pd.DataFrame({\n    \"Model\" : [\"Linear Regression\", \"Ridge\", \"Lasso\", \"Decision Tree Regressor\", \"Random Forest Regressor\"],\n    \"Best Score\" : [grid_linreg.best_score_,  grid_ridge.best_score_, grid_lasso.best_score_, grid_dtr.best_score_, grid_rf.best_score_],\n    \"R Squared\" : [str(r2_lin)[0:5], str(r2_ridge)[0:5], str(r2_lasso)[0:5], str(r2_dtr)[0:5], str(r2_rf)[0:5]],\n    \"RMSE\" : [str(rmse_lin)[0:8], str(rmse_ridge)[0:8], str(rmse_lasso)[0:8], str(rmse_dtr)[0:8], str(rmse_rf)[0:8]]\n})\nmodel_performances.round(4)\n","6619fe9a":"print(\"Sorted by Best Score:\")\nmodel_performances.sort_values(by=\"Best Score\", ascending=False)\n\nprint(\"Sorted by R Squared:\")\nmodel_performances.sort_values(by=\"R Squared\", ascending=False)\n\nprint(\"Sorted by RMSE:\")\nmodel_performances.sort_values(by=\"RMSE\", ascending=True)\n\nrf.fit(X_training, y_training)\n","cc9c2c15":"submission_predictions = np.exp(rf.predict(X_test))\n\nsubmission = pd.DataFrame({\n        \"Id\": test[\"Id\"],\n        \"SalePrice\": submission_predictions\n    })\n\nsubmission.to_csv(\"prices.csv\", index=False)\n","2848d755":"model preliminary and split data","724f3fe8":"MODELL\u0130NG\n\n","c691f63a":"import library","0c85df47":"Data cleaning and prepare part","700835a6":"sort of modelling","217e7409":"Linear regression","3e93321c":"lasso","8c1ecec8":"performance analaysis","21aa497c":"random forest","5848c65f":"decision tree ","d47f6d4d":"ridge ","2a635880":"prediction of submission","2b48519b":"ignore warning","7c6f1b2a":"xgboost","3474668d":"import data\n"}}