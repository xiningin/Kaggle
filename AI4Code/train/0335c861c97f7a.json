{"cell_type":{"8fd8b32c":"code","a480d651":"code","028f8b40":"code","2fb64c2f":"code","0595ae4e":"code","a4a07deb":"code","df4622b2":"code","4d8c3112":"code","2e464a8a":"code","512e040f":"code","1a02c1da":"code","38eee24c":"code","140e93a5":"code","5188f2d5":"code","c4c9b386":"code","a18f16fe":"code","bec02eb3":"code","a8516d0c":"code","a55b9b3d":"code","6b277db4":"code","0ffd9e1a":"code","44f7d5c7":"code","b3d5727b":"code","0161c9e5":"code","af4b17ab":"code","ca548b7b":"code","3cc3eb46":"code","23f14c19":"code","00e63635":"code","faf4de1c":"markdown","66e356bc":"markdown","3d99dd47":"markdown","00a70f4a":"markdown","a516de75":"markdown","3b68e484":"markdown","d529b3c7":"markdown","663c1a02":"markdown"},"source":{"8fd8b32c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn import preprocessing\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor\nfrom sklearn.svm import SVR\nfrom sklearn.metrics import mean_squared_log_error\n\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.layers import Dense, Input, BatchNormalization, Activation, Dropout\nfrom tensorflow.keras import optimizers, losses \nfrom tensorflow.keras.callbacks import *\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.metrics import mean_squared_logarithmic_error\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/working\/\"))\n\n# Any results you write to the current directory are saved as output.","a480d651":"seed_value= 0\n\n# 1. Set `PYTHONHASHSEED` environment variable at a fixed value\nimport os\nos.environ['PYTHONHASHSEED']=str(seed_value)\n\n# 2. Set `python` built-in pseudo-random generator at a fixed value\nimport random\nrandom.seed(seed_value)\n\n# 3. Set `numpy` pseudo-random generator at a fixed value\nimport numpy as np\nnp.random.seed(seed_value)\n\n# 4. Set `tensorflow` pseudo-random generator at a fixed value\nimport tensorflow as tf\ntf.set_random_seed(seed_value)\n\n# 5. Configure a new global `tensorflow` session\nfrom keras import backend as K\nsession_conf = tf.ConfigProto(intra_op_parallelism_threads=1, inter_op_parallelism_threads=1)\nsess = tf.Session(graph=tf.get_default_graph(), config=session_conf)\nK.set_session(sess)","028f8b40":"df = pd.read_csv('..\/input\/train.csv')\ndf.head()\n","2fb64c2f":"\ndf.describe()","0595ae4e":"def preprocess(df):\n    df.fillna('0', inplace=True)\n    \n    # Categorical boolean mask\n    categorical_feature_mask = df.dtypes==object\n    # filter categorical columns using mask and turn it into a list\n    categorical_cols = df.columns[categorical_feature_mask].tolist()\n    \n    le = LabelEncoder()\n    for col in categorical_cols:\n        try:\n            df[col] = le.fit_transform(df[col])\n        except:\n            pass\n        \n    \n    min_max_scaler = preprocessing.MinMaxScaler()\n    np_scaled = min_max_scaler.fit_transform(df)\n    df = pd.DataFrame(np_scaled, columns=df.columns)\n    \n    return df\n\n\ndef root_mean_squerd_log_error(y_pred, y_true):\n    return np.sqrt(np.mean(np.power(np.log(y_pred+1) - np.log(y_true+1), 2)))","a4a07deb":"matplotlib.rcParams['figure.figsize'] = (12.0, 6.0)\n# df['SalePrice'].hist()\nsns.distplot(df['SalePrice'],bins = 15);","df4622b2":"# sns.distplot(np.log1p(df['SalePrice']), bins=15)","4d8c3112":"sns.heatmap(df.corr())","2e464a8a":"df['SalePrice'].plot.line()","512e040f":"random_state = 20","1a02c1da":"y = df['SalePrice']\nX = preprocess(df[df.columns[:-1]])\n\n\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2)\n\nprint('shape of X_train: {} and shape of y_train: {}'.format(X_train.shape, y_train.shape))\nprint('shape of X_val: {} and shape of y_val: {}'.format(X_val.shape, y_val.shape))","38eee24c":"X.head()","140e93a5":"def create_submission(model, name='model', fit=True):\n    if fit:\n        model.fit(X, y)\n    name = name + '_submission.csv'\n    \n    test_data = pd.read_csv('..\/input\/test.csv')\n    test_data['SalePrice'] = model.predict(preprocess(test_data))\n    \n    result = test_data[(['Id', 'SalePrice'])]\n    result.to_csv(name, index=False)\n","5188f2d5":"regressor = DecisionTreeRegressor(max_depth=20,max_leaf_nodes=800, random_state=random_state)\nregressor.fit(X_train, y_train)\n# regressor.score(X_val, y_val)\nroot_mean_squerd_log_error(regressor.predict(X_val), y_val)","c4c9b386":"create_submission(regressor, 'DT')","a18f16fe":"regressor = SVR(kernel='linear', gamma='scale',epsilon=1, C=100000)\nregressor.fit(X_train, y_train)\nroot_mean_squerd_log_error(regressor.predict(X_val), y_val)","bec02eb3":"create_submission(regressor, 'SVM_linear')","a8516d0c":"regressor = AdaBoostRegressor(random_state=random_state)\nregressor.fit(X_train, y_train)\nroot_mean_squerd_log_error(regressor.predict(X_val), y_val)","a55b9b3d":"create_submission(regressor, 'AdaBoost')","6b277db4":"regressor = RandomForestRegressor(n_estimators=100, random_state=random_state)\nregressor.fit(X_train, y_train)\nroot_mean_squerd_log_error(regressor.predict(X_val), y_val)","0ffd9e1a":"create_submission(regressor, 'RandomForest')","44f7d5c7":"\ndef build_model(input_shape, l1_rate=0.0, dropout_rate=0.5):\n    \n    activations = 'elu'\n    X_input = Input(shape=input_shape)\n    \n    X = Dense(300, name='dense1')(X_input)\n#     X = BatchNormalization()(X)\n    X = Activation(activations)(X)\n    \n    X = Dense(500, name='dense2') (X)\n#     X = BatchNormalization()(X)\n    X = Activation(activations)(X)\n    \n    X = Dense(500, name='dense3') (X)\n#     X = BatchNormalization()(X)\n    X = Activation(activations)(X)\n    \n#     X = Dense(600, name='dense4') (X)\n#     X = BatchNormalization()(X)\n#     X = Activation(activations)(X)\n    \n#     X = Dense(600, name='dense5') (X)\n#     X = BatchNormalization()(X)\n#     X = Activation(activations)(X)\n    \n#     X = Dense(500, name='dense6') (X)\n#     X = BatchNormalization()(X)\n#     X = Activation(activations)(X)\n    \n#     X = Dense(500, name='dense7') (X)\n#     X = BatchNormalization()(X)\n#     X = Activation(activations)(X)\n    \n#     X = Dense(500, name='dense8') (X)\n#     X = BatchNormalization()(X)\n#     X = Activation(activations)(X)\n    \n#     X = Dense(500, name='dense9') (X)\n#     X = BatchNormalization()(X)\n#     X = Activation(activations)(X)\n    \n    X = Dense(500, name='dense10') (X)\n#     X = BatchNormalization()(X)\n    X = Activation(activations)(X)\n    \n    X = Dense(500, activation=activations, name='dense11') (X)\n    X = Dense(500, activation=activations, name='dense12') (X)\n    X = Dense(300, activation=activations, name='dense13') (X)\n    X = Dense(200, activation=activations, name='dense14') (X)\n    X = Dense(100, activation=activations, name='dense15') (X)\n    X = Dense(100, activation=activations, name='dense16') (X)\n    X = Dense(100, activation=activations, name='dense17') (X)\n    \n    output = Dense(1, name='out') (X)\n    \n    return Model(X_input, output)","b3d5727b":"def RMSLE(y_pred, y_true):\n    return K.sqrt(K.mean(K.pow(K.log(y_pred+1) - K.log(y_true+1), 2)))","0161c9e5":"\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss', factor=0.01, patience=5, verbose=1)\n\ncheckpoint = ModelCheckpoint('checkpoint.h5', monitor='val_loss', \n                             verbose=0, save_best_only=True, mode='min')\n\nmodel = build_model((80, ))\noptimizer = optimizers.Adam(lr=0.001, decay=0.0001)\n\nmodel.compile(optimizer, loss=RMSLE)\nhistory = model.fit(X, y, epochs=50, validation_data=(X_val, y_val), callbacks=[reduce_lr, checkpoint])","af4b17ab":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['loos', 'val_loss'])","ca548b7b":"root_mean_squerd_log_error(np.squeeze(model.predict(X_val)), y_val)","3cc3eb46":"# create_submission(load_model('checkpoint.h5'), name='ANN', fit=False)","23f14c19":"create_submission(model, name='ANN_reg',fit=False)","00e63635":"# model.evaluate(X_val, y_val)\n# load_model('checkpoint.h5').evaluate(X_val, y_val)","faf4de1c":"**Set seed**","66e356bc":"## Train Test Split","3d99dd47":"## Neural Network","00a70f4a":"## Random Forrest","a516de75":"## Save Model","3b68e484":"## Decision Tree","d529b3c7":"## SVM ","663c1a02":"## ADABoot"}}