{"cell_type":{"4c2be8c7":"code","d4657fe0":"code","3242446f":"code","34d94d68":"code","713de63f":"code","301b0930":"code","6b2d9f2d":"code","71f7d3a1":"code","591df5bf":"code","b790981a":"code","9f286c47":"code","37fdd394":"code","367e0d09":"code","0d4ad909":"code","ab160504":"code","23d2939e":"code","ce36b45e":"code","8a66bed3":"code","28a043e6":"code","54dcd033":"code","873d6e6b":"code","0ddb89bb":"code","aea32d10":"code","41a48481":"code","988c0a61":"code","683bc959":"code","4c523ea0":"code","12b96ace":"code","2ca4d13c":"code","72b08ffb":"code","971be0b8":"code","6301b402":"code","d75e73eb":"code","2afa7874":"code","13a23e71":"code","401a7f09":"code","28c90f45":"code","01d4b218":"code","e853e3b9":"code","e61c5b92":"code","409115f7":"code","18afd2ee":"code","75071613":"code","cdf73851":"code","efbe1cb3":"code","20c2ce68":"markdown","23f160a7":"markdown","bcaa2bc7":"markdown","31af63f5":"markdown","051adc2d":"markdown","0485ec4f":"markdown","75a23ad4":"markdown","cdff4392":"markdown","bd3d63d8":"markdown","c3f4d97b":"markdown","959c69f1":"markdown","8cacacad":"markdown","ef4e562b":"markdown","a6d0d91c":"markdown","53a0fa51":"markdown","002f24bf":"markdown","3e41e5a6":"markdown","6d34cc48":"markdown"},"source":{"4c2be8c7":"!pip install timm -q","d4657fe0":"from fastai.vision.all import *\nimport torch\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score,confusion_matrix\nfrom timm import create_model\nimport timm","3242446f":"path = Path('..\/input\/prostate-cancer-grade-assessment')\npath_img = Path('..\/input\/panda-16x128x128-tiles-data\/train')","34d94d68":"sz = 128\nN = 12\nn_classes = 6\nBS=32","713de63f":"df = pd.read_csv(path\/'train.csv')","301b0930":"df.head(5)","6b2d9f2d":"len(df)","71f7d3a1":"fns = []\nfor f in path_img.ls():\n    fns.append(str(f).split('\/')[-1].split('_')[0])","591df5bf":"remove_fns = []\nfor f in list(df['image_id'].values):\n    if f not in fns:\n        remove_fns.append(f)","b790981a":"len(remove_fns)","9f286c47":"df = df[~df['image_id'].isin(remove_fns)]","37fdd394":"len(df)","367e0d09":"N_FOLDS = 3\ndf['fold'] = -1\n\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=42, shuffle=True)\nfor i, (_, test_index) in enumerate(strat_kfold.split(df.image_id.values, df['isup_grade'].values)):\n    df.iloc[test_index, -1] = i\n    \ndf['fold'] = df['fold'].astype('int')","0d4ad909":"mean = torch.tensor([1.0-0.90949707, 1.0-0.8188697, 1.0-0.87795304])\nstd = torch.tensor([0.36357649, 0.49984502, 0.40477625])","ab160504":"def open_image(fn):\n    \n    with warnings.catch_warnings():\n        warnings.simplefilter(\"ignore\", UserWarning) # EXIF warning from TiffPlugin\n        x = PILImage.create(fn)\n\n    x = torch.Tensor(np.array(x))\n    x = x.permute(2,0,1).float()\/255.0\n    x = (1.0 - x) #invert image for zero padding plus normalize\n    \n    return x","23d2939e":"class PandaImage(fastuple):\n    def show(self, ctx=None, **kwargs):\n        img, label = self\n        img = img.view(N,-1,3,sz,sz).permute(1,2,3,0,4).contiguous().view(3,-1,sz*N)\n        img = 1- img\n        img = img.permute(1,2,0)\n        img = np.array(img*255).astype(np.uint8)\n        \n        return show_image(PILImage.create(img), title=label, ctx=ctx)","ce36b45e":"@typedispatch\ndef show_batch(x:PandaImage, y, samples, ctxs=None, max_n=6, nrows=None, ncols=1, figsize=(20,20), **kwargs):\n    if figsize is None: figsize = (ncols*6, max_n\/\/ncols * 3)\n    if ctxs is None: ctxs = get_grid(min(x[0].shape[0], max_n), nrows=None, ncols=ncols, figsize=figsize)\n    for i,ctx in enumerate(ctxs): PandaImage(x[0][i], [x[1][i].item()]).show(ctx=ctx)","8a66bed3":"class PandaTransform(Transform):\n    def __init__(self, path_img, df, files, valid=False):\n        self.files = files\n        self.path_img = path_img\n        self.df = df\n        self.valid = valid\n        self.tfms = aug_transforms(flip_vert=True, max_rotate=15, pad_mode='zeros')\n        \n    def encodes(self, i):\n        files_i = self.files[i]\n        label  = self.df[self.df['image_id'] == files_i]['isup_grade'].values\n        \n        fnames = [self.path_img\/f'{files_i}_{i}.png' for i in range(N)]\n        imgs = [open_image(fname) for fname in fnames]\n        \n        if not self.valid:\n            aug_img = []\n            for img in imgs: \n                for t in self.tfms:\n                    img = t(img, split_idx=0)\n                aug_img.append(img)\n\n            aug_img = torch.stack(aug_img, 0)\n            return (PandaImage(aug_img, label))\n        \n        else:\n            return (PandaImage(torch.stack(imgs, 0), label))","28a043e6":"train_fns = df[df['fold'] != 0]['image_id'].values\nvalid_fns = df[df['fold'] == 0]['image_id'].values","54dcd033":"train_tl= TfmdLists(range(len(train_fns)), [PandaTransform(path_img, df, train_fns, valid=False)])\nvalid_tl= TfmdLists(range(len(valid_fns)), [PandaTransform(path_img, df, valid_fns, valid=True)])","873d6e6b":"dls = DataLoaders.from_dsets(train_tl, valid_tl, \n                             after_batch=[Normalize.from_stats(*(mean, std))], bs=BS)\ndls = dls.cuda()","0ddb89bb":"dls.show_batch()","aea32d10":"x, y = dls.one_batch()","41a48481":"x.shape","988c0a61":"class CustomEnd(nn.Module):\n    def __init__(self, scaler = SigmoidRange(-1, 6.0)):\n        super().__init__()\n        self.scaler_ = scaler\n        \n    def forward(self, x):\n        classif = x[:, :-1]\n        regress = self.scaler_ (x[:, -1])\n        return classif, regress\n    \ndef make_divisible(v, divisor=8, min_value=None):\n    min_value = min_value or divisor\n    new_v = max(min_value, int(v + divisor \/ 2) \/\/ divisor * divisor)\n   # Make sure that round down does not go down by more than 10%.\n    if new_v < 0.9 * v:\n        new_v += divisor\n    return new_v\n\ndef sigmoid(x, inplace: bool = False):\n    return x.sigmoid_() if inplace else x.sigmoid()\n\nclass SqueezeExcite(nn.Module):\n    def __init__(self, in_chs, se_ratio=0.25, reduced_base_chs=None,\n             act_layer=nn.ReLU, gate_fn=sigmoid, divisor=1, **_):\n        super(SqueezeExcite, self).__init__()\n        self.gate_fn = gate_fn\n        reduced_chs = make_divisible((reduced_base_chs or in_chs) * se_ratio, divisor)\n        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n        self.conv_reduce = nn.Conv2d(in_chs, reduced_chs, 1, bias=True)\n        self.act1 = act_layer(inplace=True)\n        self.conv_expand = nn.Conv2d(reduced_chs, in_chs, 1, bias=True)\n    def forward(self, x):\n        x_se = self.avg_pool(x)\n        x_se = self.conv_reduce(x_se)\n        x_se = self.act1(x_se)\n        x_se = self.conv_expand(x_se)\n        x = x * self.gate_fn(x_se)\n        return x","683bc959":"class DrHBModel(nn.Module):\n    def __init__(self, N):\n        super().__init__()\n        self.N = N\n        m = models.resnet34(pretrained=True)\n        self.enc = nn.Sequential(*list(m.children())[:-2])       \n        nc = list(m.children())[-1].in_features\n        self.cb = SqueezeExcite(nc)\n        self.head = nn.Sequential(AdaptiveConcatPool2d(),\n                                  Flatten(),\n                                  nn.Linear(2*nc,512),\n                                  nn.ReLU(inplace=True),\n                                  nn.Dropout(0.4),\n                                  nn.Linear(512,7), \n                                  CustomEnd())\n        \n    def forward(self, x):\n        shape = x.shape\n        n = shape[1]\n        x = x.view(-1,shape[2],shape[3],shape[4])\n        x = self.enc(x)\n        \n        shape = x.shape\n        x = x.view(-1, n, x.shape[1], x.shape[2], x.shape[3]).permute(0, 2, 1, 3, 4).contiguous().\\\n        view(-1, x.shape[1], x.shape[2] * n, x.shape[3])\n        x = x.view(x.shape[0], x.shape[1], x.shape[2]\/\/int(np.sqrt(n)), -1)\n        x = self.cb(x)\n        x = self.head(x)\n        return x","4c523ea0":"drhbmodel= DrHBModel(N)","12b96ace":"def drhbmodel_splitter(m): return L(m.enc, m.cb, m.head).map(params)","2ca4d13c":"def get_timm_vis_model(arch:str, pretrained=True, cut=None):\n    model = create_model(arch, pretrained=pretrained)\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    model =  nn.Sequential(*list(model.children())[:cut])\n    \n    return model","72b08ffb":"class PandaModel(Module):\n    def __init__(self, n_classes, arch, *args, **kwargs):\n        self.vis_model = get_timm_vis_model(arch)\n        self.cb = SqueezeExcite(num_features_model(self.vis_model))\n        self.vis_head  = create_head(num_features_model(self.vis_model), n_classes+1)\n        self.custom_end = CustomEnd()\n                \n    def forward(self, x):\n        shape = x[0].shape\n        n = shape[0]\n        x = x.view(-1,shape[1],shape[2],shape[3]) \n        #x: bs*N x 3 x 128 x 128\n        \n        x = self.vis_model(x)\n        shape = x.shape \n        #x: bs*N x C x 4 x 4\n        #concatenate the output for tiles into a single map\n        x = x.view(-1,n,shape[1],shape[2],shape[3]).permute(0,2,1,3,4).contiguous().view(-1,shape[1],shape[2]*n,shape[3])\n        #x: bs x C x N*4 x 4\n        x = self.vis_head(x)\n        #x: bs x n\n        x = self.custom_end(x)\n        return x","971be0b8":"pandamodel = PandaModel(n_classes, 'ssl_resnext50_32x4d')","6301b402":"def pandamodel_splitter(m): return L(m.vis_model, m.vis_head).map(params)","d75e73eb":"class CustomCrossEntropy(nn.CrossEntropyLoss):\n  \n  def forward(self, input, target):\n    #target = target.long()\n    target = target.squeeze()\n    return F.cross_entropy(input, target, weight=self.weight, ignore_index=self.ignore_index, reduction=self.reduction)","2afa7874":"class CustomLoss(nn.Module):\n    def __init__(self, loss_ce, loss_mse):\n        super().__init__()\n        self.loss_ce  = loss_ce\n        self.loss_mse = loss_mse \n        \n    def forward(self, i, o):\n        loss_cross = self.loss_ce(i[0], o)\n        loss_mserr = self.loss_mse(i[1], o.float().squeeze())\n        return loss_cross + loss_mserr","13a23e71":"def qkp_class(y_hat, y):\n    y_hat = torch.argmax(F.softmax(y_hat[0], dim=1), dim=1)\n    return torch.tensor(cohen_kappa_score(y_hat.cpu(), y.cpu(), weights='quadratic'), device='cuda:0')\n\ndef qkp_regres(y_hat, y):\n    p = optR.predict(y_hat[1].cpu().numpy(), coefficients)\n    return torch.tensor(cohen_kappa_score(p, y.cpu(), weights='quadratic'), device='cuda:0')\n\ndef qkp_combine(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round((y_hat[1] + torch.argmax(F.softmax(y_hat[0], dim=1), dim=1))\/2).cpu(), y.cpu(), weights='quadratic'),device='cuda:0')","401a7f09":"class OptimizedRounder():\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            elif pred >= coef[3] and pred < coef[4]:\n                X_p[i] = 4\n            else:\n                X_p[i] = 5\n\n        ll = quadratic_weighted_kappa(y, X_p)\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5, 4.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            elif pred >= coef[3] and pred < coef[4]:\n                X_p[i] = 4\n            else:\n                X_p[i] = 5\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","28c90f45":"optR = OptimizedRounder()\ncoefficients = [0.5, 1.5, 2.5, 3.5, 4.5]","01d4b218":"learn = Learner(dls, \n                drhbmodel, \n                loss_func=CustomLoss(CustomCrossEntropy(), nn.MSELoss()), \n                metrics=[qkp_class, qkp_regres, qkp_combine],\n                splitter=drhbmodel_splitter).to_fp16()","e853e3b9":"learn.freeze()\nlearn.summary()","e61c5b92":"learn.fit_one_cycle(2, 1e-3)","409115f7":"learn.unfreeze()\nlearn.fit_one_cycle(3, 1e-3)","18afd2ee":"learn = Learner(dls, \n                pandamodel, \n                loss_func=CustomLoss(CustomCrossEntropy(), nn.MSELoss()), \n                metrics=[qkp_class, qkp_regres, qkp_combine],\n                splitter=pandamodel_splitter).to_fp16()","75071613":"learn.freeze()\nlearn.summary()","cdf73851":"learn.fit_one_cycle(2, 1e-3)","efbe1cb3":"learn.unfreeze()\nlearn.fit_one_cycle(3, 1e-3)","20c2ce68":"References and resources","23f160a7":"# Preparing data and dataloader","bcaa2bc7":"The following section was written to make use of `timm` models.","31af63f5":"# Preparing timm-based model with DrHB's tricks in his 2nd place solution","051adc2d":"The mean and std comes from @iafoss's notebook. ","0485ec4f":"`PandaTransform` opens N tiles of a `image_id`. Then if it is a train dataset carries out data augmentation and stacks the N images to be used for preparing dataloader.   ","75a23ad4":"The PandaImage class reverses modification and allows for the images to be displayed.","cdff4392":"# Preparing Loss Functions and Metrics","bd3d63d8":"# Training DrHB Model","c3f4d97b":"# Training timm Model","959c69f1":"In this notebook, we will try to tackle the PANDA competition dataset using fastai v2. A comprehensive EDA can be found in this [notebook](https:\/\/www.kaggle.com\/tanulsingh077\/prostate-cancer-in-depth-understanding-eda-model). The [solution](https:\/\/www.kaggle.com\/iafoss\/panda-concat-tile-pooling-starter-0-79-lb) uses concat tiling as proposed by @iafoss. The modified datasets we will use here also comes from @iafoss. We will also use tricks and models used by @DrHB in his [2nd place solution](https:\/\/github.com\/DrHB\/PANDA-2nd-place-solution\/tree\/main\/train_drhb). ","8cacacad":"https:\/\/www.kaggle.com\/iafoss\/panda-concat-tile-pooling-starter-0-79-lb\n\nhttps:\/\/www.kaggle.com\/tanulsingh077\/prostate-cancer-in-depth-understanding-eda-model\n\nhttps:\/\/github.com\/kentaroy47\/Kaggle-PANDA-1st-place-solution\/tree\/master\/src \n\nhttps:\/\/docs.google.com\/presentation\/d\/1Ies4vnyVtW5U3XNDr_fom43ZJDIodu1SV6DSK8di6fs\/edit#slide=id.g9b10629a30_0_299\n\nhttps:\/\/github.com\/DrHB\/PANDA-2nd-place-solution\/tree\/main\/train_drhb","ef4e562b":"We make use of fastcore's Type Dispatch to make `show_batch` work.","a6d0d91c":"The following model and the tricks come from DrHB's solution in the competition. The model outputs n_classes plus one (in this case: 7) output. The extra output will be used in regression-based prediction. The `CustomEnd` that is atached to the end of the model will allow for the preparation of the output that will be fed to the `loss_function`. The model also make use of `SqueezeExcite` layer.","53a0fa51":"We write a function to open images and prepare them.","002f24bf":"# Model as used in DrHB's 2nd place solution","3e41e5a6":"Looks like everything is working fine.","6d34cc48":"# Imports and initial exploration"}}