{"cell_type":{"c93a150a":"code","9afaaeb6":"code","1c86ddc7":"code","07c279da":"code","097a9208":"code","671ce853":"code","2d442cee":"code","6a78f3ab":"code","abab93ba":"code","4ced49f4":"code","89c4aa8b":"code","ac6f6831":"code","de4765a4":"code","f3f33314":"code","645551ba":"code","67a4c132":"code","23a4a27a":"code","7233bdb6":"code","a61fb05c":"code","2d56f889":"code","e624b215":"code","3f23fb5d":"code","2e450d09":"code","84d80e8c":"code","f07166ed":"code","c5e9f746":"code","8601d45d":"code","2f1945ff":"code","d3cc39a3":"code","1e66b3dd":"code","39aa18c1":"code","e8f22142":"code","64332e91":"code","86f36b96":"markdown","4e09e0dd":"markdown","c5af7732":"markdown","6e514a89":"markdown","84e3c7bd":"markdown","8214d45e":"markdown","33298a2c":"markdown"},"source":{"c93a150a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    #for filename in filenames:\n        #print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9afaaeb6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom tqdm.auto import tqdm\nfrom glob import glob\nimport time, gc\nimport cv2\nfrom keras import backend as K\nimport matplotlib.image as mpimg\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.models import clone_model\nfrom keras.layers import Dense,Conv2D,Flatten,MaxPool2D,Dropout,BatchNormalization,Activation\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ReduceLROnPlateau, ModelCheckpoint\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nimport PIL.Image as Image, PIL.ImageDraw as ImageDraw, PIL.ImageFont as ImageFont\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\nfrom keras.models import Model,Sequential, Input, load_model\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, AveragePooling2D, GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau\nfrom keras.applications import DenseNet121","1c86ddc7":"import os\nimport gc\nimport json\nimport math\nimport cv2\nimport PIL\nfrom PIL import Image\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport pandas as pd\n\nimport scipy\nfrom tqdm import tqdm\n%matplotlib inline\nfrom keras.preprocessing import image","07c279da":"sample_submission = pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/sample_submission.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/test.csv\")\ntrain = pd.read_csv(\"\/kaggle\/input\/siim-isic-melanoma-classification\/train.csv\")","097a9208":"train.head()","671ce853":"plt.hist(train['target'])\nplt.title('Frequency Histogram of Melanoma')\nplt.figure(figsize=(12, 12))\nplt.show()","2d442cee":"#def preprocess_image(image_path, desired_size=imSize):\n    #im = Image.open(image_path)\n    #im = im.resize((desired_size, )*2, resample=Image.LANCZOS)\n    \n    #return im","6a78f3ab":"#N = train.shape[0]\/\/3\n#x_train = np.empty((N, imSize, imSize, 3), dtype=np.uint8)\n#for i, image_id in enumerate(tqdm(train['image_name'])):\n    #if i==N:\n        #break\n    #x_train[i, :, :, :] = preprocess_image(\n       # f'..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/{image_id}.jpg'\n    #)","abab93ba":"x = train['image_name']\ntrain_malignant=train[train['target'] == 1]\ntrain_benign=train[train['target'] == 0]\ntrain_benign=train_benign[0:584]\nimg_size=64","4ced49f4":"train_malignant.head()","89c4aa8b":"train_benign.head()","ac6f6831":"train_malignant.shape","de4765a4":"train_benign.shape","f3f33314":"train_balanced = pd.concat([train_benign, train_malignant])\ntrain_balanced.head()","645551ba":"train_balanced.tail()","67a4c132":"train_balanced.shape","23a4a27a":"plt.hist(train_balanced['target'])\nplt.title('Frequency Histogram of Balanced Melanoma')\nplt.figure(figsize=(12, 12))\nplt.show()","7233bdb6":"train_image=[]\nfor i,name in enumerate(tqdm(train_balanced['image_name'])):\n    path='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'+name+'.jpg'\n    img=cv2.imread(path)\n    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n    train_image.append(image)","a61fb05c":"fig, ax = plt.subplots(1, 4, figsize=(15, 15))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(train_image[i])","2d56f889":"test.head()","e624b215":"test_image=[]\nfor i,name in enumerate(tqdm(test['image_name'])):\n    path='\/kaggle\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'+name+'.jpg'\n    img=cv2.imread(path)\n    image=cv2.resize(img,(img_size,img_size),interpolation=cv2.INTER_AREA)\n    test_image.append(image)","3f23fb5d":"fig, ax = plt.subplots(1, 4, figsize=(15, 15))\nfor i in range(4):\n    ax[i].set_axis_off()\n    ax[i].imshow(test_image[i])","2e450d09":"X_Train = np.ndarray(shape=(len(train_image), img_size, img_size, 3),dtype = np.float32)\ni=0\nfor image in train_image:\n    #X_Train[i]=img_to_array(image)\n    X_Train[i]=train_image[i]\n    i=i+1\nX_Train=X_Train\/255\nprint('Train Shape: {}'.format(X_Train.shape))","84d80e8c":"X_Test = np.ndarray(shape=(len(test_image), img_size, img_size, 3),dtype = np.float32)\ni=0\nfor image in test_image:\n    #X_Test[i]=img_to_array(image)\n    X_Test[i]=test_image[i]\n    i=i+1\n    \nX_Test=X_Test\/255\nprint('Test Shape: {}'.format(X_Test.shape))","f07166ed":"y = train_balanced['target']\ny.tail()","c5e9f746":"from keras.utils.np_utils import to_categorical\ny_train = np.array(y.values)\ny_train = to_categorical(y_train, num_classes=2)\nprint(y_train.shape,y_train[1100])\nprint(y_train[3])","8601d45d":"EPOCHS = 80\nSIZE=64\nN_ch=3\nBATCH_SIZE = 64","2f1945ff":"def build_densenet():\n    densenet = DenseNet121(weights='imagenet', include_top=False)\n\n    input = Input(shape=(SIZE, SIZE, N_ch))\n    x = Conv2D(3, (3, 3), padding='same')(input)\n    \n    x = densenet(x)\n    \n    x = GlobalAveragePooling2D()(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n    x = Dense(256, activation='relu')(x)\n    x = BatchNormalization()(x)\n    x = Dropout(0.5)(x)\n\n    # multi output\n    output = Dense(2,activation = 'softmax', name='root')(x)\n \n\n    # model\n    model = Model(input,output)\n    \n    optimizer = Adam(lr=0.002, beta_1=0.9, beta_2=0.999, epsilon=0.1, decay=0.0)\n    model.compile(loss='categorical_crossentropy', optimizer=optimizer, metrics=['accuracy'])\n    model.summary()\n    \n    return model","d3cc39a3":"X_train, X_val, Y_train, Y_val = train_test_split(X_Train, y_train, test_size=0.2, random_state=42)","1e66b3dd":"model = build_densenet()\nannealer = ReduceLROnPlateau(monitor='val_accuracy', factor=0.5, patience=5, verbose=1, min_lr=1e-3)\ncheckpoint = ModelCheckpoint('model.h5', verbose=1, save_best_only=True)\n# Generates batches of image data with data augmentation\ndatagen = ImageDataGenerator(rotation_range=360, # Degree range for random rotations\n                        width_shift_range=0.2, # Range for random horizontal shifts\n                        height_shift_range=0.2, # Range for random vertical shifts\n                        zoom_range=0.2, # Range for random zoom\n                        horizontal_flip=True, # Randomly flip inputs horizontally\n                        vertical_flip=True) # Randomly flip inputs vertically\n\ndatagen.fit(X_train)\n# Fits the model on batches with real-time data augmentation\nhist = model.fit_generator(datagen.flow(X_train, Y_train, batch_size=BATCH_SIZE),\n               steps_per_epoch=X_train.shape[0] \/\/ BATCH_SIZE,\n               epochs=EPOCHS,\n               verbose=1,\n               callbacks=[annealer, checkpoint],\n               validation_data=(X_val, Y_val))","39aa18c1":"final_loss, final_accuracy = model.evaluate(X_val, Y_val)\nprint('Final Loss: {}, Final Accuracy: {}'.format(final_loss, final_accuracy))","e8f22142":"predict = model.predict(X_Test)\nprint(predict)\nresult=[]\ndisease_class=['0','1']\nfor i in range(len(predict)):\n    ind=np.argmax(predict[i])\n    result.append(disease_class[ind])","64332e91":"sample_submission[\"target\"]= result\nsample_submission.to_csv('submission.csv', index=False)\nsample_submission.head()","86f36b96":"## If you like this Notebook, please Upvote. Thanks","4e09e0dd":"## Concat Data","c5af7732":"## DenseNet121 Model","6e514a89":"## Augmentation and Model Fitting","84e3c7bd":"> ## Taking same number of data from malignant and benign\nI will take less numbers of training images than available training images. It is an experiment","8214d45e":"## New Balanced Data","33298a2c":"## Benign vs Malignant Data"}}