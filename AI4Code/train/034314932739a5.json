{"cell_type":{"1842c0e9":"code","b1b8d8e1":"code","05c87363":"code","da1fd70c":"code","9abc65aa":"code","8c88f25b":"code","54666b34":"code","c15b62b4":"code","efb521c8":"code","89b0f6ba":"code","2391a2c3":"code","8e68befa":"code","aef2912b":"code","d1811707":"code","218d0c3d":"code","7b1b595a":"code","70f34b05":"code","11e0e748":"code","a44c2fe4":"code","11e7d0ea":"code","b2f28caa":"code","15faf5d6":"code","fa1ef3e4":"code","b73d85de":"code","c5392dbd":"code","3617c1d4":"code","6be51b64":"code","2f274f93":"code","9fabac42":"code","8411c0cd":"markdown","5c45201d":"markdown","04352ec8":"markdown","dd117418":"markdown"},"source":{"1842c0e9":"# import os\n## !pip install apyori\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# !pip install mlxtend\nimport numpy as np\nimport pandas as pd\nfrom mlxtend.frequent_patterns import apriori\nfrom mlxtend.frequent_patterns import association_rules\nfrom mlxtend.preprocessing import TransactionEncoder","b1b8d8e1":"pwd","05c87363":"# freq_item = pd.read_csv('..\/input\/freq-item-market-basket\/supp_freq.csv')","da1fd70c":"assoc = pd.read_csv('..\/input\/market-basket-id-ndsc-2020\/association_order.csv')\nrls = pd.read_csv('..\/input\/market-basket-id-ndsc-2020\/rules.csv')\n\nassoc.shape, rls.shape","9abc65aa":"assoc.head()","8c88f25b":"rls.head()","54666b34":"assoc.isnull().sum()","c15b62b4":"assoc['orderid'] = assoc['orderid'].astype('str')\nassoc['itemid'] = assoc['itemid'].astype('str')\n\nassoc.dtypes","efb521c8":"## Very High Memory Use!!!\n# basket = (assoc\n#           .groupby(['orderid', 'itemid'])\n#           .agg(len).unstack().reset_index().fillna(0)\n#           .set_index('orderid'))","89b0f6ba":"basket = assoc.groupby('orderid', as_index=False)['itemid'].apply(','.join)\nbasket","2391a2c3":"trans = list(basket['itemid'].apply(lambda x: sorted(x.split(','))))\ntrans","8e68befa":"# preprocessing before use apriori() --> one hot data\nencod = TransactionEncoder()\noh_trans = encod.fit_transform(trans)\noh_tr = pd.DataFrame(oh_trans, columns=encod.columns_)\n\noh_tr","aef2912b":"# Very Long Time Running!!\n# 1\/92382 = min_support\nfreq_item = apriori(oh_tr, min_support=.00001, max_len=3, use_colnames=True, low_memory=True)\nfreq_item","d1811707":"# freq_item.to_csv('.\/supp_freq.csv', index=False)","218d0c3d":"# import re\n# freq_item['itemsets'] = freq_item['itemsets'].apply(lambda x: set(map(str,re.findall(r'\\d+', x))))","7b1b595a":"# freq_item['setitem'] = freq_item['itemsets'].apply(lambda x: ','.join(set(x)))","70f34b05":"# # cek for A > B\n# rls['itemA'] = rls['rule'].apply(lambda x: x.split('>')[0])\n# rls['itemC'] = rls['rule'].apply(lambda x: x.split('>')[1])\n\n# # cek for three sets\n# rls['is_AB>C'] = rls['itemA'].apply(lambda x: 1 if(len(x.split('&')) > 1) else 0)\n# rls['is_A>BC'] = rls['itemC'].apply(lambda x: 1 if(len(x.split('&')) > 1) else 0)\n\n# # filtered based on set numbers\n# case_a_to_b = rls[(rls['is_A>BC'] == 0) & (rls['is_AB>C'] == 0)]\n# case_ab_to_c = rls[rls['is_AB>C'] == 1]\n# case_a_to_bc = rls[rls['is_A>BC'] == 1]\n\n# # three sets\n# case_ab_to_c['itemB'] = case_ab_to_c['itemA'].apply(lambda x: x.split('&')[1])\n# case_ab_to_c['itemA'] = case_ab_to_c['itemA'].apply(lambda x: x.split('&')[0])\n\n# case_a_to_bc['itemB'] = case_a_to_bc['itemC'].apply(lambda x: x.split('&')[0])\n# case_a_to_bc['itemC'] = case_a_to_bc['itemC'].apply(lambda x: x.split('&')[1])","11e0e748":"rules2 = association_rules(freq_item, metric=\"confidence\", min_threshold=0.01)\nrules2","a44c2fe4":"rules2['left_len'] = rules2['antecedents'].apply(lambda x: len(x))\nrules2['right_len'] = rules2['consequents'].apply(lambda x: len(x))","11e7d0ea":"# Matching the rules\ntwo_items = rules2[(rules2['left_len'] == 1) & (rules2['right_len'] == 1)]\nthree_items1 = rules2[rules2['left_len'] > 1]\nthree_items2 = rules2[rules2['right_len'] > 1]\n\ntwo_items = two_items[['antecedents', 'consequents', 'confidence']]\nthree_items1 = three_items1[['antecedents', 'consequents', 'confidence']]\nthree_items2 = three_items2[['antecedents', 'consequents', 'confidence']]","b2f28caa":"type(two_items['antecedents'].iloc[0])","15faf5d6":"# Matching with the rules.csv files\ntwo_items['rule'] = two_items[['antecedents', 'consequents']].apply(\n    lambda x: ''.join(sorted(x[0])) + '>' + ''.join(sorted(x[1])), axis=1\n)\n\nthree_items1['rule'] = three_items1[['antecedents', 'consequents']].apply(\n    lambda x: '&'.join(sorted(x[0])) + '>' + ''.join(sorted(x[1])), axis=1\n)\n\nthree_items2['rule'] = three_items2[['antecedents', 'consequents']].apply(\n    lambda x: ''.join(sorted(x[0])) + '>' + '&'.join(sorted(x[1])), axis=1\n)","fa1ef3e4":"drop_cols = ['antecedents', 'consequents']\n\ntwo_items = two_items.drop(drop_cols, axis=1)\nthree_items1 = three_items1.drop(drop_cols, axis=1)\nthree_items2 = three_items2.drop(drop_cols, axis=1)\n\nall_rls2 = pd.concat([two_items, three_items1, three_items2]).sort_values(by='rule').reset_index(drop=True)","b73d85de":"subss = all_rls2[all_rls2['rule'].isin(rls['rule'])]\nsubss","c5392dbd":"# rules not available\nrls[~rls['rule'].isin(subss['rule'])]","3617c1d4":"subss = rls.join(all_rls2.set_index('rule'), how='left', on='rule').fillna(0.034)","6be51b64":"int(2764.705882), int(2764.123)","2f274f93":"# submission requirements\nsubss['conf'] = subss['confidence'] * 1000\nsubss['confidence'] = subss['conf'].apply(lambda x: int(x))\nsubss = subss.drop('conf', axis=1)\nsubss","9fabac42":"subss.to_csv('.\/supp_freq.csv', index=False)","8411c0cd":"# Submission","5c45201d":"# Apriori","04352ec8":"# Association Rules","dd117418":"# ATTENTION!!<br> Need a Lot of *Memory* and *Time* to Running!!!\n\n* &pm; 3 hours &emsp;&emsp;&emsp;&nbsp;&nbsp; : Minimum Ram 16 GB (do nothing)\n* Below 30 minutes : Minimum Ram >20 GB (in apriori() use low_memory=False)"}}