{"cell_type":{"c31d9edf":"code","0fecec5d":"code","713fe8a1":"code","f410d367":"code","fc767423":"code","1de1adf0":"code","13fc9316":"code","64af51b6":"code","16d3fcd4":"code","94910f9c":"code","e62ca55e":"code","8c0aeb6d":"code","c68604a7":"code","6431e9e2":"code","b23ed999":"code","baa036a8":"code","a7640639":"code","f02f61c6":"markdown","86d4967d":"markdown","8fc78dbc":"markdown","c8346787":"markdown","e159ed64":"markdown","70fea49f":"markdown","17386f3f":"markdown","f04a2590":"markdown","4914ac30":"markdown","0902cd4e":"markdown","358c6f18":"markdown","e9abbb36":"markdown"},"source":{"c31d9edf":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing  \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier","0fecec5d":"df = pd.read_csv('..\/input\/iris\/Iris.csv')\ndf","713fe8a1":"df = df.drop(['Id'], axis = 1)  # dropping unnecessary column\ndf","f410d367":"df.info()   # getting an insight into the type of data ","fc767423":"sns.pairplot(df)  # to show relation between columns\nplt.show()","1de1adf0":"corr = df.corr()\nsns.heatmap(corr, annot=True)  # quantifying the relationship","13fc9316":"label_encoder = preprocessing.LabelEncoder()  # for columns not with int\/float type values","64af51b6":"df['Species'] = label_encoder.fit_transform(df['Species'])   # label encoding 'Species' column  \ndf","16d3fcd4":"df['Species'].value_counts()  # count of each type of species","94910f9c":"a = df.values  ","e62ca55e":"# Data Standardization gives data zero mean and unit variance, it is good practice, especially for algorithms such as KNN which is based on distance of cases\ndf = pd.DataFrame(preprocessing.StandardScaler().fit_transform(a))\ndf","8c0aeb6d":"df_new = df.rename(columns={0:'SepalLengthCm',1:'SepalWidthCm',2:'PetalLengthCm',3:'PetalWidthCm',4:'Species'}) # renaming the columns\ndf_new","c68604a7":"df_new['Species'] = df_new['Species'].astype('int32')  # converting into 'int' data type for predictions\ndf_new","6431e9e2":"data = df_new.values\nX, y = data[:,:-1], data[:,-1]\nX_train, X_test, y_train, y_test = train_test_split( X, y, test_size=0.20, random_state=0)  # splitting in the ratio 80:20","b23ed999":"# letting k = 3\nk = 3\n# training model and predicting  \nkclf = KNeighborsClassifier(n_neighbors = k).fit(X_train,y_train)\nkclf","baa036a8":"y_pred = kclf.predict(X_test)","a7640639":"print(\"Train set Accuracy: \", metrics.accuracy_score(y_train, kclf.predict(X_train)))\nprint(\"Test set Accuracy: \", metrics.accuracy_score(y_test, y_pred))","f02f61c6":"### Splitting Data for Training and Testing","86d4967d":"### **Classification is 96.67% accurate.**","8fc78dbc":"### Importing Libraries","c8346787":"### Data Preprocessing","e159ed64":"### Checking Accuracy","70fea49f":"# **Iris Species Classification using K Nearest Neighbours (KNN)**","17386f3f":"### Making Predictions","f04a2590":"### Data Normalization","4914ac30":"### Training the Model","0902cd4e":"### Label Encoding","358c6f18":"### Getting Data","e9abbb36":"### Data Visualization"}}