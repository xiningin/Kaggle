{"cell_type":{"aeeb12f8":"code","a48407de":"code","38603c60":"code","98e6a5c7":"code","3201c51a":"code","7239cee5":"code","eda8dc82":"code","07cb0ed8":"code","236c1c98":"code","de49f842":"code","9ae446bb":"code","bf2a3cf2":"code","de5d8067":"code","00e4bace":"code","d604fe97":"code","7c1a8435":"code","743dda96":"code","8976bc90":"code","5d76a6e6":"code","8ca1a15c":"code","a8670827":"code","f78e64fa":"code","1dc01ee0":"code","5ae4522f":"code","0e2b5ae7":"code","cfcf4ca0":"code","dd6f1e55":"code","62830971":"code","06c8eaa8":"code","03fcd67d":"code","e50e4936":"code","88baaece":"code","0f7721e2":"code","7248d7b0":"code","bde93ed2":"code","21d0623b":"code","10013066":"code","9be53074":"code","3001aa63":"code","19f2debd":"code","7900b1b0":"code","2449f557":"code","5aebc189":"code","2e0174d4":"code","16426057":"code","b3f639b7":"code","fb3f9fe8":"code","883e4903":"code","f657a945":"code","11e385c4":"code","9558ddd2":"code","68311a78":"code","e4c15e9b":"code","1b31a990":"code","8647299a":"code","339cf516":"code","d5209d3a":"code","6c7a3112":"markdown","55ebe8ac":"markdown","ef843117":"markdown","a3a9d8d1":"markdown","2cbb9f73":"markdown","99f2ed0f":"markdown","409ac9a5":"markdown","862f9452":"markdown","4d754d4b":"markdown","67fd9fc9":"markdown","5d770614":"markdown","0b808020":"markdown","9ff20b38":"markdown","979d488a":"markdown","c1171212":"markdown","b1c27ca1":"markdown"},"source":{"aeeb12f8":"conda install -c conda-forge librosa","a48407de":"import warnings                        # To ignore any warnings\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline\n%pylab inline\nimport os\nimport pandas as pd\nimport librosa\nimport librosa.display\nimport glob \nimport matplotlib.pyplot as plt\n%config InlineBackend.figure_format = 'retina'\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","38603c60":"import tensorflow as tf; print(\"Tensorflow version.... \",tf.__version__)\nimport keras ; print(\"Keras version... \", keras.__version__)","98e6a5c7":"INPUT_DIR = \"\/kaggle\/input\/heartbeat-sounds\"\n\nSAMPLE_RATE = 16000\n\nMAX_SOUND_CLIP_DURATION = 12","3201c51a":"!pwd\n!ls -all ..\/input","7239cee5":"set_a = pd.read_csv(INPUT_DIR+'\/set_a.csv')\nset_a.head()","eda8dc82":"set_a_timing = pd.read_csv(INPUT_DIR+'\/set_a_timing.csv')\nset_a_timing.head()","07cb0ed8":"set_b = pd.read_csv(INPUT_DIR+'\/set_b.csv')\nset_b.head()","236c1c98":"frames = [set_a, set_b]\ntrain_ab = pd.concat(frames)\ntrain_ab","de49f842":"nb_classes = train_ab.label.unique()\n\nprint(\"number of training examples : \", train_ab.shape[0],\" Number of classes : \",len(nb_classes))\nprint(nb_classes)","9ae446bb":"train_ab[train_ab.label == 'nan'].nunique()","bf2a3cf2":"train_ab.label.value_counts()","de5d8067":"train_ab.groupby(['label','dataset']).count()","00e4bace":"category_group = train_ab.groupby(['label','dataset']).count()\nplot = category_group.unstack().reindex(category_group.unstack().sum(axis=1).sort_values().index)\\\n        .plot(kind='bar', stacked=False, title=\"Number of Audio Samples per Category\", figsize=(16,5))\n\nplot.set_xlabel('class')\nplot.set_ylabel('samples count')\n","d604fe97":"print(\"minimum samples per class :\", min(train_ab.label.value_counts()))\nprint(\"maximum samples per class :\",max(train_ab.label.value_counts()))","7c1a8435":"normal_file = INPUT_DIR+'\/set_a\/normal__201105021654.wav'","743dda96":"import IPython.display as ipd\nipd.Audio(normal_file)","8976bc90":"from scipy.io import wavfile\nrate, signal = wavfile.read(normal_file)\nprint(\"Sampling Rate. \",rate)\nprint(\"Total samples  \",signal.shape[0])\nprint(\"Duration in seconds. \",signal.shape[0]\/rate)\nprint(signal)","5d76a6e6":"plt.figure(figsize=(16,5))\nplt.plot(signal, '-',)\nplt.title('Normal')","8ca1a15c":"signal1, rate1 = librosa.load(normal_file, duration=5)   #default sampling rate is 22 HZ\ndur=librosa.get_duration(signal1)\nprint(\"Duration in seconds. \",librosa.get_duration(signal1))\nprint(signal1.shape, rate1)","a8670827":"plt.figure(figsize=(16,3))\nlibrosa.display.waveplot(signal1)\nplt.title(\"Normal\")","f78e64fa":"murmur_file = INPUT_DIR+'\/set_a\/murmur__201108222236.wav'\nipd.Audio(murmur_file)","1dc01ee0":"signal2, rate2 = librosa.load(murmur_file, duration=5)   #default sampling rate is 22 HZ\ndur=librosa.get_duration(signal2)\nprint(\"Duration in seconds. \",librosa.get_duration(signal2))\nprint(signal2.shape, rate2)","5ae4522f":"plt.figure(figsize=(16,3))\nlibrosa.display.waveplot(signal2)\nplt.title(\"murmur\")","0e2b5ae7":"extrasystole_file = INPUT_DIR+'\/set_b\/extrastole__198_1308141739338_B1.wav'\n","cfcf4ca0":"ipd.Audio(extrasystole_file)","dd6f1e55":"signal3, rate3 = librosa.load(extrasystole_file, duration=5)   #default sampling rate is 22 HZ\ndur=librosa.get_duration(signal3)\nprint(\"Duration in seconds. \",librosa.get_duration(signal3))\nprint(signal3.shape, rate3)","62830971":"plt.figure(figsize=(16,5))\nlibrosa.display.waveplot(signal3)\nplt.title('Extrasystole')","06c8eaa8":"artifact_file = INPUT_DIR+'\/set_a\/artifact__201012172012.wav'\nipd.Audio(artifact_file)","03fcd67d":"signal4, rate4 = librosa.load(artifact_file, duration=5)   #default sampling rate is 22 HZ\ndur=librosa.get_duration(signal4)\nprint(\"Duration in seconds. \",librosa.get_duration(signal4))\nprint(signal4.shape, rate4)","e50e4936":"plt.figure(figsize=(16,3))\nlibrosa.display.waveplot(signal4)\nplt.title(\"Artifact\")","88baaece":"extrahls_file = INPUT_DIR+'\/set_a\/extrahls__201101070953.wav'\nipd.Audio(extrahls_file)","0f7721e2":"signal5, rate5 = librosa.load(extrahls_file, duration=5)\nprint(\"Duration \",librosa.get_duration(signal5))\nprint(signal5.shape, rate5)","7248d7b0":"plt.figure(figsize=(16,3))\nlibrosa.display.waveplot(signal5, sr = rate5)\nplt.title(\"Extra Heart Sound\")","bde93ed2":"normal_file\nsignal, rate = librosa.load(normal_file)\nmfcc = librosa.feature.mfcc(y=signal, sr = rate)\nprint(mfcc.shape)","21d0623b":"S = librosa.feature.melspectrogram(y=signal, sr=rate, n_mels=128,fmax=8000)\nlog_S=librosa.feature.mfcc(S=librosa.power_to_db(S))\nprint (log_S)","10013066":"mfcc = librosa.feature.mfcc(y = signal, sr = rate, n_mfcc = 40)","9be53074":"print(mfcc.reshape([-1,1]).shape)","3001aa63":"40*345","19f2debd":"plt.figure(figsize(12,3))\nlibrosa.display.specshow(mfcc, x_axis='time')\nplt.colorbar()\nplt.title(\"MFCC\")\nplt.tight_layout()","7900b1b0":"m_slaney = librosa.feature.mfcc(y=signal, sr=rate, dct_type=2)\nplt.figure(figsize=(12,3))\n\nm_htk = librosa.feature.mfcc(y=signal, sr=rate, dct_type=3)\nplt.subplot(3,1,1)\nlibrosa.display.specshow(m_slaney, x_axis='time')\nplt.title(\"dct_type = 2\")\nplt.colorbar()\nplt.subplot(3,1,3)\nlibrosa.display.specshow(m_htk, x_axis='time')\nplt.title(\"dct_type = 3\")\nplt.colorbar()","2449f557":"train_ab","5aebc189":"print(\"Number of training examples : \",train_ab.shape[0], \" Number of classes : \", train_ab.label.nunique())","2e0174d4":"def audio_norm(data):\n    max_data = max(data)\n    min_data = min(data)\n    data = (data-min_data)\/(max_data-min_data+0.0001)\n    return data-0.5","16426057":"def load_file_data (folder_name,file_names, duration=12, sr=16000):\n    input_length=sr*duration\n    # function to load files and extract features\n    # file_names = glob.glob(os.path.join(folder, '*.wav'))\n    data = []\n    for file_name in file_names:\n        try:\n            sound_file=folder_name+file_name\n            print (\"load file \",sound_file)\n            # use kaiser_fast technique for faster extraction\n            X, sr = librosa.load( sound_file, sr=sr, duration=duration,res_type='kaiser_fast') \n            dur = librosa.get_duration(y=X, sr=sr)\n            # pad audio file same duration\n            if (round(dur) < duration):\n                print (\"fixing audio lenght :\", file_name)\n                y = librosa.util.fix_length(X, input_length)                \n            #normalized raw audio \n            X = audio_norm(X)            \n            # extract normalized mfcc feature from data\n            mfccs = np.mean(librosa.feature.mfcc(y=X, sr=sr, n_mfcc=40).T,axis=0)             \n        except Exception as e:\n            print(\"Error encountered while parsing file: \", file)        \n        feature = np.array(mfccs).reshape([-1,1])\n        data.append(feature)\n    return data","b3f639b7":"from sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\nCLASSES = ['artifact','murmur','normal']\nNB_CLASSES = len(CLASSES)\n\nlabel_to_int = {k:v for v,k in enumerate(CLASSES)}\nprint(label_to_int)\nprint(\" \")\n\nint_to_label = {v:k for v,k in enumerate(CLASSES)}\nprint(int_to_label)","fb3f9fe8":"import os, fnmatch\n\nA_folder = INPUT_DIR+'\/set_a\/'\n\nA_artifact_files = fnmatch.filter(os.listdir(INPUT_DIR+'\/set_a\/'),'artifact*.wav')\nA_artifact_sounds = load_file_data(folder_name=A_folder, file_names=A_artifact_files, duration=MAX_SOUND_CLIP_DURATION)\nA_artifact_labels = [0 for items in A_artifact_files]\n\nA_normal_files = fnmatch.filter(os.listdir(INPUT_DIR+'\/set_a\/'), 'normal*.wav')\nA_normal_sounds = load_file_data(folder_name = A_folder, file_names = A_normal_files, duration=MAX_SOUND_CLIP_DURATION)\nA_normal_labels = [2 for items in A_normal_files]\n\nA_extrahls_files = fnmatch.filter(os.listdir(INPUT_DIR+'\/set_a\/'), 'extrahls*.wav')\nA_extrahls_sounds = load_file_data(folder_name=A_folder, file_names=A_extrahls_files, duration=MAX_SOUND_CLIP_DURATION)\nA_extrahls_labels = [1 for items in A_extrahls_files]\n\nA_murmur_files= fnmatch.filter(os.listdir(INPUT_DIR+'\/set_a\/'), 'murmur*.wav')\nA_murmur_sounds = load_file_data(folder_name=A_folder, file_names=A_murmur_files, duration=MAX_SOUND_CLIP_DURATION)\nA_murmur_labels = [1 for items in A_murmur_files]\n\nA_unlabelledtest_files = fnmatch.filter(os.listdir(INPUT_DIR+'\/set_a\/'), 'Aunlabelledtest*.wav')\nA_unlabelledtest_sounds = load_file_data(folder_name=A_folder, file_names=A_unlabelledtest_files, duration=MAX_SOUND_CLIP_DURATION)\nA_unlabelledtest_labels = [-1 for items in A_unlabelledtest_files]\n\nprint(\"loaded dataset-a\")","883e4903":"\n\nB_folder = INPUT_DIR+'\/set_b\/'\n\n\nB_normal_files = fnmatch.filter(os.listdir(INPUT_DIR+'\/set_b\/'), 'normal*.wav')\nB_normal_sounds = load_file_data(folder_name = B_folder, file_names = B_normal_files, duration=MAX_SOUND_CLIP_DURATION)\nB_normal_labels = [2 for items in B_normal_files]\n\nB_extrastole_files = fnmatch.filter(os.listdir(INPUT_DIR+'\/set_b\/'), 'extrastole*.wav')\nB_extrastole_sounds = load_file_data(folder_name=B_folder, file_names=B_extrastole_files, duration=MAX_SOUND_CLIP_DURATION)\nB_extrastole_labels = [1 for items in B_extrastole_files]\n\nB_murmur_files= fnmatch.filter(os.listdir(INPUT_DIR+'\/set_b\/'), 'murmur*.wav')\nB_murmur_sounds = load_file_data(folder_name=B_folder, file_names=B_murmur_files, duration=MAX_SOUND_CLIP_DURATION)\nB_murmur_labels = [1 for items in B_murmur_files]\n\nB_unlabelledtest_files = fnmatch.filter(os.listdir(INPUT_DIR+'\/set_b\/'), 'Bunlabelledtest*.wav')\nB_unlabelledtest_sounds = load_file_data(folder_name=B_folder, file_names= B_unlabelledtest_files, duration=MAX_SOUND_CLIP_DURATION)\nB_unlabelledtest_labels = [-1 for items in B_unlabelledtest_files]\n\nprint(\"loaded dataset-b\")","f657a945":"x_data = np.concatenate((A_artifact_sounds, A_normal_sounds, A_extrahls_sounds, A_murmur_sounds,\n                        B_normal_sounds,B_murmur_sounds, B_extrastole_sounds))\ny_data = np.concatenate((A_artifact_labels, A_normal_labels, A_extrahls_labels, A_murmur_labels,\n                        B_normal_labels,B_murmur_labels, B_extrastole_labels))\n\nx_unlabelled = np.concatenate((A_unlabelledtest_sounds, B_unlabelledtest_sounds))\ny_unlabelled = np.concatenate((A_unlabelledtest_labels, B_unlabelledtest_labels))\n\nprint(\"Combined data size : \",len(x_data), \" and unlabelled \",len(x_unlabelled))","11e385c4":"seed = 1000\n\nx_train, x_val, y_train, y_val = train_test_split(x_data, y_data, train_size=0.8,random_state=seed, shuffle=True)\n# x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, train_size=0.9, random_state = seed, shuffle=True)\n\ny_train = np.array(keras.utils.to_categorical(y_train, len(CLASSES)))\n# y_test = np.array(keras.utils.to_categorical(y_test, len(CLASSES)))\ny_val = np.array(keras.utils.to_categorical(y_val, len(CLASSES)))\ny_unlabelled = np.array(keras.utils.to_categorical(y_unlabelled, len(CLASSES)))","9558ddd2":"y_unlabelled.shape","68311a78":"print (\"label shape: \", y_data.shape)\nprint (\"data size of the array: : %s\" % y_data.size)\nprint (\"length of one array element in bytes: \", y_data.itemsize)\nprint (\"total bytes consumed by the elements of the array: \", y_data.nbytes)\nprint (y_data[1])\nprint (\"\")\nprint (\"audio data shape: \", x_data.shape)\nprint (\"data size of the array: : %s\" % x_data.size)\nprint (\"length of one array element in bytes: \", x_data.itemsize)\nprint (\"total bytes consumed by the elements of the array: \", x_data.nbytes)\n#print (x_data[1])\nprint (\"\")\nprint (\"training data shape: \", x_train.shape)\nprint (\"training label shape: \", y_train.shape)\nprint (\"\")\nprint (\"validation data shape: \", x_val.shape)\nprint (\"validation label shape: \", y_val.shape)\n# print (\"\")\n# print (\"test data shape: \", x_test.shape)\n# print (\"test label shape: \", y_test.shape)\nprint(\"\")\nprint (\"unlabelled data shape: \", x_unlabelled.shape)\nprint (\"unlabelled label shape: \", y_unlabelled.shape)","e4c15e9b":"pip install livelossplot","1b31a990":"import numpy as np\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten, LSTM\nfrom keras.optimizers import Adam\nfrom keras.callbacks import EarlyStopping,ReduceLROnPlateau,ModelCheckpoint,TensorBoard,ProgbarLogger\nfrom keras.utils import np_utils\nfrom sklearn import metrics \nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.preprocessing import LabelEncoder\nimport itertools\nfrom keras.layers import TimeDistributed, SpatialDropout1D, Bidirectional\n\nfrom livelossplot import PlotLossesKeras","8647299a":"model = Sequential()\nmodel.add(Bidirectional(LSTM(units=64, dropout=0.2, return_sequences=True), input_shape=(40,1)))\nmodel.add(Bidirectional(LSTM(units=32, dropout=0.2, return_sequences=False)))\nmodel.add(Dense(len(CLASSES), activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='Adam', \n             metrics=['acc'])\nmodel.summary()","339cf516":"max_patience = 12\nmax_epochs = 100\nmax_batch = 32\n\nearly_stopping = EarlyStopping(monitor='val_accuracy', patience = max_patience, verbose=0, mode='max', restore_best_weights=False)\n\ncallbacks=[ReduceLROnPlateau(monitor='val_loss', factor=0.2,\n                              patience=5, min_lr=0.00001),\n          early_stopping,\n         PlotLossesKeras()]\n\nprint(\"training started..\")\nhistory = model.fit(x_train, y_train,\n                   batch_size=max_batch,\n                   epochs=max_epochs,\n                   verbose=1,\n                   validation_data=(x_val, y_val),\n                   callbacks=callbacks)","d5209d3a":"score = model.evaluate(x_train, y_train, verbose=0) \nprint (\"model train data score       : \",round(score[1]*100) , \"%\")\n\n# score = model.evaluate(x_test, y_test, verbose=0) \n# print (\"model test{split} data score : \",round(score[1]*100) , \"%\")\n\nscore = model.evaluate(x_val, y_val, verbose=0) \nprint (\"model validation data score  : \", round(score[1]*100), \"%\")\n\nscore = model.evaluate(x_unlabelled, y_unlabelled, verbose=0) \nprint (\"model unlabeled data score   : \", round(score[1]*100), \"%\")","6c7a3112":"**c) Extrasystole**","55ebe8ac":"# Visualizing MFCC series \n\nmel frequency cepstral coefficients (mfcc) which is by far the best way to numerically represent audio signal for ML related tasks","ef843117":"*nan labeled examples are \"unlabeled\" test files*","a3a9d8d1":"Loading dataset a","2cbb9f73":"**e) Extra Heart Sound**","99f2ed0f":"**LOADING DATA**","409ac9a5":"**a) NORMAL**","862f9452":"**d) Artifact**","4d754d4b":"Model Evaluation","67fd9fc9":"**b) Murmur**","5d770614":"Visualize data distribution by class","0b808020":"**BUILDING MODEL**","9ff20b38":"# *Lets visit each class of labels one by one*","979d488a":"Combining set-a   set-b","c1171212":"Loading Dataset-b","b1c27ca1":"Using **LIBROSA**"}}