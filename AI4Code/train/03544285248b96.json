{"cell_type":{"583049d0":"code","66107181":"code","77585565":"code","f77f70bc":"code","b7bdcb73":"code","4f6781a3":"code","a5376b33":"code","1fecee36":"code","7204d124":"code","6d96bf08":"code","78b63cab":"code","5166944b":"code","189480b8":"code","245e4132":"code","d37dd6e5":"code","8a73acc3":"code","0b9898ae":"code","fef527ad":"code","095128e2":"code","ac96102c":"code","4108a0cf":"code","27dafa3b":"code","1335b849":"code","79df75a1":"code","96851086":"code","ec192e5a":"code","75430458":"code","455fc614":"code","8d376e55":"code","a1de1dd4":"code","93611dec":"code","ac34e538":"code","f5789e86":"code","4e6f895f":"code","420f4991":"code","56caafe6":"code","cfc9b7e4":"code","e70b1f84":"code","3881b484":"code","1a0ae5a4":"code","2761c6bd":"code","81e68982":"markdown","bf80a9b2":"markdown","7b6e8ee3":"markdown","5bd95768":"markdown","7929113e":"markdown","9d64c0ac":"markdown","67c2b88d":"markdown","2569e00e":"markdown","6911cb06":"markdown"},"source":{"583049d0":"import matplotlib.pyplot as plt\nimport pandas as pd \nimport numpy as np\nimport string\nimport nltk\nimport nltk.corpus\nimport sklearn\n\nfrom matplotlib import rcParams\nfrom nltk.stem import WordNetLemmatizer \nfrom nltk.corpus import stopwords \nfrom nltk import NaiveBayesClassifier\nfrom nltk.corpus import wordnet \nfrom nltk.tokenize import sent_tokenize, word_tokenize\nfrom nltk import pos_tag\nfrom wordcloud import WordCloud\nfrom sklearn.ensemble import RandomForestClassifier \nfrom nltk.classify.scikitlearn import SklearnClassifier\n\n","66107181":"data_path = '..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv'\ndf=pd.read_csv(data_path)\ndf.head()","77585565":"# How many columns are there \ndf.columns","f77f70bc":"# check the shape of the dataset\ndf.shape","b7bdcb73":"# Count the number of unique values in each column\ndf.nunique()","4f6781a3":"# Count the number of nulls in each column\ndf.isna().sum()","a5376b33":"# drop all non values\ndf.dropna(inplace=True)\n","1fecee36":"# reseat the index after droping some rows \ndf.reset_index(drop=True, inplace=True)\ndf.head()","7204d124":"# Check for the missing values after droping the null values \ndf.isnull().sum()\n","6d96bf08":"# drop unnecessary culomns \ndf.drop([\"Unnamed: 0\", \"Title\", 'Clothing ID'], axis=1, inplace=True)\n\n","78b63cab":"df.head()","5166944b":"# to remove spaces in columns and replace them with underscore \ndf.columns= df.columns.str.replace(\" \", \"_\")","189480b8":"# Create reviews Tuples  to store the words along the categorys  \nreviews = []\n# go through Recommended IND column and get the category and the index \nfor (index , category) in enumerate(df.Recommended_IND):\n    reviews.append((df.Review_Text[index],category)) # Store the review for spacific index with catogory inside texts array\n# Print first 4\nreviews[0:4]","245e4132":"# create lemmatizer \nlemmatizer = WordNetLemmatizer()","d37dd6e5":"# Create a list of stopwords \nstops= stopwords.words(\"english\")\npunctuations=list(string.punctuation)\nstops=stops+punctuations\nstops, string.punctuation","8a73acc3":"# business stopwords\nbusiness_stopwords= [\"i'm\",\"would\", \"look\", \"ordered\", \"wear\", \"fit\", \"one\", \"fits\",\"bought\", \"looks\", \"also\", \"got\", \"think\", \"even\",\n                     \"tried\", \"get\", \"could\", \"made\",\"way\",\"still\", \"runs\",\"true\" ,\"right\", \"see\",\"online\",\"wearing\", \"however\", \"design\",\"purchased\",\"feel\",\"go\",\n                     \"enough\",\"model\",\"though\",\"price\",\"looked\",\"person\",\"better\",\"first\",\"going\",\"try\", \"body\" \"bottom\",\"time\",\"many\",\"looking\",\"around\",\"thought\",\n                     \"make\",\"wanted\",\"saw\",\"makes\",\"went\",\"find\",\"found\",\"buy\",\"nan\",\"i've\", \"since\",\"seems\",\"ok\", \"girl\", \"woman\"]\nstops= stops+business_stopwords\nstops\n\n","0b9898ae":"# stopwords after updated with business_stopwords\nlen(stops)","fef527ad":"# function to get the simpler virsion of pos tag  to use it in lemmitazation \ndef get_simple_pos(tag):\n    if tag.startswith('N') or tag.startswith('J'):\n        return wordnet.NOUN\n    elif tag.startswith('V'):\n        return wordnet.VERB\n    elif tag.startswith('R'):\n        return wordnet.ADV\n    else:\n        return wordnet.NOUN #default case","095128e2":"# function to return Limmitzed words and cleaned from stop words  \ndef clean_review(words):\n  output_words= []\n  words_tokens= nltk.word_tokenize(words)  \n  for word in words_tokens :\n\n    if word.lower() not in stops:\n      pos = pos_tag([word]) # get the part of speech of each word \n    \n      clean_word=(lemmatizer.lemmatize(word.lower(), pos=get_simple_pos(tag)) for word, tag in pos)\n      output_words.append(', '.join(map(str,clean_word )))\n  return output_words","ac96102c":"#Test our function \nclean_review(\"My cats are running away from my arms\")","4108a0cf":"# clean all reviews \ncleaned_reviews= [(clean_review(text),category )for text,category  in reviews]\n","27dafa3b":"len(cleaned_reviews)","1335b849":"#check first 5 reviews \ncleaned_reviews[0:5]","79df75a1":"#.75% traning = 14746 and 25% testing = 19662-14746 =4916 \ntraning_words=cleaned_reviews[0:14746]\ntesting_words=cleaned_reviews[14746:]","96851086":"print(f\"Training Data = {len(traning_words)}\")\nprint(f\"Testing Data = {len(testing_words)}\")\n","ec192e5a":"# array contaning all words \nwords_list=[]\nfor word in traning_words:\n        words_list+=word[0] # 0 index to get only the words ","75430458":"# Total words in traning data \nlen(words_list)","455fc614":"#frequency distribution for all words \nfreq= nltk.FreqDist(words_list)\n# The .most_common() method lists the words which occur most frequently in the data\ncommon=freq.most_common()\n# features are an array of only the top words in word list without The number of words \nfeatures= [i[0]for i in common]","8d376e55":"print(len(common))\nprint(len(features))","a1de1dd4":"# Most common 5 words \ncommon[0:5]","93611dec":"# List of 5 features \nfeatures[0:5]","ac34e538":"# Visualizing the highest repeating words (features)\n\n# wordcload is techniqe use to show which words are the most frequent \nwordCloud = WordCloud(background_color=\"white\", max_words =3000).generate(str(features))\n\nrcParams[\"figure.figsize\"]= 10,20\nplt.imshow(wordCloud)\nplt.axis(\"off\")\nplt.show ","f5789e86":"# function to return a set of the features with true or false \ndef get_dict_for_feature(words):\n  current_features={}\n  words_set= set(words)\n  for word in features:\n    current_features[word] = word in words_set  # if word comes in words set it will return True otherwise False \n  return current_features","4e6f895f":"featuers_dic= get_dict_for_feature(traning_words[0][0])","420f4991":"# Dictionary containing all words with True classification if the word is exist in each review otherwise false  \nfeatuers_dic                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                     ","56caafe6":"# create dic for each review wich has feature with vlue and the category\ntraning_words= [( get_dict_for_feature(words),category ) for words , category in traning_words]\ntesting_words = [( get_dict_for_feature(words),category ) for words , category in testing_words]","cfc9b7e4":"traning_words[1]","e70b1f84":"# to the classifier we need to use NaiveBayesClassifier and pass the training words to it \nNB_classifier= NaiveBayesClassifier.train(traning_words)\nprint(\"classifier accuracy percent:\",(nltk.classify.accuracy(NB_classifier, traning_words))*100)","3881b484":"NB_classifier.show_most_informative_features(10)","1a0ae5a4":"# we can check how the model performs on random reviews \n\n\nreview_1 = \"Super fast and responsive with any issues. Different style print option was great! Easy to order and a pleasure to have done business with. Looking forward to ordering more items! Thank you\"\nreview_2= \"I am thrilled with the quality & fit of the t-shirts& they were very nicely packaged too. I will definitely be re-ordering from you in the future. - Kristina - Spain\"\nreview_3=\"Missing refunds. Returned parcel and got a date that I would get the refund by, five days after this date no refund. Contacted customer support and they advised I have to wait another 14 days. The service was very unhelpful and rude at times.\"\nreview_4=\"not the best service this time. I paid for next day delivery on Weds for items to arrive on the Thurs but no luck. Took for ever to try and find someone to speak to about this but who ever i was i did get on live chat was helpful. I left home yesterday to attend a wedding that i wanted the dress for so for it to arrive at 7pm this evening is no good at all.I look forward to your reply explaining why this happened and what can be done.\"\nreview_5=\"Had email saying parcel has been delivered (5 days late). However, no sign of parcel at property, with neighbour or safe place. Very disappointing as usually a good service.\"\n\nreviews = [review_1,review_2,review_3,review_4,review_5]\n\n\ndef test_custom_review(reviews_list, classifier):\n    \n    for idx,review in enumerate(reviews_list) : \n        custom_tokens = clean_review(review)\n        print(f\"The clean review is : \"  , str(custom_tokens).replace('[','').replace(']',''))\n        classifiers=classifier.classify(dict([token, True] for token in custom_tokens))\n        if (classifiers == 1):\n            pred = \"Positive\"\n        else:\n            pred = \"Negative\"\n        print(f\"Review number {idx +1 }  seems to be {pred} \\n\")\n","2761c6bd":"test_custom_review(reviews,NB_classifier)","81e68982":"**import libraries** \n","bf80a9b2":"In the given dataset we need to use two coulmns to generate text . the \"Review Text\" to get the  text and  \"Recommended IND\" to classify the review either positive or negative ","7b6e8ee3":"## **NaiveBayes classifier**\n\ncreate navie bayes classifier within nltk  Classifier","5bd95768":"**Get the data**","7929113e":"**STOPWORDS**\n* We need to clean the reviews from stopwords `","9d64c0ac":"#  **The aim of the project is to predict the sentiment of given women's clothing reviews in Review Text column , And predict if the review is positive or negative.**","67c2b88d":"**Lemmatization**","2569e00e":"**Split the data**\n*  75% for traning \n*  25% for testing ","6911cb06":"**Part-of-Speech Tagging**"}}