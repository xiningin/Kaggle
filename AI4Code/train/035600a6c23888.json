{"cell_type":{"a4a98355":"code","6a680aa0":"code","c0142f93":"code","97f61f27":"code","6488d2df":"code","3a764f73":"code","f99f0430":"code","6022ba17":"code","f6bcaf42":"code","6f81f1d4":"code","d2799bd1":"code","1027d77f":"code","2c3ffd1a":"code","745cf563":"code","277caa46":"code","d0dc700c":"code","a5ed87e7":"code","457ea896":"code","d09f07c9":"code","dc6cbe4c":"code","de03ce8f":"code","07091951":"code","92a91b51":"code","ee94bf11":"code","0e6508e5":"code","bfe62bef":"code","a47b2eb3":"code","be053ddc":"code","98372258":"code","455f5ddf":"code","da0cd5cb":"code","634f9543":"code","31e7e5b5":"code","8467540c":"code","f756f4bb":"code","feab7d05":"code","412c94bb":"code","2fecf811":"code","5b3df0c8":"code","731a1d19":"code","858c8d59":"code","7c251584":"code","32a220b5":"code","8f76ff4c":"code","33e427de":"code","1a75a710":"code","bf42ddd5":"code","0ce75fd4":"code","22d86864":"code","54c7ec31":"code","f9377b0b":"code","67295837":"code","31de789f":"code","ab789ae0":"code","5489516e":"code","1493c99b":"code","93331dfd":"markdown","570af662":"markdown","d3588b89":"markdown","212cda63":"markdown","42724fb7":"markdown","7f8b8551":"markdown","e8c96af9":"markdown","81cdd0d1":"markdown","ac18638c":"markdown","99d6aad6":"markdown","cdc26cdc":"markdown","4445955c":"markdown","d0f53378":"markdown","fe6cb848":"markdown","302b7f1d":"markdown","9e6c54f0":"markdown","9922cfbe":"markdown","8919c9f8":"markdown","a0e30ccd":"markdown"},"source":{"a4a98355":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","6a680aa0":"train_set = pd.read_csv('..\/input\/train.csv')\ntest_set = pd.read_csv('..\/input\/test.csv')\ntrain_set.head(5)","c0142f93":"train_set.shape","97f61f27":"train_set.info()","6488d2df":"test_set.head(5)","3a764f73":"test_set.shape","f99f0430":"test_set.info()","6022ba17":"train_set.head(5)","f6bcaf42":"train_test_dataset = [train_set, test_set]","6f81f1d4":"for dataset in train_test_dataset:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","d2799bd1":"train_set['Title'].value_counts()","1027d77f":"test_set['Title'].value_counts()","2c3ffd1a":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 4, \"Rev\": 4, \"Col\": 4, \"Major\": 4, \"Mlle\": 4,\"Countess\": 4,\n                 \"Ms\": 4, \"Lady\": 4, \"Jonkheer\": 4, \"Don\": 4, \"Dona\" : 4, \"Mme\": 4,\"Capt\": 4,\"Sir\": 4 }\nfor dataset in train_test_dataset:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","745cf563":"train_set.head(5)","277caa46":"test_set.head(5)","d0dc700c":"train_set.drop('Name', axis = 1, inplace = True)\ntest_set.drop('Name', axis = 1, inplace = True)","a5ed87e7":"train_set.head(5)","457ea896":"test_set.head(5)","d09f07c9":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_dataset:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","dc6cbe4c":"train_set.head(5)","de03ce8f":"test_set.head(5)","07091951":"train_set['Age'].fillna(train_set.groupby(\"Title\")['Age'].transform(\"median\"), inplace = True)\ntest_set['Age'].fillna(test_set.groupby(\"Title\")['Age'].transform(\"median\"), inplace = True)","92a91b51":"train_set.head(20)","ee94bf11":"for dataset in train_test_dataset:\n    dataset.loc[ dataset['Age'] <= 12, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 12) & (dataset['Age'] <= 20), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 20) & (dataset['Age'] <= 35), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 35) & (dataset['Age'] <= 50), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 60, 'Age'] = 4","0e6508e5":"train_set.head(5)","bfe62bef":"Pclass1 = train_set[train_set['Pclass']==1]['Embarked'].value_counts()\nPclass1","a47b2eb3":"Pclass2 = train_set[train_set['Pclass']==2]['Embarked'].value_counts()\nPclass2","be053ddc":"Pclass3 = train_set[train_set['Pclass']==3]['Embarked'].value_counts()\nPclass3","98372258":"for dataset in train_test_dataset:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","455f5ddf":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_dataset:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","da0cd5cb":"train_set.head(5)","634f9543":"train_set[\"Family\"] = train_set[\"SibSp\"] + train_set[\"Parch\"] + 1\ntest_set[\"Family\"] = test_set[\"SibSp\"] + test_set[\"Parch\"] + 1","31e7e5b5":"train_set.drop('Parch', axis = 1, inplace = True)\ntest_set.drop('Parch', axis = 1, inplace = True)\ntrain_set.drop('SibSp', axis = 1, inplace = True)\ntest_set.drop('SibSp', axis = 1, inplace = True)","8467540c":"train_set.head(10)","f756f4bb":"train_set['Family'].value_counts()","feab7d05":"test_set['Family'].value_counts()","412c94bb":"family_mapping = {1: 0, 2: 0.2, 3: 0.4, 4: 0.6, 5: 0.8, 6: 1, 7: 1.2, 8: 1.4, 9: 1.6, 10: 1.8, 11: 2}\nfor dataset in train_test_dataset:\n    dataset['Family'] = dataset['Family'].map(family_mapping)","2fecf811":"train_set.head(5)","5b3df0c8":"train_set[\"Fare\"].fillna(train_set.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest_set[\"Fare\"].fillna(test_set.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)","731a1d19":"for dataset in train_test_dataset:\n    dataset.loc[ dataset['Fare'] <= 15, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 15) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","858c8d59":"train_set.head(5)","7c251584":"train_set['Cabin'].value_counts()","32a220b5":"Pclass1 = train_set[train_set['Pclass']==1]['Cabin'].value_counts()\nPclass1","8f76ff4c":"Pclass2 = train_set[train_set['Pclass']==2]['Cabin'].value_counts()\nPclass2","33e427de":"Pclass3 = train_set[train_set['Pclass']==3]['Cabin'].value_counts()\nPclass3","1a75a710":"for dataset in train_test_dataset:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","bf42ddd5":"cabin_mapping = {\"A\": 0, \"B\": 0.2, \"C\": 0.4, \"D\": 0.6, \"E\": 0.8, \"F\": 1, \"G\": 1.2, \"T\": 1.4}\nfor dataset in train_test_dataset:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)\n\ntrain_set","0ce75fd4":"train_set[\"Cabin\"].fillna(train_set.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest_set[\"Cabin\"].fillna(test_set.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","22d86864":"train_set.drop('Ticket', axis = 1, inplace = True)\ntest_set.drop('Ticket', axis = 1, inplace = True)\ntrain_set.drop('PassengerId', axis = 1, inplace = True)","54c7ec31":"train_data = train_set.drop('Survived', axis=1)\ntarget = train_set['Survived']\n\ntrain_data.shape, target.shape","f9377b0b":"train_data","67295837":"train_data.info()","31de789f":"from sklearn.svm import SVC","ab789ae0":"clfr = SVC()\nclfr.fit(train_data, target)\n\ntest_data = test_set.drop(\"PassengerId\", axis=1).copy()\nprediction = clfr.predict(test_data)","5489516e":"submission = pd.DataFrame({\n        \"PassengerId\": test_set[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","1493c99b":"submission = pd.read_csv('submission.csv')\nsubmission.head()","93331dfd":"Let's combine both the datasets as we are gonna perform all the operations on both the sets.","570af662":"**Map the title**\nMr : 0 Miss : 1 Mrs: 2 Master: 3 Others: 4","d3588b89":"**Family**\nCalculate the family size as the possibility of a person to survive the tragedy is more if he has a family on board.","212cda63":"what we can notice from this is that First class cabins mostly start with A, B , C and D Second class cabins are D, E, F and third class cabins are E, F and G Now we will map the Cabin and then will fill up the blanks with the median","42724fb7":"**Observations:**\n1. Number of rows in the train dataset = 891 \n2. Number of columns in the train dataset = 12 \n3. Some data missing in some columns like Age, Cabin, and Embarked\n4. Number of rows in the test dataset = 418 \n5. Number of columns in the test dataset = 11\n6. The missing column in the test dataset is the Survived column whose values of course we need to find out. \n7. Some values are missing in other columns like Age, Fare, Cabin and Embarked","7f8b8551":"** Feature Engineering\u00b6**\nFeature vectors are used to represent numeric or symbolic characteristics (called features, features are basically the measurable properties).\n\nFeature engineering is the process of using domain knowledge of the data to create feature vectors that make machine learning algorithms work.\n\nWhat are the things that we need to do here?\n\nGuess the missing values first\nThen map everything into possible numeric values\n\nLet's see how we can do it.","e8c96af9":"**Do something about the cabin**","81cdd0d1":"**Data Modelling**\nHere comes the data modelling part. We will be using SVC classifier for this prediction.","ac18638c":"**LOAD THE DATA FIRST**","99d6aad6":"**Map the Age**\u00b6\nkids:0 teenagers: 1 Adults: 2 Middle-Aged: 3 Old: 4","cdc26cdc":"the minimum family size is 1 and the maximum family size is 11","4445955c":"we can drop the name from both the datasets as it's not needed now","d0f53378":"**Map the fare**","fe6cb848":"The only value that is useful in the Name of a person in this case is the title of that person. So we will extract the title and map it accordingly","302b7f1d":"**Do something about the age**\u00b6\nFill up the missing values and then map them.\nLet's fill up the missing values with the median of passengers' ages by grouping according to their title.","9e6c54f0":"Ticket isn't that much needed here, so we'll just drop that column","9922cfbe":"**Map the sex**","8919c9f8":"Let's observe the training and test dataset first.","a0e30ccd":"**Map the embarked after filling up the missing values**"}}