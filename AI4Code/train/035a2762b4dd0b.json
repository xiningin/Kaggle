{"cell_type":{"8b9ff040":"code","ed24bcb9":"code","36d287c0":"code","93aab986":"code","77ba631c":"code","6f18dbf7":"code","b7b9fa15":"code","6fdb3ba5":"code","6eff2817":"code","af373800":"code","f40f2845":"code","75c5a44c":"code","f224be14":"code","07984f3c":"code","f06535f4":"code","11abeb8b":"code","f5576c43":"code","e229e248":"code","d8e24a9a":"code","c068f2c5":"code","6c435721":"code","b3bb83af":"code","fb3246fe":"code","77137162":"code","2a732544":"code","11620d7e":"code","b524ae93":"code","1f027ed0":"code","0a10c9da":"code","c1e214b9":"code","3abeeb84":"code","967ac3f4":"code","50ee9cae":"code","b7b38f0a":"code","8540e185":"code","94d2613a":"code","37e057bc":"code","e4d3464f":"code","2435e5a0":"code","909c8d53":"code","aed95710":"code","2f5e1a9c":"code","47482c61":"code","e25decb3":"code","b73ea63a":"code","9e508d15":"code","a4f1db0d":"code","ee33cf4f":"code","95962a69":"code","6b6b2fc4":"code","0b47c373":"code","556d75e6":"code","c6c15064":"code","e9cb9b3c":"code","f4926f85":"code","fe61bb47":"code","bb24978e":"code","f03678a5":"code","52fe718a":"markdown","bc5d421d":"markdown","539bf972":"markdown","be022abe":"markdown","4e3f15a8":"markdown","f052bdea":"markdown","bd9415e2":"markdown","b177c011":"markdown","36a40bf5":"markdown","78cf1a91":"markdown","552acddc":"markdown","efe4a6e8":"markdown","4a28cef7":"markdown","5ac6c547":"markdown","c9714032":"markdown","95f525f1":"markdown","da1921c3":"markdown","fde34917":"markdown","efb8e67d":"markdown"},"source":{"8b9ff040":"!pip install seedir","ed24bcb9":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom tqdm.notebook import tqdm\nimport seaborn as sns\nimport warnings\nimport seedir as sd\nwarnings.filterwarnings(\"ignore\")\n%matplotlib inline","36d287c0":"data_dir = '\/kaggle\/input\/mlb-player-digital-engagement-forecasting'\nsd.seedir(data_dir, style='emoji')","93aab986":"train = pd.read_csv(f'{data_dir}\/train.csv')\ntrain.head()","77ba631c":"train[train['date'] == 20180101]['nextDayPlayerEngagement'][0][:500]","6f18dbf7":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int64)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float32)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float64)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df\n\nfor file in ['example_test', 'train']:\n    # drop playerTwitterFollowers, teamTwitterFollowers from example_test\n    df = pd.read_csv(f\"{data_dir}\/{file}.csv\").dropna(axis=1,how='all')\n    daily_data_nested_df_names = df.drop('date', axis = 1).columns.values.tolist()\n\n    for df_name in daily_data_nested_df_names:\n        date_nested_table = df[['date', df_name]]\n\n        date_nested_table = (date_nested_table[\n          ~pd.isna(date_nested_table[df_name])\n          ].\n          reset_index(drop = True)\n          )\n\n        daily_dfs_collection = []\n\n        for date_index, date_row in date_nested_table.iterrows():\n            daily_df = pd.read_json(date_row[df_name])\n\n            daily_df['dailyDataDate'] = date_row['date']\n\n            daily_dfs_collection = daily_dfs_collection + [daily_df]\n\n        # Concatenate all daily dfs into single df for each row\n        unnested_table = (pd.concat(daily_dfs_collection,\n          ignore_index = True).\n          # Set and reset index to move 'dailyDataDate' to front of df\n          set_index('dailyDataDate').\n          reset_index()\n          )\n        #print(f\"{file}_{df_name}.pickle\")\n        #display(unnested_table.head(3))\n        reduce_mem_usage(unnested_table).to_pickle(f\"{file}_{df_name}.pickle\")\n        #print('\\n'*2)\n\n        # Clean up tables and collection of daily data frames for this df\n        del(date_nested_table, daily_dfs_collection, unnested_table)\n\ndel train","b7b9fa15":"train_target = pd.read_pickle('train_nextDayPlayerEngagement.pickle')\ntrain_target['engagementMetricsDate'] = pd.to_datetime(train_target['engagementMetricsDate'])\ntrain_target['dailyDataDate'] = train_target['dailyDataDate'].astype(str)\ntrain_target['dailyDataDate'] = pd.to_datetime(train_target['dailyDataDate'], format=\"%Y%m%d\")\ntrain_target.head()","6fdb3ba5":"train_target.groupby('engagementMetricsDate').count()['playerId'].plot(figsize=(10,5))\nplt.title('Number of players per date')\nplt.show()","6eff2817":"fig, axes = plt.subplots(4, 1, figsize=(12,15))\n\nfor i, ax in enumerate(axes):\n    train_target.groupby('engagementMetricsDate').mean()[f'target{i+1}'].plot(ax=ax)\n    ax.set_title(f'mean target{i+1}')","af373800":"players = pd.read_csv(f'{data_dir}\/players.csv')\nplayers.head()","f40f2845":"players.groupby('birthCountry').count()['playerId'].sort_values().plot.barh(figsize=(5, 8))\nplt.title('Player birth country')","75c5a44c":"df_temp = players.groupby('primaryPositionName').count()['playerId'].sort_values()\n\ny_pos = np.arange(len(df_temp))\n\nplt.barh(y_pos, df_temp.values, align='center')\nplt.yticks(y_pos, [f'{x}_{y}' for x, y in zip(df_temp.index, df_temp.values)])\nplt.title('Player primary position name')\nplt.show()","f224be14":"fig, axes = plt.subplots(4, 1, figsize=(12,15))\nfig.subplots_adjust(hspace=0.3)\n\ndf_agg_temp = train_target.merge(players[['playerId', 'primaryPositionName']], how='left')\nfor pos in df_agg_temp['primaryPositionName'].unique():\n    if pos == 'Pitcher':\n        lw = 3\n        al = 1\n    else:\n        lw = 1\n        al = 0.5\n    for i, ax in enumerate(axes):\n        df_agg_temp[df_agg_temp['primaryPositionName']==pos].groupby(\n            'engagementMetricsDate').mean()[f'target{i+1}'].plot(ax=ax, label=pos,\n                                                                 linewidth=lw, alpha=al, figsize=(17, 30))\n        ax.set_title(f'mean target{i+1}')\nfor i, ax in enumerate(axes):\n    ax.legend(loc=\"upper left\")\n\ndel df_agg_temp, df_temp","07984f3c":"players.groupby('playerForTestSetAndFuturePreds').count()['playerId'].plot.bar()\nplt.title('True if player is among those for whom predictions are to be made in test data')","f06535f4":"fig, axes = plt.subplots(4, 1, figsize=(12,15))\nfig.subplots_adjust(hspace=0.3)\n\ndf_agg_temp = train_target.merge(players[['playerId', 'playerForTestSetAndFuturePreds']], how='left')\nfor in_test in [True, False]:\n    for i, ax in enumerate(axes):\n        df_agg_temp[df_agg_temp['playerForTestSetAndFuturePreds']==in_test].groupby(\n            'engagementMetricsDate').mean()[f'target{i+1}'].plot(ax=ax, label=f'Player in test: {in_test}',\n                                                                 figsize=(17, 30))\n        ax.set_title(f'mean target{i+1}')\nfor i, ax in enumerate(axes):\n    ax.legend(loc=\"upper left\")\n\ndel df_agg_temp","11abeb8b":"teams = pd.read_csv(f'{data_dir}\/teams.csv')\nteams.head()","f5576c43":"train_rosters = pd.read_pickle(f'train_rosters.pickle')\ntrain_target = pd.read_pickle('train_nextDayPlayerEngagement.pickle')\nteams_agg = pd.merge(train_target, train_rosters, left_on=['dailyDataDate', 'playerId'],\n                     right_on=['dailyDataDate', 'playerId'], how = 'left')\nteams_agg = pd.merge(teams_agg, teams, left_on=['teamId'], right_on=['id'], how='left')\nfor i in range(4):\n    teams_agg.groupby('shortName').mean()[f'target{i+1}'].sort_values().plot.barh(figsize=(10, 5))\n    plt.xlabel(f'mean target{i+1}')\n    plt.title(f'mean target{i+1} per team')\n    plt.show()","e229e248":"for i in range(4):\n    teams_agg.groupby('leagueName').mean()[f'target{i+1}'].sort_values().plot.barh(figsize=(4, 2))\n    plt.xlabel(f'mean target{i+1}')\n    plt.title(f'mean target{i+1} per league')\n    plt.show()","d8e24a9a":"for i in range(4):\n    teams_agg.groupby('divisionName').mean()[f'target{i+1}'].sort_values().plot.barh(figsize=(10, 5))\n    plt.xlabel(f'mean target{i+1}')\n    plt.title(f'mean target{i+1} per division')\n    plt.show()","c068f2c5":"seasons = pd.read_csv(f'{data_dir}\/seasons.csv')\nseasons.head()","6c435721":"del seasons","b3bb83af":"awards = pd.read_csv(f'{data_dir}\/awards.csv')\nawards.head()","fb3246fe":"awards.groupby('playerName').count()['awardId'].sort_values()[-20:].plot.barh()\nplt.title('Top 20 players per number of awards for period 1997-2017')","77137162":"del awards","2a732544":"train_awards = pd.read_pickle(f'train_awards.pickle')\ntrain_awards.head()","11620d7e":"train_awards.groupby('playerName').count()['awardId'].sort_values()[-20:].plot.barh()\nplt.title('Top 20 players per number of awards for training period')","b524ae93":"top_player_targets = train_target[train_target['playerId']==624413]\naward_dates = train_awards[train_awards['playerId'] == 624413]['dailyDataDate'].to_list()\ntop_player_targets['award_date'] = top_player_targets['dailyDataDate'].isin(award_dates).astype(int)\n\nfor i in range(4):\n    top_player_targets[f'target{i+1}'].plot(figsize = (20, 5))\n    top_player_targets[top_player_targets['award_date']==1][f'target{i+1}'].plot(\n        figsize = (20, 5), style='o-',markerfacecolor='red', linestyle='none')\n    plt.legend([f'target{i+1}', 'awards'])\n    plt.title(f'Pete Alonso target{i+1} and awards')\n    plt.show()","1f027ed0":"second_player_targets = train_target[train_target['playerId']==605141]\naward_dates = train_awards[train_awards['playerId'] == 605141]['dailyDataDate'].to_list()\nsecond_player_targets['award_date'] = second_player_targets['dailyDataDate'].isin(award_dates).astype(int)\n\nfor i in range(4):\n    second_player_targets[f'target{i+1}'].plot(figsize = (20, 5))\n    second_player_targets[second_player_targets['award_date']==1][f'target{i+1}'].plot(\n        figsize = (20, 5), style='o-',markerfacecolor='red', linestyle='none')\n    plt.legend([f'target{i+1}', 'awards'])\n    plt.title(f'Wander Franco target{i+1} and awards')\n    plt.show()","0a10c9da":"del train_awards","c1e214b9":"train_events = pd.read_pickle('train_events.pickle')\ntrain_events.head()","3abeeb84":"num_col = [col for col in train_events.columns if pd.api.types.is_numeric_dtype(train_events[col])]\nfig, axes = plt.subplots(nrows=18, ncols=3)\nplt.suptitle('Histograms for numeric columns in train_events data frame', y=0.9)\nfig.set_figheight(40)\nfig.set_figwidth(20)\nfig.subplots_adjust(hspace=0.4)\ncolumns = list(train_events.columns)\n\nfor i, ax in enumerate(axes.flatten()):\n    try:\n        train_events[num_col[i]].hist(ax=ax)\n        ax.set_title(num_col[i])\n    except:\n        continue\n        \nplt.show()","967ac3f4":"object_col = list(set(train_events.columns).difference(num_col))\nfig, axes = plt.subplots(nrows=10, ncols=2)\nplt.suptitle('Top 20 values for each non numeric columns', y=0.9)\nfig.set_figheight(40)\nfig.set_figwidth(20)\nfig.subplots_adjust(hspace=0.4)\n\nfor i, ax in enumerate(axes.flatten()):\n    \n    try:\n        train_events.groupby(object_col[i]).count()['dailyDataDate'].sort_values()[-20:].plot.barh(ax=ax)\n        ax.set_title(object_col[i])\n    except:\n        continue\n\nplt.show()","50ee9cae":"del train_events","b7b38f0a":"train_games = pd.read_pickle('train_games.pickle')\ntrain_games.head()","8540e185":"num_col = [col for col in train_games.columns if pd.api.types.is_numeric_dtype(train_games[col])]\nfig, axes = plt.subplots(nrows=7, ncols=3)\nplt.suptitle('Histograms for numeric columns in train_games data frame', y=0.9)\nfig.set_figheight(40)\nfig.set_figwidth(20)\nfig.subplots_adjust(hspace=0.4)\n\nfor i, ax in enumerate(axes.flatten()):\n    \n    try:\n        train_games[num_col[i]].hist(ax=ax)\n        ax.set_title(num_col[i])\n    except:\n        continue\n        \nplt.show()","94d2613a":"object_col = list(set(train_games.columns).difference(num_col))\nfig, axes = plt.subplots(nrows=7, ncols=2, dpi=120)\nplt.suptitle('Top 20 values for each non numeric columns in train_games data frame', y=0.9)\nfig.set_figheight(30)\nfig.set_figwidth(20)\nfig.subplots_adjust(hspace=0.3)\n\nfor i, ax in enumerate(axes.flatten()):\n    \n    try:\n        train_games.groupby(object_col[i]).count()['dailyDataDate'].sort_values()[-20:].plot.barh(ax=ax)\n        ax.set_title(object_col[i])\n    except:\n        continue\n\nplt.show()","37e057bc":"del train_games","e4d3464f":"train_playerBoxScores = pd.read_pickle(f'train_playerBoxScores.pickle')\ntrain_playerBoxScores.head()","2435e5a0":"num_col = [col for col in train_playerBoxScores.columns\n           if pd.api.types.is_numeric_dtype(train_playerBoxScores[col])]\nfig, axes = plt.subplots(nrows=27, ncols=3)\nplt.suptitle('Histograms for numeric columns in train_playerBoxScores data frame', y=0.9)\nfig.set_figheight(60)\nfig.set_figwidth(20)\nfig.subplots_adjust(hspace=0.4)\n\nfor i, ax in enumerate(axes.flatten()):\n    \n    try:\n        train_playerBoxScores[num_col[i]].hist(ax=ax)\n        ax.set_title(num_col[i])\n    except:\n        continue\nplt.show()","909c8d53":"object_col = list(set(train_playerBoxScores.columns).difference(num_col))\nfig, axes = plt.subplots(nrows=4, ncols=2, dpi=120)\nplt.suptitle('Top 20 values for each non numeric columns', y=0.9)\nfig.set_figheight(20)\nfig.set_figwidth(20)\nfig.subplots_adjust(hspace=0.3)\nfor i, ax in enumerate(axes.flatten()):\n    \n    try:\n        train_playerBoxScores.groupby(object_col[i]).count()['dailyDataDate'].sort_values()[-20:].plot.barh(ax=ax)\n        ax.set_title(object_col[i])\n    except:\n        continue\n\nplt.show()","aed95710":"del train_playerBoxScores","2f5e1a9c":"train_playerTwitterFollowers = pd.read_pickle(f'train_playerTwitterFollowers.pickle')\ntrain_playerTwitterFollowers.head()","47482c61":"train_playerTwitterFollowers.groupby('playerName').max()['numberOfFollowers'].sort_values()[-20:].plot.barh()\nplt.title('Top 20 players with the most twitter followers')","e25decb3":"del train_playerTwitterFollowers","b73ea63a":"train_rosters = pd.read_pickle('train_rosters.pickle')\ntrain_rosters.head()","9e508d15":"train_rosters.groupby('playerId')['teamId'].nunique().hist()\nplt.title('The number of different teams that the player changed')\nplt.show()","a4f1db0d":"train_rosters.merge(players[['playerId', 'playerName']], left_on=['playerId'],\n                    right_on=['playerId'], how='left').groupby(\n    'playerName')['teamId'].nunique().sort_values()[-40:].plot.barh(figsize=(5,10))\nplt.title('Players who changed the most different teams')\nplt.show()","ee33cf4f":"del train_rosters","95962a69":"train_standings = pd.read_pickle('train_standings.pickle')\ntrain_standings.head()","6b6b2fc4":"train_rosters = pd.read_pickle('train_rosters.pickle')\ndf_temp = pd.merge(train_target, train_rosters, left_on=['dailyDataDate', 'playerId'],\n                   right_on=['dailyDataDate', 'playerId'], how='left')\n\nfor col in ['engagementMetricsDate', 'gameDate', 'status', 'statusCode']:\n    df_temp = df_temp.drop(col, axis=1)\n\ndf_temp = pd.merge(df_temp, train_standings, left_on=['dailyDataDate', 'teamId'],\n                   right_on=['dailyDataDate', 'teamId'], how='left')\n\ndf_corr = df_temp.corr()\nplt.rcParams[\"figure.figsize\"] = (17,17)\nsns.heatmap(df_corr, xticklabels=df_corr.columns, yticklabels=df_corr.columns, annot=True)\nplt.title('Corerlation between tagret columns and columns from standing data frame')","0b47c373":"del train_rosters, train_standings","556d75e6":"train_teamBoxScores = pd.read_pickle('train_teamBoxScores.pickle')\ntrain_teamBoxScores.head()","c6c15064":"train_rosters = pd.read_pickle('train_rosters.pickle')\ndf_temp = pd.merge(train_target, train_rosters, left_on=['dailyDataDate', 'playerId'],\n                   right_on=['dailyDataDate', 'playerId'], how='left')\n\nfor col in ['engagementMetricsDate', 'gameDate', 'status', 'statusCode']:\n    df_temp = df_temp.drop(col, axis=1)\n\ndf_temp = pd.merge(df_temp, train_teamBoxScores, left_on=['dailyDataDate', 'teamId'],\n                   right_on=['dailyDataDate', 'teamId'], how='left')\n\ndf_corr = df_temp.corr()\nplt.rcParams[\"figure.figsize\"] = (17,17)\nsns.heatmap(df_corr, xticklabels=df_corr.columns, yticklabels=df_corr.columns, annot=True)\nplt.title('Corerlation between tagret columns and columns from teamBoxScores data frame')","e9cb9b3c":"del train_rosters, df_temp, train_teamBoxScores","f4926f85":"train_teamTwitterFollowers = pd.read_pickle('train_teamTwitterFollowers.pickle')\ntrain_teamTwitterFollowers.head()","fe61bb47":"plt.rcParams[\"figure.figsize\"] = (7,7)\ntrain_teamTwitterFollowers.groupby('teamName').max()['numberOfFollowers'].sort_values()[-20:].plot.barh()\nplt.title('Top 20 teams with the most twitter followers')","bb24978e":"del train_teamTwitterFollowers","f03678a5":"train_transactions = pd.read_pickle('train_transactions.pickle')\ntrain_transactions.head()","52fe718a":"<a id =topic1> <\/a>\n# Target","bc5d421d":"<a id =topic12> <\/a>\n# Train standings","539bf972":"<a id =topic2> <\/a>\n# Players","be022abe":"It is clear that we need somehow to preprocess these strings into data frames, e.g. create the unnested data frames. In that purpose, code from this notebook is used https:\/\/www.kaggle.com\/naotaka1128\/creating-unnested-dataset","4e3f15a8":"<a id =topic5> <\/a>\n# Awards","f052bdea":"<a id =topic10> <\/a>\n# Train Player Twitter Followers","bd9415e2":"<a id =topic4> <\/a>\n# Seasons","b177c011":"<a id =topic8> <\/a>\n# Train games","36a40bf5":"<a id =topic13> <\/a>\n# Train teamBoxScores","78cf1a91":"<a id =topic14> <\/a>\n# Train teamTwitterFollowers","552acddc":"<a id =topic9> <\/a>\n# Train BoxScores","efe4a6e8":"## Content:\n\n* [train_nextDayPlayerEngagement.pickle (Target)](#topic1)\n* [players.csv](#topic2)\n* [teams.csv](#topic3)\n* [seasons.csv](#topic4)\n* [awards.csv](#topic5)\n  * [train_awards.pickle](#topic6)\n  * [train_events.pickle](#topic7)\n  * [train_games.pickle](#topic8)\n  * [train_playerBoxScores.pickle](#topic9)\n  * [train_playerTwitterFollowers.pickle](#topic10)\n  * [train_rosters.pickle](#topic11)\n  * [train_standings.pickle](#topic12)\n  * [train_teamBoxScores.pickle](#topic13)\n  * [train_teamTwitterFollowers.pickle](#topic14)\n  * [transactions.pickle](#topic15)","4a28cef7":"<a id =topic7> <\/a>\n# Train events","5ac6c547":"Static files that do not change with time:\n* players.csv \n* teams.csv\n* seasons.csv\n* awards.csv\n\nDaily data:\n* train.csv\n\nExample test and submission:\n* example_test.csv\n* example_sample_submission.csv\n\nThe test data arrives in a data frame identical in format to train.csv, except it does not contain the target values. It means that all 4 targets are in column **nextDayPlayerEngagement** in the train.csv and it is represented as a big string\n\n\n","c9714032":"<a id =topic11> <\/a>\n# Train rosters","95f525f1":"<a id =topic6> <\/a>\n# Train awards","da1921c3":"* ### Designated Hitters have highest peaks althought it might be because of the low number of them (only 6).\n* ### Target 2 shows some significant spikes in other positions (like First Base and outfielder).","fde34917":"<a id =topic15> <\/a>\n# Train transactions","efb8e67d":"<a id =topic3> <\/a>\n# Teams"}}