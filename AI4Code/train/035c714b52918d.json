{"cell_type":{"53d7fbd0":"code","b689b9ac":"code","c141b13e":"code","4ac8b338":"code","8ee08220":"code","ac8fbb46":"code","81e0752b":"code","74adc74c":"code","644840fa":"code","d4b07967":"code","c1fa137d":"code","36106b61":"code","96ad67ca":"code","6e29cffc":"code","37aa0323":"code","60e85353":"code","e1e9a2c4":"code","7836e902":"code","077683d8":"code","1d591f8e":"code","8e6ae10b":"code","3787bbca":"markdown","bb962129":"markdown","a53d9507":"markdown"},"source":{"53d7fbd0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\n\n# https:\/\/zhuanlan.zhihu.com\/p\/180347090\nfrom joblib import Parallel, delayed\n\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBRegressor\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('.'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b689b9ac":"def log_return(list_stock_prices):\n    return np.log(list_stock_prices).diff() \n\ndef realized_volatility(series_log_return):\n    return np.sqrt(np.sum(series_log_return**2))\n\ndef calculate_wap(df):\n    a1 = df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']\n    b1 = df['bid_size1'] + df['ask_size1']\n    a2 = df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']\n    b2 = df['bid_size2'] + df['ask_size2']\n    \n    x = (a1\/b1 + a2\/b2)\/ 2\n    \n    return x\n\n\ndef calculate_wap2(df):\n        \n    a1 = df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']\n    a2 = df['bid_price2'] * df['ask_size2'] + df['ask_price2'] * df['bid_size2']\n    b = df['bid_size1'] + df['ask_size1'] + df['bid_size2']+ df['ask_size2']\n    \n    x = (a1 + a2)\/ b\n    return x\n\ndef calculate_wap3(df):\n    a1 = df['bid_price1'] * df['ask_size1'] + df['ask_price1'] * df['bid_size1']\n    b1 = df['bid_size1'] + df['ask_size1']\n    x = a1\/b1\n    return x\n\ndef rmspe(y_true, y_pred):\n    return  (np.sqrt(np.mean(np.square((y_true - y_pred) \/ y_true))))\n\nfrom sklearn.metrics import r2_score","c141b13e":"def get_stock_stat(stock_id : int, dataType = 'train'):\n    \n    book_train_subset = pd.read_parquet(f'..\/input\/optiver-realized-volatility-prediction\/book_{dataType}.parquet\/stock_id={stock_id}\/')\n    book_train_subset.sort_values(by=['time_id', 'seconds_in_bucket'])\n\n    book_train_subset['bas'] = (book_train_subset[['ask_price1', 'ask_price2']].min(axis = 1)\n                                \/ book_train_subset[['bid_price1', 'bid_price2']].max(axis = 1)\n                                - 1)                               \n\n    book_train_subset['wap'] = calculate_wap(book_train_subset)\n\n    book_train_subset['log_return'] = (book_train_subset.groupby(by = ['time_id'])['wap'].\n                                       apply(log_return).\n                                       reset_index(drop = True).\n                                       fillna(0)\n                                      )\n    \n    stock_stat = pd.merge(\n        book_train_subset.groupby(by = ['time_id'])['log_return'].agg(realized_volatility).reset_index(),\n        book_train_subset.groupby(by = ['time_id'], as_index = False)['bas'].mean(),\n        on = ['time_id'],\n        how = 'left'\n    )\n    \n    stock_stat.insert(0, \"stock_id\", stock_id)  #\u7b2c\u4e00\u5217\u63d2\u5165\n    \n    return stock_stat","4ac8b338":"def get_dataSet(stock_ids : list, dataType = 'train'):\n\n    stock_stat = Parallel(n_jobs=-1)(\n        delayed(get_stock_stat)(stock_id, dataType) \n        for stock_id in stock_ids\n    )\n    \n    stock_stat_df = pd.concat(stock_stat, ignore_index = True)\n\n    return stock_stat_df","8ee08220":"train = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/train.csv')\ntrain.head()","ac8fbb46":"#book_train_subset = pd.read_parquet('..\/input\/optiver-realized-volatility-prediction\/book_train.parquet\/stock_id=0')\n#book_train_subset","81e0752b":"#train_stock_stat_df = get_dataSet(stock_ids = train['stock_id'].unique(), dataType = 'train')\n#train_dataSet = pd.merge(train, train_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\n#train_dataSet.to_csv(\"optiver-realized-volatility-datasets.csv\",index=False)\n#train_dataSet","74adc74c":"train_dataSet = pd.read_csv(\"..\/input\/optiverrealizedvolatilitydatasets\/optiver-realized-volatility-datasets.csv\")\ntrain_dataSet.head()","644840fa":"df = train_dataSet[['target','log_return','bas']]\ndf","d4b07967":"import matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure(figsize=(8,5))\nx_data, y_data = (df[\"log_return\"].values, df[\"target\"])\nplt.plot(x_data, y_data, 'ro')\nplt.ylabel('target')\nplt.xlabel('log_return')\nplt.show()","c1fa137d":"plt.figure(figsize=(8,5))\nx_data, y_data = (df[\"log_return\"], df[\"target\"])\nplt.plot(x_data - y_data, 'ro')\nplt.ylabel('target')\nplt.xlabel('log_return')\nplt.show()","36106b61":"msk = np.random.rand(len(df)) < 0.8\ntrain = df[msk]\ntest = df[~msk]","96ad67ca":"from sklearn.preprocessing import PolynomialFeatures\nfrom sklearn import linear_model\n#train_x = np.asanyarray(train[['log_return','bas']])\n#train_y = np.asanyarray(train[['target']])\ntrain_x = train[['log_return','bas']]\ntrain_y = train['target']\n\ntest_x = test[['log_return','bas']]\ntest_y = test['target']\n\npoly = PolynomialFeatures(degree=3)\ntrain_x_poly = poly.fit_transform(train_x)\ntrain_x_poly","6e29cffc":"weights = 1\/np.square(train.target)\n\nclf = linear_model.LinearRegression()\ntrain_y_ = clf.fit(train_x_poly, train_y, sample_weight = weights)\n# The coefficients\nprint ('Coefficients: ', clf.coef_)\nprint ('Intercept: ',clf.intercept_)","37aa0323":"len(clf.coef_)","60e85353":"test_x_poly = poly.fit_transform(test_x)\ntest_x_poly","e1e9a2c4":"from sklearn.metrics import r2_score\n\ntest_x_poly = poly.fit_transform(test_x)\ntest_y_ = clf.predict(test_x_poly)\n\nprint(\"Mean absolute error: %.2f\" % np.mean(np.absolute(test_y_ - test_y)))\nprint(\"Residual sum of squares (MSE): %.2f\" % np.mean((test_y_ - test_y) ** 2))\nprint(\"R2-score: %.2f\" % r2_score(test_y,test_y_ ) )","7836e902":"test = pd.read_csv('..\/input\/optiver-realized-volatility-prediction\/test.csv')\n\ntest_stock_stat_df = get_dataSet(stock_ids = test['stock_id'].unique(), dataType = 'test')\ntest_dataSet = pd.merge(test, test_stock_stat_df, on = ['stock_id', 'time_id'], how = 'left')\ntest_dataSet = test_dataSet.drop(['stock_id', 'time_id'], axis = 1)\n\ny_pred = test_dataSet[['row_id']]\nX_test = test_dataSet.drop(['row_id'], axis = 1).fillna(0)\nX_test","077683d8":"X_test_poly = poly.fit_transform(X_test)\nX_test_poly","1d591f8e":"#y_pred = y_pred.assign(target = regr.predict(X_test))\ny_pred = y_pred.assign(target = clf.predict(X_test_poly))\ny_pred.to_csv('submission.csv',index = False)","8e6ae10b":"y_pred","3787bbca":"# Predict","bb962129":"# Evaluation","a53d9507":"# Polynomial regression"}}