{"cell_type":{"ffba2452":"code","6cbe212e":"code","c3c8cfee":"code","990e9d5d":"code","32eadcad":"code","174798d6":"code","bab5998c":"code","e35a9557":"code","0d5982a2":"code","08e89c2a":"code","b07d62f1":"code","0ceefc37":"code","dcafde0d":"code","361b097e":"code","849435eb":"code","7eaa9c94":"code","e69519f7":"code","9476a13b":"code","4f86d98e":"code","222ef758":"code","bb5b34d9":"code","4781f7d3":"code","fcfa1eb4":"code","97dc37d2":"code","c3d1499c":"code","6652a304":"code","fd296213":"code","318911a3":"code","3d795f52":"code","c23346e3":"code","c60e067e":"code","16623902":"code","fb34bde5":"code","fbe0b8b2":"code","de88896b":"code","8fa6a552":"code","254eecc5":"code","921a0ce3":"code","4083c9ff":"code","80ad94bd":"code","e4b4dca5":"code","a20099d2":"code","995f3a39":"code","a4fcb073":"code","64ba3b40":"code","a24838c9":"code","cbb3b8e4":"code","8e1fa27f":"code","26ae5c6a":"code","fbe70b19":"code","62edd249":"code","b9a69079":"code","b87c495b":"code","f8e476f5":"code","43751b78":"code","f4d1858b":"code","a9d68c61":"code","4fbebf9b":"code","a8e31df3":"code","e27d20a0":"code","480f3cfd":"code","caad5f63":"code","a1cab5b5":"code","36119533":"code","5693d220":"code","8bd019aa":"code","20ff007e":"code","d4a56c70":"code","bd91249f":"code","f5e25deb":"code","ce3d0863":"code","8b34e155":"code","567f0720":"code","5a1f2355":"code","fe90cbaa":"code","0a2b23ba":"code","77478348":"code","0fd04bdc":"code","10f45087":"code","221326f7":"code","44ef4078":"code","b4655458":"code","6383f9f3":"code","731d30d6":"code","3ecb8854":"code","34737466":"code","3c8cf613":"markdown","b1957c06":"markdown","bc9fa0c5":"markdown","665f93cf":"markdown","8053e10d":"markdown","6248d8f7":"markdown","39082b21":"markdown","0f326e99":"markdown","c05a271e":"markdown","53baa03c":"markdown","42c20e54":"markdown","0a828645":"markdown","638f1e21":"markdown","989a1870":"markdown","0276b00f":"markdown","788dc437":"markdown","e523d99c":"markdown","0056a622":"markdown","149ee906":"markdown","806123cc":"markdown","be1c4b65":"markdown","1f4e77b6":"markdown","29c4fa57":"markdown","67beb8ff":"markdown","6bdbde66":"markdown","e2c73aaf":"markdown","a07fa924":"markdown","5b25e036":"markdown","d7e64de0":"markdown","364dd301":"markdown","d3107c3a":"markdown","a49c91ee":"markdown","3ccfa7ff":"markdown","3bbd03af":"markdown","cdecc8fe":"markdown","33bb6b22":"markdown","127fd597":"markdown","0b2b0a0d":"markdown"},"source":{"ffba2452":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set_style('whitegrid')","6cbe212e":"train = pd.read_csv('..\/input\/titanic\/train.csv', index_col = 'PassengerId')\ntest = pd.read_csv('..\/input\/titanic\/test.csv', index_col = 'PassengerId')","c3c8cfee":"train.head()","990e9d5d":"train.info()","32eadcad":"test.head()","174798d6":"test.info()","bab5998c":"# Removing Cabin with ~80% missing values\ntrain.drop(['Cabin'], axis = 1, inplace = True)\ntest.drop(['Cabin'], axis = 1, inplace = True)","e35a9557":"# Replacing Sex columns with encouded values. \ntrain.insert(4, 'Male', train['Sex'].str.replace('female', '0').replace('male', '1').astype('category'))\ntest.insert(3, 'Male', test['Sex'].str.replace('female', '0').replace('male', '1').astype('category'))\n\n# Original columns will be saved in a separate variables\nSex_train = train.pop('Sex')\nSex_test = test.pop('Sex')\n\n# Checking if replacement is correct\nprint(\"Distribution in new 'Male' column (train dataset):\\n{}\".format(train['Male'].value_counts()))\nprint(\"\\nDistribution in old 'Sex' column (train dataset):\\n{}\".format(Sex_train.value_counts()))\n\nprint(\"\\nDistribution in new 'Male' column (test dataset):\\n{}\".format(test['Male'].value_counts()))\nprint(\"\\nDistribution in old 'Sex' column (test dataset):\\n{}\".format(Sex_test.value_counts()))","0d5982a2":"# Changing data types to appropriate ones\ntrain['Survived'] = train['Survived'].astype('bool')\ntrain['Pclass'] = train['Pclass'].astype('category')\n# Titanic route was Queenstown ---> Cherbourg ---> Southampton ---> New-York, so encouding Ports of Embarkation accordingly to route\ntrain['Embarked'] = train['Embarked'].str.replace('Q', '1').str.replace('C', '2').str.replace('S', '3').astype('float').astype('category')\n\n# Same actions for test set\ntest['Pclass'] = test['Pclass'].astype('category')\ntest['Embarked'] = test['Embarked'].str.replace('Q', '1').str.replace('C', '2').str.replace('S', '3').astype('float').astype('category')","08e89c2a":"# Checking if everything is correct\ntrain.info()","b07d62f1":"plt.figure(figsize = (8,6))\npalette = sns.color_palette([\"#e74c3c\", \"#3498db\"])\ngender = sns.countplot(train['Male'], palette = palette)\ngender.set_xlabel('Gender (Male)')\ngender.set_ylabel('Number of passengers')\ngender.set_title('Male passengers: {}%\\n'.format(int(sum(train['Male'].astype('int'))*100\/len(train['Male'].astype('int')))) + 'Female passengers: {}%\\n'.format(int(100 - sum(train['Male'].astype('int'))*100\/len(train['Male'].astype('int')))))","0ceefc37":"plt.figure(figsize = (8,6))\npalette = sns.color_palette([\"#e74c3c\", \"#3498db\"])\nsurvived = sns.countplot(train['Survived'], hue = train['Male'], palette = palette)\nsurvived.set_xlabel('Survived')\nsurvived.set_ylabel('Number of passengers')\nsurvived.set_title('Total survived: {}%'.format(int(sum(train['Survived'])*100\/len(train['Survived']))) + \n                   '\\nSurvived men: {}%'.format(int(sum(train[train['Male'] == '1']['Survived'])*100\/sum(train['Male'].astype('int'))))+\n                   '\\nSurvived women: {}%'.format(int(sum(train[train['Male'] == '0']['Survived'])*100\/(len(train['Male'].astype('int')) - sum(train['Male'].astype('int')))))\n                  )\nsurvived.legend(['Women', 'Men'])","dcafde0d":"plt.figure(figsize = (8,6))\npalette = sns.color_palette([\"#B6B3B3\", \"#3498db\"])\nclass_sex_dist = sns.countplot(train['Pclass'], hue = train['Survived'], palette = palette)\nclass_sex_dist.set_xlabel('Class')\nclass_sex_dist.set_ylabel('Number of passengers')\nclass_sex_dist.set_title('1st class passengers: {}%'.format(int(len(train[train['Pclass'] == 1])*100\/len(train['Pclass']))) + \n                   '\\n2nd class passengers: {}%'.format(int(len(train[train['Pclass'] == 2])*100\/len(train['Pclass']))) +\n                   '\\n3rd class passengers: {}%'.format(int(len(train[train['Pclass'] == 3])*100\/len(train['Pclass'])))\n                  )\nclass_sex_dist.legend([\"Didn't survive\", 'Survived'])","361b097e":"# Age distribution\n\nprint('Age distribution in different classes (column \"Age\")' +\n      '\\n0-10: {}'.format(len(train[(train['Age'] < 10)])) +\n      '\\n10-20: {}'.format(len(train[(train['Age'] >= 10) & (train['Age'] < 20)])) +\n      '\\n20-30: {}'.format(len(train[(train['Age'] >= 20) & (train['Age'] < 30)])) +\n      '\\n30-40: {}'.format(len(train[(train['Age'] >= 30) & (train['Age'] < 40)])) +\n      '\\n40-50: {}'.format(len(train[(train['Age'] >= 40) & (train['Age'] < 50)])) +\n      '\\n50-60: {}'.format(len(train[(train['Age'] >= 50) & (train['Age'] < 60)])) +\n      '\\n60+: {}'.format(len(train[train['Age'] >= 60])))\n\nsns.distplot(train['Age'], bins = 20)","849435eb":"plt.figure(figsize = (8,6))\nage_dist = sns.swarmplot(train['Pclass'], train['Age'], palette = 'PuBuGn', hue = train['Survived'])\nage_dist.set_xlabel('Class')\nage_dist.set_title('Age distribution in different classes')\nage_dist.legend([\"Didn't survive\", 'Survived'])","7eaa9c94":"# Checking how missing values in age column distributed according class and gender\nprint('Missing values in Age column per class:\\n{}'.format(train[train['Age'].isnull()]['Pclass'].value_counts()))\nprint('\\nMissing values in Age column per gender:\\n{}'.format(train[train['Age'].isnull()]['Male'].value_counts()))","e69519f7":"# Checking if there are any difference in mean ages for different classes and genders\ntrain.groupby(['Male','Pclass'])['Age'].mean()","9476a13b":"# Filling missing values\nfor i, row in train[train['Age'].isnull()].iterrows():\n    train.loc[i, 'Age'] = int(train.groupby(['Male','Pclass'])['Age'].mean()[row['Male']][row['Pclass']])\nfor i, row in test[test['Age'].isnull()].iterrows():\n    test.loc[i, 'Age'] = int(test.groupby(['Male','Pclass'])['Age'].mean()[row['Male']][row['Pclass']])","4f86d98e":"# Checking, that there are no more missing values in Age column\ntrain[train['Age'].isnull()]","222ef758":"# Here is code to create Age Groups, but I decide to avoid it.\n\n# Creating new columns with age groups\ntrain['AgeGroups'] = train['Age'].apply(lambda x: int(x\/10))\ntest['AgeGroups'] = test['Age'].apply(lambda x: int(x\/10))\n\n# Saving old age column separately\nAge_train = train.pop('Age')\nAge_test = test.pop('Age')\n\nprint('Calculated age groups:\\n{}'.format(train['AgeGroups'].value_counts().sort_index()))","bb5b34d9":"# Are you curious about the most popular second names? This information is not relevant for our analysis, but can be reviewed out of curiosity.\nsns.barplot(train['Name'].apply(lambda second_name: second_name.split(',')[0]).value_counts().head(10).values, train['Name'].apply(lambda second_name: second_name.split(',')[0]).value_counts().head(10).index, palette = 'PuBuGn_r')","4781f7d3":"# Now let's check how title affect survival\ntrain['Name'].apply(lambda title: title.split(',')[1].split('.')[0]).value_counts()","fcfa1eb4":"plt.figure(figsize = (12,6))\npalette = sns.color_palette([\"#B6B3B3\", \"#3498db\"])\ntitle_plot = sns.countplot(train['Name'].apply(lambda title: title.split(', ')[1].split('.')[0]), order = ['Mr', 'Mrs', 'Miss', 'Master'], palette = palette, hue = train['Survived'])\n#title_plot.set_xticklabels(title_plot.get_xticklabels(), rotation=90)\ntitle_plot.set_xlabel('Title')\ntitle_plot.set_ylabel('Number of passengers')\ntitle_plot.legend(loc = 1, labels = [\"Didn't survive\", 'Survived'])","97dc37d2":"# It is interesting that all reverends from our dataset passed away. But is that coincidence or part of their outlook on life? Maybe they tried to help others, but suffered themselves. I don't know, so won't make conclusion here.\ntrain[train['Name'].apply(lambda title: title.split(', ')[1].split('.')[0]) == 'Rev']","c3d1499c":"# If you are interested about the fate of other passengers with honorary titles, then take a look on subset below.\ntrain[train['Name'].apply(lambda title: title.split(', ')[1].split('.')[0]).isin(['Don', 'Dr', 'Ms', 'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'Jonkheer'])]","6652a304":"train['Name'].str.split(', ')[1]#.split('.')[0]","fd296213":"def titles(t):\n    t = t.split(', ')[1].split('.')[0]\n    if t in ['Mr', 'Don', 'Major', 'Sir', 'Col', 'Capt', 'Jonkheer']:\n        return 'Mr'\n    elif t in ['Mrs', 'Mme', 'Dona', 'Lady', 'the Countess']:\n        return 'Mrs'\n    elif t in ['Miss', 'Ms', 'Mlle']:\n        return 'Miss'\n    else:\n        return t\n    \ntrain['Title'] = train['Name'].apply(titles).astype('category')\ntest['Title'] = test['Name'].apply(titles).astype('category')","318911a3":"# Dropping Name column from both datasets\ntrain.drop('Name', axis = 1, inplace = True)\ntest.drop('Name', axis = 1, inplace = True)","3d795f52":"train['Ticket'].nunique() \/ len(train['Ticket']) * 100","c23346e3":"# Dropping Ticket column from both datasets\ntrain.drop('Ticket', axis = 1, inplace = True)\ntest.drop('Ticket', axis = 1, inplace = True)","c60e067e":"# Checking distribution of number of siblings and\/or spouses\nplt.figure(figsize = (12,6))\npalette = sns.color_palette([\"#B6B3B3\", \"#3498db\"])\nsibsp = sns.countplot(train['SibSp'], hue = train['Survived'], palette = palette)\nsibsp.set_xlabel('Number of siblings and\/or spouses')\nsibsp.set_ylabel('Number of passengers')\nsibsp.legend(loc = 1, labels = [\"Didn't survive\", 'Survived'])","16623902":"# Checking distribution of number of parents and\/or children\nplt.figure(figsize = (12,6))\npalette = sns.color_palette([\"#B6B3B3\", \"#3498db\"])\nparch = sns.countplot(train['Parch'], hue = train['Survived'], palette = palette)\nparch.set_xlabel('Number of parents and\/or children')\nparch.set_ylabel('Number of passengers')\nparch.legend(loc = 1, labels = [\"Didn't survive\", 'Survived'])","fb34bde5":"train['Relatives'] = train['Parch'] + train['SibSp']\nParch_train = train.pop('Parch')\nParch_train = train.pop('SibSp')\ntest['Relatives'] = test['Parch'] + test['SibSp']\nParch_test = test.pop('Parch')\nParch_test = test.pop('SibSp')","fbe0b8b2":"# Checking correlation between Pclass and Fare. \ntrain['Fare'].corr(train['Pclass'])","de88896b":"plt.figure(figsize = (8,6))\nsns.boxplot(train['Pclass'], train['Fare'], palette = 'PuBuGn_r')","8fa6a552":"train[train['Fare'] > 500]","254eecc5":"# Checking missing values in Fare column in test dataset. \ntest[test['Fare'].isnull()]","921a0ce3":"# Filling this cell with mean value for third class that boarded in 3rd route point\ntest.loc[1044, 'Fare'] = int(test[(test['Pclass'] == 3) & (test['Embarked'] == 3)]['Fare'].mean())","4083c9ff":"# Checking descriptive statistics for fares\ntrain.groupby(['Pclass'])['Fare'].describe()","80ad94bd":"# Creating bins\ntrain['FareBins'] = pd.cut(train['Fare'], bins=[0,10,15,30,60,100,550], labels=[1,2,3,4,5,6], include_lowest = True)\ntest['FareBins'] = pd.cut(test['Fare'], bins=[0,10,15,30,60,100,550], labels=[1,2,3,4,5,6], include_lowest = True)\nFare_train = train.pop('Fare')\nFare_test = test.pop('Fare')","e4b4dca5":"# Checking missing values in Embarked column in train set\ntrain[train['Embarked'].isnull()]","a20099d2":"# Looking at distribution depending on class\nclass_embarked = sns.countplot(train['Pclass'], hue = train['Embarked'], palette = 'PuBuGn')\nclass_embarked.set_xlabel('Class')\nclass_embarked.set_ylabel('Number of passengers')\nclass_embarked.legend(labels = ['Queenstown', 'Cherbourg', 'Southampton'])","995f3a39":"train['Embarked'].fillna(3, inplace = True)","a4fcb073":"train.info()","64ba3b40":"test.info()","a24838c9":"train_dummy = pd.get_dummies(train.drop(['Survived'], axis = 1))\ntest_dummy = pd.get_dummies(test)","cbb3b8e4":"# Uploading prediction libraries\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import GridSearchCV, train_test_split, RandomizedSearchCV\nfrom sklearn.metrics import accuracy_score, classification_report, confusion_matrix, mean_squared_error\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier, RandomForestClassifier\nfrom sklearn.svm import SVC\nfrom xgboost import XGBClassifier","8e1fa27f":"train_X = train_dummy\ntrain_y = train['Survived']\ntest_X = test_dummy","26ae5c6a":"# Train dataset split for model validation\nX_train, X_val, y_train, y_val = train_test_split(train_X, train_y, test_size = 0.40, random_state = 100)","fbe70b19":"log_reg = LogisticRegression(max_iter = 500)\nlog_reg.fit(X_train, y_train)","62edd249":"log_pred = log_reg.predict(X_val)","b9a69079":"log_reg.score(X_train, y_train)","b87c495b":"print('Confusion matrix:\\n{}'.format(confusion_matrix(y_val, log_pred)))\nprint('\\nClassification report:\\n{}'.format(classification_report(y_val, log_pred)))","f8e476f5":"# K-Neighbors Classifier\nknn_clf = KNeighborsClassifier()\n\n# Setting parameters for muting\nparameters_knn_clf = {'n_neighbors': range(3, 15, 2)}\n\n# Searching for best classificator settings\nsearch_knn_clf = GridSearchCV(knn_clf, parameters_knn_clf, cv = 5)","43751b78":"search_knn_clf.fit(X_train, y_train)","f4d1858b":"best_knn_clf = search_knn_clf.best_estimator_\nprint('Best parameters: ', search_knn_clf.best_estimator_)\nbest_knn_clf.fit(X_train, y_train)\nknn_pred = best_knn_clf.predict(X_val)\nprint('\\nPredictions ready')","a9d68c61":"best_knn_clf.score(X_train, y_train)","4fbebf9b":"print('Confusion matrix:\\n{}'.format(confusion_matrix(y_val, knn_pred)))\nprint('\\nClassification report:\\n{}'.format(classification_report(y_val, knn_pred)))","a8e31df3":"# Random Forest Classifier\ntree_clf = DecisionTreeClassifier()\n\n# Setting parameters for further search\nparameters_tree_clf = {'criterion': ['gini', 'entropy'], 'max_depth': range(5, 36, 5), 'max_leaf_nodes': range(2, 31, 5), 'min_samples_leaf': range(1, 6, 2), 'min_samples_split': range(2,5)}\n\n# Searching for best classificator settings\nsearch_tree_clf = GridSearchCV(tree_clf, parameters_tree_clf, cv = 5)","e27d20a0":"search_tree_clf.fit(X_train, y_train)","480f3cfd":"best_tree_clf = search_tree_clf.best_estimator_\nprint('Best parameters: ', search_tree_clf.best_estimator_)\nbest_tree_clf.fit(X_train, y_train)\ntree_pred = best_tree_clf.predict(X_val)\nprint('\\nPredictions ready')","caad5f63":"# t_clf = DecisionTreeClassifier(criterion='entropy', max_depth = 7, max_leaf_nodes = 15, min_samples_leaf = 2, min_samples_split = 2)\n# t_clf.fit(X_train, y_train)\n# t_pred = t_clf.predict(X_val)\n# t_clf.score(X_train, y_train)","a1cab5b5":"print('Confusion matrix:\\n{}'.format(confusion_matrix(y_val, tree_pred)))\nprint('\\nClassification report:\\n{}'.format(classification_report(y_val, tree_pred)))","36119533":"# Random Forest Classifier\nforest_clf = RandomForestClassifier()\n\n# Setting parameters for further search\nparameters_forest_clf = {'n_estimators': range(150, 601, 50), 'max_depth': range(5, 36, 5), 'max_leaf_nodes': range(5, 31, 5), 'min_samples_leaf': range(1, 6, 2), 'min_samples_split': range(2,5)}\n\n# Searching for best classificator settings\nsearch_forest_clf = RandomizedSearchCV(forest_clf, parameters_forest_clf, cv = 5)","5693d220":"search_forest_clf.fit(X_train, y_train)","8bd019aa":"best_forest_clf = search_forest_clf.best_estimator_\nprint('Best parameters: ', search_forest_clf.best_estimator_)\nbest_forest_clf.fit(X_train, y_train)\nforest_pred = best_forest_clf.predict(X_val)\nprint('\\nPredictions ready')","20ff007e":"best_forest_clf.score(X_train, y_train)","d4a56c70":"print('Confusion matrix:\\n{}'.format(confusion_matrix(y_val, forest_pred)))\nprint('\\nClassification report:\\n{}'.format(classification_report(y_val, forest_pred)))","bd91249f":"booster_clf = GradientBoostingClassifier()\n\n# Setting parameters for muting\nparameters_booster_clf = {'n_estimators': range(50, 301, 50)}\n\n# Searching for best classificator settings\nsearch_booster_clf = GridSearchCV(booster_clf, parameters_booster_clf, cv = 5)","f5e25deb":"search_booster_clf.fit(X_train, y_train)","ce3d0863":"best_booster_clf = search_booster_clf.best_estimator_\nprint('Best parameters: ', search_booster_clf.best_estimator_)\nbest_booster_clf.fit(X_train, y_train)\nbooster_pred = best_booster_clf.predict(X_val)\nprint('\\nPredictions ready')","8b34e155":"best_booster_clf.score(X_train, y_train)","567f0720":"print('Confusion matrix:\\n{}'.format(confusion_matrix(y_val, booster_pred)))\nprint('\\nClassification report:\\n{}'.format(classification_report(y_val, booster_pred)))","5a1f2355":"svc_clf = SVC()\n\n# Setting parameters for further search\nparameters_svc_clf = {'gamma': range(0, 100, 1)}\n\n# Searching for best classificator settings\nsearch_svc_clf = GridSearchCV(svc_clf, parameters_svc_clf, cv = 5)","fe90cbaa":"search_svc_clf.fit(X_train, y_train)","0a2b23ba":"best_svc_clf = search_booster_clf.best_estimator_\nprint('Best parameters: ', search_svc_clf.best_estimator_)\nbest_svc_clf.fit(X_train, y_train)\nsvc_pred = best_svc_clf.predict(X_val)\nprint('\\nPredictions ready')","77478348":"best_svc_clf.score(X_train, y_train)","0fd04bdc":"print('Confusion matrix:\\n{}'.format(confusion_matrix(y_val, svc_pred)))\nprint('\\nClassification report:\\n{}'.format(classification_report(y_val, svc_pred)))","10f45087":"xgb_clf = XGBClassifier()","221326f7":"xgb_clf.fit(X_train, y_train)#, eval_metric='auc', verbose=True)\nxgb_pred = xgb_clf.predict(X_val)\nprint('Predictions ready')","44ef4078":"xgb_clf.score(X_train, y_train)","b4655458":"print('Confusion matrix:\\n{}'.format(confusion_matrix(y_val, xgb_pred)))\nprint('\\nClassification report:\\n{}'.format(classification_report(y_val, xgb_pred)))","6383f9f3":"# Predicting results\npredictions = best_tree_clf.predict(test_dummy)","731d30d6":"# Forming dataframe\nsubmission = pd.DataFrame({'PassengerId': test.index, 'Survived': predictions.astype('int')})\nsubmission.head()","3ecb8854":"# Let's take a look on distribution\npalette = sns.color_palette([\"#B6B3B3\", \"#3498db\"])\ntitle_plot = sns.countplot(submission['Survived'], palette = palette)\ntitle_plot.set_ylabel('Number of passengers')","34737466":"submission.to_csv('\/kaggle\/working\/submission.csv', index = False)","3c8cf613":"Let's look at distributions of different parameters.","b1957c06":"Let's deal with the last field - Embarked","bc9fa0c5":"Note: There is a strong dependency between class and probability to survive. ","665f93cf":"Having only 1-2 values in a group we cannot say, that people in this group will deffinitely survive or die. For example woman with title 'Lady' survived, but we cannot conclude that every 'Lady' also survived. That's why I'll omit such titles in my visualisations and replace them with most common Mr and Miss (or Mrs) for model.","8053e10d":"### Gradient Boosting Regressor","6248d8f7":"# EDA","39082b21":"So most probably 1st class passengers were boarded in 3rd point. Let's use this value for gaps.","0f326e99":"Let's take a look on datasets.","c05a271e":"Let's create separate column for titles. ","53baa03c":"Note: Only 38% of passengers survived. Women were much more likely to survive, so Gender variable is very important for prediction model.","42c20e54":"### Support Vector Machine","0a828645":"This plot is quite interesting for me, as I thought that people in first class may travel with children oftner then people in third class, but plot shows a different picture. \n\nAlso we can see that all children before 10 years in 2nd class were saved, so I assume that Age variable may affect survival rate and should be included in prediction model. \n\nNow I'm going to deal with missing values. Let's take a look, where do we have gaps and how mean age differs depending on class and gender.","638f1e21":"### Random Forest Classifier","989a1870":"This information seems to be strange, but [this source](https:\/\/money.com\/titanic-most-expensive-ticket\/) says, that there was a woman-passanger, that bought the most expensive ticket and traveled with 36-year-old son (they both should be mentioned in row 680, son as a passenger and mother as a parent for that passenger), her maid (probably row 259, as it is female) and his valet (row 738, which is male). Source provides different ticket price, but difference can be explained with currency rate.\n\nThis small investigation shows, that data is okay and we can go further. ","0276b00f":"Fare column. \n\nAs mentioned above, I think that there should be strong correlation between passenger's class and fare, but ticket price can divide passengers into groups more precisely. Let's check if correlation really has place.","788dc437":"### XG Boost Classifier","e523d99c":"### Decision Tree Classifier","0056a622":"So far I have next assumptions:\n- PassengerId - I set it as index, because I don't need this column as part of data for EDA or predictions, however I'll need this column for submission, and it is good to have train and test datasets with the same structure. \n- Survival - 0 or 1. These values I'll need to predict, so for now I should find out, which parameters affect survival rate the most. Based on some logical assumptions I may say, that women, kinds and maybe passengers from higher class were rescued at first place. I'll check that further.\n- Pclass - 1, 2 or 3. Class of passenger. As mentioned above, it seems to be an important parameter.\n- Name - string values with passengers' names in format 'Surname, Title Name'. I have big concerns that during the rescue operation people with some specific names were prioritized and saved at first, however title may be important - e.g. 'Dr.'. For now I'll divide this column into 3 different ('Surname', 'Title', 'Name') and check the relations.\n- Sex - male of female. I think, that this is an important parameter, but for further analysis it will be tricky to deal with string values, so I'm going to code them with booleans. \n- Age - there are some missing values, that I'll need to deal with. Also I'm going to investigate the survival probability in different age groups: children, adults, elderly - so it will be easier to detect, if some age group was prioritised by rescue.\n- SibSp and Parch - number of siblings\/spouses and parents\/children. Not sure how those affect survival... Maybe parents were not so lucky to survive, because at first they worried about children?\n- Ticket - ticket number as a string. I think this information is redundant, because it should be enough to know Class of the passenger. But let's check those ticket numbers first.\n- Fare - ticket price. I assume that this parameter will be also correlated with Pclass, but may allow to divide passengers more precisely. \n- Cabin - I have only 204 values out of 891, which is way not enought to find missing values, so I'll remove this parameter from further analysis. \n- Embarked - Port of Embarkation. Passengers boarded in France (C = Cherbourg), Ireland (Q = Queenstown) and England (S = Southampton). Knowing that at the beginning of 19th century Ireland was mostly represented by workers, I'll assume, that passengers, that boarded in Queenstown were mostly from 3 class, so less lucky to survive.\n\nI'm going to do some quick correction regarding data types and then I'll start checking the assumptions.","149ee906":"# Objective","806123cc":"There is significant difference in ages in different groups, so let's replace missing values with means in corresponding classes and genders.","be1c4b65":"Analysed titles have similar to gender distribution (survived ~20% male; ~70% female), but we can see, for example, that if person is Master, then he is more likely to survive. \n\nLet's check some more titles (with 2-10 representatives).","1f4e77b6":"We can see, that if person had 1 sibling and\/or spouse or 1-2 parents and\/or children, than (s)he had more chances to survive, so this parameters affect survival probability similarly and I'll create one combinated varable.","29c4fa57":"As you may notice, by using correct data types, we reduced memory by 1.5 times.","67beb8ff":"Let's check information about datasets.","6bdbde66":"As next step I'll check if relatives aboard affect Survived parameter. ","e2c73aaf":"As 76% of Ticket numbers are unique, it is very unlikely to find any dependency between tickets and survival probability. I'm going to remove this column from datasets. ","a07fa924":"# Making Predictions","5b25e036":"Replacement is fine, so moving further.","d7e64de0":"Let's creat fare bins in the similar way to age groups.","364dd301":"My goal is to predict survival of Titanic's passengers. To do that I'll firstly review provided dataset and run EDA to create myself a general concept of the data, that I'm going to work with. After that I'll deal with missing values and redundant data. When dataset is ready I'll create several prediction models and will compare them to pick the best option.\n\nIf you will have any question about my decisions, feel free to ask. Also please rate my notebook, if you find my approaches reasonable.\n\nThank you for reviewing. ","d3107c3a":"Let's check Ticket column now.","a49c91ee":"# General: upload and preparation","3ccfa7ff":"Now let's check Name column. ","3bbd03af":"### Logistic regression","cdecc8fe":"### K-Neighbors Classifier","33bb6b22":"Note: There were men passengers twice more than women.","127fd597":"Decision Tree showed the best results, so using it for submition.","0b2b0a0d":"Correlation is really there, but even nowing that it can cause multicollinearity effects, let's still leave it on place. Also I may assume, that there is an outlier with Fare ~500, as it much bigger then the rest data. Let's check."}}