{"cell_type":{"8f6adf54":"code","7b97b197":"code","9a7c3b3d":"code","199346b3":"code","cbbaaabc":"code","0f2eeece":"code","3f9cef6f":"code","76a72a96":"code","6ab9b7da":"code","7bbefa2f":"code","7d4dd89c":"code","9178ae72":"code","0a47666a":"code","6891f382":"code","7d2ff321":"code","a3d5e96c":"code","7922f432":"code","0bb83cda":"code","49ffce7c":"code","13746595":"code","f98e2aab":"code","dd6c34ac":"code","4a529094":"code","b1ceb06e":"markdown","341001ab":"markdown","b01bcb0c":"markdown","755e4291":"markdown","bc738fd0":"markdown"},"source":{"8f6adf54":"# Connect Google Cloud\nPROJECT_ID = 'advertising-linear-nonlinear'\nfrom google.cloud import storage\nstorage_client = storage.Client(project=PROJECT_ID)","7b97b197":"import numpy as np # linear algebra\nimport pandas as pd # data manipulation\nimport seaborn as sns # data visualization\nfrom matplotlib import pyplot as plt # data visualization","9a7c3b3d":"# import data\nadvs = pd.read_csv(\"..\/input\/advertising-dataset\/advertising.csv\")\ndf = advs.copy()\ndf.head()","199346b3":"df.info() # metadata","cbbaaabc":"# describe statistics\ndf.describe([0.01, 0.05, 0.25, 0.50, 0.75, 0.95, 0.99]).T","0f2eeece":"def custom_dist_plots(dataframe):\n    for col in dataframe.columns:\n        sns.distplot(dataframe[col],hist=False).set_title(f\"{col} Distribution Graph\")\n        plt.axvline(dataframe[col].mean(),color='r',label='mean')\n        plt.axvline(np.median(dataframe[col]),color='b',label='median')\n        plt.axvline((dataframe[col].mode())[0],color='g',label='mode')\n        plt.legend()\n        plt.show();\n\ncustom_dist_plots(df)","3f9cef6f":"# Sales related other variables\ndef target_scatter(dataframe):\n    cols = [col for col in dataframe.columns if col != \"Sales\"]\n    sns.pairplot(dataframe, x_vars=cols, y_vars=\"Sales\", height=4, aspect=1, kind='scatter')\n    plt.show()\n\ntarget_scatter(df)","76a72a96":"# correlation graph\nsns.heatmap(df.corr(), cmap=\"Dark2\", annot = True)\nplt.show()","6ab9b7da":"def missing_detection(dataframe, method=\"boxplot\"):\n    if method == \"boxplot\":\n        var_names = [col for col in df.columns if col != \"Sales\"]\n        fig, axs = plt.subplots(len(var_names), figsize=(5, 5))\n        for i, col in enumerate(var_names):\n            sns.boxplot(df[col], ax=axs[i])\n        plt.tight_layout()\n    elif method == \"lof\":\n        from sklearn.neighbors import LocalOutlierFactor\n        clf = LocalOutlierFactor(n_neighbors = 20, contamination = 0.1)\n        clf.fit_predict(dataframe)\n        scores_df = pd.DataFrame(np.sort(clf.negative_outlier_factor_))\n        scores_df.plot(stacked=True, xlim=[0,20], style='.-')\n        plt.show()","7bbefa2f":"missing_detection(df) # boxplot","7d4dd89c":"missing_detection(df, \"lof\") # LOF","9178ae72":"from sklearn.linear_model import LinearRegression # Multiple Linear Regression\nfrom sklearn.linear_model import Ridge # Ridge Regression\nfrom sklearn.linear_model import Lasso # Lasso Regression\nfrom sklearn.linear_model import ElasticNet # ElasticNet Regression\nfrom sklearn.neighbors import KNeighborsRegressor # KNN\nfrom sklearn.tree import DecisionTreeRegressor # CART\nfrom sklearn.ensemble import RandomForestRegressor # Random Forests\nfrom sklearn.ensemble import GradientBoostingRegressor # GBM","0a47666a":"# holdout method\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nX = df.drop(\"Sales\", axis=1)\ny = df.Sales\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=6106)","6891f382":"model_grid = {\"Linear\": LinearRegression(),\n              \"Ridge\": Ridge(),\n              \"Lasso\": Lasso(),\n              \"ElasticNet\": ElasticNet(),\n              \"KNN\": KNeighborsRegressor(),\n              \"CART\": DecisionTreeRegressor(),\n              \"RF\": RandomForestRegressor(random_state=6106),\n              \"GBM\": GradientBoostingRegressor()}\n\nscores_dict = {}\nfor name, model in model_grid.items():\n    model.fit(X_train, y_train)\n    rmse = np.mean(np.sqrt(-cross_val_score(model, X_test, y_test, cv=10, scoring=\"neg_mean_squared_error\")))\n    scores_dict[name] = rmse\n\nscores_dict = {k: v for k, v in sorted(scores_dict.items(), key=lambda item: item[1])}\nscores_dict","7d2ff321":"# If you want the top 4 models do the following codes\n\nfrom itertools import islice\ntop_4_scores = dict(islice(scores_dict.items(), 4))\nprint(\"Top 4 Scores\")\ntop_4_scores","a3d5e96c":"# Random Forests Regression\n\n# setting model\nrf_model = RandomForestRegressor(random_state=6106)\n\n# seting param grid\nrf_params = {\"max_depth\": [5, 8, None],\n             \"n_estimators\": [200, 500],\n             \"min_samples_split\": [2, 5, 10]}\n\n# search best params\nrf_cv_model = GridSearchCV(rf_model, rf_params, cv=10, n_jobs=-1, verbose=1).fit(X_train, y_train)\n\n# tuned model\nrf_tuned = RandomForestRegressor(**rf_cv_model.best_params_).fit(X_train, y_train)","7922f432":"# Lasso Regression\n\n# setting model\nlasso_model = Lasso()\n\n# seting param grid\nlasso_param = {\"alpha\": 10 ** (np.linspace(10, -2, 100) * 0.5)}\n\n# search best params\nlasso_cv_model = GridSearchCV(lasso_model, lasso_param, cv=10, n_jobs=-1, verbose=1).fit(X_train, y_train)\n\n# tuned model\nlasso_tuned = Lasso(**lasso_cv_model.best_params_).fit(X_train, y_train)","0bb83cda":"# ElasticNet Regression\n\n# setting model\nenet_model = ElasticNet()\n\n# seting param grid\nenet_params = {\"l1_ratio\": [0.1, 0.4, 0.5, 0.6, 0.8, 1],\n               \"alpha\": [0.1, 0.01, 0.001, 0.2, 0.3, 0.5, 0.8, 0.9, 1]}\n\n# search best params\nenet_cv_model = GridSearchCV(enet_model, enet_params, cv=10, n_jobs=-1, verbose=1).fit(X_train, y_train)\n\n# tuned model\nenet_tuned = ElasticNet(**enet_cv_model.best_params_).fit(X_train, y_train)","49ffce7c":"# Ridge Regression\n\n# setting model\nridge_model = Ridge()\n\n# seting param grid\nridge_param = {\"alpha\": 10 ** (np.linspace(10, -2, 100) * 0.5)}\n\n# search best params\nridge_cv_model = GridSearchCV(ridge_model, ridge_param, cv=10, n_jobs=-1, verbose=1).fit(X_train, y_train)\n\n# tuned model\nridge_tuned = ElasticNet(**ridge_cv_model.best_params_).fit(X_train, y_train)","13746595":"from sklearn.metrics import mean_squared_error\n\n# set tuned models\ntuned_grid = dict([(\"RF\", rf_tuned), (\"Lasso\", lasso_tuned), (\"ElasticNet\", enet_tuned), (\"Ridge\", ridge_tuned)])\n\n# get rmse values from tuned models\ntuned_scores = {}\nfor name, model in tuned_grid.items():\n    y_pred = model.predict(X_test)\n    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n    tuned_scores[name] = rmse\n\n# sorting rmse\ntuned_scores = {k: v for k, v in sorted(tuned_scores.items(), key=lambda item: item[1])}\n\n# choose best model\nbest_model = dict(islice(tuned_scores.items(), 1))\nbest_model","f98e2aab":"# visualization RF (first tree)\nfrom sklearn.tree import plot_tree\n\nplt.figure(figsize=(20,20))\nplot_tree(rf_tuned.estimators_[0], filled=True)\nplt.show()","dd6c34ac":"rf_cv_model.best_params_","4a529094":"rf_new_model = RandomForestRegressor(max_depth=3, min_samples_split=2, n_estimators=200).fit(X_train, y_train)\nplt.figure(figsize=(20,20))\nplot_tree(rf_new_model.estimators_[0], filled=True)\nplt.show()","b1ceb06e":"# Settings & Imports","341001ab":"# Model Building\n\nWe used the following models:","b01bcb0c":"# Model Tuning","755e4291":"# EDA","bc738fd0":"**We did not interfere with outliers.**"}}