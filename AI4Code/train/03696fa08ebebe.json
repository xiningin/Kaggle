{"cell_type":{"530d1d71":"code","c2493485":"code","8fa2278e":"code","0d8e9e99":"code","dde8da79":"code","4c5ceb99":"code","0f20b9da":"code","6520d4c6":"code","dbbf8e7c":"code","6cfde301":"code","b0bc4a95":"code","7ee68abe":"code","cb63fe31":"code","f6ad22f4":"code","f0323b75":"code","9261f2ad":"code","c88dd577":"code","3f5afe69":"code","6834f1cb":"code","69319c00":"code","d5f63976":"code","98f1634c":"code","2cc6ebe0":"code","c3bf63ba":"code","573086b0":"code","c7d05df6":"markdown"},"source":{"530d1d71":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nimport re\nfrom nltk.corpus import stopwords\nfrom tqdm import tqdm\nfrom wordcloud import WordCloud, STOPWORDS\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nimport numpy as np\nfrom sklearn import preprocessing\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import roc_auc_score \nfrom sklearn.metrics import average_precision_score\nfrom sklearn.metrics import recall_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c2493485":"train=pd.read_csv('..\/input\/train.csv')\ntest=pd.read_csv('..\/input\/test.csv')","8fa2278e":"train.info()","0d8e9e99":"train.question_text[9]","dde8da79":"train.target.value_counts().plot(kind='bar')","4c5ceb99":"def clean_text(text, remove_stopwords = False):\n    text = text.lower()\n    text = text.strip().replace(\"\\n\", \" \").replace(\"\\r\", \" \") ## remove new line chars\n    text = re.sub(r'[_\"\\-;%()|+&=*%.,!?:#$@\\[\\]\/]', ' ', text)  ## remove unwanted chars\n    text = re.sub(r'\\'', ' ', text)\n    text = re.sub('[\\d+]', '', text) ## remove numerics\n    text=  re.sub(\"\\s\\s+\", \" \", text)  ## remove white spaces\n    \n    # Optionally, remove stop words\n    if remove_stopwords:\n        text = text.split()\n        stops = set(stopwords.words(\"english\"))\n        text = [w for w in text if not w in stops]\n        text = \" \".join(text)\n\n    return text","0f20b9da":"clean_question=[]\nfor text in tqdm(train.question_text):\n    textt=clean_text(text,remove_stopwords = True)\n    clean_question.append(textt)","6520d4c6":"train['clean_question']=clean_question","dbbf8e7c":"train.head()","6cfde301":"sincere = train[train.target==0][\"clean_question\"]\ninsincere = train[train.target==1][\"clean_question\"]\n","b0bc4a95":"wordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=STOPWORDS,\n                          max_words=50000,\n                          max_font_size=30, \n                          random_state=42\n                         ).generate(str(sincere))\n\nprint(wordcloud)\nplt.figure(figsize=(16,13))\n\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n#fig.savefig(\"word1.png\", dpi=900)","7ee68abe":"wordcloud = WordCloud(\n                          background_color='white',\n                          stopwords=STOPWORDS,\n                          max_words=50000,\n                          max_font_size=30, \n                          random_state=42\n                         ).generate(str(insincere))\n\nprint(wordcloud)\nplt.figure(figsize=(16,13))\n\nfig = plt.figure(1)\nplt.imshow(wordcloud)\nplt.axis('off')\nplt.show()\n#fig.savefig(\"word1.png\", dpi=900)","cb63fe31":"X_train, X_test, y_train, y_test = train_test_split(train['clean_question'], \n                                                    train['target'], \n                                                    random_state=0)","f6ad22f4":"tfvect=TfidfVectorizer(stop_words='english',min_df=3).fit(X_train)\nx_train_tfvect=tfvect.transform(X_train)\nx_test_tfvect=tfvect.transform(X_test)\nname=tfvect.get_feature_names()\nfeature_names = np.array(tfvect.get_feature_names())\nsorted_tfidf_index = x_train_tfvect.max(0).toarray()[0].argsort()","f0323b75":"print('Smallest tfidf:\\n{}\\n'.format(feature_names[sorted_tfidf_index[:10]]))\nprint('Largest tfidf: \\n{}'.format(feature_names[sorted_tfidf_index[:-100:-1]]))","9261f2ad":"from sklearn.linear_model import LogisticRegression","c88dd577":"model=LogisticRegression(solver='sag')\nmodel.fit(x_train_tfvect,y_train)","3f5afe69":"predicted= model.predict(x_test_tfvect)\n","6834f1cb":"accuracy=accuracy_score(y_test, predicted)\n\nreport=classification_report(y_test, predicted)","69319c00":"accuracy","d5f63976":"print(report)","98f1634c":"clean_question_test=[]\nfor text in tqdm(test.question_text):\n    textt=clean_text(text,remove_stopwords = True)\n    clean_question_test.append(textt)","2cc6ebe0":"x_testt_tfvect=tfvect.transform(clean_question_test)","c3bf63ba":"test_pred=model.predict(x_testt_tfvect)\ntest_pred","573086b0":"out_df = pd.DataFrame({\"qid\":test[\"qid\"].values})\nout_df['prediction'] = test_pred\nout_df.to_csv(\"submission.csv\", index=False)","c7d05df6":"# to be continued...."}}