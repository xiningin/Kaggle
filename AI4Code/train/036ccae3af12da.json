{"cell_type":{"d99fe88f":"code","a7817bfb":"code","eca70192":"code","00a18d73":"code","a19e1207":"code","4926f419":"code","f3e99480":"code","9edc231c":"code","238ec3f3":"code","17666f4f":"markdown","db3a1b17":"markdown","db911406":"markdown","5a3339ca":"markdown"},"source":{"d99fe88f":"import os\nfrom pathlib import Path\nimport glob\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread, imshow, imsave\nfrom keras.preprocessing.image import load_img, array_to_img, img_to_array\nfrom keras.models import Sequential, Model\nfrom keras.layers import Dense, Conv2D, MaxPooling2D, UpSampling2D, Flatten, Input\nfrom keras.optimizers import Adam, Adadelta, Adagrad\nfrom keras import backend as K\nfrom sklearn.model_selection import train_test_split\nnp.random.seed(111)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n# Any results you write to the current directory are saved as output.","a7817bfb":"input_dir  = Path('..\/input\/')\ntrain = input_dir \/ 'train\/'\ntrain_cleaned = input_dir \/ 'train_cleaned\/'\ntest = input_dir \/ 'test\/'","eca70192":"import glob\ntrain_images = glob.glob('..\/input\/train\/*.png')\ntrain_labels = glob.glob('..\/input\/train_cleaned\/*.png')\ntest_images = glob.glob('..\/input\/test\/*.png')\n\nprint(\"Total number of images in the training set: \", len(train_images))\nprint(\"Total number of cleaned images found: \", len(train_labels))\nprint(\"Total number of samples in the test set: \", len(test_images))\n\n# Lets' plot a few samples\n# First row will be raw data, second row will be the corresponding cleaned images\nsamples = train_images[:3] + train_labels[:3]\n\nf, ax = plt.subplots(2, 3, figsize=(20,10))\nfor i, img in enumerate(samples):\n    img = imread(img)\n    ax[i\/\/3, i%3].imshow(img, cmap='gray')\n    ax[i\/\/3, i%3].axis('off')\nplt.show()    ","00a18d73":"def build_autoenocder():\n    input_img = Input(shape=(420,540,1), name='image_input')\n    \n    #enoder \n    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv1')(input_img)\n    x = MaxPooling2D((2,2), padding='same', name='pool1')(x)\n   \n    #decoder\n\n    x = Conv2D(32, (3,3), activation='relu', padding='same', name='Conv2')(x)\n    x = UpSampling2D((2,2), name='upsample3')(x)\n    x = Conv2D(1, (3,3), activation='sigmoid', padding='same', name='Conv3')(x)\n    \n    #model\n    autoencoder = Model(inputs=input_img, outputs=x)\n    autoencoder.compile(optimizer='Adagrad', loss='binary_crossentropy')\n    return autoencoder","a19e1207":"autoencoder = build_autoenocder()\nautoencoder.summary()","4926f419":"X = []\nY = []\n\nfor img in train_images:\n    img = load_img(img, grayscale=True,target_size=(420,540))\n    img = img_to_array(img).astype('float32')\/255.\n    X.append(img)\n\nfor img in train_labels:\n    img = load_img(img, grayscale=True,target_size=(420,540))\n    img = img_to_array(img).astype('float32')\/255.\n    Y.append(img)\n\n\nX = np.array(X)\nY = np.array(Y)\n\nprint(\"Size of X : \", X.shape)\nprint(\"Size of Y : \", Y.shape)","f3e99480":"# Split the dataset into training and validation. Always set the random state!!\nX_train, X_valid, y_train, y_valid = train_test_split(X, Y, test_size=0.1, random_state=111)\nprint(\"Total number of training samples: \", X_train.shape)\nprint(\"Total number of validation samples: \", X_valid.shape)","9edc231c":"# Train your model\nautoencoder.fit(X_train, y_train, epochs=30, batch_size=8, validation_data=(X_valid, y_valid))","238ec3f3":"sample_test = load_img(test_images[10], grayscale=True, target_size=(420,540))\nsample_test = img_to_array(sample_test)\nsample_test_img = sample_test.astype('float32')\/255.\nsample_test_img = np.expand_dims(sample_test, axis=0)\n\n# Get the predition\npredicted_label = np.squeeze(autoencoder.predict(sample_test_img))\n\nf, ax = plt.subplots(1,2, figsize=(10,8))\nax[0].imshow(np.squeeze(sample_test), cmap='gray')\nax[1].imshow(np.squeeze(predicted_label.astype('int8')), cmap='gray')\nplt.show()","17666f4f":"Hello Kagglers, This is the simple implementation of AutoEncoders in Keras. On [denoising-dirty-documents](https:\/\/www.kaggle.com\/c\/denoising-dirty-documents) dataset. \n![](https:\/\/media.giphy.com\/media\/NL6i0bK8omoMM\/giphy.gif)","db3a1b17":"**Upvote the kernel if you liked it**. Also, if you found anything wrong in the notebook or if you want to suggest something as an improvement, please do share that in the comments section. I hope you enjoyed the kernel.","db911406":"### AutoEncoder\nAn autoencoder is a type of artificial neural network used to learn efficient data codings in an unsupervised manner. The aim of an autoencoder is to learn a representation (encoding) for a set of data, typically for the purpose of dimensionality reduction. Recently, the autoencoder concept has become more widely used for learning generative models of data.\n![](https:\/\/cdn-images-1.medium.com\/max\/1600\/1*44eDEuZBEsmG_TCAKRI3Kw@2x.png)\n\n[Read More here](https:\/\/towardsdatascience.com\/deep-inside-autoencoders-7e41f319999f)","5a3339ca":"The dataset is small, so we can actually store the numpy arrays of images and corresponding cleaned images numpy arrays into two numpy arrays."}}