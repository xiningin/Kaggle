{"cell_type":{"6917dafa":"code","8f26c70c":"code","ec63a70b":"code","6eacc9b5":"code","b933ea9f":"code","98808701":"code","9d12e249":"code","1349dc4b":"code","86546874":"code","c75582ba":"code","8f4f9685":"code","64e9e765":"code","d1eb4d2c":"code","fc22f464":"code","6402aefb":"code","f2717997":"markdown"},"source":{"6917dafa":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport cv2\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Lambda, Conv2D, Flatten, Dense\nfrom tensorflow.keras.optimizers import Adam","8f26c70c":"df = pd.read_csv(\"\/kaggle\/input\/selfdriving-car-simulator\/dataset\/dataset\/driving_log.csv\", names=[\"center\", \"left\", \"right\", \n                                                                                                   'steering', 'throttle', 'reverse', 'speed']).sample(frac=.25)\ndf.head()","ec63a70b":"df.isnull().sum()","6eacc9b5":"df.count()","b933ea9f":"X_c = np.ones((8111, 66, 200, 3), dtype=np.uint8)\nX_l = np.ones((8111, 66, 200, 3), dtype=np.uint8)\nX_r = np.ones((8111, 66, 200, 3), dtype=np.uint8)","98808701":"X_c.shape, X_l.shape, X_r.shape","9d12e249":"for i in range(8111):\n    row = df.iloc[i]\n\n    c = cv2.imread(\"\/kaggle\/input\/selfdriving-car-simulator\/dataset\/dataset\/IMG\/\"+row[\"center\"].split(\"\\\\\")[-1])\n    c = cv2.resize(c, (200, 66))\n    c = cv2.cvtColor(c, cv2.COLOR_BGR2RGB)\n    X_c[i] = c\n\n    l = cv2.imread(\"\/kaggle\/input\/selfdriving-car-simulator\/dataset\/dataset\/IMG\/\"+row[\"left\"].split(\"\\\\\")[-1])\n    l = cv2.resize(l, (200, 66))\n    l = cv2.cvtColor(l, cv2.COLOR_BGR2RGB)\n    X_l[i] = l\n\n    r = cv2.imread(\"\/kaggle\/input\/selfdriving-car-simulator\/dataset\/dataset\/IMG\/\"+row[\"right\"].split(\"\\\\\")[-1])\n    r = cv2.resize(r, (200, 66))\n    r = cv2.cvtColor(r, cv2.COLOR_BGR2RGB)\n    X_r[i] = r\n    \n# Final output value\nY = df.loc[\"steering\"].values","1349dc4b":"Y = df.steering.values\nY.shape","86546874":"# Print images\nfig, axs = plt.subplots(1, 5, figsize=(25, 5))\n\nfor ax, img, label in zip(axs, X_c[10:15], Y[10:15]):\n    ax.set_title(\"center \" + str(label))\n    ax.imshow(img)\n    ax.grid(True)\n\nplt.show()","c75582ba":"# Print images\nfig, axs = plt.subplots(1, 5, figsize=(25, 5))\n\nfor ax, img, label in zip(axs, X_l[10:15], Y[10:15]):\n    ax.set_title(\"left \" + str(label))\n    ax.imshow(img)\n    ax.grid(True)\n\nplt.show()","8f4f9685":"# Print images\nfig, axs = plt.subplots(1, 5, figsize=(25, 5))\n\nfor ax, img, label in zip(axs, X_r[10:15], Y[10:15]):\n    ax.set_title(\"right \" + str(label))\n    ax.imshow(img)\n    ax.grid(True)\n\nplt.show()","64e9e765":"# Model\nmodel = keras.models.Sequential()\nmodel.add(Lambda(lambda x: x\/127.5-1.0, input_shape=(66, 200, 3)))\nmodel.add(Conv2D(24, (5, 5), activation='relu', strides=(2, 2)))\nmodel.add(Conv2D(36, (5, 5), activation='relu', strides=(2, 2)))\nmodel.add(Conv2D(48, (5, 5), activation='relu', strides=(2, 2)))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Conv2D(64, (3, 3), activation='relu'))\nmodel.add(Flatten())\nmodel.add(Dense(100, activation='relu'))\nmodel.add(Dense(50, activation='relu'))\nmodel.add(Dense(10, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer=Adam(lr=0.01), metrics=[\"Accuracy\"])\nmodel.summary()","d1eb4d2c":"X = np.ones((8111, 66, 200, 3), dtype=np.uint8)\nX[:2703] = X_c[:2703]\nX[2703:5406] = X_l[2703:5406]\nX[5406:] = X_r[5406:]\n\nX.shape","fc22f464":"model.fit(X, Y, epochs=1, batch_size=32, validation_split=0.10, verbose=1)","6402aefb":"Y","f2717997":"for dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))"}}