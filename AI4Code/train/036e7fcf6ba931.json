{"cell_type":{"a62fb2ab":"code","0d6a2a03":"code","758c3f5e":"code","f2f3f28b":"code","9198ee1a":"code","06b9e4eb":"code","45bee9e0":"code","ade3d231":"code","0b9e77fb":"code","894289e0":"code","0ea6c957":"code","ebe93b83":"code","95b09f93":"code","c17c2b76":"code","50e8926b":"markdown","87ba1cac":"markdown","78c667c0":"markdown","1f013c03":"markdown","c4130302":"markdown","a6cecac8":"markdown","4d0cb971":"markdown"},"source":{"a62fb2ab":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport tensorflow as tf\nfrom tensorflow import keras","0d6a2a03":"story_sequence_length = 16\nquestion_sequence_length = 4\nanswer_sequence_length = 1\nbase_path = \"..\/input\/the-babi-tasks-for-nlp-qa-system\/tasks_1-20_v1-2\/en\"\ntrain_path = os.path.join(base_path, \"qa1_single-supporting-fact_train.txt\")\ntest_path = os.path.join(base_path, \"qa1_single-supporting-fact_test.txt\")","758c3f5e":"def get_data(path):\n    with open(path) as f:\n        lines = f.readlines()\n    stories, questions, answers = [] , [] , []\n    for i in range(len(lines)):\n        line = lines[i]\n        new_line = \"\"\n        trim_number = False\n        for c in line:\n            if trim_number == False:\n                if not (c.isdigit() or c == \" \"):\n                    trim_number = True\n                    new_line += c\n            else:\n                new_line += c\n        lines[i] = new_line.strip()\n    for i in range(len(lines) \/\/ 3):\n        story = lines[3 * i] + \" \" + lines[3 * i + 1]\n        stories.append(story)\n        items = lines[3 * i + 2].split(\"\\t\")\n        questions.append(items[0])\n        answers.append(items[1])\n    return stories, questions, answers","f2f3f28b":"story_vec = tf.keras.layers.TextVectorization(output_sequence_length=story_sequence_length)\nquestion_vec = tf.keras.layers.TextVectorization(output_sequence_length=question_sequence_length)\nanswer_vec = tf.keras.layers.TextVectorization(output_sequence_length=answer_sequence_length)","9198ee1a":"train_stories, train_questions, train_answers = get_data(train_path)\nstory_vec.adapt(train_stories)\nquestion_vec.adapt(train_questions)\nanswer_vec.adapt(train_answers)","06b9e4eb":"display(story_vec(train_stories[0]))\ndisplay(story_vec(train_questions[0]))\ndisplay(answer_vec(train_answers[0]))","45bee9e0":"story_vocab_size = len(story_vec.get_vocabulary())\nprint(\"Story Vocabulary size: \", story_vocab_size)\nquestion_vocab_size = len(question_vec.get_vocabulary())\nprint(\"Quesiton Vocabulary size: \", question_vocab_size)\nanswer_vocab_size = len(question_vec.get_vocabulary())\nprint(\"Answer Vocabulary size: \", answer_vocab_size)","ade3d231":"def preprocess(feature, label):\n    answer = answer_vec(label)\n    print(answer)\n    return feature, answer","0b9e77fb":"def make_dataset(path, batch_size = 32, shuffle = False):\n    stories, questions, answers = get_data(path)\n    ds = tf.data.Dataset.from_tensor_slices(((stories, questions), answers))\n    if shuffle == True:\n        ds = ds.shuffle(256)\n    ds = ds.batch(batch_size)\n    ds = ds.map(preprocess)\n    return ds","894289e0":"train_ds = make_dataset(train_path, shuffle=True)\ntest_ds = make_dataset(test_path)","0ea6c957":"for (question, answer), label in train_ds.take(1):\n    print(question.shape, answer.shape, label.shape)","ebe93b83":"embed_dim = 8\ndef get_model():\n    story_inputs = keras.Input(shape=(None,), dtype=\"string\")\n    question_inputs = keras.Input(shape=(None,), dtype=\"string\")\n    \n    story_x = story_vec(story_inputs)\n    story_x = keras.layers.Embedding(input_dim=story_vocab_size, output_dim=embed_dim, input_length=story_sequence_length)(story_x)\n    story_x = keras.layers.Dropout(0.3)(story_x)\n    \n    question_x = question_vec(question_inputs)\n    question_x = keras.layers.Embedding(input_dim=question_vocab_size, output_dim=embed_dim, input_length=question_sequence_length)(question_x)\n    question_x = keras.layers.Dropout(0.3)(question_x)\n    \n    match = keras.layers.Dot(axes=[2, 2])([story_x, question_x])\n    \n    story_encoder_c = story_vec(story_inputs)\n    story_encoder_c = keras.layers.Embedding(input_dim=story_vocab_size, output_dim=question_sequence_length, input_length=story_sequence_length)(story_encoder_c)        \n    \n    response = keras.layers.Add()([match, story_encoder_c])\n    response = keras.layers.Permute((2, 1))(response)\n    \n    answer= keras.layers.Concatenate()([response, question_x])\n    answer = keras.layers.Bidirectional(keras.layers.LSTM(32))(answer)\n    answer = keras.layers.Dropout(0.3)(answer)\n    output = keras.layers.Dense(answer_vocab_size, activation=\"softmax\")(answer)\n    model = keras.Model(inputs=[story_inputs, question_inputs], outputs=[output])\n    model.compile(optimizer=\"adam\", loss=\"sparse_categorical_crossentropy\", metrics=[\"accuracy\"])\n    return model","95b09f93":"model = get_model()\ndisplay(model.summary())\ndisplay(keras.utils.plot_model(model, show_shapes=True, show_dtype=True))","c17c2b76":"model_path = \"model.tf\"\nearly_stop = keras.callbacks.EarlyStopping(patience=50, monitor=\"val_accuracy\")\ncheckpoint = keras.callbacks.ModelCheckpoint(model_path, monitor=\"val_accuracy\", save_best_only=True)\nmodel.fit(train_ds, epochs=300, validation_data=test_ds, callbacks=[early_stop, checkpoint])","50e8926b":"## Babi Tasks Question Answering with Keras","87ba1cac":"## Make Tensorflow Dataset","78c667c0":"## Training","1f013c03":"### Configurations","c4130302":"## Modeling","a6cecac8":"##  Utilities","4d0cb971":"## Text Vectorization"}}