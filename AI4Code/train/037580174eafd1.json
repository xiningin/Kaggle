{"cell_type":{"134f1cf5":"code","f7c41e18":"code","38f9650f":"code","c03a32b5":"code","18888016":"code","b7e95570":"code","7e524b26":"code","ac65bc73":"code","978f25f8":"code","82e73a13":"code","7dd5d101":"code","99558522":"code","8fffb575":"code","f7bc6bfd":"code","fc86b136":"code","25bbce4b":"code","6d41740c":"code","8b931e00":"code","ee1e5408":"markdown","11b1bf1c":"markdown"},"source":{"134f1cf5":"import os\n\nimport numpy as np\nimport pandas as pd\nfrom sklearn import preprocessing\nimport xgboost as xgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport random\nseed = 10\nnp.random.seed(seed)\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\nimport eli5","f7c41e18":"def reduce_mem_usage(df):\n    \"\"\" iterate through all the columns of a dataframe and modify the data type\n        to reduce memory usage.        \n    \"\"\"\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage of dataframe is {:.2f} MB'.format(start_mem))\n    \n    for col in df.columns:\n        col_type = df[col].dtype\n        \n        if col_type != object:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n        else:\n            df[col] = df[col].astype('category')\n\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    print('Memory usage after optimization is: {:.2f} MB'.format(end_mem))\n    print('Decreased by {:.1f}%'.format(100 * (start_mem - end_mem) \/ start_mem))\n    \n    return df","38f9650f":"%%time\ntrain_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/train_transaction.csv', index_col='TransactionID')\ntest_transaction = pd.read_csv('..\/input\/ieee-fraud-detection\/test_transaction.csv', index_col='TransactionID')\n\n\n# train_transaction = reduce_mem_usage(train_transaction)\n# test_transaction = reduce_mem_usage(test_transaction)\n\nsample_submission = pd.read_csv('..\/input\/ieee-fraud-detection\/sample_submission.csv', index_col='TransactionID')","c03a32b5":"train_transaction['hour'] = train_transaction['TransactionDT'].map(lambda x:(x\/\/3600)%24)\ntest_transaction['hour'] = test_transaction['TransactionDT'].map(lambda x:(x\/\/3600)%24)\ntrain_transaction['weekday'] = train_transaction['TransactionDT'].map(lambda x:(x\/\/(3600 * 24))%7)\ntest_transaction['weekday'] = test_transaction['TransactionDT'].map(lambda x:(x\/\/(3600 * 24))%7)","18888016":"cols = \"TransactionDT,TransactionAmt,ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14,M1,M2,M3,M4,M5,M6,M7,M8,M9\".split(\",\")\ntrain_test = train_transaction[cols].append(test_transaction[cols])\n\nfor col in \"ProductCD,card1,card2,card3,card4,card5,card6,addr1,addr2,C1,C2,C3,C4,C5,C6,C7,C8,C9,C10,C11,C12,C13,C14\".split(\",\"):\n    col_count = train_test.groupby(col)['TransactionDT'].count()\n    train_transaction[col+'_count'] = train_transaction[col].map(col_count)\n    test_transaction[col+'_count'] = test_transaction[col].map(col_count)\n#     print(col,test_transaction[col].map(lambda x:0 if x in s else 1).sum())\n\n\nfor col in \"card1,card2,card5,addr1,addr2\".split(\",\"):\n    col_count = train_test.groupby(col)['TransactionAmt'].mean()\n    train_transaction[col+'_amtcount'] = train_transaction[col].map(col_count)\n    test_transaction[col+'_amtcount'] = test_transaction[col].map(col_count)\n    col_count1 = train_test[train_test['C5'] == 0].groupby(col)['C5'].count()\n    col_count2 = train_test[train_test['C5'] != 0].groupby(col)['C5'].count()\n    train_transaction[col+'_C5count'] = train_transaction[col].map(col_count2) \/ (train_transaction[col].map(col_count1) + 0.01)\n    test_transaction[col+'_C5count'] = test_transaction[col].map(col_count2) \/ (test_transaction[col].map(col_count1) + 0.01)\n    \ndel train_test\n","b7e95570":"train_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/train_identity.csv', index_col='TransactionID')\ntest_identity = pd.read_csv('..\/input\/ieee-fraud-detection\/test_identity.csv', index_col='TransactionID')\n\n\n# train_test = train_identity.append(test_identity).fillna(-1)    \n# for col in \"id_01,id_02,id_03,id_04,id_05,id_06,id_07,id_08,id_09,id_10,id_12,id_13,id_14,id_15,id_16,id_17,id_18,id_19,id_20,id_21,id_22,id_23,id_24,id_25,id_26,id_27,id_28,id_29,id_30,id_31,id_32,id_33,id_34,id_35,id_36,id_37,id_38,DeviceType,DeviceInfo\".split(\",\"):\n#     col_count = train_test.groupby(col)['id_01'].count()\n#     train_identity[col+'_count'] = train_identity[col].fillna(-1).map(col_count)\n#     test_identity[col+'_count'] = test_identity[col].fillna(-1).map(col_count)\n    \n# del train_test","7e524b26":"\ncol_del = []\nfor i in range(339):\n    col = \"V\" + str(i+1)\n    s = train_transaction[col].fillna(0).map(lambda x:0 if x%1 == 0 else 1).sum()\n    if s > 100:\n        print(col,s)\n        col_del.append(col)\n#         del test_transaction[col],train_transaction[col]\n\n","ac65bc73":"train = train_transaction.merge(train_identity, how='left', left_index=True, right_index=True)\ntest = test_transaction.merge(test_identity, how='left', left_index=True, right_index=True)\n\nprint(train.shape)\nprint(test.shape)\n\ny_train = train['isFraud'].copy()\ndel train_transaction, train_identity, test_transaction, test_identity\n\n# Drop target, fill in NaNs\nX_train = train.drop('isFraud', axis=1)\nX_test = test.copy()\n\ndel train, test\n\n# Label Encoding\nfor f in X_train.columns:\n    if X_train[f].dtype=='object' or X_test[f].dtype=='object': \n        lbl = preprocessing.LabelEncoder()\n        lbl.fit(list(X_train[f].values) + list(X_test[f].values))\n        X_train[f] = lbl.transform(list(X_train[f].values))\n        X_test[f] = lbl.transform(list(X_test[f].values)) ","978f25f8":"%%time\n# From kernel https:\/\/www.kaggle.com\/gemartin\/load-data-reduce-memory-usage\n# WARNING! THIS CAN DAMAGE THE DATA \n\nX_train = reduce_mem_usage(X_train)\nX_test = reduce_mem_usage(X_test)\n\ndebug = False\nif debug:\n    split_pos = X_train.shape[0]*4\/\/5\n    y_test = y_train.iloc[split_pos:]\n    y_train = y_train.iloc[:split_pos]\n    X_test = X_train.iloc[split_pos:,:]\n    X_train = X_train.iloc[:split_pos,:]","82e73a13":"import gc\ngc.collect()","7dd5d101":"%%time\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfolds = 3\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed)\ny_preds = np.zeros(X_test.shape[0])\ni = 0\nfor tr_idx, val_idx in kf.split(X_train, y_train):\n    i+=1\n    clf = xgb.XGBClassifier(\n        n_estimators=700,\n        max_depth=9,\n        learning_rate=0.03,\n        subsample=0.9,\n        colsample_bytree=0.9,\n        tree_method='gpu_hist'\n    )\n    \n    X_tr = X_train.iloc[tr_idx, :]\n    y_tr = y_train.iloc[tr_idx]\n    clf.fit(X_tr, y_tr)\n    del X_tr\n    y_preds+= clf.predict_proba(X_test)[:,1] \/ folds\n    if debug:    \n        print(\"debug:\",roc_auc_score(y_test, clf.predict_proba(X_test)[:,1] \/ folds)) \n    del clf\n        \n    \n\nif debug:    \n    print(\"debug:\",roc_auc_score(y_test, y_preds))  \n\ngc.collect()","99558522":"features = [x for x in X_train.columns if x not in col_del]\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfolds = 3\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed)\ny_preds11 = np.zeros(X_test.shape[0])\ni = 0\nfor tr_idx, val_idx in kf.split(X_train, y_train):\n    i+=1\n    clf = xgb.XGBClassifier(\n        n_estimators=800,\n        max_depth=9,\n        learning_rate=0.03,\n        subsample=0.9,\n        colsample_bytree=0.9,\n        tree_method='gpu_hist'\n    )\n    \n    X_tr = X_train[features].iloc[tr_idx, :]\n    y_tr = y_train.iloc[tr_idx]\n    clf.fit(X_tr, y_tr)\n    del X_tr\n    y_preds11+= clf.predict_proba(X_test[features])[:,1] \/ folds\n    if debug:    \n        print(\"debug:\",roc_auc_score(y_test, clf.predict_proba(X_test[features])[:,1] \/ folds))   \n    del clf    \n    \ngc.collect()\nif debug:    \n    print(\"debug:\",roc_auc_score(y_test, y_preds11))  \n    print(\"debug:\",roc_auc_score(y_test, y_preds11*0.5 + y_preds*0.5))","8fffb575":"import lightgbm as lgb\ncate = [x for x in X_train.columns if (x == 'ProductCD' or  x.startswith(\"addr\") or x.startswith(\"card\") or \n                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") ]\nprint(cate)\nparams = {'application': 'binary',\n          'boosting': 'gbdt',\n          'metric': 'auc',\n          'max_depth': 16,\n          'learning_rate': 0.05,\n          'bagging_fraction': 0.9,\n          'feature_fraction': 0.9,\n          'verbosity': -1,\n          'lambda_l1': 0.1,\n          'lambda_l2': 0.01,\n          'num_leaves': 500,\n          'min_child_weight': 3,\n          'data_random_seed': 17,\n         'nthreads':4}\n\nearly_stop = 500\nverbose_eval = 30\nnum_rounds = 600\n# \nfolds = 3\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed)\ny_preds2 = np.zeros(X_test.shape[0])\nfeature_importance_df = pd.DataFrame()\ni = 0\nfor tr_idx, val_idx in kf.split(X_train, y_train):\n\n    \n    X_tr = X_train.iloc[tr_idx, :]\n    y_tr = y_train.iloc[tr_idx]\n    d_train = lgb.Dataset(X_tr, label=y_tr,categorical_feature = cate)\n    watchlist = []\n    if debug:\n        d_test = lgb.Dataset(X_test, label=y_test,categorical_feature = cate)\n        watchlist.append(d_test)\n    \n    \n    model = lgb.train(params,\n                      train_set=d_train,\n                      num_boost_round=num_rounds,\n                      valid_sets=watchlist,\n                      verbose_eval=verbose_eval)\n        \n    \n    y_preds2+= model.predict(X_test) \/ folds\n    \n    \n    fold_importance_df = pd.DataFrame()\n    fold_importance_df[\"Feature\"] = X_tr.columns\n    fold_importance_df[\"importance\"] = model.feature_importance()\n    fold_importance_df[\"fold\"] = i + 1\n    feature_importance_df = pd.concat([feature_importance_df, fold_importance_df], axis=0)\n    if debug:    \n        print(\"debug:\",roc_auc_score(y_test, model.predict(X_test) \/ folds))  \n    i+=1\n    del X_tr,d_train\n\nif debug:    \n    print(\"debug:\",roc_auc_score(y_test, y_preds2))  \n    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2)*0.5))  \n\n\n","f7bc6bfd":"if debug:    \n    print(\"debug:\",roc_auc_score(y_test, y_preds))  \n    print(\"debug:\",roc_auc_score(y_test, y_preds2))  \n    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2)*0.5)) ","fc86b136":"cols = (feature_importance_df[[\"Feature\", \"importance\"]]\n        .groupby(\"Feature\")\n        .mean()\n        .sort_values(by=\"importance\", ascending=False)[:100].index)\nprint(cols)\nbest_features = feature_importance_df.loc[feature_importance_df.Feature.isin(cols)]\n\nplt.figure(figsize=(14,25))\nsns.barplot(x=\"importance\",\n            y=\"Feature\",\n            data=best_features.sort_values(by=\"importance\",\n                                           ascending=False))\nplt.title('LightGBM Features (avg over folds)')\nplt.tight_layout()\nplt.savefig('lgbm_importances.png')","25bbce4b":"import catboost as cb\nfrom catboost import CatBoostClassifier,Pool\n\n\nfeatures = [x for x in X_train.columns]\n\ncate = [x for x in X_train.columns if (x == 'ProductCD' or x in ['card1','card2'] or x.startswith(\"addr\") or \n                                       x.endswith(\"domain\") or x.startswith(\"Device\")) and not x.endswith(\"count\") and not x == \"id_11\" ]\n\n# cate = []\nprint(cate)\nverbose_eval = 30\nnum_rounds = 800\n\nfolds = 3\nkf = KFold(n_splits = folds, shuffle = True, random_state=seed+1)\ny_preds3 = np.zeros(X_test.shape[0])\nfeature_importance_df = pd.DataFrame()\ni = 0\nfor tr_idx, val_idx in kf.split(X_train, y_train):\n\n    \n    X_tr = X_train[features].iloc[tr_idx, :].fillna(-1)\n    y_tr = y_train.iloc[tr_idx]\n    \n    model=cb.CatBoostClassifier(iterations=num_rounds,depth=14,learning_rate=0.04,loss_function='Logloss',eval_metric='Logloss'\n                                ,task_type = \"GPU\")\n    if debug:\n        model.fit(X_tr,y_tr,cat_features=cate,verbose_eval = 30)\n    else:\n        model.fit(X_tr,y_tr,cat_features=cate,verbose_eval = 30)\n        \n\n    del X_tr\n    y_preds3+= model.predict_proba(X_test[features].fillna(-1))[:,1] \/ folds\n    \n    \n    if debug:    \n        print(\"debug:\",roc_auc_score(y_test, model.predict_proba(X_test[features].fillna(-1))[:,1] \/ folds))  \n    i+=1\n\nif debug:    \n    print(\"debug:\",roc_auc_score(y_test, y_preds3))  \n    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds3)*0.5))  \n    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2 + y_preds3)*0.33))","6d41740c":"if debug:    \n    print(\"debug:\",roc_auc_score(y_test, y_preds))\n    print(\"debug:\",roc_auc_score(y_test, y_preds2))\n    print(\"debug:\",roc_auc_score(y_test, y_preds3))  \n    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds3)*0.5))  \n    print(\"debug:\",roc_auc_score(y_test, (y_preds + y_preds2 + y_preds3*0.5)*0.33))\n    print(\"debug:\",roc_auc_score(y_test, (y_preds11*0.5 + y_preds*0.5 + y_preds2 + y_preds3*0.5)*0.33))","8b931e00":"if not debug:   \n    sample_submission['isFraud'] = (y_preds11*0.5 + y_preds*0.5 + y_preds2 + y_preds3*0.5)*0.33\n    sample_submission.to_csv('simple_ensemble6.csv')\n","ee1e5408":"**Set debug = True to see validation metric**","11b1bf1c":"**LGB + XGB + CatBoost**\n\n**Holdout valid data. For me, it's a reliable method to test your features and models offline.\nThe lb score = valid score + 0.01**\n"}}