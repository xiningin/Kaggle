{"cell_type":{"f6e8674b":"code","ba82fed6":"code","08d72e2f":"code","e520a280":"code","c17b4e1e":"code","4e9c5d2b":"code","6f816842":"code","e7af9c56":"code","5008bcdb":"code","68db6c74":"code","01332a21":"code","393ec6ef":"code","98f6d140":"code","7882be72":"code","9432b7cf":"code","3af48751":"code","8a31075d":"code","a6f04b8b":"code","d73243c1":"code","92ea37e3":"code","9a2f463c":"code","048b848b":"code","d7b611da":"code","e4ff1ff4":"code","dc371750":"code","006f47c0":"code","791a60bc":"markdown"},"source":{"f6e8674b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","ba82fed6":"from numpy.random import permutation\nfrom sklearn import metrics\nimport lightgbm\nfrom sklearn.preprocessing import LabelEncoder","08d72e2f":"train = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nsub = pd.read_csv('..\/input\/sample_submission.csv')","e520a280":"# get xyz data for each atom\nstructures = pd.read_csv('..\/input\/structures.csv')","c17b4e1e":"# atomic properties\n# https:\/\/www.lenntech.com\/periodic-chart-elements\/\natomic_radius = {'H': 0.38, 'C': 0.77, 'N': 0.75, 'O': 0.73, 'F': 0.71, np.nan: 0}\natomic_number = {'H': 1, 'C': 6, 'N': 7, 'O': 8, 'F': 9, np.nan: 0}\natomic_mass = {'H': 1.0079, 'C': 12.0107, 'N': 14.0067, 'O': 15.9994, 'F': 18.9984, np.nan: 0}\nvanderwaalsradius = {'H': 120, 'C': 185, 'N': 154, 'O': 140, 'F': 135, np.nan: 0}\ncovalenzradius = {'H': 30, 'C': 77, 'N': 70, 'O': 66, 'F': 58, np.nan: 0}\nelectronegativity = {'H': 2.2, 'C': 2.55, 'N': 3.04, 'O': 3.44, 'F': 3.98, np.nan: 0}\nionization_energy = {'H': 13.5984, 'C': 11.2603, 'N': 14.5341, 'O': 13.6181, 'F': 17.4228, np.nan: np.inf}","4e9c5d2b":"def atom_props(df, suffix):\n    df['atomic_radius' + suffix] = df['atom_' + suffix].apply(lambda x: atomic_radius[x])\n    df['atomic_protons' + suffix] = df['atom_' + suffix].apply(lambda x: atomic_number[x])\n    df['atomic_mass' + suffix] = df['atom_' + suffix].apply(lambda x: atomic_mass[x])\n    df['vanderwaalsradius' + suffix] = df['atom_' + suffix].apply(lambda x: vanderwaalsradius[x])\n    df['covalenzradius' + suffix] = df['atom_' + suffix].apply(lambda x: covalenzradius[x])\n    df['electronegativity' + suffix] = df['atom_' + suffix].apply(lambda x: electronegativity[x])\n    df['ionization_energy' + suffix] = df['atom_' + suffix].apply(lambda x: ionization_energy[x])\n    return df","6f816842":"# atom_0, atom_1\ntrain = pd.merge(train, structures[['molecule_name', 'atom_index', 'atom']], how='left',\n                 left_on=['molecule_name', 'atom_index_0'],\n                 right_on=['molecule_name', 'atom_index']).rename({'atom': 'atom_0'}, axis=1)\ntrain = pd.merge(train, structures[['molecule_name', 'atom_index', 'atom']], how='left',\n                 left_on=['molecule_name', 'atom_index_1'],\n                 right_on=['molecule_name', 'atom_index']).rename({'atom': 'atom_1'}, axis=1)\ntest = pd.merge(test, structures[['molecule_name', 'atom_index', 'atom']], how='left',\n                 left_on=['molecule_name', 'atom_index_0'],\n                 right_on=['molecule_name', 'atom_index']).rename({'atom': 'atom_0'}, axis=1)\ntest = pd.merge(test, structures[['molecule_name', 'atom_index', 'atom']], how='left',\n                 left_on=['molecule_name', 'atom_index_1'],\n                 right_on=['molecule_name', 'atom_index']).rename({'atom': 'atom_1'}, axis=1)","e7af9c56":"# no. atoms in molecule\natom_cnt = structures['molecule_name'].value_counts().reset_index(level=0)\natom_cnt.rename({'index': 'molecule_name', 'molecule_name': 'atom_count'}, axis=1, inplace=True)\ntrain = pd.merge(train, atom_cnt, how='left', on='molecule_name')\ntest = pd.merge(test, atom_cnt, how='left', on='molecule_name')\ndel atom_cnt","5008bcdb":"# neighbours by index (replace the integer codes with the original atom chars)\ndef lr(df):\n    df['atom_index_0l'] = df['atom_index_0'].apply(lambda i: max(i - 1, 0))\n    tmp = df[['atom_index_0', 'atom_count']]\n    df['atom_index_0r'] = tmp.apply(lambda row: min(row['atom_index_0'] + 1, row['atom_count']), axis=1)\n    df = pd.merge(df, structures[['molecule_name', 'atom_index', 'atom']], how='left',\n                     left_on=['molecule_name', 'atom_index_0l'],\n                     right_on=['molecule_name', 'atom_index']).rename({'atom': 'atom_0l'}, axis=1)\n    df = pd.merge(df, structures[['molecule_name', 'atom_index', 'atom']], how='left',\n                     left_on=['molecule_name', 'atom_index_0r'],\n                     right_on=['molecule_name', 'atom_index']).rename({'atom': 'atom_0r'}, axis=1)\n    df['atom_index_1l'] = df['atom_index_1'].apply(lambda i: max(i - 1, 0))\n    tmp = df[['atom_index_1', 'atom_count']]\n    df['atom_index_1r'] = tmp.apply(lambda row: min(row['atom_index_1'] + 1, row['atom_count']), axis=1)\n    df = pd.merge(df, structures[['molecule_name', 'atom_index', 'atom']], how='left',\n                     left_on=['molecule_name', 'atom_index_1l'],\n                     right_on=['molecule_name', 'atom_index']).rename({'atom': 'atom_1l'}, axis=1)\n    df = pd.merge(df, structures[['molecule_name', 'atom_index', 'atom']], how='left',\n                     left_on=['molecule_name', 'atom_index_1r'],\n                     right_on=['molecule_name', 'atom_index']).rename({'atom': 'atom_1r'}, axis=1)\n    return df","68db6c74":"train = lr(train)\ntest = lr(test)","01332a21":"# get atomic properties of both atoms and their neighbours\ntrain = atom_props(train, '0')\ntrain = atom_props(train, '0l')\ntrain = atom_props(train, '0r')\ntrain = atom_props(train, '1')\ntrain = atom_props(train, '1l')\ntrain = atom_props(train, '1r')\ntest = atom_props(test, '0')\ntest = atom_props(test, '0l')\ntest = atom_props(test, '0r')\ntest = atom_props(test, '1')\ntest = atom_props(test, '1l')\ntest = atom_props(test, '1r')","393ec6ef":"# drop duplicate columns\ntrain.drop(['atom_index_x', 'atom_index_y'], axis=1, inplace=True)\ntest.drop(['atom_index_x', 'atom_index_y'], axis=1, inplace=True)","98f6d140":"# https:\/\/www.kaggle.com\/c\/champs-scalar-coupling\/discussion\/96655#latest-558745\ndef reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                c_prec = df[col].apply(lambda x: np.finfo(x).precision).max()\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max and c_prec == np.finfo(np.float16).precision:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max and c_prec == np.finfo(np.float32).precision:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","7882be72":"train = reduce_mem_usage(train)\ntest = reduce_mem_usage(test)","9432b7cf":"atom_feats = [v for v in train.columns if v not in ['id', 'molecule_name', 'atom_index_0', 'atom_index_1', 'type',\n       'scalar_coupling_constant', 'atom_0', 'atom_1', 'atom_index_0l',\n       'atom_count', 'atom_index_0r', 'atom_0l', 'atom_0r', 'atom_1l', 'atom_1r', 'atom_index_1l', 'atom_index_1r']]","3af48751":"# save these for future use\ntrain[['id'] + atom_feats].to_csv('train_atom_feats.csv', index=False)\ntest[['id'] + atom_feats].to_csv('test_atom_feats.csv', index=False)","8a31075d":"# encode label\nlbl = LabelEncoder()\nlbl.fit(list(train['type'].values) + list(test['type'].values))\ntrain['type'] = lbl.transform(list(train['type'].values))\ntest['type'] = lbl.transform(list(test['type'].values))","a6f04b8b":"# features for prediction\npred_vars = ['type'] + atom_feats","d73243c1":"# train-val split by molecule_name\nmolecule_names = pd.DataFrame(permutation(train['molecule_name'].unique()),columns=['molecule_name'])\nnm = molecule_names.shape[0]\nntrn = int(0.9*nm)\nnval = int(0.1*nm)\n\ntmp_train = pd.merge(train, molecule_names[0:ntrn], how='right', on='molecule_name')\ntmp_val = pd.merge(train, molecule_names[ntrn:nm], how='right', on='molecule_name')\n\nX_train = tmp_train[pred_vars]\nX_val = tmp_val[pred_vars]\ny_train = tmp_train['scalar_coupling_constant']\ny_val = tmp_val['scalar_coupling_constant']\ndel tmp_train, tmp_val","92ea37e3":"# heuristic parameters for LightGBM\nparams = { 'objective': 'regression_l1',\n           'learning_rate': 0.1,\n           'num_leaves': 1023,\n           'num_threads': -1,\n           'bagging_fraction': 0.5,\n           'bagging_freq': 1,\n           'feature_fraction': 0.9,\n           'lambda_l1': 10.0,\n           'max_bin': 255,\n           'min_child_samples': 15,\n           }","9a2f463c":"# categorical features for lightgbm\ncat_feats = ['type']","048b848b":"# datasets for lightgbm\ntrain_data = lightgbm.Dataset(X_train, label=y_train, categorical_feature=cat_feats)\nval_data = lightgbm.Dataset(X_val, label=y_val, categorical_feature=cat_feats)","d7b611da":"# training\nmodel = lightgbm.train(params,\n                       train_data,\n                       valid_sets=[train_data, val_data], verbose_eval=500,\n                       num_boost_round=4000,\n                       early_stopping_rounds=100)","e4ff1ff4":"# evaluation metric for validation\n# https:\/\/www.kaggle.com\/abhishek\/competition-metric\ndef metric(df, preds):\n    df[\"prediction\"] = preds\n    maes = []\n    for t in df.type.unique():\n        y_true = df[df.type==t].scalar_coupling_constant.values\n        y_pred = df[df.type==t].prediction.values\n        mae = np.log(metrics.mean_absolute_error(y_true, y_pred))\n        maes.append(mae)\n    return np.mean(maes)","dc371750":"# validation\npreds = model.predict(X_val)\nmetric(pd.concat([X_val, y_val], axis=1), preds)","006f47c0":"# submission\npreds_sub = model.predict(test[pred_vars])\nsub['scalar_coupling_constant'] = preds_sub\nsub.to_csv('submission_atom_feats.csv', index=False)","791a60bc":"In this kernel I use basic atomic properties to predict the scalar coupling constant. The LB score is very poor but the features may be useful for further feature engineering."}}