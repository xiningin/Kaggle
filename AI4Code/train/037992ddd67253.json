{"cell_type":{"d1e887da":"code","4bdc7cdd":"code","af7a1ec5":"code","7729c459":"code","1cbabd78":"code","d322e8b8":"code","4fa9239c":"code","3a319635":"code","a329b015":"code","b4f05be9":"code","5fbcfe1c":"code","69b75fcb":"code","cc5d227f":"code","b1984b69":"code","cef67475":"code","1035e99a":"code","a95ef204":"code","0b487322":"code","e61989dc":"code","c8e26a8f":"code","32233722":"code","e813d6d8":"code","04eaa3cc":"code","7860cc25":"code","d85fd51c":"code","515be74b":"code","e9d43407":"code","60b4fc1d":"code","d04bc97f":"code","a4ad5d94":"code","490fd388":"code","c08bf345":"code","272e3b5b":"code","67f38c55":"code","823b001b":"markdown","2622b8f9":"markdown","f4bf4714":"markdown","c55a969a":"markdown","6c667732":"markdown","c0bc8a83":"markdown","9984ebd6":"markdown","322adac1":"markdown","e7eec40e":"markdown","f015be88":"markdown","de05eabf":"markdown","5f8080c4":"markdown","d017dc46":"markdown","034f612f":"markdown","f14b46a8":"markdown","67c2fe84":"markdown","6aab2c52":"markdown","432b3cdf":"markdown","acb6a756":"markdown","77814e91":"markdown"},"source":{"d1e887da":"###### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nfrom collections import Counter\n\nfrom sklearn.model_selection import cross_val_score,cross_validate, train_test_split, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom sklearn.metrics import accuracy_score, confusion_matrix, balanced_accuracy_score, make_scorer\nfrom sklearn.ensemble import RandomForestClassifier, ExtraTreesClassifier\nfrom sklearn.linear_model import LogisticRegression\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier, plot_importance\n\nfrom tqdm import tqdm\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4bdc7cdd":"train = pd.read_csv(\"..\/input\/learn-together\/train.csv\", index_col='Id')\ntest = pd.read_csv(\"..\/input\/learn-together\/test.csv\", index_col='Id')\n\ny = train['Cover_Type'] # this is the target\nX = train.drop('Cover_Type', axis = 1)\nX_test = test.copy()\n\nprint('Train set shape : ', X.shape)\nprint('Test set shape : ', X_test.shape)","af7a1ec5":"X.head()","7729c459":"X_test.head()","1cbabd78":"print('Missing Label? ', y.isnull().any())\nprint('Missing train data? ', X.isnull().any().any())\nprint('Missing test data? ', X_test.isnull().any().any())","d322e8b8":"print (X.dtypes.value_counts())\nprint (X_test.dtypes.value_counts())","4fa9239c":"X.describe()","3a319635":"X.nunique()","a329b015":"X.drop(['Soil_Type15', 'Soil_Type7'], axis=1, inplace = True)\nX_test.drop(['Soil_Type15', 'Soil_Type7'], axis=1, inplace = True)","b4f05be9":"X_test.describe()","5fbcfe1c":"columns = X.columns","69b75fcb":"scaler = StandardScaler()\nX.loc[:,:] = scaler.fit_transform(X)\nX_test.loc[:,:] = scaler.transform(X_test)\n","cc5d227f":"X.describe()","b1984b69":"X_train,  X_val, y_train, y_val = train_test_split(X, y, train_size=0.8, random_state=1)\nprint(X_train.shape)\nprint(y_train.shape)\nprint(X_val.shape)\nprint(y_val.shape)","cef67475":"xgb= XGBClassifier( n_estimators=1000,  #todo : search for good parameters\n                    learning_rate= 0.5,  #todo : search for good parameters\n                    objective= 'binary:logistic', #this outputs probability,not one\/zero. should we use binary:hinge? is it better for the learning phase?\n                    random_state= 1,\n                    n_jobs=-1)","1035e99a":"param = {'n_estimators': [100, 500, 1000, 2000],\n         'learning_rate': [0.001, 0.01, 0.1, 0.5, 1]}\ngrider = GridSearchCV(xgb, param, n_jobs=-1, cv=5, scoring='accuracy', verbose=True)\n# res = grider.fit(X, y) #commented out as it takes some time, results shown below","a95ef204":"rf = RandomForestClassifier(n_estimators = 100, n_jobs=-1, random_state=1)\nparam = {'n_estimators': [20, 100, 500, 1000, 2000]}\ngrider_rf = GridSearchCV(rf, param, n_jobs=-1, cv=5, scoring='accuracy', verbose=True)\n# score_rf = grider_rf.fit(X, y)  #commented out, this takes quite some time. results shown below","0b487322":"xgb.fit(X=X_train, y=y_train,\n        eval_metric='merror', # merror: Multiclass classification error rate. It is calculated as #(wrong cases)\/#(all cases). \n        eval_set = [(X_train, y_train), (X_val, y_val)],\n        early_stopping_rounds = 100,\n        verbose = False\n       )\nxgb_val_pred = xgb.predict(X_val)\n#print(xgb_val_pred)","e61989dc":"rf = RandomForestClassifier(n_estimators = 1000, n_jobs=-1, random_state=1)\nrf.fit(X=X_train, y=y_train)\nrf_val_pred = rf.predict(X_val)","c8e26a8f":"extc = ExtraTreesClassifier(n_estimators = 1000, n_jobs=-1, random_state=1)\nextc.fit(X=X_train, y=y_train)\nextc_pred = extc.predict(X_val)","32233722":"lr = LogisticRegression( n_jobs=-1)\nlr.fit(X_train, y_train)\nlr_pred = lr.predict(X_val)","e813d6d8":"lbm_reg = LGBMClassifier() #to optimize param\nlbm_reg.fit(X_train, y_train)\nlbm_pred = lbm_reg.predict(X_val)","04eaa3cc":"print(' random forest Val accuracy : ', accuracy_score(rf_val_pred, y_val))\nprint(' XGBR Val accuracy : ',accuracy_score(xgb_val_pred, y_val))\nprint(' LR Val accuracy : ',accuracy_score(lr_pred, y_val))\nprint(' LBM Val accuracy : ',accuracy_score(lbm_pred, y_val))\nprint(' EXTC Val accuracy : ',accuracy_score(extc_pred, y_val))\n","7860cc25":"plt.subplots(2,2,figsize=(20,10))\nax=plt.subplot(1,2,1)\nsns.heatmap(confusion_matrix(y_val, rf_val_pred), annot=True)\nax.set(ylabel='True label', xlabel='RF label')\nax2=plt.subplot(1,2,2)\nsns.heatmap(confusion_matrix(y_val, xgb_val_pred), annot=True)\nax2.set(ylabel='True label', xlabel='XGB label')","d85fd51c":"plt.figure(figsize=(25,10))\nsns.barplot(y=xgb.feature_importances_, x=columns)","515be74b":"extc.fit(X,y)\npreds_test = extc.predict(X_test)\npreds_test.shape","e9d43407":"preds_test","60b4fc1d":"count = { 1: 0.37062,\n 2: 0.49657,\n 3: 0.05947,\n 4: 0.00106,\n 5: 0.05623864624345282, #ongoing check...\n 6: 0.04450142430004312,\n 7: 0.05375584033702544}\nweight = [count[x]\/(sum(count.values())) for x in range(1,7+1)]\nclass_weight_lgbm = {i: v for i, v in enumerate(weight)}","d04bc97f":"def imbalanced_accuracy_score(y_true, y_pred):\n    return accuracy_score(y_true, y_pred, sample_weight=[weight[x] for x in y_true-1])\n\nimbalanced_accuracy_scorer = make_scorer(imbalanced_accuracy_score, greater_is_better=True)\n\ndef imbalanced_cross_validate(clf, X, y, cfg_args={}, fit_params={}, cv=5):\n    return cross_validate(clf_inst, X, y, scorer= imbalanced_accuracy_scorer, cv=cv, n_jobs=-1, fit_params=fit_params )","a4ad5d94":"# xgb= XGBClassifier( n_estimators=1000,  #todo : search for good parameters\n#                     learning_rate= 0.5,  #todo : search for good parameters\n#                     objective= 'binary:logistic', #this outputs probability,not one\/zero. should we use binary:hinge? is it better for the learning phase?\n#                     random_state= 1,\n#                     n_jobs=-1)\n# param = {'n_estimators': [500, 750, 1000],\n#          'learning_rate': [0.1, 0.3, 0.5],\n#          'max_depth': [6, 10, 25, 50]}\n# xgb_grider = GridSearchCV(xgb, param, \n#                           n_jobs=-1, \n#                           cv=5, \n#                           scoring=imbalanced_accuracy_scorer, \n#                           verbose=2)\n# res = xgb_grider.fit(X, y) \n# print(xgb_grider.best_score_)\n# print(xgb_grider.best_params_)","490fd388":"# lgb= LGBMClassifier( n_estimators=1000,  #todo : search for good parameters\n#                     learning_rate= 0.5,  #todo : search for good parameters\n#                     objective= 'binary:logistic', #this outputs probability,not one\/zero. should we use binary:hinge? is it better for the learning phase?\n#                     random_state= 1,\n#                     n_jobs=-1)\n# param = {'n_estimators': [500, 750, 1000],\n#          'learning_rate': [0.1, 0.3, 0.5],\n#          'max_depth': [6, 10, 25, 50]}\n# lgb_grider = GridSearchCV(lgb, param, \n#                           n_jobs=-1, \n#                           cv=5, \n#                           scoring=imbalanced_accuracy_scorer, \n#                           verbose=2)\n# res = lgb_grider.fit(X, y) \n# print(lgb_grider.best_score_)\n# print(lgb_grider.best_params_)","c08bf345":"rf= RandomForestClassifier( n_estimators=1000, \n                            min_samples_split = 2, \n                            min_samples_leaf = 1,\n                            bootstrap = False,\n                            random_state=2019, \n                            class_weight=count)\nparam = {'n_estimators': [500, 750, 1000, 1500, 2000],\n         'max_features': ['sqrt', 0.3, None],\n         'max_depth': [100, 250, 500, None]}\nrf_grider = GridSearchCV(rf, param, \n                          n_jobs=-1, \n                          cv=5, \n                          scoring=imbalanced_accuracy_scorer, \n                          verbose=2)\nres = rf_grider.fit(X, y) #commented out as it takes some time, results shown below\nprint(rf_grider.best_score_)\nprint(rf_grider.best_params_)\n","272e3b5b":"ext= ExtraTreesClassifier( n_estimators=1000, \n                            min_samples_split = 2, \n                            min_samples_leaf = 1,\n                            bootstrap = False,\n                            random_state=2019, \n                            class_weight=count)\nparam = {'n_estimators': [500, 750, 1000, 1500, 2000],\n         'max_features': ['sqrt', 0.3, None],\n         'max_depth': [100, 250, 500, None]}\next_grider = GridSearchCV(ext, param, \n                          n_jobs=-1, \n                          cv=5, \n                          scoring=imbalanced_accuracy_scorer, \n                          verbose=2)\nres = ext_grider.fit(X, y) #commented out as it takes some time, results shown below\nprint(ext_grider.best_score_)\nprint(ext_grider.best_params_)\n","67f38c55":"# Save test predictions to file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'Cover_Type': preds_test})\noutput.to_csv('submission.csv', index=False)\noutput.head()","823b001b":"https:\/\/www.kaggle.com\/arateris\/probing-stats\/\nThis is to know the distribution of the labels in the (public) test set. This allows to get a better accuracy check and validation during tuning\/training phase.","2622b8f9":"## TODO: Logistic regression, AdaBoost","f4bf4714":"## Extra Trees ","c55a969a":"**print(grider_rf.best_score_)\nprint(grider_rf.best_params_)\n0.7854497354497354\n{'n_estimators': 2000}","6c667732":"#Model setup\nTry classic XGB","c0bc8a83":"Note above accuracy does not count for label imbalance in the test set !","9984ebd6":"#Import datasets","322adac1":"No missing data, everything in numeric. \nSoil_type and Wilderness_area are categorial data already put as one hot encoded.","e7eec40e":"Note : large difference between train and test size. Will need to check input distributions.","f015be88":"## Random Forest","de05eabf":"# Searching model param with test distributions","5f8080c4":"best param set: {'learning_rate': 0.5, 'n_estimators': 1000}; best_score = 0.7625","d017dc46":"## XGBoost","034f612f":"TODO:\n- Check and remove outliers\n-- Should we remove columns with too few data (e.g. in soil types) or merge them ?\n- Scale to normal-ish distributions\n- Check correlations and linearities","f14b46a8":"Check for data types and missing values","67c2fe84":"output:\n\n0.6808577538090633\n\n{'learning_rate': 0.1, 'max_depth': 10, 'n_estimators': 500}","6aab2c52":"Output:\n0.6739884552078786\n{'learning_rate': 0.5, 'max_depth': 25, 'n_estimators': 500}","432b3cdf":"Many values have large numbers, std and means. Will need for scaling (ideally, we want normal distributions with (0,1))\nHowever, distributions are not very similar. \n- Should we scale based on all data? test data only? train only?  (my intuition:on train only, need to check)\n- Do we need to scale binary data ?","acb6a756":"## Light GBM","77814e91":"Soil_Type15 and Soil_Type7 have only one value. meaning these types of soils didnt appear in the training set.\n-> drop these column.\n"}}