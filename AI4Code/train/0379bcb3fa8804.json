{"cell_type":{"e191f016":"code","04091b8f":"code","5fef1698":"code","0179ded5":"code","4ca47688":"code","61148b4e":"code","023cd1ed":"code","0959390f":"code","11272a6b":"code","eb011876":"code","ae6936ac":"code","0d1a5939":"code","6852f20d":"code","ef7d8ccf":"code","a705b950":"code","9ae79602":"code","7c4948f8":"code","a3fff1ae":"code","bdc6153a":"code","5b42fd8b":"code","202c17ed":"markdown","c75f35cf":"markdown","52a9e792":"markdown","4a387166":"markdown","06e9af4c":"markdown","177adbe5":"markdown"},"source":{"e191f016":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import optim\nfrom torchvision import datasets, models\nimport torchvision.transforms as transforms\nfrom datetime import datetime\nfrom torch.utils import data\nimport random","04091b8f":"#transform the images to the default input shape 224x224\ntransform = transforms.Compose([transforms.Resize([224, 224]), transforms.ToTensor()])\ndata_set = datasets.ImageFolder(root = '..\/input\/facemask-detection-dataset-20000-images', transform = transform)\nn = len(data_set)\nn_test = int( n * .2 )\nn_train = n - n_test\n","5fef1698":"# train, test split\ntrain_set, test_set = data.random_split(data_set, (n_train, n_test))","0179ded5":"train_loader = torch.utils.data.DataLoader(train_set, batch_size = 128, shuffle = True)\ntest_loader = torch.utils.data.DataLoader(test_set, batch_size = 128, shuffle = True)","4ca47688":"#Select 10 random images of each class.\npath = '..\/input\/facemask-detection-dataset-20000-images\/'\nnum_files_per_folder = [len(files) for root, dirs, files in os.walk('..\/input\/facemask-detection-dataset-20000-images') if len(files) > 0]\nfolders = [dirs for root, dirs, files in os.walk('..\/input\/facemask-detection-dataset-20000-images') if len(dirs) > 0][0]\nfilenames = [os.listdir('..\/input\/facemask-detection-dataset-20000-images\/' + folder) for folder in folders]\nfiles = [np.random.choice(files, 10, replace = False) for files, num_files in zip(filenames, num_files_per_folder)]","61148b4e":"fig, ax = plt.subplots(2, 4, figsize = (15, 8))\nfor row in range(2):\n    category = folders[row]\n    ax_row = ax[row]\n    for column in range(4):\n        img = plt.imread(path + category + '\/' + files[row][column])\n        ax_column = ax_row[column]\n        ax_column.imshow(img, cmap='gray')\n        if column == 0:\n            ax_column.set_ylabel(category, size = 'large')\n        ax_column.set_xticklabels([])\n        ax_column.set_yticklabels([])","023cd1ed":"#downloading the pretrained model\nmodel = models.vgg16(pretrained = True)","0959390f":"print(model)","11272a6b":"from IPython.display import YouTubeVideo\n\nYouTubeVideo('5T-iXNNiwIs', width=500, height=300)","eb011876":"n_inputs = model.classifier[6].in_features\nclassification_layer = nn.Linear(n_inputs, len(train_set.dataset.classes))\nmodel.classifier[6] = classification_layer","ae6936ac":"n_inputs, len(train_set.dataset.classes)","0d1a5939":"for param in model.features.parameters():\n    param.requires_grad = False","6852f20d":"criterion = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters())","ef7d8ccf":"device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\nprint(f'Device: {device}')\nmodel.to(device)","a705b950":"def training_loop(loader, epoch):\n    \n    running_loss = 0.\n    running_accuracy = 0.\n    \n    for i, data in enumerate(loader):\n        inputs, labels = data\n        inputs, labels = inputs.to(device), labels.to(device)\n\n        optimizer.zero_grad()        \n\n        outputs = model(inputs)\n        \n        loss = criterion(outputs, labels)\n        loss.backward()\n        \n        optimizer.step()\n\n        running_loss += loss.item()\n\n\n        predicted = torch.argmax(F.softmax(outputs, dim = 1), dim = 1)\n        \n        \n        equals = predicted == labels\n        \n        \n        accuracy = torch.mean(equals.float())\n        running_accuracy += accuracy\n\n        if i %50 == 0:\n            \n            print(f'Epoch: {epoch+1} | loop {i+1}\/{len(loader)} Loss: {loss.item():.5f} - Accuracy: {accuracy:.5f}')\n        \n\n    print(f'>>>>> Epoch: {epoch+1} Loss: {running_loss\/len(loader):.5f} - Accuracy: {running_accuracy\/len(loader):.5f}')","9ae79602":"%%time \nfor epoch in range(2):\n    print('Training...')\n    training_loop(train_loader, epoch)\n    model.eval()\n    print('Validation...')\n    training_loop(test_loader, epoch)\n    model.train()","7c4948f8":"images, labels = next(iter(test_loader))\nmodel.eval()\npredicted = model(images.to(device)).cpu()\npredicted = torch.argmax(F.softmax(predicted, dim = 1), dim = 1)\nlabels, predicted = labels.detach().numpy(), predicted.detach().numpy()","a3fff1ae":"images = images.permute(0, 2, 3, 1).numpy()\nimages.shape","bdc6153a":"idx_to_class = {k: v for v, k in test_set.dataset.class_to_idx.items()}\nlabels = [idx_to_class[label] for label in labels]\npredicted = [idx_to_class[label] for label in predicted]\n\nlabels, predicted","5b42fd8b":"#Plotting the results.\nfig, ax = plt.subplots(6, 5, figsize = (15, 18))\ni = 0\nfor row in range(6):\n    ax_row = ax[row]\n    for column in range(5):\n        ax_column = ax_row[column]\n        ax_column.imshow(images[i])\n        ax_column.set_xticklabels([])\n        ax_column.set_yticklabels([])\n        col = 'blue' if labels[i] == predicted[i] else 'red'\n        ax_column.set_title(f'Label:{labels[i]}, \\nPredicted:{predicted[i]}', color = col)\n        i += 1 \n        plt.tight_layout()","202c17ed":"# Mask Detection with Pytorch and vgg16.\n![](https:\/\/i.imgur.com\/bxYKqZa.png)\n\n## Dataset\nThe original dataset was made by [Prasoon Kottarathil\n](https:\/\/www.kaggle.com\/prasoonkottarathil) All Images are Generated Using Style GAN-2, 10,000 HD images in  each Folder With mask and without mask. The dataset that i'll be working with is an edited version, with smaller images that were converted to grayscale made by [Jathin Pranav Singaraju\n](https:\/\/www.kaggle.com\/pranavsingaraju).\nFor this problem am using pythorch and vgg16 that is pretrained.\n","c75f35cf":"If you are a portuguese speaker. I would like to recommend this pytorch course:\n[Deep Learning de A \u00e0 Z com PyTorch e Python\n](https:\/\/www.udemy.com\/course\/formacao-deep-learning-pytorch-python\/)<br>\nI also would like to recommend this amazing pytorch course:\n[PyTorch: Deep Learning and Artificial Intelligence\n](https:\/\/www.udemy.com\/course\/pytorch-deep-learning\/)","52a9e792":"## Importing libraries","4a387166":"## Fine Tuning\nfor more information about fine tuning, please watch this video:","06e9af4c":"## VGG16 Architecture\n![](https:\/\/miro.medium.com\/max\/470\/1*3-TqqkRQ4rWLOMX-gvkYwA.png)","177adbe5":"With only 1 epoch we already reach 100% accuracy, because the dataset don't have any variance, all the images are almost equal, perphabs with a dataset with differente images we won't reach this accuracy."}}