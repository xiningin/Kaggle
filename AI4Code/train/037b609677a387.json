{"cell_type":{"e553f583":"code","68653f5c":"code","d4b8b238":"code","90f005e5":"code","fa1a23f2":"code","55009842":"code","e0f05b68":"code","5ce409d3":"code","d11e81e7":"code","2b137030":"code","9896a09b":"code","2e9283e4":"markdown","d4ed5df2":"markdown","128ca975":"markdown","c10f4d45":"markdown","fa562959":"markdown"},"source":{"e553f583":"import tensorflow as tf","68653f5c":"!git clone https:\/\/github.com\/tensorflow\/models\n    \n# Check out a certain commit to ensure that future changes in the TF ODT API codebase won't affect this notebook.\n!cd models && git checkout ac8d06519","d4b8b238":"%%bash\ncd models\/research\n\n# Compile protos.\nprotoc object_detection\/protos\/*.proto --python_out=.\n\n# Install TensorFlow Object Detection API.\n# Note: I fixed the version of some dependencies to make it work on Kaggle notebook. In particular:\n# * scipy==1.6.3 to avoid the missing GLIBCXX_3.4.26 error\n# * tensorflow to 2.6.0 to make it compatible with the CUDA version preinstalled on Kaggle.\n# When Kaggle notebook upgrade to TF 2.7, you can use the default setup.py script:\n# cp object_detection\/packages\/tf2\/setup.py .\nwget https:\/\/storage.googleapis.com\/odml-dataset\/others\/setup.py\npip install -q --user .\n\n# Test if the Object Dectection API is working correctly\npython object_detection\/builders\/model_builder_tf2_test.py","90f005e5":"# Create a label map to map between label index and human-readable label name.\n\nlabel_map_str = \"\"\"item {\n  id: 1\n  name: 'COTS'\n}\"\"\"\n\nwith open('label_map.pbtxt', 'w') as f:\n  f.write(label_map_str)","fa1a23f2":"!wget http:\/\/download.tensorflow.org\/models\/object_detection\/tf2\/20200711\/efficientdet_d1_coco17_tpu-32.tar.gz\n!tar -xvzf efficientdet_d1_coco17_tpu-32.tar.gz","55009842":"eg1 = \"efficientdet_d1_coco17_tpu-32\/pipeline.config\"\nfile1 = open(eg1, \"r\") \nFileContent = file1.read()\nprint(FileContent)","e0f05b68":"from string import Template\n\nconfig_file_template = \"\"\"\n# SSD with EfficientNet-b0 + BiFPN feature extractor,\n# shared box predictor and focal loss (a.k.a EfficientDet-d0).\n# See EfficientDet, Tan et al, https:\/\/arxiv.org\/abs\/1911.09070\n# See Lin et al, https:\/\/arxiv.org\/abs\/1708.02002\n# Initialized from an EfficientDet-D0 checkpoint.\n#\n# Train on GPU\n\nmodel {\n  ssd {\n    num_classes: 1\n    image_resizer {\n      keep_aspect_ratio_resizer {\n        min_dimension: 640\n        max_dimension: 640\n        pad_to_max_dimension: true\n      }\n    }\n    feature_extractor {\n      type: \"ssd_efficientnet-b1_bifpn_keras\"\n      conv_hyperparams {\n        regularizer {\n          l2_regularizer {\n            weight: 3.9999998989515007e-05\n          }\n        }\n        initializer {\n          truncated_normal_initializer {\n            mean: 0.0\n            stddev: 0.029999999329447746\n          }\n        }\n        activation: SWISH\n        batch_norm {\n          decay: 0.9900000095367432\n          scale: true\n          epsilon: 0.0010000000474974513\n        }\n        force_use_bias: true\n      }\n      bifpn {\n        min_level: 3\n        max_level: 7\n        num_iterations: 4\n        num_filters: 88\n      }\n    }\n    box_coder {\n      faster_rcnn_box_coder {\n        y_scale: 1.0\n        x_scale: 1.0\n        height_scale: 1.0\n        width_scale: 1.0\n      }\n    }\n    matcher {\n      argmax_matcher {\n        matched_threshold: 0.5\n        unmatched_threshold: 0.5\n        ignore_thresholds: false\n        negatives_lower_than_unmatched: true\n        force_match_for_each_row: true\n        use_matmul_gather: true\n      }\n    }\n    similarity_calculator {\n      iou_similarity {\n      }\n    }\n    box_predictor {\n      weight_shared_convolutional_box_predictor {\n        conv_hyperparams {\n          regularizer {\n            l2_regularizer {\n              weight: 3.9999998989515007e-05\n            }\n          }\n          initializer {\n            random_normal_initializer {\n              mean: 0.0\n              stddev: 0.009999999776482582\n            }\n          }\n          activation: SWISH\n          batch_norm {\n            decay: 0.9900000095367432\n            scale: true\n            epsilon: 0.0010000000474974513\n          }\n          force_use_bias: true\n        }\n        depth: 88\n        num_layers_before_predictor: 3\n        kernel_size: 3\n        class_prediction_bias_init: -4.599999904632568\n        use_depthwise: true\n      }\n    }\n    anchor_generator {\n      multiscale_anchor_generator {\n        min_level: 3\n        max_level: 7\n        anchor_scale: 4.0\n        aspect_ratios: 1.0\n        aspect_ratios: 2.0\n        aspect_ratios: 0.5\n        scales_per_octave: 3\n      }\n    }\n    post_processing {\n      batch_non_max_suppression {\n        score_threshold: 9.99999993922529e-09\n        iou_threshold: 0.6\n        max_detections_per_class: 100\n        max_total_detections: 100\n      }\n      score_converter: SIGMOID\n    }\n    normalize_loss_by_num_matches: true\n    loss {\n      localization_loss {\n        weighted_smooth_l1 {\n        }\n      }\n      classification_loss {\n        weighted_sigmoid_focal {\n          gamma: 1.5\n          alpha: 0.25\n        }\n      }\n      classification_weight: 1.0\n      localization_weight: 1.0\n    }\n    encode_background_as_zeros: true\n    normalize_loc_loss_by_codesize: true\n    inplace_batchnorm_update: true\n    freeze_batchnorm: false\n    add_background_class: false\n  }\n}\ntrain_config {\n  batch_size: 2\n  data_augmentation_options {\n    random_horizontal_flip {\n    }\n  }\n  data_augmentation_options {\n    random_scale_crop_and_pad_to_square {\n      output_size:640\n      scale_min: 0.10000000149011612\n      scale_max: 2.0\n    }\n  }\n  sync_replicas: true\n  optimizer {\n    momentum_optimizer {\n      learning_rate {\n        cosine_decay_learning_rate {\n          learning_rate_base: 0.003\n          total_steps:  $training_steps\n          warmup_learning_rate: 0.00001\n          warmup_steps: $warmup_steps\n        }\n      }\n      momentum_optimizer_value: 0.8999999761581421\n    }\n    use_moving_average: false\n  }\n  fine_tune_checkpoint: \"efficientdet_d1_coco17_tpu-32\/checkpoint\/ckpt-0\"\n  num_steps:  $training_steps\n  startup_delay_steps: 0.0\n  replicas_to_aggregate: 8\n  max_number_of_boxes: 100\n  unpad_groundtruth_tensors: false\n  fine_tune_checkpoint_type: \"detection\"\n  use_bfloat16: true\n  fine_tune_checkpoint_version: V2\n}\ntrain_input_reader: {\n  label_map_path: \"label_map.pbtxt\"\n  tf_record_input_reader {\n    input_path: \"..\/input\/cots-tensorflow-dataset-5fold\/dataset\/cots_train-?????-of-00004\"\n  }\n}\n\neval_config: {\n  metrics_set: \"coco_detection_metrics\"\n  use_moving_averages: false\n  batch_size: 1;\n}\n\neval_input_reader: {\n  label_map_path: \"label_map.pbtxt\"\n  shuffle: false\n  num_epochs: 1\n  tf_record_input_reader {\n    input_path: \"..\/input\/cots-tensorflow-dataset-5fold\/dataset\/cots_val-?????-of-00004\"\n  }\n}\n\"\"\"","5ce409d3":"#Prepare pipeline config\nTRAINING_STEPS = 3000\nWARMUP_STEPS = 1000\nPIPELINE_CONFIG_PATH='pipeline.config'\n\npipeline = Template(config_file_template).substitute(\n    training_steps=TRAINING_STEPS, warmup_steps=WARMUP_STEPS)\n\nwith open(PIPELINE_CONFIG_PATH, 'w') as f:\n    f.write(pipeline)","d11e81e7":"MODEL_DIR='cots_efficientdet_d1'\n!mkdir {MODEL_DIR}\n!python models\/research\/object_detection\/model_main_tf2.py \\\n    --pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n    --model_dir={MODEL_DIR} \\\n    --alsologtostderr","2b137030":"!python models\/research\/object_detection\/model_main_tf2.py \\\n    --pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n    --model_dir={MODEL_DIR} \\\n    --checkpoint_dir={MODEL_DIR} \\\n    --eval_timeout=0 \\\n    --alsologtostderr","9896a09b":"!python models\/research\/object_detection\/exporter_main_v2.py \\\n    --input_type image_tensor \\\n    --pipeline_config_path={PIPELINE_CONFIG_PATH} \\\n    --trained_checkpoint_dir={MODEL_DIR} \\\n    --output_directory={MODEL_DIR}\/output","2e9283e4":"## Prepare for Training","d4ed5df2":"## Export model","128ca975":"## Train model","c10f4d45":"## Install Object Detection API","fa562959":"## Evaluation"}}