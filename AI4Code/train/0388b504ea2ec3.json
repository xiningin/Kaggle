{"cell_type":{"03403a9f":"code","f332f946":"code","d5f1ef77":"code","7b55a042":"code","10ab956a":"code","516a733d":"code","f3aa8d6b":"code","4cf49b9d":"code","7ac74e17":"code","434a7e02":"code","609485d6":"code","157030ea":"code","a21596d0":"code","e2e32c84":"code","0b3c1221":"code","2e44a6d4":"code","5be2bcd9":"code","adb4df09":"code","905cf78d":"code","5de8ed1a":"code","aa165fea":"code","5ea72e61":"code","ccaa8363":"code","1ba2aec8":"code","d0016db6":"code","ca0640d1":"code","c9158e31":"code","dcf04740":"code","06880938":"code","fdac6180":"code","0d8718bb":"code","ad67a5e0":"code","068c0378":"code","de7591c1":"code","50046da2":"code","38f9869b":"code","6c3ad132":"code","6288ba20":"code","27c7b11e":"code","1544a443":"code","06971fb8":"code","e06bb154":"markdown","d7f67987":"markdown","a32b8dbc":"markdown","be46b311":"markdown","cda7801c":"markdown","383f876f":"markdown","61870a4f":"markdown","17ba3dcd":"markdown","996d39b3":"markdown","a25edc85":"markdown","c1a75d4c":"markdown"},"source":{"03403a9f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f332f946":"adult_data = pd.read_csv('..\/input\/adult_train.csv')","d5f1ef77":"adult_data.head()","7b55a042":"adult_data.info()","10ab956a":"sns.pairplot(adult_data, hue = 'Target', markers= ['o','s'])","516a733d":"plt.figure(figsize=(9,6))\nsns.countplot(x='Target', hue='Sex', data=adult_data)","f3aa8d6b":"adult_data['Workclass'].value_counts()","4cf49b9d":"plt.figure(figsize=(9,6))\nsns.countplot(x='Target', hue='Education', data=adult_data ,palette='rainbow')","7ac74e17":"adult_data.groupby(['Country','Target'])[['Target']].count().head(20)","434a7e02":"adult_data['Target']=[0 if i==' <=50K' else 1 for i in adult_data['Target']]","609485d6":"#assing X as a Dataframe of features and y as a Series of outcome variable\n\nX = adult_data.drop('Target', axis = 1)\ny = adult_data.Target","157030ea":"X.info()","a21596d0":"# I will decide which categorical data variables I want to use in model \nfor col_name in X.columns:\n    if X[col_name].dtypes == 'object':\n        unique_categorical = len(X[col_name].unique())\n        print(\"Feature '{col_name}' has {unique_categorical} unique categories\".format(col_name=col_name, unique_categorical = unique_categorical))","e2e32c84":"X['Country'] = ['United-States' if i == ' United-States' else 'Other' for i in X['Country']]\nX['Country'].value_counts().sort_values(ascending = False)","0b3c1221":"X.columns","2e44a6d4":"X.isnull().sum().sort_values(ascending=False)","5be2bcd9":"#create a list of features to dummy\ntodummy_list = ['Workclass', 'Education','Martial_Status', 'Occupation', 'Relationship', 'Race', 'Sex', 'Country']","adb4df09":"# Function to dummy all the categorical variables used for modeling\n\ndef dummy_df(df,todummy_list):\n    for x in todummy_list:\n        dummies = pd.get_dummies(df[x],prefix=x, dummy_na=False)\n        df = df.drop(x,1)\n        df = pd.concat([df,dummies],axis = 1)\n    return df","905cf78d":"X = dummy_df(X,todummy_list)","5de8ed1a":"X.isnull().sum().sort_values(ascending = False)","aa165fea":"# Handling missing data\nfrom sklearn.preprocessing import Imputer\nimp = Imputer(missing_values = 'NaN', strategy = 'median',axis = 0)\nimp.fit(X)\nX = pd.DataFrame(data = imp.transform(X),columns = X.columns)\n\nX.isnull().sum().sort_values(ascending = False)","5ea72e61":"def find_outliers_tukey(x):\n    q1 = np.percentile(x,25)\n    q3 = np.percentile(x,75)\n    iqr = q3 - q1\n    floor = q1 - 1.5*iqr\n    ceiling = q3 + 1.5*iqr\n    outlier_indices = list(x.index[(x<floor) | (x>ceiling)])\n    outlier_values = list(x[outlier_indices])\n    \n    return outlier_indices,outlier_values","ccaa8363":"tukey_indices,tukey_values = find_outliers_tukey(X['Age'])\nnp.sort(tukey_values)","1ba2aec8":"from itertools import combinations\nfrom sklearn.preprocessing import PolynomialFeatures\n\ndef add_interactions(df):\n    combos = list(combinations(list(df.columns),2))\n    colnames = list(df.columns) + ['_'.join(x) for  x in combos]\n    \n    poly = PolynomialFeatures(interaction_only=True, include_bias=False)\n    df = poly.fit_transform(df)\n    df = pd.DataFrame(df)\n    df.columns = colnames\n    \n    noint_indicies = [i for i, x in enumerate(list((df == 0).all())) if x]\n    df = df.drop(df.columns[noint_indicies], axis= 1)\n    \n    return df","d0016db6":"X = add_interactions(X)","ca0640d1":"X.head() # as you can se there are may many features now.","c9158e31":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=150)\nX_pca = pd.DataFrame(pca.fit_transform(X))","dcf04740":"X_pca.head()","06880938":"from sklearn.model_selection import train_test_split","fdac6180":"Xtrain,Xtest,ytrain,ytest = train_test_split(X_pca,y, test_size=0.1,random_state=101)","0d8718bb":"Xtrain.shape","ad67a5e0":"import sklearn.feature_selection\n\nselect = sklearn.feature_selection.SelectKBest(k=50)\nselected_features = select.fit(Xtrain,ytrain)\nindices_selected = selected_features.get_support(indices=True)\ncolnames_selected = [Xtrain.columns[i] for i in indices_selected] \n\n\nXtrain_selected = Xtrain[colnames_selected]\nXtest_selected = Xtest[colnames_selected]","068c0378":"colnames_selected","de7591c1":"Xtrain_selected","50046da2":"from sklearn.ensemble import RandomForestClassifier ","38f9869b":"rf= RandomForestClassifier(n_estimators=100)\nrf.fit(Xtrain_selected,ytrain)","6c3ad132":"rf_prediction = rf.predict(Xtest_selected)","6288ba20":"from sklearn.metrics import roc_auc_score\nprint(roc_auc_score(ytest, rf_prediction))","27c7b11e":"from sklearn.metrics import confusion_matrix, classification_report","1544a443":"print(confusion_matrix(ytest, rf_prediction))","06971fb8":"print(classification_report(ytest, rf_prediction))","e06bb154":"There are so much way to find outlier values. Today we are going to one.\n* **Tukey IQR**\n\n\n## Tukey IQR","d7f67987":"We are ready to create machine learning models.","a32b8dbc":"We'll try to predict to salary that it's last column that called Target. Firstly we should think about the data. Which parameters are useful for your model that you'll create. We'll make visualization and cleaning before create machine learning model.","be46b311":"## Outlier Detection","cda7801c":"# Feature Engineering","383f876f":"# Random Forest Classifier","61870a4f":"\nHello !\n\nI am going to try to tell about machine learning algorithm and mathematics behind machine learning models. Firstly I'll make data analysis, data visualization and data cleaning.\n\nLet's start! ","17ba3dcd":"# Exploratory Data Analysis","996d39b3":"This model is not good !! We have to improve this algorithm.","a25edc85":"## Dimesionality reduction using PCA\n\nPCA is a tecnique that transforms a dataset of many features into pricipal components that summarize the variance that underlies the data","c1a75d4c":"We'll examine the data."}}