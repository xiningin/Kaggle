{"cell_type":{"676558b0":"code","69c2c445":"code","9d7af58c":"code","38036bc6":"code","6b506d02":"code","448b3247":"code","498e6ba1":"code","6105da03":"code","bca907e0":"code","97da3ec8":"code","6cfbbabd":"code","c752c423":"code","21542b56":"code","062de2a8":"code","a8a30f2d":"code","325b2fe4":"code","ffc754c9":"markdown","d493665a":"markdown","d2b44a5b":"markdown","388c4cc5":"markdown","a24f7d3b":"markdown","3587e58b":"markdown","ab2c43f8":"markdown","928b3ae2":"markdown","efb3a46c":"markdown"},"source":{"676558b0":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nsns.set_style('darkgrid')\n\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import LabelBinarizer\n\nfrom nltk.tokenize import word_tokenize\nimport string\nfrom nltk.corpus import stopwords    \nfrom nltk.stem.porter import PorterStemmer\nfrom bs4 import BeautifulSoup\n\nfrom keras.preprocessing import text,sequence\nimport re,string,unicodedata","69c2c445":"real = pd.read_csv('..\/input\/fake-and-real-news-dataset\/True.csv')\nfake = pd.read_csv('..\/input\/fake-and-real-news-dataset\/Fake.csv')","9d7af58c":"real.head()","38036bc6":"fake.head()","6b506d02":"#create a target column of 0 or 1 if the new is fake or real \nreal['Label']=0\nfake['Label']=1\n\n#Using conactenate function of pandas :\ndata=pd.concat([real,fake])\ndata.sample(5)\n\n","448b3247":"#check the shape of data\nnp.shape(data)","498e6ba1":"#check for null values --> no null values found!\ndata.isnull().sum()","6105da03":"#How many of the given news are fake and how many of them are real?\nsns.countplot(data.Label)","bca907e0":"#how many unqiue titles are there. Are any of the titles repeated?\ndata.title.count()","97da3ec8":"data.subject.value_counts()","6cfbbabd":"plt.figure(figsize=(10,10))\nchart=sns.countplot(x='subject',hue='Label',data=data,palette='muted')\nchart.set_xticklabels(chart.get_xticklabels(),rotation=90,fontsize=10)","c752c423":"\nX = data['text']+ \" \" + data['title']\nY = data['Label']\nprint(X)\nprint(Y)","21542b56":"stop_words=set(stopwords.words('english'))\npunctuation=list(string.punctuation)\nstop_words.update(punctuation)\n\ndef clean_text_data(text):\n    text = BeautifulSoup(text,\"html.parser\").get_text()\n    text = re.sub('\\[[^]]*\\]','',text)\n    text = re.sub(r'http\\S+','',text)\n    final_text = []\n    for i in text.split():\n        if i.strip().lower() not in stop_words:\n            final_text.append(i.strip())\n    return \" \".join(final_text)  \n\n\nX = X.apply(clean_text_data)\nprint(X)","062de2a8":"#split the train and test data\nX_train,X_test,y_train,y_test=train_test_split(X,Y, test_size=0.2,random_state=0)\n\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntfidf_vectorizer=TfidfVectorizer(max_features=5000,ngram_range=(1,3))\n\n\ntfidf_train=tfidf_vectorizer.fit_transform(X_train) \ntfidf_test=tfidf_vectorizer.transform(X_test)\n\n\n","a8a30f2d":"from sklearn.naive_bayes import MultinomialNB\nclassifier=MultinomialNB(alpha=0.1)\n\nclassifier.fit(tfidf_train, y_train)\npred = classifier.predict(tfidf_test)\n\nprint(f'Accuracy: {round((accuracy_score(y_test, pred))*100,2)}%')\n\ncm = confusion_matrix(y_test, pred)\n\ncm=pd.DataFrame(cm,index=['Fake','Not Fake'],columns=['Fake','Not Fake'])\n\n\nplt.figure(figsize=(5,5))\nsns.heatmap(cm,cmap=\"Blues\",linecolor='black',linewidth=1,annot=True,fmt='',xticklabels=['Fake','Not Fake'],yticklabels=['Fake','Not Fake'])\nplt.xlabel('Actual')\nplt.ylabel('Predicted')","325b2fe4":"from sklearn.linear_model import PassiveAggressiveClassifier\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nclf = PassiveAggressiveClassifier(max_iter=80)\n\nclf.fit(tfidf_train,y_train)\n\ny_pred=clf.predict(tfidf_test)\nscore=accuracy_score(y_test,y_pred)\nprint(f'Accuracy: {round(score*100,2)}%')\n\ncm=confusion_matrix(y_test,y_pred)\ncm=pd.DataFrame(cm,index=['Fake','Not Fake'],columns=['Fake','Not Fake'])\n\n\nplt.figure(figsize=(5,5))\nsns.heatmap(cm,cmap=\"Blues\",linecolor='black',linewidth=1,annot=True,fmt='',xticklabels=['Fake','Not Fake'],yticklabels=['Fake','Not Fake'])\nplt.xlabel('Actual')\nplt.ylabel('Predicted')","ffc754c9":"# Building our MultinomialNB Algorithm\u00b6\n","d493665a":"How many subjects are there ? We can see that using value_counts()","d2b44a5b":"![](http:\/\/)Now we will place all of the required columns in one and delete all the not-so-required columns.","388c4cc5":"We will be removing punctuation , stopwords,URLS, html tags from our text data. <br>\nFor this we shall use beautifulsoup and re library which we imported earlier.","a24f7d3b":"## TfidfVectorizer","3587e58b":"<a id='clean_data'><\/a>\n## Cleaning the data","ab2c43f8":"# Passive Aggressive Classifier Algorithm\n","928b3ae2":"<a id='load_data'><\/a>\n# Loading the data ","efb3a46c":"<a id='visualize_data'><\/a>\n## Visualizing the data "}}