{"cell_type":{"5ecf10d8":"code","fe7972c4":"code","0d5a2ea1":"code","8325c867":"code","29fa5511":"code","dc3c093c":"code","30f93d1e":"code","89c039c8":"code","aa026ff8":"code","ae330980":"code","671cec59":"code","0c736251":"code","c9316148":"code","57964760":"code","62c21e60":"code","4b8756ba":"code","085fe89d":"code","6e603590":"code","8b6cd504":"code","01b60a39":"code","69fe25e0":"code","dededea3":"code","4032c6b5":"code","21f3dcaa":"code","f5c5e6ca":"code","095edf4c":"code","bee56c28":"code","448f4ba5":"code","8fefc7f9":"code","cdbfc038":"code","09904f43":"code","3e2ed736":"code","74a7c12d":"code","77cce7e6":"code","c79f86e8":"code","649a8355":"code","2a04c86a":"code","db634cf5":"code","9b9ca7f4":"code","927fee77":"code","ef3d4ce7":"code","04f4ebb9":"code","e1ef1f38":"code","be1f190a":"code","5ba54b00":"code","ad720053":"code","34bb1649":"code","f11cb1fd":"code","ecf34c8f":"code","d33e2354":"code","dc3b029c":"code","231b915c":"code","d32f0299":"code","e3961820":"code","4d72d93f":"code","8bc617fd":"code","60489f00":"code","8c394953":"code","6d839b90":"code","749f06df":"code","0da8a623":"code","f3485215":"code","504119c2":"code","3d332a50":"code","d3b22367":"code","9a94bbdf":"code","3e30594a":"code","99d22733":"code","82cc6620":"code","8809ab56":"code","4bcc813a":"code","56a87a91":"code","37418908":"code","0edeb3e5":"code","004714f7":"code","b23183e0":"code","3893893f":"code","05103fff":"code","d24c89b4":"code","08b5f9d8":"code","2216db3a":"code","e3919ab2":"code","21ce3988":"code","e677a27b":"code","df482d5b":"code","15e6693b":"code","c405896a":"code","51d99e7b":"code","6a2d4105":"code","50cf9772":"code","5111d27b":"code","9111a45b":"code","da24756c":"code","aeedbc56":"code","16ffc0e9":"code","b1840002":"code","4a8d0ff9":"code","07a521e5":"code","2a8be2e8":"code","987fd3a1":"code","02dd8b9b":"code","a9f6d4a7":"code","945e29d3":"code","8121ef2e":"code","7d4fcc17":"code","fd8a996c":"code","f2aaa05f":"code","ed759e3c":"code","d1a8e9e5":"code","2f3ac397":"code","5b6ead90":"code","b86a4f8c":"code","6d6acd88":"code","3429b8db":"code","b0b1429c":"code","382ba947":"code","ebe82381":"code","d6d97833":"code","1e418d42":"code","9ca03d81":"code","df5fccdb":"code","cd86640b":"code","929502d9":"code","3c3974f5":"code","6e656f4f":"code","19eaa9ad":"code","09e272fa":"code","74c0a511":"code","87abc32b":"code","bc938f3a":"code","17813605":"code","ec26ac98":"code","ffd1b597":"code","d4dceba6":"code","ae3cdec4":"code","51fcded1":"code","098d9047":"code","29db8e67":"code","c81f7200":"code","5fa265ea":"code","dc98781c":"code","26f1704d":"code","4178f7c8":"code","d7289646":"code","3837fe3e":"code","8c46da5c":"code","9d9a1382":"code","59f0e1cb":"code","f92eae4d":"code","66b0f537":"code","1ad6ce49":"code","8c2ccfe1":"code","3fc385cc":"code","05a9c5ec":"code","c8f892a7":"code","189a97d8":"code","5512a01b":"code","1d6be4b3":"code","f3897788":"code","33f9cb6c":"code","580637ab":"code","05ad2ae1":"code","f84fa1be":"code","dea8419e":"code","2a9ceb53":"code","ac6d81e2":"code","be67a861":"code","b5579454":"code","ef210d45":"code","bf3ad075":"code","f5811c73":"code","69fe299b":"code","abe245fd":"code","535d0e27":"code","d51c54aa":"code","f45a2eeb":"code","84b25836":"code","f7bb6716":"code","17611a38":"code","85db3540":"code","dc9f3915":"code","43b3a204":"code","55b8e07d":"code","29c2bb9c":"code","a8141ef4":"code","7de1b768":"code","71a7527d":"code","586c7d49":"code","98d0fbc7":"code","0469e378":"code","ddd27ad6":"code","47d5174e":"code","74babc52":"code","65439b2c":"code","a2924f5a":"code","218dc876":"code","be32b2d7":"code","66fa865a":"code","bdfd2daf":"code","a1f2ec50":"code","3b899d0a":"code","eb123e4d":"code","42b66ec5":"code","d75c02cd":"code","8a10927a":"code","64ed1e97":"code","90426462":"code","cefb0680":"code","19d6b140":"code","3ec5611e":"code","ba9e65ae":"code","2531a9f3":"code","a6631f6e":"code","ed757cf6":"code","104e6976":"code","5eeae083":"code","7fe98624":"code","02a8c562":"code","ed7685c8":"code","568c5c52":"code","7f27cdbe":"code","fcc4515d":"code","449cb9f3":"code","2ab85f00":"code","16e32a50":"code","50c07c4e":"code","d4644be0":"code","e586a138":"code","ecba1c12":"code","bf1358a2":"code","95a7d2a3":"code","4208b76b":"code","218e86e8":"code","5665f33a":"code","1f122cff":"code","ffb5fcf9":"code","3744ab0d":"code","69541f84":"code","cbe2a8a5":"markdown","d4a1f27f":"markdown","77cd7846":"markdown","245bb876":"markdown","880627ab":"markdown","73db1228":"markdown","d9d6b112":"markdown","eab2b42d":"markdown","c830bed7":"markdown","3582821a":"markdown","13b5c4a3":"markdown","90774b53":"markdown","56500f22":"markdown","d7b1288c":"markdown","74a4fba6":"markdown","dc1cc771":"markdown","ab0e0bfb":"markdown","632d8932":"markdown","0582028e":"markdown","7e51db73":"markdown","72ecb748":"markdown","de1d223b":"markdown","231f98a1":"markdown","0747223b":"markdown","38b00b97":"markdown","8da610e8":"markdown","4b526496":"markdown","ca96cc78":"markdown","8f2e1365":"markdown","4aa098df":"markdown","31960dcd":"markdown","7f71ddf2":"markdown","87d8d790":"markdown","d0842646":"markdown","de7154b5":"markdown","fa488fcd":"markdown","9e8399f5":"markdown","0ceba2f8":"markdown","287a8e24":"markdown","d6c65e52":"markdown","786edaa3":"markdown","1382920a":"markdown","68d89f8a":"markdown","39ef1c1d":"markdown","728ed383":"markdown","4b5ed8b9":"markdown","e7276c6b":"markdown","44c3a084":"markdown","26326c9b":"markdown","cc14eaaa":"markdown","acfbc969":"markdown","e9dc732f":"markdown","e8b35310":"markdown","106fcdaf":"markdown","90aba227":"markdown","60538e73":"markdown","d5a04116":"markdown","1705c9dd":"markdown","6aa7be6f":"markdown","f7419b94":"markdown","ade7a7d1":"markdown","f9241e3f":"markdown","51efc965":"markdown","7ffa2474":"markdown","efff06d5":"markdown","652b143a":"markdown","4d069caa":"markdown","2077664e":"markdown","2c13d47c":"markdown","c4465742":"markdown","e966cd36":"markdown","caeeaebd":"markdown","19121c2f":"markdown","fee8eb47":"markdown","0dba1162":"markdown","e1fdaf0d":"markdown","a22f585a":"markdown","858ac02d":"markdown","e32cc189":"markdown","4a5905d2":"markdown","8baeda56":"markdown","9c7e2d5f":"markdown","61a97207":"markdown","34979dd1":"markdown","14e8175c":"markdown","023ac33c":"markdown","e0c93a53":"markdown","e95bd15b":"markdown","69d9dc4f":"markdown","3c1c4e95":"markdown","7ae2ce7d":"markdown","3cfc5304":"markdown","d7c5d92b":"markdown","c2b136aa":"markdown","8081e706":"markdown","9c8be031":"markdown","3ba4f7a8":"markdown","4f1e4953":"markdown","e33e83be":"markdown","e4bb84c5":"markdown","49992399":"markdown"},"source":{"5ecf10d8":"import pandas as pd # As gives the naming as \"pd\"","fe7972c4":"pd.Series([10,20,30,40,50]) # It returns both indexes and values","0d5a2ea1":"s= pd.Series([10,20,30,40,50])","8325c867":"type(s)","29fa5511":"s.axes # Indexes of series can be seen by \"axes\" attribute","dc3c093c":"s.dtype #Variable Type ","30f93d1e":"s.size #Variable size","89c039c8":"s.ndim #One-dimensional array","aa026ff8":"s.values #We can use \"values\" attribute if we want to see just values","ae330980":"s.head(2) #We can reach first values by head() function. Specify number of rows you want to see. Default is 5.","671cec59":"s.tail(3) #We can reach last values by tail() function. Specify number of rows you want to see. Default is 5.","0c736251":"s[1] #Series can be indexed with selecting square brackets []. Indexes starts with 0.","c9316148":"pd.Series([13,214,210,440,53])","57964760":"pd.Series([13,214,210,440,53],index=[4,6,7,3,87]) #We can specify indexes.","62c21e60":"s=pd.Series([13,214,210,440,53],index=[\"first\",\"second\",\"third\",\"fourth\",\"fifth\"]) #We can also specify string indexes.\ns","4b8756ba":"s[\"third\"]","085fe89d":"ages = {\"Jonh\": 42, \"Julia\": 53, \"Dan\": 21}\nages","6e603590":"pd.Series(ages) #We can create series with dictionaries.The keys of the dictionary become the labels.","8b6cd504":"pd.Series(ages,index=[\"Jonh\",\"Dan\"])","01b60a39":"import numpy as np","69fe25e0":"a = np.array([10,24,36,47,85])\na","dededea3":"pd.Series(a)","4032c6b5":"s1 = pd.Series([2,3,55,2,6,44])\ns2 = pd.Series([421,325,3426,2,1,4,42])","21f3dcaa":"pd.concat([s1,s2])","f5c5e6ca":"s1 = pd.Series([2,3,55,2,6,44])\ns1","095edf4c":"s1[1]","bee56c28":"s1[0:2]","448f4ba5":"s1[:3]","8fefc7f9":"s1[4:]","cdbfc038":"s=pd.Series([13,214,210,440,53],index=[\"first\",\"second\",\"third\",\"fourth\",\"fifth\"]) #We can also specify string indexes.\ns","09904f43":"s[\"first\"]","3e2ed736":"s.index #We can reach indexes of a serie with index attribute","74a7c12d":"s.keys #We can reach keys(values) of a serie with keys attribute","77cce7e6":"list(s.items()) #We can see values and keys paired with items() function","c79f86e8":"s1 = pd.Series([2,3,55,2,6,44])\ns1","649a8355":"3 in s1 #Look if s1 contains 3","2a04c86a":"34 in s1 #Look if s1 contains 34","db634cf5":"s1 = pd.Series([2,3,55,2,6,44])\ns1","9b9ca7f4":"s1[[2,4]]","927fee77":"s1[[1,5]]","ef3d4ce7":"s=pd.Series([13,214,210,440,53],index=[\"first\",\"second\",\"third\",\"fourth\",\"fifth\"]) #We can also specify string indexes.\ns","04f4ebb9":"s[[\"first\",\"third\"]]","e1ef1f38":"s1 = pd.Series([2,3,55,2,6,44])\ns1","be1f190a":"s1[0] =4 #We can assign new values","5ba54b00":"s1","ad720053":"pd.DataFrame({'Name': [\"Mellon\",\"Josh\", \"Mary\"], 'Age': [17,34,45]}) #It can be created directly","34bb1649":"dic = {'Name': [\"Mellon\",\"Josh\", \"Mary\"], 'Age': [17,34,45]} #It can be created by external dic\ndataframe = pd.DataFrame(dic)\ndataframe","f11cb1fd":"dataframe[\"Age\"] #We can access age column with this way","ecf34c8f":"dataframe.Age #We can also access age column with this way but it gives error if there is same method as the same name as .(column_name)","d33e2354":"l = [23,35423,25235,325,235,75]\ndf = pd.DataFrame(l,columns=[\"variable\"]) #We can create dataframes also with this way\ndf # In general,dataframes are named as \"df\"","dc3b029c":"names = [\"John\",\"Mike\",\"Julia\",\"Anastacia\"]\ndf = pd.DataFrame(names,columns=[\"Names\"]) \ndf","231b915c":"import numpy as np\narr = np.array([5,6,7,3,2,1,2,42,5]).reshape(3,3,)\narr","d32f0299":"pd.DataFrame(arr,columns=[\"Variable_1\",\"Variable_2\",\"Variable_3\"])","e3961820":"df = pd.DataFrame(arr,columns=[\"Variable_1\",\"Variable_2\",\"Variable_3\"])\ndf","4d72d93f":"df.axes #It shows axes names","8bc617fd":"df.shape #It shows shape of a dataframe","60489f00":"df.ndim #It shows dimension of a dataframe","8c394953":"df.size #It shows size of a dataframe","6d839b90":"df.columns","749f06df":"df.index","0da8a623":"df.values #It shows values of a dataframe","f3485215":"df","504119c2":"df.columns #We can reach column of a dataframe with this way","3d332a50":"df.columns = (\"Var1\",\"Var2\",\"Var3\") #We can change column names of a dataframe with this way","d3b22367":"df","9a94bbdf":"df = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Ana\",\"Yohanna\"],\"Income\": [5000,7000,9000,6000],\n                   \"Age\":[35,19,26,32]})\ndf","3e30594a":"df.iloc[0]","99d22733":"#Fancy Indexing\ndf.iloc[[0,2]]","82cc6620":"#We can also select spesific rows of a column\ndf.iloc[[0,2],2]","8809ab56":"df.iloc[[0,2],[1,2]]","4bcc813a":"df.iloc[1:3]","56a87a91":"df.iloc[1:3,2] #It gets just second column-age","37418908":"df","0edeb3e5":"df.loc[0]","004714f7":"df.loc[[0,2],\"Age\"] #We can reach spesific columns with name of column","b23183e0":"df = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Ana\",\"Yohanna\"],\"Income\": [5000,7000,9000,6000],\n                   \"Age\":[35,19,26,32]},index=[\"a\",\"b\",\"c\",\"d\"])\ndf","3893893f":"df.loc[\"a\"]","05103fff":"#Fancy indexing\ndf.loc[[\"a\",\"d\"]]","d24c89b4":"df.loc[\"b\":]","08b5f9d8":"df.loc[\"c\":,\"Income\"] #It gets just income column after index c","2216db3a":"df.iloc[0]","e3919ab2":"df = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Ana\",\"Yohanna\"],\"Income\": [5000,7000,9000,6000],\n                   \"Age\":[35,19,26,32]})\ndf","21ce3988":"df.Age #We can access age column with this way but it gives error if there is same method as the same name as .(column_name)","e677a27b":"df[\"Age\"] #We can also access with this way","df482d5b":"df[\"Age\"][0] #We can select spesific row of a column with this way","15e6693b":"df = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Ana\",\"Yohanna\"],\"Income\": [5000,7000,9000,6000],\n                   \"Age\":[35,19,26,32]})\ndf","c405896a":"df.iloc[0] = [\"Berkay\",\"6000\",\"24\"] #We assign new values to a spesific row","51d99e7b":"df","6a2d4105":"df = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Ana\",\"Yohanna\"],\"Employee_Number\": [11286474,17588462,26735655,18653472],\n                   \"Income\": [5000,7000,9000,6000],\"Age\":[35,19,26,32]})\ndf","50cf9772":"df=df.set_index(\"Employee_Number\") #We assigned Employee number as index values\ndf","5111d27b":"df.loc[11286474]","9111a45b":"df = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Ana\",\"Yohanna\"],\"Employee_Number\": [11286474,17588462,26735655,18653472],\n                   \"Income\": [5000,7000,9000,6000],\"Age\":[35,19,26,32]})\ndf","da24756c":"df.set_index(\"Employee_Number\",inplace=True) #Inplace argument assign new indexes directly\ndf","aeedbc56":"df","16ffc0e9":"df.reset_index(inplace=True)\ndf","b1840002":"df = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Ana\",\"Yohanna\"],\"Employee_Number\": [11286474,17588462,26735655,18653472],\n                   \"Income\": [5000,7000,9000,6000],\"Age\":[35,19,26,32]},index=[21,43,32,1])\ndf","4a8d0ff9":"df.sort_index(inplace=True)\ndf","07a521e5":"employees = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Julia\",\"Sergio\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\"],\n                          \"Income\":[4800,5200,6600,5700],\n                          \"Age\":[24,28,33,41]})\nemployees","2a8be2e8":"employees[\"Department\"] == \"IT\"","987fd3a1":"filt = employees[\"Department\"] == \"IT\"\nemployees[filt]","02dd8b9b":"employees[employees[\"Department\"] == \"IT\"] #or we can directly write it.","a9f6d4a7":"employees.loc[employees[\"Department\"] == \"Human Resources\",\"Income\"]","945e29d3":"employees","8121ef2e":"employees[employees[\"Income\"]>5500]","7d4fcc17":"employees[employees[\"Age\"]>30]","fd8a996c":"employees[(employees[\"Age\"]>30) & (employees[\"Income\"]>5000)]","f2aaa05f":"employees[(employees[\"Name\"]==\"Sergio\") & (employees[\"Department\"]==\"IT\")] #There is no satisfying value.","ed759e3c":"employees[(employees[\"Age\"]>30) | (employees[\"Income\"]>5000)]","d1a8e9e5":"employees[(employees[\"Name\"]==\"Sergio\") | (employees[\"Department\"]==\"IT\")]","2f3ac397":"employees","5b6ead90":"employees[~(employees[\"Income\"]>5300)]","b86a4f8c":"employees[~(employees[\"Age\"]<35)]","6d6acd88":"employees","3429b8db":"employees.filter(items=[\"Department\",\"Age\"])","b0b1429c":"employees.filter(regex='e$', axis=1) #Columns end with \"e\"","382ba947":"employees = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Julia\",\"Sergio\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\"],\n                          \"Income\":[4800,5200,6600,5700],\n                          \"Age\":[24,28,33,41]})\nemployees","ebe82381":"employees.append({\"Name\": \"Berkay\"},ignore_index=True) #It adds automatically to the end of dataframe. But we need to add all values, otherwise it gives nan.","d6d97833":"employees.append({\"Name\":\"Berkay\",\"Department\":\"Finance\",\"Income\":6000,\"Age\":24},ignore_index=True)","1e418d42":"employees.drop(index=2)","9ca03d81":"employees[employees[\"Age\"]>30]","df5fccdb":"employees.drop(index=employees[employees[\"Age\"]>30].index)","cd86640b":"employees","929502d9":"employees[\"Experience\"] = [5,6,2,8]","3c3974f5":"employees","6e656f4f":"employees.drop(columns=[\"Experience\",\"Income\"])","19eaa9ad":"employees.drop([\"Experience\",\"Income\"],axis=1) #Axis 1 means columns","09e272fa":"#Fancy indexing gives same result\nemployees[[\"Name\",\"Department\",\"Age\"]]","74c0a511":"employees = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Julia\",\"Sergio\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\"],\n                          \"Income\":[4800,5200,6600,5700],\n                          \"Age\":[24,28,33,41]})\nemployees","87abc32b":"employees2 = pd.DataFrame({\"Name\":[\"Berkay\",\"Michael\",\"Christy\",\"Feder\"],\n                          \"Department\":[\"Finance\",\"Marketing\",\"Human Resources\",\"Law\"],\n                          \"Income\":[5700,6900,8700,6300],\n                          \"Age\":[29,33,29,44]})\nemployees2","bc938f3a":"pd.concat([employees,employees2]) #It will merge without changing indexes","17813605":"pd.concat([employees,employees2],ignore_index=True) #It will update indexes","ec26ac98":"class1= pd.DataFrame({\"Name\":[\"Mike\",\"Ana\",\"Janiel\"],\"Student Number\":[32212354,9364859,847937250],\"GPA\":[3.40,2.78,3.01]})\nclass1","ffd1b597":"class2= pd.DataFrame({\"Name\":[\"Kristina\",\"Michael\",\"Arhun\"],\"Student Number\":[738273948,422413342,938674938],\"Age\":[21,24,19]})\nclass2","d4dceba6":"pd.concat([class1,class2]) #Every column is not sanme","ae3cdec4":"pd.concat([class1,class2],join=\"inner\") #Inner join just gets intersection of dataframes","51fcded1":"pd.concat([class1,class2],join=\"outer\") #Full outer join just gets all of dataframes","098d9047":"pd.merge(class1,class2,how=\"left\") #Left join just gets all of rows of the left dataframe","29db8e67":"pd.merge(class1,class2,how=\"right\") #Right join just gets all of rows of the right dataframe","c81f7200":"class1= pd.DataFrame({\"Name\":[\"Kristina\",\"Michael\",\"Arhun\"],\"Student Number\":[738273948,422413342,938674938],\n                      \"Department\":[\"Informatics\",\"Computer Science\",\"Management\"]})\nclass1","5fa265ea":"lectures = pd.DataFrame({\"Department\":[\"Informatics\",\"Computer Science\",\"Management\",\"Informatics\",\"Computer Science\",\"Management\"],\n                         \"Lectures\":[\"MIS\",\"Linear Algebra\",\"Introduction to Finance\",\"Data Mining\",\"IT Project Management\",\"Marketing 101\"]})\nlectures","dc98781c":"pd.merge(class1,lectures)","26f1704d":"employees.append(employees2,ignore_index=True)","4178f7c8":"employees = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Julia\",\"Sergio\",\"Julia\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\",\"Finance\"],\n                          \"Income\":[4800,5200,6600,5700,7200],\n                          \"Age\":[24,28,33,41,22]})\nemployees","d7289646":"employees.sort_values(by=\"Age\") #We sort it by age column","3837fe3e":"employees.sort_values(by=\"Age\",ascending=False) #We sort it by descending age","8c46da5c":"employees.sort_values(by=[\"Name\",\"Income\"]) #It will first sort by name and then it will compare income column","9d9a1382":"employees.sort_values(by=[\"Name\",\"Age\"],ascending=[True,False])\n#We can also sort one column ascending order and descending with other column","59f0e1cb":"employees[\"Income\"].nlargest(2)","f92eae4d":"employees[\"Income\"].nsmallest(2)","66b0f537":"employees = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Julia\",\"Sergio\",\"Julia\",\"Michael\",\"Sarath\",\"Jakub\",\"Chris\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\",\"Finance\",\"Marketing\",\"IT\",\"Human Resources\",\"Law\"],\n                          \"Income\":[4800,5200,6600,5700,7200,8400,7700,4200,9400],\n                          \"Age\":[24,28,33,41,22,46,31,27,39],\n                          \"Experience\":[2,5,9,17,1,24,10,6,13]})\nemployees","1ad6ce49":"employees.count() #It count elements by columns","8c2ccfe1":"employees[\"Department\"].value_counts() #It count values in a column. It just work with series!","3fc385cc":"employees.mean() #Compute mean of each column if it's numeric","05a9c5ec":"employees[\"Income\"].mean() # We can also compute mean of a spesific column","c8f892a7":"employees.median() #Compute median of each column if it's numeric","189a97d8":"employees[\"Income\"].median() # We can also compute median of a spesific column","5512a01b":"employees.sum() #Compute sum of each column if it's numeric","1d6be4b3":"employees[\"Income\"].sum() # We can also compute sum of a spesific column","f3897788":"employees.min() #Compute mminimum value of each column","33f9cb6c":"employees[\"Age\"].min() # We can also compute minimum value of a spesific column","580637ab":"employees.max() #Compute maximum value of each column","05ad2ae1":"employees[\"Age\"].max() # We can also compute maximum value of a spesific column","f84fa1be":"employees.std() #Compute standart deviation of each column if it's numeric","dea8419e":"employees[\"Age\"].std() # We can also compute standart deviation of a spesific column","2a9ceb53":"employees.var() #Compute variance of each column if it's numeric","ac6d81e2":"employees[\"Age\"].var() # We can also compute variance of a spesific column","be67a861":"employees.describe() #It computes a quick summary of values per group if it's numeric.","b5579454":"employees.describe().T #We can also see transpoze of it to see better.","ef210d45":"employees.sem() #It computes standard error of the mean values for each column if it's numeric.","bf3ad075":"employees = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Julia\",\"Sergio\",\"Julia\",\"Michael\",\"Sarath\",\"Jakub\",\"Chris\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\",\"Finance\",\"Marketing\",\"IT\",\"Human Resources\",\"Law\"],\n                          \"Income\":[4800,5200,6600,5700,7200,8400,7700,4200,9400],\n                          \"Age\":[24,28,33,41,22,46,31,27,39],\n                          \"Experience\":[2,5,9,17,1,24,10,6,13]})\nemployees","f5811c73":"employees.groupby(\"Department\") #It will create an object","69fe299b":"employees_departments = employees.groupby(\"Department\")\nemployees_departments.get_group(\"IT\") #We can get the rows that employee is working in IT department.","abe245fd":"employees[employees[\"Department\"]==\"IT\"]","535d0e27":"employees.groupby(\"Department\").mean() #We can get mean of every department.","d51c54aa":"employees.groupby(\"Department\").mean()[\"Income\"] #We can also get mean of each department by a spesific column.","f45a2eeb":"employees.groupby(\"Department\")[\"Experience\"].sum()","84b25836":"employees.groupby(\"Department\").mean()[\"Age\"] #Mean of age by each department","f7bb6716":"employees.groupby(\"Department\")[\"Age\"].describe() #We also can see with describe","17611a38":"employees.groupby(\"Department\")[\"Income\"].agg([\"mean\",\"max\",\"median\"]) \n#We get mean, max and median of Income in each department.","85db3540":"employees.groupby(\"Department\")[\"Income\"].agg([\"mean\",\"max\",\"median\"]).loc[\"Finance\"] \n#We get mean, max and median of Income in Finance department.","dc9f3915":"employees.groupby(\"Department\").aggregate([\"max\",\"min\"])\n#We get max and min values in each department.","43b3a204":"employees.groupby(\"Department\").aggregate({\"Income\": \"mean\",\"Age\":\"max\"})\n#We can get different statistics for different columns thanks to dictionary.","55b8e07d":"def salary_increase(x):\n    return x+1000","29c2bb9c":"employees[\"Income\"] #Current salaries","a8141ef4":"employees[\"Income\"].transform(salary_increase) # It increase every salary.","7de1b768":"employees[\"Income\"].transform(lambda x: x+1000)","71a7527d":"employees[\"Income\"].transform(lambda x: (x-x.mean())\/x.std()) #Standartizing","586c7d49":"employees[[\"Income\",\"Age\"]].transform(\"sqrt\")#We can also apply a string function.","98d0fbc7":"employees = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Julia\",\"Sergio\",\"Julia\",\"Michael\",\"Sarath\",\"Jakub\",\"Chris\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\",\"Finance\",\"Marketing\",\"IT\",\"Human Resources\",\"Law\"],\n                          \"Income\":[4800,5200,6600,5700,7200,8400,7700,4200,9400],\n                          \"Age\":[24,28,33,41,22,46,31,27,39],\n                          \"Experience\":[2,5,9,17,1,24,10,6,13]})\nemployees","0469e378":"employees[\"Name\"].apply(len) #We get length of all names","ddd27ad6":"def increase_age(x):\n    return x+1","47d5174e":"employees[\"Age\"].apply(increase_age) #We increase each age.","74babc52":"employees[\"Age\"].apply(lambda x: x+1) #We increase each age.","65439b2c":"employees.apply(np.sum)","a2924f5a":"employees.groupby(\"Department\")[\"Income\"].apply(np.sum) #We get sum of salaries by each department.","218dc876":"employees.groupby(\"Department\")[\"Age\"].apply(min) #We get smallest age by each department.","be32b2d7":"employees.loc[:,[\"Income\",\"Age\"]].apply([\"max\",\"min\"])","66fa865a":"employees","bdfd2daf":"employees[[\"Name\",\"Department\"]].applymap(len)","a1f2ec50":"employees[[\"Name\"]].applymap(str.upper) #We get upper values of each name.","3b899d0a":"employees[\"Department\"].map({\"IT\":\"Information Technology\"})","eb123e4d":"employees[\"Department\"].replace({\"IT\":\"Information Technology\"},inplace=True)","42b66ec5":"employees","d75c02cd":"employees = pd.DataFrame({\"Name\":[\"Josh\",\"Mike\",\"Julia\",\"Sergio\",\"Julia\",\"Michael\",\"Sarath\",\"Jakub\",\"Chris\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\",\"Finance\",\"Marketing\",\"IT\",\"Human Resources\",\"Law\"],\n                          \"Work Level\":[\"WL3\",\"WL2\",\"WL2\",\"WL1\",\"WL3\",\"WL2\",\"WL1\",\"WL3\",\"WL1\"],\n                          \"Income\":[4800,5200,6600,5700,7200,8400,7700,4200,9400],\n                          \"Age\":[24,28,33,41,22,46,31,27,39],\n                          \"Experience\":[2,5,9,17,1,24,10,6,13]})\nemployees.head()","8a10927a":"employees.groupby(\"Department\")[\"Income\"].mean() ","64ed1e97":"employees.groupby([\"Department\",\"Work Level\"])[[\"Income\"]].agg(\"mean\")\n#We get mean of income according to department and work level. We see no nan values here, because it does not get na values.","90426462":"employees.groupby([\"Department\",\"Work Level\"])[[\"Income\"]].agg(\"mean\").unstack()\n#We get mean of income according to department and work level. Unstack() helps to see better.","cefb0680":"employees.pivot_table(\"Income\",index=\"Department\",columns=\"Work Level\") #We can make it easier.","19d6b140":"exp = pd.cut(employees[\"Experience\"],[0,9,16,24])\nexp #We will create a new column","3ec5611e":"employees.pivot_table(\"Income\",index=[\"Department\",exp],columns=\"Work Level\") #We can make it easier.","ba9e65ae":"employees = pd.DataFrame({\"Name\":[\"Josh\",None,\"Julia\",\"Sergio\",\"Julia\",\"Michael\",\"Sarath\",np.nan,\"Chris\"],\n                          \"Department\":[\"IT\",\"Human Resources\",\"Finance\",\"Supply Chain\",\"Finance\",\"Marketing\",\"IT\",\"Human Resources\",\"Law\"],\n                          \"Work Level\":[\"WL3\",\"WL2\",\"WL2\",\"WL1\",None,\"WL2\",\"WL1\",\"WL3\",\"WL1\"],\n                          \"Income\":[4800,5200,6600,np.nan,7200,8400,np.nan,4200,9400],\n                          \"Age\":[24,28,33,41,22,46,31,None,39],\n                          \"Experience\":[2,np.nan,9,17,1,24,10,6,13]})\nemployees.head()","2531a9f3":"employees[\"Income\"].isnull() #It returns true if row has nan value.","a6631f6e":"employees[employees[\"Income\"].isnull()] #We can select values which their income is nan.","ed757cf6":"income_nan = employees[employees[\"Income\"].isnull()]\nincome_nan","104e6976":"income_nan.fillna(1000) #It will fill all na values with 1000","5eeae083":"income_nan.fillna(employees[\"Income\"].mean()) #We can also give a statistical value. It is better generally.","7fe98624":"income_nan.fillna(employees[\"Income\"].median()) #We can also give a statistical value. It is better generally.","02a8c562":"employees","ed7685c8":"employees.dropna() # It drops all na values.","568c5c52":"employees.dropna(how=\"all\") # It drops all na values if all variables in a row is na.","7f27cdbe":"employees.dropna(axis=\"columns\") #We can drop columns if it has na value.","fcc4515d":"pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\") #We are giving path of data. In this example, path is same with this file.\n#It's default separeter is ,","449cb9f3":"netflix = pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\") #We assign it to \"netflix\" variable\nnetflix.head()","2ab85f00":"pd.read_excel(\"\/kaggle\/input\/crimeinengland\/crimeinengland.xlsx\")#We are giving path of data. In this example, path is same with this file.","16e32a50":"crimes = pd.ExcelFile(\"\/kaggle\/input\/crimeinengland\/crimeinengland.xlsx\")\ncrimes.sheet_names","50c07c4e":"pd.read_excel(\"\/kaggle\/input\/crimeinengland\/crimeinengland.xlsx\",sheet_name=\"Table D1\")","d4644be0":"df = pd.read_csv(\"\/kaggle\/input\/netflix-shows\/netflix_titles.csv\") \ndf.head()","e586a138":"df.tail()","ecba1c12":"df.shape","bf1358a2":"df.info","95a7d2a3":"df.dtypes","4208b76b":"df.describe()","218e86e8":"df.describe(include=[object, 'category',\"int64\"])","5665f33a":"df.isna().sum() # Summing NA values in each column","1f122cff":"df.columns","ffb5fcf9":"df.nunique()#It gives number of unique values","3744ab0d":"df.set_index('show_id', inplace=True)\ndf.head()","69541f84":"df[df[\"country\"]==\"United States\"] #Filtering by country","cbe2a8a5":"### Creating Pandas Series by Numpy arrays","d4a1f27f":"We can also create dataframes with numpy arrays.","77cd7846":"## Pandas Dataframes","245bb876":"## Merging Dataframes","880627ab":"### Merging 2 different series (Concat)","73db1228":"### Filtering with filter() function","d9d6b112":"### Filtering with aritmethic operators","eab2b42d":"We can also merge dataframes with many to many structure.","c830bed7":"We can also directly drop missing values with **dropna()** method. But in general, it is not preferred because it delete also information about dataset.","3582821a":"### Accessing rows of a dataframe","13b5c4a3":"In this part, we will try to understand Netflix Dataset.","90774b53":"### Resetting Indexes","56500f22":"A Pandas Series is like a column in a table. The difference between Numpy series and Pandas series is pandas series also hold indexes of values.","d7b1288c":"### Reading excel(xlsx) files","74a4fba6":"A simple way to store big data sets is to use external files. These files can be csv(comma separated files), excel,txt or any other file. Pandas gives possibility to read these files with functions.","dc1cc771":"In order to get largest elements in a column, we can use **nlargest()** function.","ab0e0bfb":"It seems that show_id is unique for each row, so we will assign it as index value.","632d8932":"Regex is another thema but we can also filter by using regex.","0582028e":"### Reading csv files","7e51db73":"**Inner Join**\n\nAn inner join requires each row in the two joined dataframes to have matching column values. This is similar to the intersection of two sets.\n\n![image.png](attachment:image.png)","72ecb748":"### Sorting Indexes","de1d223b":"We can use **lambda** for shorter way. It's a functional programming logic.","231f98a1":"**describe()** function does not contains categorical variables. In order to enable it, we will use include term.","0747223b":"## Sorting","38b00b97":"We can get values if condition satisfy.","8da610e8":"### Removing Columns","4b526496":"In order to reach rows by their indexes(labels), we can use **loc** keyword. If indexes are like 0,1,2..., it can be same as using loc.","ca96cc78":"Join is a common concept coming from SQL. It helps us merging dataframes.","8f2e1365":"### Changing Index Labels","4aa098df":"Pandas stands for \u201cPython Data Analysis Library\u201d.Pandas is a high-level Python data manipulation library developed by Wes McKinney in 2008. It is built on the Numpy package and its key data structure is called the DataFrame. DataFrames allow you to store and manipulate tabular data in rows of observations and columns of variables.\n\n![image.png](attachment:image.png)","31960dcd":"We can remove rows by index.","7f71ddf2":"Departments are categorical variables and we can to group employees by their department. In order to do that, we use **groupby()** function.","87d8d790":"### Adding Columns","d0842646":"We can use **map()** function in order to map values of Series according to input correspondence.","de7154b5":"Entries missing values are given the value **NaN**, short for \"Not a Number\". For technical reasons these NaN values are always of the float64 dtype.\n\nPandas provides some methods specific to missing data. To select NaN entries, we can use pd.isnull().","fa488fcd":"## Grouping","9e8399f5":"## Filtering","0ceba2f8":"### Opposite Filter","287a8e24":"**Created by Berkay Alan**\n\n**Pandas**\n\n**28 of December, 2020**\n\n**For more Tutorial: https:\/\/github.com\/berkayalan**","d6c65e52":"**Full Join(Full Outer Join)**\n\nFull Join, also known as Full Outer Join, returns all those records which either have a match in the left or right dataframe.\n\n![image.png](attachment:image.png)","786edaa3":"### Changing Column Names in a dataframe","1382920a":"Filtering with **loc** gives us flexibility.","68d89f8a":"## Pandas Series","39ef1c1d":"### Adding Rows - append()","728ed383":"### Removing Rows","4b5ed8b9":"A DataFrame is a table. It contains an array of individual entries, each of which has a certain value. Each entry corresponds to a row (or record) and a column.\n\nThose who are familiar with R know the data frame as a way to store data in rectangular grids that can easily be overviewed. Each row of these grids corresponds to measurements or values of an instance, while each column is a vector containing data for a specific variable. This means that a data frame\u2019s rows do not need to contain, but can contain, the same type of values: they can be numeric, character, logical, etc.","e7276c6b":"## Working external files in Pandas","44c3a084":"## Aggregation Functions","26326c9b":"## Exploring Netflix Dataset (basic)","cc14eaaa":"Any groupby operation involves one of the following operations on the original object. They are;\n\n- Splitting the Object\n\n- Applying a function\n\n- Combining the results\n\nValue which is used for grouping must be **categorical variable**.","acfbc969":"We can use **|** in order to try 2 condition. This is **or** logic.","e9dc732f":"We can apply a function to the group.","e8b35310":"### Creating series with key\/value objects(Dictionary)","106fcdaf":"### Assigning Custom Indexes","90aba227":"We can remove rows by conditions.","60538e73":"### Queries in Pandas Series","d5a04116":"As you can see, dataset seems not right because it has different sheets. In order to specify a sheet, we'll use **sheet_name** argument. We can get sheets with this way:","1705c9dd":"### Updating values","6aa7be6f":"### Creating Pandas Series","f7419b94":"We can also do that with filtering.","ade7a7d1":"For xlsx,we will use \"Crime in England\" dataset. Data from the Crime Survey for England and Wales (CSEW) showing breakdowns of victimisation over time and by various demographic characteristics. Please note: The methodology by which the CSEW calculates its incidents of crime changed in December 2018. You can download it from here:\n\nhttps:\/\/www.ons.gov.uk\/peoplepopulationandcommunity\/crimeandjustice\/datasets\/crimeinenglandandwalesannualtrendanddemographictables\n\nThe name of the file is **\"crimeinengland.xlsx\"**. So we will read it with **read_excel()** function.","f9241e3f":"We can also use **applymap()** function in order to apply a function to a Dataframe elementwise.","51efc965":"Let's say we want to make a 1000$ salary increase to each employee. First, we define a function that increase the salaries.","7ffa2474":"We can use **&** in order to try 2 condition. This is **and** logic.","efff06d5":"### Assigning a value to spesific row","652b143a":"## Apply","4d069caa":"If we want to apply more than 1 function, we need to use **agg()**. It is same as **aggregate()**.","2077664e":"CSV files contains plain text and is a well know format that can be read by everyone including Pandas. We will work with Netflix Movies and TV Shows dataset. You can download it from here:\n\nhttps:\/\/www.kaggle.com\/shivamb\/netflix-shows\n\nThe name of the file is **\"netflix_titles.csv\"**. So we will read it with **read_csv()** function.","2c13d47c":"## What is Pandas?","c4465742":"### Selections in Pandas Series","e966cd36":"In order to select only some of the items in the dictionary, use the index argument and specify only the items you want to include in the Series.","caeeaebd":"We can also merge dataframes with **append()** function.","19121c2f":"### Accessing columns of a dataframe","fee8eb47":"## Content\n\n- What is Pandas?\n- Importing Pandas Library\n- Pandas Series\n- Pandas Dataframes\n- Filtering\n- Adding\/Removing rows and columns\n- Merging Dataframes\n- Sorting\n- Aggregation Functions\n- Grouping\n- Apply\n- Pivot Tables\n- Missing values(NaN)\n- Working external files in Pandas(csv,excel)\n- Exploring Netflix Dataset(basic)\n\n**Resources:** \n\n-  https:\/\/www.datacamp.com\/community\/tutorials\/pandas-tutorial-dataframe-python\n\n-  https:\/\/www.kaggle.com\/learn\/pandas\n\n-  https:\/\/www.tutorialspoint.com\/python_pandas\/index.htm\n\n- https:\/\/www.analyticsvidhya.com\/blog\/2020\/02\/joins-in-pandas-master-the-different-types-of-joins-in-python\/#:~:text=work%20using%20Pandas.-,Inner%20Join%20in%20Pandas,the%20intersection%20of%20two%20sets.\n\n- https:\/\/www.youtube.com\/channel\/UCmLF94o4Ts4YKkoUHq5491Q","0dba1162":"### Append()","e1fdaf0d":"**transform() operation**\n\nPandas DataFrame.transform() function call func on self producing a DataFrame with transformed values and that has the same axis length as self.\n\nThe first argument **func** is to specify the function to be used for manipulating data. It can be a function, a string function name, a list of functions, or a dictionary of axis label.\n\nThe second argument axis is to specify which axis the func is applied to. 0 for applying the func to each column and 1 for applying the func to each row.","a22f585a":"## Adding\/Removing rows and columns","858ac02d":"You can also use a key\/value object, like a dictionary, when creating a Series.","e32cc189":"We can get opposite of a filter with **~(Tilde)** sign.","4a5905d2":"It applies a spesific function all values of a dataframe of serie.","8baeda56":"First, you need yo download Pandas library. You can find it here: https:\/\/pandas.pydata.org\/\n\nif you use Anaconda, you can download with conda run by using this command: conda install -c anaconda pandas\n\nThen, you need to import pandas in each notebook you want to use pandas.","9c7e2d5f":"### Creating Pandas Daraframes","61a97207":"### Fancy element Selecting in Pandas Series","34979dd1":"Pandas has a number of aggregating functions that reduce the dimension of the grouped object.\n\n**Common Aggregation Functions**\n\n- count()\n- value_count()\n- mean()\n- median()\n- sum()\n- min()\n- max()\n- std()\n- var()\n- describe()\n- sem()","14e8175c":"**Left Join(Left Outer Join)**\n\nLeft join, also known as Left Outer Join, returns a dataframe containing all the rows of the left dataframe. In order to do that, we use **merge()** function.\n\n![image.png](attachment:image.png)","023ac33c":"It creates a spreadsheet-style pivot table as a DataFrame.\n\nThe levels in the pivot table will be stored in MultiIndex objects (hierarchical indexes) on the index and columns of the result DataFrame.","e0c93a53":"But it also looks other values. In order to apply that just to IT, we will use **replace()** method.","e95bd15b":"## Importing Pandas Library","69d9dc4f":"We can check if spesific values satisfy a condition.","3c1c4e95":"We can merge dataframes with **concat()** function.","7ae2ce7d":"You can think keys as columns and values as rows.","3cfc5304":"In order to fill missing values(nan), we can use **fillna()** method by giving spesific value.","d7c5d92b":"**Right Join(Right Outer Join)**\n\nRight join, also known as Right Outer Join, is similar to the Left Outer Join. The only difference is that all the rows of the right dataframe are taken as it is and only those of the left dataframe that are common in both.\n\n![image.png](attachment:image.png)","c2b136aa":"### Joins","8081e706":"The new income values are float. Because nan values were float. We can change type after filling.","9c8be031":"## Pivot Tables","3ba4f7a8":"### Attributes of a Dataframe","4f1e4953":"In order to reach rows by their integer location, we can use **iloc** keyword.","e33e83be":"In order to get smallest elements in a column, we can use **nsmallest()** function.","e4bb84c5":"## Missing values(NaN)","49992399":"### Concat() function"}}