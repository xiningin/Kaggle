{"cell_type":{"5f8ae04e":"code","15410adc":"code","1e162da1":"code","2c83c69d":"code","6b7510a0":"code","c59144b4":"code","44ba65c8":"code","4b4a05a1":"markdown"},"source":{"5f8ae04e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfiles = []\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in sorted(filenames):\n        if(filename.split(\".\")[-1] == \"csv\"):\n            print(os.path.join(dirname, filename))\n            files.append(os.path.join(dirname, filename))\n            \n        \n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","15410adc":"## set deep learning modules \n\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport keras\nfrom keras.models import Sequential\nfrom keras.utils.np_utils import to_categorical","1e162da1":"# set make lib(function)\n\ndef draw_plot_obj(his_obj_): # \uc131\ub2a5\uc9c0\ud45c \uc2dc\uac01\ud654 \uc624\ube0c\uc81d\ud2b8 \uc0dd\uc131 \ud568\uc218\n\n  acc = his_obj_.history[\"accuracy\"]\n  val_acc = his_obj_.history[\"val_accuracy\"]\n  loss = his_obj_.history[\"loss\"]\n  val_loss = his_obj_.history[\"val_loss\"]\n\n  fig, ax = plt.subplots(2)\n  ax[0].plot(range(1, len(acc)+1), acc, \"bo\", label=\"accuracy\")\n  ax[1].plot(range(1, len(acc)+1), val_acc, \"bo\", label=\"val_accuracy\")\n  ax[1].plot(range(1, len(acc)+1), loss, \"r\", label=\"loss\")\n  ax[0].plot(range(1, len(acc)+1), val_loss, \"r\", label=\"val_loss\")\n\n  return plt\n\n\n\ndef defaultmodel__maker(config_): # \ubaa8\ub378 \uc0dd\uc131\uc744 \ube60\ub974\uac8c \ud558\uae30 \uc704\ud55c \ud568\uc218\n\n  model_ = Sequential()\n\n  for i, cfg in config_.items():\n    unit = cfg.get(\"unit\")\n    activation = cfg.get(\"activation\")\n    input_shape = cfg.get(\"input_shape\")\n    kernel_initializer = cfg.get(\"kernel_initializer\")\n    dropout = cfg.get(\"dropout\")\n\n    if (i != 1):\n      if not dropout:\n            layer = keras.layers.Dense(unit, activation=activation ,kernel_initializer=kernel_initializer)\n      else:\n            layer = keras.layers.Dropout(0.1)\n    else:\n      layer = keras.layers.Dense(unit, activation=activation, input_shape=input_shape ,kernel_initializer=kernel_initializer)\n      \n    model_.add(layer)\n  model_.summary()\n\n  return model_\n\n\n\ndef pd_sort(pd_obj_): # \"Id\"\ub97c \uae30\uc900\uc73c\ub85c \ub370\uc774\ud130 \ud504\ub808\uc784 \uc7ac\uc815\ub82c \uc2dc\ucf1c\uc8fc\ub294 \ud568\uc218\n\n  pd_obj_.set_index(\"Id\", inplace=True)\n  pd_obj_.sort_index()\n  pd_obj_.reset_index(level=[\"Id\"], inplace=True)\n\n  return pd_obj_\n","2c83c69d":"## set datas and While Flag\n\ntrain_file = \"\/kaggle\/input\/jica\/train.csv\"\ntest_file = \"\/kaggle\/input\/jica\/test.csv\"\noutput_file = \".\/output.csv\"\n\nflag = True\n","6b7510a0":"while(flag):\n\n  train = pd.read_csv(train_file) # \ud559\uc2b5 \ub370\uc774\ud130 \n  test = pd.read_csv(test_file) # \ud14c\uc2a4\ud2b8 \ub370\uc774\ud130\n\n  # \uc624\ucc28 \ucd5c\uc18c\ud654\ub97c \uc704\ud55c \uc7ac\uc815\ub82c \uc9c4\ud589 \n  train = pd_sort(train)\n  test = pd_sort(test)\n\n  # \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ub420 \ub370\uc774\ud130 \ud2b9\uc131 \uc815\ub9ac\ub97c \uc704\ud55c \ubcf5\uc81c \n  xtrain = train.copy()    \n  xtest = test.copy()\n\n  extract_cols = [\"S1\", \"C1\", \"S2\", \"C2\", \"S3\", \"C3\", \"S4\", \"C4\", \"S5\", \"C5\"]\n  target_datas = xtest[extract_cols] \n\n\n  # \ubaa8\ub378 \uc815\uc758\n  #random_uniform\n  #glorot_uniform\n  #variancescaling\n  #loss\ub97c \ucd5c\uc18c\ud654 \uc2dc\ud0a4\ub294 \ubc29\uc548\uc73c\ub85c \ubaa8\ub378\uc744 \uc124\uacc4\ud568.\n  model = defaultmodel__maker({ \n      1 : {\n          \"unit\" : 500,\n          \"activation\" : \"relu\",\n          \"kernel_initializer\" : \"glorot_uniform\",\n          \"input_shape\" : (10, )\n      },\n      2 : {\n          \"unit\" : 250,\n          \"activation\" : \"relu\",\n          \"kernel_initializer\" : \"VarianceScaling\"\n      },\n      3 : {\n          \"unit\" : 100,\n          \"activation\" : \"relu\",\n          \"kerne_initializer\" : \"glorot_uniform\"\n      },\n      4 : {\n          \"unit\" : 100,\n          \"activation\" : \"relu\",\n          \"kernel_initializer\":\"glorot_uniform\",\n      },\n      5 : {\n          \"dropout\" : True,\n      },\n      6 : {\n          \"unit\" : 50,\n          \"activation\" : \"relu\",\n          \"kernel_initializer\":\"glorot_uniform\",\n      },\n      7 : {\n          \"unit\" : 10,\n          \"activation\" : \"softmax\"\n      }\n  })\n\n\n  model.compile(\n  optimizer=keras.optimizers.Nadam(lr=0.0018), # \ud14c\uc2a4\ud2b8 \uacb0\uacfc adamax \ub4f1 \ud0c0 optimaizer\uc5d0 \ube44\ud574 Nadam \uc774 \ud6a8\uacfc\uc801\uc778 \uc131\ub2a5\uc744 \ubcf4\uc5ec\uc90c.\n  loss=\"categorical_crossentropy\",\n  metrics=[\"accuracy\"]\n  )\n\n  ytrain = to_categorical(xtrain[\"CLASS\"]) # CLASS \uc815\ubcf4 \uc6d0\ud56b\uc778\ucf54\ub529\n\n  # \ucc28\ud6c4 \ud655\uc778\uc744 \uc704\ud574\uc11c \uacb0\uacfc\uac12(CLASS Columns)\ub97c \uc81c\uac70.\n  xtrain = xtrain.drop([\"CLASS\"], axis=1)\n  xtest = xtest.drop([\"CLASS\"], axis=1)\n\n  # \ud559\uc2b5 \ud14c\uc2a4\ud2b8 \uacb0\uacfc acc\uac00 \uc548\uc815\uc801\uc73c\ub85c 1,0\uc5d0 \ub3c4\ub2ec\ud558\ub294 \uc801\uc808\ud55c epochs \uc218\ub294 1000\uc774\ub77c\ub294 \uc790\uccb4 \ud14c\uc2a4\ud2b8 \uacb0\uacfc \ubc0f \uc801\uc808\ud55c batch_size(250)\uc73c\ub85c \uc124\uc815 \ud6c4 \ud14c\uc2a4\ud2b8 \uc2dc \uc0ac\uc6a9\ud588\ub358 callbacks\ub294 \uc81c\uac70.\n  # \uacf5\uc9c0\uc0ac\ud56d \ubc0f \ub300\ud68c \ub8f0\uc5d0 \uacfc\uc801\ud569\uc774 \ud3c9\uac00\ud56d\ubaa9\uc5d0 \ub4e4\uc5b4\uac04\ub2e4\ub294 \uc5b8\uae09\uc774 \uc5c6\uc5c8\uc74c\uc73c\ub85c \uc548\uc815\uc801\uc778 epochs, batch_Size \uc0ac\uc6a9, \ud559\uc2b5 \uacfc\uc815\uae4c\uc9c0 \ubcfc \ud544\uc694\ub294 \uc5c6\uc774 \ud559\uc2b5 \uacb0\uacfc\ub97c \ud655\uc778\ud558\uba74 \ub418\uae30\uc5d0 verbose\ub294 2\ub85c \uc124\uc815.\n  his = model.fit(\n      xtrain[extract_cols],\n      ytrain,\n      batch_size = 250,\n      epochs = 1000,\n      validation_split=0.20,\n      #callbacks=callbacks,\n      verbose=2,\n  )\n\n  draw_plot_obj(his).show() # ACC, LOSS \uc131\ub2a5\uc9c0\ud45c \uc2dc\uac01\ud654\n\n  loss, accuracy = model.evaluate(xtrain[extract_cols], ytrain)\n\n  if (accuracy <0.6): # \uc624\ub958\uac00 \ubc1c\uc0dd\ud558\uc5ec \ud559\uc2b5\uc774 \uc81c\ub300\ub85c \uc774\ub8e8\uc5b4\uc9c0\uc9c0 \uc54a\uc740 \uacbd\uc6b0 acc Value\uac00 0.49..., 0.59... \ub4f1 \ud3c9\uade0\uc801\uc73c\ub85c 0.6(60%)\uc774\ud558\uc758 ACC Value\ub97c \uac16\uc74c.\n    print(\"Learnning Error!\")\n    print(\"ReStart Learnning...\")\n  else:\n    flag = False # \uc815\uc0c1\uc801\uc73c\ub85c \ud559\uc2b5\uc774 \uc644\ub8cc \ub41c \uacbd\uc6b0 \ubc18\ubcf5\ubb38 \uc885\ub8cc\ub97c \uc704\ud55c \ud50c\ub798\uadf8 \uc124\uc815\n\nprint(\"Learnning Success..\")\nprint(\"loss : %s\\nacc : %s value\" %(str(loss), str(accuracy)))\n\nprint(\"Output Shape : %s\" %str(model.output_shape))\n","c59144b4":"pred_values = model.predict(target_datas) # \uc608\uce21 \uc9c4\ud589\n\npred_class = pd.DataFrame([np.argmax(pred_values[i]) for i in range(0,len(pred_values))]) #\uacb0\uacfc\ub97c \ub370\uc774\ud130 \ud504\ub808\uc784\uc73c\ub85c \uc800\uc7a5\npred_class.columns = [\"CLASS\"]\n\nresult_table = pd.concat([xtest, pred_class], sort=False, axis=1) # CLASS \ud0d0\uc0c9\uacb0\uacfc\ub97c \uae30\uc874 \ub370\uc774\ud130\uc640 \ubcd1\ud569.\n\nprint(result_table[\"CLASS\"].value_counts())\nprint(test[\"CLASS\"].value_counts())\n\nerror_val_count = []\n\nfor i in range(0, 10): # case(CLASS)\ubcc4 \uc624\ud0d0 \uac2f\uc218 \ud655\uc778 \ubc0f \uc800\uc7a5\n    try:\n      error_val_count.append(abs(result_table[\"CLASS\"].value_counts()[i]-test[\"CLASS\"].value_counts()[i]))\n    except:\n      error_val_count.append(test[\"CLASS\"].value_counts()[i])\n\n\nprint(sum(error_val_count)\/len(test)) # \uc624\ud0d0\uc728 \ucd94\uc815\uce58\nprint(error_val_count) # case \ubcc4 \uc624\ud0d0 \uac2f\uc218\nprint(sum(error_val_count)) # \uc624\ud0d0 \uac2f\uc218 \ucd1d\ud569\nprint(len(test)) # \uc608\uce21 \ub370\uc774\ud130\uc758 \ucd1d \uac2f\uc218\nprint(1-sum(error_val_count)\/len(test)) # Val acc \ucd94\uc815\uce58","44ba65c8":"# \uc800\uc7a5 \ud6c4 \uc815\ud655\ud55c \uc624\ucc28\uac12 \uc7ac\ud655\uc778(\uba87\uac1c\uac00 \ucc28\uc774\uac00 \ubc1c\uc0dd\ud588\ub294\uc9c0, Case8 17\uac1c \ud3ec\ud568 \uacb0\uacfc).\nresult_table[[\"Id\", \"CLASS\"]].to_csv(output_file, index=False)\n\nresult_frame = pd.read_csv(output_file) # \uc800\uc7a5\ub41c \uc608\uce21\uac12 \ub85c\ub4dc\ntest_frame = pd.read_csv(test_file) # \uc608\uce21\uac12 \uc815\ubcf4 \ub85c\ub4dc\n\n#\uc815\ud655\ud55c \uac12\uc744 \ube44\uad50\ud558\uae30 \uc704\ud558\uc5ec \uace0\uc720\uac12\uc778 Id Value\ub97c Index\ub85c \uc124\uc815\nresult_frame.set_index(\"Id\", inplace=True) \ntest_frame.set_index(\"Id\", inplace=True)\n\nnon_match = {}\n\nfor i,row in result_frame.iterrows(): # Id Value\ub97c \uae30\ubc18\uc73c\ub85c \uac12\uc744 \ud638\ucd9c\ud558\uc5ec CLASS \uc608\uce21\uac12 \uc911 \uc624\ucc28 \uacc4\uc0b0\n    if(result_frame.loc[i][\"CLASS\"]!=test_frame.loc[i][\"CLASS\"]):\n        non_match[i] = {\"result_frame\":result_frame.loc[i][\"CLASS\"], \"test_frame\":test_frame.loc[i][\"CLASS\"]}\n\nprint(len(non_match)) # \uc624\ud0d0 \ucd94\uc815 \uac2f\uc218\nprint((1000000-len(non_match))*0.000001) # \uc608\uce21 val acc \uac12","4b4a05a1":"<center><h1>About This Script<\/h1><\/center><br><br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;0.1 ver \ubca0\uc774\uc2a4 \ucf54\ub4dc \uc791\uc131<br>\n\n&nbsp;&nbsp;&nbsp;&nbsp;0.2 ver \uc131\ub2a5 \uc77c\ubd80 \uac1c\uc120<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\u3134 \ucd5c\uc18c 88%, \ucd5c\ub300 95%, \ud3c9\uade0 91\\~3% \uac00\ub7c9\uc758 \uc131\ub2a5\uce58 <br><br>\n&nbsp;&nbsp;&nbsp;&nbsp;1.0 ver \uae30\uc874 \ub85c\uc9c1\uc758 \ud55c\uacc4 \ubc0f \uaddc\uce59 \uad00\ub828 \uc560\ub9e4\ud55c \ubd80\ubd84\uc73c\ub85c \uc778\ud574 \ub9ac\ube4c\ub529 & \ud14c\uc2a4\ud2b8 \uc18d\ub3c4\ubb38\uc81c\ub85c \ub85c\uceec\uc5d0\uc11c \uac1c\ubc1c \ud6c4 \uc62e\uae40.<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\u3134 \ucd5c\uc18c 98.9%, \ucd5c\ub300 99.95%, \ud3c9\uade0 99.4\\~6% \uac00\ub7c9\uc758 \uc131\ub2a5\uce58<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;\u3134 \uc131\ub2a5\ucd5c\uc801\ud654\uc5d0 \uad00\ub828\ub41c \uc774\uc57c\uae30\ub294 \uc5c6\ub294 \uad00\uacc4\ub85c \uacfc\uc801\ud569 \ubb38\uc81c\uc5d0 \ub300\ud55c \uace0\ubbfc\ubcf4\ub2e8 \ucd5c\ub300\ud55c\uc758 \uacb0\uacfc\ub97c \ub04c\uc5b4\ub0b4\ub294\ub370 \uc9d1\uc911.<br>"}}