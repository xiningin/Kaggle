{"cell_type":{"7eb87a00":"code","214c019f":"code","2aa6a5a9":"code","813ec2f3":"code","ffc0e555":"code","36a0f421":"code","96f92c86":"code","4dad683a":"code","5ae2fdcb":"code","fa7185b1":"code","f7e528ef":"code","179379f8":"code","5f53b5d8":"markdown","315d59e4":"markdown","e626992c":"markdown"},"source":{"7eb87a00":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport seaborn as sns\nimport tensorflow as tf\nimport os\n\nprint(\"TensorFlow version :\", tf.__version__)\nprint(\"Num GPUs Available: \", len(tf.config.experimental.list_physical_devices('GPU')))","214c019f":"train_dir = \"..\/input\/fer2013\/train\/\"\ntest_dir = \"..\/input\/fer2013\/test\/\"\ntotal_labels = len(os.listdir(train_dir))\n\nfig, ax = plt.subplots(nrows=5, ncols=total_labels, figsize=(35, 25))\nfor x in range(5):\n    for y,v in zip(range(total_labels),os.listdir(train_dir)):\n        ax[x][y].imshow(imread(train_dir+v+'\/'+os.listdir(train_dir+v)[x]), cmap='gray')\n\nplt.show()","2aa6a5a9":"df = {}\nfor i in os.listdir(train_dir):\n    directory = train_dir + i\n    df[i] = len(os.listdir(directory))\ndf = pd.DataFrame(df, index=[\"total\"]).transpose().sort_values(\"total\", ascending=False)\n\nplt.figure(figsize=(10,6))\nsns.barplot(x=df.index, y=\"total\", palette=\"rocket\", data=df)\nplt.ylabel(\"count\")\nplt.title(\"Total images of each label in train dataset\")\nplt.show()","813ec2f3":"happy = os.listdir(train_dir+'happy\/')\ndim1, dim2 = [], []\n\nfor img_filename in happy:\n    img = imread(train_dir+'happy\/'+img_filename)\n    d1, d2 = img.shape\n    dim1.append(d1)\n    dim2.append(d2)\n\nimg_shape = (int(np.mean(dim1)), int(np.mean(dim2)), 1)\nsns.jointplot(dim1, dim2)\nplt.show()","ffc0e555":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_gen = ImageDataGenerator(rescale=1\/255,\n                                rotation_range=40,\n                                width_shift_range=0.2,\n                                height_shift_range=0.2,\n                                shear_range=0.2,\n                                zoom_range=0.2,\n                                horizontal_flip=True,\n                                fill_mode='nearest')\n\ntest_gen = ImageDataGenerator(rescale=1\/255)\n\ntrain_generator = train_gen.flow_from_directory(directory=train_dir,\n                                                target_size=(img_shape[0], img_shape[1]),\n                                                color_mode='grayscale',\n                                                batch_size=64,\n                                                class_mode='categorical',\n                                                shuffle=True)\n\ntest_generator = test_gen.flow_from_directory(directory=test_dir,\n                                                target_size=(img_shape[0], img_shape[1]),\n                                                color_mode='grayscale',\n                                                batch_size=64,\n                                                class_mode='categorical',\n                                                shuffle=False)","36a0f421":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization\nfrom tensorflow.nn import relu, softmax\nfrom tensorflow.keras.optimizers import RMSprop, Adam\nfrom tensorflow.keras.losses import categorical_crossentropy\n\ntf.keras.backend.clear_session()\n\nmodel = Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), padding='same', activation=relu, input_shape=img_shape))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), padding='same', activation=relu))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation=relu))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Conv2D(filters=512, kernel_size=(3,3), padding='same', activation=relu))\nmodel.add(BatchNormalization())\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(0.2))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation=relu))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(1024, activation=relu))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(units=len(os.listdir(train_dir)), activation=softmax))\n\nmodel.compile(optimizer=Adam(learning_rate=0.0001, decay=1e-6), loss=categorical_crossentropy, metrics=['accuracy'])\n\nmodel.summary()","96f92c86":"import pydot\nfrom tensorflow.keras.utils import plot_model\n\nplot_model(model, show_shapes=True, show_layer_names=True)","4dad683a":"from tensorflow.keras.callbacks import EarlyStopping, LearningRateScheduler\n\nearly_stop = EarlyStopping(monitor='val_loss', patience=5)\n# lr_schedule = LearningRateScheduler(lambda epoch: 1e-8 * 10**(epoch \/ 20))\ncallbacks = [early_stop,]","5ae2fdcb":"steps_per_epoch = train_generator.n \/\/ train_generator.batch_size\nvalidation_steps = test_generator.n \/\/ test_generator.batch_size\nnum_epochs = 400\n\nhistory = model.fit(train_generator,\n                    epochs=num_epochs,\n                    verbose=1,\n                    callbacks=callbacks,\n                    validation_data=test_generator,\n                    steps_per_epoch=steps_per_epoch,\n                    validation_steps=validation_steps)","fa7185b1":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs = range(len(acc))\n\nfig, ax = plt.subplots(nrows=1, ncols=2, figsize=(20, 6))\nax[0].plot(epochs, acc, 'r', label='Training accuracy')\nax[0].plot(epochs, val_acc, 'b', label='Validation accuracy')\nax[0].legend(loc=0)\nax[1].plot(epochs, loss, 'r', label='Training loss')\nax[1].plot(epochs, val_loss, 'b', label='Validation loss')\nax[1].legend(loc=0)\n\nplt.suptitle('Training and validation')\nplt.show()","f7e528ef":"test_loss, test_acc = model.evaluate(test_generator)\nprint(\"validation accuracy :\", str(test_acc*100)+\"%\")\nprint(\"validation loss :\", test_loss)","179379f8":"from sklearn.metrics import classification_report, confusion_matrix\n\ny_pred = np.argmax(model.predict(test_generator), axis=-1)\nprint(classification_report(test_generator.classes, y_pred, target_names=test_generator.class_indices.keys()), end='\\n\\n\\n')\n\ncm = confusion_matrix(test_generator.classes, y_pred)\nplt.figure(figsize=(16,10))\nsns.heatmap(cm, cmap=plt.cm.Blues, annot=True, fmt='.0f', xticklabels=test_generator.class_indices.keys(), yticklabels=test_generator.class_indices.keys())\nplt.show()","5f53b5d8":"# Create the Model","315d59e4":"# Data Preprocessing","e626992c":"# Evaluate The Model"}}