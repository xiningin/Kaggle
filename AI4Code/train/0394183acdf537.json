{"cell_type":{"cd979977":"code","8e9a00b1":"code","94daa2e3":"code","1ed548b0":"code","f687ff85":"code","42ae242f":"code","6e582ae9":"code","35eaa072":"code","b679ec1f":"code","b7e40028":"code","7e7efc46":"code","bc40f6bf":"code","7d9a65f1":"code","f0aef67c":"code","1ead3a92":"code","2272d82a":"code","6b66a9d5":"code","b3a3ddb6":"code","fb3381ca":"code","f169bb78":"code","d641bf4b":"code","3c82f005":"code","e197ef95":"code","b4d49fb3":"code","2010da5c":"code","b20f4272":"code","7b0e80f9":"code","2403169b":"code","bb9d5400":"code","27942762":"code","c5fdf4fd":"code","254d8bd2":"code","b96ee33d":"markdown"},"source":{"cd979977":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8e9a00b1":"train = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv')\nsubmission = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')","94daa2e3":"print(train.shape)\nprint(test.shape)\nprint(train.isnull().sum())\nprint(test.isnull().sum())","1ed548b0":"train.head()","f687ff85":"### Importing the libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline","42ae242f":"train.shape , test.shape","6e582ae9":"train.info()","35eaa072":"target = 'target'\nId_Cols = ['id' ]\n#drop_cols #= ['f0' , 'f13' , 'f38' , 'f52' , 'f72' , 'f92']\nfeatures = [x for x in train.columns if x not in [target]+Id_Cols]","b679ec1f":"#for f in train[features].columns:\n#    sns.displot(train[f])\n#    plt.tight_layout()\n#    plt.show()   ","b7e40028":"#target = 'target'\n#Id_Cols = ['id' ]\n##drop_cols #= ['f0' , 'f13' , 'f38' , 'f52' , 'f72' , 'f92']\n#features = [x for x in train.columns if x not in [target]+Id_Cols]\n#X = train[features]\n#y = train['target']\n#\n#from sklearn.preprocessing import StandardScaler\n## perform a robust scaler transform of the dataset\n#trans = StandardScaler()\n#X = trans.fit_transform(X)","7e7efc46":"#cols = train[features].columns\n#df = pd.DataFrame(X, columns = cols)\n#df.head()","bc40f6bf":"#import statsmodels.api as sm\n#logit_model=sm.Logit(y,X)\n#result=logit_model.fit()\n#print(result.summary2())","7d9a65f1":"#X = df[['f3','f6','f7','f8','f9' ,'f12','f18','f29','f37','f38','f39' ]]\n#X\n# 'f1','f2','f4','f5' ,'f0','f10','f11','f13','f14','f15','f16','f17','f19','f20','f21','f22'\n# 'f23','f24','f25','f26','f27','f28',, 'f33' , 'f34'\n#'f0'","f0aef67c":"#X = df[['f34']]\n#import statsmodels.api as sm\n#logit_model=sm.Logit(y,X)\n#result=logit_model.fit()\n#print(result.summary2())\n##'f38','f39',","1ead3a92":"#target = 'target'\n#Id_Cols = ['id' ]\n#drop_cols = ['f0' , 'f13' , 'f38' , 'f52' , 'f72' , 'f92']\n#features = [x for x in train.columns if x not in [target]+Id_Cols+drop_cols]\n#X = train[features]\n#\n#from sklearn.preprocessing import StandardScaler\n## perform a robust scaler transform of the dataset\n#trans = StandardScaler()\n#X = trans.fit_transform(X)","2272d82a":"#import statsmodels.api as sm\n#logit_model=sm.Logit(y,X)\n#result=logit_model.fit()\n#print(result.summary2())","6b66a9d5":"target = 'target'\nId_Cols = ['id' ]\ndrop_cols = ['f0' , 'f13' , 'f38' , 'f52' , 'f72' , 'f92']\nfeatures = [x for x in train.columns if x not in [target]+Id_Cols]\nX = train[features]\n\nfrom sklearn.preprocessing import StandardScaler\n# perform a robust scaler transform of the dataset\ntrans = StandardScaler()\nX = trans.fit_transform(X)\nfeat_names = features\ny = train['target']","b3a3ddb6":"#from sklearn.ensemble import RandomForestRegressor\n##rf = RandomForestRegressor()\n##rf.fit(X, y)\n##print(\"Features sorted by their score:\")\n##print(sorted(zip(map(lambda x: round(x, 4), rf.feature_importances_), feat_names), \n #            reverse=True))","fb3381ca":"#import xgboost\n#import shap\n## load JS visualization code to notebook\n#shap.initjs()\n## train XGBoost model\n#\n#model = xgboost.train({\"learning_rate\": 0.01}, xgboost.DMatrix(X, label=y), 100)\n## explain the model's predictions using SHAP values\n## (same syntax works for LightGBM, CatBoost, and scikit-learn models)\n#explainer = shap.TreeExplainer(model)\n#shap_values = explainer.shap_values(X)\n#shap.summary_plot(shap_values, X, plot_type=\"bar\")","f169bb78":"#X = df[['f34','f55','f43','f80','f91','f8','f71','f27', 'f97','f50', 'f41','f57', 'f66', 'f25', 'f22', 'f96', 'f82' ]]","d641bf4b":"from sklearn.linear_model import LogisticRegression\nfrom sklearn import metrics\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=0)\nlogreg = LogisticRegression(C=0.0001, class_weight=None, dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=None, solver='liblinear', tol=0.0001, verbose=0,\n                   warm_start=False)\n\nlogreg.fit(X_train, y_train)","3c82f005":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","e197ef95":"from sklearn.metrics import confusion_matrix\nconfusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","b4d49fb3":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","2010da5c":"from sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nlogit_roc_auc = roc_auc_score(y_test, logreg.predict(X_test))\nfpr, tpr, thresholds = roc_curve(y_test, logreg.predict_proba(X_test)[:,1])\nplt.figure()\nplt.plot(fpr, tpr, label='Logistic Regression (area = %0.2f)' % logit_roc_auc)\nplt.plot([0, 1], [0, 1],'r--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic')\nplt.legend(loc=\"lower right\")\nplt.savefig('Log_ROC')\nplt.show()","b20f4272":"## Import the necessary libraries first\n#from sklearn.feature_selection import SelectKBest\n#from sklearn.feature_selection import chi2","7b0e80f9":"## Feature extraction\n#test = SelectKBest(score_func=chi2, k=4)\n#fit = test.fit(X, y)\n#\n## Summarize scores\n#np.set_printoptions(precision=3)\n#print(fit.scores_)\n#\n#features = fit.transform(X)\n## Summarize selected features\n#print(features[0:5,:])","2403169b":"#X = test[['f34','f55','f43','f80','f91','f8','f71','f27', 'f97','f50', 'f41','f57', 'f66', 'f25', 'f22', 'f96', 'f82' ]]\n#from sklearn.preprocessing import StandardScaler\n## perform a robust scaler transform of the dataset\n#trans = StandardScaler()\n#X = trans.fit_transform(X)","bb9d5400":"x_pred = logreg.predict_proba(X)[:,1]\nx_pred","27942762":"Id_Cols = ['id' ]\nfeatures = [x for x in test.columns if x not in Id_Cols]\nX = test[features]\n\nfrom sklearn.preprocessing import StandardScaler\n# perform a robust scaler transform of the dataset\ntrans = StandardScaler()\nX = trans.fit_transform(X)","c5fdf4fd":"x_pred = logreg.predict_proba(X)[:,1]\nx_pred","254d8bd2":"submission['target'] = x_pred\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","b96ee33d":"No Null data present "}}