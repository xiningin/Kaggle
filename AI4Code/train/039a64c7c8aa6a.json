{"cell_type":{"28f0269d":"code","b8fbe921":"code","2e063042":"code","1709b905":"code","0e3685d2":"code","46a29b4f":"code","9c185168":"code","e66f089a":"code","1c11d449":"code","6e669dee":"code","06948914":"code","af29e0b6":"code","4d8a2381":"code","400c3e38":"code","a93dfc78":"code","72a5416c":"code","b00c9fc0":"code","80e8c033":"code","9e75170c":"markdown","3a8c4b53":"markdown","ea545ae4":"markdown","a2fe1ec5":"markdown","d185cbe2":"markdown","1d798bb0":"markdown","d57ca030":"markdown","197e0ece":"markdown","9ee226d8":"markdown"},"source":{"28f0269d":"#Import required packages\n\nimport numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport scikitplot as skplt\nfrom sklearn.metrics import classification_report,confusion_matrix\n\n#Import packages for Deep learning\nimport keras\nfrom keras.layers import Conv2D,Dense,Dropout,Flatten,Input\nfrom keras.layers import Activation,MaxPooling2D\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam,sgd,RMSprop,Nadam,Adadelta,Adamax\nfrom keras.callbacks import ModelCheckpoint,Callback,EarlyStopping\nfrom keras.utils import to_categorical,plot_model\nfrom keras.models import Model\nfrom keras import backend as K\n\n#Ensures consistency across runs\nfrom numpy.random import seed\nseed(1)\nfrom tensorflow import set_random_seed\nset_random_seed(2)\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\n#Network visualization packages\nimport graphviz as gv\nimport pydot as pydot;\n","b8fbe921":"ds_dir = '\/kaggle\/input\/kannada-mnist\/kannada_mnist_datataset_paper\/Kannada_MNIST_datataset_paper\/Kannada_MNIST_npz\/Kannada_MNIST'\n\nX_train = np.load(os.path.join(ds_dir,'X_kannada_MNIST_train.npz'))['arr_0']\nX_test = np.load(os.path.join(ds_dir,'X_kannada_MNIST_test.npz'))['arr_0']\ny_train = np.load(os.path.join(ds_dir,'y_kannada_MNIST_train.npz'))['arr_0']\ny_test = np.load(os.path.join(ds_dir,'y_kannada_MNIST_test.npz'))['arr_0']\n\nprint(X_train.shape, X_test.shape)\nprint(y_train.shape, y_test.shape)","2e063042":"plt.figure(figsize=(6,6))\nplt.imshow(X_train[1],cmap='inferno')\nplt.title(y_train[1])","1709b905":"plt.figure(figsize=[10,8])\nfor i in range(50):\n    plt.subplot(5, 10, i+1)\n    plt.axis('Off')\n    if i < 10:\n        plt.title(y_train[i])\n    plt.imshow(X_train[i], cmap='inferno')","0e3685d2":"y_classes=np.unique(y_train)\ny_classes","46a29b4f":"#Reshape the datasets\nX_train=X_train.reshape(-1,28,28,1)\nX_test=X_test.reshape(-1,28,28,1)\nprint('Size after reshaping the datasets')\nX_train.shape,X_test.shape\n","9c185168":"#Change datatype from uint8 to float64 & scale input data to the range (0,1)\nX_train=X_train.astype('float64')\/255\nX_test=X_test.astype('float64')\/255","e66f089a":"#convert target labels from integers to categorical\ny_train=to_categorical(y_train,num_classes=10,dtype='uint8')\nprint('Shape of the target labels...')\nprint(y_train.shape,y_test.shape)","1c11d449":"#Split the train data\nX_train,X_val,y_train,y_val=train_test_split(X_train,y_train,test_size=0.1,random_state=42)\nprint('Shape of the train data..')\nprint(X_train.shape,y_train.shape)\nprint('Shape of the validation data..')\nprint(X_val.shape,y_val.shape)","6e669dee":"#Shuffle train samples\nX_train,y_train=shuffle(X_train,y_train,random_state=42)","06948914":"#LeNet architecture\nclass LeNet:\n     def build(width,height,depth,classes):\n            #Initialize the model\n            model=Sequential()\n            input_shape=(height,width,depth)\n            if K.image_data_format()=='channels_first':\n                input_shape=(depth,height,width)\n            #first set of Conv=>ReLU=> Pool layers\n            model.add(Conv2D(20,(5,5),padding='same',input_shape=input_shape))\n            model.add(Activation('relu'))\n            model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n            #Second set of Conv=>ReLU=> Pool layers\n            model.add(Conv2D(50,(5,5),padding='same',input_shape=input_shape))\n            model.add(Activation('relu'))\n            model.add(MaxPooling2D(pool_size=(2,2),strides=(2,2)))\n            #FC=>ReLU layer with 500 nodes\n            model.add(Flatten())\n            model.add(Dense(500))\n            model.add(Activation('relu'))\n            #Add dense & softmax layer\n            model.add(Dense(classes))\n            model.add(Activation('softmax'))\n            return model","af29e0b6":"#Initialize the optimizer & model\nopt=sgd(lr=0.01)\nmodel=LeNet.build(width=28,height=28,depth=1,classes=10)\nplot_model(model,to_file='LeNet.png',show_shapes=True)\nmodel.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['acc'])\nmodel.summary()","4d8a2381":"#Visualize LeNet architecture using graphviz\nfrom IPython.display import Image\nImage('LeNet.png')\n","400c3e38":"#Prepare the model & save in the directory\nsave_dir=os.path.join(os.getcwd(),'saved_models')\nmodel_name='Kannada_digit_recognition_model.h5'\nif not os.path.isdir(save_dir):\n    os.makedirs(save_dir)\nfilepath=os.path.join(save_dir,model_name)\n\n#Prepare callbacks for model saving & for learning rate adjustment\ncheckpoint=ModelCheckpoint(filepath=filepath,\n                          monitor='val_acc',\n                          verbose=1, mode='max',\n                          save_best_only=True)\nearly_stopping=EarlyStopping(monitor='val_acc',mode='max',\n                            verbose=1,patience=20)                      \ncallbacks=[checkpoint,early_stopping]","a93dfc78":"#train the network\nprint('training the network....')\nhistory=model.fit(X_train,y_train,batch_size=32,\n                   validation_data=(X_val,y_val),epochs=10,\n                   verbose=1,\n                    callbacks=callbacks,\n                    shuffle=True\n                   )","72a5416c":"#Evaluate the network\nprint('Evaluatng the network...')\ny_pred=model.predict(X_test,batch_size=32)\ntarget_names=['0','1','2','3','4','5','6','7','8','9']\nclassification_report=classification_report(y_test,y_pred.argmax(axis=1),\n                                            target_names=target_names)\nprint('Classification Report...')\nprint(classification_report)","b00c9fc0":"#plot our confusion matrix\nskplt.metrics.plot_confusion_matrix(y_test,y_pred.argmax(axis=1),normalize=False,figsize=(12,8))\nplt.show()","80e8c033":"#Plot the training loss & accuracy\nplt.style.use('ggplot')\nplt.figure()\nplt.plot(np.arange(0,10),history.history['loss'],label='train_loss')\nplt.plot(np.arange(0,10),history.history['val_loss'],label='validatin_loss')\nplt.plot(np.arange(0,10),history.history['acc'],label='train_accuracy')\nplt.plot(np.arange(0,10),history.history['val_acc'],label='validatin_accuracy')\nplt.title('Training loss & Accuracy')\nplt.xlabel('#epochs')\nplt.ylabel('Loss\/Accuracy')\nplt.legend()\nplt.show()","9e75170c":"> **Model with LeNet Architecture**","3a8c4b53":"Let's look at the 50 images","ea545ae4":"LeNet Architecture\n![image.png](attachment:image.png)\n\nIt contains two series of Conv=>ReLU=>Pool layer sets followed by a fully connected layer & softmax output.","a2fe1ec5":"The model performed well on train & validation dataset with no signs of overfitting. This model gives 96% classification accuracy on test dataset. Overall LeNet model performace is great on Kannada_MNIST dataset.","d185cbe2":"Out of 10000 test images, 399 images are misclassified &  remaining 9601 images are classified correctly.","1d798bb0":">                   * Digits Recognition in Kannada Language*\n\nThe objective of this kernel is to recognize the hand written digits (numerical symbols) in Kannada Language. The dataset contains 60k train & 10k test images of size 28X28 pixels each.The below image shows the numerical symbols in Kannada Language.\n![image.png](attachment:image.png)\n\nImage reference:\nhttps:\/\/www.researchgate.net\/figure\/speech-for-Kannada-numbers_fig2_313113588","d57ca030":"Reference: https:\/\/www.kaggle.com\/mirzarahim\/kannada-mnist-digits-model-interpret-visualize","197e0ece":"References:-\n1. Deep Learning for computer vision with Python book by Adrian Rosebrock\n2. Keras documentation- https:\/\/keras.io\/","9ee226d8":"Load the datasets"}}