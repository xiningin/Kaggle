{"cell_type":{"3360f64a":"code","26348dc0":"code","6e1a924d":"code","3de6be40":"code","f9d112c8":"code","9d08576e":"code","d29b2aa4":"code","405f88a3":"code","96a3e22d":"code","91a4b3bf":"code","71f2366b":"code","eca1115a":"code","77023f98":"code","9f35e106":"code","98bc1dbd":"code","988b78a1":"code","267ccca6":"code","bdbe4546":"code","8fc1a0b9":"code","3fd3f1ae":"code","41e42c42":"markdown","5f49a18c":"markdown","2154c728":"markdown","aa0b9809":"markdown","0453c15f":"markdown","d749c153":"markdown","90c3e872":"markdown","e63d9705":"markdown","159da552":"markdown"},"source":{"3360f64a":"import json\nimport math\nimport os\n\nimport cv2\nfrom PIL import Image\nimport numpy as np\nfrom keras import layers\nfrom keras.applications import DenseNet121\nfrom keras.callbacks import Callback, ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.optimizers import Adam\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import cohen_kappa_score, accuracy_score\nimport scipy\nfrom tqdm import tqdm","26348dc0":"train_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\ntest_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/test.csv')\nprint(train_df.shape)\nprint(test_df.shape)\ntrain_df.head()","6e1a924d":"columns=4\nrows=3\ndf = train_df\n\nfig=plt.figure(figsize=(5*columns, 4*rows))\n\nfor i in range(columns*rows):\n    image_path = df.loc[i,'id_code']\n    image_id = df.loc[i,'diagnosis']\n    img = cv2.imread(f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_path}.png')\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n    fig.add_subplot(rows, columns, i+1)\n    plt.title(image_id)\n    plt.imshow(img)","3de6be40":"# def get_pad_width(im, new_shape, is_rgb=True):\n#     pad_diff = new_shape - im.shape[0], new_shape - im.shape[1]\n#     t, b = math.floor(pad_diff[0]\/2), math.ceil(pad_diff[0]\/2)\n#     l, r = math.floor(pad_diff[1]\/2), math.ceil(pad_diff[1]\/2)\n#     if is_rgb:\n#         pad_width = ((t,b), (l,r), (0, 0))\n#     else:\n#         pad_width = ((t,b), (l,r))\n#     return pad_width\n\ndef preprocess_image(image_path, desired_size=224):\n    im = Image.open(image_path)\n    im = im.resize((desired_size, )*2, resample=Image.LANCZOS)\n    \n    return im","f9d112c8":"N = train_df.shape[0]\nx_train = np.empty((N, 224, 224, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(train_df['id_code'])):\n    x_train[i, :, :, :] = preprocess_image(\n        f'..\/input\/aptos2019-blindness-detection\/train_images\/{image_id}.png'\n    )","9d08576e":"N = test_df.shape[0]\nx_test = np.empty((N, 224, 224, 3), dtype=np.uint8)\n\nfor i, image_id in enumerate(tqdm(test_df['id_code'])):\n    x_test[i, :, :, :] = preprocess_image(\n        f'..\/input\/aptos2019-blindness-detection\/test_images\/{image_id}.png'\n    )","d29b2aa4":"y_train = pd.get_dummies(train_df['diagnosis']).values\n\nprint(x_train.shape)\nprint(y_train.shape)\nprint(x_test.shape)","405f88a3":"y_train_multi = np.empty(y_train.shape, dtype=y_train.dtype)\ny_train_multi[:, 4] = y_train[:, 4]\n\nfor i in range(3, -1, -1):\n    y_train_multi[:, i] = np.logical_or(y_train[:, i], y_train_multi[:, i+1])\n\nprint(\"Original y_train:\", y_train.sum(axis=0))\nprint(\"Multilabel version:\", y_train_multi.sum(axis=0))","96a3e22d":"x_train, x_val, y_train, y_val = train_test_split(\n    x_train, y_train_multi, \n    test_size=0.15, \n    random_state=2019\n)","91a4b3bf":"class MixupGenerator():\n    def __init__(self, X_train, y_train, batch_size=32, alpha=0.2, shuffle=True, datagen=None):\n        self.X_train = X_train\n        self.y_train = y_train\n        self.batch_size = batch_size\n        self.alpha = alpha\n        self.shuffle = shuffle\n        self.sample_num = len(X_train)\n        self.datagen = datagen\n\n    def __call__(self):\n        while True:\n            indexes = self.__get_exploration_order()\n            itr_num = int(len(indexes) \/\/ (self.batch_size * 2))\n\n            for i in range(itr_num):\n                batch_ids = indexes[i * self.batch_size * 2:(i + 1) * self.batch_size * 2]\n                X, y = self.__data_generation(batch_ids)\n\n                yield X, y\n\n    def __get_exploration_order(self):\n        indexes = np.arange(self.sample_num)\n\n        if self.shuffle:\n            np.random.shuffle(indexes)\n\n        return indexes\n\n    def __data_generation(self, batch_ids):\n        _, h, w, c = self.X_train.shape\n        l = np.random.beta(self.alpha, self.alpha, self.batch_size)\n        X_l = l.reshape(self.batch_size, 1, 1, 1)\n        y_l = l.reshape(self.batch_size, 1)\n\n        X1 = self.X_train[batch_ids[:self.batch_size]]\n        X2 = self.X_train[batch_ids[self.batch_size:]]\n        X = X1 * X_l + X2 * (1 - X_l)\n\n        if self.datagen:\n            for i in range(self.batch_size):\n                X[i] = self.datagen.random_transform(X[i])\n                X[i] = self.datagen.standardize(X[i])\n\n        if isinstance(self.y_train, list):\n            y = []\n\n            for y_train_ in self.y_train:\n                y1 = y_train_[batch_ids[:self.batch_size]]\n                y2 = y_train_[batch_ids[self.batch_size:]]\n                y.append(y1 * y_l + y2 * (1 - y_l))\n        else:\n            y1 = self.y_train[batch_ids[:self.batch_size]]\n            y2 = self.y_train[batch_ids[self.batch_size:]]\n            y = y1 * y_l + y2 * (1 - y_l)\n\n        return X, y","71f2366b":"BATCH_SIZE = 32\n\ndef create_datagen():\n    return ImageDataGenerator(\n        zoom_range=0.15,  # set range for random zoom\n        # set mode for filling points outside the input boundaries\n        fill_mode='constant',\n        cval=0.,  # value used for fill_mode = \"constant\"\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=True,  # randomly flip images\n    )\n\n# Using original generator\ndata_generator = create_datagen().flow(x_train, y_train, batch_size=BATCH_SIZE)\n# Using Mixup\nmixup_generator = MixupGenerator(x_train, y_train, batch_size=BATCH_SIZE, alpha=0.2, datagen=create_datagen())()","eca1115a":"class Metrics(Callback):\n    def on_train_begin(self, logs={}):\n        self.val_kappas = []\n\n    def on_epoch_end(self, epoch, logs={}):\n        X_val, y_val = self.validation_data[:2]\n        y_val = y_val.sum(axis=1) - 1\n        \n        y_pred = self.model.predict(X_val) > 0.5\n        y_pred = y_pred.astype(int).sum(axis=1) - 1\n\n        _val_kappa = cohen_kappa_score(\n            y_val,\n            y_pred, \n            weights='quadratic'\n        )\n\n        self.val_kappas.append(_val_kappa)\n\n        print(f\"val_kappa: {_val_kappa:.4f}\")\n        \n        if _val_kappa == max(self.val_kappas):\n            print(\"Validation Kappa has improved. Saving model.\")\n            self.model.save('model.h5')\n\n        return","77023f98":"densenet = DenseNet121(\n    weights='..\/input\/densenet-keras\/DenseNet-BC-121-32-no-top.h5',\n    include_top=False,\n    input_shape=(224,224,3)\n)","9f35e106":"def build_model():\n    model = Sequential()\n    model.add(densenet)\n    model.add(layers.GlobalAveragePooling2D())\n    model.add(layers.Dropout(0.5))\n    model.add(layers.Dense(5, activation='sigmoid'))\n    \n    model.compile(\n        loss='binary_crossentropy',\n        optimizer=Adam(lr=0.00005),\n        metrics=['accuracy']\n    )\n    \n    return model","98bc1dbd":"model = build_model()\nmodel.summary()","988b78a1":"kappa_metrics = Metrics()\n\nhistory = model.fit_generator(\n    data_generator,\n    steps_per_epoch=x_train.shape[0] \/ BATCH_SIZE,\n    epochs=30,\n    validation_data=(x_val, y_val),\n    callbacks=[kappa_metrics]\n)","267ccca6":"with open('history.json', 'w') as f:\n    json.dump(history.history, f)\n\nhistory_df = pd.DataFrame(history.history)\nhistory_df[['loss', 'val_loss']].plot()\nhistory_df[['acc', 'val_acc']].plot()","bdbe4546":"plt.plot(kappa_metrics.val_kappas)","8fc1a0b9":"model.load_weights('model.h5')\ny_val_pred = model.predict(x_val)\n\ndef compute_score_inv(threshold):\n    y1 = y_val_pred > threshold\n    y1 = y1.astype(int).sum(axis=1) - 1\n    y2 = y_val.sum(axis=1) - 1\n    score = cohen_kappa_score(y1, y2, weights='quadratic')\n    \n    return 1 - score\n\nsimplex = scipy.optimize.minimize(\n    compute_score_inv, 0.5, method='nelder-mead'\n)\n\nbest_threshold = simplex['x'][0]","3fd3f1ae":"y_test = model.predict(x_test) > 0.5\ny_test = y_test.astype(int).sum(axis=1) - 1\n\ntest_df['diagnosis'] = y_test\ntest_df.to_csv('submission.csv',index=False)","41e42c42":"### Creating keras callback for QWK","5f49a18c":"# Model: DenseNet-121","2154c728":"## Creating multilabels","aa0b9809":"# Mixup & Data Generator","0453c15f":"# APTOS 2019: Blindness Detection","d749c153":"## Submit","90c3e872":"# Loading & Exploration","e63d9705":"## Find best threshold","159da552":"# Training & Evaluation"}}