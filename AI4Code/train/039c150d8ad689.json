{"cell_type":{"e8ef4e2f":"code","014dfd0a":"code","5adbb9ed":"code","97745b55":"code","335ef9b2":"code","f0c7d8db":"code","28d646f0":"code","9685893f":"code","15800fc1":"code","2bdd95a4":"code","ba872ced":"code","c866cb54":"code","5a60385f":"code","0279223e":"code","05d53485":"code","b1c2bf2d":"code","34f3a3d9":"code","30ea8ec6":"code","3be16849":"code","4c6eca38":"code","b2fe5c44":"code","191d6cc5":"code","f9b0ff93":"code","928f3625":"code","5f3e75a9":"code","027e6391":"code","9e0be54c":"code","9674a6aa":"code","ad4ee87c":"code","09b1b270":"code","be6c9f35":"code","6831a8b8":"code","15b4ab3c":"code","9fef054b":"code","044fa44c":"code","5c671b68":"code","d57d3746":"code","b17e74f6":"code","4ee0da95":"code","e50150e3":"code","f0b7957b":"code","b33a88bc":"code","cbdd4688":"code","b5125743":"code","1e5dea2f":"code","bbe0485a":"code","563b78b7":"code","e54f5b59":"code","a2ae596a":"code","f265f08a":"code","c89cda28":"code","5f33f53f":"code","32364b85":"code","ba8ad33b":"code","f6241ed8":"code","f21a6a7b":"code","2c0c2d2c":"code","2487375d":"code","6f18a49a":"code","04e0d925":"code","a82fa997":"code","811641fd":"code","0143a6ee":"code","c617ddbf":"code","00ed2994":"code","58804133":"code","875d3c5b":"code","43cbd303":"code","1d6812e7":"code","ccd6f0db":"code","3a1ebb48":"code","c1cddace":"code","9cdad173":"code","18b8f06b":"code","4a8ccbea":"code","5e09a84d":"markdown","8c4b852b":"markdown","5e08c8c6":"markdown","e136fde4":"markdown","55dd831b":"markdown","493fccaf":"markdown","8ffeab36":"markdown","1555305d":"markdown","18d3a4ce":"markdown","2017bd32":"markdown","478a01a7":"markdown","ff71d97b":"markdown","b7e33780":"markdown","1a36c952":"markdown","649bfb46":"markdown","d59f2b65":"markdown","d5286767":"markdown","efaf7179":"markdown","96b1d5ee":"markdown","2ef76b0d":"markdown","43e9a838":"markdown","f96794c2":"markdown","ae4286a5":"markdown","31661001":"markdown","8ee6607a":"markdown","e814d9e8":"markdown","269cd585":"markdown","eefdc87f":"markdown","39d0112c":"markdown","5f468a4e":"markdown","3bd5aad7":"markdown","efa9f727":"markdown"},"source":{"e8ef4e2f":"\nimport numpy as np\nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\nfrom plotly.offline import iplot, init_notebook_mode\n\nimport cufflinks as cf\nimport plotly.graph_objs as go\n\ninit_notebook_mode(connected=True)\ncf.go_offline(connected=True)\n\n# Set global theme\ncf.set_config_file(world_readable=True, theme='ggplot')","014dfd0a":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","5adbb9ed":"train_df.head()","97745b55":"train_df.info()","335ef9b2":"train_df.describe()","f0c7d8db":"preprocess_df = train_df.copy()\n\n","28d646f0":"preprocess_df.Pclass =  preprocess_df.Pclass.astype(str)\ntest_df.Pclass =  test_df.Pclass.astype(str)","9685893f":"preprocess_df.drop([\"Name\",\"PassengerId\"],inplace=True, axis=1)","15800fc1":"passenger_id = test_df.PassengerId\ntest_df.drop([\"Name\",\"PassengerId\"],inplace=True, axis=1)","2bdd95a4":"preprocess_df.SibSp =  preprocess_df.SibSp.astype(str)\npreprocess_df.Parch =  preprocess_df.Parch.astype(str)\n\n\ntest_df.SibSp =  test_df.SibSp.astype(str)\ntest_df.Parch =  test_df.Parch.astype(str)","ba872ced":"preprocess_df.Survived = preprocess_df.Survived.astype(str).str.replace('0',\"No\")\npreprocess_df.Survived = preprocess_df.Survived.astype(str).str.replace('1',\"Yes\")\n\n\n","c866cb54":"def customized_heatmap(corr_df):\n#     corr_mat = corr_df.iloc[1:,:-1].copy()\n    corr_mat = corr_df.copy()\n    \n    #Create masks\n    mask = np.triu(np.ones_like(corr_mat), k=1)\n    \n    # Plot\n    plt.figure(figsize=(20,10))\n    plt.title(\"Heatmap Corrleation\")\n    ax = sns.heatmap(corr_mat, vmin=-1, vmax=1, cbar=False,\n                     cmap='coolwarm', mask=mask, annot=True)\n    \n    # format the text in the plot to make it easier to read\n    for text in ax.texts:\n        t = float(text.get_text())\n        if -0.15 < t < 0.15:\n            text.set_text('')        \n        else:\n            text.set_text(round(t, 2))\n        text.set_fontsize('x-large')\n    plt.xticks( size='x-large')\n    plt.yticks(rotation=0, size='x-large')\n    plt.show()\n    ","5a60385f":"sns.heatmap(preprocess_df.corr(), annot=True)\n","0279223e":"preprocess_df.loc[:,preprocess_df.isnull().sum()>0].info()","05d53485":"preprocess_df.groupby('Embarked').mean()","b1c2bf2d":"sns.heatmap(preprocess_df[['Pclass','Age','Cabin']].isnull(), cmap=\"viridis\")","34f3a3d9":"preprocess_df.Age.describe()","30ea8ec6":"preprocess_df.Age.min()","3be16849":"preprocess_df.Age.hist()","4c6eca38":"preprocess_df.groupby('Pclass').mean().round(0)","b2fe5c44":"import math","191d6cc5":"def age_null_values(columns):\n    age =columns[0]\n    Pclass = columns[1]\n    if math.isnan(age):\n        if Pclass ==1:\n            return 38\n        elif Pclass == 2:\n            return 30\n        else:\n            return 25\n    else:\n        return age\n","f9b0ff93":"preprocess_df['Age']=preprocess_df[['Age',\"Pclass\"]].apply(age_null_values,axis=1)\ntest_df['Age']=test_df[['Age',\"Pclass\"]].apply(age_null_values,axis=1)","928f3625":"\npreprocess_df.drop(\"Cabin\",axis=1, inplace=True)\npreprocess_df.dropna(axis=0,inplace=True)\n\n#Drop Cabin Column for test data\ntest_df.drop(\"Cabin\",axis=1, inplace=True)\n\n","5f3e75a9":"#TO create 418 rows replace na by either mode and mean in Embarked and Fare column respectively\ntest_df['Embarked'].fillna(test_df['Embarked'].mode())\n","027e6391":"fare_mean = test_df['Fare'].mean()\ntest_df['Fare'].fillna(fare_mean,inplace=True)\n","9e0be54c":"# lets drop ticket columns\npreprocess_df.Ticket.describe()","9674a6aa":"\npreprocess_df.drop(\"Ticket\",inplace=True,axis=1)\ntest_df.drop(\"Ticket\",inplace=True,axis=1)","ad4ee87c":"eda_df = preprocess_df.copy()","09b1b270":"eda_df.Survived.value_counts()","be6c9f35":"fig= go.Figure()\nfig.add_trace(go.Pie(labels=eda_df.Survived.value_counts().index, values=eda_df.Survived.value_counts().values))\nfig.update_layout(title=\"Survived OR Not\", legend_title=\"Survival Legend\", template=\"plotly_dark\")","6831a8b8":"sib_sp_to_str = {\n    '0':'Zero',\n    '1':\"One\",\n    '2':\"Two\",\n    '3':\"Three\",\n    '4':\"Four\",\n    '5':\"Five\",\n    '6':\"Six\",\n    '7':\"Seven\",\n    \"8\":\"Eight\"\n    }","15b4ab3c":"eda_df.SibSp = eda_df.SibSp.replace(sib_sp_to_str)\ntest_df.SibSp = test_df.SibSp.replace(sib_sp_to_str)","9fef054b":"grp_by_sibsp = eda_df.groupby('SibSp').mean().sort_values(\"Age\", ascending=False)\n","044fa44c":"fig= go.Figure()\nfig.add_trace(go.Bar(x=grp_by_sibsp.index, y=grp_by_sibsp.Age, name='Age'))\nfig.add_trace(go.Bar(x=grp_by_sibsp.index, y=grp_by_sibsp.Fare, name=\"Fare\"))\n# fig.update_layout(title=\"Survived OR Not\", legend_title=\"Survival Legend\", template=\"plotly_dark\")","5c671b68":"int_columns=  eda_df.loc[:,eda_df.dtypes!=\"object\"].columns\n","d57d3746":"\nfig,axes = plt.subplots(len(int_columns), figsize=(10,10))\nfor i,col in enumerate(int_columns):\n    axes[i].hist(eda_df[eda_df.Survived == \"No\"][col].values, alpha=0.5, color=\"maroon\", bins=15 )\n    axes[i].hist(eda_df[eda_df.Survived == \"Yes\"][col].values, alpha=0.5, bins=15)\n    axes[i].set_title(col)\n    axes[i].set_yticks(())#cause we are not actually looking for numbers\naxes[0].set_xlabel(\"Feature Columns\")\naxes[0].set_ylabel(\"Frequency\")\naxes[0].legend([\"No\", \"Yes\"], loc=\"best\", title=\"Survived?\")\nfig.tight_layout()","b17e74f6":"pclass_to_str ={'1':'First','2':\"Second\",'3':\"Third\"}\n\neda_df.Pclass= eda_df.Pclass.replace(pclass_to_str)\ntest_df.Pclass= test_df.Pclass.replace(pclass_to_str)","4ee0da95":"class_1_survived_yes = eda_df[(eda_df.Pclass == \"First\") & (eda_df.Survived == \"Yes\")].shape[0]\nclass_1_survived_no = eda_df[(eda_df.Pclass == \"First\") & (eda_df.Survived == \"No\")].shape[0]\n\n\nclass_2_survived_yes = eda_df[(eda_df.Pclass == \"Second\") & (eda_df.Survived == \"Yes\")].shape[0]\nclass_2_survived_no = eda_df[(eda_df.Pclass == \"Second\") & (eda_df.Survived == \"No\")].shape[0]\n\nclass_3_survived_yes = eda_df[(eda_df.Pclass == \"Third\") & (eda_df.Survived == \"Yes\")].shape[0]\nclass_3_survived_no= eda_df[(eda_df.Pclass == \"Third\") & (eda_df.Survived == \"No\")].shape[0]","e50150e3":"survived_no =pd.Series([class_1_survived_no,class_2_survived_no,class_2_survived_no])\nsurvived_yes =pd.Series([class_1_survived_yes,class_2_survived_yes,class_2_survived_yes])","f0b7957b":"pclass_survived_avg = pd.pivot_table(eda_df, values=['Age'],index='Pclass',columns='Survived',)\n","b33a88bc":"pclass_survived_avg.columns =[\"Survived = No\",\"Survived = Yes\"]","cbdd4688":"pclass_survived_avg['Survived = No'] = pclass_survived_avg['Survived = No']\/survived_no.values\n\npclass_survived_avg['Survived = Yes'] = pclass_survived_avg['Survived = Yes']\/survived_yes.values\n","b5125743":"pclass_survived_avg_percentage =pclass_survived_avg*100","1e5dea2f":"fig= go.Figure()\nfig.add_trace(go.Bar(x=pclass_survived_avg_percentage.T.index, y=pclass_survived_avg_percentage.T['First'], name='First'))\nfig.add_trace(go.Bar(x=pclass_survived_avg_percentage.T.index, y=pclass_survived_avg_percentage.T['Second'], name=\"Second\"))\n\nfig.add_trace(go.Bar(x=pclass_survived_avg_percentage.T.index, y=pclass_survived_avg_percentage.T['Third'], name=\"Third\"))\n\nfig.update_layout(title=\"Average Survival Percentage By Passenger Class\", template=\"plotly_dark\", xaxis_title=\"Survived ?\", yaxis_title=\"Percentage\", legend_title=\"Pclass\")","bbe0485a":"fig= go.Figure()\nfig.add_trace(go.Pie(labels=eda_df.Sex.value_counts().index, values=eda_df.Sex.value_counts().values))\nfig.update_layout(title=\"Population\", legend_title=\"Sex\", template=\"plotly_dark\")","563b78b7":"plt.figure(figsize=(10,7))\nsns.countplot(eda_df['Sex'], hue=eda_df['Survived'], palette=\"viridis\")\nplt.xlabel(\"Gender\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Survival By Gender\");","e54f5b59":"df = eda_df.copy()","a2ae596a":"from sklearn.preprocessing import MinMaxScaler\n\nscaler = MinMaxScaler()","f265f08a":"scaler.fit(df[[\"Age\",\"Fare\"]])\ndf[[\"Age\",\"Fare\"]] = scaler.transform(df[[\"Age\",\"Fare\"]])\n\ntarget = df['Survived']\n\ndf_dummy = df.loc[:,df.columns!=\"Survived\"]\n\n# For test \n\ntest_df[[\"Age\",\"Fare\"]] = scaler.transform(test_df[[\"Age\",\"Fare\"]])","c89cda28":"df_dummy = pd.get_dummies(df_dummy, drop_first=True)","5f33f53f":"from sklearn.model_selection import train_test_split","32364b85":"X_train, X_test, y_train, y_test = train_test_split( df_dummy.loc[:,df_dummy.columns!=\"Survived\"], target, test_size=0.1, random_state=101)","ba8ad33b":"#Import model and train model\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n\nfrom sklearn.model_selection import KFold, cross_val_score","f6241ed8":"num_folds = 10\nscoring = \"accuracy\"\nmodels=[]\nrand_seed= 101\n\nmodels.append((\"Knn\",KNeighborsClassifier(n_neighbors=5,p=2,leaf_size=10,) ))\nmodels.append((\"Log\",LogisticRegression(random_state=rand_seed) ))\nmodels.append((\"Svm\",SVC(random_state=rand_seed )))\nmodels.append((\"Rf\", RandomForestClassifier(n_estimators=50,max_depth=5,random_state=rand_seed )))\n\n\n\nresults=[]\nnames=[]\nmetrics=[]","f21a6a7b":"for name, model in models:\n    kfold = KFold(n_splits=num_folds, random_state=rand_seed, shuffle=True)\n    cv_score = cross_val_score(model,X_train,y_train, cv=kfold, scoring=scoring)\n    \n    names.append(name)\n    results.append(cv_score)\n    metrics.append(cv_score.mean())\n    \n    print(\"{name}: {score}\".format(name=name,score= cv_score.mean()*100))","2c0c2d2c":"from sklearn.model_selection import RandomizedSearchCV\n\nfrom sklearn.model_selection import GridSearchCV","2487375d":"# Number of trees in random forest\nn_estimators = [i for i in range(200,2001, 200)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [i for i in range(10, 111,10)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}\nprint(random_grid)\n","6f18a49a":"# rf = RandomForestClassifier()\n\n\n# # Random search of parameters, using 3 fold cross validation, \n# # search across 80 different combinations, and use all available cores\n# rf_random_cv = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 80, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n# # Fit the random search model\n# rf_random_cv.fit(X_train,y_train)","04e0d925":"# print(rf_random_cv.best_params_)","a82fa997":"param_grid_rf = {\n    'bootstrap':[True],\n    'max_depth': [5,10,15,20],\n    'max_features': ['sqrt'],\n    'min_samples_leaf': [ 1,3,5,7],\n    'min_samples_split': [8,10,12,14],\n    'n_estimators': [200,600,1200,1600,1800]\n}\n","811641fd":"# # Instantiate the grid search model\n# grid_search_cv_rf = GridSearchCV(RandomForestClassifier(), param_grid = param_grid_rf, \n#                           cv = 10, n_jobs = -1, verbose = 1)\n\n# grid_search_cv_rf.fit(X_train, y_train)\n","0143a6ee":"# print(grid_search_cv_rf.best_params_)\n# print(grid_search_cv_rf.best_score_)\n","c617ddbf":"final_rf= RandomForestClassifier(bootstrap=True,                                \n                                   max_depth=10,\n                                 max_features='sqrt',\n                                   min_samples_leaf=1,\n                                   min_samples_split=10,\n                                   n_estimators=1600)","00ed2994":"final_rf.fit(X_train,y_train)","58804133":"y_pred = final_rf.predict(X_test)","875d3c5b":"from sklearn.metrics import confusion_matrix, classification_report","43cbd303":"print(confusion_matrix(y_test, y_pred), \"\\n\")\n\nprint(classification_report(y_test, y_pred), \"\\n\")","1d6812e7":"test_df.Parch.unique()","ccd6f0db":"eda_df.Parch.unique()","3a1ebb48":"test_df_dummy = pd.get_dummies(test_df, drop_first=True)\n","c1cddace":"test_df_dummy.drop('Parch_9', inplace=True, axis=1)","9cdad173":"\n\nfinal_test_data_pred = final_rf.predict(test_df_dummy)","18b8f06b":"submission_csv = pd.DataFrame(data={'PassengerId':passenger_id,'Survived': final_test_data_pred})","4a8ccbea":"submission_csv.to_csv(\"Titianic_Submission.csv\", index=False)","5e09a84d":"Now use apply to replace values for both train and test data","8c4b852b":"Test df has more Parch values than the train df, lets drop the one that isn't in the test df.","5e08c8c6":"Best Params according to GridSearch  ","e136fde4":"lets use \"Age\" average by \"Pclass\" to fill missing data in the \"Age\" column.","55dd831b":"Following codes are commented to make loading version faster.","493fccaf":"## Correlation","8ffeab36":"# Preprocessing","1555305d":"# Model Development","18d3a4ce":"## Split the dataset into train and test set\n","2017bd32":"Parmas from randomized cv : {'n_estimators': 1600, 'min_samples_split': 10, 'min_samples_leaf': 1, 'max_features': 'sqrt', 'max_depth': 20, 'bootstrap': True}\n\n\nLets use this value in Grid Search CV.\n","478a01a7":"Drop \"Embarked\" column and missing row from \"Cabin\" column","ff71d97b":"# EDA","b7e33780":"## SibSp ","1a36c952":"# Final Prediction in Test Data\n","649bfb46":"Form the histogram, it seems that the infant had more survival rate than death rate. Surprisingly, people in their twenties were more dead than they survive.\n\nAs far as the Fare goes the people with cheaper \"Fare\" had less survival rates than those of expensive.","d59f2b65":"## Name, PassengerId\n\nName and PassengerID are not the ones that can help in analysis or model developement so lets drop it. ","d5286767":"## Fare Vs Pclass","efaf7179":"Scaling some feature columns","96b1d5ee":"## Passenger Class\n\nPassenger class is in integer value but its actually an ordinal number so lets convert it to string.","2ef76b0d":"**Lets drop the Name, PassengerID column**","43e9a838":"# Survival Column \n\nMake survival column string column 0 = No, 1 = Yes\n","f96794c2":"## Model Selection ","ae4286a5":"## Age Vs Sruvival ","31661001":"Male passengers had less sruvival count than females. ","8ee6607a":"lets use Random Forest, but first test some hyper-params","e814d9e8":"## Survival Proportion","269cd585":"# SibSp and Parch\n \n**SibSp** is the number of siblings\/ spouses aboard the Titanic, while **Parch** are the number of parents\/ children aboard the Titanic. Number of people cannot be a continuos value cause there is no possiblity of having 2.5 siblings.\n","eefdc87f":"There were more male passengers than females.","39d0112c":"We are attempting to caculate percentage of survived based on class of passengers. ","5f468a4e":"It seems the First Class passengers were more to die than others. It also looks like less than 30% of passengers survived in all classes. ","3bd5aad7":"## Gender","efa9f727":"### Dealing with missing values"}}