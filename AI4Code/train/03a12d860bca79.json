{"cell_type":{"4dd6ccab":"code","2259c7ee":"code","290a846d":"code","3aab1f56":"code","261d3403":"code","f0872fe1":"code","dc32e9f8":"code","b30106b0":"code","1301533b":"code","37db4f65":"code","127b0b15":"code","fe73e141":"code","9c099eac":"code","fb291333":"code","99c56955":"code","100fe9ad":"code","d73bd0b7":"code","1d0abda8":"code","ba6d6c48":"code","5230d529":"code","4248f314":"code","8754bd02":"code","2122ecc1":"code","0e1f987a":"code","866b40d0":"code","a25de9de":"code","2382ae9e":"code","fe90dcf7":"code","10255a49":"code","f4d64305":"code","c6d69c2c":"code","fc4681a0":"code","8c4307b5":"code","2cac3fe9":"code","7a652a6a":"code","06739125":"code","5e93c189":"code","2b16cf06":"code","84ff1aed":"code","61d7ac63":"code","a083b2f9":"code","e18330fc":"code","4c9e08d1":"code","b4733675":"code","d2f3de6e":"code","aa53cbf7":"code","3847df2a":"code","c530566c":"code","c87eebd0":"code","8b3d2187":"code","35ff6d10":"markdown","a8f219c1":"markdown","09e2aba4":"markdown","b1fc287d":"markdown"},"source":{"4dd6ccab":"!pip install git+https:\/\/github.com\/darecophoenixx\/wordroid.sblo.jp","2259c7ee":"from keras_ex.gkernel import GaussianKernel, GaussianKernel2, GaussianKernel3\nfrom keras_ex.gkernel.sklearn import (\n    RBFRegressor, RBFClassifier,\n    make_model_gkernel1,\n    make_model_gkernel2,\n    make_model_gkernel3,\n    make_model_out,\n    make_model\n)","290a846d":"%matplotlib inline\nimport os, sys\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn import datasets, linear_model\nfrom sklearn.metrics import f1_score, classification_report, confusion_matrix, make_scorer\nfrom sklearn.preprocessing import OneHotEncoder\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Input, Dense\nfrom keras.models import Model\nfrom keras.optimizers import SGD\nfrom keras import regularizers\nfrom keras.wrappers.scikit_learn import KerasClassifier, KerasRegressor\nfrom keras import backend as K\nimport tensorflow as tf","3aab1f56":"from sklearn.datasets import make_moons\n\nn_samples = 2500\nX1, y1 = make_moons(n_samples=n_samples, noise=.15, random_state=0)\ndf = pd.DataFrame(X1)\ndf.columns = [\"col1\", \"col2\"]\ndf['cls'] = y1\n\nsns.lmplot(\"col1\", \"col2\", hue=\"cls\", data=df, fit_reg=False, size=8, markers='o')","261d3403":"n_samples = 500\nX2, y2 = make_moons(n_samples=n_samples, noise=.15, random_state=0)\nX2[:,0] += 1\nX2[:,1] += 1\ndf = pd.DataFrame(X2)\ndf.columns = [\"col1\", \"col2\"]\ndf['cls'] = y2\n\nsns.lmplot(\"col1\", \"col2\", hue=\"cls\", data=df, fit_reg=False, size=8, markers='o')","f0872fe1":"X = np.r_[X1,X2]\ny = np.concatenate([y1, y2])\n\ndf = pd.DataFrame(X)\ndf.columns = [\"col1\", \"col2\"]\ndf['cls'] = y\n\nsns.lmplot(\"col1\", \"col2\", hue=\"cls\", data=df, fit_reg=False, size=8, markers='o')","dc32e9f8":"X.shape, X.min(), X.max()","b30106b0":"y.shape","1301533b":"N = y.shape[0]\nindex = np.arange(N)\nxtrain = X[index[index % 2 != 0],:]\nytrain = y[index[index % 2 != 0]]\nxtest = X[index[index % 2 == 0],:]\nyans = y[index[index % 2 == 0]]","37db4f65":"from sklearn.model_selection import StratifiedShuffleSplit, GridSearchCV, validation_curve\nfrom sklearn.feature_selection import RFECV\nfrom sklearn.linear_model import LogisticRegression, Lasso\nimport pandas as pd\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error, roc_auc_score, r2_score, make_scorer\nfrom sklearn.metrics.pairwise import cosine_similarity, euclidean_distances\nimport joblib\n\nfrom lightgbm import LGBMClassifier","127b0b15":"import warnings\nwarnings.filterwarnings('ignore')","fe73e141":"def f1_scorer(estimator, X, y):\n    pred = estimator.predict(X)\n    s = f1_score(y, pred, average='macro')\n    return s","9c099eac":"clf = RBFClassifier(\n    num_lm=200,\n    lm_select_from_x=True\n)","fb291333":"%%time\nhst = clf.fit(xtrain, ytrain, epochs=200, batch_size=300, verbose=0)","99c56955":"fig, ax = plt.subplots(1, 3, figsize=(20,5))\nax[0].set_title('loss')\nax[0].plot(list(range(len(hst[\"loss\"]))), hst[\"loss\"], label=\"Train loss\")\nax[1].set_title('accuracy')\nax[1].plot(list(range(len(hst[\"loss\"]))), hst[\"accuracy\"], label=\"accuracy\")\nax[2].set_title('learning rate')\nax[2].plot(list(range(len(hst[\"loss\"]))), hst[\"lr\"], label=\"learning rate\")\nax[0].legend()\nax[1].legend()\nax[2].legend()","100fe9ad":"pred = clf.predict(xtrain)","d73bd0b7":"print('F1_SCORE :', f1_score(ytrain, pred, average='macro'))\nprint(classification_report(ytrain, pred))\nprint(confusion_matrix(ytrain, pred))","1d0abda8":"pred_test = clf.predict(xtest)\npred_test.shape","ba6d6c48":"print('F1_SCORE :', f1_score(yans, pred_test, average='macro'))\nprint(classification_report(yans, pred_test))\nprint(confusion_matrix(yans, pred_test))","5230d529":"'''get landmarks'''\nlm = clf.current_lm()\nlm.shape","4248f314":"from matplotlib.colors import ListedColormap\n\nh = .01\nx_min, x_max = xtrain[:, 0].min() - .1, xtrain[:, 0].max() + .1\ny_min, y_max = xtrain[:, 1].min() - .1, xtrain[:, 1].max() + .1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\ny_pred = clf.predict_proba(np.c_[xx.ravel(), yy.ravel()])\ny_pred\n\n#cm = plt.cm.coolwarm\ncm = plt.cm.nipy_spectral\ncm_bright = ListedColormap(['#FFFF00', '#00FFFF'])\ny_pred = y_pred[:,1].reshape(xx.shape)\nplt.figure(figsize=(10, 8))\nplt.contourf(xx, yy, y_pred, 100, cmap=cm, alpha=1)\nplt.scatter(xtrain[:,0], xtrain[:,1], c=ytrain, cmap=cm_bright, edgecolors='k')\nplt.scatter(lm[:,0], lm[:,1], c='red', s=64, marker='s', edgecolors='w')","8754bd02":"from sklearn.svm import SVC","2122ecc1":"%%time\nsvc = SVC(gamma='scale', probability=True)\nsvc.fit(xtrain, ytrain)","0e1f987a":"pred = svc.predict(xtrain)","866b40d0":"print('F1_SCORE :', f1_score(ytrain, pred, average='macro'))\nprint(classification_report(ytrain, pred))\nprint(confusion_matrix(ytrain, pred))","a25de9de":"pred_test = svc.predict(xtest)\npred_test.shape","2382ae9e":"print('F1_SCORE :', f1_score(yans, pred_test, average='macro'))\nprint(classification_report(yans, pred_test))\nprint(confusion_matrix(yans, pred_test))","fe90dcf7":"h = .01\nx_min, x_max = xtrain[:, 0].min() - .1, xtrain[:, 0].max() + .1\ny_min, y_max = xtrain[:, 1].min() - .1, xtrain[:, 1].max() + .1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\ny_pred = svc.predict_proba(np.c_[xx.ravel(), yy.ravel()])\ny_pred\n\n#cm = plt.cm.coolwarm\ncm = plt.cm.nipy_spectral\ncm_bright = ListedColormap(['#FFFF00', '#00FFFF'])\ny_pred = y_pred[:,1].reshape(xx.shape)\nplt.figure(figsize=(10, 8))\nplt.contourf(xx, yy, y_pred, 100, cmap=cm, alpha=1)\nplt.scatter(xtrain[:,0], xtrain[:,1], c=ytrain, cmap=cm_bright, edgecolors='k')","10255a49":"cv_splitter = StratifiedShuffleSplit(n_splits=3, test_size=0.35, random_state=0)\ncv_splitter.get_n_splits(xtrain, ytrain)","f4d64305":"param_name = \"C\"\nparam_range = np.logspace(-3, 3, 7)\nparam_range","c6d69c2c":"%%time\n\ntrain_scores, test_scores = validation_curve(\n    LogisticRegression(penalty='l1', multi_class='multinomial', solver='saga', max_iter=10000),\n    xtrain, ytrain,\n    param_name=param_name, param_range=param_range,\n    cv=cv_splitter, n_jobs=1, verbose=2, scoring=f1_scorer)","fc4681a0":"train_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\nnp.c_[param_range, train_scores_mean, test_scores_mean]","8c4307b5":"plt.title(\"Validation Curve\")\nplt.xlabel(\"param\")\nplt.ylabel(\"Score\")\nplt.ylim(0.0, 1.1)\nlw = 2\nplt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n             color=\"darkorange\", lw=lw)\nplt.fill_between(param_range, train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, alpha=0.2,\n                 color=\"darkorange\", lw=lw)\nplt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n             color=\"navy\", lw=lw)\nplt.fill_between(param_range, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.2,\n                 color=\"navy\", lw=lw)\nplt.legend(loc=\"best\")","2cac3fe9":"'''test data'''\nest = LogisticRegression(penalty='l1', multi_class='multinomial', solver='saga', max_iter=10000, C=1.0)\nest.fit(xtrain, ytrain)","7a652a6a":"pred = est.predict(xtrain)","06739125":"print('F1_SCORE :', f1_score(ytrain, pred, average='macro'))\nprint(classification_report(ytrain, pred))\nprint(confusion_matrix(ytrain, pred))","5e93c189":"pred_test = est.predict(xtest)","2b16cf06":"print('F1_SCORE :', f1_score(yans, pred_test, average='macro'))\nprint(classification_report(yans, pred_test))\nprint(confusion_matrix(yans, pred_test))","84ff1aed":"h = .01\nx_min, x_max = xtrain[:, 0].min() - .1, xtrain[:, 0].max() + .1\ny_min, y_max = xtrain[:, 1].min() - .1, xtrain[:, 1].max() + .1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\ny_pred = est.predict_proba(np.c_[xx.ravel(), yy.ravel()])\ny_pred\n\ncm = plt.cm.coolwarm\ncm_bright = ListedColormap(['#FFFF00', '#00FFFF'])\ny_pred = y_pred[:,1].reshape(xx.shape)\nplt.figure(figsize=(10, 8))\nplt.contourf(xx, yy, y_pred, 100, cmap=cm, alpha=1)\nplt.scatter(xtrain[:,0], xtrain[:,1], c=ytrain, cmap=cm_bright, edgecolors='k')","61d7ac63":"cv_splitter = StratifiedShuffleSplit(n_splits=3, test_size=0.35, random_state=0)\ncv_splitter.get_n_splits(xtrain, ytrain)","a083b2f9":"param_name = \"reg_alpha\"\nparam_range = np.logspace(-3, 3, 7)\nparam_range","e18330fc":"%%time\n\ntrain_scores, test_scores = validation_curve(\n    LGBMClassifier(\n        min_child_samples=20,\n        reg_alpha=0.1\n    ),\n    xtrain, ytrain,\n    param_name=param_name, param_range=param_range,\n    cv=cv_splitter, n_jobs=1, verbose=2, scoring=f1_scorer)","4c9e08d1":"train_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\nnp.c_[param_range, train_scores_mean, test_scores_mean]","b4733675":"plt.title(\"Validation Curve\")\nplt.xlabel(\"param\")\nplt.ylabel(\"Score\")\nplt.ylim(0.0, 1.1)\nlw = 2\nplt.semilogx(param_range, train_scores_mean, label=\"Training score\",\n             color=\"darkorange\", lw=lw)\nplt.fill_between(param_range, train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, alpha=0.2,\n                 color=\"darkorange\", lw=lw)\nplt.semilogx(param_range, test_scores_mean, label=\"Cross-validation score\",\n             color=\"navy\", lw=lw)\nplt.fill_between(param_range, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.2,\n                 color=\"navy\", lw=lw)\nplt.legend(loc=\"best\")","d2f3de6e":"'''test data'''\nest = LGBMClassifier(\n        min_child_samples=20,\n        reg_alpha=0.1\n    )\nest.fit(xtrain, ytrain)","aa53cbf7":"pred = est.predict(xtrain)","3847df2a":"print('F1_SCORE :', f1_score(ytrain, pred, average='macro'))\nprint(classification_report(ytrain, pred))\nprint(confusion_matrix(ytrain, pred))","c530566c":"pred_test = est.predict(xtest)","c87eebd0":"print('F1_SCORE :', f1_score(yans, pred_test, average='macro'))\nprint(classification_report(yans, pred_test))\nprint(confusion_matrix(yans, pred_test))","8b3d2187":"h = .01\nx_min, x_max = xtrain[:, 0].min() - .1, xtrain[:, 0].max() + .1\ny_min, y_max = xtrain[:, 1].min() - .1, xtrain[:, 1].max() + .1\nxx, yy = np.meshgrid(np.arange(x_min, x_max, h),\n                     np.arange(y_min, y_max, h))\ny_pred = est.predict_proba(np.c_[xx.ravel(), yy.ravel()])\ny_pred\n\ncm = plt.cm.coolwarm\ncm_bright = ListedColormap(['#FFFF00', '#00FFFF'])\ny_pred = y_pred[:,1].reshape(xx.shape)\nplt.figure(figsize=(10, 8))\nplt.contourf(xx, yy, y_pred, 100, cmap=cm, alpha=1)\nplt.scatter(xtrain[:,0], xtrain[:,1], c=ytrain, cmap=cm_bright, edgecolors='k')","35ff6d10":"## LGBMClassifier","a8f219c1":"## SVM","09e2aba4":"* [RBFClassifier scikit-learn API](https:\/\/github.com\/darecophoenixx\/wordroid.sblo.jp\/wiki\/RBFClassifier-RBFRegressor)\n* moon","b1fc287d":"## LogisticRegression"}}