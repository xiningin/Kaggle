{"cell_type":{"96a6edaa":"code","a965d6b9":"code","6b8bb591":"code","970e776c":"code","87839891":"code","872ac207":"code","3b9ef16a":"code","04e31424":"code","f05000ca":"code","100d03d7":"code","2b7ded49":"code","43f170a7":"code","3e6001fd":"markdown","ce90e0a8":"markdown","4797bda1":"markdown","7d52df7b":"markdown","16665d52":"markdown","e20b02f6":"markdown","fd948f58":"markdown","ba720fe2":"markdown","75f64d60":"markdown"},"source":{"96a6edaa":"import pandas as pd\nimport os\nimport re\nimport string\n\nfrom nltk.tokenize import word_tokenize\n\nfrom sklearn import linear_model\nfrom sklearn import metrics\nfrom sklearn import model_selection\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nfrom sklearn import tree\nfrom sklearn import naive_bayes\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom xgboost import XGBClassifier","a965d6b9":"# read the training data\ndf = pd.read_csv(\"..\/input\/trip-advisor-hotel-reviews\/tripadvisor_hotel_reviews.csv\")","6b8bb591":"df.head()","970e776c":"# we create new column called kfold and fill it with -1\ndf[\"kfold\"] = -1\n\n# the next step is to randomize the rown of the data\ndf = df.sample(frac=1).reset_index(drop=True)\n\n# fetch the value\ny = df.Rating.values\n\n# initiate the kfold class from model selection modul\nkf = model_selection.StratifiedKFold(n_splits=5)\n\n# Fill the new kfold column\nfor f, (t_, v_) in enumerate(kf.split(X=df, y=y)):\n    df.loc[v_, 'kfold'] = f","87839891":"df.head()","872ac207":"models = {\n    \"lr\": linear_model.LogisticRegression(),\n    \"decision_tree_gini\": tree.DecisionTreeClassifier(criterion=\"gini\"),\n    \"decision_tree_entropy\": tree.DecisionTreeClassifier(criterion=\"entropy\"),\n    \"bayes\": naive_bayes.MultinomialNB(),\n    \"XGBClassifier\": XGBClassifier()\n}\n\nvectorizers = {\n    \"count_vectorizer\": CountVectorizer(\n        tokenizer = word_tokenize,\n        token_pattern=None\n        # do not see improvement use ngram\n        #ngram_range=(1, 3)\n        ),\n    \"tfid_vectorizer\": TfidfVectorizer(\n        tokenizer=word_tokenize,\n        token_pattern=None\n        # do not see improvement use ngram\n        #ngram_range=(1, 3)\n        )\n}","3b9ef16a":"def clean_text(s):\n    \"\"\"\n    This function cleans the text a bit\n    :param s: string\n    :return: cleaned string\n    \"\"\"\n    # Convert to lower case\n    s = s.lower()\n\n    # split by all whitespaces\n    s = s.split()\n\n    # join tokens by single space\n    # why we do this?\n    # this will remove all kinds of weird space # \"hi. how are you\" becomes\n    # \"hi. how are you\"\n    s = \" \".join(s)\n\n    # remove all punctuations using regex and string module\n    s = re.sub(f'[{re.escape(string.punctuation)}]', '', s)\n\n    # you can add more cleaning here if you want\n    # and then return the cleaned string\n    return s\n","04e31424":"def run(fold, model, vectorizer):\n    # applying clean_text to Revies column\n    df.loc[:, 'Review'] = df.Review.apply(clean_text)\n\n    # training data is where kfold is not equal to provided fold\n    # also, note that we reset the index\n    df_train = df[df.kfold != fold].reset_index(drop=True)\n\n    # validation data is where kfold is equal to provided fold\n    df_test = df[df.kfold == fold].reset_index(drop=True)\n\n    # initialize CountVectorizer with NLTK,s word_tokenize\n    # function as tokenizer\n    vectorizer = vectorizers[vectorizer]\n\n    #fit count_vec on training data reviews\n    vectorizer.fit(df_train.Review)\n\n    #transform training and validation data reviews\n    xtrain = vectorizer.transform(df_train['Review'])\n    xtest = vectorizer.transform(df_test['Review'])\n\n    ytrain = df_train.Rating\n\n    # initialize model\n    clf = models[model]\n\n    #initialize hyperparameter if you want use\n    # if not just give # sign in\n    # clf = logreg(clf,xtrain,ytrain)\n\n    #fit the model on training data reviews and Rating\n    clf.fit(xtrain, df_train.Rating)\n\n    # make prediction on test data\n    # threshold for predictions is 0.5\n    preds = clf.predict(xtest)\n\n    #calculate accuracy\n    accuracy = metrics.accuracy_score(df_test.Rating, preds)\n\n    print(f\"Model={model}\")\n    print(f\"Vectorizer={vectorizer}\")\n    print(f\"Fold={fold}\")\n    print(f\"Accuracy = {accuracy}\")\n    print(\"\")","f05000ca":"run(1,\"lr\",\"tfid_vectorizer\"),\nrun(1,\"decision_tree_gini\",\"tfid_vectorizer\"),\nrun(1,\"decision_tree_entropy\",\"tfid_vectorizer\"),\nrun(1,\"bayes\",\"tfid_vectorizer\"),\nrun(1,\"XGBClassifier\",\"tfid_vectorizer\")","100d03d7":"run(1,\"lr\",\"tfid_vectorizer\"),\nrun(1,\"lr\",\"count_vectorizer\")","2b7ded49":"run(0,\"lr\",\"tfid_vectorizer\"),\nrun(1,\"lr\",\"tfid_vectorizer\"),\nrun(2,\"lr\",\"tfid_vectorizer\"),\nrun(3,\"lr\",\"tfid_vectorizer\"),\nrun(4,\"lr\",\"tfid_vectorizer\"),","43f170a7":"run(3,\"lr\",\"tfid_vectorizer\")","3e6001fd":"### Search Best Folds","ce90e0a8":"## Best Result","4797bda1":"### Search best ML Model","7d52df7b":"## Create Clean Text","16665d52":"## Run Model and Search Best Model","e20b02f6":"## Create Dispatcher","fd948f58":"## Create Model","ba720fe2":"### Search Best Vectorizer","75f64d60":"### Create Folds"}}