{"cell_type":{"7ac83597":"code","7a45d0a7":"code","a8df54e5":"code","6fe17bc9":"code","cac9e58c":"code","f782b47c":"code","c4750578":"code","cdfe951a":"code","d582da06":"code","5607f5bc":"code","c8ddba91":"code","a729d207":"code","da14b012":"code","65fc3c81":"code","54034e20":"code","2da3f949":"code","7da222f4":"code","439343b9":"code","1a3d5421":"code","f9231cdc":"code","bbf00822":"code","ed4c7295":"code","b57b91d2":"code","f5f01373":"code","a56c7cd0":"code","79d19c1f":"code","915823ac":"code","989cf63f":"code","f12fa880":"code","5920ae37":"code","5aa1decd":"code","ebda7dd6":"code","03ea100c":"code","b859d979":"code","a4dc4101":"code","ba72f949":"code","3d567a68":"code","f2e2c547":"code","be96a6b4":"code","6535a4f2":"code","ae81f198":"code","78946dae":"code","1de8a295":"code","3d849318":"code","85cbe69c":"code","fd00bcd2":"code","5cc196ed":"code","4fb43711":"code","e123fb11":"code","d8b7c264":"code","68e74229":"code","8f42fbdf":"code","4d1c3e43":"code","c1d2448f":"code","a53e38f7":"code","4edcd9a4":"code","cce5e768":"markdown","dc1e5f67":"markdown","220f26f3":"markdown","fa571bd3":"markdown","116e7c10":"markdown","4b093ae0":"markdown","24d99fe9":"markdown","c281a2d3":"markdown","d7ea56de":"markdown","9025e498":"markdown","c69f019c":"markdown","27044d1e":"markdown","31d6bfba":"markdown","ea2d56cf":"markdown","68aaa196":"markdown","6f42e9de":"markdown","bec2f11e":"markdown","4b8a0e50":"markdown","22339f78":"markdown","4032e74e":"markdown","9208edc3":"markdown","ed0cf2e6":"markdown","2fd83a9b":"markdown","b4ddaa4c":"markdown","378dc3b4":"markdown","e90b27c4":"markdown","19ab8c26":"markdown","eba61200":"markdown","bab31f77":"markdown","f6d5b227":"markdown","c62f83d1":"markdown","0e441f45":"markdown","76efd6a9":"markdown","e9a1dab3":"markdown","354412b3":"markdown","eac4a790":"markdown","47378d05":"markdown","40b9fb23":"markdown","3ebd5f93":"markdown","ef2d243f":"markdown","a5cd2be1":"markdown","15022ae8":"markdown","29a3fd5c":"markdown","aae6f8ab":"markdown","7adddeb5":"markdown","db9074cc":"markdown","3a3b1156":"markdown","4ef9836e":"markdown"},"source":{"7ac83597":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7a45d0a7":"# Supress Warnings\nimport warnings\nwarnings.filterwarnings('ignore')","a8df54e5":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","6fe17bc9":"# Data display coustomization\npd.set_option('display.max_columns', None)\npd.set_option('display.max_colwidth', -1)","cac9e58c":"# To perform Hierarchical clustering\nfrom scipy.cluster.hierarchy import linkage\nfrom scipy.cluster.hierarchy import dendrogram\nfrom scipy.cluster.hierarchy import cut_tree\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.cluster import KMeans","f782b47c":"# import all libraries and dependencies for machine learning\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.decomposition import PCA\nfrom sklearn.decomposition import IncrementalPCA\nfrom sklearn.neighbors import NearestNeighbors\nfrom random import sample\nfrom numpy.random import uniform\nfrom math import isnan","c4750578":"mall= pd.read_csv(r\"\/kaggle\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv\")\nmall.head()","cdfe951a":"mall.shape","d582da06":"mall.info()","5607f5bc":"mall.describe()","c8ddba91":"mall_d= mall.copy()\nmall_d.drop_duplicates(subset=None,inplace=True)","a729d207":"mall_d.shape","da14b012":"mall.shape","65fc3c81":"(mall.isnull().sum() * 100 \/ len(mall)).value_counts(ascending=False)","54034e20":"mall.isnull().sum()","2da3f949":"(mall.isnull().sum(axis=1) * 100 \/ len(mall)).value_counts(ascending=False)","7da222f4":"mall.isnull().sum(axis=1).value_counts(ascending=False)","439343b9":"plt.figure(figsize = (5,5))\ngender = mall['Gender'].sort_values(ascending = False)\nax = sns.countplot(x='Gender', data= mall)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\nplt.xticks(rotation=90)\nplt.show()","1a3d5421":" \nplt.figure(figsize = (20,5))\ngender = mall['Age'].sort_values(ascending = False)\nax = sns.countplot(x='Age', data= mall)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\n\nplt.show()","f9231cdc":"plt.figure(figsize = (25,5))\ngender = mall['Annual Income (k$)'].sort_values(ascending = False)\nax = sns.countplot(x='Annual Income (k$)', data= mall)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\n\nplt.show()","bbf00822":"plt.figure(figsize = (27,5))\ngender = mall['Spending Score (1-100)'].sort_values(ascending = False)\nax = sns.countplot(x='Spending Score (1-100)', data= mall)\nfor p in ax.patches:\n    ax.annotate(str(p.get_height()), (p.get_x() * 1.01 , p.get_height() * 1.01))\n\nplt.show()","ed4c7295":"# Let's check the correlation coefficients to see which variables are highly correlated\n\nplt.figure(figsize = (5,5))\nsns.heatmap(mall.corr(), annot = True, cmap=\"rainbow\")\nplt.savefig('Correlation')\nplt.show()","b57b91d2":"sns.pairplot(mall,corner=True,diag_kind=\"kde\")\nplt.show()","f5f01373":"# Data before Outlier Treatment \nmall.describe()","a56c7cd0":"f, axes = plt.subplots(1,3, figsize=(15,5))\ns=sns.violinplot(y=mall.Age,ax=axes[0])\naxes[0].set_title('Age')\ns=sns.violinplot(y=mall['Annual Income (k$)'],ax=axes[1])\naxes[1].set_title('Annual Income (k$)')\ns=sns.violinplot(y=mall['Spending Score (1-100)'],ax=axes[2])\naxes[2].set_title('Spending Score (1-100)')\nplt.show()\n","79d19c1f":"Q3 = mall['Annual Income (k$)'].quantile(0.99)\nQ1 = mall['Annual Income (k$)'].quantile(0.01)\nmall['Annual Income (k$)'][mall['Annual Income (k$)']<=Q1]=Q1\nmall['Annual Income (k$)'][mall['Annual Income (k$)']>=Q3]=Q3","915823ac":"# Data After Outlier Treatment \nmall.describe()","989cf63f":"f, axes = plt.subplots(1,3, figsize=(15,5))\ns=sns.violinplot(y=mall.Age,ax=axes[0])\naxes[0].set_title('Age')\ns=sns.violinplot(y=mall['Annual Income (k$)'],ax=axes[1])\naxes[1].set_title('Annual Income (k$)')\ns=sns.violinplot(y=mall['Spending Score (1-100)'],ax=axes[2])\naxes[2].set_title('Spending Score (1-100)')\nplt.show()","f12fa880":"# Dropping CustomerID,Gender field to form cluster\n\nmall_c = mall.drop(['CustomerID','Gender'],axis=1,inplace=True)","5920ae37":"mall.head()","5aa1decd":"def hopkins(X):\n    d = X.shape[1]\n    n = len(X)\n    m = int(0.1 * n) \n    nbrs = NearestNeighbors(n_neighbors=1).fit(X.values)\n \n    rand_X = sample(range(0, n, 1), m)\n \n    ujd = []\n    wjd = []\n    for j in range(0, m):\n        u_dist, _ = nbrs.kneighbors(uniform(np.amin(X,axis=0),np.amax(X,axis=0),d).reshape(1, -1), 2, return_distance=True)\n        ujd.append(u_dist[0][1])\n        w_dist, _ = nbrs.kneighbors(X.iloc[rand_X[j]].values.reshape(1, -1), 2, return_distance=True)\n        wjd.append(w_dist[0][1])\n \n    HS = sum(ujd) \/ (sum(ujd) + sum(wjd))\n    if isnan(HS):\n        print(ujd, wjd)\n        HS = 0\n \n    return HS","ebda7dd6":"# Hopkins score\nHopkins_score=round(hopkins(mall),2)","03ea100c":"print(\"{} is a good Hopkins score for Clustering.\".format(Hopkins_score))","b859d979":"# Standarisation technique for scaling\nscaler = StandardScaler()\nmall_scaled = scaler.fit_transform(mall)","a4dc4101":"mall_scaled","ba72f949":"mall_df1 = pd.DataFrame(mall_scaled, columns = ['Age', 'Annual Income (k$)', 'Spending Score (1-100)'])\nmall_df1.head()\n","3d567a68":"# Elbow curve method to find the ideal number of clusters.\nclusters=list(range(2,8))\nssd = []\nfor num_clusters in clusters:\n    model_clus = KMeans(n_clusters = num_clusters, max_iter=150,random_state= 50)\n    model_clus.fit(mall_df1)\n    ssd.append(model_clus.inertia_)\n\nplt.plot(clusters,ssd);","f2e2c547":"# Silhouette score analysis to find the ideal number of clusters for K-means clustering\n\nrange_n_clusters = [2, 3, 4, 5, 6, 7, 8]\n\nfor num_clusters in range_n_clusters:\n    \n    # intialise kmeans\n    kmeans = KMeans(n_clusters=num_clusters, max_iter=50,random_state= 100)\n    kmeans.fit(mall_df1)\n    \n    cluster_labels = kmeans.labels_\n    \n    # silhouette score\n    silhouette_avg = silhouette_score(mall_df1, cluster_labels)\n    print(\"For n_clusters={0}, the silhouette score is {1}\".format(num_clusters, silhouette_avg))","be96a6b4":"#K-means with k=4 clusters\n\ncluster = KMeans(n_clusters=4, max_iter=150, random_state= 50)\ncluster.fit(mall_df1)","6535a4f2":"# Cluster labels\n\ncluster.labels_","ae81f198":"# Assign the label\n\nmall_d['Cluster_Id'] = cluster.labels_\nmall_d.head()","78946dae":"## Number of customers in each cluster\nmall_d['Cluster_Id'].value_counts(ascending=True)","1de8a295":"mall_d.columns","3d849318":"plt.figure(figsize = (20,15))\nplt.subplot(3,1,1)\nsns.scatterplot(x = 'Age', y = 'Annual Income (k$)',hue='Cluster_Id',data = mall_d,legend='full',palette=\"Set1\")\nplt.subplot(3,1,2)\nsns.scatterplot(x = 'Annual Income (k$)', y = 'Spending Score (1-100)',hue='Cluster_Id', data = mall_d,legend='full',palette=\"Set1\")\nplt.subplot(3,1,3)\nsns.scatterplot(x = 'Spending Score (1-100)', y = 'Age',hue='Cluster_Id',data= mall_d,legend='full',palette=\"Set1\")\nplt.show()","85cbe69c":" #Violin plot on Original attributes to visualize the spread of the data\n\nfig, axes = plt.subplots(1,3, figsize=(20,5))\n\nsns.violinplot(x = 'Cluster_Id', y = 'Age', data = mall_d,ax=axes[0])\nsns.violinplot(x = 'Cluster_Id', y = 'Annual Income (k$)', data = mall_d,ax=axes[1])\nsns.violinplot(x = 'Cluster_Id', y = 'Spending Score (1-100)', data=mall_d,ax=axes[2])\nplt.show()","fd00bcd2":"mall_d.head()","5cc196ed":"mall_d[['Age', 'Annual Income (k$)','Spending Score (1-100)','Cluster_Id']].groupby('Cluster_Id').mean()","4fb43711":"group_0= mall_d[mall_d['Cluster_Id']==0]\ngroup_0.head()","e123fb11":"fig, axes = plt.subplots(1,3, figsize=(20,5))\n\nsns.violinplot(x = 'Gender', y = 'Age', data = group_0,ax=axes[0])\nsns.violinplot(x = 'Gender', y = 'Annual Income (k$)', data = group_0,ax=axes[1])\nsns.violinplot(x = 'Gender', y = 'Spending Score (1-100)', data=group_0,ax=axes[2])\nplt.show()","d8b7c264":"group_1= mall_d[mall_d['Cluster_Id']==1]\ngroup_1.head()","68e74229":"fig, axes = plt.subplots(1,3, figsize=(20,5))\n\nsns.violinplot(x = 'Gender', y = 'Age', data = group_1,ax=axes[0])\nsns.violinplot(x = 'Gender', y = 'Annual Income (k$)', data = group_1,ax=axes[1])\nsns.violinplot(x = 'Gender', y = 'Spending Score (1-100)', data=group_1,ax=axes[2])\nplt.show()","8f42fbdf":"group_2= mall_d[mall_d['Cluster_Id']==2]\ngroup_2.head()","4d1c3e43":"fig, axes = plt.subplots(1,3, figsize=(20,5))\n\nsns.violinplot(x = 'Gender', y = 'Age', data = group_2,ax=axes[0])\nsns.violinplot(x = 'Gender', y = 'Annual Income (k$)', data = group_2,ax=axes[1])\nsns.violinplot(x = 'Gender', y = 'Spending Score (1-100)', data=group_2,ax=axes[2])\nplt.show()","c1d2448f":"group_3= mall_d[mall_d['Cluster_Id']==3]\ngroup_3.head()","a53e38f7":"fig, axes = plt.subplots(1,3, figsize=(20,5))\n\nsns.violinplot(x = 'Gender', y = 'Age', data = group_3,ax=axes[0])\nsns.violinplot(x = 'Gender', y = 'Annual Income (k$)', data = group_3,ax=axes[1])\nsns.violinplot(x = 'Gender', y = 'Spending Score (1-100)', data=group_3,ax=axes[2])\nplt.show()","4edcd9a4":"mall_d[['Age', 'Annual Income (k$)','Spending Score (1-100)','Cluster_Id']].groupby('Cluster_Id').mean()","cce5e768":"## K- means Clustering","dc1e5f67":"There are no missing \/ Null values either in columns or rows","220f26f3":"Audience are from Annual Income(k$) range between 15 to 137","fa571bd3":"## We use Percentile Capping (Winsorization) for outliers handling","116e7c10":"# Data Cleaning","4b093ae0":"# Duplicate Check","24d99fe9":"**Annual Income (k$)**","c281a2d3":"There is an outlier in Annual Income (k$) field but Income & Spending Score(1-100) has no outliers ","d7ea56de":"The shape after running the drop duplicate command is same as the original dataframe.\n\nHence we can conclude that there were zero duplicate values in the dataset.","9025e498":"## Data Loading","c69f019c":"Null Percentage: Columns","27044d1e":"**Age**","31d6bfba":"Null Percentage: Rows","ea2d56cf":"Most software packages use SVD to compute the principal components and assume that the data is scaled and centred, so it is important to do standardisation\/normalisation. There are two common ways of rescaling:\n\n- Min-Max scaling\n- Standardisation (mean-0, sigma-1)\n\nHere, we will use Standardisation Scaling.","68aaa196":"**Spending Score (1-100)**","6f42e9de":"silhouette score=(p\u2212q)\/max(p,q)\n\np is the mean distance to the points in the nearest cluster that the data point is not a part of\n\nq is the mean intra-cluster distance to all the points in its own cluster.\n\nThe value of the silhouette score range lies between -1 to 1.\n\nA score closer to 1 indicates that the data point is very similar to other data points in the cluster,\n\nA score closer to -1 indicates that the data point is not similar to the data points in its cluster.","bec2f11e":"Cluster 0  are those people whose \n- Avg Age : 54\n- Avg Annual Income (k$) : 47.7k\n- Avg Spending Score (1-100) : 40 \n\nWe can label them Medium Spender ","4b8a0e50":"# Rescaling the Features","22339f78":"Audience are having Spending Score (1-100) between 1 to 99 ","4032e74e":"It seems there are good number of countries in each clusters.","9208edc3":"- Age range for males are higher than females \n- Males earn more than females\n- Mean Spending Score (1-100) is more for males ","ed0cf2e6":"Looking at the above elbow curve it looks good to proceed with 4 clusters.","2fd83a9b":"Null Count: Columns","b4ddaa4c":"Data is not balanced, 27% more Females have participated  than males ","378dc3b4":"Cluster 3 are those people whose \n- Avg Age : 40\n- Avg Annual Income (k$) : 86.5 k\n- Avg Spending Score (1-100) : 19\n\nWe can label them Low Spender","e90b27c4":"- Mean Age of this cluster for Male is more than Females\n- Males earn more than females\n- Mean Spending Score (1-100) is same for both gender ","19ab8c26":"## Finding the Optimal Number of Clusters","eba61200":"## Outlier Analysis","bab31f77":"# Data Preparation","f6d5b227":"# Exploratory Data Analytics","c62f83d1":"A fundamental step for any unsupervised algorithm is to determine the optimal number of clusters into which the data may be clustered. The Elbow Method is one of the most popular methods to determine this optimal value of k.","0e441f45":"**Gender**","76efd6a9":"Null Count: Rows","e9a1dab3":"Univariate Analysis","354412b3":"We will opt for 4 as cluster","eac4a790":"## Silhouette Analysis","47378d05":"Elbow Curve to get the right number of Clusters","40b9fb23":"Audience are from Age 18 to 70","3ebd5f93":"Cluster 2 are those people whose \n- Avg Age : 32\n- Avg Annual Income (k$) : 86 k\n- Avg Spending Score (1-100) : 81\n\nWe can label them Extra Spender","ef2d243f":"K-means clustering is one of the simplest and popular unsupervised machine learning algorithms.\n\nThe algorithm works as follows:\n\nFirst we initialize k points, called means, randomly. We categorize each item to its closest mean and we update the mean\u2019s coordinates, which are the averages of the items categorized in that mean so far. We repeat the process for a given number of iterations and at the end, we have our clusters.","a5cd2be1":"- Age and Spending Score (1-100) are moderately correlated with correlation of -0.33","15022ae8":"# Model Building","29a3fd5c":"Cluster 1  are those people whose \n- Avg Age : 25\n- Avg Annual Income (k$) : 40 k\n- Avg Spending Score (1-100) : 60 \n\nWe can label them Large Spender","aae6f8ab":"- Age range for males are higher than females \n- Annual Income range for males are lower than females \n- Mean Spending Score (1-100) is more for females ","7adddeb5":"# Hopkins Statistics Test","db9074cc":"The Hopkins statistic (introduced by Brian Hopkins and John Gordon Skellam) is a way of measuring the cluster tendency of a data set.It acts as a statistical hypothesis test where the null hypothesis is that the data is generated by a Poisson point process and are thus uniformly randomly distributed. A value close to 1 tends to indicate the data is highly clustered, random data will tend to result in values around 0.5, and uniformly distributed data will tend to result in values close to 0.\n\n\u2022 If the value is between {0.01, ...,0.3}, the data is regularly spaced.\n\n\u2022 If the value is around 0.5, it is random.\n\n\u2022 If the value is between {0.7, ..., 0.99}, it has a high tendency to cluster.","3a3b1156":"- Mean Age of this cluster are same for both genders \n- Males earn more than females\n- Mean Spending Score (1-100) is more for males ","4ef9836e":"Final Points \n\n- Target Cluster 1 with more offers \n- Reward Cluster 2 people for being  loyal customer.\n- Improve the services to  attract Cluster 3 \n- Target Cluster 0 with better employees support "}}