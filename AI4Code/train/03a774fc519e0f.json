{"cell_type":{"557fce68":"code","c63cae2e":"code","fff00044":"code","1bdddf61":"code","ab7179a5":"code","3ffbcdfe":"code","3b14e39e":"code","9e7c3785":"code","9563cb6f":"code","a26fcd5b":"code","c3688bee":"code","bd9b89c6":"code","bd0ea875":"code","ff7f75f3":"code","a5e3e97c":"code","7e394055":"markdown","1b819db9":"markdown","02fa1d38":"markdown","bea04bc2":"markdown","5af1cfcd":"markdown","aecfcfd4":"markdown","372a8219":"markdown","e7cfbd96":"markdown","288c9799":"markdown","2999e635":"markdown","25f3c3f5":"markdown"},"source":{"557fce68":"!pip install bs4\n!pip install contractions\n\nimport re\nfrom bs4 import BeautifulSoup\nimport contractions\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem.wordnet import WordNetLemmatizer","c63cae2e":"a = \"I luv my &lt ;3 iphone &amp; you're awsm apple. Display Is Awesome, sooo happppppy \ud83d\ude42 \\n<a herf = http:\/\/www.apple.com>\"","fff00044":"soup = BeautifulSoup(a)\na = soup.get_text()\na","1bdddf61":"a = a.encode('ascii','ignore')\na = a.decode()\na","ab7179a5":"a = contractions.fix(a)\na","3ffbcdfe":"a = ' '.join([word for word in a.split() if not word in set(stopwords.words('english'))])\na","3b14e39e":"a =  re.sub('[^a-zA-Z]', ' ', a)\na = ' '.join(a.split())\na","9e7c3785":"lookup_dict = { 'dm':'direct message', \"awsm\" : \"awesome\", \"luv\" :\"love\" }\na = ' '.join( [lookup_dict[word] if word in lookup_dict.keys() else word for word in a.split()])    \na","9563cb6f":"lem = WordNetLemmatizer()\na = lem.lemmatize(a)\na","a26fcd5b":"# removing words staring with #\nstring = \"Kaggle is an #awesome platform to learn\"\npattern = \"#[\\w]*\"\nre.sub(pattern,'',string)","c3688bee":"from nltk import word_tokenize, pos_tag\ntext = \"Kaggle is great platform to learn and explore.\"\ntokens = word_tokenize(text)\npos_tag(tokens)","bd9b89c6":"nltk.help.upenn_tagset('NNP')","bd0ea875":"import spacy\nfrom spacy import displacy\nfrom collections import Counter\n!python3 -m spacy download en\nimport en_core_web_sm\nnlp = en_core_web_sm.load()","ff7f75f3":"doc = nlp(\"The World Health Organization declared the outbreak a Public Health Emergency of international concern in January 2020 and a pandemic in March 2020. As of 28 January 2021, more than 100 million cases have been confirmed, with more than 2.17 million deaths attributed to COVID-19.\")\nprint([(X.text, X.label_) for X in doc.ents])","a5e3e97c":"displacy.render(doc, jupyter=True, style='ent')","7e394055":"## Changing you're -> you are\nThese are known as contactions and shall be removed.  \nThis helps in making consistency in the vocabulary as depending on the NLP model, it might assume **you're** as completely different from **you are**, whoever we want to retain meaning of words to generate the output.","1b819db9":"## Removing Abbreviation\nMost data includes short forms of various words that are difficult to remove.  \nSome known abbreviations can be removed using this method, however, we may also use autocorrect packages to correct the words.","02fa1d38":"## Parts of speech tagging\nCertain words within a string are of more importance than other. This words are using Nouns, pronouns etc. \nExtracting specific words from the strings can help us reduce vocabulary size, helping us train faster","bea04bc2":"## Share your preprocessing techniques to help beginners learn and explore.","5af1cfcd":"## Remove stopwards\nStopwards are words like articles, verbs etc that are useful in building a sentence however do not add much information to our data.","aecfcfd4":"# Removing patterns\nMost patterns can easily be removed using [Regex](https:\/\/docs.python.org\/3\/library\/re.html) these may include words between brackets, words starting with # etc. You may refer Docs to learn more.","372a8219":"## Remove emojis and errors","e7cfbd96":"## Words to singular forms\nThis step is again optional depending on the usecase. It helps in reducing vocabulary size as certain words are just plural forms of others.  \nMost used methods are Porter Stemmer and Lemmatizer. More can be found [here](http:\/\/www.nltk.org\/api\/nltk.stem.html?highlight=lemmatizer)","288c9799":"# [Tips] List of preprocessing techniques in NLP\nPreprocessing of strings is an important task in NLP and greatly reduces bias from the strings.  \nHowever all of them may or maynot be used dependeing on the use case.\nIn this notebook I'll breif your about some basic and but most commonly used techniques of all.\n* Removing HTML Tags\n* Removing emojis\n* Changing you're -> you are\n* Removing contractions\n* Removing Punctuations\n* Remove Abbreviation\n* Change Plural forms\n* Remove Patterns\n* Parts of speech","2999e635":"## Remove punctuations and numbers\nIn most cases punctuations are not required and act as an overhead in the string. Numbers may or maynot be useful depending on the usecase.  \nTo prevent numbers from removal use `re.sub('[^a-zA-Z0-9]', ' ', a)`","25f3c3f5":"## Remove html tags\nWhile scraping data from web, it is common to encounter tags like < html > , < br > , < p > , < href > etc.  \nThese does not add any information to out data and it is advisable to remove them."}}