{"cell_type":{"25316579":"code","0dca5b98":"code","e1286c30":"code","f8c5d999":"code","a4d1324a":"code","8eda3cc9":"code","1fdce15a":"code","2aa121e9":"code","a725778d":"code","7979baee":"markdown"},"source":{"25316579":"import os\nimport numpy as np\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import Dropout\nimport scipy.ndimage\nimport pandas as pd\nimport tensorflow as tf\n\nimport numpy as np\n\nfrom matplotlib import pyplot as plt\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array","0dca5b98":"data_dir = \"\/kaggle\/input\/garbage-classification\/Garbage classification\/Garbage classification\"\nclasses = os.listdir(data_dir)","e1286c30":"image_size = (128, 128)\nbatch_size = 16\n\ntrain_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    subset= \"training\",\n    validation_split = 0.2,\n    seed=1,\n    image_size = image_size,\n    batch_size = batch_size,\n    label_mode = \"categorical\",\n    class_names = classes\n)\n\nval_ds = tf.keras.preprocessing.image_dataset_from_directory(\n    data_dir,\n    subset= \"validation\",\n    validation_split = 0.2,\n    seed=1,\n    image_size = image_size,\n    batch_size = batch_size,\n    label_mode = \"categorical\",\n    class_names = classes\n)","f8c5d999":"num_classes = 6\ninput_shape = (28, 28, 1)\n\nmodel = keras.Sequential(\n    [\n        layers.Conv2D(512, kernel_size=(3, 3), activation=\"relu\", input_shape=(image_size+(3,))),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Conv2D(64, kernel_size=(3, 3), activation=\"relu\"),\n        layers.MaxPooling2D(pool_size=(2, 2)),\n        layers.Flatten(),\n        layers.Dropout(0.5),\n        layers.Dense(num_classes, activation=\"softmax\"),\n    ]\n)\n\nmodel.summary()","a4d1324a":"epochs = 10\n\nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\nhistory = model.fit(train_ds, epochs=epochs, verbose=1, validation_data=val_ds)","8eda3cc9":"score = model.evaluate(train_ds, verbose=0)\nprint(\"Test loss:\", score[0])\nprint(\"Test accuracy:\", score[1])","1fdce15a":"val_samples = tf.concat([x for [x,_] in val_ds], axis=0).numpy().shape[0]\nval_samples = sum([16 for [_,_] in val_ds])\nval_samples","2aa121e9":"y_val = []\ny_val_pred = []\n\nfor images, targets in train_ds.take(val_samples \/\/ batch_size):\n    for i in range(batch_size):\n        img_array = images[i].numpy().astype(\"uint8\")\n        prediction = model.predict(np.array([img_array]))\n        y_val_pred.append(np.argmax(prediction))\n        y_val.append(np.argmax(targets[i]))","a725778d":"from sklearn.metrics import confusion_matrix\ncm=confusion_matrix(y_val, y_val_pred)\n\nimport plotly.express as px\n\nfig = px.imshow(\n    cm, \n    labels = dict(x=\"Predicciones\", y=\"Reales\"),\n    x=classes,\n    y=classes\n)\nfig.update_xaxes(side=\"top\")\nfig.show()","7979baee":"A. Neural Network\nUtilice el dataset Garbage Classification para predecir cada uno de los materiales reciclables.\n\nImplemente la arquitectura de una red neuronal convolucional con Keras (5 pts) para realizar la clasificaci\u00f3n.\nMuestre el accuracy y el loss a lo largo del tiempo \/ epocs (2 pts)\nMuestre sus resultados con una matriz de confusi\u00f3n o un reporte (3 pts)"}}