{"cell_type":{"38ffdaf2":"code","0818ecb7":"code","0323edfe":"code","d28bb91b":"code","d528fd35":"code","8e2c22d7":"code","9d5468d4":"code","b3af204e":"code","1c87dc1e":"code","a63eda38":"code","ad71fdc6":"code","d829587c":"code","71836931":"code","43c8a1f3":"code","c160c4e2":"code","da5de2ee":"code","969f4e20":"code","fe0e17da":"code","a6861974":"code","e830d2a7":"code","5d1d41f9":"markdown","febaa6d6":"markdown","ea3aadbb":"markdown","2361563b":"markdown"},"source":{"38ffdaf2":"import numpy as np \nfrom tqdm import tqdm\nimport cv2\nimport os\n# import shutil\nimport itertools\n# import imutils\nimport matplotlib.pyplot as plt\n# from sklearn.preprocessing import LabelBinarizer\n# from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\n# import plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode, iplot\n# from plotly import tools\n\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.applications.vgg16 import VGG16, preprocess_input\nfrom keras import layers\nfrom keras.models import Model, Sequential\nfrom keras.optimizers import Adam, RMSprop\n# from keras.callbacks import EarlyStopping\n\ninit_notebook_mode(connected=True)\nRANDOM_SEED = 123","0818ecb7":"# os.listdir('..\/input\/train-valtest\/all_files\/VAL_CROP\/'","0323edfe":"def target_label(dir_path):\n    y = []\n    i = 0\n    labels = dict()\n    for path in tqdm(sorted(os.listdir(dir_path))):\n        if not path.startswith('.'):\n            labels[i] = path\n            if path=='YES':\n#                 print(path,len(os.listdir(dir_path + path)))\n                yestarget=list(np.ones(len(os.listdir(dir_path + path))))\n            if path=='NO':\n#                 print(path,len(os.listdir(dir_path + path)))\n                notarget=list(np.zeros(len(os.listdir(dir_path + path))))\n    y = notarget+yestarget\n    print(('{} images are in {} directory').format(len(y),dir_path))\n    return y, labels","d28bb91b":"TRAIN_DIR = '..\/input\/train-valtest\/all_files\/TRAIN_CROP\/'\nTEST_DIR = '..\/input\/train-valtest\/all_files\/TEST_CROP\/'\nVAL_DIR = '..\/input\/train-valtest\/all_files\/VAL_CROP\/'\n# IMG_SIZE = (224,224)\nIMG_SIZE = (128,128)\ny_train, labels = target_label(TRAIN_DIR)\ny_test, _ = target_label(TEST_DIR)\ny_val, _ = target_label(VAL_DIR)","d528fd35":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize = (6,6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=90)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n    thresh = cm.max() \/ 2.\n    cm = np.round(cm,2)\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.show()","8e2c22d7":"# initialize  batch size\nBS = 32\ntrain_datagen = ImageDataGenerator()\nvalid_datagen = ImageDataGenerator(\n#     preprocessing_function=preprocess_input\n)\ntrain_generator = train_datagen.flow_from_directory(\n    '..\/input\/train-valtest\/all_files\/TRAIN_CROP\/',\n    target_size=(128, 128),\n    batch_size=BS,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)\nvalid_generator = valid_datagen.flow_from_directory(\n    '..\/input\/train-valtest\/all_files\/VAL_CROP\/',\n    target_size=(128, 128),\n    batch_size=25,\n    class_mode='binary',\n    seed=RANDOM_SEED\n)","9d5468d4":"# os.listdir('')","b3af204e":"IMG_SIZE = (128,128)\n# load base model\nvgg16_weight_path = '..\/input\/vgg16pretrained\/vgg16_weights_tf_dim_ordering_tf_kernels_notop.h5'\nbase_model = VGG16(\n    weights=vgg16_weight_path,\n    include_top=False, \n    input_shape=IMG_SIZE + (3,)\n)","1c87dc1e":"# model = Sequential()\n\n# # Must define the input shape in the first layer of the neural network\n# model.add(layers.Conv2D(filters=16,kernel_size=9, padding='same', activation='relu', input_shape=(128,128,3))) \n# model.add(layers.MaxPooling2D(pool_size=2))\n# model.add(layers.Dropout(0.45))\n\n# model.add(layers.Conv2D(filters=16,kernel_size=9,padding='same', activation='relu'))\n# model.add(layers.MaxPooling2D(pool_size=2))\n# model.add(layers.Dropout(0.25))\n\n# model.add(layers.Conv2D(filters=36, kernel_size=9, padding='same', activation='relu'))\n# model.add(layers.MaxPooling2D(pool_size=2))\n# model.add(layers.Dropout(0.25))\n\n# model.add(layers.Flatten())\n\n# model.add(layers.Dense(512, activation='relu'))\n# model.add(layers.Dropout(0.15))\n\n\n# model.add(layers.Dense(1, activation='sigmoid'))\n\n# # Take a look at the model summary\n# model.summary()","a63eda38":"NUM_CLASSES = 1\n\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dropout(0.5))\nmodel.add(layers.Dense(NUM_CLASSES, activation='sigmoid'))\n\nmodel.layers[0].trainable = False\nmodel.summary()","ad71fdc6":"# len(X_train)\/\/BS","d829587c":"NUM_EPOCHS = 10\nmodel.compile(loss='binary_crossentropy',\n             optimizer='Adam',\n             metrics=['accuracy'])\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=len(y_train)\/\/25,\n#     steps_per_epoch=70,\n    epochs=NUM_EPOCHS,\n    validation_data = valid_generator, \n    validation_steps=len(y_val)\/\/25,  \n#     validation_steps=10,\n)","71836931":"# plot model performance\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nloss = history.history['loss']\nval_loss = history.history['val_loss']\nepochs_range = range(1, len(history.epoch) + 1)\n\nplt.figure(figsize=(15,5))\n\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Train Set')\nplt.plot(epochs_range, val_acc, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.title('Model Accuracy')\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range[1:], loss[1:], label='Train Set')\nplt.plot(epochs_range, val_loss, label='Val Set')\nplt.legend(loc=\"best\")\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.title('Model Loss')\n\nplt.tight_layout()\nplt.show()","43c8a1f3":"test_generator = valid_datagen.flow_from_directory(\n    '..\/input\/train-valtest\/all_files\/TEST_CROP\/',\n    target_size=(128, 128),\n    batch_size=5,\n    class_mode='binary',\n    shuffle=False\n)\ntest_generator_val = valid_datagen.flow_from_directory(\n    '..\/input\/train-valtest\/all_files\/VAL_CROP\/',\n    target_size=(128, 128),\n    batch_size=10,\n    class_mode='binary',\n    shuffle=False\n)\ntest_generator_train = valid_datagen.flow_from_directory(\n    '..\/input\/train-valtest\/all_files\/TRAIN_CROP\/',\n    target_size=(128, 128),\n    batch_size=50,\n    class_mode='binary',\n    shuffle=False\n)","c160c4e2":"predIdx=model.predict_generator(test_generator,\n\tsteps= 2)\npredIdx=[1 if x>0.5 else 0 for x in predIdx]\n\naccuracy = accuracy_score(y_test, np.round(predIdx))\nprint('Test Accuracy = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_test, np.round(predIdx)) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)","da5de2ee":"# ind_list = np.argwhere((y_test == predIdx) == False)[:, -1]\n# if ind_list.size == 0:\n#     print('There are no missclassified images.')\n# else:\n#     for i in ind_list:\n#         plt.figure()\n#         plt.imshow(X_test[i])\n#         plt.xticks([])\n#         plt.yticks([])\n#         plt.title(('Actual class: {}\\nPredicted class: {}').format(y_test[i],predIdx[i]))\n#         plt.show()","969f4e20":"predIdx=model.predict_generator(test_generator_val,\n\tsteps= 5)\npredIdx=[1 if x>0.5 else 0 for x in predIdx]\nlen(predIdx)","fe0e17da":"accuracy = accuracy_score(y_val, np.round(predIdx))\nprint('VAL Accuracy = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_val, np.round(predIdx)) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)","a6861974":"### you can play with batch size, steps to limit how many images to use for prediction\npredIdx=model.predict_generator(test_generator_train,\n\tsteps= 4)\npredIdx=[1 if x>0.5 else 0 for x in predIdx]\nlen(predIdx)","e830d2a7":"accuracy = accuracy_score(y_train, np.round(predIdx))\nprint('TRAIN Accuracy = %.2f' % accuracy)\n\nconfusion_mtx = confusion_matrix(y_train, np.round(predIdx)) \ncm = plot_confusion_matrix(confusion_mtx, classes = list(labels.items()), normalize=False)","5d1d41f9":"### modified from [https:\/\/www.kaggle.com\/loaiabdalslam\/brain-tumor-mri-classification-vgg16](http:\/\/)","febaa6d6":"### Getting targets, labels for training and prediction","ea3aadbb":"# Simple tutorial for learning how to use ImageDataGenerator to read files from folder.","2361563b":"### Function to predict accuracy of model"}}