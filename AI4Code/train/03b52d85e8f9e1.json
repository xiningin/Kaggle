{"cell_type":{"b39d07f9":"code","de013413":"code","9c2e974d":"code","45a9706e":"code","37905d80":"code","4ca110a9":"code","bd456e69":"code","deb2ccb9":"code","184a9f86":"markdown","5f7faca3":"markdown","d5b05528":"markdown","78539066":"markdown","27d33aaf":"markdown","46e8dafa":"markdown"},"source":{"b39d07f9":"from pathlib import Path\nimport pickle\nimport cv2\nimport numpy as np\nimport torch\nfrom torch import nn\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom tqdm.auto import tqdm\nfrom statistics import mean, stdev\nimport pandas as pd\nimport itertools","de013413":"data_dir = Path(\"\/kaggle\/input\/sartorius-cell-instance-segmentation\")\nmask_dir = Path(\"\/kaggle\/input\/cell-image-masks\/train_masks\")   # my public dataset","9c2e974d":"class MyImageDataset(torch.utils.data.Dataset):\n    def __init__(self, filenames, mask_dir):\n        self.filenames = filenames\n        self.mask_dir = mask_dir\n\n    def __getitem__(self, index):\n        filename = Path(self.filenames[index])\n        mask_filename = self.mask_dir.joinpath(f\"mask_{filename.stem}.pkl\")\n\n        if not filename.exists():\n            raise ValueError(f\"Image {filename} does not exists\")\n\n        if not mask_filename.exists():\n            raise ValueError(f\"Mask {mask_filename} does not exists\")\n\n        img_data = load_img(filename)\n\n        with mask_filename.open(\"rb\") as f:\n            mask_data = pickle.load(f)\n\n        img_tensor = torch.tensor(img_data).unsqueeze(0)\n        mask_tensor = torch.tensor(mask_data.astype(np.float32)).unsqueeze(0)\n\n        return img_tensor, mask_tensor\n\n    def __len__(self):\n        return len(self.filenames)\n    \n    \ndef load_img(filename):\n    \"\"\"returns x-125 as float32\"\"\"\n    if not filename.exists():\n        raise IOError(f\"File {filename} not found\")\n\n    img_data = cv2.imread(str(filename))\n    assert img_data is not None\n\n    return cv2.cvtColor(img_data, cv2.COLOR_BGR2GRAY).astype(np.float32) - 125","45a9706e":"batch_size = 32\n\nimage_filenames = list(data_dir.joinpath(\"train\").glob(\"*.png\"))\n\ntrain_dataset = MyImageDataset(image_filenames, mask_dir)\n\ntrain_dataloader = torch.utils.data.DataLoader(\n    train_dataset,\n    shuffle=True,\n    batch_size=batch_size,\n)","37905d80":"n_epochs = 50\n\nNN = nn.Sequential(\n    nn.Conv2d(1, 20, kernel_size=5, padding=\"same\"),\n    nn.BatchNorm2d(20),\n    nn.ReLU(),\n    nn.Conv2d(20, 10, kernel_size=1),\n    \n    nn.Conv2d(10, 10, kernel_size=5, padding=\"same\"),\n    nn.BatchNorm2d(10),\n    nn.ReLU(),\n    nn.Conv2d(10, 1, kernel_size=1),\n).to(\"cuda\")\n\n##########################################################\nlossfunc = nn.BCEWithLogitsLoss()\n\nlosses = []\n\noptimizer = torch.optim.Adam(NN.parameters())\n\nfor epoch in tqdm(range(1, n_epochs+1)):\n    for i, (X, Y) in enumerate(train_dataloader):\n        torch.cuda.empty_cache()\n        \n        X = X.to(\"cuda\")\n        Y = Y.to(\"cuda\")\n        \n        optimizer.zero_grad()\n        \n        pred=NN(X)\n        \n        loss = lossfunc(pred, Y)\n        \n        losses.append(float(loss))\n\n        loss.backward()\n        optimizer.step()\n\n    print(f\"{epoch:3}\/{n_epochs}: {mean(losses[-10:]):.4g}\")\n    \ntorch.cuda.empty_cache()","4ca110a9":"pd.Series(losses).rolling(21).mean().plot(title=\"loss\");","bd456e69":"# unoptimized and slow; any way to speed up?\n\ndef get_threshold(Y, pred):\n    scores = list(pred.ravel())\n    mask = list(Y.ravel())\n    \n    idxs=np.argsort(scores)[::-1]\n    mask_sorted=np.array(mask)[idxs]\n    sum_mask_one=np.cumsum(mask_sorted)\n    IoU=sum_mask_one\/(np.arange(1,len(mask_sorted)+1)+np.sum(mask_sorted)-sum_mask_one)\n    best_IoU_idx=IoU.argmax()\n    best_threshold=scores[idxs[best_IoU_idx]]\n    best_IoU=IoU[best_IoU_idx]\n\n    return best_threshold, best_IoU\n    \nimg_thresholds = []         # one for each image\nimg_IoUs = []\n\nN=3\nfor X, Y in tqdm(itertools.islice(train_dataloader, N), total=N):\n    X = X.to(\"cuda\")\n    Y = Y.detach().numpy()\n\n    with torch.no_grad():\n        pred=torch.sigmoid(NN(X)).cpu().detach().numpy()\n\n    for i in range(Y.shape[0]):\n        best_img_threshold, best_img_IoU = get_threshold(Y[i], pred[i])\n        img_thresholds.append(best_img_threshold)\n        img_IoUs.append(best_img_IoU)\n    \nbest_threshold = np.mean(img_thresholds)\nbest_threshold_spread = np.std(img_thresholds)\navg_IoU = mean(img_IoUs)\n\nprint(f\"Best threshold: {best_threshold:.3g} (+-{best_threshold_spread:.3g}), Avg. Train IoU: {avg_IoU:.3f}\")","deb2ccb9":"threshold = best_threshold\n\n###########################\nX, Y = next(iter(train_dataloader))\nX = X.to(\"cuda\")\nY = Y.detach().numpy()\n\nwith torch.no_grad():\n    pred=torch.sigmoid(NN(X)).cpu().detach().numpy()\n    \npred_Y = (pred >= threshold)\n    \ncmap = mpl.colors.ListedColormap(['black', 'gray', 'orange', 'green'])\n\ndef plot(img_Y, img_pred):\n    output = np.zeros_like(img_Y)\n    output = np.where((img_Y == 0) & (img_pred == 1), 1, output)\n    output = np.where((img_Y == 1) & (img_pred == 0), 2, output)\n    output = np.where((img_Y == 1) & (img_pred == 1), 3, output)\n\n    plt.figure(figsize=(10,10))\n    plt.imshow(output, cmap=cmap)\n    plt.xticks([])\n    plt.yticks([]);\n    \n\nN = 5\nfor i in range(N):\n    img_Y = Y[i, 0]\n    img_pred = pred_Y[i, 0]\n    \n    plot(img_Y, img_pred)\n    plt.show()\n\n# green: correct prediction\n# gray: false positive (too much)\n# orange: false negative (missed)","184a9f86":"# Train simple network\n\nKeep W\/H the same across all layers and do simple log-loss against full semantic segmentation mask.","5f7faca3":"# Find best prediction mask threshold optimizing IoU score","d5b05528":"# Load data","78539066":"# Helper code","27d33aaf":"This notebook implements semantic segmentation with a simple toy network. To goal is to explore what a simple network with very few layers can achieve.\n\nI tried to keep the code clean. If you see ways to improve, please let me know in the comments.\n\nCurrently, there is no proper validation split; I will add that later.","46e8dafa":"# Visualize predictions"}}