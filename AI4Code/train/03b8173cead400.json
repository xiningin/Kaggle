{"cell_type":{"2d106631":"code","9d0dfe71":"code","e04b843a":"code","485b73fe":"code","0eb0c5eb":"code","d9fae09d":"code","6c72c812":"code","5758ab60":"code","ab24101c":"code","ee400457":"code","1f018508":"code","887e1cb2":"code","04f5969a":"code","d0ca3d0b":"code","81e25a8f":"code","d79cc2e6":"code","c45109e1":"code","57264672":"code","d5c79998":"code","0b7fdfbb":"code","81cf9a19":"code","e76ef225":"code","89465393":"code","5a55b77f":"code","141d0c39":"code","78b2b40e":"code","4e484c09":"code","61505e55":"code","30a0e088":"code","b8861f24":"code","3d58f4e8":"markdown","1a2c6aec":"markdown","524d9e27":"markdown","54bdfeb2":"markdown","75170500":"markdown","47c39f56":"markdown","476527e7":"markdown","8b3d5222":"markdown","b04bc2cb":"markdown","01ca547b":"markdown","71737978":"markdown","df8efdc5":"markdown","a68d637a":"markdown","5b31987a":"markdown","91f51434":"markdown","46249ed6":"markdown","4495c9f8":"markdown","c19ca1df":"markdown","c2e516c9":"markdown","52303718":"markdown","3059ff71":"markdown","907c3e2f":"markdown","612bba70":"markdown","024022a8":"markdown","4cce1e0b":"markdown","e1494fe0":"markdown","f6e76ac8":"markdown","99ee89e3":"markdown","6faca778":"markdown","2828fbb7":"markdown","b14144b0":"markdown","5ef55162":"markdown","af75bab7":"markdown","7de016dd":"markdown","a3dfcaad":"markdown","ddcb4ae1":"markdown","66fb592c":"markdown","ffda25dc":"markdown","07b0321e":"markdown","9467cc97":"markdown","043bd83b":"markdown","7e709a2c":"markdown","d28f77c8":"markdown","7654b58c":"markdown","96181aea":"markdown","c1b314c5":"markdown","a676ee59":"markdown","bbfdd8dc":"markdown","02d9722d":"markdown","32354f3c":"markdown","0d7ba6da":"markdown","4c40e792":"markdown","7b572368":"markdown"},"source":{"2d106631":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9d0dfe71":"'''Importing Data Manipulation Modules'''\nimport numpy as np                 # Linear Algebra\nimport pandas as pd                # Data Processing, CSV file I\/O (e.g. pd.read_csv)\n\n'''Seaborn and Matplotlib Visualization'''\nimport matplotlib                  # 2D Plotting Library\nimport matplotlib.pyplot as plt\nimport seaborn as sns              # Python Data Visualization Library based on matplotlib\nimport geopandas as gpd            # Python Geospatial Data Library\nplt.style.use('fivethirtyeight')\n%matplotlib inline\n\n'''Plotly Visualizations'''\nimport plotly as plotly                # Interactive Graphing Library for Python\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot, plot\ninit_notebook_mode(connected=True)\n\n'''Spatial Visualizations'''\nimport folium\nimport folium.plugins\n\n'''NLP - WordCloud'''\nimport wordcloud\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\n\n'''Machine Learning'''\nimport sklearn\nfrom sklearn import preprocessing\nfrom sklearn import metrics\nfrom sklearn.metrics import r2_score, mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder,OneHotEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression,LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor,  GradientBoostingRegressor\n\nimport warnings\nwarnings.filterwarnings('ignore')","e04b843a":"data=pd.read_csv('..\/input\/new-york-city-airbnb-open-data\/AB_NYC_2019.csv')\ndata.head(2)","485b73fe":"print('Rows     :',data.shape[0])\nprint('Columns  :',data.shape[1])\nprint('\\nFeatures :\\n     :',data.columns.tolist())\nprint('\\nMissing values    :',data.isnull().values.sum())\nprint('\\nUnique values :  \\n',data.nunique())","0eb0c5eb":"data.shape","d9fae09d":"plt.figure(figsize=(10,10))\nsns.heatmap(data.isnull(),cbar=False,cmap='YlGnBu')\nplt.ioff()","6c72c812":"total = data.isnull().sum().sort_values(ascending=False)\npercent = ((data.isnull().sum())*100)\/data.isnull().count().sort_values(ascending=False)\nmissing_data = pd.concat([total, percent], axis=1, keys=['Total','Percent'], sort=False).sort_values('Total', ascending=False)\nmissing_data.head(40)","5758ab60":"data.describe().T","ab24101c":"f,ax=plt.subplots(1,2,figsize=(18,8))\ndata['neighbourhood_group'].value_counts().plot.pie(explode=[0,0.05,0,0,0],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Share of Neighborhood')\nax[0].set_ylabel('Neighborhood Share')\nsns.countplot('neighbourhood_group',data=data,ax=ax[1],order=data['neighbourhood_group'].value_counts().index)\nax[1].set_title('Share of Neighborhood')\nplt.show()\nplt.ioff()","ee400457":"plt.figure(figsize=(10,6))\nsns.scatterplot(data.longitude,data.latitude,hue=data.neighbourhood_group)\nplt.ioff()","1f018508":"import folium\nfrom folium.plugins import HeatMap\nm=folium.Map([40.7128,-74.0060],zoom_start=11)\nHeatMap(data[['latitude','longitude']].dropna(),radius=8,gradient={0.2:'blue',0.4:'purple',0.6:'orange',1.0:'red'}).add_to(m)\ndisplay(m)","887e1cb2":"plt.figure(figsize=(10,6))\nsns.distplot(data[data.neighbourhood_group=='Manhattan'].price,color='maroon',hist=False,label='Manhattan')\nsns.distplot(data[data.neighbourhood_group=='Brooklyn'].price,color='black',hist=False,label='Brooklyn')\nsns.distplot(data[data.neighbourhood_group=='Queens'].price,color='green',hist=False,label='Queens')\nsns.distplot(data[data.neighbourhood_group=='Staten Island'].price,color='blue',hist=False,label='Staten Island')\nsns.distplot(data[data.neighbourhood_group=='Long Island'].price,color='lavender',hist=False,label='Long Island')\nplt.title('Borough wise price destribution for price<2000')\nplt.xlim(0,2000)\nplt.show()","04f5969a":"sns.distplot(data[(data['minimum_nights'] <= 30) & (data['minimum_nights'] > 0)]['minimum_nights'], bins=31)\nplt.ioff()","d0ca3d0b":"plt.figure(figsize=(10,6))\nplt.scatter(data.longitude, data.latitude, c=data.availability_365, cmap='spring', edgecolor='black', linewidth=1, alpha=0.75)\n\ncbar = plt.colorbar()\ncbar.set_label('availability_365')","81e25a8f":"plt.style.use('fivethirtyeight')\nfig,ax=plt.subplots(1,2,figsize=(15,8))\nclr = (\"blue\", \"forestgreen\", \"gold\", \"red\", \"purple\",'cadetblue','hotpink','orange','darksalmon','brown')\ndata.neighbourhood.value_counts().sort_values(ascending=False)[:10].sort_values().plot(kind='barh',color=clr,ax=ax[0])\nax[0].set_title(\"Top 10 neighbourhood by the number of rooms\",size=20)\nax[0].set_xlabel('rooms',size=18)\n\n\ncount=data['neighbourhood'].value_counts()\ngroups=list(data['neighbourhood'].value_counts().index)[:10]\ncounts=list(count[:10])\ncounts.append(count.agg(sum)-count[:10].agg('sum'))\ngroups.append('Other')\ntype_dict=pd.DataFrame({\"group\":groups,\"counts\":counts})\nclr1=('brown','darksalmon','orange','hotpink','cadetblue','purple','red','gold','forestgreen','blue','plum')\nqx = type_dict.plot(kind='pie', y='counts', labels=groups,colors=clr1,autopct='%1.1f%%', pctdistance=0.9, radius=1.2,ax=ax[1])\nplt.legend(loc=0, bbox_to_anchor=(1.15,0.4)) \nplt.subplots_adjust(wspace =0.5, hspace =0)\nplt.ioff()\nplt.ylabel('')\npass","d79cc2e6":"plt.style.use('fivethirtyeight')\nf,ax=plt.subplots(1,2,figsize=(18,8))\ndata['room_type'].value_counts().plot.pie(explode=[0,0.05,0],autopct='%1.1f%%',ax=ax[0],shadow=True)\nax[0].set_title('Share of Room Type')\nax[0].set_ylabel('Room Type Share')\nsns.countplot('room_type',data=data,ax=ax[1],order=data['room_type'].value_counts().index)\nax[1].set_title('Share of Room Type')\nplt.show()","c45109e1":"#word cloud\nfrom wordcloud import WordCloud, ImageColorGenerator\ntext = \" \".join(str(each) for each in data.name)\n# Create and generate a word cloud image:\nwordcloud = WordCloud(max_words=200, background_color=\"yellow\").generate(text)\nplt.figure(figsize=(10,6))\nplt.figure(figsize=(15,10))\n# Display the generated image:\nplt.imshow(wordcloud, interpolation='bilinear')\nplt.axis(\"off\")\nplt.show()\npass","57264672":"# Preparing the data \ndata.drop(['name','id','host_name','last_review'],axis=1,inplace=True)\ndata['reviews_per_month']=data['reviews_per_month'].replace(np.nan, 0)","d5c79998":"'''Encode labels with value between 0 and n_classes-1.'''\nle = preprocessing.LabelEncoder()                                            # Fit label encoder\nle.fit(data['neighbourhood_group'])\ndata['neighbourhood_group']=le.transform(data['neighbourhood_group'])    # Transform labels to normalized encoding.\n\nle = preprocessing.LabelEncoder()\nle.fit(data['neighbourhood'])\ndata['neighbourhood']=le.transform(data['neighbourhood'])\n\nle = preprocessing.LabelEncoder()\nle.fit(data['room_type'])\ndata['room_type']=le.transform(data['room_type'])\n\ndata.sort_values(by='price',ascending=True,inplace=True)\n\ndata.head(2)","0b7fdfbb":"min_thresold1, max_thresold1 = data.price.quantile([0.05, 0.95])\nmin_thresold1, max_thresold1\n\ndata = data[(data.price<max_thresold1) & (data.price>min_thresold1)]\ndata.shape","81cf9a19":"'''Train LRM'''\nlm = LinearRegression()\n\nX = data[['host_id','neighbourhood_group','neighbourhood','latitude','longitude','room_type','minimum_nights','number_of_reviews','reviews_per_month','calculated_host_listings_count','availability_365']]\ny = data['price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=101)\n\nlm.fit(X_train,y_train)","e76ef225":"'''Get Predictions & Print Metrics'''\npredicts = lm.predict(X_test)\n\nprint(\"\"\"\n        Mean Squared Error: {}\n        R2 Score: {}\n        Mean Absolute Error: {}\n     \"\"\".format(\n        np.sqrt(metrics.mean_squared_error(y_test, predicts)),\n        r2_score(y_test,predicts) * 100,\n        mean_absolute_error(y_test,predicts)\n        ))","89465393":"error_airbnb = pd.DataFrame({\n        'Actual Values': np.array(y_test).flatten(),\n        'Predicted Values': predicts.flatten()}).head(20)\n\nerror_airbnb.head(5)","5a55b77f":"title=['Pred vs Actual']\nfig = go.Figure(data=[\n    go.Bar(name='Predicted', x=error_airbnb.index, y=error_airbnb['Predicted Values']),\n    go.Bar(name='Actual', x=error_airbnb.index, y=error_airbnb['Actual Values'])\n])\n\nfig.update_layout(barmode='group')\nfig.show()","141d0c39":"plt.figure(figsize=(16,8))\nsns.regplot(predicts,y_test)\nplt.xlabel('Predictions')\nplt.ylabel('Actual')\nplt.title(\"Linear Model Predictions\")\nplt.grid(False)\nplt.show()","78b2b40e":"'''Gradient Boosted Regressor'''\nGBoost = GradientBoostingRegressor(n_estimators=3000, learning_rate=0.01)\nGBoost.fit(X_train,y_train)","4e484c09":"'''Get Predictions & Metrics'''\npredicts2 = GBoost.predict(X_test)\n\nprint(\"\"\"\n        Mean Squared Error: {}\n        R2 Score: {}\n        Mean Absolute Error: {}\n     \"\"\".format(\n        np.sqrt(metrics.mean_squared_error(y_test, predicts2)),\n        r2_score(y_test,predicts2) * 100,\n        mean_absolute_error(y_test,predicts2)\n        ))","61505e55":"error_airbnb = pd.DataFrame({\n        'Actual Values': np.array(y_test).flatten(),\n        'Predicted Values': predicts2.flatten()}).head(20)\n\nerror_airbnb.head(5)","30a0e088":"title=['Pred vs Actual']\nfig = go.Figure(data=[\n    go.Bar(name='Predicted', x=error_airbnb.index, y=error_airbnb['Predicted Values']),\n    go.Bar(name='Actual', x=error_airbnb.index, y=error_airbnb['Actual Values'])\n])\n\nfig.update_layout(barmode='group')\nfig.show()","b8861f24":"plt.figure(figsize=(16,8))\nsns.regplot(predicts2,y_test)\nplt.xlabel('Predictions')\nplt.ylabel('Actual')\nplt.title(\"Gradient Boosted Regressor model Predictions\")\nplt.show()","3d58f4e8":"### Recently I published a self help book titled Inspiration: Thoughts on Spirituality, Technology, Wealth, Leadership and Motivation. The preview of the book can be read from the Amazon link https:\/\/lnkd.in\/gj7bMQA\n\n### You can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code","1a2c6aec":"### Shape of Data ","524d9e27":"Manhatten and Brooklyn have the highest share of hotels.","54bdfeb2":"We can see than most people rent out entire apartment on airbnb followed by private room.This may also be an indicator people go on holidays and stay in airbnb with their family.Also possibility is people are listing more in Entire Apartment category.Very few people opt for shared rooms probably due to lack of privacy.","75170500":"### Scatter plot","47c39f56":"Area wise distribution of price shows that Manhattan has expensive and Staten Island has low priced rooms.","476527e7":"### Label Encoding","8b3d5222":"## A] Neighborhood_group","b04bc2cb":"### Predicted Vs Actual Price Plot","01ca547b":"Our word cloud shows the words that are more often used in the Name of this listings.We can see most of the words are related to the description,place and the experince in the room.","71737978":"The highest Density areas are marked in red and lowest density areas are marked in blue color.","df8efdc5":"### Actual Vs Predicted Price ","a68d637a":"### Count and Percentage of Missing Values","5b31987a":"### Dropping and Replacing Missing Values","91f51434":"## 2] Price","46249ed6":"### Nights Booked","4495c9f8":"## C] Minimum Nights","c19ca1df":"# 3.Model Built","c2e516c9":"The highest Density areas are marked in red and lowest density areas are marked in blue color.","52303718":"### Getting Basic Stats from Data","3059ff71":"The accuracy of our model gets affected by lot of outliers in our dataset.If we do feature engineering and remove the outliers there is a possibility of improving the accuracy of our models.I wil consider doing feature engineering in coming days.","907c3e2f":"### Importing the python module","612bba70":"### Importing Dataset","024022a8":"# TO BE CONTINUED","4cce1e0b":"Here we are getting the count and the percentage of missing values.We can see that 20% of the values are missing in the columns reviews_per_month and last_review.","e1494fe0":"### You can refer to my other notebooks from https:\/\/www.kaggle.com\/binuthomasphilip\/code","f6e76ac8":"## F] Room Details","99ee89e3":"### Pie and Count Plot","6faca778":"### Plotting Missing Values","2828fbb7":"# 4.Model Evaluation","b14144b0":"# 5.Conclusion: \n\n1.We have 20% of the missing values in last_review and review_per_month columns.Missing value column have an impact on the price.So to improve our model we need to address this issue.\n\n2.Manhatten and Brooklyn have the highest share of hotels.This we could see with the help of Pie and Bar plot.Additionally to have visual clarity we have plotted scater plot and maps of the neighbourhoods.\n\n3.Manhattan has expensive and Staten Island has low priced rooms.But we can see there are more Price outliers in the Queens,Staten Island and Bronx.We hav categorised the rooms into three categories based on price.0-75,75-500 and 500+ as Low Medium abd High priced rooms.Most of the rooms fall in the Medium (75-200 $) category followed by Low and High range rooms.Very few people prefer to live in high priced rooms.\n\n4.In most cases the rooms are occupied for less than 100 days.But as see from the log scale plot the rooms are occupied from 100 to 1200 days.Some cases the occupancy is in terms of years.We can see clearly that most books are for 1-2-3 days\n\n5.The top 10 neighbourhoods the mean price is in the range 45 to 57 dollars.Mount Eden,Concord and Grant have higher mean prices.Bulls Head, Hunts Point and Tremont are the neighbourhoods with least price.The top neighbourhoods are differnt when we consider Mean and Maximum Prices.Astoria,Greenpoint,SideEast and Harlem have the the most expensive rooms.This could be because these places are posh localities.\n\n6.We can see than most people rent out entire apartment on airbnb followed by private room.This may also be an indicator people go on holidays and stay in airbnb with their family.Also possibility is people are listing more in Entire Apartment category.Very few people opt for shared rooms probably due to lack of privacy.Manhattan has more Apartments abd Shared room.While Brooklyn has more rooms in the private room category.\n\n7.Our word cloud of reviews shows the words that are more often used in the Name of this listings.We can see most of the words are related to the description,place and the experince in the room.We can see that low cost rooms or in range 0-50 $ have more reviews.This shows us that people who pay more for the rooms generally dont write reviews.It is observed people write reviews more if they are not happy with their experience.In case of costly rooms there is high possibility that the customers are happy.So they dont write much reviews.\n\n8.We have used Linear and Gradient Boosting algorithm to predict the price of rooms.We observe higher accuracy is obtained by using Gradient Boosting Algorithm.By doing addition feature engineering it would be possible to further improve accuracy of our model.","5ef55162":"# 2.Exploratory Data Analysis ","af75bab7":"## Linear Regression ","7de016dd":"# 1.Data Exploration","a3dfcaad":"## Gradient Boosted Regressor Model","ddcb4ae1":"### Summary of Dataset","66fb592c":"1.From the above table we can see than the mean price of rooms is 157 dollars.The maximum price of a room is 10000 dollars\n\n2.On an average people spend 7 days in rooms.This kind of indicates people prefer a week of holiday.From the data we can see some one stayed for 1250 days which is nealry 4 years.","ffda25dc":"### Word Cloud","07b0321e":"## G] Reviews","9467cc97":"### Neighbourhoods with More Rooms","043bd83b":"We can see clearly that most books are for 1-2-3 days","7e709a2c":"### Linear Regression Plot","d28f77c8":"The dark horizontal lines show the missing values in the data set.We have more missing values in the column last_review and reviews_per_month.","7654b58c":"## E]Neighbourhood","96181aea":"### Removing Outliers","c1b314c5":"## D]Availability","a676ee59":"### Actual and Predicted Prices Plot ","bbfdd8dc":"Williamsburg,Bedford-Stuyvesant and Hariem have highest number of rooms.","02d9722d":"Yellow region on the map shows the places which have more room availabe throughout the year.So we book based on the region where more rooms are available there is possibility of getting cheaper rates.","32354f3c":"We will try to explore the data set to understand Airbnb business.We will be covering the following things in this notebook.\n\n1.Data Preprocesing\n\n2.Exploratory Data Analysis(EDA)\n\n3.Model Built\n\n4.Model Evaluaion\n\n5.Conclusion\n\nThis is a kernel in process and I will be updating the kernel in coming days.If you like my work please do vote.","0d7ba6da":"### Hotel Distribution in a Heat Map","4c40e792":"### Plot Gradient Boosted Regressor","7b572368":"### Actual and Predicted Prices "}}