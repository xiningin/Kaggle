{"cell_type":{"acc891d6":"code","175fa79d":"code","f2b71e13":"code","c1c9ef34":"code","3c7f23e0":"code","94b0eb9c":"code","3908c35c":"code","4f01b809":"markdown","2c6d4971":"markdown","d4f64cb1":"markdown","a9b72786":"markdown","71c323a6":"markdown","6d0078a4":"markdown","fab3a374":"markdown","84a3ca24":"markdown","b030196f":"markdown"},"source":{"acc891d6":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn import preprocessing","175fa79d":"data = pd.read_csv('\/kaggle\/input\/classictenis\/tenis.csv') # Load Data\ndata2 = data.apply(preprocessing.LabelEncoder().fit_transform) # Apply LabelEncoder","f2b71e13":"ohe = preprocessing.OneHotEncoder() # OneHotEncoder\nc = data2.iloc[:,:1] \nc = ohe.fit_transform(c).toarray()","c1c9ef34":"weatherforecast = pd.DataFrame(data=c, index = range(14), columns=['o','r','s'])\nfinaldata = pd.concat([weatherforecast,data.iloc[:,1:3]], axis=1)\nfinaldata = pd.concat([data2.iloc[:,-2:], finaldata], axis=1)","3c7f23e0":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(finaldata.iloc[:,:-1], finaldata.iloc[:,-1:], test_size=0.33, random_state=0)","94b0eb9c":"from sklearn.linear_model import LinearRegression\nregressor = LinearRegression()\nregressor.fit(x_train, y_train)\n\ny_pred = regressor.predict(x_test)","3908c35c":"import statsmodels.api as sm\n\nX = np.append(arr = np.ones((14,1)).astype(int), values = finaldata.iloc[:,:-1], axis = 1)\nX_l = finaldata.iloc[:, [0,1,2,3,4,5]].values\nX_l = np.array(X_l, dtype=float)\nmodel = sm.OLS(finaldata.iloc[:, -1:], X_l).fit()\nprint(model.summary())\n\nfinaldata = finaldata.iloc[:,1:]\n\nX = np.append(arr = np.ones((14,1)).astype(int), values = finaldata.iloc[:,:-1], axis = 1)\nX_l = finaldata.iloc[:, [0,1,2,3,4]].values\nX_l = np.array(X_l, dtype=float)\nmodel = sm.OLS(finaldata.iloc[:, -1:], X_l).fit()\nprint(model.summary())\n\nx_train = x_train.iloc[:,1:]\nx_test = x_test.iloc[:,1:]","4f01b809":"> Thanks For Reading \n     Good Bye :)","2c6d4971":"**What is One-Hot Encoding?**\n\n> For categorical variables where no such ordinal relationship exists, the integer encoding is not enough.\n> \n> In fact, using this encoding and allowing the model to assume a natural ordering between categories may result in poor performance or unexpected results (predictions halfway between categories).\n> \n> In this case, a one-hot encoding can be applied to the integer representation. This is where the integer encoded variable is removed and a new binary variable is added for each unique integer value.\n> \n> In the \u201ccolor\u201d variable example, there are 3 categories and therefore 3 binary variables are needed. A \u201c1\u201d value is placed in the binary variable for the color and \u201c0\u201d values for the other colors.\n\n**For example:**\n\n> red,\tgreen,\tblue\n> 1,\t\t0,\t\t0\n> 0,\t\t1,\t\t0\n> 0,\t\t0,\t\t1\n","d4f64cb1":"> Then let's start uploading our data..\n\nWhat is LabelEncoder ?\n- LabelEncoder encode labels with a value between 0 and n_classes-1 where n is the number of distinct labels. If a label repeats it assigns the same value to as assigned earlier.","a9b72786":"> Let's first import our necessary libraries.\n\nLibraries:\n    - Numpy\n    - Pandas\n    - matplotlib\n    - sklearn","71c323a6":"> **Linear Regression** Time !!!","6d0078a4":"> Let's See Our **Test Results**","fab3a374":"> Create Test Train","84a3ca24":"> Let's *Concat* our data","b030196f":"# Classic Tenis - Machine Learning Example\n"}}