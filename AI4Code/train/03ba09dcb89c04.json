{"cell_type":{"0284ba01":"code","be48e039":"code","e4c384d8":"code","81a81a86":"code","e71ac23d":"code","26fbcd6f":"code","3952ad6e":"code","74c6e521":"code","63cb8361":"code","ce872c73":"code","27c4604b":"code","b24a59d7":"code","440d2361":"code","970f6b27":"code","35b021a2":"code","8450cb90":"code","81fc1cbe":"code","f2d212ce":"code","1f7fdcc2":"code","490e4a78":"code","4e84b1cd":"code","7bc8ddb3":"code","d09a0f44":"code","e2e0b6d2":"code","e729c67d":"code","f5fb3f2b":"code","527c53b3":"code","038ab29b":"code","75cb9d53":"code","e7ddbe12":"code","35d1c899":"code","604f791c":"code","4fd0c719":"code","e4988abb":"code","c30ff9bd":"code","aa4615ad":"code","0e1da064":"code","bb6f01b6":"code","30f6f4d7":"code","b0a92811":"code","831a9c2f":"markdown"},"source":{"0284ba01":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","be48e039":"sub=pd.read_csv('\/kaggle\/input\/global-wheat-detection\/sample_submission.csv')\ntrain_df=pd.read_csv('\/kaggle\/input\/global-wheat-detection\/train.csv')","e4c384d8":"sub.head","81a81a86":"from tqdm import tqdm\nimport ast","e71ac23d":"\n# How many unique images?\nlen(train_df[\"image_id\"].unique())","26fbcd6f":"# Separating out the coordinates\nxmin, ymin, width, height = [], [], [], []\n\nfor i in tqdm(train_df[\"bbox\"]):\n    cooridinates_list = ast.literal_eval(i)\n    xmin.append(cooridinates_list[0])\n    ymin.append(cooridinates_list[1])\n    width.append(cooridinates_list[2])\n    height.append(cooridinates_list[3])","3952ad6e":"train_df[\"xmin\"] = xmin\ntrain_df[\"ymin\"] = ymin\ntrain_df[\"width\"] = width\ntrain_df[\"height\"] = height\ntrain_df.head()","74c6e521":"# Visualizing some samples from the training set\n\nsample_indices = np.random.choice(np.unique(train_df[\"image_id\"].tolist()), 8)\n\nfig, ax = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\ncount=0\n\nfor row in ax:\n    for col in row:\n        img = plt.imread(\"\/kaggle\/input\/global-wheat-detection\/train\/\" + sample_indices[count] + \".jpg\")\n        col.grid(False)\n        col.set_xticks([])\n        col.set_yticks([])\n        col.imshow(img)\n        count += 1\nplt.show()\n","63cb8361":"import matplotlib.patches as patches\n\ndef get_bbox(image_id, df, col, color='white'):\n    bboxes = df[df['image_id'] == image_id]\n    \n    for i in range(len(bboxes)):\n        # Create a Rectangle patch\n        rect = patches.Rectangle(\n            (bboxes['xmin'].iloc[i], bboxes['ymin'].iloc[i]),\n            bboxes['width'].iloc[i], \n            bboxes['height'].iloc[i], \n            linewidth=2, \n            edgecolor=color, \n            facecolor='none')\n\n        # Add the patch to the Axes\n        col.add_patch(rect)","ce872c73":"fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\ncount=0\nfor row in ax:\n    for col in row:\n        img = plt.imread(\"\/kaggle\/input\/global-wheat-detection\/train\/\" + sample_indices[count] + \".jpg\")\n        col.grid(False)\n        col.set_xticks([])\n        col.set_yticks([])\n        get_bbox(sample_indices[count], train_df, col, color='red')\n        col.imshow(img)\n        count += 1\nplt.show()","27c4604b":"# Images without bounding box\nimages_w_bbox = train_df[\"image_id\"].unique()\nimages_w_bbox = [\"\/kaggle\/input\/global-wheat-detection\/train\/\" + image_id + \".jpg\" for image_id in images_w_bbox]\n\nall_images = list(paths.list_images(\"\/kaggle\/input\/global-wheat-detection\/train\/\"))","b24a59d7":"images_w_bbox[:5]","440d2361":"all_images[:5]","970f6b27":"ax","35b021a2":"# Visualizing some images without any wheat heads\n\n'''fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(20, 10))\ncount=0\n\nfor row in ax:\n    for col in row:\n        img = plt.imread(images_wo_bbox[count])\n        col.grid(False)\n        col.set_xticks([])\n        col.set_yticks([])\n        col.imshow(img)\n        count += 1\nplt.show()'''","8450cb90":"images_wo_bbox = list(set(all_images) - set(images_w_bbox))\nimages_wo_bbox[:5]","81fc1cbe":"import matplotlib.patches as patches\nimport matplotlib.pyplot as plt\nfrom imutils import paths\nimport pandas as pd\nimport numpy as np \nimport cv2\nimport os","f2d212ce":"pip install imutils","1f7fdcc2":"def showbbox(image_path, xy, width, height):\n    # Create figure and axes\n    fig,ax = plt.subplots(1)\n\n    # Display the image\n    ax.imshow(plt.imread(image_path))\n\n    # Create a Rectangle patch\n    rect = patches.Rectangle(xy, width, height, \n        linewidth=2, edgecolor='r', facecolor='none')\n\n    # Add the patch to the Axes\n    ax.add_patch(rect)\n\n    plt.show()","490e4a78":"train_df","4e84b1cd":"showbbox('\/kaggle\/input\/global-wheat-detection\/train\/b6ab77fd7.jpg', (226.0, 548.0), 1024, 1024)","7bc8ddb3":"p=[]\nfor i in (train_df['bbox']):\n    d=i.split(',')\n    p.append(d)\n               ","d09a0f44":"p","e2e0b6d2":"d=[]\nfor i in range(0,len(p)):\n    s=p[i][0].strip('[')\n    #s.strip('[')\n    d.append(s)","e729c67d":"dd=[]\nfor i in range(0,len(p)):\n    s1=p[i][1].strip('[')\n    #s.strip('[')\n    dd.append(s1)","f5fb3f2b":"#train['xmin']=pd.Series(d)\n#train['ymin']=pd.Series(dd)","527c53b3":"train_df","038ab29b":"#train['xmin']=train['xmin'].astype('float')\n#train['ymin']=train['ymin'].astype('float')","75cb9d53":"train_df[\"xmax\"] = train_df[\"xmin\"] + train_df[\"width\"]\ntrain_df[\"ymax\"] = train_df[\"ymin\"] + train_df[\"height\"]\ntrain_df.head()","e7ddbe12":"# Rename the image_id column to filename & add full paths\ntrain_df.rename(columns={\n        \"image_id\":\"filename\"\n    }, inplace=True)\n\nimages_w_bbox = train_df[\"filename\"]\nimages_w_bbox = [\"\/kaggle\/input\/global-wheat-detection\/train\/\" + image_id + \".jpg\" for image_id in images_w_bbox]\ntrain_df[\"filename\"] = images_w_bbox\ntrain_df.head()","35d1c899":"# Drop the unnecessary columns, we will return to this step in a moment\ntrain_df.drop([\"source\", \"bbox\"], axis=1, inplace=True)\ntrain_df.head()","604f791c":"import math\nmath.floor(2.3)","4fd0c719":"# Add a class column \ntrain_df[\"class\"] = \"wheat_head\"\ntrain_df.head()","e4988abb":"# Prepare the splits\nfrom sklearn.model_selection import train_test_split\n\ntrain1, valid = train_test_split(train_df, test_size=0.15, random_state=666)\nprint(\"Training samples:\", train1.shape[0])\nprint(\"Validation samples:\", valid.shape[0])","c30ff9bd":"\ntrain1 = train1.reset_index(drop=True)\ntrain1.head()","aa4615ad":"\nvalid = valid.reset_index(drop=True)\nvalid.head()","0e1da064":"# Serialize the dataframes\ntrain1.to_csv(\"new_train_df.csv\")\nvalid.to_csv(\"valid_df.csv\")","bb6f01b6":"\n# Preparing the label maps\nLABEL_ENCODINGS = {\n    \"wheat_head\": 1\n}\n\nf = open(\"label_map.pbtxt\", \"w\")\n\nfor (k, v) in LABEL_ENCODINGS.items():\n    # construct the class information and write to file\n    item = (\"item {\\n\"\n            \"\\tid: \" + str(v) + \"\\n\"\n            \"\\tname: '\" + k + \"'\\n\"\n            \"}\\n\")\n    f.write(item)\n\n# close the output classes file\nf.close()","30f6f4d7":"!cat label_map.pbtxt","b0a92811":"'''from __future__ import division\nfrom __future__ import print_function\nfrom __future__ import absolute_import\n\nimport os\nimport io\nimport pandas as pd\nimport tensorflow as tf\n\nfrom PIL import Image\n#from object_detection.utils import dataset_util\nfrom collections import namedtuple, OrderedDict\n\nflags = flags\nflags.DEFINE_string('csv_input', '', 'Path to the CSV input')\nflags.DEFINE_string('output_path', '', 'Path to output TFRecord')\nFLAGS = flags.FLAGS\n\nLABEL_ENCODINGS = {\n    \"wheat_head\": 1\n}\n\n\ndef split(df, group):\n    data = namedtuple('data', ['filename', 'object'])\n    gb = df.groupby(group)\n    return [data(filename, gb.get_group(x)) for filename, x in zip(gb.groups.keys(), gb.groups)]\n\n\ndef create_tf_example(group, path):\n    with tf.gfile.GFile(os.path.join(path, '{}'.format(group.filename)), 'rb') as fid:\n        encoded_jpg = fid.read()\n    encoded_jpg_io = io.BytesIO(encoded_jpg)\n    image = Image.open(encoded_jpg_io)\n    width, height = image.size\n\n    filename = group.filename.encode('utf8')\n    image_format = b'jpg'\n    xmins = []\n    xmaxs = []\n    ymins = []\n    ymaxs = []\n    classes_text = []\n    classes = []\n\n    for index, row in group.object.iterrows():\n        xmins.append(row['xmin'] \/ width)\n        xmaxs.append(row['xmax'] \/ width)\n        ymins.append(row['ymin'] \/ height)\n        ymaxs.append(row['ymax'] \/ height)\n        classes_text.append(row['class'].encode('utf8'))\n        classes.append(LABEL_ENCODINGS[row['class']])\n\n    tf_example = tf.train.Example(features=tf.train.Features(feature={\n        'image\/height': dataset_util.int64_feature(height),\n        'image\/width': dataset_util.int64_feature(width),\n        'image\/filename': dataset_util.bytes_feature(filename),\n        'image\/source_id': dataset_util.bytes_feature(filename),\n        'image\/encoded': dataset_util.bytes_feature(encoded_jpg),\n        'image\/format': dataset_util.bytes_feature(image_format),\n        'image\/object\/bbox\/xmin': dataset_util.float_list_feature(xmins),\n        'image\/object\/bbox\/xmax': dataset_util.float_list_feature(xmaxs),\n        'image\/object\/bbox\/ymin': dataset_util.float_list_feature(ymins),\n        'image\/object\/bbox\/ymax': dataset_util.float_list_feature(ymaxs),\n        'image\/object\/class\/text': dataset_util.bytes_list_feature(classes_text),\n        'image\/object\/class\/label': dataset_util.int64_list_feature(classes),\n    }))\n    return tf_example\n\n\ndef main(_):\n    writer = tf.python_io.TFRecordWriter(FLAGS.output_path)\n    path = os.path.join(os.getcwd())\n    examples = pd.read_csv(FLAGS.csv_input)\n    grouped = split(examples, 'filename')\n    for group in grouped:\n        tf_example = create_tf_example(group, path)\n        writer.write(tf_example.SerializeToString())\n\n    writer.close()\n    output_path = os.path.join(os.getcwd(), FLAGS.output_path)\n    print('Successfully created the TFRecords: {}'.format(output_path))\n\n\nif __name__ == '__main__':\n    tf.app.run()'''","831a9c2f":"## LOADING THE LIBRARY"}}