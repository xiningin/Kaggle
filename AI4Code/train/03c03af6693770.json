{"cell_type":{"1cf206d2":"code","787d69ff":"code","a700b112":"code","f89309ee":"code","6c575acf":"code","7bb70c84":"code","01b40c8b":"code","eab262ae":"code","b21c3365":"code","e9d364f7":"code","e6453d8d":"code","5582f8cf":"code","7cec7d03":"code","1f0fe044":"code","63d348d1":"code","8ee10bd9":"code","742301a7":"code","2db07666":"markdown","d2ecc8ee":"markdown","4bebc009":"markdown","29a4f03d":"markdown","f76eae68":"markdown","cd90dee9":"markdown","bad9f2ac":"markdown","a55a7a36":"markdown","6ffed7b9":"markdown","71958402":"markdown","3adcf88d":"markdown","10838011":"markdown","a1b66ee2":"markdown","f83aa4cf":"markdown","602d91a9":"markdown","a6003c5d":"markdown","2442b41b":"markdown","688b5e40":"markdown","224e115b":"markdown","c37969e7":"markdown","ae7ee93e":"markdown"},"source":{"1cf206d2":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\n\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping, LambdaCallback\n\n%matplotlib inline\n#tf.logging.set_verbosity(tf.logging.ERROR)\n\nprint('Libraries imported.')","787d69ff":"column_names = ['serial', 'date', 'age', 'distance', 'stores', 'latitude', 'longitude', 'price']\ndf = pd.read_csv('..\/input\/house-data\/data.csv', names = column_names) \ndf.head()","a700b112":"df.isna().sum()","f89309ee":"df = df.iloc[:,1:]\ndf_norm = (df - df.mean()) \/ df.std()\ndf_norm.head()","6c575acf":"y_mean = df['price'].mean()\ny_std = df['price'].std()\n\ndef convert_label_value(pred):\n    return int(pred * y_std + y_mean)\n\nprint(convert_label_value(0.350088))","7bb70c84":"X = df_norm.iloc[:, :6]\nX.head()","01b40c8b":"Y = df_norm.iloc[:, -1]\nY.head()","eab262ae":"X_arr = X.values\nY_arr = Y.values\n\nprint('X_arr shape: ', X_arr.shape)\nprint('Y_arr shape: ', Y_arr.shape)","b21c3365":"X_train, X_test, y_train, y_test = train_test_split(X_arr, Y_arr, test_size = 0.05, shuffle = True, random_state=0)\n\nprint('X_train shape: ', X_train.shape)\nprint('y_train shape: ', y_train.shape)\nprint('X_test shape: ', X_test.shape)\nprint('y_test shape: ', y_test.shape)","e9d364f7":"def get_model():\n    \n    model = Sequential([\n        Dense(10, input_shape = (6,), activation = 'relu'),\n        Dense(20, activation = 'relu'),\n        Dense(5, activation = 'relu'),\n        Dense(1)\n    ])\n\n    model.compile(\n        loss='mse',\n        optimizer='adadelta'\n    )\n    \n    return model\n\nmodel = get_model()\nmodel.summary()","e6453d8d":"early_stopping = EarlyStopping(monitor='val_loss', patience = 5)\n\nmodel = get_model()\n\npreds_on_untrained = model.predict(X_test)\n\nhistory = model.fit(\n    X_train, y_train,\n    validation_data = (X_test, y_test),\n    epochs = 1000,\n    callbacks = [early_stopping]\n)","5582f8cf":"def plot_loss(history):\n    h = history.history\n    x_lim = len(h['loss'])\n    plt.figure(figsize=(8, 8))\n    plt.plot(range(x_lim), h['val_loss'], label = 'Validation Loss')\n    plt.plot(range(x_lim), h['loss'], label = 'Training Loss')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    return","7cec7d03":"plot_loss(history)","1f0fe044":"def compare_predictions(preds1, preds2, y_test):\n    plt.figure(figsize=(8, 8))\n    plt.plot(preds1, y_test, 'ro', label='Untrained Model')\n    plt.plot(preds2, y_test, 'go', label='Trained Model')\n    plt.xlabel('Preds')\n    plt.ylabel('Labels')\n    \n    y_min = min(min(y_test), min(preds1), min(preds2))\n    y_max = max(max(y_test), max(preds1), max(preds2))\n    \n    plt.xlim([y_min, y_max])\n    plt.ylim([y_min, y_max])\n    plt.plot([y_min, y_max], [y_min, y_max], 'b--')\n    plt.legend()\n    plt.show()\n    return","63d348d1":"preds_on_trained = model.predict(X_test)\n\ncompare_predictions(preds_on_untrained, preds_on_trained, y_test)","8ee10bd9":"def plot_predictions(preds, y_test):\n    plt.figure(figsize=(8, 8))\n    plt.plot(preds, y_test, 'ro')\n    plt.xlabel('Preds')\n    plt.ylabel('Labels')\n    plt.xlim([-0.5, 0.5])\n    plt.ylim([-0.5, 0.5])\n    plt.plot([-0.5, 0.5], [-0.5, 0.5], 'b--')\n    plt.show()\n    return","742301a7":"price_on_untrained = [convert_label_value(y) for y in preds_on_untrained]\nprice_on_trained = [convert_label_value(y) for y in preds_on_trained]\nprice_y_test = [convert_label_value(y) for y in y_test]\n\ncompare_predictions(price_on_untrained, price_on_trained, price_y_test)","2db07666":"## 6.2: Plot Training and Validation Loss\n\nLet's use the `plot_loss` helper function to take a look training and validation loss.","d2ecc8ee":"## 2.1: Importing the Data\n\nThe dataset is saved in a `data.csv` file. We will use `pandas` to take a look at some of the rows.","4bebc009":"## 3.2: Convert Label Value\n\nBecause we are using normalized values for the labels, we will get the predictions back from a trained model in the same distribution. So, we need to convert the predicted values back to the original distribution if we want predicted prices.","29a4f03d":"## 1.1: Importing Libraries & Helper Functions\n\nFirst of all, we will need to import some libraries and helper functions. This includes TensorFlow and some utility functions that I've written to save time.","f76eae68":"## 7.2: Plot Price Predictions\n\nThe plot for price predictions and raw predictions will look the same with just one difference: The x and y axis scale is changed.","cd90dee9":"## 4.3: Feature and Label Values\n\nWe will need to extract just the numeric values for the features and labels as the TensorFlow model will expect just numeric values as input.","bad9f2ac":"# Task 3: Data Normalization","a55a7a36":"## 5.1: Create the Model\n\nLet's write a function that returns an untrained model of a certain architecture.","6ffed7b9":"# Task 7: Predictions","71958402":"## 4.4: Train and Test Split\n\nWe will keep some part of the data aside as a __test__ set. The model will not use this set during training and it will be used only for checking the performance of the model in trained and un-trained states. This way, we can make sure that we are going in the right direction with our model training.","3adcf88d":"# Task 6: Model Training","10838011":"## 3.1: Data Normalization\n\nWe can make it easier for optimization algorithms to find minimas by normalizing the data before training a model.","a1b66ee2":"# Task 2: Importing the Data","f83aa4cf":"Predicting House Prices with Regression using TensorFlow\n\n---\n\nFor this project, we are going to work on evaluating price of houses given the following features:\n\n1. Year of sale of the house\n2. The age of the house at the time of sale\n3. Distance from city center\n4. Number of stores in the locality\n5. The latitude\n6. The longitude\n\nNote: This notebook uses `python 3` and these packages: `tensorflow`, `pandas`, `matplotlib`, `scikit-learn`.","602d91a9":"## 7.1: Plot Raw Predictions\n\nLet's use the `compare_predictions` helper function to compare predictions from the model when it was untrained and when it was trained.","a6003c5d":"## 2.2: Check Missing Data\n\nIt's a good practice to check if the data has any missing values. In real world data, this is quite common and must be taken care of before any data pre-processing or model training.","2442b41b":"# Task 4: Create Training and Test Sets","688b5e40":"## 4.2: Select Labels","224e115b":"## 4.1: Select Features\n\nMake sure to remove the column __price__ from the list of features as it is the label and should not be used as a feature.","c37969e7":"# Task 5: Create the Model","ae7ee93e":"## 6.1: Model Training\n\nWe can use an `EarlyStopping` callback from Keras to stop the model training if the validation loss stops decreasing for a few epochs."}}