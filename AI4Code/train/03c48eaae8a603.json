{"cell_type":{"87e7bb67":"code","892b74f5":"code","2952a91a":"code","b9b4a8e6":"code","8ec23f58":"code","4d35029a":"code","42779496":"code","7bf64e82":"code","2873c1f1":"code","76e1cfe5":"code","a9a96080":"code","a8f32d7e":"code","545f76f2":"code","bf3c0e2a":"code","2fee9209":"markdown","503dd44b":"markdown","141e789a":"markdown","acd90043":"markdown","ef0d4871":"markdown","b379f1b2":"markdown","c4784dcf":"markdown"},"source":{"87e7bb67":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","892b74f5":"df = pd.read_csv('..\/input\/googleplaystore.csv', header=0)\ndf.head()","2952a91a":"df.dtypes","b9b4a8e6":"df['Price'].value_counts()","8ec23f58":"df['SizeS'] = df['Size'].str.extract('([0-9\\.]+)[Mk]')\ndf['PriceS'] = df['Price']\ndf['PriceS'] = np.where(df['Price'] != '0', df['Price'].str.extract('\\$([0-9\\.]*)'), df['Price'])\ndf.head()","4d35029a":"df['Ratingf'] = df['Rating'].astype(\"float64\")\ndf['Pricef'] = df['PriceS'].astype(\"float64\")\ndf['Reviewsf'] = df['Reviews'].astype(\"float64\", errors=\"ignore\")\ndf['Sizef'] = df['SizeS'].astype(\"float64\")\ndf['Last Updatedf'] = pd.to_datetime(df['Last Updated'], format='%B %d, %Y', errors=\"ignore\")\ndf.head()","42779496":"df.dtypes","7bf64e82":"print(df.shape)","2873c1f1":"df.isna().sum()","76e1cfe5":"df['Category'].value_counts()","a9a96080":"df_fill = df\ndf_fill['Sizem'] = df_fill['Sizef'].fillna(df_fill.groupby(\"Category\")['Sizef'].transform('mean'))\ndf_fill['Ratingm'] = df_fill['Ratingf'].fillna(df_fill.groupby(\"Category\")['Ratingf'].transform('mean'))\ndf_fill['Pricem'] = df_fill['Pricef'].fillna(df_fill.groupby(\"Category\")['Pricef'].transform('mean'))\ndf_fill.head()","a8f32d7e":"df_fill = df_fill.dropna(how='any', subset=['Ratingm', 'Sizem', 'Pricem'])","545f76f2":"df_fill.isna().sum()","bf3c0e2a":"df_fill.head()","2fee9209":"In the dataset `Price` and `Size` are of object type. Price is either '0' or something like, '$3.99' and size is something like '2.4M' or '50.9k', so we will try to extract the price & size using regular expression groups. Remember to only extract price values when its not zero or the regex will return `NA`.\n\n_NOTE_: To analyze `Price` and `Size` run a simple `df['Price'].value_counts()`","503dd44b":"We still can see that there is one record which has missing data, This is just missaligned data in the CSV, can fix the alignment manually or we can just drop it. Here we will drop it if any of `Rating`, `Size` and `Price` is `NA`.","141e789a":"Let's check where is the missing data...","acd90043":"Cool...now let's do some `dtype` casting...Also, we need to convert `Last Updatedf` from `object` to `datetime` type.","ef0d4871":"Let's check what kind of schema\/datatypes we are dealing with here...","b379f1b2":"We have missing data at `Size`, `Rating` and at `Price`. We can easily impute this data with categorical mean. So we will fill `NA` by grouping over `Category` and taking mean of each category.","c4784dcf":"Here we go.... :)"}}