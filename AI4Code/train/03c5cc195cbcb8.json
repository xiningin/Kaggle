{"cell_type":{"a3fbbc7f":"code","d5bf33e9":"code","88f75548":"code","b5f03fbe":"code","cfacaf00":"code","7ea8c507":"code","a3c53aa9":"code","b960f2f4":"code","0c3ca72c":"code","b46ebedb":"code","4d89a008":"code","5d1d10d4":"code","42a02ff2":"markdown","0a58397c":"markdown","9915801b":"markdown","b4ba8ec9":"markdown","6ef3336d":"markdown","c5f55c8e":"markdown","0684dc05":"markdown","2b99aa9d":"markdown","7a10e413":"markdown","2791a862":"markdown"},"source":{"a3fbbc7f":"import pandas as pd\nimport tqdm\nimport math\nimport torch\nimport glob\nfrom collections import defaultdict","d5bf33e9":"YOLO_CONFIDENCE = 0.3","88f75548":"df_train = pd.read_csv('..\/input\/shopee-product-matching\/train.csv')\ndf_train","b5f03fbe":"yolov5 = torch.hub.load('..\/input\/yolov5-git\/yolov5-master\/yolov5-master', 'yolov5m', source='local')\nyolov5.conf = YOLO_CONFIDENCE  # confidence threshold","cfacaf00":"photos = glob.glob('..\/input\/shopee-product-matching\/train_images\/*.jpg')","7ea8c507":"def get_area(x1, x2, y1, y2):\n    return round(abs(x1-x2) * abs(y1-y2), 2)\n\ndef get_distance_to_center(x1, x2, y1, y2):\n    # Distance of normalized coordinates to image center (0.5, 0.5)\n    return round(((x1+x2)\/2 - 0.5)**2 + ((y1+y2)\/2 - 0.5)**2, 4)","a3c53aa9":"elements_per_batch = 70\nn_batches = math.ceil(len(photos)\/elements_per_batch)\nlast_index = 0\nlast_slash = photos[0].rfind('\/')  # Index for last slash is always the same\n\npredictions_dict = {}\n\nfor _ in tqdm.tqdm(range(n_batches)):\n    if last_index + elements_per_batch > len(photos):\n        current_photos = photos[last_index:]\n    else:\n        current_photos = photos[last_index:last_index+elements_per_batch]\n    current_photos_names = list(current_photos)  # the model modifies this list, so we keep a copy\n    \n    results = yolov5(current_photos)\n    \n    for photo_name, predictions in zip(current_photos_names, results.xyxyn):\n        photo_name = photo_name[last_slash+1:]\n        predictions_by_photo = defaultdict(list)\n        for p in predictions:\n            x1, y1, x2, y2, confidence, class_index = [round(element, 2) for element in p.tolist()]\n            class_index = int(class_index)\n            try:\n                element_index = predictions_by_photo['class_index'].index(class_index)\n                predictions_by_photo['n_occurences'][element_index] += 1\n                if confidence > predictions_by_photo['confidence'][element_index]:  # I think that the model returns predictions ordered by confidence, but just in case\n                    predictions_by_photo['confidence'][element_index] = confidence\n                    predictions_by_photo['norm_area'][element_index] = get_area(x1, x2, y1, y2)\n                    predictions_by_photo['norm_dis_to_org'][element_index] = get_distance_to_center(x1, x2, y1, y2)\n            except ValueError:  # class first occurence\n                predictions_by_photo['class_index'].append(class_index)\n                predictions_by_photo['n_occurences'].append(1)\n                predictions_by_photo['presence'].append(1)\n                predictions_by_photo['confidence'].append(confidence)\n                predictions_by_photo['norm_area'].append(get_area(x1, x2, y1, y2))\n                predictions_by_photo['norm_dis_to_org'].append(get_distance_to_center(x1, x2, y1, y2))\n            \n        predictions_dict[photo_name] = predictions_by_photo\n                \n    last_index += elements_per_batch\n    ","b960f2f4":"obj_names_without_spaces = [name.replace(' ', '-') for name in yolov5.names]\nfeatures = ['n_occurences', 'confidence', 'norm_area', 'norm_dis_to_org', 'presence']\nnew_cols = [f'objects_{feature}_{obj_names_without_spaces[object_index]}' for object_index in range(len(yolov5.names)) for feature in features]\n\ndf_train = df_train.reindex(columns=df_train.columns.tolist() + new_cols, fill_value=0)","0c3ca72c":"def get_values_for_row(row):\n    predictions = predictions_dict[row['image']]\n    values = [0] * len(features) * len(yolov5.names)  # Fill all values with 0s and only replace the not null ones\n    for element_index, class_index in enumerate(predictions['class_index']):\n        for feature_index, feature_name in enumerate(features):\n            # Replace 0 with actual value\n            values[class_index*len(features) + feature_index] = predictions[feature_name][element_index]\n    return pd.Series(values)","b46ebedb":"df_train[new_cols] = df_train.apply(get_values_for_row, axis=1)","4d89a008":"df_train","5d1d10d4":"df_train.to_csv(f'train_obj_0{int(YOLO_CONFIDENCE*10)}_one-hot.csv')","42a02ff2":"# Load data","0a58397c":"Predict objects. For each element, the following is obtained:\n* class_index: list of objects detected. Each object is identified by an index. To access the name of the object, do yolov5.names[index]\n* n_occurences: more than one instance per object may be detected, so the count is stored here\n* presence: variable equal to n_occurences > 0, but stored for easier access\n* confidence: confidence of prediction. Note that becuase of One-Hot format only the information of the instance with highest confidence per object is stored\n* norm_area: normalized area (computed with normalized coordinates, which go from 0 to 1)\n* norm_dis_to_org: normalized distance to the origin of the image from the center of the object (computed with normalized coordinates, which go from 0 to 1)","9915801b":"# Load Object Detector","b4ba8ec9":"# Objects to DataFrame","6ef3336d":"Get names of photos","c5f55c8e":"Create empty columns for all objects to then get values with .apply per row","0684dc05":"Notebook that detects objects in Shopee train set and outputs information in One-Hot format","2b99aa9d":"Auxiliary function to transfer data to DataFrame","7a10e413":"Auxiliary functions","2791a862":"# Predict objects"}}