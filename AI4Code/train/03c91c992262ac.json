{"cell_type":{"09e83027":"code","87a44e27":"code","d03d09b6":"code","7369dca3":"code","95f2e8ff":"code","5b2692a2":"code","6c254c92":"code","4ab61dda":"code","b9688062":"code","fe54f6f8":"code","6e7c9119":"code","f0781f28":"code","924055d6":"code","43bdcbb4":"code","8c5b0f5b":"code","635a9e04":"code","bae8f9a2":"code","761f2e86":"code","10f82ded":"code","c8421ddd":"markdown","27cc75dc":"markdown","a531f795":"markdown","3f5fed9e":"markdown","2079bf9e":"markdown","7094dc7c":"markdown","f56b9896":"markdown","bceaf037":"markdown","60f294ff":"markdown","7080ed1d":"markdown","ef47b798":"markdown","8cc646e1":"markdown","af8c59e5":"markdown","9991f919":"markdown","71e6ae75":"markdown","159b7814":"markdown"},"source":{"09e83027":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n","87a44e27":"df_val = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\")\ndf_val.shape","d03d09b6":"gp1=df_val.copy()\n\n# Create a hash function for every unique pair\ngp1['pair'] = gp1.apply(lambda x:\" \".join(sorted((x['less_toxic'],\n                                                  x['more_toxic']))),axis=1)\ngp1['pair_hash'] = gp1.pair.apply(lambda x: str(abs(hash(x)) % (10 ** 8)))\ndel gp1['pair']\n\nf'No. of rows in val_data: {len(gp1)} and no. of unique sentence pairs: {len(gp1.pair_hash.drop_duplicates())}'\n","7369dca3":"gp1.groupby(['pair_hash']).size().reset_index()[0].value_counts()","95f2e8ff":"gp1['pair_cnt']=gp1.groupby(['pair_hash'])['worker'].transform(lambda x: x.count())\n\ngp1['cnt']=gp1.groupby(['pair_hash', \n                        'less_toxic',\n                        'more_toxic'])['worker'].transform(lambda x: x.count())\n\nprint(gp1[['less_toxic','more_toxic','cnt']].drop_duplicates().cnt.value_counts())\n","5b2692a2":"# By this logic , max possible score is \n(4698*3 + 5302*2 + (5410-5302)) \/ len(df_val) ","6c254c92":"pd.options.display.max_colwidth = 200\ngp1[(gp1.pair_cnt == 3) & (gp1.cnt == 1)]","4ab61dda":"df_val2 = gp1[~((gp1.pair_cnt == 3) & (gp1.cnt == 1))][['worker', 'less_toxic', 'more_toxic']]","b9688062":"df_val2.shape","fe54f6f8":"df_val3 = df_val2[['less_toxic', 'more_toxic']].drop_duplicates()\ndf_val3.shape","6e7c9119":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.linear_model import Ridge,RidgeCV, LinearRegression\nfrom sklearn.pipeline import Pipeline, FeatureUnion\n","f0781f28":"df = pd.read_csv(\"..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv\")\nprint(df.shape)\n\n# Give more weight to severe toxic \ndf['severe_toxic'] = df.severe_toxic * 3\ndf['threat'] = df.threat * 2\n\ndf['y'] = (df[['toxic', 'severe_toxic', 'obscene', 'threat', 'insult', 'identity_hate']].sum(axis=1) ).astype(int)\ndf = df[['comment_text', 'y']].rename(columns={'comment_text': 'text'})\n\n# Reduce rows with 0 toxicity\ndf = pd.concat([df[df.y>0] , \n                df[df.y==0].sample(int(len(df[df.y>0])*1.5)) ], axis=0).sample(frac=1)\n\nprint(df.shape)","924055d6":"features = FeatureUnion(\n[\n        (\"vect1\", TfidfVectorizer(min_df= 3, max_df=0.5, analyzer = 'char_wb', ngram_range = (3,5))),\n])\n\npipeline = Pipeline(\n    [\n        (\"vect\", features),\n        (\"clf\", Ridge(alpha=1 )),\n    ]\n)","43bdcbb4":"pipeline.fit(df['text'], df['y'])\n","8c5b0f5b":"p1 = pipeline.predict(df_val['less_toxic'])\np2 = pipeline.predict(df_val['more_toxic'])\n\nf'Validation Accuracy from Model 1 is { np.round((p1 < p2).mean() * 100,2)}'","635a9e04":"p1_m = pipeline.predict(df_val2['less_toxic'])\np2_m = pipeline.predict(df_val2['more_toxic'])\n\nf'Validation Accuracy from Model 1 is { np.round((p1_m < p2_m).mean() * 100,2)}'","bae8f9a2":"p1_m3 = pipeline.predict(df_val3['less_toxic'])\np2_m3 = pipeline.predict(df_val3['more_toxic'])\n\nf'Validation Accuracy from Model 1 is { np.round((p1_m3< p2_m3).mean() * 100,2)}'","761f2e86":"df_sub = pd.read_csv(\"..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\")\n\nm1_preds = pipeline.predict(df_sub['text'])\n\ndf_sub['score'] = m1_preds","10f82ded":"df_sub[['comment_id', 'score']].to_csv(\"submission.csv\", index=False)","c8421ddd":"- Only 108 cases with single worker\n- 10000 cases with 3 workers","27cc75dc":"## Predict on test data","a531f795":"### Validate on __actual__ val data","3f5fed9e":"### Validate on __modified__ val3 data","2079bf9e":"### Validation scores","7094dc7c":"### Cases with 3 unique rating and 1 disagreement","f56b9896":"## The validation score is much better aligned with LB now","bceaf037":"### Test data could also be unique cases of these pairs","60f294ff":"## No. of cases per pair","7080ed1d":"## Counts per unique pair\n### Unique pairs occuring 3 times are decisively correct (3\/3 same rating)\n","ef47b798":"## Since LB scores are already ~0.85 , Val and test data are quite different.\n### It is possible that test data is cleaner and doesnt have cases with contradictory ratings","8cc646e1":"- 4698 cases are fine - 3\/3 same rating\n- 5302 cases are being rated as same by 2\/3 workers","af8c59e5":"### As seen previously, there are cases in validation with contradictory ratings from annotators\n### Lets see such cases","9991f919":"### Max possible score on val data is 0.823","71e6ae75":"- In thats case , removing the cases with contradictory ratings: ","159b7814":"### Validate on __modified__ val2 data"}}