{"cell_type":{"4d98f197":"code","d3c0a511":"code","49436db3":"code","0848e873":"code","cf6de8fa":"code","92759a2c":"code","b6eec62e":"code","c5d0e13e":"code","126f2520":"code","c839dc8e":"code","8b393f4a":"code","6b13ae11":"code","d2c3f6db":"code","8b5a818a":"code","3b497fb3":"code","4d8ff5b2":"code","01224715":"code","f5fcc651":"code","c6603627":"code","bd90906a":"markdown","ad3dc5fa":"markdown","1d2bb3e9":"markdown","5d448961":"markdown"},"source":{"4d98f197":"import numpy as np \nimport pandas as pd\n\nimport os\ndir_black = os.path.join('..\/input\/soil-types\/Soil types\/Black Soil')\ndir_Cinder = os.path.join('..\/input\/soil-types\/Soil types\/Cinder Soil')\ndir_Laterite = os.path.join('..\/input\/soil-types\/Soil types\/Laterite Soil')\ndir_peat = os.path.join('..\/input\/soil-types\/Soil types\/Peat Soil')\ndir_yellow = os.path.join('..\/input\/soil-types\/Soil types\/Yellow Soil')\n        ","d3c0a511":"import tensorflow as tf\nfrom tensorflow import keras","49436db3":"image_size = 220\nbatch_size = 10\n\n\ntarget_size = (image_size, image_size)\ninput_shape = (image_size, image_size, 3)","0848e873":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ntrain_datagen = ImageDataGenerator(rescale=1\/255)\n\n\ntrain_generator = train_datagen.flow_from_directory(\n        '..\/input\/soil-types\/Soil types\/', \n        target_size=(200, 200),\n        batch_size = batch_size,\n        classes = [ 'Black Soil','Cinder Soil', 'Laterite Soil','Peat Soil','Yellow Soil'],\n       class_mode='categorical')","cf6de8fa":"for image_batch, label_batch in train_generator:\n  break\n  image_batch.shape, label_batch.shape","92759a2c":"print (train_generator.class_indices)","b6eec62e":"model = tf.keras.models.Sequential([\n    \n    # The first convolution\n    tf.keras.layers.Conv2D(16, (3,3), activation='relu', input_shape=(220, 220, 3)),\n    tf.keras.layers.MaxPooling2D(2, 2),\n    # The second convolution\n    tf.keras.layers.Conv2D(32, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The third convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fourth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    # The fifth convolution\n    tf.keras.layers.Conv2D(64, (3,3), activation='relu'),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    # Flatten the results to feed into a dense layer\n    tf.keras.layers.Flatten(),\n    # 128 neuron in the fully-connected layer\n    tf.keras.layers.Dense(128, activation='relu'),\n    # 5 output neurons for 5 classes with the softmax activation\n    tf.keras.layers.Dense(5, activation='softmax')\n])\n\n","c5d0e13e":"model.summary()","126f2520":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=RMSprop(learning_rate=0.001),\n              metrics=['acc'])","c839dc8e":"total_sample = train_generator.n\nn_epochs = 30","8b393f4a":"history = model.fit(\n        train_generator, \n        steps_per_epoch = int(total_sample\/batch_size),  \n        epochs = n_epochs,\n        verbose = 1)","6b13ae11":"import matplotlib.pyplot as plt","d2c3f6db":"plt.figure(figsize=(7,4))\nplt.plot([i+1 for i in range(n_epochs)],history.history['acc'],'-o',c='k',lw=2,markersize=9)\nplt.grid(True)\nplt.title(\"Training accuracy with epochs\\n\",fontsize=18)\nplt.xlabel(\"Training epochs\",fontsize=15)\nplt.ylabel(\"Training accuracy\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","8b5a818a":"model.save('my_model.h5')","3b497fb3":"model.save(filepath=\"save_model\/\")","4d8ff5b2":"from tensorflow.keras.models import Sequential\nmodel.export(export_dir='.')","01224715":"converter = tf.lite.TFLiteConverter.from_saved_model('save_model')\ntflite_model = converter.convert()\nopen(\"soil.tflite\", \"wb\").write(tflite_model)","f5fcc651":"model.save_weights(\"model.h5\")","c6603627":"#  tf.keras.models.save_model(model, filepath=\"save_model\/save_model\")","bd90906a":"**Some ways to save the model...**","ad3dc5fa":"The saved model formats can be used to continue with the model preparation without actually starting from the beginning.<br>\nThe saved model files can be used to deploy the model in android or web applications.","1d2bb3e9":"This is folder based data or directory based and thus the images are in folders that are again in main folder. This creates a problem of accessing the image data which aren't augmented.<br>\nThe Keras has ImageDataGenerator class which generate batches of tensor image data with real-time data augmentation. The data will be looped over (in batches). Basically, it can be used to augment image data with a lot of built-in pre-processing.","5d448961":"In this, the flow_from_directory method automatically scans through all the sub-directories and sources the images along with their appropriate labels."}}