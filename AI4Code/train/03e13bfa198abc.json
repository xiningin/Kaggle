{"cell_type":{"3b383b1a":"code","c9911149":"code","9fee1d8a":"code","5c169ef0":"code","6004039a":"code","b8c65882":"code","7aa45c7d":"code","b3c59c36":"code","cd89bf1a":"code","8a34a7c9":"code","ebe4be94":"code","69a85e52":"code","a1ad5526":"code","b1bbd2b3":"code","e150351a":"code","3dbb6443":"code","0a149e91":"code","30399b91":"code","ca261ef8":"code","3a255c25":"code","6ec3a335":"code","f6abb936":"code","7740978c":"code","6685407e":"code","dbce120c":"code","46078d8a":"markdown","8e0ffb90":"markdown","c5fa4632":"markdown","f8b3ff31":"markdown","de6f25e8":"markdown","f8a0a2d2":"markdown","b087fc6f":"markdown","81475416":"markdown","b0bba76a":"markdown","7a14b359":"markdown","b2f32385":"markdown","c958447a":"markdown","1aa948a0":"markdown"},"source":{"3b383b1a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\n#For date Datatype\nimport datetime\n#Decision tree\nfrom sklearn.tree import DecisionTreeRegressor\n#Evaluation Metric\nfrom sklearn.metrics import mean_squared_log_error\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.compose import ColumnTransformer","c9911149":"# Reading in the data\nTRAIN_DATA=\"..\/input\/cais-x-t1-2021\/train.csv\"\nTEST_DATA=\"..\/input\/cais-x-t1-2021\/test.csv\"\n\n#Creating DataFrame\ndf=pd.read_csv(TRAIN_DATA)\ntest_df=pd.read_csv(TEST_DATA)","9fee1d8a":"#This shows how many rows and columns are in the dataset\n#In other words, the data has 2460 records split across 12 columns\ndf.shape","5c169ef0":"#This shows the columns we are working with and the first few rows of the \n#dataset\ndf.head()","6004039a":"df.tail()","b8c65882":"#Here is another way of doing the above\n#This shows the data types of each column as well\ndf.dtypes","7aa45c7d":"#change date_report column from object data types to date datatypes \ndf['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')\ntest_df['Date'] = pd.to_datetime(df['Date'], format='%Y-%m-%d')","b3c59c36":"#Notice the change in type of date_report\ndf.dtypes","cd89bf1a":"#Let's take a look at cases by visualizing the data\n#create the graph and make it size 15 x 7\nfig, ax = plt.subplots(figsize=(15,7))\n# First grouping based on the Date \n# For each Date we further group based on the Province\n# With this grouped information, we'll find the Number of Confirmed Cases for that particular grouping \ndf.groupby(['Date','Province']).mean()['# Confirmed_Cases'].unstack().plot(ax=ax)\n#set x-axis label\nax.set_xlabel('Date')\n#set y-axis label\nax.set_ylabel('Number of Cases')","8a34a7c9":"fig, ax = plt.subplots(figsize=(15,7))\n# First grouping based on the Date \n# For each Date we further group based on the Province\n# With this grouped information, we'll find the Number of Deaths for that particular grouping \ndf.groupby(['Date','Province']).mean()['# Deaths'].unstack().plot(ax=ax)\n#set x-axis label\nax.set_xlabel('Date')\n#set y-axis label\nax.set_ylabel('Number of Deaths')","ebe4be94":"#To make the data a little smoother, lets visualize the data by weekly periods \nfig, ax = plt.subplots(figsize=(15,7))\ndf.groupby(['Date','Province']).mean()['# Confirmed_Cases'].unstack().rolling(7).mean().plot(ax=ax)\nax.set_xlabel('Date')\nax.set_ylabel('Number of Cases(weekly)')","69a85e52":"fig, ax = plt.subplots(figsize=(15,7))\ndf.groupby(['Date','Province']).mean()['# Deaths'].unstack().rolling(7).mean().plot(ax=ax)\nax.set_xlabel('Date')\nax.set_ylabel('Number of Deaths(Weekly)')","a1ad5526":"df.head()","b1bbd2b3":"#Replace all null(NaN) values with 0\ndf=df.fillna(0)\ntest_df = test_df.fillna(0)\ndf.head()","e150351a":"#Make new column called 'Day' out of the translation between the date and day of year\ndf['Day'] = df['Date'].apply(lambda x: x.dayofyear)\ntest_df['Day'] = df['Date'].apply(lambda x: x.dayofyear)\ndf['Day']","3dbb6443":"#Change validation size later\nsplit_date = datetime.datetime(year = 2020, month = 3, day = 19)\nprint(split_date)","0a149e91":"# Hold every date that is before March 19th (20% of the data set)\nsplit = df['Date'] < split_date\n#Have the validation set be every date before March 19th\nvalidation_set = df[split]\n#Have the trainign set be every date from March 19th onwards(80%)\ntrain_set = df[~split]","30399b91":"validation_set.tail()","ca261ef8":"train_set.tail()","3a255c25":"df.dtypes","6ec3a335":"#Choose the columns of data that we want to train our model with\ntrainable_col = ['Day', 'Population', '# Tested', 'Long','Lat']\n#Choose the columns for which we want to predict \ntarget_col = ['# Deaths','# Confirmed_Cases', '# Recovered']\n\n#Create the model\nmodel = DecisionTreeRegressor()\n#Fit the training model with the training set\nmodel = model.fit(train_set[trainable_col], train_set[target_col])","f6abb936":"#Make predictions using with the validation set trained model\nvalidation_prediction = model.predict(validation_set[trainable_col])\ntrain_prediction = model.predict(train_set[trainable_col])\n#Make predictions on the test data\ntest_prediction = model.predict(test_df[trainable_col])\n\n#Should be 0\nprint(mean_squared_log_error(train_prediction, train_set[target_col]))\n#Print the Accuracy of predictions \nmean_squared_log_error(validation_prediction, validation_set[target_col])","7740978c":"#This will be used to force the order of the columns\ncolumn_names = ['ForcastId','# Deaths','# Confirmed_Cases', '# Recovered']\n\nsub_df = test_df\nsub_df[['# Deaths','# Confirmed_Cases', '# Recovered']] = test_prediction\nsub_df = sub_df[['# Deaths','# Confirmed_Cases', '# Recovered']]\n#Make the index column called 'ForcastId'\nsub_df['ForcastId'] = sub_df.index\nsub_df = sub_df[column_names]","6685407e":"sub_df","dbce120c":"#Turn the dataframe into a csv file that contains the predictions \nsub_df.to_csv(\"predictions.csv\",index=False)","46078d8a":"The model learns to map data to outputs in what is called the training phase of model building. It takes in the data that we want it to utilize in the prediction process(these are called the \"training columns\"), along with the  values that we want it to predict(this is called the \"target columns\")","8e0ffb90":"One thing to make note of is that currently Date is of type object, so the dates are basically read as strings. We don't want this because it will be read in numerical order, and sometimes that can get a little messy when it is a date type. We want something that will be a little more reliable when for when we are training our model. \\\n\\\nLuckily in python there is a handy module called datetime that is able to turn regular objects into date objects. ","c5fa4632":"## Preprocessing \n\nData preprocessing is an integral step in Machine Learning because the quality of data and the useful information that can be derived from it directly affects the ability of our model to learn.\n\\\nThough today we're only going to do some basic preprocessing such as handling null values and creating training and validation sets, some other  forms of preproccessing include:\n* Standardization\n* One-Hot Encoding\n* Identify outliers\n\n### Handling Null Values\nAs we saw earlier, the beginning of the data set has many null characters. It's important to assess if these null values have any  significant value or not, as there are many different ways in which you can deal with them. ","f8b3ff31":"## Visualizing the Data\nAn important part of creating a model is being able to understand the information that you're working with. One of the best ways to do this is by looking at and understanding the data you've been given. ","de6f25e8":"Now that we've accounted for the null values, something you may have noticed is that the date attribute is very different than the rest of the other data. An easier and more straightforward approach would be to use the day of year that a specific date is rather than the date itself. We're able to do this since the data is all within the same year.  ","f8a0a2d2":"## Reading in the Data \nNow that we've imported all the necessary libraries, we want to take all the data we are given by the competition, and read that in and create a Dataframe for it. \\\nBy creating a DataFrame, it provides various functionalities to analyze, change, and extract valuable information from the given dataset. ","b087fc6f":"# Building a Basic Model For Predicting COVID-19 Cases\n### Now that we've covered the different aspects of a Kaggle competition we'll work on building a base model for predicting Covid-19 Cases in Canada, and how to submit these predictions.\nThere are many ways in which you can approach this problem, but this is mainly just to get you started. \n## Importing Data and Libraries\nWhen creating any model, you need to import all the important libraries such as numpy and pandas as well as any others you might need.","81475416":"### Splitting the Data: Generalization and Overfitting\n\nGeneralization is a term used to describe a model\u2019s ability to react to new data. That is, after being trained on a training set, a model can digest new data and make accurate predictions. A model\u2019s ability to generalize is central to the success of a model. If you train a model too well on your training dataset, that's called \"overfitting\". When you overfit your model, though it will be able to accurately predict the training data, it will be unable to give accurate predictions when shown new data.\n\n![image.png](attachment:image.png)\n\n\nA good way to avoid overfitting your data is to split your training data into two subsets- a training set and a validation set.  \n\n**Training Dataset:**\nThe sample of data used to fit the model.\n\n**Validation Dataset:**\nA sample of the data that is unbiased and used while training your model. \n\n\n**Test Dataset:**\nThis is the final test, and it is to evaluate the performance of your model once it has been trained","b0bba76a":"## Create the predictions.csv to Submit ","7a14b359":"![image.png](attachment:image.png)","b2f32385":"## Implementing Model\nThere are many different types of Machine Learning Models that exist, but the one that we will specifically be focused on today is called the Decision Tree Regressor.\n\\\n\\\nA decision tree works by arriving at an estimate through making a series of True\/False \"decisions\" to narrow down our possible values until the model gets confident enough to make a single prediction. ","c958447a":"![image.png](attachment:image.png)","1aa948a0":"![image.png](attachment:image.png)"}}