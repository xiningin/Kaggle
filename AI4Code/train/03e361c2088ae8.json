{"cell_type":{"39d5bec6":"code","7011acf8":"code","9164c493":"code","9ebec89e":"code","624eb976":"code","1a3805da":"code","8a94259f":"code","fe68af4c":"code","dfe2c76b":"code","15c4e144":"code","d2a28c4a":"code","90dcda88":"code","92c33d8b":"code","54e77dbd":"code","d338702d":"code","19eb507c":"code","2106436b":"code","430a49df":"code","ff6386ac":"code","fa3ae0b8":"code","2fb43862":"code","5a90f6d3":"code","9dc7c206":"code","4fe3d32c":"code","418adf15":"code","618ffc34":"code","92875538":"code","54964711":"code","5d1c958c":"code","d7048d6f":"code","c3c33723":"code","3b168677":"code","a734c272":"code","b35c21b3":"code","ba480adb":"code","de3ed6a6":"code","9a75c2ae":"code","fe9dc243":"code","feac34f0":"code","5a7985fa":"code","e2c81224":"code","c9355d12":"code","03951612":"code","02235b04":"code","817d744d":"code","da00be68":"code","4863722b":"code","6a67ec31":"code","01a7eda4":"code","21cfa778":"code","6f45f4c3":"code","51fb3b8a":"code","52da5adf":"code","c6b5b037":"code","bbd4e70c":"code","bdaafe1e":"code","850e0e95":"code","6bb7adaf":"code","772adb49":"code","e5d86080":"code","0540dccc":"code","d7e2a830":"code","04192268":"code","5e44fcaf":"code","a3ce128a":"code","1d9faf49":"code","1a9e8990":"code","a6892483":"code","bc5e9fe7":"code","fbaa07fd":"code","92883b11":"code","fe0ac852":"code","c21cb95a":"code","c584861c":"code","2a51e28d":"code","b8e41ce1":"code","c19726ff":"markdown","e1a9d5cb":"markdown","31cb5abd":"markdown","84d36146":"markdown","2c2232d2":"markdown","0f59cd78":"markdown","a5b5a498":"markdown","4f62c8d5":"markdown","ff98d067":"markdown","cfc06196":"markdown","03abd16c":"markdown","807355c9":"markdown","3642a8bc":"markdown","0f4e38f3":"markdown","a6a0d3f6":"markdown","e23ec59d":"markdown","e9ad1e0d":"markdown","ecdd94d2":"markdown"},"source":{"39d5bec6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns","7011acf8":"train_df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/train.csv\")","9164c493":"test_df = pd.read_csv(\"..\/input\/house-prices-advanced-regression-techniques\/test.csv\")","9ebec89e":"train_df.head()","624eb976":"train_df.drop('Id', axis=1, inplace=True)  # not needed","1a3805da":"percent_missing = train_df.isnull().sum() * 100 \/ len(train_df)\nmissing_value_df = pd.DataFrame({'column_name': train_df.columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df = missing_value_df[missing_value_df.percent_missing > 0]","8a94259f":"plt.figure(figsize=(15, 10))\nplt.barh(missing_value_df['column_name'], missing_value_df['percent_missing'], color='darkblue',)\nplt.title(\"The Percentages Of The Columns Null Values\", fontsize=15 )\nplt.show()","fe68af4c":"# check duplicates\ntrain_df.duplicated().sum()","dfe2c76b":"train_df.drop(['Fence', 'MiscFeature', 'PoolQC', 'FireplaceQu', 'Alley'], axis=1, inplace=True)\ntrain_df.shape","15c4e144":"percent_missing = train_df.isnull().sum() * 100 \/ len(train_df)\nmissing_value_df = pd.DataFrame({'column_name': train_df.columns,\n                                 'percent_missing': percent_missing})\nmissing_value_df = missing_value_df[missing_value_df.percent_missing > 0]","d2a28c4a":"# LotFrontage (Linear feet of street connected to property)\nplt.figure(figsize=(10, 8))\ntrain_df.boxplot([\"LotFrontage\", \"MasVnrArea\", \"GarageYrBlt\"])\nplt.title(\"The Box Plot For the Floating Null Columns\", fontsize=15)\nplt.show()","90dcda88":"train_df[missing_value_df.column_name.values].describe()","92c33d8b":"# fill MasVnrArea\ntrain_df.MasVnrArea.fillna(method='ffill', inplace=True)  # propagate last valid observation forward to next valid\ntrain_df.MasVnrArea.fillna(method='bfill', inplace=True) # use next valid observation to fill gap","54e77dbd":"# fill LotFrontage, GarageYrBlt by median\ntrain_df.LotFrontage.fillna(train_df.LotFrontage.median(), inplace=True)\ntrain_df.GarageYrBlt.fillna(train_df.GarageYrBlt.median(), inplace=True)","d338702d":"round(train_df[missing_value_df.column_name.values].isnull().sum() \/ len(train_df), 3)","19eb507c":"train_df.fillna(method='ffill', inplace=True)  # propagate last valid observation forward to next valid\ntrain_df.fillna(method='bfill', inplace=True) # use next valid observation to fill gap","2106436b":"# give a quick EDA about the Data\ndef plot_value_counts(columns, df):\n    for column in columns:\n\n        if len(df[column].value_counts()) >= 6 and len(df[column].value_counts()) <= 15 :  # the bar chart is sutable\n            plt.figure(figsize = (10,8))\n            df[column].value_counts().plot(kind='barh' ,fontsize=12, color='gold')\n            plt.title(f\"The Frequency of the {column} column\",fontsize=15)\n            plt.show()\n            \n        elif len(df[column].value_counts()) < 6:  # pie chart\n            plt.figure(figsize = (10,8))\n            df[column].value_counts().plot(kind='pie', autopct= '%1.1f%%',fontsize=12)\n            plt.title(f\"The ratio between vlaues for the {column} column\",fontsize=15)\n            plt.ylabel(\"\")\n            plt.show()","430a49df":"# plot_value_counts(train_df.columns, train_df)","ff6386ac":"year_df = train_df.sort_values(by='YrSold')","fa3ae0b8":"plt.figure(figsize=(15, 8))\nplt.title(\"The Sales Time Line According To Year\", fontsize=20)\nsns.lineplot(data=year_df, x='YrSold', y='SalePrice', ci=0)\nplt.xlabel(\"The Year\")\nplt.show()","2fb43862":"plt.figure(figsize=(15, 8))\nplt.title(\"The Sales Time Line According To Month\", fontsize=20)\nsns.lineplot(data=year_df, x='MoSold', y='SalePrice', ci=0)\nplt.xlabel(\"The Month\")\nplt.show()","5a90f6d3":"from sklearn.preprocessing import LabelEncoder","9dc7c206":"# label encoding\nfor column in train_df.columns:\n    if train_df[column].dtype == 'O':  # if it's not Object dtype\n        le = LabelEncoder() \n        train_df[column] = le.fit_transform(train_df[column])","4fe3d32c":"# scale_columns = []\n\n# for column in train_df.columns:\n#     if train_df[column].dtype != 'O':  # if it's not Object dtype\n#         scale_columns.append(column)\n#     else:\n#         try:\n#             le = LabelEncoder()  # label encoding\n#             train_df[column] = le.fit_transform(train_df[column])\n#         except:\n#             continue","418adf15":"# # Normalize The Data (put them in the same scale)\n# def normalize(columns, df):\n#     for column in columns:\n#         df[column] = (df[column] - df[column].min()) \/ (df[column].max() - df[column].min())","618ffc34":"from sklearn.preprocessing import MinMaxScaler\n\ncol = train_df.columns \nscaler = MinMaxScaler()\n\nscaled_train = scaler.fit_transform(train_df[col])\n\nscaled_train = pd.DataFrame(scaled_train,columns=col)\nscaled_train[\"SalePrice\"] = train_df[\"SalePrice\"]","92875538":"from sklearn.model_selection import train_test_split","54964711":"X = train_df.drop(\"SalePrice\", axis=1).values\ny = train_df.SalePrice.values","5d1c958c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","d7048d6f":"from xgboost import XGBRegressor\nfrom sklearn.metrics import mean_squared_error","c3c33723":"model = XGBRegressor(objective = \"reg:linear\", max_deepth=15, seed=100,n_estimators=100, bosster = \"gblinear\")","3b168677":"model.fit(X_train, y_train)","a734c272":"model.score(X_test, y_test)","b35c21b3":"predY = model.predict(X_test)","ba480adb":"# RMSE\nnp.sqrt(mean_squared_error(y_test, predY))","de3ed6a6":"X = scaled_train.drop(\"SalePrice\", axis=1).values\ny = scaled_train.SalePrice.values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","9a75c2ae":"model = XGBRegressor(objective = \"reg:linear\", max_deepth=15, seed=100,n_estimators=100, bosster = \"gblinear\")\nmodel.fit(X_train, y_train)","fe9dc243":"model.score(X_test, y_test)","feac34f0":"from sklearn.linear_model import Lasso","5a7985fa":"names = train_df.drop('SalePrice', axis=1).columns\nlasso = Lasso(alpha=0.1)\nlasso_coef = lasso.fit(X, y).coef_","e2c81224":"top_coef = lasso_coef[np.where(np.logical_or(lasso_coef > 3000, lasso_coef < -3000))]\ntop_names = names[np.where(np.logical_or(lasso_coef > 3000, lasso_coef < -3000))]","c9355d12":"top_names","03951612":"plt.figure(figsize=(15, 8))\nplt.plot(top_names, top_coef)\nplt.xticks(range(len(top_names)), top_names, rotation=60)\nplt.title(\"Top Coefficients\", fontsize=15)\nplt.ylabel('Coefficients')\nplt.show()","02235b04":"X_top = train_df[top_names]\ny_top = train_df.SalePrice.values","817d744d":"X_train, X_test, y_train, y_test = train_test_split(X_top, y_top, test_size=.2, random_state=42)","da00be68":"lasso_model = XGBRegressor(objective = \"reg:linear\", max_deepth=15, seed=100,n_estimators=100, bosster = \"gblinear\")","4863722b":"lasso_model.fit(X_train, y_train)","6a67ec31":"lasso_model.score(X_test, y_test)","01a7eda4":"predY = lasso_model.predict(X_test)","21cfa778":"# RMSE\nnp.sqrt(mean_squared_error(y_test, predY))","6f45f4c3":"from sklearn.linear_model import LinearRegression","51fb3b8a":"X = train_df.drop(\"SalePrice\", axis=1).values\ny = train_df.SalePrice.values","52da5adf":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=.2, random_state=42)","c6b5b037":"model = LinearRegression()","bbd4e70c":"model.fit(X_train, y_train)","bdaafe1e":"model.score(X_test, y_test)","850e0e95":"from sklearn.model_selection import cross_val_score","6bb7adaf":"model = XGBRegressor()","772adb49":"cross_score = cross_val_score(model, X, y, cv=5)","e5d86080":"cross_score","0540dccc":"lasso_model = XGBRegressor(objective = \"reg:linear\", max_deepth=15, seed=100,n_estimators=100, bosster = \"gblinear\")","d7e2a830":"lasso_model.fit(X_top, y_top)","04192268":"test_df.head()","5e44fcaf":"test_df.drop(['Fence', 'MiscFeature', 'PoolQC', 'FireplaceQu', 'Alley'], axis=1, inplace=True)\ntest_df.shape","a3ce128a":"# fill MasVnrArea\ntest_df.MasVnrArea.fillna(method='ffill', inplace=True)  # propagate last valid observation forward to next valid\ntest_df.MasVnrArea.fillna(method='bfill', inplace=True) # use next valid observation to fill gap","1d9faf49":"# fill LotFrontage, GarageYrBlt by median\ntest_df.LotFrontage.fillna(test_df.LotFrontage.median(), inplace=True)\ntest_df.GarageYrBlt.fillna(test_df.GarageYrBlt.median(), inplace=True)","1a9e8990":"test_df.fillna(method='ffill', inplace=True)  # propagate last valid observation forward to next valid\ntest_df.fillna(method='bfill', inplace=True) # use next valid observation to fill gap","a6892483":"# scale_columns = []\n\n# for column in test_df.columns:\n#     if column == 'Id':\n#         continue\n#     if test_df[column].dtype != 'O':  # if it's not Object dtype\n#         scale_columns.append(column)\n#     else:\n#         try:\n#             le = LabelEncoder()  # label encoding\n#             test_df[column] = le.fit_transform(test_df[column])\n#         except:\n#             continue\n            ","bc5e9fe7":"# normalize(scale_columns, test_df)","fbaa07fd":"for column in test_df.columns:\n    if column == 'Id':\n        continue\n    if test_df[column].dtype == 'O':  # if it's not Object dtype\n        le = LabelEncoder()  # label encoding\n        test_df[column] = le.fit_transform(test_df[column])","92883b11":"X = test_df[top_names]","fe0ac852":"predY = lasso_model.predict(X)","c21cb95a":"Id = test_df.Id.values","c584861c":"sub_df = pd.DataFrame({\"Id\" : Id, \"SalePrice\" : predY})","2a51e28d":"sub_df.head()","b8e41ce1":"sub_df.to_csv('submission.csv', index=False)\nprint(\"submission successed\")","c19726ff":"> # EDA (Let's Explore It)","e1a9d5cb":"> __So The Best Accuracy We Can Get is by using Lasso Model__","31cb5abd":"__Lasso Feature Selection__","84d36146":"> The Re-main null columns are in dtype object and it's a little values","2c2232d2":"> # ML: Gonna Predict The Sales","0f59cd78":"__XGBRegressor On The Not Scaled Data__","a5b5a498":"__Linear Regression__","4f62c8d5":"> # Data Cleaning (All next Phases depends on this)","ff98d067":"__Start Modeling__","cfc06196":"> The Data Needed to be `Re-Scaled`","03abd16c":"**Drop The Columns which null percentages >= 50**","807355c9":"> __Read The Data__","3642a8bc":"__XGBRegressor On The `Scaled` Data__","0f4e38f3":"__cross_val_score__","a6a0d3f6":"> As we can see: \n1. the `MasVnrArea` column has high variance and 50% of the data is equal to 0\n2. the `LotFrontage` and `GarageYrBlt` columns has low std","e23ec59d":"> # Prediction","e9ad1e0d":"> __Visualize the null value__","ecdd94d2":"> __The Numerical Columns needed to be `Re-Scaled`__\\\n__The Object dtype Columns needed to be `encoded`__"}}