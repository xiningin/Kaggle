{"cell_type":{"d6ac88e7":"code","011346c2":"code","7e25e6a3":"code","e0fafb68":"code","7aa30791":"code","d5a0a743":"code","cd3bcb6d":"code","3447caef":"code","8283410a":"code","8bf519a5":"code","8bf2e0b2":"code","aef3e7a9":"code","f8edfaee":"code","263c739f":"code","f906554c":"code","416b10ac":"code","f9ceb636":"code","20441d72":"code","61520bb0":"code","385146d9":"code","38baede5":"code","539a0de1":"code","34ed937e":"code","ae9dd5a3":"code","712b7b42":"code","81a901ae":"code","46217054":"code","ce40a04f":"code","962a6c85":"code","b337fa60":"markdown","de7f33b0":"markdown","673fa684":"markdown","8a4e4e69":"markdown","f9f6f081":"markdown","0c0dd30a":"markdown","9c377fe6":"markdown","1bcf2489":"markdown","6f599b6d":"markdown","1e554561":"markdown","0cd03090":"markdown","eca9ed19":"markdown"},"source":{"d6ac88e7":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.optim import lr_scheduler\nimport torchvision.models as models\nfrom torchvision import transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nfrom PIL import Image\nfrom tqdm import tqdm_notebook as tqdm\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler \nfrom collections import Counter\nimport ast\nimport os \n\n%matplotlib inline\n\nimport pdb","011346c2":"torch.__version__","7e25e6a3":"torch.cuda.is_available()","e0fafb68":"!ls -c ..\/input\/tmdb-box-office-prediction-posters\/tmdb_box_office_prediction_posters\/tmdb_box_office_prediction_posters","7aa30791":"folder_posters = '..\/input\/tmdb-box-office-prediction-posters\/tmdb_box_office_prediction_posters\/tmdb_box_office_prediction_posters'","d5a0a743":"!ls -c ..\/input\/tmdb-box-office-prediction","cd3bcb6d":"folder_csv = '..\/input\/tmdb-box-office-prediction'","3447caef":"# coming from an other kernel \n# will add the reference later\ndef clean(df):\n    \n    # Runtime na\n    df.loc[df.id == 1335, 'runtime'] = 119\n    df.loc[df.id == 1336, 'runtime'] = 130\n    df.loc[df.id == 2302, 'runtime'] = 100\n    df.loc[df.id == 2303, 'runtime'] = 81\n    \n    # Runtime 0\n    df.loc[df.id == 391, 'runtime'] = 86\n    df.loc[df.id == 592, 'runtime'] = 90\n    df.loc[df.id == 925, 'runtime'] = 86\n    df.loc[df.id == 978, 'runtime'] = 93\n    df.loc[df.id == 1256, 'runtime'] = 92\n    df.loc[df.id == 1542, 'runtime'] = 93\n    df.loc[df.id == 1875, 'runtime'] = 86\n    df.loc[df.id == 2151, 'runtime'] = 108\n    df.loc[df.id == 2499, 'runtime'] = 86\n    df.loc[df.id == 2646, 'runtime'] = 98\n    df.loc[df.id == 2786, 'runtime'] = 111\n    df.loc[df.id == 2866, 'runtime'] = 96\n    \n    df.loc[df.id == 3829, 'release_date'] = '6\/1\/00'\n    df.loc[df['id'] == 16,'revenue'] = 192864          # Skinning\n    df.loc[df['id'] == 90,'budget'] = 30000000         # Sommersby          \n    df.loc[df['id'] == 118,'budget'] = 60000000        # Wild Hogs\n    df.loc[df['id'] == 149,'budget'] = 18000000        # Beethoven\n    df.loc[df['id'] == 313,'revenue'] = 12000000       # The Cookout \n    df.loc[df['id'] == 451,'revenue'] = 12000000       # Chasing Liberty\n    df.loc[df['id'] == 464,'budget'] = 20000000        # Parenthood\n    df.loc[df['id'] == 470,'budget'] = 13000000        # The Karate Kid, Part II\n    df.loc[df['id'] == 513,'budget'] = 930000          # From Prada to Nada\n    df.loc[df['id'] == 797,'budget'] = 8000000         # Welcome to Dongmakgol\n    df.loc[df['id'] == 819,'budget'] = 90000000        # Alvin and the Chipmunks: The Road Chip\n    df.loc[df['id'] == 850,'budget'] = 90000000        # Modern Times\n    df.loc[df['id'] == 1112,'budget'] = 7500000        # An Officer and a Gentleman\n    df.loc[df['id'] == 1131,'budget'] = 4300000        # Smokey and the Bandit   \n    df.loc[df['id'] == 1359,'budget'] = 10000000       # Stir Crazy \n    df.loc[df['id'] == 1542,'budget'] = 1              # All at Once\n    df.loc[df['id'] == 1542,'budget'] = 15800000       # Crocodile Dundee II\n    df.loc[df['id'] == 1571,'budget'] = 4000000        # Lady and the Tramp\n    df.loc[df['id'] == 1714,'budget'] = 46000000       # The Recruit\n    df.loc[df['id'] == 1721,'budget'] = 17500000       # Cocoon\n    df.loc[df['id'] == 1865,'revenue'] = 25000000      # Scooby-Doo 2: Monsters Unleashed\n    df.loc[df['id'] == 2268,'budget'] = 17500000       # Madea Goes to Jail budget\n    df.loc[df['id'] == 2491,'revenue'] = 6800000       # Never Talk to Strangers\n    df.loc[df['id'] == 2602,'budget'] = 31000000       # Mr. Holland's Opus\n    df.loc[df['id'] == 2612,'budget'] = 15000000       # Field of Dreams\n    df.loc[df['id'] == 2696,'budget'] = 10000000       # Nurse 3-D\n    df.loc[df['id'] == 2801,'budget'] = 10000000       # Fracture\n    df.loc[df['id'] == 3889,'budget'] = 15000000       # Colossal\n    df.loc[df['id'] == 6733,'budget'] = 5000000        # The Big Sick\n    df.loc[df['id'] == 3197,'budget'] = 8000000        # High-Rise\n    df.loc[df['id'] == 6683,'budget'] = 50000000       # The Pink Panther 2\n    df.loc[df['id'] == 5704,'budget'] = 4300000        # French Connection II\n    df.loc[df['id'] == 6109,'budget'] = 281756         # Dogtooth\n    df.loc[df['id'] == 7242,'budget'] = 10000000       # Addams Family Values\n    df.loc[df['id'] == 7021,'budget'] = 17540562       #  Two Is a Family\n    df.loc[df['id'] == 5591,'budget'] = 4000000        # The Orphanage\n    df.loc[df['id'] == 4282,'budget'] = 20000000       # Big Top Pee-wee\n\n    if 'revenue' in df.columns.values:\n        power_six = df.id[df.budget > 1000][df.revenue < 100]\n\n        for k in power_six :\n            df.loc[df['id'] == k,'revenue'] =  df.loc[df['id'] == k,'revenue'] * 1000000\n            \n    return df","8283410a":"def get_features_data(df):\n    # work on a copy \n    df = df.copy()\n    \n    # transform json\n    jsons = [\n        'crew', \n        'cast', \n        'Keywords',  \n        'genres', \n        'belongs_to_collection', \n        'production_companies', \n        'production_countries', \n        'spoken_languages'\n    ]\n    for j in jsons: \n        df[j] = df[j].apply(lambda x: {} if pd.isna(x) else ast.literal_eval(x))\n        \n    # release date year \n    release_date = pd.to_datetime(df.release_date, format='%m\/%d\/%y')\n    df['release_date_year'] = release_date.dt.year.apply(lambda x: x-100 if x>2018 else x)\n    df['release_date_month'] = release_date.dt.month\n    df['release_date_day'] = release_date.dt.day\n    df['release_date_quarter'] = release_date.dt.quarter\n    df['release_date_weekday'] = release_date.dt.weekday\n    df['release_date_weekofyear'] = release_date.dt.weekofyear\n    \n    # genres \n    df.genres = df.genres.apply(lambda x: [item['name'] for item in x])\n    df['num_genres'] = df.genres.apply(lambda x: len(x))\n    df.num_genres = df.num_genres.astype('float64')\n    \n    # one hot genre \n    genres = ['Drama', 'Comedy', 'Thriller', 'Action', 'Romance', 'Crime', \n              'Adventure', 'Horror', 'Science Fiction', 'Family', \n              'Fantasy', 'Mystery', 'Animation', 'History', 'Music', 'War', \n              'Documentary', 'Western', 'Foreign']\n    \n    genres_one_hot = np.zeros((len(df.genres),len(genres)))\n    for i in range(len(df)):\n        for j, genre in enumerate(genres):\n            row = df.iloc[i]\n            if genre in row['genres']:\n                genres_one_hot[i,j] = 1 \n                \n    # cast\n    cast = df.cast.apply( lambda x: ','.join([c['name'] for c in x] ))\n    df['size_of_cast'] = cast.apply(lambda x: len(x.split(',')))\n    \n    # crew\n    df['size_of_crew'] =  df['crew'].apply(lambda x: len(x))\n    \n    df['total_crew'] = df['size_of_crew'] + df['size_of_cast']\n                \n    # budget\n    df['log_budget'] = np.log1p(df.budget)\n    df['budget_by_runtime'] = df['budget']\/df['runtime']\n    df['budget_by_popularity'] = df['budget']\/df['popularity']\n    df['release_year_by_popularity'] = df['release_date_year']\/df['popularity']\n    df['popularity_by_release_year'] = df['popularity']\/df['release_date_year']\n\n    # scaled data \n    cols_to_scale = [\n        'release_date_year',\n        'release_date_month',\n        'release_date_day',\n        'release_date_quarter',\n        'release_date_weekday',\n        'release_date_weekofyear',\n        'popularity',\n        'budget', \n        'budget_by_runtime',\n        'budget_by_popularity',\n        'runtime', \n        'num_genres',\n        'log_budget', \n        'release_year_by_popularity', \n        'popularity_by_release_year',\n        'size_of_cast',\n        'size_of_crew'\n    ]\n    # make sure it is float before \n    for col in cols_to_scale:\n         df[col].astype('float64')\n            \n    scaler = StandardScaler()\n    data = scaler.fit_transform(df[cols_to_scale])\n    \n    # add other columns not to be scaled \n    data = np.concatenate([data,genres_one_hot], axis=1)\n    \n    return data, scaler ","8bf519a5":"df = pd.read_csv(f\"{os.path.join(folder_csv, 'train.csv')}\")","8bf2e0b2":"df = clean(df)\ntest, scaler = get_features_data(df)","aef3e7a9":"torch.from_numpy(test[0]).float().cuda()","f8edfaee":"df.columns.values","263c739f":"sample_img_path  = os.path.join(os.path.join(folder_posters, 'train'), f\"{df.iloc[10].id}.jpeg\")\nplt.figure(figsize=(5,5))\nplt.imshow(Image.open(sample_img_path))\nplt.axis('off')\nplt.show()","f906554c":"class MovieDataset(Dataset):\n    def __init__(self, csv_file, img_folder, transform=None, idx=None):\n        self.csv_file = csv_file\n        self.img_folder = img_folder \n        self.transform = transform\n        self.df = clean(pd.read_csv(csv_file))\n        # missing poster, will drop data for now \n        self.df.drop(self.df[self.df.id == 2303].index, inplace=True)\n        \n        # create features from dataframe \n        self.data, self.scaler = get_features_data(self.df)\n        self.fs = self.data.shape[1]\n        \n        if idx is not None:\n            self.df = self.df.iloc[idx]\n            \n        self.cols = self.df.columns.values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, idx): \n        features = torch.from_numpy(self.data[idx,:]).float()\n        img_path = os.path.join(self.img_folder, f\"{self.df.iloc[idx].id}.jpeg\")\n        target = None\n        if 'revenue' in self.cols:\n            target = np.log1p(self.df.iloc[idx].revenue)\n        image = Image.open(img_path)   \n        if self.transform:\n            image = self.transform(image)\n        return {'images': image, 'features': features, 'targets': target}","416b10ac":"def get_dataset(idx=None):\n    data_transform = transforms.Compose([\n        transforms.Resize((224,224)),\n        transforms.ToTensor(),\n        transforms.Normalize(mean=[0.485, .456, 0.406], # imagenet normalization\n                             std=[0.229, 0.224, 0.225])\n    ])\n    dataset = MovieDataset(csv_file=f\"{os.path.join(folder_csv, 'train.csv')}\", \n                           img_folder=f\"{os.path.join(folder_posters, 'train')}\", \n                           transform=data_transform, \n                           idx=idx)\n    return dataset","f9ceb636":"idx = [i for i in range(len(df)-1)]\nidx = np.random.permutation(idx)\ntrain_idx = idx[:round(0.9*(len(idx)))]\nvalid_idx = idx[round(0.9*(len(idx))):]\nlen(valid_idx) \/ (len(valid_idx) + len(train_idx))","20441d72":"train_dataset = get_dataset(idx=train_idx)\nvalid_dataset = get_dataset(idx=valid_idx)\nlen(valid_dataset) \/ (len(train_dataset) + len(valid_dataset))","61520bb0":"train_dataset.fs","385146d9":"dataloader = DataLoader(get_dataset(), batch_size=4, shuffle=True, num_workers=4)","38baede5":"for _, sample_batch in enumerate(dataloader):\n    image = sample_batch['images']\n    revenue = sample_batch['targets']\n    batch_size = image.shape[0]\n    fig = plt.figure(figsize=(20,20))\n    for i in range(batch_size):\n        ax = plt.subplot(1, batch_size, i + 1)\n        plt.tight_layout()\n        data = image[i].cpu().numpy().transpose((1, 2, 0))\n        plt.imshow(np.interp(data, (data.min(), data.max()), (0, 1)))\n        ax.axis('off')\n        ax.set_title(f\"Sample {i+1}, Revenue: {revenue[i]:.2f}\")\n    plt.show()\n    break","539a0de1":"class WithPosterEmbeddings(nn.Module):\n    \n    def __init__(self, features_size, dp=0.5):\n        super().__init__()\n        self.dp = dp\n        self.img_emb_size = 10 # change image embedding size \n        self.features_size = features_size\n        \n        self.resnet18 = models.resnet18(pretrained=True)\n        # freeze all layers\n        for param in self.resnet18.parameters():\n            param.requires_grad = False\n            \n        #bs, drp, linear, relu   \n        self.resnet18.fc = nn.Sequential(\n            nn.BatchNorm1d(512),\n            nn.Dropout(self.dp),\n            nn.Linear(512, 1000, bias=True),\n            nn.ReLU(),\n            nn.BatchNorm1d(1000),\n            nn.Dropout(self.dp),\n            nn.Linear(1000, self.img_emb_size, bias=True),\n            nn.ReLU(),\n            nn.Dropout(self.dp) # dropout on the poster embeddings\n        )\n        \n        self.l1 = nn.Sequential(\n            nn.BatchNorm1d(self.img_emb_size + self.features_size), \n            nn.Linear(self.img_emb_size + self.features_size,512), \n            nn.ReLU()\n        )\n        \n        self.l2 = nn.Sequential(\n            nn.BatchNorm1d(512),\n            nn.Dropout(self.dp),\n            nn.Linear(512,256),\n            nn.ReLU(),\n            nn.BatchNorm1d(256),\n            nn.Dropout(self.dp),\n            nn.Linear(256,1) \n        )\n        \n    \"\"\" imgs: posters\n        x: features\n    \"\"\"\n    def forward(self, imgs, features, skip_cnn=False):\n        x = self.resnet18(imgs)\n        if skip_cnn: \n            x = torch.zeros(imgs.size(0),self.img_emb_size).float().cuda()\n        x = torch.cat([x, features], dim=1)\n        x = self.l2(self.l1(x))\n        \n        return x","34ed937e":"fs = 36 # feature size\n\nepochs =  50\nwd = 0.001\nlr = 1e-3\ndropout=0.5\nbs = 8","ae9dd5a3":"def calculate_rmse(model, dataloader, monitor=False, skip_cnn=False):\n    criterion = nn.MSELoss()\n    model.eval()\n    losses = []\n    for sample_batch in tqdm(dataloader, disable=(not monitor)):\n        images = sample_batch['images'].cuda()\n        features = sample_batch['features'].cuda()\n        targets = sample_batch['targets'].float().cuda()\n        \n        preds = model(images, features, skip_cnn=skip_cnn)\n        loss = criterion(preds,targets)\n        \n        losses.append( loss.item() * len(sample_batch))\n        \n    # set the model to train mode\n    model.train()\n    return np.sqrt(np.mean(losses))","712b7b42":"# model & dataloader\nmodel = WithPosterEmbeddings(features_size = fs, dp=dropout).cuda()\ndataloader_train = DataLoader(get_dataset(idx=train_idx), batch_size=bs, shuffle=True, num_workers=4)\ndataloader_valid = DataLoader(get_dataset(idx=valid_idx), batch_size=bs, shuffle=True, num_workers=4)\n\ncriterion = nn.MSELoss()\nopt = optim.Adam(model.parameters(), lr=lr, weight_decay=wd)\nlr_sch = lr_scheduler.ReduceLROnPlateau(opt,'min', factor=0.1, patience=10, verbose=True) # learning rate scheduler \n\ni = 0\nrunning_losses = []\ntrain_losses = []\nvalid_losses = []\nfor epoch_i in range(epochs):\n    print(f\"Epoch {epoch_i+1}\/{epochs}\")\n    running_loss = 0\n    for sample_batch in tqdm(dataloader_train):\n        images = sample_batch['images'].cuda()\n        features = sample_batch['features'].cuda()\n        targets = sample_batch['targets'].float().cuda()\n        \n        preds = model(images, features)\n        loss = criterion(preds,targets.unsqueeze(1))\n        opt.zero_grad()\n        loss.backward()\n        opt.step()\n        \n        running_losses.append((i, loss.item() ))\n        i+=1\n        \n    print('Calculating validation loss..')\n    valid_losses.append((i, calculate_rmse(model, dataloader_valid)))\n    lr_sch.step(valid_losses[-1][1])\n    \n    print('Calculating train loss..')\n    train_losses.append((i, calculate_rmse(model, dataloader_train)))\n        \n    print(f\"Loss: {train_losses[-1][1]:.3f} (train) {valid_losses[-1][1]:.3f} (valid)\")","81a901ae":"def plot_rmse(train_losses, valid_losses):\n    plt.figure(figsize=(10,10))\n    plt.xlabel('Iteration #')\n    plt.ylabel('RMSE loss')\n    \n    it, loss = zip(*train_losses)\n    plt.plot(it, loss, marker='o')\n    \n    it, loss = zip(*valid_losses)\n    plt.plot(it, loss, marker='o')\n    \n    plt.show()","46217054":"plot_rmse(train_losses, valid_losses)","ce40a04f":"no_poster = calculate_rmse(model, dataloader_valid, skip_cnn=True)\nwith_poster = calculate_rmse(model, dataloader_valid, skip_cnn=False)","962a6c85":"print(f\"Loss: {with_poster:.3f} (poster) {no_poster:.3f} (no poster)\")","b337fa60":"## Data","de7f33b0":"## Model","673fa684":"```\nmodel = WithPosterEmbeddings(features_size = fs).cuda()\ndataloader_train = DataLoader(get_dataset(idx=train_idx), batch_size=bs, shuffle=True, num_workers=4)\ndataloader_iter = iter(dataloader_train)\nsample_batch = next(dataloader_iter)\nimages = sample_batch['images'].cuda()\nfeatures = sample_batch['features'].cuda()\ntargets = sample_batch['targets'].float().cuda()\n```","8a4e4e69":"To verify if the poster embeddings did learn some features, I will calculate the RMSE with & without the embeddings on the validation set. ","f9f6f081":"## Setup","0c0dd30a":"# TMDB with Posters Embeddings (CNN)\nUsing PyTorch 1.0.1.post2","9c377fe6":"Plot losses","1bcf2489":"* Loss: 2.939 (train) 4.986 (valid)","6f599b6d":"This kernel is more for fun than anything else. I am stuck at 1.98 RMSE & I don't want to scrape the internet for more features. \n\nAt this moment, it is a work in progress (an experiment). But, please, do follow along and if you have any idea on how it could be improved please leave a comment.\n\nI want to see if we can train a CNN to extract poster embeddings which could later be used as addtitionnal features in a gradient boosted tree. I created a dataset with all the posters of the training & test set (well I guess I did actually scrape the internet for more features hehe...)\n\nMy first try was to split the log of the revenue in ten different classes & train a CNN classifier. However, my results were not very satisfying with a final accuracy of about 20%.\n\nTherefore, I decided to combine some important features (determined by feature importance of a decision tree) with the output of a resnet18 (the poster embeddings).\n\nBelow, is the implementation in PyTorch. For now, I only consider the posters & the budget to predict the revenue. I will add more. ","1e554561":"So, for now, the embeddings are making things actually worst (yeah! :P)\n\nThings I want to try:\n- Data augmentation on the posters\n- Adding more features. For now I only have the budget. Add more, maybe it will help the cnn part to learn embeddings.\n- After a first training phase, freeze the features layers & train only the cnn part. ","0cd03090":"## Train","eca9ed19":"Print some images and associated revenue from the MovieDataset."}}