{"cell_type":{"27281be1":"code","4ec4727f":"code","d8b659af":"code","90bf68c5":"code","b905eb4a":"code","bab963c7":"code","afae7ff6":"markdown","6f910320":"markdown"},"source":{"27281be1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4ec4727f":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\n\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nsample_submission = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")\n\n# Check if there is any null value in Survived variable\nassert any(train_data['Survived'].isnull()) == False\n\n# Separate target data from features data\ny = train_data.Survived\nX = train_data.drop(['Survived'], axis=1)\n\n# Break off validation set from training data\nX_train_full, X_valid_full, y_train, y_valid = train_test_split(X, y, \n                                                                train_size=0.8, \n                                                                test_size=0.2, \n                                                                random_state=0)\n\ncategorical_columns = ['Sex', 'Embarked']\nnumerical_columns = ['Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n\n# Keep selected columns only\nmy_cols = numerical_columns + categorical_columns\nX_train = X_train_full[my_cols].copy()\nX_valid = X_valid_full[my_cols].copy()\nX_test = test_data[my_cols].copy()","d8b659af":"from sklearn.compose import ColumnTransformer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\n\n# Preprocessing for numerical data\nnumerical_transformer = SimpleImputer(strategy='median')\n\n# Preprocessing for categorical data\ncategorical_transformer = Pipeline(steps=[('imputer', SimpleImputer(strategy='most_frequent')),\n                                          ('onehot', OneHotEncoder(handle_unknown='ignore'))])\n\n# Bundle preprocessing for numerical and categorical data\npreprocessor = ColumnTransformer(transformers=[('cat', categorical_transformer, categorical_columns),\n                                              ('num', numerical_transformer, numerical_columns)])\n\n# Define model\nmodel = RandomForestClassifier(n_estimators=500, random_state=0, n_jobs=-1, max_depth=10)\n","90bf68c5":"# Bundle preprocessing and modeling code in a pipeline\nmy_pipeline = Pipeline(steps=[('preprocessor', preprocessor),\n                              ('model', model)])\n\n# Preprocessing of training data, fit model\nmy_pipeline.fit(X_train, y_train)\n\n# Preprocessing of validation data, get predictions\npreds = my_pipeline.predict(X_valid)\n\n# Evaluate the model\nacc = accuracy_score(y_valid, preds, normalize=False)\nprint(f\"Accuracy: {acc}\/{len(preds)} ({acc\/(len(preds))*100:.2f}%)\")","b905eb4a":"# Preprocessing of test data, get predictions\npreds_test = my_pipeline.predict(X_test)","bab963c7":"# Export predicted data to a CSV file\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId,\n                       'Survived': preds_test})\noutput.to_csv('submission.csv', index=False)","afae7ff6":"# Titanic competition","6f910320":"**Preprocessing**: Simple Imputer and One Hot Encoder   \n**Modeling**: Random Forest Classifier   \n**Orchestration**: Pipeline   "}}