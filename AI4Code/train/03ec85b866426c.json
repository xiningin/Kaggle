{"cell_type":{"d064bdf5":"code","63d8913a":"code","532dcf54":"code","282625b4":"code","d6430380":"code","e49dfb3f":"code","d85ade82":"code","c8339352":"code","dfcce028":"code","74542d89":"code","08cbf9fa":"code","b9629dfa":"code","46a9e5f8":"code","9990b325":"code","e69835fb":"code","597ed96c":"code","f58e29ec":"code","80877163":"code","17879da3":"code","04534a6f":"code","5fc07fff":"code","c49f6f03":"code","311d93c7":"code","4d67fe23":"code","68727e7c":"code","04fdf5bb":"code","440ef2b5":"code","2be477ee":"code","bc727467":"code","0e9becd4":"markdown","390a2a2e":"markdown","b22fbc55":"markdown"},"source":{"d064bdf5":"import numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport datetime\n\nfrom tensorflow import keras\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout,ZeroPadding2D, BatchNormalization\nfrom tensorflow.keras import regularizers","63d8913a":"!nvidia-smi","532dcf54":"#Basic variables\nwidth = 224\nheight = 224\nnum_classes = 9\nnum_batches = 32\nlearning_rate = 0.0001\nvalidation_split = 0.15\nepochs = 200\nseed = 123\ndataset_path = '..\/input\/small-polish-monetary\/small\/small'","282625b4":"#Image generators for both train and validation sets\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.\/255,\n    rotation_range = 90,\n    validation_split = validation_split,\n)\n\nval_datagen = keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1.\/255,\n    validation_split = validation_split,\n)","d6430380":"#Load data from \ntrain_dataset = train_datagen.flow_from_directory(\n    dataset_path, \n    batch_size = num_batches,\n    target_size = (width, height), \n    subset = \"training\", \n    seed = seed\n)\n\nvalidation_dataset = val_datagen.flow_from_directory(\n    dataset_path, \n    batch_size = num_batches, \n    target_size = (width, height), \n    subset = \"validation\", \n    seed = seed\n)","e49dfb3f":"#Show some random images from train dataset\nfor i in range(9):\n\t# define subplot\n\tplt.subplot(330 + 1 + i)\n\t# plot raw pixel data\n\tplt.imshow(train_dataset[0][0][i])","d85ade82":"#Create base xception model and output layer on top of it\n\nbase_model = keras.applications.xception.Xception(weights='imagenet', include_top=False)\navg = keras.layers.GlobalAveragePooling2D()(base_model.output)\noutput = Dense(num_classes, activation=\"softmax\")(avg)\nmodel = keras.Model(inputs=base_model.input, outputs=output)\n\n#First freeze xception model parameters and learn only output weights\nfor layer in base_model.layers:\n  layer.trainable = False","c8339352":"#Compile model\noptimizer = keras.optimizers.Adam(learning_rate)\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\",\"Recall\", \"Precision\"])","dfcce028":"#Create callbacks: EarlyStopping to prevent overfitting and checkpoints to save models. We try to maximize validation dataset accuracy\ncheckpoints = keras.callbacks.ModelCheckpoint(\"mode.h5\", monitor='val_accuracy', mode=\"max\")\nearlystop = keras.callbacks.EarlyStopping(monitor='val_accuracy', mode=\"max\", patience=7)","74542d89":"#Train model and save history\nhistory = model.fit(train_dataset, validation_data=validation_dataset, epochs=epochs,callbacks=[checkpoints, earlystop])","08cbf9fa":"def plot_training(history, attribiute_name):\n    plt.plot(history.history[attribiute_name])\n    plt.plot(history.history['val_' + attribiute_name])\n    plt.title('model ' + attribiute_name)\n    plt.ylabel(attribiute_name)\n    plt.xlabel('epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()","b9629dfa":"plot_training(history, \"loss\")","46a9e5f8":"plot_training(history, \"accuracy\")","9990b325":"model.evaluate(validation_dataset)","e69835fb":"model.evaluate(train_dataset)","597ed96c":"#Lets try to unfreeze more layers\nfor layers in base_model.layers:\n    layers.trainable = True\n\n#Gonna use smaller learning rate\noptimizer = keras.optimizers.Adam(0.00001)\nloss = keras.losses.CategoricalCrossentropy()\nmodel.compile(loss=loss, optimizer=optimizer, metrics=[\"accuracy\",\"Recall\", \"Precision\"])","f58e29ec":"#Train model and save history\nhistory_finetune = model.fit(train_dataset, validation_data=validation_dataset, epochs=epochs,callbacks=[checkpoints, earlystop])","80877163":"model.evaluate(validation_dataset)","17879da3":"model.evaluate(train_dataset)","04534a6f":"plot_training(history_finetune,\"loss\")","5fc07fff":"plot_training(history_finetune,\"accuracy\")","c49f6f03":"model.save('monetary.h5')","311d93c7":"#Load model\nmodel = keras.models.load_model('monetary.h5')\nnp.set_printoptions(suppress=True)","4d67fe23":"#Create preprocessing generator (for rescaling)\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n)","68727e7c":"#Load dataset from directory\ntest_set = test_datagen.flow_from_directory(\"..\/input\/small-polish-monetary\/test\/test\", target_size=(width,height))","04fdf5bb":"#Inversion map to know which class we predicted (Because flow from directory could rearrange in its own way)\ninv_map = {v: k for k, v in test_set.class_indices.items()}","440ef2b5":"inv_map","2be477ee":"#Evaluate test set\nmodel.evaluate(test_set)","bc727467":"#Evaluation on a single image from dataset\nimage = tf.keras.preprocessing.image.load_img(\"..\/input\/small-polish-monetary\/test\/test\/1\/IMG_20210403_180106.jpg\")\nplt.imshow(image)\nimage = image.resize((224,224))\ninput_arr = keras.preprocessing.image.img_to_array(image)\ninput_arr = np.array([input_arr\/255.0])  # Convert single image to a batch.\npredictions = model.predict(input_arr)\n\n#Print which class we predicted\nprint(inv_map[predictions.argmax()])\n\n#Prediction percent\nprint(predictions)","0e9becd4":"# **Polish coins detection using transfer learning for small dataset**","390a2a2e":"# Test set evaluation\n*Note that code below comes from another script (because I usually seperate test set evaluation). That's why I load model again and create new generators.*","b22fbc55":"# Inference on single image"}}