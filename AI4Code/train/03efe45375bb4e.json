{"cell_type":{"6a2d0c7e":"code","050ffe69":"code","7f0841a8":"code","07096536":"code","a908be15":"code","bec27a64":"code","f11521c5":"code","f531aa96":"code","71ddafd6":"code","36b866f1":"code","05881699":"code","14656eb4":"code","ba883660":"code","b0e307b6":"code","19afe169":"code","03429cd6":"code","9666874e":"code","1a3242fb":"code","d8d792df":"code","ff2a9b30":"code","3b3011dc":"code","155c4f7b":"code","293cccb4":"code","21501128":"code","f70fe63d":"code","83ad8949":"code","5a79a0a6":"code","f0e4fbac":"code","bc2ef771":"code","e7fb3cc7":"code","28d7f280":"code","8cce632f":"code","995a08a4":"code","e147ece7":"code","cb4a288d":"code","56bf0cfb":"code","0b32509d":"code","0919c0ba":"code","0447f0ef":"code","97fca83d":"code","c6d09a65":"code","38ab001c":"code","3c3a586d":"code","c37145bd":"code","f58eb589":"code","2eac68de":"code","c0112f6d":"code","2c98c244":"code","9942db02":"code","08355f8e":"code","9be4008a":"code","d1718c98":"code","4843d1c0":"code","2bcde786":"code","3603b09c":"code","cb8027fa":"code","1c829222":"code","8d64faa3":"code","b352723b":"code","ef07a0a7":"code","5225d43a":"code","24ceaa01":"code","d6236be8":"code","c4355a0b":"code","8053b4eb":"code","2b27e118":"code","35f7008f":"code","80e008a9":"code","6d4e67b6":"code","c65b46cf":"code","b247e896":"code","b7b7638f":"code","9b5b42fb":"code","becde0a7":"code","c7624a04":"code","18cbe9c3":"code","4db6dd33":"code","fb5de371":"code","55dc163a":"code","0afb8bb0":"code","fd7c1f0d":"code","f2e367af":"code","ad2858fc":"code","7486d241":"code","6467c0f2":"markdown","e91a73c4":"markdown","c2bef4a3":"markdown","6c562839":"markdown","83cf7429":"markdown","fb9e9b6d":"markdown","cbcb20ae":"markdown","c7f5edf3":"markdown","b5cb5466":"markdown","c425059e":"markdown","00c784b4":"markdown","0e577273":"markdown","f3e5f0c8":"markdown","d9fce5d2":"markdown","1f743d48":"markdown","59c9dd96":"markdown","8f32e234":"markdown","33d9fd56":"markdown","1386d81f":"markdown","30b2a07b":"markdown","40bddeba":"markdown","0b63ee8d":"markdown"},"source":{"6a2d0c7e":"#GENERAL\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport random\n#PATH PROCESS\nimport os\nimport os.path\nfrom pathlib import Path\nimport glob\n#IMAGE PROCESS\nfrom PIL import Image\nfrom keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nfrom keras.applications.vgg16 import preprocess_input, decode_predictions\n#SCALER & TRANSFORMATION\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import MinMaxScaler\nfrom keras.utils.np_utils import to_categorical\nfrom sklearn.model_selection import train_test_split\nfrom keras import regularizers\nfrom sklearn.preprocessing import LabelEncoder\n#ACCURACY CONTROL\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, roc_auc_score, roc_curve\nfrom sklearn.model_selection import GridSearchCV, cross_val_score\nfrom sklearn.metrics import mean_squared_error, r2_score\n#OPTIMIZER\nfrom keras.optimizers import RMSprop,Adam,Optimizer,Optimizer, SGD\n#MODEL LAYERS\nfrom tensorflow.keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization,MaxPooling2D,BatchNormalization,\\\n                        Permute, TimeDistributed, Bidirectional,GRU, SimpleRNN,\\\nLSTM, GlobalAveragePooling2D, SeparableConv2D, ZeroPadding2D, Convolution2D, ZeroPadding2D,Reshape, Conv2DTranspose, LeakyReLU, GaussianNoise\nfrom keras import models\nfrom keras import layers\nimport tensorflow as tf\nfrom keras.applications import VGG16,VGG19,inception_v3\nfrom keras import backend as K\nfrom keras.utils import plot_model\nfrom keras.datasets import mnist\nimport keras\n#SKLEARN CLASSIFIER\nfrom xgboost import XGBClassifier, XGBRegressor\nfrom lightgbm import LGBMClassifier, LGBMRegressor\nfrom catboost import CatBoostClassifier, CatBoostRegressor\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier, RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingClassifier, GradientBoostingRegressor\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.tree import DecisionTreeClassifier, DecisionTreeRegressor\nfrom sklearn.neural_network import MLPClassifier, MLPRegressor\nfrom sklearn.neighbors import KNeighborsClassifier, KNeighborsRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.cross_decomposition import PLSRegression\nfrom sklearn.linear_model import Ridge\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV\nfrom sklearn.linear_model import ElasticNet\nfrom sklearn.linear_model import ElasticNetCV\n#IGNORING WARNINGS\nfrom warnings import filterwarnings\nfilterwarnings(\"ignore\",category=DeprecationWarning)\nfilterwarnings(\"ignore\", category=FutureWarning) \nfilterwarnings(\"ignore\", category=UserWarning)","050ffe69":"Wave_Train_Data = Path(\"..\/input\/gravity-spy-gravitational-waves\/train\/train\")\nWave_Test_Data = Path(\"..\/input\/gravity-spy-gravitational-waves\/test\/test\")\nWave_Validation_Data = Path(\"..\/input\/gravity-spy-gravitational-waves\/validation\/validation\")","7f0841a8":"Train_PNG_Path = list(Wave_Train_Data.glob(r\"*\/*.png\"))\nTest_PNG_Path = list(Wave_Test_Data.glob(r\"*\/*.png\"))\nValidation_PNG_Path = list(Wave_Validation_Data.glob(r\"*\/*.png\"))","07096536":"Train_PNG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Train_PNG_Path))\nTest_PNG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Test_PNG_Path))\nValidation_PNG_Labels = list(map(lambda x: os.path.split(os.path.split(x)[0])[1],Validation_PNG_Path))","a908be15":"Train_PNG_Path_Series = pd.Series(Train_PNG_Path,name=\"PNG\").astype(str)\nTest_PNG_Path_Series = pd.Series(Test_PNG_Path,name=\"PNG\").astype(str)\nValidation_PNG_Path_Series = pd.Series(Validation_PNG_Path,name=\"PNG\").astype(str)","bec27a64":"Train_PNG_Labels_Series = pd.Series(Train_PNG_Labels,name=\"CATEGORY\")\nTest_PNG_Labels_Series = pd.Series(Test_PNG_Labels,name=\"CATEGORY\")\nValidation_PNG_Labels_Series = pd.Series(Validation_PNG_Labels,name=\"CATEGORY\")","f11521c5":"print(Train_PNG_Labels_Series.value_counts())\nprint(\"---\"*20)\nprint(Train_PNG_Labels_Series.value_counts().sum())","f531aa96":"print(Test_PNG_Labels_Series.value_counts())\nprint(\"---\"*20)\nprint(Test_PNG_Labels_Series.value_counts().sum())","71ddafd6":"print(Validation_PNG_Labels_Series.value_counts())\nprint(\"---\"*20)\nprint(Validation_PNG_Labels_Series.value_counts().sum())","36b866f1":"Main_Train_Data = pd.concat([Train_PNG_Path_Series,Train_PNG_Labels_Series],axis=1)\nMain_Test_Data = pd.concat([Test_PNG_Path_Series,Test_PNG_Labels_Series],axis=1)\nMain_Validation_Data = pd.concat([Validation_PNG_Path_Series,Validation_PNG_Labels_Series],axis=1)","05881699":"print(Main_Train_Data.head(-1))","14656eb4":"print(Main_Test_Data.head(-1))","ba883660":"print(Main_Validation_Data.head(-1))","b0e307b6":"Main_Train_Data = Main_Train_Data.sample(frac=1).reset_index(drop=True)","19afe169":"print(Main_Train_Data.head(-1))","03429cd6":"Main_Test_Data = Main_Test_Data.sample(frac=1).reset_index(drop=True)","9666874e":"print(Main_Test_Data.head(-1))","1a3242fb":"Main_Validation_Data = Main_Validation_Data.sample(frac=1).reset_index(drop=True)","d8d792df":"print(Main_Validation_Data.head(-1))","ff2a9b30":"plt.style.use(\"classic\")","3b3011dc":"example_IMG = cv2.imread(Main_Train_Data[\"PNG\"][22033])\nplt.xlabel(example_IMG.shape)\nplt.ylabel(example_IMG.size)\nplt.title(Main_Train_Data[\"CATEGORY\"][22033])\nplt.imshow(example_IMG)","155c4f7b":"example_IMG = cv2.imread(Main_Train_Data[\"PNG\"][23])\nplt.xlabel(example_IMG.shape)\nplt.ylabel(example_IMG.size)\nplt.title(Main_Train_Data[\"CATEGORY\"][23])\nplt.imshow(example_IMG)","293cccb4":"example_IMG = cv2.imread(Main_Train_Data[\"PNG\"][1009])\nplt.xlabel(example_IMG.shape)\nplt.ylabel(example_IMG.size)\nplt.title(Main_Train_Data[\"CATEGORY\"][1009])\nplt.imshow(example_IMG)","21501128":"example_IMG = cv2.imread(Main_Train_Data[\"PNG\"][101])\nplt.xlabel(example_IMG.shape)\nplt.ylabel(example_IMG.size)\nplt.title(Main_Train_Data[\"CATEGORY\"][101])\nplt.imshow(example_IMG)","f70fe63d":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = plt.imread(Main_Train_Data[\"PNG\"][i])\n    ax.imshow(IMG)\n    ax.set_xlabel(IMG.shape)\n    ax.set_ylabel(IMG.size)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","83ad8949":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    ax.imshow(IMG)\n    ax.set_xlabel(round(np.mean(IMG)))\n    ax.set_ylabel(IMG.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","5a79a0a6":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    Canny_IMG = cv2.Canny(IMG,10,100)\n    ax.imshow(Canny_IMG)\n    ax.set_xlabel(Canny_IMG.shape)\n    ax.set_ylabel(Canny_IMG.size)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","f0e4fbac":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    _,Threshold_IMG = cv2.threshold(IMG,90,255,cv2.THRESH_BINARY)\n    ax.imshow(Threshold_IMG)\n    ax.set_xlabel(round(np.mean(Threshold_IMG)))\n    ax.set_ylabel(Threshold_IMG.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","bc2ef771":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i],0)\n    AdaptiveThreshold_IMG = cv2.adaptiveThreshold(IMG,200,cv2.ADAPTIVE_THRESH_GAUSSIAN_C,cv2.THRESH_BINARY,11,2)\n    ax.imshow(AdaptiveThreshold_IMG)\n    ax.set_xlabel(round(np.mean(AdaptiveThreshold_IMG)))\n    ax.set_ylabel(AdaptiveThreshold_IMG.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","e7fb3cc7":"Background_SUB = cv2.createBackgroundSubtractorMOG2()\n\nfigure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    SUB_IMG = Background_SUB.apply(IMG)\n    ax.imshow(SUB_IMG)\n    ax.set_xlabel(round(np.mean(SUB_IMG)))\n    ax.set_ylabel(SUB_IMG.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","28d7f280":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    Canny_IMG = cv2.Canny(IMG,10,100)\n    contour,_ = cv2.findContours(Canny_IMG,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    draw_contour = cv2.drawContours(Canny_IMG,contour,-1,(255,0,0),2)\n    ax.imshow(draw_contour)\n    ax.set_xlabel(round(np.mean(draw_contour)))\n    ax.set_ylabel(draw_contour.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","8cce632f":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    IMG = cv2.resize(IMG,(28,28))\n    _,threshold_IMG = cv2.threshold(IMG,90,255,cv2.THRESH_BINARY_INV)\n    threshold_IMG = cv2.resize(threshold_IMG,(28,28))\n    mask = cv2.inRange(IMG,IMG,threshold_IMG)\n    Sub_Mask = cv2.bitwise_and(IMG,IMG,mask=mask)\n    ax.imshow(Sub_Mask)\n    ax.set_xlabel(round(np.mean(Sub_Mask)))\n    ax.set_ylabel(Sub_Mask.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","995a08a4":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    IMG = cv2.resize(IMG,(28,28))\n    _,threshold_IMG = cv2.threshold(IMG,90,255,cv2.THRESH_BINARY_INV)\n    threshold_IMG = cv2.resize(threshold_IMG,(28,28))\n    mask = cv2.inRange(IMG,IMG,threshold_IMG)\n    Sub_Mask = cv2.bitwise_and(IMG,IMG,mask=mask)\n    Canny_IMG = cv2.Canny(Sub_Mask,10,100)\n    contour,_ = cv2.findContours(Canny_IMG,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    draw_contour = cv2.drawContours(Canny_IMG,contour,-1,(255,0,0),2)\n    ax.imshow(draw_contour)\n    ax.set_xlabel(round(np.mean(draw_contour)))\n    ax.set_ylabel(draw_contour.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","e147ece7":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    IMG = cv2.resize(IMG,(28,28))\n    _,threshold_IMG = cv2.threshold(IMG,90,255,cv2.THRESH_BINARY_INV)\n    threshold_IMG = cv2.resize(threshold_IMG,(28,28))\n    mask = cv2.inRange(IMG,IMG,threshold_IMG)\n    Sub_Mask = cv2.bitwise_and(IMG,IMG,mask=mask)\n    Canny_IMG = cv2.Canny(Sub_Mask,10,100)\n    contour,_ = cv2.findContours(Canny_IMG,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    \n    for cnt in contour:\n        x,y,w,h = cv2.boundingRect(cnt)\n        cv2.rectangle(Sub_Mask,(x,y),(x+w,y+h),(255,0,0),1)\n        \n    ax.imshow(Sub_Mask)\n    ax.set_xlabel(round(np.mean(Sub_Mask)))\n    ax.set_ylabel(Sub_Mask.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","cb4a288d":"figure,axis = plt.subplots(nrows=5,ncols=5,figsize=(13,13))\n\nfor i,ax in enumerate(axis.flat):\n    IMG = cv2.imread(Main_Train_Data[\"PNG\"][i])\n    IMG = cv2.resize(IMG,(180,180))\n    _,threshold_IMG = cv2.threshold(IMG,90,255,cv2.THRESH_BINARY_INV)\n    threshold_IMG = cv2.resize(threshold_IMG,(180,180))\n    mask = cv2.inRange(IMG,IMG,threshold_IMG)\n    Sub_Mask = cv2.bitwise_and(IMG,IMG,mask=mask)\n    Canny_IMG = cv2.Canny(Sub_Mask,10,100)\n    contour,_ = cv2.findContours(Canny_IMG,cv2.RETR_EXTERNAL,cv2.CHAIN_APPROX_NONE)\n    \n    for cnt in contour:\n        x,y,w,h = cv2.boundingRect(cnt)\n        cv2.rectangle(IMG,(x,y),(x+w,y+h),(255,0,0),1)\n        \n    ax.imshow(IMG)\n    ax.set_xlabel(round(np.mean(IMG)))\n    ax.set_ylabel(IMG.shape)\n    ax.set_title(Main_Train_Data[\"CATEGORY\"][i])\nplt.tight_layout()\nplt.show()","56bf0cfb":"Y_Validation_Data = Train_PNG_Path[5000:10000]","0b32509d":"Y_Validation_Data_Series = pd.Series(Y_Validation_Data,name=\"PNG\").astype(str)","0919c0ba":"print(Y_Validation_Data_Series.shape)","0447f0ef":"X_Training_Data = Train_PNG_Path[:5000]","97fca83d":"X_Training_Data_Series = pd.Series(X_Training_Data,name=\"PNG\").astype(str)","c6d09a65":"print(X_Training_Data_Series.shape)","38ab001c":"Transformated_X = []\n\nfor IMG_X in X_Training_Data_Series:\n    X_IMG = cv2.imread(IMG_X)\n    X_IMG = X_IMG \/ 255.\n    R_IMG = cv2.resize(X_IMG,(28,28))\n    Transformated_X.append(R_IMG)","3c3a586d":"Transformated_Y = []\n\nfor IMG_Y in Y_Validation_Data_Series:\n    Y_IMG = cv2.imread(IMG_Y)\n    Y_IMG = Y_IMG \/ 255.\n    RY_IMG = cv2.resize(Y_IMG,(28,28))\n    Transformated_Y.append(RY_IMG)","c37145bd":"figure = plt.figure(figsize=(5,5))\nplt.xlabel(Transformated_X[2].shape)\nplt.ylabel(Transformated_X[2].size)\nplt.imshow(Transformated_X[2])","f58eb589":"figure = plt.figure(figsize=(5,5))\nplt.xlabel(Transformated_Y[2].shape)\nplt.ylabel(Transformated_Y[2].size)\nplt.imshow(Transformated_Y[2])","2eac68de":"X_Train = np.array(Transformated_X)\nY_Train = np.array(Transformated_Y)","c0112f6d":"print(X_Train.shape)","2c98c244":"print(Y_Train.shape)","9942db02":"encoder = Sequential()\nencoder.add(Flatten(input_shape=[28,28,3]))\nencoder.add(Dense(400,activation=\"relu\"))\nencoder.add(Dense(300,activation=\"relu\"))\nencoder.add(Dense(200,activation=\"relu\"))\nencoder.add(Dense(100,activation=\"relu\"))\nencoder.add(Dense(75,activation=\"relu\"))\nencoder.add(Dense(50,activation=\"relu\"))\nencoder.add(Dense(25,activation=\"relu\"))","08355f8e":"print(encoder.summary())","9be4008a":"decoder = Sequential()\ndecoder.add(Dense(50,input_shape=[25],activation=\"relu\"))\ndecoder.add(Dense(75,activation=\"relu\"))\ndecoder.add(Dense(100,activation=\"relu\"))\ndecoder.add(Dense(200,activation=\"relu\"))\ndecoder.add(Dense(300,activation=\"relu\"))\ndecoder.add(Dense(400,activation=\"relu\"))\ndecoder.add(Dense(2352,activation=\"sigmoid\"))\ndecoder.add(Reshape([28,28,3]))","d1718c98":"print(decoder.summary())","4843d1c0":"Auto_Encoder = Sequential([encoder,decoder])","2bcde786":"print(Auto_Encoder.summary())","3603b09c":"Auto_Encoder.compile(loss=\"binary_crossentropy\",optimizer=\"adam\",metrics=[\"accuracy\"])","cb8027fa":"Auto_Encoder.fit(X_Train,X_Train,validation_data=(Y_Train,Y_Train),epochs=10)","1c829222":"Predict_IMG = Auto_Encoder.predict(Y_Train[:10])","8d64faa3":"print(Y_Train[:10].shape)","b352723b":"print(Predict_IMG[1].shape)","ef07a0a7":"prediction_img = 5\nprint(\"NORMAL\")\nplt.imshow(Y_Train[prediction_img])\nplt.show()\nprint(\"Auto Encoder\")\nplt.imshow(Predict_IMG[prediction_img])","5225d43a":"figure,axis = plt.subplots(nrows=2,ncols=5,figsize=(10,10))\n\nfor P_Image,ax in enumerate(axis.flat):\n    ax.imshow(Predict_IMG[P_Image])","24ceaa01":"Non_Seen_IMG = Main_Train_Data[\"PNG\"][20000]\nIMG_T = cv2.imread(Non_Seen_IMG)\nIMG_T = IMG_T \/ 255.\nIMG_T = cv2.resize(IMG_T,(28,28))","d6236be8":"IMG_T = np.array(IMG_T)","c4355a0b":"IMG_T = IMG_T.reshape(-1,28,28,3)","8053b4eb":"print(IMG_T.shape)","2b27e118":"Pre_Non_Seen = Auto_Encoder.predict(IMG_T)","35f7008f":"print(\"NORMAL\")\nplt.imshow(IMG_T[0])\nplt.show()\nprint(\"Auto Encoder\")\nplt.imshow(Pre_Non_Seen[0])","80e008a9":"Generator_Input = keras.Input(shape=(28,))\nx = layers.Dense(128*14*14)(Generator_Input)\nx = layers.LeakyReLU()(x)\nx = layers.Reshape((14,14,128))(x)\n\nx = layers.Conv2D(256,5,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2DTranspose(256,4,padding=\"same\",strides=2)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(256,5,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256,4,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(256,3,padding=\"same\")(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(3,7,padding=\"same\",activation=\"tanh\")(x)\n\nGenerator = keras.models.Model(Generator_Input,x)","6d4e67b6":"Discriminator_Input = layers.Input(shape=(28,28,3))\nx = layers.Conv2D(128,3)(Discriminator_Input)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,4)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128,4)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Conv2D(128,3)(x)\nx = layers.LeakyReLU()(x)\n\nx = layers.Conv2D(128,3)(x)\nx = layers.LeakyReLU()(x)\nx = layers.Flatten()(x)\n\nx = layers.Dense(1,activation=\"sigmoid\")(x)\n\nDiscriminator = keras.models.Model(Discriminator_Input,x)","c65b46cf":"Discriminator.compile(optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","b247e896":"Discriminator.trainable = False\n\nGan_Input = keras.Input(shape=(28,))\nGan_Output = Discriminator(Generator(Gan_Input))\nGAN_Model = keras.models.Model(Gan_Input,Gan_Output)","b7b7638f":"GAN_Model.compile(optimizer=RMSprop(lr=0.0004,clipvalue=1.0,decay=1e-8),loss=\"binary_crossentropy\")","9b5b42fb":"os.mkdir(\"wave8_new\")","becde0a7":"start = 0\nbatch_size = 32\niterations = 10000\ndim_size = 28\n\nfor step in range(iterations):\n    random_noise_vector = np.random.normal(size=(batch_size,dim_size)) #32\n    generation_images = Generator.predict(random_noise_vector)\n    \n    stop = start + batch_size\n    real_images = X_Train[start:stop]\n    \n    combined_images = np.concatenate([generation_images,real_images])\n    \n    labels = np.concatenate([np.ones((batch_size,1)),np.zeros((batch_size,1))])\n    labels += 0.05 * np.random.random(labels.shape)\n    \n    D_loss = Discriminator.train_on_batch(combined_images,labels)\n    \n    random_noise_vector = np.random.normal(size=(batch_size,dim_size)) #32\n    \n    misleading_targets = np.zeros((batch_size,1))\n    \n    a_loss = GAN_Model.train_on_batch(random_noise_vector,misleading_targets)\n    \n    start += batch_size\n    \n    if start > len(X_Train) - batch_size:\n        start = 0\n    \n    if step % 100 == 0:\n        GAN_Model.save_weights(\"GAN_ONE.h5\")\n        \n        print(\"DISC_LOSS: \", D_loss)\n        print(\"ADVERSARIAL_LOSS: \", a_loss)\n        \n        Img = image.array_to_img(generation_images[0] * 255.,scale=False)\n        Img.save(os.path.join(\".\/wave8_new\",\"FAKE\"+str(step)+\".png\"))\n        \n        Img = image.array_to_img(real_images[0] * 255.,scale=False)\n        Img.save(os.path.join(\".\/wave8_new\",\"REAL\"+str(step)+\".png\"))","c7624a04":"Exp_output = Path(\".\/wave8_new\")","18cbe9c3":"list_output = list(Exp_output.glob(r\"*.png\"))","4db6dd33":"list_output_series = pd.Series(list_output,name=\"PNG\").astype(str)","fb5de371":"noise_PR = tf.random.normal(shape=[10,28])","55dc163a":"print(noise_PR.shape)","0afb8bb0":"plt.imshow(noise_PR)","fd7c1f0d":"PR_Images = Generator(noise_PR)","f2e367af":"figure, axes = plt.subplots(nrows=2,ncols=5,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    ax.imshow(PR_Images[i],cmap=\"Greys_r\")\n    ax.set_xlabel(PR_Images[i].shape)\nplt.tight_layout()\nplt.show()","ad2858fc":"figure = plt.figure(figsize=(10,10))\nplt.imshow(PR_Images[7])","7486d241":"figure, axes = plt.subplots(nrows=4,ncols=4,figsize=(10,10))\n\nfor i,ax in enumerate(axes.flat):\n    List_Gen_Image = cv2.imread(list_output_series[i])\n    ax.imshow(List_Gen_Image,cmap=\"Greys_r\")\n    ax.set_xlabel(List_Gen_Image.shape)\n    ax.set_ylabel(List_Gen_Image.size)\nplt.tight_layout()\nplt.show()","6467c0f2":"#### MAIN PATH","e91a73c4":"#### PNG PATH","c2bef4a3":"# HISTORY","6c562839":"# PATH & LABEL PROCESS","83cf7429":"#### TO DATAFRAME","fb9e9b6d":"#### MAIN DATA","cbcb20ae":"#### LABELS","c7f5edf3":"#### TRANSFORMATION","b5cb5466":"#### PREDICTION","c425059e":"#### TO SERIES","00c784b4":"# AUTO ENCODER PROCESS","0e577273":"##### LABELS","f3e5f0c8":"# PACKAGES AND LIBRARIES","d9fce5d2":"# VISION","1f743d48":"# DATA PROCESS","59c9dd96":"#### Context\n\n* The Laser Interferometer Gravitational-Wave Observatory (LIGO) was designed to open the field of gravitational-wave astrophysics through the direct detection of gravitational waves predicted by Einstein\u2019s General Theory of Relativity. LIGO\u2019s multi-kilometer-scale gravitational wave detectors use laser interferometry to measure the minute ripples in space-time caused by passing gravitational waves from cataclysmic cosmic events such as colliding neutron stars or black holes, or by supernovae. LIGO consists of two widely-separated interferometers within the United States\u2014one in Hanford, Washington and the other in Livingston, Louisiana\u2014operated in unison to detect gravitational waves.\n\n* This dataset is made up of LIGO images that have been classified by people as part of the Gravity Spy Zooniverse project and they've been placed into train,validation and test folders,ready for machine learning.","8f32e234":"#### SHUFFLING","33d9fd56":"##### PATH","1386d81f":"#### GENERAL SPLITTING","30b2a07b":"#### NON SEEN PREDICT","40bddeba":"# DC-GAN PROCESS","0b63ee8d":"#### STRUCTURE"}}