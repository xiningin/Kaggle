{"cell_type":{"1ea07ff0":"code","ffeab72f":"code","19c6c1eb":"code","be390cb1":"code","a17de28a":"code","0f3f3727":"code","1fb58331":"code","170329ae":"code","6d81c31f":"code","9027925e":"code","3bddf4b2":"code","7c32cc1f":"code","5d9ce14a":"code","c02ee39d":"code","7c3b1a92":"code","8626a085":"code","970e8d92":"code","af164777":"code","6934f561":"code","e64fff4f":"code","8a2f85c1":"code","d16eb548":"code","42d9e79f":"code","b77d49b8":"code","d34da832":"code","cf00e8b7":"code","a7713227":"code","3ce25727":"code","b6318f1b":"markdown","ba09b36a":"markdown","7a2ab0b0":"markdown","5d9b587b":"markdown","6f6e1d5b":"markdown","74fbafe6":"markdown","a1e846c2":"markdown","4a0dc5eb":"markdown","bbe22690":"markdown","a71b7070":"markdown","778871e4":"markdown","2197044b":"markdown","1cb7ef99":"markdown","954154f1":"markdown","293a5127":"markdown","14280397":"markdown","9c066559":"markdown"},"source":{"1ea07ff0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom sklearn.preprocessing import MinMaxScaler\nfrom tensorflow import keras\n","ffeab72f":"Random_seed = 42\nnp.random.seed(Random_seed)\ntf.random.set_seed(Random_seed)","19c6c1eb":"df = pd.read_csv('..\/input\/into-the-future\/train.csv',index_col = [1],parse_dates = [1])\ndf_test = pd.read_csv('..\/input\/into-the-future\/test.csv',index_col = [1],parse_dates = [1])","be390cb1":"df = df.drop(['id'],axis = 1)\ndf.dtypes","a17de28a":"test = df_test\ntest.dtypes","0f3f3727":"df.isnull().values.any()","1fb58331":"df.head()\n","170329ae":"df['hour'] = df.index.hour\ndf['minute'] = df.index.minute\ndf['second'] = df.index.second\ndf.describe()\n","6d81c31f":"test['hour'] = test.index.hour\ntest['minute'] = test.index.minute\ntest['second'] = test.index.second\ntest.describe()","9027925e":"sns.lineplot(x=df.index,y='feature_2',data =df)\nsns.set(rc={'figure.figsize':(12,8)})","3bddf4b2":"sns.lineplot(x=df.index,y='feature_1',data =df)\nsns.set(rc={'figure.figsize':(12,8)})","7c32cc1f":"#df = df.iloc[1:]","5d9ce14a":"df.head()","c02ee39d":"train = df\ntrain_size = len(df)\ntest_size = len(test)\n\nprint(len(train), len(test))","7c3b1a92":"scaler = MinMaxScaler()","8626a085":"scaler.fit(train[['feature_1']].to_numpy())","970e8d92":"scaled_train_f1 = scaler.transform(train[['feature_1']].to_numpy())\nscaled_test_f1 = scaler.transform(test[['feature_1']].to_numpy())\n\nsecond_square = np.square(train[['second']])\ntest_second_square = np.square(test[['second']])\n\ntrain_feature = np.c_[scaled_train_f1,train[['hour']],train[['minute']],train[['second']]]\ntest_feature = np.c_[scaled_test_f1,test[['hour']],test[['minute']],test[['second']]]\n","af164777":"scaler.fit(train[['feature_2']].to_numpy())\nscaled_train_f2 = scaler.transform(train[['feature_2']].to_numpy())","6934f561":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(4,)),\n    keras.layers.Dense(180, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n    keras.layers.Dropout(0.2),\n    keras.layers.Dense(180, activation='relu', kernel_regularizer=keras.regularizers.l2(0.01)),\n    keras.layers.Dropout(0.2),\n    \n    keras.layers.Dense(1, activation='sigmoid', kernel_regularizer=keras.regularizers.l2(0.01)),\n])","e64fff4f":"model.compile(optimizer='adam',\n              loss='mse'\n              )","8a2f85c1":"hist = model.fit(train_feature, scaled_train_f2, shuffle=False,\n          batch_size=32, \n                 epochs=100,validation_split=0.1)","d16eb548":"plt.plot(hist.history['loss'])\nplt.plot(hist.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Val'], loc='upper right')\nplt.show()","42d9e79f":"prediction = model.predict(test_feature)","b77d49b8":"prediction.shape","d34da832":"feature_2 = scaler.inverse_transform(prediction)","cf00e8b7":"ids = test[['id']].to_numpy()\nids = ids.flatten()\n\nfeature_2 = feature_2.flatten()\n","a7713227":"d = {'id': ids, 'feature_2': feature_2}\nsubmission = pd.DataFrame(data = d)\nsubmission.to_csv('submission.csv',index=False)","3ce25727":"submission","b6318f1b":"Lets take a look at the statistical values of the df data set using describe() function","ba09b36a":"**Saving the data into .csv file**","7a2ab0b0":"**Configuring the model**","5d9b587b":"Removing the outlier by removing the first row from df dataset","6f6e1d5b":"# Preprocessing \nThe first step of preprocessing is normalising  the features in the data set. Here I have used MinMaxScalar to normalize so that all the values lie between 0 and 1.\n","74fbafe6":"# Training the model \nThe first step is fitting the parameters to the data using fit()","a1e846c2":"Taking a insight of df dataset using head()","4a0dc5eb":"**Since we transformed our data by normalising it, we have to inverse transform our data to get the values which we want.**","bbe22690":"# Using Tensorflow to predict feature_2\nI have used neural networks to predict feature_2. \n* The program starts by Importing all the necessary libraries that I have used in this program. \n* In second step I have done visulaisation and explorarion of data by using head() function and graphs\n* Next step is preprocessing where I have used minmaxscaler on train set to scale the feature_1 so that it can give better output\n* Last step is building the model and then training it\n* Finally I tested the model on test set and saved the predictions in submission.csv file\n","a71b7070":"# Predicting\nOnce the training is done, we will predict the values for our test set using predict()","778871e4":"# Visualization and Exploration\nChecking the features and data types in df and df_test dataset","2197044b":"# Reading the train and test file\ntrain.csv file has been read into df and test.csv file has been read into df_test. I have used time column as an index in df.","1cb7ef99":"# Building the model\nThe first step is to specify the architecture of the model. I have used keras sequential model for this.","954154f1":"Graphs are very usefull as they give lot of information about the data set. I have plotted a graph between feature_2 and time. As we can see from this graph that it has an outlier value in the beginning.","293a5127":"The second graph is plotted between feature_1 and time and it has no outlier","14280397":"# Importing necessary libraries","9c066559":"Checking if the test dataset contains any null value"}}