{"cell_type":{"1d2f0a5f":"code","0b27899b":"code","4445918b":"code","81158859":"code","e9df4080":"code","d5771e64":"code","b1b10580":"code","b026be75":"code","3c9ab7e4":"code","5957e570":"code","a92d0007":"code","fa3cb3ae":"code","370d3466":"code","597a380f":"code","7a28a1eb":"code","de4ffe61":"code","6344f41e":"code","5c513748":"code","04f8ab9e":"code","67f4307e":"code","775bf353":"code","7ffd5f56":"code","e41e4f3d":"code","1080e2bf":"code","cd2ad95f":"code","b0ca720e":"code","7194c7ae":"code","f04b2991":"code","e95ed5f9":"code","4877ee90":"code","3e23e6c2":"code","17ea88ca":"code","463bfb13":"code","7b7f1879":"code","0a25f4e0":"markdown","5911e9a1":"markdown"},"source":{"1d2f0a5f":"!pip install python-whois","0b27899b":"import pandas as pd\nimport itertools\nfrom sklearn.metrics import mean_squared_error,confusion_matrix, precision_score, recall_score, auc,roc_curve\nfrom sklearn.model_selection import train_test_split\nimport pandas as pd\nimport numpy as np\nimport random\nimport math\nfrom collections import Counter\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score\nimport xgboost as xgb\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier\nimport os\nimport socket\nimport whois\nfrom datetime import datetime\nimport time\nfrom bs4 import BeautifulSoup\nimport urllib\nimport bs4\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4445918b":"df=pd.read_csv('\/kaggle\/input\/malicious-urls-dataset\/malicious_phish.csv')\n\nprint(df.shape)\ndf.head()","81158859":"df.type.value_counts()","e9df4080":"import re\n#Use of IP or not in domain\ndef having_ip_address(url):\n    match = re.search(\n        '(([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\.'\n        '([01]?\\\\d\\\\d?|2[0-4]\\\\d|25[0-5])\\\\\/)|'  # IPv4\n        '((0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\.(0x[0-9a-fA-F]{1,2})\\\\\/)' # IPv4 in hexadecimal\n        '(?:[a-fA-F0-9]{1,4}:){7}[a-fA-F0-9]{1,4}', url)  # Ipv6\n    if match:\n        # print match.group()\n        return 1\n    else:\n        # print 'No matching pattern found'\n        return 0\ndf['use_of_ip'] = df['url'].apply(lambda i: having_ip_address(i))","d5771e64":"from urllib.parse import urlparse\n\n\n\n\ndef abnormal_url(url):\n    hostname = urlparse(url).hostname\n    hostname = str(hostname)\n    match = re.search(hostname, url)\n    if match:\n        # print match.group()\n        return 1\n    else:\n        # print 'No matching pattern found'\n        return 0\n\n\ndf['abnormal_url'] = df['url'].apply(lambda i: abnormal_url(i))","b1b10580":"!pip install googlesearch-python","b026be75":"df['count.'] = df['url'].apply(lambda i: i.count('.'))\ndf.head()","3c9ab7e4":"df['count-www'] = df['url'].apply(lambda i: i.count('www'))\ndf['count@'] = df['url'].apply(lambda i: i.count('@'))\nfrom urllib.parse import urlparse\ndef no_of_dir(url):\n    urldir = urlparse(url).path\n    return urldir.count('\/')\ndf['count_dir'] = df['url'].apply(lambda i: no_of_dir(i))\ndef no_of_embed(url):\n    urldir = urlparse(url).path\n    return urldir.count('\/\/')\ndf['count_embed_domian'] = df['url'].apply(lambda i: no_of_embed(i))\ndef shortening_service(url):\n    match = re.search('bit\\.ly|goo\\.gl|shorte\\.st|go2l\\.ink|x\\.co|ow\\.ly|t\\.co|tinyurl|tr\\.im|is\\.gd|cli\\.gs|'\n                      'yfrog\\.com|migre\\.me|ff\\.im|tiny\\.cc|url4\\.eu|twit\\.ac|su\\.pr|twurl\\.nl|snipurl\\.com|'\n                      'short\\.to|BudURL\\.com|ping\\.fm|post\\.ly|Just\\.as|bkite\\.com|snipr\\.com|fic\\.kr|loopt\\.us|'\n                      'doiop\\.com|short\\.ie|kl\\.am|wp\\.me|rubyurl\\.com|om\\.ly|to\\.ly|bit\\.do|t\\.co|lnkd\\.in|'\n                      'db\\.tt|qr\\.ae|adf\\.ly|goo\\.gl|bitly\\.com|cur\\.lv|tinyurl\\.com|ow\\.ly|bit\\.ly|ity\\.im|'\n                      'q\\.gs|is\\.gd|po\\.st|bc\\.vc|twitthis\\.com|u\\.to|j\\.mp|buzurl\\.com|cutt\\.us|u\\.bb|yourls\\.org|'\n                      'x\\.co|prettylinkpro\\.com|scrnch\\.me|filoops\\.info|vzturl\\.com|qr\\.net|1url\\.com|tweez\\.me|v\\.gd|'\n                      'tr\\.im|link\\.zip\\.net',\n                      url)\n    if match:\n        return 1\n    else:\n        return 0\ndf['short_url'] = df['url'].apply(lambda i: shortening_service(i))","5957e570":"df['count-https'] = df['url'].apply(lambda i : i.count('https'))\ndf['count-http'] = df['url'].apply(lambda i : i.count('http'))","a92d0007":"df['count%'] = df['url'].apply(lambda i: i.count('%'))\ndf['count?'] = df['url'].apply(lambda i: i.count('?'))\ndf['count-'] = df['url'].apply(lambda i: i.count('-'))\ndf['count='] = df['url'].apply(lambda i: i.count('='))\n#Length of URL\ndf['url_length'] = df['url'].apply(lambda i: len(str(i)))\n#Hostname Length\ndf['hostname_length'] = df['url'].apply(lambda i: len(urlparse(i).netloc))\n\ndf.head()","fa3cb3ae":"def suspicious_words(url):\n    match = re.search('PayPal|login|signin|bank|account|update|free|lucky|service|bonus|ebayisapi|webscr',\n                      url)\n    if match:\n        return 1\n    else:\n        return 0\ndf['sus_url'] = df['url'].apply(lambda i: suspicious_words(i))","370d3466":"df.head()","597a380f":"\n!pip install tld","7a28a1eb":"#Importing dependencies\nfrom urllib.parse import urlparse\nfrom tld import get_tld\nimport os.path\n\n#First Directory Length\ndef fd_length(url):\n    urlpath= urlparse(url).path\n    try:\n        return len(urlpath.split('\/')[1])\n    except:\n        return 0\n\ndf['fd_length'] = df['url'].apply(lambda i: fd_length(i))\n\n#Length of Top Level Domain\ndf['tld'] = df['url'].apply(lambda i: get_tld(i,fail_silently=True))\ndef tld_length(tld):\n    try:\n        return len(tld)\n    except:\n        return -1\n\ndf['tld_length'] = df['tld'].apply(lambda i: tld_length(i))","de4ffe61":"def digit_count(url):\n    digits = 0\n    for i in url:\n        if i.isnumeric():\n            digits = digits + 1\n    return digits\ndf['count-digits']= df['url'].apply(lambda i: digit_count(i))","6344f41e":"def letter_count(url):\n    letters = 0\n    for i in url:\n        if i.isalpha():\n            letters = letters + 1\n    return letters\ndf['count-letters']= df['url'].apply(lambda i: letter_count(i))","5c513748":"df = df.drop(\"tld\",1)","04f8ab9e":"from sklearn.preprocessing import LabelEncoder\n\nlb_make = LabelEncoder()\ndf[\"type_code\"] = lb_make.fit_transform(df[\"type\"])\ndf[\"type_code\"].value_counts()","67f4307e":"#Predictor Variables\nX = df[['use_of_ip','abnormal_url', 'count.', 'count-www', 'count@',\n       'count_dir', 'count_embed_domian', 'short_url', 'count-https',\n       'count-http', 'count%', 'count?', 'count-', 'count=', 'url_length',\n       'hostname_length', 'sus_url', 'fd_length', 'tld_length', 'count-digits',\n       'count-letters']]\n\n#Target Variable\ny = df['type_code']","775bf353":"X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2,shuffle=True, random_state=5)","7ffd5f56":"lgb = LGBMClassifier(objective='multiclass',boosting_type= 'gbdt',n_jobs = 5, \n          silent = True, random_state=5)\nLGB_C = lgb.fit(X_train, y_train)\n\n\ny_pred = LGB_C.predict(X_test)\nprint(classification_report(y_test,y_pred))\n\nscore = metrics.accuracy_score(y_test, y_pred)\nprint(\"accuracy:   %0.3f\" % score)","e41e4f3d":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    See full source and example: \n    http:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_confusion_matrix.html\n    \n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","1080e2bf":"cm = metrics.confusion_matrix(y_test, y_pred, labels=[0,1,2,3])\nplot_confusion_matrix(cm,classes=['benign', 'defacement','phishing','malware'])","cd2ad95f":"\nlgb_feature = lgb.feature_importances_\nlgb_feature","b0ca720e":"lgb_features = lgb_feature.tolist()","7194c7ae":"model = xgb.XGBClassifier(n_estimators= 100)\nmodel.fit(X_train,y_train)\ny_pred = model.predict(X_test)\nprint(classification_report(y_test,y_pred))\n\n\nscore = metrics.accuracy_score(y_test, y_pred)\nprint(\"accuracy:   %0.3f\" % score)","f04b2991":"CM=confusion_matrix(y_test,y_pred,labels=[0,1,2,3])\n\nplot_confusion_matrix(cm,classes=['benign', 'defacement','phishing','malware'])","e95ed5f9":"xgb_feature = model.feature_importances_\nxgb_features = xgb_feature.tolist()","4877ee90":"from sklearn.ensemble import GradientBoostingClassifier\ngbdt = GradientBoostingClassifier(n_estimators=100,max_features='sqrt')\ngbdt.fit(X_train,y_train)\ny_pred = gbdt.predict(X_test)\nprint(classification_report(y_test,y_pred))\n\nscore = metrics.accuracy_score(y_test, y_pred)\nprint(\"accuracy:   %0.3f\" % score)","3e23e6c2":"CM=confusion_matrix(y_test,y_pred,labels=[0,1,2,3])\n\nplot_confusion_matrix(cm,classes=['benign', 'defacement','phishing','malware'])","17ea88ca":"gbdt_feature = gbdt.feature_importances_\ngbdt_features = gbdt_feature.tolist()","463bfb13":"cols = X_train.columns\n# Create a dataframe with features\nfeature_dataframe = pd.DataFrame( {'features': cols,\n    \n    'Gradient Boost feature importances': gbdt_features,\n    'XG Boost feature importances': xgb_features,\n    'LGBM feature importances': lgb_features\n                                   \n    })\nfeature_dataframe['mean'] = feature_dataframe.mean(axis= 1) # axis = 1 computes the mean row-wise\nfeature_dataframe.head(3)","7b7f1879":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\ndef plot_feature_importance():\n    tmp = pd.DataFrame({'Feature': X_test.columns, 'Feature importance': feature_dataframe['mean'].values})\n    tmp = tmp.sort_values(by='Feature importance',ascending=False).head(20)\n    plt.figure(figsize = (10,12))\n    plt.title('Average Feature Importance Top 20 Features',fontsize=14)\n    s = sns.barplot(y='Feature',x='Feature importance',data=tmp, orient='h')\n    s.set_xticklabels(s.get_xticklabels(),rotation=90)\n    plt.show()\nplot_feature_importance()","0a25f4e0":"## Feature Engineering","5911e9a1":"## Plotting ensemble Feature Importance"}}