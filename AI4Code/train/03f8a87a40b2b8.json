{"cell_type":{"4b1713a3":"code","99efceae":"code","d1f062fa":"code","7d848c78":"code","88e4b457":"code","945afbfe":"code","210d1cb5":"code","450cd268":"code","e2c4fc57":"code","36326c61":"code","a24ee8c8":"code","a5722f62":"code","b5d0bf4a":"code","d688e31a":"code","9a391c89":"code","2ec70594":"code","bb1d65e4":"code","404fd6f8":"code","8da6ee26":"code","41e01b03":"code","66818834":"code","5783e209":"code","979a55cd":"code","efc855b5":"code","260ec12f":"code","5b3ca87d":"code","71266e23":"code","916ebab3":"code","0727f844":"code","da1cba34":"code","8ef0f7d9":"code","975b5b84":"code","ae98eefb":"code","b57661f0":"code","9cedd593":"code","a014ec0a":"code","7c21418b":"code","fa0fac20":"code","b20a731d":"code","497ef843":"code","5e44d4a9":"code","b332468f":"code","636fc02a":"code","1477a967":"code","19f9c7aa":"code","d161d9f7":"code","f5f2c16c":"code","a4f66d58":"code","40891471":"code","3b6f3e37":"code","ff3a0211":"code","f1a910c9":"code","af0151be":"code","ccecef04":"code","1b103a11":"code","21e36f05":"code","8f6b6e1e":"code","2addc23f":"code","b515d75c":"code","8d819ba9":"code","d87c5776":"code","424bb4c2":"code","ae23c955":"code","44684378":"code","a8c446a7":"code","17710b72":"code","44c1e0c9":"code","311d3064":"code","d38abef7":"code","b787cdee":"code","0a9e94f2":"code","dee53f24":"code","ebd987a8":"code","33ebaa3d":"code","9dc57f0e":"code","98129997":"code","e5749980":"code","e87775cf":"code","9a1db52a":"code","4a7ac85f":"code","3b3c78f7":"code","88b7e649":"code","f3071d80":"code","2501b9bb":"code","dd345446":"code","73da3061":"code","935270a5":"markdown","c5df53b3":"markdown","7fa6c3a7":"markdown","58929987":"markdown","79711780":"markdown","bb27773c":"markdown","eaf09e1b":"markdown","701811c4":"markdown","6c3fce56":"markdown","a0c275c4":"markdown","d6be9f2e":"markdown","110ffe4f":"markdown","aca6d761":"markdown","8b0881ed":"markdown","e6292859":"markdown","1b3e0f2e":"markdown","3165595c":"markdown","fabf3809":"markdown","195dcb50":"markdown","6893940c":"markdown","a3dee475":"markdown","57d5f34d":"markdown","8325bfe0":"markdown","fd229558":"markdown","801c5f95":"markdown","94b72160":"markdown","42260aab":"markdown","c64f311f":"markdown","55b9ebaf":"markdown","36b38fd1":"markdown"},"source":{"4b1713a3":"# libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n# warnings\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# import tensorflow\nimport tensorflow as tf\nfrom tensorflow.keras import layers,Sequential\nfrom tensorflow.keras.layers import Dense\n\n# train and test split\nfrom sklearn.model_selection import train_test_split\n\n# modelling\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom mlxtend.classifier import OneRClassifier\n\n# metrics\nfrom sklearn.metrics import accuracy_score, f1_score,precision_score,recall_score\nfrom sklearn.metrics import precision_recall_curve\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\nfrom sklearn.metrics import matthews_corrcoef\nfrom sklearn.metrics import confusion_matrix\n\n# feature selection \nfrom sklearn.feature_selection import SelectFromModel\n\n# feature ranking\nfrom scipy.stats import mannwhitneyu\nfrom scipy.stats import pearsonr\nfrom scipy.stats import chisquare\nfrom scipy.stats import shapiro\n","99efceae":"df = pd.read_csv(\"..\/input\/dataset\/clinical_records_dataset.csv\")\ndf.head()","d1f062fa":"df.shape","7d848c78":"df.tail()","88e4b457":"df.info()","945afbfe":"df.describe()","210d1cb5":"print(df['DEATH_EVENT'].value_counts())\nprint()\nprint(sns.countplot(x='DEATH_EVENT', data=df))\nplt.show()","450cd268":"plt.figure(figsize=(20,5))\nsns.barplot(x='age',y='creatinine_phosphokinase',data=df,hue='DEATH_EVENT')\nplt.title(\"Creatinine_phosphokinase with respect to ages\", fontsize=15)\nplt.xlabel(\"Age\")\nplt.ylabel(\"creatinine_phosphokinase\")","e2c4fc57":"plt.figure(figsize=(10,10))\nsns.displot(x='age',data=df,hue='DEATH_EVENT',multiple='dodge')\nplt.show();","36326c61":"sns.kdeplot(x='age',data=df,hue='sex' )","a24ee8c8":"sns.countplot(x='sex', data=df,hue='anaemia')","a5722f62":"plt.figure(figsize=(10,5))\nsns.violinplot(x='sex',y='age',data=df,hue='diabetes')\nplt.title(\"Diabetes among different ages and gender\",fontsize=15)\nplt.legend(bbox_to_anchor=(1.18,1.0),title='Diabetes')\nplt.xlabel(\"Sex\",fontsize=10)\nplt.ylabel(\"Age\",fontsize=10)\n\n","b5d0bf4a":"plt.figure(figsize=(10,5))\nsns.catplot(x='sex',y='age',data=df,hue='smoking')\nplt.title(\"Smoking among different ages and gender\",fontsize=15)\nplt.legend(bbox_to_anchor=(1.18,1.0))\nplt.xlabel(\"Sex\",fontsize=10)\nplt.ylabel(\"Age\",fontsize=10)\n","d688e31a":"plt.figure(figsize=(23,10))\nsns.barplot(x='age',y='platelets',data=df,hue='anaemia')\nplt.title(\"Blood Platelets\",fontsize=25)\nplt.legend(bbox_to_anchor=(1.08,1.0),title='anaemia',fontsize=20)\nplt.xlabel(\"Age\",fontsize=20)\nplt.ylabel(\"platelets\",fontsize=20)","9a391c89":"\nplt.figure(figsize=(10,5))\nplt.style.use(\"seaborn\")\nsns.scatterplot(y='ejection_fraction',x='serum_creatinine',data=df,s=200,hue='DEATH_EVENT')\nplt.title(\"Ejection Fraction Versus Serum_Creatinine\",fontsize=15)\n","2ec70594":"# Correlation\ndf_corr = df.corr()\nplt.figure(figsize=(10,7))\nsns.heatmap(df_corr,\n           annot=True,\n           cmap='YlGnBu')\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.show();","bb1d65e4":"sns.pairplot(df,hue='DEATH_EVENT')","404fd6f8":"X = df.drop('DEATH_EVENT',axis=1)\ny = df['DEATH_EVENT']\n\nX.shape, y.shape","8da6ee26":"# split the dataset into training and testing\nX_train, X_test, y_train, y_test = train_test_split(X,y,stratify=y,random_state=42,test_size=0.2)\n\nlen(X_train),len(X_test),len(y_train),len(y_test)","41e01b03":"# Evaluate Preds\ndef evaluate_preds(model,X_train, y_train,X_test,y_test,y_preds):\n    \"\"\"\n    Returns all the evaluation metrics which are used in the paper\n    \n    \"\"\"\n    \n    model = model.fit(X_train,y_train)\n    # calculate accuracy_score\n    accuracy = accuracy_score(y_test,y_preds)\n    \n    # matthews correlation coefficient\n    mat_corrcoe = matthews_corrcoef(y_test,y_preds)\n    \n    # f1_score\n    f1score = f1_score(y_test,y_preds)\n    \n    # precision_recall area under curve\n    precision,recall,_ = precision_recall_curve(y_test,y_preds)\n    precision_recall_auc = auc(recall,precision)\n    \n    # roc curve\n    y_probs =model.predict_proba(X_test)\n    y_probs_positive = y_probs[:,1]\n    \n    # corr\n    cm = confusion_matrix(y_test,y_preds)\n    FP = cm.sum(axis=0) - np.diag(cm)\n    FN = cm.sum(axis=1) - np.diag(cm)\n    TP = np.diag(cm)\n    TN = cm.sum()-(FP+FN+TP)\n    # True Positive rate\n    TPR = TP\/(TP+FN)\n    # True Negative rate\n    TNR = TN\/(TN+FP)\n\n    \n    fpr, tpr, _ = roc_curve(y_test,y_probs_positive)\n    \n    roc_auc= roc_auc_score(y_test,y_probs_positive)\n    \n    return  {\"MCC\"    : mat_corrcoe,\n           \"F1_score\" : f1score,\n           \"Accuracy\" : accuracy,\n           \"TPR\"      : np.mean(TPR),\n           \"TNR\"      : np.mean(TNR),\n           \"PR Auc\"   : precision_recall_auc,\n           \"ROC Curve\": roc_auc}\n        ","66818834":"# DecisonTreeclassifier\nmodel_1 = DecisionTreeClassifier(random_state=42)\n# Fit\nmodel_1.fit(X_train,y_train)\n# y_preds\ny_preds = model_1.predict(X_test)\ny_preds","5783e209":"model_1_results  = evaluate_preds(model=DecisionTreeClassifier(random_state=42),\n                                 X_train = X_train,\n                                 y_train = y_train,\n                                 X_test = X_test,\n                                 y_test = y_test,\n                                 y_preds = y_preds)\nmodel_1_results","979a55cd":"\nmodel_1_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_1_corr,\n           annot=True,\n           cmap='YlGn',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","efc855b5":"# RandomForestClassifier\nmodel_2 = RandomForestClassifier(random_state=42)\n\n# Fit\nmodel_2.fit(X_train, y_train)","260ec12f":"# y_preds\ny_preds=model_2.predict(X_test)\ny_preds","5b3ca87d":"# model_2_results\nmodel_2_results = evaluate_preds(model=RandomForestClassifier(random_state=42),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_2_results","71266e23":"model_2_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_2_corr,\n           annot=True,\n           cmap='winter',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","916ebab3":"model_3 = XGBClassifier(verbose=0)\n# fit\nmodel_3.fit(X_train,y_train)\n# prediction\ny_preds = model_3.predict(X_test)\ny_preds","0727f844":"# model_3_Resuts\nmodel_3_results = evaluate_preds(model=XGBClassifier(random_state=42,verbose=0),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_3_results","da1cba34":"model_3_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_3_corr,\n           annot=True,\n           cmap='tab20b',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","8ef0f7d9":"# model_4\ntf.random.set_seed(42)\nmodel_4 = LogisticRegression(solver='liblinear')\n# fit\nmodel_4.fit(X_train,y_train)\n# y_preds\ny_preds = model_4.predict(X_test)\ny_preds","975b5b84":"# model_4_results\nmodel_4_results = evaluate_preds(model=LogisticRegression(solver='liblinear',random_state=42),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_4_results","ae98eefb":"model_4_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_4_corr,\n           annot=True,\n           cmap='bwr',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","b57661f0":"# model5\nmodel_5 = SVC(kernel='linear')\n# fit\nmodel_5.fit(X_train,y_train)\n# y_preds\ny_preds = model_5.predict(X_test)\ny_preds","9cedd593":"# model_5_results\nmodel_5_results = evaluate_preds(model=SVC(random_state=42,kernel='linear',probability=True),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_5_results","a014ec0a":"model_5_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_5_corr,\n           annot=True,\n           cmap='flag',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","7c21418b":"# model_6\nmodel_6 = SVC(kernel='rbf')\n# fit\nmodel_6.fit(X_train,y_train)\n# y_preds\ny_preds = model_6.predict(X_test)\ny_preds","fa0fac20":"# model_6_results \nmodel_6_results = evaluate_preds(model=SVC(random_state=42,kernel='rbf',probability=True),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_6_results","b20a731d":"model_6_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_6_corr,\n           annot=True,\n           cmap='flag_r',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","497ef843":"# model_7\ntf.random.set_seed(42)\nmodel_7 = GaussianNB()\n# Fit\nmodel_7.fit(X_train,y_train)\n# y_preds\ny_preds = model_7.predict(X_test)\ny_preds","5e44d4a9":"# model_7_results\nmodel_7_results = evaluate_preds(model=GaussianNB(),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_7_results","b332468f":"model_7_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_7_corr,\n           annot=True,\n           cmap='cubehelix',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","636fc02a":"# model_8\ntf.random.set_seed(42)\nmodel_8 = KNeighborsClassifier()\n# fit\nmodel_8.fit(X_train,y_train)\n# y_preds\ny_preds = model_8.predict(X_test)\ny_preds","1477a967":"# model_8_resutls\nmodel_8_results = evaluate_preds(model=KNeighborsClassifier(),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_8_results","19f9c7aa":"model_8_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_8_corr,\n           annot=True,\n           cmap='jet',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","d161d9f7":"# model_9\ninput_shape = (12,)\nmodel_9 = Sequential([\n    layers.BatchNormalization(input_shape=input_shape),\n    layers.Dense(256,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(256,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1,activation='sigmoid')\n])\n# compile\nmodel_9.compile(loss='binary_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy'])\n","f5f2c16c":"# model_9_evaluate\nmodel_9.fit(X_train,y_train,\n            validation_data=(X_test,y_test),epochs=100)\n","a4f66d58":"# y_preds\ny_pred_proba = model_9.predict(X_test)\ny_preds = tf.squeeze(tf.round(y_pred_proba))\ny_preds","40891471":"def evaluate_preds_nn(model,X_train, y_train,X_test,y_test,y_preds):\n    \"\"\"\n    Returns all the evaluation metrics which are used in the paper\n    \n    \"\"\"\n    \n    model = model.fit(X_train,y_train)\n    # calculate accuracy_score\n    accuracy = accuracy_score(y_test,y_preds)\n    \n    # matthews correlation coefficient\n    mat_corrcoe = matthews_corrcoef(y_test,y_preds)\n    \n    # f1_score\n    f1score = f1_score(y_test,y_preds)\n    \n    # precision_recall area under curve\n    precision,recall,_ = precision_recall_curve(y_test,y_preds)\n    precision_recall_auc = auc(recall,precision)\n    \n    # corr\n    cm = confusion_matrix(y_test,y_preds)\n    FP = cm.sum(axis=0) - np.diag(cm)\n    FN = cm.sum(axis=1) - np.diag(cm)\n    TP = np.diag(cm)\n    TN = cm.sum()-(FP+FN+TP)\n    # True Positive rate\n    TPR = TP\/(TP+FN)\n    # True Negative rate\n    TNR = TN\/(TN+FP)\n\n    \n    fpr, tpr, _ = roc_curve(y_test,y_preds)\n    \n    roc_auc= roc_auc_score(y_test,y_preds)\n    \n    return  {\"MCC\"    : mat_corrcoe,\n           \"F1_score\" : f1score,\n           \"Accuracy\" : accuracy,\n           \"TPR\"      : np.mean(TPR),\n           \"TNR\"      : np.mean(TNR),\n           \"PR Auc\"   : precision_recall_auc,\n           \"ROC Curve\": roc_auc}\n        ","3b6f3e37":"# model_9_results\nmodel_9_results = evaluate_preds_nn(model=model_9,\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_9_results","ff3a0211":"model_9_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_9_corr,\n           annot=True,\n           cmap='PuBu',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","f1a910c9":"# model 10\ntf.random.set_seed(42)\nmodel_10 = OneRClassifier()\n\n#fit\nX_train = X_train.values\ny_train = y_train.values\nmodel_10.fit(X_train,y_train)","af0151be":"# y_preds\nX_test = X_test.values\ny_preds = model_10.predict(X_test)\ny_preds","ccecef04":"# model_10_results\ntf.random.set_seed(42)\nmodel_10_results = evaluate_preds_nn(model=OneRClassifier(),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_10_results","1b103a11":"model_10_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_10_corr,\n           annot=True,\n           cmap='ocean',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","21e36f05":"## All model evaluation metrics comparison\ntf.random.set_seed(42)\nmodel_results = pd.DataFrame({\"DecisionTreeClassifier\":model_1_results,\n                             \"RandomForestClassifier\": model_2_results,\n                             \"XGBoost\":model_3_results,\n                             \"Logistic Regression\":model_4_results,\n                             \"SVM(Linear Kernel)\":model_5_results,\n                             \"SVM(Gaussian Kernel)\":model_6_results,\n                             \"Naive Bayes\":model_7_results,\n                             \"KNearestNeighbors\":model_8_results,\n                             \"ArtificialNeuralNetwork\":model_9_results,\n                             \"OneRClassifier\":model_10_results}).T\nmodel_results","8f6b6e1e":"# Sort models by MatthewscorrelationCoefficient(MCC) and plot them\nmodel_results[[\"MCC\"]].sort_values(by=\"MCC\").plot(figsize=(10,7),kind='barh')\nplt.legend(fontsize=14)\nplt.yticks(fontsize=15)\nplt.show();","2addc23f":"model_results.plot(kind='bar')\nplt.legend(bbox_to_anchor=(1.08,1.0),title='Metrics',fontsize=10)","b515d75c":"# model\nmodel = RandomForestClassifier(n_estimators=10000,random_state=42,n_jobs=-1)\n\n# fit\nmodel.fit(X_train,y_train)","8d819ba9":"#print the name and gini importance of each features\nfor feature in zip(df.columns,model.feature_importances_):\n    print(feature)","d87c5776":"# # visualize feature importance\nfeature_dict = dict(zip(df.columns,list(model.feature_importances_)))\nfeature_df = pd.DataFrame(feature_dict,index=[0])\nfeature_df.T.plot.bar(title=\"Feature Importance\",legend=False);","424bb4c2":"# Identify and select most important features\nsfm = SelectFromModel(model, threshold=0.15)\n\n# Train the selector\nsfm.fit(X_train,y_train)","ae23c955":"# Print the names of the most important feature\nfor feature_list_index in sfm.get_support(indices=True):\n    print(df.columns[feature_list_index])","44684378":"serum_creatinine = pearsonr(df.serum_creatinine,df.DEATH_EVENT)\nage = pearsonr(df.age, df.DEATH_EVENT)\nanaemia = pearsonr(df.anaemia, df.DEATH_EVENT)\ncreatinine = pearsonr(df.creatinine_phosphokinase, df.DEATH_EVENT)\ndiabetes= pearsonr(df.diabetes,df.DEATH_EVENT)\nejection_fraction = pearsonr(df.ejection_fraction,df.DEATH_EVENT)\nhigh_bp = pearsonr(df.high_blood_pressure, df.DEATH_EVENT)\nplateles = pearsonr(df.platelets, df.DEATH_EVENT)\nserum_sodium = pearsonr(df.serum_sodium, df.DEATH_EVENT)\nsex = pearsonr(df.sex, df.DEATH_EVENT)\nsmoking = pearsonr(df.smoking, df.DEATH_EVENT)\n\npearsonr_correlation_coefficient = pd.DataFrame({\"Serum creatinine\":serum_creatinine[0],\n                                                \"Ejection fraction \": ejection_fraction[0],\n                                                \"Age\": age[0],\n                                                \"Serum sodium\":serum_sodium[0],\n                                                \"High blodd pressure\":high_bp[0],\n                                                \"Anaemia\":anaemia[0],\n                                                \"Creatinine phosphokinase\":creatinine[0],\n                                                \"Plateles\":plateles[0],\n                                                \"Smoking\":smoking[0],\n                                                \"Sex\":sex[0],\n                                                \"Diabetes\":diabetes[0]},index=['PCC']).T\n\npearsonr_correlation_coefficient","a8c446a7":"pearsonr_correlation_coefficient.plot(kind='bar')","17710b72":"serum_creatinine = chisquare(df['serum_creatinine'])\nage = chisquare(df['age'])\nanaemia = chisquare(df['anaemia'])\ncreatinine = chisquare(df['creatinine_phosphokinase'])\ndiabetes= chisquare(df['diabetes'])\nejection_fraction = chisquare(df['ejection_fraction'])\nhigh_bp = chisquare(df['high_blood_pressure'])\nplateles = chisquare(df['platelets'])\nserum_sodium = chisquare(df['serum_sodium'])\nsex = chisquare(df['sex'])\nsmoking = chisquare(df['smoking'])\n\nchisquare = pd.DataFrame({\"Serum creatinine\":serum_creatinine[1],\n                                                \"Ejection fraction \": ejection_fraction[1],\n                                                \"Age\": age[1],\n                                                \"Serum sodium\":serum_sodium[1],\n                                                \"High blodd pressure\":high_bp[1],\n                                                \"Anaemia\":anaemia[1],\n                                                \"Creatinine phosphokinase\":creatinine[1],\n                                                \"Plateles\":plateles[1],\n                                                \"Smoking\":smoking[1],\n                                                \"Sex\":sex[1],\n                                                \"Diabetes\":diabetes[1]},index=['ChiSauare(p-value)']).T\n\nchisquare","44c1e0c9":"chisquare.plot(kind='bar')","311d3064":"serum_creatinine = shapiro(df.serum_creatinine)\nage = shapiro(df.age)\nanaemia = shapiro(df.anaemia)\ncreatinine = shapiro(df.creatinine_phosphokinase)\ndiabetes= shapiro(df.diabetes)\nejection_fraction = shapiro(df.ejection_fraction)\nhigh_bp = shapiro(df.high_blood_pressure)\nplateles = shapiro(df.platelets)\nserum_sodium = shapiro(df.serum_sodium)\nsex = shapiro(df.sex)\nsmoking =shapiro(df.smoking)\n\nshapiro = pd.DataFrame({\"Serum creatinine\":serum_creatinine[1],\n                                                \"Ejection fraction \": ejection_fraction[1],\n                                                \"Age\": age[1],\n                                                \"Serum sodium\":serum_sodium[1],\n                                                \"High blodd pressure\":high_bp[1],\n                                                \"Anaemia\":anaemia[1],\n                                                \"Creatinine phosphokinase\":creatinine[1],\n                                                \"Plateles\":plateles[1],\n                                                \"Smoking\":smoking[1],\n                                                \"Sex\":sex[1],\n                                                \"Diabetes\":diabetes[1]},index=['Shapiro(p-value)']).T\n\nshapiro","d38abef7":"shapiro.plot(kind='bar')","b787cdee":"_,p_value = mannwhitneyu(df.age,df.DEATH_EVENT)\nprint('Age pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.anaemia,df.DEATH_EVENT)\nprint('Anaemia pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.creatinine_phosphokinase,df.DEATH_EVENT)\nprint('Creatinine_phosphokinase pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.diabetes,df.DEATH_EVENT)\nprint('Diabetes pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.ejection_fraction,df.DEATH_EVENT)\nprint('Ejection Fraction pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.high_blood_pressure,df.DEATH_EVENT)\nprint('High Blood Pressure pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.platelets,df.DEATH_EVENT)\nprint('Platelets pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.serum_creatinine,df.DEATH_EVENT)\nprint('Serum Creatinine pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.serum_sodium,df.DEATH_EVENT)\nprint('Serum Sodium pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.sex,df.DEATH_EVENT)\nprint('Sex pvalue=%.6f' % (p_value))\n_,p_value = mannwhitneyu(df.smoking,df.DEATH_EVENT)\nprint('Smoking pvalue=%.6f' % (p_value))\n\nmann_whiteneyu = pd.DataFrame({\"Serum Creatinine\":0.000000,\n                              \"Ejection Fraction\":0.000000,\n                              \"Age\":0.000000,\n                              \"Serum Sodium\":0.000000,\n                              \"Creatinine_phosphokinase\":0.000000,\n                              \"Platelets\":0.000000,\n                              \"Sex\":0.000000,\n                              \"Anaemia\":0.005386,\n                              \"Diabetes\":0.014107,\n                              \"High Blood Pressure\":0.436468,\n                              \"Smoking\":1.000000}, index=['P-value']).T\nmann_whiteneyu","0a9e94f2":"mann_whiteneyu.plot(kind='bar')","dee53f24":"df.head()","ebd987a8":"X = df[['ejection_fraction','serum_creatinine']]\nX.head()","33ebaa3d":"y = df['DEATH_EVENT']\ny.head()","9dc57f0e":"# Split into training and testing\nX_train, X_test,y_train,y_test = train_test_split(X,y,stratify=y,test_size=0.2,random_state=42)\n\n# check lengths\nlen(X_train), len(X_test),len(y_train),len(y_test)","98129997":"# Random Forest\nmodel_1 = RandomForestClassifier(random_state=42)\n\n# fit\nmodel_1.fit(X_train,y_train)\n\n# y_preds\ny_preds = model_1.predict(X_test)\ny_preds","e5749980":"# model_1_resutls\nmodel_1_results = evaluate_preds(model=RandomForestClassifier(random_state=42),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_1_results","e87775cf":"model_1_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_1_corr,\n           annot=True,\n           cmap='binary',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","9a1db52a":"# GradientBoost\nmodel_2 = XGBClassifier(random_state=42,verbose=0)\n\n# Fit\nmodel_2.fit(X_train,y_train)\n\n# y_preds\ny_preds = model_2.predict(X_test)\ny_preds","4a7ac85f":"# model_2_resutls\nmodel_2_results = evaluate_preds(model=XGBClassifier(random_state=42,verbose=0),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_2_results","3b3c78f7":"model_2_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_2_corr,\n           annot=True,\n           cmap='binary_r',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","88b7e649":"# SVM\nmodel_3 = SVC(random_state=42,kernel='rbf')\n\n# fit\nmodel_3.fit(X_train,y_train)\n\n# y_preds\ny_preds = model_3.predict(X_test)\ny_preds","f3071d80":"# model_3_results\nmodel_3_results = evaluate_preds(model=SVC(kernel='rbf',random_state=42,probability=True),\n                                X_train=X_train,\n                                y_train=y_train,\n                                X_test=X_test,\n                                y_test=y_test,\n                                y_preds=y_preds)\nmodel_3_results","2501b9bb":"model_3_corr = confusion_matrix(y_test,y_preds)\nsns.heatmap(model_3_corr,\n           annot=True,\n           cmap='bone',\n           annot_kws={\"size\":20})\nplt.title(\"Confusion Matrix\",fontsize=20)\nplt.xlabel(\"Predicted Labels\",fontsize=15)\nplt.ylabel(\"True Labels\",fontsize=15)\nplt.xticks(fontsize=15)\nplt.yticks(fontsize=15)\nplt.show()","dd345446":"# All results\nmodel_results = pd.DataFrame({\"RandomForestClassifier\":model_1_results,\n                             \"XGBClassifier\":model_2_results,\n                             \"SVM with Gaussian Kernel\":model_3_results}).T\nmodel_results","73da3061":"model_results.plot(kind='bar')\nplt.legend(bbox_to_anchor=(1.08,1.0),title='Metrics',fontsize=10)","935270a5":"## Feature Ranking with Biostatistics\n* Mann-Whitney U test.\n* Pearson correlation coefficient.\n* Chi Square test.\n* To compare the distribution of each feature between the two groups (survived individuals and dead patients), plus the Shapiro\u2013Wilk test to check the distribution of each feature.\n\n**Pearson Correlation Coefficient.**\n\nThe Pearson correlation coefficient (or Pearson product-moment correlation coefficient, PCC) indicates the linear correlation between elements of two lists, showing the same elements\non different positions. The absolute value of PCC generates a high value (close to 1) if the elements of the two lists have linear correlation, and a low value (close to 0) otherwise.","c5df53b3":"## Import Libraries","7fa6c3a7":"### **DecisionTreeClassifier**","58929987":"### **KNN**","79711780":"## **Feature Ranking**\nFor the feature ranking, two traditional approaches are used in the paper\n\n1. **Biostatistics**.\n2. **Machine Learning**.\n\n\n1.  In **Biostatistics approach** three different approachs are used\n* *Mann-Whitney U test*.\n* *Pearson correlation coefficient*.\n* *Chi Square test*.\n* To compare the distribution of each feature between the two groups (survived individuals and dead    patients), plus the *Shapiro\u2013Wilk test* to check the distribution of each feature.\n\n2. **Machine Learning**\n\n  In this approach, only **Random Forest** is used.","bb27773c":"## **SVM With Linear Kernel**","eaf09e1b":"### **XGBoost**\n    \n","701811c4":"**Statistical quantitative description of the numeric features**\n![Screenshot%20%286%29.png](attachment:Screenshot%20%286%29.png)","6c3fce56":"## Exploratory Data Analysis","a0c275c4":"### **Survival prediction classifiers**\n\nThis part of our analysis focuses on the binary prediction of the survival of the patients in the follow-up period.\n\nTo predict patients survival, we employed ten different methods from different machine learning areas.\n\nThe classifiers include \n\n* One linear statistical method(Linear Regression).\n* Three tree-based methods (Random Forests, One Rule, Decision Tree).\n* One Artificial Neural Network (perceptron).\n* Two Support Vector Machines (Linear and Gaussian radial kernel)\n* One instance-based learning model (K-Nearest Neighbors).\n* One probabilistic classifier (Naive Bayes).\n* An ensemble boosting method (Gradient Boosting).\n\nWe measured the prediction results through \n* **Matthews correlation coefficient(MCC)** : The MCC\ntakes into account the dataset imbalance and generates a\nhigh score only if the predictor performed well both on\nthe majority of negative data instances and on the majority of positive data instances . Therefore, we give\nmore importance to the MCC than to the other confusion\nmatrix metrics, and rank the results based on the MCC\n* **Receiver operating characteristic(ROC) area under curve.**\n* **Precision-recall (PR) area under curve.**\n\n","d6be9f2e":"Clearly, we can see that our dataset is imbalance\n\nPatient Survived is represent as '0'\n\nPatient not survived is represented as '1'","110ffe4f":"###  **RandomForestClassifier**","aca6d761":"Here we can that see that `time`, `ejection_fraction`, `serum_creatinine` have more impact on `death_event`","8b0881ed":"## Methods\n\nThe methods we gonna use\n\n1. Machine Learning methods we used for the binary classification**(Survival prediction Classifier)**.\n2. Biostatistics and machine learning methods we employed for the feature ranking, discarding each patients' follow-up time **(Feature ranking)**.\n3. Survival machine learning prediction on **serum creatinine and ejection fraction alone**\n","e6292859":"### **Artificial Neural Network**","1b3e0f2e":"**Chi-Square Test**\n\n\nThe chi square test (or \u03c72 test) between two features checks how likely an observed distribution is due to chance. A low p-value (close to 0) means that the two features have a strong relation; a high p-value (close to 1) means, instead, that the null hypothesis of independence cannot be discarded.","3165595c":"<div class=\"alert alert-block alert-success\">\n    <h1 align=\"center\">MACHINE LEARNING CAN PREDICT SURVIVAL OF PATIENTS WITH HEART FAILURE FROM SERUM CREATININE AND EJECTION FRACTION ALONE<\/h1>\n\n<\/div>\n","fabf3809":"## Import Dataset\nWe analyzed a dataset containing the medical records of\n299 heart failure patients collected at the Faisalabad Institute of Cardiology and at the Allied Hospital in Faisalabad\n(Punjab, Pakistan), during April\u2013December 2015 \nThe patients consisted of 105 women and 194 men, and\ntheir ages range between 40 and 95 years old \n\n### Data Description\n![Screenshot%20%283%29.png](attachment:Screenshot%20%283%29.png)\n\n**NOTE:**\n* Regarding the features, the creatinine phosphokinase(CPK) states the level of the CPK enzyme in blood . When a muscle tissue gets damaged, CPK flows into the blood. Therefore, high levels of CPK in the blood of a patient might indicate a heart failure or injury.\n* The ejection fraction states the percentage of how much blood the left ventricle pumps out with each contraction.\n* The serum creatinine is a waste product generated by creatine, when a muscle breaks down. Especially, doctors focus on serum creatinine in blood to check kidney function. If a patient has high levels of serum creatinine, it may indicate renal dysfunction \n\n**Statistical quantitative description of the category features**\n\n","195dcb50":"### SVM with Gaussian Kernel","6893940c":"### **LogisticRegression**","a3dee475":"## Survival machine learning prediction on serum creatinine and ejection fraction alone\n\nTo investigate if machine learning can precisely predict  patients survival by using the top two ranked features alone. They therefore elaborated another computational pipeline with an initial phase of feature ranking, followed by a binary classification phase based on the top two features selected.\n\nAll the different methods employed for feature ranking identified serum creatinine and ejection fraction as the top two features.So we then performed a survival prediction on these two\nfeatures by employing three algorithms: \n* Random Forests\n* Gradient Boosting \n* SVM radial.","57d5f34d":"The parameters taken by `pearsonr` are two, we have passed 0 index to different feature columns and 1 index is Death_event column","8325bfe0":"**Mann-Whitney U Test**\n\n\nThe Mann\u2013Whitney U test (or Wilcoxon rank\u2013sum test), applied to each feature in relation to the death\nevent target, detects whether we can reject the null hypothesis that the distribution of the each feature for the groups of samples defined by death event are the same. A low p-value of this test (close to 0) means that the analyzed feature strongly relates to death event, while a high\np-value (close to 1) means the opposite","fd229558":"This is paper take from BMC:https:\/\/bmcmedinformdecismak.biomedcentral.com\/\n\n## **BACKGROUND**\n\n**Cardiovascular diseases** kill approximately 17 million people globally every year, and they mainly\nexhibit as myocardial infarctions and heart failures. Heart failure (HF) occurs when the heart cannot pump enough\nblood to meet the needs of the body.\n\nAvailable electronic medical records of patients quantify symptoms, body features, and clinical laboratory test values,\nwhich can be used to perform biostatistics analysis aimed at highlighting patterns and correlations otherwise\nundetectable by medical doctors. \n\nMachine learning, in particular, can predict patients\u2019 survival from their data and can\nindividuate the most important features among those included in their medical records.\n\n## **METHODS**\n\nIn this paper, we analyze a dataset of 299 patients with heart failure collected in 2015. We apply several\nmachine learning classifiers to both predict the patients survival, and rank the features corresponding to the most\nimportant risk factors. \n\nWe also perform an alternative feature ranking analysis by employing traditional biostatistics\ntests, and compare these results with those provided by the machine learning algorithms. \n\nSince both feature ranking approaches clearly identify **serum creatinine** and **ejection fraction** as the two most relevant features, we then build the machine learning survival prediction models on these two factors alone.\n\n## **RESULTS**\n\nOur results of these two-feature models show not only that **serum creatinine** and **ejection fraction** are\nsufficient to predict survival of heart failure patients from medical records, but also that using these *two features alone\ncan lead to more accurate predictions than using the original dataset features in its entirety*. We also carry out an\nanalysis including the follow-up month of each patient: even in this case, **serum creatinine** and **ejection fraction** *are\nthe most predictive clinical features of the dataset, and are sufficient to predict patients\u2019 survival*.\n\n\n## **KEYWORDS**\n\n#### **CARDIOVASCULAR HEART DISEASES**\n\nCardiovascular disease(CVD) is a class of diseases that involve the heart or blood vessels. CVD includes **coronary artery diseases(CAD)** such as **angina** and **myocardial infarction**(commonly known as a heart attack).\nOther CVDs include\n   * Stroke\n   * Heart Failure\n   * Hypertensive Heart Disease\n   * Rheumatic Heart Disease.\n   * Cardiomyopathy.\n   * Abnormal Heart Rhythms.\n   * Congenital Heart Disease.\n   * Valvular Heart Disease.\n   * Carditis.\n   * Aortic aneurysms.\n   * Peripheral Artery Disease.\n   * Thromboembolic Disease.\n   * Venous Thrombosis.\n\n### **HEART FAILURE**\n\nHeart failure (HF), also known as **congestive heart failure (CHF)** and **congestive cardiac failure (CCF)**, is a set of manifestations caused by the failure of the heart's function as a pump supporting the blood flow through the body; its signs and symptoms result from a structural and\/or functional abnormality of the heart, that disrupts its filling with blood or its ejecting of it during each heart beat.\n\nSigns and symptoms of heart failure commonly include shortness of breath, excessive tiredness, and leg swelling. The shortness of breath is usually worse with exercise or while lying down, and may wake the person at night.A limited ability to exercise is also a common feature.Chest pain, including angina, does not typically occur due to heart failure\n\n### **SERUM CREATININE**\n\nDiagnostic **serum creatinine** studies are used to determine renal function.The reference interval is 0.6\u20131.3 mg\/dL (53\u2013115 \u03bcmol\/L).Measuring serum creatinine is a simple test, and it is the most commonly used indicator of renal function.\n\nA rise in blood creatinine concentration is a late marker, observed only with marked damage to functioning **nephrons**. \n\nTherefore, this test is unsuitable for detecting early-stage kidney disease. A better estimation of kidney function is given by calculating the *estimated glomerular filtration rate (eGFR)*. eGFR can be accurately calculated without a 24-hour urine collection using serum creatinine concentration and some or all of the following variables: sex, age, weight, and race, as suggested by the American Diabetes Association. Many laboratories will automatically calculate eGFR when a creatinine test is requested.\n\n**NOTE: The original dataset article unfortunately\ndoes not indicate if any patient had primary kidney dis\u0002ease, and provides no additional information about what\ntype of follow-up was carried out.**\n\n### **EJECTION FRACTIOIN**\n\nAn ejection fraction (EF) is the volumetric fraction (or portion of the total) of fluid (usually blood) ejected from a chamber (usually the heart) with each contraction (or heartbeat). Thus understood, ejection fraction may be used to measure a fluid of any viscosity discharged from a hollow organ to another cavity or outside of the body. Blood, bile and urine are commonly studied under this mathematical platform. \n\nFor example, it may refer to the cardiac *atrium*, *ventricle*,*gall bladder*, or *leg veins*,although if unspecified it usually refers to the left ventricle of the heart. \n\n**EF is widely used as a measure of the pumping efficiency of the heart and is used to classify heart failure types. It is also used as an indicator of the severity of heart failure, although it has recognized limitations**.\n\nThe EF of the left heart, known as the **left ventricular ejection fraction (LVEF)**, is calculated by dividing the volume of blood pumped from the left ventricle per beat (stroke volume) by the volume of blood collected in the left ventricle at the end of diastolic filling (end-diastolic volume). LVEF is an indicator of the effectiveness of pumping into the systemic circulation. \n\nThe EF of the right heart, or **right ventricular ejection fraction (RVEF)**, is a measure of the efficiency of pumping into the pulmonary circulation. A heart which cannot pump sufficient blood to meet the body's requirements (i.e., heart failure) will often, but not invariably, have a reduced ventricular ejection fraction.\n\n","801c5f95":"![Screenshot%20%285%29.png](attachment:Screenshot%20%285%29.png)","94b72160":"### Feature Ranking With Random Forest\nFeature importance is another way of asking, \"Which features contributed most to the outcomes of the model and how did they contribute?\"\n\nFinding feature importance is different for each machine learning model. One way to find feature importance is to search for \"(MODEL NAME) feature importance\".\n\nLet's find the feature importance for our RandomForest model.","42260aab":"### **OneRuleClassifier**","c64f311f":"**Shapiro**\n\nThe Shapiro\u2013Wilk test to check the distribution of each feature (to assess if was feature was extracted from a normal distribution).","55b9ebaf":"### **Naive Bayes**","36b38fd1":"All columns are in all in numerical dtype and there are no missing values in the dataset"}}