{"cell_type":{"a14ef6f4":"code","ad7a83c5":"code","6e42ecba":"code","7104f6ca":"code","d1da029c":"code","f88806d7":"code","8f26be7e":"code","7b045057":"code","c30ed66b":"code","d97edff4":"code","f87dbd7c":"code","653531d9":"code","5f42521f":"code","b00e5019":"code","889d9c85":"code","e5440926":"code","cba32cb0":"code","149688fa":"code","9340abb0":"code","ec49dc21":"code","c25d7580":"code","c593f4a0":"code","b5cf2dba":"markdown","a37506ac":"markdown","6e7f6439":"markdown"},"source":{"a14ef6f4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","ad7a83c5":"train = pd.read_csv('..\/input\/train.csv')\ntrain.head()","6e42ecba":"train['Age'].isnull()","7104f6ca":"#Apart from using this function to fill up the missing values we can use;\n#from sklearn.impute import SimpleImputer\n#my_imputer = SimpleImputer()\n#data_with_imputed_values = my_imputer.fit_transform(original_data)\ndef impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37 #using pandas mean function or seaborn box plot \n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age","d1da029c":"train['Age'] = train[['Age','Pclass']].apply(impute_age,axis=1)","f88806d7":"Dsex = pd.get_dummies(train['Sex'],drop_first=True) #get dummies method of pandas to convert categorical variable into dummy\/indicator variables.\nDembark = pd.get_dummies(train['Embarked'],drop_first=True) #drop_first to drop first column.\n","8f26be7e":"train.head(5)","7b045057":"train['Age'].isnull()","c30ed66b":"train.drop(['PassengerId','Cabin','Sex','Embarked','Name','Ticket'],axis=1,inplace=True)","d97edff4":"train.head(1)","f87dbd7c":"train = pd.concat([train,Dsex,Dembark],axis=1)","653531d9":"train.head(1)","5f42521f":"X=train.drop(['Survived'],axis=1)\ny=train['Survived']","b00e5019":"from sklearn.model_selection import train_test_split","889d9c85":"X_train, X_test, y_train, y_test = train_test_split(train.drop('Survived',axis=1), \n                                                    train['Survived'], test_size=0.50, \n                                                    random_state=101)","e5440926":"from sklearn.linear_model import LogisticRegression","cba32cb0":"lm = LogisticRegression()\nlm.fit(X_train,y_train)","149688fa":"predictions = lm.predict(X_test)","9340abb0":"ML = pd.DataFrame(predictions)","ec49dc21":"ML #The Predictions","c25d7580":"from sklearn.metrics import confusion_matrix","c593f4a0":"confusion_matrix(y_test,predictions)","b5cf2dba":"LogisticRegression","a37506ac":"Using Logistic Regression\/Binary Classification for Predictions...\n\n\n\nStay Connected!\n\nANKIT\u62c9\u5c14\u592b ","6e7f6439":"Using Pandas library to read the data as DataFrame."}}