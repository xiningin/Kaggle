{"cell_type":{"427ff935":"code","7c019f88":"code","93497641":"code","1fdf28f8":"code","dfd40a17":"code","7a0f09fd":"code","09f91c55":"code","87200b35":"code","8848e9fd":"code","0bb37dc8":"code","7448142a":"code","a42fc396":"code","17407a2e":"code","d1a5d5aa":"code","3befb4c1":"markdown","51c6fa5d":"markdown","5a5ed548":"markdown","680b5274":"markdown","7e4b4fdc":"markdown","b6de0190":"markdown","454c3bb1":"markdown","ef9c9f88":"markdown"},"source":{"427ff935":"import numpy as np\nimport pandas as pd\nimport torch\nimport torch.nn as nn\nimport torch.nn.parallel\nimport torch.optim as optim\nimport torch.utils.data\nfrom torch.autograd import variable\nimport matplotlib.pyplot as plt","7c019f88":"path = '..\/input\/movielens-100k-dataset\/ml-100k\/'","93497641":"training_set = pd.read_csv(path + 'u1.base', delimiter = '\\t')\ntraining_set = np.array(training_set, dtype = 'int')\n\ntest_set = pd.read_csv(path + 'u1.test', delimiter = '\\t')\ntest_set = np.array(test_set, dtype = 'int')","1fdf28f8":"nb_users = int(max(max(training_set[:,0]), max(test_set[:,0])))\nnb_movies = int(max(max(training_set[:,1]), max(test_set[:,1])))","dfd40a17":"def convert(data):\n    new_data = []\n    for id_users in range(1, nb_users+1):\n        id_movies = data[:,1][data[:,0] == id_users]\n        id_ratings = data[:,2][data[:,0] == id_users]\n        ratings = np.zeros(nb_movies)\n        ratings[id_movies - 1] = id_ratings\n        new_data.append(list(ratings))\n    return np.array(new_data)","7a0f09fd":"training_set = torch.FloatTensor(convert(training_set))\ntest_set = torch.FloatTensor(convert(test_set))","09f91c55":"# convert likes\n# 1 - like, 0 - dislike\ndef convert_likes(df):\n    df[df == 0] = -1\n    df[df == 1] = 0\n    df[df == 2] = 0\n    df[df >=3 ] = 1\n    return df","87200b35":"training_set = convert_likes(training_set)\ntest_set = convert_likes(test_set)","8848e9fd":"class RBM():\n    def __init__(self, nv, nh):\n        self.W = torch.randn(nv, nh)\n        self.a = torch.randn(1, nh)\n        self.b = torch.randn(1, nv)\n        \n    def sample_h(self, x):\n        wx = torch.mm(x, self.W)\n        activation = wx + self.a.expand_as(wx)\n        p_h_given_v = torch.sigmoid(activation)\n        return p_h_given_v, torch.bernoulli(p_h_given_v)\n    \n    def sample_v(self, y):\n        wy = torch.mm(y, self.W.t())\n        activation = wy + self.b.expand_as(wy)\n        p_v_given_h = torch.sigmoid(activation)\n        return p_v_given_h, torch.bernoulli(p_v_given_h)\n    \n    def train(self, v0, vk, ph0, phk, lr=0.01):\n        self.W += lr * torch.mm(v0.t(), ph0) - torch.mm(vk.t(), phk)\n        self.b += lr * torch.sum((v0 - vk), 0)\n        self.a += lr * torch.sum((ph0 - phk), 0)","0bb37dc8":"nv = len(training_set[0])\nnh = 16\nbatch_size = 16\nrbm = RBM(nv, nh)","7448142a":"nb_epoch = 100\nlr = 0.03\nlosses = []\n\nfor epoch in range(1, nb_epoch + 1):\n    \n    train_loss = 0\n    epoch_loss = []\n    s = 0.\n    \n    for id_user in range(0, nb_users - batch_size, batch_size):\n        \n        vk = training_set[id_user:id_user+batch_size]\n        v0 = training_set[id_user:id_user+batch_size]\n        \n        ph0,_ = rbm.sample_h(v0)\n        for k in range(10):\n            _,hk = rbm.sample_h(vk)\n            _,vk = rbm.sample_v(hk)\n            vk[v0<0] = v0[v0<0]\n            \n        phk,_ = rbm.sample_h(vk)\n        rbm.train(v0, vk, ph0, phk, lr)\n        \n        train_loss += torch.mean(torch.abs(v0[v0>=0] - vk[v0>=0]))\n        epoch_loss.append(train_loss\/s)\n        s += 1.\n        \n    losses.append(epoch_loss[-1])\n    if(epoch % 10 == 0):\n        print('Epoch:{0:4d} Train Loss:{1:1.4f}'.format(epoch, train_loss\/s))","a42fc396":"def plot(losses):\n    plt.figure(figsize=(7, 7))\n    plt.title('Losses per epochs')\n    plt.xlabel(\"Epochs\")\n    plt.ylabel(\"Loss\")\n    plt.plot(losses)","17407a2e":"plot(losses)","d1a5d5aa":"test_loss = 0\ns = 0.\nfor id_user in range(nb_users):\n    v = training_set[id_user:id_user+1]\n    vt = test_set[id_user:id_user+1]\n    if len(vt[vt>=0]) > 0:\n        _,h = rbm.sample_h(v)\n        _,v = rbm.sample_v(h)\n        test_loss += torch.mean(torch.abs(vt[vt>=0] - v[vt>=0]))\n        s += 1.\nprint('Test loss: '+str(test_loss\/s))","3befb4c1":"![rbm.png](attachment:rbm.png)","51c6fa5d":"<h1 align=center style='color: blue; border: 1px dotted blue'>Restricted Boltzman Machine<\/h1>","5a5ed548":"# Training","680b5274":"# Restricted Boltzmann Machine Model","7e4b4fdc":"# Analyze Trained Data","b6de0190":"# Reference\n\n[Deep Learning Objective Book](https:\/\/www.amazon.com\/dp\/1070238945)","454c3bb1":"# Definition\n\nBoltzmann Machine was first invented in 1985 by Geoffrey Hinton, a professor at the University of Toronto. He is a leading figure in the deep learning community and is referred to by some as the \u201cGodfather of Deep Learning\u201d.\n\n\u00b7 Boltzmann Machine is a generative unsupervised model, which involves learning a probability distribution from an original dataset and using it to make inferences about never before seen data.\n\n\u00b7 Boltzmann Machine has an input layer (also referred to as the visible layer) and one or several hidden layers (also referred to as the hidden layer).","ef9c9f88":"# Prepare Data"}}