{"cell_type":{"8fec28ef":"code","97d012aa":"code","069185ed":"code","471cea0c":"code","0b55c8e7":"code","8aa1a26a":"code","7392cab4":"code","3d51a6bb":"code","57b6a33e":"code","50f7649e":"code","470e9d6f":"code","0cca91ea":"code","8fbaed75":"code","d965b55c":"code","a378f243":"code","b3a4efc2":"code","9ad8cba7":"markdown"},"source":{"8fec28ef":"import pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score,recall_score,accuracy_score,roc_auc_score,roc_curve\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nimport numpy as np\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nplt.style.use('seaborn-colorblind')\n\nimport os\nprint(os.listdir(\"..\/input\"))","97d012aa":"df = pd.read_csv(\"..\/input\/bank-additional-full.csv\",sep=';')\ndata =  df.copy()\ndf.head()","069185ed":"X_label = LabelEncoder()\n\ndf['job'] = X_label.fit_transform(df['job'])\ndf['marital'] = X_label.fit_transform(df['marital'])\ndf['education'] = X_label.fit_transform(df['education'])\ndf['default'] = X_label.fit_transform(df['default'])\ndf['housing'] = X_label.fit_transform(df['housing'])\ndf['loan'] = X_label.fit_transform(df['loan'])\ndf['contact'] = X_label.fit_transform(df['contact'])\ndf['month'] = X_label.fit_transform(df['month'])\ndf['day_of_week'] = X_label.fit_transform(df['day_of_week'])\ndf['poutcome'] = X_label.fit_transform(df['poutcome'])\ndf.head()","471cea0c":"\ny = (pd.get_dummies(data['y'], columns = ['y'], prefix = 'y', drop_first = True)).values\ntype(y)\ny[:5]\ny = np.ravel(y)\ny[:4]","0b55c8e7":"df.drop(columns=['y'],inplace=True)\ndf.head()","8aa1a26a":"df.dtypes","7392cab4":"X_train,X_valid,y_train,y_valid = train_test_split(df,y,test_size=0.3,random_state=42)","3d51a6bb":"print('Shape of Training set : ' , [X_train.shape,y_train.shape])\nprint('Shape of Validation set : ' , [X_valid.shape,y_valid.shape])","57b6a33e":"log_clf = LogisticRegression().fit(X_train,y_train)\n\nlog_pred = log_clf.predict(X_valid)\n\nprint('Training score : ' , log_clf.score(X_train,y_train))\nTraining_score_log = log_clf.score(X_train,y_train)\n \nprint('Validation score : ' , round(log_clf.score(X_valid,y_valid),2))\nValidation_score_log = log_clf.score(X_valid,y_valid)\n\nprint(\"Accuracy:\",accuracy_score(y_valid, log_pred))\nAccuracy_log = accuracy_score(y_valid, log_pred)\nprint(\"Precision:\",precision_score(y_valid, log_pred))\nPrecision_log = precision_score(y_valid, log_pred)\nprint(\"Recall:\",recall_score(y_valid, log_pred))\nRecall_log = recall_score(y_valid, log_pred)","50f7649e":"CONFMTX = confusion_matrix(y_valid,log_pred)\nCONFMTX","470e9d6f":"%matplotlib inline\ny_pred_proba  = log_clf.predict_proba(X_valid)[::,1]\nFPR,TPR,threshold = roc_curve(y_valid,y_pred_proba)\nauc_log = roc_auc_score(y_valid,y_pred_proba)\nplt.plot([0,1],[0,1],'o--');\nplt.plot(FPR,TPR,label='data 1, auc='+str(auc_log));\nplt.show()","0cca91ea":"knn_clf = KNeighborsClassifier(n_neighbors=20).fit(X_train,y_train)\n\nknn_pred = knn_clf.predict(X_valid)\n\nprint('Training score : ' , knn_clf.score(X_train,y_train))\nTraining_score_knn = knn_clf.score(X_train,y_train)\n\nprint('Validation score : ' ,(knn_clf.score(X_valid,y_valid)))\nValidation_score_knn = knn_clf.score(X_valid,y_valid)\n\nprint(\"Accuracy:\",accuracy_score(y_valid, knn_pred))\nAccuracy_knn = accuracy_score(y_valid, knn_pred)\n\nprint(\"Precision:\",precision_score(y_valid, knn_pred))\nPrecision_knn = precision_score(y_valid, knn_pred)\n\nprint(\"Recall:\",recall_score(y_valid, knn_pred))\nRecall_knn = recall_score(y_valid, knn_pred)","8fbaed75":"y_pred_proba  = knn_clf.predict_proba(X_valid)[::,1]\nauc_knn = roc_auc_score(y_valid,y_pred_proba)","d965b55c":"tree_clf = DecisionTreeClassifier().fit(X_train,y_train)\n\ntree_pred = tree_clf.predict(X_valid)\n\nprint('Training score : ' , tree_clf.score(X_train,y_train))\nTraining_score_tree = tree_clf.score(X_train,y_train)\n\nprint('Validation score : ' ,(tree_clf.score(X_valid,y_valid)))\nValidation_score_tree = tree_clf.score(X_valid,y_valid)\n\nprint(\"Accuracy:\",accuracy_score(y_valid, tree_pred))\nAccuracy_tree = accuracy_score(y_valid, tree_pred)\n\nprint(\"Precision:\",precision_score(y_valid, tree_pred))\nPrecision_tree = precision_score(y_valid, tree_pred)\n\nprint(\"Recall:\",recall_score(y_valid, tree_pred))\nRecall_tree = recall_score(y_valid, tree_pred)\n\ny_pred_proba  = tree_clf.predict_proba(X_valid)[::,1]\nauc_tree = roc_auc_score(y_valid,y_pred_proba)","a378f243":"rf_clf = RandomForestClassifier().fit(X_train,y_train)\n\nrf_pred = rf_clf.predict(X_valid)\n\nprint('Training score : ' , rf_clf.score(X_train,y_train))\nTraining_score_rf = rf_clf.score(X_train,y_train)\n\nprint('Validation score : ' ,(rf_clf.score(X_valid,y_valid)))\nValidation_score_rf = rf_clf.score(X_valid,y_valid)\n\nprint(\"Accuracy:\",accuracy_score(y_valid, rf_pred))\nAccuracy_rf = accuracy_score(y_valid, rf_pred)\n\nprint(\"Precision:\",precision_score(y_valid, rf_pred))\nPrecision_rf = precision_score(y_valid, rf_pred)\n\nprint(\"Recall:\",recall_score(y_valid, rf_pred))\nRecall_rf = recall_score(y_valid, rf_pred)\n\ny_pred_proba  = rf_clf.predict_proba(X_valid)[::,1]\nauc_rf = roc_auc_score(y_valid,y_pred_proba)","b3a4efc2":"#lets create a dataframe\nModels= pd.DataFrame({'Training_Score':[Training_score_log,Training_score_knn,Training_score_tree,Training_score_rf]\n,'Validation_score' : [Validation_score_log,Validation_score_knn,Validation_score_tree,Validation_score_rf]\n,'Accuracy' : [Accuracy_log,Accuracy_knn,Accuracy_tree,Accuracy_rf]\n,'Precision' : [Precision_log,Precision_knn,Precision_tree,Precision_rf]\n,'Recall' : [Recall_log,Recall_knn,Recall_tree,Recall_rf]\n,'AUC' : [auc_log,auc_knn,auc_tree,auc_rf]},index=['Logistic Regression','KNN','Decision Tree','Random Forest'])\nModels","9ad8cba7":"Now based on the above chart we can decide if we need a model which has more accuracy i.e. it predicts more true positive or we need recall to be high.\nThere are various factor in the above chart which willl help you understand the Models in more broader aspects."}}