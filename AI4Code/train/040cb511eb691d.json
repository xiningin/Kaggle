{"cell_type":{"1b4ddca1":"code","00fbe9a1":"code","5186a45a":"code","caf1c653":"code","52a64f54":"code","4028139e":"code","d6769ffb":"code","9872a3f7":"code","2917fe13":"code","f921968c":"code","8f91bb98":"code","430cbd67":"code","4dc610e2":"code","cce66972":"code","c2ffa0b3":"code","01882d71":"code","65988d10":"code","c2d20d9c":"code","59e2c810":"code","59aef1ec":"code","f995fa18":"code","289767c9":"code","7bf67ac6":"code","4e804d47":"code","8fcd1a95":"code","2bdc0e78":"code","3255e96f":"code","b8525ec8":"markdown","68cdd911":"markdown","46e459f8":"markdown","8266785b":"markdown","4069d5b6":"markdown","66e5993a":"markdown","a83f5c15":"markdown","1494c07a":"markdown","593b60a1":"markdown"},"source":{"1b4ddca1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00fbe9a1":"# IMPORT H2O\nimport h2o","5186a45a":"#Start H2O cluster \nh2o.init()\n","caf1c653":"# Importing H2O AUTOML pacakge \nfrom h2o.automl import H2OAutoML\n","52a64f54":"# Loading data into H2Oframe . \ntrain_path = \"..\/input\/home-data-for-ml-course\/train.csv\"\ntrain_ = h2o.upload_file(path = train_path)\n","4028139e":"#Loading Test dataset \ntest_path = '..\/input\/home-data-for-ml-course\/test.csv'\ntest_ = h2o.upload_file(path = test_path)\n\n","d6769ffb":"Id.head()","9872a3f7":"train_.types","2917fe13":"train_.describe()","f921968c":"# Spliting the dataframe in to 3 parts - train , valid , test .\n# The argument ratios take 2 values for test split ratio and for valid split ratio and rest as test split ratio with all values less 1.0 and summing 1.0\ntrain ,valid , test = train_.split_frame(ratios =[.7,.15])","8f91bb98":"valid.describe()","430cbd67":"# Removing saleprice and id from train_ \ny = 'SalePrice'\nx = train_.columns\nx.remove(y)\nx.remove('Id')\n","4dc610e2":"# Defining our automl model element . \n# max_models will decide maximum no. of models to be trained by automl .\n# exclude_algos will specify which algos to be excluded from trainig \n# verbosity is used to see output to help with debug\n# n_folds is factor for crossvalidation , by default it is 5 \n\naml = H2OAutoML(max_models = 10, seed = 10, exclude_algos = [\"StackedEnsemble\", \"DeepLearning\"], verbosity=\"info\", nfolds=0)","cce66972":"# Training our model \naml.train(x = x, y = y, training_frame = train, validation_frame=valid)","c2ffa0b3":"# defining lb as leaderboard holder . \nlb = aml.leaderboard\n","01882d71":"lb.head()","65988d10":"# Predicting values using leader model i.e GBM \ntest_pred=aml.leader.predict(test)","c2d20d9c":"test_pred.head()","59e2c810":"# Lets check performance of our model . \naml.leader.model_performance(test)\n","59aef1ec":"# Scrapping model ids of from leaderboard \nmodel_ids = list(aml.leaderboard['model_id'].as_data_frame().iloc[:,0])\n","f995fa18":"model_ids","289767c9":"# We can extract any model from the trained models . \nh2o.get_model(model_ids[0])","7bf67ac6":"out = h2o.get_model(model_ids[0])","4e804d47":"out.params","8fcd1a95":"out","2bdc0e78":"out.varimp_plot()","3255e96f":"# Let's save a Mojo binary file which is deployable ready \naml.leader.download_mojo(path = \".\/\")\n","b8525ec8":"# Extracting Models ","68cdd911":"# Conclusion ","46e459f8":"# Defining, training and predicting using our AUTOML model ","8266785b":">In this notebook I will share prediction of house prices using  H2O's AUTOML . H2O\u2019s AutoML is a helpful tool for the advanced user, by providing a simple wrapper function that performs a large number of modeling-related tasks that would typically require many lines of code, and by freeing up their time to focus on other aspects of the data science pipeline tasks such as data-preprocessing, feature engineering and model deployment. I will not discuss feature engineering and data preprocessing as i want to test out performance of AUTOML without any preprocessing and feature engineering . \n\n\n>Consider upvoting if you found this notebook helpful or enjoyed reading it . \n\n### FEATURES OF AUTOML\n* Categorical data encoding conversion\n* Take care of missing value imputation\n* Data cleaning activities \n* Provide nice leaderboard view of the model\n* Allow hyperparameters training\n* Provide confusion matrix , variable importance charts etc\n* Ability to pick any model before and after training \n* Supports GPU for XGBoost mdoel .\n* Deployment ready code (MOJO , POJO , BINARY)","4069d5b6":"### -> **INSTALLING H2O AUTOML**\n\npip install h2o \n","66e5993a":"# Analysing and Saving our Model","a83f5c15":"Our AUTOML Model gives us MAE score of around 17764 which is to be honest not really good . But lets not forget how easy it was to attain this score , saving lot of code , time and errors . Thus given the right parameters , feature enginnering etc automl can really be helpful . If you are a newbiw I recommend you first learn various aspects of machine learning before putting automl into practice as having core concepts will be even more beneficial with automl . \n\nHere follow this [link](http:\/\/docs.h2o.ai\/h2o\/latest-stable\/h2o-docs\/automl.html#) for H2O's AUTOML documentation \n\nThanks for reading . ","1494c07a":"> Here as u can see our automl model trained 10 algorithms with GBM (Gradient boosting machine) providing us the best result .\nAlso as one can see automl trained multiple GBM model but model with id - GBM_1_AutoML_20200824_160621 gave us the best result . ","593b60a1":"# Setting up Enviornment "}}