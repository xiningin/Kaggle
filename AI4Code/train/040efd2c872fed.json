{"cell_type":{"1ce00496":"code","f02e20f4":"code","66bde285":"code","f711de4b":"code","057bff48":"code","65177532":"code","fd4666f7":"code","3775a892":"code","e2ba7a7c":"code","cd45f460":"code","1e9c77ba":"code","54a2c4fb":"code","d7a9af31":"code","911065f7":"code","26b8950c":"code","014fb995":"code","0937fda4":"markdown","86e157d9":"markdown","2a6c6987":"markdown","e5be72f2":"markdown","0552fb19":"markdown","85addd04":"markdown","70ef9fa4":"markdown","3129e228":"markdown"},"source":{"1ce00496":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f02e20f4":"import matplotlib.pyplot as plt\nimport cv2","66bde285":"img = plt.imread('\/kaggle\/input\/face-mask-detection-data\/without_mask\/Faceimg690.jpg')\nplt.imshow(img)","f711de4b":"img0 = plt.imread('\/kaggle\/input\/face-mask-detection-data\/with_mask\/image1,000.jpg')\nplt.imshow(img0)","057bff48":"from keras.preprocessing.image import img_to_array,load_img\nfrom keras.applications.mobilenet_v2 import preprocess_input\nfrom keras.utils import to_categorical\n\nX= []\ny = []\n\nmaskedList = list(os.listdir('..\/input\/face-mask-detection-data\/with_mask\/'))\nunmaskedList = list(os.listdir('..\/input\/face-mask-detection-data\/without_mask\/'))\n\nfor i in maskedList:\n    photo = load_img('..\/input\/face-mask-detection-data\/with_mask\/'+i , target_size=(224,224))\n    photo = img_to_array(photo)\n    X.append(preprocess_input(photo))\n    y.append(1)\n    \nfor i in unmaskedList:\n    photo = load_img('..\/input\/face-mask-detection-data\/without_mask\/'+i,target_size=(224,224))\n    photo = img_to_array(photo)\n    X.append(preprocess_input(photo))\n    y.append(0)\n    \nX = np.asarray(X)\ny = to_categorical(y)","65177532":"from sklearn.model_selection import train_test_split\n\nXtrain,Xtest,ytrain,ytest = train_test_split(X,y,test_size=0.30,random_state=32)","fd4666f7":"from keras.preprocessing.image import ImageDataGenerator\n\naug = aug = ImageDataGenerator(\n    rotation_range=20,\n    zoom_range=0.15,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.15,\n    horizontal_flip=True,\n    fill_mode=\"nearest\")","3775a892":"import keras\nimport tensorflow as tf\nfrom keras.layers import Dense,Conv2D,MaxPool2D,Flatten,Input,Dropout","e2ba7a7c":"basemodel = keras.applications.MobileNetV2(weights = 'imagenet', include_top=False,input_tensor=Input(shape=(224, 224, 3)))","cd45f460":"baseOutput = basemodel.output\nheadModel = MaxPool2D((7,7))(baseOutput)\nheadModel = Flatten()(headModel)\nheadModel = Dense(128,activation='relu')(headModel)\nheadModel = Dropout(.5)(headModel)\nheadModel = Dense(2,activation='softmax')(headModel)\nmodel = keras.Model(inputs = basemodel.input,outputs = headModel)\n\nfor layer in basemodel.layers:\n    layer.trainable = False","1e9c77ba":"model.summary()","54a2c4fb":"from keras.optimizers import Adam\n\ninitLR = 1e-4\nepochs = 20\nbatchSize = 32\n\nclass myCallback(keras.callbacks.Callback): \n    def on_epoch_end(self, epoch, logs=None): \n        if(logs.get('val_accuracy') > 0.98):   \n            print(\"\\nReached %2.2f%% val_accuracy, so stopping training!!\" %(.98*100))   \n            self.model.stop_training = True\n            \nopt = Adam(lr=initLR, decay =initLR\/epochs)\n\nmodel.compile(loss='binary_crossentropy',optimizer=opt,metrics=['accuracy'])\n\nhistory = model.fit(aug.flow(Xtrain,ytrain,batch_size=batchSize),\n                    steps_per_epoch=len(Xtrain)\/\/batchSize,\n                    validation_data=(Xtest,ytest),\n                    validation_steps=len(Xtest)\/\/batchSize,\n                    epochs=epochs,\n                    callbacks=[myCallback()])","d7a9af31":"plt.style.use('ggplot')\nplt.plot(np.arange(1,8),history.history['loss'],label='loss')\nplt.plot(np.arange(1,8),history.history['val_loss'],label='val_loss')\nplt.xlabel('Epochs')\nplt.ylabel('loss')\nplt.legend(loc=\"lower left\")","911065f7":"plt.style.use('ggplot')\nplt.plot(np.arange(1,8),history.history['accuracy'],label='accuracy')\nplt.plot(np.arange(1,8),history.history['val_accuracy'],label='val_accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Accuracy')\nplt.legend(loc=\"lower left\")","26b8950c":"from sklearn.metrics import classification_report\npredIdxs = model.predict(Xtest, batch_size=batchSize)\npredIdxs = np.argmax(predIdxs, axis=1)\nprint(classification_report(ytest.argmax(axis=1), predIdxs))","014fb995":"model.save('masked.h5')","0937fda4":"**Generating a distribution of 70% train and 30% test data split **","86e157d9":"Applying Image augmentation for better judgment in different orientations","2a6c6987":"Importing Essential Libs","e5be72f2":"Declaring Hyper-parameters, optimizer as well as callback to stop training at stop training when a certain validation accuracy is reached to 98%","0552fb19":"**Preprocessing the data to a fixed shape and converting the labels to one-hot encoded vector to remove the significance of class number of masked and unmasked**","85addd04":"Customizing the top layer to generated a customised model from pre-trained one","70ef9fa4":"# Model Architecture","3129e228":"Loading Pre-trained model of MobileNetV2 with the wieghts of image classifier to implement Transfer Learning"}}