{"cell_type":{"31d80ea7":"code","be773428":"code","811b6e36":"code","37463b2f":"code","87f243da":"code","f41c8369":"code","569a754c":"code","989e6b17":"code","8fba4803":"code","112be84e":"code","dc84e8f7":"code","d31606df":"code","c3e927f3":"code","0fa85143":"code","0a3a56ea":"code","2586d029":"code","980bd7e3":"code","60e4f6e2":"code","58f02b78":"code","adc90620":"code","447eda99":"code","212cfb42":"code","6c1d9999":"code","2627dea1":"code","cceb265a":"code","178dc8c4":"code","e3a53c91":"code","5abc4281":"code","832dd64f":"code","5f61d4fd":"code","3b5092e8":"code","4d881c4e":"code","d383fd86":"code","0d211618":"code","743b439c":"code","feca2a95":"code","7012c920":"code","a589a509":"code","9618959d":"code","292892f3":"code","015948f4":"code","b1249226":"code","dd80d9f0":"code","24f28e9e":"code","ffcb18a1":"code","bdba870b":"code","d6971231":"code","31e7100a":"code","25dcd04f":"code","a7196322":"code","6557adb9":"code","89cd3875":"code","268f0ee2":"code","f3543549":"code","02042fe5":"code","5ab9400b":"code","4625fecf":"code","ddad751c":"code","63feb792":"code","ed94f5b8":"code","e03af0ba":"code","e5a3a9f0":"code","4940c561":"code","607597dd":"code","7071ce9f":"code","1578683c":"code","9202ce50":"code","fb7c97ac":"code","da906589":"code","dcf7b879":"code","419baa94":"code","40354760":"code","f4b16281":"code","13e8d2b7":"code","0207750d":"code","66733462":"code","4ab15f4e":"code","0d7f1610":"markdown","c4d4b187":"markdown","07013ed9":"markdown","4199195c":"markdown","12ada04a":"markdown","7b13c545":"markdown","fb40c031":"markdown","7270436f":"markdown","faeaef01":"markdown","42e4e2c2":"markdown","b2c866e2":"markdown","7aff5dd1":"markdown","0e7021d0":"markdown","1664daa6":"markdown","39b0176b":"markdown","97d74ee3":"markdown","96f66d0e":"markdown","e2a52bbb":"markdown","631c1b71":"markdown","35b0bf0e":"markdown","91acc15b":"markdown","ca6b3e93":"markdown","d2976077":"markdown","d916ee6a":"markdown","43549917":"markdown","3726b6cc":"markdown","a1005413":"markdown","8ee7a416":"markdown","c780cf52":"markdown","947c5c82":"markdown"},"source":{"31d80ea7":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.feature_selection import SelectFromModel\nsns.set_theme()","be773428":"# read the training and testing data\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\n\n# read the sample submission file\nsample_sub = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")","811b6e36":"# training data info\ntrain.info()","37463b2f":"# testing data info\ntest.info()","87f243da":"# split features into numerical and categorical features\n\n# numerical features\nnum_feats = ['Survived', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare']\n\n# categorical features\ncat_feats = ['Name', 'Sex', 'Ticket', 'Cabin', 'Embarked']","f41c8369":"# basic descriptive stats for each numerical feature (training data)\ntrain[num_feats].describe()","569a754c":"# visualize distribution for each numerical feature (training data)\n\nfig, axes = plt.subplots(2, 3, figsize=(16, 9))\n\nfor num_feat, ax in zip(num_feats, axes.flatten()):\n    sns.histplot(data=train, x=num_feat, ax=ax)","989e6b17":"# visualize correlation between each numerical features\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.heatmap(\n    data=train[num_feats].corr(),\n    annot=True,\n    fmt='.2f',\n    ax=ax)","8fba4803":"# visualize point estimates (mean) and confidence intervals on Fare and Age per Pclass\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nfor y, ax in zip(['Fare', 'Age'], axes):\n    sns.pointplot(data=train, \n              x='Pclass', \n              y=y,\n              hue='Survived',\n              dodge=True, \n              ax=ax)","112be84e":"# compute for median Fare per Pclass and Survived\nprint('Median Fare per Pclass and Survived:\\n')\nprint(train.groupby(['Pclass', 'Survived'])['Fare'].median())\nprint('-' * 40)\n# compute for median Age per Pclass and Survived\nprint('Median Age per Pclass and Survived:\\n')\nprint(train.groupby(['Pclass', 'Survived'])['Age'].median())","dc84e8f7":"# visualize boxplots of Fare, Age, SibSp, and Parch to detect outliers\nfig, axes = plt.subplots(2, 2, figsize=(16, 9))\n\nfor feat, ax in zip(['Fare', 'Age', 'SibSp', 'Parch'], axes.flatten()):\n    sns.boxplot(data=train, x=feat, ax=ax)","d31606df":"def detect_outliers(df, features):\n    \n    outliers = []\n    for feat in features:\n        \n        # if feature have null values, extract non-null values only.\n        if df[feat].isnull().sum() > 0:\n            df = df[df[feat].notnull()]\n            \n        Q1 = np.percentile(df[feat], 25)\n        Q3 = np.percentile(df[feat], 75)\n        IQR = Q3 - Q1\n        outlier_step = 1.5 * IQR\n        outliers_df = df[(df[feat] < Q1-outlier_step) | (df[feat] > Q3+outlier_step)]\n        \n        print('Feature: {}'.format(feat))\n        print('Lower-bound limit: {}'.format(Q1-outlier_step))\n        print('Upper-bound limit: {}'.format(Q3+outlier_step))\n        \n        died, survived = outliers_df.Survived.value_counts().sort_index(ascending=True)\n        \n        if ((died-survived)\/died) > 0.5:\n            outliers_indeces = outliers_df[outliers_df.Survived == 1].index\n            \n        elif ((survived-died)\/survived) > 0.5:\n            outliers_indeces = outliers_df[outliers_df.Survived == 0].index\n        else:\n            outliers_indeces = []\n            print('No outliers detected.')\n        \n        print('Died: {}'.format(died))\n        print('Survived: {}'.format(survived))\n        print('Outliers: {}'.format(outliers_indeces))\n        outliers.extend(outliers_indeces)\n        print('-' * 40)\n        \n    return set(outliers)","c3e927f3":"# identify outliers in numerical features given\nfeatures = ['Parch', 'SibSp', 'Age', 'Fare']\noutliers = detect_outliers(train, features)","0fa85143":"# identified outliers\ntrain.loc[outliers]","0a3a56ea":"# remove the identified outliers\n\nprint('Old Shape: {}'.format(train.shape))\ntrain.drop(outliers, axis=0, inplace=True)\nprint('New Shape (outlier free): {}'.format(train.shape))","2586d029":"# check new train info\ntrain.info()","980bd7e3":"# check new training (outlier free) descriptive stats \ntrain[num_feats].describe()","60e4f6e2":"# visualize distribution for each numerical feature (training data)\n\nfig, axes = plt.subplots(2, 3, figsize=(16, 9))\n\nfor num_feat, ax in zip(num_feats, axes.flatten()):\n    sns.histplot(data=train, x=num_feat, ax=ax, hue='Survived')","58f02b78":"# visualize new correlation coeff. between each numerical features\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.heatmap(\n    data=train[num_feats].corr(),\n    annot=True,\n    fmt='.2f',\n    ax=ax)","adc90620":"# visualize point estimates (mean) and confidence intervals on Fare and Age per Pclass\n\nfig, axes = plt.subplots(1, 2, figsize=(14, 6))\nfor y, ax in zip(['Fare', 'Age'], axes):\n    sns.pointplot(data=train, \n              x='Pclass', \n              y=y,\n              hue='Survived',\n              dodge=True, \n              ax=ax)","447eda99":"# categorical features basic descriptive stats\ntrain[cat_feats].describe()","212cfb42":"# visualize distribution for each categorical feature (training data)\n\nfig, axes = plt.subplots(1, 4, figsize=(20, 6))\n\nfor cat_feat, ax in zip(['Sex', 'Embarked'], axes[:2]):\n    sns.countplot(data=train, x=cat_feat, ax=ax)\n\nfor cat_feat, ax in zip(['Sex', 'Embarked'], axes[2:]):\n    sns.countplot(data=train, x=cat_feat, hue='Survived', ax=ax) ","6c1d9999":"# visualize survival rate for each categorical feature (Sex and Embarked)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\nfor cat_feat, ax in zip(['Sex', 'Embarked'], axes.flatten()):\n    sns.barplot(data=train, x=cat_feat, y='Survived', ax=ax)\n    ax.set_ylabel('Survival Rate')","2627dea1":"# convert sex and embarked features to numerical features\nnum_feats_df = train[num_feats].copy()\nsex_mappings = {'male': 0, 'female': 1}\nembarked_mappings = {'S':1, 'C':2, 'Q':3}\nnum_feats_df['sex_encoded'] = train['Sex'].apply(lambda x: sex_mappings[x])\nnum_feats_df['embarked_encoded'] = train['Embarked'].apply(lambda x: None if pd.isnull(x) else embarked_mappings[x])\nnum_feats_df.head()","cceb265a":"# visualize new correlation coeff. between each numerical features\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.heatmap(\n    data=num_feats_df.corr(),\n    annot=True,\n    fmt='.2f',\n    ax=ax)","178dc8c4":"# check train data set information\ntrain.info()","e3a53c91":"# visualize null values in train data set\ng = sns.heatmap(train.isnull(),yticklabels=False,cbar=False, cmap='viridis')\ng.figure.set_size_inches(9, 6)","5abc4281":"# check test data set information\ntest.info()","832dd64f":"# visualize null values in train data set\ng = sns.heatmap(test.isnull(),yticklabels=False,cbar=False, cmap='viridis')\ng.figure.set_size_inches(9, 6)","5f61d4fd":"# combine both dataset\ncombine = pd.concat([train, test], axis=0).reset_index(drop=True)\ncombine.head()","3b5092e8":"# total null values for each feature\ncombine.isnull().sum()","4d881c4e":"# visualize mean age difference between pclass values\n\nfig, ax = plt.subplots(figsize=(12, 6))\n\nsns.pointplot(data=combine, x='Pclass', y='Age', ax=ax)","d383fd86":"# Impute Age by mean age per Pclass\navg_age_per_pclass = combine.groupby('Pclass')['Age'].mean()\ndef impute_age(passenger):\n    if pd.isnull(passenger.Age):\n        return round(avg_age_per_pclass.loc[passenger.Pclass], 1)\n    else:\n        return passenger.Age\ncombine['Age'] = combine.apply(impute_age, axis=1)\nprint('Total missing values in Age:', combine.Age.isnull().sum())","0d211618":"# visualize mean Fare difference between pclass values\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.pointplot(data=combine, x='Pclass', y='Fare', ax=ax)","743b439c":"# impute missing fare with mean fare per pclass\navg_fare_pclass = combine.groupby('Pclass')['Fare'].mean()\npclass = combine.loc[combine.Fare.isnull(), 'Pclass'].values \ncombine.Fare.fillna(avg_fare_pclass.loc[pclass].values[0], inplace=True)\nprint('Total missing values in Fare:', combine.Fare.isnull().sum())","feca2a95":"# Check records with missing Embarked value\ncombine[combine.Embarked.isnull()]","7012c920":"# Pclass Column Distribution by Embarked\nfig, axes = plt.subplots(1, 3, figsize=(16, 6))\nsns.countplot(data=combine, x='Embarked', ax=axes[0])\nsns.countplot(data=combine, x='Embarked',  ax=axes[1], hue='Pclass')\nsns.barplot(data=combine, x='Embarked',  y='Survived', ax=axes[2])","a589a509":"# Impute Embarked my modal Embarked value (S) in Upper Class (Class-1)\ncombine.Embarked.fillna('S', inplace=True)\nprint('Total missing values in Embarked:', combine.Fare.isnull().sum())","9618959d":"# final sum of null values for each feature\ncombine.isnull().sum()","292892f3":"# drop name and ticket columns\ncombine.drop(['Name', 'Ticket'], axis=1, inplace=True)","015948f4":"# updated combine dataset info\ncombine.info()","b1249226":"# visualize passenger fare distribution\n\nfig, ax = plt.subplots(figsize=(12, 6))\nsns.histplot(data=combine, x='Fare', kde=True, ax=ax)","dd80d9f0":"# apply log transformation to Fare column to reduce skewness\ncombine.Fare = np.log(combine.Fare + 1)","24f28e9e":"# visualize passenger transformed fare distribution\n\nfig, axes = plt.subplots(1, 2,figsize=(16, 6))\nsns.histplot(data=combine, x='Fare', kde=True, ax=axes[0])\nsns.histplot(data=combine, x='Fare', hue='Survived', kde=True, ax=axes[1])","ffcb18a1":"# visualize cabin distribution (with cabin and no cabin)\n\ncombine['hasCabin'] = combine.Cabin.apply(lambda x: 0 if pd.isnull(x) else 1)\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\nsns.countplot(data=combine, x='hasCabin', hue='Survived', ax=axes[0])\nsns.barplot(data=combine, x='hasCabin', y='Survived', ax=axes[1])","bdba870b":"# calculate family size from SibSp and Parch\ncombine['FamilySize'] = combine['SibSp'] + combine['Parch'] + 1\ncombine[['SibSp', 'Parch', 'FamilySize']].head(10)","d6971231":"# visualize survival rate per FamilySize\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\nsns.countplot(data=combine, x='FamilySize', hue='Survived', ax=axes[0])\nsns.barplot(data=combine, x='FamilySize', y='Survived', ax=axes[1])\naxes[1].set_ylabel('Survival Rate')","31e7100a":"# create isAlone Feature\n\ncombine['isAlone'] = combine['FamilySize'].apply(lambda x: 1 if x == 1 else 0)","25dcd04f":"# visualize survival rate per isAlone\n\nfig, axes = plt.subplots(1, 2, figsize=(12, 6))\n\nsns.countplot(data=combine, x='isAlone', hue='Survived', ax=axes[0])\nsns.barplot(data=combine, x='isAlone', y='Survived', ax=axes[1])","a7196322":"# convert age feature to age bins\ncombine['AgeBinned'] = pd.cut(combine['Age'], 5)\n\n# compute survival rate per AgeBinned\ncombine[['AgeBinned', 'Survived']].groupby('AgeBinned', as_index=False).mean()","6557adb9":"# visualize survival rate per AgeBinned\nfig, axes = plt.subplots(1, 2, figsize=(18, 6))\nsns.countplot(data=combine, x='AgeBinned', hue='Survived', ax=axes[0])\nsns.barplot(data=combine, x='AgeBinned', y='Survived', ax=axes[1])","89cd3875":"# assign ordinals to each age bin\n\ncombine.loc[combine.Age <= 15.336, 'Age'] = 0\ncombine.loc[(combine.Age > 15.336) & (combine.Age <= 30.502), 'Age'] = 1\ncombine.loc[(combine.Age > 30.502) & (combine.Age <=  45.668), 'Age'] = 2\ncombine.loc[(combine.Age > 45.668) & (combine.Age <=   60.834), 'Age'] = 3\ncombine.loc[(combine.Age > 60.834) & (combine.Age <=   76.0), 'Age'] = 4","268f0ee2":"# create the Age*Class feature\ncombine['Age*Class'] = combine['Age'] * combine['Pclass']\ncombine[['Age', 'Pclass', 'Age*Class']].head()","f3543549":"# compute survival rate in Age*Class Feature\ncombine[['Age*Class', 'Survived']].groupby('Age*Class', as_index=False).mean()","02042fe5":"# visualize survival rate per Age*Class\nfig, axes = plt.subplots(1, 2, figsize=(18, 6))\nsns.countplot(data=combine, x='Age*Class', hue='Survived', ax=axes[0])\nsns.barplot(data=combine, x='Age*Class', y='Survived', ax=axes[1])\naxes[1].set_ylabel('Survival Rate')","5ab9400b":"# binning and discretization of Fare feature\n\n# convert fare feature to fare bins\ncombine['FareBinned'] = pd.cut(combine['Fare'], 5)\n\n# compute survival rate per FareBinned\ncombine[['FareBinned', 'Survived']].groupby('FareBinned', as_index=False).mean()","4625fecf":"# visualize survival rate per FareBinned\nfig, axes = plt.subplots(1, 2, figsize=(18, 6))\nsns.countplot(data=combine, x='FareBinned', hue='Survived', ax=axes[0])\nsns.barplot(data=combine, x='FareBinned', y='Survived', ax=axes[1])","ddad751c":"# assign ordinals to each fare bin\n\ncombine.loc[combine.Fare <= 1.248, 'Fare'] = 0\ncombine.loc[(combine.Fare > 1.248) & (combine.Fare <= 2.496), 'Fare'] = 1\ncombine.loc[(combine.Fare > 2.496) & (combine.Fare <=  3.745), 'Fare'] = 2\ncombine.loc[(combine.Fare > 3.745) & (combine.Fare <=   4.993), 'Fare'] = 3\ncombine.loc[(combine.Fare > 4.993) & (combine.Fare <=   6.241), 'Fare'] = 4","63feb792":"# drop unnecessary features\ncombine.drop(['FamilySize', 'AgeBinned', 'FareBinned', 'Cabin', 'SibSp', 'Parch'], axis=1, inplace=True)","ed94f5b8":"# new combine dataset\ncombine.head(10)","e03af0ba":"# apply one-hot encoding to specified columns\ncombine = pd.get_dummies(data=combine, columns=['Sex', 'Embarked'])\ncombine.head()","e5a3a9f0":"# divide combine dataset to training and testing data set\n\ntrain = combine[:len(train)]\ntest = combine[len(train):]","4940c561":"# new train info\ntrain.info()","607597dd":"# new test info\ntest.info()","7071ce9f":"# drop dependent variable (Survived) in test set\ntest.drop('Survived', axis=1, inplace=True)\n\n# convert Survived column in train set integer again\ntrain['Survived'] = train.Survived.astype('int')","1578683c":"# seperate input and output feature\/s in training set\nX_train = train.drop(['PassengerId','Survived'], axis=1)\ny_train = train.Survived\n\n# seperate PassengerId from testing set\nX_test = test.drop('PassengerId', axis=1)","9202ce50":"# apply iterative feature selection\nfrom sklearn.feature_selection import RFE\nselect = RFE(RandomForestClassifier(n_estimators=1000, random_state=42))\nselect.fit(X_train, y_train)\nmask = select.get_support()\nplt.matshow(mask.reshape(1, -1), cmap='gray_r')\nplt.xlabel(\"Sample index\")","fb7c97ac":"# selected features\nselected_features = list(X_train.columns[mask])\nprint('Selected Features: ', selected_features)","da906589":"# update train and test dataset\nX_train = X_train[selected_features]\nX_test = X_test[selected_features]","dcf7b879":"# build preliminary decision tree classifier and apply 10 fold-cross validation\n\nclf_dt = DecisionTreeClassifier(random_state=42)\nscores = cross_val_score(clf_dt, X_train, y_train, cv=10)\ndf = pd.DataFrame(data={'tree': range(10), 'accuracy': scores})\ndf.plot(x='tree', y='accuracy', marker='o', linestyle='--')","419baa94":"# extract available ccp alphas\npath = clf_dt.cost_complexity_pruning_path(X_train, y_train)\nccp_alphas = path.ccp_alphas[:-1]\nprint('Len of ccp_alphas: {}'.format(ccp_alphas.shape))","40354760":"# apply grid search to find optimal value for ccp alpha\nparam_grid = {'ccp_alpha': ccp_alphas}\n\ngrid_search = GridSearchCV(DecisionTreeClassifier(), param_grid, cv=10)\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best Parameters: {}\".format(grid_search.best_params_))\nprint(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))","f4b16281":"# plot results of grid search\nresults = pd.DataFrame(grid_search.cv_results_)\nfig, ax = plt.subplots(figsize=(18, 6))\nresults.plot(x='param_ccp_alpha', y='mean_test_score', \n             yerr='std_test_score', marker='o', linestyle='--', ax=ax)","13e8d2b7":"# train preliminary decision tree with whole training set\nideal_ccp_alpha = grid_search.best_params_['ccp_alpha']\n\nclf_dt = DecisionTreeClassifier(random_state=42, ccp_alpha=ideal_ccp_alpha)\nclf_dt.fit(X_train, y_train)","0207750d":"from sklearn.tree import plot_tree\nplt.figure(figsize=(15, 7.5))\n_ = plot_tree(clf_dt, filled=True, rounded=True, \n          class_names=[\"Didn't Survived\", \"Survived\"],\n         feature_names=X_train.columns)","66733462":"# make predictions in testing set\npredictions = clf_dt.predict(X_test)\npredictions.shape","4ab15f4e":"# Making submission\noutput = pd.DataFrame({'PassengerId': test.PassengerId, 'Survived': predictions})\noutput.to_csv('submission.csv', index=False)\nprint('Output shape:', output.shape)\nprint(\"Your submission was successfully saved!\")","0d7f1610":"#### Numerical Features Analysis","c4d4b187":"### Data Types, Missing Data, and Descriptive Statistics","07013ed9":"## Cost-Complexity Pruning","4199195c":"**Insights:**\n\nFrom the median computation of Fare and Age per Pclass and Survived above, we can see that:\n\n* Even using median as point estimate, a significant difference can be seen between the median Fare of passengers who died and survived (true for Class-1 and Class-2 groups).\n\n* Using median as point estimate, a significant difference of median Age can only be seen in people who survived\/died in Class-1 group. And that now only **slightly significant difference** can be seen in median Age of people survived\/died in Class2-Class3 passengers which signifies that an outlier caused the significant difference between mean Age of passengers who survived\/died for each Pclass group in the last cell.","12ada04a":"## Feature Engineering","7b13c545":"**Insights:**\n\n* Pclass and Fare has a slightly strong correlation with Survived, that is, with Pclass' negative corr. coef. with Survived implies that class-3 passengers are less likely to Survived and with Fare's positive corr.coef with Survived implies that passengers with higher fare are more likely to Survived.\n\n* Pclass and Fare has a strong negative correlation which makes sense as lower class passengers pay lower amount of fare than higher class passengers.\n\n* Age and Pclass has a slightly strong negative corr. coef. which implies that lower class passengers are relatively younger than higher class passengers.","fb40c031":"### Drop and Fill missing values","7270436f":"### Exploratory Data Analysis","faeaef01":"### Separating Input and Output Features","42e4e2c2":"#### Contents:\n* Import Libraries\n* Import and Read Data\n* Data Description\n* Data Types and Missing Data\n* Exploratory Data Analysis\n    - Numerical Features Analysis\n        - Basic Descriptive Statistics\n        - Visualize Distribution (shape and variance)\n        - Correlation\n        - Relationship with the dependent variable\n        - Outliers\n    - Categorical Features Analysis\n        - Basic Descriptive Statistics\n        - Visualize Distribution (count plots)\n        - Feature Interactions\n* Data Preprocessing\n    - Drop and Filling Missing Values\n    - Data Transformation\n    - Feature Engineering\n    - Feature Encoding","b2c866e2":"* Age, Cabin, and Embarked have missing values in training data.\n","7aff5dd1":"## Modeling","0e7021d0":"## Training Final Tree","1664daa6":"## Data Transformation (log transformation)","39b0176b":"## FareBinned Feature","97d74ee3":"## Data Preprocessing","96f66d0e":"### hasCabin Feature","e2a52bbb":"* Age, Cabin, and Fare have missing values in test data.","631c1b71":"## Import and Read Data","35b0bf0e":"### Age_Class Feature  ","91acc15b":"**Insights:**\n\n* Percentage of passengers who died is greater than that of percentage of passengers who survived. (Survived Graph)\n* Most passengers are of type class-3 passengers, followed by class-1, and class-2. (Pclass Graph)\n* Age distribution of passengers approximates a normal distribution with a little peak in the left extremeties which implies that young passengers or children are common passengers aboard along with adult passengers. (Age Graph)\n* Most passengers are alone, that is, passengers don't have a sibling, spouse, parent, and children aboard with them. (SibSp and Parch Graph)\n* Fare distribution follows a positively skewed distribution, implying that few passengers paid relatively higher amount of fare than the rest.(Fare Graph)","ca6b3e93":"## Categorical Feature Analysis","d2976077":"## One-Hot Encoding","d916ee6a":"## Feature Selection","43549917":"## Making Submission","3726b6cc":"### Outlier Detection","a1005413":"### isAlone Feature","8ee7a416":"**Insights:**\n\nAs identified in the correlation matrix in the last cell, (Fare, Pclass) and (Age, Pclass) has a slightly strong relationship. Looking on the point estimates and confidence intervals on Fare and Age per Pclass and their relationship with the dependent variable, we can see that:\n\n* Passengers who survived (especially in Class-1 and Class-2 group) have relatively higher fare than the passengers who died.\n\n* Passengers who survived (true for all Pclass groups) are relatively younger than the passengers who died.","c780cf52":"## Data Description","947c5c82":"## Import Libraries"}}