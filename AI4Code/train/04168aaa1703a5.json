{"cell_type":{"dd468125":"code","fb159a48":"code","94c489f3":"code","398edd27":"code","ba8d1711":"code","d83b2e8a":"code","7566afdd":"code","6d2c0baf":"code","9d11ffe8":"code","98a2d11c":"code","1d2213a5":"code","774fcb38":"code","41edadf4":"code","d8f276e2":"code","541d0b2c":"code","8854fbb1":"code","952c106f":"code","1e801ef6":"code","67e6626f":"code","57609a56":"code","a9d319ed":"code","63471c71":"code","ea9b8960":"code","f95ddbae":"code","682fc84b":"code","df750f5e":"code","1272d53e":"code","d509ecec":"code","47c192d9":"code","b85bd205":"code","518f8749":"code","ce75d163":"code","7ab87d90":"code","d263d0ea":"code","ac4e4216":"code","7915cce0":"code","a08e04c0":"code","04c04983":"code","2c6fe017":"code","41bda211":"code","de02023e":"code","60663dcf":"code","99635d05":"markdown","bfe7b486":"markdown","8c0cf932":"markdown","cf3b2fce":"markdown","d37bcba9":"markdown","1e45dc51":"markdown","edb3a85d":"markdown","3551ebf1":"markdown","a72a25e0":"markdown","b32bfdec":"markdown","42285361":"markdown","8751d2eb":"markdown","721d6ed2":"markdown","ba7dc03d":"markdown","3ab4b2bc":"markdown","237bc150":"markdown","34004c46":"markdown","778f617f":"markdown","7827a3cf":"markdown","af9e3442":"markdown","029b4c14":"markdown","9b42d02f":"markdown","1c861d9f":"markdown","73e11efd":"markdown","e71f7b2f":"markdown","904aa510":"markdown","7f6ae709":"markdown","1d050b6b":"markdown","d60fd870":"markdown"},"source":{"dd468125":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport numpy as np\nimport pandas as pd\nfrom scipy.stats import kurtosis, skew \nfrom scipy import stats\nfrom collections import Counter\nfrom sklearn.pipeline import Pipeline\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Importing librarys to use on interactive graphs\nimport plotly.offline as plty\nfrom plotly import tools\nimport plotly.express as px\nfrom plotly.offline import init_notebook_mode, iplot, plot \nimport plotly.graph_objs as go \n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom sklearn.metrics import fbeta_score\nfrom sklearn.metrics import make_scorer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.dummy import DummyClassifier\nfrom sklearn.preprocessing import PowerTransformer\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.svm import SVC\n\nfrom imblearn.under_sampling import TomekLinks\nfrom imblearn.under_sampling import EditedNearestNeighbours\nfrom imblearn.under_sampling import RepeatedEditedNearestNeighbours\nfrom imblearn.under_sampling import NeighbourhoodCleaningRule\nfrom imblearn.under_sampling import OneSidedSelection\n\n# to set a style to all graphs\nplt.style.use('fivethirtyeight')\ninit_notebook_mode(connected=True)\nsns.set_style(\"whitegrid\")\nsns.set_context(\"paper\")\n%matplotlib inline","fb159a48":"FILE_PATH = '..\/input\/german-credit-history\/german.csv'\ncolumns = ['STATUS_CHECKING_ACCOUNT','DURATION_MONTH','CREDIT_HISTORY','PURPOSE','CREDIT_AMOUNT',\n           'SAVINGS_ACCOUNT','EMPLOYMENT_SINCE','INSTALLMENT_PERCENTAGE_INCOME',\n           'PERSONAL_STATUS_SEX','OTHER_DEBTORS','RESIDENCE_SINCE','PROPERTY','AGE',\n           'INSTALLMENT_PLANS','HOUSING','NUMBER_OF_CREDITS','JOB','NUMBER_OF_DEPENDENTS','TELEPHONE','FOREIGN_WORKER','TARGET']\n\ncredit_df = pd.read_csv(FILE_PATH, header=None, names=columns)\n\ncredit_df.sample(5)","94c489f3":"def preprocess_data():\n    # Replace Target \n    credit_df_one_hot = credit_df.copy()\n    \n    # Remove 'A' from categorical columns\n    for column in credit_df.select_dtypes(include='object').columns:\n        credit_df[column] = credit_df[column].str.replace('A','')\n        credit_df_one_hot.drop([column], axis=1, inplace=True)\n        \n    # One hot encode Categorical columns\n    credit_df_one_hot = pd.concat([pd.get_dummies(credit_df.select_dtypes(include='object'), drop_first=True), credit_df_one_hot], axis=1) \n    \n    return credit_df, credit_df_one_hot","398edd27":"credit_df, dummy_df = preprocess_data()\n\nencode = LabelEncoder()\n\nencoded = encode.fit_transform(credit_df['TARGET'])\n\ncredit_df['TARGET'] = encoded\ndummy_df['TARGET'] = encoded","ba8d1711":"def DataDesc(df):\n    print(f\"Dataset Shape: {df.shape}\")\n    summary = pd.DataFrame(df.dtypes,columns=['dtypes'])\n    summary = summary.reset_index()\n    summary['Name'] = summary['index']\n    summary = summary[['Name','dtypes']]\n    summary['Missing'] = df.isnull().sum().values    \n    summary['Uniques'] = df.nunique().values\n    summary['First Value'] = df.loc[0].values\n    summary['Second Value'] = df.loc[1].values\n    summary['Third Value'] = df.loc[2].values\n\n    for name in summary['Name'].value_counts().index:\n        summary.loc[summary['Name'] == name, 'Entropy'] = round(stats.entropy(df[name].value_counts(normalize=True), base=2),2) \n    \n    return summary","d83b2e8a":"DataDesc(credit_df)","7566afdd":"jobs = credit_df.groupby('JOB')['CREDIT_AMOUNT'].agg(['count','sum','mean']).reset_index()\n\ncolor = [\"#ffa69e\",\"#faf3dd\",\"#b8f2e6\",\"#aed9e0\",\"#5e6472\",'#f6bd60','#84a59d','#f8edeb']\ncustomPalette = sns.set_palette(sns.color_palette(color))\n\nfig = plt.figure(figsize=(12,17))\n\nax1 = fig.add_subplot(311)\n_ = sns.barplot(data=jobs, x='JOB', y='count', palette= customPalette, ax=ax1)\nxlabels = jobs['JOB'].to_list()\nylabels = jobs['count']\n_ = ax1.set_title('Number of Applicants vs Job Type', fontsize=20)\n_ = ax1.set_ylabel('Number of Applicants', fontsize=14)\n_ = ax1.set_xlabel('')\n_ = ax1.set_xticklabels(xlabels, rotation=30, fontsize=10)\n\nax2 = fig.add_subplot(312)\n_ = sns.barplot(data=jobs, x='JOB', y='sum', palette= customPalette, ax=ax2)\nxlabels = jobs['JOB'].to_list()\nylabels = jobs['sum']\n_ = ax2.set_title('Total Amount credited in each Job Category', fontsize=20)\n_ = ax2.set_ylabel('Total Amount', fontsize=14)\n_ = ax2.set_xlabel('')\n_ = ax2.set_xticklabels(xlabels, rotation=30, fontsize=10)\n\nax3 = fig.add_subplot(313)\n_ = sns.barplot(data=jobs, x='JOB', y='mean', palette= customPalette, ax=ax3)\nxlabels = jobs['JOB'].to_list()\nylabels = jobs['mean']\n_ = ax3.set_title('Mean Amount credited by Applicants', fontsize=20)\n_ = ax3.set_ylabel('Mean Credit', fontsize=14)\n_ = ax3.set_xlabel('')\n_ = ax3.set_xticklabels(xlabels, rotation=30, fontsize=10)","6d2c0baf":"job_target = credit_df.groupby(['JOB','TARGET']).size().rename('COUNT').reset_index()\n\n\n\nfig  = px.histogram(job_target, \n              x='JOB', \n              y='COUNT',\n              color='TARGET',\n              color_discrete_sequence=[\"#457b9d\",\"#fca311\"],\n              template='plotly_white')\n\nfig.update_layout(width=900, height=400, \n                  barmode='group',\n                  title= {'text': \"Job Category vs Good\/Bad Customer\",\n                          'y':0.95,'x':0.5,\n                          'xanchor': 'center',\n                          'yanchor': 'top'},\n                 showlegend=True,\n                 margin = dict(l=25, r=10, t=50, b=10))\n                 \n                 \nfig.show()","9d11ffe8":"sum_job = job_target.groupby(['JOB']).sum().reset_index()\n\n\ndef ratio(columns):\n    JOB, TARGET, COUNT = columns[0], columns[1], columns[2]\n    TOTAL = sum_job[sum_job['JOB'] == JOB]['COUNT']\n    RATIO = np.round(COUNT\/TOTAL, 2)\n    return RATIO\n\nX = job_target[['JOB','TARGET','COUNT']].apply(ratio, axis=1)\njob_target['RATIO'] = X.sum(axis=1)","98a2d11c":"fig  = px.histogram(job_target, \n              x='JOB', \n              y='RATIO',\n              color='TARGET',\n              color_discrete_sequence=[\"#457b9d\",\"#fca311\"],\n              template='plotly_white')\n\nfig.update_layout(width=900, height=400, \n                  barmode='group',\n                  title= {'text': \"Job Category vs Good\/Bad Customer RATIO\",\n                          'y':0.95,'x':0.5,\n                          'xanchor': 'center',\n                          'yanchor': 'top'},\n                 showlegend=True,\n                 margin = dict(l=25, r=10, t=50, b=10))\n                 \n                 \nfig.show()","1d2213a5":"_ = sns.FacetGrid(credit_df[['JOB','CREDIT_AMOUNT']],\n               hue='JOB', height=5, aspect=2.5)\\\n  .map(sns.kdeplot, 'CREDIT_AMOUNT', shade=True)\\\n .add_legend()","774fcb38":"age_bad = credit_df.query(\"TARGET == 1\")['AGE']\nage_good = credit_df.query(\"TARGET == 0\")['AGE']\n\n#figure size\nplt.figure(figsize=(10,5))\n\n# Ploting the 2 variables that we create and compare the two\nsns.distplot(age_bad, bins=24, color='#0d3b66')\nsns.distplot(age_good, bins=24, color='#f5dd90')\nplt.title(\"Distribuition of Age\",fontsize=20)\nplt.xlabel(\"Age\",fontsize=15)\nplt.ylabel(\"\")\nplt.show()","41edadf4":"_ = plt.figure(figsize=(12,5))\n\n_ = sns.boxenplot(x=\"TARGET\", y = \"AGE\", \n              data=credit_df, palette=['#436a36','#802c3e']) \n_ = plt.title(\"AGE vs TARGET\", fontsize=20) \n_ = plt.xlabel(\"TARGET\", fontsize=18) \n_ = plt.ylabel(\"AGE\", fontsize=16) \n_ = plt.xticks(fontsize=18)","d8f276e2":"interval = (0, 20, 30, 40, 50, 60) \n\n#Seting the names that we want use to the categorys\ncategories = ['TEEN_AGE', 'ADULT', 'MID_AGED','SENIOR_50', 'SENIOR_60']\n\ncredit_df[\"AGE_CAT\"] = pd.cut(credit_df.AGE, interval, labels=categories) ","541d0b2c":"group = credit_df.groupby(['AGE_CAT','TARGET']).size().rename('Count').reset_index()\n\nfig  = px.histogram(group, \n              x='AGE_CAT', \n              y='Count',\n              color='TARGET',\n              color_discrete_sequence=[\"#457b9d\",\"#fca311\"],\n              template='plotly_white')\n\nfig.update_layout(width=900, height=400, \n                  barmode='group',\n                  title= {'text': \"AGE group Good vs Bad\",\n                          'y':0.95,'x':0.5,\n                          'xanchor': 'center',\n                          'yanchor': 'top'},\n                 showlegend=True,\n                 margin = dict(l=25, r=10, t=50, b=10))\n                 \n                 \nfig.show()","8854fbb1":"total_age = group.groupby('AGE_CAT')['Count'].sum().reset_index()\ndef ratio(columns):\n    AGE_CAT, Count = columns[0], columns[1]\n    TOTAL = total_age[total_age['AGE_CAT'] == AGE_CAT]['Count']\n    RATIO = Count\/TOTAL\n    \n    return np.round(RATIO, 2)\n\ngroup['RATIO'] = np.sum(group[['AGE_CAT','Count']].apply(ratio, axis=1), axis=1)","952c106f":"fig  = px.histogram(group, \n              x='AGE_CAT', \n              y='RATIO',\n              color='TARGET',\n              color_discrete_sequence=[\"#457b9d\",\"#fca311\"],\n              template='plotly_white')\n\nfig.update_layout(width=900, height=400, \n                  barmode='group',\n                  title= {'text': \"AGE Category vs Good\/Bad Customer RATIO\",\n                          'y':0.95,'x':0.5,\n                          'xanchor': 'center',\n                          'yanchor': 'top'},\n                 showlegend=True,\n                 margin = dict(l=25, r=10, t=50, b=10))\n                 \n                 \nfig.show()","1e801ef6":"group = credit_df.groupby(['AGE_CAT','NUMBER_OF_DEPENDENTS']).size().rename('Count').reset_index()\ntotal_dependents = group.groupby('AGE_CAT')['Count'].sum().reset_index()\n\ndisplay(group)\nprint('Total Dependents')\ndisplay(total_dependents)","67e6626f":"import plotly.graph_objs as go\n\nlabels = ['TEEN_AGE', 'ADULT', 'MID_AGED', 'SENIOR_50', 'SENIOR_60']\nouter_values = [16, 395, 315, 161, 68]\ninner_values = [15, 1, 376, 19, 240, 75, 112, 49, 60, 8]\n\n\ntrace1 = go.Pie(\n    hole=0.5,\n    sort=False,\n    direction='clockwise',\n    labels=['T_1','T_2','A_1','A_2','M_1','M_2','S_50_1','S_50_2','S_60_1','S_60_2'],\n    domain={'x': [0.15, 0.85], 'y': [0.15, 0.85]},\n    values=inner_values,\n    textinfo='label',\n    textposition='inside',\n    marker={'line': {'color': 'white', 'width': 1}}\n)\n\ntrace2 = go.Pie(\n    hole=0.7,\n    sort=False,\n    direction='clockwise',\n    values=outer_values,\n    labels=labels,\n    textinfo='label',\n    textposition='outside',\n    marker={'colors': ['green', 'red', 'blue', 'brown'],\n            'line': {'color': 'white', 'width': 1}}\n)\n\nfig = go.FigureWidget(data=[trace1, trace2])\niplot(fig)","57609a56":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.preprocessing import LabelEncoder\n\n\nrf = RandomForestClassifier()\n\nparams = {\n                'max_depth' : [1,2,3,4,5,6],\n               'min_samples_leaf' : [0.01,0.02,0.04,0.06],\n                'max_features' : [0.1,0.2,0.4,0.8],\n                'n_estimators' : [100,150,200,250,300]\n                \n        }\n\nrf_cv = RandomizedSearchCV(estimator=rf,\n                          param_distributions=params,\n                           n_iter=100,\n                          cv=10,\n                          scoring='accuracy',\n                          n_jobs=-1,\n                           verbose=3\n                          )\nX = credit_df.drop(['TARGET','AGE_CAT'], axis=1)\ny = credit_df['TARGET']\n\n\n# Training\nrf_cv.fit(X, y)\n\n\n#Best Estimator\nrf_best = rf_cv.best_estimator_","a9d319ed":"# Get feature importance\nselected_features = X.columns.to_list()\nfeature_importance = pd.DataFrame(selected_features, columns = [\"Feature Label\"])\nfeature_importance[\"Feature Importance\"] = rf_best.feature_importances_\n\n# Sort by feature importance\nfeature_importance = feature_importance.sort_values(by=\"Feature Importance\", ascending=False)\n\n# Set graph style\nsns.set(font_scale = 1)\nsns.set_style({\"axes.facecolor\": \"1.0\", \"axes.edgecolor\": \"0.85\", \"grid.color\": \"0.85\",\n               \"grid.linestyle\": \"-\", 'axes.labelcolor': '0.4', \"xtick.color\": \"0.4\",\n               'ytick.color': '0.4'})\n\n# Set figure size and create barplot\nf, ax = plt.subplots(figsize=(12, 5))\nsns.barplot(x = \"Feature Importance\", y = \"Feature Label\",\n            palette = reversed(sns.color_palette('winter', 15)),  data = feature_importance)\n\n# Generate a bolded horizontal line at y = 0\nax.axvline(x = 0, color = 'black', linewidth = 4, alpha = .7)\n\n# Turn frame off\nax.set_frame_on(False)\n\n# Tight layout\nplt.tight_layout()\n\n# Save Figure\nplt.savefig(\"feature_importance.png\", dpi = 1080)","63471c71":"import eli5 \nfrom eli5.sklearn import PermutationImportance\n\nperm = PermutationImportance(rf_best, random_state=105).fit(X, y)\neli5.show_weights(perm, feature_names = X.columns.to_list())","ea9b8960":"import shap \n\nexplainer = shap.TreeExplainer(rf_best)\nshap_values = explainer.shap_values(X)\n\nshap.summary_plot(shap_values[1], X, plot_type=\"bar\")","f95ddbae":"shap.summary_plot(shap_values[1], X)","682fc84b":"dummy_df.head()","df750f5e":"def f2_measure(y_true, y_pred):\n    return fbeta_score(y_true, y_pred, beta=2)\n\ndef evaluate_model(X, y, model):\n    cv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n    \n    metric = make_scorer(f2_measure)\n    \n    scores = cross_val_score(model, X, y, scoring=metric, cv=cv, n_jobs=-1)\n    return scores","1272d53e":"X = dummy_df.drop('TARGET', axis=1)\ny = dummy_df['TARGET']\n\nmodel = DummyClassifier(strategy='constant', constant=1)\n\n\nscores = evaluate_model(X, y, model)\n\nprint('Mean F2: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n","d509ecec":"def get_models():\n    models, names = list(), list()\n    # LR \n    models.append(LogisticRegression(solver='liblinear')) \n    names.append('LR')\n    # LDA\n    models.append(LinearDiscriminantAnalysis()) \n    names.append('LDA')\n    # NB\n    models.append(GaussianNB())\n    names.append('NB')\n    # GPC\n    models.append(GaussianProcessClassifier()) \n    names.append('GPC')\n    # SVM\n    models.append(SVC(gamma='scale'))\n    names.append('SVM')\n    return models, names","47c192d9":"models, names = get_models()\n\nresults = list()\n\n\nfor i in range(len(models)):\n    \n    pipeline = Pipeline(steps=[('MinMax',MinMaxScaler()),('m',models[i])])\n    \n    scores = evaluate_model(X, y, pipeline)\n    \n    results.append(scores)\n\n    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores))) ","b85bd205":"plt.figure(figsize=(10,5))\n_ = plt.boxplot(results, labels=names, showmeans=True) \n_ = plt.show()","518f8749":"def get_models():\n    models, names = list(), list()\n    \n    models.append(TomekLinks())\n    names.append('TL')\n    \n    models.append(EditedNearestNeighbours()) \n    names.append('ENN')\n     \n    models.append(RepeatedEditedNearestNeighbours()) \n    names.append('RENN')\n    \n    models.append(OneSidedSelection()) \n    names.append('OSS')\n    \n    models.append(NeighbourhoodCleaningRule()) \n    names.append('NCR')\n    \n    return models, names","ce75d163":"models, names = get_models()\nresults = list()\n\n\nfor i in range(len(models)):\n    \n    model = LogisticRegression(solver='liblinear', class_weight='balanced')\n    \n    scaler = MinMaxScaler()\n    X_trans = scaler.fit_transform(X)\n    \n    X_s, y_s = models[i].fit_resample(X_trans, y)\n    \n    scores = evaluate_model(X_s, y_s, model)\n    \n    results.append(scores)\n    \n    # summarize and store\n    print('>%s %.3f (%.3f)' % (names[i], np.mean(scores), np.std(scores)))","7ab87d90":"plt.figure(figsize=(10,5))\n_ = plt.boxplot(results, labels=names, showmeans=True) \n_ = plt.show()","d263d0ea":"from sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\n\npowert = PowerTransformer()\nscaler = MinMaxScaler()\nunder_sample = RepeatedEditedNearestNeighbours()\n\nX_scale = scaler.fit_transform(X)\n#X_t = powert.fit_transform(X_scale)\nX_s, y_s = under_sample.fit_resample(X_scale, y)\n\nX_train, X_test, y_train, y_test = train_test_split(X_s, y_s, test_size=0.1, stratify=y_s, random_state=1)\n\n\nmodel = LogisticRegression(solver='liblinear', class_weight='balanced')\n\n\nc_values = [10000, 1000, 800, 500, 100, 10, 1.0, 0.1, 0.01, 0.001]\ngrid = dict(C=c_values)\n\nmetric = make_scorer(f2_measure)\n\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\n\n\ngrid_search = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, \n                           scoring=metric,error_score=0)\n\ngrid_result = grid_search.fit(X_s, y_s)\n\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\nmeans = grid_result.cv_results_['mean_test_score']\nstds = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']","ac4e4216":"from sklearn.metrics import confusion_matrix, classification_report\n\nbest_model = grid_result.best_estimator_\n\ny_pred = best_model.predict(X_test)\n\nprint(confusion_matrix(y_test, y_pred))\n\nprint(classification_report(y_test, y_pred))","7915cce0":"from sklearn.metrics import roc_curve\n\ny_pred_proba = best_model.predict_proba(X_test)[:,1]\n\nfpr, tpr, thresholds = roc_curve(y_test, y_pred_proba)\ngmeans = np.sqrt(tpr * (1-fpr))\n\n# locate the index of the largest g-mean\nix = np.argmax(gmeans)\n\nprint('Best Threshold=%f, G-mean=%.3f' % (thresholds[ix], gmeans[ix]))","a08e04c0":"plt.figure(figsize=(10,5))\nplt.plot([0,1], [0,1], linestyle='--', label='No Skill') \n\nplt.plot(fpr, tpr, marker='.', label='Logistic') \nplt.scatter(fpr[ix], tpr[ix], marker='o', color='black', label='Best') \n# axis labels\nplt.xlabel('False Positive Rate (1 - Specificity)')\nplt.ylabel('True Positive Rate (Sensitivity)')\nplt.legend()\n# show the plot\nplt.show()","04c04983":"from sklearn.metrics import precision_recall_curve\n\nprecision, recall, thresholds = precision_recall_curve(y_test, y_pred_proba)\n\n#Calculate f-Score\nfscore = (2 * precision * recall) \/ (precision + recall)\n\n# locate the index of the largest g-mean\nix = np.argmax(fscore)\n\nprint('Best Threshold=%f, F-score=%.3f' % (thresholds[ix], fscore[ix]))","2c6fe017":"no_skill = len(y_test[y_test==1]) \/ len(y_test)\n\nplt.figure(figsize=(10,5))\nplt.plot([0,1], [no_skill,no_skill], linestyle='--', label='No Skill') \nplt.plot(recall, precision, marker='.', label='Logistic') \nplt.scatter(recall[ix], precision[ix], marker='o', color='black', label='Best') \n# axis labels\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.legend()\n# show the plot\nplt.show()","41bda211":"import itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n","de02023e":"cnf_matrix = confusion_matrix(y_test, y_pred)\nclass_names = ['-VE','+VE']","60663dcf":"np.set_printoptions(precision=2)\n\n\nplt.figure(figsize=(8,6))\nplot_confusion_matrix(cnf_matrix, classes=class_names, normalize=True, \n                      title='Normalized confusion matrix')","99635d05":"<blockquote>From Above we can see how most of the customers have only 1 dependents. Also majority of the customers are between age group 20 to 40<\/blockquote>","bfe7b486":"Features with High values(Red) that lead to a Bad Customer record(If low value then Good):\n<ol>\n    <li>Duration in Month\n    <li>Credit Amount\n<\/ol>\nFeatures with Low values(Blue) that lead to a Bad Customer Record\n<ol>\n    <li>Status of existing checking account\n        <li>Savings Account\n            <li>Credit History\n                <li>Age\n    <\/ol>\nAbove observations are true to real life instances in Banking System","8c0cf932":"<h3>9.1 RoC AUC<\/h3>","cf3b2fce":"<h3><center>9. Evaluating Model<\/center><\/h3>","d37bcba9":"<h3><center>8. Fitting Final Model<\/center><\/h3>","1e45dc51":"Features that have great impact on TARGET:\n<ol>\n<li>Status of existing checking account\n<li>Duration Month\n<li>Credit Amount\n<li>Credit History\n<li>Savings Account\n<li>Age\n    <\/ol>","edb3a85d":"In this case, we can see that none of the tested models have an F2-measure above the default of predicting the majority class in all cases (0.682). None of the models are skillful. This is surprising, although suggests that perhaps the decision boundary between the two classes is noisy.","3551ebf1":"As we can see, we have tried to maximize the Recall to 90%, having False Negative rates very low","a72a25e0":"<h3>4.3. Shap Analysis<\/h3>","b32bfdec":"<h3>3.1. Exploring Different job categories<\/h3>","42285361":"<h3><center>2. Preprocessing\/Cleaning Data<\/center><\/h3>","8751d2eb":"<blockquote>Distrubition of age in both Good and Bad categories is the same<\/blockquote>","721d6ed2":"<blockquote>No.of Applicaant having Job type-174 are second least but have creditted the highest mean amount. This category reflects the highest paying one<\/blockquote>","ba7dc03d":"<h3><center>7. Evaluating Undersampling<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\nUndersampling is perhaps the least widely used technique when addressing an imbalanced classification task as most of the focus is put on oversampling the majority class with SMOTE. Undersampling can help to remove examples from the majority class along the decision boundary that make the problem challenging for classification algorithms. In this experiment we will test the following undersampling algorithms:\n    <br><br>\n    <ul>\n    <li>Tomek Links (TL)\n    <li>Edited Nearest Neighbors (ENN)\n    <li>Repeated Edited Nearest Neighbors (RENN)\n    <li>One Sided Selection (OSS)\n    <li>Neighborhood Cleaning Rule (NCR)\n    <\/ul><br>\nThe Tomek Links and ENN methods select examples from the majority class to delete, whereas OSS and NCR both select examples to keep and examples to delete. We will use the cost-sensitive version of the logistic regression algorithm to test each undersampling method in an effort to further lift model performance\n<\/div>","3ab4b2bc":"<h3><center>6. Evaluate Machine Learning Algorithms<\/center><\/h3>","237bc150":"<h3><center>3. Exploring Data<\/center><\/h3>","34004c46":"<blockquote>The distribution of Credit amount shows a right skew<\/blockquote>","778f617f":"<h3><center>4. Important Features<\/center><\/h3>","7827a3cf":"<h3>4.1. Feature Importance using Random Forrest Classifier<\/h3>","af9e3442":"<h3><center>5. Model test & Baseline Result<\/center><\/h3>\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\n    We will predict class labels of whether a customer is good or not. Therefore, we need a measure that is appropriate for evaluating the predicted class labels. The focus of the task is on the positive class (bad customers). Precision and recall are a good place to start. Maximizing precision will minimize the false positives and maximizing recall will minimize the false negatives in the predictions made by a model.\n    <br><br>\n    False positives are cases of a good customer being marked as a bad customer and not being given a loan. False negatives are more costly to the bank than false positives.<br><br>\n    <blockquote>Cost(FalseNegatives) > Cost(FalsePositives) <\/blockquote>\nPut another way, we are interested in the F-measure that will summarize a model\u2019s ability to minimize misclassification errors for the positive class, but we want to favor models that are better are minimizing false negatives over false positives. This can be achieved by using a version of the F-measure that calculates a weighted harmonic mean of precision and recall but favors higher recall scores over precision scores. This is called the Fbeta-measure, a generalization of F-measure, where beta is a parameter that defines the weighting of the two scores. A beta value of 2 will weight more attention on recall than precision and is referred to as the F2-measure.\n    <\/div>\n    \n![image.png](attachment:image.png)","029b4c14":"<h3> Categorizing Age<\/h3>","9b42d02f":"<h3>4.2. Permutation Importance<\/h3>","1c861d9f":"<div style=\"font-family:verdana; word-spacing:1.5px;\">\nWe can evaluate a baseline model on the dataset using this test harness. A model that predicts the minority class for examples will achieve a maximum recall score and a baseline precision score. The F2-measure from this prediction provides a baseline in model performance on this problem by which all other models can be compared. This can be achieved using the DummyClassifier class from the scikit-learn library and setting the strategy argument to \u2018constant\u2019 and the constant argument to 1 for the minority class.\n  <\/div>","73e11efd":"<h3><center>German Credit<\/center><\/h3>\n\n![image.png](attachment:image.png)\n\n<ol> Column Descriptions :\n<li>Status of existing checking account\n<li>Duration in month\n<li>Credit history\n<li>Purpose\n<li>Credit amount\n<li>Savings account\n<li>Present employment since\n<li>Installment rate in percentage of disposable income\n<li>Personal status and sex\n<li>Other debtors\n<li>Present residence since\n<li>Property\n<li>Age in years\n<li>Other installment plans\n<li>Housing\n<li>Number of existing credits at this bank \udbff\udc00 Job\n<li>Number of dependents\n<li>Telephone\n<li>Foreign worker\n<\/ol>\n\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\nSome of the categorical variables have an ordinal relationship, such as Savings account, although most do not. There are two outcome classes, 1 for good customers and 2 for bad customers. Good customers are the default or negative class, whereas bad customers are the exception or positive class. A total of 70 percent of the examples are good customers, whereas the remaining 30 percent of examples are bad customers. \n<\/div>\n\n        Good Customers: Negative or majority class (70%).\n        Bad Customers: Positive or minority class (30%).\n\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\nA cost matrix is provided with the dataset that gives a different penalty to each misclas- sification error for the positive class. Specifically, a cost of five is applied to a false negative (marking a bad customer as good) and a cost of one is assigned for a false positive (marking a\ngood customer as bad).\n<\/div>\n\n        Cost for False Negative: 5\n        Cost for False Positive: 1\n\n<div style=\"font-family:verdana; word-spacing:1.5px;\">\nThis suggests that the positive class is the focus of the prediction task and that it is more costly to the bank or financial institution to give money to a bad customer than to not give money to a good customer. This must be taken into account when selecting a performance metric. \n    <\/div>","e71f7b2f":"<h3>3.2. Exploring Age <\/h3>","904aa510":"<h3><center>1. Reading file<\/center><\/h3>","7f6ae709":"<blockquote>Ratio of Good & Bad customers in each category is somewhat same, hence we cannot easily identify the category in which chances of being a bad customer is the highest<\/blockquote>","1d050b6b":"<blockquote>Customers in their 20s & 30s seem to have a bad review from the bank and the ones in their 40s & 50s have a godd relationship with the bank<\/blockquote>","d60fd870":"<h3>9.2. Precision Recall Curve<\/h3>\n"}}