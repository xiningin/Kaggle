{"cell_type":{"91faa995":"code","50c8e937":"code","3058b832":"code","0b8e8f8b":"code","5d1f7e48":"code","fb0133d1":"code","c05606a8":"code","125eba24":"code","730b362b":"code","dc865092":"code","483c926c":"code","c69a043b":"code","1b16eced":"code","10c1f5e5":"code","9fe89ff0":"code","82cbee61":"code","d5563466":"code","f9c7c3f9":"code","b1cdd32e":"code","dae0df17":"code","1fd7821b":"code","0999d6ad":"code","a797808c":"code","b4606650":"code","334ad337":"code","ac5b72fd":"code","4c5b08b4":"code","bf5eddfd":"code","848a1397":"code","f4aeca2a":"code","a76fb7eb":"code","edb6d584":"code","ffd4a95f":"code","eba3f868":"code","24648634":"code","5accde35":"code","32c1daa0":"code","8d1c96fa":"code","0dfccc1a":"code","3d13cde1":"code","1d7ef8a4":"code","a7844f04":"code","00a962e5":"code","fec576df":"code","ba9a8573":"code","0478fdbc":"code","9541731a":"code","f2f78546":"code","565dd23d":"markdown","e70075ba":"markdown","c01f1b0f":"markdown","0002ddc6":"markdown","a4e3deed":"markdown","87bab835":"markdown","2dc41a20":"markdown","4a0f0739":"markdown","5faffdce":"markdown","01a173a4":"markdown","b002b8ff":"markdown","313a9f37":"markdown","1fdda612":"markdown","50bb8350":"markdown","1d1eb090":"markdown","0e033421":"markdown","60ce5904":"markdown","b61544d7":"markdown","8b1bac77":"markdown","ea3b941a":"markdown","95988787":"markdown","995ebe42":"markdown","bd0618a6":"markdown","c908b027":"markdown","cfc6c579":"markdown","a2e960d5":"markdown","316107cd":"markdown","da74a4c9":"markdown","da68a492":"markdown","b52dac5d":"markdown","e16f4a38":"markdown","11147651":"markdown","e6e5e96d":"markdown","8b014279":"markdown","c753a954":"markdown","c3c4406d":"markdown","5421a16e":"markdown"},"source":{"91faa995":"# b\u00e1sico\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\n\n# estat\u00edstica\nfrom scipy import stats # para z-score\n\n# sklearn\nfrom sklearn.pipeline import make_pipeline, Pipeline\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.utils import class_weight\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, StandardScaler, RobustScaler, QuantileTransformer\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.metrics import confusion_matrix, classification_report, precision_recall_curve, roc_curve, roc_auc_score\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV, cross_val_score, train_test_split, cross_val_predict\n\nfrom sklearn.linear_model import RidgeClassifier, LogisticRegression, SGDClassifier, Perceptron, PassiveAggressiveClassifier\n\nfrom sklearn.svm import SVC \nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.gaussian_process import GaussianProcessClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neural_network import MLPClassifier\n\nfrom sklearn.ensemble import BaggingClassifier, RandomForestClassifier, ExtraTreesClassifier, AdaBoostClassifier, GradientBoostingClassifier\n\nfrom sklearn.ensemble import VotingClassifier\nfrom sklearn.ensemble import StackingClassifier\n\nfrom lightgbm import LGBMClassifier\nfrom xgboost import XGBClassifier","50c8e937":"df = pd.read_csv('..\/input\/wine-quality\/winequalityN.csv')","3058b832":"df.head()","0b8e8f8b":"df.info()","5d1f7e48":"df.describe()","fb0133d1":"df.describe(include=['O'])","c05606a8":"df['quality'].value_counts()","125eba24":"df.isnull().sum().sort_values(ascending=False)","730b362b":"null_values_cols = df.isnull().sum().sort_values(ascending=False).index[:7]","dc865092":"df['quality_label'] = df.quality.apply(lambda q: 0 if q <= 5 else 1)\ndf.drop('quality', axis=1, inplace=True)\ndf","483c926c":"fig = go.Figure()\n\nfig.add_trace(\n    go.Histogram(\n        x = df['fixed acidity'],\n        name = 'fixed acidity',\n    )\n)\n\nfor column in df.columns[2:11]:\n    fig.add_trace(\n        go.Histogram(\n            x = df[column],\n            name = column,\n            visible='legendonly'\n        )\n    )\n\nfig.update_layout(barmode='overlay', template='plotly_dark')\nfig.update_traces(opacity=0.75)\nfig.show()","c69a043b":"fig = go.Figure()\n\nfig.add_trace(\n    go.Violin(\n        y = df['fixed acidity'],\n        name = 'fixed acidity',\n        box_visible=True,\n    )\n)\n\nfor column in df.columns[2:11]:\n    fig.add_trace(\n        go.Violin(\n            y = df[column],\n            name = column,\n            box_visible=True,\n            visible='legendonly'\n        )\n    )\n\nfig.update_layout(barmode='overlay', template='plotly_dark',  width=1790,\n    height=800)\nfig.update_traces(opacity=0.75)\nfig.show()","1b16eced":"# z-scores\n\noutliers = df[df.columns[1:10]][(stats.zscore(df[df.columns[1:10]]) > 3)]\noutliers.tail()","10c1f5e5":"outliers.info()","9fe89ff0":"df.corr()","82cbee61":"fig = go.Figure(go.Heatmap(x=df.corr().index, y=df.corr().columns, \n    z=df.corr().values))\nfig.update_layout(template='plotly_dark')\nfig.show()","d5563466":"topCols = np.abs(df.corr()).nlargest(4, 'quality_label')['quality_label'][1:].index\ntopCols","f9c7c3f9":"fig = px.scatter_matrix(df, opacity=0.3, template='plotly_dark', height=2000)\nfig.show()","b1cdd32e":"fig = go.Figure()\n\nfig.add_trace(\n    go.Violin(\n        x = df['quality_label'],\n        y = df['fixed acidity'],\n        name = 'fixed acidity',\n        box_visible=True,\n    )\n)\n\nfor column in df.columns[2:11]:\n    fig.add_trace(\n        go.Violin(\n            x = df['quality_label'],\n            y = df[column],\n            name = column,\n            box_visible=True,\n            visible='legendonly'\n        )\n    )\n\nfig.update_layout(barmode='overlay', template='plotly_dark',  width=1790,\n    height=800)\nfig.update_traces(opacity=0.75)\nfig.show()","dae0df17":"quartils = {'Atributo': [], 'Qualidade': [], 'Quartil25': [], \n            'Quartil50': [], 'Quartil75': []}\n\nfor i in df.columns[1:11]:\n    for j in df['quality_label'].value_counts().index:\n        top = df[i][df['quality_label'] == j]\n        q25, q50, q75 = np.percentile(top.values, [25, 50, 75])\n        quartils['Atributo'].append(i)\n        quartils['Qualidade'].append(j)\n        quartils['Quartil25'].append(q25)\n        quartils['Quartil50'].append(q50)\n        quartils['Quartil75'].append(q75)\n\nquartils = pd.DataFrame(quartils)\nquartils","1fd7821b":"df.drop(outliers.index, inplace=True)","0999d6ad":"train, test = train_test_split(df, test_size=0.2, random_state=0)\ntest","a797808c":"y = train['quality_label']\ntrain.drop(['quality_label'] , axis=1, inplace=True)\nX = train.copy()\ny","b4606650":"numerical_features = train.select_dtypes(exclude=['object']).columns.tolist()\ncategorical_features = train.select_dtypes(include=['object']).columns.tolist()\nnumerical_features","334ad337":"# Num\u00e9rico\nnumerical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median')),\n    ('scaler', StandardScaler())])","ac5b72fd":"# Categ\u00f3rico\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])","4c5b08b4":"# Juntando\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numerical_transformer,   numerical_features),\n        ('cat', categorical_transformer, categorical_features)])","bf5eddfd":"# Pipeline com modelos de aprendizagem lineares\n\npipe_ridge = Pipeline(\n    steps   = [('preprocessor', preprocessor),\n            ('ridge', RidgeClassifier())])  \n  \npipe_logistic = Pipeline(\n    steps  = [('preprocessor', preprocessor),\n            ('logistic', LogisticRegression(random_state=0))])  \n\npipe_SGD = Pipeline(\n    steps  = [('preprocessor', preprocessor),\n            ('SGD', SGDClassifier())])\n\npipe_perceptron = Pipeline(\n    steps   = [('preprocessor', preprocessor),\n            ('perceptron', Perceptron())])\n\npipe_PasAgg = Pipeline(\n    steps   = [('preprocessor', preprocessor),\n            ('PasAgg', PassiveAggressiveClassifier())])\n\nlinear_pipes = [pipe_ridge, pipe_logistic, pipe_SGD, pipe_perceptron, pipe_PasAgg]","848a1397":"# Pipeline com modelos de aprendizagem n\u00e3o lineares\n\npipe_SVM = Pipeline(\n    steps = [('preprocessor', preprocessor),\n            ('SVM', SVC())])\n\npipe_KN = Pipeline(\n    steps = [('preprocessor', preprocessor),\n            ('KN', KNeighborsClassifier())])\n\npipe_tree = Pipeline(\n    steps = [('preprocessor', preprocessor),\n            ('tree', DecisionTreeClassifier())])\n\npipe_MLP = Pipeline(\n    steps = [('preprocessor', preprocessor),\n            ('MLP', MLPClassifier())])\n\nn_linear_pipes = [pipe_SVM, pipe_KN, pipe_tree, pipe_MLP]","f4aeca2a":"# Pipeline com modelos de aprendizagem ensemble\n\npipe_GB = Pipeline(\n    steps = [('preprocessor', preprocessor),\n            ('GB', GradientBoostingClassifier())])\n\npipe_ET = Pipeline(\n    steps = [('preprocessor', preprocessor),\n            ('ET', ExtraTreesClassifier())])\n\npipe_RF = Pipeline(\n    steps = [('preprocessor', preprocessor),\n            ('RF', RandomForestClassifier())])\n\npipe_bagging = Pipeline(\n    steps = [('preprocessor', preprocessor),\n            ('bagging', BaggingClassifier())])\n\npipe_ADA = Pipeline(\n    steps= [('preprocessor', preprocessor),\n            ('ADA', AdaBoostClassifier(DecisionTreeClassifier()))])\n\npipe_LGBM = Pipeline(\n    steps= [('preprocessor', preprocessor),\n            ('LGBM', LGBMClassifier())])\n\npipe_XGB = Pipeline(\n    steps= [('preprocessor', preprocessor),\n            ('XGB', XGBClassifier())])\n\nensemble_pipes = [pipe_GB, pipe_ET, pipe_RF, pipe_bagging, pipe_ADA, pipe_LGBM, pipe_XGB]","a76fb7eb":"# Lineares\n\nfor pipe in linear_pipes:\n    print('Model: ', pipe.steps[1][0])\n    y_pred = cross_val_predict(pipe, X, y, cv=5)\n    print(classification_report(y, y_pred))","edb6d584":"# N\u00e3o lineares\n\nfor pipe in n_linear_pipes:\n    print('Model: ', pipe.steps[1][0])\n    y_pred = cross_val_predict(pipe, X, y, cv=5)\n    print(classification_report(y, y_pred))","ffd4a95f":"# Ensembles\nfor pipe in ensemble_pipes:\n    print('Model: ', pipe.steps[1][0])\n    y_pred = cross_val_predict(pipe, X, y, cv=5)\n    print(classification_report(y, y_pred))","eba3f868":"# Lineares\n\nparameters_ridge = {'ridge__alpha': np.arange(0.1, 1, 0.1),\n                    'ridge__class_weight': ['balanced', 'None']}\n\nparameters_logistic = {'logistic__solver': ['newton-cg', 'lbfgs', 'liblinear', 'sag', 'saga'],\n                    'logistic__penalty': ['none', 'l1', 'l2', 'elasticnet'],\n                    'logistic__C': [100, 10, 1.0, 0.1, 0.01],\n                    'logistic__class_weight': ['balanced', 'None']}\n\nparameters_SGD = {'SGD__alpha': [1e-4, 1e-3, 1e-2, 1e-1, 1e0, 1e1, 1e2, 1e3],\n                'SGD__max_iter': [100, 1000, 2000, 5000],\n                'SGD__class_weight': ['balanced', 'None']}\n\nparameters_perceptron = {'perceptron__eta0': [0.0001, 0.001, 0.01, 0.1, 1.0],\n                        'perceptron__max_iter': [100, 1000, 10000],\n                        'perceptron__class_weight': ['balanced', 'None']}\n\nparameters_PasAgg = {'PasAgg__C': [10, 1.0, 0.1, 0.01],\n                    'PasAgg__max_iter': [500, 1000, 1500, 5000],\n                    'PasAgg__class_weight': ['balanced', 'None']}\n\n# N\u00e3o lineares\n\nparameters_SVM = {'SVM__kernel': ['linear', 'poly', 'rbf', 'sigmoid', 'precomputed'],\n                'SVM__C': [100, 10, 1.0, 0.1, 0.01, 0.001],\n                'SVM__class_weight': ['balanced', 'None']}\n\nparameters_KN = {'KN__n_neighbors' : np.arange(1, 21, 1),\n                'KN__metric':  ['euclidean', 'manhattan', 'minkowski'],\n                'KN__weights':  ['uniform', 'distance']}\n\nparameters_tree = {'tree__max_depth': [3, None],\n                'tree__max_features': np.arange(1, 9, 1),\n                'tree__min_samples_leaf': np.arange(1, 9, 1),\n                'tree__criterion': [\"gini\", \"entropy\"],\n                'tree__class_weight': ['balanced', 'None']}\n\nparameters_MLP = {'MLP__max_iter': [100, 500, 1000, 1500, 5000],\n                'MLP__hidden_layer_sizes': [(50,50,50), (50,100,50), (100,)],\n                'MLP__activation': ['tanh', 'relu'],\n                'MLP__solver': ['sgd', 'adam'], \n                'MLP__learning_rate': ['constant','adaptive'],\n                'MLP__class_weight': ['balanced', 'None']}\n\n# Ensembles\n\nparameters_GB = {'GB__learning_rate': [0.01, 0.025, 0.05, 0.075, 0.1, 0.15, 0.2],\n                'GB__max_depth': [3, 5, 8, 10, 14],\n                'GB__subsample': [0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0],\n                'GB__min_samples_leaf': np.linspace(0.1, 0.5, 12), \n                'GB__min_samples_split': np.linspace(0.1, 0.5, 12),\n                'GB__max_features': ['log2', 'sqrt', 'auto'],\n                'GB__subsample': [0.5, 0.618, 0.8, 0.85, 0.9, 0.95, 1.0]}\n\nparameters_ET = {'ET__n_estimators': np.arange(90,200,10),\n                'ET__min_samples_leaf': np.linspace(0.1, 0.5, 12), \n                'ET__min_samples_split': np.linspace(0.1, 0.5, 12),\n                'ET__max_features': ['log2', 'sqrt', 'auto'],\n                'ET__class_weight': ['balanced', 'None']}\n\nparameters_RF = {'RF__n_estimators': np.arange(90,200,10),\n                'RF__max_depth': np.arange(1, 110, 10),\n                'RF__min_samples_leaf': [1,2,4], \n                'RF__min_samples_split': [2,5,10],\n                'RF__max_features': ['log2', 'sqrt', 'auto'],\n                'RF__class_weight': ['balanced', 'None']}\n\nparameterns_bagging = {'bagging__n_estimators': np.arange(5, 200, 5),\n                       'bagging__max_features': np.arange(1, 9, 1)}\n","24648634":"# Lineares\n\nrscv_ridge = RandomizedSearchCV(pipe_ridge, parameters_ridge, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_ridge.fit(X, y)\n\nrscv_logistic = RandomizedSearchCV(pipe_logistic, parameters_logistic, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_logistic.fit(X, y)\n\nrscv_SGD = RandomizedSearchCV(pipe_SGD, parameters_SGD, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_SGD.fit(X, y)\n\nrscv_perceptron = RandomizedSearchCV(pipe_perceptron, parameters_perceptron, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_perceptron.fit(X, y)\n\nrscv_PasAgg = RandomizedSearchCV(pipe_PasAgg, parameters_PasAgg, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_PasAgg.fit(X, y)\n\nrscv_linear = [rscv_ridge, rscv_logistic, rscv_SGD, rscv_perceptron, rscv_PasAgg]\n\n# N\u00e3o lineares\n\nrscv_SVM = RandomizedSearchCV(pipe_SVM, parameters_SVM, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_SVM.fit(X, y)\n\nrscv_KN = RandomizedSearchCV(pipe_KN, parameters_KN, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_KN.fit(X, y)\n\nrscv_tree = RandomizedSearchCV(pipe_tree, parameters_tree, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_tree.fit(X, y)\n\nrscv_MLP = RandomizedSearchCV(pipe_MLP, parameters_MLP, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\n#rscv_MLP.fit(X, y)\n\nrscv_n_linear = [rscv_SVM, rscv_KN, rscv_tree]\n\n# Ensembles\n\nrscv_GB = RandomizedSearchCV(pipe_GB, parameters_GB, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_GB.fit(X, y)\n\nrscv_ET = RandomizedSearchCV(pipe_ET, parameters_ET, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_ET.fit(X, y)\n\nrscv_RF = RandomizedSearchCV(pipe_RF, parameters_RF, cv=5, \n    random_state=0, n_jobs=-1, scoring='neg_mean_squared_error', verbose=0)\n\nrscv_RF.fit(X, y)\n\nrscv_ensemble = [rscv_GB, rscv_ET, rscv_RF]","5accde35":"# Lineares\nfor rscv in rscv_linear:\n    print('Model: ', rscv.best_estimator_.steps[1][0])\n    y_pred = cross_val_predict(rscv.best_estimator_, X, y, cv=5)\n    print(classification_report(y, y_pred))","32c1daa0":"# N\u00e3o lineares\nfor rscv in rscv_n_linear:\n    print('Model: ', rscv.best_estimator_.steps[1][0])\n    y_pred = cross_val_predict(rscv.best_estimator_, X, y, cv=5)\n    print(classification_report(y, y_pred))","8d1c96fa":"# Ensembles\nfor rscv in rscv_ensemble:\n    print('Model: ', rscv.best_estimator_.steps[1][0])\n    y_pred = cross_val_predict(rscv.best_estimator_, X, y, cv=5)\n    print(classification_report(y, y_pred))","0dfccc1a":"model = rscv_RF.best_estimator_\nmodel","3d13cde1":"probs = model.predict_proba(X)[:,1]\nfpr, tpr, thresholds  = roc_curve(y, probs)\nsns.lineplot(fpr, tpr);","1d7ef8a4":"y_test = test['quality_label']\ntest.drop(['quality_label'] , axis=1, inplace=True)\nX_test = test.copy()\ny_test","a7844f04":"y_pred = cross_val_predict(model, X_test, y_test, cv=5)\ny_pred","00a962e5":"cm = confusion_matrix(y_test, y_pred)\ncm","fec576df":"probs = model.predict_proba(X_test)[:,1]\nfpr, tpr, thresholds  = roc_curve(y_test, probs)\nsns.lineplot(fpr, tpr);","ba9a8573":"print(classification_report(y_test, y_pred))","0478fdbc":"import pickle\n\npickle.dump(model, open('model.sav', 'wb'))","9541731a":"loaded_model = pickle.load(open('model.sav', 'rb'))","f2f78546":"loaded_model","565dd23d":"#### Busca aleat\u00f3ria","e70075ba":"### Obtendo atributos categ\u00f3ricos e n\u00e3o-categ\u00f3ricos","c01f1b0f":"## Modelos de aprendizado","0002ddc6":"### Separando banco de dados em treinamento e teste","a4e3deed":"#### Hiper-par\u00e2metros","87bab835":"## Leitura e explora\u00e7\u00e3o do banco de dados","2dc41a20":"### Visualiza\u00e7\u00e3o dos dados (*data visualization*)","4a0f0739":"### Valores nulos (*missing data*)","5faffdce":"#### Histogramas","01a173a4":"### Importando bibliotecas","b002b8ff":"* Os atributos n\u00e3o-categ\u00f3ricos precisam ser padronizados ou normalizados.","313a9f37":"### Exportar","1fdda612":"### *Pipelines*","50bb8350":"* Os atributos com maiores correla\u00e7\u00f5es est\u00e3o no vetor *topCols*.","1d1eb090":"## Avalia\u00e7\u00e3o","0e033421":"#### *Outliers*","60ce5904":"#### *Boxplots*","b61544d7":"#### An\u00e1lise dos vinhos de alta qualidade","8b1bac77":"#### *Heatmap*","ea3b941a":"### Treinamento e testes","95988787":"## Predi\u00e7\u00f5es com teste","995ebe42":"## Valida\u00e7\u00e3o\n\n* Matriz confusa\n* Precis\u00e3o (quanto dos selecionados s\u00e3o os relavantes?)\n* Recupera\u00e7\u00e3o - _recall_ ou sensibilidade (quanto dos relevantes s\u00e3o selecionados?)\n* _F1 score_\n* _ROC curve_\n","bd0618a6":"### Otimiza\u00e7\u00e3o de hiper-par\u00e2metros","c908b027":"## Exportar\/Importar modelo","cfc6c579":"* H\u00e1 1 atributo de n\u00fameros inteiros (num\u00e9rico e categ\u00f3rico): *quality*;\n* H\u00e1 1 atributo de texto (textual e categ\u00f3rico): *type*;\n* H\u00e1 11 atributos num\u00e9ricos reais (num\u00e9rico e n\u00e3o-categ\u00f3rico): demais atributos.","a2e960d5":"### _Pipelines_","316107cd":"* A vari\u00e1vel *outliers* armazena os pontos *outliers*.","da74a4c9":"# _Wine Quality_\n\nEstudo pr\u00e1tico de Classifica\u00e7\u00e3o de quailidade de vinhos (com *dataset* do [_Kaggle_](https:\/\/www.kaggle.com\/rajyellow46\/wine-quality?select=winequalityN.csv));\n\n---\n\n[Open In Colab](https:\/\/colab.research.google.com\/drive\/1AcaArOrR-e1XQl4N8jUDXBR8ZRt3sSmP?usp=sharing)\n\n[Open in Kaggle](https:\/\/www.kaggle.com\/leonichel\/wine-quality)\n\n---\n\n[Leonichel Guimar\u00e3es (PIBITI\/CNPq-FA-UEM)](https:\/\/github.com\/leonichel)\n\nProfessora Linnyer Ruiz (orientadora)\n\n---\n\nRefer\u00eancias bibliogr\u00e1ficas:\n\nG\u00c9RON, Aur\u00e9lien. _Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow: Concepts, Tools, and Techniques to Build Intelligent Systems_. 2. ed. O'Reilly Media, 2019.\n\n---\n\nManna Team  |  UEM       |     CNPq\n:----------:|:----------:|:----------:|\n<img src=\"https:\/\/manna.team\/_next\/static\/images\/logo2-e283461cfa92b2105bfd67e8e530529e.png\" alt=\"Manna Team\" width=\"200\"\/> | <img src=\"https:\/\/marcoadp.github.io\/WebSiteDIN\/img\/logo-uem2.svg\" alt=\"UEM\" width=\"200\"\/> | <img src=\"https:\/\/www.gov.br\/cnpq\/pt-br\/canais_atendimento\/identidade-visual\/logo_cnpq.svg\" alt=\"CNPq\" width=\"200\"\/>","da68a492":"### Lendo banco de dados","b52dac5d":"### Importar","e16f4a38":"## Pr\u00e9-processamento","11147651":"* Os atributos com valores nulos est\u00e3o no vetor *null_values_cols*, e precisam ser tratados.","e6e5e96d":"* H\u00e1 poucos vinhos com notas superiores a 8.","8b014279":"### Explora\u00e7\u00e3o do banco de dados","c753a954":"### Removendo *outliers*","c3c4406d":"#### *Scatter matrix*","5421a16e":"## Melhorias poss\u00edveis\n\n* Arrumar banco de dados desbalanceado;\n* Adicionar 'ovo' ou 'ovr' para multi-classes"}}