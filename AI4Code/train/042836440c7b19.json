{"cell_type":{"a05ed343":"code","ac9a6ff5":"code","c5438046":"code","ac2ddd34":"code","d5760401":"code","34d01984":"code","f49dde1c":"code","3b6b9e95":"code","563e2a72":"code","d77dca31":"code","0dc17915":"code","fa355ed4":"code","5ba04d61":"code","929459ca":"code","63598534":"code","03c6fdf8":"code","288e072d":"code","8caa91dc":"code","38cb38c0":"code","47ff7a27":"code","6bd62fc2":"code","d561610f":"code","a026a7e6":"code","9ff3c965":"code","546408e4":"code","ef4bc736":"code","54376121":"code","c82c6907":"code","e8cd5d50":"code","5b246bc6":"code","f2c53120":"code","f51aee4a":"code","86a9f8ce":"code","23138194":"code","c7b64edb":"code","d2ad66e8":"code","2621f4b1":"code","0fbfb126":"code","4c8b31e4":"code","ef68179c":"code","8d3159b1":"code","b3fe4bda":"code","0c8df462":"code","b3bc4e24":"code","017f0e23":"code","a19d22e9":"code","9c52a6a9":"code","d4869883":"code","c98b7120":"code","0d57bb49":"code","dbea7b20":"code","672f887e":"code","5cc1b681":"code","a5a3362d":"code","bcf38d0a":"code","4cba7112":"code","d7987206":"code","ee845db3":"code","32f4a320":"code","f14c542a":"code","5c1c68c4":"code","121aec5f":"code","de395e37":"code","b3652893":"code","132c6d2a":"code","e0a70a92":"code","c9ad0c6b":"code","a1902a72":"code","3456eab2":"code","36452caf":"code","068eb951":"code","9afb13de":"code","b9b887dc":"code","a31bd117":"code","82843431":"code","98410b4f":"code","43374567":"code","387c9925":"code","56cb4e06":"code","4e6f016d":"code","b17357e1":"code","42824f97":"code","5b334fe0":"code","83451858":"code","6ada4218":"markdown","bb62bf47":"markdown","6e031a6d":"markdown","4e788ebb":"markdown","389cc510":"markdown","ea61f16f":"markdown","2b48e3fb":"markdown","b8b5a036":"markdown","64830528":"markdown","98fe3590":"markdown","e02b2b7c":"markdown","e92937b2":"markdown","fd60a8ad":"markdown","1c310790":"markdown","686b3e07":"markdown","018e0b81":"markdown","e36f5bcc":"markdown","d7010d11":"markdown","c40a272e":"markdown","c580e03e":"markdown","22f7dbdb":"markdown","16f0d248":"markdown","d33f6afc":"markdown"},"source":{"a05ed343":"import pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport numpy as np\nimport seaborn as sns\nsns.set() # setting seaborn default for plots\n\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')","ac9a6ff5":"train.head()","c5438046":"test.head()","ac2ddd34":"train.shape","d5760401":"test.shape","34d01984":"train.info()","f49dde1c":"test.info()","3b6b9e95":"train[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","563e2a72":"train[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","d77dca31":"train[['Parch', 'Survived']].groupby(['Parch'], as_index=False).mean().sort_values(by='Survived', ascending=False)","0dc17915":"train[['SibSp', 'Survived']].groupby(['SibSp'], as_index=False).mean().sort_values(by='Survived', ascending=False)","fa355ed4":"train.corr()","5ba04d61":"plt.figure(figsize=(8, 8))\nsns.heatmap(train.corr(), linewidths=0.1, vmax=0.5, cmap=plt.cm.gist_heat, linecolor='white', annot=True)\nplt.show()","929459ca":"train.isnull().sum()","63598534":"test.isnull().sum()","03c6fdf8":"# \uc0b0 \uc0ac\ub78c\uacfc \uc8fd\uc740 \uc0ac\ub78c\uc758 \uac01 \ud53c\uccd0 \ud2b9\uc9d5 \ud655\uc778\ndef bar_chart(feature):\n    survived = train[train['Survived'] == 1][feature].value_counts() # Survived \uac12\uc774 1\uc778 \ud589\ub4e4\uc758 feature\uc5f4 \uc218 count\n    dead = train[train['Survived'] == 0][feature].value_counts() # Survived \uac12\uc774 0\uc778 \ud589\ub4e4\uc758 feature\uc5f4 \uc218 count\n    df = pd.DataFrame([survived, dead]) # \uc0b0\uc0ac\ub78c\uacfc \uc8fd\uc740\uc0ac\ub78c\uc73c\ub85c \ub098\ub204\uc5b4\uc11c DataFrame\uc73c\ub85c \uc800\uc7a5\n    df.index = ['Survived', 'Dead'] # index\uba85 \uc9c0\uc815\n    df.plot(kind='bar', stacked=True, figsize=(10, 5)) # bar chart \uadf8\ub9ac\uae30\n    plt.show()","288e072d":"bar_chart('Sex')","8caa91dc":"bar_chart('Pclass')","38cb38c0":"bar_chart('SibSp')","47ff7a27":"bar_chart('Parch')","6bd62fc2":"bar_chart('Embarked')","d561610f":"train.head(10)","a026a7e6":"train_test_data = [train, test] # train data\uc640 test data \uacb0\ud569\n\n# train_test_data\uc758 Name\ud544\ub4dc\uc5d0\uc11c Title\uc744 \ubf51\uc74c\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract('([A-za-z]+)\\.', expand=False)","9ff3c965":"# train data\uc758 \ud0c0\uc774\ud2c0 \uc885\ub958 \ubc0f \uc778\uc6d0 \ud655\uc778\ntrain['Title'].value_counts()","546408e4":"# test data\uc758 \ud0c0\uc774\ud2c0 \uc885\ub958 \ubc0f \uc778\uc6d0 \ud655\uc778\ntest['Title'].value_counts()","ef4bc736":"# \ud0c0\uc774\ud2c0\ubcc4\ub85c Mr\ub294 0, Miss\ub294 1, Mrs\ub294 2, \uadf8 \uc678 \ub098\uba38\uc9c0\ub294 3\uc73c\ub85c \ub9e4\ud551\n\ntitle_mapping = {\"Mr\":0, \"Miss\":1, \"Mrs\":2,\n                 \"Master\":3, \"Dr\":3, \"Rev\":3, \"Major\":3, \"Col\":3, \"Mlle\":3, \"Lady\":3,\n                 \"Mme\":3, \"Sir\":3, \"Jonkheer\":3, \"Ms\":3, \"Capt\":3, \"Don\":3, \"Dona\":3,\n                \"Countess\":3}\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","54376121":"train.head(10)","c82c6907":"bar_chart('Title')","e8cd5d50":"# \ub370\uc774\ud130\uc14b \uc911 \ud544\uc694\uc5c6\ub294 \ud53c\uccd0 \uc0ad\uc81c\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","5b246bc6":"train.head()","f2c53120":"sex_mapping = {\"male\":0, \"female\":1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","f51aee4a":"bar_chart('Sex')","86a9f8ce":"# Age \ud544\ub4dc\uc758 NaN\uac12\uc744 Title \uadf8\ub8f9\ubcc4\uc758 \ub098\uc774 \uc911\uac04\uac12\uc73c\ub85c \ucc44\uc6c0\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","23138194":"# train data\uc758 \ub098\uc774\uc5d0 \ub530\ub978 \uc0dd\uc0ac \ud655\uc778\nfacet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.show()","c7b64edb":"# \ub098\uc774\ub300\ubcc4 \uc0dd\uc0ac \ud655\uc778\nfacet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","d2ad66e8":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","2621f4b1":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(30, 40)","0fbfb126":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","4c8b31e4":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'Age', shade=True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(60)","ef68179c":"# \ub098\uc774\ub300\uc5d0 \ub530\ub77c \uadf8\ub8f9 \ub098\ub214\nfor dataset in train_test_data:\n    dataset.loc[dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[dataset['Age'] > 62, 'Age'] = 4","8d3159b1":"train.head()","b3fe4bda":"bar_chart('Age')","0c8df462":"Pclass1 = train[train['Pclass'] == 1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass'] == 2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass'] == 3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class', '2nd class', '3rd class']\ndf.plot(kind='bar', stacked=True, figsize=(10, 5))","b3bc4e24":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","017f0e23":"train.head(10)","a19d22e9":"embarked_mapping = {\"S\":0, \"C\":1, \"Q\":2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","9c52a6a9":"# \ub4f1\uae09\ubcc4 \uc911\uac04\uac12\uc744 NaN\uac12\uc5d0 \ub123\uc5b4\uc90c\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)","d4869883":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'Fare', shade=True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n\nplt.show()","c98b7120":"for dataset in train_test_data:\n    dataset.loc[dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 2,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 4,\n    dataset.loc[dataset['Fare'] > 100, 'Fare'] = 6","0d57bb49":"train.head()","dbea7b20":"train.Cabin.value_counts()","672f887e":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","5cc1b681":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class', '2nd class', '3rd class']\ndf.plot(kind = 'bar', stacked=True, figsize=(10, 5))","a5a3362d":"# scaling\n# \uba38\uc2e0 \ub7ec\ub2dd \ubaa8\ub378\uc740 \uac12\uc758 \ucc28\uc774\uac00 \ud074 \uc218\ub85d \ub354 \ud070 \uc758\ubbf8\ub97c \ubd80\uc5ec\ud558\uae30 \ub54c\ubb38\uc5d0 \uac12\uc744 \uc2a4\ucf00\uc77c\ub9c1 \ud574\uc90c\ncabin_mapping = {\"A\":0, \"B\":0.7, \"C\":1.4, \"D\":2.1, \"E\":2.8, \"F\":3.5, \"G\":4.2, \"T\":4.9}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","bcf38d0a":"train[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","4cba7112":"train.head()","d7987206":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","ee845db3":"facet = sns.FacetGrid(train, hue=\"Survived\", aspect=4)\nfacet.map(sns.kdeplot, 'FamilySize', shade=True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","32f4a320":"family_mapping = {1:0, 2:0.5, 3:1.0, 4:1.5, 5:2.0, 6:2.5, 7:3.0, 8:3.5, 9:4.0, 10:4.5, 11:5.0}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","f14c542a":"# import numpy as np\n# corr = train.corr()\n# mask = np.zeros_like(corr, dtype=np.bool)\n# mask[np.triu_indices_from(mask)] = True\n# f, ax = plt.subplots(figsize=(11, 9))\n# cmap = sns.diverging_palette(220, 10, as_cmap=True)\n# sns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","5c1c68c4":"train.head()","121aec5f":"# \ud544\uc694\uc5c6\ub294 \ud56d\ubaa9 drop\nfeatures_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","de395e37":"# \ubaa8\ub378 \uc785\ub825\ub370\uc774\ud130 \uad6c\uc131\uc744 \uc704\ud55c train_data \uc14b \uad6c\uc131\n#train_data = \uc785\ub825 , target = \ucd9c\ub825\ntrain_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","b3652893":"train_data.head(10)","132c6d2a":"test = test.drop(['PassengerId'], axis=1)","e0a70a92":"test.head(10)","c9ad0c6b":"plt.figure(figsize=(8, 8))\nsns.heatmap(train.corr(), linewidths=0.1, vmax=0.5, cmap=plt.cm.gist_heat, linecolor='white', annot=True)\nplt.show()","a1902a72":"import tensorflow as tf\ntrain_x = train_data\ndf = pd.DataFrame(target) # \uc0b0\uc0ac\ub78c\uacfc \uc8fd\uc740\uc0ac\ub78c\uc73c\ub85c \ub098\ub204\uc5b4\uc11c DataFrame\uc73c\ub85c \uc800\uc7a5\ndf.columns = ['Survived'] # index\uba85 \uc9c0\uc815\ntrain_y = df\ntest_x = test\ntest_y = pd.read_csv('..\/input\/gender_submission.csv')\ndf = pd.DataFrame(test_y['Survived'])\ndf.columns = ['Survived']\ntest_y = df","3456eab2":"X = tf.placeholder(tf.float32, shape=[None, 8])\nY = tf.placeholder(tf.float32, shape=[None, 1])\n\nW = tf.get_variable(\"W\", shape=[8, 10], initializer=tf.contrib.layers.xavier_initializer())\nb = tf.Variable(tf.random_normal([10]), name='bias')\nH = tf.sigmoid(tf.matmul(X, W) + b)\n\ncost = -tf.reduce_mean(Y*tf.log(H) + (1-Y) * tf.log(1-H))\n\ntrain = tf.train.AdamOptimizer(learning_rate=0.001).minimize(cost)\n\npredicted = tf.cast(H > 0.5, dtype=tf.float32)\naccuracy = tf.reduce_mean(tf.cast(tf.equal(predicted, Y), dtype=tf.float32))","36452caf":"import time\nstartTime = time.time()\n\nwith tf.Session() as sess:\n    sess.run(tf.global_variables_initializer())\n    \n    for step in range(10001):\n        cost_val, _ = sess.run([cost, train], feed_dict={X:train_x, Y:train_y})\n        if step % 1000 == 0:\n            print(step, cost_val)\n                  \n    print('-----------------------------')\n    print('train_data = ', len(train_x), 'test_data = ', len(test_x))\n\n    h, c, y, a = sess.run([H, predicted, Y, accuracy], feed_dict={X:test_x, Y:test_y})\n    print('\\ntest data accuracy : ', a)\n    \n#     h, c = sess.run([H, predicted], feed_dict={X:test_x, Y:test_y})\n#     print('test_x = ', test_x, ', predicted = ', c)\nendTime = time.time()\nprint(endTime - startTime, \" sec\")","068eb951":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import Perceptron\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.tree import DecisionTreeClassifier","9afb13de":"#Logistic Regression \ubaa8\ub378\n\nlogreg = LogisticRegression()\nlogreg.fit(train_x, train_y)\nY_pred = logreg.predict(test_x)\nacc_log = round(logreg.score(train_x, train_y) * 100 , 2)\nacc_log","b9b887dc":"# Support Vector Machines \ubaa8\ub378\n\nsvc = SVC()\nsvc.fit(train_x, train_y)\nY_pred = svc.predict(test_x)\nacc_svc = round(svc.score(train_x, train_y) * 100, 2)\nacc_svc","a31bd117":"#K Neighbors Classifier \ubaa8\ub378\n\nknn = KNeighborsClassifier(n_neighbors = 3)\nknn.fit(train_x, train_y)\nY_pred = knn.predict(test_x)\nacc_knn = round(knn.score(train_x, train_y) * 100, 2)\nacc_knn","82843431":"# Gaussian Naive Bayes \ubaa8\ub378\n\ngaussian = GaussianNB()\ngaussian.fit(train_x, train_y)\nY_pred = gaussian.predict(test_x)\nacc_gaussian = round(gaussian.score(train_x, train_y) * 100, 2)\nacc_gaussian","98410b4f":"# Perceptron \ubaa8\ub378\n\nperceptron = Perceptron()\nperceptron.fit(train_x, train_y)\nY_pred = perceptron.predict(test_x)\nacc_perceptron = round(perceptron.score(train_x, train_y) * 100, 2)\nacc_perceptron","43374567":"# Linear SVC \ubaa8\ub378\nlinear_svc = LinearSVC()\nlinear_svc.fit(train_x, train_y)\nY_pred = linear_svc.predict(test_x)\nacc_linear_svc = round(linear_svc.score(train_x, train_y) * 100, 2)\nacc_linear_svc","387c9925":"# Stochastic Gradient Descent \ubaa8\ub378\n\nsgd = SGDClassifier()\nsgd.fit(train_x, train_y)\nY_pred = sgd.predict(test_x)\nacc_sgd = round(sgd.score(train_x, train_y) * 100, 2)\nacc_sgd","56cb4e06":"# Decision Tree \ubaa8\ub378\n\ndecision_tree = DecisionTreeClassifier()\ndecision_tree.fit(train_x, train_y)\nY_pred = decision_tree.predict(test_x)\nacc_decision_tree = round(decision_tree.score(train_x, train_y) * 100, 2)\nacc_decision_tree","4e6f016d":"# Random Forest \ubaa8\ub378\n\nrandom_forest = RandomForestClassifier(n_estimators=100)\nrandom_forest.fit(train_x, train_y)\nY_pred = random_forest.predict(test_x)\nacc_random_forest = round(random_forest.score(train_x, train_y) * 100, 2)\nacc_random_forest","b17357e1":"models = pd.DataFrame({\n    'Model' : ['Support Vector Machines', 'KNN', 'Logistic Regression', 'Random Forest', 'Naive Bayes', 'Perceptron', 'Stochastic Gradient Decent', 'Linear SVC', 'Decision Tree'],\n    'Score' : [acc_svc, acc_knn, acc_log, acc_random_forest, acc_gaussian, acc_perceptron, acc_sgd, acc_linear_svc, acc_decision_tree]\n})\nmodels.sort_values(by='Score', ascending=False)","42824f97":"# \uc608\uce21 \uacb0\uacfc csv\ub85c \uc800\uc7a5\n\ntest = pd.read_csv('..\/input\/test.csv')\nsubmission = pd.DataFrame({\n    \"PassengerId\":test[\"PassengerId\"],\n    \"Survived\":decision_tree.predict(test_x)\n})","5b334fe0":"submission.to_csv(\"submission.csv\", index=False)","83451858":"submission.head()","6ada4218":"<h3>1. Name (English honorifics)<\/h3>\n<p>\uc790\uc2dd \uc5ec\ubd80, \uacc4\uae09 \ub4f1\uc744 \uc54c \uc218 \uc788\ub294 \uc9c0\ud45c\uc77c \uac83\uc774\ub77c \uac00\uc815<\/p>","bb62bf47":"<h3>3. Age<\/h3>\n<p>NaN\uc778 \ub370\uc774\ud130\uac00 \ud3ec\ud568\ub418\uc5b4 \uc788\uae30\uc5d0 \uc8fc\uc758\ud574\uc57c \ud55c\ub2e4.<br\/>\n(Missing Data)<br\/><br\/>\n<h4>\ubc29\ubc95 1. NaN \uc774\uc678 \uc804\uccb4 \ud0d1\uc2b9\uac1d\ub4e4\uc758 \ub098\uc774\uc758 \ud3c9\uade0 \ud639\uc740 \uc911\uac04\uac12\uc744 \ub300\uc785<\/h4><\/p>\n\n- NaN\uc778 \ub370\uc774\ud130\uc758 \uc131\ubcc4(\ud0c0\uc774\ud2c0)\uc744 \ub098\ub220 \uc131\ubcc4\ubcc4 \ud0d1\uc2b9\uac1d\ub4e4\uc758 \ub098\uc774\uc758 \uc911\uac04\uac12\uc744 \ub300\uc785","6e031a6d":"<h3>6. Cabin<\/h3>","4e788ebb":"<h3>4.Embarked<\/h3>","389cc510":"<h4>- Load data and analysis<\/h4>","ea61f16f":"\ubd80\ubaa8\uc790\uc2dd \uc5c6\uc774 \ud63c\uc790 \ud0d4\uc744 \uacbd\uc6b0 \uc0dd\uc874 \ud655\ub960\uc774 \ub0ae\ub2e4.","2b48e3fb":"---------------------------------------------------------------------------------------------","b8b5a036":"\uc5ec\uc790\uac00 \ub0a8\uc790\ubcf4\ub2e4 \uc0dd\uc874\ud560 \uac00\ub2a5\uc131\uc774 \ub192\ub2e4.","64830528":"<h2>Feature Engineering<\/h2>\n<p>feature\ub4e4\uc744 vector\ub85c \ub9cc\ub4dc\ub294 \uacfc\uc815 <br\/>\ndata\ub97c \uc22b\uc790\ub85c \ub9cc\ub4e4\uc5b4\uc8fc\ub294 \uac83 <br\/>\nNaN = Not a Number<\/p>","98fe3590":"<h3>Data Dictionary<\/h3>\n<br\/>\n\n- survived : 0 = No(Death), 1 = Yes(Alive)\n- pclass : Ticket class 1 = 1st, 2 = 2nd, 3 = 3rd (1 > 2 > 3)\n- sibsp : siblings \/ spouses (\ud615\uc81c\uc790\ub9e4, \ubc30\uc6b0\uc790\uac00 \ud568\uaed8 \ud0d1\uc2b9\ud55c \uc218) (\ud63c\uc790\uba74 0)\n- parch : parent \/ children (\ubd80\ubaa8\ub2d8, \uc790\uc2dd\uc774 \ud568\uaed8 \ud0d1\uc2b9\ud55c \uc218) (\ud63c\uc790\uba74 0)\n- cabin : \uac1d\uc2e4 \ubc88\ud638\n- embarked : \ud0d1\uc2b9 \uc120\ucc29\uc7a5 C = Cherbourg, Q = Queenstown, S = Southampton\n<br \/><br \/>\n<p>train data\ub294 12\uac1c\uc758 \uc5f4\uc744 \uac16\uace0 test data\ub294 \uc608\uce21\ud558\ub824\ub294 Survived \uc5f4\uc740 \uc81c\uac70\ub418\uc5b4 11\uac1c\uc758 \uc5f4\uc744 \uac16\ub294\ub2e4.<\/p>","e02b2b7c":"<h3>2. Sex<\/h3>\n<p> vector\ub85c \ubcc0\uacbd <\/p>","e92937b2":"1\ub4f1\uae09 \uc11d\uc758 \uc0ac\ub78c\uc740 \uc0dd\uc874 \ud655\ub960\uc774 \ub192\uace0 3\ub4f1\uae09 \uc11d\uc758 \uc0ac\ub78c\uc740 \uc0dd\uc874 \ud655\ub960\uc774 \ub0ae\ub2e4.","fd60a8ad":"Southampton\uc5d0\uc11c\uc758 \ud0d1\uc2b9\uac1d\uc774 \ubaa8\ub4e0 \ub4f1\uae09 \uc88c\uc11d\uc5d0\uc11c 50% \uc774\uc0c1\uc744 \ucc28\uc9c0\ud568.<br\/>\n\ub530\ub77c\uc11c NaN \ub370\uc774\ud130\ub97c S\ub85c \ucc44\uc6b4\ub2e4.","1c310790":"<h3>Lost Information<\/h3>\n<br\/>\n\n<p>\n    dataframe.info()\ub97c \ud1b5\ud574 Age, Cabin\uc774 \ube44\uc5b4\uc788\ub294 \uac83\uc744 \uc54c \uc218 \uc788\uc74c (train\uc5d0\uc11c Embarked\ub3c4 \ube60\uc838\uc788\uc74c)<br \/>\n    dataframe.isnull().sum()\uc744 \ud1b5\ud574\uc11c null\uc778 \uac12\uc774 \uba87\ud589\uc778\uc9c0 \ud655\uc778 \uac00\ub2a5\n<\/p>","686b3e07":"Queenstown\uc5d0\uc11c \ud0d1\uc2b9\ud55c \uc2b9\uac1d\uc774 \uc0dd\uc874 \ud655\ub960\uc774 \ub0ae\ub2e4","018e0b81":"<h3>5. Fare<\/h3>","e36f5bcc":"\ud615\uc81c\uc790\ub9e4 \uc5c6\uc774 \ud63c\uc790 \ud0d4\uc744 \uacbd\uc6b0 \uc0dd\uc874 \ud655\ub960\uc774 \ub0ae\ub2e4.","d7010d11":"# Titanic: Machine Learning from Disaster\n<h3> Predict survival on the Titanic <\/h3>","c40a272e":"<h3>Problem analysis<\/h3>\n\n<p> In this challenge, we ask you to complete the analysis of what sorts of people were likely to survive. In particular, we ask you to apply the tools of machine learning to predict which passengers survived the tragedy.<\/p><br \/>\n<p> RMS \ud0c0\uc774\ud0c0\ub2c9 \uce68\ubab0 \uc0ac\uace0 \uc2dc \uad6c\uba85\uc815\uc774 \ud0d1\uc2b9 \uc2b9\uac1d\ubcf4\ub2e4 \uc801\uc5c8\uae30 \ub54c\ubb38\uc5d0 \uc77c\ubd80 \uc0ac\ub78c\ub4e4\ub9cc \uc0dd\uc874\ud560 \uc218 \uc788\uc5c8\ub2e4.<br \/>\n\uc2b9\uac1d \uc911 \uc5b4\ub5a4 \uadf8\ub8f9\uc758 \uc0ac\ub78c\ub4e4\uc740 \ub2e4\ub978 \uadf8\ub8f9\ub4e4\ubcf4\ub2e4 \uc0dd\uc874\ud560 \ud655\ub960\uc774 \ub192\uc558\ub2e4. ex)\uc5ec\uc131, \uc544\uc774\ub4e4, \uc0c1\ub958\uce35<br \/>\n\ud0c0\uc774\ud0c0\ub2c9\ud638 \ud0d1\uc2b9 \uc2b9\uac1d \ub370\uc774\ud130\ub97c \ud559\uc2b5\ud558\uc5ec \ud0d1\uc2b9\uc790 \uc815\ubcf4\uac00 \ub4e4\uc5b4\uc654\uc744 \ub54c \uc0dd\uc874 \ud639\uc740 \uc0ac\ub9dd\ud560 \ud655\ub960\uc744 \uc608\uce21\ud55c\ub2e4.<\/p>","c580e03e":"<h4>- Data visualization<\/h4>","22f7dbdb":"Mr \ub0a8\uc131\uc740 \uc0dd\uc874 \ud655\ub960\uc774 \uc801\uace0, Miss, Mrs \uc5ec\uc131\uc740 \uc0dd\uc874 \ud655\ub960\uc774 \ub192\uc74c. (\ub354\uc774\uc0c1 Name \ud544\ub4dc\ub294 \ud544\uc694\uac00 \uc5c6\uc73c\ubbc0\ub85c \ud53c\uccd0 \uc0ad\uc81c)","16f0d248":"<h3>7. FamilySize<\/h3>","d33f6afc":"<p>Child : 0<br\/>\nYoung : 1<br\/>\nAdult : 2<br\/>\nmid-age : 3<br\/>\nsenior : 4\n<\/p>"}}