{"cell_type":{"bcdc7299":"code","df739253":"code","52f35dee":"code","1080bc15":"code","f2f46ff9":"markdown","17a866bd":"markdown","22070f91":"markdown","9aa98ef2":"markdown"},"source":{"bcdc7299":"import numpy as np\nimport matplotlib.pyplot as plt\nimport random\n\ndef get_frequencies(values):\n    frequencies = {}\n    for v in values:\n        if v in frequencies:\n            frequencies[v] += 1\n        else:\n            frequencies[v] = 1\n    return frequencies\n\n","df739253":"def get_probabilities(sampledata, freqs):\n    probabilities = []\n    for k, v in freqs.items():\n        probabilities.append(round(v \/ len(sampledata), 1))\n    return probabilities\n\nsample = [\"H\"] * 1 + ['T'] * 5\nprint('sample', sample)\ncalculated_frequencies = get_frequencies(sample)\nprint(calculated_frequencies)\ncalculate_probabilities = get_probabilities(sample, calculated_frequencies)\nprint(\"prob\", calculate_probabilities)\nx_axis = list(set(sample))\n\nplt.bar(x_axis, calculate_probabilities)\nplt.show()","52f35dee":"import math\nfrom scipy import stats\n# Declare A to be a normal random variable\n# We start with creating an instance of the stats.norm class\n# and initialize this object to have mean 3 and standard deviation 16:\nA = stats.norm(3, math.sqrt(16))","1080bc15":"print(A.pdf(4)) # the probability density at 3\nprint(A.cdf(2)) # F(2), which is also P(Y < 2)\nprint(A.rvs()) # Get a random sample from A\n","f2f46ff9":"[per docs](https:\/\/docs.scipy.org\/doc\/scipy\/reference\/generated\/scipy.stats.norm.html)\n\n![](https:\/\/i.imgur.com\/tYrjbTO.png)\n\nFor a normal distribution the keyword parameter loc (location (loc) keyword) defines the mean and the keyword parameter scale (scale (scale) keyword ) defines the standard deviation.  For other distributions these will correspond to appropriate parameters of the distribution","17a866bd":"Now the probability is just no of times each value occurs in the sample Now A probability frequency distribution need to be created, Its is a way to show how often an event will happen. It also shows what the probability of each event happening is. A frequency distribution table will need to be created\n","22070f91":"## Discrete vs Continuous Probability Distributions\n\n![](https:\/\/cdn-images-1.medium.com\/max\/1200\/1*t7lx34vYoJ8lAeNU6un7_g.jpeg)\n\n#### First lets define some terms for clarity\n\n## The sample space \u03a9\nThe sample space is the set of all possible outcomes of the experiment,\nusually denoted by \u03a9. For example, two successive coin tosses have\na sample space of {hh, tt, ht, th}, where \u201ch\u201d denotes \u201cheads\u201d and \u201ct\u201d\ndenotes \u201ctails\u201d.\n\n## The event space A\nThe event space is the space of potential results of the experiment. A\nsubset A of the sample space \u03a9 is in the event space A if at the end\nof the experiment we can observe whether a particular outcome \u03c9 \u2208 \u03a9\nis in A. The event space A is obtained by considering the collection of\nsubsets of \u03a9, and for discrete probability distributions (Section 6.2.1)\nA is often the power set of \u03a9.\n\n## The probability P\nWith each event A \u2208 A, we associate a number P (A) that measures the\nprobability or degree of belief that the event will occur. P (A) is called\nthe probability of A.\n\nThe probability of a single event must lie in the interval \\[0, 1\\], and the\ntotal probability over all outcomes in the sample space \u03a9 must be 1, i.e.,\nP (\u03a9) = 1. Given a probability space (\u03a9, A, P ), we want to use it to model\nsome real-world phenomenon. In machine learning, we often avoid explic-\nitly referring to the probability space, but instead refer to probabilities on\nquantities of interest, which **we denote by T as the target space** and refer to elements of of T as states.\n\nThe term `probability` relates is to an `event` and `probability distribution` relates is to a `random variable`.\n\nIt is a _convention_ that the term `probability mass function` refers to the `probability distribution` of a `discrete random variable` and the term `probability density function` refers to the probability function of a `continuous random variable`.\n\n## Understanding Probability Density\n\nFirst a quick reference on PMF, PDF and CDF\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*7zNkRF94SG1EiluoEuYgsQ.png)\n\n\nIn order to understand the heart of modern probability, we need to extend the concept of integration from basic calculus.\nTo begin, let us consider the following piecewise function\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*_ya9XYPF52QGPwpWKODN4Q.png)\n\n\nApplying the fundamental Riemann integration of Calculus we get\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*hNkbryuHYSnG2_EATqcdwQ.png)\n\n\nwhich has the usual interpretation as the area of the two rectangles that make up f (x).\n\nThe question is given f (x) = 1, what is the set of x values for which this is true? For our example, this is true whenever x \u2208 (0, 1\\]. So now we have a correspondence between the values of the function (namely, 1 and 2) and the sets of x values for which this is true, namely, {(0, 1\\]} and {(1, 2\\]}, respectively. To compute the integral, we simply take the function values\n(i.e., 1,2) and some way of measuring the size of the corresponding interval.\n\nSince areas can be defined by definite integrals, we can also define the probability of an event occuring within an interval \\[_a_, _b_\\] by the definite integral\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*rtJplzySaA6mBcXjZDSSzg.png)\n\n\nwhere _f_(_x_) is called the probability density function (pdf).\n\nA function _f_(_x_) is called a **probability density function** if\n\n1.  _f_(_x_)\u22650 for all _x_\n2.  The area under the graph of _f_(_x_) over all the real line is exactly 1\n3.  The probability that _x_ is in the interval \\[_a_, _b_\\] is\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*3ecCpHUQgljVnjYIUCaqiA.png)\n\n\ni.e. the area under the graph of _f_(_x_) from _a_ to _b_.\n\nIn the problem above, the probability density function _f_(_x_) is called a **uniform (flat) probability density function (pdf)**.\n\n> So fundamentally, what does a probability density at point \ud835\udc99\u00a0mean?\n\n> Probability density function\u2019s value at some specific point does not give you probability; it is a measure of how dense the distribution is around that value. It means how much probability is concentrated per unit length (**d**\ud835\udc99) near \ud835\udc99, or how dense the probability is near\u00a0\ud835\udc99.\n\n**For discrete random variables, we look up the value of a PMF at a single point to find its probability P(\ud835\udc17=\ud835\udc99)\u00a0\nFor continuous random variables, we take an integral of a PDF over a certain interval** to find its probability that **X** will fall in that interval.\n\n### Discrete Random\u00a0Variable\n\n## First what is a Random\u00a0Variable\n\nGiven a random experiment with sample space S,a **random variable** X is a set function that assigns one and only one real number to each element s that belongs in the sample space S.\n\nThe set of all possible values of the random variable X, denoted x, I am calling here as the **support**, or **space**, of X.\n\nNote that the capital letters at the end of the alphabet, such as W,X,Y, and Z typically represent the definition of the random variable. The corresponding lowercase letters, such as w,x,y, and z, represent the random variable\u2019s possible values.\n\n## And now what is a Discrete Random\u00a0Variable\n\nBy a discrete random variable, it is meant a function (or a mapping), say X, from a sample space \u03a9, into the set of real numbers. Symbolically, if \u03c9 \u2208\u03a9, then X (\u03c9 ) = x, where x is a real number.\n\nA random variable X is a **discrete random variable** if:\n\n*   there are a finite number of possible outcomes of X, or\n*   there are a countably infinite number of possible outcomes of X.\n\n**A countably infinite number of possible outcomes means that there is a one-to-one correspondence between the outcomes and the set of integers.**\n\nNo such one-to-one correspondence exists for an uncountably infinite number of possible outcomes.\n\n**For a value x of the set of possible outcomes of the random variable X\u00a0, i.e., x \u2208 T\u00a0, p(x) denotes the probability that random variable X has the outcome x.**\n\n**For discrete random variables, this is written as P (X = x), which is known as the probability mass function. The pmf is often referred to as the distribution\u201d. For continuous variables, p(x) is called the probability density function (often referred to as a density).**\n\nWhen we say probability distribution it may pertain to a discrete random variable or a continuous random variable, depending on the context.\n\nWhen the random variable is discrete, probability distribution means, how the total probability is distributed over various possible values of the random variable. Consider the experiment of tossing two unbiased coins simultaneously. Then, sample space _S_ associated with this experiment is:\n\n_S_ \\= {_HH_,_HT_,_TH_,_TT_}\n\n**If we define a random variable X as: the number of heads on this sample space _S_,** then we will have\n\n_X_(_HH_)=2,\n\n_X_(_HT_)=_X_(_TH_)=1,\n\n_X_(_TT_)=0\n\nX(HH)=2,\n\nX(HT)=X(TH)=1,\n\nX(TT)=0.\n\nThe probability distribution of _X_X is then given by\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*QJJTQx59XTQY1e-tnoz1sQ.png)\n\n\nFor a discrete random variable, we consider events of the type {_X_\\=_x_} and compute probabilities of such events to describe the distribution of the random variable.\n\n> The Probability Mass Function of a Discrete Random Variable expresses the probability of the variable being equal to each specific value in the range of all potential discrete values defi ned.The sum of these probabilities over all possible values equals 100%.\n\nIn mathematical form, the probability that a discrete random variable X takes on a particular value x, that is, P(X=x), is frequently denoted f(x). The function f(x) is typically called the **probability mass function**\n\nLet _X_ be a discrete random variable with possible values denoted _x_1, _x_2, _xi_, x1, x2, xi,\u2026. The probability mass function of _X_, denoted _p_\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*lZ-QmL4hLdAujjGHkXkwvA.png)\n\n\nThe same above in more general mathematical form, the **probability mass function**, P(X=x)=f(x), of a discrete random variable X is a function that satisfies the following properties:\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*tm9HWK4w0DlbQJ0iYCRfKA.png)\n\n\nFirst item basically says that, for every element x in the support S, all of the probabilities must be positive. Note that if x does not belong in the support S, then f(x)=0. The second item basically says that if you add up the probabilities for all of the possible x values in the support S, then the sum must equal 1. And, the third item says to determine the probability associated with the event A, you just sum up the probabilities of the x values in A.\n\nSince f(x) is a function, it can be presented:\n\n*   in tabular form\n*   in graphical form\n*   as a formula\n\n## Some more daily life examples of discrete random variables\n\nIf a random variable can take only a finite number of discrete values, then it is\ndiscrete.\n\nA fair die is a small cube with a natural number from 1 to 6 engraved on each side equally spaced without repetition. The fairness means that a die is made so that its weight is equally spread and, thus, all six faces are equally likely to face when rolled. So, if rolled, the set of numbers { 1,2,3,4,5,6} is the sample space of this experiment.\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*0XijFoykyVdrAOI53HwRYA.jpeg)\n\n\nNow let\u2019s consider the experiment of rolling a pair of fair dice. Then, the set of\npossible outcomes, that is, the sample space \u03a9, contains 36 pairs.\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*sEVOqPUFOAlnQlmURLO9_g.png)\n\n\nIn each pair, the first element represents the number appearing on one die and the second appearing on the other. We can define a discrete random variable X such that it assigns numbers 1 through 36 to the ordered pairs in \u03a9 from the beginning to the end, respectively, as follows:\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*Wze4Qip1oz4nJsPvMtq_4w.png)\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*Po_F9IzZ8Ap9z_l_q7Wh9A.png)\n\n\nNow an actual Python implemention in the below Jupyter Notebook","9aa98ef2":"## Continuous Random Variables\n\nA **continuous random variable** differs from a discrete random variable in that it takes on an uncountably infinite number of possible outcomes.\n\nWhile for a **discrete random variable** X that takes on a finite or countably infinite number of possible values, we determined P(X=x) for all of the possible values of X, and called it the probability mass function (\u201cp.m.f.\u201d). For **continuous random variables**, the probability that X takes on any particular value x is 0. That is, finding P(X=x) for a continuous random variable X is not going to work. Instead, we\u2019ll need to find the probability that X falls in some interval (a,b), that is, we\u2019ll need to find P(a<X<b). We\u2019ll do that using a probability density function (\u201cp.d.f.\u201d).\n\n> The Probability Density Function of a Continuous Random Variable expresses\n> the rate of change in the probability distribution over the range of potential continuous values defined, and expresses the relative likelihood of getting one value in comparison with another.\n\nA nondiscrete random variable X is said to be absolutely continuous, or simply continuous, if its distribution function may be represented as\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*iCWF6FmzF4KLSLQ1VbfdTA.png)\n\n\nwhere the function f (x) has the properties\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*wFsTXGID52aBtXJRq1z0oQ.png)\n\n\nIt follows from the above that if X is a continuous random variable, then the probability that X takes on any one particular value is zero, whereas the interval probability that X lies between two different values, say, a and b,\nis given by\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*BhniKwIhdw1mSbksK-eIhw.png)\n\n\nA function f (x) that satisfies the above requirements is called a probability function or probability distribution for a continuous random variable, but it is more often called a probability density function or simply density function. Any function f (x) satisfying Properties 1 and 2 above will automatically be a density function, and required probabilities can then be obtained from the more general form below\n\n## Probability Density\u00a0Function\n\nA function f\u00a0: RD \u2192 R is called a probability density function (pdf ) if\n1\\. \u2200x \u2208 RD\u00a0: f (x) > 0\n2\\. Its integral exists and\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*xIKEeVWI1Y0NIMydbDWwfA.png)\n\n\nSo observe that the probability density function is any function f that is\nnon-negative and integrates to one. And as stated above, we associate a random variable X with this function f by\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*wC4r2WAlFIcFVHnstV3iEw.png)\n\n\nAs you can see, the definition for the p.d.f. of a continuous random variable differs from the definition for the p.m.f. of a discrete random variable by simply changing the summations that appeared in the discrete case to integrals in the continuous case.\n\nNow at the start of this article we discussed how density histogram (representing frequency) is defined so that the area of each rectangle equals the relative frequency of the corresponding class, and the area of the entire histogram equals 1. That suggests then that finding the probability that a **continuous random variable X** falls in some interval of values involves finding the area under the curve f(x) sandwiched by the endpoints of the interval.\n\nSo from a large sample space of Pizza, the probability that a randomly selected Pizza weighs between 0.20 and 0.30 pounds is then this area: (which is what the definite Integral formulae above calculates )\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*GIVV3LjatDxwZxg54pZ0sw.png)\n\n\n**Some examples of well known discrete probability distributions include:**\n\n*   Poisson distribution.\n*   Bernoulli and binomial distributions.\n*   Multinoulli and multinomial distributions.\n*   Discrete uniform distribution.\n*   The Geometric Distribution\n*   The Negative-Binomial Distribution\n*   The Hypergeometric Distribution\n\nSome examples of common domains with well-known discrete probability distributions include:\n\n*   The probabilities of dice rolls form a discrete uniform distribution.\n*   The probabilities of coin flips form a Bernoulli distribution.\n*   The probabilities car colors form a multinomial distribution.\n\nA quick summary\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*51lPbnyMX69R6neu-v8aVA.png)\n\n\nNow lets see an simple actual exmaple of Discrete Probability Distribution. Quickly revisit the definition\n\n_The_ **probability distribution** _of a discrete random variable_ _X_ _is a list of each possible value of_ _X_ _together with the probability that_ _X_ _takes that value in one trial of the experiment._\n\nI start with a simple experiment, tossing a fair coin 10 times, and measured how many successes\/heads I observe. I can use the number of successes (heads) observed in many ways to understand the basics of probability. For example, I could simply count how many times we see 0 heads, 1 head, 2 heads with our fair coin toss, and so on. Or here, I am just denoting the outcome with \u2018H\u2019 or \u2018T\u2019 for each experiment.\n\nNow a quick and simple Math example of PDF\n\nLet X be a continuous random variable whose probability density function is:\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*ACqeGOBJ9Tp876tvG77V1g.png)\n\n\nFirst, note again that\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*OyKli-Zap_CJ8o0iES70AQ.png)\n\n\nFor example,\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*IN-5vBbVjoTW695ZKFkYUA.png)\n\n\nwhich is clearly not a probability! In the continuous case, f(x) is instead the height of the curve at X=x, so that the total area under the curve is 1. In the continuous case, it is areas under the curve that define the probabilities.\n\n**What is P(X=1\/2)?**\n\nIt is a straightforward integration to see that the probability is 0:\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*lu13KX55uEZnsFclkeQzkw.png)\n\n\nIn general, if X is continuous, the probability that X takes on any specific value x is 0. That is, when X is continuous, P(X=x)=0 for all x in the support.\n\nAn implication of the fact that **P(X=x)=0 for all x when X is continuous** is that you can be less precise about the endpoints of intervals when finding probabilities of continuous random variables. That is:\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*LfGN-ap1IlNA6lodEqi7Uw.png)\n\n\nfor any constants a and b.\n\n**Further explanation of the above principle**\n\nThe probability of observing any single value of the continuous random variable is 0 since the number of possible outcomes of a continuous random variable is uncountable and infinite. That is, for a continuous random variable, we must calculate a probability over an interval rather than at a particular point. This is why the probability for a continuous random variable can be interpreted as an area under the curve on an interval. In other words, we cannot describe the probability distribution of a continuous random variable by giving probability of single values of the random variable as we did for a discrete random variable. This property can also be seen from the fact that\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*hXhSKswuVhJtYxpiatobMA.png)\n\n\nfor any real **c**\n\n## Why do I need to Integrate over the PDF to get the Probability\n\nIn the case of of continuous random variable, we should not ask for the probability that **_X_** is exactly a single number (since that probability is zero). Instead, we need to think about the probability that **x** is close to a single number.\n\nWe capture the notion of being close to a number with a _probability density function_ which is normally denoted by **P(_x_)**. If the probability density around a point **x** is large, that means the random variable **X** is likely to be close to **_x_**. If, on the other hand, **P(_x_)=0** in some interval, then **_X_** won\u2019t be in that interval.\n\nSo building on the Integration concept of Calculus\n\nIf the probability of **X** being exactly at point \ud835\udc99 is zero, how about an extremely small interval around the point **\ud835\udc99**? Say, **\\[\ud835\udc99, \ud835\udc99+d\ud835\udc99\\]?**\n\nLet\u2019s assume **d\ud835\udc99** is infinitesimally small with a value of 0.00000000001.\n\nThen the probability that **X** will fall in **\\[\ud835\udc99, \ud835\udc99+d\ud835\udc99\\]** is the **Area** under the curve **f(\ud835\udc99)** sandwiched by **\\[\ud835\udc99, \ud835\udc99+d\ud835\udc99\\]**.\n\n**The Area Under a Curve\u200a\u2014\u200aIntegral Calculus Basics**\n\nThe area under a curve between two points can be found by doing a definite integral between the two points. To find the area under the curve y = f(x) between x = a and x = b, integrate y = f(x) between the limits of a and b.\n\nTo translate the probability density P(x) into a probability, imagine that _Ix_ is some small interval around the point x. Then, assuming P is continuous, the probability that _X_ is in that interval will depend both on the density P(_x_) and the length of the interval\n\nP ( _X_ \u2208 _Ix_) \u2248 P (_x_) \u00d7 Length of _Ix_\n\nWe don\u2019t have a true equality here, because the density P may vary over the interval Ix. But, the approximation becomes better and better as the interval Ix shrinks around the point x, as P will be come closer and closer to a constant inside that small interval. The probability P ( X \u2208 Ix ) approaches zero as Ix shrinks down to an infinitesemally small value to the point x (consistent with our above result for single numbers), but the information about X is contained in the rate that this probability goes to zero as Ix shrinks.\n\nSo, to determine the probability that X is in any subset A of the real numbers, we simply add up the values of P(x) in the subset. By \u201cadd up,\u201d we mean integrate the function P(x) over the set A.\n\n## Cumulative Distribution Function\n\n> **The Cumulative Distribution Function of a Discrete Random Variable** expresses the theoretical or observed probability of that variable being less than or equal to any given value. **It equates to the sum of the probabilities** of achieving that value and each successive lower value.\n\n## Example of the Cumulative Distribution Function for Rolling a Single\u00a0Die\n\n![](https:\/\/cdn-images-1.medium.com\/max\/800\/1*4SFG0KbHXD508qm0pxd92Q.png)\n\n\nAnd now the same for Continuous Random Variable\n\n> **The Cumulative Distribution Function of a Continuous Random Variable**  \n> expresses the theoretical or observed probability of that variable being less than or equal to any given value. **It equates to the area under the Probability Density Function curve** to the left of the value in question.\n\nNow implementing some very basic PDF with Python and Scipy"}}