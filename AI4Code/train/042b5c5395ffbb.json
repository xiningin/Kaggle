{"cell_type":{"4a8cc9d5":"code","a08269f0":"code","60c2272b":"code","5bab121e":"code","27812612":"code","851da622":"code","4636d180":"code","34503147":"code","9d353e95":"code","1cba3a65":"code","cf1dccf4":"code","c1e8b1ec":"code","cb3ae352":"code","e8d88f10":"code","7e0b5bf5":"code","66a3948c":"code","64f9e0be":"code","04ca1d69":"code","9088fc6c":"code","e35f5aee":"code","1c6e39de":"code","111b1f9a":"code","c0466720":"markdown","ba2e6591":"markdown","975fa413":"markdown","b3626149":"markdown","64f97e69":"markdown","2c18401e":"markdown","4359cbfb":"markdown"},"source":{"4a8cc9d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a08269f0":"!pip install git+https:\/\/github.com\/AutoViML\/Auto_ViML.git","60c2272b":"df = pd.read_csv(\"..\/input\/telecom-users-dataset\/telecom_users.csv\")\ndf.head()","5bab121e":"df1 = df.drop([\"customerID\", \"Unnamed: 0\"], axis = 1)  #removing unncessary features","27812612":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.preprocessing import LabelEncoder\n\n#encoding categorical variables\nfor c in df1.columns:\n    if df1[c].dtype=='object': \n        lbl = LabelEncoder()\n        lbl.fit(list(df1[c].values))\n        df1[c] = lbl.transform(df1[c].values)\n        ","851da622":"df1.head()","4636d180":"df1.describe()  #basic statistics","34503147":"#understading correlation\nimport seaborn as sn\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nplt.figure( figsize=(18,13))\nsn.heatmap(df1.corr(),annot = True)","9d353e95":"df1.corr().abs()['Churn'].sort_values(ascending = False)","1cba3a65":"# imports\nimport math\nimport numpy as np\nfrom numpy.random import randn\nfrom statsmodels.stats.weightstats import ztest\n# Generate a random array of 80 numbers having mean df.Churn.mean() and sd df.Churn.std()\/math.sqrt(80)\nmean = df1.Churn.mean()\nsd = df1.Churn.std()\/math.sqrt(80)\nalpha =0.05\nnull_mean =.25\ndata = sd*randn(80)+mean\n# print mean and sd\nprint('mean=%.2f stdv=%.2f' % (np.mean(data), np.std(data)))\n\n# now we perform the test. In this function, we passed data, in value parameter\n# we passed mean value in the null hypothesis, in alternative hypothesis we check whether the\n# mean is larger\n\nztest_Score, p_value= ztest(data,value = null_mean, alternative='larger')\n# the function outputs a p_value and z-score corresponding to that value, we compare the\n# p-value with alpha, if it is greater than alpha then we do not null hypothesis\n# else we reject it.\nprint(\"p-value is:\",float(p_value))\nif (p_value < alpha):\n    \n    \n    print(\"Reject Null Hypothesis\")\n    \nelse:\n        \n        \n    print(\"Fail to Reject NUll Hypothesis\")\n","cf1dccf4":"from scipy.stats import ttest_1samp\n\nchurn_mean = np.mean(df1.Churn)\nprint(churn_mean)\nttest, pval = ttest_1samp(df1.Churn, .25)\nprint(\"p-value is:\", pval)\nif pval < 0.05:    # alpha value is 0.05 or 5%\n    print(\"we are rejecting null hypothesis\")\nelse:\n    print(\"we are accepting null hypothesis\")","c1e8b1ec":"#revisit the data\n\ndf.head()","cb3ae352":"df.shape","e8d88f10":"size = int(0.75*df.shape[0]) #75% of data for training and 25% data for testing\nsize","7e0b5bf5":"train = df[:size]\ntest =df[size:]\ntarget ='Churn'\n#75% of data for training and 25% data for testing\nprint(f\"train shape: {train.shape}\")\nprint(f\"test shape: {test.shape}\")","66a3948c":"from autoviml.Auto_ViML import Auto_ViML","64f9e0be":"model, features, trainm, testm = Auto_ViML(\n    train,\n    target,\n    test,\n    hyper_param=\"RS\",\n    feature_reduction=True,\n    scoring_parameter=\"balancedaccuracy\",\n    KMeans_Featurizer=False,\n    Boosting_Flag=None,\n    Binning_Flag=False,\n    Add_Poly=0,\n    Stacking_Flag=False,\n    Imbalanced_Flag=False,\n    verbose=0,\n)","04ca1d69":"testm","9088fc6c":"from sklearn.metrics import classification_report, confusion_matrix\nconfusion_matrix(test[target].values, testm['Churn_Naive_Bayes_predictions'].values)\n\n","e35f5aee":"confusion_matrix(test[target].values, testm['Churn_Linear_predictions'].values)","1c6e39de":"from sklearn.metrics import accuracy_score\nprint(\"Naive Bayes:\", accuracy_score(test[target].values, testm['Churn_Naive_Bayes_predictions'].values)\n)\n\nprint(\"Linear prediction:\", accuracy_score(test[target].values, testm['Churn_Linear_predictions'].values)\n)\n\nprint(\"Decision Tree prediction:\", accuracy_score(test[target].values, testm['Churn_Decision_Tree_predictions'].values)\n)\n\n\nprint(\"AdaBoost prediction:\", accuracy_score(test[target].values, testm['Churn_Adaboost_predictions'].values)\n)\n\nprint(\"AdaBoost prediction:\", accuracy_score(test[target].values, testm['Churn_Adaboost_predictions'].values)\n)\n\nprint(\"Bagging prediction:\", accuracy_score(test[target].values, testm['Churn_Bagging_Classifier_predictions'].values)\n)","111b1f9a":"confusion_matrix(test[target].values, testm['Churn_Decision_Tree_predictions'].values)","c0466720":"## Statistical tests","ba2e6591":"Upvote if you find this useful :)","975fa413":"## One sample t-test : The One Sample t Test determines whether the sample mean is statistically different from a known or hypothesised population mean. The One Sample t Test is a parametric test.","b3626149":"### Contract and Tenure are mainly correlated with Churn, with values of 0.4 and 0.35\n### Tenure and contract are highly correlated with value of .67, which means with increase or decrease in tenure, contract will also rise or fall\n\n### Churn and gender, churn and Phone service have almost no relation at all with values of 0.01 for both \n","64f97e69":"## Decision Tree is a better predictor with accuracy score 80%","2c18401e":"### Suppose our Null Hypothesis is H0: population Churn mean = .25\n###              Alternate Hypothesis H1: Population Churn mean > .25\n## We now perform ztest and ttest to prove which hypothesis is correct.","4359cbfb":"Therefore Churn mean is more than 25%"}}