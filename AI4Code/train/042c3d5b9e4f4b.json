{"cell_type":{"8b449d96":"code","9068a9e9":"code","f17cd88b":"code","15c8a505":"code","caf9bc7d":"code","1068baa5":"code","ea09df49":"code","88659e0d":"code","ebd26c59":"code","258a3dd9":"code","8d68f5ff":"code","65cd0fd8":"code","02287b2c":"code","0dffaf15":"code","6bc7135c":"code","2e07ebcd":"code","3b0849da":"code","1139df5a":"code","1bf99b02":"code","43d3c80a":"code","df89850e":"code","130fd448":"code","13cb0a9c":"code","6782dc22":"code","a4d0ea70":"code","0015a514":"code","d634e821":"code","b523f409":"code","510c76dc":"code","a2600056":"code","c0fe0ca0":"code","cb5452f5":"code","1c73c0f6":"markdown","691a0b00":"markdown","f033a0cd":"markdown","e3835620":"markdown","5a7e8ffb":"markdown","3ad0376e":"markdown","85a8564b":"markdown","be12f0d6":"markdown","a12f4957":"markdown","92ec3d2f":"markdown","e5d698d3":"markdown","bcc6f389":"markdown","a68450cb":"markdown","3a4b5945":"markdown","76898d7a":"markdown","233b2b86":"markdown","b937d26f":"markdown","b52b2045":"markdown","4c839873":"markdown"},"source":{"8b449d96":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.filterwarnings(action='ignore')\n\nsns.set(style = 'darkgrid')","9068a9e9":"df = pd.read_csv('..\/input\/pima-indians-diabetes-database\/diabetes.csv')\ndf.shape","f17cd88b":"df.head()","15c8a505":"df.info()","caf9bc7d":"df.isnull().sum()","1068baa5":"df.describe()","ea09df49":"plt.figure(figsize = (15,4))\n\ndf_null = df.iloc[:,1:-1].replace(0, np.nan)\n\nsns.heatmap(df_null.isnull(), cmap = 'Greys')\nplt.title('Missing Value', size = 15)\nplt.show()","88659e0d":"sns.countplot(df['Outcome'])\n\nplt.title('Count of Outcome')\nplt.show()","ebd26c59":"df_0 = df[df['Outcome'] == 0]\ndf_1 = df[df['Outcome'] == 1]\ndf_0.shape, df_1.shape","258a3dd9":"fig, axes = plt.subplots(nrows=4, ncols = 2, figsize = (15,15))\n\nfor i, col_name in enumerate(df.iloc[:,:-1]):\n    row = i \/\/ 2\n    col = i % 2\n    sns.distplot(df_0[col_name], ax = axes[row,col], hist = False)\n    sns.distplot(df_1[col_name], ax = axes[row,col], hist = False)\nplt.show()","8d68f5ff":"df['Pregnancies_high'] = df['Pregnancies'] > 6\n\nsns.countplot(data = df, x = 'Pregnancies_high', hue = 'Outcome')\nplt.title('Diabetes , Pregnancies', size = 15)\nplt.xlabel('Pregnancies > 6')\nplt.show()","65cd0fd8":"df['Insulin'].replace(0, np.nan, inplace = True)\ndf.groupby('Outcome')['Insulin'].agg(['mean', 'median'])","02287b2c":"df['Insulin'].fillna(df.groupby('Outcome')['Insulin'].transform('median'), inplace = True)","0dffaf15":"df_matrix = df\ndf_corr = df.corr()\n\nplt.figure(figsize = (12,6))\nsns.heatmap(df_corr, vmax = 1, vmin = -1, cmap = 'coolwarm', annot = True)\nplt.show()","6bc7135c":"plt.figure(figsize = (10,4))\n\nsns.lmplot(data = df, x = 'Insulin', y = 'Glucose',hue = 'Outcome')\nplt.title('Glucose, Insulin', size = 15)\nplt.show()","2e07ebcd":"df['low_glu_insulin'] =(df['Glucose'] < 100) & (df['Insulin'] <= 102.5)\n\npd.crosstab(df['Outcome'], df['low_glu_insulin'])","3b0849da":"plt.figure(figsize = (15,2))\nsns.violinplot(df['Insulin'])\n\nplt.title('Violinplot of Insulin')\nplt.show()","1139df5a":"df = df[df['Insulin'] < 600]\ndf.head()","1bf99b02":"plt.figure(figsize = (10,4))\ndf['Insulin_log'] = np.log(df['Insulin'] + 1)\nsns.distplot(df[\"Insulin_log\"])\nplt.show()","43d3c80a":"from sklearn.model_selection import train_test_split\n\nX = df[['Glucose', 'BloodPressure', 'SkinThickness',\n       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Pregnancies_high',\n        'Insulin_log', 'low_glu_insulin']]\ny = df['Outcome']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)\n\nprint('train \uac1c\uc218: ', X_train.shape, y_train.shape)\nprint('test \uac1c\uc218: ', X_test.shape, y_test.shape)","df89850e":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\n\nestimators = [DecisionTreeClassifier(random_state = 42),\n             RandomForestClassifier(random_state = 42),\n             GradientBoostingClassifier(random_state = 42)\n             ]\nestimators","130fd448":"max_depth = np.random.randint(2,20,20)\nmax_features = np.random.uniform(0.5, 1.0, 20)\n\nparam_distributions = {\n    'max_depth' : max_depth, \n    'max_features' : max_features}\nparam_distributions","13cb0a9c":"from sklearn.model_selection import RandomizedSearchCV\n\nresults = []\n\nfor estimator in estimators:\n    result = []\n    if estimator.__class__.__name__ != 'DecisionTreeClassifier':\n        param_distributions['n_estimators'] = np.random.randint(100,1000,10)\n        \n    clf = RandomizedSearchCV(estimator, \n                             param_distributions = param_distributions, \n                             n_iter = 100,\n                             scoring = 'accuracy',\n                             n_jobs = -1,\n                             cv = 5,\n                             verbose = 2)\n\n    clf.fit(X_train, y_train)\n    result.append(estimator.__class__.__name__)\n    result.append(clf.best_params_)\n    result.append(clf.best_estimator_)\n    result.append(clf.best_score_)\n    result.append(clf.score(X_test, y_test))\n    result.append(clf.cv_results_)\n    results.append(result)","6782dc22":"df_cv = pd.DataFrame(results)\ndf_cv.columns = ['model', 'best_params', 'best_estimator', 'train_score', 'test_score', 'cv_result']\ndf_cv","a4d0ea70":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\n\nmodel = df_cv.loc[1, 'best_estimator']\nmodel.fit(X_train, y_train)\ny_predict = model.predict(X_test)","0015a514":"pd.DataFrame(confusion_matrix(y_test, y_predict))","d634e821":"print(classification_report(y_test, y_predict))","b523f409":"lgbm = LGBMClassifier(n_estimators = 100, num_leaves =61, random_state = 42)\nlgbm.fit(X_train, y_train)\ny_predict = lgbm.predict(X_test)\n\npd.DataFrame(confusion_matrix(y_test, y_predict))","510c76dc":"lgbm_report = classification_report(y_test, y_predict)\nprint(lgbm_report)","a2600056":"plt.figure(figsize = (10,4))\n\nfeature_importance=model.feature_importances_\nsns.barplot(x = feature_importance, y = X_train.columns)\n\nplt.title('Feature Importance', size = 15)\nplt.show()","c0fe0ca0":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import roc_auc_score\n\npred_proba = model.predict_proba(X_test)[:, 1] \npred_proba_lgbm = lgbm.predict_proba(X_test)[:,1]\n\ndef roc_curve_plot(y_test, pred_proba):\n    fprs, tprs, thresholds = roc_curve(y_test, pred_proba)\n    fprs2, tprs2, threshholds = roc_curve(y_test, pred_proba_lgbm)\n    plt.plot(fprs, tprs, label = 'Random Forest')\n    plt.plot(fprs2, tprs2, label = 'LightGBM')\n    plt.plot([0,1],[0,1], 'k--', label = \"Random\")\n    plt.xlim(0,1); plt.ylim(0,1)\n    start, end = plt.xlim()\n    plt.xticks(np.round(np.arange(start, end, 0.1),2))\n    \nroc_curve_plot(y_test, pred_proba)\nplt.legend()\nplt.show()","cb5452f5":"print('Random Forest AUC: ', roc_auc_score(y_test, pred_proba))\nprint('LightGBM AUC: ', roc_auc_score(y_test, pred_proba_lgbm))","1c73c0f6":"### Log","691a0b00":"we can see that 0 is about twice as many.","f033a0cd":"kaggle : https:\/\/www.kaggle.com\/uciml\/pima-indians-diabetes-database\n\nwikipedia : https:\/\/en.wikipedia.org\/wiki\/Pima_people","e3835620":"The higher the pregnancies, glucose, and BMI, the higher the risk of diabetes.\n\nIn the case of Pregnancies, the range is wide from 0 to 20.\n\nIt would be nice to categorize it for analysis.\n\nIn the case of Age, the proportion of people in their 20s and 30s is high, but it can be seen that the incidence rate increases after the age of 30.\n\nGenerally, Insulin is expected to be closely related to diabetes, but the graph is not.\n\nbecause NaN is marked as 0.","5a7e8ffb":"### Correlation","3ad0376e":"### Outlier","85a8564b":"# 1. Pima Indian Diabetes","be12f0d6":"# 3. Modeling","a12f4957":"People with diabetes have higher insulin levels than those who do not.","92ec3d2f":"There is no missing value.","e5d698d3":"Since we replaced it with the median, there are many numbers in 102 and 169.","bcc6f389":"There seemed to be no missing values, but you can see that the minimum values of the Glucose, BloodPressure, Skin Thickness, Insulin, and BMI variables are zero.\n\nThis means that the missing value was marked as 0, not NaN.","a68450cb":"# 2. Exploratory Data Analysis","3a4b5945":"Outcome and Glucose have the strongest correlation.","76898d7a":"### Replace Insulin","233b2b86":"There are a lot of missing values for insulin.","b937d26f":"Wow! RandomForestClassifier is the best model!","b52b2045":"We can see that insulin has a great deal of influence.","4c839873":"### Split"}}