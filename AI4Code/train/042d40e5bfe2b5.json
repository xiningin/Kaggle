{"cell_type":{"ca4b4480":"code","d19490f5":"code","92ebed00":"code","6ef4f4a1":"code","54851422":"code","8570e739":"code","5ddc7975":"code","6a78d1a9":"code","19894814":"code","d51a9f7d":"code","be035a2c":"code","13f99c3e":"code","f4635686":"code","818b6dad":"code","c114e954":"code","dc6adbc3":"code","c19f7eb4":"code","809bbf48":"code","3287351c":"code","cbe2fd6e":"code","da889644":"code","84c00408":"code","ebae7573":"code","23629b24":"code","393a556e":"code","bbbb03bd":"code","b0f43aa9":"code","d0c1c9eb":"code","4060321e":"code","daab18bc":"code","14da6b98":"code","c8e7d0d0":"code","bc1ecd75":"code","c73f86bc":"code","1543eb14":"code","8553d460":"code","9a1b9d46":"code","ae6581ee":"code","50714ba7":"code","f78fb2c8":"code","28492ec9":"code","6722e24e":"code","4493bd3a":"code","2846b623":"code","a7252c64":"code","4435a6ed":"code","7d50fcad":"code","f3c26b35":"code","b57e9cc7":"code","ff2c10f3":"code","96adc61f":"code","003b882a":"code","30c89bd9":"code","67951491":"code","922e25b9":"code","337eb54a":"code","f6194035":"code","1840ddd4":"code","9ff49382":"code","127fd14c":"code","b295f6c6":"code","ac708d93":"code","2cae9a96":"code","c59585e2":"code","e67c203d":"code","a94c8897":"code","53c6a9cd":"code","4e23b608":"code","0e7d8ce4":"code","185a5790":"code","46fc803d":"code","fb84aadd":"code","68914878":"code","bfc7e328":"code","77581b28":"code","77fbda76":"code","2140508c":"code","de461045":"code","770f7191":"code","4b709522":"code","13d950da":"code","d9ebaf45":"code","75bc0300":"code","aaedd8fe":"code","65d2b343":"code","f9f909a2":"code","74cc9b61":"code","8e02f2b7":"code","ded2cbeb":"code","1142b000":"code","0d0f5abc":"code","ec4af2c7":"code","4a113bc4":"code","34dbc628":"code","e3b1f439":"code","c2f1d6e5":"code","8af02818":"code","31df14c8":"code","97b727cf":"code","26a4b54e":"code","b07d2f3e":"code","1f25cb03":"code","7fc9ec2e":"code","ea938c9c":"code","c62900bc":"code","81a58218":"code","38579201":"markdown","c5495047":"markdown","b5d9f533":"markdown","92aa2d60":"markdown","4827023b":"markdown","3ffe1c07":"markdown","cf71a50c":"markdown","ba130d33":"markdown","a8ed28c4":"markdown","944704cb":"markdown","661f00dc":"markdown","383a25d2":"markdown","7f5357d7":"markdown","3867dccc":"markdown","9f60eeb1":"markdown","a9c67afb":"markdown","fa2b20f9":"markdown","88ae6e2b":"markdown","e35dac37":"markdown","3545ca50":"markdown","57429746":"markdown","acba81d1":"markdown","5392ebad":"markdown","c814a475":"markdown","6235ef9c":"markdown","3afc757c":"markdown","3ba7902d":"markdown","95035afb":"markdown","2e0b0df5":"markdown","f251361e":"markdown","553a170d":"markdown","4fb39902":"markdown","4417c737":"markdown","7f568d69":"markdown","8a429179":"markdown","8639f5f9":"markdown","dc9b6b6b":"markdown","581671a3":"markdown","4ea5ec03":"markdown","6a9152fe":"markdown","d90178f6":"markdown"},"source":{"ca4b4480":"# data analysis libraries:\nimport numpy as np\nimport pandas as pd\n\n# data visualization libraries:\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# to ignore warnings:\nimport warnings\nwarnings.filterwarnings('ignore')\n\n# to display all columns:\npd.set_option('display.max_columns', None)\n\nfrom sklearn.model_selection import train_test_split, GridSearchCV","d19490f5":"# Read train and test data with pd.read_csv():\ntrain_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","92ebed00":"# copy data in order to avoid any change in the original:\ntrain = train_data.copy()\ntest = test_data.copy()","6ef4f4a1":"train.head()","54851422":"test.head()","8570e739":"train.info()","5ddc7975":"train.describe().T","6a78d1a9":"train['Pclass'].value_counts()","19894814":"train['Sex'].value_counts()","d51a9f7d":"train['SibSp'].value_counts()","be035a2c":"train['Parch'].value_counts()","13f99c3e":"train['Ticket'].value_counts()","f4635686":"train['Cabin'].value_counts()","818b6dad":"train['Embarked'].value_counts()","c114e954":"sns.barplot(x = 'Pclass', y = 'Survived', data = train);","dc6adbc3":"sns.barplot(x = 'SibSp', y = 'Survived', data = train);","c19f7eb4":"sns.barplot(x = 'Parch', y = 'Survived', data = train);","809bbf48":"sns.barplot(x = 'Sex', y = 'Survived', data = train);","3287351c":"train.head()","cbe2fd6e":"# We can drop the Ticket feature since it is unlikely to have useful information\ntrain = train.drop(['Ticket'], axis = 1)\ntest = test.drop(['Ticket'], axis = 1)\n\ntrain.head()","da889644":"train.describe().T","84c00408":"# It looks like there is a problem in Fare max data. Visualize with boxplot.\nsns.boxplot(x = train['Fare']);","ebae7573":"Q1 = train['Fare'].quantile(0.25)\nQ3 = train['Fare'].quantile(0.75)\nIQR = Q3 - Q1\n\nlower_limit = Q1- 1.5*IQR\nlower_limit\n\nupper_limit = Q3 + 1.5*IQR\nupper_limit","23629b24":"# observations with Fare data higher than the upper limit:\n\ntrain['Fare'] > (upper_limit)","393a556e":"train.sort_values(\"Fare\", ascending=False).head()","bbbb03bd":"# In boxplot, there are too many data higher than upper limit; we can not change all. Just repress the highest value -512- \ntrain['Fare'] = train['Fare'].replace(512.3292, 300)","b0f43aa9":"train.sort_values(\"Fare\", ascending=False).head()","d0c1c9eb":"test.sort_values(\"Fare\", ascending=False)","4060321e":"test['Fare'] = test['Fare'].replace(512.3292, 300)","daab18bc":"test.sort_values(\"Fare\", ascending=False)","14da6b98":"train.isnull().sum()","c8e7d0d0":"train[\"Age\"] = train[\"Age\"].fillna(train[\"Age\"].mean())","bc1ecd75":"test[\"Age\"] = test[\"Age\"].fillna(test[\"Age\"].mean())","c73f86bc":"train.isnull().sum()","1543eb14":"test.isnull().sum()","8553d460":"train.isnull().sum()","9a1b9d46":"test.isnull().sum()","ae6581ee":"train[\"Embarked\"].value_counts()","50714ba7":"# Fill NA with the most frequent value:\ntrain[\"Embarked\"] = train[\"Embarked\"].fillna(\"S\")","f78fb2c8":"test[\"Embarked\"] = test[\"Embarked\"].fillna(\"S\")","28492ec9":"train.isnull().sum()","6722e24e":"test.isnull().sum()","4493bd3a":"test[test[\"Fare\"].isnull()]","2846b623":"test[[\"Pclass\",\"Fare\"]].groupby(\"Pclass\").mean()","a7252c64":"test[\"Fare\"] = test[\"Fare\"].fillna(12)","4435a6ed":"test[\"Fare\"].isnull().sum()","7d50fcad":"# Create CabinBool variable which states if someone has a Cabin data or not:\n\ntrain[\"CabinBool\"] = (train[\"Cabin\"].notnull().astype('int'))\ntest[\"CabinBool\"] = (test[\"Cabin\"].notnull().astype('int'))\n\ntrain = train.drop(['Cabin'], axis = 1)\ntest = test.drop(['Cabin'], axis = 1)\n\ntrain.head()","f3c26b35":"train.isnull().sum()","b57e9cc7":"test.isnull().sum()","ff2c10f3":"# Map each Embarked value to a numerical value:\n\nembarked_mapping = {\"S\": 1, \"C\": 2, \"Q\": 3}\n\ntrain['Embarked'] = train['Embarked'].map(embarked_mapping)\ntest['Embarked'] = test['Embarked'].map(embarked_mapping)","96adc61f":"train.head()","003b882a":"# Convert Sex values into 1-0:\n\nfrom sklearn import preprocessing\n\nlbe = preprocessing.LabelEncoder()\ntrain[\"Sex\"] = lbe.fit_transform(train[\"Sex\"])\ntest[\"Sex\"] = lbe.fit_transform(test[\"Sex\"])","30c89bd9":"train.head()","67951491":"train[\"Title\"] = train[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)\ntest[\"Title\"] = test[\"Name\"].str.extract(' ([A-Za-z]+)\\.', expand=False)","922e25b9":"train.head()","337eb54a":"train['Title'] = train['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntrain['Title'] = train['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntrain['Title'] = train['Title'].replace('Mlle', 'Miss')\ntrain['Title'] = train['Title'].replace('Ms', 'Miss')\ntrain['Title'] = train['Title'].replace('Mme', 'Mrs')","f6194035":"test['Title'] = test['Title'].replace(['Lady', 'Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Jonkheer', 'Dona'], 'Rare')\ntest['Title'] = test['Title'].replace(['Countess', 'Lady', 'Sir'], 'Royal')\ntest['Title'] = test['Title'].replace('Mlle', 'Miss')\ntest['Title'] = test['Title'].replace('Ms', 'Miss')\ntest['Title'] = test['Title'].replace('Mme', 'Mrs')","1840ddd4":"train.head()","9ff49382":"test.head()","127fd14c":"train[[\"Title\",\"PassengerId\"]].groupby(\"Title\").count()","b295f6c6":"train[['Title', 'Survived']].groupby(['Title'], as_index=False).mean()","ac708d93":"# Map each of the title groups to a numerical value\n\ntitle_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Royal\": 5, \"Rare\": 5}\n\ntrain['Title'] = train['Title'].map(title_mapping)","2cae9a96":"train.isnull().sum()","c59585e2":"test['Title'] = test['Title'].map(title_mapping)","e67c203d":"test.head()","a94c8897":"train = train.drop(['Name'], axis = 1)\ntest = test.drop(['Name'], axis = 1)","53c6a9cd":"train.head()","4e23b608":"bins = [0, 5, 12, 18, 24, 35, 60, np.inf]\nmylabels = ['Baby', 'Child', 'Teenager', 'Student', 'Young Adult', 'Adult', 'Senior']\ntrain['AgeGroup'] = pd.cut(train[\"Age\"], bins, labels = mylabels)\ntest['AgeGroup'] = pd.cut(test[\"Age\"], bins, labels = mylabels)","0e7d8ce4":"# Map each Age value to a numerical value:\nage_mapping = {'Baby': 1, 'Child': 2, 'Teenager': 3, 'Student': 4, 'Young Adult': 5, 'Adult': 6, 'Senior': 7}\ntrain['AgeGroup'] = train['AgeGroup'].map(age_mapping)\ntest['AgeGroup'] = test['AgeGroup'].map(age_mapping)","185a5790":"train.head()","46fc803d":"#dropping the Age feature for now, might change:\ntrain = train.drop(['Age'], axis = 1)\ntest = test.drop(['Age'], axis = 1)","fb84aadd":"train.head()","68914878":"# Map Fare values into groups of numerical values:\ntrain['FareBand'] = pd.qcut(train['Fare'], 4, labels = [1, 2, 3, 4])\ntest['FareBand'] = pd.qcut(test['Fare'], 4, labels = [1, 2, 3, 4])","bfc7e328":"# Drop Fare values:\ntrain = train.drop(['Fare'], axis = 1)\ntest = test.drop(['Fare'], axis = 1)","77581b28":"train.head()","77fbda76":"train.head()","2140508c":"train[\"FamilySize\"] = train_data[\"SibSp\"] + train_data[\"Parch\"] + 1","de461045":"test[\"FamilySize\"] = test_data[\"SibSp\"] + test_data[\"Parch\"] + 1","770f7191":"# Create new feature of family size:\n\ntrain['Single'] = train['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntrain['SmallFam'] = train['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntrain['MedFam'] = train['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntrain['LargeFam'] = train['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","4b709522":"train.head()","13d950da":"# Create new feature of family size:\n\ntest['Single'] = test['FamilySize'].map(lambda s: 1 if s == 1 else 0)\ntest['SmallFam'] = test['FamilySize'].map(lambda s: 1 if  s == 2  else 0)\ntest['MedFam'] = test['FamilySize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ntest['LargeFam'] = test['FamilySize'].map(lambda s: 1 if s >= 5 else 0)","d9ebaf45":"test.head()","75bc0300":"# Convert Title and Embarked into dummy variables:\n\ntrain = pd.get_dummies(train, columns = [\"Title\"])\ntrain = pd.get_dummies(train, columns = [\"Embarked\"], prefix=\"Em\")","aaedd8fe":"train.head()","65d2b343":"test = pd.get_dummies(test, columns = [\"Title\"])\ntest = pd.get_dummies(test, columns = [\"Embarked\"], prefix=\"Em\")","f9f909a2":"test.head()","74cc9b61":"# Create categorical values for Pclass:\ntrain[\"Pclass\"] = train[\"Pclass\"].astype(\"category\")\ntrain = pd.get_dummies(train, columns = [\"Pclass\"],prefix=\"Pc\")","8e02f2b7":"test[\"Pclass\"] = test[\"Pclass\"].astype(\"category\")\ntest = pd.get_dummies(test, columns = [\"Pclass\"],prefix=\"Pc\")","ded2cbeb":"train.head()","1142b000":"test.head()","0d0f5abc":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\npredictors = train.drop(['Survived', 'PassengerId'], axis=1)\ntarget = train[\"Survived\"]\nx_train, x_test, y_train, y_test = train_test_split(predictors, target, test_size = 0.20, random_state = 0)","ec4af2c7":"x_train.shape","4a113bc4":"x_test.shape","34dbc628":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(x_train, y_train)\ny_pred = logreg.predict(x_test)\nacc_logreg = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_logreg)","e3b1f439":"from sklearn.ensemble import RandomForestClassifier\n\nrandomforest = RandomForestClassifier()\nrandomforest.fit(x_train, y_train)\ny_pred = randomforest.predict(x_test)\nacc_randomforest = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_randomforest)","c2f1d6e5":"from sklearn.ensemble import GradientBoostingClassifier\n\ngbk = GradientBoostingClassifier()\ngbk.fit(x_train, y_train)\ny_pred = gbk.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","8af02818":"xgb_params = {\n        'n_estimators': [200, 500],\n        'subsample': [0.6, 1.0],\n        'max_depth': [2,5,8],\n        'learning_rate': [0.1,0.01,0.02],\n        \"min_samples_split\": [2,5,10]}","31df14c8":"xgb = GradientBoostingClassifier()\n\nxgb_cv_model = GridSearchCV(xgb, xgb_params, cv = 10, n_jobs = -1, verbose = 2)","97b727cf":"xgb_cv_model.fit(x_train, y_train)","26a4b54e":"xgb_cv_model.best_params_","b07d2f3e":"xgb = GradientBoostingClassifier(learning_rate = xgb_cv_model.best_params_[\"learning_rate\"], \n                    max_depth = xgb_cv_model.best_params_[\"max_depth\"],\n                    min_samples_split = xgb_cv_model.best_params_[\"min_samples_split\"],\n                    n_estimators = xgb_cv_model.best_params_[\"n_estimators\"],\n                    subsample = xgb_cv_model.best_params_[\"subsample\"])","1f25cb03":"xgb_tuned =  xgb.fit(x_train,y_train)","7fc9ec2e":"y_pred = xgb_tuned.predict(x_test)\nacc_gbk = round(accuracy_score(y_pred, y_test) * 100, 2)\nprint(acc_gbk)","ea938c9c":"test","c62900bc":"#set ids as PassengerId and predict survival \nids = test['PassengerId']\npredictions = xgb_tuned.predict(test.drop('PassengerId', axis=1))\n\n#set the output as a dataframe and convert to csv file named submission.csv\noutput = pd.DataFrame({ 'PassengerId' : ids, 'Survived': predictions })\noutput.to_csv('submission.csv', index=False)","81a58218":"output.head()","38579201":"### Name - Title","c5495047":"## Spliting the train data","b5d9f533":"### Sex","92aa2d60":"### Ticket","4827023b":"**Titanic Survival Prediction:**\n\nUse machine learning to create a model that predicts which passengers survived the Titanic shipwreck.","3ffe1c07":"## Importing Librarires","cf71a50c":"### Basic summary statistics about the numerical data","ba130d33":"# Business Understanding \/ Problem Definition","a8ed28c4":"### Fare","944704cb":"# Data Understanding (Exploratory Data Analysis)","661f00dc":"### Pclass","383a25d2":"**Variable Notes:**\n\nPclass: A proxy for socio-economic status (SES)\n- 1st = Upper\n- 2nd = Middle\n- 3rd = Lower\n\nAge: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nSibSp: The dataset defines family relations in this way...\n- Sibling = brother, sister, stepbrother, stepsister\n- Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nParch: The dataset defines family relations in this way...\n- Parent = mother, father\n- Child = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","7f5357d7":"#### Sex vs survived:","3867dccc":"## Deleting Unnecessary Variables","9f60eeb1":"## Gradient Boosting Classifier","a9c67afb":"### Cabin","fa2b20f9":"# Modeling, Evaluation and Model Tuning","88ae6e2b":"### Embarked","e35dac37":"## Feature Engineering","3545ca50":"## Analysis and Visualization of Numeric and Categorical Variables","57429746":"#### Pclass vs survived:","acba81d1":"#### Parch vs survived:","5392ebad":"## Random Forest","c814a475":"### Classes of some categorical variables","6235ef9c":"## Variable Transformation","3afc757c":"## Logistic Regression","3ba7902d":"### Age","95035afb":"### AgeGroup","2e0b0df5":"In general, barplot is used for categorical variables while histogram, density and boxplot are used for numerical data.","f251361e":"### Family Size","553a170d":"**Variables and Their Types:**\n\nSurvival: Survival -> 0 = No, 1 = Yes\n\nPclass: Ticket class -> 1 = 1st, 2 = 2nd, 3 = 3rd\n\nSex: Sex\n\nAge: Age in years\n\nSibSp: # of siblings \/ spouses aboard the Titanic\n\nParch: # of parents \/ children aboard the Titanic\n\nTicket: Ticket number\n\nFare: Passenger fare\n\nCabin: Cabin number\n\nEmbarked: Port of Embarkation -> C = Cherbourg, Q = Queenstown, S = Southampton","4fb39902":"## Outlier Treatment","4417c737":"## Missing Value Treatment","7f568d69":"#### SibSp vs survived:","8a429179":"### Embarked","8639f5f9":"# Deployment","dc9b6b6b":"# Data Preparation","581671a3":"### Visualization","4ea5ec03":"### Embarked & Title","6a9152fe":"## Loading Data","d90178f6":"### Fare"}}