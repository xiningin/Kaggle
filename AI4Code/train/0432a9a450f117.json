{"cell_type":{"c9a54071":"code","eb115c42":"code","215e35dd":"code","b46b0c1e":"code","e64e4e0c":"code","2ce0a5d1":"code","911db641":"code","d2f84857":"code","e156b798":"code","8f68b188":"code","e8b0cd47":"code","08cf4f26":"code","202cc973":"code","8c194d17":"code","562db61e":"code","2f5ec77d":"code","15b5b68c":"code","21bfad39":"code","8d2eb649":"code","e0f10df6":"code","4499fa16":"code","b582dfc8":"code","5a27209b":"code","0774c142":"code","da570099":"code","e7c2a539":"code","9d966dc6":"code","161f2109":"code","a666ebbd":"code","3fc985e2":"code","aa0772fd":"code","48defdc0":"code","72b1cdc9":"code","69387174":"code","2d305d00":"code","095fbb18":"code","05d09c26":"code","fe92b2da":"code","28dbe118":"code","9aa14896":"code","85371306":"code","5a80ec61":"code","68cdbc23":"code","a9964879":"code","055baeb9":"code","f6483e35":"markdown","ba77cf23":"markdown","4ff1db51":"markdown","ddeeabbb":"markdown","192eb252":"markdown","88ad0f5c":"markdown","c6f5af75":"markdown","88588c9f":"markdown","21c1bf32":"markdown","f73c17a4":"markdown","5bb10016":"markdown"},"source":{"c9a54071":"import os\nprint(os.listdir(\"..\/input\"))\n","eb115c42":"# Import all the required libraries\n\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport sqlite3\nimport pandas as pd\nimport numpy as np\nimport nltk\nimport string\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn import model_selection\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\n\nfrom collections import Counter\n\nfrom sklearn import metrics\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.metrics import classification_report\n\n# Tutorial about Python regular expressions: https:\/\/pymotw.com\/2\/re\/\nimport re\nimport string\nimport nltk.corpus\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\n\nfrom gensim.models import Word2Vec\nfrom gensim.models import KeyedVectors\nimport pickle\n\n\n\n","215e35dd":"# using the SQLite Table to read data. (KAGGLE)\nimport sqlite3\nshow_tables = \"select tbl_name from sqlite_master where type = 'table'\" \nconn = sqlite3.connect('..\/input\/database.sqlite') \npd.read_sql(show_tables,conn)","b46b0c1e":"#filtering only positive and negative reviews i.e. not taking into consideration those reviews with Score=3\nfiltered_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews WHERE Score != 3\"\"\", conn) ","e64e4e0c":"# Give reviews with Score>3 a positive rating, and reviews with a score<3 a negative rating.\ndef partition(x):\n    if x < 3:\n        return 'Negative'\n    return 'Positive'\n\n#changing reviews with score less than 3 to be positive and vice-versa\nactualScore = filtered_data['Score']\n\npositiveNegative = actualScore.map(partition) \n\nfiltered_data['Polarity'] = positiveNegative\n\nfiltered_data['Class_Label']= filtered_data['Polarity'].apply(lambda x : 1 if x == 'Positive' else 0)\n\n","2ce0a5d1":"filtered_data.head()","911db641":"# Data Cleaning: Deduplication, clearing records whereHelpfulnessNumerator is greater than HelpfulnessDenominator \nsorted_data=filtered_data.sort_values('ProductId', axis=0, ascending=True, inplace=False, kind='quicksort', na_position='last')\nfinal=sorted_data.drop_duplicates(subset={\"UserId\",\"ProfileName\",\"Time\",\"Text\"}, keep='first', inplace=False)\n\ndisplay= pd.read_sql_query(\"\"\"\nSELECT *\nFROM Reviews\nWHERE Score != 3 AND Id=44737 OR Id=64422\nORDER BY ProductID\n\"\"\", conn)\nfinal=final[final.HelpfulnessNumerator<=final.HelpfulnessDenominator]\n\n#How many positive and negative reviews are present in our dataset?\nfinal['Class_Label'].value_counts()","d2f84857":"## Text Preprocessing: Stemming, stop-word removal and Lemmatization.\n\n# find sentences containing HTML tags (DATASET FOR BRUTEFORCE)\nimport re\ni=0;\nfor sent in final['Text'].values:\n    if (len(re.findall('<.*?>', sent))):\n        print(i)\n        print(sent)\n        break;\n    i += 1;\n\n# find sentences containing HTML tags (DATASET FOR KD_TREE)\nimport re\ni=0;\nfor sent in final['Text'].values:\n    if (len(re.findall('<.*?>', sent))):\n        print(i)\n        print(sent)\n        break;\n    i += 1;\n\n# Remove Stop-Words\n\nstop = set(stopwords.words('english')) #set of stopwords\nsno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n\ndef cleanhtml(sentence): #function to clean the word of any html-tags\n    cleanr = re.compile('<.*?>')\n    cleantext = re.sub(cleanr, ' ', sentence)\n    return cleantext\ndef cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n    cleaned = re.sub(r'[.|,|)|(|\\|\/]',r' ',cleaned)\n    return  cleaned\nprint(stop)\nprint('************************************')\nprint(sno.stem('tasty'))\n","e156b798":"#  GET THE TRAINING AND TEST DATA-SET \n\n#pre-processing: agegate all positive and negative words\ni=0\nstr1=' '\nfinal_string=[]\nall_positive_words=[] # store words from +ve reviews here\nall_negative_words=[] # store words from -ve reviews here.\ns=''\nfor sent in final['Text'].values:\n    filtered_sentence=[]\n    #print(sent);\n    sent=cleanhtml(sent) # remove HTMl tags\n    for w in sent.split():\n        for cleaned_words in cleanpunc(w).split():\n            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n                if(cleaned_words.lower() not in stop):\n                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n                    filtered_sentence.append(s)\n                    if (final['Polarity'].values)[i] == 'Positive': \n                        all_positive_words.append(s) #list of all words used to describe positive reviews\n                    if(final['Polarity'].values)[i] == 'Negative':\n                        all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n                else:\n                    continue\n            else:\n                continue \n    #print(filtered_sentence)\n    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n    #print(\"***********************************************************************\")\n    \n    final_string.append(str1)\n    i+=1\n    \n#  cleaned-up columns\n\nfinal['CleanedText']=final_string #adding a column of CleanedText which displays the data after pre-processing of the review \nfinal['CleanedText']=final['CleanedText'].str.decode(\"utf-8\")\n\n# define column names\nnames = ['Time', 'Text','CleanedText', 'Polarity']\n\n\n# create design matrix X and target vector y\nX_NB =  final[names]\ny_NB = final['Class_Label']\n\nX_train_NB, X_test_NB, y_train_NB, y_test_NB = model_selection.train_test_split(X_NB, y_NB, test_size=0.2, random_state=0)\n","8f68b188":"# Get the BoW matrix\n\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\ncount_vect = CountVectorizer() \n\nbow_NB = count_vect.fit(X_train_NB['CleanedText'].values)\n\nbow_train_NB = bow_NB.transform(X_train_NB['CleanedText'].values)\n\nbow_test_NB = bow_NB.transform(X_test_NB['CleanedText'].values)\n","e8b0cd47":"# Colum Standardization of the Bag of Words vector\n\nfrom sklearn.preprocessing import StandardScaler\nscalar = StandardScaler(with_mean=False)\nscalar.fit(bow_train_NB)\nbow_train_NB_vectors = scalar.transform(bow_train_NB)\nbow_test_NB_vectors = scalar.transform(bow_test_NB)\n","08cf4f26":"# 10FOLD CV  to get the best Alpha (Hyper-Parameter)  for BOW model\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import TimeSeriesSplit, GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\n\n#parameters = {\"alpha\":  np.array([1e-1,1e-2,1e-3,1e-4,1e-5,1e-6,1e-7,1e-8,1e-9,0,1])}\n\nparameters = {\"alpha\":  np.array( [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10] )}\n\nn_folds = 10\n\ncv_timeSeries = TimeSeriesSplit(n_splits=n_folds)\n    \nmodel = MultinomialNB()\n\nmy_cv = TimeSeriesSplit(n_splits=n_folds).split(bow_train_NB_vectors)\n    \ngsearch_cv = GridSearchCV(estimator=model, param_grid=parameters, cv=my_cv,scoring='f1')\n\ngsearch_cv.fit(bow_train_NB_vectors, y_train_NB)\n","202cc973":"#Plot the Scores for each Alpha used in CRoss-Validation\n# source ref URL:  https:\/\/glowingpython.blogspot.com\/2014\/04\/parameters-selection-with-cross.html\n\nres = list(zip(*[(f1m,f1s.std(), p['alpha']) \n            for p, f1m, f1s in gsearch_cv.grid_scores_]))\n\nplt.plot(res[2],res[0],'-o', color=\"g\",)\nplt.xlabel('values of Alpha (Hyper-Parameter)')\nplt.ylabel('Average Score (Better Score implies Lesser Error)')\n\nplt.show()\n","8c194d17":"# Display the details for the  Hyper-parametrized BOW model\n\nNB_OPTIMAL_classifier_for_BOW = gsearch_cv.best_estimator_\nprint(\"Best estimator for {} model : \".format(\"BOW\"), NB_OPTIMAL_classifier_for_BOW)\n\nNB_OPTIMAL_score_for_BOW = gsearch_cv.best_score_\nprint(\"Best Score for {} model : \".format(\"BOW\"), NB_OPTIMAL_score_for_BOW)\n\nOPTIMAL_MODEL_for_BOW= gsearch_cv.best_params_\nfor alpha in OPTIMAL_MODEL_for_BOW:\n    print(\"Optimal Alpha for {} model : \".format(\"BOW\"),'{:f}'.format(OPTIMAL_MODEL_for_BOW[alpha]))\n\n\n","562db61e":"# Plotting the ROC Curve for the Best Classifier\n\n# Ref-Source-URL:  https:\/\/datamize.wordpress.com\/2015\/01\/24\/how-to-plot-a-roc-curve-in-scikit-learn\/\n\nfrom sklearn.metrics import roc_curve, auc\nY_score = NB_OPTIMAL_classifier_for_BOW.predict_proba(bow_test_NB_vectors)\nfpr, tpr, thresholds = roc_curve(y_test_NB,Y_score[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","2f5ec77d":"# Display Performance of the  Hyper-parametrized BOW model on TEST data\n\nnb_classifier = NB_OPTIMAL_classifier_for_BOW\n\ny_pred = nb_classifier.predict(bow_test_NB_vectors)\n    \n#Evaluate the model accuracy on TEST data\n\ntest_accuracy = accuracy_score(y_test_NB, y_pred, normalize=True) * 100\npoints = accuracy_score(y_test_NB, y_pred, normalize=False)\n\n# Display the classification report\nprint(classification_report(y_test_NB, y_pred,digits=4))\n\n#Display the model accuracy on TEST data\nprint('\\nThe number of accurate predictions out of {} data points on TEST data is {}'.format(bow_test_NB_vectors.shape[0], points))\nprint('Accuracy of the {} model on TEST data is {} %'.format(\"BOW\", '{:f}'.format(np.round(test_accuracy,2))))\n     \n# Display the confusion matrix\nimport scikitplot.metrics as sciplot\nsciplot.plot_confusion_matrix(y_test_NB, y_pred)\n    \n    \n","15b5b68c":"\n    # '''Get top 50 features displayed from both the negative and the positive review classes.'''\n    # Reference URL: https:\/\/stackoverflow.com\/questions\/50526898\/how-to-get-feature-importance-in-naive-bayes#50530697\n    \n    neg_class_prob_sorted = (-NB_OPTIMAL_classifier_for_BOW.feature_log_prob_[0, :]).argsort()               #Note : Putting a - sign indicates the indexes will be sorted in descending order.\n    pos_class_prob_sorted = (-NB_OPTIMAL_classifier_for_BOW.feature_log_prob_[1, :]).argsort()\n    \n    neg_class_features = np.take(bow_NB.get_feature_names(), neg_class_prob_sorted[:50])\n    pos_class_features = np.take(bow_NB.get_feature_names(), pos_class_prob_sorted[:50])\n    \n    print(\"The top 50 most frequent words from the positive class are :\\n\")\n    print(pos_class_features)\n    \n    print(\"\\nThe top 50 most frequent words from the negative class are :\\n\")\n    print(neg_class_features)\n    \n    del(neg_class_prob_sorted, pos_class_prob_sorted, neg_class_features, pos_class_features)\n\n","21bfad39":"# getting the base TFIDF vector\n\ntf_idf_vect_NB = TfidfVectorizer(ngram_range=(1,1))\n\ntfidf_NB = tf_idf_vect_NB.fit(X_train_NB['CleanedText'].values)\n\ntfidf_train_NB = tfidf_NB.transform(X_train_NB['CleanedText'].values)\n\ntfidf_test_NB  = tfidf_NB.transform(X_test_NB['CleanedText'].values)\n","8d2eb649":"#Colum Standardization of the TFIDF vector \n\nfrom sklearn.preprocessing import StandardScaler\nscalar = StandardScaler(with_mean=False)\nscalar.fit(tfidf_train_NB)\nTFIDF_train_NB_vectors = scalar.transform(tfidf_train_NB)\nTFIDF_test_NB_vectors = scalar.transform(tfidf_test_NB)\n","e0f10df6":"# 10-Fold Cross Validation to find the best Alpha for TFIDF model \n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.naive_bayes  import MultinomialNB\n\nparameters = {\"alpha\":  np.array( [0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10] )}\n\nn_folds = 10\n\ncv_timeSeries = TimeSeriesSplit(n_splits=n_folds)\n    \nmodel = MultinomialNB()\n\nmy_cv = TimeSeriesSplit(n_splits=n_folds).split(TFIDF_train_NB_vectors)\n    \ngsearch_cv_TFIDF = GridSearchCV(estimator=model, param_grid=parameters, cv=my_cv, scoring='f1')\n    \ngsearch_cv_TFIDF.fit(TFIDF_train_NB_vectors, y_train_NB)","4499fa16":"#Plot the Scores for each Alpha used in CRoss-Validation\n# source ref URL:  https:\/\/glowingpython.blogspot.com\/2014\/04\/parameters-selection-with-cross.html\n\nres_tfidf = list(zip(*[(f1m,f1s.std(), p['alpha']) \n            for p, f1m, f1s in gsearch_cv_TFIDF.grid_scores_]))\n\nplt.plot(res_tfidf[2],res_tfidf[0],'-o', color=\"g\",)\nplt.xlabel('values of Alpha (Hyper-Parameter)')\nplt.ylabel('Average Score (Better Score implies Lesser Error)')\n\nplt.show()\n","b582dfc8":"# Display  the details of the hyper-parametrized NB classifer (TFIDF)\n\nNB_OPTIMAL_classifier_for_TFIDF = gsearch_cv_TFIDF.best_estimator_\nprint(\"Best estimator for {} model : \".format(\"TFIDF\"), NB_OPTIMAL_classifier_for_TFIDF)\n\nNB_OPTIMAL_score_for_TFIDF = gsearch_cv_TFIDF.best_score_\nprint(\"Best Score for {} model : \".format(\"TFIDF\"), NB_OPTIMAL_score_for_TFIDF)\n\nOPTIMAL_MODEL_for_TFIDF= gsearch_cv_TFIDF.best_params_\nfor alpha in OPTIMAL_MODEL_for_TFIDF:\n    print(\"Optimal Alpha for {} model : \".format(\"TFIDF\"), '{:f}'.format(OPTIMAL_MODEL_for_TFIDF[alpha]))\n\n","5a27209b":"# Plotting the ROC Curve for the Best Hyper-parametrized classifier using TFIDF vector\n\n            # Ref-Source-URL:  https:\/\/datamize.wordpress.com\/2015\/01\/24\/how-to-plot-a-roc-curve-in-scikit-learn\/\n\nfrom sklearn.metrics import roc_curve, auc\nY_score = NB_OPTIMAL_classifier_for_TFIDF.predict_proba(bow_test_NB_vectors)\nfpr, tpr, thresholds = roc_curve(y_test_NB,Y_score[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","0774c142":"\n# Display  the performance of  TFIDF model on TEST data\n\n#Predict the labels for the test set\ny_pred_TFIDF = NB_OPTIMAL_classifier_for_TFIDF.predict(TFIDF_test_NB_vectors)\n    \n#Evaluate the accuracy of the model on TEST data\ntest_accuracy_TFIDF = accuracy_score(y_test_NB, y_pred_TFIDF, normalize=True) * 100\npoints_TFIDF = accuracy_score(y_test_NB, y_pred_TFIDF, normalize=False)\n\n#Display the classification_report\nprint(classification_report(y_test_NB, y_pred_TFIDF,digits=4))\n\n#Display the  accuracy of the model on TEST data\nprint('\\nThe number of accurate predictions out of {} data points on unseen data is {}'.format(TFIDF_test_NB_vectors.shape[0], points_TFIDF))\nprint('Accuracy of the {} model on unseen data is {} %'.format(\"TFIDF\", np.round(test_accuracy_TFIDF,2)))\n\n#Display the  confusion matrix\nimport scikitplot.metrics as sciplot\nsciplot.plot_confusion_matrix(y_test_NB, y_pred_TFIDF)\n","da570099":"\n # '''Get top 50 features displayed from both the negative and the positive review classes for the TF-IDF \n    # Reference URL: https:\/\/stackoverflow.com\/questions\/50526898\/how-to-get-feature-importance-in-naive-bayes#50530697\n    \n    neg_class_prob_sorted_TFIDF = (-NB_OPTIMAL_classifier_for_TFIDF.feature_log_prob_[0, :]).argsort()              \n    pos_class_prob_sorted_TFIDF = (-NB_OPTIMAL_classifier_for_TFIDF.feature_log_prob_[1, :]).argsort()\n    \n    neg_class_features_TFIDF = np.take(tfidf_NB.get_feature_names(), neg_class_prob_sorted_TFIDF[:50])\n    pos_class_features_TFIDF = np.take(tfidf_NB.get_feature_names(), pos_class_prob_sorted_TFIDF[:50])\n    \n    print(\"The top 50 most frequent words from the positive class are :\\n\")\n    print(pos_class_features_TFIDF)\n    \n    print(\"\\nThe top 50 most frequent words from the negative class are :\\n\")\n    print(neg_class_features_TFIDF)\n","e7c2a539":"# Clearing the memory space for faster processing\ndel(neg_class_prob_sorted_TFIDF, pos_class_prob_sorted_TFIDF, neg_class_features_TFIDF, pos_class_features_TFIDF)","9d966dc6":"# BI Grams matrix\n\nTFIDF_vect_BIGRAMS = TfidfVectorizer(ngram_range=(1,2) )  # here we are taking BIGRAMS only \n\nBIGRAMS_NB = TFIDF_vect_BIGRAMS.fit(X_train_NB['CleanedText'].values)\n\nBIGRAMS_train_NB = BIGRAMS_NB.transform(X_train_NB['CleanedText'].values)\n\nBIGRAMS_test_NB = BIGRAMS_NB.transform(X_test_NB['CleanedText'].values)\n","161f2109":"# Colum Standardization of the Bigrams vector\n\nfrom sklearn.preprocessing import StandardScaler\nscalar = StandardScaler(with_mean=False)\nscalar.fit(BIGRAMS_train_NB)\nBIGRAMS_train_NB_vectors = scalar.transform(BIGRAMS_train_NB)\nBIGRAMS_test_NB_vectors = scalar.transform(BIGRAMS_test_NB)","a666ebbd":"# 10 fold CV to get the Optimal Alpha for BIGRAMS model \n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.naive_bayes  import MultinomialNB\n\nparameters = {\"alpha\": np.array([0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10])}\n\nn_folds = 10\n\ncv_timeSeries = TimeSeriesSplit(n_splits=n_folds)\n    \nmodel = MultinomialNB()\n\nmy_cv = TimeSeriesSplit(n_splits=n_folds).split(BIGRAMS_train_NB_vectors)\n    \ngsearch_cv_BIGRAMS = GridSearchCV(estimator=model, param_grid=parameters, cv=my_cv, scoring='f1')\n    \ngsearch_cv_BIGRAMS.fit(BIGRAMS_train_NB_vectors, y_train_NB)\n\n    ","3fc985e2":"#Plot the Scores for the Alphas used in Cross-Validation  for the BIGRAMS vector\n            # source ref URL:  https:\/\/glowingpython.blogspot.com\/2014\/04\/parameters-selection-with-cross.html\n\nres_BIGRAMS = list(zip(*[(f1m,f1s.std(), p['alpha']) \n            for p, f1m, f1s in gsearch_cv_BIGRAMS.grid_scores_]))\n\nplt.plot(res_BIGRAMS[2],res_BIGRAMS[0],'-o', color=\"g\",)\nplt.xlabel('values of Alpha (Hyper-Parameter)')\nplt.ylabel('Average Score (Better Score implies Lesser Error)')\n\nplt.show()","aa0772fd":"# Display  the Hyper-parametrized BIGRAMS model details\n\nNB_OPTIMAL_classifier_for_BIGRAMS = gsearch_cv_BIGRAMS.best_estimator_\nprint(\"Best estimator for {} model : \".format(\"BIGRAMS\"), NB_OPTIMAL_classifier_for_BIGRAMS)\n\nNB_OPTIMAL_score_for_BIGRAMS = gsearch_cv_BIGRAMS.best_score_\nprint(\"Best Score for {} model : \".format(\"BIGRAMS\"), NB_OPTIMAL_score_for_BIGRAMS)\n\nOPTIMAL_MODEL_for_BIGRAMS= gsearch_cv_BIGRAMS.best_params_\nfor alpha in OPTIMAL_MODEL_for_BIGRAMS:\n    print(\"Optimal Alpha for {} model : \".format(\"BIGRAMS\"), '{:f}'.format(OPTIMAL_MODEL_for_BIGRAMS[alpha]))\n\n\n","48defdc0":"\n# Plotting the ROC Curve for the Hyper-parametrized BIGRAMS model\n\n# Ref-Source-URL:  https:\/\/datamize.wordpress.com\/2015\/01\/24\/how-to-plot-a-roc-curve-in-scikit-learn\/\n\nfrom sklearn.metrics import roc_curve, auc\nY_score = NB_OPTIMAL_classifier_for_BOW.predict_proba(bow_test_NB_vectors)\nfpr, tpr, thresholds = roc_curve(y_test_NB,Y_score[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n","72b1cdc9":"# Display  the performance of  BIGRAMS model on TEST data\n\n#Predict the labels of TEST data\n\ny_pred = NB_OPTIMAL_classifier_for_BIGRAMS.predict(BIGRAMS_test_NB_vectors)\n    \n#Get the accuracy of the model on TEST data\ntest_accuracy_BIGRAMS = accuracy_score(y_test_NB, y_pred, normalize=True) * 100\npoints_BIGRAMS = accuracy_score(y_test_NB, y_pred, normalize=False)\n\n# Display the classification_report\nprint(classification_report(y_test_NB, y_pred,digits=4))\n\n#Display the model accuracy of the model on TEST data\nprint('\\nThe number of accurate predictions out of {} data points on unseen data is {}'.format(BIGRAMS_test_NB_vectors.shape[0], points_BIGRAMS))\nprint('Accuracy of the {} model on unseen data is {} %'.format(\"BIGRAMS\", np.round(test_accuracy_BIGRAMS,2)))\n\n#Display the confusion matrix\nimport scikitplot.metrics as sciplot\nsciplot.plot_confusion_matrix(y_test_NB, y_pred)\n    \n    ","69387174":"\n    # '''Get top 50 features displayed from both the negative and the positive review classes for the BIGRAMS \n    # Reference URL: https:\/\/stackoverflow.com\/questions\/50526898\/how-to-get-feature-importance-in-naive-bayes#50530697\n    \n    neg_class_prob_sorted_BIGRAMS = (-NB_OPTIMAL_classifier_for_BIGRAMS.feature_log_prob_[0, :]).argsort()               #Note : Putting a - sign indicates the indexes will be sorted in descending order.\n    pos_class_prob_sorted_BIGRAMS = (-NB_OPTIMAL_classifier_for_BIGRAMS.feature_log_prob_[1, :]).argsort()\n    \n    neg_class_features_BIGRAMS = np.take(BIGRAMS_NB.get_feature_names(), neg_class_prob_sorted_BIGRAMS[:50])\n    pos_class_features_BIGRAMS = np.take(BIGRAMS_NB.get_feature_names(), pos_class_prob_sorted_BIGRAMS[:50])\n    \n    print(\"The top 50 most frequent words from the positive class are :\\n\")\n    print(pos_class_features_BIGRAMS)\n    \n    print(\"\\nThe top 50 most frequent words from the negative class are :\\n\")\n    print(neg_class_features_BIGRAMS)\n    \n    ","2d305d00":"# Clearing the memory space for faster processing\ndel(neg_class_prob_sorted_BIGRAMS, pos_class_prob_sorted_BIGRAMS, neg_class_features_BIGRAMS, pos_class_features_BIGRAMS)\n","095fbb18":"# TRI Grams matrix\n\nTFIDF_vect_TRIGRAMS = TfidfVectorizer(ngram_range=(2,3) )  # here we r taking only TRI-RAMS\n\nTFIDF_NB_TRIRAMS = TFIDF_vect_TRIGRAMS.fit(X_train_NB['CleanedText'].values)\n\nTRIGRAMS_train_NB = TFIDF_NB_TRIRAMS.transform(X_train_NB['CleanedText'].values)\n\nTRIGRAMS_test_NB = TFIDF_NB_TRIRAMS.transform(X_test_NB['CleanedText'].values)\n","05d09c26":"# #Colum Standardization of the TRigrams vector created using cleaned data\n\nfrom sklearn.preprocessing import StandardScaler\nscalar = StandardScaler(with_mean=False)\nscalar.fit(TRIGRAMS_train_NB)\nTRIGRAMS_train_NB_vectors = scalar.transform(TRIGRAMS_train_NB)\nTRIGRAMS_test_NB_vectors = scalar.transform(TRIGRAMS_test_NB)","fe92b2da":"# Running 10 fold CV to get the Hyper-Parameter Alpha for TRIGRAMS model\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom sklearn.naive_bayes  import MultinomialNB\n\nparameters = {\"alpha\": np.array([0.00001, 0.0001, 0.001, 0.01, 0.1, 1, 10])}\n\nn_folds = 10\n\ncv_timeSeries = TimeSeriesSplit(n_splits=n_folds)\n    \nmodel = MultinomialNB()\n\nmy_cv = TimeSeriesSplit(n_splits=n_folds).split(TRIGRAMS_train_NB_vectors)\n    \ngsearch_cv_TRIGRAMS = GridSearchCV(estimator=model, param_grid=parameters, cv=my_cv, scoring='f1')\n    \ngsearch_cv_TRIGRAMS.fit(TRIGRAMS_train_NB_vectors, y_train_NB)","28dbe118":"#Plot the Scores for each Alpha used in Cross-Validation\n                    # source ref URL:  https:\/\/glowingpython.blogspot.com\/2014\/04\/parameters-selection-with-cross.html\n\nres_TRIGRAMS = list(zip(*[(f1m,f1s.std(), p['alpha']) \n            for p, f1m, f1s in gsearch_cv_TRIGRAMS.grid_scores_]))\n\nplt.plot(res_TRIGRAMS[2],res_TRIGRAMS[0],'-o', color=\"g\",)\nplt.xlabel('values of Alpha (Hyper-Parameter)')\nplt.ylabel('Average Score (Better Score implies Lesser Error)')\n\nplt.show()","9aa14896":"# Display the details of the Hyper-parametrized (alpha) TRIGRAMS model\n\nNB_OPTIMAL_classifier_for_TRIGRAMS = gsearch_cv_TRIGRAMS.best_estimator_\nprint(\"Best estimator for {} model : \".format(\"TRIGRAMS\"), NB_OPTIMAL_classifier_for_TRIGRAMS)\n\nNB_OPTIMAL_score_for_TRIGRAMS = gsearch_cv_TRIGRAMS.best_score_\nprint(\"Best Score for {} model : \".format(\"TRIGRAMS\"), NB_OPTIMAL_score_for_TRIGRAMS)\n\nOPTIMALMODEL= gsearch_cv_TRIGRAMS.best_params_\nfor alpha in OPTIMALMODEL:\n    print(\"Optimal Alpha for {} model : \".format(\"TRIGRAMS\"), '{:f}'.format(OPTIMALMODEL[alpha]))\n\n","85371306":"\n# Plotting the ROC Curve for the Hyper-parametrized (alpha) TRIGRAMS model\n\n# Ref-Source-URL:  https:\/\/datamize.wordpress.com\/2015\/01\/24\/how-to-plot-a-roc-curve-in-scikit-learn\/\n\nfrom sklearn.metrics import roc_curve, auc\nY_score = NB_OPTIMAL_classifier_for_BOW.predict_proba(bow_test_NB_vectors)\nfpr, tpr, thresholds = roc_curve(y_test_NB,Y_score[:, 1])\nroc_auc = auc(fpr, tpr)\n\nplt.title('Receiver Operating Characteristic')\nplt.plot(fpr, tpr, 'b',label='AUC = %0.2f'% roc_auc)\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()\n\n\n","5a80ec61":"# Display  the performance of  TRIGRAMS model on TEST data\n\n#Predict the labels for the test set\n\ny_pred_TRIGRAMS = NB_OPTIMAL_classifier_for_TRIGRAMS.predict(TRIGRAMS_test_NB_vectors)\n    \n#Get the accuracy of the model on TEST data\ntest_accuracy_TRIGRAMS = accuracy_score(y_test_NB, y_pred_TRIGRAMS, normalize=True) * 100\npoints_TRIGRAMS = accuracy_score(y_test_NB, y_pred_TRIGRAMS, normalize=False)\n\n#Display the classification_report\nprint(classification_report(y_test_NB, y_pred_TRIGRAMS,digits=4))\n\n#Display the accuracy of the model on TEST data\nprint('\\nThe number of accurate predictions out of {} data points on unseen data is {}'.format(TRIGRAMS_test_NB_vectors.shape[0], points_TRIGRAMS))\nprint('Accuracy of the {} model on unseen data is {} %'.format(\"TRIGRAMS\", np.round(test_accuracy_TRIGRAMS,2)))\n\n#Display the confusion_matrix\nimport scikitplot.metrics as sciplot\nsciplot.plot_confusion_matrix(y_test_NB, y_pred_TRIGRAMS)","68cdbc23":"\n    # '''Get top 50 features displayed from both the negative and the positive review classes for the TRI-GRAMS \n    # Reference URL: https:\/\/stackoverflow.com\/questions\/50526898\/how-to-get-feature-importance-in-naive-bayes#50530697\n    \n    neg_class_prob_sorted_TRIGRAMS = (-NB_OPTIMAL_classifier_for_TRIGRAMS.feature_log_prob_[0, :]).argsort()               #Note : Putting a - sign indicates the indexes will be sorted in descending order.\n    pos_class_prob_sorted_TRIGRAMS = (-NB_OPTIMAL_classifier_for_TRIGRAMS.feature_log_prob_[1, :]).argsort()\n    \n    neg_class_features_TRIGRAMS = np.take(TFIDF_NB_TRIRAMS.get_feature_names(), neg_class_prob_sorted_TRIGRAMS[:50])\n    pos_class_features_TRIGRAMS = np.take(TFIDF_NB_TRIRAMS.get_feature_names(), pos_class_prob_sorted_TRIGRAMS[:50])\n    \n    print(\"The top 50 most frequent words from the positive class are :\\n\")\n    print(pos_class_features_TRIGRAMS)\n    \n    print(\"\\nThe top 50 most frequent words from the negative class are :\\n\")\n    print(neg_class_features_TRIGRAMS)","a9964879":"# Clearing the memory space for faster processing\ndel(neg_class_prob_sorted_TRIGRAMS, pos_class_prob_sorted_TRIGRAMS, neg_class_features_TRIGRAMS, pos_class_features_TRIGRAMS)\n","055baeb9":"# Summary of Results\n        #  Ref URL:  https:\/\/stackoverflow.com\/questions\/9535954\/printing-lists-as-tabular-data\n\ndef print_table(table):\n    longest_cols = [\n        (max([len(str(row[i])) for row in table]) + 3)\n        for i in range(len(table[0]))\n    ]\n    row_format = \"\".join([\"{:>\" + str(longest_col) + \"}\" for longest_col in longest_cols])\n    for row in table:\n        print(row_format.format(*row))\n\ntable = [\n    [\"Model\", \"OPTIMAL_ALPHA\", \"BEST_CV_SCORE\", \"TEST_ACCURACY\"],\n    [\"BOW-Model\", round(OPTIMAL_MODEL_for_BOW[alpha],5), NB_OPTIMAL_score_for_BOW, round(test_accuracy,2)],\n    [\"TFIDF-Model\", round(OPTIMAL_MODEL_for_TFIDF[alpha],5), NB_OPTIMAL_score_for_TFIDF, round(test_accuracy_TFIDF,2)],\n    [\"BIGRAMS-Model\", round(OPTIMAL_MODEL_for_BIGRAMS[alpha],5), NB_OPTIMAL_score_for_BIGRAMS,round(test_accuracy_BIGRAMS,2)],\n    [\"TRIGRAMS-Model\",round(OPTIMALMODEL[alpha],5), NB_OPTIMAL_score_for_TRIGRAMS,round(test_accuracy_TRIGRAMS,2)]]\n \nprint_table(table)","f6483e35":"# Step 2) Naive Bayes Classifier for BOW","ba77cf23":"# ASSIGNMENT- PART 2:  Naive-Bayes on TFIDF vector","4ff1db51":"# ASSIGNMENT- PART 1:  NB  CLASSIFIER  ON BOW  VECTOR","ddeeabbb":"#  Summarizing the Results obtained from the various models:\n","192eb252":" ##  Running the NB Classifier on BIGRAMS data","88ad0f5c":"# computing the  TRI-GRAMS matrix","c6f5af75":"1. # ASSIGNMENT- PART 4:  Naive-Bayes on TRI-GRAMS vector","88588c9f":"# computing the  BI-GRAMS matrix","21c1bf32":"# ASSIGNMENT- PART 3:  Naive-Bayes on BI-GRAMS vector","f73c17a4":" ##  Running the NB Classifier on TRIGRAMS data","5bb10016":"# STEP 1) Computing the Bag of Words (BoW)"}}