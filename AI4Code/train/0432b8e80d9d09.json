{"cell_type":{"20c74f8a":"code","7213bee4":"code","ad29e781":"code","6811aeac":"code","4ffa570e":"code","0a197d7c":"code","1a0f6bbe":"code","6002e992":"code","6ea56343":"code","288f690f":"code","e56f0c91":"code","03d7c914":"code","183ef6a8":"code","5f7a8037":"code","42603a7d":"code","f55039f4":"code","f27e04d6":"code","7543473d":"code","c08f3b56":"code","eb547c36":"code","e80780e2":"code","44f85e25":"code","14078ec8":"code","c8861975":"code","f8bd070c":"code","6649e362":"code","20a02fee":"code","3dcffb8a":"code","190828ad":"code","9d79b1cb":"code","d6dae9f5":"code","6e95375f":"code","7bf142b7":"code","81a0b9e5":"code","a4fa0853":"code","d6942f62":"code","56d5861f":"code","ce689f06":"code","f927ed5e":"code","d1aaa2a2":"code","c6db8862":"code","a5d2785f":"code","4b39ccad":"code","36d1db98":"code","1329ed05":"code","31411ee4":"code","b63e5094":"code","3a1058e6":"code","0729c0a5":"code","335067c2":"code","758a83a8":"markdown","5eb06672":"markdown","35f876d7":"markdown","e3ca395e":"markdown","e96ee71b":"markdown","5d520c7c":"markdown","73c6cdfe":"markdown","51625743":"markdown","c0d61b21":"markdown","2c7a2e17":"markdown","65c525f6":"markdown","7b03f157":"markdown","41a87d83":"markdown","10a01951":"markdown","5c5a5db9":"markdown","1a074378":"markdown","cc82520a":"markdown","a3ecaeaa":"markdown"},"source":{"20c74f8a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nprint(\"Session Started\")","7213bee4":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.set_option(\"display.max_rows\",None) #full dataset loading in notebook view\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport scipy.stats as stats\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import datasets, linear_model, metrics\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report,plot_confusion_matrix\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.datasets import make_classification","ad29e781":"df = pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')\ndf.head(10)","6811aeac":"df.info() #short info of the dataframe","4ffa570e":"df.shape","0a197d7c":"df.size","1a0f6bbe":"def dataset_description(df):\n    columns=df.columns.to_list()\n    print('No. of Columns in DataFrame: ',len(columns))\n    print('\\nColumn attribute Names: ',columns)\n    ncol=df.describe().columns.to_list()\n    ccol=[]\n    for i in columns:\n        if(ncol.count(i)==0):\n            ccol.append(i)\n        else:\n            continue\n    print('\\nNo. of Numerical Column in DataFrame: ',len(ncol))\n    print('\\nNumerical Column Names: ',ncol)\n    print('\\nNo. of Categorical Column in DataFrame: ',len(ccol))\n    print('\\nCategorical Column Names: ',ccol)\n    \ndataset_description(df)\n    ","6002e992":"df.isnull().sum() #checking the null values present in the DataFrame","6ea56343":"df.nunique() #unique values found in the DataFrame of each column","288f690f":"df.describe().T","e56f0c91":"df.corr()","03d7c914":"df.skew()","183ef6a8":"plt.figure(figsize=(18,18))\nplt.subplot(3,2,1)\nplt.style.use('seaborn')\nplt.tight_layout()\nsns.set_context('talk')\nsns.histplot(data=df, x='Age', hue=\"HeartDisease\",multiple=\"stack\",palette='magma')\nplt.title('Age vs HeartDisease')\n\nplt.subplot(3,2,2)\nplt.style.use('seaborn')\nplt.tight_layout()\nsns.set_context('talk')\nsns.histplot(data=df, x='RestingBP', hue=\"HeartDisease\",multiple=\"stack\",palette='magma')\nplt.title('RestingBP vs HeartDisease')\n\nplt.subplot(3,2,3)\nplt.style.use('seaborn')\nplt.tight_layout()\nsns.set_context('talk')\nsns.histplot(data=df, x='Cholesterol', hue=\"HeartDisease\",multiple=\"stack\",palette='magma')\nplt.title('Cholesterol vs HeartDisease')\n\nplt.subplot(3,2,4)\nplt.style.use('seaborn')\nplt.tight_layout()\nsns.set_context('talk')\nsns.histplot(data=df, x='FastingBS', hue=\"HeartDisease\",multiple=\"stack\",palette='magma')\nplt.title('FastingBS vs HeartDisease')\n\nplt.subplot(3,2,5)\nplt.style.use('seaborn')\nplt.tight_layout()\nsns.set_context('talk')\nsns.histplot(data=df, x='MaxHR', hue=\"HeartDisease\",multiple=\"stack\",palette='magma')\nplt.title('MaxHR vs HeartDisease')\n\nplt.subplot(3,2,6)\nplt.style.use('seaborn')\nplt.tight_layout()\nsns.set_context('talk')\nsns.histplot(data=df, x='Oldpeak', hue=\"HeartDisease\",multiple=\"stack\",palette='magma')\nplt.title('Oldpeak vs HeartDisease')\nplt.show()","5f7a8037":"#g = sns.FacetGrid(tips, col=\"time\")\n#g.map(sns.histplot, \"tip\")\nsns.set()\ndf.hist(figsize=(10,10))\nplt.show()","42603a7d":"sns.pairplot(df,hue='HeartDisease')","f55039f4":"df1= df.groupby('Sex').agg({'Age' : 'mean', \"ChestPainType\":'count','RestingBP':'mean','Cholesterol':'mean',\n                            'FastingBS':'sum','RestingECG':'count','MaxHR':'mean','ExerciseAngina':'count','Oldpeak':'mean',\n                            'ST_Slope':'count','HeartDisease':'sum'})\ndf1\n# average age is same for both male and female","f27e04d6":"import plotly.express as px\npx.bar(data_frame=df1, barmode='group', title = \"Gender wise Analyzing\",template=\"plotly_dark\")","7543473d":"def outliers_graph(df_column):\n    Q75, Q25 = np.percentile(df_column, [75 ,25]) \n    IQR = Q75 - Q25\n    print('Q25: ',Q25)\n    print('Q75: ',Q75)\n    print('Inter Quartile Range: ',IQR)\n    print('Outliers lie before', Q25-1.5*IQR, 'and beyond', Q75+1.5*IQR)\n    print('Number of Rows with Left Extreme Outliers:', len(df[df_column <Q25-1.5*IQR]))\n    print('Number of Rows with Right Extreme Outliers:', len(df[df_column>Q75+1.5*IQR]))","c08f3b56":"outliers_graph(df['Age'])","eb547c36":"outliers_graph(df['RestingBP'])","e80780e2":"df=df[df.RestingBP>=90]\nlen(df)","44f85e25":"outliers_graph(df['Cholesterol'])","14078ec8":"df=df[df.Cholesterol<=450]  #due more value in the right extreme outlier and '0' cholesterol level in dataset\nlen(df)","c8861975":"outliers_graph(df['FastingBS'])","f8bd070c":"outliers_graph(df['MaxHR'])","6649e362":"df=df[df.MaxHR>=70]\nlen(df)","20a02fee":"outliers_graph(df['Oldpeak'])","3dcffb8a":"print('Mean: ',df['Cholesterol'].mean())\nprint('Median: ',df['Cholesterol'].median())","190828ad":"mc=df[df['Cholesterol']>0].Cholesterol.mean() #mean value of Cholesterol without including the cholesterol=0\nprint('Mean of Cholesterol>0: ',mc)","9d79b1cb":"df.describe().T","d6dae9f5":"def OneHotEncoding(dfcolumn):\n  global df\n  dfcolumn.nunique()\n  len(df.columns)\n  finallencol = (dfcolumn.nunique() - 1) + (len(df.columns)-1)\n  dummies = pd.get_dummies(dfcolumn, drop_first=True, prefix=dfcolumn.name)\n  df=pd.concat([df,dummies],axis='columns')\n  df.drop(columns=dfcolumn.name,axis=1,inplace=True) \n  if(finallencol==len(df.columns)):\n    print('OneHotEncoding is sucessfull') \n    print('')\n  else:\n    print('Unsucessfull')\n  return df.head(5)\n","6e95375f":"OneHotEncoding(df['ChestPainType'])\nOneHotEncoding(df['Sex'])\nOneHotEncoding(df['RestingECG'])\nOneHotEncoding(df['ExerciseAngina'])\nOneHotEncoding(df['ST_Slope'])","7bf142b7":"df.describe().columns.to_list()","81a0b9e5":"#Zero value of cholesterol are filled usnig KNNImputer\nfrom sklearn.impute import KNNImputer\ndf['Cholesterol'].replace(to_replace = 0, value =np.nan, inplace=True)\nKNN_imputed = KNNImputer(n_neighbors=5)\nI=KNN_imputed.fit_transform(df)\nCholesterol=[]\nfor i in range(0,len(df)):\n  Cholesterol.append(I[i][2])\ndf['Cholesterol']=Cholesterol","a4fa0853":"\n \n# altering the DataFrame\ndf = df[['Age',\n 'RestingBP',\n 'Cholesterol',\n 'FastingBS',\n 'MaxHR',\n 'Oldpeak',\n 'ChestPainType_ATA',\n 'ChestPainType_NAP',\n 'ChestPainType_TA',\n 'Sex_M',\n 'RestingECG_Normal',\n 'RestingECG_ST',\n 'ExerciseAngina_Y',\n 'ST_Slope_Flat',\n 'ST_Slope_Up',\n 'HeartDisease',]]\n \n# printing the altered DataFrame\ndf.head(5)","d6942f62":"scaler = StandardScaler()\nscaler.fit(df.drop('HeartDisease',axis = 1))","56d5861f":"scaled_features = scaler.transform(df.drop('HeartDisease',axis = 1))\ndf_feat = pd.DataFrame(scaled_features,columns = df.columns[:-1])\ndf_feat.head()","ce689f06":"df.head(5)","f927ed5e":"col=df.describe().columns.to_list()\nprint(col)","d1aaa2a2":"X = df_feat\ny = df['HeartDisease']\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=20)","c6db8862":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\ncv = KFold(n_splits=10, random_state=100, shuffle=True)\nmodel = KNeighborsClassifier(n_neighbors=36)\nscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nprint('Accuracy of KNN: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\nmodel = SVC(kernel='rbf')\nscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nprint('Accuracy of SVC: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\nmodel=RandomForestClassifier(n_estimators =40,random_state=100)\nscores = cross_val_score(model, X, y, scoring='accuracy', cv=cv, n_jobs=-1)\nprint('Accuracy of RandomForest: %.3f (%.3f)' % (np.mean(scores), np.std(scores)))\n","a5d2785f":"from matplotlib import pyplot\nerror_rate= []\nfor i in range(1,40):\n    knn = KNeighborsClassifier(n_neighbors = i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))\n    print(i,np.mean(pred_i != y_test))","4b39ccad":"plt.figure(figsize = (10,6))\nplt.plot(range(1,40),error_rate,color = 'black',linestyle = '--',marker = 'o',markerfacecolor='red',markersize = 8)\nplt.title('Error Rate vs K')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","36d1db98":"model = KNeighborsClassifier(n_neighbors=36)\nmodel.fit(X_train, y_train)\ny_pred = model.predict(X_test)\nprint(classification_report(y_test, y_pred))\nprint('\\n')\nprint('------------------------')\nprint('Confusion Matrix')\nprint('------------------------')\nprint('')\nprint(confusion_matrix(y_test, y_pred))\nplot_confusion_matrix(model, X_test, y_test,cmap=\"binary\") \nplt.grid(False)\nplt.show()","1329ed05":"classifier = SVC(kernel='rbf', random_state=100)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\nprint(classification_report(y_test, y_pred))\nprint('\\n')\nprint('------------------------')\nprint('Confusion Matrix')\nprint('------------------------')\nprint('')\nprint(confusion_matrix(y_test, y_pred))\nplot_confusion_matrix(classifier, X_test, y_test,cmap=\"binary\") \nplt.grid(False)\nplt.show()","31411ee4":"from sklearn.model_selection import RandomizedSearchCV\n# Number of trees in random forest\nn_estimators = [int(x) for x in np.linspace(start = 103, stop = 300, num = 10)]\n# Number of features to consider at every split\nmax_features = ['auto', 'sqrt']\n# Maximum number of levels in tree\nmax_depth = [int(x) for x in np.linspace(10, 110, num = 11)]\nmax_depth.append(None)\n# Minimum number of samples required to split a node\nmin_samples_split = [2, 5, 10]\n# Minimum number of samples required at each leaf node\nmin_samples_leaf = [1, 2, 4]\n# Method of selecting samples for training each tree\nbootstrap = [True, False]\n# Create the random grid\nrandom_grid = {'n_estimators': n_estimators,\n               'max_features': max_features,\n               'max_depth': max_depth,\n               'min_samples_split': min_samples_split,\n               'min_samples_leaf': min_samples_leaf,\n               'bootstrap': bootstrap}","b63e5094":"rf = RandomForestClassifier()\nforest = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\nforest.fit(X_train,y_train)  ","3a1058e6":"forest.best_params_","0729c0a5":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=0)\nclf=RandomForestClassifier(n_estimators=124,min_samples_split= 2,\n                           min_samples_leaf= 1,max_features='sqrt',max_depth=None, bootstrap=False)\nclf.fit(X_train,y_train)\ny_pred=clf.predict(X_test)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nprint(classification_report(y_test, y_pred))\nprint('')\nprint('------------------------')\nprint('Confusion Matrix')\nprint('------------------------')\nprint('')\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\nprint(confusion_matrix(y_test, y_pred))\nplot_confusion_matrix(clf, X_test, y_test,cmap=\"binary\") \nplt.grid(False)\nplt.show()","335067c2":"from sklearn.ensemble import GradientBoostingClassifier\nclff = GradientBoostingClassifier(n_estimators=100, learning_rate=0.2, max_depth=1, random_state=23)\nclff.fit(X_train, y_train)\ny_pred=clff.predict(X_test)\nprint(classification_report(y_test, y_pred))\nprint('')\nprint('------------------------')\nprint('Confusion Matrix')\nprint('------------------------')\nprint('')\nprint(confusion_matrix(y_test, y_pred))\nplot_confusion_matrix(clff, X_test, y_test,cmap=\"binary\") \nplt.grid(False)\nplt.show()","758a83a8":"<h2>4.2 Imputation<\/h2>","5eb06672":"feature = pd.Series(forest.feature_importances_, index =).sort_values(ascending = False)\nprint(feature)","35f876d7":"<table>\n<thead><tr>\n<th>Attribute<\/th>\n<th>Description<\/th>\n<\/tr>\n<\/thead>\n<tbody>\n<tr>\n<td><strong>Age<\/strong><\/td>\n<td>Age of a patient [years]<\/td>\n<\/tr>\n<tr>\n<td><strong>Sex<\/strong><\/td>\n<td>Gender of the patient [M: Male, F: Female]<\/td>\n<\/tr>\n<tr>\n<td><strong>ChestPain<\/strong><\/td>\n<td>chest pain type [TA: Typical Angina, ATA: Atypical Angina, NAP: Non-Anginal Pain, ASY: Asymptomatic]<\/td>\n<\/tr>\n<tr>\n<td><strong>RestingBP<\/strong><\/td>\n<td>Blood pressure in Hg (Normal blood pressure - 120\/80 Hg)<\/td>\n<\/tr>\n<tr>\n<td><strong>Cholesterol<\/strong><\/td>\n<td>Serum cholestrol level in blood (Normal cholesterol level below for adults 200mg\/dL)<\/td>\n<\/tr>\n<tr>\n<td><strong>FastingBS<\/strong><\/td>\n<td>Fasting Blood Sugar (Normal less than 100mg\/dL for non diabetes for diabetes 100-125mg\/dL)<\/td>\n<\/tr>\n<tr>\n<td><strong>RestingECG<\/strong><\/td>\n<td>resting electrocardiogram results [Normal: Normal, ST: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of &gt; 0.05 mV), LVH: showing probable or definite left ventricular hypertrophy by Estes' criteria]<\/td>\n<\/tr>\n<tr>\n<td><strong>MaxHR<\/strong><\/td>\n<td>maximum heart rate achieved [Numeric value between 60 and 202]<\/td>\n<\/tr>\n<tr>\n<td><strong>ExerciseAngina<\/strong><\/td>\n<td>exercise-induced angina [Y: Yes, N: No]<\/td>\n<\/tr>\n<tr>\n<td><strong>Oldpeak<\/strong><\/td>\n<td>oldpeak = ST [Numeric value measured in depression]<\/td>\n<\/tr>\n<tr>\n<td><strong>ST_Slope<\/strong><\/td>\n<td>the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]<\/td>\n<\/tr>\n<tr>\n<td><strong>HeartDisease<\/strong><\/td>\n<td>output class [1: heart disease, 0: Normal]<\/td>\n<\/tr>\n<\/tbody>\n<\/table>","e3ca395e":"<h1>7.Model Selection<\/h1>","e96ee71b":"<h1>2. Dataset Description<\/h1>","5d520c7c":"<h2>Parameter selectikon for Random Forest Classifier<\/h2>","73c6cdfe":"<h1>4. Data Preprocessing<\/h1>","51625743":"<h2>K value estimation<\/h2>","c0d61b21":"<h1>KNN model<\/h1>","2c7a2e17":"<h2>10-Fold Cross validation and model comparision<\/h2>","65c525f6":"# Random Forest Classifier","7b03f157":"<h1>1. Import the Dataset<\/h1>","41a87d83":"<h3>5. Feature Scaling<\/h3>","10a01951":"<h1>3. Data Visualization<\/h1>","5c5a5db9":"<h1>6.Feature Selection<\/h1>","1a074378":"<h2>4.1 One Hot Encoding<\/h2>","cc82520a":"# Support Vector Classifier","a3ecaeaa":"# Gradient Boosting Classifier"}}