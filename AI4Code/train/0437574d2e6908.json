{"cell_type":{"a0fcb844":"code","95713bf6":"code","a76e88f5":"code","3629d135":"code","712d0d5f":"code","1a40c3b7":"code","fe4436f3":"code","01fa95b0":"code","928b5e99":"code","cc1cb136":"code","7d347440":"code","40711c96":"code","ae6b49ad":"code","c0fe9e42":"code","76b887b9":"code","42323529":"code","3a00c5a1":"code","ce1569e8":"code","c1294f2e":"code","425676a7":"code","610e127c":"code","e8988798":"code","cbf46800":"markdown","8ad09db1":"markdown","ba51f901":"markdown","b4eec63d":"markdown","910694c0":"markdown","6f0cdabc":"markdown","a3e21dc8":"markdown","f71d8be9":"markdown","35b06efc":"markdown","666e5a26":"markdown","4d019188":"markdown","58ef838e":"markdown","1ed78772":"markdown","e6a6dd4b":"markdown","62c87136":"markdown","89730f32":"markdown"},"source":{"a0fcb844":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib.ticker as ticker\nsns.set_style(\"whitegrid\")\n%matplotlib inline\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","95713bf6":"# Setting up the dataframe\ntrain = pd.read_csv('..\/input\/train.csv')\ntrain.info()\ntrain.head()","a76e88f5":"# Creaet violin and swarm plots\nsns.violinplot(x='Pclass',y='Fare',data=train,inner=None)\nsns.swarmplot(x='Pclass',y='Fare',data=train,color='w',alpha=0.5)\nplt.title(\"Violin and Swarm Plot to compare fare distribution among Pclass groups\")\n# Note: This takes a long time to run","3629d135":"# Create kde plot\nsns.kdeplot(train['Fare'][train['Pclass']==1],shade=True)\nsns.kdeplot(train['Fare'][train['Pclass']==2],shade=True)\nsns.kdeplot(train['Fare'][train['Pclass']==3],shade=True)\nplt.title(\"Distribution of fares across Pclass groups\")","712d0d5f":"# Create distribution plot again for pclass=1, because the scale is hard to read in previous one\nfig, (axis1,axis2) = plt.subplots(1,2,sharex=True,figsize=(12,4))\nfig.suptitle(\"PDF and CDF of fares among Pclass=1\")\nsns.distplot(train['Fare'][train['Pclass']==1],rug=True,ax=axis1)\naxis1.set_title(\"PDF\")\nsns.kdeplot(train['Fare'][train['Pclass']==1],shade=True,cumulative=True,ax=axis2)\naxis2.set_title(\"CDF\")\nx_forplot = train['Fare'][train['Pclass']==1]\naxis2 = plt.xticks(np.arange(min(x_forplot),max(x_forplot)+1,40.0))","1a40c3b7":"# Create distribution plot again for pclass=2 and 3, because the scale is hard to read in previous one\nsns.kdeplot(train['Fare'][train['Pclass']==2],shade=True)\nsns.kdeplot(train['Fare'][train['Pclass']==3],shade=True)\nplt.title(\"PDF of fares among Pclass= 2 and 3\")\n\n# Note: You need to add this line of code for the code above to work - %matplotlib inline","fe4436f3":"# Create the 2 new segmentation columns\ntrain['PaxclassA'] = train['Pclass']\ntrain.loc[(train['PaxclassA'] == 1) & (train['Fare']>100),'PaxclassA'] = 0\ntrain['PaxclassB'] = train['Pclass']\ntrain.loc[(train['Fare']>60),'PaxclassB'] = 0","01fa95b0":"# Group fare into bins to analyze survival rate across brackets. The brackets are informed by the dist plot above\nbins = [0,20,40,60,80,100,200,400,800]\ntrain['Fare_Groups'] = pd.cut(train['Fare'],bins)","928b5e99":"# Create plots to compare survival between the 2 new segmentation columns. We also show similar plot based on original Pclass and Fare buckets\nfig, ((axis1,axis2),(axis3,axis4)) = plt.subplots(2,2,sharey=True,figsize=(12,4))\nsns.factorplot(\"PaxclassA\",\"Survived\",data=train,ax=axis1)\nsns.factorplot(\"PaxclassB\",\"Survived\",data=train,ax=axis2)\nsns.factorplot(\"Pclass\",\"Survived\",data=train,ax=axis3)\nsns.factorplot(\"Fare_Groups\",\"Survived\",data=train,ax=axis4)\nfig.suptitle(\"Survival Rate across Segments, based on 2 new segments and 2 original vars\")\n\n# Note: I still don't know why these line of codes produce the blank charts on the bottom....","cc1cb136":"train['Fare_Groups2'] = train['Fare_Groups'].astype(\"object\") # Need this conversion for heatmap to work\nsns.heatmap(pd.crosstab(train['Pclass'],train['Fare_Groups2'],values=train['Survived'],aggfunc=np.mean).T,annot=True,cmap=\"Blues\")\nplt.title(\"Crosstab Heatmap of Pclass x Fares\")\n\n# Ideally, I should add 1 more heatmap to show the count. But let me put it in backburner, as the count is quite large for the regular pclass=1","7d347440":"# Analyzing cross-tab of age and sex on survival\nbins = [0,12,18,35,50,70,100]  # General age group breakdown\ntrain['Age_Groups'] = pd.cut(train['Age'],bins)\nsns.heatmap(pd.crosstab(train['Sex'],train['Age_Groups'],values=train['Survived'],aggfunc=np.mean).T,annot=True,cmap=\"Blues\")\nplt.title(\"Crosstab Heatmap of Sex x Age: Children (<12yo) seems prioritized, but elderly were not\")","40711c96":"# Create combined variable and show the survival rate\ntrain['SexAge'] = train['Sex']\ntrain.loc[(train['Age']<=12),'SexAge'] = 'children'\nsns.factorplot(\"SexAge\",\"Survived\",data=train)","ae6b49ad":"# Crosstab and heatmap on the impact of having parents \/ children\nprint(pd.crosstab(train['SexAge'],train['Parch']))\ncrosstab1 = pd.crosstab(train['SexAge'],train['Parch'],values=train['Survived'],aggfunc=np.mean)\nsns.heatmap(crosstab1.T,annot=True,cmap=\"Blues\")\nplt.title(\"Crosstab Heatmap of SexAge x Parch\")","c0fe9e42":"print(pd.crosstab(train['SexAge'],train['SibSp']))\ncrosstab1 = pd.crosstab(train['SexAge'],train['SibSp'],values=train['Survived'],aggfunc=np.mean)\nsns.heatmap(crosstab1.T,annot=True,cmap=\"Blues\")\nplt.title(\"Crosstab Heatmap of SexAge x SibSp\")","76b887b9":"# We need to convert categorical variables into binary variable\ntrain['Female'] = 0\ntrain.loc[(train['SexAge']==\"female\"),'Female'] = 1\ntrain['Children'] = 0\ntrain.loc[(train['SexAge']==\"children\"),'Children'] = 1\ntrain['Class1_Premium'] = 0\ntrain.loc[(train['PaxclassA']==0),'Class1_Premium'] = 1\ntrain['Class1'] = 0\ntrain.loc[(train['PaxclassA']==1),'Class1'] = 1\ntrain['Class2'] = 0\ntrain.loc[(train['PaxclassA']==2),'Class2'] = 1","42323529":"# Define the variables for training\nfrom sklearn import tree\nXtrain = train[['Female','Children','Parch','SibSp','Class1_Premium','Class1','Class2']]\nYtrain = train['Survived']","3a00c5a1":"# Set up and fit the decision tree model. Then export as graphviz\nTree1 = tree.DecisionTreeClassifier(max_depth=4,min_samples_split=50,random_state=1)\nTree1.fit(Xtrain,Ytrain)\nTree1_dot = tree.export_graphviz(Tree1,out_file=None,feature_names=Xtrain.columns,class_names=['Not Survived','Survived'],proportion=True,filled=True)\nprint(Tree1_dot)","ce1569e8":"# Check the score of prediction accuracy\nTree1.score(Xtrain,Ytrain)","c1294f2e":"test = pd.read_csv('..\/input\/test.csv')\n\n# Create new combined variables\ntest['SexAge'] = test['Sex']\ntest.loc[(test['Age']<=12),'SexAge'] = 'children'\ntest['PaxclassA'] = test['Pclass']\ntest.loc[(test['PaxclassA'] == 1) & (test['Fare']>100),'PaxclassA'] = 0\n\n# Create binary variables out of categorical variables\ntest['Female'] = 0\ntest.loc[(test['SexAge']==\"female\"),'Female'] = 1\ntest['Children'] = 0\ntest.loc[(test['SexAge']==\"children\"),'Children'] = 1\ntest['Class1_Premium'] = 0\ntest.loc[(test['PaxclassA']==0),'Class1_Premium'] = 1\ntest['Class1'] = 0\ntest.loc[(test['PaxclassA']==1),'Class1'] = 1\ntest['Class2'] = 0\ntest.loc[(test['PaxclassA']==2),'Class2'] = 1\n\n# Create the prediction\nXtest = test[['Female','Children','Parch','SibSp','Class1_Premium','Class1','Class2']]\nYtest_pred = Tree1.predict(Xtest)\n","425676a7":"submission = pd.DataFrame({\n    \"PassengerId\":test['PassengerId'],\n    \"Survived\":Ytest_pred\n})\nsubmission.to_csv('titanic.csv',index=False)","610e127c":"# Set up and fit the decision tree model. Then export as graphviz\nTree2 = tree.DecisionTreeClassifier(max_depth=6,min_samples_split=50,random_state=1,min_impurity_decrease=0.0003)\nTree2.fit(Xtrain,Ytrain)\nTree2_dot = tree.export_graphviz(Tree1,out_file=None,feature_names=Xtrain.columns,class_names=['Not Survived','Survived'],proportion=True,filled=True)\nprint(Tree2_dot)","e8988798":"# Create the prediction\nXtest = test[['Female','Children','Parch','SibSp','Class1_Premium','Class1','Class2']]\nYtest_pred = Tree2.predict(Xtest)\n\nsubmission = pd.DataFrame({\n    \"PassengerId\":test['PassengerId'],\n    \"Survived\":Ytest_pred\n})\nsubmission.to_csv('titanic2.csv',index=False)","cbf46800":"Lastly... we will now do all the same steps for the test data, and finally produce the submission file!","8ad09db1":"Key observations:\n* Age only matters if you are children, defined as < 12 yo\n* If you are a male, bringing a children won't help your survival\n* If you are a female, bringing a children don't impact your survival. Except if you have too many children (4+ kids)\n* For kids, seems that they are more likely to survive if they come with one parent rather than both parents. Some hypothesis of why this is likely:\n* - Perhaps if you had both parents, you are more likely to stick together (thus less likely to survive)\n* - If the child came with only mom, s\/he is more likely to survive\n* - If the child cdme with only dad, s\/he is less likely to survive\n* - Unfortunately I am not sure if we can identify if a child goes with mom or dad","ba51f901":"**1. Understanding  passengers' class and ticket fare.**\n\nQuick list of steps that I will do here:\n* Set up the dataframe\n* Show Violin + Swarm Plots on pclass and fare to understand relationship between the two\n* Show KDE distribution for more visualization lens\n* Create new segment var to combine pclass and fare\n* - Here I also tested 2 options to choose from\n* - Create bins of fare for easier EDA","b4eec63d":"So how do the two new segments compare?\n1. The first model takes premium only from pclass-1 with Fare >100. Here we could see the 4 groups with large gaps between each other. So this seems to work better\n2. The second model takes premium from any class that pays Fare >60. Here, it looks like the pclass=1 and pclass=2 seemed similar in survivability. \n\nBefore concluding to choose first segment model, let's do a heatmap in next analysis to better interpret  the result from 2nd mode. In the heatmap below, we could see that within pclass=1, we could see drop in survivability at fares less than 80","910694c0":"**2.  Understanding gender x age x family status.**","6f0cdabc":"For feature engineering, I would combine pclass and fare using the following options:\n* PaxclassA: Keep pclass 2 and 3 segment as-is. Split pclass 1 into premium and normal segment. Fare > 100 as threshold, based on 20-80 distribution.\n* PaxclassB: Carve out premium fares as one segment. Then keep existing pclass segment. Fare > 60 set as premium\n\n","a3e21dc8":"Key observations:\n* Similar to above, children with many siblings are unlikely to survive\n* For females, it doesn't really matter whether you are married or single :)\n* For adults (incl. teenagers), having many siblings make you less likely to survive. But the amount of these instances are few\n* For males, if you are married, you're a bit more likely to survive :). Nonetheless, I am still curious what is the profile of the men who survived.","f71d8be9":"**Preambule**\n\nThis notebook builds upon previous EDA analysis done by other kernels. Hence, I would like to focus on several variables that have largest impact: Sex, Age, Family Members, and Social Class. This note also attempts to look deeper on several variables that seemed closely correlated, so that we can merge those features.\n\nThis note will be organized in three sections:\n\n1. **Understanding  passengers' class and ticket fare.** Higher class passengers are usually  prioritized. But how does it relate with ticket fare? Can we simplify the variables to make a more concise prediction?\n\n2. ** Understanding gender x age x family status.** Children and women are usually prioritized. But is it always the case? Would certain type of men are more likely to survive? How are the dynamics with families?\n\n3. **Decision Tree modeling**. Finally we will create decision tree model with two purpose: (1) Describing the socio-economic dynamics based on decision tree modeling. While not the strongest prediction model, Decision Tree can give a strong explanatory power and can give insight of what is likely happening. (2) Making the prediction that will be submitted via Kaggle. I am curious how a simple model like this would fare in the prediction.\n\n[img](https:\/\/i.imgur.com\/Igoy3DG.jpg)\n","35b06efc":"Key observations from violin and swarm plots:\n* Pclass=1 fare distribution is very interesting. A significant number of passenger with \"premium\" tickets. But still a good number of passengers with same fare as pclass\n* Pclass=2 and Pclass=3 have a relatively similar distribution. But it might need a zoom\n* It seems that the premium fare passengers should be carved out as separate segment. But should we pick from pclass=1 only? \n\nSome more visualizations below to better understand the distribution of pclass vs. fares","666e5a26":"Quick list of steps that I will do here:\n* Convert categorical into binary variables\n* Run the training model and then export into graphviz\n* - The graphviz output needs to be visualized using external website. The result is posted here.\n* Run the prediction on test dataset\n* - Do all the pre-processing on test data\n* - Run the prediction and output into csv for submission","4d019188":"Public Score: 0.77990\nRank: 4335","58ef838e":"**3. Decision Tree Modeling**","1ed78772":"Quick list of steps that I will do here:\n* Show cross-tab heatmap to see interaction of Sex and Age Groups\n* - Children < 12 are special! But no other interaction\n* - Then we integrate sex and age variables\n* Show cross-tab on impact of having Siblings or Spouse\n* - This is useful to indicate single man \/ woman, which turned out to have higher survival rate\n* Show cross-tab on impact of having Children \/ Parents\n* - Large number of childrens make it less likely to survive","e6a6dd4b":"**Appendix 1: Alternative Decision Tree**","62c87136":"New Public Score: 0.77033\nNot much of an improvement. Clearly need to do 2 things: (1) Consider adding variables, (2) Implement random forest or ","89730f32":"Some key comments on decision I made on the Decision Tree parameters:\n* Overall, I want a parsimonious model that tries to explain a lot with few variables\n* Thus, I set a minimum sample of 50, and stop the branching right there\n* I set filled=True to show color gradient on the decision tree\n\nTo makes sense the decision tree model, you need to paste the output above into this website: http:\/\/www.webgraphviz.com\/\n\nBelow is the decision tree output. I added my own annotation to make it easier to read and interpret\n![](https:\/\/i.imgur.com\/Igoy3DG.jpg)\n\nSome most interesting observations:\n* The top differentiating variable is whether you are male, female, or children\n* If you are male, your best bet is to be a single man in 1st class. Survival rate is about 50-50. That's good considering average survival for male is 16%\n* If you are children with < 3 siblings, your chances are also strong at 86%. If you have 3+, survival rate is at 8%\n* If you are an adult woman, you are generally very fine. Unless if you are on 3rd class (pclass=3). But it's still 50-50, roughly the same as single man in 1st class\n\nDo note that some of the splitting is not really necessary, because the survival rate is already at ~90% and no significant changes in next branching. At some point I might be interested to add a 2nd decision tree model that sets a stopping point based on improvement of the gini ratio. It is set by adding min_impurity_decrease parameter."}}