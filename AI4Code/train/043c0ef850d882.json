{"cell_type":{"ad791f0e":"code","17e9dbc2":"code","3c9d4d11":"code","cde81295":"code","686bec2d":"code","ec3688ea":"code","c26de6e7":"code","fde11035":"code","668f9432":"code","4ec3ec64":"code","20e45a97":"code","11ee674a":"code","304f20bc":"code","e0bce139":"code","9f0fa308":"code","797ddf39":"code","97235245":"code","581baebf":"code","d39ceb63":"code","5b0e2f87":"code","535b3496":"code","8c058dac":"code","ce587686":"code","e99b167b":"code","1ce8b828":"code","1f356b09":"code","4924eda1":"code","2aca2cc4":"markdown","0d4ef31e":"markdown","8a9fd957":"markdown","6bd491aa":"markdown","f8e687a3":"markdown","3a79b6f1":"markdown","75021d65":"markdown","520eac11":"markdown","b662d686":"markdown","cf01ff6a":"markdown","3cec00cb":"markdown","37e9e430":"markdown","094a6b5e":"markdown","179e7997":"markdown"},"source":{"ad791f0e":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","17e9dbc2":"df=pd.read_csv('..\/input\/real-estate-price-prediction\/Real estate.csv')","3c9d4d11":"df.head()","cde81295":"df.corr()","686bec2d":"df.info()","ec3688ea":"plt.figure(figsize=(8,3))\nsns.displot(df['Y house price of unit area'], bins=30, kde=True)\n\nplt.xlabel('Y house price of unit area')","c26de6e7":"sns.kdeplot(df['X2 house age'])\nsns.kdeplot(df['Y house price of unit area'])\n\nplt.legend()","fde11035":"X=df.drop('Y house price of unit area' , axis=1)\ny=df['Y house price of unit area']","668f9432":"from sklearn.preprocessing import PolynomialFeatures","4ec3ec64":"polynomial_converter = PolynomialFeatures(degree=2, include_bias=False)","20e45a97":"poly_features = polynomial_converter.fit_transform(X)","11ee674a":"X.shape","304f20bc":"poly_features.shape","e0bce139":"from sklearn.model_selection import train_test_split","9f0fa308":" X_train, X_test, y_train, y_test = train_test_split( poly_features, y, test_size=0.3, random_state=101)","797ddf39":"from sklearn.linear_model import LinearRegression","97235245":"polymodel=LinearRegression()","581baebf":"polymodel.fit(X_train,y_train)","d39ceb63":"y_pred=polymodel.predict(X_test)","5b0e2f87":"pd.DataFrame({'Y_test':y_test,'Y_pred':y_pred, 'residual':(y_test-y_pred)})","535b3496":"from sklearn import metrics","8c058dac":"MAE=metrics.median_absolute_error(y_test,y_pred)\nMSE=metrics.mean_squared_error(y_test,y_pred)\nRMSE=np.sqrt(MSE)","ce587686":"pd.DataFrame([MAE,MSE,RMSE],index=['MAE','MSE','RMSE'],columns=['metrics'])","e99b167b":"#Train List of RMSE per degree\ntrain_RMSE_List=[]\n#test list of RMSE per degree\ntest_RMSE_list=[]\n\n\nfor degree in range(1,10):\n    #preprocessing\n    #create poly dataset for degree d\n    polynomial_convertor=PolynomialFeatures(degree=degree, include_bias=False)\n    poly_features=polynomial_convertor.fit_transform(X)\n    \n    #split the data set\n    X_train, X_test, y_train, y_test = train_test_split( poly_features, y, test_size=0.3, random_state=101)\n    \n    #train the model\n    polymodel=LinearRegression()\n    polymodel.fit(X_train,y_train)\n     \n    #prediction\n    y_train_pred=polymodel.predict(X_train)\n    y_test_pred=polymodel.predict(X_test)\n    \n    #evaluating\n    \n    #RMSE of train set\n    train_RMSE=np.sqrt(metrics.mean_squared_error(y_train,y_train_pred))\n    \n    #RMSE of test set\n    test_RMSE=np.sqrt(metrics.mean_squared_error(y_test,y_test_pred))\n    \n    #append the RMSE to the train and test list\n    train_RMSE_List.append(train_RMSE)\n    test_RMSE_list.append(test_RMSE)","1ce8b828":"train_RMSE_List","1f356b09":"test_RMSE_list","4924eda1":"plt.plot(range(1,5),train_RMSE_List[:4],label='Train RMSE')\nplt.plot(range(1,5),test_RMSE_list[:4],label='Test RMSE')\nplt.xlabel('polynomial degree')\nplt.ylabel('RMSE')\nplt.legend()","2aca2cc4":"for better underestanding we can have a dictionary as below","0d4ef31e":"**train the model**","8a9fd957":"**split data to train and test**","6bd491aa":"**adjusting model hyperparameters**","f8e687a3":"**determine the features and the labels:**","3a79b6f1":"* the question is, since when we can add order or how can we choose the optimal degree for the polynimial?\nBias-Variance Trade off hepls us to understand it better.(over fitting & under fitting)\n* a good model has lower error with growth of complexity(polynomial regression hyperparameter) on training and test set but we have to be carefull about overfitting.","75021d65":"**prediction:**","520eac11":"so as we see degree=2 is the best answer ","b662d686":"**data overview(it helps us to have a better understanding of data set)**","cf01ff6a":"**EDA** (plots to visualize dataset)","3cec00cb":"**Evaluating model performance**","37e9e430":"we saw how **PolynomialFeatures** expand the features","094a6b5e":"**why we use polynomial regression?**\n1. if there is a non-linear relationship between features and labels,\n2. interaction terms between faetures.\n\n> thus polynomial regression has a better performance than Linear Regression(Because it conciders higher order relationship between features).\n> **scikit learn** preprocessing library helps us to have higher order relationship between features(x1^2, X2^2,...) and intraction terms(x1x2, x1x2,...) by means of **PolynomialFeatures.**  ","179e7997":"**preprocessing**"}}