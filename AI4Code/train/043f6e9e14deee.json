{"cell_type":{"ab9f2b61":"code","f4115c44":"code","6cb4a4f1":"code","c6164814":"code","4bd3c4f8":"code","06cc9ba1":"code","d23ecb74":"code","f3473614":"code","8405a356":"code","38c61585":"code","81869930":"code","0e103582":"code","1567b781":"code","da65e240":"code","13e585e1":"code","7440068a":"code","345e890e":"code","1256b1f4":"code","76fcc61e":"code","b4d19420":"code","b7ff58f8":"code","631ba441":"code","14981387":"code","b27df9c4":"code","07f8f44a":"code","9140296f":"code","aae4eaf2":"code","7212fd82":"code","64ec325e":"code","84eeb38f":"code","bab9c2a8":"code","4879414d":"code","c0bb6275":"code","9ddcba97":"code","8271d938":"code","9e900746":"code","4e0e9e3f":"code","45bc3ff7":"code","aa8a3692":"code","a0bc9fd5":"code","e330c11f":"code","441cd2e0":"code","014678b5":"code","b3855751":"code","de04d2be":"code","40e6c492":"code","33e0e960":"code","70607659":"code","1f8b15e6":"code","fef04dbd":"code","e2fc2ddc":"code","a8208df9":"code","61af8c36":"code","45416387":"code","9eeafad2":"code","b3d39611":"code","194bf6d5":"code","c4fe34ae":"code","97b34a4d":"code","8f4e0796":"code","97f08fda":"code","0aa6233f":"code","da7bfe91":"code","23f5181a":"code","2baeea38":"code","45806223":"code","e4804294":"code","29c9b7a8":"code","0630027f":"code","aeb6e1b2":"code","3650f085":"code","5abd3b7f":"code","ecb5eef7":"code","78674217":"code","c53d0f4f":"markdown","1d9830ef":"markdown","28dcb5bf":"markdown","91aa38cf":"markdown","42605ddb":"markdown","eda42a0d":"markdown","648c39c2":"markdown","0d6b1c1d":"markdown","0619869a":"markdown","3d96bff2":"markdown","73b6547d":"markdown","1736a01a":"markdown","93241bff":"markdown","cfc48b3e":"markdown","fba7fb18":"markdown","a0d9e131":"markdown","9420ff4a":"markdown"},"source":{"ab9f2b61":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom statsmodels.tsa.statespace.sarimax import SARIMAX\nfrom statsmodels.tsa.api import ExponentialSmoothing, SimpleExpSmoothing, Holt\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nimport statsmodels.api as sm\nfrom statsmodels.graphics.tsaplots import plot_acf\nfrom statsmodels.graphics.tsaplots import plot_pacf\nfrom statsmodels.tsa.stattools import adfuller\nfrom matplotlib.pylab import rcParams\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.preprocessing import MinMaxScaler\n\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nimport keras.backend as K\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras.models import load_model","f4115c44":"april = pd.read_csv('..\/input\/uber-pickups-in-new-york-city\/uber-raw-data-apr14.csv')\nmay   = pd.read_csv('..\/input\/uber-pickups-in-new-york-city\/uber-raw-data-may14.csv')\njune  = pd.read_csv('..\/input\/uber-pickups-in-new-york-city\/uber-raw-data-jun14.csv')\njuly  = pd.read_csv('..\/input\/uber-pickups-in-new-york-city\/uber-raw-data-jul14.csv')\naug   = pd.read_csv('..\/input\/uber-pickups-in-new-york-city\/uber-raw-data-aug14.csv')\nsept  = pd.read_csv('..\/input\/uber-pickups-in-new-york-city\/uber-raw-data-sep14.csv')","6cb4a4f1":"april.shape","c6164814":"data =  april.append(may).append(june).append(july).append(aug).append(sept)","4bd3c4f8":"data","06cc9ba1":"\ndata.Timestamp = pd.to_datetime(data['Date\/Time'],format='%m\/%d\/%Y %H:%M:%S')","d23ecb74":"data['date_only'] = data.Timestamp.dt.date\ndata['date'] = data.Timestamp\ndata['month'] = data.Timestamp.dt.month\ndata['dow_num'] = data.Timestamp.dt.dayofweek\ndata['dow_name'] = data.Timestamp.dt.day_name()\ndata['month_day_num'] = data.Timestamp.dt.day\ndata['hours'] = data.Timestamp.dt.hour\n","f3473614":"data","8405a356":"data['Base'].value_counts()","38c61585":"data.groupby('hours')['hours'].count().sort_values(ascending=False)\n","81869930":"## peak days\n\ndata.groupby(pd.Grouper(key='dow_name')).count()\n\nuber_weekdays = data.pivot_table(index=['dow_num','dow_name'],values='Base', aggfunc='count')\nuber_weekdays.plot(kind='bar', figsize=(15,8))\nplt.ylabel('Total Trips')\nplt.xlabel('Day')\nplt.title('Trips by Week Day');\n","0e103582":"## peak hours \n\nuber_hour = data.pivot_table(index=['hours'], values='Base', aggfunc='count')\nuber_hour.plot(kind='bar', figsize=(8,6))\nplt.ylabel('Total Trips')\nplt.title('Trips by Hour');","1567b781":"data.groupby(pd.Grouper(key='Base')).count()\n\nuber_monthdays = data.pivot_table(index=['Base'], values='date' ,\n                                  aggfunc='count')\nuber_monthdays.plot(kind='bar', figsize=(8,6))\nplt.ylabel('Total Trips')\nplt.title('Trips by Month Day');","da65e240":"data.drop(['Lat','Lon'],axis=1,inplace=True)","13e585e1":"data","7440068a":"x = data.groupby('date_only').count()","345e890e":"x_tsf = x.copy()","1256b1f4":"x_tsf.drop(['Date\/Time','Base','month','dow_num','dow_name','month_day_num','hours'],axis=1,inplace=True)","76fcc61e":"x_tsf","b4d19420":"round(0.9*len(x_tsf))","b7ff58f8":"train_ts = x[:][:165]                     #split is 90-10\ntest_ts = x[:][166:]\n#test_ts_d = uber_dates_d[:][166:]","631ba441":"train_ts['date'].plot(kind='line',figsize=(15,8), title= 'Daily Trip', fontsize=12)\ntest_ts['date'].plot(figsize=(15,5), title= 'Daily Trip', fontsize=12)\nplt.ylabel('Total Trips')\nplt.xlabel('Month')\nplt.show()","14981387":"hat_avg = test_ts.copy()\nfit1 = ExponentialSmoothing(np.asarray(train_ts['date']) ,seasonal_periods=7 ,trend='add', seasonal='add',).fit()\nhat_avg['Holt_Winter'] = fit1.forecast(len(test_ts))","b27df9c4":"plt.figure(figsize=(15,5))\ntrain_ts['date'].plot(kind='line',figsize=(15,8),fontsize=12,label='train')\ntest_ts['date'].plot(figsize=(15,5),fontsize=12,label='test')\nplt.plot(hat_avg['Holt_Winter'], label='Holt_Winter')\nplt.legend(loc='best')\nplt.ylabel('Total Trips')\nplt.xlabel('Months')\nplt.show()","07f8f44a":"\nplt.style.use('default')\nplt.figure(figsize = (16,8))\nsm.tsa.seasonal_decompose(train_ts['date'].values,freq=30).plot()\nresult = sm.tsa.stattools.adfuller(x_tsf['date'])\nplt.show()","9140296f":"hat_avg_1 = test_ts.copy()\n\nfit1 = Holt(np.asarray(train_ts['date'])).fit(smoothing_level = 0.3,smoothing_slope = 0.1)\nhat_avg_1['Holt_linear'] = fit1.forecast(len(test_ts))","aae4eaf2":"plt.figure(figsize=(16,5))\ntrain_ts['date'].plot(kind='line',figsize=(15,8),fontsize=12,label='train')\ntest_ts['date'].plot(figsize=(15,5),fontsize=12,label='test')\nplt.plot(hat_avg_1['Holt_linear'], label='Holt_linear')\nplt.legend(loc='best')\nplt.show()\n","7212fd82":"rcParams['figure.figsize']=(20,10)\nrolmean = x_tsf['date'].rolling(24).mean()\nrolstd = x_tsf['date'].rolling(24).std()\n        \n#Plot rolling Statistics\nx_tsf['date'].plot(kind='line', color = \"blue\", label = \"Actual\")\nrolmean.plot(kind='line', color = \"brown\", label = \"Rolling Mean\")\n#.plot(kind='line', color = \"black\", label = \"Rolling Std\")\nplt.legend(loc = \"best\")\nplt.title(\"Rolling Mean and Standard Deviation\")\nplt.show(block = False)","64ec325e":"\nTrain_log = np.log(train_ts['date'])\nvalid_log = np.log(test_ts['date'])","84eeb38f":"moving_avg = Train_log.rolling(24).mean()\nTrain_log.plot(kind='line',figsize=(15,8),fontsize=12, color = 'green', label='Training_log')\nmoving_avg.plot(figsize=(15,5),fontsize=12, color = 'blue', label='Moving_avg')\n","bab9c2a8":"\ntrain_log_moving_diff = Train_log - moving_avg\ntrain_log_moving_diff.dropna(inplace = True)","4879414d":"\nrolmean = train_log_moving_diff.rolling(24).mean()\nrolstd = train_log_moving_diff.rolling(24).std()\n\n#Plot rolling Statistics\ntrain_log_moving_diff.plot(kind='line', color = \"blue\", label = \"Actual\")\nrolmean.plot(kind='line', color = \"brown\", label = \"Rolling Mean\")\nrolstd.plot(kind='line', color = \"black\", label = \"Rolling Std\")\nplt.legend(loc = \"best\")\nplt.title(\"Rolling Mean and Standard Deviation\")\nplt.show(block = False)","c0bb6275":"train_log_diff = Train_log - Train_log.shift(1)\n\n\nrolmean = train_log_diff.rolling(24).mean()\nrolstd = train_log_diff.rolling(24).std()\n\n#Plot rolling Statistics\ntrain_log_diff.plot(kind='line', color = \"blue\", label = \"Actual\")\nrolmean.plot(kind='line', color = \"brown\", label = \"Rolling Mean\")\nrolstd.plot(kind='line', color = \"black\", label = \"Rolling Std\")\nplt.legend(loc = \"best\")\nplt.title(\"Rolling Mean and Standard Deviation\")\nplt.show(block = False)","9ddcba97":"decomposition = seasonal_decompose(pd.DataFrame(Train_log)['date'].values, freq = 24)\nplt.style.use('default')\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid","8271d938":"plt.figure(figsize = (10,3))\nTrain_log.plot(kind='line', label = 'Original')\nplt.legend(loc = 'best')","9e900746":"plt.figure(figsize = (10,9))\nplt.subplot(411)\nplt.plot(trend, label = 'Trend')\nplt.legend(loc = 'best')\nplt.subplot(412)\nplt.plot(seasonal, label = 'Seasonal')\nplt.legend(loc = 'best')\nplt.subplot(413)\nplt.plot(residual, label = 'Residuals')\nplt.legend(loc = 'best')\nplt.tight_layout()","4e0e9e3f":"train_log_decompose = pd.DataFrame(residual)\ntrain_log_decompose['date'] = Train_log.index\ntrain_log_decompose.set_index('date', inplace = True)\ntrain_log_decompose.dropna(inplace = True)","45bc3ff7":"rolmean = train_log_decompose[0].rolling(24).mean()\nrolstd = train_log_decompose[0].rolling(24).std()\n\n#Plot rolling Statistics\ntrain_log_decompose[0].plot(kind='line', color = \"blue\", label = \"Actual\")\nrolmean.plot(kind='line', color = \"brown\", label = \"Rolling Mean\")\nrolstd.plot(kind='line', color = \"black\", label = \"Rolling Std\")\nplt.legend(loc = \"best\")\nplt.title(\"Rolling Mean and Standard Deviation\")\nplt.show(block = False)\n","aa8a3692":"from statsmodels.tsa.stattools import acf, pacf\n\nlag_acf = acf(train_log_diff.dropna(), nlags = 25)\nlag_pacf = pacf(train_log_diff.dropna(), nlags = 25, method= \"ols\")","a0bc9fd5":"# ACF\nplt.figure(figsize = (15,5))\nplt.style.use(\"fivethirtyeight\")\nplt.plot(lag_acf)\nplt.axhline( y = 0, linestyle = \"--\", color = \"gray\")\nplt.axhline( y= -1.96\/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\nplt.axhline(y = 1.96 \/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\nplt.title(\"Autocorrelation Function\")\nplt.show()","e330c11f":"# PACF\nplt.figure(figsize = (15,5))\nplt.plot(lag_pacf)\nplt.axhline(y = 0, linestyle = \"--\", color = \"gray\")\nplt.axhline(y = -1.96\/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\nplt.axhline( y = 1.96\/np.sqrt(len(train_log_diff.dropna())), linestyle = \"--\", color = \"gray\")\nplt.title(\"Partial Autocorrelation Function\")\nplt.show()\n","441cd2e0":"\nplt.figure(figsize = (15,6))\nmodel = ARIMA(Train_log, order = (2,1,0))  #here q value is zero since it is just AR Model\nresults_AR = model.fit(disp=-1)\ntrain_log_diff.dropna().plot(kind='line', label = \"Actual\")\nresults_AR.fittedvalues.plot(kind='line', color = 'red', label = 'Predictions')\nplt.legend(loc = 'upper right')","014678b5":"\nplt.figure(figsize = (16,8))\nmodel = ARIMA(Train_log, order = (2,1,1))\nresults_ARIMA = model.fit(disp=-1)\ntrain_log_diff.dropna().plot(kind='line',  label='Original')\nresults_ARIMA.fittedvalues.plot(kind='line', color='red', label='Predicted')\nplt.legend(loc='best')\nplt.show()","b3855751":"\ndef check_prediction_diff(predict_diff, given_set):\n    predict_diff= predict_diff.cumsum().shift().fillna(0)\n    predict_base = pd.Series(np.ones(given_set.shape[0]) * np.log(given_set['date'])[0], index = given_set.index)\n    #predict_log = predict_base.add(predict_diff,fill_value=0)\n    predict = np.exp(predict_base)\n    \n    plt.plot(given_set['date'], label = \"Given set\")\n    plt.plot(predict, color = 'red', label = \"Predict\")\n    plt.legend(loc= 'best')\n    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['date']))\/given_set.shape[0]))\n    plt.show()","de04d2be":"def check_prediction_log(predict_log, given_set):\n    predict = np.exp(predict_log)\n    \n    plt.plot(given_set['date'], label = \"Given set\")\n    plt.plot(predict, color = 'red', label = \"Predict\")\n    plt.legend(loc= 'best')\n    plt.title('RMSE: %.4f'% (np.sqrt(np.dot(predict, given_set['date']))\/given_set.shape[0]))\n    plt.show()","40e6c492":"ARIMA_predict_diff=results_ARIMA.predict(len(train_ts))\nplt.figure(figsize = (16,8))\ncheck_prediction_diff(ARIMA_predict_diff, test_ts)","33e0e960":"hat_avg = test_ts.copy()\nfit2 = SimpleExpSmoothing(np.asarray(train_ts['date'])).fit(smoothing_level = 0.7,optimized = False)\nhat_avg['SES'] = fit2.forecast(len(test_ts))\nplt.figure(figsize =(15,8))\ntrain_ts['date'].plot(kind='line',figsize=(15,8), label = 'Train')\ntest_ts['date'].plot(kind='line', label = 'Validation')\nplt.plot(hat_avg['SES'], label = 'Simple Exponential Smoothing',color='green')\nplt.legend(loc = 'best')","70607659":"hat=hat_avg['SES'].values.tolist()\nrmse = np.sqrt(mean_squared_error(test_ts['date'],hat))\nrmse","1f8b15e6":"\nhat_avg = test_ts.copy()\nhat_avg['moving_average_forecast'] = train_ts['date'].rolling(10).mean().iloc[-1]\nplt.figure(figsize = (15,5))\ntrain_ts['date'].plot(kind='line',figsize=(15,8), label = 'Train')\ntest_ts['date'].plot(kind='line', label = 'Validation')\nplt.plot(hat_avg['moving_average_forecast'], label = 'Moving Average Forecast with 10 Observations')\nplt.legend(loc = 'best')\nplt.show()","fef04dbd":"hat_avg = test_ts.copy()\nhat_avg['moving_average_forecast'] = train_ts['date'].rolling(20).mean().iloc[-1]\nplt.figure(figsize = (15,5))\ntrain_ts['date'].plot(kind='line',figsize=(15,8), label = 'Train')\ntest_ts['date'].plot(kind='line', label = 'Validation')\nplt.plot(hat_avg['moving_average_forecast'], label = 'Moving Average Forecast with 10 Observations')\nplt.legend(loc = 'best')\nplt.show()","e2fc2ddc":"\nrmse = np.sqrt(mean_squared_error(test_ts['date'], hat_avg['moving_average_forecast']))\nrmse\n","a8208df9":"hat = test_ts.copy()\nfit2 = SimpleExpSmoothing(np.asarray(train_ts['date'])).fit(smoothing_level = 0.8,optimized = False)\nhat['SES'] = fit2.forecast(len(test_ts))\nplt.figure(figsize =(15,8))\ntrain_ts['date'].plot(kind='line',figsize=(15,8), label = 'Train')\ntest_ts['date'].plot(kind='line', label = 'Validation')\nplt.plot(hat['SES'], label = 'Simple Exponential Smoothing')\nplt.legend(loc = 'best')","61af8c36":"def day_series_creator(dataframe):\n    \n    # Grouping by Date\/Time to calculate number of trips\n    day_df = pd.Series(dataframe.groupby(['date']).size())\n    # setting Date\/Time as index\n    day_df.index = pd.DatetimeIndex(day_df.index)\n    # Resampling to daily trips\n    day_df = day_df.resample('1D').apply(np.sum)\n    \n    return day_df","45416387":"day_df_2014 = day_series_creator(data)\nday_df_2014.head()\n","9eeafad2":"def initial_plots(time_series, num_lag):\n\n    #Original timeseries plot\n    plt.figure(1)\n    plt.plot(time_series)\n    plt.title('Original Uber data across time')\n    plt.figure(2)\n    plot_acf(time_series, lags = num_lag)\n    plt.title('Autocorrelation plot')\n    plot_pacf(time_series, lags = num_lag)\n    plt.title('Partial autocorrelation plot')\n    \n    plt.show()\n\n    \n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(day_df_2014)[1]))","b3d39611":"\n#plotting\ninitial_plots(day_df_2014, 45)","194bf6d5":"#plotting 30 observation\ninitial_plots(day_df_2014, 30)","c4fe34ae":"diff_series = day_df_2014.diff(periods=1)\n\n#Augmented Dickey-Fuller test for stationarity\n#checking p-value\nprint('p-value: {}'.format(adfuller(diff_series.dropna())[1]))","97b34a4d":"round(adfuller(diff_series.dropna())[1],2)","8f4e0796":"\ninitial_plots(diff_series.dropna(), 30)","97f08fda":"uber_count=data.groupby(pd.Grouper(key='date')).count()\nprint(uber_count.info())","0aa6233f":"uber_count.drop(['Base','date_only','month','dow_num','dow_name','month_day_num','hours'],axis=1,inplace=True)","da7bfe91":"uber_count","23f5181a":"train = uber_count[:][:234084]             #90% of 260093\ntest = uber_count[:][234085:]","2baeea38":"train['Date\/Time'].plot(kind='area',figsize=(15,8), title= 'Hourly Trips', fontsize=14)\ntest['Date\/Time'].plot(figsize=(15,5), title= 'Hourly Trips', fontsize=12)\nplt.ylabel('Total Trips')\nplt.xlabel('Month')\nplt.show()","45806223":"\ndef test_stationary(timeseries):\n    \n    rolmean = timeseries.rolling(24).mean()\n    rolstd = timeseries.rolling(24).std()\n    \n    \n    #Plot rolling Statistics\n    act = plt.plot(timeseries, color = \"blue\", label = \"Actual\")\n    mean = plt.plot(rolmean, color = \"brown\", label = \"Rolling Mean\")\n    std = plt.plot(rolstd, color = \"black\", label = \"Rolling Std\")\n    plt.legend(loc = \"best\")\n    plt.title(\"Rolling Mean and Standard Deviation\")\n    plt.show(block = False)","e4804294":"rcParams['figure.figsize']=(20,10)\ntest_stationary(uber_count['Date\/Time'])","29c9b7a8":"sc = MinMaxScaler()\ntrain_sc = sc.fit_transform(train)\ntest_sc = sc.transform(test)\n\nX_train = train_sc[:-1]\ny_train = train_sc[1:]\n\nX_test = test_sc[:-1]\ny_test = test_sc[1:]","0630027f":"\nK.clear_session()","aeb6e1b2":"model = Sequential()\nmodel.add(Dense(9, input_dim=1, activation='relu'))\nmodel.add(Dense(1))\nmodel.compile(loss='mean_squared_error', optimizer='adam')\nearly_stop = EarlyStopping(monitor='loss', patience=5, verbose=1)\nhistory = model.fit(X_train, y_train, epochs=20, batch_size=1, verbose=1, callbacks=[early_stop], shuffle=False)","3650f085":"y_pred_test_ann = model.predict(X_test)\ny_train_pred_ann = model.predict(X_train)\nrmse = np.sqrt(mean_squared_error(y_train,y_train_pred_ann))\nprint(\"Train : {:0.3f}\".format(rmse))\n\nrmse = np.sqrt(mean_squared_error(y_test,y_pred_test_ann))\nprint(\"Test : {:0.3f}\".format(rmse))\n","5abd3b7f":"y_pred_test_ANN = model.predict(X_test)\nplt.plot(y_test, label='True')\nplt.plot(y_pred_test_ANN, label='ANN')\nplt.title(\"ANN's_Prediction\")\nplt.xlabel('Observation')\nplt.ylabel('INR_Scaled')\nplt.legend()\nplt.show()","ecb5eef7":"from sklearn import metrics\nacc=metrics.r2_score(y_test,y_pred_test_ann)\nprint(\"Accuracy Score of Model: \",round(acc*100,2),'%')","78674217":"\nscore_ann= model.evaluate(X_test, y_test, batch_size=1)\nprint('ANN: %f'%score_ann)","c53d0f4f":"## SARIMAX","1d9830ef":"better than AR model","28dcb5bf":"## Splitting data","91aa38cf":"RMSE more, should go for any other model ","42605ddb":" ### to scale into original scale","eda42a0d":"## Holt's winter seasonal method","648c39c2":"we can observe that more people take ride in the evening around 5pm","0d6b1c1d":"## MA forecast with 10 observations","0619869a":"we can see ,there are more trips on thursdays and fridays","3d96bff2":"error is till high.. let's see other model","73b6547d":"# ANN ","1736a01a":"all the columns have same value , because we jut counted number of trips for day . so the quantities are same for all <br\/>\nLet's delete all the columns keeping one","93241bff":"you can download the dataset here  : [dataset](https:\/\/drive.google.com\/file\/d\/1emopjfEkTt59jJoBH9L9bSdmlDC4AR87\/view?usp=sharing)","cfc48b3e":"## Exponential smoothening","fba7fb18":"## MA forecast with 20 observations","a0d9e131":"## AR Model","9420ff4a":"##  ARIMA"}}