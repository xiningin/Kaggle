{"cell_type":{"9deae619":"code","bbf86199":"code","eb618af2":"code","ce7cbc4e":"code","46a0a0dc":"code","7392f4fc":"code","cd2f9a5f":"code","b8352174":"code","d7efcf4a":"code","0056f3ce":"code","e6c60f4a":"code","657c9ea3":"code","b0b1aba4":"code","8d2d84d1":"code","52c33204":"code","e498b7f3":"code","7a0ab8d1":"code","68c42760":"code","f0ce9f3e":"code","2a2618a4":"code","c2ad72c6":"code","4055c057":"code","448cfcea":"code","a5e79a8a":"code","5a1c0126":"code","01275448":"code","44e6dc55":"code","8a8a5028":"code","3dbbe890":"code","675de139":"code","2e0baa2f":"code","fea68601":"code","119117c4":"code","459319b9":"code","ddfc65ce":"code","6c844616":"code","c66dcd7d":"code","c562b355":"code","1a6f8b13":"code","b414a958":"code","daaee1fc":"code","47618a2d":"code","b7b82598":"code","5bb25b25":"code","675b93b2":"code","1f6be453":"code","5ea4296e":"code","44138cd5":"code","331e0e05":"code","c9008184":"code","50734535":"code","af9e1609":"code","0a30bb6d":"code","cd039bd2":"code","c376bb68":"code","76fd76c2":"code","af2cc802":"code","4871968e":"code","1443fcd5":"code","d3af489d":"code","dea3792d":"code","40398581":"code","bc2186f8":"code","b9ed10f3":"code","5e65198e":"code","457fb7ed":"code","69c3686d":"code","cd15b108":"code","d0270483":"code","4c9459bd":"code","ecf87a81":"code","91128fd8":"code","73ff855d":"code","d039e703":"code","f722efb3":"code","eeea7c3b":"code","bf422474":"code","68e5da6c":"code","8cd65baa":"code","cc544e95":"code","16bb0092":"code","87d23b39":"code","4b78f907":"code","881ca040":"code","09280c66":"code","ac255f11":"code","61732a3d":"code","005e09fa":"code","7496131e":"code","cd6462c5":"code","8174a622":"code","efa2fee2":"code","0d7f8600":"code","8cb10b80":"code","d3c2a738":"code","acc75148":"code","3f3c896b":"code","fce4503b":"code","9d5c107e":"code","e2718c8d":"code","3cd8e5ad":"code","22a5dcc5":"code","052f47b4":"markdown","668fb994":"markdown","ccc02e45":"markdown","69b55dc8":"markdown","c5a48c61":"markdown","25d18c5f":"markdown","e730c0ff":"markdown","576d1419":"markdown","1bf342f3":"markdown","ad06f9d9":"markdown","ebf3ccc2":"markdown","5c2c37e5":"markdown","c29f29de":"markdown","aa9e35c2":"markdown","bad52d07":"markdown","33be26da":"markdown","84526e72":"markdown","115153a9":"markdown","21b28aff":"markdown","8681290e":"markdown","6a1800ad":"markdown","7b39b707":"markdown","d6937fbd":"markdown"},"source":{"9deae619":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport gc\nfrom PIL import Image\n\nimport dask.dataframe as dd\nfrom tqdm.auto import tqdm\nimport cv2\n","bbf86199":"print(os.listdir(\"..\/input\/bengaliai-cv19\/\"))","eb618af2":"df_train_labels = pd.read_csv(\"..\/input\/bengaliai-cv19\/train.csv\")\ndf_train_labels.head()","ce7cbc4e":"len(df_train_labels.grapheme_root.unique())","46a0a0dc":"len(df_train_labels.consonant_diacritic.unique())","7392f4fc":"len(df_train_labels.vowel_diacritic.unique())","cd2f9a5f":"df_train_labels.shape","b8352174":"df_train_labels = df_train_labels.drop(['grapheme'], axis=1)","d7efcf4a":"df_train_labels.head()","0056f3ce":"#df_train_labels.image_id.stack()\ndf_tmp = pd.melt(df_train_labels, id_vars=['image_id'], value_vars=['grapheme_root',\t'vowel_diacritic',\t'consonant_diacritic'])","e6c60f4a":"df_tmp.head()","657c9ea3":"df_tmp[df_tmp['image_id']=='Train_0']","b0b1aba4":"df_tmp['row_id'] = df_tmp['image_id']+'_'+df_tmp['variable']","8d2d84d1":"df_tmp.head()","52c33204":"df_tmp= df_tmp.rename(columns={\"variable\": \"component\"}, errors=\"raise\")","e498b7f3":"df_test_labels = pd.read_csv(\"..\/input\/bengaliai-cv19\/test.csv\")\ndf_test_labels.head()","7a0ab8d1":"df_consonant = df_tmp[df_tmp['component'] =='consonant_diacritic']\ndf_grapheme = df_tmp[df_tmp['component'] =='grapheme_root']\ndf_vowel = df_tmp[df_tmp['component'] =='vowel_diacritic']","68c42760":"print(df_consonant.shape)\nprint(df_grapheme.shape)\nprint(df_vowel.shape)","f0ce9f3e":"df_consonant.head()","2a2618a4":"sns.catplot(x=\"vowel_diacritic\", data=df_train_labels, kind=\"count\")","c2ad72c6":"sns.catplot(x=\"consonant_diacritic\", data=df_train_labels, kind=\"count\")","4055c057":"sns.catplot(x=\"grapheme_root\", data=df_train_labels, kind=\"count\")","448cfcea":"HEIGHT = 137\nWIDTH = 236\n\ndef load_as_npa(file):\n    df = pd.read_parquet(file)\n    return df.iloc[:, 1:].values.reshape(-1, HEIGHT, WIDTH)","a5e79a8a":"#images0 = load_as_npa('\/kaggle\/input\/bengaliai-cv19\/train_image_data_0.parquet')\n#images1 = load_as_npa('\/kaggle\/input\/bengaliai-cv19\/train_image_data_1.parquet')\n#images2 = load_as_npa('\/kaggle\/input\/bengaliai-cv19\/train_image_data_2.parquet')\n#images3 = load_as_npa('\/kaggle\/input\/bengaliai-cv19\/train_image_data_3.parquet')\n","5a1c0126":"#f, ax = plt.subplots(4, 4, figsize=(12, 8))\n#ax = ax.flatten()\n\n#for i in range(16):\n#    ax[i].imshow(images0[i], cmap='Greys')","01275448":"#final_train_images = np.concatenate((images0, images1, images2, images3), axis=0)","44e6dc55":"#del [[images0, images1, images2, images3, final_train_images]]\n#del [[final_train_images]]\n#gc.collect()","8a8a5028":"#final_train_images.shape","3dbbe890":"#import pyarrow.parquet as pq","675de139":"#able = pq.read_table(file_path, nthreads=4)\n#df_image_0 = pq.read_table('\/kaggle\/input\/bengaliai-cv19\/train_image_data_0.parquet')","2e0baa2f":"def resize(df, size=46, need_progress_bar=True):\n    resized = {}\n    if need_progress_bar:\n        for i in tqdm(range(df.shape[0])):\n            image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n            resized[df.index[i]] = image.reshape(-1)\n    else:\n        for i in range(df.shape[0]):\n            image = cv2.resize(df.loc[df.index[i]].values.reshape(137,236),(size,size))\n            resized[df.index[i]] = image.reshape(-1)\n    resized = pd.DataFrame(resized).T\n    return resized","fea68601":"df_image_0 = pd.read_parquet('\/kaggle\/input\/bengaliai-cv19\/train_image_data_0.parquet')","119117c4":"df_image_0.shape","459319b9":"type(df_image_0)","ddfc65ce":"df_image_0.head()","6c844616":"df_image_0 = df_image_0.iloc[:,1:]","c66dcd7d":"df_image_0 = resize(df_image_0)\/255\n#X_train = resize(X_train)\/255","c562b355":"X_image_0 = df_image_0.to_numpy() # Convert the dataframe to matrix ","1a6f8b13":"X_image_0.shape","b414a958":"del [[df_image_0]]\ngc.collect()","daaee1fc":"df_image_1 = pd.read_parquet('\/kaggle\/input\/bengaliai-cv19\/train_image_data_1.parquet')\ndf_image_1= df_image_1.iloc[:,1:]","47618a2d":"df_image_1 = resize(df_image_1)\/255","b7b82598":"X_image_1 = df_image_1.to_numpy() # Convert the dataframe to matrix ","5bb25b25":"X_image_1.shape","675b93b2":"#del [[df_image_1]]\ndel df_image_1\ngc.collect()","1f6be453":"df_image_2 = pd.read_parquet('\/kaggle\/input\/bengaliai-cv19\/train_image_data_2.parquet')\ndf_image_2= df_image_2.iloc[:,1:]","5ea4296e":"df_image_2 = resize(df_image_2)\/255","44138cd5":"X_image_2 = df_image_2.to_numpy() # Convert the dataframe to matrix ","331e0e05":"X_image_2.shape","c9008184":"#del [[df_image_2]]\ndel df_image_2\ngc.collect()","50734535":"df_image_3 = pd.read_parquet('\/kaggle\/input\/bengaliai-cv19\/train_image_data_3.parquet')\ndf_image_3= df_image_3.iloc[:,1:]","af9e1609":"df_image_3 = resize(df_image_3)\/255","0a30bb6d":"X_image_3 = df_image_3.to_numpy() # Convert the dataframe to matrix ","cd039bd2":"X_image_3.shape","c376bb68":"del [[df_image_3]]\ngc.collect()","76fd76c2":"#final_train_images","af2cc802":"#image_size = 137 * 236\n#final_train_images.reshape(image_size)","4871968e":"#X = final_train_images\/255","1443fcd5":"#X = pd.merge([X_image_0, X_image_1, X_image_2, X_image_3])\nX= np.concatenate((X_image_0, X_image_1, X_image_2, X_image_3), axis=0)","d3af489d":"len(X)","dea3792d":"del X_image_0\ndel X_image_1\ndel X_image_2\ndel X_image_3\ngc.collect()","40398581":"type(X)","bc2186f8":"#from tempfile import TemporaryFile\n#train_all_image_file = TemporaryFile()\n\n\n#from joblib import dump\n#dump(X, 'all_image_4_train.joblib', compress=3)\n#import pickle\n#f=open('all_image_4_train','w')\n#pickle.dump(X, f, protocol=4)\n#f.close()","b9ed10f3":"# Download form the output folder of thsi kernel\ndf_consonant.to_csv(\"target_4_consonant.csv\")\ndf_grapheme.to_csv(\"target_4_grapheme.csv\")\ndf_vowel.to_csv(\"target_4_vowel.csv\")","5e65198e":"#X.shape","457fb7ed":"X= X.reshape(-1,46, 46,1)","69c3686d":"n_classes = 7","cd15b108":"y= df_consonant.value","d0270483":"from tensorflow.keras.utils import to_categorical","4c9459bd":"y = to_categorical(y, n_classes)","ecf87a81":"from sklearn.model_selection import train_test_split","91128fd8":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)","73ff855d":"#X = np.divide(X, 255)\n#import dask.array as da\n\n#X = np.arange(1000)  #arange is used to create array on values from 0 to 1000\n#y = da.from_array(X, chunks=(100))  #converting numpy array to dask array\n\n#y.div(255).compute()  #computing mean of the array","d039e703":"from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\nfrom keras import Sequential","f722efb3":"model_consonant = Sequential()\n\nmodel_consonant .add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(46, 46,1)))\n\nmodel_consonant .add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel_consonant .add(MaxPooling2D(pool_size=(2,2)))\nmodel_consonant .add(Dropout(0.25))\n\nmodel_consonant .add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel_consonant .add(MaxPooling2D(pool_size=(2,2)))\nmodel_consonant .add(Dropout(0.25))\n\nmodel_consonant .add(Flatten())\n\nmodel_consonant .add(Dense(128, activation='relu'))\n#model.add(Dense(128, activation='relu'))\nmodel_consonant.add(Dropout(0.5))\n\nmodel_consonant .add(Dense(n_classes, activation='softmax'))","eeea7c3b":"model_consonant.summary()","bf422474":"model_consonant.compile(loss='categorical_crossentropy',\n             optimizer='nadam',\n             metrics=['accuracy'])","68e5da6c":"model_consonant.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))","8cd65baa":"#history = model.fit(X_train, \n#                    y_train, \n#                    batch_size=128, \n#                    epochs=100,\n#                    verbose=1,\n#                    validation_data=(X_test, y_test)\n#                   )\n#history = model_consonant.fit(X, \n#                    y, \n#                    batch_size=128, \n#                    epochs=1,\n#                    verbose=1\n#                    #validation_data=(X_test, y_test)\n#                   )","cc544e95":"# Save the weights\nmodel_consonant.save_weights('model_consonant_weight.h5')\n\n# Save the model architecture\nwith open('model_consonant_architecture.json', 'w') as f:\n    f.write(model_consonant.to_json())\n    \n## READ weight and architecture\n#from keras.models import model_from_json\n\n## Model reconstruction from JSON file\n#with open('model_consonant_architecture.json', 'r') as f:\n#    model = model_from_json(f.read())\n\n## Load weights into the new model\n#model.load_weights('model_consonant_weight.h5')","16bb0092":"predictions_consonant = model_consonant.predict(X_test)\npredictions_consonant = np.argmax(predictions_consonant, axis=1) ","87d23b39":"# calculate accuracy\n#from sklearn import metrics\n#print(metrics.accuracy_score(y_test, predictions_consonant))\n#print(metrics.confusion_matrix(y_test, predictions_consonant))","4b78f907":"del X_train\ndel X_test\ndel y_train\ndel y_test\ngc.collect()","881ca040":"n_classes = 168\ny= df_grapheme.value\ny = to_categorical(y, n_classes)","09280c66":"X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)","ac255f11":"model_grapheme = Sequential()\n\nmodel_grapheme.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(46, 46,1)))\n\nmodel_grapheme.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\nmodel_grapheme.add(MaxPooling2D(pool_size=(2,2)))\nmodel_grapheme.add(Dropout(0.25))\n\nmodel_grapheme.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\nmodel_grapheme.add(MaxPooling2D(pool_size=(2,2)))\nmodel_grapheme.add(Dropout(0.25))\n\nmodel_grapheme.add(Flatten())\n\nmodel_grapheme.add(Dense(128, activation='relu'))\n#model.add(Dense(128, activation='relu'))\nmodel_grapheme.add(Dropout(0.5))\n\nmodel_grapheme.add(Dense(n_classes, activation='softmax'))","61732a3d":"model_grapheme.summary()","005e09fa":"model_grapheme.compile(loss='categorical_crossentropy',\n             optimizer='nadam',\n             metrics=['accuracy'])","7496131e":"model_grapheme.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))","cd6462c5":"predictions_grapheme = model_grapheme.predict(X_test)","8174a622":"# Save the weights\nmodel_grapheme.save_weights('model_grapheme_weight.h5')\n\n# Save the model architecture\nwith open('model_grapheme_architecture.json', 'w') as f:\n    f.write(model_grapheme.to_json())\n    \n## READ weight and architecture\n#from keras.models import model_from_json\n\n## Model reconstruction from JSON file\n#with open('model_consonant_architecture.json', 'r') as f:\n#    model = model_from_json(f.read())\n\n## Load weights into the new model\n#model.load_weights('model_consonant_weight.h5')","efa2fee2":"del X_train\ndel X_test\ndel y_train\ndel y_test\ngc.collect()","0d7f8600":"#n_classes = 11\n#y= df_vowel.value\n#y = to_categorical(y, n_classes)","8cb10b80":"#X_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.3, random_state=42)","d3c2a738":"#model_vowel = Sequential()\n\n#model_vowel.add(Conv2D(32, kernel_size=(3,3), activation='relu', input_shape=(46, 46,1)))\n\n#model_vowel.add(Conv2D(32, kernel_size=(3,3), activation='relu'))\n#model_vowel.add(MaxPooling2D(pool_size=(2,2)))\n#model_vowel.add(Dropout(0.25))\n\n#model_vowel.add(Conv2D(64, kernel_size=(3,3), activation='relu'))\n#model_vowel.add(MaxPooling2D(pool_size=(2,2)))\n#model_vowel.add(Dropout(0.25))\n\n#model_vowel.add(Flatten())\n\n#model_vowel.add(Dense(128, activation='relu'))\n##model.add(Dense(128, activation='relu'))\n#model_vowel.add(Dropout(0.5))\n\n#model_vowel.add(Dense(n_classes, activation='softmax'))","acc75148":"#model_vowel.summary()","3f3c896b":"#model_vowel.compile(loss='categorical_crossentropy',\n#             optimizer='nadam',\n#             metrics=['accuracy'])","fce4503b":"#model_vowel.fit(X_train, y_train, batch_size=32, epochs=20, validation_data=(X_test, y_test))","9d5c107e":"#predictions_vowel = model_vowel.predict(X_test)","e2718c8d":"## Save the weights\n#model_vowel.save_weights('model_vowel_weight.h5')\n\n## Save the model architecture\n#with open('model_vowel_architecture.json', 'w') as f:\n#    f.write(model_vowel.to_json())\n    \n## READ weight and architecture\n#from keras.models import model_from_json\n\n## Model reconstruction from JSON file\n#with open('model_consonant_architecture.json', 'r') as f:\n#    model = model_from_json(f.read())\n\n## Load weights into the new model\n#model.load_weights('model_consonant_weight.h5')","3cd8e5ad":"#del X_train\n#del X_test\n#del y_train\n#del y_test\n#gc.collect()","22a5dcc5":"#components = ['consonant_diacritic', 'grapheme_root', 'vowel_diacritic']\n#target=[] # model predictions placeholder\n#row_id=[] # row_id place holder\n#n_cls = [7,168,11] # number of classes in each of the 3 targets\n#IMG_SIZE = 46\n#IMG_SIZE= 46\n#N_CHANNELS = 1\n#for i in range(4):\n#    df_test_img = pd.read_parquet('\/kaggle\/input\/bengaliai-cv19\/test_image_data_{}.parquet'.format(i)) \n#    df_test_img.set_index('image_id', inplace=True)\n\n#    X_test = resize(df_test_img)\/255\n#    X_test = X_test.values.reshape(-1, IMG_SIZE, IMG_SIZE, N_CHANNELS)\n\n#    for pred in preds_dict:\n#        preds_dict[pred]=np.argmax(model_dict[pred].predict(X_test), axis=1)\n\n#    for k,id in enumerate(df_test_img.index.values):  \n#        for i,comp in enumerate(components):\n#            id_sample=id+'_'+comp\n#            row_id.append(id_sample)\n#            target.append(preds_dict[comp][k])\n\n#df_sample = pd.DataFrame(\n#    {'row_id': row_id,\n#    'target':target\n#    },\n#    columns =['row_id','target'] \n#)\n#df_sample.to_csv('submission.csv',index=False)","052f47b4":"### Free some memory. Here my memory usage was 13 Gb, after running the garbage collector, it reduced to 7 Gb.","668fb994":"- Make three separate dataframe each for 'compnent' ```consonant_discritic```, ```grapheme_root```, and ```vowel_diacritic```.\n\n- These are the train_target values. i.e. the values in column 'value'.","ccc02e45":"# Introduction\nBengali language origninated from the Prakrit or Middle Indo-Aryan, which is descended from Sanskrit. \nThe map below shows Begali or Bangla speaking regions.\n![image.png](attachment:image.png)\n\n\n","69b55dc8":"- Rename the column-names i.e. 'variable' to 'component'.","c5a48c61":"### Helper function to read and see parquet","25d18c5f":"Here, the ```final_train_images``` combines the image pixels with the three labels i.e. ```grapheme_root```, ```vowel_diacritic```, ```consonant_diacritic``` which can be used to train the model.\n\nWe will use this to train a model.","e730c0ff":"## Merge the 3 parquet image_matrix into one matrix","576d1419":"\n\n```Jana Gana Mana``` is the national anthem of India. \nIt was first written in Bengali, it is the first of five stanzas of a poem written and later set to notations by novel loriat Rbindranath Tagore (1861-1941).\n\n- Rabindranath Tagore won the Nobel Prize for Literature Language: Bengali; English) in 1913.\n\n\n### Objective:\nFor this competition, you\u2019re given the image of a handwritten Bengali grapheme and are challenged to separately classify three constituent elements in the image: grapheme root, vowel diacritics, and consonant diacritics.","1bf342f3":"# Prediction & Submission","ad06f9d9":"## Sneak peak at distribution of the three class","ebf3ccc2":"- Add a column name 'row_id' by combining image_id and variable column values.","5c2c37e5":"Read each parquet file again\n\n","c29f29de":"Let us look at some of the Bengali images","aa9e35c2":"### Save model_consonant\n","bad52d07":"# Saving the training data: Download\n\nHere, following files are being saved:\n- X ( It has all the training images, pixel in matrix format- each row in the matrix represents an image)\n\nAdditionally, the three target columns for three separate model one each for ```consonant_discritic```: 7, ```grapheme_root```: 168, and ``vowel_diacritic```: 11.\n\n- ```df_consonant.shape```\n- ```df_grapheme.shape``` and\n- ```df_vowel.shape``` \n\nEach one will work as target for our three separte models.","33be26da":"Steps:\n- Read train_label data and make it same as submission.csv file i.e. with only two columns. The image_id merge it with the three classes i.e. grapheme_root, vowel_diacritics, and consonant_diacritics e.g. Train_0_grapheme_root.","84526e72":"## Final data for training","115153a9":"## File\n### train.csv\n\n- ```image_id:``` the foreign key for the parquet files\n- ```grapheme_root:``` the first of the three target classes\n- ```vowel_diacritic:``` the second target class\n- ```consonant_diacritic:``` the third target class\n- ```grapheme:``` the complete character. Provided for informational purposes only, you should not need to use this.\n\n### test.csv\n\nEvery image in the test set will require three rows of predictions, one for each component. This csv specifies the exact order for you to provide your labels.\n- ```row_id:``` foreign key to the sample submission \n- ```image_id:``` foreign key to the parquet file \n- ```component:``` the required target class for the row (grapheme_root, vowel_diacritic, or consonant_diacritic)","21b28aff":"## Model_consonant","8681290e":"## Model grapheme","6a1800ad":"```consonant_discritic```: 7, \n\n```grapheme_root```: 168, and \n\n```vowel_diacritic```: 11\n\n#### Download the above files and load in your kernel before carryingout the below steps.","7b39b707":"# What to expect from this kernel?\n\n- Train_labels data (y)\n- Train image data (X)\n- CNN Models for Vowel, Consonant, Grapheme (Accu: 86%) \n\nDownload the train data to directly train your own deep-learning or machine learning model. You can download the prepared training data from this kernel ( Link provided below).\n\n### _Please upvote if you like it._\n# Model flow\n\n![image.png](attachment:image.png)\n\n","d6937fbd":"## Model vowel"}}