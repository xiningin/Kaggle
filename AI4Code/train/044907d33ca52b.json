{"cell_type":{"7c422d73":"code","361e9aa2":"code","c2859459":"code","e0f7f723":"code","3bf457c7":"code","964d3f15":"code","78f491e8":"code","fcb98f57":"code","53b8f52e":"code","85143c2d":"code","ee95fe6e":"code","5fc4a439":"code","d91ecb2a":"code","6ded39aa":"code","d47c1b3f":"code","4cd18b40":"code","20e2a307":"code","203c55fe":"code","285924da":"code","9c7093ab":"code","5037e883":"code","9b119d29":"code","fa01588f":"code","244ebe40":"code","9c7a0fc8":"code","58bca2c4":"code","4dc08e79":"code","a46dbc1f":"code","f6a75b5c":"code","b7440d4a":"code","55d1cf87":"code","1d13119f":"markdown","e702bcb7":"markdown","4dd6a50a":"markdown","e949bb34":"markdown","8303fe9d":"markdown","fcf3f6a4":"markdown","d73e0928":"markdown","99c4d8b5":"markdown","ef7ea5c8":"markdown","dc5215f3":"markdown"},"source":{"7c422d73":"!pip install nlp","361e9aa2":"%matplotlib inline\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport nlp\nimport random\nprint('Using TensorFlow version', tf.__version__)","c2859459":"def show_history(h):\n    epochs_trained = len(h.history['loss'])\n    plt.figure(figsize=(16, 6))\n\n    plt.subplot(1, 2, 1)\n    plt.plot(range(0, epochs_trained), h.history.get('accuracy'), label='Training')\n    plt.plot(range(0, epochs_trained), h.history.get('val_accuracy'), label='Validation')\n    plt.ylim([0., 1.])\n    plt.xlabel('Epochs')\n    plt.ylabel('Accuracy')\n    plt.legend()\n\n    plt.subplot(1, 2, 2)\n    plt.plot(range(0, epochs_trained), h.history.get('loss'), label='Training')\n    plt.plot(range(0, epochs_trained), h.history.get('val_loss'), label='Validation')\n    plt.xlabel('Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n\n    \ndef show_confusion_matrix(y_true, y_pred, classes):\n    from sklearn.metrics import confusion_matrix\n    \n    cm = confusion_matrix(y_true, y_pred, normalize='true')\n\n    plt.figure(figsize=(8, 8))\n    sp = plt.subplot(1, 1, 1)\n    ctx = sp.matshow(cm)\n    plt.xticks(list(range(0, 6)), labels=classes)\n    plt.yticks(list(range(0, 6)), labels=classes)\n    plt.colorbar(ctx)\n    plt.show()","e0f7f723":"dataset = nlp.load_dataset('emotion')","3bf457c7":"dataset","964d3f15":"train = dataset['train']\nval = dataset['validation']\ntest = dataset['test']","78f491e8":"def get_tweets(data):\n    tweets = [x['text'] for x in data]\n    labels = [x['label'] for x in data]\n    return tweets, labels","fcb98f57":"tweets, labels = get_tweets(train)","53b8f52e":"tweets[0], labels[0]","85143c2d":"tokenizer = tf.keras.preprocessing.text.Tokenizer(num_words=10000, oov_token='<OOV>')\n\ntokenizer.fit_on_texts(tweets)\n\nprint(tokenizer.texts_to_sequences([tweets[3]]))","ee95fe6e":"lengths = [len(t.split(' ')) for t in tweets]\n\nplt.hist(lengths, bins=len(set(lengths)))\nplt.show()","5fc4a439":"def get_sequences(tokenizer, tweets):\n    sequences = tokenizer.texts_to_sequences(tweets)\n    padded_sequences = pad_sequences(sequences, truncating='post', maxlen=50, padding='post')\n    return padded_sequences","d91ecb2a":"padded_train_sequences = get_sequences(tokenizer, tweets)","6ded39aa":"padded_train_sequences[0]","d47c1b3f":"classes = set(labels)\nprint(classes)","4cd18b40":"plt.hist(labels, bins=11)\nplt.show()","20e2a307":"classes_to_index = dict((c, i) for i, c in enumerate(classes))\nindex_to_classes = dict((v, k) for k, v in classes_to_index.items())","203c55fe":"classes_to_index","285924da":"index_to_classes","9c7093ab":"names_to_ids = lambda labels: np.array([classes_to_index.get(x) for x in labels])","5037e883":"train_labels = names_to_ids(labels)\nprint(train_labels[0])","9b119d29":"model = tf.keras.models.Sequential([\n    tf.keras.layers.Embedding(10000, 16, input_length=50),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(20)),\n    tf.keras.layers.Dense(6, activation='softmax')\n])\n\nmodel.compile(\n    loss='sparse_categorical_crossentropy',\n    optimizer='adam',\n    metrics=['accuracy']\n)\n\nmodel.summary()","fa01588f":"val_tweets, val_labels = get_tweets(val)\nval_sequences = get_sequences(tokenizer, val_tweets)\nval_labels = names_to_ids(val_labels)","244ebe40":"val_tweets[0], val_labels[0]","9c7a0fc8":"history = model.fit(\n    padded_train_sequences, train_labels,\n    validation_data=(val_sequences, val_labels),\n    epochs=50,\n    callbacks=[\n        tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=2)\n    ]\n)","58bca2c4":"show_history(history)","4dc08e79":"test_tweets, test_labels = get_tweets(test)\ntest_sequences = get_sequences(tokenizer, test_tweets)\ntest_labels = names_to_ids(test_labels)","a46dbc1f":"_ = model.evaluate(test_sequences, test_labels)","f6a75b5c":"i = random.randint(0, len(test_labels) - 1)\n\nprint('Sentence:', test_tweets[i])\nprint('Emotion:', index_to_classes[test_labels[i]])\n\np = model.predict_classes(np.expand_dims(test_sequences[i], axis=0))[0]\nprint('Predicted Emotion:', index_to_classes.get(p))","b7440d4a":"preds = model.predict_classes(test_sequences)\npreds.shape, test_labels.shape","55d1cf87":"show_confusion_matrix(test_labels, preds, list(classes))","1d13119f":"## Training the Model\n\n1. Preparing a validation set\n2. Training the model","e702bcb7":"## Evaluating the Model\n\n1. Visualizing training history\n2. Prepraring a test set\n3. A look at individual predictions on the test set\n4. A look at all predictions on the test set","4dd6a50a":"## Tweet Emotion Recognition with TensorFlow\n","e949bb34":"### Reference\n- [Tweet Emotion Dataset](https:\/\/github.com\/dair-ai\/emotion_dataset)\n- [Tweet Emotion Recognition with TensorFlow](https:\/\/www.coursera.org\/learn\/tweet-emotion-tensorflow)","8303fe9d":"## Tokenizing the tweets","fcf3f6a4":"## Setup and Imports\n\n1. Installing Hugging Face's nlp package\n2. Importing libraries","d73e0928":"## Padding and Truncating Sequences\n\n1. Checking length of the tweets\n2. Creating padded sequences","99c4d8b5":"## Importing Data\n\n1. Importing the Tweet Emotion dataset\n2. Creating train, validation and test sets\n3. Extracting tweets and labels from the examples","ef7ea5c8":"## Creating and Compiling the Model","dc5215f3":"## Preparing the Labels\n\n1. Creating classes to index and index to classes dictionaries\n2. Converting text labels to numeric labels"}}