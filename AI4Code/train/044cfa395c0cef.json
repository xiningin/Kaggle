{"cell_type":{"6b5dec1e":"code","dcfc5e6a":"code","73280333":"code","5643842c":"code","c7f1e5b8":"code","e8a56821":"code","ce99018e":"code","535260be":"code","62c080c8":"code","87dbc1f1":"code","8efced3d":"code","2f478e86":"code","d66217f7":"code","b03b2f90":"code","79ae1547":"markdown","ecc69f0f":"markdown"},"source":{"6b5dec1e":"\nimport datetime\nimport warnings\nwarnings.simplefilter('ignore')\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport lightgbm as lgb\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import scale\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import precision_recall_fscore_support\nfrom sklearn.metrics import accuracy_score\nfrom statsmodels.formula.api import ols\nfrom sklearn.metrics import cohen_kappa_score\nfrom collections import OrderedDict\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom scipy.stats import norm, skew, probplot\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.preprocessing import QuantileTransformer","dcfc5e6a":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    end_mem = df.memory_usage().sum() \/ 1024 ** 2\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","73280333":"df_train = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')","5643842c":"# 7:3\uc73c\ub85c \uc81c\uacf5\ub41c train data\ub97c train\uacfc validation data\ub85c \uad6c\ubd84\n\nfrom sklearn.model_selection import train_test_split\n\nrandom_state_val =42\ntest_size_val =0.05\ntrain,validation = train_test_split(df_train, test_size = test_size_val, random_state = random_state_val)","c7f1e5b8":"y_nm = 'target'\n\ndf_train_x = train.drop(y_nm, axis = 1)\ndf_train_y = pd.DataFrame(train[y_nm])\n\ndf_val_x = validation.drop(y_nm, axis = 1)\ndf_val_y = pd.DataFrame(validation[y_nm])\n\ndf_test_x = df_test","e8a56821":"scaler = QuantileTransformer()\nscaler.fit(df_train_x)\ndf_train_x = pd.DataFrame(scaler.transform(df_train_x))\ndf_val_x = pd.DataFrame(scaler.transform(df_val_x))\ndf_test_x = pd.DataFrame(scaler.transform(df_test_x))","ce99018e":"LGBClassifier = lgb.LGBMClassifier(objective='binary',\n                                   max_depth = 8,\n                                   learning_rate = 0.01,\n                                   n_estimators = 9000,\n                                   max_bin = 200,\n                                   bagging_freq = 4,\n                                   bagging_seed = 8,\n                                   feature_fraction = 0.2,\n                                   feature_fraction_seed = 8,\n                                   min_sum_hessian_in_leaf = 11,\n                                   verbose = -1,\n                                   random_state = 42)","535260be":"start = datetime.datetime.now()\nlgbm = LGBClassifier.fit(df_train_x.values,\n                       df_train_y.values.ravel(),\n                       eval_set = [(df_train_x.values, df_train_y), (df_val_x.values, df_val_y)],\n                       eval_metric ='logloss',\n                       early_stopping_rounds = 20,\n                       verbose =False)\nend = datetime.datetime.now()\nend-start","62c080c8":"import seaborn as sns\n\nfeature_imp= pd.DataFrame(sorted(zip(lgbm.feature_importances_, df_test_x.columns), reverse = True), columns = ['Value', 'Feature'])\n# feature_imp.to_excel(\"feature_imp.xlsx\")\n\nplt.figure(figsize=(7,5))\nsns.barplot(x='Value', y='Feature', data=feature_imp.sort_values(by='Value', ascending=False))\nplt.tight_layout()\nplt.show()","87dbc1f1":"fpr, tpr, _ = roc_curve(df_val_y, lgbm.predict_proba(df_val_x.values)[:, 1])\nroc_auc = auc(fpr, tpr)\n\nresult_lst =[]\nmax_roc_auc =0.\nopt_threshold =0.\nval_y_prob = lgbm.predict_proba(df_val_x.values)[:, 1]\n\nfor n in range(0,50):\n    threshold = round(((n+1)*0.01),2)\n    pred_yn = val_y_prob.copy()\n    pred_yn = np.where(pred_yn > threshold, 1., 0.)\n    \n    result_dict = {}\n    precision, recall, f1_score, support = precision_recall_fscore_support(df_val_y.values.ravel(), pred_yn, average='binary')\n    accuracy = accuracy_score(df_val_y.values.ravel(), pred_yn)\n    kappa = cohen_kappa_score(df_val_y.values.ravel(), pred_yn)\n    \n    result_dict ={'Threshold': threshold, 'Accuracy': round(accuracy,4), 'Precision': round(precision,4), 'Recall': round(recall,4), 'F1_Score': round(f1_score,4),'roc_auc': round(roc_auc,4), 'Kappa': round(kappa,4)}\n    result_lst.append(result_dict)\n    \n    if max_roc_auc <= roc_auc:\n        max_roc_auc = roc_auc\n        opt_threshold = threshold\n        \n    confMat = confusion_matrix(df_val_y.values.ravel(), pred_yn, labels=[1,0])\n    \nmatric_df = pd.DataFrame(result_lst, columns=['Threshold','Accuracy', 'Precision', 'Recall', 'F1_Score','roc_auc' ,'Kappa'])\nmatric_df.to_csv('REC_scores.csv',sep=',', header=True, index=False, encoding='UTF-8')\n\nprint('Max roc_auc =%f, optimized_threshold=%f'%(max_roc_auc, opt_threshold))\nprint('Complete')","8efced3d":"predict_lgbm = lgbm.predict_proba(df_train_x.values)[:,1]\npred_train = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntp, fn, fp, tn = confusion_matrix(df_train_y.values.ravel(), pred_train, labels=[1,0]).ravel()\n\nconf_matrix = pd.DataFrame(\n    confusion_matrix(df_train_y.values.ravel(), pred_train),\n    columns=['Predicted Value 0', 'Predicted Value 1'],\n    index=['True Value 0', 'True Value 1']\n)\n\nprint(\"1. Counfusion Matrix\")\nprint(conf_matrix.T)\nprint(\"\")\n\nprint(\"2. Classification Report\")\nprint(classification_report(df_train_y.values.ravel(), pred_train))","2f478e86":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, _ = roc_curve(df_train_y.values.ravel(), predict_lgbm)\n\nimport matplotlib.pyplot as plt\nroc_auc = auc(fpr, tpr)\n\n# Plot of a ROC curve for a specific class\nplt.figure()\nplt.plot(fpr, tpr, color='darkorange', label='ROC curve (area = %0.3f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', lw=2, linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC Curve')\nplt.legend(loc=\"lower right\")\nplt.show()","d66217f7":"Accuracy_Rate = (tp + tn) \/ (tp + tn + fp + fn)\nRecall_Rate = tp \/ (tp + fn)\nPrecision_Rate = tp \/ (tp + fp)\nSpecificity_Rate = tn \/ (tn + fp)\nF1_Score = (Precision_Rate * Recall_Rate) \/ (Precision_Rate + Recall_Rate) * 2\n\nprint(\"3. Model Metric Sumamry\")\nprint(\" - Accuracy Rate    : {:2.3f} %\".format(Accuracy_Rate*100))\nprint(\" - Recall Rate      : {:2.3f} %\".format(Recall_Rate*100))\nprint(\" - Precision Rate   : {:2.3f} %\".format(Precision_Rate*100))\nprint(\" - Specificity Rate : {:2.3f} %\".format(Specificity_Rate*100))\nprint(\" - F1 Score         : {:2.3f} \".format(F1_Score*100))\nprint(\" - ROC AUC          : {:2.3f} \".format(roc_auc*100))","b03b2f90":"df_test = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\n\npredict_lgbm = lgbm.predict_proba(df_test_x.values)[:,1]\npred_test = np.where(predict_lgbm > opt_threshold, 1., 0.)\n\ntest_result= pd.DataFrame(pred_test)\ntest_result.columns = ['target']\npredict = test_result['target']\nId_No = df_test['id']\nsubmission = pd.DataFrame({'id': Id_No, 'target': predict})\nsubmission['target'] = submission['target'].astype('Int64')\nsubmission.to_csv('submission.csv', index=False)\nsubmission.head()","79ae1547":"### \uac1c\uc694 (Introduction)\n\n##### \ubaa8\ub378\ub9c1\uc758 \uacbd\uc6b0 train, test data\ub97c \ub098\ub204\uace0,\n##### \uadf8\uac83\uc744 fit(\ud559\uc2b5) \uc2dc\ucf1c\uc11c 0.5\uc774\uc0c1\uc758 \uac12\uc5d0 \ub300\ud558\uc5ec 1,0\uc73c\ub85c \uad6c\ubd84\ud558\uc5ec predict\uc744 \uc9c4\ud589\ud569\ub2c8\ub2e4.\n\n##### \uc774 validation set data\ub97c \ud65c\uc6a9\ud558\uc5ec threshold\uac12\uc744 \uc870\uc815\ud558\uc5ec \uc6b0\ub9ac\uac00 \uc6d0\ud558\ub294 AUROC\ub098 Accuracy\uc5d0 \ub9de\ub294 \ucd5c\uc885 \uac12 \uc0ac\uc6a9\ud558\ub294 \ubaa8\ub378\uc744 \uad6c\ud604 \ud558\uc600\uc2b5\ub2c8\ub2e4. \n\n##### \uad73\uc774 Grid-Search\ub098 bayesian optimization\uac19\uc740 \uae30\ubc95\uc744 \uc0ac\uc6a9\ud558\uc5ec Hyper parameter tuning\uc5d0 \uc2dc\uac04\uc744 \uc18c\uc694\ud558\ub294 \uac83\uc744 \ucd5c\uc18c\ud654\ud558\ub294\n##### \ubaa9\uc801\uc73c\ub85c \ubaa8\ub378\ub9c1 \uc9c4\ud589\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n## \n\n##### In the case of modeling, train and test data are divided,\n##### By fitting (learning) it, we proceed to predict by classifying 1, 0 for values over 0.5.\n\n##### By adjusting this threshold value, we implemented a model that uses the final value that fits the desired AUROC or Accuracy.\n##### To minimize the time required for hyper parameter tuning by using techniques such as Grid-Search or Bayesian optimization.\n##### Modeling was done for this purpose.","ecc69f0f":"## Memory Reduction\n#### This memory reduction part taken from https:\/\/www.kaggle.com\/azzamradman\/tps-10-single-xgboost\/notebook amazing notebook. Please upvote it if you like this part."}}