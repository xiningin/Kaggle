{"cell_type":{"ea479b36":"code","18cdffa5":"code","83a95428":"code","7ac8ef89":"code","cbe184ba":"code","77ec221a":"code","51c164a9":"code","b2717ff1":"code","4a9733c6":"code","441d814a":"code","3ac4b896":"code","0970adca":"code","0fa1cf88":"code","e55e9e0e":"code","b499ea99":"code","dedb3fa5":"code","4e7418d6":"code","56bbc758":"markdown","b535ec82":"markdown","3a3970ad":"markdown","e46d792b":"markdown","c2a67304":"markdown","95aaaa60":"markdown","80618c22":"markdown"},"source":{"ea479b36":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport keras.layers as layers\nfrom sklearn.model_selection import train_test_split\nimport random\nimport tensorflow_probability as tfp\nimport tensorflow_addons as tfa","18cdffa5":"from tensorflow.keras.preprocessing import image_dataset_from_directory\nfrom keras import backend as K\n\nbatch_size= 24\nimage_size = [128, 128]\n\n\nds = image_dataset_from_directory(\n    '..\/input\/screwanomalies-detection\/screw\/train',\n    labels=None,\n    image_size=image_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=True,\n)\n\ndef convert_to_float(image):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\n\ndef trans1(img):\n    return tfa.image.rotate(tf.image.flip_left_right(tf.image.flip_up_down(img)),-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n\ndef trans2(img):\n    return tfa.image.rotate(img,-.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n\ndef trans3(img):\n    return tfa.image.rotate(img,.2,fill_mode=\"reflect\",interpolation=\"bilinear\")\n    \nds1,ds2,ds3,ds4 = ds,ds.map(trans1),ds.map(trans2),ds.map(trans3)\n\nds = ds1.concatenate(ds2).concatenate(ds3).concatenate(ds4)\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds = (\n    ds\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)","83a95428":"ds_a = image_dataset_from_directory(\n    '..\/input\/screwanomalies-detection\/screw\/test\/scratch_neck',\n    labels=None,\n    image_size=image_size,\n    interpolation='nearest',\n    batch_size=batch_size,\n    shuffle=True,\n)\nprint(type(ds))\n\ndef convert_to_float(image):\n    image = tf.image.convert_image_dtype(image, dtype=tf.float32)\n    return image\n\nAUTOTUNE = tf.data.experimental.AUTOTUNE\nds_a = (\n    ds_a\n    .map(convert_to_float)\n    .cache()\n    .prefetch(buffer_size=AUTOTUNE)\n)","7ac8ef89":"class Sampling(layers.Layer):\n    \"\"\"Uses (z_mean, z_log_var) to sample z, the vector encoding a digit.\"\"\"\n\n    def call(self, inputs):\n        z_mean, z_log_var = inputs\n        batch = tf.shape(z_mean)[0]\n        dim = tf.shape(z_mean)[1]\n        epsilon = tf.keras.backend.random_normal(shape=(batch, dim))\n        return z_mean + tf.exp(0.5 * z_log_var) * epsilon","cbe184ba":"lrelu = tf.nn.selu","77ec221a":"latent_dim = 32\na,b = image_size\nshape=(a, b,3)\n\n\nencoder_inputs = keras.Input(shape=shape)\nx = layers.Conv2D(32, 3, activation=\"relu\", strides=2, padding=\"same\")(encoder_inputs)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(128, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(256, 3, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Flatten()(x)\nx = layers.Dense(160, activation=\"tanh\")(x)\nz_mean = layers.Dense(latent_dim, name=\"z_mean\")(x)\nz_log_var = layers.Dense(latent_dim, name=\"z_log_var\")(x)\nz = Sampling()([z_mean, z_log_var])\nencoder = keras.Model(encoder_inputs, [z_mean, z_log_var, z], name=\"encoder\")\nencoder.summary()","51c164a9":"latent_inputs = keras.Input(shape=(latent_dim,))\nx = layers.Dense(8* 8 * 64, activation=\"relu\")(latent_inputs)\nx = layers.Reshape((8, 8, 64))(x)\nx = layers.Conv2DTranspose(256, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Conv2D(256, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2DTranspose(128, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Conv2D(128, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2DTranspose(64, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Conv2D(64, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2DTranspose(32, 2, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Conv2D(32, 3, activation=\"relu\", strides=1, padding=\"same\")(x)\ndecoder_outputs = layers.Conv2DTranspose(3, 3, activation=\"sigmoid\", padding=\"same\")(x)\ndecoder = keras.Model(latent_inputs, decoder_outputs, name=\"decoder\")\ndecoder.summary()","b2717ff1":"discriminator_inputs = keras.Input(shape=shape)\n\nx = layers.Conv2D(128, 8, activation=\"relu\", strides=2, padding=\"same\")(discriminator_inputs)\nx = layers.MaxPool2D()(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(64, 5, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.MaxPool2D()(x)\nx = layers.BatchNormalization()(x)\nx = layers.Conv2D(32, 4, activation=\"relu\", strides=2, padding=\"same\")(x)\nx = layers.Flatten()(x)\nx = layers.Dense(128, activation=\"relu\")(x)\ndiscriminator_outputs = layers.Dense(1,activation=\"sigmoid\")(x)\ndiscriminator = keras.Model(discriminator_inputs, discriminator_outputs, name=\"discriminator\")\ndiscriminator.summary()","4a9733c6":"def corr_loss(z):\n    coor_matrix = tfp.stats.correlation(z)\n    loss = 0\n    n,m = coor_matrix.shape\n    for i in range(n):\n        for j in range(m):\n            if i!=j:\n                loss+=coor_matrix[i,j]**2\n    return loss","441d814a":"class VAE(keras.Model):\n    def __init__(self, encoder, decoder, **kwargs):\n        super(VAE, self).__init__(**kwargs)\n        self.encoder = encoder\n        self.decoder = decoder\n        self.total_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(\n            name=\"reconstruction_loss\"\n        )\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n        \n        \n    def call(self,x):\n        z_mean, z_log_var, z = self.encoder(x)\n        reconstruction = self.decoder(z)\n        return z,reconstruction\n\n    \n    @property\n    def metrics(self):\n        return [\n            self.total_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n        ]\n\n    def train_step(self, data):\n        with tf.GradientTape() as tape:\n            z_mean, z_log_var, z = self.encoder(data)\n            reconstruction = self.decoder(z)\n            reconstruction_loss = tf.reduce_mean(\n            tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n            #coorelation_loss = corr_loss(z)\n            \n            total_loss = reconstruction_loss + kl_loss\n        grads = tape.gradient(total_loss, self.trainable_weights)\n        self.optimizer.apply_gradients(zip(grads, self.trainable_weights))\n        self.total_loss_tracker.update_state(total_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        return {\n            \"loss\": self.total_loss_tracker.result(),\n            \"reconstruction_loss\": self.reconstruction_loss_tracker.result(),\n            \"kl_loss\": self.kl_loss_tracker.result(),\n        }","3ac4b896":"from keras import backend as K\nclass VAE_GAN(keras.Model):    \n\n    def __init__(self, vae, discriminator, opti1=keras.optimizers.Adam(), opti2=keras.optimizers.Adam(), opti3=keras.optimizers.Adam(), **kwargs):\n        super(VAE_GAN, self).__init__(**kwargs)\n        \n        self.encoder = vae.encoder\n        self.decoder = vae.decoder\n        self.discriminator = discriminator\n        self.vae = vae\n        \n        self.vae_loss_tracker = keras.metrics.Mean(name=\"total_loss\")\n        self.reconstruction_loss_tracker = keras.metrics.Mean(name=\"reconstruction_loss\")\n        self.kl_loss_tracker = keras.metrics.Mean(name=\"kl_loss\")\n        self.correlation_loss_tracker = keras.metrics.Mean(name=\"cr_loss\")\n        self.disc_loss_tracker = keras.metrics.Mean(name=\"disc_loss\")\n        self.gen_loss_tracker = keras.metrics.Mean(name=\"gen_loss\")\n        self.disc_loss = keras.losses.BinaryCrossentropy()\n        \n        self.vae_optimizer = opti1\n        self.gen_optimizer = opti2\n        self.disc_optimizer = opti3\n        \n    def call(self,x):\n        z_mean, z_log_var, z = self.encoder(x)\n        reconstruction = self.decoder(z)\n        return z,reconstruction\n\n    @property\n    def metrics(self):\n        return [\n            self.vae_loss_tracker,\n            self.reconstruction_loss_tracker,\n            self.kl_loss_tracker,\n            self.correlation_loss_tracker,\n            self.disc_loss_tracker,\n            self.gen_loss_tracker\n        ]\n\n    def train_step(self, data):        \n        batch_size = K.shape(data)[0]    \n        \n        with tf.GradientTape() as enc_tape, tf.GradientTape() as dec_tape, tf.GradientTape() as disc_tape:\n            \n            z_mean, z_log_var, z = self.encoder(data)\n            \n            reconstruction = self.decoder(z)\n            \n            reconstruction_loss = tf.reduce_mean(\n            tf.reduce_sum(keras.losses.binary_crossentropy(data, reconstruction), axis=(1, 2)))\n            kl_loss = -0.5 * (1 + z_log_var - tf.square(z_mean) - tf.exp(z_log_var))\n            kl_loss = tf.reduce_mean(tf.reduce_sum(kl_loss, axis=1))\n            coorelation_loss = corr_loss(z)\n            \n            \n            # GAN\n            #batch_size = 12\n            recon_vect = z#tf.random.normal((batch_size, latent_dim))\n            contruction = self.decoder(recon_vect)\n            combined_images = tf.concat([data, contruction], axis=0)\n            data_l,recon_l = tf.zeros((batch_size, 1)),tf.ones((batch_size, 1))\n            combined_l = tf.concat([data_l, recon_l], axis=0)\n            tot_predictions = self.discriminator(combined_images)\n            r_prediction = self.discriminator(contruction)\n\n            discr_loss = self.disc_loss(combined_l,tot_predictions)\n            #fake labels : \n            #gen_loss =  self.disc_loss(recon_l,r_prediction)\n            gen_loss = tf.math.maximum(self.disc_loss(data_l,r_prediction) - discr_loss,.0001)\n        \n            #=========\n            vae_loss = reconstruction_loss + kl_loss + gen_loss #+.1*coorelation_loss \n\n               \n        grad_discr = disc_tape.gradient(discr_loss, self.discriminator.trainable_weights)\n        grad_vae = enc_tape.gradient(vae_loss, self.vae.trainable_weights)\n        #grad_gen = dec_tape.gradient(gen_loss, self.decoder.trainable_weights)\n        \n        \n        #self.gen_optimizer.apply_gradients(zip(grad_gen, self.decoder.trainable_weights))\n        self.disc_optimizer.apply_gradients(zip(grad_discr, self.discriminator.trainable_weights))\n        self.vae_optimizer.apply_gradients(zip(grad_vae, self.vae.trainable_weights))\n\n                                           \n        self.vae_loss_tracker.update_state(vae_loss)\n        self.reconstruction_loss_tracker.update_state(reconstruction_loss)\n        self.kl_loss_tracker.update_state(kl_loss)\n        self.correlation_loss_tracker.update_state(coorelation_loss)\n        self.disc_loss_tracker.update_state(discr_loss)\n        self.gen_loss_tracker.update_state(gen_loss)\n        \n        return {\n            \"vae_loss\": self.vae_loss_tracker.result(),\n            \"disc_loss\": self.disc_loss_tracker.result(),\n            \"gen_los\": self.gen_loss_tracker.result(),\n        }","0970adca":"vae = VAE(encoder,decoder)\nmodel = VAE_GAN(vae, discriminator)\nmodel.compile(optimizer=keras.optimizers.Adam())","0fa1cf88":"history = model.fit(ds, epochs=500,verbose=1)","e55e9e0e":"import pandas as pd\nhistory_frame = pd.DataFrame(history.history)\nhistory_frame.loc[:, ['vae_loss']].plot()","b499ea99":"_ ,digit_size = image_size\nscale = 1\ndef plot_latent_space(vae, n=8, figsize=15):\n    # display a n*n 2D manifold of digits\n    figure = np.zeros((digit_size * n, digit_size * n,3))\n    # linearly spaced coordinates corresponding to the 2D plot\n    # of digit classes in the latent space\n    grid_x = np.linspace(-scale, scale, n)\n    grid_y = np.linspace(-scale, scale, n)[::-1]\n\n    for i, yi in enumerate(grid_y):\n        for j, xi in enumerate(grid_x):\n            z_sample = np.array([[2*random.random()-1 for i in range(latent_dim)]])\n            x_decoded = vae.decoder.predict(z_sample)\n            digit = x_decoded[0].reshape(digit_size, digit_size,3)\n            figure[\n                i * digit_size : (i + 1) * digit_size,\n                j * digit_size : (j + 1) * digit_size,\n            ] = digit\n\n    plt.figure(figsize=(figsize, figsize))\n    start_range = digit_size \/\/ 2\n    end_range = n * digit_size + start_range\n    pixel_range = np.arange(start_range, end_range, digit_size)\n    sample_range_x = np.round(grid_x, 1)\n    sample_range_y = np.round(grid_y, 1)\n    plt.xticks(pixel_range, sample_range_x)\n    plt.yticks(pixel_range, sample_range_y)\n    plt.xlabel(\"z[0]\")\n    plt.ylabel(\"z[1]\")\n    plt.imshow(figure)\n    plt.show()\n\n\nplot_latent_space(model)","dedb3fa5":"digit_size, _ = image_size\nn = 4\nfigure = np.zeros((digit_size*3, digit_size * n,3))\nimg = list(ds)[0]\n\nfor i in range(n):\n    _,b_img = model(img)\n    a = list(b_img)[i]\n    figure[\n                 0*digit_size :  digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = a\n    figure[\n                 1*digit_size :  2*digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = list(img)[i]\n    \n    figure[\n                 2*digit_size :  3*digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = (a-list(img)[i])*10\n\n\nfigsize = 5   \nplt.figure(figsize=(figsize*n, figsize*3))\nplt.imshow(figure)\nplt.show()","4e7418d6":"n = 2\nfigure = np.zeros((digit_size*3, digit_size * n,3))\nimg = list(ds_a)[0]\nfor i in range(n):\n    _,b_img = model(img)\n    a = list(b_img)[i]\n    figure[\n                 0*digit_size :  digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = a\n    figure[\n                 1*digit_size :  2*digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = list(img)[i]\n    \n    figure[\n                 2*digit_size :  3*digit_size,\n                i * digit_size :  (i+1)* digit_size,\n            ] = (a-list(img)[i])*10\n\nfigsize = 10  \nplt.figure(figsize=(figsize*n, figsize*3))\nplt.imshow(figure)\nplt.show()","56bbc758":"# **Training**","b535ec82":"# Latent space","3a3970ad":"# On test set","e46d792b":"#  **Results Analyse**","c2a67304":"# On training set","95aaaa60":"# **Data Augmentation**","80618c22":"# **Making my model**"}}