{"cell_type":{"dfc88063":"code","00b1d3af":"code","94486e75":"code","b3d85def":"code","1d9dc98e":"code","c269588d":"code","66b3d3df":"code","3dc1867a":"code","5263d359":"code","c45a0ef3":"code","bebb4aca":"code","b06b9979":"code","7081bab0":"code","dac7e405":"code","b44e4f4a":"code","bd1ced64":"code","79eccff2":"code","5428ab21":"code","02da0682":"code","575c4fc9":"code","9fd4b0b5":"code","fd64b9d1":"code","b7a5f62c":"code","f875082e":"code","611d4a17":"code","a45024c6":"code","136cdd7d":"code","21d6f28a":"code","607a078f":"code","fe7be1a5":"code","0ef67701":"code","89866cdb":"code","9a39e8e3":"code","17f62f50":"code","277b7e1f":"code","76a8e315":"code","6dade6cc":"code","02d8c4c9":"code","7bd78e81":"code","c0a8b7d7":"code","cc132f51":"code","6112f068":"code","3900bede":"code","eb243133":"code","3f912979":"code","634923e0":"code","82819ff5":"code","74276870":"code","49d6fa84":"code","29f5dfa8":"code","4661266b":"code","b16c7eaa":"code","922a03e0":"code","515ea9c8":"code","123f1612":"code","8ca2c320":"markdown","6d6274ca":"markdown","fba32c81":"markdown","d1481f6d":"markdown","ed4fceed":"markdown","21bbe334":"markdown","fb29e2e6":"markdown"},"source":{"dfc88063":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","00b1d3af":"df = pd.read_csv('\/kaggle\/input\/water-potability\/water_potability.csv')\ndf.head()","94486e75":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n","b3d85def":"df.info()","1d9dc98e":"df.describe()","c269588d":"df.isnull().sum()","66b3d3df":"df.shape","3dc1867a":"plt.figure(figsize=(10,8))\nsns.heatmap(df.corr(), annot=True, cmap='coolwarm')","5263d359":"sns.countplot(x=\"Potability\", data=df, saturation=0.7)\nplt.xticks(ticks=[0,1], labels = [\"Not Potable\", \"Potable\"])\nplt.show()","c45a0ef3":"sns.violinplot(x='Potability', y='ph', data=df)","bebb4aca":"sns.pairplot(df, hue='Potability')","b06b9979":"plt.rcParams['figure.figsize'] = [15, 10]\ndf.hist()\nplt.show()","7081bab0":"plt.figure(figsize=(5,5))\nsns.distplot(df['Potability'])","dac7e405":"sns.histplot(x= 'Hardness', data=df)","b44e4f4a":"# Imputing missing values\ndf['ph'] = df['ph'].fillna(df['ph'].mean())\ndf['Sulfate'] = df['Sulfate'].fillna(df['Sulfate'].mean())\ndf['Trihalomethanes'] = df['Trihalomethanes'].fillna(df['Trihalomethanes'].mean())","bd1ced64":"df.isnull().sum()","79eccff2":"X = df.drop('Potability', axis=1)\ny = df['Potability']","5428ab21":"X.shape, y.shape","02da0682":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()","575c4fc9":"X = scaler.fit_transform(X)","9fd4b0b5":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","fd64b9d1":"from sklearn.tree import DecisionTreeClassifier\nmodel_dt = DecisionTreeClassifier(max_depth=5, random_state=42)","b7a5f62c":"model_dt.fit(X_train,y_train)","f875082e":"pred_dt = model_dt.predict(X_test)","611d4a17":"dt_score = accuracy_score(y_test, pred_dt)\nprint(dt_score)","a45024c6":"print(classification_report(y_test,pred_dt))","136cdd7d":"from sklearn.linear_model import LogisticRegression","21d6f28a":"# Creating model object\nmodel_lg = LogisticRegression(max_iter=120,random_state=0, n_jobs=20)","607a078f":"model_lg.fit(X_train, y_train)","fe7be1a5":"# Making Prediction\npred_lg = model_lg.predict(X_test)\n","0ef67701":"# Calculating Accuracy Score\nlg_score = accuracy_score(y_test, pred_lg)\nprint(lg_score)","89866cdb":"print(classification_report(y_test,pred_lg))","9a39e8e3":"from sklearn.ensemble import RandomForestClassifier","17f62f50":"model_rf = RandomForestClassifier(n_estimators=300,min_samples_leaf=0.16, random_state=42)","277b7e1f":"# Training Model\nmodel_rf.fit(X_train, y_train)","76a8e315":"# Making Prediction\npred_rf = model_rf.predict(X_test)","6dade6cc":"# Calculating Accuracy Score\nrf_score = accuracy_score(y_test, pred_rf)\nprint(rf_score)","02d8c4c9":"print(classification_report(y_test,pred_rf))","7bd78e81":"from xgboost import XGBClassifier","c0a8b7d7":"# Creating model object\nmodel_xgb = XGBClassifier(max_depth= 8, n_estimators= 125, random_state= 0,  learning_rate= 0.03, n_jobs=5)","cc132f51":"# Training Model\nmodel_xgb.fit(X_train, y_train)","6112f068":"pred_xgb = model_xgb.predict(X_test)","3900bede":"# Calculating Accuracy Score\nxgb_score = accuracy_score(y_test, pred_xgb)\nprint(xgb_score)","eb243133":"print(classification_report(y_test,pred_xgb))\n","3f912979":"from sklearn.svm import SVC, LinearSVC","634923e0":"model_svm = SVC(kernel='rbf', random_state = 42)\n","82819ff5":"model_svm.fit(X_train, y_train)\n","74276870":"pred_svm = model_svm.predict(X_test)","49d6fa84":"# Calculating Accuracy Score\nsv_score = accuracy_score(y_test, pred_svm)\nprint(sv_score)","29f5dfa8":"from sklearn.neighbors import KNeighborsClassifier\n","4661266b":"model_kn = KNeighborsClassifier(n_neighbors=9, leaf_size=20)\nmodel_kn.fit(X_train, y_train)","b16c7eaa":"# Making Prediction\npred_kn = model_kn.predict(X_test)","922a03e0":"kn_score = accuracy_score(y_test, pred_kn)\nprint(kn_score)","515ea9c8":"print(classification_report(y_test,pred_kn))","123f1612":"models = pd.DataFrame({\n    'Model':['Logistic Regression', 'Decision Tree', 'Random Forest', 'XGBoost', 'KNeighbours', 'SVM'],\n    'Accuracy_score' :[lg_score, dt_score, rf_score, xgb_score, kn_score, sv_score]\n})\nmodels\nsns.barplot(x='Accuracy_score', y='Model', data=models)\n\nmodels.sort_values(by='Accuracy_score', ascending=False)","8ca2c320":"**Using Random Forest Classifier**","6d6274ca":"**Using KNeighbours**","fba32c81":"**Using Decision Tree Classifier**","d1481f6d":"**Using XGBoost Classifier**","ed4fceed":"**Conclusion :- Here SVM classifier has achieved highest accuracy.**","21bbe334":"**Using Logistic Regression Model**","fb29e2e6":"**Using SVM**"}}