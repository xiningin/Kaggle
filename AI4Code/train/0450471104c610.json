{"cell_type":{"501c8b6d":"code","48b4a17d":"code","678841bc":"code","9f7cdd05":"code","62130c77":"code","e7a7c416":"code","dd13aba4":"code","893a8fd6":"code","29b424db":"code","bb688f94":"code","e50e0689":"code","f35b340b":"code","bce72f0e":"code","b1adebd8":"code","4ae73154":"code","93892b5c":"code","ebdbac09":"code","1dd2f21c":"code","6cd2d34d":"code","cd67e585":"code","de0b4611":"code","3d88c14b":"code","6d7296b4":"code","c06849cb":"code","4d22a575":"code","5157fb3e":"code","332618b7":"markdown","fcd2bdcc":"markdown","80a8c40f":"markdown","92cfbc80":"markdown"},"source":{"501c8b6d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","48b4a17d":"print(os.listdir(\"..\/input\/handwritten-math-symbols-dataset\/handwrittenmathsymbols\/data\/extracted_images\"))","678841bc":"!pip install split-folders    # Library to split Train and valid Image sets in ImageNet style","9f7cdd05":"import os\nimport numpy as np\nfrom tqdm import tqdm\nfrom fastai import *\nimport torch\nfrom fastai.vision import *\n%matplotlib inline\nfrom fastai.callbacks import *\nimport cv2\nimport pandas as pd\nimport splitfolders","62130c77":"image_load_size = 64\nbs = 24","e7a7c416":" def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True    \n\nSEED = 999\nseed_everything(SEED)","dd13aba4":"splitfolders.ratio('..\/input\/handwritten-math-symbols-dataset\/handwrittenmathsymbols\/data\/extracted_images', output=\"..\/final_output_images\", seed=SEED, ratio=(.8, .2)) # default va","893a8fd6":"tfms = get_transforms(do_flip=True, flip_vert=False, max_lighting=0.1, max_zoom=1.05,\n                      max_warp=0.,\n                      xtra_tfms=[rand_crop(), rand_zoom(1, 1.5),\n                                 symmetric_warp(magnitude=(-0.2, 0.2))])","29b424db":"data = (ImageList.from_folder(path='..\/final_output_images')\n        .split_by_folder(train='train',valid='val')\n        .label_from_folder()\n        .transform(tfms,size = image_load_size,resize_method=ResizeMethod.SQUISH)\n        .databunch(path='.',bs=bs)    \n        .normalize(imagenet_stats)\n)","bb688f94":" data.show_batch(3, figsize=(6,6), hide_axis=False)","e50e0689":"len(data.classes)","f35b340b":" data.classes","bce72f0e":"class FocalLoss(nn.Module):\n    def __init__(self, alpha=1., gamma=2.):\n        super().__init__()\n        self.alpha = alpha\n        self.gamma = gamma\n\n    def forward(self, inputs, targets, **kwargs):\n        CE_loss = nn.CrossEntropyLoss(reduction='none')(inputs, targets)\n        pt = torch.exp(-CE_loss)\n        F_loss = self.alpha * ((1-pt)**self.gamma) * CE_loss\n        return F_loss.mean()","b1adebd8":"model = cnn_learner(data,models.densenet161, metrics = [accuracy,error_rate],callback_fns=[partial(SaveModelCallback, monitor='accuracy', name='best_model')])\nmodel.loss_func = FocalLoss()\nmodel.summary()","4ae73154":"model.lr_find()\nmodel.recorder.plot(suggestion = True)","93892b5c":"lr = 2e-3\nmodel.fit_one_cycle(5,slice(lr))","ebdbac09":"model.unfreeze()\nmodel.lr_find()\nmodel.recorder.plot(suggestion = True)","1dd2f21c":" model.fit_one_cycle(5,slice(1e-6,lr\/10))","6cd2d34d":"model.recorder.plot_metrics()","cd67e585":"model.load('best_model')","de0b4611":"valid_loss_save_model,accuracy_save_model, error_rate_save_model = model.validate(model.data.valid_dl)\nprint('valid_loss:', valid_loss_save_model, 'accuracy:', float(accuracy_save_model),'error_rate:',float(error_rate_save_model))","3d88c14b":"interpreter = ClassificationInterpretation.from_learner(model)\ninterpreter.plot_confusion_matrix(figsize = (20,20))","6d7296b4":"interpreter.most_confused(min_val=50)","c06849cb":"print(os.listdir('..\/final_output_images\/val\/A'))","4d22a575":"open_image('..\/final_output_images\/val\/A\/exp3159.jpg')","5157fb3e":"pred = model.predict(open_image('..\/final_output_images\/val\/A\/exp3159.jpg'))\nprint(pred[0])","332618b7":"Note - Here I have uploded the Zip Version of DataSet as private Dataset","fcd2bdcc":"Kernal for Preprocessing INKML to PNG Image to available [here](https:\/\/www.kaggle.com\/kalikichandu\/preprossing-inkml-to-png-files)","80a8c40f":"Comment below incase if any clarification is needed.","92cfbc80":"**PLEASE UPVOTE IF FOUND INTERESTING**"}}