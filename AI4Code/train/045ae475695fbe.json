{"cell_type":{"d5ea4054":"code","89b05b0a":"code","9ec6852b":"code","dabf79d2":"code","709a4b2f":"code","6fcac6d4":"code","b4cbd25c":"code","4aad18cc":"code","41ab5053":"code","e387b237":"code","072baf7f":"code","5434e890":"code","2487fb64":"code","c18dcf59":"code","0e1d067d":"code","29094c12":"code","cd7c579b":"code","255a61aa":"code","1f762bfd":"code","dc5e3767":"code","224cc8b5":"code","60d9ba8a":"code","9f175a00":"code","cd8f9f1c":"code","87cda7fa":"code","a9032015":"code","15a68d77":"code","86f68d2f":"code","2e18e1ae":"code","f579a5ab":"code","ff7d9b92":"code","6911e953":"code","e59abf4d":"code","f096cd52":"code","01987bee":"code","98413017":"markdown","fd04436d":"markdown","326a928a":"markdown","e0f5d5dd":"markdown","457d5c97":"markdown","11535d25":"markdown","56841e68":"markdown"},"source":{"d5ea4054":"import pandas as pd\n\nimport plotly\nfrom datetime import datetime\n\nfrom tensorflow.keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.callbacks import EarlyStopping\n\nimport numpy as np\nfrom sklearn.metrics import mean_squared_error,mean_absolute_error\nfrom sklearn.metrics import r2_score\nimport matplotlib.pyplot as plt\n\nfrom tensorflow import keras\nfrom tensorflow.keras import Input, datasets, layers, models\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import ReLU,add, LeakyReLU\n\nfrom keras.layers import Conv2D, Conv2DTranspose, UpSampling2D, MaxPool2D, Flatten, BatchNormalization\nfrom keras.layers import Dropout, Add, Concatenate\nfrom tensorflow.keras.models import Model\n\nfrom tensorflow.keras.optimizers import SGD, Adam, RMSprop, Adadelta\nfrom keras.layers import MaxPooling2D, UpSampling2D, BatchNormalization, Activation\n\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.callbacks import ModelCheckpoint, Callback, LearningRateScheduler\nfrom tensorflow.keras import layers\n","89b05b0a":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9ec6852b":"def preprocess_image(array):\n\n    print(len(array))\n    array = array.astype(\"float32\") \/ 255.0\n    array = np.reshape(array, (len(array), 32, 32, 3))\n    return array\n\n\ndef adding_noise(array):\n\n    noise_factor = 0.3\n    noisy_array = array + noise_factor * np.random.normal(\n        loc=0.0, scale=1, size=array.shape\n    )\n\n    return np.clip(noisy_array, 0.0, 1.0)\n\n\ndef display_images(array1, array2):\n    n = 10\n\n    indices = np.random.randint(len(array1), size=n)\n    images1 = array1[indices, :]\n    images2 = array2[indices, :]\n\n    plt.figure(figsize=(20, 4))\n    for i, (image1, image2) in enumerate(zip(images1, images2)):\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(image1)\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(image2)\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n    plt.show()\n","dabf79d2":"#  parameters\nimg_rows, img_cols, img_ch = 32, 32, 3\n(x_train, train_labels), (x_test, test_labels) = datasets.cifar10.load_data()","709a4b2f":"print('Train: X=%s, y=%s' % (x_train.shape, train_labels.shape))\nprint('Test: X=%s, y=%s' % (x_test.shape, test_labels.shape))\n\nplt.figure(figsize=(10,10))\nfor index in range(50):\n    plt.subplot(10,10,index+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[index])\nplt.show()","6fcac6d4":"#(train_data, _), (test_data, _) = datasets.cifar10.load_data()\n\ntrain_data = preprocess_image(x_train)\ntest_data = preprocess_image(x_test)\n\n# Create a copy of the data with added noise\nnoisy_train_data = adding_noise(train_data)\nnoisy_test_data = adding_noise(test_data)\n\n# Display the train data and a version of it with added noise\ntrain_data.shape\ntest_data.shape\nnoisy_train_data.shape\nnoisy_test_data.shape","b4cbd25c":"display_images(x_train, noisy_train_data)\n","4aad18cc":"input_img = Input((32,32,3))\n\n# Encoder\nencoder = Conv2D(32, 3,activation='relu', padding=\"same\")(input_img)\nencoder = BatchNormalization()(encoder)\nencoder= MaxPool2D(2)(encoder)\nencoder = Conv2D(64, 3,activation='relu', padding=\"same\")(encoder)\nencoder = BatchNormalization()(encoder)\nencoder = MaxPool2D(2)(encoder)\n\n#Middle\nmid = Conv2D(128, 3,activation='relu', padding=\"same\")(encoder)\nmid = BatchNormalization()(mid)\n\n# Decoder\nup1 = UpSampling2D((2,2))(mid)\ndecoder = Conv2D(64, 3,activation='relu', padding=\"same\")(up1)\ndecoder = BatchNormalization()(decoder)\nup2 = UpSampling2D((2,2))(decoder)\ndecoder = Conv2D(32, 3,activation='relu', padding=\"same\")(up2)\ndecoder= BatchNormalization()(decoder)\n\n# output\ndecoder = Conv2D(3, 1)(decoder)\noutput = Activation(\"sigmoid\")(decoder)\n\nmodel1 = Model(input_img, output)\nmodel1.summary()","41ab5053":"model1.compile(Adam(learning_rate=0.0001), metrics=[\"mae\",\"accuracy\"],loss='binary_crossentropy')\n\nes_cb = EarlyStopping(monitor='val_loss', patience=2)\nhistory = model1.fit(noisy_train_data, train_data,\n                    batch_size=20,\n                    epochs=500,\n                    verbose=1,\n                    validation_data=(noisy_test_data, test_data),\n                    callbacks=[es_cb],\n                    shuffle=True)","e387b237":"score = model1.evaluate(noisy_test_data, test_data)\nprint(score)\nprediction_data = model1.predict(noisy_test_data)\n","072baf7f":"display_images(noisy_test_data, prediction_data)\n","5434e890":"index = 6\nplt.subplot(1,3,1)\nplt.imshow(test_data[index])\nplt.title('original')\nplt.subplot(1,3,2)\nplt.imshow(noisy_test_data[index])\nplt.title('noisy')\nplt.subplot(1,3,3)\nplt.imshow(prediction_data[index])\nplt.title('denoised')\nplt.show()\n","2487fb64":"f = plt.figure(figsize=(5,5))\nf.add_subplot()\n\nplt.plot(history.epoch, history.history['loss'], label = \"loss\") \nplt.plot(history.epoch, history.history['val_loss'], label = \"val_loss\")\n\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"Loss\",fontsize=10)\nplt.legend()\nplt.show()\n","c18dcf59":"f = plt.figure(figsize=(5,5))\nf.add_subplot()\n\nplt.plot(history.epoch, history.history['mae'], label = \"mae\") \nplt.plot(history.epoch, history.history['val_mae'], label = \"val_mae\") \n\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"MAE\",fontsize=10)\nplt.legend()\nplt.show()\n","0e1d067d":"input_img = Input(shape=(32, 32, 3))\n# Encoder\nx = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.5)(x)\nx = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.5)(x)\nx = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\n\n# Decoder\nx = Conv2DTranspose(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\nx = Conv2DTranspose(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = Dropout(0.5)(x)\n\nx = Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = LeakyReLU()(x)\n\nx = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n\nmodel2 = Model(input_img, x)\nmodel2.summary()\n","29094c12":"\nepochs = 20\nbatch_size = 500\nes = EarlyStopping(monitor='val_loss', patience=2)\n\nmodel2.compile(optimizer=Adam(learning_rate=0.0001),metrics=['mae', 'accuracy'], loss='binary_crossentropy')\n\nhistory2 = model2.fit(noisy_train_data, train_data,\n                    batch_size=20,\n                    epochs=500, \n                    verbose=1,\n                    validation_data=(noisy_test_data, test_data),\n                    callbacks=[es],\n                    shuffle=True)\n","cd7c579b":"score = model2.evaluate(noisy_test_data, test_data)\nprint(score)\nprediction_data = model2.predict(noisy_test_data)\n","255a61aa":"display_images(noisy_test_data, prediction_data)\n","1f762bfd":"index = 6\nplt.subplot(1,3,1)\nplt.imshow(test_data[index])\nplt.title('original')\nplt.subplot(1,3,2)\nplt.imshow(noisy_test_data[index])\nplt.title('noisy')\nplt.subplot(1,3,3)\nplt.imshow(prediction_data[index])\nplt.title('denoised')\nplt.show()\n","dc5e3767":"f = plt.figure(figsize=(5,5))\nf.add_subplot()\n\nplt.plot(history2.epoch, history2.history['loss'], label = \"loss\") \nplt.plot(history2.epoch, history2.history['val_loss'], label = \"val_loss\")\n\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"Loss\",fontsize=10)\nplt.legend()\nplt.show()\n","224cc8b5":"f = plt.figure(figsize=(5,5))\nf.add_subplot()\n\nplt.plot(history2.epoch, history2.history['mae'], label = \"mae\") \nplt.plot(history2.epoch, history2.history['val_mae'], label = \"val_mae\") \n\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"MAE\",fontsize=10)\nplt.legend()\nplt.show()\n","60d9ba8a":"# Encoder\ninput_img = Input(shape=(32, 32, 3))\n\nx = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(input_img)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\nx = Dropout(0.3)(x)\nx = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D((2, 2))(x)\n\n# Decoder\nx = Conv2DTranspose(128, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\nx = Conv2DTranspose(64, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = Dropout(0.3)(x)\n\nx = Conv2DTranspose(32, (3, 3), strides=2, activation=\"relu\", padding=\"same\")(x)\nx = BatchNormalization()(x)\nx = LeakyReLU()(x)\n\nx = Conv2D(3, (3, 3), activation=\"sigmoid\", padding=\"same\")(x)\n\ndecoded = Conv2DTranspose(3, 3, activation='sigmoid', padding='same')(x)\n\nmodel4 = Model(input_img, decoded)\nmodel4.summary()\n","9f175a00":"model4.compile(optimizer=Adam(learning_rate=0.0001),metrics=['mae','accuracy'], loss=\"binary_crossentropy\")\n\nes = EarlyStopping(monitor='val_loss', patience=2)\nhistory4 = model4.fit(noisy_train_data, train_data,\n                    batch_size=20,\n                    epochs=500,\n                    verbose=1,\n                    validation_data=(noisy_test_data, test_data),\n                    callbacks=[es],\n                    shuffle=True)","cd8f9f1c":"score = model4.evaluate(noisy_test_data, test_data)\nprint(score)\n\nprediction_data = model4.predict(noisy_test_data)","87cda7fa":"display_images(noisy_test_data, prediction_data)\n","a9032015":"index = 6\nplt.subplot(1,3,1)\nplt.imshow(test_data[index])\nplt.title('original')\nplt.subplot(1,3,2)\nplt.imshow(noisy_test_data[index])\nplt.title('noisy')\nplt.subplot(1,3,3)\nplt.imshow(prediction_data[index])\nplt.title('denoised')\nplt.show()","15a68d77":"\nf = plt.figure(figsize=(5,5))\nf.add_subplot()\n\nplt.plot(history4.epoch, history4.history['loss'], label = \"loss\") \nplt.plot(history4.epoch, history4.history['val_loss'], label = \"val_loss\")\n\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"Loss\",fontsize=10)\nplt.legend()\nplt.show()\n","86f68d2f":"f = plt.figure(figsize=(5,5))\nf.add_subplot()\n\nplt.plot(history4.epoch, history4.history['mae'], label = \"mae\") \nplt.plot(history4.epoch, history4.history['val_mae'], label = \"val_mae\") \n\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"MAE\",fontsize=10)\nplt.legend()\nplt.show()\n","2e18e1ae":"# Encoder\ny = Conv2D(32, 3, activation='relu', padding='same')(input_img)\ny = BatchNormalization()(y) #standarized the inputs\ny = MaxPool2D()(y)\ny = Dropout(0.5)(y)\n\ny = Conv2D(64, 3, activation='relu', padding='same')(y)\ny = BatchNormalization()(y)\n\nskip_connection = Conv2D(64, 3, padding='same')(y) \ny = LeakyReLU()(skip_connection)  \ny = BatchNormalization()(y)\ny = MaxPool2D()(y)\ny = Dropout(0.5)(y)\n\ny = Conv2D(128, 3, activation='relu', padding='same')(y)\ny = BatchNormalization()(y)\nencoded = MaxPool2D()(y)\n\n# Decoder\ny = Conv2DTranspose(128, 3,activation='relu',strides=(2,2), padding='same')(encoded)\ny = BatchNormalization()(y)\ny = Conv2DTranspose(64, 3,activation='relu',strides=(2,2), padding='same')(y)\ny = BatchNormalization()(y)\ny = Dropout(0.5)(y)\ny = add([y,skip_connection]) # adding skip connection\ny = LeakyReLU()(y)\ny = BatchNormalization()(y)\ny = Conv2DTranspose(32, 3, activation='relu',strides=(2,2), padding='same')(y)\ny = BatchNormalization()(y) #normalize y into 0 to 1\ny = Dropout(0.5)(y)\n\noutput = Conv2DTranspose(3, 3, activation='sigmoid', padding='same')(x)\n\nmodel5 = Model(input_img, output)\nmodel5.summary()\n","f579a5ab":"model5.compile(optimizer=Adam(learning_rate=0.0001),metrics=['mae','accuracy'], loss=\"binary_crossentropy\")\n\nes = EarlyStopping(monitor='val_loss', patience=2)\nhistory5 = model5.fit(noisy_train_data, train_data,\n                    batch_size=20,\n                    epochs=500,\n                    verbose=1,\n                    validation_data=(noisy_test_data, test_data),\n                    callbacks=[es],\n                    shuffle=True)","ff7d9b92":"score = model5.evaluate(noisy_test_data, test_data)\nprint(score)\n\nprediction_data = model5.predict(noisy_test_data)","6911e953":"display_images(noisy_test_data, prediction_data)","e59abf4d":"index = 6\nplt.subplot(1,3,1)\nplt.imshow(test_data[index])\nplt.title('original')\nplt.subplot(1,3,2)\nplt.imshow(noisy_test_data[index])\nplt.title('noisy')\nplt.subplot(1,3,3)\nplt.imshow(prediction_data[index])\nplt.title('denoised')\nplt.show()","f096cd52":"\nf = plt.figure(figsize=(5,5))\nf.add_subplot()\n\nplt.plot(history5.epoch, history5.history['loss'], label = \"loss\") \nplt.plot(history5.epoch, history5.history['val_loss'], label = \"val_loss\")\n\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"Loss\",fontsize=10)\nplt.legend()\nplt.show()\n","01987bee":"f = plt.figure(figsize=(5,5))\nf.add_subplot()\n\nplt.plot(history5.epoch, history5.history['mae'], label = \"mae\") \nplt.plot(history5.epoch, history5.history['val_mae'], label = \"val_mae\") \n\nplt.xlabel(\"Epochs\",fontsize=10)\nplt.ylabel(\"MAE\",fontsize=10)\nplt.legend()\nplt.show()\n","98413017":"## Model 2","fd04436d":"## Model 3","326a928a":"We created some functions which do preprocessing task and adding noise. The goal of these functions is to rescale all images at scale. Then add noise and then display clean and noisy images side by side we create 3 separate function for these task.\nAfter all the preprocessing we created 4 models by experiemnting vaired architecture and develop autoencode models. In first model we create encoder which contains two Convolutional d layers of 32 and 64 units with BatchNormalizer and MaxPooling layers as well. We follow architecture in which there is a encoder, then a middle layer and then decoder. We used Upsampling in decoder part with Adam as optimizer with a learning_rate paramenter. UPsampling will increase the dimension and at the end of decoder will make sure that we will get the same shape as it was given as input.\nFor the rest of the model we use Conv2dTranspose in the decoder which is the inverse of Conv2d. It do two things in layer and i.e upsampling and convolution both can be performed using this.\nWe also tried skip connection in Model 4 as they are useful in when working with autoencoders and it helps in saving useful information which we typicallly lost when performing encoder and decoder.\n\n-> Noise is removed but not completely, still some images classes cant classify properly and hard to interpret. These model can be improved by following the autoencoder architecture with different techniques like Upsampling and Convolution transpose and experiementing with hyperparameter. Unet autoencoder is also a good addition in autoenoder and it can help in reconstruction of images. We trited but couldn't implement perfectly. \n\nSo, in a nutshell at model 1 encoder with Conv2d, Batchnormalizer, Maxpooling and at decoder we use UpSampling2D with Conv2d, Batchnormalizer. At model 2 we use Conv2DTranspose and Dropout layers with LeakyRelu. At model 3 we use same architecture which was in model 2 but we increate number of units in both encoder & decoder. Then at model 4 added skip connection between layers and used it with Conv2d, Batchnormalizer, Maxpooling, Conv2DTranspose and Dropout layers.\n \n \nAll models performed well. We have tried both upsampling and Conv2DTranspose in this task. Model 4 images are much more visible as compare to other models. We used skip_connection and Conv2DTranspose layer in this technique with other layers like BatchNormalizer, Maxpooling, dropout. Using all these layers we implemented an autoencoder. Used Adam as optimizer with learning_rate parameter and analyze performance based on MAE and accuracy. At the this model give an accuracy of 72% with MAE of 0.057 and Loss of 0.56.","e0f5d5dd":"# Model Construction & Experimentation","457d5c97":"# Data Preprocessing","11535d25":"## Model 5","56841e68":"## Model 1"}}