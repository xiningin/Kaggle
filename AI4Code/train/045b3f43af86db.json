{"cell_type":{"cdab4096":"code","55383801":"code","8f54d2d1":"code","b2e7e88d":"code","07dbb981":"code","5ec2be53":"code","1d8eb9b7":"code","85bfb694":"code","fe8fe541":"code","46ce6df3":"markdown","8d1ac5f1":"markdown","db71348e":"markdown","e3b307ed":"markdown","eda17826":"markdown","e2371fee":"markdown"},"source":{"cdab4096":"# Import bibliotek\nimport pandas as pd\nimport numpy as np\nfrom sklearn import metrics\nfrom sklearn import linear_model\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.model_selection import GridSearchCV, train_test_split\nfrom sklearn.datasets import load_boston\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import Ridge\nimport matplotlib.pyplot as plt\nfrom sklearn.linear_model import RidgeCV\nfrom sklearn.linear_model import Lasso\nfrom sklearn.linear_model import LassoCV","55383801":"# Import danych\nfeature_num = 20\nboston = load_boston()\nX = boston.data[:, :feature_num]\ny = boston.target\nfeatures = boston.feature_names[:feature_num]\npd.DataFrame(X, columns = features).head()","8f54d2d1":"# Podzia\u0142 danych na treningowe i testowe\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state = 1)\nstd = StandardScaler()\nX_train_std = std.fit_transform(X_train)\nX_test_std = std.transform(X_test)","b2e7e88d":"def test(models,  iterations = 1000):\n    results = {}\n    for i in models:\n        r2_train = []\n        r2_test = []\n        for j in range(iterations):\n            X_train, X_test, y_train, y_test = train_test_split(X, \n                                                                y, \n                                                                test_size= 0.2)\n            r2_test.append(metrics.r2_score(y_test,\n                                            models[i].fit(X_train, \n                                                         y_train).predict(X_test)))\n            r2_train.append(metrics.r2_score(y_train, \n                                             models[i].fit(X_train, \n                                                          y_train).predict(X_train)))\n        results[i] = [np.mean(r2_train), np.mean(r2_test)]\n    return pd.DataFrame(results)","07dbb981":"alphas = 10 ** np.arange(1, 5)\nridge_weight = []\nfor alpha in alphas:    \n    ridge = Ridge(alpha = alpha, fit_intercept = True)\n    ridge.fit(X_train_std, y_train)\n    ridge_weight.append(ridge.coef_)\n    \ndef weight_versus_alpha_plot(weight, alphas, features):\n    fig = plt.figure(figsize = (8, 6))\n    \n    weight = np.array(weight)\n    for col in range(weight.shape[1]):\n        plt.plot(alphas, weight[:, col], label = features[col])\n\n    plt.axhline(0, color = 'black', linestyle = '--', linewidth = 3)\n    \n    plt.legend(bbox_to_anchor = (1.3, 0.9))\n    plt.title('Wsp\u00f3\u0142czynnik wagi wraz ze wzrostem alfa')\n    plt.ylabel('Wsp\u00f3\u0142czynnik wagi')\n    plt.xlabel('Alpha')\n    return fig\n\nplt.rcParams['figure.figsize'] = 8, 6 \nplt.rcParams['font.size'] = 12\n\n\nridge_fig = weight_versus_alpha_plot(ridge_weight, alphas, features)","5ec2be53":"alpha_range = 10. ** np.arange(-2, 3)\nridge_cv = RidgeCV(alphas = alpha_range, fit_intercept = True)\nridge_cv.fit(X_train_std, y_train)\n\ny_pred = ridge_cv.predict(X_test_std)\nprint('coefficients:\\n', ridge_cv.coef_)\nprint('best alpha:\\n' , ridge_cv.alpha_)\nprint('\\nRSS:', np.sum((y_test - y_pred) ** 2))\nprint(metrics.r2_score(y_test, y_pred))","1d8eb9b7":"alphas = [0.01, 0.1, 1, 5, 8]\n\nlasso_weight = []\nfor alpha in alphas:    \n    lasso = Lasso(alpha = alpha, fit_intercept = True)\n    lasso.fit(X_train_std, y_train)\n    lasso_weight.append(lasso.coef_)\n\nlasso_fig = weight_versus_alpha_plot(lasso_weight, alphas, features)","85bfb694":"from sklearn.metrics import r2_score\n\nlasso_cv = LassoCV(n_alphas = 10, fit_intercept = True)\nlasso_cv.fit(X_train_std, y_train)\n\ny_pred = lasso_cv.predict(X_test_std)\nprint('coefficients:\\n', lasso_cv.coef_)\nprint('best alpha:\\n', lasso_cv.alpha_)\nprint('\\nRSS:', np.sum(( y_test - y_pred ) ** 2))\nprint(r2_score(y_test, y_pred))","fe8fe541":"ridge_reg = Ridge(alpha=ridge_cv.alpha_)\nridge_reg.fit(X_train, y_train)\nlasso_reg = Lasso(alpha=lasso_cv.alpha_)\nlasso_reg.fit(X_train, y_train)\n\n\nprint('Regresjia ridge: R^2 wynik na danych treningowych', ridge_reg.score(X_train, y_train)*100)\nprint('Regresjia ridge: R^2 wynik na danych testowych', ridge_reg.score(X_test, y_test)*100, '\\n')\nprint('Regresjia Lasso: R^2 wynik na danych treningowych', lasso_reg.score(X_train, y_train)*100)\nprint('Regresjia Lasso: R^2 wynik na danych testowych', lasso_reg.score(X_test, y_test)*100)","46ce6df3":"### Import","8d1ac5f1":"### Lasso","db71348e":"### Wynik","e3b307ed":"### Przygotowanie danych","eda17826":"### Regresja Grzbietowa","e2371fee":"Columns:\n\nCRIM: Per capita crime rate by town\n\nZN: Proportion of residential land zoned for lots over 25,000 sq. ft\n\nINDUS: Proportion of non-retail business acres per town\n\nCHAS : Charles River dummy variable (1 if tract bounds river; 0 otherwise)\n\nNOX: Nitric oxide concentration (parts per 10 million)\n\nRM: Average number of rooms per dwelling\n\nAGE: Proportion of owner-occupied units built prior to 1940\n\nDIS: Weighted distances to five Boston employment centers\n\nRAD: Index of accessibility to radial highways\n\nPTRATIO: Pupil-teacher ratio by town\n\nB: 1000(Bk \u2014 0.63)\u00b2, where Bk is the proportion of [people of African American descent] by town\n\nLSTAT: Percentage of lower status of the population\n\nMEDV: Median value of owner-occupied homes in $1000s"}}