{"cell_type":{"08d5b9e3":"code","8212b890":"code","d479550b":"code","eff6cf88":"code","e39e84a0":"code","b0ed98b6":"code","18374a54":"code","b535a0e4":"code","1d58bdda":"code","891a7fe3":"code","b9422ceb":"code","54341629":"code","a6020e45":"code","4a22fe02":"code","46376bee":"code","c02b9a52":"code","9bb6941d":"code","d8d77267":"code","0d895001":"code","6efec6d4":"code","c625c4a3":"code","68e85135":"code","5b7224e0":"code","2585c423":"code","4c7626de":"code","46a75763":"code","48a23212":"code","1b9a7b71":"code","856f9486":"markdown","a8e3cfe0":"markdown","cf399960":"markdown","38363bf4":"markdown","29520b8d":"markdown","7ac2b9da":"markdown","f910833a":"markdown","72a07540":"markdown"},"source":{"08d5b9e3":"%reload_ext autoreload\n%autoreload 2\n%matplotlib inline","8212b890":"from fastai import *\nfrom fastai.vision import *\nimport pandas as pd\nimport matplotlib.pyplot as plt","d479550b":"if not os.path.exists('models\/'):\n        os.makedirs('models')\n\n!cp '..\/input\/aptosresnet152\/resnet50-3.pth' 'models\/resnet50.pth'\n!cp '..\/input\/aptosresnet152\/stage-2.pth' 'models\/resnet152.pth'","eff6cf88":"import os\nos.listdir('.')","e39e84a0":"def seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nSEED = 999\nseed_everything(SEED)","b0ed98b6":"base_image_dir = os.path.join('..', 'input\/aptos2019-blindness-detection\/')\ntrain_dir = os.path.join(base_image_dir,'train_images\/')\ndf = pd.read_csv(os.path.join(base_image_dir, 'train.csv'))\ndf['path'] = df['id_code'].map(lambda x: os.path.join(train_dir,'{}.png'.format(x)))\ndf = df.drop(columns=['id_code'])\ndf = df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ndf.head(10)","18374a54":"len_df = len(df)\nprint(f\"There are {len_df} images\")","b535a0e4":"folds = pd.read_csv('..\/input\/atposfolds\/folds.csv')","1d58bdda":"fold_num = 1\nval_idxs = folds[folds['folds'] == fold_num].index.values","891a7fe3":"bs = 64 #smaller batch size is better for training, but may take longer\nsz=256","b9422ceb":"tfms = get_transforms(do_flip=True, flip_vert=True, max_rotate=360, max_warp=0,\n                      max_zoom=1.1, max_lighting=0.1, p_lighting=0.5)\n\nsrc = (ImageList.from_df(df=df,path='.\/',cols='path')\n        .split_by_idx(val_idxs)\n        .label_from_df(cols='diagnosis', label_cls=FloatList)\n      )\n\ndata= (src.transform(tfms,size=sz,resize_method=ResizeMethod.SQUISH,padding_mode='zeros')\n       .databunch(bs=bs,num_workers=4)\n       .normalize(imagenet_stats) #Normalize     \n       )","54341629":"from sklearn.metrics import cohen_kappa_score\ndef quadratic_kappa(y_hat, y):\n    return torch.tensor(cohen_kappa_score(torch.round(y_hat), y, weights='quadratic'),device='cuda:0')","a6020e45":"learn = cnn_learner(data, base_arch=models.resnet50, metrics = [quadratic_kappa], pretrained=False)\nlearn.load('resnet50')","4a22fe02":"learn_2 = cnn_learner(data, base_arch=models.resnet152, metrics = [quadratic_kappa], pretrained=False)\nlearn_2.load('resnet152')","46376bee":"interp = ClassificationInterpretation.from_learner(learn)\n\nlosses,idxs = interp.top_losses()\n\nlen(data.valid_ds)==len(losses)==len(idxs)","c02b9a52":"import numpy as np\nimport pandas as pd\nimport os\nimport scipy as sp\nfrom functools import partial\nfrom sklearn import metrics\nfrom collections import Counter\nimport json","9bb6941d":"class OptimizedRounder(object):\n    def __init__(self):\n        self.coef_ = 0\n\n    def _kappa_loss(self, coef, X, y):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n\n        ll = metrics.cohen_kappa_score(y, X_p, weights='quadratic')\n        return -ll\n\n    def fit(self, X, y):\n        loss_partial = partial(self._kappa_loss, X=X, y=y)\n        initial_coef = [0.5, 1.5, 2.5, 3.5]\n        self.coef_ = sp.optimize.minimize(loss_partial, initial_coef, method='nelder-mead')\n        print(-loss_partial(self.coef_['x']))\n\n    def predict(self, X, coef):\n        X_p = np.copy(X)\n        for i, pred in enumerate(X_p):\n            if pred < coef[0]:\n                X_p[i] = 0\n            elif pred >= coef[0] and pred < coef[1]:\n                X_p[i] = 1\n            elif pred >= coef[1] and pred < coef[2]:\n                X_p[i] = 2\n            elif pred >= coef[2] and pred < coef[3]:\n                X_p[i] = 3\n            else:\n                X_p[i] = 4\n        return X_p\n\n    def coefficients(self):\n        return self.coef_['x']","d8d77267":"optR = OptimizedRounder()","0d895001":"# coefficients = optR.coefficients()\n# coefficients = [0.535809, 1.569422, 2.61038,  3.090442]\ncoefficients = [0.499944, 1.577832, 2.627495, 3.263393]\ncoefficients_2 = [0.54458,  1.570697, 2.664879, 2.892028]\n\nprint(coefficients)\nprint(coefficients_2)","6efec6d4":"sample_df = pd.read_csv('..\/input\/aptos2019-blindness-detection\/sample_submission.csv')\nsample_df.head()","c625c4a3":"learn.data.add_test(ImageList.from_df(sample_df,'..\/input\/aptos2019-blindness-detection',folder='test_images',suffix='.png'))","68e85135":"preds,y = learn.get_preds(ds_type=DatasetType.Test)","5b7224e0":"learn_2.data.add_test(ImageList.from_df(sample_df,'..\/input\/aptos2019-blindness-detection',folder='test_images',suffix='.png'))","2585c423":"preds_2, y_2 = learn_2.get_preds(ds_type=DatasetType.Test)","4c7626de":"preds_avg = (preds * 0.6 + preds_2 * 0.4)\ntest_predictions = optR.predict(preds_avg, coefficients)","46a75763":"sample_df.diagnosis = test_predictions.astype(int)\nsample_df.head()","48a23212":"sample_df.to_csv('submission.csv',index=False)","1b9a7b71":"sample_df.diagnosis.value_counts()","856f9486":"## Submission\nLet's now create a submission","a8e3cfe0":"**BEFORE YOU FORK, PLEASE SUPPORT AND UPVOTE**","cf399960":"The images are actually quite big. We will resize to a much smaller size.","38363bf4":"### Ensembling","29520b8d":"Original Kernel taken from https:\/\/www.kaggle.com\/tanlikesmath\/intro-aptos-diabetic-retinopathy-eda-starter\n\nChanges done:\n\n1. Change image size to 256\n2. Fix TTA\n3. Add stratified KFold splitting","7ac2b9da":"Inference","f910833a":"### ResNet50","72a07540":"### ResNet152"}}