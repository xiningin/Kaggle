{"cell_type":{"506ae2de":"code","ae3fa391":"code","89674384":"code","b24d5aa7":"code","3f4addec":"code","1e566945":"code","1f7b84a6":"code","595fe66c":"code","46e3e0eb":"code","48a887ab":"code","7527ef43":"code","b1128862":"code","92856946":"code","a82be0c2":"code","9a893ffb":"code","915dcb1e":"code","6387a252":"code","68f47324":"code","924836a1":"code","41e8f353":"markdown","14b47d13":"markdown","d94b4282":"markdown","34f375d4":"markdown","745ca5eb":"markdown"},"source":{"506ae2de":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ae3fa391":"import torch\nimport torch.optim as optim\nimport numpy as np\nimport pandas as pd\nimport torch.nn.functional as F\nimport random\nfrom sklearn import preprocessing\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\n\nif device == 'cuda':\n  torch.cuda.manual_seed_all(777)\n\nrandom.seed(777)\ntorch.manual_seed(777)\n\nScaler=preprocessing.StandardScaler()","89674384":"\n\nxy_data=pd.read_csv('..\/input\/2020aidiscomfort\/train.csv',header=None)\nxy_data=xy_data.dropna()\n","b24d5aa7":"x_data=xy_data.loc[1:,1:5]\ny_data=xy_data.loc[1:,6]","3f4addec":"x_data=np.array(x_data,dtype=float)\ny_data=np.array(y_data,dtype=float)\n\nx_data=Scaler.fit_transform(x_data)\nx_train=torch.FloatTensor(x_data).to(device)\ny_train=torch.LongTensor(y_data).to(device)\n","1e566945":"train_dataset=torch.utils.data.TensorDataset(x_train,y_train)","1f7b84a6":"# \ud559\uc2b5 \ud30c\ub77c\ubbf8\ud130 \uc124\uc815\nlearning_rate =0.01\ntraining_epochs = 30\nbatch_size = 10","595fe66c":"data_loader = torch.utils.data.DataLoader(dataset=train_dataset,\n                                          batch_size=batch_size,\n                                          shuffle=True,\n                                          drop_last=True)","46e3e0eb":"linear1=torch.nn.Linear(5,4,bias=True)\nlinear2=torch.nn.Linear(4,4,bias=True)\nlinear3=torch.nn.Linear(4,4,bias=True)\nlinear4=torch.nn.Linear(4,4,bias=True)\nlinear5=torch.nn.Linear(4,4,bias=True)\n\nrelu=torch.nn.ReLU()\n","48a887ab":"torch.nn.init.xavier_normal_(linear1.weight)\ntorch.nn.init.xavier_normal_(linear2.weight)\ntorch.nn.init.xavier_normal_(linear3.weight)\ntorch.nn.init.xavier_normal_(linear4.weight)\ntorch.nn.init.xavier_normal_(linear5.weight)","7527ef43":"model=torch.nn.Sequential(linear1,relu,\n                          linear2,relu,\n                          linear3,relu,\n                          linear4,relu,\n                          linear5\n                          ).to(device)","b1128862":"loss = torch.nn.CrossEntropyLoss().to(device) # softmax \ub0b4\ubd80\uc801\uc73c\ub85c \uacc4\uc0b0\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate) ","92856946":"total_batch = len(data_loader)\nfor epoch in range(training_epochs):\n    avg_cost = 0\n\n    for X, Y in data_loader:\n\n        X = X.to(device)\n        Y = Y.to(device)\n      \n        optimizer.zero_grad()\n        hypothesis = model(X)\n        cost = loss(hypothesis, Y)\n        cost.backward()\n        optimizer.step()\n\n        avg_cost += cost \/ total_batch\n\n    print('Epoch:', '%04d' % (epoch + 1), 'cost =', '{:.9f}'.format(avg_cost))\n\nprint('Learning finished')","a82be0c2":"test=pd.read_csv('..\/input\/2020aidiscomfort\/test.csv',header=None)\ntest=test.dropna()","9a893ffb":"with torch.no_grad():\n\n  test=test.loc[1:,1:5]\n  test=np.array(test,dtype=float)\n  test=Scaler.transform(test)\n  test=torch.from_numpy(test).float().to(device)\n  prediction = model(test)\n  correct_prediction = torch.argmax(prediction,dim=1)\n","915dcb1e":"result=pd.read_csv('..\/input\/2020aidiscomfort\/submit_sample.csv')\nresult","6387a252":"for i in range(len(prediction)):\n  result['Category'][i]=correct_prediction[i]\nprint(result)","68f47324":"result.to_csv('baseline.csv',index=False)","924836a1":"!kaggle competitions submit -c 2020aidiscomfort -f baseline.csv -m \"Message\"","41e8f353":"* \uacb0\uacfc\uac12 \uc81c\ucd9c","14b47d13":"* \ubaa8\ub378 \uc124\uacc4","d94b4282":"* \ubaa8\ub378 \ud559\uc2b5","34f375d4":"* \ubaa8\ub378 \ud3c9\uac00","745ca5eb":"* \ub370\uc774\ud130 \ub85c\ub4dc \ubc0f \ud30c\uc2f1"}}