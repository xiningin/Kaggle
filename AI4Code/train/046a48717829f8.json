{"cell_type":{"a1a9b497":"code","7759f573":"code","6feba6a5":"code","16946ff1":"code","7ed8f0cc":"code","a6882412":"code","c81c7492":"code","1786a8a3":"code","9b756245":"markdown","fc84251f":"markdown","7c1f43f6":"markdown","5754b9a3":"markdown","80792f42":"markdown","3007051a":"markdown"},"source":{"a1a9b497":"# Familiar imports\nimport numpy as np\nimport pandas as pd\n\n# For ordinal encoding categorical variables, splitting data\nfrom sklearn.preprocessing import OrdinalEncoder\nfrom sklearn.model_selection import train_test_split\n\n# For training  model\n# from sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\n# Evaluation\nfrom sklearn.metrics import mean_squared_error","7759f573":"# Load the training data\ntrain = pd.read_csv(\"..\/input\/30-days-of-ml\/train.csv\", index_col=0)\ntest = pd.read_csv(\"..\/input\/30-days-of-ml\/test.csv\", index_col=0)\n\n# Preview the data\ntrain.head()","6feba6a5":"# Separate target from features\ny = train['target']\nfeatures = train.drop(['target'], axis=1)\n\n# Preview features\nfeatures.head()","16946ff1":"# List of categorical columns\nobject_cols = [col for col in features.columns if 'cat' in col]\n\n# ordinal-encode categorical columns\nX = features.copy()\nX_test = test.copy()\nordinal_encoder = OrdinalEncoder()\nX[object_cols] = ordinal_encoder.fit_transform(features[object_cols])\nX_test[object_cols] = ordinal_encoder.transform(test[object_cols])\n\n# Preview the ordinal-encoded features\nX.head()","7ed8f0cc":"# split data\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, random_state=0)","a6882412":"#lgbm_parameters\nlgbm_parameters = {\n    'metric': 'rmse', \n    'n_jobs': -1,\n    'n_estimators': 50000,\n    'reg_alpha': 10.924491968127692,\n    'reg_lambda': 17.396730654687218,\n    'colsample_bytree': 0.21497646795452627,\n    'subsample': 0.7582562557431147,\n    'learning_rate': 0.009985133666265425,\n    'max_depth': 5,\n    'num_leaves': 63,\n    'min_child_samples': 27,\n    'max_bin': 523,\n    'cat_l2': 0.025083670064082797\n}\n\n# Define the model \nmodel = LGBMRegressor(**lgbm_parameters)\n\n# Train the model \nmodel.fit(X_train, y_train, \n          eval_set = ((X_valid,y_valid)),  verbose = -1,\n          early_stopping_rounds = 10)   \n\n# runing 10 minutes","c81c7492":"# predict\n\npreds_valid = model.predict(X_valid)\nprint(mean_squared_error(y_valid, preds_valid, squared=False))","1786a8a3":"# Use the model to generate predictions\npredictions = model.predict(X_test)\n\n# Save the predictions to a CSV file\noutput = pd.DataFrame({'Id': X_test.index,\n                       'target': predictions})\noutput.to_csv('submission.csv', index=False)","9b756245":"# Step 2: Load the data","fc84251f":"# Step 3: Prepare the data","7c1f43f6":"# Step 1:Import libraries","5754b9a3":"# Step 4: Train a model","80792f42":"# Step 5: Submit to the competition","3007051a":"This notebook copy by following:\n* https:\/\/www.kaggle.com\/alexisbcook\/getting-started-with-30-days-of-ml-competition\n* https:\/\/www.kaggle.com\/alexisbcook\/exercise-xgboost\n* https:\/\/www.kaggle.com\/svyatoslavsokolov\/tps-feb-2021-lgbm-simple-version"}}