{"cell_type":{"676f8d70":"code","61e2dd1d":"code","8231f81f":"code","91138bde":"code","f4cd410d":"code","d1e4d6e1":"code","fec43e71":"code","3c88f45e":"code","d16c00dd":"code","46ca9b7d":"code","b1f68286":"code","43cba171":"code","c376e58e":"code","8895d9ad":"code","53d4df1b":"code","c8ec6eae":"code","b71f2f36":"code","2fcd1c08":"code","915c4105":"code","ae516373":"code","58b31daf":"markdown","b14c94f7":"markdown","8d9e5cde":"markdown","0ab91109":"markdown","c3ce93fa":"markdown","2b94126a":"markdown","60f66af5":"markdown","d1c75349":"markdown","f858d970":"markdown","8c9b2654":"markdown"},"source":{"676f8d70":"from fastai.vision import *\nfrom fastai import *\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nimport cv2\nimport glob\nimport torch\n\n\ndevice = 'cuda:0' if torch.cuda.is_available() else 'cpu'\nprint(f'Running on device: {device}')","61e2dd1d":"PATH = Path('..\/input\/aptos2019-blindness-detection')\ntrain = PATH\/'train_images'\ntest = PATH\/'test_images'\ntrain_folder = 'train_images'\nmodel_dir = Path('\/kaggle\/working\/')\nbs = 64\nimg_size = 512\n\ntrain_df = pd.read_csv(os.path.join(PATH, 'train.csv'))\ntrain_df['id_code'] = train_df['id_code'].apply(lambda x: f'{train_folder}\/{x}.png')\ntrain_df.head()","8231f81f":"PATH.ls()","91138bde":"sns.countplot(train_csv['diagnosis'])","f4cd410d":"print(f\"Size of Training set images: {len(list(train.glob('*.png')))}\")\nprint(f\"Size of Test set images: {len(list(test.glob('*.png')))}\")","d1e4d6e1":"tfms = get_transforms(do_flip=True,flip_vert=True,max_rotate=180,\n                      max_warp=0,max_zoom=1.35,p_lighting=0.4,\n                      max_lighting=0.3,xtra_tfms=[flip_lr()] )","fec43e71":"\ndata = (ImageList.from_df(train_df, PATH)\n        .split_by_rand_pct()\n        .label_from_df()\n        .transform(tfms, size=img_size, resize_method=ResizeMethod.PAD,padding_mode='zeros')\n       ).databunch(bs=32).normalize(imagenet_stats)\ndata\n\n# The more simpler ImageDataBunch shortcut method. \n# data = ImageDataBunch.from_df(PATH, train_csv, folder='train_images', \n#                               suffix='.png', no_check=True, \n#                               ds_tfms=get_transforms(), size=512, bs=32).normalize(imagenet_stats)","3c88f45e":"data.train_ds","d16c00dd":"data.valid_ds","46ca9b7d":"data.show_batch(rows=3, figsize=(10,8))","b1f68286":"# Training\nkappa = KappaScore()\nkappa.weights = \"quadratic\"\n\nlearner = cnn_learner(data, models.resnet50, metrics=[error_rate, kappa])\n\nlearner.fit_one_cycle(4)\n","43cba171":"learner.model_dir = '\/kaggle\/working'\nlearner.unfreeze()\nlearner.lr_find()","c376e58e":"learner.recorder.plot()","8895d9ad":"learner.fit_one_cycle(4, max_lr=slice(1e-5, 1e-3))","53d4df1b":"learner.save('stage-2', return_path = True)","c8ec6eae":"tfms_456 = get_transforms(do_flip=True,flip_vert=True,max_rotate=360,\n                      max_warp=0,max_zoom=1.25,p_lighting=0.5,\n                      max_lighting=0.2)\n\ndata_456 = (ImageList.from_df(train_df, PATH)\n        .split_by_rand_pct()\n        .label_from_df()\n        .transform(tfms_456, size=456)\n       ).databunch(bs=32).normalize(imagenet_stats)\ndata_456\n\n","b71f2f36":"learner_2 = cnn_learner(data_456, models.resnet50, metrics=[error_rate, kappa])\n\nlearner_2.load(model_dir\/'stage-2')","2fcd1c08":"learner_2.model_dir = '\/kaggle\/working'\nlearner_2.unfreeze()\nlearner_2.lr_find()","915c4105":"learner_2.recorder.plot()","ae516373":"learner_2.fit_one_cycle(4, max_lr=slice(1e-5, 1e-3))","58b31daf":"# Training. \n\nAs stated by the competition, they use the Quadratic Kappa score as the evaluation metric. \nI also print the error_rate metric to get an idea how it performs side by side with Kappa. \n\nThis is **Stage-1** Training. \n> Fine tuning only the newly added final layers of the model whilst freezing the earlier layrers and using a pretrained(ImageNet) Resnet50.  ","b14c94f7":"Based on the above plot and coupled with Jeremy Howards advices:\n- We select a value for the learning rate where the loss is minimum. \n- Use this small learning rate to train the earlier layers. \n\nThis time we fine tune the entire model, albiet with varying learning rates accross the layers. \n- Smaller learning rate for earlier layers (slow learning as not much weight updation needed). ","8d9e5cde":"Running the **LR finder** which would show us the optimal learning rate through a LR plot. ","0ab91109":"# APTOS 2019 Blindness Detection\n### Detect diabetic retinopathy to stop blindness before it's too late \n\n\n","c3ce93fa":"The plot above does indicate some imbalance between the classes. ","2b94126a":"#### On to Fastai.\nThe Data block API makes it way easier to define a databunch. \nI use a couple of transformations for the first stage of training.\nThe values selected for these transformations are based on top performing solution summaries on the discussion tab. ","60f66af5":"Having a look at our Data. ","d1c75349":"This is **Stage-2** training. \n> Here we create a new databunch with differnt sized pictures. We used 512x512 Images for stage-1 training. \n> Now we use 456x456 to fine tune our model further. \n> Following the same cycle, unfreezing --> lr_finder --> training with varying learning rates. ","f858d970":"Importing Dependencies and defining file paths. ","8c9b2654":"Defining the data to be used for training and validation. \n**Randomly setting aside 2% of the data for validation. **\nFor the first training stage, i used padding as the resize method. \nTo get an understanding of how resize methods work in fastai check out the data augmentations part from fastai docs [here](https:\/\/docs.fast.ai\/vision.transform.html#Data-augmentation)\n"}}