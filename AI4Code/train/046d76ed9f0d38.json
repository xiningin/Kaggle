{"cell_type":{"22818d72":"code","cdacd6bc":"code","d244e425":"code","38052583":"code","441e0ca7":"code","faa9b08f":"code","602d1751":"code","50b32d40":"code","4cb575fb":"code","54604fb7":"code","1e118d8a":"code","eb176889":"code","04475432":"code","2736e1c9":"code","c8254e25":"code","e9cc732d":"code","f438a45b":"code","a695e70e":"code","b61ae681":"code","957b3121":"code","e80ef462":"code","bbe3951d":"code","a02be043":"code","1cbbbd8e":"code","48d0dc0d":"code","15da44a0":"code","026ccb57":"code","7d0b9a32":"code","affc2e3f":"code","7e3e72c4":"code","09279250":"markdown","694a8b63":"markdown","d922a9fd":"markdown","2edfb308":"markdown","cbe2cf0c":"markdown","2975b372":"markdown","f869141e":"markdown","8d6baf8f":"markdown","1bac03c1":"markdown","30796865":"markdown","d6d067f2":"markdown","7c071f03":"markdown","a8fa4dda":"markdown","c7505aed":"markdown","7bd234c6":"markdown","c81e401c":"markdown","0f667ae7":"markdown","6b5a262b":"markdown","1396ca24":"markdown","29e23d65":"markdown","78da9ff2":"markdown","7ec5f918":"markdown","4ae8e793":"markdown","c549e33c":"markdown","ae3d7981":"markdown","aa78d8c7":"markdown","8c110662":"markdown","19dfcb7b":"markdown","18203e27":"markdown"},"source":{"22818d72":"import os # File manipulation\nimport pandas as pd # Data manipulation\nimport numpy as np # Mathematics\nimport matplotlib.pyplot as plt # Data plotting\nimport seaborn as sns # Data plotting","cdacd6bc":"file_path_list = [] # The list to contain the CSV file paths.\n# Walk through the input directory and loop through the sorted file names to \n# append the paths of the CSV files to the file path list.\nfor dirname, _, filenames in os.walk(\"\/kaggle\/input\/\"):\n   for filename in sorted(filenames):\n        file_path = os.path.join(dirname, filename)\n        file_path_list.append(file_path)\nfile_path_list[:3] # We now have a list of sorted CSV file paths.","d244e425":"crime_data = pd.DataFrame(data=None) # Make a new DataFrame object.\n# For each of the file paths in the file path list, read the CSV\n# data and concatenate it to the DataFrame.\nfor file_path in file_path_list:\n    crime_data = pd.concat([crime_data, pd.read_csv(file_path)])","38052583":"crime_data.shape","441e0ca7":"crime_data.info()","faa9b08f":"crime_data.sample(5)","602d1751":"crime_data.drop(['Crime ID', 'Reported by', 'Falls within', 'Context'], axis=1, inplace=True)","50b32d40":"crime_data.fillna(value={'Last outcome category': 'Not stated'}, inplace=True)","4cb575fb":"crime_data.dropna(axis=0, inplace=True)","54604fb7":"new_columns = {'Month': 'datetime',\n               'Longitude': 'longitude',\n               'Latitude': 'latitude',\n               'Location': 'location',\n               'LSOA code': 'lsoa_code',\n               'LSOA name': 'lsoa_name',\n               'Crime type': 'crime_type',\n               'Last outcome category': 'last_outcome'}\ncrime_data.rename(columns=new_columns, inplace=True)","1e118d8a":"crime_data['datetime'] = pd.to_datetime(crime_data['datetime'],\n                                        infer_datetime_format=True,\n                                        errors='ignore')","eb176889":"crime_data[['location', 'lsoa_code', 'lsoa_name', 'crime_type', 'last_outcome']].nunique()","04475432":"crime_data['crime_type'] = crime_data['crime_type'].astype('category')","2736e1c9":"crime_data['crime_type'].describe()","c8254e25":"crime_data['last_outcome'] = crime_data['last_outcome'].astype('category')","e9cc732d":"crime_data['last_outcome'].describe()","f438a45b":"# Replace the four-character code ###[A-Z] and the preceding white space with empty string,\n# leaving just the area name. Assign this value to a new column, called 'area'.\ncrime_data['area'] = crime_data['lsoa_name'].str.replace('(\\s\\d{3}\\D{1})', '', regex=True)\ncrime_data.sample(5)","a695e70e":"crime_data['area'].nunique()","b61ae681":"crime_data['area'] = crime_data['area'].astype('category')","957b3121":"crime_data['area'].describe()","e80ef462":"crime_data = crime_data[['datetime',\n                         'crime_type',\n                         'location',\n                         'area',\n                         'lsoa_code',\n                         'lsoa_name',\n                         'latitude',\n                         'longitude', \n                         'last_outcome']]\ncrime_data.sample(5)","bbe3951d":"crime_data.info()","a02be043":"crime_data.groupby('area').size().sort_values(ascending=False)","1cbbbd8e":"outside_areas = ['Wandsworth',\n                 'Isles of Scilly',\n                 'Gwynedd',\n                 'Ceredigion',\n                 'West Somerset',\n                 'County Durham',\n                 'Taunton Deane',\n                 'Copeland',\n                 'West Dorset',\n                 'Swansea',\n                 'Purbeck',\n                 'Maidstone',\n                 'Poole',\n                 'Isle of Anglesey',\n                 'Conwy',\n                 'Allerdale',\n                 'Pembrokeshire',\n                 'Powys',\n                 'Neath Port Talbot',\n                 'Wiltshire']\ncrime_data['area'].cat.remove_categories(outside_areas, inplace=True)\ncrime_data.groupby('area').size().sort_values(ascending=False)","48d0dc0d":"crime_data.groupby('crime_type').size().sort_values(ascending=False)","15da44a0":"crime_data.groupby('last_outcome').size().sort_values(ascending=False)","026ccb57":"frequency_table = crime_data[['datetime', 'crime_type', 'area']] \\\n.pivot_table(index=['crime_type', 'area'],\n             columns='datetime',\n             aggfunc=np.size,\n             fill_value=0)","7d0b9a32":"crime_types = crime_data.groupby('crime_type').size().sort_values(ascending=False).index.to_list()","affc2e3f":"date_list = crime_data['datetime'].dt.strftime('%Y\/%m').unique()","7e3e72c4":"fig, ax = plt.subplots(len(crime_types), 1, figsize=(24, len(crime_types) * 9))\nfor index, crime in enumerate(crime_types): # Enumerate through our list of crime types.\n    sns.heatmap(frequency_table.loc[crime, :],\n                square=True,\n                cbar_kws={'shrink': .35, 'label': 'Crime Frequency'},\n                cmap='viridis',\n                annot=True,\n                annot_kws={'fontsize':9},\n                fmt='',\n                linewidth=1,\n                linecolor='#222',\n                robust=True,\n                ax=ax[index])\n    ax[index].set_title('Frequency of ' + crime.title() + ' for Devon and Cornwall', fontsize=32)\n    ax[index].set_xlabel('Date', fontsize=24)\n    ax[index].set_ylabel('Area', fontsize=24)\n    ax[index].figure.axes[-1].yaxis.label.set_size(24)\n    ax[index].set_xticklabels(date_list, rotation=45, horizontalalignment='right')\n    ax[index].set_yticklabels(ax[index].get_yticklabels(), rotation=45, horizontalalignment='right')\nplt.show()","09279250":"Let's see how many unique values there are for the columns containing string data. We want to identify columns which contain values that could potentially become 'category' types. To help identify such columns we can look at the number of unique values, and also consider how we would submit an entry to our DataFrame if we were recording a crime; would we select one of these values from a small number of possibilities, or would we have license to be more descriptive?","694a8b63":"There are 31 unique values for 'area', and it will be 'category' type.","d922a9fd":"## Explore","2edfb308":"The bulk of the entries are in less than half of the areas. Upon investigation we can see that most of these areas do not belong to Devon and Cornwall and are not under the authority of Devon and Cornwall Police. Perhaps these are cases that have occurred outside of the force area but have investigative links to it?\n\nWe will compile a list of the areas outside of the Devon and Cornwall region and thus outside of the scope of our analysis. We will remove these categories and their subsequent entries from our DataFrame.","cbe2cf0c":"In order to answer some of our questions that we posed in the Introduction, we will need to pivot our DataFrame so we can see the frequency of crime by date for each area.\n\nWe will use this pivot table to plot a set of heatmaps, one for each type of crime, describing the frequency of that crime by date for each area.\n\nSo let's start by building the pivot table.","2975b372":"And then we make a DataFrame object to store our concatenated data. Because the file path list was ordered, the concatenated data retains its chronology by date.","f869141e":"## Clean\nLet's examine the DataFrame and the nature of the values captured therein.","8d6baf8f":"In this notebook we will try to answer the following questions:\n1. What types of crime are most prevalent in the region?\n2. Which areas in the region generate more crime?\n3. How has the frequency of crime changed?","1bac03c1":"A list of the crime types will be useful so we can iterate through the 'frequency_table' DataFrame. We will also order this list of crime types by frequency.","30796865":"## Import\nFirst we import the libraries we will need.","d6d067f2":"We will render a sequence of plots which will describe the frequency of each type of crime by date for each area.\n\nWe will use heatmaps because they are well suited to describing such granular data in the configuration we have chosen in our 'frequency_table' DataFrame.","7c071f03":"With 26 unique values, 'last_outcome' will be 'category' type.","a8fa4dda":"Finally, let's see the frequency of last outcomes assigned to each entry for the whole DataFrame.","c7505aed":"The 'Last outcome category' can be made cohesive by filling the missing values with a simple 'Not stated'.","7bd234c6":"![banner.jpg](attachment:555e59e2-e195-47ec-98ce-374e8105e74a.jpg)","c81e401c":"Let's see how many crimes have been reported by type in all areas for the whole DataFrame.","0f667ae7":"'Datetime' is a more useful type for the YYYY-MM format recorded in the entries. The date values recorded for each entry are truncated by data.police.uk to show the year and month only, to anonymise the data.\n\nOur data spans from March 2018 to present.","6b5a262b":"Let's see how many crimes have been reported by area for the whole DataFrame.","1396ca24":"The 'datetime' type is quite verbose for an axis ticker in a plot, displaying both date *and* time. We will make our own list of tickers for the axis which will be formatted YYYY\/MM.","29e23d65":"Our DataFrame is now more harmonious, descriptive, and cohesive, and we now have three categories from which to pivot the data.","78da9ff2":"## Introduction","7ec5f918":"Let's drop our candidate list of columns from the DataFrame.","4ae8e793":"We want to perform our crime analysis by geography. 'Latitude', 'Longitude', 'LSOA code', and 'LSOA name' are now the only columns with missing values.\n\nMissing values in 'Longitude' and 'Latitude' are not germane to our analysis right now, but they will be when we come to map our data to geospatial coordinates; and similarly for 'LSOA code'. However, missing values in 'LSOA name' are problematic, as the values in this column describe the area that the crime occurred.\n\nSo any missing values in these columns detract from our ability to understand the entry. As it would be misrepresentative to infer or approximate these values, the best solution would be to drop from our DataFrame any entry with a missing value.","c549e33c":"## Load\nWhen data.police.uk serve the crime data, a zip file is provided which contains datasets for each month as CSV files. So we need to concatenate these contiguous CSV into a single cohesive DataFrame.\n\nWe make a sorted list of the file paths to each CSV.","ae3d7981":"We will re-label the columns to make our DataFrame more uniform.","aa78d8c7":"For our analysis, we really want to identify which geographical area each entry belongs to. This information is actually encoded in the values in 'lsoa_name'. The composition of each of these values is the area name followed by a four-character code. Therefore, we can extract the area name by removing the four-character code.\n\nWe will make a new column for these values, called 'area'.","8c110662":"Lastly, we will rearrange the order of the columns for readability and to lend each entry more chronology with how the values are represented.","19dfcb7b":"The DataFrame has several columns with missing values, and also several columns that are redundant to our analysis.\n\n'Crime ID' is a one-way hash of the offence reference record, and 'Last outcome category' is a reference to whichever of the outcomes associated with the crime occurred most recently. Both contain values that are missing in equal measure from the entries in the DataFrame. On examination, it appears that a Crime ID is not recorded if no last outcome category has been attributed to the entry. Crime ID is redundant to our analysis and is a candidate for our list of columns to drop from the DataFrame.\n\n'Reported by' and 'Falls within' are both the geographic police force that either supplied the data or is responsible for the data. They are both redundant to our analysis and are candidates for our list of columns to drop from the DataFrame.\n\n'Context' is additional human-readable data about individual crimes. It contains no useful data, is therefore redundant to our analysis, and is a candidate for our list of columns to drop from the DataFrame.","18203e27":"The 14 unique values in 'crime_type' are Home Office Offence Codes (see database metadata). These values will be 'category' type."}}