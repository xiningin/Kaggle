{"cell_type":{"1f52ca82":"code","cbcdd17a":"code","3ea4b25e":"code","d9b18af7":"code","cd05a91b":"code","9496cc77":"code","62b7ab49":"code","0a907ecf":"code","67d3d573":"code","8e632ba5":"code","7cec45d2":"code","1a76bb45":"code","b1a287e0":"code","e70f5d2c":"code","ae8a6b35":"code","4597366e":"code","a2560fc5":"code","f22696b5":"code","8482b880":"code","eb705640":"code","c84dfae7":"code","a0f27a40":"code","b4d4c64e":"markdown","85aa8320":"markdown","1dc460c3":"markdown"},"source":{"1f52ca82":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import TimeSeriesSplit\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor","cbcdd17a":"train = pd.read_csv(r'..\/input\/tabular-playground-series-jan-2022\/train.csv')\ntrain.head()","3ea4b25e":"test = pd.read_csv(r'..\/input\/tabular-playground-series-jan-2022\/test.csv')\ntest.head()","d9b18af7":"sample_submission = pd.read_csv(r'..\/input\/tabular-playground-series-jan-2022\/sample_submission.csv')\nsample_submission.head()","cd05a91b":"print(f'train set have {train.shape[0]} rows and {train.shape[1]} columns.')\nprint(f'test set have {test.shape[0]} rows and {test.shape[1]} columns.') \nprint(f'sample_submission set have {sample_submission.shape[0]} rows and {sample_submission.shape[1]} columns.') ","9496cc77":"# let's check for missing values\ntrain.isnull().sum()","62b7ab49":"# let's check count of unique values every cols are having\ntrain.nunique()","0a907ecf":"# let's drop row_id col\ntrain.drop('row_id',axis=1,inplace=True)\ntest.drop('row_id',axis=1,inplace=True)","67d3d573":"print(\"country unique values:\")\nprint(train['country'].value_counts())\nplt.figure(figsize=(14,5))\ncount = train['country'].value_counts()\nsns.barplot(x=count.index, y=count.values,linewidth=1.5,errcolor=\".2\", edgecolor=\".2\")\nplt.title(\"country unique values\", fontdict={'fontsize':20})\nplt.show()","8e632ba5":"print(\"store unique values:\")\nprint(train['store'].value_counts())\nplt.figure(figsize=(14,5))\ncount = train['store'].value_counts()\nsns.barplot(x=count.index, y=count.values,linewidth=1.5,errcolor=\".2\", edgecolor=\".2\")\nplt.title(\"store unique values\", fontdict={'fontsize':20})\nplt.show()","7cec45d2":"print(\"product unique values:\")\nprint(train['product'].value_counts())\nplt.figure(figsize=(14,5))\ncount = train['product'].value_counts()\nsns.barplot(x=count.index, y=count.values,linewidth=1.5,errcolor=\".2\", edgecolor=\".2\")\nplt.title(\"product unique values\", fontdict={'fontsize':20})\nplt.show()","1a76bb45":"train['date'] = pd.to_datetime(train['date'])\ntrain['year'] = train['date'].dt.year\ntrain['day'] = train['date'].dt.day\ntrain['dayofweek'] = train['date'].dt.dayofweek\ntrain['dayofyear'] = train['date'].dt.dayofyear\ntrain['weekday'] = train['date'].dt.weekday\n\ntest['date'] = pd.to_datetime(test['date'])\ntest['year'] = test['date'].dt.year\ntest['day'] = test['date'].dt.day\ntest['dayofweek'] = test['date'].dt.dayofweek\ntest['dayofyear'] = test['date'].dt.dayofyear\ntest['weekday'] = test['date'].dt.weekday","b1a287e0":"# let's drop date col\ntrain.drop('date',axis=1,inplace=True)\ntest.drop('date',axis=1,inplace=True)","e70f5d2c":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nval = ['country', 'product', 'store']\nfor i in val:\n    train[i] = le.fit_transform(train[i])\n    test[i] = le.transform(test[i])","ae8a6b35":"train.head()","4597366e":"y = train['num_sold']\ntrain.drop('num_sold',axis=1,inplace=True)","a2560fc5":"# Credit to https:\/\/www.kaggle.com\/c\/web-traffic-time-series-forecasting\/discussion\/36414\ndef SMAPE(y_true, y_pred):\n    denominator = (y_true + np.abs(y_pred)) \/ 200.0\n    diff = np.abs(y_true - y_pred) \/ denominator\n    diff[denominator == 0] = 0.0\n    return np.mean(diff)","f22696b5":"folds = TimeSeriesSplit()\n\nxgb_predictions = np.zeros(len(test))\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(train)):\n    print(f\"Fold: {fold}\")\n    X_train, X_test = train.iloc[trn_idx], train.iloc[val_idx]\n    y_train, y_test = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model_xgb = XGBRegressor(tree_method='gpu_hist')\n   \n    model_xgb.fit(X_train, y_train,\n              eval_set=[(X_test, y_test)],\n                early_stopping_rounds=400,\n                verbose=False)\n    pred = model_xgb.predict(X_test)\n    smape = SMAPE(y_test, pred)\n    print(f\" smape_value: {smape}\")\n    print(\"-\"*50)\n    \n    xgb_predictions += model_xgb.predict(test) \/ folds.n_splits","8482b880":"# plot feature importance\nfrom xgboost import plot_importance\nfig, ax = plt.subplots(1,1,figsize=(20,12))\nplot_importance(model_xgb,ax=ax, xlabel=None)\nplt.title('XGB Feature importance')\nplt.show()","eb705640":"folds = TimeSeriesSplit()\n\nlgb_predictions = np.zeros(len(test))\n\n\nfor fold, (trn_idx, val_idx) in enumerate(folds.split(train)):\n    print(f\"Fold: {fold}\")\n    X_train, X_test = train.iloc[trn_idx], train.iloc[val_idx]\n    y_train, y_test = y.iloc[trn_idx], y.iloc[val_idx]\n\n    model_lgb = LGBMRegressor(device_type='gpu')\n   \n    model_lgb.fit(X_train, y_train,\n              eval_set=[(X_test, y_test)],\n                early_stopping_rounds=400,\n                verbose=False)\n    pred = model_lgb.predict(X_test)\n    smape = SMAPE(y_test, pred)\n    print(f\" smape_value: {smape}\")\n    print(\"-\"*50)\n    \n    lgb_predictions += model_lgb.predict(test) \/ folds.n_splits","c84dfae7":"# plot feature importance\nfrom lightgbm import plot_importance\nfig, ax = plt.subplots(1,1,figsize=(20,12))\nplot_importance(model_lgb,ax=ax, xlabel=None)\nplt.title('LGB Feature importance')\nplt.show()","a0f27a40":"sample_submission['num_sold'] = xgb_predictions\nsample_submission.to_csv(f'xgb.csv',index = False)\n\nsample_submission['num_sold'] = lgb_predictions\nsample_submission.to_csv(f'lgb.csv',index = False)","b4d4c64e":"![](https:\/\/t4.ftcdn.net\/jpg\/04\/60\/05\/05\/360_F_460050532_7JjxeTTaZLyk7RTOayql8iX4O6Zlctjs.jpg)","85aa8320":"## XGBOOST","1dc460c3":"## LIGHTGBM"}}