{"cell_type":{"dbec6f9b":"code","a3c380b2":"code","6cdc1ee7":"code","ffda375b":"code","0838e75c":"code","a7615ef3":"code","98e62563":"code","2c5fd038":"code","2a182fb6":"code","4277d7f3":"code","efea32c1":"code","2e058a01":"code","2e42740a":"code","1cdcd5f2":"code","73032e61":"code","45bc6f4d":"code","2fd2c312":"code","77f3ec81":"code","5e13b058":"code","c8aa8252":"code","4438a316":"code","149e76b6":"code","382a925b":"code","b97bb578":"code","8ad7200f":"code","cd509c35":"code","5b579100":"code","17e71bca":"code","1e228df4":"code","12898f01":"code","79c0aeba":"code","5e7d1765":"code","0c0690d2":"code","de5f529e":"code","02ea35d0":"code","ed0f42f9":"code","cefc11da":"code","d821153a":"code","4ee84c57":"code","0cd6ecf7":"code","35f3ca38":"code","7bf43ab3":"code","60e1add2":"code","0272346a":"code","a34daa68":"code","96771eda":"markdown","9afceb96":"markdown","04f9acad":"markdown","1a993336":"markdown","b7cf4b1b":"markdown","b8f65679":"markdown","40347840":"markdown","da3fd088":"markdown","595266db":"markdown"},"source":{"dbec6f9b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a3c380b2":"stroke = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\ndata= stroke.copy()","6cdc1ee7":"data.head()","ffda375b":"data.describe().T","0838e75c":"df = data.loc[data[\"stroke\"]== 1]","a7615ef3":"df.shape","98e62563":"df.info()","2c5fd038":"df.head()","2a182fb6":"df.isna().sum()","4277d7f3":"df.dropna(inplace = True)","efea32c1":"df.head()","2e058a01":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport plotly.express as px\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2e42740a":"sns.countplot(data.stroke)","1cdcd5f2":"data[\"work_type\"].value_counts().plot.barh();","73032e61":"sns.boxplot(x = \"smoking_status\", y = \"avg_glucose_level\", hue = \"stroke\", data = data);","45bc6f4d":"sns.catplot(y = \"avg_glucose_level\", kind = \"violin\", data = data);","2fd2c312":"sns.pairplot(data,hue=\"stroke\")","77f3ec81":"\nsns.pairplot(df, kind  =\"reg\");","5e13b058":"\nfrom sklearn.preprocessing import LabelEncoder\n\nnumber = LabelEncoder()\ndf['gender'] = number.fit_transform(df['gender'].astype(str))\ndf['ever_married'] = number.fit_transform(df['ever_married'].astype(str))\n","c8aa8252":"df.head()","4438a316":"dms = pd.get_dummies(df[['work_type', 'Residence_type', 'smoking_status']])\n\n","149e76b6":"y = df[\"avg_glucose_level\"]\n","382a925b":"X_ = df.drop(['work_type', 'Residence_type', 'smoking_status'], axis=1).astype('float64')\n\n","b97bb578":"X = pd.concat([X_, dms],axis=1)","8ad7200f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, \n                                                    test_size=0.25, \n                                                    random_state=1994)","cd509c35":"from sklearn.svm import SVR\nfrom sklearn.ensemble import BaggingRegressor\nfrom sklearn.datasets import make_regression","5b579100":"bag_model = BaggingRegressor(bootstrap_features = True)\nbag_model.fit(X_train, y_train)","17e71bca":"bag_model.n_estimators","1e228df4":"bag_model.estimators_","12898f01":"bag_model.estimators_samples_","79c0aeba":"bag_model.estimators_features_","5e7d1765":"bag_model.estimators_[1]","0c0690d2":"y_pred1 = bag_model.predict(X_test)","de5f529e":"from sklearn.metrics import mean_squared_error\n\naccuracy1= np.sqrt(mean_squared_error(y_test, y_pred1))","02ea35d0":"second_y_pred = bag_model.estimators_[1].fit(X_train, y_train).predict(X_test)","ed0f42f9":"np.sqrt(mean_squared_error(y_test, second_y_pred))","cefc11da":"seven_y_pred = bag_model.estimators_[4].fit(X_train, y_train).predict(X_test)","d821153a":"np.sqrt(mean_squared_error(y_test, seven_y_pred))","4ee84c57":"import xgboost as xgb\nfrom xgboost import XGBRegressor\nfrom sklearn.model_selection import GridSearchCV","0cd6ecf7":"DM_train = xgb.DMatrix(data = X_train, label = y_train)\nDM_test = xgb.DMatrix(data = X_test, label = y_test)","35f3ca38":"xgb_model = XGBRegressor().fit(X_train, y_train)\n","7bf43ab3":"y_pred2 = xgb_model.predict(X_test)\naccuracy2 = np.sqrt(mean_squared_error(y_test, y_pred2))","60e1add2":"xgb_model","0272346a":"models = {\"XGBoost Score :\" : accuracy2,\n           \"Bagged Tree Score :\" : accuracy1 }\n","a34daa68":"import pandas as pd\nModelComparision = pd.DataFrame.from_dict(models,orient='index')\nModelComparision","96771eda":"**Bagged Tree Regression**","9afceb96":"# **Conclusion**\n\n","04f9acad":"# Data Exploration","1a993336":"**XGBoost**","b7cf4b1b":"**Prediction**","b8f65679":"# Data Visiualization","40347840":"**XGBoost has less MSE than Bagged Trees model  in terms of predicting people's blood sugar levels who had stroke therefore XGBoost is more successful.**\n","da3fd088":"**Hello**\n\n\n\n**In this kernel, I tried to predict blood sugar levels of people who had stroke. I used Bagged Trees Regression and XGBoost. Lastly I compared accuracy scores of both models.**\n","595266db":"**Prediction**"}}