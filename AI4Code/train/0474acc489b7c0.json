{"cell_type":{"695d1a69":"code","0ad414ee":"code","dcf2df24":"code","667b38fc":"code","b88eb340":"code","73e8acc9":"code","ac5b2e73":"code","d7657729":"code","c2b89146":"code","409e6fdb":"code","07af82ec":"code","f5a8203a":"code","d75dda13":"code","c8f0c3fc":"code","11bf746e":"code","e83a1eb0":"code","147c04d9":"code","bd2a3700":"code","13574623":"code","5f7393f6":"code","7d1a22d5":"code","2f69d749":"code","330f08c9":"code","742722c3":"code","af55fd48":"code","155d1ad2":"code","be6efaae":"code","74a34e79":"code","73c78b52":"code","39e80bb0":"code","29eadf25":"code","a9c1483f":"code","5a86428d":"code","3835ca29":"code","9584e044":"code","8bfa7d50":"code","aa19ed1b":"code","0998ce96":"code","c6f8266f":"code","4130fced":"code","fade0fd4":"code","f33067d0":"code","e39175bb":"code","a993a0d4":"code","37368e77":"code","6b7f084b":"code","e7aa76c2":"code","12b180b3":"code","f78b50b3":"code","9d64cb74":"code","2f215fe6":"code","09a943e7":"markdown","1401556c":"markdown","a2500328":"markdown","dce92b6d":"markdown","c8d81688":"markdown","49b1c2f4":"markdown"},"source":{"695d1a69":"import numpy as np\nimport pandas as pd \nimport matplotlib.dates as md\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport datetime as dt\nimport datetime,pytz\n\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nimport xgboost as xgb\nfrom xgboost import plot_importance, plot_tree\n\nfrom scipy import stats\nfrom scipy.stats import boxcox\n\nimport statsmodels.api as sm\nfrom itertools import product\n\nfrom statsmodels.tsa.seasonal import seasonal_decompose\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.tsa.arima_model import ARIMA\nfrom numpy.linalg import LinAlgError","0ad414ee":"#define a conversion function for the native timestamps in the csv file\ndef dateparse (time_in_secs):    \n    return pytz.utc.localize(datetime.datetime.fromtimestamp(float(time_in_secs)))","dcf2df24":"data=pd.read_csv('..\/input\/bitcoin-historical-data\/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv',parse_dates=[0], date_parser=dateparse)","667b38fc":"data.head()","b88eb340":"data.shape","73e8acc9":"data.isnull().sum()","ac5b2e73":"data.info()","d7657729":"data.describe().T","c2b89146":"#Preprocessing the data\n# First thing is to fix the data for bars where there are no trades. \n# Volume\/trades are a single event so fill na's with zeroes for relevant fields\ndata['Volume_(BTC)'].fillna(value=0, inplace=True)\ndata['Volume_(Currency)'].fillna(value=0, inplace=True)\ndata['Weighted_Price'].fillna(value=0, inplace=True)\n\n# next we need to fix the Open,high,low,close data which is a continuous timeseries so forwardfill those values...\ndata['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)\n\ndata.head()","409e6fdb":"corr=data.corr()\nf,ax = plt.subplots(figsize=(12, 12))\nsns.heatmap(corr,annot=True,linewidths=.5, fmt= '.1f',ax=ax)","07af82ec":"# ScatterPlot  \n# x = open, y = close\ndata.plot(kind='scatter', x='Volume_(BTC)', y='Volume_(Currency)',alpha = 0.5)\nplt.xlabel('BTC Volume')            \nplt.ylabel('Currency Volume')\nplt.title('BTC-Currency Scatter Plot') \nplt.show()","f5a8203a":"#!pip install prophet","d75dda13":"plt.figure(figsize=(16,4))\ndata.Open.plot(kind='line', color='r', label='Open', alpha=0.5, linewidth=5, grid=True, linestyle=':')\ndata.High.plot(color='g', label='High', linewidth=1, alpha=0.5, grid=True, linestyle='-.')\nplt.legend(loc='upper right') #legend put label into plot\nplt.xlabel('Time')\nplt.ylabel('price at the start of the time window')\nplt.title('Line plot')\nplt.show()","c8f0c3fc":"#open and high values have same trend","11bf746e":"data = pd.read_csv('..\/input\/bitcoin-historical-data\/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv',parse_dates=[0], date_parser=dateparse) \ndata['Timestamp'] = data['Timestamp'].dt.tz_localize(None)\ndata = data.groupby([pd.Grouper(key='Timestamp', freq='H')]).first().reset_index()\ndata = data.set_index('Timestamp')\ndata = data[['Weighted_Price']]\ndata['Weighted_Price'].fillna(method='ffill', inplace=True)","e83a1eb0":"data.plot(style='', figsize=(15,5), title='BTC Weighted_Price Price (USD) by Hours')","147c04d9":"split_date = '25-Jun-2018'\ndata_train = data.loc[data.index <= split_date].copy()\ndata_test = data.loc[data.index > split_date].copy()","bd2a3700":"_ = data_test \\\n    .rename(columns={'Weighted_Price': 'Test Set'}) \\\n    .join(data_train.rename(columns={'Weighted_Price': 'Training Set'}), how='outer') \\\n    .plot(figsize=(15,5), title='BTC Weighted_Price Price (USD) by Hours', style='')","13574623":"def create_features(df, label=None):\n    \"\"\"\n    Creates time series features from datetime index\n    \"\"\"\n    df['date'] = df.index\n    df['hour'] = df['date'].dt.hour\n    df['dayofweek'] = df['date'].dt.dayofweek\n    df['quarter'] = df['date'].dt.quarter\n    df['month'] = df['date'].dt.month\n    df['year'] = df['date'].dt.year\n    df['dayofyear'] = df['date'].dt.dayofyear\n    df['dayofmonth'] = df['date'].dt.day\n    df['weekofyear'] = df['date'].dt.weekofyear\n    \n    X = df[['hour','dayofweek','quarter','month','year',\n           'dayofyear','dayofmonth','weekofyear']]\n    if label:\n        y = df[label]\n        return X, y\n    return X","5f7393f6":"#data split\nX_train, y_train = create_features(data_train, label='Weighted_Price')\nX_test, y_test = create_features(data_test, label='Weighted_Price')","7d1a22d5":"model =  xgb.XGBRegressor(objective ='reg:linear',min_child_weight=10, booster='gbtree', colsample_bytree = 0.3, learning_rate = 0.1,\n                max_depth = 5, alpha = 10, n_estimators = 100)\nmodel.fit(X_train, y_train,\n        eval_set=[(X_train, y_train), (X_test, y_test)],\n        early_stopping_rounds=50,\n       verbose=False) ","2f69d749":"data_test['Weighted_Price_Prediction'] = model.predict(X_test)\ndata_all = pd.concat([data_test, data_train], sort=False)","330f08c9":"_ = data_all[['Weighted_Price','Weighted_Price_Prediction']].plot(figsize=(15, 5))","742722c3":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='08-01-2018', upper='09-01-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('August 2018 Forecast vs Actuals')","af55fd48":"# Plot the forecast with the actuals\nf, ax = plt.subplots(1)\nf.set_figheight(5)\nf.set_figwidth(15)\n_ = data_all[['Weighted_Price_Prediction','Weighted_Price']].plot(ax=ax,\n                                              style=['-','.'])\nax.set_xbound(lower='08-01-2018', upper='08-08-2018')\nax.set_ylim(0, 10000)\nplot = plt.suptitle('First Week of August 2018 Forecast vs Actuals')","155d1ad2":"print(\"MSE of XGBoost: \",mean_squared_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test['Weighted_Price_Prediction']))","be6efaae":"print(\"MAE of XGBoost: \",mean_absolute_error(y_true=data_test['Weighted_Price'],\n                   y_pred=data_test['Weighted_Price_Prediction']))","74a34e79":"data = pd.read_csv('..\/input\/bitcoin-historical-data\/coinbaseUSD_1-min_data_2014-12-01_to_2019-01-09.csv',parse_dates=[0], date_parser=dateparse) ","73c78b52":"data['Volume_(BTC)'].fillna(value=0, inplace=True)\ndata['Volume_(Currency)'].fillna(value=0, inplace=True)\ndata['Weighted_Price'].fillna(value=0, inplace=True)\n\n# next we need to fix the OHLC (open high low close) data which is a continuous timeseries so\n# lets fill forwards those values...\ndata['Open'].fillna(method='ffill', inplace=True)\ndata['High'].fillna(method='ffill', inplace=True)\ndata['Low'].fillna(method='ffill', inplace=True)\ndata['Close'].fillna(method='ffill', inplace=True)","39e80bb0":"#seasonality by monthly\ndecomposition = sm.tsa.seasonal_decompose(data.Weighted_Price,freq=3)\n\ntrend = decomposition.trend\nseasonal = decomposition.seasonal\nresidual = decomposition.resid\n\nfig = plt.figure(figsize=(20,8))\n\nplt.subplot(411)\nplt.plot(data.Weighted_Price, label='Original')\nplt.legend(loc='best')\nplt.subplot(412)\nplt.plot(trend, label='Trend')\nplt.legend(loc='best')\nplt.subplot(413)\nplt.plot(seasonal,label='Seasonality')\nplt.legend(loc='best')\nplt.subplot(414)\nplt.plot(residual, label='Residuals')\nplt.legend(loc='best')\n\nfig.suptitle('Decomposition of Prices Data')\nplt.show()","29eadf25":"data = pd.read_csv('..\/input\/bitcoin-historical-data\/bitstampUSD_1-min_data_2012-01-01_to_2019-08-12.csv',parse_dates=[0], date_parser=dateparse) ","a9c1483f":"data.head()","5a86428d":"data.Timestamp = pd.to_datetime(data.Timestamp, unit = 's')\ndata.index = data.Timestamp\ndata = data.resample('M').mean()","3835ca29":"data.head()","9584e044":"data.isnull().sum()","8bfa7d50":"price=data[\"Weighted_Price\"]\nplt.figure(figsize = (14,6))\nsns.lineplot(x = data.index, y = price)","aa19ed1b":"def decompose(series):\n    plt.figure(figsize = (14,7))\n    seasonal_decompose(series).plot()\n    plt.show()\n    \ndef DFTest(series):\n    testdf = adfuller(series)\n    print(\"DF test p-value : %.16f\" %testdf[1] )\n    \n    \ndef plots(series):\n    plt.figure(figsize = (10,6))\n    sns.lineplot(data = series, color = 'blue', label = 'observed line plot')\n    sns.lineplot(data = series.rolling(window = 12).mean(), color = 'green', label = 'rolling mean, window -12')\n    sns.lineplot(data = series.rolling(window = 12).std(), color = 'black', label = 'std deviation, window -12')","0998ce96":"print(\"DF Test->\")\n#running tests\nDFTest(price)\ndecompose(price)\nplots(price)","c6f8266f":"#1. Log Transformation","4130fced":"prices_log = np.log(price)\n\n#running tests\nDFTest(prices_log)\ndecompose(prices_log)\nplots(prices_log)","fade0fd4":"#prices_log with regular shift transform\nprices_log_r = prices_log - prices_log.shift(1)\nprices_log_r.dropna(inplace = True)\n\nDFTest(prices_log_r)\ndecompose(prices_log_r)\nplots(prices_log_r)","f33067d0":"#2. Box Cox Transformation","e39175bb":"prices_box_cox_, lambda_ = boxcox(price)\nprices_box_cox = pd.Series(data = prices_box_cox_, index = data.index) #decompose functions requires a pandas object that has a timestamp index.\n\ndecompose(prices_box_cox) \nDFTest(prices_box_cox)\nprint('lambda value:', lambda_)\nplots(prices_box_cox)","a993a0d4":"#Regular Time shift added to Box Cox transformation","37368e77":"prices_box_cox_r = prices_box_cox - prices_box_cox.shift(1)\nprices_box_cox_r.dropna(inplace = True)\n\ndecompose(prices_box_cox_r) \nDFTest(prices_box_cox_r)\nplots(prices_box_cox_r)","6b7f084b":"plt.figure(figsize = (14,7)) \na = acf(prices_log_r)\np = pacf(prices_log_r)\n\nplt.subplot(221)\nsns.lineplot(data = a)\nplt.axhline(y=0, linestyle='--', color='gray')\n\nplt.subplot(222)\nsns.lineplot(data = p)\nplt.axhline(y=0, linestyle='--', color='gray')","e7aa76c2":"#We infer from the plot that The ACF and PACF gets close to zero while lag approaches 1.","12b180b3":"data.head()","f78b50b3":"a = [[1,2,3], [1],[1,2,3]]\nparams = list(product(*a))\n\nresults = []   \nmin_aic = float('inf')\nbest_param = []\n\n# checking different set of params for best fit\nfor param in params:\n    try:\n        model = ARIMA(prices_log, order = param).fit(disp = -1)\n    except LinAlgError:\n        print('Rejected Parameters:', param)\n        continue\n    except ValueError:\n        print('Rejected Parameters:', param)\n        continue\n    if(min_aic > model.aic):\n        min_aic = model.aic\n        best_param = param\n        best_model = model\n        \n    results.append([param, model.aic])\n\nprint(best_param,min_aic)\nprint(results)\n\nprint(best_model.fittedvalues)\n\nplt.figure(figsize=(16,8))\nsns.lineplot(data = prices_log_r, color = 'blue')\nsns.lineplot(data = best_model.fittedvalues, color = 'red') ","9d64cb74":"fitted_values = best_model.fittedvalues\nfitted_values = fitted_values.cumsum()\n\nfitted_values = fitted_values + prices_log[0]\n\nfinal_values = np.exp(fitted_values)\n\nd = {'prices' : price, 'prices_log' : prices_log, 'price_log_r' : prices_log_r, 'fitted_values' : fitted_values, 'final_values' : final_values}\nsummaryDF = pd.DataFrame(data = d)\nsns.lineplot(data = summaryDF['prices'], color = 'green')\nsns.lineplot(data = summaryDF['final_values'], color = 'red')","2f215fe6":"predicted_values = np.exp((best_model.predict(start = 1, end = 99).cumsum()) + prices_log[0])\nsns.lineplot(data = price, label  = 'recorded')\nsns.lineplot(data = predicted_values, label = 'predicted')","09a943e7":"ACF and PACF","1401556c":"# Trial","a2500328":"# ARIMA Model","dce92b6d":"# XGBoost","c8d81688":"With the visualisation and the p value of the DF test (>0.05) we can state that the series is not stationary and hence, we can't apply ARIMA model to it just yet. we will now transform our TS to fit ARIMA","49b1c2f4":"using ARIMA model for forecasting,\nbefore that checking our TS is having stationary or not? ,by Seasonal Trend Decomposition and DF Test"}}