{"cell_type":{"21452a72":"code","a937b5ed":"code","9ca20235":"code","e258f2b8":"code","95c15286":"code","916ca7dc":"code","875b99c1":"code","e9e77c3a":"code","2d4365f8":"code","18ec5c4d":"code","8792639e":"code","29006dbe":"code","a08a9b0c":"code","f318630b":"code","82be5cc0":"code","e571f390":"code","29798ffa":"code","225b5d36":"code","5d1435ba":"code","cca1e985":"code","4c08be3b":"code","b332af3e":"code","01048d9f":"code","09109d3a":"code","fcf3c532":"code","ea6fa6df":"code","ab5dd3b5":"code","1ce3a61a":"code","ee54f216":"code","0a5a50a4":"code","d99c538c":"code","27705936":"code","300bb576":"code","2b568b50":"code","479b379f":"code","dd09e1ae":"code","fb15043f":"markdown","2c46662d":"markdown","22a9cdc6":"markdown","9a0af14e":"markdown","5fa75811":"markdown","e4761723":"markdown","f413bb00":"markdown","89b8aa56":"markdown","ed5faf0c":"markdown","0272c8ca":"markdown"},"source":{"21452a72":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\nimport gc\n\n# plot\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n# machine learning tools\nimport h2o\nfrom h2o.estimators import H2OGeneralizedLinearEstimator, H2ORandomForestEstimator, H2OGradientBoostingEstimator","a937b5ed":"# configuration to show all columns in output\npd.set_option('display.max_columns', None)","9ca20235":"# load data (this takes some time)\nt1 = time.time()\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\ndf_sub = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/sample_submission.csv')\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","e258f2b8":"# dimensions\nprint('Train Set:', df_train.shape)\nprint('Test Set :', df_test.shape)","95c15286":"# structure of data frame\ndf_train.info(verbose=True, show_counts=True)","916ca7dc":"df_test.info(verbose=True, show_counts=True)","875b99c1":"# basic stats\nprint(df_train.target.value_counts())\ndf_train.target.value_counts().plot(kind='bar')\nplt.grid()\nplt.show()","e9e77c3a":"# plot target vs binary features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in ['f22', 'f43']:\n    plt.rcParams['figure.figsize'] = (6,4) # increase plot size for mosaics\n    mosaic(df_train, [f, 'target'], title='Target vs ' + f)\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save","2d4365f8":"# plot target vs BINNED numerical features using mosaic plot\nplt_para_save = plt.rcParams['figure.figsize'] # remember plot settings\n\nfor f in ['f179','f69']:\n    # add binned version of each numerical feature first\n    new_var = f + '_bin'\n    df_train[new_var] = pd.qcut(df_train[f], 8)\n    # then create mosaic plot\n    plt.rcParams['figure.figsize'] = (16,6) # increase plot size for mosaics\n    mosaic(df_train, [new_var, 'target'], title='Target vs ' + f + ' [binned]')\n    plt.show()\n    \n# reset plot size again\nplt.rcParams['figure.figsize'] = plt_para_save\n\n# remove temporary columns\ndf_train = df_train.drop(['f69_bin','f179_bin'], axis=1)","18ec5c4d":"# extract list of features\nfeatures_num = df_train.columns.tolist()\nfeatures_num.remove('id')\nfeatures_num.remove('target')","8792639e":"# basic stats\ndf_train[features_num].describe()","29006dbe":"# boxplot of all features\nn_plot_rows = 15\nn_plot_cols = 19\nfor i in range(n_plot_rows):\n    print('Columns', n_plot_cols*i+1 , 'to', n_plot_cols*i+n_plot_cols)\n    df_train.iloc[:,n_plot_cols*i+1:n_plot_cols*i+n_plot_cols+1].plot(kind='box', figsize=(15,5))\n    plt.xticks(rotation=90)\n    plt.grid()\n    plt.show()","a08a9b0c":"# select binary features\nfeatures_bin = ['f22','f43'] + ['f'+str(i) for i in range(242,284+1)]\nprint(features_bin)","f318630b":"# identify also float features\nfeatures_float = list(set(features_num) - set(features_bin))","82be5cc0":"# plot binary features\nfor f in features_bin:\n    plt.figure(figsize=(4,3))\n    df_train[f].value_counts().sort_index().plot(kind='bar')\n    plt.title(f)\n    plt.grid()\n    plt.show()","e571f390":"# select predictors\npredictors = features_num\nprint('Number of predictors: ', len(predictors))","29798ffa":"# remove test set to reduce RAM footprint\ndel df_test","225b5d36":"# convert training data to reduce RAM footprint\ndf_train[features_bin] = df_train[features_bin].astype(np.uint8)\ndf_train[features_float] = df_train[features_float].astype(np.float32)\ndf_train.target = df_train.target.astype(np.uint8)","5d1435ba":"# garbage collection\ngc.collect();","cca1e985":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # define maximum memory usage and number of cores","4c08be3b":"# upload data in H2O environment\nt1 = time.time()\n# use SUBSET of training data only for lower RAM footprint:\nn_sub = 500000\ndf_train_sub = df_train.sample(n=n_sub, random_state=999)\ntrain_hex = h2o.H2OFrame(df_train_sub)\n# train_hex = h2o.H2OFrame(df_train) # use all data\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,4))\n\n# force categorical target\ntrain_hex['target'] = train_hex['target'].asfactor()","b332af3e":"# remove original training data frame\ndel df_train\ngc.collect();","01048d9f":"# fit Gradient Boosting model\nn_cv = 5\n\nfit_GBM = H2OGradientBoostingEstimator(ntrees=250,\n                                       max_depth=6,\n                                       min_rows=10,\n                                       learn_rate=0.1, # default: 0.1\n                                       sample_rate=1,\n                                       col_sample_rate=0.5,\n                                       nfolds=n_cv,\n                                       score_each_iteration=True,\n                                       stopping_metric='auc',\n                                       stopping_rounds=5,\n                                       stopping_tolerance=0.0001*0.5,\n                                       seed=999)\n# train model\nt1 = time.time()\nfit_GBM.train(x=predictors,\n              y='target',\n              training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","09109d3a":"# show cross validation metrics\nfit_GBM.cross_validation_metrics_summary()","fcf3c532":"# show scoring history - training vs cross validations\nfor i in range(n_cv):\n    cv_model_temp = fit_GBM.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History [AUC]'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_auc, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_auc, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.ylabel('AUC')\n    plt.ylim(0.8,0.9)\n    plt.legend()\n    plt.grid()\n    plt.show()","ea6fa6df":"# variable importance\nfit_GBM.varimp_plot()","ab5dd3b5":"# alternative variable importance using SHAP => see direction as well as severity of feature impact\nt1 = time.time()\nfit_GBM.shap_summary_plot(train_hex);\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","1ce3a61a":"# training performance\nperf_train = fit_GBM.model_performance(train=True)\nperf_train.plot()","ee54f216":"# cross validation performance\nperf_cv = fit_GBM.model_performance(xval=True)\nperf_cv.plot()","0a5a50a4":"# predict on train set (extract probabilities only)\npred_train_GBM = fit_GBM.predict(train_hex)['p1']\npred_train_GBM = pred_train_GBM.as_data_frame().p1\n\n# plot train set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_train_GBM, bins=100)\nplt.title('Predictions on Train Set - GBM')\nplt.grid()\nplt.show()","d99c538c":"# calibration\nn_actual = sum(df_train_sub.target)\nn_pred_GBM = sum(pred_train_GBM)\n\nprint('Actual Frequency    :', n_actual)\nprint('Predicted Frequency :', n_pred_GBM)\nprint('Calibration Ratio   :', n_pred_GBM \/ n_actual)","27705936":"# memory management\nh2o.remove(train_hex)\ngc.collect();","300bb576":"# reload test set into memory\nt1 = time.time()\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-oct-2021\/test.csv')\nt2 = time.time()\nprint('Elapsed time [s]:', np.round(t2-t1,4))","2b568b50":"# upload data in H2O environment\nt1 = time.time()\ntest_hex = h2o.H2OFrame(df_test)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,4))","479b379f":"# predict on test set (extract probabilities only)\npred_test_GBM = fit_GBM.predict(test_hex)['p1']\npred_test_GBM = pred_test_GBM.as_data_frame().p1\n\n# plot test set predictions (probabilities)\nplt.figure(figsize=(8,4))\nplt.hist(pred_test_GBM, bins=100)\nplt.title('Predictions on Test Set - GBM')\nplt.grid()\nplt.show()","dd09e1ae":"# GBM submission\ndf_sub_GBM = df_sub.copy()\ndf_sub_GBM.target = pred_test_GBM\ndisplay(df_sub_GBM.head())\n# save to file\ndf_sub_GBM.to_csv('submission_GBM.csv', index=False)","fb15043f":"<a id='1'><\/a>\n# Import and first checks","2c46662d":"### Impact of Features on Target (examples)","22a9cdc6":"# Table of Contents\n* [Import and First Checks](#1)\n* [Target](#2)\n* [Features](#3)\n* [Model](#4)\n* [Prediction on Test Set and Submission](#5)","9a0af14e":"### => no missing values!","5fa75811":"<a id='5'><\/a>\n# Prediction on Test Set and Submission","e4761723":"### Features f22, f43 and f242..f284 are of binary structure, let's plot them separately:","f413bb00":"<a id='3'><\/a>\n# Features","89b8aa56":"<a id='2'><\/a>\n# Target","ed5faf0c":"### => Nicely balanced!","0272c8ca":"<a id='4'><\/a>\n# Model"}}