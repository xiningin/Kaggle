{"cell_type":{"7f43173f":"code","4719b9b5":"code","f7ed1535":"code","f5904763":"code","27918178":"code","4a711031":"code","611d94cf":"code","2b8e089b":"code","11d8cf3c":"code","b5762636":"code","c5912f3c":"code","7b8d87a5":"code","de086fa8":"code","912af2a8":"code","3a8bcbc8":"code","2ef18c46":"code","e1ad3eb3":"code","2be664a0":"markdown","6108c89c":"markdown","1ed467f8":"markdown","c24a552a":"markdown","ce82268b":"markdown","b1ba621a":"markdown","95ac60c1":"markdown","38549df4":"markdown","5b3ff928":"markdown","de5358f9":"markdown","e720d8ab":"markdown","1e57ca55":"markdown","6e54b3d2":"markdown","1740bcdb":"markdown","b6f45de0":"markdown","c9359dd3":"markdown","c7b1353f":"markdown","ea93fbef":"markdown","064686f8":"markdown","d4732342":"markdown","010a1e58":"markdown","42b0d258":"markdown","19d57536":"markdown","10a0ac18":"markdown","3e6a3338":"markdown","c95f0ec1":"markdown","520e322d":"markdown","82ac9256":"markdown","f30b1a5f":"markdown","812836c0":"markdown","1856ef75":"markdown","ef3d9a37":"markdown"},"source":{"7f43173f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4719b9b5":"from selenium import webdriver\nfrom selenium.webdriver.common.by import By\nfrom selenium.webdriver.support.ui import WebDriverWait\nfrom selenium.webdriver.support import expected_conditions as EC\nimport pandas as pd\n\npath = \"\/Users\/macbookpro\/Documents\/ChromeDriver\/chromedriver\" # Chrome web driver\ndriver = webdriver.Chrome(path)\ndriver.get(\"https:\/\/www.imdb.com\/title\/tt5052448\/reviews?ref_=tt_urv\") # Movie link to be scraped\n\nmovie_name = driver.find_element_by_class_name(\"parent\").text # scrape movie name \nmovie_name = movie_name.replace(\" \", \"_\") # replace spaces with _\nmovie_name = movie_name.lower() + \".csv\" # save full movie name with csv extension\n\n# For loop below will click load button to load all reviews\nfor i in range(64): # 25reviews per page. 1600 reviews in total = 1600\/25 = 64 pages\n    try:\n        button = WebDriverWait(driver, 30).until(\n            EC.presence_of_element_located((By.ID, \"load-more-trigger\")) \n        )\n        button.click()\n\n    except:\n        driver.implicitly_wait(5)\n\n\nreviews = []\ntry:\n    # find all reviews\n    all_reviews = WebDriverWait(driver, 30).until(\n        EC.presence_of_all_elements_located((By.CLASS_NAME, \"content\"))\n    )\n    # find all ratings\n    all_ratings = WebDriverWait(driver, 30).until(\n        EC.presence_of_all_elements_located((By.CLASS_NAME, \"rating-other-user-rating\"))\n    )\n    full_review = \"\"\n    # create review like rating | review and append it to the reviews list\n    for i, j in zip(all_ratings,all_reviews):\n        full_review = i.text + \" | \" + j.text\n        reviews.append(full_review)\n\nexcept:\n    driver.quit()\n\n# convert list to the dataframe and save it like csv format\ndf = pd.DataFrame(reviews)\ndf.rename(columns={0 : \"Review\"},inplace=True)\ndf.to_csv(movie_name)","f7ed1535":"df = pd.read_csv('\/kaggle\/input\/movies\/get_out_(i)_(2017).csv')\nprint(df.head())","f5904763":"df.rename(columns={\"Unnamed: 0\" : \"Movie_ID\"},inplace=True)","27918178":"df[\"Rating\"] = df[\"Review\"].apply(lambda x: x.split(\"|\")[0])\ndf[\"Review\"] = df[\"Review\"].apply(lambda x: x.split(\"|\")[1])\nprint(df.head())","4a711031":"df['Review'].replace(\" \", np.nan, inplace=True) # replacing space with nan\n\ndf.dropna(inplace=True) #drop nan values, coz some of review didn't have actual review\ndf[\"Review\"] = df[\"Review\"].str.lower() # Converting everything to lower coz \"Movie\" and \"movie\" is not the same thing\n\n# Removing special characters from Reviews\nspec_chars = [\"\u00b1\",\"@\",\"#\",\"$\",\"%\",\"^\",\n                 \"&\",\"*\",\"(\",\")\",\"_\",\"+\",\"=\",\n                 \"-\",\"\/\",\">\",\"<\",\"?\",\n                 \"~\",\"`\",\"'\",\"[\",\"]\",\"|\",\"}\",\n                 \"{\",'\"', \".\",\",\",\"!\",\";\"]\n\nfor char in spec_chars:\n    df[\"Review\"] = df[\"Review\"].str.replace(char, \"\")\n\ndf[\"Review\"].apply(lambda x: x.encode('ascii', 'ignore').decode('ascii')) # getting rid of emojis\n\ndf['Review'] = df['Review'].str.replace('\\d+', '') # Remove numbers from Reviews","611d94cf":"df[\"Rate\"] = df[\"Rating\"].apply(lambda x: x.split(\"\/\")[0])\ndf[\"Rate\"] = pd.to_numeric(df[\"Rate\"])\n\nfor i in range(len(df)):\n    if (df[\"Rate\"].iloc[i] < 5):\n        df[\"Rating\"].iloc[i] = \"negative\"\n    else:\n        df[\"Rating\"].iloc[i] = \"positive\"\n        \ndf.to_csv(\"get_out_cleaned.csv\")","2b8e089b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom nltk.corpus import stopwords\nfrom nltk.tokenize import word_tokenize\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import ComplementNB\nfrom wordcloud import WordCloud, STOPWORDS\n\ndf = pd.read_csv('\/kaggle\/input\/movies\/get_out_cleaned.csv')\ndf.drop(columns=[\"Unnamed: 0\"],inplace=True)\nprint(df.head())","11d8cf3c":"stop_words = set(stopwords.words('english')) # eng stopwords\ndf['tokenized_reviews'] = df.apply(lambda row: word_tokenize(row['Review']), axis=1) # Tokenization of reviews\ndf[\"filtered\"] = df['tokenized_reviews'].apply(lambda x: [item for item in x if item not in stop_words]) #Removing stopwrods from tokenized data","b5762636":"df['filtered']=df['filtered'].apply(str)\ncv = CountVectorizer(lowercase=False,stop_words='english',binary=True)\ncv.fit(df[\"filtered\"])","c5912f3c":"X = cv.transform(df[\"filtered\"])\ny = df[\"Rating\"]\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.3)","7b8d87a5":"logModel = LogisticRegression(penalty='l2',max_iter=1000,C=0.3)\nlogModel.fit(X_train,y_train)\nprint(\"Logistic Regression accuracy score: {}\".format(accuracy_score(y_test, logModel.predict(X_test))))","de086fa8":"errors = []\nfor k in range(1,100):\n    model = KNeighborsClassifier(n_neighbors=k)\n    model.fit(X_train,y_train)\n    pred = model.predict(X_test)\n    errors.append(np.mean(pred!=y_test))\nplt.plot(range(1,100),errors)\nplt.show()","912af2a8":"knn = KNeighborsClassifier(n_neighbors=25)\nknn.fit(X_train,y_train)\nprint(\"K-Nearest Neighbours accuracy score: {}\".format(accuracy_score(y_test, knn.predict(X_test))))","3a8bcbc8":"MNB = MultinomialNB()\nMNB.fit(X_train,y_train)\nprint(\"Multinomial Naive Bayes accuracy score: {}\".format(accuracy_score(y_test, MNB.predict(X_test))))","2ef18c46":"CNB = ComplementNB()\nCNB.fit(X_train,y_train)\nprint(\"Complement Naive Bayes accuracy score: {}\".format(accuracy_score(y_test, CNB.predict(X_test))))","e1ad3eb3":"stopwords = set(STOPWORDS)\nwordcloud = WordCloud(width = 800, height = 800,\n                      background_color ='white',\n                      stopwords = stopwords,\n                      min_font_size = 10).generate(' '.join(df['filtered']))\n\nplt.figure(figsize = (8, 8), facecolor = None)\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad = 0)\nplt.show()","2be664a0":"Right now I will focus on cleaning the \"Review\" columns","6108c89c":"Now, I will split \"Review\" column on \"|\" and store Rating on new column called \"Rating\" and \"Review\" column will just have Review.","1ed467f8":"Models with an average accuracy of 78% on a dataset of about 1600 proved to be more than good. The model would work even better on a larger dataset.\nThis project can be improved by adding XGBoost, and it would also be interesting to try TextBlob!\nPlease upvote this if you want to see how it would be to try XGBoost and TextBlob. :)","c24a552a":"# <span style=\"color:khaki\">Sentiment Analysis: IMDB Movies<\/span>","ce82268b":"Let's import the libraries and load cleaned dataframe.","b1ba621a":"# <a id='Multinomial-Naive-Bayes' style=\"color:khaki\">**Multinomial Naive Bayes**","95ac60c1":"**Tokenization** is the process of converting text into tokens before transforming it into vectors. It is also easier to filter out unnecessary tokens. For example, a document into paragraphs or sentences into words. In this case we are tokenising the reviews into words.","38549df4":"# <a id='Tokenization' style=\"color:khaki\">**Tokenization**","5b3ff928":"# <a id='Web-Scraping' style=\"color:khaki\" >**Web Scraping**\n","de5358f9":"# <a id='Word-Cloud' style=\"color:khaki\">**Word Cloud**","e720d8ab":"![](https:\/\/monkeylearn.com\/static\/3ca10d6ce5dc6922836f278aef38f765\/50bf7\/what-is-sentiment-analysis6%402x.png)","1e57ca55":"A Wordcloud is a visual representation of text data. It displays a list of words, the importance of each beeing shown with font size or color.","6e54b3d2":"# <a id='KNN' style=\"color:khaki\">**KNN**","1740bcdb":"Let's initialize our feature and target and do the train test split.","b6f45de0":"# <a id='Introduction' style=\"color:khaki\" >**Introduction**","c9359dd3":"# <a id='Conclusion' style=\"color:khaki\">**Conclusion**","c7b1353f":"# <a id='Sentiment-Analysis' style=\"color:khaki\">**Sentiment Analysis**","ea93fbef":"\nSince I can't do web scraping directly from Kaggle, I'll leave my code here for you to see how I got the data.","064686f8":"# <a id='Data-Cleansing' style=\"color:khaki\" >**Data Cleansing**\n","d4732342":"*Therefore, the scraper first clicks the button to load all the reviews. When it loads all the reviews, then it looks for the review and rating elements and stores them in a string and then adds that string to the list.\nLater we convert the list into dataframe and save it as csv format.*","010a1e58":"# <a id='Count-Vectorizer' style=\"color:khaki\">**Count Vectorizer**","42b0d258":"![](https:\/\/exstreamist.com\/wp-content\/uploads\/2015\/10\/imdb-top-250.jpg)","19d57536":"**In this notebook you'll see:**\n* How to use Selenium to scrape movies reviews from IMDB\n* How to clean the data\n* What is Sentiment Analysis\n* How to use natural language processing (NLP) techniques","10a0ac18":"# <span style=\"color:khaki\">**Content**<span>\n- [Introduction](#Introduction) <a href = '#Introduction'><\/a>\n- [Web Scraping](#Web-Scraping) <a href = '#Web-Scraping'><\/a>   \n- [Data Cleansing](#Data-Cleansing) <a href = '#Data-Cleansing'><\/a>\n- [Sentiment Analysis](#Sentiment-Analysis) <a href = '#Sentiment-Analysis'><\/a>\n- [Tokenization](#Tokenization) <a href = '#Tokenization'><\/a>\n- [Count Vectorizer](#Count-Vectorizer) <a href = '#Count-Vectorizer'><\/a>\n- [Models](#Models) <a href = '#Models'><\/a>\n- [Logistic Regression](#Logistic-Regression) <a href = '#Logistic-Regression'><\/a>\n- [K-Nearest Neighbours](#KNN) <a href = '#KNN'><\/a>\n- [Multinomial Naive Bayes](#Multinomial-Naive-Bayes) <a href = '#Multinomial-Naive-Bayes'><\/a>\n- [Complement Naive Bayes](#Complement-Naive-Bayes) <a href = '#Complement-Naive-Bayes'><\/a>\n- [Word Cloud](#Word-Cloud) <a href = '#Word-Cloud**'><\/a>\n- [Conclusion](#Conclusion) <a href = '#Conclusion**'><\/a>\n\n\n\n","3e6a3338":"Now is the time to turn the review column into Positive and Negative reviews. We will get rid of the slash and the number ten. So, \"N\/10\" we want to save the  N because it is actually the rating left by the user. We will then convert the column to numeric and use the for loop to convert ratings less than 5 to negative and ratings greater than or equal to 5 to positive.","c95f0ec1":"First of all I will rename \"Unnamed: 0\" column to the \"Movie_ID\"","520e322d":"Let's choose the best K value.","82ac9256":"**Sentiment Analysis is the process of determining whether a piece of writing is positive, negative or neutral.** A sentiment analysis system for text analysis combines natural language processing (NLP) and machine learning techniques to assign weighted sentiment scores to the entities, topics, themes and categories within a sentence or phrase.\n\nUsing sentiment analysis could help you discover if customers are happy about your pricing plans, customer service, etc.","f30b1a5f":"# <a id='Models' style=\"color:khaki\">**Models**","812836c0":"# <a id='Complement-Naive-Bayes' style=\"color:khaki\">**Complement Naive Bayes**","1856ef75":"# <a id='Logistic-Regression' style=\"color:khaki\">**Logistic Regression**","ef3d9a37":"**CountVectorizer** is used to convert a collection of text documents to a vector of term\/token counts.\n\nFor example words=[\"movie\",\"good\",\"perfect,\"good\"] would transform to: \"movie\" = 1, \"good\" = 2,\"perfect\" = 1."}}