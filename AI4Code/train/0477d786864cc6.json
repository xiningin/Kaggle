{"cell_type":{"21a9cb64":"code","1f86f348":"code","5fa6e3a7":"code","b8152e80":"code","43ce4ad0":"code","cac81893":"code","2f4801d1":"code","b7dbd04c":"code","2293d291":"code","72c68527":"markdown","29014911":"markdown"},"source":{"21a9cb64":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom pandas_profiling import ProfileReport\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1f86f348":"df = pd.read_csv(\"\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv\")\nprof = ProfileReport(df)\nprof.to_file(output_file='output.html')\n","5fa6e3a7":"prof","b8152e80":"cols = df.columns\ncols = list(cols)\ncols","43ce4ad0":"y = df['stroke']\nX = df[set(cols)-set(['id', 'stroke'])]\nX.head()","cac81893":"y.head()","2f4801d1":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33)","b7dbd04c":"from sklearn.pipeline import make_pipeline\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\n\nflow = make_pipeline(\n    OneHotEncoder(handle_unknown='ignore'),\n    SimpleImputer(),\n    RandomForestClassifier(n_jobs=4, verbose=True, n_estimators=200, max_depth=10)\n    )\n\nflow.fit(X_train, y_train)\nflow.score(X_test, y_test)","2293d291":"from sklearn.svm import SVC\nfor ker in ['rbf', 'poly', 'sigmoid']:\n    flow_svm = make_pipeline(\n        OneHotEncoder(handle_unknown='ignore'),\n        SimpleImputer(),\n        SVC(verbose=True, kernel=ker)\n        )\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state=500)\n    flow.fit(X_train, y_train)\n    print(f'For kernel:{ker} score: {flow.score(X_test, y_test)}')","72c68527":"## Correlation:","29014911":"![image.png](attachment:image.png)"}}