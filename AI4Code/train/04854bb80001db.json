{"cell_type":{"e7e79cb4":"code","c91b3567":"code","fa933c63":"code","bd08b546":"code","8e8f1a8c":"code","16d708b7":"code","37ba049c":"code","32ef473f":"code","baa679d1":"code","4f6ab384":"code","a9ca0eef":"code","a1939363":"code","ed3e4a5e":"code","2aec5865":"code","927e435d":"code","8697ede7":"code","6f261450":"code","a44cbdbe":"code","cf0ddad5":"code","e52834f2":"code","1806b952":"code","2d06bfd6":"code","e6dd41bd":"code","6b5afaa8":"code","05aa3e44":"code","e199c701":"code","86255e2a":"code","ab6c163e":"code","973cd3a1":"code","ff5815c5":"code","53e92713":"code","2d337750":"code","5052cd63":"code","c6c16d98":"code","63f3843c":"code","a7b39590":"code","ef77c8f5":"code","6ffcd87f":"code","6e15b1fb":"code","5a59916c":"code","48a7d6a3":"code","14b62c62":"code","c1bd7be4":"code","629c5dbc":"code","0b1c102c":"code","4371c738":"code","97c3ce7d":"code","87d0083e":"code","3e154407":"markdown","48a7ba9a":"markdown","04f65c17":"markdown","394383b9":"markdown","12eec65f":"markdown","fc1c208d":"markdown","d237fa4b":"markdown","1b2b4c84":"markdown","9ff927a2":"markdown","955b03c2":"markdown","41966b1b":"markdown","326473bc":"markdown","90b7cf26":"markdown","d1ce864a":"markdown","473d2bc8":"markdown"},"source":{"e7e79cb4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom datetime import datetime as dt\nfrom tqdm import tqdm_notebook, tqdm\nfrom tqdm._tqdm_notebook import tqdm_notebook\nimport time\nimport warnings\nwarnings.filterwarnings(action='ignore')\nfrom collections import OrderedDict, defaultdict\nimport subprocess\nimport json\nimport csv\nimport gc\nfrom itertools import chain, islice\nimport itertools\nimport os\n\n\nfrom typing import Dict #dict\ud615\uc2dd \nfrom collections import Counter #\ub3d9\uc77c\ud55c\uac12\uc758 \uc790\ub8cc\uac00 \uba87\uac1c\uc778\uc9c0 \ud30c\uc545\ud558\ub294\ub370 \uc0ac\uc6a9\n\n#import missingno as msno\n#\ud55c\uae00\uae68\uc9d0\ubc29\uc9c0\nplt.rc('font',family='Malgun Gothic')\nplt.rcParams['axes.unicode_minus'] = False\n\nfrom IPython.core.display import display, HTML\ndisplay(HTML('<style>.container {width:100% !important; }<\/style>'))\n\npd.options.display.max_columns = 900","c91b3567":"# #CSV\n# path = '.\/001.data\/'\n# train_df = pd.read_csv(path + 'train.csv')\n# test_df = pd.read_csv(path + 'test.csv')\n# train_labels_df = pd.read_csv(path +'train_labels.csv')\n# sample_submission = pd.read_csv(path +'sample_submission.csv')\n# train_df.shape, test_df.shape,train_labels_df.shape","fa933c63":"path = '\/kaggle\/input\/data-science-bowl-2019\/'\ntrain_df = pd.read_csv(path+'train.csv')\ntest_df = pd.read_csv(path+'test.csv')\ntrain_labels_df = pd.read_csv(path+'train_labels.csv')\nsample_submission = pd.read_csv(path+'sample_submission.csv')","bd08b546":"def info_df(data):\n    '''\n    data\uc758 type, null_count, null_rate\ub97c \uc54c\ub824\uc8fc\ub294 \ud568\uc218 \n    \ucd94\uac00\ub85c unique\ud55c \ub370\uc774\ud130\uc758 \uc218\ub97c \uc54c\ub824\uc90c (\uc18d\ub3c4\uac00 \ub290\ub9ac\ubbc0\ub85c \ud544\uc694\uc2dc \uc8fc\uc11d\ucc98\ub9ac \ud544\uc694)\n    '''\n    info_df = pd.DataFrame({\"type\":data.dtypes,\n                            'null_count':data.isnull().sum(),\n                           'null_rate':data.isnull().sum()\/data.isnull().count() * 100})\n    \n#     cols = data.columns.values\n    \n#     uni_count =[]\n#     for col in cols:\n#         uni_count.append(len(data[col].unique()))\n#     info_df['uni_count'] = uni_count\n    \n    return info_df","8e8f1a8c":"#feature importance\ndef model_fi(model,origin_df):\n    '''\n    \ubaa8\ub378\uc758 feature_importance\ub97c \ud655\uc778\ud558\uc5ec, origin_df\uc758 \uceec\ub7fc\uba85\uc5d0 \ub530\ub978 DF\uc0dd\uc131\n    importance\uc758 \ube44\uc728 \ubc0f \ub204\uc801\ud569 \ub610\ud55c \uc0b0\ucd9c   \n    '''    \n    fi_df = pd.DataFrame({'importance': model.feature_importances_},index = origin_df.columns)\n    fi_df = fi_df.sort_values(by ='importance', ascending=False)\n    fi_df['importance'] = round(fi_df['importance'],4)\n    fi_df['rate'] = (fi_df.importance\/fi_df.importance.sum()*100)\n    fi_df['rate_cumsum'] = fi_df.rate.cumsum()\n    \n    return fi_df","16d708b7":"# data_mid = pd.DataFrame()\n# for ins_id, user_sample in tqdm_notebook(train_s.iloc[:57].groupby('installation_id', sort = False)):\n#     as_indexs = user_sample.loc[(user_sample.type.isin(['Assessment']))&\n#                                 (user_sample.accuracy_group.notnull())].index.values\n#     last_index = as_indexs[-1]\n# #     last_index = user_sample.index.max()\n#     sess_df = pd.DataFrame()\n#     #user_sample.drop(columns='accuracy_group', axis=1, inplace=True)\n#     for as_index in as_indexs:\n#         #iloc\ub97c \uc4f0\uba74 as_index\uc5d0 +1 \n#         #loc\ub97c \uc4f0\uba74 as_index\uadf8\ub300\ub85c \uc0ac\uc6a9\n#         session = user_sample.iloc[n:as_index+1,:]\n#         session_df = session.groupby('installation_id').sum().reset_index(drop=True)\n#         sess_df = pd.concat([sess_df, session_df])\n#     data_mid = pd.concat([data_mid, sess_df])\n#     n = last_index+1\n# data_mid = data_mid.reset_index(drop=True)\n# data_fin = pd.concat([data_fin, data_mid], axis=1)","37ba049c":"#\ud568\uc218\ube4c\ub824\uc624\uae30 \ndef encode_title(train, test, train_labels):\n    \n    #train in train_labels\n    uni_inst = train_labels.installation_id.unique()\n    train = train[train.installation_id.isin(list(uni_inst))]\n    \n    # title_event_code \n    train['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), train['title'], train['event_code']))\n    test['title_event_code'] = list(map(lambda x, y: str(x) + '_' + str(y), test['title'], test['event_code']))\n    all_title_event_code = list(set(train[\"title_event_code\"].unique()).union(test[\"title_event_code\"].unique()))\n    \n    # title, event_code, event_id, world\n    list_of_title = list(set(train['title'].unique()).union(set(test['title'].unique())))\n    list_of_event_code = list(set(train['event_code'].unique()).union(set(test['event_code'].unique())))\n    list_of_event_id = list(set(train['event_id'].unique()).union(set(test['event_id'].unique())))\n    list_of_worlds = list(set(train['world'].unique()))   \n    \n    # create a dictionary numerating the titles\n    title_labels = dict(zip(list_of_title, np.arange(len(list_of_title)))) \n    labels_title = dict(zip(np.arange(len(list_of_title)), list_of_title)) \n    world_labels = dict(zip(list_of_worlds, np.arange(len(list_of_worlds))))\n    labels_world = dict(zip(np.arange(len(list_of_worlds)),list_of_worlds))\n    assess_titles = list(train_df[train_df['type'] == 'Assessment']['title'].unique())\n    \n    # replace the text titles with the number titles from the dict\n    train['title'] = train['title'].map(title_labels)\n    test['title'] = test['title'].map(title_labels)\n    train['world'] = train['world'].map(world_labels)\n    test['world'] = test['world'].map(world_labels)\n    train_labels['title'] = train_labels['title'].map(title_labels)\n    \n    # win_code\n    #'Bird Measurer (Assessment)' is win_code is 4110 \n    win_code = dict(zip(title_labels.values(), (4100*np.ones(len(title_labels))).astype('int')))  \n    win_code[title_labels['Bird Measurer (Assessment)']] = 4110\n    \n    # convert text into datetime\n    train['timestamp'] = pd.to_datetime(train['timestamp'])\n    test['timestamp'] = pd.to_datetime(test['timestamp'])\n    \n    \n    return train, test, train_labels, all_title_event_code, list_of_title, list_of_event_code, list_of_event_id, list_of_worlds, title_labels, labels_title ,world_labels, labels_world, assess_titles, win_code","32ef473f":"train_df, test_df, train_labels_df, all_title_event_code, list_of_title, list_of_event_code, list_of_event_id, list_of_worlds, title_labels, labels_title ,world_labels, labels_world, assess_titles, win_code = encode_title(train_df, test_df, train_labels_df)","baa679d1":"labels_world","4f6ab384":"def get_key(string, key):\n    import re\n    repattern = re.compile(f'(?<=\"{key}\":)' + '[A-z0-9\\\"\\'\\[\\],]+' + \"(?=[\\},])\")\n\n    try:\n        value = repattern.search(string).group()\n    except:\n        value = np.NaN\n    \n    return value\n\ndef add_col(data):\n#     #duration (\ud655\uc778\uc774 \uc5b4\ub824\uc6b4\ubd80\ubd84\uc774 \uc788\uc5b4\uc11c \uc0dd\ub7b5)\n#     data['duration'] =data.event_data.apply(lambda x : get_key(x,\"duration\")).astype(float)\n#     #Scrub-A-Dub 2030\uc740 np.nan\ubd80\uc5ec\n#     data.loc[(data.event_code.isin([2030]))&(data.title.isin([title_labels['Scrub-A-Dub']])),'duration'] = np.nan\n#     #2050 \uc784\uc2dc \uc800\uc7a5 \n#     saved = data.loc[(data.event_code.isin([2050]))&(data.title.isin([title_labels['Scrub-A-Dub']])),'duration']\n#     #2030 \uc81c\uc678 np.nan\ubd80\uc5ec\n#     data.loc[data.event_code != 2030,'duration'] = np.nan \n#     data.loc[saved.index.values,'duration'] = saved\n#     data.duration.fillna(0, inplace=True)\n    start = dt.now()\n    #step\n    key_list = [\"level\", \"round\", \"stage_number\", \"round_number\"]\n    for key in key_list:\n        data[key] = data.event_data.apply(lambda x : get_key(x,key))\n        \n    #step\uc73c\ub85c \ud1b5\ud569  \n    data['step'] = data['round'].values\n    data.at[data['step'].isnull(),'step'] = data.loc[data['step'].isnull(),'stage_number']\n    data.at[data['step'].isnull(),'step'] = data.loc[data['step'].isnull(),'round_number']\n    data.at[data['level'].notnull(),'step'] = data.loc[data['level'].notnull(),'level']\n    data.drop(key_list,axis=1,inplace = True)\n    data.step.fillna(0, inplace=True)\n    data['step'] = data['step'].astype(int)\n    \n    #Assessment \uc81c\uc678\n    label_list = []\n    for title in assess_titles:\n        label_list.append(title_labels[title])\n    data.loc[data.title.isin(label_list),'step'] = 0\n    \n    step_max = data.groupby('game_session')['step'].max().reset_index()\n    data.drop('step',axis= 1,inplace = True)\n    data = pd.merge(data,step_max)\n    \n    end1 = dt.now()\n    print(\"step \uc18c\uc694\uc2dc\uac04\",round((end1 - start).total_seconds()\/60,2),\"\ubd84\")\n        \n    #miss\n    data[\"correct\"] = data.event_data.apply(lambda x : get_key(x,\"correct\"))\n    data.loc[data.event_code != 4020,\"correct\"] = np.nan\n    data['cor_t'] = 0\n    data['cor_f'] = 0\n    data.loc[data.correct.isin([\"true\"]), 'cor_t'] = 1\n    data.loc[data.correct.isin([\"false\"]), 'cor_f'] = 1\n    data.drop('correct',axis=1,inplace = True)\n    \n    end2 = dt.now()\n    print(\"miss \uc18c\uc694\uc2dc\uac04\",round((end2 - end1).total_seconds()\/60,2),\"\ubd84\")\n    \n    return data","a9ca0eef":"#\uc77c\ub2e8 \ud328\uc2a4 \ubabb\ud574\uba39\uac9f\ub2e4\n# test_df = add_col(test_df)\n# train_df = add_col(train_df)","a1939363":"# ori_sample[ori_sample.title == 18]['step'].describe()","ed3e4a5e":"# #title\ubcc4\ub85c \ubb36\uc5b4\uc11c \uc9c4\ud589\n# step_title = dict(zip(step_title,[0]* len(step_title)))\n\n# # step_title[session['title']] session['step'][0]","2aec5865":"# # step\uc774 \uc788\ub294 \ud0c0\uc774\ud2c0 \ucd1d 12\uac1c (assessment \uc81c\uc678)\n# for i in a[a>0].index.values[:]:\n#     print(i, activities_labels[i])","927e435d":"# ori_sample[ori_sample.title == 18]['step'].plot.box()","8697ede7":"# train_df.head()","6f261450":"title_count: Dict[str, int] = {eve: 0 for eve in labels_title.values()} ","a44cbdbe":"labels_title","cf0ddad5":"world_count : Dict[str, int]  = {eve: 0 for eve in labels_world.values()}","e52834f2":"world_count","1806b952":"# this is the function that convert the raw data into processed features\ndef get_data(user_sample, test_set=False):\n    '''\n    The user_sample is a DataFrame from train or test where the only one \n    installation_id is filtered\n    And the test_set parameter is related with the labels processing, that is only requered\n    if test_set=False\n    '''\n    # Constants and parameters declaration\n    last_activity = 0\n    \n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    \n    # new features: time spent in each activity\n    last_session_time_sec = 0\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy = 0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0\n    accumulated_actions = 0\n    counter = 0\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    durations = []\n    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n    title_count: Dict[str, int] = {eve: 0 for eve in labels_title.values()} \n    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n    world_count : Dict[str, int]  = {eve: 0 for eve in labels_world.values()}\n        \n    # last features\n    sessions_count = 0\n        \n    #add feature\n    step =[]\n    cor_t =0\n    cor_f = 0\n    day_gap =0\n    \n    #first_day of installation_id\n    first_day = user_sample.iloc[0,2]\n    \n    # itarates through each session of one instalation_id\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i = game_session_id\n        # session is a DataFrame that contain only one game_session\n        \n        # get some sessions information\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        session_title_text = labels_title[session_title]\n                    \n            \n        # for each assessment, and only this kind off session, the features below are processed\n        # and a register are generated\n        # \ud0c0\uc785\uc774 Assessment\uc774\uba74\uc11c test_set\uc774 True \ub610\ub294 \uae38\uc774\uac00 1\ubcf4\ub2e4 \ud074\ub54c\n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100, that represents the assessments trial\n            #\uc2b9\ub9ac\ucf54\ub4dc\uc5d0 \ud574\ub2f9\ud558\ub294 \ubd80\ubd84 \ucd9c\ub825 (\uc5ec\ub7ec\ubc88\uc77c\uc218 \uc788\uc73c\ub2c8 \ub370\uc774\ud130 \ud504\ub808\uc784\uc73c\ub85c)\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            # then, check the numbers of wins and the number of losses\n            #\uc2dc\ub3c4\uc5d0 \ub300\ud55c \uacb0\uacfc\uac12\uc744 \uac01\uac01 \ubcf4\uc874\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            # copy a dict to use as feature template, it's initialized with some itens: \n            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n            features = user_activities_count.copy()\n            features.update(last_accuracy_title.copy())\n            features.update(event_code_count.copy())\n            features.update(event_id_count.copy())\n            features.update(title_count.copy())\n            features.update(title_event_code_count.copy())\n            features.update(last_accuracy_title.copy())\n            features.update(world_count.copy())\n            features['installation_session_count'] = sessions_count\n            \n            variety_features = [('var_event_code', event_code_count),\n                              ('var_event_id', event_id_count),\n                               ('var_title', title_count),\n                               ('var_title_event_code', title_event_code_count),\n                               ('va_title_world',world_count)]\n            \n            for name, dict_counts in variety_features:\n                arr = np.array(list(dict_counts.values()))\n                features[name] = np.count_nonzero(arr)\n                 \n            # get installation_id for aggregated features\n            features['installation_id'] = session['installation_id'].iloc[-1]\n            features['game_session'] = session['game_session'].iloc[-1]\n            # add title as feature, remembering that title represents the name of the game\n            features['session_title'] = session['title'].iloc[0]\n            # the 4 lines below add the feature of the history of the trials of this player\n            # this is based on the all time attempts so far, at the moment of this assessment\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            \n            # the time spent in the app so far\n            if durations == []:\n                features['duration_mean'] = 0\n                features['duration_std'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n                features['duration_std'] = np.std(durations)\n            \n            \n            #\ub9c8\uc9c0\ub9c9\uc2dc\uac04\uc5d0\uc11c \ucc98\uc74c\uc2dc\uac04 \ube7c\uace0 \ucd08\ub85c \ubcc0\ud658 \ud6c4 durations\uc5d0 \uc804\ub2ec\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            day_gap = (session.iloc[0, 2] - first_day).days\n            features['day_gap'] = day_gap\n            \n            # the accurace is the all time wins divided by the all time attempts\n            #\ub204\uc801 \uc5b4\ud050\ub808\uc2dc \uce74\uc6b4\ud2b8\uac00 0\uc774\uc0c1\uc77c\ub54c\ub9cc \uacc4\uc0b0\n            features['accumulated_accuracy'] = accumulated_accuracy\/counter if counter > 0 else 0\n            #\uc5b4\ud050\ub808\uc2dc \uc9c1\uc811\uacc4\uc0b0\n            accuracy = true_attempts\/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            #\ub204\uc801\uac12\uc0dd\uc131\n            accumulated_accuracy += accuracy\n            last_accuracy_title['acc_' + session_title_text] = accuracy\n            # a feature of the current accuracy categorized\n            # it is a counter of how many times this player was in each accuracy group\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups)\n            #\uc5b4\ud050\ub808\uc2dc \uadf8\ub8f9\ub204\uc801\n            accuracy_groups[features['accuracy_group']] += 1\n            # mean of the all accuracy groups of this player\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group\/counter if counter > 0 else 0\n            accumulated_accuracy_group += features['accuracy_group']\n            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n            #\ub204\uc801 \uc5d1\uc158\uc218 \uc989 \ub204\uc801 row\uc218\n            features['accumulated_actions'] = accumulated_actions\n            \n            # there are some conditions to allow this features to be inserted in the datasets\n            # if it's a test set, all sessions belong to the final dataset\n            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n            # that means, must exist an event_code 4100 or 4110\n            # \ud14c\uc2a4\ud2b8\uc14b\uc758 \uacbd\uc6b0 \ubaa8\ub4e0 \ud53c\uccd0\ub97c \uc0ac\uc6a9\ud558\uace0 train\uc758 \uacbd\uc6b0\uc5d0\ub294 4100,4110\uac00 \uc788\uc5b4\uc57c\ud568 \uc544\ub2c8\uba74 pass\n            if test_set:\n                all_assessments.append(features)\n            elif true_attempts+false_attempts > 0:\n                all_assessments.append(features)\n                \n            counter += 1\n        \n        sessions_count += 1\n        # this piece counts how many actions was made in each event_code so far\n        def update_counters(counter: dict, col: str):\n                num_of_session_count = Counter(session[col])\n                for k in num_of_session_count.keys():\n                    x = k\n                    if col == 'title':\n                        x = labels_title[k]\n                    if col == 'world':\n                        x = labels_world[k]\n                    counter[x] += num_of_session_count[k]\n                return counter\n            \n        event_code_count = update_counters(event_code_count, \"event_code\")\n        event_id_count = update_counters(event_id_count, \"event_id\")\n        title_count = update_counters(title_count, 'title')\n        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n        world_count = update_counters(world_count, 'world')\n\n        # counts how many actions the player has done so far, used in the feature of the same name\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type \n                        \n    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n    if test_set:\n        return all_assessments[-1]\n    # in the train_set, all assessments goes to the dataset\n    return all_assessments","2d06bfd6":"#\uc704\uc5d0\uc11c \uc815\uc758\ub41c get_data\uac00 get_train_and_test\ud568\uc218\uc5d0\uc11c \uc0ac\uc6a9\ub428\n#\uc774\ud568\uc218\ub294 installation \ub2e8\uc704\uc758 \uc5f0\uc0b0\uc774 \uc774\ub904\uc9d0\ndef get_train_and_test(train, test):\n    compiled_train = []\n    compiled_test = []\n    for ins_id, user_sample in tqdm_notebook(train.groupby('installation_id', sort = False),total = 3614):\n        compiled_train += get_data(user_sample)\n    for ins_id, user_sample in tqdm_notebook(test.groupby('installation_id', sort = False), total = 1000):\n        test_data = get_data(user_sample, test_set = True)\n        compiled_test.append(test_data)\n    reduce_train = pd.DataFrame(compiled_train)\n    reduce_test = pd.DataFrame(compiled_test)\n    categoricals = ['session_title']\n    return reduce_train, reduce_test, categoricals","e6dd41bd":"reduce_train, reduce_test, categoricals = get_train_and_test(train_df, test_df)","6b5afaa8":"#\uc81c\uc774\uc2a8\uc624\ub958\ubc29\uc9c0\nreduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]\nreduce_train.columns = [\"\".join (c if c.isalnum() else \"_\" for c in str(x)) for x in reduce_train.columns]","05aa3e44":"reduce_train.head()","e199c701":"def add_feature2(data):\n    '''\n    \ud604\uc7ac\uc5d0 \ub123\uae30\uc704\ud574 \ub2e4\uc18c \uc218\uc815\ud568 \n    load\ud588\ub2e4\uba74 \uc22b\uc790\ubcc0\uc218 \ubb38\uc790\ub85c \uc218\uc815\ud574\uc57c\ud568\n    \n    test_df\uac00 \uc788\uc5b4\uc57c \uc791\ub3d9\n    #1.RAR(Right_action_rate) :\uc798\ud55c\ud559\uc2b5\uacfc \uc798\ubabb\ud55c \ud559\uc2b5\uc758 \ube44\uc728\n        * event_code 4020\uc740 \uc798\ud55c \ud559\uc2b5\uc774\uba70, \uc774\ub294 correct: True\/False\ub85c \ub098\ud0c0\ub0a8\n        * event_code 4035 \ubc0f 4070\uc740 \ud559\uc2b5\uacfc\uc815\uc5d0\uc11c \uc798\ubabb\ub41c \uacf3\uc744 \ub204\ub974\uac70\ub098 drop\ud55c \uacbd\uc6b0\n        * 4020_count\/ (4035,4070_count)\n    # 2. acum_winning(\ub204\uc801_\uc131\uacf5\ub960)\n        * 3020\/3021\uc740 \uc2e4\ud328\/\uc131\uacf5\uc2dc \ub098\uc624\ub294 message (Game\/Assessment\uc5d0\uc11c\ub9cc \ubc1c\ub3d9)\n        * 3021_count\/(3020,3021_count)\n    # 3.same_world_rate(\ub3d9\uc77c world \ud559\uc2b5\ub960) :last_Assessment\uc640 \ub3d9\uc77c\ud55c \uc6d4\ub4dc \ud69f\uc218\n        * last_title\uc5d0 \ub530\ub978 last_world \ucd94\ucd9c : last_world\n        * installation_id\ub2f9 \uc804\uccb4 \ud50c\ub808\uc774\ud55c title\uc218 : total_title\n        * \uac01 isntallation_id\ub2f9 \ub3d9\uc77c world \ud50c\ub808\uc774\ud55c \ube44\uc728 : same_world_rate\n        * installation_id\uc758 last_world play\ud69f\uc218 \/ total_title \n    # 4.\uc6d4\ub4dc_type\ubcc4 \ub2ec\uc131\ub960\n    '''\n    \n    # 1.RAR(Right_action_rate)\n    data['RAR'] = data[4020]\/(data[4035] + data[4070]+data[4020])\n    data.RAR.fillna(0, inplace=True)\n    \n    # 2. acum_winning(\ub204\uc801_\uc131\uacf5\ub960)\n    data['acum_winning'] = data[3021]\/(data[3020]+data[3021])\n    data.acum_winning.fillna(0, inplace=True)\n    \n#     # 3. same_world_rate(\ub3d9\uc77c world \ud559\uc2b5\ub960)\n    # world_title\uc744 \ud569\uccd0\ub193\uc740 df\n    world_title = test_ori[['title','world']].drop_duplicates()\n    world_title['title'] = world_title['title'].map(title_labels)\n    \n    data['last_world'] = np.nan\n    for title in list(set(data.session_title)):   \n        assessment_world = dict(world_title.values)\n        data.loc[data.session_title == title,'last_world'] = assessment_world[title]\n   \n    # total_title\n    data['total_title'] = data['MAGMAPEAK'] +data['CRYSTALCAVES'] +data['TREETOPCITY']\n    # same_world_rate \n    same_world_rate = []\n    for i in range(len(data)):\n        name = data['last_world'].iloc[i]\n        rate = data[name].iloc[i]\/data['total_title'].iloc[i]\n        same_world_rate.append(rate)\n    data['same_world_rate'] = same_world_rate\n    \n    # 4.\uc6d4\ub4dc_type\ubcc4 \ub2ec\uc131\ub960\n    #target\uc740 \uac01\uc6d4\ub4dc\ubcc4 type\uc774 tn\uacfc \uc77c\uce58\ud558\ub294 title\uba85\uc744 array\ub85c \ubc1b\uc74c\n    #\ub530\ub77c\uc11c world_type = plat\ud55c \ud0c0\uc774\ud2c0 \uc218 \/ type\ubcc4 \ucd1d \ud0c0\uc774\ud2c0\uc218 \n    world_name = ['CRYSTALCAVES','MAGMAPEAK','TREETOPCITY']\n    type_name = ['Activity','Clip','Game','Assessment']\n    \n    title_type = test_ori[['world','title','type']].drop_duplicates('title')\n    #\uc6d4\ub4dc_type \ud615\ud0dc\ub85c \uceec\ub7fc\uc0dd\uc131\n    for wn in world_name:\n        for tn in type_name:\n            target = title_type.loc[(title_type['world'] == wn)&(title_type['type']== tn),'title'].values\n            data[wn+\"_\"+tn] = (data[target]>0).apply(sum,axis=1)\/len(data[target].columns)\n            \n    data.drop(['last_world','total_title'], axis=1, inplace=True)\n    \n    return data","86255e2a":"test_ori = pd.read_csv(path + 'test.csv')\nreduce_train = add_feature2(reduce_train)\nreduce_test= add_feature2(reduce_test)\ndel test_ori","ab6c163e":"reduce_train.shape, reduce_test.shape","973cd3a1":"m_y = reduce_train.accuracy_group\nm_X = reduce_train.drop([\"accuracy_group\",\"game_session\",\"installation_id\"], axis = 1)\nm_test_X = reduce_test.drop([\"accuracy_group\",\"game_session\",\"installation_id\"], axis = 1)","ff5815c5":"import lightgbm as lgbm","53e92713":"default_lgbmr = lgbm.LGBMRegressor()\ndefault_lgbmr.fit(m_X, m_y)\nm_pred = default_lgbmr.predict(m_X)","2d337750":"model_fi(default_lgbmr,m_X).head(20)","5052cd63":"dist = Counter(reduce_train['accuracy_group'])\nfor k in dist:\n    dist[k] \/= len(reduce_train)\nreduce_train['accuracy_group'].hist()\n\nacum = 0\nbound = {}\nfor i in range(3):\n    acum += dist[i]\n    bound[i] = np.percentile(m_pred, acum * 100)\nprint(bound)\n\ndef classify(x):\n    if x <= bound[0]:\n        return 0\n    elif x <= bound[1]:\n        return 1\n    elif x <= bound[2]:\n        return 2\n    else:\n        return 3\n    \nfinal_pred = np.array(list(map(classify, m_pred)))","c6c16d98":"pd.Series(final_pred).value_counts()","63f3843c":"from sklearn.metrics import cohen_kappa_score\ncohen_kappa_score(final_pred,reduce_train['accuracy_group'],weights=\"quadratic\")","a7b39590":"r_m_pred = default_lgbmr.predict(m_test_X)","ef77c8f5":"dist = Counter(reduce_train['accuracy_group'])\nfor k in dist:\n    dist[k] \/= len(reduce_train)\nreduce_train['accuracy_group'].hist()\n\nacum = 0\nbound = {}\nfor i in range(3):\n    acum += dist[i]\n    bound[i] = np.percentile(r_m_pred, acum * 100)\nprint(bound)\n\ndef classify(x):\n    if x <= bound[0]:\n        return 0\n    elif x <= bound[1]:\n        return 1\n    elif x <= bound[2]:\n        return 2\n    else:\n        return 3\n    \nfinal_pred = np.array(list(map(classify, r_m_pred)))","6ffcd87f":"pd.Series(final_pred).value_counts()","6e15b1fb":"sample_submission['accuracy_group'] = final_pred.astype(int)\nsample_submission.to_csv('submission.csv', index=False)","5a59916c":"train[train.installation_id == '0006a69f']['game_session'].nunique()\ntt = train[train.installation_id == '0006a69f']\n\ntt.shape","48a7d6a3":"#Assessment\uc778\uac70\ub9cc \ucd94\ucd9c\nonly_ass = pd.DataFrame(tt[tt.type == 'Assessment'][['game_session','title']].drop_duplicates())\nonly_ass","14b62c62":"last_ass_index = tt[tt.game_session == '901acc108f55a5a1'].iloc[-1:].index[0]\nfirst_ass_index = tt[tt.game_session == '901acc108f55a5a1'].iloc[:1].index[0]\ntt.loc[:first_ass_index-1].shape","c1bd7be4":"last_ass_index = tt[tt.game_session == 'a9ef3ecb3d1acc6a'].iloc[-1:].index[0]\nfirst_ass_index = tt[tt.game_session == 'a9ef3ecb3d1acc6a'].iloc[:1].index[0]\ntt.loc[:first_ass_index-1].shape","629c5dbc":"# this is the function that convert the raw data into processed features\ndef get_data(user_sample, test_set=False):\n    '''\n    The user_sample is a DataFrame from train or test where the only one \n    installation_id is filtered\n    And the test_set parameter is related with the labels processing, that is only requered\n    if test_set=False\n    '''\n    # Constants and parameters declaration\n    last_activity = 0\n    \n    user_activities_count = {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n    \n    # new features: time spent in each activity\n    last_session_time_sec = 0\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    all_assessments = []\n    accumulated_accuracy_group = 0\n    accumulated_accuracy = 0\n    accumulated_correct_attempts = 0 \n    accumulated_uncorrect_attempts = 0\n    accumulated_actions = 0\n    counter = 0\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    durations = []\n    last_accuracy_title = {'acc_' + title: -1 for title in assess_titles}\n    event_code_count: Dict[str, int] = {ev: 0 for ev in list_of_event_code}\n    event_id_count: Dict[str, int] = {eve: 0 for eve in list_of_event_id}\n    title_count: Dict[str, int] = {eve: 0 for eve in activities_labels.values()} \n    title_event_code_count: Dict[str, int] = {t_eve: 0 for t_eve in all_title_event_code}\n        \n    # last features\n    sessions_count = 0\n    \n    # itarates through each session of one instalation_id\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i = game_session_id\n        # session is a DataFrame that contain only one game_session\n        \n        # get some sessions information\n        session_type = session['type'].iloc[0]\n        session_title = session['title'].iloc[0]\n        session_title_text = activities_labels[session_title]\n                    \n            \n        # for each assessment, and only this kind off session, the features below are processed\n        # and a register are generated\n        # \ud0c0\uc785\uc774 Assessment\uc774\uba74\uc11c test_set\uc774 True \ub610\ub294 \uae38\uc774\uac00 1\ubcf4\ub2e4 \ud074\ub54c\n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100, that represents the assessments trial\n            #\uc2b9\ub9ac\ucf54\ub4dc\uc5d0 \ud574\ub2f9\ud558\ub294 \ubd80\ubd84 \ucd9c\ub825 (\uc5ec\ub7ec\ubc88\uc77c\uc218 \uc788\uc73c\ub2c8 \ub370\uc774\ud130 \ud504\ub808\uc784\uc73c\ub85c)\n            all_attempts = session.query(f'event_code == {win_code[session_title]}')\n            # then, check the numbers of wins and the number of losses\n            #\uc2dc\ub3c4\uc5d0 \ub300\ud55c \uacb0\uacfc\uac12\uc744 \uac01\uac01 \ubcf4\uc874\n            true_attempts = all_attempts['event_data'].str.contains('true').sum()\n            false_attempts = all_attempts['event_data'].str.contains('false').sum()\n            # copy a dict to use as feature template, it's initialized with some itens: \n            # {'Clip':0, 'Activity': 0, 'Assessment': 0, 'Game':0}\n            features = user_activities_count.copy()\n            features.update(last_accuracy_title.copy())\n            features.update(event_code_count.copy())\n            features.update(event_id_count.copy())\n            features.update(title_count.copy())\n            features.update(title_event_code_count.copy())\n            features.update(last_accuracy_title.copy())\n            features['installation_session_count'] = sessions_count\n            \n            variety_features = [('var_event_code', event_code_count),\n                              ('var_event_id', event_id_count),\n                               ('var_title', title_count),\n                               ('var_title_event_code', title_event_code_count)]\n            \n            for name, dict_counts in variety_features:\n                arr = np.array(list(dict_counts.values()))\n                features[name] = np.count_nonzero(arr)\n                 \n            # get installation_id for aggregated features\n            features['installation_id'] = session['installation_id'].iloc[-1]\n            # add title as feature, remembering that title represents the name of the game\n            features['session_title'] = session['title'].iloc[0]\n            # the 4 lines below add the feature of the history of the trials of this player\n            # this is based on the all time attempts so far, at the moment of this assessment\n            features['accumulated_correct_attempts'] = accumulated_correct_attempts\n            features['accumulated_uncorrect_attempts'] = accumulated_uncorrect_attempts\n            accumulated_correct_attempts += true_attempts \n            accumulated_uncorrect_attempts += false_attempts\n            # the time spent in the app so far\n            if durations == []:\n                features['duration_mean'] = 0\n                features['duration_std'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n                features['duration_std'] = np.std(durations)\n            #\ub9c8\uc9c0\ub9c9\uc2dc\uac04\uc5d0\uc11c \ucc98\uc74c\uc2dc\uac04 \ube7c\uace0 \ucd08\ub85c \ubcc0\ud658 \ud6c4 durations\uc5d0 \uc804\ub2ec\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n            # the accurace is the all time wins divided by the all time attempts\n            #\ub204\uc801 \uc5b4\ud050\ub808\uc2dc \uce74\uc6b4\ud2b8\uac00 0\uc774\uc0c1\uc77c\ub54c\ub9cc \uacc4\uc0b0\n            features['accumulated_accuracy'] = accumulated_accuracy\/counter if counter > 0 else 0\n            #\uc5b4\ud050\ub808\uc2dc \uc9c1\uc811\uacc4\uc0b0\n            accuracy = true_attempts\/(true_attempts+false_attempts) if (true_attempts+false_attempts) != 0 else 0\n            #\ub204\uc801\uac12\uc0dd\uc131\n            accumulated_accuracy += accuracy\n            last_accuracy_title['acc_' + session_title_text] = accuracy\n            # a feature of the current accuracy categorized\n            # it is a counter of how many times this player was in each accuracy group\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups)\n            #\uc5b4\ud050\ub808\uc2dc \uadf8\ub8f9\ub204\uc801\n            accuracy_groups[features['accuracy_group']] += 1\n            # mean of the all accuracy groups of this player\n            features['accumulated_accuracy_group'] = accumulated_accuracy_group\/counter if counter > 0 else 0\n            accumulated_accuracy_group += features['accuracy_group']\n            # how many actions the player has done so far, it is initialized as 0 and updated some lines below\n            #\ub204\uc801 \uc5d1\uc158\uc218 \uc989 \ub204\uc801 row\uc218\n            features['accumulated_actions'] = accumulated_actions\n            \n            # there are some conditions to allow this features to be inserted in the datasets\n            # if it's a test set, all sessions belong to the final dataset\n            # it it's a train, needs to be passed throught this clausule: session.query(f'event_code == {win_code[session_title]}')\n            # that means, must exist an event_code 4100 or 4110\n            # \ud14c\uc2a4\ud2b8\uc14b\uc758 \uacbd\uc6b0 \ubaa8\ub4e0 \ud53c\uccd0\ub97c \uc0ac\uc6a9\ud558\uace0 train\uc758 \uacbd\uc6b0\uc5d0\ub294 4100,4110\uac00 \uc788\uc5b4\uc57c\ud568 \uc544\ub2c8\uba74 pass\n            if test_set:\n                all_assessments.append(features)\n            elif true_attempts+false_attempts > 0:\n                all_assessments.append(features)\n                \n            counter += 1\n        \n        sessions_count += 1\n        # this piece counts how many actions was made in each event_code so far\n        def update_counters(counter: dict, col: str):\n                num_of_session_count = Counter(session[col])\n                for k in num_of_session_count.keys():\n                    x = k\n                    if col == 'title':\n                        x = activities_labels[k]\n                    counter[x] += num_of_session_count[k]\n                return counter\n            \n        event_code_count = update_counters(event_code_count, \"event_code\")\n        event_id_count = update_counters(event_id_count, \"event_id\")\n        title_count = update_counters(title_count, 'title')\n        title_event_code_count = update_counters(title_event_code_count, 'title_event_code')\n\n        # counts how many actions the player has done so far, used in the feature of the same name\n        accumulated_actions += len(session)\n        if last_activity != session_type:\n            user_activities_count[session_type] += 1\n            last_activitiy = session_type \n                        \n    # if it't the test_set, only the last assessment must be predicted, the previous are scraped\n    if test_set:\n        return all_assessments[-1]\n    # in the train_set, all assessments goes to the dataset\n    return all_assessments","0b1c102c":"one = train[train.installation_id == '0001e90f']\ntwo = train[train.installation_id == '0006a69f']\nsample = pd.concat([one,two])","4371c738":"two.type.value_counts()","97c3ce7d":"compiled_train = []\ncompiled_test = []\nfor i, (ins_id, user_sample) in tqdm(enumerate(sample.groupby('installation_id', sort = False)), total = 17000):\n    compiled_train += get_data(user_sample)","87d0083e":"compiled_train","3e154407":"# user func","48a7ba9a":"### Check1 \ub9c8\uc9c0\ub9c9 assessment\ub294 \ub4e4\uc5b4\uac14\ub294\uac00?\n* \uacb0\ub860 : \ub4e4\uc5b4\uac00\uc9c0 \uc54a\uc558\ub2e4. \uc65c\ub0d0\ud558\uba74 test\uc14b\uc758 \ub9c8\uc9c0\ub9c9 assessment\uc5d0 \ub300\ud55c \uc815\ubcf4\uac00 \uc5c6\uae30 \ub584\ubb38  \n--> \uc544\ub9c8 \uc774\ub85c \uc778\ud574\uc11c overfitting\uc774 \ub0ac\uc744\uac83\uc73c\ub85c \ucd94\uc815(\uc774\ubbf8 \ub2f5\uc744\uc54c\uace0 \uc788\uae30 \ub54c\ubb38\uc5d0)\n\n* \ucd94\uc815\uacfc\uc815 : '0006a69f'\uc744 \ub300\uc0c1\uc73c\ub85c \ucc98\uc74c game_session\uc73c\ub85c \ud655\uc778   \n--> \ucc98\uc74c : 647\uac74, \ub9c8\uc9c0\ub9c9 : 2568\uac74 \ud655\uc778","04f65c17":"### test_data(\uc81c\ucd9c\uc6a9)","394383b9":"### \uae30\ubcf8\ubaa8\ub378","12eec65f":"# day gap \nfirst_day = sameple_df['timestamp'].iloc[0]\n\n#game_session\ub2e8\uc704\uc5d0\uc11c \nlast_day = session['timestamp'].iloc[-1]\nday_gap = (last_day-first_day).days","fc1c208d":"### \ud29c\ub2dd\uc911","d237fa4b":"### step \uace0\ub824\uc0ac\ud56d\n* 1. \ud55cGame_Session\uc5d0 max(step)\uc774 \ub4e4\uc5b4\uac00\ub294\uac8c \ub9de\ub2e4\n* 2. \ub2e8 \uac8c\uc784\uc5d0 \ub530\ub77c max\uac00 \uc815\ud574\uc838 \uc788\ub294 \uacbd\uc6b0\uac00 \uc788\uace0 \uc544\ub2cc \uacbd\uc6b0\uac00 \uc788\ub2e4 \ud30c\uc545 \ud544\uc694\n* 3. \uac01 \uac8c\uc784\ubcc4\ub85c step\uc774 \ub2e4\ub978\ub370 \uc774\uac78 \ud558\ub098\ub3c4 \ubb49\uce58\uae30\ub3c4 \uc560\ub9e4\ud558\uace0 \ud558\uc790\ub2c8 \ud488\uc774 \ub9ce\uc774 \ub4e4\uc5b4\uac00\ub294\ub370 \uadf8\uc815\ub3c4 \uac00\uce58\uac00 \uc788\ub294\uc9c0 \ubaa8\ub974\uaca0\uc5b4\uc11c \uc77c\ub2e8 \ud328\uc2a4","1b2b4c84":"### step \ub4f1\ub4f1 \ucd94\uac00\ud558\uae30","9ff927a2":"# Data load","955b03c2":"#\uc720\ub2c8\ud06c\ud55c\uac12\ub9cc\nuni_inst = train_labels_df.installation_id.unique()\n#\ub4e4\uc5b4\uc624\ub294\uac70 \uc548\ub4e4\uc5b4\uc624\ub294\uac70\ninlabel = train_df[train_df.installation_id.isin(list(uni_inst))]\ninlabel = train_df[~train_df.installation_id.isin(list(uni_inst))]","41966b1b":"### \uc218\uc815\uc911","326473bc":"### cut_train \uc7ac\uc774\ud574\n* \uae30\uc874\ucf54\ub4dc \uc9e7\uac8c \uac00\ub2a5\ud55c\ub4ef \n* \ub9c8\uc9c0\ub9c9 Assessment \uc774\ud6c4\ucc98\ub9ac\uac00 \ud544\uc694\ud55c\uac00? \uc5b4\ucc28\ud53c for\ubb38 \ub3cc\ub9b4\uac70\ub77c\uba74 \uad73\uc774? \ud560\ud544\uc694\uc5c6\ub2e4 (\uc65c\ub0d0\uba74 \uc624\ub798\uac78\ub9ac\ub2c8\uae4c)","90b7cf26":"### \uc544\uc774\ub514\uc5b4","d1ce864a":"### 1\uac1c installation_id\uc5d0\uc11c \ud655\uc778","473d2bc8":"#\ub4e4\uc5b4\uc624\uc9c0\uc54a\ub294\uac83\uc911 \uc2b9\ub9ac\ucf54\ub4dc\uac00 \uc788\ub294 \uacbd\uc6b0\ub294 \uc5c6\ub2e4\noutlabel[(outlabel.type == 'Assessment')&(outlabel.event_code == 4110)].shape, outlabel[(outlabel.type == 'Assessment')&(outlabel.event_code == 4100)].shape"}}