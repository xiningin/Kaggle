{"cell_type":{"2cb59030":"code","aaa81397":"code","5abd7193":"code","331e752b":"code","46eb61b1":"code","27dd3106":"code","62d01ce1":"code","218f7493":"code","40936082":"code","e4ab682c":"code","854260b0":"code","84d932a1":"code","f230edcc":"code","82d5e66f":"code","214b288c":"code","7e4c59a3":"code","a86ae8ba":"code","cf64879e":"code","833d4222":"code","a60609b6":"code","4a3ab24d":"code","ee4d14ff":"code","6431e7d2":"code","7ffc8fe5":"code","49bab31d":"code","3553bb7b":"code","d4ccb1dd":"code","2ba96c8f":"code","f19bb4a7":"code","e3b627d4":"code","8fbbefaf":"code","b6b70a26":"code","758e815e":"code","f963b6c8":"code","cf42bfc6":"code","d451abda":"code","b83f4871":"code","d413e8fe":"code","cdfc99f7":"code","4a140ee7":"code","3f519dc2":"code","86f1d12a":"code","8114799a":"code","7f63349e":"code","b5059fd4":"code","6a474f20":"code","7df1c37a":"code","b9fd2836":"code","b40b020a":"code","dec7604e":"code","4ff0ca6e":"code","4746727a":"code","35aa9950":"code","ac0d4439":"code","3a46c81b":"code","229f9663":"code","79737bbf":"code","c023a3f6":"code","c84673ad":"code","806ac928":"code","8b50e7c2":"code","f2fae29a":"code","8a45fa07":"code","a4106281":"code","d408add7":"code","5b093de7":"code","56c95303":"code","cf042b30":"code","c5ccaa71":"code","dec90011":"code","d6c7b65e":"code","f8a650bd":"code","8cde45a0":"code","b2cfa77b":"code","bfa87a00":"code","b461fb92":"code","8b5a0df1":"code","f61f807c":"code","0a7b2a70":"code","cd6fce8b":"code","4807732c":"code","3f797615":"code","7fddac79":"code","14316b43":"code","39cfe9e8":"code","0c7cbdd1":"code","2fd6f95e":"code","2ed8768e":"code","54be90c8":"code","7924b256":"code","f777cf93":"code","9b2274e3":"code","1dc03c2f":"code","44422ab2":"code","373ff1b9":"code","786c102f":"code","e2e8a85b":"markdown","8d99651c":"markdown","e85cd367":"markdown","7d765b6c":"markdown","797fda2d":"markdown","0b7ee41b":"markdown","7def84cc":"markdown","e0488bfc":"markdown","1b6bc854":"markdown","de34bfd8":"markdown"},"source":{"2cb59030":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","aaa81397":"if os.path.exists(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n    data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D\"\nelse:\n    data_directory = '\/media\/roland\/data\/kaggle\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"EfficientNet-PyTorch-3D\"\n    \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nSIZE = 256\nNUM_IMAGES = 64\n\nsys.path.append(pytorch3dpath)\nfrom efficientnet_pytorch_3d import EfficientNet3D","5abd7193":"def load_dicom_image(path, img_size=SIZE):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if np.min(data)==np.max(data):\n        data = np.zeros((img_size,img_size))\n        return data\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n    \n    #data = (data * 255).astype(np.uint8)\n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"))\n    \n    middle = len(files)\/\/2\n    num_imgs2 = num_imgs\/\/2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n            \n    return np.expand_dims(img3d,0)\n\nload_dicom_images_3d(\"00000\").shape","331e752b":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(42)","46eb61b1":"train_df = pd.read_csv(f\"{data_directory}\/train_labels.csv\")\ndisplay(train_df)\n\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.2, \n    random_state=42, \n    stratify=train_df[\"MGMT_value\"],\n)","27dd3106":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, targets=None, mri_type=None, label_smoothing=0.01, split=\"train\"):\n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        if self.targets is None:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n        else:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\")\n\n        if self.targets is None:\n            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n        else:\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}","62d01ce1":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","218f7493":"modelfiles = None\n\nif not modelfiles:\n    modelfiles = ['FLAIR-e3-loss0.694-auc0.351.pth', 'T1w-e7-loss0.685-auc0.555.pth', 'T1wCE-e6-loss0.683-auc0.633.pth', 'T2w-e8-loss0.658-auc0.677.pth']\n    print(modelfiles)","40936082":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","e4ab682c":"def predict(modelfile, df, mri_type, split):\n    print(\"Predict:\", modelfile, mri_type, df.shape)\n    df.loc[:,\"MRI_Type\"] = mri_type\n    data_retriever = Dataset(\n        df.index.values, \n        mri_type=df[\"MRI_Type\"].values,\n        split=split\n    )\n\n    data_loader = torch_data.DataLoader(\n        data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n   \n    model = Model()\n    model.to(device)\n    \n    checkpoint = torch.load(f'..\/input\/efficientnet3d-with-one-mri-type-model-weights\/{modelfile}')\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        print(f\"{e}\/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(batch[\"id\"].numpy().tolist())\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","854260b0":"submission = pd.read_csv(f\"{data_directory}\/sample_submission.csv\", index_col=\"BraTS21ID\")\n\nsubmission[\"MGMT_value\"] = 0\nfor m, mtype in zip(modelfiles, mri_types):\n    pred = predict(m, submission, mtype, split=\"test\")\n    submission[\"MGMT_value\"] += pred[\"MGMT_value\"]\n\nsubmission[\"MGMT_value\"] \/= len(modelfiles)\nsubmission[\"MGMT_value\"].to_csv(\"submission_effnet3d_score_0684.csv\")","84d932a1":"submission_effnet3d_score_0684 = submission.copy()\nsubmission_effnet3d_score_0684.head()","f230edcc":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\nimport re\nimport math\nimport numpy as np\nimport pandas as pd\nimport cv2\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pydicom\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom random import shuffle\nfrom sklearn import model_selection as sk_model_selection\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport tensorflow as tf","82d5e66f":"data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\npytorch3dpath = \"..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D\"\n \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nIMAGE_SIZE = 256\nNUM_IMAGES = 64","214b288c":"sample_submission = pd.read_csv('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv')\ntest=sample_submission\ntest['BraTS21ID5'] = [format(x, '05d') for x in test.BraTS21ID]\ntest.head(3)","7e4c59a3":"def load_dicom_image(path, img_size=IMAGE_SIZE, voi_lut=True, rotate=0):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if voi_lut:\n        data = apply_voi_lut(dicom.pixel_array, dicom)\n    else:\n        data = dicom.pixel_array\n        \n    if rotate > 0:\n        rot_choices = [0, cv2.ROTATE_90_CLOCKWISE, cv2.ROTATE_90_COUNTERCLOCKWISE, cv2.ROTATE_180]\n        data = cv2.rotate(data, rot_choices[rotate])\n        \n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=IMAGE_SIZE, mri_type=\"FLAIR\", split=\"test\", rotate=0):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"), \n               key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n\n    middle = len(files)\/\/2\n    num_imgs2 = num_imgs\/\/2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f, rotate=rotate) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n        \n    if np.min(img3d) < np.max(img3d):\n        img3d = img3d - np.min(img3d)\n        img3d = img3d \/ np.max(img3d)\n            \n    return np.expand_dims(img3d,0)\n\na = load_dicom_images_3d(\"00001\")\nprint(a.shape)\nprint(np.min(a), np.max(a), np.mean(a), np.median(a))\nimage = a[0]\nprint(\"Dimension of the CT scan is:\", image.shape)\nplt.imshow(np.squeeze(image[:, :, 30]), cmap=\"gray\")","a86ae8ba":"from tensorflow.keras.utils import Sequence\nclass Dataset(Sequence):\n    def __init__(self,df,is_train=True,batch_size=1,shuffle=True):\n        self.idx = df[\"BraTS21ID\"].values\n        self.paths = df[\"BraTS21ID5\"].values\n        self.y =  df[\"MGMT_value\"].values\n        self.is_train = is_train\n        self.batch_size = batch_size\n        self.shuffle = shuffle\n    def __len__(self):\n        return math.ceil(len(self.idx)\/self.batch_size)\n   \n    def __getitem__(self,ids):\n        id_path= self.paths[ids]\n        batch_paths = self.paths[ids * self.batch_size:(ids + 1) * self.batch_size]\n        \n        if self.y is not None:\n            batch_y = self.y[ids * self.batch_size: (ids + 1) * self.batch_size]\n            \n        list_x =  load_dicom_images_3d(id_path)#str(scan_id).zfill(5)\n        #list_x =  [load_dicom_images_3d(x) for x in batch_paths]\n        batch_X = np.stack(list_x)\n        if self.is_train:\n            return batch_X,batch_y\n        else:\n            return batch_X\n    \n    def on_epoch_end(self):\n        if self.shuffle and self.is_train:\n            ids_y = list(zip(self.idx, self.y))\n            shuffle(ids_y)\n            self.idx, self.y = list(zip(*ids_y))","cf64879e":"test_dataset = Dataset(test,is_train=False)","833d4222":"for i in range(1):\n    image = test_dataset[i]\n    print(\"Dimension of the CT scan is:\", image.shape)\n    plt.imshow(image[0,:,:, 32], cmap=\"gray\")\n    plt.show()","a60609b6":"def get_model(width=IMAGE_SIZE, height=IMAGE_SIZE, depth=64):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = keras.Input((width, height, depth, 1))\n     \n    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv3D(filters=32, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv3D(filters=64, kernel_size=3, activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.01)(x)\n    \n    x = layers.Conv3D(filters=128, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.02)(x)\n\n    x = layers.Conv3D(filters=256, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.03)(x)\n\n    x = layers.Conv3D(filters=512, kernel_size=3, activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.04)(x)\n\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=1024, activation=\"relu\")(x)\n    x = layers.Dropout(0.08)(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    # Define the model.\n    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n\n    return model\n\n# Build model.\nmodel = get_model(width=IMAGE_SIZE, height=IMAGE_SIZE, depth=64)\nmodel.summary()","4a3ab24d":"model.load_weights('..\/input\/brainclassification3d\/Brain_3d_cls_FLAIR.h5')","ee4d14ff":"preds = model.predict(test_dataset)\npreds = preds.reshape(-1)","6431e7d2":"submission_bt3d = pd.DataFrame({'BraTS21ID':sample_submission['BraTS21ID'],'MGMT_value':preds})","7ffc8fe5":"submission_bt3d","49bab31d":"submission_bt3d.to_csv('submission_bt3d.csv',index=False)","3553bb7b":"submissionDF01 = pd.read_csv('..\/input\/testsubmissions\/submission (36).csv', dtype=str)\nsubmissionDF01 = submissionDF01.set_index('BraTS21ID')\nscoreDict01 = submissionDF01['MGMT_value'].to_dict()\nprint(scoreDict01)","d4ccb1dd":"listOfStudyPaths = glob.glob('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/*')\nlistOfStudies = [eachPath.split('\/')[-1] for eachPath in listOfStudyPaths]\n\npredList = []\nfor eachStudy in listOfStudies:\n    if eachStudy not in scoreDict01:\n        predList.append('0.500')\n    else:\n        score = float(scoreDict01[eachStudy])\n        predList.append(score)\n        \nsubmission_miccai = pd.DataFrame({'BraTS21ID':listOfStudies,'MGMT_value':predList})\nsubmission_miccai.to_csv('submission_miccai.csv', index=False)","2ba96c8f":"submission_miccai.sort_values(by='BraTS21ID', inplace=True)\nsubmission_miccai","f19bb4a7":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport collections\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\nimport torch.nn.functional as F\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","e3b627d4":"if os.path.exists(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\"):\n    data_directory = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"..\/input\/efficientnetpyttorch3d\/EfficientNet-PyTorch-3D\"\nelse:\n    data_directory = '\/media\/roland\/data\/kaggle\/rsna-miccai-brain-tumor-radiogenomic-classification'\n    pytorch3dpath = \"EfficientNet-PyTorch-3D\"\n    \nmri_types = ['FLAIR','T1w','T1wCE','T2w']\nSIZE = 256\nNUM_IMAGES = 64\n\nsys.path.append(pytorch3dpath)\nfrom efficientnet_pytorch_3d import EfficientNet3D","8fbbefaf":"def load_dicom_image(path, img_size=SIZE):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if np.min(data)==np.max(data):\n        data = np.zeros((img_size,img_size))\n        return data\n    data = data - np.min(data)\n    if np.max(data) != 0:\n        data = data \/ np.max(data)\n    \n    #data = (data * 255).astype(np.uint8)\n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n\n    files = sorted(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"))\n    \n    middle = len(files)\/\/2\n    num_imgs2 = num_imgs\/\/2\n    p1 = max(0, middle - num_imgs2)\n    p2 = min(len(files), middle + num_imgs2)\n    img3d = np.stack([load_dicom_image(f) for f in files[p1:p2]]).T \n    if img3d.shape[-1] < num_imgs:\n        n_zero = np.zeros((img_size, img_size, num_imgs - img3d.shape[-1]))\n        img3d = np.concatenate((img3d,  n_zero), axis = -1)\n            \n    return np.expand_dims(img3d,0)\n\nload_dicom_images_3d(\"00000\").shape","b6b70a26":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(42)","758e815e":"train_df = pd.read_csv(f\"{data_directory}\/train_labels.csv\")\ndisplay(train_df)\n\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.2, \n    random_state=42, \n    stratify=train_df[\"MGMT_value\"],\n)","f963b6c8":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, targets=None, mri_type=None, label_smoothing=0.01, split=\"train\"):\n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.label_smoothing = label_smoothing\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        if self.targets is None:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n        else:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\")\n\n        if self.targets is None:\n            return {\"X\": torch.tensor(data).float(), \"id\": scan_id}\n        else:\n            y = torch.tensor(abs(self.targets[index]-self.label_smoothing), dtype=torch.float)\n            return {\"X\": torch.tensor(data).float(), \"y\": y}","cf42bfc6":"class Model(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = EfficientNet3D.from_name(\"efficientnet-b0\", override_params={'num_classes': 2}, in_channels=1)\n        n_features = self.net._fc.in_features\n        self.net._fc = nn.Linear(in_features=n_features, out_features=1, bias=True)\n    \n    def forward(self, x):\n        out = self.net(x)\n        return out","d451abda":"modelfiles = None\n\nif not modelfiles:\n    modelfiles = ['FLAIR-e2-loss0.693-auc0.567.pth', 'T1w-e8-loss0.682-auc0.551.pth', 'T1wCE-e3-loss0.693-auc0.617.pth', 'T2w-e8-loss0.672-auc0.593.pth']\n    print(modelfiles)","b83f4871":"device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","d413e8fe":"def predict(modelfile, df, mri_type, split):\n    print(\"Predict:\", modelfile, mri_type, df.shape)\n    df.loc[:,\"MRI_Type\"] = mri_type\n    data_retriever = Dataset(\n        df.index.values, \n        mri_type=df[\"MRI_Type\"].values,\n        split=split\n    )\n\n    data_loader = torch_data.DataLoader(\n        data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n   \n    model = Model()\n    model.to(device)\n    \n    checkpoint = torch.load(f'..\/input\/efficientnet3d-with-one-mri-type-0674\/{modelfile}')\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        print(f\"{e}\/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(batch[\"X\"].to(device))).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(batch[\"id\"].numpy().tolist())\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","cdfc99f7":"submission = pd.read_csv(f\"{data_directory}\/sample_submission.csv\", index_col=\"BraTS21ID\")\n\nsubmission[\"MGMT_value\"] = 0\nfor m, mtype in zip(modelfiles, mri_types):\n    pred = predict(m, submission, mtype, split=\"test\")\n    submission[\"MGMT_value\"] += pred[\"MGMT_value\"]\n\nsubmission[\"MGMT_value\"] \/= len(modelfiles)\nsubmission[\"MGMT_value\"].to_csv(\"submission_effnet3d_score_0674.csv\")","4a140ee7":"submission_effnet3d_score_0674 = submission.copy()\nsubmission_effnet3d_score_0674.head()","3f519dc2":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport pydicom\nimport cv2 as cv\n\nimport torch\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom torch.utils.data import DataLoader, Dataset, Subset\n# from torchvision import models\nimport torchvision\nimport kornia as K  # batch image augmentations with torch.Tensor\nfrom kornia.augmentation import AugmentationSequential\nfrom kornia.augmentation.base import AugmentationBase3D  # Subclassing this is too complicated.\nfrom kornia.enhance import invert\n\nfrom tqdm.notebook import tqdm\n\nfrom pathlib import Path\nfrom typing import Union, Tuple, List, Optional, Type, Dict, Iterable\nimport time\n\nDEBUG = False\nREPRODUCTIVE = True\nINFERENCE_ONLY = True\nUSE_CROSS_VALIDATION = True\n\nrandom_state = 42\nmodel_name = \"Net-3D\"\ndata_dir = Path(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\")\nmodels_dir = Path(\"..\/input\/model-weights-for-rsna-miccai-brain-tumor-dataset\")\n# models_dir = Path(\".\")  # If train model with local machine\n\ndevice = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n\ntime_begin = time.time()\n\nif REPRODUCTIVE:\n    np.random.seed(random_state)\n    torch.random.manual_seed(random_state)\ndisplay(list(data_dir.iterdir()), torch.__version__, torchvision.__version__)","86f1d12a":"mri_series = {0: \"FLAIR\", 1: \"T1w\", 2: \"T1wCE\", 3: \"T2w\"}\nmri_series_map = {v: k for k, v in mri_series.items()}\nplanes = {0: \"Unknown\", 1: \"Coronal\", 2: \"Sagittal\", 3: \"Axial\"}\nplanes_map = {v: k for k, v in planes.items()}","8114799a":"labels_train = pd.read_csv(data_dir \/ \"train_labels.csv\", dtype={\"BraTS21ID\": str})\nlabels_train","7f63349e":"def look_one_dcm(instance_id: str, img_dir: Path, mri_series=\"FLAIR\", verbose=False):\n    dcm_paths = list(img_dir.glob(\".\/{}\/{}\/*.dcm\".format(instance_id.zfill(5), mri_series)))\n    print(\"Containing {} dicom files(including blank).\".format(len(dcm_paths)))\n    if dcm_paths:\n        dcm_mid = dcm_paths[(len(dcm_paths) - 1) \/\/ 2]\n        dcm_ds = pydicom.read_file(str(dcm_mid))\n        if verbose:\n            print(dir(dcm_ds))\n            print(dcm_ds)\n            print(type(dcm_ds[(\"0010\", \"0010\")].value))\n            print(dcm_ds[(\"0020\", \"0032\")].name, eval(str(dcm_ds[(\"0020\", \"0032\")].value)))\n            print(dir(dcm_ds[(\"0020\", \"0032\")]))\n            print(dcm_ds.pixel_array.dtype)\n        plt.imshow(dcm_ds.pixel_array, cmap=plt.cm.gray)\n        plt.show()\n\n\nlook_one_dcm(\"00000\", data_dir \/ \"train\", verbose=True)","b5059fd4":"def get_image_plane(loc):\n    row_x, row_y, row_z, col_x, col_y, col_z = [round(v) for v in loc]\n    if (row_x, row_y, col_x, col_y) == (1, 0, 0, 0): return planes[1]\n    if (row_x, row_y, col_x, col_y) == (0, 1, 0, 0): return planes[2]\n    if (row_x, row_y, col_x, col_y) == (1, 0, 0, 1): return planes[3]\n    return planes[0]\n\n\nclass DICOMMetaLoader(Dataset):\n    \n    def __init__(self, img_dir: Path, glob=None):\n        super(DICOMMetaLoader, self).__init__()\n        if glob is None:\n            glob = \".\/*\/*\/*.dcm\"\n        self.dcm_paths = list(img_dir.glob(glob))\n    \n    def __len__(self): return len(self.dcm_paths)\n    \n    def __getitem__(self, idx) -> dict:\n        dcm_path = str(self.dcm_paths[idx])\n        dcm_obj = pydicom.read_file(dcm_path)\n        photometric = str(dcm_obj[0x28, 0x04])\n        array = dcm_obj.pixel_array\n        if photometric == \"MONOCHROME1\":\n            info_func = np.iinfo if np.issubdtype(array.dtype, np.integer) else np.finfo\n            array = info_func(array.dtype).max - array\n        image_mean, image_std = np.mean(array), np.std(array)\n        \n        impo_x, impo_y, impo_z = [float(v) for v in dcm_obj[0x20, 0x32]]\n        plane = get_image_plane(dcm_obj[0x20, 0x37])\n        \n        patient_id = str(dcm_obj[0x0010, 0x0020].value).strip().zfill(5)\n        series_desc = str(dcm_obj[0x0008, 0x103e].value).strip()\n        row = dict(dcm_path=dcm_path, BraTS21ID=patient_id, series_description=series_desc,\n                   image_mean=image_mean, image_std=image_std,\n                   plane=plane,\n                   image_position_x=impo_x, image_position_y=impo_y, image_position_z=impo_z)\n        return row\n\n\ndef get_meta_from_glob(img_dir: Path, glob=None) -> pd.DataFrame:\n    dcm_ds = DICOMMetaLoader(img_dir, glob)\n    dcm_dl = DataLoader(dcm_ds, batch_size=256, num_workers=6)\n    df = pd.DataFrame()\n    for item in tqdm(dcm_dl):\n        chunks = pd.DataFrame.from_dict({k:np.asarray(v) for k, v in item.items()})\n        df = pd.concat([df, chunks], ignore_index=True)\n    return df\n\n\n# df_train = get_meta_from_glob(data_dir \/ \"train\")","6a474f20":"# # To categorical data by mapping, \n\n# df_train.loc[:, \"plane\"] = df_train.loc[:, \"plane\"].map(planes_map)\n# df_train.loc[:, \"series_description\"] = df_train.loc[:, \"series_description\"].map(mri_series_map)","7df1c37a":"def keep_non_blank(df: pd.DataFrame):\n    \"\"\"\n    Keep data containing non blank image.\n    :params:\n        df: pd.DataFrame, requires \"image_std\" and \"image_mean\" in df.columns.\n    :returns:\n        pd.DataFrame: filtered DataFrame\n    \"\"\"\n    df = df.loc[(df[\"image_std\"] > 0) & (df[\"image_mean\"] > 0)]\n    return df\n\n\n# display(len(df_train))\n# df_train = keep_non_blank(df_train)\n# display(len(df_train))","b9fd2836":"def drop_by_id(df: pd.DataFrame, ids: List[Union[int, str]]):\n    ids = [str(s).zfill(5) for s in ids]\n    df = df.loc[~(df[\"BraTS21ID\"].isin(ids))].reset_index(drop=True)\n    return df\n\n\n# drop_ids = \"00109, 00123, 00709\".split(\", \")\n# df_train = drop_by_id(df_train, drop_ids)\n# labels_train = drop_by_id(labels_train, drop_ids)","b40b020a":"def count_values(df: pd.DataFrame):\n    groupby = df.groupby([\"BraTS21ID\", \"series_description\"])\n    count = groupby.count()\n    display(count[\"dcm_path\"].describe())\n    display(count.loc[count[\"dcm_path\"] == count[\"dcm_path\"].min(), \"dcm_path\"])\n    display(count.loc[count[\"dcm_path\"] == count[\"dcm_path\"].max(), \"dcm_path\"])\n\n\n# display(df_train.describe())\n# count_values(df_train)\n# look_one_dcm(\"00571\", data_dir \/ \"train\", mri_series[0])\n# look_one_dcm(\"00818\", data_dir \/ \"train\", mri_series[0])\n# look_one_dcm(\"00012\", data_dir \/ \"train\", mri_series[3])","dec7604e":"class MRIVoxelDataset(Dataset):\n    \n    def __init__(self, meta_df: pd.DataFrame, label_df: Optional[pd.DataFrame] = None,\n                 voxel_size: Union[int, Tuple[int, int], Tuple[int, int, int]] = (64, 256, 256),\n                 including_series: np.ndarray = np.array(list(mri_series.keys()), dtype=np.int64)):\n        \"\"\"\n        :params:\n            :meta_df: required columns: [dcm_path, BraTS21ID, series_description, plane,\n                                         image_position_x, image_position_y, image_position_z]\n            :label_df(Optional): required columns: [BraTS21ID, MGMT_value]\n            :voxel_size: if int, the D, H, W will be set to the same;\n                         if (int, int), D by voxel_size[0], H, W by voxel_size[1];\n                         if (int, int, int), D, H, W will be set respectively.\n        \"\"\"\n        super(MRIVoxelDataset, self).__init__()\n        self.meta_df,self.label_df,self.voxel_size = meta_df,label_df,voxel_size\n        self.including_series = including_series\n        if isinstance(self.voxel_size, int):\n            self.voxel_size = tuple(self.voxel_size for _ in range(3))\n        elif isinstance(self.voxel_size, tuple):\n            if len(self.voxel_size) == 2:\n                self.voxel_size = (self.voxel_size[0], self.voxel_size[1], self.voxel_size[1])\n        self.meta_df = self.meta_df.loc[self.meta_df[\"series_description\"].isin(self.including_series)].copy()\n        if self.label_df is None:\n            self.label_df = pd.concat([pd.DataFrame.from_dict(\n                dict(BraTS21ID=self.meta_df[\"BraTS21ID\"].unique())\n            )], axis=1)\n            self.label_df.loc[:, \"BraTS21ID\"] = self.label_df[\"BraTS21ID\"].map(lambda i: str(i).zfill(5))\n            labels = np.full_like(self.label_df[\"BraTS21ID\"].values, np.nan, dtype=np.float64)\n            self.label_df.loc[:, \"MGMT_value\"] = labels\n\n        new_label_df = pd.DataFrame()\n        for v in self.meta_df[\"series_description\"].unique():\n            series_desc = pd.DataFrame({\n                    \"series_description\": np.full((len(self.label_df)), v, dtype=np.int64)\n                 })\n            df = self.label_df.reset_index(drop=True)\n            df = pd.concat([df, series_desc], axis=1)\n            new_label_df = pd.concat([new_label_df, df], axis=0)\n        self.label_df = new_label_df.reset_index(drop=True)\n\n        retrievables = list()\n        for i in range(len(self.label_df)):\n            row = self.label_df.iloc[i]\n            flag = is_retrievable(self.meta_df, row.BraTS21ID, row.series_description)\n            if not flag:\n                print(row.BraTS21ID, row.series_description)\n            retrievables.append(flag)\n        retrievables = np.asarray(retrievables)\n        self.label_df = self.label_df.iloc[retrievables]\n        print(f\"Got {len(self)} samples in dataset.\")\n\n    def __len__(self): return len(self.label_df)\n    \n    def __getitem__(self, idx):\n        row = self.label_df.iloc[idx]\n        voxel, plane = get_voxel_by_id_series(self.meta_df, row[\"BraTS21ID\"], row[\"series_description\"], self.voxel_size[1:])\n        voxel = torch.tensor(voxel, dtype=torch.float32).unsqueeze(0).unsqueeze(0)  # [N, C, D, H, W]\n        voxel = F.interpolate(voxel, self.voxel_size, mode=\"trilinear\", align_corners=False)\n        voxel = voxel.squeeze(0)\n        label = torch.tensor([row[\"MGMT_value\"]], dtype=torch.float32)\n        plane = torch.tensor(plane, dtype=torch.int64)\n        series_desc = torch.tensor(row[\"series_description\"], dtype=torch.int64)\n        return voxel, label, (series_desc, plane)\n\n\n# if DEBUG:\n#     ds_ = MRIVoxelDataset(df_train, labels_train, (64, 128), np.array([0], dtype=np.int64))\n#     dl_ = DataLoader(ds_, batch_size=4, num_workers=4)\n#     for voxel, label, (series_desc, plane) in dl_:\n#         print(voxel.shape, label.shape, plane.shape, series_desc.shape)\n#         print(voxel.dtype, label.dtype, plane.dtype, series_desc.dtype)\n#         break","4ff0ca6e":"NormLayerClass = Type\nActivationLayerClass = Type\n\n\nclass SqueezeExcitation(nn.Module):\n    \n    def __init__(self, in_channels):\n        super(SqueezeExcitation, self).__init__()\n        self.in_channels = in_channels\n        self.squeeze_channels = self.in_channels \/\/ 4\n        \n        self.seq = nn.Sequential(\n            nn.AdaptiveAvgPool3d(1),\n            nn.Conv3d(self.in_channels, self.squeeze_channels, 1),\n            nn.ReLU(inplace=True),\n            nn.Conv3d(self.squeeze_channels, self.in_channels, 1),\n            nn.Hardsigmoid(inplace=True),\n        )\n    \n    def forward(self, x):\n        scale = self.seq(x)\n        out = scale * x\n        return out\n\n\nclass ConvBNActivation(nn.Module):\n    \n    def __init__(self, conv_config: dict,\n                 norm_layer_cls: NormLayerClass = nn.BatchNorm3d,\n                 activation_layer_cls: ActivationLayerClass = nn.ReLU,\n                 use_se: bool = False,\n        ) -> None:\n        super(ConvBNActivation, self).__init__()\n        layers = list()\n        layers.append(nn.Conv3d(**conv_config))\n        layers.append(norm_layer_cls(conv_config[\"out_channels\"]))\n        layers.append(activation_layer_cls(inplace=True))\n        if use_se:\n            layers.append(SqueezeExcitation(conv_config[\"out_channels\"]))\n        self.seq = nn.Sequential(*layers)\n    \n    def forward(self, x):\n        return self.seq(x)\n    \n    @staticmethod\n    def config(in_channels: int,\n               out_channels: int,\n               kernel_size: Union[int, Tuple[int, int, int]],\n               stride: Union[int, Tuple[int, int, int]] = 1,\n               padding: Union[int, Tuple[int, int, int]] = 0,\n               dilation: Union[int, Tuple[int, int, int]] = 1,\n               groups: int = 1,\n               bias: bool = True,\n               padding_mode: str = 'zeros',\n        ) -> dict:\n        return locals()\n\n\nclass BottleNeck(nn.Module):\n    \n    def __init__(self, residual_config: dict):\n        super(BottleNeck, self).__init__()\n        self.residual_config = residual_config\n        layers = list()\n        layers.append(ConvBNActivation(ConvBNActivation.config(\n            self.residual_config[\"in_channels\"],\n            self.residual_config[\"expand_channels\"],\n            1,\n            1,\n            0,\n        ), self.residual_config[\"norm_layer_cls\"], self.residual_config[\"activation_layer_cls\"]))\n        layers.append(ConvBNActivation(ConvBNActivation.config(\n            self.residual_config[\"expand_channels\"],\n            self.residual_config[\"expand_channels\"],\n            self.residual_config[\"kernel_size\"],\n            self.residual_config[\"stride\"],\n            self.residual_config[\"padding\"],\n            groups=self.residual_config[\"expand_channels\"],\n        ), self.residual_config[\"norm_layer_cls\"],\n           self.residual_config[\"activation_layer_cls\"],\n           self.residual_config[\"use_se\"]))\n        layers.append(ConvBNActivation(ConvBNActivation.config(\n            self.residual_config[\"expand_channels\"],\n            self.residual_config[\"out_channels\"],\n            1,\n            1,\n            0,\n        ), self.residual_config[\"norm_layer_cls\"], nn.Identity))\n        self.seq = nn.Sequential(*layers)\n        # The shortcut: Same as nn.Linear if channels at last dim.\n        self.shortcut = nn.Conv3d(self.residual_config[\"in_channels\"], self.residual_config[\"out_channels\"], 1)\n    \n    def forward(self, x):\n        post_seq = self.seq(x)\n        x = self.shortcut(x)\n        x = F.interpolate(x, post_seq.shape[-3:], mode=\"trilinear\", align_corners=False)\n        return x + post_seq\n    \n    @staticmethod\n    def config(in_channels: int,\n               out_channels: int,\n               expand_channels: int,\n               kernel_size: Union[int, Tuple[int, int, int]],\n               stride: Union[int, Tuple[int, int, int]] = 1,\n               padding: Union[int, Tuple[int, int, int]] = 0,\n               norm_layer_cls: NormLayerClass = nn.BatchNorm3d,\n               activation_layer_cls: ActivationLayerClass = nn.Hardswish,\n               use_se: bool = False,\n    ) -> dict:\n        return locals()\n\n\nclass NetFeatures(nn.Module):\n    \n    def __init__(self, in_channels, out_channels, residual_config_list: List[dict]):\n        super(NetFeatures, self).__init__()\n        self.in_channels,self.out_channels = in_channels,out_channels\n        self.residual_config_list = residual_config_list\n\n        first_conv_out_channels = self.residual_config_list[0][\"in_channels\"]\n        self.first_conv = ConvBNActivation(ConvBNActivation.config(\n            self.in_channels, first_conv_out_channels, 3, 2, 1), activation_layer_cls=nn.ReLU)\n        residual_layers = list()\n        for conf in self.residual_config_list:\n            residual_layers.append(BottleNeck(conf))\n        self.residual_block = nn.Sequential(*residual_layers)\n        last_conv_in_channels = self.residual_config_list[-1][\"out_channels\"]\n        self.last_conv = ConvBNActivation(ConvBNActivation.config(last_conv_in_channels, self.out_channels, 1),\n                                          nn.BatchNorm3d,\n                                          nn.Hardswish,\n                                          use_se=True)\n    \n    def forward(self, x):\n        x = self.first_conv(x)\n        x = self.residual_block(x)\n        x = self.last_conv(x)\n        return x\n\n\nclass ConcatEmbeddingLinear(nn.Module):\n    \n    def __init__(self, in_features: int, out_features: int, n_embeddings: int, embed_dim: Optional[int] = None):\n        super(ConcatEmbeddingLinear, self).__init__()\n        self.in_features,self.out_features = in_features,out_features\n        self.n_embeddings,self.embed_dim = n_embeddings,embed_dim\n        if self.embed_dim is None: self.embed_dim = self.in_features\n        \n        self.emb = nn.Embedding(self.n_embeddings, self.embed_dim)\n        self.fc = nn.Linear(self.in_features + self.embed_dim, self.out_features)\n    \n    def forward(self, x, idx_emb):\n        emb_out = self.emb(idx_emb)\n        concatenated = torch.cat([emb_out, x], dim=-1)\n        out = self.fc(concatenated)\n        return out\n\n\nclass Net(nn.Module):\n    \n    def __init__(self, in_channels, feature_out_channels, hidden_features, n_classes, n_series, n_planes,\n                 residual_config_list: List[dict]) -> None:\n        super(Net, self).__init__()\n        self.in_channels,self.feature_out_channels,self.n_classes = in_channels,feature_out_channels,n_classes\n        self.hidden_features = hidden_features\n        self.n_planes,self.n_series = n_planes,n_series\n        self.residual_config_list = residual_config_list\n        \n        self.features = NetFeatures(self.in_channels, self.feature_out_channels, self.residual_config_list)\n        self.pool_flat_linear = nn.Sequential(nn.AdaptiveAvgPool3d(1),\n            nn.Flatten(),\n            nn.Linear(self.features.out_channels, self.hidden_features),\n        )\n        self.emb_series = ConcatEmbeddingLinear(self.hidden_features, self.hidden_features, self.n_series)\n        self.emb_planes = ConcatEmbeddingLinear(self.hidden_features, self.hidden_features, self.n_planes)\n        self.classifier = nn.Sequential(\n            nn.Dropout(0.2),\n            nn.Linear(self.hidden_features, self.n_classes)\n        )\n\n    def forward(self, x, idx_series, idx_planes):\n        x = self.features(x)\n        x = self.pool_flat_linear(x)\n        x = self.emb_series(x, idx_series)\n        x = self.emb_planes(x, idx_planes)\n        out = self.classifier(x)\n        return out\n\n\ndef get_residual_config_backup():\n    # Like MobileNetV3 small, although it may be too deep.\n    # in_channels, out_channels, expand_channels, kernel_size, stride, padding, norm, activation, use_se\n    conf = list()\n    conf.append(BottleNeck.config(16, 16, 16, 3, 2, 1, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(16, 24, 72, 3, 2, 1, nn.BatchNorm3d, nn.ReLU, False))\n    conf.append(BottleNeck.config(24, 24, 88, 3, 1, 1, nn.BatchNorm3d, nn.ReLU, False))\n    conf.append(BottleNeck.config(24, 40, 96, 5, 2, 2, nn.BatchNorm3d, nn.ReLU, True))\n    conf.append(BottleNeck.config(40, 40, 240, 5, 1, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(40, 40, 240, 5, 1, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(40, 48, 120, 5, 1, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(48, 48, 144, 5, 1, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(48, 96, 288, 5, 2, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(96, 96, 576, 5, 1, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(96, 96, 576, 5, 1, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    return conf\n\n\ndef get_residual_config():\n    # in_channels, out_channels, expand_channels, kernel_size, stride, padding, norm, activation, use_se\n    conf = list()\n    conf.append(BottleNeck.config(16, 16, 16, 3, 2, 1, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(16, 24, 72, 3, 2, 1, nn.BatchNorm3d, nn.ReLU, False))\n    conf.append(BottleNeck.config(24, 24, 88, 3, 1, 1, nn.BatchNorm3d, nn.ReLU, False))\n    conf.append(BottleNeck.config(24, 40, 96, 5, 2, 2, nn.BatchNorm3d, nn.ReLU, True))\n    conf.append(BottleNeck.config(40, 40, 240, 5, 1, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(40, 80, 288, 5, 2, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    conf.append(BottleNeck.config(80, 96, 576, 5, 1, 2, nn.BatchNorm3d, nn.Hardswish, True))\n    return conf\n\n\nif DEBUG:\n    t_ = torch.ones(4, 1, 64, 256, 256, dtype=torch.float32)\n    l_ = torch.ones(4, 1, dtype=torch.float32)\n    s_ = torch.ones(4, dtype=torch.int64)\n    p_ = torch.ones(4, dtype=torch.int64)\n    config_ = get_residual_config()\n    net_ = Net(1, 512, 512, 1, 4, 4, config_).to(dtype=torch.float32)\n    print(net_)\n    with torch.no_grad():\n        o_ = net_(t_, s_, p_)\n        loss_ = F.binary_cross_entropy_with_logits(o_, l_)\n        print(loss_.item())","4746727a":"def load_model(path, *net_args, **net_kwargs):\n    net = Net(*net_args, **net_kwargs)\n    state_dict = torch.load(path)\n    net.load_state_dict(state_dict)\n    return net","35aa9950":"class RandomInvert3D(AugmentationBase3D):\n    \n    def __init__(\n        self,\n        max_val: Union[float, torch.Tensor] = torch.tensor(1.0),\n        return_transform: bool = False,\n        same_on_batch: bool = False,\n        p: float = 0.5,\n    ) -> None:\n        super(RandomInvert3D, self).__init__(\n            p=p, return_transform=return_transform, same_on_batch=same_on_batch, p_batch=1.0\n        )\n        self.max_val = max_val\n\n    def __repr__(self) -> str:\n        return self.__class__.__name__ + f\"({super().__repr__()})\"\n    \n    def generate_parameters(self, batch_shape: torch.Size):\n        return dict(max_val=torch.as_tensor(self.max_val), batch_shape=torch.as_tensor(batch_shape))\n    \n    def compute_transformation(self, input, params: Dict[str, torch.Tensor]):\n        return self.identity_matrix(input)\n\n    def apply_transform(\n        self, input: torch.Tensor,\n        params: Dict[str, torch.Tensor],\n        transform: Optional[torch.Tensor] = None\n    ) -> torch.Tensor:\n        max_val = params[\"max_val\"]\n        return invert(input, max_val)\n\n    \nNumeric = Union[int, float]\n\n\nclass RandomShift3D(nn.Module):\n    \n    def __init__(self,\n                 shift_limit: Union[Numeric, List[Numeric], Tuple[Numeric, Numeric]] = 0.125,\n                 p: float = 0.5):\n        super(RandomShift3D, self).__init__()\n        self.shift_limit,self.p = shift_limit,p\n        if isinstance(self.shift_limit, (float, int)):\n            self.shift_limit = np.array(((-abs(self.shift_limit), abs(self.shift_limit)),\n                                         (-abs(self.shift_limit), abs(self.shift_limit)),\n                                         (-abs(self.shift_limit), abs(self.shift_limit)),), dtype=np.float64)\n        elif isinstance(self.shift_limit, (tuple, list)):\n            self.shift_limit = np.array(self.shift_limit, dtype=np.float64)\n        else:\n            raise TypeError(\"shift_limit expects \")\n        self.shift_limit = np.clip(self.shift_limit, -1., 1.)\n        if self.shift_limit.shape[0] == 1:\n            self.shift_limit = np.concatenate([self.shift_limit, self.shift_limit, self.shift_limit])\n        assert self.shift_limit.shape == (3, 2), f\"\"\n    \n    def forward(self, tensor):\n        assert len(tensor.shape) == 5, f\"Requires 5 dims torch.Tensor[N, C, D, H, W], got {tensor.shape}\"\n        n, c, d, h, w = tensor.shape\n        apply_proba = np.random.uniform(size=(n,))\n        shift_size = np.random.uniform(low=self.shift_limit[:, 0], high=self.shift_limit[:, 1], size=(n, 3))\n        shift_d, shift_h, shift_w = (np.array(tensor.shape[2:])[np.newaxis, :] * shift_size).astype(np.int64).T\n        out = torch.zeros_like(tensor)\n        for i in range(n):\n            if apply_proba[i] <= self.p:\n                out[i, :,\n                    max(0, 0+shift_d[i]):min(d, d+shift_d[i]),\n                    max(0, 0+shift_h[i]):min(h, h+shift_h[i]),\n                    max(0, 0+shift_w[i]):min(w, w+shift_w[i]),\n                ] = tensor[i, :,\n                    max(0, 0-shift_d[i]):min(d, d-shift_d[i]),\n                    max(0, 0-shift_h[i]):min(h, h-shift_h[i]),\n                    max(0, 0-shift_w[i]):min(w, w-shift_w[i]),\n                ]\n            else:\n                out[i] = tensor[i]  # Unchanged.\n        return out\n\n\ndef get_augmentation(split=\"train\") -> nn.Sequential:\n    \"\"\"\n    Get Sequence of augmentations.\n    :return: nn.Sequential: requires input: torch.FloatTensor[N, C, D, H, W] in range[0., 1.]\n    \"\"\"\n    if split in (\"test\", \"val\"):\n        aug_list = nn.Sequential()\n    elif split == \"train\":\n        aug_list = nn.Sequential(\n            K.augmentation.RandomAffine3D(degrees=(5., 5., 90.), translate=(.05, .05, .05), scale=(.98, 1.02), p=.3),\n            K.augmentation.RandomHorizontalFlip3D(p=.3),\n#             K.augmentation.RandomVerticalFlip3D(p=.1),\n#             K.augmentation.RandomRotation3D((0., 0., 90.), p=1.0)\n            RandomShift3D(shift_limit=0.2, p=.3),\n            RandomInvert3D(p=.1),\n        )\n    else:\n        raise ValueError(f\"Argument `split` must in {{'train', 'val', 'test'}}, got {split}\")\n    aug_list.requires_grad_(False)\n    return aug_list\n\n\ndef plot_grid(t: torch.tensor) -> None:\n    \"\"\"\n    Plot image by middle index\n    :argument: t: torch.Tensor[N, C, D, H, W]\n    \"\"\"\n    from itertools import product\n    a = int(np.ceil(np.sqrt(len(t))))\n    fig, axes = plt.subplots(a, a, figsize=(14, 14))\n    for nth, (i, j) in zip(range(len(t)), product(range(a), range(a))):\n        nth_img = t[nth].squeeze(0).numpy()\n        nth_img_mid = nth_img[len(nth_img) \/\/ 2]\n        mean, std = np.mean(nth_img), np.std(nth_img)\n        axes[i, j].imshow(nth_img_mid, cmap=plt.cm.gray)\n        axes[i, j].set_title(f\"mean: {mean:.4f}, std: {std:.4f}\")\n        axes[i, j].set_axis_off()\n    plt.show()\n\n\n# # Check the effect of augmentation.\n# ds_ = MRIVoxelDataset(df_train, labels_train, (64, 128))\n# dl_ = DataLoader(ds_, batch_size=16, shuffle=True, num_workers=6)\n# aug_ = get_augmentation(split=\"train\")\n# for voxel, label, (_, _) in dl_:\n#     voxel = aug_(voxel)\n#     plot_grid(voxel)\n#     break","ac0d4439":"# Parameters to construct Net\nin_channels = 1\nfeature_out_channels = 576\nhidden_features = 512\nn_classes = 1\nn_series = len(mri_series)\nn_planes = len(planes)\nresidual_config = get_residual_config()\n\n# Training Parameters\nbatch_size = 16\nepochs = 18\nlr = 3e-4\nnum_workers = 6\nweight_decay = 1e-5","3a46c81b":"voxel_size = (64, 64, 64)\nincluding_series = np.array([\n    mri_series_map[\"FLAIR\"],\n    mri_series_map[\"T1w\"],\n    mri_series_map[\"T1wCE\"],\n    mri_series_map[\"T2w\"],\n], dtype=np.int64)\nNumpyNDArray = Iterable\n\ndef get_dataset_in_pipeline(img_dir: Path, including_series: NumpyNDArray[np.int64],\n                            voxel_size: Union[int, Tuple[int, int], Tuple[int, int, int]] = (64, 256, 256),\n                            glob: str = None,\n                            df_labels: pd.DataFrame = None, drop_ids: List[str] = None):\n    df_meta = get_meta_from_glob(img_dir, glob)\n    df_meta.loc[:, \"plane\"] = df_meta.loc[:, \"plane\"].map(planes_map)\n    df_meta.loc[:, \"series_description\"] = df_meta.loc[:, \"series_description\"].map(mri_series_map)\n    df_meta = keep_non_blank(df_meta)\n    if df_labels is not None:\n        df_labels = drop_by_id(df_labels, drop_ids)\n        df_meta = drop_by_id(df_meta, drop_ids)\n    ds = MRIVoxelDataset(df_meta, df_labels, voxel_size, including_series)\n    return ds","229f9663":"def is_retrievable(df: pd.DataFrame,\n                   patient_id: str,\n                   series_desc_idx: int):\n    retrieved_idx = (df[\"BraTS21ID\"].eq(patient_id)) & (df[\"series_description\"].eq(series_desc_idx))\n    return True if retrieved_idx.sum() > 0 else False\n\n\ndef get_voxel_by_id_series(df: pd.DataFrame,\n                           patient_id: str,\n                           series_desc_idx: int = 0,\n                           size: Union[int, Tuple[int, int]] = 256) -> Tuple[np.ndarray, int]:\n    \"\"\"\n    :params:\n        :df: required columns: [dcm_path, BraTS21ID, series_description, plane,\n                                image_position_x, image_position_y, image_position_z]\n    \"\"\"\n    size = (int(size), int(size)) if isinstance(size, (int, float)) else size\n    retrieved_idx = (df[\"BraTS21ID\"].eq(patient_id)) & (df[\"series_description\"].eq(series_desc_idx))\n    assert retrieved_idx.sum() > 0, \"Nothing retrived.\"\n    retrieved_df = df.loc[retrieved_idx].copy()\n    plane = retrieved_df[\"plane\"].unique()\n    assert len(plane) == 1, \"Different plane in a folder.\"\n    img_pos_cols = [c for c in retrieved_df.columns if c.startswith(\"image_position_\")]\n    img_pos_stds = np.array([retrieved_df[c].std() for c in img_pos_cols])\n    img_pos_argsort = np.argsort(img_pos_stds)[::-1]\n    sorted_df = retrieved_df.sort_values([img_pos_cols[i] for i in img_pos_argsort], ascending=True, ignore_index=True)\n    voxel_stack = list()\n    for row in sorted_df.itertuples():\n        dcm_obj = pydicom.read_file(row.dcm_path)\n        array = dcm_obj.pixel_array\n        array = cv.resize(array, size)\n        dinfo = np.iinfo(array.dtype) if np.issubdtype(array.dtype, np.integer) else np.finfo(array.dtype)\n        array = (array \/ dinfo.max).astype(np.float32)  # like (a \/ 255) if a.dtype is uint8\n        if dcm_obj[0x0028, 0x0004] == \"MONOCHROME1\":\n            array = dinfo.max - array\n        voxel_stack.append(array)\n    voxel = np.stack(voxel_stack)\n    voxel = (voxel - np.min(voxel)) \/ max(np.max(voxel), 1e-8)  # min-max normalization\n    return voxel, plane[0]\n\n\ndef plot_voxel(voxel, max_n_plots=10, cols=10):\n    actual_n_plots = min(max_n_plots, len(voxel))\n    rows = int(np.ceil(actual_n_plots \/ cols))\n    fig, axes = plt.subplots(rows, cols, figsize=(4 * cols, 4 * rows), tight_layout=True)\n    for i in range(actual_n_plots):\n        axes[i \/\/ cols, i % cols].imshow(voxel[i, :, :], cmap=plt.cm.gray)\n        axes[i \/\/ cols, i % cols].set_axis_off()\n    plt.show()","79737bbf":"ds_test = get_dataset_in_pipeline(data_dir \/ \"test\", including_series, voxel_size)","c023a3f6":"@torch.no_grad()\ndef inference_by_models(loader: DataLoader, models_list: List[Net], aug_list, device):\n\n    df_copy: pd.DataFrame = loader.dataset.label_df.copy()\n    batch_size = loader.batch_size\n    for i, model in enumerate(models_list):\n        df_copy.loc[:, f\"MGMT_value_{i}\"] = np.full_like(df_copy[\"BraTS21ID\"], np.nan, dtype=np.float64)\n        model.to(device)\n        model.eval()\n        for n, (voxel, _, (series_desc, plane))  in tqdm(enumerate(loader),\n                                                         desc=f\"Inferencing with model idx {i}\", total=len(loader)):\n            voxel, series_desc, plane = aug_list(voxel).to(device), series_desc.to(device), plane.to(device)\n            out = model(voxel, series_desc, plane)\n            pred_proba = torch.sigmoid(out.detach())[:, 0]\n            df_copy.iloc[n*batch_size:n*batch_size+len(voxel),\n                         df_copy.columns.get_loc(f\"MGMT_value_{i}\")] = pred_proba.cpu().numpy()\n    df = df_copy.groupby(\"BraTS21ID\").mean()\n    use_cols = [s for s in df.columns if s.startswith(\"MGMT_value_\")]\n    df[\"MGMT_value\"] = df.loc[:, use_cols].mean(axis=1)\n    df = df.reset_index()\n    submission = df.loc[:, [\"BraTS21ID\", \"MGMT_value\"]].copy()\n    return submission\n\n\naug_list = get_augmentation(split=\"test\")\nmodels_path = list(sorted(models_dir.glob(f\"{model_name}*whole*best-state_dict.pt\")))\nif USE_CROSS_VALIDATION:\n    models_path.extend(list(sorted(models_dir.glob(f\"{model_name}*fold*best-state_dict.pt\"))))\nprint(models_path)\nmodels_list = [load_model(path,\n                          in_channels,\n                          feature_out_channels,\n                          hidden_features,\n                          n_classes,\n                          n_series,\n                          n_planes,\n                          residual_config,\n) for path in models_path]\ndl_test = DataLoader(ds_test, batch_size=batch_size, num_workers=num_workers)\nsubmission_mob = inference_by_models(dl_test, models_list, aug_list, device)\nsubmission_mob.to_csv(\"submission_mob.csv\", index=False)","c84673ad":"# Import dependencies \nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt \n%matplotlib inline\n\nimport os, sys, glob, gc \nimport math, re, random, time\nfrom tqdm import tqdm \nimport cv2, pydicom\n\nfrom sklearn.model_selection import StratifiedKFold \n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers","806ac928":"# Params\nconfig = {\n    'data_path': '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification',\n    'model_path': '..\/input\/keras-3d-efficientnet-imagenet-weights-b0b7\/efficientnet3d_keras\/efficientnet-b0_inp_channel_3_tch_0_top_False.h5',\n    'input_path': '..\/input', \n    'output_path': '.\/',\n    'num_3d': 16,\n    'img_size': 64,\n    'n_gradients': 16,\n    'nfolds': 5, \n    'batch_size': 16,\n    'learning_rate': 1e-4,\n    'num_epochs': 10\n}\n\nAUTO = tf.data.AUTOTUNE\n\n# For reproducible results    \ndef seed_all(s):\n    random.seed(s)\n    np.random.seed(s)\n    tf.random.set_seed(s)\n    os.environ['TF_CUDNN_DETERMINISTIC'] = '1'\n    os.environ['PYTHONHASHSEED'] = str(s) \nglobal_seed = 42\nseed_all(global_seed)\n\ninput_modality = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"]\nmodality_list = [\"FLAIR\", \"T1w\", \"T2w\"] \n\ntrain_folder = os.path.join(config['data_path'], 'train')\ntest_folder = os.path.join(config['data_path'], 'test')\nsample_submission_path = os.path.join(config['data_path'], 'sample_submission.csv')\n\ntrain_df = pd.read_csv(os.path.join(config['data_path'], 'train_labels.csv')); print(train_df.shape)\nsample_df = pd.read_csv(sample_submission_path); print(sample_df.shape)\ntest_df = sample_df.copy(); print(test_df.shape)","8b50e7c2":"# Getting each folder paths of BraTS21ID\n\ntrain_df['imfolder'] = ['{:05d}'.format(s) for s in train_df['BraTS21ID']]\ntrain_df['path'] = [os.path.join(train_folder, s) for s in train_df['imfolder']]\ntrain_df","f2fae29a":"# Counting the files in FLAIR folder\n\n#input_modality = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"] \ninput_modality = [\"FLAIR\"] \nfor modality in input_modality:   \n    modality_count = []\n    for i in range(len(train_df)):\n        sample_folder = train_df['path'].iloc[i]\n        modality_folder = os.path.join(sample_folder, modality)\n        if os.path.exists(modality_folder):\n            modality_count.append(len(os.listdir(modality_folder)))\n        else:\n            modality_count.append(0)\n        \n    train_df[f'{modality}_count'] = modality_count    \n    \ntrain_df = train_df.query(\"FLAIR_count >= 16\").reset_index()\n    \ntrain_df","8a45fa07":"# k-fold (n=5) for cross-validation (I conducted hold-out validation in this notebook, though.)\n\nskf = StratifiedKFold(n_splits=config['nfolds'], shuffle=True, random_state=global_seed)\n\nfor index, (train_index, val_index) in enumerate(skf.split(X=train_df.index, y=train_df.MGMT_value)):\n    train_df.loc[val_index, 'fold'] = index\n    \nprint(train_df.groupby(['fold', train_df.MGMT_value]).size())","a4106281":"test_df['imfolder'] = ['{:05d}'.format(s) for s in test_df['BraTS21ID']]\ntest_df['path'] = [os.path.join(test_folder, s) for s in test_df['imfolder']]\ntest_df","d408add7":"#input_modality = [\"FLAIR\", \"T1w\", \"T1wCE\", \"T2w\"] \ninput_modality = [\"FLAIR\"] \n\nfor modality in input_modality:   \n    modality_count = []\n    for i in range(len(test_df)):\n        sample_folder = test_df['path'].iloc[i]\n        modality_folder = os.path.join(sample_folder, modality)\n        if os.path.exists(modality_folder):\n            modality_count.append(len(os.listdir(modality_folder)))\n        else:\n            modality_count.append(0)\n        \n    test_df[f'{modality}_count'] = modality_count    \n    \ntest_df = test_df.query(\"FLAIR_count >= 16\").reset_index()\n\ntest_df","5b093de7":"def get_img_path_3d(df, index, mri_type='FLAIR'):\n    patient_id = df['BraTS21ID'][index]\n    patient_path = df['path'][index]\n    modality_path = os.path.join(patient_path, mri_type)\n    total_img_num = df[f'{mri_type}_count'][index]\n    \n    files = sorted(glob.glob(f\"{modality_path}\/*.dcm\"), \n                   key=lambda var:[int(x) if x.isdigit() else x for x in re.findall(r'[^0-9]|[0-9]+', var)])\n    \n    mid_num = total_img_num \/\/ 2\n    num_3d2 = config['num_3d'] \/\/ 2\n    start_idx = max(0, mid_num - num_3d2)\n    end_idx = min(len(files), mid_num + num_3d2)\n    \n    target_file_paths = files[start_idx:end_idx]\n    \n    return target_file_paths\n\n@tf.function\ndef preprocessing_img(img, threashold=5):\n    img = img - tf.math.reduce_mean(img)\n    img = img \/ tf.math.reduce_variance(img)\n    img = img - tf.math.reduce_min(img)\n    img = tf.where(img<threashold, img, threashold)\n    return img\n\n    \nclass ImageGenerator(tf.keras.utils.Sequence):\n    def __init__(self, df, mri_type='FLAIR'):\n        self.df = df\n        self.mri_type = mri_type\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, index):\n        paths = get_img_path_3d(self.df, index)\n        img_list = []\n        for path in paths:\n            dicom = pydicom.read_file(path)\n            img = dicom.pixel_array\n            img = np.expand_dims(img, -1)\n            #img = np.repeat(img, 3, axis=-1)\n            img = tf.convert_to_tensor(img, dtype=tf.float32)\n            img = tf.image.resize(img, [config['img_size'], config['img_size']])\n            img = tf.expand_dims(img, -2)\n            img_list.append(img)\n        img_3d = tf.concat(img_list, axis=-2)\n        return img_3d\n    \n    \ndef parse(x):\n    result = tf.io.parse_tensor(x, out_type=tf.float32)\n    result = tf.reshape(result, [config['img_size'], config['img_size'], config['num_3d'], 1])\n    return result\n\n\ndef build_3d_train_dataloader(train_df, p_fold=0):\n    p_train = train_df.query(f'fold != {p_fold}').reset_index(drop=True)\n    p_valid = train_df.query(f'fold == {p_fold}').reset_index(drop=True)\n\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n\n    train_datasets = []\n    for mode, df in zip(['train', 'valid'], [p_train, p_valid]):\n        i_g = ImageGenerator(df)\n        img_ds = tf.data.Dataset.from_generator(lambda: map(tuple, i_g),\n                                                output_types=(tf.float32),\n                                                output_shapes=(tf.TensorShape([config['img_size'], config['img_size'], config['num_3d'], 1])),\n                                                 )\n        \n        serial_ds = img_ds.map(tf.io.serialize_tensor)\n\n        if not os.path.exists(f'{mode}-{p_fold}-img.tfrec'):\n            img_tfrec = tf.data.experimental.TFRecordWriter(f'{mode}-{p_fold}-img.tfrec')\n            img_tfrec.write(serial_ds)\n        serial_ds = tf.data.TFRecordDataset(f'{mode}-{p_fold}-img.tfrec')\n        serial_ds = serial_ds.map(parse, num_parallel_calls=AUTOTUNE)\n\n        labels = df['MGMT_value']\n        label_ds = tf.data.Dataset.from_tensor_slices(tf.cast(labels, tf.int32))\n\n        ds = tf.data.Dataset.zip((img_ds, label_ds))\n        \n        ds = ds.cache(filename=f'.\/cache.tf-{mode}-{p_fold}-data')\n        if mode == 'train':\n            train_count = len(df)\n            ds = ds.shuffle(buffer_size=train_count)\n        ds = ds.batch(config['batch_size'], drop_remainder=True)\n        ds = ds.prefetch(buffer_size=AUTOTUNE)\n        train_datasets.append(ds)\n\n    return train_datasets","56c95303":"# Building Dataset\np_fold = 0\n\ntrain_datasets = build_3d_train_dataloader(train_df, p_fold=p_fold)\ntrain_ds = train_datasets[0]\nvalid_ds = train_datasets[1]\n\nfor d, l in train_ds.take(1):\n    print('Train Data shape: ', d.shape)\n    print('Train Label shape: ', l.shape)\n    \nfor d, l in valid_ds.take(1):\n    print('Valid Data shape: ', d.shape)\n    print('Valid Label shape: ', l.shape)","cf042b30":"# TestDataset without Labels\ndef build_3d_test_dataloader(test_df):\n    AUTOTUNE = tf.data.experimental.AUTOTUNE\n\n    i_g = ImageGenerator(test_df)\n    img_ds = tf.data.Dataset.from_generator(lambda: map(tuple, i_g),\n                                         output_types=(tf.float32),\n                                         output_shapes=(tf.TensorShape([config['img_size'], config['img_size'], config['num_3d'], 1])),\n                                                 )\n    serial_ds = img_ds.map(tf.io.serialize_tensor)\n\n    if not os.path.exists('test-img.tfrec'):\n        img_tfrec = tf.data.experimental.TFRecordWriter('test-img.tfrec')\n        img_tfrec.write(serial_ds)\n    serial_ds = tf.data.TFRecordDataset('test-img.tfrec')\n    test_ds = serial_ds.map(parse, num_parallel_calls=AUTOTUNE)\n\n    test_ds = test_ds.cache(filename='.\/cache.tf-test-data')\n    test_ds = test_ds.batch(config['batch_size'], drop_remainder=False)\n    test_ds = test_ds.prefetch(buffer_size=AUTOTUNE)\n\n    return test_ds","c5ccaa71":"test_ds = build_3d_test_dataloader(test_df)\n\nfor d in test_ds.take(1):\n    print('Test Data shape: ', d.shape)","dec90011":"def get_3d_model(width=config['img_size'], height=config['img_size'], depth=config['num_3d']):\n    \"\"\"Build a 3D convolutional neural network model.\"\"\"\n\n    inputs = keras.Input((width, height, depth, 1))\n    \n    x = layers.Conv3D(filters=32, kernel_size=3, padding='same', activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv3D(filters=32, kernel_size=3, padding='same', activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    \n    x = layers.Conv3D(filters=64, kernel_size=3, padding='same', activation=\"relu\")(inputs)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.01)(x)\n    \n    x = layers.Conv3D(filters=128, kernel_size=3, padding='same', activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.02)(x)\n\n    x = layers.Conv3D(filters=256, kernel_size=3, padding='same', activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.03)(x)\n\n    x = layers.Conv3D(filters=512, kernel_size=3, padding='same', activation=\"relu\")(x)\n    x = layers.MaxPool3D(pool_size=2)(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Dropout(0.04)(x)\n\n    x = layers.GlobalAveragePooling3D()(x)\n    x = layers.Dense(units=1024, activation=\"relu\")(x)\n    x = layers.Dropout(0.08)(x)\n\n    outputs = layers.Dense(units=1, activation=\"sigmoid\")(x)\n\n    model = keras.Model(inputs, outputs, name=\"3dcnn\")\n\n    return model\n\n\nmodel = get_3d_model()\nmodel.summary()","d6c7b65e":"class BrainTumorModel3D(tf.keras.Model):\n    def __init__(self, *args, **kwargs):\n        super().__init__(*args, **kwargs)        \n        self.cnn = get_3d_model()\n        \n    @tf.function\n    def call(self, input_tensor, training=False, **kwargs):\n        x = self.cnn(input_tensor)\n        return x\n    \n    def build_graph(self, raw_shape):\n        x = tf.keras.layers.Input(shape=raw_shape)\n        return tf.keras.Model(inputs=[x], outputs=self.call(x))\n\n\nif tf.test.is_gpu_available():\n    device_name = tf.test.gpu_device_name()\nelse:\n    device_name = 'cpu:0'\n\nwith tf.device(device_name):\n    model = BrainTumorModel3D()","f8a650bd":"optimizer = tf.keras.optimizers.Adam(learning_rate=config['learning_rate'])\n\nloss_fn = tf.keras.losses.BinaryCrossentropy(from_logits=False)\n\ntrain_acc_metric = tf.keras.metrics.BinaryAccuracy()\nval_acc_metric = tf.keras.metrics.BinaryAccuracy()\n\nearly_stopping = tf.keras.callbacks.EarlyStopping(monitor='val_loss', patience=3)\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath=config['output_path'],\n    save_weights_only=True,\n    monitor='val_loss',\n    mode='min',\n    save_best_only=True)\n\n@tf.function\ndef train_step(x, y):\n    \n    with tf.GradientTape() as tape:\n        pred_y = model(x, training=True)\n        train_loss = loss_fn(y, pred_y)\n        \n    grads = tape.gradient(train_loss, model.trainable_weights)\n    \n    optimizer.apply_gradients(zip(grads, model.trainable_weights))\n    \n    train_acc_metric.update_state(y_true=y, y_pred=pred_y)\n    \n    return train_loss\n\n\n@tf.function\ndef valid_step(x, y):\n    pred_y = model(x, training=False)\n    val_loss = loss_fn(y, pred_y)\n    \n    val_acc_metric.update_state(y_true=y, y_pred=pred_y)\n    \n    return val_loss","8cde45a0":"train_history = []\nvalid_history = []\n\nfor epoch in range(config['num_epochs']):\n    t = time.time()\n    \n    train_loss_list = []\n    val_loss_list = []\n    \n    for x, y in train_ds:\n        train_batch_loss = train_step(x, y)\n        train_loss_list.append(train_batch_loss)\n        \n    for x, y in valid_ds:\n        val_batch_loss = valid_step(x, y)\n        val_loss_list.append(val_batch_loss)\n        \n    train_loss = sum(train_loss_list) \/ len(train_loss_list)\n    val_loss = sum(val_loss_list) \/ len(val_loss_list)\n    \n    train_acc = train_acc_metric.result()\n    val_acc = val_acc_metric.result()\n    \n    train_history.append(train_loss)\n    valid_history.append(val_loss)\n    \n    template = 'ETA: {} -- epoch: {}, loss: {}  acc: {}  val_loss: {}  val_acc: {}\\n'\n    print(template.format(\n                   round((time.time() -  t) \/ 60, 2), epoch+1,\n                   (train_loss, '.3f'), (train_acc, '.3f'),\n                   (val_loss, '.3f'), (val_acc, '.3f'))\n         )\n    \n    train_acc_metric.reset_states()\n    val_acc_metric.reset_states()","b2cfa77b":"class GradAcumModel(tf.keras.Model):\n    def __init__(self, model, n_gradients=config['n_gradients'], *args, **kwargs):\n        super(GradAcumModel, self).__init__(*args, **kwargs)\n        self.model = model\n        self.n_gradients = tf.constant(n_gradients, dtype=tf.int32)\n        self.n_acum_step = tf.Variable(0, dtype=tf.int32, trainable=False)\n        self.gradient_accumulation = [tf.Variable(tf.zeros_like(v, dtype=tf.float32),\n                                                  trainable=False)\n                                       for v in self.model.trainable_variables]\n\n    @tf.function\n    def train_step(self, data):\n        self.n_acum_step.assign_add(1)\n        images, labels = data\n\n        with tf.GradientTape() as tape:\n            predictions = self.model(images, training=True)\n            loss = self.compiled_loss(labels, predictions)\n\n        gradients = tape.gradient(loss, self.model.trainable_variables)\n\n        for i in range(len(self.gradient_accumulation)):\n            self.gradient_accumulation[i].assign_add(gradients[i])\n\n        # If n_acum_step reach the n_gradients then we apply accumulated gradients -\n        # - to update the variables otherwise do nothing\n        tf.cond(tf.equal(self.n_acum_step, self.n_gradients),\n                self.apply_accu_gradients, lambda: None)\n        \n        self.compiled_metrics.update_state(labels, predictions)\n        return {m.name: m.result() for m in self.metrics}\n\n    def apply_accu_gradients(self):\n        self.optimizer.apply_gradients(zip(self.gradient_accumulation,\n                                           self.model.trainable_variables))\n        \n        # Reset\n        self.n_acum_step.assign(0)\n        for i in range(len(self.gradient_accumulation)):\n            self.gradient_accumulation[i].assign(\n                tf.zeros_like(self.model.trainable_variables[i], dtype=tf.float32)\n            )\n\n    @tf.function\n    def test_step(self, data):\n        images, labels = data\n\n        predictions = self.model(images, training=False)\n        loss = self.compiled_loss(labels, predictions)\n        self.compiled_metrics.update_state(labels, predictions)\n        return {m.name: m.result() for m in self.metrics}\n\n    def call(self, inputs, *args, **kwargs):\n        return self.model(inputs)\n\nwith tf.device(device_name):\n    grad_acum_model = GradAcumModel(model, n_gradients=4)","bfa87a00":"proba = model.predict(test_ds, batch_size=config['batch_size'], verbose=1)\nproba","b461fb92":"test_df['prediction'] = proba\nsample_df['MGMT_value'] = test_df['prediction']\nsample_df","8b5a0df1":"sample_df.to_csv(\"submission_3dcnn.csv\", index=False)","f61f807c":"submission_3dcnn = sample_df.copy()","0a7b2a70":"import os\nimport sys \nimport json\nimport glob\nimport random\nimport re\nimport collections\nimport time\n\nimport numpy as np\nimport pandas as pd\nimport pydicom\nimport cv2\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport torch\nfrom torch import nn\nfrom torch.utils import data as torch_data\nfrom sklearn import model_selection as sk_model_selection\nfrom torch.nn import functional as torch_functional\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score","cd6fce8b":"data_directory = '\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\ninput_monaipath = \"\/kaggle\/input\/monai-v060-deep-learning-in-healthcare-imaging\/\"\nmonaipath = \"\/kaggle\/tmp\/monai\/\"","4807732c":"!mkdir -p {monaipath}\n!cp -r {input_monaipath}\/* {monaipath}","3f797615":"mri_types = ['FLAIR', 'T1w', 'T1wCE', 'T2w']\nSIZE = 256\nNUM_IMAGES = 64\nBATCH_SIZE = 4\nN_EPOCHS = 16\nSEED = 12345\nLEARNING_RATE = 0.0005\nLR_DECAY = 0.9\n\nsys.path.append(monaipath)\n\nfrom monai.networks.nets.densenet import DenseNet121","7fddac79":"def load_dicom_image(path, img_size=SIZE):\n    dicom = pydicom.read_file(path)\n    data = dicom.pixel_array\n    if np.min(data)==np.max(data):\n        data = np.zeros((img_size,img_size))\n        return data\n    \n    data = cv2.resize(data, (img_size, img_size))\n    return data\n\n\ndef natural_sort(l): \n    convert = lambda text: int(text) if text.isdigit() else text.lower()\n    alphanum_key = lambda key: [convert(c) for c in re.split('([0-9]+)', key)]\n    return sorted(l, key=alphanum_key)\n\n\ndef load_dicom_images_3d(scan_id, num_imgs=NUM_IMAGES, img_size=SIZE, mri_type=\"FLAIR\", split=\"train\"):\n    files = natural_sort(glob.glob(f\"{data_directory}\/{split}\/{scan_id}\/{mri_type}\/*.dcm\"))\n    \n    every_nth = len(files) \/ num_imgs\n    indexes = [min(int(round(i*every_nth)), len(files)-1) for i in range(0,num_imgs)]\n    \n    files_to_load = [files[i] for i in indexes]\n    \n    img3d = np.stack([load_dicom_image(f) for f in files_to_load]).T \n    \n    img3d = img3d - np.min(img3d)\n    if np.max(img3d) != 0:\n        img3d = img3d \/ np.max(img3d)\n    \n    return np.expand_dims(img3d,0)\n\n\nload_dicom_images_3d(\"00000\", mri_type=mri_types[0]).shape","14316b43":"def set_seed(seed):\n    random.seed(seed)\n    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    if torch.cuda.is_available():\n        torch.cuda.manual_seed_all(seed)\n        torch.backends.cudnn.deterministic = True\n\nset_seed(SEED)","39cfe9e8":"samples_to_exclude = [109, 123, 709]\n\ntrain_df = pd.read_csv(f\"{data_directory}\/train_labels.csv\")\nprint(\"original shape\", train_df.shape)\ntrain_df = train_df[~train_df.BraTS21ID.isin(samples_to_exclude)]\nprint(\"new shape\", train_df.shape)\ndisplay(train_df)\n\ndf_train, df_valid = sk_model_selection.train_test_split(\n    train_df, \n    test_size=0.2, \n    random_state=SEED, \n    stratify=train_df[\"MGMT_value\"],\n)","0c7cbdd1":"class Dataset(torch_data.Dataset):\n    def __init__(self, paths, targets=None, mri_type=None, split=\"train\"):\n        self.paths = paths\n        self.targets = targets\n        self.mri_type = mri_type\n        self.split = split\n          \n    def __len__(self):\n        return len(self.paths)\n    \n    def __getitem__(self, index):\n        scan_id = self.paths[index]\n        if self.targets is None:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=self.split)\n        else:\n            data = load_dicom_images_3d(str(scan_id).zfill(5), mri_type=self.mri_type[index], split=\"train\")\n            \n        if self.targets is None:\n            return {\"X\": data, \"id\": scan_id}\n        else:\n            return {\"X\": data, \"y\": torch.tensor(self.targets[index], dtype=torch.float)}","2fd6f95e":"def build_model():\n    model = DenseNet121(spatial_dims=3, in_channels=1, out_channels=1)\n    return model    ","2ed8768e":"modelfiles = ['FLAIR-e2-loss0.720-auc0.615.pth', 'T1w-e9-loss0.712-auc0.651.pth', 'T1wCE-e8-loss0.703-auc0.588.pth', 'T2w-e4-loss0.722-auc0.611.pth']\nprint(modelfiles)","54be90c8":"def predict(modelfile, df, mri_type, split):\n    print(\"Predict:\", modelfile, mri_type, df.shape)\n    df.loc[:,\"MRI_Type\"] = mri_type\n    data_retriever = Dataset(\n        df.index.values, \n        mri_type=df[\"MRI_Type\"].values,\n        split=split\n    )\n\n    data_loader = torch_data.DataLoader(\n        data_retriever,\n        batch_size=4,\n        shuffle=False,\n        num_workers=8,\n    )\n   \n    model = build_model()\n    model.to(device)\n    \n    checkpoint = torch.load(f'..\/input\/for-densenet\/{modelfile}')\n    model.load_state_dict(checkpoint[\"model_state_dict\"])\n    model.eval()\n    \n    y_pred = []\n    ids = []\n\n    for e, batch in enumerate(data_loader,1):\n        print(f\"{e}\/{len(data_loader)}\", end=\"\\r\")\n        with torch.no_grad():\n            tmp_pred = torch.sigmoid(model(torch.tensor(batch[\"X\"]).float().to(device)).squeeze(1)).cpu().numpy().squeeze()\n            if tmp_pred.size == 1:\n                y_pred.append(tmp_pred)\n            else:\n                y_pred.extend(tmp_pred.tolist())\n            ids.extend(batch[\"id\"].numpy().tolist())\n            \n    preddf = pd.DataFrame({\"BraTS21ID\": ids, \"MGMT_value\": y_pred}) \n    preddf = preddf.set_index(\"BraTS21ID\")\n    return preddf","7924b256":"submission_densnet = pd.read_csv(f\"{data_directory}\/sample_submission.csv\", index_col=\"BraTS21ID\")\n\nsubmission_densnet[\"MGMT_value\"] = 0\nfor m, mtype in zip(modelfiles, mri_types):\n    pred = predict(m, submission_densnet, mtype, split=\"test\")\n    submission_densnet[\"MGMT_value\"] += pred[\"MGMT_value\"]\n\nsubmission_densnet[\"MGMT_value\"] \/= len(modelfiles)\nsubmission_densnet[\"MGMT_value\"].to_csv(\"submission_densnet.csv\")","f777cf93":"fsubmission = submission_mob.copy()\nfsubmission['MGMT_value'] = submission_densnet['MGMT_value'].values*0.05 + submission_effnet3d_score_0684['MGMT_value'].values*0.4 + submission_bt3d['MGMT_value'].values*0.3 + \\\n                            submission_mob['MGMT_value'].values*0.1 + submission_effnet3d_score_0674['MGMT_value'].values*0.1 + submission_3dcnn['MGMT_value'].values*0.05","9b2274e3":"fsubmission['BraTS21ID'] = fsubmission['BraTS21ID'].apply(lambda x: str(x).zfill(5))","1dc03c2f":"fsubmission","44422ab2":"submissionDF01 = fsubmission.set_index('BraTS21ID')\nscoreDict01 = submissionDF01['MGMT_value'].to_dict()\nprint(scoreDict01)","373ff1b9":"listOfStudyPaths = glob.glob('..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/*')\nlistOfStudies = [eachPath.split('\/')[-1] for eachPath in listOfStudyPaths]\n\npredList = []\nfor eachStudy in listOfStudies:\n    if eachStudy not in scoreDict01:\n        predList.append('0.500')\n    else:\n        score = float(scoreDict01[eachStudy])\n        predList.append(score)\n        \nsubmissionDF = pd.DataFrame({'BraTS21ID':listOfStudies,'MGMT_value':predList})\nsubmissionDF.to_csv('submission.csv', index=False)","786c102f":"submissionDF","e2e8a85b":"### Efficientnet3D with one MRI type [Inference]","8d99651c":"### \ud83e\udde0Brain Tumor 3D [Inference]","e85cd367":"### Ensembling","7d765b6c":"### A-Net-With-Embeddings-for-Ordered-3D-MRI-Voxel","797fda2d":"### [RSNA-MICCAI] Monai - ensemble","0b7ee41b":"# If you copy - Upvote! Version where score is 0.715 won't predict private lb. It will get the error. Version where score is 0.706 is ready to predict.","7def84cc":"### Efficientnet3D with one MRI type 0.674","e0488bfc":"### miccai_fakeSubmission","1b6bc854":"### [TF] Simple Prediction with 3DCNN","de34bfd8":"* densnet score is 0.656\n* effnet3d 1 score is 0.684\n* bt3d score is 0.683\n* mobile net score is 0.667\n* effnet3d 2 score is 0.674\n* 3dcnn score is 0.663"}}