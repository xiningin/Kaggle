{"cell_type":{"f6bee241":"code","816bf8c8":"code","e9310fa6":"code","f77d98af":"code","059a5640":"code","40e6ea46":"code","06ad9697":"code","bfde3cf6":"code","3aca30f3":"code","390a2886":"code","18f0e72b":"code","5ebfc3ea":"code","c4410b2c":"code","061f1807":"code","89dadcb7":"code","5665190c":"code","3e4b108f":"code","8271b5b0":"code","28299756":"code","8ce7151d":"code","4a213a32":"code","17119dc0":"code","e96582a5":"code","abb2a716":"code","3bece056":"code","f039b576":"code","5bb85bf3":"code","07a841b7":"code","e7f94568":"code","be7c5ba0":"code","7a7bb6de":"code","c8b67f69":"code","422ef8b8":"markdown","6511a519":"markdown"},"source":{"f6bee241":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n#import numpy as np # linear algebra\n#import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","816bf8c8":"import numpy as np\nnp.random.seed(0)\n\nfrom skimage.transform import resize, rescale\n\nimport matplotlib.pyplot as plt\nfrom matplotlib import pyplot\n\nimport tensorflow as tf\nfrom tensorflow.keras.layers import Input, Dense, Conv2D, MaxPooling2D, Dropout\nfrom tensorflow.keras.layers import Conv2DTranspose, UpSampling2D, add\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import regularizers\n\n\n\n\nprint(tf.__version__)","e9310fa6":"!conda install -y gdown\n","f77d98af":"#!gdown --id 1Edjoxw0URUZGqsrn_yb9aHeIO5sHNZtX","059a5640":"#!gdown --id 1EgniBXFeJVbLb_W7IekUXjQP1E7tbt8S","40e6ea46":"#!gdown --id 1EljGQbTV82TU-m29bstxI52atTWlMAtV","06ad9697":"!gdown --id 1Em0vVggHuMeYA4IV90i0Flcny-mEJQU6","bfde3cf6":"#now concatenate\n#cars_train = np.concatenate((np.load('X1.npy'), np.load('X2.npy'), np.load('X3.npy')))","3aca30f3":"#train_data in high_resolution\n#print(cars_train.shape)","390a2886":"cars = np.load('X4.npy') #contains 2432 images","18f0e72b":"#test_data in high resolution\n#print(cars_test.shape)","5ebfc3ea":"#rescale up normally leads to loss of quality as the dimensions\n#is higher than original image\n#get back to original dimension degrade the quality\n#d1 = rescale(rescale(cars[:500], 2), 0.5)","c4410b2c":"def preprocessing_fun(img):\n    img1 = np.asarray(rescale(rescale(img, 2), 0.5, anti_aliasing=True))\n    return img1\n","061f1807":"lr_test = [preprocessing_fun(cars[i]) for i in range(100)]","89dadcb7":"lr_test1 = [preprocessing_fun(cars[i]) for i in range(100, 200)]","5665190c":"lr_test2 = [preprocessing_fun(cars[i]) for i in range(200, 300)]","3e4b108f":"lr = np.concatenate((lr_test, lr_test1,lr_test2))","8271b5b0":"cars_train = cars[:250]\ncars_test = cars[250:300]","28299756":"print(len(cars_test))","8ce7151d":"lr_train = lr[:250]\nlr_test = lr[250:300]","4a213a32":"plt.imshow(cars_train[0])","17119dc0":"plt.imshow(lr_train[0])","e96582a5":"#lets do the preprocessing using for both, finding low resolution\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\ntri=ImageDataGenerator()\n\ntrain = tri.flow(\n    lr_train,\n    cars_train,\n    batch_size=16\n    #class_mode=\"input\", #for autoencoder model no class so set this as input\n   )","abb2a716":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\nte=ImageDataGenerator()\n\ntest = te.flow(\n    lr_test,\n    cars_test,\n    batch_size=16\n    #class_mode=\"input\", #for autoencoder model no class so set this as input\n   )","3bece056":"input_img = Input(shape=(256, 256, 3))\nl1 = Conv2D(64, (3, 3), padding = 'same', activation = 'relu', \n            activity_regularizer = regularizers.l1(10e-10))(input_img)\n\nl2 = Conv2D(64, (3, 3), padding = 'same', activation = 'relu', \n            activity_regularizer = regularizers.l1(10e-10))(l1)\n\nl3 = MaxPooling2D(padding = 'same')(l2)\nl3 = Dropout(0.3)(l3)\n\nl4 = Conv2D(128, (3, 3),  padding = 'same', activation = 'relu', \n            activity_regularizer = regularizers.l1(10e-10))(l3)\n\nl5 = Conv2D(128, (3, 3), padding = 'same', activation = 'relu', \n            activity_regularizer = regularizers.l1(10e-10))(l4)\nl6 = MaxPooling2D(padding = 'same')(l5)\n\nl7 = Conv2D(256, (3, 3), padding = 'same', activation = 'relu', \n            activity_regularizer = regularizers.l1(10e-10))(l6)\nl8 = UpSampling2D()(l7)\n\nl9 = Conv2D(128, (3, 3), padding = 'same', activation = 'relu',\n            activity_regularizer = regularizers.l1(10e-10))(l8)\n\nl10 = Conv2D(128, (3, 3), padding = 'same', activation = 'relu',\n             activity_regularizer = regularizers.l1(10e-10))(l9)\n\nl11 = add([l5, l10])\nl12 = UpSampling2D()(l11)\n\nl13 = Conv2D(64, (3, 3), padding = 'same', activation = 'relu',\n             activity_regularizer = regularizers.l1(10e-10))(l12)\nl14 = Conv2D(64, (3, 3), padding = 'same', activation = 'relu',\n             activity_regularizer = regularizers.l1(10e-10))(l13)\n\nl15 = add([l14, l2])\n\ndecoded = Conv2D(3, (3, 3), padding = 'same', \n                 activation = 'relu', activity_regularizer = regularizers.l1(10e-10))(l15)\n\nautoencoder = Model(input_img, decoded)\n#autoencoder_hfenn = Model(input_img, decoded)","f039b576":"autoencoder.summary()","5bb85bf3":"autoencoder.compile(optimizer = 'adam', loss = 'mean_squared_error')","07a841b7":"\n\nhistory=autoencoder.fit_generator(train, epochs=20, \n                        shuffle=True,\n                       validation_data=test)\n  \n                    \n                              \n\n\n","e7f94568":"# saving whole model\nautoencoder.save('autoencoder_SR_model.h5')\n \n# loading whole model\nfrom keras.models import load_model\nmodelsr = load_model('autoencoder_SR_model.h5')","be7c5ba0":"sr1 = np.clip(modelsr.predict(lr), 0.0, 1.0)","7a7bb6de":"image_index = 4","c8b67f69":"plt.figure(figsize = (20, 20))\ni = 1\nax = plt.subplot(10, 10, i)\nplt.imshow(lr_train[image_index])\ni += 1\nax = plt.subplot(10, 10, i)\nplt.imshow(lr_train[image_index], interpolation = \"bicubic\")\ni += 1\nax = plt.subplot(10, 10, i)\nplt.imshow(cars_train[image_index])\ni += 1\nax = plt.subplot(10, 10, i)\nplt.imshow(sr1[image_index])\nplt.show()","422ef8b8":"[Prject cloned](https:\/\/github.com\/hiverkiya\/Image-Super-Resolution-Using-Keras) for more [preprocessing and trained for few data and epoches](https:\/\/colab.research.google.com\/drive\/1y3FAUsTMKpDVodSmvt-OFxL5zJjiZ6eC?usp=sharing) stages\n#Cars trained dataset of 8141 high quality images ","6511a519":"#download .npy files saved in drive using colab\n\n[download from gdrive](https:\/\/medium.com\/analytics-vidhya\/how-to-import-data-from-google-drive-into-kaggle-notebook-3af68a1f0d4)"}}