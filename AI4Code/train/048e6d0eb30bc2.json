{"cell_type":{"cd884c1d":"code","c1820d24":"code","3199ead7":"code","e4465a40":"code","ab8cc5b3":"code","34513edb":"code","8949eca6":"code","99ce3f56":"code","7878896e":"code","a703f29a":"code","a050da04":"code","e87b63e0":"code","04773840":"code","70367561":"code","a5215554":"code","a5020822":"code","a4fbaa2e":"code","c100bb13":"code","7f9f7737":"code","a6e8aa78":"code","b7d35bda":"code","4cb4edbd":"code","8afe08b7":"code","f27ecb36":"code","6bd63a7d":"code","5622fe4f":"code","511be055":"markdown","70fef94f":"markdown","e30d532d":"markdown","5c3ddbc4":"markdown","23617d09":"markdown"},"source":{"cd884c1d":"!pip install -U rouge transformers > \/dev\/null","c1820d24":"from tqdm.notebook import tqdm\ntqdm.pandas()\nfrom IPython.display import display, Markdown\nfrom pathlib import Path\n\nimport numpy as np\nimport pandas as pd \n\nimport torch\nimport transformers\nfrom transformers import BartTokenizer, BartForConditionalGeneration\n\nfrom nltk.tokenize import sent_tokenize","3199ead7":"PATH_TO_CRYPTO_NEWS = Path('..\/input\/news-about-major-cryptocurrencies-20132018-40k\/')","e4465a40":"train_df = pd.read_csv(PATH_TO_CRYPTO_NEWS \/ 'crypto_news_parsed_2013-2017_train.csv')\nvalid_df = pd.read_csv(PATH_TO_CRYPTO_NEWS \/ 'crypto_news_parsed_2018_validation.csv')\n\n# readling empty strings is a bit different locally and here, but not a big deal \ntrain_df['text'].fillna(' ', inplace=True)","ab8cc5b3":"train_df.shape, valid_df.shape","34513edb":"def minimal_processing(s):\n    return s.strip().replace('\\r', '').replace('\\n', ' ')","8949eca6":"def extract_and_process_first_k_sent(text, k=3):\n    \n    sent_tok = sent_tokenize(text)\n    \n    if not sent_tok:\n        return ' '\n    \n    result = \" \".join([minimal_processing(sent.strip(' .').lower()) \n                                 for sent in sent_tok[:k]])\n    \n    return result","99ce3f56":"# train_texts = train_df['text'].progress_apply(lambda text: \n#                                               extract_and_process_first_k_sent(text))\n\nvalid_texts = valid_df['text'].progress_apply(lambda text: \n                                              extract_and_process_first_k_sent(text, k=10))","7878896e":"torch_device = 'cuda:0' if torch.cuda.is_available() else 'cpu'","a703f29a":"tokenizer = BartTokenizer.from_pretrained('bart-large-cnn')\nmodel = BartForConditionalGeneration.from_pretrained('bart-large-cnn').to(torch_device)","a050da04":"example_text = train_df.loc[0, 'text']\nexample_title = train_df.loc[0, 'title']","e87b63e0":"display(Markdown('> **Title:** ' + example_title))\ndisplay(Markdown('> **Text:** ' + example_text))","04773840":"article_input_ids = tokenizer.batch_encode_plus([example_text], \n                                                return_tensors='pt', \n                                                max_length=128)['input_ids'].to(torch_device)\nsummary_ids = model.generate(article_input_ids,\n                             num_beams=4,\n                             length_penalty=2.0,\n                             max_length=20,\n                             min_length=5,\n                             no_repeat_ngram_size=3)\n\nsummary_txt = tokenizer.decode(summary_ids.squeeze(), skip_special_tokens=True)\ndisplay(Markdown('> **Summary:** ' + summary_txt))","70367561":"bs = 32\n\nval_summaries = []\n\nfor i in tqdm(range(0, len(valid_texts), bs)):\n\n    article_input_ids = tokenizer.batch_encode_plus(valid_texts.iloc[i:i+bs].tolist(), \n                                                    return_tensors='pt', pad_to_max_length=True,\n                                                    max_length=512)['input_ids'].to(torch_device)\n    \n    summary_ids = model.generate(article_input_ids,\n                             num_beams=4,\n                             length_penalty=2.0,\n                             max_length=40,\n                             min_length=5,\n                             no_repeat_ngram_size=3)\n    \n    val_summaries.extend([tokenizer.decode(summary_ids[i].squeeze(), skip_special_tokens=True).lower()\n            for i in range(len(summary_ids))])","a5215554":"val_summaries[:10]","a5020822":"valid_titles = valid_df['title'].str.lower().tolist()","a4fbaa2e":"from rouge import Rouge \n\nrouge = Rouge()\nscores = rouge.get_scores(hyps=[el.split('.')[0] for el in val_summaries], refs=valid_titles, \n                          avg=True, ignore_empty=True)\nscores","c100bb13":"final_metric = (scores['rouge-1']['f'] + scores['rouge-2']['f'] + scores['rouge-l']['f']) \/ 3\nfinal_metric","7f9f7737":"val_res_df = pd.DataFrame({'title': valid_titles, \n                           'generated': val_summaries,\n                          'text': valid_texts.values}).reset_index(drop=True)","a6e8aa78":"val_rouge_scores = rouge.get_scores(hyps=val_summaries, refs=valid_titles, avg=False, ignore_empty=True)","b7d35bda":"val_res_df['rouge-1'] = [el['rouge-1']['f'] for el in val_rouge_scores]\nval_res_df['rouge-2'] = [el['rouge-2']['f'] for el in val_rouge_scores]\nval_res_df['rouge-L'] = [el['rouge-l']['f'] for el in val_rouge_scores]\nval_res_df['avg_rouge'] = (val_res_df['rouge-1'] + val_res_df['rouge-2'] + val_res_df['rouge-L']) \/ 3","4cb4edbd":"val_res_df.head()","8afe08b7":"def print_result(row):\n    print('_' * 68)\n    display(Markdown('> **Rouge:** ' + str(round(row['avg_rouge'], 3))))\n    display(Markdown('> **Title:** ' + row['title']))\n    display(Markdown('> **Text:** ' + row['text']))\n    display(Markdown('> **Generated:** ' + row['generated']))\n    print('_' * 68)","f27ecb36":"for _, row in val_res_df.sort_values(by='avg_rouge', ascending=False).head(30).iterrows():\n    print_result(row)","6bd63a7d":"for _, row in val_res_df.sort_values(by='avg_rouge', ascending=True).head(30).iterrows():\n    print_result(row)","5622fe4f":"val_res_df.to_csv('val_set_with_bart_generated_titles.csv', index=None)","511be055":"## Eyeballing the resuls: good and bad cases","70fef94f":"**Generating a title for the first article**","e30d532d":" **Now same for the whole validation set**","5c3ddbc4":"## Read data","23617d09":"## BART\nFollowing [this blog post](https:\/\/sshleifer.github.io\/blog_v2\/jupyter\/2020\/03\/12\/bart.html)"}}