{"cell_type":{"7aecb979":"code","1e063ab0":"code","ca25a215":"code","b348f95b":"code","e01ba5cb":"code","cfd4f341":"markdown","947a5643":"markdown","57e6baa0":"markdown","02499b5b":"markdown","6ce27665":"markdown","deeedad7":"markdown"},"source":{"7aecb979":"import numpy as np\nimport scipy.stats as stats","1e063ab0":"observed = [11,64]\ntotal = 75\nexpected = [int(0.12*75), int((1-0.12)*75)]\nchi_square_stat =(observed[0]-expected[0])**2\/expected[0]+(observed[1] - expected[1])**2\/expected[1]\nchi_square_stat","ca25a215":"crit = stats.chi2.ppf(q = 0.95, df = 1) \ncrit","b348f95b":"p_value = 1 - stats.chi2.cdf(x = chi_square_stat, df = 1)\np_value","e01ba5cb":"treat_deaths = 39\ntreat_total = 31000\nptreat = treat_deaths\/treat_total\n\ncontrol_deaths = 63\ncontrol_total = 31000\npcontrol = control_deaths\/control_total\n\npnull = (treat_deaths + control_deaths)\/(treat_total + control_total)\n\n# an example for calculate L(x)\ndenominator = (stats.binom.pmf(treat_deaths,treat_total,pnull)*stats.binom.pmf(control_deaths,control_total,pnull))\nnumenator = (stats.binom.pmf(treat_deaths,treat_total,ptreat)*stats.binom.pmf(control_deaths,control_total,pcontrol))\n\n# calculate MLE statitic\nl_stat = -2*np.log(denominator\/numenator)\nprint(\"MLE stat:\", l_stat)\n\n# According to Wilks Theorem, calculate p_value based on chi-square distribution\np_value = 1 - stats.chi2.cdf(l_stat,1)\n\n# calculate critical value if significant level is 0.05\ncrt_value = stats.chi2.ppf(0.95,1)\nprint(p_value,crt_value)","cfd4f341":"p value > 0.05, therefore we do not have enough evidence to reject null hypotheis. ","947a5643":"## Chi Square test\n\nSee detailed explanation in this [video](https:\/\/www.youtube.com\/watch?v=ZNXso_riZag).\n\n*Scenario: there are 75 students in an art class and 11 of them are left handed. Does this class fit the prevailing theory that 12% of people are left handed?*\n\n**observation**: 11 left handed, 64 right handed\n\n**estimate**: 9 left handed, 66 right handed.\n\nSet up our hypothesis: \n\n* H<sub>0<\/sub>: pi = 0.12\n\n* H<sub>A<\/sub>: pi \u2260 0.12\n\n* significant level = 0.05\n\n\n**Chi square test statistic:** \n\n  *Note: The chi-squared test assumes none of the expected counts are less than 5.*","57e6baa0":"1. **Approach 1**: Find the critical value for siginificant level of 0.05 and df = 1 of Chi Square distribution by `stats.chi2.ppf()`","02499b5b":"since chi_square_stat < critical value, we fail to reject null hypothesis.\n\n2. **Approach 2**: calculate p value of chi-square statistic by `stats.chi2.cdf()`","6ce27665":"## Likelihood ratio test\n\n1. **Likelihood ratio** \n\n  $L(x) = \\frac{max_{\\theta\\in\\Theta_0}p(x;\\theta)}{max_{\\theta\\in\\Theta}p(x;\\theta)}$ \n\n  where $\\Theta=\\Theta_0\\cup\\Theta_A$, and model $X \\sim p(x,\\theta) \\text{ } binomial$ \n\n  * the parameter $\\hat{\\theta} $ that maximizes $p(x,\\theta)$ is called **maximum likelihood estimator**.\n\n  * L(x) \u2248 1 if $\\theta \\in \\Theta_0$\n\n  * L(x) << 1 if $\\theta \\in \\Theta_A$\n\n2. **Likelihood test**\n\n  Likelihood ratio statistics: $\\Lambda(x) = -2log(L(x)), 0 \u2264 \\Lambda(x) < \\infty$\n\n  * Reject $H_0$ if $\\Lambda(x)$ is too large\n\n  * <u>Wilks Theorem<\/u>: under $H_0$, $\\Lambda(x) \\to \\chi_d^2, when \\text{ } n \\to \\infty, df = dim(\\Theta) - dim(\\Theta_0)$","deeedad7":"Since \"MLE stat\" (5.71) is larger then critical value when alpha = 0.05 (3.84). Also, p value (0.02) is smaller than 0.05, we can reject null hypothesisi."}}