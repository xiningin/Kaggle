{"cell_type":{"5526ae80":"code","72d689e8":"code","8d090909":"code","7c77d73f":"code","1f24177b":"code","7e8a4577":"code","4c864cfb":"code","da0e4dd6":"code","a703af5e":"code","4aad6e71":"code","50aae4a1":"code","9c7c3a2d":"code","636625e1":"code","e95299d5":"code","7085fc49":"code","86226799":"code","125251d6":"code","57038e19":"code","f4e86b3a":"code","a381523b":"code","317099ae":"code","66f0c7d9":"code","8a5e4ca1":"code","12728c49":"code","f6bc0abf":"code","aee1dcd9":"code","319a1bec":"code","efe16ac6":"code","1f5703a8":"code","8e72609b":"code","54d696e6":"code","ba262976":"code","1b0f71f6":"code","c1e1d959":"code","5f8a8e0e":"markdown","10983724":"markdown","4da74f05":"markdown","c1c30fd9":"markdown","19aff78b":"markdown","d7b55620":"markdown","8488f922":"markdown","4ba30896":"markdown"},"source":{"5526ae80":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom keras.layers import Input, Dense, Dropout, Activation, Add, Concatenate, Conv2D, Conv2DTranspose, UpSampling2D, MaxPooling2D, MaxPool2D, Flatten, BatchNormalization\nfrom keras import regularizers\nfrom keras.models import Model, Sequential\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nfrom keras.optimizers import SGD, Adam, RMSprop, Adadelta\nimport keras.backend as K\nfrom keras.objectives import mean_squared_error\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils, to_categorical\nfrom keras.datasets import cifar10\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, accuracy_score, confusion_matrix\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))","72d689e8":"(X_train_images, y_train_labels), (X_test_images, y_test_labels) = cifar10.load_data()\n\nprint('X_train_images.shape: ', X_train_images.shape)\nprint('X_test_images.shape: ', X_test_images.shape)\nprint('y_train_labels.shape: ', y_train_labels.shape)\nprint('y_test_labels.shape: ', y_test_labels.shape)","8d090909":"## function used for visualizing the predicted and true labels of test data\ndef show_test(m, X_test, y_test, d):\n    plt.figure(figsize =(40,8))\n    for i in range(5):\n        ax = plt.subplot(1, 5, i+1)\n        test_image = np.expand_dims(d[1810*i+5], axis=0)\n        test_result = m.predict(test_image)\n        plt.imshow(X_test[1810*i+5])\n        index = np.argsort(test_result[0,:])\n        plt.title(\"Pred:{}, True:{}\".format(dict[index[9]], dict[y_test[1810*i+5][0]]))\n    plt.show()\n\n## function used for creating a classification report and confusion matrix\ndef report(predictions, y_test):\n    cm=confusion_matrix(y_test.argmax(axis=1), predictions.argmax(axis=1))\n    \n    print(\"Classification Report:\\n\")\n    cr=classification_report(y_test.argmax(axis=1),\n                                predictions.argmax(axis=1), \n                                target_names=list(dict.values()))\n    print(cr)\n    \n    #plot confusion_matrix\n    plt.figure(figsize=(8,6))\n    sns.heatmap(cm, annot=True, xticklabels = list(dict.values()), yticklabels = list(dict.values()), fmt=\"d\")\n    \n## function used for visualizing original and reconstructed images of the autoencoder model\ndef showOrigAndReconstructedImages(orig_imgs, decoded_imgs, img_width, img_height, channels, num=10):\n    n = num\n    plt.figure(figsize=(20, 4))\n\n    for i in range(n):\n        # display original\n        ax = plt.subplot(2, n, i+1)\n        plt.imshow(orig_imgs[300*i].reshape(img_width, img_height, channels))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        # display reconstruction\n        ax = plt.subplot(2, n, i +1 + n)\n        plt.imshow(decoded_imgs[300*i].reshape(img_width, img_height, channels))\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()\n    \ndef train_model(model, X_train, y_train, X_valid, y_valid, data_aug = False, epochs=50, batch_size=512):\n    er = EarlyStopping(monitor='val_loss', patience=10, restore_best_weights=True, verbose=1)\n#     cp = ModelCheckpoint(filepath = 'best_model.h5',save_best_only = True,verbose=1)\n    lr = ReduceLROnPlateau(monitor='val_loss', factor=0.2, patience=5, min_delta=0.0001)\n    callbacks = [er, lr]\n    \n    if not data_aug:  \n        print('Training without data augmentation...')\n        history = model.fit(X_train, y_train, batch_size=batch_size,\n                                 epochs=epochs,\n                                 verbose=1, callbacks=callbacks,\n                                 validation_data=(X_valid,y_valid))\n        return history\n    else:\n        print('Training with data augmentation...')\n        train_datagen = ImageDataGenerator(shear_range=0.2, zoom_range=0.2, horizontal_flip=True)\n        train_set_ae = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n\n        validation_datagen = ImageDataGenerator()\n        validation_set_ae = validation_datagen.flow(X_valid, y_valid, batch_size=batch_size)\n        \n        history = model.fit_generator(train_set_ae,\n                                           epochs=epochs,\n                                           steps_per_epoch=np.ceil(X_train.shape[0]\/batch_size),\n                                           verbose=1, callbacks=callbacks,\n                                           validation_data=(validation_set_ae),\n                                           validation_steps=np.ceil(X_valid.shape[0]\/batch_size))\n        \n        return history\n    \ndef plot_loss_accuracy(history, plot_loss_only= False):\n    fig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(16, 4))\n    ax1.plot(history.history['loss'])\n    ax1.plot(history.history['val_loss'])\n    ax1.set_title('Model Loss')\n    ax1.set_ylabel('Loss')\n    ax1.set_xlabel('Epoch')\n    ax1.legend(['Train', 'Val'], loc='lower right')    \n        \n    if not plot_loss_only:\n        ax2.plot(history.history['acc'])\n        ax2.plot(history.history['val_acc'])\n        ax2.set_title('Model accuracy')\n        ax2.set_ylabel('Accuracy')\n        ax2.set_xlabel('Epoch')\n        ax2.legend(['Train', 'Val'], loc='lower right')    \n    plt.show()","7c77d73f":"no_of_classes = 10\ndict = {0:'Airplane', 1:'Automobile', 2:'Bird', 3:'Cat', 4:'Deer', 5:'Dog', 6:'Frog', 7:'Horse', 8:'Ship', 9:'Truck'}\nimg_width, img_height = 32, 32\nepochs = 50\nbatch_size = 512\n\nif K.image_data_format()=='channels_first':\n    input_shape=(3, img_width, img_height)\nelse:\n    input_shape=(img_width,img_height,3)","1f24177b":"def preprocess_data(X_train_images, X_test_images, y_train_labels, y_test_labels, no_of_classes):\n    #normalize\n    X_train_images = X_train_images.astype('float32')\/255.\n    X_test = X_test_images.astype('float32')\/255.\n    \n    #split training data further into training and validation set\n    X_train, X_valid, y_train_labels, y_valid_labels = train_test_split(X_train_images, y_train_labels, test_size=0.2, random_state=42, shuffle= True)\n    print('X_train.shape: ', X_train.shape)\n    print('X_valid.shape: ', X_valid.shape)\n    print('y_train_labels.shape: ', y_train_labels.shape)\n    print('y_valid_labels.shape: ', y_valid_labels.shape)\n    \n    #The target variable is converted to one-hot encoded data using the utils.to_categorical function of the keras library.\n    y_train = to_categorical(y_train_labels, no_of_classes)\n    y_valid = to_categorical(y_valid_labels, no_of_classes)\n    y_test = to_categorical(y_test_labels, no_of_classes)\n    print('y_train.shape: ', y_train.shape)\n    print('y_test.shape: ', y_test.shape)\n    \n    return ((X_train, y_train), (X_valid, y_valid), (X_test, y_test))","7e8a4577":"(X_train, y_train), (X_valid, y_valid), (X_test, y_test) = preprocess_data(X_train_images, X_test_images, y_train_labels, y_test_labels, no_of_classes)","4c864cfb":"def create_simple_conv_model():\n    model = Sequential()\n    model.add(Conv2D(64,(3,3),input_shape=input_shape, padding=\"same\"))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())    \n    model.add(MaxPool2D(pool_size=(2,2)))    \n    \n    model.add(Conv2D(128,(3,3),input_shape=input_shape, padding=\"same\"))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())    \n    model.add(MaxPool2D(pool_size=(2,2)))\n    \n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(Dropout(0.5))\n    \n    model.add(Dense(no_of_classes))\n    model.add(Activation('softmax'))\n        \n    model.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['acc'])\n    \n    return model\n\nconv_model = create_simple_conv_model()\nconv_model.summary()","da0e4dd6":"history = train_model(conv_model, X_train, y_train, X_valid, y_valid, data_aug = True, epochs=epochs, batch_size=batch_size)","a703af5e":"plot_loss_accuracy(history)","4aad6e71":"print('Test accuracy for benchmark model= {}'.format(conv_model.evaluate(X_test, y_test)[1]))","50aae4a1":"predictions = conv_model.predict(X_test)\nreport(predictions, y_test)","9c7c3a2d":"def create_block(input, chs): ## Convolution block of 2 layers\n    x = input\n    for i in range(2):\n        x = Conv2D(chs, 3, padding=\"same\")(x)\n        x = Activation(\"relu\")(x)\n        x = BatchNormalization()(x)\n    return x\n\ndef loss_function(y_true, y_pred):  ## loss function for using in autoencoder models\n    mses = mean_squared_error(y_true, y_pred)\n    return K.sum(mses, axis=(1,2))","636625e1":"def create_convolution_ae():\n    input_img = Input((32,32,3))\n    \n    #encoder\n    x = Conv2D(64, (3, 3), activation='relu', padding='same')(input_img)\n    x = BatchNormalization()(x)\n    x = MaxPooling2D((2, 2), padding='same')(x)\n    \n    x = Conv2D(16, (3, 3), activation='relu', padding='same')(x)\n    x = BatchNormalization()(x)\n    encoded = MaxPooling2D((2, 2), padding='same')(x)    \n\n    # at this point the representation is ...\n\n    #decoder\n    x = Conv2D(16, (3, 3), activation='relu', padding='same')(encoded)\n    x = BatchNormalization()(x)\n    x = UpSampling2D((2, 2))(x)\n    \n    x = Conv2D(32, (3, 3), activation='relu', padding='same')(x)\n    x = UpSampling2D((2, 2))(x)\n    \n    decoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\n    autoencoder = Model(input_img, decoded)\n    autoencoder.compile(optimizer='adam', loss='categorical_crossentropy')\n    encoder = Model(input_img, encoded)\n    return encoder, autoencoder","e95299d5":"# def create_convolution_ae2():\n#     input = Input((32,32,3))\n    \n#     # Encoder\n#     block1 = create_block(input, 32)\n#     x = MaxPool2D(2)(block1)\n#     block2 = create_block(x, 64)\n#     x = MaxPool2D(2)(block2)\n    \n#     #Middle\n#     middle = create_block(x, 128)\n    \n#     # Decoder\n#     up1 = UpSampling2D((2,2))(middle)\n#     block3 = create_block(up1, 64)\n#     #up1 = UpSampling2D((2,2))(block3)\n#     up2 = UpSampling2D((2,2))(block3)\n#     block4 = create_block(up2, 32)\n#     #up2 = UpSampling2D((2,2))(block4)\n    \n#     # output\n#     x = Conv2D(3, 1)(up2)\n#     output = Activation(\"sigmoid\")(x)\n#     return Model(input, middle), Model(input, output)\n\n# encoder_conv, autoencoder_conv = create_convolution_ae2()\n# # autoencoder.compile(loss='categorical_crossentropy', optimizer=Adadelta())  # model_ae.compile(SGD(1e-3, 0.9), loss=loss_function) \n# autoencoder_conv.summary()","7085fc49":"encoder_conv, autoencoder_conv = create_convolution_ae()\n# autoencoder.compile(loss='categorical_crossentropy', optimizer=Adadelta())  # model_ae.compile(SGD(1e-3, 0.9), loss=loss_function) \nautoencoder_conv.summary()","86226799":"#Train the autoencoder convolution model. No need to use labels as it is unsupervised learning\nhistory = train_model(autoencoder_conv, X_train, X_train, X_valid, X_valid, data_aug = False, epochs=epochs, batch_size=batch_size)\nprint(history)","125251d6":"plot_loss_accuracy(history, plot_loss_only=True)","57038e19":"decoded_test_imgs_conv_ae = autoencoder_conv.predict(X_test)\ndecoded_valid_imgs_conv_ae = autoencoder_conv.predict(X_valid)","f4e86b3a":"showOrigAndReconstructedImages(X_valid, decoded_valid_imgs_conv_ae, 32, 32, 3)","a381523b":"showOrigAndReconstructedImages(X_test, decoded_test_imgs_conv_ae, 32, 32, 3)","317099ae":"def classifier_dense(inp):\n    input = Input((inp.shape[1], inp.shape[2], inp.shape[3]))\n    #x = MaxPool2D()(input)\n    x = Flatten()(input)\n    #x = BatchNormalization()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.64)(x)\n    x = Dense(50, activation='relu')(x)\n    #x = Reshape((-1, 1))(x)\n    #x = Conv1D(128, (3,), activation='relu', padding='same')(x)\n    #x = MaxPool1D()(x)\n    #x = CuDNNLSTM(64)(x)\n    #x = Flatten()(x)\n    x = Dropout(0.4)(x)\n    output = Dense(no_of_classes, activation='softmax')(x)\n    return Model(input, output)\n\ndef classifier_conv(inp):\n    input = Input((inp.shape[1], inp.shape[2], inp.shape[3]))\n    x = Conv2D(1024, 3, padding=\"same\")(input)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(2)(x)\n    x = Dropout(0.5)(x)\n    \n    x = Conv2D(128, 3, padding=\"same\")(x)\n    x = Activation('relu')(x)\n    x = BatchNormalization()(x)\n    x = MaxPool2D(2)(x)\n    x = Dropout(0.5)(x)\n    \n    x = Flatten()(x)\n    x = Dense(512, activation='relu')(x)\n    x = Dropout(0.35)(x)\n    x = Dense(100, activation='relu')(x)\n    x = Dropout(0.69)(x)\n    \n    output = Dense(no_of_classes, activation='softmax')(x)\n    return Model(input, output)\n\ndef create_classifier(m, inp):  ## function for choosing dense\/convolutional classifier model\n    if m=='dense':\n        classifier = classifier_dense(inp)\n    elif m=='conv':\n        classifier = classifier_conv(inp)    \n    classifier.compile(loss='categorical_crossentropy', optimizer=Adadelta(), metrics=['acc'])\n    return classifier","66f0c7d9":"#Extracting bottleneck features to use as inputs in the classifier model:\ngist_train_ae = encoder_conv.predict(X_train)\ngist_valid_ae = encoder_conv.predict(X_valid)\ngist_test_ae = encoder_conv.predict(X_test)","8a5e4ca1":"decoder_ae_dense = create_classifier('dense', gist_train_ae)\ndecoder_ae_dense.summary()","12728c49":"history = train_model(decoder_ae_dense, gist_train_ae, y_train, gist_valid_ae, y_valid, data_aug = False, epochs=epochs, batch_size=batch_size)","f6bc0abf":"plot_loss_accuracy(history)","aee1dcd9":"print('Test accuracy for AE_dense model= {}'.format(decoder_ae_dense.evaluate(gist_test_ae, y_test)[1]))","319a1bec":"show_test(decoder_ae_dense, X_test, y_test, gist_test_ae)","efe16ac6":"predictions = decoder_ae_dense.predict(gist_test_ae)\nreport(predictions, y_test)","1f5703a8":"decoder_ae_conv = create_classifier('conv', gist_train_ae)\ndecoder_ae_conv.summary()","8e72609b":"hist = train_model(decoder_ae_conv, gist_train_ae, y_train, gist_valid_ae, y_valid, data_aug = False, epochs=epochs, batch_size=batch_size)","54d696e6":"plot_loss_accuracy(history)","ba262976":"print('Test accuracy for AE_conv model= {}'.format(decoder_ae_conv.evaluate(gist_test_ae, y_test)[1]))","1b0f71f6":"show_test(decoder_ae_conv, X_test, y_test, gist_test_ae)","c1e1d959":"predictions = decoder_ae_conv.predict(gist_test_ae)\nreport(predictions, y_test)","5f8a8e0e":"## Create Convolution Autoencoder","10983724":"## Convolutional Autoencoder with CNN as classifier:","4da74f05":"## Convolutional Autoencoder with simple NN or multi-layer perceptron as classifier:","c1c30fd9":"## Some necessary functions","19aff78b":"## Classify images using features extracted from above Autoencoder model","d7b55620":"## Data Preprocessing","8488f922":"## References:\n* https:\/\/blog.keras.io\/building-autoencoders-in-keras.html\n* https:\/\/www.kaggle.com\/aninditapani\/cifar-10-cnn-from-scratch\n* https:\/\/www.kaggle.com\/mahtabshaan\/autoencoder-as-feature-extractor-cifar10\n* https:\/\/www.kaggle.com\/amithasanshuvo\/cifar-images-classification-using-cnn","4ba30896":"## Simple CNN model as Classifier:"}}