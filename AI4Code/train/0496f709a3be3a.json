{"cell_type":{"ad83fe00":"code","f529d8c8":"code","994dbf95":"code","a66a3fb3":"code","0f448944":"code","d713ee19":"code","858a5669":"code","2408ca2f":"code","3baa2468":"code","2aaec7d5":"code","0cf4ca52":"code","1ffc73e7":"code","45b39d41":"code","789cd438":"code","71b6a1aa":"code","63435d00":"code","0e7f4a56":"code","3a543b7c":"code","41c8f9ef":"code","167ab24d":"code","f4ffc29a":"code","e899d017":"code","a417d1bc":"code","fd30b7fa":"code","ab057736":"code","7ea35e18":"code","8b3a37a1":"code","cc64838b":"code","b01c95d6":"code","1b645a90":"code","80e93cce":"code","8cdece4e":"code","42fa7bb7":"code","fbf37ad6":"code","f11dbd7c":"code","d91e1c41":"code","d8d317a6":"code","ea6746b5":"code","cd652109":"code","be8a196d":"code","e847c545":"code","fe3640ec":"code","941712ee":"code","7925fbb4":"code","93c36d1f":"code","9e0d0fd9":"code","38ed890f":"code","11eca611":"code","3562fd34":"code","3c3206e7":"code","b3cfdc72":"code","86205a7b":"code","6767e99e":"code","006995c8":"code","8e25468b":"code","380854b2":"code","0fcc03d2":"code","83907d0d":"code","c2681934":"code","0add7b05":"code","640bc815":"code","b603f93e":"code","acdfdc8d":"code","6ade9642":"code","c2c6229d":"code","6b8dd582":"code","41420c52":"code","31d8d0e5":"code","3fce6715":"code","9d1cb141":"code","e1de324c":"code","4b8e26d9":"code","4068756a":"code","8bda66c6":"code","4a564f22":"code","a071d027":"code","6c22c35d":"code","16c07df5":"code","23c8729a":"code","b21994c4":"markdown","761aadf5":"markdown","85632046":"markdown","a5f332bd":"markdown","9cb9559e":"markdown","103c3827":"markdown","0ff8d62e":"markdown","25d5ca9c":"markdown","c2786be3":"markdown","c6a6b33c":"markdown","ce802273":"markdown","1ef008aa":"markdown","5a1b7e0f":"markdown","d5e74e22":"markdown","4d59ccb9":"markdown","0f5f60c7":"markdown","fa892249":"markdown","7b6f9a44":"markdown"},"source":{"ad83fe00":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport string\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n\nfrom sklearn.metrics import plot_confusion_matrix, classification_report, f1_score\nfrom sklearn.model_selection import train_test_split ,GridSearchCV, cross_val_score\nfrom sklearn.pipeline import make_pipeline\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, Normalizer\n\n#Classification Models:\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier, StackingClassifier\n#from xgboost import XGBClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n#You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n#comment","f529d8c8":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head(30)","994dbf95":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","a66a3fb3":"train_data.shape\n#Training dataset has 891 examples with 11 features and 1 target label in column 'Survived'","0f448944":"test_data.shape\n#Test dataset has 418 samples with same 11 features as training set. And it doesn't have survived column","d713ee19":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\n\nprint(\"% of women who survived:\", rate_women)","858a5669":"men = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of men who survived:\", rate_men)","2408ca2f":"train_data.info()\n#some columns have missing values\n\n\n#object columns is \n# Name         891 non-null    object\n# Sex          891 non-null    object \n# Ticket       891 non-null    object\n# Cabin        204 non-null    object \n# Embarked     889 non-null    object ","3baa2468":"train_data[\"Survived\"].unique()","2aaec7d5":"train_data[\"Survived\"].value_counts()\n# zero not survived \n# 1 survived","0cf4ca52":"s = train_data.columns\nfor i in s :\n    print(i , len(train_data[i].unique()))","1ffc73e7":"train_data[\"Ticket\"].value_counts()","45b39d41":"plt.hist(train_data[\"Pclass\"])","789cd438":"#    SibSp        891 non-null    int64  \n#  7   Parch        891 non-null \nplt.bar(train_data[\"Survived\"] , train_data[\"SibSp\"])","71b6a1aa":"plt.bar(train_data[\"Survived\"] , train_data[\"Parch\"])","63435d00":"train_data.var()","0e7f4a56":"print(\"no. of missing train data in Embarked\" , train_data.Embarked.isna().sum())\nprint(\"no. of missing test data in Embarked\" , test_data.Embarked.isna().sum())","3a543b7c":"print(\"no. of missing train data in fare\" , train_data.Fare.isna().sum())\nprint(\"no. of missing test data in fare\" , test_data.Fare.isna().sum())","41c8f9ef":"test_data.Fare.unique()#we will fill by mean value ","167ab24d":"# test_data.Embarked.unique()\ndups = train_data.pivot_table(index = ['Embarked'], aggfunc ='size')\nprint(dups)#we will fill with s the most frequent","f4ffc29a":"train_data[\"Embarked\"] = train_data[\"Embarked\"].fillna(\"S\")\ntest_data['Fare'] = test_data['Fare'].fillna(train_data['Fare'].mean())","e899d017":"train_data.Age.describe()\n#Maximum age is 80, and minimum age is 0.42, conseqeuntly there is no unusual values for this column .","a417d1bc":"# check variable Age for missing values:\nprint(train_data.Age.isnull().sum())\nprint(test_data.Age.isnull().sum())\n","fd30b7fa":"# dups = train_data.pivot_table(index = ['Age'], aggfunc ='size')\n# print(dups)","ab057736":"# 1. create feature to show rows with missing values of age:\ntrain_data['Age_NA'] =np.where(train_data.Age.isnull(), 1, 0)\ntest_data['Age_NA'] =np.where(test_data.Age.isnull(), 1, 0)\n#if age is nan we will add 1 else we add 0 ","7ea35e18":"# train_data.head(20)","8b3a37a1":" # visualize Age_NA vs survival rate\nprint(train_data[\"Age_NA\"].value_counts())\nsns.factorplot('Age_NA','Survived', data=train_data)\n#According to the plot survival rate for people with missing Age is lower than for people that have age value.\n#TRAThis information is representative as there is enough samples for both cases: 714 and 177, \n#therefore we will keep Age_NA variable for future use.","cc64838b":"train_data.Age.plot.hist()#data likes normal distribution so we will fill age by mean","b01c95d6":"train_data['Age'] = train_data['Age'].fillna(train_data['Age'].mean())\ntest_data['Age'] = test_data['Age'].fillna(train_data['Age'].mean())","1b645a90":"train_data.Age.plot.hist()","80e93cce":"test_data.Age.plot.hist()","8cdece4e":"s = train_data.columns\nfor i in s :\n    print(i , len(train_data[i].unique()))\n    \n#PassengerId \n#Name \n#Ticket \n#Cabin ","42fa7bb7":"#PassengerId and name can be dropped as it is unique and represents ID for each passenger. \ntrain_data = train_data.drop(['PassengerId'], axis=1)\n# test_data = test_data.drop(['PassengerId'], axis=1)\ntrain_data = train_data.drop(['Name'], axis=1)\ntest_data = test_data.drop(['Name'], axis=1)","fbf37ad6":"train_data.info()","f11dbd7c":"train_data.Ticket[:10]","d91e1c41":"# test_data.Embarked.unique()\ndups = train_data.pivot_table(index = ['Ticket'], aggfunc ='size')\nprint(dups)#we will fill with s the most frequent","d8d317a6":"#create function that takes ticket feature and returns list of ticket_types\ndef ticket_sep(data_ticket):\n    ticket_type = []\n\n    for i in range(len(data_ticket)):\n\n            ticket =data_ticket.iloc[i]\n\n            for c in string.punctuation:\n                ticket = ticket.replace(c,\"\")#to remove any punctuation from ticket\n                splited_ticket = ticket.split(\" \")   \n            if len(splited_ticket) == 1:\n                ticket_type.append('NO')\n            else: \n                ticket_type.append(splited_ticket[0])\n    return ticket_type ","ea6746b5":"# we will create new feature in tarin data ==> ticket_type:\ntrain_data[\"ticket_type\"] = ticket_sep(train_data.Ticket)\n\ntrain_data.head(2)","cd652109":"# and so on we will create new feature in test data ==> ticket_type:\ntest_data[\"ticket_type\"] = ticket_sep(test_data.Ticket)\ntest_data.head(2)","be8a196d":"# check how many samples are there for each ticket type and visualize:\nprint(train_data[\"ticket_type\"].value_counts())\nsns.factorplot('ticket_type','Survived', data=train_data,size=4,aspect=3)","e847c545":"# #some experiments \n# t = train_data.Ticket\n# for i in range(len(t)):\n#     ticket = t.iloc[i]\n#     #print(ticket)\n#     for c in string.punctuation:\n#         ticket = ticket.replace(c,\"\")\n#         splited_ticket = ticket.split(\" \")\n#     print(splited_ticket)\n#     #print(ticket)\n\n            \n","fe3640ec":"# m = \"pb,scr\"\n# for c in string.punctuation:\n#     m = m.replace(c,\"\")\n#     print(m)\n\n","941712ee":"# for those types that have less than 15 samples in training set, assign type to 'OTHER':\n\nfor t in train_data['ticket_type'].unique():\n    if len(train_data[train_data['ticket_type']==t]) < 15:\n        train_data.loc[train_data.ticket_type ==t, 'ticket_type'] = 'OTHER_T'\n       \n    \nfor t in test_data['ticket_type'].unique():\n    if t not in train_data['ticket_type'].unique():\n        test_data.loc[test_data.ticket_type ==t, 'ticket_type'] = 'OTHER_T'\n        \nprint(train_data['ticket_type'].unique())\nprint(test_data['ticket_type'].unique())","7925fbb4":"# visualize ticket_type vs survival rate\nprint(train_data[\"ticket_type\"].value_counts()\/len(train_data))\nsns.barplot(x = 'ticket_type', y = 'Survived', data = train_data)","93c36d1f":"# where ticket_type is 'SOTONOQ' convert it to 'A5'\ntrain_data[\"ticket_type\"] = np.where(train_data[\"ticket_type\"]=='SOTONOQ', 'A5', train_data[\"ticket_type\"])\ntest_data[\"ticket_type\"] = np.where(test_data[\"ticket_type\"]=='SOTONOQ', 'A5', test_data[\"ticket_type\"])","9e0d0fd9":"# visualize ticket_type vs survival rate\nprint(train_data[\"ticket_type\"].value_counts()\/len(train_data))\nsns.barplot(x = 'ticket_type', y = 'Survived', data = train_data)","38ed890f":"# we will now drop Ticket from dataset:\n\ntrain_data = train_data.drop(['Ticket'], axis=1)\ntest_data = test_data.drop(['Ticket'], axis=1)","11eca611":"train_data.head(2)","3562fd34":"print('No. of missing values in Train set:', train_data.Cabin.isnull().sum())\nprint('No. of missing values in Test set:', test_data.Cabin.isnull().sum())","3c3206e7":"#create function that takes cabin from dataset and extracts cabin type for each cabin that is not missing.\n# If cabin is missing, leaves missing value:\n\ndef cabin_sep(data_cabin):\n    cabin_type = []\n\n    for i in range(len(data_cabin)):\n\n            if data_cabin.isnull()[i] == True: \n                cabin_type.append('NaN') \n            else:    \n                cabin = data_cabin[i]\n                cabin_type.append(cabin[:1]) \n            \n    return cabin_type","b3cfdc72":"# apply cabin sep on test and train set:\ntrain_data['cabin_type'] = cabin_sep(train_data.Cabin)\ntest_data['cabin_type'] = cabin_sep(test_data.Cabin)\n\n\ntrain_data.head(2)","86205a7b":"# visualize cabin_type vs survival rate:\nprint(train_data[\"cabin_type\"].value_counts())\nsns.factorplot('cabin_type','Survived', data=train_data,size=4,aspect=3)","6767e99e":"# for those types that have less than 15 samples in training set, assign type to 'OTHER_C':\n\nfor t in train_data['cabin_type'].unique():\n    if len(train_data[train_data['cabin_type']==t]) <= 15:\n        train_data.loc[train_data.cabin_type ==t, 'cabin_type'] = 'OTHER_C'\n       \n    \nfor t in test_data['cabin_type'].unique():\n    if t not in train_data['cabin_type'].unique():\n        test_data.loc[test_data.cabin_type ==t, 'cabin_type'] = 'OTHER_C'\n        \nprint(train_data['cabin_type'].unique())\nprint(test_data['cabin_type'].unique())","006995c8":"# visualize cabin_type vs survival rate\nprint(train_data[\"cabin_type\"].value_counts()\/len(train_data))\nsns.barplot(x = 'cabin_type', y = 'Survived', data = train_data)","8e25468b":"# we will now drop cabin from dataset:\n\ntrain_data = train_data.drop(['Cabin'], axis=1)\ntest_data = test_data.drop(['Cabin'], axis=1)","380854b2":"train_data.head(2)","0fcc03d2":"sns.boxplot(train_data.Age)","83907d0d":"sns.boxplot(train_data.Fare)","c2681934":"print('Skew for Fare:',train_data.Fare.skew())\n","0add7b05":"# calculate upper bound for Fair\nIQR = train_data.Fare.quantile(0.75) - train_data.Fare.quantile(0.25)\nupper_bound = train_data.Fare.quantile(0.75) + 3*IQR\n# for train and test sets convert all values in column Fair where age is more than upper_bound to upper_bound:\ntrain_data.loc[train_data.Fare >upper_bound, 'Fare'] = upper_bound \ntest_data.loc[test_data.Fare >upper_bound, 'Fare'] = upper_bound\n\nmax(train_data.Fare)","640bc815":"# calculate upper bound for Age:\nupper_bound = train_data.Age.mean() + 3* train_data.Age.std()\n# for train and test sets convert all values in column Fair where age is more than upper_bound to upper_bound:\ntrain_data.loc[train_data.Age >upper_bound, 'Age'] = upper_bound \ntest_data.loc[test_data.Age >upper_bound, 'Age'] = upper_bound\n\nmax(train_data.Age)","b603f93e":"train_data.head()","acdfdc8d":"#sex column \ntrain_data['Sex'] = train_data['Sex'].replace({'male':1, 'female':0})\ntest_data['Sex'] = test_data['Sex'].replace({'male':1, 'female':0})\ntrain_data.head(2)","6ade9642":"train_data.ticket_type.value_counts()","c2c6229d":"#sex column \ntrain_data['ticket_type'] = train_data['ticket_type'].replace({'NO':1, 'OTHER_T':2 ,'PC':3,'CA':4,'A5':5})\ntest_data['ticket_type'] = test_data['ticket_type'].replace({'NO':1, 'OTHER_T':2 ,'PC':3,'CA':4,'A5':5})\ntrain_data.head(2)","6b8dd582":"train_data.cabin_type.value_counts()","41420c52":"#sex column \ntrain_data['cabin_type'] = train_data['cabin_type'].replace({'NaN':1, 'C':2 ,'B':3,'OTHER_C':4,'D':5 , 'E' : 6})\ntest_data['cabin_type'] = test_data['cabin_type'].replace({'NaN':1, 'C':2 ,'B':3,'OTHER_C':4,'D':5 , 'E' : 6})\ntrain_data.head(2)","31d8d0e5":"#Embarked column will be by 1 hot encoder \n# Get one hot encoding of columns Embarked\none_hot = pd.get_dummies(train_data['Embarked'])\ntrain_data = train_data.drop('Embarked',axis = 1)\ntrain_data = train_data.join(one_hot)\ntrain_data.head(2)","3fce6715":"#Embarked column will be by 1 hot encoder \n# Get one hot encoding of columns Embarked\none_hot = pd.get_dummies(test_data['Embarked'])\ntest_data = test_data.drop('Embarked',axis = 1)\ntest_data = test_data.join(one_hot)\ntest_data.head(2)","9d1cb141":"colormap = plt.cm.RdBu\nplt.figure(figsize=(14,8))\nplt.title('Correlation of Features', y=1.05, size=15)\nsns.heatmap(train_data.corr(),linewidths=0.1,vmax=1.0, \n            square=True,linecolor='white',cmap=colormap, annot=True)","e1de324c":"for col in train_data.columns:\n    sns.barplot(x = col, y = 'Survived', data = train_data)\n    plt.show()","4b8e26d9":"features = ['Pclass','Sex','SibSp','Parch','Fare','Age_NA','ticket_type','cabin_type','C','Q','S']\n\n\nX_train, X_val, y_train, y_val = train_test_split(train_data[features],\n                                                  train_data[\"Survived\"],\n                                                  test_size = 0.2,\n                                                  stratify = train_data[\"Survived\"],\n                                                  random_state=0)\n\nX_test = test_data[features]\n\nX_train.head(2)\n","4068756a":"# from sklearn.svm import SVC\n# svclassifier = SVC(C= 10 ,kernel=\"rbf\" , gamma =.02 ,break_ties=True,random_state=10)\n# svclassifier.fit(X_train, y_train)\n\n\n","8bda66c6":"# y_pred = svclassifier.predict(X_val)","4a564f22":"from sklearn.metrics import classification_report, confusion_matrix\n# print(confusion_matrix(y_val,y_pred))\n# print(classification_report(y_val,y_pred))","a071d027":"X_test.shape\nX_train.shape","6c22c35d":"best_rf = RandomForestClassifier(random_state=121, criterion='entropy', max_depth=9, min_samples_leaf=5, min_samples_split=2, n_estimators=50)\n\nbest_rf.fit(X_train, y_train)\n\ny_pred = best_rf.predict(X_val)\nprint(confusion_matrix(y_val,y_pred))\nprint(classification_report(y_val,y_pred))","16c07df5":"y_pred_test = best_rf.predict(X_test)\n","23c8729a":"test_data['Survived'] = y_pred_test\ntest_data[['PassengerId','Survived']].to_csv('\/kaggle\/working\/gender_submission.csv', index=False)\n\n","b21994c4":"### Features with High Cardinality(a lot of categories)","761aadf5":"### Encoding data","85632046":"### precicion of class zero means if model predicted 100 in class zero there is 78 of them is predicted true\n\n### recall means of all data in zero class model predict 80% of them correct \n\n### accuracy means all predicted true over all data \n\n","a5f332bd":"### Split training data into training and validation sets","9cb9559e":"### Importing Libraries","103c3827":"#### ticket type values has A\/5, PC ,110152 ,110413 and so on not every ticket has associated type\n\nwe have discovered that ticket number: starting from 0 to 3101317.\n\nFor most of the tickets first number is associated with Pclass\n\nexcept tickets that are less than 5 digits long or tickets than have ticket type associated with them\n\n","0ff8d62e":"### We will create variable ticket_type:","25d5ca9c":"#### All features have outliers. It can be dangerous for linear models.\nThe way to handle ourliers depends on distribution type. If distribution is close to normal --> bound values within 3std range, but if distribution is skewed --> bound between 3IQR range.\n\nWe already know that Age is close to normal","c2786be3":"### as we have seen A5 and aotonoq tickets have the lowest survive ratio and the most rare category so we can combine them together ","c6a6b33c":"### Filling missing values ","ce802273":"##### In order to make data representative we will put all cabin types in train data that have less tan 15 samples into separate type 'OTHER_C'. For test set we will also only leave cabin types that are left in training set and keep the rest under 'OTHER_C' type\n","1ef008aa":"#### 1. Variable Cabin has a lot of missing values both in train and test set. As there are a lot of missing values it worth to separate missing values from all other cabin types and check how it relates with other variables and target.\n\n\n2. Variable in column Cabin has following structure:  \n    - deck : Letter in front of number \n    - cabin number \nDeck probably has impact on survival rate. \n\nWe will Create 'cabin_type' feature","5a1b7e0f":"### Amount of missing data in both columns is insignificant. We will just fill them with most frequent value for Embarked and mean value for Fare","d5e74e22":"### Features with Outliers","4d59ccb9":"### importing DataSet","0f5f60c7":"### Explore Dataset","fa892249":"#### there are to many ticket types that are not representative ==> to make it representative we will put all ticket types that have less than 15 samples into 1 type 'other_T'","7b6f9a44":"### precicion of class zero means if model predicted 100 in class zero there is 80 of them is predicted true\n### recall means of all data in zero class model predict 91% of them correct\n### accuracy means all true predictions over all data\n### f1 score means that 2 over (1\/precision + 1\/recall)\n"}}