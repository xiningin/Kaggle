{"cell_type":{"38ac045d":"code","92f09f00":"code","ec47f23c":"code","3d0efd58":"code","41f644f6":"code","b04714da":"code","654e14fb":"code","6701a5b6":"code","2448f39b":"code","b1f40420":"code","cd0f157c":"code","4b02972f":"markdown","6f9c891d":"markdown"},"source":{"38ac045d":"### It runs much faster under GPU and TPU's. So make sure you use it.\n!pip install deep_autoviml --upgrade","92f09f00":"# use pandas numpy as usual\nimport pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\n\n#### This is how you import deep_autoviml\nfrom deep_autoviml import deep_autoviml as deepauto","ec47f23c":"!wget -O churn.zip https:\/\/github.com\/srivatsan88\/YouTubeLI\/blob\/master\/dataset\/wa-fnusec-telcocustomerchurn.zip?raw=true","3d0efd58":"!unzip churn.zip","41f644f6":"df = pd.read_csv('WA_Fn-UseC_-Telco-Customer-Churn.csv')\nprint(df.shape)\ndf.head()","b04714da":"train, test = train_test_split(df, test_size=0.33, random_state=42)\nprint(train. shape, test.shape)","654e14fb":"keras_model_type =  \"fast\" ## always try \"auto\" first, then \"basic\", \"deep\", \"big deep\", \"giant deep\", \"cnn1\" etc.\n### always set early_stopping to True first and then change it to False\n#### You always need 15 max_trials to get something decent #####\nkeras_options = {\"early_stopping\": False, 'lr_scheduler': ''}  \n#### always set tuner to \"storm\" and then \"optuna\". NLP char limit kicks off NLP processing. Feature Cross later.\nmodel_options = {'tuner':\"storm\", \"max_trials\":5, 'nlp_char_limit':10, \n                 'cat_feat_cross_flag':False, }\nproject_name = 'churn' ### this is the folder where the model will be saved","6701a5b6":"target = 'Churn'  ## this is name of your target variable in your data set","2448f39b":"### deep_autoviml will automatically convert train dataframe into a tf.data.Dataset\nmodel, cat_vocab_dict = deepauto.fit(train, target, keras_model_type,\n                        project_name=project_name, keras_options=keras_options,\n                         model_options=model_options, save_model_flag=True, \n                        use_my_model='', verbose=0)","b1f40420":"predictions = deepauto.predict(model, project_name=project_name, test_dataset=test,\n                                 keras_model_type=keras_model_type, \n                                 cat_vocab_dict=cat_vocab_dict)","cd0f157c":"from deep_autoviml import print_classification_model_stats\nprint_classification_model_stats(test[target].values,predictions[-1])","4b02972f":"# Deep_AutoViML is a new open source Python Deep Learning Library for latest TF2.5 and Keras\n###  Github :  https:\/\/github.com\/AutoViML\/deep_autoviml\n# Click on GPU in the right menu under Settings to get started.","6f9c891d":"### With just a couple of lines of code we can build a deep learning model with preprocessing layers so that it can be served by tf.serving with raw data!\nSuch a model can serve as the foundation for building an MLOps pipeline"}}