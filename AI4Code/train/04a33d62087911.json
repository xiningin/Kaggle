{"cell_type":{"36341f13":"code","6bbde7b9":"code","fc0bd296":"code","480f4a16":"code","5974960f":"code","598f7e68":"code","29094448":"code","cbac3a01":"code","18c031a1":"code","a732d67c":"code","46460202":"code","51a07ea1":"code","4a908c87":"code","1559661c":"code","47752d33":"code","f06e7121":"code","1d95d566":"code","0bbc9190":"code","20bcfaad":"code","9fbb91b5":"code","de74051e":"code","3746dee0":"code","d28f093f":"code","10e2f1f8":"code","24ab4d7c":"code","0ad91770":"code","3ffb4112":"code","7eb3d8dc":"code","a26f5462":"code","0525a0aa":"code","ff7b065e":"code","14485a1d":"code","f33bfc8b":"markdown","534e7389":"markdown","79265ba0":"markdown","3a358e66":"markdown","b0c78604":"markdown","324105ff":"markdown","2d48a9d1":"markdown","eb94068d":"markdown","c38b9c79":"markdown"},"source":{"36341f13":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nimport nltk\n#import nltk.stem\n#from nltk.tokenize import word_tokenize, sent_tokenize, PunktSentenceTokenizer\n#from nltk.corpus import stopwords\n\nimport string\nimport re\n#from string import punctuation\n#import re","6bbde7b9":"#Load UN General debates\ndf_debates = pd.read_csv('..\/input\/un-general-debates\/un-general-debates.csv')\ndf_debates","fc0bd296":"df_debates.describe(include='all')","480f4a16":"#Load UNSD countries dataset\ndf_countries = pd.read_csv('..\/input\/unsd-country-codes-and-development-status\/UNSD_M49_CountryCodes.csv')\ndf_countries","5974960f":"#Merge debates dataset with countries on country codes\ndf_debates = pd.merge(df_debates, \n                   df_countries[['RegionName','CountryName','ISOAlpha3Code', 'DevelopmentStatus']],\n                   how='inner', left_on='country', right_on='ISOAlpha3Code')\n\n#remove duplicate column as country code already exist in debates df\ndf_debates.drop('ISOAlpha3Code',axis=1, inplace=True) \n\ndf_debates","598f7e68":"df_debates.isnull().sum()","29094448":"df_debates.drop(df_debates[(df_debates.year < 2000) | \n                           (~df_debates.RegionName.isin(['Asia']))].index, \n                inplace=True)\ndf_debates","cbac3a01":"df_debates.nunique()","18c031a1":"from wordcloud import WordCloud\n\n#word cloud plot\ndef plot_word_cloud(allwords, maxwords):     \n    \n    wordcloud = WordCloud(background_color='white', width=1600, height=900,                          \n                          max_words=maxwords).generate(allwords)\n    plt.figure(figsize = (20,10), dpi=1200)\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.tight_layout(pad=0)\n    plt.show()\n    \n    return","a732d67c":"#word cloud plot\ndef plot_word_cloud_fast(allwords, maxwords):     \n    \n    wordcloud = WordCloud(background_color='white',\n                          max_words=maxwords).generate(allwords)\n    plt.figure(figsize = (20,10))\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.axis(\"off\")\n    plt.tight_layout(pad=0)\n    plt.show()\n    \n    return","46460202":"rawtext = df_debates.text.sum()\nplot_word_cloud_fast(rawtext, 2000)","51a07ea1":"#download nltk stopwords for unhelpful words\nnltk.download(\"stopwords\")\n\n#download nltk word tokenizer trained on English\nnltk.download(\"punkt\")","4a908c87":"formal_words=['united nation', 'united nations', 'general assembly', 'republic of', 'secretary general', 'the world', \n              'international community', 'security council', 'member state', 'country', 'must', 'many' ]\n\n#create a function for pre processing of the text\ndef preprocess_debate(text):    \n    #change to lower case and remove special characters\n    text = re.sub('\\W+', ' ', text.lower())\n    \n    #remove formal words used in address\n    for x in formal_words:\n        text = text.replace(x,'')\n        \n    #tokenize text to get list of individual words\n    tokens = nltk.word_tokenize(text)\n    \n    #remove uninformative words e.g. 'of', 'that', 'is' etc & punctiations e.g. '!\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_`{|}~'\n    uninformative_words = nltk.corpus.stopwords.words(\"english\") + list(string.punctuation)\n    tokens = [token for token in tokens if len(token) > 3 and\n             token not in uninformative_words]\n    \n    #remove inflectional endings and get the root word (lemma):\n    lemmatizer = nltk.stem.WordNetLemmatizer()\n    lemmas = [lemmatizer.lemmatize(token) for token in tokens]\n    \n    return lemmas","1559661c":"#apply pre processing on texts and create new features 'tokens' and 'freq_dist'\ndf_debates['tokens'] = df_debates['text'].apply(preprocess_debate)\ndf_debates['lemma_text'] = [' '.join(x) for x in df_debates['tokens']]\n\ndf_debates['freq_dist'] = df_debates['tokens'].apply(nltk.probability.FreqDist)\n\ndf_debates[['text','tokens', 'freq_dist']]","47752d33":"#viualize most common words (after pre-processing) in all debates through world cloud\n\n#combine all words from all debates\n#all_words_list = [' '.join(x) for x in df_debates['tokens']]\n#all_words = ' '.join(map(str,all_words_list))\nall_words = df_debates.lemma_text.sum()","f06e7121":"plot_word_cloud_fast(all_words, 4000) \n#plot_word_cloud(all_words, 4000) ","1d95d566":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\n\ndef analyze_polarity(text):\n    sid_obj = SentimentIntensityAnalyzer()\n    sentiment_dict = sid_obj.polarity_scores(text)\n    \n    #return the overall sentiment rating of the text\n    return sentiment_dict[\"compound\"]\n\ndef get_sentiment(polarity):    \n    \n    # decide sentiment as positive, negative and neutral \n    if polarity >= 0.05: \n        sent = \"Positive\"  \n    elif polarity <= - 0.05: \n        sent = \"Negative\"\n    else: \n        sent = \"Neutral\"\n\n    return sent","0bbc9190":"#get overall polarity scores of the raw text\ndf_debates['polarity'] = np.array([ analyze_polarity(text) for text in df_debates['text'] ])\n\n#get sentiment value for the given polarity\ndf_debates['sentiment'] = np.array([ get_sentiment(pol) for pol in df_debates['polarity'] ])\n\ndf_debates.head()","20bcfaad":"df_debates[df_debates.country=='PAK']['sentiment'].value_counts()","9fbb91b5":"temp = df_debates.groupby(['country','sentiment'], as_index=False).session.count()\ntemp.rename(columns={'session':'count'}, inplace=True)","de74051e":"for c in temp.country.unique():\n    try:\n        p = temp[(temp.sentiment =='Positive') & (temp.country == c)]['count'].values[0]\n        n = temp[(temp.sentiment =='Negative') & (temp.country == c)]['count'].values[0]\n        if(n>p):\n            print(c)\n    except:\n        print(c,'error')","3746dee0":"#get ndarry from dataframe for plotting\nyears = df_debates['year'].values\npolarity = df_debates['polarity'].values\nsentiment = df_debates['sentiment'].values","d28f093f":"#Quick Plot - Polarity\n#fig = plt.figure()\n#ax = fig.add_axes([0,0,1,1])\n#ax.bar(years,polarity)\nplt.plot(years,polarity, 'bo')\nplt.show()","10e2f1f8":"#Quick Plot - Sentiment\n#fig = plt.figure()\n#ax = fig.add_axes([0,0,1,1])\n#ax.bar(years,sentiment)\nplt.plot(years,sentiment, 'bo')\nplt.show()","24ab4d7c":"stability_df = pd.read_excel('..\/input\/governance-indicator-for-political-stability\/Political_Stability_Absence_Violence_Terrorism_W_G_Indicator.xlsx','Data')\nstability_df","0ad91770":"#Missing years before 2000, dropping those columns\nstability_df.drop([1996,1998], axis=1, inplace=True)\n\n","3ffb4112":"#reshape data from wide format to long format\nstability_df = stability_df .melt(id_vars=['CountryName', 'CountryCode'],\n                                  var_name='Indi_Year',\n                                  value_name='Indi_Value')\nstability_df","7eb3d8dc":"#drop non-asian countries\n#since df_debates is already filtered on Asian region, hence using countries from it\nstability_df.drop(stability_df[~stability_df.CountryCode.isin(df_debates.country)].index, inplace=True)\nstability_df","a26f5462":"plt.plot(stability_df.Indi_Year.unique(), stability_df[stability_df.CountryCode=='PAK'].Indi_Value.values)\nplt.show()","0525a0aa":"plt.plot(df_debates.year.unique(), df_debates[df_debates.country=='PAK'].polarity.values, 'bo')\nplt.show()","ff7b065e":"#Visualizing relation through a scatter plot\n\nfig, ax = plt.subplots()\nax.scatter(x=stability_df[stability_df.CountryCode=='PAK'].Indi_Value.values, \n           y=df_debates[df_debates.country=='PAK'].polarity.values, alpha=0.7, color='b')\n\n\n\n#set grid and fig size\nax.grid(True, ls=':')\nfig.set_figheight(6)\nfig.set_figwidth(10)\nfig.tight_layout()\n\nplt.show()","14485a1d":"fig, ax = plt.subplots()\n\n#plot stability\nax.plot(stability_df.Indi_Year.unique(), stability_df[stability_df.CountryCode=='BGD'].Indi_Value.values, color='orange', marker='o')\nax.set_xlabel('Year')\nax.set_ylabel('stability')\nax.set_ylim([0, 25])\nax.grid(True, ls=':')\n\n#get twin object for two different y-axis on the same plot\nax2 = ax.twinx()\n\n#plot polarity\nax2.plot(stability_df.Indi_Year.unique(),df_debates[df_debates.country=='BGD'].polarity.values, 'bo')\nax2.set_ylabel('polarity')\nax2.set_ylim([-1.5, 1.5])\nax2.grid(True, ls=':')\n\n#set legend and fig size\nfig.set_figheight(6)\nfig.set_figwidth(12)\nfig.tight_layout()\n#fig.legend([mort_df['IndicatorName'].iloc[0], epc_df['IndicatorName'].iloc[0]], \n#           loc=\"upper right\",\n#           bbox_to_anchor=(1,1), \n#           bbox_transform=ax.transAxes)\n\n#plt.title('Female Mortality Vs Health Expenditure in South Asia')\nplt.show()","f33bfc8b":"**Quick Observations**\n* Shape (7507, 4)\n* There are 199 countries\n* Year ranage is from 1970 to 2015 i.e. 45 years of data\n* Data is unsorted\n* Text seems to have special characters \n* Country is a 3 digit code i.e. ISO Alpha 3 Code\n\n\nTo get region name, country name and developing status: I will merge this dataset with a one from [UNSD Methodology](https:\/\/unstats.un.org\/unsd\/methodology\/m49\/overview\/)","534e7389":"# Scope of Analysis\nI will be anbalyzing debates of Asian countries, sentiments of their leaders and subsequently the affect on their political stability and absence of violenece\/terrorism\nIn short, keeping only the following data:\n* Last 18 years of debates (i.e. from 2000 - 2018)\n* For Asian countries","79265ba0":"# Stability Indicator\n**Code** = PV.PER.RNK\n\n**Indicator Name** = Political Stability and Absence of Violence\/Terrorism: Percentile Rank\n\n**Long definition:**\n\nPolitical Stability and Absence of Violence\/Terrorism measures perceptions of the likelihood of political instability and\/or politically-motivated violence, including terrorism.  Percentile rank indicates the country's rank among all countries covered by the aggregate indicator, with 0 corresponding to lowest rank, and 100 to highest rank.  Percentile ranks have been adjusted to correct for changes over time in the composition of the countries covered by the WGI.\n\n**Source:**\n\nDetailed documentation of the WGI, interactive tools for exploring the data, and full access to the underlying source data available at www.govindicators.org.The WGI are produced by Daniel Kaufmann (Natural Resource Governance Institute and Brookings Institution) and Aart Kraay (World Bank Development Research Group).  Please cite Kaufmann, Daniel, Aart Kraay and Massimo Mastruzzi (2010).  \"The Worldwide Governance Indicators:  Methodology and Analytical Issues\".  World Bank Policy Research Working Paper No. 5430 (http:\/\/papers.ssrn.com\/sol3\/papers.cfm?abstract_id=1682130).  The WGI do not reflect the official views of the Natural Resource Governance Institute, the Brookings Institution, the World Bank, its Executive Directors, or the countries they represent.","3a358e66":"**Quick Visualization**\n#prior to any pre processing, first let's do a quick view of the words\n#objective is to get a feel of what is in the text","b0c78604":"# Pre-Processing of Debates Text for Analysis","324105ff":"**Pre Processing \/ Text Cleaning**\n\nThe quick look indicates the need to perform operations like:\n* Change to lower case\n* Remove all non alphabets\n* Remove uninformative words i.e. stopwords, punctuations\n* Lemmatize words to remove inflectional ending \n\nAnother observation is the use of words like \"United Nation\", \"General Assembly\", etc. Those might be used to address the respective UN organizations. I will eliminate them also to get the right top modeling and anylyse sentimnets subsequently","2d48a9d1":"# Sentiment Analysis\n\n* Through Sentiment Analysis process I wil try to determin the attitude or the emotion of a speech, whether it is positive or negative or neutral.","eb94068d":"# UNGA Speech Sentiment Vs Regional or Country Stability","c38b9c79":"# Load & Inspect Debates Data"}}