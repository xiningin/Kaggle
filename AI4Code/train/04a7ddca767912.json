{"cell_type":{"da96bb37":"code","b8da0ee1":"code","4ea80b74":"code","ccba08ab":"code","b96273e3":"code","fc1f38e5":"code","61c690ca":"code","4fb92647":"code","be7fe9c4":"code","d7e2e93a":"code","0d65bb99":"code","07d0e00e":"code","1b0ad844":"code","3fa6af98":"code","58301b41":"code","4dbd145a":"code","56bda664":"code","f3313ed7":"code","33a8da08":"code","72ec361b":"code","b4aeabe9":"code","35ec7f39":"code","eea78ac3":"code","3d545d9d":"code","87db8892":"code","f7f718f2":"code","1a53bee4":"code","17dab6f6":"code","bb2ce533":"code","706e1721":"code","1d38b70f":"code","7de2d613":"code","d54c4d7e":"code","e2e75855":"code","de99daa3":"code","3179f1d3":"code","3fb36fe7":"code","8355e45b":"code","e4cdd0ee":"code","f5fdbf38":"code","9ed02015":"code","9e99eecc":"code","2801b824":"code","2ad72afb":"code","02455e72":"code","6f06e5af":"code","88bf7d9c":"code","caa871c7":"code","c0a302f5":"code","14dd5c31":"code","3c605c09":"code","0fc49723":"code","8deb6b5b":"code","2978ba9b":"code","a0489cbf":"code","335ae040":"code","2f852d79":"code","edba999a":"code","cd318d43":"code","38d8fe8e":"code","5151aad9":"code","d57a66a7":"code","43f4ca8e":"code","41cf4789":"code","46f3e949":"code","e9fb4987":"code","8fbc92ab":"code","a917d735":"code","4b9df4a9":"code","b3c50ddc":"code","805e833b":"code","213948bd":"code","94044eb6":"code","4661f988":"code","ab04d752":"code","88852f9c":"code","84b76fa4":"code","916b62e1":"code","9a5c8ee9":"code","52a972b7":"code","d54284d2":"code","05d61aa7":"code","012b91eb":"markdown","a3609e16":"markdown","c760836f":"markdown","fe48d963":"markdown","dca16cbb":"markdown","d8d45805":"markdown","9b9c48e2":"markdown","f5c92ba2":"markdown","f6facce6":"markdown","c033b630":"markdown","62d6a18b":"markdown","ddd81c38":"markdown","671aa01d":"markdown","4f5406fa":"markdown","c576e2b8":"markdown","c0c3bdd6":"markdown","f2b1ccc9":"markdown","4f62a230":"markdown","115b3b37":"markdown","77da3cfe":"markdown","ae604e90":"markdown","199d8be0":"markdown","ce1a3bad":"markdown","c92331b5":"markdown","5ee79b97":"markdown","5b9d5ca5":"markdown","9641e8c2":"markdown","1abf5dc2":"markdown","04465e6c":"markdown","020a2676":"markdown","d0b056d7":"markdown","4de8980e":"markdown","573801d0":"markdown","4b5c4f32":"markdown","085b5472":"markdown","acbc26f1":"markdown","33073f53":"markdown","72e62d4e":"markdown","21305b3b":"markdown"},"source":{"da96bb37":"import numpy as np\nimport pandas as pd\n\n%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline","b8da0ee1":"!pip install fastai==0.7.0 --quiet","4ea80b74":"from fastai.imports import *\nfrom fastai.structured import *\n\nfrom pandas_summary import DataFrameSummary\nfrom sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\nfrom sklearn.preprocessing import MultiLabelBinarizer\n\nfrom IPython.display import display\n\nfrom sklearn import metrics\n\nimport ast","ccba08ab":"PATH = \"..\/input\/\"\n!ls {PATH}","b96273e3":"df_raw = pd.read_csv(f'{PATH}train.csv', \n                     low_memory=False, \n                     parse_dates=[\"release_date\"])","fc1f38e5":"def display_all(df):\n    with pd.option_context(\"display.max_rows\", 1000, \"display.max_columns\", 1000): \n        display(df)","61c690ca":"# look at the data\ndisplay_all(df_raw.tail().T)","4fb92647":"# describe all the data\ndisplay_all(df_raw.describe(include='all').T)","be7fe9c4":"df_raw.dtypes","d7e2e93a":"df_raw.revenue = np.log1p(df_raw.revenue)","0d65bb99":"# transform release_date to multiple new columns containing information from the date\nadd_datepart(df_raw, 'release_date')\ndf_raw.dtypes","07d0e00e":"# we'll use it for one-hot encoding\nmlb = MultiLabelBinarizer()","1b0ad844":"# look at a random movie genres\ndf_raw.iloc[1300]['genres']","3fa6af98":"def convertStringToList(strVal):\n    if type(strVal) is not str:\n        return  []\n    else:\n        return ast.literal_eval(strVal)","58301b41":"def formatDictColumnAndExtractNames(strVal):\n    listOfItems = convertStringToList(strVal)\n    return list(map(lambda x: x['name'], listOfItems))","4dbd145a":"def extractGenres(df):\n    df['genres'] = df['genres'].apply(formatDictColumnAndExtractNames)\n\n    return df.join(pd.DataFrame(mlb.fit_transform(df.pop('genres')),\n                          columns=list(map(lambda x: 'genre_'+x,mlb.classes_)),\n                          index=df.index))","56bda664":"df_raw = extractGenres(df_raw)","f3313ed7":"def extractCommonProdCompanies(df):\n    df['production_companies'] = df['production_companies'].apply(formatDictColumnAndExtractNames)\n\n    companiesCount = df['production_companies'].apply(pd.Series).stack().value_counts()\n    companiesToKeep = companiesCount[companiesCount > 30].keys()\n    print(\"We'll keep the companies that appear more than 30 times:\")\n    print(companiesToKeep)\n\n    df['production_companies'] = df['production_companies'].apply(lambda x: list(filter(lambda i: i in companiesToKeep, x)))\n\n    return df.join(pd.DataFrame(mlb.fit_transform(df.pop('production_companies')),\n                          columns=list(map(lambda x: 'prod_company_'+x,mlb.classes_)),\n                          index=df.index))","33a8da08":"df_raw = extractCommonProdCompanies(df_raw)","72ec361b":"def extractCommonProdCountries(df):\n    df['production_countries'] = df['production_countries'].apply(formatDictColumnAndExtractNames)\n\n    countriesCount = df['production_countries'].apply(pd.Series).stack().value_counts()\n    countriesToKeep = countriesCount[countriesCount > 10].keys()\n    print(\"We'll keep the countries that appear more than 10 times:\")\n    print(countriesToKeep)\n\n    df['production_countries'] = df['production_countries'].apply(lambda x: list(filter(lambda i: i in countriesToKeep, x)))\n    return df.join(pd.DataFrame(mlb.fit_transform(df.pop('production_countries')),\n                          columns=list(map(lambda x: 'prod_country_'+x,mlb.classes_)),\n                          index=df.index))","b4aeabe9":"df_raw = extractCommonProdCountries(df_raw)","35ec7f39":"def extractCommonSpokenLanguages(df):\n    df['spoken_languages'] = df['spoken_languages'].apply(formatDictColumnAndExtractNames)\n\n    languageCount = df['spoken_languages'].apply(pd.Series).stack().value_counts()\n    languagesToKeep = languageCount[languageCount > 10].keys()\n    print(\"We'll keep the languages that appear more than 10 times:\")\n    print(languagesToKeep)\n\n    df['spoken_languages'] = df['spoken_languages'].apply(lambda x: list(filter(lambda i: i in languagesToKeep, x)))\n\n    return df.join(pd.DataFrame(mlb.fit_transform(df.pop('spoken_languages')),\n                          columns=list(map(lambda x: 'spoken_language_'+x,mlb.classes_)),\n                          index=df.index))","eea78ac3":"df_raw = extractCommonSpokenLanguages(df_raw)","3d545d9d":"def extractCommonKeywords(df):\n    df['Keywords'] = df['Keywords'].apply(formatDictColumnAndExtractNames)\n\n    keywordCount = df['Keywords'].apply(pd.Series).stack().value_counts()\n    keywordsToKeep = keywordCount[keywordCount >= 30].keys()\n    print(\"We'll keep the keywords that appear more than 30 times:\")\n    print(keywordsToKeep)\n\n    df['Keywords'] = df['Keywords'].apply(lambda x: list(filter(lambda i: i in keywordsToKeep, x)))\n\n    return df.join(pd.DataFrame(mlb.fit_transform(df.pop('Keywords')),\n                          columns=list(map(lambda x: 'keyword_'+x,mlb.classes_)),\n                          index=df.index))","87db8892":"df_raw = extractCommonKeywords(df_raw)","f7f718f2":"# have a look at a cast cell\ndf_raw.iloc[3]['cast']","1a53bee4":"def addCastLengthColumn(df):\n    castNames = df['cast'].apply(formatDictColumnAndExtractNames)\n    df['cast_len'] = castNames.apply(lambda x: len(x))\n    return df","17dab6f6":"df_raw = addCastLengthColumn(df_raw)","bb2ce533":"df_raw.drop(['cast'], axis=1, inplace=True)","706e1721":"# have a look at a crew cell\ndf_raw.iloc[113]['crew']","1d38b70f":"def formatDictColumnAndExtractJobName(strVal, job):\n    listOfItems = convertStringToList(strVal)\n    \n    jobItem = (list(filter(lambda lst: lst['job'] == job, listOfItems)) or [None])[0]\n    if type(jobItem) is dict:\n        return jobItem['name']\n    else:\n        return None","7de2d613":"def addCrewJobsColumns(df):\n    df['director'] = df['crew'].apply(formatDictColumnAndExtractJobName, args=('Director',))\n    df['screenplay'] = df['crew'].apply(formatDictColumnAndExtractJobName, args=('Screenplay',))\n    df['director_of_photography'] = df['crew'].apply(formatDictColumnAndExtractJobName, args=('Director of Photography',))\n    df['original_music_composer'] = df['crew'].apply(formatDictColumnAndExtractJobName, args=('Original Music Composer',))\n    df['art_director'] = df['crew'].apply(formatDictColumnAndExtractJobName, args=('Art Direction',))\n    \n    return df","d54c4d7e":"df_raw = addCrewJobsColumns(df_raw)","e2e75855":"def formatDictColumnAndExtractDirectorGender(strVal):\n    listOfItems = convertStringToList(strVal)\n\n    directorItem = (list(filter(lambda lst: lst['job'] == 'Director', listOfItems)) or [None])[0]\n    if type(directorItem) is dict:\n        return directorItem['gender']\n    else:\n        return None","de99daa3":"def addDirectorGenderColumn(df):\n    df['director_gender'] = df['crew'].apply(formatDictColumnAndExtractDirectorGender)\n    return df","3179f1d3":"df_raw = addDirectorGenderColumn(df_raw)","3fb36fe7":"def addCrewLenghtColumn(df):\n    df['crew'] = df['crew'].apply(formatDictColumnAndExtractNames)\n    df['crew_len'] = df['crew'].apply(lambda x: len(x))\n    return df","8355e45b":"df_raw = addCrewLenghtColumn(df_raw)","e4cdd0ee":"# drop crew column\ndf_raw.drop(['crew'], axis=1, inplace=True)","f5fdbf38":"df_raw['has_homepage'] = df_raw['homepage'].apply(lambda x: isinstance(x, str))","9ed02015":"# look at a random cell\ndf_raw.iloc[8]['belongs_to_collection']","9e99eecc":"df_raw['belongs_to_collection'] = df_raw['belongs_to_collection'].apply(lambda x: isinstance(x, str))","2801b824":"def extractTaglineInfo(df):\n    df['has_tagline'] = df['tagline'].apply(lambda x: isinstance(x, str))\n    df['tagline_len'] = df['tagline'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n    return df","2ad72afb":"df_raw = extractTaglineInfo(df_raw)","02455e72":"# check the result\ndf_raw[['tagline', 'has_tagline', 'tagline_len']].head(8)","6f06e5af":"def extractOverviewInfo(df):\n    df['has_overview'] = df['overview'].apply(lambda x: isinstance(x, str))\n    df['overview_len'] = df['overview'].apply(lambda x: len(x) if isinstance(x, str) else 0)\n    return df","88bf7d9c":"df_raw = extractOverviewInfo(df_raw)","caa871c7":"# check the result\ndf_raw[['overview', 'has_overview', 'overview_len']].head(8)","c0a302f5":"# we noticed quite a lot of movies with budget 0...\ndf_raw['has_budget'] = df_raw['budget'].apply(lambda x: x > 0)","14dd5c31":"toRemove = ['imdb_id', 'id', 'poster_path', 'overview', 'homepage', 'tagline', 'original_title', 'status']\ndf_raw.drop(toRemove, axis=1, inplace=True)","3c605c09":"train_cats(df_raw)","0fc49723":"df_trn, y_trn, nas = proc_df(df_raw, 'revenue')","8deb6b5b":"m = RandomForestRegressor(n_jobs=-1)\nm.fit(df_trn, y_trn)\nm.score(df_trn,y_trn)","2978ba9b":"def split_vals(a,n): return a[:n], a[n:]\nn_valid = 600 # 20%\nn_trn = len(df_trn)-n_valid\nX_train, X_valid = split_vals(df_trn, n_trn)\ny_train, y_valid = split_vals(y_trn, n_trn)\nraw_train, raw_valid = split_vals(df_raw, n_trn)","a0489cbf":"def rmse(x,y): return math.sqrt(((x-y)**2).mean())\n\n# print_score function depending on the evaluation metric: rmse\ndef print_score(m):\n    res = [rmse(m.predict(X_train), y_train), rmse(m.predict(X_valid), y_valid),\n                m.score(X_train, y_train), m.score(X_valid, y_valid)]\n    if hasattr(m, 'oob_score_'): res.append(m.oob_score_)\n    print(res)","335ae040":"#rf with hyper parameters\nm = RandomForestRegressor(n_estimators=40, min_samples_leaf=10, max_features=0.5, n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","2f852d79":"fi = rf_feat_importance(m, df_trn)\nfi","edba999a":"fi.plot('cols', 'imp', figsize=(10,6), legend=False);","cd318d43":"# function to plot feature importance\ndef plot_fi(fi): return fi.plot('cols', 'imp', 'barh', figsize=(12,12), legend=False)","38d8fe8e":"# plot the top 50 features\nplot_fi(fi[:50]);","5151aad9":"# we'll keep the top ~30 features\nto_keep = fi[fi.imp>0.002].cols; len(to_keep)","d57a66a7":"df_keep = df_trn[to_keep].copy()\nX_train, X_valid = split_vals(df_keep, n_trn)","43f4ca8e":"# new model with only the top ~30 features\nm = RandomForestRegressor(n_estimators=40, min_samples_leaf=10, max_features=0.5,\n                          n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","41cf4789":"# plot the new feature importance\nfi = rf_feat_importance(m, df_keep)\nplot_fi(fi);","46f3e949":"from scipy.cluster import hierarchy as hc","e9fb4987":"# dendrogram plot\ncorr = np.round(scipy.stats.spearmanr(df_keep).correlation, 4)\ncorr_condensed = hc.distance.squareform(1-corr)\nz = hc.linkage(corr_condensed, method='average')\nfig = plt.figure(figsize=(16,10))\ndendrogram = hc.dendrogram(z, labels=df_keep.columns, orientation='left', leaf_font_size=16)\nplt.show()","8fbc92ab":"# function to get the OOB score for a given datraframe (with the same hyperparameters as before)\ndef get_oob(df):\n    m = RandomForestRegressor(n_estimators=40, min_samples_leaf=10, max_features=0.5, n_jobs=-1, oob_score=True)\n    x, _ = split_vals(df, n_trn)\n    m.fit(x, y_train)\n    return m.oob_score_","a917d735":"# check the current OOB score\nget_oob(df_keep)","4b9df4a9":"for c in ('release_Month', 'release_Dayofyear', 'release_Week', 'release_Year', 'release_Elapsed'):\n    print(c, get_oob(df_keep.drop(c, axis=1)))","b3c50ddc":"to_drop = ['release_Month', 'release_Elapsed']\nget_oob(df_keep.drop(to_drop, axis=1))","805e833b":"df_keep.drop(to_drop, axis=1, inplace=True)\nX_train, X_valid = split_vals(df_keep, n_trn)\ny_train, y_valid = split_vals(y_trn, n_trn)","213948bd":"m = RandomForestRegressor(n_estimators=100, min_samples_leaf=10, max_features=0.5,\n                          n_jobs=-1, oob_score=True)\nm.fit(X_train, y_train)\nprint_score(m)","94044eb6":"df_test = pd.read_csv(f'{PATH}test.csv', \n                     low_memory=False, \n                     parse_dates=[\"release_date\"])","4661f988":"add_datepart(df_test, 'release_date')\n\ndf_test = extractGenres(df_test)\ndf_test = extractCommonProdCompanies(df_test)\ndf_test = extractCommonProdCountries(df_test)\ndf_test = extractCommonSpokenLanguages(df_test)\ndf_test = extractCommonKeywords(df_test)\ndf_test = addCastLengthColumn(df_test)\ndf_test.drop(['cast'], axis=1, inplace=True)\ndf_test = addCrewJobsColumns(df_test)\ndf_test = addDirectorGenderColumn(df_test)\ndf_test = addCrewLenghtColumn(df_test)\ndf_test.drop(['crew'], axis=1, inplace=True)\ndf_test['has_homepage'] = df_test['homepage'].apply(lambda x: isinstance(x, str))\ndf_test['belongs_to_collection'] = df_test['belongs_to_collection'].apply(lambda x: isinstance(x, str))\ndf_test = extractTaglineInfo(df_test)\ndf_test = extractOverviewInfo(df_test)\ndf_test['has_budget'] = df_test['budget'].apply(lambda x: x > 0)\ndf_test.drop(toRemove, axis=1, inplace=True)","ab04d752":"# apply the same categories\napply_cats(df_test, df_raw)","88852f9c":"# process the test dataframe\ndf_test,_,nas = proc_df(df_test,na_dict = nas)","84b76fa4":"# keep the most important features & some redundant\ndf_test_keep = df_test[to_keep].copy()\ndf_test_keep.drop(to_drop, axis=1, inplace=True)","916b62e1":"# predict!\npredictions = m.predict(df_test_keep)","9a5c8ee9":"# copy of the initial test set, to get the ids\ndf_test_raw = pd.read_csv(f'{PATH}test.csv', low_memory = False)","52a972b7":"submission = pd.DataFrame({'id': df_test_raw['id'], 'revenue': np.expm1(predictions)})","d54284d2":"submission","05d61aa7":"submission.to_csv('tmdb_predictions_kaggle.csv', index=False)","012b91eb":"- Apply proc_df: proc_df takes a data frame df and splits off the response variable, and\n    changes the df into an entirely numeric dataframe.\n- Check the initial score on all the dataframe\n- Split vals into training set and validation set","a3609e16":"# Feature importance","c760836f":"Some features have a very strong importance and most seem to not be useful at all!","fe48d963":"### Cast","dca16cbb":"# Removing redundant features","d8d45805":"Add a column for the Director gender, could be interesting","9b9c48e2":"### Train categories","f5c92ba2":"### Belongs_to_collection","f6facce6":"We'll apply on it the same transformations as on the training dataset.","c033b630":"Metric to use:  Root-Mean-Squared-Logarithmic-Error (RMSLE) between the predicted value and the actual revenue. Logs are taken to not overweight blockbuster revenue movies.","62d6a18b":"We'll drop the one in each group without which the OOB score improves: `release_Week` and `release_Year`, and check the new score.","ddd81c38":"### Homepage","671aa01d":"- Dendrogram plot\n- Write a function to get the OOB score for a dataframe\n- Get the OOB score of the base dataframe\n- Remove some of the related features one at a time to see if the model can be simplified without impacting the accuracy\n- Check the OOB score of the final dataframe\n- Get the final columns to keep","4f5406fa":"### Overview","c576e2b8":"# The data","c0c3bdd6":"Interesting crew jobs: Director, Screenplay, Director of Photography, Original Music Composer, Art Direction","f2b1ccc9":"Some features seem strongly related:\n- release_Month, release_Dayofyear and release_Week\n- release_Year and release_Elapsed.\nMaybe removing one of each group will get a better score, and some other features will gain importance.","4f62a230":"### Budget","115b3b37":"### Production companies","77da3cfe":"It seems to have improved a bit!","ae604e90":"### Spoken languages","199d8be0":"### Genres","ce1a3bad":"### Tagline","c92331b5":"Convert strings to pandas categories","5ee79b97":"Goal: plot the feature importance, keep the best features and see if it improves the score","5b9d5ca5":"### Crew","9641e8c2":"Add the crew length","1abf5dc2":"### Production countries","04465e6c":"Hmm... Depends but the model seems better without these 2 columns, let's drop them.","020a2676":"# Random forest","d0b056d7":"# Submission on test set","4de8980e":"We need to take care of some fields that seem important:\n- `genres` => extract the names & one-hot encode\n- `production_companies`, `production_countries`, `spoken_languages`, `Keywords` => extract the names & one-hot encode the most common ones\n- `cast` => extract the length\n- `crew` => extract some interesting names and the length","573801d0":"## Pre-processing","4b5c4f32":"# Final model","085b5472":"Let's define functions to extract a list of genres for each row and hot encode them.","acbc26f1":"We'll transform `belongs_to_collection` to a bool","33073f53":"### Keywords","72e62d4e":"## Initial processing","21305b3b":"### Remove biased or unusable features"}}