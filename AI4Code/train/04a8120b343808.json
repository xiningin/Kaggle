{"cell_type":{"5417f51b":"code","d94d45ee":"code","98da6972":"code","c6e5be36":"code","1e0bb66b":"code","2c598b79":"code","fc6d1516":"code","eeff1ac8":"code","57dbd3d3":"code","994ba940":"code","94eefd99":"code","c272c961":"code","fcf9348f":"code","379c4e36":"code","d44a597f":"code","214b0e79":"code","93514cb2":"code","9db36ff7":"code","38950bc2":"code","5783099b":"code","2d5d4fb5":"code","a0b826d5":"code","f318daaf":"code","dac4b646":"code","460729c6":"code","975b4128":"code","da2ff084":"code","17a94f7e":"code","ad428209":"code","9356136c":"markdown","2ab70b06":"markdown","65ce6e25":"markdown","d8c2ef36":"markdown","84f6b869":"markdown","d07b751a":"markdown","9a2b6fa2":"markdown","c1a74559":"markdown","4216b609":"markdown","aba5ca7b":"markdown","e03400bb":"markdown","bd6d0cd2":"markdown","48a39d4f":"markdown","f14178be":"markdown","d33f8d4c":"markdown","a590e6ac":"markdown","332ef857":"markdown","6f7e412f":"markdown","fc004574":"markdown","05b143ba":"markdown","fc2a24b6":"markdown","ad89c808":"markdown","ea4b5054":"markdown"},"source":{"5417f51b":"import os\nimport numpy as np\nimport matplotlib.pyplot as plt \nfrom sklearn.datasets import load_files\n\nimport tensorflow as tf\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import np_utils\nfrom keras.preprocessing.image import array_to_img, img_to_array, load_img","d94d45ee":"train_dir = '\/kaggle\/input\/neu-metal-surface-defects-data\/NEU Metal Surface Defects Data\/train'\nval_dir = '\/kaggle\/input\/neu-metal-surface-defects-data\/NEU Metal Surface Defects Data\/valid'\ntest_dir='\/kaggle\/input\/neu-metal-surface-defects-data\/NEU Metal Surface Defects Data\/test'\nprint(\"Path Direcorty: \",os.listdir(\"\/kaggle\/input\/neu-metal-surface-defects-data\/NEU Metal Surface Defects Data\"))\nprint(\"Train Direcorty: \",os.listdir(\"\/kaggle\/input\/neu-metal-surface-defects-data\/NEU Metal Surface Defects Data\/train\"))\nprint(\"Test Direcorty: \",os.listdir(\"\/kaggle\/input\/neu-metal-surface-defects-data\/NEU Metal Surface Defects Data\/test\"))\nprint(\"Validation Direcorty: \",os.listdir(\"\/kaggle\/input\/neu-metal-surface-defects-data\/NEU Metal Surface Defects Data\/valid\"))","98da6972":"print(\"Training Inclusion data:\",len(os.listdir(train_dir+'\/'+'Inclusion')))\n\nprint(\"Testing Inclusion data:\",len(os.listdir(test_dir+'\/'+'Inclusion')))\n\nprint(\"Validation Inclusion data:\",len(os.listdir(val_dir+'\/'+'Inclusion')))","c6e5be36":"# All images will be rescaled by 1.\/255\ntrain_datagen = ImageDataGenerator(\n    rescale=1. \/ 255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    horizontal_flip=True)\n\n\ntest_datagen = ImageDataGenerator(rescale=1.\/255)\n\n# Flow training images in batches of 10 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(200, 200),\n        batch_size=10,\n        class_mode='categorical')\n\n# Flow validation images in batches of 10 using test_datagen generator\nvalidation_generator = test_datagen.flow_from_directory(\n        val_dir,\n        target_size=(200, 200),\n        batch_size=10,\n        class_mode='categorical')\n","1e0bb66b":"#Using transfer learning\nfrom tensorflow.keras.applications import xception\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.models import Model\nbase_model = tf.keras.applications.xception.Xception(\n    weights='imagenet', # Load weights pre-trained on ImageNet.\n    include_top=False,  # Do not include the ImageNet classifier at the top.\n    input_shape=(200,200,3),\n    pooling='avg')","2c598b79":"base_model.trainable = False # Freeze the base_model","fc6d1516":"# Let's take a look at the base model architecture\nbase_model.summary()","eeff1ac8":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Activation, Flatten\nmodel = Sequential()\nmodel.add(base_model)\nmodel.add(Flatten())\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dense(6, activation='softmax'))","57dbd3d3":"model.compile(loss='categorical_crossentropy',\n                optimizer='adam',\n                metrics=['accuracy'])","994ba940":"model.summary()","94eefd99":"class myCallback(tf.keras.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('accuracy') > 0.98 ):\n            print(\"\\nReached 98% accuracy so cancelling training!\")\n            self.model.stop_training = True ","c272c961":"initial_epochs = 10\nloss0, accuracy0 = model.evaluate(validation_generator)\n\nprint(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","fcf9348f":"callbacks = myCallback()\nhistory = model.fit(train_generator, epochs=initial_epochs,\n                    validation_data=validation_generator, callbacks=[callbacks],\n                    verbose=1, shuffle=True)","379c4e36":"from matplotlib.ticker import StrMethodFormatter\n\nplt.figure(figsize=(8, 8))\n\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n\n# summarize history for accuracy  \nplt.subplot(211)  \nplt.plot(acc)  \nplt.plot(val_acc)  \nplt.title('Model Accuracy')  \nplt.ylabel('Accuracy') \nplt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}')) # 2 decimal places \nplt.xlabel('Epoch')  \nplt.legend(['train', 'test'], loc='lower right')  \n\nplt.figure(figsize=(8, 8)) \n\n# summarize history for loss     \nplt.subplot(212)  \nplt.plot(loss)  \nplt.plot(val_loss)  \nplt.title('Model Loss')  \nplt.ylabel('Loss') \nplt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.2f}')) # 2 decimal places \nplt.xlabel('Epoch')  \nplt.legend(['train', 'test'], loc='upper right')  \nplt.show()","d44a597f":"from keras.models import load_model\nmodel.save('my_model.h5') # save the entire model with trained weights\nnew_model = load_model('my_model.h5') # load this model with its weights","214b0e79":"# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 100\n\n# Freeze all the layers before the `fine_tune_at` layer\nfor layer in new_model.layers[:fine_tune_at]:\n    layer.trainable =  False","93514cb2":"model.compile(optimizer=tf.keras.optimizers.Adam(1e-5),  # Low learning rate\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])","9db36ff7":"model.summary()","38950bc2":"from tensorflow import keras\nfrom keras.callbacks import ReduceLROnPlateau, EarlyStopping\n\n#learning_rate reduce module\nlr_reduce = keras.callbacks.ReduceLROnPlateau('val_loss', patience=4, \n                                              factor=0.5, min_lr=1e-6)\n\n# Stop early if model doesn't improve after n epochs\nearly_stopper = EarlyStopping(monitor='val_loss', patience=4,\n                              verbose=0, restore_best_weights=True)","5783099b":"fine_tune_epochs = 10\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model.fit(train_generator,\n                         batch_size = 32,\n                         epochs=total_epochs,\n                         initial_epoch=history.epoch[-1],\n                         validation_data=validation_generator,\n                         callbacks=[lr_reduce, early_stopper],\n                         verbose=1, shuffle=True)","2d5d4fb5":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","a0b826d5":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.96, 1.01])\nplt.plot([initial_epochs-8,initial_epochs-8],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy')\nplt.ylabel('Accuracy') \nplt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.3f}')) # 3 decimal places \nplt.xlabel('Epoch')\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 0.1])\nplt.plot([initial_epochs-8,initial_epochs-8],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss')\nplt.ylabel('Loss') \nplt.gca().yaxis.set_major_formatter(StrMethodFormatter('{x:,.3f}')) # 3 decimal places \nplt.xlabel('Epoch')\nplt.show()","f318daaf":"# First, we are going to load the file names and their respective target labels into numpy array! \ndef load_dataset(path):\n    data = load_files(path)\n    files = np.array(data['filenames'])\n    targets = np.array(data['target'])\n    target_labels = np.array(data['target_names'])\n    return files,targets,target_labels\n    \nx_test, y_test,target_labels = load_dataset(test_dir)","dac4b646":"no_of_classes = len(np.unique(y_test))\nno_of_classes","460729c6":"y_test = np_utils.to_categorical(y_test,no_of_classes)","975b4128":"# We just have the file names in the x set. Let's load the images and convert them into array.\ndef convert_image_to_array(files):\n    images_as_array=[]\n    for file in files:\n        # Convert to Numpy Array\n        images_as_array.append(img_to_array(load_img(file)))\n    return images_as_array\n\nx_test = np.array(convert_image_to_array(x_test))\nprint('Test set shape : ',x_test.shape)","da2ff084":"x_test = x_test.astype('float32')\/255","17a94f7e":"# Let's visualize test prediction.\ny_pred = model.predict(x_test)\n\n# plot a raandom sample of test images, their predicted labels, and ground truth\nfig = plt.figure(figsize=(16, 9))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(y_pred[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"Pred: {}|Act: {}\".format(target_labels[pred_idx], target_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))","ad428209":"# make a prediction for a new image.\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.models import load_model\n \n# load the image\nimg = load_img('..\/input\/test-data\/Scracth.png', target_size=(200, 200))\n# convert to array\nimg = img_to_array(img)\n# reshape into a single sample with 3 channels\nimg = img.reshape(1, 200, 200, 3)\n# center pixel data\nimg = img.astype('float32')\/255\n \n# predict the class\nresult = model.predict(img)\nprint('This metal has',target_labels[np.argmax(result)])","9356136c":"Transfer learning is about leveraging feature representations from a pre-trained model, so you don\u2019t have to train a new model from scratch. \n\nThe pre-trained models are usually trained on massive datasets that are a standard benchmark in the computer vision frontier. The weights obtained from the models can be reused in other computer vision tasks. \n\nThese models can be used directly in making predictions on new tasks or integrated into the process of training a new model. Including the pre-trained models in a new model leads to lower training time and lower generalization error.  \n\nTransfer learning is particularly very useful when you have a small training dataset. In this case, you can, for example, use the weights from the pre-trained models to initialize the weights of the new model. ","2ab70b06":"Compile the model before training it. Since there are more than two classes, use a categorical_crossentropy","65ce6e25":"### Add a classification head","d8c2ef36":"It is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. Xception has many layers, so setting the entire model's trainable flag to False will freeze all of them.\n\n\n","84f6b869":"# 1. About the dataset","d07b751a":"# 7. Fine tuning","9a2b6fa2":"# 4. Data preprocessing","c1a74559":"### Un-freeze the top layers of the model\nAll you need to do is unfreeze the base_model and set the bottom layers to be un-trainable. Then, you should recompile the model (necessary for these changes to take effect), and resume training.\n\n\n","4216b609":"Stop training the model at 98% traning accuracy","aba5ca7b":"### Compile the model","e03400bb":"###Compile the model\nAs you are training a much larger model and want to readapt the pretrained weights, it is important to use a lower learning rate at this stage. Otherwise, your model could overfit very quickly.","bd6d0cd2":"# 3. Load the data from dataset\n\nWe can see the dataset distribution for 'Inclusion' surface defect. Rest of the dataset also follow the same distribution","48a39d4f":"Fine-tuning is an optional step in transfer learning. Fine-tuning will usually improve the performance of the model. However, since you have to retrain the entire model, you\u2019ll likely overfit. Overfitting is avoidable. Just retrain the model or part of it using a low learning rate. This is important because it prevents significant updates to the gradient. These updates result in poor performance. Using a callback to stop the training process when the model has stopped improving is also helpful. ","f14178be":"In this step, you will freeze the convolutional base created from the previous step and to use as a feature extractor. Additionally, you add a classifier on top of it and train the top-level classifier.\n\n","d33f8d4c":"The metal surface defect picture was predicted correctly by our model which the sample has been identified as scratches defect.","a590e6ac":"### Freeze the convolutional base","332ef857":"We test our model with one sample metal defect product from one of metal company in Indonesia to predict the type of defect from this above picture. This sample already classified as scratch defect surface by quality control of its company.","6f7e412f":"In the feature extraction experiment, you were only training a few layers on top of an Exception base model. The weights of the pre-trained network were not updated during training.\n\nOne way to increase performance even further is to train (or \"fine-tune\") the weights of the top layers of the pre-trained model alongside the training of the classifier you added. The training process will force the weights to be tuned from generic feature maps to features associated specifically with the dataset.\n\nAlso, you should try to fine-tune a small number of top layers rather than the whole Exception model. In most convolutional networks, the higher up a layer is, the more specialized it is. The first few layers learn very simple and generic features that generalize to almost all types of images. As you go higher up, the features are increasingly more specific to the dataset on which the model was trained. The goal of fine-tuning is to adapt these specialized features to work with the new dataset, rather than overwrite the generic learning.\n\n\n\n","fc004574":"### Train the model","05b143ba":"# 2. Import Library","fc2a24b6":"This dataset was downloaded from NEU Metal Surface Defects Databse which contains six kinds of typical surface defects of the hot-rolled steel strip are collected, i.e., rolled-in scale (RS), patches (Pa), crazing (Cr), pitted surface (PS), inclusion (In) and scratches (Sc). The database includes 1,800 grayscale images: 300 samples each of six different kinds of typical surface defects. The detailed defects are as follows:\n\n\n*   **Inclusion**: Inclusion is a typical defect of metal surface defects. Some inclusions are loose and easy to fall off, some pressed into the plate.\n*   **Crazing**: Crazing is the phenomenon that produces some cracks on the surface of a material.\n*   **Patches**: A part of metal marked out from the rest by a particular characteristic.\n*   **Pitted surface**: Pitting is a form of corrosion that focuses on a very small range of metal surfaces and penetrates into the metal interior. Pitting is generally small in diameter but deep in depth.\n*   **Scratches**: A scratch is a mark of abrasion on a surface.\n*   **Rolled in scale**: A rolled-in scale defect occurs when the mill scale is rolled into the metal duringthe rolling process.\n\nThe dataset divided into 3 directories. The training directory contains 276 images of each class from the 300 images. The rest 24 images of each class also divided into tests and valid datasets.\n\n","ad89c808":"# 6. Feature extraction","ea4b5054":"### Learning Curves\nLet's take a look at the learning curves of the training and validation accuracy\/loss when using the Exception base model as a fixed feature extractor."}}