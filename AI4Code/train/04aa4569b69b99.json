{"cell_type":{"849735ef":"code","80eec8ac":"code","181b02a8":"code","af9a4efc":"code","30282e9e":"code","69995124":"code","42ea1e4f":"code","307bfd67":"code","ef4bae38":"code","8cdd0a86":"code","39854afc":"code","a62e6572":"code","c37469f4":"code","52c34123":"code","b9721da1":"code","bf833d32":"code","5d526111":"markdown","bcdff537":"markdown","a4a86073":"markdown","d6832092":"markdown","273ff4ca":"markdown","3f060206":"markdown","24bd2db0":"markdown","2fc92872":"markdown","3686bc62":"markdown","610cd055":"markdown","dc72a5a4":"markdown","48413581":"markdown","f7bc9c2a":"markdown","c98c9dea":"markdown"},"source":{"849735ef":"import os\nimport cv2\n\ndata_dir =  \"..\/input\/road-damage-classification-and-assessment\/sih_road_dataset\"\nlabels = [\"good\", \"poor\", \"satisfactory\", \"very_poor\"]\nx = []\ny = []\nfor label in labels:\n    data = os.path.join(data_dir,label)\n    for image in os.listdir(data):\n        try:\n            im = cv2.imread(os.path.join(data,image),cv2.IMREAD_COLOR)\n            im = cv2.resize(im,(224,224))\n            # Using the Canny filter with different parameters\n            \n            x.append(im)\n            y.append(labels.index(label))\n            \n            \n        except Exception as e:\n            pass","80eec8ac":"# Just checking the legth of x and y\nlen(x)        \nlen(y)","181b02a8":"import numpy as np\nnp.unique(y)\nnp.unique(x)\n\nx = np.array(x)\/255.0\ny = np.array(y)\n\nx.shape\ny.shape\n\nx = x.reshape(-1, 224, 224, 3)\nx.shape\ny = y.reshape(-1, 1)","af9a4efc":"from tensorflow.keras.utils import to_categorical\n\ny = to_categorical(y,4,)\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagenerator = ImageDataGenerator(\nfill_mode= 'nearest',\nhorizontal_flip=False,\nvertical_flip=False,\nshear_range=0.1,\nzoom_range = 0.1, # Randomly zoom image \nwidth_shift_range=0.2,  # randomly shift images horizontally (fraction of total width)\nheight_shift_range=0.2\n)\ndatagenerator.fit(x)","30282e9e":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y)","69995124":"import tensorflow as tf\nmodel = tf.keras.Sequential([\ntf.keras.layers.Conv2D(32,(5,5),padding ='same',strides=(2,2),activation='relu',input_shape=(224,224,3)),\ntf.keras.layers.MaxPooling2D((2,2)),\ntf.keras.layers.Conv2D(64,(5,5),padding ='same',strides=(2,2),activation='relu'),\ntf.keras.layers.MaxPooling2D((2,2)),\ntf.keras.layers.Conv2D(128,(5,5),padding ='same',strides=(2,2),activation='relu'),\ntf.keras.layers.MaxPooling2D((2,2)),\ntf.keras.layers.Conv2D(128,(5,5),padding ='same',strides=(2,2),activation='relu'),\ntf.keras.layers.Flatten(),\ntf.keras.layers.Dense(256,activation='relu'),\ntf.keras.layers.Dropout(0.3),\n    \ntf.keras.layers.Dense(4,activation='softmax')\n])\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])","42ea1e4f":"earlystop = tf.keras.callbacks.EarlyStopping(monitor='val_loss',patience=4,restore_best_weights=True)\n\nmodel.fit(datagenerator.flow(x_train,y_train,batch_size=32),epochs=20,callbacks=[earlystop],validation_data=datagenerator.flow(x_test,y_test))","307bfd67":"import pandas as pd\nhistory = pd.DataFrame(model.history.history)\nhistory[[\"loss\", \"val_loss\"]].plot()","ef4bae38":"model.evaluate(x_test, y_test)","8cdd0a86":"from PIL import Image\ndef convert_to_array(img):\n    im = cv2.imread(img)\n    img = Image.fromarray(im, 'RGB')\n    image = img.resize((224, 224))\n    return np.array(image)","39854afc":"def get_profile_name(label):\n    if label==0:\n        return \"Good\"\n    if label==1:\n        return \"Poor\"\n    if label==2:\n        return \"Satisfactory\"\n    if label==3:\n        return \"Very_Poor\"","a62e6572":"def predict_profile(file):\n    print(\"Predicting .................................\")\n    ar=convert_to_array(file)\n    ar=ar\/255\n    a=[]\n    a.append(ar)\n    a=np.array(a)\n    score=model.predict(a,verbose=1)\n    print(score)\n    label_index=np.argmax(score)\n    print(label_index)\n    acc=np.max(score)\n    profile=get_profile_name(label_index)\n    print(profile)\n    print(\"The predicted profile is a \"+profile+\" with accuracy =    \"+str(acc))    ","c37469f4":"pre_image = \"..\/input\/road-damage-classification-and-assessment\/sih_road_dataset\/very_poor\/verypoor_003.jpg\"","52c34123":"predict_profile(pre_image)","b9721da1":"pre_image2 = \"..\/input\/road-damage-classification-and-assessment\/sih_road_dataset\/good\/good_027.JPG\"\npredict_profile(pre_image2)","bf833d32":"pre_image3 = \"..\/input\/road-damage-classification-and-assessment\/sih_road_dataset\/satisfactory\/satis_030.jpg\"\npredict_profile(pre_image3)","5d526111":"## Predicting Very poor road","bcdff537":"# Discription\n\nIn this data i have classified 4 types of roads which are good, poor, satisfactory and very poor using CNN. Upvote if you like my work.\nNow lets get Started:","a4a86073":"# Changing list to array and rescaling the Data","d6832092":"## Predicting Good road","273ff4ca":"## Predicting Satisfactory road","3f060206":"# Splitting Data into train and test","24bd2db0":"# At last evaluating the model to check accuracy","2fc92872":"# And here is the Prediction of road","3686bc62":"# Turning y labels to categorical and Analysing Images","610cd055":"Note: in this data poor roads and satisfactory road are very similar to each other thats why model wont be able to predict or differentiate between those two images.","dc72a5a4":"# Using CNN (Convolutional neural Network)","48413581":"# Using early stopping and training the model\n\n#### Note: EarlyStopping stop the model from overfitting.","f7bc9c2a":"# Plotting loss|val_loss to see if model overfitting or not\n\n#### Note: If val_loss is higher then loss it means model is overfitting.","c98c9dea":"# First i am going to split data in x and y."}}