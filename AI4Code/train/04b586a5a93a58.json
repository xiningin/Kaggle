{"cell_type":{"42310b58":"code","249aef25":"code","4284b0af":"code","2620628a":"code","c1f65754":"code","f43cf3de":"code","335d0ac2":"code","3935dcce":"code","8b376ef0":"code","718430b7":"code","b5c722ed":"code","dcaed568":"code","20994094":"code","628a3368":"code","7a4a3b1e":"markdown","3bf479c4":"markdown","01db3f4b":"markdown","bb0ca8c0":"markdown","9d3edb0d":"markdown","51256024":"markdown","2c09c312":"markdown"},"source":{"42310b58":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        data = pd.read_csv(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","249aef25":"# Let's take a look at the dataset first of all\ndata.head()","4284b0af":"# Make all the necessary imports\n\nimport matplotlib.pyplot as plt\n!pip install lazypredict \nfrom lazypredict.Supervised import LazyClassifier\n!pip install plotly\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder, MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import cross_val_score, train_test_split\nfrom plotly.subplots import make_subplots","2620628a":"# Getting a outlook of our dataset\ndata.info()","c1f65754":"# Checking this out to determine which are to be left as numeric and which to categorical\ndata.nunique()","f43cf3de":"# Separating out categorical and numerical columns\n\n\n#categorical columns\ncat = ['sex', 'cp', 'fbs', 'restecg', 'exang', 'slope', 'ca', 'thal']\nnum = [l for l in list(data.columns) if l not in cat]\nprint(\"Numerical columns:\",num)\nprint(\"Categorical columns:\",cat)","335d0ac2":"%matplotlib inline\n\n\nfig = make_subplots(rows = 2, cols = 3)\n\nfor i, n in enumerate(num):\n    if n != 'target':\n        fig.add_trace(go.Box(x = list(data['target']), y = list(data[n]), name = str(n)),\n                     row = (i\/\/3+1), col = i%3 + 1)\n\nfig.show()","3935dcce":"print('no of outliers in the thalach', sum(data['thalach']<90))\nprint('no of outliers in the oldpeak', sum(data['oldpeak']>5))\nprint('no of outliers in the chol', sum(data['chol']>400))\nprint('no of outliers in the trestbps', sum(data['trestbps']>190))","8b376ef0":"data = data[data['thalach']>90]\ndata = data[data['oldpeak']<5]\ndata = data[data['chol'] < 400]\ndata = data[data['trestbps']<190]\nprint(\"No of rows after removing the outliers\", len(data))","718430b7":"dfcat = data[cat]\ndfcat.head()","b5c722ed":"dfnum = data[num]\ndfnum.head()","dcaed568":"#One hot encoding the categorical data\n\nonehot = OneHotEncoder()\nxcat = onehot.fit_transform(dfcat.iloc[:, :].values).toarray()","20994094":"# Scaling the numerical features\n\nfor col in dfnum.columns:\n    dfnum[col] = (dfnum[col] - dfnum[col].mean())\/dfnum[col].std()\n    \nxnum = dfnum.iloc[:, :-1].values\n\nx = np.concatenate((xcat, xnum), axis = 1)\ny = data.iloc[:, -1].values","628a3368":"# Lazypredict's Model report\n\nxtrain, xtest, ytrain, ytest = train_test_split(x, y, test_size = 0.2)\nclf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\nmodels,predictions = clf.fit(xtrain, xtest, ytrain, ytest)\nmodels","7a4a3b1e":"**So our data has 303 samples, Good news is that no column has null values so phew! one less thing to worry about**\n\nThe following is the description of dataset as given in the data descrption page\n\nfeatures = \n\n1) age\n\n2) sex\n\n3) chest pain type (4 values)\n\n4) resting blood pressure\n\n5) serum cholestoral in mg\/dl\n\n6) fasting blood sugar > 120 mg\/dl\n7) resting electrocardiographic results (values 0,1,2)\n\n8) maximum heart rate achieved\n\n9) exercise induced angina\n\n10) oldpeak = ST depression induced by exercise relative to rest\n\n11) the slope of the peak exercise ST segment\n\n12) number of major vessels (0-3) colored by flourosopy\n\n13) thal: 0 = normal; 1 = fixed defect; 2 = reversable defect\n\n14) target: 0= less chance of heart attack 1= more chance of heart attac","3bf479c4":"##### First thing we can see from the boxplots is that surprisingly enough cholestrol is not a good indicator for our model, Secondly we see too many outliers, so we are going to remove them ","01db3f4b":"##### Now that we know about the outlier we are going to remove them","bb0ca8c0":"#### We will use boxplots to visualize the categorical data's influence on our target, and we will use the plotly package as it makes interactive plots","9d3edb0d":"I am going to update the notebook with some cool charts for categorical features and some feature engineering in a short while... Mean while if you liked the notebook do give an upvote.","51256024":"## In this Notebook we are going to perform some EDA and then come with a cool package called Lazypredict which can give us a detailed report of comparisons of various models","2c09c312":"Now extracting the categorical and the numerical columns separately so that we can perform the preprocessing accordingly"}}