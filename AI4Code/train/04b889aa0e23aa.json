{"cell_type":{"c63370d4":"code","4bdfdd94":"code","6e05724b":"code","d7fd7774":"code","5e6b6a9a":"code","caf66daa":"code","9e2ae385":"code","fcc4bd68":"code","cd3ad7aa":"code","8fbe3c3c":"code","5a4bd839":"code","175b8bf8":"code","58d16da0":"code","182d14de":"code","b23b722d":"code","702a9354":"code","636da5c0":"code","49ccbd56":"code","8557eb9b":"code","deef6346":"code","0a5a1e25":"code","32495a10":"code","54efa3c4":"code","bc209121":"code","442d14f6":"code","1a729e9b":"code","5c4d3100":"code","2125e859":"code","396bf85e":"code","c494055c":"code","06440368":"code","650a8e3a":"code","c67cbac4":"code","940b7bae":"code","72c818ea":"code","572e378a":"code","920f5089":"code","776f5c37":"code","108e001e":"code","f44d68f0":"code","2fb4fd63":"code","9288ac07":"code","6e11b543":"code","921d379b":"code","14d8a160":"code","3e2dc467":"code","c094afe6":"code","416e0f4a":"code","1bcf89dc":"code","a91fd585":"code","a8221a61":"code","b71123de":"code","15f05a66":"code","1b07a38f":"code","d39d5fbd":"code","2df16aa7":"code","27007597":"code","d815d24d":"code","a502a651":"code","b1ba9238":"markdown","d09ed86a":"markdown","63fe1a7b":"markdown","52d70636":"markdown","0b729c76":"markdown","900b7dfc":"markdown","c28d0154":"markdown","0b413111":"markdown","9a3be76a":"markdown","f57a9c04":"markdown","3b25ecaf":"markdown","30a487fc":"markdown","5b572285":"markdown","8cb1b374":"markdown","bed3310e":"markdown","71875dbd":"markdown","683496a4":"markdown","37ea4ca7":"markdown","f36fa75e":"markdown"},"source":{"c63370d4":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.ticker import PercentFormatter\nimport seaborn as sns\nimport math\nimport phik\nimport shap\nfrom scipy import stats\nfrom collections import Counter\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV, StratifiedKFold\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.preprocessing import OneHotEncoder\nfrom imblearn.under_sampling import CondensedNearestNeighbour, TomekLinks\nfrom imblearn.over_sampling import SMOTE, ADASYN\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost.sklearn import XGBClassifier\nfrom catboost import CatBoostClassifier\nfrom tensorflow.keras import Sequential \nfrom tensorflow.keras.layers import Input, Dense\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import roc_curve, confusion_matrix, classification_report\n\nsns.set(font_scale=1)\npd.options.display.max_columns = None","4bdfdd94":"# Ucitavanje CSV fajla\ndata = pd.read_csv(\"\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")","6e05724b":"# Pregled prvih 5 redova dataframe-a\ndata.head(5)","d7fd7774":"# Informacije o dataframe-u\ndata.info()","5e6b6a9a":"data['SeniorCitizen'].unique()","caf66daa":"# Feature SeniorCitizen je kategoricka promenljiva (zbog grafika 0 cemo zameniti sa No, a 1 sa Yes)\ndata['SeniorCitizen'] = data['SeniorCitizen'].map({0:'No', 1:'Yes'})","9e2ae385":"# Cast-ovanje TotalCharges feature-a\ndata['TotalCharges'] = pd.to_numeric(data['TotalCharges'], errors='coerce') # coerce - neispravne vrednosti se zamenjuju sa np.nan","fcc4bd68":"# Provera da li tabela sadrzi prazna polja\ndata.isnull().sum()","cd3ad7aa":"# Brisanje redova sa null vrednoscu (None) u koloni TotalCharges\ndata.drop(data[data['TotalCharges'].isnull()].index, inplace=True)\ndata.reset_index(drop=True, inplace=True)","8fbe3c3c":"# Provera da li ima vise unosa o istom korisniku\nprint(data.shape[0])\nprint(data.customerID.nunique())","5a4bd839":"# Odredjivanje broja dupliranih redova\ndata.drop('customerID',axis=1, inplace=True)\nprint(data.duplicated().sum())","175b8bf8":"# Brisanje dupliranih redova\nindex_duplicates = data[data.duplicated()].index\ndata.drop(index_duplicates, inplace=True)\ndata.reset_index(drop=True, inplace=True)","58d16da0":"# col_num - numericke promenljive\n# col_cat - kategoricke promenjive\ncol_num = data.select_dtypes(include=np.number).columns\ncol_cat = data.select_dtypes(include='object').columns","182d14de":"# Statisticki podaci o numerickim feature-ima\ndata.describe()","b23b722d":"plt.figure(figsize=(19,8))\n\nlabel = ['Tenure', 'Monthly charges', 'Total Charges']\n\nfor i in range(len(col_num)):\n    ax = plt.subplot(2,3,i+1)\n    sns.boxplot(data=data, x=\"Churn\",y=col_num[i])\n    ax.set_ylabel(label[i], fontsize=12)\n    ax.grid(False)\n    \n    ax = plt.subplot(2,3,i+4)\n    sns.kdeplot(data=data[data.Churn=='No'], x=col_num[i], fill=True, alpha=.5)\n    sns.kdeplot(data=data[data.Churn=='Yes'], x=col_num[i], fill=True, alpha=.5)\n    ax.set_xlabel(label[i], fontsize=12)\n    ax.set_ylabel('Density', fontsize=12)\n    ax.legend(['No churn', 'Churn'], loc='upper right')\n    ax.grid(False)","702a9354":"def plot_multivariate_dist(data, x_feature, y_feature):\n    plt.figure(figsize=(13,4))\n    \n    ax = plt.subplot(1,2,1)\n    sns.kdeplot(data=data[data.Churn=='No'], x=x_feature, y=y_feature, fill=True, alpha=.5)\n    ax.title.set_text('No churn')\n    ax.grid(False)\n    \n    ax = plt.subplot(1,2,2)\n    sns.kdeplot(data=data[data.Churn=='Yes'], x=x_feature, y=y_feature, fill=True, alpha=.5)\n    ax.title.set_text('Churn')\n    ax.grid(False)","636da5c0":"feature_pairs = [('tenure', 'MonthlyCharges'), ('tenure', 'TotalCharges'), ('MonthlyCharges', 'TotalCharges')]\nfor feature_pair in feature_pairs:\n    plot_multivariate_dist(data, feature_pair[0], feature_pair[1])","49ccbd56":"# Kruskal Wallis test\nkruskal_tenure_churn = stats.kruskal(data[data['Churn']=='No']['tenure'], data[data['Churn']=='Yes']['tenure'])\nprint('Kruskal Wallis test - churn + tenure')\nprint(kruskal_tenure_churn)\nprint('')\n\nkruskal_monthlycharges_churn = stats.kruskal(data[data['Churn']=='No']['MonthlyCharges'], data[data['Churn']=='Yes']['MonthlyCharges'])\nprint('Kruskal Wallis test - churn + monthly charges')\nprint(kruskal_monthlycharges_churn)\nprint('')\n\nkruskal_totalcharges_churn = stats.kruskal(data[data['Churn']=='No']['TotalCharges'], data[data['Churn']=='Yes']['TotalCharges'])\nprint('Kruskal Wallis test - churn + total charges')\nprint(kruskal_totalcharges_churn)","8557eb9b":"# Korelacija promenljivih\ndata['ChurnInt'] = data['Churn'].map({'No':0, 'Yes':1}).astype(np.uint8)\ncorr_num = data.corr(method='spearman').round(2)\n\nplt.figure(figsize=(7,5))\nsns.heatmap(corr_num, annot=True, cmap='Blues')\nytick = plt.yticks(rotation=0)\n\ndata.drop('ChurnInt', axis=1, inplace=True)","deef6346":"# Ispitivanje multikolinearnsti (variance inflation factor)\nvif_data = pd.DataFrame()\nvif_data[\"feature\"] = col_num \n\n# proracun VIF faktora za svaki numericki feature\nvif_data[\"VIF\"] = [variance_inflation_factor(data[col_num].values, i) for i in range(len(col_num))]\n  \nprint(vif_data)\ndel vif_data","0a5a1e25":"# Razmatranje iskljucivanja feature-a TotalCharges\nvif_data = pd.DataFrame()\nvif_data[\"feature\"] = ['tenure','MonthlyCharges']\nvif_data[\"VIF\"] = [variance_inflation_factor(data[['tenure','MonthlyCharges']].values, i) for i in range(2)]\n  \nprint(vif_data)\ndel vif_data","32495a10":"def plot_churn_per_feature_bins(data, feature, x_label, ylim=(0,100)):\n    barplot = sns.barplot(data=df[df['Churn']=='Yes'], x=feature, y='Percentage', palette=\"Blues_d\")\n    barplot.set(ylim=ylim)\n    barplot.set_xlabel(x_label, fontsize=12)\n    barplot.set_ylabel('Churn %', fontsize=12)\n    plt.show()","54efa3c4":"# Podela korisnika u 6 grupa na osnovu duzine trajanja saradnje i prikaz procenta raskida ugovora za svaku grupu\ndata['tenureBins'] = pd.cut(data['tenure'], list(range(0,84,12)))\ndf = (data.groupby(['tenureBins'])['Churn'].value_counts(normalize=True)\n            .rename('Percentage').mul(100).reset_index())\n\nplot_churn_per_feature_bins(df, 'tenureBins', 'Tenure [months]', (0,60))\n\ndata.drop('tenureBins', axis=1, inplace=True)\ndel df","bc209121":"# Za svaki tip ugovora izvrsena je podela korisnika u 6 grupa na osnovu duzine trajanja saradnje\n# i prikazan je procenat raskida ugovora za svaku grupu \nfor contract in data['Contract'].unique():\n    data['tenureBins'] = pd.cut(data['tenure'], list(range(0,84,12)))\n    df = (data[data['Contract']==contract].groupby(['tenureBins'])['Churn'].value_counts(normalize=True)\n                .rename('Percentage').mul(100).reset_index())\n\n    plot_churn_per_feature_bins(df, 'tenureBins', contract + ' contract: tenure [months]', (0,60))\n\n    data.drop('tenureBins', axis=1, inplace=True)\n    del df","442d14f6":"# Podela korisnika u 6 grupa na osnovu iznosa mesecne pretplate i prikaz procenta raskida ugovora za svaku grupu\ndata['MonthlyChargesBins'] = pd.cut(data['MonthlyCharges'], list(range(0,140,20)))\ndf = (data.groupby(['MonthlyChargesBins'])['Churn'].value_counts(normalize=True)\n            .rename('Percentage').mul(100).reset_index())\n\nplot_churn_per_feature_bins(df, 'MonthlyChargesBins', 'Monthly charges', (0,50))\n\ndata.drop('MonthlyChargesBins', axis=1, inplace=True)\ndel df","1a729e9b":"# Za svaki tip ugovora izvrsena je podela korisnika u 6 grupa na osnovu iznosa mesecne pretplate\n# i prikazan je procenat raskida ugovora za svaku grupu \nfor contract in data['Contract'].unique():\n    data['MonthlyChargesBins'] = pd.cut(data['MonthlyCharges'], list(range(0,140,20)))\n    df = (data[data['Contract']==contract].groupby(['MonthlyChargesBins'])['Churn'].value_counts(normalize=True)\n                .rename('Percentage').mul(100).reset_index())\n\n    plot_churn_per_feature_bins(df, 'MonthlyChargesBins', contract + ' contract: monthly charges', (0,60))\n\n    data.drop('MonthlyChargesBins', axis=1, inplace=True)\n    del df","5c4d3100":"data.describe(exclude=np.number)","2125e859":"df = pd.DataFrame()\ndf['Feature'] = col_cat\n\nuniq_vals = []\ncount = []\nfor col in col_cat:\n    counter = Counter(data[col])\n    uniq_vals.append(counter.keys())\n    count.append(counter.values())\ndf['Unique values'] = uniq_vals\ndf['Values count'] = count\n\nprint(df.to_string())\ndel df","396bf85e":"# Transformacija podataka kako bi se sprecilo postojanje redudantnih feature-a (znacajno i zbog dummy encoding-a i razvoja modela)\ndata['MultipleLines'] = data['MultipleLines'].map(lambda x: 'No' if x=='No phone service' else x)\ndata['OnlineSecurity'] = data['OnlineSecurity'].map(lambda x: 'No' if x=='No internet service' else x)\ndata['OnlineBackup'] = data['OnlineBackup'].map(lambda x: 'No' if x=='No internet service' else x)\ndata['DeviceProtection'] = data['DeviceProtection'].map(lambda x: 'No' if x=='No internet service' else x)\ndata['TechSupport'] = data['TechSupport'].map(lambda x: 'No' if x=='No internet service' else x)\ndata['StreamingTV'] = data['StreamingTV'].map(lambda x: 'No' if x=='No internet service' else x)\ndata['StreamingMovies'] = data['StreamingMovies'].map(lambda x: 'No' if x=='No internet service' else x)","c494055c":"n_rows = data.shape[0]\ndf = pd.DataFrame()\ndf['Feature'] = col_cat\n\nuniq_vals = []\ncount = []\nfor col in col_cat:\n    counter = Counter(data[col])\n    uniq_vals.append(counter.keys())\n    count.append(counter.values())\ndf['Unique values'] = uniq_vals\ndf['Values count'] = count\ndf['Dist %'] = [list(c) for c in count]\ndf['Dist %'] = df['Dist %'].map(lambda x: [round(100.*i\/n_rows,2) for i in x])\n\nprint(df.to_string())\ndel uniq_vals\ndel count\ndel df","06440368":"plt.figure(figsize=(18,24))\n\nlabel = ['Gender', 'Senior citizen', 'Partner', 'Dependents', 'Phone service',\n         'Multiple lines', 'Internet service', 'Online security', 'Online backup',\n         'Device protection', 'Tech support', 'Streaming TV', 'Streaming movies',\n         'Contract', 'Paperless billing', 'Payment method', 'Churn']\n\nfor i in range(len(col_cat)):   \n    ax = plt.subplot(6,3,i+1)    \n    sns.countplot(data=data, x=col_cat[i])\n    ax.set_xlabel(label[i], fontsize=12)\n    ax.tick_params('x', labelrotation=8)\n    \nplt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, \n                    top=0.9, wspace=0.3, hspace=0.3)","650a8e3a":"plt.figure(figsize=(18,24))\n\nlabel = label[:-1]\n\nfor i in range(len(col_cat[:-1])):  \n    df = (data.groupby(col_cat[i])['Churn'].value_counts(normalize=True)\n            .rename('Percentage').mul(100).reset_index())\n    \n    ax = plt.subplot(6,3,i+1)\n    barplot = sns.barplot(data=df, x=col_cat[i], y='Percentage', hue='Churn')\n    ax.set(ylim=(0, 100))\n    ax.set_xlabel(label[i], fontsize=12)\n    ax.tick_params('x', labelrotation=8) \n    \n    for p in barplot.patches:\n        barplot.annotate(format(p.get_height(), '.1f'), \n                       (p.get_x() + p.get_width() \/ 2., p.get_height()), \n                       ha = 'center', va = 'center', \n                       xytext = (0, 9), \n                       textcoords = 'offset points')\n        \nplt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, \n                    top=0.9, wspace=0.3, hspace=0.3)","c67cbac4":"def plot_boxplots(cols, labels):\n    n = len(cols)\n    plt.figure(figsize=(12,4*n))\n    i=1\n    for col,label in zip(cols,labels):\n        ax = plt.subplot(n,2,i)\n        sns.boxplot(data=data, x=col, y='MonthlyCharges', hue='Churn')\n        ax.set_xlabel(label, fontsize=12)\n        ax.set_ylabel('Monthly charges', fontsize=12)\n        ax.legend(bbox_to_anchor=(1.01,1), borderaxespad=0)\n        ax.tick_params('x', labelrotation=8)\n        ax.grid(False)\n\n        ax = plt.subplot(n,2,i+1)\n        sns.boxplot(data=data, x=col, y='tenure', hue='Churn')\n        ax.set_xlabel(label, fontsize=12)\n        ax.set_ylabel('Tenure', fontsize=12)\n        ax.legend(bbox_to_anchor=(1.01,1), borderaxespad=0)\n        ax.tick_params('x', labelrotation=8)\n        ax.grid(False)\n\n        i += 2\n\n    plt.subplots_adjust(left=0.1, bottom=0.1, right=0.9, \n                        top=0.9, wspace=0.3, hspace=0.3)","940b7bae":"cols = ['SeniorCitizen','gender','Partner','Dependents']\nlabels = ['Senior citizen', 'Gender','Partner','Dependents']\n\nplot_boxplots(cols, labels)","72c818ea":"data['Percenet of churn'] = data['Churn'].map(lambda x: 1 if x=='Yes' else 0)\n\ncolors = ['C0', 'C1']\nax = sns.catplot(data=data, x='Partner', y='Percenet of churn', hue='Dependents', col='SeniorCitizen', \n                 kind='point', dodge=True, palette=colors, height=3, aspect=1.5)\n\ndata.drop(['Percenet of churn'], axis=1, inplace=True)\n\nax = sns.catplot(data=data, x='Partner', y='tenure', hue='Dependents', col='SeniorCitizen', \n                 kind='point', dodge=True, palette=colors, height=3, aspect=1.5)\n\nax = sns.catplot(data=data, x='Partner', y='MonthlyCharges', hue='Dependents', col='SeniorCitizen', \n                 kind='point', dodge=True, palette=colors, height=3, aspect=1.5)","572e378a":"cols = ['PhoneService', 'MultipleLines', 'InternetService',\n        'OnlineSecurity', 'OnlineBackup', 'DeviceProtection', 'TechSupport',\n        'StreamingTV', 'StreamingMovies']\nlabels = ['Phone service', 'Multiple lines', 'Internet service',\n          'Online security', 'Online backup', 'Device protection', 'Tech support',\n          'Streaming TV', 'Streaming movies']\n\nplot_boxplots(cols, labels)","920f5089":"def cramers_corr_coef(crosstab):\n    chi2 = stats.chi2_contingency(crosstab)[0]\n    n = crosstab.sum().sum()\n    phi2 = chi2\/n\n    r,k = crosstab.shape\n    phi2corr = max(0, phi2-(k-1)*(r-1)\/(n-1))    \n    rcorr = r - (r-1)**2\/(n-1)\n    kcorr = k - (k-1)**2\/(n-1)\n    \n    return np.sqrt(phi2corr\/min(kcorr-1,rcorr-1))\n\ndef cramers_corr_matrix(data, col_cat):\n    n_cat = len(col_cat)\n    cramers_corr = np.ones((n_cat, n_cat))\n    \n    for r in range(n_cat):\n        for c in range(n_cat):\n            if (col_cat[r]!=col_cat[c]) & (cramers_corr[r][c]==1):\n                crosstab = pd.crosstab(data[col_cat[r]],data[col_cat[c]])\n                cramers_corr[r][c] = cramers_corr_coef(crosstab)\n                cramers_corr[c][r] = cramers_corr[r][c]\n    \n    return cramers_corr","776f5c37":"cramers_corr = pd.DataFrame(cramers_corr_matrix(data,col_cat), columns=col_cat, index = col_cat).round(2)            \nfig, ax = plt.subplots(figsize=(15,12))\nsns.heatmap(cramers_corr, annot=True, ax=ax, cmap='Blues')","108e001e":"data.drop('TotalCharges', axis=1, inplace=True)\ncol_num = list(col_num)\ncol_num.remove('TotalCharges')\n\n# Dummy encoding kategorickih promenljivih\ndata = pd.get_dummies(data, drop_first=True)\n\n# Podela podataka na train i test setove\nX_train, X_test, y_train, y_test = train_test_split(data.drop(['Churn_Yes'], axis=1), data['Churn_Yes'], test_size = 0.20, random_state = 7, stratify=data['Churn_Yes'].values)\n\n# stanarizacija numerickih promenjivih\nscaler= StandardScaler()\nX_train[col_num] = scaler.fit_transform(X_train[col_num])\nX_test[col_num] = scaler.transform(X_test[col_num])","f44d68f0":"def grid_search_cv(model_name, X_train, y_train, print_search_results=False):\n    if model_name=='SVC':\n        model = SVC(probability=True, class_weight='balanced')\n        kernel = ['poly', 'rbf', 'sigmoid']\n        C = [50, 10, 1.0, 0.1, 0.01]\n        gamma = ['scale']\n        param_grid = dict(kernel=kernel,C=C,gamma=gamma)\n    if model_name=='LogisticRegression':\n        model = LogisticRegression(class_weight='balanced')\n        param_grid = {'C': [100, 10, 1.0, 0.1, 0.01]}\n    if model_name=='RandomForestClassifier':\n        model = RandomForestClassifier(class_weight='balanced')\n        n_estimators = [50, 100, 500, 1000]\n        max_depth = [4, 6, 8],\n        max_features = ['sqrt']\n        param_grid = dict(n_estimators=n_estimators,max_depth=max_depth)#,max_features=max_features)\n    if model_name=='XGBClassifier':\n        model = XGBClassifier(use_label_encoder=False, scale_pos_weight=4)\n        learning_rate = [0.001, 0.01, 0.1, 0.2, 0.3]\n        n_estimators = [50, 100, 500, 1000, 5000]\n        param_grid = dict(learning_rate=learning_rate,n_estimators=n_estimators)\n    \n    cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=7)\n    search = GridSearchCV(model, param_grid, scoring='neg_log_loss', cv=cv)\n    search_result = search.fit(X_train, y_train)\n    \n    print('Best result:\\n%f\\nBest parameters:\\n%s' %(search_result.best_score_, search_result.best_params_))\n    \n    if print_search_results==True:\n        means = search_result.cv_results_['mean_test_score']\n        stds = search_result.cv_results_['std_test_score']\n        parameters = search_result.cv_results_['params']\n        for mean,stdev,param in zip(means,stds,parameters):\n            print(\"%.3f (%.3f) with: %r\" % (mean, stdev, param))","2fb4fd63":"def best_threshold(target, probability):\n    best_threshold = None\n    best_score = 0\n    \n    for threshold in np.arange(0.05, 1, 0.05):\n        prediction = probability>threshold\n        score = f1_score(target, prediction)\n        if score>best_score:\n            best_threshold = threshold\n            best_score = score\n    \n    return best_threshold","9288ac07":"def model_pred_capability(model_name, y_train, pred_train, y_test, pred_test, pred_prob=None, plot_roc_curve=False):\n    print('MODEL: ' + model_name + '\\n')\n    \n    print('Classification report - train data')\n    print(classification_report(y_train, pred_train))\n    \n    print('\\n\\nClassification report - test data')\n    print(classification_report(y_test, pred_test))\n    \n    print('\\n')\n    \n    plt.figure(figsize=(5,4))\n    sns.heatmap(confusion_matrix(y_train, pred_train), annot=True, fmt = \"d\", cmap='Blues').set_title('Confusion matrix - train data')\n    plt.show()\n    \n    print('\\n')\n    \n    plt.figure(figsize=(5,4))\n    sns.heatmap(confusion_matrix(y_test, pred_test), annot=True, fmt = \"d\", cmap='Blues').set_title('Confusion matrix - test data')\n    plt.show()\n    \n    print('\\n')\n    \n    if plot_roc_curve:\n        fpr_svc, tpr_svc, thresholds = roc_curve(y_test, pred_prob)\n        plt.plot([0, 1], [0, 1], 'k--' )\n        plt.plot(fpr_svc, tpr_svc)\n        plt.xlabel('False Positive Rate')\n        plt.ylabel('True Positive Rate')\n        plt.title(model_name + ' - ROC Curve',fontsize=14)\n        plt.show()","6e11b543":"def evaluate_model(model, X_train, X_test, y_train, y_test, model_name):    \n    pred_train = model.predict(X_train)\n    pred_test = model.predict(X_test)\n    \n    if 'ANN' in model_name:\n        pred_train = np.round(pred_train).flatten()\n        pred_test = np.round(pred_test).flatten()\n        pred_prob = model.predict(X_test).flatten()\n    else:\n        pred_prob = model.predict_proba(X_test)[:,1]\n        \n    model_pred_capability(model_name, y_train, pred_train, y_test, pred_test, pred_prob, True)","921d379b":"def evaluate_best_threshold(model, X_train, X_test, y_train, y_test, best_threshold, model_name):\n    print('Best threshold: %.2f' %best_threshold)\n    \n    pred_train = model.predict_proba(X_train)[:,1]>0.55\n    pred_test = model.predict_proba(X_test)[:,1]>0.55\n    \n    model_pred_capability(model_name, y_train, pred_train, y_test, pred_test)","14d8a160":"models = ['LogisticRegression', 'SVC', 'XGBClassifier']\nfor model in models:\n    print('Model: ' + model)\n    grid_search_cv(model, X_train, y_train, False)\n    print('')","3e2dc467":"svc_model = SVC(probability=True, C=0.01, gamma='scale', kernel='poly', class_weight='balanced')\nsvc_model.fit(X_train,y_train)\nevaluate_model(svc_model, X_train, X_test, y_train, y_test, 'SVC')","c094afe6":"log_model = LogisticRegression(C=10,class_weight='balanced')\nlog_model.fit(X_train, y_train)\nevaluate_model(log_model, X_train, X_test, y_train, y_test, 'Logistic Regression')","416e0f4a":"weights = pd.DataFrame({'Feature': X_train.columns.values, 'Coef': log_model.coef_[0], 'Abs Coef': np.abs(log_model.coef_[0])})\nweights = weights.sort_values(by='Abs Coef', ascending=False).reset_index(drop=True)\n\nplt.figure(figsize=(8,8))\nsns.barplot(data=weights, x='Coef', y='Feature')","1bcf89dc":"weights['Coeficient'] = weights['Coef'].round(3)\nweights['Odds'] = weights['Coef'].map(lambda x: np.exp(x)) \nweights['Odds'] = weights['Odds'].round(2)\nweights.drop(['Abs Coef','Coef'], axis=1, inplace=True)\nweights","a91fd585":"cols = list(X_train.columns)\nfor col in col_num:\n    cols.remove(col)\n\nX_train_inter = X_train.copy()\nX_test_inter = X_test.copy()\nfor cat_feature in cols:\n    for num_feature in col_num:\n        X_train_inter[num_feature+'_'+cat_feature] = X_train_inter[num_feature]*X_train_inter[cat_feature]\n        X_test_inter[num_feature+'_'+cat_feature] = X_test_inter[num_feature]*X_test_inter[cat_feature]\n        \nlog_model_inter = LogisticRegression(solver='sag',C=10, max_iter=1000,class_weight='balanced')\nlog_model_inter.fit(X_train_inter, y_train)\nevaluate_model(log_model_inter, X_train_inter, X_test_inter, y_train, y_test, 'Logistic Regression + feature interactions')","a8221a61":"rf_model = RandomForestClassifier(n_estimators=1000, max_depth=6, class_weight='balanced')\nrf_model.fit(X_train, y_train)\nevaluate_model(rf_model, X_train, X_test, y_train, y_test, 'Random Forest')","b71123de":"explainer = shap.TreeExplainer(rf_model)\nshap_values = explainer.shap_values(X_train)\n\nshap.summary_plot(shap_values[1], X_train)","15f05a66":"xgb_model = XGBClassifier(use_label_encoder=False, learning_rate=0.01, n_estimators=1000, scale_pos_weight=4)\nxgb_model.fit(X_train, y_train)\nevaluate_model(xgb_model, X_train, X_test, y_train, y_test, 'XGB Classifier')","1b07a38f":"N, D = X_train.shape\n\nann_model = Sequential([\n    Input(shape=(D,)),\n    Dense(5, activation='sigmoid'),\n    Dense(1, activation='sigmoid')\n])\n\nann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nr = ann_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, verbose=0)\n\nplt.figure(figsize=(10,4))\nax = plt.subplot(1,2,1)\nplt.plot(r.history['loss'], label='loss')\nplt.plot(r.history['val_loss'], label='val_loss')\nplt.legend()\n\nax = plt.subplot(1,2,2)\nplt.plot(r.history['accuracy'], label='accuracy')\nplt.plot(r.history['val_accuracy'], label='val_accuracy')\nplt.legend()\n\nevaluate_model(ann_model, X_train, X_test, y_train, y_test, 'ANN model')","d39d5fbd":"X_train, X_test, y_train, y_test = train_test_split(data.drop(['Churn_Yes'], axis=1), data['Churn_Yes'], test_size = 0.20, random_state = 7, stratify=data['Churn_Yes'].values)\n\nmin_max_scaler = MinMaxScaler(feature_range=(0,1))\nX_train[col_num] = min_max_scaler.fit_transform(X_train[col_num])\nX_test[col_num] = min_max_scaler.transform(X_test[col_num])\n\nsm = SMOTE(random_state = 7)#ADASYN()\nX_train,y_train = sm.fit_resample(X_train,y_train)","2df16aa7":"rf_model = RandomForestClassifier(n_estimators=1000, max_features='sqrt', max_depth=6)\nrf_model.fit(X_train,y_train)\nevaluate_model(rf_model, X_train, X_test, y_train, y_test, 'Random Forest + SMOTE')","27007597":"N, D = X_train.shape\n\nann_model = Sequential([\n    Input(shape=(D,)),\n    Dense(8, activation='sigmoid'),\n    Dense(1, activation='sigmoid')\n])\n\nann_model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\nr = ann_model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=30, verbose=0)\nevaluate_model(ann_model, X_train, X_test, y_train, y_test, 'ANN model + SMOTE')","d815d24d":"X_train, X_test, y_train, y_test = train_test_split(data.drop(['Churn_Yes'], axis=1), data['Churn_Yes'], test_size = 0.20, random_state = 7, stratify=data['Churn_Yes'].values)\n\nmin_max_scaler = MinMaxScaler(feature_range=(0,1))\nX_train[col_num] = min_max_scaler.fit_transform(X_train[col_num])\nX_test[col_num] = min_max_scaler.transform(X_test[col_num])\n\nundersample = CondensedNearestNeighbour(n_neighbors=1)\nX_train, y_train = undersample.fit_resample(X_train, y_train)\n\nxgb_model = XGBClassifier(use_label_encoder=False, learning_rate=0.01, n_estimators=1000)\nxgb_model.fit(X_train, y_train)\nevaluate_model(xgb_model, X_train, X_test, y_train, y_test, 'Random Forest + CondensedNearestNeighbour')","a502a651":"X_train, X_test, y_train, y_test = train_test_split(data.drop(['Churn_Yes'], axis=1), data['Churn_Yes'], test_size = 0.20, random_state = 7, stratify=data['Churn_Yes'].values)\nmin_max_scaler = MinMaxScaler(feature_range=(0,1))\nX_train[col_num] = min_max_scaler.fit_transform(X_train[col_num])\nX_test[col_num] = min_max_scaler.transform(X_test[col_num])\n\nundersample = TomekLinks()\nX_train, y_train = undersample.fit_resample(X_train, y_train)\n\nsm = SMOTE(random_state = 7)\nX_train, y_train = sm.fit_resample(X_train, y_train)\n\nrf = RandomForestClassifier(n_estimators=1000, max_features='sqrt', max_depth=6)\nrf.fit(X_train, y_train)\nevaluate_model(rf, X_train, X_test, y_train, y_test, 'Random Forest + TomekLinks + SMOTE')\n\nxgb_model = XGBClassifier(use_label_encoder=False, learning_rate=0.01, n_estimators=1000)\nxgb_model.fit(X_train, y_train)\nevaluate_model(xgb_model, X_train, X_test, y_train, y_test, 'XGB Classifier + TomekLinks + SMOTE')","b1ba9238":"### Hyperparameter tuning","d09ed86a":"## Vizualizacija podataka i statisticka analiza (kategoricki feature-i)","63fe1a7b":"# Oversampling","52d70636":"### Artificial Neural Network","0b729c76":"**SHAP analiza**","900b7dfc":"### Logistic Regression + feature interaction","c28d0154":"### Extreme Gradient Boosting ","0b413111":"**Artificial Neural Network**","9a3be76a":"### Logistic Regression","f57a9c04":"# Undersampling","3b25ecaf":"### Pomocne funkcije za hyperparameter tuning i evaluaciju modela","30a487fc":"# Undersampling and Oversampling","5b572285":"# Telco Customer Churn\n \nCilj sprovedene analize jeste predvi\u0111anje pona\u0161anja korisnika (da li \u0107e raskinuti ugovor sa telekomunikacionom kompanijom ili nastaviti saradnju), kao i procena uticaja pojedinih parametara na donosenje odluke o raskidu ugovora. \n\nData set za svakog korisnika sadr\u017ei slede\u0107e podatke:\n* da li je korisnik raskinuo ugovor u poslednjih mesec dana (feature Churn)\n* informacije o servisima na koje je korisnik pretpla\u0107en (phone, multiple lines, internet, online security, online backup, device protection, tech support, streaming TV and streaming movies)\n* informacije o korisni\u010dkom ugovoru i pla\u0107anjima (tenure - how many months he\/she has been a customer, contract type, payment method, paperless billing, monthly charges and total charges)\n* demografski podaci o korisniku (gender, age range, if he\/she has a partner and dependents)","8cb1b374":"## Vizualizacija podataka i statisticka analiza - numericki feature-i ('Tenure', 'Monthly charges', 'Total Charges')","bed3310e":"**Random Forest Classifier**","71875dbd":"### SVM","683496a4":"### Random Forest ","37ea4ca7":"## Razvoj machine learning modela","f36fa75e":"**Procena uticaja feature-a**"}}