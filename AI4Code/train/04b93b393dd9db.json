{"cell_type":{"f0de7883":"code","5f5e8552":"code","eec0a354":"code","59fe22bb":"code","a1d84165":"code","6a9ebbc7":"code","1f5c639d":"code","801f8951":"code","5ff035a7":"code","f85c53d3":"code","72dd4b5c":"code","1babdfee":"code","4801d1be":"code","a9211723":"code","1883710e":"code","15b5689e":"code","3bed411d":"code","bfce65d2":"markdown","ea02e333":"markdown","e4da874c":"markdown","ca24a189":"markdown","699fa47b":"markdown","6dfd193e":"markdown","d65f6ec8":"markdown","0d32aa66":"markdown","81aaa9a4":"markdown","05890d43":"markdown","e6a114fa":"markdown"},"source":{"f0de7883":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nimport cv2\nimport json\nimport tensorflow as tf\nfrom tensorflow import keras\nimport albumentations as A\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f5e8552":"df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\ndf.shape","eec0a354":"df.head(5)","59fe22bb":"df.info()","a1d84165":"#https:\/\/www.kaggle.com\/khotijahs1\/image-preprocessing-for-cassava-leaf-disease\n\ndata_dir = '..\/input\/cassava-leaf-disease-classification\/'\nwith open(os.path.join(data_dir,'label_num_to_disease_map.json')) as file:\n    map_class = json.loads(file.read())\n\nprint(json.dumps(map_class,indent=5))","6a9ebbc7":"plt.figure(figsize=(10,5))\nsns.countplot(df['label'].values)\nplt.title('Distrbution of Labels in Training data')\nplt.show()","1f5c639d":"new_df = pd.read_csv(os.path.join(data_dir,\"train.csv\"))\nnew_df['class_names'] = df['label'].astype(str).map(map_class)\nnew_df.head(5)","801f8951":"def show_image(image_ids, labels):\n    plt.figure(figsize=(15,10))\n    \n    for i, (image_id,label) in enumerate(zip(image_ids, labels)):\n        plt.subplot(3,3,i+1)\n        img = cv2.imread(os.path.join(data_dir, \"train_images\", image_id))\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n\n        plt.imshow(img)\n        plt.title(f\"Class: {label}\", fontsize=12)\n        plt.axis(\"off\")\n    \n    plt.show()","5ff035a7":"samples = new_df.sample(9)\nimage_ids = samples['image_id'].values\nlabels = samples['class_names'].values\n\nshow_image(image_ids, labels)","f85c53d3":"#image sizes\nimages = cv2.imread('..\/input\/cassava-leaf-disease-classification\/train_images\/1000015157.jpg')\nimages.shape","72dd4b5c":"def read_image(image_id , label):\n    plt.figure(figsize=(15, 10))\n    image = cv2.imread(os.path.join(data_dir, \"train_images\", image_id))\n    #convert image to array\n    #img = image.img_to_array(img)\n    return image\n\ndef create_masks(image):\n    image_hsv = cv2.cvtColor(image, cv2.COLOR_BGR2HSV)\n    lower_hsv = np.array([0,0,250])\n    upper_hsv = np.array([250,255,255])\n    \n    mask = cv2.inRange(image_hsv, lower_hsv, upper_hsv)\n    kernel = cv2.getStructuringElement(cv2.MORPH_ELLIPSE, (11,11))\n    mask = cv2.morphologyEx(mask, cv2.MORPH_CLOSE, kernel)\n    return mask\n\ndef segment_image(image):\n    mask = create_masks(image)\n    output = cv2.bitwise_and(image, image, mask=mask)\n    return output\/255","1babdfee":"#get an image\nimage = read_image(df['image_id'][5],(255,255))\n\n#segmentation\nimage_segmented = segment_image(image)\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 5));\nplt.suptitle('RESULT', x=0.5, y=0.8)\nplt.tight_layout(1)\n\nax[0].set_title('ORIGINAL', fontsize=12)\nax[1].set_title('SEGMENTED', fontsize=12)\n\nax[0].imshow(image\/255);\nax[1].imshow(image_segmented);","4801d1be":"#get an image\nimage = read_image(df['image_id'][15],(255,255))\n\n#segmentation\nimage_segmented = segment_image(image)\n\nfig, ax = plt.subplots(1, 2, figsize=(15, 5));\nplt.suptitle('RESULT', x=0.5, y=0.8)\nplt.tight_layout(1)\n\nax[0].set_title('ORIGINAL', fontsize=12)\nax[1].set_title('SEGMENTED', fontsize=12)\n\nax[0].imshow(image\/255);\nax[1].imshow(image_segmented);","a9211723":"from sklearn.model_selection import train_test_split\n\ntrain_df, valid_df = train_test_split(df, test_size=0.2, random_state=45, stratify=df.label.values)\n\nprint(\"Training data size : {}\".format(train_df.shape))\nprint(\"Validation data size : {}\".format(valid_df.shape))","1883710e":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rescale=1.0\/255.0, validation_split=0.2)","15b5689e":"train_generator = datagen.flow_from_directory(directory= data_dir,             \n                                                     target_size=(224, 224),\n                                                     class_mode='categorical',\n                                                     subset='training',\n                                                    shuffle=True,\n                                                     batch_size=32\n                                 )\n\nvalid_generator = datagen.flow_from_directory(directory= data_dir,\n                                                      target_size=(224, 224),\n                                                      subset='validation',\n                                                     batch_size=32\n                                                    \n                                                     )","3bed411d":"#importing the neccessary libraries\n#https:\/\/github.com\/emla2805\/vision-transformer\/blob\/master\/model.py\nimport tensorflow_addons as tfa\nfrom tensorflow.keras.layers import (\n    Dense,\n    Dropout,\n    LayerNormalization,\n)\nfrom tensorflow.keras.layers.experimental.preprocessing import Rescaling\n\n","bfce65d2":"**So there is an imbalance in our dataset with majority of labels falling into Cassava Mosaic Disease (CMD) category**\n\n**Now, for better understanding lets put these labels into our training dataset**","ea02e333":"# Vision Transformers\n\n**While the Transformer architecture has become the de-facto standard for natural language processing tasks, its applications to computer vision remain limited. In vision, attention is either applied in conjunction with convolutional networks, or used to replace certain components of convolutional networks while keeping their overall structure in place. We show that this reliance on CNNs is not necessary and a pure transformer can perform very well on image classification tasks when applied directly to sequences of image patches. When pre-trained on large amounts of data and transferred to multiple recognition benchmarks (ImageNet, CIFAR-100, VTAB, etc), Vision Transformer attains excellent results compared to state-of-the-art convolutional networks while requiring substantially fewer computational resources to train.**\n\n![](attachment:image.png)","e4da874c":"# Introduction\n\n**I will be implementing a new Deep learning architecture called Vision Transformers using Tensorflow and implementing some basic Image Preprocessing steps to give an insight about how Image processing can be useful in identifying features of importance for Machine Learning and Deep Learning models**\n\n1. [An interesting implementation of Vision Transformer](http:\/\/www.kaggle.com\/abhinand05\/vision-transformer-vit-tutorial-baseline\/comments#Introduction)\n\n2. [Image processing- Simple guide](https:\/\/www.kaggle.com\/khotijahs1\/image-preprocessing-for-cassava-leaf-disease)\n\n**Big thanks to the implementations of [An Image is Worth 16x16 Words: Transformers for Image Recognition at Scale](https:\/\/arxiv.org\/abs\/2010.11929) for making the architecture possible** \n\n**And lastly I will be referring to these implementations so feel free to check them out if you can**\n\n1. [KamalKraj Implementation](https:\/\/github.com\/kamalkraj\/Vision-Transformer)","ca24a189":"# Displaying Images with Labels","699fa47b":"# Image Segmentation","6dfd193e":"# WORK IN PROGRESS\ud83d\udd28\ud83d\udd28","d65f6ec8":"# Loading the Datasets\n\n**The Casava-leaf Disease classification Dataset contains**\n\n1. **Images data**\n2. **CSV format data of train and submission files**\n3. **tfrecords of training and test data**\n4. **Json file with labels of diseases on images**","0d32aa66":"**So from this we can infer that the labels are labelled in categorical fashion with particular disease being identified through that, so let's explore the json file for more information**","81aaa9a4":"# **Image Augmentations**","05890d43":"**Let's visualize next set**","e6a114fa":"# Transformer Architecture\n\n![image.png](attachment:image.png)"}}