{"cell_type":{"80ce63ea":"code","2d758fed":"code","dfe3a8de":"code","8917eac3":"code","a8bd6449":"code","c004e2fa":"code","7352a79c":"code","58680583":"code","600534ae":"code","752fa7f3":"code","acbd9098":"code","483c4124":"markdown","fad7c360":"markdown","7af1a057":"markdown","9ec39d44":"markdown"},"source":{"80ce63ea":"import math, re, os\nimport tensorflow as tf # deep learning\nimport pandas as pd\nimport numpy as np # linear algebra\nfrom matplotlib import pyplot as plt\nfrom kaggle_datasets import KaggleDatasets\nfrom sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nprint(\"Tensorflow version \", tf.__version__)\nAUTO = tf.data.experimental.AUTOTUNE","2d758fed":"try:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Running on TPU ', tpu.master())\nexcept ValueError:\n    tpu = None\n\nif tpu:\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nelse:\n    print('No TPU detected, look to your right under the \"Accelerator\" tab and switch to \"TPU v3-8\"')\nprint('REPLICAS: ', strategy.num_replicas_in_sync)","dfe3a8de":"# Get the Google Cloud mirror path for this Kaggle dataset\nGCS_DS_PATH = KaggleDatasets().get_gcs_path()\n!gsutil ls $GCS_DS_PATH","8917eac3":"CLASS_NAMES = pd.read_csv(GCS_DS_PATH+'\/labels.csv')\ntrain_labels = pd.read_csv('\/kaggle\/input\/imet-2020-fgvc7\/train.csv')\nids = train_labels.pop('id')\nattributes = train_labels.pop('attribute_ids')\ntrain_df = tf.data.Dataset.from_tensor_slices((ids,attributes))\n\n# Display tensor values\nfor index, tensor in train_df.enumerate().as_numpy_iterator():\n    if index > 5:\n        break\n    print('Image file path:', tensor[0], '  Labels:', tensor[1])","a8bd6449":"def decode_jpeg(filename, label):\n    bits = tf.io.read_file(GCS_DS_PATH+'\/train\/'+filename+'.png')\n    image = tf.image.decode_jpeg(bits)\n    image = tf.image.resize_with_crop_or_pad(image,300,300)\n    if tf.shape(image)[2] == 1:\n        image = tf.image.grayscale_to_rgb(image)\n    return image, label\nimage_ds = train_df.map(decode_jpeg)\n\n# Display images and labels\nfor index, tensor in image_ds.enumerate().as_numpy_iterator():\n    if index > 5:\n        break\n    print('Image Shape:',tensor[0].shape, '   Labels:', tensor[1])\n#     if index == 3:\n#         print('Image Data Example: ',tensor[0])","c004e2fa":"# TPU_CORES = strategy.num_replicas_in_sync\n# IMAGE_SIZE = [512,512]\n# EPOCHS = 12\nBATCH_SIZE = 16\ndef prepare_for_training(ds, cache=True, shuffle_buffer_size=1000):\n  # This is a small dataset, only load it once, and keep it in memory.\n  # use `.cache(filename)` to cache preprocessing work for datasets that don't\n  # fit in memory.\n  if cache:\n    if isinstance(cache, str):\n      ds = ds.cache(cache)\n    else:\n      ds = ds.cache()\n\n  ds = ds.shuffle(buffer_size=shuffle_buffer_size)\n\n  # Repeat forever\n  ds = ds.repeat()\n\n  ds = ds.batch(BATCH_SIZE)\n\n  # `prefetch` lets the dataset fetch batches in the background while the model\n  # is training.\n  ds = ds.prefetch(buffer_size=AUTO)\n\n  return ds\ntrain_ds = prepare_for_training(image_ds)\n","7352a79c":"# TAKES VERY LONG TIME TO RUN, 10+ minutes\n# image_batch, label_batch = next(iter(train_ds))","58680583":"def get_Title(labels,index):\n    title = ''\n    tag_array = labels[index].split()\n    for index, tag in enumerate(tag_array):\n        tag_array[index] = CLASS_NAMES.iloc[int(tag)].attribute_name\n    return ' '.join(tag_array)","600534ae":"def show_batch(image_batch, label_batch):\n  plt.figure(figsize=(10,10))\n  for n in range(16):\n      ax = plt.subplot(5,5,n+1)\n      plt.imshow(image_batch[n])\n      plt.title(get_Title(label_batch,n))\n      plt.axis('off')\nshow_batch(image_batch.numpy(), label_batch.numpy())","752fa7f3":"MobileNetV2 = tf.keras.applications.MobileNetV2(input_shape=[300,300,3], include_top=False)\nMobileNetV2.trainable = False\n\nmodel = tf.keras.Sequential([\n    MobileNetV2,\n    tf.keras.layers.Conv2D(kernel_size=3, filters=24, padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.Conv2D(kernel_size=3, filters=24, padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    tf.keras.layers.Conv2D(kernel_size=3, filters=12, padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.MaxPooling2D(pool_size=2),\n    tf.keras.layers.Conv2D(kernel_size=3, filters=6, padding=\"same\", activation=\"relu\"),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(5, activation=\"softmax\")\n])\n\nmodel.compile(\n    optimizer=\"adam\",\n    loss=\"categorical_crossentropy\",\n    metrics=[\"accuracy\"]\n)","acbd9098":"model.fit(image_batch,label_batch,batch_size=16,epochs=1)","483c4124":"### Create *image_dataset* using train.csv converted into a Tensorflow Dataset with (image,label)","fad7c360":"### TPU Detection","7af1a057":"### Create Multilabel Classification Model","9ec39d44":"### Normalize Image Data\n\nAs we can see, our images are not all the same size, so we need to normalize them."}}