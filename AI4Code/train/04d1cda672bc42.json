{"cell_type":{"49add556":"code","8ecc29a8":"code","bf7ed9b3":"code","7d49e931":"code","34c0141a":"code","3f3d785a":"code","b7b45611":"code","2b9b9810":"code","ae6cee83":"code","87b9aa6b":"markdown","5a36ceab":"markdown","2adc5cd5":"markdown","9ced97ea":"markdown","ebbe9449":"markdown","7ddc5255":"markdown","ef9306c8":"markdown","ff6b0c05":"markdown","d12331ff":"markdown","4c00ea9d":"markdown","d110a47d":"markdown","2c32ee38":"markdown"},"source":{"49add556":"import matplotlib.pyplot as plt\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport io","8ecc29a8":"train = pd.read_csv(\"..\/input\/train.csv\")\ntrain.head()","bf7ed9b3":"#print((train['target'] == 1).sum())\n#print((train['target'] == 0).sum())\n\nx = np.arange(2)\nvalues = [(train['target'] == 0).sum(), (train['target'] == 1).sum()]\nfig, ax = plt.subplots()\nplt.bar(x, values)\nplt.xticks(x, ('0', '1'))\nplt.title('target column in train.csv')\nplt.show()","7d49e931":"pd.set_option('display.max_colwidth', -1)\ntrain[train['target'] == 1].sample(10)","34c0141a":"pd.set_option('display.max_colwidth', -1)\ntrain[train['target'] == 0].sample(10)","3f3d785a":"from gensim.models.keyedvectors import KeyedVectors  #import this to read binary file, isn't it against rule \"No custom packages\" ?\n\ndef loadGoogleModel(pathToFile):\n    googleModel = KeyedVectors.load_word2vec_format(pathToFile, binary=True)\n    return googleModel\n\npathToGoogleFile = \"..\/input\/embeddings\/GoogleNews-vectors-negative300\/GoogleNews-vectors-negative300.bin\"\n\n# googleModel = loadGoogleModel(pathToGoogleFile)\n# result = googleModel.most_similar(positive=['dog'], topn=5) #you can also put the negative words ex. negative=['cat'], topn - number of top examples in return\n# print(result)\n","b7b45611":"def loadGloveModel(pathToFile):\n    print(\"Loading Glove Model\")\n    f = open(pathToFile,'r')\n    model = {}\n    for line in f:\n        splitLine = line.split(' ')\n        word = splitLine[0]\n        embedding = np.array([float(val) for val in splitLine[1:]])\n        model[word] = embedding\n    print(\"Done, words loaded!\")\n    return model\n\npathToGloveFile = \"..\/input\/embeddings\/glove.840B.300d\/glove.840B.300d.txt\"\n\n# gloveModel = loadGloveModel(pathToGloveFile)\n# print(gloveModel['frog'])","2b9b9810":"def loadParagramModel(pathToFile):\n    print(\"Loading Paragram Model\")\n    f = open(pathToFile,'r')\n    model = {}\n    for line in f:\n        splitLine = line.split(' ')\n        word = splitLine[0]\n        embedding = np.array([float(val) for val in splitLine[1:]])\n        model[word] = embedding\n    print(\"Done, words loaded!\")\n    return model\n\npathToParagramFile = \"..\/input\/embeddings\/glove.840B.300d\/glove.840B.300d.txt\"\n\n# paragramModel = loadParagramModel(pathToParagramFile)\n# print(paragramModel['frog'])","ae6cee83":"def loadWikiModel(pathToFile):\n    print(\"Loading Wiki Model\")\n    f = open(pathToFile,'r')\n    model = {}\n    for line in f:\n        splitLine = line.split(' ')\n        word = splitLine[0]\n        embedding = np.array([float(val) for val in splitLine[1:]])\n        model[word] = embedding\n    print(\"Done, words loaded!\")\n    return model\n\npathToWikiFile = \"..\/input\/embeddings\/wiki-news-300d-1M\/wiki-news-300d-1M.vec\"\n\n# wikiModel = loadWikiModel(pathToWikiFile)  \n# print(wikiModel['frog'])\n","87b9aa6b":"And sample properly formed questions:","5a36ceab":" *GloVe: Global Vectors for Word Representation*\n\nUsage:","2adc5cd5":"**4. Embeddings**\n\nTo start working with the data you can use this functions to read files:","9ced97ea":"**1. Train **\n\n*train.csv*","ebbe9449":"*Paragram embeddings*\n\npretrained model from Cognitive Computation Group, Univeristy Pensylvania \n\nUsage:","7ddc5255":"\n*GoogleNews-vectors-negative300*\n\nUsage:","ef9306c8":"*English word vectors: wiki-news*\n\nUsage:","ff6b0c05":"Let's see sample questions that attack the rules and are marked as 1:","d12331ff":"**Competition rules in the nutshell:**\n\n* This competition does not allow external data.\n* Be aware that this is being run as a Kernels Only Competition, requiring that all submissions be made via a Kernel output.\n* Both your training and prediction should fit in a single Kernel. \n* GPUs are enabled for this competition. If you use GPUs, you will be limited to 2 hours of run time. If you do not use GPUs, you will be limited to 6 hours of run time. \n* No internet access enabled\n* No multiple data sources enabled\n* No custom packages\n* Submission file must be named \"submission.csv\"","4c00ea9d":"**Competition goal**\n> In this competition you will be predicting whether a question asked on Quora is sincere or not.\n","d110a47d":"**I will probably proceed to develop this kernel soon. Good luck!** ","2c32ee38":"**Data that you can use:**\n\n1. train.csv \n2. test.csv\n3. sample_submission.csv\n4. embeddings:\n    *  google\n    *  glove\n    *  paragram\n    * wiki"}}