{"cell_type":{"5c22f0e3":"code","886c0295":"code","8f102c32":"code","0fdbf429":"code","27723ce1":"code","43874d34":"code","20294262":"code","045cdb0a":"code","6517e265":"code","0fb3becc":"code","cc97cec9":"code","244019a1":"code","5246ac79":"code","416f513f":"code","83fff468":"code","bae959a7":"code","a98e958b":"code","3bcff48d":"code","189e25fc":"code","5ddb6d0f":"code","80e55a96":"code","efec296b":"code","6852dbf9":"code","ba5ae5f9":"code","6ed52fff":"code","c1af3238":"code","e43c25a5":"code","923812b5":"code","5a952000":"code","a4de8147":"code","417dcbc7":"code","257e52e2":"code","d286bdac":"code","81698d86":"code","31d7dbe3":"code","08d38d05":"code","a5a588ed":"code","ef5ed301":"code","c240bdfb":"code","b6040a8d":"code","366afd2f":"code","131013d1":"code","204ec9f9":"code","348589a3":"code","69be4e9d":"code","db6e896c":"code","eeaed1a7":"code","85ef53c2":"code","0a67e83c":"code","c6bf4e1f":"markdown","46625bdb":"markdown","1ccb1a3a":"markdown","72c4c7f0":"markdown","78dcc72e":"markdown","f9a0ac76":"markdown","3dab8a57":"markdown","1ada02b1":"markdown","0bd782ff":"markdown","8531d7e0":"markdown","742b39c3":"markdown","c7188930":"markdown","e30f7945":"markdown","c8dbe5de":"markdown","1c721ada":"markdown","10ae9cac":"markdown","5903bb37":"markdown","24f3981e":"markdown","815004c0":"markdown","ecf817fb":"markdown","4e6f5e6b":"markdown","f6430b59":"markdown","3d3566e1":"markdown","f346ac89":"markdown","13df505e":"markdown","0361d264":"markdown","03021487":"markdown","9be77e40":"markdown","b3dcae3a":"markdown","f2853201":"markdown","62bd8ca3":"markdown","9929e6d5":"markdown","a35b162a":"markdown","e90b6098":"markdown","e65db393":"markdown","92366cf5":"markdown","4641f850":"markdown","7628e0ac":"markdown","8dc997a7":"markdown","b2326318":"markdown","e963cb7a":"markdown","02b55c3a":"markdown","c74ef9f5":"markdown","aeb00e43":"markdown","fbe3ab38":"markdown","8efa9c69":"markdown"},"source":{"5c22f0e3":"import warnings\nwarnings.filterwarnings(\"ignore\", category=DeprecationWarning) ","886c0295":"#!git clone https:\/\/github.com\/asvcode\/fmi.git","8f102c32":"!cp -r ..\/input\/fmipackage\/fmi-master\/* .\/","0fdbf429":"from fmi.explore import *\nfrom fmi.preprocessing import *\nfrom fmi.pipeline import *","27723ce1":"!pip install '..\/input\/timm034\/timm-0.3.4-py3-none-any.whl' -qq","43874d34":"from fastai.vision.all import *\nfrom fastai.medical.imaging import *\nimport pydicom\nfrom torchvision.utils import save_image\nfrom glob import glob\nfrom skimage import exposure\nfrom pydicom.pixel_data_handlers.util import apply_voi_lut\n\nfrom timm import create_model\nfrom fastai.vision.learner import _update_first_layer\nmatplotlib.rcParams['image.cmap'] = 'gist_ncar'","20294262":"system_info()","045cdb0a":"source = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification'\ntrain_files = get_dicom_files(f'{source}\/train\/00000')\ntrain_path = f'{source}\/train'\nlabels = pd.read_csv(f'{source}\/train_labels.csv', header=0, names=['id','value'], dtype=object)\nprint(os.listdir(source))","6517e265":"labels[:5]","0fb3becc":"get_image_info(train_files[7])","cc97cec9":"get_pii(train_files[7])","244019a1":"source_00000 = f'{source}\/train\/00000\/'\nprint(os.listdir(source_00000))","5246ac79":"sort_items = get_dicom_files(source_00000, folders='T2w')","416f513f":"imgs = []\nfor filename in sort_items:\n    file = filename.dcmread().pixel_array\n    img = TensorDicom(file)\n    imgs.append(img)\nshow_images(imgs, nrows=12)","83fff468":"instance_show(sort_items, nrows=20)","bae959a7":"FLAIR_00000 = f'{source_00000}\/FLAIR'\nshow_aspects(FLAIR_00000, show=True, save=False, figsize=(17,12))","a98e958b":"flair_00000_files = get_dicom_files(FLAIR_00000)","3bcff48d":"dicom_dataframe = pd.DataFrame.from_dicoms(flair_00000_files, window=dicom_windows.brain, px_summ=True)\ndicom_dataframe[:10]","189e25fc":"def get_dicom_image(df, key, nrows=1, source=None, folder_val=None, instance_val=None, figsize=(7,7)):\n    \"Helper to view images by key\"\n    imgs=[]\n    title=[]\n    for i in df.index:\n        file_path = Path(f\"{df.iloc[i]['fname']}\")\n        dcc = file_path.dcmread().pixel_array\n        imgs.append(dcc)\n        pct = df.iloc[i][key]\n        title.append(pct)\n    return show_images(imgs, titles=title, nrows=nrows)","5ddb6d0f":"pct = dicom_dataframe[['PatientID', 'InstanceNumber', 'img_pct_window', 'img_mean', 'img_std', 'fname']].sort_values(by=['img_pct_window'], ascending=False).reset_index(drop=True)\nget_dicom_image(pct[:10], 'img_pct_window', source=source, nrows=1, figsize=(20,20))","80e55a96":"pct = dicom_dataframe[['PatientID', 'InstanceNumber', 'img_pct_window', 'img_mean', 'img_std', 'fname']].sort_values(by=['img_mean'], ascending=False).reset_index(drop=True)\nget_dicom_image(pct[:10], 'img_mean', source=source, nrows=1, figsize=(20,20))","efec296b":"pct = dicom_dataframe[['PatientID', 'InstanceNumber', 'img_pct_window', 'img_mean', 'img_std', 'fname']].sort_values(by=['img_std'], ascending=False).reset_index(drop=True)\nget_dicom_image(pct[:10], 'img_std', source=source, nrows=1, figsize=(20,20))","6852dbf9":"matplotlib.rcParams['image.cmap'] = 'bone'","ba5ae5f9":"outpath = '.\/test1.png'\nwindow = dicom_windows.brain_soft\nsigma = 0.1\nthresh = 0.7\nremove_max = False","6ed52fff":"def get_outpath(input_dir, dataset):\n    img_id = input_dir.split('-')[-1].split('.')[0]\n    outpath = os.path.join(f'.\/{dataset}',f'{img_id}.png')\n    \n    check = os.path.isfile(outpath)\n    if check is not True:\n        process_dicom(input_dir, outpath, window=dicom_windows.brain_soft, sigma=0.1, thresh=0.7, remove_max=False, show=True, sanity=True)\n    else:\n        i = 0\n        while True:\n            outpath = os.path.join(f'.\/{dataset}',f'{img_id}_{i}.png')\n            if not os.path.exists(outpath):\n                process_dicom(input_dir, outpath, window=dicom_windows.brain_soft, sigma=0.1, thresh=0.7, remove_max=False, show=True, sanity=True)\n                break\n            i += 1    \n    return outpath","c1af3238":"if not os.path.exists('.\/train'):\n    os.makedirs('.\/train')","e43c25a5":"fpath = []\nfor file in labels['id'][:5]:\n    path = f'{train_path}\/{file}\/T1wCE\/'\n    files = get_dicom_files(path)\n    dicom_dataframe = pd.DataFrame.from_dicoms(files, window=dicom_windows.brain_soft, px_summ=True)\n    pct = dicom_dataframe[['PatientID', 'InstanceNumber', 'img_pct_window', 'img_mean', 'img_std', 'fname']].sort_values(by=['img_pct_window'], ascending=True).reset_index(drop=True)\n    ff = pct['fname'][0]\n    outfile = get_outpath(ff, 'train')\n    fpath.append(outfile)","923812b5":"labels5 = labels[:5]\nlabels5['path'] = pd.Series(fpath).values\nlabels5","5a952000":"flair_source = '..\/input\/rsna-miccai'\nt1w_source = '..\/input\/t1w-one'\nt1wce_source = '..\/input\/t1wce-one'\nt2w_source = '..\/input\/t2w-one'\ndf = pd.read_csv(f'{source}\/train_labels.csv')\ndf_rs = pd.read_csv(f'{flair_source}\/train_Fcrop_one.csv')\ndf_t1w = pd.read_csv(f'{t1w_source}\/T1w_brain_soft.csv')\ndf_1wce = pd.read_csv(f'{t1wce_source}\/T1wCE_brain_soft.csv')\ndf_t2w = pd.read_csv(f'{t2w_source}\/T2w_brain_soft.csv')","a4de8147":"def get_one(f):\n    one = f.split('\/')[-1]\n    return one","417dcbc7":"df_rs['path'] = df_rs['path'].apply(lambda x: f'..\/input\/rsna-miccai\/train_crop_FLAIR\/{get_one(x)}')\ndf_t1w['path'] = df_t1w['path'].apply(lambda x: f'..\/input\/t1w-one\/train\/{get_one(x)}')\ndf_1wce['path'] = df_1wce['path'].apply(lambda x: f'..\/input\/t1wce-one\/train\/{get_one(x)}')\ndf_t2w['path'] = df_t2w['path'].apply(lambda x: f'..\/input\/t2w-one\/train\/{get_one(x)}')","257e52e2":"df_rs['t1w_path']= df_t1w['path']\ndf_rs['t1wce_path'] = df_1wce['path']\ndf_rs['t2w_path'] = df_t2w['path']\ndf_rs","d286bdac":"batch_tfms = [Resize(224), *aug_transforms(do_flip=False, \n                                           flip_vert=False, \n                                           max_rotate=27,  \n                                           min_zoom=1.,\n                                           max_zoom=1.,\n                                           max_lighting=0.1), Normalize.from_stats(*imagenet_stats)]","81698d86":"blocks = (\n          ImageBlock(cls=PILImage),\n          ImageBlock(cls=PILImage),\n          ImageBlock(cls=PILImage),\n          ImageBlock(cls=PILImage),\n          CategoryBlock)\n\ngetters = [\n           ColReader('path'),\n           ColReader('t1w_path'),\n           ColReader('t1wce_path'),\n           ColReader('t2w_path'),\n           ColReader('value'),\n          ]\n\nmiccai = DataBlock(blocks=blocks,\n              getters=getters,\n              item_tfms=Resize(196),\n              n_inp=4\n              )\n\ndls = miccai.dataloaders(df_rs, bs=16)","31d7dbe3":"class MiccaiModel(Module):\n    def __init__(self, encoder, head):\n        self.encoder, self.head = encoder, head\n\n    def forward(self, x1, x2, x3, x4):\n        ftrs = torch.cat([self.encoder(x1), self.encoder(x2), self.encoder(x3), self.encoder(x4)], dim=1)\n        return self.head(ftrs)","08d38d05":"def miccai_splitter(model):\n    return [params(model.encoder), params(model.head)]","a5a588ed":"def create_timm_body(arch:str, pretrained=True, cut=None, n_in=3):\n    \"Creates a body from any model in the `timm` library.\"\n    model = create_model(arch, pretrained=pretrained, num_classes=0, global_pool='')\n    _update_first_layer(model, n_in, pretrained)\n    if cut is None:\n        ll = list(enumerate(model.children()))\n        cut = next(i for i,o in reversed(ll) if has_pool_type(o))\n    if isinstance(cut, int): return nn.Sequential(*list(model.children())[:cut])\n    elif callable(cut): return cut(model)\n    else: raise NamedError(\"cut must be either integer or function\")\n        \ndef create_timm_model(arch:str, n_out, cut=None, pretrained=True, n_in=3, init=nn.init.kaiming_normal_, custom_head=None,\n                     concat_pool=True, **kwargs):\n    \"Create custom architecture using `arch`, `n_in` and `n_out` from the `timm` library\"\n    body = create_timm_body(arch, pretrained, None, n_in)\n    if custom_head is None:\n        nf = num_features_model(nn.Sequential(*body.children()))\n        head = create_head(nf, n_out, concat_pool=concat_pool, **kwargs)\n    else: head = custom_head\n    model = nn.Sequential(body, head)\n    if init is not None: apply_init(model[1], init)\n    return model\n\ndef timm_learner(dls, arch:str, loss_func=None, pretrained=True, cut=None, splitter=None,\n                y_range=None, config=None, n_out=None, normalize=True, **kwargs):\n    \"Build a convnet style learner from `dls` and `arch` using the `timm` library\"\n    if config is None: config = {}\n    if n_out is None: n_out = get_c(dls)\n    assert n_out, \"`n_out` is not defined, and could not be inferred from data, set `dls.c` or pass `n_out`\"\n    if y_range is None and 'y_range' in config: y_range = config.pop('y_range')\n    model = create_timm_model(arch, n_out, default_split, pretrained, y_range=y_range, **config)\n    learn = Learner(dls, model, loss_func=loss_func, splitter=default_split, **kwargs)\n    if pretrained: learn.freeze()\n    return learn","ef5ed301":"os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n\n!cp '..\/input\/rsna-miccai\/ig_resnext101_32x16-c6f796b0.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/ig_resnext101_32x16-c6f796b0.pth'\n#!cp '..\/input\/rsna-miccai\/semi_supervised_resnext101_32x16-15fffa57.pth' '\/root\/.cache\/hub\/checkpoints\/semi_supervised_resnext101_32x16-15fffa57.pth'","c240bdfb":"body = create_timm_body('ig_resnext101_32x16d', pretrained=True)\nhead = create_head(2048*4, 2, ps=0.5)\nmodel = MiccaiModel(body, head)","b6040a8d":"learn = Learner(dls,\n                model,\n                loss_func = LabelSmoothingCrossEntropy(),\n                metrics = accuracy,\n                cbs=[ShowGraphCallback(),\\\n                    SaveModelCallback(monitor='accuracy',fname='best_accuracy',comp=np.greater, with_opt=True)])\n\nlearn.to_fp16()","366afd2f":"learn.fit_one_cycle(27, 1e-3)","131013d1":"learn.load('best_accuracy')","204ec9f9":"test_set = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test'\n\nif not os.path.exists('.\/test'):\n    os.makedirs('.\/test')","348589a3":"df_test = pd.DataFrame(columns=['id', 'value'])\ndf_test.id = os.listdir(\"..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/test\/\")\ndf_test[:5]","69be4e9d":"def get_png(t):\n    f = t.split('\/')\n    folderp = f'test\/{f[-3]}\/{f[-2]}'\n    filep = f'{folderp}\/{f[-1]}'\n    fff = filep.split('.')[0]\n    outpath = f'{fff}.png'\n    \n    dicom = pydicom.read_file(t)\n    data = apply_voi_lut(dicom.pixel_array, dicom)\n    if dicom.PhotometricInterpretation == \"MONOCHROME1\":\n        data = np.amax(data) - data\n    data = data - np.min(data)\n    data = data \/ np.max(data)\n    data = (data * 255).astype(np.uint8)\n    height = len(data)\n    width = len(data[0])\n    \n    pixels_out = []\n    for row in data:\n        pixels_out.extend(row)\n    assert(len(pixels_out) == height * width)\n    image_out = Image.new('L', (width, height))\n    image_out.putdata(pixels_out)\n\n    if not os.path.exists(folderp):\n        os.makedirs(folderp)\n    image_out.save(outpath)\n    \n    return outpath, image_out","db6e896c":"probs_one = []\nfor file in df_test['id']:\n    ## fLAIR\n    path = f'{test_set}\/{file}\/FLAIR\/'\n    g = get_dicom_files(path)\n    dicom_dataframe = pd.DataFrame.from_dicoms(g, window=dicom_windows.brain_soft, px_summ=True)\n    pct = dicom_dataframe[['PatientID', 'InstanceNumber', 'img_pct_window', 'img_mean', 'img_std', 'fname']].sort_values(by=['img_pct_window'], ascending=True).reset_index(drop=True)\n    ff = pct['fname'][0]\n    png_file, image1 = get_png(ff)\n    print(png_file)\n    \n    #T1W\n    tpath = f'{test_set}\/{file}\/T1w\/'\n    t = get_dicom_files(tpath)\n    dicom_dataframe2 = pd.DataFrame.from_dicoms(t, window=dicom_windows.brain_soft, px_summ=True)\n    pct2 = dicom_dataframe2[['PatientID', 'InstanceNumber', 'img_pct_window', 'img_mean', 'img_std', 'fname']].sort_values(by=['img_pct_window'], ascending=True).reset_index(drop=True)\n    fff = pct2['fname'][0]\n    png_file2, image2 = get_png(fff)\n    print(png_file2)\n    \n    #T1WCE\n    wpath = f'{test_set}\/{file}\/T1wCE\/'\n    w = get_dicom_files(wpath)\n    dicom_dataframe3 = pd.DataFrame.from_dicoms(w, window=dicom_windows.brain_soft, px_summ=True)\n    pct3 = dicom_dataframe3[['PatientID', 'InstanceNumber', 'img_pct_window', 'img_mean', 'img_std', 'fname']].sort_values(by=['img_pct_window'], ascending=True).reset_index(drop=True)\n    ffff = pct3['fname'][0]\n    png_file3, image3 = get_png(ffff)\n    print(png_file3)\n    \n    #T2W\n    rpath = f'{test_set}\/{file}\/T2w\/'\n    q = get_dicom_files(rpath)\n    dicom_dataframe4 = pd.DataFrame.from_dicoms(q, window=dicom_windows.brain_soft, px_summ=True)\n    pct4 = dicom_dataframe4[['PatientID', 'InstanceNumber', 'img_pct_window', 'img_mean', 'img_std', 'fname']].sort_values(by=['img_pct_window'], ascending=True).reset_index(drop=True)\n    fff3 = pct4['fname'][0]\n    png_file4, image4 = get_png(fff3)\n    print(png_file4)\n    \n    test_dl = learn.dls.test_dl([png_file, png_file2, png_file3, png_file4])\n    preds, probs2 = learn.tta(dl=test_dl, n=1)\n    print(preds, probs2)\n    show_images([image1, image2, image3, image4], titles=preds)\n    \n    value_0 = []\n    value_1 = []\n    for p in preds:\n        value_0.append(p[0].item())\n        value_1.append(p[1].item())\n    val0_final = sum(value_0)\/4\n    val1_final = sum(value_1)\/4\n    fin = [val0_final, val1_final]\n    print(max(fin))\n    probs_one.append(max(fin))","eeaed1a7":"df_test['value'] = pd.Series(probs_one).values","85ef53c2":"df_test.rename(columns={'id':'BraTS21ID','value':'MGMT_value'}, inplace=True)\ndf_test","0a67e83c":"df_test.to_csv('submission.csv', index=False)","c6bf4e1f":"Save the filepaths","46625bdb":"In order to iterate quickly and get some baseline results the aim is to get the best images from each folder.  In order to do this:\n - we will extract the dicom metadata from each sub folder\n - sort the metadata based on dicom window width and center\n - Create a mask based on the dicom window width and center and get rid of unwanted pixels\n - Save the image that best matches our criteria by converting it into PNG format\n - Create a dataframe with columns that contain the `path` to that image (we will need this when constructing the `DataBlock`)\n\nNote that the `cmap` color used above is purely for aesthetics reasons and actually does not have any impact from a training perspective.  However moving forward we change it to a more appropriate color map","1ccb1a3a":"## Load Dependancies","72c4c7f0":"## Explore Data","78dcc72e":"Specify the splitter","f9a0ac76":"Correct the path names for each image","3dab8a57":"In order to be able to use `timm` models the following is credited from [here](https:\/\/github.com\/muellerzr\/Practical-Deep-Learning-for-Coders-2.0\/blob\/master\/Computer%20Vision\/05_EfficientNet_and_Custom_Weights.ipynb)","1ada02b1":"Because we have 4 inputs we will have to alter the model so that it can accommodate the inputs (this is adapted from [here](https:\/\/docs.fast.ai\/tutorial.siamese.html))","0bd782ff":"Create the `datablock`, one for each type of scan","8531d7e0":"Load the data","742b39c3":"### Basic EDA","c7188930":"Specify the blocks, note that `n_inp` is set to 4 because there will be 4 inputs","e30f7945":"Although this displays the images within the folder they are not displayed in sequence. [fmi](https:\/\/github.com\/asvcode\/fmi) provides a handy function that easily sorts the images by `instance number`","c8dbe5de":"**Fluid Attenuated Inversion Recovery (FLAIR)**","1c721ada":"### Extract best image from each of the structural multi-parametric MRI (mpMRI) scans","10ae9cac":"You could view the images within the `T2w` folder like this:","5903bb37":"`show_aspects` is a handy function that easily lets you view the various planes.","24f3981e":"Have a test run with the first 5 independant cases and using the `T1wCE` folder, we create a dicom dataframe using a `brain_soft` dicom window for each case in the `T1wCE` folder, sort it by `img_pct_window` (img_pct_window is a handy `fastai` function that displays the percentage of pixels within a specified dicom window in an image), and then use `process_dicom` to save the image.","815004c0":"Merge all into  one dataframe","ecf817fb":"Function to extract the file name","4e6f5e6b":"Check to see if there is any personally identifiable data in the metadata","f6430b59":"Each dedicated folder is identified by a five-digit number which is further broken down into 4 subfolders:\n\n- Fluid Attenuated Inversion Recovery (FLAIR)\n- T1-weighted pre-contrast (T1w)\n- T1-weighted post-contrast (T1Gd)\n- T2-weighted (T2)\n\nUsing folder `00000` as an example","3d3566e1":"## Training","f346ac89":"`process_dicom` is a handy `fmi` function that crops a dicom image (dependant on dicom window, sigma and thresh values) and saves it in .png format. You have to specify the outpath (where the .png files will be stored), the window width and center, sigma and thresh values.  By default displaying the differences in the images and sanity check is set to `False`","13df505e":"This is how I created the datasets for each of the structural multi_parametric scans.  To generate the correct paths to save the images I used the code below, which also solves for duplicate file names across the independant cases","0361d264":"`get_dicom_image` is another handy feature that lets you view images within a dataframe and sort them by various items such as `img_pct_window`, `img_mean` or `img_std`.\n\nWe will use this later in extracting the best images from each of the folders.","03021487":"[fmi](https:\/\/github.com\/asvcode\/fmi) has a number of handy features that breakdown the metadata into useful chunks. Firstly you may want to quickly see what image information is contained in the metadata. You can access this using get_image_info","9be77e40":"Load the model with the best accuracy","b3dcae3a":"## Submission","f2853201":"You can also easily extract the metadata from the dicom images using `from_dicoms`","62bd8ca3":"### Contents\n\n![m2.PNG](attachment:0eb0a576-31cb-4283-a12e-4e3cdebab833.PNG)\n\n- Load dependancies - .. Done!\n- Explore Data - .. Done!\n    - Basic EDA\n    - Extract best image from each of the structural multi-parametric MRI (mpMRI) scans\n    - Convert that image to PNG and use for training\n- DataBlock - .. Done!\n- Training - .. Done!\n- Submission - .. Done!\n\n\n### Model\n\nExtract the best image based on dicom window width and center from each of the structural multi_parametric MRI scans, save that image into PNG and use a pretrained [timm](https:\/\/github.com\/rwightman\/pytorch-image-models\/tree\/master\/timm) model `ig_resnext101_32x16d`.  Inference involves extracting the best image (again based on dicom window width and center) and averaging the prediction across all structural multi_parametric scans.\n\n![model.PNG](attachment:ca1845a2-4d35-4073-8753-53c5735ca74d.PNG)","9929e6d5":"Since internet is off in this case you can use the [fmipackage](https:\/\/www.kaggle.com\/avirdee\/fmipackage) dataset","a35b162a":"For the `test` set we will be doing the same as we did for the `train` set ie grab the best images within each test case folder and across each structural multi_parametric scan and save the file in .png format for inference.","e90b6098":"This notebook uses various functions from the [fmi](https:\/\/github.com\/asvcode\/fmi) library which is a package that adds additional functionality to [fastai's](https:\/\/www.fast.ai\/) medical imaging module. \n\nTo learn more about medical imaging view my [blog](https:\/\/asvcode.github.io\/MedicalImaging\/)\n\n\nThe `fmi` library can be easily cloned (**with internet ON**):","e65db393":"## DataBlock","92366cf5":"**sort by `img_pct_window`**","4641f850":"You can easily review your system info using system_info","7628e0ac":"**sort by `img_std`**","8dc997a7":"We also have to save the image names and file paths so that we can use it in training later","b2326318":"MRI scans are made up of numerous 2D slices taken from a number of angles(or planes). The 3 planes are axial, sagittal and cornonal and the image below show what angels the planes represent. [Image credit](https:\/\/www.ipfradiologyrounds.com\/hrct-primer\/image-reconstruction\/)\n\n![aspects.PNG](attachment:fff21408-9c33-4dc4-9278-b8ce00d5e764.PNG)","e963cb7a":"Get the probabilities","02b55c3a":"We now have the dataframe we can use in consturcting the `DataBlock`\n\nSpecify some transforms","c74ef9f5":"create the folder where you will saving the files","aeb00e43":"**sort by `img_mean`**","fbe3ab38":"There does not seem to be any personally identifiable data.","8efa9c69":"Load `timm`"}}