{"cell_type":{"657bfb74":"code","3d0eb36a":"code","4f5c434d":"code","54f3fb9a":"code","e5d47318":"code","fb64be9a":"code","cb9a98fc":"code","15ad1c7b":"code","88608e81":"code","55ef5d64":"code","ec6d40f9":"code","dfbcfb89":"code","e345cdc8":"code","c46862fb":"code","a303d38c":"code","766b8b0c":"code","985e0317":"code","32b46140":"code","69304a03":"code","d4d34759":"code","69156447":"code","862e9aa5":"code","d7b20ecf":"code","de899a91":"code","2f9a417a":"code","fcaa2d1a":"code","97679c83":"code","60ada83c":"markdown","5fc94654":"markdown","8fb843c7":"markdown","81b717c9":"markdown","59d2e425":"markdown","efc6e4e9":"markdown","0b3eb248":"markdown","4a4d111f":"markdown","b9ed57d8":"markdown","6fc832b7":"markdown","35324664":"markdown","6df7b2ee":"markdown","6a0a77ce":"markdown","20c73b11":"markdown","a5916e0a":"markdown","df4ae79e":"markdown","61f27450":"markdown","59cf31b8":"markdown","e83a231f":"markdown","404e4e26":"markdown","7a4305f6":"markdown","92645e5a":"markdown","7cf087a0":"markdown","3fd2caa0":"markdown","7d69f1da":"markdown","6e30bae4":"markdown","924a007a":"markdown","f5eaf942":"markdown","7e5c728f":"markdown"},"source":{"657bfb74":"!pip install -U ppscore","3d0eb36a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nimport ppscore as pps\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nplt.rcParams['figure.figsize'] = 8, 5\nplt.style.use(\"fivethirtyeight\")\npd.options.plotting.backend = \"plotly\"\n\ndata = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')","4f5c434d":"fig = data.nunique().reset_index().plot(kind='bar', x='index', y=0, color=0)\nfig.update_layout(title='Unique Value Count Plot', xaxis_title='Variables', yaxis_title='Unique value count')\nfig.show()","54f3fb9a":"fig = data.isnull().sum().reset_index().plot(kind='bar', x='index', y=0)\nfig.update_layout(title='Missing Value Plot', xaxis_title='Variables', yaxis_title='Missing value count')\nfig.show()","e5d47318":"df = data.dtypes.value_counts().reset_index()\ndf['index'] = df['index'].astype('str')\nsns.barplot(df['index'], df[0])\nplt.title('DataType Count')\nplt.xlabel('DataTypes')\nplt.ylabel('Count')\nplt.show()","fb64be9a":"sns.heatmap(data.corr())\nplt.title('Correelation in data')\nplt.show()","cb9a98fc":"matrix_df = pps.matrix(data)[['x', 'y', 'ppscore']].pivot(columns='x', index='y', values='ppscore')\nsns.heatmap(matrix_df, vmin=0, vmax=1, cmap=\"Blues\", linewidths=0.5, annot=True)\nplt.title('PPS Matrix')\nplt.show()","15ad1c7b":"sns.FacetGrid(data, hue=\"DEATH_EVENT\", height=6,).map(sns.kdeplot, \"age\",shade=True).add_legend()\nplt.title('Age Distribution Plot')\nplt.show()","88608e81":"px.box(data, x='DEATH_EVENT', y='creatinine_phosphokinase', color='smoking', title='Creatinine Phosphokinase Distribution')","55ef5d64":"px.violin(data, x='ejection_fraction', color='DEATH_EVENT', title='Ejection Fraction Distribution')","ec6d40f9":"px.box(data, x='DEATH_EVENT', y='platelets', color='diabetes', points='all', title='Platelets Distribution')","dfbcfb89":"px.box(data, x='DEATH_EVENT', y='time', color='smoking', notched=True, title='Time under observation Distribution')","e345cdc8":"sns.barplot(data=data, x='high_blood_pressure', y='platelets', hue='DEATH_EVENT')\nplt.title('high_blood_pressure vs platelets')\nplt.show()","c46862fb":"sns.scatterplot(data=data, x='serum_creatinine', y='serum_sodium', hue='diabetes')\nplt.title('serum_creatinine vs serum_sodium')\nplt.show()","a303d38c":"sns.stripplot(data=data, x=\"DEATH_EVENT\", y=\"time\")\nplt.title('Time vs Death Event')\nplt.show()","766b8b0c":"sns.pairplot(data=data[['age','creatinine_phosphokinase','ejection_fraction','platelets','serum_creatinine','serum_sodium','time','DEATH_EVENT']], hue='DEATH_EVENT')","985e0317":"from sklearn.preprocessing import StandardScaler\n\ncols = ['age','creatinine_phosphokinase', 'ejection_fraction', 'platelets', 'serum_creatinine', 'serum_sodium', 'time']","32b46140":"scaler = StandardScaler()\ndata[cols] = scaler.fit_transform(data[cols])","69304a03":"X = data.drop('DEATH_EVENT', axis=1)\ny = data['DEATH_EVENT'].copy()","d4d34759":"from sklearn.model_selection import train_test_split\n\ntrain_X, test_X, train_y, test_y = train_test_split(X, y, test_size=0.25, random_state=13)","69156447":"from sklearn.metrics import roc_curve,accuracy_score,plot_confusion_matrix","862e9aa5":"from sklearn.tree import DecisionTreeClassifier\n\nmodel = DecisionTreeClassifier(min_samples_split=2, class_weight={0:2,1:7}, random_state=13)\nmodel.fit(train_X,train_y)\nprediction=model.predict(test_X)\nprint('The accuracy of the Decision Tree Classifier is', accuracy_score(prediction,test_y))","d7b20ecf":"plot_confusion_matrix(model, test_X, test_y)\nplt.title('Decision Tree Confusion Matrix')\nplt.show()","de899a91":"model = DecisionTreeClassifier(min_samples_split=2, class_weight={0:2,1:7}, random_state=13)\nmodel.fit(train_X, train_y)\ny_pred_prob = model.predict_proba(test_X)[:,1]\nfpr, tpr, thresholds = roc_curve(test_y, y_pred_prob)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='DT')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Decision Tree ROC Curve')\nplt.show()","2f9a417a":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier(min_samples_split=2, class_weight={0:2,1:7}, random_state=13)\nmodel.fit(train_X,train_y)\nprediction=model.predict(test_X)\nprint('The accuracy of the Random Forest Classifier is', accuracy_score(prediction,test_y))","fcaa2d1a":"plot_confusion_matrix(model, test_X, test_y)\nplt.title('Random Forest Confusion Matrix')\nplt.show()","97679c83":"model = RandomForestClassifier(min_samples_split=2, class_weight={0:2,1:7}, random_state=13)\nmodel.fit(train_X, train_y)\ny_pred_prob = model.predict_proba(test_X)[:,1]\nfpr, tpr, thresholds = roc_curve(test_y, y_pred_prob)\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(fpr, tpr, label='RF')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Random Forest ROC Curve')\nplt.show()","60ada83c":"# Relation in the data","5fc94654":"<p style=\"font-size:18px\">From general convention the relation among the variables that might be interesting are<br><br>1. high_blood_pressure and platelets<br>2. diabetes, serum_sodium and serum_creatinine<br>3. time and DEATH_EVENT<\/p>","8fb843c7":"# Conclusion","81b717c9":"<p style=\"font-size:18px\">If we look at a glance at the data then it will seem that the data contains very few number of observations.<br><br>But if looked closely the number of observations is still a lot more than the number of features.<br><br>So there is a chance that low bias\/high variance algorithms like KNN, Decision Trees and kernel SVM will perform better on this type of data.<br><br>Also if I use decision trees I won't needs to process the binary categorical variables in the data.<\/p>","59d2e425":"<h1>Heart Failure<\/h1>\n\n<p>Heart failure happens when the heart cannot pump enough blood and oxygen to support other organs in your body. Heart failure is a serious condition, but it does not mean that the heart has stopped beating.<\/p>\n\n<h1>Facts About Heart Failure<\/h1>\n\n<ul>\n    <li>About 6.5 million adults in the United States have heart failure.<\/li>\n    <li>Heart failure was a contributing cause of 1 in 8 deaths in 2017.<\/li>\n    <li>Heart failure costs the nation an estimated $30.7 billion in 2012. This total includes the cost of health care services, medicines to treat heart failure, and missed days of work.<a href=\"https:\/\/www.cdc.gov\/heartdisease\/heart_failure.htm\">Source<\/a><\/li>\n<\/ul>","efc6e4e9":"<p style=\"font-size:18px\">Now in this case since it is a prediction of whether or not a person has chances of heart attack, high accuracy is the main goal whatsoever.<br><br>So in this I will be using a flexible model since the interpretability can be sacrificed.<\/p>","0b3eb248":"<p style=\"font-size:18px\">The pairplot below is for checking the relation between all the continuous variables as it will help in deciding the model.<\/p>","4a4d111f":"<p style=\"font-size:18px\">Since the number of observations is not much high them it is quite feasible to use any algorithm without worrying much about the speed or training time.<br><br>In our case most of the variables are not very much linear so it will not be a good idea to use logistic regression or SVM. Rather models like random forest or neural net will be better.<br><br>I will be using decision tree classifier and random forest classifier on the data.<\/p>","b9ed57d8":"# Splitting the data","6fc832b7":"<ul style=\"font-size: 18px\">\n    <li>Facts related to heart Failure<\/li>\n    <li>Description of Data<\/li>\n    <li>Correlation in the Data<\/li>\n    <li>Outliers in Data<\/li>\n    <li>Relation between variables<\/li>\n    <li>Pairplot<\/li>\n    <li>Standardizing data<\/li>\n    <li>Deciding Model<\/li>\n    <li>Splitting the Data<\/li>\n    <li>DT Classifier<\/li>\n    <li>RF Classifier<\/li>\n    <li>Comparison of Models<\/li>\n    <li>Conclusion<\/li>\n<\/ul>","35324664":"# Standardizing the data","6df7b2ee":"# Pairplot","6a0a77ce":"# Comparison of models","20c73b11":"<p style=\"font-size:18px\">The variables that needs to be standardized are age, creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine, serum_sodium, and time.<br><br>Leaving out the categorical variables.<br><br>I will be using the StandardScaler module provided by the sklearn api<\/p>","a5916e0a":"<p style=\"font-size:18px\">Do you fear a heart attack? Then obviouly make use of random forest. Also in case this notebook gave some hint on using the model, do leave a heart here. I mean an upvote :)<\/p>\n\n<p style=\"font-size:18px\">And let me know in comments for any improvement.<\/p>","df4ae79e":"# Decision Tree CLassifier","61f27450":"# Description of Data","59cf31b8":"<p style=\"font-size:18px\">No missing values present. That's a good news. Let's check the data types as well to make sure variables don't have mized type of data here.<\/p>","e83a231f":"<p style=\"font-size:18px\">The variable creatinine_phosphokinase possibly denotes the amount of creatinine phosphokinase(an enzyme in human body) in the body of the person tested.<br><br>From the above plot it can be inferred that any amount of the enzyme higher than 4000 is an outlier.<\/p>","404e4e26":"<ol style='font-size:18px'>\n    <li>Random Forest provides a better accuracy(89.3%) than decision trees<\/li>\n    <li>RF is more efficient in prediction the negative labels in the data as can be seen from the confusion matrices of the two models<\/li>\n    <li>ROC score of RF is much better than DT<\/li>\n<\/ol>","7a4305f6":"# Random Forest Classifier","92645e5a":"# Content","7cf087a0":"<p style=\"font-size:17px\">The variables which I will need to check for outliers are mostly the continuous variables and not the categorical ones.<br><br>Since I have already confirmed the datatypes, categorical variables are already clean.<br><br>\nSo i will check thing for age, creatinine_phosphokinase, ejection_fraction, platelets, serum_creatinine, serum_sodium and time<\/p>","3fd2caa0":"# Correlation in the data","7d69f1da":"<img src=\"https:\/\/timesofindia.indiatimes.com\/thumb\/msid-71058199,width-1200,height-900,resizemode-4\/.jpg\" height=\"500px\" width=\"500px\">","6e30bae4":"# Deciding Model","924a007a":"# Outliers in the data","f5eaf942":"Let's get the model checking metric modules as well","7e5c728f":"<p style=\"font-size:18px\">Since the number of dimensions in the data isn't much high, we don't need any dimensionality reduction in this case.<\/p>"}}