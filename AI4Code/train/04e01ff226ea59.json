{"cell_type":{"136db7fd":"code","18d694f8":"code","97999f6a":"code","d0e82052":"code","2b7a3c92":"code","4f45b554":"code","89e700ed":"code","28645aa8":"code","3bbf1132":"code","4bfc60fb":"code","cac8ad7b":"code","02e61f42":"code","64fc6a8d":"code","d013f685":"code","32643bbc":"code","7b42239a":"code","fd2d96a5":"code","6358142c":"code","f9ec0d92":"code","36dfd5c2":"code","e57303f8":"code","fc99c74a":"code","16be4ee1":"code","c0fd126d":"code","3604d097":"code","25b5601c":"code","66db952e":"code","386368b4":"code","b0f6bdac":"code","aa86cdfe":"code","d8bb3398":"code","eefbfdb6":"code","8b56ef05":"markdown","af75face":"markdown","809af1af":"markdown"},"source":{"136db7fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","18d694f8":"## Importing the Dependencies\nimport numpy as np\nimport pandas as pd\nimport re\n\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\n\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import classification_report","97999f6a":"# # incase we are doing this project on our personal systems\n# import nltk\n# nltk.download('stopwords')","d0e82052":"# printing the stopwords present in english literature\nprint(stopwords.words('english'))","2b7a3c92":"# loading the dataset to dataframe\nnews_dataset = pd.read_csv('..\/input\/fake-news\/train.csv')","4f45b554":"# the number of news articles\nnews_dataset.shape","89e700ed":"# top 5 data-rows\nnews_dataset.head()","28645aa8":"# checking null values\nnews_dataset.isnull().sum()","3bbf1132":"# replacing the null values with empty strings\nnews_dataset = news_dataset.fillna(\"\")","4bfc60fb":"# checking null values: after replacement\nnews_dataset.isnull().sum()","cac8ad7b":"# using the title column and author columns together; merging columns\nnews_dataset['author_and_title'] = news_dataset['author'] + ' '+news_dataset['title']\nnews_dataset.author_and_title.head()","02e61f42":"# splitting data into dependant and independant varaibles\nX = news_dataset.drop(columns='label', axis=1)\ny = news_dataset['label']","64fc6a8d":"# looking at the split data\nprint(X.head())\nprint()\nprint(y.head())\n","d013f685":"import re","32643bbc":"# Stemming\nimport nltk\nfrom nltk.stem.porter import PorterStemmer\nporter_stemmer = PorterStemmer()\n\ndef Stemming(data):\n    removed_other_characters = re.sub('[^a-zA-Z]', ' ', data) # only keeping a-z and A-Z\n    data_lower = removed_other_characters.lower() # converting everything to lowercase\n    data_split = data_lower.split() #spliting data on the basis of space(\" \")\n    data_stemmed = [porter_stemmer.stem(word) for word in data_split if word not in stopwords.words('english')]\n    \n    data = ' '.join(data_stemmed) #convert list to string\n    \n    return data\n","7b42239a":"# Lemmatizing\nimport nltk\nfrom nltk.stem import WordNetLemmatizer\nwordnet_lemmatizer = WordNetLemmatizer()\n\ndef Lemmatizing(data):\n    removed_other_characters = re.sub('[^a-zA-Z]', ' ', data)\n    data_lower = removed_other_characters.lower()\n    data_split = data_lower.split()\n    data_lemmatized = [wordnet_lemmatizer.lemmatize(word) for word in data_split if word not in stopwords.words('english')]\n    data = ' '.join(data_lemmatized)\n    return data","fd2d96a5":"# performing stemming and lemmatizing\nnews_dataset['author_and_title_stemmed'] = news_dataset['author_and_title'].apply(Stemming)","6358142c":"news_dataset['author_and_title_lemmatizing'] = news_dataset['author_and_title'].apply(Lemmatizing)","f9ec0d92":"# let us see the output for stemmed and lemmatized contents\nnews_dataset.head()","36dfd5c2":"news_dataset.columns","e57303f8":"# separating the data and lebels i.e., splitting dependant and independant variables\n#X = news_dataset['author_and_title_stemmed'].values\nX = news_dataset['author_and_title_lemmatizing'].values\ny = news_dataset['label'].values","fc99c74a":"print(X)","16be4ee1":"# converting texual data to numeric data\nvectorizer = TfidfVectorizer()\n\nvectorizer.fit(X)\nX_vectorized = vectorizer.transform(X)","c0fd126d":"print(X_vectorized)","3604d097":"X_vectorized.shape","25b5601c":"# splitting data into train, test split\nx_train, x_test, y_train, y_test = train_test_split(X_vectorized, y, test_size=0.2, stratify=y, random_state=2)\n# startify -- y means, both the dependent variables will get splitted in equal proportion","66db952e":"# training the logistic regression model\nmodel = LogisticRegression()","386368b4":"model.fit(x_train, y_train)\nmodel","b0f6bdac":"# As it was classification problem; we will use accuracy as metrics\ntrain_prediction = model.predict(x_train)\ntraining_data_accuracy = accuracy_score(train_prediction, y_train)\ntraining_data_accuracy","aa86cdfe":"# classification report for training data\nclassification_report(y_train, train_prediction)","d8bb3398":"# As it was classification problem; we will use accuracy as metrics\ntest_prediction = model.predict(x_test)\ntest_data_accuracy = accuracy_score(test_prediction, y_test)\ntest_data_accuracy","eefbfdb6":"# making a predictive system:\nx_new = x_test[3]\n\nprediction = model.predict(x_new)\nprint(prediction)\n\nif (prediction[0]==0):\n  print('The news is Real')\nelse:\n  print('The news is Fake')","8b56ef05":"#### Stemming and Lemmatizing","af75face":"#### Data Pre-processing","809af1af":"#### About the Data:\n    1. id: unique ID for a news article\n    2. title: the title of a news article\n    3. author: author of the news article\n    4. text: the text of the article, could be incomplete\n    5. lable: a label that marks whether the news article is real or fake {1: Fake news, 0: Real news}\n"}}