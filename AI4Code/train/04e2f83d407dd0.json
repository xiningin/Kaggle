{"cell_type":{"d591abe4":"code","de398901":"code","2f1ec4da":"code","e47e5451":"code","51d2f4ac":"code","9e9a9a0c":"code","aa8da6bd":"code","5cfad4ac":"code","9873cb2d":"code","ca7567b7":"code","e5a8c93d":"code","c213303c":"code","1c4e6a19":"code","e3482204":"code","694822fd":"code","f1a16358":"code","4fc6571c":"code","5edff55c":"code","9f7a5ff5":"code","ed386f0e":"code","7aca27ae":"code","7ac5b90f":"code","04a61bd3":"code","ed79b872":"code","183ea33c":"code","1bbfde76":"code","693ae997":"code","f2ff9438":"code","27117575":"code","de8fd3c9":"code","a7a69be9":"code","774726dc":"code","8325139a":"code","47d77099":"code","5448b2e0":"code","9c63f109":"code","cc2bbe04":"code","8c9b8f14":"markdown","9953c147":"markdown","e8b6ddbd":"markdown","1e4ba8b7":"markdown","fcd6524b":"markdown","34ba603f":"markdown","15194282":"markdown","ab09cc8d":"markdown"},"source":{"d591abe4":"!pip install openpyxl","de398901":"\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly.express as px\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, plot_confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn import metrics\n","2f1ec4da":"df=pd.read_excel('..\/input\/divorce-dataset\/divorce.xlsx')","e47e5451":"df","51d2f4ac":"#getting the names of columns\ndf.columns","9e9a9a0c":"#getting the shape of the dataset\ndf.shape","aa8da6bd":"df.skew()","5cfad4ac":"df.corr()","9873cb2d":"#Global declartions of function names\nglobal Head\nglobal Size\nglobal Column_names\nglobal Describe\nglobal Shape\nglobal Count\nglobal Value_count\nglobal ISNULL\nglobal Tail\nglobal Ndim\nglobal Nunique\nglobal Memory_usage\nglobal Duplicated\nglobal ISNA\nglobal DTYPES\nglobal CORR\nglobal Info\nglobal operations\n        \n\n        ","ca7567b7":" def Head(value=5):\n            print('\\033[1m'+'displaying the', value, 'rows'+'\\033[0m')\n            a=df.head(value)\n            return a\n            print(\"--------------------------------------------------------------------------\")\nHead()","e5a8c93d":" def Tail():\n    print('\\033[1m'+\"The last five rows of the dataframe are\"+'\\033[0m')\n    co3=df.tail()\n    return(co3)\n    print(\"--------------------------------------------------------------------------\")\nTail()\n","c213303c":"def Describe():\n    print('\\033[1m'+\"The Description of our dataset is:\"+'\\033[0m')\n    des=df.describe()\n    return(des)\n    print(\"--------------------------------------------------------------------------\")\nDescribe()","1c4e6a19":"def Size():\n    print('\\033[1m'+\"The size of dataset is :\"+'\\033[0m')\n    siz=df.size\n    print(siz,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nSize()","e3482204":"def Count():\n    print('\\033[1m'+\"The count of non null values are:\"+'\\033[0m')\n    co=df.count()\n    print(co,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nCount()","694822fd":"def ISNULL():\n    print('\\033[1m'+\"Detection of missing values\"+'\\033[0m')\n    co2=df.isnull().sum()\n    print(co2,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nISNULL()","f1a16358":"def Ndim():\n    print('\\033[1m'+\"The dimensions of data set are:\"+'\\033[0m')\n    co4=df.ndim\n    print(co4,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nNdim()","4fc6571c":"def Nunique():\n    print('\\033[1m'+\"Total number of unique values are:\"+'\\033[0m')\n    co5=df.nunique()\n    print(co5,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nNunique()","5edff55c":"def Memory_usage():\n    print('\\033[1m'+\"The total memory used is :\"+'\\033[0m')\n    co6=df.memory_usage()\n    print(co6,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nMemory_usage()","9f7a5ff5":"def Duplicated():\n    print('\\033[1m'+\"Total number of duplicate rows\"+'\\033[0m')\n    co7=df.duplicated().count()\n    return(co7)\n    print(\"--------------------------------------------------------------------------\")\nDuplicated()","ed386f0e":"def DTYPES():\n    print('\\033[1m'+\"The datatypes are :\"+'\\033[0m')\n    co9=df.dtypes\n    print(co9,'\\n')\n    print(\"--------------------------------------------------------------------------\")\nDTYPES()","7aca27ae":"def Info():\n    print('\\033[1m'+\"The info of data set is :\"+'\\033[0m')\n    co11=df.info()\n    print(\"--------------------------------------------------------------------------\")\nInfo()","7ac5b90f":"def operations(df,x):\n    if df[x].dtype==\"float64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is :\\n\",df[x].mean())\n        print(\"The median is :\\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 :\\n \",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n \",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n\n            print(\"--------------------------------------------------------------------------\")\n\n\n    elif df[x].dtype==\"int64\":\n        print('\\033[1m'+'', x, 'rows'+'\\033[0m')\n        print('\\033[1m'+\"It is a quantitaive data \\n\"+'\\033[0m')\n        print(\"The mean is : \\n\",df[x].mean())\n        print(\"The median is : \\n\",df[x].median())\n        print(\"The Standard Deviation is \\n\",df[x].std())\n        q1=df[x].quantile(0.25)\n        q2=df[x].quantile(0.5)\n        q3=df[x].quantile(0.75)\n        IQR=q3-q1\n        LLP=q1-1.5*IQR\n        ULP=q3+1.5*IQR\n        print(\"The quartiles are q1 : \\n\",q1)\n        print(\"The quartiles are q2 : \\n\",q2)\n        print(\"The quartiles are q3 : \\n\",q3)\n        print(\"The Uppler limit point of the data is \\n\",ULP)\n        print(\"The lower limit point of the data is \\n\",LLP)\n        if df[x].min()>LLP and df[x].max()<ULP:\n            print(\"The outliers are not present \\n\")\n\n            print(\"--------------------------------------------------------------------------\")\n\n        else:\n\n            print(\"The outliers are present \\n\")\n            print(\"The outliers are :\")\n            print(df[df[x].values>ULP][x])\n            print(df[df[x].values<LLP][x])\n            print(\"--------------------------------------------------------------------------\")\n\n\n\n\n\n\n\n    else:\n\n        print('\\033[1m'+\"The data is Qualitative \\n\"+'\\033[0m')\n\n\n        if df[x].nunique()==1:\n            print('\\033[1m'+\"The data is singular \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()==2:\n            print('\\033[1m'+\"The data is Binary \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n        elif df[x].nunique()>2:\n            print('\\033[1m'+\"The data is Multi \\n\"+'\\033[0m')\n            print(\"The mode is :\",df[x].mode())\n            print(\"The count of mode is \\n\",df[x].value_counts())\n\n        print(\"--------------------------------------------------------------------------\")\n\nc=df.columns\nfor i in c:\n    operations(df,i)\n    print(\"\\n\")\n\n\n","04a61bd3":"def Summary():\n        print('\\033[1m'+\"The Summary of data is  \\n\"+'\\033[0m')\n        print(\"The shape of the datset is :\",df.shape)\n        print(\"The sixe o the data set is :\",df.size)\n        print(\"The dimensions of the dataset are:\",df.ndim)\n        print(\"The memory usage of the data set are\",df.memory_usage())\n        print(\"The data types of the dataset are:\",df.dtypes)\n        print(\"--------------------------------------------------------------------------\")\n\nSummary()     ","ed79b872":" def Column_Summary():\n        print('\\033[1m'+\"The Column wise Summary of data is  \\n\"+'\\033[0m')\n        k=df.columns\n        for i in k:\n            print('\\033[1m'+'', i, 'rows'+'\\033[0m')\n            print(\"The Shape of the column \",i,\"is \",df[i].shape)\n            print(\"The Size of the column \",i,\"is \",df[i].size)\n            print(\"The Dimensions of the column \",i,\"is \",df[i].ndim)\n            print(\"The Memory used by the column \",i,\"is \",df[i].memory_usage())\n            print(\"The Data types  of the column \",i,\"is \",df[i].dtypes)\n            print(\"--------------------------------------------------------------------------\")\nColumn_Summary()","183ea33c":"plt.figure(figsize=(20,16))\nax = sns.heatmap(df.corr(),annot = True, cmap = 'viridis')\nplt.show()\n\n","1bbfde76":"df.columns","693ae997":"scaler = StandardScaler()\nscaler.fit(df.drop(['Class'],axis = 1))","f2ff9438":"feature=df\nfeature=feature.drop('Class',axis=1)","27117575":"label=df['Class']","de8fd3c9":"X_train,X_test,y_train,y_test=train_test_split(feature,label,test_size=.3)","a7a69be9":"print(X_train.shape,y_train.shape)","774726dc":"print(X_test.shape,y_test.shape)","8325139a":"logreg = LogisticRegression()\nlogreg.fit(X_train, y_train)","47d77099":"y_pred = logreg.predict(X_test)\nprint('Accuracy of logistic regression classifier on test set: {:.2f}'.format(logreg.score(X_test, y_test)))","5448b2e0":"confusion_matrix = confusion_matrix(y_test, y_pred)\nprint(confusion_matrix)","9c63f109":"class_names=[0,1] # name  of classes\nfig, ax = plt.subplots()\ntick_marks = np.arange(len(class_names))\nplt.xticks(tick_marks, class_names)\nplt.yticks(tick_marks, class_names)\n# create heatmap\nsns.heatmap(pd.DataFrame(confusion_matrix), annot=True, cmap=\"YlGnBu\" ,fmt='g')\nax.xaxis.set_label_position(\"top\")\nplt.tight_layout()\nplt.title('Confusion matrix', y=1.1)\nplt.ylabel('Actual label')\nplt.xlabel('Predicted label')\n","cc2bbe04":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","8c9b8f14":"\n1. If one of us apologizes when our discussion deteriorates, the discussion ends.\n2. I know we can ignore our differences, even if things get hard sometimes.\n3. When we need it, we can take our discussions with my spouse from the beginning and correct it.\n4. When I discuss with my spouse, to contact him will eventually work.\n5. The time I spent with my wife is special for us.\n6. We don't have time at home as partners.\n7. We are like two strangers who share the same environment at home rather than family.\n8. I enjoy our holidays with my wife.\n9. I enjoy traveling with my wife.\n10. Most of our goals are common to my spouse.\n11. I think that one day in the future, when I look back, I see that my spouse and I have been in harmony with each other.\n12. My spouse and I have similar values in terms of personal freedom.\n13. My spouse and I have similar sense of entertainment.\n14. Most of our goals for people (children, friends, etc.) are the same.\n15. Our dreams with my spouse are similar and harmonious.\n16. We're compatible with my spouse about what love should be.\n17. We share the same views about being happy in our life with my spouse\n18. My spouse and I have similar ideas about how marriage should be\n19. My spouse and I have similar ideas about how roles should be in marriage\n20. My spouse and I have similar values in trust.\n21. I know exactly what my wife likes.\n22. I know how my spouse wants to be taken care of when she\/he sick.\n23. I know my spouse's favorite food.\n24. I can tell you what kind of stress my spouse is facing in her\/his life.\n25. I have knowledge of my spouse's inner world.\n26. I know my spouse's basic anxieties.\n27. I know what my spouse's current sources of stress are.\n28. I know my spouse's hopes and wishes.\n29. I know my spouse very well.\n30. I know my spouse's friends and their social relationships.\n31. I feel aggressive when I argue with my spouse.\n32. When discussing with my spouse, I usually use expressions such as \u2018you always\u2019 or \u2018you never\u2019 .\n33. I can use negative statements about my spouse's personality during our discussions.\n34. I can use offensive expressions during our discussions.\n35. I can insult my spouse during our discussions.\n36. I can be humiliating when we discussions.\n37. My discussion with my spouse is not calm.\n38. I hate my spouse's way of open a subject.\n39. Our discussions often occur suddenly.\n40. We're just starting a discussion before I know what's going on.\n41. When I talk to my spouse about something, my calm suddenly breaks.\n42. When I argue with my spouse, \u0131 only go out and I don't say a word.\n43. I mostly stay silent to calm the environment a little bit.\n44. Sometimes I think it's good for me to leave home for a while.\n45. I'd rather stay silent than discuss with my spouse.\n46. Even if I'm right in the discussion, I stay silent to hurt my spouse.\n47. When I discuss with my spouse, I stay silent because I am afraid of not being able to control my anger.\n48. I feel right in our discussions.\n49. I have nothing to do with what I've been accused of.\n50. I'm not actually the one who's guilty about what I'm accused of.\n51. I'm not the one who's wrong about problems at home.\n52. I wouldn't hesitate to tell my spouse about her\/his inadequacy.\n53. When I discuss, I remind my spouse of her\/his inadequacy.\n54. I'm not afraid to tell my spouse about her\/his incompetence.","9953c147":"# Attribute Information\n","e8b6ddbd":"# Data Visualization","1e4ba8b7":"# Exploratory  Data Analysis","fcd6524b":"# Summary of EDA","34ba603f":"# Visualizing Confusion Matrix using Heatmap","15194282":"Diagonal values represent accurate predictions, while non-diagonal elements are inaccurate predictions.","ab09cc8d":"# Data Modelling and Feature Extraction"}}