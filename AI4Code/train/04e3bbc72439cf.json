{"cell_type":{"4b050ff8":"code","a59a1fd4":"code","19c3b523":"code","8103c781":"code","0b9266d7":"code","f66460f9":"code","c212d008":"code","65502e02":"code","517577b9":"code","898d92f6":"code","71bbb3e7":"code","eddd0ebd":"code","af76e2e2":"code","545de4fe":"code","2db4b9fe":"code","026cecab":"code","8cc5c9a7":"code","9f1f8471":"code","2b8442d7":"code","3e2ab3fd":"code","ae56d12c":"code","ba0dadca":"code","d408b31c":"code","226f5321":"code","70b0e863":"code","26a7864c":"code","ba59e333":"code","89bd02a6":"code","a0bc5cfc":"code","9d419d8a":"code","b3717032":"code","7dfa9191":"code","905e0a86":"code","13e446d7":"code","895dc7d5":"code","8ca69a98":"code","894c313b":"code","c4e87efe":"code","34a8ec7c":"code","689c3f24":"code","cecd2946":"code","dc286ca0":"markdown","f956d416":"markdown","5ac2ad21":"markdown","6b7b99fc":"markdown","d0d1f958":"markdown","4d51d6e0":"markdown","eefa5f6a":"markdown","f3d1dfac":"markdown","f126d47b":"markdown","84703e4c":"markdown","45e917cd":"markdown","c80367c9":"markdown","4493258b":"markdown","e61d2eb6":"markdown","732614ec":"markdown","eb452e3c":"markdown","cddc1b74":"markdown","d8e88d48":"markdown","e534e39f":"markdown","4b518ecf":"markdown","e28e972c":"markdown","68a44f11":"markdown","5daa1887":"markdown","5a487480":"markdown","24aa6782":"markdown","724b5142":"markdown","c98c8896":"markdown","7e03f755":"markdown","d9ba5a98":"markdown","e2c11eaa":"markdown","f07bcb19":"markdown","23774ed4":"markdown","dd98b07a":"markdown","dac45cb0":"markdown","6c1887b1":"markdown","0b0144ca":"markdown","48ae2628":"markdown","ac1ac02b":"markdown","311c1dca":"markdown","90ea2cb3":"markdown","dd58aef6":"markdown"},"source":{"4b050ff8":"!conda install -c conda-forge gdcm -y\n\nimport numpy as np \nimport pandas as pd \nimport os\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.patches as patches\n%matplotlib inline\nimport glob\nfrom pydicom import dcmread\nfrom pydicom.data import get_testdata_file\n\nfrom tqdm import tqdm\n\nimport ast\n\n!pip install hvplot\nimport hvplot.pandas \n\n!pip install pylibjpeg pylibjpeg-libjpeg pydicom python-gdcm\nimport gdcm\nimport pylibjpeg","a59a1fd4":"# Read the data\ndf_train_images = pd.read_csv('..\/input\/siim-covid19-detection\/train_image_level.csv')\ndf_train_study = pd.read_csv('..\/input\/siim-covid19-detection\/train_study_level.csv')","19c3b523":"labels = ['Negative for Pneumonia', 'Typical Appearance', 'Indeterminate Appearance', 'Atypical Appearance']\n\nprint(\"Number of study : \", len(df_train_study))\n\ndf_train_study.head()","8103c781":"NUMBER_OF_SAMPLE = 5\n\ndef read_image_from_study(study_id):\n    study_name = study_id.split('_')[0]\n    file = glob.glob(\"..\/input\/siim-covid19-detection\/train\/\" + study_name + \"\/*\/*.dcm\")\n    ds = dcmread(file[0])\n    return ds.pixel_array\n\ndef show_sample_data_from_study(sample_images, NB_SAMPLE = 5):\n    fig, axes = plt.subplots(nrows=1, ncols=NB_SAMPLE, figsize=(NB_SAMPLE * 4, 4))\n    i = 0\n    for index, row in sample_images.iterrows():\n        img = read_image_from_study(row['id'])\n        axes[i].imshow(img, cmap=plt.cm.gray, aspect='auto')\n        axes[i].axis('off')\n        i += 1\n    fig.show()","0b9266d7":"sample_negative_pneumonia = df_train_study[df_train_study['Negative for Pneumonia'] == 1].sample(n=NUMBER_OF_SAMPLE, random_state=42)\nshow_sample_data_from_study(sample_negative_pneumonia, NUMBER_OF_SAMPLE)","f66460f9":"sample_negative_pneumonia = df_train_study[df_train_study['Typical Appearance'] == 1].sample(n=NUMBER_OF_SAMPLE, random_state=42)\nshow_sample_data_from_study(sample_negative_pneumonia, NUMBER_OF_SAMPLE)","c212d008":"sample_negative_pneumonia = df_train_study[df_train_study['Indeterminate Appearance'] == 1].sample(n=NUMBER_OF_SAMPLE, random_state=42)\nshow_sample_data_from_study(sample_negative_pneumonia, NUMBER_OF_SAMPLE)","65502e02":"sample_negative_pneumonia = df_train_study[df_train_study['Atypical Appearance'] == 1].sample(n=NUMBER_OF_SAMPLE, random_state=42)\nshow_sample_data_from_study(sample_negative_pneumonia, NUMBER_OF_SAMPLE)","517577b9":"# Count for each labels the number of occurence\nstudy_case = [df_train_study[label].value_counts()[1] for label in labels]\n\nplt.figure(figsize=(15, 6))\nplt.bar(labels, study_case)\nplt.title('Distribution of the different categories')\nplt.show()\n\nplt.figure(figsize=(8, 8))\nplt.pie(study_case, labels=labels, autopct='%1.1f%%')\nplt.title('Proportion of the different categories')\nplt.show()","898d92f6":"def count_column(x):\n    return x.sum()\n    \ndf_train_count = df_train_study[labels].apply(count_column, axis=1)\nprint(\"Number of multiple categories ?\", df_train_count[df_train_count != 1].sum())","71bbb3e7":"print(\"Number of images : \", len(df_train_images))\ndf_train_images.head()","eddd0ebd":"print(\"Number of duplicate images :\", df_train_images.id.duplicated().sum())\nprint(\"Number of duplicate study :\", df_train_images.StudyInstanceUID.duplicated().sum())","af76e2e2":"# Count the number of duplicated images\nunique_study_duplicate = df_train_images[df_train_images.StudyInstanceUID.duplicated()].StudyInstanceUID.unique()\nprint(\"Some duplicated id : \", ' ; '.join(unique_study_duplicate[:10]))\n\nimages_with_duplicate_study = df_train_images[df_train_images.StudyInstanceUID.isin(unique_study_duplicate)]\nprint(\"Number of image concernd with duplication :\", len(images_with_duplicate_study))","545de4fe":"def read_image_from_image(study_name, image_id):\n    image_name = image_id.split('_')[0]\n    file = glob.glob(\"..\/input\/siim-covid19-detection\/train\/\" + study_name + \"\/*\/\" + image_name + \".dcm\")\n    ds = dcmread(file[0])\n    return ds.pixel_array\n\ndef show_sample_duplicate(samples):\n    nb_show_sample = min(5, len(samples))\n    fig, axes = plt.subplots(nrows=1, ncols=nb_show_sample, figsize=(nb_show_sample * 4, 4))\n    i = 0\n    for index, row in samples.iterrows():\n        img = read_image_from_image(row['StudyInstanceUID'], row['id'])\n        axes[i].imshow(img, cmap=plt.cm.gray, aspect='auto')\n        axes[i].axis('off')\n        i += 1\n        if i == 5:\n            break\n        \n    fig.suptitle(samples.StudyInstanceUID.unique()[0], fontsize=20)\n    fig.show()\n    \n\n# Get some sample from duplicate study\nnp.random.seed(42)\nduplicated_study_sample = np.random.choice(unique_study_duplicate, 5)\n\n# See the different values\nfor sample_study_name in duplicated_study_sample:\n    sample_duplicate_image = df_train_images[df_train_images.StudyInstanceUID == sample_study_name]\n    \n    show_sample_duplicate(sample_duplicate_image)    ","2db4b9fe":"df_train_images[df_train_images.StudyInstanceUID == \"0fd2db233deb\"]","026cecab":"df_train_study[df_train_study.id == \"0fd2db233deb_study\"]","8cc5c9a7":"show_sample_duplicate(df_train_images[df_train_images.StudyInstanceUID == \"0fd2db233deb\"])","9f1f8471":"# Rename the 'StudyInstanceUID' column\ndf_train_study['StudyInstanceUID'] = df_train_study['id'].apply(lambda x : x.replace('_study', ''))\n\n# Get the duplicated study\ndf_study_from_duplicate = df_train_study[df_train_study['StudyInstanceUID'].isin(images_with_duplicate_study['StudyInstanceUID'].unique())]\n\n# Get the duplicated images\ndf_image_from_duplicate = df_train_images[df_train_images.StudyInstanceUID.isin(unique_study_duplicate)]\n\n\n# Count for each category the number of duplicated study\nduplicate_study_case = [df_study_from_duplicate[label].value_counts()[1] for label in labels]\ntotal_study_case = [df_train_study[label].value_counts()[1] for label in labels]\n\n# Get the percentage for each category\nratio_duplicate = [x \/ y for x, y in zip(duplicate_study_case, total_study_case)] \n\nprint(\"Ratio total duplicated image : \", len(df_image_from_duplicate) \/ len(df_train_images))\nprint(\"Ratio total duplicated study : \", sum(duplicate_study_case) \/ sum(total_study_case))\n\nprint()\nprint(\"Percentage of duplicated study for each category :\")\nprint() \n\nfor i in range(len(ratio_duplicate)):\n    print(labels[i], \" : \", ratio_duplicate[i])","2b8442d7":"plt.figure(figsize=(8, 8))\nplt.pie(ratio_duplicate, labels=labels, autopct='%1.1f%%', normalize=True)\nplt.suptitle(\"Distribution of duplications for each category\", fontsize=20)\nplt.show()","3e2ab3fd":"sample_images_with_boxes = df_train_images[df_train_images.boxes.notna()].sample(n=10, random_state=42)\nsample_images_with_boxes.head()","ae56d12c":"fig, axes = plt.subplots(nrows=2, ncols=5, figsize=(5 * 4, 4 * 2))\n\ni = 0\n# Iterate through the sample\nfor index, row in sample_images_with_boxes.iterrows():\n    # Read and show image\n    img = read_image_from_image(row['StudyInstanceUID'], row['id'])\n    axes[i \/\/ NUMBER_OF_SAMPLE, i % NUMBER_OF_SAMPLE].imshow(img, cmap=plt.cm.gray, aspect='auto')\n    \n    # The boxes are saved as str, we need to translate them to array of dict\n    array_boxes = ast.literal_eval(row.boxes) \n    \n    # Now, show the boxes\n    for box in array_boxes:\n        rect = patches.Rectangle((box['x'], box['y']),\n                                 box['width'], \n                                 box['height'], \n                                 edgecolor='r', \n                                 facecolor=\"none\")\n        \n        axes[i \/\/ NUMBER_OF_SAMPLE, i % NUMBER_OF_SAMPLE].add_patch(rect)\n    \n    # Remove axis information\n    axes[i \/\/ NUMBER_OF_SAMPLE, i % NUMBER_OF_SAMPLE].axis('off')\n    i += 1","ba0dadca":"sample_images_with_boxes = df_train_images[df_train_images.boxes.notna()]\nbox_size = pd.DataFrame()\n\nfor boxes in sample_images_with_boxes.boxes:\n    array_boxes = ast.literal_eval(boxes) \n    for box in array_boxes:\n        box_size = box_size.append(box, ignore_index=True)\n\nbox_size.head()","d408b31c":"box_size.describe()","226f5321":"# Show image size\nsizes = box_size.groupby(['height', 'width']).size().reset_index().rename(columns={0 : 'count'})\nsizes.hvplot.scatter(\n    x='height', \n    y='width', \n    size='count',\n    title='Box size distribution',\n    xlim=(0,3141), ylim=(0,1920), \n    grid=True, \n    height=500, width=1000).options(scaling_factor=0.1, line_alpha=1, fill_alpha=0)","70b0e863":"o = []\nfor label in df_train_images.label.values:\n    a = label.split(' ')\n    o.append(a[0])\n    \npd.Series(o).value_counts()","26a7864c":"# Merge the two dataframe\ndf_merged_data = df_train_study.merge(df_train_images, on=\"StudyInstanceUID\")","ba59e333":"path = '..\/input\/siim-covid19-detection\/train\/00086460a852\/9e8302230c91\/65761e66de9f.dcm'\nds = dcmread(path)\nprint(ds)\nplt.imshow(ds.pixel_array, cmap=plt.cm.gray)\nplt.show()","89bd02a6":"path = '..\/input\/siim-covid19-detection\/train\/057c02a959f1\/6de2191aa170\/ba463980acdb.dcm'\nds = dcmread(path)\nprint(ds)\nplt.imshow(ds.pixel_array, cmap=plt.cm.gray)\nplt.show()","a0bc5cfc":"def dcm2metadata(sample):\n    metadata = {}\n    for key in sample.keys():\n        if key.group < 50:\n            item = sample.get(key)\n        if hasattr(item, 'description') and hasattr(item, 'value'):\n            metadata[item.description()] = str(item.value)\n    return metadata\n\nTRAIN_PATH = \"..\/input\/siim-covid19-detection\/train\"\ntrain_images_path = glob.glob(TRAIN_PATH + \"\/*\/*\/*.dcm\")\nimage_metadata = pd.DataFrame()\n\n\nfor image in tqdm(train_images_path):    \n    # Read only the metadata here\n    ds = dcmread(image, stop_before_pixels=True)\n    info = dcm2metadata(ds)\n    image_metadata = image_metadata.append(info, ignore_index=True)\n        \nimage_metadata.head()","9d419d8a":"image_metadata.columns","b3717032":"print(\"Number of unique patient : \", len(image_metadata[\"Patient ID\"].unique()))","7dfa9191":"nb_male = len(image_metadata[image_metadata[\"Patient's Sex\"] == 'M'])\nnb_female = len(image_metadata[image_metadata[\"Patient's Sex\"] == 'F'])\n\nplt.figure(figsize=(6,6))\nplt.title(\"Gender distribution\")\nplt.pie([nb_male, nb_female], labels=['Male', 'Female'], autopct='%1.1f%%', colors=['b', 'r'])\nplt.show()","905e0a86":"image_metadata[\"Modality\"].value_counts()","13e446d7":"image_metadata[\"Body Part Examined\"].value_counts()","895dc7d5":"def get_sample_body_part(sample, title):\n    fig, axes = plt.subplots(nrows=1, ncols=3, figsize=(3 * 4, 4))\n    fig.suptitle(title)\n    i = 0\n    for study_id in sample['Study Instance UID'].values:\n        path = glob.glob('..\/input\/siim-covid19-detection\/train\/' + study_id + '\/*\/*.dcm')\n        ds = dcmread(path[0])\n        axes[i].imshow(ds.pixel_array, cmap=plt.cm.gray, aspect='auto')\n        axes[i].axis('off')\n        i+=1    \n\nsample_port_chest = image_metadata[image_metadata[\"Body Part Examined\"] == \"PORT CHEST\"].sample(n=3, random_state=42)\nget_sample_body_part(sample_port_chest, 'Radiography Port Chest')","8ca69a98":"sample_port_chest = image_metadata[image_metadata[\"Body Part Examined\"] == \"\"].sample(n=3, random_state=42)\nget_sample_body_part(sample_port_chest, 'Radiography Empty')","894c313b":"sample_port_chest = image_metadata[image_metadata[\"Body Part Examined\"] == \"SKULL\"].sample(n=3, random_state=42)\nget_sample_body_part(sample_port_chest, 'Radiography Skull')","c4e87efe":"sample_port_chest = image_metadata[image_metadata[\"Body Part Examined\"] == \"Pecho\"].sample(n=3, random_state=42)\nget_sample_body_part(sample_port_chest, 'Radiography Pecho')","34a8ec7c":"sample_port_chest = image_metadata[image_metadata[\"Body Part Examined\"] == \"ABDOMEN\"].sample(n=3, random_state=42)\nget_sample_body_part(sample_port_chest, 'Radiography ABDOMEN')","689c3f24":"image_metadata[\"Image Type\"].value_counts()","cecd2946":"# Convert dtype\nimage_metadata.Columns = np.array(image_metadata.Columns, dtype=int)\nimage_metadata.Rows = np.array(image_metadata.Rows, dtype=int)\n\n# Show image size\nsizes = image_metadata.groupby(['Columns', 'Rows']).size().reset_index().rename(columns={0 : 'count'})\nsizes.hvplot.scatter(\n    x='Columns', \n    y='Rows', \n    size='count',\n    title='Image size distribution',\n    xlim=(0,5000), ylim=(0,5000), \n    grid=True, \n    height=500, width=1000).options(scaling_factor=0.1, line_alpha=1, fill_alpha=0)","dc286ca0":"At a first glance, it's really complicated to really see the opacities. It's a difficult task.\nIf we focus a little bit, for the *Typical appearance*, we could see some opacities.\nWith a bigger picture, we can maybe have a better view.\n\nNote : I think that could be interesting to use images enhancement in order to help the visualisation of x-rays images. [I found on github a library called *X-Ray Images Enhancement* that could be interesting](https:\/\/github.com\/asalmada\/x-ray-images-enhancement). I will try it in another kernel. If someone already applies this kind of techniques or used that library, feel free to share your experience with us :)","f956d416":"## Image analysis with duplicate study","5ac2ad21":"### Visualization of some studies","6b7b99fc":"## See some sample images from the different categories","d0d1f958":"With these images, we can first see that the images in this sample are really different. If we take the second one, I can barely see the content (and I have to turn the brightness of my screen to the maximum!). The fourth one is also interesting because the image has been rotated and cropped. In this sample we can really see the different image contrasts we have.\n\n\nRegarding the boxes, on this sample, we see that we usually have two boxes and are places on the left and on the right. Moreover, they are mainly between the inferior and the middle lobe. However, this is a sample, we cannot make generalization on this small amount of data.\n\n\n<img src=\"https:\/\/cdn.lecturio.com\/assets\/Lobes-and-fissures-of-the-lungs-1200x570.jpg\" width=\"800\" \/>\n\nCredit : https:\/\/www.lecturio.com\/concepts\/lungs\/ - Image by Lecturio.","4d51d6e0":"### Body Part Examined","eefa5f6a":"Modality information :\n- DX : Digital Radiography\n- CR : Computed Radiography\n\n> References : https:\/\/www.dicomlibrary.com\/dicom\/modality\/\n\nTL;DR\n\nThese are two methods of achieving x-ray images. Thus, DX offers superior throughput compared to CR.\n\nMore information :\n> Computed radiography (CR) cassettes use photo-stimulated luminescence screens to capture the X-ray image, instead of traditional X-ray film. The CR cassette goes into a reader to convert the data into a digital image. Digital radiography (DR) systems use active matrix flat panels consisting of a detection layer deposited over an active matrix array of thin film transistors and photodiodes. With DR the image is converted to digital data in real-time and is available for review within seconds.\n\n> While both CR and DR have a wider dose range and can be post processed to eliminate mistakes and avoid repeat examinations, DR has some significant advantages over CR. DR improves workflow by producing higher quality images instantaneously while providing two to three times more dose efficiency than CR.\n\n> The good and bad of CR is that it enables digital imaging with the traditional workflow of X-ray film. With CR, like film, no synchronization to the generator is required, which had been a requirement for DR imaging. However, recent advances in DR panels are improving their flexibility, portability, and affordability.\n\nCited : Rick Colbeth - June 6, 2016 - https:\/\/www.vareximaging.com\/computed-radiography-cr-and-digital-radiography-dr-which-should-you-choose","f3d1dfac":"It seems that for the images present for a given study, there are duplicated but with a different quality. If we took the first, the second and the last, we clearly have different brightness. Nevertheless the fourth seems to be the same. Finally, the third one is 4 different images with different brightness and cropping.","f126d47b":"# DICOM image metadata analysis\n\nThe x-ray images are stored using a DICOM (*Digital Imaging and Communication in Medicine*)is the standard for digital files created during medical imaging examinations. It also covers the specifications concerning their archiving and their transmission over a network (particularly important aspects in the medical field). Independent of technologies (scanner, MRI, etc.) and manufacturers, it allows standardised access to medical imaging results. In addition to the digital images from medical examinations, DICOM files also carry a lot of textual information about the patient (marital status, age, weight, etc.), the examination carried out (region explored, imaging technique used, etc.), the acquisition date, the practitioner, etc.\n\n> https:\/\/sti-biotechnologies-pedagogie.web.ac-grenoble.fr\/content\/fichiers-dicom-format-dcm-en-imagerie-medicale\n\nBy analysing these files, we might be able to find interesting points that we could exploit.","84703e4c":"Regarding the size of the boxes, they seem to have similar shapes, but very variable sizes. ","45e917cd":"As we can see on the top diagram, the size of the images seems to follow a linear line starting from 0. It seems that we have globally square sized images. Moreover, we have a high concentration of images with a size between 2000 and 3000 pixels.","c80367c9":"### Modality","4493258b":"- Pixel Data Characteristics\n    - is the image an ORIGINAL Image; an image whose pixel values are based on original or source data\n    - is the image a DERIVED Image; an image whose pixel values have been derived in some manner from the pixel value of one or more other images\n\n\n\n- Patient Examination Characteristics\n    - is the image a PRIMARY Image; an image created as a direct result of the patient examination\n    - is the image a SECONDARY Image; an image created after the initial patient examination\n\n\n\n- Modality Specific Characteristics\n\n- Implementation specific identifiers; other implementation specific identifiers shall be documented in an implementation's conformance statement.\n\n\n\n> https:\/\/dicom.innolitics.com\/ciods\/ct-image\/general-image\/00080008","e61d2eb6":"Regarding the different words, I think we can regroup the words that seems to be *Thorax* (*TORAX*, *T?RAX*, *THORAX*, *2- TORAX*, *T\u00d2RAX*).\n\n- The empty category is a bit odd. Maybe doctors forgot to assign the body part when he took the x-ray?\n\n- *PORT CHEST* : referrence the upper chest where we can found a portal system, a small medical appliance, use to inject drugs or use to collect blood sample\n> https:\/\/en.wikipedia.org\/wiki\/Port_(medical)\n\n- *Pecho* : is spanish term for chest. We can group the *Pecho* and *PECHO* category.\n\n- *SKULL* : I don't really know what it means. On the sample bellow, it seems the same as chest radiography.\n\n- *ABDOMEN* : seems to be larger image in height. On the sample, we can see that we have the chest bust also the abdomen parti visible.","732614ec":"Based on the metadata, I decide to focus only on the following columns :\n\n- Patient ID\n- Patient's Sex \n- Modality\n- Body Part Examined\n- Image type\n- Columns\n- Rows","eb452e3c":"### Indeterminate appearance","cddc1b74":"#### Annotation label\n\nFor each box, we have an *opacity* tag. The question we might ask is whether we have any other tags.","d8e88d48":"## Distribution of the different categories","e534e39f":"### Image size analysis","4b518ecf":"In this section, we saw the different duplicated study and images. Those could be x-ray images that could be retaken, maybe duplicated from copy\/past or even images that have been analyze multiple times. Radiography analisys is a complex task, and some errors are possible even for the most brillant doctor. So we should keep in mind that maybe we could have error in our dataset.\n\nNevertheless, concerning the application of the duplicate images, multiple possibilites are available. \n- The simplest solution is to decide to ignore these files. As this is a small percentage of our dataset, this might be feasible. With this, we could avoid the duplication problem.\n\n- The other possibility is that we could decide to get some of the data. I mean not all the data have to be throws away. Some of them are duplicate files. For them, it would be good if we could analyse the group of images and keep only the best ones, with all the metadata information collected from the others. We could do the same for other similar images, those with a different brightness and cropping.","e28e972c":"So, in this file, we have 6054 rows. However, we have 6344 chest X-rays. So a study can group several images of a patient. One question that can be asked is why several images for one study. Are there different shots that have been taken? Was it taken in a different time frame? \n\nRegarding the diagnosis, we will have 4 labels :\n\n1. **Negative for Pneumonia**: No lung opacities.\n\n2. **Typical Appearance**: Multifocal bilateral, peripheral opacities with rounded morphology, lower lung\u2013predominant distribution\n\n3. **Indeterminate Appearance**: Absence of typical findings AND unilateral, central or upper lung predominant distribution\n\n4. **Atypical Appearance**: Pneumothorax, pleural effusion, pulmonary edema, lobar consolidation, solitary lung nodule or mass, diffuse tiny nodules, cavity.\n\n\n> https:\/\/www.kaggle.com\/c\/siim-covid19-detection\/discussion\/240250\n\n\n**Pulmonary opacification represents the result of a decrease in the ratio of gas to soft tissue** (blood, lung parenchyma and stroma) in the lung. When reviewing an area of increased attenuation (opacification) on a chest radiograph or CT it is vital to determine where the opacification is. The patterns can broadly be divided into airspace opacification, lines and dots.\n\n> https:\/\/radiopaedia.org\/articles\/pulmonary-opacification","68a44f11":"### Box size analysis","5daa1887":"For the study case, we don't have multiple categories. Which means that **each categories are distinct**. \nRegarding the distribution of the data, **we have unbalanced categories**. As we can see in our diagram, we have 47% for *Typical Appearance*. And, regarding the *Atypical Appearance*, we have 7,8%. \n\nSo, when the preprocessing of our training dataset, we should take in consideration that we're dealing with unbalance data in order to avoid important prediction on unique label.","5a487480":"To recall, we had seen in the previous part that we have multiple images for a given study. It could be interesting to visualize those data in order to understand why we have multiple images.","24aa6782":"# Introduction\n\nCOVID-19 is a **pulmonary infection resulting in inflammation and fluid in lungs**. This disease is similar to other pneumonias, which makes it difficult to diagnose. The idea of the project is to **detect and localize COVID-19** in order to help doctors to provide a quick and confident diagnosis. This will allow them to get the right treatment before severe effects of the virus.\n\nThe reason for using chest X-rays is that they are very easy to take and obtained in minutes. In addition, we can locate the disease and get a better idea of the patient's condition.\n\nIn this notebook, we will **visualise and understand** the data from a dataset X-rays. The objective is to get an overview of the data and to see if some information can be gathered. Feel free to leave a comment if you have any questions, I would be happy to answer them :)\n\n> Link for the data : [SIIM-FISABIO-RSNA COVID-19 Detection](https:\/\/www.kaggle.com\/c\/siim-covid19-detection)","724b5142":"## Visualize some DICOM image","c98c8896":"## See some image with their boxes","7e03f755":"### Image type","d9ba5a98":"# Conclusion\n\nIn this notebook, we have seen a lot of information. To summarise some of the main ideas:\n- We have unbalanced data.\n- A study can contain several images. Those images can be duplicated.\n- The brightness of the images changes a lot.\n- According to the metadata, the set of images corresponds well to the location of the chest.\n- The image appear to be square and its size is concentrated between 2000 and 3000 pixels.\n- The images were taken equally between CR and DX. \n\n\nThank you for your reading time. I hope you found this notebook usefull. Let me know if you like it or not. And if you have questions or remarks don't hesitate :)","e2c11eaa":"### Negative for pneumonia","f07bcb19":"### Patient's Sex","23774ed4":"### Atypical appearance","dd98b07a":"# Analysis of the studies\n\nIn this section we will focus mainly on the analysis of the studies. We will try to understand the different categories and their distribution.","dac45cb0":"### Typical appearance","6c1887b1":"### The particular 0fd2db233deb ID\n\nDuring my research, I found a particular ID, which have duplicated images.","0b0144ca":"## Get meta-information from train images","48ae2628":"Regarding the 0fd2db233deb ID, we have duplicated images. Moreover, regarding the image information, we have a box information for a unique rows. \n\nSo, in our dataset, we have **duplicate images**. Some are different (with different brigthness, different cropping, different angle) and some are the same. They represent 512 images of our dataset. It's represent about 8% (512 * 100 \/ 6334) of our dataset. ","ac1ac02b":"### Patient ID","311c1dca":"In this dataset, we have two important files :\n- *train_study_level.csv* : We will find all the study information as a corresponding label for the image.\n- *train_image_level.csv* : We will fing image information and the associated bounding boxes to locate the disease.\n\nThe train dataset comprises **6,334 chest scans in DICOM format**, which were de-identified to protect patient privacy. All images were labeled by a panel of experienced radiologists for the presence of opacities as well as overall appearance.","90ea2cb3":"Here, we know we have only two tags for boxes : *none* or *opacity*","dd58aef6":"# Analysis of the images"}}