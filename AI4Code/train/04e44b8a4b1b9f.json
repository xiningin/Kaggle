{"cell_type":{"10df167a":"code","6d1e55f7":"code","cbb68749":"code","dc034681":"code","be126b6f":"code","e7044bd4":"code","f4c794fa":"code","51e67e28":"code","acde0e26":"code","28d70ece":"code","25d18bd2":"code","3a83bfe0":"code","cc391997":"markdown","8ddb44e3":"markdown","b15129d7":"markdown","17197507":"markdown","fdd14d1d":"markdown","07fbeba5":"markdown","cef3a7a2":"markdown"},"source":{"10df167a":"import numpy as np\nimport pandas as pd\n\nfrom scipy.stats import skew\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder, LabelEncoder,RobustScaler, PowerTransformer, PolynomialFeatures\nfrom sklearn.ensemble import RandomForestClassifier, StackingClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.linear_model import LinearRegression, LogisticRegression\n\nimport warnings\nwarnings.simplefilter('ignore')","6d1e55f7":"train = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntest  = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/test.csv')\nsub = pd.read_csv(\"..\/input\/tabular-playground-series-apr-2021\/sample_submission.csv\")","cbb68749":"y = train.Survived.values\n\ntrain.drop(['Survived','PassengerId'], axis=1, inplace=True)\ntest.drop(['PassengerId'], axis=1, inplace=True)\nprint(f\"train size is : {train.shape}\")\nprint(f\"test size is : {test.shape}\")","dc034681":"test.Cabin     = test.Cabin.fillna('0')\ntrain.Cabin    = train.Cabin.fillna('0')\n\ntrain.Ticket   = train.Ticket.fillna(train.Ticket.mode()[0])\ntest.Ticket    = test.Ticket.fillna(test.Ticket.mode()[0])\n\ntrain.Age      = train.Age.fillna(train.Age.median())\ntest.Age       = test.Age.fillna(train.Age.median())\n\ntrain.Embarked = train.Embarked.fillna(train.Embarked.mode()[0])\ntest.Embarked  = test.Embarked.fillna(train.Embarked.mode()[0])\n\ntrain.Fare     = train.Fare.fillna(train.Fare.mean())\ntest.Fare      = test.Fare.fillna(test.Fare.mean())","be126b6f":"train['HasCabin'] = train.Cabin.apply(lambda x: 0 if x=='0' else 1).astype('category')\ntest['HasCabin'] = test.Cabin.apply(lambda x: 0 if x=='0' else 1).astype('category')\n\ntrain['Ticket_'] = train['Ticket'].str.replace('[^\\w\\s]','').replace(' ','').fillna('NA').replace('(\\d)', '', regex=True).astype('category')\ntest['Ticket_'] = test['Ticket'].str.replace('[^\\w\\s]','').replace(' ','').fillna('NA').replace('(\\d)', '', regex=True).astype('category')\n\ntrain['FirstName'] = train['Name'].str.split(',').str[1].str.split('.').str[0].str.strip().astype('category')\ntest['FirstName'] = test['Name'].str.split(',').str[1].str.split('.').str[0].str.strip().astype('category')\n\ntrain['FamilySize'] = train['SibSp'] + train['Parch']\ntest['FamilySize'] = test['SibSp'] + test['Parch']\n\ntrain.drop(['Name','Cabin','Ticket'], axis=1, inplace=True)\ntest.drop(['Name','Cabin','Ticket'], axis=1, inplace=True)","e7044bd4":"numeric_feats = train.dtypes[(train.dtypes != \"object\") & (train.dtypes != 'category')].index.tolist()\nobject_feats  = train.dtypes[(train.dtypes == \"object\") | (train.dtypes == 'category')].index.tolist()\n\nskewed_feats = train[numeric_feats].apply(lambda x: skew(x.dropna())).sort_values(ascending=False)\nskewness = pd.DataFrame({'Skew' :skewed_feats})\n\nfor i in skewness.index:\n    train[i]=np.log1p(train[i])\n    test[i]=np.log1p(test[i])","f4c794fa":"preprocessor = ColumnTransformer(\n    transformers=[\n        ('cat', OneHotEncoder(handle_unknown='ignore'), object_feats),\n        ('num', RobustScaler() , numeric_feats)\n    ])","51e67e28":"clf = Pipeline(steps=[\n                    ('pre', preprocessor),\n                    ('a', GradientBoostingClassifier(random_state=42)),\n                    ])","acde0e26":"param_grid = {\n    'a__n_estimators': list(range(50,250,50)),\n    'a__learning_rate': [0.155, 0.16, 0.165, 0.17],\n    \"a__max_depth\": list(range(3,7,1)),\n    #\"a__max_features\":[\"log2\",\"sqrt\"],\n    #\"a__criterion\": [\"friedman_mse\",  \"mae\"],\n}","28d70ece":"a = GridSearchCV(clf, param_grid,scoring='balanced_accuracy', cv=10).fit(train, y)\na.best_estimator_","25d18bd2":"a.best_estimator_.fit(train, y)\npredictions = a.best_estimator_.predict(test)","3a83bfe0":"sub['Survived'] = predictions\nsub.to_csv('submission.csv',index=False)","cc391997":"# Modeling","8ddb44e3":"# Data pre-processing","b15129d7":"## Pipeline with Gradient Boosting\nSklearn Documentation on GradientBoosting: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.ensemble.GradientBoostingClassifier.html\n\nRelated notebook on gridsearch: https:\/\/www.kaggle.com\/hatone\/gradientboostingclassifier-with-gridsearchcv","17197507":"## Loading data and libraries","fdd14d1d":"EDA and logistic regression notebook:\n* https:\/\/www.kaggle.com\/pavfedotov\/tps-april-eda-logistic-regression\n\nNotebooks on features:\n* https:\/\/www.kaggle.com\/hiro5299834\/tps-apr-2021-single-decisiontreemodel\n* https:\/\/www.kaggle.com\/sociopath00\/random-forest-using-gridsearchcv\n* https:\/\/www.kaggle.com\/dwin183287\/tps-april-2021-models-feature-enginering","07fbeba5":"## Feature Engineering","cef3a7a2":"## Imputing"}}