{"cell_type":{"2fc07088":"code","2187c8b3":"code","b284ecde":"code","219633db":"code","09994529":"code","12d0274a":"code","5fb62434":"code","176706d5":"code","881aba60":"code","b867b3fa":"code","2324cb0e":"code","8b1dd00d":"code","12a735e3":"code","e8d1a204":"code","79472f3c":"code","5987c85b":"code","558604ad":"code","6477ec81":"code","c1e850cd":"code","fbbe35be":"code","21dfb3ab":"code","4d12acef":"markdown","87d60b33":"markdown","5189f164":"markdown","9108044e":"markdown"},"source":{"2fc07088":"%load_ext autoreload\n%autoreload 2\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nfrom torch.utils.data import Dataset, DataLoader\nimport glob\nimport os.path as osp\nimport numpy as np\nfrom PIL import Image\nimport matplotlib.pyplot as plt\nimport numpy as np\nfrom pathlib import Path\n%matplotlib inline","2187c8b3":"class MNIST(Dataset):\n    \"\"\"\n    A customized data loader for MNIST.\n    \"\"\"\n    def __init__(self,\n                 root,\n                 transform=None,\n                 preload=False):\n        \"\"\" Intialize the MNIST dataset\n        \n        Args:\n            - root: root directory of the dataset\n            - tranform: a custom tranform function\n            - preload: if preload the dataset into memory\n        \"\"\"\n        self.images = None\n        self.labels = None\n        self.filenames = []\n        self.root = root\n        self.transform = transform\n\n        # read filenames\n        for i in range(10):\n            filenames = glob.glob(osp.join(root, str(i), '*.png'))\n            for fn in filenames:\n                self.filenames.append((fn, i)) # (filename, label) pair\n                \n        # if preload dataset into memory\n        if preload:\n            self._preload()\n            \n        self.len = len(self.filenames)\n                              \n    def _preload(self):\n        \"\"\"\n        Preload dataset to memory\n        \"\"\"\n        self.labels = []\n        self.images = []\n        for image_fn, label in self.filenames:            \n            # load images\n            image = Image.open(image_fn)\n            # avoid too many opened files bug\n            self.images.append(image.copy())\n            image.close()\n            self.labels.append(label)\n\n    def __getitem__(self, index):\n        \"\"\" Get a sample from the dataset\n        \"\"\"\n        if self.images is not None:\n            # If dataset is preloaded\n            image = self.images[index]\n            label = self.labels[index]\n        else:\n            # If on-demand data loading\n            image_fn, label = self.filenames[index]\n            image = Image.open(image_fn)\n            \n        # May use transform function to transform samples\n        # e.g., random crop, whitening\n        if self.transform is not None:\n            image = self.transform(image)\n        # return image and label\n        return image, label\n\n    def __len__(self):\n        \"\"\"\n        Total number of samples in the dataset\n        \"\"\"\n        return self.len","b284ecde":"# Create the MNIST dataset. \n# transforms.ToTensor() automatically converts PIL images to\n# torch tensors with range [0, 1]\ntrainset = MNIST(\n    root='..\/input\/mnistpng\/mnist_png\/training',\n    preload=True, transform=transforms.ToTensor(),\n)\n\n# Use the torch dataloader to iterate through the dataset\ntrainset_loader = DataLoader(trainset, batch_size=64, shuffle=True, num_workers=1)\n\n# load the testset\ntestset = MNIST(\n    root='..\/input\/mnistpng\/mnist_png\/testing',\n    preload=True, transform=transforms.ToTensor(),\n)\n# Use the torch dataloader to iterate through the dataset\ntestset_loader = DataLoader(testset, batch_size=1000, shuffle=False, num_workers=1)","219633db":"print(len(trainset))\nprint(len(testset))","09994529":"# functions to show an image\ndef imshow(img):\n    npimg = img.numpy()\n    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n\n# get some random training images\ndataiter = iter(trainset_loader)\nimages, labels = dataiter.next()\n\n# show images\nimshow(torchvision.utils.make_grid(images))\n# print labels\nprint(' '.join('%5s' % labels[j] for j in range(16)))","12d0274a":"# Use GPU if available, otherwise stick with cpu\nuse_cuda = torch.cuda.is_available()\ntorch.manual_seed(123)\ndevice = torch.device(cuda if use_cuda else \"cpu\")\nprint(device)","5fb62434":"\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 50)\n        self.fc2 = nn.Linear(50, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = F.relu(self.fc1(x))\n        x = F.dropout(x, training=self.training)\n        x = self.fc2(x)\n        return F.log_softmax(x, dim=1)\n\nmodel = Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","176706d5":"\ndef train(epoch, log_interval=100):\n    model.train()  # set training mode\n    iteration = 0\n    for ep in range(epoch):\n        for batch_idx, (data, target) in enumerate(trainset_loader):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            optimizer.step()\n            if iteration % log_interval == 0:\n                print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n                    100. * batch_idx \/ len(trainset_loader), loss.item()))\n            iteration += 1\n        test()","881aba60":"\ndef test():\n    model.eval()  # set evaluation mode\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        for data, target in testset_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, size_average=False).item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n\n    test_loss \/= len(testset_loader.dataset)\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.0f}%)\\n'.format(\n        test_loss, correct, len(testset_loader.dataset),\n        100. * correct \/ len(testset_loader.dataset)))","b867b3fa":"train(5) ","2324cb0e":"\ndef save_checkpoint(checkpoint_path, model, optimizer):\n    state = {'state_dict': model.state_dict(),\n             'optimizer' : optimizer.state_dict()}\n    torch.save(state, checkpoint_path)\n    print('model saved to %s' % checkpoint_path)\n    \ndef load_checkpoint(checkpoint_path, model, optimizer):\n    state = torch.load(checkpoint_path)\n    model.load_state_dict(state['state_dict'])\n    optimizer.load_state_dict(state['optimizer'])\n    print('model loaded from %s' % checkpoint_path)","8b1dd00d":"model = Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\ntest()","12a735e3":"def train_save(epoch, save_interval, log_interval=100):\n    model.train()  # set training mode\n    iteration = 0\n    for ep in range(epoch):\n        for batch_idx, (data, target) in enumerate(trainset_loader):\n            data, target = data.to(device), target.to(device)\n            optimizer.zero_grad()\n            output = model(data)\n            loss = F.nll_loss(output, target)\n            loss.backward()\n            optimizer.step()\n            if iteration % log_interval == 0:\n                print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                    ep, batch_idx * len(data), len(trainset_loader.dataset),\n                    100. * batch_idx \/ len(trainset_loader), loss.item()))\n            if iteration % save_interval == 0 and iteration > 0:\n                save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)\n            iteration += 1\n        test()\n    \n    # save the final model\n    save_checkpoint('mnist-%i.pth' % iteration, model, optimizer)","e8d1a204":"\ntrain_save(5, 500, 100)","79472f3c":"\n# create a new model\nmodel = Net().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)\n# load from the final checkpoint\nload_checkpoint('mnist-4690.pth', model, optimizer)\n# should give you the final model accuracy\ntest()","5987c85b":"\n# What's in a state dict?\nprint(model.state_dict().keys())","558604ad":"checkpoint = torch.load('mnist-4690.pth')\nstates_to_load = {}\nfor name, param in checkpoint['state_dict'].items():\n    if name.startswith('conv'):\n        states_to_load[name] = param\n\n# Construct a new state dict in which the layers we want\n# to import from the checkpoint is update with the parameters\n# from the checkpoint\nmodel_state = model.state_dict()\nmodel_state.update(states_to_load)\n        \nmodel = Net().to(device)\nmodel.load_state_dict(model_state)\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","6477ec81":"\ntrain(1)  # training 1 epoch will get you to 95%!","c1e850cd":"\nclass SmallNet(nn.Module):\n    def __init__(self):\n        super(SmallNet, self).__init__()\n        self.conv1 = nn.Conv2d(1, 10, kernel_size=5)\n        self.conv2 = nn.Conv2d(10, 20, kernel_size=5)\n        self.conv2_drop = nn.Dropout2d()\n        self.fc1 = nn.Linear(320, 10)\n\n    def forward(self, x):\n        x = F.relu(F.max_pool2d(self.conv1(x), 2))\n        x = F.relu(F.max_pool2d(self.conv2_drop(self.conv2(x)), 2))\n        x = x.view(-1, 320)\n        x = self.fc1(x)\n        return F.log_softmax(x, dim=1)\n\nmodel = SmallNet().to(device)\noptimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)","fbbe35be":"checkpoint = torch.load('mnist-4690.pth')\nstates_to_load = {}\nfor name, param in checkpoint['state_dict'].items():\n    if name.startswith('conv'):\n        states_to_load[name] = param\n\n# Construct a new state dict in which the layers we want\n# to import from the checkpoint is update with the parameters\n# from the checkpoint\nmodel_state = model.state_dict()\nmodel_state.update(states_to_load)\n        \nmodel.load_state_dict(model_state)","21dfb3ab":"train(1)  # training 1 epoch will get you to 95%!","4d12acef":"# If you liked this notebook please **upvote** this notebook","87d60b33":"# !!! Please UPVOTE","5189f164":"# References\n1. https:\/\/pytorch.org\/tutorials\/beginner\/data_loading_tutorial.html\n","9108044e":"# **This is a ocr base tutorial on MNSIT data set implemented using Pytorch.**"}}