{"cell_type":{"65818519":"code","49c8ccf0":"code","64f8ada5":"code","57d18c3c":"code","38981f7f":"code","9fceb6dc":"code","b357e65e":"code","302fd6c2":"code","cc703616":"code","fbb95e66":"code","ff62e646":"code","04066739":"code","e77e5368":"code","c3352bb7":"code","c07ab421":"code","e33f55fd":"code","cc4c4da8":"code","8ce627fc":"code","059480ee":"code","74605660":"code","8fb9ca7b":"code","4baaf019":"code","1a1545e5":"code","3770b026":"code","a6198917":"code","7a63ce89":"code","2596ecf2":"code","8f5b6955":"code","12c36fb5":"code","4a75389f":"code","d35676dd":"code","53b049b5":"code","fe6f5336":"code","301e059b":"code","40719b9a":"markdown","03742b09":"markdown"},"source":{"65818519":"import seaborn as sns\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.utils import shuffle\nfrom sklearn.model_selection import train_test_split\nimport tensorflow as tf\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, TensorBoard, ModelCheckpoint\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, AveragePooling2D\nfrom tensorflow.keras.layers import Input, Dense, Dropout, Flatten, Activation,Concatenate\nfrom tensorflow.keras.layers import BatchNormalization\nfrom keras.preprocessing.image import load_img,img_to_array,ImageDataGenerator\nfrom tensorflow.keras.applications import VGG16\nfrom tqdm import tqdm\nimport os\nfrom sklearn.utils import shuffle\n\nimport ipywidgets as widgets\nimport io\nfrom PIL import Image\nfrom IPython.display import display,clear_output\nfrom warnings import filterwarnings\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","49c8ccf0":"labels = ['glioma_tumor','no_tumor','meningioma_tumor','pituitary_tumor']\n","64f8ada5":"X_train = []\ny_train = []\nimage_size = 150\nfor i in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri','Training',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size, image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \nfor i in labels:\n    folderPath = os.path.join('..\/input\/brain-tumor-classification-mri','Testing',i)\n    for j in tqdm(os.listdir(folderPath)):\n        img = cv2.imread(os.path.join(folderPath,j))\n        img = cv2.resize(img,(image_size,image_size))\n        X_train.append(img)\n        y_train.append(i)\n        \nX_train = np.array(X_train)\ny_train = np.array(y_train)","57d18c3c":"k=0\nfig, ax = plt.subplots(1,4,figsize=(20,20))\nfig.text(s='Sample Image From Each Label',size=18,fontweight='bold',\n             fontname='monospace',y=0.62,x=0.4,alpha=0.8)\nfor i in labels:\n    j=0\n    while True :\n        if y_train[j]==i:\n            ax[k].imshow(X_train[j])\n            ax[k].set_title(y_train[j])\n            ax[k].axis('off')\n            k+=1\n            break\n        j+=1","38981f7f":"X_train, y_train = shuffle(X_train,y_train, random_state=101)\nX_train.shape","9fceb6dc":"X_train,X_test,y_train,y_test = train_test_split(X_train,y_train, test_size=0.1,random_state=101)","b357e65e":"y_train_new = []\nfor i in y_train:\n    y_train_new.append(labels.index(i))\ny_train = y_train_new\ny_train = tf.keras.utils.to_categorical(y_train)\n\n\ny_test_new = []\nfor i in y_test:\n    y_test_new.append(labels.index(i))\ny_test = y_test_new\ny_test = tf.keras.utils.to_categorical(y_test)\n\n\n","302fd6c2":"model = Sequential()\n\nmodel.add(Conv2D(64, (3, 3), padding='same',input_shape=(image_size,image_size,3))) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Conv2D(64, (3, 3))) \nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.35))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization()) \n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2))) \nmodel.add(BatchNormalization())\nmodel.add(Dropout(0.35)) #64 --> 42\n\nmodel.add(Conv2D(64, (3, 3), padding='same')) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\n\nmodel.add(Flatten()) \nmodel.add(Dropout(0.5)) \nmodel.add(Dense(512)) \nmodel.add(Activation('relu'))\nmodel.add(BatchNormalization())\nmodel.add(Dense(4)) \nmodel.add(Activation('softmax'))\n\nmodel.summary()","cc703616":"batch_size=32\nepochs = 50","fbb95e66":"model.compile(optimizer = 'adam',\n               loss = 'categorical_crossentropy',\n               metrics = ['accuracy'])","ff62e646":"tensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"cnn.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","04066739":"history = model.fit(X_train,y_train,validation_split=0.1, epochs =12, verbose=1, batch_size=32,\n                   callbacks=[tensorboard,checkpoint,reduce_lr])","e77e5368":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","c3352bb7":"effnet = EfficientNetB0(weights='imagenet',include_top=False,input_shape=(image_size,image_size,3))","c07ab421":"model = effnet.output\nmodel = tf.keras.layers.GlobalAveragePooling2D()(model)\nmodel = tf.keras.layers.Dropout(rate=0.5)(model)\nmodel = tf.keras.layers.Dense(4,activation='softmax')(model)\nmodel = tf.keras.models.Model(inputs=effnet.input, outputs = model)","e33f55fd":"model.summary()","cc4c4da8":"model.compile(loss='categorical_crossentropy',optimizer = 'Adam', metrics= ['accuracy'])","8ce627fc":"earlystop = EarlyStopping(monitor='val_loss', patience=5)\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=2, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.00001)\n\ncallbacks = [earlystop, learning_rate_reduction]","059480ee":"history = model.fit(X_train, y_train, batch_size = 64, validation_data = (X_test, y_test),\n                     epochs = 20, callbacks =[callbacks] )","74605660":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","8fb9ca7b":"vgg_model=VGG16(input_shape=(image_size,image_size,3) , weights='imagenet' , include_top=False,pooling=\"max\")\n","4baaf019":"for layer in vgg_model.layers:\n    layer.trainable  = False","1a1545e5":"vgg_model.summary()\n","3770b026":"model = Sequential()\nmodel.add(vgg_model)\n\nmodel.add(Flatten()) \nmodel.add(Activation('relu'))\nDropout(rate=0.5)\nmodel.add(Dense(4)) \nmodel.add(Activation('softmax'))\n\n\n\nmodel.summary()","a6198917":"model.compile(optimizer = 'adam',\n               loss = 'categorical_crossentropy',\n               metrics = ['accuracy'])","7a63ce89":"tensorboard = TensorBoard(log_dir = 'logs')\ncheckpoint = ModelCheckpoint(\"effnet.h5\",monitor=\"val_accuracy\",save_best_only=True,mode=\"auto\",verbose=1)\nreduce_lr = ReduceLROnPlateau(monitor = 'val_accuracy', factor = 0.3, patience = 2, min_delta = 0.001,\n                              mode='auto',verbose=1)","2596ecf2":"history = model.fit(X_train, y_train, batch_size = batch_size, validation_data = (X_test, y_test),\n                    steps_per_epoch = len(X_train) \/ batch_size, epochs = epochs, callbacks =[tensorboard,checkpoint,reduce_lr])","8f5b6955":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()\n\n# Plot loss values vs epoch\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='upper left')\nplt.show()","12c36fb5":"pred = model.predict(X_test)\npred = np.argmax(pred,axis=1)\ny_test_new = np.argmax(y_test,axis=1)","4a75389f":"from sklearn.metrics import classification_report\n\nprint(classification_report(y_test_new,pred))\n","d35676dd":"from sklearn.metrics import confusion_matrix\n\nfig,ax=plt.subplots(1,1,figsize=(14,7))\nsns.heatmap(confusion_matrix(y_test_new,pred),ax=ax,xticklabels=labels,yticklabels=labels,annot=True)\n\n\nplt.show()","53b049b5":"def img_pred(upload):\n    for name, file_info in uploader.value.items():\n        img = Image.open(io.BytesIO(file_info['content']))\n    opencvImage = cv2.cvtColor(np.array(img), cv2.COLOR_RGB2BGR)\n    img = cv2.resize(opencvImage,(150,150))\n    img = img.reshape(1,150,150,3)\n    p = model.predict(img)\n    p = np.argmax(p,axis=1)[0]\n\n    if p==0:\n        p='Glioma Tumor'\n    elif p==1:\n        print('The model predicts that there is no tumor')\n    elif p==2:\n        p='Meningioma Tumor'\n    else:\n        p='Pituitary Tumor'\n\n    if p!=1:\n        print(f'The Model predicts that it is a {p}')","fe6f5336":"import ipywidgets as widgets\n\nuploader = widgets.FileUpload()\ndisplay(uploader)","301e059b":"from IPython.display import display,clear_output\n\nbutton = widgets.Button(description='Predict')\nout = widgets.Output()\ndef on_button_clicked(_):\n    with out:\n        clear_output()\n        try:\n            img_pred(uploader)\n            \n        except:\n            print('No Image Uploaded\/Invalid Image File')\nbutton.on_click(on_button_clicked)\nwidgets.VBox([button,out])","40719b9a":"# vgg16","03742b09":"# EfficientNetB0"}}