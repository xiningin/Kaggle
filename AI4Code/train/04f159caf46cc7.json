{"cell_type":{"f3a806ff":"code","31d926b9":"code","217c9cea":"code","6cbc7f60":"code","62931995":"code","cffca68f":"code","dbcb4864":"code","9e17b558":"code","5d324fa2":"code","02811bb3":"code","89028136":"code","8e78bccc":"code","ac643356":"code","620c753f":"code","1e366a11":"code","1a8245d0":"code","07b9bf2d":"markdown","113a7f82":"markdown","1fce942f":"markdown","b6f3a7c2":"markdown","d0727640":"markdown","66c0b126":"markdown","00091d74":"markdown","d404d9c1":"markdown","d1176df2":"markdown","634c4599":"markdown","8adf7097":"markdown","26011c8c":"markdown","9ae21d36":"markdown","731e8bfe":"markdown","54bdf6ed":"markdown","0345920b":"markdown","64440ed3":"markdown","90c71986":"markdown","f96bcfb8":"markdown","7fdcb8ba":"markdown","a920e7c3":"markdown","b2f730c9":"markdown","0a55828a":"markdown","64b4d10a":"markdown","b0b1582d":"markdown","434cae41":"markdown","ea6e8a6a":"markdown","20327f67":"markdown","ced168e5":"markdown","6147ec8b":"markdown","a81297e4":"markdown","8f68212b":"markdown","519f23b7":"markdown"},"source":{"f3a806ff":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os #interact withe file sysytem\nimport re #used for data cleaning\nimport nltk #used for data cleaing\nfrom nltk.stem.porter import PorterStemmer #used for finding the root word of a word \nfrom nltk.corpus import stopwords #used fro removing the stop words\nfrom bs4 import BeautifulSoup #used for removing the html tags in the text\nfrom nltk.tokenize import TreebankWordTokenizer#it t\nfrom sklearn.linear_model import LogisticRegression #for classification\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report #for testing the model accuracy","31d926b9":"#importing all the negetive file first\ntrain_neg=os.listdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclimdb\/aclImdb\/train\/neg')#listing all the filenames present in the directory\nos.chdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclimdb\/aclImdb\/train\/neg')#setting the directory path\ntrain_set=[]\nfor i in train_neg:\n    fp=open(i,\"r\",encoding=\"utf8\")\n    train_set.append(fp.read())\n    fp.close()","217c9cea":"#now importing the all positive files\ntrain_pos=os.listdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclimdb\/aclImdb\/train\/pos')\nos.chdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclimdb\/aclImdb\/train\/pos')\nfor i in train_pos:\n    fp=open(i,\"r\",encoding=\"utf8\")\n    train_set.append(fp.read())\n    fp.close()\ntrain_set[12500]","6cbc7f60":"len(train_set)","62931995":"train_set=pd.DataFrame(train_set,columns=[\"Reviews\"])#converting train_set from list to a datframe\ntrain_set[\"Rating\"]=np.zeros([len(train_set),1],dtype=int)#adding rating column for all the rows to zero then we will change it to 1 for the positive reviews\ntrain_set.loc[12500:25000,\"Rating\"]=1#changing the rating value to 1 for positive reviews\ny=train_set.loc[:,\"Rating\"]","cffca68f":"train_set[0:5]","dbcb4864":"train_set[12500:12505]","9e17b558":"test_neg=os.listdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclimdb\/aclImdb\/test\/neg')\ntest_pos=os.listdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclimdb\/aclImdb\/test\/pos')","5d324fa2":"os.chdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclimdb\/aclImdb\/test\/neg')\ntest_set=[]\nfor i in test_neg:\n    fp=open(i,\"r\",encoding=\"utf8\")\n    test_set.append(fp.read())\n    fp.close()\ntest_set[0]","02811bb3":"os.chdir('\/kaggle\/input\/imdb-movie-reviews-dataset\/aclimdb\/aclImdb\/test\/pos')\nfor i in test_pos:\n    fp=open(i,\"r\",encoding=\"utf8\")\n    test_set.append(fp.read())\n    fp.close()\ntest_set[12500]","89028136":"test_set=pd.DataFrame(test_set,columns=[\"Reviews\"])#converting test_set from list to a datframe\ntest_set[\"Rating\"]=np.zeros([len(test_set),1],dtype=int)#adding rating column for all the rows to zero then we will change it to 1 for the positive reviews\ntest_set.loc[12500:25000,\"Rating\"]=1#changing the rating value to 1 for positive reviews\ny_test=test_set.loc[ : ,\"Rating\"]","8e78bccc":"test_set[0:5]","ac643356":"test_set[12500:12505]","620c753f":"train_corpus=[]\ntokenizer=TreebankWordTokenizer()\nfor i in range(0,len(train_set)):\n    soup=BeautifulSoup(train_set[\"Reviews\"][i],\"html.parser\")\n    review=soup.get_text()#removes all html tags\n    review.lower()#converting all words to lower case\n    review=tokenizer.tokenize(review)#tokenizing using trebankwordtokenizer\n    ps=PorterStemmer()\n    review=[ps.stem(word) for word in review]#stemming the words\n    review=' '.join(review)\n    train_corpus.append(review)\ntrain_corpus[0:10]","1e366a11":"test_corpus=[]\nfor i in range(0,len(test_set)):\n    soup=BeautifulSoup(test_set[\"Reviews\"][i],\"html.parser\")\n    review=soup.get_text()#removes all html tags\n    review.lower()#converting all words to lower case\n    review=tokenizer.tokenize(review)#tokenizing using trebankwordtokenizer\n    ps=PorterStemmer()\n    review=[ps.stem(word) for word in review]#stemming the words\n    review=' '.join(review)\n    test_corpus.append(review)","1a8245d0":"test_corpus[0:5]","07b9bf2d":"**INTRODUCTION**\n            This notebook is on classification on the basis of sentiment analysis based on imdb users reviews. Its tottaly at beginner \n            level.tf-idf vectorizer is used for the transformation of text to numbers and logistic regression model is used for the\n            classification.","113a7f82":"> cm_logi = confusion_matrix(y_test, y_pred_logi)\n\n> cm_logi\n","1fce942f":"as you can see we have made the corpus for the train set,there is no html tags ,all the words are lower case and stemmed but the articles and pontuation marks are still there .Tf-Idf vectorier will take care of this.","b6f3a7c2":"> from sklearn.feature_extraction.text import TfidfVectorizer\n\n> tfidf=TfidfVectorizer(min_df=5,max_df=0.5,ngram_range=(1,2))\n\n> x=tfidf.fit_transform(train_corpus).toarray()\n\n> x.shape()","d0727640":"**Loading the all required models**","66c0b126":"![image.png](attachment:image.png)","00091d74":"![image.png](attachment:image.png)","d404d9c1":"prdicting the vectorizer with testset","d1176df2":" ![image.png](attachment:image.png)","634c4599":"**DATA CLEANING**\nIn sentiment analysis data cleaning means text cleaning.because the texts we have contain different articles,pontuation marks,unnecessery spaces,and html tags along with the sentiment words,for the sentiment ananlysis we only need sentiment words not other words.training a model without cleaning the text is a bad practice.so we will remove those words from our text and will prepare our corpse whcih will contain only sentiment words.and we will also stem similar type of words for example enjoying and enjoy they refer to a same sentiment so we dont need that extra ing term.And one thing ,while we are removing pontuation marks there may be a chance we can lose a meaning of  word by doing so for example don't if we will tokenize it the it will become don and t and both of the words nake no sense do we will use the treebankwordtokenizer so that it will tokenize and the words wont lose their meaning.so lets start the cleaning process.","8adf7097":"> a=classification_report(y_test, y_pred_logi)\n\n> print(a)","26011c8c":"Now we have prepared the train and test datasets lets go for the data cleaning process.","9ae21d36":"![image.png](attachment:image.png)","731e8bfe":"> acc_logi=accuracy_score(y_test, y_pred_logi)\n\n> acc_logi\n","54bdf6ed":"now we have a list of negetive and positive reviews.in the list negetive reviews comes first followed by positive reviews.now we will convert this list to a dataframe and which will contain 2 columns Review and rating column.so lets make the datframe. ","0345920b":"importing the train dataset first","64440ed3":"now we have preapred our train dataset successfully now lets do the same operations for the test set","90c71986":"**CONCLUSION**","f96bcfb8":"importing the test files","7fdcb8ba":"training the model with trainset","a920e7c3":"now lets preapre the corpus for test set","b2f730c9":"as our dataset is equally devided,means we have equal number of positive and negetive records we will consider the. we will caluclate the confusion matrix using confusion_matrix model and accuracy_score model to get the accuracy score for the model and accuracy_report model for the accuracy report.","0a55828a":"> from sklearn.feature_extraction.text import TfidfVectorizer\n\n> tfidf=TfidfVectorizer(min_df=5,max_df=0.5,ngram_range=(1,2))\n\n> x_test=tfidf.fit(train_corpus).toarray()\n\n> x_test.shape()","64b4d10a":"**TRAINING THE MODEL:**","b0b1582d":"****Accuracy****","434cae41":"**** PREPARING THE VECTORIZER****\nnow we have preapred the corpuses lets prepare our vectorizer.tfidf vectorizer will remove the words which will appear morethan 50 percent of the documents and which will appear less than 5 documents.And we have considered 1gram and 2gram words for better accuracy.more accuracy can be achieved by considering bigger ngrams.","ea6e8a6a":"now lets check first 5 of each negetive and positive reviews and their ratings","20327f67":"logistic regression model produces 89.29 percentage of accuracy which is acceptable .we can achive higher accuracy using random forest model. we can achieve upto 93 percentage of accuracy using random forest but it will take a large amount of memory which may not be possible in low end systems.We used tfidf vectorizer model we can use other models.","ced168e5":"> y_pred_logi = logi_classifier.predict(x_test)\n\n> y_pred_logi\n","6147ec8b":"![image.png](attachment:image.png)","a81297e4":"now lets fit the vectorizer to the test_set","8f68212b":"**Importing the datasets**","519f23b7":"> logi_classifier = LogisticRegression(random_state = 0)\n\n> logi_classifier.fit(x, y)\n"}}