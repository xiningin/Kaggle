{"cell_type":{"0e31a385":"code","29ac46ad":"code","491dead9":"code","b570503f":"code","bc9423e1":"code","265612e5":"code","d55c68cd":"code","bbaabc75":"code","71b2bfc0":"code","3ee8830a":"code","4d322c8a":"code","0c6b466b":"markdown","02f0a5b5":"markdown","a8f84672":"markdown","4fef4cf4":"markdown","7c862056":"markdown","2403ede3":"markdown"},"source":{"0e31a385":"import sys\nsys.path.append(\"..\/input\/timmeffnetv2\")","29ac46ad":"import platform\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport cv2\nimport gc\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\n\nimport torch\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.cuda.amp import GradScaler, autocast\nfrom torch.utils.data import Dataset, DataLoader\n\nimport warnings\nwarnings.simplefilter('ignore')","491dead9":"train_labels = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntrain_labels['path'] = train_labels['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')\ntrain_labels.head()","b570503f":"def plotFromFoldScores(score_dict, colors=None):\n    if colors is None:\n        colors = ['r', 'g', 'y', 'b', 'm']\n    \n    plt.figure(figsize=(10, 7))\n    for fold_num, scores in score_dict.items():\n        plt.plot(scores, f'{colors[fold_num]}o-', label=f'Fold {fold_num}')\n    \n    plt.ylabel(\"Validation ROC-AUC Score\")\n    plt.xlabel(\"Epochs\")\n    plt.title(\"Val ROC-AUC Scores in all Folds\")\n    plt.legend()\n    plt.show()","bc9423e1":"class Config:\n    N_SPLITS = 5\n    model_name = 'vit_base_patch16_224'\n    resize = (224, 224)\n    TRAIN_BS = 32\n    VALID_BS = 16\n    num_workers = 8\n    NB_EPOCHS = 5\n    scaler = GradScaler()","265612e5":"class Trainer:\n    def __init__(self, model, optimizer, scheduler, train_dataloader, valid_dataloader, device):\n        self.model = model\n        self.optimizer = optimizer\n        self.scheduler = scheduler\n        self.train_data = train_dataloader\n        self.valid_data = valid_dataloader\n        self.loss_fn = self.yield_loss\n        self.val_loss_fn = self.yield_loss\n        self.device = device\n        \n    def yield_loss(self, outputs, targets):\n        return nn.BCEWithLogitsLoss()(outputs, targets)\n    \n    def train_one_epoch(self):\n        prog_bar = tqdm(enumerate(self.train_data), total=len(self.train_data))\n        self.model.train()\n        avg_loss = 0\n        #with autocast():\n        for idx, inputs in prog_bar:\n            image = inputs[0].to(self.device, dtype=torch.float)\n            targets = inputs[1].to(self.device, dtype=torch.float)\n\n            outputs = self.model(image)\n\n            loss = self.loss_fn(outputs, targets.view(-1, 1))\n            prog_bar.set_description('loss: {:.2f}'.format(loss.item()))\n\n            loss.backward()\n            self.optimizer.step()\n            #Config.scaler.scale(loss).backward()\n            #Config.scaler.step(self.optimizer)\n            #Config.scaler.update()\n            self.optimizer.zero_grad(set_to_none=True)\n\n            avg_loss += loss.item()\n                \n        return avg_loss \/ len(self.train_data)\n    \n    def valid_one_epoch(self):\n        prog_bar = tqdm(enumerate(self.valid_data), total=len(self.valid_data))\n        self.model.eval()\n        all_targets = []\n        all_predictions = []\n        avg_loss = 0\n        with torch.no_grad():\n            for idx, inputs in prog_bar:\n                image = inputs[0].to(self.device, dtype=torch.float)\n                targets = inputs[1].to(self.device, dtype=torch.float)\n\n                outputs = self.model(image)\n                \n                val_loss = self.val_loss_fn(outputs, targets.view(-1, 1))\n                prog_bar.set_description('val_loss: {:.2f}'.format(val_loss.item()))\n                \n                all_targets.extend(targets.cpu().detach().numpy().tolist())\n                all_predictions.extend(torch.sigmoid(outputs).cpu().detach().numpy().tolist())\n                \n                avg_loss += val_loss.item()\n        val_roc_auc = roc_auc_score(all_targets, all_predictions)\n        return val_roc_auc, avg_loss \/ len(self.valid_data)\n    \n    def get_model(self):\n        return self.model","d55c68cd":"class SETIData(Dataset):\n    def __init__(self, images, targets, is_test=False, augmentations=None): \n        self.images = images\n        self.targets = targets\n        self.is_test = is_test\n        self.augmentations = augmentations\n        \n    def __getitem__(self, index):\n        image = np.load(self.images[index]).astype(np.float32)\n        image = np.vstack(image).transpose((1, 0))\n        image = cv2.resize(image, dsize=Config.resize, interpolation=cv2.INTER_CUBIC)\n        \n        if self.augmentations is not None:\n            augmented = self.augmentations(image=image)\n            image = augmented[\"image\"]\n        else:\n            image = image[np.newaxis, :, :]\n            \n        if self.is_test:\n            return image\n        \n        else:\n            target = self.targets[index]\n            return image, target\n    \n    def __len__(self):\n        return len(self.images)","bbaabc75":"print(\"You can see the available models from EfficientNetV2 family here:\")\ntimm.list_models('*vit*_224*')","71b2bfc0":"class EffNetV2(nn.Module):\n    def __init__(self, pretrained=True) -> None:\n        super(EffNetV2, self).__init__()\n        self.backbone = timm.create_model(Config.model_name, pretrained=pretrained, in_chans=1)\n        self.backbone.classifier = nn.Linear(self.backbone.classifier.in_features, 1)\n        \n    def forward(self, x) -> torch.Tensor:\n        out = self.backbone(x)\n        return out\n    \nclass VITModel(nn.Module):\n    \"\"\"\n    Model Class for VIT Model\n    \"\"\"\n    def __init__(self, model_name=Config.model_name, pretrained=True):\n        super(VITModel, self).__init__()\n        self.model = timm.create_model(model_name, pretrained, in_chans=1)\n        self.model.head = nn.Linear(self.model.head.in_features, 1)\n    \n    def forward(self, x):\n        x = self.model(x)\n        return x","3ee8830a":"# Training Code\nif __name__ == '__main__':\n    if torch.cuda.is_available():\n        print(\"[INFO] Using GPU: {}\\n\".format(torch.cuda.get_device_name()))\n        DEVICE = torch.device('cuda:0')\n    else:\n        print(\"\\n[INFO] GPU not found. Using CPU: {}\\n\".format(platform.processor()))\n        DEVICE = torch.device('cpu')\n    \n    kfold = StratifiedKFold(n_splits=Config.N_SPLITS, shuffle=True, random_state=2021)\n    \n    fold_scores = {}\n    \n    for fold_, (trn_idx, val_idx) in enumerate(kfold.split(train_labels, train_labels['target'])):\n        print(f\"{'='*40} Fold: {fold_} {'='*40}\")\n        \n        train_data = train_labels.loc[trn_idx]\n        valid_data = train_labels.loc[val_idx]\n        \n        print(f\"[INFO] Training on {trn_idx.shape[0]} samples and validating on {valid_data.shape[0]} samples\")\n\n        # Make Training and Validation Datasets\n        training_set = SETIData(\n            images=train_data['path'].values,\n            targets=train_data['target'].values\n        )\n\n        validation_set = SETIData(\n            images=valid_data['path'].values,\n            targets=valid_data['target'].values\n        )\n\n        train = DataLoader(\n            training_set,\n            batch_size=Config.TRAIN_BS,\n            shuffle=True,\n            num_workers=8,\n            pin_memory=True\n        )\n\n        valid = DataLoader(\n            validation_set,\n            batch_size=Config.VALID_BS,\n            shuffle=False,\n            num_workers=8\n        )\n\n        model = VITModel().to(DEVICE)\n        print(f\"[INFO] Training Model: {Config.model_name}\")\n        nb_train_steps = int(len(train_data) \/ Config.TRAIN_BS * Config.NB_EPOCHS)\n        optimizer = torch.optim.Adam(model.parameters(), lr=1e-5)\n\n        trainer = Trainer(model, optimizer, None, train, valid, DEVICE)\n        \n        per_fold_score = []\n        for epoch in range(1, Config.NB_EPOCHS+1):\n            print(f\"\\n{'--'*5} EPOCH: {epoch} {'--'*5}\\n\")\n\n            # Train for 1 epoch\n            tr_lss = trainer.train_one_epoch()\n            \n            # Validate for 1 epoch\n            current_roc, vl_lss = trainer.valid_one_epoch()\n            print(f\"Validation ROC-AUC: {current_roc:.4f}\")\n            \n            per_fold_score.append(current_roc)\n            torch.save(trainer.get_model().state_dict(), f\"{Config.model_name}_fold_{fold_}.pt\")\n        \n        fold_scores[fold_] = per_fold_score\n        del training_set, validation_set, train, valid, model, optimizer, trainer, current_roc\n        gc.collect()\n        torch.cuda.empty_cache()","4d322c8a":"# Plot validation roc-auc scores for all 5 epochs from all 5 folds\nplotFromFoldScores(fold_scores)","0c6b466b":"# This is a folk of [this notebook](https:\/\/www.kaggle.com\/heyytanay\/0-9-auc-pytorch-training-amp-vit-kfolds).\nI omitted AMP (Automatic Mixed Precision), and found trainng speed becomes faster (2.18it\/s -> 2.30it\/s). Do you know why?","02f0a5b5":"<h1 align='center' style='background: #1eeacf'>4. Model Classes - ViT and EffNetV2<\/h1>","a8f84672":"<h1 align='center' style='background: #1eeacf'>1. Imports and Data Loading<\/h1>","4fef4cf4":"<h1 align='center' style='background: #1eeacf'>5. Main Training Code<\/h1>","7c862056":"<h1 align='center' style='background: #1eeacf'>3. Custom Dataset - SETIData<\/h1>","2403ede3":"<h1 align='center' style='background: #1eeacf'>2. Trainer Class - Training and Validation Code<\/h1>"}}