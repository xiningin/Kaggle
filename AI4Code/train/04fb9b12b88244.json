{"cell_type":{"724e9b7d":"code","84e8852d":"code","baf37a53":"code","8e39ec04":"code","d49b4b8f":"code","d69c2d6d":"code","707f9247":"code","a54bd628":"code","38ebcb85":"code","0ca82636":"code","358190ad":"code","528fc213":"code","58461ad0":"code","74d1ddf6":"code","24ef7f5a":"code","558e5443":"code","891e9d5a":"code","e6d8c772":"code","e1e8cb6f":"code","efd87eaa":"code","5fa2354d":"code","e21d32a4":"code","d20d755b":"code","92e13b28":"code","dc12f444":"code","f1ee5049":"code","7b418c44":"code","51b5790b":"code","1bcfb11c":"code","ea3abe05":"code","b49964b8":"code","ff8e9f88":"code","5d972ec2":"code","fa5fe364":"code","8b362edc":"code","1d519719":"code","a3a3b3d8":"markdown","0896e78d":"markdown","e92fb4db":"markdown","20544fb9":"markdown"},"source":{"724e9b7d":"# Importing few libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom mpl_toolkits.mplot3d import Axes3D\nimport seaborn as sns","84e8852d":"#Importing dataset\n\ndata = pd.read_csv(\"..\/input\/posture-reconstruction\/ConfLongDemo_JSI.csv\", header=None)\ndata.shape","baf37a53":"data.head() #Let;'s see how data look's like","8e39ec04":"#Changing the names of columns according to given data description\n\ndata.columns = ['Sequence_Name', 'Tag_identificator', 'timestamp', 'date_FORMAT', \n                'x_coordinate', 'y_coordinate', 'z_coordinate', 'activity']","d49b4b8f":"data.head()","d69c2d6d":"data.info() #Lets see if their is any Null Values and Dtype","707f9247":"data.describe(include='all').T # It describes the data acc. to Mean, Median, percentile etc and Unique values","a54bd628":"cat = data.select_dtypes(include='object').columns.to_list() # Extracting all categorical values to list\ncat.remove(\"date_FORMAT\") # Removing Date \nfor i in cat:\n    print(\"Name of {} col\".format(i)) # Name of Column\n    print(\"No. of NUnique\", data[i].nunique()) # Total Nunique Values\n    print(\"Unique Values\", data[i].unique()) # All unique values\n    print('*'*30)\n    print()\n    print()","38ebcb85":"def encoding(df):\n    '''\n    Encoding all Categorical Values to Label\n    '''\n    from sklearn.preprocessing import LabelEncoder\n\n    tag_encoder = LabelEncoder()\n    sequence_encoder =  LabelEncoder()\n    activity_encoder = LabelEncoder()\n\n    df['Tag_identificator'] = tag_encoder.fit_transform(df['Tag_identificator'])\n    df['Sequence_Name'] = sequence_encoder.fit_transform(df['Sequence_Name'])\n    df['activity'] = activity_encoder.fit_transform(df['activity'])\n    return \"Successful\"","0ca82636":"for i in data.select_dtypes(include=['int64', 'float64']):\n    sns.boxplot(data[i]) #Boxlot for all Numerical Values to check how well data is distributed\n    plt.show()","358190ad":"for i in data.select_dtypes(include=['int64', 'float64']):\n    sns.distplot(data[i]) # Distribution plot to check how data is distributed\n    plt.show()","528fc213":"fig = plt.figure()\nax = plt.axes(projection='3d') # 3D plot\nax.scatter3D(data['x_coordinate'],\n         data['y_coordinate'],\n         data['z_coordinate'],\n         c = data['z_coordinate'], cmap='Greens')","58461ad0":"def new_col(df):\n    '''\n    Creating new columns of day, month, year, hour, minute, second, microsecond from date_time Column\n    \n    It is created to check how our data is calculated and what is represent\n    '''\n    from datetime import datetime as dt # Importing Datetime library\n    \n    # transforming Datetime Column to Date_time format\n    df['date_FORMAT'] = pd.to_datetime(df['date_FORMAT'], format=\"%d.%m.%Y %H:%M:%S:%f\")\n    \n    # Extracting day, month, year, hour, minute, second, microsecond from Date_time Column\n    df['day'] = df['date_FORMAT'].dt.day\n    df['month'] = df['date_FORMAT'].dt.month\n    df['year'] = df['date_FORMAT'].dt.year\n    df['hour'] = df['date_FORMAT'].dt.hour\n    df['minute'] = df['date_FORMAT'].dt.minute\n    df['second'] = df['date_FORMAT'].dt.second\n    df['microsecond'] = df['date_FORMAT'].dt.microsecond\n    \n    del df['date_FORMAT'] # Removing Date_time Column\n    return 'Successfull'","74d1ddf6":"data.head()","24ef7f5a":"#Trasnforming our data\n\nencoding(data)\nnew_col(data)","558e5443":"data.head()","891e9d5a":"#Correlation Graph\n\nplt.figure(figsize=(20,12))\nsns.heatmap(data.corr(), annot=True)\nplt.show()","e6d8c772":"data.describe(include='all').T","e1e8cb6f":"col = ['day', 'month', 'year',\n       'hour', 'minute', 'second', 'microsecond']\n\nfor i in col:\n    print(\"Name of {} col\".format(i)) # Name of Column\n    print(\"No. of NUnique\", data[i].nunique()) # Total N_Unique Values in Column\n    print(\"Unique Values\", data[i].unique()) # All Unique values in column\n    print('*'*30)\n    print()\n    print()","efd87eaa":"data.drop(['day', 'month', 'year'], axis=1, inplace=True)","5fa2354d":"col = ['hour', 'minute', 'second']\n\nfor i in col:\n    print(\"Name of {} col\".format(i)) # Name of Column\n    print(\"No. of NUnique\", data[i].nunique()) # Total N_Unique Values in Column\n    print(\"Unique Values\", data[i].unique()) # All Unique values in column\n    print('*'*30)\n    print()\n    print()","e21d32a4":"for i in col:\n    sns.distplot(data[i]) # Distribution plot to check how data is distributed\n    plt.show()","d20d755b":"data.shape # Shape of data","92e13b28":"data.info()","dc12f444":"#for Spliting Data and Hyperparameter Tuning \nfrom sklearn.model_selection import train_test_split, GridSearchCV\n\n#Importing Machine Learning Model\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom catboost import CatBoostClassifier\n    \n#Bagging Algo\nfrom sklearn.tree import DecisionTreeClassifier\nfrom xgboost import XGBClassifier, XGBRFClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom lightgbm import LGBMClassifier\n\nfrom sklearn.neural_network import MLPClassifier\n\n#To tranform data\nfrom sklearn import preprocessing\n\n#statistical Tools\nfrom sklearn.metrics import roc_auc_score,accuracy_score,precision_score,recall_score,f1_score\n\nfrom sklearn.metrics import confusion_matrix, roc_curve, auc, classification_report","f1ee5049":"data['activity'].value_counts() # Count of all Activity","7b418c44":"X = data.drop(['activity'], axis=1) # Input Variable\ny = data['activity'] # Target Varibale","51b5790b":"from imblearn.over_sampling import SMOTE # Library to Balance Dataset\nsmote = SMOTE()\n\nX_tf,y_tf = smote.fit_resample(X,y) # Balancing our Data\nX_tf.shape, y_tf.shape # Checking our new shape after Over_Sampling","1bcfb11c":"from sklearn.preprocessing import RobustScaler\nscaler = RobustScaler()\nx = scaler.fit_transform(X_tf)","ea3abe05":"# Split the data into training and testing sets \nx_train,x_test,y_train,y_test = train_test_split(x, y_tf, test_size=.1)\n\nprint(x_train.shape[0], x_test.shape[0])","b49964b8":"accuracy = {}\n\ndef train_model(model, model_name):\n    print(model_name)\n    \n    # Fitting model\n    model = model.fit(x_train, y_train)\n    pred = model.predict(x_test)\n    \n    #Model accuracy\n    acc = accuracy_score(y_test, pred)*100\n    accuracy[model_name] = acc\n    print('accuracy_score',acc)\n    print()\n    \n    # Classification Report\n    print('Classification Report')\n    print(classification_report(y_test, pred))","ff8e9f88":"lgbm = LGBMClassifier(n_estimators=720, n_jobs=-1, max_depth=15, min_child_weight=5, \n                      min_child_samples=5, num_leaves=10, learning_rate=0.15)\n\ntrain_model(lgbm, 'LGBMClassifier')","5d972ec2":"cat = CatBoostClassifier(verbose = 0, n_estimators = 1000)\n\ntrain_model(cat, \"Cat Boost\")","fa5fe364":"xgb = XGBClassifier(n_estimators = 1500, nthread  = 4, max_depth = 15, min_child_weight = 5, learning_rate=0.01)\n\ntrain_model(xgb, 'XGBClassifier')","8b362edc":"rfc = RandomForestClassifier(n_estimators = 1500, n_jobs=-1, max_depth=15, \n                             min_samples_split=5, min_samples_leaf=3)\n\ntrain_model(rfc, 'Random Forest Classifier')","1d519719":"dtc = DecisionTreeClassifier(criterion='gini', splitter='random', max_depth=25, min_samples_split=4,\n                            min_samples_leaf=2)\n\ntrain_model(dtc, 'Decision Tree Classifier')","a3a3b3d8":"# After Extracting We have found that the data is of 5 Hours from 11 to 15 and It is collected on 27th May 2009","0896e78d":"As all data is of same date we don't need Columns naming Day, Month and Year","e92fb4db":"## XGB Classifier is giving the Best Result","20544fb9":"So we have 25 Unique Sequence Name\n\n4 Unique Tag_identifier\n\n11 Unique Activities"}}