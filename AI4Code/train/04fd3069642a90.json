{"cell_type":{"3522b7c4":"code","499ee22b":"code","b16bba0e":"code","2bdd6085":"code","67425fac":"code","e791876c":"code","78dd96cf":"code","b9043530":"code","4961646b":"code","412257a1":"code","6fc44872":"code","4e7705e8":"code","b518af1b":"code","433e6c85":"code","13db3997":"code","fe8b31cf":"code","e4e7d389":"code","77f93d6a":"code","294ae076":"code","20a4ae3b":"code","d6f94967":"code","3deaab81":"code","245d6820":"code","578c1fbc":"code","29267987":"code","264efee9":"code","54fa0bc5":"code","0af9958e":"code","0b3916f8":"code","304ab232":"code","bbf42676":"code","53153ec1":"code","e9e0a432":"code","33354c47":"code","d33b3734":"code","ad3c1088":"code","5daf7e48":"code","5aefb845":"code","bedeec4f":"code","d7f0d967":"code","92a40070":"code","8f65ae3d":"code","d6778185":"code","ac19dc70":"code","b21dca5d":"code","856309b1":"code","96109170":"code","30b2e645":"code","2a51a444":"code","dee798ef":"code","553fccf2":"code","84fc1d55":"markdown","b0cd4969":"markdown","3b63380b":"markdown","cae9850b":"markdown","ba235c3b":"markdown","e92a5207":"markdown","75055ebe":"markdown","09720332":"markdown","d8f255af":"markdown","b31e6eb9":"markdown","2d7df71d":"markdown","d76f9d15":"markdown","3211f40a":"markdown","7a759978":"markdown","29039a87":"markdown","38cab384":"markdown","9669baa7":"markdown","71d9e4f7":"markdown","8a00e000":"markdown","abc2741a":"markdown"},"source":{"3522b7c4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport datetime, gc, random\nimport json, numpy as np, pandas as pd, zipfile\nimport matplotlib.pyplot as plt\nfrom itertools import cycle\nfrom sklearn.cluster import MeanShift, estimate_bandwidth\n# file\nimport zipfile\n\n# Data preprocessing\nimport datetime\nimport re\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.metrics import precision_recall_fscore_support as score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.neighbors import KNeighborsRegressor\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.metrics import r2_score\n\n# Visualization\nfrom matplotlib import pyplot as plt\nimport folium\nimport seaborn as sns\nsns.set_theme(style=\"ticks\", color_codes=True)\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\nfrom colorama import Fore\n\n# Random forest\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.multioutput import MultiOutputRegressor\n\n# parameter opimization\nfrom sklearn.model_selection import GridSearchCV\n\n# Validation\nfrom sklearn.metrics import confusion_matrix, accuracy_score, precision_score, recall_score, f1_score\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","499ee22b":"%%time\n# Defining all our palette colours.\nprimary_blue = \"#496595\"\nprimary_blue2 = \"#85a1c1\"\nprimary_blue3 = \"#3f4d63\"\nprimary_grey = \"#c6ccd8\"\nprimary_black = \"#202022\"\nprimary_bgcolor = \"#f4f0ea\"\n\nprimary_green = px.colors.qualitative.Plotly[2]\n\nplt.rcParams['axes.facecolor'] = primary_bgcolor\n\ncolors = [primary_blue, primary_blue2, primary_blue3, primary_grey, primary_black, primary_bgcolor, primary_green]\nsns.palplot(sns.color_palette(colors))","b16bba0e":"%%time\n# Reading The Data\n\n# sample\nzip_file = zipfile.ZipFile(\"\/kaggle\/input\/pkdd-15-predict-taxi-service-trajectory-i\/sampleSubmission.csv.zip\")\nsample = pd.read_csv(zip_file.open('sampleSubmission.csv'))\n\n# train\nzip_file = zipfile.ZipFile(\"\/kaggle\/input\/pkdd-15-predict-taxi-service-trajectory-i\/train.csv.zip\")\ntrain = pd.read_csv(zip_file.open(\"train.csv\"))\n\n# test\nzip_file = zipfile.ZipFile(\"\/kaggle\/input\/pkdd-15-predict-taxi-service-trajectory-i\/test.csv.zip\")\ntest = pd.read_csv(zip_file.open(\"test.csv\"))\n\n# location_Data\nzip_file = zipfile.ZipFile(\"\/kaggle\/input\/pkdd-15-predict-taxi-service-trajectory-i\/metaData_taxistandsID_name_GPSlocation.csv.zip\")\nlocation = pd.read_csv(zip_file.open(\"metaData_taxistandsID_name_GPSlocation.csv\"))","2bdd6085":"%%time\nsample","67425fac":"%%time\ntrain","e791876c":"%%time\ntest","78dd96cf":"%%time\nlocation","b9043530":"%%time\n# Time data preprocessing\ntrain[\"TIMESTAMP\"] = [float(time) for time in train[\"TIMESTAMP\"]]\ntrain[\"data_time\"] = [datetime.datetime.fromtimestamp(time, datetime.timezone.utc) for time in train[\"TIMESTAMP\"]]","4961646b":"# Time data\ntrain[\"data_time\"].value_counts()","412257a1":"%%time\n# Time data preparation\ntrain[\"year\"] = train[\"data_time\"].dt.year\ntrain[\"month\"] = train[\"data_time\"].dt.month\ntrain[\"day\"] = train[\"data_time\"].dt.day\ntrain[\"hour\"] = train[\"data_time\"].dt.hour\ntrain[\"min\"] = train[\"data_time\"].dt.minute\ntrain[\"weekday\"] = train[\"data_time\"].dt.weekday","6fc44872":"%%time\ntrain.head()","4e7705e8":"%%time\ntrain.tail()","b518af1b":"%%time\n# Time series visualization\npivot = pd.pivot_table(train, index='month', columns=\"year\", values=\"TRIP_ID\", aggfunc=\"count\").reset_index()\n\n# Visualization, per month count\nwith plt.style.context(\"ggplot\"):\n    plt.figure(figsize=(10,6))\n    plt.rcParams[\"font.size\"] = 18\n    plt.plot(pivot[\"month\"], pivot[2013], label=\"2013\")\n    plt.plot(pivot[\"month\"], pivot[2014], label=\"2014\")\n    plt.xlabel(\"month\")\n    plt.ylabel(\"count\")\n    plt.legend(facecolor=\"white\")","433e6c85":"%%time\n# Time series visualization\npivot = pd.pivot_table(train, index='day', columns=\"month\", values=\"TRIP_ID\", aggfunc=\"count\").reset_index()\n# Visualization, per day count\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    plt.rcParams[\"font.size\"] = 18\n    plt.plot(pivot[\"day\"], pivot[1], label=\"January\")\n    plt.plot(pivot[\"day\"], pivot[2], label=\"February\")\n    plt.xlabel(\"day\")\n    plt.ylabel(\"count\")\n    plt.legend(facecolor=\"white\")","13db3997":"%%time\n# Visualization, per day count\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    plt.rcParams[\"font.size\"] = 18\n    plt.plot(pivot[\"day\"], pivot[3], label=\"March\")\n    plt.plot(pivot[\"day\"], pivot[4], label=\"April\")\n    plt.xlabel(\"day\")\n    plt.ylabel(\"count\")\n    plt.legend(facecolor=\"white\")","fe8b31cf":"%%time\n# Visualization, per day count\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    plt.rcParams[\"font.size\"] = 18\n    plt.plot(pivot[\"day\"], pivot[5], label=\"May\")\n    plt.plot(pivot[\"day\"], pivot[6], label=\"June\")\n    plt.xlabel(\"day\")\n    plt.ylabel(\"count\")\n    plt.legend(facecolor=\"white\")","e4e7d389":"%%time\n# Visualization, per day count\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    plt.rcParams[\"font.size\"] = 18\n    plt.plot(pivot[\"day\"], pivot[7], label=\"July\")\n    plt.plot(pivot[\"day\"], pivot[8], label=\"August\")\n    plt.xlabel(\"day\")\n    plt.ylabel(\"count\")\n    plt.legend(facecolor=\"white\")","77f93d6a":"%%time\n# Visualization, per day count\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    plt.rcParams[\"font.size\"] = 18\n    plt.plot(pivot[\"day\"], pivot[9], label=\"September\")\n    plt.plot(pivot[\"day\"], pivot[10], label=\"October\")\n    plt.xlabel(\"day\")\n    plt.ylabel(\"count\")\n    plt.legend(facecolor=\"white\")","294ae076":"%%time\n# Visualization, per day count\nwith plt.style.context(\"fivethirtyeight\"):\n    plt.figure(figsize=(10,6))\n    plt.rcParams[\"font.size\"] = 18\n    plt.plot(pivot[\"day\"], pivot[11], label=\"November\")\n    plt.plot(pivot[\"day\"], pivot[12], label=\"December\")\n    plt.xlabel(\"day\")\n    plt.ylabel(\"count\")\n    plt.legend(facecolor=\"white\")","20a4ae3b":"%%time\n### Call type\nfig = px.histogram(train, x='CALL_TYPE', color='CALL_TYPE', color_discrete_sequence=[primary_blue, primary_grey],)\nfig.update_layout(\n    title_text='Call Type Distribution', # title of plot\n    xaxis_title_text='Call Type', # xaxis label\n    yaxis_title_text='Count', # yaxis label\n    bargap=0.2, # gap between bars of adjacent location coordinates\n    paper_bgcolor=primary_bgcolor,\n    plot_bgcolor=primary_bgcolor,\n)\nfig.show()","d6f94967":"%%time\n# Checking Missing Values\nnan_data = (train.isna().sum().sort_values(ascending=False) \/ len(train) * 100)[:9]\nfig, ax = plt.subplots(1,1,figsize=(12, 5))\n\nax.bar(nan_data.index, 100, color=primary_grey, width=0.6)\n\nbar = ax.bar(\n    nan_data.index, \n    nan_data, \n    color=primary_blue, \n    width=0.6\n)\nax.bar_label(bar, fmt='%.01f %%')\nax.spines.left.set_visible(False)\nax.set_yticks([])\nax.set_title('Missing value Ratio', fontweight='bold')\n\nplt.show()","3deaab81":"%%time\n# First longitude\nlists_1st_lon = []\nfor i in range(0,len(train[\"POLYLINE\"])):\n    if train[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_1st_lon.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", train[\"POLYLINE\"][i]).split(\",\")[0]\n        lists_1st_lon.append(k)\n        \ntrain[\"lon_1st\"] = lists_1st_lon\n\n# First latitude\nlists_1st_lat = []\nfor i in range(0,len(train[\"POLYLINE\"])):\n    if train[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_1st_lat.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", train[\"POLYLINE\"][i]).split(\",\")[1]\n        lists_1st_lat.append(k)\n        \ntrain[\"lat_1st\"] = lists_1st_lat","245d6820":"%%time\n# Last longitude\nlists_last_lon = []\nfor i in range(0,len(train[\"POLYLINE\"])):\n        if train[\"POLYLINE\"][i] == '[]':\n            k=0\n            lists_last_lon.append(k)\n        else:\n            k = re.sub(r\"[[|[|]|]|]]\", \"\", train[\"POLYLINE\"][i]).split(\",\")[-2]\n            lists_last_lon.append(k)\n\ntrain[\"lon_last\"] = lists_last_lon\n\n# Last latitude\nlists_last_lat = []\nfor i in range(0,len(train[\"POLYLINE\"])):\n    if train[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_last_lat.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", train[\"POLYLINE\"][i]).split(\",\")[-1]\n        lists_last_lat.append(k)\n        \ntrain[\"lat_last\"] = lists_last_lat","578c1fbc":"%%time\n# Delete lon & lat have \"0\".\ntrain = train.query(\"lon_last != 0\")","29267987":"%%time\ntrain[\"lon_1st\"] = [float(k) for k in train[\"lon_1st\"]]\ntrain[\"lat_1st\"] = [float(k) for k in train[\"lat_1st\"]]\ntrain[\"lon_last\"] = [float(k) for k in train[\"lon_last\"]]\ntrain[\"lat_last\"] = [float(k) for k in train[\"lat_last\"]]","264efee9":"%%time\n# Visualization, sampling 5000 datas.\nmapping_1st = pd.DataFrame({\n    \"date\":train.head(5000)[\"data_time\"].values,\n    \"lat\":train.head(5000)[\"lat_1st\"].values,\n    \"lon\":train.head(5000)[\"lon_1st\"].values\n})\n\nmapping_last = pd.DataFrame({\n    \"date\":train.head(5000)[\"data_time\"].values,\n    \"lat\":train.head(5000)[\"lat_last\"].values,\n    \"lon\":train.head(5000)[\"lon_last\"].values\n})\n\npor_map = folium.Map(location=[41.141412,-8.590324], tiles='Stamen Terrain', zoom_start=11)\n\nfor i, r in mapping_1st.iterrows():\n    folium.CircleMarker(location=[r[\"lat\"],r[\"lon\"]], radius=0.5, color=\"red\").add_to(por_map)\n\nfor i, r in mapping_last.iterrows():\n    folium.CircleMarker(location=[r[\"lat\"],r[\"lon\"]], radius=0.5, color=\"blue\").add_to(por_map)    \n    \npor_map\n","54fa0bc5":"%%time\n# First longitude\nlists_1st_lon = []\nfor i in range(0,len(test[\"POLYLINE\"])):\n    if test[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_1st_lon.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", test[\"POLYLINE\"][i]).split(\",\")[0]\n        lists_1st_lon.append(k)\n        \ntest[\"lon_1st\"] = lists_1st_lon\n\n# First latitude\nlists_1st_lat = []\nfor i in range(0,len(test[\"POLYLINE\"])):\n    if test[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_1st_lat.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", test[\"POLYLINE\"][i]).split(\",\")[1]\n        lists_1st_lat.append(k)\n        \ntest[\"lat_1st\"] = lists_1st_lat","0af9958e":"%%time\n# Last longitude\nlists_last_lon = []\nfor i in range(0,len(test[\"POLYLINE\"])):\n        if test[\"POLYLINE\"][i] == '[]':\n            k=0\n            lists_last_lon.append(k)\n        else:\n            k = re.sub(r\"[[|[|]|]|]]\", \"\", test[\"POLYLINE\"][i]).split(\",\")[-2]\n            lists_last_lon.append(k)\n\ntest[\"lon_last\"] = lists_last_lon\n\n# Last latitude\nlists_last_lat = []\nfor i in range(0,len(test[\"POLYLINE\"])):\n    if test[\"POLYLINE\"][i] == '[]':\n        k=0\n        lists_last_lat.append(k)\n    else:\n        k = re.sub(r\"[[|[|]|]|]]\", \"\", test[\"POLYLINE\"][i]).split(\",\")[-1]\n        lists_last_lat.append(k)\n        \ntest[\"lat_last\"] = lists_last_lat","0b3916f8":"%%time\n# changin type str \u21d2 float\ntest[\"lon_1st\"] = [float(k) for k in test[\"lon_1st\"]]\ntest[\"lat_1st\"] = [float(k) for k in test[\"lat_1st\"]]\ntest[\"lon_last\"] = [float(k) for k in test[\"lon_last\"]]\ntest[\"lat_last\"] = [float(k) for k in test[\"lat_last\"]]","304ab232":"%%time\n\n# Create delta parameter\ntrain[\"delta_lon\"] = train[\"lon_last\"] - train[\"lon_1st\"]\ntrain[\"delta_lat\"] = train[\"lat_last\"] - train[\"lat_1st\"]\n\ntest[\"delta_lon\"] = test[\"lon_last\"] - test[\"lon_1st\"]\ntest[\"delta_lat\"] = test[\"lat_last\"] - test[\"lat_1st\"]","bbf42676":"%%time\n# sampling : 5,000 point\nsample = train.head(5000)\n\nwith plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(1,3,figsize=(20, 6))\n    \n    # plot\n    ax[0].scatter(sample[\"delta_lon\"], sample[\"delta_lat\"], s=3, c=\"red\")\n    ax[0].set_xlabel(\"delta longitude\")\n    ax[0].set_ylabel(\"delta_latitude\")\n    \n    # delta longitude distribution\n    ax[1].hist(sample[\"delta_lon\"], bins=30, color=\"red\")\n    ax[1].set_xlabel(\"delta longitude\")\n    ax[1].set_ylabel(\"count\")\n    ax[1].set_yscale(\"log\")\n    \n    # delta latitude distribution\n    ax[2].hist(sample[\"delta_lat\"], bins=30, color=\"red\")\n    ax[2].set_xlabel(\"delta latitude\")\n    ax[2].set_ylabel(\"count\")\n    ax[2].set_yscale(\"log\")","53153ec1":"%%time\n# monthly, delta longtitude & latitude boxplot\ntrain[\"month_str\"] = [str(i) for i in train[\"month\"]]","e9e0a432":"%%time\nwith plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(1,2, figsize=(20,6))\n    # delta_lon\n    sns.boxplot(\"month_str\", \"delta_lon\", data=train, ax=ax[0])\n    ax[0].set_xlabel(\"month\")\n    ax[0].set_ylabel(\"delta_lon\")\n    ax[0].set_ylim([-0.3,0.3])\n    # delta_lat\n    sns.boxplot(\"month_str\", \"delta_lat\", data=train, ax=ax[1])\n    ax[1].set_xlabel(\"month\")\n    ax[1].set_ylabel(\"delta_lon\")\n    ax[1].set_ylim([-0.3,0.3])","33354c47":"%%time\n# weekday, delta longtitude & latitude boxplot\ntrain[\"weekday_str\"] = [str(i) for i in train[\"weekday\"]]","d33b3734":"%%time\nwith plt.style.context(\"fivethirtyeight\"):\n    fig, ax = plt.subplots(1,2, figsize=(20,6))\n    # delta_lon\n    sns.boxplot(\"weekday_str\", \"delta_lon\", data=train, ax=ax[0])\n    ax[0].set_xlabel(\"weekday\\n (0:Monday ~ 6:Sunday)\")\n    ax[0].set_ylabel(\"delta_lon\")\n    ax[0].set_ylim([-0.3,0.3])\n    # delta_lat\n    sns.boxplot(\"weekday_str\", \"delta_lat\", data=train, ax=ax[1])\n    ax[1].set_xlabel(\"weekday\\n (0:Monday ~ 6:Sunday)\")\n    ax[1].set_ylabel(\"delta_lon\")\n    ax[1].set_ylim([-0.3,0.3])","ad3c1088":"%%time\n# copy dataframe\ndf_ml = train.copy()\n\n# outlier is dropped\ndf_ml = df_ml.query(\"delta_lon <= 0.2 & delta_lon >= -0.2 & delta_lat <= 0.2 & delta_lat >= -0.2\")\n\n","5daf7e48":"%%time\n# Call type <= 0.2 & delta_lon>=\nmap_call = {\"A\":1, \"B\":2, \"C\":3}\ndf_ml[\"Call_type\"] = df_ml[\"CALL_TYPE\"].map(map_call)\n\n# Origin_call\ndef origin_call_flg(x):\n    if x[\"ORIGIN_CALL\"] == None:\n        res = 0\n    else:\n        res = 1\n    return res\ndf_ml[\"ORIGIN_CALL\"] = df_ml.apply(origin_call_flg, axis=1)\n\n# Origin_stand\ndef origin_stand_flg(x):\n    if x[\"ORIGIN_STAND\"] == None:\n        res = 0\n    else:\n        res=1\n    return res\ndf_ml[\"ORIGIN_STAND\"] = df_ml.apply(origin_stand_flg, axis=1)\n\n# Day type\ndf_ml.drop(\"DAY_TYPE\", axis=1, inplace=True)\n\n# Missing data\ndef miss_flg(x):\n    if x[\"MISSING_DATA\"] == \"False\":\n        res = 0\n    else:\n        res = 1\n    return res\ndf_ml[\"MISSING_DATA\"] = df_ml.apply(miss_flg, axis=1)","5aefb845":"%%time\ndf_ml = df_ml.sample(50000)","bedeec4f":"%%time\nX = df_ml[[\"Call_type\", 'ORIGIN_CALL', 'ORIGIN_STAND', 'MISSING_DATA', 'lon_1st', 'lat_1st', 'delta_lon', 'delta_lat']]","d7f0d967":"%%time\ny = df_ml[[\"lon_last\",\"lat_last\"]]","92a40070":"%%time\n# copy dataframe\ndf_ml_t = test.copy()\n\n# Call type <= 0.2 & delta_lon>=\nmap_call = {\"A\":1, \"B\":2, \"C\":3}\ndf_ml_t[\"Call_type\"] = df_ml_t[\"CALL_TYPE\"].map(map_call)\n\n# Origin_call\ndf_ml_t[\"ORIGIN_CALL\"] = df_ml_t.apply(origin_call_flg, axis=1)\n\n# Origin_stand\ndf_ml_t[\"ORIGIN_STAND\"] = df_ml_t.apply(origin_stand_flg, axis=1)\n\n# Day type\ndf_ml_t.drop(\"DAY_TYPE\", axis=1, inplace=True)\n\n# Missing data\ndf_ml_t[\"MISSING_DATA\"] = df_ml_t.apply(miss_flg, axis=1)\n","8f65ae3d":"%%time\nX_Test = df_ml_t[[\"Call_type\", 'ORIGIN_CALL', 'ORIGIN_STAND', 'MISSING_DATA', 'lon_1st', 'lat_1st', 'delta_lon', 'delta_lat']]","d6778185":"%%time\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=1)","ac19dc70":"%%time\nforest = MultiOutputRegressor(RandomForestRegressor(n_estimators=100, random_state=1))\n\n# Fitting\nforest = forest.fit(X_train, y_train)\ny_train_pred = forest.predict(X_train)\ny_test_pred = forest.predict(X_test)\n\n# Make predictions on test data using the model trained on original data\n\n# Performance metrics\n\nprint(\"Mean Square Error on training Data:{}\".format(mean_squared_error(y_train, y_train_pred)))\nprint(\"Mean Square Error on testting Data:{}\".format(mean_squared_error(y_test, y_test_pred)))\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred)))\nprint(\"R2 score test:{}\".format(r2_score(y_test, y_test_pred)))\n\ny_Test_pred = forest.predict(X_Test)","b21dca5d":"bosting = MultiOutputRegressor(GradientBoostingRegressor(random_state=0))\n\n# Fitting\nbosting = bosting.fit(X_train, y_train)\ny_train_pred2 = bosting.predict(X_train)\ny_test_pred2 = bosting.predict(X_test)\n\n# Evaluation\nprint(\"Mean Square Error on training Data:{}\".format(mean_squared_error(y_train, y_train_pred2)))\nprint(\"Mean Square Error on testing Data:{}\".format(mean_squared_error(y_test, y_test_pred2)))\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred2)))\nprint(\"R2 score test:{}\".format(r2_score(y_test, y_test_pred2)))\ny_Test_pred2 = bosting.predict(X_Test)\ny_Test_pred2[2]","856309b1":"lr = MultiOutputRegressor(LinearRegression(n_jobs=1))\n\n# Fitting\nlr = lr.fit(X_train, y_train)\ny_train_pred4 = lr.predict(X_train)\ny_test_pred4 = lr.predict(X_test)\n\n# Evaluation\nprint(\"Mean Square Error on training Data:{}\".format(mean_squared_error(y_train, y_train_pred4)))\nprint(\"Mean Square Error on testing Data:{}\".format(mean_squared_error(y_test, y_test_pred4)))\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred4)))\nprint(\"R2 score test:{}\".format(r2_score(y_test, y_test_pred4)))\ny_Test_pred4 = bosting.predict(X_Test)\ny_Test_pred4[4]","96109170":"knn = MultiOutputRegressor(KNeighborsRegressor())\n\n# Fitting\nknn = knn.fit(X_train, y_train)\ny_train_pred5 = knn.predict(X_train)\ny_test_pred5 = knn.predict(X_test)\n\n# Evaluation\nprint(\"Mean Square Error on training Data:{}\".format(mean_squared_error(y_train, y_train_pred5)))\nprint(\"Mean Square Error on testing Data:{}\".format(mean_squared_error(y_test, y_test_pred5)))\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred5)))\nprint(\"R2 score test:{}\".format(r2_score(y_test, y_test_pred5)))\ny_Test_pred5 = bosting.predict(X_Test)\ny_Test_pred5[5]","30b2e645":"dt = MultiOutputRegressor(DecisionTreeRegressor(max_depth=50, random_state=1))\n\n# Fitting\ndt = dt.fit(X_train, y_train)\ny_train_pred6 = dt.predict(X_train)\ny_test_pred6 = dt.predict(X_test)\n\n# Evaluation\nprint(\"Mean Square Error on training Data:{}\".format(mean_squared_error(y_train, y_train_pred6)))\nprint(\"Mean Square Error on testing Data:{}\".format(mean_squared_error(y_test, y_test_pred6)))\nprint(\"R2 score train:{}\".format(r2_score(y_train, y_train_pred6)))\nprint(\"R2 score test:{}\".format(r2_score(y_test, y_test_pred6)))\ny_Test_pred6 = bosting.predict(X_Test)\ny_Test_pred6[5]","2a51a444":"%%time\nsubmit_lat = y_Test_pred4.T[1]\nsubmit_lon = y_Test_pred4.T[0]","dee798ef":"%%time\nsubmit = pd.DataFrame({\"TRIP_ID\":test[\"TRIP_ID\"], \"LATITUDE\":submit_lat, \"LONGITUDE\":submit_lon})","553fccf2":"submit.to_csv('submission.csv', index=False)\nsub = pd.read_csv(\".\/submission.csv\")\nsub.head(5)","84fc1d55":" 4.5 Decision Tree for Multioutput Regression","b0cd4969":" 4.2 Gradient Boosting Regressor","3b63380b":"Call type : A: 1, B: 2, C:3","cae9850b":"Sampling 1st & last ride coordinate and last coordinate","ba235c3b":"Data Description","e92a5207":"# 3. Data Preprocessing","75055ebe":"# 1. Loading the Data","09720332":"Test set preprocessing","d8f255af":"Call type","b31e6eb9":"Weekday distribution","2d7df71d":"# 5. Submission","d76f9d15":"# 4. Buliding Machine learning Models","3211f40a":"Time series visualization","7a759978":" 4.3 Linear Regression for Multioutput Regression","29039a87":"\ntrain test split","38cab384":" 4.1 Random Forest Regressor","9669baa7":"Training set preprocessing","71d9e4f7":"# 2. Exploratory Data Analysis","8a00e000":"Distribution of travel distance and direction\n\ndelta_lon = lon_last - lon_1st\ndelta_lat = lat_last - kat_last","abc2741a":" 4.4 k-Nearest Neighbors for Multioutput Regression"}}