{"cell_type":{"e3b8e86c":"code","5e9f8a71":"code","e99b2c50":"code","d05cd024":"code","aa53d141":"code","5ae2a5d0":"code","ef13ac96":"code","3c85ead6":"code","b2c1df9d":"code","b4d231b3":"code","f484537d":"code","16b543f3":"code","bc4ac2fb":"code","c7b00ad8":"code","c327a677":"code","68f0c7b2":"code","8846498e":"code","921a3f0c":"code","7c87cc68":"code","43c8df63":"code","bec38bc5":"code","e83913e6":"code","8558c0e8":"code","1d0daf31":"code","eb99fdde":"code","949dbf29":"code","f1aa548c":"code","98c68911":"code","2ea04475":"markdown","068c56c4":"markdown","caa143ff":"markdown","840135a1":"markdown","1fe750ee":"markdown","ddc935d8":"markdown","8aef9dde":"markdown","2d606e2f":"markdown","8dc84a88":"markdown","2d7f2a56":"markdown"},"source":{"e3b8e86c":"import pandas as pd\nimport numpy as np\n\nimport os\nfrom PIL import Image\n\nimport torch\nfrom torch.utils.data.dataset import Dataset\nfrom torch.utils.data import DataLoader\nfrom torchvision import transforms\nfrom torch import nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.autograd import Variable\n\nimport torch\nfrom torch.utils.tensorboard import SummaryWriter\nwriter = SummaryWriter()\n\nfrom sklearn.preprocessing import MultiLabelBinarizer","5e9f8a71":"def set_device():\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n    if device != \"cuda\":\n        print(\"WARNING: For this notebook to perform best, \"\n            \"if possible, in the menu under `Runtime` -> \"\n            \"`Change runtime type.`  select `GPU` \")\n    else:\n        print(\"GPU is enabled in this notebook.\")\n    return device","e99b2c50":"#@title Set random seed\n\n#@markdown Executing `set_seed(seed=seed)` you are setting the seed\n\n# for DL its critical to set the random seed so that students can have a\n# baseline to compare their results to expected results.\n# Read more here: https:\/\/pytorch.org\/docs\/stable\/notes\/randomness.html\n\n# Call `set_seed` function in the exercises to ensure reproducibility.\nimport random\nimport torch\n\ndef set_seed(seed=None, seed_torch=True):\n    if seed is None:\n        seed = np.random.choice(2 ** 32)\n    random.seed(seed)\n    np.random.seed(seed)\n    if seed_torch:\n        torch.manual_seed(seed)\n        torch.cuda.manual_seed_all(seed)\n        torch.cuda.manual_seed(seed)\n        torch.backends.cudnn.benchmark = False\n        torch.backends.cudnn.deterministic = True\n\n    print(f'Random seed {seed} has been set.')","d05cd024":"SEED = 2021\nset_seed(seed=SEED)\nDEVICE = set_device()","aa53d141":"IMG_PATH = '..\/input\/planets-dataset\/planet\/planet\/train-jpg\/'\nIMG_EXT = '.jpg'\nTRAIN_DATA = '..\/input\/planet-understanding-the-amazon-from-space\/train_v2.csv\/train_v2.csv'","5ae2a5d0":"class KaggleAmazonDataset(Dataset):\n    \"\"\"Dataset wrapping images and target labels for Kaggle - Planet Amazon from Space competition.\n\n    Arguments:\n        A CSV file path\n        Path to image folder\n        Extension of images\n        PIL transforms\n    \"\"\"\n\n    def __init__(self, csv_path, img_path, img_ext, transform=None):\n    \n        tmp_df = pd.read_csv(csv_path)\n        assert tmp_df['image_name'].apply(lambda x: os.path.isfile(img_path + x + img_ext)).all(), \\\n\"Some images referenced in the CSV file were not found\"\n        \n        self.mlb = MultiLabelBinarizer()\n        self.img_path = img_path\n        self.img_ext = img_ext\n        self.transform = transform\n\n        self.X_train = tmp_df['image_name']\n        self.y_train = self.mlb.fit_transform(tmp_df['tags'].str.split()).astype(np.float32)\n\n    def __getitem__(self, index):\n        img = Image.open(self.img_path + self.X_train[index] + self.img_ext)\n        img = img.convert('RGB')\n        if self.transform is not None:\n            img = self.transform(img)\n        \n        label = torch.from_numpy(self.y_train[index])\n        return img, label\n\n    def __len__(self):\n        return len(self.X_train.index)","ef13ac96":"transformations = transforms.Compose([transforms.ToTensor()])\ndataset = KaggleAmazonDataset(TRAIN_DATA,IMG_PATH,IMG_EXT)#,transformations)","3c85ead6":"class MyDataset(Dataset):\n    def __init__(self, subset, transform=None):\n        self.subset = subset\n        self.transform = transform\n        \n    def __getitem__(self, index):\n        x, y = self.subset[index]\n        if self.transform:\n            x = self.transform(x)\n        return x, y\n        \n    def __len__(self):\n        return len(self.subset)","b2c1df9d":"train_size = int(0.8 * len(dataset))\nval_size = len(dataset) - train_size\ntrain_dataset, val_dataset = torch.utils.data.random_split(dataset, [train_size, val_size])","b4d231b3":"train_stand = MyDataset(\n    train_dataset, transform = transforms.Compose([transforms.ToTensor(),\n                                                transforms.Normalize([0.3117, 0.3408, 0.2991], [0.1669, 0.1436, 0.1372])])\n)\n\nval_stand = MyDataset(\n    val_dataset, transform = transforms.Compose([transforms.ToTensor(),\n                                                transforms.Normalize([0.3117, 0.3408, 0.2991], [0.1669, 0.1436, 0.1372])])\n)","f484537d":"train_loader = DataLoader(train_stand,\n                          batch_size=16,\n                          num_workers=1, # 1 for CUDA\n                          pin_memory=True # CUDA only\n                         )\n\nval_loader = DataLoader(val_stand,\n                          batch_size=16,\n                          num_workers=1, # 1 for CUDA\n                          pin_memory=True # CUDA only\n                         )","16b543f3":"test_loader = DataLoader(val_stand,\n                          batch_size=1,\n                          shuffle = False,\n                          num_workers=1, # 1 for CUDA\n                          pin_memory=True # CUDA only\n                         )","bc4ac2fb":"del train_loader\ndel val_loader\ndel train_stand\ndel val_stand\n\ntorch.cuda.empty_cache()","c7b00ad8":"val_rot = MyDataset(\n    val_dataset, transform = transforms.Compose([transforms.ToTensor(),\n                                                transforms.Normalize([0.3117, 0.3408, 0.2991], [0.1669, 0.1436, 0.1372]),\n                                                transforms.RandomRotation(degrees=5)])\n)\n\ntest_loader = DataLoader(val_rot,\n                          batch_size=1,\n                          shuffle = False,\n                          num_workers=1, # 1 for CUDA\n                          pin_memory=True # CUDA only\n                         )","c327a677":"del train_rot\ndel val_rot\ntorch.cuda.empty_cache()","68f0c7b2":"val_rot = MyDataset(\n    val_dataset, transform = transforms.Compose([transforms.ToTensor(),\n                                                transforms.Normalize([0.3117, 0.3408, 0.2991], [0.1669, 0.1436, 0.1372]),\n                                                transforms.RandomRotation(degrees=355)])\n)\n\ntest_loader = DataLoader(val_rot,\n                          batch_size=1,\n                          shuffle = False,\n                          num_workers=1, # 1 for CUDA\n                          pin_memory=True # CUDA only\n                         )","8846498e":"del val_rot\ntorch.cuda.empty_cache()","921a3f0c":"val_gray = MyDataset(\n    val_dataset, transform = transforms.Compose([transforms.ToTensor(),\n                                                transforms.Normalize([0.3117, 0.3408, 0.2991], [0.1669, 0.1436, 0.1372]),\n                                                transforms.Grayscale(num_output_channels=3)])\n)\n\ntest_loader = DataLoader(val_gray,\n                          batch_size=1,\n                          shuffle = False,\n                          num_workers=1, # 1 for CUDA\n                          pin_memory=True # CUDA only\n                         )","7c87cc68":"labels_df = pd.read_csv('..\/input\/planet-understanding-the-amazon-from-space\/train_v2.csv\/train_v2.csv')\n\nfrom itertools import chain\nlabels_list = list(chain.from_iterable([tags.split(\" \") for tags in labels_df['tags'].values]))\nlabels_set = set(labels_list)\n\nlabels = sorted(labels_set)\nlabels_map = {l: i for i, l in enumerate(labels)}\ny_map = {v: k for k, v in labels_map.items()}","43c8df63":"labels_img = labels","bec38bc5":"class Flatten(nn.Module):\n\n    def __init__(self):\n        super(Flatten, self).__init__()\n\n    def forward(self, x):\n        shape = torch.prod(torch.tensor(x.shape[1:])).item()\n        return x.view(-1, shape)","e83913e6":"import torchvision\n# 100352\nmodel = torchvision.models.resnet50(pretrained=False)\nupdated_model = torch.nn.Sequential(*(list(model.children())[:-2]), Flatten(), nn.Linear(256 * 256 * 2, 128), nn.ReLU(),\n                           nn.Dropout(p=0.2), nn.Linear(128, 17))\n\n\nupdated_model = updated_model.to(DEVICE)\n# model.load_state_dict(torch.load('..\/input\/trained-model\/saved_model.pth'))","8558c0e8":"optimizer = optim.AdamW(updated_model.parameters(), lr=0.0001, weight_decay = 0.00001)","1d0daf31":"from sklearn.metrics import f1_score\n\ndef train(epoch, device):\n    \n    updated_model.train()\n    print('EPOCH: ' + str(epoch))\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        optimizer.zero_grad()\n        output = updated_model(data)\n        \n        loss = F.binary_cross_entropy_with_logits(output, target)\n        loss.backward()\n        optimizer.step()\n        \n        if batch_idx % 100 == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.data))\n    \n    print('Validation:')\n    updated_model.eval()\n    for batch_idx1, (data1, labels1) in enumerate(val_loader):\n        \n        data1, labels1 = data1.to(device), labels1.to(device)\n        target1 = updated_model(data1)\n        \n        loss1 = F.binary_cross_entropy_with_logits(target1,labels1)\n        \n        if batch_idx1 % 100 == 0:\n            print('Validation Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx1 * len(data1), len(val_loader.dataset),\n                100. * batch_idx1 \/ len(val_loader), loss1.data))\n                \n    if epoch % 5 == 0:\n\n        torch.save(updated_model.state_dict(), 'saved_model.pth')","eb99fdde":"#device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n\nfor epoch in range(1, 6):\n    train(epoch, device=DEVICE)","949dbf29":"from matplotlib import pyplot as plt\nactual = []\npreds = []\n\nupdated_model.eval()\nfor data, label in test_loader:\n    image, target = data.to(DEVICE), label.to(DEVICE)\n    # get all the index positions where value == 1\n    target_indices = [i for i in range(len(target[0])) if target[0][i] == 1]\n    # get the predictions by passing the image through the model\n    #outputs = model(image.unsqueeze(0))#.to(DEVICE))\n    outputs = updated_model(image)\n    outputs = torch.sigmoid(outputs)\n    outputs = outputs.detach().cpu()\n    #sorted_indices = np.argsort(outputs[0])\n    preds.append(outputs)\n    actual.append(target)\n#     best = sorted_indices[-3:]\n#     string_predicted = ''\n#     string_actual = ''\n#     for i in range(len(best)):\n#         string_predicted += f\"{labels_img[best[i]]}    \"\n#     for i in range(len(target_indices)):\n#         string_actual += f\"{labels_img[target_indices[i]]}    \"\n#     image = image.squeeze(0)\n#     image = image.detach().cpu().numpy()\n#     image = np.transpose(image, (1, 2, 0))\n#     plt.imshow(image)\n#     plt.axis('off')\n#     plt.title(f\"PREDICTED: {string_predicted}\\nACTUAL: {string_actual}\")\n#     #plt.savefig(f\"..\/outputs\/inference_{counter}.jpg\")\n#     plt.show()","f1aa548c":"res = []\nfor i in range(0, len(preds)):\n    res.append(np.where(preds[i].numpy()[0] > 0.3, 1, 0))\n\nact = []\nfor i in range(0, len(actual)):\n    act.append(actual[i].cpu().detach().numpy()[0])\n    \n\nfrom sklearn.metrics import fbeta_score\n\nfbeta_score(act, res, average='samples', beta=2)","98c68911":"# import os\n# from pathlib import Path\n\n# TEST_IMG_PATH = '..\/input\/planets-dataset\/planet\/planet\/test-jpg\/'\n# TEST_IMG_EXT = '.jpg'\n# SUBMISSION_FILE = '..\/input\/planets-dataset\/planet\/planet\/sample_submission.csv'\n# SUB_MAPPING = '..\/input\/planet-understanding-the-amazon-from-space\/test_v2_file_mapping.csv\/test_v2_file_mapping.csv'\n\n# sub = pd.read_csv(SUBMISSION_FILE)\n# # os.listdir('..\/working\/')\n# #sub = pd.DataFrame()\n# model.eval()\n# for index in range(len(sub)):\n#     my_file = Path(TEST_IMG_PATH + sub['image_name'][index] + TEST_IMG_EXT)\n#     if my_file.is_file():\n#         img = Image.open(TEST_IMG_PATH + sub['image_name'][index] + TEST_IMG_EXT)\n#         img = img.convert('RGB')\n#         img = transformations(img)\n#         Y_ = model(img.unsqueeze(0).to(DEVICE))\n#         sub['tags'][index] = ' '.join(list(dataset.mlb.inverse_transform(np.where(Y_.cpu().detach().numpy() > 0.5, 1, 0))[0]))\n#     else:\n#         next\n        \n#     if index % 20 == 0:\n#         print('{} Files Completed!')","2ea04475":"# Import Data","068c56c4":"## Train","caa143ff":"# Rotate Images 5 Degrees","840135a1":"# Train test split","1fe750ee":"# Create Model","ddc935d8":"# Rotate Images 355 degrees","8aef9dde":"# Grayscale Images","2d606e2f":"---------------------","8dc84a88":"# Standardize Only","2d7f2a56":"## Test"}}