{"cell_type":{"fee0f1a8":"code","bae32d9a":"code","e908220d":"code","f7aec451":"code","59010389":"code","f6305369":"code","ccb43714":"code","47700fc6":"code","151b2df9":"code","5f70a2ec":"code","858d7e13":"code","ebbd789d":"code","9d6b8ca8":"code","ebb36478":"code","0bc52120":"code","c8d852d1":"code","4d110c78":"markdown","3270744e":"markdown","d21e7e75":"markdown","a8add58d":"markdown","32f3e709":"markdown","705b61f7":"markdown","3e3162bb":"markdown","fc436171":"markdown","fcc80572":"markdown","fa27646c":"markdown","7b9d47fa":"markdown","c057207c":"markdown","d72b8dad":"markdown","befb5130":"markdown","c13e05f0":"markdown"},"source":{"fee0f1a8":"import torch\nimport torch.nn as nn\nimport torchvision.datasets as datasets\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nfrom PIL import Image\nfrom tqdm import tqdm\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms\nfrom torch.nn.init import kaiming_normal_ as he_init\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","bae32d9a":"!rm -rf data\n!mkdir data\n!wget -P data -O data\/concrete_data.zip https:\/\/s3-api.us-geo.objectstorage.softlayer.net\/cf-courses-data\/CognitiveClass\/DL0321EN\/data\/images\/concrete_crack_images_for_classification.zip\n!unzip -q -d data data\/concrete_data.zip","e908220d":"# class Data(Dataset):\n#     def __init__(self, transforms, train = False):\n#         self.x = torch.zeros(1)\n#         self.y = torch.zeros(1)\n        \n#         negative_file_path = os.path.join('concrete_class\/', 'Negative')\n#         negative_files = [file for file in os.listdir(negative_file_path) if file.endswith('.jpg')]\n#         negative_files.sort()\n#         positive_file_path = os.path.join('concrete_class\/', 'Positive')\n#         positive_files = [file for file in os.listdir(positive_file_path) if file.endswith('.jpg')]\n#         positive_files.sort()\n#         print(negative_files[0], type(negative_files[0]))\n        \n#         if train:\n#             self.x = torch.zeros(36000, 1)\n#             for i in range(36000):\n#                 self.x[i] = transforms(negative_files[i]) if i < 18000 else transforms(negative_files[i])\n#             self.y = torch.zeros(36000, 1, dtype = 'uint8')\n#             self.y[18000:, :] = 1\n#         else:\n#             self.x = torch.zeros(4000, 1)\n#             for i in range(4000):\n#                 self.x[i] = transforms(negative_files[i + 36000]) if i < 2000 else transforms(negative_files[i + 38000])\n#             self.y = torch.zeros(4000, 1, dtype = 'uint8')\n#             self.y[2000:, :] = 1\n        \n#     def __getitem__(self, index):\n#         return self.y[index], self.x[index]\n#     def __len__(self):\n#         return self.y.shape[0]","f7aec451":"class CNN(nn.Module):\n    def __init__(self, input_channels = 3, out_1 = 16, out_2 = 32, out_3 = 64):\n        super(CNN, self).__init__()\n        \n        self.conv_l1 = nn.Sequential(\n            nn.Conv2d(in_channels = input_channels, out_channels = out_1, kernel_size = 10), # Changed input_channels\n#             nn.Dropout2d(p = 0.35, inplace = True),\n            nn.MaxPool2d(kernel_size = 8, stride = 2),\n            nn.BatchNorm2d(out_1, momentum = 0.8),\n            nn.ReLU()\n        )\n        \n        self.conv_l2 = nn.Sequential(\n            nn.Conv2d(in_channels = out_1, out_channels = out_2, kernel_size = 8),\n#             nn.Dropout2d(p = 0.35, inplace = True),\n            nn.MaxPool2d(kernel_size = 6, stride = 2),\n            nn.BatchNorm2d(out_2, momentum = 0.8),\n            nn.ReLU()\n        )\n        \n        self.conv_l3 = nn.Sequential(\n            nn.Conv2d(in_channels = out_2, out_channels = out_3, kernel_size = 6),\n#             nn.Dropout2d(p = 0.35, inplace = True),\n            nn.MaxPool2d(kernel_size = 2, stride = 2),\n            nn.BatchNorm2d(out_3, momentum = 0.8),\n            nn.ReLU()\n        )\n        # Added conv_l4\n        self.conv_l4 = nn.Sequential(\n            nn.Conv2d(in_channels = out_3, out_channels = 96, kernel_size = 4),\n            nn.MaxPool2d(kernel_size = 2, stride = 2),\n#             nn.Dropout2d(p = 0.35, inplace = True),\n            nn.BatchNorm2d(96, momentum = 0.4),\n            nn.ReLU(),\n            nn.Flatten()\n        )\n        \n        self.fully_connected = nn.Sequential(\n            nn.Linear(384, 150),\n            nn.Dropout(p = 0.35, inplace = True),\n            nn.ReLU(),\n            nn.Linear(150, 100),\n            nn.Dropout(p = 0.35, inplace = True),\n            nn.Linear(100, 100),\n            nn.ReLU(),\n#             nn.Dropout(p = 0.1, inplace = True),\n#             nn.ReLU(),\n            nn.Linear(100, 10)\n        )\n\n    def forward(self, x):\n        x = self.conv_l1(x)\n        x = self.conv_l2(x)\n        x = self.conv_l3(x)\n        x = self.conv_l4(x)\n        x = self.fully_connected(x)\n        return x","59010389":"if torch.cuda.is_available():\n    device = torch.device('cuda:0')\n    print(torch.cuda.get_device_name(0), torch.cuda.current_device())\nelse:\n    device = torch.device('cpu')\ndevice","f6305369":"def train(model, criterion, optimizer, train_loader, val_loader, epochs):\n    loss_acc = {'training_loss': [], 'training_acc': [], 'validation_loss': [], 'validation_acc': []}\n    for epoch in range(epochs):\n        tr_acc = 0\n        tr_loss = 0\n        \n        print('Training epoch: {}...'.format(epoch))\n        for i, (x, y) in tqdm(enumerate(train_loader)):\n            optimizer.zero_grad()\n            z = model.forward(x)\n            loss = criterion(z, y)\n            loss.backward()\n            optimizer.step()\n            _, y_hat = torch.max(z, 1)\n            tr_acc += (y_hat == y).sum().item()\n            tr_loss += loss.data\n            loss_acc['training_loss'].append(loss.data)\n            loss_acc['training_acc'].append(100 * (tr_acc \/ (i + 1)))\n            \n        val_acc = 0\n        print('Validating...')\n        for i, (x, y) in tqdm(enumerate(val_loader)):\n            z = model.forward(x)\n            loss = criterion(z, y)\n            _, y_hat = torch.max(z, 1)\n            val_acc += (y_hat == y).sum().item()\n            loss_acc['validation_loss'].append(loss.data)\n            loss_acc['validation_acc'].append(100 * (val_acc \/ (i + 1)))\n        \n        print('Epoch: {} mean results, training loss: {}, validation accuracy: {}\\n'\n              .format(epoch + 1, tr_loss \/ len(train_loader), 100 * (val_acc \/ len(val_loader))))\n    return loss_acc","ccb43714":"def init_weights(layer):\n    if type(layer) == nn.Linear or type(layer) == nn.Conv2d:\n        he_init(layer.weight)","47700fc6":"class ToCudaTensor(transforms.ToTensor):\n    def __call__(self, image):\n        img = transforms.ToTensor()\n        img = img(image)\n        img = img.float().to(0)\n        return img\n    def __repr__(self):\n        return self.__class__.__name__ + '()'\n\n\nTransformTargets = lambda x: torch.tensor(x).to(device)","151b2df9":"from torch import multiprocessing\n\ntry:\n    multiprocessing.set_start_method('spawn')\nexcept RuntimeError:\n    print('Unable to execute spawn:', RuntimeError)\n\ntransformer = transforms.Compose([transforms.Resize((120, 120)), ToCudaTensor(), torch.nn.Sigmoid()]) # Got rid of grayscale, temporarily\nimages = datasets.ImageFolder(root = 'data', transform = transformer, target_transform = TransformTargets) #, transform = ToCudaTensor())\n# images = datasets.ImageFolder(root = 'data', transform = transforms.ToTensor())\n\ntrain_data, val_data = torch.utils.data.random_split(images, [36000, 4000])\n\ntrain_loader = DataLoader(train_data)#, batch_size = 1, shuffle = False, num_workers = 4, pin_memory = True)\nval_loader = DataLoader(val_data)#, batch_size = 1, shuffle = False, num_workers = 4, pin_memory = True)","5f70a2ec":"np.shape(images[0][0]), images[0]","858d7e13":"images.classes, type(train_data), type(val_data)","ebbd789d":"model = CNN()\nmodel = model.cuda(0)\nmodel = model.to(device)\nmodel.apply(init_weights)\ncriterion = torch.nn.CrossEntropyLoss()\noptimizer = torch.optim.Adam(model.parameters())\nepochs = 30\nmodel.modules","9d6b8ca8":"model_data = train(model, criterion, optimizer, train_loader, val_loader, epochs)","ebb36478":"plt.plot(model_data['training_loss'], label = 'loss')\nplt.plot(model_data['training_acc'], label = 'accuracy')\nplt.xticks([i + 1 for i in range(epochs)])\nplt.ylim(0, 100)\nplt.title('Training')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","0bc52120":"plt.plot(model_data['validation_loss'], label = 'loss')\nplt.plot(model_data['validation_acc'], label = 'accuracy')\nplt.xticks([i + 1 for i in range(epochs)])\nplt.ylim(0, 100)\nplt.title('Validation')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","c8d852d1":"torch.save(model.state_dict(), 'model')","4d110c78":"## Train function.\nThe train function returns an object with the validation accuracy\/loss and training accuracy\/loss.","3270744e":"## Training","d21e7e75":"## Training and validating the model.\nThe code below runs the model and validation, then saves the loss and accuracy for both in `model_data`.","a8add58d":"#### Function below needed to set the weights through the model's `.apply` method.","32f3e709":"## Getting a look at the data to make sure that it's properly normalized and formatted correctly.","705b61f7":"## Building the model.\nMaking sure that the model is running on the gpu with the method `cuda` and initializing the weights to kaiming, he. Setting the loss, optimizer and the number of epochs.","3e3162bb":"## Getting the data ready for the network.\nTransform the data, first resize then convert to `cuda.FloatTensor`. Then load everything up in `train_loader` and `val_loader`.","fc436171":"## Plotting the accuracy and loss for both training and validation.","fcc80572":"## Validation","fa27646c":"I had to custom make a transform from `ToTensor` so it could put all the images on the GPU.","7b9d47fa":"Checking for cuda and setting device to cuda or cpu if cuda is unavailable.","c057207c":"# Classifying images of concrete with crack and without cracks.","d72b8dad":"## The dataset, in raw image form.\n40,000 images total.\nHalf labeled positive, for concrete with cracks and the other half labeled negative, for concrete without cracks.\n\nRemove all data first, then download and unzip the data in the data folder.","befb5130":"### Dataset class\nAs it turns out I didn't need to create a dataset object and fiddle with the data myself, at least not very much. So I commented out the `class Data`, but just left it here anyways.","c13e05f0":"## Convolutional Neural Network.\nThis network has 3 convolutional layers, 2 fully connected layers and a fully connected output layer. Each convolutional layer has batch normalization and max-pooling and each fully connected layer has dropout except for the last."}}