{"cell_type":{"d1df102f":"code","12eaab81":"code","215e1144":"code","5c1d4176":"code","d9a6f00a":"code","082776e7":"code","ebb7e409":"code","a2241d28":"code","59e0162c":"code","0f389600":"code","62eccfdd":"code","97c1dd91":"code","4f558443":"code","beefec77":"code","e7f7122b":"code","117f3843":"code","5dfefe96":"code","ffa94c51":"code","5b7a4a85":"code","103ab674":"code","9a8d08cf":"code","551fb188":"code","7855bd2f":"code","79e65f02":"code","2dfeceec":"code","8d100339":"code","90af1a12":"code","b0e3f3d2":"code","4bca032a":"code","88757d07":"code","28c33b52":"code","901e5e9f":"code","d9976198":"code","fdb24740":"code","978d01cf":"code","4a7591fb":"code","df196e8e":"code","d0a115b1":"code","e5226272":"code","cc78009e":"code","99e9efef":"code","78b20da5":"code","702c7c1d":"code","ab674095":"code","024de1b9":"code","4e9def8e":"code","52b8868f":"code","ec1f6663":"code","a22b66e9":"code","e87c3235":"code","1b2a6227":"code","b7eea37d":"code","bbcbf930":"code","d45797b3":"code","39c8760f":"code","b8b02706":"code","3627918f":"code","89b2f89e":"code","d6d95927":"code","95bb5b92":"code","a8eca377":"code","62902357":"code","9713b560":"code","f29879e0":"code","a4db98a3":"code","1af34845":"code","c1268a3d":"code","383b9283":"code","48e30abe":"code","b8d7d367":"code","17d6963c":"code","888ea6b4":"code","c2602350":"code","309463b3":"code","d53fdd00":"code","309d19ec":"code","5c2d222d":"code","02c33546":"code","6b593ab8":"code","1eb44c21":"code","eb4d18a2":"code","f131dff6":"code","101af703":"code","f0beaf14":"code","7bd9d2f3":"markdown","105d6e43":"markdown","bd1dc94b":"markdown","a0d30086":"markdown","9f1dc85e":"markdown","9702ef63":"markdown","b71bee3d":"markdown","9b4e4095":"markdown","47e313a5":"markdown","52cffc9e":"markdown","ca227772":"markdown","d1f076d7":"markdown","380c1b37":"markdown","5b0776e6":"markdown","87ee366b":"markdown","1be3fc51":"markdown","c8d19740":"markdown","d705d498":"markdown","bba4eb40":"markdown","3dddfc7f":"markdown","bdaf03e6":"markdown","e722bc53":"markdown","696ec09f":"markdown","9958f971":"markdown","d35dc3ef":"markdown","0e1d4cbb":"markdown","ff5cd91f":"markdown","86623fcb":"markdown","d4bec6c1":"markdown","339f0a4a":"markdown","edf45e78":"markdown","54f8ad80":"markdown","ccae348b":"markdown","5a5404a9":"markdown","c3fcd93d":"markdown","09c1c397":"markdown","d187a8fd":"markdown","5b3a81a6":"markdown","03634a21":"markdown","2f17060c":"markdown","92b6e1c7":"markdown","1ffe1c8b":"markdown","5add04c0":"markdown","8922bb02":"markdown","69333d84":"markdown","bb6faa7f":"markdown","2599250c":"markdown","8ed266d9":"markdown","3e4a7da5":"markdown","e85fc445":"markdown","82be2e66":"markdown","f5810192":"markdown","7bad84ba":"markdown","d565e408":"markdown","7f03a805":"markdown","2ec84059":"markdown"},"source":{"d1df102f":"%matplotlib inline\nimport cv2\nimport glob\nimport os\nimport matplotlib.pylab as plt\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np\nimport os\nimport tensorflow as tf\nimport keras\nimport keras_preprocessing\nfrom keras.preprocessing.image import ImageDataGenerator  \nfrom keras.layers import (\n    GlobalAveragePooling2D, Multiply, Flatten,\n     Dense, Dropout, Conv2D, BatchNormalization, MaxPooling2D)\nfrom keras.layers.experimental.preprocessing import Resizing, Rescaling\nfrom keras.callbacks import EarlyStopping\nfrom keras.optimizers import Adam\nfrom keras import Sequential, Model\nfrom sklearn.model_selection import train_test_split\nfrom tqdm.notebook import tqdm\nimport tensorflow_addons as tfa\nimport albumentations\nimport shutil","12eaab81":"pathimagenestrain = '\/kaggle\/input\/kaggle-plant-pathology-2021-modificat\/train\/'\n\nprint(\"El directorio base entrenamiento es {}\".format(pathimagenestrain))","215e1144":"# Recorremos los subdirectorios y contamos el n\u00famero de im\u00e1genes por clase\n\nsubdirectorios = [x[1] for x in os.walk(pathimagenestrain)]\nsubdirectorios = subdirectorios[0]\n\n# Diccionario para la cuenta\nnumeroimagenes = {}\n\n# Recorremos y contamos:\nfor subpath in subdirectorios:\n    jpegCounter = len(glob.glob1(pathimagenestrain+'\/'+subpath+'\/',\"*.jp*g\"))\n    numeroimagenes[subpath] = jpegCounter\n\nprint('N\u00famero total de clases es:', len(subdirectorios))    \nprint('N\u00famero total de im\u00e1genes (jpg\/jpeg) por clase es :{}'.format(numeroimagenes))","5c1d4176":"# Guardamos el path completo a cada fichero\nficheros = [name for name in glob.glob(pathimagenestrain+'\/*\/*', recursive=True)]","d9a6f00a":"maximo = 0\nminimo = 1024\n#256\ncanales = 0\n\nimagenes = []\ntipos = []\n\n# Recorremos los ficheros y vamos guardando m\u00e1ximos y m\u00ednimos por canal\nfor i in ficheros: \n    img = cv2.imread(i)\n    # Extraemos max y min por colores\n    max_channels = np.amax([np.amax(img[:,:,0]), np.amax(img[:,:,1]), np.amax(img[:,:,2])])\n    min_channels = np.amax([np.amin(img[:,:,0]), np.amin(img[:,:,1]), np.amin(img[:,:,2])])\n    if max_channels > maximo:\n        maximo = max_channels\n    if min_channels < minimo:\n        minimo = min_channels\n    # Guardamos los canales (el m\u00e1ximo encontrado)\n    if len(img.shape) > canales:\n        canales = len(img.shape)\n\n    # Guardamos los data types que encontramos.\n    if img.dtype not in tipos:\n        tipos.append(img.dtype)\n\nprint(\"N\u00famero de imagenes le\u00eddas en \/train(entrenamiento): {}\\n\".format(len(ficheros)))\n\nprint(\"Tipos de datos de los ficheros le\u00eddos en \/train(entrenamiento): {}\\n\".format(tipos))\n\nprint(\"N\u00famero de canales de color de los ficheros: {}\\n\".format(canales))\n\nprint(\"Max. y Min de todas las im\u00e1genes en \/train son : Max={}, Min={}\\n\".format(maximo, minimo))\n\nprint(\"El rango din\u00e1mico es: {}\".format(((maximo - minimo) * 100) \/ 255))","082776e7":"#Gr\u00e1fico inicial del conteo de etiquetas\n\nplt.figure(figsize=(10,8))\nlabels = sns.barplot(x=list(numeroimagenes.keys()), y=list(numeroimagenes.values()));\n\n# Para imprimir los valores por columnas\nfor i, v in enumerate(list(numeroimagenes.values())):\n    #print (i, v)\n    labels.text(i-0.15, v , str(v), color='darkblue', fontsize=10, fontweight='bold')\nplt.title('N\u00famero de im\u00e1genes por clase', fontsize =14, color = 'darkblue');","ebb7e409":"plt.figure(figsize=(6,6))\nplt.title(\"Frecuencias relativas en % para las clases (labels)\", fontsize = 14, color = 'darkblue')\n# Contamos los valores por clases y vamos calculando sus frecuencias relativas.\nsorted_counts = list(np.array(list(numeroimagenes.values()))\/sum(list(numeroimagenes.values())))\nplt.pie(sorted_counts, labels = list(numeroimagenes.keys()), startangle = 30,\n        counterclock = False, autopct='%.2f%%', textprops={'fontsize':'14'})\nplt.show();","a2241d28":"from PIL import Image\nimport random\n\npathimagenes = '\/kaggle\/input\/kaggle-plant-pathology-2021-modificat\/train\/'\nimagenes = []\netiquetas = []\n\nfor subpath in subdirectorios:\n    ficheros = random.sample([name for name in glob.glob1(pathimagenes + subpath + '\/',\"*.jpg\")],5)\n    for i in ficheros:\n        imagen = pathimagenes + subpath + '\/' + i\n        img = cv2.imread(imagen, 1)\n        imagenes.append(img)\n        etiquetas.append(subpath)\n\nfig = plt.figure(figsize=(24, 24))\nfig.suptitle(\"5 im\u00e1genes de cada clase (label)\", fontsize = 24);\nfor i in range(len(imagenes)):\n    ax = plt.subplot(6, 5, i+1)\n    plt.imshow(imagenes[i])\n    plt.title(etiquetas[i], fontsize = 18)\n    plt.axis(\"off\")\nplt.show();","59e0162c":"#from sklearn.preprocessing import MultiLabelBinarizer\n\n## Convertimos el array a una lista\n#s = list(p_train['labels'])\n#mlb = MultiLabelBinarizer()\n## Construimos un dataframe con el resultado de aplicar el MLB con las nuevas clases como columnas con el mismo \u00edndice que p_train.\n#trainx = pd.DataFrame(mlb.fit_transform(s), columns=mlb.classes_, index=p_train.index)\n#listadoetiquetas = list(mlb.classes_)","0f389600":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n\ntrain_datagen = keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1\/255., # Normalizaci\u00f3n\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True,\n    validation_split = 0.2,\n    zoom_range = 0.2,\n    shear_range = 0.2,\n    vertical_flip = False)\n\ntest_datagen = keras.preprocessing.image.ImageDataGenerator(\n    rescale = 1\/255.,  # Normalizaci\u00f3n\n    #rotation_range=20,\n    #width_shift_range=0.2,\n    #height_shift_range=0.2,\n    #horizontal_flip=True,\n    #validation_split = 0.2,\n    #zoom_range = 0.2,\n    #shear_range = 0.2,\n    vertical_flip = False)","62eccfdd":"# Creamos los sets de entreno, validaci\u00f3n y otro espec\u00edfico para evaluaci\u00f3n (directorio \/test y sin labels).\nset_entreno = train_datagen.flow_from_directory(\n    directory= '\/kaggle\/input\/kaggle-plant-pathology-2021-modificat\/train\/',\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    classes = numeroimagenes.keys(),\n    batch_size=30, ## 7800\/30 = 260\n    shuffle=True,\n    seed=27,\n    save_to_dir=None,\n    follow_links=False,\n    subset='training',\n    interpolation=\"nearest\"\n)\n\nset_validacion = train_datagen.flow_from_directory(\n    directory='\/kaggle\/input\/kaggle-plant-pathology-2021-modificat\/train\/',\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    classes = numeroimagenes.keys(),\n    batch_size=30, # Divide 1950\/30 a 65 batches\n    shuffle=True,\n    seed=27,\n    save_to_dir=None,\n    follow_links=False,\n    subset='validation',\n    interpolation=\"nearest\",\n)\n\n# Aqu\u00ed hay un peque\u00f1o 'truco'. Si pasamos como clase 'test' el generador toma esto como el subdirectorio de 'clases', aunque realmente no hay tales.\nset_test = test_datagen.flow_from_directory(\n    directory = '\/kaggle\/input\/kaggle-plant-pathology-2021-modificat\/',\n    target_size =(256, 256),\n    color_mode = \"rgb\",\n    classes = ['test'],\n    shuffle = False,\n    seed = 27,\n    batch_size = 39, # 39 divide al set de test perfectamente (7527\/39 = 193 batches)\n    class_mode = None,\n)\n\n# Este \u00faltimo set no implementa shuffle (shuffle=False) y se usar\u00e1 para las \n# predicciones y as\u00ed poder comparar las clases de las predicciones vs. clases \n# verdaderas.\nset_validacion_ordenado = train_datagen.flow_from_directory(\n    directory='\/kaggle\/input\/kaggle-plant-pathology-2021-modificat\/train\/',\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=\"categorical\",\n    classes = numeroimagenes.keys(),\n    batch_size=30, # Divide validaci\u00f3n 1950\/30 en 65 batches\n    shuffle=False,\n    seed=27,\n    save_to_dir=None,\n    follow_links=False,\n    subset='validation',\n    interpolation=\"nearest\",\n)","97c1dd91":"labelslista  = list(set_entreno.class_indices.keys())","4f558443":"print(\"Orden 'real' tras la binarizaci\u00f3n (a tener en cuenta en predicciones): {}\".format(labelslista))","beefec77":"# Grafico con una imagen por clase tras el data augmentation.\nindices = []\nimagenes=[]\netiquetas = []\nclass_names = []\n\nwhile len(imagenes) < 6:\n  for i in range(len(class_names)):\n    indice = np.where(labels[i] == 1)[0][0]\n    #class_names = list(set_entreno.class_indices.keys())\n    if ((indice in indices) == False):\n      indices.append(indice)\n      imagenes.append(images[i])\n      etiquetas.append(class_names[indice])\n      #print(etiquetas)\n\n  images, labels = set_entreno.next()\n  class_names = list(set_entreno.class_indices.keys())\n\nfig = plt.figure(figsize=(24, 24))\nfor i in range(len(imagenes)):\n  ax = plt.subplot(6, 6, i+1)\n  plt.imshow(imagenes[i])\n  plt.title(etiquetas[i])\n  plt.axis(\"off\")\nfig.suptitle(\"Una imagen 'aumentada' de cada clase (label) tras las transformaciones\", fontsize = 24);","e7f7122b":"from datetime import datetime\ntimestampmodelo = datetime.now()\ntimestampmodelo = timestampmodelo.strftime(\"%d-%b-%Y_%H%M\")\n\nMETRIC = \"val_f1_score\"\n\ndef create_callbacks(model, metric = METRIC):\n    \n    guardar_path = '.\/mejor_modelo_' + model.name + '_' + timestampmodelo + '.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath = guardar_path,\n        monitor = metric,\n        mode ='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducccionlr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor = metric,\n        mode = 'max',\n        factor = 0.1,\n        patience = 3,\n        verbose = 0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor = metric,\n        mode ='max',\n        patience = 5, \n        verbose = 1\n    )\n    \n    callbacks = [checkpoint, reducccionlr, earlystop]         \n    \n    return callbacks","117f3843":"def compile_model(model, lr=0.03):\n    \n    optimizer = tf.keras.optimizers.SGD(lr=0.03, decay=1e-4, momentum=0.8, nesterov=True)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n    \n    metrics = [\n    tfa.metrics.F1Score(num_classes = 6, average = \"macro\",name = \"f1_score\")\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","5dfefe96":"from tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.applications.densenet import preprocess_input\n\nseed = 37\ntf.random.set_seed(seed)\n\nbase_model = tf.keras.applications.DenseNet121(input_shape=(256,256,3),\n                                               include_top=False,\n                                               weights='imagenet',\n                                               pooling='avg')\n\n## Descomentar si no queremos entrenal la primera parte del DenseNet121\n#for layer in base_model.layers:\n#    layer.trainable = False\n\nx = base_model.output\n# fully connected layer D64 a D16 y por \u00faltimo a 6 clases.\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nx = tf.keras.layers.Dense(16, activation='relu')(x)\n# Output final con funci\u00f3n sigmoid (potencialmente m\u00e1s de una, asumimos clases no excluyentes) \npredicciones = tf.keras.layers.Dense(6, activation='softmax')(x)\nmodeloDenseNet121 = tf.keras.Model(base_model.inputs, predicciones, name='DenseNet121')","ffa94c51":"EPOCHS= 10\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    #model = create_model()\n    modeloDenseNet121 = compile_model(modeloDenseNet121)\n    callbacks = create_callbacks(modeloDenseNet121)\n    historymodeloDenseNet121 = modeloDenseNet121.fit(\n                        set_entreno,\n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = set_validacion,\n                        verbose=VERBOSE\n                       )","5b7a4a85":"#modeloDenseNet121.summary()","103ab674":"loss, f1score = modeloDenseNet121.evaluate(set_validacion,verbose=1)\nprint('P\u00e9rdida y f1-score del modelo {}: p\u00e9rdida={} y f1-score(macro)={}'.format(modeloDenseNet121.name, round(loss,3), round(f1score,3)))","9a8d08cf":"resultadosDenseNet121 = pd.DataFrame(historymodeloDenseNet121.history)\nmodeloDenseNet121 = 'modeloDenseNet121_history06052021_con.csv'\nwith open(modeloDenseNet121, mode='w') as f:\n    resultadosDenseNet121.to_csv(f)","551fb188":"from keras.applications.resnet50 import ResNet50\nfrom keras.applications.resnet50 import preprocess_input\n\nseed = 43\ntf.random.set_seed(seed)\n\n#base_model = tf.keras.applications.DenseNet121(weights=weight_path, include_top=False, pooling='avg')\nbase_model = tf.keras.applications.ResNet50(input_shape=(256,256,3),\n                                               include_top=False,\n                                               weights='imagenet',\n                                               pooling='avg')\n\n# Descomentar para no entrenar la primera parte del ResNet50, solo las capas finales FC\n#for layer in base_model.layers:\n#    layer.trainable = False\n\nx = base_model.output\n# fully connected layer del Resnet a D64, a D16 y por \u00faltimo a D con 6 clases.\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nx = tf.keras.layers.Dense(16, activation='relu')(x)\n# Output final con funci\u00f3n softmax (asumimos clases excluyentes) \npredicciones = tf.keras.layers.Dense(6, activation='softmax')(x)\nmodeloResNet50 = tf.keras.Model(base_model.inputs, predicciones, name='ResNet50Prac1Final')","7855bd2f":"EPOCHS= 10\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\n# Forzamos entrenar en la GPU\nwith tf.device('\/device:GPU:0'):\n    \n    #model = create_model()\n    modeloResNet50 = compile_model(modeloResNet50)\n    callbacks = create_callbacks(modeloResNet50)\n    historymodeloResNet50 = modeloResNet50.fit(\n                        set_entreno,\n                        epochs = EPOCHS,\n                        callbacks = callbacks,\n                        validation_data = set_validacion,\n                        verbose = VERBOSE\n                       )","79e65f02":"resultadosmodeloResNet50 = pd.DataFrame(historymodeloResNet50.history)\nmodeloResNesnet50fichero = 'modeloResNet50_history06052021_con.csv'\nwith open(modeloResNesnet50fichero, mode='w') as f:\n    resultadosmodeloResNet50.to_csv(f)","2dfeceec":"loss, f1score = modeloResNet50.evaluate(set_validacion,verbose=1)\nprint('La p\u00e9rdida y f1-score del modelo {} en validaci\u00f3n son: p\u00e9rdida={} y f1-score(macro)={}'.format(modeloResNet50.name, round(loss,3), round(f1score,3)))","8d100339":"resultados_1 = pd.read_csv('\/kaggle\/input\/resultados-modelos-prac1-gpu\/modelos_Resultados_ResNet50_vs_DenseNet121.csv')","90af1a12":"fig, ((ax1,ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2,4, figsize=(24,8))\nplt.suptitle(\"Gr\u00e1ficas de p\u00e9rdida y f1-score para los modelos \\n (Sets entrenamientor y validaci\u00f3n)\", color='darkblue')\nplt.style.use('seaborn')\n\nax1.plot(resultados_1[resultados_1['modelo']=='ResNet50_ultimacapa']['loss'], color='blue')\nax1.plot(resultados_1[resultados_1['modelo']=='ResNet50_ultimacapa']['val_loss'], color='orange')\nax1.set_xticks(resultados_1[resultados_1['modelo']=='ResNet50_ultimacapa']['epoch'])\nax1.legend(['p\u00e9rdida entren.', 'perdida val.'])\nax1.set_xlabel('Epochs')\nax1.set_ylabel('P\u00e9rdida (loss)')\nax1.set_title(\"Modelo ResNet50 solo \u00faltimas capas\")\n               \nax2.plot(resultados_1[resultados_1['modelo']=='ResNet50_ultimacapa']['f1_score'].to_list(),color='maroon')\nax2.plot(resultados_1[resultados_1['modelo']=='ResNet50_ultimacapa']['val_f1_score'].to_list(),color='lime')\nax2.set_xticks(resultados_1[resultados_1['modelo']=='ResNet50_ultimacapa']['epoch'].to_list())\nax2.set_xticklabels(resultados_1[resultados_1['modelo']=='ResNet50_ultimacapa']['epoch'].to_list())\nax2.set_xlabel('Epochs')\nax2.set_ylabel('P\u00e9rdida (loss)')\nax2.legend(['f1-score entren.', 'f1-score valid.'])\nax2.set_title(\"P\u00e9rdida Modelo ResNet50 \u00faltimas capas\")\n\n\nax3.plot(resultados_1[resultados_1['modelo']=='ResNet50_todo']['loss'].to_list(), color='blue')\nax3.plot(resultados_1[resultados_1['modelo']=='ResNet50_todo']['val_loss'].to_list(), color='orange')\nax3.set_xticks(resultados_1[resultados_1['modelo']=='ResNet50_todo']['epoch'].to_list())\nax3.set_xticklabels(resultados_1[resultados_1['modelo']=='ResNet50_todo']['epoch'].to_list())\nax3.legend(['p\u00e9rdida entren.', 'perdida val.'])\nax3.set_xlabel('Epochs')\nax3.set_ylabel('P\u00e9rdida (loss)')\nax3.set_title(\"Modelo ResNet50 todas las capas\")\n               \nax4.plot(resultados_1[resultados_1['modelo']=='ResNet50_todo']['f1_score'].to_list(),color='maroon')\nax4.plot(resultados_1[resultados_1['modelo']=='ResNet50_todo']['val_f1_score'].to_list(),color='lime')\nax4.set_xticks(resultados_1[resultados_1['modelo']=='ResNet50_todo']['epoch'].to_list())\nax4.set_xticklabels(resultados_1[resultados_1['modelo']=='ResNet50_todo']['epoch'].to_list())\nax4.set_yticks(resultados_1[resultados_1['modelo']=='ResNet50_todo']['val_f1_score'].to_list())\nax4.set_xlabel('Epochs')\nax4.set_ylabel('P\u00e9rdida (loss)')\nax4.legend(['f1-score entren.', 'f1-score valid.'])\nax4.set_title(\"f1-score Modelo ResNet50 todas las capas\")\n\n\nax5.plot(resultados_1[resultados_1['modelo']=='DenseNet121_ultimacapa']['loss'].to_list(), color='blue')\nax5.plot(resultados_1[resultados_1['modelo']=='DenseNet121_ultimacapa']['val_loss'].to_list(), color='orange')\nax5.set_xticks(resultados_1[resultados_1['modelo']=='DenseNet121_ultimacapa']['epoch'].to_list())\nax5.set_xticklabels(resultados_1[resultados_1['modelo']=='DenseNet121_ultimacapa']['epoch'].to_list())\nax5.legend(['p\u00e9rdida entren.', 'perdida val.'])\nax5.set_xlabel('Epochs')\nax5.set_ylabel('P\u00e9rdida (loss)')\nax5.set_title(\"Modelo DenseNet50 solo \u00faltimas capas\")\n               \nax6.plot(resultados_1[resultados_1['modelo']=='DenseNet121_ultimacapa']['f1_score'].to_list(),color='maroon')\nax6.plot(resultados_1[resultados_1['modelo']=='DenseNet121_ultimacapa']['val_f1_score'].to_list(),color='lime')\nax6.set_xticks(resultados_1[resultados_1['modelo']=='DenseNet121_ultimacapa']['epoch'].to_list())\nax6.set_xticklabels(resultados_1[resultados_1['modelo']=='DenseNet121_ultimacapa']['epoch'].to_list())\nax6.set_xlabel('Epochs')\nax6.set_ylabel('P\u00e9rdida (loss)')\nax6.legend(['f1-score entren.', 'f1-score valid.'])\nax6.set_title(\"f1-score Modelo DesNet121 (\u00faltimas capas)\")\n\n\nax7.plot(resultados_1[resultados_1['modelo']=='DenseNet121_todo']['loss'].to_list(), color='blue')\nax7.plot(resultados_1[resultados_1['modelo']=='DenseNet121_todo']['val_loss'].to_list(), color='orange')\nax7.set_xticks(resultados_1[resultados_1['modelo']=='DenseNet121_todo']['epoch'].to_list())\nax7.legend(['p\u00e9rdida entren.', 'perdida val.'])\nax7.set_xlabel('Epochs')\nax7.set_ylabel('P\u00e9rdida (loss)')\nax7.set_title(\"Modelo DenseNet121 todas las capas\")\n               \nax8.plot(resultados_1[resultados_1['modelo']=='DenseNet121_todo']['f1_score'].to_list(),color='maroon')\nax8.plot(resultados_1[resultados_1['modelo']=='DenseNet121_todo']['val_f1_score'].to_list(),color='lime')\nax8.set_xticks(resultados_1[resultados_1['modelo']=='DenseNet121_todo']['epoch'].to_list())\nax8.set_xticklabels(resultados_1[resultados_1['modelo']=='DenseNet121_todo']['epoch'].to_list())\nax8.set_xlabel('Epochs')\nax8.set_ylabel('P\u00e9rdida (loss)')\nax8.legend(['f1-score entren.', 'f1-score valid.'])\nax8.set_title(\"f1-score Modelo DenseNet121 todas las capas\")\n\nplt.tight_layout()\nplt.show();","b0e3f3d2":"def compile_model_final(model, learning_rate=0.03):\n    \n    optimizer = tf.keras.optimizers.SGD(learning_rate=0.03, decay=1e-4, momentum=0.8, nesterov=True)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n    \n    # tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    metrics = [\n        tfa.metrics.F1Score(num_classes = 6, average = \"macro\",name = \"f1_score\"),       \n        #keras.metrics.TruePositives(name='tp'),\n        #keras.metrics.FalsePositives(name='fp'),\n        #keras.metrics.TrueNegatives(name='tn'),\n        #keras.metrics.FalseNegatives(name='fn'), \n        keras.metrics.CategoricalAccuracy(name='accuracy'),\n        keras.metrics.Precision(name='precision'),\n        keras.metrics.Recall(name='recall')\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","4bca032a":"EPOCHS= 30\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\n# Forzamos entrenar en la GPU\nwith tf.device('\/device:GPU:0'):\n    \n    modeloResNet50 = compile_model_final(modeloResNet50)\n    callbacks = create_callbacks(modeloResNet50)\n    historymodeloResNet50 = modeloResNet50.fit(\n                        set_entreno,\n                        epochs = EPOCHS,\n                        callbacks = callbacks,\n                        validation_data = set_validacion,\n                        verbose = VERBOSE\n                       )","88757d07":"# Descomentar esta celda si queremos subir y utilizar el modelo **ya entrenado** con un f1-score de 0.93409\n#from keras.models import load_model\n\n#modeloResNet50 = load_model('\/kaggle\/input\/resultados-modelos-prac1-gpu\/mejor_modelo_ResNet50Prac1Final_06052021.h5')\n##modeloResNet50 = load_model('\/kaggle\/input\/resultados-modelos-prac1-gpu\/mejor_modelo_ResNet50Prac1Final_05-Jun-2021_1240.h5')","28c33b52":"set_test.reset()\npredicciones = modeloResNet50.predict(set_test)","901e5e9f":"print('Orden de las etiquetas: {}'.format(set_entreno.class_indices.keys()))\n#set_test.class_indices.keys()","d9976198":"print('Orden de las etiquetas: {}'.format(set_validacion_ordenado.class_indices.keys()))\n#set_test.class_indices.keys()","fdb24740":"# Para confirmar\n#set_entreno.class_indices.items()","978d01cf":"preds_clases_indices = predicciones.argmax(axis=-1)","4a7591fb":"ficheros_test = [str(i).replace('test\/', '')  for i in set_test.filenames]","df196e8e":"indices_de_clases = {v: k for k, v in set_entreno.class_indices.items()}\npreds_clases = np.vectorize(indices_de_clases.get)(preds_clases_indices)\nfilenames_to_clases = list(zip(ficheros_test, preds_clases))","d0a115b1":"from collections import Counter\nprint(\"conteo de predicciones: {}\".format(Counter(preds_clases)))","e5226272":"# Grafica del % de etiquetas en las predicciones.\nplt.figure(figsize=(6,6))\nplt.title(\"Frecuencias relativas en % de las predicciones\", fontsize = 14, color = 'darkblue')\n# Contamos los valores por clases y vamos calculando sus frecuencias relativas.\nsorted_counts_pred = list(np.array(list(Counter(preds_clases).values()))\/sum(list(Counter(preds_clases).values())))\nplt.pie(sorted_counts_pred, labels = list(Counter(preds_clases).keys()), startangle = 30,\n        counterclock = False, autopct='%.2f%%', textprops={'fontsize':'14'})\nplt.show();","cc78009e":"prediccionesResNet50 = pd.DataFrame(filenames_to_clases)\npredicciones_fichero = 'test.csv'\nwith open(predicciones_fichero, mode='w') as f:\n    prediccionesResNet50.to_csv(f)","99e9efef":"path_test = '\/kaggle\/input\/kaggle-plant-pathology-2021-modificat\/test\/'\n\n# Grafico con una imagen por clase tras la  prediccion.\nindices = []\nimagenes=[]\netiquetas = []\nclass_names = []\n\nwhile len(imagenes) < 6:\n    for i in filenames_to_clases:\n    \n        etiqueta = i[1]\n        if ((etiqueta in etiquetas) == False):\n            imagenes.append(path_test+str(i[0]))\n            etiquetas.append(i[1])\n            #print(etiquetas)\n\n    #images = set_test.next() \n    #labels = preds_clases_indices\n  \nfig = plt.figure(figsize=(24, 24))\nfor i in range(len(imagenes)):\n    ax = plt.subplot(6, 6, i+1)\n    img = cv2.imread(imagenes[i], 1)\n    plt.imshow(img)\n    plt.title('Clase predicha: ' + etiquetas[i])\n    plt.axis(\"off\")\nfig.suptitle(\"Una imagen predicha de cada clase (label) con nuestro modelo ResNet50->D64->D16->D6\", fontsize = 24);\nfig.tight_layout()","78b20da5":"predicciones_val_1 = modeloResNet50.predict(set_validacion_ordenado)\npredicciones_val = np.argmax(predicciones_val_1, axis=-1)","702c7c1d":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\nprint(\"Precision f1-score 'macro': {}\".format(precision_score(set_validacion_ordenado.classes, predicciones_val , average=\"macro\")))","ab674095":"from sklearn.metrics import f1_score, precision_score, recall_score, confusion_matrix\n\n# Se calculan las m\u00e9tricas al final para el conjunto de validaci\u00f3n\nprint('Precisi\u00f3n (ponderada=weighted) en el conjunto de validaci\u00f3n: {}'.format(precision_score(set_validacion_ordenado.classes, predicciones_val , average=\"weighted\")))\nprint('Recall (ponderada=weighted) en el conjunto de validaci\u00f3n:    {}'.format(recall_score(set_validacion_ordenado.classes, predicciones_val , average=\"weighted\")))\nprint('f1-score (ponderada=weighted) en el conjunto de validaci\u00f3n:  {}'.format(f1_score(set_validacion_ordenado.classes, predicciones_val , average=\"weighted\")))","024de1b9":"#fig, ((ax1,ax2, ax3, ax4), (ax5, ax6, ax7, ax8)) = plt.subplots(2,4, figsize=(24,8))\nfig, ((ax1, ax2, ax3), (ax4, ax5, ax6)) = plt.subplots(2,3, figsize=(18,6))\nplt.suptitle(\"Gr\u00e1ficas de p\u00e9rdida, f1-score, accuracy, recall y precision \\n para el modelo ResNet50->D64->D16->D6 (entren. y valid.)\", color='darkblue')\nplt.style.use('seaborn')\n\nax1.plot(historymodeloResNet50.history['loss'], color='blue')\nax1.plot(historymodeloResNet50.history['val_loss'], color='orange')\nax1.set_xticks(np.arange(len(historymodeloResNet50.history['loss'])))\nax1.legend(['p\u00e9rdida entren.', 'perdida val.'])\nax1.set_xlabel('Epochs')\nax1.set_ylabel('P\u00e9rdida (loss)')\nax1.set_title(\"P\u00e9rdida Modelo ResNet50 final D64->D16->D6\")\n\nax2.plot(historymodeloResNet50.history['f1_score'], color='maroon')\nax2.plot(historymodeloResNet50.history['val_f1_score'], color='lime')\nax2.set_xticks(np.arange(len(historymodeloResNet50.history['loss'])))\nax2.legend(['f1-score entren.', 'f1-score valid.'])\nax2.set_xlabel('Epochs')\nax2.set_ylabel('F1-Score')\nax2.set_title(\"f1-score(macro) Modelo ResNet50 final D64->D16->D6\")\n\nax3.plot(historymodeloResNet50.history['accuracy'], color='purple')\nax3.plot(historymodeloResNet50.history['val_accuracy'], color='red')\nax3.set_xticks(np.arange(len(historymodeloResNet50.history['loss'])))\nax3.legend(['Accuracy entren.', 'Accuracy valid.'])\nax3.set_xlabel('Epochs')\nax3.set_ylabel('Accuracy')\nax3.set_title(\"Accuracy (cross-entropy) Modelo ResNet50 final D64->D16->D6\")\n\nax4.plot(historymodeloResNet50.history['precision'], color='grey')\nax4.plot(historymodeloResNet50.history['val_precision'], color='green')\nax4.set_xticks(np.arange(len(historymodeloResNet50.history['loss'])))\nax4.legend(['Precision entren.', 'Precision valid.'])\nax4.set_xlabel('Epochs')\nax4.set_ylabel('Precision')\nax4.set_title(\"Precision Modelo ResNet50 final D64->D16->D6\")\n\nax5.plot(historymodeloResNet50.history['recall'], color='gold')\nax5.plot(historymodeloResNet50.history['val_recall'], color='darkblue')\nax5.set_xticks(np.arange(len(historymodeloResNet50.history['loss'])))\nax5.legend(['Recall entren.', 'Recall valid.'])\nax5.set_xlabel('Epochs')\nax5.set_ylabel('Recall')\nax5.set_title(\"Recall Modelo ResNet50 final D64->D16->D6\")\n\nplt.tight_layout()\nplt.show();","4e9def8e":"from sklearn.metrics import accuracy_score, classification_report, confusion_matrix, f1_score, recall_score, multilabel_confusion_matrix\n\nclases_val_ord = set_validacion_ordenado.class_indices.keys()\n# Calculamos la matriz de confusion\n\ncfmatrix  = confusion_matrix(set_validacion_ordenado.classes, predicciones_val)\ncfmatrixmulti = multilabel_confusion_matrix(set_validacion_ordenado.classes, predicciones_val)","52b8868f":"#Graficamos con seaborn y un heatmap para visualizar\nimport seaborn as sns\nplt.rcParams['figure.figsize'] = (12.0, 8.0)\nplt.rcParams['font.family'] = \"serif\"\nplt.rcParams['font.size'] = \"12\"\nsns.heatmap(cfmatrix, annot=True, cmap=\"BuPu\", fmt=\".0f\", xticklabels=clases_val_ord, yticklabels=clases_val_ord)\nplt.tight_layout()\nplt.title(\"Matriz de confusi\u00f3n modelo RestNet50: \\n (RestNet50->D64->D16->D6)\\n\")\nplt.ylabel('Clase verdadera')\nplt.xlabel('Clase predicha')\nplt.show();","ec1f6663":"print('Classification Report\/Informe sobre la clasificaci\u00f3n de acuerdo a las 6 enfermedades del manzano')\nprint(classification_report(set_validacion_ordenado.classes, predicciones_val,target_names=clases_val_ord))","a22b66e9":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n\ntrain_data = train_datagen.flow_from_dataframe(\n    df_entreno2,\n    directory= '\/kaggle\/input\/resized-plant2021\/img_sz_256\/', # originales en 'plant-pathology-2021-fgvc8\/train_images\/'\n    x_col = \"image\",\n    y_col=  labelslista,\n    color_mode=\"rgb\",\n    #target_size = (256,256),\n    #class_mode=\"categorical\",\n    batch_size=32,\n    subset = \"training\",\n    shuffle=True,\n    seed=27,\n    class_mode='raw'\n)\n\nvalidacion_data = train_datagen.flow_from_dataframe(\n    df_entreno2,\n    directory= '\/kaggle\/input\/resized-plant2021\/img_sz_256\/', # originales en 'plant-pathology-2021-fgvc8\/train_images\/'\n    x_col = \"image\",\n    y_col=  labelslista,\n    color_mode=\"rgb\",\n    #target_size = (256,256),\n    #class_mode=\"categorical\",\n    batch_size=32,\n    subset = \"validation\",\n    shuffle=True,\n    seed=27,\n    class_mode='raw'\n)","e87c3235":"from tensorflow.keras.layers import Input, Lambda, Dense, Flatten\nfrom tensorflow.keras.models import Model\n#from tensorflow.keras.applications.inception_resnet_v2 import InceptionResNetV2\n#from tensorflow.keras.applications.inception_resnet_v2 import preprocess_input\nfrom tensorflow.keras.applications.resnet_v2 import ResNet50V2\nfrom tensorflow.keras.applications.resnet_v2 import preprocess_input\nfrom tensorflow.keras.models import Sequential\n\ndef create_model():\n    \n    pretrained = ResNet50V2(include_top=False, weights='imagenet',input_shape=[256,256, 3])\n    # pretrained = InceptionResNetV2(include_top=False, weights='imagenet',input_shape=[256, 256, 3])\n            \n    x = pretrained.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x)\n    outputs = tf.keras.layers.Dense(6, activation=\"sigmoid\", dtype='float32')(x)\n        \n    model = tf.keras.Model(pretrained.input, outputs, name='modeloResNetV2')\n    return model\n\nmodel = create_model()","1b2a6227":"model.name","b7eea37d":"# Funci\u00f3n que compilar\u00e1 el modelo con Adam y la learning rate como par\u00e1metro. \n# Tambi\u00e9n introducimos nuestra medidad como F1-score 'macro'\n\ndef compile_model(model, lr=0.03):\n    \n    optimizer = tf.keras.optimizers.SGD(lr=0.03, decay=1e-4, momentum=0.8, nesterov=True)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n    \n    # tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    metrics = [\n    tfa.metrics.F1Score(num_classes = 6, average = \"macro\",name = \"f1_score\")\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","bbcbf930":"METRIC = \"val_f1_score\"\n\ndef create_callbacks(metric = METRIC):\n    \n    guardar_path = '.\/mejor_modelo_' + model.name + '_' + timestampmodelo + '.h5'\n    \n    checkpoint = tf.keras.callbacks.ModelCheckpoint(\n        filepath = guardar_path,\n        monitor = metric,\n        mode ='max',\n        save_best_only=True,\n        verbose=1,\n    )\n\n    reducccionlr = tf.keras.callbacks.ReduceLROnPlateau(\n        monitor = metric,\n        mode = 'max',\n        factor = 0.1,\n        patience = 3,\n        verbose = 0\n    )\n\n    earlystop = tf.keras.callbacks.EarlyStopping(\n        monitor = metric,\n        mode ='max',\n        patience = 5, \n        verbose = 1\n    )\n    \n    callbacks = [checkpoint, reducccionlr, earlystop]         \n    \n    return callbacks","d45797b3":"EPOCHS= 10\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    model = create_model()\n    model = compile_model(model, lr=0.001)\n   \n    callbacks = create_callbacks()\n    \n    history = model.fit(\n                        train_data,\n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = validacion_data,\n                        verbose=VERBOSE\n                       )","39c8760f":"resultados = pd.DataFrame(history.history)","b8b02706":"modeloResNetV2 = 'modeloResNetV2_history.csv'\nwith open(modeloResNetV2, mode='w') as f:\n    resultados.to_csv(f)","3627918f":"p_train = pd.read_csv('\/kaggle\/input\/plant-pathology-2021-fgvc8\/train.csv')","89b2f89e":"p_train['labels'] = p_train['labels'].apply(lambda string: string.split(' '))","d6d95927":"from tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\n\ntrain_data = train_datagen.flow_from_dataframe(\n    df_entreno,\n    directory= '\/kaggle\/input\/resized-plant2021\/img_sz_256\/', # originales en 'plant-pathology-2021-fgvc8\/train_images\/'\n    x_col = \"image\",\n    y_col=  \"labels\",\n    color_mode=\"rgb\",\n    #target_size = (256,256),\n    #class_mode=\"categorical\",\n    batch_size=32,\n    subset = \"training\",\n    shuffle=True,\n    seed=27,\n    class_mode='raw'\n)\n\nvalidacion_data = train_datagen.flow_from_dataframe(\n    df_entreno,\n    directory = '\/kaggle\/input\/resized-plant2021\/img_sz_256\/',\n    x_col = \"image\",\n    y_col = \"labels\",\n    color_mode=\"rgb\",\n    #target_size = (256,256),\n    #class_mode=\"categorical\",\n    batch_size=32,\n    shuffle=True,\n    subset = \"validation\",\n    seed=27,\n    class_mode='raw'\n)\n\n# Este \u00faltimo set no implementa shuffle (shuffle=False) y se usar\u00e1 para las \n# predicciones y as\u00ed poder comparar las clases de las predicciones vs. clases \n# verdaderas.\nset_validacion_ordenado = train_datagen.flow_from_dataframe(\n    df_entreno,\n    directory = '\/kaggle\/input\/resized-plant2021\/img_sz_256\/',\n    x_col=\"image\",\n    y_col = \"labels\",\n    #target_size=(256, 256),\n    color_mode=\"rgb\",\n    #class_mode=\"categorical\",\n    batch_size=32,\n    shuffle=False,\n    seed=27,\n    subset='validation',\n    interpolation=\"nearest\",\n    class_mode='raw'\n)\n\nset_test = test_datagen.flow_from_directory(\n    directory = '\/kaggle\/input\/plant-pathology-2021-fgvc8\/test_images\/',\n    batch_size=1,\n    # No tenemos y_col porque son las que tenemos que predecir\n    target_size=(256, 256),\n    color_mode=\"rgb\",\n    class_mode=None,\n    shuffle=False,\n    seed=27,\n#    interpolation=\"nearest\",\n)","95bb5b92":"from tensorflow.keras.applications.efficientnet import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndef create_EffNetB0model():\n    \n    pretrained = EfficientNetB0(include_top=False, weights='imagenet',input_shape=[256, 256, 3], pooling = 'avg')\n    x = pretrained.output\n    x = tf.keras.layers.Dense(64, activation='relu')(x)\n    x = tf.keras.layers.Dense(16, activation='relu')(x)\n    # finally, the softmax for the classifier \n    #predictions = tf.keras.layers.Dense(6, activation='sigmoid')(x)\n    \n    outputs = tf.keras.layers.Dense(6,activation=\"sigmoid\", dtype='float32')(x)\n    model = tf.keras.Model(pretrained.input, outputs, name = 'modeloEffNetB0')\n    return model\n\nmodel = create_EffNetB0model()\n\n\ndef compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.BinaryCrossentropy()\n    \n    #tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    metrics = [\n    tfa.metrics.F1Score(num_classes = 6, average = \"macro\",name = \"f1_score\")\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","a8eca377":"EPOCHS= 10\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    #model = create_model()\n    modeloEffNetB0 = compile_model(model)\n    callbacks = create_callbacks(modeloEffNetB0)\n    historymodeloDenseNet121 = modeloEffNetB0.fit(\n                        set_entreno,\n                        epochs = EPOCHS,\n                        callbacks = callbacks,\n                        validation_data = set_validacion,\n                        verbose = VERBOSE\n                       )","62902357":"try: # TPUs, si tenemos habilitado el cluster y generamos archivos tipo .tfrec\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver.connect() # TPU detection\n    strategy = tf.distribute.TPUStrategy(tpu)\n\nexcept ValueError: # GPUs\n    strategy = tf.distribute.MirroredStrategy() # for GPU or multi-GPU machines\n    #strategy = tf.distribute.get_strategy() # una CPU y una GPU\n    #strategy = tf.distribute.experimental.MultiWorkerMirroredStrategy() # for clusters of multi-GPU machines\n\nprint(\"Number of accelerators: \", strategy.num_replicas_in_sync)","9713b560":"from tensorflow.keras.applications.inception_v3 import InceptionV3\nfrom tensorflow.keras.applications.inception_v3 import preprocess_input\n\ndef create_InceptionV3():\n    \n    pretrained = InceptionV3(include_top=False, weights='imagenet',input_shape=[256, 256, 3], pooling = 'avg')\n    x = pretrained.output\n    #x = tf.keras.layers.GlobalAveragePooling2D()(x) # No necesitamos pooling porque lo ponemos en la salida del EfficientNetB0\n    outputs = tf.keras.layers.Dense(len(validacion_data.class_indices),activation=\"sigmoid\", dtype='float32')(x)\n    model = tf.keras.Model(pretrained.input, outputs, name = 'modeloInceptionV3')\n    return model\n\nmodel = create_InceptionV3()\n\n\ndef compile_model(model, lr=0.0001):\n    \n    optimizer = tf.keras.optimizers.Adam(lr=lr)\n    \n    loss = tf.keras.losses.CategoricalCrossentropy()\n    \n    #tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    metrics = [\n    tfa.metrics.F1Score(num_classes = len(validacion_data.class_indices), average = \"macro\",name = \"f1_score\")\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","f29879e0":"model.name","a4db98a3":"EPOCHS= 10\nVERBOSE =1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    #model = create_model()\n    model = compile_model(model, lr=0.0001)\n   \n    callbacks = create_callbacks()\n    \n    historyIncepcionV3 = model.fit(\n                        train_data,\n                        epochs=EPOCHS,\n                        callbacks=callbacks,\n                        validation_data = validacion_data,\n                        verbose=VERBOSE\n                       )","1af34845":"resultadosInceptionV3 = pd.DataFrame(historyIncepcionV3.history)\nmodeloInceptionV3_cvs_file = 'resultadosInceptionV3_history.csv'\nwith open(modeloInceptionV3_cvs_file, mode='w') as f:\n    resultadosInceptionV3.to_csv(f)","c1268a3d":"from tensorflow.keras.applications.efficientnet import EfficientNetB0\nfrom tensorflow.keras.applications.efficientnet import preprocess_input\n\ndef create_EffNetB0model():\n    \n    pretrained = EfficientNetB0(include_top=False, weights='imagenet',input_shape=[256, 256, 3], pooling = 'avg')\n    x = pretrained.output\n    x = tf.keras.layers.Dense(64, activation='relu')(x)\n    x = tf.keras.layers.Dense(16, activation='relu')(x)\n    \n    #x = tf.keras.layers.GlobalAveragePooling2D()(x) # No necesitamos pooling porque lo ponemos en la salida del EfficientNetB0\n    outputs = tf.keras.layers.Dense(6,activation=\"sigmoid\")(x)\n    model = tf.keras.Model(pretrained.input, outputs, name = 'modeloEffNetB0')\n    return model\n\nmodel = create_EffNetB0model()","383b9283":"EPOCHS = 10\nVERBOSE = 1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    #model = create_EffNetB0model()\n    model = compile_model(model)\n \n    callbacks = create_callbacks(model)\n    \n    historyModeloEffNetB0 = model.fit(\n                    set_entreno,\n                    epochs=EPOCHS,\n                    callbacks=callbacks,\n                    validation_data = set_validacion,\n                    verbose = VERBOSE\n                   )","48e30abe":"resultadosEffNetB0 = pd.DataFrame(historyModeloEffNetB0.history)\nresultadosEffNetB0_csv_file = 'resultadosEffNetB0_history2.csv'\nwith open(resultadosEffNetB0_csv_file, mode='w') as f:\n    resultadosEffNetB0.to_csv(f)","b8d7d367":"from tensorflow.keras.applications.resnet import ResNet50\nfrom tensorflow.keras.applications.resnet import preprocess_input\n\ndef create_RestNet50():\n    \n    pretrained = ResNet50(include_top=False, weights='imagenet',input_shape=[256, 256, 3])\n    x = pretrained.output\n    x = tf.keras.layers.GlobalAveragePooling2D()(x) \n    # Para RestNet50 debemos usar softmax si utilizamos los pesos pre-entrenados.\n    outputs = tf.keras.layers.Dense(6,activation=\"sigmoid\", dtype='float32')(x)\n    model = tf.keras.Model(pretrained.input, outputs, name = 'modeloRestNet50')\n    return model\n\nmodel = create_RestNet50()\n\n\ndef compile_model(model):\n    \n    #optimizer = tf.keras.optimizers.Adam(lr=lr)\n    optimizer = tf.keras.optimizers.SGD(lr=0.03, decay=1e-4, momentum=0.8, nesterov=True)\n\n    \n    loss = tf.keras.losses.BinaryCrossentropy()\n    \n    #tf.keras.metrics.CategoricalAccuracy(name='categorical_accuracy')\n    metrics = [\n    tfa.metrics.F1Score(num_classes = 6, average = \"macro\",name = \"f1_score\")\n    ]\n\n    model.compile(optimizer=optimizer, loss=loss, metrics=metrics)\n\n    return model","17d6963c":"EPOCHS = 10\nVERBOSE = 1\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n    \n    callbacks = create_callbacks()\n    model = compile_model(model)\n    historyResNet50 = model.fit(\n                    train_data,\n                    epochs=EPOCHS,\n                    callbacks=callbacks,\n                    validation_data = validacion_data,\n                    verbose = VERBOSE\n                   )","888ea6b4":"resultadosRestNet50 = pd.DataFrame(historyResNet50.history)\nmodeloResNet50 = 'modeloResNet50_history2.csv'\nwith open(modeloResNet50, mode='w') as f:\n    resultadosRestNet50.to_csv(f)","c2602350":"from tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.applications.densenet import preprocess_input\n#tf.keras.applications.densenet.DenseNet121\n\nseed = 1200\ntf.random.set_seed(seed)\n\n#base_model = tf.keras.applications.DenseNet121(weights=weight_path, include_top=False, pooling='avg')\nbase_model = tf.keras.applications.DenseNet121(input_shape=(256,256,3),\n                                               include_top=False,\n                                               weights='imagenet',\n                                               pooling='avg')\n#pesos_entrenados = '..\/input\/keras-pretrained-models\/'\n#model = keras.applications.InceptionResNetV2(weights=pesos_entrenados, include_top=False, input_shape=(256, 256, 3))\nbase_model.trainable = False\n\nx = base_model.output\n#fully connected layer\nx = tf.keras.layers.Dense(64, activation='relu')(x)\nx = tf.keras.layers.Dense(16, activation='relu')(x)\n# finally, the softmax for the classifier \npredictions = tf.keras.layers.Dense(6, activation='sigmoid')(x)\nmodeloDenseNet121 = tf.keras.Model(base_model.inputs, predictions, name='DenseNet121')\n","309463b3":"resultados = pd.read_csv('\/kaggle\/input\/resultados-modelos-prac1-gpu\/modelos_Resultados_original_Kaggle.csv')","d53fdd00":"modelos = list(resultados.modelo.unique())\n\nfig = plt.figure(figsize=(18, 4))\nfig.suptitle(\"P\u00e9rdida en los 6 modelos\", fontsize = 20);\nplt.style.use('seaborn')\n\nfor i, j in enumerate(modelos):\n    ax = plt.subplot(1, 6, i+1)\n    ax.plot(resultados[resultados['modelo']==str(j)]['loss'].to_list(), color='blue')\n    ax.plot(resultados[resultados['modelo']==str(j)]['val_loss'].to_list(), color='orange')\n    ax.set_xticks(resultados[resultados['modelo']==str(j)]['epoch'].to_list())\n    ax.set_xticklabels(resultados[resultados['modelo']==str(j)]['epoch'].to_list())\n    ax.legend(['p\u00e9rdida entren.', 'perdida val.'])\n    ax.set_xlabel('Epochs')\n    ax.set_ylabel('P\u00e9rdida (loss)')\n    ax.set_title(\"P\u00e9rdida Modelo \"+str(j))\nplt.tight_layout()\nplt.show();\n\nfig2 = plt.figure(figsize=(18, 4))\nfig2.suptitle(\"f1-score en los 6 modelos\", fontsize = 20);\nplt.style.use('seaborn')\n\nfor i, j in enumerate(modelos):\n\n    ax = plt.subplot(1, 6, i+1)\n    ax.plot(resultados[resultados['modelo']==str(j)]['f1_score'].to_list(), color='maroon')\n    ax.plot(resultados[resultados['modelo']==str(j)]['val_f1_score'].to_list(), color='lime')\n    ax.set_xticks(resultados[resultados['modelo']==str(j)]['epoch'].to_list())\n    ax.set_xticklabels(resultados[resultados['modelo']==str(j)]['epoch'].to_list())\n    ax.legend(['f1-score entren.', 'f1-score val.'])\n    ax.set_xlabel('Epochs')\n    ax.set_ylabel('f1-score (macro)')\n    ax.set_title(\"F1-score Modelo \"+str(j))\n\nplt.tight_layout()\nplt.show();","309d19ec":"seed = 1200\ntf.random.set_seed(seed)\n\npesos_entrenados = '..\/input\/keras-pretrained-models\/inception_resnet_v2_weights_tf_dim_ordering_tf_kernels_notop.h5'\nmodel = keras.applications.InceptionResNetV2(weights=pesos_entrenados, include_top=False, input_shape=(256, 256, 3))\n","5c2d222d":"modelo_sobre_IncRSNet50V2 = tf.keras.Sequential([\n    model,\n    keras.layers.GlobalAveragePooling2D(),\n    keras.layers.Dense(6, kernel_initializer=keras.initializers.RandomUniform(seed=seed),\n                        bias_initializer=keras.initializers.Zeros(), name='dense_top', activation='sigmoid')\n])\n\n# Freezing the weights\nfor layer in modelo_sobre_IncRSNet50V2.layers[:-1]:\n    layer.trainable=False\n    \nmodelo_sobre_IncRSNet50V2.summary()","02c33546":"EPOCHS = 10\nVERBOSE = 1\nf1 = tfa.metrics.F1Score(num_classes=6, average='macro')\n\n#callbacks = keras.callbacks.EarlyStopping(monitor=f1, patience=3, mode='max', restore_best_weights=True)\n\n\nmodelo_sobre_IncRSNet50V2.compile(loss=tf.keras.losses.CategoricalCrossentropy(), optimizer=keras.optimizers.SGD(lr=0.03, decay=1e-4, momentum=0.8, nesterov=True), \n              metrics= [f1])\n\nwith tf.device('\/device:GPU:0'):\n    \n    callbacks = create_callbacks(modelo_sobre_IncRSNet50V2)\n    #model = compile_model(model, lr=0.0001)\n    history_IncRSNet50V2 = modelo_sobre_IncRSNet50V2.fit(\n                    set_entreno,\n                    epochs=EPOCHS,\n                    callbacks=callbacks,\n                    validation_data = set_validacion,\n                    verbose = VERBOSE\n                   )\n\n#modelo_sobre_IncRSNet50V2.fit(train_data, epochs=20, callbacks=callbacks)","6b593ab8":"resultadosIncepRSNet50V2 = pd.DataFrame(history_IncRSNet50V2.history)\nmodeloIncepResNet50v2 = 'modeloIncepRSNet50V2_history.csv'\nwith open(modeloIncepResNet50v2, mode='w') as f:\n    resultadosIncepRSNet50V2.to_csv(f)","1eb44c21":"# Probamos un DenseNet121\nfrom tensorflow.keras.applications.densenet import DenseNet121\nfrom tensorflow.keras.applications.densenet import preprocess_input\n#tf.keras.applications.densenet.DenseNet121\n\nseed = 43\ntf.random.set_seed(seed)\n\n#base_model = tf.keras.applications.DenseNet121(weights=weight_path, include_top=False, pooling='avg')\nbase_model = tf.keras.applications.DenseNet121(input_shape=(256,256,3),\n                                               include_top=False,\n                                               weights='imagenet',\n                                               pooling='avg')\nx = base_model.output\n#fully connected layer\n#x = tf.keras.layers.Dense(64, activation='relu')(x)\n#x = tf.keras.layers.Dense(16, activation='relu')(x)\n# finally, the softmax for the classifier \noutput = tf.keras.layers.Dense(6, activation='sigmoid')(x)\nmodeloDenseNet121orig = tf.keras.Model(base_model.inputs, output, name='DenseNet121')\n","eb4d18a2":"EPOCHS = 10\nVERBOSE = 1\nf1 = tfa.metrics.F1Score(num_classes=6, average='macro')\n\ntf.keras.backend.clear_session()\n\nwith tf.device('\/device:GPU:0'):\n\n    callbacks = create_callbacks(modeloDenseNet121orig)\n    modeloDenseNet121orig = compile_model(modeloDenseNet121orig)\n    history_DenseNet121 = modeloDenseNet121orig.fit(\n                    #train_data,\n                    set_entreno,\n                    epochs=EPOCHS,\n                    callbacks=callbacks,\n                    validation_data = set_validacion, \n                    #validation_data = validacion_data,\n                    verbose = VERBOSE\n                   )","f131dff6":"resultadosDenseNet121= pd.DataFrame(history_DenseNet121.history)\nmodeloDenseNet121 = 'modeloDenseNet121_history2.csv'\nwith open(modeloDenseNet121, mode='w') as f:\n    resultadosDenseNet121.to_csv(f)","101af703":"test_generator = test_datagen.flow_from_directory()","f0beaf14":"test_generator.reset()\npredicciones = model.predict_generator(test_generator, verbose=1)","7bd9d2f3":"Observamos que hay un mayor n\u00famero de im\u00e1genes con enfermedades respecto a las sanas (C0), lo cual no est\u00e1 muy en l\u00ednea con los sets de entrenamiento y validaci\u00f3n. En cualquier caso es posible que el set de test sea completamente diferente en cuanto a sus clases.","105d6e43":"Guardamos en una variable el nombre da cada fichero.","bd1dc94b":"Creaci\u00f3n de los sets de entrenamiento, validaci\u00f3n y test basados en los generadores anteriores. N\u00f3tese la divisi\u00f3n 'exacta' de las im\u00e1genes resultantes para que los batches sean uniformes.","a0d30086":"## <u>Selecci\u00f3n y entrenamiento final del modelo ResNet50->D64->D16-D6 elegido<\/u>","9f1dc85e":"A continuaci\u00f3n se muestra una imagen por clase con los datos 'aumentados', es decir, tras las funciones de aumento de datos implementadas en las celdas anteriores. Esto nos da una idea de c\u00f3mo se entrenar\u00e1n nuestras im\u00e1genes.","9702ef63":"### Conteo inicial por subdirectorios\nRecorremos los subdirectorios y contamos el n\u00famero de im\u00e1genes por directorio para obtener el conteo por clases.","b71bee3d":"Podemos ver la diferencia en cuanto al n\u00famero de par\u00e1metros si descomentamos la siguiente celda.","9b4e4095":"Esta parte del c\u00f3dico no se utiliza en nuestro problema, pero s\u00ed en el problema original de Kaggle. Se utiliza para 'binarizar' (OneHotEncoder) de MultiLabels, ya qe el problema original tienen multilabels no excluyentes.","47e313a5":"#### Creaci\u00f3n de las M\u00e9tricas, callbacks y optimizadores. N\u00f3tese c\u00f3mo vamos guardando el mejor modelo (fichero .h5 que se entrega como un activo a nuestro cliente en el repositorio p\u00fablico de Kaggle que incluimos con la entrega.\nAdem\u00e1s del checkpoint (guardar el mejor modelo), se implementa un Early Stopper de 5 \u00e9pocas que monitoriza nuestra funci\u00f3n f1-score en validaci\u00f3n y tambi\u00e9n una funci\u00f3n `ReduceOnPlateau()` que monitoriza tambi\u00e9n f1-score en validaci\u00f3n y disminuir\u00e1 el learning rate en un 10% si no se presentan mejoras en los \u00faltimas 3 \u00e9pocas. De esta forma se pretende incentivar un aprendizaje m\u00e1s granular en estos puntos de 'no aprendizaje' para tratar de recuperar aprendizaje. ","52cffc9e":"Recalculamos la p\u00e9rdida y el f1-score por si hubiera diferencias.","ca227772":"<div style=\"width: 100%; clear: both;\">\n<div style=\"float: left; width: 50%;\">\n<img src=\"http:\/\/www.uoc.edu\/portal\/_resources\/common\/imatges\/marca_UOC\/UOC_Masterbrand.jpg\", align=\"left\">\n<\/div>\n<div style=\"float: right; width: 50%;\">\n<p style=\"margin: 0; padding-top: 22px; text-align:right;\">M2.875\u00b7Deep Learning \u00b7 Pr\u00e1ctica: Implementaci\u00f3n de un algoritmo para la clasificaci\u00f3n de enfermedades foliares del \u00e1rbol del manzano<\/p>\n<p style=\"margin: 0; text-align:right;\">2020-2 \u00b7 M\u00e1ster Universitario en Ciencia de Datos (MUDS)<\/p>\n<p style=\"margin: 0; text-align:right; padding-button: 100px;\">Estudios de Inform\u00e1tica, Multimedia y Telecomunicaci\u00f3n<\/p>\n<p style=\"margin: 0; text-align:right; padding-button: 100px;\">I\u00f1aki Galech Amillano-MSDS 2020\/21 <a href=\"mailto:igalech@uoc.edu\">igalech@uoc.edu<\/a><\/p>\n<\/div>\n<\/div>\n<div style=\"width:100%;\">&nbsp;<\/div>","d1f076d7":"<div style=\"background-color: #EDF7FF; border-color: #7C9DBF; border-left: 5px solid #7C9DBF; padding: 0.5em;\">\n<strong>Nombre y apellidos:<\/strong> I\u00f1aki Galech Amillano - MSDS 2020\/21  <a href=\"mailto:igalech@uoc.edu\">igalech@uoc.edu<\/a>\n<\/div>","380c1b37":"Construimos una tupla (ficheros, clase predicha), a partir de los arrays anteriores. Una vez construido, lo guardamos en un DataFrame y lo exportamos como test.csv.","5b0776e6":"# <u>Preprocesado de los datos y an\u00e1lisis preliminar<\/u>","87ee366b":"### <u>Gr\u00e1fico mostrando cinco im\u00e1genes por clase<\/u>","1be3fc51":"## <u>Gr\u00e1ficas compartivas ResNet50 vs. DenseNet121 con\/sin entrenamiento de todas las capas<\/u>:\nEl siguiente gr\u00e1fico muestra el resumen comparativo en cuanto a p\u00e9rdida y f1-score en training y validaci\u00f3n de ambos modelos preseleccionados y entrenados tanto con todas las capas como con las 3 \u00faltimas capas (capas fully connected a\u00f1adidas: D64->D16->D6). Los resultados agrupados los tenemos en un fichero CSV dentro del repositorio de datos de la entrega: `\/kaggle\/input\/resultados-modelos-prac1-gpu\/modelos_Resultados_ResNet50_vs_DenseNet121.csv`","c8d19740":"Tomamos nota del orden en el que vienen las etiquetas en el generador de im\u00e1genes del conjunto de entrenamiento-validaci\u00f3n ya que la predicci\u00f3n se efectuar\u00e1 de acuerdo a este orden.","d705d498":"### <u>Modelo ResNet50<\/u>\nSe construye y prueba un modelo basado en ResNet50 con dos variantes: entrenando todo el modelo o \u00fanicamente las capas fully connected finales (D64->D16->D6).","bba4eb40":"## <u>Predicciones sobre el conjunto de im\u00e1genes de test y creaci\u00f3n del fichero test.csv<\/u>\nCalculamos las predicciones de nuestro set de test que hemos creado al principio. Lo podemos hacer si hemos ejecutado la celda anterior (entrenando 30 \u00e9pocas) o tambi\u00e9n si subimos el modelo que hemos guardado previamente en el repositorio Kaggle: '\/kaggle\/input\/resultados-modelos-prac1-gpu\/mejor_modelo_ResNet50Prac1Final.h5'","3dddfc7f":"Guardamos en un array las predicciones con una mayor probabilidad en cada imagen del conjunto de test.","bdaf03e6":"Obtenemos una gr\u00e1fica de nuestras predicciones en porcentaje (frecuencias relativas).","e722bc53":"Calculamos las predicciones en el conjunto de validaci\u00f3n para corroborar el f1-score, el cual calculamos nuevamente.","696ec09f":"Entrenamiento final del ResNet50 con 30 \u00e9pocas y las nuevas m\u00e9tricas.","9958f971":"Entrenamos el modelo RestNet50","d35dc3ef":"# <u>Determinaci\u00f3n de la estrategia de entrenamiento y validaci\u00f3n<\/u>","0e1d4cbb":"### <u>Gr\u00e1ficos con el conteo de etiquetas y de las frecuencias relativas<\/u>","ff5cd91f":"C\u00e1lculo y chequeo del rango din\u00e1mico, canales de color\/grises y data-types. Aunque no es imprescindible, s\u00ed es una buena idea contrastar los data-types, ya que los data types unicode 8, 16 y 32 son m\u00e1s r\u00e1pidos de procesar en Tensorflow.","86623fcb":"Importaci\u00f3n de las librer\u00edas necesarias. **Nota:** En Colab de google es necesario importar la librer\u00eda Kaggle por separado.","d4bec6c1":"# <u>Ap\u00e9ndice<\/u>: Modelos entrenados en el problema original Kaggle y en nuestro problema para la selecci\u00f3n previa de modelos a utilizar.\nA continuaci\u00f3n se presentan los 6 modelos probados tanto para el desaf\u00edo original en Kaggle como para nuestro problema. Los modelos son:  \n1. Resnet50v2  \n2. InceptionV3  \n3. EfficientNetB0  \n4. Resnet50  \n5. IncepcionResNet50V2  \n6. DenseNet121  \n \nPara estos modelos dentro del desaf\u00edo original, es necesario construir unos generadores algo diferentes que toman como input los subdirectorios de las im\u00e1genes reducidas en tama\u00f1o (256), ya que si utilizamos las im\u00e1genes originales \u00e9stas son demasiado grandes en tama\u00f1o y el entrenamiento se ralentiza mucho. En cualquier caso estos generadores requieren de un dataframe diferente, donde las clases se consideran multilabels y la binarizacion (OneHotEncoder) se implementa con un m\u00e9todo diferente MultiLabelBinarizer() de sklearn.preprocessing.\n","339f0a4a":"Para la construcci\u00f3n de este dataframe (df_entreno) hay que referirse a un segundo [notebook](https:\/\/www.kaggle.com\/nameeman\/practica-1-dl-galech-amillano-probl-originalkaggle\/edit) donde se trata el problema Kaggle original (multiclase-multilabel).  \nhttps:\/\/www.kaggle.com\/nameeman\/practica-1-dl-galech-amillano-probl-originalkaggle\/edit","edf45e78":"## <u>Modelo EfficientNetB0:<\/u>","54f8ad80":"## <u>Creaci\u00f3n de modelos y entrenamientos iniciales: DenseNet121 y ResNet50 con\/sin entrenamiento de todas las capas.<\/u>","ccae348b":"### <u>Modelo DenseNet121<\/u>","5a5404a9":"## Enriquecimiento y transformaci\u00f3n de los datos (Data Augmentation):\nGeneramos dos generadores de im\u00e1genes de Keras, uno para el set de entrenamiento y validaci\u00f3n (train_datagen) y otro para el set de test. En los generadores incluimos los siguientes par\u00e1metros que enriquecer\u00e1n las im\u00e1genes, lo cual beneficiar\u00e1 la generalizaci\u00f3n del modelo:\n* Normalizaci\u00f3n\n* Rotaci\u00f3n\n* Ensanchado\n* Alargado\n* Zoom o focalizaci\u00f3n\n* Se le da la vuelta a la imagen sobre el eje de abscisas","c3fcd93d":"Funci\u00f3n general de compilaci\u00f3n de los modelos, introduciendo como optimizador un descenso del gradiente con 'momentum' tipo Nesterov y como m\u00e9trica la funcion f1-score 'macro'.","09c1c397":"## Modelo DenseNet121","d187a8fd":"Eliminamos el prefijo  'test\/' del nombre de los ficheros.","5b3a81a6":"## <u>Modelo InceptionV3:<\/u>","03634a21":"## <u>Gr\u00e1ficas del modelo elegido: Accuracy, f1-score, precision y recall<\/u>\nA continuaci\u00f3n se obtienen las gr\u00e1ficas que incluyen accuracy, f1-score, precision y recall <u>**ponderadas**<\/u> (`average = 'weighted'`) del entrenamiento del modelo ResNet50 elegido.","2f17060c":"Guardamos las etiquetas seg\u00fan vienen en el conjunto de validaci\u00f3n, sin Shuffle. Se utilizar\u00e1 al final para evaluar el f1-score en el entrenamiento.","92b6e1c7":"Por \u00faltmos obtenemos una imagen por clase predicha y la visualizamos para 'comprobar' los resultados.","1ffe1c8b":"A continuaci\u00f3n se muestra la gr\u00e1fica de las <u>frecuencias relativas<\/u> de las distintas etiquetas.","5add04c0":"## <u>Modelo RestNet50:<\/u> \nCreamos y entrenamos el modelo RestNet50 con el mismo set de datos, mismos par\u00e1metros y guardamos tanto el modelo como los resultados del entrenamiento.","8922bb02":"Resumen (conteo) de las predicciones por clases:","69333d84":"## <u>Construcci\u00f3n y entrenamiento de 6 modelos (preselecci\u00f3n)<\/u>:\nSe construyen y entrenan los siguientes modelos para determinar cu\u00e1les de ellos son m\u00e1s prometedores respecto a la m\u00e9trica f1-score(macro) utilizada:  \n\n    1.-Resnet50v2  \n    2.-InceptionV3  \n    3.-EfficientNetB0  \n    4.-Resnet50  \n    5.-IncepcionResNet50V2  \n    6.-DenseNet121  ","bb6faa7f":"Situamos el path en nuestro set de datos, en concreto en el subidectorio \/train.","2599250c":"Se efect\u00faan las predicciones del modelo sobre las im\u00e1genes de test (set_test).","8ed266d9":"# <u>Gr\u00e1ficas del entrenamiento de los modelos<\/u>:\n\nSe muestra a continuaci\u00f3n la evoluci\u00f3n de la p\u00e9rdida y de F1-Score para los conjuntos de entrenamiento y de validaci\u00f3n para nuestros cuatro modelos.","3e4a7da5":"Individualizamos cada etiqueta de cada imagen, ya que cada una trae varias.","e85fc445":"### <u>Modelo EfficientNet80 (problema original):<\/u>","82be2e66":"### <u> Modelo InceptionResNetv2<\/u>","f5810192":"Aqu\u00ed utilizamos tanto los datos de nuestro caso como los **datos originales** del desaf\u00edo Kaggle `\/kaggle\/input\/plant-pathology-2021-fgvc8\/train.csv'` para ir probando diferentes modelos y su performance e idoneidad para nuestro problema.","7bad84ba":"## <u>Modelo DenseNet121:<\/u> \nCreamos y entrenamos el modelo DenseNet121 con el mismo set de datos, mismos par\u00e1metros y guardamos tanto el modelo como los resultados del entrenamiento.","d565e408":"A continuaci\u00f3n, ya elegido el modelo ResNet50 entrenado en su totalidad,, construimos una funci\u00f3n que lo compilar\u00e1 e incluir\u00e1 las m\u00e9tricas adicionales establecidas con nuestro cliente: f1-score, accuracy, precision y recall. Adem\u00e1s, estas m\u00e9tricas facilitar\u00e1n la construcci\u00f3n de la matriz de confusi\u00f3n resultante de nuestro entrenamiento.","7f03a805":"Los siguientes par\u00e1metros son comunes a todos los modelos. Introducen un 'checkpoint' para guardar los mejores modelos seg\u00fan se van obteniendo m\u00e1ximos en nuestra funci\u00f3n (f1-score en validaci\u00f3n). Tambi\u00e9n definimos un EarlyStop con 5 epochs de paciencia y un par\u00e1metro que act\u00faa como reductor del learning rate si se producen situaciones de estancamiento ([`ReduceLROnPlateau()`](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/callbacks\/ReduceLROnPlateau))","2ec84059":"### <u>Modelo ResNet50V2:<\/u>"}}