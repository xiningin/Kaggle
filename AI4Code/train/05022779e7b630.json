{"cell_type":{"b73147fb":"code","1f06acb7":"code","877e776b":"code","30e98592":"code","6f261e7c":"code","ffe5fce6":"code","eafdafaa":"code","9e23e699":"code","b73fe276":"code","4c37ade1":"code","cd652bd1":"code","53c08441":"code","d0410ccc":"code","c1b2ec8c":"code","650610e2":"code","1b218c43":"code","1d5f0a03":"code","eacfb95a":"code","81254cbd":"code","755d4ec4":"code","3549e8c9":"code","0983e5a7":"code","cd048766":"markdown","dbf846f8":"markdown","0ce04ae7":"markdown","c62f571a":"markdown","de99988e":"markdown","bc074a4d":"markdown","e347451f":"markdown","77f02d5c":"markdown","86ad4de0":"markdown","268f0902":"markdown"},"source":{"b73147fb":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom keras.models import Sequential\nfrom keras.layers import LSTM, Dense, Dropout, GRU\n\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"\n\nimport warnings\nwarnings.filterwarnings('ignore')","1f06acb7":"df_train = pd.read_csv(\"..\/input\/sales-train\/sales_train_v2.csv\")\ndf_test = pd.read_csv(\"..\/input\/exploresales\/test.csv\")\n# df_shopname = pd.read_csv(\"shops.csv\") The name of the shop is not needed, as they are already label encoded\n# df_item_cat = pd.read_csv(\"item_categories.csv\") Name of the categories are not needed too\ndf_items = pd.read_csv(\"..\/input\/exploresales\/items.csv\")\ndf_submit = pd.read_csv(\"..\/input\/exploresales\/submission.csv\")","877e776b":"item_dict = df_items[['item_id','item_category_id']].to_dict()\ndf_train['item_cat_id'] = pd.Series()\ndf_train['item_cat_id'] = df_train['item_id'].apply(lambda x : item_dict['item_category_id'][x])","30e98592":"len(df_train)\nlen(df_test)","6f261e7c":"df_train.head()","ffe5fce6":"items = ['shop_id', 'item_cat_id', 'date_block_num']\n\nfor item in items:\n    item_counts = df_train[item].value_counts()\n    sns.barplot(item_counts.index, item_counts.values)\n    plt.title(item+' count')\n    plt.show()","eafdafaa":"df_train.describe()","9e23e699":"df_train[df_train['item_price'] < 0].count()","b73fe276":"df_train[df_train['item_cnt_day'] < 0].count()","4c37ade1":"df_train = df_train[(df_train['item_price'] > 0) & (df_train['item_cnt_day'] > 0)]","cd652bd1":"df_train.head()","53c08441":"dataset = df_train.pivot_table(index=['item_id','shop_id'], columns=['date_block_num'], values=['item_cnt_day'], fill_value=0)","d0410ccc":"dataset.head()","c1b2ec8c":"\ndataset_filtered = pd.merge(df_test, dataset, on=['item_id', 'shop_id'], how='left')\ndataset_filtered.fillna(0, inplace=True)","650610e2":"dataset_filtered.head()","1b218c43":"dataset_filtered.drop(['ID', 'shop_id', 'item_id'], axis=1, inplace=True)","1d5f0a03":"X_train = np.expand_dims(dataset_filtered.values[:, :-1], axis=2) # all rows except the last column\ny_train = dataset_filtered.values[:, -1:] # last column will be our target value\n\nX_test = np.expand_dims(dataset_filtered.values[:, 1:], axis=2) # shifitng the days by 1, to do a predicting on n+1","eacfb95a":"model = Sequential()\nmodel.add(GRU(units=128, return_sequences=True,input_shape=(33,1)))\nmodel.add(Dropout(0.3))\nmodel.add(GRU(units=32))\nmodel.add(Dense(1))\n\nmodel.compile(loss='mse',\n              optimizer='adam',\n              metrics=['mean_squared_error'])\nmodel.summary()","81254cbd":"reg = model.fit(X_train, y_train, batch_size=512, epochs=10)","755d4ec4":"LSTM_prediction = model.predict(X_test)","3549e8c9":"submission = pd.DataFrame({'ID': df_test['ID'], 'item_cnt_month': LSTM_prediction.ravel()})\nsubmission.to_csv('submission.csv',index=False)","0983e5a7":"len(LSTM_prediction)","cd048766":"#### Removing negative item price and counts","dbf846f8":"#### Transforming the data to get item sale count at every month for each shop","0ce04ae7":"### Mapping the item categories to the item ids","c62f571a":"#### Needs data cleaning to remove negative values in item price, and item counts per day. Their count values are small enough for us to remove them","de99988e":"# Data Cleaning\n<hr>","bc074a4d":"# Objective\n\n<hr>\n\n### Predict total sales for every product and store in the next month.\n\nThis looks like a time series problem, and I'll try to tackle it using LSTM\/GRU. Since it has almost 3 millions rows of data, deep learning seems feasible","e347451f":"#### Months 11 and 23, which are year end months, have a lot of sales","77f02d5c":"## Quick data analysis\n<hr>","86ad4de0":"#### Merging with test data to only get those item_id and shop_id in the test set","268f0902":"# Modeling it as a sequence problem\n<hr>"}}