{"cell_type":{"9754f0fd":"code","f19ab122":"code","cf5888e2":"code","6c216dab":"code","ccc1157d":"code","603f77ab":"code","1d1b5e25":"code","65c8fda5":"code","87874569":"code","73f6e647":"code","73f698e5":"code","85df93e4":"code","c023682d":"code","caec4bdf":"code","edadaee3":"code","cb95d6b3":"code","d5d475d0":"code","c572ac23":"code","166832a9":"code","5891e9e5":"code","eaab63c1":"code","ee240e29":"code","12527a2b":"code","152f5569":"code","d0ed76ed":"code","e80e7da8":"code","1b3c0e29":"code","1edccd83":"code","2cb695ea":"code","0640d2ef":"code","9d127708":"code","ec93dae9":"code","ccdfb247":"code","6e84c0a4":"code","78ac0bbf":"code","e87ea100":"code","6a8ca4a2":"code","9f52663c":"code","64af274b":"code","158006a2":"code","c33a02ed":"code","3238aed5":"code","e91e094e":"code","9184dae0":"code","cc973197":"code","5c12c82f":"code","aba08362":"code","d45c2e61":"code","5e71e183":"code","97f1d5c5":"code","1cbe37d7":"code","354ad7bd":"code","c10de668":"code","9aae5c38":"code","77ae593a":"code","67e82ffb":"code","10c53492":"code","8ab9412c":"code","d65140b4":"code","4993c08e":"code","1c275857":"code","1816d04b":"code","ccfc02a0":"markdown","07d03517":"markdown","fc4df8a3":"markdown","0841aa00":"markdown","55548767":"markdown","d8cf7448":"markdown","69132474":"markdown","df86b659":"markdown","41ed1acc":"markdown","8b458589":"markdown","c4dc547a":"markdown","0e204256":"markdown"},"source":{"9754f0fd":"# Importing libraries \n\nimport pandas as pd\nimport numpy as np","f19ab122":"df = pd.read_csv('..\/input\/melbourne-housing-market\/Melbourne_housing_FULL.csv')","cf5888e2":"# Displaying first five records of datset\n\ndf.head()","6c216dab":"# Displays dimension of the dataset i.e no. of rows and columns\n\ndf.shape","ccc1157d":"df.info()","603f77ab":"# Describe the dataset\n\ndf.describe()","1d1b5e25":"# Check for null values\n\ndf.isnull().sum()","65c8fda5":"# Slicing for first 20 rows for the column named 'Method'.\n\ndf[0:20]['Method']","87874569":"# Displaying first 10 records of attributes 'Distane' and 'Price'\n\ndf.loc[0:10,['Distance','Price']]","73f6e647":"# Count no. of unique values in the column 'Method'\n\ndf['Method'].value_counts()","73f698e5":"#separate the numeric columns from the categorical columns\n\n# select numerical columns\ndata_numeric = df.select_dtypes(include=[np.number])\nnumeric_cols = data_numeric.columns.values\n# select non-numeric columns\ndata_non_numeric = df.select_dtypes(exclude=[np.number])\nnon_numeric_cols = data_non_numeric.columns.values","85df93e4":"numeric_cols","c023682d":"non_numeric_cols","caec4bdf":"# Printing contents of attribute 'Price'\n\ndf['Price']","edadaee3":"# Mean and Median of values in column 'Price'\n\nprint(f\"Median : {df['Price'].median()}\")\nprint(f\"Mean : {df['Price'].mean()}\")","cb95d6b3":"# All occurrences of missing_values are imputed by mean Price\n\nfrom sklearn.impute import SimpleImputer\n\nprice_imputer = SimpleImputer(missing_values = np.nan, strategy='median')\n\ndf[['Price']] = price_imputer.fit_transform(df[['Price']])\ndf['Price'].head(10)","d5d475d0":"# Checking null values of attribute 'Distance'\n\ndf['Distance'].isnull().sum()","c572ac23":"df['Distance'].mean()","166832a9":"# Filling null values of attribute 'Distane' using mean \n\ndistance_mean = round(df['Distance'].mean(),1)\ndf['Distance'].fillna(distance_mean, inplace = True)","5891e9e5":"# Checking null values of attribute 'Postcode'\n\ndf['Postcode'].isnull().sum()","eaab63c1":"# Counting unique postcodes in column 'Postcode'\n\ndf['Postcode'].value_counts()","ee240e29":"df['Postcode'].median()","12527a2b":"# fillna() replaces null values of attribute 'Postcode' by median\n\npostcode_median = round(df['Postcode'].median())\ndf['Postcode'].fillna(postcode_median, inplace = True)","152f5569":"# value_counts() finds the unique no. of bedroom counts\n\ndf['Bedroom2'].value_counts()","d0ed76ed":"# Checking null values in column 'Bedroom2'\n\ndf['Bedroom2'].isnull().sum()","e80e7da8":"# Displaying first 20 values of attribute 'Bedroom2'\n\nprint(\"Bedrooms with NULL values\")\ndf['Bedroom2'].head(20)","1b3c0e29":"# Null values of Bedroom replaced by 0\n\ndf['Bedroom2'].fillna(0, inplace= True)\nprint(\"Bedrooms after replacing NULL values\")\ndf['Bedroom2'].head(20)","1edccd83":"# Checking null values in column 'Bathroom'\n\ndf['Bathroom'].isnull().sum()","2cb695ea":"# Displaying first 20 values of attribute 'Bathroom'\n\nprint(\"Bathroom with NULL values\")\ndf['Bathroom'].head(20)","0640d2ef":"# Null values of Bathroom replaced by 1\n\ndf['Bathroom'].fillna(1, inplace= True)\nprint(\"Bathroom after replacing NULL values\")\ndf['Bathroom'].head(20)","9d127708":"# Checking null values in column 'Car'\n\ndf['Car'].isnull().sum()","ec93dae9":"# Displaying first 20 values of attribute 'Car'\n\nprint(\"Car with NULL values\")\ndf['Car'].head(20)","ccdfb247":"# Null values of Car replaced by 0\n\ndf['Car'].fillna(0, inplace= True)\nprint(\"Car after replacing NULL values\")\ndf['Car'].head(20)","6e84c0a4":"# Checking null values in column 'Landsize'\n\ndf['Landsize'].isna().sum()","78ac0bbf":"# Mean and Median values of column 'Landsize'\n\nprint(f\"Median : {df['Landsize'].median()}\")\nprint(f\"Mean : {round(df['Landsize'].mean(),0)}\")","e87ea100":"# Displaying first 20 values of attribute 'Car'\n\nprint(\"Landsize with NULL values\")\ndf['Landsize'].head(20)","6a8ca4a2":"# All occurrences of missing_values are imputed by median Landsize\n\nfrom sklearn.impute import SimpleImputer\n\nland_imputer = SimpleImputer(missing_values = np.nan, strategy='median')\n\ndf[['Landsize']] = land_imputer.fit_transform(df[['Landsize']])\ndf['Landsize'].head(20)","9f52663c":"# Checking NULL values in column BuildingArea\n\ndf['BuildingArea'].isna().sum()","64af274b":"# Mean and Median of values in column 'BuildingArea'\n\nprint(f\"Median : {df['BuildingArea'].median()}\")\nprint(f\"Mean : {round(df['BuildingArea'].mean())}\")","158006a2":"# Dosplaying first 20 values of attribute 'BuildingArea'\n\nprint(\"BuildingArea with NULL values\")\ndf['BuildingArea'].head(20)","c33a02ed":"# All occurrences of missing_values are imputed by mean building area\n\nfrom sklearn.impute import SimpleImputer\n\narea_imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n\ndf[['BuildingArea']] = land_imputer.fit_transform(df[['BuildingArea']])\ndf['BuildingArea'].head(20)","3238aed5":"# Mean and Median of values in column 'YearBuilt'\n\nprint(f\"Median : {df['YearBuilt'].median()}\")\nprint(f\"Mean : {round(df['YearBuilt'].mean())}\")","e91e094e":"# All occurrences of missing_values are imputed by mean YearBuilt\n\nfrom sklearn.impute import SimpleImputer\n\nyear_imputer = SimpleImputer(missing_values = np.nan, strategy='mean')\n\ndf[['YearBuilt']] = land_imputer.fit_transform(df[['YearBuilt']])\ndf['YearBuilt'].head(20)","9184dae0":"# Displaying first 20 values of 'CouncilArea'\n\ndf['CouncilArea'].head(20)","cc973197":"# Appying bfill for NULL values in attribute 'CouncilArea'\n\ndf['CouncilArea'].bfill(inplace=True)","5c12c82f":"df['CouncilArea']","aba08362":"# Checking NULL values in column 'CouncilArea' after bfill\n\ndf['CouncilArea'].isnull().sum()","d45c2e61":"# Checking NULL values in column 'Latitude'\n\ndf['Lattitude'].isnull().sum()","5e71e183":"# ffill: Forward fill (NULL values are replaced by corresponding value in the previous row)\n\ndf['Lattitude'].fillna(method = 'ffill' , inplace=True)","97f1d5c5":"# Checking NULL values in column 'Lattitude' after ffill\n\ndf['Lattitude'].isnull().sum()","1cbe37d7":"# Checking NULL values in column 'Longtitude'\n\ndf['Longtitude'].isnull().sum()","354ad7bd":"# ffill: Forward fill (NULL values are replaced by corresponding value in the previous row)\n\ndf['Longtitude'].fillna(method = 'ffill' , inplace=True)","c10de668":"# Checking NULL values in column 'Lattitude' after ffill\n\ndf['Longtitude'].isnull().sum()","9aae5c38":"# Checking NULL values in column 'Regionname' \n\ndf['Regionname'].isnull().sum()","77ae593a":"# bfill: Backward fill (NULL values are replaced by corresponding value in the previous row)\n\ndf['Regionname'].bfill(inplace=True)","67e82ffb":"df['Regionname']","10c53492":"# Checking NULL values in column 'Regionname' after bfill\n\ndf['Regionname'].isnull().sum()","8ab9412c":"# Checking NULL values in column 'Propertycount'\n\ndf['Propertycount'].isnull().sum()","d65140b4":"# value_counts() finds number of unique properties in each suburb\n\ndf['Propertycount'].value_counts()","4993c08e":"# NULL values of attribute 'Propertycount' are replaced by ffill\n\ndf['Propertycount'].ffill(inplace=True)","1c275857":"# Checking NULL values in column 'Propertycount' after ffill\n\ndf['Propertycount'].isnull().sum()","1816d04b":"df.isnull().sum()","ccfc02a0":"### 4. For assurance let's check for any other NULL or Missing values in dataset","07d03517":"### 3. Pre-processing attributes having null values\n\nTo find and fill the missing data in the dataset \n#### There are 5 ways to find the null values if present in the dataset\n1. `isnull()` \u2014 provides the boolean value for the complete dataset to know if any null value is present or not\n2. `isna()` \u2014 same as the isnull() function, provides the same output\n3. `isna().any()` \u2014 gives a boolean value if any null value is present or not, but it gives results column-wise, not in tabular format\n4. `isna().sum()` \u2014 gives the sum of the null values preset in the dataset column-wise\n5. `isna().any().sum()` \u2014 gives output in a single value if any null is present or not","fc4df8a3":"### 1. Import Pandas and Numpy","0841aa00":"### df.info() :\nGives a summary of the dataframe, displaying number of non-null values and the datatype of each attribute, where 'object' denotes categorical type(non-numeric) and int64\/float64 denotes numeric type","55548767":"### 2. Reading a CSV File\nThe `read_csv` function of the pandas library is used read the content of a CSV file into the python environment as a pandas DataFrame.\nThe function can read the files from the OS by using proper path to the file.","d8cf7448":"### - bfill() :\nIt is used to backward fill the missing values in the dataset. <br\/>\nThe missing values are replaced by values in next row of the same column\n","69132474":"- S - property sold\n- SP - property sold prior\n- PI - property passed in\n- PN - sold prior not disclosed\n- SN - sold not disclosed\n- NB - no bid\n- VB - vendor bid\n- W - withdrawn prior to auction\n- SA - sold after auction\n- SS - sold after auction price not disclosed\n- N\/A - price or highest bid not available","df86b659":"### Imputing techniquess\n1. `fillna` \u2014 filling in null values based on given value (mean, median, mode, or specified value)\n2. `bfill` \/ `ffill` \u2014 stands for backward fill and forward fill (filling in missing values based on the value after or before the column.)\n3. **Simple Imputer** \u2014 Sklearn\u2019s built-in function that imputes missing values (commonly used alongside a pipeline when building ML models)","41ed1acc":"### Cleaning \/ Filling Missing Data\nPandas provides various methods for cleaning the missing values. <br\/>\nThe fillna function can \u201cfill in\u201d NA values with non-null data in a couple of ways\n- Replace NaN with a Scalar Value\n- Replacing \"NaN\" with \"0\".","8b458589":"## Data Pre-processing\n\nThis notebook explains the different data pre-processing techniques applied to the Melbourne housing dataset.","c4dc547a":"### `.loc()` method is used for multi-axes indexing","0e204256":"### Now all NULL values of all attributes are replaced "}}