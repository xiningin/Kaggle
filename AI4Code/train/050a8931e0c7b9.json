{"cell_type":{"110ffccc":"code","e1ef2ca2":"code","5ffb705d":"code","2f873342":"code","7df5f5cb":"code","e3f2ea45":"code","f43b8719":"code","1ecf1edc":"code","721b1ee8":"code","20823375":"code","45af294a":"code","d1b08336":"code","4c387b63":"code","f142860e":"code","2a205f0c":"code","914ba1cd":"code","4035ad59":"code","dfebabfb":"code","f046ef7e":"code","ecf41d45":"code","f92df211":"code","8bf7f71e":"code","c252a294":"code","bc3a8f87":"code","54b11238":"code","ad6700e0":"code","2b5e0848":"code","53cf1206":"code","9ac3445e":"code","879a919c":"code","0fe4582a":"code","d57a7af3":"code","9bf4d9eb":"code","bb9e4ded":"code","e4f88499":"code","e9f77db6":"code","14989c84":"code","ed661d4d":"code","6c64237a":"code","0c5c4fa2":"code","fda430de":"code","8c4ddd6b":"code","4228af8f":"code","085d63c8":"code","97c77711":"code","9a8e19c7":"code","8874c7bd":"code","3693c421":"code","6b75d6e7":"code","e37369c7":"code","227fcabb":"code","92f6b1c1":"code","6dc6bb1b":"code","7f6daec2":"code","e9b6c8ac":"code","86da657b":"code","5ce74adf":"code","33ddf343":"code","0d106129":"code","a3834bab":"code","1eb7dbe4":"code","ee40f4fd":"code","f7c0324f":"code","d243213d":"code","ddf9e0fd":"code","f2e5b0bc":"code","8b06fb48":"code","6f63ee99":"code","ee53743a":"code","6431697c":"code","a5fce97a":"code","eefe5a42":"markdown","f0136896":"markdown","6fff477e":"markdown","6b9d37dd":"markdown","069c3475":"markdown","b5cccff2":"markdown","10d164c3":"markdown","2699d470":"markdown","61ce3bbc":"markdown","85cc1652":"markdown","6ad69e05":"markdown","fd038625":"markdown","1f4a5999":"markdown","e7058b23":"markdown","289430b3":"markdown","9ce35c4b":"markdown","32ea4ac1":"markdown","38f0edee":"markdown","1ba891a1":"markdown","a257dc1d":"markdown","49c788e0":"markdown","c9c660ec":"markdown","42e143a7":"markdown","df1c3c21":"markdown","6de2254d":"markdown","a8405f23":"markdown","d63022b4":"markdown","b308b1a4":"markdown","b9c397bb":"markdown","8938bf55":"markdown","76219064":"markdown","8e34f6a7":"markdown","d9d2d45a":"markdown","a290259f":"markdown"},"source":{"110ffccc":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams[\"figure.figsize\"] = (9,6)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\npd.set_option('display.float_format', lambda x: '%.3f' % x)\npd.set_option('display.max_rows', None)\n\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, classification_report, plot_confusion_matrix\nfrom sklearn.metrics import plot_roc_curve, plot_precision_recall_curve, roc_auc_score, auc, roc_curve, average_precision_score, precision_recall_curve","e1ef2ca2":"df = pd.read_csv('..\/input\/heart-stroke-prediction\/heart.csv')\ndf.head()","5ffb705d":"df.info()","2f873342":"df.duplicated().sum()","7df5f5cb":"df.drop_duplicates(inplace=True)","e3f2ea45":"df.info()","f43b8719":"cat =[\"sex\",\"cp\",\"fbs\",\"restecg\",\"exang\",\"slope\",\"thal\"]\nnum =[\"age\",\"trestbps\",\"chol\",\"thalach\",\"oldpeak\"]","1ecf1edc":"print (f' We have {df.shape[0]} instances with the {df.shape[1]-1} features and 1 target variable')","721b1ee8":"def missing (df):\n    missing_number = df.isnull().sum().sort_values(ascending=False)\n    missing_percent = (df.isnull().sum()\/df.isnull().count()).sort_values(ascending=False)\n    missing_values = pd.concat([missing_number, missing_percent], axis=1, keys=['Missing_Number', 'Missing_Percent'])\n    return missing_values\n\nmissing(df)","20823375":"df[num].describe().T","45af294a":"df[num].skew()","d1b08336":"df[num].hist(figsize=(12,8),bins=20);","4c387b63":"for i in cat:\n    print(\"=\"*30)\n    print(df[i].value_counts())\n    print(\"=\"*30)","f142860e":"for i in cat:\n    plt.figure(figsize=(8,6))\n    sns.countplot(data=df, x=i, hue=\"target\")","2a205f0c":"index = 0\nplt.figure(figsize=(20,20))\nfor feature in df[num]:\n    if feature != \"target\":\n        index += 1\n        plt.subplot(3,3,index)\n        sns.boxplot(x='target',y=feature,data=df)","914ba1cd":"y = df['target']\nprint(f'Percentage of patient had a stroke: % {round(y.value_counts(normalize=True)[1]*100,2)} --> ({y.value_counts()[1]} patient)')\nprint(f'Percentage of patient did not have a stroke: % {round(y.value_counts(normalize=True)[0]*100,2)} --> ({y.value_counts()[0]} patient)')","4035ad59":"sns.countplot(df[\"target\"]);","dfebabfb":"df.corr()[\"target\"].drop(\"target\").sort_values().plot.barh();","f046ef7e":"plt.figure(figsize=(15,8))\nsns.heatmap(df.corr(), annot=True);","ecf41d45":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler","f92df211":"X = df.drop('target',axis=1)\ny = df['target']","8bf7f71e":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)","c252a294":"scaler = MinMaxScaler()\nX_train_scaled = scaler.fit_transform(X_train)\nX_test_scaled = scaler.transform(X_test)","bc3a8f87":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import GridSearchCV","54b11238":"log_model = LogisticRegression(class_weight = \"balanced\")\nlog_model.fit(X_train_scaled,y_train)\ny_pred = log_model.predict(X_test_scaled)\ny_pred_proba = log_model.predict_proba(X_test_scaled)","ad6700e0":"test_data = pd.concat([X_test, y_test], axis=1)\ntest_data[\"pred\"] = y_pred\ntest_data[\"pred_proba\"] = y_pred_proba[:,1]\ntest_data.sample(10)","2b5e0848":"print(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","53cf1206":"from sklearn.model_selection import cross_validate","9ac3445e":"model = LogisticRegression(class_weight = \"balanced\")\n\nscores = cross_validate(model, X_train_scaled, y_train, scoring = ['accuracy', 'precision_weighted','recall_weighted',\n                                                                   'f1_weighted'], cv = 10)\ndf_scores = pd.DataFrame(scores, index = range(1, 11))\ndf_scores.mean()[2:]","879a919c":"from sklearn.metrics import plot_roc_curve, plot_precision_recall_curve, roc_auc_score, auc, roc_curve, average_precision_score, precision_recall_curve","0fe4582a":"plot_roc_curve(log_model, X_test_scaled, y_test);","d57a7af3":"plot_precision_recall_curve(log_model, X_test_scaled, y_test);","9bf4d9eb":"plot_roc_curve(log_model, X_train_scaled, y_train);","bb9e4ded":"y_pred_proba = log_model.predict_proba(X_train_scaled) # Train datas\u0131ndan proba de\u011ferini ald\u0131k\nroc_auc_score(y_train, y_pred_proba[:,1]) # AUC de\u011frerini b\u00f6yle hesapl\u0131yoruz","e4f88499":"fp_rate, tp_rate, thresholds = roc_curve(y_train, y_pred_proba[:,1])","e9f77db6":"optimal_idx = np.argmax(tp_rate - fp_rate) # argmax bu array i\u00e7indeki max de\u011ferin indexini verir\noptimal_threshold = thresholds[optimal_idx] # bu indexi threshold de\u011ferinde yerine yazark optimum th de\u011ferini buldum\noptimal_threshold","14989c84":"test_data[\"pred2\"] = test_data[\"pred_proba\"].apply(lambda x : 1 if x >= optimal_threshold else 0)\ny_pred2 = test_data[\"pred2\"]","ed661d4d":"test_data[(test_data[\"pred_proba\"]>0.4) & (test_data[\"pred_proba\"]<0.6)]","6c64237a":"print(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","0c5c4fa2":"y_pred2 = test_data[\"pred2\"]","fda430de":"print(confusion_matrix(y_test,y_pred2))\nprint(classification_report(y_test,y_pred2))","8c4ddd6b":"from sklearn.neighbors import KNeighborsClassifier","4228af8f":"knn_model = KNeighborsClassifier(n_neighbors=5)\nknn_model.fit(X_train_scaled,y_train)\ny_pred = knn_model.predict(X_test_scaled)\ny_pred_proba = knn_model.predict_proba(X_test_scaled)","085d63c8":"my_dict = {\"Actual\": y_test, \"Pred\":y_pred, \"Proba_1\":y_pred_proba[:,1], \"Proba_0\":y_pred_proba[:,0]}","97c77711":"pd.DataFrame.from_dict(my_dict).sample(10)","9a8e19c7":"print(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","8874c7bd":"test_error_rates = []\n\nfor k in range(1,30):\n    knn_model = KNeighborsClassifier(n_neighbors=k)\n    knn_model.fit(X_train_scaled,y_train) \n   \n    y_pred_test = knn_model.predict(X_test_scaled)\n    \n    test_error = 1 - recall_score(y_test,y_pred_test)\n    test_error_rates.append(test_error)","3693c421":"plt.figure(figsize=(15,8))\nplt.plot(range(1,30), test_error_rates, color='blue', linestyle='--', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K_values')\nplt.ylabel('Error Rate')\n# Ama\u00e7 kabul edilebilir hata oran\u0131na g\u00f6re en k\u00fc\u00e7\u00fck k de\u011ferini se\u00e7mek","6b75d6e7":"# FIRST A QUICK COMPARISON TO OUR ORIGINAL K=1\nknn = KNeighborsClassifier(n_neighbors=1)\n\nknn.fit(X_train_scaled,y_train)\npred = knn.predict(X_test_scaled)\n\nprint('WITH K=1')\nprint('\\n')\nprint(confusion_matrix(y_test, pred))\nprint('\\n')\nprint(classification_report(y_test, pred))","e37369c7":"# NOW WITH K=5\nknn = KNeighborsClassifier(n_neighbors=5)\n\nknn.fit(X_train_scaled,y_train)\npred = knn.predict(X_test_scaled)\n\nprint('WITH K=5')\nprint('\\n')\nprint(confusion_matrix(y_test, pred))\nprint('\\n')\nprint(classification_report(y_test, pred))","227fcabb":"# NOW WITH K=11\nknn_optimal = KNeighborsClassifier(n_neighbors=11)\n\nknn_optimal.fit(X_train_scaled,y_train)\npred = knn.predict(X_test_scaled)\n\nprint('WITH K=11')\nprint('\\n')\nprint(confusion_matrix(y_test, pred))\nprint('\\n')\nprint(classification_report(y_test, pred))","92f6b1c1":"model = KNeighborsClassifier(n_neighbors=11)\n\nscores = cross_validate(model, X_train_scaled, y_train, scoring = ['accuracy', 'precision','recall',\n                                                                   'f1'], cv = 10)\ndf_scores = pd.DataFrame(scores, index = range(1, 11))\ndf_scores.mean()[2:]","6dc6bb1b":"knn_grid = KNeighborsClassifier()\nk_values= range(1,30)","7f6daec2":"param_grid = {\"n_neighbors\":k_values, \"p\": [1,2], \"weights\": ['uniform', \"distance\"]}\nknn_grid_model = GridSearchCV(knn_grid, param_grid, cv=10, scoring= 'recall')","e9b6c8ac":"knn_grid_model.fit(X_train_scaled, y_train)\nknn_grid_model.best_params_","86da657b":"knn_grid_optimal = KNeighborsClassifier(n_neighbors=11, p =1, weights='uniform')\n\nknn.fit(X_train_scaled,y_train)\npred = knn.predict(X_test_scaled)\n\nprint('WITH K=11')\nprint('\\n')\nprint(confusion_matrix(y_test, pred))\nprint('\\n')\nprint(classification_report(y_test, pred))","5ce74adf":"knn_grid_optimal = KNeighborsClassifier(n_neighbors=11, p =1, weights='uniform').fit(X_train_scaled, y_train)","33ddf343":"plot_roc_curve(knn_grid_optimal, X_test_scaled, y_test);","0d106129":"from sklearn.svm import SVC","a3834bab":"svm_model_scaled = SVC()\nsvm_model_scaled.fit(X_train_scaled, y_train)\ny_pred = svm_model_scaled.predict(X_test_scaled)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","1eb7dbe4":"model = SVC(random_state=42)\nscores = cross_validate(model, X_train_scaled, y_train, scoring = ['accuracy', 'precision','recall','f1'], cv = 10)\ndf_scores = pd.DataFrame(scores, index = range(1, 11))\ndf_scores.mean()[2:]","ee40f4fd":"param_grid = {'C': [0.1,1, 10, 100, 1000, 5000, 10000],\n              'gamma': [\"scale\", \"auto\", 1,0.1,0.01,0.001,0.0001],\n              'kernel': ['rbf', 'linear']}","f7c0324f":"model = SVC(random_state=42)\nsvm_model_grid = GridSearchCV(model, param_grid, verbose=3, refit=True)","d243213d":"svm_model_grid.fit(X_train_scaled, y_train)","ddf9e0fd":"svm_model_grid.best_params_","f2e5b0bc":"svm_model_grid.best_estimator_","8b06fb48":"y_pred = svm_model_grid.predict(X_test_scaled)\nprint(confusion_matrix(y_test, y_pred))\nprint(classification_report(y_test, y_pred))","6f63ee99":"log_model = LogisticRegression(class_weight=\"balance\")\nknn_model = KNeighborsClassifier(n_neighbors=11, p=1, weights=\"uniform\")\nsvc_model = SVC(random_state=42, probability=True, C=100, kernel=\"linear\", gamma=\"scale\")\n\nmodels=[knn_model,log_model,svc_model]\nnames=['LogisticRegression','KNeighboursClassifiers','SVC']","ee53743a":"def model_test(X,y,models=models, names=names):\n    for i in range(len(models)):\n        models[i]=models[i].fit(X,y)\n    accuracy=[]\n    precision=[]\n    recall=[]\n    f1=[]\n    for i in range(len(models)):\n        accuracy.append(accuracy_score(y,models[i].predict(X)))\n        \n        precision.append(precision_score(y, models[i].predict(X)))\n        \n        recall.append(recall_score(y, models[i].predict(X)))\n        \n        f1.append(f1_score(y, models[i].predict(X)))\n        \n    metrics=pd.DataFrame(columns=['Accuracy','Precision','Recall','F1'],index=names)\n    metrics['Accuracy']= accuracy\n    metrics['Precision']= precision\n    metrics['Recall']= recall\n    metrics['F1']= f1\n    print(metrics.sort_values('Recall',ascending=False))\n    print()\n    metrics.plot.barh()","6431697c":"model_test(X_train_scaled,y_train)","a5fce97a":" model_test(X_test_scaled,y_test)","eefe5a42":"# Import esential Libraries","f0136896":"**Checking histogram plot of numeric columns**","6fff477e":"# Implement KNN and Evaluate","6b9d37dd":"## Gridsearch Method for Choosing Reasonable K Values","069c3475":"### Cross Validate","b5cccff2":"**Data vocabulary:**\n\n    1. #3 (age): age in years \n    2. #4 (sex): sex (1 = male; 0 = female) \n    3. #9 (cp): cp: chest pain type | Value 0: typical angina | Value 1: atypical angina | Value 2: non-anginal pain | Value 3: asymptomatic \n    4. #10 (trestbps): resting blood pressure (in mm Hg on admission to the hospital) \n    5. #12 (chol): serum cholestoral in mg\/dl \n    6. #16 (fbs): (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false) \n    7. #19 (restecg): resting electrocardiographic results | Value 0: normal | Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV) | Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria \n    8. #32 (thalach): maximum heart rate achieved \n    9. #38 (exang): exercise induced angina (1 = yes; 0 = no) \n    10. #40 (oldpeak): ST depression induced by exercise relative to rest \n    11. #41 (slope): the slope of the peak exercise ST segment | Value 1: upsloping | Value 2: flat | Value 3: downsloping \n    12. #44 (ca): number of major vessels (0-3) colored by flourosopy \n    13. #51 (thal): 3 = normal; 6 = fixed defect; 7 = reversable defect \n    14. #58 (num) (the predicted attribute): Value 0: < 50% diameter narrowing | Value 1: > 50% diameter narrowing ","10d164c3":"### With Best Parameters (GridsearchCV)","2699d470":"#### We examined the numerical columns on the boxplot. \n**Although there are some outlier data, we did not delete the outlier data here because there may be such values in the health data.**","61ce3bbc":"**Missing value control**","85cc1652":"**Our model predicted 1s in test data with a rate of 93%**","6ad69e05":"# Implement SVM and Evaluate","fd038625":"**Checking distribution curve skew of numeric columns**","1f4a5999":"### Elbow Method for Choosing Reasonable K Values","e7058b23":"**Our data seems balanced.**","289430b3":"**Although all our features are numerical, we have separated them categorically and numerically according to the values they take. We did not include the \"target\" column here, we will consider it separately**","9ce35c4b":"# EDA","32ea4ac1":"### With Default Parameters","38f0edee":"**Duplicate value control**","1ba891a1":"# Implement Logistic Regression and Evaluate","a257dc1d":"# Visually compare models based on your chosen metric","49c788e0":"**Showing the value counts of categorical columns by target column on the chart**","c9c660ec":"### We examine the \"target\" column","42e143a7":"**We have one duplicate observation. We dropped it and reset dataframe index**","df1c3c21":"# Ingest the data to notebook","6de2254d":"**Our th value is almost 0.5. When we re-estimate with this value, we will see that there is no change in the results**","a8405f23":"**We examined the correlation of the features according to the target column**","d63022b4":"**The values on the train and test data are almost the same. No overfitting or underfitting**","b308b1a4":"**Statistic insight on the numerical columns**","b9c397bb":"### Cross Validation","8938bf55":"# Data Preprocessing","76219064":"**Shape control**","8e34f6a7":"### ROC (Receiver Operating Curve) and AUC (Area Under Curve)","d9d2d45a":"## Cross Validate For Optimal K Value","a290259f":"**Checking value counts of categorical columns**"}}