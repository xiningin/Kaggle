{"cell_type":{"c318710e":"code","55a6fbc0":"code","c83ee47a":"code","faac232a":"code","0e5d883e":"code","d75df772":"code","7dfba5cf":"code","bd137c7b":"code","7f346fca":"code","cce897cd":"code","059c0478":"code","938002ea":"code","615ce434":"code","c5fb1f47":"code","49f16e0d":"code","66f9ecaa":"code","8e73e592":"code","cbbe7c3a":"code","b15d2d7b":"code","2bf73586":"code","a149c5dd":"code","39b2dc6e":"code","ccade57c":"code","3e885b65":"code","517010a5":"code","19666bac":"code","39cd5dfd":"code","273a4ff7":"markdown","a5333070":"markdown","70d8f06b":"markdown","daa980dd":"markdown","36555355":"markdown","0568ceba":"markdown","3c78ebcb":"markdown","afe31865":"markdown","fe3210d9":"markdown","0e869528":"markdown","3e9cf909":"markdown","93d8fded":"markdown","303e57e2":"markdown","e834e75b":"markdown","6a6c56a3":"markdown","5eeea089":"markdown","e51ded9b":"markdown"},"source":{"c318710e":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport sklearn\nfrom sklearn import metrics\nimport tensorflow as tf\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split, KFold","55a6fbc0":"train = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv\")\n\ntest = pd.read_csv(\"\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv\")\n","c83ee47a":"def evaluate(model, x_val, y_val):\n    y_pred = model.predict(x_val)\n    r2 = metrics.r2_score(y_val, y_pred)\n    mse = metrics.mean_squared_error(y_val, y_pred)\n    mae = metrics.mean_absolute_error(y_val, y_pred)\n    msle = metrics.mean_squared_log_error(y_val, y_pred)\n    mape = np.mean(tf.keras.metrics.mean_absolute_percentage_error(y_val, y_pred))\n    rmse = np.sqrt(mse)\n    rmlse_score = rmlse(y_val, y_pred)\n    print(\"R2 Score:\", r2)\n    print(\"MSE:\", mse)\n    print(\"MAE:\", mae)\n    print(\"MSLE:\", msle)\n    print(\"MAPE\", mape)\n    print(\"RMSE:\", rmse)\n    print(\"RMLSE\", rmlse_score)\n    return {\"r2\": r2, \"mse\": mse, \"mae\": mae, \"msle\": msle, \"mape\": mape, \"rmse\": rmse, \"rmlse\": rmlse_score}","faac232a":"def rmlse(y_true, y_pred):\n    return np.sqrt(np.mean(np.square(np.log(y_pred + 1) - np.log(y_true + 1))))","0e5d883e":"def submit(model, X, ids, file_path):\n    SalePrice = model.predict(X)\n    submission = pd.DataFrame({\"Id\": ids, \"SalePrice\": SalePrice.reshape(-1)})\n    submission.to_csv(file_path, index=False)","d75df772":"train.head()","7dfba5cf":"train.shape","bd137c7b":"train.info()","7f346fca":"train.describe()","cce897cd":"correlation_scores = train.corr()\ncorrelation_scores","059c0478":"train.corr()[\"SalePrice\"].sort_values(key = lambda x: abs(x), ascending=False)","938002ea":"for data in [train, test]:\n    null_counts = data.isnull().sum()\n    null_counts[null_counts > 0]\n    null_columns = list(pd.DataFrame(null_counts[null_counts > 0]).index)\n    for column in null_columns:\n        if data[column].dtype == object:\n            data[column] = data[[column]].replace(np.NAN, \"Unknown\")\n        else:\n            data[column] = data[column].replace(np.NAN, data[column].mean())","615ce434":"train_test = pd.get_dummies(pd.concat([train, test]))","c5fb1f47":"train_test.head()","49f16e0d":"mean_value = train_test.mean()\nstd_value = train_test.std()\nmean_value.pop(\"SalePrice\")\nstd_value.pop(\"SalePrice\")\nprint(mean_value)\nprint(std_value)","66f9ecaa":"train_features = train_test.iloc[0: len(train)]\ntest_features = train_test.iloc[len(train):]\n_ = train_features.pop(\"Id\")\n_ = test_features.pop(\"SalePrice\")\ntest_ids = test_features.pop(\"Id\")","8e73e592":"train_features.corr()","cbbe7c3a":"thresold = 0.05\ncorrelated_scores = train_features.corr()[\"SalePrice\"]\ncorrelated_scores = correlated_scores[correlated_scores.abs() >= thresold]\ncorrelated_columns = list(correlated_scores.index)\ncorrelated_columns.remove(\"SalePrice\")\nprint(correlated_columns)","b15d2d7b":"y = train_features.pop(\"SalePrice\")\nX = train_features","2bf73586":"categorical_columns = set(train.dtypes[train.dtypes==object].index)","a149c5dd":"scale_strategies = [\"none\", \"standard_scale\", \"standard_scale_exclude_categorcial_features\"]\nscale_strategy = scale_strategies[2]\nif scale_strategy == scale_strategies[1]:\n    X = (X - mean_value) \/ std_value\n    test_features = (test_features - mean_value) \/ std_value\nif scale_strategy == scale_strategies[2]:\n    for column in train_features.columns:\n        is_categorical_feature = False\n        components = column.split(\"_\")\n        if len(components) == 2 and components[0] in categorical_columns:\n            is_categorical_feature = True\n        if is_categorical_feature == False:\n            for features in [X, test_features]:\n                features.loc[:, column] = (features.loc[:, column] - mean_value[column]) \/ std_value[column]","39b2dc6e":"X.head()","ccade57c":"use_correlated_columns = True\nif use_correlated_columns:\n    X = X[correlated_columns]\n    test_features = test_features[correlated_columns]","3e885b65":"import xgboost\nimport time\nimport sklearn\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_absolute_error\ndef train_with_xgboost(hyperparameters, X_train,  y_train, X_val = None, y_val = None):\n    keys = hyperparameters.keys()\n    #for key in keys:\n    #    hyperparameters[key] = sklearn.utils.shuffle(hyperparameters[key])\n    best_index = {key:0 for key in keys}\n    best_model = None\n    best_parameters = None\n    best_score = 10e8\n    for (index, key) in enumerate(keys):\n        print(\"Find best parameter for %s\" %(key))\n        items = hyperparameters[key]\n        best_parameter = items[best_index[key]]\n        for (key_index, item) in enumerate(items):\n            params = {key2: hyperparameters[key2][best_index[key2]] if key2 != key else item for key2 in keys}\n            print(\"Training with %s\" %(params))\n            model = xgboost.XGBRegressor(\n                **params\n            )\n            model.fit(X_train, y_train, verbose=False)\n            if len(X_val) != 0 and len(y_val) != 0:\n                result = evaluate(model, X_val, y_val)\n            else:\n                result = evaluate(model, X_train, y_train)\n            score = result[\"rmlse\"]\n            if score < best_score:\n                best_score = score\n                best_index[key] = key_index\n                best_parameter = item\n                best_model = model\n                best_parameters = params\n        print(\"Best Parameter for %s: \"%(key), best_parameter)\n    return best_model, best_score, best_parameters","517010a5":"def split_data(X, y, strategy):\n    if not strategy in [\"full\", \"kfold\", \"train_validation_split\"]:\n        return (0, [], [], [], [])\n    if strategy == \"full\":\n        yield (0, X, y, [], [])\n    for index, (train_indices, valid_indices) in enumerate(KFold(n_splits=5, shuffle=True).split(X)):\n            X_train = X.iloc[train_indices]\n            X_val = X.iloc[valid_indices]\n            y_train = y.iloc[train_indices]\n            y_val = y.iloc[valid_indices]\n            yield (index, X_train, y_train, X_val, y_val)\n            if strategy != \"kfold\":\n                break","19666bac":"parameters = {\n    \"max_depth\": list(range(4, 10)),\n    \"learning_rate\": list(np.linspace(0.03, 0.15, 13)),\n    \"booster\": [\"gbtree\", \"gblinear\", \"dart\"],\n}\nmodels = []\nfor strategy in [\"full\", \"kfold\"]:\n    for (index, X_train, y_train, X_val, y_val) in split_data(X, y, strategy):\n        begin = time.time()\n        best_model, best_score, best_parameters = train_with_xgboost(parameters, X_train, y_train, X_val, y_val)\n        print(\"Best RMLSE: \", best_score)\n        print(\"Best Parameters: \", best_parameters)\n        elapsed = time.time() - begin \n        print(\"Elapsed time: \", elapsed)\n        submit(best_model, test_features, test_ids, \"submission_%s_%d.csv\"%(strategy, index))\n        models.append(best_model)","39cd5dfd":"SalePrice = np.mean([model.predict(test_features) for model in models], axis=0)\nsubmission = pd.DataFrame({\"Id\": test_ids, \"SalePrice\": SalePrice})\nsubmission.to_csv(\"submission.csv\", index=False)","273a4ff7":"### Calculate Correlated Features","a5333070":"**Statistic infos**","70d8f06b":"### Feature Scaling","daa980dd":"**Submission**","36555355":"### Convert Categorical Features to Numerical Features","0568ceba":"## Exploratory Data Analysis & Data Preprocessing","3c78ebcb":"\n## If you found my work useful, please give me an upvote, thanks.","afe31865":"## Common Functions","fe3210d9":"**Evaluation Function**","0e869528":"### Missing Value Imputation\n\nI will use following strategies to apply imputation to missing values. \n- For numerical columns, I will replace missing value with their mean value.\n- For categorical columns, I will replace missing value with unknown category.","3e9cf909":"## House Price Regression with XGBoost\n## Table of Contents\n- Summary\n- Import Packages\n- Import Datasets\n- Common Functions\n- Exploratory Data Analysis & Data Preprocessing\n    - Statistic infos\n    - Missing Value Imputation\n    - Convert Categorical Features to Numerical Features\n    - Train Validation Split\n    - Calculate Correlated Features\n    - Feature Scaling\n- Model Development and Evaluation\n\n## Summary\nIn this notebook, I will use XGBoost to create House Price Predictor and use hyperparameter searching techniques to find best results.","93d8fded":"**Root Mean Squared Logarithmic Error**","303e57e2":"**Correlation scores**","e834e75b":"## Import Packages","6a6c56a3":"**Factors that impact house price most**","5eeea089":"## Model Development and Evaluation","e51ded9b":"## Import Datasets"}}