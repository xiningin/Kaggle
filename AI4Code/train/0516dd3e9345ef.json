{"cell_type":{"60506988":"code","22394b7c":"code","60b3fc31":"code","bff9f5ec":"code","11539f27":"code","67e8cead":"code","a330eb01":"code","8024e556":"code","eb243cbf":"code","19d8d417":"code","c08e775f":"code","837013b4":"code","5b2d4e83":"code","f8f1011f":"code","0252358c":"code","d2283082":"code","9dfe2b7f":"code","432fe951":"code","c89ae0eb":"code","e26b257c":"code","6d1b6df9":"code","2347d842":"code","aeb89aed":"code","87faef36":"code","d334a606":"code","7b95afaf":"code","9431f308":"code","b6bfecb9":"code","da774237":"code","602500a7":"code","d8201e18":"code","9e4c229e":"code","c0a66853":"code","63f36107":"code","bb5dc263":"code","9aa5cfaf":"code","e1b97a66":"code","8aa5f12e":"code","677342cc":"code","93dd7076":"markdown","47e59ac6":"markdown","8e55d9c2":"markdown","a85f9c0a":"markdown","a4b28773":"markdown","6d8d9ee3":"markdown","290b5e18":"markdown","f20c59c4":"markdown","f3e4a6a6":"markdown","e2547cf0":"markdown","bcdef7ed":"markdown","80ddc376":"markdown","163c8053":"markdown","9e4cea99":"markdown","f3ef66a9":"markdown","f27c4a23":"markdown","eb27da4e":"markdown","965b4c2b":"markdown","64d37751":"markdown","5f0e21d8":"markdown","86307ff5":"markdown","f15b0cfe":"markdown","fd6ecf5f":"markdown"},"source":{"60506988":"import seaborn as sns\nimport matplotlib\nimport matplotlib.pyplot as plt\nimport pandas as pd\nimport numpy as np\nimport os\nimport re\nimport pickle\n\nfrom IPython.display import display\nfrom collections import Counter\nfrom functools import partial\n\nimport warnings\nwarnings.filterwarnings(action='ignore', category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore', category=FutureWarning)\nfrom pprint import pprint","22394b7c":"from sklearn.model_selection import RandomizedSearchCV, StratifiedKFold, KFold\nfrom sklearn.preprocessing import PolynomialFeatures\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom lightgbm import LGBMClassifier, LGBMRegressor","60b3fc31":"from google.colab import drive\ndrive.mount('\/content\/gdrive\/')\n\npath_to_files = '\/content\/gdrive\/My Drive\/_made\/auctions\/'","bff9f5ec":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","11539f27":"path_to_files = '\/kaggle\/input\/real-time-advertisers-auction\/'","67e8cead":"#calculating CPM\n#calculating the value that the Advertisers Bid for the month of June\n# CPM(the value which was the winning bid value) = \n#((revenue of the publisher*100)\/revenue_share_percentage)\/measurable_impressions)*1000\n\ndef weird_division(n, d):\n    return n \/ d if d else 0\n\n# all_data['CPM'] = all_data.apply(lambda x: weird_division( x['total_revenue'] * 100 , x['measurable_impressions']) * 1000 , axis = 1)","a330eb01":"all_data = pd.read_csv(path_to_files + 'Dataset.csv')\nall_data['CPM'] = all_data.apply(lambda x: weird_division( x['total_revenue'] * 100 , x['measurable_impressions']) * 1000 , axis = 1)\n(all_data['CPM'] < 0).sum(), (all_data['CPM'] == 0).sum(), (all_data['CPM'] > 0).sum()","8024e556":"all_data = pd.read_csv(path_to_files + 'Dataset.csv')\nall_data['CPM'] = all_data.apply(lambda x: weird_division( x['total_revenue'] * 100 , x['measurable_impressions']) * 1000 , axis = 1)\nall_data = all_data.query(\"CPM >= 0\")\ntrain_data = all_data.query(\"date < '2019-06-22'\")\ntest_data = all_data.query(\"date >= '2019-06-22'\")","eb243cbf":" f\"{np.quantile(all_data['CPM'], q = 0.95):.4f} {np.quantile(train_data['CPM'], q = 0.95):.4f} {np.quantile(test_data['CPM'], q = 0.95):.4f}\"","19d8d417":"np.quantile(all_data['CPM'], q = np.arange(0,1.01,0.01))[90:]","c08e775f":"train_data = train_data[train_data['CPM'] < np.quantile(test_data['CPM'], q = 0.95)].reset_index(drop = True)\ntest_data = test_data[test_data['CPM'] < np.quantile(test_data['CPM'], q = 0.95)].reset_index(drop = True)","837013b4":"plt.figure(figsize = (10,6))\n\nsns.distplot(train_data['CPM'], color = 'magenta')\nsns.distplot(test_data['CPM'], color = 'forestgreen')\nplt.grid(True)","5b2d4e83":"EPS = 1\n\nplt.figure(figsize = (10,6))\n\nsns.distplot(np.log(train_data['CPM'] + EPS), color = 'magenta')\nsns.distplot(np.log(test_data['CPM'] + EPS), color = 'forestgreen')\nplt.grid(True)","f8f1011f":"EPS = 1\n\nplt.figure(figsize = (10,6))\n\nsns.distplot(np.log(train_data['CPM'][train_data['CPM'] > 0]), color = 'magenta')\nsns.distplot(np.log(test_data['CPM'][test_data['CPM'] > 0]), color = 'forestgreen')\nplt.grid(True)","0252358c":"drops = ['CPM', 'date', 'total_revenue', 'integration_type_id', 'revenue_share_percent']\nfeatures = [f for f in train_data.columns if f not in drops]\n\ncat_features = [f for f in features if f.endswith('_id')]\nnum_features = [f for f in features if f not in cat_features]","d2283082":"from tqdm.notebook import tqdm\ncat_unions = {}\nfor f in tqdm(cat_features):\n    train_gb = train_data.groupby(f)[['CPM']].agg(['mean', 'count'])\n    test_gb = test_data.groupby(f)[['CPM']].agg(['mean', 'count'])\n    inconsistent_categories = pd.merge(train_gb, test_gb, left_index = True, right_index = True, how = 'outer')\n    if inconsistent_categories.isna().sum(axis = 0).sum() > 0:\n        cat_unions[f] = set(inconsistent_categories.index[inconsistent_categories.isna().sum(axis = 1) > 0])\n        print(f'{len(train_data[train_data[f].isin(cat_unions[f])])} rows in train have categories in {f} which are not in the test')","9dfe2b7f":"for f in tqdm(cat_features):\n    drop_criteria = cat_unions.get(f, None)\n    if drop_criteria:\n        print(f' dropping {len(train_data[train_data[f].isin(drop_criteria)])} rows from train cause of {f}')\n        train_data = train_data[~train_data[f].isin(drop_criteria)]\n        print(f'{len(train_data)} rows left')","432fe951":"for f in tqdm(features):\n    plt.figure(figsize = (8,8))\n    _ = sns.scatterplot(data = train_data, y = 'CPM', x = f)","c89ae0eb":"for f in tqdm(features):\n    if f in cat_features:\n        train_data[f] = train_data[f].astype(int)\n        test_data[f] = test_data[f].astype(int)\n    plt.figure(figsize = (10,6))\n    sns.distplot(train_data[f], color = 'mediumorchid')\n    sns.distplot(test_data[f], color = 'gold')\n    \n#### \u0447\u0442\u043e \u044d\u0442\u043e \u0442\u0430\u043a\u043e\u0435??!","e26b257c":"# from itertools import combinations\n# from copy import deepcopy\n\n# train_data['weekday'] = pd.to_datetime(train_data['date']).dt.weekday\n# test_data['weekday'] = pd.to_datetime(test_data['date']).dt.weekday\n\n# cat_features += ['weekday']\n\n# exclude_features = []\n\n# CAT_UPPER_BOUND = 200\n\n# for c in tqdm(cat_features):\n#     if len(train_data[c].unique()) > CAT_UPPER_BOUND:\n#         exclude_features.append(c)\n#     train_data[c] = train_data[c].astype(str)\n#     test_data[c] = test_data[c].astype(str)\n    \n# cross_cat_features = []\n# for c1, c2 in tqdm(list(combinations(cat_features, 2))):\n#     if c1 != c2:\n#         c = f'{c1}_{c2}'\n#         train_data[c] = train_data[c1].values + '_' + train_data[c2].values\n#         test_data[c] = test_data[c1].values + '_' + test_data[c2].values\n#         if len(train_data[c].unique()) > CAT_UPPER_BOUND:\n#             exclude_features.append(c)\n#         cross_cat_features.append(c)","6d1b6df9":"# from sklearn.preprocessing import LabelEncoder\n# cat_encoders = {}\n# new_cat_value = 'NAN'\n\n# cat_features = [f for f in cat_features if f not in exclude_features] \n# cat_features_init = deepcopy(cat_features)\n# cat_features += [f for f in cross_cat_features if f not in exclude_features] \n\n# for c in tqdm(cat_features):\n#     encoder = LabelEncoder()\n#     encoder.fit(train_data[c].fillna(new_cat_value))\n#     le = dict(zip(encoder.classes_, encoder.transform(encoder.classes_)))\n#     if new_cat_value not in le:\n#         le[new_cat_value] = -1\n#     cat_encoders[c] = le\n#     train_data[c] = train_data[c].fillna(new_cat_value).apply(lambda x: x if x in le else new_cat_value).replace(le)\n#     test_data[c] = test_data[c].fillna(new_cat_value).apply(lambda x: x if x in le else new_cat_value).replace(le)\n\n# from sklearn.preprocessing import PolynomialFeatures\n# pf = PolynomialFeatures(2)\n# train_pf = pd.DataFrame(pf.fit_transform(train_data[num_features]))\n# test_pf = pd.DataFrame(pf.transform(test_data[num_features]))\n# poly_features = [f'pf_{i}' for i in range(train_pf.shape[1])]\n# train_pf.columns = poly_features\n# test_pf.columns = poly_features\n\n# train_data = pd.concat([train_data, train_pf], axis = 1)\n# test_data = pd.concat([test_data, test_pf], axis = 1)","2347d842":"# with open(path_to_files + 'poly_features.pkl', 'wb') as f:\n#     pickle.dump(poly_features, f)\n# with open(path_to_files + 'cat_features_init.pkl', 'wb') as f:\n#     pickle.dump(cat_features_init, f)\n# with open(path_to_files + 'cat_features.pkl', 'wb') as f:\n#     pickle.dump(cat_features, f)\n# with open(path_to_files + 'cross_cat_features.pkl', 'wb') as f:\n#     pickle.dump(cross_cat_features, f)\n# with open(path_to_files + 'num_features.pkl', 'wb') as f:\n#     pickle.dump(num_features, f)\n# with open(path_to_files + 'cat_encoders.pkl', 'wb') as f:\n#     pickle.dump(cat_encoders, f)","aeb89aed":"# train_data.to_csv(path_to_files + 'train.csv', index = False)\n# test_data.to_csv(path_to_files + 'test.csv', index = False)","87faef36":"from sklearn.metrics import make_scorer\nimport scipy.optimize\n\ndef mean_absolute_percentage_error(y_true, y_pred): \n    return np.mean(np.abs((y_true - y_pred) \/ y_true)) * 100\n\ndef mean_absolute_error(y_true, y_pred): \n    return np.mean(np.abs((y_true - y_pred)))\n\ndef mean_squared_error(y_true, y_pred): \n    return np.mean((y_true - y_pred) ** 2)\n\ndef get_importances(lgb):\n    return pd.DataFrame({'feature':lgb.booster_.feature_name(), 'importance': lgb.booster_.feature_importance('gain'),}).sort_values(by = 'importance', ascending = False)\n\ndef calc_optimal_shift(y_true, y_predicted):\n\n    start_point = (y_true - y_predicted).mean(axis = 0)\n    def f(x):\n        return mean_squared_error(y_true, y_predicted + x)\n    res = scipy.optimize.minimize(f, start_point, method='nelder-mead', options={'xtol': 1e-4, 'disp': True})\n\n    return res.x\n\ndef calc_optimal_alpha(y_true, y_predicted):\n\n    alpha = 1\n    def f(alpha):\n        return mean_squared_error(y_true, alpha * y_predicted)\n    res = scipy.optimize.minimize(f, alpha, method='nelder-mead', options={'xtol': 1e-4, 'disp': True})\n\n    return res.x\n\nmape_scorer = make_scorer(mean_absolute_percentage_error, greater_is_better = False)\nmae_scorer = make_scorer(mean_absolute_error, greater_is_better = False)\nmse_scorer = make_scorer(mean_squared_error, greater_is_better = False)","d334a606":"lgb_params = {'max_depth': 3, 'num_leaves': 16, 'n_estimators':800, 'min_child_samples':100}\nlgb_grid = {'max_depth': np.arange(2, 10), 'num_leaves': 2**np.arange(3,10),\n            'reg_alpha': 10.0**np.arange(-2, 3), 'reg_lambda': 10.0**np.arange(-2, 3), 'feature_fraction': np.arange(0.7, 1.1, 0.1),\n            'n_estimators':np.linspace(50, 1000, 100, dtype = int), 'min_child_samples':np.linspace(50, 1000, 100, dtype = int)}","7b95afaf":"X_train, y_train = train_data[features], train_data['CPM']\nX_val, y_val = test_data[features], test_data['CPM']\n\n# X_train, y_train = train_data[cat_features_init + num_features + poly_features], train_data['CPM']\n# X_val, y_val = test_data[cat_features_init + num_features + poly_features], test_data['CPM']","9431f308":"%%time\nlgb = LGBMRegressor(random_state = 8, metric = None, n_jobs = -1, objective = 'mse')\ngrid = RandomizedSearchCV(lgb, param_distributions = lgb_grid, cv = KFold(2, random_state = 8),\n                          n_jobs= -1, refit = False,\n                          n_iter = 10, scoring = mse_scorer, verbose = True, random_state = 8)\ngrid.fit(X_train, y_train,\n         eval_metric = 'mse', early_stopping_rounds = 50, eval_set = (X_val, y_val),\n         **{'categorical_feature': cat_features}\n         )\n\ngrid.best_params_, grid.best_score_","b6bfecb9":"pprint(grid.best_params_)\nlgb_best = lgb.set_params(**grid.best_params_)\nlgb_best.set_params(**{'n_estimators': 5000,\n                       'objective': 'mse'})\n\nlgb_best.fit(X_train, y_train,\n         eval_metric = 'mse', early_stopping_rounds = 50, eval_set = (X_val, y_val),\n         **{'categorical_feature': cat_features}\n         )","da774237":"imps = get_importances(lgb_best)\nfig, ax = plt.subplots(1,1,figsize = (20,6))\nimps[['importance']].plot(kind = 'bar', ax = ax)\n_ = ax.set_xticklabels(imps['feature'])","602500a7":"y_train_pred = lgb_best.predict(X_train)\ny_val_pred = lgb_best.predict(X_val)\nmean_squared_error(y_train, y_train_pred), mean_squared_error(y_val, y_val_pred)","d8201e18":"plt.figure(figsize = (10,6))\n\nsns.distplot(y_train, color = 'mediumorchid')\nsns.distplot(y_train_pred, color = 'crimson')\nsns.distplot(y_val, color = 'forestgreen')\nsns.distplot(y_val_pred, color = 'gold')\nplt.grid(True)","9e4c229e":"def clip_correction(y_predicted, low = 0, high = np.inf):\n    return np.clip(y_predicted, low, high)\n\ndef calc_optimal_transformation(y_true, y_predicted):\n\n    x = np.array([1,1])\n    def f(x):\n        return mean_squared_error(y_true, x[0] + x[1] * y_predicted)\n    res = scipy.optimize.minimize(f, x, method='nelder-mead', options={'xtol': 1e-4, 'disp': True})\n\n    return res.x","c0a66853":"mean_squared_error(y_train, clip_correction(y_train_pred)), mean_squared_error(y_val, clip_correction(y_val_pred))","63f36107":"calc_optimal_transformation(y_train, clip_correction(y_train_pred)), calc_optimal_transformation(y_val, clip_correction(y_val_pred))","bb5dc263":"linear_correction_coefs = calc_optimal_transformation(y_val, clip_correction(y_val_pred))","9aa5cfaf":"with open(path_to_files+'lgb_final_model.pkl', 'wb') as f:\n    pickle.dump(lgb_best, f)","e1b97a66":"display(X_train.head())\ndisplay(X_val.head())","8aa5f12e":"final_forecast = linear_correction_coefs[0] + linear_correction_coefs[1] * clip_correction(y_val_pred)","677342cc":"f'Final MSE Value on Test :{mean_squared_error(y_val, final_forecast):.4f}'","93dd7076":"### reading data","47e59ac6":"### \u0431\u0443\u0441\u0442\u0438\u043d\u0433 \u0432 \u0440\u0435\u0433\u0440\u0435\u0441\u0441\u0438\u044f\u0445 \u0432 \u0441\u0438\u043b\u0443 \u0441\u0432\u043e\u0435\u0439 \u043f\u0440\u0438\u0440\u043e\u0434\u044b \u043f\u043e\u0441\u0442\u0440\u043e\u0435\u043d\u0438\u044f \u0438\u043d\u043e\u0433\u0434\u0430 \u0437\u0430\u043b\u0435\u0437\u0430\u0435\u0442 \u0432 \u043e\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043b\u044c\u043d\u0443\u044e \u043e\u0431\u043b\u0430\u0441\u0442\u044c, \u0434\u0430\u0436\u0435 \u0435\u0441\u043b\u0438 true target \u043d\u0435\u043e\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043b\u0435\u043d - \u043f\u043e\u0434\u043a\u043e\u0440\u0440\u0435\u043a\u0442\u0438\u0440\u0443\u0435\u043c\n\n\n\u0430 \u0440\u0430\u0437 \u0443\u0436 \u0440\u0435\u0448\u0438\u043b\u0438 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u043f\u043e\u0434 test, \u0442\u043e \u0435\u0449\u0451 \u0438 \u043b\u0438\u043d\u0435\u0439\u043d\u044b\u0439 \u0441\u0434\u0432\u0438\u0433 \u043a \u043f\u0440\u043e\u0433\u043d\u043e\u0437\u0443 \u043d\u0430\u0439\u0434\u0451\u043c","8e55d9c2":"### \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044f","a85f9c0a":"### feature exploration","a4b28773":"### features distribution","6d8d9ee3":"### feature generation\n\n\n\u0432 \u0438\u0442\u043e\u0433\u0435 \u043f\u043e\u0437\u0432\u043e\u043b\u044f\u0435\u0442 \u043b\u0438\u0448\u044c \u0441\u0438\u043b\u044c\u043d\u0435\u0435 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0438\u0442\u044c\u0441\u044f \u043f\u043e\u0434 train - \u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u043c, \u043d\u043e \u0434\u043b\u044f \u0438\u0441\u0442\u043e\u0440\u0438\u0438 \u043e\u0441\u0442\u0430\u0432\u0438\u043c","290b5e18":"### CPM calculation","f20c59c4":"### grid settings","f3e4a6a6":"#### \u0432\u0440\u043e\u0434\u0435 \u0431\u044b \u0442\u0430\u043a\u043e\u0439 \u0432\u0430\u0440\u0438\u0430\u043d\u0442 \u0441\u043f\u043b\u0438\u0442\u0430 \u0438 \u0432\u0438\u043d\u0437\u043e\u0440\u0438\u0437\u0430\u0446\u0438\u0438 \u0441\u0430\u043c\u044b\u0439 \u0430\u0434\u0435\u043a\u0432\u0430\u0442\u043d\u044b\u0439","e2547cf0":"### \u0435\u0449\u0451 \u0440\u0430\u0437 \u0443\u0431\u0435\u0434\u0438\u043c\u0441\u044f, \u0447\u0442\u043e \u043d\u0435 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0438 \u043d\u0438\u0447\u0435\u0433\u043e \u043b\u0438\u0448\u043d\u0435\u0433\u043e","bcdef7ed":"### \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043c \u043c\u043e\u0434\u0435\u043b\u044c","80ddc376":"### \u043e\u043f\u0440\u0435\u0434\u0435\u043b\u0438\u043c \u043d\u0435\u043a\u043e\u043d\u0441\u0442\u0438\u0441\u0442\u0435\u043d\u0442\u043d\u044b\u0435 \u0441 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0435\u0439 \u0444\u0438\u0447\u0438 \u043d\u0430 \u0442\u0435\u0441\u0442\u043e\u0432\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435","163c8053":"\u0412 \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0435 train \u043d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043e 21.06.2019 \u0432\u043a\u043b\u044e\u0447\u0438\u0442\u0435\u043b\u044c\u043d\u043e, \u0434\u043b\u044f test - \u0432\u0441\u0435 \u043e\u0441\u0442\u0430\u0432\u0448\u0438\u0435\u0441\u044f (\u0432\u0430\u0436\u043d\u043e: \u0438\u0437 test \u0438\u0441\u043a\u043b\u044e\u0447\u0430\u044e\u0442\u0441\u044f \u043e\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f, \u0430 \u0442\u0430\u043a\u0436\u0435 \u043e\u0431\u0440\u0435\u0437\u0430\u044e\u0442\u0441\u044f \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f \u0441\u043f\u0440\u0430\u0432\u0430 \u043f\u043e 95 \u043f\u0435\u0440\u0446\u0435\u043d\u0442\u0438\u043b\u044e)\n\n- \u043d\u0435 \u0441\u043e\u0432\u0441\u0435\u043c \u043e\u0434\u043d\u043e\u0437\u043d\u0430\u0447\u043d\u043e\u0435 \u0443\u0441\u043b\u043e\u0432\u0438\u0435, \u043f\u0440\u0435\u0434\u043f\u043e\u043b\u0430\u0433\u0430\u0435\u043c, \u0447\u0442\u043e \u043a\u0432\u0430\u043d\u0442\u0438\u043b\u044c \u0431\u0435\u0440\u0451\u0442\u0441\u044f \u043f\u043e\u0441\u043b\u0435 \u0438\u0441\u043a\u043b\u044e\u0447\u0435\u043d\u0438\u044f \u043e\u0442\u0440\u0438\u0446\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0445 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u0438 \u0442\u043e\u043b\u044c\u043a\u043e \u043f\u043e \u0440\u0430\u0441\u043f\u0440\u0435\u0434\u0435\u043b\u0435\u043d\u0438\u044e \u043d\u0430 test-\u0432\u044b\u0431\u043e\u0440\u043a\u0435","9e4cea99":"#### \u043b\u043e\u0433\u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u0435\u043d\u044c\u043a\u043e \u0442\u0430\u043a, \u0445\u043e\u0442\u044f \u0434\u0430\u0436\u0435 \u0438 \u043d\u0435 \u0442\u0430\u043a (\u0441\u043c. \u043d\u0438\u0436\u0435) - \u0447\u0442\u043e-\u0442\u043e zero-inflated, \u043d\u043e \u043d\u0435\u043f\u0440\u0435\u0440\u044b\u0432\u043d\u043e, \u0430 \u043d\u0435 Poisson","f3ef66a9":"### metrics & optimizations","f27c4a23":"### direct mse optimization through stochastic grid search\n\n\n\n","eb27da4e":"### target distribution","965b4c2b":"### \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0438\u043c \u043d\u0430 \u0431\u0430\u0437\u043e\u0432\u044b\u0435 \u0437\u043d\u0430\u0447\u0438\u043c\u043e\u0441\u0442\u0438","64d37751":"### \u043a\u0430\u0436\u0435\u0442\u0441\u044f, \u0432\u043f\u043e\u043b\u043d\u0435 \u043d\u0435\u043f\u043b\u043e\u0445\u043e\n\n\u0434\u0430, \u043c\u044b \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0438 \u0442\u0435\u0441\u0442 \u0432\u044b\u0431\u043e\u0440\u043a\u0443 \u043f\u0440\u0438 \u043e\u0442\u0431\u043e\u0440\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u0439 \u043a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u044b\u0445 \u0444\u0438\u0447\u0435\u0439 \u0438 \u043f\u0440\u0438 early stopping, \u043d\u043e \u043d\u0435 \u0442\u043e, \u0447\u0442\u043e\u0431\u044b \u0442\u044e\u043d\u0438\u043b\u0438\u0441\u044c \u043f\u043e\u0434 \u043d\u0435\u0435 \u0441\u0438\u043b\u044c\u043d\u043e \u044f\u0432\u043d\u043e\n\n\u044d\u0442\u043e \u043d\u0435 best practice, \u043d\u043e \u0437\u0434\u0435\u0441\u044c-\u0442\u043e \u0437\u0430\u0434\u0430\u0447\u0430 \u0441\u0442\u043e\u0438\u0442 \u0438\u043c\u0435\u043d\u043d\u043e \u043d\u0430 \u043d\u0435\u0439 \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0438\u0440\u043e\u0432\u0430\u0442\u044c mse, \u0442\u0430\u043a \u0447\u0442\u043e..","5f0e21d8":"### winsorization + train-test time split","86307ff5":"#### \u043e\u0447\u0435\u043d\u044c \u0445\u0432\u043e\u0441\u0442\u0430\u0442\u043e \u0432\u0441\u0451","f15b0cfe":"### scoring","fd6ecf5f":"### Finally,"}}