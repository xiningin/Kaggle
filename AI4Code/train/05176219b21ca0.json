{"cell_type":{"398254d8":"code","15fd8711":"code","f0d52707":"code","33e084fb":"code","e5032f5b":"code","cbc09e3e":"code","758a192c":"code","b08ee6e3":"code","35bd8128":"code","939d6531":"code","db925e81":"code","953a8b3d":"markdown","3935fadf":"markdown","79230184":"markdown","3942b520":"markdown","557782b5":"markdown","9386d0d2":"markdown","3bf5ea62":"markdown","01f8bb95":"markdown","1cefbc92":"markdown","a85407e7":"markdown","2f269784":"markdown","6a495a26":"markdown"},"source":{"398254d8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","15fd8711":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n\n","f0d52707":"num_classes = 2\nresnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmy_new_model = Sequential()\nmy_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmy_new_model.add(Dense(num_classes, activation='softmax'))\n\n# Say not to train first layer (ResNet) model. It is already trained\nmy_new_model.layers[0].trainable = False","33e084fb":"my_new_model.compile(optimizer='sgd', loss='categorical_crossentropy', metrics=['accuracy'])","e5032f5b":"from tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = 224\ndata_generator = ImageDataGenerator(preprocessing_function=preprocess_input)\n\n\ntrain_generator = data_generator.flow_from_directory(\n        '..\/input\/urban-and-rural-photos\/rural_and_urban_photos\/train',\n        target_size=(image_size, image_size),\n        batch_size=24,\n        class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(\n        '..\/input\/urban-and-rural-photos\/rural_and_urban_photos\/val',\n        target_size=(image_size, image_size),\n        class_mode='categorical')\n\n","cbc09e3e":"my_new_model.fit_generator(\n        train_generator,\n        steps_per_epoch=3,\n        validation_data=validation_generator,\n        validation_steps=1)","758a192c":"from tensorflow.keras.applications import ResNet50\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D\n","b08ee6e3":"num_classes = 2\nresnet_weights_path = '..\/input\/resnet50\/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\nmy_new_model = Sequential()\nmy_new_model.add(ResNet50(include_top=False, pooling='avg', weights=resnet_weights_path))\nmy_new_model.add(Dense(num_classes, activation='softmax'))\n\n# Indicate whether the first layer should be trained\/changed or not.\nmy_new_model.layers[0].trainable = False\n","35bd8128":"my_new_model.compile(optimizer='sgd', \n                     loss='categorical_crossentropy', \n                     metrics=['accuracy'])","939d6531":"from tensorflow.keras.applications.resnet50 import preprocess_input\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimage_size = 224\ndata_generator = ImageDataGenerator(preprocess_input)\n\ntrain_generator = data_generator.flow_from_directory(\n                                        directory= '..\/input\/dogs-gone-sideways\/images\/train',\n                                        target_size=(image_size, image_size),\n                                        batch_size=10,\n                                        class_mode='categorical')\n\nvalidation_generator = data_generator.flow_from_directory(\n                                        directory='..\/input\/dogs-gone-sideways\/images\/val',\n                                        target_size=(image_size, image_size),\n                                        class_mode='categorical')\n\n","db925e81":"# fit_stats below saves some statistics describing how model fitting went\n# the key role of the following line is how it changes my_new_model by fitting to data\nfit_stats = my_new_model.fit_generator(train_generator,\n                                       steps_per_epoch=22,\n                                       validation_data=validation_generator,\n                                       validation_steps=1)\n","953a8b3d":"# Fit Model","3935fadf":"## Imports","79230184":"# Transfer Learning(Using ResNet50) for Urban and Rural Classification\n\nThis small dataset contains images from a Google Image search for both rural and urban topics. The search results were limited to images in the public domain with a 1:1 aspect ratio. This may be useful for experimenting with image processing techniques.\n\nThe dataset is divided into training data (36 images each of urban and rural scenes) and validation (10 images of each). The labels are indicated by the directory name of the image file.\n\n\n![image.png](attachment:image.png)\n\n**Reference**\nhttps:\/\/www.kaggle.com\/dansbecker\/transfer-learning","3942b520":"## Imports","557782b5":"## Specify the Model","9386d0d2":"# Data Generation and Pre-Processing","3bf5ea62":"# Training\/Validation","01f8bb95":"# Specify the Model","1cefbc92":"# Compile the Model","a85407e7":"# Deep Learning Model To Distinguish between Sideways and Upright Images\n\nCameraman offers a service that scans photographs to store them digitally. He uses a machine that quickly scans many photos. But depending on the orientation of the original photo, many images are digitized sideways. He fixes these manually, looking at each photo to determine which ones to rotate.\n\nIn this exercise, you will build a model that distinguishes which photos are sideways and which are upright, so an app could automatically rotate each image if necessary.\n\nIf you were going to sell this service commercially, you might use a large dataset to train the model. But you'll have great success with even a small dataset. You'll work with a small dataset of dog pictures, half of which are rotated sideways.\n\nSpecifying and compiling the model look the same as in the example you've seen. But you'll need to make some changes to fit the model.\n","2f269784":"## Compile the Model","6a495a26":"## Data Generation and Pre-Processing\n\nYour training data is in the directory ..\/input\/dogs-gone-sideways\/images\/train. The validation data is in ..\/input\/dogs-gone-sideways\/images\/val. Use that information when setting up train_generator and validation_generator.\n\nYou have 220 images of training data and 217 of validation data. For the training generator, we set a batch size of 10. Figure out the appropriate value of steps_per_epoch in your fit_generator call."}}