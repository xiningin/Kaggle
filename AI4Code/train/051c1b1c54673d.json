{"cell_type":{"a48e12ed":"code","b12ce081":"code","d8f0be66":"code","40c9824a":"code","b7291989":"code","32a80ead":"code","01241c77":"code","391f2cae":"code","be5b0dfb":"code","14d39621":"code","3c04efe3":"code","cda73ff5":"code","4556a1f1":"code","c101cafc":"code","cd09f52e":"code","8479ce20":"code","28803214":"code","26972276":"code","f7839501":"code","b5cbe698":"code","db54afde":"code","e5ce89b5":"code","c7f73cba":"code","790afa6a":"code","f1e44c37":"markdown","ce75d6c3":"markdown","3d1d0b1e":"markdown","199d8c10":"markdown","a2f8315a":"markdown","58e335b2":"markdown","cdee7971":"markdown","422c516a":"markdown","139bb979":"markdown","05a229fb":"markdown","f95facf4":"markdown","49983aa6":"markdown","a7dc498b":"markdown","67a45e06":"markdown","2a095744":"markdown","48cfb7e5":"markdown","b070d0ee":"markdown","d81b068c":"markdown","12c543de":"markdown","94230f6b":"markdown","f7ce4188":"markdown","d7dc9054":"markdown"},"source":{"a48e12ed":"import os\nimport time\nimport datetime\nimport numpy as np\nimport pandas as pd\n\n# Keras\nimport tensorflow.keras as keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import callbacks\nfrom tensorflow.keras import backend as K\n\n# Standard ML stuff\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler, StandardScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.manifold import TSNE\nfrom sklearn.decomposition import PCA, TruncatedSVD, FastICA\nfrom sklearn.random_projection import GaussianRandomProjection, SparseRandomProjection\n\n# Oversampling of minority class 'Churn customers'\nfrom imblearn.over_sampling import SMOTE\n\n# Plotting\nimport matplotlib.pyplot as plt","b12ce081":"def get_keras_dataset(df):\n    X = {str(col) : np.array(df[col]) for col in df.columns}\n    return X","d8f0be66":"# Plot the results of the training\ndef plot_history(history):\n    fig = plt.figure(figsize=(15,8))\n    ax = plt.subplot(211)\n    \n    plt.xlabel('Epoch')\n    plt.ylabel('loss, acc')\n    \n    # Losses\n    ax.plot(history.epoch, history.history['loss'], label='Train LOSS')\n    ax.plot(history.epoch, history.history['val_loss'], label='Val LOSS')\n    ax.plot(history.epoch, history.history['acc'], label ='Train Accuracy')\n    ax.plot(history.epoch, history.history['val_acc'], label='Val Accuracy')\n    plt.legend()\n    \n    # Plot the learning_rate\n    if 'lr' in history.history:\n        ax = plt.subplot(212)\n        plt.ylabel('Learning rate')\n        ax.plot(history.epoch, history.history['lr'], label='learning_rate')\n        plt.legend()\n    plt.show()\n    plt.close(fig)","40c9824a":"# Load the dataset\ntelcom = pd.read_csv(\"..\/input\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ntelcom.head()","b7291989":"telcom['TotalCharges'] = telcom[\"TotalCharges\"].replace(\" \",np.nan)\nprint(\"Missing values in TotalCharges: \", telcom[\"TotalCharges\"].isnull().sum())\n\ntelcom = telcom[telcom[\"TotalCharges\"].notnull()]\ntelcom = telcom.reset_index()[telcom.columns]\nprint(\"Missing values in TotalCharges: \", telcom[\"TotalCharges\"].isnull().sum())\n\ntelcom[\"TotalCharges\"] = telcom[\"TotalCharges\"].astype(float)\nprint(\"dType TotalCharges: \", telcom['TotalCharges'].dtype)","32a80ead":"telcom[\"SeniorCitizen\"] = telcom[\"SeniorCitizen\"].replace({1:\"Yes\", 0:\"No\"})","01241c77":"def tenure_lab(telcom) :\n    if telcom[\"tenure\"] <= 12 :\n        return \"Tenure_0-12\"\n    elif (telcom[\"tenure\"] > 12) & (telcom[\"tenure\"] <= 24 ):\n        return \"Tenure_12-24\"\n    elif (telcom[\"tenure\"] > 24) & (telcom[\"tenure\"] <= 48) :\n        return \"Tenure_24-48\"\n    elif (telcom[\"tenure\"] > 48) & (telcom[\"tenure\"] <= 60) :\n        return \"Tenure_48-60\"\n    elif telcom[\"tenure\"] > 60 :\n        return \"Tenure_gt_60\"\n    \ntelcom[\"tenure_group\"] = telcom.apply(lambda telcom:tenure_lab(telcom), axis=1)","391f2cae":"numeric_cols = ['MonthlyCharges', 'TotalCharges', 'tenure']\ntarget_col = ['Churn']\nignored_cols = ['customerID']\ncategorical_cols = telcom.select_dtypes(include='object').columns\ncategorical_cols = [col for col in categorical_cols if col not in target_col + ignored_cols]","be5b0dfb":"for col in categorical_cols:\n    telcom[col] = LabelEncoder().fit_transform(telcom[col])\n\ntelcom['Churn'] = telcom['Churn'].map({'Yes' : 1, 'No' : 0})","14d39621":"telcom[numeric_cols] = StandardScaler().fit_transform(telcom[numeric_cols])","3c04efe3":"pca = PCA(n_components=3)\n_X = pca.fit_transform(telcom[numeric_cols + categorical_cols])\npca_data = pd.DataFrame(_X, columns=[\"PCA1\", \"PCA2\", \"PCA3\"])\ntelcom[[\"PCA1\", \"PCA2\", \"PCA3\"]] = pca_data\n\nfica = FastICA(n_components=3)\n_X = fica.fit_transform(telcom[numeric_cols + categorical_cols])\nfica_data = pd.DataFrame(_X, columns=[\"FICA1\", \"FICA2\", \"FICA3\"])\ntelcom[[\"FICA1\", \"FICA2\", \"FICA3\"]] = fica_data\n\ntsvd = TruncatedSVD(n_components=3)\n_X = tsvd.fit_transform(telcom[numeric_cols + categorical_cols])\ntsvd_data = pd.DataFrame(_X, columns=[\"TSVD1\", \"TSVD2\", \"TSVD3\"])\ntelcom[[\"TSVD1\", \"TSVD2\", \"TSVD3\"]] = tsvd_data\n\ngrp = GaussianRandomProjection(n_components=3)\n_X = grp.fit_transform(telcom[numeric_cols + categorical_cols])\ngrp_data = pd.DataFrame(_X, columns=[\"GRP1\", \"GRP2\", \"GRP3\"])\ntelcom[[\"GRP1\", \"GRP2\", \"GRP3\"]] = grp_data\n\nsrp = SparseRandomProjection(n_components=3)\n_X = srp.fit_transform(telcom[numeric_cols + categorical_cols])\nsrp_data = pd.DataFrame(_X, columns=[\"SRP1\", \"SRP2\", \"SRP3\"])\ntelcom[[\"SRP1\", \"SRP2\", \"SRP3\"]] = srp_data\n\n#tsne = TSNE(n_components=3)\n#_X = tsne.fit_transform(telcom[numeric_cols + categorical_cols])\n#tsne_data = pd.DataFrame(_X, columns=[\"TSNE1\", \"TSNE2\", \"TSNE3\"])\n#telcom[[\"TSNE1\", \"TSNE2\", \"TSNE3\"]] = tsne_data\n\nnumeric_cols.extend(pca_data.columns.values)\nnumeric_cols.extend(fica_data.columns.values)\nnumeric_cols.extend(tsvd_data.columns.values)\nnumeric_cols.extend(grp_data.columns.values)\nnumeric_cols.extend(srp_data.columns.values)\n#numeric_cols.extend(tsne_data.columns.values)","cda73ff5":"train_df, test_df = train_test_split(telcom, test_size=0.15, random_state=42)\nprint(train_df.shape)","4556a1f1":"smote = SMOTE(sampling_strategy='minority', random_state=42)\nos_smote_X, os_smote_Y = smote.fit_sample(train_df[numeric_cols + categorical_cols], train_df[target_col].values.ravel())\n\ntrain_df = pd.DataFrame(os_smote_X, columns=numeric_cols + categorical_cols)\ntrain_df['Churn'] = os_smote_Y\nprint(train_df.shape)","c101cafc":"customer_id = telcom['customerID']\ntelcom = telcom.drop('customerID', axis=1)","cd09f52e":"K.clear_session()","8479ce20":"FEATURE_COLS = numeric_cols + categorical_cols\nTARGET_COL = 'Churn'\nEPOCHS = 50\nBATCH_SIZE = 4\nCLASS_WEIGHTS = {0 : 1., 1 : 2.5}","28803214":"cat_inputs = []\nnum_inputs = []\nembeddings = []\nembedding_layer_names = []\nemb_n = 10","26972276":"# Embedding for categorical features\nfor col in categorical_cols:\n    _input = layers.Input(shape=[1], name=col)\n    _embed = layers.Embedding(telcom[col].max() + 1, emb_n, name=col+'_emb')(_input)\n    cat_inputs.append(_input)\n    embeddings.append(_embed)\n    embedding_layer_names.append(col+'_emb')\n    \n# Simple inputs for the numeric features\nfor col in numeric_cols:\n    numeric_input = layers.Input(shape=(1,), name=col)\n    num_inputs.append(numeric_input)\n    \n# Merge the numeric inputs\nmerged_num_inputs = layers.concatenate(num_inputs)\n#numeric_dense = layers.Dense(20, activation='relu')(merged_num_inputs)\n\n# Merge embedding and use a Droput to prevent overfittting\nmerged_inputs = layers.concatenate(embeddings)\nspatial_dropout = layers.SpatialDropout1D(0.2)(merged_inputs)\nflat_embed = layers.Flatten()(spatial_dropout)\n\n# Merge embedding and numeric features\nall_features = layers.concatenate([flat_embed, merged_num_inputs])\n\n# MLP for classification\nx = layers.Dropout(0.2)(layers.Dense(100, activation='relu')(all_features))\nx = layers.Dropout(0.2)(layers.Dense(50, activation='relu')(x))\nx = layers.Dropout(0.2)(layers.Dense(25, activation='relu')(x))\nx = layers.Dropout(0.2)(layers.Dense(15, activation='relu')(x))\n\n# Final model\noutput = layers.Dense(1, activation='sigmoid')(x)\nmodel = models.Model(inputs=cat_inputs + num_inputs, outputs=output)","f7839501":"model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\nprint(model.summary())","b5cbe698":"# TB Callback\nlog_folder = datetime.datetime.fromtimestamp(time.time()).strftime('%Y-%m-%d-%H-%M-%S')\ntb_callback = callbacks.TensorBoard(\n    log_dir=os.path.join('tb-logs', log_folder),\n)\n\n# Best model callback\nbm_callback = callbacks.ModelCheckpoint(\n    filepath=os.path.join('tb-logs', log_folder, 'bm.h5'),\n    save_best_only=True,\n    save_weights_only=False\n)","db54afde":"_hist = model.fit(\n    x=get_keras_dataset(train_df[FEATURE_COLS]),\n    y=train_df[TARGET_COL],\n    validation_data=(get_keras_dataset(test_df[FEATURE_COLS]), test_df[TARGET_COL]),\n    epochs=EPOCHS,\n    batch_size=BATCH_SIZE,\n    class_weight=CLASS_WEIGHTS,\n    callbacks=[tb_callback, bm_callback],\n    verbose=2\n)","e5ce89b5":"plot_history(_hist)","c7f73cba":"model = keras.models.load_model(os.path.join('tb-logs', log_folder, 'bm.h5'), compile=False)","790afa6a":"pred = np.around(model.predict(get_keras_dataset(test_df[FEATURE_COLS])))\n\nprint(accuracy_score(test_df[TARGET_COL], pred))\nprint(classification_report(test_df[TARGET_COL], pred))","f1e44c37":"### Define global parameters","ce75d6c3":"## Transform the numeric features","3d1d0b1e":"### Placeholders for the model input and embedding layers","199d8c10":"### Keras model architecture","a2f8315a":"## Replace space characters with nan","58e335b2":"# Data preparation","cdee7971":"### Training","422c516a":"## Extract different feature groups","139bb979":"# Load the dataset","05a229fb":"## Add low dim representations as additional features","f95facf4":"### Definition model callbacks","49983aa6":"### Evaluation","a7dc498b":"## Delete the CustomerID","67a45e06":"## Helper functions","2a095744":"## Encode the categorical features + target variable","48cfb7e5":"def dice_coef(y_true, y_pred, smooth=1):\n    intersection = K.sum(K.abs(y_true * y_pred), axis=-1)\n    return (2. * intersection + smooth) \/ (K.sum(K.square(y_true),-1) + K.sum(K.square(y_pred),-1) + smooth)\n\ndef dice_coef_loss(y_true, y_pred):\n    return 1-dice_coef(y_true, y_pred)","b070d0ee":"# Begin the modelling process","d81b068c":"## SMOTE oversampling of minority class","12c543de":"## Group customers by tenure","94230f6b":"### Compile model with all parameters","f7ce4188":"## Split dataset in a traning and evaluation part","d7dc9054":"## Create categories for integer values "}}