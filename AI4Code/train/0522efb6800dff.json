{"cell_type":{"21130a45":"code","38f64cb4":"code","7a74b931":"code","9156cf62":"code","29919266":"code","53a03280":"code","8989afba":"code","c4f1f8f0":"code","f9b6d3a1":"code","eb3a99fe":"code","d34b22c6":"code","5ad18157":"code","2a1f2f45":"code","d80fbb27":"code","3c29ba6c":"code","0bf199b8":"code","a827aded":"code","5ba9dbae":"code","691e14f4":"code","bd6178e7":"code","eddccf64":"code","60af40b8":"code","63076f06":"code","dd1048b3":"markdown","57772a5f":"markdown","9037c869":"markdown","f1560f3f":"markdown"},"source":{"21130a45":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","38f64cb4":"\nimport pandas as pd\npd.set_option('display.max_columns', None)\n# pd.set_option('display.max_rows', None)\npd.set_option('display.width', 500)\npd.set_option('display.expand_frame_repr', False)\nfrom mlxtend.frequent_patterns import apriori, association_rules","7a74b931":"df_ = pd.read_excel(\"..\/input\/retail-iidataset\/online_retail_II.xlsx\", sheet_name=\"Year 2010-2011\")","9156cf62":"df = df_.copy()\ndf.info()\ndf.head()","29919266":"def outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\ndef retail_data_prep(dataframe):\n    dataframe.dropna(inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe = dataframe[dataframe[\"Price\"] > 0]\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    return dataframe\n\ndf = retail_data_prep(df)","53a03280":"df_gr = df[df['Country'] == \"Germany\"]","8989afba":"df_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).head(20)","c4f1f8f0":"df_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().iloc[0:5, 0:5]","f9b6d3a1":"df_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().fillna(0).iloc[0:5, 0:5]","eb3a99fe":"df_gr.groupby(['Invoice', 'Description']).agg({\"Quantity\": \"sum\"}).unstack().fillna(0).applymap(\n    lambda x: 1 if x > 0 else 0).iloc[0:5, 0:5]\n\ndef create_invoice_product_df(dataframe, id=False):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n\ngr_inv_pro_df = create_invoice_product_df(df_gr)\ngr_inv_pro_df.head()","d34b22c6":"gr_inv_pro_df = create_invoice_product_df(df_gr, id=True)\ngr_inv_pro_df.head()","5ad18157":"def check_id(dataframe, stock_code):\n    product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n    print(product_name)\n\ncheck_id(df_gr, 10125)","2a1f2f45":"frequent_itemsets = apriori(gr_inv_pro_df, min_support=0.01, use_colnames=True)\nfrequent_itemsets.sort_values(\"support\", ascending=False).head(50)","d80fbb27":"rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\nrules.sort_values(\"support\", ascending=False).head()\n","3c29ba6c":"rules.sort_values(\"lift\", ascending=False).head(500)","0bf199b8":"def check_id(dataframe, stock_code):\n    product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n    print(product_name)\n    \ncheck_id(df_gr, 21987) ","a827aded":"import pandas as pd\n\npd.set_option('display.max_columns', None)\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\ndef create_invoice_product_df(dataframe, id=False):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    \ndef check_id(dataframe, stock_code):\n    product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n    print(product_name)\n\ndef create_rules(dataframe, id=True, country=\"Germany\"):\n    dataframe = dataframe[dataframe['Country'] == country]\n    dataframe = create_invoice_product_df(dataframe, id)\n    frequent_itemsets = apriori(dataframe, min_support=0.01, use_colnames=True)\n    rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\n    return rules\n\n\ndf_ = pd.read_excel(\"..\/input\/retail-iidataset\/online_retail_II.xlsx\", sheet_name=\"Year 2010-2011\")\ndf = df_.copy()","5ba9dbae":"df = retail_data_prep(df)\nrules = create_rules(df)\n\nrules_grm = create_rules(df, country=\"Germany\")\nrules_grm.sort_values(\"lift\", ascending=False).head(50)","691e14f4":"product_id = 22746\ncheck_id(df, product_id)","bd6178e7":"sorted_rules = rules.sort_values(\"lift\", ascending=False)","eddccf64":"recommendation_list = []\n\nfor i, product in enumerate(sorted_rules[\"antecedents\"]):\n    for j in list(product):\n        if j == product_id:\n            recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"])[0])\n\nrecommendation_list[0:2]\n\ncheck_id(df, recommendation_list[0])","60af40b8":"def arl_recommender(rules_df, product_id, df, rec_count=1):\n\n    sorted_rules = rules_df.sort_values(\"lift\", ascending=False)\n\n    recommendation_list = []\n\n    for i, product in sorted_rules[\"antecedents\"].items():\n        for j in list(product):\n            if j == product_id:\n                recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"]))\n\n    recommendation_list = list({item for item_list in recommendation_list for item in item_list})\n\n    ids = recommendation_list[:rec_count]\n    for id in ids:\n        print(df[df[\"StockCode\"] == id][[\"Description\"]].values[0].tolist())\n\n\narl_recommender(rules, 22746, df, 2)\n","63076f06":"product_id = 22423\ncheck_id(df, product_id)","dd1048b3":"**Check ID**","57772a5f":"**To make a suggestion to the user**","9037c869":"**SCR\u0130PT**","f1560f3f":"**5 products, 5 observations**"}}