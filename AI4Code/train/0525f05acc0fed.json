{"cell_type":{"91fffabc":"code","3c34b783":"code","6449dd27":"code","d23370bb":"code","2b59387e":"code","c12ed534":"code","e6b32c03":"code","942c1cbb":"code","d7d90937":"code","20efe43d":"code","327ae841":"code","36e59c8d":"code","f6a3f276":"code","eb9fb656":"code","87180fcc":"code","8d244e83":"code","ac655960":"code","e02c7da6":"code","3d72f000":"code","930b6779":"code","7b15b3c7":"code","14f4c328":"code","1cd3adf8":"code","c2531f6f":"code","f4c301ae":"code","0cff1a01":"code","55078fc4":"code","2fa0b302":"code","02959310":"code","fbdb08d7":"code","9e178ceb":"code","8d5ab021":"code","ed812bf8":"code","3684e41c":"code","ee5bc0b0":"code","efedb7e8":"code","7d8633f3":"code","78c7c01d":"code","106f7524":"code","392e1ff3":"code","e4ff1b57":"code","fdd43a66":"code","86a6012b":"code","74b6c4bf":"code","c43705f6":"markdown","adff4b66":"markdown","67b2bdd5":"markdown","5aeed243":"markdown","c305f93d":"markdown","67fba91a":"markdown","6efe534f":"markdown","26fd0a95":"markdown","dfbe57af":"markdown"},"source":{"91fffabc":"import pandas as pd\nimport glob\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\nimport tensorflow as tf\nimport tensorflow.keras as keras\nfrom tensorflow.keras.utils import Sequence\nfrom random import shuffle\nfrom sklearn.model_selection import train_test_split\nfrom tensorflow.keras.applications import EfficientNetB0\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport math\nimport numpy as np\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.svm import SVC","3c34b783":"#!pip install opendatasets\n#import opendatasets as od\n#od.download('https:\/\/www.kaggle.com\/kmader\/satellite-images-of-hurricane-damage')","6449dd27":"def get_files(directory):\n    df = pd.DataFrame(columns=['file','target'])\n    damage = glob.glob(directory+'\/damage\/*.jpeg')\n    no_damage = glob.glob(directory+'\/no_damage\/*jpeg')\n    for f in damage:\n        df = df.append({'file':f,'target':'1'},ignore_index=True)\n    for f in no_damage:\n        df = df.append({'file':f,'target':'0'},ignore_index=True)\n    return df\n\ndef get_image(file_path):\n    return mpimg.imread(file_path)\/255","d23370bb":"df_train = pd.concat([get_files('.\/satellite-images-of-hurricane-damage\/train_another'),\n                      get_files('.\/satellite-images-of-hurricane-damage\/test_another'),\n                      get_files('.\/satellite-images-of-hurricane-damage\/validation_another')],axis=0)\ndf_test = get_files('.\/satellite-images-of-hurricane-damage\/test')","2b59387e":"df_train.reset_index(inplace=True,drop=True)","c12ed534":"df_train.head()","e6b32c03":"df_train.shape","942c1cbb":"ax = sns.histplot(x='target', data=df_train, bins=2)\n#ax.set_xticks([0.25,0.75])\n#ax.set_xticklabels([0,1])\nplt.show()","d7d90937":"img = get_image(df_train[df_train['target']=='1']['file'].iloc[0])\nimg.shape","20efe43d":"fig = plt.figure(figsize=(5,5))\nplt.imshow(img)","327ae841":"fig = plt.figure(figsize=(5,5))\nplt.imshow(get_image(df_train[df_train['target']=='0']['file'].iloc[0]))","36e59c8d":"train_gen = ImageDataGenerator(validation_split=0.1)\ntest_gen = ImageDataGenerator()\n\ntrain_data = train_gen.flow_from_dataframe(\n    dataframe = df_train,\n    x_col = 'file',\n    y_col = 'target',\n    target_size = (256,256),\n    color_mode = 'rgb',\n    class_mode = 'binary',\n    shuffle = True,\n    subset = 'training',\n    batch_size=100\n)\n\nval_data = train_gen.flow_from_dataframe(\n    dataframe = df_train,\n    x_col = 'file',\n    y_col = 'target',\n    target_size = (256,256),\n    color_mode = 'rgb',\n    class_mode = 'binary',\n    shuffle = False,\n    subset = 'validation',\n    batch_size=100\n)\n\ntest_data = test_gen.flow_from_dataframe(\n    dataframe = df_test,\n    x_col = 'file',\n    y_col = 'target',\n    target_size = (256,256),\n    color_mode = 'rgb',\n    class_mode = 'binary',\n    shuffle = False,\n    batch_size=100\n)","f6a3f276":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(4,4), activation='relu', input_shape=(256,256,3)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=256, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Flatten(),\n    keras.layers.Dense(4096, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(4096, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(\n    optimizer=tf.optimizers.Adam(lr=0.000001),\n    loss='binary_crossentropy',\n    metrics=['accuracy','Recall']\n)\n\nmodel.summary()","eb9fb656":"history = model.fit(train_data,epochs=15,validation_data=val_data)","87180fcc":"#plotting the Accuracy of test and training sets\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","8d244e83":"#plotting the loss of test and training sets\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","ac655960":"y_pred = model.predict(test_data)\ny_pred = np.where(y_pred > 0.5,1,0)","e02c7da6":"print(classification_report(test_data.labels,y_pred))","3d72f000":"con_mat_df = pd.DataFrame(confusion_matrix(test_data.labels,y_pred))","930b6779":"figure = plt.figure(figsize=(12, 6))\nsns.heatmap(con_mat_df, annot=True,fmt='d')\nplt.tight_layout()\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","7b15b3c7":"model = tf.keras.Sequential([\n        keras.layers.InputLayer(input_shape=(256,256,3)),\n        keras.layers.Conv2D(3,3,activation='relu',padding='same'),\n        EfficientNetB0(include_top=False,input_shape=(),weights='imagenet'),\n        keras.layers.GlobalAveragePooling2D(),\n        keras.layers.Dense(32,activation='relu'),\n        keras.layers.Dense(1, activation='sigmoid')])\n\nmodel.compile(\n    optimizer=tf.optimizers.Adam(lr=0.000001),\n    loss='binary_crossentropy',\n    metrics=['accuracy','Recall'])\nmodel.summary()","14f4c328":"history = model.fit(train_data,epochs=15,validation_data=val_data)","1cd3adf8":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","c2531f6f":"#plotting the loss of test and training sets\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","f4c301ae":"y_pred = model.predict(test_data)\ny_pred = np.where(y_pred > 0.5,1,0)","0cff1a01":"print(classification_report(test_data.labels,y_pred))","55078fc4":"con_mat_df = pd.DataFrame(confusion_matrix(test_data.labels,y_pred))","2fa0b302":"figure = plt.figure(figsize=(12, 6))\nsns.heatmap(con_mat_df, annot=True,fmt='d')\nplt.tight_layout()\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","02959310":"train_idx =  df_train['file'].values\ny = df_train['target'].values\ntest_idx =  df_test['file'].values\ny_test = df_test['target'].values\nx_train,x_valid,y_train,y_valid = train_test_split(train_idx,y,test_size=0.2,random_state=42,stratify=y)","fbdb08d7":"x_train_img = np.zeros((len(x_train),128*128*3))\nfor i,f in enumerate(x_train):\n    x_train_img[i,:] = get_image(f).reshape(-1)\n\nx_train_img.shape    ","9e178ceb":"x_valid_img = np.zeros((len(x_valid),128*128*3))\nfor i,f in enumerate(x_valid):\n    x_valid_img[i,:] = get_image(f).reshape(-1)    \n\nx_valid_img.shape      ","8d5ab021":"x_test_img = np.zeros((len(test_idx),128*128*3))\nfor i,f in enumerate(test_idx):\n    x_test_img[i,:] = get_image(f).reshape(-1)   \n    \nx_test_img.shape    ","ed812bf8":"model = SVC()\nmodel.fit(x_train_img,y_train)","3684e41c":"y_pred = model.predict(x_test_img)\nprint(classification_report(y_test,y_pred))","ee5bc0b0":"con_mat_df = pd.DataFrame(confusion_matrix(y_test,y_pred))","efedb7e8":"figure = plt.figure(figsize=(12, 6))\nsns.heatmap(con_mat_df, annot=True,fmt='d')\nplt.tight_layout()\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","7d8633f3":"model = keras.models.Sequential([\n    keras.layers.Conv2D(filters=96, kernel_size=(11,11), strides=(1,1), activation='relu', input_shape=(256,256,3)),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=256, kernel_size=(5,5), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(2,2)),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=384, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2D(filters=3, kernel_size=(3,3), strides=(1,1), activation='relu', padding=\"same\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.MaxPool2D(pool_size=(3,3), strides=(1,1)),\n    EfficientNetB0(include_top=False,weights='imagenet'),\n    keras.layers.Flatten(),\n    keras.layers.Dense(4096, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(4096, activation='relu'),\n    keras.layers.Dropout(0.5),\n    keras.layers.Dense(1, activation='sigmoid')\n])\nmodel.compile(\n    optimizer=tf.optimizers.Adam(lr=0.000001),\n    loss='binary_crossentropy',\n    metrics=['accuracy','Recall']\n)\n\nmodel.summary()","78c7c01d":"history = model.fit(train_data,epochs=15,validation_data=val_data)","106f7524":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('Model Accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","392e1ff3":"#plotting the loss of test and training sets\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('Model Loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","e4ff1b57":"y_pred = model.predict(test_data)\ny_pred = np.where(y_pred > 0.5,1,0)","fdd43a66":"print(classification_report(test_data.labels,y_pred))","86a6012b":"con_mat_df = pd.DataFrame(confusion_matrix(test_data.labels,y_pred))","74b6c4bf":"figure = plt.figure(figsize=(12, 6))\nsns.heatmap(con_mat_df, annot=True,fmt='d')\nplt.tight_layout()\nplt.ylabel('Actual')\nplt.xlabel('Predicted')\nplt.show()","c43705f6":"**Evaluate model**","adff4b66":"**Get dataset**","67b2bdd5":"**Try out SVM model**","5aeed243":"**Fit model**","c305f93d":"**Define the data structure for the model**","67fba91a":"**Try transfer learning with imagenet**","6efe534f":"**Build database with filenames and labels**","26fd0a95":"**Create model**","dfbe57af":"**Visualize some data**"}}