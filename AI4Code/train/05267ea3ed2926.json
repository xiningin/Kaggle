{"cell_type":{"39b62c4e":"code","9ae548cd":"code","5129028a":"code","2960df61":"code","9277c6b6":"code","5662fdb9":"code","d3021685":"code","59bc5010":"code","8a714a3c":"code","e4e59e0e":"code","58184c43":"code","04489bc2":"code","fe8948db":"code","8a35fce7":"code","66629cb4":"code","3b0b5176":"code","c4398c65":"code","429cc44c":"code","93faeaaa":"code","2508b67b":"code","0ec0359c":"code","1c5c125e":"code","cce044d0":"code","1def120e":"code","5e3250f9":"code","55b22213":"code","996c9999":"code","20d55bf0":"code","79274cee":"code","584d98aa":"code","f423e68d":"code","104ad184":"code","9eab4462":"code","f0a38eee":"code","3473b3f6":"code","d5085ea6":"code","83df35a0":"code","41a6e21c":"code","fd0a2e61":"code","90148d76":"code","7e72ced5":"code","8fc8b374":"code","27790731":"code","938a6794":"code","5cf20a25":"code","e8b7bfb1":"code","e1076df1":"code","00ce73d2":"code","dcbd434e":"code","a23c7428":"code","e3a95e6d":"code","899b4f16":"code","8d983e75":"code","99b88c52":"code","b0ad1dd8":"code","efb13abf":"code","402415de":"code","481e1858":"code","74d0d46d":"code","b000405b":"code","acb72dcc":"markdown","b4935bc0":"markdown","3cc6bce0":"markdown","c504079b":"markdown","07dc6f2e":"markdown","c59b640a":"markdown","105be5b6":"markdown","fa86fa84":"markdown","deed13db":"markdown","0d309e1d":"markdown","a7d3afba":"markdown","7137f6d9":"markdown","088a01fb":"markdown","920e9c33":"markdown","abf567e4":"markdown","8d683973":"markdown","2c5d1cf1":"markdown","d4048d1b":"markdown","3f6d3736":"markdown","fd95986a":"markdown","6a463de3":"markdown","aabc2090":"markdown","6fe8ee15":"markdown","441705ed":"markdown","64fa1140":"markdown","17d5e3bb":"markdown"},"source":{"39b62c4e":"import pandas as pd\nimport numpy as np\nimport pickle","9ae548cd":"df = pd.read_csv('..\/input\/amazon-fine-food-reviews\/Reviews.csv')","5129028a":"df.head()","2960df61":"df.shape # data shape","9277c6b6":"df.nunique() # check num of unique items per column","5662fdb9":"df.columns","d3021685":"# rename columns HelpfulnessNumerator and HelpfulnessDenominator\ndf.columns = [\"Id\", \"ProductId\", \"UserId\", \"ProfileName\", \"VotesHelpful\",\n              \"VotesTotal\", \"Score\", \"Time\", \"Summary\", \"Text\"]","59bc5010":"df[\"Sentiment\"] = df[\"Score\"].apply(lambda score: \"positive\" if score > 3 else \"negative\")\ndf.head(5)","8a714a3c":"# check some statistics\nprint(df['Sentiment'].value_counts())","e4e59e0e":"df = df[[\"Score\", \"Sentiment\", \"Summary\", \"Text\"]]","58184c43":"df[df.Score == 5].head(10)","04489bc2":"df[df.Score == 1].head(10)","fe8948db":"import nltk\nnltk.download('stopwords')\nfrom nltk.corpus import stopwords\nstop = stopwords.words('english')\nprint(stop)","8a35fce7":"'not' in stop","66629cb4":"from nltk.stem import SnowballStemmer # Stemmers remove morphological affixes from words, leaving only the word stem.\nsnow = SnowballStemmer('english') \nprint(snow.stem('tasty'))\nprint(snow.stem('joined'))\nprint(snow.stem('apples'))","3b0b5176":"import re\n# cleaning punctuations from the sentence\nsentence = \"I'd like to have some coffee today!\"\nsentence = re.sub(r'[\\'|\"|#]', r'', sentence) # remove these punctuation\nsentence = re.sub(r'[?|!|.|,|)|(|\\|\/]',r' ',sentence) # replace these punctuation with space\nsentence","c4398c65":"def cleanup(sentence):\n    sentence = str(sentence)\n    sentence = sentence.lower() # lower case\n    sentence = re.sub(r'[?|!|.|,|)|(|\\|\/]',r' ',sentence) # replace these punctuation with space\n    tokens = sentence.split()\n    out = []\n    for t in tokens:\n        out.append(snow.stem(t))\n    out = \" \".join(out)\n    out = re.sub(r'[\\'|\"|#]', r'', out) # remove these punctuation\n    return out    ","429cc44c":"print(cleanup(\"how are you today?\"))\nprint(cleanup(\"Not as Advertised\"))\nprint(cleanup(6))","93faeaaa":"df[\"Summary_Clean\"] = df[\"Summary\"].apply(cleanup)","2508b67b":"%matplotlib inline\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\nfrom wordcloud import WordCloud, STOPWORDS\n\n#mpl.rcParams['figure.figsize']=(8.0,6.0)    #(6.0,4.0)\nmpl.rcParams['font.size']=12                #10 \nmpl.rcParams['savefig.dpi']=100             #72 \nmpl.rcParams['figure.subplot.bottom']=.1 \n\ndef show_wordcloud(data, title = None):\n    wordcloud = WordCloud(\n        background_color='white',\n        stopwords=None,\n        max_words=200,\n        max_font_size=40, \n        scale=3,\n        random_state=1 # chosen at random by flipping a coin; it was heads\n    ).generate(str(data))\n    \n    fig = plt.figure(1, figsize=(8, 8))\n    plt.axis('off')\n    if title: \n        fig.suptitle(title, fontsize=20)\n        fig.subplots_adjust(top=2.3)\n\n    plt.imshow(wordcloud)\n    plt.show()","0ec0359c":"show_wordcloud(df.Summary_Clean.loc[df.Score == 5], title = \"High scoring\")","1c5c125e":"show_wordcloud(df.Summary_Clean.loc[df.Score == 1], title = \"Low scoring\")","cce044d0":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size=0.2, random_state = 1)\nprint(\"%d items in training data, %d in test data\" % (len(train), len(test)))","1def120e":"train = train.reset_index(drop=True)\ntrain.head()","5e3250f9":"test = test.reset_index(drop=True)\ntest.head()","55b22213":"from sklearn.feature_extraction.text import CountVectorizer","996c9999":"train['Summary_Clean'].values","20d55bf0":"uni_gram = CountVectorizer(min_df = 5, binary = True) # only use keyword which shows up more than 5 times. \nuni_gram_vectors_train = uni_gram.fit_transform(train['Summary_Clean'].values)\nuni_gram_vectors_test = uni_gram.transform(test['Summary_Clean'].values)","79274cee":"uni_gram_vectors_train.shape","584d98aa":"uni_gram_vectors_train[0]","f423e68d":"type(uni_gram_vectors_train)","104ad184":"bi_gram = CountVectorizer(ngram_range=(1,2), min_df = 5, binary = True) # 1 means the minimum is unigram, 2 means max is bigrams, \nbi_gram_vectors_train = bi_gram.fit_transform(train['Summary_Clean'].values)\nbi_gram_vectors_test = bi_gram.transform(test['Summary_Clean'].values)\n","9eab4462":"bi_gram_vectors_train.shape","f0a38eee":"features = bi_gram.get_feature_names()\nfeatures[-20:]","3473b3f6":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfidf = TfidfVectorizer(ngram_range=(1,2), min_df = 5)\ntfidf_vectors_train = tfidf.fit_transform(train['Summary_Clean'].values)\ntfidf_vectors_test = tfidf.transform(test['Summary_Clean'].values)","d5085ea6":"tfidf_vectors_train.shape","83df35a0":"features = tfidf.get_feature_names()\nfeatures[0:10]","41a6e21c":"prediction = dict()\nprob = dict()","fd0a2e61":"from sklearn.linear_model import LogisticRegression","90148d76":"logreg_bi_gram = LogisticRegression(C = 1e5, class_weight = 'balanced', max_iter = 8000)\nlogreg_bi_gram_result = logreg_bi_gram.fit(bi_gram_vectors_train, train['Sentiment'])\n# logreg_bi_gram = pickle.load(open('amazon.lr.pickle', 'rb'))","7e72ced5":"prediction['logistic_bi_gram'] = logreg_bi_gram.predict(bi_gram_vectors_test)","8fc8b374":"prediction['logistic_bi_gram']","27790731":"import collections\nprint('test data')\nprint(test['Sentiment'].value_counts())\nprint('--------------')\nprint('predicted data')\nprint(collections.Counter(prediction['logistic_bi_gram']))","938a6794":"prob['logistic_bi_gram'] = logreg_bi_gram.predict_proba(bi_gram_vectors_test)","5cf20a25":"prob['logistic_bi_gram'][:,1]","e8b7bfb1":"from sklearn import metrics\nfrom sklearn.metrics import roc_curve, auc","e1076df1":"cmp = 0\ncolors = ['b', 'g', 'y', 'm', 'k']\nfor model, predicted in prediction.items():\n    false_positive_rate, true_positive_rate, thresholds = \\\n            roc_curve(test['Sentiment'].values, prob['logistic_bi_gram'][:,1], pos_label = 'positive')\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.plot(false_positive_rate, true_positive_rate, colors[cmp], label='%s: AUC %0.2f'% (model,roc_auc))\n    cmp += 1\n\nplt.title('Classifiers comparaison with ROC')\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","00ce73d2":"print(metrics.classification_report(test['Sentiment'].values, \n                                    prediction['logistic_bi_gram'], \n                                    target_names = [\"negative\", \"positive\"]))","dcbd434e":"feature = bi_gram.get_feature_names()\nfeature_coefs = pd.DataFrame(\n    data = list(zip(feature, logreg_bi_gram.coef_[0])),\n    columns = ['feature', 'coef'])\n\nfeature_coefs.sort_values(by='coef')","a23c7428":"from sklearn.ensemble import RandomForestClassifier","e3a95e6d":"rf_bi_gram = RandomForestClassifier(n_estimators = 100, class_weight = 'balanced', n_jobs = -1)\nrf_bi_gram_result = rf_bi_gram.fit(bi_gram_vectors_train, train['Sentiment'])\n#rf_bi_gram = pickle.load(open('amazon.rf.pickle', 'rb'))","899b4f16":"prediction['rf_bi_gram'] = rf_bi_gram.predict(bi_gram_vectors_test)","8d983e75":"print('test data')\nprint(test['Sentiment'].value_counts())\nprint('--------------')\nprint('predicted data')\nprint(collections.Counter(prediction['rf_bi_gram']))","99b88c52":"prob['rf_bi_gram'] = rf_bi_gram.predict_proba(bi_gram_vectors_test)\nprob['rf_bi_gram'][0:10,1]","b0ad1dd8":"test['Sentiment'][0:10]","efb13abf":"cmp = 0\ncolors = ['b', 'g', 'y', 'm', 'k']\nfor model, predicted in prediction.items():\n    false_positive_rate, true_positive_rate, thresholds = \\\n            roc_curve(test['Sentiment'].values, prob[model][:,1], pos_label = 'positive')\n    roc_auc = auc(false_positive_rate, true_positive_rate)\n    plt.plot(false_positive_rate, true_positive_rate, colors[cmp], label='%s: AUC %0.2f'% (model,roc_auc))\n    cmp += 1\n\nplt.title('Classifiers comparaison with ROC')\nplt.legend(loc='lower right')\nplt.plot([0,1],[0,1],'r--')\nplt.xlim([-0.1,1.2])\nplt.ylim([-0.1,1.2])\nplt.ylabel('True Positive Rate')\nplt.xlabel('False Positive Rate')\nplt.show()","402415de":"print(metrics.classification_report(test['Sentiment'].values, \n                                    prediction['logistic_bi_gram'], \n                                    target_names = [\"negative\", \"positive\"]))","481e1858":"print(metrics.classification_report(test['Sentiment'].values, \n                                    prediction['rf_bi_gram'], \n                                    target_names = [\"negative\", \"positive\"]))","74d0d46d":"feature = bi_gram.get_feature_names()\nrf_feature_importance = pd.DataFrame(data = list(zip(feature, rf_bi_gram.feature_importances_)),\n    columns = ['feature', 'importance'])\nrf_feature_importance.sort_values(by='importance', ascending=False)","b000405b":"pickle.dump(logreg_bi_gram, open(' amazon.lr.pickle', 'wb'))\npickle.dump(rf_bi_gram, open('amazon.rf.pickle', 'wb'))    \n\n# logreg_bi_gram = pickle.load(open('amazon.lr.pickle', 'rb'))\n# rf_bi_gram = pickle.load(open('amazon.rf.pickle', 'rb'))\n","acb72dcc":"### Let's get fancy with WordClouds!","b4935bc0":"And some 1s as well:","3cc6bce0":"### stemming","c504079b":"### Let's also have a look at what the best & words are by looking at the importance score:","07dc6f2e":"### Stopwords\n* A stop word is a commonly used word (such as \u201cthe\u201d, \u201ca\u201d, \u201can\u201d, \u201cin\u201d) that a search engine has been programmed to ignore, both when indexing entries for searching and when retrieving them as the result of a search query.\n\n![alt text](https:\/\/www.geeksforgeeks.org\/wp-content\/uploads\/Stop-word-removal-using-NLTK.png)","c59b640a":"### train test split","105be5b6":"## *3) tf-idf*\n\n* TF*IDF is an information retrieval technique that weighs a term's frequency (TF) and its inverse document frequency (IDF). Each word or term has its respective TF and IDF score. The product of the TF and IDF scores of a term is called the TF*IDF weight of that term\n\n![alt text](https:\/\/1.bp.blogspot.com\/-tnzPA6dDtTU\/Vw6EWm_PjCI\/AAAAAAABDwI\/JatHtUJb4fsce9E-Ns5t02_nakFtGrsugCLcB\/s1600\/%25E8%259E%25A2%25E5%25B9%2595%25E5%25BF%25AB%25E7%2585%25A7%2B2016-04-14%2B%25E4%25B8%258A%25E5%258D%25881.39.07.png)","fa86fa84":"## Cleaning the data\n\nTo format our data and build the Term-doc incidence matrix, many operations will be performed on the data :\n\n- Stop words removal\n- Stemming\n- Punctuations\n- Lowering","deed13db":"## *2) Bi-gram BOW*","0d309e1d":"Select subcolumns","a7d3afba":"## Applying RandomForest method","7137f6d9":"Let's have a look at some 5s:","088a01fb":"Let's add the **Sentiment** column that turns the numeric score into either *positive* or *negative*.\n\nSimilarly, the **Usefulness** column turns the number of votes into a boolean.","920e9c33":"### Punctuations Removal","abf567e4":"# Ways to convert text to vector\n## *1) Uni-gram BOW*","8d683973":"## Applying Logistic regression learning method","2c5d1cf1":"### combine","d4048d1b":"# recall precision are low for negative class. More improvement can be made. ","3f6d3736":"### Let's also have a look at what the best & words are by looking at the coefficients:","fd95986a":"# note that in this example, we do not use stopwords removal. \n# b\/c stopwords like 'not', \"hadn't\" for example, have strong negative signal. ","6a463de3":"## next step\n- try tfidf\n- try using Logistic regression + L1 regularization\n- try other machine learning methods. ","aabc2090":"## So we will not use stopwords removal for our modeling. ","6fe8ee15":"# Making predictions over amazon recommendation dataset\n\n## Predictions\nThe purpose of this analysis is to make up a prediction model where we will be able to predict whether a recommendation is positive or negative. In this analysis, we will not focus on the Score, but only the positive\/negative sentiment of the recommendation. \n\nTo do so, we will work on Amazon's recommendation dataset, we will build a Term-doc incidence matrix using term frequency and inverse document frequency ponderation. When the data is ready, we will load it into predicitve algorithms. In the end, we hope to find a \"best\" model for predicting the recommendation's sentiment.\n\n## Loading the data\nAs we only want to get the global sentiment of the recommendations (positive or negative), we will purposefully ignore all Scores equal to 3. If the score id above 3, then the recommendation wil be set to \"postive\". Otherwise, it will be set to \"negative\". \n\nThe data will be split into an training set and a test set with a test set ratio of 0.2","441705ed":"Let's remember what Precision and Recall are (more here https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall)","64fa1140":"![Precision_Recall](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/2\/26\/Precisionrecall.svg\/525px-Precisionrecall.svg.png)","17d5e3bb":"## Results\n\nIn order to compare our learning algorithms, let's build the ROC curve. The curve with the highest AUC value will show our \"best\" algorithm."}}