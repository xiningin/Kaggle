{"cell_type":{"15f3653d":"code","dfc5731a":"code","063c3736":"code","b2f7ba54":"code","96ea7a45":"code","ac199d23":"code","89ad14a1":"code","b5632468":"code","0171ae31":"code","b596d629":"code","b50a3b1b":"code","6061729a":"code","fdbe2b7f":"code","2e3aeae5":"code","5d5bd16a":"code","8559a485":"code","5d2b9655":"code","6e9de69d":"code","fadf2e8d":"code","f8d134fb":"code","398161b2":"code","3b9f36cb":"code","16e70d11":"code","83a805ca":"code","bf0c5724":"code","751bc12f":"code","7e7fd2c1":"code","11537a91":"markdown","31ce5ae9":"markdown","bd614c2b":"markdown","35e99892":"markdown","d7b80972":"markdown","f66b0f49":"markdown","48e855eb":"markdown","76d1cd5d":"markdown","cc8d8033":"markdown","850fb44a":"markdown","6c51712b":"markdown","6c9a3989":"markdown","603d5750":"markdown","6998b750":"markdown","87123271":"markdown","e6e372ec":"markdown"},"source":{"15f3653d":"%matplotlib inline\nimport os\nimport pandas as pd, numpy as np\nimport matplotlib.pyplot as plt\nfrom skimage.io import imread\nimport seaborn as sns # nice visuals\nfrom sklearn.model_selection import train_test_split # splitting data\n# quantifying models\nfrom sklearn.metrics import accuracy_score, classification_report, roc_curve, roc_auc_score, confusion_matrix\ndata_dir = '..\/input\/'","dfc5731a":"def categories_to_indicators(in_df):\n    new_df = in_df.copy()\n    new_df['IsMale'] = in_df['PatientSex'].map(lambda x: 'M' in x).astype(float)\n    new_df['IsAP'] = in_df['ViewPosition'].map(lambda x: 'AP' in x).astype(float)\n    return new_df.drop(['PatientSex', 'ViewPosition'], axis=1)\nfull_train_df = categories_to_indicators(pd.read_csv(os.path.join(data_dir, 'train_all.csv')))\nfull_stack = imread(os.path.join(data_dir, 'train.tif')) # read all slices\nfull_train_df['image'] = full_train_df['slice_idx'].map(lambda x: full_stack[x]) # get the slice\nfull_train_df.sample(3)","063c3736":"sns.pairplot(full_train_df, hue='opacity')","b2f7ba54":"submission_test_df = categories_to_indicators(pd.read_csv(os.path.join(data_dir, 'test_info.csv')))\ntest_stack = imread(os.path.join(data_dir, 'test.tif')) # read all slices\nsubmission_test_df['image'] = submission_test_df['slice_idx'].map(lambda x: full_stack[x]) # get the slice\nsubmission_test_df.sample(3)","96ea7a45":"from sklearn.preprocessing import RobustScaler\ndef fit_and_score(in_model, feature_maker, rescale=True):\n    \"\"\"\n    Take a given model, set of features, and labels\n    Break the dataset into training and validation\n    Fit the model\n    Show how well the model worked\n    Input\n        in_model: The model to fit (in scikit-learn model format)\n        feature_maker: the function to run on the training data to turn it into a feature vector\n        rescale: whether or not to rescale all features first\n    \"\"\"\n    # compute features on the training data\n    full_features = feature_maker(full_train_df)\n    full_labels = full_train_df['opacity']\n    # compute features on the test data\n    submission_feat = feature_maker(submission_test_df)\n    # split the training data into a training portion and a validation portion\n    # so we can see how well the model works\n    train_feat, valid_feat, train_lab, valid_lab = train_test_split(full_features, \n                                                                    full_labels,\n                                                                    test_size=0.25,\n                                                                    random_state=2018)\n    \n    if rescale:\n        feature_scaler = RobustScaler()\n        train_feat = feature_scaler.fit_transform(train_feat)\n        valid_feat = feature_scaler.transform(valid_feat)\n        submission_feat = feature_scaler.transform(submission_feat)\n    # fit the model\n    in_model.fit(train_feat, train_lab)\n    # predict on the validation feature set\n    predictions = in_model.predict_proba(valid_feat)[:, 1]\n    # convert predictions to a class (opacity = 1, no-opacity = 0)\n    predicted_class = predictions>0.5\n    # make an ROC curve based on the known label for the validations et\n    tpr, fpr, _ = roc_curve(valid_lab, predictions)\n    # compute the AUC score\n    auc = roc_auc_score(valid_lab, predictions)\n    fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\n    ax1.plot(tpr, fpr, 'r.-', label='Prediction (AUC:{:2.2f})'.format(auc))\n    ax1.plot(tpr, tpr, 'k-', label='Random Guessing')\n    ax1.legend()\n    ax1.set_title('ROC Curve')\n    # make a full classification report\n    print(classification_report(valid_lab, predicted_class, target_names=['opacity', 'no opacity']))\n    # create a confusion matrix\n    sns.heatmap(confusion_matrix(valid_lab, predicted_class), \n                annot=True, fmt='4d', ax=ax2)\n    ax2.set_xlabel('Prediction')\n    ax2.set_ylabel('Actual Value')\n    ax2.set_title('Confusion Matrix ({:.1%})'.format(accuracy_score(valid_lab, predicted_class)))\n    \n    # create a submission file as a csv\n    sub_df = submission_test_df[['tile_id']].copy()\n    sub_df['opacity'] = in_model.predict_proba(submission_feat)[:, 1]\n    \n    sub_df[['tile_id', 'opacity']].to_csv(\n        'm-{model}-f-{features}-s-{auc:2.0f}.csv'.format(\n            model=in_model.__class__.__name__, # model name\n            features=feature_maker.__name__, # feature name\n            auc=100*auc, # add the auc score to the name\n        ), index=False)","ac199d23":"# dummy random guesser\nfrom sklearn.dummy import DummyClassifier\ndum_model = DummyClassifier(strategy='stratified', random_state=2018)\ndef justage(in_df):\n    return in_df[['PatientAge']].values\nfit_and_score(\n    dum_model,\n    justage\n)","89ad14a1":"# nearest neighbor\nfrom sklearn.neighbors import KNeighborsClassifier\nknn_model = KNeighborsClassifier(1) # one neighbor\ndef table_features(in_df):\n    return in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].values\nfit_and_score(\n    knn_model,\n    table_features\n)","b5632468":"def basic_image_features(in_df):\n    out_df = in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].copy()\n    out_df['Mean_Intensity'] = in_df['image'].map(np.mean)\n    out_df['Std_Intensity'] = in_df['image'].map(np.std)\n    return out_df.values\nknn_model = KNeighborsClassifier(2) # two neighbor\nfit_and_score(\n    knn_model,\n    basic_image_features\n)","0171ae31":"from sklearn.linear_model import LogisticRegression\nlr_model = LogisticRegression(solver='lbfgs', random_state=2018)\nfit_and_score(\n    lr_model,\n    basic_image_features\n)","b596d629":"from sklearn.ensemble import RandomForestClassifier\nrf_model = RandomForestClassifier(random_state=2018)\nfit_and_score(\n    rf_model,\n    basic_image_features\n)","b50a3b1b":"from sklearn.naive_bayes import GaussianNB\nnb_model = GaussianNB()\nfit_and_score(\n    nb_model,\n    basic_image_features\n)","6061729a":"from sklearn.svm import SVC\nsvm_model = SVC(probability=True)\nfit_and_score(\n    svm_model,\n    basic_image_features\n)","fdbe2b7f":"from skimage.feature import greycomatrix, greycoprops\ngrayco_prop_list = ['contrast', 'dissimilarity', 'homogeneity', 'energy', 'correlation', 'ASM']\ndef calc_texture_features(in_slice):\n    glcm = greycomatrix(in_slice, [5], [0], 256, symmetric=True, normed=True)\n    out_row = {}\n    for c_prop in grayco_prop_list:\n        out_row[c_prop] = greycoprops(glcm, c_prop)[0, 0]\n    return pd.Series(out_row)\ndef texture_features(in_df):\n    out_df = in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].copy()\n    out_df['Mean_Intensity'] = in_df['image'].map(np.mean)\n    out_df['Std_Intensity'] = in_df['image'].map(np.std)\n    # add the results to the current matrix\n    aug_df = pd.concat([\n        out_df,\n        in_df.apply(lambda x: calc_texture_features(x['image']), axis=1)\n    ], 1)\n    return aug_df.values","2e3aeae5":"svm_model = SVC(probability=True)\nfit_and_score(\n    svm_model,\n    texture_features\n)","5d5bd16a":"from keras.applications.vgg16 import VGG16 as PTModel, preprocess_input\nfrom keras import models, layers\nc_model = models.Sequential()\nc_model.add(PTModel(include_top=False, \n                    # get the shape of the image\n                    input_shape=full_train_df['image'].iloc[0].shape+(3,), \n                    weights='imagenet'))\nc_model.add(layers.GlobalAvgPool2D())\n\ndef vgg_features(in_df):\n    out_df = in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].copy()\n    full_image_stack = np.stack(in_df['image'], 0)\n    color_image_stack = np.stack([full_image_stack, full_image_stack, full_image_stack], -1).astype(float)\n    pp_color_image_stack = preprocess_input(color_image_stack)\n    # add the results to the current matrix\n    vgg_features = c_model.predict(pp_color_image_stack)\n    return np.concatenate([out_df.values, vgg_features], 1)","8559a485":"rf_model = RandomForestClassifier(random_state=2018)\nfit_and_score(\n    rf_model,\n    vgg_features\n)","5d2b9655":"from xgboost import XGBClassifier\nxg_model = XGBClassifier()\nfit_and_score(\n    xg_model,\n    vgg_features\n)","6e9de69d":"trn_image, vld_image, trn_label , vld_label = train_test_split(full_train_df['image'], \n                                               full_train_df['opacity'],\n                                               test_size=0.25,\n                                               random_state=2018)\ntrn_image = np.stack(trn_image, 0)\nvld_image = np.stack(vld_image, 0)","fadf2e8d":"out_model = models.Sequential()\nout_model.add(layers.Reshape((64, 64, 1), input_shape=trn_image.shape[1:]))\nout_model.add(layers.Conv2D(16, (3, 3), padding='valid', activation='relu'))\nout_model.add(layers.MaxPool2D((2, 2)))\nout_model.add(layers.Conv2D(32, (3, 3), padding='valid', activation='relu'))\nout_model.add(layers.MaxPool2D((2, 2)))\nout_model.add(layers.Conv2D(64, (3, 3), padding='valid', activation='relu'))\nout_model.add(layers.MaxPool2D((2, 2)))\nout_model.add(layers.Conv2D(128, (3, 3), padding='valid', activation='relu'))\nout_model.add(layers.MaxPool2D((2, 2)))\nout_model.add(layers.GlobalAveragePooling2D())\nout_model.add(layers.Dense(32, activation='relu'))\nout_model.add(layers.Dense(1, activation='sigmoid'))\nout_model.compile(optimizer='adam', \n                  loss='binary_crossentropy', \n                  metrics=['binary_accuracy'])\nout_model.summary()","f8d134fb":"from keras.utils.vis_utils import model_to_dot\nfrom IPython.display import Image\nmodel_rep = model_to_dot(out_model, show_shapes=True)\nmodel_rep.set_rankdir('LR')\nImage(model_rep.create_png())","398161b2":"from IPython.display import clear_output\nfit_results = out_model.fit(trn_image, trn_label, \n                            validation_data=(vld_image, vld_label),\n                            epochs=100)\nclear_output()","3b9f36cb":"fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(20, 10))\nax1.plot(fit_results.history['loss'], label='Training')\nax1.plot(fit_results.history['val_loss'], label='Validation')\nax1.legend()\nax1.set_title('Loss History')\nax2.plot(100*np.array(fit_results.history['binary_accuracy']), label='Training')\nax2.plot(100*np.array(fit_results.history['val_binary_accuracy']), label='Validation')\nax2.legend()\nax2.set_title('Accuracy History')","16e70d11":"def custom_cnn_features(in_df):\n    out_df = in_df[['PatientAge', 'opacity_prior', 'IsMale', 'IsAP']].copy()\n    full_image_stack = np.stack(in_df['image'], 0)\n    # add the results to the current matrix\n    model_pred = out_model.predict(full_image_stack)\n    return np.concatenate([out_df.values, model_pred], 1)","83a805ca":"rf_model = RandomForestClassifier(random_state=2018)\nfit_and_score(\n    rf_model,\n    custom_cnn_features\n)","bf0c5724":"svm_model = SVC(probability=True)\nfit_and_score(\n    svm_model,\n    custom_cnn_features\n)","751bc12f":"xg_model = XGBClassifier()\nfit_and_score(\n    xg_model,\n    custom_cnn_features\n)","7e7fd2c1":"!ls *.csv","11537a91":"# Overview\nThe notebook has runs various models on the the Pneumonia data, the notebook tries to consistently train the models on the same splits so they are comparable. \n1. Basic baseline models\n1. Simple image features (mean and standard deviation)\n1. Adding texture features (co-occurence matrix features)","31ce5ae9":"# Create Training and Validation Groups","bd614c2b":"## Custom CNN Features\nWe use the prediction from the custom CNN as an additional feature in our model","35e99892":"# Train our own CNN\nHere we train our own CNN rather than using a pretrained VGG model. We build a fairly basic model in the spirit of alex net to apply to the tiles. We train the model on a subset of the data ","d7b80972":"# Using Deep Learning\nRather than doing deep learning from scratch, we can try a technique called transfer learning. Here we take a pretrained model called VGG16 from the [Visual Geometry Group at Oxford](http:\/\/www.robots.ox.ac.uk\/~vgg\/) (the model itself classifies objects into categories like cat, wolf, airplane that do not interest us), but we can use the model to generate features (a few layers before the end, often called the 'top', shown in blue below, which we leave off). The model is described in detail [here](https:\/\/arxiv.org\/abs\/1409.1556). \n\n![VGG16](https:\/\/www.cs.toronto.edu\/~frossard\/post\/vgg16\/vgg16.png)","f66b0f49":"## Show the distribution\nWe can use tools like `pairplot` from the `seaborn` package to show the distribution and relationship between multiple variables.","48e855eb":"## Features from greycomatrix\nThe matrix itself isn't very useful, since we are trying to build machine learning-based models and they require features. We can create features by focusing on a few different properties as shown in the `greyco_prop_list` section. More details about some of these features can be found [here](https:\/\/www.mathworks.com\/help\/images\/ref\/graycoprops.html)\n### Contrast \nThe measure of differentiation in intensity between a pixel and its neighbor over the whole image. If an image is constant the contrast will be 0\n- Formula $ \\Sigma_{i,j}|i-j|^2 p(i,j) $\n### Homogeneity\nA measure of the closeness of the distribution of elements. A purely diagonal greycomatrix would result in a homogeneity of 1\n- Formula $ \\Sigma_{i,j} \\frac{p(i, j)}{1+|i-j|} $","76d1cd5d":"# Baseline Models","cc8d8033":"## Try using a gradient boosting\nHere we can try using a stronger classifier that interatively improves itself using a technique called [gradient boosting](http:\/\/blog.kaggle.com\/2017\/01\/23\/a-kaggle-master-explains-gradient-boosting\/). The technique has proved very successful in Kaggle competitions and could provide good results here as well.","850fb44a":"## Reading and Formatting\nHere we read in the training data. We perform a few simple transformations to make the analysis easier.\n1. Replace `PatientSex` with a binary indicator variable `IsMale`\n1. Replace `ViewPosition` with binary indicator variable `IsAP`\n1. Read the slice from the full image","6c51712b":"# Visualize the Model\nHere we can visualize the different layers in the model and compare them to what we see in AlexNet\n![AlexNet](https:\/\/www.researchgate.net\/profile\/Huafeng_Wang4\/publication\/300412100\/figure\/fig1\/AS:388811231121412@1469711229450\/AlexNet-Architecture-To-be-noted-is-copied-2.png)","6c9a3989":"## Adding Basic Image Features\nWe can easily add the mean and std values from the image","603d5750":"# Train the Model\nHere we train the model for 100 epochs which should be enough to get a reasonable result. We clear the output afterwards since it is messy and we use a plot to show the results instead","6998b750":"# Texture Features\n## Greyscale Co-occurence Matrix\nHere we finally add some more interesting texture features using the [scikit-image feature package](http:\/\/scikit-image.org\/docs\/dev\/api\/skimage.feature.html). We initially just use the `greycomatrix` which is short for the [greyscale co-occurence matrix](https:\/\/en.wikipedia.org\/wiki\/Co-occurrence_matrix). The matrix shows how likely certain patterns of pixels are to show up together.\n![greycomatrix](http:\/\/www.jpathinformatics.org\/articles\/2016\/7\/1\/images\/JPatholInform_2016_7_1_36_189699_f2.jpg)\n","87123271":"## Read the Test Data\nHere we read the test data (that we use for the submission), the same way we read the training data","e6e372ec":"# Show all of the files we have made\nHere we can see all of the submissions we have made and we can choose the best one to submit to the competition. The scores here could be overfitted and so the best AUC on the validation data MIGHT NOT be the best score in the competition"}}