{"cell_type":{"ef936341":"code","d1b5102b":"code","e52006d0":"code","b485c14f":"code","db267874":"code","8e58d43d":"code","3ddbbbf6":"code","8407d8e9":"code","eea01fdf":"code","1f2404df":"code","ff9919ca":"code","40ceea1d":"code","58330040":"code","92cc1d0b":"code","5a301527":"code","f0865606":"code","e5023b5e":"code","7adbd3b9":"code","7d866870":"code","832d3563":"code","c066846e":"code","539d3f0a":"code","3daa32ef":"code","d07953b2":"code","9af67c72":"code","1383fc3d":"code","fb14170e":"code","4c46e0e1":"code","fc851005":"code","acdc0a42":"code","fa38a743":"code","3dfd331f":"code","fa80ed1d":"code","93cb11b0":"code","5148a1f0":"code","7d77af4d":"markdown","79d5172f":"markdown","e3b780d7":"markdown","7105382a":"markdown","8f3c7e34":"markdown","dd23da03":"markdown","dedf4c7a":"markdown","fe227af2":"markdown","1e15a7d6":"markdown","7416e049":"markdown","32418f09":"markdown","2acc9b3e":"markdown","80dd215a":"markdown","d360b9b7":"markdown","84ce8656":"markdown","2dabfe4d":"markdown","72e13ba1":"markdown","7dc51e93":"markdown","45cb7298":"markdown","ad62928f":"markdown","bd526bdb":"markdown","7c6b5f81":"markdown"},"source":{"ef936341":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\n#import biblioth\u00e8que pour DataViz\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\n#https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.DistanceMetric.html\nfrom sklearn.neighbors import DistanceMetric\nfrom math import radians","d1b5102b":"df_initial=pd.read_csv('..\/input\/weather-dataset-rattle-package\/weatherAUS.csv')\ndf=df_initial\ndf.head()\n","e52006d0":"# description du set de donn\u00e9es\ndf.info()","b485c14f":"# description du set de donn\u00e9es\ndf.describe()","db267874":"df_loc=pd.read_csv('..\/input\/aus-town-gps\/aus_town_gps.csv',sep=',')\ndf_loc.head()","8e58d43d":"df_loc['Latitude']=np.radians(df_loc['Latitude'])\ndf_loc['Longitude']=np.radians(df_loc['Longitude'])\n\ndist = DistanceMetric.get_metric('haversine')","3ddbbbf6":"df_loc[['Latitude','Longitude']].to_numpy()","8407d8e9":"df_loc_dist=pd.DataFrame(dist.pairwise(df_loc[['Latitude','Longitude']].to_numpy())*6373,  columns=df_loc.Location.unique(), index=df_loc.Location.unique())\ndf_loc_dist","eea01fdf":"#Cr\u00e9ation liste des colonnes \u00e0 \u00e9tudier\ndf_evap=df[['Location','Evaporation']]\n#df_evap=df_evap[df['Evaporation']=='NA']\ndf_evap['isna']=(df['Evaporation'].isna()==True)*1\ndf_evap\n#\n#Tracer des Na pour ces quatres colonnes par ordre d\u00e9croissant suivant la ville\nfig,ax1=plt.subplots(figsize=(20,20))\nsns.countplot(y='Location',hue='isna',ax=ax1,data=df_evap,orient='h');","1f2404df":"#Cr\u00e9ation liste des colonnes \u00e0 \u00e9tudier\ndf_sunshine=df[['Location','Sunshine']]\n#df_evap=df_evap[df['Evaporation']=='NA']\ndf_sunshine['isna']=(df['Sunshine'].isna()==True)*1\ndf_sunshine\n#\n#Tracer des Na pour ces quatres colonnes par ordre d\u00e9croissant suivant la ville\nfig,ax1=plt.subplots(figsize=(20,20))\nsns.countplot(y='Location',hue='isna',ax=ax1,data=df_sunshine,orient='h');\n","ff9919ca":"\npd.crosstab(df_sunshine['Location'],df_sunshine['isna'],normalize='index')","40ceea1d":"# traitement de BadgerysCreek\n# recherche de la ville la plus proche\ndist_Albury=df_loc_dist[df_loc_dist['Albury']!=0]\ndist_Albury","58330040":"#Cr\u00e9ation liste des colonnes \u00e0 \u00e9tudier\ndf_cloud9=df[['Location','Cloud9am']]\n#df_evap=df_evap[df['Evaporation']=='NA']\ndf_cloud9['isna']=(df['Cloud9am'].isna()==True)*1\ndf_cloud9\n#\n#Tracer des Na pour ces quatres colonnes par ordre d\u00e9croissant suivant la ville\nfig,ax1=plt.subplots(figsize=(20,20))\nsns.countplot(y='Location',hue='isna',ax=ax1,data=df_cloud9,orient='h');","92cc1d0b":"#Cr\u00e9ation liste des colonnes \u00e0 \u00e9tudier\ndf_cloud3=df[['Location','Cloud3pm']]\n#df_evap=df_evap[df['Evaporation']=='NA']\ndf_cloud3['isna']=(df['Cloud3pm'].isna()==True)*1\ndf_cloud3\n#\n#Tracer des Na pour ces quatres colonnes par ordre d\u00e9croissant suivant la ville\nfig,ax1=plt.subplots(figsize=(20,20))\nsns.countplot(y='Location',hue='isna',ax=ax1,data=df_cloud3,orient='h');","5a301527":"df['Date'] = pd.to_datetime(df['Date'])\ndf['Mois'] = df['Date'].dt.month\ndf['Trimestre'] = df['Date'].dt.quarter\ndf['Annee'] = df['Date'].dt.year","f0865606":"#Code de Lionel\n#cr\u00e9ation d'un dictionnaire associant la direction du vent \u00e0 l'angle correspondant (en degr\u00e9s) sur le cercle trigonom\u00e9trique (ie. E=0\u00b0 et rotation dans le sens direct)\nangles = {'E':0, \n          'ENE':22.5, \n          'NE':45, \n          'NNE':67.5, \n          'N':90, \n          'NNW':112.5, \n          'NW':135, \n          'WNW':157.5, \n          'W':180, \n          'WSW':202.5, \n          'SW':225, \n          'SSW':247.5, \n          'S':270, \n          'SSE':292.5, \n          'SE':315, \n          'ESE':337.5}\n#ajout des variables indiquant l'angle du vent au DF\ndf['WindGust_Ang']=df['WindGustDir'].map(angles)\ndf['Wind9am_Ang'] = df['WindDir9am'].map(angles)\ndf['Wind3pm_Ang'] = df['WindDir3pm'].map(angles)\ndf","e5023b5e":"colInter=['MinTemp','MaxTemp','Rainfall','WindGustSpeed','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm','Temp9am','Temp3pm','WindGust_Ang','Wind9am_Ang','Wind3pm_Ang']\n\ndf_inter=df[colInter]\ndf_inter\ndf_inter.info()\n\n\n    ","7adbd3b9":"df_inter.interpolate(method='linear',inplace=True)\ndf_inter","7d866870":"df[colInter]=df_inter[colInter]\ndf.info()\n","832d3563":"df=df.dropna(subset=['RainTomorrow'])\ndf.info()","c066846e":"df['RainToday_Num'] = (df['Rainfall'] >  1)*1\n\n","539d3f0a":"df['RainTomorrow_Num'] = (df['RainTomorrow'] =='Yes')*1\ndf","3daa32ef":"df=df.drop(['WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow'],axis=1)","d07953b2":"# Statut des NA pour chaque colonne\nfor i in df:\n    # comptage du nb de NA dans chaque colonne\n    n_miss = df[i].isnull().sum()\n    perc = n_miss \/ df.shape[0] * 100 \n    print(f\"La colonne {i} contient {n_miss} valeurs manquantes soit {perc:.2f} %\")","9af67c72":"df_imputer=df.drop(['Date','Location'],axis=1)\n# import de KNNImputer\nfrom sklearn.impute import KNNImputer\n# d\u00e9finition du transformeur\nimputer=KNNImputer(n_neighbors=5,weights='uniform',metric='nan_euclidean')\n#fit du transformeur\nimputer.fit(df_imputer)","1383fc3d":"df_trans=imputer.transform(df_imputer)","fb14170e":"from numpy import isnan\nprint('Missing: %d' % sum(isnan(df_trans).flatten()))","4c46e0e1":"df_imputer","fc851005":"df_final=df_imputer","acdc0a42":"df_final['Evaporation']=df_trans[:,3]\ndf_final['Sunshine']=df_trans[:,4]\ndf_final['Cloud9am']=df_trans[:,12]\ndf_final['Cloud3pm']=df_trans[:,13]\ndf_final['Date']=df['Date']\ndf_final['Location']=df['Location']","fa38a743":"df_final.info()","3dfd331f":"df_final.to_csv('.\/weatherAUS_Rev1.csv')","fa80ed1d":"plt.figure(figsize=(20,20))\ndf_final2015=df_final[df_final[\"Annee\"]==2015]\nsns.barplot(x='Mois',y='Sunshine',hue='Location',data=df_final2015[(df_final2015['Location']=='AliceSprings')|(df_final2015['Location']=='Uluru')]);","93cb11b0":"plt.figure(figsize=(20,20))\ndf_final2015=df_final[df_final[\"Annee\"]==2015]\nsns.barplot(x='Mois',y='Sunshine',hue='Location',data=df_final2015[(df_final2015['Location']=='Penrith')|(df_final2015['Location']=='SydneyAirport')|(df_final2015['Location']=='Sydney')|(df_final2015['Location']=='BadgerysCreek')]);","5148a1f0":"#SGD Classifier\n#Cr\u00e9ation du dataset de features et target\nfeatures=df_final.drop(['Date','Location','RainTomorrow_Num'],axis=1)\ntarget=df_final['RainTomorrow_Num']","7d77af4d":"Conversion de la latitude et longitude en radians","79d5172f":"* Cloud3pm","e3b780d7":"* interpolation lin\u00e9aire des Na pour les colonnes s\u00e9lectionn\u00e9es","7105382a":"* Sunshine","8f3c7e34":"**Chargement des sets de donn\u00e9es**\nChargement du set de donn\u00e9es de notre projet 'weatherAUS.csv': \n* df qui sera le dataframe qui sera modifi\u00e9 dans notre projet\n* df_initial pour conserver le set de donn\u00e9es initial","dd23da03":"1.Exploration des Na sur colonnes Evaporation, Sunshine, Cloud9am, Cloud3pm\n\n* Evaporation","dedf4c7a":"Cette table de distance pourra \u00eatre exploit\u00e9 si n\u00e9cessaire par la suite","fe227af2":"**Les stations non \u00e9quip\u00e9es pour mesurer la couverture nuageuse \u00e0 9am et \u00e0 3pm sont les m\u00eames**\n\n**De mani\u00e8re g\u00e9n\u00e9rale, les stations suivantes sont moins bien \u00e9quip\u00e9es avec aucune capacit\u00e9 de mesure de l'\u00e9vaporation, l'ensoleillement et de la couverture nuageuse:\n\nBadgryscreek,NorahHead,Penrith,Tuggeranong,Mountginini,Nhil,Goldcoast,Witchcliffe,Salmonguns,Walpole","1e15a7d6":"Conversion de la colonne data","7416e049":"* Affectation des variables qui seront interpol\u00e9es \u00e0 la liste colInter puis cr\u00e9ation d'un dataframe sp\u00e9cifique pour l'interpolation","32418f09":"****Calcul des distances entre les villes \u00e0 partir de la formule d'Haversine et cr\u00e9ation une matrice de distance ville \u00e0 ville.\n\n[https:\/\/fr.wikipedia.org\/wiki\/Formule_de_haversine](https:\/\/fr.wikipedia.org\/wiki\/Formule_de_haversine)","2acc9b3e":"**Gestion des valeurs manquantes - knn-imputation - **","80dd215a":"**Stations non \u00e9quip\u00e9es pour la mesure de l'ensoleillement:**\nAlbury,Badgryscreek,Newcastle,NorahHead,Penrith,Richmond,Wollogong,Tuggeranong,Mountginini,Ballarat,Bendigo,Nhil,Goldcoast,Witchcliffe,Salmonguns,Walpole, Launceston,Katherine, Uluru","d360b9b7":"**Chargement des sets de donn\u00e9es**\nChargement d'un set de donn\u00e9es GPS des stations m\u00e9t\u00e9o: \n* df qui sera le dataframe qui sera modifi\u00e9 dans notre projet\n* df_initial pour conserver le set de donn\u00e9es initial","84ce8656":"* conversion direction vent en angles","2dabfe4d":"* Cloud9am","72e13ba1":"**Stations non \u00e9quip\u00e9es pour la mesure de la couverture nuageuse \u00e0 3 pm:**\nBadgryscreek,NorahHead,Penrith,Tuggeranong,Mountginini,Nhil,Dartmoor,Goldcoast,Adelaide, Witchcliffe,Salmonguns,Walpole","7dc51e93":"**Stations non \u00e9quip\u00e9es pour la mesure de la couverture nuageuse \u00e0 9 am:**\nBadgryscreek,NorahHead,Penrith,Tuggeranong,Mountginini,Nhil,Dartmoor,Goldcoast,Adelaide, Witchcliffe,Salmonguns,Walpole","45cb7298":"Transfert des colonnes sans NA dans df","ad62928f":"suppression des lignes avec raintomorrow = NA","bd526bdb":"* Gestion des NA:\n1. Exploration des Na sur colonnes Evaporation, Sunshine, Cloud9am, Cloud3pm1.Exploration des Na sur colonnes Evaporation, Sunshine, Cloud9am, Cloud3pm\n\n","7c6b5f81":"**Stations non \u00e9quip\u00e9es pour la mesure de l'\u00e9vaporation:**\nAlbury,Badgryscreek,Newcastle,NorahHead,Penrith,Wollogong,Tuggeranong,Mountginini,Ballarat,Nhil,Goldcoast,Witchcliffe,PearceRAAF,Salmonguns,Walpole, Uluru"}}