{"cell_type":{"f3508ef7":"code","261ff40f":"code","1423c510":"code","24a28831":"code","7f79316e":"code","1c1ef6d5":"code","ebc6400d":"code","d32b7e46":"code","39610f08":"code","ecbee7ff":"code","717abb27":"code","4dc9392d":"code","a37a7167":"code","ebf7bcbc":"code","6a7bdf8f":"code","beb0f5bd":"code","3cbee7a6":"code","7a1c199d":"code","2d4c3011":"code","de73c203":"code","6286c8a3":"code","d6e154a4":"code","e8d4a496":"code","ef204915":"code","162fd990":"code","2f2a90de":"code","37ce273e":"code","3f620edc":"code","0f83cf36":"code","2fac3b4e":"markdown","42ef2f0d":"markdown"},"source":{"f3508ef7":"# # Google\u30c9\u30e9\u30a4\u30d6\u306e\u30de\u30a6\u30f3\u30c8\uff08Colab\u4f7f\u3044\u306e\u307f\uff09\n\nfrom google.colab import drive\ndrive.mount('\/content\/drive')\n\n%cd \/content\/drive\/MyDrive","261ff40f":"# \u5fc5\u8981\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u5c0e\u5165\n\n!pip install japanize_matplotlib | tail -n 1\n!pip install torchviz | tail -n 1\n!pip install torchinfo | tail -n 1","1423c510":"# \u5fc5\u8981\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\n\n%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport japanize_matplotlib\nfrom IPython.display import display","24a28831":"# torch\u95a2\u9023\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torchinfo import summary\nfrom torchviz import make_dot","7f79316e":"# warning\u8868\u793aoff\nimport warnings\nwarnings.simplefilter('ignore')\n\n# \u30c7\u30d5\u30a9\u30eb\u30c8\u30d5\u30a9\u30f3\u30c8\u30b5\u30a4\u30ba\u5909\u66f4\nplt.rcParams['font.size'] = 14\n\n# \u30c7\u30d5\u30a9\u30eb\u30c8\u30b0\u30e9\u30d5\u30b5\u30a4\u30ba\u5909\u66f4\nplt.rcParams['figure.figsize'] = (6,6)\n\n# \u30c7\u30d5\u30a9\u30eb\u30c8\u3067\u65b9\u773c\u8868\u793aON\nplt.rcParams['axes.grid'] = True\n\n# numpy\u306e\u8868\u793a\u6841\u6570\u8a2d\u5b9a\nnp.set_printoptions(suppress=True, precision=5)","1c1ef6d5":"import matplotlib.pyplot as plt\n%matplotlib inline","ebc6400d":"# \u30c7\u30d0\u30a4\u30b9\u306e\u5272\u308a\u5f53\u3066\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","d32b7e46":"import numpy as np\nfrom torch.utils.data import Dataset\n\n# DataLoader\u306b\u6e21\u305b\u308b\u3088\u3046\u306b\u3059\u308b\u30af\u30e9\u30b9\u3092\u5b9a\u7fa9\nclass FashionMNIST(Dataset):\n    def __init__(self, X, y=None, transform=None):\n        self.X = X\n        self.y = y\n        self.transform = transform\n        \n    # \u30c7\u30fc\u30bf\u6570\u3092\u8fd4\u3059\n    def __len__(self):\n        return len(self.X.index)\n    \n    # \u30c7\u30fc\u30bf\u3068\u30e9\u30d9\u30eb\u3092\u8fd4\u3059\n    def __getitem__(self, index):\n        image = self.X.iloc[index, ].values.astype(np.uint8).reshape((28, 28, 1))\n        \n        if self.transform is not None:\n            image = self.transform(image)\n            \n        if self.y is not None:\n            return image, self.y.iloc[index]\n        else:\n            return image","39610f08":"import pandas as pd\nfrom sklearn.model_selection import train_test_split\nimport torchvision.transforms as transforms\n\n# csv\u30d5\u30a1\u30a4\u30eb\u306e\u8aad\u307f\u8fbc\u307f\ntrain_df = pd.read_csv('input\/train.csv')\ntest_df = pd.read_csv('input\/test.csv')\n\n# train.csv\u306e\u5185\u5bb9\u3092\u8a13\u7df4\u30c7\u30fc\u30bf\u3068\u691c\u8a3c\u30c7\u30fc\u30bf\u306b\u5206\u5272\nX_train, X_valid, y_train, y_valid = \\\n    train_test_split(train_df.iloc[:, 1:], train_df['label'], test_size=0.2, random_state=0)\n\n\n# \u30c6\u30b9\u30c8\u30c7\u30fc\u30bf\u4f5c\u6210\nX_test = test_df\n\ntransform3 = transforms.Compose([\n  transforms.ToTensor(),\n\n  transforms.Normalize(0.5, 0.5),\n\n  transforms.Lambda(lambda x: x.view(-1)),\n])\n\n# pytorch dataset\u3092\u4f5c\u6210\uff08DataLoader\u306b\u6e21\u305b\u308b\u3088\u3046\u306b\u5909\u63db\uff09\ntrain_dataset = FashionMNIST(X=X_train, y=y_train, transform=transform3)\nvalid_dataset = FashionMNIST(X=X_valid, y=y_valid, transform=transform3)\ntest_dataset = FashionMNIST(X=X_test, transform=transforms.ToTensor())","ecbee7ff":"image, label = train_dataset[0]\nprint(len(train_dataset))\nprint(type(image))\nprint(type(label))","717abb27":"print(image.shape)\nprint(image.data.min())\nprint(image.data.max())","4dc9392d":"#\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u306b\u3088\u308b\u30df\u30cb\u30d0\u30c3\u30c1\u7528\u30c7\u30fc\u30bf\u4f5c\u6210\n\nfrom torch.utils.data import DataLoader\n\n#\u30df\u30cb\u30d0\u30c3\u30c1\u306e\u30b5\u30a4\u30ba\u6307\u5b9a\nbatch_size = 500\n\n#\u8a13\u7df4\u7528\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\ntrain_loader = DataLoader(\n    train_dataset, batch_size = batch_size,\n    shuffle = True)\n#\u691c\u8a3c\u7528\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\nvalid_loader = DataLoader(\n    valid_dataset, batch_size = batch_size,\n    shuffle = False)\n","a37a7167":"print(len(train_loader))\n\nfor images, labels in train_loader:\n  break\n\nprint(images.shape)\nprint(labels.shape)","ebf7bcbc":"\n\n#\u5165\u529b\u6b21\u5143\u6570\nn_input = image.shape[0]\n\n#\u51fa\u529b\u6b21\u5143\u6570\nn_output = len(set(list(labels.data.numpy())))\n\n#\u96a0\u308c\u5c64\u306e\u30ce\u30fc\u30c9\nn_hidden = 128\n\n#\u7d50\u679c\u78ba\u8a8d\nprint(n_input)\nprint(n_output)\nprint(n_hidden)","6a7bdf8f":"#\u30e2\u30c7\u30eb\u5b9a\u7fa9\n#784\u5165\u529b10\u51fa\u529b\uff11\u96a0\u308c\u5c64\u306e\u30cb\u30e5\u30fc\u30e9\u30eb\u30cd\u30c3\u30c8\u30ef\u30fc\u30af\u30e2\u30c7\u30eb\n\nclass Net(nn.Module):\n  def __init__(self, n_input, n_output, n_hidden):\n    super().__init__()\n\n    #\u96a0\u308c\u5c64\u306e\u5b9a\u7fa9\n    self.l1 = nn.Linear(n_input, n_hidden)\n\n    #\u51fa\u529b\u5c64\u306e\u5b9a\u7fa9\n    self.l2 = nn.Linear(n_hidden, n_output)\n\n    #ReLu\u95a2\u6570\u306e\u5b9a\u7fa9\n    self.relu = nn.ReLU(inplace=True)\n\n  def forward(self, x):\n    x1 = self.l1(x)\n    x2 = self.relu(x1)\n    x3 = self.l2(x2)\n    return x3","beb0f5bd":"#\u4e71\u6570\u306e\u56fa\u5b9a\u5316\ntorch.manual_seed(123)\ntorch.cuda.manual_seed(123)\n\n#\u30e2\u30c7\u30eb\u5909\u6570\u306e\u751f\u6210\nnet = Net(n_input, n_output, n_hidden)\n\n#\u30e2\u30c7\u30eb\u3092GPU\u5074\u306b\u9001\u308b\nnet = net.to(device)","3cbee7a6":"#\u8a13\u7df4\u30c7\u30fc\u30bf\u30bb\u30c3\u30c8\u3000\u6700\u521d\u306e1\u9805\u76ee\u3092\u53d6\u5f97\n#\u30c7\u30fc\u30bf\u30ed\u30fc\u30c0\u30fc\u304b\u3089\u6700\u521d\u306e1\u30bb\u30c3\u30c8\u3092\u53d6\u5f97\u3059\u308b\nfor images, labels in train_loader:\n  break\n\ninputs = images.to(device)\nlabels = labels.to(device)","7a1c199d":"# \u5b66\u7fd2\u7387\nlr = 0.01\n\n# \u30a2\u30eb\u30b4\u30ea\u30ba\u30e0: \u52fe\u914d\u964d\u4e0b\u6cd5\noptimizer = torch.optim.SGD(net.parameters(), lr=lr)\n\n# \u640d\u5931\u95a2\u6570\uff1a \u4ea4\u5dee\u30a8\u30f3\u30c8\u30ed\u30d4\u30fc\u95a2\u6570\ncriterion = nn.CrossEntropyLoss()","2d4c3011":"#\u4e88\u6e2c\u5024\u306e\u8a08\u7b97\noutputs = net(inputs)\n\nprint(outputs)","de73c203":"#\u640d\u5931\u8a08\u7b97\nloss = criterion(outputs, labels)\n\n#\u640d\u5931\u5024\u306e\u53d6\u5f97\nprint(loss.item())\n\n#\u640d\u5931\u306e\u8a08\u7b97\u30b0\u30e9\u30d5\u53ef\u8996\u5316\nmake_dot(loss, params=dict(net.named_parameters()))","6286c8a3":"#\u521d\u671f\u5316\u51e6\u7406\n#\u4e71\u6570\u306e\u56fa\u5b9a\u5316\ntorch.manual_seed(123)\ntorch.cuda.manual_seed(123)\n\n#\u5b66\u7fd2\u7387\nlr = 0.01\n\n#\u30e2\u30c7\u30eb\u306e\u521d\u671f\u5316\nnet = Net(n_input, n_output, n_hidden).to(device)\n\n#\u640d\u5931\u95a2\u6570\ncriterion = nn.CrossEntropyLoss()\n\n#\u6700\u9069\u5316\u95a2\u6570:\u52fe\u914d\u964d\u4e0b\u6cd5\noptimizer = optim.SGD(net.parameters(), lr=lr)\n\n#\u7e70\u308a\u8fd4\u3057\u56de\u6570\nnum_epochs = 100\n\n#\u8a55\u4fa1\u7d50\u679c\u8a18\u9332\u7528\nhistory = np.zeros((0,5))\n","d6e154a4":"# tqdm\u30e9\u30a4\u30d6\u30e9\u30ea\u306e\u30a4\u30f3\u30dd\u30fc\u30c8\nfrom tqdm.notebook import tqdm\n\n# \u7e70\u308a\u8fd4\u3057\u8a08\u7b97\u30e1\u30a4\u30f3\u30eb\u30fc\u30d7\n\nfor epoch in range(num_epochs):\n    train_acc, train_loss = 0, 0\n    val_acc, val_loss = 0, 0\n    n_train, n_test = 0, 0\n\n    # \u8a13\u7df4\u30d5\u30a7\u30fc\u30ba\n    for inputs, labels in tqdm(train_loader):\n        n_train += len(labels)\n\n        # GPU\u30d8\u8ee2\u9001\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n    \n        #\u52fe\u914d\u306e\u521d\u671f\u5316\n        optimizer.zero_grad()\n\n        # \u4e88\u6e2c\u8a08\u7b97\n        outputs = net(inputs)\n\n        # \u640d\u5931\u8a08\u7b97\n        loss = criterion(outputs, labels)\n\n        # \u52fe\u914d\u8a08\u7b97\n        loss.backward()\n    \n        # \u30d1\u30e9\u30e1\u30fc\u30bf\u4fee\u6b63\n        optimizer.step()\n\n        # \u4e88\u6e2c\u30e9\u30d9\u30eb\u5c0e\u51fa\n        predicted = torch.max(outputs, 1)[1]\n\n        # \u640d\u5931\u3068\u7cbe\u5ea6\u306e\u8a08\u7b97\n        train_loss += loss.item()\n        train_acc += (predicted == labels).sum() \n\n    #\u4e88\u6e2c\u30d5\u30a7\u30fc\u30ba\n    for inputs_test, labels_test in valid_loader:\n        n_test += len(labels_test)\n\n        inputs_test = inputs_test.to(device)\n        labels_test = labels_test.to(device)\n\n            \n        # \u4e88\u6e2c\u8a08\u7b97\n        outputs_test = net(inputs_test)\n\n        # \u640d\u5931\u8a08\u7b97\n        loss_test = criterion(outputs_test, labels_test)\n\n        #\u4e88\u6e2c\u30e9\u30d9\u30eb\u5c0e\u51fa\n        predicted_test = torch.max(outputs_test, 1)[1]\n\n        # \u640d\u5931\u3068\u7cbe\u5ea6\u306e\u8a08\u7b97\n        val_loss +=  loss_test.item()\n        val_acc +=  (predicted_test == labels_test).sum()\n\n    # \u8a55\u4fa1\u5024\u306e\u7b97\u51fa\u30fb\u8a18\u9332\n    train_acc = train_acc \/ n_train\n    val_acc = val_acc \/ n_test\n    train_loss = train_loss * batch_size \/ n_train\n    val_loss = val_loss * batch_size \/ n_test\n    print (f'Epoch [{epoch+1}\/{num_epochs}], loss: {train_loss:.5f} acc: {train_acc:.5f} val_loss: {val_loss:.5f}, val_acc: {val_acc:.5f}')\n    item = np.array([epoch+1 , train_loss, train_acc, val_loss, val_acc])\n    history = np.vstack((history, item))","e8d4a496":"plt.plot(history[:,0], history[:,1], 'b', label='\u8a13\u7df4')\nplt.plot(history[:,0], history[:,3], 'k', label='\u691c\u8a3c')\nplt.xlabel('\u7e70\u308a\u8fd4\u3057\u56de\u6570')\nplt.ylabel('\u640d\u5931')\nplt.title('\u5b66\u7fd2\u66f2\u7dda(\u640d\u5931)')\nplt.legend()\nplt.show()","ef204915":"# \u5b66\u7fd2\u66f2\u7dda\u306e\u8868\u793a (\u7cbe\u5ea6)\n\nplt.rcParams['figure.figsize'] = (9,8)\nplt.plot(history[:,0], history[:,2], 'b', label='\u8a13\u7df4')\nplt.plot(history[:,0], history[:,4], 'k', label='\u691c\u8a3c')\nplt.xlabel('\u7e70\u308a\u8fd4\u3057\u56de\u6570')\nplt.ylabel('\u7cbe\u5ea6')\nplt.title('\u5b66\u7fd2\u66f2\u7dda(\u7cbe\u5ea6)')\nplt.legend()\nplt.show()","162fd990":"import pandas as pd\nimport numpy as np\n\nout_df = pd.DataFrame()\nout_df['ImageId'] = np.arange(1, len(test_df)+1)\nout_df['Label'] = # \u4e88\u6e2c\u7d50\u679c\n\nout_df.to_csv('submission.csv', index=None)","2f2a90de":"# test_loader\u3092\u4f5c\u308b\ntest_loader = DataLoader(\n    dataset=test_dataset\n    , batch_size=batch_size\n    , shuffle=False\n)","37ce273e":"# \u30bd\u30d5\u30c8\u30de\u30c3\u30af\u30b9\u95a2\u6570\ndef softmax(x):\n    return np.exp(x)\/np.sum(np.exp(x), axis=1)[:, None]","3f620edc":"# \u3053\u3053\u3067\u8a55\u4fa1\nnet.eval()\ntest_preds = []\n\nwith torch.no_grad():\n    for image in test_loader:\n        image = image.view(-1, 28 * 28 * 1 ).to(device)\n        test_pred = net.forward(image)\n        # \u30bd\u30d5\u30c8\u30de\u30c3\u30af\u30b9\u95a2\u6570\u3067\u5404\u30e9\u30d9\u30eb\u306e\u78ba\u7387\u3092\u8a08\u7b97\u3057\u3066\u30ea\u30b9\u30c8\u306b\u4fdd\u5b58\n        test_preds.append(softmax(test_pred.detach().cpu().numpy()))","0f83cf36":"import pandas as pd\nimport numpy as np\n\nout_df = pd.DataFrame()\n# 1~10000\nout_df['ImageId'] = np.arange(1, len(test_df)+1)\n# \u6700\u3082\u78ba\u7387\u306e\u9ad8\u3044\u30e9\u30d9\u30eb\u3060\u3051\u3092'Label'\u306b\u4fdd\u5b58\nout_df['Label'] = np.argmax(np.concatenate(test_preds, axis=0), axis=1)\n\nout_df.to_csv('submission.csv', index=None)","2fac3b4e":"## \u52d5\u4f5c\u691c\u8a3c\u3057\u3066\u306a\u3044\u304b\u3089\u6ce8\u610f","42ef2f0d":"##\u3053\u3053\u304b\u3089\u5148\u304c\u5206\u304b\u308a\u307e\u305b\u3093"}}