{"cell_type":{"9287c70b":"code","3cb04b23":"code","7d4325d5":"code","c3792319":"code","88352d32":"code","e44a8058":"code","5205a8e1":"code","1e93d582":"code","93762fa0":"code","e158bd64":"code","8c34f309":"code","cef814c2":"code","33243429":"code","004e77aa":"code","329f0282":"code","36f614a1":"code","d72649d9":"code","46a91aba":"code","37365897":"code","14d146d5":"code","4fc130a0":"code","8895893d":"code","3e9c9546":"code","0578840c":"code","2d271039":"code","a21a5a83":"markdown","0decbbcd":"markdown","a2002b56":"markdown","765c9aa8":"markdown","1e93a4c6":"markdown","8bb2da6e":"markdown","df0357b0":"markdown","bca3b7ec":"markdown","3c70186a":"markdown","b99d547e":"markdown","bb6b9a84":"markdown","29bea543":"markdown"},"source":{"9287c70b":"pip install openpyxl","3cb04b23":"# Import Important Libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nimport re\nimport tensorflow\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.layers import Embedding, LSTM, Dropout, Dense\nfrom tensorflow.keras.models import Sequential","7d4325d5":"df = pd.read_excel('..\/input\/amazon-reviews-dataset\/review-details.xlsx', engine = 'openpyxl', usecols= ['review_title', 'review_text', 'review_rating'])\n# test = pd.read_excel('..\/input\/amazon-reviews-dataset\/null', usecols= ['reviewtitle', 'reviewtext', 'reviewrating'])","c3792319":"df.head()","88352d32":"df.info()","e44a8058":"print(df['review_rating'].value_counts())\ndf['review_rating'].value_counts().plot.bar(color='green')","5205a8e1":"df.isnull().sum()","1e93d582":"df = df.dropna()","93762fa0":"df['sentiments'] = df['review_rating'].apply(lambda x: 0 if x == [1, 2] else 1)\ndf.head()","e158bd64":"# Dependent Features\ny = df['sentiments']\n\n# Independent Features\nX = df.drop('sentiments', axis=1)","8c34f309":"messages = X.copy()\nmessages = messages.reset_index()   ## we reset the index because above we drop the nan values because of this the index will be disturb","cef814c2":"stopwords = set(stopwords.words('english'))","33243429":"ps = PorterStemmer()\ncorpus = []\nfor i in range(0, len(messages)):\n    review = re.sub('[^a-zA-Z]', ' ', messages['review_text'][i])\n    review = review.lower()\n    review = review.split()\n    \n    review = [ps.stem(word) for word in review if not word in stopwords]\n    review = ' '.join(review)\n    corpus.append(review)","004e77aa":"corpus[0]","329f0282":"voc_size = 15000\nmax_length = 120\nembedding_dim = 16","36f614a1":"from tensorflow.keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words=voc_size, oov_token='<OOV>')\ntokenizer.fit_on_texts(corpus)","d72649d9":"sequences = tokenizer.texts_to_sequences(corpus)\n\nembedded_docs = pad_sequences(sequences, maxlen=max_length, padding='post', truncating= 'post')","46a91aba":"X_final = np.array(embedded_docs)\ny_final = np.array(y)","37365897":"X_final.shape, y_final.shape","14d146d5":"model = Sequential()\nmodel.add(Embedding(voc_size, embedding_dim, input_length=max_length))\nmodel.add(LSTM(100))\nmodel.add(Dense(64, activation= 'relu'))\nmodel.add(Dense(32, activation = 'relu'))\nmodel.add(Dense(1, activation = 'sigmoid'))\nmodel.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\nprint(model.summary())","4fc130a0":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_final, y_final, test_size=0.33, random_state=42)","8895893d":"model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=10, batch_size=32)","3e9c9546":"y_predict = ((model.predict(X_test)>0.5).astype('int32'))","0578840c":"#confusion Matrix\nfrom sklearn.metrics import confusion_matrix\nconfusion_matrix(y_test, y_predict)","2d271039":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_predict)","a21a5a83":"**Always make a copy before working on dataset this is a good practice**","0decbbcd":"Here, the value of oov_token is set to be \u2018OOV\u2019. That means any unknown words will be replaced by oov_token.","a2002b56":"# Model Training","765c9aa8":"# Sentiment Analysis (Amazon Review Dataset)","1e93a4c6":"# Performance Metrics and Accuracy","8bb2da6e":"# Split the Data into Train and Test","df0357b0":"# Model Creation","bca3b7ec":"**Now Separate a Dependent and Independent Features**","3c70186a":"# Stemming The Words\nSimpy we change the words into its root word","b99d547e":"**Load The Dataset**","bb6b9a84":"# Now Tokenize the Dataset","29bea543":"# EDA and Data Preprocessing"}}