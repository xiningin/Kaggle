{"cell_type":{"759fb231":"code","5cebd316":"code","c878f7b7":"code","e7c0d327":"code","fb3ba624":"code","b63397b6":"code","b92dd32c":"code","2eeee6c2":"code","3706b8b5":"code","8c388c31":"code","e5128176":"markdown","2172b03a":"markdown","2dca89c4":"markdown","be96261e":"markdown","eaeeeda3":"markdown","f109d7f0":"markdown","c1e4025d":"markdown","d94aff11":"markdown","70edc64b":"markdown","8b832d62":"markdown","fab03fed":"markdown"},"source":{"759fb231":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5cebd316":"filename = '..\/input\/indias-population-simple-linear-regression\/population.csv'\ndf = pd.read_csv(filename)","c878f7b7":"df.head(5)","e7c0d327":"df.describe()","fb3ba624":"df.info()","b63397b6":"x = df['Year'].values\ny = df['Population'].values\n\nx = x.reshape(-1,1)\ny = y.reshape(-1,1)\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, train_size=.8, test_size=.2, random_state=17)","b92dd32c":"plt.scatter(x_train, y_train, color='blue')\nplt.xlabel('Year')\nplt.ylabel('Population')\nplt.title('Population of India Over Time')\nplt.show()","2eeee6c2":"lm = LinearRegression()\nlm.fit(x_train,y_train)\ny_predict =lm.predict(x_test)","3706b8b5":"print(f'Train Accuracy {round(lm.score(x_train,y_train)*100, 2)}%')\nprint(f'Test Accuracy {round(lm.score(x_test,y_test)*100, 2)}%')","8c388c31":"plt.scatter(x_train, y_train, color='blue')\nplt.plot(x_test,y_predict)\nplt.xlabel('Year')\nplt.ylabel('Population')\nplt.title('Population of India Over Time')\nplt.show()","e5128176":"# Exploratory Analysis with Linear Regressions\n## Utilizes Statistics on the Population of India\n### Michael Greene","2172b03a":"### Viewing the top 5 rows, we can see how the data will be arranged:","2dca89c4":"### First we found a suitable dataset, imported it into our notebook, and assigned it as a Pandas dataframe:","be96261e":"### Lastly, we draw our linear regression line:","eaeeeda3":"### The `.info()` method allows us to view all column names, their counts, and their data types supported within the data frame:","f109d7f0":"### Next, using a linear regression model, we predict the trend of the population data:","c1e4025d":"### The `.describe()` method allows us to view the measures of central tendency of the dataframe at a glance:","d94aff11":"## We can answer 3 general questions using the above data:\n  + **1)When were birthrates lowest in modern Indian history?** \n    + Between the 1950s-1970s.\n  + **2)Will birthrates remain consistent for the next 30 years?** \n    + No, it is predicted that in the 2030s, there will begin a gentle decline of birthrates until 2050.\n  + **3)Approximately when do we estimate India's population to overtake the current population total of China?** \n    + According to the data, approaching the approximate year 2040, the Indian population will overtake the current #1 global population.","70edc64b":"### Here we can see the data charted:","8b832d62":"### We then test the accuracy score, or how closely our data sticks to the predicted trend. We see our data was extremely consistent:","fab03fed":"### Next, we separate the data into a training set and testing sets:"}}