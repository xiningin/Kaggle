{"cell_type":{"12528611":"code","0c7e3175":"code","a0beb0b5":"code","df999e11":"code","a2b286e0":"code","68ec7944":"code","55c13cfc":"code","ce2328c5":"code","cb97c33f":"code","7f093794":"code","05649847":"code","7d2993e3":"code","ff3fbc67":"code","cf5b35d8":"code","e15626cf":"code","d669f623":"code","6334e6b3":"code","5a0a00f3":"code","857c2084":"code","e26c8329":"code","4ec0aede":"code","4abe1769":"code","7bdeaef9":"code","7a131c66":"code","0681df9e":"code","0f3e410d":"code","16030169":"code","3db3057d":"code","fdcb7875":"code","10e9d314":"code","cb8ad14d":"code","731dbda9":"code","e11d96fa":"code","6f2e8909":"code","7fc2d756":"code","6882e6f1":"code","58c63064":"code","c21f262f":"code","c733326a":"markdown","472ffaba":"markdown","761e7b8f":"markdown","933dc122":"markdown","cd7ce46e":"markdown","4729cb49":"markdown","0cd72af8":"markdown","3cae0a0e":"markdown","ffef1453":"markdown","846c1827":"markdown","4778f10b":"markdown","931a0750":"markdown","5ae1ac47":"markdown"},"source":{"12528611":"import torch\nfrom torchvision.datasets import ImageFolder\nimport torch.nn.functional as F\nfrom torchvision import transforms\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.utils.data import random_split\nfrom torchvision.utils import make_grid\nfrom torch.utils.data import DataLoader, SubsetRandomSampler\n\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport time\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report\nfrom collections import Counter","0c7e3175":"root_folder = '..\/input\/minerals-identification-dataset\/minet'\ntarget_label = ['biotite', 'bornite', 'chrysocolla', 'malachite', \n                'muscovite', 'pyrite', 'quartz']\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")","a0beb0b5":"#load data and tranform it into tensor\ndataset = ImageFolder(root_folder, transform=transforms.ToTensor())\nprint('Data size: ',len(dataset))\ndataset.classes","df999e11":"#check images of the dataset for first 20 images\nfig = plt.figure(figsize=(25, 4))\n\nfor i in range(20):\n    image, label = dataset[i]\n    ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks = [])\n    ax.imshow(image.permute(1,2,0))\n    ax.set_title(target_label[label], color='green')","a2b286e0":"#count number for each label\ncount = {}\n\nfor i in range(len(dataset)):\n    _, labels = dataset[i]\n    label = target_label[labels]\n    if label not in count:\n        count[label] = 1\n    elif label in count:\n        count[label] += 1\n\n#insert count into dataframe\ndf = pd.DataFrame(count, index=np.arange(1))\ndf = df.transpose().reset_index()\ndf.columns = ['Mineral', 'count']\ndf","68ec7944":"#plot barplot for the sake of easy to read\nsns.barplot(df['Mineral'], df['count'])\nplt.title('Dataset for each label');\nplt.xticks(rotation=30)\nplt.grid(axis='y')","55c13cfc":"#check image size for all datasets\n# torch.FloatTensor of shape (C x H x W) \nheight = []\nweight = []\nfor i in range(len(dataset)):\n    image, label = dataset[i]\n    height.append(image.size(1))\n    weight.append(image.size(2))\nprint(f\"maximum_height:{np.max(height)} \\tminimum_height:{np.min(height)} \\tmean_height:{np.mean(height)}\")\nprint(f\"maximum_weight:{np.max(weight)} \\tminimum_weight:{np.min(weight)} \\tmean_weight:{np.mean(weight)}\")","ce2328c5":"#transform format to augmetation dataset beacuse our dataset only has 956 images\n#I reload the data and do multiple transformation and resize it\ndata_transform = transforms.Compose([transforms.Resize((224, 224)), \n                                     transforms.RandomRotation(30), \n                                     transforms.RandomVerticalFlip(p=0.5),\n                                     transforms.RandomHorizontalFlip(p=0.5),\n                                     transforms.ToTensor(),\n                                     transforms.Normalize(mean = [0.485, 0.456, 0.406],std = [0.229, 0.224, 0.225])]) #imagenet mean and std\n\nload_data = ImageFolder(root_folder, transform=data_transform)\n\n#check the images result from transformation\nfig = plt.figure(figsize=(25, 4))\nfor i in range(20):\n    image, label = load_data[i]\n    ax = fig.add_subplot(2, 10, i+1, xticks=[], yticks = [])\n    ax.imshow(image.permute(1,2,0))\n    ax.set_title(target_label[label], color='green')","cb97c33f":"# split base on random_split\n\n# #ration for data split\n# train_ratio = 0.90 \n# train_size = int(len(load_data)*train_ratio) #90% data training\n# val_size = int((len(load_data) - train_size) * 0.5)  #5% validation\n# test_size = len(load_data) - (train_size + val_size) #5% testing\n\n# datasize = len(load_data)\n# data_idx = [x for x in range(datasize)]\n\n# np.random.seed(97)\n# np.random.shuffle(data_idx)\n\n# train_idx = data_idx[:train_size]\n# val_idx = data_idx[train_size:-test_size]\n# test_idx = data_idx[train_size+val_size:]\n# # #split data into 3 parts train, validation and testing\n# # #train_set, val_set, test_set = random_split(load_data, [train_size, val_size, test_size])\n# print('size of training data: ', len(train_idx))\n# print('size of validation data: ', len(val_idx))\n# print('size of test data: ', len(test_idx))","7f093794":"def plot_dist(indexes, dataset=dataset):\n    #dist = {}\n    count = Counter()\n    for i in indexes:\n        _, label = dataset[i]\n        count[target_label[label]] += 1\n    \n    # for i in indexes:\n    #     img, labels = dataset[i]\n    #     label = target_label[labels]\n    #     if label not in dist:\n    #         dist[label] = 1\n    #     elif label in dist:\n    #         dist[label] +=1\n\n    dist_2 = dict(sorted(count.items(), key=lambda kv: kv[1], reverse=True))\n    plt.bar(dist_2.keys(), dist_2.values())\n    plt.xticks(rotation=30)\n    plt.title('Data distribution'); plt.ylabel('count')\n    plt.show()","05649847":"# split data to get the same distributiom\n\n\n#get index and its label\nidx_label = {}\nfor i in range(len(dataset)):\n    _, label = dataset[i]\n    idx_label[i] = label\n\n#split for data validation\nx_train, x_val, y_train, y_val = train_test_split(list(idx_label.keys()), list(idx_label.values()), \n                                                  stratify = list(idx_label.values()), test_size=0.05)\n\n","7d2993e3":"#exclude validation index from dataset\nx_val\nidx_label_2 = {}\nfor idx, label in idx_label.items():\n    if idx not in x_val:\n        idx_label_2[idx] = label\n\n#split data train and test after exlude x_val\nx_train, x_test, y_train, y_test = train_test_split(list(idx_label_2.keys()), list(idx_label_2.values()),\n                                                    stratify = list(idx_label_2.values()), test_size=0.05)\nprint(len(x_train))\nprint(len(x_val))\nprint(len(x_test))","ff3fbc67":"plot_dist(x_train)\nplot_dist(x_val)\nplot_dist(x_test)","cf5b35d8":"#load into dataloader for each data after split it\nbatch_size = 128\n\n#using subset to get data from indexes with the same distribution label\ntrain_set = SubsetRandomSampler(x_train)\nval_set = SubsetRandomSampler(x_val)\ntest_set = SubsetRandomSampler(x_test)\n\n#dataloader\ntrain_loader = DataLoader(load_data, batch_size=batch_size, \n                          shuffle=False, num_workers=4, sampler= train_set)\nval_loader = DataLoader(load_data, batch_size=batch_size,  \n                        num_workers=4, sampler=val_set)\ntest_loader = DataLoader(load_data, batch_size=batch_size,\n                         num_workers=4, sampler=test_set)","e15626cf":"#check image in trainloader for one batch\nfor images, _ in train_loader:\n    print('images.shape:', images.shape)\n    plt.figure(figsize=(16,16))\n    plt.axis('off')\n    plt.imshow(make_grid(images, nrow=16).permute((1, 2, 0)))\n    break","d669f623":"#calculation for convnet\nw1 = 20\nF_SIZE= 3\nF_POOL = 3\nP = 0\nS_SIZE = 1\nS_POOL = 3\n\nSIZE = (w1 - F_SIZE + 2*P)\/S_SIZE+1 #size after conv\nPOOL = (SIZE - F_POOL)\/S_POOL+1\nw1 = POOL #size after pool\nprint(SIZE)\nw1","6334e6b3":"6*6*64","5a0a00f3":"class Mineral_1(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.net = nn.Sequential(\n            nn.Conv2d(3, 48, 11, stride=3, padding=0),\n            nn.ReLU(),\n            nn.MaxPool2d(3, 1), #out 70x70\n\n            nn.Conv2d(48, 128, 5, stride=1, padding=0),\n            nn.ReLU(),\n            nn.MaxPool2d(3, 1),#out 64x64\n\n            nn.Conv2d(128, 128, 4, stride=1, padding=0),\n            nn.ReLU(),\n            nn.MaxPool2d(4, 3),#out 20x20\n\n            nn.Conv2d(128, 64, 3, stride=1, padding=0),\n            nn.ReLU(),\n            nn.MaxPool2d(3, 3),#out 20x20\n\n            nn.Flatten(),\n            nn.Linear(64*6*6, 512),\n            nn.ReLU(),\n            nn.Dropout(p=0.3),\n            nn.Linear(512, 7),\n            nn.LogSoftmax(dim=1),\n            )\n        \n    def forward(self, x):\n        out = self.net(x)\n        return out\n\nmodel_1 = Mineral_1()\nmodel_1.to(device)\nmodel_1","857c2084":"# # model paper\n# class Mineral(nn.Module):\n#     def __init__(self):\n#         super().__init__()\n#         # input shape  (3, 224x224) W2=(W1\u2212F+2P)\/S+1\n#         self.conv1 = nn.Conv2d(3, 48, 7, stride=3, padding=1)\n#         self.conv2 = nn.Conv2d(48, 128, 5, stride=3, padding=1)\n#         self.conv3 = nn.Conv2d(128, 128, 4, stride=2, padding=1)\n#         self.conv4 = nn.Conv2d(128, 128, 4, stride=1, padding=1)\n        \n#         self.pool = nn.MaxPool2d(3,1) #(W1\u2212F)\/S+1\n \n#         #Classifier layer\n#         self.fc1 = nn.Linear(4608, 512)\n#         self.fc2 = nn.Linear(512,7)\n        \n#         #dropout for minimalize overfitting\n#         self.drop = nn.Dropout(p=0.3)\n#         self.soft = nn.LogSoftmax(dim=1)\n    \n#     def forward(self, x):\n#         #conv layers\n#         x = self.pool(F.relu(self.conv1(x)))\n#         x = self.pool(F.relu(self.conv2(x)))\n#         x = self.pool(F.relu(self.conv3(x)))\n#         x = self.pool(F.relu(self.conv4(x)))  \n \n#         #Dense Layers\n#         #flattening the input from conv layers\n#         x = x.view(x.size(0), -1)\n#         # add dropout layer\n#         x = self.drop(F.relu(self.fc1(x)))\n#         x = self.soft(self.fc2(x))\n        \n#         return x\n\n# model = Mineral()\n\n# criterion = nn.NLLLoss()\n# optimizer = optim.Adam(model.parameters(), lr=0.0001)\n# model.to(device);\n# model","e26c8329":"def fit(epochs, model, train_loader, val_loader, criterion, optimizer):\n    train_losses = []\n    test_losses = []\n    train_accu = []\n    val_accu = []\n    fit_time = time.time()\n    for e in range(epochs):\n        since = time.time()\n        running_loss = 0\n        train_acc = 0\n        for image, label in train_loader:\n            optimizer.zero_grad()\n            image = image.to(device); label = label.to(device);\n\n            output = model(image)\n            ps = torch.exp(output)\n            _, top_class = ps.topk(1, dim=1)\n            correct = top_class == label.view(*top_class.shape)\n            train_acc += torch.mean(correct.type(torch.FloatTensor))\n\n            loss = criterion(output, label)\n            loss.backward()\n            optimizer.step()\n            running_loss += loss.item()\n\n        else:\n            model.eval()\n            test_loss = 0\n            accuracy = 0\n            with torch.no_grad():\n                for image, label in val_loader:\n                    image = image.to(device); label = label.to(device);\n\n                    output = model(image)\n                    loss = criterion(output, label)\n\n                    ps = torch.exp(output)\n                    _, top_class = ps.topk(1, dim=1)\n                    correct = top_class == label.view(*top_class.shape)\n                    accuracy += torch.mean(correct.type(torch.FloatTensor))\n\n                    test_loss += loss.item()\n\n            train_losses.append(running_loss\/len(train_loader))\n            test_losses.append(test_loss\/len(val_loader))\n            train_accu.append(train_acc\/len(train_loader))\n            val_accu.append(accuracy\/len(val_loader))\n            model.train()\n            print(\"Epoch: {}\/{}.. \".format(e+1, epochs),\n                  \"Train Loss: {:.3f}.. \".format(running_loss\/len(train_loader)),\n                  \"Test Loss: {:.3f}.. \".format(test_loss\/len(val_loader)),\n                  \"Train Accuracy: {:.3f}.. \".format(train_acc\/len(train_loader)),\n                  \"Test Accuracy: {:.3f}.. \".format(accuracy\/len(val_loader)),\n                  \"Time: {:.2f}s\" .format((time.time()-since)))\n    \n    history = {'train_loss' : train_losses, 'val_loss': test_losses, \n               'train_accuracy': train_accu, 'val_accuracy':val_accu}\n    print('Total time: {:.2f} m' .format((time.time()- fit_time)\/60))\n    return history","4ec0aede":"#saving model\ndef save_model(model, optim, fpath):\n    checkpoint = {'model' : model,\n                'state_dict': model.state_dict(),\n                'optim' : optim.state_dict()\n                }\n\n    torch.save(checkpoint, fpath)\n\n#load model\ndef load_model(fpath, inferece = True):\n    check = torch.load(fpath)\n    model = check['model']\n    model.load_state_dict(check['state_dict'])\n    if inferece:\n        for param in model.parameters():\n            param.requires_grad = False\n        model.eval()\n    else:\n        model.train()\n    return model","4abe1769":"criterion = nn.NLLLoss()\noptimizer = optim.Adam(model_1.parameters(), lr=0.0001)\nepoch = 40\nhistory_mineral = fit(epoch, model_1, train_loader, val_loader, criterion, optimizer)","7bdeaef9":"#save mode\nsave_model(model_1, optimizer, 'mineral_seq_own.pt')","7a131c66":"def plot_loss(history, n_epoch):\n    epoch = [x for x in range(1, n_epoch+1)]\n    plt.plot(epoch, history['train_loss'], label='Train_loss')\n    plt.plot(epoch, history['val_loss'], label='val_loss')\n    plt.title('Loss per epoch')\n    plt.ylabel('Loss')\n    plt.xlabel('epoch')\n    plt.legend(); \n    plt.show()\n\ndef plot_accuracy(history, n_epoch):\n    epoch = [x for x in range(1, n_epoch+1)]\n    plt.plot(epoch, history['train_accuracy'], label='Train_accuracy')\n    plt.plot(epoch, history['val_accuracy'], label='val_accuracy')\n    plt.title('accuracy per epoch')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(); \n    plt.show()\nplot_loss(history_mineral, epoch)\nplot_accuracy(history_mineral, epoch)","0681df9e":"from torchvision import models\n\n# Use GPU if it's available\ndevice = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n\nmodelVGG = models.vgg16(pretrained=True)\n\n# Freeze parameters so we don't backprop through them\nfor param in modelVGG.parameters():\n    param.requires_grad = False\n\n#vgg16\nmodelVGG.classifier = nn.Sequential(nn.Linear(in_features=25088, out_features=4096),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.5),\n                                 nn.Linear(in_features=4096, out_features=1000),\n                                 nn.ReLU(),\n                                 nn.Dropout(p=0.5),\n                                 nn.Linear(in_features=1000, out_features=500),\n                                 nn.Linear(500, 7),\n                                 nn.LogSoftmax(dim=1))\n\n#vgg19\n# model.classifier = nn.Sequential(nn.Linear(in_features=25088, out_features=4096, bias=True),\n#                                  nn.ReLU(inplace=True),\n#                                  nn.Dropout(p=0.5, inplace=False),\n#                                  nn.Linear(in_features=4096, out_features=4096, bias=True),\n#                                  nn.ReLU(inplace=True),\n#                                  nn.Dropout(p=0.5, inplace=False),\n#                                  nn.Linear(in_features=4096, out_features=7, bias=True),\n#                                  nn.LogSoftmax(dim=1))\n\n\n\nmodelVGG.to(device);\nmodelVGG.train()\nmodelVGG","0f3e410d":"criterion = nn.NLLLoss()\noptimizer = optim.Adam(modelVGG.classifier.parameters(), lr=0.0001)\nepoch = 40\nhistory_VGG = fit(epoch, modelVGG, train_loader, val_loader, criterion, optimizer)","16030169":"save_model(modelVGG,  optimizer, 'mineral_vgg.pt')","3db3057d":"plot_loss(history_VGG, epoch)\nplot_accuracy(history_VGG, epoch)","fdcb7875":"def predict_label(model, dataloader):\n    prediction_list = []\n    labels = []\n    model.to(device)\n    model.eval()\n    for i, batch in enumerate(dataloader):\n        image, label = batch\n        image = image.to(device); label = label.to(device)\n      \n        out = model(image)\n        ps = torch.exp(out)\n        _, top_class = torch.max(ps , 1)\n        preds = np.squeeze(top_class.cpu().numpy())\n        prediction_list.append(preds)\n        labels.append(label.cpu().numpy())\n    return np.squeeze(prediction_list), np.squeeze(labels)","10e9d314":"def predict_plot(test_loader, model, target_label=target_label, n=20):\n\n    # obtain one batch of test images\n    dataiter = iter(test_loader)\n    images, labels = dataiter.next()\n    images.numpy()\n\n    # move model inputs to cuda, if GPU available\n    train_on_gpu = torch.cuda.is_available()\n    if train_on_gpu:\n        images = images.cuda()\n\n    model.eval()\n    # get sample outputs\n    model.to(device)\n    output = model(images)\n    # convert output probabilities to predicted class\n    _, preds_tensor = torch.max(output, 1)\n    preds = np.squeeze(preds_tensor.cpu().numpy()) #np.squeeze(preds_tensor.numpy()) if not train_on_gpu else np.squeeze(preds_tensor.cpu().numpy())\n    images = images.cpu()\n\n    # plot the images in the batch, along with predicted and true labels\n    fig = plt.figure(figsize=(25, 4))\n    for idx in np.arange(n):\n        ax = fig.add_subplot(2, n\/2, idx+1, xticks=[], yticks=[])\n        plt.imshow(images[idx].permute(1 ,2, 0))\n        ax.set_title(\"{} ({})\".format(target_label[preds[idx]], target_label[labels[idx]]),\n                    color=(\"green\" if preds[idx]==labels[idx].item() else \"red\"))\n    plt.show()","cb8ad14d":"model_mineral = load_model('mineral_seq_own.pt', inferece=True)\nmodel_mineral","731dbda9":"#how model perfome in test_data\ny_predict, y_true = predict_label(model_mineral, test_loader)","e11d96fa":"#plot confusion matric\nprint(classification_report(y_true, y_predict))\nsns.heatmap(confusion_matrix(y_true, y_predict), annot=True)\nplt.ylabel('True label'); plt.xlabel('Predicted Label')\nplt.yticks(np.arange(0.5, len(target_label)), labels=target_label, rotation=0);\nplt.xticks(np.arange(0.5, len(target_label)), labels=target_label, rotation=45)\nplt.title('My Model Prediction Over Test Set')\nplt.show()","6f2e8909":"model_vgg = load_model('mineral_vgg.pt', inferece=True)","7fc2d756":"#how model perfome in test_data\ny_predict_vgg, y_true_vgg = predict_label(model_vgg, test_loader)","6882e6f1":"#plot confusion matric\nprint(classification_report(y_true_vgg, y_predict_vgg))\nsns.heatmap(confusion_matrix(y_true_vgg, y_predict_vgg), annot=True)\nplt.ylabel('True label'); plt.xlabel('Predicted Label')\nplt.yticks(np.arange(0.5, len(target_label)), labels=target_label, rotation=0);\nplt.xticks(np.arange(0.5, len(target_label)), labels=target_label, rotation=45)\nplt.title('VGG Model Prediction Over Test Set')\nplt.show()","58c63064":"predict_plot(test_loader, model_vgg)","c21f262f":"predict_plot(test_loader, model_mineral)","c733326a":"## My own model","472ffaba":"# Load Data and Get Insight","761e7b8f":"# Data Loader","933dc122":"## My Model ","cd7ce46e":"## Split Data","4729cb49":"## VGG Model","0cd72af8":"I still don't know why my model only learn one class but it's not for pre-trained model so the dataloader not the problem","3cae0a0e":"## Load All Data","ffef1453":"## Plot Prediction","846c1827":"# Prediction and Evaluation","4778f10b":"# Build Model","931a0750":"## Pre-trained mode","5ae1ac47":"# Load Library"}}