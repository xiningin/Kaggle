{"cell_type":{"3956e4fd":"code","791861d4":"code","71d908fa":"code","14c92750":"code","c16621f3":"code","b5fd4190":"code","4d9162ad":"code","83dec4db":"code","72d5e6c5":"code","4c8bc118":"code","7e0c19be":"code","911e9bc1":"code","48472489":"code","cd7b2fec":"code","895609c3":"code","322503c0":"code","447dfe11":"code","47c8a4a6":"code","322e67a8":"code","d428ccf9":"code","15883b42":"code","fc7d602e":"code","f6633019":"code","3147cc56":"code","704d7b7a":"code","075837b9":"code","d251855d":"code","c688b867":"code","e19e482a":"code","fa072f8d":"code","419da6ce":"code","4c4dc9c2":"code","e0052955":"code","54cf9754":"code","491656d6":"code","dd740d05":"markdown","79bf7472":"markdown","68d6f302":"markdown","f8a5134a":"markdown","edcc7aba":"markdown","4c5fcab3":"markdown","293b047d":"markdown"},"source":{"3956e4fd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n%matplotlib inline\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom sklearn.preprocessing import LabelEncoder, StandardScaler, MinMaxScaler\nfrom sklearn.model_selection import train_test_split, cross_validate, cross_val_score, KFold, GridSearchCV\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.compose import ColumnTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.linear_model import LinearRegression\nfrom xgboost import XGBRegressor","791861d4":"# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","71d908fa":"df_train = pd.read_csv('\/kaggle\/input\/diamonds-ds-ft-2109\/diamonds_train.csv', index_col='Unnamed: 0')\ndf_test = pd.read_csv('\/kaggle\/input\/diamonds-ds-ft-2109\/diamonds_test.csv', index_col='Unnamed: 0')\ndf_train.head()","14c92750":"df_train.info()","c16621f3":"df_train.describe()","b5fd4190":"sns.lineplot(data=df_train, x=\"carat\", y=\"price\")","4d9162ad":"sns.lineplot(data=df_train, x=\"depth\", y=\"price\")","83dec4db":"sns.barplot(data=df_train, x=\"clarity\", y=\"price\")","72d5e6c5":"sns.barplot(data=df_train, x=\"color\", y=\"price\")","4c8bc118":"sns.barplot(data=df_train, x=\"cut\", y=\"price\")","7e0c19be":"sns.barplot(data=df_train, x=\"table\", y=\"price\")","911e9bc1":"df_train[\"size\"] = df_train[\"x\"] * df_train[\"y\"] * df_train[\"z\"]\ndf_train.head()","48472489":"df_train.isna().sum()","cd7b2fec":"duplicate = df_train[df_train.duplicated(keep=False)]\nduplicate","895609c3":"df_train.shape","322503c0":"df_train = df_train.drop(columns=['x','y','z'])","447dfe11":"df_train.info()","47c8a4a6":"category = [\"cut\", \"clarity\", \"color\"]\ndf_cat = df_train[category]\ndf_cat.head()","322e67a8":"def cut_to_n(cut):\n    return ['Fair', 'Good', 'Very Good', 'Premium', 'Ideal'].index(cut)\n\ndef color_to_n(color):\n    return ['D', 'E', 'F', 'G', 'H', 'I','J'].index(color)\n\ndef clarity_to_n(clarity):\n    return ['I1', 'SI2', 'SI1', 'VS2', 'VS1', 'VVS2', 'VVS1', 'IF'].index(clarity)\n\ndf_train['n_cut'] = df_train['cut'].map(cut_to_n)\ndf_train['n_color'] = df_train['color'].map(color_to_n)\ndf_train['n_clarity'] = df_train['clarity'].map(clarity_to_n)\ndf_train = df_train.drop(labels=['cut','color','clarity'],axis=1)","d428ccf9":"df_train.head()","15883b42":"sns.heatmap(df_train.corr(),linewidths=.5,annot=True,cmap='RdYlGn')\nfig=plt.gcf()\nfig.set_size_inches(10,10)\nplt.show()","fc7d602e":"df_train_ready = df_train[[\"n_cut\", \"size\", \"carat\", \"price\"]]\ndf_train_ready.head()","f6633019":"X = df_train_ready.drop('price', axis=1)\ny = df_train_ready['price']\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n\nprint(\"X Train : \", len(X_train))\nprint(\"y Train : \", len(y_train))\nprint(\"X Test : \", len(X_test))\nprint(\"t Test : \", len(y_test))","3147cc56":"pipeline = Pipeline([\n    ('std_scalar', StandardScaler())\n])\n\nX_train = pipeline.fit_transform(X_train)\nX_test = pipeline.transform(X_test)","704d7b7a":"lin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train,y_train)","075837b9":"print(lin_reg.intercept_)","d251855d":"xgber = XGBRegressor()\nxgber.fit(X_train, y_train)","c688b867":"Input = sm.add_constant(X)\nSimpleModel = sm.OLS(y,Input, missing='drop')\nresults = SimpleModel.fit()\nprint(results.summary())","e19e482a":"f_value = results.fvalue\nprint(\"f-test score : \", f_value)\n\np_value = results.f_pvalue\nprint(\"P-value : \", p_value)\n\nif p_value < 0.05:\n  print(\"Reject H0\")\nelse:\n  print(\"Failed to Reject H0\")","fa072f8d":"pred = lin_reg.predict(X_test)\ndf_train_ready[\"residual\"] = y_test - pred\nasm_homosk = plt.scatter(df_train_ready[\"price\"], df_train_ready[\"residual\"])\nplt.xlabel('predicted')\nplt.ylabel('residuals')\nasm_homosk = sns.regplot([2,5],[0,0],color='red')\nasm_homosk = plt.title('Residuals vs Prediction')","419da6ce":"olsmod = sm.OLS(df_train_ready['price'], X).fit()\nprint('R2 score:', olsmod.rsquared)","4c4dc9c2":"print('Root Mean Squared Error :', mean_squared_error(y_test, pred, squared=False))","e0052955":"df_test['n_cut'] = df_test['cut'].map(cut_to_n)\ndf_test['n_color'] = df_test['color'].map(color_to_n)\ndf_test['n_clarity'] = df_test['clarity'].map(clarity_to_n)\ndf_test = df_test.drop(labels=['cut','color','clarity'],axis=1)\ndf_test[\"size\"] = df_test[\"x\"] * df_test[\"y\"] * df_test[\"z\"]\ndf_test_ready = df_test[[\"n_cut\", \"size\", \"carat\"]]\n\n\ndf_test_ready.head()","54cf9754":"df_test_ready = pipeline.transform(df_test_ready)","491656d6":"testpred = xgber.predict(df_test_ready)\noutput = pd.DataFrame({'id':df_test.index, 'price':testpred})\noutput.to_csv('submission.csv', index=False)","dd740d05":"# **Load and Predict Data Test**","79bf7472":"Cut, size, carat highly correlates with price of Diamonds","68d6f302":"# **Data Pre-Processing**","f8a5134a":"# **Modeling**","edcc7aba":"# **Feature Engineering**","4c5fcab3":"# **Exploratory Data Analysis**","293b047d":"# **Evaluation**"}}