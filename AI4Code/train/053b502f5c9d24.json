{"cell_type":{"a1b3b655":"code","a08ca570":"code","03bb8891":"code","9ad385d5":"code","e7ece8d8":"code","cace996f":"code","4cf1f857":"code","8de7bf94":"code","d8d5207b":"code","1929612f":"code","6a325f70":"code","cce9978b":"code","ce3de369":"code","a524815a":"code","4220f1b5":"code","802eba06":"code","64f2e8c6":"code","09e12b12":"markdown","45ee6b29":"markdown","68a0310d":"markdown"},"source":{"a1b3b655":"### Install H2O\n!pip install h2o","a08ca570":"import h2o\nfrom h2o.automl import H2OAutoML","03bb8891":"### Initialize H2o Cluster\nh2o.init()","9ad385d5":"# Data Preparation\ndf = h2o.import_file(path='..\/input\/song-popularity-prediction\/train.csv')\ndf","e7ece8d8":"# Describe the dataset. H2O provides 10 rows of sample data along with basic summary statistics for numerical columns.\ndf.describe(chunk_summary=True)","cace996f":"##  Split the dataset into train and test set\ntrain, test = df.split_frame(ratios=[0.8], seed = 1)","4cf1f857":"y = \"song_popularity\"\nx = train.columns\nx.remove(y)","8de7bf94":"aml = H2OAutoML(max_models =20, balance_classes=True,seed =7 ,exclude_algos = [ \"DeepLearning\"], nfolds=5)\n\n### 2nd way\n# aml = H2OAutoML(max_models = 10, seed = 10, exclude_algos = [\"StackedEnsemble\", \"DeepLearning\"], verbosity=\"info\", nfolds=0)","d8d5207b":"!nvidia-smi","1929612f":"%%time\naml.train(training_frame = train, y = y, x=x)","6a325f70":"lb = aml.leaderboard","cce9978b":"lb.head(rows=lb.nrows)","ce3de369":"# aml.train(training_frame = train,y = 'song_popularity',leaderboard_frame = my_leaderboard_frame)\naml.train(training_frame = train,y = y)","a524815a":"### Lets get the best performing model\nbest_model = aml.get_best_model()\nprint(best_model)","4220f1b5":"best_model.model_performance(test)","802eba06":"explain_model = aml.explain(frame = test, figsize = (8,6))","64f2e8c6":"aml.explain_row(frame = test, row_index = 15, figsize = (8,6))","09e12b12":"### Evaluation\nAfter the models are trained, we can compare the model performance using the leaderboard. H2O AutoML produces a leaderboard which ranks the trained model based on a predefined metric. By default it ranks models by ascending order of logloss and rmse for classification and regression task respectively.\n\n#### `NOTE:` The leaderboard metrics are calculated based on the cross validation set unless a leaderboard_frame is specified during training.","45ee6b29":"### Explainability\nH2O AutoML also provides insights into model\u2019s global explainability such as variable importance, partial dependence plot, SHAP values and model correlation with just one line of code","68a0310d":"### Train AutoML Models\nLet's configure the AutoML training parameters.\n* **max_models**: Maximum number of models to train\n* **balance_classes**: set to True to balance the class labels for tasks with imbalance data\n* **seed** : Set for reproducibility\n\n#### We can limit the amount of time spent on searching for the best model by limiting:\n* maximum number of models using max_models\n* total time spent using max_runtime_secs\n* time spend training any single model using max_runtime_secs_per_model.\n\n#### Start the training by specifying:\n* training_frame: the dataframe that contains training data\n* y: the column in the training_frame which contains the target variable"}}