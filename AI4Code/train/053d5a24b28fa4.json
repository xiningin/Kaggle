{"cell_type":{"2536dca1":"code","a5f41b24":"code","e5540cd6":"code","ff11ecdf":"code","fdbdd468":"code","b4750b50":"code","fb30c1b2":"code","1dcab523":"code","3ae0364b":"code","ca4671e5":"code","bde7fb1b":"code","b21051e7":"code","9829fe88":"code","5749f897":"code","5a627dc7":"code","f4837717":"code","1bb3205b":"code","f7af332b":"code","a204178b":"code","19771f3e":"code","3ea75670":"code","5501370d":"code","117acf00":"code","dd095217":"code","a3383243":"code","d5904ab2":"code","4e45b766":"code","63329dc1":"code","3c4ba627":"code","31c82fa7":"code","72fb5e66":"code","b769aded":"code","10bb9c97":"code","39796c30":"code","9b343a37":"code","fa8f0116":"code","21f77269":"code","4efe8486":"code","d35a19ba":"code","2592e4eb":"code","77832161":"code","d0a63dd9":"code","bf2654a0":"code","5108e3eb":"code","d2ba7f4b":"code","6f35ce9d":"code","81d62588":"code","e4d5c3c7":"code","d205ba24":"code","7980fefa":"code","4a75c1b1":"code","f184a89a":"code","24eba3fc":"code","21dfce3c":"code","d7159518":"code","018b073e":"code","c0016400":"code","5f5f6dfc":"code","4c357fe1":"code","a5b0088b":"code","426c834b":"code","7240eb5d":"code","d0eac712":"code","586a27f8":"code","79559f87":"code","6e38bbf4":"code","99d03511":"code","e178163b":"code","9a092bd0":"code","10ea1617":"code","54ef4ff4":"code","a0787d8c":"code","5bc62248":"markdown","78b29190":"markdown","2d91bcfa":"markdown","e7a977a9":"markdown","ab8f66c3":"markdown","35c530b8":"markdown","897682ae":"markdown","6cf508a1":"markdown","8a19e56c":"markdown","23832dc8":"markdown","7d30751b":"markdown","265401ce":"markdown","5f286091":"markdown","c978dc93":"markdown","d5b1c9f2":"markdown","beb2321f":"markdown","36227ff0":"markdown","ac4ef8c7":"markdown","45e2b080":"markdown","4d7acfa5":"markdown","203b3c98":"markdown","4d49c533":"markdown","ad99fa39":"markdown","b2dc7e78":"markdown","c47dcef0":"markdown","ad044d2f":"markdown","ef98e9d4":"markdown","9d049bdc":"markdown","31c0f5f8":"markdown","9ee5d9bb":"markdown","492488cd":"markdown","416157bc":"markdown","b4aa0048":"markdown","516bdac1":"markdown","7df8dd26":"markdown","2116a944":"markdown","2d27c285":"markdown","b053258b":"markdown","008c10c0":"markdown","20383924":"markdown","d0410ad4":"markdown","e56997eb":"markdown","0c38b218":"markdown","e10e9873":"markdown","e16e04cc":"markdown","dee36c79":"markdown"},"source":{"2536dca1":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom IPython.core.display import display, HTML\ndisplay(HTML(\"<style>.container { width:100% !important; }<\/style>\"))\nsns.set()\n\n# set up display area to show dataframe in jupyter qtconsole\npd.set_option('display.max_rows', 500)\npd.set_option('display.max_columns', 500)","a5f41b24":"df = pd.read_csv(\"..\/input\/qsar-biodegradation-data-set\/biodegradation.csv\")","e5540cd6":"df.head()","ff11ecdf":"df.shape","fdbdd468":"df.info() #Valid Dtype for Machine learning","b4750b50":"df.describe()","fb30c1b2":"df.isnull().sum()","1dcab523":"df.isnull().sum().sum()","3ae0364b":"df.replace([\"RB\",\"NRB\"],[1,0], inplace = True) #apply decoding","ca4671e5":"#rename target for better readability\ndf.rename(columns = {\"experimental class\": \"degradable\"}, inplace = True);","bde7fb1b":"df.head(5)","b21051e7":"y = df['degradable']\nX_features = df.drop('degradable', axis=1)","9829fe88":"from sklearn.neighbors import LocalOutlierFactor\n\ncolumns= df.columns.tolist()\n\nlof= LocalOutlierFactor()\ny_out=lof.fit_predict(X_features)\ny_out[0:30]","5749f897":"x_score= lof.negative_outlier_factor_\noutlier_score= pd.DataFrame()\noutlier_score[\"score\"]=x_score\n\nlofthreshold= -3\nloffilter= outlier_score[\"score\"]< lofthreshold\noutlier_index= outlier_score[loffilter].index.tolist()","5a627dc7":"plt.figure(figsize=(30,15))\nplt.scatter(X_features.iloc[outlier_index,0], X_features.iloc[outlier_index,4] ,color=\"blue\",s=50,label=\"outliers\")\nplt.scatter(X_features.iloc[:,0],X_features.iloc[:,4],color=\"k\",s=3,label=\"Data Points\")\n\nradius=(x_score.max()- x_score)\/(x_score.max()-x_score.min())\noutlier_score[\"radius\"]=radius\nplt.scatter(X_features.iloc[:,0],X_features.iloc[:,4],s=1000*radius,edgecolors=\"r\",facecolors=\"none\",label=\"outlier scores\")\nplt.legend()","f4837717":"X_features= X_features.drop(outlier_index)\ny= y.drop(outlier_index).values","1bb3205b":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nX_transform = scaler.fit_transform(X_features)\nX_transform_pd = pd.DataFrame(X_transform, columns = X_features.columns)\nX_transform_pd.head(10)","f7af332b":"X_transform_pd.head(10).style.background_gradient(cmap='Blues')","a204178b":"df.corr().style.background_gradient(cmap='Reds')","19771f3e":"#get critical correlation values\ndf.corr().applymap(lambda x: x if abs(x)>.90 else \"\")","3ea75670":"df.columns","5501370d":"df = df.drop(columns=[\"SM6_L\",\"SpMax_A\",\"SM6_B(m)\"])","117acf00":"df.columns","dd095217":"df.corr().applymap(lambda x: x if abs(x)>.90 else \"\")","a3383243":"pd.set_option('use_inf_as_na', True)\nfrom sklearn.base import clone\nimport matplotlib.colors as mcolors\nimport plotly.graph_objs as go\nimport plotly.offline as py","d5904ab2":"bio_df = df.loc[df[\"degradable\"] == 1]\nno_bio_df = df.loc[df[\"degradable\"] == 0]","4e45b766":"trace = go.Pie(labels = ['Degradable', 'Not-Degradable'], values = df['degradable'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['lightskyblue','gold'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of target variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","63329dc1":"corr_keep = list(set(df.columns))","3c4ba627":"color = sns.color_palette(\"pastel\")\n\nfig, ax1 = plt.subplots(8,4, figsize=(30,60))\nk = 0\ncolumns = list(bio_df.columns)\nfor i in range(8):\n    for j in range(4):\n            sns.distplot(bio_df[columns[k]], ax = ax1[i][j], color = 'blue', )\n            plt.xlabel(columns[k],size=20)\n            k += 1\nplt.show()","31c82fa7":"color = sns.color_palette(\"pastel\")\n\nfig, ax1 = plt.subplots(8,4, figsize=(30,60))\nk = 0\ncolumns = list(no_bio_df.columns)\nfor i in range(8):\n    for j in range(4):\n        sns.distplot(no_bio_df[columns[k]], ax = ax1[i][j], color = 'red')\n        k += 1\nplt.show()","72fb5e66":"features = corr_keep\n\n#plot the features side by side\nfor col in list(filter(lambda x: x != \"diagnosis\", features)):\n    sns.distplot(bio_df[col], label = \"Degradable\", color = \"blue\")\n    sns.distplot(no_bio_df[col], label = \"Not-degradable\", color ='red' )\n    plt.legend(loc=1, prop={'size': 6})\n    plt.show()","b769aded":"corrmat = df.corr()\nplt.figure(figsize = (30, 20),)\nsns.heatmap(corrmat,\n            square=True,\n            annot = True,\n            annot_kws={'size': 9},\n            fmt = \".2f\")\nplt.title('Correlation between features');\nplt.show()","10bb9c97":"# Correlation matrix\nplt.figure(figsize = (30, 20), dpi = 150)\n\nmask = np.triu(np.ones_like(corrmat, dtype = bool))\nsns.heatmap(corrmat,\n            mask = mask,\n            cmap = 'BuPu',\n            annot = True,\n            annot_kws={'size': 9},\n            linewidths = 0.5,\n            fmt = \".2f\")\n\nplt.title('Correlation Matrix',\n          fontsize = 20,\n          weight = 'semibold',\n          color = 'Black')\nplt.show()","39796c30":"# Correlation matrix \nf, (ax1, ax2) = plt.subplots(1,2,figsize =(45, 20))\n\nmask = np.zeros_like(corrmat, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap((df.loc[df['degradable'] == 1]).corr(), \n            vmax = .8,\n            square=True,\n            annot = True,\n            annot_kws={'size': 9},\n            fmt = \".2f\",\n            ax = ax1, \n            cmap = 'YlGnBu', \n            mask=mask);\nax1.set_title('Degradable',\n             fontsize = 20)\n\nsns.heatmap((df.loc[df['degradable'] == 0]).corr(),\n            vmax = .8,\n            square=True,\n            annot = True,\n            annot_kws={'size': 9},\n            fmt = \".2f\",\n            ax = ax2,\n            cmap = 'YlGnBu',\n            mask=mask);\n\nax2.set_title('Not-Degradable',\n             fontsize = 20)\nplt.show()","9b343a37":"#Selecting the best 30 features\nfrom sklearn.feature_selection import SelectKBest, f_classif\nkBest = SelectKBest(f_classif, k = 30)\nX_kBestFeatures = kBest.fit_transform(X_transform, y)\nX_kBestFeatures.shape","fa8f0116":"X_kBestFeatures = X_transform_pd.iloc[:, kBest.get_support(True)]\nX_kBestFeatures.columns","21f77269":"print('Not Degradable', round(df['degradable'].value_counts()[0]\/len(df) * 100,2), '% of the dataset')\nprint('Degradable', round(df['degradable'].value_counts()[1]\/len(df) * 100,2), '% of the dataset')","4efe8486":"from sklearn.model_selection import train_test_split\n\nfrom sklearn.metrics import plot_confusion_matrix\nimport seaborn as sns\n\nX_train, X_test, y_train, y_test = train_test_split(X_kBestFeatures, y, test_size=0.30, random_state=30)\n\n# describes info about train and test set\nprint(\"Number transactions X_train dataset: \", X_train.shape)\nprint(\"Number transactions y_train dataset: \", y_train.shape)\nprint(\"Number transactions X_test dataset: \", X_test.shape)\nprint(\"Number transactions y_test dataset: \", y_test.shape)","d35a19ba":"from sklearn.metrics import confusion_matrix, classification_report\nfrom sklearn.linear_model import LogisticRegression\n# logistic regression object\nlr = LogisticRegression(random_state=30)\n  \n# train the model on train set\nclf = lr.fit(X_train, y_train.ravel())\n  \npredictions = lr.predict(X_test)\n  \n# print classification report\nprint(classification_report(y_test, predictions))","2592e4eb":"sns.set_context(\"poster\")\ndisp = plot_confusion_matrix(clf, X_test, y_test, cmap = 'cividis')\nplt.grid(False)","77832161":"print(\"Before OverSampling, counts of label '1': {}\".format(sum(y_train == 1)))\nprint(\"Before OverSampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n\n# import SMOTE module from imblearn library\n\nfrom imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=1)\nX_train_res, y_train_res = sm.fit_resample(X_train, y_train.ravel())\n\nprint('After OverSampling, the shape of train_X: {}'.format(X_train_res.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_res.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))","d0a63dd9":"colors = ['red' if v == 0 else 'blue' for v in y_train]\nkwarg_params = {'linewidth': 1, 'edgecolor': 'black'}\nfig, av = plt.subplots(figsize=(24,16))\nav.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=colors, **kwarg_params)\nplt.suptitle(\"Benchmark Data before Oversampling\")\nplt.show()","bf2654a0":"colors = ['red' if v == 0 else 'blue' for v in y_train_res]\nkwarg_params = {'linewidth': 1, 'edgecolor': 'black'}\nfig, av = plt.subplots(figsize=(24,16))\nav.scatter(X_train_res.iloc[:, 0], X_train_res.iloc[:, 1], c=colors, **kwarg_params)\nplt.suptitle(\"Benchmark Data after Oversampling\")\nplt.show()","5108e3eb":"lr1 = LogisticRegression(random_state = 30)\nclf_smote = lr1.fit(X_train_res, y_train_res.ravel())\npredictions = lr1.predict(X_test)\n\n# print classification report\nprint(classification_report(y_test, predictions))","d2ba7f4b":"sns.set_context(\"poster\")\ndisp = plot_confusion_matrix(clf_smote, X_test, y_test, cmap = 'cividis')\nplt.grid(False)","6f35ce9d":"print(\"Before Undersampling, counts of label '1': {}\".format(sum(y_train == 1)))\nprint(\"Before Undersampling, counts of label '0': {} \\n\".format(sum(y_train == 0)))\n\n# apply near miss\nfrom imblearn.under_sampling import NearMiss\nnr = NearMiss()\n\nX_train_miss, y_train_miss = nr.fit_resample(X_train, y_train.ravel())\n\nprint('After Undersampling, the shape of train_X: {}'.format(X_train_miss.shape))\nprint('After Undersampling, the shape of train_y: {} \\n'.format(y_train_miss.shape))\n\nprint(\"After Undersampling, counts of label '1': {}\".format(sum(y_train_miss == 1)))\nprint(\"After Undersampling, counts of label '0': {}\".format(sum(y_train_miss == 0)))\n","81d62588":"colors = ['red' if v == 0 else 'blue' for v in y_train]\nkwarg_params = {'linewidth': 1, 'edgecolor': 'black'}\nfig, av = plt.subplots(figsize=(24,16))\nav.scatter(X_train.iloc[:, 0], X_train.iloc[:, 1], c=colors, **kwarg_params)\nplt.suptitle(\"Benchmark Data before Undersampling\")\nplt.show()","e4d5c3c7":"colors = ['red' if v == 0 else 'blue' for v in y_train_miss]\nkwarg_params = {'linewidth': 1, 'edgecolor': 'black'}\nfig, av = plt.subplots(figsize=(24,16))\nav.scatter(X_train_miss.iloc[:, 0], X_train_miss.iloc[:, 1], c=colors, **kwarg_params)\nplt.suptitle(\"Benchmark Data after Undersampling\")\nplt.show()","d205ba24":"# train the model on train set\nlr2 = LogisticRegression(random_state = 30)\nclf_miss = lr2.fit(X_train_miss, y_train_miss.ravel())\npredictions = lr2.predict(X_test)\n\n# print classification report\nprint(classification_report(y_test, predictions))","7980fefa":"sns.set_context(\"poster\")\ndisp = plot_confusion_matrix(clf_miss, X_test, y_test, cmap = 'cividis')\nplt.grid(False)","4a75c1b1":"print(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_res == 1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_res == 0)))","f184a89a":"from sklearn.metrics import roc_auc_score, accuracy_score, precision_score, recall_score, f1_score\nfrom sklearn.metrics import precision_recall_fscore_support\n\n#Models\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\n\n\nfrom sklearn.model_selection import cross_validate","24eba3fc":"LR = LogisticRegression(random_state=30)\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\nscores = cross_validate(LR, X_train_res, y_train_res, scoring=scoring, cv=20)\n\nsorted(scores.keys())\nLR_fit_time = scores['fit_time'].mean()\nLR_score_time = scores['score_time'].mean()\nLR_accuracy = scores['test_accuracy'].mean()\nLR_precision = scores['test_precision_macro'].mean()\nLR_recall = scores['test_recall_macro'].mean()\nLR_f1 = scores['test_f1_weighted'].mean()\nLR_roc = scores['test_roc_auc'].mean()","21dfce3c":"decision_tree = DecisionTreeClassifier(random_state=30)\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\nscores = cross_validate(decision_tree, X_train_res, y_train_res, scoring=scoring, cv=20)\n\nsorted(scores.keys())\ndtree_fit_time = scores['fit_time'].mean()\ndtree_score_time = scores['score_time'].mean()\ndtree_accuracy = scores['test_accuracy'].mean()\ndtree_precision = scores['test_precision_macro'].mean()\ndtree_recall = scores['test_recall_macro'].mean()\ndtree_f1 = scores['test_f1_weighted'].mean()\ndtree_roc = scores['test_roc_auc'].mean()","d7159518":"SVM = SVC(probability = True, random_state=30)\n\nscoring = ['accuracy','precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\nscores = cross_validate(SVM, X_train_res, y_train_res, scoring=scoring, cv=20)\n\nsorted(scores.keys())\nSVM_fit_time = scores['fit_time'].mean()\nSVM_score_time = scores['score_time'].mean()\nSVM_accuracy = scores['test_accuracy'].mean()\nSVM_precision = scores['test_precision_macro'].mean()\nSVM_recall = scores['test_recall_macro'].mean()\nSVM_f1 = scores['test_f1_weighted'].mean()\nSVM_roc = scores['test_roc_auc'].mean()","018b073e":"LDA = LinearDiscriminantAnalysis()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\n\nscores = cross_validate(LDA, X_train_res, y_train_res, scoring=scoring, cv=20)\n\nsorted(scores.keys())\nLDA_fit_time = scores['fit_time'].mean()\nLDA_score_time = scores['score_time'].mean()\nLDA_accuracy = scores['test_accuracy'].mean()\nLDA_precision = scores['test_precision_macro'].mean()\nLDA_recall = scores['test_recall_macro'].mean()\nLDA_f1 = scores['test_f1_weighted'].mean()\nLDA_roc = scores['test_roc_auc'].mean()","c0016400":"QDA = QuadraticDiscriminantAnalysis()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\nscores = cross_validate(QDA, X_train_res, y_train_res, scoring=scoring, cv=20)\n\nsorted(scores.keys())\nQDA_fit_time = scores['fit_time'].mean()\nQDA_score_time = scores['score_time'].mean()\nQDA_accuracy = scores['test_accuracy'].mean()\nQDA_precision = scores['test_precision_macro'].mean()\nQDA_recall = scores['test_recall_macro'].mean()\nQDA_f1 = scores['test_f1_weighted'].mean()\nQDA_roc = scores['test_roc_auc'].mean()","5f5f6dfc":"random_forest = RandomForestClassifier(random_state=30)\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\nscores = cross_validate(random_forest, X_train_res, y_train_res, scoring=scoring, cv=20)\n\nsorted(scores.keys())\nforest_fit_time = scores['fit_time'].mean()\nforest_score_time = scores['score_time'].mean()\nforest_accuracy = scores['test_accuracy'].mean()\nforest_precision = scores['test_precision_macro'].mean()\nforest_recall = scores['test_recall_macro'].mean()\nforest_f1 = scores['test_f1_weighted'].mean()\nforest_roc = scores['test_roc_auc'].mean()","4c357fe1":"KNN = KNeighborsClassifier()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\nscores = cross_validate(KNN, X_train_res, y_train_res, scoring=scoring, cv=20)\n\nsorted(scores.keys())\nKNN_fit_time = scores['fit_time'].mean()\nKNN_score_time = scores['score_time'].mean()\nKNN_accuracy = scores['test_accuracy'].mean()\nKNN_precision = scores['test_precision_macro'].mean()\nKNN_recall = scores['test_recall_macro'].mean()\nKNN_f1 = scores['test_f1_weighted'].mean()\nKNN_roc = scores['test_roc_auc'].mean()","a5b0088b":"bayes = GaussianNB()\n\nscoring = ['accuracy', 'precision_macro', 'recall_macro' , 'f1_weighted', 'roc_auc']\nscores = cross_validate(bayes, X_train_res, y_train_res, scoring=scoring, cv=20)\n\nsorted(scores.keys())\nbayes_fit_time = scores['fit_time'].mean()\nbayes_score_time = scores['score_time'].mean()\nbayes_accuracy = scores['test_accuracy'].mean()\nbayes_precision = scores['test_precision_macro'].mean()\nbayes_recall = scores['test_recall_macro'].mean()\nbayes_f1 = scores['test_f1_weighted'].mean()\nbayes_roc = scores['test_roc_auc'].mean()","426c834b":"models_initial = pd.DataFrame({\n    'Models'       : ['Logistic Regression', 'Decision Tree', 'Support Vector Machine', 'Linear Discriminant Analysis', 'Quadratic Discriminant Analysis', 'Random Forest', 'K-Nearest Neighbors', 'Bayes'],\n    'Fitting time': [LR_fit_time, dtree_fit_time, SVM_fit_time, LDA_fit_time, QDA_fit_time, forest_fit_time, KNN_fit_time, bayes_fit_time],\n    'Scoring time': [LR_score_time, dtree_score_time, SVM_score_time, LDA_score_time, QDA_score_time, forest_score_time, KNN_score_time, bayes_score_time],\n    'Accuracy'    : [LR_accuracy, dtree_accuracy, SVM_accuracy, LDA_accuracy, QDA_accuracy, forest_accuracy, KNN_accuracy, bayes_accuracy],\n    'Precision'   : [LR_precision, dtree_precision, SVM_precision, LDA_precision, QDA_precision, forest_precision, KNN_precision, bayes_precision],\n    'Recall'      : [LR_recall, dtree_recall, SVM_recall, LDA_recall, QDA_recall, forest_recall, KNN_recall, bayes_recall],\n    'F1_score'    : [LR_f1, dtree_f1, SVM_f1, LDA_f1, QDA_f1, forest_f1, KNN_f1, bayes_f1],\n    'AUC_ROC'     : [LR_roc, dtree_roc, SVM_roc, LDA_roc, QDA_roc, forest_roc, KNN_roc, bayes_roc],\n    }, columns = ['Models', 'Fitting time', 'Scoring time', 'Accuracy', 'Precision', 'Recall', 'F1_score', 'AUC_ROC'])","7240eb5d":"models_initial.sort_values(by='Accuracy', ascending=False, ignore_index=True)","d0eac712":"models_initial.sort_values(by='F1_score', ascending=False, ignore_index=True)","586a27f8":"models_initial.sort_values(by='Precision', ascending=False, ignore_index=True)","79559f87":"models_initial.sort_values(by='Recall', ascending=False, ignore_index=True)","6e38bbf4":"models_initial.sort_values(by='AUC_ROC', ascending=False, ignore_index=True)","99d03511":"# Seperate into two data frame (performance_metric and AUC_ROC_performance) \nmodels_initial.index = models_initial['Models']\nperformance_metric = models_initial\nAUC_ROC_performance = models_initial['AUC_ROC']\nperformance_metric = performance_metric.drop(columns = 'AUC_ROC')\n\n# Bar plot the performance_metric\nax1 = performance_metric.plot.bar()\nplt.legend(loc=\"upper center\", bbox_to_anchor=(1.3, 0.75), ncol=2)\n\n# Line plot the AUC_ROC_performance in the same figure\nax2 = ax1.twiny()\nax2 = AUC_ROC_performance.plot.line(figsize=(40,40),color='purple')\nplt.xticks([])\nplt.xlabel('')\n\n# Adjustment of the plotting\nplt.xticks(rotation=90)\nplt.legend(loc=\"upper center\", bbox_to_anchor=(1.3, 0.60), ncol=2)\nplt.ylabel(\"Scoring\")\nplt.title(\"Model Performances\", fontdict = {\"fontsize\": 20} )\nplt.show()","e178163b":"from sklearn.model_selection import GridSearchCV","9a092bd0":"from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n\ndef print_score(clf, X_train_res, y_train_res, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train_res)\n        clf_report = pd.DataFrame(classification_report(y_train_res, pred, output_dict=True))\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train_res, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train_res, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        clf_report = pd.DataFrame(classification_report(y_test, pred, output_dict=True))\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"CLASSIFICATION REPORT:\\n{clf_report}\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_test, pred)}\\n\")","10ea1617":"%%time\n\nsvm_clf = SVC(kernel='rbf', gamma=0.1, C=1.0, random_state=30)\n\nparams = {\"C\":(0.1, 0.5, 1, 2, 3, 5, 10, 20), \n          \"gamma\":(0.001, 0.02, 0.01, 0.1, 0.2, 0.25, 0.5, 0.75, 1), \n          \"kernel\":('linear', 'poly', 'rbf')}\n\nsvm_cv = GridSearchCV(svm_clf, params, n_jobs=-1, cv=4, verbose=1, scoring=\"accuracy\")\nsvm_cv.fit(X_train_res, y_train_res)\nbest_params = svm_cv.best_params_\nprint(f\"Best params: {best_params}\")\n\nsvm_clf = SVC(**best_params, random_state=30)\nsvm_clf.fit(X_train_res, y_train_res)\n\nprint_score(svm_clf, X_train_res, y_train_res, X_test, y_test, train=True)\nprint_score(svm_clf, X_train_res, y_train_res, X_test, y_test, train=False)","54ef4ff4":"%%time\n# n_estimators = [1200, 1400, 1600, 2000]\n\nn_estimators = [2000, 2200, 2300]\nmax_features = [2, 3]\nmax_depth = [40,50,60,70]\nmin_samples_split = [9, 10, 11]\nmin_samples_leaf = [1,2]\n\nparams_grid = {\n    'n_estimators': n_estimators, \n    'max_features': max_features,\n    'max_depth': max_depth, \n    'min_samples_split': min_samples_split,\n    'min_samples_leaf': min_samples_leaf,\n              }\n\nrf_clf = RandomForestClassifier(random_state=30)\nrf_cv = GridSearchCV(rf_clf, params_grid, scoring=\"accuracy\", cv=3, verbose=2, n_jobs=-1)\nrf_cv.fit(X_train_res, y_train_res)\nbest_params = rf_cv.best_params_\nprint(f\"Best parameters: {best_params}\")\n\nrf_clf = RandomForestClassifier(**best_params, random_state=30)\nrf_clf.fit(X_train_res, y_train_res)\n\nprint_score(rf_clf, X_train_res, y_train_res, X_test, y_test, train=True)\nprint_score(rf_clf, X_train_res, y_train_res, X_test, y_test, train=False)","a0787d8c":"#Saving final model : Support Vector Machine (SVM)\nimport joblib\nfilename = 'finalized_model.sav'\njoblib.dump(svm_clf, filename)","5bc62248":"<a name=\"Features_Selection\">\n\n# 5) Features Selection \n---\n","78b29190":"Since undersampling may discard the useful information which could be important for building good classifiers. I went with the Oversampling method with SMOTE.\nUndersampling gets you less data, and most classifiers' performance suffers with less data.\n\n### Why is this important ?\nWith a greater imbalanced ratio, the decision function favor the class with the larger number of samples, usually referred as the majority class. Roughly speaking, weight of class begins depending on count samples. Also, we can't use some metrics, like **accuracy**, if we have disproportion of samples. **The objective here is to try to get the best accuracy on a reliable model.**\n\n\n### Important note :\nI first used SMOTE and then split the data into train test split. The results were enthusiastic, the confusion matrix and classification report were pleasing. As I understood the problem with this approach is that the new synthetically created observations from the minority class in the training dataset might end up in the testing dataset. This in a way allows the algorithm to \"cheat\" since it learned from something similar and now is testing on almost very similar data points.\n\n\nWhen the model is in production, it\u2019s predicting on unseen data. The main point of model validation is to estimate how the model will generalize to new data. If the decision to put a model into production is based on how it performs on a validation set, it\u2019s critical that oversampling is done correctly.\n\n***To summarize:*** When you use any sampling technique you divide your data first and then apply synthetic sampling on the training data only. After you do the training, you use the test set which contains only original samples to evaluate.\n","2d91bcfa":"## 8.2 Random Forest","e7a977a9":"## 6.2 SMOTE - Oversampling \nSMOTE is an intelligent alternative to oversampling: rather than creating duplicates of the minority class, it creates synthetic data points that are relatively similar to the original ones.\nUsing SMOTE, the model start detected more cases of the minority class, which will result in an increased recall, but a decreased precision. ","ab8f66c3":"<a name=\"Handling_Imbalanced_Data\">\n\n# 6) Handling Imbalanced Data \n---","35c530b8":"## 2.2 Target Encoding","897682ae":"## 4.2 Bivariate Analysis\nIdentify Dependency","6cf508a1":"We have a lot of 0 values in the columns","8a19e56c":"First glance at the dataset","23832dc8":"## 4.3 Correlation Analysis\nIdentify collinearity","7d30751b":"<a name=\"Testing_Models\">\n\n# 8) Testing Models\n---","265401ce":"<a name=\"Final_Model_&_Conclusion\">\n\n# 9) Final Model & Conclusion\n---","5f286091":"<a name=\"Data_Preprocessing\">\n\n# 2) Data Preprocessing\n---","c978dc93":"<a name=\"EDA\">\n\n# 4) Exploratory Data Analysis (EDA)\n---","d5b1c9f2":"Let's try this initially without any method and let's see if this changes anything","beb2321f":"## 3.3 Multicollinearity\n\nMulticollinearity refers to a situation in which more than two explanatory variables in a multiple regression model are highly linearly related.\nThere's a known problem with variable\n\nIn the next step multicolinearity is checked. This becomes a problem when running Regression models. Thus, highly cocorrelated features (|r| > 0.90) will be dropped. When deciding which of two correlated features to keep, the one with the higher correlation to the traget and therefore higher prediction value will be keept.","36227ff0":"In this process, we modified the hyperparameter of each models to see how it performed by using GridSearchCV()\n\nI am satisfied by the overall result of the Support Vector Machine (SVM) model with an accuracy of **89.24%**\n\n### Note :\nWe need to check the accuracy difference between train and test set for each fold result. If my model gives me high training accuracy but low test accuracy my model is overfitting. On the other hand, if it does not give good training accuracy, my model is underfitting.","ac4ef8c7":"## 8.1 Support Vector Machine","45e2b080":"<a name=\"Abstract\">\n\n## Abstract\n---","4d7acfa5":"## 7.1 Model Selection - Comparison\nModel selection is the process of selecting one final machine learning model from among a collection of candidate machine learning models for a training dataset.\nHere we will be using, Cross-validation for evaluating estimator performance. We will also be using the metric **AUC_ROC**, it is one of the most important evaluation metrics for checking any classification model\u2019s performance.","203b3c98":"DATASET LINK : https:\/\/archive.ics.uci.edu\/ml\/datasets\/QSAR+biodegradation","4d49c533":"## 3.2 Standardizing","ad99fa39":"The Goal of this project is to **train a reliable model to determine if a substance is biodegradable or not** by using the QSAR biodegradation Data Set provided by UCI.\n\nHere we are dealing with a **classification problem.** We are trying to predict a discrete value output: ***Degradable*** and ***Not-Degradable.***\n\nThe challenge here personnally is that I don't have a chemical engineering background. This project was definitely intriguing for me.","b2dc7e78":"## 3.1 Removing Outliers\nIf we remove outliers after standardizing, the resulting data won't be standardized anymore (if many outliers are removed, standard deviation could become considerably smaller than 1)","c47dcef0":"<a name=\"Data_Collection\">\n\n# 1) Data Collection\n---","ad044d2f":"## 4.1 Univariate Analysis\nIdentify Data distribution","ef98e9d4":"<a name=\"Data_Processing\">\n\n# 3) Data Processing\n---","9d049bdc":"## 6.3 NearMiss Algorithm \u2013 Undersampling","31c0f5f8":"The following variables have been dropped","9ee5d9bb":"# Python Project - QSAR \ud83d\udd2c\n\n---\n\n## Nader Narcisse","492488cd":"### *Table of Contents*\n  - [Abstract](#Abstract)\n  - [1) Data Collection](#Data_Collection)\n  - [2) Data Preprocessing](#Data_Preprocessing)\n     - 2.1 Missing Data\n     - 2.2 Target Enconding\n  - [3) Data Processing](#Data_Processing) \n    - 3.1 Removing Outliers\n    - 3.2 Standardizing\n    - 3.3 Multicollinearity\n  - [4) Exploratory Data Analysis (EDA)](#EDA)\n    - 4.1 Univariate Analysis\n    - 4.2 Bivariate Analysis\n    - 4.3 Corellation Analysis\n  - [5) Features Selection](#Features_Selection)\n    - 5.1 Features Selection (SelectKBest)\n  - [6) Handling Imbalanced Data](#Handling_Imbalanced_Data)\n    - 6.1 Testing with imbalanced Data\n    - 6.2 SMOTE - Oversampling\n    - 6.3 NearMiss Algorithm \u2013 Undersampling\n    - 6.4 Choosing the Oversampling method (SMOTE)\n  - [7) Modeling](#Modeling)\n    - 7.1 Model Selection - Comparison\n  - [8) Testing Models](#Testing_Models)\n    - 8.1 Support Vector Machine\n    - 8.2  Random Forest\n  - [9) Final Model & Conclusion](#Final_Model_&_Conclusion)\n    - 9.1 Saving final model using Joblib\n    - 9.2 Conclusion","416157bc":"## 6.1 Testing with imbalanced Data","b4aa0048":"In this project, our objective was to make sure we have a reliable model that can be used in order to determine if a substance is biodegradable or not.\n\nI conclude that the best type of model for this problem is a Support Vector Machine (SVM) model with an accuracy of **89.24%** ","516bdac1":"Fortunately, there is no missing data we can proceed with the next step","7df8dd26":"As seen before, we can see almost 2\/3 of them are non-ready degradable while the rest of 1\/3 of them are ready degradable.\n\nThere is an significant class imbalance. Class imbalance will lead to a bias towards the majority class. In this case we will perform an **oversampling** or **undersampling** method to equalise the data and choose one of them.","2116a944":"<a name=\"Modeling\">\n\n# 7) Modeling\n---","2d27c285":"As we can see in overall performance, the **Random Forest** and **Support Vector Machine** models are the best ones in this selection process, in the next step we will be using them for testing.\n\n### Note :\nWe are not necessarly looking for the best fit time but we see that the 2 best models in terms of performance are the ones with a bigger fit time.","b053258b":"## 6.4 Choosing the Oversampling method (SMOTE)","008c10c0":"We can see that there are total 41 features and 1 target class named 'experimental_class' in this dataset. Also, there are 1055 instances.","20383924":"Importing standard modules.","d0410ad4":"If there is no correlation between two variables, it means that the variables do not appear to be statistically related, that the value of one variable doesn\u2019t increase or decrease in association with the increase or decrease of the other variable. Here we see that **nN-N** and **nCRX3** are two variables not correlated with the other variables for the **Degradable** class.","e56997eb":"## 5.1 Features Selection (SelectKBest)","0c38b218":"## 9.2 Conclusion","e10e9873":"## 2.1 Missing values","e16e04cc":"Since it is a classification problem, **Ready Degradability** will be encoded as 1, wheres as **Non-Ready Degradability** will be decoded as 0","dee36c79":"## 9.1 Saving final model using Joblib"}}