{"cell_type":{"b078f86d":"code","b079a184":"code","6aa7e8d2":"code","c4da4fa1":"code","14203084":"code","9a78903d":"code","17ea3109":"code","fdad14fe":"code","7fdb2667":"code","5605d4f9":"code","3d85a6dc":"code","06f65b8e":"code","ce185960":"code","02a1f1fb":"code","faa88ff0":"code","665e6b48":"code","7e21c62b":"code","2a8b37c6":"code","612507b2":"code","3027d460":"code","5bcbdd22":"code","1c226ec6":"code","febd4f86":"code","de69fae6":"code","774c7b57":"code","0bb41364":"code","ba57c7a9":"code","c9180001":"code","eac6a946":"code","b0b001f3":"code","b2ae3577":"code","9ea482dd":"code","008123b0":"code","e7425fa7":"code","35fb5d8a":"code","737709c0":"code","c6b1bd42":"code","f6b4bfd9":"code","77b79026":"code","62d949dc":"code","dba65b15":"code","f8e07626":"code","e40d1ece":"code","0af30bcd":"code","9fe30280":"code","983d4009":"code","76589932":"code","6c8afe62":"code","c1d6c16e":"markdown","40264e34":"markdown","d43f6332":"markdown","e3bdcb5d":"markdown","85e1752a":"markdown","41b3af71":"markdown","1fe0d2f8":"markdown","68b4975e":"markdown","585b0599":"markdown","94784e9f":"markdown","ac01b5b7":"markdown","1e96eed4":"markdown","264ff9ab":"markdown","397491a7":"markdown"},"source":{"b078f86d":"#importing necessary libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom mpl_toolkits.mplot3d import axes3d\nfrom sklearn.decomposition import PCA\nfrom sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\nfrom sklearn.metrics import accuracy_score, confusion_matrix, classification_report, roc_curve, roc_auc_score\n\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","b079a184":"#importing data and getting shape\ndf = pd.read_csv(\"..\/input\/breast-cancer-detection\/data.csv\")\ndf.shape","6aa7e8d2":"df.head()\n# we can see here that last column is having NaN values so we have to resolve it","c4da4fa1":"# finding missing values\ndf.isnull().sum()\n# we noticed here that in 'unnamed: 32' feature we have zero non-null data so its useless for our problem","14203084":"# dropping irrelevant features \ndf.drop(['id', 'Unnamed: 32'], axis = 1, inplace = True)","9a78903d":"# here we get some more insight about our data set\ndf.describe()","17ea3109":"#checking Malignant (M) and Benign (B) class observations in dataset\ndf['diagnosis'].value_counts()","fdad14fe":"# visualizing the same using bar graphs\ndf.diagnosis.value_counts().plot(kind = \"bar\")\nplt.title(\"People Diagnosed Benign and Malignant\")","7fdb2667":"# Visualizing corelation between features which will help in further process using heatmap\ndf['diagnosis'] = df['diagnosis'].map({'M': 1, 'B':0})\ncorr = df.corr()\ncmap = sns.diverging_palette(220, 10, as_cmap = True)\n\nf, ax = plt.subplots(figsize = (21, 19))\nsns.heatmap(corr, cmap = cmap, center = 0, annot = True, square = True, linewidths = .5, cbar_kws = {\"shrink\": .5})","5605d4f9":"sns.pairplot(df, hue = 'diagnosis')","3d85a6dc":"# splitting the data\nX = df.iloc[:, 1:]\ny = df.iloc[:, 0]\n\n# encoding the diagnosis column\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ny = le.fit_transform(y) # 1 = M, 0 = B\n\n# splitting data into test and train sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, random_state = 42)","06f65b8e":"from sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)","ce185960":"pca = PCA() #This graph gives us the distribution of maxmium information at each component\npca.fit_transform(X_train) \npca_var = pca.explained_variance_\nplt.figure(figsize = (8, 6))\nplt.bar(range(30), pca_var, alpha = 0.5, align = 'center', label = 'Variance retrieved by component')\nplt.legend()\nplt.ylabel('Variance ratio')\nplt.xlabel('Principal components')\nplt.show() ","02a1f1fb":"pca = PCA(n_components = 10) #This is used to decompose or reduce the dimension into the specified dimensions given in the components\npca.fit(X_train)\nX_train_pca = pca.transform(X_train) \npca.explained_variance_ratio_ ","faa88ff0":"np.sum(pca.explained_variance_ratio_)*100 #The percentage of the values imply that the 10 components retrieves close to 95% percent of the information from the original dataset that had 30 features","665e6b48":"X_train.shape # Before Pca","7e21c62b":"X_train_pca.shape #After Pca As you see the features have been readuced from 30 to 10","2a8b37c6":"X1 = pd.DataFrame(data = X_train_pca, columns = [\"PC1\",\"PC2\",\"PC3\",\"PC4\",\"PC5\",\"PC6\",\"PC7\",\"PC8\",\"PC9\",\"PC10\"])\nX1.head()","612507b2":"plt.figure(figsize = (7, 7))\nsns.heatmap(X1.corr(), annot= True, fmt = '.1f')\nplt.show() #Thus the extracted faetures show zero correlation with each other","3027d460":"y1 = pd.DataFrame(y_train, columns = [\"diagnosis\"])\ny1.head()\nprint(y1.shape)","5bcbdd22":"X1[\"common\"] = range(398)\ny1[\"common\"] = range(398)\ndataset = pd.merge(X1, y1, on = [\"common\"])\ndataset = dataset.drop('common', axis=1)\ndataset.shape","1c226ec6":"sns.pairplot(dataset,hue='diagnosis')","febd4f86":"#%matplotlib notebook\nfig = plt.figure()\nax = fig.add_subplot(111, projection = '3d')\n\nfor x in dataset.diagnosis.unique():\n    ax.scatter(dataset.PC1[dataset.diagnosis==x], dataset.PC2[dataset.diagnosis==x], dataset.PC3[dataset.diagnosis==x], label=x)\n    \nax.set_xlabel(\"PC1\")\nax.set_ylabel(\"PC2\")\nax.set_zlabel(\"PC3\")\n\nfor angle in range(0, 360):\n    ax.view_init(30, angle)\n    plt.draw()\n    plt.pause(.001)\n    \nplt.show()","de69fae6":"# standard scaling test data\nX_test = scaler.transform(X_test) \n# transforming test data with pca from above obtained parameters\nX_test_pca = pca.transform(X_test)","774c7b57":"from sklearn.linear_model import LogisticRegression\nlogreg = LogisticRegression()\n\nlogreg.fit(X_train_pca, y_train)\n\nyl_pred = logreg.predict(X_test_pca)\n\nprint('Confusion Matrix:\\n', confusion_matrix(y_test, yl_pred))\nprint(\"Accuracy score:\", accuracy_score(y_test, yl_pred))\nprint('Classification Report:\\n', classification_report(y_test, yl_pred))","0bb41364":"param_grid=[{'penalty':['l2',],\n            'C':[0.01,0.1,1,10,100],\n            'solver':['liblinear','sag','newton-cg','lbfgs'],\n            'max_iter':[100,1000,2500,5000]}]\n\nfrom sklearn.model_selection import GridSearchCV\ngrid = GridSearchCV(logreg,param_grid=param_grid,cv=10,scoring='accuracy',verbose=True)\ngrid.fit(X_train_pca,y_train)","ba57c7a9":"print(grid.best_params_)","c9180001":"logreg = LogisticRegression(C=0.1, max_iter=100, penalty='l2', solver='liblinear' )\n\nlogreg.fit(X_train_pca, y_train)\n\nyl_pred = logreg.predict(X_test_pca)\n\nprint('Confusion Matrix:\\n', confusion_matrix(y_test, yl_pred))\nprint(\"Accuracy score:\", accuracy_score(y_test, yl_pred))\nprint('Classification Report:\\n', classification_report(y_test, yl_pred))","eac6a946":"from sklearn.model_selection import learning_curve\ntrain_sizes, train_scores, test_scores = learning_curve(logreg, X_train_pca, y_train, cv=10, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.01, 1.0, 50))\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nplt.subplots(1, figsize=(10,10))\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","b0b001f3":"# Stratified KFold\n\nX1 = pd.DataFrame(X)\ny1 = pd.DataFrame(y)\n\naccuracyl = []\n\nskf = StratifiedKFold(n_splits = 10, random_state = None)\nskf.get_n_splits(X1, y1)\nfor train_index, test_index in skf.split(X1, y1):\n    X1_train, X1_test = X1.iloc[train_index], X1.iloc[test_index]\n    y1_train, y1_test = y1.iloc[train_index], y1.iloc[test_index]\n    \n    # applying PCA\n    scaler.fit(X1_train)\n    X1_train = scaler.transform(X1_train)\n    pca = PCA(n_components = 10)\n    pca.fit(X1_train)\n    X1_train = pca.transform(X1_train)\n\n    X1_test = scaler.transform(X1_test)\n    X1_test = pca.transform(X1_test)\n\n    logreg.fit(X1_train, y1_train)\n    yl_pred = logreg.predict(X1_test)\n    accuracyl.append(accuracy_score(yl_pred, y1_test))\n    \n    \nprint(np.array(accuracyl).mean())","b2ae3577":"from sklearn import svm\nsclf = svm.SVC()\nsclf.fit(X_train_pca, y_train)\n\nys_pred = sclf.predict(X_test_pca)\n\nprint('Confusion Matrix:\\n', confusion_matrix(y_test, ys_pred))\nprint(\"Accuracy score:\", accuracy_score(y_test, ys_pred))\nprint('Classification Report:\\n', classification_report(y_test, ys_pred))","9ea482dd":"param_grid=[{'C': [0.1, 1, 10, 100, 1000],  \n              'gamma': [1, 0.1, 0.01, 0.001, 0.0001], \n              'kernel': ['rbf','linear','poly'],\n            }]\n\ngrid=GridSearchCV(sclf,param_grid=param_grid,cv=10,scoring='accuracy',verbose=True)\ngrid.fit(X_train_pca,y_train)","008123b0":"print(grid.best_params_)","e7425fa7":"sclf = svm.SVC(C=1000, gamma= 0.0001, kernel='rbf', probability = True)\nsclf.fit(X_train_pca, y_train)\n\nys_pred = sclf.predict(X_test_pca)\n\nprint('Confusion Matrix:\\n', confusion_matrix(y_test, ys_pred))\nprint(\"Accuracy score:\", accuracy_score(y_test, ys_pred))\nprint('Classification Report:\\n', classification_report(y_test, ys_pred))","35fb5d8a":"from sklearn.model_selection import learning_curve\ntrain_sizes, train_scores, test_scores = learning_curve(sclf, X_train_pca, y_train, cv=10, scoring='accuracy', n_jobs=-1, train_sizes = np.linspace(0.01, 1.0, 50))\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nplt.subplots(1, figsize=(10,10))\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","737709c0":"# Stratified KFold\naccuracys = []\n\nskf = StratifiedKFold(n_splits = 10, random_state = None)\nskf.get_n_splits(X1, y1)\nfor train_index, test_index in skf.split(X1, y1):\n    X1_train, X1_test = X1.iloc[train_index], X1.iloc[test_index]\n    y1_train, y1_test = y1.iloc[train_index], y1.iloc[test_index]\n\n    # applying PCA\n    scaler.fit(X1_train)\n    X1_train = scaler.transform(X1_train)\n    pca = PCA(n_components = 10)\n    pca.fit(X1_train)\n    X1_train = pca.transform(X1_train)\n\n    X1_test = scaler.transform(X1_test)\n    X1_test = pca.transform(X1_test)\n    \n    sclf.fit(X1_train, y1_train)\n    ys_pred = sclf.predict(X1_test)\n    accuracys.append(accuracy_score(ys_pred, y1_test))\n    \n    \nprint(np.array(accuracys).mean())","c6b1bd42":"from sklearn.naive_bayes import BernoulliNB\nBernNb = BernoulliNB()\nBernNb.fit(X_train_pca, y_train)\n\nyn_pred = BernNb.predict(X_test_pca)\n\nprint('Confusion Matrix:\\n', confusion_matrix(y_test, yn_pred))\nprint(\"Accuracy score:\", accuracy_score(y_test, yn_pred))\nprint('Classification Report:\\n', classification_report(y_test, yn_pred))","f6b4bfd9":"param_grid = [{'binarize':[0.0,0.001,0.01,0.1,1,10,100], \n               'alpha': [0.0, 0.0001, 0.001, 0.01, 0.1, 0.5, 1.0, 2.0, 10.0], \n               'fit_prior' : [True, False],\n               'class_prior': [None, [.1,.9],[.2, .8]]\n             }]\n\ngrid = GridSearchCV(BernNb,param_grid=param_grid,cv=10,scoring='accuracy',verbose=True)\ngrid.fit(X_train_pca,y_train)","77b79026":"print(grid.best_params_)","62d949dc":"BernNb=BernoulliNB(alpha=10,binarize=0.0,fit_prior=True)\nBernNb.fit(X_train_pca, y_train)\n\nyn_pred = BernNb.predict(X_test_pca)\n\nprint('Confusion Matrix:\\n', confusion_matrix(y_test, yn_pred))\nprint(\"Accuracy score:\", accuracy_score(y_test, yn_pred))\nprint('Classification Report:\\n', classification_report(y_test, yn_pred))","dba65b15":"from sklearn.model_selection import learning_curve\ntrain_sizes, train_scores, test_scores = learning_curve(BernNb, X_train_pca, y_train, cv=10, scoring='accuracy', n_jobs=-1, train_sizes=np.linspace(0.01, 1.0, 50))\ntrain_mean = np.mean(train_scores, axis=1)\ntrain_std = np.std(train_scores, axis=1)\n\ntest_mean = np.mean(test_scores, axis=1)\ntest_std = np.std(test_scores, axis=1)\nplt.subplots(1, figsize=(10,10))\nplt.plot(train_sizes, train_mean, '--', color=\"#111111\",  label=\"Training score\")\nplt.plot(train_sizes, test_mean, color=\"#111111\", label=\"Cross-validation score\")\n\nplt.fill_between(train_sizes, train_mean - train_std, train_mean + train_std, color=\"#DDDDDD\")\nplt.fill_between(train_sizes, test_mean - test_std, test_mean + test_std, color=\"#DDDDDD\")\n\nplt.title(\"Learning Curve\")\nplt.xlabel(\"Training Set Size\"), plt.ylabel(\"Accuracy Score\"), plt.legend(loc=\"best\")\nplt.tight_layout()\nplt.show()","f8e07626":"# Stratified KFold\naccuracyn = []\n\nskf = StratifiedKFold(n_splits = 10, random_state = None)\nskf.get_n_splits(X1, y1)\nfor train_index, test_index in skf.split(X1, y1):\n    X1_train, X1_test = X1.iloc[train_index], X1.iloc[test_index]\n    y1_train, y1_test = y1.iloc[train_index], y1.iloc[test_index]\n    \n    # applying PCA\n    scaler.fit(X1_train)\n    X1_train = scaler.transform(X1_train)\n    pca = PCA(n_components = 10)\n    pca.fit(X1_train)\n    X1_train = pca.transform(X1_train)\n\n    X1_test = scaler.transform(X1_test)\n    X1_test = pca.transform(X1_test)\n\n    BernNb.fit(X1_train, y1_train)\n    yn_pred = BernNb.predict(X1_test)\n    accuracyn.append(accuracy_score(yn_pred, y1_test))\n    \n    \nprint(np.array(accuracyn).mean())","e40d1ece":"df = pd.DataFrame({'Logistic Regression': accuracyl,\n                   'SVM': accuracys,\n                   'Naive Bayes': accuracyn\n                    })\ndf","0af30bcd":"plt.figure()\nplt.boxplot([df['Logistic Regression'], df['SVM'], df['Naive Bayes']]);\nplt.xticks([1, 2, 3], ['Logistic Regression', 'SVM', 'Naive Bayes'])\nplt.xlabel('Classifier');\nplt.ylabel('Mean Accuracy score')\nplt.title('Comparing 10 fold CV accuracies of classifiers')","9fe30280":"# calculation of probabilities\nlr_probs = logreg.predict_proba(X_test_pca)\nsvc_probs = sclf.predict_proba(X_test_pca)\nnb_probs = BernNb.predict_proba(X_test_pca)\n\n# Keeping only True Positive and False Positive \nlr_probs = lr_probs[:, 1]\nsvc_probs = svc_probs[:, 1]\nnb_probs = nb_probs[:, 1]\n\n# calculating roc auc score to evaluate each ones performance\nlr_auc = roc_auc_score(y_test, lr_probs)\nsvc_auc = roc_auc_score(y_test, svc_probs)\nnb_auc = roc_auc_score(y_test, nb_probs)","983d4009":"print(\"Logistic Regression: \", lr_auc)\nprint(\"SVM: \", svc_auc)\nprint(\"Naive Bayes: \", nb_auc)\n# so from below we see that auc roc score of Logistic Regresion is highest","76589932":"# Calculating True Positive Rate and False Positive Rate for Each Models\nlr_fpr, lr_tpr, thr_l = roc_curve(y_test, lr_probs)\nsvc_fpr, svc_tpr, thr_s = roc_curve(y_test, svc_probs)\nnb_fpr, nb_tpr, thr_n = roc_curve(y_test, nb_probs)","6c8afe62":"# Plotting ROC Curve\nplt.figure(figsize = (10, 10))\n\nplt.plot(lr_fpr, lr_tpr, marker = \".\", label = 'Logistic Regression', color = 'green')\nplt.plot(svc_fpr, svc_tpr, marker = \".\", label = 'SVM', color = 'blue')\nplt.plot(nb_fpr, nb_tpr, marker = \".\", label = 'Naive Bayes', color = 'red')\n\nplt.title('ROC Plot')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.legend()\nplt.show()","c1d6c16e":"# Box Plot of Accuracies achieved from 10 Fold Stratified K Fold","40264e34":"### After Hyperparameter Tuning","d43f6332":"### After Hyperparameter Tuning","e3bdcb5d":"### Hyperparameter Tuning","85e1752a":"### After Hyperparameter Tuning","41b3af71":"### Hyperparameter Tuning","1fe0d2f8":"## Logistic Regression","68b4975e":"Above 3D visualization shows that derived principal components have separability in target class.","585b0599":"### Hyperparameter Tuning","94784e9f":"## SVM ","ac01b5b7":"# Training and Validating Models","1e96eed4":"# Dimensionality Reduction using PCA","264ff9ab":"# Evaluation of Models using ROC","397491a7":"## Naive Bayes "}}