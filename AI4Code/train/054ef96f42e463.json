{"cell_type":{"c184b912":"code","4bf04b2d":"code","fdac6993":"code","bcf8e4f8":"code","cae96b76":"code","f91b9bc0":"code","66b5e60c":"code","81919c05":"code","66ad2dfc":"code","23d37e18":"code","ec2af077":"code","db464ffc":"code","6aa65754":"code","a59928f9":"code","3d37fe4f":"code","7ab4d85d":"code","d3239b4a":"code","9973f865":"code","c50fc738":"code","5202669b":"code","feb15368":"code","29affc72":"markdown","3045774d":"markdown","b0e1e3f3":"markdown","0aa626a4":"markdown","451f6fe5":"markdown","b0e51404":"markdown","266a3a33":"markdown","2d0f0896":"markdown","4ff5ef7d":"markdown","55b43923":"markdown","de7aafe1":"markdown","5ec89676":"markdown","306f04b1":"markdown","5db45c5f":"markdown","44a45dab":"markdown","86b99629":"markdown","5cf90aab":"markdown","609fd944":"markdown","f2fc295d":"markdown","325fc0fd":"markdown","dde90ea8":"markdown","77c98cad":"markdown","b44faa67":"markdown","0214c752":"markdown","55a5ba57":"markdown","b29927cd":"markdown","87c9394c":"markdown","38cb6537":"markdown"},"source":{"c184b912":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","4bf04b2d":"# Load libraries\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom wordcloud import WordCloud, STOPWORDS, ImageColorGenerator\nimport re","fdac6993":"# Load the datasets\nbio = pd.read_csv(\"\/kaggle\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/biorxiv_clean.csv\")\nnoncomm = pd.read_csv(\"\/kaggle\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/clean_noncomm_use.csv\")\ncomm = pd.read_csv(\"\/kaggle\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/clean_comm_use.csv\")\npmc = pd.read_csv(\"\/kaggle\/input\/cord-19-eda-parse-json-and-generate-clean-csv\/clean_pmc.csv\")","bcf8e4f8":"# Missing Value Visualization\n\nfig, axes = plt.subplots(2 ,2, figsize=(30,15))\n\ntitle = \"Biorxiv\"\nax = sns.heatmap(bio.isnull(), cmap=\"Reds\", cbar=False, ax=axes[0,0])\nax.vlines([1,2,3,4,5,6,7,8,9], *ax.get_ylim(), color=\"black\")\naxes[0,0].set_title(title, fontsize=15)\n\ntitle = \"Non-commercial Use\"\nax = sns.heatmap(noncomm.isnull(), cmap=\"Reds\", cbar=False, ax=axes[0,1])\nax.vlines([1,2,3,4,5,6,7,8,9], *ax.get_ylim(), color=\"black\")\naxes[0,1].set_title(title, fontsize=15)\n\ntitle = \"Commercial Use\"\nax = sns.heatmap(comm.isnull(), cmap=\"Reds\", cbar=False, ax=axes[1,0])\nax.vlines([1,2,3,4,5,6,7,8,9], *ax.get_ylim(), color=\"black\")\naxes[1,0].set_title(title, fontsize=15)\n\ntitle = \"PMC\"\nax = sns.heatmap(pmc.isnull(), cmap=\"Reds\", cbar=False, ax=axes[1,1])\nax.vlines([1,2,3,4,5,6,7,8,9], *ax.get_ylim(), color=\"black\")\naxes[1,1].set_title(title, fontsize=15)\n\nfig.suptitle(\"Missing Value Heatmaps for all 4 datasets\", fontsize=20)\nplt.show()","cae96b76":"# Impute NaNs with \"Missing\"\n\nbio = bio.fillna(\"Missing\")\nnoncomm = noncomm.fillna(\"Missing\")\ncomm = comm.fillna(\"Missing\")\npmc = pmc.fillna(\"Missing\")","f91b9bc0":"# Concatenate all the dataframes together\npapers = pd.concat([bio, comm, noncomm, pmc], ignore_index=True)","66b5e60c":"# Data Cleaning\ndef clean_up(t):\n    \"\"\"\n    Cleans up the passed value\n    \"\"\"\n    # Remove New Lines\n    t = t.replace(\"\\n\",\" \") # removes newlines\n\n    # Remove citation numbers (Eg.: [4])\n    t = re.sub(\"\\[[0-9]+(, [0-9]+)*\\]\", \"\", t)\n\n    # Remove et al.\n    t = re.sub(\"et al.\", \"\", t)\n\n    # Remove Fig and Table\n    t = re.sub(\"\\( ?Fig [0-9]+ ?\\)\", \"\", t)\n    t = re.sub(\"\\( ?Table [0-9]+ ?\\)\", \"\", t)\n    \n    # Replace continuous spaces with a single space\n    t = re.sub(' +', ' ', t)\n    \n    # Convert all to lowercase\n    t = t.lower()\n    \n    return t\n\npapers[\"abstract\"] = papers[\"abstract\"].apply(clean_up)\npapers[\"text\"] = papers[\"text\"].apply(clean_up)","81919c05":"# Utility Functions for this Section\n\ndef word_occurence(entry, word):\n    \"\"\"\n    Identifies if a given word exists in a dataframe's entry\n    or not\n    \n    Parameters\n    ----------\n    entry : The entry OR cell or value\n    \n    Returns\n    -------\n    0 if the word is not found\n    1 if it the word is found\n    \"\"\"\n    # convert to lower case for uniformity\n    word=word.lower()\n    \n    if(word in entry.lower()):\n        return 1\n    else:\n        return 0\n    \ndef select_papers(dataframe, keyword):\n    \"\"\"\n    Creates new features in a dataframe depicting\n    the existence of the given keyword\n    \n    Parameters\n    ----------\n    dataframe : The dataframe in which you are searching\n                for\n    keyword : The keyword that you are searching for\n    \n    Returns\n    -------\n    The new dataframe with the newly created \n    feature\/columns\n    \"\"\"\n    # title\n    feature_header = keyword+\"_exists_title\"\n    dataframe[feature_header] = dataframe[\"title\"].apply(word_occurence, word=keyword)\n    \n    # abstract\n    feature_header = keyword+\"_exists_abstract\"\n    dataframe[feature_header] = dataframe[\"abstract\"].apply(word_occurence, word=keyword)\n    \n    # text\n    feature_header = keyword+\"_exists_text\"\n    dataframe[feature_header] = dataframe[\"text\"].apply(word_occurence, word=keyword)\n    \n    return dataframe","66ad2dfc":"# Example\n\nbio = select_papers(bio, \"risk\")\nbio.head()","23d37e18":"# restore to normal\nbio = bio.drop([\"risk_exists_title\", \"risk_exists_abstract\", \"risk_exists_text\"], axis=1)","ec2af077":"# Utility Functions for this Section\n\ndef display_papers(dataframe):\n    \"\"\"\n    Displays all the papers in a \n    data subset obtained like \n    bio_pulmonary or bio_smoking\n    \n    Parameters\n    ----------\n    dataframe : The dataframe\n    \n    Returns\n    -------\n    Prints all paper titles and paper ids\n    in a given dataframe\n    \"\"\"\n    papers = \";\".join(comment for comment in dataframe[\"title\"])\n    paper_ids = \";\".join(comment for comment in dataframe[\"paper_id\"])\n    papers = papers.split(\";\")\n    paper_ids = paper_ids.split(\";\")\n    for p,p_id in zip(papers, paper_ids):\n        print(\"-> \",p,\" ( Paper ID :\", p_id,\")\")\n    print(\"----------\")\n           \ndef gen_wordcloud(df, feature, remove_list=[]):\n    \"\"\"\n    Generate word clouds for a given feature\n    \n    Parameters\n    ----------\n    df : Dataframe\n    feature : Feature in the Dataframe\n    remove_list : List of words that need to be removed\n    \n    Returns\n    -------\n    Displays the wordcloud\n    \"\"\"\n    words = \" \".join(comment for comment in df[feature])\n    words = words.lower()\n    for w in remove_list:\n        words = words.replace(w,\"\")\n    \n    wordcloud = WordCloud(max_words=1000,background_color=\"white\", width=800, height=800,\n                     contour_width=3, contour_color='firebrick').generate(words)\n    # Display the generated image:\n    plt.figure(figsize=[15,15])\n    plt.imshow(wordcloud, interpolation='bilinear')\n    plt.title(feature)\n    plt.axis(\"off\")\n    plt.show()\n    \ndef choosing_sentences(text, word):\n    \"\"\"\n    Function to choose sentences from a text\n    passage\/string based on the existence of a\n    given word in these strings\n    \n    Parameters\n    ----------\n    text : The text passage\n    word : Word to search for in the text\n    \n    Returns\n    -------\n    Sentences that contain the word\n    \"\"\"\n    # Initializing empty list\n    qualified = []\n    \n    text = text.split(\".\")\n    text = [x.strip() for x in text]\n    for i in text:\n        if(word in i):\n            qualified.append(i)\n    return qualified\n\ndef extract_impt_sentences(dataframe, identifier, feature_list, keyword):\n    \"\"\"\n    Select important sentences from textual features that\n    contain a specific keyword\n    \n    Parameters\n    ----------\n    dataframe : The Dataframe\n    identifier : The feature that has the ability\n                 to uniquely identify each row\n    feature_list : The features that are to be \n                   searched for the given keyword\n    keyword : The keyword to search for; every sentence\n              having this keyword should be stored in a\n              list and returned\n    \n    Returns\n    -------\n    Dictionary with \n    Keys : Paper titles\n    Values : Sentences that have the word in the given paper\n    \"\"\"\n    # number of rows\n    n_rows = dataframe.shape[0]\n    documents = {}\n    \n    for f in feature_list:\n        for i in range(dataframe.shape[0]):\n            u_id = dataframe[identifier].iloc[i]\n            qualifying_sentences = choosing_sentences(dataframe[f].iloc[i], keyword)\n            # ignore papers where there are NO QUALIFYING SENTENCES\n            if(len(qualifying_sentences) != 0):\n                documents[u_id] = qualifying_sentences\n            else:\n                pass\n    return (documents)\n\ndef choose_sentences_based_on_words(list_sentences, list_words):\n    \"\"\"\n    Chooses all sentences in the list_sentences that consist of\n    words from list_words\n    \"\"\"\n    q = []\n    for i in list_sentences:\n        flag=0\n        for j in list_words:\n            if(not(j in i)):\n                flag+=1\n        if(flag==0):\n            q.append(i)\n    return q","db464ffc":"# Selecting papers\npapers = select_papers(papers, \"smoking\")\npapers = select_papers(papers, \"pulmonary\")\n\n# Subsetting\npapers_smoking = papers[(papers[\"smoking_exists_title\"]==1) | (papers[\"smoking_exists_abstract\"]==1) | (papers[\"smoking_exists_text\"]==1)]\npapers_pulmonary = papers[(papers[\"pulmonary_exists_title\"]==1) | (papers[\"pulmonary_exists_abstract\"]==1) | (papers[\"pulmonary_exists_text\"]==1)]","6aa65754":"# Display papers in which \"pulmonary\" is mentioned atleast once in the title, abstract or text\nprint(\"10 Papers in which the word 'pulmonary' is mentioned :\\n\")\ndisplay_papers(papers_pulmonary.sample(10))\n\n# Display papers in which \"smoking\" is mentioned atleast once in the title, abstract or text\nprint(\"\\n10 Papers in which the word 'smoking' is mentioned :\\n\")\ndisplay_papers(papers_smoking.sample(10))","a59928f9":"pulmonary_docs = extract_impt_sentences(papers_pulmonary, \"title\", [\"abstract\", \"text\"], \"pulmonary\")\nsmoking_docs = extract_impt_sentences(papers_smoking, \"title\", [\"abstract\", \"text\"], \"smoking\")","3d37fe4f":"# Wordcloud Analysis on the \"text\" feature of papers_pulmonary\n\"\"\"\nprint(\"papers_pulmonary\")\ngen_wordcloud(\n    papers_pulmonary,\n    \"text\",\n    [\"rights\", \"reserved\", \"supplementary\", \"fig\", \"holder\", \"preprint\",\n     \"copyright\", \"peer\", \"reviewed\", \"et al\", \"reviewed\", \"permission\",\n    \"using\", \"funder\"])\n\n# Wordcloud Analysis on the \"text\" feature of papers_smoking\n\nprint(\"papers_smoking\")\ngen_wordcloud(\n    papers_smoking,\n    \"text\",\n    [\"rights\", \"reserved\", \"supplementary\", \"fig\", \"holder\", \"preprint\",\n     \"copyright\", \"peer\", \"reviewed\", \"et al\", \"reviewed\", \"permission\",\n    \"using\", \"funder\", \"author\", \"license\", \"international\", \"made\",\n    \"available\", \"medrxiv\", \"doi\", \"org\"])\n\"\"\"","7ab4d85d":"# Sentences that contain both the words \"pulmonary\" and \"risk\" and any word of (\"-cov\", \"cov-\", \"hcov\", \"coronavirus\")\n\npulmonary_docs_risk = {}\nfor u_id,sent in pulmonary_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"-cov\"])\n    if(len(s)!=0):\n        pulmonary_docs_risk[u_id] = s\n\nfor u_id,sent in pulmonary_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"cov-\"])\n    if(len(s)!=0):\n        pulmonary_docs_risk[u_id] = s\n        \nfor u_id,sent in pulmonary_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"hcov\"])\n    if(len(s)!=0):\n        pulmonary_docs_risk[u_id] = s\n        \nfor u_id,sent in pulmonary_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"coronavirus\"])\n    if(len(s)!=0):\n        pulmonary_docs_risk[u_id] = s\n        \nfor u_id,sent in pulmonary_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"covid\"])\n    if(len(s)!=0):\n        pulmonary_docs_risk[u_id] = s\n\nfor u_id,sentence in pulmonary_docs_risk.items():\n    print(\"Paper Title : \"+u_id)\n    print(sentence)\n    print()","d3239b4a":"# Sentences that contain both the words \"smoking\" and \"risk\"\n\nsmoking_docs_risk = {}\nfor u_id,sent in smoking_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"cov-\"])\n    if(len(s)!=0):\n        smoking_docs_risk[u_id] = s\n        \nfor u_id,sent in smoking_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"-cov\"])\n    if(len(s)!=0):\n        smoking_docs_risk[u_id] = s\n        \nfor u_id,sent in smoking_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"hcov\"])\n    if(len(s)!=0):\n        smoking_docs_risk[u_id] = s\n        \nfor u_id,sent in smoking_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"coronavirus\"])\n    if(len(s)!=0):\n        smoking_docs_risk[u_id] = s\n        \nfor u_id,sent in smoking_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"covid\"])\n    if(len(s)!=0):\n        smoking_docs_risk[u_id] = s\n\nfor u_id,sentence in smoking_docs_risk.items():\n    print(\"Paper Title : \"+u_id)\n    print(sentence)\n    print()","9973f865":"# Selecting papers\npapers = select_papers(papers, \"women\")\npapers = select_papers(papers, \"pregnancy\")\npapers = select_papers(papers, \"pregnant\")\npapers = select_papers(papers, \"newborn\")\npapers = select_papers(papers, \"neonate\")\n\n# Subsetting\npapers_preg_new = papers[(papers[\"women_exists_title\"]==1) | (papers[\"women_exists_abstract\"]==1) | (papers[\"women_exists_text\"]==1) | (papers[\"pregnancy_exists_title\"]==1) | (papers[\"pregnancy_exists_abstract\"]==1) | (papers[\"pregnancy_exists_text\"]==1) | (papers[\"pregnant_exists_title\"]==1) | (papers[\"pregnant_exists_abstract\"]==1) | (papers[\"pregnant_exists_text\"]==1) | (papers[\"neonate_exists_title\"]==1) | (papers[\"neonate_exists_abstract\"]==1) | (papers[\"neonate_exists_text\"]==1) | (papers[\"newborn_exists_title\"]==1) | (papers[\"newborn_exists_abstract\"]==1) | (papers[\"newborn_exists_text\"]==1)]","c50fc738":"# Display papers in which \"women\", \"pregnancy\", \"pregnant\", \"newborn\" or \"neonate\" are mentioned atleast once\nprint(\"10 Papers in which \\\"women\\\", \\\"pregnancy\\\", \\\"pregnant\\\", \\\"newborn\\\" or \\\"neonate\\\" are mentioned atleast once:\\n\")\ndisplay_papers(papers_preg_new.sample(10))","5202669b":"preg_docs = extract_impt_sentences(papers_preg_new, \"title\", [\"abstract\", \"text\"], \"pregnan\") # to relate to any pregnan- word\n\n# Sentences that contain both the words \"pulmonary\" and \"risk\" and any word of (\"-cov\", \"cov-\", \"hcov\", \"coronavirus\")\n\npreg_docs_risk = {}\nfor u_id,sent in preg_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"-cov\"])\n    if(len(s)!=0):\n        preg_docs_risk[u_id] = s\n\nfor u_id,sent in preg_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"cov-\"])\n    if(len(s)!=0):\n        preg_docs_risk[u_id] = s\n        \nfor u_id,sent in preg_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"hcov\"])\n    if(len(s)!=0):\n        preg_docs_risk[u_id] = s\n        \nfor u_id,sent in preg_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"coronavirus\"])\n    if(len(s)!=0):\n        preg_docs_risk[u_id] = s\n        \nfor u_id,sent in preg_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"covid\"])\n    if(len(s)!=0):\n        preg_docs_risk[u_id] = s\n\nfor u_id,sentence in preg_docs_risk.items():\n    print(\"Paper Title : \"+u_id)\n    print(sentence)\n    print()","feb15368":"new_docs = extract_impt_sentences(papers_preg_new, \"title\", [\"abstract\", \"text\"], \"newborn\")\nneo_docs = extract_impt_sentences(papers_preg_new, \"title\", [\"abstract\", \"text\"], \"neonate\") \n\n# Sentences that contain both the words \"pulmonary\" and \"risk\" and any word of (\"-cov\", \"cov-\", \"hcov\", \"coronavirus\")\n\nnew_docs_risk = {}\nfor u_id,sent in new_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"-cov\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n\nfor u_id,sent in new_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"cov-\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n        \nfor u_id,sent in new_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"hcov\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n        \nfor u_id,sent in new_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"coronavirus\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n        \nfor u_id,sent in new_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"covid\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n    \nfor u_id,sent in neo_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"-cov\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n\nfor u_id,sent in neo_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"cov-\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n        \nfor u_id,sent in neo_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"hcov\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n        \nfor u_id,sent in neo_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"coronavirus\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n        \nfor u_id,sent in neo_docs.items():\n    s = choose_sentences_based_on_words(sent, [\"risk\", \"covid\"])\n    if(len(s)!=0):\n        new_docs_risk[u_id] = s\n\nfor u_id,sentence in new_docs_risk.items():\n    print(\"Paper Title : \"+u_id)\n    print(sentence)\n    print()","29affc72":"---\n\n### Risks associated with Pulmonary Infections in the case of COVID-19\n\n- The following sentence pools (i.e list of sentences) that are associated with a unique identifier(paper title) are those sentences where the word ***pulmonary and risk*** occur together\n- There are 439 such papers\n\nNow, what is important for analysis is to understand the **Impact of pre-existing pulmonary disease on COVID-19**. For this purpose, I choose\/select those sentences from the sentence pools in such fashion that only those sentencs which have either of the ***covid representation words*** will be chosen\/selected.  \n\n***covid representation words*** : Just a term I have given to those words that represent the covid disease. From a preliminary observation, it has come to my notice that the following words\/patterns are used to refer to the covid virus in multiple papers :\n- -cov\n- cov-\n- hcov\n- coronavirus\n\n**NOTE :** More words that represent covid shall be added here when I find more. If you happen to find some that are not considered by me, do let me know. I shall add them to my code too.  \n\n\nAfter applying the above mentioned filtering, we have 7 papers with qualifying sentences.","3045774d":"---\n### Risks associated with Pregnancy or Pregnant women in the case of COVID","b0e1e3f3":"### Basic Wordcloud Analysis\n\n**NOTE :** This section has been temporarily commented out as running it exceeds the memory capacity. I shall rectify that error and run this section again.","0aa626a4":"> There are 1,191 papers with either \"smoking\" in the title, abstract or text.  \n> There are 5,012 papers with the word \"pulmonary\" in the title, abstract or text.  ","451f6fe5":"## II. Finding the Necessary Papers based on simple \"Keyword\" search","b0e51404":"A few of the associated key points are :\n- Other case-control and retrospective observational studies from both ksa and korea have suggested that **smoking and\/or comorbid respiratory diseases** are **significant risk factors for mers-cov-related mortality**\n- In saudi arabia, the **probable risk factors for mers-cov** infection were older age , male sex , exposure to dromedary camels, comorbidities and **smoking**","266a3a33":"---\n## Analyzing papers that contain words related to \"pregnancy\" and \"newborns\"","2d0f0896":"The old dataframe has been restored back to normal.  \n\n---","4ff5ef7d":"A few of the associated key points are :\n\n- the mother should not breastfeed until she has recovered from sars or is deemed not to have sars\n- to minimize neonatal transmission risk, the mother should be isolated from the neonate until she is no longer potentially infectious communications\n- neonates born to mothers with potential sars close contact are considered to be potentially infectious until 10 days postpartum\n- Pregnant women and newborn babies should be considered key atrisk populations in strategies focusing on prevention and management of covid19 infection","55b43923":"## Methodology\n\n### I. Data Cleaning\n  \n### II. Finding the Necessary Papers based on simple \"Keyword\" search\n  \n### III. Analyzing papers that contain words like \"pulmonary\" or \"smoking\"\n\n### IV. Analyzing papers that contain words related to \"pregnancy\" and \"newborns\"","de7aafe1":"### My next steps would be to \n- Fix the wordcloud\n- Deal with other points to be covered in the Tasks homepage for this task","5ec89676":"- The Dark Red horizontal lines indicate missing values\n- To get rid of the NaNs, all NaNs will be imputed with \"Missing\"","306f04b1":"The imputation has been performed.  \n\nMore steps for data cleaning will be added at a later stage if required.  \n\n**NOTE :** The dataframe ***papers*** contains all the papers. This will be used for analysis.","5db45c5f":"10 papers in which \"women\", \"pregnancy\", \"pregnant\", \"newborn\" or \"neonate\" are mentioned atleast once","44a45dab":"### Risks associated with Smoking in the case of COVID-19\n\n- The following sentence pools (i.e list of sentences) that are associated with a unique identifier(paper title) are those sentences where the word ***smoking and risk*** occur together\n- There are 322 such papers\n\nAfter applying the filtering like in the previous section, I get 4 papers.","86b99629":"The biggest dilemma is to select the right kind of papers to get the right information pertaining to a given task. This section deals with re-usable code that can help find the right papers based on specific keywords we are looking for.  \n\n**How to use this section?**\n\n- Step 1. Choose your dataframe (You can either choose one of the 4 initial dataframes loaded or select ***papers*** which consists of all papers (I will be using the latter in this notebook)\n- Step 2. Choose a specific keyword you are looking for (Eg. :***smoking***)\n- Step 3. Run the select_papers() function with necessary arguments\n    - The original dataframe will now have 3 more features, each feature depicting the presence of the given keyword in title, abstract or text respectively.\n","5cf90aab":"There are some very key points that can be taken away from the sentences filtered out above like the following :\n- Risk of severe pulmonary disease in persons who fail to develop a neutralizing antibody response following exposure to mers-cov\n- In mers-cov infection, the important risk factors factors for death are old age (>50-65 years, depending on the study), underlying diseases (cardiac disease, chronic pulmonary disease, diabetes, chronic renal disease, etc\n\n---","609fd944":"A few of the associated key points are :\n\n- Coronaviruses can result in maternal death in a small but significant number of cases, but the **specific risk factors for a fatal outcome during pregnancy have not been clarified**\n- Pregnant women are conventionally considered a high-risk group for the progression to severe disease or death, and a case was reported of stillbirth in the second trimester of pregnancy for a woman infected with mers-cov\n- According to current recommendations that are reviewed yearly, because of the high mortality rates associated with mers-cov infection, people with the following risk factors should postpone hajj or umrah for their own safety: individuals who are older than 65 years of age; individuals who have chronic diseases including diabetes, heart disease, kidney disease, respiratory disease, autoimmune disease, or immune defi ciency (congenital and acquired); people who are taking immunosuppressive drugs; individuals who have a malignant disease or a terminal illness; pregnant women; and children younger than 12 years\n- Given the maternal physiologic and immune function changes in pregnancy , pregnant individuals might face greater risk of getting infected by sars-cov-2 and might have more complicated clinical events\n- **Pregnant women are at an increased risk** to suffer from acute and chronic viral infections such as rhinovirus, severe acute respiratory syndrome, **coronavirus**, varicella zoster, hepatitis e\/b, hiv, and cytomegalovirus\n","f2fc295d":"## I. Data Cleaning\nMaking the data more usable for the analysis","325fc0fd":"# COVID-19 Risk Factors Analysis\n\n## Aim of this Notebook\nTo understand the risk factors surrounding COVID-19\n\n**Task Details (Taken from [Task Home Page](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge\/tasks?taskId=558))**  \nWhat do we know about COVID-19 risk factors? What have we learned from epidemiological studies?\n\n1. Data on potential risks factors  \n    **a.** Smoking, pre-existing pulmonary disease  \n    **b.** Co-infections (determine whether co-existing respiratory\/viral infections make the virus more transmissible or virulent) and other            co-morbidities  \n    **c.** Neonates and pregnant women  \n    **d.** Socio-economic and behavioral factors to understand the economic impact of the virus and whether there were differences.  \n2. Transmission dynamics of the virus, including the basic reproductive number, incubation period, serial interval, modes of transmission and environmental factors\n3. Severity of disease, including risk of fatality among symptomatic hospitalized patients, and high-risk patient groups\n4. Susceptibility of populations\n5. Public health mitigation measures that could be effective for control\n\n### Main Goal\nThe main goal of this notebook will be to filter out answers to those questions asked in the [CORD-19 Task](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge\/tasks?taskId=558) as mentioned above. \n\n## Acknowledgements\n\n- I thank [xhlulu](https:\/\/www.kaggle.com\/xhlulu) for cleaning up the original json files in the [CORD Dataset](https:\/\/www.kaggle.com\/allen-institute-for-ai\/CORD-19-research-challenge) and providing the data in a .csv format.  \nHis kernel can be found [here](https:\/\/www.kaggle.com\/xhlulu\/cord-19-eda-parse-json-and-generate-clean-csv).","dde90ea8":"The **bio** dataframe has got 3 new features based on the existence of the given keyword. In this case, it is ***risk***.  \n\nBased on these features, we can subset the dataframe into relevant papers and analyse.","77c98cad":"Let's have a look at 10 papers each of thoe that contain the word \"smoking\" or \"pulmonary\".","b44faa67":"---\n### Points associated with Neonates and Newborns in the case of COVID","0214c752":"### Missing Value Imputation\n\nAt this point, I am replacing all the NaN values with \"Missing\".  \nFirst, let's see how many missing values are even there.","55a5ba57":"---\n### Example of Working of the above Idea","b29927cd":"### Cleaning the Textual Values\n\nIn this part, I am performing some rudimentary text cleaning. The following steps are taken :  \n- Remove newline characters\n- Remove citation numbers like [5]\n- Remove et. al\n- Remove Fig and Table citations like (Fig 5) or ( Table 6 )\n- Replace continuous spaces with a single space\n- Convert all alphabets to lower case","87c9394c":"**NOTE :** Essentially what the select_papers() function is doing is **Introducing 3 new features everytime for every new word that is being searched for**. These features correspond to the presence of a given word in\n- Title of the Paper\n- Abstract of the Paper\n- Text of the Paper\n***If the word exists, it is represented with a 1. Else, it's a 0.***\n\n**Why am I doing this?**  \nAn intuitive way to look at this is to maintain a kind of record within the dataframe itself to understand at a later stage what papers contain a certain word or not.","38cb6537":"## III. Analyzing Papers that contain words like \"pulmonary\" or \"smoking\""}}