{"cell_type":{"b9490cbf":"code","d7a3c13d":"code","4c4e9a3d":"code","31997960":"code","da28cdec":"code","ea101ed5":"code","b63fc33c":"code","26d140f8":"code","7b756324":"code","1725a14b":"code","1d161a9b":"code","4c1e7059":"code","b04ee3d4":"code","0e20fe05":"code","2a0bfa02":"code","2d042ccd":"code","ebe8e6d8":"code","117e1242":"code","723d138d":"code","e0cc86d6":"code","dc387084":"code","f1141605":"code","77682e63":"code","9b8ad9cd":"code","7b5d44f3":"code","2e654cc0":"code","4c41ee82":"markdown"},"source":{"b9490cbf":"import os\nprint(\"Total classes: \",len(os.listdir('\/kaggle\/input\/dl-and-ai-with-sadiq\/Train\/Train')))\nprint('\\n')\nprint(\"Total images in Angrybird: \\t\",len(os.listdir('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Angrybirds')))\nprint(\"Total images in Ben: \\t\\t\",len(os.listdir('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Ben')))\nprint(\"Total images in Chicken_little: \",len(os.listdir('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Chicken_little')))\nprint(\"Total images in Cinderella: \\t\",len(os.listdir('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Cinderella')))\nprint(\"Total images in Godzilla: \\t\",len(os.listdir('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Godzilla')))\nprint(\"Total images in Mickey_mouse: \\t\",len(os.listdir('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Mickey_mouse')))\nprint(\"Total images in Naruto: \\t\",len(os.listdir('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Naruto')))\nprint(\"Total images in Pokemon: \\t\",len(os.listdir('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Pokemon')))\n","d7a3c13d":"import cv2\nimg1 = cv2.imread('..\/input\/dl-and-ai-with-sadiq\/Train\/Train\/Angrybirds\/Ang (100).jpeg')\nimg2 = cv2.imread('..\/input\/dl-and-ai-with-sadiq\/Test\/Test\/1.jpeg')\n\nprint(\"Traing image shape: \",img1.shape)\nprint(\"Traing image shape: \",img2.shape)","4c4e9a3d":"classes = 10\nimg_rows, img_cols = 220, 220\nbatch_size = 16","31997960":"from keras.preprocessing.image import ImageDataGenerator\n\nTRAIN_DIR = '\/kaggle\/input\/dl-and-ai-with-sadiq\/Train\/Train'\n\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=30,\n      width_shift_range=0.3,\n      height_shift_range=0.3,\n      horizontal_flip=True,\n      fill_mode='nearest',\n      validation_split=0.3)\n \ntrain_generator = train_datagen.flow_from_directory(\n        TRAIN_DIR,\n        target_size=(img_rows, img_cols),\n        batch_size=batch_size,\n        class_mode='categorical',\n        shuffle=True)\n\n\nvalidation_datagen=train_datagen.flow_from_directory(TRAIN_DIR,\n                                                          subset='validation',\n                                                          target_size=(img_rows, img_cols),\n                                                          batch_size=batch_size,\n                                                          class_mode='categorical')","da28cdec":"nb_train_samples = 1485  \nnb_validation_samples = 630 \n","ea101ed5":"from tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Activation, Flatten, GlobalAveragePooling2D\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D, ZeroPadding2D\nfrom keras.layers.normalization import BatchNormalization\nfrom tensorflow.keras.models import Model\n\n\n# Re-loads the MobileNet model without the top or FC layers\nvgg16 = VGG16(weights = 'imagenet',include_top = False,input_shape = (img_rows, img_cols, 3))\n\nfor layer in vgg16.layers:\n    layer.trainable = False\n    \n\ndef addTopModelvgg16(bottom_model, num_classes):\n    \"\"\"creates the top or head of the model that will be \n    placed ontop of the bottom layers\"\"\"\n\n    top_model = bottom_model.output\n    top_model = GlobalAveragePooling2D()(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(512,activation='relu')(top_model)\n    top_model = Dense(num_classes,activation='softmax')(top_model)\n    return top_model\n\n\nnum_classes = classes\n\nFC_Head = addTopModelvgg16(vgg16, num_classes)\n\nmodel = Model(inputs = vgg16.input, outputs = FC_Head)","b63fc33c":"epochs = 10","26d140f8":"%%time\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n                   \ncheckpoint = ModelCheckpoint(\"vgg16FINAL.h5\",\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only = True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0, \n                          patience = 5,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.25,\n                              patience = 2,\n                              verbose = 1)\n\n# we put our call backs into a callback list\ncallbacks = [checkpoint, reduce_lr]\n\n# Note we use a very small learning rate \nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = Adam(),\n              metrics = ['accuracy'])\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples \/\/ batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = validation_datagen,\n    validation_steps = nb_validation_samples \/\/ batch_size)","7b756324":"import pandas as pd\nresult = pd.DataFrame(history.history)\nresult.plot(figsize=(10,8))","1725a14b":"print(\"Max Training Accurracy: \",result['accuracy'].max())\nprint(\"Min Training Loss: \",result['loss'].min())\nprint(\"Max Validation Accurracy: \",result['val_accuracy'].max())\nprint(\"Min Validation Loss: \",result['val_loss'].min())","1d161a9b":"import cv2\nimport numpy as np\n\nimg_size = 220\ndata_dir_ts = '..\/input\/dl-and-ai-with-sadiq\/Test\/Test'\npath_ts = os.path.join(data_dir_ts)\nxts = []\ndef create_test_data():\n    path_ts = os.path.join(data_dir_ts)\n    for img_ts in os.listdir(path_ts):\n        image_array_ts = cv2.imread(os.path.join(path_ts,img_ts))\n        new_im_array_ts = cv2.resize(image_array_ts, (img_size,img_size))\n        xts.append([new_im_array_ts])\n            \ncreate_test_data()\n\n\nxts =np.array(xts).reshape(-1,img_size,img_size,3)\nxts = xts\/255\nxts.shape","4c1e7059":"from keras.models import load_model\nclassifier = load_model('.\/vgg16FINAL.h5')\n\nt_pred = classifier.predict(xts)\nt_pred = np.argmax(t_pred, axis=1)\n\nts_im_list = []\nfor img_ts in os.listdir(path_ts):\n    ts_im_list.append(img_ts)\ntest = pd.DataFrame({'ImageId':ts_im_list})\ntest.insert(1, 'Class',t_pred)\ntest.head()","b04ee3d4":"label_map = train_generator.class_indices\nlabel_map","0e20fe05":"reverse_map = {\n    0 : 'Angrybirds',\n    1 : 'Ben',\n    2 : 'Chicken_little',\n    3 : 'Cinderella',\n    4 : 'Godzilla',\n    5 : 'Mickey_mouse',\n    6 : 'Naruto',\n    7 : 'Pokemon',\n    8 : 'Popeye',\n    9 : 'Tom and Jerry'\n}","2a0bfa02":"for i in range(len(test)):\n    test['Class'][i] = reverse_map[test['Class'][i]]","2d042ccd":"sub = test.sort_values(['ImageId'])\nsub.head()","ebe8e6d8":"sub.to_csv('sampleSubmission.csv', index=False)","117e1242":"# import the modules we'll need\nfrom IPython.display import HTML\nimport pandas as pd\nimport numpy as np\nimport base64\n\n# function that takes in a dataframe and creates a text link to  \n# download it (will only work for files < 2MB or so)\ndef create_download_link(df, title = \"Download CSV file\", filename = \"Test.csv\"):  \n    csv = df.to_csv()\n    b64 = base64.b64encode(csv.encode())\n    payload = b64.decode()\n    html = '<a download=\"{filename}\" href=\"data:text\/csv;base64,{payload}\" target=\"_blank\">{title}<\/a>'\n    html = html.format(payload=payload,title=title,filename=filename)\n    return HTML(html)\ncreate_download_link(sub)","723d138d":"epochs = 1","e0cc86d6":"from keras.layers import GlobalAveragePooling2D\nfrom keras.applications.inception_v3 import InceptionV3\n\ninceptionV3 = InceptionV3(weights=\"imagenet\",\n                          include_top= False, \n                          input_shape=(img_rows,img_cols,3))\n\nfor layer in inceptionV3.layers:\n    layer.trainable = False\n    \ndef addTopModelinceptionV3(bottom_model, num_classes):\n    \"\"\"creates the top or head of the model that will be \n    placed ontop of the bottom layers\"\"\"\n\n    top_model = bottom_model.output\n    top_model = GlobalAveragePooling2D()(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(512,activation='relu')(top_model)\n    top_model = Dense(num_classes,activation='softmax')(top_model)\n    return top_model\n\n\nnum_classes = classes\n\nFC_Head = addTopModelinceptionV3(inceptionV3, num_classes)\n\nmodel = Model(inputs = inceptionV3.input, outputs = FC_Head)","dc387084":"%%time\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n                   \ncheckpoint = ModelCheckpoint(\"vgg16_2.h5\",\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only = True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0, \n                          patience = 5,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.30,\n                              patience = 2,\n                              verbose = 1)\n\n# we put our call backs into a callback list\ncallbacks = [checkpoint, reduce_lr, reduce_lr]\n\n# Note we use a very small learning rate \nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = Adam(),\n              metrics = ['accuracy'])\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples \/\/ batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = validation_datagen,\n    validation_steps = nb_validation_samples \/\/ batch_size)","f1141605":"%%time\n\ncheckpoint = ModelCheckpoint(\"vgg16_3.h5\",\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only = True,\n                             verbose=1)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.30,\n                              patience = 2,\n                              verbose = 1)\n\n# we put our call backs into a callback list\ncallbacks = [checkpoint, reduce_lr]\n\n# Note we use a very small learning rate \nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = Adam(),\n              metrics = ['accuracy'])\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples \/\/ batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = validation_datagen,\n    validation_steps = nb_validation_samples \/\/ batch_size)","77682e63":"from tensorflow.keras.applications import ResNet50V2\nres50 = ResNet50V2(weights=\"imagenet\",\n                          include_top= False, \n                          input_shape=(img_rows,img_cols,3))\n\nfor layer in res50.layers:\n    layer.trainable = False\n    \ndef addTopModelres50(bottom_model, num_classes):\n    \"\"\"creates the top or head of the model that will be \n    placed ontop of the bottom layers\"\"\"\n\n    top_model = bottom_model.output\n    top_model = GlobalAveragePooling2D()(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(1024,activation='relu')(top_model)\n    top_model = Dense(512,activation='relu')(top_model)\n    top_model = Dense(num_classes,activation='softmax')(top_model)\n    return top_model\n\n\nnum_classes = classes\n\nFC_Head = addTopModelinceptionV3(res50, num_classes)\n\nmodel = Model(inputs = res50.input, outputs = FC_Head)","9b8ad9cd":"%%time\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n                   \ncheckpoint = ModelCheckpoint(\"res50.h5\",\n                             monitor=\"val_loss\",\n                             mode=\"min\",\n                             save_best_only = True,\n                             verbose=1)\n\nearlystop = EarlyStopping(monitor = 'val_loss', \n                          min_delta = 0, \n                          patience = 5,\n                          verbose = 1,\n                          restore_best_weights = True)\n\nreduce_lr = ReduceLROnPlateau(monitor = 'val_loss',\n                              factor = 0.30,\n                              patience = 2,\n                              verbose = 1)\n\n# we put our call backs into a callback list\ncallbacks = [checkpoint, reduce_lr, reduce_lr]\n\n# Note we use a very small learning rate \nmodel.compile(loss = 'categorical_crossentropy',\n              optimizer = Adam(),\n              metrics = ['accuracy'])\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples \/\/ batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = validation_datagen,\n    validation_steps = nb_validation_samples \/\/ batch_size)","7b5d44f3":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nmodel = Sequential()\n\n# Padding = 'same'  results in padding the input such that\n# the output has the same length as the original input\nmodel.add(Conv2D(32, (3, 3), padding='same',\n                 input_shape= (img_rows, img_cols, 3)))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(32, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Conv2D(64, (3, 3), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\nmodel.add(Conv2D(64, (3, 3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\nmodel.add(Dense(512))\nmodel.add(Activation('relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(num_classes))\nmodel.add(Activation('softmax'))","2e654cc0":"model.compile(loss = 'categorical_crossentropy',\n              optimizer = Adam(),\n              metrics = ['accuracy'])\n\n\nhistory = model.fit(\n    train_generator,\n    steps_per_epoch = nb_train_samples \/\/ batch_size,\n    epochs = epochs,\n    callbacks = callbacks,\n    validation_data = validation_datagen,\n    validation_steps = nb_validation_samples \/\/ batch_size)","4c41ee82":"# **Experimenting Other models**"}}