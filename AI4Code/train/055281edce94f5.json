{"cell_type":{"19554400":"code","817a7bd1":"code","08a72677":"code","ceb086ab":"code","00556ac1":"code","518dcfe5":"code","89e81e49":"code","b304ef75":"code","bf702cff":"code","03ceb85b":"code","da0746a1":"code","5cabbdbc":"code","e52b26dd":"code","46ee4eb2":"code","1921ec5d":"code","8fedce2a":"code","9dbf1e58":"code","d40af1f8":"code","f5964577":"code","ae4ca684":"code","b3373598":"code","d289ec0d":"code","5de7c538":"code","09c4cb24":"code","14fe653c":"markdown","3f267d37":"markdown","8273f621":"markdown","2b4d1240":"markdown","3cf54968":"markdown"},"source":{"19554400":"\nimport os\nimport pandas as pd\nimport numpy as np\nfrom pandas.io.json import json_normalize\nimport json\nimport time\nimport warnings\n\n#from pycountry_convert import ( map_countries, country_name_to_country_alpha3,)\nimport pytz as pytz\nimport datetime\n\n#Plotting\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nplt.style.use('ggplot')\n\n#Sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.model_selection import KFold\n\n#lgm and graph viz\nimport graphviz \nimport lightgbm as lgb\n\nwarnings.filterwarnings('ignore')\n","817a7bd1":"def load_df(csv_path='..\/input\/train.csv', nrows=None):\n    JSON_COLUMNS = ['device', 'geoNetwork', 'totals', 'trafficSource']\n      \n    df = pd.read_csv(csv_path, \n                     converters={column: json.loads for column in JSON_COLUMNS}, \n                     dtype={'fullVisitorId': 'str', 'visitId':'str', 'visitStartTime':'str', 'date':'str'}, \n                     nrows=nrows)\n\n    #Normalize JSON colunmns and drop\n    for column in JSON_COLUMNS:\n        column_as_df = json_normalize(df[column])\n        column_as_df.columns = [f\"{column}.{subcolumn}\" for subcolumn in column_as_df.columns]\n        df = df.drop(column, axis=1).merge(column_as_df, right_index=True, left_index=True)\n    return df\n\n\ndef drop_constant_cols(df):\n    ## Drop constant columns\n    const_cols = [c for c in df.columns if df[c].nunique(dropna=False) == 1]\n    df.drop(const_cols, axis=1, inplace=True)\n    \n    #this columnm is only in train data\n    try:\n        df.drop('trafficSource.campaignCode', axis=1, inplace=True)   \n    except:\n        None   \n    \n","08a72677":"os.listdir('..\/input')","ceb086ab":"%%time\n#Load\ntrain_df = load_df(csv_path='..\/input\/ga-customer-revenue-prediction\/train.csv', nrows = None)\n#train_df.to_pickle('train_flat_no_drop.pkl')\ndrop_constant_cols(train_df)\n\ntest_df = load_df(csv_path='..\/input\/ga-customer-revenue-prediction\/test.csv', nrows = None)\n#train_df.to_pickle('test_flat_no_drop.pkl')\ndrop_constant_cols(test_df)\n","00556ac1":"# Extract target values and Ids\ncat_cols = ['channelGrouping','device.browser',\n       'device.deviceCategory', 'device.isMobile', 'device.operatingSystem',\n       'geoNetwork.city', 'geoNetwork.continent', 'geoNetwork.country',\n       'geoNetwork.metro', 'geoNetwork.networkDomain', 'geoNetwork.region',\n       'geoNetwork.subContinent','trafficSource.adContent',\n       'trafficSource.adwordsClickInfo.adNetworkType',\n       'trafficSource.adwordsClickInfo.gclId',\n       'trafficSource.adwordsClickInfo.isVideoAd',\n       'trafficSource.adwordsClickInfo.page',\n       'trafficSource.adwordsClickInfo.slot', 'trafficSource.campaign',\n       'trafficSource.isTrueDirect', 'trafficSource.keyword',\n       'trafficSource.medium', 'trafficSource.referralPath',\n       'trafficSource.source'  ]\n\n\nnum_cols = ['visitNumber', 'totals.bounces', 'totals.hits',\n            'totals.newVisits', 'totals.pageviews', \n            '_local_hourofday'  ]\n\ninteraction_cols = ['totals.hits \/ totals.pageviews', 'totals.hits * totals.pageviews',\n       'totals.hits - totals.pageviews']\n\nvisitStartTime = ['visitStartTime']\n\nID_cols = ['date', 'fullVisitorId', 'sessionId', 'visitId']\n\ntarget_col = ['totals.transactionRevenue']\n\n","518dcfe5":"os.listdir('..\/input\/geocodes-timezones')","89e81e49":"#Load\ngeocode_df= pd.read_pickle('..\/input\/geocodes-timezones\/geocodes_timezones.pkl')\n\ndef time_zone_converter(x):\n    \n    try:\n        return pytz.country_timezones(x)[0]\n    except AttributeError:\n        return np.nan\n   \n\ndef time_localizer(s):\n    #format of series [time,zone]\n    try:\n        tz =pytz.timezone(s[1])\n        return pytz.utc.localize(s[0], is_dst=None).astimezone(tz)\n    except:\n        return np.nan\n    \ndef remove_missing_vals(x):\n    remove_list = ['(not set)', 'not available in demo dataset','unknown.unknown']\n    if x in remove_list:\n        return ''\n    else:\n        return x \n    \ndef map_timezone(x):   \n    try:\n        return timezone_dict[x]\n    except KeyError:\n        return 'UTC'\n\n","b304ef75":"%%time\ntrain_df['visitStartTime'] = pd.to_datetime(train_df['visitStartTime'], unit = 's')\ntest_df['visitStartTime'] = pd.to_datetime(test_df['visitStartTime'], unit = 's')\n\n#Generate foreign key '_search_term' by concatenating city, region, country\ntrain_df['_search_term'] = train_df['geoNetwork.city'].map(remove_missing_vals) + ' ' + train_df['geoNetwork.region'].map(remove_missing_vals) + ' ' + train_df['geoNetwork.country'].map(remove_missing_vals)\ntest_df['_search_term'] = test_df['geoNetwork.city'].map(remove_missing_vals) + ' ' + test_df['geoNetwork.region'].map(remove_missing_vals) + ' ' + test_df['geoNetwork.country'].map(remove_missing_vals)\n\n#Set global variable, needed for map_timezone function\nglobal timezone_dict\ntimezone_dict = dict(zip(geocode_df['search_term'], geocode_df['timeZoneId']))\n\n#Map timezones\ntrain_df['_timeZoneId'] = train_df['_search_term'].map(map_timezone)\ntest_df['_timeZoneId'] = test_df['_search_term'].map(map_timezone)\n  \n#Create time zone aware column\ntrain_df['_local_time'] = train_df[['visitStartTime', '_timeZoneId']].apply(time_localizer, axis = 1).astype(str)\ntest_df['_local_time'] = test_df[['visitStartTime', '_timeZoneId']].apply(time_localizer, axis = 1).astype(str)  \n\n#Localize hour time\ntrain_df['_local_hourofday'] = train_df['_local_time'].str[11:13]\ntest_df['_local_hourofday'] = test_df['_local_time'].str[11:13]\n\n","bf702cff":"%%time\ndef map_longitude(x):   \n    try:\n        return longitude_dict[x]\n    except KeyError:\n        return np.nan\n    \ndef map_latitude(x):   \n    try:\n        return latitude_dict[x]\n    except KeyError:\n        return np.nan\n    \nglobal longitude_dict\nlongitude_dict = dict(zip(geocode_df['search_term'], geocode_df['geometry.location.lng']))\n\nglobal latitude_dict\nlatitude_dict = dict(zip(geocode_df['search_term'], geocode_df['geometry.location.lat']))\n\n\n#Map latitude\ntrain_df['_latitude'] = train_df['_search_term'].map(map_latitude)\ntest_df['_latitude'] = test_df['_search_term'].map(map_latitude)\n\n#Map longitude\ntrain_df['_longitude'] = train_df['_search_term'].map(map_longitude)\ntest_df['_longitude'] = test_df['_search_term'].map(map_longitude)","03ceb85b":"%%time\ntrain_ts = train_df[['fullVisitorId', 'sessionId', 'visitId', 'visitNumber', 'visitStartTime']].copy()\ntest_ts = test_df[['fullVisitorId', 'sessionId', 'visitId', 'visitNumber', 'visitStartTime']].copy()\n\n\ntrain_df['_time_since_last_visit'] = train_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff()\ntrain_df['_time_since_last_visit_2'] = train_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff(2)\ntest_df['_time_since_last_visit'] = test_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff()\ntest_df['_time_since_last_visit_2'] = test_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff(2)\n\ntrain_df['_time_to_next_visit'] = train_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff(-1)\ntrain_df['_time_to_next_visit_2'] = train_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff(-2)\ntest_df['_time_to_next_visit'] = test_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff(-1)\ntest_df['_time_to_next_visit_2'] = test_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff(-2)\n\n#del train_ts\n#del test_ts","da0746a1":"%%time\nfor col in ['totals.bounces', 'totals.hits','totals.pageviews',  '_local_hourofday']:\n    train_df['_prev_{}_1'.format(col)] = train_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')[col].shift(1)\n    test_df['_prev_{}_1'.format(col)] = test_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')[col].shift(1)\n    train_df['_prev_{}_2'.format(col)] = train_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')[col].shift(2)\n    test_df['_prev_{}_2'.format(col)] = test_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')[col].shift(2)\n    \n    train_df['_next_{}_1'.format(col)] = train_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')[col].shift(-1)\n    test_df['_next_{}_1'.format(col)] = test_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')[col].shift(-1)\n    train_df['_next_{}_2'.format(col)] = train_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')[col].shift(-2)\n    test_df['_next_{}_2'.format(col)] = test_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')[col].shift(-2)\n    \n","5cabbdbc":"%%time\ntrain_df['_time_first_visit'] = train_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime']\\\n.transform('first')\ntrain_df['_time_last_visit'] = train_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime']\\\n.transform('last')\ntrain_df['_difference_first_last'] = train_df['_time_last_visit'] - train_df['_time_first_visit']\ntrain_df['_time_since_first_visit'] = train_df['visitStartTime'] - train_df['_time_first_visit']\ntrain_df.drop(['_time_first_visit', '_time_last_visit'], axis = 1,inplace = True)\n\n\ntest_df['_time_first_visit'] = test_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime']\\\n.transform('first')\ntest_df['_time_last_visit'] = test_df.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime']\\\n.transform('last')\ntest_df['_difference_first_last'] = test_df['_time_last_visit'] - test_df['_time_first_visit']\ntest_df['_difference_first_last'] = test_df['_time_last_visit'] - test_df['_time_first_visit']\ntest_df['_time_since_first_visit'] = test_df['visitStartTime'] - test_df['_time_first_visit']\ntest_df.drop(['_time_first_visit', '_time_last_visit'], axis = 1,inplace = True)\n\n","e52b26dd":"train_df.info()","46ee4eb2":"%%time\n#train_df['_time_since_last_visit'] = pd.to_numeric(train_df['_time_since_last_visit'])\n#test_df['_time_since_last_visit'] = pd.to_numeric(test_df['_time_since_last_visit'])\n\n#Preparation\nwip_cols = ['fullVisitorId', 'sessionId', 'visitId',\n       'visitNumber', 'visitStartTime','totals.bounces', 'totals.hits',\n       'totals.newVisits', 'totals.pageviews', '_time_since_last_visit']\n\ntrain_ts = train_df.sort_values(['fullVisitorId', 'visitStartTime']).reset_index()\ntrain_ts['index'] = train_ts['index'].astype('str')\ntrain_ts_grouped = train_ts.groupby('fullVisitorId')\n\n#Calculating rolling frequency\ntemp_roll = train_ts_grouped.rolling('12H', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_12H') \ntrain_ts = pd.concat([train_ts, temp_roll['visitNumber_12H']], axis = 1)\n\ntemp_roll = train_ts_grouped.rolling('7D', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_7D') \ntrain_ts = pd.concat([train_ts, temp_roll['visitNumber_7D']], axis = 1)\n\ntemp_roll = train_ts_grouped.rolling('30D', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_30D') \ntrain_ts = pd.concat([train_ts, temp_roll['visitNumber_30D']], axis = 1)\n\ntrain_ts['index'] = train_ts['index'].astype('int')\ntrain_ts.set_index('index', inplace = True)\ntrain_ts.sort_index(inplace = True)\ntrain_df = train_ts.copy()\ndel train_ts\n","1921ec5d":"train_df.info()","8fedce2a":"%%time\n\ntest_ts = test_df.sort_values(['fullVisitorId', 'visitStartTime']).reset_index()\ntest_ts['index'] = test_ts['index'].astype('str')\ntest_ts_grouped = test_ts.groupby('fullVisitorId')\n\n#Calculating rolling frequency\ntemp_roll = test_ts_grouped.rolling('12H', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_12H') \ntest_ts = pd.concat([test_ts, temp_roll['visitNumber_12H']], axis = 1)\n\ntemp_roll = test_ts_grouped.rolling('7D', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_7D') \ntest_ts = pd.concat([test_ts, temp_roll['visitNumber_7D']], axis = 1)\n\ntemp_roll = test_ts_grouped.rolling('30D', on ='visitStartTime')['visitNumber'].count().reset_index().add_suffix('_30D')\ntest_ts = pd.concat([test_ts, temp_roll['visitNumber_30D']], axis = 1)\n\ntest_ts['index'] = test_ts['index'].astype('int')\ntest_ts.set_index('index', inplace = True)\ntest_ts.sort_index(inplace = True)\ntest_df = test_ts.copy()\ndel test_ts\n\n","9dbf1e58":"test_df.info()","d40af1f8":"train_df.to_pickle('train_flat_FE.pkl')\ntest_df.to_pickle('test_flat_FE.pkl')","f5964577":"%%time\n#Categorical encoding\nfor c in cat_cols:\n    #Convert NAs to unknown\n    train_df[c] = train_df[c].fillna('unknown')\n    test_df[c] = test_df[c].fillna('unknown')\n\n\n#Rename \"Other\" those with less than 10\nfor col in cat_cols:\n    #For train data\n    series1 = pd.value_counts(train_df[col])\n    mask1 = series1 < 10\n    train_df[col] = np.where(train_df[col].isin(series1[mask1].index),'Other_{}'.format(col), train_df[col])\n    \n    #For test data\n    series2 = pd.value_counts(test_df[col])\n    mask2 = series2 < 10\n    test_df[col] = np.where(test_df[col].isin(series2[mask2].index),'Other_{}'.format(col), test_df[col])\n    ","ae4ca684":"%%time\ninteract_cats = ['channelGrouping', 'device.operatingSystem',\n                'geoNetwork.city', 'geoNetwork.country', 'geoNetwork.networkDomain',\n                 'trafficSource.medium', \n                'trafficSource.referralPath', 'trafficSource.source']\n\n#2-way interactions\nfrom itertools import combinations\n\ndef categorical_interaction_terms_2(df, columns):\n    for c in combinations(columns,2):\n        df['{}+{}'.format(c[0], c[1]) ] = df[c[0]] + '_' + df[c[1]]\n    return df\n\ndef categorical_interaction_terms_3(df, columns):\n    for c in combinations(columns,3):\n        df['{}+{}+{}'.format(c[0], c[1], c[2]) ] = df[c[0]] + '_' + df[c[1]] + '_' + df[c[2]]\n    return df\n\ntrain_df = categorical_interaction_terms_2(train_df,interact_cats )\n#train_df = categorical_interaction_terms_3(train_df,interact_cats )\n\ntest_df = categorical_interaction_terms_2(test_df,interact_cats )\n#test_df = categorical_interaction_terms_3(test_df,interact_cats )\n\ninteract_cats_to_keep = [ 'geoNetwork.city+geoNetwork.networkDomain',\n  'device.operatingSystem+geoNetwork.networkDomain',\n  'device.operatingSystem+geoNetwork.city', \n  'channelGrouping+geoNetwork.networkDomain',\n  'geoNetwork.city+trafficSource.source',\n 'geoNetwork.networkDomain+trafficSource.source',\n 'geoNetwork.networkDomain+trafficSource.referralPath',\n 'geoNetwork.networkDomain+trafficSource.medium',\n 'geoNetwork.city+trafficSource.medium',\n 'geoNetwork.city+geoNetwork.country']\n\n","b3373598":"%%time\n\n#Factorize cats\nfor f in (cat_cols + interact_cats_to_keep ):\n    train_df[f], indexer = pd.factorize(train_df[f])\n    test_df[f] = indexer.get_indexer(test_df[f])\n\ndel indexer","d289ec0d":"train_df.to_pickle('train_flat_FE_CAT_LE.pkl')\ntest_df.to_pickle('test_flat_FE_CAT_LE.pkl')","5de7c538":"train_df.info()","09c4cb24":"test_df.info()","14fe653c":"# Categoricals processing ","3f267d37":"test_df['_previous_'] = test_ts.sort_values(['fullVisitorId', 'visitStartTime']).groupby('fullVisitorId')['visitStartTime'].diff()\n\nnum_cols = ['visitNumber', 'totals.bounces', 'totals.hits',\n            'totals.newVisits', 'totals.pageviews', \n            '_local_hourofday'  ]","8273f621":"# Label encoding ","2b4d1240":"# Time since last visit ","3cf54968":"## Previous numerical values "}}