{"cell_type":{"5a7ec80a":"code","1ed076a7":"code","8ed55ef3":"code","96b6026f":"code","09a2241d":"code","44506625":"code","b00c6d4a":"code","688aa471":"code","5c0d7a90":"code","3214d12c":"code","c9fa85d5":"code","538e599e":"code","c0b3e9a3":"code","87d8afc6":"code","e0c5a643":"code","7e22c8e4":"code","b454a655":"code","bc888745":"code","180cd8a9":"code","b4fb7b5b":"code","d4507a50":"code","2615ea24":"code","3b30564b":"code","5b4eb652":"code","9d822d02":"code","c583695e":"markdown","d95d006c":"markdown","68aa289e":"markdown","a1ff7a70":"markdown","0db6420d":"markdown","d933006a":"markdown","5e10a308":"markdown","c532782e":"markdown","a8e0ad80":"markdown","76ccadd2":"markdown","43e1c9f4":"markdown"},"source":{"5a7ec80a":"import os\nimport math\nimport librosa\nimport numpy as np\nfrom sklearn.model_selection import train_test_split\nimport tensorflow.keras as keras\nimport matplotlib.pyplot as plt","1ed076a7":"DATASET_PATH = \"\/kaggle\/input\"\nSAMPLE_RATE = 22050\nTRACK_DURATION = 30 # measured in seconds\nSAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\nnum_mfcc=13\nn_fft=2048\nhop_length=512\nnum_segments = 10\nsamples_per_segment = int(SAMPLES_PER_TRACK \/ num_segments)\nnum_mfcc_vectors_per_segment = math.ceil(samples_per_segment \/ hop_length)","8ed55ef3":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/blues\/blues.00000.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","96b6026f":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/classical\/classical.00000.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","09a2241d":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/country\/country.00004.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","44506625":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/disco\/disco.00013.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","b00c6d4a":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/hiphop\/hiphop.00006.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","688aa471":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/jazz\/jazz.00003.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","5c0d7a90":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/metal\/metal.00007.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","3214d12c":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/pop\/pop.00011.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","c9fa85d5":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/reggae\/reggae.00009.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","538e599e":"import librosa\nimport librosa.display\ny, sr = librosa.load('..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/rock\/rock.00013.wav')\nmel_spect = librosa.feature.melspectrogram(y=y, sr=sr, n_fft=2048, hop_length=1024)\nmel_spect = librosa.power_to_db(mel_spect, ref=np.max)\nlibrosa.display.specshow(mel_spect, y_axis='mel', fmax=8000, x_axis='time');","c0b3e9a3":"# dictionary to store mapping, labels, and MFCCs\ndata = {\n    \"mapping\": [],\n    \"labels\": [],\n    \"mfcc\": []\n}\n# loop through all genre sub-folder\nfor i, (dirpath, dirnames, filenames) in enumerate(os.walk(DATASET_PATH)):\n\n    # ensure we're processing a genre sub-folder level\n    if dirpath is not DATASET_PATH:\n\n        # save genre label (i.e., sub-folder name) in the mapping\n        dirpathSplit = dirpath.split(\"\/\")\n        semantic_label = dirpathSplit[-1]\n        if('genres_original' in dirpathSplit and 'jazz' not in dirpathSplit):\n            data[\"mapping\"].append(semantic_label)\n            print(\"\\nProcessing: {}\".format(semantic_label))\n\n            # process all audio files in genre sub-dir\n            for f in filenames:\n\n            # load audio file\n                file_path = os.path.join(dirpath, f)\n                signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n\n                # process all segments of audio file\n                for d in range(num_segments):\n\n                    # calculate start and finish sample for current segment\n                    start = samples_per_segment * d\n                    finish = start + samples_per_segment\n\n                    # extract mfcc\n                    mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n                    mfcc = mfcc.T\n\n                    # store only mfcc feature with expected number of vectors\n                    if len(mfcc) == num_mfcc_vectors_per_segment:\n                        data[\"mfcc\"].append(mfcc.tolist())\n                        data[\"labels\"].append(i-15)\n                        #print(\"{}, segment:{}\".format(file_path, d+1))\n","87d8afc6":"#print data \nprint(data[\"labels\"])","e0c5a643":"def plot_history(history):\n    fig, axs = plt.subplots(2)\n\n    # create accuracy sublpot\n    axs[0].plot(history.history[\"accuracy\"], label=\"train accuracy\")\n    axs[0].plot(history.history[\"val_accuracy\"], label=\"test accuracy\")\n    axs[0].set_ylabel(\"Accuracy\")\n    axs[0].legend(loc=\"lower right\")\n    axs[0].set_title(\"Accuracy eval\")\n\n    # create error sublpot\n    axs[1].plot(history.history[\"loss\"], label=\"train error\")\n    axs[1].plot(history.history[\"val_loss\"], label=\"test error\")\n    axs[1].set_ylabel(\"Error\")\n    axs[1].set_xlabel(\"Epoch\")\n    axs[1].legend(loc=\"upper right\")\n    axs[1].set_title(\"Error eval\")\n\n    plt.show()","7e22c8e4":"def prepare_datasets(test_size, validation_size):\n\n    # load data\n    X = np.array(data[\"mfcc\"])\n    y = np.array(data[\"labels\"])\n\n    # create train, validation and test split\n    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size)\n    X_train, X_validation, y_train, y_validation = train_test_split(X_train, y_train, test_size=validation_size)\n\n    return X_train, X_validation, X_test, y_train, y_validation, y_test\n","b454a655":"def build_model(input_shape):\n\n    # build network topology\n    model = keras.Sequential()\n\n    # 2 LSTM layers\n    model.add(keras.layers.LSTM(64, input_shape=input_shape, return_sequences=True))\n    model.add(keras.layers.LSTM(64))\n\n    # dense layer\n    model.add(keras.layers.Dense(64, activation='relu'))\n    model.add(keras.layers.Dropout(0.3))\n\n    # output layer\n    model.add(keras.layers.Dense(10, activation='softmax'))\n\n    return model","bc888745":"# get train, validation, test splits\nX_train, X_validation, X_test, y_train, y_validation, y_test = prepare_datasets(0.25, 0.2)","180cd8a9":"# create network\ninput_shape = (X_train.shape[1], X_train.shape[2]) # 130, 13\nmodel = build_model(input_shape)","b4fb7b5b":"# compile model\noptimiser = keras.optimizers.Adam(learning_rate=0.0001)\nmodel.compile(optimizer=optimiser,\n                  loss='sparse_categorical_crossentropy',\n                  metrics=['accuracy'])\nmodel.summary()","d4507a50":"# train model\nhistory = model.fit(X_train, y_train, validation_data=(X_validation, y_validation), batch_size=32, epochs=30)","2615ea24":"# plot accuracy\/error for training and validation\nplot_history(history)","3b30564b":"# evaluate model on test set\ntest_loss, test_acc = model.evaluate(X_test, y_test, verbose=2)\nprint('\\nTest accuracy:', test_acc)","5b4eb652":"def predict(model, X, y):\n    X = X[np.newaxis,...]\n    prediction = model.predict(X)\n    predicted_index = np.argmax(prediction, axis=1)\n    print(f\"Expected index: {y}, Predicted index: {predicted_index}\")","9d822d02":"predict(model, X_test[1], y_test[1])","c583695e":"## Rock","d95d006c":"## Jazz","68aa289e":"## Metal","a1ff7a70":"## Blues","0db6420d":"## Hiphop","d933006a":"## Classical","5e10a308":"## Country","c532782e":"## Reggae","a8e0ad80":"## Pop","76ccadd2":"## Disco","43e1c9f4":"# **Data Visualization**"}}