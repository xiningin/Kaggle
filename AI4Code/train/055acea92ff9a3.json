{"cell_type":{"4b63a56f":"code","9d236b36":"code","daca0542":"code","2dba4095":"code","ac086063":"code","9c385ecf":"code","4d1f6c24":"code","31e93919":"code","cf5a428c":"code","f60dec2c":"code","5cad5a60":"code","2dafafe3":"code","1cd2b605":"code","3b20c160":"code","d60e43dd":"code","43f65e13":"code","e9efcf5f":"code","eacc47ee":"code","de35d3c6":"markdown","d8698096":"markdown","d02609da":"markdown","c07d0c8c":"markdown","70fe6b13":"markdown","87ba6ac8":"markdown","5ec23c94":"markdown","ca0f4328":"markdown","08df63f4":"markdown","8b1662c5":"markdown","ccabf0d8":"markdown","1884f25a":"markdown","24f012d4":"markdown","c2afdf54":"markdown","3b447f3f":"markdown"},"source":{"4b63a56f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\n# Any results you write to the current directory are saved as output.","9d236b36":"from time import time\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport cv2\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns; sns.set()\n#from IPython.display import SVG\n#from keras.utils.vis_utils import model_to_dot\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report\n#from sklearn.metrics import confusion_matrix\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Convolution2D, MaxPooling2D, GlobalAveragePooling2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.preprocessing.image import ImageDataGenerator","daca0542":"name = \"version_01\"\n\n# read data (only the first time)\nread_image = True\n\n# number of epochs to train:\nepochs = 4\n\n# Pixel size for image resizeing:\npixel_x = 32\npixel_y = 32\n\n# batch size\nbatch_size = 32","2dba4095":"t = time()\nif read_image:\n    # set directories for images\n    p_pa = os.path.join(os.getcwd(), '..\/input\/cell_images\/cell_images\/Parasitized')\n    p_un = os.path.join(os.getcwd(), '..\/input\/cell_images\/cell_images\/Uninfected')\n\n    d_pa = [os.path.join(p_pa, f) for f in os.listdir(p_pa) if f.endswith('.png')]\n    d_un = [os.path.join(p_un, f) for f in os.listdir(p_un) if f.endswith('.png')]\n\n    # data container:\n    N = len(d_pa) + len(d_un)\n    X_all = np.zeros((N, pixel_x, pixel_y, 3))\n    y_all = np.zeros(N)\n\n    # read parasitized images and set label = 1:\n    counter = 0\n    for file in d_pa:\n        img = plt.imread(file)\n        img = cv2.resize(img, (pixel_x, pixel_y))\n        X_all[counter] = img\n        counter += 1\n    y_all[:counter] = 1\n\n    # read uninfected images and set label = 0:\n    for file in d_un:\n        img = plt.imread(file)\n        img = cv2.resize(img, (pixel_x, pixel_y))\n        X_all[counter] = img\n        counter += 1\n    y_all[counter:] = 0\n\n    # save images as numpy variables:\n    np.save(\"X_all.npy\", X_all)\n    np.save(\"y_all.npy\", y_all)\n\nelse:\n    # load image numpy arrays:\n    X_all = np.load(\"X_all.npy\")\n    y_all = np.load(\"y_all.npy\")\n    pixel_x = X_all.shape[1]\n    pixel_y = X_all.shape[2]\n    \nprint(\"Delta Time for execution: {:.2f} sec\".format(time()-t))","ac086063":"fig, axes = plt.subplots(nrows=1, ncols=4, figsize=(10,5))\n\nn_pa = 1; n_un = 26000\naxes[0].imshow(X_all[n_pa])\naxes[0].set_title('Label: {:d}'.format(int(y_all[n_pa])))\naxes[0].grid(False)\naxes[1].imshow(X_all[n_un])\naxes[1].set_title('Label: {:d}'.format(int(y_all[n_un])))\naxes[1].grid(False)\n\nn_pa = 25339; n_un = 10212\nnpa=2; nui=10212\naxes[2].imshow(X_all[n_pa])\naxes[2].set_title('Label: {:d}'.format(int(y_all[n_pa])))\naxes[2].grid(False)\naxes[3].imshow(X_all[n_un])\naxes[3].set_title('Label: {:d}'.format(int(y_all[n_un])))\naxes[3].grid(False)\n\nplt.show()","9c385ecf":"np.random.seed(seed=42)\ndisorder = np.arange(X_all.shape[0])\nprint(disorder[:10])\nnp.random.shuffle(disorder)\nprint(disorder[:10])\nX_all = X_all[disorder]\ny_all = y_all[disorder]","4d1f6c24":"# Test set (20%) for final rating. This set is to be used only at the very end!!\nX, X_test, y, y_test = train_test_split(X_all, y_all, test_size = 0.2, random_state=42)\n\n# Traing and validation set to optimize the CNN:\n# Val set (20% from total => 25% from the X, y above)\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size = 0.25, random_state=42)\n\nprint(\"X_train shape: \", X_train.shape)\nprint(\"X_val shape:   \", X_val.shape)\nprint(\"X_test shape:  \", X_test.shape)\n\ny_train = pd.get_dummies(y_train).values\ny_val= pd.get_dummies(y_val).values\ny_test = pd.get_dummies(y_test).values\n\nprint(\"\")\nprint(\"y_train shape after encoding: \", y_train.shape)\nprint(\"y_val shape after encoding:   \", y_val.shape)\nprint(\"y_test shape after encoding:  \", y_test.shape)","31e93919":"# normalize only on training data\nX_mean = np.mean(X_train, axis=0)\nX_std = np.std(X_train, axis=0)\n\n# apply the nomalized values from the training data to all sets\nX_train_norm = np.array((X_train - X_mean)\/(X_std + 0.0002), dtype=\"float32\")\nX_val_norm = np.array((X_val - X_mean)\/(X_std + 0.0002), dtype=\"float32\")\nX_test_norm = np.array((X_test - X_mean)\/(X_std + 0.0002), dtype=\"float32\")","cf5a428c":"datagen = ImageDataGenerator(rotation_range=20,          #Int. Degree range for random rotations\n                             width_shift_range=0.2,      #float: fraction of total width, if < 1, or pixels if >= 1.\n                             height_shift_range=0.2,\n                             horizontal_flip=True,\n                             vertical_flip=True,\n                             zoom_range=0.2)             #Float or [lower, upper],\n\ntrain_generator = datagen.flow(x=X_train_norm, \n                               y=y_train, \n                               batch_size=batch_size, \n                               shuffle = True)","f60dec2c":"model = Sequential()\n\n# CNN 1\nmodel.add(Convolution2D(16, (3, 3), padding='same', input_shape=(pixel_x, pixel_y,3)))\nmodel.add(Convolution2D(16, (1, 1), padding='same'))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n# CNN 2\nmodel.add(Convolution2D(16, (3, 3), padding='same'))\nmodel.add(Convolution2D(16, (1, 1), padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n# CNN 3\nmodel.add(Convolution2D(24, (3, 3), padding='same'))\nmodel.add(Convolution2D(24, (1, 1), padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n# CNN 4\nmodel.add(Convolution2D(24, (3, 3), padding='same'))\nmodel.add(Convolution2D(24, (1, 1), padding='same'))\nmodel.add(MaxPooling2D(pool_size=2))\nmodel.add(BatchNormalization())\nmodel.add(Activation('relu'))\n\n# fcNN\nmodel.add(Flatten())\nmodel.add(Dense(2, activation='softmax'))\n\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\nmodel.summary()","5cad5a60":"model.evaluate(X_train_norm, y_train)","2dafafe3":"#nn = 'tensorboard\/malaria\/' + name + '\/'\n#tensorboard = keras.callbacks.TensorBoard(nn, write_graph=True, histogram_freq=1)","1cd2b605":"t = time()\n\nhistory = model.fit_generator(train_generator,\n                              steps_per_epoch = int(X_train_norm.shape[0]\/10),\n                              epochs=epochs,\n                              verbose=1,\n                              validation_data=(X_val_norm, y_val))#\n                              #,callbacks=[tensorboard])\n\nprint(\"\\nDelta Time for execution: {:.2f} min.\\n\".format((time() - t)\/60))","3b20c160":"model.save(name)","d60e43dd":"# summarize history for accuracy\nimport seaborn as sns; sns.set()\n\nt_acc = max(history.history['acc'])\nv_acc = max(history.history['val_acc'])\n\nfig, axes = plt.subplots(nrows=1, ncols=2, figsize=(12,5))\naxes[0].plot(history.history['acc'], color='royalblue', label='training')\naxes[0].plot(history.history['val_acc'], color='red', label='validation')\naxes[0].set_title('Model Accuracy: train:  {:0.2f}%;  val: {:0.2f}%'.format(t_acc*100, v_acc*100))\naxes[0].set_xlabel('epoch')\naxes[0].set_ylabel('accuracy')\naxes[0].set_ylim((-0.1, 1.1))\naxes[0].legend(loc=\"lower right\", frameon=True, shadow=True)\n\naxes[1].plot(history.history['loss'], color='royalblue', label='training')\naxes[1].plot(history.history['val_loss'], color='red', label='validation')\naxes[1].set_title('Model loss (name:'+name+')')\naxes[1].set_xlabel('epoch')\naxes[1].set_ylabel('loss')\naxes[1].set_ylim((-0.1, 2.5))\naxes[1].legend(loc=\"upper right\", frameon=True, shadow=True)\nplt.tight_layout()\nplt.savefig(name+'.png', dpi=400, bbox_inches='tight')\nplt.show()","43f65e13":"y_pred = model.predict(X_train_norm)\n\nprint(\"Accuracy = {:0.2f}%\".format(np.sum(y_train[:,1] == np.argmax(y_pred, axis=1)) \/ len(y_pred) * 100))\nprint(classification_report(y_train[:,1], np.argmax(y_pred, axis=1)))","e9efcf5f":"y_pred = model.predict(X_val_norm)\n\nprint(\"Accuracy = {:0.2f}%\".format(np.sum(y_val[:,1] == np.argmax(y_pred, axis=1)) \/ len(y_pred) * 100))\nprint(classification_report(y_val[:,1], np.argmax(y_pred, axis=1)))","eacc47ee":"y_pred = model.predict(X_test_norm)\n\nprint(\"Acc = {:0.2f}%\".format(np.sum(y_test[:,1] == np.argmax(y_pred, axis=1)) \/ len(y_pred) * 100))\nprint(classification_report(y_test[:,1], np.argmax(y_pred, axis=1)))","de35d3c6":"## Data preparation","d8698096":"# Malaria Cell Images Data Set\n**Input:** images from data set<br>\n**Output:** graphical analysis<br>\n**Functions:** none<br>\n**Notebook:** Malaria_Kaggle_V1.ipynb<br>\n**Version:** V1<br>\n**Author:** Pascal Wenger<br>\n**Created:** 2019-03-01<br>\n**Updated:** 2019-04-06<br>","d02609da":"### Data augmentation (on the fly)","c07d0c8c":"### Train data:","70fe6b13":"## Definition of CNN","87ba6ac8":"### Split: training (60%), validation (20%), and test (20%) data, respectively","5ec23c94":"### Validation data:","ca0f4328":"### Training","08df63f4":"### Shuffle image order:","8b1662c5":"### Normalize data:","ccabf0d8":"## Parameter setting","1884f25a":"### Read Data, shape RBG images and save images as numpy arrays","24f012d4":"### Show image examples:","c2afdf54":"### Test data:","3b447f3f":"## Testing"}}