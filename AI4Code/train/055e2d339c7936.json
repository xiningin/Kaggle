{"cell_type":{"e6cbc219":"code","4f52f42f":"code","fa9e26c4":"code","4f8785dd":"code","f4fc84f6":"code","6946a2ce":"code","aa1a278e":"code","6321a0db":"code","7181f4b3":"code","048bda1d":"code","9a30cd9e":"code","41c242ae":"code","15dd7ea7":"code","28cc7793":"code","4e5a0e7a":"code","0c9fdc33":"code","8b2510d1":"code","43e2f0d5":"code","df8dec12":"code","ee35517f":"code","54773270":"code","aa2d4630":"code","681c15f9":"code","2c82c5f3":"code","2440f2e7":"code","79d75ccc":"markdown","5ddd78bf":"markdown","a3211aac":"markdown","6b9e7a0b":"markdown","06764c7f":"markdown","aae08239":"markdown","5572e821":"markdown","51096ba5":"markdown","5a9483aa":"markdown","3356bdd3":"markdown","137c00d7":"markdown","5c995ca9":"markdown","65c43b02":"markdown","d8ea91e1":"markdown","57102438":"markdown","b9ebda3e":"markdown","73f27561":"markdown","247a7068":"markdown","e3e8a826":"markdown","b06ad672":"markdown","da4845ad":"markdown","26c7790e":"markdown"},"source":{"e6cbc219":"import os\nimport sys\nimport numpy as np\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# To reduce output size while working with vscode\n%config InlineBackend.figure_format = 'png'\n\n%matplotlib inline\n\n# Display all columns\npd.options.display.max_columns = None\n\nFIGURES_PATH = \"plots\/\"\n\ndef save_fig(name, extension=\"png\", resolution=300):\n    os.makedirs(FIGURES_PATH, exist_ok=True)\n    path = os.path.join(FIGURES_PATH, name + \".\" + extension)\n    # print(\"Saving figure\", name)\n    plt.tight_layout()\n    plt.savefig(path, format=extension, dpi=resolution)\n\nnp.random.seed(42)","4f52f42f":"AUDI_DATASET_PATH = \"..\/input\/used-car-dataset-ford-and-mercedes\/audi.csv\"\n\naudi_orig = pd.read_csv(AUDI_DATASET_PATH)","fa9e26c4":"audi = audi_orig.copy()\naudi","4f8785dd":"audi.describe()","f4fc84f6":"audi.info()","6946a2ce":"num_attribs = audi_orig.select_dtypes(\"number\").columns.to_numpy()\ncat_attribs = audi_orig.select_dtypes(\"object\").columns.to_numpy()","aa1a278e":"audi.hist(figsize=(15, 10), bins=30)\nsave_fig(\"audi_numerical_hist\")\nfor cat in cat_attribs:\n    plt.subplots(figsize=(10, 4))\n    sns.countplot(cat, data=audi, order=audi[cat].value_counts().index)\n    save_fig(f\"audi_{cat}_hist\")","6321a0db":"from sklearn.model_selection import train_test_split\naudi_train, audi_test = train_test_split(audi_orig, random_state=42, test_size=0.2)","7181f4b3":"print(\"Train:\\t\", audi_train.shape)\nprint(\"Test:\\t\", audi_test.shape)","048bda1d":"from pandas.plotting import scatter_matrix\n\nattribs = num_attribs\n\nscatter_matrix(audi[attribs], figsize=(12, 10))\nsave_fig(\"audi_scatter_matrix\")","9a30cd9e":"corr = audi[num_attribs].corr()\ncorr[\"price\"].sort_values(ascending=False)","41c242ae":"audi_corr = audi_train.copy()\n\ncolumns_search = num_attribs[num_attribs != \"price\"]\nfor i in columns_search:\n    for j in columns_search:\n        if i != j:\n            i_num = audi[columns_search].columns.get_loc(i)\n            j_num = audi[columns_search].columns.get_loc(j)\n            audi_corr[(i_num, j_num)] = audi_corr[i] \/ audi_corr[j]\n\ncorrelations = audi_corr.corr()[\"price\"]\ncorrelations = correlations[~correlations.index.isin(num_attribs)].abs().sort_values()\ncorrelations","15dd7ea7":"def divided_attributes(X, min_corr=0.7):\n    new_attribs = []\n    for i, j in correlations[correlations >= min_corr].index:\n        new_attribs.append((X[:, i] \/ X[:, j]).reshape((-1, 1)))\n    new_attribs = np.concatenate(new_attribs, axis=1)\n    return np.concatenate((X, new_attribs), axis=1)","28cc7793":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import PolynomialFeatures, FunctionTransformer, StandardScaler, OneHotEncoder, Normalizer\nfrom sklearn.compose import ColumnTransformer","4e5a0e7a":"X_train = audi_train.drop(\"price\", axis=1)\nX_test = audi_test.drop(\"price\", axis=1)\ny_train = audi_train[[\"price\"]].to_numpy()\ny_test = audi_test[[\"price\"]].to_numpy()","0c9fdc33":"num_attribs = X_train.select_dtypes(\"number\").columns\ncat_attribs = X_train.select_dtypes(\"object\").columns","8b2510d1":"num_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"median\")),\n    (\"additional_attribs\", FunctionTransformer(divided_attributes, kw_args={\"min_corr\":0.65})),\n    (\"polynomial_attribs\", PolynomialFeatures(degree=2)),\n    (\"scaler\", StandardScaler()),\n])\n\ncat_pipeline = Pipeline([\n    (\"imputer\", SimpleImputer(strategy=\"most_frequent\")),\n    (\"encoder\", OneHotEncoder(handle_unknown=\"ignore\")),\n])\n\nfull_pipeline = ColumnTransformer([\n    (\"num\", num_pipeline, num_attribs),\n    (\"cat\", cat_pipeline, cat_attribs),\n])\n\nlabel_pipeline = Pipeline([\n    (\"scaler\", StandardScaler()),\n])","43e2f0d5":"X_train = full_pipeline.fit_transform(X_train, y_train)\nX_test = full_pipeline.transform(X_test)\n\ny_train = label_pipeline.fit_transform(y_train)\n\ny_test = label_pipeline.transform(y_test)","df8dec12":"from sklearn.metrics import r2_score\nfrom sklearn.model_selection import cross_val_score\n\ndef train_evaluate(model, X_train, y_train, X_test, y_test, cv=10):\n    model.fit(X_train, y_train)\n    scores = cross_val_score(model, X_test, y_test, cv=cv, scoring=\"neg_mean_absolute_error\")\n    print(\"Model:\\t\", model)\n    print(\"Mean MAE:\\t\", -scores.mean())\n    print(\"StD MAE:\\t\", scores.std())","ee35517f":"%%time\nfrom sklearn.tree import DecisionTreeRegressor\n\ntrain_evaluate(DecisionTreeRegressor(), X_train, y_train, X_train, y_train)","54773270":"\"\"\"\n%%time\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {\"max_depth\": [12, 15, 17, 20],\n     \"splitter\": [\"random\", \"best\"],\n     \"random_state\": [42],\n     \"min_samples_split\": [3, 4, 5, 6]}\n]\n\ntree = DecisionTreeRegressor()\ngrid_search = GridSearchCV(tree, param_grid, cv=10, scoring=\"neg_mean_absolute_error\", verbose=1)\ngrid_search.fit(X_train, y_train)\n\nprint(\"Best params:\\t\", grid_search.best_params_)\nprint(\"Best MAE:\\t\", -grid_search.best_score_)\nbest_tree = grid_search.best_estimator_\n\"\"\"\nbest_tree = DecisionTreeRegressor(max_depth=12, min_samples_split=3, splitter=\"random\", random_state=42)\ntrain_evaluate(best_tree, X_train, y_train, X_train, y_train)","aa2d4630":"%%time\nfrom sklearn.ensemble import RandomForestRegressor\n\ntrain_evaluate(RandomForestRegressor(n_jobs=16), X_train, y_train.ravel(), X_train, y_train.ravel())","681c15f9":"\"\"\"\n%%time\nfrom sklearn.model_selection import GridSearchCV\n\nparam_grid = [\n    {\"n_estimators\": [200],\n     \"random_state\": [42],\n     \"warm_start\": [True, False],\n     \"oob_score\": [True, False],\n     \"bootstrap\": [True, False],\n     \"min_samples_split\": [7, 8]}\n]\n\nforest = RandomForestRegressor()\ngrid_search = GridSearchCV(forest, param_grid, cv=10, scoring=\"neg_mean_absolute_error\", verbose=1, n_jobs=16)\ngrid_search.fit(X_train, y_train.ravel())\n\nprint(\"Best params:\\t\", grid_search.best_params_)\nprint(\"Best MAE:\\t\", -grid_search.best_score_)\nbest_forest = grid_search.best_estimator_\n\"\"\"\nbest_forest = RandomForestRegressor(bootstrap=True, min_samples_split=7, n_estimators=200, \n                                    oob_score=True, random_state=42, warm_start=True, n_jobs=16)\ntrain_evaluate(best_forest, X_train, y_train.ravel(), X_train, y_train.ravel())","2c82c5f3":"predictions = best_forest.predict(X_test)","2440f2e7":"from sklearn.metrics import r2_score, mean_absolute_error\n \nfinal_r2 = r2_score(y_test, predictions)\nfinal_mae = mean_absolute_error(y_test, predictions)\n\nprint(\"Final R\u00b2:\\t\", final_r2)\nprint(\"Final MAE:\\t\", final_mae)","79d75ccc":"## Discovering data","5ddd78bf":"Try to divide each attribute by another. Maybe some interesting correlations will appear.","a3211aac":"## Splitting into test and train data","6b9e7a0b":"# Building models","06764c7f":"## Preparing data","aae08239":"# Predicting Car Prizes","5572e821":"Create a method which add new attributes to the dataframe. It will be used later.","51096ba5":"Firstly, create a copy of the original dataframe:","5a9483aa":"Transform the data:","3356bdd3":"Define pipelines for data transformations:","137c00d7":"### Decision Tree Regression","5c995ca9":"Split into X and y:","65c43b02":"Draw histograms to better know the data.","d8ea91e1":"Calculate Pearson correlation coefficient:","57102438":"# Audi\nPredicting Audi prices.","b9ebda3e":"## Having a look at data","73f27561":"### Random Forest Regression","247a7068":"Setting up the notebook, loading necessary libraries, defining some useful methods:","e3e8a826":"There are no missing values, everything looks ok for now.\n\nGet the names of numerical and categorical columns:","b06ad672":"Draw some plots about the correlation of attributes:","da4845ad":"## Final Predictions","26c7790e":"Loading data form CSV files:"}}