{"cell_type":{"f557ced5":"code","04dbeaf3":"code","94b8e54b":"code","67bbf66f":"code","9675bd18":"code","168885ae":"code","3e9c0812":"code","65eb3d49":"code","591d4af2":"code","0767b2b2":"code","02fbb3c2":"code","0cec7ee6":"code","ed1c17ca":"code","171e09b3":"code","5c259b68":"code","0d9d3a6f":"code","24e47718":"code","0a133aa0":"code","78b4fe1e":"code","5f78ebab":"code","e49da647":"code","19998f52":"code","0426f051":"code","b8f5ae51":"code","0c11178d":"code","4c036f89":"code","34847188":"code","ba4c0d1d":"code","f7c1b9f0":"code","1b54a259":"markdown","bf902e95":"markdown","2951a722":"markdown","68a82c9c":"markdown","03cadcb1":"markdown","51b2b3e3":"markdown","845e4215":"markdown","ddbc9880":"markdown","5ae16867":"markdown","7a0f02d6":"markdown","b58a667a":"markdown","197b03b8":"markdown","e109859c":"markdown","53dbe778":"markdown","ab8f4786":"markdown","e0102444":"markdown","48df8bb8":"markdown"},"source":{"f557ced5":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os\nimport tensorflow as tf\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n%matplotlib inline","04dbeaf3":"## Loading data\n\n(x_train, y_train), (x_test, y_test) = tf.keras.datasets.mnist.load_data()","94b8e54b":"## Shapes\n\nprint('X_train shape :', x_train.shape)\nprint('y_train shape :', y_train.shape)","67bbf66f":"## Let's visualize first 3 data points.\n\nfig, ax = plt.subplots(1,3, figsize=(16,4))\nfor i in range(3):\n    image = np.reshape(x_train[i], (28, 28))\n    ax[i].imshow(image, cmap='Greys');","9675bd18":"# Create validation data on train data\n\nx_valid = x_train[48000:]\ny_valid = y_train[48000:]\n\nx_train = x_train[:48000]\ny_train = y_train[:48000]","168885ae":"print(x_train.shape[0], 'train samples')\nprint(x_valid.shape[0], 'validation samples')\nprint(x_test.shape[0], 'test samples')","3e9c0812":"# Flattening the images from the 28x28 pixels to 1D\n\nx_train = x_train.reshape(x_train.shape[0], 28, 28, 1)\nx_valid = x_valid.reshape(x_valid.shape[0], 28, 28, 1)\nx_test = x_test.reshape(x_test.shape[0], 28, 28, 1)","65eb3d49":"x_train = x_train.astype('float32')\nx_valid = x_valid.astype('float32')\nx_test = x_test.astype('float32')","591d4af2":"# Normalizing pixel values (0-255) > (0-1)\n\nx_train \/= 255\nx_test \/= 255","0767b2b2":"# One-hot encoding using keras\n\nfrom tensorflow.keras.utils import to_categorical\n\ny_train = to_categorical(y_train, 10)\ny_valid = to_categorical(y_valid, 10)\ny_test = to_categorical(y_test, 10)","02fbb3c2":"# Building a linear stack of layers with the sequential model\n\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Conv2D, MaxPool2D, Flatten\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import categorical_crossentropy\n\nmodel = Sequential()\n\n# convolutional layer\nmodel.add(Conv2D(32, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(64, kernel_size=(3,3), strides=(1,1), activation='relu', input_shape=(28,28,1)))\nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n# flatten output of conv\nmodel.add(Flatten())\n\n# hidden layer\nmodel.add(Dense(32, activation='relu'))\n\n# output layer\nmodel.add(Dense(10, activation='softmax'))","0cec7ee6":"model.summary()","ed1c17ca":"from tensorflow.keras.utils import plot_model\nplot_model(model)","171e09b3":"# compiling the sequential model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","5c259b68":"# training the model for 2 epochs\nhistory = model.fit(x_train, y_train, batch_size=128, epochs=3, validation_data=(x_valid, y_valid))\nhistory","0d9d3a6f":"test_scores = model.evaluate(x_test, y_test,verbose = 0)\n\nprint(\"Train Accuracy =\", history.history['accuracy'][-1])\nprint(\"Validation Accuracy =\", history.history['val_accuracy'][-1])\nprint('Test accuracy:', test_scores[1])\nprint(\"--------------------------------------\")\nprint(\"Train Loss =\", history.history['loss'][-1])\nprint(\"Validation Loss =\", history.history['val_loss'][-1])\nprint('Test loss:', test_scores[0])","24e47718":"fig = plt.figure()\nplt.figure(figsize=(12,6))\nplt.subplot(2,1,1)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='lower right')\nplt.subplot(2,1,2)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.tight_layout()\nfig;","0a133aa0":"(x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()","78b4fe1e":"x = x_train.reshape(60000,784)","5f78ebab":"from sklearn.preprocessing import StandardScaler\nx = StandardScaler().fit_transform(x)","e49da647":"from sklearn.decomposition import TruncatedSVD\ntsvd = TruncatedSVD(n_components=50).fit_transform(x)","19998f52":"from sklearn.manifold import TSNE\ntsne_res = TSNE(n_components=2, n_jobs = -1, random_state = 42).fit_transform(tsvd)","0426f051":"import seaborn as sns\n\nplt.figure(figsize=(14, 14))\nplt.title(\"Visualization of t-SNE results on MNIST train data\", fontsize=24, weight='bold')\nsns.scatterplot(tsne_res[:, 0], tsne_res[:, 1], data = tsne_res, hue=y_train, palette=\"bright\", legend=\"full\")\nplt.xticks(fontsize=14)\nplt.yticks(fontsize=14)\nplt.xlabel(\"Component 1\", fontsize=16)\nplt.ylabel(\"Component 2\", fontsize=16)\nplt.legend(fontsize=16);","b8f5ae51":"(x_train,y_train), (x_test,y_test) = tf.keras.datasets.mnist.load_data()\nx_train = pd.DataFrame(x_train.reshape(60000,x_train.shape[1]**2))","0c11178d":"x_train.head()","4c036f89":"from sklearn.decomposition import PCA\n\npca = PCA(n_components = 5)\npca_data = pca.fit_transform(x_train)\ninverse_pca_data = pca.inverse_transform(pca_data)\n\nprint(\"x_train shape\",x_train.shape)\nprint(\"pca_data shape\",pca_data.shape)\nprint(\"inverse_pca_data shape\",inverse_pca_data.shape)","34847188":"# Reconstruction Error\nMSE = ((x_train-inverse_pca_data)**2).sum(axis=1)","ba4c0d1d":"# Visualization 20 digits with the highest MSE ( decreasing from left to right )\n\nMSE_max_scores = MSE.nlargest(20).index\n\nplt.figure(figsize = (18,10))\n\nfor i in range(20):  \n    plt.subplot(4, 5, i+1)\n    plt.imshow(x_train.iloc[MSE_max_scores[i]].values.reshape(28,28),interpolation='nearest', cmap='Greys')\nplt.show()","f7c1b9f0":"# 3 photos of each digit with the highest MSE\n\nplt.figure(figsize = (20,15))\nrow, colums = 3, 10\n    \nfor number in range(10):\n    dataset = pd.DataFrame(x_train[(y_train == number)].reset_index().drop(\"index\",axis = 1))\n    pca = PCA(n_components = 5)\n    pca_dataset = pca.fit_transform(dataset)\n\n    inverse_transform_dataset = pca.inverse_transform(pca_dataset)\n    MSE_score = ((dataset-inverse_transform_dataset)**2).sum(axis=1)\n    MSE_worst = MSE_score.nlargest(3).index\n    for number2 in range(0,3):\n        plt.subplot(colums, row, (number2+(number*3))+ 1)\n        plt.imshow(dataset.iloc[MSE_worst[number2]].values.reshape(28,28),interpolation='nearest', cmap='Greys')\nplt.show()","1b54a259":"<pre>\n\nWhen we look at the performance metrics, it is possible to say that the model learns very well and makes predictions with very high accuracy in the test data.\n\n<\/pre>","bf902e95":"<pre>\n\nCNN method has the best accuracy result and also the worst source performance compared to other methods according by literature. Especially, the feature extraction layer in CNN can capture the sharp and important points of the image that comes from the numbers.The structure of a CNN is actually very similar to Regular Neural Networks. Just like in RegularNets, we use a loss function and an optimizer in CNNs. Additionally, in CNNs, there are also Convolutional Layers, Pooling Layers, and Flatten Layers. So I thought CNN was the most appropriate method.\n\n<\/pre>","2951a722":"## Preprocessing Before Model","68a82c9c":"<font color='orange'>**We will use t-SNE as the model for 2 dimension, but before we will use TruncatedSVD to reduce the dimension to 50. Because, in essence, tSNE requires pairwise comparison of datapoints, so it can be incredibly computationally taxing on scRNA-seq datasets unless the dimensionality undergoes an initial reduction.**","03cadcb1":"**Data**: The MNIST database (Modified National Institute of Standards and Technology database) is a large database of handwritten digits that is commonly used for training various image processing systems. Some examples from the MNIST are below: ","51b2b3e3":"## Anomally Detection with PCA","845e4215":"<font color='blue'>*Created with* \u2764 *by Mustafa Batuhan Ermi\u015f.*<font>","ddbc9880":"# Image Classification & Anomaly Detection","5ae16867":"## 2D Visualizing Data in 2D Latent Dimensions with t-SNE","7a0f02d6":"#### t-SNE","b58a667a":"## Building Classification Model","197b03b8":"Some interesting findings:\n\n<pre>\nWe can see that images of 7 are more close to images of 9 than images of 1. Also when we look at the middle region, it is remarkable that 3, 5 and 8 are more confused with each other because they are similar numbers compared to other groups. Since the algorithm separates the corners well, it is seen that 9 and 6 are very far from each other. The fact that 4 is very close to 9 may indicate that there are anomalies in these pictures.\n<\/pre>","e109859c":"## Data Description","53dbe778":"#### TruncatedSVD","ab8f4786":"#### t-SNE Visualization","e0102444":"## Measurement Model Performance","48df8bb8":"<pre>\nThe technique roughly calculates the distance between the projection of the subspace created by PCA for each data point and the original data point. ( MSE as Reconstruction Error ) \n\nThe larger this distance is, the more abnormal the initial image is. Because, even when a decent photograph is reduced to subspace, its structure is not deformed beyond recognition.\n<\/pre>"}}