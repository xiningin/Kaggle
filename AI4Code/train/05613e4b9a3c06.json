{"cell_type":{"0aca0474":"code","99af5119":"code","4f641662":"code","d7d82917":"code","96d69fac":"code","6ae7bcdf":"code","f70786af":"code","c40aeb75":"code","0cab387c":"code","87c6eb1c":"code","ab90cdff":"code","f08971a6":"code","07087af9":"code","89ef64ef":"code","fa740f4c":"code","24ed7851":"code","b54a50b3":"code","a35ce967":"code","5e4bf502":"code","53548642":"code","c466307b":"code","0e938c61":"code","4e92dfb0":"markdown","f8715829":"markdown","5d774c75":"markdown","b32aa9b8":"markdown","e134819e":"markdown","c800a738":"markdown","897c10cc":"markdown","6bc6cc9e":"markdown","be90207f":"markdown"},"source":{"0aca0474":"import numpy as np\nimport os\nimport pandas as pd\nfrom fastai.vision.all import *","99af5119":"set_seed(999,reproducible=True)","4f641662":"dataset_path = Path('..\/input\/cassava-leaf-disease-classification')\nos.listdir(dataset_path)","d7d82917":"train_df = pd.read_csv(dataset_path\/'train.csv')","96d69fac":"train_df.head()","6ae7bcdf":"train_df['path'] = train_df['image_id'].map(lambda x:dataset_path\/'train_images'\/x)\ntrain_df = train_df.drop(columns=['image_id'])\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\ntrain_df.head(10)","f70786af":"len_df = len(train_df)\nprint(f\"There are {len_df} images\")\n","c40aeb75":"#delete part of label 3 data. Makes result worse!!! \n#0.3 frac gives about 76% accuracy, \n#0.7 frac gives about 82% accuracy\n\n#filtered_train_df = train_df[train_df['label'] != 3]\n#label3_df = train_df[train_df['label'] == 3]\n#label3_df = label3_df.sample(frac = 0.7)\n\n#result = pd.concat([filtered_train_df,label3_df])\n#train_df = result.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n","0cab387c":"train_df['label'].hist(figsize = (10, 5))\n","87c6eb1c":"item_tfms = RandomResizedCrop(460, min_scale=0.75, ratio=(1.,1.))\nbatch_tfms = [*aug_transforms(size=224, max_warp=0), Normalize.from_stats(*imagenet_stats)]\nbs=256","ab90cdff":"dls = ImageDataLoaders.from_df(train_df, #pass in train DataFrame\n                               valid_pct=0.2, #80-20 train-validation random split\n                               seed=999, #seed\n                               label_col=0, #label is in the first column of the DataFrame\n                               fn_col=1, #filename\/path is in the second column of the DataFrame\n                               bs=bs, #pass in batch size\n                               item_tfms=item_tfms, #pass in item_tfms\n                               batch_tfms=batch_tfms) #pass in batch_tfms","f08971a6":"dls.show_batch()","07087af9":"# Making pretrained weights work without needing to find the default filename\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n        os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/resnet50\/resnet50.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/resnet50-19c8e357.pth'","89ef64ef":"learn = cnn_learner(dls, \n                    resnet50, \n                    loss_func = LabelSmoothingCrossEntropy(), \n                    metrics = [accuracy], \n                    #cbs=MixUp()\n                   ).to_native_fp16()","fa740f4c":"learn.lr_find()","24ed7851":"learn.fine_tune(5,base_lr=1e-2)","b54a50b3":"learn.recorder.plot_loss()","a35ce967":"#Remove CBS to prevent mess up with learn.get_preds, predict, etc\n#learn.remove_cbs([MixUp])","5e4bf502":"learn = learn.to_native_fp32()","53548642":"learn.export()","c466307b":"interp = ClassificationInterpretation.from_learner(learn)","0e938c61":"interp.plot_confusion_matrix()","4e92dfb0":"## Model training:","f8715829":"Put the model back to fp32, and export the model ","5d774c75":"## A look at the data","b32aa9b8":"All dataset >21,000 images\n\nThe distribution of the different classes:","e134819e":"**Checking the confusion matrix:**","c800a738":"Let's start out by setting up our environment by importing the required modules and setting a random seed:","897c10cc":"`learn.fine_tune` trains frozen pretrained model for a single epoch (using one-cycle training), then train the whole pretrained model for several epochs using one-cycle training.","6bc6cc9e":"## Data loading\n* The item transforms performs a large crop on each of the images.\n* The batch transforms performs random resized crop to 224 and also apply other standard augmentations (in `aug_tranforms`) at the batch level on the GPU.\n* The batch size is set to 256 here.\n","be90207f":"Categories\n0. Cassava Bacterial Blight (CBB)\n1. Cassava Brown Streak Disease (CBSD)\n2. Cassava Green Mottle (CGM)\n3. Cassava Mosaic Disease (CMD)\n4. Healthy\n"}}