{"cell_type":{"af624828":"code","1e7319ad":"code","335b3b3a":"code","bf827db3":"code","61a9e36a":"code","6c609613":"code","f11f7865":"code","490629fc":"code","7202c619":"code","41a54a87":"code","6d799f6e":"code","734493b1":"code","4720d424":"code","81dfffa7":"code","62f86b37":"code","f255554b":"code","4da374a0":"code","d0a14f50":"code","89d9282f":"code","a62cf164":"code","6cf39975":"code","60c0a2ff":"code","e31df7d6":"code","bb2ea81c":"code","ee0d0084":"markdown","5298b474":"markdown","8b379d86":"markdown"},"source":{"af624828":"from keras.layers import Input, Conv2D, Lambda, merge, Dense, Flatten,MaxPooling2D,Activation, Dropout, BatchNormalization,  GlobalMaxPool2D, GlobalAvgPool2D, Concatenate, Subtract,Multiply\nfrom keras.models import Model, Sequential\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.optimizers import Adam\nfrom skimage.io import imshow\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nimport random\nimport cv2\nimport os\nfrom tqdm import tqdm","1e7319ad":"!ls ..\/input\/","335b3b3a":"import keras_vggface\nfrom keras.engine import  Model\nfrom keras.layers import Input\nfrom keras_vggface.vggface import VGGFace","bf827db3":"input_train_dir = \"..\/input\/train\/\"\n\ndef train_image():\n    train_image = map(lambda f : os.path.join(input_train_dir, f) , os.listdir(\"%s\" % input_train_dir))\n    train_images = []\n    for f in train_image:\n        for d in os.listdir(f):\n            p = os.path.join(f,d)\n            train_images.extend([os.path.join(p,l) for l in os.listdir(p) ] )\n    \n    return train_images\n\ntrain_images = train_image()\n\n\n","61a9e36a":"def f_path(x):\n    r = []\n    for i in train_images:\n        if x in i:\n            r.append(i)\n    if r != []:\n        return random.choice(r)\n    return x","6c609613":"train_df = pd.read_csv(\"..\/input\/train_relationships.csv\")\ntrain_df['p1_path'] = train_df['p1'].apply(lambda x : f_path(x) )\ntrain_df['p2_path'] = train_df['p2'].apply(lambda x : f_path(x) )\ntrain_df['add'] = train_df['p1'] + train_df['p2']\ntrain_df = train_df[train_df['p1']!=train_df['p1_path']]\ntrain_df = train_df[train_df['p2']!=train_df['p2_path']]\ntrain_df[\"target\"] = 1","f11f7865":"n_shuffle = 1\ntrain_target_0 = pd.concat([ train_df.copy() for i in range(n_shuffle)],ignore_index=True)\ntrain_target_0['target'] = 0\np1_shuffle = train_target_0[['p1','p1_path']].values\nnp.random.shuffle(p1_shuffle)\ntrain_target_0[['p1','p1_path']] = p1_shuffle\np2_shuffle = train_target_0[['p2','p2_path']].values\nnp.random.shuffle(p2_shuffle)\ntrain_target_0[['p2','p2_path']] = p2_shuffle\ntrain_target_0['add'] = train_target_0['p1'] + train_target_0['p2']\ndata_1 = list(train_df['add'].values)\ndata_0 = list(train_target_0['add'].values)\ndata = []\nfor d in data_0:\n    if d in data_1:\n        data.append(d)\ntrain_target_0 = train_target_0[~train_target_0['add'].isin(data)]","490629fc":"train_concate = pd.concat([train_df, train_target_0], ignore_index=True)","7202c619":"train_concate['family1'] = train_concate['p1'].apply(lambda x : x.split('\/')[0])\ntrain_concate['family2'] = train_concate['p2'].apply(lambda x : x.split('\/')[0])\n# Family approach\ntrain_concate['target'] = train_concate[['family1', 'family2']].apply(lambda x : 1 if x['family1'] == x['family2'] else 0, axis=1)","41a54a87":"print('Size of data %d' % len(train_concate))","6d799f6e":"shape = (224,224,3)","734493b1":"train_concate = train_concate.sample(frac=1).reset_index(drop=True)","4720d424":"# We have 2 inputs, 1 for each picture\nleft_input = Input(shape)\nright_input = Input(shape)\n\n# We will use 2 instances of 1 network for this task\nconvnet = Sequential([\n    Conv2D(32,3, input_shape=shape),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(16,3),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(8,2),\n    BatchNormalization(),\n    Activation('relu'),\n    MaxPooling2D(),\n    Conv2D(4,2),\n    BatchNormalization(),\n    Activation('relu'),\n    Flatten(),\n    Dense(2),\n    Activation('sigmoid')\n])\n# Connect each 'leg' of the network to each input\n# Remember, they have the same weights\nencoded_l = convnet(left_input)\nencoded_r = convnet(right_input)\n\n# Getting the L1 Distance between the 2 encodings\nL1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n\n# Add the distance function to the network\nL1_distance = L1_layer([encoded_l, encoded_r])\n\nprediction = Dense(1,activation='sigmoid')(L1_distance)\nsiamese_net = Model(inputs=[left_input,right_input],outputs=prediction)\n\noptimizer = Adam(0.001, decay=2.5e-4)\n#\/\/TODO: get layerwise learning rates and momentum annealing scheme described in paperworking\nsiamese_net.compile(loss=\"binary_crossentropy\",optimizer=optimizer,metrics=['accuracy'])","81dfffa7":"\ndef baseline_model():\n    vgg_features = VGGFace(include_top=False, input_shape=shape, pooling='avg') # pooling: None, avg or max\n    input_1 = Input(shape=shape)\n    input_2 = Input(shape=shape)\n\n    base_model = VGGFace(include_top=False, input_shape=shape, pooling='avg')\n\n    for x in base_model.layers[:-3]:\n        x.trainable = True\n\n    x1 = base_model(input_1)\n    x2 = base_model(input_2)\n\n    \n    \n    \n    L1_layer = Lambda(lambda tensor:K.abs(tensor[0] - tensor[1]))\n\n    # Add the distance function to the network\n    x = L1_layer([x1, x2])\n    out = Dense(1, activation=\"sigmoid\")(x)\n\n    model = Model([input_1, input_2], out)\n\n    model.compile(loss=\"binary_crossentropy\", metrics=['acc'], optimizer=Adam(0.00001))\n\n    model.summary()\n\n    return model","62f86b37":"histories = {\"loss\":[], 'acc' : []}\nhistories_vgg = {\"loss\":[], 'acc' : []}","f255554b":"from tqdm import tqdm_notebook","4da374a0":"batch_size = 16\nfor _ in tqdm_notebook(range(50), desc=\"Epochs ...\"):\n    left_data = []\n    right_data = []\n    targets = []\n    for i in tqdm_notebook(range(len(train_concate)), desc=\"Files process ...\", leave=False):\n        dt = train_concate.iloc[i].to_dict()\n        left_img = cv2.imread(dt['p1_path'])\n        left_img = cv2.resize(left_img, (shape[0], shape[1]))\n        left_data.append(left_img)\n\n        right_img = cv2.imread(dt['p2_path'])\n        right_img = cv2.resize(right_img, (shape[0], shape[1]))\n        right_data.append(right_img)\n        targets.append(dt['target'])\n\n        if  len(left_data) % batch_size ==0:\n            left_data = np.squeeze(np.array(left_data))\n            right_data = np.squeeze(np.array(right_data))\n            targets = np.squeeze(np.array(targets))\n            history = siamese_net.train_on_batch([left_data,right_data], targets)\n            #history_vgg = siamese_net_vgg.train_on_batch([left_data,right_data], targets)\n            left_data = []\n            right_data = []\n            targets = []\n\n    left_data = np.squeeze(np.array(left_data))\n    right_data = np.squeeze(np.array(right_data))\n    targets = np.squeeze(np.array(targets))\n    history = siamese_net.train_on_batch([left_data,right_data], targets)\n    left_data = []\n    right_data = []\n    targets = []\n    histories['loss'].append(history[0])\n    histories['acc'].append(history[1])\n    #histories_vgg['loss'].append(history_vgg[0])\n    #histories_vgg['acc'].append(history_vgg[1])\n","d0a14f50":"\n# summarize history for accuracy\nplt.plot(histories['acc'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train'], loc='upper left')\nplt.show()","89d9282f":"# # summarize history for accuracy\n# plt.plot(histories_vgg['acc'])\n# plt.title('model accuracy')\n# plt.ylabel('accuracy')\n# plt.xlabel('epoch')\n# plt.legend(['train'], loc='upper left')\n# plt.show()","a62cf164":"test_path = \"..\/input\/test\/\"\ntest_df = pd.read_csv(\"..\/input\/sample_submission.csv\")\ntest_df['p1_path'] = test_df['img_pair'].apply(lambda x : os.path.join(test_path, x.split('-')[0] ))\ntest_df['p2_path'] = test_df['img_pair'].apply(lambda x : os.path.join(test_path, x.split('-')[1]))","6cf39975":"test_img_left = []\ntest_img_right = []\n\nfor i in range(len(test_df)):\n    \n    dt = test_df.iloc[i].to_dict()\n    left_img = cv2.imread(dt['p1_path'])\n    left_img = cv2.resize(left_img, (shape[0], shape[1]))\n    test_img_left.append(left_img)\n    \n    right_img = cv2.imread(dt['p2_path'])\n    right_img = cv2.resize(right_img, (shape[0], shape[1]))\n    test_img_right.append(right_img)\n    ","60c0a2ff":"left_data = np.squeeze(np.array(test_img_left))\nright_data = np.squeeze(np.array(test_img_right))\n","e31df7d6":"sub = test_df[['img_pair']]\nsub['is_related'] = siamese_net.predict([left_data,right_data])\nsub.to_csv('sub.csv',index=False)","bb2ea81c":"# sub = test_df[['img_pair']]\n# sub['is_related'] = siamese_net_vgg.predict([left_data,right_data])\n# sub.to_csv('sub_vgg.csv',index=False)","ee0d0084":"## Siamese NN \n(credits : https:\/\/www.kaggle.com\/arpandhatt\/siamese-neural-networks)","5298b474":"Overfitting ... ","8b379d86":"# Siamese With VGG_FACE\nhttps:\/\/github.com\/rcmalli\/keras-vggface"}}