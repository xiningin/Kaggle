{"cell_type":{"84687ba6":"code","c1860c61":"code","9fd0e91b":"code","760e0a0e":"code","2a3ed27b":"code","cb523be6":"code","096f6e2f":"code","d2113ddd":"code","86657c84":"code","d38d852a":"code","8e7a30b0":"code","94a81442":"code","8ac4158f":"code","0fc4210c":"markdown","394373fa":"markdown","973b7ddd":"markdown","e86fffa0":"markdown"},"source":{"84687ba6":"import matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nimport tensorflow as tf\nfrom tensorflow.keras import layers, losses\nfrom tensorflow.keras.models import Model\nimport random\nimport os\nimport gc","c1860c61":"image_classes = ['buildings', 'forest', 'glacier', 'mountain', 'sea', 'street']","9fd0e91b":"def get_paths(im_class: str) -> (list, list):\n    if im_class not in image_classes:\n        return [], []\n    \n    train_path = '..\/input\/intel-image-classification\/seg_train\/seg_train\/' + im_class\n    test_path = '..\/input\/intel-image-classification\/seg_test\/seg_test\/' + im_class\n    \n    train_paths = []\n    for dirname, _, filenames in os.walk(train_path):\n        for filename in filenames:\n            train_paths.append(os.path.join(dirname, filename))\n    \n    test_paths = []\n    for dirname, _, filenames in os.walk(test_path):\n        for filename in filenames:\n            test_paths.append(os.path.join(dirname, filename))\n            \n    print(f'Image class \"{im_class}\" has {len(train_paths)} training images ' +\n          f'and {len(test_paths)} testing images')\n    \n    return train_paths, test_paths","760e0a0e":"for i in image_classes:\n    get_paths(i)","2a3ed27b":"def load_image(path, max_dim=None, gray=False, size=None):\n    img = Image.open(path)\n    if max_dim:\n        img.thumbnail((max_dim, max_dim))\n    if size:\n        img = img.resize(size)\n    if gray:\n        img = img.convert('L')\n    return np.array(img)\n\n\ndef normalize(img):\n    img = img \/ 255\n    return img\n\n\ndef denormalize(img):\n    img = img * 255\n    return img\n\n\ndef show(img, gray=False):\n    plt.axis('off')\n    if gray:\n        plt.imshow(img, cmap='gray')\n    else:\n        plt.imshow(img)","cb523be6":"p_train, p_test = get_paths(image_classes[0])","096f6e2f":"size = (128, 128)\ngray = False","d2113ddd":"im = load_image(p_train[0], size=size, gray=gray)\nimage_shape = im.shape\nprint(f'Shape: {image_shape}')\nshow(im, gray)","86657c84":"def get_images(train_paths: list, test_paths: list):\n    train_images = np.array([load_image(path, size=size, gray=gray)\n                             for path in train_paths])\n    train_images = normalize(train_images)\n    print(f'Training data shape: {train_images.shape}')\n    \n    test_images = np.array([load_image(path, size=size, gray=gray)\n                             for path in test_paths])\n    test_images = normalize(test_images)\n    print(f'Testing data shape: {test_images.shape}')\n    \n    return train_images, test_images","d38d852a":"class Autoencoder(Model):\n    def __init__(self, encoded_dim):\n        super(Autoencoder, self).__init__()\n        self.encoded_dim = encoded_dim   \n        self.encoder = tf.keras.Sequential([\n            layers.Flatten(),\n            layers.Dense(encoded_dim, activation='relu')\n        ])\n        self.decoder = tf.keras.Sequential([\n            layers.Dense(np.prod(image_shape), activation='sigmoid'),\n            layers.Reshape(image_shape)\n        ])\n\n    def call(self, x):\n        encoded = self.encoder(x)\n        decoded = self.decoder(encoded)\n        return decoded","8e7a30b0":"def show_results(original_images, reconstructed_images):\n    n = 8\n    rand = random.randint(0, len(original_images) - n)\n\n    plt.figure(figsize=(40, 10))\n    for i in range(n):\n        # display original\n        ax = plt.subplot(2, n, i + 1)\n        plt.imshow(original_images[i + rand])\n        plt.title('original')\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n\n        # display reconstruction\n        ax = plt.subplot(2, n, i + 1 + n)\n        plt.imshow(reconstructed_images[i + rand])\n        plt.title('reconstructed')\n        plt.gray()\n        ax.get_xaxis().set_visible(False)\n        ax.get_yaxis().set_visible(False)\n    plt.show()","94a81442":"# Just pretend I'm a good programmer whose code is so good she doesn't get any warnings\ntf.get_logger().setLevel('WARNING')","8ac4158f":"for image_class in image_classes:\n    training_paths, testing_paths = get_paths(image_class)\n    train_images, test_images = get_images(training_paths, testing_paths)\n    \n    # The number of encoded dimensions\n    n_encoded_dims = np.prod(image_shape) \/\/ 10\n    print(f'Encoded in {n_encoded_dims} float values. That is {n_encoded_dims * 8} bytes.')\n    \n    autoencoder = Autoencoder(n_encoded_dims)\n    autoencoder.compile(optimizer='adam', loss=losses.MeanSquaredError())\n    autoencoder.fit(train_images, train_images,\n                    epochs=25,\n                    shuffle=True,\n                    validation_data=(test_images, test_images),\n                    verbose=0)\n    \n    encoded_imgs = autoencoder.encoder(test_images).numpy()\n    decoded_imgs = autoencoder.decoder(encoded_imgs).numpy()\n    show_results(test_images, decoded_imgs)\n    \n    # delete variables to save memory\n    del train_images, test_images, autoencoder, encoded_imgs, decoded_imgs\n    gc.collect()","0fc4210c":"# Show Results Method","394373fa":"# The Auto-Encoder","973b7ddd":"# Run Auto-Encoder on Every Image Class","e86fffa0":"# Data Loading Methods"}}