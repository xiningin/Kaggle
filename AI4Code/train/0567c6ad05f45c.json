{"cell_type":{"2a7d6069":"code","16a91dbe":"code","bde8844e":"code","773bb0a1":"code","64fe8d80":"code","76bac36b":"code","06aa2f84":"code","3f647617":"code","68fc20a0":"code","b7999634":"code","601acdfc":"code","1ab1c853":"code","391006a3":"code","64b2bf00":"code","de18d480":"code","e20ce5a6":"code","ce03dc3d":"code","11293e2d":"code","b4eed6da":"code","6a8aec3d":"code","3e0b3151":"code","15738a23":"code","f98e589e":"code","5ff63e8b":"code","693492f5":"code","6289ccd9":"markdown","66ee6b8b":"markdown","3fd12cdf":"markdown","0f5b95b2":"markdown","7afe0172":"markdown","2e1b40dc":"markdown","0a1c3d44":"markdown","995b33ff":"markdown","14e26908":"markdown","81451c46":"markdown","f9f744c0":"markdown","27d44563":"markdown","885c328a":"markdown","78d7a03b":"markdown","fd77c44e":"markdown","eddd03d4":"markdown","1c87d4d2":"markdown","63d1b1c1":"markdown","1c033955":"markdown","7fbbb773":"markdown","433bd88d":"markdown","94c93fc1":"markdown"},"source":{"2a7d6069":"import os\nimport numpy as np\nimport pandas as pd\nfrom PIL import Image\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nos.environ['CUDA_VISIBLE_DEVICES'] = '0' # specify GPUs locally","16a91dbe":"train = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ntest = pd.read_csv('..\/input\/seti-breakthrough-listen\/sample_submission.csv')\n\ndef get_train_file_path(image_id):\n    return \"..\/input\/seti-breakthrough-listen\/train\/{}\/{}.npy\".format(image_id[0], image_id)\n\ndef get_test_file_path(image_id):\n    return \"..\/input\/seti-breakthrough-listen\/test\/{}\/{}.npy\".format(image_id[0], image_id)\n\ntrain['file_path'] = train['id'].apply(get_train_file_path)\ntest['file_path'] = test['id'].apply(get_test_file_path)\n\ndisplay(train.head())\ndisplay(test.head())","bde8844e":"sns.histplot(train['target'], kde=False)","773bb0a1":"plt.figure(figsize=(10, 8))\nfor i in range(10):\n    image = np.load(train.loc[i, 'file_path']) # (6, 273, 256)\n    image = image[::2].astype(np.float32) # (3, 273, 256)\n    image = np.vstack(image).transpose((1, 0)) # (768, 256) -> (256, 768)\n    plt.subplot(5, 2, i + 1)\n    plt.tight_layout()\n    plt.imshow(image)\nplt.show()","64fe8d80":"image.shape","76bac36b":"plt.figure(figsize=(24, 8))\nfor i in range(10):\n    image = np.load(train.loc[i, 'file_path']) # (6, 273, 256)\n    image = image.astype(np.float32)\n    image = np.vstack(image).transpose((1, 0)) # (1638, 256) -> (256, 768)\n    plt.subplot(5, 2, i + 1)\n    plt.tight_layout()\n    plt.imshow(image)\nplt.show()","06aa2f84":"image.shape","3f647617":"# ====================================================\n# Directory settings\n# ====================================================\nimport os\nos.environ['CUDA_VISIBLE_DEVICES'] = '0' # specify GPUs locally\n\nOUTPUT_DIR = '.\/output\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)","68fc20a0":"# ====================================================\n# CFG\n# ====================================================\nclass CFG:\n    debug=False\n    apex=True\n    device='GPU'\n    print_freq=100\n    num_workers=8\n    encoder='tf_efficientnetv2_b0' #['tf_efficientnetv2_b0', 'tf_efficientnet_b0', 'resnext50_32x4d']\n    size=224\n    epochs=4\n    scheduler='CosineAnnealingLR' # ['ReduceLROnPlateau', 'CosineAnnealingLR', 'CosineAnnealingWarmRestarts']\n    factor=0.2 # ReduceLROnPlateau\n    patience=4 # ReduceLROnPlateau\n    eps=1e-6 # ReduceLROnPlateau\n    T_max=4 # CosineAnnealingLR\n    #T_0=4 # CosineAnnealingWarmRestarts\n    lr=1e-4\n    min_lr=1e-6\n    batch_size=64\n    weight_decay=1e-6\n    gradient_accumulation_steps=1\n    max_grad_norm=1000\n    seed=2021\n    target_size=1\n    target_col='target'\n    n_fold=5\n    trn_fold=[0] #[0, 1, 2, 3]\n    train=True\n    mode='spatial_3ch' #['spatial_6ch', 'spatial_3ch', '6_channel', '3_channel']\n\nif CFG.debug:\n    print('debug!')\n    CFG.epochs = 2\n    train = train.sample(n=1000, random_state=CFG.seed).reset_index(drop=True)","b7999634":"# ====================================================\n# Library\n# ====================================================\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\n\nimport os\nimport math\nimport time\nimport random\nimport shutil\nfrom pathlib import Path\nfrom contextlib import contextmanager\nfrom collections import defaultdict, Counter\n\nimport scipy as sp\nimport numpy as np\nimport pandas as pd\n\nfrom sklearn import preprocessing\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold\n\nfrom tqdm.auto import tqdm\nfrom functools import partial\n\nimport cv2\nfrom PIL import Image\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.optim import Adam, SGD\nimport torchvision.models as models\nfrom torch.nn.parameter import Parameter\nfrom torch.utils.data import DataLoader, Dataset\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, CosineAnnealingLR, ReduceLROnPlateau\n\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nfrom albumentations import ImageOnlyTransform\n\nimport timm\n\nfrom torch.cuda.amp import autocast, GradScaler\n\nimport warnings \nwarnings.filterwarnings('ignore')\n\ndevice = torch.device('cuda' if torch.cuda.is_available() else 'cpu')","601acdfc":"# ====================================================\n# Utils\n# ====================================================\ndef get_score(y_true, y_pred):\n    score = roc_auc_score(y_true, y_pred)\n    return score\n\n\n@contextmanager\ndef timer(name):\n    t0 = time.time()\n    LOGGER.info(f'[{name}] start')\n    yield\n    LOGGER.info(f'[{name}] done in {time.time() - t0:.0f} s.')\n\n\ndef init_logger(log_file=OUTPUT_DIR+'train.log'):\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\nLOGGER = init_logger()\n\n\ndef seed_torch(seed=2021):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\nseed_torch(seed=CFG.seed)","1ab1c853":"Fold = StratifiedKFold(n_splits=CFG.n_fold, shuffle=True, random_state=CFG.seed)\nfor n, (train_index, val_index) in enumerate(Fold.split(train, train[CFG.target_col])):\n    train.loc[val_index, 'fold'] = int(n)\ntrain['fold'] = train['fold'].astype(int)\nprint(train.groupby(['fold', CFG.target_col]).size())","391006a3":"# ====================================================\n# Dataset\n# ====================================================\nclass TrainDataset(Dataset):\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.file_names = df['file_path'].values\n        self.labels = df[CFG.target_col].values\n        self.transform = transform\n        \n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image = np.load(self.file_names[idx])\n        if CFG.mode == 'spatial_6ch':\n            image = image.astype(np.float32)\n            image = np.vstack(image).transpose((1, 0))\n        elif CFG.mode == 'spatial_3ch':\n            image = image[::2].astype(np.float32)\n            image = np.vstack(image).transpose((1, 0))\n        elif CFG.mode == '6_channel':\n            image = image.astype(np.float32)\n            image = np.transpose(image, (1,2,0))\n        elif CFG.mode == '3_channel':\n            image = image[::2].astype(np.float32)\n            image = np.transpose(image, (1,2,0))\n        \n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n        else:\n            image = torch.from_numpy(image).float()\n\n        label = torch.tensor(self.labels[idx]).float()\n        return image, label","64b2bf00":"# ====================================================\n# Transforms\n# ====================================================\ndef get_transforms(*, data):\n    \n    if data == 'train':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            ToTensorV2(),\n        ])\n\n    elif data == 'valid':\n        return A.Compose([\n            A.Resize(CFG.size, CFG.size),\n            ToTensorV2(),\n        ])","de18d480":"CFG.mode = '3_channel'\n\ntrain_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(2):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show()\nimage.shape","e20ce5a6":"CFG.mode = '6_channel'\n\ntrain_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(2):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show()\nimage.shape","ce03dc3d":"CFG.mode = 'spatial_6ch'\n\ntrain_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(2):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show()\nimage.shape","11293e2d":"CFG.mode = 'spatial_3ch'\n\ntrain_dataset = TrainDataset(train, transform=get_transforms(data='train'))\n\nfor i in range(2):\n    image, label = train_dataset[i]\n    plt.imshow(image[0])\n    plt.title(f'label: {label}')\n    plt.show()\nimage.shape","b4eed6da":"# ====================================================\n# MODEL\n# ====================================================\nclass SETImodel(nn.Module):\n    def __init__(self, model_name=CFG.encoder, pretrained=False):\n        super().__init__()\n        if CFG.mode == 'spatial_6ch' or CFG.mode == 'spatial_3ch':\n            self.encoder = timm.create_model(model_name, pretrained=pretrained, in_chans=1, num_classes=CFG.target_size)\n        else:\n            self.encoder = timm.create_model(model_name, pretrained=pretrained, in_chans=6, num_classes=CFG.target_size)\n\n    @autocast()\n    def forward(self, x):\n        x = self.encoder(x)\n        return x","6a8aec3d":"model = SETImodel(model_name=CFG.encoder, pretrained=False)\ntrain_dataset = TrainDataset(train, transform=get_transforms(data='train'))\ntrain_loader = DataLoader(train_dataset, batch_size=4, shuffle=True,\n                          num_workers=4, pin_memory=True, drop_last=True)\n\nfor image, label in train_loader:\n    output = model(image)\n    print(output)\n    break","3e0b3151":"output.shape","15738a23":"# ====================================================\n# Helper functions\n# ====================================================\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n\n\ndef asMinutes(s):\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\n\ndef train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device):\n    if CFG.device == 'GPU':\n        scaler = GradScaler()\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to train mode\n    model.train()\n    start = end = time.time()\n    global_step = 0\n    for step, (images, labels) in enumerate(train_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        if CFG.device == 'GPU':\n            with autocast():\n                y_preds = model(images)\n                loss = criterion(y_preds.view(-1), labels)\n                # record loss\n                losses.update(loss.item(), batch_size)\n            if CFG.gradient_accumulation_steps > 1:\n                loss = loss \/ CFG.gradient_accumulation_steps\n            scaler.scale(loss).backward()\n            grad_norm = torch.nn.utils.clip_grad_norm_(model.parameters(), CFG.max_grad_norm)\n            if (step + 1) % CFG.gradient_accumulation_steps == 0:\n                scaler.step(optimizer)\n                scaler.update()\n                optimizer.zero_grad()\n                global_step += 1\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if CFG.device == 'GPU':\n            if step % CFG.print_freq == 0 or step == (len(train_loader)-1):\n                print('Epoch: [{0}][{1}\/{2}] '\n                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                      'Grad: {grad_norm:.4f}  '\n                      'LR: {lr:.6f}  '\n                      .format(\n                       epoch+1, step, len(train_loader), batch_time=batch_time,\n                       data_time=data_time, loss=losses,\n                       remain=timeSince(start, float(step+1)\/len(train_loader)),\n                       grad_norm=grad_norm,\n                       lr=optimizer.param_groups[0][\"lr\"],\n                       ))\n    return losses.avg\n\n\ndef valid_fn(valid_loader, model, criterion, device):\n    batch_time = AverageMeter()\n    data_time = AverageMeter()\n    losses = AverageMeter()\n    scores = AverageMeter()\n    # switch to evaluation mode\n    model.eval()\n    trues = []\n    preds = []\n    start = end = time.time()\n    for step, (images, labels) in enumerate(valid_loader):\n        # measure data loading time\n        data_time.update(time.time() - end)\n        images = images.to(device)\n        labels = labels.to(device)\n        batch_size = labels.size(0)\n        # compute loss\n        with torch.no_grad():\n            y_preds = model(images)\n        loss = criterion(y_preds.view(-1), labels)\n        losses.update(loss.item(), batch_size)\n\n        trues.append(labels.view(-1).detach().to('cpu').numpy())\n        preds.append(y_preds.sigmoid().detach().to('cpu').numpy())\n\n        if CFG.gradient_accumulation_steps > 1:\n            loss = loss \/ CFG.gradient_accumulation_steps\n        # measure elapsed time\n        batch_time.update(time.time() - end)\n        end = time.time()\n        if CFG.device == 'GPU':\n            if step % CFG.print_freq == 0 or step == (len(valid_loader)-1):\n                print('EVAL: [{0}\/{1}] '\n                      'Data {data_time.val:.3f} ({data_time.avg:.3f}) '\n                      'Elapsed {remain:s} '\n                      'Loss: {loss.val:.4f}({loss.avg:.4f}) '\n                      .format(\n                       step, len(valid_loader), batch_time=batch_time,\n                       data_time=data_time, loss=losses,\n                       remain=timeSince(start, float(step+1)\/len(valid_loader)),\n                       ))\n\n    trues = np.concatenate(trues)\n    predictions = np.concatenate(preds)\n    \n    return losses.avg, predictions, trues","f98e589e":"# ====================================================\n# Train loop\n# ====================================================\ndef train_loop(folds, fold):\n    \n    LOGGER.info(f\"========== fold: {fold} training ==========\")\n\n    # ====================================================\n    # loader\n    # ====================================================\n    trn_idx = folds[folds['fold'] != fold].index\n    val_idx = folds[folds['fold'] == fold].index\n\n    train_folds = folds.loc[trn_idx].reset_index(drop=True)\n    valid_folds = folds.loc[val_idx].reset_index(drop=True)\n    valid_labels = valid_folds[CFG.target_col].values\n\n    train_dataset = TrainDataset(train_folds, \n                                 transform=get_transforms(data='train'))\n    valid_dataset = TrainDataset(valid_folds, \n                                 transform=get_transforms(data='valid'))\n\n    train_loader = DataLoader(train_dataset, \n                              batch_size=CFG.batch_size, \n                              shuffle=True, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=True)\n    valid_loader = DataLoader(valid_dataset, \n                              batch_size=CFG.batch_size * 2, \n                              shuffle=False, \n                              num_workers=CFG.num_workers, pin_memory=True, drop_last=False)\n    \n    # ====================================================\n    # scheduler \n    # ====================================================\n    def get_scheduler(optimizer):\n        if CFG.scheduler=='ReduceLROnPlateau':\n            scheduler = ReduceLROnPlateau(optimizer, mode='min', factor=CFG.factor, patience=CFG.patience, verbose=True, eps=CFG.eps)\n        elif CFG.scheduler=='CosineAnnealingLR':\n            scheduler = CosineAnnealingLR(optimizer, T_max=CFG.T_max, eta_min=CFG.min_lr, last_epoch=-1)\n        elif CFG.scheduler=='CosineAnnealingWarmRestarts':\n            scheduler = CosineAnnealingWarmRestarts(optimizer, T_0=CFG.T_0, T_mult=1, eta_min=CFG.min_lr, last_epoch=-1)\n        return scheduler\n\n    # ====================================================\n    # model & optimizer\n    # ====================================================\n    model = SETImodel(CFG.encoder, pretrained=True)\n    model.to(device)\n\n    optimizer = Adam(model.parameters(), lr=CFG.lr, weight_decay=CFG.weight_decay, amsgrad=False)\n    scheduler = get_scheduler(optimizer)\n\n    # ====================================================\n    # loop\n    # ====================================================\n    def get_criterion():\n        criterion = nn.BCEWithLogitsLoss()\n        return criterion\n    \n    criterion = get_criterion()\n    LOGGER.info(f'Criterion: {criterion}')\n\n    best_score = 0.\n    best_loss = np.inf\n    \n    for epoch in range(CFG.epochs):\n        \n        start_time = time.time()\n        \n        # train\n        avg_loss = train_fn(train_loader, model, criterion, optimizer, epoch, scheduler, device)\n\n        # eval\n        avg_val_loss, preds, _ = valid_fn(valid_loader, model, criterion, device)\n        \n        if isinstance(scheduler, ReduceLROnPlateau):\n            scheduler.step(avg_val_loss)\n        elif isinstance(scheduler, CosineAnnealingLR):\n            scheduler.step()\n        elif isinstance(scheduler, CosineAnnealingWarmRestarts):\n            scheduler.step()\n\n        # scoring\n        score = get_score(valid_labels, preds)\n\n        elapsed = time.time() - start_time\n\n        LOGGER.info(f'Epoch {epoch+1} - avg_train_loss: {avg_loss:.4f}  avg_val_loss: {avg_val_loss:.4f}  time: {elapsed:.0f}s')\n        LOGGER.info(f'Epoch {epoch+1} - Score: {score:.4f}')\n\n        if score > best_score:\n            best_score = score\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Score: {best_score:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.encoder}_fold{fold}_best_score.pth')\n        \n        if avg_val_loss < best_loss:\n            best_loss = avg_val_loss\n            LOGGER.info(f'Epoch {epoch+1} - Save Best Loss: {best_loss:.4f} Model')\n            torch.save({'model': model.state_dict(), \n                        'preds': preds},\n                        OUTPUT_DIR+f'{CFG.encoder}_fold{fold}_best_loss.pth')\n    \n    valid_folds['preds'] = torch.load(OUTPUT_DIR+f'{CFG.encoder}_fold{fold}_best_loss.pth', \n                                      map_location=torch.device('cpu'))['preds']\n\n    return valid_folds","5ff63e8b":"# ====================================================\n# main\n# ====================================================\ndef main():\n\n    \"\"\"\n    Prepare: 1.train  2.folds\n    \"\"\"\n\n    def get_result(result_df):\n        preds = result_df['preds'].values\n        labels = result_df[CFG.target_col].values\n        score = get_score(labels, preds)\n        LOGGER.info(f'Score: {score:<.5f}')\n    \n    if CFG.train:\n        # train \n        oof_df = pd.DataFrame()\n        for fold in range(CFG.n_fold):\n            if fold in CFG.trn_fold:\n                _oof_df = train_loop(train, fold)\n                _oof_df.to_csv(OUTPUT_DIR+f'_oof_df_{fold}.csv', index=False)\n                oof_df = pd.concat([oof_df, _oof_df])\n            \n        # CV result\n        LOGGER.info(f\"========== CV ==========\")\n        get_result(oof_df)\n        # save result\n        oof_df.to_csv(OUTPUT_DIR+'oof_df.csv', index=False)","693492f5":"if __name__ == '__main__':\n    if CFG.device == 'GPU':\n        main()","6289ccd9":"`V2` - Initial version : It is `Debug` mode. :)\n\n`V3` - Add Inference notebook link\n\n`V4` - Change code to simple way for `6 channel`. \n\n> please see [this discussion](https:\/\/www.kaggle.com\/c\/seti-breakthrough-listen\/discussion\/238611).\n> <img src='https:\/\/i.ibb.co\/JFQ44tB\/channel-vs-spatial.png' width='640'>\n\n`V6` - Add `CFG.mode` for `6-channel` and `spatial`\n> `6 channel` - (6, 273, 256)\n\n> `spatial` - (1, 256, 1638). please see [this notebook](https:\/\/www.kaggle.com\/yasufuminakama\/seti-nfnet-l0-starter-training).\n\n`V7` - Add `tf_efficientnet_b0` and fix some bugs.\n\n`V8` - Add `3 channel` mode. please see [[this notebook]](https:\/\/www.kaggle.com\/awsaf49\/seti-bl-nfnet-l0-3-channels).\n> `3-channel` - (3, 273, 256)\n\n> `spatial` - (1, 256, 768). please see [this notebook](https:\/\/www.kaggle.com\/awsaf49\/seti-bl-nfnet-l0-3-channels).\n\n`V9` - `CFG.mode` has `4` types.\n> `spatial_6ch`, `spatial_3ch`, `6_channel`, `3_channel`\n\n> Add Simple View for `4` types.\n\n`V12` - Update `timm` package and add `tf_efficientnetv2` models.\n\n`V13` - Change code for `head` ","66ee6b8b":"# Utils","3fd12cdf":"# MODEL","0f5b95b2":"# Data Loading","7afe0172":"## 6-channel","2e1b40dc":"# About this\n- Starter Training Notebook using Pytorch\n- StratifiedKFold 5 folds\n- `3` or `6` channel (channel-wise)\n- `1` channel (spatial)\n\n- Original notebook is [here](https:\/\/www.kaggle.com\/yasufuminakama\/ranzcr-resnext50-32x4d-starter-training).\n\n# Inference notebook\n- [[Infer] SETI-BL: Pytorch Starter\ud83d\udd25](https:\/\/www.kaggle.com\/piantic\/infer-seti-bl-pytorch-starter)","0a1c3d44":"# Helper functions","995b33ff":"## Quick Veiw For `4` types of mode","14e26908":"# Split","81451c46":"# Reference","f9f744c0":"- https:\/\/www.kaggle.com\/kneroma\/clean-fast-simple-bird-identifier-training-colab\n- https:\/\/www.kaggle.com\/jiny333\/pytorch-simple-baseline-resnet-18-trn-infer\n- https:\/\/www.kaggle.com\/heyytanay\/pytorch-lightning-efficientnetb3-training-starter\n- https:\/\/www.kaggle.com\/yasufuminakama\/seti-nfnet-l0-starter-training","27d44563":"`V14` - New dataset version","885c328a":"# Train loop","78d7a03b":"# Dataset","fd77c44e":"# Quick EDA","eddd03d4":"## Only 3-channel","1c87d4d2":"If this is helpful, feel free to upvote.\n","63d1b1c1":"# Transforms","1c033955":"# Library","7fbbb773":"# Directory settings","433bd88d":"# CFG","94c93fc1":"## AverageMeter"}}