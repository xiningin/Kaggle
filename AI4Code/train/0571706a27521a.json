{"cell_type":{"7f1d311e":"code","35cc7c4a":"code","425fa3eb":"code","11882060":"code","2c08fdee":"code","936454c1":"code","fc98e200":"code","bb00d798":"code","b8af5e98":"code","c4c5707b":"code","6d335896":"code","973482ff":"code","8fe788dd":"code","90b48064":"code","d74a2433":"code","221162e8":"code","2f1f6e10":"code","91e9dac7":"code","3133ee70":"code","f59f0b1c":"markdown","aac4c0ed":"markdown","7b9955e2":"markdown","163a3280":"markdown","30c10e32":"markdown","987ca3d8":"markdown","a4082334":"markdown","dbc8c55e":"markdown","97a4ce58":"markdown","6f1a57f2":"markdown","7fd6a19f":"markdown","cf835a0f":"markdown","6880a367":"markdown","0e53b863":"markdown"},"source":{"7f1d311e":"#import necessary libraries\nimport pandas as pd\nimport numpy as np\nimport json\nimport re\nfrom nltk.tokenize import RegexpTokenizer, word_tokenize, sent_tokenize\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\nfrom sklearn.manifold import TSNE\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n#open dataset\ndata = []\nwith open('..\/input\/recipes.json') as f:\n    for line in f:\n        data.append(json.loads(line))","35cc7c4a":"#read dataset\nrecipe = data[0]\ndf = pd.DataFrame(recipe)\ndf.head()","425fa3eb":"df.shape","11882060":"df = df.drop_duplicates(['Name'],keep='first')","2c08fdee":"df.shape","936454c1":"df = df.drop(['Day','Month','Url','Weekday','Year'],axis=1)\n\ndf.head()","fc98e200":"df['Ingredients'] = df['Ingredients'].apply(lambda x: ' '.join(x))","bb00d798":"df.head()","b8af5e98":"# Define a function to perform both stemming and tokenization\ndef tokenizer(text):\n    \n    # Tokenize by sentence, then by word\n    tokens = [word for text in sent_tokenize(text) for word in word_tokenize(text)]\n    \n       \n    # Filter out raw tokens to remove noise\n    filtered_tokens = [token for token in tokens if re.match(r'[A-Z\u00c4\u00d6\u00dc][a-z\u00e4\u00f6\u00fc\u00df]+', token)]\n    \n    return filtered_tokens","c4c5707b":"# Instantiate TfidfVectorizer object with stopwords and tokenizer parameters for efficient processing of text\n\ntfidf_vectorizer = TfidfVectorizer(tokenizer=tokenizer,lowercase=False)","6d335896":"# Fit and transform the tfidf_vectorizer with the \"plot\" of each movie to create a vector representation of the plot summaries\n\ntfidf_matrix = tfidf_vectorizer.fit_transform([x for x in df['Ingredients']])\n\nprint(tfidf_matrix.shape)","973482ff":"pca = PCA(n_components=5)\nX = pca.fit_transform(tfidf_matrix.todense())","8fe788dd":"def find_optimal_clusters(data, max_k):\n    iters = range(2, max_k+1, 1)\n    \n    sse = []\n    for k in iters:\n        sse.append(KMeans(n_clusters=k, random_state=20).fit(data).inertia_)\n        print('Fit {} clusters'.format(k))\n        \n    f, ax = plt.subplots(1, 1)\n    ax.plot(iters, sse, marker='o')\n    ax.set_xlabel('Cluster Centers')\n    ax.set_xticks(iters)\n    ax.set_xticklabels(iters)\n    ax.set_ylabel('SSE')\n    ax.set_title('SSE by Cluster Center Plot')\n    \nfind_optimal_clusters(tfidf_matrix, 20)","90b48064":"clusters = KMeans(n_clusters=5, random_state=20).fit_predict(tfidf_matrix)","d74a2433":"df['clusters'] = clusters\ndf.head()","221162e8":"#plotting k-means clustering\n\ntrace_Kmeans = go.Scatter(x=X[:, 0], y= X[:, 1], mode=\"markers\",\n                    showlegend=False,\n                    text = df['Name'],\n                    hoverinfo = 'text',\n                    marker=dict(\n                            size=8,\n                            color = clusters,\n                            colorscale = 'Portland',\n                            showscale=False, \n                            line = dict(\n            width = 2,\n            color = 'rgb(255, 255, 255)'\n        )\n                   ))\nlayout = dict(title = 'KMeans Clustering',\n              hovermode= 'closest',\n              yaxis = dict(zeroline = False),\n              xaxis = dict(zeroline = False),\n              showlegend= False,\n              width=600,\n              height=600,\n             )\n\ndata = [trace_Kmeans]\nfig1 = dict(data=data, layout= layout)\n# fig1.append_trace(contour_list)\npy.iplot(fig1, filename=\"svm\")","2f1f6e10":"tsne = TSNE()\ntsne_results = tsne.fit_transform(tfidf_matrix.todense()) ","91e9dac7":"traceTSNE = go.Scatter(\n    x = tsne_results[:,0],\n    y = tsne_results[:,1],\n#    name = Target,\n#     hoveron = Target,\n    mode = 'markers',\n     text = df['Name'],\n    hoverinfo = 'text',\n    showlegend = True,\n    marker = dict(\n        size = 8,\n        color = clusters,\n        colorscale ='Portland',\n        showscale = False,\n        line = dict(\n            width = 2,\n            color = 'rgb(255, 255, 255)'\n        ),\n        opacity = 0.8\n    )\n)\ndata = [traceTSNE]\n\nlayout = dict(title = 'TSNE (T-Distributed Stochastic Neighbour Embedding)',\n              hovermode= 'closest',\n              yaxis = dict(zeroline = False),\n              xaxis = dict(zeroline = False),\n              showlegend= True,\n              autosize=False,\n              width=600,\n              height=600,\n             )\n\nfig = dict(data=data, layout=layout)\npy.iplot(fig, filename='styled-scatter')","3133ee70":"def get_top_keywords(data, clusters, labels, n_terms):\n    df = pd.DataFrame(data.todense()).groupby(clusters).mean()\n    \n    for i,r in df.iterrows():\n        print('\\nCluster {}'.format(i))\n        print(','.join([labels[t] for t in np.argsort(r)[-n_terms:]]))\n            \nget_top_keywords(tfidf_matrix, clusters, tfidf_vectorizer.get_feature_names(), 5)","f59f0b1c":"From cluster plot, there seems to be no change in direction of plot, 'elbow' is not visible. Hence, a random guess would be used for fitting and prediction in K Means.","aac4c0ed":"## 1. Introduction\n\nA dataset consisting of 12190 recipe in German which was scraped from the web is used to determine which group they belong to according to the ingredients. Since there is no label provided, unsupervised learning methods will be used. Initially, data will be cleaned and preprocessed before using Natural Language Processing(NLP) technique via Tf-idf vectorization to obtain importance of each ingredient accross all observations in the dataset. Thereafter, dimensions will be reduced from a higher dimension after vectorization to a lower dimension for K-Means Clustering and also t-SNE plot to visualize the clusters. Interactive plotting via plotly to better visualize the plots.\n\nNote that, I have very little knowledge in the language and the recipes. However, the outcome may be interesting.","7b9955e2":"## 3. TOKENIZATION & VECTORIZATION","163a3280":"## 5. T-SNE","30c10e32":"## 4. K Means Clustering","987ca3d8":"Perform dimensional reduction before K Means Clustering","a4082334":"*Note: Plot is interactive, hover for more details. Double to click to pan return*","dbc8c55e":"Estimate n_clusters using Elbow Method","97a4ce58":"## 7. Future work\n\nSome other more detailed bag of words methods can be used to obtain better information about the ingredients. Other models perhaps deep learning models of neural networks might be able to provide a better clustering of observations.","6f1a57f2":"Using n_clusters = 5, seems to be able to display a little distinction in clustering as shown in the K-Means plot.","7fd6a19f":"## 6. Additional Information","cf835a0f":"Obtaining key ingredients of each cluster may be able to provide some information about the recipes in each cluster.","6880a367":"*Note: Plot is interactive, hover for more details. Double to click to pan return*","0e53b863":"## 2. Data Cleaning and Preprocessing"}}