{"cell_type":{"ad3925e4":"code","f9a17cfe":"code","8553d5b1":"code","073e95a0":"code","e2f5712b":"code","2e2d1fe0":"code","fb351031":"code","563afeee":"markdown","73e4a376":"markdown","45c551ba":"markdown","8a95b85e":"markdown","b09baf50":"markdown","27147c90":"markdown","af8d4495":"markdown","f6316c71":"markdown"},"source":{"ad3925e4":"import numpy as np\nimport pandas as pd\n\ndata_filepath = '..\/input\/jobs-on-naukricom\/home\/sdf\/marketing_sample_for_naukri_com-jobs__20190701_20190830__30k_data.csv'\ndf = pd.read_csv(data_filepath)\ndf.head()","f9a17cfe":"import pandas_profiling\npandas_profile = pandas_profiling.ProfileReport(df, progress_bar=False)\npandas_profile.to_widgets()","8553d5b1":"# Let's look at the freshness of the data using the crawl timestamp\n\nimport plotly.express as px\ndf['Crawl Timestamp_dt'] = pd.to_datetime(df['Crawl Timestamp']) #Convert to Pandas DateTime\npx.box(df, y=\"Crawl Timestamp_dt\", points=\"all\", hover_data=[\"Uniq Id\"])","073e95a0":"# Let's now look at categorical columns such as Functional Area\n\nfunc_area_df = (df['Functional Area'].str.split(' , ', expand=True) #Multiple categories are combined in the column as comma-separated so we first need to split this\n     .stack() # We then stack them again as they'd otherwise be represented as separate columns\n     .value_counts() # As last transformation we count all the values\n    )\n\n# We only want to show the top values, and combine the smaller values together\ntop_func_area_df = pd.concat([func_area_df[:20], pd.Series(func_area_df[20:].sum(), index=[\"Others\"])])\n\n\nfig = px.pie(top_func_area_df, values=top_func_area_df.values, names=top_func_area_df.index)\nfig.update_traces(textposition='inside', textinfo='percent+label')","e2f5712b":"# Let's do the same with Industry and Key Skills\n\nindustry_df = (df['Industry'].str.split(', ', expand=True) #Multiple categories are combined in the column as comma-separated so we first need to split this\n     .stack() # We then stack them again as they'd otherwise be represented as separate columns\n     .value_counts() # As last transformation we count all the values\n    )\n\n# We only want to show the top values, and combine the smaller values together\ntop_industry_df = pd.concat([industry_df[:30], pd.Series(industry_df[30:].sum(), index=[\"Others\"])])\npx.bar(top_industry_df)","2e2d1fe0":"# Let's do the same with Industry and Key Skills\n\nkey_skills_df = (df['Key Skills'].str.split('\\| ', expand=True) #Multiple categories are combined in the column as comma-separated so we first need to split this\n     .stack() # We then stack them again as they'd otherwise be represented as separate columns\n     .value_counts() # As last transformation we count all the values\n    )\n\n# We only want to show the top values, and combine the smaller values together\ntop_key_skills_df = pd.concat([key_skills_df[:30], pd.Series(key_skills_df[30:].sum(), index=[\"Others\"])])\nfig = px.bar(top_key_skills_df)\nfig.update_layout(yaxis_type=\"log\")","fb351031":"%matplotlib inline\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\n\nwc = WordCloud(max_words=30, background_color='white', width = 2400, height = 800, min_font_size = 10)\n\nplt.imshow(wc.generate_from_frequencies(df['Role'].astype(str).value_counts()))","563afeee":"We notice there is a large amount of IT and Software jobs","73e4a376":"# Suggested further work\nA more detailed look at job experience and job salary would be useful, especially converting the string value to a range and analyzing this would be useful","45c551ba":"# Initial data analysis\n## Pandas profiling","8a95b85e":"I'm still learning all the in-and-outs of ML and creating\/sharing notebooks. All constructive feedback would be greatly appreciated.\n\n# Import the data","b09baf50":"Crawling seems to have occured during two clusters: July 4 2019-July 8 2019 and Aug 4 2019-Aug 7 2019","27147c90":"## Pandas profiling results\n### Categorial data\nAlthough many columns seem to be categorical, we can see they still show a high cardinality. For example \"Key skills\" has 26909 distinct values for 30000 data entries.\nLooking at the data this seems to have two main reasons:\n1. Categories are not standardized\n2. Multi-selection of categories is group together as comma-seperated into the same column\n\n### Missing values\nWe have missing values for several columns. Usually around 2% per column, with a couple of outliers. \"Key Skills\" with 4.2% and \"Role Category\" with 7.7% are most notable.\n\n### Correlations\/Interactions\nDue to the nature of the data (non-numerical), Pandas profiling doesn't perform any correlation analysis\n\n# Specific column analysis","af8d4495":"We notice a large amount of different skills required, without any real outlier.\nAs already noticed when analyzing Industry, we notice a large amount of programming skills in the top","f6316c71":"Analyse the dataset using pandas profiling"}}