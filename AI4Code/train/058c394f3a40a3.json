{"cell_type":{"eccb6a88":"code","acdfa02d":"code","d12f3540":"code","3dcfbfe2":"code","c388d8b1":"code","5bb1b2cd":"code","b787083b":"code","bd465265":"code","b1af4dc3":"code","66cccdaa":"code","feaf301b":"code","399716ce":"code","ee8254ee":"code","6e2c9488":"code","30e2dfeb":"code","a9b65188":"code","edbaa90d":"code","03554d9a":"code","ebd87d48":"code","c2aa42f5":"code","7b40d6f2":"code","b4570476":"code","bbed40f9":"code","bfff43da":"code","81f3e657":"code","68c9b42c":"code","4c4ed534":"code","99d43beb":"markdown","91377161":"markdown","cfc45d5e":"markdown","fc9837ab":"markdown","b01ea39e":"markdown","76d39a65":"markdown","28ffe605":"markdown"},"source":{"eccb6a88":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","acdfa02d":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pylab as plt\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.pipeline import Pipeline\n\nimport tensorflow as tf\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Dropout, Flatten\n\nimport warnings\nwarnings.filterwarnings(action='ignore')","d12f3540":"sample_submission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\ntrain_df_origin = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/train.csv\")\ntest_df_origin = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-nov-2021\/test.csv\")","3dcfbfe2":"train_df_origin = train_df_origin.drop(['id'], axis=1)\ntrain_df_origin.head(2)","c388d8b1":"## have no target column\n\ntest_df_origin.head(2)","5bb1b2cd":"temp_df = test_df_origin.copy()\ntemp_df = temp_df.drop([\"id\"], axis=1)\ntotal_features = temp_df.columns.to_list()\nnumeric_cols = []\ncategorical_cols = []\n\nfor col in total_features:\n    if len(train_df_origin[col].unique()) <3:\n        categorical_cols.append(col)\n    else:\n        numeric_cols.append(col)","b787083b":"len(numeric_cols), len(categorical_cols) ## variables are all numeric","bd465265":"len(numeric_cols) + len(categorical_cols) == 100","b1af4dc3":"## check target feature's distribution\n\ntrain_df_origin['target'].value_counts()","66cccdaa":"train_df, validation_df = train_test_split(train_df_origin, test_size=0.2, random_state=42)","feaf301b":"trainX = train_df[numeric_cols].values\n\nvalidationX = validation_df[numeric_cols].values\n\ntrainY = train_df['target']\nvalidationY = validation_df['target']","399716ce":"trainX.shape, trainY.shape, validationX.shape, validationY.shape","ee8254ee":"model = Sequential([\n    Dense(256, input_shape=(100,), activation='relu'),\n    Dropout(0.2),\n    Dense(128, activation='relu'),\n    Dropout(0.2),\n    Dense(1, activation='sigmoid'),\n])","6e2c9488":"model.compile(loss='binary_crossentropy', optimizer=\"adam\", metrics=[\"AUC\"])","30e2dfeb":"tf.keras.utils.plot_model(model, show_shapes=True)","a9b65188":"history = model.fit(trainX, trainY, epochs=100, batch_size=512, validation_data=(validationX, validationY))","edbaa90d":"def plot_history(history):\n    auc = history.history['auc']\n    val_auc = history.history['val_auc']\n    loss = history.history['loss']\n    val_loss = history.history['val_loss']\n\n    epochs = range(len(auc))\n\n    plt.plot(epochs, auc, 'bo' ,label = 'training auc')\n    plt.plot(epochs, val_auc, 'r' , label= 'validation auc')\n    plt.title('Training and Validation auc')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'bo' ,label = 'training loss')\n    plt.plot(epochs, val_loss, 'r' , label= 'validation loss')\n    plt.title('Training and Validation loss')\n    plt.legend()","03554d9a":"plot_history(history)","ebd87d48":"## see sample submission format\n\nsample_df = pd.read_csv('\/kaggle\/input\/tabular-playground-series-nov-2021\/sample_submission.csv')","c2aa42f5":"sample_df.head()","7b40d6f2":"test_df_origin.head()","b4570476":"testX_df = test_df_origin.drop(['id'], axis=1)\ntestX = testX_df.values","bbed40f9":"y_pred = model.predict(testX).reshape(1, -1)[0]","bfff43da":"len(test_df_origin) == len(y_pred)","81f3e657":"submission_df = pd.DataFrame().from_dict({'id': test_df_origin['id'], 'target': y_pred})","68c9b42c":"submission_df.head()","4c4ed534":"# submission_df.to_csv(\"\/kaggle\/input\/submission_yj.csv\")","99d43beb":"## Visualize history","91377161":"## Split train\/validation set","cfc45d5e":"## Load Data","fc9837ab":"## Load packages","b01ea39e":"## Variables type check \n- numeric  vs  categorical","76d39a65":"## ANN modeling","28ffe605":"## Predict & make submission table"}}