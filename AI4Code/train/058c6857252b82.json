{"cell_type":{"d63a3792":"code","31e35676":"code","f2d3325d":"code","00e2b2e6":"code","01215454":"code","75832019":"code","07e71c8f":"code","ed8a73ce":"code","651d2fe8":"code","422cfc98":"code","c1949716":"code","e083f0ed":"code","3ac5211f":"code","53b0bab3":"code","8942753d":"code","1b64d336":"code","db6de4d2":"code","62b4f602":"code","ff532b5e":"code","71acdce2":"code","590054be":"code","c04d49c3":"code","3a6a2436":"code","9ca230ca":"code","e2289c7a":"code","ce55904b":"code","b53a8c97":"code","376502cf":"code","307444b4":"markdown","480e6a5f":"markdown","307d34df":"markdown","3d92fbab":"markdown","1058f250":"markdown","2de74952":"markdown","04409ed5":"markdown","705e54c4":"markdown","6ba07d29":"markdown","ca0e8f26":"markdown"},"source":{"d63a3792":"# Import all the important    \nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import optimize, stats    \n%matplotlib inline","31e35676":"df_train = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\ndf_shops = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ndf_items = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/items.csv')\ndf_item_categories = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/test.csv')","f2d3325d":"df_train.head(4)","00e2b2e6":"df_shops.head(4)\n","01215454":"df_items.head(4)","75832019":"df_item_categories.head(4)","07e71c8f":"df_test.head(4)","ed8a73ce":"# we check data type of all columns\ndf_train.info()","651d2fe8":"#date is object so we will change Dtype from object to datetime64\ndf_train['date']=pd.to_datetime(df_train['date'])","422cfc98":"#now we check if there is any null values present in dataset\ndf_train.isnull().sum()","c1949716":"df_train['date']=df_train['date'].dt.strftime('%Y-%m')","e083f0ed":"df_train.head().sort_values(by='date')","3ac5211f":"df_train.drop(['date_block_num','item_price'] , axis =1, inplace= True)","53b0bab3":"df_train.head(10)","8942753d":"# sorting data acording to date sort \ndf_train.head().sort_values(by='date')","1b64d336":"df=df_train.groupby(['date','shop_id','item_id']).sum()\ndf.head()","db6de4d2":"df = df.pivot_table(index=['shop_id','item_id'], columns='date', values='item_cnt_day', fill_value=0)\ndf.reset_index(inplace=True)\ndf.head()","62b4f602":"df_test= pd.merge(df_test , df , on = ['shop_id', 'item_id'], how = 'left')\ndf_test.drop(['ID', '2013-01'], axis =1, inplace=True)\ndf_test= df_test.fillna(0)","ff532b5e":"df_test.head()","71acdce2":"from sklearn.linear_model import LinearRegression, Ridge\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import GradientBoostingRegressor\nfrom lightgbm import LGBMRegressor\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.utils import resample\nfrom sklearn.pipeline import Pipeline","590054be":"Y_train = df['2015-10'].values\nX_train = df.drop(['2015-10'], axis = 1)\nX_test = df_test","c04d49c3":"x_train, x_test, y_train, y_test = train_test_split( X_train, Y_train, test_size=0.2, random_state=101)","3a6a2436":"LR = LinearRegression()\nLR.fit(x_train,y_train)\n\nprint('Train set mse:', mean_squared_error(y_train, LR.predict(x_train)))\nprint('Test set mse:', mean_squared_error(y_test, LR.predict(x_test)))\nprint('Test set score:', LR.score(x_train,y_train))","9ca230ca":"RFR = RandomForestRegressor(n_estimators = 100)\nRFR.fit(x_train,y_train)\n\nprint('Train set mse:', mean_squared_error(y_train, RFR.predict(x_train)))\nprint('Test set mse:', mean_squared_error(y_test, RFR.predict(x_test)))\nprint('Test set score:', RFR.score(x_train,y_train))","e2289c7a":"prediction = RFR.predict(X_test)","ce55904b":"prediction = list(map(round, prediction))","b53a8c97":"df_submission = pd.read_csv('\/kaggle\/input\/competitive-data-science-predict-future-sales\/sample_submission.csv')\nprint(df_submission.shape)\ndf_submission.head()","376502cf":"df_submission['item_cnt_month'] = prediction\ndf_submission.to_csv('prediction.csv', index=False)\ndf_submission.head()","307444b4":"### Training and Testing Data","480e6a5f":"Now we will groupby our data with reference to date, shop_id, item_id","307d34df":"Now,in dataset 'date_block_num' = consicutive month number and 'item_price' is given\nBut for our prediction we do not need these columns so we will deletd these columns","3d92fbab":"## Predicting Future Sales","1058f250":"### Linear Regression","2de74952":"Now after group by we will make pivot table for easy understanding \nwe keep shop_id and item_id as index\nwe keep date as columns and fill item_cnt_day in value","04409ed5":"## Machine Learning Model","705e54c4":"You are provided with daily historical sales data. The task is to forecast the total amount of products sold in every shop for the test set. Note that the list of shops and products slightly changes every month. Creating a robust model that can handle such situations is part of the challenge.","6ba07d29":"In this data set date format is 02-10-2015 but we only need month and year\nSO we delete date day and keep only month and year","ca0e8f26":"### Read all the data files"}}