{"cell_type":{"3a808062":"code","56c2515a":"code","c7099da8":"code","646fc1c8":"code","a4a63f9e":"code","c9064f6d":"code","aebee4ad":"code","bf721587":"code","9d3dee4f":"code","1f0967e8":"code","a4596831":"code","e6963956":"code","18d8217d":"code","e0dd2ff3":"code","4cca2c6f":"code","e3cc97f3":"code","960350a5":"code","a39b7049":"code","a8b84800":"markdown","c5761ecc":"markdown","89bb4256":"markdown","529035ac":"markdown","4af0c7b2":"markdown","608c3679":"markdown","a5159832":"markdown","4730eab7":"markdown","97e84bbf":"markdown","57f335ac":"markdown","e0878d27":"markdown","1ae16f83":"markdown","55f5019b":"markdown","c83d0bdb":"markdown","9f12035a":"markdown","f3c05b3a":"markdown","5411f0ed":"markdown"},"source":{"3a808062":"from bs4 import BeautifulSoup\nimport requests ","56c2515a":"res = requests.get('https:\/\/vishnurao.tech\/')\n","c7099da8":"res.text","646fc1c8":"soup =BeautifulSoup(res.text)","a4a63f9e":"soup.title","c9064f6d":"title = soup.title.text","aebee4ad":"title","bf721587":"list_of_a_tags = soup.find_all('a')","9d3dee4f":"list_of_a_tags","1f0967e8":"for link in list_of_a_tags:\n    print(link['href'])","a4596831":"dates_list= soup.find_all('small')","e6963956":"for date in dates_list:\n    print(date.text)","18d8217d":"image_tag= soup.find('img')\nimage_tag","e0dd2ff3":"image_tag['src']","4cca2c6f":"div_with_id = soup.find('div',{'id':\"gatsby-focus-wrapper\"})","e3cc97f3":"div_with_id","960350a5":"non_existent_element = soup.find('div',{\"id\":\"foo\"})","a39b7049":"print(non_existent_element)","a8b84800":"## Finding all the dates","c5761ecc":"## Basics of Webscraping\n     \n   Web Scraping is one of the important concepts that every Data Scientist must learn ,In this tutorial I will be showing you the bare basics of Web     Scraping like how to fetch a WebPage and scrape details from it and store it as CSV file.\n               \n               \n  ![Web Scraping](https:\/\/p0.pxfuel.com\/preview\/1022\/769\/167\/social-media-twitter-googleplus-royalty-free-thumbnail.jpg)                 ","89bb4256":"## To extract the Text from the HTML Element use the **text** property of the  website","529035ac":"## Further Resources\n\n - https:\/\/www.crummy.com\/software\/BeautifulSoup\/bs4\/doc\/\n - https:\/\/www.youtube.com\/watch?v=ng2o98k983k&t=5s\n - https:\/\/www.youtube.com\/watch?v=XQgXKtPSzUI\n - https:\/\/vishnurao.tech\/day-2-100-days-of-code\/","4af0c7b2":"## If we try to select a element that doesn't exist None will be returned","608c3679":"# Note\n\nBefore starting to Scrape a Website we must see their policies like which routes they allow us to scrape  Every major site has a route **robots.txt**. We will be  using my website to scrape","a5159832":"# Importing the Necessary Modules","4730eab7":"# Making Http Request","97e84bbf":"The important modules for Webscraping are \n- requests\n- BeautifulSoup4\n\n**requests**: requests module is an awesome Http Client for Python used to make Http requests to a website.\n**BeautifulSoup4** : BeautifulSoup4 is a library to parse the response ","57f335ac":"## Finding all the **links** in the Website","e0878d27":"## We are fetching the websites content","1ae16f83":"## **href** is known as the attribute  of the Html tag when the HTML is passed to the Parser a tag is converted as dictionary its corresponding attributes are keys in the dictionary","55f5019b":"## We are passing the HTML Content to the BeautifulSoup Parser","c83d0bdb":"## To find all the the occurences of the given tag  find_all method is used","9f12035a":"## To select a element with particular Class or id we can pass a dict with the required arguments to the find method","f3c05b3a":"## Finding image in the Website , To find the first occurence of the element find is used","5411f0ed":"## Getting the Title Element of the Website"}}