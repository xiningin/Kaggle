{"cell_type":{"a14913a0":"code","e8c95df1":"code","07f6efed":"code","2968b478":"code","507e4b47":"code","0613e7b2":"code","03d64348":"code","40b02859":"code","ba639cdc":"code","6beac82f":"code","71db59e0":"code","6186148f":"code","4ccfea69":"code","3f6234d7":"code","f833f0ea":"code","61745764":"code","1b374610":"code","4f417765":"code","555f9d7e":"code","e4d732a7":"code","81dbfc82":"code","f9335fe2":"code","991610d3":"code","20c46b9c":"code","5f718d76":"code","dd71343a":"code","1f154025":"code","9b700eb0":"code","229dbb7b":"code","81fc8cb5":"code","0e3ce487":"code","79fa1d4b":"code","a2c3c85e":"code","124e3c4d":"code","97ffd40c":"code","08a395ff":"code","d9eca980":"code","c272dcbf":"code","ac4afbc5":"code","8dbfb547":"code","5219ee50":"code","093171df":"code","07deb0a7":"code","43641b7d":"code","591e798c":"code","d83ccd73":"code","7f0cf73f":"code","271f235f":"code","e37156e4":"code","a8eef38f":"code","68f16b88":"code","debe3f27":"code","643eceb8":"code","ff22b443":"code","6acb7494":"code","b6f9f293":"code","7800123c":"code","453c425e":"code","05f394d3":"code","9473093f":"code","acc22e9e":"code","85e28c7a":"code","abefc41e":"code","639b8ec1":"code","1a3c11b7":"code","f31f887d":"code","946c33b4":"markdown","70e38016":"markdown","3b5efddb":"markdown","ca741d50":"markdown","9d445be0":"markdown","20100d08":"markdown","6ecb9b2a":"markdown","d9e18637":"markdown","4f581067":"markdown","e547f886":"markdown"},"source":{"a14913a0":"# Importing the libraries\nimport pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Importing the dataset\ndf = pd.read_csv('..\/input\/listings_summary.csv')","e8c95df1":"df.columns","07f6efed":"# Dropping not necessary columns. Criteria: intuition and common sense.\ndf.drop(['listing_url', 'scrape_id', 'last_scraped', 'experiences_offered', 'neighborhood_overview',\n        'transit', 'access', 'interaction', 'house_rules',\n       'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url',\n       'host_about', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location',\n       'host_acceptance_rate', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count',\n       'host_total_listings_count', 'host_verifications',\n       'host_has_profile_pic', 'host_identity_verified', 'street',\n       'neighbourhood', 'neighbourhood_cleansed', 'host_is_superhost',\n       'city', 'state', 'zipcode', 'market', 'weekly_price', 'monthly_price', \n       'smart_location', 'country_code', 'country','calendar_updated', 'has_availability',\n       'availability_30', 'availability_60', 'availability_90', 'instant_bookable',\n       'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'is_location_exact',\n       'first_review', 'last_review', 'requires_license','maximum_nights',\n       'license', 'jurisdiction_names', 'require_guest_profile_picture', 'require_guest_phone_verification',\n       'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n       'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value',\n       'calculated_host_listings_count', 'reviews_per_month', 'is_business_travel_ready', 'minimum_nights'],\n        axis=1, inplace=True)","2968b478":"# Checking for duplicates\ndf.duplicated().sum()","507e4b47":"# Checking missing values\ndf.isna().sum()","0613e7b2":"# Setting 'id' as an index\ndf = df.set_index('id')","03d64348":"# Dropping a few more columns with extremely high level of NaN\n# Except security_deposit and cleaning_fee because here NaN seems to be 0\ndf.drop(['space', 'notes', 'square_feet', 'host_response_time', 'host_response_rate'], axis=1, inplace=True)","40b02859":"# Taking care of missing values in several columns\n\n# NaNs in bathrooms and bedrooms can be replaced by 1 to be on a safe side\ndf.bathrooms.fillna(1, inplace=True)\ndf.bedrooms.fillna(1, inplace=True)\n# NaNs in beds can be replaced by value in neighbour column 'accommodates' \ndf.beds.fillna(df['accommodates'], inplace=True)","ba639cdc":"# Communities deployment\nplt.figure(figsize=(10,5))\nsns.countplot(y=df['neighbourhood_group_cleansed'], order = df.neighbourhood_group_cleansed.value_counts().index)\nplt.xlabel('Quantity of listings', fontsize='medium')\nplt.ylabel('')\nplt.title('Communities deployment', fontsize='large')","6beac82f":"# Property type deployment - TOP-10 types\nplt.figure(figsize=(15,5))\nsns.countplot(df['property_type'], order = df.property_type.value_counts().iloc[:10].index)\nplt.xlabel('')\nplt.ylabel('Quantity of listings', fontsize='large')\nplt.title('Property type')","71db59e0":"# Room type deployment\nplt.figure(figsize=(5,5))\nsns.countplot(df['room_type'], order = df.room_type.value_counts(normalize=True).index)\nplt.xlabel('')\nplt.ylabel('Quantity of listings', fontsize='large')\nplt.title('Room type')","6186148f":"# Cleaning (replace '$') and formating price-related columns \ndf.price = df.price.str.replace('$', '').str.replace(',', '').astype(float)\ndf.security_deposit = df.security_deposit.str.replace('$', '').str.replace(',', '').astype(float)\ndf.cleaning_fee = df.cleaning_fee.str.replace('$', '').str.replace(',', '').astype(float)\ndf.extra_people = df.extra_people.str.replace('$', '').str.replace(',', '').astype(float)\n\n# NaNs in security_deposit and cleaning_fee seem to be 0\ndf.security_deposit.fillna(0, inplace=True)\ndf.cleaning_fee.fillna(0, inplace=True)","4ccfea69":"# Checking suspiciously low prices\nprint(df[(['price', 'name'])][(df.price < 10)])","3f6234d7":"# Dropping rows with price <8$\ndf = df.drop(df[df.price < 8].index)","f833f0ea":"# Checking suspiciously high prices\ndf['price'].plot(kind='box', xlim=(0, 600), vert=False, figsize=(16,1));","61745764":"# Dropping rows with extremely high price\ndf = df.drop(df[df.price > 380].index)","1b374610":"# Extract numbers that may contain info re square of rooms from 'description' columns (contains ' s\/m\/S\/M')\ndf['room_size'] = df['description'].str.extract(\"(\\d{2,3}\\s[smSM])\", expand=True)\ndf['room_size'] = df['room_size'].str.replace(\"\\D\", \"\").astype(float)\n\nrv = len(df) - df['room_size'].isna().sum()\nprint('Real values in \"room_size\" column:      ', rv)\nprint('Real values in \"room_size\" column (%):  ', round(rv\/len(df)*100,1), '%')\n\n# (C) This cell of code was taken from the original research, done by Britta Bettendorf","4f417765":"# Extract numbers that may contain info re square of rooms from 'name' columns (contains ' s\/m\/S\/M')\ndf['room_size_name'] = df['name'].str.extract(\"(\\d{2,3}\\s[smSM])\", expand=True)\ndf['room_size_name'] = df['room_size_name'].str.replace(\"\\D\", \"\").astype(float)\n\nrv = len(df) - df['room_size_name'].isna().sum()\nprint('Real values in \"room_size_name\" column:      ', rv)\nprint('Real values in \"room_size_name\" column (%):  ', round(rv\/len(df)*100,1), '%')\n\n# (C) This cell of code was taken from the original research, done by Britta Bettendorf","555f9d7e":"df.room_size.fillna(0, inplace=True)","e4d732a7":"# Updating column 'room_size' with values extracted from column 'name'\ndf.loc[df['room_size'] == 0, 'room_size'] = df['room_size_name']","81dbfc82":"# We don't need it any more\ndf.drop(['room_size_name'], axis=1, inplace=True)","f9335fe2":"# Checking suspiciously low sizes\nprint(df[(['room_size', 'name'])][(df.room_size < 10)])","991610d3":"# Dropping rows with suspiciously low sizes\ndf = df.drop(df[df.room_size < 10].index)","20c46b9c":"# Checking suspiciously high sizes\ndf['room_size'].plot(kind='box', vert=False, figsize=(16,1));","5f718d76":"print(df[(['room_size', 'name'])][(df.room_size > 250)])","dd71343a":"# Dropping values of suspiciously high sizes\ndf.loc[df['room_size'] > 250, 'room_size'] = ''\ndf.room_size.replace(to_replace='', value=np.nan, inplace=True)","1f154025":"# We have 'NaN's in our column, 2\/3 of all values\ndf.room_size.isna().sum()","9b700eb0":"df.isna().sum()","229dbb7b":"# New df for further regression\ndf_temp = df[['neighbourhood_group_cleansed', 'accommodates', 'bathrooms', 'bedrooms', 'beds', 'price',\n              'security_deposit', 'cleaning_fee', 'guests_included', 'extra_people', 'room_size']]","81fc8cb5":"print(df_temp.shape)\ndf_temp.head(10).transpose()","0e3ce487":"# Taking care of categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\ncategorical_cols = ['neighbourhood_group_cleansed']\ndf_temp[categorical_cols] = df_temp[categorical_cols].apply(lambda col: labelencoder_X.fit_transform(col.astype(str)))\ndf_temp.head(10).transpose()","79fa1d4b":"# Arranging datasets by existence of 'room_size' value\ntrain_set = df_temp[df_temp['room_size'].notnull()]\ntest_set  = df_temp[df_temp['room_size'].isnull()]\n\n# Arranging X-training and X-testing datasets\nX_train = train_set.drop('room_size', axis=1)\nX_test  = test_set.drop('room_size', axis=1)\n\n# Arranging y-training datasets\ny_train = train_set['room_size']","a2c3c85e":"# Regression model\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 300, random_state = 123)\nregressor.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test) ","124e3c4d":"# Indroduction of predicted data to the main dataset 'df'\ny_pred = pd.DataFrame(y_pred)\ny_pred.columns = ['room_size']","97ffd40c":"temp_id = pd.DataFrame(X_test.index)\ntemp_id.columns = ['temp_id']\n\ny_pred = pd.concat([y_pred, temp_id], axis=1)\ny_pred.set_index(['temp_id'], inplace=True)\n\ndf_pred = pd.concat([X_test, y_pred], axis=1)\ndf_pred.head()","08a395ff":"df_pred.shape","d9eca980":"train_set.shape","c272dcbf":"df_temp = pd.DataFrame()\ndf_temp = pd.concat([df_pred, train_set], axis=0)\nprint(df_temp.shape)\ndf_temp.head().transpose()","ac4afbc5":"# Checking again suspiciously low sizes\nprint(df_temp[(['room_size'])][(df_temp.room_size < 10)])","8dbfb547":"# Checking again suspiciously high sizes\ndf_temp['room_size'].plot(kind='box', vert=False, figsize=(16,1));","5219ee50":"print(df.shape)\ndf.head(2).transpose()","093171df":"print(df_temp.shape)\ndf_temp.head().transpose()","07deb0a7":"df = df[['property_type', 'amenities', 'cancellation_policy']]\nprint(df.shape)\ndf.isna().sum()","43641b7d":"df = pd.concat([df, df_temp], axis=1)\ndf.head(3).transpose()","591e798c":"print(df.shape)\ndf.isna().sum()","d83ccd73":"# Let's explore amenities\npd.set_option('display.max_colwidth', -1)\ndf.amenities.head(5)","7f0cf73f":"# Let's introduce new column with score of amenities\ndf['amen_score'] = df['amenities'].str.count(',') +1","271f235f":"# We don't need it any more\ndf.drop(['amenities'], axis=1, inplace=True)","e37156e4":"df.head().transpose()","a8eef38f":"df.isna().sum()","68f16b88":"# Taking care of categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\ncategorical_cols = ['property_type','cancellation_policy']\ndf[categorical_cols] = df[categorical_cols].apply(lambda col: labelencoder_X.fit_transform(col.astype(str)))\ndf.head(10).transpose()","debe3f27":"# Creating DV and IV sets\nX = df.drop('price', axis=1)\ny = df['price']\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state=123)","643eceb8":"# Gradient Boosting Regression\nfrom sklearn.ensemble import GradientBoostingRegressor\nregressor = GradientBoostingRegressor(n_estimators = 100, max_depth = 3, min_samples_split = 2, learning_rate = 0.1)\nregressor.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)\n\n# Finding the mean_squared error (MSE)\nfrom sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, y_pred)\n\n# Finding the r2 score or the variance (R2)\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, y_pred)\n\n# Applying k-Fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = regressor, X = X_test, y = y_test, cv = 10)\n\n# Printing metrics\nprint(\"RMSE Error:\", round(np.sqrt(mse), 2))\nprint(\"R2 Score:\", round(r2, 4))\nprint(\"Mean accuracy:\", round(accuracies.mean(), 2))\nprint(\"Std deviation:\", round(accuracies.std(), 4))","ff22b443":"import tensorflow as tf","6acb7494":"# Establish feeding type for this version of TF\ndf_tf = df.apply(lambda x: x.astype('float32'))","b6f9f293":"# Creating DV and IV sets\nX_tf = df_tf.drop('price', axis=1)\ny_tf = df_tf['price']\n\n# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_tf, y_tf, test_size = 0.25, random_state=123)","7800123c":"# Feature columns\nproperty_type = tf.feature_column.numeric_column('property_type')\ncancellation_policy = tf.feature_column.numeric_column('cancellation_policy')\nneighbourhood_group_cleansed = tf.feature_column.numeric_column('neighbourhood_group_cleansed')\naccommodates = tf.feature_column.numeric_column('accommodates')\nbathrooms = tf.feature_column.numeric_column('bathrooms')\nbedrooms = tf.feature_column.numeric_column('bedrooms')\nbeds = tf.feature_column.numeric_column('beds')\nsecurity_deposit = tf.feature_column.numeric_column('security_deposit')\ncleaning_fee = tf.feature_column.numeric_column('cleaning_fee')\nguests_included = tf.feature_column.numeric_column('guests_included')\nroom_size = tf.feature_column.numeric_column('room_size')\namen_score = tf.feature_column.numeric_column('amen_score')","453c425e":"feat_cols = [property_type, cancellation_policy, neighbourhood_group_cleansed, accommodates, bathrooms,\n             bedrooms, beds, security_deposit, cleaning_fee, guests_included, room_size, amen_score]","05f394d3":"# Input function\ninput_func = tf.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=1000,shuffle=True)","9473093f":"# Creating and training model\nmodel = tf.estimator.DNNRegressor(hidden_units=[12,12,12], feature_columns = feat_cols)","acc22e9e":"model.train(input_fn=input_func, steps = 10000)","85e28c7a":"pred_input_func = tf.estimator.inputs.pandas_input_fn(x=X_test, batch_size=10, num_epochs=1, shuffle=False)","abefc41e":"predictions = list(model.predict(pred_input_func))","639b8ec1":"y_pred = []\nfor i in predictions:\n    y_pred.append(i['predictions'][0])","1a3c11b7":"from sklearn.metrics import mean_squared_error\ntf_mse = mean_squared_error(y_test, y_pred)\nprint(\"MSE Error:\", round(tf_mse, 2))\nprint(\"RMSE Error:\", round(np.sqrt(tf_mse), 2))","f31f887d":"print(\"Gradient Boosting Regression RMSE Error: \", round(mse**0.5, 2))\nprint(\"TensorFlow DNN Regression RMSE Error:    \", round(tf_mse**0.5, 2))","946c33b4":"This is very simple idea to score the quantity of amenities, assuming more the room has, more price might be.","70e38016":"# Amenities score introduction","3b5efddb":"# 'price' and other money related columns","ca741d50":"# First look and data frame creation","9d445be0":"# Tensor Flow DNN-Regressor","20100d08":"# BERLIN AIRBNB DATASET\nGradient Boosting Regression vs TensorFlow DNN-Regressor","6ecb9b2a":"# Brief summary","d9e18637":"# Gradient Boosting Regression","4f581067":"# Extracting and working out data re room size","e547f886":"As we can see in that particular case Gradient Boosting Regression showed a bit better result than TensorFlow DNN-Regressor."}}