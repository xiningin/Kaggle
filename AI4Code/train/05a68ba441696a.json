{"cell_type":{"3f64ad1b":"code","10d85fcc":"code","8a0d0a76":"code","afd10338":"code","50604d38":"code","817797da":"code","6a626706":"code","e0a17153":"code","464636e6":"code","b61b17ff":"code","6e7f3c0c":"code","174359ef":"code","cb22c862":"code","2c2e168f":"code","836de78e":"code","3d5c07a3":"code","65ba3f52":"code","ffd1ddd5":"code","3d960c74":"code","5b3c2735":"code","205b11ed":"code","9e81c11d":"code","c124cce2":"code","efd5e651":"code","c56244ff":"code","7ff10005":"code","fb9381da":"code","c5ca9b2a":"markdown"},"source":{"3f64ad1b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","10d85fcc":"df=pd.read_csv('\/kaggle\/input\/prediction-facebook-comment\/Dataset.csv')\ndf.head()","8a0d0a76":"#show data last 5 rows\ndf.tail()","afd10338":"#Describe function includes analysis of all our numerical data. For this, count, mean, std, min,% 25,% 50,% 75%, max values are given.\ndf.describe()","50604d38":"df.iloc[:,1:5].describe()","817797da":"#Now,I will check null on all data and If data has null, I will sum of null data's. In this way, how many missing data is in the data.\ndf.isnull().sum()","6a626706":"#As you can see, most of the shares,mon_pub,thu_pub,mon_base value is empty. That's why I want this value deleted.\ndf=df.drop(['shares'],axis='columns')\ndf=df.drop(['mon_pub'],axis='columns')\ndf=df.drop(['thu_pub'],axis='columns')\ndf=df.drop(['mon_base'],axis='columns')","e0a17153":"#filling the remaining null values\ndf['Returns']=df['Returns'].fillna(df['Returns'].mode()[0])\ndf['Category']=df['Category'].fillna(df['Category'].mode()[0])\ndf['commBase']=df['commBase'].fillna(df['commBase'].mode()[0])\ndf['comm48']=df['comm48'].fillna(df['comm48'].mode()[0])\n","464636e6":"#for checking the null values in given Dataset\ndf.isnull().any().any()","b61b17ff":"#scatter plot\nimport matplotlib.pyplot as plt\nplt.scatter(df.sat_base,df.output,marker='+',color='red')\nplt.xlabel('sat_base')\nplt.ylabel('output')","6e7f3c0c":"plt.scatter(df.comm24,df.output,marker='+',color='red')\nplt.xlabel('comm24')\nplt.ylabel('output')","174359ef":"plt.scatter(df.baseTime,df.output,marker='+',color='red')\nplt.xlabel('baseTime')\nplt.ylabel('output')","cb22c862":"import seaborn as sns\ndef correlation_heatmap(df):\n    _,ax=plt.subplots(figsize=(20,20))\n    colormap=sns.diverging_palette(220,10,as_cmap=True)\n    sns.heatmap(df.corr(),annot=True,cmap=colormap)\n    \n    \ncorrelation_heatmap(df)","2c2e168f":"#plot histogram of each parameter\nimport matplotlib.pyplot as plt\ndf.hist(figsize=(20,20))\nplt.show()","836de78e":"print(df.columns)","3d5c07a3":"#get all the columns from the dataframe\ncolumns=df.columns.tolist()\n\n#filter the columns to remove data we do not want\ncolumns=[c for c in columns if c not in ['output']]\n\n#store the value we will predicting on\ntarget='output'\n\nx=df[['likes', 'Checkins', 'Returns', 'Category', 'commBase', 'comm24',\n       'comm48', 'comm24_1', 'diff2448', 'baseTime', 'length', 'hrs',\n       'sun_pub', 'tue_pub', 'wed_pub', 'fri_pub', 'sat_pub', 'sun_base',\n       'tue_base', 'wed_base', 'thu_base','fri_base']]\ny=df[target]\n\n#print the shape of x and y\nprint(x.shape)\nprint(y.shape)","65ba3f52":"from sklearn.model_selection import train_test_split","ffd1ddd5":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2)","3d960c74":"len(x_train)","5b3c2735":"len(x_test)","205b11ed":"from sklearn import tree","9e81c11d":"model=tree.DecisionTreeRegressor()\nmodel.fit(x_train,y_train)","c124cce2":"model.predict(x_test)","efd5e651":"model.score(x_test,y_test)","c56244ff":"from sklearn.ensemble import RandomForestRegressor\nmodel = RandomForestRegressor(n_estimators=20)\nmodel.fit(x_train, y_train)","7ff10005":"model.predict(x_test)","fb9381da":"model.score(x_test,y_test)","c5ca9b2a":"**Conclusion: This prediction creates a baseline for the minimum popularity required for any business post.\n              Though the business problem was to predict the no. Of comments it adds more business value to predict the comments range or volume. As this\n              gives the user a better picture of the amount of comments they are likely to get.\n              The data is heavily biased towards data with low comments. To create a better and accurate model we need a more observation on high and mediumlevel of comments ."}}