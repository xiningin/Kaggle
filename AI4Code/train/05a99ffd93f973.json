{"cell_type":{"8a91910c":"code","1d754eb8":"code","3512e322":"code","5e265c62":"code","edeca108":"code","6958ee9b":"code","0049fcfa":"code","1194a1ee":"code","3e6d66a0":"code","dfcc9949":"code","975f9799":"code","83cc24bc":"code","9c5cfa95":"code","9fba7ff9":"code","f12fc22f":"code","6757115c":"code","b85a97c5":"code","eeddf77c":"code","6a7fbc5a":"code","b82914af":"code","795c728f":"code","a87178a1":"code","e8355884":"code","5467842d":"code","9b3445e9":"code","5c0504ae":"code","400b5bd5":"code","10a2f50e":"code","2a637657":"code","835ec419":"code","d86e36c0":"code","1bc10a33":"markdown","f7ed62ef":"markdown","828d0b30":"markdown","7af60fcd":"markdown","00dde01a":"markdown","bcb07e5a":"markdown","91624cb4":"markdown","82ea8cac":"markdown","3a5cb2c3":"markdown","c56297f1":"markdown","ee1f6392":"markdown","470e3505":"markdown"},"source":{"8a91910c":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport gc,os,sys\n\nfrom sklearn import metrics, preprocessing\nfrom sklearn.decomposition import PCA, KernelPCA\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.feature_selection import RFE, RFECV, VarianceThreshold\nfrom sklearn.model_selection import StratifiedKFold, RepeatedStratifiedKFold\nfrom sklearn.preprocessing import StandardScaler, MinMaxScaler, RobustScaler\nfrom sklearn.svm import NuSVC\nfrom tqdm import tqdm\n\nsns.set_style('darkgrid')\npd.options.display.float_format = '{:,.3f}'.format\n\nprint(os.listdir(\"..\/input\"))","1d754eb8":"%%time\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint(train.shape, test.shape)","3512e322":"train.head()","5e265c62":"null_cnt = train.isnull().sum().sort_values()\nprint('null count:', null_cnt[null_cnt > 0])","edeca108":"c = train['target'].value_counts().to_frame()\nc.plot.bar()\nprint(c)","6958ee9b":"fig, ax = plt.subplots(1, 3, figsize=(16,3), sharey=True)\n\ntrain['muggy-smalt-axolotl-pembus'].hist(bins=50, ax=ax[0])\ntrain['dorky-peach-sheepdog-ordinal'].hist(bins=50, ax=ax[1])\ntrain['slimy-seashell-cassowary-goose'].hist(bins=50, ax=ax[2])","0049fcfa":"for col in train.columns:\n    unicos = train[col].unique().shape[0]\n    if unicos < 1000:\n        print(col, unicos)","1194a1ee":"train['wheezy-copper-turtle-magic'].hist(bins=128, figsize=(12,3))\n#test['wheezy-copper-turtle-magic'].hist(bins=128, figsize=(12,3))","3e6d66a0":"print(train['wheezy-copper-turtle-magic'].describe())\nprint()\nprint('unique value count:', train['wheezy-copper-turtle-magic'].nunique())","dfcc9949":"numcols = train.drop(['id','target','wheezy-copper-turtle-magic'],axis=1).select_dtypes(include='number').columns.values","975f9799":"pca = PCA()\npca.fit(train[numcols])\nplt.xlabel('components')\nplt.plot(np.add.accumulate(pca.explained_variance_ratio_))\nplt.show()","83cc24bc":"X_subset = train[train['wheezy-copper-turtle-magic'] == 0][numcols]\npca.fit(X_subset)\nplt.xlabel('components')\nplt.plot(np.add.accumulate(pca.explained_variance_ratio_))\nplt.show()","9c5cfa95":"from sklearn.neighbors import KNeighborsClassifier\n\nX_subset = train[train['wheezy-copper-turtle-magic'] == 1][numcols]\nY_subset = train[train['wheezy-copper-turtle-magic'] == 1]['target']\n\nfor k in range(2, 10):\n    knc = KNeighborsClassifier(n_neighbors=k)\n    knc.fit(X_subset, Y_subset)\n    score = knc.score(X_subset, Y_subset)\n    print(\"[{}] score: {:.2f}\".format(k, score))","9fba7ff9":"filters = [('StandardScaler', StandardScaler()),\n           ('MinMaxScaler', MinMaxScaler()),\n           ('PCA', PCA(n_components=0.98)),\n           ('KernelPCA(poly)', KernelPCA(kernel=\"poly\", degree=3, gamma=15)),\n           ('KernelPCA(rbf)', KernelPCA(kernel=\"rbf\")),\n           ]\nfor name, f in filters:\n    X_subset2 = f.fit_transform(X_subset)\n    knc = KNeighborsClassifier(n_neighbors=3)\n    knc.fit(X_subset2, Y_subset)\n    score = knc.score(X_subset2, Y_subset)\n    print(\"[{}] score: {:.2f}\".format(name, score))","f12fc22f":"from sklearn.ensemble import BaggingClassifier\n\nknn3 = KNeighborsClassifier(n_neighbors=3)\nknnb = BaggingClassifier(base_estimator=knn3, n_estimators=20)\nknnb.fit(X_subset, Y_subset)\nscore = knnb.score(X_subset, Y_subset)\nprint(\"score: {:.2f}\".format(score))","6757115c":"all_data = train.append(test, sort=False).reset_index(drop=True)\ndel train, test\ngc.collect()\n\nall_data.head()","b85a97c5":"# drop constant column\nconstant_column = [col for col in all_data.columns if all_data[col].nunique() == 1]\nprint('drop columns:', constant_column)\nall_data.drop(constant_column, axis=1, inplace=True)","eeddf77c":"corr_matrix = all_data.corr().abs()\nupper = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(np.bool))\nto_drop = [c for c in upper.columns if any(upper[c] > 0.95)]\ndel upper\n\ndrop_column = all_data.columns[to_drop]\nprint('drop columns:', drop_column)\n#all_data.drop(drop_column, axis=1, inplace=True)","6a7fbc5a":"X_train = all_data[all_data['target'].notnull()].reset_index(drop=True)\nX_test = all_data[all_data['target'].isnull()].drop(['target'], axis=1).reset_index(drop=True)\ndel all_data\ngc.collect()\n\n# drop ID_code\nX_train.drop(['id'], axis=1, inplace=True)\nX_test_ID = X_test.pop('id')\n\nY_train = X_train.pop('target')\n\nprint(X_train.shape, X_test.shape)","b82914af":"oof_preds = np.zeros(X_train.shape[0])\nsub_preds = np.zeros(X_test.shape[0])\n\nsplits = 11\n\nfor i in tqdm(range(512)):\n    train2 = X_train[X_train['wheezy-copper-turtle-magic'] == i][numcols]\n    test2 = X_test[X_test['wheezy-copper-turtle-magic'] == i][numcols]\n    train2_y = Y_train[train2.index]\n    idx1 = train2.index; idx2 = test2.index\n    train2.reset_index(drop=True,inplace=True)\n    \n    sel = VarianceThreshold(threshold=1.5)\n    train2 = sel.fit_transform(train2)\n    test2 = sel.transform(test2)    \n    \n    skf = StratifiedKFold(n_splits=splits, random_state=42)\n    for train_index, test_index in skf.split(train2, train2_y):\n        clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n        clf.fit(train2[train_index], train2_y.iloc[train_index])\n        oof_preds[idx1[test_index]] = clf.predict_proba(train2[test_index])[:,1]\n        sub_preds[idx2] += clf.predict_proba(test2)[:,1] \/ skf.n_splits","795c728f":"error = X_train[((Y_train == 1) & (oof_preds < 0.5)) | ((Y_train == 0) & (oof_preds >= 0.5))]\nprint('error rate: %.3f%%' % (len(error) \/ X_train.shape[0] * 100))","a87178a1":"fpr, tpr, thresholds = metrics.roc_curve(Y_train, oof_preds)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","e8355884":"X_test_p1 = X_test[(sub_preds <= 0.01)].copy()\nX_test_p2 = X_test[(sub_preds >= 0.99)].copy()\nX_test_p1['target'] = 0\nX_test_p2['target'] = 1\nprint(X_test_p1.shape, X_test_p2.shape)\n\nY_train = pd.concat([Y_train, X_test_p1.pop('target'), X_test_p2.pop('target')], axis=0)\nX_train = pd.concat([X_train, X_test_p1, X_test_p2], axis=0)\nY_train.reset_index(drop=True, inplace=True)\nX_train.reset_index(drop=True, inplace=True)","5467842d":"_='''\nfor i in range(512):\n    train_f = (X_train['wheezy-copper-turtle-magic'] == i)\n    test_f = (X_test['wheezy-copper-turtle-magic'] == i)\n    X_train_sub = X_train[train_f][numcols]\n    Y_train_sub = Y_train[train_f]\n    X_test_sub = X_test[test_f][numcols]\n\n    lda = LinearDiscriminantAnalysis(n_components=1)\n    lda.fit(X_train_sub, Y_train_sub)\n    X_train.loc[train_f, 'lda'] = lda.transform(X_train_sub).reshape(-1)\n    X_test.loc[test_f, 'lda'] = lda.transform(X_test_sub).reshape(-1)\n    \n    knc = KNeighborsClassifier(n_neighbors=3)\n    knc.fit(X_train_sub, Y_train_sub)\n    X_train.loc[train_f, 'knc'] = knc.predict_proba(X_train_sub)[:,1]\n    X_test.loc[test_f, 'knc'] = knc.predict_proba(X_test_sub)[:,1]\n'''","9b3445e9":"splits = 11\n\nY_train_org = Y_train.copy()\nX_train_org = X_train.copy()\n\nfor itr in range(4):\n    X_test_p1 = X_test[(sub_preds <= 0.04)].copy()\n    X_test_p2 = X_test[(sub_preds >= 0.96)].copy()\n    X_test_p1['target'] = 0\n    X_test_p2['target'] = 1\n    print(X_test_p1.shape, X_test_p2.shape)\n\n    Y_train = pd.concat([Y_train_org, X_test_p1.pop('target'), X_test_p2.pop('target')], axis=0)\n    X_train = pd.concat([X_train_org, X_test_p1, X_test_p2], axis=0)\n    Y_train.reset_index(drop=True, inplace=True)\n    X_train.reset_index(drop=True, inplace=True)\n\n    oof_preds = np.zeros(X_train.shape[0])\n    sub_preds = np.zeros(X_test.shape[0])\n        \n    for i in tqdm(range(512)):\n        train2 = X_train[X_train['wheezy-copper-turtle-magic'] == i][numcols]\n        train2_y = Y_train[train2.index]\n        test2 = X_test[X_test['wheezy-copper-turtle-magic'] == i][numcols]\n        idx1 = train2.index; idx2 = test2.index\n        train2.reset_index(drop=True,inplace=True)\n\n        sel = VarianceThreshold(threshold=1.5)\n        train2 = pd.DataFrame(sel.fit_transform(train2))\n        test2 = pd.DataFrame(sel.transform(test2))\n        \n        sel = StandardScaler()\n        train2 = pd.DataFrame(sel.fit_transform(train2))\n        test2 = pd.DataFrame(sel.transform(test2))\n\n        skf = StratifiedKFold(n_splits=splits, random_state=42)\n        for train_index, test_index in skf.split(train2, train2_y):\n            #clf = KNeighborsClassifier(n_neighbors=3)\n            clf = NuSVC(probability=True, kernel='poly', degree=4, gamma='auto', random_state=42, nu=0.59, coef0=0.053)\n            #clf = QuadraticDiscriminantAnalysis(reg_param=0.5)\n            #clf = BaggingClassifier(base_estimator=clf, n_estimators=30)\n            clf.fit(train2.iloc[train_index], train2_y.iloc[train_index])\n            oof_preds[idx1[test_index]] += clf.predict_proba(train2.iloc[test_index])[:,1]\n            sub_preds[idx2] += clf.predict_proba(test2)[:,1] \/ skf.n_splits","5c0504ae":"#oof_preds[oof_preds <= 0.01] = 0\n#oof_preds[oof_preds >= 0.99] = 1","400b5bd5":"fpr, tpr, thresholds = metrics.roc_curve(Y_train, oof_preds)\nauc = metrics.auc(fpr, tpr)\n\nplt.plot(fpr, tpr, label='ROC curve (area = %.3f)'%auc)\nplt.legend()\nplt.title('ROC curve')\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.grid(True)","10a2f50e":"#sub_preds[sub_preds <= 0.01] = 0\n#sub_preds[sub_preds >= 0.99] = 1","2a637657":"submission = pd.DataFrame({\n    'id': X_test_ID,\n    'target': sub_preds\n})\nsubmission.to_csv(\"submission.csv\", index=False)","835ec419":"submission['target'].hist(bins=25, alpha=0.6)\nprint(submission['target'].sum() \/ len(submission))","d86e36c0":"submission.head()","1bc10a33":"## Prepare","f7ed62ef":"# Predict","828d0b30":"### KNeighborsClassifier","7af60fcd":"### 'wheezy-copper-turtle-magic'","00dde01a":"# Feature engineering","bcb07e5a":"# Submit","91624cb4":"### Add pseudo labeled data","82ea8cac":"### PCA","3a5cb2c3":"# Load data","c56297f1":"### target","ee1f6392":"# Data analysis","470e3505":"### any feature"}}