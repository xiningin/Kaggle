{"cell_type":{"024b9d32":"code","3d7e2822":"code","f8c7766a":"code","fda0a8b3":"code","1fddc3c6":"code","3be93aef":"code","f4420d41":"code","7ee0d433":"code","35874965":"code","7e64bf2a":"code","f98bc32b":"code","386e512c":"code","4a20b10e":"code","481422b0":"code","d66ad30b":"code","c3035a78":"markdown","feda8f9b":"markdown","fb3dafba":"markdown","6874d052":"markdown"},"source":{"024b9d32":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras import Input, Model\nfrom keras.layers import Conv3D, BatchNormalization, MaxPooling3D, GlobalAveragePooling3D, Dense, Activation\nimport tensorflow_addons as tfa #for image manipulation(augmentation)\n\nimport matplotlib.pyplot as plt","3d7e2822":"#data import\ndata_dir = '..\/input\/chestctdataset\/CT_preprocessed.npz'\nct_volume = np.load(data_dir)\n# dictionary \ud615\ud0dc\ub85c \ud150\uc11c\uac00 \uc800\uc7a5\ub418\uc5b4 \uc788\ub2e4\n# \uadf8\ub807\ub2e4\uba74 dictionary\uc758 \ud0a4\ub294 \uc5b4\ub5bb\uac8c \ubcfc \uc218 \uc788\ub294\uac00 -> https:\/\/stackoverflow.com\/questions\/49219436\/how-to-show-all-the-element-names-in-a-npz-file-without-having-to-load-the-compl \ucc38\uace0\nprint(ct_volume.keys) #\uc774\uac70\ub294 \uadf8\ub0e5 '\ud0a4'\ub77c\ub294 \uc774\uc57c\uae30\uace0 \uc2e4\uc81c\ub85c \ud0a4\ub97c \ubcf4\ub824\uba74\nprint(list(ct_volume.keys())) #\uc774\ub807\uac8c \ud568\uc218 \uacb0\uacfc\ub97c \ub9ac\uc2a4\ud2b8\ub85c \ubb36\uc5b4 \uc8fc\uba74 \ub41c\ub2e4","f8c7766a":"tensor_abnormal = np.array(ct_volume['abnormal'], np.float32)\ntensor_normal = np.array(ct_volume['normal'], np.float32)\nprint(tensor_abnormal.shape, tensor_normal.shape)","fda0a8b3":"#visualization\nprint(tensor_abnormal[1,:,:,0])\nplt.imshow(tensor_abnormal[1,:,:,0])\nplt.show()","1fddc3c6":"#data augmentation\n#tensorflow \uc5f0\uc0b0\uc774 \ud655\uc2e4\ud788 \ube68\ub77c\uc11c \ud150\uc11c\ud50c\ub85c\uc6b0 \uc0dd\ud0dc\uacc4 \ub0b4 \ud568\uc218\ub97c \uc704\uc8fc\ub85c \uc4f0\uc790\n\nimport random\nimport tensorflow_addons as tfa #\uc774\ubbf8\uc9c0 \ud68c\uc804!\n\n#rotation\uc73c\ub85c data augmentation\ndef rotate(volume):\n    aug_tensor = []\n    for idx in np.arange(volume.shape[0]):\n        #case\ub9c8\ub2e4 \ub3cc\ub9b4 \uac01\ub3c4\ub97c \ub2e4\ub974\uac8c \ud558\uc790\n        angle = int(np.random.randint(-1,1,1)) \n        rot_tensor = tfa.image.rotate(volume[idx,:,:,:], angle)\n        aug_tensor.append(rot_tensor) #\ud3b8\uc758\uc0c1 \ub9ac\uc2a4\ud2b8\uc5d0 \ucb49\ucb49\ucb49 \uc774\uc5b4\ubd99\uc774\uac8c \ud558\uace0\n        result = tf.convert_to_tensor(aug_tensor) #\ub9c8\uc9c0\ub9c9\uc5d0 \ub9ac\uc2a4\ud2b8\ub97c \ud150\uc11c\ub85c \ubc14\uafc8\n        result = tf.clip_by_value(result, 0, 1) #min-max scaling\n    return result\n\n#\uc0ac\uc2e4 tf.keras.preprocessing.image\uc5d0 \ub354 \ub9ce\uc740 augmentation \uc218\ub2e8\uc774 \uc788\uae34 \ud574...review..","3be93aef":"#visualization\naug_normal = rotate(tensor_normal)\nplt.imshow(aug_normal[37,:,:,1])\nplt.show()\nplt.imshow(aug_normal[3,:,:,2])\nplt.show()","f4420d41":"# Augmented data reproduce\n# tensor_normal, tensor_abnormal \uc911 \uc55e 70\uac1c\ub294 aug\ub97c \uac70\uccd0\uc11c \uc880 \ubee5\ud280\uae30\ub97c \ud574 \uc8fc\uace0 \ub4a4\uc5d0 30\uac1c\ub294 \uadf8\ub300\ub85c validation data\n# tensor_normal\uc758 \uc55e 70\uac1c + \uadf8 70\uac1c\ub97c aug \ud558\uc5ec \ucd1d 140\uac1c\uc758 \ub370\uc774\ud130 \uc0dd\uc0b0\n# \uadf8\ub7ec\ubbc0\ub85c label\uc740 0(\uc815\uc0c1)\uc774 140\uac1c\ny_train_normal = [0]*140\ny_train_abnormal = [1]*140\nx_train_normal = tf.concat([tensor_normal[:70], rotate(tensor_normal[:70])], axis = 0)\nx_train_abnormal = tf.concat([tensor_abnormal[:70], rotate(tensor_abnormal[:70])], axis = 0)\nx_train = tf.concat([x_train_normal, x_train_abnormal], axis = 0)\ny_train = tf.concat([y_train_normal, y_train_abnormal], axis=0)\nprint(x_train.shape, y_train.shape)\n\ny_val_normal = [0]*30\ny_val_abnormal = [1]*30\nx_val = tf.concat([tensor_normal[70:], tensor_abnormal[70:]], axis = 0)\ny_val = tf.concat([y_val_normal, y_val_abnormal], axis=0)\nprint(x_val.shape, y_val.shape)","7ee0d433":"# keras.io\uc758 conv3d \uc124\uba85\uc744 \ubcf4\uba74 input shape == (w, h, depth, rgb(channel))\uc774\ub2e4\n# \uc8fc\uc5b4\uc9c4 CT data\ub294 \uac01\uac01\uc774 \ud751\ubc31 \uc0ac\uc9c4\uc774\ubbc0\ub85c w,h,depth,1 shape\uc73c\ub85c \ubc14\uafd4\uc8fc\uc5b4\uc57c \ud55c\ub2e4\nx_val = tf.expand_dims(x_val, 4)\nx_train = tf.expand_dims(x_train,4)\nx_train.shape, x_val.shape","35874965":"#\ud150\uc11c\ub97c \ub370\uc774\ud130\uc14b\uc73c\ub85c \ub9cc\ub4e4\uc790\n#tf dataset\uc740 (\uc778\ud48b, \uc544\uc6c3\ud48b) \ubb36\uc74c\uc744 \ub9cc\ub4e4\uc5b4 \uc918\uc11c \ub098\uc911\uc5d0 training\ud560 \ub54c \ub354 \ube60\ub974\uace0 \ud3b8\ud558\uac8c \ud560 \uc218 \uc788\uac8c \ud55c\ub2e4\n#\ud504\ub9ac\ud398\uce58\ub294 \ubaa8\ub378 \ud559\uc2b5\uc744 \uac00\uc18d\ud558\ub294 \ubc29\ubc95\nautotune = tf.data.experimental.AUTOTUNE\ntrain_dataset = tf.data.Dataset.from_tensor_slices((x_train, y_train)).shuffle(280).batch(10).prefetch(autotune)\nval_dataset=tf.data.Dataset.from_tensor_slices((x_val, y_val)).shuffle(60).batch(10).prefetch(autotune)","7e64bf2a":"for img, lab in val_dataset.take(1):\n    for idx in np.arange(20):\n        print(f\"{idx}\ubc88\uc9f8 \uc2ac\ub77c\uc774\uc2a4\")\n        plt.imshow(img[5,:,:,idx,0])\n        plt.show()","f98bc32b":"def get_3dcnn():\n    input_layer = keras.Input((100,100,64,1))\n    cnn1 = Conv3D(filters = 64, activation = 'tanh', kernel_size = 3)(input_layer) #\ube44\uc120\ud615 \ud568\uc218 -> \uc5f0\uc0b0\uc2dc\uac04\uc740 \uc624\ub798 \uac78\ub9ac\uaca0\uc9c0\ub9cc \uc6cc\ub099 \ub370\uc774\ud130\uac00 \uc801\uace0 \ud574\uc0c1\ub3c4\ub3c4 \ub0ae\uc544 \uc8fc\uc5b4\uc9c4 \uc815\ubcf4\ub97c \ucd5c\ub300\ud55c \uc774\uc6a9(\ub810\ub8e8 \uac19\uc740 \uacbd\uc6b0\ub294 \uc77c\ubd80\uc758 \ub370\uc774\ud130\uac00 \uc190\uc2e4\ub428)\n    cnn2 = Conv3D(filters = 64, activation = 'tanh',kernel_size = 3)(cnn1)\n    cnn3 = Conv3D(filters = 64, activation = 'tanh',kernel_size = 3)(cnn2)\n    bn1 = BatchNormalization()(cnn3)\n    bn1 = MaxPooling3D()(bn1)\n    cnn4 = Conv3D(filters = 128, activation = 'tanh',kernel_size = 3)(bn1)\n    cnn5 = Conv3D(filters = 128, activation = 'tanh',kernel_size = 3)(cnn4)\n    cnn6 = Conv3D(filters = 128,activation = 'tanh', kernel_size = 3)(cnn5)\n    bn2 = BatchNormalization()(cnn6)\n    bn2 = MaxPooling3D()(bn2)\n    cnn7 = Conv3D(filters = 256, activation = 'tanh',kernel_size = 3)(bn2)\n    cnn8 = Conv3D(filters = 256, activation = 'tanh',kernel_size = 3)(cnn7)\n    cnn9 = Conv3D(filters = 256, activation = 'tanh',kernel_size = 3)(cnn8)\n    bn3 = BatchNormalization()(cnn9)\n    bn3 = MaxPooling3D()(bn3)\n    flat = GlobalAveragePooling3D()(bn3)\n    dense = Dense(units = 1024)(flat)\n    dense_bn = BatchNormalization()(dense)\n    act = Activation('tanh')(dense_bn)\n    \n    dense2 = Dense(units = 512)(act)\n    dense2_bn = BatchNormalization()(dense2)\n    act2=Activation('relu')(dense2_bn)\n    \n    classification_layer = Dense(units = 1, activation = 'sigmoid', name = \"Classification_layer\")(act2)\n    model = Model(input_layer, classification_layer)\n    return model","386e512c":"model = get_3dcnn()\nmodel.summary()","4a20b10e":"#lr scheduling\nlr_schedule = keras.optimizers.schedules.ExponentialDecay(0.001, decay_steps = 5*280\/10, decay_rate = 0.5, staircase = True)\n#learning rate\ub97c epoch\uac00 \uc9c4\ud589\ub428\uc5d0 \ub530\ub77c\uc11c exponential\ud558\uac8c \uac10\uc18c\uc2dc\ud0b4(decay)\nmodel.compile(loss = 'binary_crossentropy',\n             metrics = ['AUC','accuracy'],\n             optimizer = keras.optimizers.Adam(lr_schedule))","481422b0":"# tracking training sequence\n#!pip install wandb\n#import wandb\n#wandb.login()\n#from wandb.keras import WandbCallback\n#wandb.init(project=\"CT_3DCNN\", entity='id')\n\n#WandB \uad6c\uae00\ub9c1 \ud6c4 \uac04\ub2e8\ud55c \ud29c\ud1a0\ub9ac\uc5bc\uc744 \ud1b5\ud574 \ubaa8\ub378 \ud559\uc2b5\uacfc\uc815\uc744 \uc27d\uac8c \uc2dc\uac01\ud654\ud560 \uc218 \uc788\uc74c.","d66ad30b":"model.fit(train_dataset, epochs = 25, validation_data = val_dataset)","c3035a78":"# Define 3dCNN, compile and Training","feda8f9b":"# Data import","fb3dafba":"> Augmentation\uc744 \ubc14\ud0d5\uc73c\ub85c dataset\uc744 \ub9cc\ub4e4\uc790\n- \uc704\uc5d0\uc11c \uc774\ubbf8 \ud150\uc11c\uc758 \uc870\uac01\ub4e4, \uadf8\ub7ec\ub2c8\uae4c \uc774\ubbf8\uc9c0(\ud150\uc11c)\ub97c \ub9cc\ub4e4\uc5c8\ub2e4. \uc774\ubbf8\uc9c0 \ud558\ub098\ud558\ub098\ub294 \ud55c \uac1c\uc758 \ud150\uc11c, \uc989 \ud150\uc11c \uc870\uac01(tensor slice)\ub85c \uc774\ud574\ud560 \uc218 \uc788\ub2e4\n- \uadf8\ub9ac\uace0 \ud150\uc11c \uc870\uac01\uc744 \ub370\uc774\ud130\uc14b\uc73c\ub85c \ubc14\uafb8\ub824\uba74 tf.data.Dataset.from_tensor_slices(())","6874d052":"# Data augmentation"}}