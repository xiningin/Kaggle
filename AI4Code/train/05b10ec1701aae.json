{"cell_type":{"763da1df":"code","4e10b03c":"code","d47af542":"code","ade56a9e":"code","fce4e5d8":"code","5e2d866b":"code","0aed39cd":"code","946e3afe":"code","3b58b11a":"code","94561190":"code","f5eab63a":"code","0cd4436c":"markdown","cdb36184":"markdown","e7d54696":"markdown","f8f62468":"markdown","c417a9c7":"markdown","bfcfd876":"markdown","b7499a00":"markdown","94e49b92":"markdown","5f5ab948":"markdown","ce1c2023":"markdown"},"source":{"763da1df":"!pip install tez\n!pip install efficientnet-pytorch","4e10b03c":"import os\nimport albumentations\nimport pandas as pd\nimport numpy as np\nimport tez\nfrom tez.datasets import ImageDataset\nfrom tez.callbacks import EarlyStopping\n\nimport torch\nimport torch.nn as nn\nfrom torch.nn import functional as F\n\nfrom efficientnet_pytorch import EfficientNet\nfrom sklearn import metrics, model_selection, preprocessing\nimport matplotlib.pyplot as plt\nimport cv2\n\nSEED = 42\nIMAGE_SIZE = 256\n","d47af542":"dfx = pd.read_csv('..\/input\/aptos2019-blindness-detection\/train.csv')\ndf_train, df_valid = model_selection.train_test_split(\n        dfx, test_size=0.1, random_state=SEED, stratify=dfx.diagnosis.values\n)\n\ndf_train = df_train.reset_index(drop=True)\ndf_valid = df_valid.reset_index(drop=True)\n\nimage_path = \"..\/input\/aptos2019-blindness-detection\/train_images\/\"\ntrain_image_paths = [os.path.join(image_path, x+\".png\") for x in df_train.id_code.values]\nvalid_image_paths = [os.path.join(image_path, x+\".png\") for x in df_valid.id_code.values]\ntrain_targets = df_train.diagnosis.values\nvalid_targets = df_valid.diagnosis.values","ade56a9e":"fig = plt.figure(figsize=(25, 16))\n# display 10 images from each class\nfor class_id in sorted(np.unique(train_targets)):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"..\/input\/aptos2019-blindness-detection\/train_images\/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n\n        plt.imshow(image)\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","fce4e5d8":"fig = plt.figure(figsize=(25, 16))\n# display 10 images from each class\nfor class_id in sorted(np.unique(train_targets)):\n    for i, (idx, row) in enumerate(df_train.loc[df_train['diagnosis'] == class_id].sample(5, random_state=SEED).iterrows()):\n        ax = fig.add_subplot(5, 5, class_id * 5 + i + 1, xticks=[], yticks=[])\n        path=f\"..\/input\/aptos2019-blindness-detection\/train_images\/{row['id_code']}.png\"\n        image = cv2.imread(path)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n        image = cv2.resize(image, (IMAGE_SIZE, IMAGE_SIZE))\n\n        plt.imshow(image, cmap='gray')\n        ax.set_title('Label: %d-%d-%s' % (class_id, idx, row['id_code']) )","5e2d866b":"class EyeModel(tez.Model):\n    def __init__(self, num_classes):\n        super().__init__()\n\n        self.effnet = EfficientNet.from_pretrained(\"efficientnet-b4\")\n        self.dropout = nn.Dropout(0.1)\n        self.out = nn.Linear(1792, num_classes)\n        self.step_scheduler_after = \"epoch\"\n        \n    def monitor_metrics(self, outputs, targets):\n        if targets is None:\n            return {}\n        outputs = torch.argmax(outputs, dim=1).cpu().detach().numpy()\n        targets = targets.cpu().detach().numpy()\n        accuracy = metrics.accuracy_score(targets, outputs)\n        return {\"accuracy\": accuracy}\n    \n    def fetch_optimizer(self):\n        opt = torch.optim.Adam(self.parameters(), lr=3e-4)\n        return opt\n    \n    def fetch_scheduler(self):\n        sch = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n            self.optimizer, T_0=10, T_mult=1, eta_min=1e-6, last_epoch=-1\n        )\n        return sch\n\n    def forward(self, image, targets=None):\n        batch_size, _, _, _ = image.shape\n\n        x = self.effnet.extract_features(image)\n        x = F.adaptive_avg_pool2d(x, 1).reshape(batch_size, -1)\n        outputs = self.out(self.dropout(x))\n        \n        if targets is not None:\n            loss = nn.CrossEntropyLoss()(outputs, targets)\n            metrics = self.monitor_metrics(outputs, targets)\n            return outputs, loss, metrics\n        return outputs, None, None\n","0aed39cd":"\ntrain_aug = albumentations.Compose([\n            albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n            albumentations.Normalize(\n                mean=[0.485], \n                std=[0.229], \n                max_pixel_value=255.0, \n                p=1.0\n            )])\n        \nvalid_aug = albumentations.Compose([\n            albumentations.Resize(IMAGE_SIZE, IMAGE_SIZE, p=1.0),\n            albumentations.Normalize(\n                mean=[0.485], \n                std=[0.229], \n                max_pixel_value=255.0, \n                p=1.0\n            )])","946e3afe":"train_dataset = ImageDataset(\n    image_paths=train_image_paths,\n    targets=train_targets,\n    augmentations=train_aug,\n)\n\ntest_dataset = ImageDataset(\n    image_paths=valid_image_paths,\n    targets=valid_targets,\n    augmentations=valid_aug,\n)\n","3b58b11a":"model = EyeModel(num_classes=5)\nes = EarlyStopping(\n    monitor=\"valid_loss\", model_path=\"model.bin\", patience=5, mode=\"min\"\n)\n","94561190":"model.fit(\n    train_dataset,\n    valid_dataset=test_dataset,\n    train_bs=32,\n    valid_bs=64,\n    device=\"cuda\",\n    epochs=10,\n    callbacks=[es],\n    fp16=True,\n)\n","f5eab63a":"model.save(\"model.bin\")","0cd4436c":"## Install Tez and efficientnet-pytorch impelmentation\n","cdb36184":"## Load, Train & Save Model\n","e7d54696":"## Import What You Need\n","f8f62468":"## Why [Tez](https:\/\/github.com\/abhishekkrthakur\/tez)?\nI always found the learning curve of pytorch a bit complicated, **Tez (\u0924\u0947\u095b \/ \u062a\u06cc\u0632)** aims to make  pytorch training easy and allow fast prototyping by keeping things as simple and as customizable as possible.","c417a9c7":"## What is Diabetic Retinopathy?\nThere are at least 5 things to spot on in order to know that a patient have diabetic retinopahy. Image credit \n\n![](https:\/\/sa1s3optim.patientpop.com\/assets\/images\/provider\/photos\/1947516.jpeg)\n\n\n- [Image source](https:\/\/www.eyeops.com\/contents\/our-services\/eye-diseases\/diabetic-retinopathy)\n\nFrom quick investigations of the data (see various pictures below), Hemorrphages, Hard Exudates and Cotton Wool spots are quite easily observed. However, examples of Aneurysm or Abnormal Growth of Blood Vessels are hard to find in the data. Perhaps the latter two cases are important if we want to catch up human benchmnark using our model.","bfcfd876":"## Visualize Data","b7499a00":"## Model via Tez.Model\n","94e49b92":"## Generate Training and Validation dataset\n","5f5ab948":"## Split Data","ce1c2023":"## Augmentations\n"}}