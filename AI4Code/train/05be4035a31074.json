{"cell_type":{"fb5be728":"code","f806baa1":"code","cbba7d4d":"code","f6b55135":"code","1a641e9a":"code","c6e4d17e":"code","ffe2d651":"code","3d9bf924":"code","446295f1":"code","70712a7f":"code","8f87d522":"code","6beec4bc":"code","a83f307a":"code","36df2f3f":"code","40f8abd1":"code","8f383a64":"code","829e7f98":"code","c2a67e3f":"code","cd771ffb":"code","9cd22c39":"code","a9f00159":"code","61864a57":"code","5e98b148":"code","2ec0b423":"code","8f87685a":"code","1559c4a4":"code","0bff8fb7":"code","b734ca34":"code","6e3e9894":"code","24323011":"code","3753332c":"code","af9e0026":"code","52a2c828":"code","c76de2a3":"code","7f4b362a":"code","cc085930":"code","02f88489":"code","78e913ab":"code","0a2e6588":"code","7ae91849":"code","f246874b":"code","1d485e79":"markdown","16dea866":"markdown","c98b3f2a":"markdown","8fcf9c64":"markdown","dd01239d":"markdown","57e80672":"markdown"},"source":{"fb5be728":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","f806baa1":"reservoir_levels = pd.read_csv('\/kaggle\/input\/chennai-water-management\/chennai_reservoir_levels.csv')\nreservoir_rainfalls = pd.read_csv('\/kaggle\/input\/chennai-water-management\/chennai_reservoir_rainfall.csv')","cbba7d4d":"print(reservoir_levels.head())\nprint(reservoir_rainfalls.head())","f6b55135":"import matplotlib.pyplot as plt\nplt.plot(range(len(reservoir_levels['POONDI'])),reservoir_levels['POONDI'])\nplt.plot(range(len(reservoir_levels['CHOLAVARAM'])),reservoir_levels['CHOLAVARAM'])\nplt.plot(range(len(reservoir_levels['REDHILLS'])),reservoir_levels['REDHILLS'])\nplt.plot(range(len(reservoir_levels['CHEMBARAMBAKKAM'])),reservoir_levels['CHEMBARAMBAKKAM'])\nplt.legend()","1a641e9a":"import matplotlib.pyplot as plt\nplt.plot(range(len(reservoir_rainfalls['POONDI'])),reservoir_rainfalls['POONDI'])\nplt.plot(range(len(reservoir_rainfalls['CHOLAVARAM'])),reservoir_rainfalls['CHOLAVARAM'])\nplt.plot(range(len(reservoir_rainfalls['REDHILLS'])),reservoir_rainfalls['REDHILLS'])\nplt.plot(range(len(reservoir_rainfalls['CHEMBARAMBAKKAM'])),reservoir_rainfalls['CHEMBARAMBAKKAM'])\nplt.legend()","c6e4d17e":"import seaborn as sns\n\nrainfall_corr = reservoir_rainfalls.corr()\nlevel_corr = reservoir_levels.corr()\n\nfig, (ax1, ax2) = plt.subplots(1,2)\nsns.heatmap(rainfall_corr, ax=ax1,annot=True)\nsns.heatmap(level_corr, ax=ax2,annot=True)\nplt.show()","ffe2d651":"# group by month\n# predict by year","3d9bf924":"poondi = [[each] for each in reservoir_levels['POONDI'].values]\ncholavaram = [[each] for each in reservoir_levels['CHOLAVARAM'].values]\nredhills = [[each] for each in reservoir_levels['REDHILLS'].values]\nchembarambakkam = [[each] for each in reservoir_levels['CHEMBARAMBAKKAM'].values]","446295f1":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0, 1))\ny_poondi = scaler.fit_transform(poondi)\ny_cholavaram = scaler.fit_transform(cholavaram)\ny_redhills = scaler.fit_transform(redhills)\ny_chembarambakkam = scaler.fit_transform(chembarambakkam)","70712a7f":"def get_feature_set(train_scaled):\n    features_set = []  \n    labels = []\n    for i in range(60, train_scaled.shape[0]):  \n        features_set.append(train_scaled[i-60:i,0])\n        labels.append(train_scaled[i,0])\n\n    features_set, labels = np.array(features_set), np.array(labels)  \n    features_set = np.reshape(features_set, (features_set.shape[0], features_set.shape[1], 1))\n    \n    return features_set","8f87d522":"l_train = int(y_poondi.shape[0]*0.7)\nl_test = int(y_poondi.shape[0]*0.3)\ntrain_poondi = y_poondi[:l_train]\ntest_poondi = y_poondi[-l_test:]\ntrain_cholavaram = y_cholavaram[:l_train]\ntest_cholavaram = y_cholavaram[-l_test:]\ntrain_redhills = y_redhills[:l_train]\ntest_redhills = y_redhills[-l_test:]\ntrain_chembarambakkam = y_chembarambakkam[:l_train]\ntest_chembarambakkam = y_chembarambakkam[-l_test:]","6beec4bc":"feature_set_p = get_feature_set(train_poondi)\nfeature_set_c = get_feature_set(train_cholavaram)\nfeature_set_r = get_feature_set(train_redhills)\nfeature_set_ch = get_feature_set(train_chembarambakkam)","a83f307a":"print(feature_set_p.shape, feature_set_c.shape, feature_set_r.shape, feature_set_ch.shape)","36df2f3f":"from keras.models import Sequential  \nfrom keras.layers import Dense, LSTM, Dropout\n\ndef def_model(feature_set):\n    model = Sequential()\n\n    model.add(LSTM(units=50, return_sequences=True, input_shape=(feature_set.shape[1], 1)))  \n    model.add(Dropout(0.2))  \n    model.add(LSTM(units=50, return_sequences=True))  \n    model.add(Dropout(0.2))\n\n    model.add(LSTM(units=50, return_sequences=True))  \n    model.add(Dropout(0.2))\n\n    model.add(LSTM(units=50))  \n    model.add(Dropout(0.2))  \n\n    model.add(Dense(units = 1)) \n    model.compile(optimizer = 'adam', loss = 'mean_squared_error')\n    return model","40f8abd1":"pmodel = def_model(feature_set_c)\ncmodel = def_model(feature_set_c)\nrmodel = def_model(feature_set_c)\nchmodel = def_model(feature_set_c)\nchmodel.summary()","8f383a64":"pmodel.fit(feature_set_p, train_poondi[60:], epochs = 10, batch_size = 32)","829e7f98":"feature_set_tp = get_feature_set(test_poondi)\npredictions = pmodel.predict(feature_set_tp)","c2a67e3f":"scaler.inverse_transform(predictions)","cd771ffb":"plt.figure(figsize=(10,6))  \nplt.plot(test_poondi[60:], color='blue', label='Actual')  \nplt.plot(predictions, color='red', label='Predicted')  \nplt.legend()  \nplt.show()","9cd22c39":"cmodel.fit(feature_set_c, train_cholavaram[60:], epochs = 10, batch_size = 32)\nrmodel.fit(feature_set_r, train_redhills[60:], epochs = 10, batch_size = 32)\nchmodel.fit(feature_set_ch, train_chembarambakkam[60:], epochs = 10, batch_size = 32)","a9f00159":"feature_set_tc = get_feature_set(test_cholavaram)\nfeature_set_tr = get_feature_set(test_redhills)\nfeature_set_tch = get_feature_set(test_chembarambakkam)\n\npredictions_tc = cmodel.predict(feature_set_tc)\npredictions_tr = rmodel.predict(feature_set_tr)\npredictions_tch = chmodel.predict(feature_set_tch)","61864a57":"from keras.models import load_model\npmodel.save('\/kaggle\/working\/pmodel.h5')\ncmodel.save('\/kaggle\/working\/cmodel.h5')\nrmodel.save('\/kaggle\/working\/rmodel.h5')\nchmodel.save('\/kaggle\/working\/chmodel.h5')","5e98b148":"crop_range_df = pd.read_csv('\/kaggle\/input\/monthly-normalized-crop-ranges\/ranges.csv')\ncrop_range_df","2ec0b423":"import random\n\nmonths = crop_range_df.columns\ndf = []\n\nfor year in range(2004,2020):\n    for month,each in enumerate(crop_range_df.iloc[0,:].values): # one year\n        x = each.split('-')\n        high = float(x[0])\n        low = float(x[1])\n        noise = random.uniform(-0.05,0.05)\n        df.append([months[month], year, round(random.uniform(high,low)+noise,2)])\n\ndf_generated = pd.DataFrame(df,columns=['month','year','crop'])\ndf_generated.head()","8f87685a":"# example for one field\nimport matplotlib.pyplot as plt\n\nfor i in range(0,len(df_generated),12):\n    plt.plot(df_generated.iloc[i:i+12,2:3].values)\n","1559c4a4":"import random\n\nmonths = crop_range_df.columns\ndf = []\n\nfor year in range(2004,2020):\n    for month,each in enumerate(crop_range_df.iloc[0,:].values): # one year\n        x = each.split('-')\n        high = float(x[0])\n        low = float(x[1])\n        noise = random.uniform(-0.05,0.05)\n        # df.append([months[month], year, round(random.uniform(high,low)+noise,2)])\n        for field in range(0,20):\n            df.append([months[month], year, round(random.uniform(high,low)+noise,2), field])\n\ndf_generated = pd.DataFrame(df,columns=['month','year','crop','field'])\ndf_generated.head()","0bff8fb7":"columns = ['field_id','requirement','closest_reservoir','month','year']","b734ca34":"'''\nAssume there are 20 fields in a district and these 4 are the only reservoirs.\nDataset: field_id, its requirement (sampled from a function) in a month and the closest reservoir\nGroup by month, field and closest. \nPredict: requirement in next month (1 months at a time)\nMake analysis before going to next month\n\nWater going to field (available) = Prev month beginning - next month beginning in reservoir\n\nEx: Jan - F0 - 830 required - POONDI\n    Jan - F1 - 650 required - POONDI ... predicted values in Jan\n    if sum(requirements from POONDI) > available(POONDI) in Jan:\n        # do something\n'''","6e3e9894":"# say 20 fields, 4 reservoirs\n#                0           1           2              3\nreservoirs = ['POONDI','CHOLAVARAM','REDHILLS','CHEMBARAMBAKKAM']\nclosest_reservoirs = [random.randint(0,3) for i in range(20)]\nprint(closest_reservoirs)","24323011":"import matplotlib.pyplot as plt\nplt.hist(closest_reservoirs)","3753332c":"for field in range(0,20):\n    df_generated.loc[df_generated['field']==field,'closest_reservoir'] = closest_reservoirs[field]\ndf_generated.head()","af9e0026":"len(df_generated)","52a2c828":"# Groupby month, year and closest_reservoir\ndf_generated_copy = df_generated.copy()\ndf_generated_copy = df_generated_copy.drop(['field'], axis=1)\ndf_generated_copy = df_generated_copy.groupby(['closest_reservoir','year','month'],sort=False).agg({'crop':'sum'})\n# df_generated_copy.head(12)","c76de2a3":"# normalize crop column\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler(feature_range = (0, 1))\ndf_generated_copy['crop'] = scaler.fit_transform([[crop] for crop in df_generated_copy['crop'].values])\n# df_generated_copy.head()\ndf_generated_copy.loc[1.0,:].head(12)","7f4b362a":"closest_r0 = df_generated_copy.loc[0.0,:].values\nclosest_r1 = df_generated_copy.loc[1.0,:].values\nclosest_r2 = df_generated_copy.loc[2.0,:].values\nclosest_r3 = df_generated_copy.loc[3.0,:].values\nplt.plot(closest_r_0,label=\"0\")\nplt.plot(closest_r_1,label=\"1\")\nplt.plot(closest_r_2,label=\"2\")\nplt.plot(closest_r_3,label=\"3\")\nplt.legend()","cc085930":"train_closest_r2 = closest_r2[:-80]\ntest_closest_r2 = closest_r2[-80:]\nplt.plot(train_closest_r2)","02f88489":"# increase data points.. i.e. add values per day basis\n","78e913ab":"feature_set_r2 = get_feature_set(train_closest_r2)\nr2model = def_model(feature_set=feature_set_r2)\nr0model.fit(feature_set_r2, train_closest_r2[60:], epochs = 10, batch_size = 32)","0a2e6588":"len(train_closest_r2)","7ae91849":"feature_set_tr2 = get_feature_set(test_closest_r2)\npredictions_r2 = r0model.predict(feature_set_tr2)","f246874b":"plt.figure(figsize=(10,6))  \nplt.plot(test_closest_r2[60:], color='blue', label='Actual')  \nplt.plot(predictions_r2, color='red', label='Predicted')  \nplt.legend()  \nplt.show()","1d485e79":"# Associate Reservoir and Crops data","16dea866":"# Visulaize and preprocess","c98b3f2a":"Now we have month, year, requirement and field, reservoir","8fcf9c64":"# Time series prediction of reservoir level and rainfall","dd01239d":"# Time series prediction of crops","57e80672":"# Create dataset for Field information"}}