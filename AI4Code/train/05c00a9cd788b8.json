{"cell_type":{"8d19a203":"code","dee6bf04":"code","d2a56318":"code","86bce979":"code","296b9fc3":"code","06a58a86":"code","851c01ef":"code","a37f264c":"code","b95f76fc":"code","c8bb5582":"code","e4aa03bb":"code","2e978e96":"code","505ecaf4":"code","43125c99":"code","07e2dc7f":"code","ae239586":"code","f62eb2c9":"code","60b2b39e":"code","88582ee8":"code","2bba4434":"code","1a7bffa4":"code","9454023d":"code","7231af0b":"code","aa1666aa":"code","2f0eaf4d":"code","84727809":"code","c5c889d6":"code","95c5a81a":"code","2f8859e8":"code","39e2632b":"code","83b7e3f2":"code","2840ba64":"code","6a931f22":"code","cb51ba2d":"code","815c57f2":"code","f67cb5b1":"code","c46fddce":"code","5db1db7a":"code","0938d591":"code","27c1012c":"code","0b6384e0":"code","4e755207":"code","44450ade":"code","79cf7230":"code","30464c69":"code","ea59cee6":"code","1ee52cc3":"code","10473da5":"code","6bea7ca4":"code","1b85f97d":"code","97a662a1":"code","f5031c0a":"code","012e448c":"code","afa105ca":"code","0ff48161":"code","d291b04e":"code","b42f37fb":"code","166b036e":"code","d6d7fdad":"code","7ac59209":"markdown","7d9a7ecd":"markdown","29427b33":"markdown"},"source":{"8d19a203":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","dee6bf04":"import pandas as pd\nimport numpy as np\nimport datetime\nfrom time import strftime\n\nfrom sklearn.metrics import accuracy_score,precision_score,roc_curve,roc_auc_score,classification_report\nfrom sklearn.model_selection import GridSearchCV,KFold,train_test_split,learning_curve\nfrom sklearn.preprocessing import LabelEncoder,StandardScaler,MinMaxScaler\nimport seaborn as se\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\n\nimport keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom tensorflow.keras.callbacks import EarlyStopping\n\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\nimport seaborn as sns\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.pipeline import Pipeline\nfrom xgboost import XGBClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.tree import ExtraTreeClassifier\nfrom sklearn.linear_model import RidgeClassifier","d2a56318":"data = pd.read_csv('..\/input\/noshowappointments\/KaggleV2-May-2016.csv')","86bce979":"print(\"The shape of the DataFrame {}\".format(data.shape))","296b9fc3":"data.head()","06a58a86":"data['PatientId'] = data['PatientId'].astype('int64')\n\ndata['ScheduledDay'] = pd.to_datetime(data['ScheduledDay']).dt.date.astype('datetime64[ns]')\ndata['AppointmentDay'] = pd.to_datetime(data['AppointmentDay']).dt.date.astype('datetime64[ns]')\n\ndata = data.rename(columns={'Hipertension': 'Hypertension', 'Handcap': 'Handicap', 'SMS_received': 'SMSReceived', 'No-show': 'NoShow'})","851c01ef":"data.info()","a37f264c":"percent_missing = (data.isnull().sum() \/ len(data)).sort_values(ascending = False)\npercent_missing.head()","b95f76fc":"data.head()","c8bb5582":"print(f\"Total of Unique Patients is {data.PatientId.nunique()} and Appointments is {data.AppointmentID.nunique()}\")","e4aa03bb":"null_feat = pd.DataFrame(len(data['PatientId']) - data.isnull().sum(), columns = ['Count'])\n\ntrace = go.Bar(x = null_feat.index, y = null_feat['Count'] ,opacity = 0.8, marker=dict(color = 'lightblue',\n        line=dict(color='#000000',width=1.5)))\n\nlayout = dict(title =  \"Missing Values\")\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","2e978e96":"# Print Unique Values\nprint(\"Unique Values in `Gender` => {}\".format(data.Gender.unique()))\nprint(\"Unique Values in `Scholarship` => {}\".format(data.Scholarship.unique()))\nprint(\"Unique Values in `Hypertension` => {}\".format(data.Hypertension.unique()))\nprint(\"Unique Values in `Diabetes` => {}\".format(data.Diabetes.unique()))\nprint(\"Unique Values in `Alcoholism` => {}\".format(data.Alcoholism.unique()))\nprint(\"Unique Values in `Handicap` => {}\".format(data.Handicap.unique()))\nprint(\"Unique Values in `SMSReceived` => {}\".format(data.SMSReceived.unique()))","505ecaf4":"data['Scholarship'] = data['Scholarship'].astype('object')\ndata['Hypertension'] = data['Hypertension'].astype('object')\ndata['Diabetes'] = data['Diabetes'].astype('object')\ndata['Alcoholism'] = data['Alcoholism'].astype('object')\ndata['Handicap'] = data['Handicap'].astype('object')\ndata['SMSReceived'] = data['SMSReceived'].astype('object')","43125c99":"data.info()","07e2dc7f":"print(\"Patients with `Age` less than -1 - {}\".format(data[data.Age == -1].shape[0]))","ae239586":"data = data[(data.Age >= 0 ) & (data.Age <= 100)]\nprint(\"Unique Values in `Age` => {}\".format(np.sort(data.Age.unique())))","f62eb2c9":"# Get Day of the Week for ScheduledDay and AppointmentDay\ndata['ScheduledDay_DOW'] = data['ScheduledDay'].dt.weekday_name\ndata['AppointmentDay_DOW'] = data['AppointmentDay'].dt.weekday_name","60b2b39e":"data['AppointmentDay'] = np.where((data['AppointmentDay'] - data['ScheduledDay']).dt.days < 0, data['ScheduledDay'], data['AppointmentDay'])\n\n# Get the Waiting Time in Days of the Patients.\ndata['Waiting_Time_days'] = data['AppointmentDay'] - data['ScheduledDay']\ndata['Waiting_Time_days'] = data['Waiting_Time_days'].dt.days","88582ee8":"data","2bba4434":"M = data[(data['NoShow'] == 'Yes')]\nB = data[(data['NoShow'] == 'No')]\ntrace = go.Bar(x = (len(M), len(B)), y = ['Yes','No'], orientation = 'h', opacity = 0.8, marker=dict(\n        color=['green','red'],\n        line=dict(color='#000000',width=1.5)))\n\nlayout = dict(title =  'Count of NoShow variable')\n                    \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","1a7bffa4":"print(\"NoShow and Show '%' of Patients\")\nshow = data.groupby(['NoShow']).size()[0]\/(data.groupby(['NoShow']).size()[0]+data.groupby(['NoShow']).size()[1])\nprint(\"Percent of Patients who `Showed Up`  {}%\".format(show*100))\nnoshow = data.groupby(['NoShow']).size()[1]\/(data.groupby(['NoShow']).size()[0]+data.groupby(['NoShow']).size()[1])\nprint(\"Percent of Patients who Did `Not Showed Up` {}%\".format(noshow*100))","9454023d":"data.groupby(['NoShow']).size()[0]","7231af0b":"g = sns.distplot(data['Age'])\ng.set_title(\"Age Count Distribuition\", fontsize=18)\ng.set_xlabel(\"\")\ng.set_ylabel(\"Probability\", fontsize=12)","aa1666aa":"x = data.groupby('PatientId')['AppointmentDay'].nunique()\nprint('Mean number of appointments per patient:\\t%s' %np.mean(x))\nprint('Median number of appointments per patient:\\t%s' %np.median(x))\n\nplt.figure(1)\nplt.hist(x, bins = x.nunique())\nplt.title(\"Number of Appointments per patient\")\nplt.show","2f0eaf4d":"plt.figure(figsize=(16,4))\nplt.xticks(rotation=90)\nax  = se.countplot(data['Age'],hue = data['NoShow'])\nax.set_title('Appointment by Age')\nplt.show()","84727809":"plt.figure(figsize=(16,4))\nplt.xticks(rotation=90)\nax  = se.countplot(data['Neighbourhood'],hue = data['NoShow'])\nax.set_title('Appointment by Neighbourhood')\nplt.show()","c5c889d6":"data","95c5a81a":"plt.figure(figsize=(16,4))\nax = sns.countplot(x=data.Waiting_Time_days, order=data.Waiting_Time_days.value_counts(ascending=True).iloc[:55].index)\nax.set_title(\"Waiting Time in Days\")\nplt.show()","2f8859e8":"data_viz = data.copy()\nbin_ranges = [-1, 2, 8, 16, 18, 25, 40, 50, 60, 75]\nbin_names = [\"Baby\", \"Children\", \"Teenager\", 'Young', 'Young-Adult', 'Adult', 'Adult-II', 'Senior', 'Old']\n\ndata_viz['age_bin'] = pd.cut(np.array(data_viz['Age']),\n                               bins=bin_ranges, labels=bin_names)\n# now stack and reset\nshow_prob_age = pd.crosstab(data_viz['age_bin'], data_viz['NoShow'], normalize='index')","39e2632b":"stacked = show_prob_age.unstack().reset_index().rename(columns={0:'value'})\nplt.figure(figsize=(16,12))\nax1 = sns.countplot(x=\"age_bin\", data=data_viz)\nax1.set_title(\"Age Bins Count\", fontsize=22)\nax1.set_xlabel(\"Age Categories\", fontsize=18)\nax1.set_ylabel(\"Count\", fontsize=18)","83b7e3f2":"plt.figure(figsize=(10,4))\nax  = se.countplot(data_viz['Hypertension'],hue = data_viz['NoShow'])\nax.set_title('Plot for  Hypertension')\nplt.show()","2840ba64":"plt.figure(figsize=(10,4))\nplt.xticks(rotation=90)\nax  = se.countplot(data_viz['Alcoholism'],hue = data_viz['NoShow'])\nax.set_title('Plot for  Alcoholism')\nplt.show()","6a931f22":"plt.figure(figsize=(10,4))\nplt.xticks(rotation=90)\nax  = se.countplot(data_viz['Diabetes'],hue = data_viz['NoShow'])\nax.set_title('Plot for  Diabetes')\nplt.show()","cb51ba2d":"week_key = ['Monday','Tuesday','Wednesday','Thursday','Friday','Saturday','Sunday']\nplt.figure(figsize=(16,4))\nax = sns.countplot(x=data_viz.AppointmentDay_DOW, hue=data_viz.NoShow, order=week_key)\nax.set_title(\"Show\/NoShow for Appointment Day of the Week\")\nplt.show()","815c57f2":"def dayToNumber(day):\n    if day == 'Monday': \n        return 0\n    if day == 'Tuesday': \n        return 1\n    if day == 'Wednesday': \n        return 2\n    if day == 'Thursday': \n        return 3\n    if day == 'Friday': \n        return 4\n    if day == 'Saturday': \n        return 5\n    if day == 'Sunday': \n        return 6\n\ndata.Gender = data.Gender.apply(lambda x: 1 if x == 'M' else 0)\ndata.ScheduledDay_DOW = data.ScheduledDay_DOW.apply(dayToNumber)\ndata.AppointmentDay_DOW = data.AppointmentDay_DOW.apply(dayToNumber)\ndata.NoShow = data.NoShow.apply(lambda x: 1 if x == 'Yes' else 0)","f67cb5b1":"data['ScheduledDay_Y'] = data['ScheduledDay'].dt.year\ndata['ScheduledDay_M'] = data['ScheduledDay'].dt.month\ndata['ScheduledDay_D'] = data['ScheduledDay'].dt.day\ndata.drop(['ScheduledDay'], axis=1, inplace=True)\n\ndata['AppointmentDay_Y'] = data['AppointmentDay'].dt.year\ndata['AppointmentDay_M'] = data['AppointmentDay'].dt.month\ndata['AppointmentDay_D'] = data['AppointmentDay'].dt.day\ndata.drop(['AppointmentDay'], axis=1, inplace=True)","c46fddce":"col_to_drop = ['PatientId', 'AppointmentID']\ndata = data.drop(col_to_drop,axis=1)","5db1db7a":"le = LabelEncoder()\ndata['Neighbourhood'] = le.fit_transform(data['Neighbourhood'])","0938d591":"data","27c1012c":"data.columns","0b6384e0":"from sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import accuracy_score, confusion_matrix\n\nX = data.drop('NoShow',1)\ny = data.NoShow\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=0)","4e755207":"from imblearn.over_sampling import ADASYN\nbalancer = ADASYN(random_state=42)\nx_resampled, y_resampled = balancer.fit_sample(X_train, y_train)\n\nprint('Normal Data: ', Counter(y_train))\nprint('Resampled: ', Counter(y_resampled))","44450ade":"scaler = MinMaxScaler(feature_range=(0, 1))\nx_resampled = scaler.fit_transform(x_resampled)\nX_test = scaler.transform(X_test)","79cf7230":"def plot_confusion_matrix(cm, classes,\n                          normalize = False,\n                          title = 'Confusion matrix\"',\n                          cmap = plt.cm.Blues) :\n    plt.imshow(cm, interpolation = 'nearest', cmap = cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 0)\n    plt.yticks(tick_marks, classes)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])) :\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment = 'center',\n                 color = 'white' if cm[i, j] > thresh else 'black')\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \n# Show metrics \ndef show_metrics():\n    tp = cm[1,1]\n    fn = cm[1,0]\n    fp = cm[0,1]\n    tn = cm[0,0]\n    print('Accuracy  =     {:.3f}'.format((tp+tn)\/(tp+tn+fp+fn)))\n    print('Precision =     {:.3f}'.format(tp\/(tp+fp)))\n    print('Recall    =     {:.3f}'.format(tp\/(tp+fn)))\n    print('F1_score  =     {:.3f}'.format(2*(((tp\/(tp+fp))*(tp\/(tp+fn)))\/\n                                                 ((tp\/(tp+fp))+(tp\/(tp+fn))))))","30464c69":"def plot_precision_recall():\n    plt.step(recall, precision, color = 'b', alpha = 0.2,\n             where = 'post')\n    plt.fill_between(recall, precision, step ='post', alpha = 0.2,\n                 color = 'b')\n\n    plt.plot(recall, precision, linewidth=2)\n    plt.xlim([0.0,1])\n    plt.ylim([0.0,1.05])\n    plt.xlabel('Recall')\n    plt.ylabel('Precision')\n    plt.title('Precision Recall Curve')\n    plt.show();\n","ea59cee6":"def plot_roc():\n    plt.plot(fpr, tpr, label = 'ROC curve', linewidth = 2)\n    plt.plot([0,1],[0,1], 'k--', linewidth = 2)\n   # plt.xlim([0.0,0.001])\n   # plt.ylim([0.0,1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC Curve')\n    plt.show();","1ee52cc3":"def plot_learning_curve(estimator, title, X, y, ylim = None, cv = None,\n                        n_jobs = 1, train_sizes = np.linspace(.1, 1.0, 5)):\n    \"\"\"\n    Plots a learning curve. http:\/\/scikit-learn.org\/stable\/modules\/learning_curve.html\n    \"\"\"\n    plt.figure()\n    plt.title(title)\n    if ylim is not None:\n        plt.ylim(*ylim)\n    plt.xlabel('Training examples')\n    plt.ylabel('Score')\n    train_sizes, train_scores, test_scores = learning_curve(\n        estimator, X, y, cv = cv, n_jobs = n_jobs, train_sizes = train_sizes)\n    train_scores_mean = np.mean(train_scores, axis = 1)\n    train_scores_std = np.std(train_scores, axis = 1)\n    test_scores_mean = np.mean(test_scores, axis = 1)\n    test_scores_std = np.std(test_scores, axis = 1)\n    plt.grid()\n    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n                     train_scores_mean + train_scores_std, alpha=0.1,\n                     color=\"r\")\n    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n                     test_scores_mean + test_scores_std, alpha = 0.1, color = \"g\")\n    plt.plot(train_sizes, train_scores_mean, 'o-', color = \"r\",\n             label = \"Training score\")\n    plt.plot(train_sizes, test_scores_mean, 'o-', color = \"g\",\n             label = \"Cross-validation score\")\n    plt.legend(loc = \"best\")\n    return plt","10473da5":"def cross_val_metrics(model) :\n    scores = ['accuracy', 'precision', 'recall']\n    for sc in scores:\n        scores = cross_val_score(model, X, y, cv = 5, scoring = sc)\n        print('[%s] : %0.5f (+\/- %0.5f)'%(sc, scores.mean(), scores.std()))","6bea7ca4":"from sklearn.linear_model import LogisticRegression\nlog_clf = LogisticRegression(random_state = 42)\nparam_grid = {\n            'penalty' : ['l2','l1'],  \n            'C' : [0.001, 0.01, 0.1, 1, 10, 100, 1000]\n            }\n\nCV_log_clf = GridSearchCV(estimator = log_clf, param_grid = param_grid , scoring = 'accuracy', verbose = 1, n_jobs = -1)\nCV_log_clf.fit(x_resampled, y_resampled)\n\nbest_parameters = CV_log_clf.best_params_\nprint('The best parameters for using this model is', best_parameters)","1b85f97d":"CV_log2_clf = LogisticRegression(C = best_parameters['C'], \n                                 penalty = best_parameters['penalty'], \n                                 random_state = 42)\n\n\nCV_log2_clf.fit(x_resampled, y_resampled)\n\ny_pred = CV_log2_clf.predict(X_test)\ny_score = CV_log2_clf.decision_function(X_test)\n# Confusion maxtrix & metrics\ncm = confusion_matrix(y_test, y_pred)\nclass_names = [0,1]","97a662a1":"show_metrics()","f5031c0a":"cross_val_metrics(CV_log2_clf)","012e448c":"# ROC curve\nfpr, tpr, t = roc_curve(y_test, y_score)\nplot_roc()","afa105ca":"clfs = []\nseed = 3\n\nclfs.append((\"LogReg\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"LogReg\", LogisticRegression())])))\n\nclfs.append((\"XGBClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"XGB\", XGBClassifier())]))) \nclfs.append((\"KNN\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"KNN\", KNeighborsClassifier())]))) \n\nclfs.append((\"DecisionTreeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"DecisionTrees\", DecisionTreeClassifier())]))) \n\nclfs.append((\"RandomForestClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RandomForest\", RandomForestClassifier())]))) \n\nclfs.append((\"GradientBoostingClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"GradientBoosting\", GradientBoostingClassifier(max_features=15, \n                                                                       n_estimators=600))]))) \n\nclfs.append((\"RidgeClassifier\", \n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"RidgeClassifier\", RidgeClassifier())])))\n\n\nclfs.append((\"ExtraTreesClassifier\",\n             Pipeline([(\"Scaler\", StandardScaler()),\n                       (\"ExtraTrees\", ExtraTreeClassifier())])))\n\nscoring = 'accuracy'\nn_folds = 10\nmsgs = []\nresults, names  = [], [] \n\nfor name, model  in clfs:\n    kfold = KFold(n_splits=n_folds, random_state=seed)\n    cv_results = cross_val_score(model, x_resampled, y_resampled, \n                                 cv=kfold, scoring=scoring, n_jobs=-1)    \n    names.append(name)\n    results.append(cv_results)    \n    msg = \"%s: %f (+\/- %f)\" % (name, cv_results.mean(),  \n                               cv_results.std())\n    msgs.append(msg)\n    print(msg)\n    \n","0ff48161":"# creating a model\nmodel = RandomForestClassifier()\n\n# feeding the training set into the model\nmodel.fit(x_resampled, y_resampled)\n\n# predicting the test set results\ny_pred = model.predict(X_test)\n\n# Calculating the accuracies\nprint(\"Training accuracy :\", model.score(x_resampled, y_resampled))\nprint(\"Testing accuarcy :\", model.score(X_test, y_test))\n\n# classification report\ncr = classification_report(y_test, y_pred)\nprint(cr)\n\n# confusion matrix \ncm = confusion_matrix(y_test, y_pred)\nplt.rcParams['figure.figsize'] = (5, 5)\nse.heatmap(cm, annot = True, cmap = 'winter')\nplt.title('Confusion Matrix', fontsize = 20)\nplt.show()","d291b04e":"model = Sequential()\nmodel.add(Dense(64,input_dim = 18,activation='relu'))\nmodel.add(Dense(32,activation='relu',init = 'uniform'))\nmodel.add(Dense(16,activation='relu',init = 'uniform'))\nmodel.add(Dense(1,activation = 'sigmoid'))\nmodel.summary()","b42f37fb":"model.compile(loss = 'binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1,patience=2)\nhistory=model.fit(x_resampled,y_resampled ,epochs=50,batch_size=128, validation_data=(X_test,y_test))","166b036e":"# evaluate the keras model\n_, accuracy = model.evaluate(x_resampled, y_resampled)\nprint('Accuracy: %.2f' % (accuracy*100))","d6d7fdad":"from matplotlib import pyplot\npyplot.plot(history.history['loss'], label='train')\npyplot.plot(history.history['val_loss'], label='test')\npyplot.legend()\npyplot.show()","7ac59209":"### Machine Learning","7d9a7ecd":"#### Experimenting with ANNs","29427b33":"#### Balancing Dataset using Adasyn"}}