{"cell_type":{"a51dc6d8":"code","0f620799":"code","7433ab97":"code","b10597db":"code","d80148dd":"code","c5ac1425":"code","85ca6e6d":"code","b4720cc3":"code","6db11a33":"code","7f9738b0":"code","60ae2020":"code","afb04bcd":"code","63ea1ead":"code","1bfa8c8e":"code","b9d9ed4a":"code","69862bfe":"code","2b3b4fcf":"code","d8cd93c7":"code","833ccdc3":"markdown","9498bbb8":"markdown","dd59a577":"markdown","61092bd0":"markdown","85a62e9e":"markdown","4705fb7d":"markdown","fd5d2b60":"markdown","c2b99c6c":"markdown","1ae42f2f":"markdown"},"source":{"a51dc6d8":"# author @esha123\n# necessary libraries\nimport os\nfrom glob import glob\nimport torch\nfrom collections import OrderedDict\nimport matplotlib.pyplot as plt\nfrom torchvision import datasets, transforms, models\n%matplotlib inline","0f620799":"# changing working directory\npath = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/chest_xray\/\"\nos.chdir(path)\nprint(os.getcwd())\n\nprint(\"Folders in directory\",end=\" - \")\nprint(os.listdir())\n\n# Total image files in directory\nn_files = len([x for x in glob(os.path.join('*','*','*.jpeg'))])\nprint(\"Total image files : \",n_files)","7433ab97":"data = {}\ndata['Normal'] = len([x for x in glob(os.path.join('*','NORMAL','*.jpeg'))])\ndata['Pneumonia'] = len([x for x in glob(os.path.join('*','PNEUMONIA','*.jpeg'))])\nplt.bar( data.keys(),data.values(), color='green')\nprint(\"Total images: {}, PNEUMONIA: {}, NORMAL: {}\".format(n_files, data['Pneumonia'], data['Normal']))\nplt.xlabel(\"CATEGORIES\")\nplt.ylabel(\"COUNT\")","b10597db":"# transformations on images \ntrans_train = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.RandomRotation(degrees=10),\n    transforms.ColorJitter(), \n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n\ntrans = transforms.Compose([\n    transforms.Resize((256, 256)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],std=[0.229, 0.224, 0.225])])\n\n# Creating datasets using ImageFolder module\ntest_data = datasets.ImageFolder(os.path.join(path,\"test\"), transform = trans)\ntrain_data = datasets.ImageFolder(os.path.join(path,\"train\"), transform = trans_train)\nval_data = datasets.ImageFolder(os.path.join(path,\"val\"), transform = trans)\n\n#creating Data Loaders\ntest_loader = torch.utils.data.DataLoader(test_data, batch_size=64, shuffle=True)\ntrain_loader = torch.utils.data.DataLoader(train_data, batch_size=64, shuffle=True)\nval_loader = torch.utils.data.DataLoader(val_data, batch_size=64, shuffle=True)","d80148dd":"#peek in data\ncategories = ['NORMAL', 'PNEUMONIA']\nimg, label = next(iter(train_loader))\nprint(\"Images shape :{} \".format(img.size()))\nprint(\"Label for 1st image : \",categories[label[0]])\nplt.imshow(img[0].numpy().transpose())\n#labels\nprint(train_data.class_to_idx)","c5ac1425":"# using densenet121 pretrained model \nmodel = models.densenet121(pretrained=True)\n# set no grad as we are not going to modify weights of pretrained model except for last layer\nfor param in model.parameters():\n    param.requires_grad = False\n    \nin_feature = model.classifier.in_features # in_feature for input to custom layers\nprint(\"Input for classifier \",in_feature)","85ca6e6d":"# modifying classifier layer\nmodel.classifier = torch.nn.Sequential(OrderedDict([\n    ('layer1',torch.nn.Linear(in_feature,256)),\n    ('ReLU1', torch.nn.ReLU()),\n    ('dp1', torch.nn.Dropout(0.2)),\n    ('layer2', torch.nn.Linear(256,32)),\n    ('ReLU2', torch.nn.ReLU()),\n    ('Output', torch.nn.Linear(32,2)),\n    ('LogSoftmax', torch.nn.LogSoftmax(dim=1))    \n]))\nmodel.classifier","b4720cc3":"total_parameters = sum([p.numel() for p in model.parameters()])\ntrainable_parameters = sum([p.numel() for p in model.parameters() if p.requires_grad==True])\nprint(\"Total parameters : {} | Trainable Parameters : {} \".format(total_parameters,trainable_parameters))","6db11a33":"#Validation Function\ndef validation(model, val_loader, gpu):\n    steps = 0\n    with torch.no_grad():\n        model.eval()\n        val_loss = 0\n        val_acc = 0\n        steps += 1\n        for images, labels in val_loader:\n            if gpu:\n                images, labels = images.cuda(), labels.cuda()\n            out = model(images)\n            loss = loss_fun(out, labels)\n            val_loss+=loss.item()*images.size(0)\n            output = torch.nn.functional.softmax(out,dim=1)\n            val_acc+=(output.max(1)[1] == labels.data).type(torch.FloatTensor).mean()\n    print(\"Validation Loss : {} | Validation accuracy : {} \".format(val_loss\/steps, val_acc*100\/steps))\n    return val_loss\/steps, val_acc*100\/steps\n    ","7f9738b0":"gpu = torch.cuda.is_available()\nprint(\"GPU available : {} \".format(gpu))\nif gpu:\n    dev = torch.cuda.device_count()\n    if dev>1:\n        multi_dev = True\n    else:\n        multi_dev = False\n    print(\"No of devices : {} \".format(dev))\n    for _ in range(dev):\n        print(\"Device - \",torch.cuda.get_device_name(_))","60ae2020":"epochs = 15\nloss_fun = torch.nn.NLLLoss()\noptimizer = torch.optim.Adam(model.parameters(), lr=0.01)","afb04bcd":"# transfer to GPU if available\nif gpu:\n    model = model.to(torch.device('cuda'))\n    print(\"Model is now on GPU\")\nelse:\n    print(\"Model is on CPU\")","63ea1ead":"# Training Model\ntrain_loss = 0\ntrain_acc = 0\nloss_list=[]\nbest={\n    'epoch':0,\n    'train_loss':0,\n    'train_acc':0,\n    'val_acc':0,\n    'val_loss':0,\n    'state_dict':None\n}\nmodel.train()\nfor e in range(epochs):\n    steps=0\n    for images, labels in train_loader:\n        steps+=1\n        if gpu:\n            images, labels = images.cuda(), labels.cuda()\n        output = model(images)\n        optimizer.zero_grad()\n        loss = loss_fun(output, labels)\n        loss.backward()\n        optimizer.step()\n        train_acc+=(output.max(1)[1]==labels.data).type(torch.FloatTensor).mean()  \n        train_loss+=loss.item()*images.size(0)\n    print(\"Epoch {} \/ {} completed \".format(e+1,epochs))\n    print(\"Training Accuracy : {}\".format(train_acc*100\/steps))\n    print(\"Training Loss : {}\".format(train_loss\/steps))\n    val_loss, val_acc = validation(model, val_loader, gpu)\n    loss_list.append(train_loss\/steps)\n    print(\"---------------------------------------------------------------------------------------\")\n    if (train_acc*100\/steps)>=best['train_acc']:\n        best['epoch'] = e+1\n        best['train_loss'] = train_loss\/steps\n        best['train_acc'] = train_acc*100\/steps\n        best['val_loss'] = val_loss\n        best['val_acc'] = val_acc\n        best['state_dict'] = model.state_dict()\n    train_loss = 0\n    train_acc = 0\n\nprint(\"Best Epoch: {} with\\n training loss: {} | training accuracy: {} |\\n validation loss: {} | validation accuracy: {}\".\nformat(best['epoch'], best['train_loss'], best['train_acc'], best['val_loss'], best['val_acc']))\nmodel.load_state_dict(best['state_dict'])","1bfa8c8e":"# Training Loss\nplt.plot(range(1,len(loss_list)+1), loss_list )\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Training Loss\")\nplt.title(\"Training Loss variations (NLLLoss)\")\nplt.show()\n","b9d9ed4a":"if gpu:\n    model = model.to(torch.device('cpu'))\nimages, label = next(iter(train_loader))\noutput = model(images).max(1)[1]\nfig, axs = plt.subplots(4,4, sharex=True, sharey=True, figsize=((20, 20)))\nimg_index=0\nprint(\"L- Label, P- Prediction\")\nfor x in range(4):\n    for y in range(4):\n        axs[x][y].imshow(images[img_index].numpy().transpose())\n        axs[x][y].title.set_text(\"L-{}, P-{}\".format(categories[label[img_index]], categories[output[img_index]]))\n        img_index+=1\nplt.show()","69862bfe":"#Testing\nmodel.eval()\nsteps = 0 \ntest_loss = 0\ntest_acc = 0\nif gpu:\n    model = model.to(torch.device('cuda'))\nfor images, labels in test_loader:\n    steps+=1\n    if gpu:\n        images, labels = images.cuda(), labels.cuda()\n    output = model(images)\n    test_loss+=loss_fun(output,labels).item()*images.size(0) \n    test_acc+= (labels.data == output.max(1)[1]).type(torch.FloatTensor).mean()\n\nprint(\"Testing Loss : {} || Testing accuracy : {}\".format(test_loss\/steps, test_acc*100\/steps))","2b3b4fcf":"# saving the model\ndef save_model(file_name):\n    save = {\n        'Model':'Densenet121',\n        'Loss_Function':'NLLLoss',\n        'Epochs':epochs,\n        'Learning_rate':'0.01',\n        'Data':'https:\/\/www.kaggle.com\/paultimothymooney\/chest-xray-pneumonia'\n    }\n    save['State_dict'] = model.state_dict()\n    save['Optimizer'] = optimizer ## save Optimizer if you want to resume training \n    save['Optimizer_state_dict'] = optimizer.state_dict()\n    save['Classifier'] = model.classifier\n    torch.save(save,file_name)\n    print(\"Model successfully saved in \",file_name)\n    \n#Loading Model\ndef load_model(file_name):\n    ld = torch.load(file_name)\n    model = models.densenet121(pretrained=True)\n    for param in model.parameters():\n        param.requires_grad = False\n    model.classifier = ld['Classifier']\n    model.load_state_dict(ld['State_dict'])\n    optimizer = ld['Optimizer']\n    optimizer.load_state_dict(ld['Optimizer_state_dict'])\n    return model, optimizer","d8cd93c7":"os.chdir('\/kaggle\/working')\nf_name = 'Pneumoia_Densenet121.pth'\nsave_model(f_name)","833ccdc3":"<h2>Import Libraries<\/h2>\n<ul>\n    <li>os - for various system commands like changing directories, etc<\/li>\n    <li>glob - for searching for all files using pattern [ used for counting image files] <\/li>\n    <li>torch - Pytorch modules<\/li>\n    <li>OrderedDict<\/li>\n    <li>matplotlib.pyplot - for visualizations<\/li>\n    <li>torchvision -  models, datasets, transforms<\/li>\n<\/ul>    ","9498bbb8":"<h1>About Project <\/h1>\nIn this notebook, we'll see how to use PyTorch to train a classifier to identify the presence of Pneumonia by looking at chest X Ray images. Through this project, we'll get familiar with the basics of transfer learning, PyTorch and convolutional neural networks. This project will culminate in a model that can predict the presence of pneumonia with human radiologist-level accuracy.<br>\n<br>\n<h2>What is Pneumonia?<\/h2>\nPneumonia is a lung inflammation caused by a viral or bacterial infection that can range from mild to \nsevere cases. This inflammation makes the patient unable to breathe enough oxygen to reach the bloodstream. \nIt happens when an infection makes the air sacs (alveoli) in the lungs fill with fluid or pus that might \naffect either one or both lungs. If your doctor thinks you might have pneumonia, a chest X-ray will be\nperformed to find the infection in the patient's lungs and how far it\u2019s spread.  <a href=\"https:\/\/en.wikipedia.org\/wiki\/Pneumonia\">wikipedia<\/a><br><br>\n<h2>Pytorch<\/h2>\nis An open source deep learning platform that provides a seamless path from research prototyping to production deployment. <a href=\"https:\/\/pytorch.org\/\">see the oficial web site<\/a><br>\n\n<h2>Dataset<\/h2><ul>\n<li><h3>Content<\/h3>\n The dataset is organized into 3 folders (train, test, val) and contains subfolders for each image category (Pneumonia\/Normal). There are 5,863 X-Ray images (JPEG) and 2 categories (Pneumonia\/Normal).\n\nChest X-ray images (anterior-posterior) were selected from retrospective cohorts of pediatric patients of one to five years old from Guangzhou Women and Children\u2019s Medical Center, Guangzhou. All chest X-ray imaging was performed as part of patients\u2019 routine clinical care.\n\nFor the analysis of chest x-ray images, all chest radiographs were initially screened for quality control by removing all low quality or unreadable scans. The diagnoses for the images were then graded by two expert physicians before being cleared for training the AI system. In order to account for any grading errors, the evaluation set was also checked by a third expert.\n<\/li><br>\n<li><h3>Acknowledgements<\/h3>\nData: <a href=\"https:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/2\">\n    https:\/\/data.mendeley.com\/datasets\/rscbjbr9sj\/2<\/a> <br>\nLicense: CC BY 4.0 <br>\nCitation: <a href=\"http:\/\/www.cell.com\/cell\/fulltext\/S0092-8674(18)30154-5\">http:\/\/www.cell.com\/cell\/fulltext\/S0092-8674(18)30154-5 <\/a><br>\n<\/li>\n<\/ul>","dd59a577":"<h2>Model Architecture <\/h2>\nIn this project, we will fine-tune an existing CNN architecture to classify x-rays images for the\npresence of pneumonia. There is no required architecture required for this project, but a\nreasonable choice would be using the <strong>DENSENET121<\/strong> architecture with weights trained on the\nImageNet dataset. Fine-tuning can be performed by freezing our chosen pre-built network and\nadding several new layers to the end to train.\n\n<img src=\"https:\/\/github.com\/imasy36\/Machine-Learning-with-python\/blob\/master\/Pneumonia_Detection_densenet\/images\/Densenet121.png?raw=true\" \/>\n\n<center><i>One level deeper look at DenseNet-121. Dense Block and Transition Block.<\/i><\/center>","61092bd0":"<h3>Detecting GPU<\/h3>","85a62e9e":"<h3>Training Loss and Optimizer : <\/h3>\nThe loss is the negative log likelihood and the optimizer is the Adam optimizer with learning rate = 0.1.","4705fb7d":"<h2> Exploring Data <\/h2>","fd5d2b60":"<h2>Training <\/h2>\nFor training, we iterate through the train DataLoader, each time passing one batch through the model. One complete pass through the training data is known as an epoch. After each batch, we calculate the loss and then calculate the gradients of the loss with respect to the model parameters with loss.backward(). This uses autodifferentiation and backpropagation to calculate the gradients.\n\nAfter calculating the gradients, we call optimizer.step() to update the model parameters with the gradients. This is done on every training batch so we are implementing stochastic gradient descent (or rather a version of it with momentum known as Adam). After the training loop has completed, we start the validation loop.","c2b99c6c":"<h2>Image pre processing and data iterators<\/h2>\n<h3>Image Pre-Processing and Augmentation<\/h3>\n<img src=\"https:\/\/github.com\/imasy36\/Machine-Learning-with-python\/blob\/master\/Pneumonia_Detection_densenet\/images\/image_pre.png?raw=true\" \/>","1ae42f2f":"<h3>Custom Classifier<\/h3>\n<ul>\n    <li>Layer1 - input:1024, out:256<\/li>\n    <li>ReLU as activation function<\/li>\n    <li>Dropout with probability of 0.2<\/li>\n    <li>Layer2 - input:256, out:32<\/li>\n    <li>ReLU as activation function<\/li>\n    <li>Output layer - Input:32 , out:2<\/li>\n    <li>LogSoftmax<\/li>\n<\/ul>"}}