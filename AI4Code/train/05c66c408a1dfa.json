{"cell_type":{"0b9e665d":"code","4324660e":"code","937fdfe8":"code","e8f35ed7":"code","df77e9b8":"code","3054b2da":"code","c563ce1a":"code","aa16295c":"code","cacc3dff":"code","98669236":"code","58ea5dba":"code","14b52253":"code","e8b7fada":"code","88d9f36c":"code","387cfd9b":"code","5d2bf582":"code","bcb25ebb":"code","50d93348":"code","2eee5657":"code","73b2aa23":"code","1d22bf39":"code","ca488616":"code","e15c88b5":"code","985fd1ea":"code","30e3822f":"code","0e49cc50":"code","b4dafbd1":"code","d05369bd":"code","bed9fc58":"code","4e162642":"code","1c6b78b0":"markdown","dccf7d00":"markdown"},"source":{"0b9e665d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4324660e":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","937fdfe8":"import os \nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print (os.path.join(dirname, filename))","e8f35ed7":"train = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2022\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2022\/test.csv\")\nsubmission = pd.read_csv(\"\/kaggle\/input\/tabular-playground-series-jan-2022\/sample_submission.csv\")","df77e9b8":"sns.distplot(train['num_sold'])","3054b2da":"for x in ['num_sold']:\n    q75,q25 = np.percentile(train.loc[:,x],[75,25])\n    intr_qr = q75-q25\n \n    max = q75+(1.5*intr_qr)\n    min = q25-(1.5*intr_qr)\n \n    train.loc[train[x] < min,x] = np.nan\n    train.loc[train[x] > max,x] = np.nan","c563ce1a":"train['num_sold'].isnull().sum()","aa16295c":"train = train.dropna(axis = 0)\ntrain","cacc3dff":"target = train['num_sold']\n\nsns.distplot(train['num_sold'])","98669236":"combi = train.drop(['num_sold'], axis=1).append(test)\ncombi","58ea5dba":"combi = combi.drop(['row_id'], axis=1)\ncombi","14b52253":"combi['date'] = pd.to_datetime(combi['date'], errors='coerce')\ncombi","e8b7fada":"from datetime import datetime\n\ncombi[\"day_of_week\"] = combi['date'].dt.dayofweek\ncombi[\"is_weekend\"] = combi['day_of_week'] > 4\n\ncombi","88d9f36c":"combi['is_weekend'] = combi['is_weekend']* 1\ncombi","387cfd9b":"combi['year'] = combi['date'].dt.year\ncombi['month'] = combi['date'].dt.month\ncombi['day'] = combi['date'].dt.day\n\ncombi","5d2bf582":"if combi['month'] is 12 and combi['day'] is 25:\n    combi['xmas1'] = True\nelse:\n    combi['xmas1'] = False\n\ncombi['xmas1'] = combi['xmas1'] * 1\n\ncombi","bcb25ebb":"if combi['month'] is 12 and combi['day'] is 26:\n    combi['xmas2'] = True\nelse:\n    combi['xmas2'] = False\n\ncombi['xmas2'] = combi['xmas2'] * 1\n\ncombi","50d93348":"if combi['month'] is 1 and combi['day'] is 1:\n    combi['new_year'] = True\nelse:\n    combi['new_year'] = False\n\ncombi['new_year'] = combi['new_year'] * 1\n\ncombi","2eee5657":"if combi['year'] is 2015 and combi['month'] is 4 and combi['day'] is 5:\n    combi['easter'] = True\nelif combi['year'] is 2016 and combi['month'] is 3 and combi['day'] is 27:\n    combi['easter'] = True\nelif combi['year'] is 2017 and combi['month'] is 4 and combi['day'] is 16:\n    combi['easter'] = True\nelif combi['year'] is 2018 and combi['month'] is 4 and combi['day'] is 1:\n    combi['easter'] = True\nelif combi['year'] is 2019 and combi['month'] is 4 and combi['day'] is 21:\n    combi['easter'] = True\nelse:\n    combi['easter'] = False\n\ncombi['easter'] = combi['easter'] * 1\n\ncombi","73b2aa23":"from sklearn import preprocessing\nfrom sklearn.preprocessing import OrdinalEncoder\n\nenc = OrdinalEncoder()\n\nfor col in combi:\n    if combi[col].dtype==\"object\":\n        combi[col] = enc.fit_transform(combi[col].values.reshape(-1,1))\ncombi","1d22bf39":"import datetime \n\ncombi['date_num'] = combi['date'].dt.strftime('%d%m%Y')\ncombi['date_num'] = combi['date_num'].astype(int)\ncombi","ca488616":"combi.drop(['date'], axis=1, inplace=True)\ncombi.drop(['year'], axis=1, inplace=True)\ncombi","e15c88b5":"y = target\nX = combi[: len(train)]\nX_test = combi[len(train) :]","985fd1ea":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.1, random_state=42)\nX_train.shape, X_val.shape, y_train.shape,y_val.shape, X_test.shape","30e3822f":"from sklearn.experimental import enable_hist_gradient_boosting \nfrom sklearn.ensemble import HistGradientBoostingRegressor\n\nmodel = HistGradientBoostingRegressor().fit(X_train, y_train)\nprint(model.score(X_train, y_train))","0e49cc50":"y_pred = model.predict(X_val)\nprint(model.score(X_val, y_val))","b4dafbd1":"from sklearn.metrics import mean_squared_error\n\nrmse = mean_squared_error(y_val, y_pred, squared=False)\nrmse","d05369bd":"fig, ax = plt.subplots()\nax.scatter(y_val, y_pred, edgecolors=(0, 0, 0))\nax.plot([y.min(), y.max()], [y.min(), y.max()], 'k--', lw=4)\nax.set_xlabel('Measured')\nax.set_ylabel('Predicted')\nplt.show()","bed9fc58":"preds = model.predict(X_test)\npreds = preds.astype(int)\npreds[preds < 0] = 0\npreds","4e162642":"submission.num_sold = preds\nsubmission.to_csv('submission.csv', index=False)\nsubmission = pd.read_csv(\"submission.csv\")\nsubmission","1c6b78b0":"#### Did it work?\nI checked the metrics.\nI used matplotlib to graph the predicted values against the true values.\nI then predicted on the test set.\nOnce I had predicted on the test set, I prepared the data for submission.\n\n#### What did you not understand about this process?\nWell, everything provides in the competition data page. I've no problem while working on it. If you guys don't understand the thing that I'll do in this notebook then please comment on this notebook.\n\n#### What else do you think you can try as part of this approach?\nLook at a notebook which presents feature engineering (based on the insights of this EDA) and a linear model which makes use of the features.","dccf7d00":"#### What are you trying to do in this notebook?\nThe first thing I did was to import some of the libraries that I would initially need to run the program, being numpy for algebraic expressions, pandas for dataframes, and matplotlib and seaborn for graphics. \nI then used the os library to go into the operating system and retrieve the three csv files that I would need to run the program.\nI then used pandas to read the three csv files into the program and to convert them to dataframes, calling them train, test, and submission.\nI used seaborn to analyse the target, being train[\u2018num_sold\u2019]. When I analysed it, it could be seen that it was skewed and there were a number of outliers.\nI then decided to remove the outliers in the hope that my predictions would improve.\n\n#### What we learned while making this notebook?\nOnce I had converted the outliers to null values, I checked for null values. I dropped the rows that had null values and this had the effect of reducing the length of the train dataframe.\nI created the variable, target, which would be used to make predictions.\nI analysed the target once more and, once the outliers had been removed, the shape of the column of data had greatly improved.\nIt is at this point that I created a new dataframe, combi, which was the train dataframe with the target dropped, and the test dataframe appended to it.\n\n#### Why are you trying it?\nFinding out if a day fell on Easter was a bit trickier because I was required to find out when Easter fell on the train and test data. Once the holidays had been put in the appropriate columns, I used sklearn and created a for loop to ordinal encode all of the columns that were of dtype object.\nI then used datetime to convert the date to a number in the newly created column, [\u2018date_num\u2019] and then convert this number to an integer.\nI then dropped the [\u2018date\u2019] and [\u2018year\u2019] columns because they don\u2019t contribute any valuable information when making predictions.\nOnce the dataframe had been suitably prepared, I defined the X, y and X_test variables. The y variable is the target, the X variable is composed of combi up to the length of train, and the X_test variable is composed of combi from the length of train to the end.\nI then used sklearn\u2019s train_test_split to split the X and y variables up into training and validation sets.\n"}}