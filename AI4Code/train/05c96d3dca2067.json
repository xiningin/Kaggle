{"cell_type":{"4d36b873":"code","a5983fee":"code","80bda1f6":"code","7e8d5c11":"code","a5fbdc55":"code","5fe67754":"code","e2759b82":"code","d8e0958e":"code","0c53e5cc":"code","d8f7fdc5":"code","c408d227":"code","2abc0714":"code","db8adf2d":"code","c874511e":"code","9eb845c1":"code","f111a4d0":"code","c76c70e2":"code","973eba7d":"code","766946fb":"code","65e50747":"code","19a1bdf0":"code","5991dcc3":"code","dd93714e":"code","636a4f84":"code","738dc85f":"code","0c1aa88b":"code","3cf398c3":"code","33b4dfb2":"code","7d34614a":"code","9de398e2":"code","5a38284f":"code","90eb3695":"markdown","bc3bd235":"markdown","bd30468b":"markdown","b5732622":"markdown","0eaf3c25":"markdown","045999c4":"markdown","e9e170bb":"markdown","1ff7f522":"markdown","68d7fcb4":"markdown","90016332":"markdown","fa90bd57":"markdown","7f1b0db0":"markdown"},"source":{"4d36b873":"import json, sys, random, os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport PIL\nimport seaborn as sns\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Flatten, Activation\nfrom tensorflow.keras.layers import Dropout\nfrom tensorflow.keras.layers import Conv2D, MaxPooling2D,ZeroPadding2D\nfrom tensorflow.keras.optimizers import SGD\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau, EarlyStopping, ModelCheckpoint, LearningRateScheduler\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.initializers import glorot_uniform\nfrom tensorflow.keras.utils import plot_model\nfrom PIL import Image, ImageDraw \nfrom sklearn.model_selection import train_test_split\nfrom sklearn.utils import shuffle\nimport tensorflow as tf\nfrom keras.preprocessing.image import ImageDataGenerator\nimport cv2\nimport matplotlib.pyplot as plt\nfrom os import listdir\nimport time  \nimport math\nimport shutil\nfrom tqdm import tqdm\nfrom tensorflow.keras.preprocessing import image\n","a5983fee":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\ntrain = train_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/train',\n        target_size=(400, 400),\n        batch_size=32,\n        class_mode='binary')\ntest = test_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/test',\n        target_size=(400, 400),\n        batch_size=32,\n        class_mode='binary')\nvalidation = val_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/valid',\n        target_size=(400, 400),\n        batch_size=32,\n        class_mode='binary')","80bda1f6":"print(train.class_indices)\nprint(test.class_indices)\nprint(validation.class_indices)","7e8d5c11":"plt.imshow(plt.imread(\"..\/input\/brats-2019-traintestvalid\/dataset\/test\/N1.jpeg\"))","a5fbdc55":"!pip install imutils","5fe67754":"IMG_SIZE = (224,224)\nimport imutils\nimg = cv2.imread('..\/input\/brats-2019-traintestvalid\/dataset\/test\/N2.jpeg')\nimg = cv2.resize(\n            img,\n            dsize=IMG_SIZE,\n            interpolation=cv2.INTER_CUBIC\n        )\ngray = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\ngray = cv2.GaussianBlur(gray, (5, 5), 0)\n\n# threshold the image, then perform a series of erosions +\n# dilations to remove any small regions of noise\nthresh = cv2.threshold(gray, 45, 255, cv2.THRESH_BINARY)[1]\nthresh = cv2.erode(thresh, None, iterations=2)\nthresh = cv2.dilate(thresh, None, iterations=2)\n\n# find contours in thresholded image, then grab the largest one\ncnts = cv2.findContours(thresh.copy(), cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)\ncnts = imutils.grab_contours(cnts)\nc = max(cnts, key=cv2.contourArea)\n\n# find the extreme points\nextLeft = tuple(c[c[:, :, 0].argmin()][0])\nextRight = tuple(c[c[:, :, 0].argmax()][0])\nextTop = tuple(c[c[:, :, 1].argmin()][0])\nextBot = tuple(c[c[:, :, 1].argmax()][0])\n\n# add contour on the image\nimg_cnt = cv2.drawContours(img.copy(), [c], -1, (0, 255, 255), 4)\n\n# add extreme points\nimg_pnt = cv2.circle(img_cnt.copy(), extLeft, 8, (0, 0, 255), -1)\nimg_pnt = cv2.circle(img_pnt, extRight, 8, (0, 255, 0), -1)\nimg_pnt = cv2.circle(img_pnt, extTop, 8, (255, 0, 0), -1)\nimg_pnt = cv2.circle(img_pnt, extBot, 8, (255, 255, 0), -1)\n\n# crop\nADD_PIXELS = 0\nnew_img = img[extTop[1]-ADD_PIXELS:extBot[1]+ADD_PIXELS, extLeft[0]-ADD_PIXELS:extRight[0]+ADD_PIXELS].copy()","e2759b82":"plt.figure(figsize=(15,6))\nplt.subplot(141)\nplt.imshow(img)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 1. Get the original image')\nplt.subplot(142)\nplt.imshow(img_cnt)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 2. Find the biggest contour')\nplt.subplot(143)\nplt.imshow(img_pnt)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 3. Find the extreme points')\nplt.subplot(144)\nplt.imshow(new_img)\nplt.xticks([])\nplt.yticks([])\nplt.title('Step 4. Crop the image')\nplt.show()","d8e0958e":"# early stopping\nes = EarlyStopping(monitor='val_accuracy', min_delta= 0.01 , patience= 5, verbose= 1, mode='auto')","0c53e5cc":"model = Sequential() \n\nmodel.add(Conv2D(filters=32, kernel_size= (3,3), activation= 'relu', input_shape=(400, 400,3)) )\n\nmodel.add(Conv2D(filters=32, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(Conv2D(filters=64, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(Conv2D(filters=128, kernel_size=(3,3), activation='relu' ))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n\nmodel.add(Flatten())\nmodel.add(Dense(units=512, activation='relu'))\nmodel.add(Dense(units=64, activation='relu'))\nmodel.add(Dense(units=1, activation='sigmoid'))\n\nmodel.compile(loss= \"binary_crossentropy\", optimizer='adam', metrics=['accuracy'] )\n \nmodel.summary()","d8f7fdc5":"es = EarlyStopping(monitor='val_accuracy',min_delta= 0.01 ,  patience= 2, verbose= 2, mode='auto')\nmc = ModelCheckpoint(filepath=\"..\/kaggle\/working\/best_model.h5\",monitor='val_accuracy',save_best_only = True )","c408d227":"model.fit(x=train,validation_data=validation,epochs=5,callbacks = [mc,es], steps_per_epoch=50)","2abc0714":"pd.DataFrame(model.history.history)","db8adf2d":"import seaborn as sns\nsns.set_style(\"darkgrid\")\nplt.figure(figsize=(12,10))\npd.DataFrame(model.history.history).plot(figsize=(15,8))","c874511e":"def predictor(location):\n    test_image=image.load_img(location,target_size=(400,400))\n    test_image=image.img_to_array(test_image)\n    test_image=np.expand_dims(test_image, axis=0)\n    result=model.predict(test_image)\n\n    if result[0][0] == 0:\n        \n        prediction = \"The MRI image is no of BRAIN TUMOR\"\n    else:\n        prediction = \"The MRI image is of BRAIN TUMOR\"\n    print(result[0][0])\n    return prediction","9eb845c1":"plt.imshow(plt.imread(\"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1400.jpg\"))","f111a4d0":"predictor(\"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1400.jpg\")","c76c70e2":"import PIL\nfig, axs = plt.subplots(2, 5, figsize=(20, 10))\nlst = [\"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1401.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1402.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1403.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1404.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1405.jpg\",\n       \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1400.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1401.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1402.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1403.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1404.jpg\"]\n\naxs[0][0].title.set_text(predictor(lst[0]))\naxs[0][0].imshow(PIL.Image.open(lst[0]))\naxs[0][1].title.set_text(predictor(lst[1]))\naxs[0][1].imshow(PIL.Image.open(lst[1])) \naxs[0][2].title.set_text(predictor(lst[2]))\naxs[0][2].imshow(PIL.Image.open(lst[2]))  \naxs[0][3].title.set_text(predictor(lst[3]))\naxs[0][3].imshow(PIL.Image.open(lst[3]))  \naxs[0][4].title.set_text(predictor(lst[4]))\naxs[0][4].imshow(PIL.Image.open(lst[4]))    \naxs[1][0].title.set_text(predictor(lst[5]))\naxs[1][0].imshow(PIL.Image.open(lst[5]))   \naxs[1][1].title.set_text(predictor(lst[6]))\naxs[1][1].imshow(PIL.Image.open(lst[6]))  \naxs[1][2].title.set_text(predictor(lst[7]))\naxs[1][2].imshow(PIL.Image.open(lst[7])) \naxs[1][3].title.set_text(predictor(lst[8]))\naxs[1][3].imshow(PIL.Image.open(lst[8]))  \naxs[1][4].title.set_text(predictor(lst[9]))\naxs[1][4].imshow(PIL.Image.open(lst[9]))\n\nfig.tight_layout()","973eba7d":"from tensorflow.keras.applications.mobilenet import MobileNet, preprocess_input","766946fb":"train_datagen = ImageDataGenerator(\n        rescale=1.\/255,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale = 1.\/255)\n\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)\ntrain = train_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/train',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='binary')\ntest = test_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/test',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='binary')\nvalidation = val_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/valid',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='binary')","65e50747":"from tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Dense, GlobalAveragePooling2D\nfrom tensorflow.keras.optimizers import RMSprop\nbase_model = MobileNet(input_shape=(224, 224, 3),#we can specify the inpur shape with this parameter\n    include_top=False) # Do not include the ImageNet classifier at the top.)","19a1bdf0":"base_model.trainable = False # We freeze the training of the convolutions\nbase_model.summary()","5991dcc3":"# Flatten the output layer to 1 dimension\ncnn = Flatten()(base_model.output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\ncnn = Dense(units=1024, activation =\"relu\")(cnn)\n# Add a dropout rate of 0.2\ncnn = Dropout(0.2)(cnn)\n# Add a final sigmoid layer for classification\ncnn = Dense(units = 1, activation = \"sigmoid\")(cnn)\ncnn = Model( base_model.input, cnn)","dd93714e":"cnn.summary()","636a4f84":"cnn.compile(optimizer = RMSprop(learning_rate=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['accuracy'])","738dc85f":"es = EarlyStopping(monitor='val_accuracy',min_delta= 0.01 ,  patience= 2, verbose= 2, mode='auto')\nmc = ModelCheckpoint(filepath=\"..\/kaggle\/working\/best_modelwithtransferlearning.h5\",monitor='val_accuracy',save_best_only = True )\ncnn.fit(x=train,validation_data=validation,epochs=5,callbacks = [mc,es], steps_per_epoch=50)","0c1aa88b":"print(cnn.evaluate(validation))","3cf398c3":"model_best = load_model(\"..\/kaggle\/working\/best_modelwithtransferlearning.h5\")","33b4dfb2":"model_best.evaluate(validation)","7d34614a":"validation.class_indices","9de398e2":"def predictor(path):\n    img = image.load_img(path, target_size=(224,224),  )\n    i = image.img_to_array(img)\/255\n    input_arr = np.array([i])\n    input_arr.shape\n    pred = model.predict(input_arr)[0][0] \n    if pred > 0.5:\n        print(\"The MRI image is of BRAIN TUMOR\")\n    else:\n        print(\"The MRI image is of HEALTHY BRAIN WITHOUT TUMOR\")\n        ","5a38284f":"fig, axs = plt.subplots(2, 5, figsize=(20, 10))\nlst = [\"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1401.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1402.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1403.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1404.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/yes\/y1405.jpg\",\n       \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1400.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1401.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1402.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1403.jpg\",\n      \"..\/input\/brats-2019-traintestvalid\/dataset\/valid\/no\/no1404.jpg\"]\n\naxs[0][0].title.set_text(predictor(lst[0]))\naxs[0][0].imshow(PIL.Image.open(lst[0]))\naxs[0][1].title.set_text(predictor(lst[1]))\naxs[0][1].imshow(PIL.Image.open(lst[1])) \naxs[0][2].title.set_text(predictor(lst[2]))\naxs[0][2].imshow(PIL.Image.open(lst[2]))  \naxs[0][3].title.set_text(predictor(lst[3]))\naxs[0][3].imshow(PIL.Image.open(lst[3]))  \naxs[0][4].title.set_text(predictor(lst[4]))\naxs[0][4].imshow(PIL.Image.open(lst[4]))    \naxs[1][0].title.set_text(predictor(lst[5]))\naxs[1][0].imshow(PIL.Image.open(lst[5]))   \naxs[1][1].title.set_text(predictor(lst[6]))\naxs[1][1].imshow(PIL.Image.open(lst[6]))  \naxs[1][2].title.set_text(predictor(lst[7]))\naxs[1][2].imshow(PIL.Image.open(lst[7])) \naxs[1][3].title.set_text(predictor(lst[8]))\naxs[1][3].imshow(PIL.Image.open(lst[8]))  \naxs[1][4].title.set_text(predictor(lst[9]))\naxs[1][4].imshow(PIL.Image.open(lst[9]))\nfig.tight_layout()","90eb3695":"<font color=\"green\">\n1.Take layers from a previously trained model.","bc3bd235":"<font color=\"green\">\nOur transfer model has nearly %98 accuracy compared to my own model. We saved this model during trainng and we will load this model,","bd30468b":"## 3. Transfer Learning for Better Accuracy","b5732622":"<font color=\"green\">\n3.Add some new, trainable layers on top of the frozen layers. ","0eaf3c25":"<font color=\"green\">\nTransfer learning consists of taking features learned on one problem, and leveraging them on a new, similar problem. For instance, features from a model that has learned to identify racoons may be useful to kick-start a model meant to identify tanukis.\n\nTransfer learning is usually done for tasks where your dataset has too little data to train a full-scale model from scratch.\n\nA pre-trained model is a saved network that was previously trained on a large dataset, typically on a large-scale image-classification task. You either use the pretrained model as is or use transfer learning to customize this model to a given task.\n\nThe intuition behind transfer learning for image classification is that if a model is trained on a large and general enough dataset, this model will effectively serve as a generic model of the visual world. You can then take advantage of these learned feature maps without having to start from scratch by training a large model on a large dataset.\nFirst of all, we need repreprocess the images that can suit to our imported model.\n    \nYou will follow the general machine learning workflow.\n\n    1.Take layers from a previously trained model.\n\n    2.Freeze them, so as to avoid destroying any of the information they contain during future training rounds.\n\n    3.Add some new, trainable layers on top of the frozen layers. They will learn to turn the old features into predictions on a new dataset.\n\n    4.Train the new layers on your dataset.","045999c4":"## 2, BUILDING THE MODEL","e9e170bb":"train_datagen = ImageDataGenerator(\n        preprocessing_function=preprocess_input,\n        shear_range=0.2,\n        zoom_range=0.2,\n        horizontal_flip=True)\nval_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n\ntest_datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\ntrain = train_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/train',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='binary')\ntest = test_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/test',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='binary')\nvalidation = val_datagen.flow_from_directory(\n        '..\/input\/brats-2019-traintestvalid\/dataset\/valid',\n        target_size=(224, 224),\n        batch_size=32,\n        class_mode='binary')","1ff7f522":"<font color=\"green\">\n4.Train the new layers on your dataset.","68d7fcb4":"## 1.DATA PREPROCESSING AND DATA ANALYSIS","90016332":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fa90bd57":"<font color=\"green\">\n2.Then, freeze the base model.\n\nIt is important to freeze the convolutional base before you compile and train the model. Freezing (by setting layer.trainable = False) prevents the weights in a given layer from being updated during training. MobileNet  has many layers, so setting the entire model's trainable flag to False will freeze all of them.","7f1b0db0":"<font color=\"green\">\nLets compare the predictions of both models with the test data. When we test two model with the same test data, as seen below the model with transfer learning preidict all of them correctly while the previous one make 3 of tehm fail prediction."}}