{"cell_type":{"2efb665f":"code","a515dbbb":"code","82a0cc49":"code","abfa8f20":"code","2da78d77":"code","55719f24":"code","6dda2b85":"code","56ef6f6a":"code","7317ed5f":"code","c00fffbf":"code","80bbbd61":"code","f5d6055d":"code","4c5e6d66":"code","00cc26f7":"code","4876547a":"code","b56ce001":"code","c261baa3":"code","cc072b67":"code","521ed510":"code","8cd7422b":"code","dfc9b677":"code","57e14e3c":"code","36edec9e":"code","3f481ccd":"code","6e76945c":"markdown","9999d0c8":"markdown","c417949b":"markdown","28e4435b":"markdown","c20d9c6c":"markdown","45e018e6":"markdown","bccaf390":"markdown","c0495ef8":"markdown","3422585f":"markdown","6da7ea3b":"markdown","cf263451":"markdown","dea1c285":"markdown","e179c564":"markdown","613479a5":"markdown","b34efaaa":"markdown","787ab9c9":"markdown","7b9ddd96":"markdown","3c671c48":"markdown","762621d6":"markdown","2ac449a1":"markdown","c28d2de8":"markdown"},"source":{"2efb665f":"!pip install git+https:\/\/github.com\/mjkvaak\/ImageDataAugmentor\n\nimport numpy as np \n\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport cv2\n\nimport keras\nfrom keras import losses\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.layers.core import Activation,Flatten, Dropout, Dense\nfrom keras.layers.convolutional import MaxPooling2D\nfrom keras import Model\nfrom keras.layers import GlobalAveragePooling2D\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras.optimizers import Nadam,Adam\n\nfrom ImageDataAugmentor.image_data_augmentor import *\nimport albumentations\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_curve, auc, roc_auc_score\n\nimport glob\n\n\n\n","a515dbbb":"df = pd.read_csv('..\/input\/histopathologic-cancer-detection\/train_labels.csv')\nprint(df.head(10))","82a0cc49":"column_names = list(df.columns)\nprint(len(df))\n\nprint(len(df[column_names[0]].unique()))\nprint(df[column_names[1]].unique())\n# No duplciate rows","abfa8f20":"df['id']=df['id'].apply(lambda x: x+'.tif')\nprint(df['id'])","2da78d77":"hist = df['label'].hist(bins=5)","55719f24":"fig, axs = plt.subplots(4,4,figsize=(10, 10), dpi=150)\n\n\nimages = []\nfor i in range(4):\n    for j in range(4):\n        \n        No = np.random.randint(0,2000)\n                \n        image = cv2.imread('..\/input\/histopathologic-cancer-detection\/train\/'+ df.iloc[No]['id'])\n        images.append(axs[i, j].imshow(image))\n        \n        if df.iloc[No]['label'] == 1:\n            axs[i,j].set_title('Cancerous')\n        else:\n            axs[i,j].set_title('Non Cancerous')\n            \n        axs[i,j].set_xticks([])\n        axs[i,j].set_yticks([])\n        \n\n    \nplt.show()\n# This will be helpful for image augmentations, like we can do do channel shuffling in order for the model to extract features well or\n# contrast enhancement to make features distinguishable.\ndel images","6dda2b85":"malignant_data = df[(df.label==1)]\nmalignant_image = malignant_data.iloc[1000]['id']\n\nimg = cv2.imread('..\/input\/histopathologic-cancer-detection\/train\/'+malignant_image)\nplt.imshow(img)\nplt.title(\"Cancerous Image\")\nplt.show()\nplt.hist(img[:, :,  0].ravel(), bins = 256, color = 'red')\nplt.hist(img[:, :, 1].ravel(), bins = 256, color = 'Green')\nplt.hist(img[:, :, 2].ravel(), bins = 256, color = 'Blue')\nplt.xlabel('Intensity Value')\nplt.ylabel('Count')\nplt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\nplt.title(\"Cancerous Frequency plot\")\nplt.show()\n\nbenign_data = df[(df.label==0)]\nbenign_image = benign_data.iloc[1]['id']\n\nimg = cv2.imread('..\/input\/histopathologic-cancer-detection\/train\/'+benign_image)\nplt.imshow(img)\nplt.title(\"Non Cancerous Image\")\nplt.show()\nplt.hist(img[:, :, 0].ravel(), bins = 256, color = 'red')\nplt.hist(img[:, :, 1].ravel(), bins = 256, color = 'Green')\nplt.hist(img[:, :, 2].ravel(), bins = 256, color = 'Blue')\nplt.xlabel('Intensity Value')\nplt.ylabel('Count')\nplt.legend(['Red_Channel', 'Green_Channel', 'Blue_Channel'])\nplt.title(\"Non Cancerous Frequency plot\")\nplt.show()\n\ndel img,benign_data,malignant_data","56ef6f6a":"AUGMENTATIONS = albumentations.Compose([\n    \n    albumentations.Flip(p=0.5),\n    albumentations.Rotate(p=0.5),    \n    albumentations.CLAHE(p=0.3), \n    albumentations.RandomContrast(p=0.3) # (Default varies from -0.2 to 0.2)\n    \n]) \n\ntrain_datagen = ImageDataAugmentor(\n        rescale=1.\/255,\n        augment = AUGMENTATIONS\n      )","7317ed5f":"df['label'] = df['label'].astype('str')\n\ntrain, test = train_test_split(df, test_size=0.2,random_state=42)\ntrain, valid = train_test_split(train, test_size=0.1,random_state=42)\n\ntrain_path = '..\/input\/histopathologic-cancer-detection\/train\/'\nvalid_path = '..\/input\/histopathologic-cancer-detection\/train\/'\n\ntrain_generator = train_datagen.flow_from_dataframe(\n                dataframe=train,\n                directory=train_path,\n                x_col = 'id',\n                y_col = 'label',\n                shuffle=True,\n                subset='training',\n                target_size=(94, 94),\n                batch_size=64,\n                class_mode=\"binary\"\n                )\n\nvalid_datagen = ImageDataAugmentor(\n        rescale=1.\/255, )\n\nvalidation_generator = valid_datagen.flow_from_dataframe(\n                dataframe=valid,\n                directory=valid_path,\n                x_col = 'id',\n                y_col = 'label',\n                subset=None, \n                target_size=(94, 94),\n                batch_size=64,\n                shuffle=True,\n                class_mode=\"binary\"\n                )","c00fffbf":"plt.imshow(train_generator[0][0][1])","80bbbd61":"plt.imshow(train_generator[0][0][2])","f5d6055d":"image_shape = (94,94, 3)\n\n# Define base_model\nTLModel = keras.applications.VGG19(weights='imagenet',\n                  include_top=False,\n                  input_shape=(image_shape))\n\n# Make the botton 8 layers trainable\nfor layer in TLModel.layers[:-8]:\n    layer.trainable = False\n\n\nx = TLModel.output\nx = GlobalAveragePooling2D()(x)\n\n# Helps to learn new features\nx = Dense(1000,activation='relu')(x)\nx = Dense(500,activation='relu')(x)\nx = Dense(500,activation='relu')(x)\nx = BatchNormalization()(x)\n\noutput = Dense(1, activation='sigmoid')(x)\n\nmodel = Model(inputs=TLModel.input, outputs=output)\n    \nmodel.summary()\n\n","4c5e6d66":"opt = Nadam()\nmodel.compile(optimizer= opt, loss=losses.binary_crossentropy, metrics=['accuracy'])","00cc26f7":"earlyStop = EarlyStopping(monitor='val_accuracy', mode='max',patience= 4)\nCheckpoint = ModelCheckpoint(filepath='best_model.h5', monitor='val_accuracy', save_best_only=True,mode='max',verbose=1)\n\nStepSizeTrain= int(train_generator.n\/train_generator.batch_size)\nStepSizeValid= int(validation_generator.n\/validation_generator.batch_size)\n\nhist = model.fit_generator(\n                train_generator,\n                steps_per_epoch=StepSizeTrain,\n                validation_steps=StepSizeValid,\n                epochs=25,\n                validation_data=validation_generator\n                ,callbacks=[earlyStop,Checkpoint],verbose=1)\n\n","4876547a":"# Summarize Accuracy\nplt.plot(hist.history['accuracy'])\nplt.plot(hist.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","b56ce001":"# Summarize Loss \nplt.plot(hist.history[\"loss\"])\nplt.plot(hist.history['val_loss'])\nplt.title(\"model loss\")\nplt.ylabel(\"loss\")\nplt.xlabel(\"Epoch\")\nplt.legend([\"Loss\",\"Validation Loss\"])\nplt.show()","c261baa3":"test_datagen = ImageDataAugmentor(rescale=1.\/255)\n\ntest_path = '..\/input\/histopathologic-cancer-detection\/train\/'\ntest_gen = test_datagen.flow_from_dataframe(\n                dataframe=test,\n                directory=test_path,\n                x_col = 'id',\n                y_col = 'label',      \n                target_size=(94, 94),\n                batch_size=1,\n                shuffle=False,\n               class_mode=\"binary\"\n                ) \n\n","cc072b67":"model.load_weights(\"best_model.h5\")\n\n# make predictions\npredictions = model.predict_generator(test_gen, steps=len(test_gen), verbose=1)\nFalse_Positive_rate, True_Positive_rate, Thresholds = roc_curve(test_gen.classes, predictions)\nAUC = auc(False_Positive_rate, True_Positive_rate)","521ed510":"plt.figure(figsize=(20,20))\nplt.plot([0, 1], [0, 1], 'k--')\nplt.plot(False_Positive_rate, True_Positive_rate, label='area = {:.3f}'.format(AUC))\nplt.xlabel('False positive rate')\nplt.ylabel('True positive rate')\nplt.title('ROC curve')\nplt.legend(loc='best')\nplt.show()","8cd7422b":"del test_gen, train_generator, validation_generator","dfc9b677":"test  = pd.DataFrame()\ntest_fileNames = [file for file in glob.glob(\"..\/input\/histopathologic-cancer-detection\/test\/*.tif\")]\n\ntest_fileNames.sort()\n\nFileNames = []\nfor name in test_fileNames:\n    Name = name.replace(\"..\/input\/histopathologic-cancer-detection\/test\/\", \"\")\n    FileNames.append(Name)\n    \ntest['id'] = FileNames","57e14e3c":"test_datagen = ImageDataAugmentor(rescale=1.\/255)\n\ntest_path = '..\/input\/histopathologic-cancer-detection\/test\/'\ntest_gen = test_datagen.flow_from_dataframe(\n                dataframe=test,\n                directory=test_path,\n                x_col = 'id',\n                y_col = None,\n                class_mode=None,\n                target_size=(94, 94),\n                batch_size=1,\n                shuffle=False,   \n                ) ","36edec9e":"predictions = model.predict(test_gen, steps=len(test_gen), verbose=1)","3f481ccd":"output = pd.DataFrame()\n\noutput['id'] = test_gen.filenames\noutput['id'] = output['id'].str.replace('.tif','')\noutput['label'] = predictions\n\n\noutput.to_csv(\"submission.csv\",index=False)\nprint(output)","6e76945c":"# Model Structure adapted from VGG19","9999d0c8":"- Aim\n  -  Create an algorithm to identify metastatic cancer in small image patches taken from larger digital pathology scans.\n  \n- Techniques\n  - Check the distribution of labels \n  - Take a random look at a certain set of images to check for any noticable difference\n  - Check variation of the color channels in a cancerous and non cancerous image\n  - Apply image augmentations based on the features noticed above\n  - Apply transfer learning on the training set using VGG19 architecture.\n  - Apply model on the test set. ","c417949b":"# Libraries","28e4435b":"<img src=\"https:\/\/healthitanalytics.com\/images\/site\/article_headers\/_normal\/ThinkstockPhotos-495951912.jpg\">","c20d9c6c":"# Testing on testing set which was seperated from training set","45e018e6":"# Check distribution of labels","bccaf390":"# Splitting into training, validation and testing sets","c0495ef8":"# References\n- https:\/\/www.kaggle.com\/sdelecourt\/cnn-with-keras\n- https:\/\/www.alibabacloud.com\/blog\/part-3-image-classification-using-features-extracted-by-transfer-learning-in-keras_595291\n- https:\/\/www.kaggle.com\/frlemarchand\/transfer-learning-for-cancer-detection-keras","3422585f":"# Implementing Results on Model","6da7ea3b":"- Frequency in a cancerous image more spread out as compared to a non cancerous image\n- However, this could vary from image to image","cf263451":"# Extract tabular data","dea1c285":"# Check frequency count of the color channels","e179c564":"# Look at random set of images for any noticable difference","613479a5":"- Almost fair distribution of labels","b34efaaa":"- Testing accuracy higher than the training accuracy. This means model is not overfitting.\n- Also a higher accuracy suggest model is not underfitting. ","787ab9c9":"- From the above it is difficult to ascertain the features that distinguish between the cancerous and non cancerous cells\n- There are images of cancerous and non cancerous cells with similar colors.\n- Also, there are images of cancerous and non cancerous with high and low number of circular nodes.\n- Let's look at the frequency count of the color channels of a random image from each category.","7b9ddd96":"- Would appreciate feedback","3c671c48":"# Image Augmentation","762621d6":"# Plot training - validation accuracy and loss curves to check for over and underfitting","2ac449a1":"-  Apart from flipping and rotating the images, we can apply other augmentations\n-  We can reduce contrast of the image to bring down the effect of the color channels.\n-  And apply CLAHE (Contrast Limited Adaptive histogram equalization) to improve the contrast in the image to pick up the effect of the features and the color channel","c28d2de8":"# Applying on testing set"}}