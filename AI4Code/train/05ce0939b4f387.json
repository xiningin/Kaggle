{"cell_type":{"674524d5":"code","0f27cdc0":"code","7f112130":"code","a7d82f02":"code","95423dfa":"code","0460265e":"code","91519fd2":"code","4f273843":"code","99248103":"code","b8c799d3":"code","117b5698":"code","df33f59a":"code","21b00f12":"code","bd3482fb":"code","8e4e3aa0":"code","87c2bf61":"code","98e9ee3d":"markdown","52e217ea":"markdown","c8636eba":"markdown","49321666":"markdown","62323413":"markdown","1db7182f":"markdown","cf153835":"markdown"},"source":{"674524d5":"import pandas as pd\nimport numpy as np\nfrom nltk.stem import WordNetLemmatizer\nimport nltk\nfrom nltk.corpus import stopwords \nfrom nltk.tokenize import word_tokenize \nimport re\nimport spacy\nfrom nltk.corpus import sentiwordnet as swn\nfrom IPython.display import clear_output\nimport plotly.express as px\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud\nimport plotly\nplotly.offline.init_notebook_mode (connected = True)","0f27cdc0":"data=pd.read_csv('..\/input\/trip-advisor-hotel-reviews\/tripadvisor_hotel_reviews.csv')","7f112130":"data.head()","a7d82f02":"data.head()","95423dfa":"# Function to preprocess the hotel data\ndef preprocess_hotel_data(data,name):\n    # Proprocessing the data\n    data[name]=data[name].str.lower()\n    # Code to remove the Hashtags from the text\n    data[name]=data[name].apply(lambda x:re.sub(r'\\B#\\S+','',x))\n    # Code to remove the links from the text\n    data[name]=data[name].apply(lambda x:re.sub(r\"http\\S+\", \"\", x))\n    # Code to remove the Special characters from the text \n    data[name]=data[name].apply(lambda x:' '.join(re.findall(r'\\w+', x)))\n    # Code to substitute the multiple spaces with single spaces\n    data[name]=data[name].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n    # Code to remove all the single characters in the text\n    data[name]=data[name].apply(lambda x:re.sub(r'\\s+[a-zA-Z]\\s+', '', x))\n    # Remove the twitter handlers\n    data[name]=data[name].apply(lambda x:re.sub('@[^\\s]+','',x))\n\n# Function to tokenize and remove the stopwords    \ndef rem_stopwords_tokenize(data,name):\n      \n    def getting(sen):\n        example_sent = sen\n\n        stop_words = set(stopwords.words('english')) \n\n        word_tokens = word_tokenize(example_sent) \n\n        filtered_sentence = [w for w in word_tokens if not w in stop_words] \n\n        filtered_sentence = [] \n\n        for w in word_tokens: \n            if w not in stop_words: \n                filtered_sentence.append(w) \n        return filtered_sentence\n    x=[]\n    for i in data[name].values:\n        x.append(getting(i))\n    data[name]=x\n# Making a function to lemmatize all the words\nlemmatizer = WordNetLemmatizer() \ndef lemmatize_all(data,name):\n    arr=data[name]\n    a=[]\n    for i in arr:\n        b=[]\n        for j in i:\n            x=lemmatizer.lemmatize(j,pos='a')\n            x=lemmatizer.lemmatize(x)\n            b.append(x)\n        a.append(b)\n    data[name]=a\n# Function to make it back into a sentence \ndef make_sentences(data,name):\n    data[name]=data[name].apply(lambda x:' '.join([i+' ' for i in x]))\n    # Removing double spaces if created\n    data[name]=data[name].apply(lambda x:re.sub(r'\\s+', ' ', x, flags=re.I))\n\n","0460265e":"# Using the preprocessing function to preprocess the hotel data\npreprocess_hotel_data(data,'Review')\n# Using tokenizer and removing the stopwords\nrem_stopwords_tokenize(data,'Review')\n# Converting all the texts back to sentences\nmake_sentences(data,'Review')","91519fd2":"# Getting nlp from spacy.load\nnlp=spacy.load('en')\n# Making the function to get the sentiments out of the dataframe\ndef get_sentiment(data,name):\n    count=1\n    l=len(data)\n    positive_sentiments=[]\n    negative_sentiments=[]\n    for tex in data[name].values:\n        print('The current status is :',count*100\/l,'%')\n        tex=nlp(tex)\n        noun=[]\n        verb=[]\n        adj=[]\n        adv=[]\n        for i in tex :\n            if i.pos_=='NOUN':\n                noun.append(i)\n            elif i.pos_ =='ADJ':\n                adj.append(i)\n            elif i.pos_ =='VERB':\n                verb.append(i)\n            elif i.pos_=='ADV':\n                adv.append(i)\n        clear_output(wait=True)\n        count+=1\n        neg_score=[]\n        pos_score=[]\n        for i in tex :\n            try:\n                if i in noun:\n                    x=swn.senti_synset(str(i)+'.n.01')\n                    neg_score.append(x.neg_score())\n                    pos_score.append(x.pos_score())\n                elif i in adj:\n                    x=swn.senti_synset(str(i)+'.a.02')\n                    neg_score.append(x.neg_score())\n                    pos_score.append(x.pos_score())\n                elif i in adv :\n                    x=swn.senti_synset(str(i)+'.r.02')\n                    neg_score.append(x.neg_score())\n                    pos_score.append(x.pos_score())\n                elif i in verb :\n                    x=swn.senti_synset(str(i)+'.v.02')\n                    neg_score.append(x.neg_score())\n                    pos_score.append(x.pos_score())\n\n            except:\n                pass\n        positive_sentiments.append(np.mean(pos_score))\n        negative_sentiments.append(np.mean(neg_score))\n\n    data['Positive Sentiment']=positive_sentiments\n    data['Negative Sentiment']=negative_sentiments","4f273843":"get_sentiment(data,'Review')","99248103":"data.head()","b8c799d3":"overall=[]\nfor i in range(len(data)):\n    if data['Positive Sentiment'][i]>data['Negative Sentiment'][i]:\n        overall.append('Positive')\n    elif data['Positive Sentiment'][i]<data['Negative Sentiment'][i]:\n        overall.append('Negative')\n    else:\n        overall.append('Neutral')\ndata['Overall Sentiment']=overall\n        \n","117b5698":"data.head()","df33f59a":"sns.countplot(data['Overall Sentiment'])","21b00f12":"# The following code creates a word-document matrix.\nfrom sklearn.feature_extraction.text import CountVectorizer\n\nvec = CountVectorizer()\nX = vec.fit_transform(data['Review'])\ndf = pd.DataFrame(X.toarray(), columns = vec.get_feature_names())\ndf.head(3)","bd3482fb":"### Creating a python object of the class CountVectorizer\n\nbow_counts = CountVectorizer(tokenizer= word_tokenize, # type of tokenization\n                             ngram_range=(1,1)) # number of n-grams\n\nbow_data = bow_counts.fit_transform(data['Review'])","8e4e3aa0":"from sklearn.model_selection import train_test_split\nX_train_bow, X_test_bow, y_train_bow, y_test_bow = train_test_split(bow_data, # Features\n                                                                    data['Overall Sentiment'], # Target variable\n                                                                    test_size = 0.2, # 20% test size\n                                                                    random_state = 0) # random","87c2bf61":"from sklearn.linear_model import LogisticRegression\n### Training the model \nlr_model_all = LogisticRegression() # Logistic regression\nlr_model_all.fit(X_train_bow, y_train_bow) # Fitting a logistic regression model\n\n## Predicting the output\ntest_pred_lr_all = lr_model_all.predict(X_test_bow) # Class prediction\n\n\n## Calculate key performance metrics\n\nfrom sklearn.metrics import classification_report\n# Print a classification report\nprint(classification_report(y_test_bow,test_pred_lr_all))","98e9ee3d":"# Preprocessing The Data","52e217ea":"# Importing The Data","c8636eba":"# Having a look at the data","49321666":"So when we are working with sentiwordnet we need to know the characterstic of the word for which we want to know the sentiment . So for finding that position of the word here we are gonna use Spacy.pos_ which tells us about the position of the word which then is used to get the sentiment using the sentiwordnet . We then average out the score for both the positive and the negative score from the whole sentence .\nThe positions compatible with the sentiwordnet are:\n* n - NOUN\n* v - VERB\n* a - ADJECTIVE\n* s - ADJECTIVE SATELLITE\n* r - ADVERB","62323413":"Making the columns for the sentiments(Positive and Neagative ) and declearing overall sentiment which sohows whether the data is positive negative or neutral .","1db7182f":"# Importing The Packages","cf153835":"# Using spacy to Position of a words and working it with sentiwordnet"}}