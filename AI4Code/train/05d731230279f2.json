{"cell_type":{"1bae2e79":"code","b7467dec":"code","c049bdbf":"code","ae847c41":"code","5cc22945":"code","fd79fc61":"code","8d270305":"code","4ec88b13":"code","e5f8440e":"code","c77367f4":"code","84112307":"code","e0d1ffcc":"code","83d1310a":"code","b2f77a7d":"code","aba5de76":"code","d57b4b01":"code","f5e90d50":"code","35604178":"markdown","c2e52582":"markdown","92893ec7":"markdown","9ff18be2":"markdown","afca5b2f":"markdown","0f63faf0":"markdown","e10f037f":"markdown","89c03094":"markdown","2caeb536":"markdown","967609f2":"markdown","1752d379":"markdown","985a51d3":"markdown","a7b547cd":"markdown","0ebf57a0":"markdown"},"source":{"1bae2e79":"cp -r \/kaggle\/input\/images \/tmp","b7467dec":"mv \/tmp\/images\/images\/validation\/ \/tmp\/images\/images\/valid","c049bdbf":"import numpy as np\nimport pandas as pd\n\nfrom fastai.vision import *\nfrom fastai.widgets import *","ae847c41":"path='\/tmp\/images\/images'","5cc22945":"data=ImageDataBunch.from_folder(path,ds_tfms=get_transforms(),size=300)","fd79fc61":"data.show_batch(rows=3,figsize=(6,6))","8d270305":"learner=cnn_learner(data,models.resnet50,metrics=error_rate)\nlearner.fit_one_cycle(4)","4ec88b13":"learner.lr_find()","e5f8440e":"learner.recorder.plot()","c77367f4":"learner.unfreeze()","84112307":"learner.fit_one_cycle(4,max_lr=slice(1e-5,1e-3))","e0d1ffcc":"interp=ClassificationInterpretation.from_learner(learner)","83d1310a":"interp.plot_top_losses(9,figsize=(10,10))","b2f77a7d":"interp.most_confused(min_val=10)","aba5de76":"ds, idxs = DatasetFormatter().from_toplosses(learner, ds_type=DatasetType.Valid)\nImageCleaner(ds,idxs,path)","d57b4b01":"ds, idxs = DatasetFormatter().from_toplosses(learner, ds_type=DatasetType.Train)\nImageCleaner(ds,idxs,path)","f5e90d50":"learner.fit_one_cycle(4,max_lr=slice(1e-5,1e-3))","35604178":"So I decided to fine tune the learning rate for my model with lr_find(). Might help minimizing the error rate. ","c2e52582":"After cleaning up as much as we can, let's fit the model again.","92893ec7":"I'm useing a resnet50 model and error_rate as my metric.\nThe error rate is quite large. Nearly 40% error is not very impressive, given that even the model is usually very accurate.","9ff18be2":"As we can see, error_rate was reduced 10%.\nI guess this is the best we can expect from a noisy dataset. \nWe could spend some more time with cleaning the Training set, improving performance significantly.","afca5b2f":"It is pretty obvious some instances have been missclassified in the dataset. ","0f63faf0":"Importing my packages","e10f037f":"This error_rate is better than before, but the improvement is not significant. At this point I think it's safe to assume that the dataset might have some bad labels and noise. ","89c03094":"Using the optimal learning rate and fitting again.","2caeb536":"Let's see our data now...","967609f2":"Hi, This is my first kernel . I've been doing the fastai course and found this dataset. So I decided to practice with a bit.","1752d379":"Creating a databunch from folder. Fortunately this dataset follows imagenet style, allowing me to just use a factory method.\nI'm taking the pictures with size 300X300 (the larger the better, right?)","985a51d3":"It would be better to fix some of these labels myself. From both training and testing set.","a7b547cd":"So I unfreeze the model to train all of my layers.","0ebf57a0":"It seems my model performs worse after the learning rate goes above 1e-3. Also we can see a consistance downward slope of loss from 1e-5 to 1e-3. This should be our learning rate range."}}