{"cell_type":{"ef3e1fca":"code","881b93a4":"code","6c873c57":"code","743c7ae3":"code","e363b0b1":"code","f2a2f39a":"code","204d1d49":"code","1ed0bf71":"code","dfa1ee15":"code","052d4eee":"code","d8a5f902":"code","3503766d":"code","f4013415":"code","dac77a54":"code","1f9b5de8":"code","b4083530":"code","2674b442":"code","bd71dfd9":"code","e650f9b1":"code","bb66b1a2":"code","9d53ae8f":"code","d750b4b8":"code","7b9e6324":"code","3e58bef6":"code","09ef548f":"code","4819311d":"code","f55f40a8":"code","96f9ffc8":"code","b925d6e4":"markdown","0d43492c":"markdown","53e0b956":"markdown","7a761d39":"markdown","7fc89463":"markdown","a44a4d09":"markdown","25fd5cf9":"markdown","1e3d8fa3":"markdown","ccf27560":"markdown","e2a27b79":"markdown","518b6718":"markdown","f9935ac2":"markdown","0f4a817b":"markdown","84ceb188":"markdown","1f4634bb":"markdown"},"source":{"ef3e1fca":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn import linear_model, preprocessing\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import KFold, learning_curve, cross_val_score, train_test_split\n\nfrom joblib import dump","881b93a4":"# Loading the dataset\ndf = pd.read_csv('\/kaggle\/input\/student-performance-data-set\/student-por.csv')\ndf.sample(5)","6c873c57":"# Getting the average of the grades\ndf['Average Grades'] = df[['G1', 'G2', 'G3']].mean(axis='columns')\ndf.head()","743c7ae3":"df.info()","e363b0b1":"def plot_corr(df, annot=True):\n    _, ax = plt.subplots(figsize=(16, 12))\n    sns.heatmap(\n        df.corr(),\n        annot=annot,\n        cmap=sns.cubehelix_palette(start=.5, rot=-.5, as_cmap=True),\n        ax=ax\n    )\n\n\ndef plot_histplot(column):\n    sns.histplot(x=column, color='#65b87b', alpha=.7) \n    \n    \ndef plot_countplot(df, column_name, ax=None):\n    _df = df[[column_name]].copy()\n    if len(_df[_df[column_name].isnull()]):\n        _df.fillna('NaN', inplace=True)\n    \n    color = '#42b0f5' if ax != None else '#7661ff'\n    sns.countplot(x=column_name, data=_df, color=color, alpha=.7, ax=ax)\n    del _df","f2a2f39a":"plot_histplot(df['Average Grades'])","204d1d49":"plot_corr(df)","1ed0bf71":"def plot_base_relation(df, figsize=(20, 60)):\n    columns = df.columns.tolist()\n    _, axs = plt.subplots(len(columns), 3, figsize=figsize)\n    \n    for idx, column in enumerate(columns):\n        # To get distribution of data\n        sns.histplot(\n            x=df[column],\n            kde=False,\n            color='#65b87b', alpha=.7,\n            ax=axs[idx][0]\n        )\n\n        # To get knowledge about outliers\n        sns.boxplot(\n            x=df[column],\n            color='#6fb9bd',\n            ax=axs[idx][1]\n        )\n\n        # To get its realtion with Average Grades\n        sns.scatterplot(\n            x=column, y='Average Grades', data=df,\n            color='#706dbd', alpha=.7, s=80,\n            ax=axs[idx][2]\n        )\n        \n        \nplot_base_relation(df.select_dtypes(include=[int, float]))","dfa1ee15":"def plot_base_categorical_relation(df, figsize=(20, 60)):\n    columns = df.columns.tolist()\n    _, axs = plt.subplots(len(columns), 3, figsize=figsize)\n    \n    for idx, column in enumerate(columns):\n        try:\n            # To get knowledge about outliers & distribution\n            sns.boxplot(x=df[column], y=df['Average Grades'], ax=axs[idx][0])\n\n            # To get its realtion with Average Grades\n            sns.stripplot(\n                x=column, y='Average Grades', data=df,\n                color='#706dbd', alpha=.7, jitter=.1,\n                ax=axs[idx][1]\n            )\n\n            # To get count plot for `column` (considering NaN, so we can know \n            # how much of data is missing)\n            plot_countplot(df, column, axs[idx][2])\n        except ValueError:\n            # ValueError: min() arg is an empty sequence\n            # \n            # The above error happens while creating plot for some columns (maybe \n            # because it has NaN value)\n            print(f'{column} cannot be plotted')\n        \n        \nplot_base_categorical_relation(\n    pd.concat(\n        [df.select_dtypes(include=['object']), df[['Average Grades']]],\n        axis='columns'\n    )\n)","052d4eee":"ohe_df = pd.get_dummies(df.select_dtypes('object'))\nohe_df.head()","d8a5f902":"# Removing one column after doing one hot encoding to avoid multi-collinearity issues\nohe_df.drop(['romantic_yes'], axis='columns', inplace=True)","3503766d":"# Removing the categorical columns and adding one hot encoded df\n\n# Removing\ncategorical_columns = df.select_dtypes('object').columns.tolist()\ndf.drop(categorical_columns, axis='columns', inplace=True)\n\n# Adding\ndf = pd.concat([df, ohe_df], axis='columns')\ndf.head()","f4013415":"# Since is collinear to G1, G2 & G3\ndf.drop(['Average Grades'], axis='columns', inplace=True)","dac77a54":"# KFold for cross validation\nkf = KFold(n_splits=10, shuffle=True)","1f9b5de8":"# Shuffling the dataset\ndf = df.sample(frac=1, random_state=5)","b4083530":"# Selecting features by analysing which features are collinear to `G3` and collinear \n# to the selected columns\nfeatures = ['failures', 'Medu', 'studytime', 'absences', 'G1', 'G2', 'higher_no', 'higher_yes']\ntarget = 'G3'\n\nx_train, x_test, y_train, y_test = train_test_split(\n    df[features], df[target], test_size=0.3, random_state=0\n)","2674b442":"# Scaling the dataset\n\nscaler = StandardScaler()\n\nx_train = scaler.fit_transform(np.asanyarray(x_train))\ny_train = np.asanyarray(y_train)\n\nx_test = scaler.fit_transform(np.asanyarray(x_test))\ny_test = np.asanyarray(y_test)","bd71dfd9":"# Cross Validation\nscoring = 'r2'\nscore = cross_val_score(linear_model.LinearRegression(), x_train, y_train, cv=4, scoring=scoring)\nscore.mean()","e650f9b1":"# Plotting learning curve\n_sizes = [i for i in range(1, 408, 10)]\ntrain_sizes = np.array([_sizes])  # Relative sizes\nscoring = 'neg_mean_squared_error'\n\nlr = linear_model.LinearRegression()\ntrain_sizes_abs, train_scores, cv_scores = learning_curve(\n    lr, x_train, y_train, train_sizes=train_sizes, cv=10, scoring=scoring\n)","bb66b1a2":"train_scores_mean = []\nfor row in train_scores:\n    _mean = row.mean()\n    train_scores_mean.append(_mean)\n    \ncv_scores_mean = []\nfor row in cv_scores:\n    _mean = row.mean()\n    cv_scores_mean.append(_mean)    \n    \ntrain_scores_mean = -np.array(train_scores_mean)\ncv_scores_mean = -np.array(cv_scores_mean)\n    \nprint(train_scores_mean)\nprint()\nprint(cv_scores_mean)","9d53ae8f":"plt.plot(train_sizes_abs, train_scores_mean, label='Train')\nplt.plot(train_sizes_abs, cv_scores_mean, label='Cross Validation')\n\nplt.legend()","d750b4b8":"# Fitting the model\nmodel = lr.fit(x_train, y_train)","7b9e6324":"# Optimal parameter\ncoefficients = model.coef_\nintercept = model.intercept_\n\nprint(\"Coefficients: \", coefficients)\nprint(\"Intercept: \", model.intercept_)","3e58bef6":"y_test_pred = model.predict(x_test)","09ef548f":"# To see how our model performs on data that model has NOT seen\n\nrms_error = mean_squared_error(y_test, y_test_pred, squared=False)\nr2_score_value = r2_score(y_test, y_test_pred)\n\nprint(f\"Root mean squared error: {rms_error}\")\nprint(f\"R2-score: {r2_score_value}\")","4819311d":"scaling = ('scale', StandardScaler())\nmodel = ('model', linear_model.LinearRegression())\n\n# Steps in the pipeline\nsteps = [scaling, model]\n\npipe = Pipeline(steps=steps)\n\n# Fiitting the model\nmodel = pipe.fit(x_train, y_train)\n\n# Out-Of-Sample Forecast\ny_test_pred = model.predict(x_test)\n\n# Evaluation\nrms_error = mean_squared_error(y_test, y_test_pred, squared=False)\nr2_score_value = r2_score(y_test, y_test_pred)\n\nprint(f\"Root mean squared error: {rms_error}\")\nprint(f\"R2-score: {r2_score_value}\")","f55f40a8":"# Saving the model\ndump(model, 'model.joblib')","96f9ffc8":"f, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(13, 5))\n\nax1.plot(np.arange(len(y_test)), y_test, label='Actual')\nax2.plot(np.arange(len(y_test_pred)), y_test_pred, label='Prediction')\n\nax1.legend()\nax2.legend()\n\nf, ax3 = plt.subplots(nrows=1, ncols=1, figsize=(13, 5))\n\nax3.plot(np.arange(len(y_test)), y_test, label='Actual')\nax3.plot(np.arange(len(y_test_pred)), y_test_pred, label='Prediction')\n\nax3.legend()","b925d6e4":"Here we won't be removing outliers since the dataset size is small","0d43492c":"> `age` has low positive correlation with `failure`\n>\n> `Medu` & `Fedu` has moderate positive correlation & they both have low positive correlation with `grades`\n>\n> `studytime` & `grades` have a low positive correlation\n>\n> `failure` has low negative correlation with `grades`\n>\n> `freetime` has low positive correlation with `goout`\n>\n> `goout` has low positive correlation with `Walc`\n>\n> `Walc` has moderate positive correlation with `Dalc` and they both have negligible negative correlation ","53e0b956":"## \ud83c\udfc4\u200d\u2640\ufe0f Exploratory Data Analysis","7a761d39":"## \u26c4\ufe0f Data preparation","7fc89463":"`Visualizing` our prediction against actual values.","a44a4d09":"Since the number of samples and categories in categorical columns are less, therefore doing `one hot encoding`","25fd5cf9":"**Creating a pipeline**","1e3d8fa3":"**Pearson correlation coefficient significance** \n![Pearson correlation coefficient significance](https:\/\/miro.medium.com\/max\/466\/1*Qz_gwy4ZaSZuOpl3IyO2HA.png)","ccf27560":"### \ud83e\uddec Attribute Information:\n\n1. `school` - student's school (binary: 'GP' - Gabriel Pereira or 'MS' - Mousinho da Silveira)\n2. `sex` - student's sex (binary: 'F' - female or 'M' - male)\n3. `age` - student's age (numeric: from 15 to 22)\n4. `address` - student's home address type (binary: 'U' - urban or 'R' - rural)\n5. `famsize` - family size (binary: 'LE3' - less or equal to 3 or 'GT3' - greater than 3)\n6. `Pstatus` - parent's cohabitation status (binary: 'T' - living together or 'A' - apart)\n7. `Medu` - mother's education (numeric: 0 - none, 1 - primary education (4th grade), 2 \u00e2\u20ac\u201c 5th to 9th grade, 3 \u00e2\u20ac\u201c secondary education or 4 \u00e2\u20ac\u201c higher education)\n8. `Fedu` - father's education (numeric: 0 - none, 1 - primary education (4th grade), 2 \u00e2\u20ac\u201c 5th to 9th grade, 3 \u00e2\u20ac\u201c secondary education or 4 \u00e2\u20ac\u201c higher education)\n9. `Mjob` - mother's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n10. `Fjob` - father's job (nominal: 'teacher', 'health' care related, civil 'services' (e.g. administrative or police), 'at_home' or 'other')\n11. `reason` - reason to choose this school (nominal: close to 'home', school 'reputation', 'course' preference or 'other')\n12. `guardian` - student's guardian (nominal: 'mother', 'father' or 'other')\n13. `traveltime` - home to school travel time (numeric: 1 - <15 min., 2 - 15 to 30 min., 3 - 30 min. to 1 hour, or 4 - >1 hour)\n14. `studytime` - weekly study time (numeric: 1 - <2 hours, 2 - 2 to 5 hours, 3 - 5 to 10 hours, or 4 - >10 hours)\n15. `failures` - number of past class failures (numeric: n if 1<=n<3, else 4)\n16. `schoolsup` - extra educational support (binary: yes or no)\n17. `famsup` - family educational support (binary: yes or no)\n18. `paid` - extra paid classes within the course subject (Math or Portuguese) (binary: yes or no)\n19. `activities` - extra-curricular activities (binary: yes or no)\n20. `nursery` - attended nursery school (binary: yes or no)\n21. `higher` - wants to take higher education (binary: yes or no)\n22. `internet` - Internet access at home (binary: yes or no)\n23. `romantic` - with a romantic relationship (binary: yes or no)\n24. `famrel` - quality of family relationships (numeric: from 1 - very bad to 5 - excellent)\n25. `freetime` - free time after school (numeric: from 1 - very low to 5 - very high)\n26. `goout` - going out with friends (numeric: from 1 - very low to 5 - very high)\n27. `Dalc` - workday alcohol consumption (numeric: from 1 - very low to 5 - very high)\n28. `Walc` - weekend alcohol consumption (numeric: from 1 - very low to 5 - very high)\n29. `health` - current health status (numeric: from 1 - very bad to 5 - very good)\n30. `absences` - number of school absences (numeric: from 0 to 93)\n31. `G1` - first period grade (numeric: from 0 to 20)\n32. `G2` - second period grade (numeric: from 0 to 20)\n33. `G3` - final grade (numeric: from 0 to 20, output target)","e2a27b79":"## \ud83c\udfb8 Modelling\n\nCreating a regression model that can predict student's final grades.","518b6718":"**Helper plotting functions**","f9935ac2":"# Predict students grades\n\nHere [Student Performance Data Set](https:\/\/www.kaggle.com\/larsen0966\/student-performance-data-set) dataset by [Data-Science Sean](https:\/\/www.kaggle.com\/larsen0966) is used to perform `EDA` and create a `machine learning model` that can predict student's final grades i.e. Tthe goal is to predict `G3` using `G1` and `G2`.\n\n![](https:\/\/media.giphy.com\/media\/IPbS5R4fSUl5S\/giphy.gif)","0f4a817b":"---\n\nI'll wrap things up there. If you want to find some other answers then go ahead `edit` this kernel. If you have any `questions` then do let me know.\n\nIf this kernel helped you then don't forget to \ud83d\udd3c `upvote` and share your \ud83c\udf99 `feedback` on improvements of the kernel.\n\n![](https:\/\/media.giphy.com\/media\/ny7UCd6JETnmE\/giphy.gif)\n\n---","84ceb188":"No missing data","1f4634bb":"## \u26f1 Evaluation"}}