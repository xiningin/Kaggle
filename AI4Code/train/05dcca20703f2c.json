{"cell_type":{"6cafe93d":"code","1ad2a5d3":"code","2a485412":"code","b9a4f86b":"code","3bb109b0":"code","7a5a1a4e":"code","bec65e3b":"code","2ff48603":"code","9e865390":"code","57561726":"code","bfec3a87":"code","3d2cbbe4":"code","ef72329d":"code","e0e49f84":"code","1d1aa240":"code","26be64d4":"code","6aecfecd":"code","086259c4":"code","2db57ded":"code","6ed5b7ad":"code","5cbe8284":"code","f8cf3f35":"code","9062a41d":"code","ed952f39":"code","f2a61555":"code","ac376c0f":"code","84e55885":"code","d19c8c91":"code","d8044ca5":"code","03bb71f9":"code","3127b5df":"code","e3504e25":"code","36b6ad2f":"code","2f386621":"code","a7ebcd9c":"code","ffcdc57b":"code","94e0bfce":"code","aa7f7ded":"code","9a8c68d6":"code","d5d7648a":"code","2edde5a7":"code","b0774c1d":"code","b842e70d":"code","f2909105":"code","3a54edd5":"markdown","7af39c15":"markdown","33a57562":"markdown","52a830a7":"markdown","5944f124":"markdown","6b0ed295":"markdown","054a15ad":"markdown","8527544e":"markdown","d56d3ef2":"markdown","ce4438a5":"markdown","d9a1054b":"markdown","d2ec6a04":"markdown","6228a601":"markdown"},"source":{"6cafe93d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","1ad2a5d3":"from kaggle.competitions import twosigmanews\n# You can only call make_env() once, so don't lose it!\nenv = twosigmanews.make_env()","2a485412":"(market_train_df, news_train_df) = env.get_training_data()","b9a4f86b":"# inspired by\n# https:\/\/www.kaggle.com\/artgor\/eda-feature-engineering-and-everything\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\n\nfrom wordcloud import WordCloud\nfrom nltk.corpus import stopwords\nstop = set(stopwords.words('english'))\n\nimport datetime\nimport lightgbm as lgb\nfrom scipy import stats\nfrom scipy.sparse import hstack, csr_matrix\nfrom sklearn.model_selection import train_test_split\nfrom nltk.util import ngrams\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import StandardScaler","3bb109b0":"market_train_df.head()","7a5a1a4e":"market_train_df.isna().sum()","bec65e3b":"market_train_df = market_train_df.drop(columns=\"universe\")","2ff48603":"# zavies\u0165 ist\u00fa metriku, pre detekovanie\nmarket_train_df['price_diff'] = market_train_df['close'] - market_train_df['open']\n\ngrouped = market_train_df.groupby('time').agg({'price_diff': ['std', 'min']}).reset_index()\n\nprint(f\"Average standard deviation of price change within a day in {grouped['price_diff']['std'].mean():.4f}.\")","9e865390":"market_train_df.sort_values('price_diff')[:10]","57561726":"market_train_df['close_to_open'] =  np.abs(market_train_df['close'] \/ market_train_df['open'])","bfec3a87":"market_train_df['assetName_mean_open'] = market_train_df.groupby('assetName')['open'].transform('mean')\nmarket_train_df['assetName_mean_close'] = market_train_df.groupby('assetName')['close'].transform('mean')\n\n# if open price is too far from mean open price for this company, replace it. Otherwise replace close price.\nfor i, row in market_train_df.loc[market_train_df['close_to_open'] >= 2].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']\n        \nfor i, row in market_train_df.loc[market_train_df['close_to_open'] <= 0.5].iterrows():\n    if np.abs(row['assetName_mean_open'] - row['open']) > np.abs(row['assetName_mean_close'] - row['close']):\n        market_train_df.iloc[i,5] = row['assetName_mean_open']\n    else:\n        market_train_df.iloc[i,4] = row['assetName_mean_close']","3d2cbbe4":"market_train_df.sort_values('price_diff')[:10]","ef72329d":"# fill with 0s, but knowing it won't be good\n# and still having outliers\nmarket_train_df['returnsClosePrevMktres1'].fillna(0, inplace=True)\n\nmarket_train_df.head()","e0e49f84":"sns.boxplot(x=market_train_df['returnsOpenNextMktres10'])","1d1aa240":"max(market_train_df['returnsOpenNextMktres10'])","26be64d4":"market_train_df.sort_values('returnsOpenNextMktres10')[:10]","6aecfecd":"market_train_df.sort_values('returnsOpenNextMktres10')           ","086259c4":"Q1 = market_train_df.quantile(0.25)\nQ3 = market_train_df.quantile(0.75)\nIQR = Q3 - Q1\nlowerBound = Q1 - 1.5 * IQR\nupperBound = Q3 + 1.5 * IQR\nprint(IQR)","2db57ded":"IQR_df = market_train_df.loc[lambda df: (df['returnsOpenNextMktres10'] < lowerBound['returnsOpenNextMktres10']) |  (df['returnsOpenNextMktres10'] > upperBound['returnsOpenNextMktres10'])]","6ed5b7ad":"outliers = market_train_df[(market_train_df['returnsOpenNextMktres10'] < lowerBound['returnsOpenNextMktres10']) | (market_train_df['returnsOpenNextMktres10'] > upperBound['returnsOpenNextMktres10'])]\nprint('Identified outliers: %d' % len(outliers))","5cbe8284":"# to have a list\noutliers_list = [x for x in market_train_df['returnsOpenNextMktres10'] if x < lowerBound['returnsOpenNextMktres10'] or x > upperBound['returnsOpenNextMktres10']]\nprint('Identified outliers: %d' % len(outliers))","f8cf3f35":"# removing outliers, that is not wanted HERE IS A DF WITHOUT OUTLIERS\ncond = market_train_df['returnsOpenNextMktres10'].isin(outliers['returnsOpenNextMktres10']) == True # compares\nmarket_train_df_reduced = market_train_df.drop(market_train_df[cond].index, inplace = True) # drops outliers","9062a41d":"market_train_df.sort_values('returnsOpenNextMktres10').head()","ed952f39":"outliers_removed = [x for x in market_train_df['returnsOpenNextMktres10'] if x >= lowerBound['returnsOpenNextMktres10'] or x <= upperBound['returnsOpenNextMktres10']]\nprint('Non-outlier observations: %d' % len(outliers_removed))","f2a61555":"data = [go.Histogram(x=outliers_removed[:10000])]\nlayout = dict(title = \"returnsOpenNextMktres10 (random 10.000 sample; without outliers)\")\npy.iplot(dict(data=data, layout=layout), filename='basic-non-outliers')","ac376c0f":"sns.boxplot(x=market_train_df['returnsOpenNextMktres10'])","84e55885":"# take all continuous; maybe remove those returns not Savitzky-Golay-ed, or use it on them too.\nX = market_train_df[['volume', 'close', 'open', 'returnsClosePrevRaw1','returnsOpenPrevRaw1', 'returnsClosePrevRaw10', 'returnsOpenPrevRaw10']]\ny = market_train_df['returnsOpenNextMktres10']\n\nZ = market_train_df[['close', 'open', 'volume', 'returnsOpenPrevMktres10']] # for correlation","d19c8c91":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=123)","d8044ca5":"from sklearn.linear_model import LinearRegression\n\nslr = LinearRegression()\nslr.fit(X_train, y_train)\nprint('Intercept: %.3f' % slr.intercept_)\nprint('Beta 1:  %.3f' % slr.coef_[0])\nprint('Beta 2:  %.3f' % slr.coef_[1])\nprint('Beta 3:  %.3f' % slr.coef_[2])\n\ny_pred = slr.predict(X_test)\nprint(y_pred[:5])","03bb71f9":"slr.score(X_test, y_test) # R^2","3127b5df":"from sklearn.metrics import mean_absolute_error\n\nprint(mean_absolute_error(y_test, y_pred))","e3504e25":"from sklearn.metrics import mean_squared_error\n\nprint('MSE train: %.3f' % (mean_squared_error(y_test, y_pred)))","36b6ad2f":"max(y_pred)","2f386621":"from sklearn.ensemble import RandomForestRegressor\n\nforest = RandomForestRegressor(n_estimators=10,\n                               max_depth=7, \n                               random_state=123, \n                               n_jobs=-1)\nforest.fit(X_train, y_train)\ny_pred = forest.predict(X_test)","a7ebcd9c":"from sklearn.metrics import mean_absolute_error\nmean_absolute_error(y_test, y_pred)","ffcdc57b":"from sklearn.model_selection import RandomizedSearchCV,GridSearchCV\n# maybe do GridSearch for optimal parameters\ngbm = xgb.XGBRegressor()\nreg_cv = GridSearchCV(gbm, {\"colsample_bytree\":[1.0],\"min_child_weight\":[1.0,1.2], \n                            'max_depth': [3,4,6], \n                            'n_estimators': [5, 10,100]})\nreg_cv.fit(X_train, y_train)\nreg_cv.best_params_","94e0bfce":"gbm = xgb.XGBRegressor(**reg_cv.best_params_)\ngbm.fit(X_train,y_train)","aa7f7ded":"predictions = gbm.predict(X_test)\npredictions","9a8c68d6":"gbm.score(X_test,y_test)","d5d7648a":"gbm.score(X_train,y_train)","2edde5a7":"import xgboost as xgb\n\n#Fitting XGB regressor \nmodel = xgb.XGBRegressor(n_estimators=10,  \n                         max_depth=7, \n                         n_jobs=-1,\n                         random_state=123)\nmodel.fit(X_train, y_train)\npreds = model.predict(X_test)","b0774c1d":"from sklearn.metrics import explained_variance_score # why\nprint(explained_variance_score(y_test, preds))","b842e70d":"mean_absolute_error(y_test, preds)","f2909105":"plt.scatter(y_test, preds)\nplt.show()","3a54edd5":"trace0 = go.Histogram(\n    x=y\n)\ntrace1 = go.Histogram(\n    x=y_pred\n)\ndata = [trace0, trace1]\nlayout = go.Layout(barmode='stack')\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='stacked histogram')","7af39c15":"# Preprocessing","33a57562":"# XGBoosted","52a830a7":"# TO DO\n","5944f124":"## PLAN: no\n1) You have an array of indices of rows with outliers\n\n2) You need to map outlier column value\n\n3) You got savgol coefs\n\n4) You run accross df and check row indices\n\n5) If index is as outlier index then you apply mapping using manual expression with polynom","6b0ed295":"# Random Forest","054a15ad":"trace0 = go.Histogram(\n    x=y\n)\ntrace1 = go.Histogram(\n    x=y_pred\n)\ndata = [trace0, trace1]\nlayout = go.Layout(barmode='stack')\nfig = go.Figure(data=data, layout=layout)\n\npy.iplot(fig, filename='stacked histogram')","8527544e":"V priemere je n\u00e1\u0161 model mimo o 6,8 % v\u00fdnosu.","d56d3ef2":"# need to remove these outliers, make the returnsOpenNextMktres10 more reliable","ce4438a5":"Check outliers within returns","d9a1054b":"# Lin Reg","d2ec6a04":"Prediction of market residuals? Elab more","6228a601":"# **Decision Tree**"}}