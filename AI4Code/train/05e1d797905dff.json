{"cell_type":{"1e119746":"code","9747de64":"code","6262a456":"code","295de61f":"code","fe5d7ef1":"code","ce7f27b8":"code","23743646":"code","08f45eb8":"code","37450fa2":"code","d9ea5bef":"code","b827af63":"code","f9c71ef3":"code","b902f7d9":"code","b94ebe7b":"code","c8e82fc7":"code","f95d6046":"code","cdedaedc":"code","79db7686":"code","4a42811c":"markdown"},"source":{"1e119746":"# Config\nbatch_size = 1\nmin_tokens = 5\ntok_checkpoint = '..\/input\/longformer\/model'\nmodel_checkpoint = '..\/input\/feedback-prize-huggingface-baseline-training\/longformer-base-4096-4\/pytorch_model.bin'","9747de64":"# Load data\nimport pandas as pd\n\ntrain = pd.read_csv('..\/input\/feedback-prize-2021\/train.csv')\ntrain.head(1)\n\ntest = pd.read_csv('..\/input\/feedback-prize-2021\/sample_submission.csv')\ntest.head(1)","6262a456":"# Setup dictionaries\nclasses = train.discourse_type.unique().tolist()\n\nfrom collections import defaultdict\n\ntags = defaultdict()\nfor i, c in enumerate(classes):\n    tags[f'B-{c}'] = i\n    tags[f'I-{c}'] = i + len(classes)\ntags[f'O'] = len(classes) * 2\ntags[f'Special'] = -100\nl2i = dict(tags)\n\ni2l = defaultdict()\nfor k, v in l2i.items(): \n    i2l[v] = k\ni2l[-100] = 'Special'\ni2l = dict(i2l)","295de61f":"# Helper functions\nfrom pathlib import Path\n\ntest_path = Path('..\/input\/feedback-prize-2021\/test')\n\ndef get_test_text(ids):\n    with open(test_path\/f'{ids}.txt', 'r') as file: data = file.read()\n    return data","fe5d7ef1":"# Tokenizer\nfrom transformers import AutoTokenizer\n    \ntokenizer = AutoTokenizer.from_pretrained(tok_checkpoint, add_prefix_space=True)","ce7f27b8":"# Load model\nfrom transformers import AutoModelForTokenClassification, TrainingArguments, Trainer\nimport torch\n\nmodel = AutoModelForTokenClassification.from_pretrained(tok_checkpoint, num_labels=len(i2l)-1)\n\nmodel.load_state_dict(torch.load(model_checkpoint))\nmodel.eval();","23743646":"from transformers import DataCollatorForTokenClassification\n\ndata_collator = DataCollatorForTokenClassification(tokenizer)","08f45eb8":"# We'll use trainer with the loaded model to run inference on test set\ntrainer = Trainer(\n    model,\n    data_collator=data_collator,\n    tokenizer=tokenizer,\n)","37450fa2":"# code that will convert our predictions into prediction strings. we'll skip visualization here. \n# this most likely requires some refactoring\n\ndef get_class(c):\n    if c == 14: return 'Other'\n    else: return i2l[c][2:]\n\ndef pred2span(pred, example, viz=False, test=False):\n    example_id = example['id']\n    n_tokens = len(example['input_ids'])\n    classes = []\n    all_span = []\n    for i, c in enumerate(pred.tolist()):\n        if i == n_tokens-1:\n            break\n        if i == 0:\n            cur_span = example['offset_mapping'][i]\n            classes.append(get_class(c))\n        elif i > 0 and (c == pred[i-1] or (c-7) == pred[i-1]):\n            cur_span[1] = example['offset_mapping'][i][1]\n        else:\n            all_span.append(cur_span)\n            cur_span = example['offset_mapping'][i]\n            classes.append(get_class(c))\n    all_span.append(cur_span)\n    \n    if test: text = get_test_text(example_id)\n    else: text = get_raw_text(example_id)\n        \n    # map token ids to word (whitespace) token ids\n    predstrings = []\n    for span in all_span:\n        span_start = span[0]\n        span_end = span[1]\n        before = text[:span_start]\n        token_start = len(before.split())\n        if len(before) == 0: token_start = 0\n        elif before[-1] != ' ': token_start -= 1\n        num_tkns = len(text[span_start:span_end+1].split())\n        tkns = [str(x) for x in range(token_start, token_start+num_tkns)]\n        predstring = ' '.join(tkns)\n        predstrings.append(predstring)\n                    \n    rows = []\n    for c, span, predstring in zip(classes, all_span, predstrings):\n        e = {\n            'id': example_id,\n            'discourse_type': c,\n            'predictionstring': predstring,\n            'discourse_start': span[0],\n            'discourse_end': span[1],\n            'discourse': text[span[0]:span[1]+1]\n        }\n        rows.append(e)\n\n\n    df = pd.DataFrame(rows)\n    df['length'] = df['discourse'].apply(lambda t: len(t.split()))\n    \n    # short spans are likely to be false positives, we can choose a min number of tokens based on validation\n    df = df[df.length > min_tokens].reset_index(drop=True)\n\n    return df","d9ea5bef":"# Load test data\nimport os \n\nfiles = os.listdir('..\/input\/feedback-prize-2021\/test')\nids = [x.split('.')[0] for x in files]\n\ndf_test = pd.DataFrame()\ndf_test['id'] = ids\ndf_test['text'] = df_test['id'].apply(get_test_text)\ndf_test","b827af63":"from datasets import Dataset\n\ntest_ds = Dataset.from_pandas(df_test)\ntest_ds","f9c71ef3":"def tokenize_for_test(examples):\n\n    o = tokenizer(examples['text'], truncation=True, return_offsets_mapping=True, max_length=4096)\n  \n    return o","b902f7d9":"tokenized_test = test_ds.map(tokenize_for_test)\ntokenized_test","b94ebe7b":"predictions, _, _ = trainer.predict(tokenized_test)","c8e82fc7":"import numpy as np\n\npreds = np.argmax(predictions, axis=-1)\npredictions.shape, preds.shape","f95d6046":"dfs = []\nfor i in range(len(tokenized_test)):\n    dfs.append(pred2span(preds[i], tokenized_test[i], test=True))\n\npred_df = pd.concat(dfs, axis=0)\npred_df['class'] = pred_df['discourse_type']","cdedaedc":"sub = pred_df[['id', 'class', 'predictionstring']]","79db7686":"sub.to_csv('submission.csv', index=False)","4a42811c":"# HuggingFace Inference Baseline\n\nTraining notebook: https:\/\/www.kaggle.com\/thedrcat\/feedback-prize-huggingface-baseline-training"}}