{"cell_type":{"8da1645a":"code","699f527e":"code","ac8ccb94":"code","a40d481f":"code","cbd98909":"code","610b1afb":"code","cebcd9aa":"code","f42f04e8":"code","7a353cbf":"code","690ac1a7":"code","501d28d7":"code","dec5e89b":"code","2ff92c41":"code","3055acb9":"markdown","3fcac847":"markdown","bf0234c8":"markdown","70b8c3de":"markdown","e4f1bc95":"markdown","75bf1778":"markdown","6fa03cca":"markdown","cdf69f09":"markdown","d910b8b1":"markdown","099ebb69":"markdown","e1c23092":"markdown","08604e5f":"markdown","37870e86":"markdown","715df317":"markdown"},"source":{"8da1645a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\npd.options.display.max_columns = None\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","699f527e":"train = pd.read_csv(\"\/kaggle\/input\/bcu-ratings-20\/train.csv\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/bcu-ratings-20\/test.csv\/test.csv\")\n\ntrain.head()","ac8ccb94":"features = list(set(train.columns.values) - set(['ID', 'TARGET']))\ncat_features = [feat for feat in features if train[feat].dtype.name in ['category', 'object']]\nnum_features = list(set(features) - set(cat_features))\n\nprint(f\"Categorical features: \\n {cat_features}\")\nprint(f\"Numerical features: \\n {num_features}\")","a40d481f":"# Funci\u00f3n para contar el n\u00famero de missing de un feature del train y del test\ndef count_missing(feature):\n    num_missing_train = np.sum(train[feature].isna())\n    num_missing_test = np.sum(test[feature].isna())\n    \n    # solo mostramos mensaje si el feature tiene missing\n    if (num_missing_train + num_missing_test) > 0:\n        print(f\"N\u00famero de missing del feature {feature}: train = {num_missing_train} | test = {num_missing_test}\")\n        \n    return (num_missing_train + num_missing_test)\n    \n# contamos el n\u00famero de missing del train y del test para cada feature\nfeat_missing = []\nfor feat in features:\n    num_miss = count_missing(feat)\n    if num_miss > 0:\n        feat_missing.append(feat)","cbd98909":"for feat in [i for i in feat_missing if i in num_features]:\n    # calculamos la mediana solamente con los valores del train, e imputamos tanto el train como el test con el valor mediano\n    mediana = train[feat].median()\n    train.loc[train[feat].isna(), feat] = mediana\n    test.loc[test[feat].isna(), feat] = mediana","610b1afb":"for feat in [i for i in feat_missing if i in cat_features]:\n    train.loc[train[feat].isna(), feat] = \"NA\"\n    test.loc[test[feat].isna(), feat] = \"NA\"","cebcd9aa":"# contamos el n\u00famero de missing del train y del test para cada feature\nfor feat in features:\n    count_missing(feat)","f42f04e8":"test['TARGET'] = np.nan\ndata = pd.concat([train, test], axis = 0)","7a353cbf":"data = pd.get_dummies(data, drop_first = True, columns = cat_features) # el par\u00e1metro drop first elimina uno de los valores, tal y como queremos que suceda\n\n# volvemos a calcular los features, ya que el nombre de algunas columnas ha cambiado\nfeatures = list(set(data.columns.values) - set(['ID', 'TARGET']))\n\n# separamos otra vez el train del test (el test ser\u00e1n aquellas observaciones para las que el target es NA)\ntrain = data.loc[np.logical_not(data['TARGET'].isna())]\ntest = data.loc[data['TARGET'].isna()]\n\ntrain.head()","690ac1a7":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(train[features], train['TARGET'], test_size = 0.25,\n                                                  stratify = train['TARGET'], random_state = 1234)","501d28d7":"from sklearn.linear_model import LogisticRegression\n\nlog_regressor = LogisticRegression(max_iter = 1e5) # en realidad la logistic regression de sklearn es regularizada, \n                                                   # pero de momento esto no es importante para el ejercicio\nlog_regressor.fit(X = X_train, y = y_train)","dec5e89b":"from sklearn.metrics import roc_auc_score\n\ny_pred_val = log_regressor.predict_proba(X_val)\ny_pred_val = [i[1] for i in y_pred_val]\n\nscore = roc_auc_score(y_val, y_pred_val)\n\nprint(f\"ROC AUC score of the model: {np.round(score, 5)}\")","2ff92c41":"test_pred = log_regressor.predict_proba(test[features])\ntest_pred = [i[1] for i in test_pred]\n\nsubmission = pd.DataFrame({'ID': test['ID'], 'Pred': test_pred}).to_csv(\"logistic_regression.csv\", index = False)","3055acb9":"Guardamos en distintas variables el listado de features (total de columnas exceptuando el ID y el TARGET), las variables num\u00e9ricas y las variables categ\u00f3ricas","3fcac847":"## Tratado valores missing\n\nPara cada feature, contamos el n\u00famero de valores missing que tiene el feature. Se debe rellenar los valores missing, ya que en la mayor\u00eda de casos, un modelo no admite valores missing","bf0234c8":"## Importado de los datos \n\nEn primer lugar, importamos los datos que se usar\u00e1n para modelizar:\n- **train**: estos datos contienen el target que se quiere predecir, son los datos que se usar\u00e1n para entrenar el modelo\n- **test**: estos datos no contienen el campo target, son los datos para los que se quiere realizar una predicci\u00f3n (y al tratarse de una competici\u00f3n, con los que se evaluar\u00e1 el modelo en la leaderboard)","70b8c3de":"## Modelizaci\u00f3n","e4f1bc95":"Una vez unidos los dos data frames en uno solo, procedemos a crear las variables categ\u00f3ricas (el package pandas tiene una funci\u00f3n `get_dummies` muy \u00fatil para conseguir esto f\u00e1cilmente) y volvemos a separar el train del test","75bf1778":"En segundo lugar, rellenamos los missing de las variables categ\u00f3ricas. En este caso, para los valores missing creamos una nueva categor\u00eda llamada \"NA\"","6fa03cca":"Por \u00faltimo, con el modelo entrenado, hacemos predicciones para el test y guardamos los resultados en un CSV con el formato necesario para hacer una submission, de manera que podamos ver el resultado del modelo en la Leaderboard","cdf69f09":"Existen valores missing, por lo que es necesario rellenarlos. En primer lugar, para los features num\u00e9ricos, rellenamos con la mediana.\n\n**Importante**: tanto los valores missing del train como los del test se deben rellenar con la mediana de los datos del train. De esta manera, se evita introducir informaci\u00f3n del test (en este caso, los valores del test al calcular la mediana) en el train.","d910b8b1":"Podemos comprobar que, ahora, ning\u00fana variable tiene valores missing, por lo que podemos proceder a modelizar.","099ebb69":"Una vez entrenado el modelo, lo validamos con la muestra de validaci\u00f3n (diferente a la que se ha utilizado para entrenar el modelo). De esta forma, podemos tener una idea de c\u00f3mo se comporta el modelo predicidendo datos no observados hasta el momento.","e1c23092":"En primer lugar, separamos el train original en dos sub-muestras: una, tambi\u00e9n llamada \"train\", usaremos para evaluar el modelo, y otra, llamada \"validation\", la usaremos para comprobar c\u00f3mo de bueno es el modelo.\n\nEsta separaci\u00f3n de la muestra se puede hacer f\u00e1cilmente con la funci\u00f3n `train_test_split` del package scikit-learn. La funci\u00f3n necesita los datos de entrada, el porcentaje de muestra que se destinar\u00e1 a \"validaci\u00f3n\" y el tipo de separaci\u00f3n que se quiere realizar. En nuestro caso, usaremos \"stratified\" con el objetivo de tener una proporci\u00f3n similar de defaults vs. no defaults tanto en el train como en la muestra de validaci\u00f3n.\n\nLos par\u00e1metros de la funci\u00f3n train_test_split son:\n\n- En primer lugar, los datos con los features que se van a utilizar para modelizar\n- Segundo, el Target o variable y del train, la variable que se quiere predecir\n- Especificar el % de muestra que se destinar\u00e1 a validaci\u00f3n en el par\u00e1metro test_size\n- En caso que se quiera un split estratificado (que mantenga a las proporciones entre clases en la separaci\u00f3n, en este caso 0s y 1s), aqu\u00ed se pasa la variable por la que se quiere estratificar (en este caso, vuelve a ser el propio target)\n- random_state. **Importante**: el proceso de corte de las muestras involucra cierta aleatoriedad (qu\u00e9 observaciones van al train y cu\u00e1les a la muestra de validaci\u00f3n). Sin embargo, para que los resultados sean reproducibles y se pueda comparar de manera justa distintos modelos, es necesario que el resultado de este proceso aleatorio sea siempre el mismo dadas las mismas condiciones iniciales. Esto se consigue estableciendo la variable random_state (en este caso, al valor 1234, pero da igual que valor se elija). Es muy importante establecer las variables \"seed\" o \"random_state\" en todos los procesos de ML, ya que si no, puede que una mejora o empeoramiento en un modelo se deba \u00fanicamente al resultado de un proceso aleatorio m\u00e1s que a una mejora real del modelo","08604e5f":"## P\u00f3ximos pasos\n\nEn el pr\u00f3ximo ejercicio de este curso, revisaremos el concepto de hyperpar\u00e1metros de un modelo y veremos como optimizar los hyperparametos del modelo.\n\nDe momento, un buen ejercicio a realizar individualmente es analizar las distintas variables (dado el volumen de datos, las variables se pueden analizar incluso en Excel) y probar de \"jugar\" con las variables y hacer feature engineering a ver si mejora el modelo actual.","37870e86":"## One-hot encoding de variables categ\u00f3ricas\n\nEn el dataset, tenemos variables categ\u00f3ricas que hay que pasar a num\u00e9ricas. Una de las opciones disponibles es convertir una variable categ\u00f3rica en distintas variables num\u00e9ricas (una por cada categor\u00eda distinta), de la siguiente forma: para cada valor (VAL) de la variable categ\u00f3rica (FEAT), se crea una nueva columna que vale 1 si FEAT = VAL, y 0 si FEAT no es igual a VAL.\n\nAs\u00ed, si la variable original ten\u00eda X valores distintos, se crean X-1 nuevas variables que valen 0 o 1. **Importante**: es una buena pr\u00e1ctica dejar uno de los valores de la variable original sin transformar, y crear X - 1 nuevas variables en vez de X variables. Una explicaci\u00f3n detallada del motivo por el que se debe tener esto en cuenta se puede encontrar aqu\u00ed https:\/\/towardsdatascience.com\/one-hot-encoding-multicollinearity-and-the-dummy-variable-trap-b5840be3c41a\n\nPara realizar este proceso, en primer lugar, vamos a unir los data frames de train y test en un \u00fanico data frame. El objetivo de esto es que queremos que, en caso de que en el test haya valores de una variable categ\u00f3rica que no est\u00e9 presente en el train, tambi\u00e9n se cree una nueva variable para dicho valor, aunque la variable solamente valga 0's en todo el train.","715df317":"Una vez separadas las muestras, entrenamos el modelo de regresi\u00f3n log\u00edstica:"}}