{"cell_type":{"7e48af71":"code","3dac95d5":"code","1fb88043":"code","4a131043":"code","9ff969af":"code","df4345b7":"code","b6f354b8":"code","93c2478b":"code","c909c574":"code","f51ea100":"code","ec62965a":"code","fb773d74":"code","531cdc14":"markdown","f910f84d":"markdown","16a8e6d3":"markdown","28b166a9":"markdown","e62dd3c5":"markdown","c8c81561":"markdown","30a41152":"markdown","41120127":"markdown"},"source":{"7e48af71":"# !apt update\n!apt install -y python-opengl ffmpeg > \/dev\/null 2>&1\n# !apt install -y xvfb\n%pip install pyvirtualdisplay gym[atari] gym[box2d] gym[classic_control]\n# WORKAROUND: retry ---v\n%pip install gym[box2d]\n%pip install --no-deps baselines\n# %conda list","3dac95d5":"from pyvirtualdisplay import Display\ndisplay = Display(visible=0, size=(1024, 768))\ndisplay.start()\n\n\nfrom matplotlib import pyplot as plt, animation\n%matplotlib inline\nfrom IPython import display\n\ndef create_anim(frames, dpi, fps):\n    plt.figure(figsize=(frames[0].shape[1] \/ dpi, frames[0].shape[0] \/ dpi), dpi=dpi)\n    patch = plt.imshow(frames[0])\n    def setup():\n        plt.axis('off')\n    def animate(i):\n        patch.set_data(frames[i])\n    anim = animation.FuncAnimation(plt.gcf(), animate, init_func=setup, frames=len(frames), interval=fps)\n    return anim\n\ndef display_anim(frames, dpi=72, fps=50):\n    anim = create_anim(frames, dpi, fps)\n    return anim.to_jshtml()\n\ndef save_anim(frames, filename, dpi=72, fps=50):\n    anim = create_anim(frames, dpi, fps)\n    anim.save(filename)\n\n\nclass trigger:\n    def __init__(self):\n        self._trigger = True\n\n    def __call__(self, e):\n        return self._trigger\n\n    def set(self, t):\n        self._trigger = t","1fb88043":"import gym\nimport numpy as np","4a131043":"frames = []\nenv = gym.make(\"Breakout-v0\")\nenv.reset()\nfor _ in range(300):\n    frames.append(env.render(mode='rgb_array'))\n    env.step(env.action_space.sample())\nenv.close()","9ff969af":"display.HTML(display_anim(frames))","df4345b7":"filename = 'Breakout-v0.mp4'\nsave_anim(frames, filename=filename)","b6f354b8":"display.Video(filename, width=300, height=400)","93c2478b":"#\n# WORKAROUND:\n# In case you got following error, you have to import Box2D manually.\n#\n# AttributeError: module 'gym.envs.box2d' has no attribute 'LunarLander'\n#\nimport Box2D\n# # gym.envs.registry.env_specs\n# from gym.envs import box2d\n# from gym.envs.box2d.lunar_lander import LunarLander\n# gym.make('BipedalWalker-v3')\n# # gym.make('LunarLander-v2')","c909c574":"from gym import wrappers\n\nrec = trigger()\nenv = gym.make(\"LunarLander-v2\")\n# env = LunarLander()\nenv = wrappers.Monitor(env, '.\/', video_callable=rec, force=True)\n\nfor _ in range(10):\n    rec.set(_ % 3 == 0)    # ex. skip every 3 episodes\n    env.reset()\n    done = False\n    while not done:\n        env.render()\n        _, _, done, _ = env.step(env.action_space.sample())\nenv.close()","f51ea100":"from gym.wrappers.monitor import load_results\nr = load_results('.\/')","ec62965a":"r","fb773d74":"for video in r['videos']:\n    print(video[0])\ntry:\n    filename = input('mp4 filename? ')\nexcept:\n    filename = r['videos'][-1][0]\ndisplay.Video(filename, width=300, height=400)","531cdc14":"And you can preview mp4 file via [IPython.display.Video class](https:\/\/ipython.readthedocs.io\/en\/stable\/api\/generated\/IPython.display.html#IPython.display.Video).\nYou also can preview an episode, its control panel is more simple though.","f910f84d":"# Method 1: previewing an episode on notebook\n\nYou can preview an episode step by step with control panel, using display_anim() and [IPython.display.HTML() class](https:\/\/ipython.readthedocs.io\/en\/stable\/api\/generated\/IPython.display.html#IPython.display.HTML).\nYou have to pass all of frame images to display_anim().\nTo retrieve frame images, pass mode='rgb_array' to gym.Environment.render().","16a8e6d3":"Welcome to my notebook on Kaggle!\nI did record my notebook so it might help others who start studying reinforcement learning.\nThis sample code demonstrates a kind of usual environments for investigating how your models behave well.\n\nIt covers environments below:\n- OpenAI Gym\n    - Classic Control environments\n    - Box2D environments\n    - Atari environments\n\nIt covers features below:\n- previewing an episode on notebook\n- explicitly saving an episode to mp4 file\n- implicitly saving episodes to mp4 files","28b166a9":"# Utilities","e62dd3c5":"You can retrieve result of episodes using gym.wrappers.monitor.load_results().","c8c81561":"# Method 2: explicitly saving an episode to mp4 file, and replay it\n\nYou can save an episode to mp4 file, using save_anim() and [matplotlib.pyplot.Animation.save()](https:\/\/matplotlib.org\/3.1.1\/api\/_as_gen\/matplotlib.animation.Animation.html#matplotlib.animation.Animation).\nYou have to pass all of frame images to save_anim().\nTo retrieve frame images, pass mode='rgb_array' to gym.Environment.render().","30a41152":"# Method 3: implicitly saving episodes to mp4 files\n\nYou can save episodes to mp4 files, using [gym.wrappers.Monitor class](https:\/\/github.com\/openai\/gym\/blob\/master\/gym\/wrappers\/monitor.py).\nYou can schedule to be saved when with manual_scheduler(), or default schedule is used which save at capped cubic(1, 8, 27, 64, ...).","41120127":"# Kernel Setup"}}