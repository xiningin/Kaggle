{"cell_type":{"b9f20986":"code","c316d10e":"code","27d6958c":"code","1870e15f":"code","3cb05418":"code","6a5ad6b5":"code","d0d7cbe2":"code","3d454571":"code","09bfc2dd":"code","edac3f5d":"code","8d5b901e":"code","1bc0b5d2":"code","44bd987a":"code","5d4d65db":"code","c60ccc68":"code","a20bb922":"code","ca93447b":"code","3edb79f7":"code","2278d2f1":"code","4b190f6b":"code","94303587":"code","9e991575":"code","943859f4":"code","32512e3d":"code","2075904a":"code","055f1533":"code","cb82bfb0":"markdown","7ece9ab4":"markdown","5f8fcf88":"markdown","01eda4ee":"markdown","8694e057":"markdown","3d465cab":"markdown","f5683763":"markdown","62e5633d":"markdown","e8ed74a4":"markdown","c766787d":"markdown","6b9ed3b8":"markdown","5e36a1a0":"markdown","33c2ac89":"markdown"},"source":{"b9f20986":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","c316d10e":"df=pd.read_csv(\"..\/input\/breast-cancer-wisconsin-data\/data.csv\")","27d6958c":"df.head(7)","1870e15f":"df.dropna()","3cb05418":"df.isnull().sum()","6a5ad6b5":"df.describe()","d0d7cbe2":"df.corr()","3d454571":"x=df[[\"radius_mean\",\"texture_mean\",\"smoothness_mean\",\"compactness_mean\",\"concavity_mean\"]]","09bfc2dd":"y=df[\"diagnosis\"]","edac3f5d":"from sklearn.model_selection import train_test_split","8d5b901e":"x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.33)","1bc0b5d2":"from sklearn.linear_model import LogisticRegression\nlogmodel=LogisticRegression()\n\n","44bd987a":"logmodel.fit(x_train,y_train)\npredictions=logmodel.predict(x_test)","5d4d65db":"df1=x_test","c60ccc68":"len(x_test)","a20bb922":"df1","ca93447b":"predictions","3edb79f7":"from sklearn.metrics import jaccard_similarity_score","2278d2f1":"accuracy_score=jaccard_similarity_score(y_test,predictions)\nprint(accuracy_score*100)","4b190f6b":"from sklearn.metrics import confusion_matrix","94303587":"matrix=confusion_matrix(y_test,predictions)\nprint(matrix)","9e991575":"from sklearn import svm","943859f4":"clf=svm.SVC(gamma=\"scale\")","32512e3d":"clf.fit(x_train,y_train)","2075904a":"predictions=clf.predict(x_test)","055f1533":"accuracy_score=jaccard_similarity_score(y_test,predictions)\nprint(accuracy_score*100)","cb82bfb0":"# We have got an accuracy score of 86.17% which is an awesome score.","7ece9ab4":"# We have got an accuracy score of 89.36% with the KNN model and 86.17% with the SVM model.","5f8fcf88":"# Checking for the accuracy score using jaccard_similarity_score","01eda4ee":"# Using the model of LogisticRegression","8694e057":"# Splitting the data for training and testing","3d465cab":"## Giving a look to the confusion matrix","f5683763":"# Analyzing the data for null values and dropping the rows having an empty value","62e5633d":"Features are computed from a digitized image of a fine needle aspirate (FNA) of a breast mass. They describe characteristics of the cell nuclei present in the image. n the 3-dimensional space is that described in: [K. P. Bennett and O. L. Mangasarian: \"Robust Linear Programming Discrimination of Two Linearly Inseparable Sets\", Optimization Methods and Software 1, 1992, 23-34].\n\nThis database is also available through the UW CS ftp server: ftp ftp.cs.wisc.edu cd math-prog\/cpo-dataset\/machine-learn\/WDBC\/\n\nAlso can be found on UCI Machine Learning Repository: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Breast+Cancer+Wisconsin+%28Diagnostic%29\n\nAttribute Information:\n\n1) ID number 2) Diagnosis (M = malignant, B = benign) 3-32)\n\nTen real-valued features are computed for each cell nucleus:\n\na) radius (mean of distances from center to points on the perimeter) b) texture (standard deviation of gray-scale values) c) perimeter d) area e) smoothness (local variation in radius lengths) f) compactness (perimeter^2 \/ area - 1.0) g) concavity (severity of concave portions of the contour) h) concave points (number of concave portions of the contour) i) symmetry j) fractal dimension (\"coastline approximation\" - 1)\n\nThe mean, standard error and \"worst\" or largest (mean of the three largest values) of these features were computed for each image, resulting in 30 features. For instance, field 3 is Mean Radius, field 13 is Radius SE, field 23 is Worst Radius.\n\nAll feature values are recoded with four significant digits.\n\nMissing attribute values: none\n\nClass distribution: 357 benign, 212 malignant","e8ed74a4":"# Reading the dataset","c766787d":"# Training the model and making predictions","6b9ed3b8":"# We will predict wether the tumor is Malignant or Benign on the basis of radius,texture,smoothness,compactness, and concavity","5e36a1a0":"# Now, we will be using SVM as our second model and then we will compare the accuracy with the KNN model.","33c2ac89":"# We have got an accuracy score of 89.36% which is an awesome score."}}