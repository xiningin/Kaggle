{"cell_type":{"3cf2e70e":"code","d5c6d035":"code","3070b427":"code","03547f22":"code","54b8cb6c":"code","15283554":"code","05a43d2f":"code","60682824":"code","069899f4":"code","5afccb83":"code","493e8d98":"code","1a9da2bb":"code","edf0c874":"code","040be419":"code","b2d30e3d":"code","700a4edc":"code","6c6d5b6a":"code","3ce497e8":"code","10c90df8":"code","3a67f052":"code","a66f2127":"code","52a516fe":"code","6c2cd3c7":"code","78d3a22e":"code","955974f2":"code","12e3f010":"code","6e8ae97c":"code","e044a6eb":"code","9313955b":"code","7184aa29":"code","f8889fbb":"code","ba90ce80":"code","c9a7bdc5":"code","c88eea31":"code","0993ddda":"code","c20204ac":"markdown"},"source":{"3cf2e70e":"import os\nimport shutil\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport cv2 as cv\n\nimport tensorflow as tf\nfrom matplotlib import pyplot as plt\nfrom sklearn.preprocessing import MultiLabelBinarizer\nfrom sklearn.metrics import multilabel_confusion_matrix\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import Input, Dense, Flatten, Conv2D, MaxPooling2D, Dropout, BatchNormalization, concatenate\nfrom tensorflow.keras.activations import relu, sigmoid\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.losses import binary_crossentropy\nfrom tensorflow.keras.metrics import Precision, Recall, AUC\nfrom tensorflow.keras.utils import plot_model, save_img\nfrom tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import load_img, img_to_array, array_to_img","d5c6d035":"base_dir = '..\/input'","3070b427":"cassava_dir = os.path.join(base_dir, 'cassava-leaf-disease-classification')\nplant_village_dir = os.path.join(base_dir, 'plantvillage-dataset')\nrice_dir = os.path.join(base_dir, 'rice-leaf-images\/rice_images')","03547f22":"fnames = []\n\nfor dir in os.listdir(os.path.join(plant_village_dir, 'color')):\n    columns = dir.split('___')\n    columns.append(dir)\n    fnames.append(columns)","54b8cb6c":"fnames = pd.DataFrame(fnames, columns=['Tree type', 'Disease', 'Folder'])\nfnames","15283554":"fnames.drop([4,17,33],axis=0,inplace=True)","05a43d2f":"fnames['Disease'] = fnames['Disease'].str.replace('_', ' ')\nfnames['Disease'] = fnames['Disease'].str.lstrip()\nfnames['Tree type'] = fnames['Tree type'].str.replace('_', ' ')\nfnames['Tree type'] = fnames['Tree type'].str.lstrip()\nfnames","60682824":"os.mkdir('image data')","069899f4":"os.mkdir(os.path.join('image data', 'train'))\nos.mkdir(os.path.join('image data', 'validation'))\nos.mkdir(os.path.join('image data', 'test'))","5afccb83":"train_path = os.path.join('image data\/train')\nval_path = os.path.join('image data\/validation')\ntest_path = os.path.join('image data\/test')","493e8d98":"for tree in fnames['Tree type'].unique().tolist():\n    # create directory for tree\n    path_1 = os.path.join(train_path, tree)\n    path_2 = os.path.join(test_path, tree)\n    path_3 = os.path.join(val_path, tree)\n\n    os.mkdir(path_1)\n    os.mkdir(path_2)\n    os.mkdir(path_3)\n\n    for disease, folder in fnames[fnames['Tree type'] == tree][['Disease', 'Folder']].values.tolist():\n        # create directory to each disease\n        sub_path_1 = os.path.join(path_1, disease.strip())\n        sub_path_2 = os.path.join(path_2, disease.strip())\n        sub_path_3 = os.path.join(path_3, disease.strip())\n\n        os.mkdir(sub_path_1)\n        os.mkdir(sub_path_2)\n        os.mkdir(sub_path_3)\n\n        # read data from source folder\n        src = os.path.join(plant_village_dir, 'color', folder)\n        image_count = len(os.listdir(src))\n        test_img_count = image_count \/\/ 10\n        val_img_count = (image_count - test_img_count) \/\/ 5\n        train_img_count = image_count - (test_img_count + val_img_count)\n        counts = [train_img_count, test_img_count, val_img_count]\n        splits = [sub_path_1, sub_path_2, sub_path_3]\n\n        for i in range(3):\n            images = os.listdir(src)\n            for j in images[:counts[i]]:\n                shutil.copyfile(src=os.path.join(src, j),\n                                dst=os.path.join(splits[i], j))","1a9da2bb":"os.mkdir(os.path.join(train_path, 'Rice'))\nos.mkdir(os.path.join(test_path, 'Rice'))\nos.mkdir(os.path.join(val_path, 'Rice'))","edf0c874":"source_dirs = os.listdir(rice_dir)\n\nfor source in source_dirs:\n    src = os.path.join(rice_dir, source)\n    image_count = len(os.listdir(src))\n    test_img_count = image_count \/\/ 10\n    val_img_count = (image_count - test_img_count) \/\/ 5\n    train_img_count = image_count - (test_img_count + val_img_count)\n    path_1 = os.path.join('image data\/train\/Rice', source.replace('_', '').lower())\n    path_2 = os.path.join('image data\/test\/Rice', source.replace('_', '').lower())\n    path_3 = os.path.join('image data\/validation\/Rice', source.replace('_', '').lower())\n\n    os.mkdir(path_1)\n    os.mkdir(path_2)\n    os.mkdir(path_3)\n    paths = [path_1, path_2, path_3]\n    split_counts = [train_img_count, test_img_count, val_img_count]\n\n    for i in range(3):\n        images = os.listdir(src)\n        for j in images[:split_counts[i]]:\n            shutil.copyfile(src=os.path.join(src, j),\n                        dst=os.path.join(paths[i], j))","040be419":"# disease_map = {0: \"Bacterial Blight (CBB)\",\n#                1: \"Brown Streak Disease (CBSD)\",\n#                2: \"Green Mottle (CGM)\",\n#                3: \"Mosaic Disease (CMD)\",\n#                4: \"Healthy\"}","b2d30e3d":"# pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')['label'].value_counts()","700a4edc":"# os.mkdir(os.path.join(train_path, 'Cassava'))\n# os.mkdir(os.path.join(test_path, 'Cassava'))\n# os.mkdir(os.path.join(val_path, 'Cassava'))","6c6d5b6a":"# for disease in disease_map.values():\n#     os.mkdir(os.path.join('image data\/train\/Cassava', disease))\n#     os.mkdir(os.path.join('image data\/test\/Cassava', disease))\n#     os.mkdir(os.path.join('image data\/validation\/Cassava', disease))","3ce497e8":"# df = pd.read_csv('..\/input\/cassava-leaf-disease-classification\/train.csv')\n\n# for img in df[df['label'] == 0].reset_index().loc[:378, 'image_id']:\n#     src = os.path.join(cassava_dir, 'train_images', img)\n#     dst = os.path.join('image data\/train\/Cassava', disease_map[0], img)\n\n#     if os.path.isfile(src):\n#         img_ = img_to_array(load_img(src))\n#         cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#         save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))\n\n# for img in df[df['label'] == 0].reset_index().loc[378:486, 'image_id']:\n#     src = os.path.join(cassava_dir, 'train_images', img)\n#     dst = os.path.join('image data\/test\/Cassava', disease_map[0], img)\n\n#     if os.path.isfile(src):\n#         img_ = img_to_array(load_img(src))\n#         cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#         save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))\n\n# for img in df[df['label'] == 0].reset_index().loc[486:540, 'image_id']:\n#     src = os.path.join(cassava_dir, 'train_images', img)\n#     dst = os.path.join('image data\/validation\/Cassava', disease_map[0], img)\n\n#     if os.path.isfile(src):\n#         img_ = img_to_array(load_img(src))\n#         cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#         save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))","10c90df8":"# for i in range(1, 4):\n#     for img in df[df['label'] == i].reset_index().loc[:448, 'image_id']:\n#         src = os.path.join(cassava_dir, 'train_images', img)\n#         dst = os.path.join('image data\/train\/Cassava', disease_map[i], img)\n\n#         if os.path.isfile(src):\n#             img_ = img_to_array(load_img(src))\n#             cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#             save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))\n\n#     for img in df[df['label'] == i].reset_index().loc[448:572, 'image_id']:\n#         src = os.path.join(cassava_dir, 'train_images', img)\n#         dst = os.path.join('image data\/test\/Cassava', disease_map[i], img)\n\n#         if os.path.isfile(src):\n#             img_ = img_to_array(load_img(src))\n#             cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#             save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))\n\n#     for img in df[df['label'] == i].reset_index().loc[572:634, 'image_id']:\n#         src = os.path.join(cassava_dir, 'train_images', img)\n#         dst = os.path.join('image data\/validation\/Cassava', disease_map[i], img)\n\n#         if os.path.isfile(src):\n#             img_ = img_to_array(load_img(src))\n#             cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#             save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))","3a67f052":"# for img in df[df['label'] == 4].reset_index().loc[:708, 'image_id']:\n#     src = os.path.join(cassava_dir, 'train_images', img)\n#     dst = os.path.join('image data\/train\/Cassava', disease_map[4], img)\n\n#     if os.path.isfile(src):\n#         img_ = img_to_array(load_img(src))\n#         cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#         save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))\n\n# for img in df[df['label'] == 4].reset_index().loc[708:910, 'image_id']:\n#     src = os.path.join(cassava_dir, 'train_images', img)\n#     dst = os.path.join('image data\/test\/Cassava', disease_map[4], img)\n\n#     if os.path.isfile(src):\n#         img_ = img_to_array(load_img(src))\n#         cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#         save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))\n\n# for img in df[df['label'] == 4].reset_index().loc[910:1011, 'image_id']:\n#     src = os.path.join(cassava_dir, 'train_images', img)\n#     dst = os.path.join('image data\/validation\/Cassava', disease_map[4], img)\n\n#     if os.path.isfile(src):\n#         img_ = img_to_array(load_img(src))\n#         cropped = tf.image.central_crop(img_, central_fraction=0.65)\n#         save_img(dst, cv.resize(src=img_to_array(cropped), dsize=(256, 256)))","a66f2127":"X = []\ny = []\nval_x = []\nval_y = []\ntest_x = []\ntest_y = []\ntree_types = os.listdir('image data\/train')\n\nfor tree in tree_types:\n    tree_path = os.path.join('image data\/train', tree)\n    tree_disease_types = os.listdir(tree_path)\n\n    for disease in tree_disease_types:\n        img_name = os.listdir(os.path.join(tree_path, disease))\n\n        for img in img_name:\n            image_path = os.path.join(tree_path, disease, img)\n            image = img_to_array(load_img(image_path, target_size=(56,56)))\n            X.append(image)\n            y.append([tree, disease])\n            \nfor tree in tree_types:\n    tree_path = os.path.join('image data\/validation', tree)\n    tree_disease_types = os.listdir(tree_path)\n\n    for disease in tree_disease_types:\n        img_name = os.listdir(os.path.join(tree_path, disease))\n\n        for img in img_name:\n            image_path = os.path.join(tree_path, disease, img)\n            image = img_to_array(load_img(image_path, target_size=(56,56)))\n            val_x.append(image)\n            val_y.append([tree, disease])\n            \nfor tree in tree_types:\n    tree_path = os.path.join('image data\/test', tree)\n    tree_disease_types = os.listdir(tree_path)\n\n    for disease in tree_disease_types:\n        img_name = os.listdir(os.path.join(tree_path, disease))\n\n        for img in img_name:\n            image_path = os.path.join(tree_path, disease, img)\n            image = img_to_array(load_img(image_path, target_size=(56,56)))\n            test_x.append(image)\n            test_y.append([tree, disease])","52a516fe":"mlb = MultiLabelBinarizer()\n\nX = np.array(X)\nval_x = np.array(val_x)\ny = mlb.fit_transform(y)\nval_y = mlb.transform(val_y)\ntest_y = mlb.transform(test_y)\ntest_x = np.array(test_x)\/255\nval_x = val_x\/255\nX.shape, y.shape","6c2cd3c7":"generator = ImageDataGenerator(rescale=1. \/ 255,\n                               rotation_range=15,\n                               width_shift_range=0.1,\n                               height_shift_range=0.1,\n                               horizontal_flip=True,\n                               vertical_flip=True\n                                    )\ngenerator.fit(X)","78d3a22e":"check_pointer = ModelCheckpoint(filepath='exp_conv_20.hdf5',\n                                save_best_only=True)\n\nearly_stop = EarlyStopping(monitor='val_loss',\n                           patience=40,\n                           min_delta=0,\n                           restore_best_weights=True)\n\nreduce_lr = ReduceLROnPlateau(monitor='val_loss',\n                              factor=0.1,\n                              patience=20,\n                             cooldown=15)","955974f2":"def inception_module(x, filter_1x1, filter_3x3_reduce, filter_3x3, filter_5x5_reduce, filter_5x5, filters_pool_proj,\n                     name=None):\n    # reduction layer\n    conv_3x3_reducer = Conv2D(filters=filter_3x3_reduce, kernel_size=(1, 1), activation=relu, padding='same')(x)\n    conv_5x5_reducer = Conv2D(filters=filter_5x5_reduce, kernel_size=(1, 1), activation=relu, padding='same')(x)\n    pool_3x3 = MaxPooling2D(pool_size=(3, 3), strides=(1, 1), padding='same')(x)\n\n    # extraction layer\n    conv_3x3 = Conv2D(filters=filter_3x3, kernel_size=(3, 3), activation=relu, padding='same')(conv_3x3_reducer)\n    conv_5x5 = Conv2D(filters=filter_5x5, kernel_size=(5, 5), activation=relu, padding='same')(conv_5x5_reducer)\n    conv_1x1_proj = Conv2D(filters=filters_pool_proj, kernel_size=(1, 1), activation=relu, padding='same')(pool_3x3)\n\n    # projection layer\n    proj = Conv2D(filters=filter_1x1, kernel_size=(1, 1), activation=relu, padding='same')(x)\n\n    # output\n    x = concatenate([proj, conv_1x1_proj, conv_3x3, conv_5x5], axis=3, name=name)\n\n    return x","12e3f010":"exp_input = Input(shape=(56,56,3))\n\n# conv_7x7\nx = Conv2D(filters=64, kernel_size=(7,7), padding='same', activation=relu)(exp_input)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(3,3), strides=(1,1))(x)\n\n# conv_5x5\nx = Conv2D(filters=192, kernel_size=(5,5), padding='same', activation=relu)(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(3,3), strides=(1,1))(x)\n\n# inception block 1\nx = inception_module(x,\n                     filter_1x1=64,\n                     filter_5x5_reduce=96,\n                     filter_3x3=128,\n                     filter_3x3_reduce=16,\n                     filter_5x5=32,\n                     filters_pool_proj=32,\n                     name='inception_1a')\nx = inception_module(x,\n                     filter_1x1=96,\n                     filter_5x5_reduce=128,\n                     filter_3x3=160,\n                     filter_3x3_reduce=32,\n                     filter_5x5=48,\n                     filters_pool_proj=64,\n                     name='inception_1b')\n\n# pooling\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n\n# inception block 2\nx = inception_module(x,\n                     filter_1x1=128,\n                     filter_5x5_reduce=96,\n                     filter_3x3=128,\n                     filter_3x3_reduce=48,\n                     filter_5x5=32,\n                     filters_pool_proj=32,\n                     name='inception_2a')\nx = inception_module(x,\n                     filter_1x1=160,\n                     filter_5x5_reduce=112,\n                     filter_3x3=160,\n                     filter_3x3_reduce=32,\n                     filter_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_2b')\nx = inception_module(x,\n                     filter_1x1=192,\n                     filter_5x5_reduce=128,\n                     filter_3x3=128,\n                     filter_3x3_reduce=48,\n                     filter_5x5=64,\n                     filters_pool_proj=64,\n                     name='inception_2c')\nx = inception_module(x,\n                     filter_1x1=256,\n                     filter_5x5_reduce=160,\n                     filter_3x3=160,\n                     filter_3x3_reduce=32,\n                     filter_5x5=96,\n                     filters_pool_proj=96,\n                     name='inception_2d')\n\n# pooling\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n\n# conv 3x3\nx = Conv2D(filters=256, kernel_size=(3,3), activation=relu, padding='same')(x)\nx = Conv2D(filters=256, kernel_size=(3,3), activation=relu, padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n\nx = Conv2D(filters=256, kernel_size=(3,3), activation=relu, padding='same')(x)\nx = Conv2D(filters=256, kernel_size=(3,3), activation=relu, padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n\nx = Conv2D(filters=256, kernel_size=(3,3), activation=relu, padding='same')(x)\nx = Conv2D(filters=256, kernel_size=(3,3), activation=relu, padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPooling2D(pool_size=(2,2), padding='same')(x)\n\n# flatten\nx = Flatten()(x)\n\n# output layer\nx = Dense(units=1024, activation=relu)(x)\nx = Dropout(0.5)(x)\nx = Dense(units=1024, activation=relu)(x)\nx = Dropout(0.5)(x)\nexp_output = Dense(units=36, activation=sigmoid)(x)\n\nexp_conv = Model(exp_input, exp_output)\nexp_conv.summary()","6e8ae97c":"plot_model(exp_conv,\n           to_file='baseline_conv_15_exp(VGGNet with INCEPTION).png',\n           show_shapes=True,\n           show_dtype=True,\n           show_layer_names=True)","e044a6eb":"exp_conv.compile(optimizer=Adam(),\n                   loss=binary_crossentropy,\n                   metrics=[Recall(), Precision(), 'accuracy'])\n\nhistory = exp_conv.fit(generator.flow(X,y, batch_size=128), \n                        epochs=500, \n                        validation_data=(val_x,val_y),\n                        callbacks=[early_stop, check_pointer, reduce_lr])","9313955b":"exp_conv.evaluate(test_x,test_y)","7184aa29":"figure, axes = plt.subplots(nrows=1, ncols=3, figsize=[18, 6], dpi=300)\naxes = axes.ravel()\nepochs = list(range(len(history.history['loss'])))\n\nsns.lineplot(x=epochs, y=history.history['loss'], ax=axes[0],label='loss')\nsns.lineplot(x=epochs, y=history.history['val_loss'], ax=axes[0],label='val loss')\nsns.lineplot(x=epochs, y=history.history['precision'], ax=axes[1],label='precision')\nsns.lineplot(x=epochs, y=history.history['val_precision'], ax=axes[1],label='val precision')\nsns.lineplot(x=epochs, y=history.history['recall'], color='#025918', ax=axes[1],label='recall')\nsns.lineplot(x=epochs, y=history.history['val_recall'], color='#D9B504',ax=axes[1],label='val recall')\nsns.lineplot(x=epochs, y=history.history['accuracy'], ax=axes[2],label='accuracy')\nsns.lineplot(x=epochs, y=history.history['val_accuracy'], ax=axes[2],label='val accuracy')\naxes[0].set_xlabel('epoch')\naxes[0].set_ylabel('loss')\naxes[1].set_xlabel('epoch')\naxes[1].set_ylabel('precision and recall')\naxes[2].set_xlabel('epoch')\naxes[2].set_ylabel('accuracy')\nplt.savefig('VGGNet_base_conv_train_history_with_cassava.png')\nplt.show()","f8889fbb":"figure, axes = plt.subplots(nrows=1, ncols=2, figsize=[12, 6], dpi=300)\naxes = axes.ravel()\n\nsns.lineplot(x=epochs, y=history.history['lr'], ax=axes[0],label='learning rate')\nsns.lineplot(x=history.history['lr'], y=history.history['val_accuracy'], ax=axes[1],label='accuracy & lr')\naxes[0].set_xlabel('epoch')\naxes[0].set_ylabel('learning rate')\naxes[1].set_xlabel('learning rate')\naxes[1].set_ylabel('accuracy')\n\nplt.savefig('VGGNet_base_conv_lr_history_4.png')\nplt.show()","ba90ce80":"# Plot confusion matrix\nfig, axes = plt.subplots(nrows=14, ncols=3, figsize=[24, 72], dpi=300)\naxes = axes.ravel()\n\npreds = np.where(exp_conv.predict(test_x) < 0.65, 0, 1)\nconfusion = multilabel_confusion_matrix(test_y, preds)\n\nfor i, (label, matrix) in enumerate(zip(mlb.classes_, confusion)):\n    labels = [f'not_{label}', label]\n    sns.heatmap(matrix, annot=True, square=True, fmt='d', cbar=False, cmap='Blues',\n                xticklabels=labels, yticklabels=labels, linecolor='black', linewidth=1,\n                ax=axes[i])\n    axes[i].set_title(labels[0])\n\nplt.savefig('VGGNet_base_conv_4_cm.png')\nplt.show()","c9a7bdc5":"exp_conv.save('VGGNet_based_with_all_data_be_top.hdf5')","c88eea31":"fig, axes = plt.subplots(nrows=5, ncols=2,figsize = (8, 24))\npreds = exp_conv.predict(test_x[200:210])\naxes = axes.ravel()\n\nfor i in range(len(preds)):\n    p = zip(list(mlb.classes_), list(preds[i]))\n    p = sorted(list(p), key = lambda z: z[1], reverse = True)[:2]\n    axes[i].imshow(test_x[200+i])\n    axes[i].set_title(f'{p[0][0]}: {round(p[0][1] * 100, 2)}% \\n {p[1][0]}: {round(p[1][1] * 100, 2)}%')\n    ","0993ddda":"pd.to_pickle(pd.DataFrame(history.history), 'VGGNet_base_conv_lr_history.pkl')","c20204ac":"## modeling"}}