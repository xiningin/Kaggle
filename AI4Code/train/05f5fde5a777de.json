{"cell_type":{"421b88d6":"code","ee909ad2":"code","8a515a9e":"code","7d54f951":"code","ca7e61ef":"code","9573ab36":"code","d7a6f8aa":"code","2852c752":"code","0de40c88":"code","4048029c":"code","d20f53e2":"code","c36e48a2":"code","27fc0138":"code","8723f3fe":"code","1597deed":"code","b094e419":"code","3215775b":"code","e86174a1":"code","af66f059":"code","4d357135":"code","eb4cbcba":"code","6f7dd6bf":"code","5aff9f82":"code","d0f0f95f":"code","1467277f":"code","bf2c455e":"code","dfd40273":"code","b01765cc":"code","c504b5a3":"code","7f653e36":"markdown","b0325da1":"markdown","ce66ab8b":"markdown","9ee4c77a":"markdown","9cc1a7f5":"markdown","b7091ad1":"markdown","41c12c5f":"markdown","e24215d2":"markdown","abd885c5":"markdown","aace9a04":"markdown","13b11f8e":"markdown","820ab7d5":"markdown","adb3c514":"markdown","587efdc6":"markdown","4ba69fb6":"markdown"},"source":{"421b88d6":"import pandas as pd\nimport warnings\nwarnings.filterwarnings(\"ignore\")\ndf_train = pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict_Ver1.1.csv')\ndf_test = pd.read_csv('..\/input\/graduate-admissions\/Admission_Predict.csv')\nprint(df_train.count()) \n\nprint(df_test.count())","ee909ad2":"df_train.columns","8a515a9e":"df_train.drop('Serial No.', axis=1, inplace=True)\ndf_test.drop('Serial No.', axis=1, inplace=True)\n\ndf_train.head()","7d54f951":"df_train['admission'] =  np.where(df_train['Chance of Admit '] >= 0.75, 1, 0)\ndf_train.head()","ca7e61ef":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\n# plt.rcParams['figure.figsize'] = (8, 6)\n# plt.rcParams['font.size'] = 14","9573ab36":"# Pandas scatter plot\ndf_train.plot(kind='scatter', x='GRE Score', y='CGPA')","d7a6f8aa":"sns.scatterplot(x='GRE Score', y='CGPA', hue=\"admission\", data=df_train)","2852c752":"feature_cols = ['GRE Score', 'TOEFL Score', 'University Rating', 'SOP','LOR ', 'CGPA', 'Research']\n\n# multiple scatter plots in Seaborn\ng = sns.pairplot(df_train, x_vars=feature_cols, y_vars='Chance of Admit ', kind='reg')\n\nfor chts in g.axes[0]: \n    chts.axes.axhline(y= 0.75, linewidth=2, color='r', ls='--')\n","0de40c88":"sns.relplot(x='GRE Score', y='CGPA',\n                 col=\"University Rating\", hue=\"admission\", \n                 kind=\"scatter\", data=df_train)","4048029c":"sns.relplot(x='GRE Score', y='TOEFL Score',\n                 col=\"University Rating\", hue='admission', \n                 kind=\"scatter\", data=df_train)","d20f53e2":"pdf=df_train.groupby(['Research','University Rating']).mean().reset_index()\npdf","c36e48a2":"bg = sns.boxplot(y=\"Chance of Admit \",  x= 'Research', palette=[\"m\", \"g\"], data=df_train)\nsns.despine(offset=10, trim=True)\nbg.axes.axhline(y= 0.75, linewidth=2, color='r', ls='--')","27fc0138":"bg = sns.boxplot(y=\"Chance of Admit \",  x= 'University Rating', data=df_train)\nsns.despine(offset=10, trim=True)\nbg.axes.axhline(y= 0.75, linewidth=2, color='r', ls='--')","8723f3fe":"gr = sns.catplot(x = \"University Rating\",   \n            y = \"Chance of Admit \",       \n            hue = \"Research\",  \n            data = df_train.groupby(['Research','University Rating']).mean().reset_index() , \n            kind = \"bar\")\ngr.axes[0][0].axes.axhline(y= 0.75, linewidth=2, color='r', ls='--')","1597deed":"sns.relplot(x='CGPA', y='Research',\n            col=\"University Rating\", hue='admission', \n            kind=\"scatter\", data=df_train)","b094e419":"colormap = sns.diverging_palette(100, 5, as_cmap=True)\nsns.heatmap(df_train.corr(), annot = True, cmap= colormap, cbar=True,  fmt=\".2f\" )","3215775b":"corr = df_train.corr()\ndropSelf = np.zeros_like(corr)\ndropSelf[np.triu_indices_from(dropSelf)] = True\ncolormap = sns.diverging_palette(100, 5, as_cmap=True)\n\nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(8, 8))\n    ax = sns.heatmap(corr,cmap=colormap,linewidths=.5, annot=True, mask=dropSelf )","e86174a1":"# import, instantiate, fit\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import mean_squared_error, mean_absolute_error\nfrom math import sqrt\nfrom sklearn.model_selection import train_test_split\n\n\nlinreg = LinearRegression()","af66f059":"feature_cols = ['GRE Score', 'TOEFL Score', 'University Rating', 'SOP', 'LOR ', 'CGPA', 'Research']\n\n## training set\nX = df_train[feature_cols]\ny = df_train['Chance of Admit ']\n\n## test set \nX_test = df_test[feature_cols]\ny_test = df_test['Chance of Admit ']\n\n## fit model\nlinreg.fit(X, y)","4d357135":"# print the coefficients\nprint(list(zip(feature_cols,linreg.coef_)))","eb4cbcba":"# define a function that accepts a list of features and returns RMSE, prediction \ndef train_test_rmse(feature_cols, X , y):\n    y_pred = linreg.predict(X)\n    return np.sqrt(mean_squared_error(y, y_pred)), y_pred","6f7dd6bf":"rmse, ypred = train_test_rmse(feature_cols, X_test , y_test)\n\ndf_test['admission_predict'] = y_pred\nprint(rmse)","5aff9f82":"print('MAE:',  mean_absolute_error(y_test, y_pred), ' ',  (1.\/len(y_test))*(sum(abs(y_test-y_pred))))\nprint('MSE:', mean_squared_error(y_test, y_pred), ' ',   (1.\/len(y_test))*(sum((y_test-y_pred)**2)))\nprint('RMSE:', np.sqrt(mean_squared_error(y_test, y_pred)), ' ', sqrt((1.\/len(y_test))*(sum((y_test-y_pred)**2))))","d0f0f95f":"fig, ax = plt.subplots()\nsns.set(color_codes=True)\nsns.set(rc={'figure.figsize':(7, 7)})\nsns.regplot(x=y_test, y=y_pred,  scatter=False, ax=ax);","1467277f":"##Check for Linearity\nf = plt.figure(figsize=(14,5))\n## linear\nax = f.add_subplot(121)\nsns.scatterplot(y_test,y_pred,ax=ax,color='r')\nax.set_title('Check for Linearity:\\n Actual Vs Predicted value')\n\n# Check for Residual error\nf = plt.figure(figsize=(14,5))\nax = f.add_subplot(121)\nsns.distplot((y_test-y_pred), bins = 50)\nax.axvline((y_test - y_pred).mean(),color='r',linestyle='--')\nax.set_title('Check for Residual normality & mean: \\n Residual eror');","bf2c455e":"sns.distplot(y_test,hist=True,label = 'Actual')\nsns.distplot(y_pred,hist=True, label ='Predicted')\nplt.legend(loc=\"upper right\")\nplt.xlabel('Prediction')","dfd40273":"from sklearn.preprocessing import StandardScaler as SS\nss = SS()\nX_ss = ss.fit_transform(X)\nss1 = SS()\nX_test_ss = ss.fit_transform(X_test)","b01765cc":"linreg.fit(X_ss, y)\n \nrmse_ss = train_test_rmse(feature_cols, X_test_ss , y_test)[0]\ny_pred_ss = train_test_rmse(feature_cols, X_test_ss , y_test)[1]\nprint(rmse_ss)","c504b5a3":"sns.distplot(y_test,hist=True,label = 'Actual')\nsns.distplot(y_pred_ss,hist=True, label ='Predicted (for StandardScaler inputs)')\nplt.legend(loc=\"upper right\")\nplt.xlabel('Prediction')","7f653e36":"> correlation of variables, different heatmap visualization.\n\n> ref: https:\/\/seaborn.pydata.org\/generated\/seaborn.heatmap.html","b0325da1":"> **GRE Score, TOEFL Score** and **CGPA** seems to be more correlated features","ce66ab8b":">`Serial No` column is of no use for the model. Drop col from train and test sets","9ee4c77a":"##       Lets do some data exploration","9cc1a7f5":"># ** Linear regression model **","b7091ad1":"> Lets have a look at error as per MAE, MSE & RMSE ","41c12c5f":"\n>Welcome to my kernel. We're performing here some data cleansing, transformation, EDA and finally a ML Linear regression model for Graduate admission dataset. \n\n![alt text](https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn%3AANd9GcRAGHhGeSTlVOtL2cwPvfAz61HAr20IOOeFIS5ODM80_LP9j67b&usqp=CAU)","e24215d2":">Lets check if scaling inpute features does have any impact on model","abd885c5":"> There is no much improvement, for a simple model like linear regression won't have any improvement on scaling features","aace9a04":"># Admission chance prediction done ! ","13b11f8e":"> I'm estimating chance of admit greater than 75% should be confirmed admissions. \n> It doesn't make this a classification problem, this is purely for data exploration purpose. ","820ab7d5":"> coefficients for each features","adb3c514":"> lets check correlation among all variables using heatmap","587efdc6":">Pulling Graduation dataset here. \n>Creating df_train and df_test dataframes","4ba69fb6":"> Check correlation between input features against Chance of Admission.\n\n> For further insight, marking 75% chance of admit on charts"}}