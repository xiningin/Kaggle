{"cell_type":{"b806c5b3":"code","0f91d5cc":"code","3322ece8":"code","71244f44":"code","0d85e214":"code","efa5664a":"code","adfb51f8":"code","6485ce00":"code","53e80d4a":"code","2bef5eaa":"code","4ad02da8":"code","c39ff79f":"code","f53fe023":"code","53c140e3":"code","12a4f660":"code","d492c0a1":"code","b41edb68":"code","d2e70918":"code","197203b0":"code","cc7615ea":"code","7c5f2312":"code","b7878916":"code","f170a997":"code","231cd1fc":"code","6d9addd3":"code","a64ae486":"code","045786db":"code","6ac524d7":"code","b8e8f20b":"code","04cba970":"code","bdd45242":"code","8d72d615":"code","63041c35":"code","8e44c77b":"code","81d4f852":"code","d5c92247":"code","c7babb25":"code","c13a18de":"code","9699f749":"code","d560eba0":"code","362096f1":"code","7d42828d":"markdown","7280cf58":"markdown","83b60645":"markdown","d506ceb5":"markdown","f02cfbf2":"markdown","3a36f951":"markdown","519757c5":"markdown"},"source":{"b806c5b3":"import numpy as np \nimport sys\nimport librosa , librosa.display\nimport matplotlib.pyplot as plt\nimport numpy as np\nsys.path.append('..\/input\/audio-data\/wild.wmv')","0f91d5cc":"file = '..\/input\/audio-data\/wild.wmv'\nSignal , sr = librosa.load(file , sr = 22050) # n_samples = 2.6 * 60 * 22050\nlibrosa.display.waveplot(Signal , sr = sr)\nplt.xlabel('Time')\nplt.ylabel('Amplitude')\nplt.show()","3322ece8":"fft = np.fft.fft(Signal) \nfft # there are complex numbers in fft array so we should extract the magnitudes","71244f44":"magnitude = np.abs(fft)\nmagnitude # These magnitudes represent the contribution of each frequency within the sound","0d85e214":"frequency = np.linspace(0 , sr , len(magnitude))\nfrequency","efa5664a":"plt.plot(frequency,magnitude)\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()","adfb51f8":"left_frequency = frequency[:int(len(frequency)\/2)]\nleft_magnitude = magnitude[:int(len(frequency)\/2)]","6485ce00":"plt.plot(left_frequency,left_magnitude)\nplt.xlabel('Frequency')\nplt.ylabel('Magnitude')\nplt.show()","53e80d4a":"n_fft = 2048 # the window\nhop_length = 512 # the amount of shifting the window to the right\nstft = librosa.core.stft(Signal , hop_length = hop_length , n_fft = n_fft)","2bef5eaa":"spectogram = np.abs(stft)\nlog_spectogram = librosa.amplitude_to_db(spectogram)\nlibrosa.display.specshow(log_spectogram , sr = sr , hop_length = hop_length)\nplt.xlabel('Time')\nplt.ylabel('Frequency')\nplt.colorbar()\nplt.show()","4ad02da8":"MFCCs = librosa.feature.mfcc(Signal , n_fft = n_fft , hop_length = hop_length , n_mfcc = 13)\nlibrosa.display.specshow(MFCCs , sr = sr , hop_length = hop_length)\nplt.xlabel('Time')\nplt.ylabel('MFCC')\nplt.colorbar()\nplt.show()","c39ff79f":"import json\nimport os\nimport math\nimport librosa\n\nDATASET_PATH = \"..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\"\nJSON_PATH = \".\/data_10.json\"\nSAMPLE_RATE = 22050\nTRACK_DURATION = 30 # measured in seconds\nSAMPLES_PER_TRACK = SAMPLE_RATE * TRACK_DURATION\nnot_allowed = \"..\/input\/gtzan-dataset-music-genre-classification\/Data\/genres_original\/jazz\/jazz.00054.wav\"\n\ndef save_mfcc(dataset_path, json_path, num_mfcc=13, n_fft=2048, hop_length=512, num_segments=5):\n    \"\"\"Extracts MFCCs from music dataset and saves them into a json file along witgh genre labels.\n\n        :param dataset_path (str): Path to dataset\n        :param json_path (str): Path to json file used to save MFCCs\n        :param num_mfcc (int): Number of coefficients to extract\n        :param n_fft (int): Interval we consider to apply FFT. Measured in # of samples\n        :param hop_length (int): Sliding window for FFT. Measured in # of samples\n        :param: num_segments (int): Number of segments we want to divide sample tracks into\n        :return:\n        \"\"\"\n\n    # dictionary to store mapping, labels, and MFCCs\n    data = {\n        \"mapping\": [],\n        \"labels\": [],\n        \"mfcc\": []\n    }\n    \n    samples_per_segment = int(SAMPLES_PER_TRACK \/ num_segments)\n    num_mfcc_vectors_per_segment = math.ceil(samples_per_segment \/ hop_length)\n\n    # loop through all genre sub-folder\n    for i, (dirpath, dirnames, filenames) in enumerate(os.walk(dataset_path)):\n\n        # ensure we're processing a genre sub-folder level\n        if dirpath is not dataset_path:\n\n            # save genre label (i.e., sub-folder name) in the mapping\n            semantic_label = dirpath.split(\"\/\")[-1]\n            data[\"mapping\"].append(semantic_label)\n            print(\"\\nProcessing: {}\".format(semantic_label))\n\n            # process all audio files in genre sub-dir\n            for f in filenames:\n               \n\t\t# load audio file\n                file_path = os.path.join(dirpath, f)\n                if file_path != not_allowed :\n                    signal, sample_rate = librosa.load(file_path, sr=SAMPLE_RATE)\n\n                # process all segments of audio file\n                    for d in range(num_segments):\n\n                    # calculate start and finish sample for current segment\n                        start = samples_per_segment * d\n                        finish = start + samples_per_segment\n\n                    # extract mfcc\n                        mfcc = librosa.feature.mfcc(signal[start:finish], sample_rate, n_mfcc=num_mfcc, n_fft=n_fft, hop_length=hop_length)\n                        mfcc = mfcc.T\n\n                    # store only mfcc feature with expected number of vectors\n                        if len(mfcc) == num_mfcc_vectors_per_segment:\n                            data[\"mfcc\"].append(mfcc.tolist())\n                            data[\"labels\"].append(i-1)\n                            print(\"{}, segment:{}\".format(file_path, d+1))\n\n    # save MFCCs to json file\n    with open(json_path, \"w\") as fp:\n        json.dump(data, fp, indent=4)\n        \n        \n        \nif __name__ == \"__main__\":\n    save_mfcc(DATASET_PATH, JSON_PATH, num_segments=10)","f53fe023":"from tensorflow.keras import losses","53c140e3":"import json\nimport numpy as np\nDATASET_PATH = \".\/data_10.json\"\ndef load_data(dataset_path):\n    with open(dataset_path,\"r\") as fp:\n        data = json.load(fp)\n    inputs = np.array(data[\"mfcc\"])  \n    targets = np.array(data[\"labels\"])   \n    \n    return inputs , targets\n\ninputs,targets = load_data(DATASET_PATH)    ","12a4f660":"from sklearn.model_selection import train_test_split\nimport tensorflow.keras  as keras","d492c0a1":"inputs_train,inputs_test,targets_train,targets_test = train_test_split(inputs,targets,test_size=0.3)","b41edb68":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(inputs.shape[1],inputs.shape[2])),\n    \n    keras.layers.Dense(512,activation=\"relu\"),\n    keras.layers.Dense(256,activation=\"relu\"),\n    keras.layers.Dense(64,activation=\"relu\"),\n    \n    keras.layers.Dense(10,activation=\"softmax\"),\n\n    \n])\n\noptimizer = keras.optimizers.Adam(learning_rate = 0.0001)\nmodel.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\nmodel.summary()","d2e70918":"history = model.fit(inputs_train,targets_train,validation_data=(inputs_test,targets_test),epochs=50,batch_size=32)","197203b0":"import matplotlib.pyplot as plt\ndef plot_history(history):\n    \n    fig,axs = plt.subplots(2)\n    axs[0].plot(history.history[\"accuracy\"],label=\"train accuracy\")\n    axs[0].plot(history.history[\"val_accuracy\"],label=\"test accuracy\")\n    axs[0].set_ylabel(\"Accuracy\")\n    axs[0].legend(loc='lower right')\n    axs[0].set_title(\"Accuracy eval\")\n    \n    axs[1].plot(history.history[\"loss\"],label=\"train error\")\n    axs[1].plot(history.history[\"val_loss\"],label=\"test error\")\n    axs[1].set_ylabel(\"Error\")\n    axs[1].set_xlabel(\"Epoch\")\n    axs[1].legend(loc='upper right')\n    plt.show()\n    \n    ","cc7615ea":"plot_history(history)","7c5f2312":"model = keras.Sequential([\n    keras.layers.Flatten(input_shape=(inputs.shape[1],inputs.shape[2])),\n    \n    keras.layers.Dense(512,activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(256,activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(64,activation=\"relu\",kernel_regularizer=keras.regularizers.l2(0.001)),\n    keras.layers.Dropout(0.3),\n    keras.layers.Dense(10,activation=\"softmax\"),\n\n    \n])\n\noptimizer = keras.optimizers.Adam(learning_rate = 0.0001)\nmodel.compile(optimizer=optimizer,loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])\nmodel.summary()","b7878916":"history = model.fit(inputs_train,targets_train,validation_data=(inputs_test,targets_test),epochs=50,batch_size=32)","f170a997":"plot_history(history)","231cd1fc":"import json\nimport numpy as np","6d9addd3":"DATA_PATH = \".\/data_10.json\"\n\ndef load_dataset(data_path):\n    \n    with open(data_path,\"r\") as fp:\n        data = json.load(fp)\n        \n    X = np.array(data[\"mfcc\"])\n    y = np.array(data[\"labels\"])\n    return X , y    \n    \n","a64ae486":"from sklearn.model_selection import train_test_split\n\ndef prepare_datasets(test_size,val_size):\n    \n    X , y = load_dataset(DATA_PATH)\n    X_train,X_test,y_train,y_test = train_test_split(X , y , test_size = test_size)\n    X_train,X_validation,y_train,y_validation = train_test_split(X_train , y_train , test_size = val_size)\n    #from 2d-(130,13) to 3d-(130,13,1) \n    X_train = X_train[...,np.newaxis] # (num_samples,130,13,1)\n    X_validation = X_validation[...,np.newaxis] \n    X_test = X_test[...,np.newaxis]\n    \n    return X_train,X_validation,X_test,y_train,y_validation,y_test \n\n    ","045786db":"X_train,X_validation,X_test,y_train,y_validation,y_test = prepare_datasets(0.25,0.2)","6ac524d7":"import tensorflow.keras as keras\n\n\ndef build_model(input_shape):\n    model = keras.Sequential()\n    model.add(keras.layers.Conv2D(32 , (3,3) ,activation = 'relu', input_shape=input_shape))\n    model.add(keras.layers.MaxPooling2D((3,3),strides=(2,2),padding='same'))\n    model.add(keras.layers.BatchNormalization())\n\n    model.add(keras.layers.Conv2D(64 , (3,3) ,activation = 'relu'))\n    model.add(keras.layers.MaxPooling2D((3,3),strides=(2,2),padding='same'))\n    model.add(keras.layers.BatchNormalization())\n    \n    model.add(keras.layers.Conv2D(120 , (2,2) ,activation = 'relu'))\n    model.add(keras.layers.MaxPooling2D((2,2),strides=(2,2),padding='same'))\n    model.add(keras.layers.BatchNormalization())\n    \n    model.add(keras.layers.Flatten())\n    model.add(keras.layers.Dense(64,activation = 'relu'))\n    model.add(keras.layers.Dropout(0.3))\n    model.add(keras.layers.Dense(10,activation='softmax'))\n    \n    return model","b8e8f20b":"input_shape = (X_train.shape[1],X_train.shape[2],X_train.shape[3])\nmodel = build_model(input_shape)\noptimizer =  keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer = optimizer ,loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])","04cba970":"model.fit(X_train,y_train,validation_data=(X_validation,y_validation),batch_size=32,epochs=30)","bdd45242":"test_error , test_accuracy = model.evaluate(X_test,y_test,verbose=1)\nprint(\"Accuracy on test is {}\".format(test_accuracy))\nprint(\"Test error is {}\".format(test_error))","8d72d615":"def predict(model , X , y):\n    X = X[np.newaxis,...]\n    prediction = model.predict(X)\n    predicted_index = np.argmax(prediction , axis = 1)\n    print(\"Expected index : {} predicted index : {}\".format(y,predicted_index[0]))\n    ","63041c35":"X = X_test[100]\ny = y_test[100]\npredict(model , X , y)","8e44c77b":"from sklearn.model_selection import train_test_split\n\ndef prepare_datasets(test_size,val_size):\n    \n    X , y = load_dataset(DATA_PATH)\n    X_train,X_test,y_train,y_test = train_test_split(X , y , test_size = test_size)\n    X_train,X_validation,y_train,y_validation = train_test_split(X_train , y_train , test_size = val_size)\n\n    return X_train,X_validation,X_test,y_train,y_validation,y_test \n\n    ","81d4f852":"X_train,X_validation,X_test,y_train,y_validation,y_test = prepare_datasets(0.25,0.2)","d5c92247":"X_train.shape","c7babb25":"def build_model(input_shape):\n    model = keras.Sequential()\n    # 64 represnets the number of units NOT cells\n    # the number of cells equal to the numper of steps which is 130 here\n    model.add(keras.layers.LSTM(64,input_shape=input_shape,return_sequences=True))\n    model.add(keras.layers.LSTM(64))\n    model.add(keras.layers.Dense(64,activation='relu'))\n    model.add(keras.layers.Dropout(0.3))\n    model.add(keras.layers.Dense(10,activation='softmax'))\n    \n    return model","c13a18de":"input_shape = (X_train.shape[1],X_train.shape[2])\nmodel = build_model(input_shape)\noptimizer =  keras.optimizers.Adam(learning_rate=0.001)\nmodel.compile(optimizer = optimizer ,loss = 'sparse_categorical_crossentropy',metrics=['accuracy'])","9699f749":"model.summary()","d560eba0":"model.fit(X_train,y_train,validation_data=(X_validation,y_validation),batch_size=32,epochs=30)","362096f1":"test_error , test_accuracy = model.evaluate(X_test,y_test,verbose=1)\nprint(\"Accuracy on test is {}\".format(test_accuracy))\nprint(\"Test error is {}\".format(test_error))","7d42828d":"# CNN ","7280cf58":"# Music Genre Classification\n","83b60645":"# Waveform","d506ceb5":"# STFT","f02cfbf2":"# Fast Fourier Transform","3a36f951":"# RNN","519757c5":"# MFCCs"}}