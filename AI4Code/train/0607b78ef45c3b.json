{"cell_type":{"43316549":"code","6d5bf360":"code","16b7297a":"code","411866be":"code","b947a8bb":"code","bc1e8cdd":"code","b5a31864":"code","15a3e4b6":"code","b29e6335":"code","91e7bb73":"code","6decd452":"code","13dbf5f2":"code","ff789c41":"code","0a3b1ac6":"code","ebb1b4b5":"code","f3744973":"code","4c5090ce":"code","ce3c9c61":"code","43598f75":"code","e83cfc41":"code","5eca68b5":"code","a66cd97f":"code","cfd1c78b":"code","82d92edc":"code","83346682":"code","418d983d":"code","98d21c30":"code","bc1bb878":"code","de755205":"code","330de820":"code","2dffe3d2":"code","8d51113a":"code","eafd2415":"code","2b2e1bdc":"code","78c79144":"code","249c0c4c":"code","4d126196":"markdown","8402d1c1":"markdown","8aa70999":"markdown","b9295985":"markdown","70873c6a":"markdown","8ded99a9":"markdown","c606fbd0":"markdown","5fc5ee70":"markdown","7dba19cf":"markdown","1a0fb5c8":"markdown","f31e6dfc":"markdown","73e42db8":"markdown","a98d6458":"markdown","970920ce":"markdown","90b300ef":"markdown","458d2388":"markdown","7feac3aa":"markdown","9fd44bfd":"markdown"},"source":{"43316549":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","6d5bf360":"import pandas as pd\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","16b7297a":"train_len = len(train)\ntrain_len","411866be":"train_wo_Sv = train.drop(labels='Survived', axis= 1)","b947a8bb":"train_test_total = pd.concat([train_wo_Sv,test], axis = 0)","bc1e8cdd":"train_test_total.head()","b5a31864":"train_test_total['Age'].fillna(value = train_test_total.Age.mean(), inplace = True)","15a3e4b6":"import re\ntrain_test_total['Title'] = train_test_total.Name.str.extract('([a-zA-Z]+)\\.', expand = True)\ntrain_test_total['Title'] = train_test_total.Title.replace('Mme','Mrs')\ntrain_test_total['Title'] = train_test_total.Title.replace('Mlle','Miss')\ntrain_test_total['Title'] = train_test_total.Title.replace('Ms','Miss')","b29e6335":"title_counts = train_test_total.Title.value_counts()\nleast_frequent_title = title_counts[title_counts<=10].index\nleast_frequent_title\n\ntrain_test_total['Title'] = train_test_total['Title'].replace(least_frequent_title,'Rare')","91e7bb73":"train_test_total['Fare'] = train_test_total['Fare'].fillna(train_test_total['Fare'].median())","6decd452":"train_test_total['Embarked'] = train_test_total['Embarked'].fillna(train_test_total['Embarked'].mode()[0])","13dbf5f2":"train_test_total.head()","ff789c41":"train_test_total.drop(labels=['PassengerId','Cabin','Name','Ticket'], axis = 1, inplace = True)\n","0a3b1ac6":"train_test_total.head()","ebb1b4b5":"train_test_total['Family'] = train_test_total['Parch'] + train_test_total['SibSp'] + 1","f3744973":"train_test_total.head()","4c5090ce":"train_test_total['Age'] = pd.qcut(train_test_total['Age'], 5, labels=['child','young','mid_age','old','very_old'])","ce3c9c61":"train_test_total['Fare'] = pd.qcut(train_test_total['Fare'], 5, labels=['low','low_medium','medium','high','very_high'])","43598f75":"from sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import OneHotEncoder\n\nlabelencoder = LabelEncoder()\ntrain_test_total['Sex'] = labelencoder.fit_transform(train_test_total['Sex'])\ntrain_test_total['Embarked'] = labelencoder.fit_transform(train_test_total['Embarked'])\ntrain_test_total['Title'] = labelencoder.fit_transform(train_test_total['Title'])\ntrain_test_total['Age'] = labelencoder.fit_transform(train_test_total['Age'])\ntrain_test_total['Fare'] = labelencoder.fit_transform(train_test_total['Fare'])","e83cfc41":"train_test_total.head()","5eca68b5":"train_test_total = pd.get_dummies(train_test_total, columns= ['Pclass','Embarked','Title','Family','Age','Fare'], drop_first= True, prefix= ['P_','Em_','T_','F_','Age_','Fare_'])","a66cd97f":"train_test_total.head()","cfd1c78b":"from sklearn.preprocessing import StandardScaler","82d92edc":"train_cleaned = train_test_total.iloc[:train_len,:]\ntest_cleaned = train_test_total.iloc[train_len:,:]\nX_train = train_cleaned\nY_train = train.Survived","83346682":"from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, ExtraTreesClassifier, VotingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.model_selection import cross_val_score, GridSearchCV","418d983d":"random_state = 2\nclassifiers = []\n\nclassifiers.append(RandomForestClassifier(criterion = 'entropy', random_state = random_state))\nclassifiers.append(AdaBoostClassifier(DecisionTreeClassifier(criterion = 'entropy', random_state = random_state),learning_rate = 0.1,random_state = random_state))\nclassifiers.append(GradientBoostingClassifier(random_state = random_state))\nclassifiers.append(ExtraTreesClassifier(criterion = 'entropy', random_state = random_state))\nclassifiers.append(LinearDiscriminantAnalysis())\nclassifiers.append(LogisticRegression(random_state = random_state))\nclassifiers.append(KNeighborsClassifier(n_neighbors = 5, metric = 'minkowski', p =2))\nclassifiers.append(SVC(random_state = random_state))\nclassifiers.append(SVC(kernel = 'linear',random_state = random_state))\nclassifiers.append(GaussianNB())","98d21c30":"\ncv_results = []\nfor classifier in classifiers:\n    cv_results.append(cross_val_score(estimator = classifier, X = X_train, y = Y_train, scoring = 'accuracy', cv = 10, n_jobs = -1))","bc1bb878":"cv_mean = []\ncv_std = []\n\nfor cv_result in cv_results:\n    cv_mean.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n    \ncv_vis = pd.DataFrame({'CrossValMean':cv_mean,'CrossValError': cv_std ,'Algorithm':['RandomForest','Adaboost','Gradientboost','Extratrees',\n                                                            'LinearDiscriminat','LogisticReg','KNeighbor','Kernel_SVC','SVC','GaussianNB']})","de755205":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize= (8,5))\nsns.barplot(y = 'Algorithm',x = 'CrossValMean', data= cv_vis, orient='h', **{'xerr': cv_std})\nplt.xlabel('Mean Accuracy', fontsize = 15)\nplt.ylabel('Algorithm', fontsize = 15)\nplt.yticks(rotation = 35)\nplt.show()","330de820":"from sklearn.model_selection import GridSearchCV","2dffe3d2":"# Gradient boosting tunning\n\nGBC_classifier = GradientBoostingClassifier()\ngb_param_grid = {'loss' : [\"deviance\"],\n              'n_estimators' : [100,200,300],\n              'learning_rate': [0.1, 0.05, 0.01], \n              }\n\ngsGBC = GridSearchCV(GBC_classifier,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsGBC.fit(X_train,Y_train)\n\nGBC_best = gsGBC.best_estimator_\n\n# Best score\ngsGBC.best_score_","8d51113a":"# Linear Discriminant Analysis tunning\n\nLDA_classifier = LinearDiscriminantAnalysis()\ngb_param_grid = {\n              }\n\ngsLDA = GridSearchCV(LDA_classifier,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsLDA.fit(X_train,Y_train)\n\nLDA_best = gsLDA.best_estimator_\n\n# Best score\ngsLDA.best_score_","eafd2415":"# Logistic Regression tunning\n\nLR_classifier = LogisticRegression()\ngb_param_grid = {\n                  'C': [0.1,1, 10, 50, 100,]\n              }\n\ngsLR = GridSearchCV(LR_classifier,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsLR.fit(X_train,Y_train)\n\nLR_best = gsLR.best_estimator_\n\n# Best score\ngsLR.best_score_","2b2e1bdc":"# Kernel SVC tunning\n\nKSVC_classifier = SVC(probability=True)\ngb_param_grid = {'kernel': ['rbf'], \n                  'gamma': [ 0.001, 0.01, 0.1, 1],\n                  'C': [0.1,1, 10, 50, 100,]\n              }\n\ngsKSVC = GridSearchCV(KSVC_classifier,param_grid = gb_param_grid, cv=10, scoring=\"accuracy\", n_jobs= 4, verbose = 1)\n\ngsKSVC.fit(X_train,Y_train)\n\nKSVC_best = gsKSVC.best_estimator_\n\n# Best score\ngsKSVC.best_score_","78c79144":"votingC = VotingClassifier(estimators=[('gbc', GBC_best), ('lda', LDA_best),\n('lr', LR_best), ('ksvc',KSVC_best)], voting='soft', n_jobs=4)\n\nvotingC = votingC.fit(X_train, Y_train)\n","249c0c4c":"test_Survived = pd.Series(votingC.predict(test_cleaned), name=\"Survived\")\n\nresults = pd.concat([test.PassengerId,test_Survived],axis=1)\n\nresults.to_csv(\"ensemble_python_voting.csv\",index=False)","4d126196":"1. 2. To incoprate the cross_val_score results into cv_mean and cv_std, respectively:","8402d1c1":"To extract the training and test datasets:","8aa70999":"2. 1. To apply GridSearch on best performing models: SVC, LogisticRegression, LinearDiscrimination, Gradientboost:","b9295985":"To import the various classifier classes:","70873c6a":"For Name collumn, to extract the tile using regex, then to replace the low frequent title with 'Rare':","8ded99a9":"To note: I've learned lots of tricks and patterns from Dr.Yassine Ghouzam. He is a great machine learning scientist. Every work out of his magical hands is classic. Thank you very much!","c606fbd0":"To combine the classifiers into the list:","5fc5ee70":"For Age collumn, first to fill null values:","7dba19cf":"To catogerize Fare:","1a0fb5c8":"1. 3. To visualize the accuracies and corresponding algorithm:","f31e6dfc":"For Fare collumn, to fill na with median value:","73e42db8":"To catogerize Age:","a98d6458":"Ensemble Voting:","970920ce":"Modelling:****","90b300ef":"Combing train and test datasets together for consistent data cleaning:","458d2388":"To predict and submit results:","7feac3aa":"For Embarked collumn, to fill na with first mode value:","9fd44bfd":"1. 1. To fit and transform the training sets using Cross_Val_Score method:"}}