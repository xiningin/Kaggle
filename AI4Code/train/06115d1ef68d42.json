{"cell_type":{"e073790a":"code","2ec43a3d":"code","3503b8ba":"code","4657ac6e":"code","a09cd82e":"code","e2a8836c":"code","9727b646":"code","b4a54927":"code","829b797b":"code","41720053":"code","f4615726":"code","69b8aca6":"code","c7133565":"code","57e8cd19":"code","853e8f8f":"code","d8a853ff":"code","996b1913":"code","d42b06d4":"code","a52be791":"code","59cd922f":"code","f95885bc":"code","b25d0eec":"code","a990a2dc":"code","ec28ac04":"markdown"},"source":{"e073790a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(len(os.listdir(\"..\/input\/train\")))\n\n# Any results you write to the current directory are saved as output.","2ec43a3d":"os.mkdir(\"modifiedtrain\")\nos.mkdir(\"modifiedtrain\/cat\")\nos.mkdir(\"modifiedtrain\/dog\")","3503b8ba":"os.listdir(\"modifiedtrain\")","4657ac6e":"from shutil import copyfile\nfor file in os.listdir(\"..\/input\/train\"):\n    name=file.split('.')[0]\n    filename=\"..\/input\/train\/\"+file\n    if name=='cat':\n        copyfile(filename,\"modifiedtrain\/cat\/\"+file)\n    elif name=='dog':\n        copyfile(filename,\"modifiedtrain\/dog\/\"+file)\n    \n    ","a09cd82e":"os.listdir(\"modifiedtrain\/dog\/\")","e2a8836c":"%pylab inline\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimage = Image.open('modifiedtrain\/dog\/dog.411.jpg')\nplt.imshow(image)\nplt.show()","9727b646":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","b4a54927":"train_datagen=ImageDataGenerator(rescale=1.\/255)\n","829b797b":"train_generator=train_datagen.flow_from_directory(\"modifiedtrain\/\",batch_size=20,target_size=(150,150),\n                                                  class_mode='binary')","41720053":"model=tf.keras.models.Sequential([\n    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(150,150,3)),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.MaxPool2D(2,2),\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation='relu'),\n    tf.keras.layers.Dense(1,activation='sigmoid')\n])","f4615726":"model.summary()","69b8aca6":"from tensorflow.keras.optimizers import RMSprop\n\nmodel.compile(loss='binary_crossentropy',optimizer=RMSprop(lr=0.001),metrics=['accuracy'])","c7133565":"history=model.fit_generator(train_generator,steps_per_epoch=100,epochs=15)","57e8cd19":"train_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')","853e8f8f":"train_generator=train_datagen.flow_from_directory(\"modifiedtrain\/\",batch_size=20,target_size=(150,150),\n                                                  class_mode='binary')","d8a853ff":"history=model.fit_generator(train_generator,steps_per_epoch=100,epochs=5)","996b1913":"import os\n\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import Model\n!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O \/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5\n  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3\n\nlocal_weights_file = '\/tmp\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n\npre_trained_model = InceptionV3(input_shape = (256, 256, 3), \n                                include_top = False, \n                                weights = None)\n\npre_trained_model.load_weights(local_weights_file)\n\nfor layer in pre_trained_model.layers:\n  layer.trainable = False\n  \n# pre_trained_model.summary()\n\nlast_layer = pre_trained_model.get_layer('mixed7')\nprint('last layer output shape: ', last_layer.output_shape)\nlast_output = last_layer.output","d42b06d4":"from tensorflow.keras.optimizers import RMSprop\n\n# Flatten the output layer to 1 dimension\nx = layers.Flatten()(last_output)\n# Add a fully connected layer with 1,024 hidden units and ReLU activation\nx = layers.Dense(1024, activation='relu')(x)\n# Add a dropout rate of 0.2\nx = layers.Dropout(0.2)(x)                  \n# Add a final sigmoid layer for classification\nx = layers.Dense  (1, activation='sigmoid')(x)           \n\nmodel = Model( pre_trained_model.input, x) \n\nmodel.compile(optimizer = RMSprop(lr=0.0001), \n              loss = 'binary_crossentropy', \n              metrics = ['acc'])","a52be791":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n      rescale=1.\/255,\n      rotation_range=40,\n      width_shift_range=0.2,\n      height_shift_range=0.2,\n      shear_range=0.2,\n      zoom_range=0.2,\n      horizontal_flip=True,\n      fill_mode='nearest')","59cd922f":"train_generator=train_datagen.flow_from_directory(\"modifiedtrain\/\",batch_size=20,target_size=(256,256),\n                                                  class_mode='binary')","f95885bc":"history=model.fit_generator(train_generator,steps_per_epoch=100,epochs=5)","b25d0eec":"import matplotlib.pyplot as plt\nacc = history.history['acc']\nloss = history.history['loss']\nepochs = range(len(acc))\n\nplt.plot(epochs, acc, 'r', label='Training accuracy')\nplt.legend(loc=0)\nplt.figure()","a990a2dc":"plt.plot(epochs, loss, 'b', label='Training loss')\nplt.legend(loc=0)\nplt.figure()","ec28ac04":"#Image Generator"}}