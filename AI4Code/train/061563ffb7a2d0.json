{"cell_type":{"3b4afd11":"code","a1ea8707":"code","26117e4d":"code","01478783":"code","47740f64":"code","5e011dff":"code","1610d713":"code","b9258ae4":"code","d6d38c31":"code","f5f98efa":"code","1852bb7c":"code","18e7c0eb":"code","6c6bbb2b":"code","fb659ee1":"code","94807d00":"code","9082e639":"code","02fbc99e":"code","d8d3b7c3":"code","d0ab2e66":"markdown","c0c2c468":"markdown","34e728f2":"markdown","e3f0784f":"markdown","e3eb90f7":"markdown","c0f6ad04":"markdown","d2e9878b":"markdown","75abf670":"markdown","9f7856ec":"markdown","0d4ac166":"markdown","211a52c5":"markdown"},"source":{"3b4afd11":"import optuna\nimport numpy as np\nimport pandas as pd\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GroupKFold\n\nimport matplotlib.pyplot as plt\nfrom matplotlib.colors import ListedColormap","a1ea8707":"train = pd.read_parquet('..\/input\/dtrain-parquet\/dtrain.parquet')\ntrain = train.query(\"weight != 0\")\ntrain.reset_index(inplace=True, drop=True)\ntrain[\"action\"] = (train[\"resp\"] > 0).astype(int)\ntrain[\"sample_weight\"] = abs(train['resp'])*train['weight'].transform('sqrt')\nfs = [\"weight\"] + [f'feature_{x}' for x in range(130)] \nfs_median = train[fs].median()\ntrain.fillna(fs_median,inplace=True)\nfs_median_v = fs_median.values\nX = train[fs].values\ny = train[[\"action\"]].values.ravel()\ndates = train[\"date\"].values.ravel()","26117e4d":"LOCAL_CV = False\nSUBMISSION = True\nshow_plot = False\nSUBMISSION_d = 6","01478783":"from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\nfrom sklearn.utils.validation import _deprecate_positional_args\n\n# https:\/\/www.kaggle.com\/marketneutral\/purged-rolling-time-series-cv-split\n# https:\/\/github.com\/getgaurav2\/scikit-learn\/blob\/d4a3af5cc9da3a76f0266932644b884c99724c57\/sklearn\/model_selection\/_split.py#L2243\nclass PurgedGroupTimeSeriesSplit(_BaseKFold):\n    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n    Allows for a gap in groups to avoid potentially leaking info from\n    train into test if the model has windowed or lag features.\n    Provides train\/test indices to split time series data samples\n    that are observed at fixed time intervals according to a\n    third-party provided group.\n    In each split, test indices must be higher than before, and thus shuffling\n    in cross validator is inappropriate.\n    This cross-validation object is a variation of :class:`KFold`.\n    In the kth split, it returns first k folds as train set and the\n    (k+1)th fold as test set.\n    The same group will not appear in two different folds (the number of\n    distinct groups has to be at least equal to the number of folds).\n    Note that unlike standard cross-validation methods, successive\n    training sets are supersets of those that come before them.\n    Read more in the :ref:`User Guide <cross_validation>`.\n    Parameters\n    ----------\n    n_splits : int, default=5\n        Number of splits. Must be at least 2.\n    max_train_group_size : int, default=Inf\n        Maximum group size for a single training set.\n    group_gap : int, default=None\n        Gap between train and test\n    max_test_group_size : int, default=Inf\n        We discard this number of groups from the end of each train split\n    \"\"\"\n\n    @_deprecate_positional_args\n    def __init__(self,\n                 n_splits=5,\n                 *,\n                 max_train_group_size=np.inf,\n                 max_test_group_size=np.inf,\n                 group_gap=None,\n                 ):\n        super().__init__(n_splits, shuffle=False, random_state=None)\n        self.max_train_group_size = max_train_group_size\n        self.group_gap = group_gap\n        self.max_test_group_size = max_test_group_size\n\n    def split(self, X, y=None, groups=None):\n        \"\"\"Generate indices to split data into training and test set.\n        Parameters\n        ----------\n        X : array-like of shape (n_samples, n_features)\n            Training data, where n_samples is the number of samples\n            and n_features is the number of features.\n        y : array-like of shape (n_samples,)\n            Always ignored, exists for compatibility.\n        groups : array-like of shape (n_samples,)\n            Group labels for the samples used while splitting the dataset into\n            train\/test set.\n        Yields\n        ------\n        train : ndarray\n            The training set indices for that split.\n        test : ndarray\n            The testing set indices for that split.\n        \"\"\"\n        if groups is None:\n            raise ValueError(\n                \"The 'groups' parameter should not be None\")\n        X, y, groups = indexable(X, y, groups)\n        n_samples = _num_samples(X)\n        n_splits = self.n_splits\n        group_gap = self.group_gap\n        max_test_group_size = self.max_test_group_size\n        max_train_group_size = self.max_train_group_size\n        n_folds = n_splits + 1\n        group_dict = {}\n        u, ind = np.unique(groups, return_index=True)\n        unique_groups = u[np.argsort(ind)]\n        n_samples = _num_samples(X)\n        n_groups = _num_samples(unique_groups)\n        for idx in np.arange(n_samples):\n            if (groups[idx] in group_dict):\n                group_dict[groups[idx]].append(idx)\n            else:\n                group_dict[groups[idx]] = [idx]\n        if n_folds > n_groups:\n            raise ValueError(\n                (\"Cannot have number of folds={0} greater than\"\n                 \" the number of groups={1}\").format(n_folds,\n                                                     n_groups))\n\n        group_test_size = min(n_groups \/\/ n_folds, max_test_group_size)\n        group_test_starts = range(n_groups - n_splits * group_test_size,\n                                  n_groups, group_test_size)\n        for group_test_start in group_test_starts:\n            train_array = []\n            test_array = []\n\n            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n                train_array_tmp = group_dict[train_group_idx]\n                \n                train_array = np.sort(np.unique(\n                                      np.concatenate((train_array,\n                                                      train_array_tmp)),\n                                      axis=None), axis=None)\n\n            train_end = train_array.size\n \n            for test_group_idx in unique_groups[group_test_start:\n                                                group_test_start +\n                                                group_test_size]:\n                test_array_tmp = group_dict[test_group_idx]\n                test_array = np.sort(np.unique(\n                                              np.concatenate((test_array,\n                                                              test_array_tmp)),\n                                     axis=None), axis=None)\n\n            test_array  = test_array[group_gap:]\n                    \n            yield [int(i) for i in train_array], [int(i) for i in test_array]","47740f64":"from sklearn.metrics import roc_auc_score\n\ndef utility(estimator, X, y, idx):\n    \"\"\"Custom scoring object as per documentation:\n    https:\/\/scikit-learn.org\/stable\/modules\/model_evaluation.html#implementing-your-own-scoring-object\n    Utility score formulae are defined in competition's intro:\n    https:\/\/www.kaggle.com\/c\/jane-street-market-prediction\/overview\/evaluation\n    Using optimisation tricks from @gogo827jz:\n    https:\/\/www.kaggle.com\/c\/jane-street-market-prediction\/discussion\/201257\n    \"\"\"\n\n    # still looking for a way to write this for xgb.cv but it passes DMatrix which doesn't allow indexing...\n    # https:\/\/xgboost.readthedocs.io\/en\/latest\/tutorials\/custom_metric_obj.html\n    date = train.loc[idx, 'date'].values\n    num_date = np.unique(date).size\n    weight = train.loc[idx, 'weight'].values\n    resp = train.loc[idx, 'resp'].values\n    \n    action = estimator.predict(X)\n    proba = estimator.predict_proba(X)[:, 1]\n    roc_auc = roc_auc_score(y, proba)\n    p_i = np.bincount(date, weight * resp * action)\n    \n    t = p_i.sum() \/ np.sqrt((p_i ** 2).sum()) * np.sqrt(250 \/ num_date)\n    u = np.clip(t, 0, 6) * p_i.sum()\n    u_daily = u \/ num_date\n    print(\"{} days, roc_auc:{:<10.3f}, t:{:<10.3f}, u:{:<10.3f}, u_daily:{:<10.3f}\".format(num_date, roc_auc, t, u, u_daily))\n    return roc_auc, t, u, u_daily","5e011dff":"depths = [3, 4, 5, 6, 7, 8 ,9]\ncv_dict = {\n    \"PurgedCV\": PurgedGroupTimeSeriesSplit(n_splits=5, \n                                           group_gap=5, \n                                           max_train_group_size=200, \n                                           max_test_group_size=100), # train: valid = 2:1 \n    \"GroupCV_1\": GroupKFold(n_splits=3), # train: valid = 2:1\n    \"GroupCV_2\": GroupKFold(n_splits=5), # train: valid = 4:1\n}\nlgb_params = dict(num_leaves=31, \n                       max_depth=7, \n                       learning_rate=0.01, \n                       n_estimators=200, \n                       objective=\"binary\", \n                       min_child_weight=0.001, min_child_samples=20, \n                       subsample=1.0, subsample_freq=0, \n                       colsample_bytree=0.8, \n                       reg_alpha=1, reg_lambda=1, \n                       random_state=2, \n                       n_jobs=-1, \n                       silent=True, \n                       importance_type='split'\n                      )\n","1610d713":"# Code from https:\/\/www.kaggle.com\/gogo827jz\/jane-street-ffill-xgboost-purgedtimeseriescv\ndef plot_cv_indices(cv, X, y, group, ax, n_splits, lw=10):\n    \"\"\"Create a sample plot for indices of a cross-validation object.\"\"\"\n    \n    cmap_cv = plt.cm.coolwarm\n\n    jet = plt.cm.get_cmap('jet', 256)\n    seq = np.linspace(0, 1, 256)\n    _ = np.random.shuffle(seq)   # inplace\n    cmap_data = ListedColormap(jet(seq))\n\n    # Generate the training\/testing visualizations for each CV split\n    for ii, (tr, tt) in enumerate(cv.split(X=X, y=y, groups=group)):\n        # Fill in indices with the training\/test groups\n        indices = np.array([np.nan] * len(X))\n        indices[tt] = 1\n        indices[tr] = 0\n\n        # Visualize the results\n        ax.scatter(range(len(indices)), [ii + .5] * len(indices),\n                   c=indices, marker='_', lw=lw, cmap=cmap_cv,\n                   vmin=-.2, vmax=1.2)\n\n    # Plot the data classes and groups at the end\n    ax.scatter(range(len(X)), [ii + 1.5] * len(X),\n               c=y, marker='_', lw=lw, cmap=plt.cm.Set3)\n\n    ax.scatter(range(len(X)), [ii + 2.5] * len(X),\n               c=group, marker='_', lw=lw, cmap=cmap_data)\n\n    # Formatting\n    yticklabels = list(range(n_splits)) + ['target', 'day']\n    ax.set(yticks=np.arange(n_splits+2) + .5, yticklabels=yticklabels,\n           xlabel='Sample index', ylabel=\"CV iteration\",\n           ylim=[n_splits+2.2, -.2], xlim=[0, len(y)])\n    ax.set_title('{}'.format(type(cv).__name__), fontsize=15)\n    return ax","b9258ae4":"%%time\nif show_plot:\n    fig, ax = plt.subplots()\n    cv = cv_dict[\"PurgedCV\"]\n    plot_cv_indices(cv, X, y, dates, ax, 5, lw = 20)\n    plt.show()","d6d38c31":"score_cols = [\"roc_auc\",\"t\",\"u\",\"u_daily\"]\nscore_df = pd.DataFrame([])\nif LOCAL_CV:\n    result_d = {}\n    for cv_name, cv in cv_dict.items():\n        print(\"*\" * 10 + \"  \" + cv_name + \"  \" + \"*\" * 10)    \n        for d in depths:\n            print(\"*\" * 5 + \" Depth: \",d,\" \"+ \"*\" * 5)\n            new_lgb_params = lgb_params.copy()\n            new_lgb_params[\"max_depth\"] = d\n            model = LGBMClassifier(**new_lgb_params)\n            t_score = []\n            v_score = []        \n            for f,(t_idx, v_idx) in enumerate(cv.split(X, y, dates)):\n                print(\"Fold \"+str(f)+\" :\")\n                X_t, X_v = X[t_idx], X[v_idx]\n                y_t, y_v = y[t_idx], y[v_idx]\n                w_t = train.loc[t_idx, \"sample_weight\"]\n                model.fit(X_t, y_t, eval_set =[(X_v, y_v)], eval_metric = [\"logloss\"], early_stopping_rounds = 20, sample_weight= w_t,verbose=True)\n                iteration = model.best_iteration_\n                print(\"Training Iteration: \", iteration)\n                print(\"Train\",end=\":\\t\")\n                t_roc_auc, t_t, t_u, t_u_daily = utility(model, X_t, y_t, t_idx)\n                print(\"Valid\",end=\":\\t\")\n                v_roc_auc, v_t, v_u, v_u_daily = utility(model, X_v, y_v, v_idx)\n                t_score.append([t_roc_auc,t_t,t_u,t_u_daily,iteration])\n                v_score.append([v_roc_auc,v_t,v_u,v_u_daily,iteration])  \n            t_score_df = pd.DataFrame(t_score, columns = score_cols+[\"iteration\"])\n            v_score_df = pd.DataFrame(v_score, columns = score_cols+[\"iteration\"])\n            t_score_df[\"train\"] = True \n            t_score_df[\"cv\"] = cv_name\n            t_score_df[\"depth\"] = d\n            v_score_df[\"train\"] = False \n            v_score_df[\"cv\"] = cv_name\n            v_score_df[\"depth\"] = d\n            t_score_mean = t_score_df[score_cols].mean()\n            t_score_std = t_score_df[score_cols].std()\n            v_score_mean = v_score_df[score_cols].mean()\n            v_score_std = v_score_df[score_cols].std()\n            score_df = pd.concat([score_df, t_score_df, v_score_df],axis=0)","f5f98efa":"if LOCAL_CV:\n    score_df.to_csv(\"score_df.csv\")\nelse:\n    CV_FOLDER = \"cv-score\"\n    score_df = pd.read_csv('..\/input\/'+ CV_FOLDER +'\/score_df.csv', index_col=0)","1852bb7c":"score_df.head()","18e7c0eb":"score_df_mean = score_df.groupby([\"cv\",\"depth\",\"train\"])[score_cols+[\"iteration\"]].mean()\nscore_df_std = score_df.groupby([\"cv\",\"depth\",\"train\"])[score_cols+[\"iteration\"]].std()","6c6bbb2b":"score_df_mean.style.format(\"{:.2f}\")","fb659ee1":"def highlight_max(s):\n    '''\n    highlight the maximum in a Series yellow.\n    '''\n    is_max = s == s.max()\n    return ['background-color: yellow' if v else '' for v in is_max]\nIdx = pd.IndexSlice\nscore_df_mean.loc[Idx[:,:,False],:].style.apply(highlight_max).format(\"{:.4f}\")","94807d00":"import janestreet\nif SUBMISSION:\n    env = janestreet.make_env() # initialize the environment\n    iter_test = env.iter_test() # an iterator which loops over the test set","9082e639":"if SUBMISSION:\n    new_lgb_params = lgb_params.copy()\n    new_lgb_params[\"max_depth\"] = SUBMISSION_d\n    model = LGBMClassifier(**new_lgb_params)\n    model.fit(X, y,sample_weight= train[\"sample_weight\"])","02fbc99e":"from tqdm import tqdm\nif SUBMISSION:\n    for (test_df, sample_prediction_df) in tqdm(iter_test):\n        if test_df.iloc[0,0] == 0:\n            action = 0\n        else:\n            X_test = test_df.loc[:,fs]\n            X_test = X_test.iloc[0,:].values\n            if np.isnan(X_test.sum()):\n                X_test = np.nan_to_num(X_test)+np.isnan(X_test)*fs_median_v\n            pred = model.predict(X_test.reshape(1,-1))\n            action = (pred).astype(int)\n        sample_prediction_df.action = action #make your 0\/1 prediction here\n        env.predict(sample_prediction_df)","d8d3b7c3":"# sample_prediction_df.action = 0 #make your 0\/1 prediction here\n# env.predict(sample_prediction_df)","d0ab2e66":"# Present CV and LB Result","c0c2c468":"# Summary\n1.  **GroupKFold 3 folds** is much more consistent with LB result compared with **the 5 fold version** and **PurgedGroupTimeSeriesSplit**\n    - 5 fold use train:valid data ratio 4:1, which is not the real train:test ratio. The difference between each CV is relatively small as well\n    - \n2.  As depth go from 7 to 11, we should see a decreasing validation score here because of overfitting issue. **GroupKFold 3 fold version** and LB score confirmed this but **PurgedGroupTimeSeriesSplit** didn't.\n\n\n###  Please let me know if you have any idea or suggestion towards the CV and LB consistency issue. Thank you!","34e728f2":"# Load Data","e3f0784f":"# Janestreet CV Research: **GroupKFold** or **PurgedGroupTimeSeriesSplit**\nIn this notebook, I want to see which CV result is more close to LB (or maybe private test set): **GroupKFold** or **PurgedGroupTimeSeriesSplit**. Through the notebook, we can see that **GroupKFold** result is more close to LB. Here is my thought:\n1. Many people tend to use **PurgedGroupTimeSeriesSplit** method as it can prevent data leakage issue in time series fitting, but we found it hard to match the rank of local CV result and the rank of LB.\n2. Opposite views towards the two assumptions by using the **PurgedGroupTimeSeriesSplit**: \n    1. This is a time series competition: as we are not given \"stock id\", we can hardly construct some time based features. Also, there is no feature in the data like \"price\" that can be seen continuous from day 1 to day 2. \n    2. Training with the data in the future to predict the past data may cause data leakage: this data is unlikely to be raw data and they may have been normalized from day to day. As they are normalized day by day, data leakage may not be a issue here.\n3. Reasons why **GroupKFold** can be better:\n    1. Training and Validation data can be larger than those used in **PurgedGroupTimeSeriesSplit** as it uses whole train data\n    2. When we used the future data to train and past data to valid, we actually tested the robustness in a different perspective: based on future market environment, whether or not we can predict current market.\n    \nSome notes:\n1. During local CV, using **train size : valid size = 2:1** can match **whole train size: private test size**. So that's why I chose those parameter in the Local CV part.\n2. As Utility is positively related with the data length, I use `u_daily = u \/ num_of_date` here as another metric to relief this issue.\n\n\n## If you found this helpful, please UP VOTE! Thank you!","e3eb90f7":"## Local CV Score","c0f6ad04":"# Utility","d2e9878b":"# Submission","75abf670":"# PurgedGroupTimeSeriesSplit","9f7856ec":"# Read Package","0d4ac166":"## LB Score:\n| Depth      | GroupCV 3 folds u_daily | GroupCV 5 folds u_daily | PurgedCV u_daily | LB     |\n| :---        |    :----:   |  :----:   |   :----:   |        ---: |\n| 3   | 6.63 (9) | 9.55 (5) | 6.36 (9) |  1548 (9) |\n| 4   | 7.10 (8)  | 9.17 (7) |  7.26 (5)  | 2169 (8) |\n| 5   | 10.04 (1)  | 9.60 (4) | 8.37 (1) |  2374 (7) |\n| 6   | 8.52 (3)  |  9.48 (6) | 6.92 (6) |  2512 (2) |\n| 7      | 9.37 (2)  |  9.96 (1)   | 7.33 (4) | 2660 (1)  |\n| 8   | 8.52 (4)    | 9.91 (2) | 7.40 (3) | 2485   (4)  |\n| 9      | 8.20 (5) | 9.73 (3)  | 6.78 (7) |  2488 (3) |\n| 10   | 7.90  (6)  |    | 7.59 (2) | 2484   (5)   |\n| 11      |   7.84 (7) |    | 6.61 (8) | 2463  (6) |","211a52c5":"# Local CV"}}