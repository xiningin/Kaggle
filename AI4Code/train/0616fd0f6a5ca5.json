{"cell_type":{"6a1f0a59":"code","1b259230":"code","aeb641d0":"code","385d4715":"code","efe6060c":"code","a05de9ad":"code","a8ee4d12":"code","8f2998c3":"code","fc9e0989":"code","02583c67":"code","a198d2d5":"code","7e8688e7":"code","79b19de6":"code","42f1e617":"code","1d7f63b8":"code","54b0de8d":"code","96fd1af7":"code","02fe3a94":"code","a8ef9285":"code","9bcb72ed":"code","70bbcf82":"code","5da9c525":"code","31eaff6a":"code","f672fe62":"code","ee3fcee7":"code","54b7db4f":"code","d8fd6c7d":"code","9331ea61":"code","7447300d":"code","097814b3":"code","847e3d20":"code","3196b4d5":"code","63cfa86b":"code","e3765ab4":"code","e1a3a916":"code","efc1a133":"code","d7081a89":"code","b68d068a":"code","7de5abee":"code","d40258dd":"code","8e0cc39a":"code","2c8cdd9b":"code","4d090d6d":"code","1e271eec":"code","fbe59969":"code","b11b3a32":"code","9f91d2fb":"code","90deb76d":"code","0904a158":"code","cd62cd9a":"code","0c636e4f":"code","a1da9d86":"code","e8e6b2a1":"code","bd138279":"code","eec3e1a4":"code","cc73a381":"code","61e334a0":"code","b74d484b":"code","935ed715":"code","8cd8bcd4":"code","69828cec":"code","98bc0567":"code","bbf7474d":"code","ebeb8128":"code","4e111457":"code","e170b43e":"code","8f88c98c":"markdown","f8e2f2da":"markdown","29bf4084":"markdown","20eebf87":"markdown","eff53163":"markdown","4316e6b1":"markdown","f4cecc4b":"markdown","38cb3a99":"markdown","b4fedf20":"markdown","8a80768a":"markdown","f07b48eb":"markdown","3dbd285e":"markdown","ae5849bf":"markdown","1c1bda4c":"markdown","1b880e11":"markdown","adfa6c4c":"markdown","afe5d407":"markdown","339747b3":"markdown","170fff5e":"markdown","08b8459f":"markdown","e23a0688":"markdown","9524f878":"markdown","d87fd7cd":"markdown","32b62234":"markdown","12a68c33":"markdown","367accef":"markdown","dc789524":"markdown","9fab0b95":"markdown","4d1b30fd":"markdown","a3a2a069":"markdown","2c4a2d7c":"markdown","0df47f36":"markdown","8809dceb":"markdown","a1ccc587":"markdown","eb460bf8":"markdown","232d3d33":"markdown","86ee324e":"markdown","fa196326":"markdown","a7d8f14f":"markdown","ac565285":"markdown","b82a78cf":"markdown","4d616408":"markdown","88a64231":"markdown","ad18ff33":"markdown","3eeb5edf":"markdown","6632339a":"markdown","19805def":"markdown","07cfedbd":"markdown","2f476c76":"markdown","b6d7a8c0":"markdown","a5fc3cc3":"markdown","5771f538":"markdown","1033d6b2":"markdown","4adda399":"markdown","de54f007":"markdown","1b8921d4":"markdown","bf546fd0":"markdown","b44837af":"markdown","1d4f959e":"markdown","d8106fb7":"markdown","9ef3d48a":"markdown","b103bd69":"markdown","0e3e43e2":"markdown","7ea14ee6":"markdown","92348f95":"markdown","50e5b007":"markdown","1caf3402":"markdown","92de7556":"markdown","74b8b63f":"markdown","0c1984ea":"markdown","3b95e6a8":"markdown","5252cb32":"markdown","70bdb13d":"markdown","49585d9d":"markdown","f5259719":"markdown","8671a680":"markdown","cb68256e":"markdown","186aaf15":"markdown","a8ec3dec":"markdown","81375804":"markdown","e4790a94":"markdown","1b419615":"markdown","9ea1fa45":"markdown","6689b96a":"markdown","41e1fdb6":"markdown","f3bc9a02":"markdown","fcd1ba5b":"markdown","3d73decb":"markdown","9402cadd":"markdown"},"source":{"6a1f0a59":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings \nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","1b259230":"train = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")","aeb641d0":"print(train.shape)","385d4715":"train.head()","efe6060c":"sns.countplot(train.label)\nplt.title(\"Counts of pictures in dataset\")\nplt.show()\n\ntrain.label.value_counts()","a05de9ad":"train[train.label == 1].head()","a8ee4d12":"train[train.label == 1].iloc[0]","8f2998c3":"train[train.label == 1].iloc[0][1:]","fc9e0989":"image = train[train.label == 1].iloc[0][1:]  # filtering data as explained above\nplt.imshow(image.values.reshape(28,28))\nplt.axis(\"off\")\nplt.show()","02583c67":"fig, ax = plt.subplots(1,6, figsize = (36,6))\nfor i in range(0,6):\n    ax[i].imshow(train[train.label == 1].iloc[i][1:].values.reshape(28,28))\n    ax[i].axis(\"off\")\nplt.show()","a198d2d5":"\nfig, ax = plt.subplots(10,15, figsize = (20,10))\nj = 0   # flag for rows of fig\nwhile j < 10:\n    for i in range(0,15):  # i for columns of fig\n        ax[j,i].imshow(train[train.label == j].iloc[i][1:].values.reshape(28,28))\n        ax[j,i].axis(\"off\")\n    j = j + 1\nplt.show()","7e8688e7":"test = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")","79b19de6":"print(test.shape)","42f1e617":"test.head()","1d7f63b8":"y_train = train[\"label\"]","54b0de8d":"X_train = train.drop(columns = [\"label\"], axis = 0)","96fd1af7":"print(\"Shape of X_train :\", X_train.shape)\nprint(\"Shape of y_train :\", y_train.shape)","02fe3a94":"X_train.iloc[0,:].values.reshape(28,28)","a8ef9285":"# Normalization\n# As i previously showed, our data have 255 as maximum pixel values.\n# In order to normalize, i will divide X_train and test data to 255.\n# Thus all values to be between 0 and 1.\n\nX_train = X_train \/ 255\ntest = test \/ 255","9bcb72ed":"# Reshape\nprint(\"Shape of X_train before reshape :\", X_train.shape )\nprint(\"Shape of test before reshape :\", test.shape )\n\nX_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)\n\nprint(\"Shape of X_train after reshape :\", X_train.shape )\nprint(\"Shape of test after reshape :\", test.shape )","70bbcf82":"X_train[0][0]","5da9c525":"a = np.array([list(range(16))])\na.shape","31eaff6a":"a = a.reshape(-1,2)\na.shape","f672fe62":"from keras.utils.np_utils import to_categorical\ny_train = to_categorical(y_train, num_classes = 10)","ee3fcee7":"y_train.shape","54b7db4f":"from sklearn.model_selection import train_test_split\n\nX_train, X_val, y_train, y_val = train_test_split(\n    X_train, \n    y_train, \n    test_size = 0.1, \n    random_state = 2 )","d8fd6c7d":"# print shape of split datas\nprint(\"Shape of X_train :\", X_train.shape)\nprint(\"Shape of y_train :\", y_train.shape)\nprint(\"Shape of X_val :\", X_val.shape)\nprint(\"Shape of y_val :\", y_val.shape)","9331ea61":"from sklearn.metrics import confusion_matrix\nimport itertools\n\nfrom keras.utils.np_utils import to_categorical   # for converting to one hot encoding\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.optimizers import RMSprop, Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","7447300d":"# Creating model\nmodel = Sequential()   \n\n#----------------\n# Convolution_1\n#----------------\n# Adding convolutin layer to model\n# Convolution layer will be created by 8 filters(feature detectors), \n# feature detector size will be 5x5,\n# padding type will be same padding,\n# and activation function will be relu.\nmodel.add(\n    Conv2D(\n        filters = 8, \n        kernel_size = (5,5),\n        padding = \"Same\",\n        activation = \"relu\",\n        input_shape = (28,28,1)))\n\n#----------------\n# Maxpooling_1\n#----------------\n\n# Adding maxpooling to model, poolsize will be 2x2.\nmodel.add(\n    MaxPool2D(pool_size = (2,2)))\n\n#----------------\n# Dropout_1\n#----------------\n\n# Adding drop out, drop out ratio will be %25.\nmodel.add(Dropout(0.25))\n\n\n#----------------\n# Convolution_2\n#----------------\nmodel.add(\n    Conv2D(\n        filters = 16, \n        kernel_size = (3,3),\n        padding = \"Same\",\n        activation = \"relu\"))\n\n#----------------\n# Maxpooling_2\n#----------------\nmodel.add(\n    MaxPool2D(\n        pool_size = (2,2),\n        strides = (2,2)))\n\n#----------------\n# Dropout_2\n#----------------\nmodel.add(Dropout(0.25))\n\n#----------------\n# Fully Connected layers\n#----------------\nmodel.add(Flatten()) # flattening\nmodel.add(Dense(256, activation = \"relu\")) # adding 1st hidden layer with 256 neurons\nmodel.add(Dropout(0.5))\nmodel.add(Dense(10, activation = \"softmax\")) # adding 2nd hidden layer with 10 neurons\n# softmax function is used for multiple classification and sigmoid is used for binary classification\n","097814b3":"model.summary()","847e3d20":"optimizer = Adam(lr = 0.001,\n                 beta_1 = 0.9,\n                 beta_2 = 0.999)","3196b4d5":"model.compile(optimizer = optimizer,\n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])","63cfa86b":"epochs = 5\nbatch_size = 250","e3765ab4":"datagen = ImageDataGenerator(\n    featurewise_center = False,# sets input mean to 0\n    samplewise_center = False, # sets each sample mean to 0\n    featurewise_std_normalization = False, # divide inputs by std of dataset\n    samplewise_std_normalization = False, # divides each input by its std\n    zca_whitening = False, # dimension reduction\n    rotation_range = 0.5, # randomly rotate images in 5 degree ranges\n    zoom_range = 0.5, # randomly zoom image\n    width_shift_range = 0.5, # randomly shift image horizantally\n    height_shift_range = 0.5, # randomly shift image vertically\n    horizontal_flip = False, # randomly flip image\n    vertical_flip = False # randomly flip image\n    )\n\n\ndatagen.fit(X_train)  # apply data augmentation to our X_train data","e1a3a916":"batch_size\n","efc1a133":"X_train.shape[0]  # samples","d7081a89":"X_train.shape[0] \/\/ batch_size","b68d068a":"result = model.fit_generator(\n    datagen.flow(X_train,y_train,batch_size = batch_size),\n    epochs = epochs,\n    validation_data = (X_val, y_val),\n    steps_per_epoch = X_train.shape[0] \/\/ batch_size\n)","7de5abee":"result.history","d40258dd":"# Losses \nplt.subplots(figsize=(8,6))\nplt.plot(result.history[\"loss\"], color = \"b\", label = \"train loss\")\nplt.plot(result.history[\"val_loss\"], color = \"r\", label = \"test loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Losses of fit with Augmented Data\")\nplt.legend()\nplt.show()","8e0cc39a":"# Accuracies\nplt.subplots(figsize=(8,6))\nplt.plot(result.history[\"accuracy\"], color = \"b\", label = \"train accuracy\")\nplt.plot(result.history[\"val_accuracy\"], color = \"r\", label = \"test accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracies of fit with Augmented Data\")\nplt.legend()\nplt.show()","2c8cdd9b":"print(\"Shape of X_val :\", X_val.shape)\nprint(\"Shape of y_val :\", y_val.shape)","4d090d6d":"# checking 1st row of y_val\n\ny_val[0]","1e271eec":"# Predicting labels of X_val data\n\ny_pred = model.predict(X_val)","fbe59969":"print(\"Shape of y_pred :\", y_pred.shape)","b11b3a32":"y_pred[0]","9f91d2fb":"# predicted class of first row of X_val data\nnp.argmax(y_pred[0])    ","90deb76d":"# true label of first row of X_val data\nnp.argmax(y_val[0])","0904a158":"# getting predicted classes (convert ot one-hot-vectors)\n \ny_pred_classes = np.argmax(y_pred, axis = 1)\n\n# validation observations to one-hot-vectors\n\ny_true = np.argmax(y_val, axis = 1)\n\nprint(\"Shape of y_pred_classes :\", y_pred_classes.shape)\nprint(\"Shape of y_true_classes :\", y_true.shape)","cd62cd9a":"# confusion matrix\nimport seaborn as sns\n\ncm = confusion_matrix(y_true, y_pred_classes)\n\nf,ax = plt.subplots(figsize = (8,5)) # creating f,ax object\nsns.heatmap(\n    cm, \n    annot = True, \n    linewidths = 0.01, \n    cmap = \"Greens\", \n    linecolor = \"gray\", \n    fmt = \".1f\", \n    ax = ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix of fit with Augmented Data\")\nplt.show()","0c636e4f":"result_1 = model.fit(\n    X_train,\n    y_train,\n    epochs = epochs,\n    validation_data = (X_val, y_val),\n    steps_per_epoch =  X_train.shape[0] \/\/ batch_size\n)","a1da9d86":"# Losses\nplt.subplots(figsize=(8,6))\nplt.plot(result_1.history[\"loss\"], label = \"train loss\")\nplt.plot(result_1.history[\"val_loss\"], label = \"test loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Losses of fit w\/o data augmentation\")\nplt.legend()\nplt.show()","e8e6b2a1":"# Accuracies\nplt.subplots(figsize=(8,6))\nplt.plot(result_1.history[\"accuracy\"], label = \"train accuracy\")\nplt.plot(result_1.history[\"val_accuracy\"], label = \"test accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracies\")\nplt.title(\"Accuracies of fit w\/o data augmentation\")\nplt.legend()\nplt.show()","bd138279":"# Predicting labels of X_val data\n\ny_pred = model.predict(X_val)\n\n# getting predicted classes (convert ot one-hot-vectors)\n \ny_pred_classes = np.argmax(y_pred, axis = 1)\n\n# validation observations to one-hot-vectors\n\ny_true = np.argmax(y_val, axis = 1)\n\n# confusion matrix\n\ncm = confusion_matrix(y_true, y_pred_classes)\n\nf,ax = plt.subplots(figsize = (8,5)) # creating f,ax object\nsns.heatmap(\n    cm, \n    annot = True, \n    linewidths = 0.01, \n    cmap = \"Greens\", \n    linecolor = \"gray\", \n    fmt = \".1f\", \n    ax = ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix of fit without Augmented Data\")\nplt.savefig(\"Confusion Matrix of fit without Augmented Data\")\nplt.show()\n","eec3e1a4":"from keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import GridSearchCV\n\n","cc73a381":"# Preparing cnn model\n\ndef create_model(optimizer , activation  , drop_out_rate, filters, kernel_size, padding ):\n    model = Sequential()  \n    \n    model.add(\n    Conv2D(\n        filters = filters, \n        kernel_size = kernel_size,\n        padding = padding,\n        activation = activation,\n        input_shape = (28,28,1)))\n    \n    model.add(\n    MaxPool2D(pool_size = (2,2)))\n    \n    model.add(Dropout(drop_out_rate))\n    \n    model.add(\n    Conv2D(\n        filters = filters, \n        kernel_size = kernel_size,\n        padding = padding,\n        activation = activation))\n    \n    model.add(\n    MaxPool2D(\n        pool_size = (2,2),\n        strides = (2,2)))\n    \n    \n    model.add(Dropout(drop_out_rate))\n    \n    model.add(Flatten()) # flattening\n    model.add(Dense(256, activation = activation)) # adding 1st hidden layer with 256 neurons\n    model.add(Dropout(drop_out_rate))\n    model.add(Dense(10, activation = \"softmax\")) # adding 2nd hidden layer with 10 neurons\n    \n\n    \n    model.compile(optimizer = optimizer,\n              loss = \"categorical_crossentropy\",\n              metrics = [\"accuracy\"])\n    \n    \n    return model\n    ","61e334a0":"new_model = KerasClassifier(build_fn = create_model)\n\nparam_grid = {\n              'epochs':[3],\n              'batch_size':[250],\n              'optimizer' : [\"Adam\"],\n              'drop_out_rate' : [0.2],\n              'activation' : ['relu'],\n              \"filters\":[15],\n              \"kernel_size\":[(3,3)],\n              \"padding\":[\"same\"]\n             }\n\n\ngrid = GridSearchCV(\n    estimator = new_model, \n    param_grid = param_grid,\n    cv =2)\n\nresult_2 = grid.fit(X_train, y_train)","b74d484b":"result_2.best_params_","935ed715":"result_2.best_score_","8cd8bcd4":"from keras.callbacks import ReduceLROnPlateau\nlearning_rate_red = ReduceLROnPlateau(monitor='val_accuracy', \n                                            mode = \"auto\",\n                                            patience=1, \n                                            cooldown=2,\n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0)","69828cec":"model_lr_reduction = create_model(\n    optimizer = result_2.best_params_[\"optimizer\"],\n    activation = result_2.best_params_[\"activation\"],\n    drop_out_rate = result_2.best_params_[\"drop_out_rate\"],\n    filters = result_2.best_params_[\"filters\"],\n    kernel_size = (3,3),\n    padding = result_2.best_params_[\"padding\"]\n)","98bc0567":"result_3 = model_lr_reduction.fit(\n    X_train,\n    y_train,\n    epochs = 30,\n    validation_data = (X_val, y_val),\n    steps_per_epoch =  X_train.shape[0] \/\/ batch_size,\n    callbacks = [learning_rate_red]\n)","bbf7474d":"# Losses\nplt.subplots(figsize=(8,6))\nplt.plot(result_3.history[\"loss\"], label = \"train loss\")\nplt.plot(result_3.history[\"val_loss\"], label = \"test loss\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Losses of fit w LR reduction\")\nplt.legend()\nplt.savefig(\"Losses of fit w LR reduction\")\nplt.show()","ebeb8128":"# Losses\nplt.subplots(figsize=(8,6))\nplt.plot(result_3.history[\"accuracy\"], label = \"train accuracy\")\nplt.plot(result_3.history[\"val_accuracy\"], label = \"test accuracy\")\nplt.xlabel(\"Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Accuracies of fit w LR reduction\")\nplt.legend()\nplt.savefig(\"Accuracies of fit w LR reduction\")\nplt.show()","4e111457":"# Final results for submission\n\nfinal_result = model_lr_reduction.predict(test)\n\n# Selecting the classes which have the maximum probability\n\nfinal_result = np.argmax(final_result, axis = 1)\n\nfinal_result = pd.Series(final_result,name=\"Label\")","e170b43e":"submission = pd.concat(\n    [pd.Series(range(1,28001),name = \"ImageId\"),final_result],\n    axis = 1\n)\n\nsubmission.to_csv(\"cnn_mnist_datagen.csv\",index=False)","8f88c98c":"<a id=\"2.3\"><\/a>\n### 2.3 One hot encoding with Keras","f8e2f2da":"<a id=\"5.5\"><\/a>\n## 5.5 Data Augmentation","29bf4084":"* KerasClassifier class in Keras takes an argument `build_fn` which is the name of the function to call to get your model.\n* We must define a function that defines our model, compiles it and returns it.\n* Defining function named as create_model :","20eebf87":"Creating model with best parameters","eff53163":"![image.png](attachment:image.png)","4316e6b1":"* Now, i can plot the image.\n* I need to reshape it to 28x28.\n* I will use `image.values.reshape()` code because `image.reshape()` is not working due to type of image is \"series\".","f4cecc4b":"<a id=\"5.9\"><\/a>\n## 5.9 Evaluating model without Data Augmentation","38cb3a99":"<a id=\"5.8\"><\/a>\n## 5.8 Fitting model without Data Augmentation\n","b4fedf20":"To keep the advantage of the fast computation time with a high LR, i decreased the LR dynamically every X steps (epochs) depending if it is necessary (when accuracy is not improved).","8a80768a":"### Ploting Confusion Matrix","f07b48eb":"## Let us have a look at picture of 1, how it looks like:","3dbd285e":"## Creating X_train and y_train from train data","ae5849bf":"<a id=\"5.4\"><\/a>\n## 5.4 Epochs and Batch size","1c1bda4c":"* When model running, keras maintains `history` object in the backround.\n* This object keeps loss values, accuracies, validation losses and validation accuracies as per epoch in memory\n* History object is the output of the fit operation (in our model it is output of `model.fit_generator()`)\n* Type of history object is dictionary:\n* keys of dictionary : loss, accuracy, val_loss, val_accuracy\n* We can access the the dictionary as `result.history`\n* We can access keys and values for visualisation","1b880e11":"<a id=\"5\"><\/a>\n## 5. Implementing with Keras","adfa6c4c":"<a id=\"4.5\"><\/a>\n## 4.5 Full Connection","afe5d407":"* I want to see some other pictures of 1.\n* So, i will plot the first 6 samples from filtered data in a for loop.","339747b3":"* As a result of softmax function:\n* It creates a propability between 0 and 1 for each classes.\n* y_pred[0] has 10 probabilies for each classses (digits from 0 to 9.)\n* Sum of all probabilies is equal to 1.\n* In order to get the predicted class we will find the class that has maximum probability.\n* We will use `np.argmax` function.\n* It gives the index of maximum element in array.\n* So that index will be our predicted class.","170fff5e":"<a id=\"5.10\"><\/a>\n## 5.10 Modelling the CNN using `KerasClassifier` and GridSearch optimization","08b8459f":"Importing Libraries:","e23a0688":"* First i will filter data as to get label = 1:","9524f878":"* From above, shape of y_val is (4200x10)\n* We did one hot encoding with keras before.\n* 10 columns are coming from one-hot-encoding, num_classes, we created 10 classes, one class for one digit.\n* Class1is digit 0, class2 is digit 1, class 3 is digit 2 etc..","d87fd7cd":"* Catergorical cross entropy (CCE) to be used for calculating losses.\n* CCE is used for multi-class classifications.\n* Binary cross entropy is isued for binary classifications.\n* For detailed explanation refer to: https:\/\/gombru.github.io\/2018\/05\/23\/cross_entropy_loss\/\n* CCE loss function:\n![image.png](attachment:image.png)","32b62234":"* To plot the image i need only pixels, not label.\n* Thus, i will exlude the label by filtering again:","12a68c33":"* Now we have 4D arrays after reshape.\n* (42000, 28, 28, 1) means:\n> we have 42000 rows,<br>\n> each 42000 rows has again 28 rows, <br>\n> each 28 rows has 28 rows and 1 column.\n* We can check slicing first row of the first row by X_train[0][0]:\n> we will see 28 rows and 1 column","367accef":"* Adam to be used as optimizer\n* Adam changes learning rate in order to optimize the calculation\n* Detailed explanation on Adam: <br> \nhttps:\/\/machinelearningmastery.com\/adam-optimization-algorithm-for-deep-learning\/ <br>\nhttps:\/\/keras.io\/api\/optimizers\/adam\/","dc789524":"<a id=\"5.1\"><\/a>\n## 5.1 Creating Model","9fab0b95":"<a id=\"4.1.1\"><\/a>\n### 4.1.1 Feature Mapping","4d1b30fd":"<a id=\"2.1\"><\/a>\n### 2.1 Normalization:","a3a2a069":"* In order to remember:\n* We had training and validation splits before.\n* Train split --> X_train, y_train\n* Validation split --> X_val, y_val","2c4a2d7c":"![image.png](attachment:image.png)","0df47f36":"<a id=\"1\"><\/a>\n# 1.Loading and Understanding Data","8809dceb":"* As we can see above, shape of Y_pred is 4200x10, 4200 rows and 10 columns\n* Each predicted label has 10 values (columns)\n* Lets examine the 1st predicted label:","a1ccc587":"<a id=\"4.1.3\"><\/a>\n### 4.1.3 Convolutional Layer","eb460bf8":"![image.png](attachment:image.png)","232d3d33":"Dropout:<br>\nSimply dropout refers to ignoring units (i.e. neurons) during the training phase of certain set of neurons which is chosen at random. By \u201cignoring\u201d, these units are not considered during a particular forward or backward pass.","86ee324e":"<a id=\"2\"><\/a>\n# 2.Normalization, Reshape, Label Encoding","fa196326":"<a id=\"4.1.2\"><\/a>\n### 4.1.2 Same Padding","a7d8f14f":"* I will use same model structure as i did in the begining. ","ac565285":"* From above, we see the max values for pixel columns.\n* We have different values changing between 0 to 255 for pixels.\n* In color structure, each color is composed of Red - Green - Blue (RGB).\n* RGB values are represebted by integers betweem 0 and 255.\n* For example, if RGB is\n >255,0,0 then the color is RED <br>\n >0,255,0 then the color is GREEN <br>\n >0,0,255 then the color is BLUE\n* Also, this can show that the colors are 3-dimensional (R-G-B)","b82a78cf":"* Same epoch and batchsize will be used.","4d616408":"* From above, for the first row of X_val data,\n* Prediction is digit 6 and prediction is correct.\n* Now time to same predictions for all rows in X_val:","88a64231":"![image.png](attachment:image.png)","ad18ff33":"## Normalization, Reshape, Label encoding(one hot encoding)","3eeb5edf":"<a id=\"5.7\"><\/a>\n## 5.7 Evaluating Data Augmented Model","6632339a":"* First, let us check pixel values of first sample in our data X_train.","19805def":"* Flattening is converting data into a vector.\n* So, it will be used as input of our classification algorithm (Artificial Neural Network)","07cfedbd":"* Intersects of true label 4 and predicted label 9 is 66.\n* This means: algorithm predicted 66 number of digit 4 as digit 9.","2f476c76":"Model will be composed of below parts: <br>\n* Convolution_1 <br>\n* Max pooling_1 <br>\n* Dropout_1<br>\n* Convolution_2 <br>\n* Max pooling_2 <br>\n* Dropout_2 <br>\n* Full connected layer (2 hidden layers)","b6d7a8c0":"<a id=\"4.1\"><\/a>\n## 4.1 Convolution operation","a5fc3cc3":"![image.png](attachment:image.png)","5771f538":"<a id=\"2.2\"><\/a>\n### 2.2 Reshape","1033d6b2":"* In test data; we have 28000 rows and 784 columns.\n* There is no label column, we will find the labels after we train our data.\n* So, there are 28000 samples, their labels to be defined with CNN.","4adda399":"![image.png](attachment:image.png)","de54f007":"<a id=\"4.2\"><\/a>\n## 4.2 ReLU","1b8921d4":"* As we can see, there are lots of samples which are picture 1.\n* Now, i will pick the first row, from filtered data:","bf546fd0":"### Defining a function as create_model to pass by `build_fn` argument","b44837af":"![image.png](attachment:image.png)","1d4f959e":"* We lilke to have small size in order to have a faster computation.\n* For this purpose we do \"pooling\"; we create a pool of matris 2x2 or 3x3 etc.\n* And scan the output data with that pool, get the mean, sum or max value of the pool.\n* In below example, we will get the max of pool, so it is max pooling.\n* New output data will be decreased to 4x4 from 7x7 size.\n* So pooling:\n> Reduces the number of parameters (makes down-sampling, sub-sampling).<br>\n> Reduces the computation in network, also controls overfitting.","d8106fb7":"<a id=\"4\"><\/a>\n## 4. Convolutional Neural Network","9ef3d48a":"![image.png](attachment:image.png)","b103bd69":"### What \"-1\" means in Reshape operation ?","0e3e43e2":"* In normalization:\n> We change colors as to be the pictures in grayscale, thus we can reduce the effect of color differences.<br>\n> This will increase CNN performance and speed.\n* In reshape:\n> We change the shape off all images to 3-dimension.<br>\n> Shape of our images is 28x28 in our train and test data.<br>\n> So, all our data to be reshaped as 28x28x1.\n>> 1 in 28x28x1 --> means that it is grayscale<br>\n>> 3 in 28x28x3 --> means that it is colored (R-G-B)\n* Label encoding:\n> We change our labels (y_train data) to one hot vectors:<br>\n>> 0 --> [1,0,0,0,0,0,0,0,0,0]<br>\n>> 3 --> [0,0,0,1,0,0,0,0,0,0]<br>\n>> 9 --> [0,0,0,0,0,0,0,0,0,1]","7ea14ee6":"* Now time to classify our flattened data.\n* In this step, our full convolutional neural network is been added to artificial neural network.\n* In ANN we have:<br>\n> - an input layer,<br>\n> - hidden layers,<br>\n> - an output layer.<br>\n\n![image.png](attachment:image.png)","92348f95":"### Getting predicted values with the validation split","50e5b007":"<a id=\"5.3\"><\/a>\n## 5.3 Compiling Model","1caf3402":"* Convolute means: to fold or coil into numerous overlapping layers\n* In CNN, a detector scans the images or objects and detect the features of images; so it is called as `feature detector`.\n* Feature detector can be named as `kernel` or `filter`.\n* Features can be anyting specific for that image, it can be horizontal, vertical or oval edges or shapes.\n* If we think a table as an input, features can be legs, top surface shape etc.\n* Feature detector can be axb matrix (like 3x3 , 4x4).\n* Input image is convolved by feature detector (or filter) and `Feature Map` is created.\n* Feature map is the result of element-wise multiplication of Feature Detector and corresponding matris on input.\n* Stride is the navigation step of filter: if stride is 1, filter scans the input moving 1 step.\n* After feature maping, size of image is decreased; in below example it is decreased from 7x7 to 5x5.","92de7556":"<a id=\"3\"><\/a>\n## 3. Train - Test split","74b8b63f":"* We know the X_val and corresponding true labels as y_val\n* We want to test our model by giving X_val as input and y_pred as output (predicted labels)\n* Afterward we will compare y_pred and y_label\n","0c1984ea":"## Test Data","3b95e6a8":"* After convolutional layer created, we apply ReLU activation function.\n* We apply the rectifier function here because we want to increase the nonlinearity in our CNN. The reason for increasing the nonlinearity in CNN because images are highly nonlinear. But when we apply different functions like convolution, so the image may become linear. Therefore, we want to break the linearity.\n* ReLU(x) = 0 if x < 0 \n* ReLU(x) = x if x > 0 \n\n![image.png](attachment:image.png)","5252cb32":"[1.Loading and Understanding Data](#1)<br>\n[2.Normalization, Reshape and Label Encoding](#2)<br>\n>[2.1 Normalization](#2.1)<br>\n>[2.2 Reshape](#2.2)<br>\n>[2.3 One hot encoding with Keras](#2.3)<br>\n\n[3.Train-Test split](#3)<br>\n[4.Convolutional Neural Network](#4)<br>\n>[4.1 Convolution operation](#4.1)<br>\n   * [4.1.1 Feature Mapping](#4.1.1)<br>\n   * [4.1.2 Same Padding](#4.1.2)<br>\n   * [4.1.3 Convolutional Layer](#4.1.3)<br>\n   \n>[4.2 ReLU](#4.2)<br>\n>[4.3 Max Pooling](#4.3)<br>\n>[4.4 Flattening](#4.4)<br>\n>[4.5 Full Connection](#4.5)<br>\n\n[5.Implementing with Keras](#5)<br>\n>[5.1 Creating Model](#5.1)<br>\n>[5.2 Defining Optimizer](#5.2)<br>\n>[5.3 Compiling Model](#5.3)<br>\n>[5.4 Epochs and Batch size](#5.4)<br>\n>[5.5 Data Augmentation](#5.5)<br>\n>[5.6 Fiting model with Data Augmentation](#5.6)<br>\n>[5.7 Evaluating the data augmented model](#5.7)<br>\n>[5.8 Fiting model without data augmentation](#5.8)<br>\n>[5.9 Evaluating model without data augmentation](#5.9)<br>\n>[5.10 Modelling the CNN using `KerasClassifier`  and GridSearch Optimization](#5.10)<br>\n>[5.11 Using keras `ReduceLROnPlateau` with best parameters](#5.11)<br>\n\n","70bdb13d":"<a id=\"4.4\"><\/a>\n## 4.4 Flattening","49585d9d":"## Train Data","f5259719":"* `epochs`: Generally defined as \"one pass over the entire dataset\", used to separate training into distinct phases, which is useful for logging and periodic evaluation.\n* If we have 100 samples in our train data; in one epoch, one forward and backward propogation to be passed for all 100 samples and one accuracy to be calculated.\n* When we get epochs as 10; it means that 10 forward-backward to be passed and 10 accuracies to be calculated.\n* `batch_size`: Number of samples per gradient update. \n* If we set batch size as 20; we will have 100 samples \/ 20 = 5 batches in each epoch.","8671a680":"* So, we have created a single feature map by a single feature detector.\n* However, we prefer to use multiple filters\/feature detectors rather then using a single filter.\n* You can think about filtering a dog image: While a filter can be created for ears, an other filter is created for nose, an other filter for tail etc. \n* One layer is created for each feature detector\/filter; we can say that a layer is a feature map.\n* Thus, we created our convolutional layer which is composed of feature maps.\n","cb68256e":"<a id=\"5.2\"><\/a>\n## 5.2 Defining Optimizer","186aaf15":"* We learnt that we loose some info during feature mapping.\n* When you think that we do multiple convolution we loose a bit of information in each convolution.\n* So, in order to prevent or minimize the loss, we do padding.\n* Here, we will apply \"same padding\".\n* In same padding aim is to have the same size in output with the input data.\n* In previous figure we got 5x5 feature map (output) while we have input size as 7x7.\n* With same padding we will get 7x7 output without loosing any size.\n* For this aim, input is covered by zeros like a frame and feature mapping performed on this input as stride = 1.","a8ec3dec":"* For above reshape coding, you noticed that there is `-1` in (-1,28,28,1).\n* In reshape, if you do not know the exact size of the axis, you put -1 for that axis and python calculates it automatically for you.\n* Here we could have coded it as (42000,28,28,1) and there would be no difference.\n* We passed -1 in place of 42000; and also -1 in place of 28000.\n* Another example can be seen as below:\n> I have an array \"a\" with a shape of (1,16).<br>\n> I want to reshape it as to have 2 columns, not want to calculate how many rows i will need.<br>\n> Than i will put reshape(-1,2).<br>\n> This is same as reshape(8,2)","81375804":"* Dataset is composed of 42000 rows and 785 columns.\n* There is \"label\" column which shows the numbers from 0 to 9; so dataset is composed of pictures from 0 to 9.\n* Each picture has 28x28 = 784 pixels; thus data has columns from pixel0 to pixel 783.\n* So, there are 42000 samples; those are pictures labeled from 0 to 9.\n* Let us see the distribution of labels (pictures):","e4790a94":"* CNN is widely used for image classification and object detection.\n* In Convolutional Neural Network, there are basically following steps:<br>\n    -Convolution Operation (Feature Mapping + Padding).<br>\n    -ReLU.<br>\n    -Pooling.<br>\n    -Flattening.<br>\n    -Full Connection.","1b419615":"<a id=\"5.11\"><\/a>\n## 5.11 Using `ReduceLROnPlateau` with best parameters","9ea1fa45":"* Now i will plot 15 different images for each numbers as below:","6689b96a":"* Data augmentation is a strategy that enables practitioners to significantly increase the diversity of data available for training models, without actually collecting new data. \n* Data augmentation techniques such as cropping, padding, and horizontal flipping are commonly used to train large neural networks.\n* Detailed explanation: https:\/\/nanonets.com\/blog\/data-augmentation-how-to-use-deep-learning-when-you-have-limited-data-part-2\/\n\n* Aim is to prevent overfitting, by artificially expanding our dataset.\n* For example, below digit 6, is augmented by flipping, rotating,zooming in and out etc. \n![image.png](attachment:image.png)","41e1fdb6":"* First, we pass input values to the input layer.\n* A fully connected layer performs an operation, and predict the output.\n* Then it checks for the error rate in the output layer with the help of cost function as we did in artificial neural networks.\n* After that, we backpropagate and adjust the weights, and again predict the output.\n* Then again the predicted output is matched with actual output and calculates the error rate.\n* Again backpropagate, update the weights.\n* This process is repeated until CNN predicts the accurate result.","f3bc9a02":"* We split our train data as:\n>train and<br> \n>validation data","fcd1ba5b":"<a id=\"4.3\"><\/a>\n## 4.3 Max Pooling","3d73decb":"### Plotting loss and accuracy","9402cadd":"<a id=\"5.6\"><\/a>\n## 5.6 Fitting Data Augmented Model"}}