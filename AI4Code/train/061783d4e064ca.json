{"cell_type":{"34248b9d":"code","8d83065a":"code","deada1b2":"code","2c76f406":"code","791bcb1b":"code","d0a73b97":"code","9c419965":"code","7d90f205":"code","91409ec7":"code","57a217f8":"code","f5e97395":"code","e2a6d8aa":"code","2a8aeccb":"code","25c3a780":"code","2a42410c":"code","c5fb29fd":"markdown","bc34734b":"markdown","975175d9":"markdown","7f918ad7":"markdown","90e129cb":"markdown","457eadb6":"markdown","a9e4107f":"markdown","c1411cee":"markdown","626a726d":"markdown","6e4d05cb":"markdown","5c885692":"markdown","e5599832":"markdown","b75d022f":"markdown","7b1df35b":"markdown","e3a0ace4":"markdown","fdc34d73":"markdown","328378c6":"markdown","fa159389":"markdown","412acbfa":"markdown","0c2981cd":"markdown","adc6df28":"markdown","7a548dd2":"markdown","7643fde1":"markdown","ecff1b8d":"markdown","8e351146":"markdown"},"source":{"34248b9d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\nfrom matplotlib.pyplot import imshow # For showing some samples from the data\nfrom matplotlib.pyplot import axis\nfrom matplotlib.pyplot import show\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8d83065a":"y = np.load('\/kaggle\/input\/sign-language-digits-dataset\/Sign-language-digits-dataset\/Y.npy')\nx = np.load('\/kaggle\/input\/sign-language-digits-dataset\/Sign-language-digits-dataset\/X.npy')","deada1b2":"print(\"Shape of x dataset is: \",x.shape)\nprint(\"Shape of y dataset is:\",y.shape)","2c76f406":"print(x[0])\nprint(\"--------------------------------------------------------------------------\")\nprint(y[0])","791bcb1b":"#Slicing one sample\nrandom_sample = x[0]\nimshow(random_sample)\naxis('off')\nshow()","d0a73b97":"#Slicing one sample\nrandom_sample = x[334]\nimshow(random_sample)\naxis('off')\nshow()","9c419965":"#Slicing one sample\nrandom_sample = x[765]\nimshow(random_sample)\naxis('off')\nshow()","7d90f205":"from keras.models import Sequential\nfrom keras.layers import Dense,Dropout,Conv2D,MaxPool2D,Flatten\nfrom keras.optimizers import Adam","91409ec7":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.2,random_state=1) # Train Test Splitting","57a217f8":"x_train = x_train.reshape((-1,64,64,1))\nx_test = x_test.reshape((-1,64,64,1))\nprint(\"Shape of x_train is now: \",x_train.shape)\nprint(\"Shape of x_test is now: \",x_test.shape)","f5e97395":"model = Sequential()\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding=\"Same\",activation=\"relu\",input_shape=(64,64,1))) #Convolutional Operator\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding=\"Same\",activation=\"relu\")) #Convolutional Operator\n\nmodel.add(MaxPool2D(pool_size=(5,5))) # Max Pool\nmodel.add(Dropout(0.25)) # Dropout\n\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding=\"Same\",activation=\"relu\"))\nmodel.add(Conv2D(filters=32,kernel_size=(5,5),padding=\"Same\",activation=\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(5,5)))\nmodel.add(Dropout(0.25))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(256,activation=\"relu\"))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(10,activation=\"softmax\"))\n","e2a6d8aa":"# There are hyperparameters\noptimizer = Adam(lr=0.001,beta_1=0.9,beta_2=0.999)\n\nmodel.compile(optimizer=optimizer,loss=\"categorical_crossentropy\",metrics=[\"accuracy\"])","2a8aeccb":"model.fit(x_train,\n          y_train,\n          batch_size=30,\n          epochs=25)","25c3a780":"from sklearn.metrics import accuracy_score\nfrom keras.utils.np_utils import to_categorical\n\ny_head = model.predict_classes(x_test)\ny_head = to_categorical(y_head,num_classes=10)\nprint(y_head.shape)\nprint(y_test.shape)","2a42410c":"print(\"Accuracy of model is \",accuracy_score(y_test,y_head))","c5fb29fd":"* And now I will fit the model using our train arrays.","bc34734b":"* And I think it is 0 as well. It is hard to understand.","975175d9":"## Building The Frame Of Model\nIn this section I will build our model. Let's start.","7f918ad7":"* Good news, our values are already normalized, I guess we won't make any process to the data. :D\n* Our label is 0 for this sample.","90e129cb":"### Some Samples From The Datas\n\nYeah, let's check some images from the data. In order to do this I will use matplotlib library's imshow function. Let me show how to do that.","457eadb6":"* Our images are 64x64. And there are 2062 samples in our dataset. Great number for introducing\n* Our labels are already one hot encoded. This dataset is very useful for beginners.","a9e4107f":"# Results\nIn this section I will evaulate our model using accuracy score and confusion matrix.","c1411cee":"### Checking Some Values From The Datas","626a726d":"## Compiling And Fitting Model\nIn this section I will compile and fit the model","6e4d05cb":"## Evaulating Accuracy","5c885692":"### Checking Shapes of The Datas","e5599832":"## Train Test Splittig\n* I will split datas into two, train and test. I will use %80 of the data for training and %20 of the data for testing.\n","b75d022f":"# Modeling\n\nFinally we came our main stage. In this section I will train a CNN model using keras library. I will start with importing libraries that I need","7b1df35b":"# Conclusion\n\nThanks for your attention, if you want to check more exercises and beginner kernels, you can check my profile, because I am a beginner as well. If you have any questions in your mind, you can ask me but I recommend google it because english is not my native language, and when I try to explain anything in english, I will have to make smaller and simplier the answer of question.","e3a0ace4":"# 1. Importing Libraries and Data\nThis kernel will be so simple, so  I won't add so many general libraries. And I won't import deep learning libraries in this section, I will import them when I need them.","fdc34d73":"* And now I am going to import np files. In kaggle, numpy files are rare. In order to import numpy files, we use np.load() function. Our data types are numpy arrays. \n","328378c6":"* I've did it. Because keras wants 3D arrays. Let's take a look at the name of dimensions\n\n\n\n* Dimension 1 : X Axis Of Image\n* Dimension 2 : Y Axis Of Image\n* Dimension 3 : Number of Colors In Scale (In grayscale its 1)","fa159389":"* Our score is %97. Not bad but it could be better if we increase the number of layers and epochs\n* Why I convert y_head using to_categorical(one hot encoding):\n    * Because, our y_train dataset is not contains label. It contains one hot encoded labels.","412acbfa":"# Introduction\nHello people, welcome to my kernel! Nowadays, I've learnt the basics of CNN. I've joined the MNIST competetion, and now I am going to make a similar exercise. In this kernel I will train a CNN model using Keras\n\n# Content\n1. Importing Libraries and Data\n    * Importing Libraries\n    * Importing Datas\n1. Data Overview\n    * Checking Shapes of Datas\n    * Checking Count of Datas\n    * Checking Some Values from Datas\n    * Some Samples from Datas\n1. Modeling\n    * Importing Libraries\n    * Train Test Splitting\n    * Deciding The Layers of Model\n    * Building Frame Of The Model\n    * Compiling And Fitting Model\n1. Results\n    * Evaulating Accuracies\n1. Conclusion","0c2981cd":"# 2. Data Overview\nIn this section, we will examine the dataset. This part won't be long because there is not much things in the dataset that we can examine ;)\n\nWe will start with examine the shape of the dataset.","adc6df28":"* And I think it is three.","7a548dd2":"## Deciding The Layers Of The Model\n\nIn this section I will decide how many and how layers that I will use in my model. Let's check my plan\n\n\n\n1. Conv2D Layer\n1. Conv2D Layer\n1. MaxPool2D Layer\n1. Dropout Layer\n1. Conv2D Layer\n1. Conv2D Layer\n1. MaxPool2D Layer\n1. Dropout Layer\n1. Flatten Layer\n1. Dense Layer\n1. Dropout Layer\n1. Dense Layer\n1. Dropout Layer\n1. Dense Layer\n\nIf you need more simple information about what the fuck is this layers, you can check my other kernel for Digit Recognizer Competetion. \nhttps:\/\/www.kaggle.com\/mehmetlaudatekman\/mnist-dataset-cnn-with-keras#Preprocessing","7643fde1":"* Yes, it is 0 as we know from the dataset.","ecff1b8d":"## Importing Libraries","8e351146":"* And now I will rehsape the dataset for keras. "}}