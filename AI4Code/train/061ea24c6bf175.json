{"cell_type":{"7544e7b1":"code","ee2731b5":"code","aaa3a15a":"code","968a76f2":"code","b45fa9e2":"code","efbbf220":"code","88133fa9":"code","56c39d0d":"code","1b0234a5":"code","1354ac4d":"markdown","3c749ac7":"markdown","25d17ea5":"markdown","bb26c594":"markdown","f0856ee6":"markdown","15c26a87":"markdown","987a8703":"markdown","2cb983c6":"markdown","e72a6229":"markdown","827cd980":"markdown"},"source":{"7544e7b1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        os.path.join(dirname, filename)\n\n# Any results you write to the current directory are saved as output.","ee2731b5":"mi = pd.read_csv(\"\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/ETFs\/spy.us.txt\") # Market index\naapl = pd.read_csv(\"\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/aapl.us.txt\") # Apple\ngoogl = pd.read_csv(\"\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/googl.us.txt\") # Alphabet\nfb = pd.read_csv(\"\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/fb.us.txt\") # Facebook\namzn = pd.read_csv(\"\/kaggle\/input\/price-volume-data-for-all-us-stocks-etfs\/Stocks\/amzn.us.txt\") # Amazon","aaa3a15a":"aapl['aapl'] = aapl.Close.pct_change()\namzn['amzn'] = amzn.Close.pct_change()\nfb['fb'] = fb.Close.pct_change()\ngoogl['googl'] = googl.Close.pct_change()\nmi['mi'] = mi.Close.pct_change()","968a76f2":"# New DataFrame by using the market index (mi) dates and returns as a starting point\nreturns=mi[['Date','mi']]#\n\n# Merge returns to returns DataFrame\nreturns = returns.merge(aapl[['Date','aapl']], left_on='Date', right_on='Date').set_index('Date')\nreturns = returns.merge(amzn[['Date','amzn']], left_on='Date', right_on='Date').set_index('Date')\nreturns = returns.merge(fb[['Date','fb']], left_on='Date', right_on='Date').set_index('Date')\nreturns = returns.merge(googl[['Date','googl']], left_on='Date', right_on='Date').set_index('Date')\n\n# Create the big tech portfolio\nreturns[\"bt_portfolio\"] = 1\/4*(returns.aapl + returns.amzn + returns.fb + returns.googl)\n\n# Clean the DataFrame\nreturns = returns.dropna()\n\n# Display first five rows.\nreturns.head()","b45fa9e2":"(returns+1).cumprod().plot()","efbbf220":"# daily risk free rate.\nrf = (1.02**(1\/360))-1 \n\n# New dataframe to stock_data.\nstock_data = pd.DataFrame(columns=['security','e_returns','vol', 'sr' ]).set_index('security')\n\n# Calculate volatilities, expected returns and sharpe ratios.\nfor security in returns.columns:\n    vol = returns[security].std() # volatility\n    e_r = returns[security].mean() # excpected returns\n    sr = (e_r-rf)\/vol # Sharpe ratio\n    stock_data.loc[security]= [e_r, vol,sr]\n    \nstock_data.shape","88133fa9":"stock_data[\"sec_type\"]=[\"portfolio\",\"stock\",\"stock\",\"stock\",\"stock\",\"portfolio\"]\nstock_data.groupby(\"sec_type\").size().plot.pie()","56c39d0d":"stock_data.groupby(\"sec_type\").vol.mean().sort_values().plot.barh()","1b0234a5":"stock_data.sr.sort_values().plot.barh()","1354ac4d":"## 3. Merge all returns to one \"returns\" DataFrame\n1. Create a new DataFrame \"returns\" and use the market index (mi) dates and returns as a starting point.\n2. Merge every stock to  \"returns\" DataFrame by using .merge() method. Remember to assign the \"returns\" DataFrame everytime you merge since the method will not change the calling object.\n3. Create a big tech portfolio  by calculat\u00edng a equally balanced portfolio by taking the average of return for each trading day. Add the portfolio to DataFrame as a \"bt_portfolio\" column.\n4. Use .dropa() method to clean the DataFrame from na values.\n5. Use .head() method to display the 5 first rows of the DataFrame.","3c749ac7":"## 2. Calculate the returns for each stock.\nWe only need the return data from previous datasets. In order to calculate security returns we only need to select the \u201cClose\u201d price column and calculate the percentage change from previous dates to each date (change_t (%) = r_t\/r_(t-1), where r refers to return and t to date) in the data.\n1. Create new column for each stock by naming the column as a name of the stock. This naming is helpful while moving the columns to other dataframes.\n2. Use .pct_change() method to calculate the percentage change for each date of each stock. This gives the values of daily returns for each stock.","25d17ea5":"# Pandas tutorial for finance: Has investing in Big Tech securities been a good idea between 2012 - 2017? \n\n#### In this notebook I examine how good investments big tech securities have been between 2012 and 2017. At the same time I will explain and show how to use pandas to examine this question.\n\n### Method:\n* To answer the problem I compare risk adjusted returns of Big Tech firm stocks, big tech portfolio and market index to each other.\n* Big Tech firms or the portfolio are better investments if they are able to provide higher risk-adjusted returns than the market portfolio.\n\n### Secondary questions: \n1. Which security has provided best returns over the period?\n2. Are portfolios less volatile than stocks due to decentralization??\n\n### Definitions and limitations:\n* In this notebook Big Tech refers to Apple, Amazon, Alphabet and Facebook.\n* I use SPY-etf as a market portfolio.\n* While creating portfolios I assume that investors can rebalance the portfolio after every trading day.\n* I assume the historical and current risk free rate is 2% p.a.","bb26c594":"### **Findings:**\n* Between 2012 and 2017 Amazon has been the most successful stock.\n* The market index has provided the lowest returns in this context.\n\n## 5. Calculate volatility and sharpe ratio for each stock.\nIn order to observe risk adjusted returns we need to calculate sharpe ratios for each stock. (more information about Sharpe Ratio: https:\/\/www.investopedia.com\/terms\/s\/sharperatio.asp) \n\nSharpe Ratio = (excpected return - risk free rate)\/volatility.\n\n* Excpected return = arithmetic average of returns.\n* Volatility = standard deviation of returns.\n* risk free return = 2% per annum.\n\n\n1. Calculate daily risk free rate rf.\n2. Create new stock_data DataFrame with columns \"security\", \"e_returns\", \"vol\", \"sr\" by using pd.DataFrame() method. Then set \"security\" to index by using .set_index() method.\n3. Use for loop to calculate volatility, expected return and sharpe ratio for each stock.\n4. Calculate volatility by using .std() method for each return column.\n5. Calculate expected returns by using .mean() method.\n6. Calculate sharpe ratio.\n7. Add each dataset to DataFrame as a row by using .loc[] method.\n8. Check the the dimensionality of the DataFrame (# of rows, #  of columns) by using .shape. Note: this does not include the index of the DataFrame","f0856ee6":"## 6. Set stock_type column to underline the difference between portfolios and stocks.\n1. Add \"sec_type\" column to stock_data DataFrame. Use the variable \"portfolio\" when referring to portfolios and \"stock\" when referring to stocks.\n2. Display the amount of portfolios and stocks by using .groupby().size() method to count the amount of the different sec_types and .plot.pie() method to illustrate the structure of different securities in the comparison.","15c26a87":"### Findings:\n* The Big Tech portfolio has the best Sharpe Ratio.\n* Single stocks provided lower risk-adjusted returns than the portfolio.\n\n# Conclusion:\n* A portfolio constructed from Big Tech firms provided better returns than the market index.\n* Standalone big tech stocks have provided weaker risk-adjusted returns than the market portfolio. This can be explained by the high volatility of big tech stocks.\n* Decentralization plays a big role while investing in high risk (tech) stocks.\n* Investing in a Big Tech portfolio has been a good idea between 2012 and 2017.","987a8703":"## 1. Download DataFrame attributes.\n Download market index (SPY) and stock (AAPL, FB, AMZN and GOOGL) data.\n \n1. Load the data for each stock into separate dataframes by using .read_csv() method from  Pandas library. You can find the file paths from the previous cell by looking for each security**** tickers.","2cb983c6":"## 4. Illustrate the stock returns by calculating cumulative indices.\n1. Add 1 to each return value by writing \"(returns + 1)\" and use method .cumprod() to calculate the cumulative returns for each stock. The number must be added since .cumprod() multiplies column values together.\n2. Use .plot() method to display a chart of all returns\n\nNote: the results are displayed as indices (t_0 = 1)","e72a6229":"### Findings:\n* Stocks have greater volatility compared to portfolios. This is consistent with the theory of decentralization.\n\n## 8. Illustrate Sharpe Ratios as a graph.\n\nCreate a horizontal barchart to compare sharpe ratios. Sort values to ascending order.\n\n1. Use .sort_values() method to set sharpe ratios to ascending order.\n2. use plot.barh() to display horizontal barchart.","827cd980":"## 7. Illustrate daily volatility as a graph.\n\nCreate a horizontal barchart to compare daily volatilities. Sort values to descending order.\n\n1. Use .groupby() method to organise data according to \"sec_type\" values.\n2. Use .vol to get only volatility columns for each stock_type groups.\n3. Use .mean() to calculate the arithmetic average volatility for each group.\n4. Use .sort_values() to sort averages to ascending order.\n3. use plot.barh() to display horizontal barchart"}}