{"cell_type":{"4e998842":"code","0eec6f4d":"code","8a094d89":"code","a94d0e0e":"code","2897ea99":"code","d2ee8e2a":"code","63214a3f":"code","576be0aa":"code","5775286e":"code","a24e5d66":"code","049a3b71":"code","d1696f61":"code","92fcfa9f":"code","213df70b":"code","bfd92255":"code","43c71e68":"code","8db1058c":"code","171974f1":"code","5aaa6691":"code","6d931bff":"code","ec8d1fa5":"code","1deb3c3b":"code","ed9c107a":"code","da0ec368":"code","d0fb70da":"code","405bef41":"code","097d5955":"code","6748a538":"code","047f16a3":"code","0133e569":"code","b9bc5977":"code","85d6fbab":"code","c23d3cb3":"code","dc7dd767":"code","9e29699f":"code","1d400388":"code","ed9b413b":"code","d180c7f6":"code","15c4a2f0":"code","7c210931":"code","9ab41c15":"code","9f954836":"code","46bee0bb":"code","6b76f04d":"code","addbd558":"code","086f0570":"code","8711f965":"code","d8bdf603":"code","dd485379":"code","7d024982":"code","c918a423":"code","d8183cad":"code","ee57d4af":"code","9e048aae":"code","a333aca8":"code","a4fc6bb9":"code","7fc1a73c":"code","520f33ed":"code","e0f13786":"code","e1d03d8e":"code","80947d2d":"markdown","5ed8b471":"markdown","8b2badea":"markdown","5b92ccf6":"markdown","d2f34dc2":"markdown","a6b55584":"markdown","6ec86eea":"markdown","bbd70930":"markdown","53d95c5f":"markdown","ec5d77dd":"markdown","54cb4136":"markdown","ebea3009":"markdown","c8476cbf":"markdown","7d361082":"markdown","1d2ed0d9":"markdown","2dbd0990":"markdown","94a33bb0":"markdown","ef289770":"markdown","ddddbefa":"markdown","3e8ade18":"markdown","f9ee24e6":"markdown","26cf23bb":"markdown","04023abb":"markdown","0277d59f":"markdown","0f5cdfc1":"markdown","e950074e":"markdown","316fbee1":"markdown","c2290f75":"markdown","798b3597":"markdown","eadf5c9d":"markdown","8f22bbe8":"markdown","c052b09d":"markdown","400b3d94":"markdown","9e95e62f":"markdown","581586e3":"markdown","0d717d08":"markdown","d835ddec":"markdown","81d4728d":"markdown","0d4e5aba":"markdown","f1ef7ceb":"markdown","c3e8da77":"markdown","83e7e4f2":"markdown","68103eae":"markdown","4b02af3f":"markdown"},"source":{"4e998842":"import numpy as np\nimport scipy as sp\nimport pandas as pd\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(action='once')\n\n%matplotlib inline\nmpl.style.use('ggplot')\nsns.set(style='whitegrid')","0eec6f4d":"transactions = pd.read_csv(r\"C:\\Users\\NANA-KHUSHI\\Desktop\\nands\\python\\Credit Card Fraud detection\\creditcard.csv\")\ntransactions.shape","8a094d89":"transactions.info()","a94d0e0e":"transactions.isnull().any().any()","2897ea99":"transactions.head()","d2ee8e2a":"transactions['Class'].value_counts()","63214a3f":"transactions['Class'].value_counts(normalize = True)","576be0aa":"X= transactions.drop(labels='Class',axis = 1) #Features\ny=transactions.loc[:,'Class'] #Response\n#del transactions #Delete the original data","5775286e":"from sklearn.model_selection import train_test_split","a24e5d66":"X_train , X_test, y_train, y_test = train_test_split(X , y , test_size=0.2 , random_state=1 , stratify = y)","049a3b71":"X_train.shape,X_test.shape","d1696f61":"#to flag off warnings\nX_train.is_copy = False\nX_test.is_copy = False","92fcfa9f":"X_train['Time'].describe()","213df70b":"#convert seconds to hours for easy of calculations\n\nX_train.loc[:,'Time'] = X_train.Time \/ 3600\nX_test.loc[:,'Time'] = X_test.Time \/ 3600","bfd92255":"# time of last transaction in days\nX_train['Time'].max() \/ 24","43c71e68":"#histogram of transition times. \nplt.figure(figsize=(12,8))\nsns.distplot(X_train['Time'],bins=50,color='green')\nplt.xlim([0,50])\nplt.xticks(np.arange(0,50,5))\nplt.xlabel('Time after 1st transaction(hr)')\nplt.ylabel('Count')\nplt.title('Transaction times')","8db1058c":"#Summary stats\nX_train['Amount'].describe()","171974f1":"plt.figure(figsize=(12,8))\nsns.distplot(X_train['Amount'],bins=300,color='g')\nplt.ylabel('Count')\nplt.title('Transaction Amounts')","5aaa6691":"# box plot as the histogram doesnot shoe the details properly.\nplt.figure(figsize=(12,8), dpi=80)\nsns.boxplot(X_train['Amount'])\nplt.title('Transaction Amounts')","6d931bff":"X_train['Amount'].skew()","ec8d1fa5":"X_train.loc[:,'Amount'] = X_train['Amount']+ 1e-9\n# Shift all amounts by 1e-9","1deb3c3b":"from scipy import stats\nX_train.loc[:,'Amount'], maxlog, (min_ci, max_ci) = sp.stats.boxcox(X_train['Amount'], alpha=0.01)","ed9c107a":"X_train.dropna()","da0ec368":"#plotting newly transformed accounts\nplt.figure(figsize=(12,8))\nsns.distplot(X_train['Amount'],color='g')\nplt.xlabel('Transformed Amount')\nplt.ylabel('Count')\nplt.title('Transaction Amounts (Box-Cox Transformed)')\n","d0fb70da":"X_train['Amount'].describe()","405bef41":"X_train['Amount'].skew()","097d5955":"X_test.loc[:,'Amount'] = X_test['Amount'] + 1e-9 # Shift all amounts by 1e-9\nX_test.loc[:,'Amount'] = sp.stats.boxcox(X_test['Amount'], lmbda=maxlog)\n","6748a538":"#Time vs Amount\nsns.jointplot(X_train['Time'].apply(lambda x: x % 24), X_train['Amount'], kind='hex', stat_func=None, size=12, xlim=(0,24), ylim=(-7.5,14)).set_axis_labels('Time of Day (hr)','Transformed Amount')\n","047f16a3":"pca_vars = ['V%i' % k for k in range(1,29)]","0133e569":"X_train[pca_vars].describe()","b9bc5977":"plt.figure(figsize=(12,8))\nsns.barplot(x=pca_vars, y=X_train[pca_vars].mean(), color='green')\nplt.xlabel('Column')\nplt.ylabel('Mean')\nplt.title('V1-V28 Means')","85d6fbab":"plt.figure(figsize=(12,8))\nsns.barplot(x=pca_vars, y=X_train[pca_vars].std(), color='green')\nplt.xlabel('Column')\nplt.ylabel('Mean')\nplt.title('V1-V28 Means')","c23d3cb3":"plt.figure(figsize=(12,8))\nsns.barplot(x=pca_vars, y=X_train[pca_vars].skew(), color='green')\nplt.xlabel('Column')\nplt.ylabel('Mean')\nplt.title('V1-V28 Means')","dc7dd767":"plt.figure(figsize=(12,8))\nsns.distplot(X_train['V8'], bins=100)\nplt.ylabel('Count')\nplt.title('V8')","9e29699f":"plt.figure(figsize=(12,8), dpi=80)\nsns.boxplot(X_train['V8'])\nplt.title('V8')","1d400388":"plt.figure(figsize=(12,8))\nplt.yscale('log')\nsns.barplot(x=pca_vars, y=X_train[pca_vars].kurtosis(), color='green')\nplt.xlabel('Column')\nplt.ylabel('Kurtosis')\nplt.title('V1-V28 Kurtoses')","ed9b413b":"plt.figure(figsize=(12,8))\nsns.barplot(x=pca_vars, y=X_train[pca_vars].median(), color='green')\nplt.xlabel('Column')\nplt.ylabel('Mean')\nplt.title('V1-V28 Means')","d180c7f6":"plt.figure(figsize=(12,8))\nsns.barplot(x=pca_vars, y=X_train[pca_vars].quantile(0.75) - X_train[pca_vars].quantile(0.25), color='green')\nplt.xlabel('Column')\nplt.ylabel('IQR')\nplt.title('V1-V28 IQRs')","15c4a2f0":"from sklearn.feature_selection import mutual_info_classif","7c210931":"data=mutual_info_classif(X_train, y_train, discrete_features=False, random_state=1)\n","9ab41c15":"mutual_infos = pd.Series(data,index= X_train.columns)","9f954836":"mutual_infos.sort_values(ascending=False)","46bee0bb":"from sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import SGDClassifier","6b76f04d":"pipeline_sgd = Pipeline([\n    ('scaler', StandardScaler(copy=False)),\n    ('model', SGDClassifier(max_iter=1000, tol=1e-3, random_state=1, warm_start=True))\n])","addbd558":"param_grid_sgd = [{\n    'model__loss': ['log'],\n    'model__penalty': ['l1', 'l2'],\n    'model__alpha': np.logspace(start=-3, stop=3, num=20)\n}, {\n    'model__loss': ['hinge'],\n    'model__alpha': np.logspace(start=-3, stop=3, num=20),\n    'model__class_weight': [None, 'balanced']\n}]","086f0570":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import make_scorer, matthews_corrcoef","8711f965":"\nMCC_scorer = make_scorer(matthews_corrcoef)\ngrid_sgd = GridSearchCV(estimator=pipeline_sgd, param_grid=param_grid_sgd, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)","d8bdf603":"import warnings\nwith warnings.catch_warnings(): # Suppress warnings from the matthews_corrcoef function\n    warnings.simplefilter(\"ignore\")\n    grid_sgd.fit(X_train, y_train)","dd485379":"grid_sgd.best_score_","7d024982":"grid_sgd.best_params_","c918a423":"from sklearn.ensemble import RandomForestClassifier","d8183cad":"pipeline_rf = Pipeline([\n    ('model', RandomForestClassifier(n_jobs=-1, random_state=1))\n])\n","ee57d4af":"param_grid_rf = {'model__n_estimators': [75]}","9e048aae":"grid_rf = GridSearchCV(estimator=pipeline_rf, param_grid=param_grid_rf, scoring=MCC_scorer, n_jobs=-1, pre_dispatch='2*n_jobs', cv=5, verbose=1, return_train_score=False)","a333aca8":"grid_rf.fit(X_train, y_train)","a4fc6bb9":"\ngrid_rf.best_score_","7fc1a73c":"\ngrid_rf.best_params_","520f33ed":"from sklearn.metrics import confusion_matrix, classification_report, matthews_corrcoef, cohen_kappa_score, accuracy_score, average_precision_score, roc_auc_score","e0f13786":"def classification_eval(estimator,X_test,y_test):\n    y_pred=estimator.predict(X_test)\n    dec = np.int64(np.ceil(np.log10(len(y_test))))\n    \n    print(\"Confusion Matrix\")\n    print(confusion_matrix(y_test,y_pred),'\\n')\n    \n    print('Classification report')\n    print(classification_report(y_test, y_pred, digits=dec))\n    \n    print(\"Scalar Metrics\")\n    format_str = '%%13s = %%.%if' % dec\n    print(format_str % ('MCC', matthews_corrcoef(y_test, y_pred)))\n    \n    if y_test.nunique() <= 2: # Additional metrics for binary classification\n        try:\n            y_score = estimator.predict_proba(X_test)[:,1]\n        except:\n            y_score = estimator.decision_function(X_test)\n        print(format_str % ('AUPRC', average_precision_score(y_test, y_score)))\n        print(format_str % ('AUROC', roc_auc_score(y_test, y_score)))\n    print(format_str % (\"Cohen's kappa\", cohen_kappa_score(y_test, y_pred)))\n    print(format_str % ('Accuracy', accuracy_score(y_test, y_pred)))","e1d03d8e":"classification_eval(grid_rf, X_test, y_test)","80947d2d":" The type of linear classifier is chosen with the loss hyperparameter. For a linear SVC we set loss = 'hinge', and for logistic regression we set loss = 'log'.\n\nSet the hyperparameter grids to search over, one grid for the linear SVC and one for logistic regression:","5ed8b471":"All of V1-V28 have approximately zero mean. Now plot the standard deviations:","8b2badea":"\nPerform the grid search:","5b92ccf6":"Looking at the details, it can be observed that the amonunts appear to be right skewed. To verify this, lets construct a histogram.","d2f34dc2":"\nThe five most correlated variables with Class are, in decreasing order, V17, V14, V10, V12, and V11.","a6b55584":"Thus, it can be observed that there are 2 lulls during the nighttime on each day.","6ec86eea":"### Random Forest","bbd70930":"\nThe medians are also roughly zero. Next let's look at the interquartile ranges (IQR)*:","53d95c5f":"\nThe histogram doesn't show us outliers. Let's try a boxplot:","ec5d77dd":"#### Mutual Information between Fraud and the Predictors","54cb4136":"Mean cross-validated MCC score of the best estimator found:","ebea3009":"### Test Set Evaluation of the Best Model","c8476cbf":"This is a pretty good MCC score---random guessing has a score of 0, and a perfect predictor has a score of 1. Now check the best hyperparameters found in the grid search:","7d361082":"So the linear SVC performed better than logistic regression, and with a high level of regularization ($\\alpha\\approx 483$).","1d2ed0d9":"We see that 0.17% of the transactions turn out to be fraudulent.","2dbd0990":"Lets remove the skewness and convert the data into a normal distribution.","94a33bb0":"The grid search, implemented by GridSearchCV, uses StratifiedKFold with 5 folds for the train\/validation splits. We'll use matthews_corrcoef (the Matthews correlation coefficient, MCC) as our scoring metric.","ef289770":"\nAccording to the MCC, the random forest performed better on the test set than on the training set. This is probably due to the refit model being trained on the entire training data set, and not on the smaller CV folds.","ddddbefa":"We've learned that many of the PCA variables are heavy-tailed. The large numbers of outliers in V1-V28 motivates us to consider robust descriptive statistics. Let's plot the medians:","3e8ade18":"\nThe PCA variables have roughly unit variance, but as low as ~0.3 and as high as ~1.9. Plot the skewnesses next:","f9ee24e6":"\nThe boxplot is also hard to read due to the large number of outliers, which indicates high kurtosis in V8. This motivates us to plot the kurtoses of the PCA variables. The kurtosis method employed in pandas is Fisher\u2019s definition, for which the standard normal distribution has kurtosis 0.\n\nNote the log scale on the y-axis in the plot below:","26cf23bb":"There are no outliers in the left and right side. Thus the amounts were roght skewed. We can check for the skewness to be sure.","04023abb":"### Importing the required files and libraries.","0277d59f":"Let's compare the descriptive stats of the PCA variables V1-V28.","0f5cdfc1":"Check for any missing data in CSV file.","e950074e":"### Logistic Regression","316fbee1":"the fraudulent transactions occur at every 2 days","c2290f75":"I will use a test size of 20%. I will also stratify the split on the response variable, which is very important to do because there are so few fraudulent transactions.","798b3597":"The random forest performed much better than the linear SVC","eadf5c9d":"## Conclusion\n\nWe were able to accurately identify fraudulent credit card transactions using a random forest model. We found that the five variables most correlated with fraud are, in decreasing order, V17, V14, V10, V12, and V11. Only a few preprocessing steps were necessary before constructing predictive models:\n\n1.Split the data using a random, stratified train\/test split with a test size of 20%\n\n2.Box-Cox power transform of the transaction amounts to remove skewness in the data\n\n3.Mean and variance standardization of all features as part of a machine learning pipeline\n\nWe used the Matthews correlation coefficient (MCC) to compare the performance of different models. In cross validation, the best linear model (logistic regression, linear SVC) achieved a cross-validated MCC score of 0.807, and a random forest achieved a cross-validated MCC score of 0.856. We therefore chose the random forest as the better model, which obtained an MCC of 0.869 on the test set.\n\nTo improve a chosen model, we searched over a grid of hyperparameters and compared performance with cross-validation. It may be possible to improve the random forest model by further tweaking the hyperparameters, given additional time and\/or computational power.","8f22bbe8":"Divide the dataset into training and testing sets.","c052b09d":"Display the frequency of fraudulent transactions. 1 stands for fradulent and 0 for true.","400b3d94":"\nThe maximum likelihood estimate of $\\lambda$ in the Box-Cox transform:","9e95e62f":"### Data Analysis","581586e3":"### Train\/Test Split","0d717d08":"\nSo our power transform removed most of the skewness in the Amount variable. Now we need to compute the Box-Cox transform on the test data amounts as well, using the $\\lambda$ value estimated on the training data.","d835ddec":"Mutual information of 0 indicates no dependence, and higher values indicate higher dependence. According to the sklearn User Guide, \"mutual information methods can capture any kind of statistical dependency, but being nonparametric, they require more samples for accurate estimation.\" We have 227,845 training samples, so mutual information should work well. Because the target variable is discrete, we use mutual_info_classif (as opposed to mutual_info_regression for a continuous target).","81d4728d":"\nThe random forest takes much longer to train on this fairly large dataset, so we don't actually do a hyperparameter grid search, only specifiying the number of estimators. We'll leave the grid search implemented in case we decide to try different hyperparameter values in the future.","0d4e5aba":"Full Table descriptive stats","f1ef7ceb":"Performing Box-Cox Transform","c3e8da77":"\nA few of the PCA variables are significantly skewed. Let's plot a histogram of one of the particularly skewed variables, V8, to see the distribution in detail.","83e7e4f2":"The calculated mutual informations of each variable with Class, in descending order:","68103eae":"Importing the dataset into variable transactions and displaying its metadata.","4b02af3f":"\nThe transaction amounts appear to be similarly distributed throughout the daytime hours. However, in the earliest hours of the day, around 5-7 AM, amounts around 2.5 are the most common (recall this is a Box-Cox transformed value). Perhaps everyone's buying their morning coffee?"}}