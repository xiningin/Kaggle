{"cell_type":{"08869afe":"code","23259b99":"code","692db6a6":"code","ae4d20d9":"code","08d76a23":"code","9ce56a18":"code","a73d000c":"code","fb34c9d9":"code","7b5cf943":"code","086dadbe":"code","1d44f5ef":"code","ed3f4f62":"code","55cb4b59":"code","83803317":"code","c7acafce":"markdown","a01af70a":"markdown","3e19005e":"markdown","40ff52db":"markdown","74189a07":"markdown","53c2f32a":"markdown","78ffdb13":"markdown"},"source":{"08869afe":"# General Libs\nfrom tensorflow import keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.models import Sequential, Model\nfrom tensorflow.keras.layers import GlobalAveragePooling2D, Dense, BatchNormalization, Dropout, Flatten, Conv2D, MaxPooling2D, LeakyReLU\nfrom tensorflow.keras.optimizers import Adam\n\nfrom tensorflow.keras.applications import MobileNetV2\nfrom tensorflow.keras.applications.mobilenet_v2 import preprocess_input\n\nimport numpy as np\nimport random\nimport matplotlib.pyplot as plt\n%matplotlib inline","23259b99":"im_shape = (250,250)\n\nTRAINING_DIR = '..\/input\/ds_frutas_am\/train'\nTEST_DIR = '..\/input\/ds_frutas_am\/test'\n\nseed = 10\n\nBATCH_SIZE = 12","692db6a6":"#Using keras ImageGenerator and flow_from_directoty\n\n# Subdivision in test\/validation\ndata_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)\nval_data_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)","ae4d20d9":"# If you want data augmentation, uncomment and run this cell\ndata_generator = ImageDataGenerator(\n    rescale=1.\/255,\n    validation_split=0.2,\n    rotation_range=30,\n    width_shift_range=0.25,\n    height_shift_range=0.25,\n#     brightness_range=(0.5,0.95),\n    shear_range=0.4,\n    zoom_range=0.1,\n    horizontal_flip=True,\n    vertical_flip=True,\n    fill_mode='reflect',\n#     preprocessing_function=preprocess_input\n)\n\nval_data_generator = ImageDataGenerator(rescale=1.\/255, validation_split=0.2)","08d76a23":"# Generator para parte train\ntrain_generator = data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=True, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"training\")\n# Generator para parte valida\u00e7\u00e3o\nvalidation_generator = val_data_generator.flow_from_directory(TRAINING_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE, subset=\"validation\")\n\n# Generator para dataset de teste\ntest_generator = ImageDataGenerator(rescale=1.\/255)\ntest_generator = test_generator.flow_from_directory(TEST_DIR, target_size=im_shape, shuffle=False, seed=seed,\n                                                     class_mode='categorical', batch_size=BATCH_SIZE)\n\nnb_train_samples = train_generator.samples\nnb_validation_samples = validation_generator.samples\nnb_test_samples = test_generator.samples\nclasses = list(train_generator.class_indices.keys())\nprint('Classes: '+str(classes))\nnum_classes  = len(classes)\n","9ce56a18":"# Visualizing some examples\nplt.figure(figsize=(15,15))\nfor i in range(9):\n    #gera subfigures\n    plt.subplot(330 + 1 + i)\n    batch = train_generator.next()[0]*255\n    image = batch[0].astype('uint8')\n    plt.imshow(image)\nplt.show()","a73d000c":"base_model = MobileNetV2(\n    include_top=False,\n    weights=\"imagenet\",\n    input_tensor=None,\n    input_shape=(im_shape[0],im_shape[1],3),\n    pooling=None,\n    classes=6\n)\n\nx = base_model.output\nx = Flatten()(x)\nx = Dense(256, activation='relu')(x)\nx = Dropout(0.2)(x)\n# x = Dense(256, activation='relu')(x)\n# x = Dropout(0.2)(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.2)(x)\nx = Dense(128, activation='relu')(x)\nx = Dropout(0.2)(x)\n# x = Dense(64, activation='relu')(x)\n# x = Dropout(0.2)(x)\n# x = LeakyReLU()(x)\npredictions = Dense(num_classes, activation='softmax')(x)\n\nmodel = Model(inputs=base_model.input, outputs=predictions)\n\nfor layer in base_model.layers:\n    layer.trainable=False\n\n# Compila o modelo\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Adam(),\n              metrics=['accuracy'])","fb34c9d9":"epochs = 80\n\n#Callback to save the best model\ncallbacks_list = [\n    keras.callbacks.ModelCheckpoint(\n        filepath='model.h5',\n        monitor='val_loss', save_best_only=True, verbose=1),\n    keras.callbacks.EarlyStopping(monitor='val_loss', patience=15,verbose=1)\n]\n\n#Training\nhistory = model.fit(\n        train_generator,\n        steps_per_epoch=nb_train_samples \/\/ BATCH_SIZE,\n        epochs=epochs,\n        callbacks = callbacks_list,\n        validation_data=validation_generator,\n        verbose = 1,\n        validation_steps=nb_validation_samples \/\/ BATCH_SIZE)","7b5cf943":"# Training curves\nimport matplotlib.pyplot as plt\n\nhistory_dict = history.history\nloss_values = history_dict['loss']\nval_loss_values = history_dict['val_loss']\n\nepochs_x = range(1, len(loss_values) + 1)\nplt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nplt.plot(epochs_x, loss_values, 'bo', label='Training loss')\nplt.plot(epochs_x, val_loss_values, 'b', label='Validation loss')\nplt.title('Training and validation Loss and Accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.subplot(2,1,2)\nacc_values = history_dict['accuracy']\nval_acc_values = history_dict['val_accuracy']\nplt.plot(epochs_x, acc_values, 'bo', label='Training acc')\nplt.plot(epochs_x, val_acc_values, 'b', label='Validation acc')\n#plt.title('Training and validation accuracy')\nplt.xlabel('Epochs')\nplt.ylabel('Acc')\nplt.legend()\nplt.show()","086dadbe":"# Load the best saved model\n# from tensorflow.keras.models import load_model\n\n# model = load_model('model.h5')","1d44f5ef":"# Using the validation dataset\nscore = model.evaluate_generator(validation_generator)\nprint('Val loss:', score[0])\nprint('Val accuracy:', score[1])","ed3f4f62":"# Using the test dataset\nscore = model.evaluate_generator(test_generator)\nprint('Test loss:', score[0])\nprint('Test accuracy:', score[1])","55cb4b59":"import itertools\n\n#Plot the confusion matrix. Set Normalize = True\/False\ndef plot_confusion_matrix(cm, classes, normalize=True, title='Confusion matrix', cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.figure(figsize=(10,10))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        cm = np.around(cm, decimals=2)\n        cm[np.isnan(cm)] = 0.0\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n","83803317":"# Some reports\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport numpy as np\n\n#On test dataset\nY_pred = model.predict_generator(test_generator)\ny_pred = np.argmax(Y_pred, axis=1)\ntarget_names = classes\n\n#Confution Matrix\ncm = confusion_matrix(test_generator.classes, y_pred)\nplot_confusion_matrix(cm, target_names, normalize=False, title='Confusion Matrix')\n\n#Classification Report\nprint('Classification Report')\nprint(classification_report(test_generator.classes, y_pred, target_names=target_names))","c7acafce":"## Exploratory Analysis\nLet's view some dataset samples.\n\nThis example uses keras ImageDataGenerator. This lib turns easier to read and use image classes from a subdirectoty structure.","a01af70a":"### Reading the dataset","3e19005e":"## Introduction\nThis kernel is a simple example of fruit classification with a simple CNN implemented with Keras model and tools. Click the blue \"Edit Notebook\" or \"Fork Notebook\" button at the top of this kernel to begin editing.","40ff52db":"## Creating a simple CNN Model","74189a07":"## General Libs","53c2f32a":"### Showing some examples","78ffdb13":"## Evaluating the model"}}