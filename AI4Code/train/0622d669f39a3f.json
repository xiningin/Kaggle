{"cell_type":{"1a86894f":"code","2ae92afc":"code","b3aff0ba":"code","ebc546eb":"code","1aef731c":"code","4c90b145":"code","c4a05aab":"code","367c5605":"code","5a739896":"code","f3394ccc":"code","a2d175e6":"code","6a780425":"code","07b5f1d5":"code","0471b251":"code","28ad1384":"code","b20eb522":"code","094745d1":"code","9c42341b":"code","5f61b1f1":"code","2c224f56":"code","44691dd2":"markdown","c998798a":"markdown","a8f19dd9":"markdown","65062c95":"markdown","6fcdf81b":"markdown","26b2fa32":"markdown","6ed4ae8d":"markdown","2f191d4c":"markdown","1e8dea9b":"markdown","6ddc102f":"markdown","d6403893":"markdown","0eb03e87":"markdown","04df7d51":"markdown","93e51a5d":"markdown","097bc7ae":"markdown","94e9c448":"markdown","d1c53f52":"markdown","b480b82f":"markdown"},"source":{"1a86894f":"import numpy as np\nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.model_selection import train_test_split\n\nfrom keras.utils.np_utils import to_categorical\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.layers import Dropout\nfrom keras.layers import Flatten\nfrom keras.layers import Conv2D\nfrom keras.layers import Convolution2D\nfrom keras.layers import MaxPooling2D\nfrom keras.layers import Activation\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.callbacks import ModelCheckpoint\n","2ae92afc":"train = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\n\ny_train = train['label']\nX_train = train.drop(labels = [\"label\"], axis = 1)\n\nprint(X_train.shape)\nprint(test.shape)\ntrain.head()\n","b3aff0ba":"print(np.where(pd.isnull(X_train)))\nprint(np.where(pd.isnull(y_train)))\nprint(np.where(pd.isnull(test)))\n\ncounts = y_train.value_counts()\nprint(counts)","ebc546eb":"plt.figure()\nsns.barplot(counts.index, counts.values)\nplt.title('Frequency of each digit class')\nplt.xlabel('Digits')\nplt.ylabel('Number of occurrences')\nplt.show()","1aef731c":"X_train = X_train.values.reshape(-1,28,28,1)\ntest = test.values.reshape(-1,28,28,1)","4c90b145":"# display the first four training images to gain an understanding\n# of the data\nfig, axis = plt.subplots(2,2)\naxis[0,0].imshow(X_train[0,:,:,0], cmap = plt.get_cmap('gray'))\n# axis[0,0].set_title(\"First Image\")\naxis[0,0].axis(\"off\")\n\naxis[0,1].imshow(X_train[1,:,:,0], cmap = plt.get_cmap('gray'))\n# axis[0,1].set_title(\"Second Image\")\naxis[0,1].axis(\"off\")\n\naxis[1,0].imshow(X_train[2,:,:,0], cmap = plt.get_cmap('gray'))\n# axis[1,0].set_title(\"Third Image\")\naxis[1,0].axis(\"off\")\n\naxis[1,1].imshow(X_train[3,:,:,0], cmap = plt.get_cmap('gray'))\n# axis[1,1].set_title(\"Fourth Image\")\naxis[1,1].axis(\"off\")\n\nplt.suptitle(\"Some training examples\")\nplt.show()\n","c4a05aab":"X_train.astype('float32')\ntest.astype('float32')\nX_train = X_train \/ 255.0\ntest = test \/ 255.0\n\n# one hot encode the labels of the training data\ny_train = to_categorical(y_train)\nprint(y_train.shape)","367c5605":"random_seed = 42\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n                                                  test_size = 0.10,\n                                                  random_state = random_seed)","5a739896":"def baseline_cnn(num_classes=10):\n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same',input_shape = (28,28,1)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return model","f3394ccc":"def cnn(num_classes=10):\n    model = Sequential()\n\n    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same',input_shape = (28,28,1)))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 32, kernel_size = (5,5), padding = 'same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n\n\n    model.add(Conv2D(filters = 64, kernel_size = (2,2), padding = 'same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Conv2D(filters = 64, kernel_size = (2,2), padding = 'same'))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(MaxPooling2D(pool_size=(2,2)))\n    model.add(Dropout(0.20))\n\n    model.add(Flatten())\n    model.add(Dense(256))\n    model.add(Activation('relu'))\n    model.add(BatchNormalization())\n    model.add(Dropout(0.5))\n    model.add(Dense(num_classes))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss = 'categorical_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n    return model","a2d175e6":"learning_rate_reduction = ReduceLROnPlateau(monitor = 'val_acc',\n                                            patience = 5,\n                                            verbose = 1,\n                                            factor = 0.8,\n                                            min_lr = 0.00001)","6a780425":"datagen = ImageDataGenerator(rotation_range = 20,\n                             zoom_range = 0.2,\n                             width_shift_range = 0.1,\n                             height_shift_range = 0.1,\n                             fill_mode = 'constant',\n                             cval = 0.0)\ndatagen.fit(X_train)\nfor X_batch, y_batch in datagen.flow(X_train, y_train, batch_size = 16):\n    for i in range(16):\n        plt.subplot(4, 4, i+1)\n        plt.imshow(X_batch[i,:,:,0], cmap = plt.get_cmap('gray'))\n        plt.axis('off')\n    plt.show()\n    break","07b5f1d5":"batch_size = 86\nepochs = 100\n\n# Comment baseline_model and history_baseline if only the larger CNN needs to be run\n#baseline_model = baseline_cnn(y_train.shape[1])\n#history_baseline = baseline_model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n#                    validation_data=(X_val, y_val),\n#                    epochs = epochs,\n#                    steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n#                    callbacks = [learning_rate_reduction],\n#                    verbose=2)","0471b251":"model = cnn(y_train.shape[1])\nhistory = model.fit_generator(datagen.flow(X_train, y_train, batch_size = batch_size),\n                    validation_data=(X_val, y_val),\n                    epochs = epochs,\n                    steps_per_epoch = X_train.shape[0] \/\/ batch_size,\n                    callbacks = [learning_rate_reduction],\n                    verbose=2)","28ad1384":"try:\n    baseline_model\nexcept NameError: \n    baseline_model = None\n\nif baseline_model is None:\n    fig, axis = plt.subplots(1,2,figsize=[10,5])\n    axis[0].plot(history.history['acc'])\n    axis[0].plot(history.history['val_acc'])\n    axis[0].set_title('Model Accuracy')\n    axis[0].set_xlabel('epoch')\n    axis[0].set_ylabel('accuracy')\n    axis[0].legend(['acc','val_acc'], loc='lower right')\n\n    axis[1].plot(history.history['loss'])\n    axis[1].plot(history.history['val_loss'])\n    axis[1].set_title('Model Loss')\n    axis[1].set_xlabel('epoch')\n    axis[1].set_ylabel('accuracy')\n    axis[1].legend(['acc','val_acc'], loc='lower right')\nelse:\n    fig, axis = plt.subplots(2,2,figsize=[15,10])\n    axis[0,0].plot(history_baseline.history['acc'])\n    axis[0,0].plot(history_baseline.history['val_acc'])\n    axis[0,0].set_title('Baseline model accuracy')\n    axis[0,0].set_xlabel('epoch')\n    axis[0,0].set_ylabel('accuracy')\n    axis[0,0].legend(['acc','val_acc'], loc='lower right')\n\n    axis[0,1].plot(history_baseline.history['loss'])\n    axis[0,1].plot(history_baseline.history['val_loss'])\n    axis[0,1].set_title('Baseline model Loss')\n    axis[0,1].set_xlabel('epoch')\n    axis[0,1].set_ylabel('accuracy')\n    axis[0,1].legend(['acc','val_acc'], loc='lower right')\n\n    axis[1,0].plot(history.history['acc'])\n    axis[1,0].plot(history.history['val_acc'])\n    axis[1,0].set_title('Model Accuracy')\n    axis[1,0].set_xlabel('epoch')\n    axis[1,0].set_ylabel('accuracy')\n    axis[1,0].legend(['acc','val_acc'], loc='lower right')\n\n    axis[1,1].plot(history.history['loss'])\n    axis[1,1].plot(history.history['val_loss'])\n    axis[1,1].set_title('Model Loss')\n    axis[1,1].set_xlabel('epoch')\n    axis[1,1].set_ylabel('accuracy')\n    axis[1,1].legend(['acc','val_acc'], loc='lower right')\n\n    plt.show()\n","b20eb522":"from sklearn.metrics import confusion_matrix\npredicted_val = model.predict(X_val)\npredicted_val = np.argmax(predicted_val, axis=1)\ntrue_val = np.argmax(y_val, axis=1)\nconfusion_matrix = confusion_matrix(true_val, predicted_val)","094745d1":"print(confusion_matrix)\nprint(\"Validation dataset shape: \", X_val.shape)","9c42341b":"errors = (predicted_val - true_val !=0)\ntotal_errors = sum(errors)\nprint(total_errors)\nerrors_index = np.where(errors==True)\ntrue_value_labels = true_val[errors_index]\npred_value_labels = predicted_val[errors_index]\nX_val_errors = X_val[errors_index]\n\n\n","5f61b1f1":"index = 0\nn_rows = 5\nn_cols = 5\n\nfig, axis = plt.subplots(n_rows,n_cols,figsize=[25,25])\n\nfor row in range(n_rows):\n    for col in range(n_cols):\n        if index < total_errors:\n            axis[row,col].imshow(X_val_errors[index,:,:,0],plt.get_cmap('gray'))\n            axis[row,col].set_title(\"Predicted label :{}\\nTrue label :{}\".format(pred_value_labels[index],true_value_labels[index]),fontsize=10)\n            index += 1\n","2c224f56":"prediction_test = model.predict(test)\nprediction_test = np.argmax(prediction_test, axis =1)\ndataframe = pd.read_csv(\"..\/input\/sample_submission.csv\") \nlist_of_images = dataframe.ImageId.values\nname = 'submission'\nsubmission = pd.DataFrame({'ImageId':list_of_images})\nsubmission['Label'] = prediction_test\nsubmission.to_csv(f'{name}.csv',index=False)","44691dd2":"## Evaluating the model\nPlot the accuracy and loss of the models for the 100 epochs.","c998798a":"## Submitting the results","a8f19dd9":"Display some of the training images to check what the handwritten characters look like. It can be seen that there is variation in the handwritten digits, e.g. the rotated 1.","65062c95":"Reshape the list of pixel values into a 28x28 matrix for use within the CNN and to display images. Images in the MNIST are in gray scale so rather than the three RGB colour channels there is only one channel.","6fcdf81b":"This kernel is forked from my\n[previous kernel Digit Recognition Convolutional Neural Network in Keras](https:\/\/www.kaggle.com\/kagglemlearner\/digit-recognition-cnn-in-keras-0-996-updated).\n\nIn this kernel, the model performance is evaluated in more detail by generating the confusion matrix and displaying the images that are misclassified by the CNN. ","26b2fa32":"## Data Preprocessing\nNext, the MNIST data is loaded using the Pandas library. It can be seen from the data frames that there are 42000 training examples, 28000 samples in the test data and 784 pixel values. ","6ed4ae8d":"Next the training and test data is normalized so that pixels are in between 0 to 1 rather than 0 to 255 and the labels of the training data are one hot encoded. One hot encoding maps numbered classes (0-9) to binary vectors e.g. class with digit 1 will be mapped to [0, 1, 0, 0, 0, 0, 0, 0, 0, 0].","2f191d4c":"Check for missing values and class imbalance. Using the isnull() function, it can be observed that there are no null or missing values in this dataset because the output array is empty. The value_counts() function can be used to determine the unique counts of a class. This function arranges the counts in descending order so from the output it can be seen that class with digit 1 occurs most frequently with a count of 4684. From the bar plot it can be seen that the frequency with which each digit occurs is fairly consistent.","1e8dea9b":"In order to improve the performance of the CNN, we augment the data using ImageDataGenerator to create additional images when training the model. Some examples of the augmented images are also shown.","6ddc102f":" Define the learning rate annealer to reduce the learning rate when training the model.","d6403893":"Split the data into training and validation set for fitting a model using the sklearn train_test_split. In order to build a robust model, we need a validation set to test the model's accuracy as it learns information about the data. For this kernel, the data is split into a 90\/10 split, i.e., 90% of data is used for testing and 10% data is used for validation. The random seed is also set so that the splits can be reproduced if required.","0eb03e87":"## Creating the model\nA baseline model and a deeper model are defined next and compiled with the categorical cross entropy loss function and adam as the optimizer. Convolutional layers are used along with the relu activation function followed by batch normalization and maxpooling. The baseline model consists of one convolutional layer Conv2D as opposed to four convolutional layers in the deeper CNN. ","04df7d51":"## Training the model\nNext, we can call the baseline model and run it with data augmentation for 100 epochs to evaluate the accuracy. We can then run the deeper CNN and compare the performance of the two models created.","93e51a5d":"## Confusion matrix\nA confusion matrix or error matrix helps us visualise the performance of a machine learning algorithm. In sklearn, the function call confusion_matrix can be used to generate a model's confusion matrix. Each row of the confusion matrix represents instances of the predicted class while each column represents instances of the true labels. The diagonal of the confusion matrix represents all the instances that were correctly labelled by the classifier. Hence, a consfusion matrix makes it straightforward to isolate errors of the classifier which are instances not in the diagonal of a matrix. ","097bc7ae":"Generate the csv file for submission to Kaggle using the larger CNN model.","94e9c448":"Images that are incorrectly labelled by the classifier are displayed and it can be seen that most of the images are difficult to classify even to the human eye. ","d1c53f52":"Importing the relevant libraries.","b480b82f":"\n## Introduction\nThis dataset has 42000 training samples ranging over ten classes (0-9) of hand written digits. The test set consists of 28000 unlabelled samples that need to be labelled from 0-9. The samples are listed as a list of 784 values which can be reshaped into a 28x28 matrix in order to give an image. Such a problem is usually solved using a Convolutional Neural Network (CNN) which preserves the spatial information within images. In a traditional feed forward neural network, an image would have to be flattened i.e. in this case we would use the 784 values along with a bias value as an input to the network. However, in CNNs small squares of information from the 28x28 image scene are convolved with kernels\/filters and this information is then used to build a model. Such a structure is robust to distortions such as those caused due to shifts and translations in the scene.\n\nI tried a shallow baseline Convolutional Neural Network followed by a deeper model to check the level of improvement. The score of > 0.994 is achieved using the larger model structure so the baseline_model function call can be commented if only the main model needs to be run.\n\nUpdate: The baseline_model in this kernel is currently commented.\n\n* Data Preprocessing\n * Loading the data\n * Missing values and class imbalance\n * Visualizing the images\n * Creating the validation data set\n* Defining the models\n * Baseline model\n * Deeper CNN model\n * Learning rate scheduler\n * Data augmentation\n* Training the model\n* Evaluating the models\n * Plotting accuracy and loss\n* Generating the submission file\n\n\n\n"}}