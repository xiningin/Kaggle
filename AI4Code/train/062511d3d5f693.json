{"cell_type":{"2cde3d51":"code","412dd59b":"code","842b5385":"markdown","b913102e":"markdown"},"source":{"2cde3d51":"from transformers import *\nimport numpy as np\n\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nbert_model = TFBertForMaskedLM.from_pretrained('bert-base-uncased') \n\ndef bert_predict(str_mask):\n    indices = tokenizer.encode(str_mask, add_special_tokens=False, return_tensors='tf')\n\n    # PREDICT MISSING WORDS\n    pred = bert_model(indices)\n    masked_indices = np.where(indices==103)[1]\n\n    # DISPLAY MISSING WORDS\n    predicted_words = np.argmax( np.asarray(pred[0][0])[masked_indices,:] ,axis=1)\n    predicted_words_decoded = tokenizer.decode(predicted_words)\n    print(f\"Original phrase: {str_mask}\")\n    str_out = str_mask.replace(\"[MASK]\", \"{}\")\n    str_out = str_out.replace(\"[CLS] \", \"\")\n    str_out = str_out.replace(\"[SEP]\", \"\")          \n    print(f\"Predicted words decoded: {predicted_words_decoded}\")\n    print(f\"Resulted phrase: {str_out.format(predicted_words_decoded)}\")    ","412dd59b":"str_mask = '[CLS] The leaderboard drastic change will be soon [MASK] on Kaggle. [SEP]'\nbert_predict(str_mask)","842b5385":"Inspiration\n* https:\/\/www.kaggle.com\/nxrprime\/kaggle-is-chicken-as-proven-by-bert\n* https:\/\/www.kaggle.com\/c\/google-quest-challenge\/discussion\/129399\n","b913102e":"Push **Code** button to see the code."}}