{"cell_type":{"19af7caf":"code","c184d171":"code","b9a4d433":"code","cee754a4":"code","4834e6a4":"code","a824eaaa":"code","f5322fb6":"code","22d19c79":"code","e0a7820e":"code","4edd1387":"code","d8af20f1":"code","1938e61a":"code","736479ca":"code","a16c88ee":"code","eefe07d7":"code","3b18db58":"code","f72dc1da":"code","45da7eed":"code","ea509e84":"code","47cc995c":"code","a055ab63":"code","dcf4e669":"code","9cecac53":"code","7c4e6001":"code","776598c7":"code","68600844":"code","99448225":"code","f92c1f9d":"code","2690279e":"code","515dbcbc":"code","21013b24":"code","a98d0fb4":"code","045d0d0a":"code","a9067aa4":"code","24c006f4":"code","a3eb0464":"code","909aa157":"code","54d7127a":"code","4c3b49c9":"code","697fd116":"code","235a3130":"code","38da69ec":"code","f5bac631":"code","27af411d":"code","db0bea70":"code","2981833a":"code","77d53fd1":"code","e837609d":"code","9b70f872":"code","57531b86":"code","b168d30e":"code","12b8aea5":"code","9cfeecff":"code","15938dbb":"code","cffd222c":"code","7bcba952":"code","9ea22efc":"code","de2ad7c4":"code","ac7a5809":"markdown","39cfeee8":"markdown","b2418902":"markdown","c80f2758":"markdown","99d3d338":"markdown","5181f1c6":"markdown","78110cfc":"markdown","d44c5ae0":"markdown","3a806f92":"markdown","2b68c05c":"markdown","28bcd61a":"markdown","b02e953c":"markdown","64716642":"markdown","cb4708ce":"markdown","7d4cb4f3":"markdown","3ba384eb":"markdown","6b8abdfc":"markdown","d24863f2":"markdown","a4eb3918":"markdown","c91a45fc":"markdown","5505456a":"markdown","1f64a380":"markdown","8ea00198":"markdown","4ebf13e4":"markdown","3033745f":"markdown","8ed22667":"markdown"},"source":{"19af7caf":"#Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport nltk\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom nltk.tokenize import word_tokenize\nfrom nltk import pos_tag","c184d171":"# reading the Treebank tagged sentences\nnltk.download('universal_tagset')\nnltk_data = list(nltk.corpus.treebank.tagged_sents(tagset='universal'))","b9a4d433":"len(nltk_data)","cee754a4":"# Let's view the first few tagged sentences\nprint(nltk_data[:5])","4834e6a4":"# Splitting into train and validation sets in the ratio of 95:5\nrandom.seed(1234)\ntrain_set, test_set = train_test_split(nltk_data,train_size=0.95, test_size=0.05, random_state=42)\n\nprint(len(train_set))\nprint(len(test_set))","a824eaaa":"# Getting list of tagged words - train data\ntrain_tagged_words = [tup for sent in train_set for tup in sent]\nprint(len(train_tagged_words))\n\n# Getting list of tagged words - validtion data\ntest_tagged_words = [tup for sent in test_set for tup in sent]\nprint(len(test_tagged_words))","f5322fb6":"# tokens. i.e. the list of words from list of (word, tag) fom train set\ntokens = [pair[0] for pair in train_tagged_words]\ntokens[:10]","22d19c79":"# vocabulary\nV = set(tokens)\nprint(len(V))","e0a7820e":"# number of tags\nT = sorted(list(set([pair[1] for pair in train_tagged_words])))\nlen(T)","4edd1387":"# Let us view the tags\nprint(T)","d8af20f1":"# computing P(w\/t) and storing in T x V matrix\nt = len(T)\nv = len(V)\nw_given_t = np.zeros((t, v))","1938e61a":"# compute Emission Probability- P(word given tag)\ndef word_given_tag(word, tag, train_bag = train_tagged_words):\n    \n    # Calculate No.of times tag t appears\n    tag_list = [pair for pair in train_bag if pair[1]==tag]\n    count_tag = len(tag_list)\n    \n    # Calculate No.of times word w has been tagged as tag t\n    w_given_tag_list = [pair[0] for pair in tag_list if pair[0]==word]\n    count_w_given_tag = len(w_given_tag_list)\n    \n    return (count_w_given_tag, count_tag)","736479ca":"#Example\n\nprint(\"\\n\", \"October\")\nprint(word_given_tag('October','NOUN'))\nprint(word_given_tag('October','VERB'))\nprint(word_given_tag('October','ADJ'))\n\nprint(\"\\n\", \"reported\")\nprint(word_given_tag('reported','NOUN'))\nprint(word_given_tag('reported','VERB'))\nprint(word_given_tag('reported','ADJ'))","a16c88ee":"# Compute Transition Probability - tag2(t2) given tag1 (t1)\n\ndef t2_given_t1(t2, t1, train_bag = train_tagged_words):\n    \n    # Calculate No.of times tag t1 appears\n    tags = [pair[1] for pair in train_bag]\n    count_t1 = len([t for t in tags if t==t1])\n    \n    # Calculate No.of times t1 is followed by tag t2\n    count_t2_t1 = 0\n    for index in range(len(tags)-1):\n        if tags[index]==t1 and tags[index+1] == t2:\n            count_t2_t1 += 1\n    return (count_t2_t1, count_t1)","eefe07d7":"# examples\nprint(t2_given_t1('NOUN', 'ADJ'))\nprint(t2_given_t1('NOUN', 'DET'))\nprint(t2_given_t1('NOUN', 'VERB'))\nprint(t2_given_t1('VERB', 'NOUN'))","3b18db58":"# Please note P(tag|start) is same as P(tag|'.')\nprint(t2_given_t1('DET', '.'))\nprint(t2_given_t1('NOUN', '.'))\nprint(t2_given_t1('VERB', '.'))","f72dc1da":"# creating t x t transition matrix of tags. Each column is t2, each row is t1, thus M(i, j) represents P(tj given ti)\ntags_matrix = np.zeros((len(T), len(T)), dtype='float32')\nfor i, t1 in enumerate(list(T)):\n    for j, t2 in enumerate(list(T)): \n        tags_matrix[i, j] = t2_given_t1(t2, t1)[0]\/t2_given_t1(t2, t1)[1]","45da7eed":"tags_matrix","ea509e84":"# convert the matrix to a df for better readability\ntags_df = pd.DataFrame(tags_matrix, columns = list(T), index=list(T))","47cc995c":"# Each column is t2, each row is t1\ntags_df","a055ab63":"tags_df.loc['.', :]","dcf4e669":"# heatmap of tags matrix\nplt.figure(figsize=(14, 5))\nsns.heatmap(tags_df, annot=True)\nplt.show()","9cecac53":"# filter the df to get P(t2, t1) > 0.5\ntags_frequent = tags_df[tags_df>0.5]\nplt.figure(figsize=(14,5))\nsns.heatmap(tags_frequent,annot = True)\nplt.show()","7c4e6001":"# Viterbi Heuristic\ndef Viterbi(words, train_bag = train_tagged_words):\n    state = []\n    \n    # Take the list of unique tags present in the corpus\n    T = sorted(list(set([pair[1] for pair in train_bag])))\n        \n    for key, word in enumerate(words):\n        #initialise list of probability column for a given observation\n        p = []\n        \n        for tag in T:\n            if key == 0: #first word has key=0\n                transition_p = tags_df.loc['.', tag]                 \n            else:\n                transition_p = tags_df.loc[state[-1], tag]\n                \n            # compute emission and state probabilities\n            emission_p = word_given_tag(words[key], tag)[0]\/word_given_tag(words[key], tag)[1]\n            state_probability = emission_p * transition_p    \n            p.append(state_probability)\n            \n        pmax = max(p)\n        # getting state for which probability is maximum\n        state_max = T[p.index(pmax)]\n        state.append(state_max)\n    return list(zip(words, state))","776598c7":"# Let's test our Viterbi algorithm on the validation dataset which is 5% of the entire dataset\n\nrandom.seed(1234)\n# list of tagged words\ntest_run_base = [tup for sent in test_set for tup in sent]\n\n# take the list of words alone without the tags\ntest_tagged_words = [tup[0] for sent in test_set for tup in sent]","68600844":"# tagging the test sentences\nstart = time.time()\ntagged_seq = Viterbi(test_tagged_words)\nend = time.time()\ndifference = end-start","99448225":"# Below code takes around 22 mins to execute\nprint(\"Time taken in seconds: \", difference)","f92c1f9d":"# accuracy\ncheck = [i for i, j in zip(tagged_seq, test_run_base) if i == j] ","2690279e":"accuracy = len(check)\/len(tagged_seq)","515dbcbc":"accuracy","21013b24":"incorrect_tagged_cases = [j for i, j in enumerate(zip(tagged_seq, test_run_base)) if j[0]!=j[1]]","a98d0fb4":"incorrect_tagged_cases[:5]","045d0d0a":"# Modified Viterbi Heuristic- Approach I\ndef Viterbi_approach1(words, train_bag = train_tagged_words):\n    state = []\n    \n    # Take the list of unique tags present in the corpus\n    T = sorted(list(set([pair[1] for pair in train_bag])))\n    V = [i[0] for i in train_bag]\n    \n    for key, word in enumerate(words):\n        #initialise list of probability column for a given observation\n        p = [] \n        \n        for tag in T:\n            if key == 0: #first word has key=0\n                transition_p = tags_df.loc['.', tag]\n            else:\n                transition_p = tags_df.loc[state[-1], tag]\n                \n            # compute emission and state probabilities\n            emission_p = word_given_tag(words[key], tag)[0]\/word_given_tag(words[key], tag)[1]\n            \n            # modification to the original vanilla viterbi algorithm. \n            # Vocab contains the list of unique words in training dataset\n            if word not in V: \n                state_probability = transition_p\n            else:\n                state_probability = emission_p * transition_p\n                \n            p.append(state_probability)\n            \n        pmax = max(p)\n        # getting state for which probability is maximum\n        state_max = T[p.index(pmax)] \n        state.append(state_max)\n    return list(zip(words, state))","a9067aa4":"# tagging the test sentences\nstart = time.time()\ntransition_tagged_seq = Viterbi_approach1(test_tagged_words)\nend = time.time()\ndifference = end-start","24c006f4":"# Below code takes around 23 mins to execute\nprint(\"Time taken in seconds: \", difference)","a3eb0464":"# accuracy\ntransition_check = [i for i, j in zip(transition_tagged_seq, test_run_base) if i == j] ","909aa157":"transition_accuracy = len(transition_check)\/len(transition_tagged_seq)","54d7127a":"transition_accuracy","4c3b49c9":"transition_incorrect_tagged_cases = [j for i, j in enumerate(zip(transition_tagged_seq, test_run_base)) if j[0]!=j[1]]","697fd116":"transition_incorrect_tagged_cases[:5]","235a3130":"# Lexicon (or unigram tagger)\nunigram_tagger = nltk.UnigramTagger(train_set)\nunigram_tagger.evaluate(test_set)","38da69ec":"# patterns for tagging using a rule based tagger\npatterns = [\n    (r'.*\\'s$', 'NOUN'),                     # possessive nouns\n    (r'.*s$', 'NOUN'),                       # plural nouns\n    (r'^[aA-zZ].*[0-9]+','NOUN'),            \n    (r'.*ness$', 'NOUN'),                    # words ending with 'ness' such as 'sluggishness' \n    (r'.*', 'NOUN'), \n    (r'^([0-9]|[aA-zZ])+\\-[aA-zZ]*$','ADJ'),     \n    (r'[aA-zZ]+(ed|ing|es)$', 'VERB'),       # words ending with 'ed' or 'ing' or 'es'    \n    (r'.*ly$', 'ADV'),                       # words ending with 'ly'    \n    (r'^[0-9]+(.[0-9]+)?$', 'NUM'),          # cardinal numbers such as 61, 1956, 9.8, 8.45, 352.7        \n    (r'(The|the|A|a|An|an)$', 'DET')\n    ]","f5bac631":"# Rule based tagger\nrule_based_tagger = nltk.RegexpTagger(patterns)\n\n# unigram tagger backed up by the rule-based tagger\nrule_based_unigram_tagger = nltk.UnigramTagger(train_set, backoff = rule_based_tagger)\nrule_based_unigram_tagger.evaluate(test_set)","27af411d":"# Bigram tagger backed up by the rule-based-unigram tagger\nbigram_tagger = nltk.BigramTagger(train_set, backoff = rule_based_unigram_tagger)\nbigram_tagger.evaluate(test_set)","db0bea70":"# trigram tagger\ntrigram_tagger = nltk.TrigramTagger(train_set, backoff = bigram_tagger)\ntrigram_tagger.evaluate(test_set)","2981833a":"# A trigram tagger backed off by a rule based tagger.\n\ndef trigram_tagger(word, train_set = train_set):\n    \n    # specify patterns for tagging. I have identified most of the patterns from the first 100 sentences in universal dataset\n    patterns = [\n    (r'^([0-9]|[aA-zZ])+\\-([0-9]|[aA-zZ])*$','ADJ'), # words such as '10-lap','30-day','York-based'\n    (r'.*able$', 'ADJ'),                     # words ending with 'able' such as 'questionable'\n    (r'.*ful$', 'ADJ'),                      # words ending with 'ful' such as 'useful'\n    (r'.*ous$', 'ADJ'),                      # words ending with 'ous' such as 'Previous'\n    \n    (r'.*\\'s$', 'NOUN'),                     # possessive nouns\n    (r'.*s$', 'NOUN'),                       # plural nouns\n    (r'^[aA-zZ].*[0-9]+','NOUN'),            # Alpha Numeric such as Door Number, Street Number etc\n    (r'.*ers$', 'NOUN'),                     # words ending with 'ers' such as 'filters','workers'\n    (r'.*ment$', 'NOUN'),                    # words ending with 'ment' such as 'reinvestment' \n    (r'.*town$', 'NOUN'),                    # words ending with 'town' such as 'town','downtown'  \n    (r'.*ness$', 'NOUN'),                    # words ending with 'ness' such as 'sluggishness' \n    (r'^[A-Z]+([a-z]{1,2})?\\.?$','NOUN'),    # words such as 'Nov.','Mr.','Inc.'\n    \n    (r'[aA-zZ]+(ed|ing|es)$', 'VERB'),       # words ending with 'ed' or 'ing' or 'es'    \n    (r'.*ly$', 'ADV'),                       # words ending with 'ly'\n    \n    (r'^[0-9]+(.[0-9]+)?$', 'NUM'),          # cardinal numbers such as 61, 1956, 9.8, 8.45, 352.7        \n    (r'^(0|([*|-|$].*))','X'),               # words such as '*', '0', *-1', '*T*-1', '*ICH*-1', '*?*'   \n    \n    (r'(The|the|A|a|An|an|That|that|This|this|Those|those|These|these)$', 'DET'), # determinants     \n    (r'.*', 'NOUN')  \n    ]\n    \n    rule_based_tagger = nltk.RegexpTagger(patterns)\n\n    # trigram backed up by the regex tagger\n    trigram_regex_tagger = nltk.TrigramTagger(train_set, backoff = rule_based_tagger)\n    return trigram_regex_tagger.tag_sents([[(word)]])    ","77d53fd1":"# Modified Viterbi Heuristic- Approach II - Backoff to rule based tagger in case an unknown word is encountered.\ndef Viterbi_approach2(words, train_bag = train_tagged_words):\n    state = []\n    T = sorted(list(set([pair[1] for pair in train_bag])))\n    V = [i[0] for i in train_bag]\n    \n    # use the trigram tagger backed up by the rule based tagger for unknown words.\n    for key, word in enumerate(words):\n        if word not in V:\n            unknown_word_tag = trigram_tagger(word)\n            for sent in unknown_word_tag:\n                for tup in sent:\n                    state.append(tup[1])\n        else:            \n            p = [] \n            for tag in T:\n                if key == 0:\n                    transition_p = tags_df.loc['.', tag]\n                else:\n                    transition_p = tags_df.loc[state[-1], tag]\n                \n                # compute emission and state probabilities\n                emission_p = word_given_tag(words[key], tag)[0]\/word_given_tag(words[key], tag)[1]\n                state_probability = emission_p * transition_p    \n                p.append(state_probability)\n            \n            pmax = max(p)\n            # getting state for which probability is maximum\n            state_max = T[p.index(pmax)] \n            state.append(state_max)\n    return list(zip(words, state))","e837609d":"# tagging the test sentences. Below code takes around 49 mins to execute\nstart = time.time()\nviterbi_trigram_tagged_seq = Viterbi_approach2(test_tagged_words)\nend = time.time()\ndifference = end-start\n\nprint(\"Time taken in seconds: \", difference)\n\n# accuracy\nviterbi_trigram_word_check = [i for i, j in zip(viterbi_trigram_tagged_seq, test_run_base) if i == j]\n\nviterbi_trigram_accuracy = len(viterbi_trigram_word_check)\/len(viterbi_trigram_tagged_seq)\nviterbi_trigram_accuracy","9b70f872":"viterbi_trigram_incorrect_tagged_cases = [j for i, j in enumerate(zip(viterbi_trigram_tagged_seq, test_run_base)) if j[0]!=j[1]]\nviterbi_trigram_incorrect_tagged_cases[:5]","57531b86":"sentence_test1 = 'Android has been the best-selling OS worldwide on smartphones since 2011 and on tablets since 2013.'\nwords = word_tokenize(sentence_test1)\ntagged_seq = Viterbi(words)\nprint(tagged_seq)","b168d30e":"tagged_seq_modified1 = Viterbi_approach1(words)\nprint(tagged_seq_modified1)","12b8aea5":"tagged_seq_modified2 = Viterbi_approach2(words)\nprint(tagged_seq_modified2)","9cfeecff":"sentence_test2 = \"Google and Twitter made a deal in 2015 that gave Google access to Twitter's firehose.\"\nwords = word_tokenize(sentence_test2)\ntagged_seq = Viterbi(words)\nprint(tagged_seq)","15938dbb":"tagged_seq_modified1 = Viterbi_approach1(words)\nprint(tagged_seq_modified1)","cffd222c":"tagged_seq_modified2 = Viterbi_approach2(words)\nprint(tagged_seq_modified2)","7bcba952":"sentence_test3 = \"The 2018 FIFA World Cup is the 21st FIFA World Cup, an international football tournament contested once every four years.\"\nwords = word_tokenize(sentence_test3)\ntagged_seq = Viterbi(words)\nprint(tagged_seq)","9ea22efc":"tagged_seq_modified1 = Viterbi_approach1(words)\nprint(tagged_seq_modified1)","de2ad7c4":"tagged_seq_modified2 = Viterbi_approach2(words)\nprint(tagged_seq_modified2)","ac7a5809":"### Compare the tagging accuracies of the modifications with the vanilla Viterbi algorithm","39cfeee8":"####  Let us combine the unigram tagger with a rule based regex tagger.","b2418902":"## POS tagging using modified Viterbi\n\n### Steps involved:\n\n1. Vanilla Viterbi Algorithm.\n2. Viterbi Modification-Approach I:\n    - Transition probability is considered in case of unknown words since emission probability is zero.\n3. Viterbi Modification-Approach II:\n    - Trigram tagger backed off to a rule based tagger in case of an unknown word.\n4. Checked the tagging accuracies on the sample test sentences.\n5. Listed down cases which were incorrectly tagged by original POS tagger and got corrected by modified approaches. ","c80f2758":"#### Evaluating tagging accuracy","99d3d338":"#### Evaluating on Validation\/Test Set","5181f1c6":"### Solve the problem of unknown words\n### Viterbi Modification-Technique I\n#### Use transition probability of tags when emission probability is zero (in case of unknown words)\n\nIf a word is not present in the training vocabulary i.e. unknown word, then its emission probability will be 0 and hence The state probability will also be zero. Therefore in cases where the algorithm encounters a word which it has not see previously, we can leave out the emission probability and consider only the transition probability.\n\nThe vanilla viterbi algorithm can be modified as given below as part of Approach I:\n\n__If word is unknown then,<br>\nconsider only the transition prob (since, emission probability will be 0)<br>\nElse<br>\nconsider both the emission and transition probabilities as state probability.__","78110cfc":" __Observations__:\n \n Below words have been correctly tagged by Approach II compared to Vanilla viterbi and Modified Approach-I.\n\n| Incorrect Tags-Original POS Tagger | Corrected Tags-Modified Approach I | Corrected Tags-Modified Approach II |\n| :--- | --- | --- |\n| ('pre-1917', '.') | ('pre-1917', 'X') | ('pre-1917', 'ADJ') |\n| ('Tokio', '.') | ('Tokio', 'DET') | ('Tokio', 'NOUN') |\n| ('20.5', '.') | ('20.5', 'NOUN') | ('20.5', 'NUM') |\n| ('polarized', '.') | ('polarized', 'X') | ('polarized', 'VERB') |\n| ('154.2', '.') | ('154.2', 'X') | ('154.2', 'NUM') |","d44c5ae0":"### List down cases which were incorrectly tagged by original POS tagger and got corrected by our modifications\n### Case 1","3a806f92":"### Case 3","2b68c05c":"__Observations__:\n\n| Incorrect Tags-Original POS Tagger | Corrected Tags-Modified Approach I | Corrected Tags-Modified Approach II |\n| :--- | --- | --- |\n| ('Android', '.') | ('Android', 'NOUN') | ('Android', 'NOUN') |\n| ('OS', '.') | ('OS', 'NOUN') | ('OS', 'NOUN') |\n| ('worldwide', '.') | ('worldwide', 'NOUN') | ('worldwide', 'NOUN') |\n| ('smartphones', '.') | ('smartphones', 'DET') | ('smartphones', 'NOUN') |\n| ('2011', '.') | ('2011', 'DET') | ('2011', 'NUM') \n| ('2013', '.') | ('2013', 'DET') | ('2013', 'NUM') ","28bcd61a":"__Observations__:\n\n| Incorrect Tags-Original POS Tagger | Corrected Tags-Modified Approach I | Corrected Tags-Modified Approach II |\n| :--- | --- | --- |\n| ('Google', '.') | ('Google', 'NOUN') | ('Google', 'NOUN') |\n| ('Twitter', '.') | ('Twitter', 'NOUN') | ('Twitter', 'NOUN') |\n| ('2015', '.') | ('2015', 'DET') | ('2015', 'NUM') |\n| ('Google', '.') | ('Google', 'X') | ('Google', 'NOUN') |\n| ('Twitter', '.') | ('Twitter', 'VERB') | ('Twitter', 'NOUN') |\n| ('firehose', '.') | ('firehose', 'VERB') | ('firehose', 'NOUN') |","b02e953c":"### Case 2","64716642":"#### From above heatmap, we can observe that most of the transition probabilities are between Noun and other parts of speech such as Adjective and Determinant.","cb4708ce":"### Data Preparation","7d4cb4f3":"### Emission Probabilities","3ba384eb":"The incorrect tagged cases can be attributed to the fact that when the algorithm hits an unknown word (i.e. not present in the training set hence emission probability is 0), it naively assigns the first tag in the list of tags that we have created.","6b8abdfc":"### POS Tagging Algorithm using Hidden Markov Model\n__Viterbi algorithm__ -> For each word, we compute the P(tag|word) for each tag in the tag set and then assign the tag having the max P(tag\/word). \n\nP(tag|word)  = (emission probability of the word-tag pair) * (transition probability from the previous tag).<br>\ni.e. P(t|w)  = P(w|t) * P(t2|t1)\n\n\n![image.png](attachment:image.png)\n\n\n1. __Emission probability__ of a word 'w' for tag 't':\n    - __P(w|t)__= (No.of times w has been tagged as t)\/(No.of times t appears)\n    \n2. __Transition probability__ of tag t1 followed by tag t2:\n    - __P(t2|t1)__= (No.of times t1 is followed by tag t2)\/(No.of times t1 appears)\n    \nSo, Let us calculate the emission and transition probabilities.\n\n","d24863f2":"### Viterbi Modification-Technique II\n\n__Approach 2__ : Rule Based engine on unknown words, by modifying the Viterbi Algorithm. If the state of the word is zero then use rule based engine to tag vocabulary to the words.\n\nWe saw that the Trigram Tagger backed up by the bigram tagger gives an accuracy of about 96%. Let's now try to modify the viterbi algorithm to use this trigram tagger as a back-off. When the viterbi algorithm is not able to tag an unknown word, it uses the rule-based tagger.","a4eb3918":"__Observations__:\n\n| Incorrect Tags-Original POS Tagger | Corrected Tags-Modified Approach I | Corrected Tags-Modified Approach II |\n| :--- | --- | --- |\n| ('2018', '.') | ('2018', 'NOUN') | ('2018', 'NUM') |\n| ('FIFA', '.') | ('FIFA', 'NOUN') | ('FIFA', 'NOUN') |\n| ('Cup', '.') | ('Cup', 'NOUN') | ('Cup', 'NOUN') |\n| ('contested', '.') | ('contested', 'NOUN') | ('contested', 'VERB') |\n\n\nWe can see that in all the above 3 cases, unknown words are being tagged as '.'(punctuation) because it is the first tag in the list of all tags.<br> \n\nAlso, the first modified approach was able to correctly tag only few of the incorrect words while the second modified approach was able to perform much better than the 1st approach.","c91a45fc":"### Build the vanilla Viterbi based POS tagger\nThe Viterbi algorithm takes a greedy heuristic. It starts from the start of a sentence and at every step maximizes the likelihood of this tag sequence that is likely to be assigned to this sentence so far.","5505456a":"### Transition Probabilities","1f64a380":"### Let us summarize the tagging accuracies we got on the Validation set\n| Approach | Accuracy |\n| :--- | --- |\n| Vanilla Viterbi algorithm | 91.38% |\n| Modified Vanilla Viterbi- Approach I(Use transition probability of tags when emission probability is zero) | 93.88% |\n| Unigram\/Lexicon Tagger | 91.17% |\n| Unigram backed by Rule based Tagger | 93.78% |\n| Bigram backed by Unigram_Rule_based tagger | 94.12% |\n| Trigram backed by Bigram tagger | 94.04% |\n| Viterbi+ Trigram and Rule Based tagger -Approach II | 96.18% |\n","8ea00198":"__The tagset consists of the following 12 coarse tags__\n\n    . - punctuation\n    ADJ - adjectives\n    ADP - adpositions\n    ADV - adverbs\n    CONJ - conjunctions\n    DET - determiners\n    NOUN - nouns\n    NUM - cardinal numbers\n    PRON - pronouns\n    PRT - particles or other function words\n    VERB - verbs    \n    X - other: foreign words, typos, abbreviations","4ebf13e4":"We see the modified viterbi algorithm performs better than the original vanilla viterbi algorithm. The modified viterbi achieves an accuracy of approx. 93.88% compared to 91.38% of the vanilla viterbi algorithm.\n\nStill there is a loss of approx. 6.12%.\n\nCompared to the vanilla viterbi on the validation dataset, there is a slight improvement in modified viterbi-approach I.\nWe can see that the word 'copied' which was incorrect in vanilla viterbi has been correctly identified as 'VERB' by modified viterbi Approach I.\n\n| Incorrect Tag-Original POS Tagger | Corrected Tag-Modified Approach I |\n| :--- | --- |\n| ('Overseas', '.') | ('Overseas', 'NOUN') |\n| ('Unemployment', '.') | ('Unemployment', 'NOUN') |\n| ('paycheck', '.') | ('paycheck', 'NOUN') |\n| ('Funded', '.') | ('Funded', 'VERB') |\n| ('existed', '.') | ('existed', 'VERB') |\n \nNow lets see if we can improve further using 2nd Approach.","3033745f":"#### Unigram Tagger","8ed22667":"### Lexicon and Rule-Based Models for POS Tagging"}}