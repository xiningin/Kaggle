{"cell_type":{"e040e9e1":"code","d4a5ca99":"code","d38cc24f":"code","9dfc69eb":"code","b87d892a":"code","d4b05829":"code","d9d25640":"code","2b24f06a":"code","2bab1a13":"code","104dee1c":"code","b0335385":"code","d775ae1c":"code","ef0f3379":"code","69db9e96":"code","0af74805":"code","fb5445fb":"code","9f0b6932":"markdown"},"source":{"e040e9e1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4a5ca99":"from tensorflow import keras\n\nimport matplotlib.pyplot as plt\n\nimport zipfile as zp\nimport os\nimport glob\nimport random","d38cc24f":"input_path = \"\/kaggle\/input\/aerial-cactus-identification\"\n## train\ntrain_zpfile = zp.ZipFile(os.path.join(input_path, \"train.zip\"))\ntrain_zpfile.extractall(\"\/kaggle\/working\")\n## test\ntest_zpfile = zp.ZipFile(os.path.join(input_path, \"test.zip\"))\ntest_zpfile.extractall(\"\/kaggle\/working\")","9dfc69eb":"train_images = glob.glob('\/kaggle\/working\/train\/*')\ntrain_images[0:4]","b87d892a":"from PIL import Image\nimg = Image.open('\/kaggle\/working\/train\/570ceff6e1c6eededfb4c256f9d6bfdd.jpg')\nimg.size","d4b05829":"display(img)","d9d25640":"np.asarray(img).shape","2b24f06a":"train_labels = pd.read_csv(\"\/kaggle\/input\/aerial-cactus-identification\/train.csv\")\ntrain_labels.head()","2bab1a13":"train_labels['has_cactus'].value_counts().plot(kind='barh')","104dee1c":"os.makedirs('\/kaggle\/working\/train\/cactus_0')\nos.makedirs('\/kaggle\/working\/train\/cactus_1')\nos.makedirs('\/kaggle\/working\/validation\/cactus_0')\nos.makedirs('\/kaggle\/working\/validation\/cactus_1')","b0335385":"for i in range(train_labels.shape[0]):\n    \n    i_id = train_labels.loc[i, 'id']\n    i_label = train_labels.loc[i, 'has_cactus']\n    \n    i_id_path = os.path.join('\/kaggle\/working\/train\/', i_id)\n    train_path = \"\/kaggle\/working\/train\"\n    val_path = \"\/kaggle\/working\/validation\"\n    \n    if i_label == 1:\n        if random.uniform(0, 1) < 0.2:\n            os.rename(i_id_path, os.path.join(val_path, 'cactus_1', i_id))\n        else:            \n            os.rename(i_id_path, os.path.join(train_path, 'cactus_1', i_id))\n    else:\n        if random.uniform(0, 1) < 0.2:\n            os.rename(i_id_path, os.path.join(val_path, 'cactus_0', i_id))\n        else:\n            os.rename(i_id_path, os.path.join(train_path, 'cactus_0', i_id))","d775ae1c":"train_images = glob.glob('\/kaggle\/working\/train\/*\/*')\ntrain_images[0:5]","ef0f3379":"## image generators\ntrain_generator = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255.0)\nvalidation_generator = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255.0)\ntest_generator = keras.preprocessing.image.ImageDataGenerator(rescale = 1\/255.0)\n\n## Create model\nkeras.backend.clear_session()\nmodel = keras.models.Sequential()\n\nmodel.add(keras.layers.Conv2D(filters = 16, kernel_size = 3, padding = 'same', input_shape = (32, 32, 3), activation = 'elu', kernel_initializer = 'he_normal'))\nmodel.add(keras.layers.BatchNormalization())\nmodel.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2, padding = 'same'))\n\nfor i in [32] * 1 + [64] * 1 + [128] * 1 + [256] * 1:\n    model.add(keras.layers.Conv2D(filters = i, kernel_size = 3, padding = 'same', activation = 'elu', kernel_initializer = 'he_normal'))\n    model.add(keras.layers.BatchNormalization())\n    model.add(keras.layers.MaxPooling2D(pool_size = 2, strides = 2, padding = 'same'))\n\nmodel.add(keras.layers.Flatten())\n\nfor i in [712, 356]:\n    model.add(keras.layers.Dense(i, activation = 'elu', kernel_initializer = 'he_normal'))\n\nmodel.add(keras.layers.Dense(1, activation = 'sigmoid'))\n\n## optimizer & model compile\noptimizer = keras.optimizers.RMSprop(learning_rate=0.0001)\nmodel.compile(loss='binary_crossentropy', metrics='accuracy', optimizer=optimizer)\n\n## call back\ncallback = keras.callbacks.EarlyStopping(patience=5, restore_best_weights=True)","69db9e96":"history = model.fit(train_generator.flow_from_directory('\/kaggle\/working\/train', \n                                                        target_size = (32, 32), \n                                                        class_mode = 'binary'),\n                   validation_data=validation_generator.flow_from_directory('\/kaggle\/working\/validation',\n                                                                           target_size = (32, 32),\n                                                                           class_mode = 'binary'),\n                    epochs=100,\n                    callbacks= callback,\n                    steps_per_epoch = len(train_images)\/10\/16\n                   )","0af74805":"test_gen = test_generator.flow_from_directory('\/kaggle\/working',classes = ['test'], target_size=(32,32), class_mode=None,shuffle=None, batch_size=16)\nypred = model.predict_generator(test_gen)","fb5445fb":"test_file_names = test_gen.filenames\nypred = ypred.flatten().tolist()\n\nsubmission = pd.DataFrame({'id':range(1, len(test_file_names)+1), 'has_cactus':ypred})\nsubmission.to_csv('submission.csv', index=False)","9f0b6932":"These images are so small.. I can't actual see anything."}}