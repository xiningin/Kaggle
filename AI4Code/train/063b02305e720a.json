{"cell_type":{"e3a1e9cc":"code","e37e0331":"code","c307b0db":"code","007536e2":"code","171ea20b":"code","183be074":"code","189419e1":"code","896e77aa":"code","6f104702":"code","e8d9ba60":"code","e3eab154":"code","b2875f2d":"markdown","49cac283":"markdown","ecdb1a6f":"markdown","11e999a2":"markdown","dff749bb":"markdown","27b20d6d":"markdown","8c116977":"markdown","c553129d":"markdown","307af4b8":"markdown","1fc200fd":"markdown"},"source":{"e3a1e9cc":"import pandas as pd # importing libraries","e37e0331":"# importing the data to a dataframe \ndf = pd.read_csv(\"..\/input\/heart-attack-analysis-prediction-dataset\/heart.csv\") ","c307b0db":"df.head() # displaying first 5 rows","007536e2":"df.columns #column names","171ea20b":"print('Shape is',df.shape) # shape of the dataframe","183be074":"df.isnull().sum() # checking for null values","189419e1":"df.describe() #summary statistics","896e77aa":"# dividing some columns with their maximum value, to get normalized values between 0 and 1\ndf['age'] = df['age']\/max(df['age'])\ndf['cp'] = df['cp']\/max(df['cp'])\ndf['trtbps'] = df['trtbps']\/max(df['trtbps'])\ndf['chol'] = df['chol']\/max(df['chol'])\ndf['thalachh'] = df['thalachh']\/max(df['thalachh'])","6f104702":"#now let us look at normalized data.\ndf.describe()","e8d9ba60":"from sklearn.model_selection import train_test_split\n\n#splitting data into training data and testing data\nX_train, X_test, y_train, y_test = train_test_split(\n    df.drop(['output'], axis=1),\n    df.output,\n    test_size= 0.2,  # 20% test data & 80% train data\n    random_state=0,\n    stratify=df.output\n)","e3eab154":"# Logistic regression\nfrom sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nclf.fit(X_train, y_train)\n\nfrom sklearn.metrics import accuracy_score\n\nY_pred = clf.predict(X_test)\nacc=accuracy_score(y_test, Y_pred)\nprint('Accuracy is',round(acc,2)*100,'%')","b2875f2d":"## Data Modelling","49cac283":"I will keep present the code as simple as possible, for beginners to understand.","ecdb1a6f":"There are no null values","11e999a2":"If you like the notebook, please consider upvotting. Thank you","dff749bb":"### Logistic regression","27b20d6d":"## Understanding the data","8c116977":"Looking at the data we can understand that the data need to be scaled, because some features have different ranges.","c553129d":"# Heart Attack Prediction","307af4b8":"## Feature Scaling","1fc200fd":"Feature scaling is a method used to normalize the range of independent variables or features of data. In data processing,"}}