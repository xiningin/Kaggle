{"cell_type":{"fd0b8530":"code","0e341062":"code","248b12a9":"code","7f208a08":"code","3e489f69":"code","c19cb6f9":"code","038a42a7":"code","9de3987c":"code","8ac4e7a4":"markdown","40d5fe0f":"markdown","16af3c5e":"markdown","bdc05417":"markdown","45a20389":"markdown","63ccf6af":"markdown","4ce562af":"markdown","63f3c87d":"markdown"},"source":{"fd0b8530":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport soundfile as sf\nimport librosa\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nimport IPython.display as ipd\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e341062":"sound, samplerate = sf.read(\"\/kaggle\/input\/linkin-park\/In_The_End-Linkin_Park.wav\")\nsound = sound[:,0]\n\nw_size = sound.shape[0]\/\/samplerate\nwindow = np.array_split(sound, w_size)\n\nfeatures = np.zeros(14)\nfor i in range(w_size):\n    \n    window = np.asfortranarray(sound[i*samplerate:(i+1)*samplerate])\n    flatness = librosa.feature.spectral_flatness(y=window)\n    rms = librosa.feature.rms(window)\n    rolloff = librosa.feature.spectral_rolloff(window)\n    mfcc = librosa.feature.mfcc(y=window,sr=samplerate,n_mfcc=5)\n    mfcc = mfcc[1:,:]\n    \n    f = np.hstack([flatness.mean(axis=1), flatness.std(axis=1), rms.mean(axis=1), rms.std(axis=1), rolloff.mean(axis=1), rolloff.std(axis=1), mfcc.mean(axis=1), mfcc.std(axis=1)])\n    features = np.vstack([features,f])\n    \nfeatures = features[1:,:]\nscl = StandardScaler()\nscl.fit(features)\nx = scl.transform(features)\n\n\ninertia = []\nclusters = range(2,20)\nfor n_c in clusters:\n    model = KMeans(n_clusters=n_c, random_state=42)\n    model.fit(x)\n    inertia.append(model.inertia_)\n\nplt.plot(clusters, inertia)","248b12a9":"clusteres = 5\nmodel = KMeans(n_clusters=clusteres, random_state=42)\nmodel.fit(x)\nlabels  = model.predict(x)\nplt.plot(labels)","7f208a08":"clusters = model.transform(x)\nP = (1\/(10**-6 + clusters)) \/ np.sum(1\/(10**-6 + clusters), axis=1, keepdims=1)\ndef transition_matrix(ndim, p_stay):\n  T = np.ones ( (ndim, ndim)) * ((1-p_stay)\/(ndim-1))\n  T *= 1-np.eye(ndim)\n  T += np.eye(ndim)*p_stay\n  return T\nT = transition_matrix(clusteres, .9)\nstates = librosa.sequence.viterbi(P.T, T)\nplt.plot(states)","3e489f69":"def get_soundfile(file, genre):\n    return sf.read(f\"\/kaggle\/input\/gtzan-genre-collection\/genres\/{genre}\/{file}\")\n\ndf = pd.read_csv(\"\/kaggle\/input\/trabalho-final-csv\/sound.csv\")\nrock=[]\nsrt_rock=[]\nhiphop=[]\nsrt_hiphop=[]\n\n\nfor i in range(len(df[\"file\"])):\n\n    x, y = get_soundfile(df[\"file\"][i] , df[\"genre\"][i])\n        \n    if(df[\"genre\"][i] == \"rock\"):\n        rock.append(x)\n        srt_rock.append(y)\n        \n    else:\n        hiphop.append(x)\n        srt_hiphop.append(y)\n        \nrms_rock=[]\nrms_hiphop=[]\ncentroid_rock=[]\ncentroid_hiphop=[]\nflatness_rock=[]\nflatness_hiphop=[]\n\nfor i in range(len(rock)):\n    rms_rock.append(librosa.feature.rms(y=rock[i]))\n    rms_hiphop.append(librosa.feature.rms(y=hiphop[i]))\n    centroid_rock.append(librosa.feature.spectral_centroid(y=rock[i]))\n    centroid_hiphop.append(librosa.feature.spectral_centroid(y=hiphop[i]))\n    flatness_rock.append(librosa.feature.spectral_flatness(y=rock[i]))\n    flatness_hiphop.append(librosa.feature.spectral_flatness(y=hiphop[i]))\n    \nfts = np.zeros((1,7))\n\nfor i in range(len(rock)):\n    f = np.hstack([rms_rock[i].max(), rms_rock[i].std(), centroid_rock[i].max(), centroid_rock[i].std(), flatness_rock[i].min(), flatness_rock[i].std(), \"rock\"])\n    fts=np.vstack([fts,f])\n    \nfor i in range(len(hiphop)):\n    f = np.hstack([rms_hiphop[i].max(), rms_hiphop[i].std(), centroid_hiphop[i].max(), centroid_hiphop[i].std(), flatness_hiphop[i].min(), flatness_hiphop[i].std(), \"hiphop\"])\n    fts=np.vstack([fts,f])\n    \nfts = fts[1:,:]\nDf = pd.DataFrame(data=fts)\nDf.head()","c19cb6f9":"x, y = Df.iloc[:,:-1], Df.iloc[:,-1]\ny, labels = pd.factorize(y)\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.1, random_state = 67)\n\nscaler = StandardScaler()\nscaler.fit(x_train)\nx_train = scaler.transform(x_train)\nx_test = scaler.transform(x_test)\n\ntrain_scores = np.zeros(0)\ntest_scores = np.zeros(0)\nknns = []\nfor i in range(1,10):\n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(x_train,y_train)\n    test_scores = np.hstack([test_scores, knn.score(x_test,y_test)])\n    knns.append(knn)\n\nplt.plot(range(1,10),test_scores,label=\"test score\")\nplt.xlabel('N\u00famero de Vizinhos')\nplt.ylabel('Taxa de Acertos')\nplt.legend()\nplt.show()","038a42a7":"knn = KNeighborsClassifier(n_neighbors=4)\nknn.fit(x,y)","9de3987c":"sound, samplerate = librosa.load(\"\/kaggle\/input\/linkin-park\/In_The_End-Linkin_Park.wav\")\nchanges = np.where(states[:-1] != states[1:])[0]\nmusica = []\n\nfor i in range(int(len(sound)\/samplerate)):\n    musica.append(sound[(i-1)*samplerate:(i*samplerate)])\nmusica.pop(0)\n\nif (changes[0]==0):\n    changes = np.delete(changes,0)\n\nseg_musica = []\nstart=0\n\nfor i in changes:\n    aux=np.zeros(0)\n    for j in range(start,i):\n        aux=np.hstack([aux,musica[j]])\n    start=i\n    seg_musica.append(aux)\n    \nprevisao=[]\n    \nfor trecho in seg_musica:\n\n    rms_trecho = librosa.feature.rms(y=trecho)\n    centroid_trecho=librosa.feature.spectral_centroid(y=trecho)\n    flatness_trecho=librosa.feature.spectral_flatness(y=trecho)\n    \n    fts_trecho=[rms_trecho.max(), rms_trecho.std(), centroid_trecho.max(), centroid_trecho.std(), flatness_trecho.min(), flatness_trecho.std()]\n    Df_trecho = pd.DataFrame([fts_trecho])\n    \n    previsao.append(knn.predict_proba(Df_trecho)[0])\n\nchance_rock=0\nchance_hiphop=0\n\nfor i in range(len(previsao)):\n    chance_rock += previsao[i][0]\n    chance_hiphop += previsao[i][1]\n    \nprint(\"A chance da musica ser um rock eh de: \"+ str(100*(chance_rock\/len(previsao))) +\"%\")\nprint(\"A chance da musica ser um hiphop eh de: \"+ str(100*(chance_hiphop\/len(previsao))) +\"%\")\n","8ac4e7a4":"Inicialmente, irei carregar a m\u00fasica, separar algumas features, e usar KMeans para dividir a m\u00fasica em partes. Para isso, usarei v\u00e1rios valores de cluster para ver qual o melhor a ser utilizado","40d5fe0f":"Nesse projeto, irei fazer a classifica\u00e7\u00e3o da m\u00fasica \"In The End - Linkin Park\", por meio de um aprendizado n\u00e3o-supervisionado para dividir a m\u00fasica em partes, e apredizado supervisionado para classificar cada uma dessas partes de acordo com labels pr\u00e9-definidas","16af3c5e":"Agora, irei carregar a m\u00fasica e separar suas partes de acordo com as divis\u00f5es do KMeans.\nFinalmente, calcularei as features de cada uma dessas partes, e utilizarei o resultado no modelo j\u00e1 treinado.","bdc05417":"Como se observa, com 4 vizinhos temos, aproximadamente, 85% de acerto, logo, utilizarei esse valor no treinamento do modelo.","45a20389":"Como pode se observar, o \"cotovelo\" do gr\u00e1fico est\u00e1 por volta do valor 5, sendo esse o valor que utilizarei no modelo do KMeans.","63ccf6af":"Aqui, utilizarei o filtro \"Viterbi\" para ficar menos sens\u00edveis a pequenas altera\u00e7\u00f5es de lebels da sa\u00edda do KMeans","4ce562af":"Agora utilizarei essas features no modelo de KNeighborsClassifier para treinamento e teste. Testarei v\u00e1rios valores de n_neighbors para achar o que d\u00e1 a melhor taxa de acerto.","63f3c87d":"A seguir, carregarei as m\u00fasicas que ser\u00e3o utilizadas para treinar o modelo, no caso, utilizarei os g\u00eaneros rock e hiphop para classificar a m\u00fasica em quest\u00e3o.\n\nVale ressaltar que ap\u00f3s alguns testes cheguei a conclus\u00e3o que as features que mais diferenciam os g\u00eaneros s\u00e3o:\n* rms      (max\/std)\n* centroid (max\/std)\n* flatness (min\/std)"}}