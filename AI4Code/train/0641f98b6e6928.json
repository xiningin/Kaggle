{"cell_type":{"a8952b75":"code","c73f4492":"code","4c0bbd29":"code","977ba596":"code","9769379e":"code","b437ebf2":"code","00097dbb":"code","12218eb5":"code","8984a528":"code","36373730":"code","d36a4a5b":"code","7876feda":"code","9f377511":"code","27540000":"code","6d10b52c":"code","6ebf2558":"code","42fc3b16":"code","cd5e53a4":"code","abe2cfa2":"code","ce8fbcdd":"code","74af5a7b":"code","c17fafb2":"markdown","ad7a7b8b":"markdown","a3c42fdf":"markdown","789e1035":"markdown","0e0f7804":"markdown"},"source":{"a8952b75":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c73f4492":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.stats import linregress\nimport matplotlib.pyplot as plt","4c0bbd29":"0,8.5,21.2,29.5,38,50,60.5,70.5,79.8,90.5,99,109.5,118.3,128.7,140.2,151,159.5,169.3,180.5,188.5,198.8\n2562,2591,2629,2652,2678,2706,2744,2764,2786,2811,2831,2852,2871,2890,2914,2935,2950,2967,2986,2998,3016\n\n2583,2610,2649,2672,2695,2726,2752,2784,2802,2827,2845,2866,2884,2905,2928,2946,2958,2980,2997,3009,3027\n\n2548,2574,2613,2636,2662,2692,2720,2745,2771,2796,2815,2836,2857,2877,2899,2920,2934,2953,2972,2986,2998\n","977ba596":"x1 = np.array([2562,2591,2629,2652,2678,2706,2744,2764,2786,2811,2831,2852,2871,2890,2914,2935,2950,2967,2986,2998,3016])\nx2= np.array([2583,2610,2649,2672,2695,2726,2752,2784,2802,2827,2845,2866,2884,2905,2928,2946,2958,2980,2997,3009,3027])\nx3=np.array([2548,2574,2613,2636,2662,2692,2720,2745,2771,2796,2815,2836,2857,2877,2899,2920,2934,2953,2972,2986,2998])\n\nxdata=((x1+x2+x3)\/3)\n\nydata=np.array([0,8.5,21.2,29.5,38,50,60.5,70.5,79.8,90.5,99,\n                109.5,118.3,128.7,140.2,151,159.5,169.3,180.5,188.5,198.8])\n\n#\nslope, intercept, r_value, p_value, std_err = linregress(xdata,ydata)\nprint('slope_value',slope,'intercept_value',intercept)","9769379e":"# Raw values\nxdata=np.array([2562,2591,2629,2652,2678,2706,2744,2764,\n                2786,2811,2831,2852,2871,2890,2914,2935,\n                2950,2967,2986,2998,3016,2583,2610,2649,2672,2695,\n                2726,2752,2784,2802,2827,2845,2866,2884,2905,\n                2928,2946,2958,2980,2997,3009,3027,2548,2574,2613,\n                2636,2662,2692,2720,2745,2771,2796,2815,2836,2857,\n                2877,2899,2920,2934,2953,2972,2986,2998])\n\n# measure References\nydata=np.array([0,8.5,21.2,29.5,38,50,60.5,70.5,79.8,90.5,99,\n                109.5,118.3,128.7,140.2,151,159.5,169.3,180.5,188.5,198.8,\n                0,8.5,21.2,29.5,38,50,60.5,70.5,79.8,90.5,99,\n                109.5,118.3,128.7,140.2,151,159.5,169.3,180.5,188.5,198.8,\n                0,8.5,21.2,29.5,38,50,60.5,70.5,79.8,90.5,99,\n                109.5,118.3,128.7,140.2,151,159.5,169.3,180.5,188.5,198.8])\n\n#\nslope, intercept, r_value, p_value, std_err = linregress(xdata,ydata)\nprint('slope_value',slope,'intercept_value',intercept)","b437ebf2":"xdata","00097dbb":"# check results compare with references values.\n# ([50,55,60,65,70,75,80,85,92])\n#x=np.array([574,589,604,620,628,641,651,663,680])\ny = slope * xdata + intercept\nprint('check_results',y)","12218eb5":"ydata","8984a528":"#plot \nplt.plot(xdata,ydata,'b+',label='data')\nplt.plot(xdata,y,'r')","36373730":"adc = np.array([2871,2884, 2857])\nreal_T  =  slope * adc + intercept\nprint('expected_values: 118.3',real_T)","d36a4a5b":"real_T = 0\nxraw   = (real_T - intercept)\/slope\nprint('raw_value',xraw)","7876feda":"mymodel = np.poly1d(np.polyfit(xdata, ydata, 4))","9f377511":"mymodel\ny= 3.55359818e-04*xdata**2  -1.54946197e+00*xdata + 1.63849360e+03","27540000":"plt.plot(xdata,ydata,'r+',label='data')\n#plt.scatter(x3, mymodel(x3))\nplt.scatter(xdata, y)\nplt.show()","6d10b52c":"from sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.linear_model import LinearRegression \n\npoly = PolynomialFeatures(degree = 4)\nx= xdata.reshape(-1, 1)\nX_poly = poly.fit_transform(x) \n#poly.fit(x, ydata) \nlin2 = LinearRegression() \nlin2.fit(X_poly, y) \nlin2.coef_","6ebf2558":"# Visualising the Polynomial Regression results \nplt.scatter(x, ydata, color = 'blue') \n  \nplt.plot(x, lin2.predict(X_poly),'r+')\n\nplt.title('Polynomial Regression') \nplt.xlabel('Temperature') \nplt.ylabel('Pressure') \n  \nplt.show() ","42fc3b16":"from sklearn.preprocessing import PolynomialFeatures \nfrom sklearn.linear_model import LinearRegression ","cd5e53a4":"#outside_T= np.array([20,15,10,0,-10,-20])\n#supply_T= np.array([20,40,45,55,59,61])\noutside_T= np.array([20,15,10,5,0,-5,-10,-15,-20])\nsupply_T= np.array([20,40,45,51,55,57,59,60,62])\n\n# modify up\n\noutside_T_up= np.array([20,15,10,2,-3,-7,-10,-15,-20])\n#supply_T= np.array([20,45,55,59,61])\n\n# modify down\n\noutside_T_down= np.array([20,15,10,7,3,0,-10,-15,-20])\n#supply_T= np.array([20,45,55,59,61])","abe2cfa2":"poly = PolynomialFeatures(degree = 4)\npoly_u = PolynomialFeatures(degree = 4)\npoly_d = PolynomialFeatures(degree = 4)\n\n# original curve\no = outside_T.reshape(-1, 1)\nO_poly = poly.fit_transform(o) \npoly.fit(x, ydata) \nlin_o = LinearRegression() \nlin_o.fit(O_poly, supply_T) \n#lin2.coef_\n\n# up curve\n\nu = outside_T_up.reshape(-1, 1)\nU_poly = poly_u.fit_transform(u) \npoly.fit(x, ydata) \nlin_u = LinearRegression() \nlin_u.fit(U_poly, supply_T) \n\n# down curve\n\nd = outside_T_down.reshape(-1, 1)\nD_poly = poly_d.fit_transform(d) \n#poly.fit(x, ydata) \nlin_d = LinearRegression() \nlin_d.fit(D_poly, supply_T) \n\n","ce8fbcdd":"# Visualising the Polynomial Regression results \nf = plt.figure()\nplt.figure(figsize=(15,6))\n\n#plt.plot(outside_T, supply_T, color = 'blue')\n#plt.plot(outside_T_up, supply_T, color = 'blue')\n#plt.plot(outside_T_down, supply_T)\nplt.plot(o, lin_o.predict(O_poly),'r')\nplt.plot(u, lin_u.predict(U_poly),'go')\nplt.plot(d, lin_d.predict(D_poly),'k+')\n\nplt.gca().invert_xaxis()\n\n#ax = f.add_subplot(111)\n#ax.yaxis.tick_right()\n\nplt.title('Polynomial Regression') \nplt.xlabel('Temperature') \nplt.ylabel('Pressure') \n  \nplt.show() ","74af5a7b":"'''\nfrom scipy.interpolate import make_interp_spline, BSpline\n\n# 300 represents number of points to make between T.min and T.max\nT_sort=np.sort(outside_T)\nTnew = np.linspace(T_sort.min(), T_sort.max(), 300) \nspl = make_interp_spline(T_sort, supply_T,k=1)\nT_smooth = spl(Tnew)\nT_reverse = np.sort(Tnew).flatten()[::-1]\n\n\n#plt.plot(T_reverse,T_smooth)\n#plt.plot(o, lin_o.predict(O_poly),'r+')\nplt.figure(figsize=(20,8))\n\nplt.plot(T_reverse,T_smooth)\nplt.plot(u, lin_u.predict(U_poly),'gx')\nplt.plot(d, lin_d.predict(D_poly),'ko')\n\nplt.gca().invert_xaxis()\n\nplt.show()\n'''","c17fafb2":"### check 1 points\n> Add raw value to x, check the results from the measures Temp","ad7a7b8b":"slope_value 0.44937916996666316 intercept_value -1172.4545123175378\n\n","a3c42fdf":"118.3  (average : expected_values: 118.3 [124.09904541 129.84436715 117.91177585])\n       (data points:  expected_values: 118.3 [123.88946658 129.58562044 117.75514703])\n2871\n2884\n2857","789e1035":"# Polinomial heat curve","0e0f7804":"https:\/\/www.ritchieng.com\/machine-learning-polynomial-regression\/"}}