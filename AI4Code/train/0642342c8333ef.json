{"cell_type":{"92d01998":"code","3b1f6438":"code","6b941bff":"code","2e4d8ed8":"code","293227ce":"code","10f17cd5":"markdown","014f8d88":"markdown"},"source":{"92d01998":"!pip install pyspark","3b1f6438":"!apt-get update -qq\n!apt-get install openjdk-8-jdk-headless -qq > \/dev\/null\n!wget -q https:\/\/archive.apache.org\/dist\/spark\/spark-3.1.2\/spark-3.1.2-bin-hadoop2.7.tgz\n!tar xf spark-3.1.2-bin-hadoop2.7.tgz\n!pip install -q findspark","6b941bff":"import os\nos.environ[\"JAVA_HOME\"] = \"\/usr\/lib\/jvm\/java-8-openjdk-amd64\"\nos.environ[\"SPARK_HOME\"] = \"\/content\/spark-3.1.2-bin-hadoop2.7\"","2e4d8ed8":"import findspark\nfindspark.init()","293227ce":"from pyspark.sql import SparkSession\n\nspark = SparkSession.builder \\\n    .master('local[*]') \\\n    .appName(\"Iniciando com Spark\") \\\n    .getOrCreate()","10f17cd5":"# **Ready to run, you can also use this same coding for google colaboratory.**","014f8d88":"# **If you find this notebook useful, support with an upvote** \ud83d\udc4d\n"}}