{"cell_type":{"a31ca056":"code","4379c1b9":"code","f496aeb0":"code","7d9f68b0":"code","6cede411":"code","ddb931b4":"code","210e2899":"code","d5a735f5":"code","bc723e6a":"code","71fdf2c3":"code","d67846b0":"code","ce50abcf":"code","dedac545":"code","6ed6509c":"code","54d346ce":"code","189d5af3":"code","fdb1839b":"code","d1e668d0":"code","b68fc1be":"code","4f940d41":"code","b14d3ac0":"code","f858512e":"code","b4b1e234":"markdown","bbb8213e":"markdown","e1c5867b":"markdown","cb641429":"markdown","d899ce36":"markdown","f0b693c7":"markdown","2bfad90e":"markdown","0bbf460f":"markdown","dd7fc40c":"markdown","3fd47ec7":"markdown","77201b52":"markdown","db1fb2b0":"markdown","8416ee0f":"markdown","dcd949aa":"markdown"},"source":{"a31ca056":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\nimport matplotlib.pyplot as plt \nfrom sklearn import preprocessing\n\nfrom xgboost import XGBClassifier\nfrom catboost import CatBoostClassifier, cv, Pool\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4379c1b9":"train = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/train.csv\")\ntest = pd.read_csv(\"..\/input\/tabular-playground-series-dec-2021\/test.csv\")","f496aeb0":"cols_with_missing = [col for col in train.columns if train[col].isnull().any()]\nprint(cols_with_missing)\ncols_with_missing = [col for col in test.columns if test[col].isnull().any()]\nprint(cols_with_missing)","7d9f68b0":"s = (train.dtypes == 'object')\nobject_cols = list(s[s].index)\n\ns_ = (test.dtypes == 'object')\nobject_cols_ = list(s[s].index)\n\nprint(\"train Categorical variables:\")\nprint(object_cols)\nprint(\"test Categorical variables:\")\nprint(object_cols_)","6cede411":"print(train.shape,test.shape)\n\nfor r in range(7):\n    ct = (train['Cover_Type'] == r+1) \n    ratio = ct.sum()*100\/ len(train)\n    print('Cover_Type=',str(r+1),' is :',ct.sum(),'    ratio is:',ratio,'%')","ddb931b4":"train.drop(train.index[train['Cover_Type'] == 5],inplace = True)","210e2899":"train.describe().T","d5a735f5":"train.drop(['Soil_Type7','Soil_Type15'],axis = 1,inplace = True)\ntest.drop(['Soil_Type7','Soil_Type15'],axis = 1,inplace = True)\nprint(train.shape,test.shape)","bc723e6a":"number_colums = [ 'Elevation','Aspect', 'Slope',\n       'Horizontal_Distance_To_Hydrology', 'Vertical_Distance_To_Hydrology',\n       'Horizontal_Distance_To_Roadways', 'Hillshade_9am', 'Hillshade_Noon',\n       'Hillshade_3pm', 'Horizontal_Distance_To_Fire_Points']\ncategorical_colums1 = ['Wilderness_Area1', 'Wilderness_Area2', 'Wilderness_Area3','Wilderness_Area4'] \ncategorical_colums2 = ['Soil_Type1', 'Soil_Type2', 'Soil_Type3',\n       'Soil_Type4', 'Soil_Type5', 'Soil_Type6',  'Soil_Type8',\n       'Soil_Type9', 'Soil_Type10', 'Soil_Type11', 'Soil_Type12',\n       'Soil_Type13', 'Soil_Type14',  'Soil_Type16',\n       'Soil_Type17', 'Soil_Type18', 'Soil_Type19', 'Soil_Type20',\n       'Soil_Type21', 'Soil_Type22', 'Soil_Type23', 'Soil_Type24',\n       'Soil_Type25', 'Soil_Type26', 'Soil_Type27', 'Soil_Type28',\n       'Soil_Type29', 'Soil_Type30', 'Soil_Type31', 'Soil_Type32',\n       'Soil_Type37', 'Soil_Type38', 'Soil_Type39', 'Soil_Type40']","71fdf2c3":"train[\"f_c1\"] = train[categorical_colums1].sum(axis=1)\ntrain[\"f_c2\"] = train[categorical_colums2].sum(axis=1)\n\n\ntest[\"f_c1\"] = test[categorical_colums1].sum(axis=1)\ntest[\"f_c2\"] = test[categorical_colums2].sum(axis=1)\n","d67846b0":"mm = preprocessing.MinMaxScaler()\n\n# mm.fit_transform(l)\n# ValueError: Expected 2D array, got 1D array instead:\ntrain_a=train.drop(['Id','Cover_Type'],axis = 1)\nl_2d_min_max = mm.fit_transform(train_a)\ndf = pd.DataFrame(data=l_2d_min_max, columns=train_a.columns)\nl_2d_min_max_t = mm.fit_transform(test[number_colums])\ndf_t = pd.DataFrame(data=l_2d_min_max_t, columns=number_colums)\n\ntrain[\"max\"] = df.max(axis=1)\ntrain[\"std\"] = df.std(axis=1)\ntrain[\"mean\"] = df.mean(axis=1)\ntrain[\"sum\"] = df.sum(axis=1)\n\ntest[\"max\"] = df_t.max(axis=1)\ntest[\"std\"] = df_t.std(axis=1)\ntest[\"mean\"] = df_t.mean(axis=1)\ntest[\"sum\"] = df_t.sum(axis=1)","ce50abcf":"X=train.drop(['Id','Cover_Type'],axis = 1)\ny = train.Cover_Type\n\n#Separate data into training and validation sets\nX_train, X_valid, y_train, y_valid = train_test_split(X, y, train_size=0.8, test_size=0.2,random_state=0)","dedac545":"model_classifier = XGBClassifier(objective='multi:softmax',eval_metric = 'mlogloss')\nmodel_classifier.fit(X_train, y_train)","6ed6509c":"predict_classifier = model_classifier.predict(X_valid)\ny_reshape=np.ravel(y_valid)\nc = 0\ne = 0\nct1 = 0\nct2 = 0\nct3 = 0\nct4 = 0\nct5 = 0\nct6 = 0\nct7 = 0\nct0 = 0\ngerrorlist = []\n\nfor r in range(y_reshape.size):\n        if y_reshape[r]==predict_classifier[r]:\n            c = c + 1\n        if y_reshape[r]!=predict_classifier[r]:\n            gerrorlist.append(r)\n            e = e + 1\n            if y_reshape[r] == 1:\n                ct1 = ct1 + 1\n            elif y_reshape[r] == 2:\n                ct2 = ct2 + 1\n            elif y_reshape[r] == 3:\n                ct3 = ct3 + 1\n            elif y_reshape[r] == 4:\n                ct4 = ct4 + 1\n            elif y_reshape[r] == 5:\n                ct5 = ct5 + 1\n            elif y_reshape[r] == 6:\n                ct6 = ct6 + 1\n            elif y_reshape[r] == 7:\n                ct7 = ct7 + 1\n            else:\n                ct0 = ct0 + 1\n\n                \nratio1 = ct1*100\/e\nratio2 = ct2*100\/e\nratio3 = ct3*100\/e\nratio5 = ct5*100\/e\nratio4 = ct4*100\/e\nratio6 = ct6*100\/e\nratio7 = ct7*100\/e\n\nprint('correct count is',c)\nprint('error count is',e)\nprint('1 is :',ct1 ,'    ratio is:',ratio1,'%')\nprint('2 is :',ct2 ,'    ratio is:',ratio2,'%')\nprint('3 is :',ct3 ,'    ratio is:',ratio3,'%')\nprint('4 is :',ct4 ,'    ratio is:',ratio4,'%')\nprint('5 is :',ct5 ,'    ratio is:',ratio5,'%')\nprint('6 is :',ct6 ,'    ratio is:',ratio6,'%')\nprint('7 is :',ct7 ,'    ratio is:',ratio7,'%')","54d346ce":"plt.figure(figsize=(10,20))\n\nimportances = pd.Series(model_classifier.feature_importances_, index = X.columns)\nimportances = importances.sort_values()\nimportances.plot(kind = \"barh\")\nplt.title(\"importance in the XGBClassifier Model\")\n\nplt.show()","189d5af3":"model_catclassifier = CatBoostClassifier(use_best_model = True, random_seed = 42)\nmodel_catclassifier.fit(X_train, y_train, eval_set= (X_valid, y_valid), early_stopping_rounds=100,verbose = False)","fdb1839b":"predict_classifier = model_catclassifier.predict(X_valid)\ny_reshape=np.ravel(y_valid)\nc = 0\ne = 0\nct1 = 0\nct2 = 0\nct3 = 0\nct4 = 0\nct5 = 0\nct6 = 0\nct7 = 0\nct0 = 0\ncerrorlist = []\n\nfor r in range(y_reshape.size):\n        if y_reshape[r]==predict_classifier[r]:\n            c = c + 1\n        if y_reshape[r]!=predict_classifier[r]:\n            gerrorlist.append(r)\n            e = e + 1\n            if y_reshape[r] == 1:\n                ct1 = ct1 + 1\n            elif y_reshape[r] == 2:\n                ct2 = ct2 + 1\n            elif y_reshape[r] == 3:\n                ct3 = ct3 + 1\n            elif y_reshape[r] == 4:\n                ct4 = ct4 + 1\n            elif y_reshape[r] == 5:\n                ct5 = ct5 + 1\n            elif y_reshape[r] == 6:\n                ct6 = ct6 + 1\n            elif y_reshape[r] == 7:\n                ct7 = ct7 + 1\n            else:\n                ct0 = ct0 + 1\n\nratio1 = ct1*100\/e\nratio2 = ct2*100\/e\nratio3 = ct3*100\/e\nratio5 = ct5*100\/e\nratio4 = ct4*100\/e\nratio6 = ct6*100\/e\nratio7 = ct7*100\/e\n\nprint('correct count is',c)\nprint('error count is',e)\nprint('1 is :',ct1 ,'    ratio is:',ratio1,'%')\nprint('2 is :',ct2 ,'    ratio is:',ratio2,'%')\nprint('3 is :',ct3 ,'    ratio is:',ratio3,'%')\nprint('4 is :',ct4 ,'    ratio is:',ratio4,'%')\nprint('5 is :',ct5 ,'    ratio is:',ratio5,'%')\nprint('6 is :',ct6 ,'    ratio is:',ratio6,'%')\nprint('7 is :',ct7 ,'    ratio is:',ratio7,'%')","d1e668d0":"plt.figure(figsize=(10,20))\n\nimportances = pd.Series(model_catclassifier.feature_importances_, index = X.columns)\nimportances = importances.sort_values()\nimportances.plot(kind = \"barh\")\nplt.title(\"importance in the CatBoostClassifier Model\")\n\nplt.show()","b68fc1be":"cont_features = ['Elevation','Horizontal_Distance_To_Fire_Points','Horizontal_Distance_To_Roadways', 'Wilderness_Area3','f_c2','max']\nprint(\"Feature distribution of important columns : \")\nncols = 3\nnrows = 2\n\nfig, axes = plt.subplots(nrows, ncols, figsize=(40,10), facecolor='#EAEAF2')\n\nfor r in range(nrows):\n    for c in range(ncols):\n        col = cont_features[r*ncols+c]\n        sns.kdeplot(x=train[col], ax=axes[r, c], color='red', label='Train data')\n        sns.kdeplot(x=test[col], ax=axes[r, c], color='blue', label='Test data')\n        axes[r, c].set_ylabel('')\n        axes[r, c].set_xlabel(col, fontsize=15, fontweight='bold')\n        axes[r, c].tick_params(labelsize=10, width=0.5)\n        axes[r, c].xaxis.offsetText.set_fontsize(20)\n        axes[r, c].yaxis.offsetText.set_fontsize(20)\nplt.show()","4f940d41":"test_target = test.drop(['Id'],axis = 1)\nint_predict = model_catclassifier.predict(test_target)","b14d3ac0":"int_predict = np.ravel(int_predict)","f858512e":"output = pd.DataFrame({'Id': test.Id, 'Cover_Type': int_predict})\noutput.to_csv('submission.csv', index=False)","b4b1e234":"# check data state","bbb8213e":"# From the above, I think\n\n1. catboost is better than xgboost a littele bit\u3000\n2. predict error ratio with 'Cover_Type' is almost same at catboost and xgboost\n3. it is interesting most important columns is same 'Elevation' but second , third or other colums is different order. and they have almost same prediction(=99.8% is same)","e1c5867b":"i will drop colums 'Soil_Type7' and 'Soil_Type15' because they have only '0'","cb641429":"train and test have integer only","d899ce36":"**prepare training data**","f0b693c7":"# read train and test dataset","2bfad90e":"train and test data is almost same at important columns in catboost model so it will work to predict testdata","0bbf460f":"kind of Cover_Type is 7 and Cover_Type='2' is most","dd7fc40c":"# create model with using XGBClassifier","3fd47ec7":"# check train and test data situation at Top6 importance columns in catboost model","77201b52":"# create model with using CatBoostClassifier","db1fb2b0":"# make some columns group \ncontinuous and categorical, in categorical i will make 2groups depends on columns name","8416ee0f":"**add some more feature columns**","dcd949aa":"train and test have no missing value"}}