{"cell_type":{"1f1267da":"code","a584775a":"code","f1573e4d":"code","d7d162a0":"code","3f283546":"code","0897e29f":"code","ac77a157":"code","1cd69402":"code","2ca3e21e":"code","ef8b7d9a":"code","bf6b5b3d":"code","76255168":"code","8943671c":"code","7f75e87d":"code","a019b123":"code","33223a8a":"code","53c05ef1":"markdown","50e37429":"markdown","bab4ff65":"markdown","932b76b9":"markdown","2072a624":"markdown","e68167e0":"markdown","47f80385":"markdown","d392a250":"markdown","aba03c1d":"markdown","3dd6ff05":"markdown"},"source":{"1f1267da":"import pandas as pd\nimport numpy as np\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')","a584775a":"\nnum_classes = 10\nx_train = train.drop('label', axis = 1)\ny_train = train['label']\n\n# visualization of label count\ng = sns.countplot(y_train)\ny_train.value_counts()\n","f1573e4d":"y_train.isnull().sum()","d7d162a0":"x_test = test\n\nx_train = x_train.to_numpy()\ny_train = y_train.to_numpy()\n\n\n\ny_train = keras.utils.to_categorical(y_train, num_classes)\nx_test = x_test.to_numpy()\n\nx_train = x_train.reshape(-1, 28, 28, 1)\nx_test = x_test.reshape(-1, 28, 28, 1)","3f283546":"\nx_train_normal = x_train\/ 255.0\nx_test_normal = x_test \/ 255.0\n\n","0897e29f":"from keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D\nfrom keras.layers.normalization import BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import train_test_split\nbatch_size = 64\nnum_classes = 10\nepochs = 20\ninput_shape = (28, 28, 1)\n\n","ac77a157":"# datagen will randomly generate rotated, zoomed, shifted image\ndatagen = ImageDataGenerator(\n        rotation_range=15, # randomly rotate images in the range (degrees, 0 to 180)\n        zoom_range = 0.1, # Randomly zoom image \n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n)  ","1cd69402":"X_train3 = x_train_normal[9,].reshape((1,28,28,1))\nY_train3 = y_train[9,].reshape((1,10))\nplt.figure(figsize=(15,4.5))\nfor i in range(30):  \n    plt.subplot(3, 10, i+1)\n    X_train2, Y_train2 = datagen.flow(X_train3,Y_train3).next()\n    plt.imshow(X_train2[0].reshape((28,28)),cmap=plt.cm.binary)\n    plt.axis('off')\n    if i==9: X_train3 = x_train[11,].reshape((1,28,28,1))\n    if i==19: X_train3 = x_train[18,].reshape((1,28,28,1))\nplt.subplots_adjust(wspace=-0.1, hspace=-0.1)\nplt.show()","2ca3e21e":"# model1 and model 2 have same structure, but model1 will be trained with image augmentation, and model2 will be trained\n# without image augmentation\nmodel1 = Sequential()\nmodel1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=[28, 28, 1]))\nmodel1.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel1.add(MaxPool2D((2, 2)))\nmodel1.add(Dropout(0.20))\nmodel1.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel1.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel1.add(MaxPool2D(pool_size=(2, 2)))\nmodel1.add(Dropout(0.25))\nmodel1.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel1.add(Dropout(0.25))\nmodel1.add(Flatten())\nmodel1.add(Dense(128, activation='relu'))\nmodel1.add(BatchNormalization())\nmodel1.add(Dropout(0.25))\nmodel1.add(Dense(num_classes, activation='softmax'))\n\nmodel1.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])\n\n\nmodel2 = Sequential()\nmodel2.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal',input_shape=[28, 28, 1]))\nmodel2.add(Conv2D(32, kernel_size=(3, 3),activation='relu',kernel_initializer='he_normal'))\nmodel2.add(MaxPool2D((2, 2)))\nmodel2.add(Dropout(0.20))\nmodel2.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel2.add(Conv2D(64, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel2.add(MaxPool2D(pool_size=(2, 2)))\nmodel2.add(Dropout(0.25))\nmodel2.add(Conv2D(128, (3, 3), activation='relu',padding='same',kernel_initializer='he_normal'))\nmodel2.add(Dropout(0.25))\nmodel2.add(Flatten())\nmodel2.add(Dense(128, activation='relu'))\nmodel2.add(BatchNormalization())\nmodel2.add(Dropout(0.25))\nmodel2.add(Dense(num_classes, activation='softmax'))\n\nmodel2.compile(loss=keras.losses.categorical_crossentropy,\n              optimizer=keras.optimizers.RMSprop(),\n              metrics=['accuracy'])\n\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc', \n                                            patience=3, \n                                            verbose=1, \n                                            factor=0.5, \n                                            min_lr=0.0001)\n","ef8b7d9a":"from sklearn.model_selection import train_test_split\nx_train_normal_split, x_valid_normal, y_train_split, y_valid = train_test_split(x_train_normal, y_train, test_size = 0.2, random_state=42)","bf6b5b3d":"datagen.fit(x_train_normal_split)\n# fitting model with image augmentation\nh1 = model1.fit(datagen.flow(x_train_normal_split,y_train_split, batch_size=batch_size),\n                              epochs = epochs, validation_data = (x_valid_normal,y_valid),\n                              verbose = 1, steps_per_epoch=x_train_normal_split.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction],) \n\n\n# fitting model without image augmentation\nh2 = model2.fit(x_train_normal_split,y_train_split, batch_size=batch_size,\n                              epochs = epochs, validation_data = (x_valid_normal,y_valid),\n                              verbose = 1, steps_per_epoch=x_train_normal_split.shape[0] \/\/ batch_size\n                              , callbacks=[learning_rate_reduction],) #without augmentation\n","76255168":"result_with_augmentation = model1.predict(x_test_normal)\nresult_without_augmentation = model2.predict(x_test_normal)","8943671c":"result_with_augmentation_int = np.argmax(result_with_augmentation, axis = 1)\nresult_without_augmentation_int = np.argmax(result_without_augmentation, axis = 1)\nprint(result_with_augmentation_int)","7f75e87d":"submission_with_augmentation = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\nsubmission_without_augmentation = pd.read_csv('..\/input\/digit-recognizer\/sample_submission.csv')\n","a019b123":"submission_with_augmentation['Label'] = result_with_augmentation_int\nsubmission_without_augmentation['Label'] = result_without_augmentation_int","33223a8a":"submission_with_augmentation.to_csv(\"\/kaggle\/working\/with_augmentation.csv\", index=False)\nsubmission_without_augmentation.to_csv(\"\/kaggle\/working\/without_augmentation.csv\", index=False)\nprint(\"making csv complete\")","53c05ef1":"# CNN with\/without augmentation\n\nIn this notebook, we will use simple CNN neural network, and compare result between with\/without using image preprocessing\n\n*data augmentation*  means randomly shifting\/ rotating\/ flipping\/ lighting your images. It reduces overfitting, and helps to get better results. \n\n\n\n","50e37429":"# change data type, normalizing","bab4ff65":"# Making CSV file","932b76b9":"### we did not flip images because it can make confusions between numbers like 6 and 9","2072a624":"# Load data","e68167e0":"# Comparing results with\/without augmentation\n\n![kaggle_result.PNG](attachment:8ae2a670-d781-49cd-9fcf-ba7ca359e891.PNG)\n\n\n# Thank you for reading this notebook!","47f80385":"# Preparing and training model!","d392a250":"# check how labels are distributed","aba03c1d":"# checking whether there is NanValue in label counts","3dd6ff05":"# Data augmentation visualization"}}