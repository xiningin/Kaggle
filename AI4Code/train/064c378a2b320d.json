{"cell_type":{"cf1108df":"code","69a3c14f":"code","748869f2":"code","df99ad6f":"code","94f6c3b6":"code","be1e6383":"code","4bf4a801":"code","91ccfc35":"code","cf751439":"code","9e143d26":"code","6242553e":"code","8adf8f5d":"code","d4df4991":"code","8a7ad80e":"code","72c67911":"code","bd24cd6f":"code","1c782a6c":"code","c5f288c2":"code","cca3f7a0":"code","4f70b393":"code","500b272e":"code","be77e588":"code","a9154579":"code","64055649":"code","02b31981":"code","34cd337a":"code","fa26247d":"code","2c9b341a":"code","8ce2e5e0":"code","a3a45fd3":"code","83600edc":"code","9e32c8dd":"code","f70b3c21":"code","03d41719":"code","023c13ef":"code","77e07fbb":"code","78c3d0ef":"code","1c3acacb":"code","904843ea":"code","954e37b8":"code","0fbc7a26":"code","19d22287":"code","5d6107b2":"code","09f0a355":"markdown","45d5cfa4":"markdown","28fde1dd":"markdown","e6a821ed":"markdown","cec3dee4":"markdown","98f7e974":"markdown","4724b8ab":"markdown","6e81cb73":"markdown","b7273cd3":"markdown","cc27c66c":"markdown","6d243a23":"markdown","c7badb11":"markdown","c3b5b27c":"markdown","59e3757c":"markdown"},"source":{"cf1108df":"import json\nimport csv\nimport requests\nimport pandas as pd\nimport numpy as np\nfrom copy import deepcopy\nimport matplotlib.pyplot as plt\nimport matplotlib\nfrom math import log,exp\nimport seaborn as sns\nplt.rcParams[\"figure.figsize\"]=20,10","69a3c14f":"states_data=pd.read_csv('..\/input\/coviddata-indianstate-wise-dec12csv\/state_wise.csv')\n#states_data\nstates_data=states_data.drop(['Last_Updated_Time','Migrated_Other','State_code','Delta_Confirmed', 'Delta_Deaths',\n                              'Delta_Recovered', 'State_Notes'], axis=1)\nstates_data","748869f2":"tested=pd.read_csv('..\/input\/coviddata-indianstate-wise-dec18csv\/statewise_tested_numbers_data.csv')\ntested=tested.drop(['Updated On', 'RT-PCR Test(Includes TrueNat,CBNAAT,CRISPR)','RAT(Rapid Antigen Test)','Other Tests'],axis=1)\ntested\ntested=tested.drop(tested.columns[2:], axis=1)","df99ad6f":"tested=tested.dropna()\ntested=tested.drop_duplicates(subset=['State'],keep='last')\n","94f6c3b6":"total=states_data.iloc[0]\n\nstates_data=states_data.merge(tested, how='left')\nstates_data=states_data.dropna()\nstates_data=states_data.rename({'Total Tested':'Total_Tested'}, axis='columns')\nstates_data","be1e6383":"pop=[123144223,67562686,53903393,77841267,237882725,35699443,18710922,99609303,46356334,39362732,124799926,81032689,35607039,29436231\n,28204692,63872399,85358965,30141373,38593948,13606320,11250858,1586250,1413542,4169794,7451955,3091545,1570458,1158473,3366710,\n2249695,289023,417036,690251,615724,1239244,\n]\nstates_data['Total_Population']=pop\nstates_data=states_data.sort_values('State')\n","4bf4a801":"\nTotal_beds=[915+258+165+24,85777+16607+16902+4846,1449+1403+172+62,24784+5746+1682+396,28440+8173+6814+650,2789+650+885+113,\n           18013+4218+1544 + 722,628+560 +200 +46 +229 +330 +139 +21,19929+5790+10023+2617,1410+268+178+134,38741+11410+14708+4942,\n            27905+28381+5985+2227,3109+304+763+86,19058+4364+3213+436,13885+4014+3185+393,92780+46515+17162+4963,25838+13860+4082+2822,\n            246+30+109+37,37233+32861+14616+2673,200266+149917+56737+14866,2315+156+358+47,1552+660+345+83,\n            2370+361+308+44,536+145+142+54,17088+13118+4129+554,901+427+339+110,14187+12648+4266+1643,26365+16817+8449+1797,\n            842+223+229+20,127162+64189+25409+8439,14814+790+2794+1782,1856+202+230+74,150384+4044+11413+4256,\n            19864+10771+2174+481,14127+56465+12635+1284]\n\nstates_data['Total_beds']=Total_beds\nstates_data.columns=states_data.columns.str.strip()\nstates_data","91ccfc35":"states_data['test_rate']=states_data['Total_Tested']*100\/states_data['Total_Population']","cf751439":"states_data['mortality_rate']=states_data['Deaths']*100\/states_data['Confirmed']","9e143d26":"states_data['Positivity_ratio']=states_data['Confirmed']*100\/states_data['Total_Tested']","6242553e":"states_data['Beds_per_hundred']=states_data['Total_beds']*(100)\/states_data['Confirmed']\nstates_data","8adf8f5d":"test_data=deepcopy(states_data)\ntest_data=test_data.drop(['Confirmed','Recovered','Deaths','Active','Total_Tested','Total_beds'], axis=1)\ntest_data_big = test_data[test_data['Total_Population'] >= 10000000]\ntest_data_small = test_data[test_data['Total_Population'] < 10000000]\ntest_data=test_data.drop(['Total_Population'], axis=1)\ntest_data_big=test_data_big.drop(['Total_Population'], axis=1)\ntest_data_small=test_data_small.drop(['Total_Population'], axis=1)","d4df4991":"test_data","8a7ad80e":"test_data_big","72c67911":"test_data_small","bd24cd6f":"def topsis(df1, weights, impacts):\n    df=deepcopy(df1)\n    for i in impacts:\n        if i!='+' and i!='-':\n            print(\"Impacts contain foriegn values. Please try again with '+' and '-' ONLY. Seperate them using commas ONLY. \")\n            return\n    if len(weights)!=len(impacts):\n        print(\"Number of weights and impacts are different. Please try again.\")\n        return\n    if (len(df.columns)-1) != len(weights):\n        print(\"Number of weights and attributes are not the same. try again\")\n        return\n    \n    if df.shape[0]<3:\n        print(\"There is only one model in the input. Please try again.\")\n    \n    root_sum_sq=[]\n    for i in df.columns[1:]:\n        total=0\n        for j in list(df[i]):\n            total+=(j**2)\n        root_sum_sq.append(total**(0.5))\n    for index,i in enumerate(df.columns[1:]):\n        for j in df[i]:\n            df[i]=df[i].replace(j,j*(weights[index]\/sum(weights))\/root_sum_sq[index])\n    print(\"Normalized weighted Confusion matrix is: \")\n    with pd.option_context('expand_frame_repr', False):\n        print (df)\n    ideal=[]\n    for index,i in enumerate(df.columns[1:]):\n        if impacts[index]=='-':\n            ideal_best=min(df[i])\n            ideal_worst=max(df[i])\n        else:\n            ideal_best=max(df[i])\n            ideal_worst=min(df[i])\n\n        ideal.append((ideal_best, ideal_worst))\n    n=len(df.index)\n    tp=[]\n    for i in range(n):\n        totalplus=0\n        totalminus=0\n        for index,j in enumerate(list(df.iloc[i])[1:]):\n            totalplus+=((j-ideal[index][0])**2)\n            totalminus+=((j-ideal[index][1])**2)\n      #      \n        totalplus=totalplus**(0.5)\n        totalminus=totalminus**(0.5)\n       # \n        tp.append(totalminus\/totalplus+totalminus)\n    final=deepcopy(df)\n    final['Topsis Score']=tp\n    final[\"Rank\"]=final[\"Topsis Score\"].rank(ascending=False)\n    return final","1c782a6c":"test_data_topsis=topsis(test_data,[1,1,1,1],['+','-','-','+'])\n\ntest_data_topsis=test_data_topsis.sort_values(by=['Rank'])\ntest_data_topsis","c5f288c2":"test_data_big_topsis=topsis(test_data_big,[1,1,1,1],['+','-','-','+'])\ntest_data_big_topsis=test_data_big_topsis.sort_values(by=['Rank'])\ntest_data_big_topsis","cca3f7a0":"test_data_small_topsis=topsis(test_data_small,[1,1,1,1],['+','-','-','+'])\ntest_data_small_topsis=test_data_small_topsis.sort_values(by=['Rank'])\ntest_data_small_topsis","4f70b393":"vals, names, xs = [],[],[]\nfor i, col in enumerate(test_data_topsis.columns[1:-2]):\n    vals.append(test_data_topsis[col].values)\n    names.append(col)\n    xs.append(np.random.normal(i + 1, 0.04, test_data_topsis[col].values.shape[0]))  \n    # adds jitter to the data points - can be adjusted\nplt.boxplot(vals, labels=names)\npalette = ['r', 'g', 'b', 'purple']\nfor x, val, c in zip(xs, vals, palette):\n    plt.scatter(x, val, alpha=0.3, color=c)\nplt.xticks(size = 25)\nplt.yticks(size = 25)\nplt.savefig('fulldata_boxplot.png')\nplt.show()","500b272e":"vals, names, xs = [],[],[]\nfor i, col in enumerate(test_data_big_topsis.columns[1:-2]):\n    vals.append(test_data_big_topsis[col].values)\n    names.append(col)\n    xs.append(np.random.normal(i + 1, 0.04, test_data_big_topsis[col].values.shape[0]))  \n    # adds jitter to the data points - can be adjusted\nplt.boxplot(vals, labels=names)\npalette = ['r', 'g', 'b','purple']\nfor x, val, c in zip(xs, vals, palette):\n    plt.scatter(x, val, alpha=0.3, color=c)\nplt.xticks(size = 25)\nplt.yticks(size = 25)\nplt.savefig('bigdata_boxplot.png')\nplt.show()","be77e588":"vals, names, xs = [],[],[]\nfor i, col in enumerate(test_data_small_topsis.columns[1:-2]):\n    vals.append(test_data_small_topsis[col].values)\n    names.append(col)\n    xs.append(np.random.normal(i + 1, 0.04, test_data_small_topsis[col].values.shape[0]))  \n    # adds jitter to the data points - can be adjusted\nplt.boxplot(vals, labels=names)\npalette = ['r', 'g', 'b','purple']\nfor x, val, c in zip(xs, vals, palette):\n    plt.scatter(x, val, alpha=0.3, color=c)\nplt.xticks(size = 25)\nplt.yticks(size = 25)\nplt.savefig('smalldata_boxplot.png')\nplt.show()","a9154579":"plt.rcParams[\"figure.figsize\"]=20,10\nparams = {'legend.fontsize': 15,\n          'legend.handlelength': 2}\nplt.rcParams.update(params)\nplt.plot(test_data_big_topsis['State'][:10], test_data_big_topsis['test_rate'][:10], label='test_rate')\nplt.plot(test_data_big_topsis['State'][:10], test_data_big_topsis['mortality_rate'][:10], label='mortality_rate')\n#plt.plot(test_data_big_topsis['State'][:10], test_data_big_topsis['Recovery_rate'][:10], label='Recovery_rate')\nplt.plot(test_data_big_topsis['State'][:10], test_data_big_topsis['Positivity_ratio'][:10], label='Positivity_ratio')\nplt.plot(test_data_big_topsis['State'][:10], test_data_big_topsis['Beds_per_hundred'][:10], label='Beds_per_hundred')\nplt.legend(loc=\"upper right\")\nplt.xticks(size = 15)\nplt.yticks(size = 25)\nplt.savefig('topsis_big_graph.png')\nplt.show()","64055649":"test_data_big_topsis=test_data_big_topsis.sort_values(['test_rate'])\nplt.subplot(221)\nplt.title('Test rate')\n#print(test_data_big_topsis['test_rate'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['test_rate'])\n\nplt.scatter('Jammu and Kashmir',test_data_big_topsis.iloc[-2,1])\n#plt.scatter('Bihar',test_data_big_topsis.iloc[8,1])\nplt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_big_topsis.iloc[-2,1]),(14.5,0.085),'data')\nax=plt.gca()\nax.axes.xaxis.set_ticks([])\nplt.subplot(222)\nplt.title('Mortality rate')\ntest_data_big_topsis=test_data_big_topsis.sort_values(['mortality_rate'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['mortality_rate'])\nplt.scatter('Jammu and Kashmir',test_data_big_topsis.iloc[-7,2])\n#plt.scatter('Bihar',test_data_big_topsis.iloc[3,2])\nplt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_big_topsis.iloc[-7,2]),(13,0.05), 'data')\nax=plt.gca()\nax.axes.xaxis.set_ticks([])\nplt.subplot(223)\nplt.title('Positivity ratio')\ntest_data_big_topsis=test_data_big_topsis.sort_values(['Positivity_ratio'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['Positivity_ratio'])\nplt.scatter('Jammu and Kashmir',test_data_big_topsis.iloc[4,3])\n#plt.scatter('Bihar',test_data_big_topsis.iloc[0,3])\nplt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_big_topsis.iloc[4,3]),(1,0.035), 'data')\nax=plt.gca()\nax.axes.xaxis.set_ticks([])\n\nplt.subplot(224)\nplt.title('Beds per hundred')\ntest_data_big_topsis=test_data_big_topsis.sort_values(['Beds_per_hundred'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['Beds_per_hundred'])\nplt.scatter('Jammu and Kashmir',test_data_big_topsis.iloc[-7,4])\n#plt.scatter('Bihar',test_data_big_topsis.iloc[9,4])\nplt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_big_topsis.iloc[-7,4]),(14,0.050), 'data')\nax=plt.gca()\nax.axes.xaxis.set_ticks([])","02b31981":"test_data_big_topsis=test_data_big_topsis.sort_values(['test_rate'])\nplt.subplot(221)\nplt.title('Test rate',size=20)\n#print(test_data_big_topsis['test_rate'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['test_rate'], alpha=0.5)\nplt.scatter('Jammu and Kashmir',test_data_big_topsis.iloc[-2,1],s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[-1],test_data_big_topsis.iloc[-1,1], color='g',s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[0],test_data_big_topsis.iloc[0,1], color='r',s=100)\n#plt.scatter('Bihar',test_data_big_topsis.iloc[8,1])\n#plt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_big_topsis.iloc[-2,1]),(14.5,0.085),'data')\nax=plt.gca()\nplt.plot(test_data_big_topsis['State'], [list(test_data_big_topsis.median())[0]]*21, '--', alpha=0.5)\nax.axes.xaxis.set_ticks(['Jammu and Kashmir'])\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.subplot(222)\nplt.title('Mortality rate',size=20)\ntest_data_big_topsis=test_data_big_topsis.sort_values(['mortality_rate'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['mortality_rate'], alpha=0.5)\nplt.scatter('Jammu and Kashmir',test_data_big_topsis.iloc[-7,2],s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[-1],test_data_big_topsis.iloc[-1,2], color='r',s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[0],test_data_big_topsis.iloc[0,2], color='g',s=100)\n#plt.scatter('Bihar',test_data_big_topsis.iloc[3,2])\n#plt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_big_topsis.iloc[-7,2]),(12.5,0.065), 'data')\nax=plt.gca()\nplt.plot(test_data_big_topsis['State'], [list(test_data_big_topsis.median())[1]]*21, '--', alpha=0.5)\nax.axes.xaxis.set_ticks(['Jammu and Kashmir'])\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.subplot(223)\nplt.title('Positivity ratio',size=20)\ntest_data_big_topsis=test_data_big_topsis.sort_values(['Positivity_ratio'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['Positivity_ratio'], alpha=0.5)\nplt.scatter('Jammu and Kashmir',test_data_big_topsis.iloc[4,3],s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[-1],test_data_big_topsis.iloc[-1,3], color='r',s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[0],test_data_big_topsis.iloc[0,3], color='g',s=100)\n#plt.scatter('Bihar',test_data_big_topsis.iloc[0,3])\n#plt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_big_topsis.iloc[4,3]),(1,0.035), 'data')\nax=plt.gca()\nplt.plot(test_data_big_topsis['State'], [list(test_data_big_topsis.median())[2]]*21, '--', alpha=0.5)\nax.axes.xaxis.set_ticks(['Jammu and Kashmir'])\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.subplot(224)\nplt.title('Beds per hundred',size=20)\ntest_data_big_topsis=test_data_big_topsis.sort_values(['Beds_per_hundred'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['Beds_per_hundred'], alpha=0.5)\nplt.scatter('Jammu and Kashmir',test_data_big_topsis.iloc[-7,4],s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[-1],test_data_big_topsis.iloc[-1,4], color='g',s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[0],test_data_big_topsis.iloc[0,4], color='r',s=100)\n#plt.scatter('Bihar',test_data_big_topsis.iloc[9,4])\n#plt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_big_topsis.iloc[-7,4]),(14,0.050), 'data')\nax=plt.gca()\nplt.plot(test_data_big_topsis['State'], [list(test_data_big_topsis.median())[3]]*21, '--', alpha=0.5)\nax.axes.xaxis.set_ticks(['Jammu and Kashmir'])\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.subplots_adjust(hspace=0.35)\nplt.savefig('topsis_big_compare_jnk.png')\nplt.show()","34cd337a":"test_data_big_topsis=test_data_big_topsis.sort_values(['test_rate'])\n\nplt.subplot(221)\nplt.title('Test rate',size=20)\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['test_rate'], alpha=0.5)\nplt.scatter('Delhi',test_data_big_topsis.iloc[-1,1], s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[-1],test_data_big_topsis.iloc[-1,1], color='g',s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[0],test_data_big_topsis.iloc[0,1], color='r',s=100)\n#plt.annotate('Delhi',('Delhi',test_data_big_topsis.iloc[-1,1]),(18.5,0.127),'data')\nax=plt.gca()\nplt.plot(test_data_big_topsis['State'], [list(test_data_big_topsis.median())[0]]*21, '--', alpha=0.5)\nax.axes.xaxis.set_ticks(['Delhi'])\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.subplot(222)\nplt.title('Mortality rate',size=20)\ntest_data_big_topsis=test_data_big_topsis.sort_values(['mortality_rate'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['mortality_rate'], alpha=0.5)\nplt.scatter('Delhi',test_data_big_topsis.iloc[-6,2], s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[-1],test_data_big_topsis.iloc[-1,2], color='r',s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[0],test_data_big_topsis.iloc[0,2], color='g',s=100)\n#plt.annotate('Delhi',('Delhi',test_data_big_topsis.iloc[-6,2]),(14.5,0.065), 'data')\nax=plt.gca()\nplt.plot(test_data_big_topsis['State'], [list(test_data_big_topsis.median())[1]]*21, '--', alpha=0.5)\nax.axes.xaxis.set_ticks(['Delhi'])\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.subplot(223)\nplt.title('Positivity ratio',size=20)\ntest_data_big_topsis=test_data_big_topsis.sort_values(['Positivity_ratio'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['Positivity_ratio'], alpha=0.5)\nplt.scatter('Delhi',test_data_big_topsis.iloc[-4,3], s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[-1],test_data_big_topsis.iloc[-1,3], color='r',s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[0],test_data_big_topsis.iloc[0,3], color='g',s=100)\n#plt.annotate('Delhi',('Delhi',test_data_big_topsis.iloc[-4,3]),(16,0.070), 'data')\nax=plt.gca()\nplt.plot(test_data_big_topsis['State'], [list(test_data_big_topsis.median())[2]]*21, '--', alpha=0.5)\nax.axes.xaxis.set_ticks(['Delhi'])\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.subplot(224)\nplt.title('Beds per hundred',size=20)\ntest_data_big_topsis=test_data_big_topsis.sort_values(['Beds_per_hundred'])\nplt.plot(test_data_big_topsis['State'], test_data_big_topsis['Beds_per_hundred'], alpha=0.5)\nplt.scatter('Delhi',test_data_big_topsis.iloc[0,4], s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[-1],test_data_big_topsis.iloc[-1,4], color='g',s=100)\nplt.scatter(test_data_big_topsis['State'].iloc[0],test_data_big_topsis.iloc[0,4], color='r',s=100)\n#plt.annotate('Delhi',('Delhi',test_data_big_topsis.iloc[0,4]),(0.5,0.020), 'data')\nax=plt.gca()\nplt.plot(test_data_big_topsis['State'], [list(test_data_big_topsis.median())[3]]*21, '--', alpha=0.5)\nax.axes.xaxis.set_ticks(['Delhi'])\nplt.xticks(size = 20)\nplt.yticks(size = 20)\nplt.subplots_adjust(hspace=0.35)\nplt.savefig('topsis_big_compare_delhi.png')\nplt.show()","fa26247d":"test_data_topsis=test_data_topsis.sort_values(['test_rate'])\nplt.subplot(221)\nplt.title('Test rate')\n\nplt.plot(test_data_topsis['State'], test_data_topsis['test_rate'])\n\nplt.scatter('Jammu and Kashmir',test_data_topsis.iloc[-5,1])\n#plt.scatter('Bihar',test_data_big_topsis.iloc[8,1])\nplt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_topsis.iloc[-5,1]),(22,0.060),'data')\nax=plt.gca()\ny_min, y_max = ax.axes.get_ylim()\nplt.plot(test_data_topsis['State'], [list(test_data_topsis.median())[0]]*35, '--', alpha=0.5)\nax.axes.xaxis.set_ticks([])\nplt.subplot(222)\nplt.title('Mortality rate')\ntest_data_topsis=test_data_topsis.sort_values(['mortality_rate'])\nplt.plot(test_data_topsis['State'], test_data_topsis['mortality_rate'])\nplt.scatter('Jammu and Kashmir',test_data_topsis.iloc[-11,2])\n#plt.scatter('Bihar',test_data_big_topsis.iloc[3,2])\nplt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_topsis.iloc[-11,2]),(20,0.04), 'data')\nax=plt.gca()\ny_min, y_max = ax.axes.get_ylim()\nplt.plot(test_data_topsis['State'], [list(test_data_topsis.median())[1]]*35, '--', alpha=0.5)\nax.axes.xaxis.set_ticks([])\nplt.subplot(223)\nplt.title('Positivity ratio')\ntest_data_topsis=test_data_topsis.sort_values(['Positivity_ratio'])\n\nplt.plot(test_data_topsis['State'], test_data_topsis['Positivity_ratio'])\nplt.scatter('Jammu and Kashmir',test_data_topsis.iloc[6,3])\n#plt.scatter('Bihar',test_data_big_topsis.iloc[0,3])\nplt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_topsis.iloc[6,3]),(0.5,0.025), 'data')\nax=plt.gca()\ny_min, y_max = ax.axes.get_ylim()\nplt.plot(test_data_topsis['State'], [list(test_data_topsis.median())[2]]*35, '--', alpha=0.5)\nax.axes.xaxis.set_ticks([])\n\nplt.subplot(224)\nplt.title('Beds per hundred')\ntest_data_topsis=test_data_topsis.sort_values(['Beds_per_hundred'])\nplt.plot(test_data_topsis['State'],test_data_topsis['Beds_per_hundred'])\nplt.scatter('Jammu and Kashmir',test_data_topsis.iloc[-12,4])\n#plt.scatter('Bihar',test_data_big_topsis.iloc[9,4])\nplt.annotate('Jammu and Kashmir',('Jammu and Kashmir',test_data_topsis.iloc[-12,4]),(16,0.042), 'data')\nax=plt.gca()\ny_min, y_max = ax.axes.get_ylim()\nplt.plot(test_data_topsis['State'], [list(test_data_topsis.median())[3]]*35, '--', alpha=0.5)\nax.axes.xaxis.set_ticks([])","2c9b341a":"from mpl_toolkits.mplot3d import Axes3D\nplt.rcParams.update({'font.size': 12})\nfig = plt.figure()\nax = fig.add_subplot(111, projection='3d')\naxes = plt.gca()\naxes.set_xlim([0,1])\naxes.set_ylim([0,1])\naxes.set_zlim([0,1])\nxs=[0,1]\nys=[0,1]\nzs=[0,1]\n#ideal worst\nax.scatter(0, 0, 0, s=100, color='r')\n#ideal best\nax.scatter(1, 1, 1, s=100, color='#079022')\n#random point\nax.scatter(0.5,0.7,0.7, s=100)\nax.plot([0.5,1],[0.7,1],[0.7,1], '--', color='#90DD00', alpha=0.7)\nax.plot([0,0.5],[0,0.7],[0,0.7],'--',color='orange', alpha=0.7)\nax.text(0.05,0,0,'Ideal Worst')\nax.text(0.75,1,0.9,'Ideal best')\nax.text(0.56,0.7,0.7,'(0.5, 0.7, 0.7)')\nax.text(0.6,1,0.7,'S+')\nax.text(0.1,1,0, 'S-')\nax.set_xlabel('Criterion 1')\nax.set_ylabel('Criterion 2')\nax.set_zlabel('Criterion 3')","8ce2e5e0":"test_data_big_topsis.sort_values('Rank')","a3a45fd3":"test_data_big_topsis.sort_values('Positivity_ratio')","83600edc":"def topsis_minmax(df1, weights, impacts):\n    df=deepcopy(df1)\n    for i in impacts:\n        if i!='+' and i!='-':\n            print(\"Impacts contain foriegn values. Please try again with '+' and '-' ONLY. Seperate them using commas ONLY. \")\n            return\n    if len(weights)!=len(impacts):\n        print(\"Number of weights and impacts are different. Please try again.\")\n        return\n    if (len(df.columns)-1) != len(weights):\n        print(\"Number of weights and attributes are not the same. try again\")\n        return\n    \n    if df.shape[0]<3:\n        print(\"There is only one model in the input. Please try again.\")\n    \n   \n    for index,i in enumerate(df.columns[1:]):\n        for j in df[i]:\n            df[i]=df[i].replace(j,(j-min(df[i]))*(weights[index]\/sum(weights))\/(max(df[i])-min(df[i])))\n    print(\"Normalized weighted Confusion matrix is: \")\n    with pd.option_context('expand_frame_repr', False):\n        print (df)\n    ideal=[]\n    for index,i in enumerate(df.columns[1:]):\n        if impacts[index]=='-':\n            ideal_best=min(df[i])\n            ideal_worst=max(df[i])\n        else:\n            ideal_best=max(df[i])\n            ideal_worst=min(df[i])\n\n        ideal.append((ideal_best, ideal_worst))\n    n=len(df.index)\n    tp=[]\n    for i in range(n):\n        totalplus=0\n        totalminus=0\n        for index,j in enumerate(list(df.iloc[i])[1:]):\n            totalplus+=((j-ideal[index][0])**2)\n            totalminus+=((j-ideal[index][1])**2)\n      #      \n        totalplus=totalplus**(0.5)\n        totalminus=totalminus**(0.5)\n       # \n        tp.append(totalminus\/totalplus+totalminus)\n    final=deepcopy(df)\n    final['Topsis Score']=tp\n    final[\"Rank\"]=final[\"Topsis Score\"].rank(ascending=False)\n    return final","9e32c8dd":"topsis_data_big_minmax=topsis_minmax(test_data_big,[1,1,1,1],['+','-','-','+'])","f70b3c21":"def topsis_zscore(df1, weights, impacts):\n    df=deepcopy(df1)\n    for i in impacts:\n        if i!='+' and i!='-':\n            print(\"Impacts contain foriegn values. Please try again with '+' and '-' ONLY. Seperate them using commas ONLY. \")\n            return\n    if len(weights)!=len(impacts):\n        print(\"Number of weights and impacts are different. Please try again.\")\n        return\n    if (len(df.columns)-1) != len(weights):\n        print(\"Number of weights and attributes are not the same. try again\")\n        return\n    \n    if df.shape[0]<3:\n        print(\"There is only one model in the input. Please try again.\")\n    \n    \n    for index,i in enumerate(df.columns[1:]):\n        for j in df[i]:\n            df[i]=df[i].replace(j,(j-np.mean(df[i]))*(weights[index]\/sum(weights))\/np.std(df[i]))\n    print(\"Normalized weighted Confusion matrix is: \")\n    with pd.option_context('expand_frame_repr', False):\n        print (df)\n    ideal=[]\n    for index,i in enumerate(df.columns[1:]):\n        if impacts[index]=='-':\n            ideal_best=min(df[i])\n            ideal_worst=max(df[i])\n        else:\n            ideal_best=max(df[i])\n            ideal_worst=min(df[i])\n\n        ideal.append((ideal_best, ideal_worst))\n    n=len(df.index)\n    tp=[]\n    for i in range(n):\n        totalplus=0\n        totalminus=0\n        for index,j in enumerate(list(df.iloc[i])[1:]):\n            totalplus+=((j-ideal[index][0])**2)\n            totalminus+=((j-ideal[index][1])**2)\n      #      \n        totalplus=totalplus**(0.5)\n        totalminus=totalminus**(0.5)\n       # \n        tp.append(totalminus\/totalplus+totalminus)\n    final=deepcopy(df)\n    final['Topsis Score']=tp\n    final[\"Rank\"]=final[\"Topsis Score\"].rank(ascending=False)\n    return final","03d41719":"topsis_data_big_zscore=topsis_zscore(test_data_big,[1,1,1,1],['+','-','-','+'])","023c13ef":"def topsis_outlier(df1, weights, impacts):\n    df=deepcopy(df1)\n    for i in impacts:\n        if i!='+' and i!='-':\n            print(\"Impacts contain foriegn values. Please try again with '+' and '-' ONLY. Seperate them using commas ONLY. \")\n            return\n    if len(weights)!=len(impacts):\n        print(\"Number of weights and impacts are different. Please try again.\")\n        return\n    if (len(df.columns)-1) != len(weights):\n        print(\"Number of weights and attributes are not the same. try again\")\n        return\n    \n    if df.shape[0]<3:\n        print(\"There is only one model in the input. Please try again.\")\n    \n    \n    for index,i in enumerate(df.columns[1:]):\n        q1= np.percentile(df[i], 25, interpolation = 'midpoint')\n        q3= np.percentile(df[i], 75, interpolation = 'midpoint')\n        iqr=q3-q1\n        maximum=q3+1.5*iqr\n        minimum=q1-1.5*iqr\n        for j in df[i]:\n            if j>maximum:\n                df[i]=df[i].replace(j,maximum*(weights[index]\/sum(weights)))\n            elif j<minimum:\n                df[i]=df[i].replace(j,minimum*(weights[index]\/sum(weights)))\n            else:\n                df[i]=df[i].replace(j,j*(weights[index]\/sum(weights)))\n    print(\"Normalized weighted Confusion matrix is: \")\n    with pd.option_context('expand_frame_repr', False):\n        print (df)\n    ideal=[]\n    for index,i in enumerate(df.columns[1:]):\n        if impacts[index]=='-':\n            ideal_best=min(df[i])\n            ideal_worst=max(df[i])\n        else:\n            ideal_best=max(df[i])\n            ideal_worst=min(df[i])\n\n        ideal.append((ideal_best, ideal_worst))\n    n=len(df.index)\n    tp=[]\n    for i in range(n):\n        totalplus=0\n        totalminus=0\n        for index,j in enumerate(list(df.iloc[i])[1:]):\n            totalplus+=((j-ideal[index][0])**2)\n            totalminus+=((j-ideal[index][1])**2)\n      #      \n        totalplus=totalplus**(0.5)\n        totalminus=totalminus**(0.5)\n       # \n        tp.append(totalminus\/totalplus+totalminus)\n    final=deepcopy(df)\n    final['Topsis Score']=tp\n    final[\"Rank\"]=final[\"Topsis Score\"].rank(ascending=False)\n    return final","77e07fbb":"topsis_data_big_outlier=topsis_outlier(test_data_big,[1,1,1,1],['+','-','-','+'])","78c3d0ef":"topsis_data_big_outlier","1c3acacb":"topsis_data_big_zscore","904843ea":"compared_df=pd.DataFrame(columns=['State','vector', 'Minmax','zscore', 'outlier'])\ntest_data_big_topsis=test_data_big_topsis.sort_values(by=['State'])\ncompared_df['State']=test_data_big_topsis['State']\ncompared_df['vector']=test_data_big_topsis['Rank']\ntopsis_data_big_minmax=topsis_data_big_minmax.sort_values(by=['State'])\ncompared_df['Minmax']=topsis_data_big_minmax['Rank']\ntopsis_data_big_zscore=topsis_data_big_zscore.sort_values(by=['State'])\ncompared_df['zscore']=topsis_data_big_zscore['Rank']\ntopsis_data_big_outlier=topsis_data_big_outlier.sort_values(by=['State'])\ncompared_df['outlier']=topsis_data_big_outlier['Rank']\ncompared_df","954e37b8":"n=len(compared_df['vector'])\nminmax_correlation=1-sum((compared_df['vector']-compared_df['Minmax'])**2)\/(n*(n-1))","0fbc7a26":"n=len(compared_df['vector'])\nzscore_correlation=1-sum((compared_df['vector']-compared_df['zscore'])**2)\/(n*(n-1))","19d22287":"n=len(compared_df['vector'])\noutlier_correlation=1-sum((compared_df['vector']-compared_df['outlier'])**2)\/(n*(n-1))","5d6107b2":"print(minmax_correlation, zscore_correlation, outlier_correlation)","09f0a355":"# Outlier removal. ","45d5cfa4":"# Evaluating Covid Management of each Indian State","28fde1dd":"# Topsis Equal weights on all 3 datasets","e6a821ed":"# Calculating the criteria","cec3dee4":"### Test data big","98f7e974":"In order to evaluate every Indian States' Covid management it is important to look at data such as; Total number of Covid patients (Confirmed cases) , Number of tests done (Tested patients), Number of deceased, as well as number of active cases of each State.\nUsing these, we can calculate other statistics such as Test rate, Positivity Ratio, Mortality rate, as well as Population density. \nAfter this, we will have multiple criterias from which to choose which State has handled this crisis the best. This would be an easy task if let's say, only one State led the charts in every criteria, however as the variance between each criteria increases, so do the number of 'best' States corresponding to every criteria. Moreover, as every criteria cannot be added or averaged with each other, it once more becomes harder to calculate the best State. \n\nTherefore, we will use a technique known as 'Technique of Order Preference Similarity to the Ideal Solution' or TOPSIS in short, which is a simple Multiple Criteria Decision Making (MCDA) method. \n","4724b8ab":"### with median jnk","6e81cb73":"# TOPSIS ","b7273cd3":"The first step is always to collect data in order to establish our statistics.\nFor this, I used the data given by Coronavirus Outbreak in India - covid19india.org and uidai.gov.in for getting the State populations. ","cc27c66c":"## Step 1: Collecting the data ","6d243a23":"# Splitting the data to remove outliers (reasoning given after TOPSIS)","c7badb11":"### test data topsis full","c3b5b27c":"### with median delhi","59e3757c":"## Function "}}