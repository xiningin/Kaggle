{"cell_type":{"580ed4ca":"code","57f38ee0":"code","7ecf0ef0":"code","12dbf056":"code","140e4a1e":"code","58734399":"code","3311f568":"code","f41b90c1":"code","3df1ead6":"code","7a813549":"code","77f44c45":"code","de8165d5":"code","83619a92":"code","ae89c489":"code","dddedc7e":"code","b6da31ff":"code","5b6c9e90":"code","5973b393":"code","bf3d9ff6":"code","5779e130":"code","99cbbc61":"code","5d4a91ce":"code","16d43b0e":"code","ba805bcb":"markdown","f0e106e4":"markdown","7426b9b7":"markdown","8f4764f4":"markdown","dc1e30f8":"markdown","e58ca1ee":"markdown","9b9f3986":"markdown","c3688065":"markdown","b5cbd8bb":"markdown","aae52b1c":"markdown"},"source":{"580ed4ca":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","57f38ee0":"trainfile = '\/kaggle\/input\/body-performance-data\/bodyPerformance.csv'\ndf=pd.read_csv(trainfile)\nprint(df.shape)\ndf.head()","7ecf0ef0":"!pip install autoviml","12dbf056":"target = 'class'","140e4a1e":"from sklearn.model_selection import train_test_split\ntrain, test = train_test_split(df, test_size=0.1, random_state=99,\n                                stratify=df[target])\nprint(train.shape, test.shape)","58734399":"from autoviml.Auto_ViML import Auto_ViML","3311f568":"model, features, trainm, testm = Auto_ViML(\n    train,\n    target,\n    test,\n    sample_submission='',\n    hyper_param=\"RS\",\n    feature_reduction=True,\n    scoring_parameter=\"weighted-f1\",\n    KMeans_Featurizer=False,\n    Boosting_Flag=\"CatBoost\",\n    Binning_Flag=False,\n    Add_Poly=True,\n    Stacking_Flag=False,\n    Imbalanced_Flag=False,\n    verbose=1,\n)\nlen(features)","f41b90c1":"print(len(features))\nfeatures","3df1ead6":"testm.head(1)","7a813549":"from sklearn.metrics import classification_report\nprint(classification_report(test[target].values, testm[target+'_predictions'].values))","77f44c45":"pip install pycaret --ignore-installed llvmlite numba","de8165d5":"from pycaret.classification import *","83619a92":"!pip install scikit-learn==0.23.2","ae89c489":"exp_clf = setup(train, target = 'class',silent=True,session_id=1)","dddedc7e":"best = compare_models()","b6da31ff":"dt = create_model('lightgbm')","5b6c9e90":"tuned_dt = tune_model(dt)","5973b393":"plot_model(dt)","bf3d9ff6":"plot_model(dt, plot = 'confusion_matrix') ","5779e130":"final_dt = finalize_model(tuned_dt)","99cbbc61":"predf = predict_model(final_dt, data=test)\npredf.head()","5d4a91ce":"from sklearn.metrics import classification_report","16d43b0e":"print(classification_report(test[target].values,predf['Label'].values))","ba805bcb":"## Let's do some feature engg and then feature selection using AutoViML","f0e106e4":"# 1) Data Preprocessing","7426b9b7":"# So either way, when you have more choices to build models faster, you win!\nIf you like this notebook, save it, share it, upvote it","8f4764f4":"# 2) Feature Selection using AutoViML","dc1e30f8":"## Let us look at the results on held out test data by AutoViML\n#### It selected 10 features out of the 45 new features and these are results - 71% Macro Average in F1-Score|","e58ca1ee":"### You can see that PyCaret produces slightly better results than AutoViML though it takes longer time to do so. If this were a very large dataset, you can see the results much starker. However, if you want faster results, you can limit the number of models in PyCaret. ","9b9f3986":"# 3) Multi Classification by PyCaret","c3688065":"## Split df into train and test so we assess model performance","b5cbd8bb":"df=df.replace({'M':0, 'F':1})\ndf=df.replace({'A':1,'B':2,'C':3,'D':4})","aae52b1c":"## The goal of this notebook is to show how PyCaret and AutoViML can be used together to build better models for a dataset.\n\nThis notebook is derived from the following notebook:\nhttps:\/\/www.kaggle.com\/sasakitetsuya\/visualization-and-prediction-by-auto-ml\nMany thanks to the author!"}}