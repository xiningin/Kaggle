{"cell_type":{"65e707ae":"code","8a69c680":"code","363483ab":"code","4952941f":"code","f81cdaba":"code","4d9b3d8e":"code","d7f1d600":"code","bc839f9d":"code","4bd050d8":"code","3be38531":"code","103098fd":"code","e0e7a661":"code","cb38bebd":"code","ff612596":"code","8fe94fdb":"code","eab364a9":"code","4b9d3df9":"code","bf39b41f":"code","d8a6b771":"code","62373e66":"code","ba426d86":"code","7023071f":"markdown","3ca12ea3":"markdown","88c8401d":"markdown","2daae8d6":"markdown","7a9681b4":"markdown","15899c99":"markdown","d8239539":"markdown","b81bf266":"markdown","6a19a084":"markdown","b7561cee":"markdown","93599586":"markdown","5d1e2c24":"markdown","e4c2428a":"markdown","0b563f02":"markdown","bb605c51":"markdown","ae7f9dc3":"markdown","1ecdabe1":"markdown","ff2e42c7":"markdown","cc8b07ff":"markdown","ca2e0d5a":"markdown","b2cfd76f":"markdown"},"source":{"65e707ae":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8a69c680":"import matplotlib.pyplot as plt","363483ab":"data = pd.read_csv('\/kaggle\/input\/adult-census-income\/adult.csv')\nprint(data.shape)\nprint(data.columns)","4952941f":"for col in data.columns:\n    print(data[col].describe())\n    plt.figure()\n    plt.hist(data[col])\n    plt.show()","f81cdaba":"col_rename = {'fnlwgt':'final_weight', \n              'education.num':'education_num',\n              'marital.status':'marital_status',\n              'capital.gain':'capital_gain', \n              'capital.loss':'capital_loss', \n              'hours.per.week':'hours_per_week', \n              'native.country':'native_country'}\ndata = data.rename(columns = col_rename)","4d9b3d8e":"print(data.columns)","d7f1d600":"def value_change(x):\n    if x == '<=50K': return 0\n    return 1","bc839f9d":"data['income'] = data['income'].apply(lambda x: value_change(x))","4bd050d8":"def plot_new_fig(series):\n    plt.figure()\n    plt.hist(series)\n    plt.show()","3be38531":"num_cols = ['age', 'final_weight','capital_gain', \n            'capital_loss', 'hours_per_week']\ncat_cols = [ 'native_country','workclass','education','education_num',\n             'marital_status','occupation','relationship', 'race','sex']\nordinal_cols = ['workclass','education', 'education_num', 'occupation']","103098fd":"for col in num_cols:\n    print(\"currently examining the categorical column:\",col)\n    print(np.corrcoef(data['income'],data[col])[0][1])\n    print(\"Let's check histogram for low income:\")\n    plot_new_fig(data[data['income'] == 0][col])\n    print(\"Let's check histogram for high income:\")\n    plot_new_fig(data[data['income'] == 1][col])\n    print(\"Note if there is any difference.\")\n    ","e0e7a661":"data_less40 = data[data['hours_per_week']<=40]\ndata_more40 = data[data['hours_per_week']>40]","cb38bebd":"print(data_less40.shape)\nprint(data_more40.shape)","ff612596":"for col in data.columns:\n    print(\"less than 40 histogram for\",col,\" is:\")\n    plot_new_fig(data_less40[col])\n    print(\"more than 40 histogram for\",col,\" is:\")\n    plot_new_fig(data_more40[col])","8fe94fdb":"data_less40['marital_status'].value_counts()\/data_less40.shape[0]","eab364a9":"data_more40['marital_status'].value_counts()\/data_more40.shape[0]","4b9d3df9":"for col in cat_cols:\n    print(col, \"is being analyzed\")\n    print(data[col].value_counts())","bf39b41f":"data['country_special'] = data['native_country'].apply(lambda x: x== 'United-States')","d8a6b771":"#for workclass; let's merge up '?','without pay','not worked' into one category of unknown.\n#also let's merge government jobs into one 'gov' category.\ndef work_val_change(x):\n    if x in ['?','Without-pay','Never-worked']:\n        return 'unknown'\n    elif x in ['Local-gov','State-gov','Federal-gov']:\n        return 'gov'\n    else:\n        return x\ndata['workclass_special'] = data['workclass'].apply(lambda x: work_val_change(x))","62373e66":"#let's drop armed-forces; as it is grossly under-sampled and that is very differently salaried job.\ndata = data[~(data['occupation']=='Armed-Forces')]","ba426d86":"print(data.shape)\n#9 rows dropped","7023071f":"We will now check the correlation of the numerical variables with the binary income variable in different ways. For each numeric variable, we will observe the histogram of the numeric variable under each category ( 0 or 1 income). Then we will also observe the correlation. For more, we will check segment-wise correlations of the numeric variables. let's begin.","3ca12ea3":"The data is shaped (32651,15). The columns have bad formats with '.' in them. It is advisable to change it from that to more acceptable settings; i.e. with dash between different words in a column name. We will first check the histograms for each column.","88c8401d":"**In this** notebook we are going to explore the Adult-census-income data. In this data, there are two categories, '<=50k' income\/yr and '>50k' income\/yr. We will explore the plots; perform basic eda on the data; and generate in-depth insights from the data.","2daae8d6":"# dummy variable creation","7a9681b4":"# Numerical columns plot","15899c99":"let's check the names of columns now!","d8239539":"And our third smaller insight checks out. There is a significance difference in different work hr sections in terms of marital status. While both parties have married-civ-spouse([meaning checks here](https:\/\/rpubs.com\/Net\/IncomeLevelClassification)) as most dominant category; married-civ-spouse is even more dominant category in case of 40+ hr weeks. Also, it seems that there is a significantly more chance of being unmarried in case of less than 40- hr week. This can arise from both lesser age and lesser resources as I guess.","b81bf266":"will update soon.","6a19a084":"So as we observe the distribution of different variables along the hour of week division; we can see two major insights.<br\/>\n(1) age is highly associated with hours of work par week.<br\/>\n(2) there is much higher male dominance in 40+hr week section than in the 40- hr week.<br\/>\nOther smaller insights are that the population is inclined to be lesser educated with lesser work hours, and also marital status seems to have different dominance in different work hr sections.","b7561cee":"# classification efforts:\nSo, now that we have done significant amount of eda; let's go ahead and try to model this data for classification. From the eda, it is very clear that a random forest model is going to be very efficient as different cuts are very significant in this data. Yet; we are going to make some custom variables before that. ","93599586":"# Key insights:<br\/>\n(1) the age is a major factor in driving higher income; with the median of lower income being around 20 and the median of higher income being around 45.<br\/>\n    the correlation of 0.23 also responds to show a high indicative signal that with increasing age there is more chance to be on from low income to high income.<br\/>\n(2) the hour par week is also pretty strong signal with a correlation of ~0.23 and the median of hr\/week is just below 40 hrs\/week; while in high income, the hr\/week is bimodal, with one peak near 40hr\/week and other being near 60hr\/week.<br\/>\nThis refers to a hypothesis that the population of high income can be further divided into two parts; with one being regular wage earners with 40hr\/week work; while other one is business people with higher ( near 60hr\/week) schedules.<br\/>\nWe will test this hypothesis out in next block.<br\/>\n(3) capital gain and capital loss; are more interesting. While they have significant correlations with the binary income variable( 0.22 and 0.15 respectively); the graphs are more highly concentrated towards 0 in all cases. This refers to the possibility that in our sample, people with significant capital movement is less.<br\/>\nWhile the highest population is at 0 loss and gain, the tails are further interesting.<br\/>\nIn high income people, there is a bit of a population where 100k capital gains have happened. But in case of low income people, capital gain is much less at max, with a 40k max.<br\/>\nThis can lead to an observation that, if someone is bringing home more than 40k; definitely they are also earning more than 50k. We will check this hypothesis in 2nd next block.<br\/>\nSimilar thing is observable in capital loss. When capital loss is non-zero, the median of capital loss in that portion is near 1500, while for high income the median is 2000. So it is evident that higher capital loss is also more correlated with higher income.<br\/>\nNow, let's test out the hypotheses.","5d1e2c24":"# Basic data definition:","e4c2428a":"Now that we have created more stronger signals, we will generate dummy variables and train our model.","0b563f02":"Now, let's rename the columns to more acceptable nomenclature.","bb605c51":"## Let's check the hour of week based population segment","ae7f9dc3":"One other thing I didn't like here is that the categorical column named income, has two values '<=50k' and '>50k'. We will change it to a more intuitive, 0 and 1 respectively using the **value_change** function below.","1ecdabe1":"# Observe the data","ff2e42c7":"country we will turn into us vs non-us. As us is way too huge a sample, therefore non-us is only meaningful other feature. ","cc8b07ff":"implementing the value_change for each value in the income column using apply.","ca2e0d5a":"Now that we are set with correct column names, let's check how much individual features influence the binary variable income. We can do simple chi-square test with occurrence matrix and check the performance of each variable based on that.\n\nThe numeric variables are:<br\/>\n(1) age<br\/>\n(2) final_weight<br\/>\n(3) capital_gain<br\/>\n(4) capital_loss<br\/>\n(5) hours_per_week<br\/>\n<br\/>\nThe categorical variables are:\n<br\/>\n(6) native_country<br\/>\n(7) workclass<br\/>\n(8) education <br\/>\n(9) education_num<br\/>\n(10) marital_status <br\/>\n(11) occupation <br\/>\n(12) relationship <br\/>\n(13) race <br\/>\n(14) sex<br\/>\n\nWe can also treat the following as ordinal variables:<br\/>\n(7) workclass<br\/>\n(8) education <br\/>\n(9) education_num<br\/>\n(11) occupation <br\/>","b2cfd76f":"first, lets check the categorical columns and merge weak classes to create stronger signals. For this, we will check value counts and merge any class which has very less ( < 30) presence."}}