{"cell_type":{"fd3b99cf":"code","18b94a45":"code","8450480d":"code","14c391a1":"code","9c069165":"code","675aa1e3":"code","2d56c39d":"code","057d8724":"code","751dc4d8":"code","a196e86f":"code","22c9c88e":"code","96f7f5b9":"code","f06e037b":"code","77a4799a":"code","a9409896":"code","761f4dad":"code","550e63ad":"code","75b818a1":"markdown","54f9f58e":"markdown","f940a07e":"markdown","105577e5":"markdown","da19ef65":"markdown","ad8ef7eb":"markdown","645a80b1":"markdown","ac49342b":"markdown","010fe3cd":"markdown","f2a53e7e":"markdown"},"source":{"fd3b99cf":"import os\nimport sys\nimport random\nfrom random import randint\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-white')\nimport seaborn as sns\nsns.set_style(\"white\")\n\n%matplotlib inline\n\n# import cv2\nfrom sklearn.model_selection import train_test_split\n\nfrom tqdm import tqdm_notebook, tnrange\nfrom itertools import chain\nfrom skimage.io import imread, imshow, concatenate_images\nfrom skimage.transform import resize\nfrom skimage.morphology import label\n\nfrom keras.models import Model, load_model\nfrom keras.layers import Input,Dropout,BatchNormalization,Activation,Add,UpSampling2D,Concatenate\nfrom keras.layers.core import Lambda\nfrom keras.layers.convolutional import Conv2D, Conv2DTranspose\nfrom keras.layers.pooling import MaxPooling2D\nfrom keras.layers.merge import concatenate\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint, ReduceLROnPlateau\nfrom keras import backend as K\n\nimport tensorflow as tf\n\nfrom keras.preprocessing.image import ImageDataGenerator, array_to_img, img_to_array, load_img#","18b94a45":"# Set some parameters\nim_width = 101\nim_height = 101\nim_chan = 1\nbasicpath = '..\/input\/'\npath_train = basicpath + 'train\/'\npath_test = basicpath + 'test\/'\n\npath_train_images = path_train + 'images\/'\npath_train_masks = path_train + 'masks\/'\npath_test_images = path_test + 'images\/'","8450480d":"# Loading of training\/testing ids and depths\n\ntrain_df = pd.read_csv(\"..\/input\/train.csv\", index_col=\"id\", usecols=[0])\ndepths_df = pd.read_csv(\"..\/input\/depths.csv\", index_col=\"id\")\ntrain_df = train_df.join(depths_df)\ntest_df = depths_df[~depths_df.index.isin(train_df.index)]\n\nlen(train_df)","14c391a1":"train_df[\"images\"] = [np.array(load_img(\"..\/input\/train\/images\/{}.png\".format(idx), grayscale=True)) \/ 255 for idx in tqdm_notebook(train_df.index)]\ntrain_df[\"masks\"] = [np.array(load_img(\"..\/input\/train\/masks\/{}.png\".format(idx), grayscale=True)) \/ 255 for idx in tqdm_notebook(train_df.index)]\ntrain_df[\"coverage\"] = train_df.masks.map(np.sum) \/ pow(101, 2)\n\ndef cov_to_class(val):    \n    for i in range(0, 11):\n        if val * 10 <= i :\n            return i\n\nx_train_sorted_by_coverage=np.array(train_df.sort_values(by='coverage').images.tolist()).reshape(-1, 101, 101, 1)\nx_train_sorted_by_z=np.array(train_df.sort_values(by='z').images.tolist()).reshape(-1, 101, 101, 1)\ny_train_sorted_by_coverage=np.array(train_df.sort_values(by='coverage').masks.tolist()).reshape(-1, 101, 101, 1)\ny_train_sorted_by_z=np.array(train_df.sort_values(by='z').masks.tolist()).reshape(-1, 101, 101, 1)\n        \ntrain_df[\"coverage_class\"] = train_df.coverage.map(cov_to_class)\nids_train, ids_valid, x_train, x_valid, y_train, y_valid, cov_train, cov_test, depth_train, depth_test = train_test_split(\n    train_df.index.values,\n    np.array(train_df.images.tolist()).reshape(-1, 101, 101, 1), \n    np.array(train_df.masks.tolist()).reshape(-1, 101, 101, 1), \n    train_df.coverage.values,\n    train_df.z.values,\n    test_size=0.2, stratify=train_df.coverage_class, random_state= 1234)","9c069165":"import cv2\nfrom IPython.display import display, Image\ndef cvshow(image, format='.png', rate=255 ):\n    decoded_bytes = cv2.imencode(format, image*rate)[1].tobytes()\n    display(Image(data=decoded_bytes))\n    return\n\n#usage\ncvshow(x_train_sorted_by_coverage[0])","675aa1e3":"def imgtile(imgs,tile_w):\n    assert imgs.shape[0]%tile_w==0,\"'imgs' cannot divide by 'th'.\"\n    r=imgs.reshape((-1,tile_w)+imgs.shape[1:])\n    return np.hstack(np.hstack(r))\n\n#usage\ntiled = imgtile(x_train_sorted_by_coverage[:100],10)\ncvshow(tiled)\ntiled.shape","2d56c39d":"from ipywidgets import interact,IntSlider\n@interact\ndef f(i=IntSlider(min=0,max=39,step=1,value=0)):\n    cvshow(imgtile(x_train_sorted_by_coverage[i*100:(i+1)*100],10))","057d8724":"all=imgtile(x_train_sorted_by_z,80)\ncvshow(cv2.resize( all, (80*16,50*16), interpolation=cv2.INTER_LINEAR ))","751dc4d8":"all=imgtile(y_train_sorted_by_z,80)\ncvshow(cv2.resize( all, (80*16,50*16), interpolation=cv2.INTER_LINEAR ))","a196e86f":"all=imgtile(x_train_sorted_by_coverage,80)\ncvshow(cv2.resize( all, (80*16,50*16), interpolation=cv2.INTER_LINEAR ))","22c9c88e":"all_train=imgtile(y_train_sorted_by_coverage,80)\ncvshow(cv2.resize( all_train, (80*16,50*16), interpolation=cv2.INTER_LINEAR ))","96f7f5b9":"def create_padded(imgs,dst_hw,odd_mirror=True):\n    imgs_hw=imgs.shape[1:3]\n    assert((np.array(imgs_hw)<=np.array(dst_hw)).all())\n    #calc\n    pad_t, pad_l = int((dst_hw[0]-imgs_hw[0])\/2), int((dst_hw[1]-imgs_hw[1])\/2)\n    pad_b, pad_r = dst_hw[0]-imgs_hw[0]-pad_t, dst_hw[1]-imgs_hw[1]-pad_l\n    #copy\n    ret=np.zeros((imgs.shape[0],)+dst_hw+(imgs.shape[3],))\n    ret[:,pad_t:pad_t+imgs_hw[0],pad_l:pad_l+imgs_hw[1],:]=imgs[:,:,:,:]\n    #pad\n    ofs=1 if odd_mirror else 0\n    ret[:,:pad_t,:,:]=ret[:,pad_t*2+ofs:pad_t+ofs:-1,:,:]\n    ret[:,-pad_b:,:,:]=ret[:,-pad_b-1-ofs:-pad_b*2-1-ofs:-1,:,:]\n    ret[:,:,:pad_l,:]=ret[:,:,pad_l*2+ofs:pad_l+ofs:-1,:]\n    ret[:,:,-pad_r:,:]=ret[:,:,-pad_r-1-ofs:-pad_r*2-1-ofs:-1,:]    \n    return ret\n\n#usage\nx_train_padded=create_padded(x_train_sorted_by_coverage,(192,192))\ny_train_padded=create_padded(y_train_sorted_by_coverage,(192,192))\ncvshow(imgtile(x_train_padded[:40],10))","f06e037b":"def rand_crop(x,crop_hw):\n    x_hw=x.shape[1:3]\n    assert((np.array(x_hw)>=np.array(crop_hw)).all())\n    crop_ys_max, crop_xs_max = np.array(x_hw)-np.array(crop_hw)\n    ret=[]\n    for xx in x:\n        ys, xs = randint(0,crop_ys_max), randint(0,crop_xs_max)\n        ret.append(xx[ys:ys+crop_hw[0],xs:xs+crop_hw[1],:])\n    return np.array(ret)\n\nfrom keras.callbacks import Callback\nclass RandCrop(Callback):\n    def __init__(self,src,dst):\n        self.src=src\n        self.dst=dst\n    def on_epoch_end(self, epoch, logs=None):\n        self.dst=rand_crop(self.src,self.dst.shape[1:3])","77a4799a":"#usage\n\n#Definie UNet Builder\ndef conv_block_mod(m, dim, acti, bn, res, do=0):\n    n = Conv2D(dim, 3, activation=acti, padding='same')(m)\n    n = BatchNormalization()(n) if bn else n\n    n = Dropout(do)(n) if do else n\n    n = Conv2D(dim, 3, activation=acti, padding='same')(n)\n    n = BatchNormalization()(n) if bn else n\n    return Concatenate()([m, n]) if res else n\ndef level_block_mod(m, dim, depth, inc, acti, do, bn, mp, up, res):\n    if depth > 0:\n        n = conv_block_mod(m, dim, acti, bn, res)\n        m = MaxPooling2D()(n) if mp else Conv2D(dim, 3, strides=2, padding='same')(n)\n        m = level_block_mod(m, int(inc*dim), depth-1, inc, acti, do, bn, mp, up, res)#\u518d\u5e30\n        if up:\n            m = UpSampling2D()(m)\n            m = Conv2D(dim, 2, activation=acti, padding='same')(m)\n        else:\n            m = Conv2DTranspose(dim, 3, strides=2, activation=acti, padding='same')(m)\n        n = Concatenate()([n, m])\n        m = conv_block_mod(n, dim, acti, bn, res)\n    else:\n        m = conv_block_mod(m, dim, acti, bn, res, do)\n    return m\ndef UNet_mod(img_shape, out_ch=1, start_ch=64, depth=4, inc_rate=2., activation='relu', \n         dropout=0.5, batchnorm=False, maxpool=True, upconv=True, residual=False):\n    i = Input(shape=img_shape)\n    o = level_block_mod(i, start_ch, depth, inc_rate, activation, dropout, batchnorm, maxpool, upconv, residual)#Unet\n    o = Conv2D(out_ch, 1, activation='sigmoid')(o)\n    return Model(inputs=i, outputs=o)\n\n#Create UNet\nmodel=UNet_mod((None,None,1),start_ch=16,depth=5,batchnorm=True,dropout=0.5)\nmodel.compile(loss=\"binary_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])\n\n#Set Callback\nxy_train_padded=np.concatenate((x_train_padded,y_train_padded),axis=3)\nxy_train_cropped=xy_train_padded[:,:64,:64,:]\nrandcrop = RandCrop(xy_train_padded,xy_train_cropped)\n\n#Train\nhistory = model.fit(xy_train_cropped[...,0:1], xy_train_cropped[...,1:2],\n                    epochs=1,\n                    batch_size=64,\n                    callbacks=[randcrop])","a9409896":"def cvshow_BGR(image, format='.png', rate=255 ):\n    decoded_bytes = cv2.imencode(format, image*rate)[1].tobytes()\n    display(Image(data=decoded_bytes))\n    return","761f4dad":"def create_xyp(x,y,p,p_thresh=.5):\n    if p_thresh>0:\n        p=(p>p_thresh).astype(np.float32)\n    xyp=np.concatenate((x\/2+.25,y\/8+.5,-p\/8+.5),axis=-1)\n    return np.array( [cv2.cvtColor((i*255).astype(np.uint8),cv2.COLOR_YCrCb2BGR) for i in xyp] )","550e63ad":"#usage\nx = xy_train_cropped[...,0:1]\ny = xy_train_cropped[...,1:2]\np = model.predict(x)\ncvshow_BGR(imgtile( create_xyp(x,y,p,.4)[2000:2100],10))","75b818a1":"# How to randomly cut out images using Keras's callback function\n(I have not learned how to use the generator function)\n","54f9f58e":"# Information\n* [OpenCV Python Tutorial](https:\/\/docs.opencv.org\/master\/d6\/d00\/tutorial_py_root.html)  \n* [OpenCV API Umage Processing](https:\/\/docs.opencv.org\/3.0-beta\/modules\/imgproc\/doc\/imgproc.html)","f940a07e":"# I will introduce some tips.\n","105577e5":"# Check x,y,pred","da19ef65":"# A method of arranging image arrays in a tile shape","ad8ef7eb":"# Preparation","645a80b1":"# How to display all training data as thumbnails","ac49342b":"# How to display while switching images using the slide bar","010fe3cd":"# How to display images on the screen using OpenCV","f2a53e7e":"# How to pad four sides of an image into a mirror image"}}