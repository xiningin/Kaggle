{"cell_type":{"5c04547d":"code","78b4a380":"code","080e70af":"code","5180e8a3":"code","02d84e3f":"code","d4265605":"code","fd3183c5":"code","3bbb6bcb":"code","91f5bcae":"code","56571bd8":"code","ecc1fb5c":"code","6c786b1f":"code","e34c61d5":"code","e3916a90":"code","cc3e2489":"code","775fd5fc":"code","d74ebb86":"code","81901189":"code","f1fafe8b":"code","15f45d29":"code","0487c398":"code","397e2070":"code","b0291d19":"code","7a3653d0":"code","f5c87437":"code","f95ab0a5":"code","233308a8":"code","3f722b37":"code","07ba4229":"code","c17da70a":"code","f1cb5e1f":"code","a6f6fb2e":"code","bb868254":"code","27bb199d":"code","ff29b8d1":"code","53de6a3f":"code","2f265c11":"code","318866a4":"markdown","4ebcf5b6":"markdown","50c6d60d":"markdown","026aff8b":"markdown","6dd8532d":"markdown","1304d804":"markdown","376ae02b":"markdown","e3901263":"markdown","fc6e71b6":"markdown","9ba91a2c":"markdown","3480dc7a":"markdown","54b1da0a":"markdown","d9b29db9":"markdown","f6f27d78":"markdown","81d49087":"markdown","b6740f96":"markdown","8930bf79":"markdown","afcb3a0b":"markdown","106aeb08":"markdown"},"source":{"5c04547d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\npd.options.display.max_columns = 50\nimport warnings\nwarnings.filterwarnings('ignore')\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","78b4a380":"%matplotlib inline\nimport plotly.express as px\n\nfrom collections import Counter\n\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\n\nimport holoviews as hv\nfrom holoviews import opts\n\nimport datashader as ds, datashader.transfer_functions as tf, numpy as np\nfrom datashader import spatial\nimport holoviews.operation.datashader as hd\nfrom holoviews.operation import decimate\n\nfrom functools import partial\nimport datashader as ds\nfrom datashader.utils import export_image\nfrom seaborn import color_palette\nfrom holoviews.element.tiles import StamenTerrain, EsriTerrain\n\nhv.extension('bokeh')","080e70af":"input_path = \"\/kaggle\/input\/birdsong-recognition\/\"\n\nhv_opts = dict(cmap='jet', \n               bgcolor='aqua',\n                fontsize={'xticks':7.7, 'yticks':7},\n                xrotation=90,\n                xaxis='top',\n                yaxis='left',\n                height=2200,\n                width=1300,\n                colorbar=True,\n                tools=['hover'])\n\nhv_bar = dict(fontsize={'xticks':7.7, 'yticks':7},\n#               xrotation=90,\n                xaxis='top',\n                yaxis='left',\n                height=2100,\n                width=800,\n                show_grid=True,\n                invert_axes=True,\n                tools=['hover'])\n\nhv_subplot = dict(fontsize={'xticks':7.7, 'yticks':7},\n#               xrotation=90,\n#                 xaxis='top',\n                yaxis='left',\n                height=300,\n                width=1100,\n                show_grid=True,\n                  shared_axes=False,\n#                 invert_axes=True,\n                tools=['hover'])\n\nhv_spectra = dict(height=250,\n                  width=550,\n                  show_grid=True,\n                  xaxis=None,\n                  yaxis=None,\n                  tools=['hover'])","5180e8a3":"#check audio files per bird-type\naudio_path = os.path.join(input_path, \"train_audio\/\")\naudio_dist = {}\nfor bird_type in os.listdir(audio_path):\n    len_audio = len(os.listdir(audio_path + os.sep + f\"{bird_type}\"))\n    audio_dist[bird_type] = len_audio\n\naudio_df = pd.DataFrame.from_dict(audio_dist, orient='index', \\\n                                  columns=['Audio_Count']).reset_index(drop=False).rename(columns={'index':'Bird_Type'})\n\n\naudio_df.info()","02d84e3f":"hv.Bars(audio_df.sort_values(by='Audio_Count', ascending=False)).opts(**hv_bar, color='lightpink',\n                                                                      title='Audio File Distribution For Different Birds.')","d4265605":"train_df = pd.read_csv(os.path.join(input_path, 'train.csv'))\ntrain_df.head()","fd3183c5":"train_df.info()","3bbb6bcb":"lat_long_df = train_df[['longitude', 'latitude', 'country', 'species', 'ebird_code', 'duration', 'elevation']]\nlat_long_df.replace('Not specified', np.NaN, inplace=True)\nlat_long_df.replace('?', np.NaN, inplace=True)\nlat_long_df.dropna(axis=0, inplace=True)\nlat_long_df['longitude'] = lat_long_df['longitude'].apply(lambda x: float(x))\nlat_long_df['latitude'] = lat_long_df['latitude'].apply(lambda x: float(x))\nlat_long_df[['country', 'species']] = lat_long_df[['country', 'species']].apply(lambda x: x.astype('category'))\n\n#generate Web Mercator format for Latitude and Longitude..\nfrom datashader.utils import lnglat_to_meters as webm\nlat_long_webm = list(lat_long_df[['longitude', 'latitude']].apply(lambda x: webm(*x), axis=1).values)\nlat_long_df.loc[:, 'long_wemr'] = [i[0] for i in lat_long_webm]\nlat_long_df.loc[:, 'lat_wemr'] = [i[1] for i in lat_long_webm]","91f5bcae":"decimate.max_samples=10\nx_range,y_range = (-19230442.03453801,  19831389.17363642), (-6933173.79129572, 15142823.60169782)\n\nplot_width  = int(1300)\nplot_height = int(800)\n\nunique_values = lat_long_df['ebird_code'].unique()\ncolors = ['#%02x%02x%02x' % (a, b, c) for a,b,c in np.round(255*np.array(color_palette('plasma',n_colors=len(unique_values)))).astype(int)]\ncolor_key = {val:color for val,color in zip(unique_values,colors)}","56571bd8":"tiles = StamenTerrain().redim.range(x=tuple(x_range), y=tuple(y_range))\nlat_longs = hv.Points(lat_long_df, ['long_wemr', 'lat_wemr']).opts(size=5, alpha=0.7)\n\nshade = hd.datashade(lat_longs,\n                     aggregator=ds.count_cat('ebird_code'),\n                     color_key=color_key)\n\ntiles * hd.dynspread(shade).opts(width=plot_width,\n                                  height=plot_height,\n                                  xaxis=None, yaxis=None)","ecc1fb5c":"def create_image(df, country_name, title=None, w=plot_width, h=plot_height, annotate=True):\n    \n    country_lat_long = lat_long_df[lat_long_df['country'] == country_name][['long_wemr', 'lat_wemr', 'ebird_code']]\n    country_lat_long.reset_index(drop=True,inplace=True)\n    country_species = country_lat_long.pop('ebird_code')\n    \n    (long_min, lat_min), (long_max, lat_max) = country_lat_long.min(), country_lat_long.max()\n    \n    longitude_range, latitude_range = (long_min, long_max), (lat_min, lat_max)\n    x_range, y_range = longitude_range, latitude_range\n    \n    country_lat_long.loc[:, 'ebird_code'] = country_species.values\n\n    tiles = EsriTerrain().redim.range(x=tuple(x_range), y=tuple(y_range))\n    \n    lat_longs = hv.Points(country_lat_long, ['long_wemr', 'lat_wemr']).opts(size=25, alpha=0.9)\n    shade = hd.datashade(lat_longs,\n                         aggregator=ds.count_cat('ebird_code'),\n                         color_key=color_key)\n    if annotate:\n        labels = hv.Labels(country_lat_long, ['long_wemr', 'lat_wemr'], 'ebird_code').opts(opts.Labels(text_color='ebird_code',\n                                                                                                        padding=5.5, \n                                                                                                        fontsize=1,\n                                                                                                        text_alpha=0.4))\n        layout = tiles * hd.dynspread(shade).opts(width=w,title=title,\n                                                  fontsize=13,\n                                                height=h,\n                                                xaxis=None,\n                                                yaxis=None) * decimate(labels)\n        return layout\n    \n    else:\n        layout = tiles * hd.dynspread(shade).opts(width=w,title=title,\n                                                height=h,\n                                                xaxis=None,\n                                                yaxis=None)\n        return layout","6c786b1f":"top_5 = lat_long_df['country'].value_counts()[:5].index.to_list()\ncountry_layout = []\n\nfor country in top_5:\n    country_layout.append(create_image(lat_long_df, str(country), title=str(country), w=700, h=500, annotate=True))\n    \nlayout = hv.Layout(country_layout).cols(2)\n\ndisplay(layout)","e34c61d5":"cat_unique_df = train_df.select_dtypes(include='object').nunique().reset_index().rename(columns={'index':'Column_Name',\n                                                                                 0 : 'Unique_values'}).sort_values(by='Unique_values')\nhv.Bars(cat_unique_df).opts(**hv_bar, color='aqua', title='Unique Values For Each Catergorical Variable.')","e3916a90":"int_unique_df = train_df.select_dtypes(include=['int', 'float']).nunique().reset_index().rename(columns={'index':'Column_Name',\n                                                                                                   0 : 'Unique_values'}).sort_values(by='Unique_values')\nhv.Bars(int_unique_df).opts(**hv_subplot,\n                            color='lightgreen',\n#                             height=500,\n                            title='Unique Values For Each Integer\/Float Variable.')","cc3e2489":"hv.Bars(train_df['species'].value_counts()).opts(**hv_bar, color='orange', title='Distribution of Species.')","775fd5fc":"hv.Bars(train_df['ebird_code'].value_counts()).opts(**hv_bar, color='orange', title='Distribution of ebird_code.')","d74ebb86":"hv.Bars(train_df['rating'].value_counts()).opts(**hv_subplot, color='lightblue', title='Distribution of Ratings.')","81901189":"hv.Bars(train_df['sampling_rate'].value_counts()).opts(**hv_subplot, color='lightblue', title='Distribution of Sampling Rate for the Audio Files.')","f1fafe8b":"hv.Bars(train_df['playback_used'].value_counts()).opts(**hv_subplot, color='lightblue', title='Distribution of Playback Audio.')","15f45d29":"hv.Bars(train_df['number_of_notes'].value_counts()).opts(**hv_subplot, color='lightblue', title='Distribution Of Number Of Notes in Audio.')","0487c398":"hv.Bars(train_df['playback_used'].value_counts()).opts(**hv_subplot, color='lightblue', title='Distribution Of Playback Used.')","397e2070":"df_date = train_df.groupby(\"date\")[\"species\"].count().reset_index().rename(columns = {\"species\": \"recordings\"})\ndf_date.date = pd.to_datetime(df_date.date, errors = \"coerce\")\ndf_date[\"weekday\"] = df_date.date.dt.day_name()\ndf_date.dropna(inplace = True)\nper_day_records = df_date.groupby('weekday', as_index=False).sum().sort_values(by='weekday')","b0291d19":"sub_1 = hv.Curve(data=df_date).opts(**hv_subplot, color='darkgrey', title='Yearwise Recordings')\nsub_2 = hv.Bars(data=per_day_records).opts(**hv_subplot, color='grey', title='Daywise Recordings')\nhv.Layout([sub_1, sub_2]).cols(1)","7a3653d0":"hv.BoxWhisker(train_df, vdims='duration', kdims='species').opts(**hv_bar, title='Distribution of Duration Of Audio \\n wrt. Bird Species.')","f5c87437":"countrywise_species_df = train_df.groupby(['country', 'species'], as_index=False)['ebird_code'].count()\nhv_opts['cmap'] = 'viridis'\nhv.HeatMap(countrywise_species_df).opts(**hv_opts, title='Countrywise Bird Species Distribution.')","f95ab0a5":"import librosa\nimport random\n\ndef get_file(n=1, species=5):\n    ran_samples = {}\n    \n    for species in list(audio_dist.keys())[:5]:\n        species_samples = os.listdir(audio_path + os.sep + species)\n        ran_samples[species] = random.sample(species_samples, n).pop()\n    \n    return [audio_path + sp + os.sep + file for sp, file in ran_samples.items()]\n    \n\nsample_files = get_file(n=1,species=5)\nprint(sample_files)","233308a8":"tempogram_info = {}\nchromagram_info = {}\nspectral_bandwidth_info = {}\ntonnetz_info = {}\nmfcc_info = {}\npoly_info = {}\nspec_contrast_info = {}\nfourier_tempo_info = {}\n\n\nfor file in sample_files:\n    print(file)\n    data, sr = librosa.load(file)\n    \n    chromagram_info[file] = librosa.feature.chroma_stft(data, sr=sr)\n    spectral_bandwidth_info[file] = librosa.feature.spectral_bandwidth(data, sr=sr)\n    tonnetz_info[file] = librosa.feature.tonnetz(data, sr=sr)\n    mfcc_info[file] = librosa.feature.mfcc(data, sr=sr)\n    poly_info[file] = librosa.feature.poly_features(data, win_length=15, sr=sr)\n    spec_contrast_info[file] = librosa.feature.spectral_contrast(data, sr=sr)\n    \n    #declare onset strength with hop length for rythmic features aka tempogram..\n    oenv = librosa.onset.onset_strength(y=data, sr=sr, hop_length=512)\n    fourier_tempo_info[file] = np.abs(librosa.feature.fourier_tempogram(onset_envelope=oenv,\n                                                                        sr=sr,\n                                                                        hop_length=512))\n    tempogram_info[file] = librosa.feature.tempogram(onset_envelope=oenv,\n                                                     sr=sr,\n                                                     hop_length=512)","3f722b37":"def plot_features(features_dict, title='Chromagram'):\n    layout = []\n\n    for k,v in features_dict.items():\n        species, files = k.split(\"\/\")[-2:]\n        gram = hv.Image(features_dict[k]).opts(**hv_spectra, cmap='plasma',\n                                               title=f\"{species.capitalize()}-{files.capitalize()} || {title}\")\n\n        layout.append(gram)\n    \n    plot = hv.Layout(layout).cols(2)\n\n    return plot","07ba4229":"plot_features(chromagram_info)","c17da70a":"plot_features(tonnetz_info, title='Tonnetz - Tonal Centroid.')","f1cb5e1f":"plot_features(mfcc_info, title='MFCCs.')","a6f6fb2e":"plot_features(poly_info, title='Poly Feats. window size 15')","bb868254":"plot_features(spec_contrast_info, title='Spectral Contrast.')","27bb199d":"plot_features(tempogram_info, title='Auto-Correlation Tempogram')","ff29b8d1":"plot_features(fourier_tempo_info, title='Fourier Tempogram.')","53de6a3f":"#let's use one audio file\n\nsample_audio = sample_files[0]\nsample_audio, rate = librosa.load(sample_audio)\n\n#spectrogram ..\nsample_stft = np.abs(librosa.stft(sample_audio))\n#decompose the spectrogram such that components.dot(activations)..\ncomps, acts = librosa.decompose.decompose(sample_stft, n_components=32)\n\n#reconstructed...\nstft_recons = comps.dot(acts)","2f265c11":"stft_glyph = hv.Raster(librosa.amplitude_to_db(sample_stft,\n                                               ref=np.max)).opts(**hv_subplot,\n                                                                              cmap='plasma',\n                                                                              title=\"Spectrogram\")\n\n#decompose..\ncomps_glyph = hv.Raster(librosa.amplitude_to_db(comps,\n                                                ref=np.max)).opts(**hv_subplot,\n                                                                         cmap='plasma',\n                                                                         title='Components')\nacts_glyph = hv.Image(acts).opts(**hv_subplot,\n                                 cmap='plasma',\n                                 title='Activations')\n\n#reconstruct..\nstft_recons_glyph = hv.Raster(librosa.amplitude_to_db(stft_recons,\n                                                      ref=np.max)).opts(**hv_subplot,\n                                                                                     cmap='plasma',\n                                                                                     title='Reconstructed Spectogram | [coms.dot(actss)]')\n\nhv.Layout(stft_glyph + comps_glyph + acts_glyph + stft_recons_glyph).cols(1) ","318866a4":"# Top 5 Countries","4ebcf5b6":"# [Chromagram](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.chroma_stft.html#librosa.feature.chroma_stft) - Compute a chromagram from a waveform","50c6d60d":"# Train Data","026aff8b":"### Categorical Types","6dd8532d":"### Float Types","1304d804":"# [Data Shading](https:\/\/holoviews.org\/index.html) - Using Lat & Long Information","376ae02b":"# Unique Values Check","e3901263":"# [Poly-Features](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.poly_features.html#librosa.feature.poly_features) - Coefficients of fitting an nth-order polynomial to the columns of a spectrogram.","fc6e71b6":"# [MFCC](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.mfcc.html#librosa.feature.mfcc) - Mel-frequency cepstral coefficients (MFCCs)","9ba91a2c":"# [Spectral Contrast](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.spectral_contrast.html#librosa.feature.spectral_contrast) - Computes Spectral Contrast","3480dc7a":"# [Tonnetz](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.tonnetz.html#librosa.feature.tonnetz) - Computes the tonal centroid features (tonnetz)","54b1da0a":"# Spectrogram","d9b29db9":"## [Fourier Tempogram](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.fourier_tempogram.html#librosa.feature.fourier_tempogram) - Computes the Fourier Tempogram","f6f27d78":"# Rhythm Features\n\n## [Tempogram](https:\/\/librosa.org\/librosa\/generated\/librosa.feature.tempogram.html#id1) - Computes the Auto-Correlation tempogram","81d49087":"Looks like `ebird_code` and `species` has same Distribution.","b6740f96":"# Audio Files Check","8930bf79":"# Audio Data - Feature Extraction using Librosa[[](http:\/\/)](http:\/\/)\n\nLet's extract some features using Librosa library from the audio signals","afcb3a0b":"# Some Variable Distributions","106aeb08":"### The Cornell Lab of Ornithology\u2019s Center for Conservation Bioacoustics (CCB)\u2019s mission is to collect and interpret sounds in nature. The CCB develops innovative conservation technologies to inspire and inform the conservation of wildlife and habitats globally. By partnering with the data science community, the CCB hopes to further its mission and improve the accuracy of soundscape analyses.In this competition, you will identify a wide variety of bird vocalizations in soundscape recordings. Due to the complexity of the recordings, they contain weak labels. There might be anthropogenic sounds (e.g., airplane overflights) or other bird and non-bird (e.g., chipmunk) calls in the background, with a particular labeled bird species in the foreground. Bring your new ideas to build effective detectors and classifiers for analyzing complex soundscape recordings!. To unlock the full potential of these extensive and information-rich sound archives, researchers need good machine listeners to reliably extract as much information as possible to aid data-driven conservation."}}