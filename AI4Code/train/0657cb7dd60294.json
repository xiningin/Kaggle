{"cell_type":{"7972564b":"code","6142704b":"code","ecdddc50":"code","08fdd886":"code","7c0a9e80":"code","f3112763":"code","4561ec8d":"code","5a9c8e63":"code","d46d988c":"code","7c64cf13":"code","ba640581":"code","9050d21e":"code","173aead4":"code","c81d2768":"code","97eea61e":"code","052b3a8e":"code","e47de1d0":"code","da100c2b":"code","982a2f83":"code","5a2988e1":"code","8e3975f2":"code","597aa0bf":"code","a3100aba":"code","25c2d1ee":"code","b3dc13f2":"code","1770dcac":"code","af04235f":"code","522136c2":"code","b31bd327":"code","e6e58dd3":"code","5c629895":"code","cc3bd43a":"code","620595d4":"code","1119f7f3":"code","e96c1dd5":"code","f28ca2fa":"code","63f83e7b":"code","c52ead65":"code","a48974f1":"code","a46e00d4":"code","c3285f22":"code","49821826":"code","0a1cff59":"code","a370793b":"code","e81e9e9f":"code","f81b8003":"code","90cb32bc":"code","c4fc238f":"code","6d9b1565":"markdown","3b20f28d":"markdown","5cbad453":"markdown","2e8e52fb":"markdown","80fa3b29":"markdown","29c7b7e4":"markdown","188660c1":"markdown","d2466a06":"markdown","634849cb":"markdown","b16b3b1f":"markdown","bf5bd008":"markdown","822d0a09":"markdown","e32a5a51":"markdown","2edbb1a3":"markdown","d8651abc":"markdown","9a28d896":"markdown"},"source":{"7972564b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns  # visualization tool\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\"))\n\n# Any results you write to the current directory are saved as output.","6142704b":"data = pd.read_csv('..\/input\/Country.csv') # Show the path you will use","ecdddc50":"data.info() # Display content of data ","08fdd886":"data.head() # Display first 5 rows of data\n#data.tail","7c0a9e80":"data.columns # Display first all columns of data","f3112763":"# data frames from dictionary\ncountry = [\"Spain\",\"Turkey\"]\nprint(country)\npopulation = [\"100\",\"200\"]\nprint(population)\nlist_label = [\"countries\",\"populations\"]\nprint(list_label)\nprint('')\nlist_col = [country,population]\nprint(list_col)\nzipped = list(zip(list_label,list_col))\nprint(zipped)\ndata_dict = dict(zipped)\ndf = pd.DataFrame(data_dict)\ndf\n","4561ec8d":"# Adding new columns\ndf[\"capital\"]=[\"Madrid\",\"Ankara\"]\ndf\n","5a9c8e63":"# Broadcasting\ndf[\"income\"] = 0 # Broadcasting entire column\ndf","d46d988c":"data.head()","7c64cf13":"# Plotting all data \ndata1 = data.loc[:,[\"LatestIndustrialData\",\"LatestTradeData\",\"LatestWaterWithdrawalData\"]]\ndata1.plot()\n# graph is confusing, lets create subplots","ba640581":"# subplots let us seperate graphs\ndata1.plot(subplots = True)\nplt.show()","9050d21e":"# scatter plot usage\ndata1.plot(kind = \"scatter\",x=\"LatestTradeData\",y = \"LatestWaterWithdrawalData\")\nplt.show()","173aead4":"# histogram plot \ndata1.plot(kind=\"hist\",y = \"LatestWaterWithdrawalData\",bins = 10)","c81d2768":"# histogram subplot with non-cumulative and cumulative\nfig, axes = plt.subplots(nrows=2,ncols=1)\ndata1.plot(kind = \"hist\",y = \"LatestWaterWithdrawalData\",bins = 50,normed = True,ax = axes[0])\ndata1.plot(kind = \"hist\",y = \"LatestWaterWithdrawalData\",bins = 50,normed = True,ax = axes[1],cumulative = True)\nplt.savefig('graph.png')\nplt","97eea61e":"# Lets take a look at statistical information\ndata.describe()","052b3a8e":"time_list = [\"1992-03-08\",\"1992-04-12\"]\nprint(type(time_list[1])) # As you can see date is string\n# however, we want it to be a datetime object\ndatetime_object = pd.to_datetime(time_list)\nprint(type(datetime_object))","e47de1d0":"# close warning (not about this part)\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# In order to practice, lets take a look at head of world development data and add it to a time list\ndata2 = data.head()\ndate_list = [\"1992-01-10\",\"1992-02-10\",\"1992-03-10\",\"1993-03-15\",\"1993-03-16\"]\ndatetime_object = pd.to_datetime(date_list)\ndata2[\"date\"] = datetime_object\n\n# lets make date as index\ndata2= data2.set_index(\"date\")\ndata2 ","da100c2b":"# Now we can select according to our date index\nprint(data2.loc[\"1993-03-16\"])","982a2f83":"print(data2.loc[\"1992-03-10\":\"1993-03-16\"])","5a2988e1":"# We will use data2 that we create at previous part\ndata2.resample(\"A\").mean()","8e3975f2":"# Lets resample with month\ndata2.resample(\"M\").mean()\n# As you can see there are a lot of nan values because data2 does not include all months","597aa0bf":"# In real life (Data is real. Not created from us like data2), we can solve this problem with interpolate\n# We can interpolete from first value\ndata2.resample(\"M\").first().interpolate(\"linear\")\n# Take a look at last columns","a3100aba":"# Or we can interpolate with mean()\ndata2.resample(\"M\").mean().interpolate(\"linear\")","25c2d1ee":"#Changing index of our data\n#data = data.set_index(\"CountryCode\")   \n#data.head()","b3dc13f2":"# indexing using square brackets (same as below)\ndata[\"Alpha2Code\"][1]\n\n# using column attribute and row label\n# data.Alpha2Code[1]","1770dcac":"# Selecting only some columns\ndata[[\"ShortName\",\"LongName\"]]","af04235f":"# Difference between selecting columns: series and dataframes\nprint(type(data[\"ShortName\"]))     # series\nprint(type(data[[\"ShortName\"]]))   # data frames","522136c2":"# Slicing and indexing series\ndata.loc[1:10,\"Alpha2Code\":\"Region\"]   # 10 and \"Defense\" are inclusive","b31bd327":"# Reverse slicing \ndata.loc[10:1:-1,\"Alpha2Code\":\"Region\"]","e6e58dd3":"# From something to end\ndata.loc[1:10,\"LatestAgriculturalCensus\":]","5c629895":"# Creating boolean series\nboolean = data.LatestWaterWithdrawalData > 2011\ndata[boolean]","cc3bd43a":"# Combining filters\nfirst_filter = data.LatestIndustrialData > 2008\nsecond_filter = data.LatestWaterWithdrawalData > 2011\ndata[first_filter & second_filter]","620595d4":"# Filtering column based others\ndata.LatestIndustrialData[data.LatestIndustrialData<2008]","1119f7f3":"# Applying python functions to data\ndef div(n):\n    return n\/2\ndata.LatestIndustrialData.apply(div)","e96c1dd5":"# Or we can use lambda function for shorter way\ndata.LatestIndustrialData.apply(lambda n : n\/2)","f28ca2fa":"# Defining column using other columns\ndata[\"superiors\"] = data.LatestIndustrialData + data.LatestTradeData  #just an example\ndata.head()","63f83e7b":"# this shows our index name:\nprint(data.index.name)   #None\n# lets change it\ndata.index.name = \"index_name\"\ndata.head()","c52ead65":"# Overwrite index\n# if we want to modify index we need to change all of them.\ndata.head()\n# first copy of our data to data3 then change index \ndata3 = data.copy()\n# lets make index start from 100. It is not remarkable change but it is just an example\ndata3.index = range(100,347,1)\ndata3.head()","a48974f1":"# We can make one of the column as index. I actually did it at the beginning of manipulating data frames with pandas section\n# It was like this;\n# data = data.set_index(\"CountryCode\")\n# also you can use; \n# data.index = data[\"CountryCode\"]","a46e00d4":"dic = {\"sports\":[\"Football\",\"Football\",\"Basketball\",\"Basketball\"],\"gender\":[\"F\",\"M\",\"F\",\"M\"],\"skill\":[10,45,32,9],\"age\":[15,20,52,43]}\ndf = pd.DataFrame(dic)\ndf","c3285f22":"# pivoting\ndf.pivot(index=\"sports\",columns = \"gender\",values=\"skill\")","49821826":"df1 = df.set_index([\"sports\",\"gender\"])\ndf1\n# lets unstack it","0a1cff59":"# level determines indexes\ndf1.unstack(level=0)\n\n# or\n#df1.unstack(level=1)","a370793b":"# change inner and outer level index position\ndf2 = df1.swaplevel(0,1)\ndf2","e81e9e9f":"# df.pivot(index=\"sports\",columns = \"gender\",values=\"response\")\npd.melt(df,id_vars=\"sports\",value_vars=[\"age\",\"skill\",\"gender\"])","f81b8003":"# according to sports take means of other features\ndf.groupby(\"sports\").mean()   # mean is aggregation \/ reduction method\n# there are other methods like sum, std, max or min","90cb32bc":"# we can choose specific feature\ndf.groupby(\"sports\").age.max()","c4fc238f":"# Or we can choose multiple features\ndf.groupby(\"sports\")[[\"age\",\"skill\"]].min() ","6d9b1565":"**Transforming Data**","3b20f28d":"**Building Data Frames From Scratch**","5cbad453":"**Basic steps to start Data Science: PART4**","2e8e52fb":"**Indexing Data Frames**","80fa3b29":"**Filtering Data Frames**","29c7b7e4":"**Pivoting Data Frames**","188660c1":"**Visual Exploratory Data Analysis**\n\n* Plot\n\n* Subplot\n\n* Histogram","d2466a06":"**Categoricals and Groupby**","634849cb":"**Index Objects and Labeled Data**","b16b3b1f":"**Indexing Pandas Time Series**\n\n* datetime = object\n\n* parse_dates(boolean): Transform date to ISO 8601 (yyyy-mm-dd hh:mm:ss ) format","bf5bd008":"**Statistical Exploratory Data Analysis**\n\n* count: number of entries\n\n* mean: average of entries\n\n* std: standart deviation\n\n* min: minimum entry\n\n* 25%: first quantile\n\n* 50%: median or second quantile\n\n* 75%: third quantile\n\n* max: maximum entry","822d0a09":"**Slicing Data Frame**","e32a5a51":"**Staking and Unstacking Dataframe**","2edbb1a3":"**Resampling Pandas Time Series**\n\n* Resampling: statistical method over different time intervals\n * Needs string to specify frequency like \"M\" = month or \"A\" = year\n\n* Downsampling: reduce date time rows to slower frequency like from daily to weekly\n\n* Upsampling: increase date time rows to faster frequency like from daily to hourly\n\n* Interpolate: Interpolate values according to different methods like \u2018linear\u2019, \u2018time\u2019 or index\u2019","d8651abc":"Read more here:\n\n* [Basic steps to start Data Science: PART1](https:\/\/www.kaggle.com\/osmanaliyardim\/data-science-introduction)\n\n* [Basic steps to start Data Science: PART2](https:\/\/www.kaggle.com\/osmanaliyardim\/data-science-introduction-2)\n\n* [Basic steps to start Data Science: PART3](https:\/\/www.kaggle.com\/osmanaliyardim\/data-science-introduction-3)\n","9a28d896":"**Melting Dataframes**"}}