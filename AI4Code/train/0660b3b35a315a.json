{"cell_type":{"810439ff":"code","c83ae7d4":"code","cd24ab8a":"code","c3029750":"code","c540b2bd":"code","01466673":"code","4b247854":"code","b28a57fd":"code","223febee":"code","6decfde1":"code","3430d8b3":"code","d3507637":"code","7a822825":"code","d23db4b1":"code","7abe75f6":"code","a63cbab8":"code","8f2a3f3a":"code","47dcba2d":"code","b63d8dcb":"code","73b22e7d":"code","32adb3ec":"code","6acc87b7":"markdown","272ec853":"markdown","d423b6a2":"markdown","96036d3d":"markdown","3e2f55b6":"markdown","e76b4864":"markdown","a3a7fbbb":"markdown","2a570f0b":"markdown","9dd141c4":"markdown","11d2a2eb":"markdown","47422c93":"markdown","c148ad46":"markdown","1107aae0":"markdown","20472dce":"markdown"},"source":{"810439ff":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split\n\n\n#PyTorch\nimport torch\nimport torch.nn as nn\nfrom torchvision import transforms, models\nfrom torch import optim , nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset","c83ae7d4":"#Getting csv data\n\ntrain = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nx_train = train.iloc[:,1:].values\/255\ny_train = train.label.values","cd24ab8a":"#Dividing into train and validation set\n\ntrain_x, val_x, train_y, val_y = train_test_split(x_train, y_train, test_size = 0.2, random_state = 42)","c3029750":"#Converting into Tensors from_numpy()\n\ntrain_x_torch = torch.from_numpy(train_x).type(torch.FloatTensor)\nval_x_torch = torch.from_numpy(val_x).type(torch.FloatTensor)\n\ntrain_y_torch = torch.from_numpy(train_y).type(torch.LongTensor) #Data typecasting\nval_y_torch = torch.from_numpy(val_y).type(torch.LongTensor)","c540b2bd":"batch_size = 128  #anything b\/w 64 and 256 works\n\n#Preparing training set and test set\ntrainset = torch.utils.data.TensorDataset(train_x_torch, train_y_torch)\nvalset = torch.utils.data.TensorDataset(val_x_torch, val_y_torch)\n\n\n#Preparing Data loaders\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size = batch_size, shuffle = True)\nvalloader = torch.utils.data.DataLoader(valset, batch_size = batch_size, shuffle = True)","01466673":"# Building a Neural Network\n\nclass Net(nn.Module):\n    def __init__(self):\n        super(Net, self).__init__()\n        self.fc1 = nn.Linear(28*28*1, 1024)\n        self.fc2 = nn.Linear(1024, 512)\n        self.fc3 = nn.Linear(512,256)\n        self.fc4 = nn.Linear(256,128)\n        self.fc5 = nn.Linear(128,64)\n        self.fc6 = nn.Linear(64,10)\n        \n        self.dropout = nn.Dropout(p=0.3)\n        \n        self.softmax = F.log_softmax\n        \n    def forward(self, X):\n        X = self.dropout(F.relu(self.fc1(X)))\n        X = self.dropout(F.relu(self.fc2(X)))\n        X = self.dropout(F.relu(self.fc3(X)))\n        X = self.dropout(F.relu(self.fc4(X)))\n        X = self.dropout(F.relu(self.fc5(X)))\n        X = self.softmax(self.fc6(X), dim=1)\n        \n        return X","4b247854":"## Training Our Neural Network\nmodel = Net()\n\ndef fit(model, trainloader, valloader, epochs = 25):\n    criterion = nn.NLLLoss()\n\n    #weight decay for L2 Regularization\n    optimizer = optim.Adam(model.parameters(), lr = 0.0003)\n\n    epochs = epochs\n\n    steps = 0\n    print_at = 50\n\n    train_losses, test_losses = [], []\n\n    for e in range(epochs):\n        running_loss = 0\n    \n        for images, labels in trainloader:\n            steps+=1\n        \n            #Start from zero every epoch\n            optimizer.zero_grad()\n        \n            #Make predictions\n            output = model(images)\n        \n            #Calculate loss\n            loss = criterion(output, labels)\n        \n            #backprop\n            loss.backward()\n        \n            #Adjusting weights\n            optimizer.step()\n        \n            running_loss += loss.item()\n        \n            #For validation\n            if steps%print_at == 0:\n                test_loss = 0\n                accuracy = 0\n            \n                #Turn of gradients and go into eval mode\n                with torch.no_grad():\n                    model.eval()\n                \n                    for images, labels in valloader:\n                        output = model(images)\n                        test_loss += criterion(output, labels)\n                    \n                        probs = torch.exp(output)\n                    \n                        top_p, top_class = probs.topk(1, dim = 1)\n                    \n                        equals = top_class == labels.view(*top_class.shape)\n                    \n                        accuracy += torch.mean(equals.type(torch.FloatTensor))\n                    \n                model.train()\n            \n                train_losses.append(running_loss\/len(trainloader))\n                test_losses.append(test_loss\/len(valloader))\n            \n                print('epochs{}\/{}.. '.format(e+1, epochs),\n                     \"Training Loss: {:.3f}.. \".format(train_losses[-1]),\n                     \"Validation Loss: {:.3f}.. \".format(test_losses[-1]),\n                     \"Test Accuracy: {:.3f}.. \".format(accuracy\/len(valloader)) )\n            \n    return train_losses, test_losses       ","b28a57fd":"train_losses, test_losses = fit(model, trainloader, valloader)","223febee":"%matplotlib inline\n\nplt.plot(train_losses, label ='Training Loss')\nplt.plot(test_losses, label = 'Test Loss')\nplt.title('ANN Training')\nplt.legend(frameon=False)","6decfde1":"test = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nx_test = test.values\/255\nx_test_torch = torch.from_numpy(x_test).type(torch.FloatTensor)","3430d8b3":"dummy_labels = np.zeros(x_test.shape)\ndummy_labels = torch.from_numpy(dummy_labels)","d3507637":"testset = torch.utils.data.TensorDataset(x_test_torch, dummy_labels)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)","7a822825":"submit = [['ImageId', 'Label']]\n\n#turning of gradients\nwith torch.no_grad():\n    model.eval()\n    image_id = 1\n    \n    for images, _ in testloader:\n        outputs = model(images)\n        probs = torch.exp(outputs)\n        \n        top_p, top_class = probs.topk(1, dim = 1)\n        \n        for preds in top_class:\n            submit.append([image_id,preds.item()])\n            image_id += 1","d23db4b1":"submit_df = pd.DataFrame(submit)\nsubmit_df.columns = submit_df.iloc[0]\nsubmit_df = submit_df.drop(0, axis = 0)\n\nsubmit_df.to_csv('ANN_Submission.csv', index = False)","7abe75f6":"batch_size = 128\n\ntrain_x_torch = train_x_torch.view(-1, 1,28,28).float()\nval_x_torch = val_x_torch.view(-1, 1,28,28).float()\n\n#preparing training and validation dataset\ntrainset = torch.utils.data.TensorDataset(train_x_torch, train_y_torch)\nvalset = torch.utils.data.TensorDataset(val_x_torch, val_y_torch)\n\n#preparing Data Loaders\n\ntrainloader = torch.utils.data.DataLoader(trainset, shuffle = True, batch_size = batch_size)\nvalloader = torch.utils.data.DataLoader(valset, shuffle = True, batch_size = batch_size)","a63cbab8":"class CNN(nn.Module):\n    def __init__(self):\n        super(CNN, self).__init__()\n        self.conv1 = nn.Conv2d(1, 64, kernel_size = 3, padding =1)\n        self.conv2 = nn.Conv2d(64, 128, kernel_size = 3, padding =1)\n        self.conv3 = nn.Conv2d(128, 128, kernel_size = 3, padding =1)\n        \n        self.relu = nn.ReLU()\n        \n        self.pool = nn.MaxPool2d(2, 2)\n        \n        self.fc1 = nn.Linear(3*3*128, 512)\n        \n        self.fc2 = nn.Linear(512, 10)\n        \n        self.dropout = nn.Dropout(p=0.3)\n        \n        self.softmax = F.log_softmax\n        \n    def forward(self, X):\n        X = self.dropout(self.relu(self.pool(self.conv1(X))))\n        X = self.dropout(self.relu(self.pool(self.conv2(X))))\n        X = self.dropout(self.relu(self.pool(self.conv3(X))))\n        X = X.view(-1, 3*3*128)\n        \n        X = self.dropout(self.relu(self.fc1(X)))\n        \n        X = self.softmax(self.fc2(X), dim = 1)\n        \n        return X\n        \n        ","8f2a3f3a":"cnn = CNN()\n\n#training our CNN\ntrain_losses, test_losses = fit(cnn, trainloader, valloader, epochs = 10)","47dcba2d":"%matplotlib inline\n\nplt.plot(train_losses, label ='Training Loss')\nplt.plot(test_losses, label = 'Test Loss')\nplt.title('CNN Training')\nplt.legend(frameon=False)","b63d8dcb":"#reshaping test data for feeding CNN\nx_test_torch = x_test_torch.view(-1, 1, 28, 28)\n\ntestset = torch.utils.data.TensorDataset(x_test_torch, dummy_labels)\n\ntestloader = torch.utils.data.DataLoader(testset, batch_size = batch_size, shuffle = False)","73b22e7d":"submit = [['ImageId', 'Label']]\n\n#turning of gradients\nwith torch.no_grad():\n    cnn.eval()\n    image_id = 1\n    \n    for images, _ in testloader:\n        outputs = cnn(images)\n        probs = torch.exp(outputs)\n        \n        top_p, top_class = probs.topk(1, dim = 1)\n        \n        for preds in top_class:\n            submit.append([image_id,preds.item()])\n            image_id += 1","32adb3ec":"submit_df = pd.DataFrame(submit)\nsubmit_df.columns = submit_df.iloc[0]\nsubmit_df = submit_df.drop(0, axis = 0)\n\nsubmit_df.to_csv('CNN_Submission.csv', index = False)","6acc87b7":"# 2. CNN (Convolution Neural Network)","272ec853":"## Making Predictions","d423b6a2":"## Creating ANN Submission File!","96036d3d":"# Digit Recognition Using PyTorch (ANN and CNN Implementation)\n\n#### Just learnt and gone through how things work in PyTorch, how to train and work on deep learning use cases, and thouht to try out my skills on this baseline model.\n\n#### All steps are covered from preparing data loaders to training and Validating our model. Feel free to give feedback.","3e2f55b6":"## Importing Libraries","e76b4864":"## Preparing test Data for submission","a3a7fbbb":"## Preparing Train and Validation Data","2a570f0b":"## How did our baseline model performed","9dd141c4":"## Constructing a basic Neural Network in PyTorch","11d2a2eb":"## Training and Validation","47422c93":"## Making CNN Submission file!","c148ad46":"## Preparing Data","1107aae0":"# 1. ANN (Artificial Neural Network)","20472dce":"\n\n## I am just a beginner and your upvote will motivate me! \ud83e\udd17\ud83d\ude07 "}}