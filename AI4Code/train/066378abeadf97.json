{"cell_type":{"967bd3b5":"code","6a2144e0":"code","47fcfa9e":"code","5f2fc756":"code","4748985b":"code","8ff632f8":"code","44eaeb4b":"code","81416749":"code","a4eb01f8":"code","aa6a2656":"code","56181659":"code","67bd2d0e":"code","aeff85e4":"code","c0a2cc42":"code","29291b7d":"code","75f512a5":"code","00ba355f":"code","cce02351":"code","fefb92d8":"code","2e71468a":"code","bb61c7d8":"code","5a401cf4":"code","4bc92b91":"code","3c60b228":"code","bf9aa11e":"code","f974501d":"code","f5edb180":"code","ad767dba":"code","3a323743":"code","5eecc55e":"markdown","8e9528f6":"markdown","3def11a0":"markdown","2be24cc8":"markdown","87c58e3a":"markdown","03923b7f":"markdown","fcbed22d":"markdown","7cc134e2":"markdown","c6ff7481":"markdown","f26c8958":"markdown","80b05660":"markdown","e3a5b3e8":"markdown","2949648a":"markdown"},"source":{"967bd3b5":"import pandas as pd\nimport numpy as np\nimport scipy\nimport sklearn\nfrom sklearn import linear_model\nfrom sklearn.linear_model import TweedieRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\nfrom sklearn.neural_network import MLPRegressor","6a2144e0":"# training data: ..\/data\/train.csv\n# test data:     ..\/data\/test.csv","47fcfa9e":"filepath = '..\/input\/2020fa-inls690-funny-news-headline\/train.csv'\ndataframe = pd.read_csv(filepath)\nprint(len(dataframe))\n# print(dataframe)","5f2fc756":"train_ratio = 0.7 # 70% for training, 30% for validation\nrandom_seed = None # a fixed random seed allows fixed random runs (for controlled debugging). set to None to be random.\n\ntrain_dataframe = dataframe.sample(frac= train_ratio, random_state=100) \nvalid_dataframe = dataframe.drop(train_dataframe.index)\nprint('training set size:', len(train_dataframe))\nprint('validation set size:', len(valid_dataframe))\n# print(train_dataframe)","4748985b":"test_filepath = '..\/input\/2020fa-inls690-funny-news-headline\/test.csv'\ntest_dataframe = pd.read_csv(test_filepath)\nprint('test set size:', len(test_dataframe))\n# print(test_dataframe)","8ff632f8":"# take out prediction targets: mean grades \ntrain_Y = train_dataframe['meanGrade']\nvalid_Y = valid_dataframe['meanGrade']","44eaeb4b":"# compute average of a list of numbers: np.mean\ntrain_Y_avg = np.mean(train_dataframe['meanGrade'])\nprint('average meanGrade on training set:', train_Y_avg)\n\n# make a list filled with train_Y_avg, essentially predicting the same number for all lines in validation set\navg_pred_valid = [train_Y_avg for i in range(len(valid_dataframe))]\n# print (avg_pred_valid)\n\n# compute root mean squared error (RMSE) of this prediction on validation set\nrmse = np.sqrt(mean_squared_error(valid_Y, avg_pred_valid))\nprint('RMSE on validation set:', rmse)\n\n#taking the mean as the error","81416749":"# helper function: write out prediction values into a csv format file\n# params:\n#     df: dataframe, where each row is a test example, with column 'id' as data id\n#     pred: a list or 1-d array of prediction values\n#     filepath: the output file path\n# return:\n#     None\n\ndef write_test_prediction(df, pred, filepath):\n    with open(filepath, 'w') as outfile:\n        outfile.write('{},{}\\n'.format('id', 'pred'))\n        for index, row in df.iterrows():\n            outfile.write('{},{}\\n'.format(row['id'], pred[index]))","a4eb01f8":"# make a list filled with train_Y_avg, essentially predicting the same number for all lines in test set\navg_pred_test = [train_Y_avg for i in range(len(test_dataframe))]\nwrite_test_prediction(test_dataframe, avg_pred_test, '.\/average_constant_baseline_new-tf.csv')","aa6a2656":"# get entire raw text in training corpus, including title and edit words (for learning vocabulary and IDF)\n# params:\n#     df: dataframe, with 'original' and 'edit' columns\n# return:\n#     corpus: a list of text strings, each is a concatenation of original text and edit word on each line\n\ndef get_raw_text(df):\n    corpus = []\n    for index, row in df.iterrows():\n        title = row['original'].replace('<', '').replace('\/>', '')\n        edit = row['edit']\n        corpus.append( title + ' ' + edit )\n    return corpus","56181659":"train_corpus = get_raw_text(train_dataframe)\n# print (train_corpus)\n\n#vectorizer = TfidfVectorizer(stop_words = None).fit(train_corpus)\n\nvectorizer = CountVectorizer(stop_words = None).fit(train_corpus)\n#print(vectorizer.vocabulary_)","67bd2d0e":"# helper function: separate each title into (original_word, context), where context = title text without original word \n# params:\n#     df: dataframe, with 'original' and 'edit' columns\n# return:\n#     original_words: a list of original word strings before editing\n#     contexts:       a list of context strings \n\ndef separate_original_word_from_title(df):\n    original_words = []\n    contexts = []\n    for index, row in df.iterrows():\n        title = row['original']\n        start_position = title.find('<')\n        end_position = title.find('\/>')\n        original_words.append(title[start_position+1 : end_position])\n        contexts.append(title[:start_position] + title[end_position+2 :])\n    return original_words, contexts","aeff85e4":"# construct sparse feature matrix\n# params:\n#     df: dataframe, with 'original' and 'edit' columns\n#     vectorizer: sklearn text vectorizer, either TfidfVectorizer or Countvectorizer \n# return:\n#     M: a sparse feature matrix that represents df's textual information (used by a predictive model)\n\ndef construct_feature_matrix(df, vectorizer):\n    edit_words = df['edit'].tolist()\n    original_words, contexts = separate_original_word_from_title(df)\n    \n    \n    # here the dimensionality of X is len(df) x |V|\n    X_edit = vectorizer.transform(edit_words)\n\n    \n    return X_edit","c0a2cc42":"# Construct feature matrices for training and validation data\ntrain_X = construct_feature_matrix(train_dataframe, vectorizer)\n# print(train_X)\nvalid_X = construct_feature_matrix(valid_dataframe, vectorizer)\ntest_X = construct_feature_matrix(test_dataframe, vectorizer)\n\n# print (train_X)","29291b7d":"mlp = MLPRegressor()\n\n\nmodel = mlp.fit(train_X, train_Y)\n","75f512a5":"# Evaluate model on validation set\nvalid_Y_hat = model.predict(valid_X)\nrmse = np.sqrt(sklearn.metrics.mean_squared_error(valid_Y, valid_Y_hat))\nprint('RMSE on validation set:', rmse)","00ba355f":"# Evaluate model on training set: \n# expect to see unrealistically good performance! (for RMSE: lower is better)\n# unrealistic because YOUR MODEL IS TRAINED ON EXACTLY THESE DATA!\n# It gives the best validation\/test performance you could hope to achieve using this model.\n\ntrain_Y_hat = model.predict(train_X)\nrmse = np.sqrt(sklearn.metrics.mean_squared_error(train_Y, train_Y_hat))\nprint('RMSE on training set:', rmse)","cce02351":"# apply the model on test data, write out prediction results to a csv file\ntest_Y_hat = model.predict(test_X)\nwrite_test_prediction(test_dataframe, test_Y_hat, '.\/ridge-regression_alpha=1_baseline_new-tf.csv')","fefb92d8":"# print(vectorizer.vocabulary_)","2e71468a":"print(model.coef_)","bb61c7d8":"# construct a mapping: word -> learned weight of this word\nfeature_weight = {}\nfor word, idx in vectorizer.vocabulary_.items():\n    feature_weight[word] = model.coef_[idx]\n# print(feature_weight)","5a401cf4":"# words positively correlate with funniness (top ones)\nfor k, v in sorted(feature_weight.items(), key = lambda x: x[1], reverse = True)[:10]:\n     print (k, v)","4bc92b91":"# words negatively correlate with funniness (top ones)\nfor k, v in sorted(feature_weight.items(), key = lambda x: x[1], reverse = False)[:10]:\n     print (k, v)","3c60b228":"# We pick a set of examples from the validation set (we predicted scores for those).\n# We usually we don't pick from training data (since the good performance may be unrealistic).\n# We cannot do error analysis on test data \uff08because no true target value is provided\uff09.","bf9aa11e":"def explain_linear_prediction(df, model, idx2feature, X, Y, Y_hat, idx_list):\n    print('indices:', idx_list)\n    for idx in idx_list:\n        print ('==============', idx, '================')\n        print ('original:', df.iloc[idx]['original'])\n        print ('edit:', df.iloc[idx]['edit'])\n        print ('grades:', df.iloc[idx]['grades'])\n        print ('TRUE score:', df.iloc[idx]['meanGrade'])\n        print ('PRED score:', Y_hat[idx])\n        \n        print ('\\nPRED breakdown:')\n        print ('\\tINTERCEPT', model.intercept_)\n        if X[idx, :].nnz == 0:\n            print ('\\tFEATURE', '[EMPTY]')\n        else:\n            for entry in X[idx, :]: # looping over a row in sparse matrix \n                feature_value = entry.data[0]\n                feature_dim = entry.indices[0]\n                print ('\\tFEATURE', idx2feature[feature_dim], ':', 'f_value', feature_value, '*', 'f_weight', model.coef_[feature_dim], '=', feature_value*model.coef_[feature_dim])\n        ","f974501d":"# construct a dictionary mapping: feature index -> word\nidx2feature = dict([(v,k) for k,v in vectorizer.vocabulary_.items()])\n\nerrors = (valid_Y - valid_Y_hat)**2\n# sort errors from low to high\nsorted_errors = sorted(enumerate(errors.iloc[:].tolist()), key = lambda x: x[1], reverse = False)\n# print(sorted_errors)","f5edb180":"# pick a random set of examples from validation set:\nK = 5\nrandom_indices = np.random.randint(0, valid_X.shape[0], K)\nexplain_linear_prediction(valid_dataframe, model, idx2feature, valid_X, valid_Y, valid_Y_hat, random_indices)","ad767dba":"K = 5\n# look at data with lowest prediction error\nlow_error_indices  = [i for i, v in sorted_errors[:K]]\nexplain_linear_prediction(valid_dataframe, model, idx2feature, valid_X, valid_Y, valid_Y_hat, low_error_indices)","3a323743":"K = 5\n# look at data with highest prediction error\nhigh_error_indices = [i for i, v in sorted_errors[-K:]]\nexplain_linear_prediction(valid_dataframe, model, idx2feature, valid_X, valid_Y, valid_Y_hat, high_error_indices)","5eecc55e":"# Build feature extractor from training data (here we use a CountVectorizer or TfidfVectorizer )","8e9528f6":"## Also load test data (no splitting needed)","3def11a0":"# Try the trivial baseline: always predicting the average meanGrade (of training data)","2be24cc8":"# Load data, split into training and validation sets","87c58e3a":"# Train model on training set, evaluate model on validation set","03923b7f":"### examples with closest prediction","fcbed22d":"### examples with worst predictions","7cc134e2":"# Download files, set up folder, put files into folder","c6ff7481":"## Look at learned parameters (for linear model: weight of each dimension)","f26c8958":"# Investigate what the model has learned and where it failed (A.K.A. error analysis)","80b05660":"## Look at how the model makes predictions on individual examples","e3a5b3e8":"### prediction on random examples","2949648a":"# Extract features of both training and validation data"}}