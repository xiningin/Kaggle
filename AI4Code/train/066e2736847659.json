{"cell_type":{"f987bcef":"code","63985dcb":"code","ea0dbf7f":"code","c48257c8":"code","0e2aecf4":"code","8043743d":"code","99ab1386":"code","c60c75cb":"code","dbe5d8e2":"code","76114dbe":"code","c3da8eb3":"code","4b4467e9":"code","a26f476a":"code","e1f66dd7":"code","967e068c":"code","8245044c":"code","5e30767e":"code","6bd6ef50":"code","5174af79":"code","d5dbd7f0":"code","d39247b9":"code","90f9cb33":"code","5b6b69ab":"code","7543976e":"code","6a8a4cdf":"code","00e8d7c3":"code","f61100a1":"code","0615b102":"code","2da472fb":"code","6bf2adcf":"code","7121f1c2":"code","45dbbb94":"code","449dbd8b":"code","4223c55a":"markdown","5af2195d":"markdown","9cef5a9c":"markdown","794e44ad":"markdown","dfbae891":"markdown","9268cdb5":"markdown","bed0e921":"markdown","6c975c63":"markdown","f38cbfe0":"markdown","983f78b7":"markdown","5347f73a":"markdown","183b170b":"markdown","2d0250f9":"markdown","556c01c3":"markdown","bf8d7cf1":"markdown","be7762b3":"markdown","e7a023b8":"markdown","4808a970":"markdown","217089fa":"markdown","82f56032":"markdown","297fdfa8":"markdown","7ad3a9f0":"markdown","08a7ddd2":"markdown","1cf03f05":"markdown","6be23594":"markdown","6e20dfd3":"markdown","2c48dbb7":"markdown","b60a03d2":"markdown","87cabd0d":"markdown","676c1d95":"markdown","cb522704":"markdown","8ff1c43e":"markdown","82e298f9":"markdown","f179d64a":"markdown","78383c7f":"markdown","ec7627e4":"markdown","b0c78da7":"markdown","53d4d592":"markdown","d9c9d83d":"markdown","ee318103":"markdown","23b1356d":"markdown"},"source":{"f987bcef":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","63985dcb":"data = pd.read_csv('\/kaggle\/input\/daily-temperature-of-major-cities\/city_temperature.csv', low_memory = False)","ea0dbf7f":"data.head(5)","c48257c8":"print('No. of Regions: %i' %data['Region'].nunique())\nprint('No. of Countries: %i' %data['Country'].nunique())\nprint('No. of States: %i' %data['State'].nunique())\nprint('No. of Cities: %i' %data['City'].nunique())","0e2aecf4":"print(data[\"Region\"].unique())\nprint(data[\"Country\"].unique())\nprint(data[\"Month\"].unique())\nprint(data[\"Day\"].unique())\nprint(data[\"Year\"].unique())","8043743d":"data.info()","99ab1386":"data.describe()","c60c75cb":"data.isna().sum()","dbe5d8e2":"# Removing '201' and '200' from Year column\ndf = data[~data['Year'].isin(['201','200'])]\n\n# Removing '0' from Date column\ndf = df[df['Day'] != 0]\n\n# Removing 'State' column\ndf = df.drop(columns=['State'])\n\n# Dropping the rowns with temperature -99\ndf = df.drop(df[df['AvgTemperature'] == -99.0].index)","76114dbe":"# Adding a row with average temperatures in Celcius\ndf['AvgTempCelcius'] = round((((df.iloc[:,6] - 32) * 5) \/ 9),2)\n\n# Adding the Date column in the format YYYY-MM-DD\ndf['Date'] = df.iloc[:,5].astype(str) + '-' + df.iloc[:,3].astype(str) + '-' + df.iloc[:,4].astype(str)\n\n# Coverting the Date column into Pandas Date type datetime64[ns]\ndf['Date'] = pd.to_datetime(df['Date'])\n\n# Introducing the Period column in format YYYY-MM\ndf['Month\/Year'] = pd.to_datetime(df['Date']).dt.to_period('M')","c3da8eb3":"df.info()","4b4467e9":"df.head()","a26f476a":"print(df.groupby(['Region'])['AvgTemperature'].mean())\navg_temp_world = pd.Series(round(df.groupby('Region')['AvgTemperature'].mean().sort_values(),2))\navg_temp_world.plot(kind='bar', figsize = (10,6), color='yellow', alpha=0.5)\nplt.xlabel('Mean Average Temperature')\nplt.ylabel('Regions')\nplt.title('Mean Average Temperatures by Region')","e1f66dd7":"world_temp_date = pd.DataFrame(pd.Series(round(df.groupby('Date')['AvgTempCelcius'].mean(),2))[:-1])\nworld_temp_year = pd.DataFrame(pd.Series(round(df.groupby('Year')['AvgTempCelcius'].mean(),2))[:-1])\n\nplt.subplot(2,1,1)\nsns.set_style(\"darkgrid\")\nsns.lineplot(data = world_temp_date, color = 'blue')\nplt.xlabel('Time')\nplt.ylabel('Temperature (in Celcius)')\nplt.title('Mean Avg. Temperature Over Time (Date) in the world')\nplt.show()\n\nplt.subplot(2,1,2)\nsns.set_style(\"darkgrid\")\nsns.lineplot(data = world_temp_year, color = 'blue')\nplt.xlabel('Time')\nplt.ylabel('Temperature (in Celcius)')\nplt.title('Mean Avg. Temperature Over Time (Years) in the world')\nplt.show()","967e068c":"## Creating a function to plot the temperature over the Periods in different countries\ndef plot_temp_country_month(country, format = '-', temp = 'Celcius'):\n    dat = df[df['Country'] == country]\n    if temp == 'Celcius':\n        dat_temp = pd.Series(round(dat.groupby('Date')['AvgTempCelcius'].mean().sort_values(),2))\n    else:\n        dat_temp = pd.Series(round(dat.groupby('Date')['AvgTemperature'].mean().sort_values(),2))\n    sns.set_style(\"darkgrid\")\n    sns.lineplot(data = dat_temp, color = 'red')\n    plt.xlabel('Time (Periods)')\n    plt.ylabel('Temperature (in %s)' %temp)\n    plt.title('Mean Avg. Temperature Over Time in %s' %country)\n    plt.show()\n\n    \n## Creating a function to plot the temperature over the Years in different countries\ndef plot_temp_country_year(country, format = '-', temp = 'Celcius'):\n    dat = df[df['Country'] == country]\n    if temp == 'Celcius':\n        dat_temp = pd.DataFrame(pd.Series(round(df[df['Country'] == country].groupby('Year')['AvgTempCelcius'].mean(),2))[:-1])\n    else:\n        dat_temp = pd.DataFrame(pd.Series(round(df[df['Country'] == country].groupby('Year')['AvgTemperature'].mean(),2))[:-1])\n    sns.set_style(\"darkgrid\")\n    sns.lineplot(data = dat_temp, color = 'red' , style = 'event', hue = 'cue')\n    plt.xlabel('Time (Years)')\n    plt.ylabel('Temperature (in %s)' %temp)\n    plt.title('Mean Avg. Temperature Over Time in %s' %country)\n    plt.show()","8245044c":"plot_temp_country_year('India')\nplot_temp_country_month('India')","5e30767e":"## Function to calculate the temperature fluctuation\ndef calculate_fluctuation(series):\n    fluctuation = np.zeros((len(series),))\n    for i in range(1,len(series)):\n        fluctuation[i] = series[i] - series[0]\n    return fluctuation\n\n## Function to plot the temperature fluctuation Lineplot\ndef plot_change(years, fluctuation, entity):\n    change_df = pd.DataFrame(np.column_stack((years, fluctuation)), columns = ['Year', 'Change'])\n    change_df['Year'] = change_df['Year'].astype(int)\n    sns.lineplot(x = \"Year\", y = \"Change\", data = change_df, err_style=\"bars\", ci=68, label = entity)\n    x = np.zeros((len(change_df['Year']),1))\n    plt.plot(change_df['Year'], x, '--')\n    plt.title('Temperature fluctuations over the years')\n    plt.ylabel('Change in Temperature')\n\n## Function to plot the temperature fluctuation in the world \ndef world_change_temp():\n    dat = np.array(pd.Series(round(df.groupby('Year')['AvgTempCelcius'].mean(),2)))[:-1]\n    years = np.arange(1995,2020)\n    fluctuation = calculate_fluctuation(dat)\n    plot_change(years, fluctuation, 'World')\n\n## Function to plot the temperature fluctuation in every country\ndef country_change_temp(country):\n    dat = np.array(pd.Series(round(df[df['Country'] == country].groupby('Year')['AvgTempCelcius'].mean(),2)))[:-1]\n    years = np.arange(1995,2020)\n    fluctuation = calculate_fluctuation(dat)\n    plot_change(years, fluctuation, country)\n\n## Function to plot the temperature fluctuation in every continent\ndef region_change_temp(region):\n    dat = np.array(pd.Series(round(df[df['Region'] == region].groupby('Year')['AvgTempCelcius'].mean(),2)))[:-1]\n    years = np.arange(1995,2020)\n    fluctuation = calculate_fluctuation(dat)\n    plot_change(years, fluctuation, region)\n\n## Function to plot the average temperature and temperature fluctutaion distribution for every country\ndef temperature_histogram(country):\n    hist1_s = np.array(pd.Series(round(df.groupby('Year')['AvgTempCelcius'].mean(),2)))[:-1]\n    hist2_s = np.array(pd.Series(round(df[df['Country'] == country].groupby('Year')['AvgTempCelcius'].mean(),2)))[:-1]\n    hist1_fluctuation = calculate_fluctuation(hist1_s)\n    hist2_fluctuation = calculate_fluctuation(hist2_s)\n    print('Skewness for Temperature in %s: ' %country, df[df['Country'] == country]['AvgTempCelcius'].skew())\n    print('Kurtosis for Temperature in %s: ' %country, df[df['Country'] == country]['AvgTempCelcius'].kurt())\n    plt.figure(figsize = (10,5))\n    plt.subplot(1,2,1)\n    sns.distplot(df[df['Country'] == country]['AvgTempCelcius'], label = country)\n    sns.distplot(df['AvgTempCelcius'], label = 'World')\n    plt.legend()\n    plt.subplot(1,2,2)\n    sns.distplot(hist1_fluctuation , label = 'World')\n    sns.distplot(hist2_fluctuation, label = country)\n    plt.xlabel('Temperature Fluctuations')\n    plt.legend()","6bd6ef50":"world_change_temp()","5174af79":"country_change_temp('US')","d5dbd7f0":"country_change_temp('Canada')","d39247b9":"country_change_temp('China')","90f9cb33":"region_change_temp('Africa')","5b6b69ab":"temperature_histogram('US')","7543976e":"# Create the series\nseries = np.array(list(pd.Series(round(df.groupby('Date')['AvgTempCelcius'].mean(),2))))\n\n# Creating time intervals\ntime = np.array(np.arange(0,len(series)))","6a8a4cdf":"# We have 7000 training examples and rest as training examples\nsplit_time = 7000\n\n# Defining the Training set and test set\ntime_train = time[:split_time]\nx_train = series[:split_time]\ntime_valid = time[split_time:]\nx_valid = series[split_time:]\n\n# Initialising the Hyperparamenters\nwindow_size = 60\nbatch_size = 100\nshuffle_buffer_size = 1000","00e8d7c3":"## Function to create a line plot\ndef plot_series(time, series, format=\"-\", start=0, end=None):\n    plt.plot(time[start:end], series[start:end], format)\n    plt.xlabel(\"Time\")\n    plt.ylabel(\"Value\")\n    plt.grid(False)\n\n## Function to prepare data to be fed into the Tensorflow model\ndef windowed_dataset(series, window_size, batch_size, shuffle_buffer):\n    series = tf.expand_dims(series, axis=-1)\n    dp = tf.data.Dataset.from_tensor_slices(series)\n    dp = dp.window(window_size + 1, shift=1, drop_remainder=True)\n    dp = dp.flat_map(lambda w: w.batch(window_size + 1))\n    dp = dp.shuffle(shuffle_buffer)\n    dp = dp.map(lambda w: (w[:-1], w[1:]))\n    return dp.batch(batch_size).prefetch(1)\n\n## Function to prepare validation data into the model for prediction\ndef model_forecast(model, series, window_size):\n    dp = tf.data.Dataset.from_tensor_slices(series)\n    dp = dp.window(window_size, shift=1, drop_remainder=True)\n    dp = dp.flat_map(lambda w: w.batch(window_size))\n    dp = dp.batch(32).prefetch(1)\n    forecast = model.predict(dp)\n    return forecast","f61100a1":"# Plotting the time series\nplot_series(time, series)","0615b102":"## The model contains 1 ConV1D filter, 2 LSTMs, 3 Dense layers and 1 Lambda layer\n\ntf.keras.backend.clear_session()\ntf.random.set_seed(51)\nnp.random.seed(51)\n\n## Defining window sizes for hyperparameter tuning \nwindow_size = 64\nbatch_size = 256\ntrain_set = windowed_dataset(x_train, window_size, batch_size, shuffle_buffer_size)\nprint(train_set)\nprint(x_train.shape)\n\n# Defining the model\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv1D(filters=32, kernel_size=5,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]),\n  tf.keras.layers.LSTM(64, return_sequences=True),\n  tf.keras.layers.LSTM(64, return_sequences=True),\n  tf.keras.layers.Dense(30, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 400)\n])\n\n# Create a callback function to get optimal learning rate\nlr_schedule = tf.keras.callbacks.LearningRateScheduler(\n    lambda epoch: 1e-8 * 10**(epoch \/ 20))\n\n# Defining the optimizer\noptimizer = tf.keras.optimizers.SGD(lr=1e-8, momentum=0.9)\n\n# Compiling the model with Huber loss function \nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\n\n# Running the model\nhistory = model.fit(train_set, epochs=100, callbacks=[lr_schedule])","2da472fb":"plt.semilogx(history.history[\"lr\"], history.history[\"loss\"])\nplt.axis([1e-8, 1e-3, 0, 60])","6bf2adcf":"tf.keras.backend.clear_session()\ntf.random.set_seed(51)\nnp.random.seed(51)\ntrain_set = windowed_dataset(x_train, window_size=60, batch_size=100, shuffle_buffer=shuffle_buffer_size)\n\n# Defining the model with 1 ConV1D filter, 2 LSTMs, 3 Dense layers and 1 Lambda layer\nmodel = tf.keras.models.Sequential([\n  tf.keras.layers.Conv1D(filters=60, kernel_size=5,\n                      strides=1, padding=\"causal\",\n                      activation=\"relu\",\n                      input_shape=[None, 1]),\n  tf.keras.layers.LSTM(60, return_sequences=True),\n  tf.keras.layers.LSTM(60, return_sequences=True),\n  tf.keras.layers.Dense(30, activation=\"relu\"),\n  tf.keras.layers.Dense(10, activation=\"relu\"),\n  tf.keras.layers.Dense(1),\n  tf.keras.layers.Lambda(lambda x: x * 400)\n])\n\n# Defining the optimizer with learning rate 1e-6 and momentum 0.9\noptimizer = tf.keras.optimizers.SGD(lr=1e-6, momentum=0.9)\n\n# Compiling model with Huber loss function\nmodel.compile(loss=tf.keras.losses.Huber(),\n              optimizer=optimizer,\n              metrics=[\"mae\"])\n\n# Training with 50 epochs\nhistory = model.fit(train_set,epochs=50)","7121f1c2":"rnn_forecast = model_forecast(model, series[..., np.newaxis], window_size)\nrnn_forecast = rnn_forecast[split_time - window_size:-1, -1, 0]","45dbbb94":"plt.figure(figsize=(10, 6))\nplot_series(time_valid, x_valid)\nplot_series(time_valid, rnn_forecast)","449dbd8b":"tf.keras.metrics.mean_absolute_error(x_valid, rnn_forecast).numpy()","4223c55a":"## Plotting learning rate vs loss","5af2195d":"## Adding data\/columns","9cef5a9c":"The Average world temperature has continually increased after 1995. There have been ups and downs. One can also find that the temperature has dropped during the 2008 economic crisis. ","794e44ad":"In order to create a forecasting model, the data has been considered as a time-series data and Neural networks are used to recognise and predict time series","dfbae891":"## Temperature fluctuation in a country","9268cdb5":"## Building the model and training","bed0e921":"In the section the temperature fluctuations from 1996 to 2019 relative to the year 1995 are calculated and visualised. Below are the functions defined:\n\nNote: The analysis has been carried out in Celcius scale ","6c975c63":"## Temperature fluctuation in a continent","f38cbfe0":"## Counting N\/As in data","983f78b7":"### Displaying basic information about data","5347f73a":"From the below graphs, we can find that there is a gradual increase in the temprerature from 1995 in the United States and China, but temperature has dropped in Canada. Also, we can find that the temperature dropped during the 2008 economic crisis. ","183b170b":"# Visualization and Exploratory Data Analysis","2d0250f9":"The following columns are added\n\n* Average Temperature in Celcius is added.\n* Combining year, month and day to make the Date column in the format YYYY-MM-DD\n* Introduce column Period in the format YYYY-MM","556c01c3":"Data is imported as .csv from Kaggle and imported with pandas library","bf8d7cf1":"# Time - Series Forecasting Model with DNN, LSTM and CNN","be7762b3":"## Removing data","e7a023b8":"### Average Temperatures for various countries over time from 1995 to 2019","4808a970":"### Number of unique members belonging to different dimensions","217089fa":"## Temperature and fluctuation distribution in a country","82f56032":"## Plotting the validation data and the forecast","297fdfa8":"# Importing Packages","7ad3a9f0":"The following procedures are performed to clean the data\n\n* The rows with values '201' and '200' are removed from the Years column.\n* The rows with day as '0' is removed.\n* The States column with data only for the US is removed.\n* The rows with temperature -99 degress Fahrenheit is removed ","08a7ddd2":"## Creating a forecast for the validation data","1cf03f05":"## Mean Average temperature of different continents in Fahrenheit","6be23594":"## Exploring data","6e20dfd3":"### Members of various dimensions","2c48dbb7":"## Temperature fluctuation in the world","b60a03d2":"Here we find that the minimum Average temperaure temperature is -99 degrees which is unusual","87cabd0d":"## Importing data","676c1d95":"## Checking the mean absolute error of the validation set","cb522704":"### Descriptive statistics of measures","8ff1c43e":"Counting the number of N\/As, we find that the states is only defined for the U.S.A. Hence we need to drop the column.","82e298f9":"### Mean Average temperature in the world from 1995 to 2019","f179d64a":"We can find that the MAE for the validation set is pretty low and hence the model is a good forcasting model","78383c7f":"# Importing data and cleaning","ec7627e4":"# Cleaning Data","b0c78da7":"## Defining and running the model with callbacks to tune Learning rate for SGD optimizer","53d4d592":"## Defining functions to feed into the training Model","d9c9d83d":"## Temperature Fluctuation over time from 1995 to 2019","ee318103":"## Plotting Time series","23b1356d":"Plotting a line plot of Learning rate vs loss to find the learning rate with minimal loss. Here we can see that at e-6 the loss is very low. Hence the learning rate is chosen to be 1e-6"}}