{"cell_type":{"2ed75b05":"code","d6503ae1":"code","21197ebe":"code","3dd103aa":"code","fdd6a85c":"code","0856e85d":"code","42bfed35":"code","15354938":"code","97407c36":"code","0c0b9b3f":"code","e6984a64":"code","e6a1ccaa":"code","d9041f72":"code","bf96213e":"code","030a48e0":"code","ffcf238c":"code","4c7caadb":"code","525ed01a":"code","c1ad3f3e":"code","7fe62869":"code","e1243224":"code","77ed877d":"code","730151bb":"code","dda3f401":"code","62d74d5e":"code","98738e7d":"markdown","145d279e":"markdown","8dcfc17e":"markdown","87c6870a":"markdown","3aa25679":"markdown","7d8ba769":"markdown","741fff0f":"markdown"},"source":{"2ed75b05":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os,sys,shutil\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames[:30]:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d6503ae1":"# Load the libraries\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport seaborn as sns\nimport cv2\nfrom sklearn.model_selection import train_test_split\n# pd.set_option('display.max_colwidth',0)","21197ebe":"# Load the data and url\n\ntrain_url = r'\/kaggle\/input\/age-prediction-dataset-indian-actors\/train\/' \ntest_url = r'\/kaggle\/input\/age-prediction-dataset-indian-actors\/test\/'\n\ntrain_dir = train_url + 'Train\/'\ntest_dir = test_url + 'Test\/'\n\ntrain_data  = pd.read_csv(train_url + 'train.csv') \ntest_data = pd.read_csv(test_url + 'test.csv')","3dd103aa":"# Train data\nprint('Shape of the train data - ',train_data.shape)\ntrain_data.head()","fdd6a85c":"# Manipulating the dataframe\ntrain_data1=train_data.copy()\ntrain_data1['loc'] = train_dir + train_data['ID']\ntrain_data1.head()","0856e85d":"# Show the image present in the data\ndef read_img(data):\n    classes = ['YOUNG',\"MIDDLE\",'OLD']\n    for c in classes:\n            img = plt.imread(data[data['Class']==c].head(1)['loc'].values[0])\n            print('Shape of the image -',img.shape)\n            plt.title(c)\n            plt.imshow(img)\n            plt.show()\nread_img(train_data1)","42bfed35":"# Train Data\ntrain_data1.drop(columns= ['ID'],inplace=True)\ntrain_data1 = train_data1[['loc','Class']].copy()\ntrain_data1.head()","15354938":"# Visulaizing the number of images in the particular class\ntrain_data1.groupby('Class').count().plot(kind='bar',figsize=(20,10))","97407c36":"train_data1['Class'].replace(['YOUNG','MIDDLE','OLD'],[0,1,2],inplace=True)","0c0b9b3f":"new_images = []\nnew_classes = []\nfor img_loc,classes in zip(train_data1['loc'],train_data1['Class']):\n    img = cv2.imread(img_loc,flags=0)\n    img_resize = cv2.resize(img,(32,32))\n    new_images.append(img_resize.astype('float32'))\n    new_classes.append(classes)\n\nplt.imshow(new_images[0])\nplt.title(new_classes[0])","e6984a64":"# Code to Image Data Generator\ngenerator = tf.keras.preprocessing.image.ImageDataGenerator(rotation_range=15,\n                                                            horizontal_flip=True,\n                                                            data_format='channels_last')\n\n# generator.flow_from_dataframe() ____________________Please check this one! Exclusive!","e6a1ccaa":"# Train sets\ntrain_x = np.stack(new_images)\ntrain_y = np.stack(new_classes)","d9041f72":"# Splitting the data set\nX_train,X_val,y_train,y_val = train_test_split(train_x,train_y,test_size=0.2,random_state=42)\n\nX_train.shape,y_train.shape,X_val.shape,y_val.shape","bf96213e":"# Manipulating the target values\ny_train = tf.keras.utils.to_categorical(y_train,num_classes=3)\ny_val = tf.keras.utils.to_categorical(y_val,num_classes=3)","030a48e0":"# Assemble the model components --->>> Keras Framework\nfrom keras import Sequential\nfrom keras.callbacks import EarlyStopping,ModelCheckpoint\nfrom keras import Input,regularizers,optimizers,losses,metrics,layers\nfrom keras import Model,optimizers\nfrom keras.utils import plot_model\nfrom keras.losses import CategoricalCrossentropy","ffcf238c":"train_x.shape","4c7caadb":"# Augmentation on the data\ndata_augmentation = Sequential([\n    layers.experimental.preprocessing.RandomFlip('horizontal'),\n    layers.experimental.preprocessing.RandomRotation(0.1)\n])","525ed01a":"# Function for model \ndef model():\n    inputs = Input(shape=(32,32,1))\n    # Data Augmentation\n    x = data_augmentation(inputs)\n    \n    # Entry block\n    x = layers.experimental.preprocessing.Rescaling(1.\/255)(x)\n    x = layers.Conv2D(32,(3,3),(2,2),padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    x = layers.Conv2D(64,(3,3),(2,2),padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    \n    residual1 = x\n    \n    for FilterSize in [128,256,512]:\n        x = layers.Activation('relu')(x)\n        x = layers.SeparableConv2D(FilterSize,(3,3),(2,2),padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation(tf.nn.relu)(x)\n        \n        x = layers.SeparableConv2D(FilterSize,(3,3),(2,2),padding='same')(x)\n        x = layers.BatchNormalization()(x)\n        x = layers.Activation(tf.nn.relu)(x)\n        \n        x = layers.MaxPool2D((3,3),(2,2),padding='same')(x)\n        \n        residual = layers.Conv2D(FilterSize,(1,1),(2,2),padding='same')(residual1)\n        \n        x = layers.add([x,residual])\n        \n        FinalResidual = x\n    \n    x = layers.SeparableConv2D(1024,(3,3),(2,2),padding='same')(x)\n    x = layers.BatchNormalization()(x)\n    x = layers.Activation('relu')(x)\n    \n    x = layers.Flatten()(x)\n    \n    x = layers.Dropout(0.5)(x)\n    \n    output = layers.Dense(3,activation=tf.nn.softmax)(x)\n    \n    return Model(inputs = inputs,outputs=output)\n\n# Intialize the model\nmodel = model()\n\n# Plot the model architecture\nplot_model(model,show_shapes =True)","c1ad3f3e":"epochs = 200\n\ncallbacks = [  \n    ModelCheckpoint(filepath = 'save_at_{epoch}.h5',save_best_only=True),\n    EarlyStopping(monitor='val_loss',patience=20)\n]\n\nmodel.compile(optimizer=optimizers.SGD(0.01,momentum=0.9),\n              loss='categorical_crossentropy',\n              metrics=['accuracy'])\n# CategoricalCrossentropy()\n\nhistory = model.fit(X_train,y_train,\n          batch_size=32,\n          validation_batch_size=8,\n          validation_data=(X_val,y_val),\n          callbacks=callbacks,epochs=epochs)","7fe62869":"# History plots\nplt.figure(figsize=(10,7))\nplt.plot(history.history['loss'],'b')\nplt.plot(history.history['val_loss'],'r')\nplt.legend(labels = ['loss','val_loss'])\nplt.title('LOSS',fontsize=20)\nplt.show()","e1243224":"plt.figure(figsize=(10,7))\nplt.plot(history.history['accuracy'],'b')\nplt.plot(history.history['val_accuracy'],'r')\nplt.legend(labels = ['loss','val_loss'])\nplt.title('LOSS',fontsize=20)\nplt.show()","77ed877d":"# Test data\ntest_data['loc'] = test_dir+test_data[\"ID\"]\ntest_data1 = test_data['loc'].copy()","730151bb":"test_data2 = []\nfor image in test_data1:\n    img = cv2.imread(image,flags=0)\n    img = cv2.resize(img,(32,32))\n    test_data2.append(img.astype('float32'))\n\ntest_data2 = np.stack(test_data2)    ","dda3f401":"#### Train set\n# loc = int(input('Enter the number-'))\nloc = 0\n# test_img = test_data2[loc]\ntest_img = train_x[loc]\nplt.imshow(test_img)\n\nimg_array = tf.keras.preprocessing.image.img_to_array(test_img)\nimg_array = tf.expand_dims(img_array,0)\nimg_array.shape\npredicted = model.predict(img_array)\n\n\n\ndef caption(pred):\n    cap = np.argmax(pred)\n    if cap==0:\n        return 'Young'\n    elif cap==1:\n        return 'Middle'\n    elif cap == 2:\n        return 'Old'# Young=0, Middle=1,Old=2\n    \ncap = caption(predicted[0])\nprint(predicted[0])\nplt.title(cap)\nplt.show()","62d74d5e":"# Test set\n# loc = int(input('Enter the number-'))\nloc = 0\ntest_img = test_data2[loc]\nplt.imshow(test_img)\n\nimg_array = tf.keras.preprocessing.image.img_to_array(test_img)\nimg_array = tf.expand_dims(img_array,0)\nimg_array.shape\npredicted = model.predict(img_array)\n\n\n# Getting the predicted captions of the Image\ndef caption(pred):\n    cap = np.argmax(pred)\n    if cap==0:\n        return 'Young'\n    elif cap==1:\n        return 'Middle'\n    elif cap == 2:\n        return 'Old'# Young=0, Middle=1,Old=2\n    \ncap = caption(predicted[0])\nprint(predicted[0])\nplt.title(cap)\nplt.show()","98738e7d":"# Modeling Part","145d279e":"## Predictions on train dataset","8dcfc17e":"# Model","87c6870a":"## Predictions on test Data set","3aa25679":"# Data Augmentation","7d8ba769":"## Training the model","741fff0f":"# Test Data"}}