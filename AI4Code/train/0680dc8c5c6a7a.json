{"cell_type":{"e002b6d9":"code","f9154aae":"code","152113d6":"code","f838efb0":"code","00aea73c":"code","62eea4ea":"code","0f5ca582":"code","52a8cba9":"code","b70194c3":"code","8f741b47":"code","10493237":"code","7942eb9f":"code","9772aa64":"code","f84aa597":"code","d4dfde7a":"markdown","38cda502":"markdown"},"source":{"e002b6d9":"import pandas as pd\nimport numpy as np\nimport hashlib\n\nfrom catboost import CatBoostRegressor, Pool\nfrom sklearn.metrics import mean_absolute_error, make_scorer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\n\npd.set_option('display.max_columns', None)","f9154aae":"# Taking a look at input data\ndata = pd.read_csv('..\/input\/car-price-prediction\/CarPrice_Assignment.csv').drop(columns=['car_ID',\n                                                                                          'symboling']) # Dropping the unique ID and feature with unknown purpose\nlen_data = len(data)\ndata","152113d6":"# Finding the range between maximum and minimum car price to compare it with model error\nprice_range = data.price.max() - data.price.min()\nprint(f\"The car price range is {price_range}\")","f838efb0":"# Let's design a couple of new feature\n# First, we check whether the car is of premium brand or not\nCarMake = pd.Series([name.split(\" \")[0] for name in data.CarName])\nCarMake.unique()","00aea73c":"# There are some misspellings in the advertisements, that's why Porsche is included twice\npremium_makes = ['alfa-romero', 'audi', 'bmw', 'jaguar', 'porsche', 'porcshce']\ndata['IsPremium'] = [1 if name.split(\" \")[0] in premium_makes else 0 for name in data.CarName]","62eea4ea":"# No. of cylinders is written as text, let's replace it to corresponding integers\ndata.cylindernumber.unique()","0f5ca582":"data.cylindernumber = data.cylindernumber.replace({'four': 4, 'six': 6, 'five': 5, 'three': 3, 'twelve': 12,\n                                                  'two': 2, 'eight': 8}).astype(int)\ndata.cylindernumber","52a8cba9":"# First feature tells us whether the car has a powerful engine or not, second is a measure if volume of one engine cylinder\ndata['HipowerEngine'] = [1 if power >= data.horsepower.min() + (data.horsepower.max() - data.horsepower.min()) \/ 2 else 0 for power in data.horsepower]\ndata['CylinderVolume'] = data.enginesize \/ data.cylindernumber","b70194c3":"data","8f741b47":"# Replacing remaining object features with one-hot dummies if the certain feature has few unique values\n# or with hash if there are many uniques\ncols_to_drop = []\n\nfor col in data.drop(columns=['price']).columns:\n  if data[col].dtype == 'object':\n    print(f'Column {col} has {data[col].nunique()} values among {len_data}')\n\n    if data[col].nunique() < 25:\n      print(f'One-hot encoding of {col}')\n      one_hot_cols = pd.get_dummies(data[col])\n      for ohc in one_hot_cols.columns:\n        data[col + '_' + ohc] = one_hot_cols[ohc]\n    else:\n      print(f'Hashing of {col}')\n      data[col + '_hash'] = data[col].apply(lambda row: int(hashlib.sha1((col + \"_\" + str(row)).encode('utf-8')).hexdigest(), 16) % len_data)\n\n    cols_to_drop.append(col)\n    \ndata = data.drop(columns=cols_to_drop)","10493237":"# Removing the features with high correlation to reduce the model dimensionality and avoid\n# information redundancy\ncorr = data.drop(columns=[\"price\"]).corr()\ncorr_top = corr.abs().unstack().sort_values(kind='quicksort')\ncorr_top = corr_top[corr_top > 0.9][corr_top < 1]\n\ncols_to_drop = [corr_top.index[i][0] for i in range(0, len(corr_top), 2)]\nprint(f\"Highly correlated features: {cols_to_drop}\")\ndata = data.drop(columns=cols_to_drop)\n\ndata","7942eb9f":"# Rescaling the feaures\nss = StandardScaler()\ndata_scaled = pd.DataFrame(columns=data.drop(columns=['price']).columns,\n                               data=ss.fit_transform(data.drop(columns=['price']), data.price))\ndata_scaled['price'] = data.price\n\nX = data_scaled.drop(columns=['price'])\nY = data_scaled.price","9772aa64":"# Training and evaluating of CB regression\nX_train, X_test, Y_train, Y_test = train_test_split(data_scaled.drop(columns=['price']), data_scaled.price, random_state=42,train_size=0.7)\n\ncbr = CatBoostRegressor(random_state=42, verbose=0)\n\ncbr.fit(X_train, Y_train)\ncb_mae = round(mean_absolute_error(Y_test, cbr.predict(X_test)), 2)\nprint(f\"CatBoost MAE on CV is {round(cb_mae, 2)}$, which is {round(cb_mae \/ price_range * 100, 2)}% of price range\")","f84aa597":"# Printing top-10 useful features as a Pandas frame\npd.DataFrame({'feature_importance': cbr.get_feature_importance(Pool(X_train, Y_train)), \n              'feature_names': X.columns}).sort_values(by=['feature_importance'], \n                                                           ascending=False).iloc[:10]","d4dfde7a":"**Greetings!**\n\nToday we'll train a regressor based on CatBoost to estimate the price of used cars and find out what factors impact most on car prices.\n\nMean absolute error will be used as quality metric as it can be easily interpreted.","38cda502":"The CatBoost MAE is around 1.3k\\$, which is relatively small comparing with the price range. Suprisingly, the top feature impacting the car price is the size of the engine (which can be possibly explained with American traditional habit to big engines :D). Our synthetic features also give some impact to the regressor's decisions.\n\n**Thanks for your attention! I'll be glad to have a productive discussion :)**"}}