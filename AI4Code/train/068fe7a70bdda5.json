{"cell_type":{"a4b764f3":"code","c90bf456":"code","495aa90d":"code","2ae21fb8":"code","32cb653f":"code","20a02ffa":"code","c0c706f0":"code","e43ec5b4":"code","3f9ccfa5":"code","51a71744":"code","a6def90d":"code","5c4adc32":"code","4e51b2a8":"code","5641bc19":"code","3470cbf1":"code","1f9b51a5":"code","d08973cf":"code","d548164b":"code","8a471d2b":"code","87d5f05d":"code","eab7dada":"code","92075ac2":"code","f5fbf476":"code","61b9f5a1":"code","22f91a41":"code","391d712a":"code","db819bbb":"code","303e997b":"code","f12f2ef8":"code","9e943484":"code","0d1a51ae":"code","92a16184":"code","3ce8beba":"code","7d5f9b0a":"markdown","41d0a7d5":"markdown"},"source":{"a4b764f3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c90bf456":"import seaborn as sns\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.style.use('ggplot')\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split","495aa90d":"df_trainfile = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_testfile = pd.read_csv('..\/input\/titanic\/test.csv')\ncombine = [df_trainfile, df_testfile]\n","2ae21fb8":"print('Number of Training Examples = {}'.format(df_trainfile.shape[0]))\nprint('Number of Test Examples = {}\\n'.format(df_testfile.shape[0]))","32cb653f":"display(df_trainfile.head())\ndisplay(df_testfile.head())","20a02ffa":"display(df_trainfile.info())\ndisplay(df_testfile.info())","c0c706f0":"display(df_trainfile.describe())\ndisplay(df_testfile.describe())","e43ec5b4":"sns.pairplot(df_trainfile, hue = 'Survived')","3f9ccfa5":"#checking if there is null values in the train dataframe and if there is duplicates\nnulls = df_trainfile.isnull().sum().sort_values(ascending=False)\nprint(nulls,'\\n')\nprint('number of duplicates values in train data = ' ,df_trainfile.duplicated().sum())","51a71744":"#checking if there is null values in the test dataframe and if there is duplicates\nnulls = df_testfile.isnull().sum().sort_values(ascending=False)\nprint(nulls,'\\n')\nprint('number of duplicates values in test data = ' ,df_testfile.duplicated().sum())","a6def90d":"mis_val_percent = 100 * df_trainfile.isnull().sum() \/ len(df_trainfile)\nmis_val_percent","5c4adc32":"#more than half of the Cabin column are null so i'll drop it \ndf_trainfile = df_trainfile.drop(['Cabin'],axis=1)\ndf_testfile = df_testfile.drop(['Cabin'],axis=1)","4e51b2a8":"df_trainfile.dtypes","5641bc19":"# df_trainfile['Ticket'].unique()\n# sns.countplot(data = df_trainfile, x='Ticket', hue='Survived')\n# plt.title('survived or not')\n# plt.show()'\n\ndf_trainfile['Ticket_Frequency'] = df_trainfile.groupby('Ticket')['Ticket'].transform('count')\ndf_testfile['Ticket_Frequency'] = df_testfile.groupby('Ticket')['Ticket'].transform('count')\nsns.countplot(data = df_trainfile, x='Ticket_Frequency', hue='Survived')\nplt.title('Count of Survival in Ticket_Frequency Feature')\nplt.show()\n\n","3470cbf1":"#dropping ticket column 'more than half of the data in this column is unique'\ndf_trainfile.drop(labels='Ticket', axis = 1, inplace= True)\ndf_testfile.drop(labels='Ticket', axis = 1, inplace= True)","1f9b51a5":"#Features like \"Ticket , cabin , Name\" ---> can be used to generate new feature\ncombine = [df_trainfile, df_testfile]\nfor dataset in combine:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\npd.crosstab(df_trainfile['Title'], df_trainfile['Sex'])\n\nmapping_title = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5}\nfor dataset in combine:\n    dataset['Title'] = dataset['Title'].map(mapping_title)\n    dataset['Title'] = dataset['Title'].fillna(0)\n","d08973cf":"display(df_trainfile.head())\ndisplay(df_testfile.head())","d548164b":"#checking the correlation between feature and target['Survived']\nfig, ax = plt.subplots(figsize=(14,5))\ncorr_matrix = df_trainfile.corr().abs()\nsns.heatmap(corr_matrix, annot=True, linewidths=.5)","8a471d2b":"#analyzing feature\ndisplay(df_trainfile[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).count().sort_values(by='Survived', ascending=False))\ndf_trainfile[['Pclass', 'Survived']].groupby(['Pclass'], as_index=False).mean().sort_values(by='Survived', ascending=False)","87d5f05d":"sns.countplot(data = df_trainfile, x='Pclass', hue='Survived')\nplt.title('Number of people survived according to their class')\nplt.show()\n","eab7dada":"display(df_trainfile[['Sex', 'Survived']].groupby(['Sex'], as_index=False).count().sort_values(by='Survived', ascending=False))\ndf_trainfile[['Sex', 'Survived']].groupby(['Sex'], as_index=False).mean().sort_values(by='Survived', ascending=False)","92075ac2":"sns.countplot(data = df_trainfile, x='Sex', hue='Survived')\nplt.title('Number of people survived according to their Gender')\nplt.show()","f5fbf476":"#types of columns('Numerical','Categorical')\ndisplay(df_trainfile.dtypes)\ndisplay(df_testfile.dtypes)\n","61b9f5a1":"# df_trainfile['Sex'] = df_trainfile['Sex'].map({'female': 1 , 'male' : 0})\n# df_testfile['Sex'] = df_testfile['Sex'].map({'female': 1 , 'male' : 0})","22f91a41":"# # Handling Missing Values\ndf_trainfile['Age'] = df_trainfile['Age'].fillna(df_trainfile['Age'].mean())\ndf_testfile['Age'] = df_testfile['Age'].fillna(df_trainfile['Age'].mean())\ndf_trainfile['Embarked'] = df_trainfile['Embarked'].fillna(df_trainfile['Embarked'].mode()[0])\n# df_trainfile['Embarked'] = df_trainfile['Embarked'].fillna(\"S\")\ndf_testfile['Fare'] = df_testfile['Fare'].fillna(df_trainfile['Fare'].mean())\n\n\ndf_trainfile.info()","391d712a":"# using labelEncoder to Handle Categorical data\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\ndf_trainfile['Sex'] = le.fit_transform(df_trainfile['Sex'])\ndf_testfile['Sex'] = le.fit_transform(df_testfile['Sex'])\ndf_trainfile['Embarked']= le.fit_transform(df_trainfile['Embarked'])\ndf_testfile ['Embarked'] = le.fit_transform(df_testfile ['Embarked'])\n\n\ndisplay(df_trainfile.head())\ndisplay(df_testfile.head())","db819bbb":"display('train data ' , df_trainfile.isnull().sum())\ndisplay(' test data ' ,df_testfile.isnull().sum())","303e997b":"#types of columns('Numerical','Categorical')\ndisplay(df_trainfile.dtypes)\ndisplay(df_testfile.dtypes)","f12f2ef8":"Y = df_trainfile[['Survived']]\ndf_trainfile = df_trainfile.drop(['PassengerId', 'Survived', 'Name'], axis = 1)\ndf_testfile = df_testfile.drop(['Name'], axis = 1)","9e943484":"from sklearn.model_selection import train_test_split\ndf_trainfile_train, x_trainfile_test, y_train, y_test = train_test_split(df_trainfile, Y,  test_size=0.25, stratify = Y)","0d1a51ae":"lo = LogisticRegression(solver = 'liblinear')\nlo.fit(df_trainfile_train,y_train)\nprint(\"model score: %.3f\" % lo.score(df_trainfile_train, y_train))\ny_pred1 = lo.predict(x_trainfile_test)","92a16184":"df_testfile_updated = df_testfile.drop(['PassengerId'], axis = 1)\nlo.fit(df_trainfile,Y)\ny_pred = lo.predict(df_testfile_updated)","3ce8beba":"y_pred = np.squeeze(y_pred)\ny_pred.shape\n# # Save test predictions to file\noutput = pd.DataFrame({'PassengerId': df_testfile.PassengerId,\n                     'Survived': y_pred})\noutput.to_csv('submissionv3.csv', index=False)","7d5f9b0a":"**Importing Libraries**","41d0a7d5":"**Read Data  from csv Files**"}}