{"cell_type":{"9891384a":"code","e0abba75":"code","5a328de4":"code","44cd6c27":"code","a107c9dd":"code","febf6af1":"code","62c9daf5":"code","65b814d5":"markdown","6e9222a6":"markdown","2d36815d":"markdown","5dc784bc":"markdown","8802ce57":"markdown","9390d335":"markdown"},"source":{"9891384a":"# To install the package and data internet connection must be enabled. Check kernel settings.\n\n!pip install git+https:\/\/github.com\/onurtunali\/FrEIA.git\n!wget https:\/\/raw.githubusercontent.com\/onurtunali\/FrEIA\/master\/examples\/data.py","e0abba75":"%matplotlib notebook\n\nimport torch\nimport torch.optim\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom time import time\n\nfrom FrEIA.framework import InputNode, OutputNode, Node, ReversibleGraphNet\nfrom FrEIA.modules import rev_multiplicative_layer, F_fully_connected\n\nimport data\n\ndevice = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(f\"Current device is {device} and Data is imported\")","5a328de4":"batch_size = 1600\ntest_split = 10000\n\npos, labels = data.generate(\n    labels='all',\n    tot_dataset_size=2**20\n)\nc = np.where(labels[:test_split])[1]\nplt.figure(figsize=(6, 6))\nplt.scatter(pos[:test_split, 0], pos[:test_split, 1], c=c, cmap='Set1', s=0.25)\nplt.xticks([])\nplt.yticks([])\nplt.show()\n# print(f\"{pos[0]}\\n{labels[0]}\\n{np.where(labels[:test_split])}\")","44cd6c27":"ndim_tot = 16\nndim_x = 2\nndim_y = 8\nndim_z = 2\n\ninp = InputNode(ndim_tot, name='input')\n\nt1 = Node([inp.out0], rev_multiplicative_layer,\n          {'F_class': F_fully_connected, 'clamp': 2.0,\n           'F_args': {'dropout': 0.0}})\n\nt2 = Node([t1.out0], rev_multiplicative_layer,\n          {'F_class': F_fully_connected, 'clamp': 2.0,\n           'F_args': {'dropout': 0.0}})\n\nt3 = Node([t2.out0], rev_multiplicative_layer,\n          {'F_class': F_fully_connected, 'clamp': 2.0,\n           'F_args': {'dropout': 0.0}})\n\noutp = OutputNode([t3.out0], name='output')\n\nnodes = [inp, t1, t2, t3, outp]\nmodel = ReversibleGraphNet(nodes)","a107c9dd":"# Training parameters\nn_epochs = 300\nmeta_epoch = 12\nn_its_per_epoch = 4\nbatch_size = 1600\n\nlr = 1e-2\ngamma = 0.01**(1.\/120)\nl2_reg = 2e-5\n\ny_noise_scale = 3e-2\nzeros_noise_scale = 3e-2\n\n# relative weighting of losses:\nlambd_predict = 300.\nlambd_latent = 300.\nlambd_rev = 400.\n\npad_x = torch.zeros(batch_size, ndim_tot - ndim_x)\npad_yz = torch.zeros(batch_size, ndim_tot - ndim_y - ndim_z)\n\noptimizer = torch.optim.Adam(model.parameters(), lr=lr, betas=(0.8, 0.8),\n                             eps=1e-04, weight_decay=l2_reg)\n\nscheduler = torch.optim.lr_scheduler.StepLR(optimizer,\n                                            step_size=meta_epoch,\n                                            gamma=gamma)\n\n\ndef MMD_multiscale(x, y):\n    xx, yy, zz = torch.mm(x,x.t()), torch.mm(y,y.t()), torch.mm(x,y.t())\n\n    rx = (xx.diag().unsqueeze(0).expand_as(xx))\n    ry = (yy.diag().unsqueeze(0).expand_as(yy))\n\n    dxx = rx.t() + rx - 2.*xx\n    dyy = ry.t() + ry - 2.*yy\n    dxy = rx.t() + ry - 2.*zz\n\n    XX, YY, XY = (torch.zeros(xx.shape).to(device),\n                  torch.zeros(xx.shape).to(device),\n                  torch.zeros(xx.shape).to(device))\n\n    for a in [0.2, 0.5, 0.9, 1.3]:\n        XX += a**2 * (a**2 + dxx)**-1\n        YY += a**2 * (a**2 + dyy)**-1\n        XY += a**2 * (a**2 + dxy)**-1\n\n    return torch.mean(XX + YY - 2.*XY)\n\n\ndef fit(input, target):\n    return torch.mean((input - target)**2)\n\nloss_backward = MMD_multiscale\nloss_latent = MMD_multiscale\nloss_fit = fit\n\ntest_loader = torch.utils.data.DataLoader(\n    torch.utils.data.TensorDataset(pos[:test_split], labels[:test_split]),\n    batch_size=batch_size, shuffle=True, drop_last=True)\n\ntrain_loader = torch.utils.data.DataLoader(\n    torch.utils.data.TensorDataset(pos[test_split:], labels[test_split:]),\n    batch_size=batch_size, shuffle=True, drop_last=True)","febf6af1":"def train(i_epoch=0):\n    model.train()\n\n    l_tot = 0\n    batch_idx = 0\n    \n    t_start = time()\n    \n    loss_factor = 600**(float(i_epoch) \/ 300) \/ 600\n    if loss_factor > 1:\n        loss_factor = 1\n\n    for x, y in train_loader:\n        batch_idx += 1\n        if batch_idx > n_its_per_epoch:\n            break\n\n        x, y = x.to(device), y.to(device)\n        \n        y_clean = y.clone()\n        pad_x = zeros_noise_scale * torch.randn(batch_size, ndim_tot -\n                                                ndim_x, device=device)\n        pad_yz = zeros_noise_scale * torch.randn(batch_size, ndim_tot -\n                                                 ndim_y - ndim_z, device=device)\n\n        y += y_noise_scale * torch.randn(batch_size, ndim_y, dtype=torch.float, device=device)\n\n        x, y = (torch.cat((x, pad_x),  dim=1),\n                torch.cat((torch.randn(batch_size, ndim_z, device=device), pad_yz, y),\n                          dim=1))\n        \n\n        optimizer.zero_grad()\n\n        # Forward step:\n\n        output = model(x)\n\n        # Shorten output, and remove gradients wrt y, for latent loss\n        y_short = torch.cat((y[:, :ndim_z], y[:, -ndim_y:]), dim=1)\n\n        l = lambd_predict * loss_fit(output[:, ndim_z:], y[:, ndim_z:])\n\n        output_block_grad = torch.cat((output[:, :ndim_z],\n                                       output[:, -ndim_y:].data), dim=1)\n\n        l += lambd_latent * loss_latent(output_block_grad, y_short)\n        l_tot += l.data.item()\n\n        l.backward()\n\n        # Backward step:\n        pad_yz = zeros_noise_scale * torch.randn(batch_size, ndim_tot -\n                                                 ndim_y - ndim_z, device=device)\n        y = y_clean + y_noise_scale * torch.randn(batch_size, ndim_y, device=device)\n\n        orig_z_perturbed = (output.data[:, :ndim_z] + y_noise_scale *\n                            torch.randn(batch_size, ndim_z, device=device))\n        y_rev = torch.cat((orig_z_perturbed, pad_yz,\n                           y), dim=1)\n        y_rev_rand = torch.cat((torch.randn(batch_size, ndim_z, device=device), pad_yz,\n                                y), dim=1)\n        \n        output_rev = model(y_rev, rev=True)\n        output_rev_rand = model(y_rev_rand, rev=True)\n\n        l_rev = (\n            lambd_rev\n            * loss_factor\n            * loss_backward(output_rev_rand[:, :ndim_x],\n                            x[:, :ndim_x])\n        )\n\n        l_rev += 0.50 * lambd_predict * loss_fit(output_rev, x)\n        \n        l_tot += l_rev.data.item()\n        l_rev.backward()\n\n        for p in model.parameters():\n            p.grad.data.clamp_(-15.00, 15.00)\n\n        optimizer.step()\n\n#     print('%.1f\\t%.5f' % (\n#                              float(batch_idx)\/(time()-t_start),\n#                              l_tot \/ batch_idx,\n#                            ), flush=True)\n\n    return l_tot \/ batch_idx","62c9daf5":"for mod_list in model.children():\n    for block in mod_list.children():\n        for coeff in block.children():\n            coeff.fc3.weight.data = 0.01*torch.randn(coeff.fc3.weight.shape)\n            \nmodel.to(device)\n\nfig, axes = plt.subplots(1, 2, figsize=(8,4))\naxes[0].set_xticks([])\naxes[0].set_yticks([])\naxes[0].set_title('Predicted labels (Forwards Process)')\naxes[1].set_xticks([])\naxes[1].set_yticks([])\naxes[1].set_title('Generated Samples (Backwards Process)')\nfig.show()\nfig.canvas.draw()\n\nN_samp = 4096\n\nx_samps = torch.cat([x for x,y in test_loader], dim=0)[:N_samp]\ny_samps = torch.cat([y for x,y in test_loader], dim=0)[:N_samp]\nc = np.where(y_samps)[1]\ny_samps += y_noise_scale * torch.randn(N_samp, ndim_y)\ny_samps = torch.cat([torch.randn(N_samp, ndim_z),\n                     zeros_noise_scale * torch.zeros(N_samp, ndim_tot - ndim_y - ndim_z), \n                     y_samps], dim=1)\ny_samps = y_samps.to(device)\n            \ntry:\n#     print('#Epoch \\tIt\/s \\tl_total')\n    t_start = time()\n    for i_epoch in tqdm(range(n_epochs), ascii=True, ncols=80):\n\n        scheduler.step()\n\n        # Initially, the l2 reg. on x and z can give huge gradients, set\n        # the lr lower for this\n        if i_epoch < 0:\n            for param_group in optimizer.param_groups:\n                param_group['lr'] = lr * 1e-2\n\n#         print(i_epoch, end='\\t ')\n        train(i_epoch)\n\n        rev_x = model(y_samps, rev=True)\n        rev_x = rev_x.cpu().data.numpy()\n        \n        pred_c = model(torch.cat((x_samps, torch.zeros(N_samp, ndim_tot - ndim_x)),\n                                 dim=1).to(device)).data[:, -8:].argmax(dim=1)\n\n        axes[0].clear()\n        axes[0].scatter(x_samps[:,0].cpu(), x_samps[:,1].cpu(), c=pred_c.cpu(), cmap='Set1', s=1., vmin=0, vmax=9)\n        axes[0].axis('equal')\n        axes[0].axis([-3,3,-3,3])\n        axes[0].set_xticks([])\n        axes[0].set_yticks([])\n\n        \n        axes[1].clear()\n        axes[1].scatter(rev_x[:,0], rev_x[:,1], c=c, cmap='Set1', s=1., vmin=0, vmax=9)\n        axes[1].axis('equal')\n        axes[1].axis([-3,3,-3,3])\n        axes[1].set_xticks([])\n        axes[1].set_yticks([])\n        \n        fig.canvas.draw()\n\n\nexcept KeyboardInterrupt:\n    pass\nfinally:\n    print(f\"\\n\\nTraining took {(time()-t_start)\/60:.2f} minutes\\n\")","65b814d5":"## Setting up the data\n\nWe generate the data by sampling from a Gaussian mixture distribution with 8 labeled modes. The dataset will contain $2^{20}$ samples, $10000$ of which we will use for testing purposes.\n\nYou can see a plot of the test data below.\n\nIn the forward process our model is supposed to predict the label (or in this case, color) of a sample based on its position in $\\mathbb{R}^2$. In the reverse direction the model should allow us to sample from the mixture component given by a label.","6e9222a6":"## Training the model\n\nWe will train our model using 3 losses. In the forward direction we apply a MSE loss to the assigned label and a distributional loss to the latent variable $z$.\nWe make use of the reversability of our model and apply a third loss, that matches the distribution of samples from our dataset to the distribution of backward predictions of our model.\nYou can find more information on the losses in the [paper](https:\/\/arxiv.org\/abs\/1808.04730).\n","2d36815d":"We initialize our model parameters using normal distributions. The following loop over epochs plots label predictions and backwards predicted samples, so you can see the model getting better during training.","5dc784bc":"We can now define ou training method. Note how we simply used the model for forward training, zeroed the gradients and switch to backwards training simply by setting `rev=True`. Randomness in the samples generated by backwards prediction is achieved by drawing $z$ randomly from a 2-dimensional Normal distribution.","8802ce57":"# Toy Minimum Example for Invertible Neural Networks\n\nThis notebook is supposed to demonstrate how to use FrEIA to create reversible architectures. We will use the toy data from the following paper. Credit goes to [Visual Learning Lab](https:\/\/github.com\/VLL-HD) and the original notebok is [here](https:\/\/github.com\/VLL-HD\/FrEIA\/tree\/master\/experiments\/toy_8-modes). This is just for practice.\n\n**\"Analyzing inverse problems with invertible neural networks.\" (2018)** \n\nhttps:\/\/arxiv.org\/abs\/1808.04730","9390d335":"## Setting up the model\n\nOur model consists of three invertible blocks using multiplicative coupling layers and 3-layer fully connected sub-networks for $s_i$ and $t_i$. The input is encoded in 2 dimensions. The latent dimension $z$ is set to 2 and concatenated with the predicted labels $y$ encoded as a 8-dimensional one-hot vector. In- and output are zero-padded to 16 dimensions."}}