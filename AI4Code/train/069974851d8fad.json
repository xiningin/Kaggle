{"cell_type":{"e05fcfe9":"code","62ca73a9":"code","a1e24d5c":"code","02b40f34":"code","ad463fe6":"code","fda05999":"code","5ae02bdf":"code","71892861":"code","b249e3e2":"code","162f094b":"code","18fd8f60":"code","48fa7edd":"code","66169378":"code","fb614dda":"code","14edf07e":"code","62048679":"code","ac67ae19":"code","0af5bb44":"code","a1c18d87":"code","c39ed726":"code","b5d13d29":"code","3841d98f":"code","79d6631c":"code","8406c25c":"code","e0186323":"code","d3f250dc":"code","6226a3aa":"code","234b0bdb":"code","67bee1c0":"code","abf4f285":"code","41072520":"code","acc27327":"code","ddd2c85a":"code","401201a9":"code","8093c263":"code","d9b867f7":"code","4f353e41":"code","339ac747":"code","4fcfcca6":"code","3248fea8":"markdown","1fdeb8a6":"markdown","dc12c0b0":"markdown","6fd997a8":"markdown","ad1039a8":"markdown","40c8e03a":"markdown","1511fec5":"markdown","4673d4ae":"markdown","babda340":"markdown"},"source":{"e05fcfe9":"import numpy as np\nimport pandas as pd\npd.set_option('display.max_columns', None)\nfrom scipy import stats\n\nimport os, sys, datetime\nfrom time import time\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom collections import Counter\n\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import cohen_kappa_score\n\nfrom catboost import CatBoostClassifier\nimport category_encoders as ce","62ca73a9":"Kaggle = True\n\nif Kaggle:\n    DIR = '..\/input\/data-science-bowl-2019'\n    task_type = 'CPU'\nelse:\n    DIR = '.\/data-science-bowl-2019'\n    task_type = 'GPU'","a1e24d5c":"train = pd.read_csv(os.path.join(DIR,'train.csv'))\ntrain_labels = pd.read_csv(os.path.join(DIR,'train_labels.csv'))\nspecs = pd.read_csv(os.path.join(DIR,'specs.csv'))\ntest = pd.read_csv(os.path.join(DIR,'test.csv'))","02b40f34":"print('train:\\t\\t',train.shape)\nprint('train_labels:\\t',train_labels.shape)\nprint('specs:\\t\\t',specs.shape)\nprint('test:\\t\\t',test.shape)","ad463fe6":"train.head()","fda05999":"train[['event_id','game_session','installation_id',\n       'title','type','world']].describe()","5ae02bdf":"event_code_n = train['event_code'].nunique()\nprint(\"num of unique 'event_code':\", event_code_n)\nprint(\"'event_code': \",\n      train['event_code'].min(), \"-\", train['event_code'].max())","71892861":"# 'event_data' exsample\nprint(train['event_data'][40])\nprint(train['event_data'][41])\nprint(train['event_data'][43])","b249e3e2":"train_labels.head()","162f094b":"train_labels[['game_session','installation_id', 'title']].describe()","18fd8f60":"# unique 'title' list\ntrain_labels['title'].unique()","48fa7edd":"specs.head()","66169378":"specs.describe()","fb614dda":"# 'info' exsample\nprint(specs['info'][0])\nprint(specs['info'][6])\nprint(specs['info'][7])","14edf07e":"# 'args' exsample\nprint(specs['args'][0])\nprint(specs['args'][1])","62048679":"test.head(8)","ac67ae19":"test[['event_id','game_session','installation_id',\n       'title','type','world']].describe()","0af5bb44":"# make 'title' and 'event_code' list\ntitle_list = list(set(train['title'].value_counts().index) \\\n                   .union(set(test['title'].value_counts().index)))\nevent_code_list = list(set(train['event_code'].value_counts().index) \\\n                   .union(set(test['event_code'].value_counts().index)))","a1c18d87":"# makes dict 'title to number(integer)'\ntitle2num = dict(zip(title_list, np.arange(len(title_list))))\n# makes dict 'number to title'\nnum2title = dict(zip(np.arange(len(title_list)), title_list))\n# makes dict 'title to win event_code' \n# (4100 except 'Bird Measurer' and 4110 for 'Bird Measurer'))\ntitle2win_code = dict(zip(title2num.values() \\\n                    ,(np.ones(len(title2num))).astype('int') * 4100))\ntitle2win_code[title2num['Bird Measurer (Assessment)']] = 4110","c39ed726":"# Convert 'title' to the number\ntrain['title'] = train['title'].map(title2num)\ntest['title'] = test['title'].map(title2num)\ntrain_labels['title'] = train_labels['title'].map(title2num)\n\n# Convert 'timestamp' to datetime\ntrain['timestamp'] = pd.to_datetime(train['timestamp'])\ntest['timestamp'] = pd.to_datetime(test['timestamp'])","b5d13d29":"# Convert the raw data into processed features\ndef get_data(user_sample, test_set=False):\n    '''\n    user_sample : DataFrame from train\/test group by 'installation_id'\n    test_set    : related with the labels processing\n    '''\n    # Constants and parameters declaration\n    user_assessments = []\n    last_type = 0\n    types_count = {'Clip':0, 'Activity':0, 'Assessment':0, 'Game':0}\n    time_first_activity = float(user_sample['timestamp'].values[0])\n    time_spent_each_title = {title:0 for title in title_list}\n    event_code_count = {code:0 for code in event_code_list}\n    accuracy_groups = {0:0, 1:0, 2:0, 3:0}\n    \n    accumu_accuracy_group = 0\n    accumu_accuracy=0\n    accumu_win_n = 0 \n    accumu_loss_n = 0 \n    accumu_actions = 0\n    counter = 0\n    durations = []\n    \n    # group by 'game_session'\n    for i, session in user_sample.groupby('game_session', sort=False):\n        # i      : game_session_id\n        # session: DataFrame from user_sample group by 'game_session'\n        session_type = session['type'].iloc[0]  # Game\/Assessment\/Activity\/Clip\n        session_title = session['title'].iloc[0]\n        \n        if session_type != 'Assessment':\n            time_spent = int(session['game_time'].iloc[-1] \/ 1000)   # [sec]\n            time_spent_each_title[num2title[session_title]] += time_spent\n        \n        if (session_type == 'Assessment') & (test_set or len(session)>1):\n            # search for event_code 4100(4110)\n            all_4100 = session.query(f'event_code == \\\n                                         {title2win_code[session_title]}')\n            # numbers of wins and losses\n            win_n = all_4100['event_data'].str.contains('true').sum()\n            loss_n = all_4100['event_data'].str.contains('false').sum()\n\n            # init features and then update\n            features = types_count.copy()\n            features.update(time_spent_each_title.copy())\n            features.update(event_code_count.copy())\n            features['session_title'] = session_title\n            features['accumu_win_n'] = accumu_win_n\n            features['accumu_loss_n'] = accumu_loss_n\n            accumu_win_n += win_n\n            accumu_loss_n += loss_n\n            \n            features['day_of_the_week'] = (session['timestamp'].iloc[-1]). \\\n                                            strftime('%A')    # Mod 2019-11-17\n\n            if durations == []:\n                features['duration_mean'] = 0\n            else:\n                features['duration_mean'] = np.mean(durations)\n            durations.append((session.iloc[-1, 2] - session.iloc[0, 2] ).seconds)\n\n            # average of the all accuracy of this player\n            features['accuracy_ave'] = accumu_accuracy \/ counter \\\n                                                if counter > 0 else 0\n            accuracy = win_n \/ (win_n + loss_n) \\\n                                   if (win_n + loss_n) > 0 else 0\n            accumu_accuracy += accuracy\n            if accuracy == 0:\n                features['accuracy_group'] = 0\n            elif accuracy == 1:\n                features['accuracy_group'] = 3\n            elif accuracy == 0.5:\n                features['accuracy_group'] = 2\n            else:\n                features['accuracy_group'] = 1\n            features.update(accuracy_groups)\n            accuracy_groups[features['accuracy_group']] += 1\n            # average of accuracy_groups of this player\n            features['accuracy_group_ave'] = \\\n                    accumu_accuracy_group \/ counter if counter > 0 else 0\n            accumu_accuracy_group += features['accuracy_group']\n            \n            # how many actions the player has done in this game_session\n            features['accumu_actions'] = accumu_actions\n            \n            # if test_set, all sessions belong to the final dataset\n            # elif train, needs to be passed throught this clausule\n            if test_set or (win_n + loss_n) > 0:\n                user_assessments.append(features)\n                \n            counter += 1\n        \n        # how many actions was made in each event_code\n        event_codes = Counter(session['event_code'])\n        for key in event_codes.keys():\n            event_code_count[key] += event_codes[key]\n\n        # how many actions the player has done\n        accumu_actions += len(session)\n        if last_type != session_type:\n            types_count[session_type] += 1\n            last_type = session_type\n            \n    # if test_set, only the last assessment must be predicted,\n    # the previous are scraped\n    if test_set:\n        return user_assessments[-1]\n    return user_assessments","3841d98f":"# get_data function is applyed to each installation_id\ncompiled_data = []\ninstallation_n = train['installation_id'].nunique()\nfor i, (ins_id, user_sample) in tqdm(enumerate(train.groupby( \\\n                                     'installation_id', sort=False)),\n                                     total=installation_n):\n    # user_sample : DataFrame group by 'installation_id'\n    compiled_data += get_data(user_sample)","79d6631c":"# the compiled_data is converted to DataFrame and deleted to save memory\nnew_train = pd.DataFrame(compiled_data)\ndel compiled_data","8406c25c":"new_train.head(10)","e0186323":"# process test set, the same that was done with the train set\nnew_test = []\nfor ins_id, user_sample in tqdm(test.groupby('installation_id',sort=False),\n                                total=1000):\n    new_test.append(get_data(user_sample, test_set=True))\n    \nnew_test = pd.DataFrame(new_test)","d3f250dc":"new_test.head(10)","6226a3aa":"# all_features but 'accuracy_group', that is the label y\nall_features = [x for x in new_train.columns if x not in ['accuracy_group']]\n# categorical feature\ncategorical_features = ['session_title','day_of_the_week']","234b0bdb":"# Encode categorical_features to integer(for use with LightGB,XGBoost,etc)\n\n# concatnate train and test data\ntemp_df = pd.concat([new_train[all_features], new_test[all_features]])\n# encode\nencoder = ce.ordinal.OrdinalEncoder(cols = categorical_features)\ntemp_df = encoder.fit_transform(temp_df)\n# dataset\nX, y = temp_df.iloc[:len(new_train),:], new_train['accuracy_group']\nX_test = temp_df.iloc[len(new_train):,:]","67bee1c0":"X.head()","abf4f285":"y.head()","41072520":"X_test.head()","acc27327":"# makes the model and set the parameters\ndef make_classifier():\n    model = CatBoostClassifier(\n        loss_function='MultiClass',\n        eval_metric=\"WKappa\",\n        task_type=task_type,\n        thread_count=-1,\n        od_type=\"Iter\",\n        early_stopping_rounds=500,\n        random_seed=50,\n        \n        border_count=110,\n        l2_leaf_reg=10,\n        iterations=2000,\n        learning_rate=0.1,\n        depth=6\n    )\n    return model","ddd2c85a":"# Train and make 5 models\nstart_time = time()\n\nNFOLDS = 5\nfolds = StratifiedKFold(n_splits=NFOLDS, shuffle=True, random_state=42)\nmodels = []\nscores = []\nfor fold, (train_ids, test_ids) in enumerate(folds.split(X, y)):\n    print('\u25cf Fold :', fold+1)\n    model = make_classifier()\n    model.fit(X.loc[train_ids, all_features], y.loc[train_ids], \n              eval_set=(X.loc[test_ids, all_features], y.loc[test_ids]),\n              use_best_model=False,     # The meaning of this parameter does not fall into the trap\n              verbose=500,\n              cat_features=categorical_features)    \n    models.append(model)\n    scores.append(model.get_best_score()['validation']['WKappa'])\n    print('\\n')\n    \nprint('-' * 50)\nprint(\"Average 'WKappa' Score =\", np.mean(scores))\nprint('-' * 50)\nprint('finished in {}'.format( \n    str(datetime.timedelta(seconds=time() - start_time))))","401201a9":"# Check the effect of 'voting'\npredictions = []\nfor model in models:\n    predictions.append(model.predict(X).astype(int))\npredictions = np.concatenate(predictions, axis=1)\ndf = pd.DataFrame(predictions)\n\nvote = stats.mode(predictions, axis=1)[0].reshape(-1)\ndf['vote'] = vote\ndf['y'] = y\ndf.head(10)","8093c263":"kappa_score = []\nfor col in df.columns[:NFOLDS+1]:\n    kappa_score.append(cohen_kappa_score(df['y'], df[col]))\nprint('kappa_score:\\n',kappa_score)\nprint('average score:',np.mean(kappa_score[:NFOLDS]))\nprint('voting score :',kappa_score[-1],'\\n')\nprint('Improved from',np.mean(kappa_score[:NFOLDS]),'to',\n      kappa_score[-1],\"by 'voting'\")","d9b867f7":"predictions = []\nfor model in models:\n    predictions.append(model.predict(X_test))\npredictions = np.concatenate(predictions, axis=1)\n# Voting\npredictions = stats.mode(predictions, axis=1)[0].reshape(-1)\nprint(predictions.shape)","4f353e41":"submission = pd.read_csv(os.path.join(DIR,'sample_submission.csv'))\nsubmission['accuracy_group'] = np.round(predictions).astype('int')\nsubmission.head(10)","339ac747":"submission['accuracy_group'].plot(kind='hist')","4fcfcca6":"submission.to_csv('submission.csv', index=None)","3248fea8":"### 4. test","1fdeb8a6":"### 1. train","dc12c0b0":"### 3. specs","6fd997a8":"## Model (CatBoostClassifier)","ad1039a8":"## Observe the data","40c8e03a":"## CatBoost with Voting\n- Create several types of train_data with kFold, and then create a model for each dataset.\n- Estimate the final result by 'voting method' of the prediction result of each model.","1511fec5":"## Compile data\nBased on several kernels\n- Hosseinali: https:\/\/www.kaggle.com\/mhviraf\/a-new-baseline-for-dsb-2019-catboost-model\n- Bruno Aquino: https:\/\/www.kaggle.com\/braquino\/catboost-some-more-features","4673d4ae":"### 2. train_labels","babda340":"## Make submission"}}