{"cell_type":{"a77f1907":"code","fdf155b4":"code","f4672765":"code","97d08a72":"code","db792a7f":"code","652eb07f":"code","63b39482":"code","8b53feb0":"code","cf217326":"code","9dea3433":"code","4579784a":"code","43745a8c":"code","9a93ce27":"code","b0753ce5":"code","6c5e2769":"code","3085f32c":"code","5c618b72":"code","b00f2cca":"code","b5a79ffe":"code","f107dcd5":"code","99da1172":"code","d347cd5e":"code","bb7a4170":"code","0936e1e4":"markdown","f27375e5":"markdown","1bc2a183":"markdown","c0eccca9":"markdown","44116608":"markdown","47861535":"markdown","9611ad7e":"markdown","8be3b354":"markdown","72d774bc":"markdown","7f63fffe":"markdown","dda24005":"markdown","86f8747c":"markdown","9345b69d":"markdown","3438ffc2":"markdown","b1206694":"markdown","41017438":"markdown","32a6391a":"markdown","67fa5f8d":"markdown"},"source":{"a77f1907":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns\nimport tensorflow\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.random import set_random_seed\nfrom tensorflow.keras.applications import VGG16\nfrom tensorflow.keras.layers import Flatten, Dense, Dropout\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.optimizers import RMSprop, SGD, Adam, Nadam\nfrom tensorflow.keras.regularizers import l1, l2, L1L2\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n\nset_random_seed(0)\nnp.random.seed(0)","fdf155b4":"path = \"..\/input\/split-garbage-dataset\/split-garbage-dataset\"","f4672765":"train_datagen = ImageDataGenerator(\n        rescale = 1.\/255,\n        rotation_range = 20,\n        width_shift_range = 0.2,\n        height_shift_range = 0.2,\n        horizontal_flip = True,\n        vertical_flip = True,\n        fill_mode='nearest'\n)\nvalidation_datagen = ImageDataGenerator(\n        rescale = 1.\/255\n)\ntest_datagen = ImageDataGenerator(\n        rescale = 1.\/255\n)","97d08a72":"img_shape = (224, 224, 3) # default values\n\ntrain_batch_size = 256\nval_batch_size = 32\n\ntrain_generator = train_datagen.flow_from_directory(\n            path + '\/train',\n            target_size = (img_shape[0], img_shape[1]),\n            batch_size = train_batch_size,\n            class_mode = 'categorical',)\n\nvalidation_generator = validation_datagen.flow_from_directory(\n            path + '\/valid',\n            target_size = (img_shape[0], img_shape[1]),\n            batch_size = val_batch_size,\n            class_mode = 'categorical',\n            shuffle=False)\n\ntest_generator = test_datagen.flow_from_directory(\n            path + '\/test',\n            target_size = (img_shape[0], img_shape[1]),\n            batch_size = val_batch_size,\n            class_mode = 'categorical',\n            shuffle=False,)","db792a7f":"vgg = VGG16(weights = 'imagenet',\n              include_top = False,\n              input_shape = img_shape)","652eb07f":"# Freeze the layers except the last 3 layers\nfor layer in vgg.layers[:-3]:\n    layer.trainable = False","63b39482":"# Create the model\nmodel = Sequential()\n \n# Add the vgg convolutional base model\nmodel.add(vgg)\n \n# Add new layers\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.2))\nmodel.add(Dense(6, activation='softmax'))","8b53feb0":"model.summary()","cf217326":"# Compile the model\nmodel.compile(loss='categorical_crossentropy',\n              optimizer=Nadam(lr=1e-4),\n              metrics=['acc'])","9dea3433":"# Train the model\nes = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=10)\nmc = ModelCheckpoint('VGG16 Garbage Classifier.h5', monitor='val_acc', mode='max', verbose=1, save_best_only=True)\n\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=train_generator.samples\/train_generator.batch_size ,\n    epochs=30,\n    validation_data=validation_generator,\n    validation_steps=validation_generator.samples\/validation_generator.batch_size,\n    verbose=0,\n    callbacks = [es, mc],)","4579784a":"score = model.evaluate(validation_generator,batch_size=32)\nscore\nprint('Score Accuracy : {:.2f}%'.format(score[1]*100))","43745a8c":"train_acc = history.history['acc']\nval_acc = history.history['val_acc']\ntrain_loss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs = range(1, len(train_acc) + 1)\n\nplt.plot(epochs, train_acc, 'b*-', label = 'Training accuracy')\nplt.plot(epochs, val_acc, 'r', label = 'Validation accuracy')\nplt.title('Training and validation accuracy')\nplt.legend()\n\nplt.figure()\n\nplt.plot(epochs, train_loss, 'b*-', label = 'Training loss')\nplt.plot(epochs, val_loss, 'r', label = 'Validation loss')\nplt.title('Training and validation loss')\nplt.legend()\n\nplt.show()","9a93ce27":"pred_Y = model.predict(validation_generator, batch_size = 32, verbose = True)\npred_Y_cat = np.argmax(pred_Y, -1)","b0753ce5":"from sklearn.preprocessing import LabelBinarizer\nLABELS=[\"CARDBOARD\",\"GLASS\",\"METAL\",\"PAPER\",\"PLASTIC\",\"TRASH\"]\n# binarize the labels\nlabels = np.array(LABELS)\nlb = LabelBinarizer()\nlabels = lb.fit_transform(labels)","6c5e2769":"!pip install imutils","3085f32c":"from tensorflow.keras.preprocessing.image import img_to_array\nfrom tensorflow.keras.preprocessing.image import load_img\nfrom tensorflow.keras.models import load_model\nimport numpy as np\nimport mimetypes\nimport argparse\nimport imutils\nimport pickle\nimport cv2\nimport os","5c618b72":"print(\"[INFO] loading object detector...\")\nmodel = load_model('.\/VGG16 Garbage Classifier.h5')","b00f2cca":"def predict(imagePath):\n    # load the input image (in Keras format) from disk and preprocess\n    # it, scaling the pixel intensities to the range [0, 1]\n    image = cv2.imread(imagePath)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    output = image.copy()\n    image = cv2.resize(image, (224, 224))\n    image = image.astype(\"float\") \/ 255.0\n    image = img_to_array(image)\n    image = np.expand_dims(image, axis=0)\n    # make bounding box predictions on the input image\n    proba = model.predict(image)[0]\n    idx = np.argmax(proba)\n    label = lb.classes_[idx]\n    label = \"{}: {:.2f}% \".format(label, proba[idx] * 100)\n    cv2.putText(output, label, (10, 25),  cv2.FONT_HERSHEY_SIMPLEX,\n        0.7, (255, 0, 0), 2)\n        \n    # show the output image\n    fig=plt.figure(figsize=(10,10))\n    plt.grid(b=None)\n    plt.axis('off')\n    return plt.imshow(output)","b5a79ffe":"imagePath = \"..\/input\/split-garbage-dataset\/test\/glass\/glass118.jpg\"\npredict(imagePath)","f107dcd5":"imagePath = \"..\/input\/split-garbage-dataset\/test\/plastic\/plastic122.jpg\"\npredict(imagePath)","99da1172":"imagePath = \"..\/input\/split-garbage-dataset\/test\/trash\/trash109.jpg\"\npredict(imagePath)","d347cd5e":"imagePath = \"..\/input\/split-garbage-dataset\/test\/cardboard\/cardboard260.jpg\"\npredict(imagePath)","bb7a4170":"imagePath = \"..\/input\/split-garbage-dataset\/test\/metal\/metal170.jpg\"\npredict(imagePath)","0936e1e4":"# Building model","f27375e5":"## Test set accuracy (Test seti do\u011frulu\u011fu)","1bc2a183":"# Prediction on test set","c0eccca9":"> Keras'ta her katman\u0131n \"e\u011fitilebilir\" adl\u0131 bir parametresi vard\u0131r. Belirli bir katman\u0131n a\u011f\u0131rl\u0131klar\u0131n\u0131 dondurmak i\u00e7in bu parametreyi False olarak ayarlamal\u0131y\u0131z, bu da bu katman\u0131n e\u011fitilmemesi gerekti\u011fini belirtir. Bu kadar! Her katman\u0131n \u00fczerinden ge\u00e7ip hangi katmanlar\u0131 e\u011fitmek istedi\u011fimizi se\u00e7iyoruz. ","44116608":"# Data preprocessing","47861535":"##  Gerekli k\u00fct\u00fcphaneleri y\u00fckle","9611ad7e":"###### - Burada elimizdeki g\u00f6rsellerin belli \u00f6zellikleri ile oynayarak g\u00f6r\u00fcnt\u00fcy\u00fc \u00e7o\u011faltabiliriz.Bunu yapmam\u0131z\u0131n sebebi ileride e\u011fitim s\u0131ras\u0131nda ,modelimizden daha iyi bir sonu\u00e7 alabilmek\n\n* Derin \u00f6\u011frenme modelleri ,e\u011fitim verilerine uyma konusunda iyi olma e\u011filimindedir. ancak as\u0131l zorluk uydurmak de\u011fil genelleme yapt\u0131rabilmek \n\n* modelin datasetini ezberlemeden ka\u00e7\u0131nmak\n\n###### - overfitting veya underfitting olmas\u0131n\u0131 engellemek i\u00e7in \u015fu a\u015famalar\u0131 ger\u00e7ekle\u015ftirebiliriz\n\n* Veri seti artt\u0131rma (dataset augmentation)\n* D\u00fc\u011f\u00fcm seyreltme (Dropout layer)\n* erken durdurma(early Stoping)","8be3b354":"> * ##### \u00d6nceden E\u011fitilmi\u015f Evri\u015fimli Taban (VGG16) modeli kullan\u0131lacak","72d774bc":"## Model definition ( modelimizi tan\u0131ml\u0131yoruz )","7f63fffe":"Bu, do\u011frulama metriklerini \u00e7izip e\u011fitim metrikleriyle kar\u015f\u0131la\u015ft\u0131r\u0131rsan\u0131z g\u00f6r\u00fcn\u00fcr.\n\n* K\u00fc\u00e7\u00fck bir fark olmas\u0131 normaldir.\n* Her iki \u00f6l\u00e7\u00fcm de ayn\u0131 y\u00f6nde hareket ediyorsa, her \u015fey yolunda demektir.\n* E\u011fitim metri\u011fi geli\u015fmeye devam ederken do\u011frulama metri\u011fi durgunla\u015fmaya ba\u015flarsa, muhtemelen a\u015f\u0131r\u0131 uyuma yakla\u015f\u0131yorsunuz demektir.\n* Do\u011frulama \u00f6l\u00e7\u00fcs\u00fc yanl\u0131\u015f y\u00f6ne gidiyorsa, model a\u00e7\u0131k\u00e7a gere\u011finden fazla uyumludur.","dda24005":"### Freeze VGG layers","86f8747c":"## Pretrained Convolutional Base (VGG16)","9345b69d":"### Training history","3438ffc2":"## Train the model ( olu\u015fturdu\u011fumuz modeli e\u011fitme zaman\u0131 )","b1206694":"## Fine-tuning","41017438":"Burada at\u0131lan \u00e7\u00f6plerin s\u0131n\u0131f\u0131rlar\u0131n\u0131 belirlemeye \u00e7al\u0131\u015faca\u011f\u0131z","32a6391a":"K\u00fct\u00fcphaneden verilerimizi \u00e7ektik","67fa5f8d":"loss='categorical_crossentropy'\n* Etiketler ve tahminler aras\u0131ndaki \u00e7aprazentropi kayb\u0131n\u0131 hesaplar.\n\u0130ki veya daha fazla etiket s\u0131n\u0131f\u0131 oldu\u011funda bu \u00e7aprazentropi kayb\u0131 i\u015flevini kullan\u0131n"}}