{"cell_type":{"c14ca74d":"code","02a2c173":"code","a25a71c2":"code","5c456166":"code","6acc0176":"code","3f44713e":"code","7c44caba":"code","cb6b549c":"code","7b1fc1d1":"code","c4aee075":"code","36508adb":"code","f0a5f1d2":"code","a7d2bc03":"code","d788c2d4":"code","551df81a":"code","71823be1":"code","17c17f46":"code","ff19a54c":"code","c5babb83":"code","38dc4527":"code","f2d9e9a2":"code","6adb8db4":"code","3d3b1b00":"markdown","f5d7ffdc":"markdown","54a52b1e":"markdown","d13c6080":"markdown","37be8163":"markdown","6c4ed253":"markdown","842247d9":"markdown","c33399ca":"markdown"},"source":{"c14ca74d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","02a2c173":"import os\nimport cv2\nimport json\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n\nfrom sklearn.model_selection import train_test_split\n\nfrom tensorflow.keras import layers, models\nfrom tensorflow.keras.optimizers import Adam\nfrom tensorflow.keras.applications import Xception\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator","a25a71c2":"df = pd.read_csv('\/kaggle\/input\/cassava-leaf-disease-classification\/train.csv')\ndf.head(5)","5c456166":"df = df[~df['image_id'].isin(['1562043567.jpg', '3551135685.jpg', '2252529694.jpg'])]","6acc0176":"with open('\/kaggle\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json') as f:\n    mapping = json.loads(f.read())\n    print(mapping)","3f44713e":"df['label'].value_counts().plot.bar()","7c44caba":"plt.pie(df['label'].value_counts(), labels = mapping.values()) \nplt.show()","cb6b549c":"def visualize(img_list):\n    rows = 2\n    cols = 4\n\n    plt.figure(figsize=(20, 10))\n\n    for i in range(rows*cols):\n        plt.subplot(10\/cols+1, cols, i+1)\n        r = np.random.randint(len(img_list))\n        img_path = \"\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/\" + str(img_list[r])\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        #hsv = cv2.cvtColor(img, cv2.COLOR_RGB2HSV)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(str(img_list[r]))\n        plt.imshow(img)\n        #plt.imshow(hsv, cmap = 'hsv')\n\n    plt.tight_layout()\n    plt.show()","7b1fc1d1":"#Visualizing Class 0 -> Cassava Bacterial Blight (CBB)\ncbb_df = df[df['label'].isin([0])]\ncbb_img_list = list(df['image_id'])\n\nvisualize(cbb_img_list)","c4aee075":"#Visualizing Class 1 -> Cassava Brown Streak Disease (CBSD)\ncbsd_df = df[df['label'].isin([1])]\ncbsd_img_list = list(df['image_id'])\n\nvisualize(cbsd_img_list)","36508adb":"#Visualizing Class 2 -> Cassava Green Mottle (CGM)\ncgm_df = df[df['label'].isin([2])]\ncgm_img_list = list(df['image_id'])\n\nvisualize(cgm_img_list)","f0a5f1d2":"#Visualizing Class 3 -> Cassava Mosaic Disease (CMD)\ncmd_df = df[df['label'].isin([3])]\ncmd_img_list = list(df['image_id'])\n\nvisualize(cmd_img_list)","a7d2bc03":"#Visualizing Class 4 -> Healthy Leaves\nhealthy_df = df[df['label'].isin([4])]\nhealthy_img_list = list(df['image_id'])\n\nvisualize(healthy_img_list)","d788c2d4":"BATCH_SIZE = 16\nTARGET_SIZE = 299\nBASE_DIR = \"\/kaggle\/input\/cassava-leaf-disease-classification\/\"\nEPOCHS = 30","551df81a":"#Defining the preprocessing function\ndef preprocess(image):\n    #Converting to numpy array from numpy tensor with rank 3\n    image = np.array(image, dtype=np.uint8)\n    #Converting to RGB\n    #img = cv2.cvtCoor(img, cv2.COLOR_BGR2RGB)\n    #Gaussian Blur\n    gaussian_blur = cv2.GaussianBlur(image,(5,5),0)\n    img = np.asarray(gaussian_blur, dtype=np.float64)\n    return img","71823be1":"#Converting labels to string to use sparse class mode\ndf.label = df.label.astype('str')\n\n#Training  Augumentation\ndatagen = ImageDataGenerator(rescale=1.0\/255,\n                             featurewise_center=True,\n                             featurewise_std_normalization=True,\n                             rotation_range=30,\n                             width_shift_range=0.3,\n                             height_shift_range=0.3,\n                             shear_range=15.0,\n                             zoom_range=0.3,\n                             horizontal_flip=True,\n                             brightness_range=[0.5, 1.0],\n                             validation_split=0.2,\n                             fill_mode='nearest',\n                             preprocessing_function=preprocess)\n\n\ntrain_datagen = datagen.flow_from_dataframe(df,\n                                            directory = os.path.join(BASE_DIR, \"train_images\"),\n                                            subset = \"training\",\n                                            x_col = \"image_id\",\n                                            y_col = \"label\",\n                                            target_size = (TARGET_SIZE, TARGET_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"sparse\")\n\n#Validation\nvalidation_datagen = ImageDataGenerator(rescale=1.0\/255,\n                                        validation_split=0.2,\n                                       preprocessing_function=preprocess)\n\n\nvalid_datagen = validation_datagen.flow_from_dataframe(df,\n                                            directory = os.path.join(BASE_DIR, \"train_images\"),\n                                            subset = \"validation\",\n                                            x_col = \"image_id\",\n                                            y_col = \"label\",\n                                            target_size = (TARGET_SIZE, TARGET_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"sparse\")","17c17f46":"#He Uniform Initializer for Dense Layer\nimport tensorflow as tf\ndef my_init(shape, dtype=None):\n    initializer = tf.keras.initializers.he_uniform(seed = 1)\n    return initializer(shape, dtype=dtype)","ff19a54c":"base_model = Xception(weights = 'imagenet', include_top=False, input_shape = (TARGET_SIZE, TARGET_SIZE, 3), pooling=None)\n\nbase_output = base_model.output\npooling_layer = layers.GlobalAveragePooling2D()(base_output)\nDense1 = layers.Dense(128, activation = \"relu\", kernel_initializer=my_init)(pooling_layer)\nBN1 = layers.BatchNormalization()(Dense1)\ndropout = layers.Dropout(0.2)(BN1)\nmodel = layers.Dense(5, activation=\"softmax\")(dropout)\n\nmodel = models.Model(base_model.input, model)\n\nmodel.compile(optimizer = Adam(lr = 0.001), \n              loss = \"sparse_categorical_crossentropy\", \n              metrics=[\"acc\"])","c5babb83":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nfilepath = \"model.h5\"\n    \ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.2),\n             EarlyStopping(monitor='val_loss', patience=3),\n             ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]","38dc4527":"h = model.fit(train_datagen, epochs = EPOCHS, validation_data = valid_datagen, callbacks=callbacks)","f2d9e9a2":"plt.style.use(\"ggplot\")\nplt.figure()\nN = 12\nplt.plot(np.arange(0, N), h.history[\"acc\"], label=\"train_acc\")\nplt.plot(np.arange(0, N), h.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()","6adb8db4":"plt.style.use(\"ggplot\")\nplt.figure()\nN = 12\nplt.plot(np.arange(0, N), h.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, N), h.history[\"val_loss\"], label=\"val_loss\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()","3d3b1b00":"## Defining the Model","f5d7ffdc":"## Defining Hyper Parameters","54a52b1e":"## Augumentations along with Preprocessing","d13c6080":"## Distrubtion of classes","37be8163":"## Importing Libraries","6c4ed253":"## Visualization","842247d9":"## Plotting ","c33399ca":"### Remove the duplicate image according to discussions"}}