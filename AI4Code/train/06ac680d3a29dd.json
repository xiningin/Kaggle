{"cell_type":{"d8127e5e":"code","afe40c56":"code","fa291fb8":"code","ba90d0bb":"code","d70f58e8":"code","35a6bb6d":"code","201a7fdd":"code","064610e0":"code","2b85517d":"markdown"},"source":{"d8127e5e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","afe40c56":"#  read the data\nData1 = pd.read_csv(\"..\/input\/Sheet_1.csv\",usecols=['response_id','class','response_text'],encoding='latin-1')\nData2 = pd.read_csv(\"..\/input\/Sheet_2.csv\",encoding='latin-1')\nData1.head()\nSampls = Data1['response_text']","fa291fb8":"# Delet panctioation marks, numbers and short\nimport nltk\nAllWords=[]\nSentences = [ nltk.word_tokenize(s) for s in Sampls]\nfor i,words in enumerate(Sentences):\n    words=[word.lower() for word in words if word.isalpha()]\n    AllWords.append(words)\nflat_list = [item for sublist in AllWords for item in sublist]\n","ba90d0bb":"# tokenize create:\nfrom keras.preprocessing.text import Tokenizer\ntokenizer = Tokenizer(num_words=1000)\ntokenizer.fit_on_texts(flat_list)","d70f58e8":"# transform the data:\nfrom keras.preprocessing import sequence\nfrom keras.models import Sequential\nfrom keras.layers import Dense,SimpleRNN,Conv1D\nSeqData = tokenizer.texts_to_sequences(AllWords)\nMatData = tokenizer.texts_to_matrix(Sampls.tolist())\n\nAll_input = sequence.pad_sequences(SeqData,maxlen=100)\nAll_output = np.array([x==  'flagged' for x in Data1['class'].tolist()],dtype=int)\n","35a6bb6d":"# split into train and text\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split( All_input, All_output, test_size=0.13, random_state=42)","201a7fdd":"# create NN \nfrom keras.models import Sequential\nfrom keras.layers import Dense,Embedding,SimpleRNN,Dropout,LSTM\nmodel = Sequential()\nmodel.add(Embedding(1000,32))\nmodel.add(LSTM(32))\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(optimizer='rmsprop',loss='binary_crossentropy',metrics=['acc'])\nhistory = model.fit(X_train,y_train,epochs=10,batch_size=8)","064610e0":"# predict results\nPred = model.predict_classes(X_test)\nAccuracy = sum(Pred.flat == y_test)\/len(y_test)\nprint(Accuracy)","2b85517d":"This model load the data, tokenize the word and trasform for sequence, then build RNN, traqin and predict. Deu to small amount of data this net will be overfitted and will not predict accurate."}}