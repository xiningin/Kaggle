{"cell_type":{"965cdc2a":"code","746e97c1":"code","3d15e825":"code","12daa456":"code","7d5c2bc6":"code","cd0e234f":"code","16a7e46a":"code","10cd487f":"code","a6b594c8":"code","05dbe362":"code","49e802d0":"code","c60ab846":"code","06ec8b28":"code","6d26a7b1":"code","9537b0ea":"code","b62d6b50":"code","5511be14":"code","27a4df37":"code","a817e168":"markdown","c57e39cd":"markdown","872a6c99":"markdown","521cd7b6":"markdown","c5a72cff":"markdown","552e9307":"markdown","670a0d88":"markdown","e264766d":"markdown","a8276d04":"markdown","b969fa0b":"markdown","3d821d54":"markdown","e4707451":"markdown","29db752c":"markdown","aee73d8d":"markdown","dfd853c1":"markdown"},"source":{"965cdc2a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","746e97c1":"# word vectorizor\n# first converts the text into a matrix of word counts\n# then transforms these counts by normalizing them based on the term frequency\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\n# Multinomial Naive Bayes Classifier\nfrom sklearn.naive_bayes import MultinomialNB","3d15e825":"train_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntest_df = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")","12daa456":"train_df.groupby(\"target\")[\"id\"].nunique()","7d5c2bc6":"test_df.head()","cd0e234f":"X_train = train_df[\"text\"].copy()\nX_test = test_df[\"text\"].copy()\ny_train = train_df[\"target\"].copy()\n\ntxt_vectorizer = TfidfVectorizer()\nX_train_tf = txt_vectorizer.fit_transform(X_train)\n## note that we're NOT using .fit_transform() here. Using just .transform() makes sure\n# that the tokens in the train vectors are the only ones mapped to the test vectors - \n# i.e. that the train and test vectors use the same set of tokens.\nX_test_tf = txt_vectorizer.transform(X_test)\n\n# Fit a Naive Base classifier to the training set\nmultinominalNB_clf = MultinomialNB().fit(X_train_tf, y_train)\n\n# get predicted values\ntest_df.loc[:,\"target\"] = multinominalNB_clf.predict(X_test_tf)","16a7e46a":"predProbGivenText_df = pd.DataFrame(multinominalNB_clf.predict_proba(X_test_tf))","10cd487f":"uniq_keywords = train_df[\"keyword\"].unique()[1:]\nprint(len(uniq_keywords))\nprint(uniq_keywords)","a6b594c8":"def replace_keywords(df_og):\n    df = df_og.copy()\n    df[\"keyword\"] = df[\"keyword\"].replace(\"ablaze\",\"blaze\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"blazing\",\"blaze\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"annihilated\",\"annihilation\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"attacked\",\"attack\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"bioterror\",\"bioterrorism\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"blown%20up\",\"blew%20up\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"bloody\",\"blood\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"bleeding\",\"blood\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"body%20bags\",\"body%20bag\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"body%20bagging\",\"body%20bag\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"bombed\",\"bomb\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"bombing\",\"bomb\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"burning%20buildings\",\"buildings%20burning\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"buildings%20on%20fire\",\"buildings%20burning\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"burned\",\"burning\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"casualties\",\"casualty\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"catastrophe\",\"catastrophic\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"collapse\",\"collapsed\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"collide\",\"collision\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"collided\",\"collision\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"crash\",\"crashed\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"crush\",\"crushed\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"dead\",\"death\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"deaths\",\"death\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"deluge\",\"deluged\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"demolished\",\"demolish\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"demolition\",\"demolish\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"derailment\",\"derail\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"derailed\",\"derail\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"desolation\",\"desolate\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"destroyed\",\"destroy\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"destruction\",\"destroy\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"detonate\",\"detonation\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"devastated\",\"devastation\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"drowned\",\"drown\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"drowning\",\"drown\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"electrocute\",\"electrocuted\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"evacuated\",\"evacuate\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"evacuation\",\"evacuate\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"explode\",\"explosion\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"exploded\",\"explosion\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"fatality\",\"fatalities\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"floods\",\"flood\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"flooding\",\"flood\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"bush%20fires\",\"forest%20fire\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"forest%20fires\",\"forest%20fire\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"hailstorm\",\"hail\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"hazardous\",\"hazard\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"hijacking\",\"hijack\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"hijacker\",\"hijack\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"hostages\",\"hostage\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"injured\",\"injury\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"injures\",\"injury\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"inundated\",\"inundation\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"mass%20murderer\",\"mass%20murder\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"obliterated\",\"obliterate\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"obliteration\",\"obliterate\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"panicking\",\"panic\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"quarantined\",\"quarantine\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"rescuers\",\"rescue\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"rescued\",\"rescue\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"rioting\",\"riot\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"dust%20storm\",\"sandstorm\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"screamed\",\"screams\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"screaming\",\"screams\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"sirens\",\"siren\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"suicide%20bomb\",\"suicide%20bomber\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"suicide%20bombing\",\"suicide%20bomber\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"survived\",\"survive\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"survivors\",\"survive\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"terrorism\",\"terrorist\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"thunderstorm\",\"thunder\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"traumatised\",\"trauma\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"twister\",\"tornado\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"typhoon\",\"hurricane\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"weapons\",\"weapon\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"wild%20fires\",\"wildfire\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"wounded\",\"wounds\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"wrecked\",\"wreckage\")\n    df[\"keyword\"] = df[\"keyword\"].replace(\"wreck\",\"wreckage\")\n    return(df)","05dbe362":"train_df = replace_keywords(train_df)\ntest_df = replace_keywords(test_df)","49e802d0":"uniq_keywords = train_df[\"keyword\"].unique()[1:]\nkword_resArr = []\nprint(len(uniq_keywords))\nfor kword in uniq_keywords:\n    kword_df = train_df.loc[train_df[\"keyword\"] == kword,: ]\n    total_kword = float(len(kword_df))\n    target0_n = float(len(kword_df.loc[kword_df[\"target\"]==0,:]))\n    target1_n = float(len(kword_df.loc[kword_df[\"target\"]==1,:]))\n    kword_prob_df = pd.DataFrame({'keyword':[kword],\n                                 \"keywordPred0\": [target0_n\/total_kword],\n                                 \"keywordPred1\": [target1_n\/total_kword]})\n    kword_resArr.append(kword_prob_df)\npredProbGivenKeyWord_df= pd.concat(kword_resArr)\npredProbGivenKeyWord_df.head()","c60ab846":"get probabilities given the tweet text","06ec8b28":"test_df[\"textprob0\"]=predProbGivenText_df.loc[:,0].copy()\ntest_df[\"textprob1\"]=predProbGivenText_df.loc[:,1].copy()\ntest_df.head()","6d26a7b1":"test_df = test_df.merge(predProbGivenKeyWord_df, how='left', on=\"keyword\")","9537b0ea":"test_df[\"keywordPred0\"]=test_df[\"keywordPred0\"].fillna(0.5)\ntest_df[\"keywordPred1\"]=test_df[\"keywordPred1\"].fillna(0.5)","b62d6b50":"test_df[\"pred0\"]=test_df[\"textprob0\"]*test_df[\"keywordPred0\"]\ntest_df[\"pred1\"]=test_df[\"textprob1\"]*test_df[\"keywordPred1\"]\ntest_df[\"target\"]=test_df[\"pred1\"]>test_df[\"pred0\"]\ntest_df[\"target\"] = test_df[\"target\"].astype(np.int)","5511be14":"submission_df = test_df.loc[:,[\"id\",\"target\"]].copy()\nsubmission_df.head()","27a4df37":"submission_df.to_csv('submission.csv', index = False)","a817e168":"read in data to pandas dataframes","c57e39cd":"Create submission file","872a6c99":"count how many of each target is found in the training set ","521cd7b6":"Note that in the code above I only look at the tweets themselves and the keywords, but many of the tweets do not have keywords. We could maybe create a model to infer keywords from tweets that do not have keywords. We also did not include location in the model.","c5a72cff":"# Text: Multinominal Naive Bayes","552e9307":"This is amazing! Our training set has no null targets and our targets are fairly balanced as well!","670a0d88":"I noticed that there are some keywords that are very similar to each other so I decided to manually make them the same word.","e264766d":"Let's look at our unique key words.","a8276d04":"# Import Data","b969fa0b":"Now let's calculate the probability given the text and the keyword. Then let's choose our prediction based on which target has the higher probability.","3d821d54":"Using the updated set of keywords let's get the probability for each target given a specific key word.","e4707451":"# Background\nIn this competition we are a keyword(sometimes), location(sometimes), and text to represent a Tweet. Our goal is to predict whether the tweet is describing a real disaster (1) or not (0).\n\nIn this kernel I am only going to focus on the text and keyword features to predict a target. First, I must convert the text into vectors to use in my model. I will use a Naive Bayes classifiers to build my model.","29db752c":"get the probabilities given the key words. Note that if there is no key word than the probability is 50% for both targets.","aee73d8d":"# Keyword: Naive Bayes","dfd853c1":"# Create Submission File"}}