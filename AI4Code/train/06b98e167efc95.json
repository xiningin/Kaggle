{"cell_type":{"80b05a67":"code","18f9b4cc":"code","e50e11a5":"code","02cde433":"code","92207b7b":"code","7de83387":"code","5120f09b":"code","a8d68a5f":"code","fb3bae69":"code","f7cdb5a4":"code","ece5ce07":"code","2196fe22":"code","c2f297fa":"code","3e02ba52":"code","5825baaa":"code","b4da32ed":"code","57a5aed0":"code","a28877f9":"code","96f3c232":"code","ebd9022e":"code","0b0e69a3":"code","2dbad4b9":"code","490d6f7e":"code","08426ae7":"code","5b22f5d2":"code","47003ee1":"code","299d210a":"code","03bb2c3c":"markdown","04a1b66f":"markdown","0bbc3d4d":"markdown","bd69b21a":"markdown","199aa0f6":"markdown","8ec46be2":"markdown","d04de6a7":"markdown","004ccb7a":"markdown","cdd04b83":"markdown","39b60c3c":"markdown","e4948254":"markdown","14c7c129":"markdown","91174dc5":"markdown"},"source":{"80b05a67":"#Python 3 environment\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #import the graphing functions\nimport seaborn as sns #graphing functions\nfrom sklearn.model_selection import train_test_split #import split function\nfrom sklearn.ensemble import RandomForestClassifier #random forest classifier tool\nfrom sklearn import metrics #analysis tools\nfrom sklearn.metrics import confusion_matrix #confusion matrix\n\n\n    #\"as\" defines the functions so you dont have to write them out all the time \n\nimport os\nprint(os.listdir(\"..\/input\"))","18f9b4cc":"data = pd.read_csv(\"..\/input\/loan.csv\", low_memory = False) \n       #Load the data using pandas read csv function, low_memory is turned on by default and \n       #allows the file to be processed in chunks default","e50e11a5":"x = data[(data.loan_status == \"Fully Paid\") | (data.loan_status == \"Default\")] \n       #Only keep data for loans whose status is \"Fully Paid\" or \"Default","02cde433":"x[\"target\"] = (data.loan_status == \"Fully Paid\")\n       #Transform loans that are paid into a binary target variable \n       #also note that in Python3 True\/False are actually 0 and 1 so no need to transform","92207b7b":"#ANSWER\nprint(\"Remaining Observations: \", x.shape[0]) #print the first line of shape command (i.e. the number of rows)\nprint()\nprint(\"Remaining Features:     \", x.shape[1]) #print the second line of the shape command (i.e. the number of columns)","7de83387":"###############\n#ANALYSIS BACKUP\n\n#Original dataset\nprint(\"Original Data Rows and Columns            =\", data.shape)\n       #show the shape of the original dataset \n\n#New dataset which only has defaluted and repaid loans\nprint(\"Defaulted & Repaid Data: Rows and Columns =\", x.shape)\nprint()\n       #show the shape of the transformed dataset x then space\n    \nprint(\"Number of Loans Repaid:   \", len(x[x.loan_status == \"Fully Paid\"]))\nprint(\"Number of Loans Defaulted:\", len(x[x.loan_status ==\"Default\"]))\n       #show the number of repaid loans and the number of defaulted loans\n    \n       #We see that the transformation leads us to have a smaller set \n       #of observations and we have one addtional column \"target\"....\n       #Note that there are only 31 defaults in a dataset of over a \n       #million repaid loans!!!!-> CONCERN\n       #Probably not very useful for default prediction.\n       #To check that we didnt accedentially lose defaulted loans when removing \n       #current loans we can count the number of defaulted loans in the original dataset\n\nprint()\nprint(\"Number of Loans Defaulted Original Dataset:\", len(data[data.loan_status ==\"Default\"]))\n       #Show the number of defaulted loans in the entire dataset\n    \n       #We can see that in the entire dataset of 2.26m loans there are only 31 recorded defaults\n       #-> CONCERN","5120f09b":"#ANSWER\n\n#HISTOGRAM\nplt.hist(x[\"loan_amnt\"],bins = 100)\n      #plot histogram loan amounts across one hundred bins\nplt.title(\"Distribution of Loan Amounts\")\n      #name title\nplt.xlabel(\"Loan Amounts in $\")\n      #Label x axis\nplt.ylabel(\"Number #\")\n      #Label y axis\nplt.grid(axis=\"y\")\n      #add grid only to y axis (default would add to both axis)\n\n#Notice that the histogram shows that people apply \n#for round $ numbers for their loans i.e. 5k, 10k, 15k, 10k, 25k\n    \n    \n#SUMMARY STATISTICS\nprint(\"Mean =    $\", round(np.mean(x.loan_amnt),2))\n      #find the mean of loan amount (use print so that many outputs from one block of code)\nprint(\"Median =  $\", round(np.median(x.loan_amnt),2))\n      #find the median of loan amount\nprint(\"Maximum = $\", round(np.max(x.loan_amnt),2))\n      #find the maximum of loan amount\nprint(\"Std =     $\", round(np.std(x.loan_amnt),2))\n      #find the standard deviation of loan amount then add space","a8d68a5f":"#ANSWER\n\n#mean\nprint(\"Mean Interest Rate by Maturity (%):\")\nprint(round(x.groupby(by=\"term\").int_rate.mean(),2))\nprint()\n      #show the summary statistics of interest rate grouped by the loan maturities\n\n#standard deviation\nprint(\"Standard Deviation of Interest Rate by Maturity (%):\")\nprint(round(x.groupby(by=\"term\").int_rate.std(),2))\nprint()\n      #show the summary statistics of interest rate grouped by the loan maturities\n\n#boxplot \nbplot = sns.boxplot(x= x[\"term\"], y= data[\"int_rate\"], fliersize=0) \n    #define boxplot using seaborn, fliersize=0 turnsoff \n    #highlighting of outliers\nbplot.axes.set_title(\"Interest Rate by Maturity\", fontsize=16) #set title\nbplot.set_xlabel(\"Maturity\", fontsize=14) #set x axis label\nbplot.set_ylabel(\"Annual Interest Rate (%)\", fontsize=14) #set y axis label\nprint(bplot)","fb3bae69":"###############\n#ANALYSIS BACKUP\n\nprint(x.groupby(by=\"term\").int_rate.describe())\n      #show the summary statistics of interest rate grouped by the loan maturities","f7cdb5a4":"#ANSWER\n\n#Grade with highest interest rate\nprint(\"Debt Grade with Highest Average Interest Rate:  \",x.groupby(by=\"grade\").int_rate.mean().idxmax())\n\n#Average interest rate of grade G\nprint(\"Average Interest Rate for Grade G:              \", round(x[x.grade == \"G\"].int_rate.mean(),2),\"%\")","ece5ce07":"###############\n#ANALYSIS BACKUP\n\n#average interest rate by grade\nprint(\"Average Interest Rate by Grade (%)\",x.groupby(by=\"grade\").int_rate.mean())\nprint()\n     #check that grade G is actually the highest\n\n#box-plot by sub-grade (out of curiosity)\nx.boxplot(column=\"int_rate\",by=\"sub_grade\",showfliers=False, grid=False, rot=90) \n     #turn off outliers, gridlinse, rotate x-axis labels 90 degrees\n\n","2196fe22":"#ANSWER\n\nprint(\"Highest Realized Yield by Debt Grade (%):\")\nprint((x.groupby(\"grade\")[\"total_pymnt\"].sum() \/ x.groupby(\"grade\")[\"funded_amnt\"].sum()-1)*100)\n\n     #Highest realized yield is 32.5% in grade F","c2f297fa":"###############\n#ANALYSIS BACKUP\n\nprint(\"Defaulted Loans by Grade:\", x.groupby([\"grade\",\"loan_status\"]).size())\nprint()\n     #since there are so few defaulted loans almost meaningless to remove \n\nprint(\"Maximum Interest Rate (%) on Repaid Loans by Sub-Grade:\")\nprint(x[x.loan_status == \"Fully Paid\"].groupby(by=\"grade\").int_rate.max())\n     #only count loans that are repaid and then show maximum interest rate displayed by grade\n     #notice that the maximum interest rate for G is lower than the maximum realized yield \n     #suggesting that additional fees must have been charged","3e02ba52":"#ANSWER\nprint(\"Number of Applications by Type:\", x.groupby(\"application_type\").size())\n      #Shows the number of each type of application\n    \n#It seems to be very unevenly distributed. With a larger dataset and \n#outside of a LendingClub environment this may be an interesting feature \n#because joint applicants give you recourse to two people (which may reduce \n#the possibility of default) but also may reduce the loss-given-default.","5825baaa":"#ANSWER\n\nmodel_dataset = x.loc[:, [\"loan_amnt\",\"funded_amnt\",\"funded_amnt_inv\",\"term\",\"int_rate\",\"emp_length\",\"addr_state\",\"verification_status\",\"purpose\",\"policy_code\"]]\nprint(\"Model Dataset Shape:             \", model_dataset.shape)\n          #create new dataset with the suggested variables - same row number but 10 columns\n\nmodel_dataset2 = pd.get_dummies(data=model_dataset,columns=[\"addr_state\",\"term\",\"purpose\",\"verification_status\",\"policy_code\", \"emp_length\"])\n          #convert categorical data into dummies\n    \nfeature_list = list(model_dataset2.columns)\n          #saving list of features for later use\n\nprint(\"Dataset with Dummy Features Size:\", model_dataset2.shape)\n          #size of dataset with dummies. \n          #Note that the number of observations remails at 1,041,983\n          #The number of columns is now at 86 this compares to 10 in the \"model_dataset\" dataset\n          #This makes sense given that we have 6 dummy features with 81 unique entries\n          #10+81-6+1(because \"purpose\" only has one entry) = 86","b4da32ed":"###############\n#ANALYSIS BACKUP\n\n#see how many unique terms there are for the features\nprint(\"States:\", np.unique(x.addr_state))\nprint(\"  \")\n          #51 unique entries\nprint(\"Term:\", np.unique(x.term))\nprint(\"  \")\n          #2 unique entries\nprint(\"Purpose:\", np.unique(x.purpose))\nprint(\"  \")\n          #14 unique entries\nprint(\"Verification Status:\", np.unique(x.verification_status))\nprint(\"  \")\n          #3 unique entries\nprint(\"Policy Code:\", np.unique(x.policy_code))\nprint(\"  \")\n          #this entry is 1 in all cases\n          #employment length has 12 unique entries but does not print\n          #all other listed features are numerical","57a5aed0":"#ANSWER\n\ntrain_features, test_features, train_labels, test_labels = train_test_split(model_dataset2, x.target, test_size=0.67, train_size=0.33, random_state=42)\nprint(\"Training Features Shape:\",train_features.shape)\nprint(\"Testing Features Shape:\",test_features.shape)\nprint('Training Labels Shape:', train_labels.shape)\nprint('Testing Labels Shape:', test_labels.shape)\n        #split data using a training size of 33% (test_size corresponts) and random state 42\n        #notie the the lables (y) is taken from the original dataset \"x\" and the features comes from \"model_dataset2\"\n        #we need to set random_state otherwise everytime the program runs we will get a different training set\n        #print shape of training and test set.\n        #Notice that the feature test set has 698,129 rows which corresponds to 67% of 1,041,983.\n        ","a28877f9":"#ANSWER\n\n#train model\nrf = RandomForestClassifier(n_estimators = 100, max_depth = 4, random_state = 42)\n       #we use the classifier becasue we have a binary output (otherwise we would use the regressor)\nrf.fit(train_features,train_labels)\n       #fit the model","96f3c232":"predictions = rf.predict(test_features)\n      #save the predictions for the test sample\n      #note that the model rounds the estimated default probability to be either 0 or 1\n\n\n\nprint(\"Accuracy:\",round(metrics.accuracy_score(test_labels, predictions)*100,4),\"%\")\n       #accuracy of the predictions\n       #accuracy of 99.9968%\n       #the model is predicting that all applicants will repay and with such a low number of \n       #defaults we (only 22 defaults in an test sample of 698,129) a \"dumb\" approach \n       #of predicting that every single loan will be repaid yields an accuracy of 99.9968%\n       #(1 - 22\/698,129)","ebd9022e":"###############\n#ANALYSIS BACKUP\n\n#confirm that model is making \"dumb\" predictions\nprint(\"Types of Prediction:\", np.unique(predictions))\nprint()\n      #confirm that predictions are binary\n      #Notice that the model is only making \"True\" predictions. This \"dumb\" \n      #approach will result in an illusionary accuracy ratio. We will have \n      #a 100% accuracy for repaid loans and a 0% accuracy for defaulted loans. \n      #Because the sample us unbalanced this will mean a very high accuracy \n      #ratio overall...\n\n#see how many defaults there are in the test data\nprint(\"Number of Defaults in Test Data:\", (len(test_labels)-test_labels.sum()))\nprint()\n      #only 22 defaults\n        \n#Generate confusion matrix\ndef print_confusion_matrix(test_labels,predictions):\n    cm = confusion_matrix(test_labels,predictions)\n    print(\"Defaulting Applicant Rejected = \", cm[0][0])\n    print(\"Defaulting Applicant Approved = \", cm[0][1])\n    print(\"Paying Applicant Rejected =     \", cm[1][0])\n    print(\"Paying Applicant Approved =     \", cm[1][1])\n    #define the condusion matrix so that it prints output in easily interpretable way\n    #note that the print settings call predefined parts of the output 2x2 matrix (i.e. true positive is 0;0 i.e. top-left)\n    #to execute command print_confusion_matrix(test_default,predictions)\nprint_confusion_matrix(test_labels,predictions)\n\n    #another way to see that all defaulting loan applicants would be approved by this model\n    ","0b0e69a3":"predictions0 = np.ones(test_labels.shape)\n\nprint(\"Accuracy:\",round(metrics.accuracy_score(test_labels, predictions0)*100,4),\"%\")","2dbad4b9":"#ANSWER\n#I adjusted for this imbalance in two ways: \n#(1) the nature of LendingClub's business model is such that they have no interest to hold \n#on to, or enforce, non-performing loans, so as soon as a loan is more than 120 days past due \n#they sell the loan to debt collectors. The loan is then part of the \"charged-off\" category. \n#See https:\/\/help.lendingclub.com\/hc\/en-us\/articles\/216127897-What-happens-when-a-loan-is-charged-off- \n#for details. Therefore, I included the charged-off category and renamed it \"default\" because that \n#is what this category is in reality\n\n#(2) as a result of the above I had 261,686 defaults in a dataset of 1,303,638; to further account for \n#the imbalanced data I used \"class_weight = \"balanced\"\" in my random forest classifier to oversample from \n#the default group.","490d6f7e":"#Investigate and prepare data\nprint(\"Number by Status Types:\", data.groupby(\"loan_status\").size())\n       #shows the number of loans in each category\nx2 = data[(data.loan_status == \"Fully Paid\") | (data.loan_status == \"Default\") | (data.loan_status == \"Charged Off\")] \nprint()\n       #Only keep data for loans whose status is \"Fully Paid\" or \"Default\" or \"Charged Off\"\n       #Keep \"charged Off\" bacause they are merely defaulted loans that LendingClub has sold to \n       #debt collectors (see answer to question 11 for details).\n       #Also drop current or overdue loans to affect our predictions since a loan can turn into a\n       #default tomorrow or an overdue loan can be repaid (thereby biasing our model). \n       #I dropped the \"does not meet credit policy\" items because there are not many \n       #of them and there is no clear description from LendingClub on what these items are.\n    \nx2 = x2.replace(\"Charged Off\", \"Default\")\n       #replace \"charged off\" with \"default\" to account for the fact that they are the same thing\n\nprint(\"Observations by Status Types:\")\nprint(x2.groupby(\"loan_status\").size())\nprint()\n       #show shape of new dataset and the unique loan_status entries\n       #we see that the new number of defaults is 261,686 which equals 261,655 + 31\n        \nx2[\"target2\"] = (x2.loan_status == \"Fully Paid\")\n       #Transform loans that are paid into a binary target variable \n    \nprint(\"New Dataset Shape:                \",x2.shape)\nprint()\n       #check that the new target2 column has been added (146 vs 145)\n    \nmodel_data = x2.loc[:, [\"loan_amnt\",\"funded_amnt\",\"funded_amnt_inv\",\"term\",\"int_rate\",\"emp_length\",\"addr_state\",\"verification_status\",\"purpose\"]]\nprint(\"Model Dataset Shape:              \", model_data.shape)\nprint()\n          #create new dataset with the suggested variables (dropped \"policy code\" beacause it is always 1)\n\nmodel_data2 = pd.get_dummies(data=model_data,columns=[\"addr_state\",\"term\",\"verification_status\",\"purpose\", \"emp_length\"])\n          #convert categorical data into dummies\n    \nfeature_list2 = list(model_data2.columns)\n          #saving list of features for later use\n\nprint(\"Dataset with Dummy Features Shape:\", model_data2.shape)\n          #size of dataset with dummies. \n          #Note that the number of observations remails at 1,303,638\n          #The number of columns is now at 85 this compares to 9 in the \"model_data\" dataset\n          #This makes sense given that we have 6 dummy features with 81 unique entries\n          #9+81-5 = 85","08426ae7":"#Split data\ntrain_features2, test_features2, train_labels2, test_labels2 = train_test_split(model_data2, x2.target2, test_size=0.67, train_size=0.33, random_state=42)\nprint(\"Training Features Shape:\",train_features2.shape)\nprint(\"Testing Features Shape: \",test_features2.shape)\nprint(\"Training Labels Shape:  \", train_labels2.shape)\nprint(\"Testing Labels Shape:   \", test_labels2.shape)\n        #split data using a training size of 33% (test_size corresponts) and random state 42\n        #notie the the lables (y) is taken from the original dataset \"x2\" and the features comes from \"model_data2\"\n        #print shape of training and test set.\n        #Notice that the feature test set has 873,438 rows which corresponds to 67% of 1,303,638.\n        \nprint()\nprint(\"Repaid Loans in Test Set:\", test_labels2.sum())\n        #Note that there are 698,154 repaid loans in the test data.\n        #Therefore, a model would need to perform better than \n        #79.93% accuracy (1 - 698,154\/873,438) to beat a \"dumb\" approach","5b22f5d2":"train_features2, test_features2, train_labels2, test_labels2 = train_test_split(model_data2, x2.target2, test_size=0.67, train_size=0.33, random_state=42)\nprint(\"Training Features Shape:\",train_features2.shape)\nprint(\"Testing Features Shape: \",test_features2.shape)\nprint(\"Training Labels Shape:  \", train_labels2.shape)\nprint(\"Testing Labels Shape:   \", test_labels2.shape)\n        #split data using a training size of 33% (test_size corresponts) and random state 42\n        #notie the the lables (y) is taken from the original dataset \"x2\" and the features comes from \"model_data2\"\n        #print shape of training and test set.\n        #Notice that the feature test set has 873,438 rows which corresponds to 67% of 1,303,638.\n        \nprint()\nprint(\"Repaid Loans in Test Set:\", test_labels2.sum())\n        #Note that there are 698,154 repaid loans in the test data.\n        #Therefore, a model would need to perform better than \n        #79.93% accuracy (1 - 698,154\/873,438) to beat a \"dumb\" approach","47003ee1":"#Train model\nrf = RandomForestClassifier(n_estimators = 100, max_depth = 4, random_state = 42, class_weight = \"balanced\")\n       #classify ... To correct for the unbalanced data I weighted the sampling \n       #The \u201cbalanced\u201d mode uses the values of y to automatically adjust weights \n       #inversely proportional to class frequencies in the input data (default\/repaid)\n    \nrf.fit(train_features2,train_labels2)\n       #fit the model","299d210a":"#Model outputs\npredictions2 = rf.predict(test_features2)\n      #make predictions in the test sample\n      #note that the predictor takes the probability and rounds them to be either 0 or 1\n\nprint(\"Types of Prediction:\", np.unique(predictions2))\nprint()\n      #confirm that predictions are binary\n\nprint(\"Accuracy:\",round(metrics.accuracy_score(test_labels2, predictions2)*100,4),\"%\")\nprint()\n       #accuracy of 64.7681%\n       #Therfore, the model performs worse that guessing that all will repay\n        \n#show proportion of loans repaid in test data\nprint(\"Repaid Loans in Test Set %:    \", round((test_labels2.sum() \/ test_labels2.size)*100,4),\"%\")\nprint()\n       #Notice that the accuracy of the model is worse than the 79.93% of repaid \n       #loans in the test data. We would be better off projecting that all loans would be repaid\n\n#Generate confusion matrix\ndef print_confusion_matrix(test_labels2,predictions2):\n    cm = confusion_matrix(test_labels2,predictions2)\n    print(\"Defaulting Applicant Rejected = \", cm[0][0])\n    print(\"Defaulting Applicant Approved = \", cm[0][1])\n    print(\"Paying Applicant Rejected =     \", cm[1][0])\n    print(\"Paying Applicant Approved =     \", cm[1][1])\n\nprint(\"Confusion Matrix:\")\nprint_confusion_matrix(test_labels2,predictions2)","03bb2c3c":"\n**Q10:**                                                                                                                        \n**Now change your model so that you predict repayment for all applicants. What is the accuracy now?**","04a1b66f":"\n**Q6:**                                                                                                                        \n**Your boss suggests that you should use the feature application_type for your predictions                                       \na) How many records for each application type are there?                                                                       \nb) Does it make sense to use this feature?**","0bbc3d4d":"\n**Q9:**                                                                                                                        \n**Use a random forest to train a predictive model with \u2018target\u2019 as outcome variable. Use n_estimators=100, max_depth=4 as hyper parameters, and use test_size=0.33 for splitting. Remember to set the random_state=42 for both splitting and training.                              \nWhat out of sample accuracy do you achieve? **\n","bd69b21a":"\n**Q4:**                                                                                                                        \n**What is the average interest rate on the debt grade with the highest average interest rate?**","199aa0f6":"**IMPORT:**","8ec46be2":"\n**Q3:**                                                                                                                        \n**a.) What are mean and standard deviations of the interest rates of short and long term loans?                                  \nb.) Plot a box plot of interest rate by term.**","d04de6a7":"\n**UPLOAD DATA:**","004ccb7a":"\n**Q1:** **How many records are there left? How many features are there?**","cdd04b83":"\n**Q7:**                                                                                                                        \n**You ultimately settle on the features 'loan_amnt', 'funded_amnt', 'funded_amnt_inv', 'term','int_rate', 'emp_length', 'addr_state', 'verification_status', 'purpose', 'policy_code' as input variables for your predictive model. Convert the categorical variables into dummy variables using pandas get_dummies function, what is the total width of your feature set now?**","39b60c3c":"\n**Q5:**                                                                                                                        \n**What is the highest realized yield within any debt grade? (Do not worry about discounting and present value considerations here, assume all values are present values)**","e4948254":"\n**Q8:**                                                                                                                        \n**Use scikit learn\u2019s train_test_split function to split your data. If your training set size is 33%, what is the shape of your X_train? Set the random_state to 42.**","14c7c129":"\n**Q11:**                                                                                                                        \n**BONUS: The loan data is imbalanced as the bulk of loans does get repaid. Adjust your sampling strategy accordingly. **","91174dc5":"\n**Q2:**                                                                                                                        \n**a.) Plot the distribution of loan amounts (using a histogram)                                                                   \nb.) Compute the mean, median, maximum and standard deviation**"}}