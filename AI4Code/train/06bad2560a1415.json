{"cell_type":{"10b5265a":"code","94aad4d5":"code","04d6c2d5":"code","8ff8355d":"code","3c6a375c":"code","3e78fa3d":"code","0040c12a":"code","f45b16e7":"code","57a0121f":"code","2515051b":"code","db255ca4":"code","463dd41b":"code","594fcf23":"code","955e406f":"code","087c236b":"code","c010bd28":"code","7e3c591d":"code","1a967999":"code","00a1843d":"code","a975a6a2":"code","9e6a37ed":"code","fa626efd":"code","13031129":"code","82b0b0ae":"code","b88aeed0":"code","e438b960":"code","b23319eb":"code","8dbee5db":"code","379a3ddb":"code","b97b9da5":"code","3c71336d":"code","0f9e0f61":"code","594a854a":"code","ca2a07d7":"code","2519240d":"code","7f796a88":"code","2d32fd09":"code","f60e3891":"code","f4a5311b":"code","600c8e97":"code","029102b8":"code","b6f30e5d":"code","abe6d243":"code","9e0c61ef":"markdown","5d9f9266":"markdown","24ef2166":"markdown","cc6d30f8":"markdown","2931eca4":"markdown","5066fbed":"markdown","91d743d5":"markdown","d4d146b6":"markdown","4c2f8768":"markdown","915a7505":"markdown","d870faaa":"markdown","3b3d3d50":"markdown","f7d69e0e":"markdown","d9bbc201":"markdown","58f087a3":"markdown","078795da":"markdown","96c2d0e2":"markdown","4a8e1be9":"markdown","c078e84f":"markdown","87109855":"markdown","f96315dd":"markdown","6fcc7c73":"markdown","600f69f5":"markdown","ef12d360":"markdown","37a1aa1c":"markdown","38041a11":"markdown","a1aa797f":"markdown","ae610b22":"markdown","9f6795f9":"markdown","ecec343b":"markdown","f710b5a8":"markdown","a3fc9b2e":"markdown","e1d648db":"markdown","1783e012":"markdown","888d1ac7":"markdown","15903f1c":"markdown","12182ab8":"markdown","6003919b":"markdown","1cf727a7":"markdown","9a2b492a":"markdown","5d7217b8":"markdown","be4f465a":"markdown","e643dd54":"markdown","796733b1":"markdown"},"source":{"10b5265a":"# -*- coding: utf-8 -*-\nimport numpy as np \nimport pandas as pd \n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport seaborn as sns\ncolor = sns.color_palette()\nsns.set_style('whitegrid')\nimport warnings\nwarnings.filterwarnings('ignore')\npd.options.display.max_seq_items = 8000\npd.options.display.max_rows = 8000\n\n\nfrom scipy import stats\nfrom scipy.stats import norm, skew \nfrom scipy.special import boxcox1p\nfrom scipy.stats import boxcox_normmax\n\npd.set_option('display.float_format', lambda x: '{:.3f}'.format(x))# \u6240\u6709float\u4fdd\u75593\u4f4d\u6709\u6548\u6570\u5b57\n\nfrom subprocess import check_output\n#\u67e5\u770b\u5f53\u524d\u53ef\u7528\u7684\u6570\u636e\u76ee\u5f55\nprint(check_output([\"ls\", \"..\/input\"]).decode(\"utf8\")) \n#\u5bfc\u5165\u6570\u636e\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\nprint(\"success\")","94aad4d5":"train.head(3)\nprint(train.shape)","04d6c2d5":"test.head(3)\nprint(train.shape)","8ff8355d":"#\u6570\u636e\u672c\u6765\u5c31\u6709\u5217\u7d22\u5f15\uff0c\u56e0\u6b64\u53bb\u6389Id\u5217\ntrain_ID = train['Id']\ntest_ID = test['Id']\ntrain.drop(\"Id\", axis = 1, inplace = True)\ntest.drop(\"Id\", axis = 1, inplace = True)\nprint(\"\u53bb\u6389Id\u540e\u7684train: %s  \u53bb\u6389Id\u540e\u7684test: %s\" %(train.shape,test.shape))","3c6a375c":"#\u6570\u636e\u53ef\u89c6\u5316\u6709\u5229\u4e8e\u5f02\u5e38\u70b9\u7684\u68c0\u6d4b\nfig, ax = plt.subplots()\nax.scatter(x = train['GrLivArea'], y = train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","3e78fa3d":"#Deleting outliers\ntrain = train.drop(train[(train['GrLivArea']>4000) & (train['SalePrice']<300000)].index)\n\n#Check the graphic again\nfig, ax = plt.subplots()\nax.scatter(train['GrLivArea'], train['SalePrice'])\nplt.ylabel('SalePrice', fontsize=13)\nplt.xlabel('GrLivArea', fontsize=13)\nplt.show()","0040c12a":"#\u8981\u5bf9\u6574\u4f53\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u56e0\u6b64\u8981\u7ec4\u5408\u6570\u636e\u3002\nntrain = train.shape[0]\nntest = test.shape[0]\ny_train = train.SalePrice.values\nall_data = pd.concat((train, test)).reset_index(drop=True)\nall_data.drop(['SalePrice'], axis=1, inplace=True)\nprint(\"all_data size is : {}\".format(all_data.shape))\nall_data.head()","f45b16e7":"#\u7f3a\u5931\u503c\u68c0\u6d4b\nall_data_na = (all_data.isnull().sum() \/ len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)[:30]\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data","57a0121f":"plt.figure(figsize=(15,5))\nsns.heatmap(all_data.isnull(),cbar= False, yticklabels=False, cmap = \"cividis\")\nplt.title('Missing data by feature', fontsize=15)\nf, ax = plt.subplots(figsize=(15, 12))\nplt.xticks(rotation='90')\nsns.barplot(x=all_data_na.index, y=all_data_na)\nplt.xlabel('Features', fontsize=10)\nplt.ylabel('Percent of missing values', fontsize=10)\nplt.title('Percent missing data by feature', fontsize=15)","2515051b":"#\u4e22\u5f03  Utilities\u7684\u6240\u6709\u503c\u51e0\u4e4e\u6ca1\u6709\u53d8\uff0c\u56e0\u6b64\u4e22\u5f03\u3002\nall_data = all_data.drop(['PoolQC','MiscFeature','Alley','Fence','Utilities'], axis=1)\n#\u586b\u5145\uff1a\u6839\u636e\u5c5e\u6027\u503c\u7684\u60c5\u51b5\u8fdb\u884c\u586b\u5145\nall_data[\"FireplaceQu\"] = all_data[\"FireplaceQu\"].fillna(\"None\")\nall_data[\"LotFrontage\"] = all_data.groupby(\"Neighborhood\")[\"LotFrontage\"].transform(\n    lambda x: x.fillna(x.median()))# \u5747\u503c\u586b\u5145\nfor col in ('GarageType', 'GarageFinish', 'GarageQual', 'GarageCond'):\n    all_data[col] = all_data[col].fillna('None')\nfor col in ('GarageYrBlt', 'GarageArea', 'GarageCars'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF','TotalBsmtSF', 'BsmtFullBath', 'BsmtHalfBath'):\n    all_data[col] = all_data[col].fillna(0)\nfor col in ('BsmtQual', 'BsmtCond', 'BsmtExposure', 'BsmtFinType1', 'BsmtFinType2'):\n    all_data[col] = all_data[col].fillna('None')\nall_data[\"MasVnrType\"] = all_data[\"MasVnrType\"].fillna(\"None\")\nall_data[\"MasVnrArea\"] = all_data[\"MasVnrArea\"].fillna(0)\nall_data['MSZoning'] = all_data['MSZoning'].fillna(all_data['MSZoning'].mode()[0])#\u4f17\u6570\u586b\u5145\nall_data[\"Functional\"] = all_data[\"Functional\"].fillna(\"Typ\")\nall_data['Electrical'] = all_data['Electrical'].fillna(all_data['Electrical'].mode()[0])\nall_data['KitchenQual'] = all_data['KitchenQual'].fillna(all_data['KitchenQual'].mode()[0])\nall_data['Exterior1st'] = all_data['Exterior1st'].fillna(all_data['Exterior1st'].mode()[0])\nall_data['Exterior2nd'] = all_data['Exterior2nd'].fillna(all_data['Exterior2nd'].mode()[0])\nall_data['SaleType'] = all_data['SaleType'].fillna(all_data['SaleType'].mode()[0])\nall_data['MSSubClass'] = all_data['MSSubClass'].fillna(\"None\")\n","db255ca4":"#\u68c0\u67e5\u4e00\u4e0b\u73b0\u5728\u7684\u786e\u5b9e\u7387\nall_data_na = (all_data.isnull().sum() \/ len(all_data)) * 100\nall_data_na = all_data_na.drop(all_data_na[all_data_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :all_data_na})\nmissing_data.head()","463dd41b":"#\u5c06\u4e00\u4e0b\u6570\u636e\u8f6c\u4e3astring\u7c7b\u578b\n#MSSubClass\uff1a\u9500\u552e\u7684\u4f4f\u623f\u7c7b\u578b\nall_data['MSSubClass'] = all_data['MSSubClass'].apply(str)\n\n#OverallCond\uff1a\u623f\u5b50\u6574\u4f53\u72b6\u51b5\u8bc4\u4ef7\nall_data['OverallCond'] = all_data['OverallCond'].astype(str)\n\n#YrSold\uff0cMoSold\uff1a\u9500\u552e\u5e74\u4efd\u548c\u6708\u4efd\nall_data['YrSold'] = all_data['YrSold'].astype(str)\nall_data['MoSold'] = all_data['MoSold'].astype(str)","594fcf23":"# LabelEncoder\u7f16\u7801\nfrom sklearn.preprocessing import LabelEncoder\ncols = ('FireplaceQu', 'BsmtQual', 'BsmtCond', 'GarageQual', 'GarageCond', \n        'ExterQual', 'ExterCond','HeatingQC', 'KitchenQual', 'BsmtFinType1', \n        'BsmtFinType2', 'Functional', 'BsmtExposure', 'GarageFinish', 'LandSlope',\n        'LotShape', 'PavedDrive', 'Street', 'CentralAir', 'MSSubClass', 'OverallCond', \n        'YrSold', 'MoSold')\n\nfor c in cols:\n    lbl = LabelEncoder() \n    lbl.fit(list(all_data[c].values)) \n    all_data[c] = lbl.transform(list(all_data[c].values))\n       \nprint('Shape all_data: {}'.format(all_data.shape))\nall_data.head()\n","955e406f":"#Dummy\u7f16\u7801\nall_data = pd.get_dummies(all_data)\nprint(all_data.shape)\nall_data.head()","087c236b":"# \u589e\u52a0\u201cTotalSF\u201d\uff08\u603b\u4f4f\u623f\u9762\u79ef\uff09\u5c5e\u6027\nall_data['TotalSF'] = all_data['TotalBsmtSF'] + all_data['1stFlrSF'] + all_data['2ndFlrSF']","c010bd28":"# \u7279\u5f81\u53d8\u91cf\u7684\u6570\u636e\u5206\u5e03\n\nnumeric_dtypes = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\nnumeric = [] # \u6570\u503c\u578b\u5c5e\u6027\nfor i in all_data.columns:\n    if all_data[i].dtype in numeric_dtypes:\n        numeric.append(i)\nprint('\u6570\u503c\u578b\u5c5e\u6027\u5171\uff1a',len(numeric),'\u79cd')   \n\nsns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(9, 10))\nax.set_xscale(\"log\")\nax = sns.boxplot(data=all_data[numeric] , orient=\"h\", palette=\"Set1\")\nax.xaxis.grid(False)\nax.set(ylabel=\"Feature names\")\nax.set(xlabel=\"Numeric values\")\nax.set(title=\"Numeric Distribution of Features\")\nsns.despine(trim=True, left=True)","7e3c591d":"# \u627e\u5230\u90a3\u4e9b \u503e\u659c\u5ea6>0.5 \u7684\u7279\u5f81\nskew_features = all_data[numeric].apply(lambda x: skew(x)).sort_values(ascending=False)\n\nhigh_skew = skew_features[skew_features > 0.5]\nskew_index = high_skew.index\n\nprint(\"There are {} numerical features with Skew > 0.5 :\".format(high_skew.shape[0]))\nskewness = pd.DataFrame({'Skew' :high_skew})\nskew_features.head(10)","1a967999":"# boxcox1p\u51fd\u6570\u8fdb\u884c\u6570\u636e\u53d8\u6362\u4f7f\u5176\u670d\u4ece\u6b63\u6001\u5206\u5e03\nfor i in skew_index:\n    all_data[i] = boxcox1p(all_data[i], boxcox_normmax(all_data[i] + 1))","00a1843d":"#\u89c2\u5bdf\u53d8\u6362\u540e\u7684\u76d2\u56fe\nsns.set_style(\"white\")\nf, ax = plt.subplots(figsize=(9,10))\nax.set_xscale(\"log\")\nax = sns.boxplot(data=all_data[skew_index] , orient=\"h\", palette=\"Set1\")\nax.xaxis.grid(False)\nax.set(ylabel=\"Feature names\")\nax.set(xlabel=\"Numeric values\")\nax.set(title=\"Numeric Distribution of Features\")\nsns.despine(trim=True, left=True)","a975a6a2":"# \u76ee\u6807\u53d8\u91cf\u7684\u6570\u636e\u5206\u5e03\n\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\nsns.distplot(y_train, color=\"b\");\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice distribution\")\nsns.despine(trim=True, left=True)\nplt.show()\n\n#QQ-plot\nfig = plt.figure()\nres = stats.probplot(y_train, plot=plt)\nplt.show()","9e6a37ed":"# \u505alog(1+x) \u53d8\u6362\ny_train = np.log1p(y_train)\n\nsns.set_style(\"white\")\nsns.set_color_codes(palette='deep')\nf, ax = plt.subplots(figsize=(8, 7))\nsns.distplot(y_train , fit=norm, color=\"b\");\n\n#\u83b7\u53d6y_train\u7684\u5747\u503c\u548c\u65b9\u5dee\n(mu, sigma) = norm.fit(y_train)\nprint( '\\n mu = {:.2f} and sigma = {:.2f}\\n'.format(mu, sigma))\n\n\nplt.legend(['Normal dist. ($\\mu=$ {:.2f} and $\\sigma=$ {:.2f} )'.format(mu, sigma)],\n            loc='best')\nax.xaxis.grid(False)\nax.set(ylabel=\"Frequency\")\nax.set(xlabel=\"SalePrice\")\nax.set(title=\"SalePrice distribution\")\nsns.despine(trim=True, left=True)\n\nplt.show()\n\n#QQ-plot\nfig = plt.figure()\nres = stats.probplot(y_train, plot=plt)\nplt.show()","fa626efd":"#\u67e5\u770b\u73b0\u5728\u7684\u6570\u636e\u60c5\u51b5\nall_data.head(3)\nprint(all_data.shape)","13031129":"y_train","82b0b0ae":"from sklearn.model_selection import train_test_split\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom sklearn.metrics import mean_absolute_error\n\ndef lgb_mae(X,y):\n    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n    # Light Gradient Boosting Regressor\n    model = lgb.LGBMRegressor(objective='regression', \n                           num_leaves=6,\n                           learning_rate=0.01, \n                           n_estimators=7000,\n                           max_bin=200, \n                           bagging_fraction=0.8,\n                           bagging_freq=4, \n                           bagging_seed=8,\n                           feature_fraction=0.2,\n                           feature_fraction_seed=8,\n                           min_sum_hessian_in_leaf = 11,\n                           verbose=-1,\n                           random_state=42)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\ndef xgb_mae(X,y):\n    train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\n    # XGBoost Regressor\n    model = xgb.XGBRegressor(learning_rate=0.01,\n                           n_estimators=6000,\n                           max_depth=4,\n                           min_child_weight=0,\n                           gamma=0.6,\n                           subsample=0.7,\n                           colsample_bytree=0.7,\n                           objective='reg:linear',\n                           nthread=-1,\n                           scale_pos_weight=1,\n                           seed=27,\n                           reg_alpha=0.00006,\n                           random_state=42)\n    model.fit(train_X, train_y)\n    preds_val = model.predict(val_X)\n    mae = mean_absolute_error(val_y, preds_val)\n    return(mae)\n#maelist\u6709[lgb][xgb]\u4e24\u5217\u7528\u4e8e\u5b58\u50a8\u6a21\u578b\u7684mae\u503c\nmaelist=[]","b88aeed0":"#\u964d\u7ef4\u524d\nproper_lgb=lgb_mae(all_data[:1458],y_train)\nproper_xgb=xgb_mae(all_data[:1458],y_train)\nprint(\"lgb:%s xgb:%s\" %(proper_lgb,proper_xgb))\nmaelist.append([proper_lgb,proper_xgb])","e438b960":"from sklearn.decomposition import PCA\npca = PCA(0.99)\npca_dataset_X = pca.fit_transform(all_data) \nprint(\"\u4ece212\u7ef4\u964d\u81f3\uff1a\",pca.n_components_)\npd.DataFrame(pca_dataset_X).plot(title='PCA_dataset')","b23319eb":"pca_lgb=lgb_mae(pca_dataset_X[:1458],y_train)\npca_xgb=xgb_mae(pca_dataset_X[:1458],y_train)\nprint(\"lgb:%s xgp:%s\" %(pca_lgb,pca_xgb))\nmaelist.append([pca_lgb,pca_xgb])","8dbee5db":"#from sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n#lda = LinearDiscriminantAnalysis(0.99)\n#lda_dataset_X = lda.fit(x_train, y_train).transform(x_train)\n#pd.DataFrame(lda_dataset_X).plot(title='LDA_dataset')","379a3ddb":"from sklearn.decomposition import FactorAnalysis\nfa=FactorAnalysis(n_components=5)\nfa_dataset_X = fa.fit_transform(all_data)\npd.DataFrame(fa_dataset_X).plot(title='ICA_dataset')","b97b9da5":"fa_lgb=lgb_mae(fa_dataset_X[:1458],y_train)\nfa_xgb=xgb_mae(fa_dataset_X[:1458],y_train)\nprint(\"lgb:%s xgp:%s\" %(fa_lgb,fa_xgb))\nmaelist.append([fa_lgb,fa_xgb])","3c71336d":"from sklearn.decomposition import FastICA\nica = FastICA(n_components=5)\nica_dataset_X = ica.fit_transform(all_data)\npd.DataFrame(ica_dataset_X).plot(title='ICA_dataset')","0f9e0f61":"ica_lgb=lgb_mae(ica_dataset_X[:1458],y_train)\nica_xgb=xgb_mae(ica_dataset_X[:1458],y_train)\nprint(\"lgb:%s xgp:%s\" %(ica_lgb,ica_xgb))\nmaelist.append([ica_lgb,ica_xgb])","594a854a":"#\u65b9\u5dee\u9009\u62e9\u6cd5\uff0c\u8fd4\u56de\u503c\u4e3a\u7279\u5f81\u9009\u62e9\u540e\u7684\u6570\u636e\nfrom sklearn.feature_selection import VarianceThreshold\n#\u53c2\u6570threshold\u4e3a\u65b9\u5dee\u7684\u9608\u503c\nnew_data=VarianceThreshold(threshold=3).fit_transform(all_data)\nnew_data.shape","ca2a07d7":"f1_lgb=lgb_mae(new_data[:1458],y_train)\nf1_xgb=xgb_mae(new_data[:1458],y_train)\nprint(\"lgb:%s xgp:%s\" %(f1_lgb,f1_xgb))\nmaelist.append([f1_lgb,f1_xgb])","2519240d":"#SelectKBest\u51fd\u6570\nfrom sklearn.feature_selection import SelectKBest  \nfrom array import array\nfrom sklearn.feature_selection import f_regression\nskb_model=SelectKBest(f_regression)\nskb_model.fit_transform(all_data[:1458],y_train)\nnew_data.shape","7f796a88":"f2_lgb=lgb_mae(new_data[:1458],y_train)\nf2_xgb=xgb_mae(new_data[:1458],y_train)\nprint(\"lgb:%s xgp:%s\" %(f2_lgb,f2_xgb))\nmaelist.append([f2_lgb,f2_xgb])","2d32fd09":"# \u9012\u5f52\u7279\u5f81\u6d88\u9664\u6cd5\nfrom sklearn.feature_selection import RFE \n\n#\u9012\u5f52\u7279\u5f81\u6d88\u9664\u6cd5\uff0c\u8fd4\u56de\u7279\u5f81\u9009\u62e9\u540e\u7684\u6570\u636e \n#\u53c2\u6570estimator\u4e3a\u57fa\u6a21\u578b \n#\u53c2\u6570n_features_to_select\u4e3a\u9009\u62e9\u7684\u7279\u5f81\u4e2a\u6570 \n\ntrain_X, val_X, train_y, val_y = train_test_split(all_data[:1458],y_train, random_state = 0)\nmodel1=RFE(estimator=lgb.LGBMRegressor(), n_features_to_select=20)\nmodel1.fit(train_X, train_y)\npreds_val1 = model1.predict(val_X)\nmae1 = mean_absolute_error(val_y, preds_val1)\n\nmodel2=RFE(estimator= xgb.XGBRegressor(), n_features_to_select=20)\nmodel2.fit(train_X, train_y)\npreds_val2 = model2.predict(val_X)\nmae2 = mean_absolute_error(val_y, preds_val2)","f60e3891":"print(\"lgb:%s xgp:%s\" %(mae1,mae2))\nmaelist.append([mae1,mae2])","f4a5311b":"#\u57fa\u4e8e\u60e9\u7f5a\u9879\u7684\u7279\u5f81\u9009\u62e9\u6cd5\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.linear_model import LogisticRegression\n\n#\u5e26L1\u60e9\u7f5a\u9879\u7684\u7ebf\u6027\u56de\u5f52\u4f5c\u4e3a\u57fa\u6a21\u578b\u7684\u7279\u5f81\u9009\u62e9\none_model = lgb.LGBMRegressor(penalty=\"l1\",\n                              objective='regression', \n                           num_leaves=6,\n                           learning_rate=0.01, \n                           n_estimators=7000,\n                           max_bin=200, \n                           bagging_fraction=0.8,\n                           bagging_freq=4, \n                           bagging_seed=8,\n                           feature_fraction=0.2,\n                           feature_fraction_seed=8,\n                           min_sum_hessian_in_leaf = 11,\n                           verbose=-1,\n                           random_state=42)\none_model.fit(all_data[:1458], y_train)\nfe_model = SelectFromModel(one_model,prefit=True)\nX_new1 = fe_model.transform(all_data[:1458])\nprint(\"X_new1 \u5171\u6709 %s \u4e2a\u7279\u5f81\"%X_new1.shape[1])\n\ntwo_model = xgb.XGBRegressor( penalty=\"l1\",\n                         learning_rate=0.01,\n                           n_estimators=6000,\n                           max_depth=4,\n                           min_child_weight=0,\n                           gamma=0.6,\n                           subsample=0.7,\n                           colsample_bytree=0.7,\n                           objective='reg:linear',\n                           nthread=-1,\n                           scale_pos_weight=1,\n                           seed=27,\n                           reg_alpha=0.00006,\n                           random_state=42)\ntwo_model.fit(all_data[:1458],y_train)\nfe_model = SelectFromModel(two_model,prefit=True)\nX_new2 = fe_model.transform(all_data[:1458])\nprint(\"X_new2 \u5171\u6709 %s \u4e2a\u7279\u5f81\"%X_new2.shape[1])","600c8e97":"train_X, val_X, train_y, val_y = train_test_split(X_new1,y_train, random_state = 0)\nmodel1 = lgb.LGBMRegressor(objective='regression', \n                           num_leaves=6,\n                           learning_rate=0.01, \n                           n_estimators=7000,\n                           max_bin=200, \n                           bagging_fraction=0.8,\n                           bagging_freq=4, \n                           bagging_seed=8,\n                           feature_fraction=0.2,\n                           feature_fraction_seed=8,\n                           min_sum_hessian_in_leaf = 11,\n                           verbose=-1,\n                           random_state=42)\nmodel1.fit(train_X, train_y)\npreds_val1 = model1.predict(val_X)\nmae1 = mean_absolute_error(val_y, preds_val1)\n\ntrain_X, val_X, train_y, val_y = train_test_split(X_new2,y_train, random_state = 0)\nmodel2= xgb.XGBRegressor(learning_rate=0.01,\n                           n_estimators=6000,\n                           max_depth=4,\n                           min_child_weight=0,\n                           gamma=0.6,\n                           subsample=0.7,\n                           colsample_bytree=0.7,\n                           objective='reg:linear',\n                           nthread=-1,\n                           scale_pos_weight=1,\n                           seed=27,\n                           reg_alpha=0.00006,\n                           random_state=42)\nmodel2.fit(train_X, train_y)\npreds_val2 = model2.predict(val_X)\nmae2 = mean_absolute_error(val_y, preds_val2)\nprint(\"lgb:%s xgp:%s\" %(mae1,mae2))\nmaelist.append([mae1,mae2])","029102b8":"#\u57fa\u4e8e\u6811\u6a21\u578b\u7684\u7279\u5f81\u9009\u62e9\u6cd5\nfrom sklearn.feature_selection import SelectFromModel\nfrom sklearn.ensemble import RandomForestRegressor\ntrain_X, val_X, train_y, val_y = train_test_split(all_data[:1458],y_train, random_state = 0)\n\nmodel=RandomForestRegressor()\nmodel.fit(train_X, train_y)\npreds_val = model.predict(val_X)\nmae = mean_absolute_error(val_y, preds_val)\nprint('\u968f\u673a\u68ee\u6797\uff1a',mae)","b6f30e5d":"plt.figure(figsize=(17, 7)) \ntitle = ('all above features selection methods mae results')\nplt.title(title,fontsize=20)\nplt.ylabel('mae_score')\nplt.xticks([0,1,2,3,4,5,6,7,8,9],['proper','jw_PCA', 'jw_FA', 'jw_ICA', 'Filter_VT', 'Filter_F','Wrapper_RFE','Embedded_L1','Embedded_RF'])\nplt.grid(axis='y',color=\"grey\",linestyle='--',lw=0.5,alpha=0.5)\nplt.tick_params(axis='both',labelsize=14)\n\nimport seaborn as sns\nsns.despine(left=True,bottom=True)\nx=range(8)\ndata1=[x[0] for x in maelist]\ndata2=[x[1] for x in maelist]\n\nl1=plt.plot(x,data1)\nl2=plt.plot(x,data2)\n#\u968f\u673a\u68ee\u6797\u7684mae\u70b9\u5355\u72ec\u753b\nl3=plt.scatter(8,mae)\nplt.annotate(\"%s\" %round(mae,3),xy=(8,mae) , xytext=(-20, 10), textcoords='offset points')\nfor x,y1,y2 in zip(x,data1,data2):\n    plt.annotate(\"%s\" %round(y1,3),xy=(x,y1) , xytext=(-20, 10), textcoords='offset points')\n    plt.annotate(\"%s\" %round(y2,3),xy=(x,y2), xytext=(-20, 10), textcoords='offset points')\nplt.text(2,0.128,\"xgb\",fontdict={'size': 15, 'color':  'red'})\nplt.text(2,0.142,\"lgb\",fontdict={'size': 15, 'color':  'red'})\nplt.text(7,0.1,\"RandomForest\",fontdict={'size': 15, 'color':  'red'})\n\n","abe6d243":"#\u63d0\u4ea4\u6a21\u578b\nmodel = lgb.LGBMRegressor(objective='regression', \n                           num_leaves=6,\n                           learning_rate=0.01, \n                           n_estimators=7000,\n                           max_bin=200, \n                           bagging_fraction=0.8,\n                           bagging_freq=4, \n                           bagging_seed=8,\n                           feature_fraction=0.2,\n                           feature_fraction_seed=8,\n                           min_sum_hessian_in_leaf = 11,\n                           verbose=-1,\n                           random_state=42)\nmodel.fit(all_data[:1458],y_train)\npreds_val = model.predict(all_data[1458:2917])\noutput = pd.DataFrame({'Id': test_ID,\n                       'SalePrice': preds_val})\noutput.to_csv('submission.csv', index=False)\nprint(\"Your first model has finished!\")","9e0c61ef":"* \u7f3a\u5931\u503c\u5904\u7406","5d9f9266":"\u4ece\u4e0a\u56fe\u6211\u4eec\u53ef\u4ee5\u770b\u51fa\uff0c\u6a21\u578bLGBMRegressor\u5728proper\u548cL1\u5904\u7684mae\u662f\u6700\u4f4e\u7684\u3002\u800cL1\u6bd4proper\u7684mae\u4ec5\u4ec5\u4f4e\u4e860.001\uff0c\u5b83\u5374\u9700\u8981\u8017\u8d39\u5927\u91cf\u7684\u65f6\u95f4\u6210\u672c\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u5c06\u63d0\u4ea4proper\u6a21\u578b\u7684\u7ed3\u679c\uff01","24ef2166":"SalePrice\u7684\u6570\u636e\u7684\u5206\u5e03\u662f\u503e\u659c\u7684,\u6211\u4eec\u53ef\u4ee5\u5e94\u7528log(1+x)\u53d8\u6362\u6765\u4fee\u6b63\u503e\u659c\u3002","cc6d30f8":"\u53ef\u4ee5\u770b\u51fa\u6548\u679c\u8fd8\u4e0d\u9519\uff0c\u4f46\u662f\u82b1\u8d39\u7684\u65f6\u95f4\u6709\u70b9\u957f\uff01","2931eca4":"\u4ece\u4ee5\u4e0a\u5904\u7406\u6211\u4eec\u53ef\u4ee5\u770b\u51fa\uff0c\u67e5\u770b\u6570\u636e\u7684\u5206\u5e03\u540e\u6211\u4eec\u53ef\u4ee5\u5bf9\u5176\u8fdb\u884c\u6570\u636e\u53d8\u6362\u3001\u5f02\u5e38\u503c\u68c0\u6d4b\u3002","5066fbed":"\u53ef\u89c1\u4ece141\u7ef4\u964d\u5230\u4e8620\u7ef4","91d743d5":"\u8ba9\u6211\u4eec\u6765\u770b\u770b\u5404\u79cd\u7279\u5f81\u9009\u62e9\u65b9\u6cd5\u540e\u6a21\u578b\u7684\u53d8\u5316\u6548\u679c\u5427\uff01","d4d146b6":"* \u79bb\u6563\u5316\uff1a\u4e00\u4e9b\u8868\u793a\u7c7b\u522b\u7684\u6570\u503c\u578b\u6570\u636eor\u9002\u5408\u7528\u7c7b\u522b\u8868\u793a\u7684\u5c5e\u6027\u6211\u4eec\u5c06\u5176\u79bb\u6563\u5316\u3002\u5373\uff1a\u6570\u503c\u5c5e\u6027\u7684\u6982\u5ff5\u5206\u5c42","4c2f8768":"## \u5bfc\u5165\u5e93\u548c\u6570\u636e\u96c6","915a7505":"* \u6df1\u5ea6\u5b66\u4e60\uff1a\u6301\u7eed\u66f4\u65b0\u4e2d\uff01\n\u8bf7\u7ee7\u7eed\u5173\u6ce8\u6211\u7684Kernel\u5427\uff01","d870faaa":"# \u7279\u5f81\u5904\u7406\n1. \u7279\u5f81\u6e05\u6d17\n    * \u6570\u636e\u5f02\u5e38\u68c0\u6d4b\n    * \u6570\u636e\u91c7\u6837\n1. \u7279\u5f81\u9884\u5904\u7406\n    * \u7f3a\u5931\u503c\u5904\u7406\n    * \u89c4\u8303\u5316\n    * \u79bb\u6563\u5316\n    * \u6570\u636e\u7f16\u7801\n    * \u7279\u5f81\u6784\u9020    \n    * \u6570\u636e\u53d8\u6362\n1. \u7279\u5f81\u964d\u7ef4\n    * PCA\u4e3b\u6210\u5206\u5206\u6790\n    * LDA\u7ebf\u6027\u5224\u522b\u5206\u6790\n    * FA\u56e0\u5b50\u5206\u6790\n    * ICA\u72ec\u7acb\u4e3b\u6210\u5206\u5206\u6790\n1. \u7279\u5f81\u9009\u62e9\n    * Fileter \n    * Wrapper\n    * Embedded\n","3b3d3d50":"## Tips\uff1a\n\u5bf9\u4e8e\u6570\u636e\u7684\u63a2\u7d22\uff0c\u6211\u4eec\u53ef\u4ee5\u901a\u8fc7\u5408\u5e76train\u548ctest\u7684\u65b9\u5f0f\u6765\u5bf9\u6574\u4f53\u6570\u636e\u8fdb\u884c\u5904\u7406\uff0c\u4e5f\u53ef\u4ee5\u4ec5\u4ec5\u5bf9train\u8fdb\u884c\u5904\u7406\u3002\u8fd9\u53d6\u51b3\u4e8e\u4f60\u7684\u63a2\u7d22\u76ee\u7684\uff1a\u5982\u679c\u4f60\u8981\u63a2\u7d22\u7f3a\u5931\u503c\uff0c\u90a3\u4f60\u5c31\u9700\u8981\u5bf9\u6574\u4f53\u6570\u636e\u96c6\u8fdb\u884c\u5904\u7406\uff08test\u4e5f\u4f1a\u6709\u7f3a\u5931\u503c\uff0c\u5b83\u5c06\u5f71\u54cd\u6211\u4eec\u6700\u7ec8\u7684\u9884\u6d4b\u6548\u679c\uff09;\u5982\u679c\u4f60\u4ec5\u4ec5\u5173\u6ce8\u5bf9\u6a21\u578b\u7684\u5851\u9020\uff0c\u90a3\u4f60\u5c31\u53ef\u4ee5\u5c06\u6ce8\u610f\u529b\u96c6\u4e2d\u5728trian\u7684\u5904\u7406\u4e0a\uff0c\u6bd4\u5982\uff1a\u5f02\u5e38\u70b9\u68c0\u6d4b\u3002","f7d69e0e":"* Encoding:\u9488\u5bf9\u5206\u7c7b\u578b\u5c5e\u6027","d9bbc201":"## 2.\u7279\u5f81\u9884\u5904\u7406","58f087a3":"* \u6570\u636e\u91c7\u6837\uff1a\u5728\u6b64\u4e0d\u8ba8\u8bba\u6570\u636e\u91c7\u6837\uff0c\u56e0\u4e3a\u8fd9\u662f\u4e00\u4e2a\u56de\u5f52\u95ee\u9898\uff0c\u4e0d\u6d89\u53ca\u6b63\u8d1f\u6837\u672c\u7684\u6570\u91cf\u95ee\u9898\u3002","078795da":"* LDA:\u5206\u7c7b\u95ee\u9898\u65f6\u7528,\u8fd9\u91cc\u53ea\u5199\u4ee3\u7801\u4e0d\u8fd0\u884c","96c2d0e2":"* \u6570\u636e\u53d8\u6362: \u9488\u5bf9\u6570\u503c\u578b\u6570\u636e\uff0c\u5927\u591a\u6570ML\u6a21\u578b\u4e0d\u80fd\u5f88\u597d\u5730\u5904\u7406\u975e\u6b63\u6001\u5206\u5e03\u6570\u636e\uff0c\u56e0\u6b64\u9700\u8981\u8fdb\u884c\u6570\u636e\u5206\u5e03\u7684\u8c03\u6574\u3002","4a8e1be9":"* ICA","c078e84f":"* \u7279\u5f81\u6784\u9020\uff1a\u624b\u5de5\u6784\u9020\u4e00\u4e9b\u66f4\u6709\u4ef7\u503c\u7684\u7279\u5f81\u5427\uff01","87109855":"\u53ef\u4ee5\u770b\u51fa\uff0ctrain\u548ctest\u90fd\u670979\u4e2a\u7279\u5f81\u53d8\u91cf\uff0c\u800ctrain\u8fd8\u6709\u4e00\u4e2a\u76ee\u6807\u53d8\u91cfSalePrice\u3002","f96315dd":"* \u5f02\u5e38\u70b9\u68c0\u6d4b","6fcc7c73":"# **\u7279\u5f81\u5de5\u7a0b\u5b9e\u6218\u6559\u7a0b**\n\u672c\u7bc7\u6587\u7ae0\u4ee5Kaggle\u6bd4\u8d5b\u4e2d\u201c\u623f\u4ef7\u9884\u6d4b\u201d\u9879\u76ee\u4e3a\u57fa\u7840\uff0c\u5c06\u672c\u4eba\u7406\u89e3\u7ed3\u5408Kaggle\u3001csdn\u4e0a\u4f17\u591a\u7f51\u53cb\u7684\u4f18\u79c0\u4ee3\u7801\u548c\u89e3\u8bf4\uff0c\u603b\u7ed3\u51fa\u7684\u80fd\u591f\u5c06\u7279\u5f81\u5de5\u7a0b\u7684\u7406\u8bba\u77e5\u8bc6\u8fd0\u7528\u4e8e\u5b9e\u8df5\u7684\u6570\u636e\u5904\u7406\u6559\u7a0b\u3002\u5728\u5f00\u59cb\u6587\u7ae0\u4e4b\u524d\uff0c\u6211\u60f3\u5148\u5bf9\u5404\u4f4dKerneler\u8868\u793a\u7531\u8877\u7684\u611f\u8c22\uff01\u6ca1\u6709\u4ed6\u4eec\u4f18\u79c0\u5185\u6838\u7684\u5f15\u5bfc\uff0c\u6211\u5c06\u5728\u7eb7\u7e41\u590d\u6742\u7684\u6570\u636e\u4e2d\u5bf8\u6b65\u96be\u884c\uff0c\u4e5f\u66f4\u4e0d\u4f1a\u50cf\u73b0\u5728\u8fd9\u822c\u4eab\u53d7\u63a2\u7d22\u6570\u636e\u7684\u7f8e\u611f\u3002\u5e9f\u8bdd\u4e0d\u591a\u8bf4\uff0c\u76f4\u63a5\u8fdb\u5165\u4e3b\u9898\uff1a\u7279\u5f81\u5de5\u7a0b\u5b9e\u6218\u6559\u7a0b\u3002\u7531\u4e8eKaggle\u6bd4\u8d5b\u4e2d\u4f1a\u7ed9\u6211\u4eec\u5b9e\u9645\u7684\u6570\u636e\u96c6\uff0c\u56e0\u6b64\u7279\u5f81\u5de5\u7a0b\u4e2d\u7684\u7279\u5f81\u4f7f\u7528\u3001\u7279\u5f81\u83b7\u53d6\u90e8\u5206\u5728\u6b64\u6211\u4eec\u5c06\u6682\u65f6\u4e0d\u9700\u8003\u8651\uff0c\u53ef\u4ee5\u76f4\u63a5\u8fdb\u5165\u7279\u5f81\u5904\u7406\u9636\u6bb5\uff01\n\n\u53c2\u8003Kernel\uff1a\n\n[https:\/\/www.kaggle.com\/serigne\/stacked-regressions-top-4-on-leaderboard](http:\/\/)\n\n[https:\/\/www.kaggle.com\/pmarcelino\/comprehensive-data-exploration-with-python](http:\/\/)\n\n[https:\/\/www.kaggle.com\/piyras23\/an-approach-with-statistical-learning-regress](http:\/\/)","600f69f5":"\u7f3a\u5931\u503c\u5904\u7406\u5b8c\u6bd5\uff01","ef12d360":"\u901a\u8fc7mae\u503c\u7684\u5bf9\u6bd4\u4f60\u5c06\u4f1a\u53d1\u73b0\uff0c\u964d\u7ef4\u524d\u7684mae\u66f4\u597d\u4e00\u4e9b\u3002\u5f53\u7136\u6211\u4eec\u6ca1\u6709\u5bf9\u964d\u7ef4\u7b97\u6cd5\u8fdb\u884c\u8c03\u53c2\uff0c\u4f60\u6709\u5174\u8da3\u53ef\u4ee5\u81ea\u5df1\u8c03\u4e00\u4e0b\uff0c\u4e5f\u8bb8\u80fd\u591f\u5f97\u5230\u6bd4\u8f83\u597d\u7684\u6548\u679c\uff01","37a1aa1c":"\u5728\u6b63\u5f0f\u5f00\u59cb\u5904\u7406\u6570\u636e\u4e4b\u524d\uff0c\u6211\u4eec\u9700\u8981\u505a\u4e00\u4e9b\u51c6\u5907\u5de5\u4f5c\uff01","38041a11":"> **SelectKBest**\u662fsklearn\u5e93\u4e2d\u7684\u4e00\u79cd\u7279\u5f81\u5b50\u96c6\u9009\u62e9\u7684\u51fd\u6570\uff0c\u53ef\u4ee5\u901a\u8fc7\u6539\u53d8\u5b83\u7684\u53c2\u6570\u6765\u6539\u53d8\u5212\u5206\u81ea\u5df1\u7684\u7b56\u7565\u3002\n> \u9009\u62e9K\u4e2a\u6700\u597d\u7684\u7279\u5f81\uff0c\u8fd4\u56de\u9009\u62e9\u7279\u5f81\u540e\u7684\u6570\u636e\n> \u7b2c\u4e00\u4e2a\u53c2\u6570\u4e3a\u8ba1\u7b97\u8bc4\u4f30\u7279\u5f81\u662f\u5426\u597d\u7684\u51fd\u6570\uff0c\u8be5\u51fd\u6570\u8f93\u5165\u7279\u5f81\u77e9\u9635\u548c\u76ee\u6807\u5411\u91cf\uff0c\u8f93\u51fa\u4e8c\u5143\u7ec4\uff08\u8bc4\u5206\uff0cP\u503c\uff09\u7684\u6570\u7ec4\uff0c\u6570\u7ec4\u7b2ci\u9879\u4e3a\u7b2ci\u4e2a\u7279\u5f81\u7684\u8bc4\u5206\u548cP\u503c\u3002\n> \u53c2\u6570k\u4e3a\u9009\u62e9\u7684\u7279\u5f81\u4e2a\u6570\n> \u7b2c\u4e00\u4e2a\u53c2\u6570\uff1a\t*score_func*\n> \u53ef\u586b\u9009\u9879\uff1a(\u6216\u81ea\u5df1\u6784\u9020)\n> * f_classif\uff1a\u5206\u7c7b\u4efb\u52a1\u7684\u6807\u7b7e\/\u7279\u5f81\u4e4b\u95f4\u7684\u65b9\u5dee\u5206\u6790f\u503c\u3002\n> * mutual_info_classif\uff1a\u79bb\u6563\u76ee\u6807\u7684\u4e92\u4fe1\u606f\u3002\n> * chi2\uff1a\u5206\u7c7b\u4efb\u52a1\u7684\u975e\u8d1f\u7279\u5f81\u5361\u65b9\u7edf\u8ba1\u3002\n> * f_regression\uff1a\u7528\u4e8e\u56de\u5f52\u4efb\u52a1\u7684\u6807\u7b7e\/\u7279\u6027\u4e4b\u95f4\u7684f\u503c\n> * mutual_info_regression\uff1a\u8fde\u7eed\u76ee\u6807\u7684\u76f8\u4e92\u4fe1\u606f\u3002\n> * SelectPercentile\uff1a\u6839\u636e\u6700\u9ad8\u5206\u7684\u767e\u5206\u4f4d\u6570\u9009\u62e9\u7279\u5f81\n> * SelectFpr\uff1a\u6839\u636e\u5047\u9633\u6027\u7387\u6d4b\u8bd5\u9009\u62e9\u7279\u5f81\u3002\n> * SelectFdr\uff1a\u6839\u636e\u4f30\u8ba1\u7684\u9519\u8bef\u53d1\u73b0\u7387\u9009\u62e9\u7279\u6027\n> * SelectFwe\uff1a\u6839\u636eFWER\u9009\u62e9\u7279\u5f81\n> * GenericUnivariateSelect\uff1a\u5177\u6709\u53ef\u914d\u7f6e\u6a21\u5f0f\u7684\u5355\u53d8\u91cf\u7279\u6027\u9009\u62e9\u5668\u3002","a1aa797f":"\u89c2\u5bdf\u76d2\u56fe\u53d1\u73b0\uff0c\u53d8\u91cf\u7684\u6570\u636e\u5206\u5e03\u5341\u5206\u51cc\u4e71\uff0c\u6709\u5f88\u591a\u53d8\u91cf\u7684\u5206\u5e03\u90fd\u662f\u503e\u659c\u7684\uff08\u975e\u6b63\u6001\u5206\u5e03\uff09\u3002\u8ba9\u6211\u4eec\u4e00\u8d77\u6574\u7406\u4e00\u4e0b\u6570\u636e\u7684\u5206\u5e03\u5427\uff01","ae610b22":"## 4.\u7279\u5f81\u5b50\u96c6\u7684\u9009\u62e9","9f6795f9":"**Pointing:**\n1. \u4ee5\u4e0a\u5185\u5bb9\u662f\u56de\u5f52\u95ee\u9898\u7684\u89e3\u51b3\u65b9\u6cd5\uff0c\u800c\u5206\u7c7b\u4e0e\u4e4b\u4e0d\u540c\u4f46\u6d41\u7a0b\u76f8\u4f3c\uff0c\u9700\u8981\u8bfb\u8005\u81ea\u5df1\u53bb\u63a2\u7d22\u3002\n1. \u672c\u6587\u63d0\u4f9b\u4e86\u6709\u5173\u7279\u5f81\u5de5\u7a0b\u65b9\u9762\u7684\u8bb8\u591a\u65b9\u6cd5\uff0c\u5927\u5bb6\u4e0d\u9700\u8981\u5168\u90e8\u90fd\u7528\uff0c\u9009\u62e9\u51e0\u79cd\u4f60\u559c\u6b22\u7684\u65b9\u6cd5\u5c31\u597d\u3002\n1. \u7279\u5f81\u9009\u62e9\u662f\u4e00\u4e2a\u8fed\u4ee3\u7684\u8fc7\u7a0b\uff0c\u9700\u8981\u6211\u4eec\u4e0d\u65ad\u7684\u5c1d\u8bd5\uff0c\u7136\u540e\u9a8c\u8bc1\uff0c\u518d\u5c1d\u8bd5\uff0c\u518d\u9a8c\u8bc1\u2026\u2026\n\n**\u672c\u6587\u6301\u7eed\u66f4\u65b0\u4e2d\uff0c\u559c\u6b22\u7684\u8bdd\u4e0d\u8981\u5fd8\u4e86vote\u54e6\uff01**","ecec343b":"## 3.\u6570\u636e\u964d\u7ef4","f710b5a8":"## \u89c2\u5bdf\u6570\u636e\n### Tips\uff1a\n1. \u8bf7\u5728\u770b\u672c\u6587\u524d\uff0c\u5148\u770b\u4e00\u4e0b\u6587\u6863\u4e2d\u5c5e\u6027\u8bf4\u660e\u4e66\uff0c\u5426\u5219\u60a8\u5c06\u4e0d\u80fd\u771f\u6b63\u7406\u89e3\u4ee5\u4e0b\u64cd\u4f5c\u3002\n1. \u5728\u5bf9\u6bcf\u4e00\u4e2a\u5c5e\u6027\u8fdb\u884c\u64cd\u4f5c\u524d\uff0c\u90fd\u8981\u5148\u7b80\u5355\u6d4f\u89c8\u4e00\u4e0b\u8fd9\u4e2a\u5c5e\u6027\u7684\u53d6\u503c\u60c5\u51b5\u3002\n1. \u4e86\u89e3\u5c5e\u6027\u7684\u771f\u6b63\u542b\u4e49\u548c\u5c5e\u6027\u7684\u53d6\u503c\u60c5\u51b5\u540e\uff0c\u4f60\u624d\u80fd\u5bf9\u6570\u636e\u505a\u51fa\u6b63\u786e\u7684\u64cd\u4f5c\u3002","a3fc9b2e":"* Wrapper\uff1aFilter\u65b9\u6cd5\u4ece\u539f\u59cb\u7279\u5f81\u4e2d\u9009\u62e9\u7279\u5f81\u5b50\u96c6\uff0c\u7528\u4e8e\u540e\u7eed\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u3002\u7531\u4e8eFilter\u5728\u7279\u5f81\u9009\u62e9\u65f6\uff0c\u6ca1\u6709\u8003\u8651\u5230\u6240\u7528\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\u6a21\u578b\uff0c\u53ef\u80fd\u4f1a\u5bfc\u81f4\u9009\u62e9\u51fa\u7684\u7279\u5f81\u5b50\u96c6\u4e0d\u9002\u5408\u540e\u7eed\u7684\u5b66\u4e60\u7b97\u6cd5\u4ece\u800c\u5f71\u54cd\u6027\u80fd\uff08\u8fd9\u91cc\u6307\u51c6\u786e\u7387\uff09\u3002\u56e0\u6b64\uff0cwrapper\u65b9\u6cd5\u7ed3\u5408\u540e\u7eed\u7684\u673a\u5668\u5b66\u4e60\u7b97\u6cd5\uff0c\u9009\u62e9\u51fa\u80fd\u4f7f\u6700\u7ec8\u7684\u7b97\u6cd5\u8fbe\u5230\u8f83\u9ad8\u6027\u80fd\u7684\u7279\u5f81\u5b50\u96c6\u3002","e1d648db":"\u6211\u4eec\u73b0\u5728\u7684\u6570\u636e\u7ef4\u5ea6\u4e3a212\u7ef4\uff0c\u800c\u6837\u672c\u6570\u8981\u8fdc\u8fdc\u5927\u4e8e\u8fd9\u4e2a\u6570\u503c\uff0c\u56e0\u6b64\u6211\u4eec\u8fd8\u6ca1\u4e0e\u9762\u4e34\u592a\u4e25\u91cd\u7684\u6570\u636e\u7ef4\u5ea6\u707e\u96be\u3002\u56e0\u6b64\uff0c\u6211\u4eec\u53ef\u4ee5\u964d\u7ef4\uff0c\u4e5f\u53ef\u4ee5\u4e0d\u964d\u7ef4\u3002\u5728\u6b64\uff0c\u6211\u60f3\u5148\u6784\u9020\u597d\u8981\u8bad\u7ec3\u7684\u6a21\u578b\uff0c\u5c06\u5176\u5c01\u88c5\u6210\u51fd\u6570\uff0c\u540e\u9762\u6211\u4eec\u6d4b\u8bd5\u6570\u636e\u964d\u7ef4\u548c\u7279\u5f81\u5b50\u96c6\u9009\u62e9\u7684\u6548\u679c\u65f6\uff0c\u5c31\u80fd\u5f88\u65b9\u4fbf\u7684\u8c03\u7528\u4e86\u3002\u6a21\u578b\u91c7\u7528Kaggle\u6bd4\u8d5b\u4e2d\u5e38\u7528\u7684\u7b80\u5355\u7684\u4e5f\u662f\u7ed3\u679c\u6bd4\u8f83\u597d\u7684\u4e24\u79cd\u6a21\u578b\uff1a Light Gradient Boosting Regressor\u548cXGBoost Regressor\u3002","1783e012":"* \u89c4\u8303\u5316\uff1a\u5728\u6b64\u4e0d\u5355\u72ec\u505a\u89c4\u8303\u5316\u64cd\u4f5c\uff0c\u5b83\u5c06\u7ed3\u5408\u540e\u9762\u7684\u65b9\u6cd5\u6765\u4e00\u8d77\u4f7f\u7528\uff0c\u4f8b\u5982\uff1aPCA\u3002","888d1ac7":"\u5bf9\u4e8e\u7f3a\u5931\u7387\u8d85\u8fc750%\u7684\u6570\u636e\u76f4\u63a5\u4e22\u5f03\uff0c\u5bf9\u5176\u4ed6\u6570\u636e\u8fdb\u884c\u586b\u5145\u3002","15903f1c":"* Filter","12182ab8":"\u8fd9\u6837\u5c31\u53bb\u9664\u597d\u4e86\uff0c\u800c\u5728\u6570\u636e\u96c6\u4e2d\u53ef\u80fd\u8fd8\u6709\u5f88\u591a\u5176\u4ed6\u5f02\u5e38\u70b9\uff0c\u4f46\u662f\u4f60\u6ca1\u6709\u5fc5\u8981\u628a\u6240\u6709\u7684\u5f02\u5e38\u70b9\u90fd\u53bb\u9664\uff0c\u56e0\u4e3a\u5f02\u5e38\u70b9\u53ef\u4ee5\u4f7f\u4f60\u7684\u6a21\u578b\u66f4\u5177\u5065\u58ee\u6027\uff0c\u6240\u4ee5\u5728\u6b64\u6211\u4eec\u5c31\u4ec5\u4ec5\u505a\u4e86\u4ee5\u4e0a\u64cd\u4f5c\u3002","6003919b":"* PCA","1cf727a7":"\u73b0\u5728\u5927\u591a\u6570\u7684\u76d2\u56fe\u770b\u8d77\u6765\u66f4\u50cf\u662f\u670d\u4ece\u6b63\u6001\u5206\u5e03\u4e86\u3002","9a2b492a":"## 1. \u7279\u5f81\u6e05\u6d17","5d7217b8":"* Embedded","be4f465a":"\u53ef\u89c1\uff0c\u56fe\u4e2d\u7684\u53f3\u4e0b\u65b9\u6709\u4e24\u4e2a\u70b9\uff1a\u4ee3\u8868\u623f\u5b50\u9762\u79ef\u5f88\u5927\u4f46\u662f\u4ef7\u683c\u5374\u5f88\u4fbf\u5b9c\uff0c\u5728\u65e5\u5e38\u751f\u6d3b\u4e2d\u8fd9\u663e\u7136\u662f\u975e\u5e38\u5f02\u5e38\u7684\u6570\u636e\uff0c\u6211\u4eec\u8981\u5c06\u5176\u53bb\u9664\u3002","e643dd54":"* FA","796733b1":"\u56fe1\u4e2d\u9ec4\u8272\u7686\u4e3a\u7f3a\u5931\u503c\uff0c\u56fe2\u6309\u7f3a\u5931\u7387\u6392\u5e8f"}}