{"cell_type":{"261e3d98":"code","8473d5d1":"code","faf7c7ca":"code","709a68ab":"code","2521a41b":"code","06e3cba4":"code","d2147d7f":"code","ce88a2e9":"code","e72fa5da":"code","a394805f":"markdown","af21f08c":"markdown","bf130c6d":"markdown","36241035":"markdown","156b3e1b":"markdown","e622585b":"markdown","0e8f6928":"markdown"},"source":{"261e3d98":"# This is the demo to illustrate unsupervised pretraining and its significance ","8473d5d1":"%env KERAS_BACKEND=theano\n%reset\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n \nimport keras\nimport keras.backend as K\nfrom keras.layers import Input, Convolution2D, Activation, MaxPooling2D, \\\n     Dense, BatchNormalization, Dropout\nfrom keras.layers.core import Flatten\nimport tensorflow as tf\ntf.keras.optimizers.SGD(\n    learning_rate=0.01, momentum=0.9, nesterov=False, name=\"SGD\")\nfrom tensorflow.keras.layers import (Input, Convolution2D, Activation, MaxPooling2D, \\\n     Dense, BatchNormalization, Dropout)\nfrom keras.models import Model\nfrom keras.utils import np_utils\nfrom keras.constraints import maxnorm\nfrom keras.regularizers import l2\nfrom keras.callbacks import LearningRateScheduler\n#from keras.layers.normalization import BatchNormalization\n\nprint(keras.__version__)\n\nfrom subprocess import check_output\nprint(check_output([\"ls\", \"..\/input\/digit-recognizer\"]).decode(\"utf8\"))","faf7c7ca":"N_train = 30000 # Out of 42000, to reduce processing time\ntrain = np.genfromtxt('..\/input\/digit-recognizer\/train.csv', delimiter = ',', skip_header = 1)\ntraining_inputs = train[0:N_train, 1:] \/ 255.0\ntraining_targets = np_utils.to_categorical(train[:, int(0)])[0:N_train]\n\nval_inputs = train[(N_train+1):42000, 1:] \/ 255.0\nval_targets = np_utils.to_categorical(train[:, int(0)])[(N_train+1):42000]\n\n# For 2D data (e.g. image), ordering type \"tf\" assumes (rows, cols, channels)\n#  type \"th\" assumes (channels, rows, cols). See https:\/\/keras.io\/backend\/\nprint('We are using image ordering type', K.image_data_format())\n\ntraining_inputs = training_inputs.reshape(training_inputs.shape[0], 784)\nprint(training_inputs.shape)\nprint(val_inputs.shape)\n","709a68ab":"# Layer by layer pretraining Models\n\n# Layer 1\ninput_img = Input(shape = (784, ))\ndistorted_input1 = Dropout(.1)(input_img)\nencoded1 = Dense(800, activation = 'sigmoid')(distorted_input1)\nencoded1_bn = BatchNormalization()(encoded1)\ndecoded1 = Dense(784, activation = 'sigmoid')(encoded1_bn)\n\nautoencoder1 = Model( input_img,  decoded1)\nencoder1 = Model( input_img, encoded1_bn)\n# autoencoder1 represent the AE with only one layer in each of the encoder and decoder. \n# The one layer here is the first layer of encoder in two layered AE and its corresponding\n# layer in decoder.\n\n\n# Layer 2\nencoded1_input = Input(shape = (800,))\ndistorted_input2 = Dropout(.2)(encoded1_input)\nencoded2 = Dense(400, activation = 'sigmoid')(distorted_input2)\nencoded2_bn = BatchNormalization()(encoded2)\ndecoded2 = Dense(800, activation = 'sigmoid')(encoded2_bn)\n\nautoencoder2 = Model(encoded1_input, decoded2)\nencoder2 = Model( encoded1_input, encoded2_bn)\n# autoencoder2 represent the AE with only one layer in each of the encoder and decoder. \n# The one layer here is the second layer of encoder in two layered AE and its corresponding\n# layer in decoder.\n\n\n\n# What will happen to the learnning rates under this decay schedule?\nlr = 5\nfor i in range(12):\n    lr = lr - lr * .15\n    print(lr)    \n\n# Not as Deep Autoencoder\nnad_encoded1_da = Dense(800, activation = 'sigmoid')(input_img)\nnad_encoded1_da_bn = BatchNormalization()(nad_encoded1_da)\nnad_encoded2_da = Dense(400, activation = 'sigmoid')(nad_encoded1_da_bn)\nnad_encoded2_da_bn = BatchNormalization()(nad_encoded2_da)\nnad_decoded2_da = Dense(800, activation = 'sigmoid')(nad_encoded2_da_bn)\nnad_decoded1_da = Dense(784, activation = 'sigmoid')(nad_decoded2_da)\n\nnad_deep_autoencoder = Model(input_img, nad_decoded1_da)\n# nad_deep_autoencoder represents the two layered AE. Its weights we will initialized with above AEs after traiining them\n\n\nautoencoder1.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.SGD(lr = 5, decay = 0.5, momentum = .85, nesterov = True))\nautoencoder2.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.SGD(lr = 5, decay = 0.5, momentum = .85, nesterov = True))\n\nencoder1.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.SGD(lr = 5, decay = 0.5, momentum = .85, nesterov = True))\nencoder2.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.SGD(lr = 5, decay = 0.5, momentum = .85, nesterov = True))\n\nnad_deep_autoencoder.compile(loss='binary_crossentropy', optimizer = tf.keras.optimizers.SGD(lr = 5, decay = 0.5, momentum = .85, nesterov = True))\n","2521a41b":"autoencoder1.fit(training_inputs, training_inputs,\n                epochs = 8, batch_size = 512,\n                validation_split = 0.30,\n                shuffle = True)\n\nfirst_layer_code = encoder1.predict(training_inputs)\nprint(first_layer_code.shape)\n# first_layer_code is the output of first layer of encoder in two layered AE.\n# it would be the input to autoencoder2 since autoencoder2 has one layer which is second layer of two layered AE.\n\n\nautoencoder2.fit(first_layer_code, first_layer_code,\n                epochs = 8, batch_size = 512,\n                validation_split = 0.25,\n                shuffle = True)\n\nsecond_layer_code = encoder2.predict(first_layer_code)\nprint(second_layer_code.shape)\n\n# Setting up the weights of the not-as-deep autoencoder\nnad_deep_autoencoder.layers[1].set_weights(autoencoder1.layers[2].get_weights()) # first dense layer\nnad_deep_autoencoder.layers[2].set_weights(autoencoder1.layers[3].get_weights()) # first bn layer\nnad_deep_autoencoder.layers[3].set_weights(autoencoder2.layers[2].get_weights()) # second dense layer\nnad_deep_autoencoder.layers[4].set_weights(autoencoder2.layers[3].get_weights()) # second bn layer\nnad_deep_autoencoder.layers[5].set_weights(autoencoder2.layers[4].get_weights()) # second decoder\nnad_deep_autoencoder.layers[6].set_weights(autoencoder1.layers[4].get_weights()) # third decoder\n\n","06e3cba4":"# Attach the two layered AE with pre-trained weights (nad_decoded1_da) with output layer with sigmoid to classify.\ndense1 = Dense(500, activation = 'relu')(nad_decoded1_da)#(decoded1_da)\ndense1_drop = Dropout(.3)(dense1)\ndense2 = Dense(10, activation = 'sigmoid')(dense1_drop)\n\n# compile the full AE based 'classifier' i.e. AE + output layer\nclassifier = Model( input_img,  dense2)\n\nclassifier.compile(loss='categorical_crossentropy',optimizer = tf.keras.optimizers.SGD(lr = 0.1, decay = 0.001, momentum = .95, nesterov = True), metrics=['accuracy'])\n   \nclassifier.fit(training_inputs, training_targets,\n                epochs = 6, batch_size = 600,\n                validation_split = 0.25,\n                shuffle = True)\n\nval_preds = classifier.predict(val_inputs)\npredictions = np.argmax(val_preds, axis = 1)\ntrue_digits = np.argmax(val_targets, axis = 1)\npredictions[0:25]\n\n\nn_correct = np.sum(np.equal(predictions, true_digits).astype(int))\ntotal = float(len(predictions))\nprint(\"Validation Accuracy:\", round(n_correct \/ total, 3))","d2147d7f":"\n#nad_encoded1_das is w laywewd AE to be trained from scratch\n\nnad_encoded1_das = Dense(800, activation = 'sigmoid')(input_img)\nnad_encoded1_da_bns = BatchNormalization()(nad_encoded1_das)\nnad_encoded2_das = Dense(400, activation = 'sigmoid')(nad_encoded1_da_bns)\nnad_encoded2_da_bns = BatchNormalization()(nad_encoded2_das)\nnad_decoded2_das = Dense(800, activation = 'sigmoid')(nad_encoded2_da_bns)\nnad_decoded1_das = Dense(784, activation = 'sigmoid')(nad_decoded2_das)\n\n\n# deep_autoencoders2 is AE based on nad_encoded1_das\ndeep_autoencoders2 = Model( input_img,  nad_decoded1_das)\ndense1s2 = Dense(500, activation = 'relu')(nad_decoded1_das)#(nad_decoded1_da)\ndense1_drops2 = Dropout(.3)(dense1s2)\n#dense1_bn = BatchNormalization()(dense1_drop)\ndense2s2 = Dense(10, activation = 'sigmoid')(dense1_drops2)\n\n\n# classifiers is classifier (to be trained rom scratch) based on nad_encoded1_das\n\nclassifiers = Model( input_img,  dense2s2)\n\nclassifiers.compile(loss='categorical_crossentropy',optimizer = tf.keras.optimizers.SGD(lr = 0.1, decay = 0.001, momentum = .95, nesterov = True), metrics=['accuracy'])\n   \nclassifiers.fit(training_inputs, training_targets,\n                epochs = 6, batch_size = 600,\n                validation_split = 0.25,\n                shuffle = True)\n\nval_preds = classifiers.predict(val_inputs)\npredictions = np.argmax(val_preds, axis = 1)\ntrue_digits = np.argmax(val_targets, axis = 1)\npredictions[0:25]\n\nn_correct = np.sum(np.equal(predictions, true_digits).astype(int))\n\ntotal = float(len(predictions))\n\nprint(\"Validation Accuracy:\", round(n_correct \/ total, 3))","ce88a2e9":"decoded_inputs = deep_autoencoders2.predict(val_inputs[0:25,]) #deep_autoencoders\ndecoded_inputp = nad_deep_autoencoder.predict(val_inputs[0:25,])\npredictions = np.argmax(decoded_inputs, axis = 1)\n\nfig = plt.figure(figsize = (12, 12))\nfig.suptitle('Deep autoencoder reconstructions: \\n First row - Input data, \\nSecond row: Classifier with randon initliazation, \\nThird row: With pre-trained initialization', fontsize=24, fontweight='bold')\n\nax1 = fig.add_subplot(331)\nplt.imshow(val_inputs[2].reshape(28, 28))\n\nax2 = fig.add_subplot(334)\nplt.imshow(decoded_inputs[2].reshape(28, 28))\n\nax7 = fig.add_subplot(337)\nplt.imshow(decoded_inputp[2].reshape(28, 28))\n\n\nax3 = fig.add_subplot(332)\nplt.imshow(val_inputs[6].reshape(28, 28))\n\nax4 = fig.add_subplot(335)\nplt.imshow(decoded_inputs[6].reshape(28, 28))\n\nax8 = fig.add_subplot(338)\nplt.imshow(decoded_inputp[6].reshape(28, 28))\n\n\nax5 = fig.add_subplot(333)\nplt.imshow(val_inputs[4].reshape(28, 28))\n\nax6 = fig.add_subplot(336)\nplt.imshow(decoded_inputs[4].reshape(28, 28))\n\nax9 = fig.add_subplot(339)\nplt.imshow(decoded_inputp[4].reshape(28, 28))","e72fa5da":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport  numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a394805f":"**Two layer AE using pre-trained weights initialization**","af21f08c":"****Pre-requisite ****","bf130c6d":"Define Layers of AE to be pretrained","36241035":"Autoencoder (AE) based classifier is used to demonstrate the unsupervised pretraining procedure and its significance. Each of the encoder and decoder of AE has two fully connected (FC) layers. The AE is connected to an output FC layer with softmax to provide class label.\n\nThe dataset is handwritten digits 0 to 9. \n\n\nWe have created two AEs. Two FC layers of one AE are initialized with random weights. The FC layers of second AE are intialized using unsupervised layer-wise pretraining. \n\n\n\n\n","156b3e1b":"**Prepare the dataset.**","e622585b":"**Two layer AE classifier using randon initialization**","0e8f6928":"**Prepare Data**"}}