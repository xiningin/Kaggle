{"cell_type":{"4cb43f03":"code","3615bd58":"code","9d584480":"code","4848994f":"code","1e940e87":"code","ba5838df":"code","e862613d":"code","842dc702":"code","57ccec19":"code","0793027a":"code","dddf59a4":"code","953500f3":"code","5d7f8d04":"code","6544bef9":"code","2f895c14":"code","72e2e1ba":"code","2ea9cbe1":"code","8652c539":"code","2d57c810":"code","6bfce850":"code","ed137453":"code","478e7653":"code","7787eced":"code","8c7d78e5":"code","b106ed03":"code","13426e8c":"code","20ca8546":"code","3cf326dc":"code","122cf504":"code","39cfcb68":"code","8e814c6f":"code","5a6cf8c1":"code","78b469c8":"code","f08b8878":"code","8e329cd3":"code","17781864":"code","724b5695":"code","b3cf83b2":"code","28955fc2":"code","9f7ab39a":"code","4f57951e":"code","8376a9df":"code","ea4a3ee1":"code","edc166da":"code","13a66720":"code","77e2afd6":"code","cc829c59":"code","3b67a806":"code","99981d7f":"code","3d3f31f6":"code","307d060f":"code","10293b74":"code","19a154fd":"code","fe982627":"code","df7227e6":"code","5f620fa4":"code","ee830065":"code","63f95685":"code","793ad764":"code","a0d90d16":"code","309d961f":"code","b891306b":"code","5aa757ac":"code","faf9a54c":"code","1903b20d":"code","37c51de5":"code","bccadc11":"code","59236305":"code","a25bcca0":"code","ad53e8f0":"code","cf19ec6e":"code","81899cee":"code","3706086a":"code","c2eb7e84":"code","3f109aaa":"code","e2e24e4e":"code","c42429f1":"code","dbfed21f":"code","7fea0026":"code","8ddbbed8":"code","4350989e":"code","67ea6f9d":"code","ed2aa2dd":"code","0fcf0fff":"code","845cedc4":"code","362a1473":"code","a15c2996":"code","f96f0f23":"code","8e29b26b":"code","d71b4990":"code","44268611":"code","d80ce880":"code","2c1d6783":"code","4fdb6ad8":"code","7c1e1184":"code","b3d14334":"code","c15fb212":"code","31588727":"code","e10de2b6":"code","a4edc794":"code","9b6fa35f":"code","78fe324a":"code","0e188164":"code","ff55d22c":"code","3b71cb60":"code","6d1a92f2":"code","c7cd819f":"code","370127ef":"code","14ac6397":"code","ca2c0319":"code","6d80801e":"code","de7bcd58":"code","47d2b6c0":"code","905a769f":"code","8133e390":"markdown","45cea119":"markdown","dfe2adea":"markdown","9c791fd3":"markdown","a055e9e3":"markdown","5d6a3c61":"markdown","225aeeb3":"markdown","f7d623e8":"markdown","5d55c7c0":"markdown","316a200e":"markdown","dfaf67d2":"markdown","9f2c2ca8":"markdown","d2ead6ce":"markdown","d963a460":"markdown","cf911f4c":"markdown","0ef3492c":"markdown","ec2e695f":"markdown","df7f6f0c":"markdown","c1a889f0":"markdown","e1ae9fc8":"markdown","db2eb27a":"markdown","55a4aab4":"markdown","be329452":"markdown","fcebd200":"markdown","0071b802":"markdown","f13b7fea":"markdown","06d177a4":"markdown","f28743f9":"markdown","66470b3f":"markdown","6ce9a250":"markdown","0e29d595":"markdown","c38dcd07":"markdown","0a092eec":"markdown","61bf323b":"markdown","8198c36e":"markdown","33c0f75c":"markdown","815ad856":"markdown","ab2c77d2":"markdown","849f8059":"markdown","12e03f29":"markdown","52be4956":"markdown","43e29a3f":"markdown","3f5db172":"markdown","74a223c5":"markdown","c7ebb72e":"markdown","225d1a57":"markdown","12c68f08":"markdown","de42e163":"markdown","cc11049b":"markdown","ab2e4726":"markdown","09a304dc":"markdown","3921c713":"markdown","670fbfc6":"markdown","ab220d80":"markdown","526a0dcb":"markdown","704a9b3c":"markdown","ce0a5bd4":"markdown","7365ac92":"markdown","250a94f7":"markdown","3c4c4de3":"markdown","f2378172":"markdown"},"source":{"4cb43f03":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\n# user local module stochastic product search\n#import stochprodsearch_03 # DOESNT WORK SO FAR\n\nfrom datetime import datetime\nimport time \nimport numpy as np # linear algebra\n\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# to save \nimport pickle\nfrom sklearn.externals import joblib\n#import joblib\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) \n# will list all files under the input directory\n\nimport os\nfrom numba import njit, jit, prange\n\n# to get computer name\nimport platform\nimport re\n\n# For Figures\n%matplotlib inline\nimport matplotlib.pyplot as plt\nplt.style.use('seaborn-whitegrid')\nimport seaborn as sns\nsns.set(color_codes=True, font_scale=1.33)","3615bd58":"###\n# Paths to folders\/files\n###\n\n# KAGGLE\nPATH_INPUT_KAGGLE = '\/kaggle\/input' #for kaggle\nPATH_TO_SAVE_DATA_KAGGLE = '\/kaggle\/working' #for kaggle\nPATH_TO_EXPLORE_DATA_KAGGLE = '\/kaggle\/input\/santa-2019-for-my-exploration' # for kaggle\n\n# LOCAL\nPATH_INPUT = 'kaggle\/input'\nPATH_TO_SAVE_DATA = \"..\/..\/data\"\nPATH_TO_EXPLORE_DATA = 'kaggle\/input\/santa_2019_for_my_exploration'\n\n# GOOGLE COLAB\nPATH_GOOGLE_COLAB = \"\/content\/drive\/My Drive\/OpenClassRooms\/IML_projet_8\"  + \\\n             \"\/code\/santa-workshop-tour-2019\"\n\n# get computer name\nCOMPUTERNAME = platform.node()\n# select current platform\nMY_PLATFORM = platform.system()\n# check if Google colab need Drive ?\nif re.match(\"^\/content\", os.getcwd()):\n    print(\"GOOGLE COLAB MODE\")\n    from google.colab import drive\n    drive.mount('\/content\/drive', force_remount=True)\n    os.chdir(PATH_GOOGLE_COLAB)\nelif re.match(\"^\/kaggle\", os.getcwd()):\n    print(\"KAGGLE COLAB MODE\")\n    PATH_INPUT = PATH_INPUT_KAGGLE \n    PATH_TO_SAVE_DATA = PATH_TO_SAVE_DATA_KAGGLE \n    PATH_TO_EXPLORE_DATA = PATH_TO_EXPLORE_DATA_KAGGLE \n    \n# PROB FILE PATH\nPATH_SAVE_PROB_FAM = PATH_TO_SAVE_DATA + '\/df_prob_fam.pkl'\n\n## POP PATH : to generate first pop, used 'RAMDOM_PATH' instead of None\n#SAVE_POP = None\n#SAVE_POP = '10R' # 10 ranges method\nSAVE_POP = 'RANDOM_PATH' # random ranges method\n#SAVE_POP = 'RANDOM_CHOICE' # first random choices method\n\n# path to pop df file id save pop is none.\n#PATH_DF_POP = PATH_TO_SAVE_DATA + '\/' + \\\n#   \"df_pop_choices_10R_1000_fs10_rfm0.05_dc2.pkl\"\nPATH_DF_POP = PATH_TO_SAVE_DATA + '\/' + \"df_pop_choices_RANDOM_PATH_1000.pkl\"\n#PATH_DF_POP = PATH_TO_SAVE_DATA + '\/' + \\\n#    \"df_pop_choices_RANDOM_CHOICE_1000_dcr1.pkl\"\n#PATH_DF_POP = PATH_TO_SAVE_DATA + '\/' + \\\n#    \"df_pop1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen200000_s84089.67769691352.pkl\"\n# DAY information (useless ?)\nDAY_RANGE = list(range(1, 101)) # day before Christmas\nDAY_RANGE_MIN = np.min(DAY_RANGE) \nDAY_RANGE_MAX = np.max(DAY_RANGE) \n\n##########\n## Hyper-parameters: DEFAULT\n\n# from data \nCHOICE_RANGE_MIN = 0 # minimum choice number\nCHOICE_RANGE_MAX = 4 # maximum choice number\n\n# for POP \nNB_FIRST_SEED = 10 # best parent to create mutated first population\nNB_FIRST_POP = 1000 # number of first population of choices \nDELTA_CHOICE_FIRST_POP = 2 # +\/- delta choice of mutated first population \nR_FIRST_MUT = 0.05 # RATIO of mutation for first population\nDELTA_CHOICE_RANDOM_POP = 1 # delta for first random choice pop\nDELTA_RANDOM_MUT_POP = 1 # delta for first random mut pop\nR_FIRST_RANDOM_MUT = 0.2 # RATIO of mutation for first population in random mut\n# for all generations\nR_POP_MUT = 0.05 # RATIO of population mutation after first generation\nR_MUT = 0.01 # RATIO of number of family choices mutated\nDELTA_DAYS = 1 # delta of days around previous best day for generation\/mutation\nR_POP_LOST = 0.01 # Ratio of lost individuals in population \nPOW_SELECTION = 0.3 # power for slection during crossing\nNB_BEST_KEEP = 10 # number of best indiv to keep at each epoch\nNB_MAX_EPOCHS = 1000\nDELTA_CHOICE = 1 # +\/- delta choice of mutated for generation population\nR_CROSSOVER = 1 # Crossover Ratio of pop for next generation \n    \n# check DATA input folder\nfor dirname, _, filenames in os.walk(PATH_INPUT):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","9d584480":"def find_choice_range(choice_curr):\n    '''\n    select range of choices \n    from random between +\/- delta choice around choice_curr\n    \n    return a range\n    '''\n    choice_min = np.min([np.max([CHOICE_RANGE_MIN, choice_curr - DELTA_CHOICE]), \n                          CHOICE_RANGE_MAX - 2 * DELTA_CHOICE])\n    choice_max = np.min([CHOICE_RANGE_MAX, \n                        np.max([CHOICE_RANGE_MIN + 2 * DELTA_CHOICE, \n                        choice_curr + DELTA_CHOICE])]) + 1\n    range_choice = range(choice_min, choice_max)\n    \n    return range_choice\n\n@njit\ndef find_choice_range_optim(choice_curr, delta_choice=DELTA_CHOICE):\n    '''\n    select range of choices \n    from random between +\/- delta choice around choice_curr\n    \n    return a range\n    \n    use external constant var : CHOICE_RANGE_MIN & CHOICE_RANGE_MAX\n    '''\n    #return max(choice_curr, CHOICE_RANGE_MIN)\n    \n    \n    choice_min = min(max(CHOICE_RANGE_MIN, choice_curr - delta_choice), \n                          CHOICE_RANGE_MAX - 2 * delta_choice)\n    choice_max = min(CHOICE_RANGE_MAX, \n                        max(CHOICE_RANGE_MIN + 2 * delta_choice, \n                        choice_curr + delta_choice)) + 1\n    range_choice = np.arange(choice_min, choice_max)\n    \n    return range_choice\n\n\ndef find_choice_from_day(day_curr, fam_id):\n    '''\n    find current choice according to day_curr and family id\n    '''\n    fam_days = data_choice.loc[fam_id]\n    \n    idx_choice_curr = fam_days[day_curr == fam_days].index\n    \n    if idx_choice_curr.shape[0] == 0:\n        return 10 \n    else:\n        return idx_choice_curr[0]\n\ndef find_choice_from_day_arr(day_curr, fam_id):\n    '''\n    find current choice according to day_curr and family id\n    \n    use external constant var : arr_choice\n    '''\n    idx_choice_curr = np.nonzero(arr_choice[fam_id,:] == day_curr)[0]\n\n    if idx_choice_curr.shape[0] == 0:\n        return 10 \n    else:\n        return idx_choice_curr[0]\n\n@njit\ndef find_choice_from_day_optim(day_curr, fam_id):\n    '''\n    find current choice according to day_curr and family id\n    \n    use external constant var : arr_choice\n    '''\n    idx_choice_curr = np.nonzero(arr_choice[fam_id,:] == day_curr)[0]\n\n    if idx_choice_curr.shape[0] == 0:\n        return 10 \n    else:\n        return idx_choice_curr[0]\n    \n    \ndef choose_day_prob(choice_curr, fam_id):\n    '''\n    find or choose the day of given choice number according to family choices\n    \n    if choice 10, then find a day randomly\n    \n    return a day\n    '''\n  \n    choice_curr = np.array(choice_curr)\n    \n    vect_days_choice = data_choice.loc[fam_id, np.minimum(9, choice_curr)]\n    vect_days_choice = np.array(vect_days_choice)\n    \n    idx_choice_10 = np.nonzero(choice_curr == 10)[0]\n    if idx_choice_10.shape[0] > 0:\n        nb_10 = idx_choice_10.shape[0]\n        vect_all_days = np.array(range(1, 101))\n        vect_prob_10 = np.array(df_prob_fam.astype(\"float\").loc[fam_id])\/ \\\n            df_prob_fam.loc[fam_id].sum()\n        #vect_prob_10 = np.ones(vect_all_days.shape[0])\n        vect_prob_10[idx_choice_10] = 0\n        vect_prob_10 = vect_prob_10 \/ np.sum(vect_prob_10)\n        days_10 = np.random.choice(vect_all_days, size=nb_10,\n                                  p=vect_prob_10)\n        #print(\"idx_choice_10: \", idx_choice_10)\n        for i_day, indice in enumerate(idx_choice_10):\n            \n            if vect_days_choice.shape:\n                \n                ''' print(\"days_10: \", days_10)\n                print(\"vect_days_choice: \", np.array(vect_days_choice))\n                print(\"vect_days_choice[indice]: \", \n                      np.array(vect_days_choice)[indice])\n                print(\"i_day: \", i_day)\n                print(\"days_10[i_day]: \", days_10[i_day])\n                print(\"indice : \", indice)'''\n\n                vect_days_choice[indice] = days_10[i_day]\n            else:\n                vect_days_choice = np.array(days_10[i_day])\n            \n        return vect_days_choice\n    else:\n        return vect_days_choice\n    \ndef choose_day_prob_arr(choice_curr, fam_id):\n    '''\n    find or choose the day of given choice number according to family choices\n    \n    if choice 10, then find a day randomly\n    \n    return a day\n    '''\n    choice_curr = np.array(choice_curr)\n    \n    vect_days_choice = arr_choice[fam_id, np.minimum(9, choice_curr)]\n    #vect_days_choice = np.array(vect_days_choice)\n    \n    idx_choice_10 = np.nonzero(choice_curr == 10)[0]\n    if idx_choice_10.shape[0] > 0:\n        nb_10 = idx_choice_10.shape[0]\n        vect_all_days = np.array(range(1, 101))\n        vect_prob_10 = arr_prob_fam[fam_id]\/arr_prob_fam[fam_id].sum()\n        #np.array(df_prob_fam.astype(\"float\").loc[fam_id])\/ \\\n        #    df_prob_fam.loc[fam_id].sum()\n        #vect_prob_10 = np.ones(vect_all_days.shape[0])\n        vect_prob_10[idx_choice_10] = 0\n        vect_prob_10 = vect_prob_10 \/ np.sum(vect_prob_10)\n        days_10 = np.random.choice(vect_all_days, size=nb_10,\n                                  p=vect_prob_10)\n        #print(\"idx_choice_10: \", idx_choice_10)\n        for i_day, indice in enumerate(idx_choice_10):\n            \n            if vect_days_choice.shape:\n                \n                vect_days_choice[indice] = days_10[i_day]\n            else:\n                vect_days_choice = np.array(days_10[i_day])\n            \n        return vect_days_choice\n    else:\n        return vect_days_choice    \n\n@njit\ndef choose_day_prob_optim(choice_curr, fam_id):\n    #def choose_day_prob_optim(choice_curr, fam_id, arr_choice=arr_choice):\n    '''\n    V1.1 : correction about no selection of days choices for choice 10 \n    \n    find or choose the day of given choice number according to family choices\n    \n    if choice 10, then find a day randomly\n    \n    return a day\n    \n    use external constant vars : arr_choice & arr_prob_fam\n    '''\n    #choice_curr = np.array(choice_curr)\n        \n    idx_choice_10 = []\n    for I in np.arange(choice_curr.shape[0]):\n        if choice_curr[I] == 10:\n            idx_choice_10.append(I)\n            \n    idx_choice_10 = np.array(idx_choice_10)\n    \n    vect_days_choice = []\n    for J in np.arange(choice_curr.shape[0]):\n        vect_days_choice.append(arr_choice[fam_id, \n                                           np.minimum(9, choice_curr[J])])\n        \n    vect_days_choice = np.array(vect_days_choice)\n    #print(\"idx_choice_10 \" , idx_choice_10)\n    if idx_choice_10.shape[0] > 0:\n        nb_10 = idx_choice_10.shape[0]\n        vect_all_days = np.arange(1, 101)\n        vect_prob_10 = arr_prob_fam[fam_id].copy()\n        vect_prob_10[arr_choice[fam_id]] = 0\n        vect_prob_10 = vect_prob_10 \/ np.sum(vect_prob_10)\n        #print(\"vect_prob_10 \",vect_prob_10)\n        days_10 = rand_choice_nb(vect_all_days, size=nb_10,\n                                  prob=vect_prob_10)\n        #print(\"days_10 \", days_10)\n        for i_day, indice in enumerate(idx_choice_10):\n            vect_days_choice[indice] = days_10[i_day]         \n        return vect_days_choice\n    else:\n        return vect_days_choice \n\ndef mutation_day(day_curr, fam_id, nb_mut=1, flag_prob=False):\n    # function mutation of days : around choices\n    # day_curr -> choice_curr -> range choices -> \n    # choose randomly 1 choice -> 1 day \n    # fam_id = 0\n    # day_curr = 100\n    # mutation_day(day_curr, fam_id, 10)\n    choice_curr = find_choice_from_day_arr(day_curr, fam_id)\n    #print(\"choice_curr: \", choice_curr)\n    range_choices = find_choice_range(choice_curr)\n    #print(\"range_choices: \", np.array(range_choices))\n    \n    if flag_prob:\n        vect_prob = arr_prob[family_size_dict[fam_id]-2, range_choices]\n        #np.array(df_prob.loc[data.loc[fam_id,\"n_people\"], \n        #                     ['choice_{}'.format(i) for i in range_choices]])\n        vect_prob = vect_prob \/ vect_prob.sum()\n        #print(\"vect_prob: \", vect_prob)\n        choice_new = np.random.choice(range_choices, size=nb_mut,\n                                     p=vect_prob)\n    else:\n        choice_new = np.random.choice(range_choices, size=nb_mut)\n        \n    #print(\"choice_new: \", choice_new)\n    return choose_day_prob_arr(choice_new, fam_id)\n\n\ndef find_day_range(day_curr):\n    '''\n    select range of days from random between +\/- delta day around day_curr\n    \n    return a range\n    '''\n    day_min = np.min([np.max([DAY_RANGE_MIN, day_curr-DELTA_DAYS]), \n                      DAY_RANGE_MAX - 2 * DELTA_DAYS])\n    day_max = np.min([DAY_RANGE_MAX, np.max([DAY_RANGE_MIN + 2 * DELTA_DAYS, \n                                             day_curr + DELTA_DAYS])]) + 1\n    range_day = range(day_min, day_max)\n\n    return range_day\n\n\ndef generate_pop(seed_indiv=None, nb_pop=None, r_mut=None):\n    '''\n    Generate first polulation from one seed individual\n    - seed_indiv # best submission \n    - nb_pop # number of individual\n    - r_mut # ratio of individual who mutate for each family\n    \n    return dataFrame population\n    '''\n    t_fit_0 = time.time()\n    # GENERATION OF FIRST POP:\n    print(\"Generating population : \")\n    # definitions:\n    if seed_indiv is None:\n        seed_indiv = submission\n    if nb_pop is None:\n        nb_pop = NB_FIRST_POP\n    if r_mut is None:\n        r_mut = R_FIRST_MUT\n    #print(\"seed_indiv: \", seed_indiv)\n    print(\"nb_pop: \", nb_pop)\n    print(\"r_mut: \", r_mut)\n    # initialize with same previous best indiv.\n    df_pop = pd.DataFrame(index=range(0, nb_pop), \n                          columns=seed_indiv[\"family_id\"])\n\n    for fam_id in seed_indiv[\"family_id\"]:\n        df_pop[fam_id] = seed_indiv.at[fam_id,'assigned_day']\n\n    # create nb_pop family choices from baseline :\n    # use probabilies\n    # df_pop : contains number choices of all the population of 5000 families\n    # df_pop = f(indiv., family)\n    # for each family, create n choice among their first choice\n    # use day probabilities specific for each family\n    for fam_id in data.index: # data = f(family, num choice)\n        # day current is the old best seed_indiv day for this family\n        day_curr = seed_indiv.at[fam_id, 'assigned_day']\n        # find range around day curr +\/- DELTA\n        range_curr = find_day_range(day_curr)\n        # retrict probabilities to range. use df_prob_fam = f(fam_id, day)\n        day_prob = df_prob_fam.astype(\"float\").loc[fam_id, range_curr]\/ \\\n            df_prob_fam.loc[fam_id, range_curr].sum()\n        # choose randomly with probabilities days around old best day\n        vect_pop_mutated = np.random.choice(np.array(range_curr), \n                                size=nb_pop, \n                                p=np.array(day_prob))\n\n        # apply the new days only a part of pop : r_mut [-]\n        range_mut = np.random.choice(range(0, nb_pop), \n                                     size=int(r_mut*nb_pop))\n\n        df_pop.loc[range_mut, fam_id] = vect_pop_mutated[range_mut]\n\n    # keep the best : \n    df_pop.loc[0] = seed_indiv['assigned_day']\n    \n    print(\"Generation population is done.\")\n    t_fit_1 = time.time()\n    print(\"Timing : \", t_fit_1 - t_fit_0)\n    \n    return df_pop\n\n@njit\ndef generate_crossing(arr_pop_in):\n    '''\n    function to generate crossing\n    2 parents give 2 children\n    Crossing point is randomly chosen\n    \n    input the current poulation array\n    \n    return new array of whole population\n    '''\n    # Do the Crossover between pair indiv.\n    # 1 Cross point is ramdomly choosen (prob uniform)\n    # example : \n    # 1-2-3\\  \/5-8-9-1-3-4-9  \n    #       \\\/\n    # 5-6-5\/ \\4-5-6-7-8-9-10\n    #\n    # give : \n    #\n    # 1-2-3--4-5-6-7-8-9-10\n    # 5-6-5--5-8-9-1-3-4-9 \n    # create pairs : ramdomly\n    arr_pop = arr_pop_in.copy()\n    vect_indiv = np.arange(arr_pop.shape[0])\n    vect_fam = np.arange(arr_pop.shape[1])\n    vect_fam = vect_fam[2:-2]\n    \n    # method 1 : each 2 parents create 2 children (by replacement)\n    arr_pairs = np.random.choice(vect_indiv, replace=False,\n                        size=(int(arr_pop.shape[0]\/2), 2))\n    \n    \n    # loop over pairs of indiv.\n    for indice in np.arange(arr_pairs.shape[0]):\n        id_0 = arr_pairs[indice, 0]\n        id_1 = arr_pairs[indice, 1]\n        \n        # random point of crossover (among families)\n        fam_id_cross = np.random.choice(vect_fam)\n        \n        # find parts of first new indiv    \n        vect_id_0_part_0 = arr_pop[id_0].take(np.arange(fam_id_cross))\n        vect_id_0_part_1 = arr_pop[id_1].take(np.arange(fam_id_cross, \n                                                   arr_pop.shape[1]))\n    \n        # find parts of second new indiv\n        vect_id_1_part_0 = arr_pop[id_1].take(np.arange(fam_id_cross))\n        vect_id_1_part_1 = arr_pop[id_0].take(np.arange(fam_id_cross, \n                                                  arr_pop.shape[1])) \n    \n        # replace 2 parents by 2 children\n        arr_pop[id_0,:] = np.concatenate((vect_id_0_part_0, vect_id_0_part_1))\n        arr_pop[id_1,:] = np.concatenate((vect_id_1_part_0, vect_id_1_part_1))\n      \n    return arr_pop\n\n\n\ndef create_df_prob_day_fam(df_prob_day, df_prob):\n    df_prob_fam = pd.DataFrame(index = data.index, columns=df_prob_day.index)\n    for fam_id in df_prob_fam.index:\n        # give at first to each families the same day probabilities\n        df_prob_fam.loc[fam_id] = df_prob_day[\"prob\"]\n        # and add prob for each day choosen by families\n        for choice in list_choice_all: \n            prob_curr = df_prob.at[data.at[fam_id, \"n_people\"], choice]\n            day_curr = data.at[fam_id, choice]\n            # add this prob of these days to family into df_prob_fam\n            df_prob_fam.loc[fam_id, day_curr] += prob_curr\n            #print(day_curr)\n            #print(prob_curr)\n        df_prob_fam.loc[fam_id] = \\\n            df_prob_fam.loc[fam_id] \/ df_prob_fam.loc[fam_id].sum()\n    return df_prob_fam\n\ndef create_df_prob_day_fam_optim(df_prob_day, df_prob):\n    '''\n    Creation of probabilities for each families and each days\n    We give at first to each families the same day probabilities df_prob_day.\n    (df_prob_day is inversely proportional to sum of all choices of this day)\n    And we add for each family their probability df_prob \n    (df_prob depends to )\n    info : Optimized version\n    \n    input : df_prob_day, df_prob\n    ouput : df_prob_fam\n    '''\n    \n    arr_prob_fam = np.zeros([data.shape[0], df_prob_day.shape[0]])\n    arr_prob = np.array(df_prob)\n    list_choice_all = ['choice_{}'.format(n) for n in range(0, 10)]\n    arr_data = np.array(data.filter(items=list_choice_all))\n    for fam_id in np.arange(data.shape[0]):\n        # give at first to each families the same day probabilities\n        \n        #df_prob_fam.loc[fam_id] = df_prob_day[\"prob\"]\n        arr_prob_fam[fam_id] = df_prob_day[\"prob\"].values\n        # and add prob for each day choosen by families\n        for choice in np.arange(df_prob.shape[1]-1): \n            prob_curr = arr_prob[family_size_dict[fam_id]-2, choice]\n            day_curr = arr_data[fam_id, choice]\n            # add this prob of these days to family into df_prob_fam\n            arr_prob_fam[fam_id, day_curr-1] += prob_curr\n            #print(day_curr)\n            #print(prob_curr)\n        arr_prob_fam[fam_id] = \\\n            arr_prob_fam[fam_id] \/ arr_prob_fam[fam_id].sum()\n        \n    df_prob_fam = pd.DataFrame(index = data.index, columns=df_prob_day.index, \n                              data = arr_prob_fam)\n    \n    return df_prob_fam\n\n\n\n@njit#(parallel=True, fastmath=True)\ndef rand_choice_nb(arr, size=1, prob=None):\n    \"\"\"\n    numba compatible vesrion of np.random.choice(arr, size=size, prob=prob)\n    \n    :param arr: A 1D numpy array of values to sample from.\n    :param prob: A 1D numpy array of probabilities for the given samples.\n    :return: A random sample from the given array with a given probability.\n    \n    source : https:\/\/github.com\/numba\/numba\/issues\/2539\n    \"\"\"\n    if prob is not None:\n        list_value=[]\n        for I in prange(size):\n            list_value.append(arr[np.searchsorted(np.cumsum(prob), \n                                                  np.random.random(), \n                                                  side=\"right\")])\n        return np.array(list_value)\n    else:\n        return np.random.choice(arr, size=size)\n\n\n\n\ndef find_max_same_indiv(arr_pop):\n    '''\n    Counts max number of same indiv among population\n    return only max number of same indiv\n    '''\n    arr_unique, arr_counts = np.unique(arr_pop, axis=0, return_counts=True)\n    nb_same_indiv = np.max(arr_counts) - 1\n    return nb_same_indiv\n\n\n\ndef selection_prob(df_cost, df_pop=None, pow_selection=0.3, flag_ouput=False,\n                   nb_best_keep = NB_BEST_KEEP):\n    '''\n    Calculate prob for selection of best indiv. among pop\n    Can return also best individuates : df_best, and their cost : df_cost_best\n    '''\n    df_cost_sort = df_cost.sort_values(by=\"cost\")\n    df_cost_sort[\"rank\"] = range(df_cost.shape[0]+1,1,-1 )\n    arr_select_prob = np.zeros(df_cost_sort.shape[0])\n    arr_select_prob[df_cost_sort.index] = df_cost_sort[\"rank\"].values\n    arr_select_prob = (arr_select_prob)**POW_SELECTION\n    arr_select_prob = arr_select_prob \/ np.sum(arr_select_prob)\n\n    if flag_ouput:\n        list_index_best = df_cost_sort.iloc[range(0,nb_best_keep)].index\n        df_best = df_pop.loc[list_index_best]\n        df_cost_best = df_cost.loc[list_index_best]\n        return arr_select_prob, df_best, df_cost_best\n    else:\n        return arr_select_prob\n\n@njit\ndef selection_prob_arr(arr_cost, arr_pop=None, pow_selection=0.3, \n                       flag_ouput=False,\n                   nb_best_keep = NB_BEST_KEEP):\n    '''\n    Calculate prob for selection of best indiv. among pop\n    return also best individuates : arr_best, and their cost : arr_cost_best\n    '''\n    indice_cost = np.argsort(arr_cost)\n    rank_range = np.arange(arr_cost.shape[0]+1,1,-1)\n    arr_select_prob = np.zeros(arr_cost.shape[0])\n    K=0\n    for indice in indice_cost:\n        arr_select_prob[indice] = rank_range[K]\n        K=K+1\n    arr_select_prob = (arr_select_prob)**POW_SELECTION\n    arr_select_prob = arr_select_prob \/ np.sum(arr_select_prob)\n\n    list_index_best = indice_cost[np.arange(0, nb_best_keep)]\n    arr_best = arr_pop[list_index_best].copy()\n    arr_cost_best = arr_cost[list_index_best].copy()\n    return arr_select_prob, arr_best, arr_cost_best\n    \n\ndef pop_choices_info(df_pop):\n    '''\n    \n    Show information about population df_pop\n    \n    outputs :\n    - df_choices  : assignation day for each families for all pop\n    - df_des_choices : describe of df_dhoices\n    -  std_mean = Mean Standard deviation over families for whole population \n    \n    '''\n    \n    @njit\n    def find_pop_choices(arr_pop):\n        '''\n        Determine all choices of the population, from days\n        '''\n        arr_choices = np.zeros((arr_pop.shape[0], arr_pop.shape[1]))*np.nan\n        for fam_id in range(arr_pop.shape[1]):\n            for indice in range(arr_pop.shape[0]):\n                arr_choices[indice, fam_id] = \\\n                    find_choice_from_day_optim(arr_pop[indice, fam_id], fam_id)\n        return arr_choices\n    \n    arr_choices = find_pop_choices(df_pop.values)   \n    df_choices = pd.DataFrame(arr_choices.astype(np.int64), \n                              index = df_pop.index,\n                              columns=df_pop.columns) \n    arr_choices = find_pop_choices(df_pop.values)   \n    df_choices = pd.DataFrame(arr_choices.astype(np.int64), \n                              index = df_pop.index,\n                              columns=df_pop.columns) \n    df_des_choices = df_choices.describe()\n    std_mean = df_des_choices.loc[\"std\"].mean()\n    print(\"Mean Standard deviation over families for whole population : \", \n         std_mean)\n    print(\"Info about std: \",df_des_choices.loc[\"std\"].describe())\n    return df_choices, df_des_choices, std_mean\n\ndef create_seek_ranges(nb_first_seed=NB_FIRST_SEED):\n    \n    '''create df_range : contains all path to seek optimum'''\n    \n    df_range = pd.DataFrame(index=range(0, nb_first_seed), \n                            columns=range(0, submission.shape[0]))\n\n    df_range.loc[0] = np.array(range(0, submission.shape[0]))\n\n    df_range.loc[1] = np.array(range(submission.index.max(), \n                                     submission.index.min()-1, -1))  \n    # generate start points\n    start_pt = np.linspace(0, submission.shape[0], \n                           num=int((NB_FIRST_SEED)\/2)+1, dtype=\"int\")\n    start_pt = start_pt[1:-1]\n    start_pt\n\n    # create range order for seeking\n    indice = 2\n    for st_id, _ in enumerate(start_pt):\n        df_range.loc[indice+st_id] = np.concatenate((np.array(range(start_pt[st_id], \n                                                    submission.shape[0])), \n                   np.array(range(0, start_pt[st_id]))))\n\n    indice = 6\n    for st_id, _ in enumerate(start_pt):\n        df_range.loc[indice+st_id] = \\\n            np.concatenate((range(start_pt[st_id], 0-1, -1), \n                    range(submission.shape[0]-1, start_pt[st_id], -1)))\n\n    return df_range ","4848994f":"@njit(parallel=True, fastmath=True)\ndef generate_crossing_prob(arr_pop_in, p=None , n_indiv=None, r_cross=1):\n    '''\n    function to generate crossing indiv  (version with probabilities)\n    V1.1 : add force create new child if same parents by changing parent\n           and limitation to start - 1 end end - 1 for crossing point.\n           \n    time exec : 3.5ms 1000 children\n    \n    2 parents give 1 child\n    \n    Crossing point is randomly chosen\n    \n    input the current population array\n    \n    return new array of whole population\n    \n    r_cross is more a target of ratio of crossover individuates.\n    if not enough children, then generate more than the ratio\n    \n    EXAMPLE : \n    arr_test = np.array([[1,2,3,4,5,6,7,8,9,1], [2,5,8,9,5,5,5,5,5,2],\n                [3,1,1,1,5,5,5,5,5,3], [4,6,6,6,6,9,9,9,9,4], \n                [5,6,6,6,6,9,9,9,9,5]])\n    arr_prob_test = 1 \/ np.array([1,2,3,4,5])\n    arr_prob_test = arr_prob_test \/ np.sum(arr_prob_test)\n    arr_test_new = generate_crossing_prob(arr_test, p=arr_prob_test, n_indiv=11)\n    plt.plot(arr_test_new[0]-arr_test[1])\n    \n    '''\n    # Do the Crossover between pair indiv.\n    # 1 Cross point is ramdomly choosen (prob uniform)\n    # example : \n    # 1-2-3\\  \/5-8-9-1-3-4-9  \n    #       \\\/\n    # 5-6-5\/ \\4-5-6-7-8-9-10\n    #\n    # give : \n    #\n    # 1-2-3--4-5-6-7-8-9-10\n    # 5-6-5--5-8-9-1-3-4-9 \n    # create pairs : ramdomly\n\n    # check number of indiv : \n    nb_pop = arr_pop_in.shape[0]\n    # calculate number of new children\n    n_indiv_cross = int(n_indiv*r_cross)\n    if n_indiv_cross == 0:\n        n_indiv_cross = 1\n    # if not enough to create n_indiv, add crossover indiv:\n    if n_indiv > nb_pop + n_indiv_cross:\n        n_indiv_cross = n_indiv - nb_pop\n    #print(\"n_indiv_cross : \", n_indiv_cross) \n    # initialize output\n    arr_pop = np.zeros((int(n_indiv), arr_pop_in.shape[1]), dtype=np.int64)\n    #print('arr_pop.shape :', arr_pop.shape)\n    \n    # preparation for loop over pairs : \n    vect_parents = np.arange(arr_pop_in.shape[0])\n    vect_fam = np.arange(arr_pop.shape[1])\n    # NOT replacing all part of parents : limit range\n    vect_fam = vect_fam[1:-1]\n    arr_pairs = np.zeros((int(n_indiv_cross), 2), dtype=np.int64)\n    # create pairs : select best ones more frequently first\n    for I in prange(int(arr_pairs.shape[0])):\n        arr_pairs[I] = rand_choice_nb(vect_parents, size=2, prob=p)\n        #arr_pairs[I] = np.random.choice(vect_parents, size=2)\n        K=0\n        # check and force to new children from same parents\n        # patch dirty ! but njit doenst work with random choice prob \n        # & non replace...\n        while (arr_pairs[I,0] == arr_pairs[I,1]) & (K < 1000):\n            arr_pairs[I] = rand_choice_nb(vect_parents, size=2, prob=p)\n            # test if same indiv : \n            while not(np.any(arr_pop_in[arr_pairs[I,0]] - \\\n                             arr_pop_in[arr_pairs[I,1]])) & (K < 1000):\n                arr_pairs[I] = rand_choice_nb(vect_parents, size=2, prob=p)\n                K=K+1\n            K=K+1\n            \n    # for all pairs wanted as output  \n    for indice in prange(int(arr_pairs.shape[0])):\n        # indice of 2 parents\n        id_0 = arr_pairs[indice, 0]\n        id_1 = arr_pairs[indice, 1]\n        # random point of crossover (among families)\n        fam_id_cross = np.random.choice(vect_fam)\n        # find parts of first new indiv    \n        vect_id_0_part_0 = arr_pop_in[id_0].take(np.arange(fam_id_cross))\n        vect_id_0_part_1 = arr_pop_in[id_1].take(np.arange(fam_id_cross, \n                                                   arr_pop_in.shape[1]))\n        # create 1 children \n        arr_pop[indice] = np.concatenate((vect_id_0_part_0, \n                                            vect_id_0_part_1))\n    # if crossing not all pop\n    if r_cross < 1:\n        # keep some of best parents \n        nb_parents_keep = n_indiv - n_indiv_cross\n        #print(\"nb_parents_keep: \", nb_parents_keep)\n        #vect_parent_keep = rand_choice_nb(vect_parents, size=nb_parents_keep, \n        #                                  prob=p)\n        # we keep only the best parents\n        inv_ind_best = np.argsort(p)\n        arr_pop_ranked = arr_pop_in[inv_ind_best, :]\n        \n        #print('inv_ind_best.shape: ', inv_ind_best.shape)\n        #print('arr_pop_in red: ', arr_pop[n_indiv_cross:, :].shape)\n        #print('arr_pop_ranked.shape red: ',  arr_pop_ranked[-nb_parents_keep:, :].shape)\n        #print('arr_pop_ranked.shape: ', arr_pop_ranked.shape)\n        arr_pop[n_indiv_cross:, :] = \\\n            arr_pop_ranked[-nb_parents_keep:, :]\n        \n        return arr_pop\n    else:  \n        return arr_pop\n    \ndef boost_diff_browsing(arr_choice, best, arr_range):\n    '''\n    Boosting simple by seeking by ranges \n    Simple baseline optimisation following different path range of families.\n    Forward\/Backward\n    \n    input : arr_choice : array of choice days by families\n            best : best submission\n            arr_range : ranges of paths into families\n    return :  arr_sub : array of submissions\n            arr_score : array of their score\/cost\n    \n    example :\n    arr_sub, arr_score = boost_diff_browsing(arr_choice, best, arr_range)\n    \n    '''\n    # Create baselines # optimized version\n    t_fit_0 = time.time()\n    # Create baselines # optimized version\n    start_cost = cost_function_optim(best)\n    print(\"Start cost: \", start_cost)\n    \n    # prepare output : best submission seeking in different range walk around\n    arr_sub = np.zeros((arr_range.shape[0], best.shape[0])).astype(np.int64)\n    arr_score = np.zeros(arr_range.shape[0])\n    \n    #new = best.copy()\n    \n    for indice in np.arange(arr_range.shape[0]):\n    #for indice in df_range.index:\n        # choose current range in df_range\n        range_optim = arr_range[indice]\n        #range_optim = df_range.loc[indice]\n\n        # initiate first inviduate \n        new = best.copy()\n        cost_best = start_cost\n\n        # loop over each family with this current range       \n        for fam_id in range_optim:\n            # loop over each family choice\n            for pick in range(10):\n                day = arr_choice[fam_id, pick]\n                temp = new.copy()\n                temp[fam_id] = day # add in the new pick\n                cost_curr = cost_function_optim(temp) # test cost\n                if cost_curr < cost_best:\n                    new = temp.copy()\n                    cost_best = cost_curr\n                    #print(f'...Baseline #{indice} current best Score: {cost_best}')\n                \n        print(f'Baseline #{indice} Score: {cost_best}')\n        arr_sub[indice] = new\n        arr_score[indice] = cost_best\n        \n        \n    # timing\n    t_fit_1 = time.time()\n    print(\"Timing: \", t_fit_1 - t_fit_0)\n        \n    return arr_sub, arr_score\n\ndef generate_pop_choices(seed_indiv=None, nb_pop=None, r_mut=None, \n                         delta_choice=DELTA_CHOICE_FIRST_POP):\n    '''\n    Generate first polulation from one seed individual by family choices\n    - seed_indiv # best submission \n    - nb_pop # number of individual\n    - r_mut # ratio of individual who mutate for each family\n    \n    return dataFrame population\n    \n    external argument : data & \n    '''\n    t_fit_0 = time.time()\n    # GENERATION OF FIRST POP:\n    print(\"Generating population : \")\n    # definitions:\n    #if seed_indiv is None:\n    #    seed_indiv = submission\n    if nb_pop is None:\n        nb_pop = NB_FIRST_POP\n    if r_mut is None:\n        r_mut = R_FIRST_MUT\n    #print(\"seed_indiv: \", seed_indiv)\n    print(\"nb_pop: \", nb_pop)\n    print(\"r_mut: \", r_mut)\n    # initialize with same previous best indiv.\n    #df_pop = pd.DataFrame(index=range(0, nb_pop), \n    #                      columns=seed_indiv[\"family_id\"])\n    df_pop = pd.DataFrame(index=range(0, nb_pop), \n                          columns=range(seed_indiv.shape[0]))\n    #print(\"df_pop.shape \", df_pop.shape)\n    #for fam_id in seed_indiv[\"family_id\"]:\n    for fam_id in range(seed_indiv.shape[0]):\n        #df_pop[fam_id] = seed_indiv.at[fam_id,'assigned_day']\n        df_pop[fam_id] = seed_indiv[fam_id]\n\n    # create nb_pop family choices from baseline :\n    # use probabilies\n    # df_pop : contains number choices of all the population of 5000 families\n    # df_pop = f(indiv., family)\n    # for each family, create n choice among their first choice\n    # use day probabilities specific for each family\n    for fam_id in data.index: # data = f(family, num choice)\n        # day current is the old best seed_indiv day for this family\n        #day_curr = seed_indiv.at[fam_id, 'assigned_day']\n        day_curr = seed_indiv[fam_id]\n        vect_pop_mutated = mutation_day_optim(day_curr, fam_id, nb_mut=nb_pop, \n                                        flag_prob=True, \n                                        delta_choice=delta_choice)\n        \n        # apply the new days only a part of pop : r_mut [-]\n        range_mut = np.random.choice(range(0, nb_pop), \n                                     size=int(r_mut*nb_pop))\n        #range_mut = rand_choice_nb(range(0, nb_pop), size=int(r_mut*nb_pop))\n        #print(\"df_pop.shape: \", df_pop.shape)\n        #print(\"range_mut.shape: \", range_mut.shape)\n        #print(\"fam_id \", fam_id)\n        df_pop.loc[range_mut, fam_id] = vect_pop_mutated[range_mut]\n\n    # keep the best : \n    #df_pop.loc[0] = seed_indiv['assigned_day']\n    df_pop.loc[0] = seed_indiv\n    print(\"Generation population is done.\")\n    t_fit_1 = time.time()\n    print(\"Timing : \", t_fit_1 - t_fit_0)\n    \n    return df_pop\n\n@njit\ndef generate_pop_choices_optim(seed_indiv=None, \n                               nb_pop=NB_FIRST_POP, \n                               r_mut=R_FIRST_MUT, \n                               delta_choice=DELTA_CHOICE_FIRST_POP):\n    '''\n    Generate first polulation from one seed individual by family choices\n    - seed_indiv # best submission \n    - nb_pop # number of individual\n    - r_mut # ratio of individual who mutate for each family\n    \n    return array population\n    '''\n    # GENERATION OF FIRST POP:\n    print(\"Generating population : \")\n    # definitions:\n    print(\"nb_pop: \", nb_pop)\n    print(\"r_mut: \", r_mut)\n    print(\"delta choice: \", delta_choice)\n    # initialize with same previous best indiv.\n    arr_pop = np.zeros((nb_pop, seed_indiv.shape[0]), dtype=np.int64)\n    \n    for fam_id in range(seed_indiv.shape[0]):\n        arr_pop[:, fam_id] = seed_indiv[fam_id]\n        \n    # create nb_pop family choices from baseline :\n    # use probabilies\n    # df_pop : contains number choices of all the population of 5000 families\n    # df_pop = f(indiv., family)\n    # for each family, create n choice among their first choice\n    # use day probabilities specific for each family\n    for fam_id in range(seed_indiv.shape[0]): # data = f(family, num choice)\n        # day current is the old best seed_indiv day for this family\n        day_curr = seed_indiv[fam_id]\n        vect_pop_mutated = mutation_day_optim(day_curr, fam_id, nb_mut=nb_pop, \n                                        flag_prob=True, \n                                        delta_choice=delta_choice)\n        \n        # apply the new days only a part of pop : r_mut [-]\n        range_mut = np.random.choice(np.arange(nb_pop), \n                                     size=int(r_mut*nb_pop))\n        arr_pop[range_mut, fam_id] = vect_pop_mutated[range_mut]\n\n    # keep the best : \n    arr_pop[0] = seed_indiv\n    \n    print(\"Generation population is done.\")\n    \n    return arr_pop\n\n@njit\ndef removeDups(arr): \n    # Python 3 program to remove the \n    # duplicates from the array\n    \n    # example : removeDups(np.array([9, 8, 8, 8, 4, 5, 6, 7, 8, 9]))\n    # >> (array([4, 5, 6, 7, 1, 0]), array([4, 5, 6, 7, 8, 9]))\n    arr_u = np.unique(arr)\n    nb_arr = arr.shape[0]\n    nb_arr_u = arr_u.shape[0]\n    if nb_arr == nb_arr_u:\n        indices = np.arange(nb_arr)\n        return indices, arr\n\n    #indices = np.arange(arr.shape[0])\n    indices = np.empty(nb_arr_u, dtype=np.int64)\n    K=0\n    for u_val_curr in arr_u:\n        i_arr = 0\n        for val_curr in arr:\n            if val_curr == u_val_curr:\n                indices[K] = i_arr\n                K=K+1\n                break\n            i_arr = i_arr + 1\n    \n    return indices, arr[indices]\n            \n","1e940e87":"def fun_find_choices_sub(my_days):\n    nb_fam = my_days.shape[0]\n    my_choices = np.empty(nb_fam)\n    for fam_id in range(nb_fam):\n        my_choices[fam_id] = \\\n            find_choice_from_day_optim(my_days[fam_id], fam_id)\n    return my_choices\n\ndef plot_std_choice_pop(df_pop, df_des_choices):\n    ax = []\n    d_plot = 1000\n    for I in range(int(df_pop.shape[1]\/d_plot)):\n        fig = plt.figure(figsize=(16, 4))\n        ax_curr = fig.gca() \n        ax.append(ax_curr)\n\n        error_margin = \\\n            1.96*df_des_choices.loc[\"std\",range(I*d_plot, \n                                                I*d_plot+d_plot)]\/(df_pop.shape[0])**0.5\n\n        plt.plot(range(I*d_plot, I*d_plot+d_plot), error_margin,'.')\n            \n    \n\n\ndef plot_delta_choice_pop(df_pop, df_des_choices):\n    ax = []\n    d_plot = 1000\n    for I in range(int(df_pop.shape[1]\/d_plot)):\n        fig = plt.figure(figsize=(16, 4))\n        ax_curr = fig.gca() \n        ax.append(ax_curr)\n\n        error_margin = \\\n            1.96*df_des_choices.loc[\"std\",range(I*d_plot, \n                                                I*d_plot+d_plot)]\/(df_pop.shape[0])**0.5\n\n        plt.plot(range(I*d_plot, I*d_plot+d_plot), \n                 df_des_choices.loc[\"mean\", range(I*d_plot, \n                                                  I*d_plot+d_plot)], 'o-', alpha=0.25)\n        plt.plot(range(I*d_plot, I*d_plot+d_plot), \n                 df_des_choices.loc[\"mean\", range(I*d_plot, \n                                                  I*d_plot+d_plot)] + error_margin,'.')\n        plt.plot(range(I*d_plot, I*d_plot+d_plot), \n                 df_des_choices.loc[\"mean\", range(I*d_plot, \n                                                  I*d_plot+d_plot)] - error_margin,'.')\n","ba5838df":"fpath = PATH_INPUT + '\/santa-2019-workshop-scheduling\/family_data.csv'\ndata = pd.read_csv(fpath, index_col='family_id')\n\nfpath = PATH_INPUT + '\/santa-2019-workshop-scheduling\/sample_submission.csv'\nsubmission = pd.read_csv(fpath, index_col='family_id')\n\ndata_choice = data.iloc[:,range(0,10)]\ndata_choice.columns = range(0,10)\n# patch for optimization\narr_choice = np.array(data_choice)\ndata_choice.head()\n","e862613d":"data.head()","842dc702":"submission.head()","57ccec19":"#family_size_dict[fam_id]\narr_n_people = data[\"n_people\"].values\n\n@njit\ndef mutation_day_optim(day_curr, fam_id, nb_mut=1, flag_prob=False, \n                       arr_n_people=arr_n_people, delta_choice=DELTA_CHOICE):\n    # function mutation of days : around choices\n    # day_curr -> choice_curr -> range choices -> \n    # choose randomly 1 choice -> 1 day \n    # fam_id = 0\n    # day_curr = 100\n    # mutation_day(day_curr, fam_id, 10)\n    # time cpu = #1=4us & 1000=191us\n    choice_curr = find_choice_from_day_optim(day_curr, fam_id)\n    #print(\"choice_curr: \", choice_curr)\n    range_choices = find_choice_range_optim(choice_curr, \n                                            delta_choice=delta_choice)\n    #print(\"range_choices: \", np.array(range_choices))\n    \n    if flag_prob:\n        #vect_prob = arr_prob[family_size_dict[fam_id]-2, range_choices]\n        vect_prob = arr_prob[arr_n_people[fam_id]-2].take(range_choices)\n        #np.array(df_prob.loc[data.loc[fam_id,\"n_people\"], \n        #                     ['choice_{}'.format(i) for i in range_choices]])\n        vect_prob = vect_prob \/ vect_prob.sum()\n        #print(\"vect_prob: \", vect_prob)\n        choice_new = rand_choice_nb(range_choices, size=nb_mut, \n                                    prob=vect_prob)\n                        #np.random.choice(range_choices, size=nb_mut,\n                        #             p=vect_prob)\n    else:\n        choice_new = np.random.choice(range_choices, size=nb_mut)\n        \n    #print(\"type choice_new: \", type(choice_new))\n    return choose_day_prob_optim(choice_new, fam_id)\n\n","0793027a":"@njit#(parallel=True, fastmath=True)\ndef fun_vect_mut(arr_pop_in, r_pop_mut=R_POP_MUT, r_mut=R_MUT, \n                 delta_choice=DELTA_CHOICE):\n    '''\n    Mutation of all population\n    \n    input arr_pop\n    output new arr_pop\n    \n    Example : \n    \n    arr_test = np.array([[1,2,3,4,5,6,7,8,9,10], [4,5,8,9,5,5,5,5,5,5],\n                    [1,1,1,1,5,5,5,5,5,5], [6,6,6,6,6,9,9,9,9,9]])\n    arr_test = np.concatenate((arr_test, np.minimum(10,arr_test+1)))\n\n    R_POP_MUT =1\n    R_MUT =1\n    DELTA_CHOICE = 2\n    print(\"R_POP_MUT \", R_POP_MUT)\n    print(\"R_MUT \", R_MUT)\n    print(\"DELTA_CHOICE \", DELTA_CHOICE)\n    %timeit arr_test_mut = fun_vect_mut(arr_test, r_pop_mut=R_POP_MUT, r_mut=R_MUT, delta_choice=DELTA_CHOICE)\n    \n    # timeit : 342 \u00b5s \u00b1 31.9 \u00b5s\n    \n    # timeit : 32 ms on pop = 1000,  R_POP=0.1 R_MUT=0.01 DELTA_CHOICE=2\n    '''\n    #print(\"fun_vect_mut : r_pop_mut: \", r_pop_mut)\n    #print(\"fun_vect_mut : r_pop_mut: \", r_mut)\n    #print(\"fun_vect_mut : delta_choice: \", delta_choice)\n    arr_pop = arr_pop_in.copy()\n    nb_fam = arr_pop.shape[1]\n    np_pop = arr_pop.shape[0]\n    nb_mut = int(r_pop_mut*arr_pop.shape[0])\n    # indice of mutated indiv.\n    indice_mut = np.random.choice(np.arange(np_pop), size=nb_mut, \n                                  replace=False)\n    #indice_mut = np.random.permutation(arr_pop.shape[0])\n    #indice_mut = indice_mut[0:nb_mut]\n    \n    # number of family who mutate for each mutated indiv. : R_MUT * nb families\n    nb_fam_mut = int(r_mut*nb_fam)\n    # loop over indice of mutated indiv to apply mutation to number of family\n    # who mutated :\n    #print(\"nb_mut: \", nb_mut)\n    #print(\"nb_fam_mut: \", nb_fam_mut)\n    # for each indiv to mutate, select a random group of families to mutate\n    for idx_mut in prange(indice_mut.shape[0]):\n        indice = indice_mut[idx_mut]\n        # faster version : multiple mutation of same fam is possible\n        #fam_mut = np.random.choice(np.arange(arr_pop.shape[1]), size=nb_fam_mut)\n        # slower version : one familly can mutate only once\n        #fam_mut = np.random.permutation(nb_fam) # better but slower\n        #fam_mut = fam_mut[0:nb_fam_mut] # better but slower\n        # new version\n        fam_mut = np.random.choice(np.arange(nb_fam), replace=False, \n                                   size=nb_fam_mut)\n        # for each family to mutate, find a new day among their choices\n        for idx_fam in np.arange(nb_fam_mut):\n            fam_id = fam_mut[idx_fam]\n            arr_pop[indice, fam_id] = mutation_day_optim(\n                            arr_pop[indice, fam_id], fam_id, nb_mut=1, \n                            flag_prob=True, delta_choice=delta_choice)[0]\n\n    return arr_pop\n","dddf59a4":"family_size_dict = data[['n_people']].to_dict()['n_people']\n\ncols = [f'choice_{i}' for i in range(10)]\nchoice_dict = data[cols].to_dict()\n\nN_DAYS = 100\nMAX_OCCUPANCY = 300\nMIN_OCCUPANCY = 125\n\n# from 100 to 1\ndays = list(range(N_DAYS,0,-1))","953500f3":"def cost_function(prediction, flag_prompt=False):\n\n    penalty = 0\n\n    # We'll use this to count the number of people scheduled each day\n    daily_occupancy = {k:0 for k in days}\n    \n    # Looping over each family; d is the day for each family f\n    for f, d in enumerate(prediction):\n\n        # Using our lookup dictionaries to make simpler variable names\n        n = family_size_dict[f]\n        choice_0 = choice_dict['choice_0'][f]\n        choice_1 = choice_dict['choice_1'][f]\n        choice_2 = choice_dict['choice_2'][f]\n        choice_3 = choice_dict['choice_3'][f]\n        choice_4 = choice_dict['choice_4'][f]\n        choice_5 = choice_dict['choice_5'][f]\n        choice_6 = choice_dict['choice_6'][f]\n        choice_7 = choice_dict['choice_7'][f]\n        choice_8 = choice_dict['choice_8'][f]\n        choice_9 = choice_dict['choice_9'][f]\n\n        # add the family member count to the daily occupancy\n        daily_occupancy[d] += n\n\n        # Calculate the penalty for not getting top preference\n        if d == choice_0:\n            penalty += 0\n        elif d == choice_1:\n            penalty += 50\n        elif d == choice_2:\n            penalty += 50 + 9 * n\n        elif d == choice_3:\n            penalty += 100 + 9 * n\n        elif d == choice_4:\n            penalty += 200 + 9 * n\n        elif d == choice_5:\n            penalty += 200 + 18 * n\n        elif d == choice_6:\n            penalty += 300 + 18 * n\n        elif d == choice_7:\n            penalty += 300 + 36 * n\n        elif d == choice_8:\n            penalty += 400 + 36 * n\n        elif d == choice_9:\n            penalty += 500 + 36 * n + 199 * n\n        else:\n            penalty += 500 + 36 * n + 398 * n\n    if flag_prompt:\n        print(\"penalty for only families: \", penalty)\n    # for each date, check total occupancy\n    #  (using soft constraints instead of hard constraints)\n    for _, v in daily_occupancy.items():\n        if (v > MAX_OCCUPANCY) or (v < MIN_OCCUPANCY):\n            penalty += 100000000\n    if flag_prompt:\n        print(\"daily_occupancy: \", daily_occupancy)\n    # Calculate the accounting cost\n    # The first day (day 100) is treated special\n    accounting_cost = (daily_occupancy[days[0]]-125.0) \/ 400.0 * daily_occupancy[days[0]]**(0.5)\n    # using the max function because the soft constraints might allow occupancy to dip below 125\n    accounting_cost = max(0, accounting_cost)\n    \n    # Loop over the rest of the days, keeping track of previous count\n    yesterday_count = daily_occupancy[days[0]]\n    for day in days[1:]:\n        today_count = daily_occupancy[day]\n        diff = abs(today_count - yesterday_count)\n        accounting_cost += max(0, (daily_occupancy[day]-125.0) \/ 400.0 * daily_occupancy[day]**(0.5 + diff \/ 50.0))\n        yesterday_count = today_count\n    if flag_prompt:\n        print(\"accounting_cost: \", accounting_cost)\n    penalty += accounting_cost\n    \n    if flag_prompt:\n        return penalty, accounting_cost, daily_occupancy\n    else:\n        return penalty","5d7f8d04":"\"\"\"\nV 2.0 : 17\/01\/2020 : G.LANG : limitation when use  accounting_matrix\n# About this kernel\n\nThe `cost_function` in this kernel is roughly 600x faster compared to the original kernel. \nEach function call takes roughly 24 \u00b5s.\n\n## Quick Start\n\n1. Import this utility file: File > Add utility script > Search Notebooks > *Type this notebook name*\n\n2. Copy the code below to get started:\n```\n# Imports\nimport pandas as pd\nimport numpy as np\n\n# The name of the kernel might change, so update this if needed\nfrom santa_s_2019_faster_cost_function_24_s import build_cost_function\n\n# Load Data\nbase_path = '\/kaggle\/input\/santa-workshop-tour-2019\/'\ndata = pd.read_csv(base_path + 'family_data.csv', index_col='family_id')\nsubmission = pd.read_csv(base_path + 'sample_submission.csv', index_col='family_id')\n\n# Build your \"cost_function\"\ncost_function = build_cost_function(data)\n\n# Run it on default submission file\nbest = submission['assigned_day'].values\nstart_score = cost_function(best)\n```\n\nA longer example is provided at the end.\n\n\n## Note\n\nStarting in V12, I decided to make this an utility script instead of a regular notebook.\nI think this is a better use of this kernel, since you can now directly import this into\nyour project and use it just like an API, instead of copy-pasting the lengthy code.\n\nI think that make this into a script forces me to keep the code cleaner.\n\n## Reference\n\n* (Excellent) Original Kernel: https:\/\/www.kaggle.com\/inversion\/santa-s-2019-starter-notebook\n* First kernel that had the idea to use Numba: https:\/\/www.kaggle.com\/nickel\/250x-faster-cost-function-with-numba-jit\n* Another great cost function optimization: https:\/\/www.kaggle.com\/sekrier\/fast-scoring-using-c-52-usec\n* More modular output for intermediate function: https:\/\/www.kaggle.com\/nickel\/santa-s-2019-fast-pythonic-cost-23-s\n\"\"\"\n\nfrom functools import partial\n\n## Intermediate Helper Functions\ndef _build_choice_array(data, n_days):\n    choice_matrix = data.loc[:, 'choice_0': 'choice_9'].values\n    choice_array_num = np.full((data.shape[0], n_days + 1), -1)\n\n    for i, choice in enumerate(choice_matrix):\n        for d, day in enumerate(choice):\n            choice_array_num[i, day] = d\n    \n    return choice_array_num\n\n\ndef _precompute_accounting(max_day_count, max_diff):\n    accounting_matrix = np.zeros((max_day_count+1, max_diff+1))\n    # Start day count at 1 in order to avoid division by 0\n    for today_count in range(1, max_day_count+1):\n        for diff in range(max_diff+1):\n            accounting_cost = (today_count - 125.0) \/ 400.0 * today_count**(0.5 + diff \/ 50.0)\n            accounting_matrix[today_count, diff] = max(0, accounting_cost)\n    \n    return accounting_matrix\n\n\ndef _precompute_penalties(choice_array_num, family_size):\n    penalties_array = np.array([\n        [\n            0,\n            50,\n            50 + 9 * n,\n            100 + 9 * n,\n            200 + 9 * n,\n            200 + 18 * n,\n            300 + 18 * n,\n            300 + 36 * n,\n            400 + 36 * n,\n            500 + 36 * n + 199 * n,\n            500 + 36 * n + 398 * n\n        ]\n        for n in range(family_size.max() + 1)\n    ])\n    \n    penalty_matrix = np.zeros(choice_array_num.shape)\n    N = family_size.shape[0]\n    for i in range(N):\n        choice = choice_array_num[i]\n        n = family_size[i]\n        \n        for j in range(penalty_matrix.shape[1]):\n            penalty_matrix[i, j] = penalties_array[n, choice[j]]\n    \n    return penalty_matrix\n\n\n@njit\ndef _compute_cost_fast(prediction, family_size, days_array, \n                       penalty_matrix, accounting_matrix, \n                       MAX_OCCUPANCY, MIN_OCCUPANCY, N_DAYS):\n    \"\"\"\n    Do not use this function. Please use `build_cost_function` instead to \n    build your own \"cost_function\".\n    \"\"\"\n    N = family_size.shape[0]\n    # We'll use this to count the number of people scheduled each day\n    daily_occupancy = np.zeros(len(days_array)+1, dtype=np.int64)\n    penalty = 0\n    \n    # Looping over each family; d is the day, n is size of that family\n    for i in range(N):\n        n = family_size[i]\n        d = prediction[i]\n        \n        daily_occupancy[d] += n\n        penalty += penalty_matrix[i, d]\n\n    # for each date, check total occupancy \n    # (using soft constraints instead of hard constraints)\n    # Day 0 does not exist, so we do not count it\n    relevant_occupancy = daily_occupancy[1:]\n    \n    # patch : G.L. 12\/01\/2020 - begins\n    incorrect_occupancy =  (relevant_occupancy > MAX_OCCUPANCY) | \\\n        (relevant_occupancy < MIN_OCCUPANCY)\n    for inc_curr in incorrect_occupancy:\n        if inc_curr:\n            #print(\"inc_curr\", inc_curr)\n            penalty += 100000000\n    #print(incorrect_occupancy)\n    # patch : G.L. 12\/01\/2020 - ends\n\n    # Calculate the accounting cost\n    # The first day (day 100) is treated special\n    init_occupancy = daily_occupancy[days_array[0]]\n    accounting_cost = (init_occupancy - 125.0) \/ 400.0 * init_occupancy**(0.5)\n    # using the max function because the soft constraints might allow occupancy to dip below 125\n    accounting_cost = max(0, accounting_cost)\n    \n    # Loop over the rest of the days_array, keeping track of previous count\n    yesterday_count = init_occupancy\n    for day in days_array[1:]:\n        today_count = daily_occupancy[day]\n        diff = abs(today_count - yesterday_count)\n        # patch G.L. : 17\/01\/2020 : limit inputs\n        today_count_lim = max(MIN_OCCUPANCY, min(MAX_OCCUPANCY, today_count))\n        diff_lim = max(0, min(N_DAYS, diff))\n        accounting_cost += accounting_matrix[today_count_lim, diff_lim]\n\n        yesterday_count = today_count\n    #print(\"penalty: \", penalty)   \n    #print(\"accounting_cost: \", accounting_cost)\n    return penalty, accounting_cost, daily_occupancy\n\ndef build_cost_function(data, N_DAYS=100, MAX_OCCUPANCY=300, MIN_OCCUPANCY=125):\n    \"\"\"\n    data (pd.DataFrame): \n        should be the df that contains family information. Preferably load it from \"family_data.csv\".\n    \"\"\"\n    family_size = data.n_people.values\n    days_array = np.arange(N_DAYS, 0, -1)\n\n    # Precompute matrices needed for our cost function\n    choice_array_num = _build_choice_array(data, N_DAYS)\n    penalty_matrix = _precompute_penalties(choice_array_num, family_size)\n    # patch G.L. 12\/01\/2020 - begins\n    accounting_matrix = _precompute_accounting(max_day_count=MAX_OCCUPANCY, \n                                               max_diff=MAX_OCCUPANCY)\n    # patch G.L. 12\/01\/2020 - ends\n    \n    # Partially apply `_compute_cost_fast` so that the resulting partially applied\n    # function only requires prediction as input. E.g.\n    # Non partial applied: score = _compute_cost_fast(prediction, family_size, days_array, ...)\n    # Partially applied: score = cost_function(prediction)\n    def cost_function(prediction: np.ndarray) -> float:\n        penalty, accounting_cost, daily_occupancy = _compute_cost_fast(\n            prediction=prediction,\n            family_size=family_size, \n            days_array=days_array, \n            penalty_matrix=penalty_matrix, \n            accounting_matrix=accounting_matrix,\n            MAX_OCCUPANCY=MAX_OCCUPANCY,\n            MIN_OCCUPANCY=MIN_OCCUPANCY,\n            N_DAYS=N_DAYS\n        )\n        #print('penalty', penalty)\n        #print('accounting_cost', accounting_cost)\n        return penalty + accounting_cost\n    \n    return cost_function  \n\n# Build your \"cost_function\"\ncost_function_optim = build_cost_function(data)","6544bef9":"# version build : AVEC les parametres dans le build \n\n@njit(parallel=True, fastmath=False)\ndef _eval_cost_vect_optim(arr_pop, family_size, days_array, \n                       penalty_matrix, accounting_matrix, \n                       MAX_OCCUPANCY, MIN_OCCUPANCY, N_DAYS):\n    '''\n    Boosting simple by seeking by ranges \n    Simple baseline optimisation following different path range of families.\n    \n    info : speed up to max prop to cost optim  : 24e-6s by cost calculation.\n    \n    input : arr_choice : array of choice days by families\n            best : best submission\n            arr_range : ranges of paths into families\n    return :  arr_sub : array of submissions\n            arr_score : array of their score\/cost\n    \n    example :\n    arr_sub, arr_score = boost_diff_browsing(arr_choice, best, arr_range)\n    \n    # time execution : parallel 17 ms ald 24ms for 1000 cost evaluation \n\n    '''\n    #@njit\n    def _compute_cost_fast_intern(prediction):\n        \"\"\"\n        Do not use this function. Please use `build_cost_function` instead to \n        build your own \"cost_function\".\n        \"\"\"\n        N = family_size.shape[0]\n        # We'll use this to count the number of people scheduled each day\n        daily_occupancy = np.zeros(len(days_array)+1, dtype=np.int64)\n        penalty = 0\n\n        # Looping over each family; d is the day, n is size of that family\n        for i in range(N):\n            n = family_size[i]\n            d = prediction[i]\n\n            daily_occupancy[d] += n\n            penalty += penalty_matrix[i, d]\n\n        # for each date, check total occupancy \n        # (using soft constraints instead of hard constraints)\n        # Day 0 does not exist, so we do not count it\n        relevant_occupancy = daily_occupancy[1:]\n\n        # patch : G.L. 12\/01\/2020 - begins\n        a = (relevant_occupancy > MAX_OCCUPANCY)\n        b = (relevant_occupancy < MIN_OCCUPANCY)\n        incorrect_occupancy = a | b \n        for inc_curr in incorrect_occupancy:\n            if inc_curr:\n                #print(\"inc_curr\", inc_curr)\n                penalty += 100000000\n        #print(incorrect_occupancy)\n        # patch : G.L. 12\/01\/2020 - ends\n\n        # Calculate the accounting cost\n        # The first day (day 100) is treated special\n        init_occupancy = daily_occupancy[days_array[0]]\n        accounting_cost = (init_occupancy - 125.0) \/ \\\n            400.0 * init_occupancy**(0.5)\n        # using the max function because the soft constraints \n        # might allow occupancy to dip below 125\n        accounting_cost = max(0, accounting_cost)\n\n        # Loop over the rest of the days_array, keeping track of previous count\n        yesterday_count = init_occupancy\n        for day in days_array[1:]:\n            today_count = daily_occupancy[day]\n            diff = abs(today_count - yesterday_count)\n            # patch G.L. : 17\/01\/2020 : limit inputs\n            today_count_lim = max(MIN_OCCUPANCY, \n                                  min(MAX_OCCUPANCY, today_count))\n            diff_lim = max(0, min(N_DAYS, diff))\n            accounting_cost += accounting_matrix[today_count_lim, diff_lim]\n\n            yesterday_count = today_count\n        #print(\"penalty: \", penalty)   \n        #print(\"accounting_cost: \", accounting_cost)\n        return penalty, accounting_cost, daily_occupancy\n    \n    \n    arr_score = np.zeros(arr_pop.shape[0])\n    \n    for indice in prange(arr_pop.shape[0]):\n        # patch to accelerate _compute_cost_fast_intern fct (do a copy)\n        arr_curr = arr_pop[indice].copy()\n        penalty, accounting_cost, daily_occupancy  = \\\n            _compute_cost_fast_intern(arr_curr)\n        arr_score[indice] = penalty + accounting_cost\n         \n    return  arr_score\n\n\ndef build_eval_cost_vect_optim(data, N_DAYS=100, MAX_OCCUPANCY=300, \n                                    MIN_OCCUPANCY=125):\n    family_size = data.n_people.values\n    days_array = np.arange(N_DAYS, 0, -1)\n    # Precompute matrices needed for our cost function\n    choice_array_num = _build_choice_array(data, N_DAYS)\n    penalty_matrix = _precompute_penalties(choice_array_num, family_size)\n    # patch G.L. 12\/01\/2020 - begins\n    accounting_matrix = _precompute_accounting(max_day_count=MAX_OCCUPANCY,\n                                       max_diff=MAX_OCCUPANCY)\n    \n    def my_eval_cost_vect_optim(arr_pop):\n        \n        arr_score = _eval_cost_vect_optim(arr_pop, \n            family_size=family_size, \n            days_array=days_array, \n            penalty_matrix=penalty_matrix, \n            accounting_matrix=accounting_matrix,\n            MAX_OCCUPANCY=MAX_OCCUPANCY,\n            MIN_OCCUPANCY=MIN_OCCUPANCY,\n            N_DAYS=N_DAYS)\n    \n        return arr_score\n    \n    return my_eval_cost_vect_optim\n\neval_cost_vect_optim = build_eval_cost_vect_optim(data)","2f895c14":"# version build : AVEC les parametres dans le build \n\n@njit\ndef _boost_diff_browsing_optim(best, arr_range, family_size, days_array, \n                               penalty_matrix, accounting_matrix, \n                               MAX_OCCUPANCY, MIN_OCCUPANCY, N_DAYS, flag_seq,\n                               flag_prompt):\n    '''\n    Boosting simple by seeking by ranges \n    Simple baseline optimisation following different path range of families.\n    \n    info : speed up to max prop to cost optim  : 24e-6s by cost calculation.\n    \n    input : arr_choice : array of choice days by families\n            best : best submission\n            arr_range : ranges of paths into families\n    return :  arr_sub : array of submissions\n            arr_score : array of their score\/cost\n    \n    example :\n    arr_sub, arr_score = boost_diff_browsing(arr_choice, best, arr_range)\n    \n    speed exec : 10.8 s for 10 ranges.\n\n    '''\n    #@njit\n    def _compute_cost_fast_intern(prediction):\n        \"\"\"\n        Do not use this function. Please use `build_cost_function` instead to \n        build your own \"cost_function\".\n        \"\"\"\n        N = family_size.shape[0]\n        # We'll use this to count the number of people scheduled each day\n        daily_occupancy = np.zeros(len(days_array)+1, dtype=np.int64)\n        penalty = 0\n\n        # Looping over each family; d is the day, n is size of that family\n        for i in range(N):\n            n = family_size[i]\n            d = prediction[i]\n\n            daily_occupancy[d] += n\n            penalty += penalty_matrix[i, d]\n\n        # for each date, check total occupancy \n        # (using soft constraints instead of hard constraints)\n        # Day 0 does not exist, so we do not count it\n        relevant_occupancy = daily_occupancy[1:]\n\n        # patch : G.L. 12\/01\/2020 - begins\n        a = (relevant_occupancy > MAX_OCCUPANCY)\n        b = (relevant_occupancy < MIN_OCCUPANCY)\n        incorrect_occupancy = a | b \n        for inc_curr in incorrect_occupancy:\n            if inc_curr:\n                #print(\"inc_curr\", inc_curr)\n                penalty += 100000000\n        #print(incorrect_occupancy)\n        # patch : G.L. 12\/01\/2020 - ends\n\n        # Calculate the accounting cost\n        # The first day (day 100) is treated special\n        init_occupancy = daily_occupancy[days_array[0]]\n        accounting_cost = (init_occupancy - 125.0) \/ \\\n            400.0 * init_occupancy**(0.5)\n        # using the max function because the soft constraints \n        # might allow occupancy to dip below 125\n        accounting_cost = max(0, accounting_cost)\n\n        # Loop over the rest of the days_array, keeping track of previous count\n        yesterday_count = init_occupancy\n        for day in days_array[1:]:\n            today_count = daily_occupancy[day]\n            diff = abs(today_count - yesterday_count)\n            # patch G.L. : 17\/01\/2020 : limit inputs\n            today_count_lim = max(MIN_OCCUPANCY, \n                                  min(MAX_OCCUPANCY, today_count))\n            diff_lim = max(0, min(N_DAYS, diff))\n            accounting_cost += accounting_matrix[today_count_lim, diff_lim]\n\n            yesterday_count = today_count\n        #print(\"penalty: \", penalty)   \n        #print(\"accounting_cost: \", accounting_cost)\n        return penalty, accounting_cost, daily_occupancy\n    \n    \n    # Create baselines # optimized version\n    penalty, accounting_cost, daily_occupancy  = _compute_cost_fast_intern(best)\n    start_cost = penalty + accounting_cost\n    #start_cost = cost_function_optim(best)\n    if flag_prompt:\n        print(\"Start cost: \", start_cost)\n    \n    # prepare output : best submission seeking in different range walk around\n    arr_sub = np.zeros((arr_range.shape[0], best.shape[0])).astype(np.int64)\n    arr_score = np.zeros(arr_range.shape[0])\n    new = best.copy() # TEST\n    for indice in prange(arr_range.shape[0]):\n\n        # initiate first inviduate\n        if flag_seq == False:\n            # if mode where each range is treated independently (no seq)\n            # we reset the best to the first best as input arg.\n            new = best.copy() \n        \n        cost_best = start_cost\n        \n        # choose current range in df_range\n        range_optim = arr_range[indice]\n        # loop over each family with this current range       \n        for fam_id in range_optim:\n            # loop over each family choice\n            for pick in range(10):\n                day = arr_choice[fam_id, pick]\n                temp = new.copy()\n                temp[fam_id] = day # add in the new pick\n        \n                penalty, accounting_cost, daily_occupancy = \\\n                    _compute_cost_fast_intern(temp) #test cost\n                cost_curr =  penalty + accounting_cost\n                #cost_curr = cost_function_optim(temp)\n                # if best cost found save it\n                if cost_curr < cost_best:\n                    new = temp.copy()\n                    cost_best = cost_curr\n                    #print(\"Current best cost: \", cost_best)\n\n        arr_sub[indice] = new\n        arr_score[indice] = cost_best\n        if flag_prompt:\n            print(\"Score: \", cost_best)\n          \n    return arr_sub, arr_score\n\n\ndef build_boost_diff_browsing_optim(data, flag_seq=True, flag_prompt=True,\n                                    N_DAYS=100, \n                                    MAX_OCCUPANCY=300, \n                                    MIN_OCCUPANCY=125):\n    family_size = data.n_people.values\n    days_array = np.arange(N_DAYS, 0, -1)\n    # Precompute matrices needed for our cost function\n    choice_array_num = _build_choice_array(data, N_DAYS)\n    penalty_matrix = _precompute_penalties(choice_array_num, family_size)\n    # patch G.L. 12\/01\/2020 - begins\n    accounting_matrix = _precompute_accounting(max_day_count=MAX_OCCUPANCY,\n                                       max_diff=MAX_OCCUPANCY)\n    \n    def my_boost_diff_browsing_optim(best, arr_range):\n        \n        arr_sub, arr_score = _boost_diff_browsing_optim(best, arr_range, \n                                                        family_size=family_size, \n            days_array=days_array, \n            penalty_matrix=penalty_matrix, \n            accounting_matrix=accounting_matrix,\n            MAX_OCCUPANCY=MAX_OCCUPANCY,\n            MIN_OCCUPANCY=MIN_OCCUPANCY,\n            N_DAYS=N_DAYS,\n            flag_seq=flag_seq,\n            flag_prompt=flag_prompt)\n    \n        return arr_sub, arr_score\n    \n    return my_boost_diff_browsing_optim\n# boost seq from one best along several range as input \nboost_diff_browsing_optim = build_boost_diff_browsing_optim(data)","72e2e1ba":"family_size = data.n_people.values\ndays_array = np.arange(N_DAYS, 0, -1)\n# Precompute matrices needed for our cost function\nchoice_array_num = _build_choice_array(data, N_DAYS)\npenalty_matrix = _precompute_penalties(choice_array_num, family_size)\n# patch G.L. 12\/01\/2020 - begins\naccounting_matrix = _precompute_accounting(max_day_count=MAX_OCCUPANCY,\n                                   max_diff=MAX_OCCUPANCY)\n\n@njit(parallel=True, fastmath=True)\ndef boost_optim_one_by_one(best, arr_range):\n    '''\n    Calculation optim cost from one best indiv (submission) seeking along \n    several ranges (arr_range) but not sequential.\n    '''\n    arr_pop = np.zeros((arr_range.shape[0], best.shape[0]), dtype=np.int64)\n    arr_score = np.zeros(arr_range.shape[0], dtype=np.float64)\n    for indice in prange(arr_range.shape[0]):\n        arr_pop_curr, arr_score_curr = \\\n            _boost_diff_browsing_optim(best, \n                                       arr_range[indice:indice+1], \n                                       family_size, \n                                       days_array, \n                                       penalty_matrix, \n                                       accounting_matrix, \n                       MAX_OCCUPANCY, MIN_OCCUPANCY, N_DAYS, flag_seq=False, \n                                      flag_prompt=False)\n        arr_pop[indice] = arr_pop_curr\n        arr_score[indice] = arr_score_curr[0]\n    return arr_pop, arr_score\n\n@njit(parallel=True, fastmath=True)\ndef boost_optim_one_by_one_multi(arr_pop_in, arr_range):\n    '''\n    Calculation optim cost from several best indiv (arr_pop_in) seeking along \n    arr_range not sequential.\n    '''\n    arr_pop = arr_pop_in.copy()#np.zeros((arr_pop_in.shape[0], best.shape[0]), dtype=np.int64)\n    arr_score = np.zeros(arr_pop.shape[0], dtype=np.float64)\n    for indice in prange(arr_pop_in.shape[0]):\n        arr_pop_curr, arr_score_curr = \\\n            _boost_diff_browsing_optim(arr_pop_in[indice], \n                                       arr_range, \n                                       family_size, \n                                       days_array, \n                                       penalty_matrix, \n                                       accounting_matrix, \n                       MAX_OCCUPANCY, MIN_OCCUPANCY, N_DAYS, flag_seq=False, \n                                      flag_prompt=False)\n        arr_pop[indice] = arr_pop_curr\n        arr_score[indice] = arr_score_curr[0]\n    return arr_pop, arr_score\n\n@njit(parallel=True, fastmath=True)\ndef boost_optim_one_by_one_epochs(arr_pop_in, n_epochs=100, nb_epoch_check=10,\n                                  nb_try_not_best_max=2):\n    '''\n    Calculation simple optim cost from several best indiv (arr_pop_in) seeking \n    along random range several times sequentially (n_epochs).\n    '''\n    arr_pop = arr_pop_in.copy()#np.zeros((arr_pop_in.shape[0], best.shape[0]), dtype=np.int64)\n    nb_pop = arr_pop.shape[0]\n    nb_fam = arr_pop.shape[1]\n    arr_score = np.zeros(nb_pop, dtype=np.float64)\n    if n_epochs < nb_epoch_check:\n        nb_epoch_check = n_epochs\n    nb_check = int(np.ceil(n_epochs\/nb_epoch_check))   \n    print(\"nb_check: \", nb_check)\n    for indice in prange(nb_pop):\n        # For each check\n        best = arr_pop_in[indice].copy()\n        nb_try_not_best = 0\n        for i_check in np.arange(nb_check):\n            print(\"Indiv #\", indice)\n            print(\"         check #\", i_check)\n            # calculate number of ranges to test\n            if (i_check + 1)* nb_epoch_check > n_epochs:\n                nb_epochs_curr = n_epochs - (i_check * nb_epoch_check)\n            else:\n                nb_epochs_curr = nb_epoch_check\n            #print(\"nb_epochs_curr: \", nb_epochs_curr)    \n            # create nb_epochs_curr ranges    \n            arr_range = np.empty((nb_epochs_curr, nb_fam), dtype=np.int64) \n            for i_epoch in np.arange(nb_epochs_curr):\n                arr_range[i_epoch] = np.random.permutation(np.arange(nb_fam))\n                \n            # optimize sequentially to find best for one indiv\n            arr_pop_curr, arr_score_curr = \\\n                _boost_diff_browsing_optim(best, \n                                           arr_range, \n                                           family_size, \n                                           days_array, \n                                           penalty_matrix, \n                                           accounting_matrix, \n                           MAX_OCCUPANCY, MIN_OCCUPANCY, N_DAYS, flag_seq=True, \n                                          flag_prompt=False)\n            #print(\"arr_score_curr: \", arr_score_curr)\n            \n            best_score_curr = arr_score_curr.min()\n            \n            if i_check > 0:\n                if best_score_curr >= arr_score[indice]:\n                    print(\"Not better for Indiv #\", indice)\n                    nb_try_not_best +=1 \n                    if nb_try_not_best > nb_try_not_best_max:\n                        print(\"Early stop for Indiv #\", indice)\n                        break\n            arr_score[indice] = arr_score_curr.min()\n            arr_pop[indice] = arr_pop_curr[np.argmin(arr_score_curr)].copy()\n            best = arr_pop[indice].copy()\n        print(\"Best cost for indiv #\", indice, \":\", arr_score[indice])\n    return arr_pop, arr_score","2ea9cbe1":"'''\nData preparation\n'''\n# for KAGGLE, GOOGLE COLAB & LOCAL compatibility\n# copy of familly data \n# Source path \nsource = PATH_INPUT + '\/santa-2019-workshop-scheduling\/family_data.csv'\n  \n# Destination path \ndestination = os.getcwd() + \"\/family_data.csv\"\n  \n# Copy the content of \n# source to destination \nif not os.path.exists(destination):\n    import shutil\n    dest = shutil.copyfile(source, destination) \n    print(\"Copy ok\")\nelse:\n    print(\"file exists\")\n","8652c539":"%%writefile stochprodsearch_03.cpp\n#include <array>\n#include <cassert>\n#include <algorithm>\n#include <cmath>\n#include <fstream>\n#include <iostream>\n#include <vector>\n#include <thread>\n#include <atomic>\n#include <random>\n#include <string.h>\nusing namespace std;\n#include <chrono>\nusing namespace std::chrono;\n\n\/\/ V1.1 : 16\/02\/2020 : extend range to choice 10\n\n\/\/int N_JOBS = 4;\n\/\/int END_TIME = 1*N_JOBS;\/\/in minutes\n\nauto START_TIME = high_resolution_clock::now();\n\/\/constexpr array<uint8_t, 4> DISTRIBUTION{2, 2, 3, 5}; \/\/ 82400 -> 72172.8 in 8h (KAGGLE V4)\nconstexpr array<uint8_t, 6> DISTRIBUTION{2, 2, 2, 2, 3, 5}; \/\/ 82400 -> 72060.8 in 8h (KAGGLE V5)\n\/\/ constexpr array<uint8_t, 15> DISTRIBUTION{2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 3, 5};  \/\/ You can setup how many families you need for swaps and what best choice use for each family\n\/\/ {2, 5} it's mean the first random family will brute force for choices 1-2 and the second random family will brute force for choices 1-5\n\nconstexpr int MAX_OCCUPANCY = 300;\nconstexpr int MIN_OCCUPANCY = 125;\nconstexpr int BEST_N = 10;\narray<uint8_t, 5000> n_people;\narray<array<uint8_t, 11>, 5000> choices;\narray<array<uint16_t, 11>, 5000> PCOSTM;\narray<array<double, 176>, 176> ACOSTM;\n\nstruct Index {\n    Index(array<int, 5000> assigned_days_) : assigned_days(assigned_days_)  {\n        setup();\n    }\n    array<int, 5000> assigned_days;\n    array<uint16_t, 100> daily_occupancy_{};\n    int preference_cost_ = 0;\n    void setup() {\n        preference_cost_ = 0;\n        daily_occupancy_.fill(0);\n        for (int j = 0; j < assigned_days.size(); ++j) {\n            daily_occupancy_[choices[j][assigned_days[j]]] += n_people[j];\n            preference_cost_ += PCOSTM[j][assigned_days[j]];\n        }\n    }\n    double calc(const array<uint16_t, 5000>& indices, const array<uint8_t, DISTRIBUTION.size()>& change) {\n        double accounting_penalty = 0.0;\n        auto daily_occupancy = daily_occupancy_;\n        int preference_cost = preference_cost_;\n        for (int i = 0; i < DISTRIBUTION.size(); ++i) {\n            int j = indices[i];\n            daily_occupancy[choices[j][assigned_days[j]]] -= n_people[j];\n            daily_occupancy[choices[j][       change[i]]] += n_people[j];\n            \n            preference_cost += PCOSTM[j][change[i]] - PCOSTM[j][assigned_days[j]];\n        }\n\n        for (auto occupancy : daily_occupancy)\n            if (occupancy < MIN_OCCUPANCY) \n                return 1e12*(MIN_OCCUPANCY-occupancy);\n            else if (occupancy > MAX_OCCUPANCY)\n                return 1e12*(occupancy - MAX_OCCUPANCY);\n\n        for (int day = 0; day < 99; ++day)\n            accounting_penalty += ACOSTM[daily_occupancy[day]-125][daily_occupancy[day+1]-125];\n\n        accounting_penalty += ACOSTM[daily_occupancy[99]-125][daily_occupancy[99]-125];\n        return preference_cost + accounting_penalty;\n    }\n    void reindex(const array<uint16_t, DISTRIBUTION.size()>& indices, const array<uint8_t, DISTRIBUTION.size()>& change) {\n        for (int i = 0; i < DISTRIBUTION.size(); ++i) {\n            assigned_days[indices[i]] = change[i];\n        }\n        setup();\n    }\n};\n\nstatic std::atomic<bool> flag(false);\nstatic Index global_index({});\n\nbool time_exit_fn(int end_time){\n    return duration_cast<seconds>(high_resolution_clock::now()-START_TIME).count() < end_time;\n}\n\nvoid init_data() {\n    ifstream in(\"family_data.csv\");\n    \n    assert(in && \"family_data.csv\");\n    string header;\n    int n,x;\n    char comma;\n    getline(in, header);\n    for (int fam_id = 0; fam_id < choices.size(); ++fam_id) {\n        in >> x >> comma;\n        for (int n_choice = 0; n_choice < 10; ++n_choice) {\n            in >> x >> comma;\n            choices[fam_id][n_choice] = x-1;\n        }\n        in >> n;\n        n_people[fam_id] = n;\n        \/\/std::cout << fam_id << \", \" << (int)n_people[fam_id] << endl;\n    }\n    array<int, 11> pc{0, 50, 50, 100, 200, 200, 300, 300, 400, 500, 500};\n    array<int, 11> pn{0,  0,  9,   9,   9,  18,  18,  36,  36, 235, 434};\n    \/\/cout << endl << \"PCOSTM:\";\n    for (int j = 0; j < PCOSTM.size(); ++j) {\n        \/\/cout << endl << j << \": \";\n        for (int i = 0; i < 11; ++i) {\n            PCOSTM[j][i] = pc[i] + pn[i] * n_people[j];\n            \/\/cout << PCOSTM[j][i] << \" \";\n        }\n    }\n    \n    for (int i = 0; i < 176; ++i)\n        for (int j = 0; j < 176; ++j)\n            ACOSTM[i][j] = i * pow(i+125, 0.5 + abs(i-j) \/ 50.0) \/ 400.0;\n}\n\/\/ not used (keep for later add-on ?)\narray<int, 5000> read_submission(string filename) {\n    ifstream in(filename);\n    assert(in && \"submission.csv\");\n    array<int, 5000> assigned_day{};\n    string header;\n    int id, x;\n    char comma;\n    getline(in, header);\n    for (int j = 0; j < choices.size(); ++j) {\n        in >> id >> comma >> x;\n        assigned_day[j] = x-1;\n        auto it = find(begin(choices[j]), end(choices[j]), assigned_day[j]);\n        if (it != end(choices[j]))\n            assigned_day[j] = distance(begin(choices[j]), it);\n    }\n    return assigned_day;\n}\n\n\ndouble calc(const array<int, 5000>& assigned_days, bool print=false) {\n    int preference_cost = 0;\n    double accounting_penalty = 0.0;\n    array<uint16_t, 100> daily_occupancy{};\n    for (int j = 0; j < assigned_days.size(); ++j) {\n        preference_cost += PCOSTM[j][assigned_days[j]];\n        daily_occupancy[choices[j][assigned_days[j]]] += n_people[j];\n        \/\/cout << j  << \", \" << (int)assigned_days[j] << \", \" << (int)n_people[j] << endl;\n        \/\/cout << j << \", \" << n_people[j] << endl;\n    }\n    int K=1;\n    for (auto occupancy : daily_occupancy) {\n        if (occupancy < MIN_OCCUPANCY) {\n            \/\/std::cout << \"occ. day \" << K << \"=\" << occupancy << \" ! MIN_OCC reached\" << endl;\n            return 1e12*(MIN_OCCUPANCY-occupancy);\n        } else if (occupancy > MAX_OCCUPANCY) {\n            \/\/std::cout << \"occ. day \" << K << \"=\" << occupancy << \" ! MAX_OCC reached\" << endl;\n            return 1e12*(occupancy - MAX_OCCUPANCY);\n        }\n        K = K+1;\n    }\n\n    for (int day = 0; day < 99; ++day)\n        accounting_penalty += ACOSTM[daily_occupancy[day]-125][daily_occupancy[day+1]-125];\n\n    accounting_penalty += ACOSTM[daily_occupancy[99]-125][daily_occupancy[99]-125];\n    if (print) {\n        cout << preference_cost+accounting_penalty << \": pc: \" << preference_cost << \" + ac: \" << accounting_penalty << endl;\n    }\n    return preference_cost + accounting_penalty;\n}\n\nvoid save_sub(const array<int, 5000>& assigned_day) {\n    ofstream out(\"submission.csv\");\n    out << \"family_id,assigned_day\" << endl;\n    for (int i = 0; i < assigned_day.size(); ++i)\n        out << i << \",\" << choices[i][assigned_day[i]]+1 << endl;\n}\n        \nconst vector<array<uint8_t, DISTRIBUTION.size()>> changes = []() {\n    vector<array<uint8_t, DISTRIBUTION.size()>> arr;\n    array<uint8_t, DISTRIBUTION.size()> tmp{};\n    for (int i = 0; true; ++i) {\n        arr.push_back(tmp);\n        tmp[0] += 1;\n        for (int j = 0; j < DISTRIBUTION.size(); ++j)\n            if (tmp[j] >= DISTRIBUTION[j]) {\n                if (j >= DISTRIBUTION.size()-1)\n                    return arr;\n                tmp[j] = 0;\n                ++tmp[j+1];\n            }\n    }\n    return arr;\n}();\n\n\/\/template<class ExitFunction>\nvoid stochastic_product_search(Index index, int end_time) { \/\/ 15'360'000it\/s  65ns\/it  0.065\u00b5s\/it\n    double best_local_score = calc(index.assigned_days);\n    thread_local std::mt19937 gen(std::random_device{}());\n    uniform_int_distribution<> dis(0, 4999);\n    array<uint16_t, 5000> indices;\n    iota(begin(indices), end(indices), 0);\n    array<uint16_t, DISTRIBUTION.size()> best_indices{};\n    array<uint8_t, DISTRIBUTION.size()> best_change{};\n    for (;time_exit_fn(end_time);) {\n        bool found_better = false;\n        for (int k = 0; k < BEST_N; ++k) {\n            for (int i = 0; i < DISTRIBUTION.size(); ++i) \/\/random swap for n first families\n                swap(indices[i], indices[dis(gen)]);\n            for (const auto& change : changes) {\n                auto score = index.calc(indices, change);\n                if (score < best_local_score) {\n                    found_better = true;\n                    best_local_score = score;\n                    best_change = change;\n                    copy_n(begin(indices), DISTRIBUTION.size(), begin(best_indices));\n                }\n            }\n        }\n\n        if (flag.load() == true){\n            return;\n        }\n\n        if (found_better && flag.load() == false) { \/\/ reindex from N best if found better\n            flag = true;\n\n            index.reindex(best_indices, best_change);\n            global_index = index;\n            return;\n        }\n    }\n}\n\n\/\/ output function : for python ctypes, needed to add extern \"C\"\nextern \"C\" int* sps(int* days, int duration=6, int n_jobs=4) {\n    \n    int N_JOBS = n_jobs;\n    int END_TIME = duration*N_JOBS; \/\/in seconds\n    std::cout << \"duration = \" << duration << endl; \/\/ debug\n    std::cout << \"END_TIME = \" << END_TIME << endl; \/\/ debug\n    \n    init_data();\n    \/\/auto assigned_day = read_submission(\"..\/input\/first-simple-optimization-santa-submission\/submission_535295.5188186927.csv\");\n    \/\/auto assigned_day = read_submission(\"..\/input\/best-result-with-algo-genetic\/submission_85181.22055864273.csv\");\n    \/\/auto assigned_day = read_submission(\"..\/input\/santa-workshop-tour-2019\/sample_submission.csv\");\n    \/\/auto assigned_day = read_submission(\"submission_82477.85928353199.csv\");\n    \/\/auto assigned_day = read_submission(\"submission_100135.53956452094.csv\");\n    \/\/auto assigned_day = read_submission(\"submission_535295.5188186927.csv\");\n    \n    \/\/ read input from python\n    array<int, 5000> assigned_day{};\n    \/\/ int pointer instead of array format for output to python : it is the best solution found\n    int *assigned_days_out = new int[5000];\n    \n    \/\/ read python input pointer days to good format for C++\n    \/\/std::cout << \"current choices:\";\n    int K = 0;\n    for (int i = 0; i < 2*5000; i+=2) {\n        \/\/std::cout << \" \" << days[i] << \", \";\n        assigned_day[K] = days[i] - 1;\n        \/\/auto it = find(begin(choices[K]), end(choices[K]), assigned_day[K]);\n        auto it = find(begin(choices[K]), end(choices[K])-1, assigned_day[K]);\n        if (it != end(choices[K])-1) {\n            assigned_day[K] = distance(begin(choices[K]), it);\n            \/\/cout << \" \" << K << \": \" << (int)assigned_day[K];\n        } else {\n            \/\/cout << \" \" << K << \": \" << (int)assigned_day[K]; \n            choices[K][10] = days[i] - 1;\n            assigned_day[K] = 10;\n        }\n        K = K + 1;\n    }\n    \n    Index index(assigned_day);\n    global_index = index;\n    std::cout << \"current cost: \";\n    calc(index.assigned_days, true);\n    std::cout << endl << \"Start s.p.s V1.1...\" << endl;\n    for(;time_exit_fn(END_TIME);){\n\n        std::thread threads[N_JOBS];\n        for(int i = 0; i < N_JOBS; i++){\n            threads[i] = std::thread(stochastic_product_search, index, END_TIME);\n        }\n        for(int i = 0; i < N_JOBS; i++){\n            threads[i].join();\n        }\n\n        auto best_score = calc(global_index.assigned_days, false);\n\n        flag = false;\n        index = global_index;      \n    }\n    \n    \/\/ display best cost : \n    std::cout << \"Best cost found: \";\n    calc(global_index.assigned_days, true);\n    \/\/ creation of output for python\n    \/\/std::cout << endl; \/\/ for debug\n    for (int i = 0; i < global_index.assigned_days.size(); ++i) {\n        assigned_days_out[i] = choices[i][global_index.assigned_days[i]]+1;\n        \/\/std::cout << assigned_days_out[i] << \", \"; \/\/ for debug\n    }\n    \n    return assigned_days_out;\n    \/\/return 0;\n}\n","2d57c810":"if MY_PLATFORM == \"Linux\":\n    print(\"Linux compilation...\")\n    !g++ -c -pthread -O3 -std=c++17 -fPIC stochprodsearch_03.cpp -o stochprodsearch_03_linux.o\n    !g++ -shared -Wl,-soname,libstochprodsearch_03.so -o libstochprodsearch_03.so  stochprodsearch_03_linux.o\nelif MY_PLATFORM == \"Darwin\":\n    !g++ -c -pthread -O3 -std=c++17 -fPIC stochprodsearch_03.cpp -o stochprodsearch_03.o\n    !g++ -dynamiclib -undefined suppress -flat_namespace stochprodsearch_03.o -o libstochprodsearch_03.dylib\nelif MY_PLATFORM == \"Windows\":\n  # TODO\n  pass\nelse:\n    print(\"Unknow platform ! \")","6bfce850":"%%writefile stochprodsearch_03.py\nimport platform\nimport pandas as pd\nimport numpy as np\nfrom numpy.ctypeslib import ndpointer\nimport ctypes\nfrom ctypes import cdll\nfrom ctypes import c_char_p\nfrom ctypes import c_double\nfrom ctypes import c_int\n'''\nThis script link C++ executable as a ctypes library in python.\nBut because lib ctypes doesnt execute well twice when used directly in another\npython script, it is needed to used a dirty csv file as output. \n \nHow to use examples : \n- From command line: 6 sec and 4 threads:\n>> python stochprodsearch_03.py my_submission.csv 6 4 \n- From notebooks : run_stochprodsearch(arr_best_curr, end_time=6, nb_jobs=4)\n'''\n# DEFINTION : \nOUTPOUT_FILE_NAME = \"submission_from_sps.csv\" # TO BE CHANGED !!!\n# select current platform\nMY_PLATFORM = platform.system()\n#Linux: Linux\n#Mac: Darwin\n#Windows: Windows\n# load lib\nif MY_PLATFORM == \"Darwin\":\n    lib = cdll.LoadLibrary('.\/libstochprodsearch_03.dylib')\nelif MY_PLATFORM == \"Linux\":\n    lib = cdll.LoadLibrary('.\/libstochprodsearch_03.so')\nelif MY_PLATFORM == \"Windows\":\n    lib = cdll.LoadLibrary('.\/libstochprodsearch_03.dll') \nelse:\n    print(\"Unknow platform ! \")\n    lib = None\n# declare ctypes pointer format for output from C++\nc_int_p = ctypes.POINTER(ctypes.c_int)\n# prepare output from C++ to numpy array of size 5000 \nif lib is not None:\n    lib.sps.restype = ndpointer(dtype=ctypes.c_int, shape=(5000,))\n\ndef sps(arr_in, end_time=6, nb_jobs=4):\n    '''\n    Stochastic product search ctypes function to link with C++ code\n    \n    arr_in : initial days assigned numpy array\n    end_time : duration of search in seconds\n    nb_jobs : number of threads used for searching\n    '''\n\n    # cast to integer (security : if needed)\n    arr_in = arr_in.astype(np.int)\n\n    # prepare input for C++ to integer pointer \n    arr_in_p = arr_in.ctypes.data_as(c_int_p)\n    \n    # execute the optimisation product search with inital value arr_in_p\n    arr_best_sps = lib.sps(arr_in_p, c_int(end_time), c_int(nb_jobs))\n    \n    return arr_best_sps\n    #return lib.sps(arr_in_p)\n    \nif __name__ == \"__main__\":\n    import sys\n    try:\n        csv = sys.argv[1]\n    except:\n        csv = 'submission_100135.53956452094.csv' \n    try:\n        end_time = int(sys.argv[2])\n    except:\n        end_time= 6\n    try:\n        nb_jobs = int(sys.argv[3])\n    except:\n        nb_jobs = 4\n        \n    submission_test = pd.read_csv(csv, \n                         index_col='family_id')\n    arr_curr = submission_test[\"assigned_day\"].values\n    \n    print(\"arr_curr : \", arr_curr)\n    # run stochastic product search\n    arr_best = sps(arr_curr, end_time, nb_jobs)\n    print(\"Days : \", arr_best)\n    # prepare ouput data\n    submission_final = submission_test.copy()\n    submission_final[\"assigned_day\"] = arr_best\n    # FALLBACK : Export res in CSV format (to be read by notebook)\n    submission_final.to_csv(OUTPOUT_FILE_NAME)","ed137453":"%%time\ntry:\n    !python stochprodsearch_03.py ..\/input\/santa-2019-for-my-exploration\/submission_71447.87946293628_for_sps.csv 6 4\nexcept:\n    print(\"Module test failed : Try to change csv input file!\")","478e7653":"def run_stochprodsearch(arr_best_curr, end_time=6, nb_jobs=4):\n    '''\n    Run stochastic product search from python\n    (fallback solution because problem with ctypes)\n    '''\n    \n    cost_best = cost_function_optim(arr_best_curr)\n    \n    csv_in = \"submission_{}_for_sps.csv\".format(cost_best)\n    csv_out = \"submission_from_sps.csv\"\n    \n    submission_in = pd.DataFrame(columns=[\"assigned_day\"])\n    submission_in[\"assigned_day\"] = arr_best_curr\n    submission_in.index.name = 'family_id'\n    submission_in.to_csv(csv_in)    \n    \n    os.system(\"python stochprodsearch_03.py {} {} {}\".format(csv_in ,end_time,\n                                                            nb_jobs))\n    csv_out = \"submission_from_sps.csv\"\n    submission_from_sps = pd.read_csv(csv_out, index_col='family_id')\n    \n    return submission_from_sps[\"assigned_day\"].values","7787eced":"# show how people choose days : \n# 5 first choices \n# 5 last choices\n#data\ndf_day = pd.DataFrame(index=range(1,101))\ndf_day[\"all_choices\"] = 0\ndf_day[\"first_choices\"] = 0\ndf_day[\"mid_choices\"] = 0\ndf_day[\"last_choices\"] = 0\nlist_choice_all = ['choice_{}'.format(n) for n in range(0, 10)]\nlist_choice_first = ['choice_{}'.format(n) for n in range(0, 3)]\nlist_choice_mid = ['choice_{}'.format(n) for n in range(3, 7)]\nlist_choice_last = ['choice_{}'.format(n) for n in range(7, 10)]\n\n# for each first choices, add to each days the number of people\nfor choice in list_choice_all:\n    for indice in data.index:\n        df_day.loc[data.at[indice, choice], \n                   \"all_choices\"] += data.at[indice, \"n_people\"]\n        \nfor choice in list_choice_first:\n    for indice in data.index:\n        df_day.loc[data.at[indice, choice], \n                   \"first_choices\"] += data.at[indice, \"n_people\"]\n        \nfor choice in list_choice_mid:\n    for indice in data.index:\n        df_day.loc[data.at[indice, choice], \n                   \"mid_choices\"] += data.at[indice, \"n_people\"]\n        \nfor choice in list_choice_last:\n    for indice in data.index:\n        df_day.loc[data.at[indice, choice], \n                   \"last_choices\"] += data.at[indice, \"n_people\"]\n        \ndf_day.head()","8c7d78e5":"fig = plt.figure(figsize=(12, 22)) \nax1 = fig.gca()\ndf_day[\"all_choices\"].plot.barh(ax=ax1)\nax1.set_xlabel(\"max nb people\")\nax1.set_ylabel(\"number of days before Christmas [days]\");\nax1.set_title(\"all choices\");","b106ed03":"fig = plt.figure(figsize=(12, 22)) \n#plt.title(\"potential people vs choices\")\n\nax1 = fig.add_subplot(1,3,1)\ndf_day[\"first_choices\"].plot.barh(ax=ax1)\nax1.set_xlabel(\"max nb people\")\nax1.set_ylabel(\"number of days before Christmas [days]\");\nax1.set_title(\"first choices\")\n\nax2 = fig.add_subplot(1,3,2)\ndf_day[\"mid_choices\"].plot.barh(ax=ax2)\nax2.set_xlabel(\"max nb people\")\nax2.set_title(\"mid choices\")\n\nax3 = fig.add_subplot(1,3,3)\ndf_day[\"last_choices\"].plot.barh(ax=ax3)\nax3.set_xlabel(\"max nb people\")\nax3.set_title(\"last choices\");","13426e8c":"fig = plt.figure(figsize=(12, 6)) \n\ndf_day[\"first_choices\"].plot(label=\"first_choices [1-3]\")\n\ndf_day[\"mid_choices\"].plot(label=\"mid_choices [4-7]\")\n\ndf_day[\"last_choices\"].plot(label=\"last_choices [8-10]\")\nplt.legend(loc='upper right');\nax=fig.gca()\nax.set_ylabel(\"attendance\")\nax.set_xlabel(\"number of days before Christmas [days]\");\nax.set_title(\"Maximum of attendance by days\")","20ca8546":"df_prob_day = pd.DataFrame(df_day[\"all_choices\"])\ndf_prob_day[\"prob\"] = 1\/df_prob_day[\"all_choices\"]\ndf_prob_day[\"prob\"] = df_prob_day[\"prob\"] \/ df_prob_day[\"prob\"].sum()\ndf_prob_day[\"prob\"].sum()","3cf326dc":"df_prob_day.head()","122cf504":"#df_prob_day[\"prob\"].plot.barh()\nfig = plt.figure(figsize=(12, 22)) \nax1 = fig.gca()\ndf_prob_day[\"prob\"].plot.barh(ax=ax1)\nax1.set_xlabel(\"prob [-]\")\nax1.set_ylabel(\"number of days before Christmas [days]\");\nax1.set_title(\"Probabilities for each days\");","39cfcb68":"def cost_family(n=1, choice=0):\n    # Calculate the penalty for not getting top preference\n    penalty = 0\n    if choice == 0:\n        penalty += 0\n    elif choice == 1:\n        penalty += 50\n    elif choice == 2:\n        penalty += 50 + 9 * n\n    elif choice == 3:\n        penalty += 100 + 9 * n\n    elif choice == 4:\n        penalty += 200 + 9 * n\n    elif choice == 5:\n        penalty += 200 + 18 * n\n    elif choice == 6:\n        penalty += 300 + 18 * n\n    elif choice == 7:\n        penalty += 300 + 36 * n\n    elif choice == 8:\n        penalty += 400 + 36 * n\n    elif choice == 9:\n        penalty += 500 + 36 * n + 199 * n\n    else:\n        penalty += 500 + 36 * n + 398 * n\n        \n    return penalty","8e814c6f":"ax = sns.boxplot(x=data[\"n_people\"])\n","5a6cf8c1":"ax = sns.boxplot(data)","78b469c8":"df_fam_cost = pd.DataFrame(index = np.array(range(np.min(data[\"n_people\"]),\n                            np.max(data[\"n_people\"]) + 1)),\n            columns=['choice_{}'.format(n_choice) for n_choice in range(0, 11)])\ndf_fam_cost[\"n\"] = df_fam_cost.index\ndf_fam_cost","f08b8878":"df_fam_cost[\"choice_0\"] = df_fam_cost[\"n\"].apply(cost_family, args=(0,))\ndf_fam_cost[\"choice_1\"] = df_fam_cost[\"n\"].apply(cost_family, args=(1,))\ndf_fam_cost[\"choice_2\"] = df_fam_cost[\"n\"].apply(cost_family, args=(2,))\ndf_fam_cost[\"choice_3\"] = df_fam_cost[\"n\"].apply(cost_family, args=(3,))\ndf_fam_cost[\"choice_4\"] = df_fam_cost[\"n\"].apply(cost_family, args=(4,))\ndf_fam_cost[\"choice_5\"] = df_fam_cost[\"n\"].apply(cost_family, args=(5,))\ndf_fam_cost[\"choice_6\"] = df_fam_cost[\"n\"].apply(cost_family, args=(6,))\ndf_fam_cost[\"choice_7\"] = df_fam_cost[\"n\"].apply(cost_family, args=(7,))\ndf_fam_cost[\"choice_8\"] = df_fam_cost[\"n\"].apply(cost_family, args=(8,))\ndf_fam_cost[\"choice_9\"] = df_fam_cost[\"n\"].apply(cost_family, args=(9,))\ndf_fam_cost[\"choice_10\"] = df_fam_cost[\"n\"].apply(cost_family, args=(10,))\ndf_fam_cost","8e329cd3":"fig = plt.figure(figsize=(12, 8))\nplt.title(\"Cost family [$]\")\nlist_choice = ['choice_{}'.format(n_choice) for n_choice in range(0, 11)]\n\nfor choice in list_choice:\n    plt.plot(df_fam_cost[\"n\"], df_fam_cost[choice], '-o', label=choice)\nplt.legend(loc='upper left');\n\nax = fig.gca()\nax.set_xlabel(\"number of people [-]\");","17781864":"fig = plt.figure(figsize=(12, 8))\nplt.title(\"Cost for family by number of people [$]\")\nlist_choice = ['choice_{}'.format(n_choice) for n_choice in range(0, 11)]\n\nfor n in df_fam_cost[\"n\"]:\n    plt.plot(range(0, df_fam_cost.filter(items=list_choice).shape[1]), \n        np.array(df_fam_cost.filter(items=list_choice).filter(items=[n], \n                                                              axis=0))[0],\n             '-o', label=n)\nplt.legend(loc='upper left');\n\nax = fig.gca()\nax.set_xlabel(\"choice number [-]\");","724b5695":"def create_df_fam_cost_prob(df_fam_cost, p_min=0.03, p_max=0.1):\n    # For genetic algo, for start population or mutation,\n    # try to assign probabilities of choice for each possibilities : \n    # from  choice 0 to 10.\n    list_choice = ['choice_{}'.format(n_choice) for n_choice in range(0, \n                                                        CHOICE_RANGE_MAX + 1)]\n    df_prob = df_fam_cost.filter(items=list_choice)\n    vect_penalty = [0, np.max(np.max(df_prob))]\n    print(\"vect_penalty: \", vect_penalty)\n    vect_prob = [p_max, p_min]\n    print(\"vect_prob\", vect_prob)\n    # family : number of people\n    df_prob = df_prob.applymap(lambda x: np.interp(x, vect_penalty, vect_prob))\n    for indice in df_prob.index:\n        df_prob.loc[indice] = df_prob.loc[indice]\/df_prob.loc[indice].sum()\n    return df_prob  \n\n","b3cf83b2":"df_prob = create_df_fam_cost_prob(df_fam_cost, p_min=0.01, p_max=1)\ndf_prob","28955fc2":"df_prob\nfig = plt.figure(figsize=(8, 5))\nplt.title(\"probabilities during mutation [-]\")\nax = sns.heatmap(df_prob)\nax.set_ylabel(\"nb people [-]\")","9f7ab39a":"# save\njoblib.dump(df_prob, PATH_TO_SAVE_DATA + '\/df_prob.pkl')","4f57951e":"df_prob_fam = create_df_prob_day_fam_optim(df_prob_day, df_prob)","8376a9df":"df_prob_fam.head()","ea4a3ee1":"# save\njoblib.dump(df_prob_fam, PATH_SAVE_PROB_FAM)","edc166da":"PATH_SAVE_PROB_FAM","13a66720":"df_prob_fam = joblib.load(PATH_SAVE_PROB_FAM)\ndf_prob = joblib.load(PATH_TO_SAVE_DATA + '\/df_prob.pkl')\n# patch to optimize mutation fonction:\narr_prob = np.array(df_prob)\narr_prob_fam = np.array(df_prob_fam.astype(\"float\"))","77e2afd6":"#SAVE_POP = 'RANDOM_MUT'\n#NB_FIRST_POP = 3\n#DELTA_RANDOM_MUT_POP = 1 # delta for first random mut pop\n#R_FIRST_RANDOM_MUT = 0.2 # RATIO of mutation for first population in random mut","cc829c59":"if SAVE_POP == 'RANDOM_MUT':\n    print(\"Generate Random Mutation\")\n    # Create ranges\n    submission = pd.read_csv(fpath, index_col='family_id')\n    \n    # create normal range \n    #arr_range = np.array([np.arange(submission.shape[0])])\n    #arr_range = np.empty((NB_FIRST_POP, submission.shape[0]), dtype=np.int64)\n    \n    vect_pop_first_0 = submission[\"assigned_day\"].values\n        \n    # generate first first choice for every families : \n    arr_pop_first_0 = np.empty((NB_FIRST_POP, vect_pop_first_0.shape[0]), \n                               dtype=np.int64)\n    for indice in range(NB_FIRST_POP):\n        arr_pop_first_0[indice] = vect_pop_first_0\n    \n    # generated random choice for first pop around 0 + DELTA_CHOICE_RANDOM_POP\n    arr_pop_first = fun_vect_mut(arr_pop_first_0, \n                                 r_pop_mut=1, \n                                 r_mut=R_FIRST_RANDOM_MUT, \n                                 delta_choice=DELTA_RANDOM_MUT_POP)\n    # replace first line by sample\n    arr_pop_first[0] = vect_pop_first_0\n    \n    # Optimize first pop along some random ranges \n    t_fit_0 = time.time()\n    print(\"Optimizing one by one indiv along random ranges ...\")\n    arr_pop, arr_score = boost_optim_one_by_one_epochs(arr_pop_first,\n                                                       n_epochs=40, \n                                                       nb_epoch_check=10,\n                                                       nb_try_not_best_max=2)\n    t_fit_1 = time.time()\n    print(\"Timing : \", t_fit_1 - t_fit_0)\n    df_cost = pd.DataFrame(data=arr_score, columns=[\"cost\"])\n    df_cost.boxplot()\n    print(\"df_cost: \", df_cost.sort_values(by=\"cost\").head(10))\n    df_pop = pd.DataFrame(arr_pop)\n    df_pop","3b67a806":"#SAVE_POP = 'RANDOM_CHOICE'","99981d7f":"if SAVE_POP == 'RANDOM_CHOICE':\n    print(\"Generate random Choices\")\n    # Create ranges\n    submission = pd.read_csv(fpath, index_col='family_id')\n    \n    # create normal range \n    #arr_range = np.array([np.arange(submission.shape[0])])\n    #arr_range = np.empty((NB_FIRST_POP, submission.shape[0]), dtype=np.int64)\n    \n    arr_pop_first_0 = \\\n        np.empty((NB_FIRST_POP, submission.shape[0]), dtype=np.int64)\n    # generate first first choice for every families : \n    \n    for fam_id in range(submission.shape[0]):\n        arr_pop_first_0[0,fam_id] = choose_day_prob_optim(np.array([0]), fam_id)\n    for indice in range(NB_FIRST_POP):\n        arr_pop_first_0[indice] = arr_pop_first_0[0]\n    \n    # generated random choice for first pop around 0 + DELTA_CHOICE_RANDOM_POP\n    arr_pop_first = fun_vect_mut(arr_pop_first_0, \n                                 r_pop_mut=1, \n                                 r_mut=1, \n                                 delta_choice=DELTA_CHOICE_RANDOM_POP)\n    \n    # Optimize first pop along one range only\n    t_fit_0 = time.time()\n    #best = submission['assigned_day'].values\n    print(\"Optimizing one by one indiv along random range ...\")\n    arr_pop, arr_score = boost_optim_one_by_one_epochs(arr_pop_first,\n                                                       n_epochs=100, \n                                                       nb_epoch_check=10,\n                                                       nb_try_not_best_max=2)\n    t_fit_1 = time.time()\n    print(\"Timing : \", t_fit_1 - t_fit_0)\n    df_cost = pd.DataFrame(data=arr_score, columns=[\"cost\"])\n    df_cost.boxplot()\n    print(\"df_cost: \", df_cost.sort_values(by=\"cost\").head(10))\n    df_pop = pd.DataFrame(arr_pop)\n    df_pop","3d3f31f6":"#SAVE_POP = 'RANDOM_PATH' ","307d060f":"if SAVE_POP == 'RANDOM_PATH':\n    print(\"Generate random paths\")\n    # Create ranges\n    submission = pd.read_csv(fpath, index_col='family_id')\n    \n    # create NB_FIRST_POP random path to seek optimum\n    arr_range = np.empty((NB_FIRST_POP, submission.shape[0]), dtype=np.int64)\n    \n    for indice in range(NB_FIRST_POP):\n        arr_range[indice] = np.random.permutation(submission.shape[0])\n    \n    df_range = pd.DataFrame(data=arr_range)\n    print(df_range.head(10))\n    fig = plt.figure(figsize=(8, 8))\n    plt.title(\"ranges\")\n    #for indice in range(0, df_range.shape[0]):\n    plt.plot(df_range.loc[0])\n    \n    # create pop from submision by seeking along random paths\n    t_fit_0 = time.time()\n    best = submission['assigned_day'].values\n    arr_pop, arr_score = boost_optim_one_by_one(best, arr_range=arr_range)\n    t_fit_1 = time.time()\n    print(\"Timing : \", t_fit_1 - t_fit_0)\n    df_cost = pd.DataFrame(data=arr_score, columns=[\"cost\"])\n    df_cost.boxplot()\n    print(\"df_cost: \", df_cost.sort_values(by=\"cost\").head(10))\n    df_pop = pd.DataFrame(arr_pop)\n    df_pop","10293b74":"#SAVE_POP = '10R'","19a154fd":"# OPTIM VERSION \n# std pop choices : 0.578\nif SAVE_POP == '10R':\n    # Create ranges\n    submission = pd.read_csv(fpath, index_col='family_id')\n    df_range = create_seek_ranges(nb_first_seed=NB_FIRST_SEED)\n    fig = plt.figure(figsize=(8, 8))\n    plt.title(\"ranges\")\n    for indice in range(0, df_range.shape[0]):\n        plt.plot(df_range.loc[indice])\n        \n    # Create baselines : optimized version\n    t_fit_0 = time.time()\n    # Start with the sample submission values\n    submission = pd.read_csv(fpath, index_col='family_id')\n    best = submission['assigned_day'].values\n    arr_range = df_range.values.astype(np.int64)\n    arr_sub, arr_score = boost_diff_browsing_optim(best, arr_range=arr_range)\n    t_fit_1 = time.time()\n    print(\"Timing: \", t_fit_1 - t_fit_0)\n    print(\"Info first pop of 10 :\")\n    _, df_des_choices_0, _ = pop_choices_info(pd.DataFrame(arr_sub))\n\n    \n    t_tot_0 = time.time()\n    nb_indiv_done = 0\n    nb_range = df_range.index.shape[0]\n    nb_indiv_curr = np.floor(NB_FIRST_POP\/df_range.shape[0])\n    for i_seed in df_range.index:\n        # choose number of indiv.\n        nb_indiv_done += nb_indiv_curr\n        if i_seed == nb_range-1:\n            if NB_FIRST_POP % nb_range != 0:\n                nb_indiv_curr += NB_FIRST_POP % nb_range\n        nb_indiv_curr = int(nb_indiv_curr)\n        print(\"# {} \/ nb_indiv_curr: {} \/ done: {}\".format(i_seed, nb_indiv_curr, \n                                                           nb_indiv_done))\n        # load best indiv in range #i_seed\n        #seed_indiv = pd.read_csv(f'submission_range{i_seed}.csv')\n        seed_indiv = arr_sub[i_seed]\n        #print(\"seed_indiv.shape: \", seed_indiv.shape)\n        # generate sub-pop \n        t_fit_0 = time.time()\n        arr_pop_curr = generate_pop_choices_optim(seed_indiv=seed_indiv, \n                                           nb_pop=nb_indiv_curr, \n                                           r_mut=R_FIRST_MUT, \n                                           delta_choice=DELTA_CHOICE_FIRST_POP)\n        t_fit_1 = time.time()\n        print(\"Timing : \", t_fit_1 - t_fit_0)\n        df_pop_curr = pd.DataFrame(arr_pop_curr)\n        \n        # add sub-pop to pop\n        if i_seed == 0:\n            df_pop = df_pop_curr\n        else:\n            df_pop = df_pop.append(df_pop_curr, ignore_index=True)\n            \n    t_tot_1 = time.time()\n    print(\"Timing TOTAL: \", t_tot_1 - t_tot_0)\n    print(\"df_pop.shape: \", df_pop.shape) \n    df_choices_0, df_des_choices_0, std_mean_0 = pop_choices_info(df_pop)\n    print(\"Info for all pop: \")\n    df_des_choices_0","fe982627":"if SAVE_POP == \"10R\": \n    #plt.plot(df_pop.columns,df_pop.loc[0]-df_pop.loc[1])\n    \n    \n    path_df_pop_saved = PATH_TO_SAVE_DATA + \\\n        '\/df_pop_choices_{}_{}_fs{}_rfm{}_dc{}.pkl'.format(\n                    SAVE_POP,\n                    NB_FIRST_POP,\n                    NB_FIRST_SEED, \n                    R_FIRST_MUT, \n                    DELTA_CHOICE_FIRST_POP)\n    # check file already exist : \n    if os.path.isfile(path_df_pop_saved):\n        path_df_pop_saved_old = PATH_TO_SAVE_DATA + \\\n        '\/df_pop_choices_{}_{}_fs{}_rfm{}_dc{}_{}.pkl'.format(\n                    SAVE_POP,\n                    NB_FIRST_POP,\n                    NB_FIRST_SEED, \n                    R_FIRST_MUT, \n                    DELTA_CHOICE_FIRST_POP,\n                    datetime.today().strftime('%Y_%m_%d_%H_%M_%S'))\n        os.rename(path_df_pop_saved, path_df_pop_saved_old)\n    # save\n    joblib.dump(df_pop, path_df_pop_saved, compress=True)","df7227e6":"if SAVE_POP == \"RANDOM_PATH\": \n    path_df_pop_saved = PATH_TO_SAVE_DATA + \\\n        '\/df_pop_choices_{}_{}.pkl'.format(\n                    SAVE_POP,\n                    NB_FIRST_POP)\n    # check file already exist : \n    if os.path.isfile(path_df_pop_saved):\n        path_df_pop_saved_old = PATH_TO_SAVE_DATA + \\\n        '\/df_pop_choices_{}_{}_{}.pkl'.format(\n                    SAVE_POP,\n                    NB_FIRST_POP,\n                    datetime.today().strftime('%Y_%m_%d_%H_%M_%S'))\n        os.rename(path_df_pop_saved, path_df_pop_saved_old)\n    # save\n    joblib.dump(df_pop, path_df_pop_saved, compress=True)\n    print(path_df_pop_saved)\n","5f620fa4":"if SAVE_POP == \"RANDOM_CHOICE\": \n    path_df_pop_saved = PATH_TO_SAVE_DATA + \\\n        '\/df_pop_choices_{}_{}_dcr{}.pkl'.format(\n                    SAVE_POP,\n                    NB_FIRST_POP,\n                    DELTA_CHOICE_RANDOM_POP)\n    # check file already exist : \n    if os.path.isfile(path_df_pop_saved):\n        path_df_pop_saved_old = PATH_TO_SAVE_DATA + \\\n        '\/df_pop_choices_{}_{}_dcr{}_{}.pkl'.format(\n                    SAVE_POP,\n                    NB_FIRST_POP,\n                    DELTA_CHOICE_RANDOM_POP,\n                    datetime.today().strftime('%Y_%m_%d_%H_%M_%S'))\n        os.rename(path_df_pop_saved, path_df_pop_saved_old)\n    # save\n    joblib.dump(df_pop, path_df_pop_saved, compress=True)\n    print(path_df_pop_saved)\n","ee830065":"if SAVE_POP == \"RANDOM_MUT\": \n    path_df_pop_saved = PATH_TO_SAVE_DATA + \\\n        '\/df_pop_choices_{}_{}_rfrm{}_dcr{}.pkl'.format(\n                    SAVE_POP,\n                    NB_FIRST_POP,\n                    R_FIRST_RANDOM_MUT,\n                    DELTA_RANDOM_MUT_POP)\n    # check file already exist : \n    if os.path.isfile(path_df_pop_saved):\n        path_df_pop_saved_old = PATH_TO_SAVE_DATA + \\\n        '\/df_pop_choices_{}_{}_rfrm{}_dcr{}_{}.pkl'.format(\n                    SAVE_POP,\n                    NB_FIRST_POP,\n                    R_FIRST_RANDOM_MUT,\n                    DELTA_RANDOM_MUT_POP,\n                    datetime.today().strftime('%Y_%m_%d_%H_%M_%S'))\n        os.rename(path_df_pop_saved, path_df_pop_saved_old)\n    # save\n    joblib.dump(df_pop, path_df_pop_saved, compress=True)\n    print(path_df_pop_saved)","63f95685":"df_range = create_seek_ranges(nb_first_seed=NB_FIRST_SEED)\narr_range = df_range.values.astype(np.int64) # f(num range, families)\ndf_range","793ad764":"df_prob_fam = joblib.load(PATH_SAVE_PROB_FAM)\ndf_prob = joblib.load(PATH_TO_SAVE_DATA + '\/df_prob.pkl')\n# patch to optimize mutation fonction:\narr_prob = np.array(df_prob)\narr_prob_fam = np.array(df_prob_fam.astype(\"float\"))\n\n\nif (SAVE_POP is None) & os.path.isfile(PATH_DF_POP):\n    print(\"Loading: \", PATH_DF_POP)\n    df_pop = joblib.load(PATH_DF_POP)\nelse:\n    print(\"Loading: \", path_df_pop_saved)\n    df_pop = joblib.load(path_df_pop_saved)\n    \n# info about first pop\nprint(\"Infos about population: \")\nplt.plot(df_pop.columns,df_pop.loc[0]-df_pop.loc[1])\nplt.title(\"Example : indiv_0 - indiv_1\")\nprint(\"Max Same indiv nb : \", find_max_same_indiv(df_pop.values))\n_, df_des_choices_0, _ = pop_choices_info(df_pop)\ndf_des_choices_0","a0d90d16":"# create cost dataFrame for all population\nt_0 = time.time()\narr_pop = np.array(df_pop)\narr_score = eval_cost_vect_optim(arr_pop)\ndf_cost = pd.DataFrame(data=arr_score, columns=[\"cost\"])\nprint(\"Timing: \", time.time()-t_0)\ndf_cost.boxplot()\ndf_cost.sort_values(by=\"cost\").head(10)","309d961f":"POW_SELECTION = 0.3","b891306b":"# Prob for indiv = inverse rank * POW_SELECTION\narr_select_prob = selection_prob(df_cost, pow_selection=POW_SELECTION)\nplt.plot(np.sort(arr_select_prob))\nplt.title(\"Selection probabilities\");","5aa757ac":"arr_pop = np.array(df_pop) # df_pop = f(indiv., families)\narr_cost = df_cost[\"cost\"].values","faf9a54c":"## HYPERPARAMETERS\nNB_MAX_EPOCHS = 125000\nR_POP_MUT = 0.1\nR_MUT = 0.01 \nDELTA_CHOICE = 2\nNB_BEST_KEEP = 20\nPOW_SELECTION = 0.3\nflag_boost = True\nboost_freq = 2000\nR_CROSSOVER = 1\nboost_sps_freq = 1000 # epochs frequency to run Stochastic Product Search \nthr_sps_cost = 0 # delta cost over boost_sps_freq epochs : -1 to disable\n\n## DISPLAY PARAM\nflag_prompt = False # timing information to each steps \nprompt_freq = 500 #100 # frequency info about cost & timing \n\n## PREPARE LOOP\n# prepare data \nFIRST_COST = arr_cost.min()\nnb_indiv_boost = 0\nnb_sps_not_found = 0\n#list_best_cost = []\nlist_best_cost = np.empty(0)\nindice_cost = np.argsort(arr_cost)\nt_fit_0 = time.time()\n\n## LOOP OVER GENERATIONS (MAIN ALGO GEN)\nfor gen_id in range(0, NB_MAX_EPOCHS):\n    \n    t_epoch_0 = time.time()\n    if flag_prompt:\n        t_lost_0 = time.time()\n\n    # add current epoch best cost among population:\n    list_best_cost = np.append(list_best_cost, arr_cost.min())\n    \n    ############\n    # STOCHASTIC PRODUCT SEARCH \n    # boost by stochastic product search if critera is reached:\n    # critera = if no better improvement of cost during boost_sps_freq epochs\n    if (gen_id % boost_sps_freq == 0):\n        if (list_best_cost.shape[0] > boost_sps_freq):\n            if (list_best_cost[-boost_sps_freq] - list_best_cost[-1]) <= \\\n            thr_sps_cost:\n                print(\"GEN. #{} \/ Stochastic Product Search...\".format(gen_id))\n                # select best\n                arr_best_curr = arr_pop[np.argmin(arr_cost)]\n                # search time\n                duration_sps = max(6,min(6*nb_sps_not_found, 300)) # max 5 min \n                # run s.p.s\n                #arr_best_sps=stochprodsearch_03.sps(arr_best_curr)# BUG ctypes\n                arr_best_sps = run_stochprodsearch(arr_best_curr, \n                                                   end_time=duration_sps, \n                                                   nb_jobs=4)\n                cost_best_sps = cost_function_optim(arr_best_sps)\n                # if better found we replace it into population\n                if cost_best_sps < cost_function_optim(arr_best_curr):\n                    arr_pop[np.argmin(arr_cost)] = arr_best_sps\n                    arr_cost[np.argmin(arr_cost)] = cost_best_sps\n                    print(\"Stochastic Product Search : Best cost: \", \n                          cost_best_sps)\n                    nb_sps_not_found = 0\n                else:\n                    nb_sps_not_found = nb_sps_not_found + 1\n\n    ############\n    # SELECTION  \n    # calculation of probabilities for crossing next generation \n    # prob =  (1\/rank)^POW_SELECTION\n\n    # Keep the NB_BEST_KEEP best indiv.s\n    arr_select_prob, arr_best, arr_cost_best = selection_prob_arr(arr_cost, \n      pow_selection=POW_SELECTION, arr_pop=arr_pop, flag_ouput=True,\n      nb_best_keep=NB_BEST_KEEP)\n    \n    if flag_prompt:\n        t_lost_1 = time.time()\n        print(\"Timing lost: \", t_lost_1 - t_lost_0)\n        \n    ############\n    # CROSSOVER \n    #\n    # Do the Crossover between pair indiv.\n    # 1 Cross point is ramdomly choosen (prob uniform)\n    # example : \n    # 1-2-3\\  \/5-8-9-1-3-4-9  \n    #       \\\/\n    # 5-6-5\/ \\4-5-6-7-8-9-10\n    #\n    # give : \n    #\n    # 1-2-3--4-5-6-7-8-9-10\n    # 5-6-5--5-8-9-1-3-4-9 \n    # create pairs : ramdomly\n    if flag_prompt:\n        t_cross_0 = time.time()\n\n    # crossing with more prob for best indiv.\n    # number of new children = N pop - N best to keep same nb of indiv each gen.\n    nb_cross = int(NB_FIRST_POP - NB_BEST_KEEP - nb_indiv_boost)\n    # reset nb boost indiv\n    if nb_indiv_boost > 0:\n        nb_indiv_boost = 0 \n\n    arr_pop = generate_crossing_prob(arr_pop.copy(), p=arr_select_prob, \n                                     n_indiv=nb_cross, r_cross=R_CROSSOVER)\n    if flag_prompt:\n        t_cross_1 = time.time()\n        print(\"Timing cross: \", t_cross_1 - t_cross_0)\n\n    ############\n    # MUTATION\n    # among pop, number of mutation = R_POP_MUT * number of indiv\n    # arr_pop or df_pop = f(indiv, family)\n    if flag_prompt:\n        t_mut_0 = time.time()\n    arr_pop = fun_vect_mut(arr_pop, r_pop_mut=R_POP_MUT, r_mut=R_MUT, \n                delta_choice=DELTA_CHOICE)\n    \n    ############    \n    ## ADD the best ones\n    #\n    #arr_pop = np.append(arr_pop, np.array(df_best), axis=0)\n    arr_pop = np.append(arr_pop, arr_best, axis=0)\n    # AVOID DUPLICATE INDIV \n    if flag_prompt:\n        t_mut_1 = time.time()\n        print(\"Timing mutation: \", t_mut_1 - t_mut_0)\n\n    ############\n    # EVALUATION\n    # create cost dataFrame for all population\n    if flag_prompt:\n        t_eval_0 = time.time()\n    # optim\n    arr_cost = eval_cost_vect_optim(arr_pop)\n    \n    ##########\n    # BOOSTING\n    #\n    # cost of last best submission\n\n    if flag_boost & (gen_id % boost_freq == 0) & (gen_id > 0) :\n        # the 1st best indiv only \n        \n        best = arr_pop[np.argmin(arr_cost)]\n    \n        arr_sub, arr_score = boost_diff_browsing_optim(best=best, \n                                                       arr_range=arr_range)\n    \n        nb_indiv_boost = arr_sub.shape[0]\n        \n        arr_pop = np.append(arr_pop, arr_sub, axis=0)\n        \n        arr_cost = np.append(arr_cost, arr_score, axis=0)\n    \n    ##########\n    # AVOID DUPLICATES BY SAME COST : very FASTER\n    # but potential diff indiv elimitated...\n    #\n    \n    indices_cost, arr_cost = removeDups(arr_cost)\n    arr_pop = arr_pop[indices_cost]\n    \n    \n    if flag_prompt:\n        t_eval_1 = time.time()\n        print(\"Timing eval: \", t_eval_1 - t_eval_0)\n    \n    ##########\n    # DISPLAY\n    #\n    t_epoch_1 = time.time()\n    if (flag_prompt) | (gen_id % prompt_freq == 0):    \n        print(\"GEN. #{} \/ cost: {} \/ nb. pop: {} \/ timing: {}\".format(gen_id, \n                        arr_cost.min(), arr_pop.shape[0],\n                                                      t_epoch_1 - t_epoch_0))        \n\n# timing \nt_fit_1 = time.time()\nprint(\"END:\")\n\nprint(\"LAST GEN. #{} \/ cost: {} \/ nb. pop: {} \/ timing Total: {}\".format(gen_id, \n                        arr_cost.min(), arr_pop.shape[0], t_fit_1 - t_fit_0)) \n\n\ndf_cost = pd.DataFrame(data=arr_cost, columns=[\"cost\"])\ndf_pop = pd.DataFrame(arr_pop)\n\n# figure\nfig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost)\nplt.title(\"Cost over generations\")\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")","1903b20d":"arr_cost.min()","37c51de5":"print(\"How many same indiv. into population at the end : \")\nfind_max_same_indiv(df_pop)","bccadc11":"print(\"Pop Info :\")\ndf_choices, df_des_choices, std_mean = pop_choices_info(df_pop)\ndf_des_choices","59236305":"fig = plt.figure(figsize=(12, 6))\nplt.plot(df_cost.sort_values(by=\"cost\").head(NB_BEST_KEEP+300).values)\nax = fig.gca()\nax.set_title(\"Best Cost\")\nax.set_ylabel(\"Cost $\")\nax.set_xlabel('assignement n#');","a25bcca0":"# POP\njoblib.dump(df_pop,\n    PATH_TO_SAVE_DATA + '\/df_pop{}_fs{}_rfm{}_dc{}_rm{}_nk_{}_gen{}_s{}.pkl'.format(\n                NB_FIRST_POP,\n                NB_FIRST_SEED, \n                R_FIRST_MUT,\n                DELTA_CHOICE,\n                R_POP_MUT,\n                NB_BEST_KEEP,\n                NB_MAX_EPOCHS,\n                df_cost.sort_values(by=\"cost\").iloc[0,0]),\n           compress=True)\n# COST\njoblib.dump(df_cost,\n    PATH_TO_SAVE_DATA + \\\n            '\/df_cost_pop{}_fs{}_rfm{}_dc{}_rm{}_nk_{}_gen{}_s{}.pkl'.format(\n                NB_FIRST_POP,\n                NB_FIRST_SEED, \n                R_FIRST_MUT,\n                DELTA_CHOICE,\n                R_POP_MUT,\n                NB_BEST_KEEP,\n                NB_MAX_EPOCHS,\n                df_cost.sort_values(by=\"cost\").iloc[0,0]),\n           compress=True)\n\n# submission csv\nsubmission_final = pd.DataFrame(columns=[\"assigned_day\"])\nsubmission_final[\"assigned_day\"] = \\\n    df_pop.loc[df_cost.sort_values(by=\"cost\").iloc[0].name]\nsubmission_final.index.name = 'family_id'\nsubmission_final.to_csv(\"submission_{}.csv\".format(\n    df_cost.sort_values(by=\"cost\").iloc[0,0]))           \nprint(\"Submission saved here :\", \"submission_{}.csv\".format(\n    df_cost.sort_values(by=\"cost\").iloc[0,0]))\n\n# SUBMISSION pickle\njoblib.dump(submission_final,\n    PATH_TO_SAVE_DATA + \\\n            '\/submission_pop{}_fs{}_rfm{}_dc{}_rm{}_nk_{}_gen{}_s{}.pkl'.format(\n                NB_FIRST_POP,\n                NB_FIRST_SEED, \n                R_FIRST_MUT,\n                DELTA_CHOICE,\n                R_POP_MUT,\n                NB_BEST_KEEP,\n                NB_MAX_EPOCHS,\n                df_cost.sort_values(by=\"cost\").iloc[0,0]),\n           compress=True)\n# list cost vs epochs \njoblib.dump(list_best_cost,\n    PATH_TO_SAVE_DATA + \\\n            '\/list_best_cost{}_fs{}_rfm{}_dc{}_rm{}_nk_{}_gen{}_s{}.pkl'.format(\n                NB_FIRST_POP,\n                NB_FIRST_SEED, \n                R_FIRST_MUT,\n                DELTA_CHOICE,\n                R_POP_MUT, \n                NB_BEST_KEEP,\n                NB_MAX_EPOCHS,\n                df_cost.sort_values(by=\"cost\").iloc[0,0]),\n           compress=True)\n\n\n","ad53e8f0":"BEST_COST = df_cost.sort_values(by=\"cost\")[\"cost\"].iloc[0]\n# datetime object containing current date and time\nnow = datetime.now()\n# dd\/mm\/YY H:M:S\ndt_string = now.strftime(\"%d\/%m\/%Y %H:%M:%S\")\ntry:\n    timing = t_fit_1 - t_fit_0\nexcept:\n    timing = t_epoch_1 - t_fit_0 \n\nnb_pop = df_pop.shape[0]\ndf_res = pd.DataFrame(columns=[\"date\", \"COMPUTERNAME\", \"FIRST_COST\", \n                               \"BEST_COST\", \"NB_MAX_EPOCHS\", \"timing\", \"nb_pop\",\n                              \"NB_FIRST_SEED\", \"DELTA_CHOICE_FIRST_POP\",\n                              \"R_FIRST_MUT\", \"R_POP_MUT\", \"R_MUT\", \n                               \"DELTA_CHOICE\", \"NB_BEST_KEEP\", \"POW_SELECTION\",\n                              \"flag_boost\", \"boost_freq\"], index=[0])\n\ndf_res[\"date\"] = dt_string\ndf_res[\"COMPUTERNAME\"] = COMPUTERNAME\ndf_res[\"FIRST_COST\"] = FIRST_COST\ndf_res[\"BEST_COST\"] = BEST_COST\ndf_res[\"NB_MAX_EPOCHS\"] = NB_MAX_EPOCHS\ndf_res[\"timing\"] = timing\ndf_res[\"nb_pop\"] = df_pop.shape[0]\ndf_res[\"NB_FIRST_SEED\"] = NB_FIRST_SEED\ndf_res[\"DELTA_CHOICE_FIRST_POP\"] = DELTA_CHOICE_FIRST_POP\ndf_res[\"R_FIRST_MUT\"] = R_FIRST_MUT\ndf_res[\"R_POP_MUT\"] = R_POP_MUT\ndf_res[\"R_MUT\"] = R_MUT\ndf_res[\"DELTA_CHOICE\"] = DELTA_CHOICE\ndf_res[\"NB_BEST_KEEP\"] = NB_BEST_KEEP\ndf_res[\"POW_SELECTION\"] = POW_SELECTION\ndf_res[\"flag_boost\"] = flag_boost\ndf_res[\"boost_freq\"] = boost_freq\ndf_res[\"pop_path\"] = PATH_DF_POP\ndf_res.index.name = 'job'\ndf_res.to_csv(PATH_TO_SAVE_DATA + \\\n              '\/res_pop{}_fs{}_rfm{}_dc{}_rm{}_nk_{}_gen{}_s{}.csv'.format(\n                NB_FIRST_POP,\n                NB_FIRST_SEED, \n                R_FIRST_MUT,\n                DELTA_CHOICE,\n                R_POP_MUT,\n                NB_BEST_KEEP,\n                NB_MAX_EPOCHS,\n                df_cost.sort_values(by=\"cost\").iloc[0,0]))\ndf_res","cf19ec6e":"df_pop_0 = joblib.load(PATH_DF_POP)\n\ndf_choices_0, df_des_choices_0, std_mean_0 = pop_choices_info(df_pop_0)\ndf_des_choices_0","81899cee":"df_choices_0.loc[0].value_counts()","3706086a":"best = df_pop.loc[df_cost[\"cost\"].idxmin()].values","c2eb7e84":"cost_function_optim(best)","3f109aaa":"penalty, accounting_cost , daily_occupancy = cost_function(best, flag_prompt=True)\ndf_daily = pd.DataFrame(index=daily_occupancy.keys(), data=list(daily_occupancy.values()), \n             columns=['nb_people'])","e2e24e4e":"df_daily.describe()","c42429f1":"submission_opti = pd.read_csv(PATH_TO_EXPLORE_DATA + '\/submission_68888.04.csv', \n                         index_col='family_id')\n# find daily occ\npenalty_opti, accounting_cost_opti , daily_occupancy_opti = \\\n    cost_function(submission_opti[\"assigned_day\"].values, flag_prompt=True)\n\ndf_daily_opti = pd.DataFrame(index=daily_occupancy_opti.keys(), \n                             data=list(daily_occupancy_opti.values()), \n             columns=['nb_people'])\ndf_daily[\"nb_opti\"] = df_daily_opti['nb_people']\ndf_daily[\"delta_nb_opti\"] = df_daily[\"nb_opti\"] - df_daily['nb_people']","dbfed21f":"fig = plt.figure(figsize=(14, 6))\nplt.title(\"Occupancy : compare my best \/ optimal\")\nplt.plot(df_daily.index, df_daily[\"nb_people\"],'+-', label=\"my_best\")\nplt.plot(df_daily.index, df_daily[\"nb_opti\"],'.-', label=\"opti\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"Days before Christmas\")\nax.set_ylabel(\"nb people\");","7fea0026":"arr_choice_best = fun_find_choices_sub(best)\narr_choice_opti = fun_find_choices_sub(submission_opti[\"assigned_day\"].values)\n\nfig = plt.figure(figsize=(14, 8))\nplt.title(\"choices\")\nplt.plot(arr_choice_best, '+', label=\"best\")\nplt.plot(arr_choice_opti, '.', label=\"opti\")\nplt.legend(loc='best');\n","8ddbbed8":"fig = plt.figure(figsize=(14, 8))\nplt.title(\"delta choices : best-opti\")\nplt.plot(arr_choice_best-arr_choice_opti, '.')","4350989e":"arr_choices = fun_find_choices_sub(best)\ndf_best = pd.DataFrame(arr_choices.astype(np.int64), columns=[\"choice\"]) \ndf_best[\"day\"] = best\ndf_best[\"day_opti\"] = submission_opti[\"assigned_day\"].values\ndf_best[\"choice_opti\"] = arr_choice_opti.astype(np.int64)\ndf_best.describe()","67ea6f9d":"df_best[\"choice\"].value_counts()","ed2aa2dd":"df_best[\"choice_opti\"].value_counts()","0fcf0fff":"fig = plt.figure(figsize=(14, 6)) \nplt.title(\"Count of choices # : compare current best & optimal\")\nax = sns.countplot(y=\"value\", hue=\"variable\", \n                   data=df_best.melt(value_vars=['choice', 'choice_opti']))\nax.set_ylabel(\"choice #\");\n","845cedc4":"df_des_choices","362a1473":"df_des_choices.loc[\"std\"].max()","a15c2996":"plot_delta_choice_pop(df_pop, df_des_choices)","f96f0f23":"plot_std_choice_pop(df_pop, df_des_choices)","8e29b26b":"sns.boxplot(df_des_choices.loc[\"std\"])","d71b4990":"sub_my_best = pd.read_csv(PATH_TO_EXPLORE_DATA + \\\n                          '\/submission_71447.87946293628_for_sps.csv', \n                   index_col='family_id')\nsub_opti = pd.read_csv(PATH_TO_EXPLORE_DATA + \\\n                          '\/submission_68888.04.csv', \n                   index_col='family_id')","44268611":"\narr_choice_best = fun_find_choices_sub(sub_my_best[\"assigned_day\"].values)\narr_choice_opti = fun_find_choices_sub(sub_opti[\"assigned_day\"].values)\n\nfig = plt.figure(figsize=(16, 8))\nplt.title(\"Compare my best with optimum choices\")\nplt.plot(arr_choice_best, '+', label=\"best\")\nplt.plot(arr_choice_opti, '.', label=\"opti\")\nplt.legend(loc='upper left');","d80ce880":"fig = plt.figure(figsize=(12, 8))\nplt.title(\"delta choices : best-opti\")\nplt.plot(arr_choice_best-arr_choice_opti, '.')","2c1d6783":"penalty, accounting_cost , daily_occupancy = \\\n    cost_function(sub_my_best[\"assigned_day\"].values, flag_prompt=True)\n\ndf_daily = pd.DataFrame(index=daily_occupancy.keys(), \n                        data=list(daily_occupancy.values()), \n                        columns=['nb_people'])\n#df_daily.plot()\n\n# find daily occ\npenalty_opti, accounting_cost_opti , daily_occupancy_opti = \\\n    cost_function(sub_opti[\"assigned_day\"].values, flag_prompt=True)\n\ndf_daily_opti = pd.DataFrame(index=daily_occupancy_opti.keys(), \n                             data=list(daily_occupancy_opti.values()), \n             columns=['nb_people'])\ndf_daily[\"nb_opti\"] = df_daily_opti['nb_people']\ndf_daily[\"delta_nb_opti\"] = df_daily[\"nb_opti\"] - df_daily['nb_people']","4fdb6ad8":"df_daily","7c1e1184":"fig = plt.figure(figsize=(12, 6))\nplt.title(\"Occupancy : compare my best \/ optimal\")\nplt.plot(df_daily.index, df_daily[\"nb_people\"], label=\"my_best\")\nplt.plot(df_daily.index, df_daily[\"nb_opti\"], label=\"opti\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"Days before Christmas\")\nax.set_ylabel(\"nb people\")","b3d14334":"df_daily[\"delta_nb_opti\"].plot()","c15fb212":"arr_choices = fun_find_choices_sub(sub_my_best[\"assigned_day\"].values)\ndf_best = pd.DataFrame(arr_choices.astype(np.int64), columns=[\"choice\"]) \ndf_best[\"day\"] = best\ndf_best[\"day_opti\"] = sub_opti[\"assigned_day\"].values\ndf_best[\"choice_opti\"] = arr_choice_opti.astype(np.int64)\ndf_best.describe()","31588727":"df_best[\"choice\"].value_counts()","e10de2b6":"df_best[\"choice_opti\"].value_counts()","a4edc794":"fig = plt.figure(figsize=(14, 6)) \nplt.title(\"Count of choices # : compare current best & optimal\")\nax = sns.countplot(y=\"value\", hue=\"variable\", \n                   data=df_best.melt(value_vars=['choice', 'choice_opti']))\nax.set_ylabel(\"choice #\");\n","9b6fa35f":"list_best_cost200_1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' +\n    'list_best_cost200_fs10_rfm0.05_dc2_rm0.2_nk_3_gen1000000_s426993.2726332134.pkl')\nlist_best_cost1000_1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' +\n    'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen200000_s89924.27707458043.pkl')\nlist_best_cost2000_1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' +\n    'list_best_cost2000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s98547.53260584155.pkl')\nlist_best_cost2000_1 = np.array(list_best_cost2000_1)\nlist_best_cost2000_2 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' +\n    'list_best_cost2000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen200000_s90591.5811766185.pkl')\nlist_best_cost2000_2 = np.array(list_best_cost2000_2)\n\nfig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost200_1, label=\"200\")\nplt.plot(list_best_cost1000_1, label=\"1000 #1\")\nplt.plot(list_best_cost2000_1, label=\"2000 #1\")\nplt.plot(list_best_cost2000_2, label=\"2000\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"Population size impact\");","78fe324a":"fig = plt.figure(figsize=(12, 8))\nplt.plot(np.arange(list_best_cost200_1.shape[0])*200\/1000,list_best_cost200_1, \n         label=\"200\")\nplt.plot(list_best_cost1000_1, label=\"1000 #1\")\nplt.plot(np.arange(list_best_cost2000_1.shape[0])*2000\/1000, \n         list_best_cost2000_1, label=\"2000 #1\")\nplt.plot(np.arange(list_best_cost2000_2.shape[0])*2000\/1000, \n         list_best_cost2000_2, label=\"2000 #2\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"equivalent computation time [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"Population size impact\");","0e188164":"fig = plt.figure(figsize=(12, 8))\nplt.plot(np.arange(list_best_cost200_1.shape[0])*200\/1000,list_best_cost200_1, \n         label=\"200\")\nplt.plot(list_best_cost1000_1, label=\"1000 #1\")\nplt.plot(np.arange(list_best_cost2000_1.shape[0])*2000\/1000, \n         list_best_cost2000_1, label=\"2000 #1\")\nplt.plot(np.arange(list_best_cost2000_2.shape[0])*2000\/1000, \n         list_best_cost2000_2, label=\"2000 #2\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"equivalent computation time [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"Population size impact\");\nax.set_xlim([0,25000])","ff55d22c":"path_RPM1 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s99225.99788819549.pkl'\npath_RPM2 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.2_nk_20_gen50000_s381309.48944465496.pkl'\npath_RPM3 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.3_nk_20_gen50000_s421919.51684736356.pkl'\nlist_best_cost_RPM1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_RPM1)\nlist_best_cost_RPM2 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_RPM2)\nlist_best_cost_RPM3 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_RPM3)\nfig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost_RPM1, label=\"R_POP_MUT = 0.1\")\nplt.plot(list_best_cost_RPM2, label=\"R_POP_MUT = 0.2\")\nplt.plot(list_best_cost_RPM3, label=\"R_POP_MUT = 0.3\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"R_POP_MUT impact\");\nax.set_xlim([0 ,50000]);","3b71cb60":"path_RM1 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s99225.99788819549.pkl'\npath_RM2 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen50000_s109860.65058950568.pkl'\npath_RM5 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen50000_s214233.05776615342.pkl'\nlist_best_cost_RPM1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_RM1)\nlist_best_cost_RPM2 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_RM2)\nlist_best_cost_RPM5 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_RM5)\nfig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost_RPM1, label=\"R_MUT = 0.01\")\nplt.plot(list_best_cost_RPM2, label=\"R_MUT = 0.02\")\nplt.plot(list_best_cost_RPM5, label=\"R_MUT = 0.05\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"R_MUT impact\");\nax.set_xlim([0 ,50000]);","6d1a92f2":"path_NB1 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen200000_s89924.27707458043.pkl'\npath_NB2_1 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s96208.60596179293.pkl'\npath_NB2_2 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s94453.49753916638.pkl'\npath_NB2_3 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s91042.12644135197.pkl'\n\npath_B1_1 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen50000_s319490.03112310503.pkl'\npath_B1_2 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen150000_s290524.2660717894.pkl'\npath_B1_3 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s270105.47270251444.pkl'\npath_B1_4 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s92151.41696552017.pkl'\npath_B1_5 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s89450.1477974278.pkl'\npath_B1_6 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s88419.49004815941.pkl'\n\npath_B2_1 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen50000_s91072.03135739548.pkl'\npath_B2_2 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen150000_s89893.01980541403.pkl'\npath_B2_3 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s89027.70096301885.pkl'\npath_B2_4 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s87875.04506597946.pkl'\npath_B2_5 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s86868.67258295594.pkl'\npath_B2_6 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen100000_s86508.96967131883.pkl'","c7cd819f":"list_best_cost_NB1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_NB1)\n\nlist_best_cost_NB2_1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_NB2_1)\nlist_best_cost_NB2_2 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_NB2_2)\nlist_best_cost_NB2_3 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_NB2_3)\nlist_best_cost_NB2 = np.concatenate((list_best_cost_NB2_1, list_best_cost_NB2_2,\n                                     list_best_cost_NB2_3))\nlist_best_cost_B1_1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B1_1)\nlist_best_cost_B1_2 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B1_2)\nlist_best_cost_B1_3 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B1_3)\nlist_best_cost_B1_4 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B1_4)\nlist_best_cost_B1_5 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B1_5)\nlist_best_cost_B1_6 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B1_6)\nlist_best_cost_B1 = np.concatenate((list_best_cost_B1_1, list_best_cost_B1_2,\n                                     list_best_cost_B1_3, list_best_cost_B1_4,\n                                    list_best_cost_B1_5, list_best_cost_B1_6))\n\nlist_best_cost_B2_1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B2_1)\nlist_best_cost_B2_2 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B2_2)\nlist_best_cost_B2_3 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B2_3)\nlist_best_cost_B2_4 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B2_4)\nlist_best_cost_B2_5 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B2_5)\nlist_best_cost_B2_6 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_B2_6)\nlist_best_cost_B2 = np.concatenate((list_best_cost_B2_1, list_best_cost_B2_2,\n                                     list_best_cost_B2_3, list_best_cost_B2_4,\n                                    list_best_cost_B2_5, list_best_cost_B2_6))\n\nfig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost_NB1, label=\"no boost #1\")\nplt.plot(list_best_cost_NB2, label=\"no boost #2\")\nplt.plot(list_best_cost_B1, label=\"boost #1\")\nplt.plot(list_best_cost_B2, label=\"boost #2\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"Simple seq. Boost impact\");\n#ax.set_xlim([0 ,50000]);","370127ef":"fig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost_NB1, label=\"no boost #1\")\nplt.plot(list_best_cost_NB2, label=\"no boost #2\")\nplt.plot(list_best_cost_B1, label=\"boost #1\")\nplt.plot(list_best_cost_B2, label=\"boost #2\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"Simple seq. Boost impact [Start Zoom.]\");\nax.set_xlim([0 ,50000]);","14ac6397":"fig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost_NB1, label=\"no boost #1\")\nplt.plot(list_best_cost_NB2, label=\"no boost #2\")\nplt.plot(list_best_cost_B1, label=\"boost #1\")\nplt.plot(list_best_cost_B2, label=\"boost #2\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"Simple seq. Boost impact [End Zoom.]\");\nax.set_xlim([280000, 600000]);\nax.set_ylim([80000, 100000])","ca2c0319":"path_cr4_1 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen200000_s84928.91135928089.pkl'\npath_cr4_2 = 'list_best_cost1000_fs10_rfm0.05_dc2_rm0.1_nk_20_gen200000_s84089.67769691352.pkl'\nlist_best_cost_cr4_1 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_cr4_1)\nlist_best_cost_cr4_2 = joblib.load(PATH_TO_EXPLORE_DATA + '\/' + path_cr4_2)\nlist_best_cost_cr4 = np.concatenate((list_best_cost_cr4_1, \n                                     list_best_cost_cr4_2))","6d80801e":"fig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost_cr4, label=\"CH RANGE=4 & boost\")\nplt.plot(list_best_cost_B2, label=\"CH RANGE=10 & boost\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"CHOICE_RANGE_MAX impact\");\nax.set_xlim([0 ,50000]);","de7bcd58":"fig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost_cr4, label=\"CH RANGE=4 & boost\")\nplt.plot(list_best_cost_B2, label=\"CH RANGE=10 & boost\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"CHOICE_RANGE_MAX impact\");\nax.set_xlim([15000, 50000]);\nax.set_ylim([80000, 120000]);","47d2b6c0":"fig = plt.figure(figsize=(12, 8))\nplt.plot(list_best_cost_cr4, label=\"CH RANGE=4 & boost\")\nplt.plot(list_best_cost_B2, label=\"CH RANGE=10 & boost\")\nplt.legend(loc='upper right');\nax = fig.gca()\nax.set_xlabel(\"epochs [-]\")\nax.set_ylabel(\"cost [$]\")\nax.set_title(\"CHOICE_RANGE_MAX impact [Zoom end.]\");\n#ax.set_xlim([50000, 50000]);\nax.set_ylim([80000, 100000]);","905a769f":"submission_final","8133e390":"During mutation, we use this probabilities to have a choice close to zero.\n\nIt depends of family size. more impact for big families","45cea119":"### CHOICES RANGE","dfe2adea":"# Explore day occupancy","9c791fd3":"# Cost Function","a055e9e3":"# Prepare mutation function","5d6a3c61":"### Load","225aeeb3":"### Random paths method","f7d623e8":"# Explore family choice cost","5d55c7c0":"### First version : from baseline","316a200e":"### Mutation ratio","dfaf67d2":"#### Compare current Best with optimum","9f2c2ca8":"### Data preparation","d2ead6ce":"# Definitions","d963a460":"\nThese method take sample as input and generate NB_FIRST_POP (usually 1000) paths along famillies to find a best by trying one by one all choices of families.\n\nIt can take 15min to proceed.","cf911f4c":"### Initialize costs","0ef3492c":"nb pop = 200 is too low and nb pop = 2000 is too slow.","ec2e695f":"##### Ranges to seek for boost mode","df7f6f0c":"# Generate first population","c1a889f0":"##### Load Pre-generate population","e1ae9fc8":"### Boost activation","db2eb27a":"### C++ code creation : stochprodsearch_03.cpp","55a4aab4":"# Prepare generation","be329452":"### Init data","fcebd200":"This probability is inversely proportional to the number of people for each days. \n\nWe assume that all choices are chosen and we sum all choices ","0071b802":"### Python module creation : stochprodsearch_03.py","f13b7fea":"### Optimized numba version\n\n","06d177a4":"### 10 ranges method","f28743f9":"# Santa's 2019 : Original Genetic Algorithm method","66470b3f":"#### Compare my best with optimum","6ce9a250":"This lookup table is used only for choice 10, where we need to find a random day.\n\nWe try to have this random day on a day with low occupancy.\n\nWe calculate a weight for each days proportional equal to the maximum sum of people who want this date.\n\nThe day propability will be inversely proportional to this weight.","0e29d595":"# Explore Hyper-parameters","c38dcd07":"### Boost optim (build)","0a092eec":"##### All population","61bf323b":"### Code compilation : multi-platform","8198c36e":"### Evolution of cost by number of people into family","33c0f75c":"### Random choice method","815ad856":"# Loop over generations","ab2c77d2":"### Load","849f8059":"# Algo gen","12e03f29":"### Creation of probality matrix","52be4956":"#### module test","43e29a3f":"### Creation of probability matrix","3f5db172":"This Notebook contains : \n- main fonction to optimize schedule of santa tour 2019 KAGGLE competition : (Loop over Generation part)\n- a lot of sub-functions used by genetic algo main in Useful functions, Prepare mutation and Cost function parts.\n- cost function optim is based on kaggle kernel: https:\/\/www.kaggle.com\/xhlulu\/santa-s-2019-faster-cost-function-24-s\n- C++ Stochastic Product Search is base on kaggle kernel : https:\/\/www.kaggle.com\/golubev\/c-stochastic-product-search-65ns & https:\/\/www.kaggle.com\/dmintry\/c-stochastic-product-search-in-few-threads\n- Most of the python functions are numba optimized\n- Link to my Github : https:\/\/github.com\/jeugregg\/santa-workshop-tour-2019\/\n- Link to my report\/presentation (in French) : https:\/\/github.com\/jeugregg\/santa-workshop-tour-2019\/tree\/master\/doc\n\nVERSIONS :\n- V3.2: 16\/02\/2020 : fixes sps c++ add-on for range choices = 10\n- V3.1: 15\/02\/2020 : impove sps add-on\n- V3.0: 12\/02\/2020 : add stochastic product search boost \n- V2.1: 04\/02\/2020 : correction fun_vect_mut\n- V2.0: 03\/02\/2020 : random path population generation\n- V1.1: 03\/02\/2020 : @njit(parallel=True)\n- V1.0: 03\/02\/2020 : update generate_crossing_prob (optimize perf.)\n\n\n","74a223c5":"# Create some lookup dictionaries and define constants\n\nYou don't need to do it this way. :-)","c7ebb72e":"# Stochastic Product Search","225d1a57":"This is the main function of algo. genetic. \nIt executes subfuntions : \n- Selection\n- Crossover\n- Mutation\n- Evaluation\n\n2 addons are avaiblable : \n- Simple Boost\n- Stochastic Product Search","12c68f08":"### Save pop","de42e163":"# Save results","cc11049b":"## Creation of days probabilities by family","ab2e4726":"Reference : \nAdapted version of https:\/\/www.kaggle.com\/xhlulu\/santa-s-2019-faster-cost-function-24-s","09a304dc":"## Explore results","3921c713":"#### Run function","670fbfc6":"### Selection probability","ab220d80":"# Import","526a0dcb":"# Useful functions","704a9b3c":"# output","ce0a5bd4":"### Population size","7365ac92":"#### p max = 1, p min = 0.01","250a94f7":"# Exploration functions","3c4c4de3":"# Read in the family information and sample submission","f2378172":"### Random mutation method"}}