{"cell_type":{"8d9083ce":"code","f2393247":"code","eee7a7ea":"code","35fc9b55":"code","569317c6":"code","420cd63c":"code","0802c27d":"code","bc94d304":"markdown"},"source":{"8d9083ce":"#constants\nIMG_FOLDER_PATH=\"..\/input\/hpa-single-cell-image-classification\/train\/\"\nCSV_FILE_PATH=\"..\/input\/hpa-single-cell-image-classification\/train.csv\"\nMASK_FOLDER_PATH=\".\/masks\"","f2393247":"#load HPA dataset\nimport pandas as pd\nCSV_FILE_PATH=\"..\/input\/hpa-single-cell-image-classification\/train.csv\"\nid_labels_array=pd.read_csv(CSV_FILE_PATH)\nid_array=(id_labels_array[\"ID\"]).tolist()\nlabels_dict=id_labels_array.set_index('ID').T.to_dict('list')\nlabels_dict = {num: labels[0] for num, labels in labels_dict.items()}","eee7a7ea":"%%capture\n#function for cell segmentation\n!pip install https:\/\/github.com\/CellProfiling\/HPA-Cell-Segmentation\/archive\/master.zip\nimport hpacellseg.cellsegmentator as cellsegmentator\nfrom hpacellseg.utils import label_cell, label_nuclei\nfrom PIL import Image\nimport numpy as np\nNUC_MODEL = \"..\/input\/hpacellsegmentatormodelweights\/dpn_unet_nuclei_v1.pth\"\nCELL_MODEL = \"..\/input\/hpacellsegmentatormodelweights\/dpn_unet_cell_3ch_v1.pth\"\nsegmentator = cellsegmentator.CellSegmentator(\n    NUC_MODEL,\n    CELL_MODEL,\n    scale_factor=0.25,\n    device=\"cpu\", # why not gpu? does not lead to major increase, as the bottleneck is the file loading!\n    padding=False,\n    multi_channel_model=True,\n)\n\n#function to get mask only using supplied img_id\ndef get_mask(img_id):\n    ch_r=Image.open(IMG_FOLDER_PATH+img_id+\"_red.png\")\n    ch_y=Image.open(IMG_FOLDER_PATH+img_id+\"_yellow.png\")\n    ch_b=Image.open(IMG_FOLDER_PATH+img_id+\"_blue.png\")\n    nuc_segmentations = segmentator.pred_nuclei([np.asarray( ch_b )])\n    cell_segmentations = segmentator.pred_cells([\n            [np.asarray( ch_r )],\n            [np.asarray( ch_y )],\n            [np.asarray( ch_b )]\n        ])\n    nuclei_mask, mask = label_cell(nuc_segmentations[0], cell_segmentations[0])\n    mask = np.uint8(mask)\n    return mask\n\n#function for bbox creation\ndef get_bboxes(mask):\n    mask_flattened=np.ravel(mask)\n    cell_ids=set(mask_flattened)\n    cell_ids.remove(0)\n    bboxes=list()\n    for cell_id in cell_ids:\n        a = np.where(mask == cell_id)\n        ymin, ymax, xmin, xmax = np.min(a[0]), np.max(a[0]), np.min(a[1]), np.max(a[1])\n        bboxes.append([ymin,ymax,xmin,xmax])\n    return bboxes","35fc9b55":"#this step takes more than the maximum of 9h allowed for a kaggle notebook:\n##SOLUTION1: divide dataset into about 20 pieces and run kaggle notebooks in parallel, one for each part\n##SOLUTION2: download data and compute on local machine\n##  --> PROBLEM WITH SOLUTION 2: kaggle upload of large datasets is very buggy\n\nimport pickle\nfrom tqdm import tqdm\n\nbboxes_dict={}\nfor img_id in tqdm(id_array[:10]):    ###LIMITED TO 10 ONLY FOR DEMONSTRATION\n    mask=get_mask(img_id)\n    bboxes=get_bboxes(mask)\n    bboxes_dict[img_id]=bboxes\n    \nwith open('bboxes_dict.pkl', 'wb') as handle:\n    pickle.dump(bboxes_dict, handle, protocol=pickle.HIGHEST_PROTOCOL)","569317c6":"df = pd.DataFrame(columns=['ID','cell','Label','ymin','ymax','xmin','xmax'])\nfor img_id in bboxes_dict.keys():\n    for i,bbox in enumerate(bboxes_dict[img_id]):\n        df = df.append({'ID': img_id,\n                        'cell':i+1,\n                        'Label': labels_dict[img_id],\n                        'ymin': bbox[0],\n                        'ymax': bbox[1],\n                        'xmin': bbox[2],\n                        'xmax': bbox[3]}, ignore_index=True)\nwith open('hpa_data_df.pkl', 'wb') as handle:\n    pickle.dump(df, handle, protocol=pickle.HIGHEST_PROTOCOL)","420cd63c":"#show results\ndf","0802c27d":"#show results\nbboxes_dict","bc94d304":"#### this notebook is part of the documentation on my HPA approach  \n    -> main notebook: https:\/\/www.kaggle.com\/philipjamessullivan\/0-hpa-approach-summary\n\n# 1: make masks, get bboxes, make dataframe\n## GOAL:\nextract the bounding boxes of the individual cells contained in each image  \n\n## RESULTS:\n**dataset name:** \"hpa-data\" (linked to this notebook)  \n---> contains two files;  \n\n**file1 type:** dictionary (pickled)  \n**file1 name:** \"bboxesone.pkl\"  \n**file 1 contents:** all image ids mapped to all bbox coordinates contained  \n\n**file2 type:** dataframe (pickled)   \n**file2 name:** \"hpa-data.pkl  \n**file2 contents:** all image ids mapped to all labels and all bbox coordinates with one row per bbox and one column per value"}}