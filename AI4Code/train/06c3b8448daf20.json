{"cell_type":{"3f29e172":"code","2b0a447a":"code","05032483":"code","b307a1a7":"code","3136d670":"code","1c68ff7d":"code","50b8a09a":"code","3128c48a":"code","965bf13d":"code","3ede3989":"code","3ef811b9":"code","6e2fd893":"code","b4b2e197":"code","6dbe763a":"code","7afec1ae":"code","084049d9":"code","57807d95":"code","9cc06925":"code","7248969e":"code","acadde12":"code","168018b0":"code","c394ae80":"code","085debf6":"code","e0fea65f":"markdown"},"source":{"3f29e172":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport time\nimport math\nimport itertools\nfrom wordcloud import WordCloud\nfrom itertools import combinations\n\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\n\nSIA = SentimentIntensityAnalyzer()\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.\n\nsns.set_style(\"whitegrid\")\nnotebookstart = time.time()\npd.options.display.max_colwidth = 500","2b0a447a":"def meta_text_features(df, col):\n    df[col] = df[col].astype(str)\n    df[col + '_num_words'] = df[col].apply(lambda comment: len(comment.split())) # Count number of Words\n    df[col + '_num_unique_words'] = df[col].apply(lambda comment: len(set(w for w in comment.split())))\n    df[col + '_words_vs_unique'] = df[col+'_num_unique_words'] \/ df[col+'_num_words'] * 100 # Count Unique Words\n    if col == \"text\":\n        df[col+\"_vader_Compound\"]= df[col].apply(lambda x:SIA.polarity_scores(x)['compound'])\n\n    return df\n\ndef big_count_plotter(plot_df, plt_set, columns, figsize, hue = None,\n                      custom_palette = sns.color_palette(\"Paired\", 15), top_n = 15):\n    \"\"\"\n    Iteratively Plot all categorical columns\n    Has category pre-processing - remove whitespace, lower, title, and takes first 30 characters.\n    \"\"\"\n    rows = math.ceil(len(plt_set)\/columns)\n    n_plots = rows*columns\n    f,ax = plt.subplots(rows, columns, figsize = figsize)\n    for i in range(0,n_plots):\n        ax = plt.subplot(rows, columns, i+1)\n        if i < len(plt_set):\n            c_col = plt_set[i]\n            plt_tmp = plot_df.loc[plot_df[c_col].notnull(),c_col]\\\n                .astype(str).str.lower().str.strip()\\\n                .str.title().apply(lambda x: x[:30])\n            plot_order = plt_tmp.value_counts().index[:top_n]\n            if hue:\n                sns.countplot(y = plt_tmp, ax = ax, hue = hue, order = plot_order, palette = custom_palette)\n            else:\n                sns.countplot(y = plt_tmp, ax = ax, order = plot_order, palette = custom_palette)\n            ax.set_title(\"{} - {} Missing\".format(c_col.title(), plot_df[c_col].isnull().sum()))\n            ax.set_ylabel(\"{} Categories\".format(c_col.title()))\n            ax.set_xlabel(\"Count\")\n        else:\n            ax.axis('off')\n\n    plt.tight_layout(pad=1)\n    \n    \ndef big_boxplotter(plot_df, plt_set, columns, figsize, hue = None, plottype='kde',\n                   custom_palette = sns.color_palette(\"Dark2\", 15), quantile = .99):\n    rows = math.ceil(len(plt_set)\/columns)\n    n_plots = rows*columns\n    f,ax = plt.subplots(rows, columns, figsize = figsize)\n    palette = itertools.cycle(custom_palette)\n    for i in range(0,n_plots):\n        ax = plt.subplot(rows, columns, i+1)\n        if i < len(plt_set):\n            cont_col = plt_set[i]\n            if hue:\n                plt_tmp = plot_df.loc[(plot_df[cont_col].notnull()) & \n                                          (plot_df[cont_col] < plot_df[cont_col].quantile(quantile)),\n                                      [cont_col, hue]]\n                if plottype == 'box':\n                    sns.boxplot(data=plt_tmp, x=cont_col, y=hue, color = next(palette), ax=ax)\n                    ax.set_ylabel(\"Categories\")\n                elif plottype == 'kde':\n                    for h in plt_tmp.dropna()[hue].value_counts()[:5].index:\n                        c = next(palette)\n                        sns.distplot(plt_tmp.loc[plt_tmp[hue] == h,cont_col], bins=10, kde=True, ax=ax,\n                                     kde_kws={\"color\": c, \"lw\": 2, \"label\":h}, color=c)\n                    ax.set_ylabel(\"Density Occurence\")\n            else:\n                plt_tmp = plot_df.loc[(plot_df[cont_col].notnull()) &\n                                          (plot_df[cont_col] < plot_df[cont_col].quantile(quantile)),\n                                      cont_col].astype(float)\n                if plottype == 'box':\n                    sns.boxplot(plt_tmp, color = next(palette), ax=ax)\n                    ax.set_ylabel(\"Categories\")\n                elif plottype == 'kde':\n                    sns.distplot(plt_tmp, bins=10, kde=True, ax=ax,\n                        kde_kws={\"color\": \"k\", \"lw\": 2}, color=next(palette))\n                    ax.set_ylabel(\"Density Occurence\")\n            ax.set_title(\"{} - {:.0f} Missing - {:.2f} Max\".format(cont_col.title(),\n                plot_df[cont_col].isnull().sum(), plot_df[cont_col].max()))\n            ax.set_xlabel(\"Value\")\n            \n        else:\n            ax.axis('off')\n\n    plt.tight_layout(pad=1)\n    \ndef big_word_cloud(plot_df, plt_set, columns, figsize, cmap = \"plasma\"):\n    \"\"\"\n    Iteratively Plot WordClouds\n    \"\"\"\n    rows = math.ceil(len(plt_set)\/columns)\n    n_plots = rows*columns\n    f,ax = plt.subplots(rows, columns, figsize = figsize)\n    for i in range(0,n_plots):\n        ax = plt.subplot(rows, columns, i+1)\n        if i < len(plt_set):\n            str_col = plt_set[i]\n            string = \" \".join(plot_df.loc[plot_df[str_col].notnull(),str_col]\\\n                              .astype(str).str.lower().str.replace(\"none\", \"\").str.title())\n            string += 'EMPTY'\n            ax = plt.subplot(rows, 2, i+1)\n            plot_cloud(string, ax, title = \"{} - {:.0f} Missing\".format(\n                str_col.title(), plot_df[str_col].isnull().sum()), cmap = cmap)\n        else:\n            ax.axis('off')\n    plt.tight_layout(pad=0)\n    \ndef plot_cloud(string, ax, title = \"WordCloud\", cmap = \"plasma\"):\n    wordcloud = WordCloud(width=800, height=500,\n                          collocations=True,\n                          background_color=\"black\",\n                          max_words = 100,\n                          colormap=cmap\n                ).generate(string)\n\n    ax.imshow(wordcloud, interpolation='bilinear')\n    ax.set_title(title,  fontsize=18)\n    ax.axis('off')\n    \n    \ndef rank_correlations(df, figsize=(12,20), n_charts = 18, polyorder = 2, custom_palette = sns.color_palette(\"Paired\", 5)):\n    # Rank Correlations\n    palette = itertools.cycle(custom_palette)\n    continuous_rankedcorr = (df\n                             .corr()\n                             .unstack()\n                             .drop_duplicates().reset_index())\n    continuous_rankedcorr.columns = [\"f1\",\"f2\",\"Correlation Coefficient\"]\n    continuous_rankedcorr['abs_cor'] = abs(continuous_rankedcorr[\"Correlation Coefficient\"])\n    continuous_rankedcorr.sort_values(by='abs_cor', ascending=False, inplace=True)\n\n    # Plot Top Correlations\n    top_corr = [(x,y,cor) for x,y,cor in list(continuous_rankedcorr.iloc[:, :3].values) if x != y]\n    f, axes = plt.subplots(int(n_charts\/3),3, figsize=figsize, sharex=False, sharey=False)\n    row = 0\n    col = 0\n    for (x,y, cor) in top_corr[:n_charts]:\n        if col == 3:\n            col = 0\n            row += 1\n        g = sns.regplot(x=x, y=y, data=df, order=polyorder, ax = axes[row,col], color=next(palette))\n        axes[row,col].set_title('{} and {}'.format(x, y))\n        axes[row,col].text(0.18, 0.93,\"Cor Coef: {:.2f}\".format(cor),\n                           ha='center', va='center', transform=axes[row,col].transAxes)\n        col += 1\n    plt.tight_layout(pad=0)\n    plt.show()\n    \n    \n# Data Exploration\ndef custom_describe(df, value_count_n = 5):\n    \"\"\"\n    Custom Describe Function - More Tailored to categorical type variables..\n    \"\"\"\n    unique_count = []\n    for x in df.columns:\n        unique_values_count = df[x].nunique()\n        value_count = df[x].value_counts().iloc[:5]\n\n        value_count_list = []\n        value_count_string = []\n        \n        for vc_i in range(0,value_count_n):\n            value_count_string += [\"ValCount {}\".format(vc_i+1),\n                                   \"Occ\"]\n            if vc_i <= unique_values_count - 1:\n                value_count_list.append(value_count.index[vc_i])\n                value_count_list.append(value_count.iloc[vc_i])\n            else:\n                value_count_list.append(np.nan)\n                value_count_list.append(np.nan)\n        \n        unique_count.append([x,\n                             unique_values_count,\n                             df[x].isnull().sum(),\n                             df[x].dtypes] + value_count_list)\n        \n    print(\"Dataframe Dimension: {} Rows, {} Columns\".format(*df.shape))\n    return pd.DataFrame(unique_count,\n            columns=[\"Column\",\"Unique\",\"Missing\",\"dtype\"\n                    ] + value_count_string\n                       ).set_index(\"Column\")\n\nprint(\"Helper Functions Ready\")","05032483":"time_cols = [\n    'month',\n    'day',\n    'year',\n]\n\ncategorical_cols = [\n 'gender',\n 'raceethnicity',\n 'city',\n 'state',\n 'cause',\n 'armed',\n#  'county_bucket',\n#  'nat_bucket',\n#  'state_fp',\n#  'county_fp',\n#  'tract_ce',\n#  'geo_id',\n#  'county_id',\n]\n\n\ncontinuous_cols = [\n    'age',\n    'pop',\n    'share_white',\n    'share_black',\n    'share_hispanic',\n    'p_income',\n    'h_income',\n    'county_income',\n    'comp_income',\n    'pov',\n    'urate',\n    'college'\n]\n\ntext_cols = [\n    'name',\n    'namelsad',\n    'lawenforcementagency',\n    'streetaddress',\n]\n\ngeo_cols =  [\n    'latitude',\n    'longitude'\n\n]\n\ndf = pd.read_csv(\"\/kaggle\/input\/fivethirtyeight-police-killings-dataset\/police_killings.csv\", encoding = \"ISO-8859-1\")\nprint(\"DF Shape: {} Rows, {} Columns\".format(*df.shape))\n\n# Data Cleaning\ndf = df.assign(\n    age = df.age.astype(str).replace('Unknown', np.nan),\n    share_white = df.share_white.replace('-', np.nan),\n    share_black = df.share_black.replace('-', np.nan),\n    share_hispanic = df.share_hispanic.replace('-', np.nan),\n    p_income = df.p_income.replace('-', np.nan),\n    pov = df.pov.replace('-', np.nan)\n)\nfor col in continuous_cols:\n    df[col] = pd.to_numeric(df[col])","b307a1a7":"display(df.sample(5))","3136d670":"print(\"Categorical Variables\")\ndisplay(custom_describe(df[categorical_cols+text_cols]))\nprint(\"Continuous Variables\")\ndisplay(df[continuous_cols].describe().T)","1c68ff7d":"big_word_cloud(df,\n               plt_set = ['name'],\n               columns = 1,\n               cmap='Spectral',\n               figsize = [15,15])\nplt.show()","50b8a09a":"big_count_plotter(plot_df = df,\n                  plt_set = categorical_cols,\n                  columns = 2,\n                  figsize = [14,16],\n                  custom_palette = sns.color_palette(\"Paired\", 15))","3128c48a":"big_boxplotter(plot_df = df,\n               plt_set = continuous_cols,\n               hue = None,\n               columns = 2,\n               figsize = [12,18],\n               quantile = .98)","965bf13d":"# Plot Correlation Matrix\nf, ax = plt.subplots(figsize=[12,8])\nax = sns.heatmap(df[continuous_cols].corr(), \n                 annot=True, fmt=\".2f\",\n                 vmin=-1, vmax=1,\n                 cbar_kws={'label': 'Correlation Coefficient'})\nax.set_title(\"Continuous Variable Correlation Matrix\")\nplt.show()","3ede3989":"rank_correlations(df = df.loc[:,continuous_cols])","3ef811b9":"big_boxplotter(plot_df = df,\n               plt_set = continuous_cols,\n               hue = 'gender',\n               plottype= 'box',\n               columns = 2,\n               figsize = [10,14],\n               quantile = .98)","6e2fd893":"big_boxplotter(plot_df = df,\n               plt_set = continuous_cols,\n               hue = 'raceethnicity',\n               plottype= 'box',\n               columns = 2,\n               figsize = [16,20],\n               quantile = .98)","b4b2e197":"def big_count_pivot_tables(df, heatmap_vars, index_variable, top_n_factors):\n    aggfunc='count'\n    f, axes = plt.subplots(len(heatmap_vars), 3, figsize = [16,4*len(heatmap_vars)], sharex=False, sharey=False)\n    for row,column_var in enumerate(heatmap_vars):\n        tmp_plot_pd = df.loc[(df[column_var].isin(df[column_var].value_counts()[:top_n_factors].index)) &\n                              (df[index_variable].isin(df[index_variable].value_counts()[:top_n_factors].index)) ,:].copy()\n        tmp_plot_pd['placeholder'] = 1\n\n        pivot_pd = pd.pivot_table(tmp_plot_pd, index=index_variable, columns=column_var,\n                                  values='placeholder', aggfunc=aggfunc).fillna(0)\n        pivot_pd_row_norm = pivot_pd.div(pivot_pd.sum(axis=1), axis=0).mul(100).round(0)\n        pivot_pd_col_norm = pivot_pd.div(pivot_pd.sum(axis=0), axis=1).mul(100).round(0)\n\n        # Plot\n        sns.heatmap(pivot_pd, annot=True, fmt=\"g\", linewidths=.5,\n                    linecolor='black', cbar=False, cmap=\"Blues\", ax = axes[row,0])\n\n        sns.heatmap(pivot_pd_row_norm, annot=True, fmt=\"g\", linewidths=.5,\n                    linecolor='black', cbar=False, cmap=\"Reds\", ax = axes[row,1])\n\n        sns.heatmap(pivot_pd_col_norm, annot=True, fmt=\"g\", linewidths=.5,\n                    linecolor='black', cbar=False, cmap=\"Purples\", ax = axes[row,2])  \n\n        axes[row,0].set_title(\"{}: Total Police Killins Cases\".format(column_var))\n        axes[row,1].set_title(\"Row Normalised Pivot Table\")\n        axes[row,2].set_title(\"Columns Normalised Pivot Table\")\n\n    plt.tight_layout(pad=1)\n    plt.show()\n    \ndef big_agg_pivot_tables(df, heatmap_vars, top_n_factors, value_var, aggfunc, figsize, color, columns=2):\n    all_combinations = [x for x in combinations(heatmap_vars, 2)]\n    rows = math.ceil(len(all_combinations)\/columns)\n    \n    f, ax = plt.subplots(rows, columns, figsize = figsize, sharex=False, sharey=False)\n    for i,(index_var, column_var) in enumerate(all_combinations):\n        ax = plt.subplot(rows, columns, i+1)            \n        tmp_plot_pd = df.loc[(df[column_var].isin(df[column_var].value_counts()[:top_n_factors].index)) &\n                              (df[index_var].isin(df[index_var].value_counts()[:top_n_factors].index)),\n                             [index_var,column_var,value_var]].copy()\n\n        pivot_pd = pd.pivot_table(tmp_plot_pd, index=index_var, columns=column_var,\n                                  values=value_var, aggfunc=aggfunc)\n        # Plot\n        sns.heatmap(pivot_pd, annot=True, fmt=\"g\", linewidths=.5,\n                    linecolor='black', cbar=False, cmap=color, ax = ax)\n\n        ax.set_title(\"{} {} Pivot Table on\\nX: {}, Y: {}\".format(\n            value_var.title(), aggfunc,column_var.title(), index_var.title()))\n\n    plt.tight_layout(pad=1)\n    plt.show()","6dbe763a":"heatmap_vars = ['gender','city','state','cause','armed']\nindex_variable = 'raceethnicity'\ntop_n_factors = 5\n\nbig_count_pivot_tables(df=df, heatmap_vars=heatmap_vars, index_variable=index_variable, top_n_factors=top_n_factors)","7afec1ae":"heatmap_vars = ['gender','city','state','cause','armed','raceethnicity']\ntop_n_factors = 5\nbig_agg_pivot_tables(df=df, heatmap_vars=heatmap_vars,\n                     top_n_factors=top_n_factors, aggfunc='mean',\n                     color='OrRd', value_var='age',\n                     figsize=[14,20], columns=2)","084049d9":"heatmap_vars = ['gender','city','state','cause','armed','raceethnicity']\ntop_n_factors = 5\nbig_agg_pivot_tables(df=df, heatmap_vars=heatmap_vars,\n                     top_n_factors=top_n_factors, aggfunc='mean',\n                     color='Blues', value_var='college',\n                     figsize=[14,20], columns=2)","57807d95":"heatmap_vars = ['gender','city','state','cause','armed','raceethnicity']\ntop_n_factors = 5\nbig_agg_pivot_tables(df=df, heatmap_vars=heatmap_vars,\n                     top_n_factors=top_n_factors, aggfunc='mean',\n                     color='Purples', value_var='county_income',\n                     figsize=[14,20], columns=2)","9cc06925":"heatmap_vars = ['gender','city','state','cause','armed','raceethnicity']\ntop_n_factors = 5\nbig_agg_pivot_tables(df=df, heatmap_vars=heatmap_vars,\n                     top_n_factors=top_n_factors, aggfunc='mean',\n                     color='Greens', value_var='comp_income',\n                     figsize=[14,20], columns=2)","7248969e":"heatmap_vars = ['gender','city','state','cause','armed','raceethnicity']\ntop_n_factors = 5\nbig_agg_pivot_tables(df=df, heatmap_vars=heatmap_vars,\n                     top_n_factors=top_n_factors, aggfunc='mean',\n                     color='mako', value_var='county_bucket',\n                     figsize=[14,20], columns=2)","acadde12":"heatmap_vars = ['gender','city','state','cause','armed','raceethnicity']\ntop_n_factors = 5\nbig_agg_pivot_tables(df=df, heatmap_vars=heatmap_vars,\n                     top_n_factors=top_n_factors, aggfunc='mean',\n                     color='Purples', value_var='nat_bucket',\n                     figsize=[14,20], columns=2)","168018b0":"heatmap_vars = ['gender','city','state','cause','armed','raceethnicity']\ntop_n_factors = 5\nbig_agg_pivot_tables(df=df, heatmap_vars=heatmap_vars,\n                     top_n_factors=top_n_factors, aggfunc='mean',\n                     color='GnBu', value_var='urate',\n                     figsize=[14,20], columns=2)","c394ae80":"heatmap_vars = ['gender','city','state','cause','armed','raceethnicity']\ntop_n_factors = 5\nbig_agg_pivot_tables(df=df, heatmap_vars=heatmap_vars,\n                     top_n_factors=top_n_factors, aggfunc='mean',\n                     color='Reds', value_var='pov',\n                     figsize=[14,20], columns=2)","085debf6":"print(\"Script Complete - Runtime: {:.2f} Minutes\".format((time.time() - notebookstart) \/ 60))","e0fea65f":"# Where Police Have Killed Americans In 2015\n_By Nick Brooks, June 2020_\n\n**Resources:** <br>\n- https:\/\/www.kaggle.com\/fivethirtyeight\/fivethirtyeight-police-killings-dataset\n"}}