{"cell_type":{"14175b5a":"code","b402bb32":"code","751d8482":"code","4845f138":"code","b2ca96bd":"code","8df827f5":"code","3c15d398":"code","390fb5bf":"code","f6aed0d8":"code","dfc4fa02":"code","c896de67":"code","3083b4c8":"code","af595fc6":"code","8b3adc3c":"code","de66f9d9":"code","7ba27013":"code","03deaa7b":"code","95150754":"code","777ab5af":"code","49f8e98a":"code","51122f05":"code","966eb391":"code","b91cf2cc":"code","0bb84a00":"code","11627cbc":"code","5e75066a":"code","95bc7cc5":"code","be63eec9":"code","7c640fb2":"code","182ded74":"code","30d2e7fe":"code","a177d9df":"code","679d8e20":"code","7b645385":"code","d00b437e":"code","39f752c0":"code","1ff49313":"code","b47d0cd7":"code","90724914":"code","22b12628":"code","44c5b0ab":"code","1ddb205b":"code","3839e3cf":"code","85696731":"code","82d12b05":"markdown","32a6c256":"markdown","de1363cb":"markdown","08bf9033":"markdown","fcad6054":"markdown","4f205072":"markdown","1f9f0d12":"markdown","bbd9057e":"markdown","fe2570bb":"markdown","d05aeaf0":"markdown","99976432":"markdown","2498a414":"markdown","1eada843":"markdown","54e5d9e4":"markdown","b6dd44fb":"markdown","ba257d7a":"markdown","cbb66e39":"markdown","18178d41":"markdown","36468a6a":"markdown","0f83d400":"markdown","f5d28205":"markdown","be14f86a":"markdown","66124727":"markdown","f08a955e":"markdown","7d025a8a":"markdown","f04ccda7":"markdown","bd079ef0":"markdown","8a42a6e0":"markdown","7d8c168d":"markdown","0ad2c31b":"markdown","29d6b525":"markdown","ce1ddf2c":"markdown","65a12fde":"markdown","0490c904":"markdown","cff33f41":"markdown","fa6ed70f":"markdown","3c3be525":"markdown","126bf932":"markdown","ab3f02e0":"markdown","6a6454d7":"markdown"},"source":{"14175b5a":"# all base libs\nimport numpy as np \nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\n\n\n# all numpy related libs\nfrom numpy import expand_dims,zeros,ones\nfrom numpy.random import randn,randint\n\n# all image based libraries\nimport cv2\n\n# all keras libraries\n\nimport keras\nfrom keras.optimizers import Adam\nfrom keras.models import Sequential, load_model,Model\nfrom keras.layers import Input,Dense,Reshape,Flatten,Conv2D,Conv2DTranspose,LeakyReLU,Dropout,Embedding,\\\nConcatenate\n","b402bb32":"data = pd.read_csv(\"..\/input\/fashionmnist\/fashion-mnist_train.csv\")\ndata.head()","751d8482":"# taking all cols except first as it stores labels\npixel_data = data.iloc[:,1:]\n\n# taking labels col\nlabels_data = data.iloc[:,0]\n\n# reshaping all cols to create 28*28 size image in grayscale\npixel_data = np.array(pixel_data.values.reshape(-1, 28, 28, 1))\n\nprint(\"Pixel shape : \", pixel_data.shape)","4845f138":"# meaning of all the labels\nlabels_word = { 0 : \"T-shirt\/top\",\n                1 : \"Trouser\",\n                2 : \"Pullover\",\n                3 : \"Dress\",\n                4 : \"Coat\",\n                5 : \"Sandal\",\n                6 : \"Shirt\",\n                7 : \"Sneaker\",\n                8 : \"Bag\",\n                9 : \"Ankle boot\"\n              }","b2ca96bd":"# plotting one rows and 5 cols of images\nfig, axs = plt.subplots(1,5,figsize=(15,5))\n\nfor i in range(5):\n    img = pixel_data[i]\n    img = np.squeeze(img)\n    axs[i].imshow(img)\n    axs[i].set_title(labels_word[labels_data[i]])\n\nfig.suptitle(\"Plotting first 5 images from dataset\", fontsize=15)\nplt.show()","8df827f5":"# train_data is brought in range of 0 to 1 from 0 to 255, also stored as numpy array for training\ntrain_data = np.array(pixel_data)\ntrain_data = train_data.astype('float')\ntrain_data = train_data\/255.0\n\nprint(\"Final data shape: \", train_data.shape)","3c15d398":"# model for Labels\nn_nodes = 7 * 7\n\n# only one input for labels\ninput_label = Input(shape = (1,))\n\n# embedding layer is required for creating vectors form categories\nmodelGenLabel = Embedding(10, 50)(input_label)\n\n# adding all previous nodes to current layer nodes\nmodelGenLabel = Dense(n_nodes)(modelGenLabel)\n\nmodelGenLabel = Reshape((7, 7, 1))(modelGenLabel)","390fb5bf":"# model for Images\n\nn_nodes = 128 * 7 * 7\n\nimage_input = Input(shape=(100,))\n\nmodelGenImg = Dense(n_nodes)(image_input)\n\n# LeakyRelu is an activation function, slightly faster than RELU, using alpha as 0.3\nmodelGenImg = LeakyReLU(alpha=0.2)(modelGenImg)\n\nmodelGenImg = Reshape((7, 7, 128))(modelGenImg)","f6aed0d8":"# concatenating both the previous models, one for image and one for label to create final Generator\nmodelGen = Concatenate()([modelGenImg, modelGenLabel])\n\nmodelGen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(modelGen)\nmodelGen = LeakyReLU(alpha=0.2)(modelGen)\n\nmodelGen = Conv2DTranspose(128, (4,4), strides=(2,2), padding='same')(modelGen)\nmodelGen = LeakyReLU(alpha=0.2)(modelGen)\n\noutput_layer = Conv2D(1, (7,7), activation='sigmoid', padding='same')(modelGen)\n\nmodelGen = Model([image_input, input_label], output_layer)\n\nmodelGen.summary()","dfc4fa02":"# displaying the Generator model\nkeras.utils.plot_model(modelGen, \"modelGen.png\", show_shapes=True)","c896de67":"input_label = Input(shape=(1,))\n\n# number of categories = 10\nmodelDisLabel = Embedding(10, 50)(input_label)\n\nn_nodes = 28*28\n\nmodelDisLabel = Dense(n_nodes)(modelDisLabel)\n\nmodelDisLabel = Reshape((28, 28, 1))(modelDisLabel)","3083b4c8":"input_img = Input(shape=(28,28,1))\n\nmodelDis = Concatenate()([input_img,modelDisLabel])\n\nmodelDis = Conv2D(64, (3,3), strides=(2, 2), padding='same')(modelDis)\nmodelDis = LeakyReLU(alpha=0.2)(modelDis)\n\nmodelDis = Conv2D(64, (3,3), strides=(2, 2), padding='same')(modelDis)\nmodelDis = LeakyReLU(alpha=0.2)(modelDis)\n\nmodelDis = Flatten()(modelDis)\n\nmodelDis = Dropout(0.4)(modelDis)\n\noutput_dis = Dense(1, activation='sigmoid')(modelDis)\n\nmodelDis = Model([input_img, input_label], output_dis)\n\nmodelDis.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5) , metrics=['accuracy'])\n\nmodelDis.summary()","af595fc6":"# displaying the Discriminator model\nkeras.utils.plot_model(modelDis, \"modelDis.png\", show_shapes=True)","8b3adc3c":"#disabling training for discriminator\nmodelDis.trainable = False\n\nmodel = Sequential()\n\nnoiseGen, labelGen = modelGen.input\n\noutputGen = modelGen.output\n\noutputDis = modelDis([outputGen, labelGen])\n\nmodel = Model([noiseGen, labelGen], outputDis)\n\nmodel.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0002, beta_1=0.5))\n\nmodel.summary()","de66f9d9":"def generate_real_samples(dataset, n_samples):\n    \n    # copying all images and labels from the dataset\n    images, labels = dataset, labels_data\n\n    # selecting random n_sample instances\n    index = randint(0, images.shape[0], n_samples)\n    X, labels = images[index], labels[index]\n\n    # generate class labels, 1 for real dataset, 0 for fake    \n    y = ones((n_samples, 1))\n    \n    # returning [images, labels] and y=1 for real dataset\n    return [X, labels], y\n ","7ba27013":"fig, axs = plt.subplots(1,2, figsize=(15,5))\n\n[real_sample, real_label], y_label = generate_real_samples(train_data,2)\n\nprint(\"Sample len : \", len(real_sample))\nprint(\"Sample shape : \", real_sample[0].shape)\n\n# squeezing the extra dimensions\nreal_sample1 = np.squeeze(real_sample[0])\nreal_sample2 = np.squeeze(real_sample[1])\n\naxs[0].imshow(real_sample1)\naxs[1].imshow(real_sample2)\n\naxs[0].set_title(\"Actual label : \" + labels_word[list(real_label)[0]] + \" , Given label: \" + str(y_label[0]))\naxs[1].set_title(\"Actual label : \" + labels_word[list(real_label)[1]] + \" , Given label: \" + str(y_label[1]))\n\nplt.show()","03deaa7b":"def generate_latent_points(latent_dim, n_samples, n_classes=10):\n\n    # generaating latent_dim * n_samples random points\n    x_input = randn(latent_dim * n_samples)\n    \n    # reshape function to create\n    z_input = x_input.reshape(n_samples, latent_dim)\n    \n    # generate labels\n    labels = randint(0, n_classes, n_samples)\n    \n    return [z_input, labels]","95150754":"generate_latent_points(100,1)","777ab5af":"def generate_fake_samples(latent_dim, n_samples):\n    \n    # generate (latent_dim * n_samples) points latent space\n    z_input, labels_input = generate_latent_points(latent_dim, n_samples)\n    \n    # generate output with generator \n    images = modelGen.predict([z_input, labels_input])\n    \n    # create class labels\n    y = zeros((n_samples, 1))\n    \n    return [images, labels_input], y","49f8e98a":"fig, axs = plt.subplots(1,2, figsize=(15,5))\n\n[real_sample, real_label], y_label = generate_fake_samples(100,2)\n\nprint(\"Sample len : \", len(real_sample))\nprint(\"Sample shape : \", real_sample[0].shape)\n\n# squeezing the extra dimensions\nreal_sample1 = np.squeeze(real_sample[0])\n\naxs[0].imshow(real_sample1)\naxs[1].imshow(real_sample2)\n\naxs[0].set_title(\"Fake label : \" + labels_word[list(real_label)[0]] + \" , Given label: \" + str(y_label[0]))\naxs[1].set_title(\"Fake label : \" + labels_word[list(real_label)[1]] + \" , Given label: \" + str(y_label[1]))\n\nplt.show()\n","51122f05":"# displaying the output for predict function of Generator\nz_input, labels_input = generate_latent_points(100, 2)\n    \n# generate output with generator \nimages = modelGen.predict([z_input, labels_input])\n\nprint(\"Images shape : \" , images.shape)\n\nfig, axs = plt.subplots(1,2, figsize=(15,5))\n\nimage1 = np.squeeze(images[0])\nimage2 = np.squeeze(images[1])\n\naxs[0].imshow(image1)\naxs[1].imshow(image2)\n\nplt.show()","966eb391":"def generator_output():\n    \n    z_input, labels_input = generate_latent_points(100, 2)\n\n    # generate output with generator \n    images = modelGen.predict([z_input, labels_input])\n\n    print(\"Images shape : \" , images.shape)\n\n    fig, axs = plt.subplots(1,2, figsize=(15,5))\n\n    image1 = np.squeeze(images[0])\n    image2 = np.squeeze(images[1])\n\n    axs[0].imshow(image1)\n    axs[1].imshow(image2)\n\n    plt.show()","b91cf2cc":"def save_plot(examples, n=10):\n    \n    for i in range(n * n):\n        # define subplot\n        plt.subplot(n, n, 1 + i)\n        # turn off axis\n        plt.axis('off')\n        # plot raw pixel data\n        plt.imshow(examples[i, :, :, 0], cmap='gray_r')\n    plt.show()","0bb84a00":"def show_img_each_category(given_model):\n    # generate images\n    latent_points, labels = generate_latent_points(100, 10)\n\n    # specify labels\n    labels = np.asarray([x for _ in range(1) for x in range(10)])\n\n    # generate images\n    X  = given_model.predict([latent_points, labels])\n\n    # scale from [-1,1] to [0,1]\n    X = (X + 1) \/ 2.0\n    \n    return X","11627cbc":"dis_loss_1 = []\ndis_loss_2 = []\ngan_loss = []","5e75066a":"def train(latent_dim=100, n_epochs=10, n_batch=256):\n    \n    bat_per_epo = int(train_data.shape[0] \/ n_batch) # In our case : 60,000 \/ 256 = 234\n    half_batch = int(n_batch \/ 2) # 256\/2 = 128\n        \n    # defining the number of epochs\n    for i in range(n_epochs):\n        \n        # batches per epoch\n        for j in range(bat_per_epo):\n    \n            # get randomly selected 'real' samples\n            X_real, y_real = generate_real_samples(train_data, half_batch)\n            \n            d_loss1, _ = modelDis.train_on_batch(X_real, y_real)\n                    \n            # generate 'fake' examples\n            X_fake, y_fake = generate_fake_samples(latent_dim, half_batch)\n            \n            # update discriminator model weights\n            d_loss2, _ = modelDis.train_on_batch(X_fake, y_fake)\n            \n            # prepare points in latent space as input for the generator\n            X_gan = generate_latent_points(latent_dim, n_batch)\n            \n            # create inverted labels for the fake samples\n            y_gan = ones((n_batch, 1))\n            \n            # update the generator via the discriminator's error\n            g_loss = model.train_on_batch(X_gan, y_gan)\n            \n            print('>%d, %d\/%d, d1=%.3f, d2=%.3f g=%.3f' %\n                (i+1, j+1, bat_per_epo, d_loss1, d_loss2, g_loss))\n            \n            # adding losses to the list\n            dis_loss_1.append(d_loss1)\n            dis_loss_2.append(d_loss2)\n            gan_loss.append(g_loss)\n            \n        # printing generator's output after each epoch\n        generator_output()\n\n        print('> %d epoches done out of %d' % (i+1 , n_epochs))\n        \n    # save the generator model\n    modelGen.save('cgan_generator.h5')\n","95bc7cc5":"train(n_epochs = 100, n_batch=256)","be63eec9":"plt.figure(figsize=(15,5))\nplt.plot(gan_loss, label = \"Gan Loss\")\nplt.plot(dis_loss_1, label = \"Dis Loss 1\")\nplt.plot(dis_loss_2, label = \"Dis Loss 2\")\nplt.legend(loc=\"upper left\")\nplt.xlabel(\"Number of epoches\")\nplt.title(\"Losses for Generator and Discriminator\", fontsize = 12)\nplt.show()","7c640fb2":"# displaying the output for predict function of Generator\nz_input, labels_input = generate_latent_points(100, 10)\n    \n# generate output with generator \nimages = modelGen.predict([z_input, labels_input])\n\nprint(\"Images shape : \" , images.shape)\n\nfig, axs = plt.subplots(2, 5, figsize=(15,5))\n\ncount = 0\n\nfor i in range(2):\n    for j in range(5):        \n\n        image = np.squeeze(images[count])\n        axs[i][j].imshow(image)\n        count += 1\n\nplt.show()","182ded74":"model = load_model('cgan_generator.h5')\n# generate images\nlatent_points, labels = generate_latent_points(100, 100)\n# specify labels\nlabels = np.asarray([x for _ in range(10) for x in range(10)])\n# generate images\nX  = model.predict([latent_points, labels])\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n# plot the result\nsave_plot(X, 10)","30d2e7fe":"# printing all shirts\nlatent_points, labels = generate_latent_points(100, 100)\n\nlabels = np.asarray([0 for x in range(100)])\n\nprint(\"All : \" , labels_word[0])\n\n# generate images\nX  = model.predict([latent_points, labels])\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nsave_plot(X, 10)","a177d9df":"latent_points, labels = generate_latent_points(100, 100)\n\nlabels = np.asarray([9 for x in range(100)])\n\nprint(\"All : \" , labels_word[9])\n\n# generate images\nX  = model.predict([latent_points, labels])\n\n# scale from [-1,1] to [0,1]\nX = (X + 1) \/ 2.0\n\n# plot the result\nsave_plot(X, 10)","679d8e20":"modelEmbedding = Sequential()\n\n# embedding 10 classes , using 4 vectors for each class and 2 as sequence length\nembeddingLayer = Embedding(input_dim = 10, output_dim = 4, input_length = 2)\n\nmodelEmbedding.add(embeddingLayer)\n\nmodelEmbedding.compile('rmsprop', 'mse')\n\nmodelEmbedding.summary()","7b645385":"embeddingLayer.get_weights()","d00b437e":"input_array = np.array([1,2,5,9])\noutput_array = modelEmbedding.predict(input_array)\nprint(\"Input array : \", input_array)\nprint(\"\\nOutput array : \\n\\n\", output_array)\nprint(\"\\nOutput array shape : \", output_array.shape)","39f752c0":"try:\n    input_array = np.array([1,2,10])\n    output_array = modelEmbedding.predict(input_array)\n    print(input_array)\n    print(output_array)\n    print(output_array.shape)\nexcept Exception as e:\n    print(\"Error:\", e)","1ff49313":"try:\n    input_array = np.array([\n    [1,0,0],\n    [0,1,0],\n    [0,0,1]\n])\n    output_array = modelEmbedding.predict(input_array)\n    print(input_array)\n    print(output_array)\n    print(output_array.shape)\nexcept Exception as e:\n    print(\"Error:\", e)","b47d0cd7":"modelDense = Sequential()\n\nlayer_dense = Dense(2, input_shape = (2,)) \n\nmodelDense.add(layer_dense) \n\nmodelDense.summary()","90724914":"layer_dense.get_weights()","22b12628":"input_array = np.array([[1,2],[3,4]])\noutput_array = modelDense.predict(input_array)\nprint(\"Input array shape : \", input_array.shape)\nprint(\"Output array :\\n  \", output_array)\nprint(\"Output array shape : \", output_array.shape)\n","44c5b0ab":"modelRelu = Sequential()\n\nlayer_relu = LeakyReLU(alpha = 0.3, input_shape = (1,)) \n\nmodelRelu.add(layer_relu) \n\nmodelRelu.summary()","1ddb205b":"layer_relu.get_weights()","3839e3cf":"modelRelu.predict([-0.9, -0.3, 0.0, 2.0])","85696731":"\n# Example 1 :  Setting the rate to 0.3\nlayer_dropout = Dropout(rate = 0.3, input_shape=(2,)) \n\ndata = np.arange(10).reshape(5, 2).astype(np.float32)\n\nprint(\"\\n Setting the rate to 0.3, data : \\n\", data, \"\\n\\nSum of data : \",  sum(sum(data)))\n\noutput = layer_dropout(data, training=True)\n\nprint(\"\\nOutput 1 : \", output, \"\\n\\nSum of output 1 : \", sum(sum(data)))\n\n\n# Example 2 : Setting the rate to 0.5\nlayer_dropout = Dropout(rate = 0.5, input_shape=(2,)) \n\ndata = np.arange(10).reshape(5, 2).astype(np.float32)\n\nprint(\"\\nSetting the rate to 0.5, data : \\n\", data, \"\\n\\nSum of data : \", sum(sum(data)))\n\noutput = layer_dropout(data, training=True)\n\nprint(\"\\nOutput 2 : \", output, \"\\n\\nSum of output 2 : \", sum(sum(data)))","82d12b05":"### Generator Before: \n\nLet's see the images generated by the Generator before, in between and after and after the training","32a6c256":"# Conditional Generative Adverserial Network\n\n\nAccording to oxford Adverserial means: `involving or characterized by conflict or opposition`, and that is the basic approach of training the GANs, by having a game between Generator and Discriminator using a minmax approach where loss of one part is gain of other.\n\n**Table of content:**\n\n1. [Introduction](#Introduction)\n2. [Creating dataset](#Creating-dataset)\n3. [Creating models](#Creating-models)\n4. [Defining functions](#Defining-functions)\n5. [Training the model](#Training-the-model)\n6. [Testing the model](#Testing-the-model)\n7. [Background Knowledge](#Background-Knowledge)\n","de1363cb":"### Generator After:\n\nLet's see the output of the generator after all the tranining ","08bf9033":"# Creating models","fcad6054":"This section is created to provide insights about some of the important parts of this project.\n\n## Embedding layer\n\nWhen dealing with textual data, its important to tokenize or transform it to numerical data. Most of the times we use one hot encoder for this purpose, which assigns a variable for each word. For large data it could be a problem to have these many variables.\n\nWe can use embedding layer instead to create vectors of fixed length and express every input in terms of vectors by using neural net and obivously weights. The main parameters are:\n\n1. input_dim (integer) = the number of classes or words which we want to be convert into vector.\n2. output_dim (integer) = the length of vector used for representing each label or class\n3. input_length (integer) = \"*Length of input sequences, when it is constant. This argument is required if you are going to connect Flatten then Dense layers upstream (without it, the shape of the dense outputs cannot be computed).*\" (From documentation)\n\n\n**Note** : `This layer can only be used as the first layer in a model.`(From documentation)\n\nMore info:\n[Amazing explanation by Jeff Heaton](https:\/\/youtu.be\/OuNH5kT-aD0) | \n[Documentation](https:\/\/keras.io\/api\/layers\/core_layers\/embedding\/#embedding) | \n[Tensorflow Github code for Embedding layer](https:\/\/github.com\/tensorflow\/tensorflow\/blob\/v2.4.0\/tensorflow\/python\/keras\/layers\/embeddings.py)\n\n\n\nLet's create a simple model with only one layer of Embedding","4f205072":"Let's start by creating the Generator and Discriminator\n\n![](http:\/\/)\n\n## Generator\n\n","1f9f0d12":"So, the vectors or wieghts stored at indices 1,2,5 and 9 are returned as the output array. Let's try to get output for input 1,2 and 10. It should create error.","bbd9057e":"## LeakyReLU\n\nLeakyRelU is an activation function. It uses a simple function:\n\n**f(x) = alpha * x if x < 0 <br>\n  f(x) = x if x >= 0**\n\nalpha is by default set to 0.3.\n\n**Note : Input shape is not required here, I have added to only print the summary**  \n\nRead more: [Documentation](https:\/\/keras.io\/api\/layers\/activation_layers\/leaky_relu\/)","fe2570bb":"### show_img_each_class() : \n\nTo generate 1 image from each category","d05aeaf0":"We require only the training data beacuse it has labels","99976432":"As you can see, we mentioned the output_dim = 4, the size of each vector is 4. And also, 10 such unique vectors are created as we have passed input_dim to be 10. Let's see what values can we get for the input 1, 2, 5 and 9","2498a414":"## Combining Discriminator and Generator","1eada843":"As it is an activation function, it doesnot have any weights","54e5d9e4":"# Creating dataset","b6dd44fb":"### generator_output():\n\nLet's create a function to show the output of Generator\n","ba257d7a":"Evaluating the loss over the 100 epoches * batches per epoches(234) = 23400 points","cbb66e39":"The first array shows the weights and the second shows the bias. First array contains 2 vectors in each element and has 2 such elements because of the input shape.","18178d41":"Apart from the first column label. we have 28\\*28 = 784 pixels values, stored in next 784 columns. Let's create an image out of these pixel values ","36468a6a":"<h1 style=\"color:red;\"> Thank You <\/h1>\n\n","0f83d400":"### generate_latent_points() : \n\nfunction to generate random points for the generator to evaluate. The function generates ( latent_dim * n_samples ) points.\n\n\nRead more [numpy.random.randn()](https:\/\/www.geeksforgeeks.org\/numpy-random-randn-python\/)","f5d28205":"## Discriminator","be14f86a":"# References\n\n1. [The original paper on Conditional GANs](https:\/\/arxiv.org\/pdf\/1411.1784.pdf)\n2. [Machine Learning Mastery: How to Develop a Conditional GAN (cGAN) From Scratch, many parts of the code is taken from here](https:\/\/machinelearningmastery.com\/how-to-develop-a-conditional-generative-adversarial-network-from-scratch\/)\n","66124727":"Discriminator is trained on real image (x) and label (y), our model is slmost same as the image from the cGAN","f08a955e":"Let's create list for storing losses","7d025a8a":"# Training the model","f04ccda7":"So there are 60000 Fashion MNIST training instance, plotting first 5 among them","bd079ef0":"If you look closely, the Generator model which we created is same as cGAN image shown. Generator gets two input z (fake image) and y(labels)","8a42a6e0":"Seems like everythong is loaded perfectly. Now let's start creating the dataset","7d8c168d":"## Dense Layer\n\nIt is one of the most commonly used layer. All neurons from previous layer provides input to each neuron in dense layer. It dot products weights with input, add bias and feed it into the specified activation function. Important parameters are:\n\n1. units (Integer): Dimension of the output.\n\n2. activation: Activation function to use. If no activation function is mentioned, then \"linear\" activation is used ie a(x) = x.\n\n \n**output = activation(dot(input, kernel) + bias)**\n\nKernal is weight.\n\nRead more: [Tutorialspoint](#https:\/\/www.tutorialspoint.com\/keras\/keras_dense_layer.htm) | \n[Documentation](#https:\/\/keras.io\/api\/layers\/core_layers\/dense\/)\n","0ad2c31b":"# Testing the model","29d6b525":"### generate_fake_samples() : \n\ngenerating fake samples based on the output of latent points","ce1ddf2c":"The maths behind it pretty simply.Let's look at the first element in the output.\n\nRemember: output = activation(dot(input,kernal) + bias)\n\n1.5043085 =  1 * (- 0.5328983 )  +  2 * 1.0186034  + 0 (for bias),\n\na simple matrix product. Also activation(x) = x , as we have not defined any activation function.","65a12fde":"# Defining functions\n\nDefining functions which will be repetitively used for training the final model","0490c904":"<hr><hr><br><br>\n\n# Background Knowledge","cff33f41":"# Introduction\n\n1. Preivosuly the GANs where producing the combined results for all categories, conditional GANs made it possible to generate results for a specific category.\n\n2. We have to pass Y to both the generator and discriminator. According to the paper, \"y could be any kind of auxiliary information, such as class labels or data from other modalities\".\n\n3. The loss function is also changed,\n    \n    **Normal GANs:** min(G)max(D) V(D, G) = Ex\u223cpdata(x)[log D(x)] + Ez\u223cpz(z)[log(1 \u2212 D(G(z)))]\n\n    **Conditional GANs:** min(G)max(D) V(D, G) = Ex\u223cpdata(x)[log D(x|y)] + Ez\u223cpz(z)[log(1 \u2212 D(G(z|y)))]\n \n\nRead more : [Base Paper](https:\/\/arxiv.org\/pdf\/1411.1784.pdf) | [How to Develop a Conditional GAN (cGAN) From Scratch](https:\/\/machinelearningmastery.com\/how-to-develop-a-conditional-generative-adversarial-network-from-scratch\/)\n","fa6ed70f":"Without even training, we can see the weights and values of the vectors assigned for each classes. We can also train the model to update the weights.\n\n**Note** : Weights which are initalized seems to be random and between -1 to +1 ","3c3be525":"### generate_real_samples() : \n\nfunction to get real samples from the datasets for the discriminator to train on","126bf932":"## Dropout Layer\n\nDropout layer is used to minimize overfitting. Basically, it decreases randomly one of the input values to 0 and increases rest of the values by a  1\/(1 - rate) , where rate is the frequency of decreasing the values. Also, trainable should be set to True for droupout to work.\n\nRead more: [How to Reduce Overfitting With Dropout Regularization in Keras](https:\/\/machinelearningmastery.com\/dropout-regularization-deep-learning-models-keras\/) | [Documentation](https:\/\/keras.io\/api\/layers\/regularization_layers\/dropout\/)","ab3f02e0":"Here's an image from the paper descibing both Discriminator and Generator. \n\n1. x : images from actual dataset\n2. z : fake images created by Generator\n3. y : labels ","6a6454d7":"![Both Generator and Discriminator models](https:\/\/3qeqpr26caki16dnhd19sv6by6v-wpengine.netdna-ssl.com\/wp-content\/uploads\/2019\/05\/Example-of-a-Conditional-Generator-and-a-Conditional-Discriminator-in-a-Conditional-Generative-Adversarial-Network-1024x887.png)"}}