{"cell_type":{"cb71c9b8":"code","e7bf5733":"code","efabbc1f":"code","118eb4ce":"code","0a4fed03":"code","31a552b3":"code","6d4aabe8":"code","b66e4b74":"code","502e221d":"code","ec323c96":"code","6474ebef":"code","d9bfcbc8":"code","b7cdb9f7":"code","1885b0d1":"code","315525eb":"code","f33ac179":"code","9d7de5b0":"code","08a24c1b":"code","3352ce28":"code","23b1f7cc":"code","25cb0a53":"code","432fe7ac":"code","9dc5982f":"code","64a48b93":"code","fbe36f56":"code","900de840":"code","dbc9223e":"code","00700b0c":"code","0b8eb7c0":"code","e8dd08dc":"code","db3c50aa":"code","60d64f89":"code","0ab4ddab":"code","43a7d233":"code","8fa0015d":"code","4992b86a":"code","35344c5e":"code","551498fa":"markdown","a3c6a294":"markdown","6dfe3e73":"markdown","f5011e6b":"markdown","0213bad9":"markdown","7fdb3b7b":"markdown","5f695bf9":"markdown"},"source":{"cb71c9b8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e7bf5733":"df = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")\ndf.head()","efabbc1f":"df.shape","118eb4ce":"df.describe()","0a4fed03":"df.info","31a552b3":"df.isnull().any()","6d4aabe8":"import matplotlib.pyplot as plt \nimport seaborn as sns","b66e4b74":"sns.histplot(df['Amount'],bins =40,color=\"green\")\nsns.set_style(\"darkgrid\")","502e221d":"sns.set_style(\"whitegrid\")\ndf[\"log_amount\"] = np.log2(df[\"Amount\"]+0.01)\nsns.displot(x = \"log_amount\",bins = 25, kde = True, hue = \"Class\", data=df)","ec323c96":"sns.set_style(\"ticks\")\nfig,ax  = plt.subplots(ncols = 2,nrows =1,figsize = (10,10))\nax.flatten()\nsns.boxplot(x = \"Class\", y = \"Amount\", data=df, ax = ax[0])\nsns.boxplot(x = \"Class\",y = \"log_amount\", data =df, ax = ax[1])","6474ebef":"sns.set_style(\"darkgrid\")\nplt.figure(figsize = (10,6))\nsns.countplot(x = \"Class\", data=df)","d9bfcbc8":"fraud = df[df[\"Class\"]==1]\nnot_fraud = df[df[\"Class\"]==0]","b7cdb9f7":"print(fraud.shape,not_fraud.shape)","1885b0d1":"x = df.drop([\"Class\"], axis = 1)\ny = df[\"Class\"]","315525eb":"x.head()","f33ac179":"from imblearn.under_sampling import NearMiss\nnm = NearMiss()\nx_nm, y_nm = nm.fit_resample(x, y)","9d7de5b0":"print(x_nm.shape,y_nm.shape)","08a24c1b":"from sklearn.preprocessing import StandardScaler\nscalar = StandardScaler()","3352ce28":"x_scaled = scalar.fit_transform(x_nm)","23b1f7cc":"from sklearn.model_selection import train_test_split, cross_val_score\nx_train,x_test,y_train,y_test = train_test_split(x_scaled,y_nm, test_size = 0.25)","25cb0a53":"scores = {}\nacc = []\ncv_scores = []\ndef model(model):\n    model.fit(x_train,y_train)\n    score = model.score(x_test,y_test)\n    print(\"Accuracy: {}\".format(score))\n    cv_score = cross_val_score(model,x_train,y_train,cv=5)\n    print(\"Cross Val Score: {}\".format(np.mean(cv_score)))\n    acc.append(score)\n    cv_scores.append(np.mean(cv_score))","432fe7ac":"from xgboost import XGBClassifier\nclf = XGBClassifier()\nmodel(clf)","9dc5982f":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression()\nmodel(clf)","64a48b93":"from sklearn.ensemble import RandomForestClassifier\nclf = RandomForestClassifier()\nmodel(clf)","fbe36f56":"from sklearn.tree import DecisionTreeClassifier\nclf = DecisionTreeClassifier()\nmodel(clf)","900de840":"from sklearn.neighbors import KNeighborsClassifier\nclf = KNeighborsClassifier()\nmodel(clf)","dbc9223e":"from sklearn.svm import SVC\nclf = SVC()\nmodel(clf)","00700b0c":"from sklearn.naive_bayes import GaussianNB\nclf = GaussianNB()\nmodel(clf)","0b8eb7c0":"from sklearn.ensemble import AdaBoostClassifier\nclf = AdaBoostClassifier()\nmodel(clf)","e8dd08dc":"from sklearn.ensemble import GradientBoostingClassifier\nclf = GradientBoostingClassifier()\nmodel(clf)","db3c50aa":"models = [\"XGBClassifier\",\"LogisticRegression\",\"RandomForestClassifier\",\"DecisionTreeClassifier\",\"KNeighborsClassifier\",\"SVC\",\"GaussianNB\",\"AdaBoostClassifier\",\"GradientBoostingClassifier\"]\nacc","60d64f89":"cv_scores","0ab4ddab":"scores = { \"Model Name\" : models , \"Accuracy Score\" : acc, \"Cross val Score\": cv_scores}","43a7d233":"df1 = pd.DataFrame(scores)","8fa0015d":"df1","4992b86a":"plt.figure(figsize = (20,10))\nsns.barplot(x = \"Model Name\", y = \"Accuracy Score\", data=df1)\nplt.title(\"Model Comparision wrt Score\")","35344c5e":"plt.figure(figsize = (20,10))\nsns.barplot(x = \"Model Name\", y = \"Cross val Score\", data=df1)\nplt.title(\"Model Comparision wrt Cross validation\")","551498fa":"# Reading Data","a3c6a294":"# Model Creation and Comparison","6dfe3e73":"# Data Analysis","f5011e6b":"Standardization","0213bad9":"# Handling Imbalanced Data","7fdb3b7b":"#  AdaBoost Classifier has the highest accuracy of 97.5%","5f695bf9":"## Imbalanced Dataset Credit Card Fraud\n### Group 9\n### Arjun Gopikrishnan RA1911003010284\n### Dhruv Upadhyay RA1911003010303\n### P Kumar RA1911003010304\n### Pilli Venkata Sai RA1911003010328\n### Kodumuru Adarsh RA1911003010329\n### Kommineni Rakesh RA1911003010336"}}