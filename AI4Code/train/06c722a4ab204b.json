{"cell_type":{"156d596c":"code","c78c9244":"code","cfa53831":"code","4785b871":"code","8a2c0727":"code","715a26ef":"code","8a2027bc":"code","d87bafd6":"code","6e718e7e":"code","ee823810":"code","63ea3b34":"code","44c950ef":"code","c93eda2d":"markdown","55850b9e":"markdown","37cf05fe":"markdown","46f44652":"markdown","a45bae63":"markdown"},"source":{"156d596c":"import numpy as np\nimport pandas as pd \nimport json\nfrom collections import deque","c78c9244":"data = pd.read_json('\/kaggle\/input\/scl-2021-da\/contacts.json')\n\n# see what's the original data is like\ndata.head(5)","cfa53831":"# step 1\n\ndef find_direct_relationship(columns):\n    global data\n    # find all direct relationships and store in new columns\n    for col in columns:\n        temp_data = data.loc[data[col] != '', :].groupby([col])['Id'].apply(list).reset_index()\n        temp_data.columns = [col, col + '_list']\n        data = data.merge(temp_data, on=col, how='left')\n    # fill NaNs occur with merging with empty lists\n    colnames = [col + '_list' for col in columns]\n    data[colnames] = data[colnames].apply(lambda x: x.fillna({i: [] for i in data.index}))\n        \nfind_direct_relationship(['Email', 'Phone', 'OrderId'])","4785b871":"# step 2\n\n# append three columns\ndata['Id_list'] = data['Email_list'] + data['Phone_list'] + data['OrderId_list']\n\n# eliminate dulicates\ndata['Id_list'] = data['Id_list'].apply(lambda x: list(set(x)))","8a2c0727":"data.head(5)","715a26ef":"# step 3\n\n# DFS without Memoization\ndef dfs(id_list):\n    global data\n    seen = set(id_list)\n    stack = id_list[:] # deep copy here to leave the column Id_list untouched\n    while stack:\n        Id = stack.pop()\n        for new_id in data.loc[Id]['Id_list']:\n            if new_id not in seen:\n                seen.add(new_id)\n                stack.append(new_id)\n    return '-'.join([str(Id) for Id in sorted(list(seen))])\n\n\n# BFS without Memoization\ndef bfs(id_list):\n    global data\n    seen = set(id_list)\n    queue = deque(id_list)\n    while queue:\n        Id = queue.popleft()\n        for new_id in data.loc[Id]['Id_list']:\n            if new_id not in seen:\n                seen.add(new_id)\n                queue.append(new_id)\n    return '-'.join([str(Id) for Id in sorted(list(seen))])","8a2027bc":"bfs([1])","d87bafd6":"# step 3\nmemo = {}\n\n# DFS with Memoization\ndef dfs_memo(id_list):\n    # early stopping\n    if len(id_list) == 1:\n        return str(id_list[0])\n    \n    # check if we have visited this id before\n    for Id in id_list:\n        if Id in memo:\n            return memo[Id]\n    global data\n    seen = set(id_list)\n    stack = id_list[:] # deep copy here to leave the column Id_list untouched\n    while stack:\n        Id = stack.pop()\n        for new_id in data.loc[Id]['Id_list']:\n            if new_id not in seen:\n                seen.add(new_id)\n                stack.append(new_id)\n    ticket_trace = '-'.join([str(Id) for Id in sorted(list(seen))])\n    \n    # add result to our memoization table\n    for Id in seen:\n        memo[Id] = ticket_trace\n    return ticket_trace\n\n\n# BFS without Memoization\ndef bfs_memo(id_list):\n    # early stopping\n    if len(id_list) == 1:\n        return str(id_list[0])\n    \n    # check if we have visited this id before\n    for Id in id_list:\n        if Id in memo:\n            return memo[Id]\n        \n    global data\n    seen = set(id_list)\n    queue = deque(id_list)\n    while queue:\n        Id = queue.popleft()\n        for new_id in data.loc[Id]['Id_list']:\n            if new_id not in seen:\n                seen.add(new_id)\n                queue.append(new_id)\n                \n    ticket_trace = '-'.join([str(Id) for Id in sorted(list(seen))])\n    \n    # add result to our memoization table\n    for Id in seen:\n        memo[Id] = ticket_trace\n        \n    return ticket_trace","6e718e7e":"data['ticket_trace'] = data['Id_list'].apply(lambda x: bfs_memo(x))","ee823810":"# our data now looks like this\ndata.head()","63ea3b34":"# step 4\n\ncontact_sum = data.groupby('ticket_trace')['Contacts'].sum().reset_index()\ncontact_sum.columns = ['ticket_trace', 'contact_sum']\ndata = pd.merge(data, contact_sum, on=\"ticket_trace\", how='left')","44c950ef":"# format for submission\n\ndata['ticket_trace\/contact'] = data['ticket_trace'] + ', ' + data['contact_sum'].apply(str)\nans = data[['Id', 'ticket_trace\/contact']]\nans.columns = ['ticket_id', 'ticket_trace\/contact']\nans = ans.sort_values('ticket_id').reset_index(drop=True)\nans.to_csv('\/kaggle\/working\/output.csv', index=False)  ","c93eda2d":"This notebook is aimed to help people struggling to solve this problem with pandas. If you are familar with pandas but have less experience with Python's built-in data structures, this might be a good starting point for you.\n\nPlease note that for this problem, using Python's built-in data stuctures is sufficient and gives better runtime. There are other notebooks that uses the same BFS\/DFS\/graph theory concept without pandas so I'm not going into details of that. Check out [this brilliant notebook](https:\/\/www.kaggle.com\/santisantichaivekin\/multi-channel-contacts-graph-theory-solution) written by Santi Santichaivekin for a similar BFS solution, feel free to adapt the memoization technique to his solution if you like.","55850b9e":"Our data now looks like this:","37cf05fe":"Now we're good to group the data by *ticket_trace* and sum up the contacts.","46f44652":"### Improving BFS\/DFS with Memoization and Early Stopping\n\n**Memoization**\n\nYou probably wouldn't want to try the above functions out, they take years to complete. To improve the runtime of these functions, we can use a dictionary to hold ticket_trace for every Id we've visited. \n\nFor example, when we see Id 1, our BFS\/DFS function goes out and search for every indirect relationship and returns 1-2458-98519-115061-140081-165605-476346, without memoization, when we encounter, say 2458, our function triggers again and return 1-2458-98519-115061-140081-165605-476346, the same result as Id 1. This is a waste of computational power. \n\nNow, with memoization, we store the result 1-2458-98519-115061-140081-165605-476346 for every Id in it, so we don't have to call our function again and again for the same result, this technique is called memoization, trading extra space for less computational power needed.\n\n**Early Stopping**\n\nWhen there's only one element in a Id_list, we know there's no other Id in its relationship, so we can stop early without DFS\/BFS, this will slightly boost the runtime.","a45bae63":"### Solutions by steps\n\n\n1. For each Id, search for other Ids that share the same OrderId, Email and Phone with it and create three extra columns holding the values\n2. Merge three columns created in step 1, here for each Id, we've got all Ids in its **direct relationship**\n3. Loop through each Id, find all Ids in its **indirect relationship** using DFS\/BFS and store it in a new column\n4. Group the data by new column created in step 3, sum the contacts\n\nYes, some steps taken and extra columns added are not necessary, here I am trying to be clear with every step I took to make the solution more comprehensible."}}