{"cell_type":{"d34cd55f":"code","def6ee13":"code","d2b465df":"code","a177b736":"code","ba304f6d":"code","ec886810":"code","c44dc0b8":"code","218ea8d0":"code","36d1ef61":"code","605beec1":"code","b1392de8":"code","528a9de3":"code","1c8d5235":"code","184a7f36":"code","7b60c1ca":"code","600f837a":"code","d53ea420":"code","9ee4e727":"code","7baf1990":"code","70208575":"code","3fa6cd89":"code","76b5480e":"code","c2b26e29":"code","9b1f2285":"markdown","a19b0659":"markdown","7d589607":"markdown","9f069638":"markdown","e42da2a2":"markdown","6d50a2ec":"markdown","12b8f889":"markdown","5da2a4fd":"markdown","25b0e9b3":"markdown","add85d47":"markdown","6fe9ea9a":"markdown","25eb37d6":"markdown","894fb510":"markdown","4f52e18b":"markdown","87990ca4":"markdown","c1850f8b":"markdown"},"source":{"d34cd55f":"import numpy as np \nimport sklearn\nfrom sklearn.datasets import load_iris # traer el dataset de las flores de iris\nfrom sklearn.model_selection import train_test_split \nimport matplotlib.pyplot as plt\n%matplotlib inline","def6ee13":"iris = load_iris() # Creamos la variable para traer nuestro dataset","d2b465df":"type(iris) # Tipo de dato Bunch es una especie de diccionario ","a177b736":"iris.keys() # Revisamos las llaves de nuestro diccionario","ba304f6d":"iris['data'] ","ec886810":"iris['target_names']","c44dc0b8":"iris['target']","218ea8d0":"iris['feature_names'] # Nombre de las mediciones que se le hacen a las flores","36d1ef61":"X=iris['data'] # Mediciones de las flores\ny=iris['target'] # Etiquetas de las flores\n# Dividimos nuestros datos en set de entrenamiento y de pruebas \nX_train, X_test, y_train, y_test = train_test_split(X, y,)","605beec1":"X_train.shape # Matriz de 112 flores con 4 mediciones","b1392de8":"y_train.shape # Cada una de las etiquetas de las  flores","528a9de3":"from sklearn.neighbors import KNeighborsClassifier","1c8d5235":"KNN_iris=KNeighborsClassifier(n_neighbors=9) # para este caso elegimos k=7","184a7f36":"KNN_iris.fit(X_train,y_train) # Recibe como parametros nuestros datos de prueba ","7b60c1ca":"KNN_iris.score(X_test,y_test) # los parametros que recibe son los X and y de testing","600f837a":"KNN_iris.predict([[1.1,1.5,2.5,3.5]]) # Le ingresamos las 4 medidas para que nos diga el tipo","d53ea420":"iris.target_names # Lo que quiere decir que pertenece a una versicolor ","9ee4e727":"pred_iris = KNN_iris.predict(X_test) # Creamos la variable de prediccion","7baf1990":"from sklearn.metrics import confusion_matrix,classification_report","70208575":"# Los parametros que recibe son los y de pruebas y los de prediccion\nprint(confusion_matrix(y_test,pred_iris)) \nprint('\\n')\nprint(classification_report(y_test,pred_iris))\n","3fa6cd89":"# Creamos un arreglo vacio para llenarlo con los valores a medida que cambie los puntos vecinos\n\nerror_rate = [] \n# Will take some time\nfor i in range(1,60):\n    \n    KNN_iris = KNeighborsClassifier(n_neighbors=i) # Instancia con numeros vecinos \n    KNN_iris.fit(X_train,y_train)\n    pred_i = KNN_iris.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test)) # Zona de carga del vector de error donde calcula el promedio\n                                                 # de los valores que son diferentes a los valores reales","76b5480e":"# Creamos nuestro grafico y lo personalizamos","c2b26e29":"plt.figure(figsize=(10,6))\nplt.plot(range(1,60),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate')","9b1f2285":"# Zona de evaluacion y reportes ","a19b0659":"# Uso de la funcion del codo para identificar  el valor adecuado de K","7d589607":"NOTA : Tener muy en cuenta que la funcion \"score\" nos da una idea de que tambien aprendio nuestro algoritmo con nuestro set de prueba , es decir que porcentaje de los datos de prueba  logro predecir correctamente","9f069638":"# NOTA :\n\nPodemos observar que los valores con los errores mas bajos respecto a los vecinos cercanos pueden ser usados  desde un valor de k=7 hasta k= 25","e42da2a2":"NOTA : Si queremos revisar el tama\u00f1o de nuestros datos de entrenamiento simplemente usamos la funcion shape para ver las dimensiones de nuestros arreglos ","6d50a2ec":"2) Ahora vamos a explorar que hay en nuestra llave de 'target_names'","12b8f889":"# Algoritmo vecinos mas cercanos (KNN)\n\nEl siguiente ejercicio busca explicar de una manera muy basica el funcionamiento del metodo de machine leranig vecinos mas cercanos , haciendo uso del dataset iris para predecir el tipo de flor apartir de las mediciones ingresadas al modelo","5da2a4fd":"Hacemos uso de nuestra funcion \"fit\" que sirve para entrenar nuestro modelo","25b0e9b3":"3) En target encontramos las etiquetas de cada una de las flores :\n    * 0= setosa\n    * 1= versicolor\n    * 2= virginica","add85d47":"1) Si revisamos nuestra llave de dato encontraremos un arreglo de 4 dimensiones con cada una de las mediciones que se le hacen a las flores :\n \n * Cada fila es una flor\n * Cada columna es una medicion ","6fe9ea9a":"# De nuestras libreria sklearn importamos las metricas ","25eb37d6":"Ahora vamos a crear nuestra instancia y le vamos a dar los parametros que nosotros \nelijamos ","894fb510":"# Zona de importacion de librerias ","4f52e18b":"# Ahora vamos a importar desde sklearn nuestro clasificador de KNN ","87990ca4":"Zona de pruebas ","c1850f8b":"# Vamos a revisar que datos encontramos en cada una de las llaves de nuestro dataset iris"}}