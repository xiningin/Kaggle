{"cell_type":{"364f6eef":"code","f6835601":"code","eae3ffad":"code","e0bc2c8c":"code","e334b2f0":"code","faca6081":"code","26746139":"code","a913a3ef":"code","257e104b":"code","3f9e7711":"code","487f7138":"code","04637c7a":"code","327d73b0":"code","bc9da1bf":"code","6879d2ea":"code","e3543f18":"code","db8ff18f":"code","a90ac937":"code","62794ee1":"code","17b41d8a":"code","ea1385ec":"code","14aa1c3a":"code","339be06e":"code","802e131d":"code","218b8470":"code","6229f97d":"code","e2747565":"code","d2bc340e":"code","1cda4ee7":"code","8b3df277":"code","c48c89a6":"code","2cf8365e":"code","63e392d1":"code","b18ea1a5":"code","4f1b1fa7":"code","f7ed950c":"code","06653267":"code","abf38660":"code","cf2708ac":"code","02cc2080":"code","80bd01bb":"code","76da72f0":"code","8d28e390":"code","57f66da6":"code","edd297e3":"code","e81a95ce":"code","0400c9e0":"code","a6d86ddc":"code","49ac471e":"code","ee43c82f":"code","6a32f2ab":"code","2101ca9f":"code","1f5a2377":"code","6d91a4b2":"code","4e2386d7":"code","b30bb567":"code","facd0a61":"code","893c052a":"code","0e00d610":"code","5c54248b":"code","320d2dfe":"code","800b12b2":"code","4a4e1333":"code","fe453260":"code","a819c547":"code","b5e73d17":"code","bc822895":"code","c52a2c80":"code","4128e96b":"code","891338b9":"code","1b09c556":"code","423b8d80":"code","7274bd0f":"markdown","416e46f9":"markdown","1a92f228":"markdown","7058550d":"markdown","0a9a6d74":"markdown","ff4741b0":"markdown","9f172926":"markdown","5c90d74b":"markdown","4c15aab8":"markdown","364d82f5":"markdown","0ce8a319":"markdown","21065f9d":"markdown","d456a8c7":"markdown","892b10d3":"markdown","b8309eb1":"markdown","e806bef0":"markdown"},"source":{"364f6eef":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f6835601":"import matplotlib.pyplot as plt","eae3ffad":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent1\/Capture.PNG\"))","e0bc2c8c":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent2\/Capture1.PNG\"))","e334b2f0":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent3\/Capture2.PNG\"))","faca6081":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent4\/Capture4.PNG\"))","26746139":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent5\/Capture5.PNG\"))","a913a3ef":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent6\/Capture6.PNG\"))","257e104b":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent7\/Capture7.PNG\"))","3f9e7711":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent8\/Capture8.PNG\"))","487f7138":"plt.figure(figsize=(15,10))\nplt.imshow(plt.imread(\"..\/input\/recurrent9\/Capture9.PNG\"))","04637c7a":"pip install nlp","327d73b0":"import nlp","bc9da1bf":"data=nlp.load_dataset(\"emotion\")\ndata","6879d2ea":"train=data[\"train\"]\ntrain[\"text\"][0]","e3543f18":"train[\"label\"][0]","db8ff18f":"test=data[\"test\"]","a90ac937":"validation=data[\"validation\"]","62794ee1":"def get_tweet(tweets):\n    tweet=[x[\"text\"] for x in tweets]\n    label=[x[\"label\"] for x in tweets]\n    return tweet, label","17b41d8a":"tweets, labels=get_tweet(train)\nprint(tweets[0],labels[0])","ea1385ec":"val_tweets,val_labels=get_tweet(validation)\nprint(val_tweets[0],val_labels[0])","14aa1c3a":"from tensorflow.keras.preprocessing.text import Tokenizer","339be06e":"tokenizer=Tokenizer(num_words=10000,oov_token=\"<UNK>\")","802e131d":"tokenizer.fit_on_texts(tweets)","218b8470":"tokenizer.texts_to_sequences([tweets[0]])","6229f97d":"tweets[0]","e2747565":"tokenizer.texts_to_sequences([tweets[1]])","d2bc340e":"tweets[1]","1cda4ee7":"new_tweets=tokenizer.texts_to_sequences(tweets)\nnew_tweets[0]","8b3df277":"new_val_tweets=tokenizer.texts_to_sequences(val_tweets)\nnew_val_tweets[0]","c48c89a6":"import matplotlib.pyplot as plt\nimport seaborn as sns","2cf8365e":"sns.set_style(\"darkgrid\")","63e392d1":"plt.figure(figsize=(15,10))\nplt.hist(labels)","b18ea1a5":"labels[0]","4f1b1fa7":"from sklearn.preprocessing import LabelEncoder","f7ed950c":"le= LabelEncoder()","06653267":"labels=le.fit_transform(labels)\nlabels[0]","abf38660":"val_labels=le.transform(val_labels)\nval_labels[0]","cf2708ac":"new_tweets[0]","02cc2080":"new_val_tweets[0]","80bd01bb":"from tensorflow.keras.preprocessing.sequence import pad_sequences","76da72f0":"pad_sequences(new_tweets).shape","8d28e390":"new_tweets2=pad_sequences(new_tweets,truncating=\"post\",padding=\"post\",maxlen=60)\nnew_tweets2[0]","57f66da6":"new_tweets2.shape","edd297e3":"pad_sequences(new_val_tweets).shape","e81a95ce":"val_tweets2=pad_sequences(new_val_tweets,truncating=\"post\",padding=\"post\",maxlen=60)\nval_tweets2[0]","0400c9e0":"val_tweets2.shape","a6d86ddc":"\nlabels2=np.array(labels)\n\nval_labels2=np.array(val_labels)\nval_labels2.shape","49ac471e":"labels2.shape","ee43c82f":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.keras.layers import LSTM\nfrom tensorflow.keras.layers import Bidirectional","6a32f2ab":"rnn=Sequential()","2101ca9f":"rnn.add(Embedding(10000,16))","1f5a2377":"rnn.add(Bidirectional(LSTM(20,return_sequences=True)))","6d91a4b2":"rnn.add(Bidirectional(LSTM(20)))","4e2386d7":"rnn.add(Dense(6,activation=\"softmax\"))","b30bb567":"rnn.compile(optimizer=\"adam\",loss=\"sparse_categorical_crossentropy\",metrics=[\"accuracy\"])","facd0a61":"rnn.summary()","893c052a":"import tensorflow","0e00d610":"rnn.fit(new_tweets2,labels2,validation_data=(val_tweets2,val_labels2),epochs=20,callbacks=[tensorflow.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\",patience=2)])","5c54248b":"rnn.history.history","320d2dfe":"pd.DataFrame(rnn.history.history)","800b12b2":"pd.DataFrame(rnn.history.history).plot(figsize=(15,10))","4a4e1333":"test_tweets,test_labels=test[\"text\"],test[\"label\"]\ntest_tweets[0]","fe453260":"print(test_tweets[0],test_labels[0])","a819c547":"test_tweets_latest=tokenizer.texts_to_sequences(test_tweets)\ntest_tweets_latest[0]","b5e73d17":"test_labels2=le.transform(test_labels)\ntest_labels2[0]","bc822895":"test_tweets_latest2=pad_sequences(test_tweets_latest,truncating=\"post\",padding=\"post\",maxlen=60)\ntest_tweets_latest2.shape","c52a2c80":"test_labels2.shape","4128e96b":"np.argmax(rnn.predict(np.expand_dims(test_tweets_latest2[0],axis=0)))","891338b9":"print(test_tweets[0],test_labels[0])","1b09c556":"test_labels2[0]","423b8d80":"len(test_tweets_latest2)","7274bd0f":"Finally, we need to decide what we\u2019re going to output. This output will be based on our cell state, but will be a filtered version. First, we run a sigmoid layer which decides what parts of the cell state we\u2019re going to output. Then, we put the cell state through tanh (to push the values to be between \u22121 and 1) and multiply it by the output of the sigmoid gate, so that we only output the parts we decided to.\n\nFor the language model example, since it just saw a subject, it might want to output information relevant to a verb, in case that\u2019s what is coming next. For example, it might output whether the subject is singular or plural, so that we know what form a verb should be conjugated into if that\u2019s what follows next.","416e46f9":"All recurrent neural networks have the form of a chain of repeating modules of neural network. In standard RNNs, this repeating module will have a very simple structure, such as a single tanh layer","1a92f228":"The Problem of Long-Term Dependencies:\n\nSometimes, we only need to look at recent information to perform the present task. For example, consider a language model trying to predict the next word based on the previous ones. If we are trying to predict the last word in \u201cthe clouds are in the sky,\u201d we don\u2019t need any further context \u2013 it\u2019s pretty obvious the next word is going to be sky. In such cases, where the gap between the relevant information and the place that it\u2019s needed is small, RNNs can learn to use the past information.\n\nBut there are also cases where we need more context. Consider trying to predict the last word in the text \u201cI grew up in France\u2026 I speak fluent French.\u201d Recent information suggests that the next word is probably the name of a language, but if we want to narrow down which language, we need the context of France, from further back. It\u2019s entirely possible for the gap between the relevant information and the point where it is needed to become very large.\n\nUnfortunately, as that gap grows, RNNs become unable to learn to connect the information.","7058550d":"<fontcolor:\"blue\">\n****\nHumans don\u2019t start their thinking from scratch every second. As you read this essay, you understand each word based on your understanding of previous words. You don\u2019t throw everything away and start thinking from scratch again. Your thoughts have persistence.\n\nTraditional neural networks can\u2019t do this, and it seems like a major shortcoming. ","0a9a6d74":"applying RNNs to a variety of problems: speech recognition, language modeling, translation, image captioning","ff4741b0":"This chain-like nature reveals that recurrent neural networks are intimately related to sequences and lists. They\u2019re the natural architecture of neural network to use for such data","9f172926":"LSTMs also have this chain like structure, but the repeating module has a different structure. Instead of having a single neural network layer, there are four, interacting in a very special way.\n","5c90d74b":"The first step in our LSTM is to decide what information we\u2019re going to throw away from the cell state. This decision is made by a sigmoid layer called the \u201cforget gate layer.\u201d It looks at ht\u22121 and xt, and outputs a number between 0 and 1 for each number in the cell state Ct\u22121. A 1 represents \u201ccompletely keep this\u201d while a 0 represents \u201ccompletely get rid of this.\u201d\n\nLet\u2019s go back to our example of a language model trying to predict the next word based on all the previous ones. In such a problem, the cell state might include the gender of the present subject, so that the correct pronouns can be used. When we see a new subject, we want to forget the gender of the old subject.\n\n","4c15aab8":"Evaluating the Model:","364d82f5":"In the above diagram, each line carries an entire vector, from the output of one node to the inputs of others. The pink circles represent pointwise operations, like vector addition, while the yellow boxes are learned neural network layers.\n\nThe LSTM does have the ability to remove or add information to the cell state, carefully regulated by structures called gates.\n\nGates are a way to optionally let information through. They are composed out of a sigmoid neural net layer and a pointwise multiplication operation.\n\nThe sigmoid layer outputs numbers between zero and one, describing how much of each component should be let through. A value of zero means \u201clet nothing through,\u201d while a value of one means \u201clet everything through!\u201d\n\nAn LSTM has three of these gates, to protect and control the cell state.","0ce8a319":"These loops make recurrent neural networks seem kind of mysterious. However, if you think a bit more, it turns out that they aren\u2019t all that different than a normal neural network. A recurrent neural network can be thought of as multiple copies of the same network, each passing a message to a successor. ","21065f9d":"Long Short Term Memory networks (LSTM):\n\nLong Short Term Memory networks \u2013 usually just called \u201cLSTMs\u201d \u2013 are a special kind of RNN, capable of learning long-term dependencies.\n\nLSTMs are explicitly designed to avoid the long-term dependency problem. Remembering information for long periods of time is practically their default behavior, not something they struggle to learn!\n\n","d456a8c7":"Recurrent neural networks address this issue. They are networks with loops in them, allowing information to persist.\n\nIn the above diagram, a chunk of neural network, A, looks at some input xt and outputs a value ht. A loop allows information to be passed from one step of the network to the next.","892b10d3":"Preparing the Labels:","b8309eb1":"It\u2019s now time to update the old cell state, Ct\u22121, into the new cell state Ct.\n\nWe multiply the old state by ft, forgetting the things we decided to forget earlier. Then we add it\u2217C~t. This is the new candidate values, scaled by how much we decided to update each state value.\n\nIn the case of the language model, this is where we\u2019d actually drop the information about the old subject\u2019s gender and add the new information, as we decided in the previous steps.","e806bef0":"The next step is to decide what new information we\u2019re going to store in the cell state. This has two parts. First, a sigmoid layer called the \u201cinput gate layer\u201d decides which values we\u2019ll update. Next, a tanh layer creates a vector of new candidate values, C~t, that could be added to the state. In the next step, we\u2019ll combine these two to create an update to the state.\n\nIn the example of our language model, we\u2019d want to add the gender of the new subject to the cell state, to replace the old one we\u2019re forgetting."}}