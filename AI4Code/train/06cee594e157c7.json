{"cell_type":{"bd80cd8e":"code","fe2c00c0":"code","5a617b1f":"code","15b407fe":"code","86ab3db3":"code","89f5adb0":"code","791a4846":"code","1265f802":"code","239332e1":"code","b75e3068":"code","e42517e3":"code","0d3a4b4c":"code","58475328":"code","68c64ddb":"code","e408c138":"code","36acd1ec":"code","eca28b3a":"code","cf41428c":"code","d2104bf2":"code","9d3fe746":"code","0ef15bd5":"code","dd89f2ea":"code","e5afa3c9":"code","f62311bb":"code","cd30858d":"code","7078c83f":"code","5a5c5656":"code","6380de69":"code","655beb27":"code","4f99fb47":"code","e800a6d3":"code","1d4d742d":"code","96182c4e":"code","cef231f8":"markdown","168f3271":"markdown","a4db4721":"markdown","ca710f33":"markdown","c0a1d133":"markdown"},"source":{"bd80cd8e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","fe2c00c0":"import warnings\nwarnings.filterwarnings(\"ignore\")","5a617b1f":"train = pd.read_csv(filepath_or_buffer='\/kaggle\/input\/train_LZdllcl.csv')\ntest = pd.read_csv(filepath_or_buffer='\/kaggle\/input\/test_2umaH9m.csv')","15b407fe":"train.shape, test.shape","86ab3db3":"train.duplicated().sum(), test.duplicated().sum()","89f5adb0":"train.head()","791a4846":"train.info()","1265f802":"train.nunique()","239332e1":"train.is_promoted.value_counts(), train.is_promoted.value_counts(normalize=True) ","b75e3068":"train.drop(columns='employee_id', inplace=True)\ntest.drop(columns='employee_id', inplace=True)","e42517e3":"for col in ['department', 'region', 'education', 'gender', 'recruitment_channel', \n            'previous_year_rating', 'KPIs_met >80%', 'awards_won?']:\n    train[col] = train[col].astype('object')\n    test[col] = test[col].astype('object')","0d3a4b4c":"train.head()","58475328":"train.education.fillna(train.education.mode()[0], inplace=True)\ntrain.previous_year_rating.fillna(train.previous_year_rating.median(), inplace=True)","68c64ddb":"# encoder cannot handle Nan\n# function to encode non-null data and replace it in the original data\ndef encode(data):\n    from sklearn.preprocessing import OrdinalEncoder\n    encoder = OrdinalEncoder()   \n    \n    #retains only non-null values\n    nonulls = np.array(data.dropna())\n    #reshapes the data for encoding\n    impute_reshape = nonulls.reshape(-1,1)\n    #encode data\n    impute_ordinal = encoder.fit_transform(impute_reshape)\n    #Assign back encoded values to non-null values\n    data.loc[data.notnull()] = np.squeeze(impute_ordinal)\n    return data","e408c138":"# create a list of categorical columns to iterate over\ncat_cols = train.columns[((train.dtypes == 'object') | (train.dtypes == 'category'))]\n\n#create a for loop to iterate through each column in the data\nfor columns in cat_cols[0: -1]:\n    encode(train[columns])\n    encode(test[columns])","36acd1ec":"train.head()","eca28b3a":"train['education'] = train['education'].astype('float64')\ntrain['previous_year_rating'] = train['previous_year_rating'].astype('float64')\ntrain['awards_won?'] = train['awards_won?'].astype('float64')\ntest['education'] = test['education'].astype('float64')\ntest['previous_year_rating'] = test['previous_year_rating'].astype('float64')\ntest['awards_won?'] = test['awards_won?'].astype('float64')","cf41428c":"# from sklearn.impute import KNNImputer\n# imputer = KNNImputer()\n# encoded_train = pd.DataFrame(np.round(imputer.fit_transform(train)), columns = train.columns)\n# test['is_promoted'] = np.nan\n# encoded_test = pd.DataFrame(np.round(imputer.transform(test)), columns = test.columns)","d2104bf2":"# test.drop(columns='is_promoted', inplace=True)\n# encoded_test.drop(columns='is_promoted', inplace=True)","9d3fe746":"X = train.drop(columns='is_promoted')\ny = train['is_promoted']\nX_test = test\n\n# X = encoded_train.drop(columns='is_promoted')\n# y = encoded_train['is_promoted']\n# X_test = encoded_test\n\nX.shape, y.shape, X_test.shape","0ef15bd5":"from sklearn.model_selection import train_test_split\nx_train, x_val, y_train, y_val = train_test_split(X, y, test_size=0.2)","dd89f2ea":"from lightgbm import LGBMClassifier\nmodel = LGBMClassifier(max_depth=5,\n                       learning_rate=0.4, \n                       n_estimators=100)\n\nmodel.fit(x_train,y_train,\n          eval_set=[(x_train,y_train),(x_val, y_val.values)],\n          eval_metric='auc',\n          early_stopping_rounds=100,\n          verbose=200)\n\npred_y = model.predict_proba(x_val)[:,1]","e5afa3c9":"from sklearn.metrics import accuracy_score, confusion_matrix, roc_auc_score, roc_curve\nprint(roc_auc_score(y_val, pred_y))\nconfusion_matrix(y_val, pred_y>0.5)","f62311bb":"import plotly.express as px\nfpr, tpr, thresholds = roc_curve(y_val, pred_y)\nfig = px.line(x=fpr, y=tpr, width=400, height=400,\n              labels={'x':'False Positive Rates','y':'True Positive Rates'})\nfig.show()","cd30858d":"import lightgbm\nlightgbm.plot_importance(model)","7078c83f":"err = []\ny_pred_tot_lgm = []\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfold = StratifiedKFold(n_splits=15)\ni = 1\nfor train_index, test_index in fold.split(X, y):\n    x_train, x_val = X.iloc[train_index], X.iloc[test_index]\n    y_train, y_val = y[train_index], y[test_index]\n    m = LGBMClassifier(boosting_type='gbdt',\n                       max_depth=5,\n                       learning_rate=0.05,\n                       n_estimators=5000,\n                       min_child_weight=0.01,\n                       colsample_bytree=0.5,\n                       random_state=1994)\n    m.fit(x_train, y_train,\n          eval_set=[(x_train,y_train),(x_val, y_val)],\n          early_stopping_rounds=200,\n          eval_metric='auc',\n          verbose=200)\n    pred_y = m.predict_proba(x_val)[:,1]\n    print(\"err_lgm: \",roc_auc_score(y_val,pred_y))\n    err.append(roc_auc_score(y_val, pred_y))\n    pred_test = m.predict_proba(X_test)[:,1]\n    i = i + 1\n    y_pred_tot_lgm.append(pred_test)","5a5c5656":"np.mean(err,0)","6380de69":"submission = pd.read_csv(filepath_or_buffer='\/kaggle\/input\/test_2umaH9m.csv')\nnp.mean(y_pred_tot_lgm, 0).max()","655beb27":"pd.read_csv(filepath_or_buffer='\/kaggle\/input\/test_2umaH9m.csv').shape","4f99fb47":"len(np.mean(y_pred_tot_lgm, 0))","e800a6d3":"submission = pd.DataFrame([pd.read_csv(filepath_or_buffer='\/kaggle\/input\/test_2umaH9m.csv').iloc[:, 0], np.mean(y_pred_tot_lgm, 0)])","1d4d742d":"submission = submission.T\nsubmission['employee_id'] = submission['employee_id'].astype('int')\nsubmission.rename(columns={'Unnamed 0': 'is_promoted'}, inplace=True)\nsubmission['is_promoted'] = submission['is_promoted'].round()\nsubmission['is_promoted'] = submission['is_promoted'].astype('int')\n\nsubmission.head()","96182c4e":"submission.to_csv('submit.csv', index=False, header=True)","cef231f8":"# Data exploration","168f3271":"# Boosting algorithms","a4db4721":"# Data creation ","ca710f33":"# Import datasets","c0a1d133":"# Data preprocessing"}}