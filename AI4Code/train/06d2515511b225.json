{"cell_type":{"fe71c97d":"code","f06f0d92":"code","881421fb":"code","cbe35e70":"code","988588fc":"code","910545e1":"code","986e11ff":"code","ff1962af":"code","70933aea":"code","6614f0e5":"code","32f6f3f8":"code","f26609cd":"code","d62fcb64":"code","98daed14":"code","3e99ea6e":"code","3090ac15":"code","71e7703c":"code","73343b86":"code","a50a8e22":"code","e457579b":"code","aeb7cc27":"code","0e7b1de3":"code","5881e036":"code","54233d63":"code","03a91370":"code","3c4a4478":"code","8e1f279a":"code","9a4e9b6d":"code","cbdbd31a":"code","45c9bb25":"code","2ba285a9":"code","9936c6e2":"code","87433a0f":"code","c6166fa2":"code","d54d76f2":"code","df7d3b0a":"code","63954471":"code","3ece705e":"code","38430208":"code","0f09bba3":"code","f40e0c58":"code","72a1bac5":"code","cf486fae":"code","bc47607f":"code","30202256":"code","29878dd3":"code","bc51e2d3":"code","852d419f":"code","7767f961":"code","4eec2975":"markdown","a8be2566":"markdown","11bda8df":"markdown","b59ed3e8":"markdown","911e8732":"markdown","a63b8dd6":"markdown","374e9009":"markdown","ba8b9ca6":"markdown","ad6203e5":"markdown","e52d6b30":"markdown","d5093831":"markdown","6fb31949":"markdown","90c31b58":"markdown","cbe14a03":"markdown","982c1344":"markdown","bb5651d3":"markdown","a58fb540":"markdown","29bc9313":"markdown","d3ac27b4":"markdown","53ad7059":"markdown","03205246":"markdown","8e166bc7":"markdown","d980372d":"markdown","72e7a10a":"markdown","f8b11637":"markdown","ab9bb7e8":"markdown","245e151e":"markdown","cb39f0ad":"markdown","982c25ca":"markdown","a86b5f03":"markdown","78db23fd":"markdown","d6b47686":"markdown","919fa227":"markdown","1e300dcc":"markdown","bb884b1f":"markdown","fa9ba17f":"markdown","6bb74da6":"markdown","5187b2f4":"markdown","2419cf7e":"markdown","1a956dbc":"markdown","de92b713":"markdown","0fa30fe1":"markdown","19474b48":"markdown"},"source":{"fe71c97d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f06f0d92":"#importing the necessary libraries\nfrom sklearn.metrics import roc_auc_score\nfrom lightgbm import LGBMClassifier\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import LabelEncoder\n\n\n","881421fb":"#function for one hot encoding of the categorical columns\ndef one_hot_encoding_dataframe(df):\n    original_columns = list(df.columns)\n    cat_columns=[x for x in df.columns if df[x].dtype == 'object']\n    df=pd.get_dummies(df,columns=cat_columns,dummy_na= False)\n    new_added_columns=list(set(df.columns).difference(set(original_columns)))\n    return df,new_added_columns,df.columns","cbe35e70":"#loading the main test and train data\nmain_df=pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/application_train.csv')\ntest_df=pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/application_test.csv')\ntrain_target = main_df[['TARGET', 'SK_ID_CURR']]\ntest_target = test_df['SK_ID_CURR'].copy()\n","988588fc":"#plot the top 20 features\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\ndef plotImp(model, X , num = 20, fig_size = (40, 20)):\n    feature_imp = pd.DataFrame({'Value':model.feature_importances_,'Feature':X.columns})\n    plt.figure(figsize=fig_size)\n    sns.set(font_scale = 5)\n    sns.barplot(x=\"Value\", y=\"Feature\", data=feature_imp.sort_values(by=\"Value\", \n                                                        ascending=False)[0:num])\n    plt.title('LightGBM Features (avg over folds)')\n    plt.tight_layout()\n    plt.show()","910545e1":"def credit_card_bal(df):\n    \n    \n    categorical_cols = ['NAME_CONTRACT_STATUS']\n    for col in categorical_cols:\n            enc = LabelEncoder()\n            df[col] = enc.fit_transform(df[col])\n            \n    #Creating new features\n    df['ratio_ab_acl'] = df['AMT_BALANCE'] \/ df['AMT_CREDIT_LIMIT_ACTUAL']\n    df['sum_draw'] = df[['AMT_DRAWINGS_ATM_CURRENT','AMT_DRAWINGS_CURRENT','AMT_DRAWINGS_OTHER_CURRENT', 'AMT_DRAWINGS_POS_CURRENT']].sum(axis=1)\n    df['ratio_tc_tr'] = df['AMT_PAYMENT_TOTAL_CURRENT'] \/ df['AMT_TOTAL_RECEIVABLE']\n    df['ratio_pc_ar'] = df['AMT_PAYMENT_CURRENT'] \/ df['AMT_RECIVABLE']\n    df['sum_cntdraw'] = df[['CNT_DRAWINGS_ATM_CURRENT', 'CNT_DRAWINGS_CURRENT', 'CNT_DRAWINGS_OTHER_CURRENT', 'CNT_DRAWINGS_POS_CURRENT']].sum(axis=1)\n    df['diff_tr_tc'] = df['AMT_TOTAL_RECEIVABLE'] \/ df['AMT_PAYMENT_TOTAL_CURRENT']\n    df['ratio_pc_ptc'] = df['AMT_PAYMENT_CURRENT'] \/ df['AMT_PAYMENT_TOTAL_CURRENT']\n    \n    #Creating aggregates\n    aggs = {\n        'MONTHS_BALANCE': ['min', 'max', 'size'],\n        'CNT_DRAWINGS_ATM_CURRENT': ['max'], \n        'CNT_DRAWINGS_CURRENT': ['max'],\n        'CNT_DRAWINGS_POS_CURRENT': ['max'],\n        'CNT_INSTALMENT_MATURE_CUM': ['mean', 'sum'],\n        'AMT_BALANCE': ['min', 'max', 'mean', 'sum'],\n        'AMT_CREDIT_LIMIT_ACTUAL': ['max', 'mean','var'],\n        'AMT_DRAWINGS_ATM_CURRENT': ['max'],\n        'AMT_DRAWINGS_CURRENT': ['max'],\n        'AMT_DRAWINGS_POS_CURRENT': ['max'],\n        'AMT_PAYMENT_CURRENT': ['max'],\n        'AMT_PAYMENT_TOTAL_CURRENT': ['max'],\n        'AMT_RECEIVABLE_PRINCIPAL': ['mean', 'sum'],\n        'AMT_RECIVABLE': ['mean', 'sum'],\n        'AMT_TOTAL_RECEIVABLE': ['mean'],\n        \n        #New features\n        'ratio_ab_acl': ['min', 'max', 'mean'],\n        'ratio_tc_tr': ['min', 'max', 'mean'],\n        'ratio_pc_ar': ['min', 'max', 'mean'],\n        'diff_tr_tc': ['min', 'max', 'mean'],\n        'ratio_pc_ptc': ['min', 'max', 'mean']\n    }\n    #creating n from those aggregates\n    cc_aggs = df.groupby('SK_ID_CURR').agg(aggs)\n    cc_aggs.columns = pd.Index([i[0] + \"_\" + i[1].upper() + '_(CREDIT_CARD)' for i in cc_aggs.columns.tolist()])\n    cc_aggs['CC_COUNT'] = df.groupby('SK_ID_CURR').size()\n    \n    return cc_aggs","986e11ff":"#reading credit information\ncredit_data = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/credit_card_balance.csv')\ndf_credit=credit_card_bal(credit_data)\n","ff1962af":"df_credit =main_df.merge(df_credit, how='left', on='SK_ID_CURR')\ndf_credit=df_credit[df_credit['TARGET'].notnull()]\n\ny_train=df_credit['TARGET']\ntrain_column=set(df_credit.columns)-set(main_df.columns)\nX_train=df_credit[train_column]\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)\n","70933aea":"import sklearn\nclasses_zero = main_df[main_df['TARGET'] == 0]\nclasses_one = main_df[main_df['TARGET'] == 1]\n\n# Convert parts into NumPy arrays for weight computation\nzero_numpy = classes_zero['TARGET'].to_numpy()\none_numpy = classes_one['TARGET'].to_numpy()\nall_together = np.concatenate((zero_numpy, one_numpy))\nunique_classes = np.unique(all_together)\n\n# Compute weights\nweights = sklearn.utils.class_weight.compute_class_weight('balanced', unique_classes, all_together)","6614f0e5":"#convert weights to dictionary\nwts={}\nfor i in range(len(weights)):\n    wts[i]=weights[i]","32f6f3f8":"poswt = len(classes_zero) \/ len(classes_one)\nposwt","f26609cd":"from sklearn.linear_model import LogisticRegression\n\nclf = LogisticRegression(class_weight=wts,solver='liblinear') # Linear Kernel\n\n#Train the model using the training sets\nclf.fit(X_train, y_train)\n","d62fcb64":"print(\"ROCAUC Score :\",roc_auc_score(y_train,clf.predict_proba(X_train)[:,1]))","98daed14":"from sklearn import tree\nDTclf = tree.DecisionTreeClassifier(class_weight=wts,max_depth=6)\nDTclf.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,DTclf.predict_proba(X_train)[:,1]))","3e99ea6e":"lgclf=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)\nlgclf.fit(X_train,y_train,eval_metric='auc')\n","3090ac15":"print(\"ROCAUC Score :\",roc_auc_score(y_train,lgclf.predict_proba(X_train)[:,1]))","71e7703c":"plotImp(lgclf,df_credit[train_column])","73343b86":"def install_bal(inst_df):\n    \n    inst_df['late_pay']=inst_df['DAYS_INSTALMENT']-inst_df['DAYS_ENTRY_PAYMENT']\n    inst_df['less_pay']=inst_df['AMT_INSTALMENT']-inst_df['AMT_PAYMENT']    \n    inst_df['late_lp']=0.5*inst_df['late_pay']+0.5*inst_df['less_pay']   \n    inst_df['ltp_flag']=((inst_df['DAYS_INSTALMENT']-inst_df['DAYS_ENTRY_PAYMENT'])>0).astype(int)    \n    inst_df['lsp_flag']=((inst_df['AMT_INSTALMENT']-inst_df['AMT_PAYMENT'])>0).astype(int)\n    \n    for col in inst_df.columns:\n        if col.startswith('DAYS'):\n            inst_df[col].replace(365243, np.nan, inplace= True)\n            \n    inst_df,installments_payments_cat_columns,all_columns=one_hot_encoding_dataframe(inst_df)\n       \n    inst_df_agg={}\n    for col in inst_df.columns:\n        if col!='SK_ID_CURR' and col !='SK_ID_PREV':\n            inst_df_agg[col]=['mean']\n            if (col=='late_pay') |  (col=='less_pay') | (col=='NUM_INSTALMENT_VERSION') | (col=='NUM_INSTALMENT_NUMBER'):\n                inst_df_agg[col]=['mean','sum','max','min']\n    \n    inst_agg = inst_df.groupby('SK_ID_CURR').agg(inst_df_agg)\n    \n    modified_col=[]\n    for c in list(inst_agg.columns):\n        modified_col.append(\"INST_\"+c[0]+\"_\"+c[1].upper())\n    inst_agg.columns=modified_col\n    \n    inst_agg['cnt_inst'] = inst_df.groupby('SK_ID_CURR')['SK_ID_PREV'].count()\n\n    no = -365*3\n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['3365_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['3365_ltp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].min()\n    inst_agg['3365_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    inst_agg['3365_ltp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['ltp_flag'].sum() \n\n    no = -365*2\n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['2365_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['2365_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    inst_agg['2365_ltp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['ltp_flag'].sum()\n\n    no = -365 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['365_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['365_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    inst_agg['365_ltp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['ltp_flag'].sum()\n    \n    no = -180 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >= no].copy()\n    inst_agg['180_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['180_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    inst_agg['180_ltp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['ltp_flag'].sum()\n    \n    no = -90 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >= no].copy()\n    inst_agg['90_ltp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].mean()\n    inst_agg['90_ltp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].min()\n    inst_agg['90_ltp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['late_pay'].max()\n    \n    no = -365*2\n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['2365_lsp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].mean()\n    inst_agg['2365_lsp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].min()\n    inst_agg['2365_lsp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].max()\n    inst_agg['2365_lsp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['lsp_flag'].sum()\n\n    no = -365 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >=no].copy()\n    inst_agg['365_lsp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].mean()\n    inst_agg['365_lsp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].min()\n    inst_agg['365_lsp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].max()\n    inst_agg['365_lsp_flag_cnt'] = inst_agg_temp.groupby('SK_ID_CURR')['lsp_flag'].sum()\n    \n    no = -180 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >= no].copy()\n    inst_agg['180_lsp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].mean()\n    inst_agg['180_lsp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].min()\n    inst_agg['180_lsp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].max()\n    \n    no = -90 \n    inst_agg_temp = inst_df[inst_df.DAYS_ENTRY_PAYMENT >= no].copy()\n    inst_agg['90_lsp_flag_mean'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].mean()\n    inst_agg['90_lsp_flag_min'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].min()\n    inst_agg['90_lsp_flag_max'] = inst_agg_temp.groupby('SK_ID_CURR')['less_pay'].max()\n    \n    return inst_agg","a50a8e22":"inst_data = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/installments_payments.csv')\n\ndf_inst=install_bal(inst_data)\ndf_inst =main_df.merge(df_inst, how='left', on='SK_ID_CURR')\ndf_inst=df_inst[df_inst['TARGET'].notnull()]\n\ny_train=df_inst['TARGET']\ntrain_column=set(df_inst.columns)-set(main_df.columns)\nX_train=df_inst[train_column]\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)","e457579b":"from sklearn.linear_model import LogisticRegression\n\nclf2 = LogisticRegression(class_weight=wts,solver='liblinear') # Linear Kernel\n\n#Train the model using the training sets\nclf2.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf2.predict_proba(X_train)[:,1]))","aeb7cc27":"from sklearn import tree\nDTclf2 = tree.DecisionTreeClassifier(class_weight=wts,max_depth=6)\nDTclf2.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,DTclf2.predict_proba(X_train)[:,1]))","0e7b1de3":"lgclf2=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)\nlgclf2.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,lgclf2.predict_proba(X_train)[:,1]))","5881e036":"plotImp(lgclf2,df_inst[train_column])","54233d63":"def pos_appl(pos_df):\n    \n    pos_df=pos_df[pos_df['NAME_CONTRACT_STATUS']!='XNA'] \n    pos_df,pos_data_cat_columns,all_columns=one_hot_encoding_dataframe(pos_df)\n     \n    pos_data_agg={}\n    for col in pos_df.columns:\n        if col!='SK_ID_CURR' and col !='SK_ID_PREV':\n            pos_data_agg[col]=['mean']\n        if col=='MONTHS_BALANCE':\n            pos_data_agg[col]=['sum','mean','max']\n    \n    pos_agg = pos_df.groupby('SK_ID_CURR').agg(pos_data_agg)\n    \n    modified_col=[]\n    for col in list(pos_agg.columns):\n        modified_col.append(\"POS_\"+col[0]+\"_\"+col[1].upper())\n    pos_agg.columns=modified_col\n    pos_agg['pos_cnt'] = pos_df.groupby('SK_ID_CURR')['SK_ID_PREV'].count() \n\n    month = -24 \n    pos_temp = pos_df[pos_df.MONTHS_BALANCE >= month].copy()\n    pos_agg['24_c_inst_mean'] = pos_temp.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].mean()\n    pos_agg['24_c_inst_max'] = pos_temp.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].max()\n    \n    month = -12 \n    pos_temp = pos_df[pos_df.MONTHS_BALANCE >= month].copy()\n    pos_agg['12_c_inst_mean'] = pos_temp.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].mean()\n    pos_agg['12_c_inst_max'] = pos_temp.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].max()\n    \n    active = pos_df[pos_df['NAME_CONTRACT_STATUS_Active'] == 1]\n   \n    pos_agg['active_inst_mean'] = active.groupby('SK_ID_CURR')['CNT_INSTALMENT'].mean()\n    pos_agg['active_inst_max'] = active.groupby('SK_ID_CURR')['CNT_INSTALMENT'].max()\n  \n    pos_agg['active_dpd_mean'] = active.groupby('SK_ID_CURR')['SK_DPD'].mean()\n    pos_agg['active_dpd_max'] = active.groupby('SK_ID_CURR')['SK_DPD'].max()\n\n    pos_agg['active_inst_fut_mean'] = active.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].mean()\n    pos_agg['active_inst_fut_max'] = active.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].max()\n  \n    pos_agg['active_dpd_def_mean'] = active.groupby('SK_ID_CURR')['SK_DPD_DEF'].mean()\n    pos_agg['active_dpd_def_max'] = active.groupby('SK_ID_CURR')['SK_DPD_DEF'].max()\n  \n    completed = pos_df[pos_df['NAME_CONTRACT_STATUS_Completed'] == 1]\n    pos_agg['com_dpd_mean'] = completed.groupby('SK_ID_CURR')['SK_DPD'].mean()\n    pos_agg['com_dpd_max'] = completed.groupby('SK_ID_CURR')['SK_DPD'].max()\n\n    pos_agg['com_dpd_def_mean'] = completed.groupby('SK_ID_CURR')['SK_DPD_DEF'].mean()\n    pos_agg['com_dpd_def_max'] = completed.groupby('SK_ID_CURR')['SK_DPD_DEF'].max()\n\n    pos_agg['com_inst_fut_mean'] = completed.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].mean()\n    pos_agg['com_inst_fut_max'] = completed.groupby('SK_ID_CURR')['CNT_INSTALMENT_FUTURE'].max()\n  \n    pos_agg['com_inst_mean'] = completed.groupby('SK_ID_CURR')['CNT_INSTALMENT'].mean()\n    pos_agg['com_inst_max'] = completed.groupby('SK_ID_CURR')['CNT_INSTALMENT'].max()\n  \n    return pos_agg\n","03a91370":"pos_data = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/POS_CASH_balance.csv')\n\ndf_pos=pos_appl(pos_data)\ndf_pos =main_df.merge(df_pos, how='left', on='SK_ID_CURR')\ndf_pos=df_pos[df_pos['TARGET'].notnull()]\n\ny_train=df_pos['TARGET']\ntrain_column=set(df_pos.columns)-set(main_df.columns)\nX_train=df_pos[train_column]\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)","3c4a4478":"from sklearn.linear_model import LogisticRegression\n\nclf3 = LogisticRegression(class_weight=wts,solver='liblinear') # Linear Kernel\n\n#Train the model using the training sets\nclf3.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf3.predict_proba(X_train)[:,1]))","8e1f279a":"from sklearn import tree\nDTclf3 = tree.DecisionTreeClassifier(class_weight=wts,max_depth=6)\nDTclf3.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,DTclf3.predict_proba(X_train)[:,1]))","9a4e9b6d":"lgclf3=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)\nlgclf3.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,lgclf3.predict_proba(X_train)[:,1]))","cbdbd31a":"plotImp(lgclf3,df_pos[train_column])","45c9bb25":"def bureau_bal(bureau_balance_data,bureau_data):\n\n    bureau_balance_data,bureau_balance_data_cat_columns,all_columns=one_hot_encoding_dataframe(bureau_balance_data)\n    #Aggregate function to be applied on numerical column \n    bureau_balance_agg = {'MONTHS_BALANCE': ['min', 'max','sum']}\n\n    #Aggregate function to be applied on cat column \n    for col in bureau_balance_data_cat_columns:\n        if (col!='SK_BUREAU_ID'):\n            bureau_balance_agg[col] = ['mean']\n\n    bal_agg = bureau_balance_data.groupby(['SK_ID_BUREAU']).agg(bureau_balance_agg)\n    \n    modified_col=[]\n    for col in list(bal_agg.columns):\n        if (col!='SK_BUREAU_ID'):\n            modified_col.append(col[0]+\"_\"+col[1].upper())\n    bal_agg.columns=modified_col\n    \n    bureau_data,bureau_data_cat_columns,all_columns=one_hot_encoding_dataframe(bureau_data)\n\n    bureau_data['SEC_LOAN_COUNT']=(bureau_data[['CREDIT_TYPE_Car loan','CREDIT_TYPE_Loan for the purchase of equipment','CREDIT_TYPE_Mortgage','CREDIT_TYPE_Real estate loan','CREDIT_TYPE_Loan for purchase of shares (margin lending)'\n                         ]]==1).sum(axis=1)\n    \n    bureau_data['UNSEC_LOAN_COUNT']=(bureau_data[[ 'CREDIT_TYPE_Another type of loan',\n       'CREDIT_TYPE_Cash loan (non-earmarked)', 'CREDIT_TYPE_Consumer credit',\n       'CREDIT_TYPE_Credit card', 'CREDIT_TYPE_Interbank credit',\n       'CREDIT_TYPE_Loan for business development',\n       'CREDIT_TYPE_Loan for working capital replenishment',\n       'CREDIT_TYPE_Microloan', 'CREDIT_TYPE_Mobile operator loan',\n       'CREDIT_TYPE_Unknown type of loan']]==1).sum(axis=1)\n    \n    bureau_data['ex_pay'] = bureau_data['AMT_ANNUITY']-bureau_data['AMT_CREDIT_SUM']\n    bureau_data['debt']=bureau_data['AMT_CREDIT_SUM_DEBT']\/bureau_data['AMT_CREDIT_SUM']\n    bureau_data['annu_per_cred']=bureau_data['AMT_ANNUITY']\/bureau_data['AMT_CREDIT_SUM']\n    \n    for col in bureau_data.columns:\n        if col.startswith('DAYS'):\n            bureau_data[col].replace(365243, np.nan, inplace= True)\n            \n    bureau_data = bureau_data.join(bal_agg, how='left', on=['SK_ID_BUREAU'])\n     \n    bureau_data_agg={}\n    for col in bureau_data.columns:\n        if (col!='SK_ID_CURR' or col!='SK_BUREAU_ID'):\n            bureau_data_agg[col]=['mean']\n            if (col=='AMT_CREDIT_SUM_DEBT') | (col=='AMT_CREDIT_SUM_OVERDUE') | (col=='UNSEC_LOAN_COUNT') |(col=='SEC_LOAN_COUNT'):\n                bureau_data_agg[col]=['sum']\n            if col=='DAYS_CREDIT':\n                bureau_data_agg[col]=['min']\n            if col=='debt':\n                bureau_data_agg[col]=['mean']\n    \n            \n    bureau_agg = bureau_data.groupby('SK_ID_CURR').agg(bureau_data_agg)\n    \n    modified_col=[]\n    for col in list(bureau_agg.columns):\n        modified_col.append(col[0]+\"_\"+col[1].upper())\n    bureau_agg.columns=modified_col\n    \n    bureau_agg['abs_cre_max']=abs(bureau_agg['DAYS_CREDIT_MIN']\/365) \n    bureau_agg['cre_max_od_max'] = bureau_data.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].max()\n    bureau_agg['cnt'] = bureau_data.groupby('SK_ID_CURR')['SK_ID_BUREAU'].count()\n    bureau_data_active = bureau_data[bureau_data['CREDIT_ACTIVE_Active'] == 1]\n    \n    bureau_agg['active_cred_mean'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM'].mean()\n    bureau_agg['active_cred_max'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM'].max()\n    bureau_agg['cred_od_mean'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].mean()\n    bureau_agg['cred_od_max'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].max()   \n    bureau_agg['active_cred_debt_mean'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_DEBT'].mean()\n    bureau_agg['active_cred_debt_max'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_DEBT'].max()\n    bureau_agg['active_cred_limit_mean'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_LIMIT'].mean()\n    bureau_agg['active_cred_limit_max'] = bureau_data_active.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_LIMIT'].max()\n    bureau_agg['cred_days_mean'] = bureau_data_active.groupby('SK_ID_CURR')['DAYS_CREDIT'].mean()\n    bureau_agg['cred_days_max'] = bureau_data_active.groupby('SK_ID_CURR')['DAYS_CREDIT'].max()  \n    bureau_agg['cred_ed_mean'] = bureau_data_active.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].mean()\n    bureau_agg['cred_ed_max'] = bureau_data_active.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].max()\n    bureau_data_closed = bureau_data[bureau_data['CREDIT_ACTIVE_Closed'] == 1]\n    bureau_agg['cls_cred_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM'].mean()\n    bureau_agg['cls_cred_max'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM'].max()\n    bureau_agg['B_CLO_AMT_CREDIT_MAX_OVERDUE_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].mean()\n    bureau_agg['B_CLO_AMT_CREDIT_MAX_OVERDUE_max'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_MAX_OVERDUE'].max()\n    bureau_agg['cls_cred_d_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_DEBT'].mean()\n    bureau_agg['cls_cred_d_max'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_DEBT'].max()\n    bureau_agg['cls_cred_d_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_LIMIT'].mean()\n    bureau_agg['cls_cred_d_max'] = bureau_data_closed.groupby('SK_ID_CURR')['AMT_CREDIT_SUM_LIMIT'].max()\n    bureau_agg['cls_credd_ed_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].mean()\n    bureau_agg['cls_credd_ed_max'] = bureau_data_closed.groupby('SK_ID_CURR')['DAYS_CREDIT_ENDDATE'].max()\n    bureau_agg['cls_credd_mean'] = bureau_data_closed.groupby('SK_ID_CURR')['DAYS_CREDIT'].mean()\n    bureau_agg['cls_credd_max'] = bureau_data_closed.groupby('SK_ID_CURR')['DAYS_CREDIT'].max()\n    bureau_agg.drop(['SK_ID_CURR_MEAN'], axis=1, inplace= True)\n    bureau_agg.drop(['SK_ID_BUREAU_MEAN'], axis=1, inplace= True)\n    \n    \n    return bureau_agg","2ba285a9":"bureau_bal_data = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/bureau_balance.csv')\nbureau_data = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/bureau.csv')\n\ndf_bureau=bureau_bal(bureau_bal_data,bureau_data)\ndf_bureau =main_df.merge(df_bureau, how='left', on='SK_ID_CURR')\ndf_bureau=df_bureau[df_bureau['TARGET'].notnull()]\n\ny_train=df_bureau['TARGET']\ntrain_column=set(df_bureau.columns)-set(main_df.columns)\nX_train=df_bureau[train_column]\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)\n","9936c6e2":"from sklearn.linear_model import LogisticRegression\n\nclf4 = LogisticRegression(class_weight=wts,solver='liblinear') # Linear Kernel\n\n#Train the model using the training sets\nclf4.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf4.predict_proba(X_train)[:,1]))","87433a0f":"from sklearn import tree\nDTclf4 = tree.DecisionTreeClassifier(class_weight=wts,max_depth=6)\nDTclf4.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,DTclf4.predict_proba(X_train)[:,1]))","c6166fa2":"lgclf4=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)\nlgclf4.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,lgclf4.predict_proba(X_train)[:,1]))","d54d76f2":"plotImp(lgclf4,df_bureau[train_column])","df7d3b0a":"def prev_appl(prev_df):\n    \n    for col in prev_df.columns:\n        if col.startswith('DAYS'):\n            prev_df[col].replace(365243, np.nan, inplace= True)\n    \n    prev_df['extra_paid'] = prev_df['CNT_PAYMENT']*prev_df['AMT_ANNUITY']-prev_df['AMT_CREDIT']\n    prev_df['to_pay'] = prev_df['CNT_PAYMENT']*prev_df['AMT_ANNUITY']-prev_df['AMT_DOWN_PAYMENT']\n    prev_df['roi'] = (1\/prev_df['CNT_PAYMENT'])*(((prev_df['CNT_PAYMENT']*prev_df['AMT_ANNUITY'])\/prev_df['AMT_CREDIT'])-1)\n    prev_df['si']= (prev_df['AMT_CREDIT']*prev_df['roi']*prev_df['CNT_PAYMENT'])\/100    \n    prev_df['xap']=((prev_df['CODE_REJECT_REASON']=='XAP')).astype(int)\n    prev_df['dp']=(prev_df['AMT_DOWN_PAYMENT']<=(0.40*prev_df['AMT_CREDIT'])).astype(int) \n    prev_df,prev_df_cat_columns,all_columns=one_hot_encoding_dataframe(prev_df)\n   \n    prev_df_agg={}\n    for col in prev_df.columns:\n        if col!='SK_ID_CURR' and col !='SK_ID_PREV':\n            prev_df_agg[col]=['mean']\n        if (col=='DAYS_TERMINATION') | (col=='DAYS_FIRST_DUE') | (col=='DAYS_LAST_DUE') | (col=='AMT_CREDIT') | (col=='AMT_ANNUITY') | (col=='AMT_DOWN_PAYMENT') | (col=='DAYS_LAST_DUE_1ST_VERSION') |(col=='HOUR_APPR_PROCESS_START') :\n            prev_df_agg[col]=['max','mean']\n            \n    prev_agg = prev_df.groupby('SK_ID_CURR').agg(prev_df_agg)\n    \n    modified_col=[]\n    for col in list(prev_agg.columns):\n        modified_col.append(\"PREV_\"+col[0]+\"_\"+col[1].upper())\n    \n    prev_agg.columns=modified_col\n    \n    ref_canc = prev_df[(prev_df['NAME_CONTRACT_STATUS_Refused'] == 1) | (prev_df['NAME_CONTRACT_STATUS_Canceled'] == 1)]\n    prev_agg['cr_cred_mean'] = ref_canc.groupby('SK_ID_CURR')['AMT_CREDIT'].mean()\n    prev_agg['cr_cred_max'] = ref_canc.groupby('SK_ID_CURR')['AMT_CREDIT'].max()\n    prev_agg['cr_int_mean'] = ref_canc.groupby('SK_ID_CURR')['roi'].mean()\n    prev_agg['cr_int_max'] = ref_canc.groupby('SK_ID_CURR')['roi'].max()\n    prev_agg['cr_annu_mean'] = ref_canc.groupby('SK_ID_CURR')['AMT_ANNUITY'].mean()\n    prev_agg['cr_annu_max'] = ref_canc.groupby('SK_ID_CURR')['AMT_ANNUITY'].max()\n    prev_agg['cr_dp_mean'] = ref_canc.groupby('SK_ID_CURR')['AMT_DOWN_PAYMENT'].mean()\n    prev_agg['cr_dp_max'] = ref_canc.groupby('SK_ID_CURR')['AMT_DOWN_PAYMENT'].max()\n    prev_agg['cr_lp_mean'] = ref_canc.groupby('SK_ID_CURR')['to_pay'].mean()\n    prev_agg['cr_lp_max'] = ref_canc.groupby('SK_ID_CURR')['to_pay'].max()\n \n    appr = prev_df[(prev_df['NAME_CONTRACT_STATUS_Approved'] == 1)]\n    prev_agg['va_cred_mean'] = appr.groupby('SK_ID_CURR')['AMT_CREDIT'].mean()\n    prev_agg['va_cred_max'] = appr.groupby('SK_ID_CURR')['AMT_CREDIT'].max()\n    prev_agg['va_annu_mean'] = appr.groupby('SK_ID_CURR')['AMT_ANNUITY'].mean()\n    prev_agg['va_annu_max'] = appr.groupby('SK_ID_CURR')['AMT_ANNUITY'].max()\n    prev_agg['va_dp_mean'] = appr.groupby('SK_ID_CURR')['AMT_DOWN_PAYMENT'].mean()\n    prev_agg['va_int_mean'] = appr.groupby('SK_ID_CURR')['roi'].mean()\n    prev_agg['va_int_max'] = appr.groupby('SK_ID_CURR')['roi'].max()\n    prev_agg['va_dp_max'] = appr.groupby('SK_ID_CURR')['AMT_DOWN_PAYMENT'].max()\n    prev_agg['va_lp_mean'] = appr.groupby('SK_ID_CURR')['to_pay'].mean()\n    prev_agg['va_lp_max'] = appr.groupby('SK_ID_CURR')['to_pay'].max()\n    \n    return prev_agg","63954471":"prev_data = pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/previous_application.csv')\n\ndf_prevapp=prev_appl(prev_data)\ndf_prevapp =main_df.merge(df_prevapp, how='left', on='SK_ID_CURR')\ndf_prevapp=df_prevapp[df_prevapp['TARGET'].notnull()]\n\ny_train=df_prevapp['TARGET']\ntrain_column=set(df_prevapp.columns)-set(main_df.columns)\nX_train=df_prevapp[train_column]\n\ntrain_column=X_train.columns\nX_train=X_train.replace([np.inf, -np.inf],np.nan)\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\nscaler = MinMaxScaler(feature_range = (0, 1))\nX_train=scaler.fit_transform(X_train)\n","3ece705e":"from sklearn.linear_model import LogisticRegression\n\nclf5 = LogisticRegression(class_weight=wts,solver='liblinear') # Linear Kernel\n\nclf5.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf5.predict_proba(X_train)[:,1]))","38430208":"from sklearn import tree\nDTclf5 = tree.DecisionTreeClassifier(class_weight=wts,max_depth=6)\nDTclf5.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,DTclf5.predict_proba(X_train)[:,1]))","0f09bba3":"lgclf5=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)\nlgclf5.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,lgclf5.predict_proba(X_train)[:,1]))","f40e0c58":"plotImp(lgclf5,df_prevapp[train_column])","72a1bac5":"def appl_train_test(app_train,app_test):\n    \n    df=app_train.append(app_test).reset_index()\n        \n    #as 365243 is an outlier\n    df[\"DAYS_EMPLOYED\"].replace({365243: np.nan}, inplace = True)\n    df['hdwmqy']=(df[['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n       'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON', 'AMT_REQ_CREDIT_BUREAU_QRT',\n       'AMT_REQ_CREDIT_BUREAU_YEAR']]).sum(axis=1)\n    \n    #Using domain knowledge \n    #time spent in work\n    df['days_work']=df['DAYS_EMPLOYED'] \/ df['DAYS_BIRTH']\n    df['days_unemp']=abs(df['DAYS_BIRTH'])-abs(df['DAYS_EMPLOYED'])\n    df['inc_per_price']=df['AMT_INCOME_TOTAL']\/df['AMT_GOODS_PRICE']\n    df['cred_per_price']=df['AMT_CREDIT']\/df['AMT_GOODS_PRICE']\n    df['ann_per_price']=df['AMT_ANNUITY']\/df['AMT_GOODS_PRICE']\n    #percentage income of person and the credit amount\n    df['inc_per'] = df['AMT_INCOME_TOTAL'] \/ (df['CNT_FAM_MEMBERS']+1)\n    #income per credit\n    df['inc_per_cred'] = df['AMT_INCOME_TOTAL'] \/ df['AMT_CREDIT']\n    df['emp_per_cred'] = df['DAYS_EMPLOYED']\/ df['AMT_CREDIT']  \n\n    #Anually paid amount to amount credited\n    df['pay_rate'] = df['AMT_ANNUITY'] \/ df['AMT_CREDIT']\n    df['loan_pay'] = df['AMT_INCOME_TOTAL']-df['AMT_ANNUITY']\n    df['soc_cir']=((df[['OBS_30_CNT_SOCIAL_CIRCLE', 'DEF_30_CNT_SOCIAL_CIRCLE',\n       'OBS_60_CNT_SOCIAL_CIRCLE', 'DEF_60_CNT_SOCIAL_CIRCLE']]).sum(axis=1))\/\/4\n    df['mean_eq']=((df[['AMT_REQ_CREDIT_BUREAU_HOUR', 'AMT_REQ_CREDIT_BUREAU_DAY',\n       'AMT_REQ_CREDIT_BUREAU_WEEK', 'AMT_REQ_CREDIT_BUREAU_MON','AMT_REQ_CREDIT_BUREAU_QRT','AMT_REQ_CREDIT_BUREAU_YEAR']]).mean(axis=1))    \n    df['contact']=((df[['FLAG_MOBIL', 'FLAG_EMP_PHONE',\n       'FLAG_WORK_PHONE', 'FLAG_CONT_MOBILE','FLAG_PHONE','FLAG_EMAIL']]).sum(axis=1))\n    \n    #Creating features from useful features\n    df['ext_mean']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n       'EXT_SOURCE_3']]).mean(axis=1)   \n    df['ext_med']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n       'EXT_SOURCE_3']]).median(axis=1)  \n    df['ext_min']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n       'EXT_SOURCE_3']]).min(axis=1) \n    df['ext_max']=(df[['EXT_SOURCE_1', 'EXT_SOURCE_2',\n       'EXT_SOURCE_3']]).max(axis=1)\n\n    df['DOCUMNNET_COUNT']=(df[['FLAG_DOCUMENT_2', 'FLAG_DOCUMENT_3',\n       'FLAG_DOCUMENT_4', 'FLAG_DOCUMENT_5', 'FLAG_DOCUMENT_6',\n       'FLAG_DOCUMENT_7', 'FLAG_DOCUMENT_8', 'FLAG_DOCUMENT_9',\n       'FLAG_DOCUMENT_10', 'FLAG_DOCUMENT_11', 'FLAG_DOCUMENT_12',\n       'FLAG_DOCUMENT_13', 'FLAG_DOCUMENT_14', 'FLAG_DOCUMENT_15',\n       'FLAG_DOCUMENT_16', 'FLAG_DOCUMENT_17', 'FLAG_DOCUMENT_18',\n       'FLAG_DOCUMENT_19', 'FLAG_DOCUMENT_20', 'FLAG_DOCUMENT_21']]==1).sum(axis=1)\n    \n    df,cal_cols,acols=one_hot_encoding_dataframe(df)\n    \n    return df","cf486fae":"dtrain=pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/application_train.csv')\ndtest=pd.read_csv('\/kaggle\/input\/home-credit-default-risk\/application_test.csv')\n\ndf=appl_train_test(dtrain,dtest)\n","bc47607f":"train_data_df=df[df['TARGET'].notnull()]\ntrain_column=set(train_data_df.columns)-set({'TARGET','index','SK_ID_CURR'})\ntest_data_df=df[df['TARGET'].isnull()]\ntest_column=set(test_data_df.columns)-set({'SK_ID_CURR','TARGET','index'})\n#ytrain to train the model\ny_train=train_data_df['TARGET']\nX_train=train_data_df[train_column]\nfrom sklearn.impute import SimpleImputer\nimputer1 = SimpleImputer(missing_values=np.nan, strategy='median')\nX_train=imputer1.fit_transform(X_train)\n\nscaler = MinMaxScaler(feature_range = (0, 1))\nscaler.fit(X_train)\nX_train = scaler.transform(X_train)","30202256":"from sklearn.linear_model import LogisticRegression\n\nclf6 = LogisticRegression(class_weight=wts,solver='liblinear') # Linear Kernel\n\n#Train the model using the training sets\nclf6.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,clf6.predict_proba(X_train)[:,1]))","29878dd3":"from sklearn import tree\nDTclf6 = tree.DecisionTreeClassifier(class_weight=wts,max_depth=6)\nDTclf6.fit(X_train, y_train)\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,DTclf6.predict_proba(X_train)[:,1]))","bc51e2d3":"lgclf6=LGBMClassifier(boosting_type= 'goss',n_estimators= 10000,\n    learning_rate= 0.005,\n    num_leaves= 30,\n    max_depth= 6,\n    subsample_for_bin= 24000,\n    reg_alpha= 0.436193,\n    reg_lambda= 0.479169,\n    min_split_gain= 0.024766,\n    subsample= 1,\n    scale_pos_weight=poswt)\nlgclf6.fit(X_train,y_train,eval_metric='auc')\nprint(\"ROCAUC Score :\",roc_auc_score(y_train,lgclf6.predict_proba(X_train)[:,1]))","852d419f":"plotImp(lgclf4,train_data_df[train_column])","7767f961":"from sklearn.ensemble import RandomForestClassifier\nrf = RandomForestClassifier(class_weight=wts,max_depth=6)\nrf_model= rf.fit(X_train, y_train)\n","4eec2975":"### Decison tree","a8be2566":"For choosing the best model to use in Level 0 of our stacking ensemble, we tried 3 models and used the model that gave the best score on train data for all tables","11bda8df":"## 4) Bureau Balance table","b59ed3e8":"# A comparision of L0 models","911e8732":"### Logistic Regression","a63b8dd6":"## 2) For Installments table","374e9009":"### Decision tree","ba8b9ca6":"### Linear Regression","ad6203e5":"### Top 20 features of application train (main) table","e52d6b30":"### Top 20 features for POS table","d5093831":"### We will also be plotting the top 20 features that help in predicting the target\nWe are using feature_importances of lightgbm to show the top 20 features. This is the function to find the top features","6fb31949":"## 1) Credit Card balance table","90c31b58":"### Decision Tree","cbe14a03":"### LightGBM","982c1344":"### Top 20 features for installments table","bb5651d3":"## 5) Previous application table","a58fb540":"### Logistic Regression","29bc9313":"### LightGBM","d3ac27b4":"## Training models and finding their auc scores on train data to find the best model","53ad7059":"### Decision tree","03205246":"**The best model is Lightgbm**","8e166bc7":"# Hence the most suitable model for level 0 model is LighGBM with the same parameters used","d980372d":"### LightGBM","72e7a10a":"### Logistic Regression","f8b11637":"**The best model is Lightgbm**","ab9bb7e8":"**The best model is Lightgbm**","245e151e":"### Logistic regression","cb39f0ad":"### LightGBM","982c25ca":"### Top 20 features of previous applications table","a86b5f03":"### LightGBM","78db23fd":"### To assign weight for decision tree","d6b47686":"### Top 20 features of Bureau and bureau balance tables","919fa227":"## 3) POS table","1e300dcc":"### Since the classes are imbalanced, we need to assign them weights","bb884b1f":"**The best model is Lightgbm**","fa9ba17f":"## 6) Application train and test data","6bb74da6":"### Top 20 features for credit card balance table","5187b2f4":"### Decision tree","2419cf7e":"**The best model is Lightgbm**","1a956dbc":"**The best model is Lightgbm**","de92b713":"### Decision tree","0fa30fe1":"### Logistic Regression","19474b48":"### Logistic regression"}}