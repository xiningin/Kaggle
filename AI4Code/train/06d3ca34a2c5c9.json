{"cell_type":{"d1dd261f":"code","22ff15f7":"code","580b2673":"code","eb71fb45":"code","f3014214":"code","b02bb64f":"code","6c891a40":"code","945763ca":"code","e869a1d2":"code","dcddf0f4":"code","cccd0c3c":"code","eed7304f":"code","a3acd09e":"code","b802de81":"code","806e74fa":"code","7e53a841":"code","86f7f769":"code","bb552940":"code","e0472720":"code","fd32063e":"code","1d68f041":"code","87fd9a2b":"code","d4f277b5":"code","5b71e356":"markdown"},"source":{"d1dd261f":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport glob\nimport os\nimport gc\nimport time\nfrom scipy.interpolate import interp1d\nimport lightgbm as lgb\nimport xgboost as xgb\nfrom joblib import Parallel, delayed\nfrom tqdm.notebook import tqdm\nfrom scipy.stats import rankdata\n\nfrom sklearn.model_selection import GroupKFold\nfrom sklearn.metrics import roc_auc_score, label_ranking_average_precision_score\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.ensemble import RandomForestClassifier,AdaBoostClassifier,GradientBoostingClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn import svm\nfrom sklearn.ensemble import VotingClassifier\n\nimport soundfile as sf\n# Librosa Libraries\nimport librosa\nimport librosa.display\nimport IPython.display as ipd\nimport matplotlib.pyplot as plt\n\nimport cuml as cm\nimport cupy as cp","22ff15f7":"trainfiles = glob.glob( '..\/input\/rfcx-species-audio-detection\/train\/*.flac' )\ntestfiles = glob.glob( '..\/input\/rfcx-species-audio-detection\/test\/*.flac' )\nlen(trainfiles), len(testfiles), trainfiles[0]","580b2673":"traint = pd.read_csv( '..\/input\/rfcx-species-audio-detection\/train_tp.csv' )\ntrainf = pd.read_csv( '..\/input\/rfcx-species-audio-detection\/train_fp.csv' )\ntraint.shape, trainf.shape","eb71fb45":"traint.head()","f3014214":"trainf.head()","b02bb64f":"df_for_zero = traint[traint.species_id == 0]['recording_id']\ndf_for_zero.reset_index(inplace=True, drop=True)\n#print(df_for_zero)\nprint(type(df_for_zero), len(df_for_zero),df_for_zero.get(0))","6c891a40":"fn = df_for_zero.get(1)\ndata, samplerate = sf.read('..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac')\nprint( data.shape, samplerate )\nprint (data.shape[0])\nlibrosa.display.waveplot(y = data, sr = samplerate, color = \"#B14D\")\nipd.Audio('..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac')","945763ca":"print(type(data),data.shape)\n","e869a1d2":"data1 = cp.array(data)\nprint(type(data1),data1.shape)\nvarfft = cp.abs( cp.fft.fft(data1)[:(len(data1)\/\/2)] )\nprint(type(varfft),varfft.shape)\nvarfft1 = cp.asnumpy( varfft.reshape( (1000,1440) ).mean(axis=1) )\nprint(type(varfft1),varfft1.shape)\n","dcddf0f4":"mfccs = librosa.feature.mfcc(y=data, sr=samplerate , n_mfcc=40)\nprint(type(mfccs),mfccs.shape)\nmfccs_scaled = np.mean(mfccs.T,axis=0)\nprint(type(mfccs_scaled),mfccs_scaled.shape)\n","cccd0c3c":"import matplotlib.pyplot\nplt.plot(mfccs_scaled)\nplt.show()","eed7304f":"plt.plot(varfft1)\nplt.show()","a3acd09e":"def extract_fft(fn):\n    data, samplerate = sf.read(fn)\n    data = cp.array(data)\n\n    varfft = cp.abs( cp.fft.fft(data)[:(len(data)\/\/2)] )\n    \n    return cp.asnumpy( varfft.reshape( (1000,1440) ).mean(axis=1) )","b802de81":"def extract_mfccs(fn):\n    data, samplerate = sf.read(fn)\n    mfccs = librosa.feature.mfcc(y=data, sr=samplerate , n_mfcc=40)\n    \n    return np.mean(mfccs.T,axis=0)","806e74fa":"FT = []\nfor fn in tqdm(traint.recording_id.values):\n    FT.append( extract_mfccs( '..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac' ) )\nFT = np.stack(FT)\ngc.collect()\n\nFT.shape","7e53a841":"# This loop runs in 7min using cupy(GPU) and 40min on numpy(CPU). ~7x Faster in GPU\n\nFF = []\nfor fn in tqdm(trainf.recording_id.values):\n    FF.append( extract_mfccs( '..\/input\/rfcx-species-audio-detection\/train\/'+fn+'.flac' ) )\nFF = np.stack(FF)\ngc.collect()\n\nFF.shape","86f7f769":"#Combine True Positives and False Positives\n\nTRAIN = np.vstack( (FT, FF) )\n\ndel FT, FF\ngc.collect()\nTRAIN.shape","bb552940":"TEST = []\nfor fn in tqdm(testfiles):\n    TEST.append( extract_mfccs(fn) )\nTEST = np.stack(TEST)\ngc.collect()\n\nTEST.shape","e0472720":"tt = traint[['recording_id','species_id']].copy()\ntf = trainf[['recording_id','species_id']].copy()\ntf['species_id'] = -1\n\nTRAIN_TAB = pd.concat( (tt, tf) )\n\nfor i in range(24):\n    TRAIN_TAB['s'+str(i)] = 0\n    TRAIN_TAB.loc[TRAIN_TAB.species_id==i,'s'+str(i)] = 1\n\nTRAIN_TAB.head()","fd32063e":"from sklearn.preprocessing import StandardScaler\n\nstd = StandardScaler()\nstd.fit( np.vstack((TRAIN,TEST)) )\n\nTRAIN = std.transform(TRAIN)\nTEST  = std.transform(TEST)\ngc.collect()","1d68f041":"sub = pd.DataFrame({'recording_id': [f.split('\/')[-1].split('.')[0] for f in testfiles] })\ngkf = GroupKFold(5)\n\nSCORE = []\ngroups = TRAIN_TAB['recording_id'].values\nfor tgt in range(0,24):\n    starttime = time.time()\n    target = TRAIN_TAB['s'+str(tgt)].values\n\n    ytrain = np.zeros(TRAIN.shape[0])\n    ytest = np.zeros(TEST.shape[0])\n    for ind_train, ind_valid in gkf.split( TRAIN, target, groups ):\n        \n        # Define 4 models\n        clf1 = LogisticRegression(random_state=49)\n        clf4 = XGBClassifier(reg_alpha=3, reg_lambda=1,gamma=5, n_estimators=2, objective='binary:logistic',                 \n                                     learning_rate=1, max_delta_step=0, max_depth=2)\n        clf5 = svm.SVC(C=0.05, degree=2, gamma='scale', shrinking=True, kernel='poly',probability=True)\n        clf6 = RandomForestClassifier(n_estimators=3, random_state=2)\n        clf7 = svm.SVC(C=0.01, degree=1, gamma='scale', shrinking=True, kernel='linear',probability=True)\n\n\n        eclf = VotingClassifier(estimators=[('lr', clf1),('xgb', clf4),('svm', clf5),\n                                           ('rf2', clf6),('svm2', clf7)],voting='soft')\n\n        \n        # Train using GPUs\n        eclf.fit( X=TRAIN[ind_train], y=target[ind_train] )\n\n        # Predict valid and test sets\n        yvalid1 = eclf.predict_proba(TRAIN[ind_valid])[:,1]\n        ytest1 = eclf.predict_proba(TEST)[:,1]\n  \n        \n        #Rank predictions\n        #Weighted average models\n        ytrain[ind_valid] = yvalid1\n        ytest += ytest1 \/ 5.\n\n    score = roc_auc_score(target, ytrain)\n    print( 'Target AUC', tgt, score, time.time()-starttime )\n    SCORE.append(score)\n    \n    TRAIN_TAB['y'+str(tgt)] = ytrain\n    sub['s'+str(tgt)] = ytest\n\nprint('Overall Score:', np.mean(SCORE) )","87fd9a2b":"sub.to_csv('submission.csv', index=False)","d4f277b5":"!ls","5b71e356":"This is with MFCC and XGBoost"}}