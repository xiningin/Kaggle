{"cell_type":{"1f2106ae":"code","57803dbc":"code","05194f35":"code","78d2b0f5":"code","7449223e":"code","49dd459c":"code","ea99fd6f":"code","9a20b94c":"code","78e6181c":"code","f3aee49a":"code","f43bd948":"code","7d11e0d7":"code","955f4b80":"code","9d2058b8":"code","b6a9c7ca":"code","b1ba9d3d":"code","fba58542":"code","9f850b31":"code","cb0134db":"code","d091f243":"code","66960a2f":"code","a25ee38c":"code","042acea8":"code","591aa0da":"code","977140f3":"code","fa35cfae":"code","709a9e15":"code","e49c1cb3":"code","9649b381":"code","5a07835e":"code","35fd75af":"code","fb4f2594":"code","51efcedc":"code","8809cd81":"code","9b62ee04":"code","2d79a36b":"code","8c3c1b85":"markdown","b308138f":"markdown","d2a37dd7":"markdown"},"source":{"1f2106ae":"from __future__ import print_function, division\n\nimport torch\nfrom torch.autograd import Variable\nimport torch.nn.functional as F\nimport numpy as np\ntry:\n    from itertools import  ifilterfalse\nexcept ImportError: # py3k\n    from itertools import  filterfalse\n\n\ndef lovasz_grad(gt_sorted):\n    \"\"\"\n    Computes gradient of the Lovasz extension w.r.t sorted errors\n    See Alg. 1 in paper\n    \"\"\"\n    p = len(gt_sorted)\n    gts = gt_sorted.sum()\n    intersection = gts - gt_sorted.float().cumsum(0)\n    union = gts + (1 - gt_sorted).float().cumsum(0)\n    jaccard = 1. - intersection \/ union\n    if p > 1: # cover 1-pixel case\n        jaccard[1:p] = jaccard[1:p] - jaccard[0:-1]\n    return jaccard\n\n\ndef iou_binary(preds, labels, EMPTY=1., ignore=None, per_image=True):\n    \"\"\"\n    IoU for foreground class\n    binary: 1 foreground, 0 background\n    \"\"\"\n    if not per_image:\n        preds, labels = (preds,), (labels,)\n    ious = []\n    for pred, label in zip(preds, labels):\n        intersection = ((label == 1) & (pred == 1)).sum()\n        union = ((label == 1) | ((pred == 1) & (label != ignore))).sum()\n        if not union:\n            iou = EMPTY\n        else:\n            iou = float(intersection) \/ union\n        ious.append(iou)\n    iou = mean(ious)    # mean accross images if per_image\n    return 100 * iou\n\n\ndef iou(preds, labels, C, EMPTY=1., ignore=None, per_image=False):\n    \"\"\"\n    Array of IoU for each (non ignored) class\n    \"\"\"\n    if not per_image:\n        preds, labels = (preds,), (labels,)\n    ious = []\n    for pred, label in zip(preds, labels):\n        iou = []    \n        for i in range(C):\n            if i != ignore: # The ignored label is sometimes among predicted classes (ENet - CityScapes)\n                intersection = ((label == i) & (pred == i)).sum()\n                union = ((label == i) | ((pred == i) & (label != ignore))).sum()\n                if not union:\n                    iou.append(EMPTY)\n                else:\n                    iou.append(float(intersection) \/ union)\n        ious.append(iou)\n    ious = map(mean, zip(*ious)) # mean accross images if per_image\n    return 100 * np.array(ious)\n\n\n# --------------------------- BINARY LOSSES ---------------------------\n\n\ndef lovasz_hinge(logits, labels, per_image=True, ignore=None):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      per_image: compute the loss per image instead of per batch\n      ignore: void class id\n    \"\"\"\n    if per_image:\n        loss = mean(lovasz_hinge_flat(*flatten_binary_scores(log.unsqueeze(0), lab.unsqueeze(0), ignore))\n                          for log, lab in zip(logits, labels))\n    else:\n        loss = lovasz_hinge_flat(*flatten_binary_scores(logits, labels, ignore))\n    return loss\n\n\ndef lovasz_hinge_flat(logits, labels):\n    \"\"\"\n    Binary Lovasz hinge loss\n      logits: [P] Variable, logits at each prediction (between -\\infty and +\\infty)\n      labels: [P] Tensor, binary ground truth labels (0 or 1)\n      ignore: label to ignore\n    \"\"\"\n    if len(labels) == 0:\n        # only void pixels, the gradients should be 0\n        return logits.sum() * 0.\n    signs = 2. * labels.float() - 1.\n    errors = (1. - logits * Variable(signs))\n    errors_sorted, perm = torch.sort(errors, dim=0, descending=True)\n    perm = perm.data\n    gt_sorted = labels[perm]\n    grad = lovasz_grad(gt_sorted)\n    loss = torch.dot(F.elu(errors_sorted) +1, Variable(grad))\n    return loss\n\n\ndef flatten_binary_scores(scores, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch (binary case)\n    Remove labels equal to 'ignore'\n    \"\"\"\n    scores = scores.view(-1)\n    labels = labels.view(-1)\n    if ignore is None:\n        return scores, labels\n    valid = (labels != ignore)\n    vscores = scores[valid]\n    vlabels = labels[valid]\n    return vscores, vlabels\n\n\nclass StableBCELoss(torch.nn.modules.Module):\n    def __init__(self):\n         super(StableBCELoss, self).__init__()\n    def forward(self, input, target):\n         neg_abs = - input.abs()\n         loss = input.clamp(min=0) - input * target + (1 + neg_abs.exp()).log()\n         return loss.mean()\n\n\ndef binary_xloss(logits, labels, ignore=None):\n    \"\"\"\n    Binary Cross entropy loss\n      logits: [B, H, W] Variable, logits at each pixel (between -\\infty and +\\infty)\n      labels: [B, H, W] Tensor, binary ground truth masks (0 or 1)\n      ignore: void class id\n    \"\"\"\n    logits, labels = flatten_binary_scores(logits, labels, ignore)\n    loss = StableBCELoss()(logits, Variable(labels.float()))\n    return loss\n\n\n# --------------------------- MULTICLASS LOSSES ---------------------------\n\n\ndef lovasz_softmax(probas, labels, only_present=False, per_image=False, ignore=None):\n    \"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [B, C, H, W] Variable, class probabilities at each prediction (between 0 and 1)\n      labels: [B, H, W] Tensor, ground truth labels (between 0 and C - 1)\n      only_present: average only on classes present in ground truth\n      per_image: compute the loss per image instead of per batch\n      ignore: void class labels\n    \"\"\"\n    if per_image:\n        loss = mean(lovasz_softmax_flat(*flatten_probas(prob.unsqueeze(0), lab.unsqueeze(0), ignore), only_present=only_present)\n                          for prob, lab in zip(probas, labels))\n    else:\n        loss = lovasz_softmax_flat(*flatten_probas(probas, labels, ignore), only_present=only_present)\n    return loss\n\n\ndef lovasz_softmax_flat(probas, labels, only_present=False):\n    \"\"\"\n    Multi-class Lovasz-Softmax loss\n      probas: [P, C] Variable, class probabilities at each prediction (between 0 and 1)\n      labels: [P] Tensor, ground truth labels (between 0 and C - 1)\n      only_present: average only on classes present in ground truth\n    \"\"\"\n    C = probas.size(1)\n    losses = []\n    for c in range(C):\n        fg = (labels == c).float() # foreground for class c\n        if only_present and fg.sum() == 0:\n            continue\n        errors = (Variable(fg) - probas[:, c]).abs()\n        errors_sorted, perm = torch.sort(errors, 0, descending=True)\n        perm = perm.data\n        fg_sorted = fg[perm]\n        losses.append(torch.dot(errors_sorted, Variable(lovasz_grad(fg_sorted))))\n    return mean(losses)\n\n\ndef flatten_probas(probas, labels, ignore=None):\n    \"\"\"\n    Flattens predictions in the batch\n    \"\"\"\n    B, C, H, W = probas.size()\n    probas = probas.permute(0, 2, 3, 1).contiguous().view(-1, C)  # B * H * W, C = P, C\n    labels = labels.view(-1)\n    if ignore is None:\n        return probas, labels\n    valid = (labels != ignore)\n    vprobas = probas[valid.nonzero().squeeze()]\n    vlabels = labels[valid]\n    return vprobas, vlabels\n\ndef xloss(logits, labels, ignore=None):\n    \"\"\"\n    Cross entropy loss\n    \"\"\"\n    return F.cross_entropy(logits, Variable(labels), ignore_index=255)\n\n\n# --------------------------- HELPER FUNCTIONS ---------------------------\n\ndef mean(l, ignore_nan=False, empty=0):\n    \"\"\"\n    nanmean compatible with generators.\n    \"\"\"\n    l = iter(l)\n    if ignore_nan:\n        l = ifilterfalse(np.isnan, l)\n    try:\n        n = 1\n        acc = next(l)\n    except StopIteration:\n        if empty == 'raise':\n            raise ValueError('Empty mean')\n        return empty\n    for n, v in enumerate(l, 2):\n        acc += v\n    if n == 1:\n        return acc\n    return acc \/ n","57803dbc":"from fastai.conv_learner import *\nfrom fastai.dataset import *\nimport matplotlib.pyplot as plt\nfrom concurrent.futures import ThreadPoolExecutor\nfrom PIL import Image\nimport os\n\nfrom pathlib import Path\nimport json\ntorch.cuda.set_device(0)","05194f35":"MASKS_FN = 'train.csv'\nTRAIN_DN = Path('train\/images\/')\nMASKS_DN = Path('train\/masks\/')\nTEST = Path('test\/images\/')\n\nPATH = Path('\/kaggle\/input\/tgs-salt-identification-challenge\/')\nPATH128 = Path('\/tmp\/128\/')\nTMP = Path('\/tmp\/')\nMODEL = Path('\/tmp\/model\/')\nPRETRAINED = Path('\/kaggle\/input\/fork-of-is-there-salt-resnet34\/model\/resnet34_issalt.h5')\nseg = pd.read_csv(PATH\/MASKS_FN).set_index('id')\nseg.head()\n\nsz = 128\nbs = 64\nnw = 4","78d2b0f5":"ls \/kaggle\/input\/is-there-salt-resnet34\/models\/res","7449223e":"train_names_png = [TRAIN_DN\/f for f in os.listdir(PATH\/TRAIN_DN)]\ntrain_names = list(seg.index.values)\nmasks_names_png = [MASKS_DN\/f for f in os.listdir(PATH\/MASKS_DN)]\ntest_names_png = [TEST\/f for f in os.listdir(PATH\/TEST)]","49dd459c":"train_names_png[0], masks_names_png[0], test_names_png[0]","ea99fd6f":"TMP.mkdir(exist_ok=True)\nPATH128.mkdir(exist_ok=True)\n(PATH128\/'train').mkdir(exist_ok=True)\n(PATH128\/'test').mkdir(exist_ok=True)\n(PATH128\/MASKS_DN).mkdir(exist_ok=True)\n(PATH128\/TRAIN_DN).mkdir(exist_ok=True)\n(PATH128\/TEST).mkdir(exist_ok=True)","9a20b94c":"def resize_mask(fn, sz=128):\n    Image.open(PATH\/fn).resize((sz,sz)).save(PATH128\/fn)","78e6181c":"with ThreadPoolExecutor(4) as e: e.map(resize_mask, train_names_png)","f3aee49a":"with ThreadPoolExecutor(4) as e: e.map(resize_mask, masks_names_png)","f43bd948":"with ThreadPoolExecutor(4) as e: e.map(resize_mask, test_names_png)","7d11e0d7":"def show_img(im, figsize=None, ax=None, alpha=None):\n    if not ax: fig,ax = plt.subplots(figsize=figsize)\n    ax.imshow(im, alpha=alpha)\n    ax.set_axis_off()\n    return ax","955f4b80":"show_img(open_image(str(PATH128\/train_names_png[0])))","9d2058b8":"class CustomDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        assert(len(fnames)==len(y))\n        super().__init__(fnames, transform, path)\n        \n    def get_x(self, i): \n        return open_image(os.path.join(self.path,self.fnames[i]))\n    def get_y(self, i): \n        return open_image(os.path.join(self.path,self.y[i]))\n    def get_c(self): return 0","b6a9c7ca":"class TestFilesDataset(FilesDataset):\n    def __init__(self, fnames, y, transform, path):\n        self.y=y\n        self.th = 1\n        super().__init__(fnames, transform, path)        \n    def get_x(self, i): \n        return np.fliplr(open_image(os.path.join(self.path, self.fnames[i])))\n    def get_y(self, i): \n        return np.fliplr(open_image(os.path.join(self.path,self.y[i])))\n    def get_c(self): return 0","b1ba9d3d":"def IoU_np(pred, targs, thres=0):\n    pred = (pred>thres)\n    intersection = (pred*targs).sum()\n    return intersection \/ ((pred+targs).sum() - intersection + 1.0)\n\ndef IoU(pred, targs, thres=0):\n    pred = (pred>thres).float()\n    intersection = (pred*targs).sum()\n    return intersection \/ ((pred+targs).sum() - intersection + 1.0)","fba58542":"def get_base(f, cut):\n    layers = cut_model(f(True), cut)\n    return nn.Sequential(*layers)\n\ndef load_pretrained(model, path):\n    weights = torch.load(PRETRAINED, map_location=lambda storage, loc: storage)\n    model.load_state_dict(weights, strict=False)\n            \n    return model","9f850b31":"class SaveFeatures():\n    features=None\n    def __init__(self, m): self.hook = m.register_forward_hook(self.hook_fn)\n    def hook_fn(self, module, input, output): self.features = output\n    def remove(self): self.hook.remove()","cb0134db":"class UnetBlock(nn.Module):\n    def __init__(self, up_in, x_in, n_out):\n        super().__init__()\n        up_out = x_out = n_out\/\/2\n        self.x_conv  = nn.Conv2d(x_in,  x_out,  1)\n        self.tr_conv = nn.ConvTranspose2d(up_in, up_out, 2, stride=2)\n        self.bn = nn.BatchNorm2d(n_out)\n        \n    def forward(self, up_p, x_p):\n        up_p = self.tr_conv(up_p)\n        x_p = self.x_conv(x_p)\n        cat_p = torch.cat([up_p,x_p], dim=1)\n        return self.bn(F.relu(cat_p))","d091f243":"class Unet34(nn.Module):\n    def __init__(self, rn):\n        super().__init__()\n        self.rn = rn\n        self.sfs = [SaveFeatures(rn[i]) for i in [2,4,5,6]]\n        self.up1 = UnetBlock(512,256,256)\n        self.up2 = UnetBlock(256,128,256)\n        self.up3 = UnetBlock(256,64,256)\n        self.up4 = UnetBlock(256,64,256)\n#         self.conv1 = nn.Conv2d(512, 256, kernel_size=3, bias=False, stride=1, padding=1)\n#         self.bn1 = nn.BatchNorm2d(256)\n#         self.conv2 = nn.Conv2d(256, 512, kernel_size=1, bias=False, stride=1, padding=0)\n#         self.bn2 = nn.BatchNorm2d(512)\n        self.cSE = nn.Sequential(nn.AdaptiveAvgPool2d(1),\n                             nn.Conv2d(512,256,1),\n                             nn.ReLU(inplace=True),\n                             nn.Conv2d(256, 512,1),\n                             nn.Sigmoid()\n                               )\n        self.sSE = nn.Sequential(nn.Conv2d(512,512,1),\n                             nn.Sigmoid())\n        \n        self.up5 = nn.ConvTranspose2d(256, 1, 2, stride=2)\n        \n    def forward(self,x):\n        x = F.dropout(F.relu(self.rn(x)),0.3)\n        x = torch.addcmul(x * self.cSE(x), 1, x, self.sSE(x))\n\n#         x = F.leaky_relu(self.bn2(self.conv2(x)))\n        \n        x1 = self.up1(x, self.sfs[3].features)\n        x2 = self.up2(x1, self.sfs[2].features)\n        x = self.up3(x2, self.sfs[1].features)\n        x = self.up4(x, self.sfs[0].features)\n        x = self.up5(x)\n        x = torch.cat((x,\n                       F.interpolate((x2),scale_factor=8,mode='bilinear',align_corners=True),\n                       F.interpolate((x1),scale_factor=16,mode='bilinear', align_corners=True)\n                      ),1)\n        return F.dropout(x[:,0],0.3)\n    \n    def close(self):\n        for sf in self.sfs: sf.remove()","66960a2f":"class UnetModel():\n    def __init__(self,model,name='unet'):\n        self.model,self.name = model,name\n\n    def get_layer_groups(self, precompute):\n        lgs = list(split_by_idxs(children(self.model.rn), [lr_cut]))\n        return lgs + [children(self.model)[1:]]","a25ee38c":"x_names = [f'{x}.png' for x in train_names]\nx_names_path = np.array([str(TRAIN_DN\/x) for x in x_names])\ny_names = [x for x in x_names]\ny_names_path = np.array([str(MASKS_DN\/x) for x in x_names])","042acea8":"class RandomRotate2(CoordTransform):\n    \"\"\" Rotates images and (optionally) target y.\n\n    Rotating coordinates is treated differently for x and y on this\n    transform.\n     Arguments:\n        deg (float): degree to rotate.\n        p (float): probability of rotation\n        mode: type of border\n        tfm_y (TfmType): type of y transform\n    \"\"\"\n    def __init__(self, deg, p=0.75, mode=cv2.BORDER_REFLECT, tfm_y=TfmType.NO):\n        super().__init__(tfm_y)\n        self.deg,self.p = deg,p\n        if tfm_y == TfmType.COORD or tfm_y == TfmType.CLASS:\n            self.modes = (mode,cv2.BORDER_CONSTANT)\n        else:\n            self.modes = (mode,mode)\n\n    def set_state(self):\n        self.store.rdeg = rand0(self.deg)\n        self.store.rp = random.random()<self.p\n\n    def do_transform(self, x, is_y):\n        if self.store.rp: x = rotate_cv(x, self.store.rdeg, \n                mode = self.modes[0],\n                interpolation=cv2.INTER_NEAREST if is_y else cv2.INTER_AREA)\n        return x","591aa0da":"aug_tfms = [RandomRotate2(4, tfm_y=TfmType.CLASS),\n            RandomFlip(tfm_y=TfmType.CLASS),\n            RandomStretch(0.2,tfm_y=TfmType.CLASS),\n            RandomLighting(0.05, 0.05, tfm_y=TfmType.CLASS)]\ntfms = tfms_from_model(resnet34, sz=sz, pad=0, crop_type=CropType.NO, tfm_y=TfmType.CLASS, aug_tfms=aug_tfms)\n\ndef get_data(val_idxs):\n    ((val_x,trn_x),(val_y,trn_y)) = split_by_idx(val_idxs, x_names_path, y_names_path)\n    datasets = ImageData.get_ds(CustomDataset, (trn_x,trn_y), (val_x,val_y), tfms, (test_x, test_x), path=PATH128)\n    return ImageData(PATH128, datasets, bs=32, num_workers=nw, classes=None)\n    ","977140f3":"f = resnet34\ncut,lr_cut = model_meta[f]\n\ndef get_learner(md):\n    m_base = load_pretrained(get_base(f, cut),PRETRAINED)\n    m = to_gpu(Unet34(m_base))\n    models = UnetModel(m)\n    learn = ConvLearner(md, models, tmp_name=TMP, models_name=MODEL)\n    learn.opt_fn=optim.Adam\n    learn.crit = nn.BCEWithLogitsLoss()\n    learn.metrics=[accuracy_thresh(0.5), IoU]\n    learn.clip = 0.25\n    return learn","fa35cfae":"n_folds = 5\nval_size = 4000\/\/n_folds\nactual_its = []\nlr=3e-3\nwd=1e-7\nlrs = np.array([lr\/100,lr\/10,lr\/3])\ntest_x = np.array(test_names_png)\n\nout=np.zeros((18000,sz,sz))\nalpha = 0","709a9e15":"for i in [0,1,2]:\n    #fold i\n    print(f'Fold{i}------------------------------------')\n    val_idxs=list(range(i*val_size, (i+1)*val_size))\n    md = get_data(val_idxs)\n    \n    #learner\n    learn = get_learner(md)\n    learn.freeze_to(1)\n    print(f'fit (lrs, wd): {lrs, wd}')\n    learn.fit(lrs, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9),best_save_name='best1')\n    print('unfreezing')\n    learn.unfreeze()\n#     learn.fit(lrs\/10, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9))\n    learn.load('best1')\n    learn.crit = lovasz_hinge\n    learn.fit(lrs\/10, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9),best_save_name='best2')\n    learn.load('best2')\n    print(f'computing test set: {i}')\n    p = learn.predict(is_test=True)\n    learn.save(f'{i}-model')\n    print('Computing optimal threshold')\n    preds, targs = learn.predict_with_targs()\n    IoUs=[]\n    for a in np.arange(0, 1, 0.1):\n        IoUs.append(IoU_np(preds, targs, a))\n    IoU_max = np.array(IoUs).argmax()\n    print(f'optimal Threshold: {IoU_max\/10.0}')\n    alpha+=IoU_max\/10.0\n    print('TTA')\n    md.test_dl.dataset = TestFilesDataset(test_x,test_x,tfms[1],PATH128)\n    p_f = learn.predict(is_test=True)\n    p_f = p_f[:,:,::-1]\n    out = (p+p_f)\/2\n    actual_its.append(i)","e49c1cb3":"print(f'Last Iteration group [0,1,2]: {i} ')","9649b381":"for i in [3,4]:\n    #fold i\n    print(f'Fold{i}------------------------------------')\n    val_idxs=list(range(i*val_size, (i+1)*val_size))\n    md = get_data(val_idxs)\n    \n    #learner\n    learn = get_learner(md)\n    learn.freeze_to(1)\n    print(f'fit (lrs, wd): {lrs, wd}')\n    learn.fit(lrs, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9),best_save_name='best1')\n    print('unfreezing')\n    learn.unfreeze()\n#     learn.fit(lrs\/10, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9))\n    learn.load('best1')\n    learn.crit = lovasz_hinge\n    learn.fit(lrs\/10, 1, wds=wd, cycle_len=20,use_clr_beta=(10,10, 0.85, 0.9),best_save_name='best2')\n    learn.load('best2')\n    print(f'computing test set: {i}')\n    p = learn.predict(is_test=True)\n    learn.save(f'{i}-model')\n    print('Computing optimal threshold')\n    preds, targs = learn.predict_with_targs()\n    IoUs=[]\n    for a in np.arange(0, 1, 0.1):\n        IoUs.append(IoU_np(preds, targs, a))\n    IoU_max = np.array(IoUs).argmax()\n    print(f'optimal Threshold: {IoU_max\/10.0}')\n    alpha+=IoU_max\/10.0\n    print('TTA')\n    md.test_dl.dataset = TestFilesDataset(test_x,test_x,tfms[1],PATH128)\n    p_f = learn.predict(is_test=True)\n    p_f = p_f[:,:,::-1]\n    out = (p+p_f)\/2\n    actual_its.append(i)","5a07835e":"print(f'Last Iteration group [3,4]: {i} ')","35fd75af":"print(actual_its)\nout = out\/n_folds\nalpha = alpha\/n_folds","fb4f2594":"fig, axes = plt.subplots(12, 6, figsize=(12, 40))\nfor i,ax in enumerate(axes.flat):\n    ax = show_img(Image.open(PATH128\/test_names_png[i+30]), ax=ax)\n    show_img(out[i+30]>alpha, ax=ax, alpha=0.2)\nplt.tight_layout(pad=0.1)","51efcedc":"def rle_encode(im):\n    '''\n    im: numpy array, 1 - mask, 0 - background\n    Returns run length as string formated\n    '''\n    pixels = im.flatten(order='F')\n    pixels = np.concatenate([[0], pixels, [0]])\n    runs = np.where(pixels[1:] != pixels[:-1])[0] + 1\n    runs[1::2] -= runs[::2]\n    return ' '.join(str(x) for x in runs)","8809cd81":"tmp_list = []\nname_list = []\nfor i in range(18000):\n    img = cv2.resize(out[i,:,:], dsize=(101,101), interpolation = cv2.INTER_CUBIC)\n    tmp_list.append(rle_encode(img>alpha))\n    name_list.append(test_names_png[i].name[0:-4])","9b62ee04":"sub = pd.DataFrame(list(zip(name_list, tmp_list)), columns = ['id', 'rle_mask'])","2d79a36b":"sub.to_csv('submission.csv', index=False)","8c3c1b85":"# UNET","b308138f":"Checking FastAI","d2a37dd7":"# Predict"}}