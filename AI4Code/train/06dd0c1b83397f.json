{"cell_type":{"333b2b99":"code","f5afc7ff":"code","08c89832":"code","4385578b":"code","b5daf69b":"code","c9d20613":"code","9bf2ff47":"code","17ce19d7":"code","36c527db":"code","bf229bc2":"code","7161e285":"code","a5c6c81e":"code","63012f38":"code","314043d8":"code","59215fce":"code","bde9f15c":"code","8ededccd":"code","11116195":"code","019e64a9":"code","3b22f758":"code","6d413d92":"code","c6d91944":"code","a169779b":"code","2aadddc2":"code","41d5dc34":"code","4d7321f8":"code","a6bf01f3":"code","504182ca":"code","0222042b":"code","b3c1c287":"code","d64aa6d4":"code","88a99350":"code","ae0f1e89":"code","67f8e972":"code","5b170df7":"code","36b4b4fe":"code","e3becf12":"code","51690469":"code","fbb56ac1":"code","50bafdc0":"code","be1eabde":"code","ed187bf0":"code","de117712":"code","fde267f9":"code","eee5b6dd":"code","7e7213a5":"code","9833b0a7":"code","5841ff17":"code","9a0f8c2c":"code","f6584d5f":"code","866806ae":"code","deb8d80a":"code","c3b2a88a":"code","778049ca":"code","b603e51a":"code","ca0392a3":"code","42f53e9c":"code","f1812718":"code","ad7b521c":"code","1339f12d":"code","b8ed665a":"code","e6d7f6b3":"code","4cdb7bc9":"code","b9a2ace5":"code","5feb8c95":"code","60a1fecd":"code","2fc94ec9":"code","c8239cd3":"code","bce91d7c":"code","3564334d":"code","b346e0d5":"code","3edd5c0b":"code","4cb25782":"code","e59b6783":"code","39001734":"code","5cedf243":"code","1862f384":"code","f1a3268e":"code","f324066c":"code","6239f9ce":"code","506555ba":"code","d69375c9":"code","156b51a5":"code","dd26ca59":"code","deda8c37":"code","c75120d5":"code","ef71152f":"code","b4cc27fb":"code","a4fdb8ee":"code","0e14e512":"code","36281f14":"code","7c6d4ed1":"code","a1325df4":"code","0fc0fee5":"code","318ed2ab":"code","4c568f44":"code","a91b6040":"code","0796c651":"code","ba198ab4":"code","80a4b305":"code","e928a197":"code","af31b931":"code","a581fcc6":"code","995764ff":"code","3c804a1b":"code","394e90e1":"code","8696d30a":"code","d469f801":"markdown","9900fde3":"markdown","a2faa0d9":"markdown","e8994a33":"markdown","78fb344e":"markdown","8ff8ab2a":"markdown","739e9d43":"markdown","1e7aeea0":"markdown","2855253c":"markdown","507a53ce":"markdown","0fe6e79e":"markdown","1efd180e":"markdown","6ee2d36b":"markdown","1f10e15a":"markdown","54622fbb":"markdown","3ee9d350":"markdown","6228c428":"markdown","426e58e3":"markdown","938e6279":"markdown","0ed16ac9":"markdown","81054c1d":"markdown","32a0eddf":"markdown","0e298231":"markdown","51d7bec2":"markdown","8d13ed19":"markdown","ba04c505":"markdown","3feb743c":"markdown","b1859c49":"markdown","fad469d5":"markdown","a2ff1ce0":"markdown","6a02d370":"markdown","343b3a81":"markdown","bb1559ed":"markdown","8f84a0c7":"markdown","9d1a8d8f":"markdown","2af15535":"markdown","11d62590":"markdown","bafcaa55":"markdown","ef9e9d03":"markdown","d75e6cc6":"markdown"},"source":{"333b2b99":"!pip install chart_studio","f5afc7ff":"import csv\nimport pprint\n\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport matplotlib as ml\nimport seaborn as sns\nimport plotly\nimport chart_studio.plotly as py\nimport warnings\nfrom scipy import stats","08c89832":"\ndata = list(csv.DictReader(open(\"..\/input\/suicide-rates-overview-1985-to-2016\/master.csv\")))\ndata2 =  pd.read_csv(\"..\/input\/suicide-rates-overview-1985-to-2016\/master.csv\", thousands=r',')\n#data2 =  pd.read_csv(\"suicide-rates-overview-1985-to-2016\\master.csv\")","4385578b":"#printing data description\nprint(data2.describe())","b5daf69b":"data2.head()","c9d20613":"#Seems like HDI for year from above has quite some Null values\n#Hence replacing the null values with 0\ndata2[\"HDI for year\"].replace(np.nan,0, inplace=True)","9bf2ff47":"\n#print(data2.head())\ndata2.columns = [c.replace('$', '').replace('(', '').replace(')', '').strip().replace(' ', '_').replace('\/','_') for c in data2.columns]\nprint(data2.describe())","17ce19d7":"import matplotlib.pyplot as plt\n\ndata2.groupby(['country']).suicides_no.mean().nlargest(10).plot(kind='barh')\nplt.xlabel('Average Suicides_no', size=20)\nplt.ylabel('Country', fontsize=20);\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n\n\ndata2.groupby(['country']).suicides_no.sum().nlargest(10).plot(kind='barh')\nplt.xlabel('Total Suicides_no', size=20)\nplt.ylabel('Country', fontsize=20);\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n\n\ndata2.groupby(['country']).suicides_100k_pop.sum().nlargest(10).plot(kind='barh')\nplt.title('Top 10 country of suicide per 100k from 1987-2016')\nplt.xlabel('Total Suicides per 100k', size=20)\nplt.ylabel('Country', fontsize=20);\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","36c527db":"data2.columns = [c.replace('$', '').replace('(', '').replace(')', '').strip().replace(' ', '_').replace('\/','_') for c in data2.columns]\n","bf229bc2":"#Print all countries\ncountries = data2.country.unique()","7161e285":"year = data2.groupby('year').year.unique()\n\n\n\ntotalpyear = pd.DataFrame(data2.groupby('year').suicides_no.sum())\n\nplt.plot(year.index[0:31], totalpyear[0:31])\nplt.xlabel('year', fontsize=14)\nplt.ylabel('Total number of suicides in the world', fontsize=14)","a5c6c81e":"year = data2.groupby('year').year.unique()\n\n\n\ntotalpyear = pd.DataFrame(data2.groupby('year').suicides_100k_pop.sum())\n#plt.figure(9)\nplt.plot(year.index, totalpyear)\nplt.xlabel('year')\nplt.ylabel('Total number of suicides per 100k in the world')\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","63012f38":"labels = 'Male', 'Female'\nvalues = [np.sum(data2[data2.sex.eq(\"male\")].suicides_no), np.sum(data2[data2.sex.eq(\"female\")].suicides_no)]\nfig1, ax1 = plt.subplots()\nax1.pie(values,  labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title('Distribution of suicides by Gender')\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","314043d8":"labels = '5-14 years', '15-24 years','25-34 years','35-54 years','55-74 years','75+ years'\nvalues =[]\nfor eachlab in labels:\n    values.append(np.sum(data2[data2.age.eq(eachlab)].suicides_no))\n\nfig1, ax1 = plt.subplots()\nax1.pie(values,  labels=labels, autopct='%1.1f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')\nplt.title('Distribution of suicides by Age')\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","59215fce":"countries = data2['country'].unique()\n\ndata2.columns = [c.replace('$', '').replace('(', '').replace(')', '').strip().replace(' ', '_') for c in data2.columns]\n\n\n        #print(data2[data2.country.eq(eachcon)].population)\n\nfrom matplotlib.pyplot import figure\n\ndef getvalofcountries(data, column_key):\n    print(column_key)\n    values = []\n    for eachcon in countries:\n        if column_key == 'population':\n            values.append(np.sum(data2[data2.country.eq(eachcon)].population))\n        elif column_key == 'HDI_for_year':\n            values.append(float(data2[data2.country.eq(eachcon)].HDI_for_year.iloc[0]))\n        elif column_key == 'gdp_for_year':\n            values.append(float(data2[data2.country.eq(eachcon)].gdp_for_year.iloc[0]))\n\n    df = pd.DataFrame(values, index = countries,columns =['values'])\n    df = df[(df.values != 0)] # remove empty values\n    df.plot(kind='barh',figsize=(6,20))\n    plt.xlabel('Values', size=20)\n    plt.ylabel('Country', fontsize=20)\n    plt.title(\"Country vs \"+column_key)\n    #plt.show()\n    figure(figsize=(200,10))\n    plt.show()\n    plt.clf()\n    plt.cla()\n    plt.close()\n    \n\ngetvalofcountries(data2,'population')\n\n","bde9f15c":"getvalofcountries(data2,'HDI_for_year')","8ededccd":"getvalofcountries(data2,'gdp_for_year')","11116195":"#Total suicide number by year\ngsdtt=pd.DataFrame(data2.groupby(['age','year'])['suicides_100k_pop'].sum().unstack())\ngsdtt = gsdtt.fillna(0)\ngsdtt\n\n\nTgsdtt = gsdtt.T\nTgsdtt.iloc[:,:].plot(kind='bar',stacked = True, figsize=(10,6))\nplt.legend(bbox_to_anchor=(1,1), title = 'Age group')\nplt.title('Suicide number by year')\nplt.xlabel('Year')\nplt.ylabel('Suicide number')\nwarnings.filterwarnings('ignore')\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","019e64a9":"#Group data by age gender of each year\ngsd=pd.DataFrame(data2.groupby(['age','sex','year'])['suicides_no'].sum().unstack())\ngsd = gsd.fillna(0)\ngsd\n\n#male\ngsdm = pd.DataFrame(gsd.iloc[[1,3,5,7,9,11],:])\ngsdm\n\n#female\ngsdf = pd.DataFrame(gsd.iloc[[0,2,4,6,8,10],:])\ngsdf","3b22f758":"#Suicide population for male\nfor i in range(1985,2016):\n    gsdm.loc[:,i].plot(kind='bar', color = ('skyblue'))\n    plt.xticks(range(6),['15-24 years','25-34 years', '35-54 years', '5-14 years', '55-74 years', '75+ years'],\n               rotation = 60)\n    plt.xlabel('Age group')\n    plt.ylabel('Suicide number')\n    plt.title('Suicide population of male in '+ str(i))\n    \n    plt.show()\n    plt.clf()\n    plt.cla()\n    plt.close()","6d413d92":"\n\n#Suicide population for female\nfor i in range(1985,2016):\n    gsdf.loc[:,i].plot(kind='bar', color = ('lightpink'))\n    plt.xticks(range(6),['15-24 years','25-34 years', '35-54 years', '5-14 years', '55-74 years', '75+ years'],rotation = 60)\n    plt.xlabel('Age group')\n    plt.ylabel('Suicide number')\n    plt.title('Suicide population of female in'+ str(i))\n    \n    plt.show()\n    plt.clf()\n    plt.cla()\n    plt.close()\n\n","c6d91944":"#Total number by age group\ngsd02=pd.DataFrame(data2.groupby(['age','sex'])['suicides_no'].sum().unstack())\ngsd02\ngsd02_02 = pd.DataFrame(gsd02.T.sum())\ngsd02_02","a169779b":"#Pie chart by age group\n\nage=['05-14 years','15-24 years','25-34 years','35-54 years','55-74 years','75+ years']\nplt.pie(gsd02_02,\n               labels = age,\n               autopct = '%.1f%%',\n               startangle =0,\n               radius = 1.5,\n               frame = 0,\n               center = (4.5,4.5),\n               explode=(0.2,0.1,0,0,0,0),\n               shadow=True\n               )\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n","2aadddc2":"#Total by gender\nsexsum = gsd02\nsexsum = pd.DataFrame(sexsum.sum())\nsexsum = sexsum.reset_index()\nsexsum","41d5dc34":"#Compare the suicide number of male and female\ngsd02.iloc[:,1].plot(kind='bar', color='skyblue', width = 1, figsize=(8,5))\ngsd02.iloc[:,0].plot(kind='bar', color='lightpink', width = 1, alpha = 0.8,figsize=(8,5))\nplt.ylabel('Suicide number')\nplt.xlabel('Age group')\nplt.xticks(rotation = 60)\nplt.title('Suicide number')\nplt.legend(['Male','Female'], bbox_to_anchor=(1, 1),title = 'Sex')\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","4d7321f8":"#Total number by age group\ngsd03=pd.DataFrame(data2.groupby(['age','sex'])['suicides_100k_pop'].sum().unstack())\ngsd03\ngsd03_02 = pd.DataFrame(gsd03.T.sum())\ngsd03_02\n\n#Compare the suicide number of male and female\ngsd03.iloc[:,1].plot(kind='bar', color='skyblue', width = 1, figsize=(8,5))\ngsd03.iloc[:,0].plot(kind='bar', color='lightpink', width = 1, alpha = 0.8,figsize=(8,5))\nplt.ylabel('Suicide count 100k pop')\nplt.xlabel('Age group')\nplt.xticks(rotation = 60)\nplt.title('Suicide number')\nplt.legend(['Male','Female'], bbox_to_anchor=(1, 1),title = 'Sex')\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","a6bf01f3":"#Plot by year (line)\ngsd_year=pd.DataFrame(data2.groupby(['year','country'])['suicides_no'].sum().unstack())\ngsd_year = gsd_year.fillna(0)\ngsd_year['Suicide number'] = gsd_year.sum(axis=1)\n\ngsd_year.loc[:,'Suicide number'].plot(kind='line',figsize=(10,6),marker='o')\nplt.title('Suicide number from 1985 to 2016')\nplt.xlabel('year')\nplt.ylabel('suicide number')\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","504182ca":"\n\n#Group data by country (absolute)\ngsdcountry= (pd.DataFrame(data2.groupby(['country','sex'])['suicides_no'].sum().unstack()))\/1000000\ngsdcountry['Suicide number']=gsdcountry.apply(lambda gsdcountry: gsdcountry['female']+gsdcountry['male'], axis = 1)\ngsdcountry = gsdcountry.sort_values(by='Suicide number',ascending=False)\ngsdcountry.head(10)\n\ngsdcountry.iloc[0:10,2].plot(kind='barh')\nplt.ylabel('Country')\nplt.xlabel('Suicide number (million)')\nplt.title('Top 10 country of suicide from 1987-2016')\n\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n","0222042b":"#Original suicide number data\ngsdcountrynormal = gsdcountry*1000000\ngsdcountrynormal = pd.DataFrame(gsdcountrynormal['Suicide number'])\ngsdcountrynormal = gsdcountrynormal.reset_index()\ngsdcountrynormal","b3c1c287":"py.sign_in('hbin7552', 'kI7QRK2ZvMwh5vSJP9az')\nprint(plotly.__version__)","d64aa6d4":"#Draw a choropleth map of world to show the suicide numnber by country\nplotly.offline.init_notebook_mode()\n\n#data to graph\nmy_data = [dict(type='choropleth', \n        autocolorscale=True,\n        locations=gsdcountrynormal['country'],\n        z=gsdcountrynormal['Suicide number'].astype(float),\n        locationmode='country names',\n        text=gsdcountrynormal['country'],\n        hoverinfo='location+z',\n        marker=dict(line=dict(color='rgb(180,180,180)',width=0.5)),\n        colorbar=dict(title='Suicide number'))]\n\n#layout\nmy_layout = dict(title='Suicide number',\n                 geo=dict(scope='world',\n                          projection=dict(type='mercator'),\n                          showcoastlines= False,\n                          showframe= False))\n\nfig = dict(data=my_data, layout=my_layout)\npy.iplot(fig, validata=False, filename='Suicide number')\n\n","88a99350":"\n\n#Group data by country (per 100k)\ngsdcountryper= pd.DataFrame(data2.groupby(['country','sex'])['suicides_100k_pop'].sum().unstack())\ngsdcountryper['Suicide number']=gsdcountryper.apply(lambda gsdcountryper: gsdcountryper['female']\n                                                    +gsdcountryper['male'], axis = 1)\ngsdcountryper = gsdcountryper.sort_values(by='Suicide number',ascending=False)\ngsdcountryper.head(10)\n\ngsdcountryper.iloc[0:10,2].plot(kind='barh')\nplt.ylabel('Country')\nplt.xlabel('Suicide population (per 100k)')\nplt.title('Top 10 country of suicide from 1987-2016')\n\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n","ae0f1e89":"\n\n#Top ten suicide country by percentage\ngsdcountry10 = pd.DataFrame(gsdcountry.iloc[0:10,2])\n\ntop10country = [\"Russian Federation\",\"Unites States\",\"Japan\",\"France\",\"Ukraine\",\"Germany\",\"Republic of Korea\",\"Brazil\",\"Poland\",\"United Kingdom\"]\n\nplt.pie(gsdcountry10,\n               labels = top10country,\n               autopct = '%.1f%%',\n               startangle =0,\n               radius = 1.5,\n               frame = 0,\n               center = (4.5,4.5),\n               explode=(0.2,0,0,0,0,0,0,0,0,0)\n               )\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n","67f8e972":"\n        #print(data2[data2.country.eq(eachcon)].population)\nyears = data2['year'].unique()\n\nvalues2 = []\n\ngdp_df = pd.DataFrame(columns=['country','gdp','gdp_per_capita'])\ngdp_df = gdp_df.fillna(0)\n\n\nfor eachcon in countries:\n    #print(\"--------------------------\")\n    #print(eachcon)\n    gdp_for_country = 0\n    gdp_for_every_year = []\n    gdp_per_capita_every_year = []\n    for eachyear in years:\n                    #print(eachyear)\n                    try:\n                        gdp_for_country +=float(data2[data2.country.eq(eachcon) & data2.year.eq(eachyear)].gdp_for_year.iloc[0])\n                        gdp_for_every_year.append(float(data2[data2.country.eq(eachcon) & data2.year.eq(eachyear)].gdp_for_year.iloc[0]))\n                        #print(float(data2[data2.country.eq(eachcon) & data2.year.eq(eachyear)].gdp_per_capita.iloc[0]))\n                        gdp_per_capita_every_year.append(float(data2[data2.country.eq(eachcon) & data2.year.eq(eachyear)].gdp_per_capita.iloc[0]))\n                    except Exception as e:\n                        #print(e)\n                        print(\"Info : GDP for\",eachcon,eachyear,\"not found\")\n    #print(gdp_for_country)\n    gdp_df = gdp_df.append({'country' : eachcon , 'gdp' : np.average(gdp_for_every_year),'gdp_per_capita':np.average(gdp_per_capita_every_year)} , ignore_index=True)","5b170df7":"gdp_df.head()","36b4b4fe":"gsdcountry","e3becf12":"#print(list(data2.groupby(['country']).suicides_100k_pop.sum().to_frame().suicides_100k_pop))\ngdp_df['suicides_100k_pop'] = list(data2.groupby(['country']).suicides_100k_pop.sum().to_frame().suicides_100k_pop)\ngdp_df['suicides_no'] = list(data2.groupby(['country']).suicides_no.sum().to_frame().suicides_no)\n\nlen(gdp_df)","51690469":"print(gdp_df.head())","fbb56ac1":"#The correlation between perGDP vs suicide number\nsns.lmplot(x = \"gdp\",y = \"suicides_100k_pop\",\n                 data = gdp_df)\n\ng = sns.JointGrid(x = \"gdp\",y = \"suicides_100k_pop\",\n                 data = gdp_df)\ng = g.plot_joint(plt.scatter,\n               color=\"g\",s=40,edgecolor=\"white\")\ng=g.plot_marginals(sns.distplot, kde=False, color=\"g\")\nrsquare = lambda a,b: stats.pearsonr(a,b)[0]**2\ng = g.annotate(rsquare, template=\"{stat}:{val:.2f}\",\n              stat=\"$R^2$\",loc= \"upper right\", fontsize=12)","50bafdc0":"#The correlation between perGDP vs suicide number\nsns.lmplot(x = \"gdp_per_capita\",y = \"suicides_100k_pop\",\n                 data = gdp_df)\n\ng = sns.JointGrid(x = \"gdp_per_capita\",y = \"suicides_100k_pop\",\n                 data = gdp_df)\ng = g.plot_joint(plt.scatter,\n               color=\"g\",s=40,edgecolor=\"white\")\ng=g.plot_marginals(sns.distplot, kde=False, color=\"g\")\nrsquare = lambda a,b: stats.pearsonr(a,b)[0]**2\ng = g.annotate(rsquare, template=\"{stat}:{val:.2f}\",\n              stat=\"$R^2$\",loc= \"upper right\", fontsize=12)","be1eabde":"#The correlation between perGDP vs suicide number\nsns.lmplot(x = \"gdp_per_capita\",y = \"suicides_no\",\n                 data = gdp_df)\n\ng = sns.JointGrid(x = \"gdp_per_capita\",y = \"suicides_no\",\n                 data = gdp_df)\ng = g.plot_joint(plt.scatter,\n               color=\"g\",s=40,edgecolor=\"white\")\ng=g.plot_marginals(sns.distplot, kde=False, color=\"g\")\nrsquare = lambda a,b: stats.pearsonr(a,b)[0]**2\ng = g.annotate(rsquare, template=\"{stat}:{val:.2f}\",\n              stat=\"$R^2$\",loc= \"upper right\", fontsize=12)","ed187bf0":"#The correlation between perGDP vs suicide number\nsns.lmplot(x = \"gdp\",y = \"suicides_no\",\n                 data = gdp_df)\n\ng = sns.JointGrid(x = \"gdp\",y = \"suicides_no\",\n                 data = gdp_df)\ng = g.plot_joint(plt.scatter,\n               color=\"g\",s=40,edgecolor=\"white\")\ng=g.plot_marginals(sns.distplot, kde=False, color=\"g\")\nrsquare = lambda a,b: stats.pearsonr(a,b)[0]**2\ng = g.annotate(rsquare, template=\"{stat}:{val:.2f}\",\n              stat=\"$R^2$\",loc= \"upper right\", fontsize=12)","de117712":"\n        #print(data2[data2.country.eq(eachcon)].population)\nyears = data2['year'].unique()\n\n\n\nhdi_df = pd.DataFrame(columns=['country','HDI'])\nhdi_df = hdi_df.fillna(0)\n\n\nfor eachcon in countries:\n    #print(\"--------------------------\")\n    #print(eachcon)\n    hdi_for_year = []\n    for eachyear in years:\n                    #print(eachyear)\n                    try:\n                        temphd = float(data2[data2.country.eq(eachcon) & data2.year.eq(eachyear)].HDI_for_year.iloc[0])\n                        if temphd != 0:\n                            hdi_for_year.append(temphd)\n                    except Exception as e:\n                        #print(e)\n                        print(\"Info : HDI for\",eachcon,eachyear,\"not found\")\n    #print(gdp_for_country)\n    hdi_df = hdi_df.append({'country' : eachcon , 'HDI' : np.average(hdi_for_year)} , ignore_index=True)","fde267f9":"#print(list(data2.groupby(['country']).suicides_100k_pop.sum().to_frame().suicides_100k_pop))\nhdi_df['suicides_100k_pop'] = list(data2.groupby(['country']).suicides_100k_pop.sum().to_frame().suicides_100k_pop)","eee5b6dd":"hdi_df.head()","7e7213a5":"\n\n#Draw a choropleth map of world to show the HDI by country\nplotly.offline.init_notebook_mode()\n\ncolorscale = [[0,\"#f7fbff\"], \n              [0.1,\"#ebf3fb\"], \n              [0.2,\"#deebf7\"], \n              [0.3,\"#d2e3f3\"], \n              [0.4,\"#c6dbef\"], \n              [0.45,\"#b3d2e9\"], \n              [0.5,\"#9ecae1\"],\n              [0.55,\"#85bcdb\"],\n              [0.6,\"#6baed6\"], \n              [0.65,\"#57a0ce\"], \n              [0.7,\"#4292c6\"],\n              [0.75,\"#3082be\"],\n              [0.8,\"#2171b5\"],\n              [0.85,\"#1361a9\"],\n              [0.9,\"#08519c\"],\n              [0.95,\"#0b4083\"],\n              [1.0,\"#08306b\"]]\n\n\n#data to graph\nmy_data01 = [dict(type='choropleth', \n        colorscale=colorscale,\n        locations=hdi_df['country'],\n        z=hdi_df['HDI'],\n        locationmode='country names',\n        text=gdp_df['country'],\n        hoverinfo='location+z',\n        marker=dict(line=dict(color='rgb(180,180,180)',width=0.5)),\n        colorbar=dict(title='HDI'))]\n\n#layout\nmy_layout01 = dict(title='HDI',\n                 geo=dict(scope='world',\n                          projection=dict(type='mercator'),\n                          showcoastlines= False,\n                          showframe= False))\n\nfig = dict(data=my_data01, layout=my_layout01)\npy.iplot(fig, validata=False, filename='HDI')\n\n","9833b0a7":"hdi_df2 = hdi_df.dropna()\nlen(hdi_df2)","5841ff17":"#The correlation between HDI vs suicide number\nsns.lmplot(x = \"HDI\",y = \"suicides_100k_pop\",\n                 data = hdi_df2)\n\ng = sns.JointGrid(x = \"HDI\",y = \"suicides_100k_pop\",\n                 data = hdi_df2)\ng = g.plot_joint(plt.scatter,\n               color=\"g\",s=40,edgecolor=\"white\")\ng=g.plot_marginals(sns.distplot, kde=False, color=\"g\")\nrsquare = lambda a,b: stats.pearsonr(a,b)[0]**2\ng = g.annotate(rsquare, template=\"{stat}:{val:.2f}\",\n              stat=\"$R^2$\",loc= \"upper right\", fontsize=12)","9a0f8c2c":"gdp_n_HDI = gdp_df\n\n#print(list(data2.groupby(['country']).suicides_100k_pop.sum().to_frame().suicides_100k_pop))\ngdp_n_HDI['HDI'] = hdi_df['HDI']\ngdp_n_HDI.head()","f6584d5f":"#Correlation between 4 variables\ncorrelation= gdp_n_HDI.corr()\nplt.figure(figsize=(10,8))\nax = sns.heatmap(correlation, vmax=1, square=True, annot=True,fmt='.2f', \n                 cmap ='GnBu', cbar_kws={\"shrink\": .5}, robust=True)\nplt.title('Correlation between the features', fontsize=20)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n","866806ae":"\n\n#Correlation between 4 variables\npd.plotting.scatter_matrix(gdp_n_HDI, figsize=(8, 8))\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n","deb8d80a":"\n\nsuic_sum_m = data2['suicides_no'].groupby([data2['country'],data2['sex']]).sum()\nsuic_sum_m = suic_sum_m.reset_index().sort_index(ascending=False)\nmost_cont_m = suic_sum_m.head(10)\nmost_cont_m.head(10)\nfig = plt.figure(figsize=(20,5))\nplt.title('Count of suicides for 31 years.')\nsns.set(font_scale=1.5)\nsns.barplot(y='suicides_no',x='country',hue='sex',data=most_cont_m,palette='Set2');\nplt.ylabel('Count of suicides')\nplt.tight_layout()\n\n","c3b2a88a":"\n\nsuic_sum_yr = pd.DataFrame(data2['suicides_no'].groupby(data2['year']).sum())\nsuic_sum_yr = suic_sum_yr.reset_index().sort_index(ascending=False)\nmost_cont_yr = suic_sum_yr\nfig = plt.figure(figsize=(30,10))\nplt.title('Count of suicides for years.')\nsns.set(font_scale=2.5)\nsns.barplot(y='suicides_no',x='year',data=most_cont_yr,palette=\"OrRd\");\nplt.ylabel('Count of suicides')\nplt.xlabel('')\nplt.xticks(rotation=45)\nplt.tight_layout()\n\n","778049ca":"\n\nsuic_sum_yr = pd.DataFrame(data2['suicides_no'].groupby([data2['generation'],data2['year']]).sum())\nsuic_sum_yr = suic_sum_yr.reset_index().sort_index(ascending=False)\nmost_cont_yr = suic_sum_yr\nfig = plt.figure(figsize=(30,10))\nplt.title('The distribution of suicides by age groups')\n\nsns.set(font_scale=2)\nsns.barplot(y='suicides_no',x='year',hue='generation',data=most_cont_yr,palette='deep');\nplt.ylabel('Count of suicides')\nplt.xticks(rotation=45)\nplt.tight_layout()\n","b603e51a":"year = data2.groupby('year').year.unique()\n\nmalesuicides = pd.DataFrame(data2[data2.sex == 'male'].groupby('year').suicides_100k_pop.sum())\nfemalesuicides = pd.DataFrame(data2[data2.sex == 'female'].groupby('year').suicides_100k_pop.sum())\nplt.figure(figsize=(16,8))\nplt.plot(year.index, malesuicides,label=\"Male suicides\")\nplt.plot(year.index, femalesuicides,label=\"Female suicides\")\nplt.xlabel('year', fontsize=18)\nplt.ylabel('Total number of suicides per 100k in the world', fontsize=18)\nplt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=18)\nplt.rc('ytick',labelsize=18)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n#print(data2[data2.sex == 'male'].groupby('year').suicides_100k_pop.sum())\n","ca0392a3":"agegroups = data2.age.unique()\nprint(agegroups)\n\nagegone_suicides = pd.DataFrame(data2[data2.age == '5-14 years'].groupby('year').suicides_100k_pop.sum())\nagegtwo_suicides = pd.DataFrame(data2[data2.age == '15-24 years'].groupby('year').suicides_100k_pop.sum())\nagegthr_suicides = pd.DataFrame(data2[data2.age == '25-34 years'].groupby('year').suicides_100k_pop.sum())\nagegfou_suicides = pd.DataFrame(data2[data2.age == '35-54 years'].groupby('year').suicides_100k_pop.sum())\nagegfiv_suicides = pd.DataFrame(data2[data2.age == '55-74 years'].groupby('year').suicides_100k_pop.sum())\nagegsix_suicides = pd.DataFrame(data2[data2.age == '75+ years'].groupby('year').suicides_100k_pop.sum())\n\n#print(agegone_suicides.suicides_100k_pop.columns)\n#print(year.index)\nplt.figure(figsize=(16,8))\nplt.plot( agegone_suicides,label='5-14 years')\nplt.plot(agegtwo_suicides,label='15-24 years')\nplt.plot(year.index, agegthr_suicides,label='25-34 years')\nplt.plot(year.index, agegfou_suicides,label='35-54 years')\nplt.plot(year.index, agegfiv_suicides,label='55-74 years')\nplt.plot(year.index, agegsix_suicides,label='75+ years')\nplt.xlabel('year', fontsize=18)\nplt.ylabel('Total number of suicides per 100k in the world', fontsize=18)\nplt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=18)\nplt.rc('ytick',labelsize=18)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n#print(data2[data2.sex == 'male'].groupby('year').suicides_100k_pop.sum())","42f53e9c":"import seaborn as seabornInstance \nfrom sklearn.model_selection import train_test_split \nfrom sklearn.linear_model import LinearRegression\nfrom sklearn import metrics\n%matplotlib inline","f1812718":"gdp_n_HDI = gdp_n_HDI.dropna()\nlen(gdp_n_HDI)","ad7b521c":"regressor = LinearRegression()  \nregressor.fit(gdp_n_HDI[['gdp','gdp_per_capita','HDI']], gdp_n_HDI[['suicides_100k_pop']])\n","1339f12d":"import statsmodels.api as sm\n\nX =gdp_n_HDI[['gdp','gdp_per_capita','HDI']] ## X usually means our input variables (or independent variables)\n\nX = sm.add_constant(X)\n# Note the difference in argument order\nmodel = sm.OLS(gdp_n_HDI[['suicides_100k_pop']],X).fit()\n#predictions = model.predict(X) # make the predictions by the model\n\n# Print out the statistics\nmodel.summary()","b8ed665a":"import statsmodels.api as sm\n\n# Note the difference in argument order\n\nX =gdp_n_HDI[['HDI']] ## X usually means our input variables (or independent variables)\n\nX = sm.add_constant(X)\n\n\nmodel = sm.OLS(gdp_n_HDI[['suicides_100k_pop']],X).fit()\n#predictions = model.predict(X) # make the predictions by the model\n\n# Print out the statistics\nmodel.summary()","e6d7f6b3":"plt.scatter(gdp_n_HDI.HDI, gdp_n_HDI[['suicides_100k_pop']])\nbeta = 4846.0429\nalpha = 0\nst_err =  362.311\n#plt.xlabel('Number of friends')\n#plt.ylabel('Average minutes per day on site')\nplt.plot(gdp_n_HDI.HDI,  alpha+ np.array(gdp_n_HDI.HDI)*beta, '-',color=\"red\",label=\"Regression line\")\ny1 = alpha+ np.array(gdp_n_HDI.HDI)*beta - 2*st_err\ny2 = alpha+ np.array(gdp_n_HDI.HDI)*beta + 2*st_err\nplt.fill_between(gdp_n_HDI.HDI, y1, y2, facecolor=(1,0,0,.4), edgecolor=(0,0,0,.5), label=\"95% confidence interval\")\nplt.plot(gdp_n_HDI.HDI,y1 , \"--\", color=\"0.5\", label=\"95% Prediction Limits\")\nplt.plot(gdp_n_HDI.HDI,y2, \"--\", color=\"0.5\")\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","4cdb7bc9":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy.interpolate import interp1d\nimport statsmodels.api as sm\n\n# introduce some floats in our x-values\n\nX =gdp_n_HDI.HDI\nY= gdp_n_HDI.suicides_100k_pop\n# lowess will return our \"smoothed\" data with a y value for at every x-value\nlowess = sm.nonparametric.lowess(Y, X, frac=.3)\n\n# unpack the lowess smoothed points to their values\nlowess_x = list(zip(*lowess))[0]\nlowess_y = list(zip(*lowess))[1]\n\n# run scipy's interpolation. There is also extrapolation I believe\nf = interp1d(lowess_x, lowess_y, bounds_error=False)\n\nxnew = [i\/10. for i in range(400)]\n\n# this this generate y values for our xvalues by our interpolator\n# it will MISS values outsite of the x window (less than 3, greater than 33)\n# There might be a better approach, but you can run a for loop\n#and if the value is out of the range, use f(min(lowess_x)) or f(max(lowess_x))\nynew = f(xnew)\n\n\nplt.plot(X, Y, 'o',label=\"Actual data\")\nplt.plot(lowess_x, lowess_y, '-',label=\"Local regression\")\n#plt.plot(xnew, ynew, '-')\nplt.xlabel('HDI', fontsize=18)\nplt.ylabel('suicides per 100k', fontsize=18)\nplt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=18)\nplt.rc('ytick',labelsize=18)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n\n","b9a2ace5":"gdp_n_HDI.head()","5feb8c95":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy.interpolate import interp1d\nimport statsmodels.api as sm\n\n# introduce some floats in our x-values\n\nX =gdp_n_HDI.gdp\nY= gdp_n_HDI.suicides_100k_pop\n# lowess will return our \"smoothed\" data with a y value for at every x-value\nlowess = sm.nonparametric.lowess(Y, X, frac=.3)\n\n# unpack the lowess smoothed points to their values\nlowess_x = list(zip(*lowess))[0]\nlowess_y = list(zip(*lowess))[1]\n\n# run scipy's interpolation. There is also extrapolation I believe\nf = interp1d(lowess_x, lowess_y, bounds_error=False)\n\nxnew = [i\/10. for i in range(400)]\n\n# this this generate y values for our xvalues by our interpolator\n# it will MISS values outsite of the x window (less than 3, greater than 33)\n# There might be a better approach, but you can run a for loop\n#and if the value is out of the range, use f(min(lowess_x)) or f(max(lowess_x))\nynew = f(xnew)\n\n\nplt.plot(X, Y, 'o',label=\"Actual data\")\nplt.plot(lowess_x, lowess_y, '-',label=\"Local regression\")\n#plt.plot(xnew, ynew, '-')\nplt.xlabel('gdp', fontsize=18)\nplt.ylabel('suicides per 100k', fontsize=18)\nplt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=18)\nplt.rc('ytick',labelsize=18)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n\n","60a1fecd":"import matplotlib.pyplot as plt\n%matplotlib inline\nfrom scipy.interpolate import interp1d\nimport statsmodels.api as sm\n\n# introduce some floats in our x-values\n\nX =gdp_n_HDI.gdp_per_capita\nY= gdp_n_HDI.suicides_100k_pop\n# lowess will return our \"smoothed\" data with a y value for at every x-value\nlowess = sm.nonparametric.lowess(Y, X, frac=.3)\n\n# unpack the lowess smoothed points to their values\nlowess_x = list(zip(*lowess))[0]\nlowess_y = list(zip(*lowess))[1]\n\n# run scipy's interpolation. There is also extrapolation I believe\nf = interp1d(lowess_x, lowess_y, bounds_error=False)\n\nxnew = [i\/10. for i in range(400)]\n\n# this this generate y values for our xvalues by our interpolator\n# it will MISS values outsite of the x window (less than 3, greater than 33)\n# There might be a better approach, but you can run a for loop\n#and if the value is out of the range, use f(min(lowess_x)) or f(max(lowess_x))\nynew = f(xnew)\n\n\nplt.plot(X, Y, 'o',label=\"Actual data\")\nplt.plot(lowess_x, lowess_y, '-',label=\"Local regression\")\n#plt.plot(xnew, ynew, '-')\nplt.xlabel('gdp_per_capita', fontsize=18)\nplt.ylabel('suicides per 100k', fontsize=18)\nplt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=18)\nplt.rc('ytick',labelsize=18)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n\n","2fc94ec9":"data3 = data2.drop(['country','country-year','generation','suicides_no'], axis = 1) \ndata3 = data3.drop(['HDI_for_year'], axis = 1) \n#data3 = data3.drop(['generation'], axis = 1) ","c8239cd3":"data3.head()","bce91d7c":"#Converting sex into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['sex'], prefix='sex',drop_first=True)],axis=1).drop(['sex'],axis=1)\ndata3.head()","3564334d":"#Converting age into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['age'], prefix='age',drop_first=True)],axis=1).drop(['age'],axis=1)\ndata3.head()","b346e0d5":"#Converting age into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['year'], prefix='year',drop_first=True)],axis=1).drop(['year'],axis=1)\ndata3.head()","3edd5c0b":"import statsmodels.api as sm\n#data3 = data3.drop(['gdp_for_year'], axis = 1)\nX =data3.drop(['suicides_100k_pop'], axis = 1)   \t ## X usually means our input variables (or independent variables)\n\nX = sm.add_constant(X)\n# Note the difference in argument order\nmodel = sm.OLS(data3.suicides_100k_pop,X).fit()\n#predictions = model.predict(X) # make the predictions by the model\n\n# Print out the statistics\nmodel.summary()","4cb25782":"data3 = data2.drop(['country','country-year','generation','suicides_no','year'], axis = 1) \ndata3 = data3.drop(['HDI_for_year'], axis = 1) \n#data3 = data3.drop(['generation'], axis = 1) \n\n#Converting sex into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['sex'], prefix='sex',drop_first=True)],axis=1).drop(['sex'],axis=1)\ndata3.head()\n\n#Converting age into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['age'], prefix='age',drop_first=True)],axis=1).drop(['age'],axis=1)\ndata3.head()\n\n\nimport statsmodels.api as sm\n#data3 = data3.drop(['gdp_for_year'], axis = 1)\nX =data3.drop(['suicides_100k_pop'], axis = 1)   \t ## X usually means our input variables (or independent variables)\n\nX = sm.add_constant(X)\n# Note the difference in argument order\nmodel = sm.OLS(data3.suicides_100k_pop,X).fit()\n#predictions = model.predict(X) # make the predictions by the model\n\n# Print out the statistics\nmodel.summary()","e59b6783":"data3 = data2.drop(['country','country-year','generation','suicides_no'], axis = 1) \n#data3 = data3.drop(['HDI_for_year'], axis = 1) \n#data3 = data3.drop(['generation'], axis = 1) \n\n#Converting sex into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['sex'], prefix='sex',drop_first=True)],axis=1).drop(['sex'],axis=1)\ndata3.head()\n\n#Converting age into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['age'], prefix='age',drop_first=True)],axis=1).drop(['age'],axis=1)\ndata3.head()\n\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['year'], prefix='year',drop_first=True)],axis=1).drop(['year'],axis=1)\ndata3.head()\n\ndata3 = data3.dropna()  #Remove empty HDI\n\nimport statsmodels.api as sm\n#data3 = data3.drop(['gdp_for_year'], axis = 1)\nX =data3.drop(['suicides_100k_pop'], axis = 1)   \t ## X usually means our input variables (or independent variables)\n\nX = sm.add_constant(X)\n# Note the difference in argument order\nmodel = sm.OLS(data3.suicides_100k_pop,X).fit()\n#predictions = model.predict(X) # make the predictions by the model\n\n# Print out the statistics\nmodel.summary()","39001734":"data3 = data2.drop(['country','country-year','generation','suicides_no','year'], axis = 1) \n#data3 = data3.drop(['HDI_for_year'], axis = 1) \n#data3 = data3.drop(['generation'], axis = 1) \n\n#Converting sex into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['sex'], prefix='sex',drop_first=True)],axis=1).drop(['sex'],axis=1)\ndata3.head()\n\n#Converting age into onehot encoding\n\ndata3 = pd.concat([data3,pd.get_dummies(data3['age'], prefix='age',drop_first=True)],axis=1).drop(['age'],axis=1)\ndata3.head()\n\n\n\n\ndata3 = data3.dropna()  #Remove empty HDI\n\nimport statsmodels.api as sm\n#data3 = data3.drop(['gdp_for_year'], axis = 1)\nX =data3.drop(['suicides_100k_pop'], axis = 1)   \t ## X usually means our input variables (or independent variables)\n\nX = sm.add_constant(X)\n# Note the difference in argument order\nmodel = sm.OLS(data3.suicides_100k_pop,X).fit()\n#predictions = model.predict(X) # make the predictions by the model\n\n# Print out the statistics\nmodel.summary()","5cedf243":"plt.hist(data2.suicides_100k_pop,bins=20)\nplt.title(\"Distribution of suicides_100k_pop\", fontsize=14)\nplt.xlabel('suicides_100k_pop', fontsize=16)\nplt.ylabel('Frequency', fontsize=16)\n#plt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=16)\nplt.rc('ytick',labelsize=16)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","1862f384":"# > 80 Z3\n#  40 - 79 Z2\n#  20 - 39 Z1\n# 0 - 19 Z0\ndata4 = data2\ndata4['suicides_class'] = pd.cut(x=data2['suicides_100k_pop'], bins=[-0.1,19, 39, 79, 500], labels=['Z0', 'Z1', 'Z2','Z3'])\n\nplt.hist(data4['suicides_class'])\nplt.title(\"Distribution of suicides_class\", fontsize=14)\nplt.xlabel('Suicide class', fontsize=16)\nplt.ylabel('Frequency', fontsize=16)\n#plt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=16)\nplt.rc('ytick',labelsize=16)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()\n\n","f1a3268e":"from sklearn.utils import resample\n\ndf_majority = data4[data4.suicides_class==\"Z0\"]\ndf_minority1 = data4[data4.suicides_class==\"Z1\"]\ndf_minority2 = data4[data4.suicides_class==\"Z2\"]\ndf_minority3 = data4[data4.suicides_class==\"Z3\"]\n \n# Upsample minority class\ndf_minority1_upsampled = resample(df_minority1, \n                                 replace=True,     # sample with replacement\n                                 n_samples=len(df_majority),    # to match majority class\n                                 random_state=123) # reproducible results\ndf_minority2_upsampled = resample(df_minority2, \n                                 replace=True,     # sample with replacement\n                                 n_samples=len(df_majority),    # to match majority class\n                                 random_state=123) # reproducible results\n \ndf_minority3_upsampled = resample(df_minority3, \n                                 replace=True,     # sample with replacement\n                                 n_samples=len(df_majority),    # to match majority class\n                                 random_state=123) # reproducible results\n \n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority1_upsampled, df_minority2_upsampled, df_minority3_upsampled])","f324066c":"plt.hist(df_upsampled['suicides_class'])\nplt.title(\"Distribution of suicides_class - balanced\", fontsize=14)\nplt.xlabel('Suicide class', fontsize=16)\nplt.ylabel('Frequency', fontsize=16)\n#plt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=16)\nplt.rc('ytick',labelsize=16)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","6239f9ce":"data4 = df_upsampled\ndata5 = data4.drop(['country','country-year','generation','suicides_no','suicides_100k_pop'], axis = 1) \n#data5 = df_upsampled.drop(['country','country-year','generation','suicides_no','suicides_100k_pop'], axis = 1) ","506555ba":"data5.head()\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['sex'], prefix='sex',drop_first=True)],axis=1).drop(['sex'],axis=1)\n\n\n#Converting age into onehot encoding\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['age'], prefix='age',drop_first=True)],axis=1).drop(['age'],axis=1)\n\n\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['year'], prefix='year',drop_first=True)],axis=1).drop(['year'],axis=1)\ndata5.head()\n\n#data3 = data3.dropna()  #Remove empty HDI","d69375c9":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data5.drop(['suicides_class'],axis=1), data5.suicides_class, test_size=0.25,random_state=5)","156b51a5":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\n\ncomplexities = []\ntrain_errors = []\ntest_errors = []\nfor n_estimators in [1,2,4,8,16,32,64]:\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=8)\n    #sample_size = len(y_train)\n    \n    clf.fit(X_train, y_train)\n    #train_error = 1-clf.score(X_train,y_train)#error(clf,X_train,y_train)\n    \n    \n    \n    #test_error =  1-clf.score(X_test,y_test)\n    #train_error = sum(train_errors)\/len(train_errors)\n    #test_error = sum(test_errors)\/len(test_errors)\n    complexities.append(n_estimators)\n    train_errors.append(f1_score(y_train, clf.predict(X_train), average='weighted'))\n    test_errors.append(f1_score(y_test, clf.predict(X_test), average='weighted'))\n    #print(clf.predict(X_test))\nplt.plot(complexities, train_errors, c='b', label='Training f1-score')\nplt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\nplt.ylim(0,1)\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('Random forest')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","dd26ca59":"data5 = data4.drop(['country','country-year','generation','suicides_no','suicides_100k_pop','year'], axis = 1) \n\ndata5.head()\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['sex'], prefix='sex',drop_first=True)],axis=1).drop(['sex'],axis=1)\n\n\n#Converting age into onehot encoding\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['age'], prefix='age',drop_first=True)],axis=1).drop(['age'],axis=1)\nprint(data5.head())\n\n#data3 = data3.dropna()  #Remove empty HDI\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data5.drop(['suicides_class'],axis=1), data5.suicides_class, test_size=0.25,random_state=5)\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\n\ncomplexities = []\ntrain_errors = []\ntest_errors = []\nfor n_estimators in [1,2,4,8,16,32,64]:\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=8)\n    #sample_size = len(y_train)\n    \n    clf.fit(X_train, y_train)\n    #train_error = 1-clf.score(X_train,y_train)#error(clf,X_train,y_train)\n    \n    \n    \n    #test_error =  1-clf.score(X_test,y_test)\n    #train_error = sum(train_errors)\/len(train_errors)\n    #test_error = sum(test_errors)\/len(test_errors)\n    complexities.append(n_estimators)\n    train_errors.append(f1_score(y_train, clf.predict(X_train), average='weighted'))\n    test_errors.append(f1_score(y_test, clf.predict(X_test), average='weighted'))\n    #print(clf.predict(X_test))\nplt.plot(complexities, train_errors, c='b', label='Training f1-score')\nplt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\nplt.ylim(0,1)\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('Random forest')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","deda8c37":"data5 = data4.drop(['country','country-year','generation','suicides_no','suicides_100k_pop','year','gdp_for_year'], axis = 1) \n\ndata5.head()\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['sex'], prefix='sex',drop_first=True)],axis=1).drop(['sex'],axis=1)\n\n\n#Converting age into onehot encoding\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['age'], prefix='age',drop_first=True)],axis=1).drop(['age'],axis=1)\ndata5.head()\n\n#data3 = data3.dropna()  #Remove empty HDI\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data5.drop(['suicides_class'],axis=1), data5.suicides_class, test_size=0.25,random_state=5)\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\n\ncomplexities = []\ntrain_errors = []\ntest_errors = []\nfor n_estimators in [1,2,4,8,16,32,64]:\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=8)\n    #sample_size = len(y_train)\n    \n    clf.fit(X_train, y_train)\n    #train_error = 1-clf.score(X_train,y_train)#error(clf,X_train,y_train)\n    \n    \n    \n    #test_error =  1-clf.score(X_test,y_test)\n    #train_error = sum(train_errors)\/len(train_errors)\n    #test_error = sum(test_errors)\/len(test_errors)\n    complexities.append(n_estimators)\n    train_errors.append(f1_score(y_train, clf.predict(X_train), average='weighted'))\n    test_errors.append(f1_score(y_test, clf.predict(X_test), average='weighted'))\n    #print(clf.predict(X_test))\nplt.plot(complexities, train_errors, c='b', label='Training f1-score')\nplt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\nplt.ylim(0,1)\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('Random forest')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","c75120d5":"data5 = data4.drop(['country','country-year','generation','suicides_no','suicides_100k_pop','year','gdp_for_year'], axis = 1) \n\ndata5.head()\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['sex'], prefix='sex',drop_first=True)],axis=1).drop(['sex'],axis=1)\n\n\n#Converting age into onehot encoding\n\ndata5 = pd.concat([data5,pd.get_dummies(data5['age'], prefix='age',drop_first=True)],axis=1).drop(['age'],axis=1)\ndata5.head()\n\ndata5 = data5[data5.HDI_for_year != 0] #Remove empty HDI\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(data5.drop(['suicides_class'],axis=1), data5.suicides_class, test_size=0.25,random_state=5)\n\n\n\n\n\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import f1_score\n\ncomplexities = []\ntrain_errors = []\ntest_errors = []\nfor n_estimators in [1,2,4,8,16,32,64]:\n    clf = RandomForestClassifier(n_estimators=n_estimators, max_depth=8)\n    clf.fit(X_train, y_train)\n    complexities.append(n_estimators)\n    train_errors.append(f1_score(y_train, clf.predict(X_train), average='weighted'))\n    test_errors.append(f1_score(y_test, clf.predict(X_test), average='weighted'))\nplt.plot(complexities, train_errors, c='b', label='Training f1-score')\nplt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\nplt.ylim(0,1)\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('Random forest')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","ef71152f":"#tree = DecisionTreeClassifier(max_depth=2,criterion,splitter)\n#_ = tree.fit(X_train, Y_train)\n\n# Evaluate\n#print('Classification report ({}):\\n'.format(key))\n#print(classification_report(Y_test, tree.predict(X_test)))\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\npipe = Pipeline([('classifier' , RandomForestClassifier())])\nparam_grid = [\n    {'classifier' : [RandomForestClassifier()],\n     'classifier__criterion' : ['entropy', 'gini'],\n    'classifier__max_depth' : [2,3,4,5,6,8,16,32,None],\n     'classifier__n_estimators':[1,2,4,8,16,32,64],\n     'classifier__max_features' : [6, 11, 16, 21, 26, 31]\n    }\n]\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=False, n_jobs=-1,scoring='f1_macro')\n\n# Fit on data\n\nbest_clf = clf.fit(X_train, y_train)\nprint(\"Best paramters are:\")\nprint(best_clf.best_params_)\nprint(\"Best f1 score (training) :\",best_clf.best_score_)\nprint(\"Best f1 score (validation) :\",f1_score(y_test, best_clf.predict(X_test), average='macro'))\n\n\n","b4cc27fb":"%matplotlib inline\nfrom sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\n\nfrom sklearn.metrics import classification_report\nimport pandas as pd\nkey=', '.join(['{}={}'.format(i,name) for i,name in enumerate(y_test)])\n#print('Classification report ({}):\\n'.format(key))\n#print(confusion_matrix(best_clf.predict(X_test) , y_test ))\n\n#y_actu = pd.Series(y_test, name='Actual')\n#y_pred_s1 = pd.Series(best_clf.predict(X_test), name='Predicted')\n#confusion_matrix = pd.crosstab(y_pred_s1, y_actu)\n#print(confusion_matrix)\n\n#print('Confusion matrix ({}):\\n'.format(key))\n_ = plt.matshow(confusion_matrix(best_clf.predict(X_test) , y_test ), cmap=plt.cm.binary, interpolation='nearest')\n_ = plt.colorbar()\n_ = plt.ylabel('true label')\n_ = plt.xlabel('predicted label')\nplt.show()\n#print(confusion_matrix(best_clf.predict(X_test) , y_test ))\nprint(classification_report(y_test, best_clf.predict(X_test)))","a4fdb8ee":"from sklearn.tree import DecisionTreeClassifier\n\ncomplexities = []\ntrain_errors = []\ntest_errors = []\nfor max_depth in [2,4,8,16,32,None]:\n    clf = DecisionTreeClassifier(max_depth=max_depth)\n    clf.fit(X_train, y_train)\n    complexities.append(max_depth)\n    train_errors.append(f1_score(y_train, clf.predict(X_train), average='macro'))\n    test_errors.append(f1_score(y_test, clf.predict(X_test), average='macro'))\nplt.plot(complexities, train_errors, c='b', label='Training f1-score')\nplt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\n#plt.ylim(0,1)\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('DecisionTreeClassifier')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","0e14e512":"#tree = DecisionTreeClassifier(max_depth=2,criterion,splitter)\n#_ = tree.fit(X_train, Y_train)\n\n# Evaluate\n#print('Classification report ({}):\\n'.format(key))\n#print(classification_report(Y_test, tree.predict(X_test)))\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\npipe = Pipeline([('classifier' , DecisionTreeClassifier())])\nparam_grid = [\n    {'classifier' : [DecisionTreeClassifier()],\n     'classifier__criterion' : ['entropy', 'gini'],\n    'classifier__max_depth' : [2,3,4,5,6,8,16,32,None], #2,4,8,16,32,None\n     'classifier__splitter' : ['best', 'random']\n    }\n]\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=False, n_jobs=-1,scoring='f1_macro')\n\n# Fit on data\n\nbest_clf = clf.fit(X_train, y_train)\nprint(\"Best paramters are:\")\nprint(best_clf.best_params_)\nprint(\"Best f1 score (training) :\",best_clf.best_score_)\nprint(\"Best f1 score (validation) :\",f1_score(y_test, best_clf.predict(X_test), average='macro'))","36281f14":"from sklearn.neighbors import KNeighborsClassifier\n\ncomplexities = []\ntrain_errors = []\ntest_errors = []\nfor neighbour in range(3,10):\n    clf = KNeighborsClassifier(n_neighbors=neighbour)#DecisionTreeClassifier(max_depth=max_depth)\n    clf.fit(X_train, y_train)\n    complexities.append(neighbour)\n    train_errors.append(f1_score(y_train, clf.predict(X_train), average='macro'))\n    test_errors.append(f1_score(y_test, clf.predict(X_test), average='macro'))\nplt.plot(complexities, train_errors, c='b', label='Training f1-score')\nplt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\n#plt.ylim(0,1)\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('KNeighborsClassifier')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","7c6d4ed1":"k_range = list(range(1, 31))\nprint(k_range)","a1325df4":"#tree = DecisionTreeClassifier(max_depth=2,criterion,splitter)\n#_ = tree.fit(X_train, Y_train)\n\n# Evaluate\n#print('Classification report ({}):\\n'.format(key))\n#print(classification_report(Y_test, tree.predict(X_test)))\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\npipe = Pipeline([('classifier' , KNeighborsClassifier())])\nparam_grid = [\n    {'classifier' : [KNeighborsClassifier()],\n     'classifier__n_neighbors' :k_range,\n     'classifier__weights':['uniform','distance'],\n'classifier__metric':['euclidean','manhattan'],\n    }\n]\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=False, n_jobs=-1,scoring='f1_macro')\n\n# Fit on data\n\nbest_clf = clf.fit(X_train, y_train)\nprint(\"Best paramters are:\")\nprint(best_clf.best_params_)\nprint(\"Best f1 score (training) :\",best_clf.best_score_)\nprint(\"Best f1 score (validation) :\",f1_score(y_test, best_clf.predict(X_test), average='macro'))","0fc0fee5":"#from sklearn import svm\nfrom sklearn.svm import LinearSVC\nclf = LinearSVC(random_state=0, tol=1e-5)#DecisionTreeClassifier(max_depth=max_depth)\nclf.fit(X_train, y_train)\n    #complexities.append(neighbour)\ntrain_err = f1_score(y_train, clf.predict(X_train), average='macro')\ntest_err = f1_score(y_test, clf.predict(X_test), average='macro')\n#plt.plot(complexities, train_errors, c='b', label='Training f1-score')\n#plt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\n#plt.ylim(0,1)\nprint(train_err)\nprint(test_err)\nplt.bar([1,2],[train_err,test_err])\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('Linear SVM')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","318ed2ab":"#tree = DecisionTreeClassifier(max_depth=2,criterion,splitter)\n#_ = tree.fit(X_train, Y_train)\n\n# Evaluate\n#print('Classification report ({}):\\n'.format(key))\n#print(classification_report(Y_test, tree.predict(X_test)))\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\npipe = Pipeline([('classifier' , LinearSVC())])\nparam_grid = [\n    {'classifier' : [LinearSVC()],\n     'classifier__C' :np.arange(0.01,100,10)\n    }\n]\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=False, n_jobs=-1,scoring='f1_macro')\n\n# Fit on data\n\nbest_clf = clf.fit(X_train, y_train)\nprint(\"Best paramters are:\")\nprint(best_clf.best_params_)\nprint(\"Best f1 score (training) :\",best_clf.best_score_)\nprint(\"Best f1 score (validation) :\",f1_score(y_test, best_clf.predict(X_test), average='macro'))","4c568f44":"from sklearn.linear_model import LogisticRegression\nclf =LogisticRegression()#DecisionTreeClassifier(max_depth=max_depth)\nclf.fit(X_train, y_train)\n    #complexities.append(neighbour)\ntrain_err = f1_score(y_train, clf.predict(X_train), average='macro')\ntest_err = f1_score(y_test, clf.predict(X_test), average='macro')\n#plt.plot(complexities, train_errors, c='b', label='Training f1-score')\n#plt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\n#plt.ylim(0,1)\nprint(train_err)\nprint(test_err)\nplt.bar([1,2],[train_err,test_err])\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('LogisticRegression')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","a91b6040":"#tree = DecisionTreeClassifier(max_depth=2,criterion,splitter)\n#_ = tree.fit(X_train, Y_train)\n\n# Evaluate\n#print('Classification report ({}):\\n'.format(key))\n#print(classification_report(Y_test, tree.predict(X_test)))\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\npipe = Pipeline([('classifier' , LogisticRegression())])\nparam_grid = [\n    {'classifier' : [LogisticRegression()],\n     'classifier__penalty' : ['l1', 'l2'],\n    'classifier__C' : np.logspace(-4, 4, 20),\n    'classifier__solver' : ['liblinear']}\n]\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=False, n_jobs=-1,scoring='f1_macro')\n\n# Fit on data\n\nbest_clf = clf.fit(X_train, y_train)\nprint(\"Best paramters are:\")\nprint(best_clf.best_params_)\nprint(\"Best f1 score (training) :\",best_clf.best_score_)\nprint(\"Best f1 score (validation) :\",f1_score(y_test, best_clf.predict(X_test), average='macro'))","0796c651":"import numpy as np\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nclf = LinearDiscriminantAnalysis()\nclf.fit(X_train, y_train)\n    #complexities.append(neighbour)\ntrain_err = f1_score(y_train, clf.predict(X_train), average='macro')\ntest_err = f1_score(y_test, clf.predict(X_test), average='macro')\n#plt.plot(complexities, train_errors, c='b', label='Training f1-score')\n#plt.plot(complexities, test_errors, c='r', label='Generalisation f1-score')\n#plt.ylim(0,1)\nprint(train_err)\nprint(test_err)\nplt.bar([1,2],[train_err,test_err])\nplt.ylabel('f1-score')\nplt.xlabel('Model complexity')\nplt.title('LinearDiscriminantAnalysis')\nplt.legend()\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","ba198ab4":"#tree = DecisionTreeClassifier(max_depth=2,criterion,splitter)\n#_ = tree.fit(X_train, Y_train)\n\n# Evaluate\n#print('Classification report ({}):\\n'.format(key))\n#print(classification_report(Y_test, tree.predict(X_test)))\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.model_selection import GridSearchCV\npipe = Pipeline([('classifier' , LinearDiscriminantAnalysis())])\nparam_grid = [\n    {'classifier' : [LinearDiscriminantAnalysis()],\n     'classifier__solver' : ['svd', 'lsqr','eigen'],\n    'classifier__shrinkage' : [None,'auto']\n    }\n]\n\n\n\nclf = GridSearchCV(pipe, param_grid = param_grid, cv = 5, verbose=False, n_jobs=-1,scoring='f1_macro')\n\n# Fit on data\n\nbest_clf = clf.fit(X_train, y_train)\nprint(\"Best paramters are:\")\nprint(best_clf.best_params_)\nprint(\"Best f1 score (training) :\",best_clf.best_score_)\nprint(\"Best f1 score (validation) :\",f1_score(y_test, best_clf.predict(X_test), average='macro'))","80a4b305":"from sklearn.model_selection import cross_val_score\nfrom sklearn import metrics\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\n\nscoring_func = \"f1_macro\"  #'f1_weighted'\n\n#train_test_split(data5.drop(['suicides_class'],axis=1), data5.suicides_class, test_size=0.25,random_state=5)\nclf = LinearDiscriminantAnalysis(shrinkage=None, solver='svd')\nscores_lda = cross_val_score(clf, data5.drop(['suicides_class'],axis=1), data5.suicides_class, cv=10, scoring=scoring_func)\n\nfrom sklearn.ensemble import RandomForestClassifier\nclf2 = RandomForestClassifier(criterion= 'gini', max_depth=None, max_features=6, n_estimators=32)\nscores_randfor = cross_val_score(clf2, data5.drop(['suicides_class'],axis=1), data5.suicides_class, cv=10, scoring=scoring_func)\n\n#'classifier__criterion': 'entropy', 'classifier__max_depth': 32, 'classifier__max_features': 6, 'classifier__n_estimators': 32}\n\nfrom sklearn.tree import DecisionTreeClassifier\nclf3 = DecisionTreeClassifier(criterion= 'entropy', max_depth=None,splitter='best')\nscores_tree = cross_val_score(clf3, data5.drop(['suicides_class'],axis=1), data5.suicides_class, cv=10, scoring=scoring_func)\n\n\nfrom sklearn.neighbors import KNeighborsClassifier\nclf4 = KNeighborsClassifier(metric='manhattan',n_neighbors=1, weights='uniform')\nscores_knn = cross_val_score(clf4, data5.drop(['suicides_class'],axis=1), data5.suicides_class, cv=10, scoring=scoring_func)\n\nfrom sklearn.svm import LinearSVC\nclf5 = LinearSVC(C=0.01)\nscores_linsvc = cross_val_score(clf5, data5.drop(['suicides_class'],axis=1), data5.suicides_class, cv=10, scoring=scoring_func)\n\nfrom sklearn.linear_model import LogisticRegression\nclf6 = LogisticRegression(C=206.913808111479,penalty='l1',solver='liblinear')\nscores_log = cross_val_score(clf6, data5.drop(['suicides_class'],axis=1), data5.suicides_class, cv=10, scoring=scoring_func)\n\n#C': 206.913808111479, 'classifier__penalty': 'l1', 'classifier__solver': 'liblinear'}\n\n","e928a197":"x_val = list(range(1,11))\nfrom matplotlib.pyplot import figure\nfigure(num=None, figsize=(8, 6), dpi=80, facecolor='w', edgecolor='k')\naxes = plt.gca()\n#axes.set_xlim([xmin,xmax])\naxes.set_ylim([0,1])\n#plt.plot(x_val, scores_lda,label=\"LDA\")\nplt.plot(x_val, scores_randfor,label=\"Random Forest\")\nplt.plot(x_val, scores_tree,label=\"Decision Tree\")\n#plt.plot(x_val, scores_knn,label=\"kNN\")\n#plt.plot(x_val, scores_linsvc,label=\"Linear SVC\")\n#plt.plot(x_val, scores_log,label=\"Logistic Regression\")\n\nplt.xlabel('Fold', fontsize=18)\nplt.ylabel('F1-score', fontsize=18)\nplt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=18)\nplt.rc('ytick',labelsize=18)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","af31b931":"'{:.10f}'.format(stats.ttest_rel(scores_randfor, scores_tree).pvalue*0.5)","a581fcc6":"'{:.18f}'.format(stats.ttest_rel(scores_randfor, scores_lda).pvalue*0.5)","995764ff":"'{:.10f}'.format(stats.ttest_rel(scores_randfor, scores_knn).pvalue*0.5)","3c804a1b":"'{:.18f}'.format(stats.ttest_rel(scores_randfor, scores_linsvc).pvalue*0.5)","394e90e1":"'{:.18f}'.format(stats.ttest_rel(scores_randfor, scores_log).pvalue*0.5)","8696d30a":"trainf1= [0.976,0.97,0.92,0.16,0.57,0.57]\nvalidationf1 = [0.98,0.976,0.93,0.17,0.57,0.57]\n\n\nx = np.array([0,1,2,3,4,5])\nmy_xticks = ['Random Forest','Decision Tree','KNeighbors','Linear SVC','LogisticRegression','LDA']\nplt.xticks(x, my_xticks,rotation=45)\n\nplt.plot(x,trainf1,label=\"Training f1-score\")\nplt.plot(x,validationf1,label=\"Validation f1-score\")\n#plt.plot(x_val, scores_knn,label=\"kNN\")\n#plt.plot(x_val, scores_linsvc,label=\"Linear SVC\")\n#plt.plot(x_val, scores_log,label=\"Logistic Regression\")\n\n#plt.xlabel('Fold', fontsize=18)\nplt.ylabel('F1-score', fontsize=18)\nplt.legend(fontsize='medium')\nplt.rc('xtick',labelsize=10)\nplt.rc('ytick',labelsize=18)\nplt.show()\nplt.clf()\nplt.cla()\nplt.close()","d469f801":"## Attempt to classify with all variables except year","9900fde3":"## Attempt to classify with all variables except year, gdp_for_year  ","a2faa0d9":"# Regression analysis","e8994a33":"# Load Data","78fb344e":"## Linear Regression with all variables","8ff8ab2a":"* Suicide rates are decreasing globally.\n* Of those countries that show clear linear trends over time, 2\/3 are decreasing.\n* On average, suicide rate increases with age. (2.4)\n* This remains true when controlling for continent in the Americas, Asia & Europe, but not for Africa & Oceania.\n* There is a weak positive relationship between a countries GDP (per capita) and suicide rate.\n* The highest suicide rate ever recorded in a demographic (for 1 year) is 225 (per 100k population).\n* There is an overrepresentation of men in suicide deaths at every level of analysis (globally, at a continent and country level). Globally, the male rate is ~3.5x higher.\n* When GDP is low, it seems that there will be more suicides per 100,000 people.","739e9d43":"# LinearSVC","1e7aeea0":"# Individual students T test","2855253c":"## Attempt to classify with all variables except year, gdp_for_year, remove empty HDI - good result","507a53ce":"### Choropleth maps","0fe6e79e":"# Load Libraries","1efd180e":"# LinearSVC GridSearch","6ee2d36b":"# LogisticRegression GridSearch","1f10e15a":"# Key insights","54622fbb":"## Linear Regression without year, HDI","3ee9d350":"# KNeighborsClassifier","6228c428":"# LinearDiscriminant","426e58e3":"## Linear Regression without year","938e6279":"# Classification","0ed16ac9":"# Cross Validation scores","81054c1d":"## Suicide count","32a0eddf":"# More visualizations","0e298231":"# Report\n\n\nThe report details out the Setup, Approach, Experiments, Results and Conclusion. Please refer to [EstimateSuicideRate - Report.pdf](https:\/\/github.com\/harinath0906\/Estimate-Suicide-Rates\/blob\/master\/EstimateSuicideRate%20-%20Report.pdf)","51d7bec2":"## GDP of countries","8d13ed19":"### HDI analysis","ba04c505":"# Comparison of various classifers","3feb743c":"# Visualizations - EDA","b1859c49":"## sucides vs gdp, gdp_per_Capita, hdi","fad469d5":"## sucides vs hdi","a2ff1ce0":"# Random Forest Grid Search CV","6a02d370":"# Advanced Visualisations","343b3a81":"# LinearDiscriminant GridSearchCV","bb1559ed":"# KNeighborsClassifier GridsearchCV","8f84a0c7":"# Relationship analysis","9d1a8d8f":"# DecisionTree","2af15535":"# LogisticRegression","11d62590":"# Correlation - GDI, HDI, Suicides","bafcaa55":"# GridsearchCV - DecisionTree","ef9e9d03":"## Linear Regression on all variables without HDI","d75e6cc6":"# Oversampling"}}