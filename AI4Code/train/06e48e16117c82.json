{"cell_type":{"371f9da5":"code","1b9c78b3":"code","5cbdc198":"code","345b8ea2":"code","5ab3b8ad":"code","92d91bb0":"code","a57f0aa7":"code","745269ad":"code","c6e5a728":"code","ac4b1c5f":"code","3141e84e":"code","f92e30f0":"code","6a336920":"code","bb42acb3":"code","8fbc0939":"code","a8185804":"code","26c60c9f":"markdown","7af987d2":"markdown","fd10ec1f":"markdown","cb719890":"markdown","1f042364":"markdown","05a3b942":"markdown","cf637e7d":"markdown","a3cbc46f":"markdown","17a9272b":"markdown"},"source":{"371f9da5":"import pandas as pd\nimport missingno as msno\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport plotly\nimport plotly.graph_objects as go\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.metrics import make_scorer\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.pipeline import Pipeline, FeatureUnion\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom xgboost import XGBClassifier\nimport time\nimport xgboost as xgb\nfrom sklearn.ensemble import RandomForestClassifier\n#from google.colab import files\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nimport numpy as np","1b9c78b3":"\ntest = pd.read_csv(\"..\/input\/test.csv\")\ntitanic_public = pd.read_csv(\"..\/input\/titanic_public.csv\")\ntrain = pd.read_csv(\"..\/input\/train.csv\")","5cbdc198":"aux = train.copy()\n\n# fill missing values with -0.5\naux[\"Age\"] = aux[\"Age\"].fillna(-0.5)\n\n# divide age column into a range of values\ncut_points = [-1,0,5,12,18,35,60,100]\nlabel_names = [\"Missing\",\"Infant\",\"Child\",\n               \"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\naux[\"Age_categories\"] = pd.cut(aux[\"Age\"],\n                                 cut_points,\n                                 labels=label_names)\ndef create_dummies(df,column_name):\n    # drop_first = True to avoid colinearity\n    dummies = pd.get_dummies(df[column_name],\n                             prefix=column_name,\n                             drop_first=True)\n    df = pd.concat([df,dummies],axis=1)\n    return df\n\naux = create_dummies(aux,\"Pclass\")\naux = create_dummies(aux,\"Age_categories\")\naux = create_dummies(aux,\"Sex\")","345b8ea2":"#Custom Transformer that extracts columns passed as argument to its constructor \nclass FeatureSelector(BaseEstimator, TransformerMixin ):\n  #Class Constructor \n  def __init__( self, feature_names ):\n    self.feature_names = feature_names \n    \n  #Return self nothing else to do here    \n  def fit( self, X, y = None ):\n    return self \n    \n  #Method that describes what we need this transformer to do\n  def transform(self, X, y = None):\n    return X[self.feature_names]","5ab3b8ad":"#converts certain features to categorical\nclass CategoricalTransformer(BaseEstimator, TransformerMixin):\n  def __init__(self, model=0):\n    self.model = model\n\n  #Return self nothing else to do here    \n  def fit( self, X, y = None ):\n    return self \n\n  def create_dummies(self, df, column_name, drop_first_col):\n    \"\"\"Create Dummy Columns from a single Column\n    \"\"\"\n    dummies = pd.get_dummies(df[column_name],prefix=column_name, drop_first=drop_first_col)\n    return dummies\n# extracting title information from the passenger's name\n  def process_titles(self, df):\n    df[\"Titles\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    titles = {\n        \"Mr\" :         0,\n        \"Mme\":         1,\n        \"Ms\":          1,\n        \"Mrs\" :        1,\n        \"Master\" :     2,\n        \"Mlle\":        3,\n        \"Miss\" :       3,\n        \"Capt\":        4,\n        \"Col\":         4,\n        \"Major\":       4,\n        \"Dr\":          4,\n        \"Rev\":         4,\n        \"Jonkheer\":    5,\n        \"Don\":         5,\n        \"Sir\" :        5,\n        \"Countess\":    5,\n        \"Dona\":        5,\n        \"Lady\" :       5\n    } \n\n  def process_family_size(self, df):\n    df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    titles = {\n        \"Mr\" :         \"man\",\n        \"Mme\":         \"woman\",\n        \"Ms\":          \"woman\",\n        \"Mrs\" :        \"woman\",\n        \"Master\" :     \"boy\",\n        \"Mlle\":        \"woman\",\n        \"Miss\" :       \"woman\",\n        \"Capt\":        \"man\",\n        \"Col\":         \"man\",\n        \"Major\":       \"man\",\n        \"Dr\":          \"man\",\n        \"Rev\":         \"man\",\n        \"Jonkheer\":    \"man\",\n        \"Don\":         \"man\",\n        \"Sir\" :        \"man\",\n        \"Countess\":    \"woman\",\n        \"Dona\":        \"woman\",\n        \"Lady\" :       \"woman\"\n    } \n\n    # new gender: man, woman, boy\n    df[\"Gender\"] = df[\"Title\"].map(titles)\n\n    # family surname\n    df[\"family\"] = df[\"Name\"].str.extract('([A-Za-z]+)\\,',expand=False)\n\n    # count the number of boy and women by family\n    boy_women = df[df[\"Gender\"] != \"man\"].groupby(by=[\"family\"])[\"Name\"].agg(\"count\")\n\n    # fill with zero that passengers are traveling alone or with family without boy and women\n    df[\"family_size\"] = df[\"family\"].map(boy_women).fillna(0.0)\n\n    if self.model in [8,9]:\n      return pd.DataFrame(df[\"family_size\"],columns=[\"family_size\"])\n    else:\n      return None\n\n  def process_sex(self, df):\n    df[\"Title\"] = df[\"Name\"].str.extract(' ([A-Za-z]+)\\.',expand=False)\n    titles = {\n        \"Mr\" :         \"man\",\n        \"Mme\":         \"woman\",\n        \"Ms\":          \"woman\",\n        \"Mrs\" :        \"woman\",\n        \"Master\" :     \"boy\",\n        \"Mlle\":        \"woman\",\n        \"Miss\" :       \"woman\",\n        \"Capt\":        \"man\",\n        \"Col\":         \"man\",\n        \"Major\":       \"man\",\n        \"Dr\":          \"man\",\n        \"Rev\":         \"man\",\n        \"Jonkheer\":    \"man\",\n        \"Don\":         \"man\",\n        \"Sir\" :        \"man\",\n        \"Countess\":    \"woman\",\n        \"Dona\":        \"woman\",\n        \"Lady\" :       \"woman\"\n    }\n    \n    if self.model == 0:\n      df[\"Sex\"] = pd.Categorical(df.Sex).codes\n      return pd.DataFrame(df[\"Sex\"],columns=[\"Sex\"])\n    elif self.model in [1,2,3,4,5]:  \n      sex_dummies = self.create_dummies(df,\"Sex\",True)\n      return sex_dummies\n    elif self.model == 6:\n      df[\"Sex\"] = df[\"Title\"].map(titles)\n      sex_dummies = self.create_dummies(df,\"Sex\",False)\n      return sex_dummies\n    elif self.model in [7,8,9]:\n      df[\"Sex\"] = df[\"Title\"].map(titles)\n      sex_dummies = self.create_dummies(df,\"Sex\",False)\n      sex_dummies.drop(labels=\"Sex_woman\",axis=1,inplace=True)\n      return sex_dummies\n    else:\n      return None\n\n  def process_embarked(self, df):\n    if self.model in [0,1,2,3,8]:\n      return None\n    elif self.model == 4:\n      # fill null values using the mode\n      df[\"Embarked\"].fillna(\"S\",inplace=True)\n      df[\"Embarked\"] = pd.Categorical(df.Embarked).codes\n      return pd.DataFrame(df[\"Embarked\"],columns=[\"Embarked\"])\n    elif self.model in [5,6,7,9]:\n      df[\"Embarked\"].fillna(\"S\",inplace=True)\n      embarked_dummies = self.create_dummies(df,\"Embarked\",False)\n      return embarked_dummies\n\n  #Transformer method we wrote for this transformer \n  def transform(self, X , y = None ):\n    df = X.copy()\n    sex = self.process_sex(df)\n    embarked = self.process_embarked(df)\n    family_size = self.process_family_size(df)\n    tit = self.process_titles(df)\n\n    if self.model == 0:\n      return  pd.concat([sex,tit],axis=1)  \n    elif self.model in [1,2,3]:\n      return sex\n    elif self.model == 4:\n      return pd.concat([sex,family_size,tit],axis=1)\n    elif self.model in [4,5,6,7]:\n      return pd.concat([sex,embarked,tit],axis=1)\n    elif self.model == 8:\n      return pd.concat([sex,family_size],axis=1)\n    elif self.model == 9:\n      return pd.concat([sex,family_size,embarked],axis=1)\n    else:\n      return None","92d91bb0":"# for validation purposes only\nselect = FeatureSelector(train.select_dtypes(include=[\"object\"]).columns).transform(train)\n\n# change the value of model 0,1,2,3,....7\nmodel = CategoricalTransformer(model=9)\ndf_cat = model.transform(select)\ncat_cols_final = df_cat.columns\ndf_cat.head()","a57f0aa7":"#converts certain features to categorical\nclass NumericalTransformer(BaseEstimator, TransformerMixin):\n  def __init__(self, model=0):\n    \"\"\"Class constructor method that take: \n    model: \n      - 0: Sex column (categorized), Pclass (raw)\n      - 1: Sex column (get_dummies(drop_first=True)), Pclass (raw)\n      - 2: Sex column (get_dummies(drop_first=True)), Pclass (get_dummies(drop_first=False))\n      - 3: Sex column (get_dummies(drop_first=True)), Pclass (raw), Age (get_dummies(drop_first=False))\n      - 4: Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (categorized)\n      - 5: Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 6: New Sex column (get_dummies(drop_first=False)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 7: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Embarked (get_dummies(drop_first=False))\n      - 8: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Family_Size\n      - 9: New Sex column (get_dummies(drop_first=True)), Pclass (raw), Family_Size, Embarked (get_dummies(drop_first=False))\n    \"\"\"\n    self.model = model\n\n  #Return self nothing else to do here    \n  def fit( self, X, y = None ):\n    return self \n\n  def create_dummies(self, df, column_name, drop_first_col):\n    \"\"\"Create Dummy Columns from a single Column\n    \"\"\"\n    dummies = pd.get_dummies(df[column_name],prefix=column_name, drop_first=drop_first_col)\n    return dummies\n\n  # manipulate column \"Age\"\n  def process_age(self, df):\n    # fill missing values with -0.5\n    df[\"Age\"] = df[\"Age\"].fillna(-0.5)\n\n    # divide age column into a range of values\n    cut_points = [-1,0,5,12,18,35,60,100]\n    label_names = [\"Missing\",\"Infant\",\"Child\",\"Teenager\",\"Young Adult\",\"Adult\",\"Senior\"]\n    df[\"Age_categories\"] = pd.cut(df[\"Age\"],\n                                 cut_points,\n                                 labels=label_names)\n    if self.model in [0,1,2,6,7,8,9]:\n      return None\n    elif self.model == 3:\n      return self.create_dummies(df,\"Age_categories\",False)\n   \n  def process_pclass(self, df):\n    if self.model in [0,1,3,4,5,6,7,8,9]:\n      return pd.DataFrame(df[\"Pclass\"],columns=[\"Pclass\"])\n    elif self.model == 2:\n      return self.create_dummies(df,\"Pclass\",False)\n    else:\n      return None\n        \n  #Transformer method we wrote for this transformer \n  def transform(self, X , y = None ):\n    df = X.copy()\n\n    age = self.process_age(df)  \n    pclass = self.process_pclass(df)\n    \n    if self.model in [0,1,2,4,5,6,7,8,9]:\n      return pclass\n    elif self.model == 3:\n      return pd.concat([pclass,age],axis=1)\n    else:\n      return None","745269ad":"# for validation purposes only\nselect = FeatureSelector(train.drop(labels=[\"Survived\"],axis=1).select_dtypes(include=[\"int64\",\"float64\"]).columns).transform(train)\n\n# change model to 0,1,2,3, ..., 7\nmodel = NumericalTransformer(model=9)\ndf = model.transform(select)\nnum_cols_final = df.columns\npd.concat([df.select_dtypes(include=[\"int64\",\"uint8\"]),\n                       df_cat.select_dtypes(include=[\"int64\",\"uint8\"]),\n                       train.Survived],axis=1).corr()[\"Survived\"].abs().sort_values()\ndf.head()","c6e5a728":"# global varibles\nseed = 42\nnum_folds = 10\nscoring = {'Accuracy': make_scorer(accuracy_score)}\n# load the datasets\ntrain = pd.read_csv(\"train.csv\")\n\n# split-out train\/validation and test dataset\nX_train, X_test, y_train, y_test = train_test_split(train.drop(labels=\"Survived\",axis=1),\n                                                    train[\"Survived\"],\n                                                    test_size=0.20,\n                                                    random_state=seed,\n                                                    shuffle=True,\n                                                    stratify=train[\"Survived\"])","ac4b1c5f":"# Categrical features to pass down the categorical pipeline \ncategorical_features = X_train.select_dtypes(include=[\"object\"]).columns\n\n# Numerical features to pass down the numerical pipeline \nnumerical_features = X_train.select_dtypes(include=[\"int64\",\"float64\"]).columns\n\n# Defining the steps in the categorical pipeline \ncategorical_pipeline = Pipeline(steps = [('cat_selector', FeatureSelector(categorical_features)),\n                                         ('cat_transformer', CategoricalTransformer(model=9))\n                                         ]\n                                )\n# Defining the steps in the numerical pipeline     \nnumerical_pipeline = Pipeline(steps = [('num_selector', FeatureSelector(numerical_features)),\n                                       ('num_transformer', NumericalTransformer(model=9)) \n                                       ]\n                              )\n\n# Combining numerical and categorical piepline into one full big pipeline horizontally \n# using FeatureUnion\nfull_pipeline_preprocessing = FeatureUnion(transformer_list = [('categorical_pipeline', categorical_pipeline),\n                                                               ('numerical_pipeline', numerical_pipeline)\n                                                               ]\n                                           )# for validate purposes\nnew_data = full_pipeline_preprocessing.fit_transform(X_train)\nnew_data_df = pd.DataFrame(new_data,)#columns=cat_cols_final.tolist() + num_cols_final.tolist())\nnew_data_df.head()","3141e84e":"\n\n# The full pipeline as a step in another pipeline with an estimator as the final step\npipe = Pipeline(steps = [('full_pipeline', full_pipeline_preprocessing),\n                         #(\"fs\",SelectKBest()),\n                         (\"clf\",XGBClassifier())])\n\n# create a dictionary with the hyperparameters\nsearch_space = [\n                {\"clf\":[RandomForestClassifier()],\n                 \"clf__n_estimators\": [100, 200],\n                 \"clf__criterion\": [\"entropy\"],\n                 \"clf__max_leaf_nodes\": [64, 128, 256],\n                 \"clf__random_state\": [seed]\n                 },\n                {\"clf\":[LogisticRegression()],\n                 \"clf__solver\": [\"liblinear\"]\n                 },\n                {\"clf\":[XGBClassifier()],\n                 \"clf__n_estimators\": [200, 300],\n                 \"clf__max_depth\": [2,3,4],\n                 \"clf__booster\":['gbtree'],\n                 \"clf__learning_rate\": [0.001, 0.01,0.1],\n                 \"clf__random_state\": [seed],\n                 \"clf__subsample\": [1.0],\n                 \"clf__objective\":['reg:squarederror'],\n                 \"clf__tree_method\":[\"auto\"],\n                 \"clf__colsample_bytree\": [1.0],\n                 \"full_pipeline__numerical_pipeline__num_transformer__model\":[0],\n                 \"full_pipeline__categorical_pipeline__cat_transformer__model\":[6]\n                 }\n                ]\n\n# create grid search\nkfold = StratifiedKFold(n_splits=num_folds,random_state=seed)\n\n# return_train_score=True\n# official documentation: \"computing the scores on the training set can be\n# computationally expensive and is not strictly required to\n# select the parameters that yield the best generalization performance\".\ngrid = GridSearchCV(estimator=pipe, \n                    param_grid=search_space,\n                    cv=kfold,\n                    scoring=scoring,\n                    return_train_score=True,\n                    n_jobs=-1,\n                    refit=\"Accuracy\")\n\ntmp = time.time()\n\n# fit grid search\nbest_model = grid.fit(X_train,y_train)\n\nprint(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp)))","f92e30f0":"print(\"Best: %f using %s\" % (best_model.best_score_,best_model.best_params_))","6a336920":"result = pd.DataFrame(best_model.cv_results_)\nresult.head()","bb42acb3":"print(\"Best: %f using %s\" % (best_model.best_score_,best_model.best_params_))","8fbc0939":"# best model\npredict_first = best_model.best_estimator_.predict(X_test)\nprint(accuracy_score(y_test, predict_first))","a8185804":"predict_final = best_model.best_estimator_.predict(test)\nholdout_ids = test[\"PassengerId\"]\nsubmission_df = {\"PassengerId\": holdout_ids,\n                 \"Survived\": predict_final}\nsubmission = pd.DataFrame(submission_df)\n\nsubmission.to_csv(\"submission.csv\",index=False)\nfiles.download('submission.csv')","26c60c9f":"**Creating a Submission File**","7af987d2":"**Modeling (train and test)**","fd10ec1f":"**Algorithm Tuning**","cb719890":"**Get data**","1f042364":"**Load Libraries**","05a3b942":"**Numerical Pipeline**","cf637e7d":"**Feature selector**","a3cbc46f":"**Categorical pipeline**","17a9272b":"**Clean, prepare and manipulate data**"}}