{"cell_type":{"6a785a95":"code","277b02a7":"code","25c47b69":"code","d5e28314":"code","c3f6dc00":"code","467a76a9":"code","e4aba2ec":"code","49f549e7":"code","1891ad44":"code","d4b84668":"code","6c60a80a":"code","3289ceb4":"code","6ce29f18":"code","46f585e7":"code","0da6bcae":"code","36ac76fa":"markdown","3ae37d08":"markdown","83f6dd83":"markdown"},"source":{"6a785a95":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","277b02a7":"#importing data\ndata=pd.read_csv('\/kaggle\/input\/iba-ml1-mid-project\/train.csv')\ndata.head()","25c47b69":"#First column is useless. Let's drop it.\ndata.drop(['Id'], axis=1, inplace=True)","d5e28314":"#Showing first 5 rows\ndata.head()","c3f6dc00":"#Showing last 5 rows\ndata.tail()","467a76a9":"#Showing number of columns and rows\ndata.shape","e4aba2ec":"#Showing data types of features.\ndata.dtypes","49f549e7":"data['credit_line_utilization']=data['credit_line_utilization'].str.replace(',','.')\ndata['credit_line_utilization']=data['credit_line_utilization'].astype(float)","1891ad44":"data.dtypes","d4b84668":"#Describing some statistics of numeric columns\ndata.describe()","6c60a80a":"#find features that have at least one missing value:\nmissing = []\nfor ft in data.columns:\n    if data[ft].isnull().sum()>0:\n        missing.append(ft)\nprint('Number of variables with missing values is equal to:', len(missing))\ndata[missing].isnull().sum()","3289ceb4":"#Number of unique (distinct) values in each feature.\ndata.nunique()","6ce29f18":"# Showing correlation between numeric features with Pearson method.\nimport seaborn as sns\nsns.heatmap(data.corr())","46f585e7":"#Showing correlation on the above with numeric values\ndata.corr()","0da6bcae":"data['defaulted_on_loan'].value_counts()","36ac76fa":"It is clear that our dataset is imbalanced. ","3ae37d08":"So our final dataset contains 11 numeric columns.","83f6dd83":"As you can see type of column: credit_line_utilization is object. We must convert it to float type. \nBut firstly we must replace commas with dots to get ride of error."}}