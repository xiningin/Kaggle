{"cell_type":{"44180669":"code","e57455e8":"code","013dea49":"code","46feef8d":"code","45551bc0":"code","69998ce5":"code","47793d43":"code","574f0d40":"code","1005c59c":"code","81ac9573":"code","b9ecbc69":"code","e244c98c":"code","a98b6b86":"code","61d6d035":"code","4007099e":"code","f5e47315":"code","9d984450":"code","db6a46ba":"code","7d57a01c":"code","8ab41f37":"code","9f75fcb9":"code","71dced44":"code","83291cec":"code","43afc814":"code","4a55e657":"code","73322894":"code","9718b86c":"code","b78ff66d":"code","b3fe1fa7":"code","f425bc7e":"code","ebb69c99":"code","ce83e916":"code","88668015":"code","2a28bff0":"code","e9e4f5c7":"code","f8a4baf5":"code","79f83405":"code","25abb17a":"code","cacfc571":"code","14f5203c":"code","f80f4d37":"code","32ca4eff":"code","d181a0d7":"code","ed422b4d":"code","2146d52f":"code","feca55e9":"code","86bb0c9a":"code","ac13c4da":"code","0feee9bb":"code","38573b0e":"code","8f54d50f":"code","67952c50":"code","cee52511":"code","c6b6c41a":"code","66615fb8":"code","4cfada86":"code","48f99d6d":"code","e3d3db4c":"code","8c1dedc8":"code","55d47006":"code","0b433475":"code","53277c64":"code","730cde07":"code","ef801994":"code","09332317":"code","59804d5c":"code","b390e23e":"code","f7a0dd00":"code","015487c0":"code","be8ef1c7":"code","d5b32291":"code","9c9ec9dc":"code","f7d78fb6":"code","d859c7de":"code","3db183a6":"code","fe30f55f":"code","6d804fe6":"code","5a639c29":"code","2d42a5a0":"code","16719158":"code","59488a14":"code","60a81f9e":"code","49111e59":"code","5b186a8c":"code","e13a3643":"code","5e9b5166":"code","44bbc9fd":"markdown","ecacf640":"markdown","69149e8a":"markdown","5ae49c3d":"markdown","b6a222c2":"markdown","edeb20b4":"markdown","fd01bac7":"markdown","7ee4837a":"markdown","50f6e97a":"markdown","ebfc96ae":"markdown","0afbdbd2":"markdown","29c50668":"markdown","87087196":"markdown","481c6c74":"markdown","411461f9":"markdown","a0764637":"markdown","14a5aaa4":"markdown","8b5ed99e":"markdown","e1e8ab6d":"markdown","e3e59100":"markdown","1636955f":"markdown","b29da57d":"markdown","a44ab7b0":"markdown","089a3cc5":"markdown","6a95f6f1":"markdown","74ece1c5":"markdown","21340a8c":"markdown","7152c63f":"markdown","b2dad294":"markdown","7e16dc26":"markdown","34e73c11":"markdown","95151912":"markdown","9a24a6c0":"markdown","1051596d":"markdown"},"source":{"44180669":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e57455e8":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport warnings \n%matplotlib inline\n\nwarnings.filterwarnings('ignore')","013dea49":"train_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/train.csv')\ntest_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/test.csv')\nsub_df = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')","46feef8d":"train_df.head()","45551bc0":"print(f'number of unique patients = {len(train_df.patient_id.unique())}')","69998ce5":"plt.figure(figsize=(4, 6))\nsns.countplot(x = 'benign_malignant' , data=train_df)\nplt.title('class distribution')","47793d43":"print(train_df.shape)\ntrain_df.isnull().sum()","574f0d40":"plt.figure()\nsns.distplot(train_df.age_approx)\nplt.title('Distribution of Age')","1005c59c":"train_df.age_approx.value_counts()","81ac9573":"fig = plt.figure(figsize=(10, 16))\nfig.add_subplot(2,1,1)\nsns.countplot(x='age_approx' , data = train_df)\nplt.title('freq count of AGE')\n\nfig.add_subplot(2,1,2)\nsns.countplot(x='benign_malignant' , hue='age_approx' , data=train_df)\nplt.title('distribution of age with respect to outcome')","b9ecbc69":"sns.countplot(x='sex' , data= train_df)\nplt.title('distribution by sex')","e244c98c":"train_df.anatom_site_general_challenge.value_counts()","a98b6b86":"plt.figure(figsize=(10,6))\nsns.countplot(x='anatom_site_general_challenge' , data=train_df)\nplt.title('dustribution of anatom_site_general_challenge')","61d6d035":"train_df['age_approx'] = train_df.age_approx.fillna(np.mean(train_df['age_approx']))\ntest_df['age_approx'] = test_df.age_approx.fillna(np.mean(test_df['age_approx']))","4007099e":"train_df.isnull().sum()","f5e47315":"test_df.isnull().sum()","9d984450":"unknown_sex= train_df.loc[train_df.sex.isnull()]\nun_sex_list = unknown_sex.patient_id.unique()","db6a46ba":"\nfor p in un_sex_list:\n    a = train_df.loc[(train_df.patient_id == p) & (train_df.sex.notnull()) , 'sex']\n    print(a)\n    #train_df.loc[(train_df.patient_id == p)].fillna(a , inplace=True)","7d57a01c":"test_df.isnull().sum()","8ab41f37":"train_df.dropna(subset=['sex'] , inplace=True)\nprint(train_df.shape)\ntrain_df.isnull().sum()","9f75fcb9":"train_df['sex'] = train_df['sex'].replace('male' , 0)\ntrain_df['sex'] = train_df['sex'].replace('female' , 1)\n\ntest_df['sex'] = test_df['sex'].replace('male' ,0)\ntest_df['sex'] = test_df['sex'].replace('female' , 1)\n\ntrain_df.dtypes","71dced44":"# filling nan with U\ntrain_df['anatom_site_general_challenge'] = train_df['anatom_site_general_challenge'].fillna('U')\ntest_df['anatom_site_general_challenge'] = test_df['anatom_site_general_challenge'].fillna('U')\nprint(len(train_df['anatom_site_general_challenge'].unique()))","83291cec":"num_enc_dict = { p: i for i, p in enumerate(train_df['anatom_site_general_challenge'].unique())}\nnum_enc_dict","43afc814":"train_df['anatom_site_general_challenge'] = train_df['anatom_site_general_challenge'].map(num_enc_dict)\ntest_df['anatom_site_general_challenge'] = test_df['anatom_site_general_challenge'].map(num_enc_dict)","4a55e657":"train_df.isnull().sum()","73322894":"test_df.isnull().sum()","9718b86c":"num_enc_dict = { p: i for i, p in enumerate(train_df['diagnosis'].unique())}\nnum_enc_dict","b78ff66d":"train_df['diagnosis'] = train_df['diagnosis'].map(num_enc_dict)\n#test_df['diagnosis'] = test_df['diagnosis'].map(num_enc_dict)","b3fe1fa7":"fig = plt.figure(figsize=(12,10))\ni =1\nfor p in train_df.columns[2:]:\n    ax = fig.add_subplot(3,3,i)\n    sns.countplot(x=p, data=train_df)\n    ax.set_xticks([])\n    i +=1\n\nfig.tight_layout(pad=3)","f425bc7e":"import pydicom\nfrom PIL import Image\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport cv2\nimport io\nimport gc","ebb69c99":"train_path = os.path.join('..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/')\ntest_path = os.path.join('..\/input\/siim-isic-melanoma-classification\/jpeg\/test\/')","ce83e916":"TFRpath = os.path.join('..\/input\/siim-isic-melanoma-classification\/tfrecords\/')","88668015":"for f in os.listdir(train_path)[:30]:\n    a = cv2.imread(train_path + f)\n    print(a.shape)","2a28bff0":"# image dimension\nIMG_DIM = 64\nIMG_DEPTH = 3\nBATCH_SIZE = 32\n","e9e4f5c7":"raw_data = tf.data.TFRecordDataset('..\/input\/siim-isic-melanoma-classification\/tfrecords\/train00-2071.tfrec')\nfor r in raw_data.take(1):\n    ex = tf.train.Example()\n    ex.ParseFromString(r.numpy())\n    print(ex)","f8a4baf5":"feature_description = {\n    'image': tf.io.FixedLenFeature([], tf.string, default_value=''),\n    'image_name': tf.io.FixedLenFeature([], tf.string, default_value=''),\n    'target': tf.io.FixedLenFeature([], tf.int64, default_value=0),\n}\ndef parse_data_func(ex_proto):\n    return tf.io.parse_single_example(ex_proto , feature_description)","79f83405":"dic = {}\nparsed_data = raw_data.map(parse_data_func)\nfor p in parsed_data.take(10):\n    img = p['image'].numpy()\n    name = p['image_name'].numpy()\n    name = name.decode('utf-8')\n    img = np.array(Image.open(io.BytesIO(img)))\n    img = cv2.resize(img , (IMG_DIM , IMG_DIM))\n    print(img.shape)\n    di = {name : img}\n    dic.update(di)","25abb17a":"parsed_data = raw_data.map(parse_data_func)","cacfc571":"# function to load TFR data into a dictionary\ndef load_TFR_data(sample, img_dim):\n    img = sample['image'].numpy()\n    name = sample['image_name'].numpy()\n    name = name.decode('utf-8')\n    img = np.array(Image.open(io.BytesIO(img)))\n    img = cv2.resize(img , (img_dim , img_dim))\n    img = img\/255\n    img = img.astype(np.uint8)\n    return {name : img}","14f5203c":"train_ct_data = {}\nfor p in parsed_data:\n    train_ct_data.update(load_TFR_data(p , IMG_DIM))\n\nlen(train_ct_data)","f80f4d37":"def load_ct_data_to_dict(directory , _set='train'):\n    data_dict = {}\n    for p in os.listdir(directory):\n        if p.startswith(_set):\n            path = directory+p\n            raw_data = tf.data.TFRecordDataset(path)\n            parsed_data = raw_data.map(parse_data_func)\n            for p in parsed_data:\n                data_dict.update(load_TFR_data(p , IMG_DIM))\n    return data_dict\n            \n                ","32ca4eff":"train_ct_data_dict = load_ct_data_to_dict(TFRpath , _set='train')\ntest_ct_data_dict = load_ct_data_to_dict(TFRpath , _set='test')\n\nprint(f'number of samples of ct in train set = {len(train_ct_data_dict)}')\nprint(f'number of samples of ct in test set = {len(test_ct_data_dict)}')","d181a0d7":"x_train_images = []\nfor p in train_df['image_name']:\n    x_train_images.append(train_ct_data_dict[p])\n    del(train_ct_data_dict[p])\n    \nx_train_images = np.array(x_train_images)\n    ","ed422b4d":"x_train_images.shape","2146d52f":"x_test_images = []\nfor p in test_df['image_name']:\n    x_test_images.append(test_ct_data_dict[p])\n    del(test_ct_data_dict[p])\n    \nx_test_images = np.array(x_test_images)\nx_test_images.shape","feca55e9":"np.save('x_train_images.npy' , x_train_images)\nnp.save('x_test_images.npy' , x_test_images)","86bb0c9a":"gc.collect()","ac13c4da":"x_train_images.nbytes","0feee9bb":"train_df.columns","38573b0e":"x_train_numerical = train_df[['sex' ,'age_approx' ,'anatom_site_general_challenge']]\nx_train_numerical = np.array(x_train_numerical)\ny_train = train_df[['target']]\ny_train = np.array(y_train)\nx_test_numerical = test_df[['sex' ,'age_approx' ,'anatom_site_general_challenge']]\nx_test_numerical = np.array(x_test_numerical)\n\nprint(f'shape of train images : {x_train_images.shape}')\nprint(f'shape of train numerical : {x_train_numerical.shape}')\nprint(f'shape of train target (y) : {y_train.shape}')\nprint(f'shape of test images : {x_test_images.shape}')\nprint(f'shape of test numerical : {x_test_numerical.shape}')\n\n","8f54d50f":"from tensorflow.keras.layers import Conv2D , Activation , MaxPool2D , concatenate , GlobalAvgPool2D\nfrom tensorflow.keras.layers import Flatten , Dense , Input , BatchNormalization , Dropout \nfrom tensorflow.keras.models import Model , Sequential","67952c50":"def perceptron_model(dim):\n    model = Sequential()\n    model.add(Dense(12 , input_dim=dim , activation='relu'))\n    model.add(Dense(8 , activation = 'relu'))\n    return model","cee52511":"def CNN_model(h,w,d):\n    input_shape = (h,w,d)\n    _input = Input(shape=input_shape)\n    x = Conv2D(16 ,(3,3) , activation='relu' , padding='same')(_input)\n    x = Conv2D(32 ,(3,3) , activation ='relu' , padding='same')(x)\n    x = MaxPool2D((2,2))(x)\n    x = BatchNormalization()(x)\n    x = Conv2D(64 , (3,3) , activation='relu' , padding='same')(x)\n    x = MaxPool2D((2,2))(x)\n    x = BatchNormalization()(x)\n    x = Flatten()(x)\n    x = Dense(1024 , activation='relu')(x)\n    x = Dropout(0.5)(x)\n    x = Dense(128 , activation='relu')(x)\n    model = Model(inputs=_input , outputs=x)\n    return model","c6b6c41a":"! mkdir model_checkpoints","66615fb8":"cp_callback = tf.keras.callbacks.ModelCheckpoint(filepath = 'model_checkpoints\/model_weights.hdf5' , save_best_only = True , verbose =1)","4cfada86":"linear_model = perceptron_model(3)\nCnn_model = CNN_model(IMG_DIM , IMG_DIM, 3)\n\nf = concatenate([linear_model.output , Cnn_model.output])\nf = Dense(128 , activation = 'relu')(f)\nf = Dropout(0.3)(f)\nf = Dense(64 , activation = 'relu')(f)\nf = Dropout(0.5)(f)\nf = Dense(1 , activation = 'sigmoid')(f)\n\nfinal_model = Model(inputs=[linear_model.input , Cnn_model.input] , outputs=f)","48f99d6d":"final_model.compile(optimizer='adam' , loss='binary_crossentropy' , metrics=['accuracy'])\nfinal_model.summary()","e3d3db4c":"history = final_model.fit(x=[x_train_numerical , x_train_images] , y = y_train , epochs=30 , batch_size=32 , callbacks=[cp_callback])","8c1dedc8":"preds = final_model.predict(x=[x_test_numerical , x_test_images])","55d47006":"sub_df.head()","0b433475":"sub_df['target'] = preds\nsub_df.set_index('image_name' , inplace=True)\nsub_df.head()","53277c64":"sub_df.to_csv('submission.csv')","730cde07":"# creating validation set\n# number of samples in validation set = k\nk = 5000\nx_val_numerical = x_train_numerical[len(x_train_numerical) - k :]\nx_val_images = x_train_images[len(x_train_images) -k :]\ny_val = y_train[len(y_train)-k:]\n\nx_train_numerical = x_train_numerical[:len(x_train_numerical) - k]\nx_train_images = x_train_images[:len(x_train_images) - k]\ny_train = y_train[:len(y_train)-k]\n\nprint(f'shape of training numerical : {x_train_numerical.shape}')\nprint(f'shape of training images : {x_train_images.shape}')\nprint(f'shape of training target : {y_train.shape}')\nprint(f'shape of validation set (numerical) : {x_val_numerical.shape}')\nprint(f'shape of validation set (images) : {x_val_images.shape}')\nprint(f'shape of validation set (target) : {y_val.shape}')\n","ef801994":"METRICS = [\n      tf.keras.metrics.TruePositives(name='tp'),\n      tf.keras.metrics.FalsePositives(name='fp'),\n      tf.keras.metrics.TrueNegatives(name='tn'),\n      tf.keras.metrics.FalseNegatives(name='fn'), \n      tf.keras.metrics.BinaryAccuracy(name='accuracy'),\n      tf.keras.metrics.Precision(name='precision'),\n      tf.keras.metrics.Recall(name='recall'),\n      tf.keras.metrics.AUC(name='auc'),\n]","09332317":"final_model.compile(optimizer='adam' , loss='binary_crossentropy' , metrics=METRICS)","59804d5c":"# early_stopping\nes_callback = tf.keras.callbacks.EarlyStopping(monitor='val_auc' , verbose=1, patience=10 , mode='max' ,restore_best_weights=True)","b390e23e":"history2 = final_model.fit(x= [x_train_numerical , x_train_images] , \n                           y = y_train , \n                           epochs = 50 , \n                           validation_data=([x_val_numerical , x_val_images] , y_val), \n                           callbacks = [cp_callback , es_callback])","f7a0dd00":"ax = plt.figure()\nax1 = plt.plot(history2.history['loss'])\nax2 = plt.plot(history2.history['val_loss'])\nplt.title('LOSS')\nplt.legend(labels =['loss' ,'val_loss'])\nplt.show()","015487c0":"plt.plot(history2.history['auc'])\nplt.plot(history2.history['val_auc'])\nplt.title('AUC')\nplt.legend(labels = ['auc' ,'val_auc'])\nplt.show()","be8ef1c7":"preds = final_model.predict([x_test_numerical , x_test_images])","d5b32291":"sub_df['target'] = preds\nsub_df.head()","9c9ec9dc":"sub_df.to_csv('submission.csv')","f7d78fb6":"# first lets look at the count of each class in our training sample\npos = np.count_nonzero(y_train==0)\nneg = np.count_nonzero(y_train==1)\ntotal = len(y_train)\nprint('class 0 : ' + str(pos))\nprint('class 1 : ' + str(neg))\nprint('total : ' +str(total))","d859c7de":"w_0 = (1\/pos)*(total)\/2\nw_1 = (1\/neg)*(total)\/2\n\nclass_weights = {0:w_0 ,1:w_1}\nprint(f'weight of class 0 : {w_0}')\nprint(f'weight of class 1 : {w_1}')","3db183a6":"history3 = final_model.fit(x= [x_train_numerical , x_train_images] , \n                           y = y_train , \n                           epochs = 50 , \n                           validation_data=([x_val_numerical , x_val_images] , y_val), \n                           callbacks = [cp_callback , es_callback],\n                           class_weight=class_weights)","fe30f55f":"ax = plt.figure()\nax1 = plt.plot(history3.history['loss'])\nax2 = plt.plot(history3.history['val_loss'])\nplt.title('LOSS')\nplt.legend(labels =['loss' ,'val_loss'])\nplt.show()","6d804fe6":"plt.plot(history3.history['auc'])\nplt.plot(history3.history['val_auc'])\nplt.title('AUC')\nplt.legend(labels = ['auc' ,'val_auc'])\nplt.show()","5a639c29":"preds = final_model.predict([x_test_numerical , x_test_images])","2d42a5a0":"sub_df['target'] = preds\nsub_df.head()","16719158":"sub_df.to_csv('submission.csv')","59488a14":"es_callback2 = tf.keras.callbacks.EarlyStopping(monitor='val_loss' , verbose=1, patience=10 , mode='auto' ,restore_best_weights=True)","60a81f9e":"history4 = final_model.fit(x= [x_train_numerical , x_train_images] , \n                           y = y_train , \n                           epochs = 50 , \n                           validation_data=([x_val_numerical , x_val_images] , y_val), \n                           callbacks = [cp_callback , es_callback2],\n                           class_weight=class_weights)","49111e59":"z = final_model.evaluate([x_val_numerical , x_val_images] , y_val)","5b186a8c":"preds = final_model.predict([x_test_numerical , x_test_images])\n","e13a3643":"sub_df['target'] = preds\nsub_df.head()","5e9b5166":"sub_df.to_csv('submission.csv')","44bbc9fd":"As we can see that the Age has discrete values and a normal distribtuon. we can use countplot to better visualize the age feature and how our outcome is dependent on AGE","ecacf640":"now lets explore anatom_site_general_challenge feature","69149e8a":"okay so we have a class imbalance problem","5ae49c3d":"now our data is ready for training and we can go on to create our model","b6a222c2":"lets create the multilayer perceptron first","edeb20b4":"so there are only two pateints whose sex we don't know so now lest look if there are any null values for sex in test set or not","fd01bac7":"hello evryone,\nThis notebook goes through the whole process of model training from EDA , data wrngling to feature engineering to processingg the ct data to final model training \n\nplease upvote if you like my work","7ee4837a":"# Data Exploration and Feature Engineering\n----\n----","50f6e97a":"now lets handle the missing values\n\n* ## 1. AGE - we can fill the missing values with mean","ebfc96ae":"this is a huge imbalnce. so lets how weighting of classes is done","0afbdbd2":"now the CNN","29c50668":"now our model is ready lets satrt the training","87087196":"and lets recompile our model which use auc score as a metrics","481c6c74":"now lets define our final model","411461f9":"so this time our score improved to 0.6770\n\nnow one thing we can also do is to get rid of class imabalnce as we saw in the beginning there is a huge imbalnce between classes so we need to handle this imbalnce\n\nthe techninque we are going to use is class weighting","a0764637":"converting sex to a numerical feature","14a5aaa4":"now we can use the same approcah to write our function","8b5ed99e":"* ## 2. SEX -- \nif the unknown values are also present in the test set we will replace the nan with an unknown class U otherwise we will look to find its value in train set first if not found we will drop the unknown","e1e8ab6d":"now lets make a prediction with this model","e3e59100":"now lets create a checkpoint so that we can store the weights of our model pause and continue the training the way we want. first lets create a directory to hold our checkpoint","1636955f":"now this was a baseline model which didn't use any validation set. the score of this model was 0.5757 so now we create a validation and use early stopping to save our model from overfitting","b29da57d":"we can see our val loss was going during the training so lets apply early stopping on val_loss and check how the model performs","a44ab7b0":"now since there are no null values for sex in the test set we can drop these two pateints out of our training set","089a3cc5":"* at last fixing the diagnosis columns","6a95f6f1":"we will be using a two branch model which will process the different tupes inputs\n* branch 1 -- processes the image data\n* branch 2 -- processes the tabular data\n* final model will predict on [branch 1+ branch 2]\nas shown in the figure \n\n![](https:\/\/www.pyimagesearch.com\/wp-content\/uploads\/2019\/02\/keras_multi_input_design.png)\n","74ece1c5":"disttribution by sex","21340a8c":"so we can see that the images are pretty big and we can use fed these directly to the the convnets so we will need to reduce the size of of these images","7152c63f":"* ## 3. anatom_site_general_challenge --\nnow we numerically encode the labels and use unknown class U for unknown labels","b2dad294":"# Image data processing\nnow lets look at image data","7e16dc26":"now we will feed this class weight to the model while training this will penalise the model weights for the imbalance between classes","34e73c11":"# model creation and training","95151912":"Hurrah! we replaced all the unknown values with a proper value and now both our test and train set are clean and contain no null values\n\nnow for once final time lets look at the count of all the features in the dataset","9a24a6c0":"now our final model is ready and we can now compile it. remember the metric we need is roc_auc_score","1051596d":"now we have  training and testing images preparesd\nlets prepare our numerical data\n"}}