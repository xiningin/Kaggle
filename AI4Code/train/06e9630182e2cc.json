{"cell_type":{"71ba926a":"code","290272fd":"code","1f644af5":"code","9076d0b5":"code","58bb8733":"code","77b3abc3":"code","d2765bfa":"code","f2545d8a":"code","a3b65168":"code","4a190d03":"code","fbc066fe":"code","eaad06d4":"code","8421f37d":"code","2fc3c5ad":"code","c2b6bd0a":"code","2660e38d":"code","d500b85b":"code","dca5f97f":"code","6c585b32":"code","a64753f6":"code","7e6b4d46":"code","41d0ff90":"code","a81e2bc0":"code","2eda2cc9":"code","a6f710cd":"code","9b68ac19":"code","ed30fd39":"code","2c3f11f6":"code","1e1a535d":"code","5084cff1":"code","3f972e82":"code","815de97d":"code","76166def":"code","79b2bc2f":"code","a3d62db8":"code","3433e66e":"code","c71d1b2e":"code","c68bd313":"code","2e9fdac6":"code","81f0bf8d":"code","aa6b5445":"code","61fc7845":"code","f9cb48ac":"code","335e2ab1":"code","9f5c6b04":"code","b97441dd":"code","bcb120aa":"code","40d1adc9":"markdown","9fb03f7e":"markdown","e44408be":"markdown","a439e588":"markdown","033ed7e4":"markdown","fc5b3591":"markdown","b33c871a":"markdown","2a1d4bea":"markdown","cec2f23a":"markdown","e31add8a":"markdown","d5251eee":"markdown","adf03fb9":"markdown","acdaedfc":"markdown","b7f7704a":"markdown","7f19bb11":"markdown","c0fc13ea":"markdown","0b755527":"markdown"},"source":{"71ba926a":"!pip install torchsummary","290272fd":"import seaborn as sns\n# PyTorch\nfrom torchvision import transforms, datasets, models\nimport torch\nfrom torch import optim, cuda\nfrom torch.utils.data import DataLoader, sampler\nimport torch.nn as nn\n\nimport warnings\nwarnings.filterwarnings('ignore', category=FutureWarning)\n\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import normalize\n\n# Data science tools\nimport numpy as np\nimport pandas as pd\nimport os\n\n# Image manipulations\nfrom PIL import Image\n# Useful for examining network\nfrom torchsummary import summary\n# Timing utility\nfrom timeit import default_timer as timer\n\n# Visualizations\nimport matplotlib.pyplot as plt\n%matplotlib inline\nplt.rcParams['font.size'] = 14","1f644af5":"ROOT = '\/kaggle\/input\/polytech-ds-2019\/polytech-ds-2019\/'","9076d0b5":"def imshow(image):\n    \"\"\"Display image\"\"\"\n    plt.figure(figsize=(6, 6))\n    plt.imshow(image)\n    plt.axis('off')\n    plt.show()\n\n\n# Example image\nx = Image.open(ROOT + 'training\/' + '0_0.jpg')\nnp.array(x).shape\nimshow(x)","58bb8733":"save_file_name = 'googlenet.pt'\ncheckpoint_path = 'googlenet.pth'\n\n# Change to fit hardware\nbatch_size = 128\n\n# Whether to train on a gpu\ntrain_on_gpu = cuda.is_available()\nprint(f'Train on gpu: {train_on_gpu}')\n\n# Number of gpus\nif train_on_gpu:\n    gpu_count = cuda.device_count()\n    print(f'{gpu_count} gpus detected.')\n    if gpu_count > 1:\n        multi_gpu = True\n    else:\n        multi_gpu = False","77b3abc3":"notrain_trans = transforms.Compose([\n    transforms.Resize(size=228),\n    transforms.CenterCrop(size=224),\n    transforms.ToTensor(),\n    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n])\n\nimage_transforms = {\n            # Train uses data augmentation\n            'training': transforms.Compose([        \n#         transforms.Resize(size=256),\n        transforms.RandomResizedCrop(size=228, scale=(0.8, 1.0)),\n        transforms.RandomRotation(degrees=20),\n        transforms.ColorJitter(),\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        transforms.CenterCrop(size=224),  \n        transforms.ToTensor(),\n        transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)), \n        transforms.RandomErasing(p=0.2, scale=(0.05, 0.2)),#, value='random'        \n    ]),\n            # Validation does not use augmentation\n            'validation': notrain_trans\n            \n        }","d2765bfa":"def imshow_tensor(image, ax=None, title=None):\n    \"\"\"Imshow for Tensor.\"\"\"\n\n    if ax is None:\n        fig, ax = plt.subplots()\n\n    # Set the color channel as the third dimension\n    image = image.numpy().transpose((1, 2, 0))\n\n    # Reverse the preprocessing steps\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    image = std * image + mean\n\n    # Clip the image pixel values\n    image = np.clip(image, 0, 1)\n\n    ax.imshow(image)\n    plt.axis('off')\n\n    return ax, image","f2545d8a":"t = image_transforms['training']\nplt.figure(figsize=(24, 24))\n\nfor i in range(16):\n    ax = plt.subplot(4, 4, i + 1)\n    _ = imshow_tensor(t(x), ax=ax)\n\nplt.tight_layout()","a3b65168":"class FoodDataset(torch.utils.data.Dataset):\n    def __init__(self, img_dir, image_transforms):\n        super().__init__()\n        # store directory names\n        self.img_dir = img_dir\n        \n        # use glob to get all image names\n        self.img_names = [filenames for _, _, filenames in os.walk(ROOT+img_dir)][0]\n\n        # PyTorch transforms\n        # Image transformations\n        \n        self.transform = image_transforms[img_dir]\n  \n    def __len__(self):\n        return len(self.img_names)\n    \n    def __getitem__(self,i):\n        return self._read_img_and_label(i)\n  \n    def _read_img_and_label(self, i):\n        img = Image.open(ROOT +self.img_dir + \"\/\" + self.img_names[i])\n        label = self.img_names[i].split(\"_\")[0]\n        img = self.transform(img)\n        return img, int(label)","4a190d03":"# Dataloader iterators\ndataloaders = {\n    'val': DataLoader(FoodDataset('validation', image_transforms), batch_size=batch_size, shuffle=True),\n    'train': DataLoader(FoodDataset('training', image_transforms), batch_size=batch_size, shuffle=True)\n}","fbc066fe":"n_classes = 11\ncriterion = nn.CrossEntropyLoss()\nmodel = models.googlenet(pretrained=True)\nmodel","eaad06d4":"#Get only the label for each image as a list\nlabels = [x[1] for x in FoodDataset('training', image_transforms)]\nn_train = []\n#Use the \"count\" method from Python lists\nfor x in range(n_classes):\n    i_train = labels.count(x)\n    n_train.append(i_train)\n    print(\"Number of\", x, \":\", i_train)","8421f37d":"# Domain Transfer\n# for name, param in model.named_parameters():\n#     if(\"bn\" not in name):        \n#         param.requires_grad = False\nn_inputs = model.fc.in_features\nmodel.fc = nn.Sequential(\n    nn.Linear(n_inputs, 128), nn.ReLU(), nn.Dropout(0.3),\n    nn.Linear(128, n_classes))\n\noptimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=0.01)\n\n\n\nif train_on_gpu:\n    model = model.to('cuda')\n\nif multi_gpu:\n    model = nn.DataParallel(model)\n    \ntotal_params = sum(p.numel() for p in model.parameters())\nprint(f'{total_params:,} total parameters.')\ntotal_trainable_params = sum(\n    p.numel() for p in model.parameters() if p.requires_grad)\nprint(f'{total_trainable_params:,} training parameters.')","2fc3c5ad":"if multi_gpu:\n    summary(\n        model.module,\n        input_size=(3, 224, 224),\n        batch_size=batch_size,\n        device='cuda')\nelse:\n    summary(\n        model, input_size=(3, 224, 224), batch_size=batch_size, device='cuda')","c2b6bd0a":"def train(model,\n          criterion,\n          optimizer,\n          train_loader,\n          valid_loader,\n          save_file_name,\n          max_epochs_stop=3,\n          n_epochs=20,\n          print_every=2):\n    \"\"\"Train a PyTorch Model\n\n    Params\n    --------\n        model (PyTorch model): cnn to train\n        criterion (PyTorch loss): objective to minimize\n        optimizer (PyTorch optimizier): optimizer to compute gradients of model parameters\n        train_loader (PyTorch dataloader): training dataloader to iterate through\n        valid_loader (PyTorch dataloader): validation dataloader used for early stopping\n        save_file_name (str ending in '.pt'): file path to save the model state dict\n        max_epochs_stop (int): maximum number of epochs with no improvement in validation loss for early stopping\n        n_epochs (int): maximum number of training epochs\n        print_every (int): frequency of epochs to print training stats\n\n    Returns\n    --------\n        model (PyTorch model): trained cnn with best weights\n        history (DataFrame): history of train and validation loss and accuracy\n    \"\"\"\n\n    # Early stopping intialization\n    epochs_no_improve = 0\n    valid_loss_min = np.Inf\n\n    valid_max_acc = 0\n    history = []\n\n    # Number of epochs already trained (if using loaded in model weights)\n    try:\n        print(f'Model has been trained for: {model.epochs} epochs.\\n')\n    except:\n        model.epochs = 0\n        print(f'Starting Training from Scratch.\\n')\n\n    overall_start = timer()\n\n    # Main loop\n    for epoch in range(n_epochs):\n\n        # keep track of training and validation loss each epoch\n        train_loss = 0.0\n        valid_loss = 0.0\n\n        train_acc = 0\n        valid_acc = 0\n\n        # Set to training\n        model.train()\n        start = timer()\n\n        # Training loop\n        for ii, (data, target) in enumerate(train_loader):\n            # Tensors to gpu\n            if train_on_gpu:\n                data, target = data.cuda(), target.cuda()\n\n            # Clear gradients\n            optimizer.zero_grad()\n            # Predicted outputs are log probabilities\n            output = model(data)\n\n            # Loss and backpropagation of gradients\n            loss = criterion(output, target)\n            loss.backward()\n\n            # Update the parameters\n            optimizer.step()\n\n            # Track train loss by multiplying average loss by number of examples in batch\n            train_loss += loss.item() * data.size(0)\n\n            # Calculate accuracy by finding max log probability\n            _, pred = torch.max(output, dim=1)\n            correct_tensor = pred.eq(target.data.view_as(pred))\n            # Need to convert correct tensor from int to float to average\n            accuracy = torch.mean(correct_tensor.type(torch.FloatTensor))\n            # Multiply average accuracy times the number of examples in batch\n            train_acc += accuracy.item() * data.size(0)\n\n            # Track training progress\n            print(\n                f'Epoch: {epoch}\\t{100 * (ii + 1) \/ len(train_loader):.2f}% complete. {timer() - start:.2f} seconds elapsed in epoch.',\n                end='\\r')\n\n        # After training loops ends, start validation\n        else:\n            model.epochs += 1\n\n            # Don't need to keep track of gradients\n            with torch.no_grad():\n                # Set to evaluation mode\n                model.eval()\n\n                # Validation loop\n                for data, target in valid_loader:\n                    # Tensors to gpu\n                    if train_on_gpu:\n                        data, target = data.cuda(), target.cuda()\n\n                    # Forward pass\n                    output = model(data)\n\n                    # Validation loss\n                    loss = criterion(output, target)\n                    # Multiply average loss times the number of examples in batch\n                    valid_loss += loss.item() * data.size(0)\n\n                    # Calculate validation accuracy\n                    _, pred = torch.max(output, dim=1)\n                    correct_tensor = pred.eq(target.data.view_as(pred))\n                    accuracy = torch.mean(\n                        correct_tensor.type(torch.FloatTensor))\n                    # Multiply average accuracy times the number of examples\n                    valid_acc += accuracy.item() * data.size(0)\n\n                # Calculate average losses\n                train_loss = train_loss \/ len(train_loader.dataset)\n                valid_loss = valid_loss \/ len(valid_loader.dataset)\n\n                # Calculate average accuracy\n                train_acc = train_acc \/ len(train_loader.dataset)\n                valid_acc = valid_acc \/ len(valid_loader.dataset)\n\n                history.append([train_loss, valid_loss, train_acc, valid_acc])\n\n                # Print training and validation results\n                if (epoch + 1) % print_every == 0:\n                    print(\n                        f'\\nEpoch: {epoch} \\tTraining Loss: {train_loss:.4f} \\tValidation Loss: {valid_loss:.4f}'\n                    )\n                    print(\n                        f'\\t\\tTraining Accuracy: {100 * train_acc:.2f}%\\t Validation Accuracy: {100 * valid_acc:.2f}%'\n                    )\n\n                # Save the model if validation loss decreases\n                if valid_loss < valid_loss_min:\n                    # Save model\n                    torch.save(model.state_dict(), save_file_name)\n                    # Track improvement\n                    epochs_no_improve = 0\n                    valid_loss_min = valid_loss\n                    valid_best_acc = valid_acc\n                    best_epoch = epoch\n\n                # Otherwise increment count of epochs with no improvement\n                else:\n                    epochs_no_improve += 1\n                    # Trigger early stopping\n                    if epochs_no_improve >= max_epochs_stop:\n                        print(\n                            f'\\nEarly Stopping! Total epochs: {epoch}. Best epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n                        )\n                        total_time = timer() - overall_start\n                        print(\n                            f'{total_time:.2f} total seconds elapsed. {total_time \/ (epoch+1):.2f} seconds per epoch.'\n                        )\n\n                        # Load the best state dict\n                        model.load_state_dict(torch.load(save_file_name))\n                        # Attach the optimizer\n                        model.optimizer = optimizer\n\n                        # Format history\n                        history = pd.DataFrame(\n                            history,\n                            columns=[\n                                'train_loss', 'valid_loss', 'train_acc',\n                                'valid_acc'\n                            ])\n                        return model, history\n\n    # Attach the optimizer\n    model.optimizer = optimizer\n    # Record overall time and print out stats\n    total_time = timer() - overall_start\n    print(\n        f'\\nBest epoch: {best_epoch} with loss: {valid_loss_min:.2f} and acc: {100 * valid_acc:.2f}%'\n    )\n    print(\n        f'{total_time:.2f} total seconds elapsed. {total_time \/ (epoch+1):.2f} seconds per epoch.'\n    )\n    # Format history\n    history = pd.DataFrame(\n        history,\n        columns=['train_loss', 'valid_loss', 'train_acc', 'valid_acc'])\n    return model, history","2660e38d":"model, history = train(\n    model,\n    criterion,\n    optimizer,\n    dataloaders['train'],\n    dataloaders['val'],\n    save_file_name=save_file_name,\n    max_epochs_stop=8,\n    n_epochs=20,\n    print_every=2)","d500b85b":"model.eval()\n\npreds, y_test = np.array([]), np.array([])\n\nfor i, batch in enumerate(dataloaders['val']):\n\n  with torch.no_grad():\n    # Get a batch from the dataloader\n    x = batch[0]\n    labels = batch[1]\n\n    # move the batch to GPU\n    x = x.cuda()\n    labels = labels.cuda()\n\n    # Compute the network output\n    y = model(x)\n\n    # Compute the loss\n    loss = criterion(y, labels)\n    \n    ## Store all the predictions an labels for later\n    preds = np.hstack([preds, y.max(1)[1].cpu().numpy()])\n    y_test = np.hstack([y_test, labels.cpu().numpy()])\n","dca5f97f":"def show_confusion_matrix(pred, Y_TEST, classes):\n\n    cm = confusion_matrix(y_true=Y_TEST, y_pred=pred)\n    cm = normalize(cm,axis=1,norm='l1')\n\n    df_cm = pd.DataFrame(cm, index = classes, columns = classes)\n\n    plt.figure(figsize=(30,15))\n\n    cmap = sns.cubehelix_palette(light=1, as_cmap=True)\n    sns.heatmap(df_cm, annot=True,cmap=cmap)\n    plt.title('Confusion Matrix',fontdict={'fontsize':20})\n    plt.xlabel('Predicted labels')\n    plt.ylabel('True labels')\n    plt.show\n\n\nshow_confusion_matrix(preds, y_test, list(range(11)))","6c585b32":"plt.figure(figsize=(8, 6))\nfor c in ['train_loss', 'valid_loss']:\n    plt.plot(\n        history[c], label=c)\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Average Negative Log Likelihood')\nplt.title('Training and Validation Losses')","a64753f6":"plt.figure(figsize=(8, 6))\nfor c in ['train_acc', 'valid_acc']:\n    plt.plot(\n        100 * history[c], label=c)\nplt.legend()\nplt.xlabel('Epoch')\nplt.ylabel('Average Accuracy')\nplt.title('Training and Validation Accuracy')","7e6b4d46":"def save_checkpoint(model, path):\n    \"\"\"Save a PyTorch model checkpoint\n\n    Params\n    --------\n        model (PyTorch model): model to save\n        path (str): location to save model. Must start with `model_name-` and end in '.pth'\n\n    Returns\n    --------\n        None, save the `model` to `path`\n\n    \"\"\"\n    \n    # Basic details\n    checkpoint = {\n        'epochs': model.epochs,\n    }\n\n    # Extract the final classifier and the state dictionary\n    if multi_gpu:\n        checkpoint['fc'] = model.module.fc\n        checkpoint['state_dict'] = model.module.state_dict()\n    else:\n        checkpoint['fc'] = model.fc\n        checkpoint['state_dict'] = model.state_dict()\n\n    # Add the optimizer\n    checkpoint['optimizer'] = model.optimizer\n    checkpoint['optimizer_state_dict'] = model.optimizer.state_dict()\n\n    # Save the data to the path\n    torch.save(checkpoint, path)","41d0ff90":"save_checkpoint(model, path=checkpoint_path)","a81e2bc0":"def load_checkpoint(path):\n    \"\"\"Load a PyTorch model checkpoint\n\n    Params\n    --------\n        path (str): saved model checkpoint. Must start with `model_name-` and end in '.pth'\n\n    Returns\n    --------\n        None, save the `model` to `path`\n\n    \"\"\"\n\n    # Load in checkpoint\n    checkpoint = torch.load(path)\n\n\n    model = models.googlenet(pretrained=True)\n    for name, param in model.named_parameters():\n        param.requires_grad = True\n        if(\"bn\" in name):        \n            param.requires_grad = False\n    # Make sure to set parameters as not trainable\n#         for param in model.parameters():\n#             param.requires_grad = False\n    model.fc = checkpoint['fc']\n\n    # Load in the state dict\n    model.load_state_dict(checkpoint['state_dict'])\n\n    total_params = sum(p.numel() for p in model.parameters())\n    print(f'{total_params:,} total parameters.')\n    total_trainable_params = sum(\n        p.numel() for p in model.parameters() if p.requires_grad)\n    print(f'{total_trainable_params:,} total gradient parameters.')\n\n    # Move to gpu\n    if multi_gpu:\n        model = nn.DataParallel(model)\n\n    if train_on_gpu:\n        model = model.to('cuda')\n\n    # Model basics\n    model.epochs = checkpoint['epochs']\n\n    # Optimizer\n    optimizer = checkpoint['optimizer']\n    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n\n    return model, optimizer","2eda2cc9":"model, optimizer = load_checkpoint(path='\/kaggle\/input\/resnet50-file-checkpoint\/' + checkpoint_path)\nif multi_gpu:\n    summary(model.module, input_size=(3, 224, 224), batch_size=batch_size)\nelse:\n    summary(model, input_size=(3, 224, 224), batch_size=batch_size)","a6f710cd":"# for g in optimizer.param_groups:\n#     g['lr'] = 0.0005\n# model, history = train(\n#     model,\n#     criterion,\n#     optimizer,\n#     dataloaders['train'],\n#     dataloaders['val'],\n#     save_file_name=save_file_name,\n#     max_epochs_stop=8,\n#     n_epochs=20,\n#     print_every=2)","9b68ac19":"def process_image(image_path):\n    \"\"\"Process an image path into a PyTorch tensor\"\"\"\n\n    image = Image.open(image_path)\n    # Resize\n    img = image.resize((228, 228))\n\n    # Center crop\n    width = 228\n    height = 228\n    new_width = 224\n    new_height = 224\n\n    left = (width - new_width) \/ 2\n    top = (height - new_height) \/ 2\n    right = (width + new_width) \/ 2\n    bottom = (height + new_height) \/ 2\n    img = img.crop((left, top, right, bottom))\n\n    # Convert to numpy, transpose color dimension and normalize\n    img = np.array(img).transpose((2, 0, 1)) \/ 256\n\n    # Standardization\n    means = np.array([0.5, 0.5, 0.5]).reshape((3, 1, 1))\n    stds = np.array([0.5, 0.5, 0.5]).reshape((3, 1, 1))\n\n    img = img - means\n    img = img \/ stds\n\n    img_tensor = torch.Tensor(img)\n\n    return img_tensor","ed30fd39":"def predict(image_path, model, topk=5):\n    \"\"\"Make a prediction for an image using a trained model\n\n    Params\n    --------\n        image_path (str): filename of the image\n        model (PyTorch model): trained model for inference\n        topk (int): number of top predictions to return\n\n    Returns\n\n    \"\"\"\n\n    # Convert to pytorch tensor\n    img_tensor = process_image(image_path)\n\n    # Resize\n    if train_on_gpu:\n        img_tensor = img_tensor.view(1, 3, 224, 224).cuda()\n    else:\n        img_tensor = img_tensor.view(1, 3, 224, 224)\n\n    # Set to evaluation\n    with torch.no_grad():\n        model.eval()\n        # Model outputs log probabilities\n        out = model(img_tensor)\n        ps = torch.exp(out)\n\n        # Find the topk predictions\n        topk, topclass = ps.topk(topk, dim=1)\n\n        # Extract the actual classes and probabilities\n        top_classes = [\n            class_ for class_ in topclass.cpu().numpy()[0]\n        ]\n        top_p = topk.cpu().numpy()[0]\n\n        return img_tensor.cpu().squeeze(), top_p, top_classes","2c3f11f6":"def predict2csv(model):\n    ls_id = []\n    ls_predict_category = []\n    root = testdir + '0\/'\n    for i in os.listdir(root):\n        ls_id.append(str(os.path.splitext(i)[0]))\n        ls_predict_category.append(\" \" + str(predict(root + i, model)[2][0]))\n    pd_submission = pd.DataFrame({'Id': ls_id,\n                                 'Category': ls_predict_category}).sort_values('Id')\n    pd_submission.to_csv('submission.csv', index=False, encoding='utf_8_sig')\n    return pd_submission","1e1a535d":"!mkdir \/kaggle\/evaluation\n!mkdir \/kaggle\/evaluation\/0\n!cp \/kaggle\/input\/polytech-ds-2019\/polytech-ds-2019\/kaggle_evaluation\/* \/kaggle\/evaluation\/0","5084cff1":"testdir = '\/kaggle\/evaluation\/'\neval_data = datasets.ImageFolder(root=testdir, transform=notrain_trans)\ndataloaders['test'] = DataLoader(eval_data, batch_size=batch_size, shuffle=False)       \npd_submission = predict2csv(model)\npd_submission.head(20)","3f972e82":"def display_prediction(image_path, model, topk):\n    \"\"\"Display image and preditions from model\"\"\"\n\n    # Get predictions\n    img, ps, classes = predict(image_path, model, topk)\n    # Convert results to dataframe for plotting\n    result = pd.DataFrame({'p': ps}, index=classes)\n\n    # Show the image\n    plt.figure(figsize=(16, 5))\n    ax = plt.subplot(1, 2, 1)\n    ax, img = imshow_tensor(img, ax=ax)\n\n    ax = plt.subplot(1, 2, 2)\n    # Plot a bar plot of predictions\n    result.sort_values('p')['p'].plot.barh(color='blue', edgecolor='k', ax=ax)\n    plt.xlabel('Predicted Probability')\n    plt.tight_layout()","815de97d":"display_prediction(ROOT + 'training\/' + '0_0.jpg', model, topk=5)","76166def":"**Testing Accuracy**\n\nImage identification models are usually assessed in terms of topk accuracy (for example the vgg16 model gets 28.41% top1 error and 9.62% top5 error on Imagenet). We'll assess out model by the top1 and top5 accuracy, that is, the percentage of predictions it gets exactly correct, and the percentage of predictions where the real class is in the top 5 actual classes.\n\nThe function below computes accuracy for a prediction and a target in terms of topk.","79b2bc2f":"def accuracy(output, target, topk=(1, )):\n    \"\"\"Compute the topk accuracy(s)\"\"\"\n    if train_on_gpu:\n        output = output.to('cuda')\n        target = target.to('cuda')\n\n    with torch.no_grad():\n        maxk = max(topk)\n        batch_size = target.size(0)\n\n        # Find the predicted classes and transpose\n        _, pred = output.topk(k=maxk, dim=1, largest=True, sorted=True)\n        pred = pred.t()\n\n        # Determine predictions equal to the targets\n        correct = pred.eq(target.view(1, -1).expand_as(pred))\n\n        res = []\n\n        # For each k, find the percentage of correct\n        for k in topk:\n            correct_k = correct[:k].view(-1).float().sum(0, keepdim=True)\n            res.append(correct_k.mul_(100.0 \/ batch_size).item())\n        return res","a3d62db8":"testiter = iter(dataloaders['val'])\n# Get a batch of testing images and labels\nfeatures, targets = next(testiter)\n\nif train_on_gpu:\n    accuracy(model(features.to('cuda')), targets, topk=(1, 5))\nelse:\n    accuracy(model(features), targets, topk=(1, 5))","3433e66e":"def evaluate(model, test_loader, criterion, topk=(1, 5)):\n    \"\"\"Measure the performance of a trained PyTorch model\n\n    Params\n    --------\n        model (PyTorch model): trained cnn for inference\n        test_loader (PyTorch DataLoader): test dataloader\n        topk (tuple of ints): accuracy to measure\n\n    Returns\n    --------\n        results (DataFrame): results for each category\n\n    \"\"\"\n\n    classes = []\n    losses = []\n    # Hold accuracy results\n    acc_results = np.zeros((len(test_loader.dataset), len(topk)))\n    i = 0\n\n    model.eval()\n    with torch.no_grad():\n\n        # Testing loop\n        for data, targets in test_loader:\n\n            # Tensors to gpu\n            if train_on_gpu:\n                data, targets = data.to('cuda'), targets.to('cuda')\n\n            # Raw model output\n            out = model(data)\n            # Iterate through each example\n            for pred, true in zip(out, targets):\n                # Find topk accuracy\n                acc_results[i, :] = accuracy(\n                    pred.unsqueeze(0), true.unsqueeze(0), topk)\n                classes.append(true.item())\n                # Calculate the loss\n                loss = criterion(pred.view(1, n_classes), true.view(1))\n                losses.append(loss.item())\n                i += 1\n\n    # Send results to a dataframe and calculate average across classes\n    results = pd.DataFrame(acc_results, columns=[f'top{i}' for i in topk])\n    results['class'] = classes\n    results['loss'] = losses\n    results = results.groupby(classes).mean()\n\n    return results.reset_index().rename(columns={'index': 'class'})","c71d1b2e":"criterion = nn.CrossEntropyLoss()#NLLLoss()\n# Evaluate the model on all the training data\nresults = evaluate(model, dataloaders['val'], criterion)\nresults = results.loc[:,~results.columns.duplicated()]\nresults.head()","c68bd313":"#Get only the label for each image as a list\nlabels = [x[1] for x in FoodDataset('validation', image_transforms)]\nn_val = []\n#Use the \"count\" method from Python lists\nfor x in range(n_classes):\n    i_val = labels.count(x)\n    n_val.append(i_val)\n    print(\"Number of\", x, \":\", n_val)\n    \ncat_df = pd.DataFrame({'category': list(range(n_classes)),\n                       'n_train': n_train,#, 'n_test': n_test\n                       'n_valid': n_val})","2e9fdac6":"print(results)","81f0bf8d":"results['n_train']=n_train\nresults['n_valid']=n_val\n# results = results.merge(cat_df, left_on='class', right_on='category').\\\n#     drop(columns=['category'])\n\n# Plot using seaborn\nsns.lmplot(\n    y='top1', x='n_train', data=results, height=6)\nplt.xlabel('images')\nplt.ylabel('Accuracy (%)')\nplt.title('Top 1 Accuracy vs Number of Training Images')\nplt.ylim(-5, 105)","aa6b5445":"print('Category with minimum accuracy.')\nresults.loc[results['top1'].idxmin]\n\nprint('Category with minimum images.')\nresults.loc[results['n_train'].idxmin]","61fc7845":"sns.lmplot(\n    y='top5', x='n_train', data=results, height=6)\nplt.xlabel('images')\nplt.ylabel('Accuracy (%)')\nplt.title('Top 5 Accuracy vs Number of Training Images')\nplt.ylim(-5, 105)","f9cb48ac":"# Weighted column of test images\nresults['weighted'] = results['n_valid'] \/ results['n_valid'].sum()\n\n# Create weighted accuracies\nfor i in (1, 5):\n    results[f'weighted_top{i}'] = results['weighted'] * results[f'top{i}']\n\n# Find final accuracy accounting for frequencies\ntop1_weighted = results['weighted_top1'].sum()\ntop5_weighted = results['weighted_top5'].sum()\nloss_weighted = (results['weighted'] * results['loss']).sum()\n\nprint(f'Final test cross entropy per image = {loss_weighted:.4f}.')\nprint(f'Final test top 1 weighted accuracy = {top1_weighted:.2f}%')\nprint(f'Final test top 5 weighted accuracy = {top5_weighted:.2f}%')","335e2ab1":"croc1 = testdir + '0\/0.jpg'\ncroc2 = testdir + '0\/1.jpg'\ncroc3 = testdir + '0\/10.jpg'\n\ndisplay_prediction(croc1, model, 5)\ndisplay_prediction(croc2, model, 5)\ndisplay_prediction(croc3, model, 5)","9f5c6b04":"def display_category(model, category, n=4):\n    \"\"\"Display predictions for a category    \n    \"\"\"\n    category_results = results.loc[results['class'] == category]\n    print(category_results.iloc[:, :6], '\/n')\n\n    images = np.random.choice(\n        os.listdir(ROOT+'\/validation'), size=4, replace=False)\n\n    for img in images:\n        display_prediction(ROOT+'\/validation' + '\/' + img, model, 5)","b97441dd":"display_category(model, '0')","bcb120aa":"display_category(model, '3')","40d1adc9":"# 6 Conclusions\n\nThis project taught us the basics of using PyTorch and pretrained neural networks for image recognition. We saw how to take a network that was trained on a large set of images and apply it successfully to a different task. Along the way, we learned a number of useful concepts for working with cnns in PyTorch including how to get our data into a model. The end result is a capable model trained in far less time than one trained from starting weights.\n\nThe performance of the system is high, and is considered acceptable from a usage point of view. However, the CNNs need high-performance computing machines in order toexperiment on the huge multi-media datasets. The CNN is capable of train highly non-linear data, and for that in contrast, it takes more computational time to train the network.However, the performance matters a lot, and once the systemis properly trained, the system can produce the results in less time. The images are properly preprocessed and all kinds of images are tested with CNN. From this, it is concluded that CNNs are more suitable for classifying the images when thenumber of classes are more.The task of image classi\ufb01cation can be extended using prominent features that can categorize food images. Since the CNNs are consuming high computational time, the feature-based approach is highly appreciable. A multi-level classi\ufb01cation approach (hierarchical approach) is suitable to avoid mis-classi\ufb01cations when the number of classes is more.\n\nThrough the above experiments, we can find that some food pictures can not have only one label, but can have multiple labels, so you can consider establishing a multi-classification model to make the results more accurate. And it can be used in conjunction with image segmentation technology to detect targets for better food identification.\n\nSome of the ideas covered in this notebook were:\n\n* PyTorch basics\n* Data transformations\n* Training data augmentation\n* Transfer Learning for object recognition\n* Training a PyTorch model with early stopping on a validation set\n* Inference using a PyTorch model","9fb03f7e":"### 1.4 Image Preprocessing\nTo prepare the images for our network, we have to resize them to 224 x 224 and normalize each color channel by subtracting a mean value and dividing by a standard deviation. We will also augment our training data in this stage. These operations are done using image transforms, which prepare our data for a neural network.\n","e44408be":"### 1.5 Data Iterators\n\nTo avoid loading all of the data into memory at once, we use training DataLoaders. First, we create a dataset object from the image folders, and then we pass these to a DataLoader. At training time, the DataLoader will load the images from disk, apply the transformations, and yield a batch. To train and validation, we'll iterate through all the batches in the respective DataLoader.\n\nOne crucial aspect is to shuffle the data before passing it to the network. This means that the ordering of the image categories changes on each pass through the data (one pass through the data is one training epoch).","a439e588":"Score: 88\n# Food Classification\n\n* **1 Data**\n    * 1.1 Load data\n    * 1.2 Display samples\n    * 1.3 Data augumentation\n    * 1.4 Image Preprocessing\n    * 1.5 Data Iterators\n* **2 Network**\n    * 2.1 Process to Use Pre-Trained Model\n    * 2.1 Training Loss and Optimizer\n    * 2.3 Add on Custom Classifier\n* **3 Training**\n    * 3.1 Training network\n    * 3.2 Training results\n* **4 Testing**\n    * 4.1 Confusion matrix\n    * 4.2 Predictions\n    * 4.3 Display Predictions\n    * 4.4 Evaluate Model Over All Classes\n    * 4.5 Test Results\n* **5 Progress**\n* **6 Conclusion**","033ed7e4":"# 5 Progress\nWe use  an approach of convolutional neural networks  to classify images of food. Unlike the traditional arti\ufb01cial neural networks, convolutional neural networks have thecapability of estimating the score function directly from imagepixels. A 2D convolution layer has been utilised which createsa convolution kernel that is convolved with the layer input toproduce a tensor of outputs. There are multiple such layers, andthe outputs are concatenated at parts to form the \ufb01nal tensor ofoutputs. We also build train model for the data, and the features extracted from this are used to train the network. Our program can get an accuracy of 88.04% for the classes of the FOOD-101dataset.\n\nAccording to the classification of cats and dogs on lab, we chose ResNet-18 at the beginning and found that the results are not very good. Then we consulted the PyTorch document and obtained preliminary results by simply using each model. We finally decided to use GoogleNet and then fine-tuned the pre-training. Model, change the last layer structure. And we used data enhancement, using various transformations on the image to increase the robustness of the model. In addition, we also added Early-stopping during training to prevent over-fitting. We save the model file every time we train to prevent accidental interruption of training and can start training warmly.","fc5b3591":"# 4 Testing\n### 4.1 Confusion matrix","b33c871a":"### 1.3 Data augumentation\u00b6\nBecause there are a limited number of images in some categories, we can use image augmentation to artificially increase the number of images \"seen\" by the network. This means for training, we randomly resize and crop the images and also flip them horizontally. A different random transformation is applied each epoch (while training), so the network effectively sees many different versions of the same image. All of the data is also converted to Torch Tensors before normalization. The validation and testing data is not augmented but is only resized and normalized. The normalization values are standardized for Imagenet.","2a1d4bea":"### 4.4 Evaluate Model Over All Classes\n\nThe next function iterates through the testing set in order to make predictions for each image. It calculates performance for each category.","cec2f23a":"### 1.2 Display samples","e31add8a":"### 3.2 Training Results","d5251eee":"### 4.3 Display Predictions\n\nThis function displays the picture along with the topk predictions from the model. The title over the image displays the true class.","adf03fb9":"### 2.3 Add on Custom Classifier\n\nWe'll train a classifier consisting of the following layers\n\n* Fully connected with ReLU activation (n_inputs, 256)\n* Dropout with 40% chance of dropping\n* Fully connected with log softmax output (256, n_classes)\n\nTo build our custom classifier, we use the nn.Sequential() module which allows us to specify each layer one after the other. We assign our custom classifier to the final classifier layer in the already trained vgg network. When we add on the extra layers, they are set to require_grad=True by default. These will be the only layers that are trained.","acdaedfc":"# 3 Training\nFor training, we iterate through the train DataLoader, each time passing one batch through the model. One complete pass through the training data is known as an epoch, and we train for a set number of epochs or until early stopping kicks in (more below). After each batch, we calculate the loss (with criterion(output, targets)) and then calculate the gradients of the loss with respect to the model parameters with loss.backward(). This uses autodifferentiation and backpropagation to calculate the gradients.\n\nAfter calculating the gradients, we call optimizer.step() to update the model parameters with the gradients. This is done on every training batch so we are implementing AdamW. For each batch, we also compute the accuracy for monitoring and after the training loop has completed, we start the validation loop. This will be used to carry out early stopping.\n\n### 3.1 Training network\n\nEarly stopping halts the training when the validation loss has not decreased for a number of epochs. Each time the validation loss does decrease, the model weights are saved so we can later load in the best model. Early stopping is an effective method to prevent overfitting on the training data. If we continue training, the training loss will continue to decrease, but the validation loss will increase because the model is starting to memorize the training data. Early stopping prevents this from happening, and, if we save the model each epoch when the validation loss decreases, we are able to retrieve the model that does best on the validation data.","b7f7704a":"# 1 Data\n### 1.1 Load data","7f19bb11":"### 4.5 Test Results\n\nWe'd expect the model to do better on those classes for which it had the most training images. We can see if that is the case.","c0fc13ea":"# 2 Network\n### 2.1 Process to Use Pre-Trained Model\nWe'll illustrate the process by using one model, googlenet.\nFirst off, load in the model with pretrained weights.\n\n\n### 2.2 Training Loss and Optimizer\nThe loss is the negative log likelihood and the optimizer is the Adamw optimizer. The negative log likelihood in PyTorch expects log probabilities so we need to pass it the raw output from the log softmax in our model's final layer. The optimizer is told to optimizer the model parameters (only a few of which require a gradient).\n\n* Loss (criterion): keeps track of the loss itself and the gradients of the loss with respect to the model parameters (weights)\n* Optimizer: updates the parameters (weights) with the gradients","0b755527":"### 4.2 Predictions\n\nThe next function makes predictions on a single image. It will return the top probabilities and classes."}}