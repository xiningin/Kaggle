{"cell_type":{"bb9587c9":"code","212c4bf5":"code","e94dd5fc":"code","f374e3a2":"code","24edb8ef":"code","a45f20c1":"code","2e311283":"code","8f374ddd":"code","6c131742":"code","7424a8cf":"code","02f47974":"code","c13eda83":"code","f638fea3":"code","98b5b735":"code","20a708a1":"code","9d87e4d7":"code","972ea437":"code","a1457688":"code","0678c7ca":"code","6099d81f":"code","6ffabe86":"code","bced8576":"code","d1bc404d":"code","f3ec7b15":"code","ea8135fc":"code","968d9eba":"code","1da710e2":"code","8ed8c6d6":"code","3a18c3c2":"code","04c9ca07":"code","88085cde":"code","22b4b1e9":"code","45f3ec8a":"code","33a466c6":"code","6644d872":"code","8f0951bb":"code","036da251":"code","ff806a05":"code","55e93c2e":"code","739ac68b":"code","f2873f71":"markdown","01ba3a4c":"markdown","815ba1fb":"markdown","1982c014":"markdown","487f954c":"markdown","193a1963":"markdown","3e48dd9a":"markdown","dc939d83":"markdown","33af53cf":"markdown","d5ceb178":"markdown","59bbecef":"markdown","3fc3c8fa":"markdown","9e5ab0c3":"markdown"},"source":{"bb9587c9":"# importing libraries\nimport os, time, random, sys\nos.environ['PYTHONHASHSEED']=str(1)\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set_style('whitegrid')\nplt.style.use('seaborn-deep')\nplt.style.use('fivethirtyeight')\nplt.rcParams['font.family'] = 'sans-serif'\nplt.rcParams['font.serif'] = 'Ubuntu'\nplt.rcParams['font.monospace'] = 'Ubuntu Mono'\nplt.rcParams['font.size'] = 10\nplt.rcParams['axes.labelsize'] = 12\nplt.rcParams['axes.titlesize'] = 12\nplt.rcParams['xtick.labelsize'] = 8\nplt.rcParams['ytick.labelsize'] = 8\nplt.rcParams['legend.fontsize'] = 12\nplt.rcParams['figure.titlesize'] = 14\nplt.rcParams['figure.figsize'] = (12, 8)\n\npd.options.mode.chained_assignment = None\npd.options.display.float_format = '{:.2f}'.format\npd.set_option('display.max_columns', 200)\npd.set_option('display.width', 400)\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport sklearn.utils as sku\nfrom skimage.io import imread\nfrom skimage.transform import resize\nseed = 12","212c4bf5":"import tensorflow as tf\nimport tensorflow_addons as tfa\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\nfrom keras import backend as K","e94dd5fc":"def runSeed():\n    global seed\n    os.environ['PYTHONHASHSEED']=str(seed)\n    tf.random.set_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)\n\nrunSeed()\n\n## Checking the GPU configuration\n!nvidia-smi","f374e3a2":"basePath = '\/kaggle\/input\/dockship-boat-type-classification\/'\ntrainPath = basePath + 'Train\/'\nos.listdir(trainPath)","24edb8ef":"def showImage(img):\n    plt.imshow(img)\n    plt.show()","a45f20c1":"# constants\nbatch_size = 128\nimg_tensor = (224, 224, 3)","2e311283":"# reading training and validation separately to prevent overlapping \n\ntrain_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255, \n                                                         validation_split=0.2,\n#                                                          shear_range=0.2, \n#                                                          zoom_range=0.2, \n                                                         horizontal_flip=True, \n#                                                          width_shift_range=0.1, \n#                                                          height_shift_range=0.1\n                                                        )\n\ntrain_generator=train_datagen.flow_from_directory(directory=trainPath,\n                                                  subset=\"training\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=img_tensor[:2])","8f374ddd":"# generate class weights as classes are imbalanced\nclass_weights = sku.class_weight.compute_class_weight('balanced',\n                                                      np.unique(train_generator.classes), \n                                                      train_generator.classes)\ntrain_class_weights = {i:x for i, x in enumerate(class_weights)}\ntrain_class_weights","6c131742":"valid_generator=train_datagen.flow_from_directory(directory=trainPath,\n                                                  subset=\"validation\",\n                                                  batch_size=batch_size,\n                                                  color_mode=\"rgb\",\n                                                  seed=seed,\n                                                  shuffle=True,\n                                                  class_mode=\"categorical\",\n                                                  target_size=img_tensor[:2])","7424a8cf":"test_datagen = k.preprocessing.image.ImageDataGenerator(rescale=1.\/255)\n\ntest_generator=test_datagen.flow_from_directory(basePath, \n                                                batch_size=1,\n                                                color_mode=\"rgb\",\n                                                seed=seed,\n                                                shuffle=False,\n                                                classes=['TEST'],\n                                                target_size=img_tensor[:2])","02f47974":"def plotModelHistory(h):\n    fig, ax = plt.subplots(1, 2, figsize=(15,4))\n    ax[0].plot(h.history['loss'])   \n    ax[0].plot(h.history['val_loss'])\n    ax[0].legend(['loss','val_loss'])\n    ax[0].title.set_text(\"Train loss vs Validation loss\")\n\n    ax[1].plot(h.history['categorical_accuracy'])   \n    ax[1].plot(h.history['val_categorical_accuracy'])\n    ax[1].legend(['categorical_accuracy','val_categorical_accuracy'])\n    ax[1].title.set_text(\"Train accuracy vs Validation accuracy\")\n\n    print(\"Max. Training Accuracy\", max(h.history['categorical_accuracy']))\n    print(\"Max. Validaiton Accuracy\", max(h.history['val_categorical_accuracy']))","c13eda83":"class myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        ACCURACY_THRESHOLD = 0.90\n        if(logs.get('val_categorical_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True","f638fea3":"def trainModel(model, epochs, optimizer, vb=1, modelName='model'):\n    bestModelPath = '.\/'+modelName+'_model.hdf5'\n    callback = myCallback()\n    callbacks_list = [\n        callback,\n        k.callbacks.ReduceLROnPlateau(monitor = 'loss', patience = 5, verbose = 1, min_lr=0.00001), \n        k.callbacks.EarlyStopping(monitor = 'val_categorical_accuracy', patience = 10, verbose = 1, restore_best_weights = True), \n        k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)\n    ]\n    model.compile(optimizer=optimizer,\n                  loss='categorical_crossentropy',\n                  metrics=[k.metrics.CategoricalAccuracy(), k.metrics.Precision(), k.metrics.Recall()]\n    )\n    train_generator.reset()\n    if (train_generator.n%train_generator.batch_size) == 0:\n        steps_per_epoch = int(train_generator.n\/train_generator.batch_size)\n    else:\n        steps_per_epoch = (train_generator.n\/\/train_generator.batch_size) + 1\n\n    if (valid_generator.n%valid_generator.batch_size) == 0:\n        validation_steps = int(valid_generator.n\/valid_generator.batch_size)\n    else:\n        validation_steps = (valid_generator.n\/\/valid_generator.batch_size) + 1\n\n    return model.fit_generator(generator=train_generator, steps_per_epoch=steps_per_epoch, \n                               validation_data=valid_generator, validation_steps=validation_steps, \n                               epochs=epochs, verbose=vb,\n#                                class_weight=train_class_weights,\n                               callbacks=callbacks_list)","98b5b735":"# evaluate model with time\ndef evaluateModel(model):\n    batch_size = valid_generator.batch_size\n    num_train_sequences = valid_generator.n\n    valid_generator.reset()\n    steps_per_epoch = 0\n    if (valid_generator.n%valid_generator.batch_size) == 0:\n        steps_per_epoch = int(valid_generator.n\/valid_generator.batch_size)\n    else:\n        steps_per_epoch = int(valid_generator.n\/\/valid_generator.batch_size) + 1\n\n    t1 = time.time()\n    model = k.models.load_model(model)\n    eval_results = model.evaluate_generator(valid_generator, steps=steps_per_epoch)\n    t2 = time.time()\n    print(f'\\nLoss: {eval_results[0]}, Accuracy: {eval_results[1]}, Precision: {eval_results[2]}, Recall: {eval_results[3]}')\n    print(f'Prediction Time per Image: {(t2-t1)\/valid_generator.n}')","20a708a1":"# predict images using model\ndef predictModel(modelPath):\n    batch_size = test_generator.batch_size\n    num_train_sequences = test_generator.n\n    steps_per_epoch = 0\n    if (test_generator.n%test_generator.batch_size) == 0:\n        steps_per_epoch = int(test_generator.n\/test_generator.batch_size)\n    else:\n        steps_per_epoch = int(test_generator.n\/\/test_generator.batch_size) + 1\n\n    test_generator.reset()\n\n    t1 = time.time()\n    model = k.models.load_model(modelPath)\n    predictions = model.predict_generator(test_generator, steps=steps_per_epoch, verbose=1)\n    t2 = time.time()\n    print(f'Prediction Time per Image: {(t2-t1)\/test_generator.n}')\n    \n    print(\"Generating Predictions file..\")    \n    labels = (train_generator.class_indices)\n    labels = dict((v,k) for k,v in labels.items())\n    predicted_class_indices=np.argmax(predictions, axis=1)\n    predictions_label = [labels[k] for k in predicted_class_indices]\n    filenames = list(map(lambda x: x.split('\/')[-1], test_generator.filenames))\n    submission=pd.DataFrame({\n        \"Image\":filenames, \n        \"Class\":predictions_label\n    })\n    submission_file = \"submission_\"+modelPath.split('\/')[-1].split('_')[0]+\".csv\"\n    submission.to_csv(submission_file,index=False)\n    print(f\"Submission file with {len(submission.values)} rows generated:\", submission_file)\n    submission.head()","9d87e4d7":"mobilenet = k.applications.mobilenet_v2.MobileNetV2(weights='imagenet', input_shape=img_tensor, include_top=False)\nmobilenet.trainable = False\n\nmodel = k.models.Sequential([\n                             mobilenet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.1),\n                             k.layers.Dense(128, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.1),\n                             k.layers.Dense(9, activation='softmax')\n])\nprint(model.summary())","972ea437":"history_1 = trainModel(model, 50, 'adam', modelName='mobilenet')","a1457688":"plotModelHistory(history_1)","0678c7ca":"resnet = k.applications.ResNet50(weights='imagenet', input_shape=img_tensor, include_top=False)\nresnet.trainable = False\n\nmodel_2 = k.models.Sequential([\n                             resnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(1024, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.3),\n\n                             k.layers.Dense(512, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(9, activation='softmax')\n])\nprint(model_2.summary())","6099d81f":"history_2 = trainModel(model_2, 50, 'adam', modelName='resnet')","6ffabe86":"plotModelHistory(history_2)","bced8576":"vgg16 = k.applications.VGG16(weights='imagenet', input_shape=img_tensor, include_top=False)\nvgg16.trainable = False\n\nmodel_3 = k.models.Sequential([\n                             vgg16,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(512, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(9, activation='softmax')\n])\nprint(model_3.summary())","d1bc404d":"history_3 = trainModel(model_3, 50, 'adam', modelName='vgg16')","f3ec7b15":"plotModelHistory(history_3)","ea8135fc":"nasnet = k.applications.nasnet.NASNetMobile(weights='imagenet', input_shape=img_tensor, include_top=False)\nnasnet.trainable = False\n\nmodel_4 = k.models.Sequential([\n                             nasnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(512, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(9, activation='softmax')\n])\nprint(model_4.summary())","968d9eba":"history_4 = trainModel(model_4, 50, 'adam', modelName='nasnet')","1da710e2":"plotModelHistory(history_4)","8ed8c6d6":"inceptionresnet = k.applications.InceptionResNetV2(weights='imagenet', input_shape=img_tensor, include_top=False)\ninceptionresnet.trainable = False\n\nmodel_5 = k.models.Sequential([\n                             inceptionresnet,\n                             tf.keras.layers.GlobalAveragePooling2D(),\n                             k.layers.Dropout(0.3),\n                             k.layers.Dense(512, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(256, activation='relu'),\n                             k.layers.BatchNormalization(),\n                             k.layers.Dropout(0.2),\n                             k.layers.Dense(9, activation='softmax')\n])\nprint(model_5.summary())","3a18c3c2":"history_5 = trainModel(model_5, 50, 'adam', modelName='inceptionresnet')","04c9ca07":"plotModelHistory(history_5)","88085cde":"# mobile net\nevaluateModel('\/kaggle\/working\/mobilenet_model.hdf5')","22b4b1e9":"# resnet50\nevaluateModel('.\/resnet_model.hdf5')","45f3ec8a":"# vgg16\nevaluateModel('.\/vgg16_model.hdf5')","33a466c6":"# nasnet\nevaluateModel('.\/nasnet_model.hdf5')","6644d872":"# inceptionresnet\nevaluateModel('.\/inceptionresnet_model.hdf5')","8f0951bb":"# mobile net\npredictModel('.\/mobilenet_model.hdf5')","036da251":"# resnet50\npredictModel('.\/resnet_model.hdf5')","ff806a05":"# vgg16\npredictModel('.\/vgg16_model.hdf5')","55e93c2e":"# nasnet\npredictModel('.\/nasnet_model.hdf5')","739ac68b":"# inceptionresnet\npredictModel('.\/inceptionresnet_model.hdf5')","f2873f71":"## Train MobileNetV2 - Light Model","01ba3a4c":"# Model Prediction","815ba1fb":"## Train InceptionResNetV2 - Heavy Model","1982c014":"## Setup Image Generator","487f954c":"# Model Building","193a1963":"# Model Evaluation","3e48dd9a":"## Train NASNetMobile - Light Model","dc939d83":"# Dockship - Boat Type Classification AI Challenge\n\nThe dataset contains images of 9 types of boats. It contains two directories \"TRAIN\" and \"TEST\" with 1162 and 300 images respectively. The training images are provided in the directory of the specific class itself. The names of the directories are \"class labels\" to be used for submission. The aim is to classify the \"TEST\" images into one of the 9 classes.\n\nClasses:-\n- ferry_boat\n- gondola\n- sailboat\n- cruise_ship\n- kayak\n- inflatable_boat\n- paper_boat\n- buoy\n- freight_boat\n\n# Reading & Understanding Data\n## Importing Libraries","33af53cf":"### Loading Dataset","d5ceb178":"## Train ResNet50 - Medium Model","59bbecef":"# Data Preparation\n","3fc3c8fa":"## Best Model\n\nInceptionResNet","9e5ab0c3":"## Train VGG16 - Medium Model"}}