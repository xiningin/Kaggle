{"cell_type":{"761284aa":"code","a270ed4e":"code","bfe9ed71":"code","df0f3043":"code","01f80e43":"code","33134faa":"code","234b5ed7":"code","78fb4ac4":"code","4b216949":"code","e3dccd5b":"code","97ad6618":"code","4d32c4e3":"code","f2f04bf7":"code","196df723":"code","2b9f8a49":"code","3c0bfe4c":"code","d827f923":"code","c58d46d7":"code","edf0d0c9":"markdown"},"source":{"761284aa":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))","a270ed4e":"import matplotlib.pyplot as plt\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import NuSVR\nfrom sklearn.kernel_ridge import KernelRidge\nfrom sklearn.metrics import mean_absolute_error, make_scorer\nfrom sklearn.model_selection import GridSearchCV","bfe9ed71":"train = pd.read_csv('..\/input\/train.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float64})","df0f3043":"train.head()","01f80e43":"# pandas doesn't show us all the decimals\npd.options.display.precision = 15","33134faa":"# much better!\ntrain.head()","234b5ed7":"from sklearn.linear_model import LinearRegression\ndef add_trend_feature(arr, abs_values=False):\n    idx = np.array(range(len(arr)))\n    if abs_values:\n        arr = np.abs(arr)\n    lr = LinearRegression()\n    lr.fit(idx.reshape(-1, 1), arr)\n    return lr.coef_[0]\n\nfrom scipy import stats","78fb4ac4":"# Create a training file with simple derived features\n\nrows = 150_000\nsegments = int(np.floor(train.shape[0] \/ rows))\n\nX_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n                       columns=['ave', 'std', 'max', 'min','q95','q99', 'q05','q01',\n                               'abs_max', 'abs_mean', 'abs_std', 'trend', 'abs_trend', 'iqr', \n                                'q999','q001','ave10'])\ny_train = pd.DataFrame(index=range(segments), dtype=np.float64,\n                       columns=['time_to_failure'])\n\nfor segment in tqdm(range(segments)):\n    seg = train.iloc[segment*rows:segment*rows+rows]\n    x = seg['acoustic_data'].values\n    y = seg['time_to_failure'].values[-1]\n    \n    y_train.loc[segment, 'time_to_failure'] = y\n    \n    X_train.loc[segment, 'ave'] = x.mean()\n    X_train.loc[segment, 'std'] = x.std()\n    X_train.loc[segment, 'max'] = x.max()\n    X_train.loc[segment, 'min'] = x.min()\n    X_train.loc[segment, 'q95'] = np.quantile(x,0.95)\n    X_train.loc[segment, 'q99'] = np.quantile(x,0.99)\n    X_train.loc[segment, 'q05'] = np.quantile(x,0.05)\n    X_train.loc[segment, 'q01'] = np.quantile(x,0.01)\n    \n    X_train.loc[segment, 'abs_max'] = np.abs(x).max()\n    X_train.loc[segment, 'abs_mean'] = np.abs(x).mean()\n    X_train.loc[segment, 'abs_std'] = np.abs(x).std()\n    X_train.loc[segment, 'trend'] = add_trend_feature(x)\n    X_train.loc[segment, 'abs_trend'] = add_trend_feature(x, abs_values=True)\n    \n    X_train.loc[segment, 'iqr'] = np.subtract(*np.percentile(x, [75, 25]))\n    X_train.loc[segment, 'q999'] = np.quantile(x,0.999)\n    X_train.loc[segment, 'q001'] = np.quantile(x,0.001)\n    X_train.loc[segment, 'ave10'] = stats.trim_mean(x, 0.1)","4b216949":"X_train.head()","e3dccd5b":"scaler = StandardScaler()\nscaler.fit(X_train)\nX_train_scaled = scaler.transform(X_train)","97ad6618":"scorer = make_scorer(mean_absolute_error, greater_is_better=False)\nparameters = [{ 'gamma': [0.6, 0.7, 0.8],\n               'C': [2.35, 2.4, 2.45, 2.5],\n              'nu': [0.85, 0.9, 0.95]}]\n\nreg1 = GridSearchCV(NuSVR(kernel='rbf', tol=0.01), parameters, cv = 3, scoring=scorer)\nreg1.fit(X_train_scaled, y_train.values.flatten())\ny_pred1 = reg1.predict(X_train_scaled)\n\nprint(reg1.best_params_)\nprint(reg1.best_score_)","4d32c4e3":"parameters = [{ 'gamma': [0.06, 0.1, 0.08, 0.09], #np.logspace(-2, 2, 5)\n               'alpha': [0.005, 0.01, 0.05]}]\n\nreg2 = GridSearchCV(KernelRidge(kernel='rbf'), parameters, cv = 3, scoring=scorer)\nreg2.fit(X_train_scaled, y_train.values.flatten())\ny_pred2 = reg2.predict(X_train_scaled)\n\nprint(reg2.best_params_)\nprint(reg2.best_score_)","f2f04bf7":"plt.tight_layout()\nf = plt.figure(figsize=(12, 6))\nf.add_subplot(1,2, 1)\nplt.scatter(y_train.values.flatten(), y_pred1)\nplt.title('reg1', fontsize=20)\nplt.xlim(0, 20)\nplt.ylim(0, 20)\nplt.xlabel('actual', fontsize=12)\nplt.ylabel('predicted', fontsize=12)\nplt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\nf.add_subplot(1,2, 2)\nplt.scatter(y_train.values.flatten(), y_pred2)\nplt.title('reg2', fontsize=20)\nplt.xlim(0, 20)\nplt.ylim(0, 20)\nplt.xlabel('actual', fontsize=12)\nplt.ylabel('predicted', fontsize=12)\nplt.plot([(0, 0), (20, 20)], [(0, 0), (20, 20)])\nplt.show(block=True)","196df723":"score1 = mean_absolute_error(y_train.values.flatten(), y_pred1)\nprint(f'Score1: {score1:0.3f}')\nscore2 = mean_absolute_error(y_train.values.flatten(), y_pred2)\nprint(f'Score2: {score2:0.3f}')\nscore3 = mean_absolute_error(y_train.values.flatten(), y_pred1*0.5+y_pred2*0.5)\nprint(f'Score3: {score3:0.3f}')","2b9f8a49":"submission = pd.read_csv('..\/input\/sample_submission.csv', index_col='seg_id')","3c0bfe4c":"X_test = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)","d827f923":"for seg_id in X_test.index:\n    seg = pd.read_csv('..\/input\/test\/' + seg_id + '.csv')\n    \n    x = seg['acoustic_data'].values\n    \n    X_test.loc[seg_id, 'ave'] = x.mean()\n    X_test.loc[seg_id, 'std'] = x.std()\n    X_test.loc[seg_id, 'max'] = x.max()\n    X_test.loc[seg_id, 'min'] = x.min()\n    X_test.loc[seg_id, 'q95'] = np.quantile(x,0.95)\n    X_test.loc[seg_id, 'q99'] = np.quantile(x,0.99)\n    X_test.loc[seg_id, 'q05'] = np.quantile(x,0.05)\n    X_test.loc[seg_id, 'q01'] = np.quantile(x,0.01)\n    \n    X_test.loc[seg_id, 'abs_max'] = np.abs(x).max()\n    X_test.loc[seg_id, 'abs_mean'] = np.abs(x).mean()\n    X_test.loc[seg_id, 'abs_std'] = np.abs(x).std()\n    X_test.loc[seg_id, 'trend'] = add_trend_feature(x)\n    X_test.loc[seg_id, 'abs_trend'] = add_trend_feature(x, abs_values=True)\n    \n    X_test.loc[seg_id, 'iqr'] = np.subtract(*np.percentile(x, [75, 25]))\n    X_test.loc[seg_id, 'q999'] = np.quantile(x,0.999)\n    X_test.loc[seg_id, 'q001'] = np.quantile(x,0.001)\n    X_test.loc[seg_id, 'ave10'] = stats.trim_mean(x, 0.1)","c58d46d7":"X_test_scaled = scaler.transform(X_test)\nsubmission['time_to_failure'] = reg1.predict(X_test_scaled)*0.5 + reg2.predict(X_test_scaled)*0.5\nsubmission.to_csv('submission.csv')","edf0d0c9":"- added Gaussian Process Regression with a generalised RBF kernel to the mix"}}