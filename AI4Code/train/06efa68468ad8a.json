{"cell_type":{"7eaaf3d9":"code","cd6d1bea":"code","04c90bf4":"code","ad73df62":"code","5cdc3a94":"code","58e1744c":"code","19528736":"code","718542f9":"code","29db9e77":"code","1854e8bf":"code","d0868f2f":"code","106a00a3":"code","f7fcda0f":"code","6a37d28c":"code","33a5c0f6":"markdown","3f708e75":"markdown","cf65d4a1":"markdown","1a6f8953":"markdown","1de9c259":"markdown","f6022a8a":"markdown","f3d8436c":"markdown","79c0d387":"markdown"},"source":{"7eaaf3d9":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os","cd6d1bea":"# imports used in this project\n\n# keras\nimport keras\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import EarlyStopping, ModelCheckpoint\n# keras layers\nfrom keras.layers import Activation, Dense, Input\nfrom keras.layers import Conv2D, Flatten\nfrom keras.layers import Reshape, Conv2DTranspose\nfrom keras.models import Model\nfrom keras import backend as K\nfrom keras.datasets import mnist\n# ploting\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg","04c90bf4":"# import MNIST dataset and format the images\n(x_train_imgs, _), (x_test_imgs, _) = mnist.load_data()\nimage_size = x_train_imgs.shape[1]\nx_train = np.reshape(x_train_imgs, [-1, image_size, image_size, 1])\nx_test = np.reshape(x_test_imgs, [-1, image_size, image_size, 1])\nx_train = x_train.astype('float32') \/ 255\nx_test = x_test.astype('float32') \/ 255","ad73df62":"# format image back to ordinary image format\ndef imageShowFormat(img):\n    image = img.reshape(image_size,image_size)\n    return (image*255).astype(np.uint8)","5cdc3a94":"# Create noised images\nnoise = np.random.normal(loc=0.5, scale=0.5, size=x_train.shape)\nx_train_noisy = x_train + noise\nnoise = np.random.normal(loc=0.5, scale=0.5, size=x_test.shape)\nx_test_noisy = x_test + noise\n# limit the noisy image's pixel to 0-1\nx_train_noisy = np.clip(x_train_noisy, 0., 1.)\nx_test_noisy = np.clip(x_test_noisy, 0., 1.)","58e1744c":"# Plot some of the normal&noised images\nfig = plt.figure(figsize=(8,8))\n# select 8 images\nimg_indexes = np.random.choice(len(x_train),8)\nfor i,img_index in enumerate(img_indexes):\n    original = x_train[img_index]\n    noised = x_train_noisy[img_index]\n    sp = plt.subplot(4,4,i*2+1)\n    sp.set_title('original')\n    sp.axis('off')\n    plt.imshow(imageShowFormat(original))\n    sp = plt.subplot(4,4,i*2+2)\n    sp.set_title('noised')\n    sp.axis('off')\n    plt.imshow(imageShowFormat(noised))","19528736":"# Encoder\n# input layer\nencoder_inputs = Input(shape=(image_size, image_size, 1), name='encoder_input')\n# convolutioning and shrink down\nencoder_1 = Conv2D(filters=32,kernel_size=3,strides=2,activation='relu',padding='same')(encoder_inputs)\nencoder_2 = Conv2D(filters=64,kernel_size=3,strides=2,activation='relu',padding='same')(encoder_1)\n# flatten and make latent\nencoder_flat = Flatten()(encoder_2)\nlatent_length = 16\nlatent = Dense(latent_length, name='latent_vector')(encoder_flat)\n# the encoder model\nencoder = Model(encoder_inputs, latent, name='encoder')\nencoder.summary()","718542f9":"# Decoder\n# latent input\ndecoder_inputs = Input(shape=(latent_length,), name='decoder_input')\n# a dense a layer to get enough output numbers\ndecoder_dense = Dense(encoder_2.shape[1]*encoder_2.shape[2]*encoder_2.shape[3])(decoder_inputs)\n# reshape to images\ndecoder_reshape = Reshape((encoder_2.shape[1],encoder_2.shape[2],encoder_2.shape[3]))(decoder_dense)\n# transpose the conv2d\ndecoder_bigger_1 = Conv2DTranspose(filters=64,kernel_size=3,strides=2,activation='relu',padding='same')(decoder_reshape)\ndecoder_bigger_2 = Conv2DTranspose(filters=32,kernel_size=3,strides=2,activation='relu',padding='same')(decoder_bigger_1)\ndecoder_single = Conv2DTranspose(filters=1,kernel_size=3,padding='same')(decoder_bigger_2)\n# the decoded image\ndecoder_outputs = Activation('sigmoid', name='decoder_output')(decoder_single)\n# the decoder model\ndecoder = Model(decoder_inputs, decoder_outputs, name='decoder')\ndecoder.summary()","29db9e77":"# AutoEncoder\nautoencoder = Model(encoder_inputs, decoder(encoder(encoder_inputs)), name='autoencoder')\nautoencoder.summary()","1854e8bf":"# callback for each epoch\nmodel_path = '\/kaggle\/working\/best_model.h5'\ncallbacks = [\n    # save model\n    ModelCheckpoint(filepath=model_path, monitor='val_loss', save_best_only=True)\n]","d0868f2f":"# compiling\nautoencoder.compile(loss='mse', optimizer='adam')\n# fitting\nautoencoder.fit(x_train_noisy,x_train,\n                validation_data=(x_test_noisy, x_test),\n                epochs=30,\n                batch_size=128,\n                callbacks=callbacks)","106a00a3":"# load the best model\nautoencoder.load_weights(model_path)","f7fcda0f":"# predict\ntest_denoised = autoencoder.predict(x_test_noisy)","6a37d28c":"fig = plt.figure(figsize=(6,16))\n# select 8 images\nimg_indexes = np.random.choice(len(x_test),8)\nfor i,img_index in enumerate(img_indexes):\n    original = x_test[img_index]\n    noised = x_test_noisy[img_index]\n    denoised = test_denoised[img_index]\n    sp = plt.subplot(8,3,i*3+1)\n    sp.set_title('original')\n    sp.axis('off')\n    plt.imshow(imageShowFormat(original))\n    sp = plt.subplot(8,3,i*3+2)\n    sp.set_title('noised')\n    sp.axis('off')\n    plt.imshow(imageShowFormat(noised))\n    sp = plt.subplot(8,3,i*3+3)\n    sp.set_title('denoised')\n    sp.axis('off')\n    plt.imshow(imageShowFormat(denoised))","33a5c0f6":"### Plotting the results!","3f708e75":"### Summary\n* The result looks good for such simple AutoDecoder model.\n* The purpose of encoder may be to get the features of the image, and the decoder is to generate image from the features. Obiviously more complicated images needs more length of latent array.\n* In my opinion, this kind of AutoEncoder might have some limitions. It depends hugely on the latent, and latent may not sufficiently represent all the information to re-generate the the whole denoised image. Maybe link the encoder's conv layer to decoder's convtranspose layer is a good idea.\n    ","cf65d4a1":"### Problem description\nDenoising photos of numbers.\n\n### Point\n* Review AutoEncoder.\n* Rethink what latent space means\n\n### Flow of this project\n* Get Mnist dataset, and create a noised counter part\n* Create AutoEncoder model with Keras\n* Training and Validating the model","1a6f8953":"### Use the Trained AutoEncoder model","1de9c259":"### Training the AutoEncoder","f6022a8a":"### Create the noised images","f3d8436c":"#### This is pretty noisy in my opinion...","79c0d387":"### Create AutoEncoder model"}}