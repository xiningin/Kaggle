{"cell_type":{"9c3ce32c":"code","28873f8d":"code","2b6c5fcf":"code","f36dfc19":"code","5ae3aed8":"code","e64a4181":"code","c5a2d5cd":"code","4cb6c4a5":"code","5325d721":"code","82589707":"code","a8fee043":"code","289664a2":"code","1324d3f1":"code","39495ab6":"code","764d0ce5":"code","95afc014":"code","ac0bbc55":"code","de1d9312":"code","92824c7c":"code","2ac13ada":"code","8c08dbe9":"code","fd7e29d2":"code","2622cbf7":"code","81f3e277":"code","8b23cd13":"code","c438ca36":"code","e1d1f8c3":"code","85172b61":"code","7796fbcd":"code","6b09caf6":"code","723dbbae":"code","78d9f3af":"code","ac1949c1":"code","b96b25c1":"code","334a0db8":"code","8c3398fe":"code","da260df7":"code","927bd897":"code","7d20200a":"code","ed1a7d11":"code","20ab46d3":"code","2939a296":"code","be161635":"code","228f43e2":"markdown","a4afb62c":"markdown","0d412df9":"markdown","802681fc":"markdown","7c124bdc":"markdown","b2b1c1ca":"markdown","fb750c16":"markdown","7587b539":"markdown","e83b93f2":"markdown","f5ad3dca":"markdown","c448da79":"markdown","f8003f23":"markdown","317982f9":"markdown","697e3d97":"markdown","6376db03":"markdown","a9dba1e3":"markdown","d3dc9137":"markdown","6c49c755":"markdown","c146e363":"markdown","c9ec8535":"markdown","d41510db":"markdown"},"source":{"9c3ce32c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","28873f8d":"import pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom collections import Counter\ngender_submission = pd.read_csv(\"..\/input\/titanic\/gender_submission.csv\")\ntest = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntrain = pd.read_csv(\"..\/input\/titanic\/train.csv\")","2b6c5fcf":"def detect_outliers(df,n,features):\n    \"\"\"\n    Takes a dataframe df of features and returns a list of the indices\n    corresponding to the observations containing more than n outliers according\n    to the Tukey method.\n    \"\"\"\n    outlier_indices = []\n    \n    # iterate over features(columns)\n    for col in features:\n        # 1st quartile (25%)\n        Q1 = np.percentile(df[col], 25)\n        # 3rd quartile (75%)\n        Q3 = np.percentile(df[col],75)\n        # Interquartile range (IQR)\n        IQR = Q3 - Q1\n        \n        # outlier step\n        outlier_step = 1.5 * IQR\n        \n        # Determine a list of indices of outliers for feature col\n        outlier_list_col = df[(df[col] < Q1 - outlier_step) | (df[col] > Q3 + outlier_step )].index\n        \n        # append the found outlier indices for col to the list of outlier indices \n        outlier_indices.extend(outlier_list_col)\n        \n    # select observations containing more than 2 outliers\n    outlier_indices = Counter(outlier_indices)        \n    multiple_outliers = list( k for k, v in outlier_indices.items() if v > n )\n    \n    return multiple_outliers   \n\n# detect outliers from Age, SibSp , Parch and Fare\nOutliers_to_drop = detect_outliers(train,2,[\"Age\",\"SibSp\",\"Parch\",\"Fare\"])","f36dfc19":"train.loc[Outliers_to_drop]","5ae3aed8":"train = train.drop(Outliers_to_drop, axis = 0).reset_index(drop=True)","e64a4181":"dataset =  pd.concat(objs=[train, test], axis=0).reset_index(drop=True)","c5a2d5cd":"dataset = dataset.fillna(np.nan)\ndataset.isnull().sum()","4cb6c4a5":"g = sns.heatmap(train[[\"Survived\",\"SibSp\",\"Parch\",\"Age\",\"Fare\"]].corr(),annot=True, fmt = \".2f\", cmap = \"coolwarm\")","5325d721":"# Explore SibSp feature vs Survived\ng = sns.factorplot(x=\"SibSp\",y=\"Survived\",data=train, kind=\"bar\", height = 5 , \npalette = \"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","82589707":"g  = sns.factorplot(x=\"Parch\",y=\"Survived\",data=train,kind=\"bar\", height = 6)\ng.despine(left=True)\ng = g.set_ylabels(\"survival probability\")","a8fee043":"a = train[\"Parch\"] \nind = list(a.index[a==4])\ntrain.loc[ind]","289664a2":"g = sns.FacetGrid(train, col='Survived')\ng = g.map(sns.distplot, \"Age\")","1324d3f1":"g = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 0) & (train[\"Age\"].notnull())], color=\"Red\", shade = True)\ng = sns.kdeplot(train[\"Age\"][(train[\"Survived\"] == 1) & (train[\"Age\"].notnull())], ax =g, color=\"Blue\", shade= True)\ng.set_xlabel(\"Age\")\ng.set_ylabel(\"Frequency\")\ng = g.legend([\"Not Survived\",\"Survived\"])","39495ab6":"g = sns.FacetGrid(train, col='Survived')\ng = g.map(sns.distplot, \"Fare\")","764d0ce5":"g = sns.barplot(x=\"Sex\",y=\"Survived\",data=train)\ng = g.set_ylabel(\"Survival Probability\")","95afc014":"g = sns.factorplot(x=\"Pclass\",y=\"Survived\",data=train,kind=\"bar\", height = 6 , \npalette = \"muted\")\ng.despine(right=True)\ng = g.set_ylabels(\"survival probability\")","ac0bbc55":"g = sns.factorplot(x = \"Embarked\", y = \"Survived\", data = train,kind = \"bar\", height = 6, palette = \"muted\")\ng.despine(left = False)\ng = g.set_ylabels(\"survival probability\")","de1d9312":"# Explore Pclass vs Embarked \ng = sns.factorplot(\"Pclass\", col=\"Embarked\",  data=train,\n                   size=6, kind=\"count\", palette=\"muted\")\ng.despine(left=True)\ng = g.set_ylabels(\"Count\")","92824c7c":"g = sns.factorplot(y=\"Age\",x=\"Sex\",data=dataset,kind=\"bar\")\ng = sns.factorplot(y=\"Age\",x=\"Sex\",hue=\"Pclass\", data=dataset,kind=\"bar\")\ng = sns.factorplot(y=\"Age\",x=\"Parch\", data=dataset,kind=\"bar\")\ng = sns.factorplot(y=\"Age\",x=\"SibSp\", data=dataset,kind=\"bar\")","2ac13ada":"dataset[\"Sex\"] = dataset[\"Sex\"].map({\"male\": 0, \"female\":1})\ng = sns.heatmap(dataset[[\"Age\",\"Sex\",\"SibSp\",\"Parch\",\"Pclass\"]].corr(),cmap=\"BrBG\",annot=True)","8c08dbe9":"dataset[\"Name\"].head()","fd7e29d2":"# Get Title from Name\ndataset_title = [i.split(\",\")[1].split(\".\")[0].strip() for i in dataset[\"Name\"]]\ndataset[\"Title\"] = pd.Series(dataset_title)\ndataset[\"Title\"].head()","2622cbf7":"g = sns.countplot(x=\"Title\",data=dataset)\ng = plt.setp(g.get_xticklabels(), rotation=45)","81f3e277":"# Convert to categorical values Title \ndataset[\"Title\"] = dataset[\"Title\"].replace(['Lady', 'the Countess','Countess','Capt', 'Col','Don', 'Dr', 'Major', 'Rev', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\ndataset[\"Title\"] = dataset[\"Title\"].map({\"Master\":0, \"Miss\":1, \"Ms\" : 1 , \"Mme\":1, \"Mlle\":1, \"Mrs\":1, \"Mr\":2, \"Rare\":3})\ndataset[\"Title\"] = dataset[\"Title\"].astype(int)\ndataset[\"Title\"].head()","8b23cd13":"g = sns.countplot(dataset[\"Title\"])\ng = g.set_xticklabels([\"Master\",\"Miss\/Ms\/Mme\/Mlle\/Mrs\",\"Mr\",\"Rare\"])","c438ca36":"g = sns.factorplot(x=\"Title\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_xticklabels([\"Master\",\"Miss-Mrs\",\"Mr\",\"Rare\"])\ng = g.set_ylabels(\"survival probability\")","e1d1f8c3":"# Create a family size descriptor from SibSp and Parch\ndataset[\"Fsize\"] = dataset[\"SibSp\"] + dataset[\"Parch\"] + 1\n\ng = sns.factorplot(x=\"Fsize\",y=\"Survived\",data = dataset)\ng = g.set_ylabels(\"Survival Probability\")","85172b61":"# Create new feature of family size\ndataset['Single'] = dataset['Fsize'].map(lambda s: 1 if s == 1 else 0)\ndataset['SmallF'] = dataset['Fsize'].map(lambda s: 1 if  s == 2  else 0)\ndataset['MedF'] = dataset['Fsize'].map(lambda s: 1 if 3 <= s <= 4 else 0)\ndataset['LargeF'] = dataset['Fsize'].map(lambda s: 1 if s >= 5 else 0)","7796fbcd":"dataset[['Fsize','Single','SmallF','MedF','LargeF']].head(\n                                                         )","6b09caf6":"g = sns.factorplot(x=\"Single\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"SmallF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"MedF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")\ng = sns.factorplot(x=\"LargeF\",y=\"Survived\",data=dataset,kind=\"bar\")\ng = g.set_ylabels(\"Survival Probability\")","723dbbae":"dataset.head()","78d9f3af":"# convert to indicator values Title and Embarked \ndataset = pd.get_dummies(dataset, columns = [\"Title\"])\ndataset = pd.get_dummies(dataset, columns = [\"Embarked\"], prefix=\"Em\")","ac1949c1":"dataset.head()","b96b25c1":"# Replace the Cabin number by the type of cabin 'X' if not\ndataset[\"Cabin\"] = pd.Series([i[0] if not pd.isnull(i) else 'X' for i in dataset['Cabin'] ])","334a0db8":"g = sns.countplot(dataset[\"Cabin\"],order=['A','B','C','D','E','F','G','T','X'])","8c3398fe":"g = sns.factorplot(y=\"Survived\",x=\"Cabin\",data=dataset,kind=\"bar\",order=['A','B','C','D','E','F','G','T','X'])\ng = g.set_ylabels(\"Survival Probability\")","da260df7":"#convert to indicators\ndataset = pd.get_dummies(dataset, columns = [\"Cabin\"],prefix=\"Cabin\")","927bd897":"dataset.head()","7d20200a":"# Treat Ticket by extracting the ticket prefix. When there is no prefix it returns X. \n\nTicket = []\nfor i in list(dataset.Ticket):\n    if not i.isdigit() :\n        Ticket.append(i.replace(\".\",\"\").replace(\"\/\",\"\").strip().split(' ')[0]) #Take prefix\n    else:\n        Ticket.append(\"X\")\n        \ndataset[\"Ticket\"] = Ticket","ed1a7d11":"dataset[\"Ticket\"].head() ","20ab46d3":"dataset = pd.get_dummies(dataset, columns = [\"Ticket\"], prefix=\"T\")\n\n# Create categorical values for Pclass\ndataset[\"Pclass\"] = dataset[\"Pclass\"].astype(\"category\")\ndataset = pd.get_dummies(dataset, columns = [\"Pclass\"],prefix=\"Pc\")\n\n# Drop useless variables \ndataset.drop(labels = [\"PassengerId\"], axis = 1, inplace = True)\n\ndataset.head()","2939a296":"dataset.drop(labels = [\"Name\"], axis = 1, inplace = True)","be161635":"dataset.head()","228f43e2":"A peak can be clearly seen in survival of young children.","a4afb62c":"\n\nIt is clearly obvious that Male have less chance to survive than Female.\n\nSo Sex, might play an important role in the prediction of the survival.\n\nFor those who have seen the Titanic movie (1997), I am sure, we all remember this sentence during the evacuation : \"Women and children first\".\n","0d412df9":"There is 17 titles in the dataset, most of them are very rare and we can group them in 4 categories.","802681fc":"\n\nAge distribution seems to be a tailed distribution, maybe a gaussian distribution.\n\nWe notice that age distributions are not the same in the survived and not survived subpopulations. Indeed, there is a peak corresponding to young passengers, that have survived. We also see that passengers between 60-80 have less survived.\n\nSo, even if \"Age\" is not correlated with \"Survived\", we can see that there is age categories of passengers that of have more or less chance to survive.\n\nIt seems that very young passengers have more chance to survive.\n","7c124bdc":"People with too many siblings didn't have much chance.\nOne would'nt like to save too many, people of just one family. \nSo for people with 0,1 or 2 siblings had more chance to survive","b2b1c1ca":"\n\nThe correlation map confirms the factorplots observations except for Parch. Age is not correlated with Sex, but is negatively correlated with Pclass, Parch and SibSp.\n\nIn the plot of Age in function of Parch, Age is growing with the number of parents \/ children. But the general correlation is negative.\n\nSo, i decided to use SibSP, Parch and Pclass in order to impute the missing ages.\n\nThe strategy is to fill Age with the median age of similar rows according to Pclass, Parch and SibSp.\n","fb750c16":"\n\nAge distribution seems to be the same in Male and Female subpopulations, so Sex is not informative to predict Age.\n\nHowever, 1rst class passengers are older than 2nd class passengers who are also older than 3rd class passengers.\n\nMoreover, the more a passenger has parents\/children the older he is and the more a passenger has siblings\/spouses the younger he is.\n","7587b539":"\n\nIndeed, the third class is the most frequent for passenger coming from Southampton (S) and Queenstown (Q), whereas Cherbourg passengers are mostly in first class which have the highest survival rate.\n\nMy hypothesis is that first class passengers were prioritised during the evacuation due to their influence.\n","e83b93f2":"**Categorical Values**","f5ad3dca":"**Titanic DataSet Data Analysis**\n* Data Uploading\n* Outlier Detection\n* Feature Analysis\n* Filling Missing Value\n* Feature Analysis\n\n(Refered to Analysis by Yassine Ghouzam, PhD)\n(Made for my own learning purpose)","c448da79":"**Cabin**\n\n\nThe Cabin feature column contains 292 values and 1007 missing values.\nIt can be assumed, that passengers without a cabin have a missing value displayed instead of the cabin number.\nThe first letter of the cabin indicates the Desk, i choosed to keep this information only, since it indicates the probable location of the passenger in the Titanic.\n","f8003f23":"**Family size**\n\nWe can imagine that large families will have more difficulties to evacuate, looking for theirs sisters\/brothers\/parents during the evacuation. So, i choosed to create a \"Fize\" (family size) feature which is the sum of SibSp , Parch and 1 (including the passenger).","317982f9":"\n\nBecause of the low number of passenger that have a cabin, survival probabilities have an important standard deviation and we can't distinguish between survival probability of passengers in the different desks.\n\nBut we can see that passengers with a cabin have generally more chance to survive than passengers without (X).\n\nIt is particularly true for cabin B, C, D, E and F.\n","697e3d97":"\n\nAge and Cabin features have an important part of missing values.\n\nSurvived missing values correspond to the join testing dataset (Survived column doesn't exist in test set and has been replace by NaN values when concatenating the train and test set)\n","6376db03":"\n**Filling missing Values**\n\nAge\n\nAs we see, Age column contains 256 missing values in the whole dataset.\n\nSince there is subpopulations that have more chance to survive (children for example), it is preferable to keep the age feature and to impute the missing values.\n\nTo adress this problem, i looked at the most correlated features with Age (Sex, Parch , Pclass and SibSP).\n","a9dba1e3":"\n\nThe family size seems to play an important role, survival probability is worst for large families.","d3dc9137":"**Feature analysis**","6c49c755":"**Ticket**\n\n\nIt could mean that tickets sharing the same prefixes could be booked for cabins placed together. It could therefore lead to the actual placement of the cabins within the ship.\n\nTickets with same prefixes may have a similar class and survival.\n\nSo i decided to replace the Ticket feature column by the ticket prefixe. Which may be more informative.\n","c146e363":"\n\nIt seems that passenger coming from Cherbourg (C) have more chance to survive.\n\nMy hypothesis is that the proportion of first class passengers is higher for those who came from Cherbourg than Queenstown (Q), Southampton (S).\n\nLet's see the Pclass distribution vs Embarked\n","c9ec8535":"**Feature engineering**\n\n*Name\/Title*\n\n\nThe Name feature contains information on passenger's title.\nSince some passenger with distingused title may be preferred during the evacuation, it is interesting to add them to the model.","d41510db":"Factorplots of family size categories show that Small and Medium families have more chance to survive than single passenger and large families."}}