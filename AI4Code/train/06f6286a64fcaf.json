{"cell_type":{"7c61f795":"code","6716f1b5":"code","87d2562b":"code","0739fc5e":"code","811ecf4e":"code","dc64c6b5":"code","331d0673":"code","0c7a7930":"code","17bf5671":"code","7a1874e4":"code","dda38061":"code","c8134bca":"code","c3acb30a":"code","e1a4cfaf":"code","cfe9b8ea":"code","7106688c":"markdown"},"source":{"7c61f795":"# import libraries\nimport numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\nimport numpy as np\nimport os\nprint(os.listdir(\"..\/input\"))\n","6716f1b5":"data = pd.read_csv('..\/input\/column_2C_weka.csv')","87d2562b":"# view data\ndata.head()","0739fc5e":"data['class'].unique()","811ecf4e":"data.info()","dc64c6b5":"# you split class as abnormal and normal\nA = data[data['class'] == 'Abnormal']\nN = data[data['class'] == 'Normal']","331d0673":"N.info()","0c7a7930":"#visualization\nplt.scatter(A.pelvic_incidence, A.pelvic_radius, color = 'purple', label = 'Abnormal',alpha = 0.5)\nplt.scatter(N.pelvic_incidence, N.pelvic_radius, color = 'orange', label = 'Normal', alpha = 0.5)\nplt.xlabel('pelvic_incidence')\nplt.ylabel('pelvic_radius')\nplt.legend()\nplt.show()","17bf5671":"# abnormal and normal are string. So you transform integer or float.\ndata['class'] = [0 if each == 'Abnormal' else 1 for each in data['class']]","7a1874e4":"# determine feature and feature class.\ny = data['class'].values\nx_data = data.drop(['class'], axis=1)","dda38061":"# normalization\nx = (x_data-np.min(x_data))\/(np.max(x_data)-np.min(x_data))\n# (x-min(x))\/(max(x)-min(x))","c8134bca":"#train test split\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.2, random_state = 1)","c3acb30a":"#knn model\nfrom sklearn.neighbors import KNeighborsClassifier\nknn = KNeighborsClassifier(n_neighbors = 4)\nknn.fit(x_train,y_train)\nprediction = knn.predict(x_test)","e1a4cfaf":"print('{} n\u0131n score: {}'.format(3,knn.score(x_test,y_test)))","cfe9b8ea":"# find the most appropriate k value\nscore_list = []\nfor each in range(1,15):\n    knn2 = KNeighborsClassifier(n_neighbors=each)\n    knn2.fit(x_train, y_train)\n    score_list.append(knn2.score(x_test,y_test))\n    \nplt.plot(range(1,15),score_list,color='purple')\nplt.xlabel(\"k values\")\nplt.ylabel(\"accuracy\")\nplt.show()","7106688c":"# KNN ALGOR\u0130THM\n* This algorithm used to classification.\n* Suppose you have a new property and you want classification this property. You should look nearest neighbors and you must make classification according to nearest neighbors. \n* This algorithm has to k value. The value of k tells you how many nearest neighbors you should look. For example: If k=3, you should look nearest three neigbors. Assume, first neigbor classified as X, second neigbor classified as Y and third neigbor classified as X. You should make classification according this classicification results. And you can tell 'New property should classification as X' \n"}}