{"cell_type":{"db474082":"code","7d493e6d":"code","7f44e8cd":"code","1a794e84":"code","88aacdbc":"code","130c607e":"code","bfe06df6":"code","90231792":"code","0556424e":"code","88b2aece":"code","4e557ee0":"code","cd57dd34":"code","6f4de18c":"code","2151482c":"code","e9e8d9e3":"code","788218e9":"code","cf7014ce":"code","4e027a9a":"code","70d4bd4f":"code","ac049151":"code","cbac20bc":"code","61c4ab6f":"code","bc7dfc8f":"code","cde4a402":"code","736c116c":"code","e1ac7a3b":"code","57a26114":"code","df5b1347":"code","d5beb49d":"code","843f56e0":"code","8afa976d":"code","0e71b8c1":"code","588f496c":"code","f6cac022":"code","d95caab5":"code","c1193f8d":"code","82c9df4d":"code","5cbe3f55":"code","26a5eada":"code","bc8bc3aa":"code","53e2a9d6":"code","3e928151":"code","e00013d4":"code","6f0833ff":"markdown","07123935":"markdown","54e446ad":"markdown","95ad60e9":"markdown","369d9a3b":"markdown","3be38e81":"markdown","d4a705da":"markdown","e2bbfcdf":"markdown","289a647a":"markdown","fee6f253":"markdown","dda3f6a6":"markdown","7379682a":"markdown","60e8994d":"markdown","66f56a08":"markdown"},"source":{"db474082":"##################################################\n## Titanic Prediction\n##################################################\n#!\/usr\/bin\/python\n__author__ = 'Midhunkumar S'\n__version__ = '0.1.0'\n__maintainer__ = 'Kaggle'\n__status__ = 'Dev'\n##################################################","7d493e6d":"# Importing Libraries for data handling and EDA\nimport pandas as pd\nimport re\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\nsns.set_palette(\"YlGnBu\")\n\n# Ignoring FutureWarning\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Importing Libraries for Feature engineering and Modeling \nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.impute import KNNImputer\n\n# Setting Random seed\nseed =np.random.seed(55)\n\n# Importing Libraries for Modeling\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree  import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBRFClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.metrics import roc_curve,auc","7f44e8cd":"# Importing dataset\n\nTrain_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")\nTest_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")","1a794e84":"# Dataset Size\nprint(\"Train Shape :\",Train_df.shape)\nprint(\"Test Shape :\",Test_df.shape)","88aacdbc":"# Comparing Columns with Train and test\nprint (\"Train:\", Train_df.columns.to_list())\nprint (\"Test:\",Test_df.columns.to_list())","130c607e":"#Train sample \nTrain_df.sample(5)","bfe06df6":"#Test Sample\nTest_df.sample(5)","90231792":"# Train Info\nTrain_df.info()\n","0556424e":"Test_df.info()","88b2aece":"# null Value Counts \n\nTrain_df.isnull().sum()\/len(Train_df)*100","4e557ee0":"Test_df.isnull().sum()\/len(Test_df)*100","cd57dd34":"# Correlation betwenn columns\nplt.figure(figsize=[10,5])\nsns.heatmap(Train_df.corr(), vmax= 1, vmin= -1, annot= True, cmap= \"YlGnBu_r\")","6f4de18c":"# Checking Sex wise Survival\nsns.barplot(Train_df[\"Sex\"],Train_df[\"Survived\"])","2151482c":"# Checking Embarked wise Survival\nsns.barplot(Train_df[\"Embarked\"],Train_df[\"Survived\"])","e9e8d9e3":"# Checking Sex wise Survival\nsns.barplot(Train_df[\"Pclass\"],Train_df[\"Survived\"])","788218e9":"# Checking Parch wise Survival\nsns.barplot(Train_df[\"Parch\"],Train_df[\"Survived\"])","cf7014ce":"# Checking SibSP wise Survival\nsns.barplot(Train_df[\"SibSp\"],Train_df[\"Survived\"])","4e027a9a":"# Fare Box Plot \n\nsns.boxplot(Train_df[\"Fare\"])","70d4bd4f":"# Replacing Ticket fare more than 60 to 60\nTrain_df['Fare'] = Train_df['Fare'].replace([Train_df['Fare'].iloc[Train_df['Fare'].values >= 60]], 60)\nTest_df['Fare'] = Test_df['Fare'].replace([Test_df['Fare'].iloc[Test_df['Fare'].values >= 60]], 60)","ac049151":"sns.boxplot(Train_df[\"Fare\"])","cbac20bc":"# Age Plot\n\nsns.histplot(Train_df[\"Age\"])","61c4ab6f":"Train_df.Ticket.head(30)","bc7dfc8f":"# We need to remove the String Values in the ticket\nValues = Train_df['Ticket']\nTicket =[]\nfor x in Values:\n    if not x.isdigit():\n        if x ==\"LINE\":\n            Ticket.append(0)\n        else:  \n            Ticket.append(x.split(\" \")[-1])\n    else:\n        Ticket.append(x)\nTrain_df['Ticket'] = Ticket","cde4a402":"Values = Test_df['Ticket']\nTicket =[]\nfor x in Values:\n    if not x.isdigit():\n        if x ==\"LINE\":\n            Ticket.append(0)\n        else:  \n            Ticket.append(x.split(\" \")[-1])\n    else:\n        Ticket.append(x)\nTest_df['Ticket'] = Ticket","736c116c":"\nTrain_df['Ticket'] = Train_df['Ticket'].astype(int)\nTest_df['Ticket'] = Test_df['Ticket'].astype(int)","e1ac7a3b":"# Working on Name\nTrain_Name = Train_df['Name']\nTest_name = Test_df['Name']\nTrain_df['Name'] = [x.split(\" \")[1] for x in Train_Name]\nTest_df['Name'] =  [x.split(\" \")[1] for x in Test_name]","57a26114":"len(Train_df['Name'].value_counts()),len(Test_df['Name'].value_counts())","df5b1347":"Train_df['Name'].unique(), Test_df['Name'].unique()","d5beb49d":"Train_df.info()","843f56e0":"# Dropping Cabin and Name Columns\n\nX = Train_df.drop(['Name','Cabin'], axis=1)\nSub_test = Test_df.drop(['Name','Cabin'], axis=1)","8afa976d":"X.shape,Sub_test.shape","0e71b8c1":"# Encoding Lables\nCat_columns = list(X.dtypes[X.dtypes == \"object\"].index)\nCat_columns\n","588f496c":"LC = LabelEncoder()\nfor x in Cat_columns:\n    X[x] = LC.fit_transform(X[x])\n    Sub_test[x] = LC.fit_transform(Sub_test[x])\n","f6cac022":"X.info()","d95caab5":"# Imputing Age \n\ndata = [X, Sub_test]\nfor dataset in data:\n    mean = X[\"Age\"].mean()\n    std = Sub_test[\"Age\"].std()\n    is_null = dataset[\"Age\"].isnull().sum()\n    # Random No generator\n    rand_age = np.random.randint(mean - std, mean + std, size = is_null)\n    # Imputing missing Values\n    age_slice = dataset[\"Age\"].copy()\n    age_slice[np.isnan(age_slice)] = rand_age\n    dataset[\"Age\"] = age_slice\n    dataset[\"Age\"] = X[\"Age\"].astype(int)","c1193f8d":"X.isnull().sum()\/len(X)*100","82c9df4d":"# Taking out the Y from X\ny = X.pop('Survived')","5cbe3f55":"X.shape, y.shape","26a5eada":"# Trying out Naive Bayes\nnb = GaussianNB()\nnb.fit(X,y)\ncross_val_score(nb, X,y, cv=10).mean()","bc8bc3aa":"# Trying out Decision Tree\ndt = DecisionTreeClassifier(random_state=seed)\ndt.fit(X,y)\ncross_val_score(dt, X,y,cv = 10 ).mean()","53e2a9d6":"# Trying out RandomForest\nrf = RandomForestClassifier(random_state=seed)\nrf.fit(X,y)\ncross_val_score(rf, X,y, cv=15).mean()","3e928151":"# Using Stratified Kfold With RF modle and finding the ROC\ncv = StratifiedKFold(n_splits=5,shuffle=False)","e00013d4":"tprs = []\naucs = []\nmean_fpr = np.linspace(0,1,100)\ni =1\nfor train,test in cv.split(X,y):\n    prob = rf.fit(X.iloc[train],y.iloc[train]).predict_proba(X.iloc[test])[:,1]\n    fpr, tpr, t = roc_curve(y[test], prob)\n    tprs.append(np.interp(mean_fpr, fpr, tpr))\n    roc_auc = auc(fpr, tpr)\n    aucs.append(roc_auc)\n    plt.plot(fpr, tpr, lw=2, alpha=0.3, label='ROC fold %d (AUC = %0.2f)' % (i, roc_auc))\n    i= i+1\nplt.plot([0,1],[0,1],linestyle = '--',lw = 2,color = 'black')\nmean_tpr = np.mean(tprs, axis=0)\nmean_auc = auc(mean_fpr, mean_tpr)\nplt.plot(mean_fpr, mean_tpr, color='blue',\n         label=r'Mean ROC (AUC = %0.2f )' % (mean_auc),lw=2, alpha=1)\n\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('ROC')\nplt.legend(loc=\"lower right\")\nplt.text(0.32,0.7,'More accurate area',fontsize = 12)\nplt.text(0.63,0.4,'Less accurate area',fontsize = 12)\nplt.show()","6f0833ff":" `* C - Embarked Passngers are most survived than S and Q `","07123935":"## `Feature Engineering`","54e446ad":"`* From Above title we cant add much value to the analysis as test and train title are diffrent \nalso we alreday found that Feamle passengers has high survival ratio`","95ad60e9":"`* From Above Null Value counts we can see that cabin has 78% of null Values and Age 20%.`\n\n`* So, I would suggest to remove Cabin from dataset, as it might not be helpful for our analysis`","369d9a3b":"## `EDA`","3be38e81":" ` * From Above Correlation, Fare is one of the importent feature for Survival `","d4a705da":" `* More than 3 Children's having family survival is very less`","e2bbfcdf":"`* Fare has outliers which needs to be taken care in the same time fare also correlated with Survaival so, we cant throw away those outliers blindly` ","289a647a":"`* Female Passgers are survived more than male, M first priority ` ","fee6f253":"` * I am choosing Randomforest for teh final Model`","dda3f6a6":"` * Higer Siblings has lesser survival count`","7379682a":"` * Pclass - 3 has lesser chance to survival ","60e8994d":"`* Note : we need to take care of the Missing Values `","66f56a08":"## `Modeling`"}}