{"cell_type":{"ed85921f":"code","2a5e95b6":"code","7f921576":"code","c09c222a":"code","a76eeebc":"code","8a6f7ebd":"code","dd193b9a":"code","4111aa01":"code","7acd7591":"code","6465ab07":"code","be4dd116":"code","0a785d9d":"code","ab7672e6":"code","8d932370":"code","dc465eb1":"code","3e9146d0":"code","777bd7aa":"code","95fbe312":"code","193265f2":"code","a37ab362":"code","53ac43b0":"code","14f5313f":"code","d879af00":"code","e1599a73":"code","a92ebb38":"code","3a3ef150":"code","02d6a2c9":"code","f38aafd9":"code","21c1b7cd":"code","260e86b0":"code","d1de27ba":"code","029a61b5":"code","1fffc6cc":"code","b2be92a8":"code","afc42c35":"code","19972e5c":"code","b3ea4e81":"code","37dff2da":"code","84de2fed":"code","3e6947c9":"code","c5811f58":"code","69849303":"code","77ba8a38":"code","dea971a8":"code","03c55357":"code","797ad270":"code","bbe7a31f":"code","30f5cbf6":"code","d7bcbc45":"markdown","f293b115":"markdown","5f240ec9":"markdown","95e9bef6":"markdown","bde14929":"markdown","79bff6c9":"markdown","ea3e469a":"markdown","aaae2027":"markdown","7269e371":"markdown","9276b2a2":"markdown","da28ab54":"markdown","5fce2933":"markdown","0990fe9b":"markdown","fbf02d49":"markdown","7a3d6bff":"markdown","a4eccd05":"markdown","93ff8111":"markdown","c1e4e54b":"markdown","6a7ab49c":"markdown","76c86d2a":"markdown","2cabab53":"markdown","ed5b9b00":"markdown","13c3de71":"markdown","19525f67":"markdown","9f22933a":"markdown","a267de14":"markdown"},"source":{"ed85921f":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","2a5e95b6":"heart = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')","7f921576":"heart.head()","c09c222a":"heart.info()","a76eeebc":"heart.describe()","8a6f7ebd":"sns.set_theme()","dd193b9a":"sns.countplot(x='target',data=heart,hue='sex') ","4111aa01":"plt.figure(figsize=(12,6))\nheart['age'].plot(kind='hist',bins=40)","7acd7591":"heart.corr()","6465ab07":"plt.figure(figsize=(15,8))\nsns.heatmap(heart.corr(),cmap='viridis',annot=True)","be4dd116":"plt.figure(figsize=(10,6))\nsns.barplot(x='cp',y='target',data=heart)","0a785d9d":"plt.figure(figsize=(10,6))\nsns.countplot(x='restecg',data=heart,hue='target')","ab7672e6":"heart.corr()['target'][:-1].sort_values().plot(kind='bar')\nplt.tight_layout","8d932370":"plt.figure(figsize=(10,6))\nheart['thalach'].plot(kind='hist',bins=40)","dc465eb1":"plt.figure(figsize=(10,6))\nsns.countplot(x='slope',data=heart,hue='target')","3e9146d0":"plt.figure(figsize=(12,6))\nheart.isnull().sum()","777bd7aa":"heart.head()","95fbe312":"from sklearn.model_selection import train_test_split","193265f2":"heart.columns","a37ab362":"X = heart.drop('target',axis=1).values\ny = heart['target'].values","53ac43b0":"print(len(heart)) # data size is small","14f5313f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=101)","d879af00":"from sklearn.preprocessing import MinMaxScaler","e1599a73":"scaler = MinMaxScaler()","a92ebb38":"X_train = scaler.fit_transform(X_train)","3a3ef150":"X_test = scaler.transform(X_test)","02d6a2c9":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense,Dropout","f38aafd9":"model = Sequential()\n\nmodel.add(Dense(40,activation='relu'))\nmodel.add(Dropout(0.2))\n\nmodel.add(Dense(20,activation='relu'))\nmodel.add(Dropout(0.2))\n\n# BINARY CLASSIFICATION so use sigmoid for the last layer\nmodel.add(Dense(1,activation='sigmoid'))\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam')","21c1b7cd":"from tensorflow.keras.callbacks import EarlyStopping","260e86b0":"early_stop = EarlyStopping(monitor='val_loss',mode='min',verbose=1,patience=25)","d1de27ba":"model.fit(x=X_train,y=y_train,epochs=200,validation_data=(X_test,y_test),batch_size=30,callbacks=[early_stop])","029a61b5":"model_loss = pd.DataFrame(model.history.history)\nmodel_loss.plot()","1fffc6cc":"predictions = model.predict_classes(X_test)","b2be92a8":"from sklearn.metrics import classification_report, confusion_matrix","afc42c35":"print(classification_report(y_test,predictions))\nprint(confusion_matrix(y_test,predictions))","19972e5c":"sns.countplot(x='target',data=heart) # fairly balanced ","b3ea4e81":"from tensorflow.keras.models import load_model","37dff2da":"neural_net_model = model.save('heart-disease-predictor.h5') # save model","84de2fed":"model_loss # loss vs. val loss ","3e6947c9":"from sklearn.linear_model import LogisticRegression","c5811f58":"logmodel = LogisticRegression()","69849303":"logmodel.fit(X_train,y_train)","77ba8a38":"predictions = logmodel.predict(X_test)","dea971a8":"from sklearn.metrics import classification_report, confusion_matrix","03c55357":"print(classification_report(y_test,predictions))\nconfusion_matrix(y_test,predictions)","797ad270":"acc = logmodel.score(X_test, y_test)*100\n\nprint(\"Test Accuracy {:.2f}%\".format(acc))","bbe7a31f":"import pickle","30f5cbf6":"filename = \"heart-disease-LR.pkl\"  # save model with pickle\n\nwith open(filename, 'wb') as file:  \n    pickle.dump(logmodel, file)","d7bcbc45":"Data is already cleaned -> no need to fill in missing data or convert data to numerical data.","f293b115":"Eventually, the validation loss goes below the loss. This is ideal as the loss is reaching a minimum point, and overfitting is not occuring.","5f240ec9":"## Train Test Split","95e9bef6":" Visual representation (bar chart) showing most correlated features with target column.","bde14929":"## Create Model","79bff6c9":"Attribute info: \n- age\n- sex\n-  pain type (4 values)\n- resting blood pressure\n- serum cholestoral in mg\/dl\n- fasting blood sugar > 120 mg\/dl\n- resting electrocardiographic results (values 0,1,2)\n- maximum heart rate achieved\n- exercise induced angina\n- oldpeak = ST depression induced by exercise relative to rest\n- the slope of the peak exercise ST segment\n- number of major vessels (0-3) colored by flourosopy\n- thal: 3 = normal; 6 = fixed defect; 7 = reversable defect","ea3e469a":"More people have heart disease.\nMore females have heart disease than males; more females are included in this dataset","aaae2027":"[Features scaling](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.preprocessing.MinMaxScaler.html#:~:text=Transform%20features%20by%20scaling%20each,e.g.%20between%20zero%20and%20one) (also known as Standardization) helps normalise the data within a specific range. This ensures\nmore accurate results as the model does not have to process large ranges of data. MinMaxScaler transforms the data\nsuch that it is all within a given range.\n","7269e371":"## Model Evaluation","9276b2a2":"Chest pain of 1 is the most common.","da28ab54":"Data visualization is a useful tool in comparing these features of patients to find the most correlated attributes with the presence of heart disease.\nVarious plot types such as heatmaps, countplots, barplots, and histplots help find common patterns between patients with and without heart disease. My code\nincludes a few of these plots to compare and contrast patients. ","5fce2933":"Most affected people have a slope of 2","0990fe9b":"Most people have a thalach between 140 and 170.","fbf02d49":"Most people who had heart disease have a restcg of 1.","7a3d6bff":"No null values","a4eccd05":"Most patients are ages 50-60.","93ff8111":"According to CDC, heart disease is the leading cause of death in the United States. Wouldn't it be great if we tried to diagnose heart disease before it becomes\nsevere? My model predicts whether a patient has heart disease or not based on the patient's medical reports.\n\n## Dataset Specifics\nIn the data, you are given several attributes: \n\n 1. age\n \n 2. sex\n \n 3. chest pain type (4 values)\n \n 4. resting blood pressure\n \n 5. serum cholesterol in mg\/dl\n \n 6.  fasting blood sugar > 120 mg\/dl\n \n 7. resting electrocardiographic results (values 0, 1, 2)\n \n 8. maximum heart rate achieved\n \n 9. exercise induced angina\n \n 10. oldpeak = ST depression induced by exercise relative to rest \n \n 11. the slope of the peak exercise ST segment\n \n 12.  number of major vessels (0-3) colored by flourosopy\n \n 13.   thal: 3 = normal; 6 = fixed defect; 7 = reversable defect\n\n## Algorithm \nThis is a classification problem (binary classification) and the results can be interpreted as 0 and 1 (0 = without heart disease, 1 = with heart disease). I used two methods: a [neural network]( https:\/\/en.wikipedia.org\/wiki\/Artificial_neural_network) using **Keras**, and [Logistic Regression](https:\/\/en.wikipedia.org\/wiki\/Logistic_regression#:~:text=Logistic%20regression%20is%20a%20statistical,a%20form%20of%20binary%20regression). My neural network involves the use of [Early Stopping](https:\/\/en.wikipedia.org\/wiki\/Early_stopping) and [Dropout Layers](https:\/\/keras.io\/api\/layers\/regularization_layers\/dropout\/) to prevent overfitting of the data. Logistic Regression is used when dealing with categorical data (in this case, patients with and without heart disease).\n\n\n| Type | Accuracy |  Precision| Recall|F1-Score|\n|--|--|--|--|--|\n| Logistic Regression | 85% | 0 = 88%, 1 = 82% | 0 = 80%, 1 = 89% |0 = 83%, 1 = 86%   |\n| Neural Network|  87%| 0 = 90%, 1 = 83%| 0 = 80%, 1 = 91%| 0 = 84%, 1 = 87%\n\n**[My Github](https:\/\/github.com\/anyaiyer\/heart-disease-predictor) for this project**\n\n\n\n","c1e4e54b":"## Exploratory Data Analysis","6a7ab49c":"# Logistic Regression","76c86d2a":"Use of [EarlyStopping](https:\/\/en.wikipedia.org\/wiki\/Early_stopping) and [Dropout layers](https:\/\/keras.io\/api\/layers\/regularization_layers\/dropout\/) prevents overfitting of the data.\n","2cabab53":"Recall is most important because we need to detect all the true positives of heart disease. It is the most important that recall is high for all positive cases. Accuracy is ok because the data set is fairly balanced. Precision is less important than recall in this case.","ed5b9b00":"## Data PreProcessing ","13c3de71":"# Heart Disease Model","19525f67":"Most correlated features:\n- slope (slope of peak exercise ST segment) -> 35% correlated\n\n- thalach (max heart rate achieved) -> 42% correlated\n\n- restecg (resting electrocadiographic results) -> 14% correlated\n\n- cp (chest pain type) -> 43% correlated (most correlated feature with target) ","9f22933a":"In order to fit the model, we pass in X_train, y_train, the number of epochs (number of times the model will \nwork through the entire dataset), validation data (testing data), batch size (number of samples to work through \nbefore updating the model parameters), and early stopping.","a267de14":"Using a heatmap, we can get the most correlated features with target."}}