{"cell_type":{"217dd864":"code","edf62782":"code","6ed0efa3":"code","7cf360de":"code","174946c1":"code","7589bd62":"code","e4a4a296":"code","dd8c14fc":"code","91e20933":"code","aecf966d":"code","76bddbbc":"code","882ef3cd":"code","78692e8c":"code","0aa14afe":"code","3df20dd3":"code","692130d3":"code","202f39f5":"code","87c3d6ff":"code","4af56848":"code","7d3ae612":"code","c3974ccc":"code","b4665d65":"code","d67fdf79":"code","d3f3cd3b":"code","87b52425":"code","1edfcc67":"code","b86380fe":"code","5ef7dd21":"code","2aa78dec":"code","6e376b5c":"code","ed0083b2":"code","867726ca":"code","a7943a82":"code","f6d07ec6":"code","b86dfb09":"code","2c2005c1":"code","d04c64e9":"code","6f8f545b":"code","38c05bf4":"code","fdde1c64":"code","59b76e60":"code","4a6473cb":"code","dd23516f":"code","afc87f6e":"code","29a66006":"code","67686e73":"code","b0e1f594":"code","99dad9b1":"code","b8184e6d":"code","9f69d226":"code","8afc2370":"code","edc3dc0a":"code","0299a18e":"code","5024ff6b":"code","b956e0b3":"code","31ac2901":"code","39c655d7":"code","a295ae43":"code","12f7f5cb":"code","a3678c07":"code","f46081c8":"code","614d4051":"markdown","0e1778b9":"markdown","f45969b7":"markdown","2d2e1510":"markdown","b2706b45":"markdown","05614cda":"markdown","632bce76":"markdown","1f72513f":"markdown","8a73b0b4":"markdown","df6110f1":"markdown","04e204ae":"markdown","b191a382":"markdown","700ee14b":"markdown","10ff5762":"markdown","abafb217":"markdown","b1cbe9c4":"markdown","d34551cf":"markdown","4406e3cf":"markdown","34f550df":"markdown","9874ae82":"markdown","82f26b44":"markdown","8f3db7b4":"markdown","795832d0":"markdown","6621816a":"markdown","2f95f25a":"markdown","a593513d":"markdown","b8390d5e":"markdown","ff503329":"markdown","7aed0322":"markdown","e89625d0":"markdown","94330d91":"markdown","cde32552":"markdown","0cfc5954":"markdown","cc3432d4":"markdown","6319794c":"markdown","e820a739":"markdown","7bf90c10":"markdown","99cbab96":"markdown","cfad2258":"markdown","90af5b5e":"markdown","a7975044":"markdown","71d1a268":"markdown","af8e29b5":"markdown","f046ca0a":"markdown","9846de88":"markdown","2851ec9e":"markdown","75b21675":"markdown","2b6dc2b9":"markdown","aeb5c2bd":"markdown","2ec5aae0":"markdown","d56996ac":"markdown","10f5e6b2":"markdown","2724ba01":"markdown","233b51a5":"markdown","caa2af01":"markdown","cd8e9417":"markdown","a18ea370":"markdown","e8bce0e5":"markdown"},"source":{"217dd864":"# Basic library loading\nimport numpy as np\nimport pandas as pd\nimport re\nimport matplotlib.pyplot as plt\n%pylab inline","edf62782":"# Read in the dataset required\ntroll = pd.read_csv('..\/input\/tweets.csv')\nprint(troll.shape)\ntroll.head(2)","6ed0efa3":"troll.isnull().sum().sort_values(ascending = False)","7cf360de":"# drop NAs in the text column and update the troll dataframe\ntroll.dropna(subset = ['text'], inplace = True)","174946c1":"print(troll.dtypes)","7589bd62":"# convert created_str to datetime format\ntroll['created_str'] = pd.to_datetime(troll['created_str'])\n\n# convert ids to object datatype\ncolumns = ['user_id', 'tweet_id', 'retweeted_status_id', \n           'retweeted_status_id', 'in_reply_to_status_id']\n\nfor column in columns:\n    troll[column] = troll[column].astype('object')","e4a4a296":"troll.dtypes","dd8c14fc":"start_date_tweet = troll['created_str'].min()\nend_date_tweet = troll['created_str'].max()\n\nprint(start_date_tweet, end_date_tweet)","91e20933":"# created_str_data holds the date component of the created_str column\ntroll['created_str_date'] = pd.to_datetime(troll['created_str'].dt.date)","aecf966d":"# Count the number of times a date appears in the dataset and convert to dataframe\ntweet_trend = pd.DataFrame(troll['created_str_date'].value_counts())\n\n# index is date, columns indicate tweet count on that day\ntweet_trend.columns = ['tweet_count']\n\n# sort the dataframe by the dates to have them in order\ntweet_trend.sort_index(ascending = True, inplace = True)","76bddbbc":"# make a line plot of the tweet count data and give some pretty labels! ;)\n# the 'rot' argument control x-axis ticks rotation\nplt.style.use('seaborn-darkgrid')\ntweet_trend['tweet_count'].plot(linestyle = \"-\", figsize = (12,8), rot = 45, color = 'k',\n                               linewidth = 1)\nplt.title('Tweet counts by date', fontsize = 15)\nplt.xlabel('Date', fontsize = 13)\nplt.ylabel('Tweet Count', fontsize = 13)","882ef3cd":"# these are dates corresponding to important dates from the trump campaign.\ndates_list = ['2015-06-16', '2015-12-07', '2016-02-01',\n              '2016-03-01', '2016-03-03', '2016-03-11',\n              '2016-05-03', '2016-05-26', '2016-06-20', \n              '2016-07-15', '2016-07-21', '2016-08-17',\n              '2016-09-01', '2016-10-07', '2016-11-08']\n\n# create a series of these dates.\nimportant_dates = pd.Series(pd.to_datetime(dates_list))\n\n# add columns to identify important events, and mark a 0 or 1.\ntweet_trend['Important Events'] = False\ntweet_trend.loc[important_dates, 'Important Events'] = True\ntweet_trend['values'] = 0\ntweet_trend.loc[important_dates, 'values'] = 1","78692e8c":"# plot the line chart for trend, a monthly average of tweet counts and add red dots to \n# mark important events.\nplt.style.use('seaborn-darkgrid')\ntweet_trend['tweet_count'].plot(linestyle = \"--\", \n                                figsize = (12,8), rot = 45, \n                                color = 'k',\n                                label = 'Tweet Count per Day',\n                               linewidth = 1)\n\n# plot dots for where values in the tweet_trend df are 1\nplt.plot(tweet_trend[tweet_trend['Important Events'] == True].index.values,\n         tweet_trend.loc[tweet_trend['Important Events'] == True, 'values'],\n         marker = 'o', \n         color = 'r',\n         linestyle = 'none',\n        label = 'Important Dates in campaign')\n\n# Lets add a 30 day moving average on top to view the trend! Min_periods tells rolling() to\n# use 10 points if 30 not available!\nplt.plot(tweet_trend['tweet_count'].rolling(window = 30, min_periods = 10).mean(), \n         color = 'r', \n         label = '30 Day Moving Avg # of tweets')\nplt.title('Tweet counts by date', fontsize = 15)\nplt.xlabel('Date', fontsize = 13)\nplt.ylabel('Tweet Count', fontsize = 13)\nplt.legend(loc = 'best')","0aa14afe":"# Calculate the percentage change in tweet counts\ntweet_trend['Pct_Chg_tweets'] = tweet_trend['tweet_count'].pct_change()*100\n\n# Lets see values only for the important dates. This Pct_Chg_tweets shows us the percentage\n# change in tweets for the day of the event versus the previous day!\ntweet_trend.loc[tweet_trend['values'] == 1,['tweet_count', 'Pct_Chg_tweets']]","3df20dd3":"import matplotlib.pyplot as plt\nplt.style.use('seaborn-darkgrid')\n\n# line plot of the percentage change in tweet counts\ntweet_trend['Pct_Chg_tweets'].plot(linestyle = \"--\", figsize = (12,8), rot = 45, \n                                   color = 'k',\n                                  linewidth = 1)\n# add the dots for important events!\nplt.plot(tweet_trend[tweet_trend['Important Events'] == True].index.values,\n         tweet_trend.loc[tweet_trend['Important Events'] == True, 'values'],\n         marker = 'o', \n         color = 'r',\n         linestyle = 'none')\nplt.title('Tweet count change', fontsize = 15)\nplt.xlabel('Date', fontsize = 13)\nplt.ylabel('Tweet Count Change', fontsize = 13)","692130d3":"# take a look at what the 'text' column holds\ntroll['text'].head(10)","202f39f5":"# define a function that takes in a tweet and throws out the text without the RT.\ndef remove_retweet(tweet):\n    '''Given a tweet, remove the retweet element from it'''\n    text_only = []\n    if len(re.findall(\"^RT.*?:(.*)\", tweet)) > 0:\n        text_only.append(re.findall(\"^RT.*?:(.*)\", tweet)[0])\n    else:\n        text_only.append(tweet)\n    return text_only[0]\n\n# extract texts and place in a list\ntext_only = troll['text'].map(remove_retweet)","87c3d6ff":"# this method checks for links and removes these from the tweet provided!\ndef remove_links(tweet):\n    '''Provide a tweet and remove the links from it'''\n    text_only = []\n    if len(re.findall(\"(https:\/\/[^\\s]+)\", tweet)) > 0:\n        tweet = re.sub(\"(https:\/\/[^\\s]+)\", \"\", tweet)\n    if len(re.findall(\"(http:\/\/[^\\s]+)\", tweet)) > 0:\n        tweet = re.sub(\"(http:\/\/[^\\s]+)\", \"\", tweet)    \n    text_only.append(tweet)\n    return text_only[0]\n\ntext_no_links = text_only.map(remove_links)","4af56848":"def remove_hashtags(tweet):\n    '''Provide a tweet and remove hashtags from it'''\n    hashtags_only = []\n    if len(re.findall(\"(#[^#\\s]+)\", tweet)) > 0:\n        tweet = re.sub(\"(#[^#\\s]+)\", \"\", tweet) \n    hashtags_only.append(tweet)\n    return hashtags_only[0]\n\ntext_all_removed = text_no_links.map(remove_hashtags)","7d3ae612":"def remove_extraneous(tweet):\n    '''Given a text, remove unnecessary characters from the beginning and the end'''\n    tweet = tweet.rstrip()\n    tweet = tweet.lstrip()\n    tweet = tweet.rstrip(\")\")\n    tweet = tweet.lstrip(\"(\")\n    tweet = re.sub(\"\\.\", \"\", tweet)\n    return tweet\n\ntext_clean = text_all_removed.map(remove_extraneous)","c3974ccc":"# in case no mention present, we return \"0\"\ndef extract_mentions(tweet):\n    '''Given a tweet, this function returns the user mentions'''\n    mentions = []\n    if len(re.findall('@[^\\s@]+', tweet))>0:\n        mentions.append(re.findall('@([^\\s@]+)', tweet))\n    else:\n        mentions.append([\"0\"])\n    return mentions[0]\n\n# Put the user mentions in a new column in our dataframe\ntroll['user_mentions'] = text_clean.map(extract_mentions)","b4665d65":"# Now lets remove the mentions from the tweet text\ndef remove_mentions(tweet):\n    '''Given a text, remove the user mentions'''\n    mentions = []\n    if len(re.findall('@[^\\s@]+', tweet))>0:\n        tweet = re.sub('@[^\\s@]+', \"\" , tweet)\n        mentions.append(tweet)\n    else:\n        mentions.append(tweet)\n    return mentions[0]\n\ntext_clean_final = text_clean.map(remove_mentions)","d67fdf79":"troll['tweet_text_only'] = text_clean_final","d3f3cd3b":"# in case hashtags are not found, we will use \"0\" as the placeholder\ndef extract_hashtags(tweet):\n    '''Provide a tweet and extract hashtags from it'''\n    hashtags_only = []\n    if len(re.findall(\"(#[^#\\s]+)\", tweet)) > 0:\n        hashtags_only.append(re.findall(\"(#[^#\\s]+)\", tweet))\n    else:\n        hashtags_only.append([\"0\"])\n    return hashtags_only[0]\n\n# make a new column to store the extracted hashtags and view them!\ntroll['tweet_hashtags'] = troll['text'].map(extract_hashtags)\ntroll['tweet_hashtags'].head(10)","87b52425":"# create a list of all hashtags\nall_hashtags = troll['tweet_hashtags'].tolist()\n\n# Next we observe that our all_hashtags is a list of lists...lets change that\ncleaned_hashtags = []\nfor i in all_hashtags:\n    for j in i:\n            cleaned_hashtags.append(j)\n\n# Convert cleaned_hashtags to a series and count the most frequent occuring\ncleaned_hashtag_series = pd.Series(cleaned_hashtags)\nhashtag_counts = cleaned_hashtag_series.value_counts()","1edfcc67":"# Get hashtag terms from the series and convert to list\nhashes = cleaned_hashtag_series.values\nhashes = hashes.tolist()\n\n# convert list to one string with all the words\nhashes_words = \" \".join(hashes)\n\n# generate the wordcloud. the max_words argument controls the number of words on the cloud\nfrom wordcloud import WordCloud\nwordcloud = WordCloud(width= 1600, height = 800, \n                      relative_scaling = 1.0, \n                      colormap = \"Blues\",\n                     max_words = 100).generate(hashes_words)\n\nplt.figure(figsize=(20,10))\nplt.imshow(wordcloud)\nplt.axis(\"off\")\nplt.tight_layout(pad=0)\nplt.show()","b86380fe":"plt.style.use('seaborn-darkgrid')\nplt.figure(figsize = (12,8))\nplt.barh(y = hashtag_counts[1:21].index.values, width = hashtag_counts[1:21])\nplt.title(\"Top 20 Hashtags used in Troll tweets\", fontsize = 15)\nplt.xlabel('Count of hashtags', fontsize = 13)\nplt.ylabel('Hashtags', fontsize = 13)","5ef7dd21":"# Create a dataframe with just the date and the hashtags in the tweet on that date\nhashtag_date_df = troll[['created_str_date', 'tweet_hashtags']]\nhashtag_date_df = hashtag_date_df.reset_index(drop = True)\n\n# extract a list of hashtags from the dataframe\nall_hashtags = hashtag_date_df['tweet_hashtags'].tolist()\n\nhashtag_date_df.head()","2aa78dec":"# For the top 6 hashtags, lets calculate how many times that appears against each date!\ncount_dict = {}\nfor i in hashtag_counts.index.values[1:7]:\n    count_hash = []\n    for j in all_hashtags:\n        count_hash.append(j.count(i))\n    count_dict[i] = count_hash","6e376b5c":"# create a dataframe from the hashtags\nhashtag_count_df = pd.DataFrame(count_dict)\n\n# concatenate this dataframe with the hashtag_count_df\nhashtag_count_df = pd.concat([hashtag_date_df, hashtag_count_df], axis = 1)","ed0083b2":"hashtag_count_df.head()","867726ca":"# change the created_str column into datetime format and extract just the date from it\nhashtag_count_df['created_str_date'] = pd.to_datetime(hashtag_count_df['created_str_date'])\n\n# set the index so as to plot the time series\nhashtag_count_df.set_index('created_str_date', inplace = True)\n\n# get a monthly sum of the tweets for each of these hashtags\nhashtag_count_df_pivot = hashtag_count_df.resample('M').sum()\n\n# replace 0 with nan so that these can be removed in rows where they are all NaNs\nhashtag_count_df_pivot.replace(0, np.nan, inplace = True)\nhashtag_count_df_pivot.dropna(how = 'all', inplace = True, axis = 0)\n\n# replace NaNs back by 0s so that we can plot\nhashtag_count_df_pivot.replace(np.nan, 0, inplace = True)\nhashtag_count_df_pivot","a7943a82":"plt.style.use('seaborn-darkgrid')\n# create a 3 by 2 subplot to hold the trend of all hashtags\nfigure, ((ax1, ax2), (ax3, ax4), (ax5, ax6)) = subplots(nrows = 3,\n                                                       ncols = 2,\n                                                       sharey = True,\n                                                       figsize = (10,8))\n\nplt.subplots_adjust(top = 1, hspace = 0.9)\nhashtag_count_df_pivot['#politics'].plot(linestyle = \"-\", marker = \"o\", color = \"green\",ax = ax1)\nax1.set_title(\"#POLITICS\", fontsize = 10)\nax1.set_xlabel('Date', fontsize = 12)\n\nhashtag_count_df_pivot['#tcot'].plot(linestyle = \"-\", marker = \"o\", color = \"red\", ax = ax2)\nax2.set_title(\"#TCOT\", fontsize = 10)\nax2.set_xlabel('Date', fontsize = 12)\n\nhashtag_count_df_pivot['#MAGA'].plot(linestyle = \"-\", marker = \"o\", color = \"orange\", ax = ax3)\nax3.set_title(\"#MAGA\", fontsize = 10)\nax3.set_xlabel('Date', fontsize = 12)\n\nhashtag_count_df_pivot['#PJNET'].plot(linestyle = \"-\", marker = \"o\", color = \"blue\",ax = ax4)\nax4.set_title(\"#PJNET\", fontsize = 10)\nax4.set_xlabel('Date', fontsize = 12)\n\nhashtag_count_df_pivot['#news'].plot(linestyle = \"-\", marker = \"o\", color = \"grey\", ax = ax5)\nax5.set_title(\"#NEWS\", fontsize = 10)\nax5.set_xlabel('Date', fontsize = 12)\n\nhashtag_count_df_pivot['#Trump'].plot(linestyle = \"-\", marker = \"o\", color = \"maroon\", ax = ax6)\nax6.set_title(\"#TRUMP\", fontsize = 10)\nax6.set_xlabel('Date', fontsize = 12)","f6d07ec6":"troll['user_mentions'].head(10)","b86dfb09":"user_mention = troll.loc[:, ['user_key', 'user_mentions']]\nuser_mention.head(6)","2c2005c1":"row_remove_mask = user_mention['user_mentions'].map(lambda x: \"0\" in x)","d04c64e9":"np.sum(row_remove_mask)","6f8f545b":"# keep rows where row_remove_mask is FALSE\nuser_mention_df = user_mention.loc[~row_remove_mask, :]\nuser_mention_df.reset_index(drop = True, inplace = True)\nuser_mention_df.head(10)","38c05bf4":"# for each row, create a one-to-one tuple of user and his user mention\nnew_list = []\nfor i in range(len(user_mention_df)):\n    for j in user_mention_df.loc[i, \"user_mentions\"]:\n        (a,b) = (user_mention_df.loc[i, 'user_key'], j)\n        new_list.append((a,b))","fdde1c64":"user_mention_clean_df = pd.DataFrame({\"User_Key\": [a for (a,b) in new_list],\n                                     \"User_Mention\": [b for (a,b) in new_list]})\nuser_mention_clean_df.head()","59b76e60":"# create a df with user and hashtags in one tweet\nuser_hashtag_df = troll[['user_key', 'tweet_hashtags']]\nuser_hashtag_df = user_hashtag_df.reset_index(drop = True)","4a6473cb":"# Lets remove the rows where no hashtags were used\nrow_remove_mask = user_hashtag_df['tweet_hashtags'].map(lambda x: \"0\" in x)\n\n# Remove these rows from the user hashtag df\nuser_hashtag_df_clean = user_hashtag_df.loc[~row_remove_mask, :]\nuser_hashtag_df_clean.reset_index(drop = True, inplace = True)\nuser_hashtag_df_clean.head()","dd23516f":"# separate out all hashtags used.\nall_hashtags = user_hashtag_df_clean['tweet_hashtags']","afc87f6e":"# count_dict = {}\n# count_df = pd.DataFrame()\n# for i in range(len(hashtag_counts.index.values)):\n#     count_hash = all_hashtags.map(lambda x: x.count(hashtag_counts.index.values[i]))\n#     count_dict[i] = count_hash\n#     if i == 5000:\n#         count_df = pd.DataFrame(count_dict)\n#         count_dict = {}\n#     elif i % 5000 == 0:\n#         count_df = pd.concat([count_df, pd.DataFrame(count_dict)])\n#         count_dict = {}\n#     else:\n#         next","29a66006":"# get hashtags that qualify - present in 50 or more tweets\nqualify_hashtags_mask = (hashtag_counts >= 50)\nqualify_hashtags = hashtag_counts[qualify_hashtags_mask]\n\n# remove the \"0\" hashtags\nqualify_hashtags = qualify_hashtags.drop(labels = \"0\")\nqualify_hashtags.head()","67686e73":"# lets count the number of times these qualified hashtags appear in the tweets with hashtags\ncount_dict = {}\n\nfor i in qualify_hashtags.index.values:\n    count_hash = all_hashtags.map(lambda x: x.count(i))\n    count_dict[i] = count_hash\n\n# create a dataframe from the hashtags and their counts in tweets\nhashtag_count_df = pd.DataFrame(count_dict)\n\n# concatenate this dataframe with the hashtag_count_df\nuser_hashtag_count_df = pd.concat([user_hashtag_df_clean, hashtag_count_df], axis = 1)","b0e1f594":"# group by user_key and get the sum of times they have used a hashtag\nuser_hashtag_group = user_hashtag_count_df.groupby('user_key').agg('sum').reset_index()\nuser_hashtag_group.head()","99dad9b1":"user_tweet_df = troll.loc[:, ['user_key', 'tweet_text_only']]\nuser_tweet_df.head()","b8184e6d":"users = pd.read_csv('..\/input\/users.csv')\nusers.head(2)","9f69d226":"# First we get a count of users from each time-zone and language combination!\nuser_loc_lang = users.groupby(['time_zone', 'lang'])['id'].agg('count').reset_index()\nuser_loc_lang.rename(columns = {'id':'user_count'}, inplace = True)\nuser_loc_lang.head(5)","8afc2370":"# This is a custom package installed within kaggle kernel\nfrom pySankey import sankey\nsankey.sankey(user_loc_lang['time_zone'],\n              user_loc_lang['lang'],\n              leftWeight = user_loc_lang['user_count'],\n              rightWeight = user_loc_lang['user_count'], \n              fontsize = 10)\nplt.title(\"User profile\")","edc3dc0a":"# First we convert the created_at to datetime and then extract the date from this\nusers['created_at'] = pd.to_datetime(users['created_at'])\nusers['created_at_date'] = pd.to_datetime(users['created_at'].dt.date)\n\nusers['created_at_date'].head()","0299a18e":"user_created = users.groupby('created_at_date')['id'].agg('count')\n\nplt.style.use('fivethirtyeight')\nuser_created.resample('W',kind = 'period').sum().\\\nplot(linestyle = '-', figsize = (10,8), linewidth = 1)\ntitle('Troll User Account Created')\nxlabel('Dates')\nylabel('Count of accounts created')","5024ff6b":"user_tweet_count = troll.groupby('user_id')['text'].agg('count').reset_index()\nuser_tweet_count.rename(columns = {'text':'Tweet_count'}, inplace = True)","b956e0b3":"user_tweet_count_df = user_tweet_count.merge(users,\n                                      left_on = 'user_id',\n                                      right_on = 'id')\nuser_tweet_count_df.head(2)","31ac2901":"plt.style.use('seaborn-darkgrid')\nuser_tweet_count_df[['name', 'Tweet_count']].sort_values('Tweet_count', ascending = False)[:10].\\\nset_index('name').plot(kind = 'barh', figsize = (10,8))\ntitle('User Wise Tweet Count', fontsize = 15)\nxlabel('Tweet Count', fontsize = 13)\nylabel('User Name', fontsize = 13)","39c655d7":"correl = user_tweet_count_df['Tweet_count'].corr(user_tweet_count_df['followers_count'])\nprint(\"{0:.2f}\".format(correl))","a295ae43":"# Drawing a scatterplot of the tweet count with number of followers\nfig = plt.figure(figsize = (10,8))\nplt.style.use('seaborn-darkgrid')\nplt.scatter(user_tweet_count_df['Tweet_count'], \n        user_tweet_count_df['followers_count'],\n       marker = 'o',\n       alpha = 0.5)\nplt.title(\"Followers vs Number of Tweets\", fontsize = 15)\nplt.xlabel(\"Number of Tweets\", fontsize = 13)\nplt.ylabel(\"Follower Count\", fontsize = 13)\nplt.text(6000, 80000, s = \"Correlation is: {0:.2f}\".format(correl), fontsize = 15)","12f7f5cb":"user_tweet_count_df['lang'].value_counts()","a3678c07":"user_tweet_count_df[['name', 'lang', 'followers_count']].sort_values('followers_count', \n                                                               ascending = False)[:10]","f46081c8":"# Lets write out these files as datasets so that they can be used in my next Kernel!\nuser_mention_clean_df.to_csv('User_Mentions.csv')\nuser_hashtag_group.to_csv('User_Hashtags.csv')\nuser_tweet_df.to_csv('User_Tweets.csv')","614d4051":"## Text Analytics Time!\nSo we see that the tweets contain extra elements like RT mentions, links and hashtags! Let's separate out these elements so that we can analyze just the tweet text or the hashtags as we so prefer!","0e1778b9":"**Let's remove all extra spaces from the beginning and the end of the text that we got!**","f45969b7":"***qualify_hashtags* now has 435 hashtags that are present in 50 or more different tweets.** Wow! Thats such a reduction from the 28000 unique hashtags that we originally had! \n\nMy hope is that now I should be able to count how many times those appear in the tweets and then make the dataframe I intended to above!","2d2e1510":"We now have a tuple with each user -> user_mention value. Lets get a dataframe from this!","b2706b45":"## Where are users from and what language do they use?\nLets create a sankey plot (also called alluvial plot in R) to get a sense of which time zone are the users from and what language they speak!","05614cda":"So, our tweet data has 203,482 rows and 16 columns. It captures data about the *userid, tweetid, tweet text, hashtags, mentions* and the number of times a tweet was re-tweeted or favorited. We also see a datetime column *created_str*.\n\nLet's check missing values in the dataframe!","632bce76":"**The US president was elected on 8th November 2016 - the last red dot on the chart. We see a lot of tweet activity near the end of his campaign.** \n\nWe can also calculate the percentage change in tweet counts between subsequent dates and then see if an important date relates with a spike!","1f72513f":"**We see that most of these hashtags picked up in the year 2016 near March or later in July, close to the elections! This is also the time when alleged interference by Russian trolls started!** \n\nWe see the largest peak in the **#politics**.  Maybe tweeting about politics got these trolls the largest following!","8a73b0b4":"## What hashtags are being used the most?\nFirst, lets use the function created above but use it in a way that we can extract the hashtags and not remove them!","df6110f1":"**First let's remove the RT mentions from tweets.**","04e204ae":"## But First, Let me take a selfie! \nJust kidding, lets take a look at the first few rows of our data!","b191a382":"Okay, so what I wanted was to create columns with the different hashtags used as the column names and the count of the number of times they appear in a tweet by a person as the value. The code below should have done that, however, I find that it eats up all my RAM and crashes the Kernel. This is because there are around 28k unique hashtags used in around 100,000 different tweets.","700ee14b":"Thank you for following along! This is the end of my exploratory analysis of the troll tweets! I will use some of the work I have done here to create an R notebook and run some additional text analytics. In [Part 2 ](https:\/\/www.kaggle.com\/chadalee\/russian-troll-tweet-analysis-part-2)(Grand Finale :P), we look at - <br>\n\n1. **user_mention_clean_df** and try to see using a network graph, which users reference which other user and which user appears the most in between two links on the network!\n2. **user_hashtag_group** and create clusters of users based on what they tweet about!\n3. **user_tweet_df** and try to predict users based on their tweet texts!","10ff5762":"Let's now separate out the *user_key* and *user_mentions* columns from this dataframe!","abafb217":"## Hashtags based clustering\nCan we get some cluster of users who use similar hashtags? First we will create a dataframe which holds the *user_key* and the *tweet_hashtags*.","b1cbe9c4":"So my alternate strategy is to count the number of tweets with hashtags that a hashtag appears in and filter out those hashtags that are present in less than 50 tweets. Hopefully this should give me a less dramatic dataframe to work with.","d34551cf":"## Lets look at user mentions!\nWe already have the user mentions in a column in our **troll** dataframe! Let's create a dataframe with each user's tweet with the user mentions against it! ","4406e3cf":"# Russian Troll Tweets Analysis\nThis is my attempt at putting to use my recent learnings in text analytics. I have never worked with text data before so it should be exciting.\n\nWhat comes to mind when I think of tweet data is to analyze - \n1. What are the most trending hashtags?\n2. When were people most tweeting? Are tweets spiking around the time of major events? - Common sense tells me **Yes**\n3. Which users mention which users? Can a graph be made to see which are the most mentioned users?\n4. Can some clusters be made for users tweeting on similar topics?\n5. Can we predict users from their tweet contents!","34f550df":"Hmm, so <br>\n1. *user_id*, *tweet_id*, *retweeted_status_id* and *in_reply_to_status_id* have been read in as a float when it should be of object data type - we dont want computations on this column. \n2. We also see that *created_str* has been imported as type object - this needs to be changed to datetime for further processing.","9874ae82":"## Which user tweets the most?","82f26b44":"This is an excellent way to visually see the most common hashtags, but there is no way to quantify the frequency of each hashtag from this! Let's plot a barplot too!","8f3db7b4":"## What period of tweets does this data capture?\nThe *created_str* column would help us know this!","795832d0":"Most troll accounts were created in the second half of 2013 or first half of 2014!","6621816a":"**Lets remove hashtags from these!**","2f95f25a":"# Users!\nWe also have data on the users who write these tweets! What can we gather from this data?\nLet's just look at the data first.","a593513d":"## Check the trend of these tweets against time!\nSince each row is one tweet on a given data (as given in the *created_str_date*), lets count the number of times a date appears and that gives us the number of tweets on that day!","b8390d5e":"We have ~3 years of tweets starting **14th July 2014** until the **26th of September 2017**! Times appear with these dates, so let's create a new column to hold only the date component of this! ","ff503329":"## Which users had the most influence?\nWe see that although there are only 90 users with language 'ru', there are 4 of them in the top 10 most followed users!","7aed0322":"**The table above shows that for most of these dates, there was an increase in the tweet counts** - some days as large as 350%. However, there are some negative changes as well! **Keep in mind that these dates are not in order, these are just dates when there was an important event** - and the percent_change is with respect to the previous day!\n\nLet's plot the percent change in tweet count with dates on the x axis to look at signs of correlation!","e89625d0":"The above chart shows the user profile in the troll tweet users. **English speaking** users come from **US, Canada & Arizona**. *Russian* speaking users come from *Moscow, Volgograd, Yerevan and Minsk*! All french speaking users are from Paris. This makes sense!","94330d91":"Each column above is a hashtag and each cell underneath tells us the count of times that hashtag appeared in a tweet on that date! **We now need to summarise this data at the monthly level to get a sense of the month-on-month usage of these hashtags!**","cde32552":"## When were these accounts created?\nThe *created_at* column in the **users** dataframe captures this information!","0cfc5954":"Let's remove these rows!","cc3432d4":"The nice part about having a datetime index is the pretty x-axis ticks it gives us! \n\n**If these tweets really had to impact the way of the US presidential elections, these tweets would be most numerous during important parts of the trump rally or milestones in the trump rally.** Let's get these dates online and try to map that data on with the line plot! \n\n[Important Dates in Trump's presidential elections](https:\/\/www.reuters.com\/article\/us-usa-election-timeline-factbox\/timeline-pivotal-moments-in-trumps-presidential-campaign-idUSKBN1341FJ)","6319794c":"**Next, let's remove the links from these tweet texts so that we have a column for just the tweet text devoid of any links and RT mentions.**","e820a739":"**At last, we remove the user mentions from the text_clean** But before we do that, lets store these user mentions in a new column within the dataframe!","7bf90c10":"Okay, for each user now we have the count of the qualifying hashtags in each of their tweets. Lets group this by the user and get a sum of the counts of hashtags used!","99cbab96":"## What are the languages with which users registered?\nThe table below shows that english is the most common language, followed by Russian and German!","cfad2258":"We see information about *user_id*, *user_name*, *follower_count*, *language*, etc.","90af5b5e":"Let's first create a wordcloud of the most commonly used hashtags! This requires us to put the word list as a single string separated by spaces. The algorithm then counts the number of times each term appears and makes the words bigger\/bolder commensurate to their frequency!","a7975044":"This gives us a T\/F series - **True** where *user_mentions* are empty, **False** otherwise. How many rows are we removing?","71d1a268":"A tweet count of the top 10 tweeting users follows-","af8e29b5":"We see around 21 missing values in the text column. Since this is the critical column to be analyzed, **we will drop rows with NaNs in the text column**","f046ca0a":"Check data types of output dataframe! Always good to do when you are just beginning! :)","9846de88":"## Were these hashtags used most just before the presidents campaign?\n\nTo analyze this, we will use the top 6 hashtags and a count of how many times these were used on the dates provided in the *created_str_date*. \n\nLet's first extract the dates and the hashtags used on those dates. We would then count each top hashtag in these and proceed.","2851ec9e":"#### In Part 2 of this analysis, we will take the *user_mention_clean_df* to R to analyse the graph of user mentions!","75b21675":"## Lets look at user wise tweet text\nRecall that we had created a *tweet_text_only* column that contained just the tweet text devoid of any links, RT, mentions or hashtags! Lets get a user wise text dataframe!","2b6dc2b9":"Looking at the top hashtags, we find that the most common hashtags in use - <br>\n1. **#TCOT**  \n2. **#POLITICS** \n3. **#PJNET**\n4. **#MAGA**\n5. **#Trump**\n\nare all in support of the current president's campaign! Looks like the trolls were mostly supporting his candidacy!\n\nAmong the top 20 used hashtags, we see that  **#WAKEUPAMERICA, #P2, @HILLARY** are against the candidacy but these have been used far fewer times than others!\n \n**#2A** - refers to the Second Amendment of the US constitution to keep and bear arms which the president supports!\n\nSurprisingly, these trolls also tweeted with the hastag **#MERKELMUSSBLEIBEN** which is in support of the German Chancellor - Angela Merkel and translates to 'Merkel Must Stay'","aeb5c2bd":"The table above shows that  - <br>\n1. **Retweets** begin with the **keyword 'RT'**. These are followed by _@userkey_.\n2. **Hashtags** begin with a **_#_** and are one continuous string with a space next to them!\n3. **Links** begin with **_https:\/\/_ or _http:\/\/_** and can be present anywhere in the string.\n4. **There can be multiple links and hashtags in a tweet, but retweet identifier is just one.**\n5. **User mentions** begin with **'@'** and are a continuous word!","2ec5aae0":"Lets check the data types of the columns and convert the *created_str* to datetime if its not already that way.","d56996ac":"Remove rows where no user is mentioned! These are rows where the *user_mentions* column has a [0].","10f5e6b2":"**In Part 2 of this analysis, we take a look at clusters of users based on hashtags used!**","2724ba01":"## Do a larger number of tweets mean higher number of followers?\nLets see if there is a linear correlation here!","233b51a5":"Let's merge this dataframe with the **users** data to get the associated *followers_count* and *name*.","caa2af01":"This gives us each user and the user they mentioned. For meaningful analysis, we want it such that each row has a user against **one** user and not multiple! Let's do that now!","cd8e9417":"**We can see from the chart that no such correlation exists!** Most users have very low tweet counts but their followers range from very few to numerous!","a18ea370":"Nect we need to extract all unique hashtags from the hashtags column just created and take a value count on those!","e8bce0e5":"With the cleaned tweet text now available to us in the _Text_clean_ list, let's append it to our dataframe!"}}