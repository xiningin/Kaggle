{"cell_type":{"1079f79f":"code","020d3065":"code","9eba7796":"code","e29b8263":"code","f43539d5":"code","df2eb90e":"code","e4d06ecc":"code","792cf710":"code","6c28aa13":"code","5d1f97ad":"code","cb0a6bbf":"code","ce75790b":"code","f41a56a7":"code","ae72db14":"code","fb9abec8":"code","46240574":"code","56032a1d":"code","7ebcb401":"code","23c89c10":"code","ef9eae23":"code","ba6ce484":"code","f4d98a15":"code","77319edb":"code","2733705b":"code","b2958904":"code","440d3dc2":"code","d2b716ed":"code","57283aac":"code","852b66b4":"code","1bb5ce2f":"code","13bf2c11":"code","ada0ef90":"markdown","5a9b9e90":"markdown","702e3f3b":"markdown","132c4a82":"markdown","54d34319":"markdown","520ee328":"markdown","5e5cdf1d":"markdown","2d866ac8":"markdown","dc22655a":"markdown","3c33d367":"markdown","119a5b02":"markdown","c78fbf53":"markdown","5c29bf06":"markdown","fe1b1788":"markdown","90d7b4c6":"markdown"},"source":{"1079f79f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \nfrom datetime import datetime\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nimport gc\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","020d3065":"!pip install https:\/\/s3.amazonaws.com\/artifacts.h2o.ai\/releases\/ai\/h2o\/pydatatable\/0.7.0.dev490\/x86_64-centos7\/datatable-0.7.0.dev490-cp36-cp36m-linux_x86_64.whl","9eba7796":"from sklearn.metrics import log_loss, roc_auc_score\nfrom datetime import datetime\nimport datatable as dt\nfrom datatable.models import Ftrl","e29b8263":"%%time\ntrain = dt.fread('..\/input\/train.csv')","f43539d5":"%%time\ntest = dt.fread('..\/input\/test.csv')","df2eb90e":"train.head()","e4d06ecc":"train.shape","792cf710":"test.head()","6c28aa13":"test.shape","5d1f97ad":"train.nunique()","cb0a6bbf":"test.nunique()","ce75790b":"train[:, 'EngineVersion'].nunique1()","f41a56a7":"train_unique = dt.unique(train[:, 'EngineVersion']).to_list()[0]\nlen(train_unique)","ae72db14":"test_unique = dt.unique(test[:, 'EngineVersion']).to_list()[0]\nlen(test_unique)","fb9abec8":"intersection = list(set(train_unique) & set(test_unique))\nlen(intersection)","46240574":"train.names","56032a1d":"train.ltypes","7ebcb401":"'''%%time\nfor name in test.names:\n    if test[:, name].ltypes[0] == dt.ltype.str:\n        train.replace(None, '-1')\n        test.replace(None, '-1')\n    elif test[:, name].ltypes[0] == dt.ltype.int:\n        train.replace(None, -1)\n        test.replace(None, -1)\n    elif test[:, name].ltypes[0] == dt.ltype.bool:\n        train.replace(None, 0)\n        test.replace(None, 0)\n    elif test[:, name].ltypes[0] == dt.ltype.real:\n        train.replace(None, -1.0)\n        test.replace(None, -1.0)'''\n","23c89c10":"%%time\nfor f in train.names:\n    if f not in ['MachineIdentifier', 'HasDetections']:\n        if train[:, f].ltypes[0] == dt.ltype.str:\n            print('factorizing %s' % f)\n            col_f = pd.concat([train[:, f].to_pandas(), test[:, f].to_pandas()], ignore_index=True)\n            encoding = col_f.groupby(f).size()\n            encoding = encoding\/len(col_f)\n            column = col_f[f].map(encoding).values.flatten()\n            del col_f, encoding\n            gc.collect()\n            train[:, f] = dt.Frame(column[:8921483])\n            test[:, f] = dt.Frame(column[8921483:])\n            del column\n            gc.collect()","ef9eae23":"train[:, f]","ba6ce484":"train.head()","f4d98a15":"test.head()","77319edb":"features = [f for f in train.names if f not in ['HasDetections']]\nftrl = Ftrl(nepochs=2, interactions=True)\n","2733705b":"%%time\nprint('Start Fitting on   ', train.shape, ' @ ', datetime.now())\nftrl.fit(train[:, features], train[:, 'HasDetections'])\nprint('Fitted complete on ', train.shape, ' @ ', datetime.now())  \nprint('Current loss : %.6f' \n          % log_loss(np.array(train[:, 'HasDetections'])[:, 0],  \n                             np.array(ftrl.predict(train[:, features]))))","b2958904":"print('Current AUC : %.6f' \n          % roc_auc_score(np.array(train[:, 'HasDetections'])[:, 0],  \n                             np.array(ftrl.predict(train[:, features]))))","440d3dc2":"preds1 = np.array(ftrl.predict(test[:, features]))\npreds1 = preds1.flatten()","d2b716ed":"ftrl = Ftrl(nepochs=20, interactions=False)\nftrl.fit(train[:, features], train[:, 'HasDetections'])\npreds2 = np.array(ftrl.predict(test[:, features]))\npreds2 = preds2.flatten()","57283aac":"np.save('preds1', preds1)\nnp.save('preds2', preds2)","852b66b4":"sample_submission = pd.read_csv('..\/input\/sample_submission.csv')","1bb5ce2f":"sample_submission['HasDetections'] = 0.6*preds1+0.4*preds2","13bf2c11":"sample_submission.to_csv('datatable_ftrl_submission.csv', index=False)","ada0ef90":"To be continued ...","5a9b9e90":"And test:","702e3f3b":"Next, we are going to try to fit an Ftrl model on the train set. Here we will adopt [Olivier's great discussion topic](https:\/\/www.kaggle.com\/c\/microsoft-malware-prediction\/discussion\/75478). First, let's replace all the missing values.","132c4a82":"And test:","54d34319":"Now, let's fit the model:","520ee328":"And their types:","5e5cdf1d":"We see there are only 66 values that overlap in the train and test for this feature.\n\nLet's see what are the names of the features in the dataset:","2d866ac8":"One of the main issues in this competition is the size of the dataset. Pandas crashes when attempting to load the entire train and test datasets at once. [One of the kernels has been able to read the entire train dataset using dask](https:\/\/www.kaggle.com\/ashishpatel26\/how-to-handle-this-big-dataset-dask-vs-pandas). In this kernels we'll use [Python datatable package](https:\/\/github.com\/h2oai\/datatable) to load the entire train and test datasets, and do some simple EDA on them. Python datatable is still in early alpha stage and is under very active curent development. It is designed from ground up for big datasets and with efficiency and speed in mind. It is closely related to [R's data.table](https:\/\/github.com\/Rdatatable\/data.table) and attempts to mimic its core algorithams and API. ","dc22655a":"Now let's load the train dataset:","3c33d367":"Let's take a look at the train:","119a5b02":"Look at the number of unique values in the two datasets:","c78fbf53":"We were able to load all of the train and test datasets, and pretty much exhausted all of kernel's 17.2 GB of RAM. But we did it!","5c29bf06":"Now let's import datatable","fe1b1788":"Unfortunately datatable is not currently available in Kaggle Docker image. My attempts to install it via Kaggle kernel package installation API have failed, but I have been able to load it from the following pre-made wheel. (A huge shoutout to [Olivier](https:\/\/www.kaggle.com\/ogrellier) for his help with this.)","90d7b4c6":"Next, we'll factorize all the string columns. Unfortunately, datatabel still doesn't handle this natively, so we'll have to use the Pandas crutch."}}