{"cell_type":{"10e21a77":"code","ee1a5d01":"code","a64ebb61":"code","e44b74f7":"code","e7b31f09":"code","143cfa57":"code","7818cbdd":"code","df14eaa1":"code","f8a82a74":"code","1c180e03":"code","803f7be8":"markdown","efaf6678":"markdown","02c7ce75":"markdown","0c3e14a8":"markdown","21a79d00":"markdown","f8d743b0":"markdown","34e6a974":"markdown"},"source":{"10e21a77":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n\nimport spacy\nnlp = spacy.load('en_core_web_sm')","ee1a5d01":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\nX_train = np.array(train['text'])\ny_train = np.array(train['target'])\n\ntest = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\nX_test = np.array(test['text'])\n\nsub = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/sample_submission.csv\")\n","a64ebb61":"train['text'].apply(lambda x: len(x)).plot.hist()","e44b74f7":"import re\ndef clean(sen):\n    text=sen.lower()\n    text = re.sub(r'https?:\\\/\\\/.*[\\r\\n]*', '', text)\n    text = re.sub(r'http?:\\\/\\\/.*[\\r\\n]*', '', text)\n    text=text.replace(r'&amp;?',r'and')\n    text=text.replace(r'&lt;',r'<')\n    text=text.replace(r'&gt;',r'>')\n    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n    text=re.sub(r'[:\"#$%&\\*+,-\/:;<=>@\\\\^_`{|}~]+','',text)\n    text=re.sub(r'[!]+','!',text)\n    text=re.sub(r'[?]+','?',text)\n    text=re.sub(r'[.]+','.',text)\n    text=re.sub(r\"'\",\"\",text)\n    text=re.sub(r\"\\(\",\"\",text)\n    text=re.sub(r\"\\)\",\"\",text)\n    \n    text=\" \".join(text.split())\n    \n    return text\n\ndef tok (text):\n    n_t = clean(text)\n    sen = nlp(n_t)\n    new_text_array = []\n    new_text = \" \"\n    for tok in sen:\n        if (not (tok.is_stop or tok.is_punct or tok.pos_ == 'NUM')):\n            new_text_array.append(tok.lemma_)\n            new_text += tok.lemma_ + \" \"\n            \n    return new_text\n\n\ndef pre_pro (texts):\n    doc = []\n    for s in texts:\n        doc.append(tok(s))\n    return np.array(doc)\n\ndocs = pre_pro(X_train)\nprint(\"finished\")","e7b31f09":"from sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\n\nvectorizer =  CountVectorizer(ngram_range=(1, 2),token_pattern=r'\\b\\w+\\b', min_df=5, max_df=100)\nbag = vectorizer.fit_transform(docs)","143cfa57":"from sklearn.feature_selection import SelectKBest, chi2\n \nseleck = SelectKBest(chi2, k=2000)\nX_new = seleck.fit_transform(bag.toarray(), y_train)\nX_new.shape","7818cbdd":"X_train = X_new\n\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import svm\n\nmodel = MultinomialNB()\nmodel.fit(X_train, y_train)","df14eaa1":"docs_test = pre_pro(X_test)\nvectes = vectorizer.transform(docs_test)\nbag_test = seleck.transform(vectes)","f8a82a74":"pred = model.predict(bag_test.toarray())","1c180e03":"sub['target'] = pred\nsub.to_csv('submission_new.csv', index=False)","803f7be8":"# Preprocessing Test Data","efaf6678":"# Create Model","02c7ce75":"# Text Preprocessing","0c3e14a8":"# Predict data ","21a79d00":"# BOW - BINARY","f8d743b0":"# Read Dataset","34e6a974":"# Select K Bests - CHI2 (k = 2000)"}}