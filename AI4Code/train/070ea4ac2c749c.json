{"cell_type":{"76728405":"code","d1c675e0":"code","3575d6b2":"code","3fc81dad":"code","255708dc":"code","977012bd":"code","b3abb209":"code","c2640605":"code","cb72a10c":"code","57b1da45":"code","e751b8bb":"code","62aa31a7":"code","e267d733":"markdown","fd882b36":"markdown","166c946e":"markdown","380f7efe":"markdown","035039a8":"markdown","359fdd62":"markdown","8ee0f058":"markdown","fc6a1f86":"markdown","7e876038":"markdown","c85d0a89":"markdown"},"source":{"76728405":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.linear_model import LogisticRegression, LogisticRegressionCV\n\nfrom sklearn.metrics import confusion_matrix, roc_curve, roc_auc_score\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","d1c675e0":"cancer = pd.read_csv(\"\/kaggle\/input\/breast-cancer-prediction-dataset\/Breast_cancer_data.csv\")\ncancer.head()","3575d6b2":"cancer.describe().T","3fc81dad":"scaler = MinMaxScaler()\ncancer = pd.DataFrame(data=scaler.fit_transform(cancer), columns=cancer.columns)\ncancer.head()","255708dc":"sns.pairplot(data=cancer)","977012bd":"plt.figure(figsize=(10, 8))\nsns.heatmap(cancer.corr(), annot=True)","b3abb209":"target = cancer.diagnosis\nfeatures = cancer.drop(columns=[\"diagnosis\"])","c2640605":"while True:\n    temp_var = 0\n    temp_col = \"\"\n    for i in range(features.shape[1]):\n        if variance_inflation_factor(features.values, i) > temp_var:\n            temp_col = features.columns[i]\n            temp_var = variance_inflation_factor(features.values, i)\n    if temp_var > 5:\n        print(\"Dropping feature '{}' which has a VIF value: {}\\n\".format(temp_col, temp_var))\n        features.drop(columns=[temp_col], inplace=True)\n    else:\n        break\n        \nprint(\"Final Features with VIF <=5:\")\nfor i in range(features.shape[1]):\n    print(features.columns[i], variance_inflation_factor(features.values, i))","cb72a10c":"X_train, X_test, y_train, y_test = train_test_split(features, target, random_state=0)","57b1da45":"model_data = []\nlistOfModels = [LogisticRegression(), LogisticRegressionCV(), KNeighborsClassifier(), SVC(), GradientBoostingClassifier(), DecisionTreeClassifier()]\n\nfor model in listOfModels:\n    classifier = model\n    classifier.fit(X_train, y_train)\n    y_pred = classifier.predict(X_test)\n    model_data.append([model.__class__.__name__, roc_auc_score(y_test, y_pred)])\n    \nmodel_data_frame = pd.DataFrame(columns=[\"Model\", \"ROC_Score\"], data=model_data)\nprint(model_data_frame.sort_values(\"ROC_Score\"))","e751b8bb":"print(\"Confusion Matrix\")\nprint(pd.DataFrame(data=confusion_matrix(y_test, y_pred), columns=[\"Predicted True\", \"Predicted False\"], index=[\"Actual True\", \"Actual False\"]))","62aa31a7":"falsePositive, truePositive, threshold = roc_curve(y_test, y_pred, pos_label=1)\nplt.figure(figsize=(10, 8))\nsns.lineplot(falsePositive, truePositive)\nplt.title(\"ROC - AUC Curve\")","e267d733":"# Using different classification models and selecting the best fit","fd882b36":"# Data Scaling","166c946e":"Clearly, there is no missing data so we can proceed with the next steps:\n1. Scaling\n2. Visualization\n3. Modification (if required)","380f7efe":"# Removing multi-colilinearity using VIF\nHere we remove the features that increase the multi-collinearity of the data distribution. We do this using variance_inflation_factor","035039a8":"# Splitting data into training and test set","359fdd62":"# Check if there is missing data","8ee0f058":"# Data Visualization","fc6a1f86":"Gradient Boosting Classifier is the best fitting model amongst all. We'll now derive its confusion matrix and plot auc-roc curve","7e876038":"# Loading dataset","c85d0a89":"From the above pairplot it is clearly visible that \"mean_area\", \"mean_radius\" and \"mean_perimeter\" are closely related to one another and can thereby be removed to reduce collinearity. Same can be visualized using the heatmap (as shown below)"}}