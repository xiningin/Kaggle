{"cell_type":{"019d0047":"code","7d0fc3cd":"code","9b72b8d1":"code","74284b4a":"code","7f991765":"code","6cdb1d95":"code","d68c4e1c":"code","1a608dec":"code","fb0607a1":"code","e45a012e":"code","d703e760":"code","b367d777":"code","711f0ffa":"code","e4091ad7":"code","a253f379":"code","6fcbb48e":"code","863ce7ab":"code","1e6e5f77":"code","37f9c437":"code","13555ce5":"code","6f45cd19":"code","c8628f56":"code","ded79b59":"code","12004ef8":"code","e15157ed":"code","1b57374a":"code","83b437a3":"code","64147e48":"code","d339e464":"code","5c828b3f":"code","fc0e54f6":"code","196aae25":"code","cc8aa893":"code","f086a8e4":"markdown","1a1597e3":"markdown","c499c5b4":"markdown","60d4d287":"markdown"},"source":{"019d0047":"import pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn import metrics","7d0fc3cd":"df = pd.read_csv(r\"..\/input\/predicting-a-pulsar-star\/pulsar_stars.csv\")","9b72b8d1":"df.sample(10)","74284b4a":"df['target_class'].value_counts()","7f991765":"df.columns","6cdb1d95":"df.hist(column = ' Standard deviation of the integrated profile', bins = 50)","d68c4e1c":"x = df[[' Mean of the integrated profile',\n       ' Standard deviation of the integrated profile',\n       ' Excess kurtosis of the integrated profile',\n       ' Skewness of the integrated profile', ' Mean of the DM-SNR curve',\n       ' Standard deviation of the DM-SNR curve',\n       ' Excess kurtosis of the DM-SNR curve', ' Skewness of the DM-SNR curve']].values\n\nx","1a608dec":"y = df['target_class'].values\ny","fb0607a1":"x = preprocessing.StandardScaler().fit(x).transform(x.astype(float))\nx","e45a012e":"x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)\nprint('Train set: ', x_train.shape, y_train.shape)\nprint('Test set: ', x_test.shape, y_test.shape)","d703e760":"Ks = 30\nmean_acc = np.zeros((Ks-1))\nstd_acc = np.zeros((Ks-1))\nConfusionMx = []\nfor n in range(1, Ks):\n    neigh = KNeighborsClassifier(n_neighbors= n).fit(x_train, y_train)\n    yhat = neigh.predict(x_test)\n    mean_acc[n-1] = metrics.accuracy_score(y_test,yhat)\n    std_acc[n-1] = np.std(yhat == y_test)\/np.sqrt(yhat.shape[0])\n    \nmean_acc","b367d777":"plt.plot(range(1,Ks),mean_acc,'g')\nplt.fill_between(range(1,Ks),mean_acc - 1 * std_acc,mean_acc + 1 * std_acc, alpha=0.10)\nplt.legend(('Accuracy ', '+\/- 3xstd'))\nplt.ylabel('Accuracy ')\nplt.xlabel('Number of Nabors (K)')\nplt.tight_layout()\nplt.show()","711f0ffa":"print( \"The best accuracy was with\", mean_acc.max(), \"with k=\", mean_acc.argmax()+1) ","e4091ad7":"!apt-get -qq install -y graphviz && pip install -q pydotplus\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.externals.six import StringIO\nfrom sklearn import tree\nimport pydotplus\nimport matplotlib.image as mpimg\n%matplotlib inline","a253f379":"pulsar_stars = DecisionTreeClassifier(criterion = 'gini', max_depth = 10)\npulsar_stars.fit(x_train, y_train)","6fcbb48e":"predTree = pulsar_stars.predict(x_test)\nprint(\"DecisionTree's Accuracy: \", metrics.accuracy_score(y_test, predTree))","863ce7ab":"dot_data = StringIO()\nfilename = \"pulsar_stars.png\"\nfeaturesNames = df.columns[0:8]\ntargetNames = ['0', '1']\nout = tree.export_graphviz(pulsar_stars, \n                           feature_names = featuresNames, \n                           out_file= dot_data, \n                           class_names = targetNames, \n                           filled = True, \n                           special_characters = True,\n                           rotate = False)","1e6e5f77":"graph = pydotplus.graph_from_dot_data(dot_data.getvalue())\ngraph.write_png(filename)\nimg = mpimg.imread(filename)\nplt.figure(figsize=(60, 60))\nplt.imshow(img, interpolation = 'nearest')","37f9c437":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import jaccard_similarity_score\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import log_loss\nimport itertools","13555ce5":"LR = LogisticRegression(C=0.05, solver='liblinear').fit(x_train, y_train)\nLR","6f45cd19":"yhat = LR.predict(x_test)\nyhat","c8628f56":"yhat_prob = LR.predict_proba(x_test)\nyhat_prob","ded79b59":"jaccard_similarity_score(y_test, yhat)","12004ef8":"def plot_confusion_matrix(cm,\n                         classes,\n                         normalize = False, #normalize can be True\n                         title='Confusion Matrix',\n                         cmap = plt.cm.Blues):\n    if normalize:\n        cm = cm.astype('float')\/cm.sum(axis=1)[:, np.newaxis]\n        print (\"Normalize confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n    \n    print (cm)\n    \n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation = 45)\n    plt.yticks(tick_marks, classes)\n    \n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max()\/2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                horizontalalignment = 'center',\n                color = 'white' if cm[i, j] > thresh else \"black\")\n        \n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    \nprint(confusion_matrix(y_test, yhat, labels = [1, 0]))","e15157ed":"cnf_matrix = confusion_matrix(y_test, yhat, labels=[1,0])\nnp.set_printoptions(precision = 2)\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['target_class = 1', 'target_class = 0'], normalize = False, title = 'Confusion matrix')","1b57374a":"print(classification_report(y_test, yhat))","83b437a3":"log_loss(y_test, yhat_prob)","64147e48":"from sklearn import svm\nfrom sklearn.metrics import classification_report, confusion_matrix\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import jaccard_similarity_score\nimport itertools","d339e464":"clf = svm.SVC(kernel = 'rbf', gamma = 'auto')\nclf.fit(x_train, y_train)","5c828b3f":"yhat = clf.predict(x_test)\nyhat[0:5]\nyhat","fc0e54f6":"cnf_matrix = confusion_matrix(y_test, yhat)\nnp.set_printoptions(precision = 2)\n\nprint(classification_report(y_test, yhat))\n\nplt.figure()\nplot_confusion_matrix(cnf_matrix, classes=['Benign(2)', 'Malignant(4)'], normalize = False, title = 'Confusion Matrix')\n","196aae25":"f1_score(y_test, yhat, average = 'weighted')","cc8aa893":"jaccard_similarity_score(y_test, yhat)","f086a8e4":"# Logistic Regression","1a1597e3":"# Support Vector Machine","c499c5b4":"# K Nearest Neighbor","60d4d287":"# Decision Tree"}}