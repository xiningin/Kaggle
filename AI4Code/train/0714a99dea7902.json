{"cell_type":{"b0e0e34e":"code","369b21e4":"code","65b90cde":"code","08f7dd14":"code","f53c3d5c":"code","1db2d2da":"code","d90dbfbb":"code","96534c9a":"code","2cc95c9f":"code","6ce69a5f":"code","d43ec639":"code","d86dee61":"code","a449e810":"code","807d1d21":"code","b2f96c2c":"code","a43738b5":"code","50b50e15":"code","b5c98556":"code","fc129f3f":"code","55551da2":"code","752b38e3":"code","ec04ce25":"code","820ac7ea":"code","abf05d63":"code","43be3300":"code","771ba3b6":"code","20688455":"code","57f5b85f":"code","d9d88647":"code","e179f3e0":"code","465e20bc":"code","c13b0d9a":"code","d9d555ce":"code","ca4b6354":"code","b3fdcb89":"code","750f3ba8":"code","abc21d75":"code","680fff37":"code","151e8bbe":"code","af713a95":"code","cf38ab7a":"code","cd8ac89b":"code","0bf7ca52":"code","ba7f3706":"code","2402e3bc":"code","c11206d4":"code","fd5c4e38":"code","15286abc":"code","8927ba9a":"code","bd78289b":"code","0e088bfa":"code","8d064c35":"code","a3f47187":"code","2d0285db":"code","58a19f4c":"code","e7ad1e35":"code","5b4197e5":"code","68795975":"code","68e90679":"code","3a091dce":"markdown","d36ab5b5":"markdown","8b27584f":"markdown"},"source":{"b0e0e34e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","369b21e4":"import numpy as np\nimport pandas as pd","65b90cde":"data=pd.read_csv('..\/input\/fake-news\/train.csv')","08f7dd14":"test=pd.read_csv('..\/input\/fake-news\/test.csv')","f53c3d5c":"data.shape","1db2d2da":"data.head(2)","d90dbfbb":"test.shape","96534c9a":"test.head(2)","2cc95c9f":"data.info()","6ce69a5f":"data.isnull().sum()","d43ec639":"test.isnull().sum()","d86dee61":"data=data.dropna()","a449e810":"test=test.fillna(\" \")","807d1d21":"test.isnull().sum()","b2f96c2c":"data.isnull().sum()","a43738b5":"data['label'].hist()","50b50e15":"x=data.drop(['label'],1)","b5c98556":"y=data['label']","fc129f3f":"x.head(2)","55551da2":"y.head(2)","752b38e3":"y.value_counts()","ec04ce25":"import tensorflow as tf\nfrom tensorflow.keras.layers import Embedding\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.preprocessing.text import one_hot\nfrom tensorflow.keras.layers import LSTM , Dense , Bidirectional , Dropout\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom sklearn.metrics import accuracy_score","820ac7ea":"vocabulary_size=6000","abf05d63":"news=x.copy()","43be3300":"nltk.download('stopwords')","771ba3b6":"news.reset_index(inplace=True)","20688455":"news.head(2)","57f5b85f":"news['title']=news['title']+news['author']","d9d88647":"test['title']=test['title']+test['author']","e179f3e0":"ps=PorterStemmer()","465e20bc":"corpus=[]","c13b0d9a":"news['title'][0]","d9d555ce":"re.sub('[^a-zA-Z]' , \" \", news['title'][0])","ca4b6354":"re.sub('[^a-zA-Z]' , \" \", news['title'][0]).lower()","b3fdcb89":"words=re.sub('[^a-zA-Z]' , \" \", news['title'][0]).lower().split()\nwords","750f3ba8":"[ps.stem(word) for word in words if not word in stopwords.words('english')]","abc21d75":"for i in range(len(news)):\n    title=re.sub('[^a-zA-Z]' , \" \", news['title'][i]).lower().split()\n    title= [ps.stem(word) for word in title if not word in stopwords.words('english')]\n    title=' '.join(title)\n    corpus.append(title)","680fff37":"corpus_test=[]\nfor i in range(len(test)):\n    title=re.sub('[^a-zA-Z]' , \" \", test['title'][i]).lower().split()\n    title= [ps.stem(word) for word in title if not word in stopwords.words('english')]\n    title=' '.join(title)\n    corpus_test.append(title)","151e8bbe":"len(corpus_test)","af713a95":"corpus[:4]","cf38ab7a":"onehot_representation=[one_hot(words , vocabulary_size) for words in corpus] ","cd8ac89b":"onehot_representation_test=[one_hot(words , vocabulary_size) for words in corpus_test] ","0bf7ca52":"onehot_representation[:5]","ba7f3706":"padding_length=25\npadded_title=pad_sequences(onehot_representation , padding='pre' , maxlen=padding_length)","2402e3bc":"padded_title_test=pad_sequences(onehot_representation_test , padding='pre' , maxlen=padding_length)","c11206d4":"padded_title[:5]","fd5c4e38":"len(padded_title)","15286abc":"y.shape","8927ba9a":"x=np.array(padded_title)\ny=np.array(y)","bd78289b":"x_test=np.array(padded_title_test)","0e088bfa":"model2=Sequential([\n    Embedding(vocabulary_size , 40, input_length=padding_length),\n    Dropout(0.3),\n    LSTM(100),\n    Dropout(0.3),\n    Dense(64,activation='relu'),\n    Dropout(0.3),\n    Dense(1,activation='sigmoid')\n])\nmodel2.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])","8d064c35":"history=model2.fit(x,y,epochs=10,batch_size=64)","a3f47187":"import matplotlib.pyplot as plt","2d0285db":"plt.plot(history.history['accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')","58a19f4c":"pred=model2.predict_classes(x_test)","e7ad1e35":"pred.shape","5b4197e5":"submission_data = pd.read_csv('\/kaggle\/input\/fake-news\/submit.csv')","68795975":"submission_data['label']=pred","68e90679":"submission_data.to_csv('submit.csv' ,index=False)","3a091dce":"# Cleaning text  \nRemoved urls, emojis and punctuations , stopwords\nand Lower cased clean text","d36ab5b5":"# Model creation","8b27584f":"Model training"}}