{"cell_type":{"448ff66a":"code","3d2c7dba":"code","8aebf06f":"code","5bbd4598":"code","68bdd0b8":"code","4e4955a0":"code","76f986be":"code","056d957f":"code","3bfde8b7":"code","674972e1":"code","4cedd135":"code","5bdd242e":"code","df8b299c":"code","364b912a":"code","70dafb61":"code","6c8ed521":"code","5985d45d":"code","e7420319":"code","db927d5c":"code","1b52f714":"code","623ff9c3":"code","f0b31ece":"code","44c8f3f5":"code","216cca08":"code","82c76dec":"code","38b88c11":"code","d90b97cd":"code","f28a52b6":"code","ad73694f":"code","9715fdc7":"code","849272d4":"code","912759dd":"code","9988fdb9":"markdown","73629ed8":"markdown","0519ec5c":"markdown","4f49cf60":"markdown","560b46ad":"markdown","2651b6e1":"markdown","aae7fccf":"markdown","5ac37dd6":"markdown","3f63c513":"markdown","dd65f092":"markdown","56e2cc52":"markdown"},"source":{"448ff66a":"!pip install efficientnet_pytorch","3d2c7dba":"import torch\nimport tqdm\nimport copy\nimport cv2\nimport pandas as pd\nimport numpy as np\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nimport os\nimport pandas as pd\nimport seaborn as sns\n#import matplotlib\nimport matplotlib.pyplot as plt\nfrom torch.utils.data import DataLoader\nimport torch.nn as nn\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.model_selection import train_test_split\nfrom imblearn.over_sampling import RandomOverSampler\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV\n\nfrom efficientnet_pytorch import EfficientNet\nfrom torch.optim.lr_scheduler import StepLR","8aebf06f":"#prepare data for training first NN\ndf = pd.read_csv('..\/input\/seti-breakthrough-listen\/train_labels.csv')\ndf['img_path'] = df['id'].apply(lambda x: f'..\/input\/seti-breakthrough-listen\/train\/{x[0]}\/{x}.npy')\nX = df['img_path'].values\nY = df['target'].values\n\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size=0.05, stratify = Y, random_state = 1)\n\ndf = pd.DataFrame({'image': X_train,\n                      'target': y_train})\ndf = df.sample(frac=1)","5bbd4598":"class make_tensor:\n    \n    def __init__(self, images, labels, mode = 'train'):\n        self.image = images\n        self.label = labels\n        self.mode = mode\n        \n    def __len__(self):\n        return len(self.image)\n\n    def __getitem__(self, idx):\n        im = self.image[idx]\n        lb = self.label[idx]\n        sample = {\"image\":  torch.tensor(im, dtype=torch.float), \n                  \"label\":  torch.tensor(lb).item()}\n            \n        return sample","68bdd0b8":"X = []\nY = []\n\nfor path, target in zip(X_test, y_test): \n    temp = np.load(path)\n    if target == 1:\n        for t in range(6):\n            label = [1,0][t % 2]\n            im = temp[t].astype(np.float32)\n            im = cv2.resize(im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n            im1 = cv2.flip(im, 1)\n                        \n            X.append(im)\n            X.append(im1)\n            Y.append(label)\n            Y.append(label)\n        \n    else:\n         for t in range(6):\n                label = 0\n                im = temp[t].astype(np.float32)\n                im = cv2.resize(im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                        \n                X.append(im)\n                Y.append(label)\n    del(temp)\n\nprint(np.shape(X))\nvalid_data = make_tensor(X, Y)\nvalid_data = DataLoader(valid_data, batch_size=64, shuffle=True, drop_last = True)\n\ndel(X, Y)","4e4955a0":"class CNN(nn.Module):\n    def __init__(self, name, output_dim):\n        super(CNN, self).__init__()\n        self.model = EfficientNet.from_pretrained(name)\n        self.model._fc = nn.Linear(in_features = self.model._fc.in_features, out_features=output_dim)\n        self.conv =  nn.Conv2d(1, 3, kernel_size=1, stride=1, bias=False)\n        \n        \n    def forward(self, image):\n        image.requires_grad_(True)\n        image = torch.unsqueeze(image, 1)\n        image = self.conv(image)\n        \n        output = self.model(image)\n        \n        return(output)","76f986be":"model = CNN(name = 'efficientnet-b4', output_dim = 1)","056d957f":"best_model_wts = []\nauc_fin_tr = []\nacc_fin_tr = []\nauc_fin_val = []\nacc_fin_val = []\nlos_fin_train = []\nlos_fin_test = []\n\ndef train(df, x_valid, model, learning_rate = 0.0001, num_epochs = 1, max_num = 512):\n    loss_fn = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    scheduler = StepLR(optimizer, step_size = 2, gamma=0.1, verbose=True)\n    \n\n    best_auc = 0.0\n    auc_tr_eph = []\n    acc_tr_eph = []    \n        \n    for epoch in tqdm.tqdm(range(num_epochs), position=0, leave=True, desc='Epoch'):\n        \n        running_loss_tr = 0.0\n        running_loss_test = 0.0\n        \n        acc_tr = []\n        auc_tr = []\n        \n        start = -max_num\n        end = 0\n        \n        model.train()\n        \n        for batch_counter in tqdm.tqdm(range(int(len(df)\/max_num)),position=0, leave=True, desc='Load batch'):\n            #print(\"Batch counter:\", batch_counter)\n            start += max_num\n            end += max_num\n            X = []\n            Y = [] \n            auc_tr_mb = []\n            acc_tr_mb = []\n        \n            for path, target in zip(df['image'][start:end], df['target'][start:end].values): \n                temp = np.load(path)\n                if target == 1:\n                    for t in range(6):\n                        label = [1,0][t % 2]\n                        im = temp[t].astype(np.float32)\n                        im = cv2.resize(im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                        im1 = cv2.flip(im, 1)\n                        \n                        X.append(im)\n                        X.append(im1)\n                        Y.append(label)\n                        Y.append(label)\n        \n                else:\n                    for t in range(6):\n                        label = 0\n                        im = temp[t].astype(np.float32)\n                        im = cv2.resize(im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                        \n                        X.append(im)\n                        Y.append(label)\n        \n        \n            \n            x_train = make_tensor(X,Y)\n            x_oversam = [x['image'].numpy() for x in x_train]\n            y_oversam = [x['label'] for x in x_train]\n            \n            n, xd, yd = np.shape(x_oversam)\n            #print(n)\n            y_oversam = np.reshape(y_oversam, (-1, 1))\n            x_oversam = np.reshape(x_oversam, (n,xd*yd))\n            \n            overrsample = RandomOverSampler(sampling_strategy=1)\n            X, Y = overrsample.fit_resample(x_oversam, y_oversam)\n            n, _ = np.shape(X)\n            #print(n)\n            X = np.reshape(X, (n, xd, yd))\n            Y = np.reshape(Y, (-1,))\n            \n            \n            x_train = make_tensor(X,Y)\n            x_train = DataLoader(x_train, batch_size=32, shuffle=True, drop_last = True)\n            del(X, Y)\n            del(x_oversam, y_oversam)\n        \n            for data in tqdm.tqdm(x_train, position=0, leave=True, desc='Training'):\n                model.zero_grad()\n                x = data['image']\n                y = data['label']\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device, dtype=torch.float)\n        \n                output =  model(x)\n            #print('\u0412\u044b\u0445\u043e\u0434 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f: ', output[:3] )\n                loss = loss_fn(output, torch.unsqueeze(y, 1))\n                loss.backward()\n                optimizer.step()\n                running_loss_tr += loss.item()\n            \n                y = torch.unsqueeze(y, 1).detach().cpu().numpy().tolist()\n                output = output.detach().cpu().numpy().tolist()\n                output = sum(output, [])\n            \n                for i in range(len(output)):\n                    if output[i] >= 0:\n                        output[i] = int(1)\n                    else:\n                        output[i] = int(0)\n                \n                roc = roc_auc_score(y, output)\n                acc = accuracy_score(y, output)\n                auc_tr_mb.append(roc)\n                acc_tr_mb.append(acc)\n                                     \n            \n            auc_tr.append(np.mean(auc_tr_mb))\n            acc_tr.append(np.mean(acc_tr_mb))\n        \n        auc_tr_eph = np.mean(auc_tr)\n        acc_tr_eph = np.mean(acc_tr)\n    \n        del(auc_tr, acc_tr)\n        \n        auc_val = []\n        acc_val = []\n    \n        model.eval()\n        with torch.no_grad():\n            \n            \n            for data in tqdm.tqdm(x_valid, position=0, leave=True, desc='Testing'):\n                x = data['image']\n                y = data['label']\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device, dtype=torch.float)\n            \n                output =  model(x)\n                loss = loss_fn(output, torch.unsqueeze(y, 1))\n                running_loss_test += loss.item()\n                y = torch.unsqueeze(y, 1).detach().cpu().numpy().tolist()\n                output = output.detach().cpu().numpy().tolist()\n                output = sum(output, [])\n            \n                for i in range(len(output)):\n                    if output[i] >= 0:\n                        output[i] = int(1)\n                    else:\n                        output[i] = int(0)\n                \n                try:\n                    auc_val.append(roc_auc_score(y, output))\n                    acc_val.append(accuracy_score(y, output))\n                except ValueError:\n                    pass\n\n            auc_val = np.mean(auc_val)\n            acc_val = np.mean(acc_val)\n         \n        if best_auc < auc_val:\n            best_auc = auc_val\n            torch.save(model.state_dict(), f'.\/best_us_model-epoch-{epoch+1}.pth')\n            print(\"This model is saved.\")\n    \n    \n        auc_fin_tr.append(auc_tr_eph)\n        acc_fin_tr.append(acc_tr_eph)\n        auc_fin_val.append(auc_val)\n        acc_fin_val.append(acc_val)\n        los_fin_train.append(running_loss_tr)\n        los_fin_test.append(running_loss_test)\n        \n        print(f'Epoch: {epoch} \\n  Train loses = {running_loss_tr}, \\n Train accur = {acc_tr_eph}, \\n \\\n        Train AUC = {auc_tr_eph} \\n Val loses = {running_loss_test}, \\n \\\n        Val accur = {acc_val} \\n Val AUC = {auc_val}, ') \n        scheduler.step()","3bfde8b7":"#train(df, valid_data, model = model, learning_rate = 0.001, num_epochs = 5, max_num = 256)","674972e1":"model.load_state_dict(torch.load('..\/input\/usmodel5epoch\/new_SETI_us_5epoch.pth'))","4cedd135":"#prepare data for training second NN\noverrsample = RandomOverSampler(sampling_strategy=1)\nX_train, y_train = overrsample.fit_resample(X_train.reshape(-1,1), y_train)\nX_train = X_train.reshape(-1,)\n\ndf1 = pd.DataFrame({'image': X_train,\n                      'target': y_train})\ndf1 = df1.sample(frac=1)","5bdd242e":"class make_tensor1:\n    \n    def __init__(self, images, labels):\n        self.image = images\n        self.label = labels\n        \n    def __len__(self):\n        return len(self.image)\n\n    def __getitem__(self, idx):\n        im = np.load(self.image[idx])\n        lb = self.label[idx]\n        sample = {\"image\":  torch.tensor(im, dtype=torch.float), \n                  \"label\":  torch.tensor(lb).item()}\n            \n        return sample","df8b299c":"valid_data1 = make_tensor1(X_test, y_test)\nvalid_data1 = DataLoader(valid_data1, batch_size=64, shuffle=True, drop_last = True)","364b912a":"class common_CNN(nn.Module):\n    def __init__(self, name, output_dim):\n        super(common_CNN, self).__init__()\n        self.model = EfficientNet.from_pretrained(name)\n        self.model._fc = nn.Linear(in_features = self.model._fc.in_features, out_features=output_dim)\n        self.conv =  nn.Conv2d(6, 3, kernel_size=1, stride=1, bias=False)\n        \n        \n    def forward(self, image):\n        image.requires_grad_(True)\n        #image = torch.unsqueeze(image, 1)\n        image = self.conv(image)\n        \n        output = self.model(image)\n        \n        return(output)","70dafb61":"model1 = common_CNN(name = 'efficientnet-b4', output_dim = 1)","6c8ed521":"best_model_wts = []\nauc_fin_tr = []\nacc_fin_tr = []\nauc_fin_val = []\nacc_fin_val = []\nlos_fin_test = []\n\n\ndef common_train(df,x_valid, model, epoch = 1, max_num = 256, learning_rate = 0.0001):\n    loss_fn = nn.BCEWithLogitsLoss()\n    optimizer = torch.optim.Adam(model.parameters(),lr=learning_rate)\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    scheduler = StepLR(optimizer, step_size = 1, gamma=0.1, verbose=True) \n    best_auc = 0\n    \n    for ep in range(epoch):\n        start = -max_num\n        end = 0\n        auc_tr = []\n        acc_tr = []\n    \n        for batch_counter in tqdm.tqdm(range(int(len(df)\/max_num)),position=0, leave=True, desc='Load batch'):\n            #print(\"Batch counter:\", batch_counter, 'from', int(len(df)\/max_num))\n            start += max_num\n            end += max_num\n            \n            x = df['image'][start:end].values \n            y = df['target'][start:end].values\n                \n            x_train = make_tensor1(x,y)\n            x_train = DataLoader(x_train, batch_size=32, shuffle=True, drop_last = True)\n            del(x, y)\n            \n            auc_tr_mb = []\n            acc_tr_mb = []\n            \n            model.train()\n            for data in tqdm.tqdm(x_train, position=0, leave=True, desc='Training'):\n                model.zero_grad()\n                x = data['image']\n                y = data['label']\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device, dtype=torch.float)\n        \n                output =  model(x)\n                loss = loss_fn(output, torch.unsqueeze(y, 1))\n                loss.backward()\n                optimizer.step()\n            \n                y = torch.unsqueeze(y, 1).detach().cpu().numpy().tolist()\n                output = output.detach().cpu().numpy().tolist()\n                output = sum(output, [])\n            \n                for i in range(len(output)):\n                    if output[i] >= 0:\n                        output[i] = int(1)\n                    else:\n                        output[i] = int(0)\n                 \n                try:\n                    auc_tr_mb.append(roc_auc_score(y, output))\n                    acc_tr_mb.append(accuracy_score(y, output))\n                except ValueError:\n                    pass\n                                     \n            \n            auc_tr.append(np.mean(auc_tr_mb))\n            acc_tr.append(np.mean(acc_tr_mb))\n        \n        auc_tr_eph = np.mean(auc_tr)\n        acc_tr_eph = np.mean(acc_tr)\n    \n        del(auc_tr, acc_tr)\n        \n        auc_val = []\n        acc_val = []\n        running_loss_test = 0\n    \n        model.eval()\n        with torch.no_grad():   \n            for data in tqdm.tqdm(x_valid, position=0, leave=True, desc='Testing'):\n                x = data['image']\n                y = data['label']\n                x = x.to(device, dtype=torch.float)\n                y = y.to(device, dtype=torch.float)\n            \n                output =  model(x)\n                #print('\u0412\u044b\u0445\u043e\u0434 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438: ', output[:3] )\n                loss = loss_fn(output, torch.unsqueeze(y, 1))\n                running_loss_test += loss.item()\n                y = torch.unsqueeze(y, 1).detach().cpu().numpy().tolist()\n                output = output.detach().cpu().numpy().tolist()\n                output = sum(output, [])\n            \n                for i in range(len(output)):\n                    if output[i] >= 0:\n                        output[i] = int(1)\n                    else:\n                        output[i] = int(0)\n                \n                try:\n                    auc_val.append(roc_auc_score(y, output))\n                    acc_val.append(accuracy_score(y, output))\n                except ValueError:\n                    pass\n        \n            auc_val = np.mean(auc_val)\n            acc_val = np.mean(acc_val)\n         \n        if best_auc < auc_val:\n            best_auc = auc_val\n            torch.save(model.state_dict(), f'.\/com_model_epoh{ep+6}.pth')\n            print(\"This model is saved.\")\n    \n    \n        auc_fin_tr.append(auc_tr_eph)\n        acc_fin_tr.append(acc_tr_eph)\n        auc_fin_val.append(auc_val)\n        acc_fin_val.append(acc_val)\n        los_fin_test.append(running_loss_test)\n        \n        print(f'Epoch: {ep+1} \\n Train accur = {acc_tr_eph}, \\n \\\n        Train AUC = {auc_tr_eph} \\n Val loses = {running_loss_test}, \\n \\\n        Val accur = {acc_val} \\n Val AUC = {auc_val}') \n        scheduler.step()\n","5985d45d":"#common_train(df = df1,x_valid = valid_data1, model = model1, learning_rate = 0.0001, epoch = 1, max_num = 512)","e7420319":"model1.load_state_dict(torch.load('..\/input\/com-model-epoch1\/com_model_epoh1.pth'))","db927d5c":"#Create Data Frame where each column is prediction of first and second NN\nfeature0 = []\nfeature1 = []\nfeature2 = []\nfeature3 = []\nfeature4 = []\nfeature5 = []\nfeature6 = []\ntarget = []\n\ndef feature_table(x, y, model, model1):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model1.to(device)\n    \n    valid = make_tensor1(x, y)\n    valid = DataLoader(valid, batch_size=64, shuffle=False, drop_last = False)\n    \n    with torch.no_grad():\n        model.eval()\n        model1.eval()\n        for data in valid:\n            \n            x = data[\"image\"]\n            y = data['label']\n            x = x.to(device, dtype=torch.float)\n            y = y.to(device, dtype=torch.float)\n            target.extend(y.tolist())\n            \n            output =  model1(x)\n                \n            output = torch.sigmoid(output)\n            output = output.reshape(-1,) \n            feature0.extend(output.tolist())\n            \n            \n            for im in x:\n                temp = []\n                for sub_im in im:\n                    sep_im = sub_im.cpu().numpy().astype(np.float32)\n                    sep_im = cv2.resize(src = sep_im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                    temp.append(sep_im)\n                    \n                in_put = make_tensor(temp, y[range(6)])\n                in_put = DataLoader(in_put, batch_size=6, shuffle=False, drop_last = False)\n                    #sep_im = torch.tensor(sep_im, dtype=torch.float)\n                    #sep_im  = torch.unsqueeze(sep_im , 0)\n                    \n                out = model(next(iter(in_put))['image'].to(device, dtype=torch.float))\n                out = out.reshape(-1,) \n                out = torch.sigmoid(out)\n                for n in range(6):\n                    globals()[\"feature{}\".format(n+1)].append(out[n].item())\n            \n    \n    feature_df1 = pd.DataFrame(data= zip(feature1, feature2, feature3, feature4, feature5,\n                                      feature6, target),columns=['feature1', 'feature2','feature3', \n                                                          'feature4', 'feature5', 'feature6', 'target'])\n    \n    feature_df1.insert(0, value = feature0, column = 'feature0')\n    \n    return feature_df1","1b52f714":"#feature_df = feature_table(x = X_test, y = y_test, model = model, model1 = model1)","623ff9c3":"feature_df = pd.read_csv('..\/input\/feature-df-5us-1com\/feature_df_5us_1com.csv')","f0b31ece":"#Use GridSearch to find best parametrs for Random Forest Classifier\n\nparam_grid = { \n    'n_estimators': [150, 350],\n    'max_features': [4,5,6,7],\n    'max_depth' : [5, 10, 15, None],\n    'min_samples_split': [2, 3, 7, 10],\n    'bootstrap' : [True],\n    'criterion' :['gini', 'entropy']\n}\n\n\n#rf = RandomForestClassifier(random_state=0, n_jobs = -1)\n#clf = GridSearchCV(rf, param_grid, cv = 3, refit='AUC')\n#clf.fit(feature_df.iloc[:, 0:7], feature_df['target'])\n","44c8f3f5":"import pickle\nclf = pickle.load(open('..\/input\/forest-5us-1com\/forest_5us_1com.sav', 'rb'))","216cca08":"cm = confusion_matrix(feature_df.target, clf.predict(feature_df.iloc[:, 0:7]))\ncm","82c76dec":"roc_auc_score(feature_df.target, clf.predict(feature_df.iloc[:, 0:7]))","38b88c11":"from catboost import CatBoostClassifier\ncatb = CatBoostClassifier(random_state=42,\n                                 thread_count=4,\n                                 verbose=False,\n                                 loss_function='Logloss',\n                                 od_type=\"Iter\",\n                                 early_stopping_rounds=500,\n                                 iterations=5000)\ncatb.fit(feature_df.iloc[:, 0:7], feature_df['target'])","d90b97cd":"#prepare data for submission\npath = []\nid = []\narr = os.listdir('..\/input\/seti-breakthrough-listen\/test')\nfor folder in arr:\n    content = os.listdir(f'..\/input\/seti-breakthrough-listen\/test\/{folder}')\n    for t in range(len(content)):\n        path.append(f'..\/input\/seti-breakthrough-listen\/test\/{folder}\/{content[t]}')\n        id.append(content[t][:-4])\nsubmission = pd.DataFrame(data = zip(id, path), columns = ['id','im_path'])","f28a52b6":"feature0_sub = []\nfeature1_sub = []\nfeature2_sub = []\nfeature3_sub = []\nfeature4_sub = []\nfeature5_sub = []\nfeature6_sub = []\n\ndef feature_table_sub(x, model, model1):\n    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n    model.to(device)\n    model1.to(device)\n    y = np.zeros(len(submission))\n    \n    valid = make_tensor1(x, y)\n    valid = DataLoader(valid, batch_size=64, shuffle=False, drop_last = False)\n    \n    with torch.no_grad():\n        model.eval()\n        model1.eval()\n        for data in valid:\n            \n            x = data[\"image\"]\n            x = x.to(device, dtype=torch.float)\n            \n            output =  model1(x)\n                \n            output = torch.sigmoid(output)\n            output = output.reshape(-1,) \n            feature0_sub.extend(output.tolist())\n            \n            \n            for im in x:\n                temp = []\n                for sub_im in im:\n                    sep_im = sub_im.cpu().numpy().astype(np.float32)\n                    sep_im = cv2.resize(src = sep_im, dsize=(256, 256), interpolation=cv2.INTER_CUBIC)\n                    temp.append(sep_im)\n                \n                in_put = make_tensor(temp, y[range(6)])\n                in_put = DataLoader(in_put, batch_size=6, shuffle=False, drop_last = False)\n                    #sep_im = torch.tensor(sep_im, dtype=torch.float)\n                    #sep_im  = torch.unsqueeze(sep_im , 0)\n                \n                out = model(next(iter(in_put))['image'].to(device, dtype=torch.float))\n                out = out.reshape(-1,) \n                out = torch.sigmoid(out)\n                for n in range(6):\n                    globals()[\"feature{}_sub\".format(n+1)].append(out[n].item())\n            \n    \n    feature_df1_sub = pd.DataFrame(data= zip(feature1_sub, feature2_sub, feature3_sub, feature4_sub,\n                                             feature5_sub,feature6_sub),columns=['feature1', 'feature2','feature3', \n                                                          'feature4', 'feature5', 'feature6'])\n    \n    feature_df1_sub.insert(0, value = feature0_sub, column = 'feature0')\n    \n    return feature_df1_sub","ad73694f":"#feature_df_sub = feature_table_sub(submission.im_path, model = model, model1 = model1)","9715fdc7":"feature_df_sub = pd.read_csv('..\/input\/df-sub-5us-1-com\/df_sub_5us_1com.csv')","849272d4":"feature_df_sub","912759dd":"submis1 = catb.predict_proba(feature_df_sub.iloc[:, 0:7])[:,1]\nsubmis2 = clf.predict_proba(feature_df_sub.iloc[:, 0:7])[:,1]\nsubmis = (submis1 + submis2)\/2\n\nsub_cat_forest_5us_1com = pd.DataFrame({'id': submission.id,\n                    'target' : submis2})\nsub_cat_forest_5us_1com.to_csv('forest_5us_1com.csv', index = False)","9988fdb9":"####    In this notebook I used two 'efficientnet-b4' Neural Networks (NN). First one was trained on each separate image. Second NN was trained using 6 given images as 6 dimension input. This way I got 7 predictions for each observation (first NN gives 6 predictions (since each observation includes 6 seperate images) and second NN gives one prediction (since it uses the same observtion but considering all 6 pictures as 6 dimnsion input)).\u00b6\n\n####    After that I created DataFrame whre each column is prediction of NN. So I got 7 columns of predictions and 8th column is target. Then RandomForest and CatBoost Classifier used this DataFrame for training. A simple average of RandomForest and CatBoost Classifier was used as a final answer.","73629ed8":"#### Training of the first NN model\n<a id=\"section-twoB\"><\/a>\n","0519ec5c":"## CatBoost\n<a id=\"section-four\"><\/a>","4f49cf60":"#### Training of the first NN model\n<a id=\"section-oneB\"><\/a>\n","560b46ad":"## First NN\n<a id=\"section-one\"><\/a>","2651b6e1":"## Random Forest prediction\n<a id=\"section-three\"><\/a>","aae7fccf":"## SUBMISSION\n<a id=\"section-five\"><\/a>","5ac37dd6":"1. [First NN](#section-one)\n  - [Training](#section-oneB)\n2. [Second NN](#section-two)\n  - [Training](#section-twoB)\n3. [Random Forest ](#section-three)\n4. [CatBoostClassifier](#section-four)\n5. [Composition and submission](#section-five)\n","3f63c513":"<a id=\"section-one\"><\/a>","dd65f092":"## Second NN\n<a id=\"section-two\"><\/a>","56e2cc52":"prepare data for submission"}}