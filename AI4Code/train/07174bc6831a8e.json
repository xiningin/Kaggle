{"cell_type":{"5d5000c3":"code","2d49461e":"code","ade0d793":"code","f7e596e2":"code","900021d3":"code","dac0a5b8":"code","87b46e8c":"code","ef484047":"code","b5fcc475":"code","cb7a4cc7":"code","39acf810":"code","b8802d1b":"code","a007e450":"code","fd61caae":"code","2b01a49c":"code","ca7f9c20":"code","e28f09ab":"code","6c1955df":"code","ba139e0c":"code","d549dab2":"code","4324ae68":"code","064e8bbf":"code","cea3f273":"code","91f0ba6c":"code","4f90a728":"code","59f6d3dc":"code","4a05e16d":"code","bd7f4835":"code","bfb27e4f":"code","6734813e":"code","7bfed9f2":"markdown","b3ec8aa7":"markdown","9c61691c":"markdown","d2ae8f67":"markdown","ddfb15bd":"markdown","20591f84":"markdown","9613e628":"markdown","fe2e8b1e":"markdown","0ec3e141":"markdown","03ed2f25":"markdown","0798b7d1":"markdown","293c6f32":"markdown","8862ebca":"markdown","4b1e8c83":"markdown","edb129d9":"markdown","1f123b15":"markdown","57161bc9":"markdown","85dd8fd3":"markdown","cb4a3538":"markdown","599dc2d0":"markdown","04144071":"markdown","8115a750":"markdown","d5ddbf55":"markdown"},"source":{"5d5000c3":"import pandas as pd\nimport numpy as np\nfrom sklearn.impute import SimpleImputer\nimport matplotlib.pyplot as plt\nimport re\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score","2d49461e":"df_train = pd.read_csv('..\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('..\/input\/titanic\/test.csv')\n\n# Adding a new column so I can split them again\ndf_train['type'] = \"train\"\ndf_test['type'] = \"test\"\n\ndf_full = df_train.append(df_test, sort=False)","ade0d793":"df_full.head()","f7e596e2":"len(df_full)","900021d3":"df_full.describe()","dac0a5b8":"df_full.dtypes","87b46e8c":"df_full.isnull().sum().plot(kind='bar')","ef484047":"# Split the name to collect the title\ndf_full['Title'] = df_full['Name'].str.split(\", \", expand=True)[1].str.split(\".\", expand=True)[0]\n\n# Set up a minimum occurrence\nmin_occ = 10\n\ntitle_names = (df_full['Title'].value_counts() < min_occ)\ndf_full['Title'] = df_full['Title'].apply(lambda x: 'Other' if title_names.loc[x] == True else x)\ndf_full['Title'].value_counts()","b5fcc475":"# count family size\ndf_full['f_size'] = df_full['SibSp'] + df_full['Parch'] + 1\ndf_full['IsAlone'] = 1\n\n# check if the person is alone or not\ndf_full['IsAlone'].loc[df_full['f_size'] > 1] = 0","cb7a4cc7":"# Fill missing Age with mean\ndf_full['Age'].fillna(df_full['Age'].mean(), inplace = True)\n\n# Fill missing Fare with mean\ndf_full['Fare'].fillna(df_full['Fare'].mean(), inplace = True)\n\n# Fill missing Embarked with mode\ndf_full['Embarked'].fillna(df_full['Embarked'].mode()[0], inplace = True)","39acf810":"df_full['Fare_b'] = pd.qcut(df_full['Fare'], 5)\ndf_full['Age_b'] = pd.cut(df_full['Age'].astype(int), 5)","b8802d1b":"del [df_full['Name'], df_full['Cabin'], df_full['Ticket']]","a007e450":"df_full.head()","fd61caae":"df_full.isnull().sum().plot(kind='bar')","2b01a49c":"for col in df_full[['Survived', 'Pclass', 'Fare_b', 'Embarked', 'Title', 'Age_b', 'Sex']]:\n    sns.catplot(x=col, kind=\"count\", data=df_full,\n    height=5, \n    aspect=2)","ca7f9c20":"sns.countplot(x='Pclass', hue=\"Survived\", data=df_full)","e28f09ab":"sns.countplot(x='Fare_b', hue=\"Survived\", data=df_full)","6c1955df":"sns.countplot(x='Embarked', hue=\"Survived\", data=df_full)","ba139e0c":"sns.countplot(x='Title', hue=\"Survived\", data=df_full)","d549dab2":"sns.countplot(x='Age_b', hue=\"Survived\", data=df_full)","4324ae68":"sns.countplot(x='Sex', hue=\"Survived\", data=df_full)","064e8bbf":"# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(15, 15))\nsns.heatmap(df_full.corr(), cmap=cmap, vmax=.3, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","cea3f273":"# Generate dummies\ndf_full = pd.get_dummies(df_full, columns=['Embarked', 'Sex', 'Fare_b', 'Age_b', 'Title'],drop_first=True)\ndel [df_full['Age'], df_full['Fare']]\n\n# Split train and test\ndf_train = df_full[df_full['type'] == 'train']\ndf_test = df_full[df_full['type'] == 'test']\n\ndel [df_train['PassengerId'], df_test['Survived'], df_train['type'], df_test['type']]\n\n# separate the target variable\nX_train = df_train.loc[:, df_train.columns != 'Survived']\ny_train = df_train['Survived']","91f0ba6c":"df_train.head()","4f90a728":"sc = StandardScaler()\ntrain_std = sc.fit_transform(X_train)\ntest_std = sc.fit_transform(df_test.loc[:, df_test.columns != 'PassengerId'])","59f6d3dc":"train_std[0]","4a05e16d":"regressor = RandomForestClassifier(n_estimators=20, random_state=0)\nregressor.fit(train_std, y_train)","bd7f4835":"final_pred = regressor.predict(test_std)","bfb27e4f":"# Creates a dataframe with PassengerId and the predicted values\n\ndf_solution = pd.DataFrame()\ndf_solution['PassengerId'] = df_test['PassengerId']\ndf_solution['Survived'] = final_pred.astype(int)","6734813e":"df_solution['Survived'].value_counts()","7bfed9f2":"#### With that, we have 1309 records","b3ec8aa7":"## 1. Introduction","9c61691c":"#### Train and test data are already split by kaggle, I'll join them to do a single data wrangling ","d2ae8f67":"#### Here I just created two more categorical features based on Fare and Age with 5 bins each","ddfb15bd":"#### Thinking about what I could extract from the person's name, I realized that we can extract the person's title (like Mr. Miss. Master.), and this might be useful to or classifier.\n#### I'll split the name by comma and set up a minimum occurrence to avoid creating too many categorical features, all Title with less than 10 will be count as 'other'","20591f84":"#### Deleting features that I'll not use in my model","9613e628":"#### Now le'ts dealt with NA values using mean and mode","fe2e8b1e":"## 1.1 Load and check data","0ec3e141":"#### If we look to the dataset description we'll see that SibSp is the number of siblings\/spouses and Parch is the number of parents\/children associated to that passenger.\n#### With that I've created a new feature for the size of the family, doing a simple sum of those 2 variables and with that I can also define if the person's is alone or not.","03ed2f25":"#### Let's take a look in our dataset behavior and distribution using Seaborn \n\n#### Let's start checking our dataset distribution.","0798b7d1":"#### Now we just have \u2018Survived\u2019 with NA values, which is ok cause we don't have this values at the test dataset","293c6f32":"#### In order to avoid bias in my model, I'll use standart scallar.","8862ebca":"#### To build the model, I'll first create some dummies in order to inprove performance and split test and train.","4b1e8c83":"#### This notebook was made for Titanic: Machine Learning from Disaster kaggle competition. The idea is to classify if a person survived or not the disaster, I'll be unsing Random FOrest for this task. This is my first kaggle submission and every feedback about code and documentation are welcome.","edb129d9":"## 4. Model","1f123b15":"#### Now let's take a closer look on the missing data and build new features to make the model more precise","57161bc9":"## 3. Data exploration","85dd8fd3":"## 2. Feature engineering","cb4a3538":"#### Here we can see the behavior of each feature in relation to our target variable","599dc2d0":"#### Now let's train the model","04144071":"# Titanic survival classifier","8115a750":"#### Predicting values","d5ddbf55":"#### Now let's see what we've got on the dataset"}}