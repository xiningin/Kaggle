{"cell_type":{"63c1dd3f":"code","2bf74c8a":"code","c836980d":"code","573a111b":"code","44cb4a0e":"code","402f489e":"code","1cc45e57":"code","5d13ac7f":"code","03b3c10c":"code","e5f095c2":"code","1a99be8a":"code","10b60a22":"code","7e0e1136":"code","5650b276":"code","f2608306":"code","989a0f82":"code","fbb1626d":"code","b3bb5079":"code","047f5b4f":"code","01e7b6b4":"code","79b98829":"code","f916cc32":"code","3f6c77fe":"code","e8d1c50e":"code","c81ef6ef":"code","4d164b03":"code","bf5d8ca2":"code","8a60c38f":"markdown","6264b168":"markdown","59383f92":"markdown","46b137ff":"markdown","2f19fb71":"markdown","5107f7c9":"markdown","cbf6aa26":"markdown","356dde56":"markdown","75ab295a":"markdown","2e1c638e":"markdown","45048e0e":"markdown","48f97b53":"markdown","21f463b8":"markdown","03f6c7e1":"markdown","aa521df6":"markdown","e70e38c7":"markdown","b6b731a9":"markdown","5222d820":"markdown","3cb4947f":"markdown","867109d9":"markdown"},"source":{"63c1dd3f":"!ls \/kaggle\/input\/dogs-vs-cats","2bf74c8a":"from zipfile import ZipFile as zf\ntrain_zip = zf('\/kaggle\/input\/dogs-vs-cats\/train.zip', 'r')\ntrain_zip.extractall()\ntrain_zip.close()\ntest_zip = zf('\/kaggle\/input\/dogs-vs-cats\/test1.zip', 'r')\ntest_zip.extractall()\ntest_zip.close()","c836980d":"import os, shutil\nimport random\n\n# PATH_DATA = '\/kaggle\/input\/dogs-vs-cats\/'\nBASE_DIR = '.\/my_arange_data\/'\nos.makedirs(BASE_DIR, exist_ok=True)\n\n# Make directories of train, validation, test\ntrain_dir = os.path.join(BASE_DIR, 'train')\nos.makedirs(train_dir, exist_ok=True)\nvalidation_dir = os.path.join(BASE_DIR, 'validation')\nos.makedirs(validation_dir, exist_ok=True)\n\n# With cats pictures\ntrain_cats_dir = os.path.join(train_dir, 'cats')\nos.makedirs(train_cats_dir, exist_ok=True)\nvalid_cats_dir = os.path.join(validation_dir, 'cats')\nos.makedirs(valid_cats_dir, exist_ok=True)\n\n\n# With dogs pictures\ntrain_dogs_dir = os.path.join(train_dir, 'dogs')\nos.makedirs(train_dogs_dir, exist_ok=True)\nvalid_dogs_dir = os.path.join(validation_dir, 'dogs')\nos.makedirs(valid_dogs_dir, exist_ok=True)\n\n# copy train to base_dir train\nfor filename in os.listdir('.\/train'):\n    if filename.split('.')[0] == 'dog':\n        shutil.copy(os.path.join('.\/train\/',filename), os.path.join(train_dogs_dir, filename))\n    else:\n        shutil.copy(os.path.join('.\/train\/',filename), os.path.join(train_cats_dir, filename))\n\n        # move some of train to validation\ntrain_dogs = os.listdir(train_dogs_dir)\ntrain_cats = os.listdir(train_cats_dir)\n\nrandom.shuffle(train_dogs)\nrandom.shuffle(train_cats)\n\n## train: 10000 image, valid: 2500 for each class\nfor i in range(2500):\n    shutil.move(os.path.join(train_dogs_dir, train_dogs[i]), os.path.join(valid_dogs_dir, train_dogs[i]))\n    shutil.move(os.path.join(train_cats_dir, train_cats[i]), os.path.join(valid_cats_dir, train_cats[i]))        ","573a111b":"print(len(os.listdir(train_dogs_dir)), len(os.listdir(valid_dogs_dir)))","44cb4a0e":"import matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\nfnames = [os.path.join('.\/train\/', fname) for fname in os.listdir('.\/train')]\nfor i, fname in enumerate(fnames):\n    if i <= 4:\n        plt.figure(i)\n        plt.imshow(mpimg.imread(fname))","402f489e":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nload_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = load_datagen.flow_from_directory(\\\n                                                   train_dir,\n                                                   target_size=(150, 150),\n                                                   batch_size=32,\n                                                   class_mode='binary')\nvalid_generator = load_datagen.flow_from_directory(\\\n                                                   validation_dir,\n                                                   target_size=(150, 150),\n                                                   batch_size=32,\n                                                   class_mode='binary')","1cc45e57":"import tensorflow as tf\ndevice_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","5d13ac7f":"from tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\n\nmodel = models.Sequential()\nmodel.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(150, 150, 3)))\nmodel.add(layers.MaxPooling2D(2, 2))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Conv2D(128, (3, 3), activation='relu'))\nmodel.add(layers.MaxPooling2D(2, 2))\nmodel.add(layers.Conv2D(64, (3, 3), activation='relu'))\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(\n    loss='binary_crossentropy',\n    optimizer=optimizers.RMSprop(lr=1e-4),\n    metrics=['acc'])","03b3c10c":"model.summary()","e5f095c2":"\nhistory = model.fit_generator(\n    train_generator,\n    steps_per_epoch=100,\n    epochs=50, \n    validation_data=valid_generator, \n    validation_steps=50)","1a99be8a":"import numpy as np\nimport matplotlib.pyplot as plt\ndef visualize_result(history):\n    fig, axes = plt.subplots(2, 1, figsize=(15, 12))\n    epochs = np.arange(1, len(history.history['acc']) + 1, 1)\n    # accuracy\n    axes[0].plot(epochs, history.history['acc'], '-o', color='b', label='train_accuracy')\n    axes[0].plot(epochs, history.history['val_acc'], '-o', color='r', label='val_accuracy')\n    axes[0].legend()\n    #loss\n    axes[1].plot(epochs, history.history['loss'], '-o', color='b', label='train_loss')\n    axes[1].plot(epochs, history.history['val_loss'], '-o', color='r', label='val_loss')\n    axes[1].legend()\n\n    axes[0].set_xticks(epochs)\n    axes[1].set_xticks(epochs)\nvisualize_result(history)","10b60a22":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\n    rescale=1.\/255,\n    horizontal_flip=True,\n    rotation_range=30,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    shear_range=0.2,\n    zoom_range=0.2,\n    fill_mode='nearest')\n\ntest_datagen = ImageDataGenerator(\n    rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n    train_dir,\n    batch_size=128,\n    target_size=(150, 150),\n    class_mode='binary')\nvalid_generator = test_datagen.flow_from_directory(\n    validation_dir,\n    target_size=(150, 150),\n    batch_size=128,\n    class_mode='binary')","7e0e1136":"from tensorflow.keras.preprocessing import image\nimg = image.load_img(fnames[1], target_size=(150, 150))\nplt.imshow(img)","5650b276":"x = image.img_to_array(img)\nx = x.reshape((1,x.shape[0], x.shape[1], x.shape[2]))\ngenerator_img = train_datagen.flow(x, batch_size=1)\n\nfor i, batch in enumerate(generator_img):\n    plt.figure(i)\n    plt.imshow(image.array_to_img(batch[0]))\n    if i == 10:\n        break\nplt.show()","f2608306":"from keras.applications import Xception\n\npretrained_model = Xception(\n    weights='imagenet', \n    include_top=False, \n    input_shape=(150, 150, 3))\n\npretrained_model.summary()","989a0f82":"def extract_features(dir):\n    n_samples = len(os.listdir(dir))\n    features = np.zeros(shape=(n_samples, 5, 5, 2048))\n    labels = np.zeros(shape=(n_samples))\n    datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    batch_size = 1\n    # using ImageDataGenerator format\n    gen_data = datagen.flow_from_directory(\n        dir, \n        target_size=(150, 150), \n        batch_size=batch_size, \n        class_mode='binary')\n    i = 0\n    for inputs_batch, labels_batch in gen_data:\n        features_batch = pretrained_model.predict(inputs_batch)\n        features[i*batch_size: (i+1)*batch_size] = features_batch\n        labels[i*batch_size: (i+1)*batch_size] = labels_batch\n        if i*batch_size > n_samples:\n            break\n        i += 1\n    return features, labels\n\ntrain_features, train_labels = extract_features(train_dir)\nvalid_features, valid_labels = extract_features(validation_dir)","fbb1626d":"train_features = train_features.reshape(train_features.shape[0], 5*5*2048)\nvalid_features = valid_features.reshape(valid_features.shape[0], 5*5*2048)","b3bb5079":"from tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers\n\nmodel = models.Sequential()\nmodel.add(layers.Dense(256, activation='relu', input_dim=(5*5*2048)))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.compile(\n    optimizer=optimizers.RMSprop(lr=2e-5), \n    loss='binary_crossentropy', \n    metrics=['acc'])","047f5b4f":"model.fit(\n    train_features, \n    train_labels, \n    epochs=30, \n    batch_size=20, \n    validation_data=(valid_features, valid_labels))","01e7b6b4":"model = models.Sequential()\nmodel.add(pretrained_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\n\nmodel.summary()","79b98829":"model.compile(\n    optimizer=optimizers.RMSprop(lr=2e-5), \n    loss='binary_crossentropy', \n    metrics=['acc'])\n\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nload_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = load_datagen.flow_from_directory(\\\n                                                   train_dir,\n                                                   target_size=(150, 150),\n                                                   batch_size=32,\n                                                   class_mode='binary')\nvalid_generator = load_datagen.flow_from_directory(\\\n                                                   validation_dir,\n                                                   target_size=(150, 150),\n                                                   batch_size=32,\n                                                   class_mode='binary')\nmodel.fit(\n    train_generator, \n    epochs=50, \n    steps_per_epoch=100, \n    validation_data=valid_generator, \n    validation_steps=50)","f916cc32":"from tensorflow.keras.applications import Xception\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras import optimizers","3f6c77fe":"pretrained_model = Xception(\n    weights='imagenet', \n    include_top=False, input_shape=(150, 150, 3))\npretrained_model.summary()","e8d1c50e":"pretrained_model.trainable = True\nset_trainable = False\n\nfor layer in pretrained_model.layers:\n    if layer == 'block14_sepconv1':\n        set_trainable = True\n        \n    if set_trainable:\n        layer.trainable = True\n    else:\n        layer.trainable = False","c81ef6ef":"model = models.Sequential()\nmodel.add(pretrained_model)\nmodel.add(layers.Flatten())\nmodel.add(layers.Dense(256, activation='relu'))\nmodel.add(layers.Dense(1, activation='sigmoid'))\nmodel.compile(\n    optimizer=optimizers.RMSprop(lr=2e-5), \n    loss='binary_crossentropy', \n    metrics=['acc'])","4d164b03":"model.summary()","bf5d8ca2":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nload_datagen = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = load_datagen.flow_from_directory(\\\n                                                   train_dir,\n                                                   target_size=(150, 150),\n                                                   batch_size=32,\n                                                   class_mode='binary')\nvalid_generator = load_datagen.flow_from_directory(\\\n                                                   validation_dir,\n                                                   target_size=(150, 150),\n                                                   batch_size=32,\n                                                   class_mode='binary')\nmodel.fit(\n    train_generator, \n    epochs=50, \n    steps_per_epoch=100, \n    validation_data=valid_generator, \n    validation_steps=50)","8a60c38f":"Add some layers to pretrained model","6264b168":"Using layers in block14 ","59383f92":"Using pretrained model to extract the features of data, then using these to predict.","46b137ff":"### Load data\n\nUsing class ImageDataGenerator to load images","2f19fb71":"### Path to the directory where the original dataset was uncompressed","5107f7c9":"Using Xception model from keras api, you can read more in this: https:\/\/keras.io\/api\/applications\/xception\/","cbf6aa26":"# Data Preprocessing","356dde56":"notice the final feature map has shape (None, 5, 5, 2048)","75ab295a":"### Uncompressing data","2e1c638e":"### Augmentation data","45048e0e":"Check gpu device","48f97b53":"# USING PRETRAINED CONVNET","21f463b8":"# Try with simple model","03f6c7e1":"- Let see images generator after using augmentation for a picture","aa521df6":"### Display some pictures","e70e38c7":"## 2. Fine-tuning","b6b731a9":"## 1. Feature extraction before training","5222d820":"# CREATE FOLDER FOR LOAD DATA","3cb4947f":"## 1. training with pretrained model","867109d9":"You can using augmentation method to make more data from original data."}}