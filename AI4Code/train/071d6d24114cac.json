{"cell_type":{"3ab06bac":"code","baa35a06":"code","dfafed4f":"code","0653dc09":"code","2477a075":"code","d6f7e53a":"code","25572824":"code","501f92db":"code","3a350c41":"code","31ecb77c":"code","93f7385f":"code","513d4868":"code","a1e69eba":"code","244ebb38":"code","f324d6e8":"code","dce7df92":"code","9d6a408d":"code","f5ecb28b":"code","fa218431":"code","927cf5bc":"code","39aeaa16":"code","cc18c835":"code","e34461fa":"code","7bab0a57":"code","cbdefd89":"code","956e3ea6":"code","da41e7cd":"code","ec8ffeba":"code","50199721":"code","ff703597":"code","53e810bb":"code","209843e3":"code","5aacfc7a":"code","4eaf9a63":"code","8cbe260f":"code","ecec36dc":"code","a94fc700":"code","065f475a":"code","90a0a530":"code","91b31ce4":"code","04ae9358":"code","ba1cb423":"code","9e31ceb5":"code","11753afa":"code","d2afc08c":"code","d4c72b40":"code","380404d5":"code","f1f56863":"code","13f82b23":"code","2e47fb64":"code","1a25f87d":"code","b346b2bf":"code","b45e2b4a":"code","868761db":"code","541b032b":"code","35458a92":"code","f7315d3f":"code","a10bdad7":"code","c3f09499":"code","a17b6def":"code","4231a8fa":"code","1ed85f18":"code","638107b5":"code","3243d84a":"markdown","1a58c661":"markdown","3303f32b":"markdown","d8b4d6b2":"markdown","ae739481":"markdown","487c0f37":"markdown","e3776c0f":"markdown","00c588c5":"markdown","0082513f":"markdown","8c5fec38":"markdown","da556d1d":"markdown","6eaab95d":"markdown","8fb0abeb":"markdown","addbfe52":"markdown","37c18c4c":"markdown","00617e08":"markdown","ec5f2520":"markdown"},"source":{"3ab06bac":"# By :-Chintan Chitroda","baa35a06":"import numpy as np \nimport pandas as pd \nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom sklearn import metrics","dfafed4f":"trainds = pd.read_csv(\"\/kaggle\/input\/predict-the-churn-for-customer-dataset\/Train File.csv\")\ntestds = pd.read_csv(\"\/kaggle\/input\/predict-the-churn-for-customer-dataset\/Test File.csv\")\n\ntrainds.head(3)","0653dc09":"testds.head(3)","2477a075":"print('Train Dataset Infomarion')\nprint (\"Rows     : \" ,trainds.shape[0])\nprint (\"Columns  : \" ,trainds.shape[1])\nprint (\"\\nFeatures : \\n\" ,trainds.columns.tolist())\nprint (\"\\nMissing values :  \", trainds.isnull().sum().values.sum())\nprint (\"\\nUnique values :  \\n\",trainds.nunique())","d6f7e53a":"plt.subplots(figsize=(10, 6))\nplt.title('Cooralation Matrix', size=30)\nsns.heatmap(trainds.corr(),annot=True,linewidths=0.5)","25572824":"trainds.loc[trainds['TotalCharges'].isnull()] #NUll values Present","501f92db":"trainds['TotalCharges'] = trainds['TotalCharges'].fillna(trainds['TotalCharges'].median()) #\n#trainds = trainds[trainds[\"TotalCharges\"].notnull()]","3a350c41":"CustomerIDS = testds['customerID']\ntrainds.drop('customerID', axis=1,inplace =True)\ntestds.drop('customerID', axis=1,inplace =True)","31ecb77c":"trainds.columns","93f7385f":"testds.describe()","513d4868":"testds['TotalCharges'] = testds['TotalCharges'].fillna(testds['TotalCharges'].median())","a1e69eba":"trainds[\"InternetService\"]=trainds[\"InternetService\"].astype('str')\ntestds[\"InternetService\"]=testds[\"InternetService\"].astype('str')","244ebb38":"trainds[\"TotalCharges\"] = trainds[\"TotalCharges\"].astype(float)\ntrainds[\"MonthlyCharges\"] = trainds[\"MonthlyCharges\"].astype(float)\n\ntestds[\"TotalCharges\"] = testds[\"TotalCharges\"].astype(float)\ntestds[\"MonthlyCharges\"] = testds[\"MonthlyCharges\"].astype(float)","f324d6e8":"replace_cols = [ 'OnlineSecurity', 'OnlineBackup', 'DeviceProtection','TechSupport','StreamingTV', 'StreamingMovies']\nfor i in replace_cols : \n    trainds[i]  = trainds[i].replace({'No internet service' : 'No'})\n    testds[i]  = testds[i].replace({'No internet service' : 'No'})","dce7df92":"replace_cols = ['MultipleLines']\nfor i in replace_cols : \n    trainds[i]  = trainds[i].replace({'No phone service' : 'No'})\n    testds[i]  = testds[i].replace({'No phone service' : 'No'})","9d6a408d":"def customercountplot(x):\n    z = \"Customer Count wrt \"+ x\n    plt.title(z,size=20)\n    sns.countplot(trainds[x])","f5ecb28b":"def churnratio():\n    import plotly.offline as py\n    import plotly.graph_objs as go\n    val = trainds[\"Churn\"].value_counts().values.tolist()\n\n    trace = go.Pie(labels = [\"Not Churned\",\"Churned\"] ,\n                   values = val ,\n                   marker = dict(colors =  [ 'royalblue' ,'lime']), hole = .5)\n    layout = go.Layout(dict(title = \"Train Dataset Customers\"))\n    data = [trace]\n    fig = go.Figure(data = data,layout = layout)\n    py.iplot(fig)","fa218431":"def churnrate():\n    features = ['PhoneService','MultipleLines','InternetService',\n                'TechSupport','StreamingTV','StreamingMovies','Contract']\n    for i, item in enumerate(features):\n        if i < 3:\n            fig1 = pd.crosstab(trainds[item],trainds.Churn,margins=True)\n            fig1.drop('All',inplace=True)\n            fig1.drop('All',axis=1, inplace=True)\n            fig1.plot.bar()\n            z= 'Customer Churned wrt ' + item\n            plt.title(z,size=20)\n        elif i >=3 and i < 6:\n            fig1 = pd.crosstab(trainds[item],trainds.Churn,margins=True)\n            fig1.drop('All',inplace=True)\n            fig1.drop('All',axis=1, inplace=True)\n            fig1.plot.bar()\n            z= 'Customer Churned wrt ' + item\n            plt.title(z,size=20)\n        elif i < 9:\n            fig1 = pd.crosstab(trainds[item],trainds.Churn,margins=True)\n            fig1.drop('All',inplace=True)\n            fig1.drop('All',axis=1, inplace=True)\n            fig1.plot.bar()\n            z= 'Customer Churned wrt ' + item\n            plt.title(z,size=20)","927cf5bc":"churnratio()","39aeaa16":"customercountplot('Churn')","cc18c835":"customercountplot('gender')","e34461fa":"customercountplot('Contract')","7bab0a57":"customercountplot('Partner')","cbdefd89":"customercountplot('PhoneService')","956e3ea6":"customercountplot('MultipleLines')","da41e7cd":"customercountplot('StreamingTV')","ec8ffeba":"tempdf = trainds.copy()\nbins=[0,12,24,48,60,100]\ntempdf['tenure_group']=pd.cut(tempdf['tenure'],bins,labels=['0-12','12-24','24-48','48-60','>60'])\nplt.title('Customer Count wrt to tenure',size=20)\nsns.countplot(tempdf['tenure_group'])","50199721":"plt.title(\"Distribution Plot For Montly Charges\",size=20)\nsns.distplot(trainds['MonthlyCharges'],hist_kws={'edgecolor':'black','alpha':.5})","ff703597":"plt.title(\"Distribution Plot For TotalCharges\",size=20)\nsns.distplot(trainds['TotalCharges'],hist_kws={'edgecolor':'black','alpha':.5})","53e810bb":"churnrate()","209843e3":"train = trainds.copy()\ntest = testds.copy()\ntrain","5aacfc7a":"train.columns","4eaf9a63":"train = pd.get_dummies(train, columns=['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n                                       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n                                       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n                                       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod'])","8cbe260f":"test = pd.get_dummies(test, columns=['gender', 'SeniorCitizen', 'Partner', 'Dependents',\n                                       'PhoneService', 'MultipleLines', 'InternetService', 'OnlineSecurity',\n                                       'OnlineBackup', 'DeviceProtection', 'TechSupport', 'StreamingTV',\n                                       'StreamingMovies', 'Contract', 'PaperlessBilling', 'PaymentMethod'])","ecec36dc":"train.head(3)","a94fc700":"train[\"Churn\"] = train[\"Churn\"].replace({'Yes':1,'No':0})","065f475a":"# For writing solution to file\ndef writetofile(solution,filename):\n    with open(filename,'w') as file:\n        file.write('customerID,Churn\\n')\n        for (a, b) in zip(CustomerIDS, solution):\n            c=\"\"\n            if b==0:\n                c=\"No\"\n            else:\n                c='Yes'\n            file.write(str(a)+','+str(c)+'\\n')","90a0a530":"X = train.drop('Churn', axis=1)\ny = train['Churn']","91b31ce4":"from sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix,accuracy_score,classification_report\nfrom sklearn.metrics import f1_score","04ae9358":"X_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42)","ba1cb423":"logreg = LogisticRegression()\nlogreg.fit(X_train,y_train)","9e31ceb5":"y_pred=logreg.predict(X_test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","11753afa":"sol2=logreg.predict(test)\nsol2","d2afc08c":"print(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","d4c72b40":"import collections, numpy\ncollections.Counter(sol2)","380404d5":"pds = pd.DataFrame(columns=['CustomerID','Churn'])\npds['CustomerID'] = CustomerIDS\npds['Churn']=sol2\npds","f1f56863":"#writetofile(Prediction ,'filename you want to save')\nwritetofile(sol2,'Prediction-Solution')","13f82b23":"from sklearn import tree\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.20,random_state=42)\ndt = tree.DecisionTreeClassifier(criterion='entropy', max_depth=7)\ndt = dt.fit(X_train,y_train)\n\ny_pred = dt.predict(X_test)\nsol4=dt.predict(test)\nprint(\"Accuracy:\",metrics.accuracy_score(y_test, y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))\nprint(sol4)","2e47fb64":"#writetofile(Prediction ,'filename you want to save')\n#writetofile(sol4,'Prediction-Solution')","1a25f87d":"from sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, average_precision_score\nfrom xgboost import XGBClassifier\nimport xgboost as xgb","b346b2bf":"X_train, X_test, y_train, y_test = train_test_split( X , y, test_size=0.3, random_state=42)\nfrom sklearn.model_selection import GridSearchCV\n\nparam_test = {\n    \n    'gamma': [0.5, 1, 1.5, 2, 5],\n    'max_depth': [3, 4, 5]\n  \n}\n\nclf = GridSearchCV(estimator = \nXGBClassifier(learning_rate =0.1,\n              objective= 'binary:logistic',\n              nthread=4,\n              seed=27), \n              param_grid = param_test,\n              scoring= 'accuracy',\n              n_jobs=4,\n              iid=False,\n              verbose=10)","b45e2b4a":"clf.fit(X_train, y_train)","868761db":"y_pred= clf.predict(X_test)\nprint(y_pred)\nprint(\"Accuracy:\",accuracy_score(y_test,y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","541b032b":"sol3= clf.predict(test)\nprint(y_pred)","35458a92":"import collections, numpy\ncollections.Counter(sol3)","f7315d3f":"#writetofile(Prediction ,'filename you want to save')\n#writetofile(sol3,'Prediction-Solution')","a10bdad7":"from sklearn.ensemble import RandomForestClassifier\n\nX_train,X_test,y_train,y_test=train_test_split(X,y,test_size=0.30,random_state=42)\nrf = RandomForestClassifier(n_estimators = 50, random_state = 42)\nrf.fit(X_train,y_train)","c3f09499":"y_pred = rf.predict(X_train)","a17b6def":"y_pred= clf.predict(X_test)\nprint(y_pred)\nprint(\"Accuracy:\",accuracy_score(y_test,y_pred))\nprint(\"Precision:\",metrics.precision_score(y_test, y_pred))\nprint(\"Recall:\",metrics.recall_score(y_test, y_pred))","4231a8fa":"sol3 = rf.predict(test)","1ed85f18":"#import collections, numpy\n#collections.Counter(sol3)","638107b5":"#writetofile(Prediction ,'filename you want to save')\n#writetofile(sol3,'Prediction-Solution')","3243d84a":"## Decision Tree Classifier","1a58c661":"#### Save to file","3303f32b":"## XGBoost CLassifier Algorithm","d8b4d6b2":"### Save to File","ae739481":"## Random Forest","487c0f37":"## Data Exploration","e3776c0f":"## Data PreProcessing","00c588c5":"#### Data Exploration code:","0082513f":"##### The Best accuracy Model was Logistic Regression Model .\n##### You can see other Models I Tried.","8c5fec38":"#### Data Manipulation","da556d1d":"## Customer Churn Prediction","6eaab95d":"## Still working on this u guys can Contribute..","8fb0abeb":"## Writing Predicted Data to Solution.csv","addbfe52":"# Building model","37c18c4c":"### Save to File","00617e08":"## Logistic Regression Model","ec5f2520":"#### The Notebook Contains 5 machine learning Algorithm.\n#### Output File is based on Logistic Regression model.\n#### XGBCLassifier Algorithm is taking time to compute so Be patient me took 15 mins on Kaggle commit and 2 mins in pc\n### Go to version 7 of Telecom-Churn-Prediction it is only solution using Logistic regression and execute quickly.\n### Note:\n#### Remove # From write to file command under each algorith for their output fill\n#### By Default the output File will be Predition of Logistic Regression Model.\n#### Its a big file Due to 5 algorithms, so suggest to donload the file and run. "}}