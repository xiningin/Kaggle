{"cell_type":{"e4b77788":"code","e49f4598":"code","07cf7eb2":"code","63a0b028":"code","7a7c890f":"code","b14740d3":"code","fd5a332b":"code","7c46e412":"code","06b20cd8":"code","0326d2cb":"code","4555381e":"code","13b0edfc":"code","6ef807dc":"code","c3296e98":"code","0917e751":"code","1b56a06d":"code","b7207bd8":"code","6227440f":"code","721e3918":"code","5c27fe3a":"code","eb7716f5":"code","7f8c6655":"code","af5fd005":"code","2d02cb50":"code","c82fe1b3":"code","84eccdc4":"code","25598425":"code","c5504ee9":"code","0eca5b44":"code","5b2eadf0":"code","c6429231":"code","b8a5eb4e":"code","0a4e92d7":"code","6a804116":"code","96d9d1e6":"code","b5f9f562":"code","48a30ca2":"code","d375ee2e":"code","24209473":"code","2cec4969":"code","50ea3649":"code","efee51fe":"code","93c62895":"code","4f0418dc":"code","1122c6a2":"code","54e8d22f":"code","5b0b15b7":"code","ab436488":"code","2d218d0f":"code","780fdece":"code","9a07dcb3":"code","4a952030":"code","be132b3e":"code","0c990288":"code","0ffb3907":"code","de7be472":"code","412c4898":"code","908130ab":"code","d8d723be":"code","a5567dc4":"code","27f42aa2":"code","54fc0818":"code","da1575ef":"code","7020fceb":"code","a42dd2fe":"code","e8af4a9e":"code","be75a325":"code","56d026e2":"code","dfdd61d3":"code","12d890c6":"code","cf00e17a":"code","13fcd7e1":"code","7fed8d8e":"code","02ff13a2":"code","24bc2c75":"code","f2817999":"code","5d136b96":"code","88c5baff":"code","311151da":"code","a735bc1b":"code","41c6e646":"code","ef01987c":"code","dc1d2543":"markdown","78dff8da":"markdown","f848ad56":"markdown","956fc361":"markdown","fb4417b3":"markdown","e70dee86":"markdown","66bdad7f":"markdown","798c65ef":"markdown","134a255f":"markdown","3b9c5979":"markdown","f735bce0":"markdown","778cd4f8":"markdown","f4900771":"markdown","f4040fa4":"markdown","c73d2937":"markdown","6022010c":"markdown","96316a3c":"markdown","ea82acfe":"markdown","302fbc02":"markdown","720997bb":"markdown","a63933ce":"markdown","2035f992":"markdown","6ba31202":"markdown","30a6fec5":"markdown","13e701e1":"markdown","1751b19e":"markdown","3926c2ad":"markdown","e7330fe0":"markdown","d33c79af":"markdown","fc54c869":"markdown","17c21fa2":"markdown","dce6d12e":"markdown","f02a21db":"markdown","4dd7073c":"markdown","b7def831":"markdown","ebbc7863":"markdown","15e10ee9":"markdown","e7fe69da":"markdown","1814855b":"markdown","bf1972be":"markdown","635601b1":"markdown","58a4f9b1":"markdown","57c5f2d5":"markdown","78851157":"markdown","24e76eb5":"markdown","e7f8c350":"markdown","392d6a26":"markdown","38537fd9":"markdown","039689a2":"markdown","27a54b42":"markdown","ab993908":"markdown","a490f965":"markdown","1449a252":"markdown","e9383651":"markdown"},"source":{"e4b77788":"from matplotlib import pyplot as plt\nimport string\nimport missingno as miss\nimport pandas as pd\nimport numpy as np\nimport plotly.io as pio\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nfrom plotly.subplots import make_subplots\n\nfrom sklearn.utils import shuffle\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.tree import DecisionTreeRegressor, plot_tree","e49f4598":"train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntest_passenger_id = test.PassengerId","07cf7eb2":"# Read first few rows\ntrain.head()","63a0b028":"# Missing data matrix\nmiss.matrix(train);","7a7c890f":"def missing_values_table(df):\n    # Total missing values\n    mis_val = df.isnull().sum()\n\n    # Percentage of missing values\n    mis_val_percent = 100 * df.isnull().sum() \/ len(df)\n\n    # Coumn for dtypes\n    dtype = df.dtypes\n\n    # Make a table with the results\n    mis_val_table = pd.concat([mis_val, mis_val_percent, dtype], axis=1)\n\n    # Rename the columns\n    mis_val_table_ren_columns = mis_val_table.rename(\n        columns={0: 'Missing Values', 1: '% of Total Values', 2: 'Data Types'})\n\n    # Sort the table by percentage of missing descending\n    mis_val_table_ren_columns = mis_val_table_ren_columns[\n        mis_val_table_ren_columns.iloc[:, 1] != 0].sort_values(\n        '% of Total Values', ascending=False).round(1)\n\n    # Print some summary information\n    print(\"Your selected dataframe has \" + str(df.shape[1]) + \" columns.\\n\"\n                                                              \"There are \" + str(mis_val_table_ren_columns.shape[0]) +\n          \" columns that have missing values.\")\n\n    # Return the dataframe with missing information\n    return mis_val_table_ren_columns","b14740d3":"train_miss = missing_values_table(train)\ntrain_miss","fd5a332b":"# Check for test cases\nmiss.matrix(test)\ntest_miss = missing_values_table(test)\ntest_miss","7c46e412":"train.drop(columns='PassengerId', inplace=True)\ntest.drop(columns='PassengerId', inplace=True)","06b20cd8":"survived_percentage = (train[train['Survived'] == 1]['Survived'].sum()) \/ train.shape[0] * 100\nnot_survived_percentage = 100 - survived_percentage","0326d2cb":"fig = px.bar(train, x=[\"Survived\", \"Not Survived\"], y=[survived_percentage, not_survived_percentage], color=[\"Survived\", \"Not Survived\"],\n                width=600,height=350,\n                color_discrete_map={ \n                    \"Survived\": \"mediumturquoise\", \"Not Survived\": \"lightsalmon\"\n                },\n                labels=dict(x = \"Survived or Not\", y=\"Percentage\", color=\"Place\"),\n                )\n\nfig.update_layout(\n    title={\n        'text': \"Survival Rate Distribution\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\n\n\nfig.show();","4555381e":"pclass=['First Class(1)', 'Second class(2)', 'Third Class(3)']\n\nsurvived_count = train.groupby('Pclass').sum()['Survived']\ntotal_count = train.groupby('Pclass').count()['Survived']\nnot_survived = total_count - survived_count\n\nfig = go.Figure(data=[\n                    go.Bar(name='Survived', x=pclass, y=survived_count, marker_color='mediumturquoise'),\n                    go.Bar(name='Not Survived', x=pclass, y=not_survived, marker_color='lightsalmon'),],)\n# Change the bar mode\nfig.update_layout(width=700,\n                  height=350,\n                  barmode='group',\n                  xaxis = dict(title=\"Pclass\"),\n                  yaxis = dict(title=\"Passenger Count\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Count with respect to Pclass\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","13b0edfc":"# One Hot Encoding function\ndef categorical_encode(name, training_set, test_set):\n    df = pd.concat([training_set[name], test_set[name]])\n    encoder = OneHotEncoder(handle_unknown='ignore')\n    features = encoder.fit_transform(df.values.reshape(-1, 1)).toarray()\n    \n    # Find unique number of encodings\n    n = df.nunique()\n    cols = ['{}_{}'.format(name, n) for n in range(1, n + 1)]\n    \n    # Create a new dataframe and re-indexing\n    encoded_df = pd.DataFrame(features, columns=cols)\n    encoded_df.index = df.index\n    for col in encoded_df.columns:\n        encoded_df = encoded_df.astype({col: 'object'})\n    \n    training_set = pd.concat([training_set, encoded_df[:training_set.shape[0]]], axis=1)\n    test_set = pd.concat([test_set, encoded_df[training_set.shape[0]:]], axis=1)\n    return training_set, test_set","6ef807dc":"train, test = categorical_encode('Pclass', train, test)","c3296e98":"sex = pd.concat([train['Sex'], test['Sex']]).unique()\n\nsurvived_count = train.groupby('Sex').sum()['Survived']\ntotal_count = train.groupby('Sex').count()['Survived']\nnot_survived = total_count - survived_count\n\nfig = go.Figure(data=[\n    go.Bar(name='Survived', x=sex, y=survived_count, marker_color='mediumturquoise'),\n    go.Bar(name='Not Survived', x=sex, y=not_survived, marker_color='lightsalmon'),\n])\n# Change the bar mode\nfig.update_layout(width=600,\n                  height=350,\n                  barmode='group',\n                  xaxis = dict(title=\"Sex\"),\n                  yaxis = dict(title=\"Passenger Count\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Count with respect to Sex\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","0917e751":"train, test = categorical_encode('Sex', train, test)","1b56a06d":"train['Family_members'] = train['SibSp'] + train['Parch'] + 1\ntest['Family_members'] = test['SibSp'] + test['Parch'] + 1","b7207bd8":"members = sorted(pd.concat([train['Family_members'], test['Family_members']]).unique())\n\nsurvived_count = train.groupby('Family_members').sum()['Survived']\ntotal_count = train.groupby('Family_members').count()['Survived']\nnot_survived = total_count - survived_count\n\nfig = go.Figure(data=[\n    go.Bar(name='Survived', x=members, y=survived_count, marker_color='mediumturquoise'),\n    go.Bar(name='Not Survived', x=members, y=not_survived, marker_color='lightsalmon'),\n])\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=1000,\n                  height=450,\n                  barmode='group',\n                  xaxis = dict(title=\"Family size\"),\n                  yaxis = dict(title=\"Passenger Count\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Count with respect to Family Size\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","6227440f":"percentage_survived = survived_count \/ total_count * 100\n\nfig = go.Figure(go.Bar(name='Survived', \n                       x=members, \n                       y=percentage_survived, \n                       marker={\n                            'color': percentage_survived,\n                            'colorscale': 'Viridis'\n                        }))\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=600,\n                  height=400,\n                  barmode='group',\n                  xaxis = dict(title=\"Family size\"),\n                  yaxis = dict(title=\"Survival Percentage\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Rate with respect to Family Size\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","721e3918":"train['Family_cat'] = [('Single' if member == 1 else (\n                        'Large' if member >= 5 else 'Small')) for member in train['Family_members']]\ntest['Family_cat'] = [('Single' if member == 1 else (\n                        'Large' if member >= 5 else 'Small')) for member in test['Family_members']]","5c27fe3a":"members = sorted(pd.concat([train['Family_cat'], test['Family_cat']]).unique())\n\nsurvived_count = train.groupby('Family_cat').sum()['Survived']\ntotal_count = train.groupby('Family_cat').count()['Survived']\n\npercentage_survived = survived_count \/ total_count * 100\n\nfig = go.Figure(go.Bar(name='Survived', \n                       x=members, \n                       y=percentage_survived, \n                       marker={\n                            'color': percentage_survived,\n                            'colorscale': 'Viridis'\n                        }))\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=600,\n                  height=400,\n                  barmode='group',\n                  xaxis = dict(title=\"Family Category\"),\n                  yaxis = dict(title=\"Survival Percentage\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Rate with respect to Family Category\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","eb7716f5":"train, test = categorical_encode('Family_cat', train, test)","7f8c6655":"indicies = train[train['Embarked'].isnull()].index.tolist()\ntrain.loc[indicies,'Embarked'] = 'S'","af5fd005":"members = sorted(pd.concat([train['Embarked'], test['Embarked']]).unique())\n\nsurvived_count = train.groupby('Embarked').sum()['Survived']\ntotal_count = train.groupby('Embarked').count()['Survived']\nnot_survived = total_count - survived_count\n\nfig = go.Figure(data=[\n    go.Bar(name='Survived', x=members, y=survived_count, marker_color='mediumturquoise'),\n    go.Bar(name='Not Survived', x=members, y=not_survived, marker_color='lightsalmon'),\n])\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=600,\n                  height=450,\n                  barmode='group',\n                  xaxis = dict(title=\"Port Embarked\"),\n                  yaxis = dict(title=\"Passenger Count\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Count with respect to Port Embarked\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","2d02cb50":"train, test = categorical_encode('Embarked', train, test)","c82fe1b3":"train.columns","84eccdc4":"df = train.copy()\ndf.reset_index(inplace=True)\ndf.drop(columns='index', inplace=True)\n\n# Also drop Name, Ticket and Cabin and redundant columns\ndf.drop(columns=['Survived', 'Name', 'Ticket', 'Cabin', 'Pclass', 'Sex', 'SibSp', \n                 'Parch', 'Embarked', 'Family_members', 'Family_cat'], inplace=True)","25598425":"# Preparation work to build a decision tree\ntemp_df = df.copy()\ntemp_df.dropna(inplace=True)\nage_Y = temp_df.Age\ntemp_train = temp_df.drop(columns=['Age'])","c5504ee9":"# Depth of 5 is a hyperparameter\nage_model = DecisionTreeRegressor(max_depth=5)\nage_model.fit(temp_train, age_Y)","0eca5b44":"fig = plt.figure(figsize=(25,20))\nplot_tree(age_model, fontsize=18, max_depth=3, impurity=False, feature_names=temp_train.columns);","5b2eadf0":"na_age_index = train[train['Age'].isna()]\nna_age_index = na_age_index.drop(columns=['Survived', 'Age', 'Name', 'Ticket', 'Cabin', 'Pclass', 'Sex', \n                                          'SibSp', 'Parch', 'Embarked', 'Family_members', 'Family_cat'])\nage_na_pred = age_model.predict(na_age_index)\nage_fill_na = train[train['Age'].isna()].index\ntrain.loc[age_fill_na,'Age'] = age_na_pred\n\nna_age_index_test = test[test['Age'].isna()]\nna_age_index_test = na_age_index_test.drop(columns=['Age', 'Name', 'Ticket', 'Cabin', 'Pclass', 'Sex', \n                                                    'SibSp', 'Parch', 'Embarked', 'Family_members', 'Family_cat'])\nage_na_pred_test = age_model.predict(na_age_index_test)\nage_fill_na_test = test[test['Age'].isna()].index\ntest.loc[age_fill_na_test,'Age'] = age_na_pred_test","c6429231":"surv = train['Age']\nvict = test['Age']\n\ngroup_labels = ['Train Set', 'Test Set']\n\nfig = make_subplots(\n    rows=1, cols=2, subplot_titles=(\"Age Distribution\", \"Survival Distribution by Age\")\n)\n\nfig2 = ff.create_distplot([surv, vict],\n                         group_labels, \n                         show_hist=False, \n                         show_rug=False,\n                         )\n\nfig.add_trace(go.Scatter(fig2['data'][0],\n                           marker_color='blue'\n                          ), row=1, col=1)\nfig.add_trace(go.Scatter(fig2['data'][1],\n                           marker_color='red'\n                          ), row=1, col=1)\n\nfig.update_xaxes(title_text=\"Age\", row=1, col=1)\nfig.update_xaxes(title_text=\"Age\", row=1, col=2)\nfig.update_yaxes(title_text=\"Probability Distribution\", row=1, col=1)\nfig.update_yaxes(title_text=\"Probability Distribution\", row=1, col=2)\n\nsurv = train[train['Survived'] == 1]['Age']\nvict = train[train['Survived'] == 0]['Age']\n\ngroup_labels = ['Survived', 'Not Survived']\n\nfig3 = ff.create_distplot([surv, vict],\n                         group_labels, \n                         show_hist=False, \n                         show_rug=False,\n                         )\n\nfig.add_trace(go.Scatter(fig3['data'][0],\n                           marker_color='orange'\n                          ), row=1, col=2)\nfig.add_trace(go.Scatter(fig3['data'][1],\n                           marker_color='green'\n                          ), row=1, col=2)\nfig.show();\n","b8a5eb4e":"train['Deck'] = ['M' if pd.isnull(string) else string[0]  for string in train['Cabin']]\ntest['Deck'] = ['M' if pd.isnull(string) else string[0]  for string in test['Cabin']]","0a4e92d7":"decks = pd.concat([train['Deck'], test['Deck']])\ndecks.value_counts()","6a804116":"train['Deck'] = train['Deck'].replace(['T'],'A')","96d9d1e6":"members = sorted(pd.concat([train['Deck'], test['Deck']]).unique())\n\nsurvived_count = train.groupby('Deck').sum()['Survived']\ntotal_count = train.groupby('Deck').count()['Survived']\nnot_survived = total_count - survived_count\n\nfig = go.Figure(data=[\n    go.Bar(name='Survived', x=members, y=survived_count, marker_color='mediumturquoise'),\n    go.Bar(name='Not Survived', x=members, y=not_survived, marker_color='lightsalmon'),\n])\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=1000,\n                  height=450,\n                  barmode='group',\n                  xaxis = dict(title=\"Deck\"),\n                  yaxis = dict(title=\"Passenger Count\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Count with respect to Deck\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","b5f9f562":"percentage_survived = survived_count \/ total_count * 100\n\nfig = go.Figure(go.Bar(name='Survived', \n                       x=members, \n                       y=percentage_survived, \n                       marker={\n                            'color': percentage_survived,\n                            'colorscale': 'Viridis'\n                        }))\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=600,\n                  height=400,\n                  barmode='group',\n                  xaxis = dict(title=\"Deck\"),\n                  yaxis = dict(title=\"Survival Percentage\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Rate with respect to Deck\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","48a30ca2":"temp_df = train.groupby(['Deck', 'Pclass'], as_index=False)['Survived'].count()\ntemp_df['Total_Survived'] = [total_count[deck] for deck in temp_df['Deck']]\ntemp_df['Percentage'] = temp_df['Survived'] \/ temp_df['Total_Survived'] * 100","d375ee2e":"fig = px.bar(temp_df, x=\"Deck\", y=\"Percentage\", color=\"Pclass\")\nfig.update_layout(width=600,\n                  height=400,\n                  barmode='group',\n                  xaxis = dict(title=\"Deck\"),\n                  yaxis = dict(title=\"Percentage\"))\nfig.update_layout(\n    title={\n        'text': \"Pclass Distribution with respect to Deck\",\n        'y':0.9,\n        'x':0.5,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show()","24209473":"train['Deck_cat'] = ['upper' if (deck >= 'A' and deck <= 'E') else\n                     ('middle' if deck == 'F' else\n                     ('lower' if deck == 'G' else 'missing'))\n                     for deck in train['Deck']]\ntest['Deck_cat'] = ['upper' if (deck >= 'A' and deck <= 'E') else\n                     ('middle' if deck == 'F' else\n                     ('lower' if deck == 'G' else 'missing'))\n                     for deck in test['Deck']]","2cec4969":"train, test = categorical_encode('Deck_cat', train, test)","50ea3649":"df = train.copy()\ndf.reset_index(inplace=True)\ndf.drop(columns='index', inplace=True)\n\n# Also drop Name, Ticket and Cabin and redundant columns\ndf.drop(columns=['Survived', 'Name', 'Ticket', 'Cabin', 'Pclass', 'Sex', 'SibSp', \n                 'Parch', 'Embarked', 'Family_members', 'Family_cat', 'Deck', 'Deck_cat'], inplace=True)\n\n# Preparation work to build a decision tree\ntemp_df = df.copy()\ntemp_df.dropna(inplace=True)\nfare_Y = temp_df.Fare\ntemp_train = temp_df.drop(columns=['Fare'])","efee51fe":"# Depth of 5 is a hyperparameter\nfare_model = DecisionTreeRegressor(max_depth=5)\nfare_model.fit(temp_train, fare_Y)","93c62895":"na_fare_index_test = test[test['Fare'].isna()]\nna_fare_index_test = na_fare_index_test.drop(columns=['Fare', 'Name', 'Ticket', 'Cabin', 'Pclass', 'Sex', \n                                                    'SibSp', 'Parch', 'Embarked', 'Family_members', 'Family_cat', 'Deck', 'Deck_cat'])\nfare_na_pred_test = fare_model.predict(na_fare_index_test)\nfare_fill_na_test = test[test['Fare'].isna()].index\ntest.loc[fare_fill_na_test,'Fare'] = fare_na_pred_test","4f0418dc":"train_fare = train['Fare']\ntest_fare = test['Fare']\n\ngroup_labels = ['Train Set', 'Test Set']\n\nfig = make_subplots(\n    rows=1, cols=2, subplot_titles=(\"Fare Distribution\", \"Survival Distribution by Fare\")\n)\n\nfig2 = ff.create_distplot([train_fare, test_fare],\n                         group_labels, \n                         show_hist=False, \n                         show_rug=False,\n                         )\n\nfig.add_trace(go.Scatter(fig2['data'][0],\n                           marker_color='blue'\n                          ), row=1, col=1)\nfig.add_trace(go.Scatter(fig2['data'][1],\n                           marker_color='red'\n                          ), row=1, col=1)\n\nfig.update_xaxes(title_text=\"Fare\", row=1, col=1)\nfig.update_xaxes(title_text=\"Fare\", row=1, col=2)\nfig.update_yaxes(title_text=\"Probability Distribution\", row=1, col=1)\nfig.update_yaxes(title_text=\"Probability Distribution\", row=1, col=2)\n\nsurv = train[train['Survived'] == 1]['Fare']\nvict = train[train['Survived'] == 0]['Fare']\n\ngroup_labels = ['Survived', 'Not Survived']\n\nfig3 = ff.create_distplot([surv, vict],\n                         group_labels, \n                         show_hist=False, \n                         show_rug=False,\n                         )\n\nfig.add_trace(go.Scatter(fig3['data'][0],\n                           marker_color='orange'\n                          ), row=1, col=2)\nfig.add_trace(go.Scatter(fig3['data'][1],\n                           marker_color='green'\n                          ), row=1, col=2)\nfig.show();\n","1122c6a2":"df = pd.concat([train.drop(columns='Survived'), test], ignore_index=True)\nticket_group = df.groupby('Ticket').size()\nticket_group.name = 'Ticket_count'","54e8d22f":"df = df.join(ticket_group, on='Ticket')","5b0b15b7":"train_column = train.columns\ntest_column = test.columns\ntrain = pd.concat([train.Survived, df[:train.shape[0]]], ignore_index=True, axis=1)\ntrain.columns = train_column.append(pd.Index(['Ticket_count']))\ntest = df[train.shape[0]:]","ab436488":"train['Ticket_count'].value_counts()","2d218d0f":"members = sorted(df['Ticket_count'].unique())\n\nsurvived_count = train.groupby('Ticket_count').sum()['Survived']\ntotal_count = train.groupby('Ticket_count').count()['Survived']\nnot_survived = total_count - survived_count\n\nfig = go.Figure(data=[\n    go.Bar(name='Survived', x=members, y=survived_count, marker_color='mediumturquoise'),\n    go.Bar(name='Not Survived', x=members, y=not_survived, marker_color='lightsalmon'),\n])\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=1000,\n                  height=450,\n                  barmode='group',\n                  xaxis = dict(title=\"Ticket Count\"),\n                  yaxis = dict(title=\"Passenger Count\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Count with respect to Ticket Count\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","780fdece":"corr = df['Ticket_count'].corr(df['Family_members'])\nprint(\"The correlation is: {}\".format(corr))","9a07dcb3":"train['Ticket_cat'] = [('Single' if member == 1 else (\n                        'Large' if member >= 5 else 'Small')) for member in train['Ticket_count']]\ntest['Ticket_cat'] = [('Single' if member == 1 else (\n                        'Large' if member >= 5 else 'Small')) for member in test['Ticket_count']]","4a952030":"train, test = categorical_encode('Ticket_cat', train, test)","be132b3e":"train['Title'] = train['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\ntrain['Is_Married'] = 0\ntrain['Is_Married'].loc[train['Title'] == 'Mrs'] = 1\n\ntest['Title'] = test['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\ntest['Is_Married'] = 0\ntest['Is_Married'].loc[test['Title'] == 'Mrs'] = 1","0c990288":"members = sorted(train['Title'].unique())\n\nsurvived_count = train.groupby('Title').sum()['Survived']\ntotal_count = train.groupby('Title').count()['Survived']\nnot_survived = total_count - survived_count\n\nfig = go.Figure(data=[\n    go.Bar(name='Survived', x=members, y=survived_count, marker_color='mediumturquoise'),\n    go.Bar(name='Not Survived', x=members, y=not_survived, marker_color='lightsalmon'),\n])\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=1000,\n                  height=450,\n                  barmode='group',\n                  xaxis = dict(title=\"Title\"),\n                  yaxis = dict(title=\"Passenger Count\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Count with respect to Title\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","0ffb3907":"train['Title'] = train['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss\/Mrs\/Ms')\ntrain['Title'] = train['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr\/Military\/Noble\/Clergy')\n\ntest['Title'] = test['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss\/Mrs\/Ms')\ntest['Title'] = test['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr\/Military\/Noble\/Clergy')","de7be472":"members = sorted(train['Title'].unique())\n\nsurvived_count = train.groupby('Title').sum()['Survived']\ntotal_count = train.groupby('Title').count()['Survived']\nnot_survived = total_count - survived_count\n\nfig = go.Figure(data=[\n    go.Bar(name='Survived', x=members, y=survived_count, marker_color='mediumturquoise'),\n    go.Bar(name='Not Survived', x=members, y=not_survived, marker_color='lightsalmon'),\n])\nfig.update_xaxes(type='category')\n# Change the bar mode\nfig.update_layout(width=1000,\n                  height=450,\n                  barmode='group',\n                  xaxis = dict(title=\"Title\"),\n                  yaxis = dict(title=\"Passenger Count\"))\nfig.update_layout(\n    title={\n        'text': \"Survival Count with respect to Title\",\n        'y':0.9,\n        'x':0.45,\n        'xanchor': 'center',\n        'yanchor': 'top'})\nfig.show();","412c4898":"train, test = categorical_encode('Title', train, test)","908130ab":"df_all = pd.concat([train.drop(columns='Survived'), test], ignore_index=True)\ntrain_column = train.columns\ntest_column = test.columns","d8d723be":"def extract_surname(data):    \n    \n    families = []\n    \n    for i in range(len(data)):        \n        name = data.iloc[i]\n\n        if '(' in name:\n            name_no_bracket = name.split('(')[0] \n        else:\n            name_no_bracket = name\n            \n        family = name_no_bracket.split(',')[0]\n        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n        \n        for c in string.punctuation:\n            family = family.replace(c, '').strip()\n            \n        families.append(family)\n            \n    return families\n\ndf_all['Family'] = extract_surname(df_all['Name'])\ndf_train = df_all.loc[:890]\ndf_test = df_all.loc[891:]\n\ndf_train = pd.concat([train.Survived, df_all[:train.shape[0]]], ignore_index=True, axis=1)\ndf_train.columns = train_column.append(pd.Index(['Family']))\n\ndfs = [df_train, df_test]","a5567dc4":"non_unique_families = [x for x in df_train['Family'].unique() if x in df_test['Family'].unique()]\nnon_unique_tickets = [x for x in df_train['Ticket'].unique() if x in df_test['Ticket'].unique()]\n\ndf_family_survival_rate = df_train.groupby('Family')[['Survived', 'Family','Family_members']].median()\ndf_ticket_survival_rate = df_train.groupby('Ticket')[['Survived', 'Ticket','Ticket_count']].median()\n\nfamily_rates = {}\nticket_rates = {}\n\nfor i in range(len(df_family_survival_rate)):\n    # Checking a family exists in both training and test set, and has members more than 1\n    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\n        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]\n\nfor i in range(len(df_ticket_survival_rate)):\n    # Checking a ticket exists in both training and test set, and has members more than 1\n    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\n        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]","27f42aa2":"mean_survival_rate = np.mean(df_train['Survived'])\n\ntrain_family_survival_rate = []\ntrain_family_survival_rate_NA = []\ntest_family_survival_rate = []\ntest_family_survival_rate_NA = []\n\nfor i in range(len(df_train)):\n    if df_train['Family'][i] in family_rates:\n        train_family_survival_rate.append(family_rates[df_train['Family'][i]])\n        train_family_survival_rate_NA.append(1)\n    else:\n        train_family_survival_rate.append(mean_survival_rate)\n        train_family_survival_rate_NA.append(0)\n        \nfor i in range(len(df_test)):\n    if df_test['Family'].iloc[i] in family_rates:\n        test_family_survival_rate.append(family_rates[df_test['Family'].iloc[i]])\n        test_family_survival_rate_NA.append(1)\n    else:\n        test_family_survival_rate.append(mean_survival_rate)\n        test_family_survival_rate_NA.append(0)\n        \ndf_train['Family_Survival_Rate'] = train_family_survival_rate\ndf_train['Family_Survival_Rate_NA'] = train_family_survival_rate_NA\ndf_test['Family_Survival_Rate'] = test_family_survival_rate\ndf_test['Family_Survival_Rate_NA'] = test_family_survival_rate_NA\n\ntrain_ticket_survival_rate = []\ntrain_ticket_survival_rate_NA = []\ntest_ticket_survival_rate = []\ntest_ticket_survival_rate_NA = []\n\nfor i in range(len(df_train)):\n    if df_train['Ticket'][i] in ticket_rates:\n        train_ticket_survival_rate.append(ticket_rates[df_train['Ticket'][i]])\n        train_ticket_survival_rate_NA.append(1)\n    else:\n        train_ticket_survival_rate.append(mean_survival_rate)\n        train_ticket_survival_rate_NA.append(0)\n        \nfor i in range(len(df_test)):\n    if df_test['Ticket'].iloc[i] in ticket_rates:\n        test_ticket_survival_rate.append(ticket_rates[df_test['Ticket'].iloc[i]])\n        test_ticket_survival_rate_NA.append(1)\n    else:\n        test_ticket_survival_rate.append(mean_survival_rate)\n        test_ticket_survival_rate_NA.append(0)\n        \ndf_train['Ticket_Survival_Rate'] = train_ticket_survival_rate\ndf_train['Ticket_Survival_Rate_NA'] = train_ticket_survival_rate_NA\ndf_test['Ticket_Survival_Rate'] = test_ticket_survival_rate\ndf_test['Ticket_Survival_Rate_NA'] = test_ticket_survival_rate_NA","54fc0818":"for df in [df_train, df_test]:\n    df['Survival_Rate'] = (df['Ticket_Survival_Rate'] + df['Family_Survival_Rate']) \/ 2\n    df['Survival_Rate_NA'] = (df['Ticket_Survival_Rate_NA'] + df['Family_Survival_Rate_NA']) \/ 2    \ntrain = df_train\ntest = df_test","da1575ef":"train_corr = train[['Survived', 'Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Cabin', 'Family_members', 'Ticket_count', 'Title', 'Is_Married']]\ncorr = train_corr.corr()\nfig = ff.create_annotated_heatmap(\n    z=corr.to_numpy().round(2),\n    x=list(corr.index.values),\n    y=list(corr.columns.values),       \n    xgap=3, ygap=3,\n    zmin=-1, zmax=1,\n    colorscale='YlGnBu',\n    colorbar_thickness=30,\n    colorbar_ticklen=3,\n)\nfig.update_layout(title_text='Correlation Matrix (train set)',\n                  title_x=0.5,\n                  titlefont={'size': 24},\n                  width=550, height=550,\n                  xaxis_showgrid=False,\n                  xaxis={'side': 'bottom'},\n                  yaxis_showgrid=False,\n                  yaxis_autorange='reversed',                   \n                  paper_bgcolor=None,\n                  )\nfig.show()","7020fceb":"test_corr = test[['Pclass', 'Sex', 'Age', 'Fare', 'Embarked', 'Cabin', 'Family_members', 'Ticket_count', 'Title', 'Is_Married']]\ncorr = test_corr.corr()\nfig = ff.create_annotated_heatmap(\n    z=corr.to_numpy().round(2),\n    x=list(corr.index.values),\n    y=list(corr.columns.values),       \n    xgap=3, ygap=3,\n    zmin=-1, zmax=1,\n    colorscale='YlGnBu',\n    colorbar_thickness=30,\n    colorbar_ticklen=3,\n)\nfig.update_layout(title_text='Correlation Matrix (test set)',\n                  title_x=0.5,\n                  titlefont={'size': 24},\n                  width=550, height=550,\n                  xaxis_showgrid=False,\n                  xaxis={'side': 'bottom'},\n                  yaxis_showgrid=False,\n                  yaxis_autorange='reversed',                   \n                  paper_bgcolor=None,\n                  )\nfig.show()","a42dd2fe":"train.drop(columns=['Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'Family_members', 'Family_cat', 'Deck', 'Deck_cat',\n            'Ticket_count', 'Ticket_cat', 'Title', 'Family'], inplace=True)\ntest.drop(columns=['Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'Family_members', 'Family_cat', 'Deck', 'Deck_cat',\n            'Ticket_count', 'Ticket_cat', 'Title', 'Family'], inplace=True)","e8af4a9e":"# Import related libraries\n\nfrom sklearn.model_selection import cross_validate\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.svm import SVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import GradientBoostingClassifier\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import ParameterGrid","be75a325":"# Define scoring and StratifiedKFold\nscoring = ['accuracy', 'f1', 'precision', 'recall', 'roc_auc']\ncv = StratifiedKFold(5, shuffle=True, random_state=42)","56d026e2":"# Drop the columns and Standardize the columns\ny = train.Survived\ntrain.drop(columns='Survived', inplace=True)\n\nmin_max_scaler = MinMaxScaler()\ntrain = min_max_scaler.fit_transform(train)\ntest = min_max_scaler.transform(test)","dfdd61d3":"# Dictionaries for plotting graph\naccuracy = {}\nf1 = {}\nprecision = {}\nrecall = {}\nroc_auc = {}","12d890c6":"def add_scores(model, scoring):\n    accuracy[model] = scoring['test_accuracy'].mean()\n    f1[model] = scoring['test_f1'].mean()\n    precision[model] = scoring['test_precision'].mean()\n    recall[model] = scoring['test_recall'].mean()\n    roc_auc[model] = scoring['test_roc_auc'].mean()","cf00e17a":"models = [SVC(max_iter=5000000), RandomForestClassifier(), LogisticRegression(solver='liblinear'), DecisionTreeClassifier(), GradientBoostingClassifier()]\nmodel_name = ['SVC', 'Random_Forest', 'Logistic', 'Decision_Tree', 'Gradient_Boosting']","13fcd7e1":"# Try different Models with Cross Validation\n\nfor i in range(len(models)):\n    model = models[i]\n    scores = cross_validate(model, train, y, cv=cv, scoring=scoring)\n    add_scores(model_name[i], scores)","7fed8d8e":"fig = make_subplots(\n    rows=2, cols=3, subplot_titles=(\"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\", \"ROC AUC\")\n)\n\nfig.add_trace(go.Bar(x=list(accuracy.values()),\n                     y=model_name, \n                     marker_color='mediumseagreen',\n                     orientation='h',\n                          ), row=1, col=1)\n\nfig.add_trace(go.Bar(x=list(f1.values()),\n                     y=model_name, \n                     marker_color='mediumseagreen',\n                     orientation='h',\n                          ), row=1, col=2)\n\nfig.add_trace(go.Bar(x=list(precision.values()),\n                     y=model_name, \n                     marker_color='mediumseagreen',\n                     orientation='h',\n                          ), row=1, col=3)\n\nfig.add_trace(go.Bar(x=list(recall.values()),\n                     y=model_name, \n                     marker_color='mediumseagreen',\n                     orientation='h',\n                          ), row=2, col=1)\n\nfig.add_trace(go.Bar(x=list(roc_auc.values()),\n                     y=model_name, \n                     marker_color='mediumseagreen',\n                     orientation='h',\n                          ), row=2, col=2)\n\nfig.update_xaxes(range=[0.8, 0.9], row=1, col=1)\nfig.update_xaxes(range=[0.75, 0.85], row=1, col=2)\nfig.update_xaxes(range=[0.75, 0.85], row=1, col=3)\nfig.update_xaxes(range=[0.7, 0.8], row=2, col=1)\nfig.update_xaxes(range=[0.75, 0.95], row=2, col=2)\n\nfig.update_layout(showlegend=False)\nfig.show();\n","02ff13a2":"# Empty dictionaries\nbest_models = {}","24bc2c75":"param_grid =  {'Gradient_Boosting': {\"n_estimators\":[5, 50, 250, 500, 1000, 2000],\"max_depth\":[1,3,5],\"learning_rate\":[0.001, 0.005, 0.01,]},\n               'SVC': {'C': [0.01, 0.025, 0.05, 0.075, 0.1], 'gamma': [1,0.5, 0.1,0.01],'kernel': ['rbf', 'poly', 'sigmoid']},\n               'Decision_Tree': {'criterion': ['gini', 'entropy'], 'max_depth': [1, 2, 3, 5, 10, 20, 50, None], 'min_samples_leaf': [2, 3, 5, 10, 20, 50, 100]},\n               'Logistic': {'penalty': ['l1', 'l2'], 'C': [0.5, 0.1, 0.05, 0.01]},\n               'Random_Forest': {'max_depth': [1, 3, 5, 7], 'min_samples_leaf': [1, 2, 4, 6, 8], 'min_samples_split': [2, 4, 5, 6, 7, 10],\n                                 'n_estimators': [5, 10 ,20, 25, 50, 100]}}\nfor i in range(len(models)):\n    model = models[i]\n    grid = GridSearchCV(model, param_grid[model_name[i]], cv=cv, scoring='accuracy', verbose=1)\n    grid.fit(train, y)\n    best_models[model_name[i]] = grid.best_estimator_\n    print(grid.best_estimator_)\n    print(grid.best_score_)","f2817999":"# Dictionaries for plotting graph\naccuracy = {}\nf1 = {}\nprecision = {}\nrecall = {}\nroc_auc = {}\n\nfor name, model in best_models.items():\n    scores = cross_validate(model, train, y, cv=cv, scoring=scoring)\n    add_scores(name, scores)","5d136b96":"fig = make_subplots(\n    rows=2, cols=3, subplot_titles=(\"Accuracy\", \"F1 Score\", \"Precision\", \"Recall\", \"ROC AUC\")\n)\n\nfig.add_trace(go.Bar(x=list(accuracy.values()),\n                     y=model_name, \n                     marker_color='lightsalmon',\n                     orientation='h',\n                          ), row=1, col=1)\n\nfig.add_trace(go.Bar(x=list(f1.values()),\n                     y=model_name, \n                     marker_color='lightsalmon',\n                     orientation='h',\n                          ), row=1, col=2)\n\nfig.add_trace(go.Bar(x=list(precision.values()),\n                     y=model_name, \n                     marker_color='lightsalmon',\n                     orientation='h',\n                          ), row=1, col=3)\n\nfig.add_trace(go.Bar(x=list(recall.values()),\n                     y=model_name, \n                     marker_color='lightsalmon',\n                     orientation='h',\n                          ), row=2, col=1)\n\nfig.add_trace(go.Bar(x=list(roc_auc.values()),\n                     y=model_name, \n                     marker_color='lightsalmon',\n                     orientation='h',\n                          ), row=2, col=2)\n\nfig.update_xaxes(range=[0.8, 0.9], row=1, col=1)\nfig.update_xaxes(range=[0.75, 0.85], row=1, col=2)\nfig.update_xaxes(range=[0.8, 0.9], row=1, col=3)\nfig.update_xaxes(range=[0.7, 0.8], row=2, col=1)\nfig.update_xaxes(range=[0.75, 0.95], row=2, col=2)\n\nfig.update_layout(showlegend=False)\nfig.show();","88c5baff":"model_results = []\nbest_models = {'SVC' : SVC(max_iter=5000000, C=0.05, gamma=0.1, kernel='poly'),\n               'Random_Forest': RandomForestClassifier(max_depth=1, min_samples_leaf=2, min_samples_split=5, n_estimators=20),\n               'Logistic': LogisticRegression(solver='liblinear', C=0.1, penalty='l2'),\n               'Decision_Tree': DecisionTreeClassifier(criterion='gini', max_depth=2, min_samples_leaf=2),\n               'Gradient_Boosting': GradientBoostingClassifier(learning_rate=0.001, max_depth=1, n_estimators=2000)}\nfor name, model in best_models.items():\n    model.fit(train, y)\n    predicted_survival = model.predict(test)\n    model_results.append(predicted_survival)","311151da":"model_results = np.asarray(model_results)\nmodel_results = model_results.sum(axis=0)","a735bc1b":"voting_df = pd.DataFrame(model_results, columns=['Vote'])\nvoting_df.value_counts()","41c6e646":"prediction = [1 if count >= 4 else 0 for count in model_results]","ef01987c":"result = pd.DataFrame(prediction, columns=['Survived'])\nresult['PassengerId'] = test_passenger_id\nresult.set_index('PassengerId', inplace=True)\nresult.head()\nresult.to_csv('train_test.csv')","dc1d2543":"Next we will encode the family and ticket survival rate, as suggested in this post: https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial\/notebook#2.-Feature-Engineering\n\nAfter such encoding, there are couple of new columns:\n* Ticket_Survival_Rate\n* Ticket_Survival_Rate_NA\n* Family_Survival_Rate\n* Family_Survival_Rate_NA\n* Survival_Rate\n* Survival_Rate_NA","78dff8da":"Seems it is not (almost) perfectly correlated. We can transform it into categorical variable as we have done in Family section.","f848ad56":"It seems that `Deck = T` is not shown in the above diagram. After some investigation, Deck T is in fact the boat deck, so it would make sense if we merge deck T with deck A.","956fc361":"For Cabin column, there are a lot of missing values in both training and testing set. In particular, around **80%** of the data are missing. In order to deal with this, we have to have a look at the cross section of the Titanic.\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/0\/0d\/Olympic_%26_Titanic_cutaway_diagram.png\/330px-Olympic_%26_Titanic_cutaway_diagram.png)\n\nAs we can see, the first Character of the Cabin Column represents the Deck, so we could extract this feature. As for missing data, it is almost impossible to do imputation since most of the cabin data are missing, so we will replace missing value with Deck 'M', which stands for missing deck.","fb4417b3":"As a reference, \n* `Pclass_1` is the encoder for first class\n* `Pclass_2` is the encoder for second class\n* `Pclass_3` is the encoder for third class\n* `Sex_1` is the encoder for female\n* `Sex_2` is the encoder for male\n* `Embarked_1` is the encoder for Cherbourg\n* `Family_cat_1` is the encoder for Large Family Size\n* `Family_cat_2` is the encoder for Single Family\n* `Family_cat_3` is the encoder for Small Family\n\nAnd the result from Decision Tree matches our intuition. For instance, at the root if the passenger is in first class the average age would be 38.233, else the average age would be 26.693.\n\nNow we could fit the tree to our missing ages.","e70dee86":"After filling in the missing values, we can plot the distribution of age in both train set and test set, and check if they are similar.","66bdad7f":"This is the metrics score after hyperparameter tuning:","798c65ef":"Turns out that Ported Embarked is not a redundant feature. As we can see that, `Embarked = S` has a lower survival rate than other groups. As usual, we will transform the categorical labels into one hot encoding.","134a255f":"Great! Let's investigate the next column.","3b9c5979":"# Summary\nHi everyone! This is my first time joining a compeition and sharing my work with others. \n\nIn this notebook I will share my approach for solving the Titianic Dataset with Interactive Plots. Here is the link for plotly tutorial: https:\/\/www.kaggle.com\/desalegngeb\/plotly-guide-customize-for-better-visualizations\n\nThis notebook will be divided into these stages:\n1. Exploratory Data Analysis (EDA) and Feature Engineering\n1. Choosing the Best Model\n1. Hyperparameter Tuning\n\nDon't forget to upvote this notebook if you enjoyed it, and if you have any thoughts please feel free to comment below!","f735bce0":"From the bar plot above, we can divide family size into 3 different groups, with a distinctive survival rate:\n* `Single` with `Family_members = 1`\n* `Small` with `Family_members` between `2` and `4`\n* `Large` with `Family_members` greater or equal to `5`\n\nAnother reason to make this choice is that when family size is greater or equal to 4, there are only a handful of sample points so it would be reasonable to group them together.\n\n\nNow we can transform this column into a new feature, `Family_cat`.","778cd4f8":"After merging we can plot the survival rate again:","f4900771":"After some tuning, most of the models perfrom better than before. We will apply all models to the test set and see the results. Also, after some experimenting these models works best.","f4040fa4":"It seems that Gradient Boosting and SVC are good model candidate, without any hyperparameter fitting. Next we will fit these models with different hyperparameters and choose the best tuned model.","c73d2937":"# Section 3: Hyperparameter Tuning","6022010c":"We can then plot the Fare Distribution and Survival Distribution agsinst Fare.","96316a3c":"For these two column of features, we could merge it into `Family_numbers` column. As we plot the survival against `Family_members` column, we can see a distinct pattern where some family sizes have a higher survival rate than other groups.\n\nWe will create a new column with the name `Family_numbers`, calculated by the sum of SibSp, Parch and 1. We have to add 1 in order to take account of the passenger.","ea82acfe":"## Section 1.3: Analysis by columns","302fbc02":"Last but not least we will transform the categorical labels into one hot encoding.","720997bb":"## Section 1.1: Import relevant libraries and peek raw data","a63933ce":"Let's also investigate the survival rate for each family size.","2035f992":"# Section 2: Choose the best model","6ba31202":"Creating a new class 'M' seems makes sense: Most passenger in Deck 'M' could not survive. We can have a look at the class distribution for each Decks before we can merge these categories together.","30a6fec5":"### Section 1.3.4: Sex\nFrom the Survival Count we can see that Female generally has higher Survival Rate than Male. If you have seen the movie Titanic, places on life boat are prioritized to female and children!","13e701e1":"### Section 1.3.2: Survived\nAfter some exploration we can plot the survival distribution in the training set.","1751b19e":"It seems that Ticket count is highly correlated with family count from the survival count plot. Let's calculate the correlation.","3926c2ad":"### Section 1.3.5: SibSp\/Parch","e7330fe0":"The column Fare is pretty much the same as Age: They both have missing values and they are continuous variables. We can reuse the code from Age and do similar analysis. For sure using Decision Tree would be an overkill to estimate one missing value, but resuing code is more convenient :)","d33c79af":"As a conclusion we can plot the confusion matrix between different features, as well as dropping some columns.","fc54c869":"### Section 1.3.8: Cabin\n","17c21fa2":"It is obvious that Passenger Class is a categorical value, so we could use One-Hot Encoding by adding three different columns, each representing whether that Passenger is in that Class.","dce6d12e":"# Please **upvote** if you like this notebook!","f02a21db":"We can plot a graph and see the metrics across different models.","4dd7073c":"### Section 1.3.7: Age\nThis column represents the age of a passenger. Note that around **20%** of the test rows and **20%** of the train rows have missing age. In order to impute the missing value, we will train a shallow decision tree with age as the target.","b7def831":"### Section 1.3.10: Name\nName column represents the name of each passenger. We could not drop the column since we can extract their title and infer their social status, for example a person with title Dr. might have a different survival rate compare to a person with title Mr. \n\nWe can define a function to extract first name and the title of the passenger, and if possible, the marital status. These functions are inspired from this post: https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial\/notebook","ebbc7863":"This matrix shows that there are some missing values for Age, Cabin and Embarked. We can check the missing values and percentage with the following function.","15e10ee9":"We can see how to group the Decks:\n* 'Deck = A', 'Deck = B', 'Deck = C', 'Deck = D', 'Deck = E' can be groupped to upper deck, since most of the passengers are first class.\n* 'Deck = F' can be groupped to middle deck, since most of the passengers are second class.\n* 'Deck = G' can be groupped to lower deck, since most of the passengers are third class.\n* 'Deck = M' can be groupped to missing deck.","e7fe69da":"You can hover on the bar and see the actual percentage for each category. Sadly most of the people could not survive according to the training set :(","1814855b":"After some preparation work, we can now fit the data into different models. The models considered in this notebook are:\n* SVC\n* RandomForestClassifier\n* LogisticRegression\n* DecisionTreeClassifier\n* GradientBoostingClassifier","bf1972be":"### Section 1.3.6: Embarked\nThis field represents which Port did the passenger embark on Titanic. There are three possible entries:\n* `Embarked = S`: The passenger embarkes from the port Southampton\n* `Embarked = C`: The passenger embarks from the port Cherbourg\n* `Embarked = Q`: The passenger embarks from the port Queenstown\n\nNote that there are two missing `Embarked` entry in the training set. One of the possible way to deal with it is to replace the missing value with the most frequent value, i.e.`Embarked = S`. \n\nThen we will plot the Survival Count against Embarked.","635601b1":"As expected, `Family_members` and `Ticket_count` are highly positive correlated (0.82), whereas `Pclass` and `Fare` are highly negative correlated (-0.55).","58a4f9b1":"We can now apply voting to mark whether the passenger in test set survived. The passenger is marked as survived if 4 or more models agrees with it. You could experiment with different values but i have tried it and it seems to perform best.","57c5f2d5":"We can see that the higher the fare, the higher the survival probability. It is likely that the fare is correlated to the passenger class, which turns out affects the survival rate.","78851157":"### Section 1.3.9: Ticket\n\nAfter careful inspection we can see duplicate values of ticket. This shows that some of the passenger purchased the same ticket so they are at the same group. We can utilize this information and create a new column called `Ticket_count`.","24e76eb5":"## Section 1.2: Missing values\nSo far so good. It seems that there are some missing data for Age and Cabin Column. We will further investigate it by generating a missing value matrix. Referenced from: https:\/\/www.kaggle.com\/rushikeshdarge\/handle-missing-values-only-notebook-you-need","e7f8c350":"### Section 1.3.11: Conclusion","392d6a26":"# Section 1: Exploratory Data Analysis (EDA) and Feature Engineering","38537fd9":"We can now group into three groups, `Mr`, `Miss\/Mrs\/Ms` and `Master`. `Master` is isolated out since it has a higher survival rate than `Mr` class.","039689a2":"### Section 1.3.3: Pclass\nPclass refers to the class that passenger belongs to.\n* `Pclass = 1` refers to first class\n* `Pclass = 2` refers to second class\n* `Pclass = 3` refers to third class\n\nAs shown in the following plot, passengers on first class had a higher survival rate than that of second class, and second class passenger had a higher survival rate than that of third class.","27a54b42":"We now select the best hyperparameter for different models.","ab993908":"Let's plot the survival count and survival rate against Deck.","a490f965":"From the above table we can see that **80%** of the Cabin values are missing! And we can do similar analysis for the test set.","1449a252":"### Section 1.3.1: PassengerId\nPassengerId Column can be dropped since this Column is clearly irrelavent to the prediction of Survival. However we will be keeping test case's PassengerId for future use.","e9383651":"### Section 1.3.9: Fare"}}