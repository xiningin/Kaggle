{"cell_type":{"eda00c66":"code","7a79cd68":"code","8ccf840f":"code","a3c1edba":"code","fa65afe0":"code","ec366d3e":"code","d144ae61":"code","b3b56334":"code","fbcb16d5":"code","c63e8fdb":"code","b5a9c424":"code","14ccb74e":"code","630565a9":"code","f4de53b5":"code","d27b485b":"code","c4b8ad02":"code","3349a513":"code","19bc2b6a":"code","15d783e1":"code","ec483b02":"code","148b24e0":"code","6e8555fa":"code","9876ad94":"code","0e1e01c8":"code","55e86421":"code","91cdba70":"code","79c1e3ae":"code","3385d5e0":"code","d2104643":"code","7b5990fd":"code","018522b4":"code","63dcbd7b":"code","b152c375":"code","880b6ba7":"markdown","2a57f94a":"markdown","2db44c86":"markdown","838a3a29":"markdown","9bf14c23":"markdown","9287f8c8":"markdown","9c16b5d0":"markdown","25dd99b4":"markdown","cc842b61":"markdown","440eb58c":"markdown","88a1a775":"markdown","e1004ece":"markdown","64c321e9":"markdown","8c89de25":"markdown","4012b079":"markdown"},"source":{"eda00c66":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.metrics import confusion_matrix, accuracy_score","7a79cd68":"df = pd.read_csv('..\/input\/heart-failure-clinical-data\/heart_failure_clinical_records_dataset.csv')\ndf = df.drop('anaemia', 1).drop('creatinine_phosphokinase', 1).drop('diabetes', 1).drop('high_blood_pressure', 1).drop('platelets', 1).drop('serum_sodium', 1).drop('sex', 1).drop('smoking', 1)\nX = df.iloc[:, :-2].values#excluding time\ny = df.iloc[:, -1].values","8ccf840f":"df.head()","a3c1edba":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 0)","fa65afe0":"from sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX_train = sc.fit_transform(X_train)\nX_test = sc.transform(X_test)","ec366d3e":"result_comparison = pd.DataFrame(columns=['Model', 'Cross Validation Mean Accuracy', 'Cross Validation Standard Deviation', 'Test Data Accuracy', 'Test Data Precision', 'Test Data Recall', 'Test Data Specificity' ])","d144ae61":"from sklearn.linear_model import LogisticRegression\nclassifier = LogisticRegression(random_state = 0)\nclassifier.fit(X_train, y_train)","b3b56334":"accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","fbcb16d5":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","c63e8fdb":"precision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","b5a9c424":"result_comparison = result_comparison.append({'Model':'Logistic Regression', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","14ccb74e":"from sklearn.tree import DecisionTreeClassifier\nclassifier = DecisionTreeClassifier(criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)","630565a9":"accuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","f4de53b5":"y_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)*100","d27b485b":"precision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","c4b8ad02":"result_comparison = result_comparison.append({'Model':'Decision Tree', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","3349a513":"from sklearn.ensemble import RandomForestClassifier\nclassifier = RandomForestClassifier(n_estimators = 10, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint (\"Accuracy on Test Set: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n\nprecision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)\n","19bc2b6a":"result_comparison = result_comparison.append({'Model':'Random Forest', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","15d783e1":"from sklearn.svm import SVC\nclassifier = SVC(kernel = 'linear')\nclassifier.fit(X_train, y_train)\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint (\"Accuracy on Test Set: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n\nprecision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","ec483b02":"result_comparison = result_comparison.append({'Model':'SVM', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","148b24e0":"classifier = SVC(kernel = 'rbf')\nclassifier.fit(X_train, y_train)\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint (\"Accuracy on Test Set: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n\nprecision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","6e8555fa":"result_comparison = result_comparison.append({'Model':'Kernel SVM', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","9876ad94":"from sklearn.naive_bayes import GaussianNB\nclassifier = GaussianNB()\nclassifier.fit(X_train, y_train)\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint (\"Accuracy on Test Set: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n\nprecision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","0e1e01c8":"result_comparison = result_comparison.append({'Model':'Naive Bayes', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","55e86421":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(X_train, y_train)\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint (\"Accuracy on Test Set: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n\nprecision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","91cdba70":"result_comparison = result_comparison.append({'Model':'XG Boost', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","79c1e3ae":"# Params Copied from https:\/\/www.kaggle.com\/para24\/comparing-the-performance-of-12-classifiers\n\nparams = {'learning_rate': 0.014724527414939945,\n          'num_boost_round': 3451,\n          'gamma': 0.4074467665676125,\n          'reg_lambda': 31.082862686792716,\n          'reg_alpha': 0.008543705214252668,\n          'max_depth': 7,\n          'min_child_weight': 3.2435633342899867e-06,\n          'subsample': 0.15432895096353877,\n          'colsample_bytree': 0.7665394913603492}\nclassifier = XGBClassifier(**params,\n                        random_state=0, n_jobs=-1)\nclassifier.fit(X_train, y_train)\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint (\"Accuracy on Test Set: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n\nprecision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","3385d5e0":"result_comparison = result_comparison.append({'Model':'XG Boost with Params', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","d2104643":"from catboost import CatBoostClassifier\nclassifier = CatBoostClassifier()\n\nclassifier.fit(X_train, y_train, \n                 eval_set=(X_train, y_train),\n                 verbose=False)\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint (\"Accuracy on Test Set: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n\nprecision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","7b5990fd":"result_comparison = result_comparison.append({'Model':'CatBoost', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","018522b4":"from lightgbm import LGBMClassifier\nclassifier = LGBMClassifier(n_jobs=-1)\nclassifier.fit(X_train, y_train);\n\naccuracies = cross_val_score(estimator = classifier, X = X_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))\n\ny_pred = classifier.predict(X_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(\"Confusion Matrix\")\nprint(cm)\nprint (\"Accuracy on Test Set: {:.2f} %\".format(accuracy_score(y_test, y_pred)*100))\n\nprecision = cm[0,0]\/(cm[0,0]+cm[1,0]) * 100\nprint (precision)\nrecall = cm[0,0]\/(cm[0,0]+cm[0,1]) * 100\nprint (recall)\nspecificity = cm[1,1]\/(cm[1,1]+cm[1,0]) * 100\nprint (specificity)","63dcbd7b":"result_comparison = result_comparison.append({'Model':'Light GBM', 'Cross Validation Mean Accuracy': accuracies.mean()*100, 'Cross Validation Standard Deviation': accuracies.std()*100, 'Test Data Accuracy': accuracy_score(y_test, y_pred)*100, 'Test Data Precision':precision, 'Test Data Recall':recall, 'Test Data Specificity':specificity}, ignore_index=True)","b152c375":"result_comparison","880b6ba7":"# Imports and Data Preperations","2a57f94a":"## SVM","2db44c86":"### Confusion Matrix","838a3a29":"### K-Fold Cross Validation","9bf14c23":"# XGBoost","9287f8c8":"### XG Boost with Params \n\nCopied from https:\/\/www.kaggle.com\/para24\/comparing-the-performance-of-12-classifiers","9c16b5d0":"# Kernel SVM","25dd99b4":"# Naive Bayes","cc842b61":"# Random Frost","440eb58c":"# Decision Tree","88a1a775":" # Light GBM","e1004ece":"### Sesitivity and Specificity","64c321e9":"# Logistic Regression","8c89de25":"# CatBoost","4012b079":"# Result and Comparison"}}