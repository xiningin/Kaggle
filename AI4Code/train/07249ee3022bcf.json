{"cell_type":{"ce74788d":"code","303a20ce":"code","ed77e784":"code","1b009c7f":"code","1879d684":"code","4f6ea3d3":"code","92b8f39e":"code","7aa3881e":"code","b224d48a":"code","c8dce386":"code","1355afca":"code","d603846f":"code","6ad824e1":"code","d63e1dcf":"code","52da2582":"code","8c83bc52":"code","6dace30b":"code","6f2e059a":"code","61e9b99b":"code","ac4a60a6":"code","a3397208":"code","d99582a8":"code","2e88099e":"code","dd5aee89":"code","18f7781d":"code","41a146b1":"code","72492aa5":"code","c076ea1e":"code","d97b1207":"code","d1b5f798":"code","993fef6e":"code","2fe98c06":"code","174d1c4e":"code","5a370f8d":"code","6bc32aa9":"code","5187b0ba":"code","c3c8faf5":"markdown","3bfc78f4":"markdown","9dec87f1":"markdown","34e84d2e":"markdown","b3c991da":"markdown","b1e7ca1a":"markdown","0d2fd92c":"markdown","9c28bfb8":"markdown","749f1d03":"markdown","8df70f7a":"markdown","41e6e345":"markdown","98e6718b":"markdown","59cbd870":"markdown","d594a547":"markdown","80d1b1c7":"markdown","2d618e31":"markdown","852be708":"markdown"},"source":{"ce74788d":"import numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style=\"darkgrid\")\n\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, StandardScaler\nfrom sklearn.metrics import roc_curve, auc, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold, train_test_split\n\nfrom lightgbm import LGBMClassifier\n\nimport string\nimport warnings\nwarnings.filterwarnings('ignore')","303a20ce":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","ed77e784":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nss = pd.read_csv(\"\/kaggle\/input\/titanic\/gender_submission.csv\")","1b009c7f":"print(f'Shape of Train dataset is : {train.shape}')\nprint(f'Shape of Test dataset is : {test.shape}')\nprint(f'Shape of Sample Submission dataset is : {ss.shape}')","1879d684":"train.columns","4f6ea3d3":"train.isnull().sum()\/train.shape[0]","92b8f39e":"test.isnull().sum()\/test.shape[0]","7aa3881e":"train.describe().T","b224d48a":"test.describe().T","c8dce386":"total = pd.concat([train,test],axis=0)","1355afca":"age_by_pclass_sex = total.groupby(['Sex', 'Pclass']).median()['Age']\n\nfor pclass in range(1, 4):\n    for sex in ['female', 'male']:\n        print('Median age of Pclass {} {}s: {}'.format(pclass, sex, age_by_pclass_sex[sex][pclass]))\nprint('Median age of all passengers: {}'.format(total['Age'].median()))\n\n# Filling the missing values in Age with the medians of Sex and Pclass groups\ntotal['Age'] = total.groupby(['Sex', 'Pclass'])['Age'].apply(lambda x: x.fillna(x.median())).reset_index(drop=True)","d603846f":"# Filling the missing values in Embarked with S\ntotal['Embarked'] = total['Embarked'].fillna('S')","6ad824e1":"med_fare = total.groupby(['Pclass', 'Parch', 'SibSp']).Fare.median()[3][0][0]\n# Filling the missing value in Fare with the median Fare of 3rd class alone passenger\ntotal['Fare'] = total['Fare'].fillna(med_fare)","d63e1dcf":"# Creating Deck column from the first letter of the Cabin column (M stands for Missing)\ntotal['Deck'] = total['Cabin'].apply(lambda s: s[0] if pd.notnull(s) else 'M')\n\ntotal_decks = total.groupby(['Deck', 'Pclass']).count().drop(columns=['Survived', 'Sex', 'Age', 'SibSp', 'Parch', \n                                                                        'Fare', 'Embarked', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name': 'Count'}).transpose()\n\ndef get_pclass_dist(df):\n    \n    # Creating a dictionary for every passenger class count in every deck\n    deck_counts = {'A': {}, 'B': {}, 'C': {}, 'D': {}, 'E': {}, 'F': {}, 'G': {}, 'M': {}, 'T': {}}\n    decks = df.columns.levels[0]    \n    \n    for deck in decks:\n        for pclass in range(1, 4):\n            try:\n                count = df[deck][pclass][0]\n                deck_counts[deck][pclass] = count \n            except KeyError:\n                deck_counts[deck][pclass] = 0\n                \n    df_decks = pd.DataFrame(deck_counts)    \n    deck_percentages = {}\n\n    # Creating a dictionary for every passenger class percentage in every deck\n    for col in df_decks.columns:\n        deck_percentages[col] = [(count \/ df_decks[col].sum()) * 100 for count in df_decks[col]]\n        \n    return deck_counts, deck_percentages\n\ndef display_pclass_dist(percentages):\n    \n    df_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M', 'T')\n    bar_count = np.arange(len(deck_names))  \n    bar_width = 0.85\n    \n    pclass1 = df_percentages[0]\n    pclass2 = df_percentages[1]\n    pclass3 = df_percentages[2]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, pclass1, color='#b5ffb9', edgecolor='white', width=bar_width, label='Passenger Class 1')\n    plt.bar(bar_count, pclass2, bottom=pclass1, color='#f9bc86', edgecolor='white', width=bar_width, label='Passenger Class 2')\n    plt.bar(bar_count, pclass3, bottom=pclass1 + pclass2, color='#a3acff', edgecolor='white', width=bar_width, label='Passenger Class 3')\n\n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Passenger Class Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Passenger Class Distribution in Decks', size=18, y=1.05)   \n    \n    plt.show()    \n\nall_deck_count, all_deck_per = get_pclass_dist(total_decks)\ndisplay_pclass_dist(all_deck_per)","52da2582":"# Passenger in the T deck is changed to A\nidx = total[total['Deck'] == 'T'].index\ntotal.loc[idx, 'Deck'] = 'A'","8c83bc52":"total_decks_survived = total.groupby(['Deck', 'Survived']).count().drop(columns=['Sex', 'Age', 'SibSp', 'Parch', 'Fare', \n                                                                                   'Embarked', 'Pclass', 'Cabin', 'PassengerId', 'Ticket']).rename(columns={'Name':'Count'}).transpose()\n\ndef get_survived_dist(df):\n    \n    # Creating a dictionary for every survival count in every deck\n    surv_counts = {'A':{}, 'B':{}, 'C':{}, 'D':{}, 'E':{}, 'F':{}, 'G':{}, 'M':{}}\n    decks = df.columns.levels[0]    \n\n    for deck in decks:\n        for survive in range(0, 2):\n            surv_counts[deck][survive] = df[deck][survive][0]\n            \n    df_surv = pd.DataFrame(surv_counts)\n    surv_percentages = {}\n\n    for col in df_surv.columns:\n        surv_percentages[col] = [(count \/ df_surv[col].sum()) * 100 for count in df_surv[col]]\n        \n    return surv_counts, surv_percentages\n\ndef display_surv_dist(percentages):\n    \n    df_survived_percentages = pd.DataFrame(percentages).transpose()\n    deck_names = ('A', 'B', 'C', 'D', 'E', 'F', 'G', 'M')\n    bar_count = np.arange(len(deck_names))  \n    bar_width = 0.85    \n\n    not_survived = df_survived_percentages[0]\n    survived = df_survived_percentages[1]\n    \n    plt.figure(figsize=(20, 10))\n    plt.bar(bar_count, not_survived, color='#b5ffb9', edgecolor='white', width=bar_width, label=\"Not Survived\")\n    plt.bar(bar_count, survived, bottom=not_survived, color='#f9bc86', edgecolor='white', width=bar_width, label=\"Survived\")\n \n    plt.xlabel('Deck', size=15, labelpad=20)\n    plt.ylabel('Survival Percentage', size=15, labelpad=20)\n    plt.xticks(bar_count, deck_names)    \n    plt.tick_params(axis='x', labelsize=15)\n    plt.tick_params(axis='y', labelsize=15)\n    \n    plt.legend(loc='upper left', bbox_to_anchor=(1, 1), prop={'size': 15})\n    plt.title('Survival Percentage in Decks', size=18, y=1.05)\n    \n    plt.show()\n\nall_surv_count, all_surv_per = get_survived_dist(total_decks_survived)\ndisplay_surv_dist(all_surv_per)","6dace30b":"total['Deck'] = total['Deck'].replace(['A', 'B', 'C'], 'ABC')\ntotal['Deck'] = total['Deck'].replace(['D', 'E'], 'DE')\ntotal['Deck'] = total['Deck'].replace(['F', 'G'], 'FG')\n\ntotal['Deck'].value_counts()","6f2e059a":"total.drop(['Cabin'], inplace=True, axis=1)","61e9b99b":"total['Fare'] = pd.qcut(total['Fare'], 13)","ac4a60a6":"total['Age'] = pd.qcut(total['Age'], 9)","a3397208":"total['Ticket_Frequency'] = total.groupby('Ticket')['Ticket'].transform('count')","d99582a8":"total['Title'] = total['Name'].str.split(', ', expand=True)[1].str.split('.', expand=True)[0]\ntotal['Is_Married'] = 0\ntotal['Is_Married'].loc[total['Title'] == 'Mrs'] = 1","2e88099e":"def extract_surname(data):    \n    \n    families = []\n    \n    for i in range(len(data)):        \n        name = data.iloc[i]\n\n        if '(' in name:\n            name_no_bracket = name.split('(')[0] \n        else:\n            name_no_bracket = name\n            \n        family = name_no_bracket.split(',')[0]\n        title = name_no_bracket.split(',')[1].strip().split(' ')[0]\n        \n        for c in string.punctuation:\n            family = family.replace(c, '').strip()\n            \n        families.append(family)\n            \n    return families\n\ntotal['Family'] = extract_surname(total['Name'])","dd5aee89":"total['Family_Size'] = total['SibSp'] + total['Parch'] + 1\n\nfamily_map = {1: 'Alone', 2: 'Small', 3: 'Small', 4: 'Small', 5: 'Medium', 6: 'Medium', 7: 'Large', 8: 'Large', 11: 'Large'}\ntotal['Family_Size_Grouped'] = total['Family_Size'].map(family_map)\n\ntotal['Title'] = total['Title'].replace(['Miss', 'Mrs','Ms', 'Mlle', 'Lady', 'Mme', 'the Countess', 'Dona'], 'Miss\/Mrs\/Ms')\ntotal['Title'] = total['Title'].replace(['Dr', 'Col', 'Major', 'Jonkheer', 'Capt', 'Sir', 'Don', 'Rev'], 'Dr\/Military\/Noble\/Clergy')","18f7781d":"train = total.iloc[:891,:]\ntest = total.iloc[891:,:]\n\ndfs = [train, test]","41a146b1":"# Creating a list of families and tickets that are occuring in both training and test set\nnon_unique_families = [x for x in train['Family'].unique() if x in test['Family'].unique()]\nnon_unique_tickets = [x for x in train['Ticket'].unique() if x in test['Ticket'].unique()]\n\ndf_family_survival_rate = train.groupby('Family')['Survived', 'Family','Family_Size'].median()\ndf_ticket_survival_rate = train.groupby('Ticket')['Survived', 'Ticket','Ticket_Frequency'].median()\n\nfamily_rates = {}\nticket_rates = {}\n\nfor i in range(len(df_family_survival_rate)):\n    # Checking a family exists in both training and test set, and has members more than 1\n    if df_family_survival_rate.index[i] in non_unique_families and df_family_survival_rate.iloc[i, 1] > 1:\n        family_rates[df_family_survival_rate.index[i]] = df_family_survival_rate.iloc[i, 0]\n\nfor i in range(len(df_ticket_survival_rate)):\n    # Checking a ticket exists in both training and test set, and has members more than 1\n    if df_ticket_survival_rate.index[i] in non_unique_tickets and df_ticket_survival_rate.iloc[i, 1] > 1:\n        ticket_rates[df_ticket_survival_rate.index[i]] = df_ticket_survival_rate.iloc[i, 0]","72492aa5":"mean_survival_rate = np.mean(train['Survived'])\n\ntrain_family_survival_rate = []\ntrain_family_survival_rate_NA = []\ntest_family_survival_rate = []\ntest_family_survival_rate_NA = []\n\nfor i in range(len(train)):\n    if train['Family'][i] in family_rates:\n        train_family_survival_rate.append(family_rates[train['Family'][i]])\n        train_family_survival_rate_NA.append(1)\n    else:\n        train_family_survival_rate.append(mean_survival_rate)\n        train_family_survival_rate_NA.append(0)\n        \nfor i in range(len(test)):\n    if test['Family'].iloc[i] in family_rates:\n        test_family_survival_rate.append(family_rates[test['Family'].iloc[i]])\n        test_family_survival_rate_NA.append(1)\n    else:\n        test_family_survival_rate.append(mean_survival_rate)\n        test_family_survival_rate_NA.append(0)\n        \ntrain['Family_Survival_Rate'] = train_family_survival_rate\ntrain['Family_Survival_Rate_NA'] = train_family_survival_rate_NA\ntest['Family_Survival_Rate'] = test_family_survival_rate\ntest['Family_Survival_Rate_NA'] = test_family_survival_rate_NA\n\ntrain_ticket_survival_rate = []\ntrain_ticket_survival_rate_NA = []\ntest_ticket_survival_rate = []\ntest_ticket_survival_rate_NA = []\n\nfor i in range(len(train)):\n    if train['Ticket'][i] in ticket_rates:\n        train_ticket_survival_rate.append(ticket_rates[train['Ticket'][i]])\n        train_ticket_survival_rate_NA.append(1)\n    else:\n        train_ticket_survival_rate.append(mean_survival_rate)\n        train_ticket_survival_rate_NA.append(0)\n        \nfor i in range(len(test)):\n    if test['Ticket'].iloc[i] in ticket_rates:\n        test_ticket_survival_rate.append(ticket_rates[test['Ticket'].iloc[i]])\n        test_ticket_survival_rate_NA.append(1)\n    else:\n        test_ticket_survival_rate.append(mean_survival_rate)\n        test_ticket_survival_rate_NA.append(0)\n        \ntrain['Ticket_Survival_Rate'] = train_ticket_survival_rate\ntrain['Ticket_Survival_Rate_NA'] = train_ticket_survival_rate_NA\ntest['Ticket_Survival_Rate'] = test_ticket_survival_rate\ntest['Ticket_Survival_Rate_NA'] = test_ticket_survival_rate_NA","c076ea1e":"for df in dfs:\n    df['Survival_Rate'] = (df['Ticket_Survival_Rate'] + df['Family_Survival_Rate']) \/ 2\n    df['Survival_Rate_NA'] = (df['Ticket_Survival_Rate_NA'] + df['Family_Survival_Rate_NA']) \/ 2    ","d97b1207":"non_numeric_features = ['Embarked', 'Sex', 'Deck', 'Title', 'Family_Size_Grouped', 'Age', 'Fare']\n\nfor df in dfs:\n    for feature in non_numeric_features:        \n        df[feature] = LabelEncoder().fit_transform(df[feature])","d1b5f798":"cat_features = ['Pclass', 'Sex', 'Deck', 'Embarked', 'Title', 'Family_Size_Grouped']\nencoded_features = []\n\nfor df in dfs:\n    for feature in cat_features:\n        encoded_feat = OneHotEncoder().fit_transform(df[feature].values.reshape(-1, 1)).toarray()\n        n = df[feature].nunique()\n        cols = ['{}_{}'.format(feature, n) for n in range(1, n + 1)]\n        encoded_df = pd.DataFrame(encoded_feat, columns=cols)\n        encoded_df.index = df.index\n        encoded_features.append(encoded_df)\n\ntrain = pd.concat([train, *encoded_features[:6]], axis=1)\ntest = pd.concat([test, *encoded_features[6:]], axis=1)","993fef6e":"total = pd.concat([train, test],axis=0)\ndrop_cols = ['Deck', 'Embarked', 'Family', 'Family_Size', 'Family_Size_Grouped', 'Survived',\n             'Name', 'Parch', 'PassengerId', 'Pclass', 'Sex', 'SibSp', 'Ticket', 'Title',\n            'Ticket_Survival_Rate', 'Family_Survival_Rate', 'Ticket_Survival_Rate_NA', 'Family_Survival_Rate_NA']\n\ntotal.drop(columns=drop_cols, inplace=True, axis=1)\n\ntotal.head()","2fe98c06":"X = StandardScaler().fit_transform(train.drop(columns=drop_cols))\ny = train['Survived'].values\nX_test = StandardScaler().fit_transform(test.drop(columns=drop_cols))\n\nprint('X_train shape: {}'.format(X.shape))\nprint('y_train shape: {}'.format(y.shape))\nprint('X_test shape: {}'.format(X_test.shape))","174d1c4e":"X_train, X_valid, y_train, y_valid = train_test_split(X, y , test_size=0.3, stratify=y, random_state=42)","5a370f8d":"clf = LGBMClassifier(random_state=42)\n\nclf.fit(X_train, y_train)","6bc32aa9":"valid_preds = clf.predict(X_valid)\nprint(accuracy_score(y_valid, valid_preds))","5187b0ba":"ss['Survived'] = clf.predict(X_test).astype(\"int\")\nss.to_csv(\"\/kaggle\/working\/submission.csv\", index=False)","c3c8faf5":"# Model ","3bfc78f4":"# Approach","9dec87f1":"# \ud83d\udcc1 Submission file","34e84d2e":"<br>\n<h1 style=\"color:pink; text-align:center; font-size:30px; font-family:Arial Black; border-radius:30px 30px; background-color:black; line-height: 50px; padding: 15px 15px 15px 2.5%;\">\ud83d\udca5Titanic - LGBM with advanced feature engineering\ud83d\udca5<\/h1>\n<br>","b3c991da":"# Feature Engineering","b1e7ca1a":"# \u2705Reading the Data","0d2fd92c":"### Missing value treatment","9c28bfb8":"# \u2705 Importing Required Libraries","749f1d03":"* Training set has 891 rows and test set has 418 rows\n* Training set have 12 features and test set have 11 features\n* One extra feature in training set is Survived feature, which is the target variable","8df70f7a":"<div class=\"alert alert-block alert-info\"><p style='color:black;'>Thanks to Gunes Evitan @gunesevitan for his wonderful notebook on EDA and feature engineering. Please do check his notebook. I am taking the insights and the fetures from his notebook.<br>\n\n    https:\/\/www.kaggle.com\/gunesevitan\/titanic-advanced-feature-engineering-tutorial<\/p><\/div>","41e6e345":"# Kindly Upvote, if you like this notebook.","98e6718b":"# \ud83d\udd0dBasic Data Checks","59cbd870":"<div class=\"alert alert-block alert-info\"><p style='color:black;'>\n1. Import libraries<br>\n2. Read the data<br>\n3. Basic checks<br>\n4. Feature engineering<br>\n5. Model<br>\n    6. Submission file<\/p><\/div>","d594a547":"### Hi everyone, this is a beginner friendly notebook for the famous Titanic dataset.","80d1b1c7":"### Feature engineering","2d618e31":"* Training set have missing values in Age, Cabin and Embarked columns\n* Test set have missing values in Age, Cabin and Fare columns","852be708":"* PassengerId is the unique id of the row and it doesn't have any effect on target\n* Survived is the target variable we are trying to predict (0 or 1):\n    * 1 = Survived\n    * 0 = Not Survived\n* Pclass (Passenger Class) is the socio-economic status of the passenger and it is a categorical ordinal feature which has 3 unique values (1, 2 or 3):\n    * 1 = Upper Class\n    * 2 = Middle Class\n    * 3 = Lower Class\n* Name, Sex and Age are self-explanatory\n* SibSp is the total number of the passengers' siblings and spouse\n* Parch is the total number of the passengers' parents and children\n* Ticket is the ticket number of the passenger\n* Fare is the passenger fare\n* Cabin is the cabin number of the passenger\n* Embarked is port of embarkation and it is a categorical feature which has 3 unique values (C, Q or S):\n    * C = Cherbourg\n    * Q = Queenstown\n    * S = Southampton"}}