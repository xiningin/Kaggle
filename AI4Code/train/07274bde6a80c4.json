{"cell_type":{"f135b487":"code","892139d4":"code","35e2f8ef":"code","cdca79b4":"code","1f2f587d":"code","c179a3b7":"code","a72bb642":"code","36300f43":"code","0af61eaa":"code","a0cd7045":"code","d3bb2d5e":"code","16153dda":"code","1ea2978f":"code","3e97c325":"code","f4f951bb":"code","c7d98d06":"code","159b8a9c":"code","1ce8e4e7":"code","33ad033e":"code","974c0e68":"code","7ed3ea23":"code","6337b557":"code","dc7a6fcc":"code","cd91a114":"code","be372d09":"code","d31200e6":"code","037604a6":"code","090919c3":"code","e6583efb":"code","bfe6ca43":"code","340fcb22":"code","9c0e18d5":"code","f9d30be4":"code","d3656352":"code","dfb46561":"code","6397feda":"code","9b13ec9b":"code","1b9b33fd":"code","921beb33":"code","7283d9af":"code","7d6ddb1e":"code","2e4ff05b":"code","c084a95a":"code","c165b0d0":"code","f09ce9db":"code","0fdeabea":"code","ce63617b":"code","1c083388":"code","b1575c34":"code","47d0cca8":"markdown","74097109":"markdown","72747a06":"markdown","d943c34d":"markdown","ccd7e7e6":"markdown","181f78b6":"markdown"},"source":{"f135b487":"import warnings\nwarnings.filterwarnings(\"ignore\")\nimport itertools\nimport numpy as np\nimport matplotlib.pyplot as plt\nplt.style.use('fivethirtyeight')\nimport pandas as pd\nimport statsmodels.api as sm\nfrom pylab import rcParams\nrcParams['figure.figsize'] = 18, 6\nfrom tqdm import tqdm_notebook as tqdm\n\n!pip install dateparser\nimport dateparser\n\nfrom sklearn import linear_model\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom statsmodels.tsa.stattools import acf, pacf\nfrom statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n\nfrom fbprophet import Prophet\n\nimport matplotlib\nmatplotlib.rcParams['axes.labelsize'] = 24\nmatplotlib.rcParams['xtick.labelsize'] = 12\nmatplotlib.rcParams['ytick.labelsize'] = 12\nmatplotlib.rcParams['text.color'] = 'k'","892139d4":"def date_parser(x):\n    return pd.datetime.strptime(x, '%d-%m-%Y %H:%M')\n\ntrain_data = pd.read_csv('..\/input\/train.csv', index_col = 1, parse_dates = [1], date_parser = date_parser)\ntest_data = pd.read_csv('..\/input\/test.csv', index_col = 1, parse_dates = [1], date_parser = date_parser)\ntrain_data.columns = train_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\ntest_data.columns = test_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\ny = train_data['count'].resample('D').sum()\ntrain_data = pd.DataFrame(y.astype(int))\ntrain_data.head(20)","35e2f8ef":"train_data.shape","cdca79b4":"train_data.isnull().sum()","1f2f587d":"test_data.isnull().sum()","c179a3b7":"train_data.dtypes","a72bb642":"train_data.nunique()","36300f43":"test_ID = test_data['id'].values\ntest_data = test_data.drop('id', axis = 1)\n#train_data = train_data.drop('id', axis = 1)\ntrain_data.head()","0af61eaa":"train_data.index[1]","a0cd7045":"train_data.plot()\nplt.show()","d3bb2d5e":"plot_acf(train_data)\nplt.show()\nplot_pacf(train_data)\nplt.show()","16153dda":"#calling auto correlation function\nlag_acf = acf(train_data, nlags = 250)\n#Plot ACF:\nplt.figure(figsize = (16, 7))\nplt.plot(lag_acf, marker = '+')\nplt.axhline(y = 0, linestyle = '--', color = 'gray')\nplt.axhline(y = -1.96\/np.sqrt(len(train_data)), linestyle = '--', color = 'gray')\nplt.axhline(y = 1.96\/np.sqrt(len(train_data)), linestyle = '--', color = 'gray')\nplt.title('Autocorrelation Function')\nplt.xlabel('number of lags')\nplt.ylabel('correlation')\nplt.tight_layout()","1ea2978f":"rcParams['figure.figsize'] = 18, 22\nsm.tsa.seasonal_decompose(train_data['count'], freq = 24).plot()\nresult = sm.tsa.stattools.adfuller(train_data['count'])\nplt.show()","3e97c325":"X = train_data.values\ntrain = X[0:535] # 534 data as train data\ntest = X[535:]  # 228 data as test data\npredictions = []","f4f951bb":"p = d = q = range(0, 3)\npdq = list(itertools.product(p, d, q))\nseasonal_pdq = [(x[0], x[1], x[2], 7) for x in list(itertools.product(p, d, q))]","c7d98d06":"param_aic_seasonal = {}\nfor param in tqdm(pdq):\n    for param_seasonal in seasonal_pdq:\n        try:\n            mod = sm.tsa.statespace.SARIMAX(train, \n                                            order = param, \n                                            seasonal_order = param_seasonal)\n            results = mod.fit()\n            #print('ARIMA{}x{}7 - AIC:{}'.format(param, param_seasonal, results.aic))\n            param_aic_seasonal[param, param_seasonal] = results.aic\n        except:\n            continue","159b8a9c":"{k: v for k, v in sorted(param_aic_seasonal.items(), key = lambda item: item[1])}","1ce8e4e7":"\"\"\"\nARIMA(0, 1, 2)x(0, 2, 2, 7)7 - AIC:7796.930684951293\nARIMA(0, 1, 3)x(0, 2, 2, 7)7 - AIC:7798.195336121731\nARIMA(1, 1, 3)x(0, 2, 2, 7)7 - AIC:7800.689430109041\nARIMA(1, 1, 3)x(1, 2, 3, 7)7 - AIC:7801.455544313485\nARIMA(1, 1, 3)x(0, 2, 3, 7)7 - AIC:7817.536127810834\nARIMA(1, 1, 3)x(1, 2, 2, 7)7 - AIC:7821.356956716344\n\nARIMA(2, 2, 2)x(2, 2, 3, 7)7 - AIC:7812.823078011056\nARIMA(2, 2, 2)x(1, 2, 3, 7)7 - AIC:7813.068983822397\n\nARIMA(0, 0, 1)x(1, 2, 2, 7)7 - AIC:7838.228692638588\nARIMA(0, 0, 1)x(1, 2, 3, 7)7 - AIC:7840.423833342043\nARIMA(0, 0, 1)x(0, 2, 2, 7)7 - AIC:7836.734523887294\nARIMA(0, 0, 1)x(0, 2, 3, 7)7 - AIC:7838.20996590997\nARIMA(0, 0, 1)x(0, 2, 4, 7)7 - AIC:7840.067090844341\nARIMA(0, 0, 1)x(0, 2, 5, 7)7 - AIC:7840.052586356935\n\nARIMA(0, 0, 0)x(0, 2, 2, 7)7 - AIC:7923.896707311315\nARIMA(0, 0, 0)x(0, 2, 3, 7)7 - AIC:7912.299111269296\nARIMA(0, 0, 0)x(0, 2, 4, 7)7 - AIC:7925.219651372339\nARIMA(0, 0, 0)x(0, 2, 5, 7)7 - AIC:7914.754898950585\nARIMA(0, 0, 0)x(0, 3, 5, 7)7 - AIC:7942.688159983001\nARIMA(0, 0, 0)x(1, 2, 2, 7)7 - AIC:7912.265579854375\nARIMA(0, 0, 0)x(1, 2, 3, 7)7 - AIC:7933.789327232746\nARIMA(0, 0, 0)x(1, 2, 4, 7)7 - AIC:7916.247023781987\nARIMA(0, 0, 0)x(1, 2, 5, 7)7 - AIC:7928.90160963447\nARIMA(0, 0, 0)x(4, 2, 2, 7)7 - AIC:7918.9959792007885\nARIMA(0, 0, 0)x(5, 2, 1, 7)7 - AIC:7923.534611519698\nARIMA(0, 0, 0)x(5, 2, 2, 7)7 - AIC:7924.175712677705\nARIMA(0, 0, 0)x(5, 2, 4, 7)7 - AIC:7932.990955173896\nARIMA(0, 0, 0)x(5, 3, 2, 7)7 - AIC:7902.697468081234\n\"\"\"","33ad033e":"# 1. Based on minimal AIC : {((0, 1, 2), (0, 2, 2, 7)): 7796.9306841312355}\n\nmod = sm.tsa.statespace.SARIMAX(train, order = (0, 1, 2), seasonal_order = (0, 2, 2, 7))\nresults = mod.fit()\nprint(results.summary())\n\ny_pred = results.predict(start = 535, end = 761, dynamic = True)\nrcParams['figure.figsize'] = 18, 6\nplt.plot(test)\nplt.plot(y_pred, color = 'red')\nplt.show()\n# preds_old = results.predict(start = 0, end = 761, dynamic = False)\nprint(y_pred.sum())","974c0e68":"train_df = train_data[:]\n\nmod = sm.tsa.statespace.SARIMAX(train_df['count'], order = (0, 1, 2), seasonal_order = (0, 2, 2, 7))\nresults = mod.fit()\nprint(results.summary())\n\ny_new = results.predict(start = 762, end = 974, dynamic = True)\ny_old = results.predict(start = 0, end = 761, dynamic = False)\nprint(y_new.sum())","7ed3ea23":"plt.plot(train_data.index, train_data['count'])\nplt.plot(y_new.index, y_new)\nplt.plot(y_old.index, y_old, 'm')\nplt.show()","6337b557":"train_data = pd.read_csv('..\/input\/train.csv', parse_dates = [1], date_parser = date_parser)\ntest_data = pd.read_csv('..\/input\/test.csv', parse_dates = [1], date_parser = date_parser)\ntrain_data.columns = train_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\ntest_data.columns = test_data.columns.str.strip().str.lower().str.replace(' ', '_').str.replace('(', '').str.replace(')', '')\n\ntrain_data['date'] = train_data['datetime'].dt.date\ntrain_data = train_data.groupby(['date'])['count'].sum().reset_index()\ntrain_data.columns = ['ds', 'y']\ntrain_data['y'] = np.log(train_data['y'])\nmodel = Prophet(daily_seasonality = False)\nmodel.add_seasonality(name = 'weekly', period = 7, fourier_order = 300)\nmodel.fit(train_data)\nfuture = model.make_future_dataframe(periods = 213)\nforecast = model.predict(future)\nfig1 = model.plot(forecast)","dc7a6fcc":"fig2 = model.plot_components(forecast)","cd91a114":"f_preds = np.exp(forecast[-213:]['yhat']).values\ner = []\nlistm = [0.044286588, 0.035343014, 0.029911076, 0.024714453, 0.02080223, 0.018621427, \n         0.020023091, 0.023221497, 0.026741002, 0.034555218, 0.049047207, 0.05437526, \n         0.054951351, 0.048600186, 0.051965438, 0.051309072, 0.049999488, 0.051164262, \n         0.052423477, 0.055626605, 0.053455246, 0.049894816, 0.050075828, 0.048892166]\nfor p in range(len(f_preds)):\n    for l in range(len(listm)):\n        er.append(f_preds[p]*listm[l])\n\nResult = {'Count': er}\n\nsubmission_df = pd.DataFrame({\n                  \"ID\": pd.Series([x + 18288 for x in range(5112)]), \n                  \"Count\": pd.Series(Result['Count'])})\nsubmission_df.to_csv('submission_1.csv', index = False)","be372d09":"#checking how well the learning happened\n\ny_old_df = y_old.reset_index(name = \"count\")\ny_new_df = y_new.reset_index(name = \"count\")\nplt.plot(range(0, len(y_old_df)), train_df['count'], color = 'red')\nplt.plot(range(0, len(y_old_df)), y_old_df['count'])","d31200e6":"df = pd.read_csv(\"..\/input\/train.csv\")\ndf['Datetime'] = pd.to_datetime(df['Datetime'], format = '%d-%m-%Y %H:%M')\ndf['date'] = df['Datetime'].dt.date\ndf = df.groupby(['date'])['Count'].sum().reset_index()\ndf['date'] = pd.to_datetime(df['date'])\ndf['month'] = df.date.dt.month\ndf['day'] = df.date.dt.weekday\ndf['month_start'] = df.date.apply(lambda x: 1 if x.is_month_start else 0)\ndf['month_end'] = df.date.apply(lambda x: 1 if x.is_month_end else 0)\ndf['week_start'] = df.day.apply(lambda x: 1 if x == 0 or x == 1 else 0)\ndf['week_end'] = df.day.apply(lambda x: 1 if x == 5 or x == 6 else 0)\ndf['month_day'] = df.date.dt.day\ndf['predicted'] = y_old_df['count']\ndf['diff'] = df.date.apply(lambda x: (x - dateparser.parse('2012-08-25')).days)\ndf.head()","037604a6":"dfh = df.groupby(['date'])['Count'].sum().reset_index()\ndfh.sort_values(['Count'], ascending = [False]).head(50)","090919c3":"df.groupby(['month'])['Count'].mean().plot()","e6583efb":"df.groupby(['day'])['Count'].sum().plot()","bfe6ca43":"df.groupby(['month_day'])['Count'].sum().plot()","340fcb22":"df.groupby(['month_start'])['Count'].sum().plot()","9c0e18d5":"def forecast_accuracy(forecast, actual):\n    mape = np.mean(np.abs(forecast - actual)\/np.abs(actual))  # MAPE\n    me = np.mean(forecast - actual)             # ME\n    mae = np.mean(np.abs(forecast - actual))    # MAE\n    mpe = np.mean((forecast - actual)\/actual)   # MPE\n    rmse = np.mean((forecast - actual)**2)**.5  # RMSE\n    corr = np.corrcoef(forecast, actual)[0, 1]   # corr\n    mins = np.amin(np.hstack([forecast[:, None], \n                              actual[:, None]]), axis = 1)\n    maxs = np.amax(np.hstack([forecast[:, None], \n                              actual[:, None]]), axis = 1)\n    minmax = 1 - np.mean(mins\/maxs)             # minmax\n    acf1 = 0#acf(fc-test)[1]                      # ACF1\n    return({'mape': mape, 'me': me, 'mae': mae, \n            'mpe': mpe, 'rmse': rmse, 'acf1': acf1, \n            'corr': corr, 'minmax': minmax})","f9d30be4":"new_df = df.drop(['date'], axis = 1)\nnew_df.shape","d3656352":"test_df = pd.read_csv(\"..\/input\/test.csv\")\ntest_df['Datetime'] = pd.to_datetime(test_df['Datetime'], format = '%d-%m-%Y %H:%M')\ntest_df['date'] = test_df['Datetime'].dt.date\ntest_df = test_df.groupby(['date']).sum().reset_index()\ntest_df['date'] = pd.to_datetime(test_df['date'])\ntest_df['month'] = test_df.date.dt.month\ntest_df['day'] = test_df.date.dt.weekday\ntest_df['month_start'] = test_df.date.apply(lambda x: 1 if x.is_month_start else 0)\ntest_df['month_end'] = test_df.date.apply(lambda x: 1 if x.is_month_end else 0)\ntest_df['week_start'] = test_df.day.apply(lambda x: 1 if x == 0 or x == 1 else 0)\ntest_df['week_end'] = test_df.day.apply(lambda x: 1 if x == 5 or x == 6 else 0)\ntest_df['month_day'] = test_df.date.dt.day\ntest_df['predicted'] = y_new_df['count']\ntest_df['diff'] = test_df.date.apply(lambda x: (x - dateparser.parse('2012-08-25')).days)\ntest_df.head()","dfb46561":"X_train = new_df[:]\ny_train = X_train['Count']\ndropcols = ['Count']\nX_train.drop(dropcols, axis = 1, inplace = True)\n\nX_test = new_df[700:]\ny_test = X_test['Count']\nX_test.drop(dropcols, axis = 1, inplace = True)\n\ntesting_df = test_df.drop([\"ID\", \"date\"], axis = 1)\ntesting_df","6397feda":"linear = linear_model.LinearRegression()\nlinear.fit(X_train, y_train)\n\nlinear1 = linear_model.LinearRegression()\nlinear1.fit(X_train, np.log(y_train))\n\nrtp = linear.predict(X_test)\nrtp1 = np.exp(linear1.predict(X_test))\n\nnew_rtp = (rtp + rtp1) \/ 2\n\nprint(forecast_accuracy(np.array(rtp), np.array(y_test)))\nprint(forecast_accuracy(np.array(rtp1), np.array(y_test)))\n\nfor c, cc in enumerate(linear.coef_):\n    print(X_train.columns[c])\n    print(cc)","9b13ec9b":"plt.plot(range(0, len(rtp)), rtp, color = 'red')\nplt.plot(range(0, len(rtp)), y_test)","1b9b33fd":"plt.plot(range(0, len(y_old_df[700:])), train_df[700:]['count'], color = 'red')\nplt.plot(range(0, len(y_old_df[700:])), y_old_df[700:]['count'])","921beb33":"rf = RandomForestRegressor(random_state = 42)\nrandom_grid = {'bootstrap': [True, False], \n               'max_depth': [10, 20, 30, 40, 50, 60, 70, 80, 90, 100, None], \n               'max_features': ['auto', 'sqrt'], \n               'min_samples_leaf': [1, 2, 4], \n               'min_samples_split': [2, 5, 10, 15], \n               'n_estimators': [100, 200, 400, 600, 800, 1000, 1200, 1400, 1600, 1800, 2000]\n              }\n\nrf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 5, verbose = 1, random_state = 42, n_jobs = -1)\nrf_random.fit(X_train, y_train)","7283d9af":"rf_model = RandomForestRegressor(**rf_random.best_params_)\nrf_model.fit(X_train, y_train)","7d6ddb1e":"rtp = rf_model.predict(X_test)\nprint(forecast_accuracy(np.array(rtp), np.array(y_test)))","2e4ff05b":"plt.plot(range(0, len(rtp)), rtp, color = 'red')\nplt.plot(range(0, len(rtp)), y_test)","c084a95a":"linear_pred = linear.predict(testing_df)","c165b0d0":"plt.plot(df.index, df.Count)\nplt.plot(testing_df.index + 761, linear_pred)","f09ce9db":"rf_test_pred = rf_model.predict(testing_df)\nplt.plot(df.index, df.Count)\nplt.plot(testing_df.index + 761, rf_test_pred)","0fdeabea":"rf_test_pred.sum()","ce63617b":"ensemble_preds = (y_new + f_preds + linear_pred) \/ 3","1c083388":"plt.plot(X_train.index, y_train)\nplt.plot(testing_df.index + 761, ensemble_preds)","b1575c34":"er = []\nlistm = [0.044286588, \n         0.035343014, \n         0.029911076, \n         0.024714453, \n         0.02080223, \n         0.018621427, \n         0.020023091, \n         0.023221497, \n         0.026741002, \n         0.034555218,\n         0.049047207, \n         0.05437526, \n         0.054951351, \n         0.048600186, \n         0.051965438, \n         0.051309072, \n         0.049999488, \n         0.051164262, \n         0.052423477, \n         0.055626605, \n         0.053455246, \n         0.049894816, \n         0.050075828, \n         0.048892166]\nfor p in range(len(ensemble_preds)):\n    for l in range(len(listm)):\n        er.append(ensemble_preds[p]*listm[l])\nd = {'Count': er}\npredf = pd.DataFrame(data = d)\nsubmission_df = pd.DataFrame({\n                  \"ID\": pd.Series([x + 18288 for x in range(5112)]),\n                  \"Count\": pd.Series(predf['Count'])})\nsubmission_df.to_csv('submission_FBprophet.csv', index = False)","47d0cca8":"## Dickey\u2013Fuller test","74097109":"## Prediction using Prophet","72747a06":"## Ensembles","d943c34d":"### Find best params for  SARIMAX  (p, d, q), (P, D, Q)n and seasonal ","ccd7e7e6":"## SARIMA","181f78b6":"## Random Forest Regressor"}}