{"cell_type":{"3b5491f9":"code","1ea03928":"code","8ff6da9e":"code","2677b7fb":"code","8b186127":"code","14e35b80":"code","d1d47ae6":"code","465544e4":"code","80aac1f5":"code","525bd12a":"code","aa4c0585":"markdown","2dd34efe":"markdown","95274840":"markdown","fcab7dfa":"markdown","cc858ad9":"markdown"},"source":{"3b5491f9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\n# Any results you write to the current directory are saved as output.","1ea03928":"import h5py\nimport cv2","8ff6da9e":"from tensorflow.python.keras.applications.resnet import preprocess_input\nfrom tensorflow.python.keras.preprocessing.image import load_img, img_to_array\nfrom tensorflow import keras\nimport matplotlib.pylab as plt\n\nimg_paths=[]\nletters2 = pd.read_csv(\"..\/input\/classification-of-handwritten-letters\/letters2.csv\")\nnum_ex=len(letters2)\nfor k in range(0,len(letters2)):\n    img_paths.append('..\/input\/classification-of-handwritten-letters\/letters2\/'+ letters2['file'][k])\nimage_size = 32\ndef read_prep_images(img_paths, img_height=image_size, img_width=image_size):\n    imgs=[load_img(img_path, target_size=(img_height, img_width)) for img_path in img_paths]\n    img_array = np.array([img_to_array(img) for img in imgs])\n    output = preprocess_input(img_array)\n    output=output\/255\n    return(output)\ntest_data=read_prep_images(img_paths)\nx=(np.dot(test_data,[0.299, 0.587, 0.114]))\ny=letters2['label']\nplt.imshow(x[1000], cmap=plt.cm.bone)\n\n#print(np.shape(y))\ny = keras.utils.to_categorical(y-1,num_classes=None)\nx=x.reshape(-1,32,32,1)","2677b7fb":"print(np.shape(y))","8b186127":"def history_plot(fit_history, n):\n    plt.plot(fit_history.history['loss'], color='slategrey', label='train')\n    plt.plot(fit_history.history['val_loss'], color='blue', label='valid')\n    plt.xlabel('epochs')\n    plt.ylabel('loss')\n    plt.legend()","14e35b80":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, \n                                                    test_size = 0.2, \n                                                    random_state = 1)\nn = int(len(x_test)\/2)\nx_valid, y_valid = x_test[:n], y_test[:n]\nx_test, y_test = x_test[n:], y_test[n:]","d1d47ae6":"# Print the shape\nprint (\"Training tensor's shape:\", x_train.shape)\nprint (\"Training target's shape\", y_train.shape)\nprint (\"Validating tensor's shape:\", x_valid.shape)\nprint (\"Validating target's shape\", y_valid.shape)\nprint (\"Testing tensor's shape:\", x_test.shape)\nprint (\"Testing target's shape\", y_test.shape)","465544e4":"from sklearn.model_selection import train_test_split\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout, Activation, GlobalMaxPooling2D, MaxPooling2D\n\ndef model():\n    model = Sequential()\n\n    model.add(Conv2D(32, (5, 5), padding='same', input_shape=(32, 32,1)))\n    model.add(Activation('relu'))    \n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(196, (5, 5)))\n    model.add(Activation('relu'))    \n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n    \n    model.add(GlobalMaxPooling2D()) \n    \n    model.add(Dense(1024, activation='relu'))\n    model.add(Dropout(0.5)) \n    \n    model.add(Dense(33))\n    model.add(Activation('softmax'))\n    \n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    \n    return model\n\nmodel2 = model()","80aac1f5":"from tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense, Flatten, Conv2D, Dropout\n\nmodel=Sequential()\nmodel.add(Conv2D(32,\n                 activation='relu',\n                 kernel_size=5,\n                 input_shape=(32, 32,1),\n                 padding='same'))\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(20,\n                 kernel_size=5,\n                 activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Conv2D(20,activation='relu',\n                        kernel_size=3))\nmodel.add(Dropout(0.25))\nmodel.add(Flatten())\nmodel.add(Dense(1024, activation='relu'))\nmodel.add(Dropout(0.5))\nmodel.add(Dense(33, activation='softplus'))\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics= ['accuracy'])\nhistory=model.fit(x_train, y_train, \n                    epochs=50, batch_size=64, verbose=2,\n                    validation_data=(x_valid, y_valid))\n","525bd12a":"history_plot(history,0)","aa4c0585":"split train and bla bla bla","2dd34efe":"Now create prep_image:","95274840":"Now, make a history function","fcab7dfa":"> This Notebook was solely made for the purpose of learning, mine obviously. I took inspiration from many notebooks from this Dataset. This is quite an interesting Dataset to work to. Some of my models, which I trained are are as below","cc858ad9":"Now, create a model"}}