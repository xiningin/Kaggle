{"cell_type":{"19554bce":"code","c6e6dff1":"code","f1202506":"code","6dc7443f":"code","b00be7c2":"code","7269c86a":"code","e30a4c62":"code","936a5ced":"code","15c15e22":"code","f6a08e9c":"code","2292a4a4":"code","cb789bf0":"code","6775906a":"code","f2eb5bf7":"code","3a374894":"code","8d69d591":"code","4d1372b9":"code","75d4d664":"code","7235d23d":"code","f9132a58":"code","dd45ea4c":"code","23a4fc8d":"code","49262e7b":"code","34298119":"code","f7f5800b":"code","5c33b582":"code","6815ab42":"code","6c4af8dd":"code","83a0f4dc":"code","1c7f59d5":"code","edba2a7d":"code","900e1c71":"code","6a55a507":"code","11cf858c":"code","389797dd":"code","417526b3":"code","3a616d8e":"code","d79f7a32":"code","5f6bb27c":"code","acf6af66":"code","00839652":"code","31b7ddc2":"markdown"},"source":{"19554bce":"import tensorflow as tf","c6e6dff1":"import numpy as np\nimport cv2\nimport os\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils.np_utils import to_categorical\nfrom keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.optimizers import Adam\nfrom keras.layers import Dropout,Flatten\nfrom keras.layers.convolutional import Conv2D,MaxPooling2D\nimport pickle","f1202506":"path1 =\"\/kaggle\/input\/kermany2018\/OCT2017 \/train\"\npath2 =\"\/kaggle\/input\/kermany2018\/OCT2017 \/test\"\npath3 =\"\/kaggle\/input\/kermany2018\/OCT2017 \/val\"\ntest_ratio=0.2\nval_ratio=0.2\nimage_size=(128,128,3)","6dc7443f":"myList = os.listdir(path1)\nprint(\"Total Number of Classes Detected :\",len(myList))","b00be7c2":"noOfclasses= len(myList)","7269c86a":"print(myList)","e30a4c62":"print(\"Importing Classes...\")","936a5ced":"images=[]\nclassNo=[]\nCATEGORIES = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]\nfor x in myList:\n  myPicList = os.listdir(path1+\"\/\"+str(x))\n  for y in myPicList:\n    curImg = cv2.imread(path1+\"\/\"+str(x)+\"\/\"+y)\n    curImg = cv2.resize(curImg,(image_size[0],image_size[1]))\n    images.append(curImg)\n    classNo.append(CATEGORIES.index(x))\n  print(x,end=\" \")","15c15e22":"x_test=[]\ny_test=[]\nCATEGORIES = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]\nfor x in myList:\n  myPicList = os.listdir(path2+\"\/\"+str(x))\n  for y in myPicList:\n    curImg = cv2.imread(path2+\"\/\"+str(x)+\"\/\"+y)\n    curImg = cv2.resize(curImg,(image_size[0],image_size[1]))\n    x_test.append(curImg)\n    y_test.append(CATEGORIES.index(x))\n  print(x,end=\" \")","f6a08e9c":"x_val=[]\ny_val=[]\nCATEGORIES = ['NORMAL',\"CNV\",\"DME\",\"DRUSEN\"]\nfor x in myList:\n  myPicList = os.listdir(path3+\"\/\"+str(x))\n  for y in myPicList:\n    curImg = cv2.imread(path3+\"\/\"+str(x)+\"\/\"+y)\n    curImg = cv2.resize(curImg,(image_size[0],image_size[1]))\n    x_val.append(curImg)\n    y_val.append(CATEGORIES.index(x))\n  print(x,end=\" \")","2292a4a4":"print(len(images))\nprint(len(classNo))","cb789bf0":"x_train = np.array(images)\ny_train = np.array(classNo)","6775906a":"x_test = np.array(x_test)\ny_test = np.array(y_test)\nx_val = np.array(x_val)\ny_val = np.array(y_val)","f2eb5bf7":"print(x_train.shape)\nprint(x_test.shape)","3a374894":"#x_train,x_test,y_train,y_test = train_test_split(images,classNo,test_size=test_ratio,random_state = 42,stratify=classNo)\n#x_train,x_validation,y_train,y_validation = train_test_split(x_train,y_train,test_size=val_ratio,random_state = 42,stratify=y_train)\n","8d69d591":"del images\ndel classNo","4d1372b9":"print(x_train.shape)\nprint(x_test.shape)\nprint(x_val.shape)","75d4d664":"numofSamples=[]\nfor x in range(0,noOfclasses):\n  numofSamples.append(len(np.where(y_train==x)[0]))","7235d23d":"print(numofSamples)","f9132a58":"plt.figure(figsize=(10,5))\nplt.bar(range(0,noOfclasses),numofSamples)\nplt.title('No of Images for each Class')\nplt.xlabel(\"Class ID\")\nplt.ylabel(\"No of Images\")\nplt.show()","dd45ea4c":"from imblearn.under_sampling import RandomUnderSampler\nimport pandas as pd\nimport seaborn as sns\nX_trainShape = x_train.shape[1]*x_train.shape[2]*x_train.shape[3]\nX_trainFlat = x_train.reshape(x_train.shape[0], X_trainShape)\nY_train = y_train\nros = RandomUnderSampler()\nX_trainRos, Y_trainRos = ros.fit_sample(X_trainFlat, Y_train)\n# Encode labels to hot vectors (ex : 2 -> [0,0,1,0,0,0,0,0,0,0])\nY_trainRosHot = to_categorical(Y_trainRos, num_classes = 4)\n# Make Data 2D again\nfor i in range(len(X_trainRos)):\n    height, width, channels = image_size[0],image_size[1],3\n    X_trainRosReshaped = X_trainRos.reshape(len(X_trainRos),height,width,channels)\n# Plot Label Distribution\ndfRos = pd.DataFrame()\ndfRos[\"labels\"]=Y_trainRos\nlabRos = dfRos['labels']\nsns.countplot(labRos)","23a4fc8d":"def preProcessing(img):\n    img = cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n    return img","49262e7b":"del x_train\ndel y_train","34298119":"x_train = np.array(list(map(preProcessing,X_trainRosReshaped)))\nprint(x_train[0].shape)","f7f5800b":"x_test = np.array(list(map(preProcessing,x_test)))\nprint(x_test[0].shape)","5c33b582":"#print(x_validation[0].shape)\nx_validation = np.array(list(map(preProcessing,x_val)))\nprint(x_validation[0].shape)","6815ab42":"print(x_train.shape)","6c4af8dd":"X_train = x_train.reshape(x_train.shape[0],x_train.shape[1],x_train.shape[2],1)\nprint(X_train.shape)","83a0f4dc":"X_test = x_test.reshape(x_test.shape[0],x_test.shape[1],x_test.shape[2],1)\nX_validation = x_validation.reshape(x_validation.shape[0],x_validation.shape[1],x_validation.shape[2],1)","1c7f59d5":"del x_test\ndel x_train\ndel x_validation","edba2a7d":"\"\"\"dataGen = ImageDataGenerator(width_shift_range=0.1,\n                             height_shift_range=0.1,\n                             zoom_range=0.2,\n                             shear_range=0.1,\n                             rotation_range=10)\"\"\"","900e1c71":"#dataGen.fit(X_train)\n","6a55a507":"y_train = to_categorical(Y_trainRos,noOfclasses)\ny_test = to_categorical(y_test,noOfclasses)\ny_validation = to_categorical(y_val,noOfclasses)","11cf858c":"class CustomCallback(tf.keras.callbacks.Callback):\n  def __init__(self,fraction):\n    super(CustomCallback,self).__init__()\n    self.fraction = fraction\n    self.train_a = [];\n    self.val_a =[];\n\n    with open('log.txt','w') as f:\n      f.write('Starting of logging..\\n')\n\n    self.fig = plt.figure(figsize=(4,3))\n    self.ax = plt.subplot(1,1,1)\n    plt.ion()\n\n  def on_train_begin(self,logs=None):\n    self.fig.show()\n    self.fig.canvas.draw()\n  \n  def on_train_end(self,logs=None):\n    with open('log.txt','a') as f:\n      f.write('End of logging..\\n')\n  def on_epoch_begin(self,epoch,logs=None):\n    lr= tf.keras.backend.get_value(self.model.optimizer.lr)\n    lr *= self.fraction\n    tf.keras.backend.set_value(self.model.optimizer.lr,lr)\n    with open('log.txt','a') as f:\n      f.write('At epoch {:02d}, learning rate changed to {:.4f}\\n'.format(epoch,lr))\n  def on_epoch_end(self,epoch,logs=None):\n    val_acc = logs.get('val_accuracy')\n    train_acc = logs.get('accuracy')\n    self.train_a.append(train_acc)\n    self.val_a.append(val_acc)\n    with open('log.txt','a') as f:\n        f.write('At epoch {:02d}, training accuracy: {:.3f}, validation accuracy: {:.3f}\\n'.format(epoch,train_acc,val_acc))\n    self.ax.clear()\n    self.ax.plot(range(1+epoch),self.train_a,label=\"Training\")\n    self.ax.plot(range(1+epoch),self.val_a,label=\"Validation\")\n    self.ax.set_xlabel('Epochs')\n    self.ax.set_ylabel('Accuracy')\n    self.ax.legend()\n    self.fig.canvas.draw()\n    self.fig.show()","389797dd":"def model():\n  filters=60\n  sizeoffilter1 = (5,5)\n  sizeoffilter2 = (4,4)\n  sizeoffilter3 = (3,3)\n  sizeofpool = (2,2)\n  node=5000\n\n  model = Sequential();\n  model.add((Conv2D(filters,sizeoffilter1,input_shape=(image_size[0],image_size[1],1)\n  ,activation=\"relu\")))\n\n  model.add((Conv2D(filters,sizeoffilter1,activation=\"relu\")))\n  model.add((Conv2D(filters\/\/2,sizeoffilter2,activation=\"relu\")))\n  model.add((Conv2D(filters\/\/2,sizeoffilter2,activation=\"relu\")))\n  model.add(MaxPooling2D(pool_size=sizeofpool))\n  model.add(Dropout(0.2))\n\n  model.add((Conv2D(filters,sizeoffilter1,activation=\"relu\")))\n  model.add((Conv2D(filters\/\/2,sizeoffilter2,activation=\"relu\")))\n  model.add((Conv2D(filters\/\/2,sizeoffilter2,activation=\"relu\")))\n  model.add(MaxPooling2D(pool_size=sizeofpool))\n  model.add(Dropout(0.2))\n\n  model.add((Conv2D(filters,sizeoffilter2,activation=\"relu\")))\n  model.add(MaxPooling2D(pool_size=sizeofpool))\n  model.add((Conv2D(filters\/\/2,sizeoffilter3,activation=\"relu\")))\n  model.add((Conv2D(filters\/\/2,sizeoffilter3,activation=\"relu\")))\n  model.add(MaxPooling2D(pool_size=sizeofpool))\n  model.add(Dropout(0.2))\n\n  model.add(Flatten())\n  model.add(Dense(node,activation=\"relu\"))\n  model.add(Dropout(0.2))\n  model.add(Dense(noOfclasses,activation=\"softmax\"))\n\n  model.compile(Adam(lr=0.001),loss=\"categorical_crossentropy\",metrics=['accuracy'])\n\n  return model\n  \nmodel=model()","417526b3":"model.summary()","3a616d8e":"os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"","d79f7a32":"\nhistory = model.fit(X_train,Y_trainRosHot,epochs=50,validation_data =(X_validation,y_validation) ,batch_size=256,\n                    shuffle=True,\n                    max_queue_size=20,\n                    use_multiprocessing=True,\n                    workers=1,\n                   callbacks=[CustomCallback(fraction=0.9)])","5f6bb27c":"plt.figure(1)\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['training','validation'])\nplt.title('Loss')\nplt.xlabel('epoch')\nplt.figure(2)\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['training','validation'])\nplt.title('Accuracy')\nplt.xlabel('epoch')\nplt.show()\n","acf6af66":"score = model.evaluate(X_test,y_test,verbose=0)\nprint('Test Score = ',score[0])\nprint('Test Accuracy = ',score[1])","00839652":"model.save('trained.model')","31b7ddc2":"#Spliting Data"}}