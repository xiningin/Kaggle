{"cell_type":{"a431713c":"code","24801f6e":"code","dcbd02fe":"code","2a7da77c":"code","2bd0f9ad":"code","dab84296":"code","9f0aa588":"code","d34f13c0":"code","716cd267":"code","db7cfaf2":"code","49f180b9":"code","9344be09":"code","0789e137":"code","d8fc3698":"code","e0a1b762":"code","8cf239c7":"code","3bdfdc25":"code","d7211d1b":"code","0e9df23a":"code","c4c11565":"code","487ab92a":"code","8009a99e":"code","a54a3523":"code","b98ed677":"code","1afc5a8d":"code","ac93e084":"code","4f0a3e67":"code","34dfaead":"code","a830c51c":"code","72364dd7":"code","10c53ffd":"code","d20bf589":"code","11330a63":"code","99699e7c":"code","9cea989d":"code","fc15a3e2":"code","ac50e6fe":"code","2821457a":"code","574f61ba":"code","6edba8f0":"code","aec86e9c":"code","b1757212":"code","d9caf062":"code","ae3fbe00":"code","31d39ddf":"code","dc6cd229":"code","e19fc816":"code","59d59845":"code","1838d18c":"code","55cb1b34":"code","932f7fc9":"code","dd1ff68d":"code","c9540266":"code","897da657":"code","1cc5f498":"code","5668cfc2":"code","608fe048":"code","428f6034":"code","9cb4cb37":"code","db5f976a":"code","24b85043":"code","3700d392":"code","01969c3d":"code","c7fbca13":"code","3cf8d39d":"markdown","c965905a":"markdown","3379f1e4":"markdown","7388970e":"markdown","6d644455":"markdown","f509715e":"markdown","d681ccc5":"markdown","5453c3c6":"markdown","18bddf19":"markdown","29fabdd4":"markdown","68ec28ef":"markdown","ab4c7907":"markdown","5cce80a4":"markdown","a7b6fbc2":"markdown","60f71331":"markdown"},"source":{"a431713c":"import pandas as pd \nimport numpy as np ","24801f6e":"train_df = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/nlp-getting-started\/test.csv')","dcbd02fe":"train_df.head()","2a7da77c":"train_df.info()","2bd0f9ad":"train_df.nunique()","dab84296":"test_df.head()","9f0aa588":"test_df.info()","d34f13c0":"test_df.nunique()","716cd267":"train_df.head()","db7cfaf2":"train_df.drop(columns=['id','keyword','location'], axis=1, inplace=True)","49f180b9":"test_df.head()","9344be09":"test_df.drop(columns=['keyword','location'],axis=1, inplace=True)","0789e137":"print(train_df.shape, test_df.shape)","d8fc3698":"from sklearn.model_selection import train_test_split","e0a1b762":"X_train, X_valid, y_train, y_valid = train_test_split(train_df['text'],train_df['target'], test_size=0.2, random_state=111)","8cf239c7":"print(X_train.shape, y_train.shape, X_valid.shape, y_valid.shape)","3bdfdc25":"from tensorflow.keras.preprocessing.text import Tokenizer","d7211d1b":"vocab_size = 1000\noov_token = \"<OOV>\"\ntokenizer = Tokenizer(num_words=vocab_size, oov_token=oov_token)","0e9df23a":"tokenizer.fit_on_texts(X_train)","c4c11565":"X_train = tokenizer.texts_to_sequences(X_train)\nX_valid = tokenizer.texts_to_sequences(X_valid)","487ab92a":"for i in range(10):\n    print(len(X_train[i]))","8009a99e":"X_train[0]","a54a3523":"for i in range(10):\n    print(len(X_valid[i]))","b98ed677":"X_valid[0]","1afc5a8d":"from tensorflow.keras.preprocessing.sequence import pad_sequences","ac93e084":"max_length = 120\ntrunc_type = 'post'\npad_type = 'post'","4f0a3e67":"X_train_padded = pad_sequences(X_train, maxlen=max_length, truncating=trunc_type, padding=pad_type)\nX_valid_padded = pad_sequences(X_valid, maxlen=max_length, truncating=trunc_type, padding=pad_type)","34dfaead":"X_train_padded[:2]","a830c51c":"X_valid_padded[:2]","72364dd7":"print(X_train_padded.shape, X_valid_padded.shape)","10c53ffd":"print(type(X_train_padded), type(X_valid_padded))\nprint(type(y_train), type(y_valid))","d20bf589":"y_train = np.array(y_train)\ny_valid = np.array(y_valid)","11330a63":"print(type(X_train_padded), type(X_valid_padded))\nprint(type(y_train), type(y_valid))","99699e7c":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Embedding, LSTM, Dense, Bidirectional, Flatten","9cea989d":"embedding_dim = 16\n# vocab_size = 1000\n# max_length = 120","fc15a3e2":"model = Sequential([\n    Embedding(vocab_size, embedding_dim, input_length=max_length),\n    Bidirectional(LSTM(64, return_sequences=True)),\n    Bidirectional(LSTM(64, return_sequences=True)),\n    Bidirectional(LSTM(64, dropout=0.5)),\n    Dense(32, activation='relu'),\n    Dense(16, activation='relu'),\n    Dense(1, activation='sigmoid')\n])","ac50e6fe":"model.summary()","2821457a":"model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['acc'])","574f61ba":"from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping","6edba8f0":"filepath = 'my_checkpoint.ckpt'\ncp = ModelCheckpoint(\n    filepath=filepath,\n    save_weights_only=True,\n    save_best_only=True,\n    monitor='val_loss',\n    verbose=1\n)","aec86e9c":"ep = EarlyStopping(\n    monitor='val_loss', \n    patience=5,\n)","b1757212":"epochs=30\nmodel.fit(\n    X_train_padded, y_train,\n    validation_data = (X_valid_padded, y_valid),\n    callbacks=[cp,ep],\n    epochs=epochs\n)","d9caf062":"model.load_weights(filepath)","ae3fbe00":"model.evaluate(X_valid_padded, y_valid)","31d39ddf":"X_valid[0]","dc6cd229":"model.save('.\/model\/basic_nlp.h5')","e19fc816":"import tensorflow as tf","59d59845":"mymodel = tf.keras.models.load_model('.\/model\/basic_nlp.h5')","1838d18c":"mymodel.summary()","55cb1b34":"X_test = tokenizer.texts_to_sequences(test_df['text'])","932f7fc9":"X_test_padded = pad_sequences(X_test, maxlen=max_length, truncating=trunc_type, padding=pad_type)","dd1ff68d":"y_test_raw = model.predict(X_test_padded)","c9540266":"y_test_raw","897da657":"y_test = list(map(lambda x : 1 if x > 0.5 else 0, y_test_raw))","1cc5f498":"set(y_test)","5668cfc2":"y_test[:5]","608fe048":"test_df['predict'] = y_test","428f6034":"test_df","9cb4cb37":"test_df[test_df['predict']==1]","db5f976a":"submission = test_df[['id','predict']]","24b85043":"submission","3700d392":"submission.columns = ['id', 'target']","01969c3d":"submission","c7fbca13":"submission.to_csv('.\/sample_submission.csv', index=False)","3cf8d39d":"## Step 6. Model Fit","c965905a":"## Step 8. Reload Model","3379f1e4":"## INDEX\n```\nStep 1. Library Import & Data Load\nStep 2. Data Preprocessing\n     2-a. Drop Columns\n     2-b. Tokenizer\n     2-c. Pad Sequences\n     2-d. Match Data type to numpy.ndarray\nStep 3. Modeling\nStep 4. Model Compile\nStep 5. Callbacks\nStep 6. Model Fit\nStep 7. Model Evaluate & Save\nStep 8. Reload Model\nStep 9. Predict Test Data\n```\n---","7388970e":"# NLP Quick Start for newbie\ud83d\ude01 - with 9 steps","6d644455":"### 2-c. Pad Sequences","f509715e":"## Step 1. Library Import & Data Load","d681ccc5":"## Step 7. Model Evaluate & Save","5453c3c6":"### 2-d. Match Data type to numpy.ndarray","18bddf19":"## Step 4. Model Compile","29fabdd4":"### 2-a. Drop Columns","68ec28ef":"## Step 2. Data Preprocessing","ab4c7907":"## Step 3. Modeling","5cce80a4":"### 2-b. Tokenizer","a7b6fbc2":"## Step 5. Callbacks","60f71331":"## Step 9. Predict Test Data "}}