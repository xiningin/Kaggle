{"cell_type":{"fe43c7cd":"code","aa8561e5":"code","cf0483e7":"code","835ea0cd":"code","9cfca8ba":"code","83b88d0f":"code","cc360b0e":"code","c40613cf":"code","41c98f80":"code","a3b47570":"code","452df425":"code","1f8721f7":"code","2df62046":"code","8e9f6c25":"code","70a6b9b2":"code","4ac76de4":"code","12d022ef":"code","745f0762":"code","d6ecd1e1":"code","786669a8":"code","8a1e87d6":"code","a09016d0":"code","c1482be0":"code","2fac5a4a":"code","351e28c0":"code","56464388":"code","78d947ec":"code","4fc93ccd":"code","a6618331":"code","65500e95":"code","8938dc32":"code","26435d3c":"code","8accbbda":"code","e7f8a8ba":"code","11b22d1a":"code","e73971bd":"code","d0063d3d":"code","4d828723":"code","e9e33648":"code","a3e076aa":"code","761b93df":"code","e42da4e6":"code","ab6b17e9":"code","24b50e03":"code","c4e12f55":"markdown","87470997":"markdown","2e935181":"markdown","977f0a87":"markdown","f19b2947":"markdown","2bef645d":"markdown","3d0f049b":"markdown","7440aa8f":"markdown"},"source":{"fe43c7cd":"from __future__ import division\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.neighbors import KNeighborsClassifier\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nsns.set_style('whitegrid')","aa8561e5":"train = pd.read_csv('..\/input\/titanic\/train.csv')\ntrain.name = 'Train Data'\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ntest.name = 'Test Data'","cf0483e7":"# to play with data I create copies of them\n\ntrain_copy = train.copy(deep=True)\ntrain_copy.name = 'Train Data'\ntest_copy = train.copy(deep=True)\ntest_copy.name = 'Test Data'","835ea0cd":"train.head(6)","9cfca8ba":"# Printing datasets' info\n\nfor data in [train, test]:\n    print('Info of %s \\n' %data.name), \n    print(data.info())\n    print('\\n')\n    \n# In test data one column is missing - 'Survived'\n# It will be the feature which we will want to predict","83b88d0f":"# Describing train data\n\ntrain_copy.describe()","cc360b0e":"data_cleaner = [train, test]","c40613cf":"# Seeing null values in datasets\n\nfor data in data_cleaner:\n    print('Null values in %s'%data.name), \n    print('in every column: \\n')\n    print(data.isnull().sum())\n    print('\\n')","41c98f80":"# Heatmap to see null values - training data\n\nplt.figure(figsize=(10, 6))\n\nsns.heatmap(data=train.isnull(), cmap='plasma', yticklabels=False, cbar=False)\nplt.show()","a3b47570":"# Viewing Age column \n\nplt.figure(figsize=(10, 6))\nplt.title('Age distribution in every class', fontsize=15)\nsns.boxenplot(x='Pclass', y='Age', data=train, palette='GnBu_d')","452df425":"# Removing Cabin, Ticket and PassengerId column\n\ntrain.drop(columns=['Cabin', 'Ticket', 'PassengerId'], axis=1, inplace=True)\ntest.drop(columns=['Cabin', 'Ticket', 'PassengerId'], axis=1, inplace=True)","1f8721f7":"# For Embarked for now I decide to replace NaN values with 'S'\n\ntrain['Embarked'].fillna(value='S', inplace=True)","2df62046":"# For Age column I decide to see age distribution and deicde which mean value assign\n# I have to see how age is connected with Pclass\n\nplt.figure(figsize=(10, 6))\nplt.title('Age distribution', fontsize=15)\nsns.distplot(train['Age'].dropna(), kde=True, bins=40)","8e9f6c25":"# For mean age for every class i want to replace null values with mean age for specific class\n# I am preparing a funcition \n\nclass_mean_age = pd.DataFrame(train.groupby('Pclass')['Age'].mean())\nclass_mean_age","70a6b9b2":"def mean_age(col):\n    age = col[0]\n    pclass = col[1]\n    \n    if pd.isnull(age):\n        if pclass == 1:\n            return 38\n        elif pclass == 2:\n            return 30\n        else:\n            return 25\n    else:\n        return age\n\n    \n# Applying function to Age column to set mean values for missing ones    \ntrain['Age'] = train[['Age', 'Pclass']].apply(mean_age, axis=1)\ntest['Age'] = test[['Age', 'Pclass']].apply(mean_age, axis=1)","4ac76de4":"# For test dataset one values is missing also in Fare column. I decided to replace this value with mean value of Fare which is 32\n\ntest.fillna(value=32, inplace=True)","12d022ef":"train.head(6)","745f0762":"# Visualisation 1 - survived people in each class\n# Result: overwhelmingly more people from third class died in disaster. \n\nplt.figure(figsize=(10, 6))\nplt.title('Number of survived people versus classes', fontsize=15)\nsns.countplot(data=train, x='Pclass', hue='Survived', palette='Blues')\n\n# Number of dead people in every class - i want to sum and print percentage of people\nclass3 = train[(train_copy['Pclass'] == 3) & (train_copy['Survived'] == 0)].count()['Pclass']\nclass2 = train[(train_copy['Pclass'] == 2) & (train_copy['Survived'] == 0)].count()['Pclass']\nclass1 = train[(train_copy['Pclass'] == 1) & (train_copy['Survived'] == 0)].count()['Pclass']\n\nsum_dead = class3+class2+class1\nclass1_dead = round((class1\/sum_dead)*100, 2)\n\nprint('Percentage of people from First Class who died is: %s' %class1_dead),\nprint('%')","d6ecd1e1":"# Visualisation 2 - survived people in exact age\n# Result: as we can see there is blue peak for survived babies and kids.\n# Also there is more older people who survivde (30-60 years) but in age 70-80 year more people died.\n\nplt.figure(figsize=(10, 6))\nplt.title('Survived people vs Age', fontsize=15)\ng = sns.kdeplot(train['Age'][train['Survived']==0], color='red', shade=True)\ng = sns.kdeplot(train['Age'][train['Survived']==1], color='blue', shade=True)\ng.set_xlabel('Age')\ng.set_ylabel('Frequency')\ng.legend(['Not Survived', 'Survived'])","786669a8":"# Visualisation 3 - survived people based on gender\n# Result: in every class more females survived than males. \n\nsns.catplot(data=train, x='Pclass', y='Survived', hue='Sex', palette='GnBu_d', kind='bar')\nplt.title('Distribution of Survival based on Gender', fontsize=15)\nplt.ylabel('Survival Probability')","8a1e87d6":"# Mean values of females and males who survived\n# Result: much more females survived during the disaster\n\ntrain[['Sex', 'Survived']].groupby('Sex').mean()","a09016d0":"# Visualisation 4 - Embarked and survived categorical plot\n# Result: people who embarked in Cherbourg had more chance to survive\n\nplt.figure(figsize=(10, 6))\nplt.title('Survived people with specific place of embarkation', fontsize=15)\nplt.xlabel('Survival probability')\nsns.barplot(data=train, x='Embarked', y='Survived', palette='GnBu_d')","c1482be0":"# Table shows descending survival rate versus place of embark\n\ntrain[['Embarked', 'Survived']].groupby('Embarked').mean().sort_values(by='Survived', ascending=False)","2fac5a4a":"# Visualisation 5 - siblings\/spouses abord\n# Result: one or two sibling\/spuses had more chance to survive\n\nplt.figure(figsize=(10, 6))\nplt.title('Survived vs sibling\/spouses aboard', fontsize=15)\nsns.barplot(data=train, x='SibSp', y='Survived', palette='GnBu_d')","351e28c0":"train_corr = train.corr()\n\nplt.figure(figsize=(10, 6))\nplt.title('Correlations between features', fontsize=15)\nsns.heatmap(train_corr, cmap='Blues', annot=True, linewidths=.5)\n\n# As we can see the biggest correlation is between Survived&Fare, Fare&SibSp and Parch&Fare","56464388":"train.head()","78d947ec":"train.drop('Name', axis=1, inplace=True)","4fc93ccd":"test.drop('Name', axis=1, inplace=True)","a6618331":"train.head()","65500e95":"sex = pd.get_dummies(train['Sex'], drop_first=True)\nembarked = pd.get_dummies(train['Embarked'], drop_first=True)\ntrain = pd.concat([train, sex, embarked], axis=1)","8938dc32":"sex = pd.get_dummies(test['Sex'], drop_first=True)\nembarked = pd.get_dummies(test['Embarked'], drop_first=True)\ntest = pd.concat([test, sex, embarked], axis=1)","26435d3c":"train.drop(['Sex', 'Embarked'], axis=1, inplace=True)\ntest.drop(['Sex', 'Embarked'], axis=1, inplace=True)","8accbbda":"train.rename(columns={'male': 'Sex'}, inplace=True)\ntest.rename(columns={'male': 'Sex'}, inplace=True)","e7f8a8ba":"train.head(6)","11b22d1a":"test.head()","e73971bd":"# Preparing X features and y value to predict for training and test data\n\nX_train = train.drop('Survived', axis=1)\ny_train = train['Survived']\nX_test = test","d0063d3d":"logmodel = LogisticRegression()","4d828723":"logmodel.fit(X_train, y_train)","e9e33648":"y_predictions = logmodel.predict(X_test)","a3e076aa":"# Accuracy = (TP+TN)\/total\n\nacc_matrix = round((133+74)\/268, 2)\nacc_matrix","761b93df":"# Error rate = (FP+FN)\/total\n\nerror_matrix = round((40+21)\/268,2)\nerror_matrix","e42da4e6":"# Printing accuracy\n\naccuracy_log = round(logmodel.score(X_train, y_train) * 100, 2)\naccuracy_log","ab6b17e9":"# Printing correlations\n\ncoef_df = pd.DataFrame(train.columns[1:])\ncoef_df.columns = ['Feature']\ncoef_df\ncoef_df['Correlation'] = pd.Series(logmodel.coef_[0])\ncoef_df.sort_values(by='Correlation', ascending=False)","24b50e03":"knn = KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)\ny_predictions = knn.predict(X_test)\n\naccuracy_knn = round(knn.score(X_train, y_train) * 100, 2)\naccuracy_knn","c4e12f55":"1. Importing Libraries and Packages","87470997":"This notebook contains my very first public machine learning and data science, visualization approach for specific dataset. Titanic dataset is the most popular on Kaggle to deal with so that is why I decided to start my kernels from here. ","2e935181":"4. Data Visualisation","977f0a87":"2. Loading and viewing Dataset","f19b2947":"3. Data cleaning\n\nWe have to see how null values deal with the rest of dataset.\n\n'Cabin' column has to be removed from dataset, because it contains more null values than \nnormal. Also 'Ticket' column is going to be deleted because contains messy values, not connected with this task.\n\nFor 'Age' column we have to see how age in this dataset is distributed and decide what mean values assign. \n\nFor 'Embarked' column I will replace null values with 'S'","2bef645d":"6. Machine Learning - k-Nearest Neighbors","3d0f049b":"For now better accuracy is for KNN method - with my further learning I am going to make another approaches to better predict data. ","7440aa8f":"5. Machine learning - logistic regression\n\nThis dataset consists of typical categorical features which i want to use to build machine learning approach with logistic regression to predict survival. "}}