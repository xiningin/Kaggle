{"cell_type":{"e6ebadf6":"code","cf21b8c1":"code","7669cb5d":"code","f10ac125":"code","59ed6a10":"code","124b0349":"code","2d02234d":"code","4cbc9e82":"code","3ac74e60":"code","86158c41":"code","a17627d3":"code","42e8efc5":"code","207787f6":"code","482e1811":"code","4cc4f1b1":"code","54a56063":"code","ef1d0688":"code","8cfede83":"code","9fa0af95":"code","30c693eb":"code","36e3a066":"code","a8e4d016":"code","fdc79abb":"code","7b0b4518":"code","0ac54afd":"code","4ada6d3f":"code","1afb22fc":"code","decc6891":"code","bf10dfff":"code","65987c84":"code","7baa3038":"code","25a3e86f":"code","6be78217":"code","d82b11c0":"code","b82a8006":"code","990db7cc":"code","ad8cba12":"markdown"},"source":{"e6ebadf6":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport os\nimport random\nimport time\nimport copy\n\nimport torchvision\nimport torch\nimport torch.nn as nn\nfrom torch.autograd import Variable\nimport torch.utils.data\nimport torch.nn.functional as F\nfrom torchvision import datasets, transforms, models\nfrom torch.utils.data import DataLoader, Dataset, TensorDataset\nimport torch.optim as optim\nfrom torch.utils.data.sampler import SubsetRandomSampler, WeightedRandomSampler\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report, confusion_matrix\n\nprint(os.listdir(\"..\/input\"))","cf21b8c1":"use_gpu = torch.cuda.device_count() > 0\nprint(\"{} GPU's available:\".format(torch.cuda.device_count()) )","7669cb5d":"def get_images(path2images, path2labels):\n    \n    df_images = pd.read_csv(path2images, header=None)\n    df_labels = pd.read_csv(path2labels)\n    \n    X = np.vstack(df_images.values)\n    #X = X \/ 255.   # scale pixel values to [0, 1]\n    #X = X.astype(np.float32)\n    X = X.astype(np.uint8)    \n    X = X.reshape(-1, 1, 110, 110) # return each images as 1 x 110 x 110\n    \n    y = df_labels['Volcano?'].values\n    \n    return X, y","f10ac125":"path2trainImages = '..\/input\/volcanoes_train\/train_images.csv'\npath2trainLabels = '..\/input\/volcanoes_train\/train_labels.csv'\n\nX, y = get_images(path2trainImages, path2trainLabels)","59ed6a10":"path2testImages = '..\/input\/volcanoes_test\/test_images.csv'\npath2testLabels = '..\/input\/volcanoes_test\/test_labels.csv'\n\nX_test, y_test = get_images(path2trainImages, path2trainLabels)","124b0349":"print('Train Dataset shape: {} Labels: {}'.format(X.shape, y.shape))\nprint('Test Dataset shape: {} Labels: {}'.format(X_test.shape, y_test.shape))","2d02234d":"print('Is Volcano: {}'.format(np.sum(y==1)))\nprint('Is Not Volcano: {}'.format(np.sum(y==0)))","4cbc9e82":"X_train, X_valid, y_train, y_valid = train_test_split(X,\n                                                    y,\n                                                    test_size=0.33,\n                                                    random_state=42,\n                                                    stratify = y)","3ac74e60":"class VolcanoesDataset(Dataset):\n\n    def __init__(self, X, y, transforms=None):\n        self.transform = transforms    \n        self.X = X\n        self.y = y\n        \n    def __getitem__(self, index):\n        image = self.X[index]\n        label = self.y[index]        \n        \n        image = image.reshape(110, 110, 1)\n\n        if self.transform:\n            image = self.transform(image)\n        return image, label\n\n    def __len__(self):\n        return len(self.X)","86158c41":"class AdjustGamma(object):\n    def __call__(self, img):\n        return transforms.functional.adjust_gamma(img, 0.8, gain=1)","a17627d3":"class AdjustContrast(object):\n    def __call__(self, img):\n        return transforms.functional.adjust_contrast(img, 2)","42e8efc5":"class AdjustBrightness(object):\n    def __call__(self, img):\n        return transforms.functional.adjust_brightness(img, 2)","207787f6":"data_transforms = {\n    'train': transforms.Compose([\n        #CloneArray(),\n        transforms.ToPILImage(), # because the input dtype is numpy.ndarray\n        transforms.RandomHorizontalFlip(),\n        transforms.RandomVerticalFlip(),\n        AdjustGamma(),\n        AdjustContrast(),\n        #AdjustBrightness(),\n        transforms.ToTensor()\n    ]),\n    'valid': transforms.Compose([\n        transforms.ToPILImage(), # because the input dtype is numpy.ndarray\n        transforms.RandomHorizontalFlip(), \n        transforms.RandomVerticalFlip(),\n        AdjustGamma(),\n        AdjustContrast(),\n        transforms.ToTensor(),\n    ]),\n}","482e1811":"dsets = {\n    'train': VolcanoesDataset(X_train, y_train, transforms=data_transforms['train']),\n    'valid': VolcanoesDataset(X_valid, y_valid, transforms=data_transforms['valid']),\n    'test':  VolcanoesDataset(X_test, y_test, transforms=data_transforms['valid']),\n}","4cc4f1b1":"batch_size = 32\nrandom_seed = 3\nvalid_size = 0.2\nshuffle = True","54a56063":"class_sample_count = np.array([len(np.where(y_train==t)[0]) for t in np.unique(y_train)])\nweight = 1. \/ class_sample_count\nsamples_weight = np.array([weight[t] for t in y_train])\n\nsamples_weight = torch.from_numpy(samples_weight)\n\nsampler = {'train':  WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight)),\n          'valid': None,\n          'test': None}","ef1d0688":"def create_dataLoader(dsets, batch_size, sampler={'train': None, 'valid': None,'test': None},\n                      pin_memory=False):\n    dset_loaders = {} \n    for key in dsets.keys():\n        if sampler[key] != None:\n            dset_loaders[key] = DataLoader(dsets[key], batch_size=batch_size, sampler=sampler[key], pin_memory=pin_memory)\n        else:          \n            dset_loaders[key] = DataLoader(dsets[key], batch_size=batch_size, pin_memory=pin_memory, shuffle=False)\n\n    return dset_loaders","8cfede83":"dset_loaders = create_dataLoader(dsets, batch_size, sampler, pin_memory=False)","9fa0af95":"dset_loaders.keys()","30c693eb":"image, label = next(iter(dset_loaders['train']))\nprint(image.size(), label.size())","36e3a066":"def plot_volcanos(dset_loaders, is_train = True, preds_test = [], preds_train = []):\n    \n    X, y = next(iter(dset_loaders))\n    X, y = X.numpy(), y.numpy()\n    \n    plt.figure(figsize=(20,10))\n    for i in range(0, 4):\n        plt.subplot(1,4,i+1)\n        \n        rand_img = random.randrange(0, X.shape[0])\n        img = X[rand_img,:,:,:]\n        \n        #img = np.clip(img, 0, 1.0)\n        plt.imshow(img[0,:,:], cmap = 'gray')\n        plt.title('Volcano: {}'.format(y[rand_img]))\n        plt.axis('off')","a8e4d016":"plot_volcanos(dset_loaders['train'])","fdc79abb":"class Net(nn.Module):\n    def __init__(self, nb_out=2, nb_channels=1):\n        super(Net, self).__init__()\n        self.conv1 = nn.Conv2d(nb_channels, 6, 5)\n        self.pool = nn.MaxPool2d(2, 2)\n        self.conv2 = nn.Conv2d(6, 16, 5)\n\n        self.fc1 = nn.Linear(9216, 32)\n        self.fc2 = nn.Linear(32, 16)\n        self.fc3 = nn.Linear(16, nb_out)\n                \n    def forward(self, x):\n        x = self.pool(F.relu(self.conv1(x)))\n        x = self.pool(F.relu(self.conv2(x)))\n\n        x = x.view(x.size(0), -1)\n        x = F.relu(self.fc1(x))\n        x = F.relu(self.fc2(x))\n        x = self.fc3(x)\n        return x","7b0b4518":"model = Net()","0ac54afd":"print(model)","4ada6d3f":"if use_gpu:\n    print(\"Using all GPU's \")\n    model = torch.nn.DataParallel(model) #device_ids=[1,3]\n    model.cuda()\nelse:\n    print(\"Using CPU's\")","1afb22fc":"def evaluate_model(loader, model, loss_fn, use_gpu = False):\n    \n    total_loss = 0\n    for i, ( inputs, labels) in enumerate(loader):     \n        \n        if use_gpu:\n            inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n        else:\n            inputs, labels = Variable(inputs), Variable(labels)\n                \n        # forward pass\n        outputs = model(inputs)\n        \n        # loss\n        loss = loss_fn(outputs, labels)\n        \n        # metrics\n        total_loss += loss.item()\n            \n    return (total_loss \/ i)","decc6891":"def train(model, train_loader, test_loader ,num_epochs, loss_fn, optimizer, patience  ):\n    \n    loss_train = []\n    loss_test = []\n    best_test_acc =  np.inf\n    \n    patience_count= 0\n    ii_n = len(train_loader)\n    for epoch in range(num_epochs):\n        for i, (inputs, labels) in enumerate(train_loader):\n            print('\\rpredict: {}\/{}'.format(i, ii_n - 1), end='')\n\n            if use_gpu:\n                inputs, labels = Variable(inputs.cuda()), Variable(labels.cuda())\n            else:\n                inputs, labels = Variable(inputs), Variable(labels)\n            predict = model(inputs)\n            \n            loss = loss_fn(predict, labels)\n            optimizer.zero_grad()\n            loss.backward()\n            optimizer.step()\n            \n        loss_train.append(loss.item())\n        loss_test.append( evaluate_model(test_loader, model,loss_fn, use_gpu) )\n        \n        print('\\nEpoch: {}  Loss Train: {}  Lost Test: {}'.format(epoch, loss_train[-1], loss_test[-1]), end='\\n')\n        \n        #Early stopping\n        if(best_test_acc > loss_test[-1]):\n            patience_count = 0\n            best_test_acc = loss_test[-1]\n            best_model = copy.deepcopy(model)\n\n        if(patience_count > patience):\n            break;\n\n        patience_count += 1\n        \n        \n    print('\\rDone!')\n    return loss_train, loss_test, model","bf10dfff":"loss_fn = torch.nn.CrossEntropyLoss()\noptimizer =  optim.RMSprop(model.parameters(), lr=1e-4)\nnum_epochs = 100\npatience = 5","65987c84":"params = {'model' : model, \n        'train_loader':dset_loaders['train'],\n         'test_loader':dset_loaders['valid'],\n         'num_epochs': num_epochs,\n         'loss_fn': loss_fn,\n         'optimizer': optimizer, \n         'patience': patience \n         }","7baa3038":"loss_train, loss_test, model = train(**params)","25a3e86f":"def predict(dset_loaders, model,use_gpu=False):\n    \n    predictions = []\n    labels_lst = []\n\n    ii_n = len(dset_loaders)\n    start_time = time.time()\n\n    for i, (inputs, labels) in enumerate(dset_loaders):\n                   \n        if use_gpu:\n          inputs = inputs.cuda()\n          labels = labels.cuda()\n\n        inputs = Variable(inputs)\n        labels = Variable(labels)\n\n        predictions.append(model(inputs).data)\n        labels_lst.append(labels)\n        \n        print('\\rpredict: {}\/{}'.format(i, ii_n - 1), end='')\n    print(' ok')\n    print('Execution time {0:.2f} s'.format(round(time.time()- start_time), 2))\n    if len(predictions) > 0:\n        return {'pred': torch.cat(predictions, 0), 'true': torch.cat(labels_lst, 0) }","6be78217":"results_fine = {}\ntrue_dict = {}\npred_dict = {}\n\nfor k in dset_loaders.keys(): \n    \n    prediction = predict(dset_loaders[k], model, use_gpu=use_gpu)    \n    \n    _, predicted = torch.max(prediction['pred'], 1)  \n    if use_gpu:\n        true, pred = prediction['true'].cpu(), predicted.cpu()\n    \n    true, pred = true.data.numpy(), pred.numpy()\n    correct = (true == pred).sum()\n    print('{}: {}\/{}'.format(k, correct, len(prediction['pred'])))\n    print('\\n----------------\\n')\n    \n    true_dict[k] = true\n    pred_dict[k] = pred","d82b11c0":"plt.figure(figsize=(20,5))\n\nidx = 1\nfor k in dset_loaders.keys():\n    true, pred = true_dict[k], pred_dict[k]\n    plt.subplot(1,3,idx);\n\n    mc = confusion_matrix(true, pred)\n    plt.imshow(mc\/mc.sum(axis=0), cmap = 'jet');\n    plt.colorbar();\n    plt.axis('off');\n    \n    plt.title(k, fontsize=20)\n    plt.suptitle('Confusion Matrix', fontsize=22)\n    idx+=1","b82a8006":"print(classification_report(pred_dict['valid'], true_dict['valid']))  ","990db7cc":"print(classification_report(pred_dict['test'], true_dict['test']))  ","ad8cba12":"**Evaluate Results**"}}