{"cell_type":{"c21a8267":"code","5472ba8c":"code","2489eae4":"code","02f59bf7":"code","4a7d2af3":"code","d86d97c3":"code","79707c08":"code","b17caa9b":"code","b2eae701":"code","a74b93ee":"code","331bdba3":"code","c8996213":"markdown","ee40cc72":"markdown","707f19ad":"markdown"},"source":{"c21a8267":"import os\nimport glob\nimport numpy as np\nimport re\nimport scipy.io.wavfile\nimport torch\nimport torch.utils.data as data\nimport torchvision.transforms as transforms\nfrom sklearn.preprocessing import LabelEncoder\n\n\nclass TrainDataset(data.Dataset):\n    \"\"\"Pytorch dataset for instruments\n    args:\n        root: root dir containing an audio directory with wav files.\n        transform (callable, optional): A function\/transform that takes in\n                a sample and returns a transformed version.\n        blacklist_patterns: list of string used to blacklist dataset element.\n            If one of the string is present in the audio filename, this sample\n            together with its metadata is removed from the dataset.\n    \"\"\"\n\n    def __init__(self, filenames, transform=None, blacklist_patterns=[]):\n        assert(isinstance(root, str))\n        assert(isinstance(blacklist_patterns, list))\n\n        self.filenames = filenames \n\n        for pattern in blacklist_patterns:\n            self.filenames = self.blacklist(self.filenames, pattern)\n            \n        self.labelEncoder = LabelEncoder() # Encode labels with value between 0 and n_classes-1.\n        self.labelEncoder.fit(np.unique(self._instrumentsFamily(self.filenames)))\n            \n        self.transform = transform\n        \n    def transformInstrumentsFamilyToString(self, targets=[]):\n        return self.labelEncoder.inverse_transform(targets) # Decode values into labels\n                    \n    def _instrumentsFamily(self, filenames):\n        instruments = np.zeros(len(filenames), dtype=object)\n        for i, file_name in enumerate(filenames): # Extract family name from filename\n            no_folders = re.compile('\\\/').split(file_name)[-1]\n            instruments[i] = re.compile('_').split(no_folders)[0]\n        return instruments\n    \n    def blacklist(self, filenames, pattern):\n        return [filename for filename in filenames if pattern not in filename]\n\n    def __len__(self):\n        return len(self.filenames)\n\n    def __getitem__(self, index):\n        name = self.filenames[index]\n        _, sample = scipy.io.wavfile.read(name) # load audio\n        \n        target = self._instrumentsFamily([name])\n        categorical_target = self.labelEncoder.transform(target)[0]\n                \n        if self.transform is not None:\n            sample = self.transform(sample)\n        return [sample, categorical_target]","5472ba8c":"from customdatasets import TestDataset","2489eae4":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.optim as optim\nfrom torchvision import datasets, transforms\nfrom types import SimpleNamespace\nimport matplotlib.pyplot as plt\nimport csv\nimport librosa\nimport scipy as sc","02f59bf7":"# Hyperparameters\nargs = SimpleNamespace(batch_size=64, test_batch_size=64, epochs=10,\n                       lr=0.01, momentum=0.5, seed=1, log_interval=2000)\ntorch.manual_seed(args.seed)\nuse_cuda = torch.cuda.is_available()\ndevice = torch.device('cuda' if use_cuda else 'cpu')","4a7d2af3":"import numpy as np\n\ntoFloat = transforms.Lambda(lambda x: x \/ np.iinfo(np.int16).max)\n\nroot = \"..\/input\/oeawai\/train\/kaggle-train\"\nfilenames = glob.glob(os.path.join(root, \"audio\/*.wav\"))\nnp.random.shuffle(filenames)\n\ntrainDataset = TrainDataset(filenames[:int(len(filenames)*0.95)], transform=toFloat)\nprint(len(trainDataset))\nvalidDataset = TrainDataset(filenames[int(len(filenames)*0.95):], transform=toFloat)\nprint(len(validDataset))\n\ntestDataset = TestDataset(\"..\/input\/oeawai\/kaggle-test\/kaggle-test\", transform=toFloat)\nprint(len(testDataset))\n\ntrain_loader = torch.utils.data.DataLoader(trainDataset,\n    batch_size=args.batch_size, shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(validDataset,\n    batch_size=args.batch_size, shuffle=True)\ntest_loader = torch.utils.data.DataLoader(testDataset,\n        batch_size=args.test_batch_size, shuffle=False) #Shuffle should be false!","d86d97c3":"def logMagStft(numpyArray, sample_rate, n_fft):\n    f, t, sx = sc.signal.stft(numpyArray, fs=sample_rate, nperseg=n_fft, noverlap=n_fft\/\/2) \n    return np.log(np.abs(sx)+np.e**-10)\n\ndef computeMelspectrogram(numpyArray, sample_rate,  n_fft):\n    S = librosa.feature.melspectrogram(y=numpyArray, sr=sample_rate, n_mels=256, fmax=8000, n_fft=n_fft, hop_length=n_fft\/\/2)\n    return np.log(S+1e-4)\n\nsample_rate = 16000\nnumber_of_examples_to_plot = 5\nn_fft = 510\nspectrograms = np.zeros((number_of_examples_to_plot, n_fft\/\/2+1, int(2*64000\/n_fft)+1))\nfor samples, instrumentsFamily in train_loader:\n    for index in range(number_of_examples_to_plot):\n        spectrograms[index] = computeMelspectrogram(samples[index].numpy(), sample_rate, n_fft)\n    family = trainDataset.transformInstrumentsFamilyToString(instrumentsFamily.numpy().astype(int))\n    break # SVM is only fitted to a fixed size of data\n\nimport matplotlib.pyplot as plt\n    \nfor i in range(number_of_examples_to_plot):\n    print(spectrograms[i].shape)\n    plt.imshow(spectrograms[i])\n    print(family[i])\n    plt.colorbar()\n    plt.show()","79707c08":"# CNN resnet architecture\nclass BasicBlock(nn.Module):\n    expansion = 1\n\n    def __init__(self, in_planes, planes, stride=1):\n        super(BasicBlock, self).__init__()\n        self.conv1 = nn.Conv2d(in_planes, planes, kernel_size=3, stride=stride, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(planes)\n        self.conv2 = nn.Conv2d(planes, planes, kernel_size=3, stride=1, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(planes)\n\n        self.shortcut = nn.Sequential()\n        if stride != 1 or in_planes != self.expansion*planes:\n            self.shortcut = nn.Sequential(\n                nn.Conv2d(in_planes, self.expansion*planes, kernel_size=1, stride=stride, bias=False),\n                nn.BatchNorm2d(self.expansion*planes)\n            )\n\n    def forward(self, x):\n        out = F.relu(self.bn1(self.conv1(x)))\n        out = self.bn2(self.conv2(out))\n        out += self.shortcut(x)\n        out = F.relu(out)\n        return out\n\nclass ResNet(nn.Module):\n    def __init__(self, block, num_blocks, num_classes=10):\n        super(ResNet, self).__init__()\n        self.in_planes = 64\n\n        self.conv1 = nn.Conv2d(1, 32, kernel_size=5, stride=2, padding=1, bias=False)\n        self.bn1 = nn.BatchNorm2d(32)\n        self.conv2 = nn.Conv2d(32, 64, kernel_size=5, stride=2, padding=1, bias=False)\n        self.bn2 = nn.BatchNorm2d(64)\n        \n        self.layer1 = self._make_layer(block, 64, num_blocks[0], stride=1)\n        self.layer2 = self._make_layer(block, 128, num_blocks[1], stride=2)\n        self.layer3 = self._make_layer(block, 256, num_blocks[2], stride=2)\n        self.layer4 = self._make_layer(block, 512, num_blocks[3], stride=2)\n        self.linear = nn.Linear(512*block.expansion, num_classes)\n\n    def _make_layer(self, block, planes, num_blocks, stride):\n        strides = [stride] + [1]*(num_blocks-1)\n        layers = []\n        for stride in strides:\n            layers.append(block(self.in_planes, planes, stride))\n            self.in_planes = planes * block.expansion\n        return nn.Sequential(*layers)\n\n    def forward(self, x):\n        n_fft = 510\n    \n        spectrograms = np.zeros((len(x), n_fft\/\/2+1, int(2*64000\/n_fft)+1))\n        for index, audio in enumerate(x.cpu().numpy()):\n            spectrograms[index] = computeMelspectrogram(audio, 16000, n_fft)\n        \n        x = torch.from_numpy(spectrograms[:, np.newaxis, :, :]).to(device).float()\n\n        \n        out = F.relu(self.bn1(self.conv1(x)))\n        out = F.max_pool2d(out, 2, 1)\n        out = F.relu(self.bn2(self.conv2(out)))\n        out = F.max_pool2d(out, 2, 2)\n\n        out = self.layer1(out)\n        out = self.layer2(out)\n        out = self.layer3(out)\n        out = self.layer4(out)\n        out = F.avg_pool2d(out, 4)\n        out = out.view(out.size(0), -1)\n        out = self.linear(out)\n        return F.log_softmax(out, dim=1)\n    \ndef ResNet18():\n    return ResNet(BasicBlock, [2,2,2,2])\n\ndef ResNet34():\n    return ResNet(BasicBlock, [3,4,6,3])\n\ndef ResNet50():\n    return ResNet(Bottleneck, [3,4,6,3])\n\ndef ResNet101():\n    return ResNet(Bottleneck, [3,4,23,3])\n\ndef ResNet152():\n    return ResNet(Bottleneck, [3,8,36,3])","b17caa9b":"def train(args, model, device, train_loader, optimizer, epoch):\n    model.train()\n    for batch_idx, (data, target) in enumerate(train_loader):\n        data, target = data.to(device), target.to(device)\n        \n        optimizer.zero_grad()\n        output = model(data)\n        loss = F.nll_loss(output, target)\n        loss.backward()\n        optimizer.step()\n        if batch_idx % args.log_interval == 0:\n            print('Train Epoch: {} [{}\/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n                epoch, batch_idx * len(data), len(train_loader.dataset),\n                100. * batch_idx \/ len(train_loader), loss.item()))\n            with torch.no_grad():\n                print('F1 score: ' + str(sklearn.metrics.f1_score(target.cpu().numpy(), output.max(1)[1].cpu().numpy(), average='macro')))","b2eae701":"# This function trains the model for one epoch\nimport sklearn\ndef valid(args, model, device, test_loader):\n    model.eval()\n    \n    test_loss = 0\n    f1_loss = []\n    correct = 0\n    with torch.no_grad():\n        for data, target in test_loader:\n            data, target = data.to(device), target.to(device)\n            output = model(data)\n            test_loss += F.nll_loss(output, target, reduction='sum').item() # sum up batch loss\n            pred = output.max(1, keepdim=True)[1] # get the index of the max log-probability\n            correct += pred.eq(target.view_as(pred)).sum().item()\n            f1_loss.append(sklearn.metrics.f1_score(target.cpu().numpy(), pred.cpu().numpy(), average='macro')) \n    test_loss \/= len(test_loader.dataset)\n    f1_loss = np.mean(f1_loss)\n\n    print('\\nTest set: Average loss: {:.4f}, Accuracy: {}\/{} ({:.2f}%)\\n'.format(\n        test_loss, correct, len(test_loader.dataset),\n        100. * correct \/ len(test_loader.dataset)))\n    print(\"F1 valid loss: \" + str(f1_loss))\n","a74b93ee":"# This function evaluates the model on the test data\ndef test(args, model, device, test_loader, epoch):\n    model.eval()\n    test_loss = 0\n    correct = 0\n    with torch.no_grad():\n        familyPredictions = np.zeros(len(test_loader.dataset), dtype=np.int)\n        for index, samples in enumerate(test_loader):\n            samples = samples.to(device)\n            familyPredictions[index*len(samples):(index+1)*len(samples)] = model(samples).max(1)[1].cpu() # get the index of the max log-probability\n    \n    familyPredictionStrings = trainDataset.transformInstrumentsFamilyToString(familyPredictions.astype(int))\n\n    with open('NN-submission-' +str(epoch)+'.csv', 'w', newline='') as writeFile:\n        fieldnames = ['Id', 'Predicted']\n        writer = csv.DictWriter(writeFile, fieldnames=fieldnames, delimiter=',',\n                                quotechar='|', quoting=csv.QUOTE_MINIMAL)\n        writer.writeheader()\n        for index in range(len(testDataset)):\n            writer.writerow({'Id': index, 'Predicted': familyPredictionStrings[index]})\n    print('saved predictions')","331bdba3":"# Main\ntorch.cuda.empty_cache()\nmodel = ResNet18().to(device)\noptimizer = optim.SGD(model.parameters(), lr=args.lr, \n                      momentum=args.momentum)\n\nfor epoch in range(1, args.epochs + 1):\n    train(args, model, device, train_loader, optimizer, epoch) \n    valid(args, model, device, valid_loader)\n    test(args, model, device, test_loader, epoch)\n","c8996213":"# Data preprocessing\n\nLet's define a way to transform the time-domain audio signals into time-frequency domain. It is always a good idea to plot the data to make sure the preprocessing is doing what we want it to do. ","ee40cc72":"# Example CNN solution for the challenge\n\nFor this example, I started the CNN example notebook provided on the [summer's school github](https:\/\/github.com\/WolfgangWaltenberger\/oeawai\/blob\/master\/CNN\/CNN_example.ipynb), and adapted it to our challenge. It doesn't perform great, but it should be a good starting point for anyone wanting to tackle the challenge with a CNN.\n\nThis time we will need to use kaggle's GPU. On the right under settings you can turn the GPU on. ","707f19ad":"# Net\n\nIn this class, you can modify the network's structure to try to improve the performance. "}}