{"cell_type":{"2e564b0d":"code","9eb8c589":"code","40894814":"code","fe0760c4":"code","de9a700b":"code","4a865c02":"code","dde65458":"code","5c32911f":"code","ff3312ea":"code","30ec6132":"code","ad1ddfa4":"code","7d6a0a8e":"code","a2b3a8dc":"code","4b73b5d4":"code","125e59e7":"code","abf8fb83":"code","7d331cc2":"code","3e5348be":"code","09f4cbf9":"markdown","0290f734":"markdown","c9b5716c":"markdown","730393d4":"markdown","c9926daa":"markdown","8e9d9dcf":"markdown","d4a30a9b":"markdown","48b550bc":"markdown","e78f9570":"markdown","e2570d0d":"markdown","94be6a9a":"markdown","45dda3aa":"markdown","2656263d":"markdown","d685360c":"markdown","e0d9ce3b":"markdown","c8fbee4a":"markdown"},"source":{"2e564b0d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport cv2\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9eb8c589":"PATH = '\/kaggle\/input\/thin-content-web-page-data\/visuals of predicted errors\/'\nsuffix = 'screenshots.png'","40894814":"list_contentimg = []\nfor i in range(145):\n    img = cv2.imread(PATH+str(i)+suffix)\n    list_contentimg.append(img)","fe0760c4":"img.shape","de9a700b":"image_data = pd.DataFrame()\nimage_data['index'] = [i for i in range(145)]\nimage_data['images'] = list_contentimg","4a865c02":"#for the preprocessing purpose\nfrom keras.preprocessing.image import load_img\nfrom keras.preprocessing.image import img_to_array\nfrom keras.applications.vgg16 import preprocess_input\n\n#for the models\nfrom keras.applications.vgg16 import VGG16\nfrom keras.models import Model\n\n#for clustering and dimension reduction\nfrom sklearn.cluster import KMeans\nfrom sklearn.decomposition import PCA\n\nimport os\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom random import randint\nimport pandas as pd\nimport pickle","dde65458":"list_img_path = []\nfor i in range(146):\n    list_img_path.append(PATH+str(i)+suffix)","5c32911f":"model = VGG16()\nmodel = Model(inputs = model.inputs, outputs = model.layers[-2].output)","ff3312ea":"def feature_extraction(image_path,shape_input,model):\n    #load the image with shape_input shape\n    img = load_img(image_path,target_size = shape_input)\n    #convert from PIL.Image.Image to numpy array\n    img = np.array(img)\n    reshaped_img = img.reshape(1,224,224,3)\n    #preprocess image to put into model object\n    imgx = preprocess_input(reshaped_img)\n    #get features\n    feature = model.predict(imgx,use_multiprocessing = True)\n    return feature","30ec6132":"data = {}\nfor i in range(145):\n    if i == 131:\n        continue\n    data[i] = feature_extraction(image_path = list_img_path[i],\n                                 shape_input = (224,224),\n                                 model = model)","ad1ddfa4":"feature_set = np.array(list(data.values()))\nprint(feature_set.shape)\n#reshaping it to 2 dimension\nfeature_set = feature_set.reshape(-1,4096)\n#check the changed shape\nprint(feature_set.shape)","7d6a0a8e":"pca = PCA(n_components = 128,random_state = 22)\nx = pca.fit_transform(feature_set)\nprint(sum(pca.explained_variance_ratio_))","a2b3a8dc":"cluster_numbers = [i for i in range(3,20)]\ncluster_inertias = []\ncluster_labels = []\nfor cluster in cluster_numbers:\n    kmeans = KMeans(n_clusters = cluster,random_state = cluster*5)\n    kmeans.fit(x)\n    cluster_inertias.append(kmeans.inertia_)\n    cluster_labels.append(kmeans.labels_)","4b73b5d4":"plt.plot(cluster_numbers,cluster_inertias)","125e59e7":"final_labels = cluster_labels[9]\nprint(final_labels)","abf8fb83":"groups = {}\nfor i in range(144):\n    if final_labels[i] not in groups.keys():\n        groups[final_labels[i]] = [i]\n    else:\n        groups[final_labels[i]].append(i)","7d331cc2":"groups","3e5348be":"for key in groups.keys():\n    print(\"We are visualizing this label:\",groups[key])\n    labels = groups[key]\n    for label in labels:\n        if label==131:\n            continue\n        fig  = plt.figure()\n        fig.suptitle(str(key), fontsize=14, fontweight='bold')\n        plt.imshow(list_contentimg[label])","09f4cbf9":"So this ends our clustering exercise. It looks like most clusters are based on color variation across the webpages i.e. how the colors are distributed across the webpage and the webpage textures. A more detailed data will probably be able to distinguish between such different varieties well. Anyway, that's all! If you liked the work share the notebook and if you have more ideas on it; feel free to copy and edit!","0290f734":"## custom feature generation function:","c9b5716c":"Here we will give shape_input to (224,224) as that is the default input shape to VGG16.","730393d4":"You can see that we actually didn't lose any information as the explained_variance_ratio i.e. how much variance from original data we have explained in the 128 components in the pca, is 99.6%","c9926daa":"Now, as we don't know how much clusters are there, we will create multiple cluster with different number of clusters and check which one is best.<br\/>\n(1) This is a good article on how [clusterings can be evaluated](https:\/\/medium.com\/@ODSC\/assessment-metrics-for-clustering-algorithms-4a902e00d92d).<br\/>\n(2) We will use the inertia_ which is nothing but Sum of squared distance of each entry to their assigned clusters. As we will increase n_component number, we will plot that and choose the best number of pca component from that. Read inertia_'s definition in [sklearn documentation](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.cluster.KMeans.html).","8e9d9dcf":"## Analyzing thin content webpage data\nWe call webpages with less number of text contents as thin content. In this dataset, we have 146 screenshots of such thin content webpages. In this notebook, we are going to pre-process the images, analyze the webpage images using different pre-trained neural network models and then analyze similarity and different features of such webpages.<br\/>\n\nAs I will be referring to multiple articles for working with pre-processing and using pre-trained models for clustering, here are the articles I am referring:<br\/>\n(1) [geeksforgeeks image reading article](https:\/\/www.geeksforgeeks.org\/reading-images-in-python\/)<br\/>\n(2) [towardsdatascience image clustering with pre-trained NN models](https:\/\/towardsdatascience.com\/how-to-cluster-images-based-on-visual-similarity-cd6e7209fe34)<br\/>","d4a30a9b":"Clearly, after 12, there is a decrease in the incremental addition of components. So we will go with 12 clusters only. Let's now visualize the different clusters and see if they are originally similar.","48b550bc":"## visualization of clusters\nLet's see the plots of the different clusters","e78f9570":"So now feature_set is reshaped from (145,1,4096) to (145,4096). Now we will perform dimension reduction on this data to ease the clustering procedure.","e2570d0d":"## Model preparation:\nTo get feature from vgg16 model, we have to take output before the softmax dense layer. We will peel off the last 2 layers and take output from there. In the following block we will change the model object to do that.","94be6a9a":"Now, data is a dictionary with each image's features of 4096 length which came out from the vgg16 model. We will first arrange it into one compact numpy array and then move on with dimension reduction and clustering.","45dda3aa":"Now, let's create groups of labels.","2656263d":"## Dimension Reduction\nWe will reduce 4096 dimension to a low 128 vectors, to compactify the vectors, as well as to not complicate the clustering operation.\nWe already have imported pca in the imports. Now we will create pca object and transform using that. You can read more about [pca here.](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.decomposition.PCA.html)","d685360c":"Now what we will do is we will create a function which takes an image path, does all the pre-processing and finally processes it through vgg16 to get feature vector created.","e0d9ce3b":"### Thank you!","c8fbee4a":"Here we used cv2 to read the images and stored them in a pandas dataframe with corresponding indices. Now, we will do the same process again; but with keras."}}