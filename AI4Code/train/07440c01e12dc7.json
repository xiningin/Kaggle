{"cell_type":{"36fb65ed":"code","ea842965":"code","639bb056":"code","e883efd7":"code","7399362e":"code","ac5119c3":"code","6a6408fd":"code","79ff53f0":"code","802c1c1c":"code","a5a64eaa":"code","5e4781ca":"code","ffa51005":"code","214ed420":"code","ab9a37fc":"code","394c3b61":"code","68b0a42b":"code","69c5bc3c":"code","eddb0af0":"code","004a1d4a":"code","5cc0c919":"code","5e2bc463":"code","9d94d63f":"code","032f36c2":"code","0d09bb28":"code","a63b1e1b":"code","dc31a9bb":"code","388004bd":"code","0a9341a8":"code","91d07152":"code","82945fe1":"code","afe2015e":"code","ec034ca0":"code","6ffd497e":"code","1ead9b57":"code","dbf361f3":"code","e762b4dd":"code","193aae7c":"code","91144e07":"code","d0067f1c":"code","b6efa13d":"code","39cbf74d":"code","73dae602":"markdown"},"source":{"36fb65ed":"import pandas as pd\nimport numpy as np","ea842965":"df = pd.read_csv('..\/input\/facial-expression-recognitionferchallenge\/fer2013\/fer2013\/fer2013.csv')\nprint(df.shape)\nprint(type(df))","639bb056":"df.head()","e883efd7":"df.emotion.unique()\n","7399362e":"emotion_label_to_text = {0:'anger', 1:'disgust',2:'fear', 3:'happiness',4:'sadness',5:'surprice',6:'neural'}","ac5119c3":"df.emotion.value_counts()","6a6408fd":"import scikitplot\nimport seaborn as sns\nfrom matplotlib import pyplot","79ff53f0":"sns.countplot(df.emotion)\npyplot.show()","802c1c1c":"df.pixels[0].split(' ')","a5a64eaa":"len(df.pixels[0].split(' '))","5e4781ca":"import math\nmath.sqrt(len(df.pixels[0].split(' ')))\n","ffa51005":"df[df.emotion==1].pixels","214ed420":"fig = pyplot.figure(1,(14,14))\nk=0\n\nfor label in sorted(df.emotion.unique()):\n    for j in range(7):\n        px = df[df.emotion==label].pixels.iloc[k]   #Image of a single photo of a specific emotion\n        px = np.array(px.split(' ')).reshape(48,48).astype('float32') #Converting into nupy array,spllition numbers by comma(,), Then converting it into float32 dtype which is required in cnn\n        \n        k = k+1\n        \n        ax = pyplot.subplot(7,7,k)\n        ax.imshow(px,cmap='gray')\n        ax.set_xticks([]) #Remove scale from x axis\n        ax.set_yticks([]) #Remove scale from y axis\n        ax.set_title(emotion_label_to_text[label]) #To give title of emotion in every photo","ab9a37fc":"INTERESTED_LABELS = [3, 4, 6] #As they have the hightest number of phtos\n# 3 = happiness\n# 4 = sadness\n# 6 = neural","394c3b61":"df = df[df.emotion.isin(INTERESTED_LABELS)]  #To take the data for interested labels\ndf.shape","68b0a42b":"img_array = df.pixels.apply(lambda x: np.array(x.split(' ')).reshape(48,48,1).astype('float32'))\nimg_array = np.stack(img_array, axis = 0)","69c5bc3c":"img_array.shape","eddb0af0":"df.emotion","004a1d4a":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\nimg_labels = le.fit_transform(df.emotion)\nimg_labels","5cc0c919":"from keras.utils import np_utils\nimg_labels = np_utils.to_categorical(img_labels)\nimg_labels.shape","5e2bc463":"le.classes_","9d94d63f":" le.transform(le.classes_)","032f36c2":" dict(zip(le.classes_, le.transform(le.classes_)))","0d09bb28":"le_name_mapping = dict(zip(le.classes_, le.transform(le.classes_)))\nprint(le_name_mapping)\n","a63b1e1b":"from sklearn.model_selection import train_test_split\n\nX_train,X_test,y_train,y_test = train_test_split(img_array,img_labels,test_size = 0.1, random_state = 42,shuffle = True)","dc31a9bb":"print(X_train.shape)\nprint(y_train.shape)","388004bd":"img_width = X_train.shape[1]\nimg_height = X_train.shape[2]\nimg_depth = X_train.shape[3]\nnum_classes = y_train.shape[1]","0a9341a8":"X_train = X_train \/ 255.\nX_test = X_test \/ 255.","91d07152":"import tensorflow as tf\nfrom tensorflow.keras import optimizers\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras.layers import Input, Flatten, Dense, Conv2D, MaxPooling2D, Concatenate\nfrom tensorflow.keras.layers import Dropout, BatchNormalization\nfrom tensorflow.keras.callbacks import Callback, EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential","82945fe1":"def build_net(optim):\n    net = Sequential(name='DCNN')\n\n    net.add(\n        Conv2D(\n            filters=64,\n            kernel_size=(5,5),\n            input_shape=(img_width, img_height, img_depth),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_1'))\n    net.add(\n        Conv2D(\n            filters=64,\n            kernel_size=(5,5),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_2'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_2'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_1'))\n    net.add(Dropout(0.4, name='dropout_1'))\n\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_3'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_3'))\n    net.add(\n        Conv2D(\n            filters=128,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_4'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_4'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_2'))\n    net.add(Dropout(0.4, name='dropout_2'))\n\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_5'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_5'))\n    net.add(\n        Conv2D(\n            filters=256,\n            kernel_size=(3,3),\n            activation='elu',\n            padding='same',\n            kernel_initializer='he_normal',\n            name='conv2d_6'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_6'))\n    \n    net.add(MaxPooling2D(pool_size=(2,2), name='maxpool2d_3'))\n    net.add(Dropout(0.5, name='dropout_3'))\n\n    net.add(Flatten(name='flatten'))\n        \n    net.add(\n        Dense(\n            128,\n            activation='elu',\n            kernel_initializer='he_normal',\n            name='dense_1'\n        )\n    )\n    net.add(BatchNormalization(name='batchnorm_7'))\n    \n    net.add(Dropout(0.6, name='dropout_4'))\n    \n    net.add(\n        Dense(\n            num_classes,\n            activation='softmax',\n            name='out_layer'\n        )\n    )\n    \n    net.compile(\n        loss='categorical_crossentropy',\n        optimizer=optim,\n        metrics=['accuracy']\n    )\n    \n    net.summary()\n    \n    return net\n","afe2015e":"\nearly_stopping = EarlyStopping(\n    monitor='val_accuracy',\n    min_delta=0.00005,\n    patience=11,\n    verbose=1,\n    restore_best_weights=True,\n)\n\nlr_scheduler = ReduceLROnPlateau(\n    monitor='val_accuracy',\n    factor=0.5,\n    patience=7,\n    min_lr=1e-7,\n    verbose=1,\n)\n\ncallbacks = [\n    early_stopping,\n    lr_scheduler,\n]","ec034ca0":"train_datagen = ImageDataGenerator(\n    rotation_range=15,\n    width_shift_range=0.15,\n    height_shift_range=0.15,\n    shear_range=0.15,\n    zoom_range=0.15,\n    horizontal_flip=True,\n)\ntrain_datagen.fit(X_train)","6ffd497e":"batch_size = 32 \nepochs = 10\noptims = [\n    optimizers.Nadam(learning_rate=0.001, beta_1=0.9, beta_2=0.999, epsilon=1e-07, name='Nadam'),\n    optimizers.Adam(0.001),\n]","1ead9b57":"model = build_net(optims[1]) ","dbf361f3":"history = model.fit_generator(\n    train_datagen.flow(X_train, y_train, batch_size=batch_size),\n    validation_data=(X_test, y_test),\n    steps_per_epoch=len(X_train) \/ batch_size,\n    epochs=epochs,\n    callbacks=callbacks,\n    use_multiprocessing=True\n)","e762b4dd":"model_yaml = model.to_yaml()\nwith open(\"model.yaml\", \"w\") as yaml_file:\n    yaml_file.write(model_yaml)\n    \nmodel.save(\"model.h5\")","193aae7c":"sns.set()\nfig = pyplot.figure(0, (12, 4))\n\nax = pyplot.subplot(1, 2, 1)\nsns.lineplot(history.epoch, history.history['accuracy'], label='train')\nsns.lineplot(history.epoch, history.history['val_accuracy'], label='valid')\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.lineplot(history.epoch, history.history['loss'], label='train')\nsns.lineplot(history.epoch, history.history['val_loss'], label='valid')\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('epoch_history_dcnn.png')\npyplot.show()","91144e07":"df_accu = pd.DataFrame({'train': history.history['accuracy'], 'valid': history.history['val_accuracy']})\ndf_loss = pd.DataFrame({'train': history.history['loss'], 'valid': history.history['val_loss']})\n\nfig = pyplot.figure(0, (14, 4))\nax = pyplot.subplot(1, 2, 1)\nsns.violinplot(x=\"variable\", y=\"value\", data=pd.melt(df_accu), showfliers=False)\npyplot.title('Accuracy')\npyplot.tight_layout()\n\nax = pyplot.subplot(1, 2, 2)\nsns.violinplot(x=\"variable\", y=\"value\", data=pd.melt(df_loss), showfliers=False)\npyplot.title('Loss')\npyplot.tight_layout()\n\npyplot.savefig('performance_dist.png')\npyplot.show()","d0067f1c":"from sklearn.metrics import classification_report\n\nyhat_valid = model.predict_classes(X_test)\nscikitplot.metrics.plot_confusion_matrix(np.argmax(y_test, axis=1), yhat_valid, figsize=(7,7))\npyplot.savefig(\"confusion_matrix_dcnn.png\")\n\nprint(f'total wrong validation predictions: {np.sum(np.argmax(y_test, axis=1) != yhat_valid)}\\n\\n')\nprint(classification_report(np.argmax(y_test, axis=1), yhat_valid))","b6efa13d":"mapper = {\n    0: \"happy\",\n    1: \"sad\",\n    2: \"neutral\",\n}","39cbf74d":"np.random.seed(2)\nrandom_sad_imgs = np.random.choice(np.where(y_test[:, 1]==1)[0], size=9)\nrandom_neutral_imgs = np.random.choice(np.where(y_test[:, 2]==1)[0], size=9)\n\nfig = pyplot.figure(1, (18, 4))\n\nfor i, (sadidx, neuidx) in enumerate(zip(random_sad_imgs, random_neutral_imgs)):\n        ax = pyplot.subplot(2, 9, i+1)\n        sample_img = X_test[sadidx,:,:,0]\n        ax.imshow(sample_img, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"true:sad, pred:{mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n\n        ax = pyplot.subplot(2, 9, i+10)\n        sample_img = X_test[neuidx,:,:,0]\n        ax.imshow(sample_img, cmap='gray')\n        ax.set_xticks([])\n        ax.set_yticks([])\n        ax.set_title(f\"t:neut, p:{mapper[model.predict_classes(sample_img.reshape(1,48,48,1))[0]]}\")\n\n        pyplot.tight_layout()","73dae602":"Let's make tha data compatible for cnn"}}