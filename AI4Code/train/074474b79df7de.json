{"cell_type":{"e98e0d51":"code","543dac05":"code","2e3dced0":"code","61fa4ad3":"code","453aea27":"code","5a538301":"code","5a7efde2":"code","37a07084":"code","024e5a75":"code","52fcbe97":"code","1090d45d":"code","dc6b0d6e":"code","f0501979":"code","fb314a5d":"code","1338a64e":"code","80336f93":"code","4efc7188":"code","adbbdd4c":"code","256e51e4":"code","1fc502fa":"code","9aba598f":"code","fd46aa68":"code","f88ad4d1":"code","b00395d5":"code","1e8279bd":"code","8c9b5fb4":"code","112b7e29":"code","6fc7ec9b":"code","1e6017ff":"code","27e57050":"code","b4f45104":"code","8b68d2cc":"code","44ffd21f":"markdown","258ac2ae":"markdown","34c7579b":"markdown","e77a2fef":"markdown","0ce9ab1b":"markdown","0f30beed":"markdown","b92bbdf0":"markdown","e5561460":"markdown","07b955e7":"markdown"},"source":{"e98e0d51":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt #for visualization\nimport seaborn as sns #for visualization\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","543dac05":"data = pd.read_csv(\"..\/input\/countries of the world.csv\")  #reading csv with pandas","2e3dced0":"data.info() #column's name,type,count and row's count","61fa4ad3":"#shape gives number of rows and columns\ndata.shape","453aea27":"data.head() #it shows first 5 row or you can show 10 rows head(10) etc..","5a538301":"# some columns's names have gap, brackets, dot etc.. we have to change them for use them in some methods.\ndata.columns","5a7efde2":"data.rename(columns={\"Area (sq. mi.)\": \"Area\", \"Pop. Density (per sq. mi.)\":\"Pop_Density\",\n                        \"Coastline (coast\/area ratio)\":\"Coastline\",\"Net migration\":\"Net_migration\",\n                        \"Infant mortality (per 1000 births)\":\"Infant_mortality\",\"GDP ($ per capita)\":\"GPD\",\n                        \"Literacy (%)\":\"Literacy\",\"Phones (per 1000)\":\"Phone_using\",\"Arable (%)\":\"Arable\",\n                        \"Crops (%)\":\"Crops\",\"Other (%)\":\"Other\"},inplace = True)\n#We are using inplace=True to change column names in place.\ndata.columns","37a07084":"# as we can see many columns' entry is  number but they include \",\"(comma) so pandas describe them object\n# so we replace \",\"(comma) to \".\"(dot) then change their types float with \"astype\"\ndata.dtypes ","024e5a75":"data.Literacy = data.Literacy.str.replace(\",\",\".\").astype(float)\ndata.Pop_Density = data.Pop_Density.str.replace(\",\",\".\").astype(float)\ndata.Coastline = data.Coastline.str.replace(\",\",\".\").astype(float)\ndata.Net_migration = data.Net_migration.str.replace(\",\",\".\").astype(float)\ndata.Infant_mortality = data.Infant_mortality.str.replace(\",\",\".\").astype(float)\ndata.Phone_using = data.Phone_using.str.replace(\",\",\".\").astype(float)\ndata.Arable = data.Arable.str.replace(\",\",\".\").astype(float)\ndata.Crops = data.Crops.str.replace(\",\",\".\").astype(float)\ndata.Birthrate = data.Birthrate.str.replace(\",\",\".\").astype(float)\ndata.Deathrate = data.Deathrate.str.replace(\",\",\".\").astype(float)\ndata.Agriculture = data.Agriculture.str.replace(\",\",\".\").astype(float)\ndata.Industry = data.Industry.str.replace(\",\",\".\").astype(float)\ndata.Service = data.Service.str.replace(\",\",\".\").astype(float)\ndata.Other = data.Other.str.replace(\",\",\".\").astype(float)\ndata.Climate = data.Climate.str.replace(\",\",\".\").astype(float)","52fcbe97":"#checking \ndata.dtypes","1090d45d":"data.describe() #only numeric feature (float,int)","dc6b0d6e":"#boxplot = visualize basic statistics (outliers,max,min)\n\n#first black line at top  is max\n#first blue line at top is  Q3 \n#green line is median \n#second blue line at bottom is Q1\n#second black line at bottom is min\n#circle at bottom is lower fence\n#upper fence\n\ndata.boxplot(column = \"Literacy\")","f0501979":"d1 = data.head(10)\n\n#d1.loc[:,\"Area\":\"GPD\"] #first select is row \":\" for all row , second is column\n#d1.loc[:,[\"Area\",\"GPD\"]]\n#d1.loc[:2,:]\n#d1.loc[::-1,\"Area\"]\n#d1.loc[::-1,[\"Area\"]]\n#d1.iloc[:,:2] #when we use iloc (integer-location) \u0131f we select 1. column we have to write 2\n#d1.iloc[1:4,2:5]\n","fb314a5d":"d1 = data.head(3)\nd2 = data.tail(3)\n# axis = 0 vertical(working with row) concat  axis=1 horizontal(working with column) \n#ignore_index = True new indexing numbers\ndata_concat = pd.concat([d1,d2], axis=0, ignore_index = True)\ndata_concat ","1338a64e":"d1 = data.loc[2:5,\"Country\":\"Area\"]\nd2 = data.loc[2:5,\"GPD\"]\n#axis = 1 working with column you can see it when we use ignore_index = True or False\ndata_concat = pd.concat([d1,d2],axis=1 ,ignore_index = False) \ndata_concat","80336f93":"#frequency of climates \n#dropna = False it shows nan values frequency\ndata.Climate.value_counts(dropna = False)","4efc7188":"#drop nan values\ndata.Climate = data.Climate.dropna() \n","adbbdd4c":"#checking with assert we can check alot thing in data\nassert data.Climate.notnull().all()  #return nothing because it is true \n#if it is false return error\n#assert 1==2 #example","256e51e4":"#change nan values. \n#if you drop nan values then you use fillna you change all values\ndata.Climate = data[\"Climate\"].fillna(value=0)  ","1fc502fa":"assert data.Climate.notnull().all()","9aba598f":"d1 = data.head(10)\nd1","fd46aa68":"#value_vars = what we want to melt\n#id_vars = what we dont want to melt\nmelt_d1 = pd.melt(frame = d1, id_vars = \"Country\", value_vars = [\"Population\",\"GPD\",\"Literacy\"])\nmelt_d1","f88ad4d1":"#reverse of melting\nmelt_d1.pivot(index = \"Country\", columns = \"variable\", values = \"value\")","b00395d5":"data.head(7)","1e8279bd":"mean_area = data.Area.mean()\ndata[\"area_level\"] = [\"big\" if i>mean_area else \"small\" for i in data.Area]\ndata.loc[:10,[\"area_level\",\"Area\"]]","8c9b5fb4":"data.head()","112b7e29":"#Line plot  is better when x axis is time.\n#alpha = opacity,  linewidth=width of line, figsize = size of the plot(x,y)\ndata.Birthrate.plot(kind = \"line\",x= \"Birthrate\",  color = \"g\", label = \"Birthrate\", linewidth = 3, alpha = 0.6, grid = True,\n                   linestyle = \"-\", figsize = (20,5))\ndata.Deathrate.plot(kind = \"line\",x= \"Deathrate\",  color = \"black\", label = \"Deathrate\", linewidth = 3, alpha = 0.6, grid = True,\n                   linestyle = \"-\", figsize = (20,5))\n\nplt.legend(loc =\"upper right\") #it shows label into plot\nplt.xlabel(\"x-axis\")\nplt.ylabel(\"y-axis\")\nplt.title(\"Line plot\")\nplt.show()","6fc7ec9b":"#Scatter plot is better when there is correlation between two variables\n\ndata.plot(kind = \"scatter\", x = \"GPD\", y = \"Literacy\", alpha = 0.7, color = \"r\", grid = True, figsize = (8,8))\nplt.xlabel(\"GPD\")\nplt.ylabel(\"Literacy\")\nplt.title(\"scatter plot\")\nplt.show()","1e6017ff":"#histogram is better when we need to see distribution of numerical data.\n#bins = number of bar in figure\ndata.Phone_using.plot(kind = \"hist\", bins = 50, figsize = (20,5),  label=\"Phone_using\")\nplt.legend()\nplt.title(\"Histogram Plot\")\nplt.show()\n\n","27e57050":"#clf = cleans it up again you can start a fresh\ndata.Phone_using.plot(kind = \"hist\", bins = 60, figsize = (10,10), grid = True)\nplt.clf()\n#we cant see plot due to clf","b4f45104":"data.corr()","8b68d2cc":"#correlation map\n#annot = True means we can see numbers in square, fmt = number of digits after comma\nf,ax = plt.subplots(figsize = (20,10))\nsns.heatmap(data.corr(),annot = True, linewidth = 0.5, fmt = \".1f\", ax=ax)  #seaborn \nplt.show()","44ffd21f":"**TIDY AND PIVOTING DATA**\n","258ac2ae":"**LETS  SEE  A FEW PLOTS**","34c7579b":"**This my first  work . I am still learning. I will always update after learn new things. If you find irregular code in here please comment. Thank you.**","e77a2fef":"**MISSING DATA**","0ce9ab1b":"**\u0130NDEX\u0130NG AND SL\u0130C\u0130NG**\n* **u can run them with delete \"#\" one by one **","0f30beed":"**This part is so irregular .I will change this part later. **","b92bbdf0":"* count : total entry\n* mean : average of column \n* std : standart deviation *I will explain later*\n* min : minimum entry\n* max : maximum entry\n* 25% lower quartile (Q1)\n* 50% median (Q2)\n* 75% upper quartile (Q3)\n* [https:\/\/i.hizliresim.com\/RD5XPR.png] picture of about quartile \n* [https:\/\/en.wikipedia.org\/wiki\/Quartile] more information about quartile","e5561460":"**\nCONCATENATING DATA**","07b955e7":"**LIST COMPREHENSION **\n*  **This part is  important. We use it so often in data analysis **"}}