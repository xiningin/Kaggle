{"cell_type":{"f853b333":"code","596bda91":"code","d94c74a9":"code","14bd1259":"code","c9de5ebc":"code","51854afb":"code","5765506b":"code","1e387eba":"code","f007c831":"code","777cb0ff":"code","2a7d04d5":"code","8ffd838a":"code","795575e1":"code","0abdaf6b":"code","1159113e":"code","461605a5":"code","6395754e":"code","79467e4b":"code","ad26e37e":"code","20cf1d3c":"code","3cae5058":"code","bc602728":"code","2b7c578d":"code","3f54fc90":"code","c17c2101":"code","10cea4c6":"code","ca9e947a":"code","1c7269ae":"code","26306e96":"code","278b9d4c":"code","b473e2d4":"markdown","282e1790":"markdown","438ff7ed":"markdown","fd7cf8cc":"markdown","5c46d09d":"markdown","adcef479":"markdown","6a2c1ba0":"markdown","11282301":"markdown","5cd98ac6":"markdown","5f6e3b32":"markdown","9341b669":"markdown","afbfa9a0":"markdown","aba46226":"markdown","6b5ca7d7":"markdown","c3c214eb":"markdown","a4ace61d":"markdown","d794cd1f":"markdown","8b058726":"markdown","21f1e9d9":"markdown","de3d6894":"markdown","877a41cd":"markdown","a73aefce":"markdown","dd2a69d9":"markdown","3eb363f1":"markdown","cd15264c":"markdown","c261771b":"markdown","f2471a0f":"markdown"},"source":{"f853b333":"import torch,gc\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import DataLoader, Dataset\nfrom torchvision import transforms, models\nfrom torchvision.utils import make_grid\nimport os\nimport random\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport time\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix, classification_report","596bda91":"torch.cuda.empty_cache()","d94c74a9":"class BrainTumorDataset(Dataset):\n  def __init__(self, images, labels):\n    # images\n    self.X = images\n    # labels\n    self.y = labels\n    \n    # Transformation for converting original image array to an image and then convert it to a tensor\n    self.transform = transforms.Compose([transforms.ToPILImage(),\n        transforms.ToTensor()\n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -45 degrees and 45 degrees, and then convert it to a tensor\n    self.transform1 = transforms.Compose([\n        transforms.ToPILImage(),                                          \n        transforms.RandomRotation(45),\n        transforms.ToTensor()                                 \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -90 degrees and 90 degrees, and then convert it to a tensor\n    self.transform2 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(90),\n        transforms.ToTensor()                                  \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -120 degrees and 120 degrees, and then convert it to a tensor\n    self.transform3 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(120),\n        transforms.ToTensor()                                  \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -180 degrees and 180 degrees, and then convert it to a tensor\n    self.transform4 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(180),\n        transforms.ToTensor()                                \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -270 degrees and 270 degrees, and then convert it to a tensor\n    self.transform5 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(270),\n        transforms.ToTensor()                                \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -300 degrees and 300 degrees, and then convert it to a tensor\n    self.transform6 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(300),\n        transforms.ToTensor()                               \n    ])\n\n    # Transformation for converting original image array to an image, rotate it randomly between -330 degrees and 330 degrees, and then convert it to a tensor\n    self.transform7 = transforms.Compose([\n        transforms.ToPILImage(),\n        transforms.RandomRotation(330),\n        transforms.ToTensor()                                 \n    ])\n\n  def __len__(self):\n    # return length of image samples\n    return len(self.X)\n\n  def __getitem__(self, idx):\n    # perform transformations on one instance of X\n    # Original image as a tensor\n    data = self.transform(self.X[idx])\n\n    # Augmented image at 45 degrees as a tensor\n    aug45 = self.transform1(self.X[idx])\n\n    # Augmented image at 90 degrees as a tensor\n    aug90 = self.transform2(self.X[idx])\n\n    # Augmented image at 120 degrees as a tensor\n    aug120 = self.transform3(self.X[idx])\n\n    # Augmented image at 180 degrees as a tensor\n    aug180 = self.transform4(self.X[idx])\n\n    # Augmented image at 270 degrees as a tensor\n    aug270 = self.transform5(self.X[idx])\n\n    # Augmented image at 300 degrees as a tensor\n    aug300 = self.transform6(self.X[idx])\n\n    # Augmented image at 330 degrees as a tensor\n    aug330 = self.transform7(self.X[idx])      \n    \n    # store the transformed images in a list\n    new_batch = [data, aug45, aug90, aug120, aug180, aug270, aug300, aug330]\n\n    # one-hot encode the labels\n    labels = torch.zeros(4, dtype=torch.float32)\n    labels[int(self.y[idx])] = 1.0\n\n    new_labels = [labels, labels, labels, labels, labels, labels, labels, labels]\n\n    # 8 augmented images and corresponding labels per sample will be returned\n    return (torch.stack(new_labels), torch.stack(new_batch))","14bd1259":"training_data = pickle.load(open('..\/input\/brain-tumor-classification-mri-images\/brain_tumor_mri\/new_dataset\/training_data.pickle', 'rb'))","c9de5ebc":"Xt = []\nyt = []\nfeatures = None\nlabels = None\nlabel = []","51854afb":"for features,labels in training_data:\n  Xt.append(features)\n  yt.append(labels)","5765506b":"len(yt)","1e387eba":"# 70 % training, 15% validating, 15% testing\nX_train, X_test, y_train, y_test = train_test_split(Xt, yt, test_size=0.3, shuffle=True)  # 70% training, 30% testing\nX_valid, X_test, y_valid, y_test = train_test_split(X_test, y_test, test_size=0.5, shuffle=True)  # split testing set into 50% validation , 50% testing ","f007c831":"Xt = None\nyt = None\nfeatures = None\nlabels = None\nlabel = None\ntraining_data = None ","777cb0ff":"train_set = BrainTumorDataset(X_train, y_train)\nvalid_set = BrainTumorDataset(X_valid, y_valid)\ntest_set = BrainTumorDataset(X_test, y_test)","2a7d04d5":"print(f\"Number of training samples: {len(X_train)}\")\nprint(f\"Number of validation samples: {len(X_valid)}\")\nprint(f\"Number of testing samples: {len(X_test)}\")","8ffd838a":"print(f\"Number of augmented training samples: {len(X_train) * 8}\")\nprint(f\"Number of augmented validation samples: {len(X_valid)* 8}\")\nprint(f\"Number of augmented testing samples: {len(X_test)* 8}\")","795575e1":"train_gen = DataLoader(train_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=2)\nvalid_gen = DataLoader(valid_set, batch_size=4, shuffle=True, pin_memory=True, num_workers=2)\ntest_gen = DataLoader(test_set, batch_size=10, shuffle=True, pin_memory=True, num_workers=2)","0abdaf6b":"device_name = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\ndevice = torch.device(device_name)\ndevice","1159113e":"# instantiate transfer learning model\nresnet_model = models.resnet50(pretrained=True)\n\n# set all paramters as trainable\nfor param in resnet_model.parameters():\n    param.requires_grad = True\n\n# get input of fc layer\nn_inputs = resnet_model.fc.in_features\n\n# redefine fc layer \/ top layer\/ head for our classification problem\nresnet_model.fc = nn.Sequential(nn.Linear(n_inputs, 64),\n                                nn.SELU(),\n                                nn.Dropout(p=0.4),\n                                nn.Linear(64, 64),\n                                nn.SELU(),\n                                nn.Dropout(p=0.4),\n                                nn.Linear(64, 4),\n                                nn.LogSigmoid())\n\n# set all paramters of the model as trainable\nfor name, child in resnet_model.named_children():\n  for name2, params in child.named_parameters():\n    params.requires_grad = True\n\n# set model to run on GPU or CPU absed on availibility\nresnet_model.to(device)\n\n# print the trasnfer learning NN model's architecture\nresnet_model","461605a5":"torch.cuda.empty_cache()","6395754e":"# loss function\n# if GPU is available set loss function to use GPU\ncriterion = nn.CrossEntropyLoss().to(device)\n\n# optimizer\noptimizer = torch.optim.SGD(resnet_model.parameters(), momentum=0.9, lr=3e-4)\n\n# number of training iterations\nepochs = 5\n\n# empty lists to store losses and accuracies\ntrain_losses = []\ntest_losses = []\ntrain_correct = []\ntest_correct = []","79467e4b":"def save_checkpoint(state, is_best, filename='.\/bt_resnet50_ckpt_v2.pth.tar'):\n    torch.save(state, filename)","ad26e37e":"# set training start time\nstart_time = time.time()\n\n\n# set best_prec loss value as 2 for checkpoint threshold\nbest_prec1 = 2\n\n# empty batch variables\nb = None\ntrain_b = None\ntest_b = None\n\n# start training\nfor i in range(epochs):\n    # empty training correct and test correct counter as 0 during every iteration\n    trn_corr = 0\n    tst_corr = 0\n    \n    # set epoch's starting time\n    e_start = time.time()\n    \n    # train in batches\n    for b, (y, X) in enumerate(train_gen):\n        # set label as cuda if device is cuda\n\n        X = X.to(device)\n        y= y.to(device)\n          \n          # forward pass image sample\n        y_pred = resnet_model(X.view(-1, 3, 512, 512))\n        gc.collect()\n        torch.cuda.empty_cache()\n          # calculate loss\n        loss = criterion(y_pred.float(), torch.argmax(y.view(32, 4), dim=1).long())\n\n          # get argmax of predicted tensor, which is our label\n        predicted = torch.argmax(y_pred, dim=1).data\n          # if predicted label is correct as true label, calculate the sum for samples\n        batch_corr = (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n          # increment train correct with correcly predicted labels per batch\n        trn_corr += batch_corr\n          \n          # set optimizer gradients to zero\n        optimizer.zero_grad()\n          # back propagate with loss\n        loss.backward()\n          # perform optimizer step\n        optimizer.step()\n      \n\n    # set epoch's end time\n    e_end = time.time()\n    # print training metrics\n    print(f'Epoch {(i+1)} Batch {(b+1)*4}\\nAccuracy: {trn_corr.item()*100\/(4*8*b):2.2f} %  Loss: {loss.item():2.4f}  Duration: {((e_end-e_start)\/60):.2f} minutes') # 4 images per batch * 8 augmentations per image * batch length\n\n    # some metrics storage for visualization\n    train_b = b\n    train_losses.append(loss)\n    train_correct.append(trn_corr)\n\n    X, y = None, None\n\n    # validate using validation generator\n    # do not perform any gradient updates while validation\n    with torch.no_grad():\n        for b, (y, X) in enumerate(valid_gen):\n            X, y = X.to(device), y.to(device)\n\n                # forward pass image\n            y_val = resnet_model(X.view(-1, 3, 512, 512))\n\n                # get argmax of predicted tensor, which is our label\n            predicted = torch.argmax(y_val, dim=1).data\n\n                # increment test correct with correcly predicted labels per batch\n            tst_corr += (predicted == torch.argmax(y.view(32, 4), dim=1)).sum()\n\n    # get loss of validation set\n    loss = criterion(y_val.float(), torch.argmax(y.view(32, 4), dim=1).long())\n    # print validation metrics\n    print(f'Validation Accuracy {tst_corr.item()*100\/(4*8*b):2.2f} Validation Loss: {loss.item():2.4f}\\n')\n\n    # if current validation loss is less than previous iteration's validatin loss create and save a checkpoint\n    is_best = loss < best_prec1\n    best_prec1 = min(loss, best_prec1)\n    save_checkpoint({\n            'epoch': i + 1,\n            'state_dict': resnet_model.state_dict(),\n            'best_prec1': best_prec1,\n        }, is_best)\n\n    # some metrics storage for visualization\n    test_b  = b\n    test_losses.append(loss)\n    test_correct.append(tst_corr)\n\n# set total training's end time\nend_time = time.time() - start_time    \n\n# print training summary\nprint(\"\\nTraining Duration {:.2f} minutes\".format(end_time\/60))\nprint(\"GPU memory used : {} kb\".format(torch.cuda.memory_allocated()))\nprint(\"GPU memory cached : {} kb\".format(torch.cuda.memory_cached()))","20cf1d3c":"torch.cuda.empty_cache()","3cae5058":"torch.save(resnet_model.state_dict(), '.\/bt_resnet50_model.pt')","bc602728":"print(f'Validation accuracy: {test_correct[-1].item()*100\/(test_b*8*4):.2f}%')","2b7c578d":"plt.plot(train_losses, label='Training loss')\nplt.plot(test_losses, label='Validation loss')\nplt.title('Loss Metrics')\nplt.ylabel('Loss')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","3f54fc90":"plt.plot([t*(1\/171) for t in train_correct], label='Training accuracy')\nplt.plot([t*(1\/36) for t in test_correct], label='Validation accuracy')\nplt.title('Accuracy Metrics')\nplt.ylabel('Accuracy')\nplt.xlabel('Epochs')\nplt.legend()\nplt.show()","c17c2101":"resnet_model.load_state_dict(torch.load('.\/bt_resnet50_model.pt'))\ntrain_gen = None\nvalid_gen = None\ntrain_set = None\nvalid_set = None","10cea4c6":"# set model to evaluation mode\nresnet_model.eval()\n\n# perform no gradient updates\nwith torch.no_grad():\n    # soem metrics storage for visualization and analysis\n    correct = 0\n    test_loss = []\n    test_corr = []\n    labels = []\n    pred = []\n    # perform test set evaluation batch wise\n    for (y, X) in test_gen:\n        # set label to use CUDA if available\n        X, y = X.to(device), y.to(device)\n\n        # append original labels\n        labels.append(torch.argmax(y.view(10 * 8, 4), dim=1).data)\n\n        # perform forward pass\n        y_val = resnet_model(X.view(-1, 3, 512, 512))\n\n        # get argmax of predicted values, which is our label\n        predicted = torch.argmax(y_val, dim=1).data\n        # append predicted label\n        pred.append(predicted)\n\n        # calculate loss\n        loss = criterion(y_val.float(), torch.argmax(y.view(10 * 8, 4), dim=1).long())\n\n        # increment correct with correcly predicted labels per batch\n        correct += (predicted == torch.argmax(y.view(10 * 8, 4), dim=1)).sum()\n\n        # append correct samples labels and losses\n        test_corr.append(correct)\n        test_loss.append(loss)\n        \nprint(f\"Test Loss: {test_loss[-1].item():.4f}\")","ca9e947a":"print(f'Test accuracy: {test_corr[-1].item()*100\/(460*8):.2f}%')","1c7269ae":"labels = torch.stack(labels)\npred = torch.stack(pred)","26306e96":"LABELS = ['Meningioma', 'Glioma', 'Pitutary']","278b9d4c":"arr = confusion_matrix(pred.view(-1).cpu(), labels.view(-1).cpu())\ndf_cm = pd.DataFrame(arr, LABELS, LABELS)\nplt.figure(figsize = (9,6))\nsns.heatmap(df_cm, annot=True, fmt=\"d\", cmap='viridis')\nplt.xlabel(\"Prediction\")\nplt.ylabel(\"Target\")\nplt.show()","b473e2d4":"**Get device to set the training to run on GPU or CPU later based on its availibility**","282e1790":"**I take iteration upto 5 epochs , since it takes 10 min\/epochs, you can increase traning epoch for better accuracy**","438ff7ed":"Print original number of samples in each set","fd7cf8cc":"## Custom Dataset Class\n\n**Create a custom dataset class that augments each image into 4 different angles: 0, 45, 90, 120, 180, 270, 300, 330 degrees. Fuse it with Pytorch's DataLoader class so data can be loaded, augmented and trained in realtime instead of caching all training samples in memory for augmenting.**","5c46d09d":"**Plot the confusion matrix**","adcef479":"**Store images in Xt and labels in yt iteratively**","6a2c1ba0":"**Print the validation accuracy of the model calculated using validation set during training**","11282301":"# Save the model\n\n### Save the model after the training is completed","5cd98ac6":"**Define ground-truth labels as a list**","5f6e3b32":"**Get the test accuracy of 92.72% not bad for 5 epochs**","9341b669":"## Train the model","afbfa9a0":"___","aba46226":"## Train Validation Test split\n\nSplit the dataset for training using cross-validation method.\n\n* 70 % of images for training \n* 15% of images for validating\n* 15% of images for testing\n","6b5ca7d7":"**Import all the required library**","c3c214eb":"**Plot the loss graph**","a4ace61d":"**Convert list of tensors to tensors**","d794cd1f":"## Set Training Configuration","8b058726":"**Create training set, validation set and test set using our custom dataset class**","21f1e9d9":"**Create a DataLoader for each set with batch size of 4 and shuffling enabled**","de3d6894":"## Build the Model\n\n","877a41cd":"## Evaluation","a73aefce":"**Print the test accuracy**\n","dd2a69d9":"## Util function\n\n### Checkpoint Saver\n","3eb363f1":"**Print augmented number of samples in each set**","cd15264c":"## Load the Dataset\n\n* Load the **training_data.pickle** file. \n","c261771b":"**Set model to evaluation mode**\n\n**Calculate loss, correctly classified samples, predicted values, labels and store them in a list using test dataloader**","f2471a0f":"**Empty GPU's memory\/cache for training so we'd clear garbage values in it and more memory will be available**"}}