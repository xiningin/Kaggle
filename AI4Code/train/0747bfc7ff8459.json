{"cell_type":{"b6279c58":"code","952726b5":"code","0d56d6a4":"code","00f30e62":"code","b0b3a716":"code","878736e5":"code","b4b2f607":"code","a4a2757e":"code","a1355e6c":"code","112a0637":"code","e9fc1a5e":"code","e8318920":"code","d0746053":"code","85530ba1":"code","f9411dec":"code","261898db":"code","c7b0bca6":"code","3239d662":"code","b17e3fdb":"code","5eddd09f":"code","fda92c6c":"code","cd21cb64":"code","e12b5522":"code","ccda6d9e":"code","c364801c":"code","6de521f1":"code","edc97542":"code","ea6c1700":"code","a4533530":"code","b22f7a01":"code","6415d66e":"code","b1e6a783":"code","3ae0b708":"code","de8cb000":"code","88d2269a":"code","bab71f68":"code","adea6cfe":"code","310715d3":"code","8951bba6":"code","ac3c1b4f":"code","88e32de3":"code","710f68f0":"code","ea185b47":"code","933ab6e8":"code","c71bb6b3":"code","ca721833":"code","463c51f6":"code","5858e7b6":"code","a6b27cc4":"code","1b40784a":"code","fc3987fb":"code","32baaa70":"code","57327dba":"code","b38c66c8":"code","027d2325":"code","24f3a48a":"code","d3dfb768":"code","8024be4e":"code","8aa15d1b":"code","5fe50212":"code","5c193d99":"code","0669ef82":"code","15055cb0":"code","2960a785":"code","8aa06584":"code","01d7b408":"code","cabe594c":"markdown","a5e2892f":"markdown","92d2befe":"markdown","3c2eabb7":"markdown","a4d79d25":"markdown","3de228b2":"markdown","65894f75":"markdown","0b970059":"markdown","0597b35c":"markdown","8eb37175":"markdown","8914c8a5":"markdown","fa341485":"markdown","729f7bf2":"markdown","c9741afd":"markdown","086e282e":"markdown","8026f2f2":"markdown","8bcdbb7e":"markdown","cbc703b7":"markdown","d739f4f7":"markdown","ef3d328a":"markdown","882dbd57":"markdown","e48c171e":"markdown","c877f93c":"markdown","57263c2c":"markdown","396577c3":"markdown","bd6e65f5":"markdown","9b31b20b":"markdown","a137afb7":"markdown","736c451a":"markdown","0b38dc46":"markdown","7bd4fc22":"markdown","4d7f0ea8":"markdown","99bf4625":"markdown","34000b13":"markdown","bd657f46":"markdown","05f4d535":"markdown","3294438c":"markdown","8dac9578":"markdown","37c171e2":"markdown","90f88148":"markdown","49355253":"markdown","e847da76":"markdown","a079a876":"markdown","c5232519":"markdown","529ee960":"markdown","77162f68":"markdown","15a7fc40":"markdown","2f97da5a":"markdown","2717bb9a":"markdown","e2ede4d6":"markdown","a58017f4":"markdown","97b0166d":"markdown","7c82ad33":"markdown","5e75db7d":"markdown","4bb768e6":"markdown","0f684420":"markdown","bc9ba740":"markdown","6f5d3538":"markdown","49f87f07":"markdown","7ccea694":"markdown","9c8f6c9d":"markdown","2c9c1864":"markdown"},"source":{"b6279c58":"import numpy as np \nimport pandas as pd\nimport os\nimport pandas_profiling\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nrandom_state = 42\n\nprint(os.listdir(\"..\/input\"))\n\nimport warnings\nwarnings.filterwarnings('ignore')","952726b5":"df = pd.read_csv('..\/input\/heart.csv')\ndf.head()","0d56d6a4":"df.info()","00f30e62":"df.describe()","b0b3a716":"values = [96, 207]\nlabels = ['Weiblich', 'M\u00e4nnlich']\nplt.pie(values, labels= values,counterclock=False, shadow=True)\nplt.title('Geschlechterverteilung der Patienten')\nplt.legend(labels,loc=3)\nplt.show()","878736e5":"df.groupby('sex').age.plot(kind='kde')\nplt.title('Alter der Patienten abh\u00e4ngig von Geschlecht')\nlabels = ['Weiblich', 'M\u00e4nnlich']\nplt.legend(labels,loc=1)","b4b2f607":"values = [138, 165]\nlabels = ['Nicht herzkrank', 'Herzkrank']\nplt.pie(values, labels= values,counterclock=False, shadow=True)\nplt.title('Verteilung der Pr\u00e4senz von Herzkrankheiten')\nplt.legend(labels,loc=3)\nplt.show()","a4a2757e":"ct_tarsex = pd.crosstab(df.target, df.sex)\nct_tarsex.plot.bar(stacked=True)\nlabels = ['Weiblich', 'M\u00e4nnlich']\nplt.legend(labels,loc=3)\nplt.title('Pr\u00e4senz von Herzkrankheiten nach Geschlechtern')","a1355e6c":"values = [143, 86, 50, 23]\nlabels = ['Typisches Beklemmungsgef\u00fchl \/ Angina', 'Untpyische Angina', 'Nicht-anginale Schmerzen', 'Ohne erkennbare Symptome']\nplt.pie(values, labels= values,counterclock=False, shadow=True)\nplt.title('Verteilung der Schmerzkategorien')\nplt.legend(labels, loc=3)\nplt.show()","112a0637":"ct2_anglabel = pd.crosstab(df.target, df.cp)\nct2_anglabel.plot.bar(stacked=True)\n\nplt.title('Schmerzkategorien gemappt zu vorhandenen Herzkrankheiten')","e9fc1a5e":"ct2_calabel = pd.crosstab(df.target, df.ca)\nct2_calabel.plot.bar(stacked=True)\n\nplt.title('Anzahl erkannter Gef\u00e4\u00dfe im Verh\u00e4ltnis zu pr\u00e4senten Herzkrankheiten')","e8318920":"norm_bot = 120\nnorm_top = 129\n\nresult = plt.hist(df[['trestbps']].values, bins=24, color='dodgerblue', edgecolor='k', alpha=0.65)\nplt.axvline(norm_bot, color='r', linewidth=2)\nplt.axvline(norm_top, color='r', linewidth=2)\n\n_, max_ = plt.ylim()\n\nplt.text(160 + 160\/10, \n         max_ - max_\/10, \n         'Optimal      {:}'.format(norm_bot))\n\nplt.text(160 + 160\/10, \n         max_ - max_\/10 - 5, \n         'Normal <= {:}'.format(norm_top))\n\nplt.title('Werteverteilung des Ruhepuls')","d0746053":"avg = 240\n\nresult = plt.hist(df[['chol']].values, bins=24, color='dodgerblue', edgecolor='k', alpha=0.65)\nplt.axvline(avg, color='r', linewidth=2)\n\n_, max_ = plt.ylim()\n\nplt.text(400 + 400\/10, \n         max_ - max_\/10, \n         'Durchschnitt: {:}'.format(avg))\n\nplt.title('Werteverteilung der Cholesterin-Konzentration in mg\/dl')","85530ba1":"#pandas_profiling.ProfileReport(df)","f9411dec":"# L\u00f6schen der Duplikate und dauerhafte Speicherung mtihilfe von inplace=True, andernfalls w\u00fcrde eine Kopie erstellt werden\ndf.drop_duplicates(inplace=True)","261898db":"df.corr()","c7b0bca6":"plt.matshow(df.corr())","3239d662":"from sklearn.feature_selection import f_classif, SelectKBest","b17e3fdb":"def select_kbest_clf(data_frame, target, k=5):\n\n    feat_selector = SelectKBest(f_classif, k=k)\n    _ = feat_selector.fit(data_frame.drop(target, axis=1), data_frame[target])\n    \n    feat_scores = pd.DataFrame()\n    feat_scores[\"F Score\"] = feat_selector.scores_\n    feat_scores[\"P Value\"] = feat_selector.pvalues_\n    feat_scores[\"Support\"] = feat_selector.get_support()\n    feat_scores[\"Attribute\"] = data_frame.drop(target, axis=1).columns\n    \n    return feat_scores ","5eddd09f":"select_kbest_clf(df, 'target')","fda92c6c":"from sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import f_classif, SelectKBest\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import StratifiedKFold, RandomizedSearchCV, GridSearchCV","cd21cb64":"#Visualizieren der Confusion Matrix\n#Source: https:\/\/github.com\/rohanjoseph93\/Python-for-data-science\/blob\/master\/Grid%20Search%20-%20Breast%20Cancer.ipynb\nfrom sklearn.metrics import confusion_matrix\nnp.set_printoptions(precision=2)\n\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n    print(cm)\n    print('False Negative Rate (should be close to 0): ', cnf_matrix[0][1] \/ (cnf_matrix[0][1] + cnf_matrix[1][1]))\n\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    fmt = '.2f' if normalize else 'd'\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, format(cm[i, j], fmt),\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')\n    plt.tight_layout()","e12b5522":"from sklearn.model_selection import train_test_split\n\nX, y = df.iloc[:,:-1],df.iloc[:,-1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=random_state)\n\nprint('Training Shapes:', X_train.shape, y_train.shape)\nprint('Test Shapes:', X_test.shape, y_test.shape)","ccda6d9e":"from sklearn.linear_model import SGDClassifier\n\nsgdcd = SGDClassifier(random_state = random_state)\nsgdcd.fit(X_train,y_train)\nac_sgdcd = sgdcd.score(X_test, y_test)\n\nprint('Dummy Classifier Accuracy:', ac_sgdcd)","c364801c":"cnf_matrix = confusion_matrix(y_test, sgdcd.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - Dummy Classifier')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","6de521f1":"from sklearn.linear_model import SGDClassifier\n\nsgdc_pipe  = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('sgdc', SGDClassifier())\n])\n\nsgdc_pipe.set_params(\n    kbest__k=5,\n    sgdc__eta0=0.1, sgdc__random_state=random_state, sgdc__n_jobs=-1\n)\n\nsgdc_pipe.fit(X_train,y_train)\n\nac_sgdc = sgdc_pipe.score(X_test, y_test)\nprint('SGD Classifier Accuracy:', ac_sgdc)","edc97542":"sgdc_params = {\n        'sgdc__penalty': ['l1', 'l2', 'none', 'elasticnet'],\n        'sgdc__learning_rate': ['constant', 'optimal', 'invscaling'],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }","ea6c1700":"grid_search_sgdc = GridSearchCV(sgdc_pipe, param_grid=sgdc_params, scoring='roc_auc', n_jobs=-1)\ngrid_search_sgdc.fit(X_train, y_train)\n\ngrid_search_sgdc.best_params_","a4533530":"grid_search_sgdc.best_score_","b22f7a01":"ac_sgdc_cv = grid_search_sgdc.best_estimator_.score(X_test,y_test)\nprint('SGD Classifier Accuracy CV:', ac_sgdc_cv)","6415d66e":"cnf_matrix = confusion_matrix(y_test, grid_search_sgdc.best_estimator_.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - SGDClassifier + Grid Search')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","b1e6a783":"from sklearn.tree import DecisionTreeClassifier\n\ndtc_pipe = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('dtc', DecisionTreeClassifier(random_state=random_state))\n])\n\ndtc_pipe.set_params(\n    kbest__k=5\n)\n\ndtc_pipe.fit(X_train, y_train)\n\nac_dtc = dtc_pipe.score(X_test, y_test)\nprint('DecisionTree Classifier Accuracy:', ac_dtc)","3ae0b708":"dtc_params = {\n        'dtc__max_depth': [2, 3, 5, 10, None],\n        'dtc__max_leaf_nodes': [3, 5, 8, 10, 15, 20, None],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }","de8cb000":"grid_search_dtc = GridSearchCV(dtc_pipe, param_grid=dtc_params, scoring='roc_auc', n_jobs=-1)\ngrid_search_dtc.fit(X_train, y_train)\n\ngrid_search_dtc.best_params_","88d2269a":"grid_search_dtc.best_score_","bab71f68":"ac_dtc_cv = grid_search_dtc.best_estimator_.score(X_test, y_test)\nprint('DecisionTree Classifier Accuracy CV:', ac_dtc_cv)","adea6cfe":"cnf_matrix = confusion_matrix(y_test, grid_search_dtc.best_estimator_.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - DecisionTreeClassifier + Grid Search')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","310715d3":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_pipe = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('knn', KNeighborsClassifier())\n])\n\nknn_pipe.set_params(\n    kbest__k=5,\n    knn__n_jobs=-1\n)\n\nknn_pipe.fit(X_train,y_train)\n\nac_knn = knn_pipe.score(X_test, y_test)\nprint('KNN Classifier Accuracy:', ac_knn)","8951bba6":"knn_params = {\n        'knn__n_neighbors': [3, 5, 7, 9, 11, 13, 15],\n        'knn__algorithm': ['ball_tree', 'kd_tree', 'brute'],\n        'knn__leaf_size': [20, 30, 40],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }","ac3c1b4f":"grid_search_knn = GridSearchCV(knn_pipe, param_grid=knn_params, scoring='roc_auc', n_jobs=-1)\ngrid_search_knn.fit(X_train, y_train)\n\ngrid_search_knn.best_params_","88e32de3":"grid_search_knn.best_score_","710f68f0":"ac_knn_cv = grid_search_knn.best_estimator_.score(X_test,y_test)\nprint('KNN Classifier Accuracy CV:', ac_knn_cv)","ea185b47":"cnf_matrix = confusion_matrix(y_test, grid_search_knn.best_estimator_.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - KNN + Grid Search')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","933ab6e8":"from sklearn.ensemble import RandomForestClassifier\n\nrfc_pipe = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('rfc', RandomForestClassifier())\n])\n\nrfc_pipe.set_params(\n    rfc__random_state=random_state,\n    kbest__k=5\n)\n\nrfc_pipe.fit(X_train, y_train)\n\nac_rfc = rfc_pipe.score(X_test, y_test)\nprint('RandomForest Classifier Accuracy:', ac_rfc)","c71bb6b3":"rfc_params = {\n        'rfc__min_samples_split': [2, 5, 10, 15, 20],\n        'rfc__max_depth': [5, 10, 15, 20, 25, None],\n        'rfc__n_estimators': [100, 250, 500, 750, 1000],\n        'rfc__bootstrap': [True, False],\n        'rfc__min_samples_leaf': [1, 2, 5, 6, 10],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }\n\nparams_comb_all = int(5 * 6 * 5 * 2 * 5  * 6)\nparam_comb = int(params_comb_all \/ 100)\n\nprint('GridSearchCV parameter combinations: ' + str(params_comb_all) + '\\n' + 'RandomizedSearchCV parameter combinations: ' + str(param_comb))","ca721833":"rnd_search_rfc = RandomizedSearchCV(rfc_pipe, param_distributions=rfc_params, n_iter=param_comb, scoring='roc_auc', n_jobs=-1, random_state=random_state )\nrnd_search_rfc.fit(X_train, y_train)\n\nrnd_search_rfc.best_params_","463c51f6":"rnd_search_rfc.best_score_","5858e7b6":"ac_rfc_cv = rnd_search_rfc.best_estimator_.score(X_test,y_test)\nprint('RandomForest Classifier Accuracy CV:', ac_rfc_cv)","a6b27cc4":"cnf_matrix = confusion_matrix(y_test, rnd_search_rfc.best_estimator_.predict(X_test))\n\nplt.figure()\nclass_names = [0,1]\nplot_confusion_matrix(cnf_matrix, classes=class_names,\n                      title='Confusion matrix - RandomForestClassifier + Randomized Grid Search')\na = plt.gcf()\na.set_size_inches(4,3)\nplt.show()","1b40784a":"ac_df = pd.DataFrame()\nac_df['Dummy'] = [ac_sgdcd, '-']\nac_df['Linear'] = [ac_sgdc, ac_sgdc_cv]\nac_df['Decision Tree'] = [ac_dtc, ac_dtc_cv]\nac_df['KNN'] = [ac_knn, ac_knn_cv]\nac_df['Random Forest'] = [ac_rfc, ac_rfc_cv]\nac_df\n\n#0 ist ohne CV, 1 ist mit CV","fc3987fb":"from xgboost import XGBClassifier\n\nxgc_pipe = Pipeline([\n    ('kbest', SelectKBest(f_classif)),\n    ('scaler', StandardScaler()),\n    ('xgc', XGBClassifier())\n])\n\nxgc_pipe.set_params(\n    kbest__k=5\n)\n\nxgc_pipe.fit(X_train, y_train)\n\nxgc_pipe.score(X_test, y_test)","32baaa70":"xgc_params = {\n        'xgc__learning_rate': [.0001, .001, .01, .1],\n        'xgc__max_depth': [5, 10, 15, 20, 25],\n        'xgc__n_estimators': [250, 500, 750, 1000],\n    \n        'kbest__k': [3, 5, 7, 9, 11, 13]\n        }\n\nparams_comb_all = int(4 * 5 * 4 * 6)\nparam_comb = int(params_comb_all \/ 5)\n\nprint('GridSearchCV parameter combinations: ' + str(params_comb_all) + '\\n' + 'RandomizedSearchCV parameter combinations: ' + str(param_comb))","57327dba":"rnd_search_xgc = RandomizedSearchCV(xgc_pipe, param_distributions=xgc_params, n_iter=param_comb, scoring='roc_auc', n_jobs=-1, random_state=random_state )\nrnd_search_xgc.fit(X_train, y_train)\n\nrnd_search_xgc.best_params_","b38c66c8":"rnd_search_xgc.best_score_","027d2325":"rnd_search_xgc.best_estimator_.score(X_test,y_test)","24f3a48a":"y_pred = rnd_search_xgc.best_estimator_.predict(X_test)\nconfusion_matrix(y_test, y_pred)","d3dfb768":"grid_search_xgc = GridSearchCV(xgc_pipe, param_grid=xgc_params, scoring='roc_auc', n_jobs=-1)\ngrid_search_xgc.fit(X_train, y_train)\n\ngrid_search_xgc.best_params_","8024be4e":"grid_search_xgc.best_score_","8aa15d1b":"grid_search_xgc.best_estimator_.score(X_test,y_test)","5fe50212":"from keras.models import Sequential\nfrom keras.layers import Dense\nfrom keras.wrappers.scikit_learn import KerasClassifier\n\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.preprocessing import StandardScaler","5c193d99":"def keras_model():\n    model = Sequential()\n    model.add(Dense(22, input_dim=5, activation='relu'))\n    model.add(Dense(1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","0669ef82":"kfold = KFold(n_splits=10, shuffle=True, random_state=random_state)","15055cb0":"estimators = []\nestimators.append(('scaler', StandardScaler()))\nestimators.append(('keras_clf', KerasClassifier(build_fn=keras_model, epochs=200, batch_size=5, verbose=0)))\n\npipeline = Pipeline(estimators)","2960a785":"results = cross_val_score(pipeline, X[['cp', 'thalach', 'exang', 'oldpeak', 'ca']], y, cv=kfold)\nprint(\"Accuracy der verschiedenen Folds: \", results)\nprint(\"Accuracy: mean %.2f%% (std %.2f%%)\" % (results.mean()*100, results.std()*100))","8aa06584":"pipeline.fit(X_train[['cp', 'thalach', 'exang', 'oldpeak', 'ca']], y_train)\n\ny_pred = pipeline.predict(X_test[['cp', 'thalach', 'exang', 'oldpeak', 'ca']])","01d7b408":"from sklearn.metrics import accuracy_score\naccuracy_score(y_test, y_pred)","cabe594c":"Parameter Tuning um eine h\u00f6here Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Maximale Tiefe des Baumes\n    - Maximale Anzahl an Bl\u00e4ttern (des Baumes)\n- Datenspezifisch\n    - Anzahl der (besten) Features","a5e2892f":"**Interpretation**: Hinsichtlich der Pr\u00e4senz von Herzkrankheiten ist der Datensatz \"relativ\" ausbalanciert. Somit hat das ML Modell eine augeglichene Informationsbasis f\u00fcr die Klassifizierung von gesunden und kranken Patienten.","92d2befe":"In diesem Fall sind False Negatives (versehentlich als gesund eingestuft) aus medizinischer Perspektive relevanter als False Positives (versehentlich als krank eingestuft), da es wesentlich gravierender ist einen kranken Patienten als gesund einzustufen, als einen gesunden Patienten als krank einzustufen. Wird ein kranker Patient als gesund eingestuft und sucht deshalb keinen Arzt auf, ist dies weitaus schlimmer, als ein gesunder Patient, dessen falsche Diagnose sich sp\u00e4testens beim n\u00e4chsten Arztbesuch aufl\u00f6st. \n\nDie hierzu passende Metrik ist die False Negative-Rate, welche m\u00f6glichst niedrig sein sollte (nahe 0).","3c2eabb7":"### 1.1 Data Visualization","a4d79d25":"Accuracy mit Cross Validation (gemittelt):","3de228b2":"**Interpretation**: Sowohl bei weiblichen, als auch bei m\u00e4nnlichen Patienten liegen die meisten daten f\u00fcr Personen zwischen 40 und ca. 75 Jahren vor.","65894f75":"Im Verlgeich die Accuracy ohne Cross Validation (ein einzelner Split):","0b970059":"Die mit \"True\" gekennzeichneten Attribute sind laut der Analyse als Features am besten geeignet.","0597b35c":"Initialisieren der Pipeline und erster Test des K-Nearest-Neighbor Classifiers mit dem gesplitteten Datensatz:\n\n(Output: Accuracy gemessen am Testdatensatz)","8eb37175":"Vermutete Korrelationen:\n\n- Wie bereits vermutet, haben Ruhepuls und Cholesterin-Konzentration aufgrund ihrer starken Orientierung an Durchschnittswerten keine starke Korrelation zu dem Label. (Korrelation nahe 0)\n\nAm st\u00e4rksten korrelieren die folgenden Features:\n\n- CP (0,43)\n- Thalach (0,41)\n- Exang (-0,43)\n- Oldpeak (-0,42)\n- Ca (-0,40)\n\nDie Vermutung liegt nahe, dass diese Features am besten f\u00fcr das sp\u00e4tere Model Training geeignet sind. ","8914c8a5":"## Zusatz Modeling","fa341485":"### Modeling - Neural Network with Keras\n\nBase Setup:\n\nhttps:\/\/machinelearningmastery.com\/binary-classification-tutorial-with-the-keras-deep-learning-library\/\n\nNumber of Neurons in Hidden Layer:\n\nhttps:\/\/stats.stackexchange.com\/questions\/181\/how-to-choose-the-number-of-hidden-layers-and-nodes-in-a-feedforward-neural-netw","729f7bf2":"### 3.2 Dummy Classifier","c9741afd":"### Vergleich der Modelle\n\nDurch das Trainieren verschiedener Modelle und Optimierung der zugeh\u00f6rigen Stellschrauben (Hyperparameter), konnten mehrere L\u00f6sungsans\u00e4tze evaluiert werden.","086e282e":"Initialisieren der Pipeline und erster Test des Linear Classifiers mit dem gesplitteten Datensatz:\n\n(Output: Accuracy gemessen am Testdatensatz)","8026f2f2":"Um das Model noch weiter zu verbessern wird die in diesem Falle etwas aufwendigere GridSearchCV durchgef\u00fchrt, welche alle 480 Parameterkombinationen abdeckt.","8bcdbb7e":"Da hier 480 Parameterkombinationen existieren, wird vorerst eine RandomizedSearchCV durchgef\u00fcrht, welche die Kombinationen auf 96 reduziert und somit auch auf einem Mittelklasserechner in annehmbarer Zeit durchgef\u00fchrt werden kann.","cbc703b7":"Parameter Tuning um eine h\u00f6here Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Minimale Anzahl an Sampels, bevor ein Ast aufgespaltet werden darf\n    - Maximale Tiefe des Baumes\n    - Anzahl der zu trainierenden Estimators\n    - Einsatz von Bootstrap-Samples\n    - Minimale Samples pro Blatt\n- Datenspezifisch\n    - Anzahl der (besten) Features","d739f4f7":"Der obige Vergleich anhand der Accuracy zeigt, dass das KNN Modell in Verbidnung mit Cross Validation die besten Ergebnisse erzielt. Unter Verwendung dieses Modells kann eine vorhandene Herzkrankheit mit einer Accuracy von 0.9 vorhergesagt werden. Dies bedeutet, dass auf Basis der eingegebenen Daten eine Herzkrankheit zu 90% korrekt diagnostiziert werden kann.","ef3d328a":"Der folgende Classifier ist ein initiales Modell, um die Trefferquote eines ML Modells zu zeigen, das bisher mit keinen Methoden optimiert wurde. Es dient zum Vergleich von sp\u00e4ter eingesetzten Modellen.","882dbd57":"### 3.3 Linear Classifier","e48c171e":"Die obige Matrix l\u00e4sst eine erste Beurteilung der Signifikanz der Attribute zu. Um eine m\u00f6glichst optimale Anzahl an repr\u00e4sentativen Attributen bzw. Features zu erhalten, wird eine statistische Selektionsmethode gew\u00e4hlt:","c877f93c":"\n\n#### Model Aufbau:\n- Input Layer mit 13 Inputs \n    - alle verf\u00fcgbaren Features werden verwendet\n- Hidden Layer mit 10 Neuronen\n    - relu als Activation Function\n- Output Layer mit 1 Ouput\n    - Binary Classification, sigmoid als Activation Function -> Value entweder 0 oder 1\n    \n#### Model Parameter:\n- Loss Function\n    - Binary Crossentropy\n- Optimizer\n    - Adam\n- Zu optimierende Metrik\n    - Accuracy\n- Dense Layer\n    - Neuron eines Layers erh\u00e4lt Input von allen Neuronen des vorangeheneden Layers\n- Sequential\n    - Feed Forward\n    \n#### Zusatz:\nAuch hier wird wieder eine Pipeline verwendet um das Scaling direkt in den Prozess zu integrieren. Durch den Keras Wrapper, welcher von Sklearn bereitgestellt wird, l\u00e4sst sich der KerasClassifier wie ein Sklearn nativer Classifier verwenden (Stellt z.B. Methoden wie fit() und score() bereit.\n\nZudem wird Cross Validation eingesetzt, wobei der Datensatz in k = 10 Folds aufgeteilt und anschliessend kombiniert wird. Auf ein Test- bzw. Validationset wird hier verzichtet, da ein DNN einen gr\u00f6sseren Datensatz ben\u00f6tigt und durch die Cross Validation hier aussreichend Schutz gegen Overfitting existiert. Tradeoff hier zwischen Overfitting und Datensatzgr\u00f6sse!","57263c2c":"Im Folgenden wird versucht mit Hilfe des XGBoost Algorithmus und eines Deep Neural Networks eine m\u00f6glichst hohe Accuracy zu erziehlen. Es bleibt jedoch zu erw\u00e4hnen, dass dies aufgrund des sehr kleinen Datensatzes (~ 300 Tupeln) mit Vorsicht zu behandeln ist und am besten als \"Mit Kanonen auf Spatzen schiessen\" beschrieben werden kann.","396577c3":"**Interpretation**: In Bezug auf die Cholesterin Konzentration der Patienten l\u00e4sst sich ein \u00e4hnliches Ph\u00e4nomen feststellen. Auch hier wird eine geringe Korrelation mit dem Label vermutet, da sich ein Gro\u00dfteil der Cholesterin Werte des Datensatzes um einen normalen bzw. durchschnittlichen Wertebereich ansiedeln.\n\nHinweis: Zun\u00e4chst wurde der Wert von \u00fcber 500 mg\/dl Cholesterin als Outlier betrachtet, weitere Recherchen ergaben, dass ein derartiger Wert allerdings durchaus bei spezifischen Herzkrankheiten auftreten kann.","bd6e65f5":"### 3.4 DecisonTreeClassifier","9b31b20b":"Parameter Tuning um eine h\u00f6here Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Anzahl der einbezogenen Nachbarn\n    - Verwendeter Algorithmus\n    - Blattgr\u00f6sse\n- Datenspezifisch\n    - Anzahl der (besten) Features","a137afb7":"Um ein besseres Verst\u00e4ndnis von den entahltenen Daten zu erhalten, werden einige Zusammenh\u00e4nge als Statistiken visualisiert.","736c451a":"**Interpretation**: Der obigen Graphik kann entnommen werden, dass die Mehrheit aller Patienten in ihren Ruhepuls-Werten um Durchschnittswerte zentriert ist. Aus diesem Grund l\u00e4sst sich vermuten, dass der Ruhepuls als solches nicht direkt mit dem Label korreliert.  ","0b38dc46":"## 3. Modeling","7bd4fc22":"### Modeling - xgboost","4d7f0ea8":"## 1. Data Exploration","99bf4625":"#### Pipeline:\n- Pipeline \n    - Zusammenfassen von Teilen des Preprocessing und des Classifiers zu einer Pipeline. Da die Pipeline Modifikationen aller Paramter der einzelnen Komponenten anbietet, wird die Anwendung einer Grid Search erleichtert\/erm\u00f6glicht\n    \n\n\n#### Feature Selection: \n- SelectKBest \n    - Ermitteln der am besten korrelierenden Features -> reduzieren der Features\n\n#### Scaling: \n- StandardScaler\n    - Normalizieren der einzelnen Spalten auf einen mean = 0 (Durchschnitt) und eine standard deviation = 1 (Standardabweichung)\n\n#### Parameter Tuning: \n- GridSearchCV \n    - Trainieren mehrerer Modelle mit unterschiedlichen Parameterkombinationen. Hier wird ein Modell pro Kombination trainiert, was diese Methode bei grossen Datens\u00e4tzen und vielen Parameterkombinationen sehr langsam macht. \n    - Zus\u00e4tzlich wird Cross Validation angewandt, was den Datensatz in sogenannte Folds einteilt. Die Anzahl kann hier mit Parameter k festgelegt werden. Das Modell wird dann auf verschiedene Kombinationen dieser Folds trainiert und aus den Ergebnissen ein Mittelwert erzeugt. Hierdurch kann Overfitting weitesgehend verhindert werden.\n- RandomizedGridSearchCV\n    - Randomisierte Grid Search um bei grosser Anzahl an Parameterkombinationen die Trainingszeit zu verringern. Hier werden zuf\u00e4llig Parameterkombinationen gew\u00e4hlt und die entsprechenden Modelle trainiert.\n- StratifiedKFold \n    - Methode zur Einteilung des Datensatzes in k Folds\n","34000b13":"Um erkennen zu k\u00f6nnen, welche Attribute tats\u00e4chlich ausschlaggebend f\u00fcr die Diagnose einer Herzkrankheit sind, k\u00f6nnen sowohl ihre Korrelationen mit dem Label \"krank\" oder \"nicht krank\", als auch ihre Verbidnung untereinander betrachtet werden. Die Matrix zeigt die jeweiligen Korrelationen auf Basis des Pearson Koeffizients, wobei eine N\u00e4he zu dem Wert 1 eine starke Korrelation bedeutet. ","bd657f46":"#### Attributtypen\n\nDer Datensatz umfasst 9 kategorische und 5 numerische Attribute:\n\n###### Kategorische Variablen:\n\nAlle kategorischen Attribute (Geschlecht, Cp (Schmerzkategorie), hoher Blutzucker, restecg & slope (EKG Resultate), ca (Anzahl der Hauptgef\u00e4\u00dfe) und thal (Einstfung des Thaliumwerts) wurden bereits in Dummy Variablen umgesetzt\n\n- **Sex**: Geschlecht\n- **Cp**: Schmerzkategorie von 1-4 \n- **Fbs**: Abnormalie des Blutzuckers (0 = unter dem Durchschnittswert, 1 = \u00fcber dem Durchschnittswert)\n- **Exang**: \"Engegef\u00fchl\" bei sportlicher Aktivit\u00e4t (0 = Nein, 1 = Ja)\n- **Restecg**: EKG Untersuchung nach Abnormalit\u00e4ten (0 = ohne Befund, 1 & 2 mittlerer bis schwerwiegender Befund)\n- **Slope**: EKG Untersuchung nach kardiographischen Auff\u00e4lligkeiten (Einteilung von 0-4)\n- **Ca**: Anzahl erkennbarer Hauptgef\u00e4\u00dfe im Rahmen einer Durchleuchtungsuntersuchung (Einteilung von 0-4, ein Hauptgef\u00e4\u00df ist bei Verstopfung nicht sichtbar)\n- **thal**: Test zur Qualit\u00e4t der Blutversorgung, Pr\u00fcfung nach Durchblutungsst\u00f6rung \"Thalass\u00e4mie\", welche vererbt werden kann\n- **target**: Ergebnis der Patientenuntersuchung (0 = keine Herzkrankheit, 1 = Herzkrankheit)\n\n###### Numerische Variablen:\n\n- **Age**: Alter\n- **Trestbps**: Ruhepuls gemessen an Millimeter Quecksilbers\u00e4ule, Durchschnittswert bei Erwachsenen: 120-129)\n- **Chol**: Cholesterin in mg pro Deziliter, Durchschnittswert ist 240 mg\/dl\n- **Thalach**: Maximale Herzfrequenz (bei gr\u00f6\u00dftm\u00f6glicher Anstrengung) in Herzschl\u00e4ge\/ Minute\n- **Oldpeak**: Befund bei EKG (ST Streckensenkung), der eine bestimmte Basislinie nicht unterschreiten sollte","05f4d535":"**Interpretation**: Der Datensatz enth\u00e4lt 96 weibliche und 207 m\u00e4nnliche Patienten. Damit ist der Datensatz hinsichtlich der Geschlechteraufteilung hin zu m\u00e4nnlichen Geschlechtern verzerrt, da fast doppelt so viele Daten zu M\u00e4nnern, als zu Frauen vorliegen. ","3294438c":"**Interpretation**: Der Graphik zufolge sind unter den Patienten ohne Herzkrankheiten deutlich mehr M\u00e4nner als Frauen. Das Modell k\u00f6nnte demnach bei der Klassifizierung von gesunden Patienten daher m\u00f6glicherweise \"biased\" bzw. voreingenommen sein und M\u00e4nner tendenziell \u00f6fter als nicht herzkrank einstufen. Jedoch muss bei der Graphik die ungleiche Geschlechterverteilung innerhalb des Datensatzes beachtet werden.","8dac9578":"Die folgende Tabelle enth\u00e4lt allgemeine Informationen zu den vorhandenen Daten, aus denen sich erste R\u00fcckschl\u00fcsse ziehen lassen, wie z.B.: Das Durchschnittsalter der Patienten betr\u00e4gt ca. 54 Jahre, der j\u00fcngste Studienteilnehmer ist 29 Jahre alt, der \u00e4lteste 77.","37c171e2":"Initialisieren der Pipeline und erster Test des RandomForest Classifiers mit dem gesplitteten Datensatz:\n\n(Output: Accuracy gemessen am Testdatensatz)","90f88148":"## Beschreibung der Attribute\n\nDer Datensatz stammt aus einer klinischen Testreihe der \u00c4rzte Andras Janosi, William Steinbrunn, Matthias Pfisterer und Robert \nDetrano. Die anschlie\u00dfende Beschreibung ist der Quelle entnommen, detaillierte Informationen folgen im Rahmen der Data Exploration.\n\n- **Age**: in years\n- **Sex**: (1 = male; 0 = female)\n- **Cp**: chest pain type\n    - Value 1: typical angina \n    - Value 2: atypical angina \n    - Value 3: non-anginal pain \n    - Value 4: asymptomatic \n- **Testbps**: resting blood pressure (in mm Hg on admission to the hospital)\n- **Chol**: serum cholestoral in mg\/dl\n- **Fbs**: (fasting blood sugar > 120 mg\/dl) (1 = true; 0 = false)\n- **Restec**: gresting electrocardiographic results\n- **Thalach**: maximum heart rate achieved\n- **Exang**: exercise induced angina (1 = yes; 0 = no)\n- **Oldpeak**: ST depression induced by exercise relative to rest\n- **Slope**: the slope of the peak exercise ST segment\n- **Ca**: number of major vessels (0-3) colored by flourosopy\n- **Thal**: thallium heart scan, 3 = normal; 6 = fixed defect; 7 = reversable defect\n- **Target**: 1 or 0\n\nQuelle: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Heart+Disease\n\n### Ziel: Vorhersage einer vorhandenen Herzkrankheit auf Basis von Patientendaten","49355253":"Parameter Tuning um eine h\u00f6here Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Learning Rate\n    - Maximale Tiefe der einzelnen Baume\n    - Anzahl der Estimator die trainiert bzw. f\u00fcr die Prediciton zu Rate gezogen werden\n- Datenspezifisch\n    - Anzahl der (besten) Features","e847da76":"**Interpretation**: Fast 50% aller Patienten haben ein typisches Beklemmungsgef\u00fchl im Herzbereich, auch Angina genannt. Die verbleibenden Testpersonen teilen sich zu ungef\u00e4hr gleichen Teilen auf untypische Beklemmungserscheinungen und nicht pr\u00e4sente Symptome auf.","a079a876":"### 3.1 Data Preprocessing","c5232519":"####  1.1.2 Spezifische medizinische Informationen","529ee960":"### 3.5 KNN","77162f68":"### 3.6 RandomForestClassifier","15a7fc40":"**Interpretation**: Auf Basis des allgemeinen medizinischen Kontexts kann die Hypothese aufgestellt werden, dass Patienten mit 0 erkannten gro\u00dfen Hergef\u00e4\u00dfen (durch Verstopfung) h\u00e4ufiger unter einer Herzkrankheiten leiden. D.h. je weniger Gef\u00e4\u00dfe erkannt wurden, desto h\u00f6her w\u00e4re die Wahrscheinlichkeit einer Herzkrankheit. \n\nDie obige Graphik best\u00e4tigt diese Vermutung, da ein Gro\u00dfteil aller Patienten mit verstopften Gef\u00e4\u00dfen tats\u00e4chlich unter einer Herzkrankheit leiden. Dies liefert einen ersten Hinweis auf eine vorliegende Korrelation zwischen der Anzahl erkannter Hauptgef\u00e4\u00dfe und dem \"Label\" Herzkrankheit. ","2f97da5a":"Aufteilen des Datensatzes in X (Features) und y (Label).\nSplitten der X Matrix und des y Vektors in Training- und Testset. Hierzur wird train_test_split von Sklearn verwendet und der Datensatz in 80% Trainings- und 20% Testdaten aufgeteilt.","2717bb9a":"13 features = all\n5 features = cp thalach exang oldpeak ca\n\n#### Neural Network Configurations\nI played around with the number of neurons in the hidden layer, but finally sticked to a formula that worked quite well.\n\nInput, Hidden, Output, Accuracy\n13 - 10 - 1 \t80.75\n\n5 - 10 - 1 \t\t83.06\n\n5 - 4 - 1 \t\t81.43\n\n5 - 15 - 1\t\t83.42\n\n5 - 22 - 1 \t\t83.75\n\n5 - 30 - 1      81.75 \n\n\n5 - 22 - 5 - 1\t\t82.40\n\n5 - 15 - 5 -  1\t\t81.09\n\n\t","e2ede4d6":"## Fazit\n\nIm Zuge der Analyse von Patientendaten f\u00fcr die Vorhersage von Herzkrankheiten wurden verschiedene g\u00e4ngige ML Praktiken durchgef\u00fchrt, wie beispielweise Data Preprocessing, Feature Engineering und Modeling. Um bestm\u00f6gliche Vorhersagen zu erreichen, wurden verschiedene Classifier Modelle mit den Daten trainiert. Im Folgenden werden die Modelle in ihrer Performance gegen\u00fcbergestellt und die Gr\u00f6sse des Datensatyes kritisch evaluiert. ","a58017f4":"Nach der folgenden Analyse l\u00e4sst sich der Datensatz mit diesen Eckpunkten beschreiben:\n\n- Der Datensatz umfasst 303 Reihen und 14 Spalten\n- Der Speicherplatz betr\u00e4gt 33.2 KB\n- Bis auf das Attribut \"oldpeak\" liegen alle weiteren Spalten im \"int64\" Datenformat vor\n\nAlle kategorischen Attribute wurden bereits in numerische Dummy-Variablen umgewandelt.","97b0166d":"**Interpretation**: Entgegen der g\u00e4ngigen Vermutung, dass anginale Schmerzen stark mit Herzkrankheiten korrelieren, sind vor allem nicht-angila und untypische Schmerzen Zeichen f\u00fcr eine Herzkrankheit.","7c82ad33":"#### Interpretation der zus\u00e4tzlichen Report-Ergebnisse:\n\n- Im Datensatz befindet sich ein Duplikat, welches aus Gr\u00fcnden der Repr\u00e4sentativit\u00e4t entfernt werden sollte\n- Das Attribut \"oldpeak\" ist in der Verteilung seiner Werte linksverzerrt, da 32,7% aller Datens\u00e4tze den Wert \"0\" enthalten. \n\nHinweis: Die verbleibenden \"zero\" Warnungen bei Attributen beziehen sich auf kategrosiche Variablen und sind in diesem Fall nicht negativ auszuwerten.","5e75db7d":"### Kritische Betrachtung\n\nSowohl die Auswahl der Parameter, als auch die obige Evaluation der Modelle wurde haupts\u00e4chlich anhand der Performance Metrik \"Accuracy\" durchgef\u00fchrt. Die Akkuratheit stellt eine repr\u00e4sentative Kennzahl dar, wenn eine m\u00f6glichst gleihe Verteilung der Labels vorliegt. Auch wenn diese Bedingung durch den Datensatz gut erf\u00fcllt ist, sollten bei einer tiefergrehenden Beurteilung auch andere Metriken, wie beispielsweise die erw\u00e4hnte \"True Negative Rate\" in Betracht gezogen werden.\n\n#### Kleiner Datensatz\n\nIm Vergleich zu g\u00e4ngigen Machine Learning Projekten handelt sich bei dem verwendeten Datensatz mit ca. 300 Eintr\u00e4gen um einen sehr kleinen Datensatz, dessen Nutzung einige Risiken birgt. Die Accuracy von \u00fcber 90% sollte daher unter den Risiken einer geringeren Repr\u00e4sentativit\u00e4t und der Beeintr\u00e4chtigung der F\u00e4higkeit der Generalisierung des Modells betrachtet werden. Der Datensatz repr\u00e4sentiert nur einen kleinen Teil der realen Welt und spiegelt damit nur wenige Krankheitsmuster wider. Es besteht damit die Gefahr des Overifittings, das bedeutet, dass das Modell m\u00f6glicherweise zu stark an die gegebenen Daten angepasst ist und bei neuen, ungesehenen Daten schlechtere Vorhersagen trifft.","4bb768e6":"Parameter Tuning um eine h\u00f6here Accuracy zu erzielen:\n    \nParameter:\n- Modelspezifisch:\n    - Regularization\/Penalty\n    - Learning Rate\n- Datenspezifisch\n    - Anzahl der (besten) Features","0f684420":"## 2. Feature Selection","bc9ba740":"Initialisieren der Pipeline und erster Test des DecisionTree Classifiers mit dem gesplitteten Datensatz:\n\n(Output: Accuracy gemessen am Testdatensatz)","6f5d3538":"Erster Einblick in den Datensatz:","49f87f07":"####  1.1.1 Allgemeine Patienteninformationen","7ccea694":"Der \\\"Dummy Classifier\\\" hat eine Accuracy von 59%, damit ist er \"nur knapp\" besser als eine zuf\u00e4llige Klassifizierung, da er \u00fcber 40% der Labels nicht richtig zuordnet. Da jedoch keine False Positives auftreten, wird eine Specificity von 1 erreicht.","9c8f6c9d":"# Heart Disease Classification\n\nEin weit verbreiteter Anwendungsbereich von Machine Learning ist die medizinische Diganostik, die durch ihre Interaktion mit k\u00fcnstlicher Intelligenz tiefgr\u00fcndigere Zusammenh\u00e4nge zwischen Krankheiten und ihren Ursachen aufdecken kann. Birgt die maschinell gest\u00fctzte Diagnose selbst einige Risiken, profitieren \u00c4rzte dennoch durch die Unterst\u00fctzung eines repr\u00e4sentativen, trainierten Modells, da Erfahrungswerte aus Millionen von Patientendaten zu einer Diagnose heranzgezogen werden k\u00f6nnen.\n\nDie folgende Arbeit soll einen Einblick in die medizinische Anwendung von Machine Learning am Beispiel der Erkennung von Herzkrankheiten erm\u00f6glichen. Die Diagnose von Herzkrankheiten st\u00fctzt sich auf eine Reihe k\u00f6rperlicher Anzeichen und klinischer Testergebnisse, wie z.B. EKG Tests, Herz-Scans oder Bluttests. \n\nDer im Folgenden verwendete Datensatz beinhaltet eine Auswahl von Attributen, die Ergebnisse solcher Tests und zus\u00e4tzliche Patienteninformationen wie Alter und Geschlecht beinhalten. Auf Basis dieser Daten soll ein Modell des Supervised Learning, die bin\u00e4re Klassifikation, das Vorliegen einer Herzkrankheit beurteilen. ","2c9c1864":"### Vorgehensweise Modeling\n\nAufbau einer Pipeline:\n- Feature Selection ('kbest')\n- Scaling ('scaler')\n- Classifier\n\nSetzen der Parameter:\n- Anzahl der (besten) Features, die verwendet werden sollen\n- Classifier spezifische Parameter (n_jobs=-1 erlaubt maximal m\u00f6gliche Anzahl an parallelen Prozessen)\n\nFitting \/ Training der Pipeline:\n- Aufrufen der fit() Methode mit den Trainingsdaten\n\nScore der Pipeline mit dem ausgew\u00e4hlten Classifier:\n- Aufrufen der score() Methode mit den Testdaten\n\nHyperparameter Tuning:\n- In CLASSIFIERNAME_params werden m\u00f6gliche Parameter definiert, welche sp\u00e4ter von der Grid Search kombiniert werden\n- Aufrufen der fit() Methode der GridSearchCV mit den Trainingsdaten (trotz integrierter Cross Validation)\n\nAuswerten der Grid Search\n- Anzeigen der besten Parameterkombinationen\n- Anzeigen der besten erzielten Accuracy durch Abfragen des best_score_ Attributs der Grid Search, welches die Accuracy des besten Models enth\u00e4lt\n    - Trainingsdaten, GRIDSEARCH.best_score_\n- Verifikation des Ergebnisses durch Aufrufen der score() Methode des besten ermittelten Models \n    - Testdaten, GRIDSEARCH.best_estimator_.score(X_test,y_test)\n- Aufrufen der score() Methode des besten Classifiers, welcher durch die Grid Search bestimmt wurde. Hierzu werden die Testdaten verwendet, welche hier jedoch eher als Validation Set verwendet werden\n\nDa die Grid Search eine integrierte Cross Validation durchf\u00fchrt, k\u00f6nnen die bei Seite gelegten Testdaten als Validationset verwendet werden. Durch die unterschiedlichen Folds wird Overfitting weitesgehend verhindert. Da manche Folds jedoch schlechter performen als andere, ist eine geringere Accuracy als bei der vorherigen Prediction (fit(Trainingsdaten), score(Testdaten), keine Cross Validation) zu erwarten. Die Aussagekraft ist jedoch h\u00f6her, da es das Generalisieren neuer Daten besser wiederspiegelt."}}