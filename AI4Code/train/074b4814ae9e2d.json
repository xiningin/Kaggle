{"cell_type":{"4813d85d":"code","63f7df3d":"code","43fbf5e1":"code","c3a8bcaf":"code","479bc7c0":"code","4c2e2ef0":"code","a387499f":"code","5902b69d":"code","bc9c4232":"code","2419a591":"code","3ce36b15":"code","52e62c6f":"code","27435510":"code","aabee00a":"code","b59f492f":"code","b822545b":"code","72d4b5a9":"code","99277ff1":"code","3dcf6ec6":"code","3413810b":"code","d761104f":"code","c2ad0577":"code","778aac23":"code","a52c4d6a":"code","10b4b769":"code","4ce65efc":"code","595a0afd":"code","52e48195":"code","68dad9d1":"code","6ca5ccda":"code","a9a7425d":"code","662961b1":"code","fc342b6c":"code","2a6d571a":"code","c93fae34":"code","e356c239":"markdown","e60b86b2":"markdown","25b26adc":"markdown","07a3fd26":"markdown","1666267f":"markdown","3b3f6712":"markdown","18d2230a":"markdown","47643dd8":"markdown","e836b22b":"markdown","2cc50214":"markdown","f2c2f7c0":"markdown"},"source":{"4813d85d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","63f7df3d":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","43fbf5e1":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","c3a8bcaf":"file = '\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv'\ndf = pd.read_csv(file)\ndf.head()","479bc7c0":"df.dtypes","4c2e2ef0":"df.describe()","a387499f":"df.isnull().any()","5902b69d":"df['quality'].value_counts()","bc9c4232":"label = df['quality'].unique()\nheight = df['quality'].value_counts()\nplt.bar(label,height)","2419a591":"X = df.iloc[:,:-1]\nX.head()","3ce36b15":"sns.pairplot(X)","52e62c6f":"corrmat = df.corr()\nf, ax = plt.subplots(figsize =(9, 8)) \nsns.heatmap(corrmat, ax = ax, cmap =\"YlGnBu\", linewidths = 0.1) ","27435510":"X_s = X[['alcohol','sulphates']]","aabee00a":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX_s = sc_X.fit_transform(X_s)","b59f492f":"y=df['quality']","b822545b":"# Spliting the dataset between a train and a test set\nfrom sklearn.model_selection import train_test_split\nX_train_s, X_test_s, y_train_s, y_test_s = train_test_split(X_s,y, test_size = 0.2, random_state = 0)","72d4b5a9":"print(X_train_s.shape, y_train_s.shape)\n","99277ff1":"from sklearn.linear_model import LinearRegression\nreg = LinearRegression().fit(X_train_s,y_train_s)","3dcf6ec6":"reg.score(X_test_s,y_test_s)","3413810b":"df_n = df","d761104f":"df_n.shape","c2ad0577":"df_n['Good'] = df_n['quality']>=6","778aac23":"df_n['Good'].sum()","a52c4d6a":"df_n.shape","10b4b769":"Y = pd.get_dummies(df_n['Good'], drop_first = True) ## Tip Use drop_first = True do avoid the dummies trap\nY.head()","4ce65efc":"Y.sum()","595a0afd":"X = df_n[['fixed acidity','residual sugar','chlorides','free sulfur dioxide','density','pH','sulphates','alcohol']]","52e48195":"from sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\nX= sc_X.fit_transform(X)","68dad9d1":"# Division du dataset en train et un test set \nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,Y, test_size = 0.2, random_state = 0)","6ca5ccda":"from sklearn.linear_model import LogisticRegression\nclf = LogisticRegression(random_state=0).fit(X_train, y_train)","a9a7425d":"clf.score(X_test,y_test)","662961b1":"y_pred =  clf.predict(X_test)","fc342b6c":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix, accuracy_score\nprint(classification_report(y_test,y_pred))\n","2a6d571a":"print(accuracy_score(y_test,y_pred))","c93fae34":"print(confusion_matrix(y_test,y_pred))","e356c239":"# Data Exploration","e60b86b2":"I start by isolating the paramaters in my data in a matrice called X","25b26adc":"For the 'quality' factor which is the output we are trying to predict, there is no obvisous correlation between parameters so I decide to try to work on a smaller set of parameters for my mutltiparameter regression","07a3fd26":"# Multiparameter regression","1666267f":"This method doesn't give satisfactory results. A correlation factor of 0,28 is very low and suggest the model is not good a perdicting wine quality","3b3f6712":"\n# Classification method","18d2230a":"Let's create a new colomun called 'Good'. The values of this colomun are set to True when the wine is of quality >=6","47643dd8":"I tried to work on a limited parameter dataset. I chose those that seemed to have the strongest correlation with 'wine quality' in the graphs above.","e836b22b":"# Searching for parameter correlation","2cc50214":"Precision for 1 is of 0.79 which means that on the test set 79% of the time the algoritms predicts accurately that the wine is of good quality\nrecall for 1 is of 0.71 wich means that on the test set the algorithms is able to predict 71% of all good wines in the test set\n\nThe results for predicting wine quality using a clustering method is higher than through a multiparameter regression","f2c2f7c0":"I call X_s my new parameter matrix"}}