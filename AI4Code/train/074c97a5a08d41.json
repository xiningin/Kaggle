{"cell_type":{"42880d8e":"code","5371cbb0":"code","cba36644":"code","601fd6c5":"code","b929f608":"code","3764c3bf":"code","04ad9d79":"code","3e12bc65":"code","cffa00d3":"code","240d167b":"code","6f5dd9af":"code","70e5dc9e":"code","7f42739a":"code","598c186a":"code","cd469adf":"code","6ff8d45d":"code","830252cf":"code","7bee9d84":"code","5d0845bc":"code","8d88045b":"code","69cc3a4c":"code","789bbfe9":"code","35cdc181":"code","931e7342":"markdown","58091277":"markdown","40330bdd":"markdown","e44253f7":"markdown","5a04b5bc":"markdown","dff8af85":"markdown","613a6aa9":"markdown","c40491c1":"markdown","99a24f56":"markdown","de5c9c7c":"markdown","c4e6234f":"markdown","81c70d3c":"markdown","bd92fa81":"markdown","98aa2ba4":"markdown"},"source":{"42880d8e":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport re\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom sklearn.model_selection import train_test_split, cross_val_score, GridSearchCV\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder, OneHotEncoder, Binarizer\nfrom sklearn.linear_model import LinearRegression, LogisticRegression, Ridge, Lasso, ElasticNet\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.tree import export_graphviz\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.decomposition import PCA\n\nfrom lightgbm import LGBMRegressor, plot_importance\n\nimport graphviz","5371cbb0":"# Load data\ndata = pd.read_csv('..\/input\/equity-residential-apartment-data\/Equity_Apartments_Data.csv')\ndata","cba36644":"# Check wheter data contains NaN or Null\ndata.isnull().sum()","601fd6c5":"# Drop rows which contain NaN or Null\ndata.dropna(axis=0, inplace=True)\ndata.reset_index(drop=True, inplace=True)\ndata","b929f608":"# Check what columns does data have\ndata.columns","3764c3bf":"# Drop unnecessary columns\ncolumns_drop = ['Unnamed: 0', 'Move_in_date', 'building_id', 'unit_id', 'URL', 'Day_Recorded', 'Amenity', 'Apartment Name', 'Address', 'Day_of_the_week_recorded', 'Unique_ID', 'Estiamted_Vacancy']\ndata.drop(columns=columns_drop, axis=1, inplace=True)\ndata","04ad9d79":"# Check distribution of 'Price'\nsns.distplot(data['Price'])\nplt.title('Distribution of Price')","3e12bc65":"# Plot pie charts indicate features of inside \nfig, axs = plt.subplots(ncols=3, figsize=(15, 5))\n\ninside_features = ['Beds', 'Baths', 'Floor']\n\nfor i, feature in enumerate(inside_features):\n    cols=i%3\n    pd.value_counts(data[feature]).plot.pie(autopct=\"%.1f%%\", ax=axs[cols])\n\nplt.suptitle('Distribution of inside features')\nplt.tight_layout()","cffa00d3":"# Plot pie charts indicate features of inside \nfig, axs = plt.subplots(ncols=4, figsize=(20, 5))\n\nexposures = ['Northern_Exposure', 'Southern_Exposure', 'Eastern_Exposure', 'Western_Exposure']\n\nfor i, exposure in enumerate(exposures):\n    cols=i%4\n    pd.value_counts(data[exposure]).plot.pie(autopct=\"%.1f%%\", ax=axs[cols])\n\nplt.suptitle('Distribution of directional exposures')\nplt.tight_layout()","240d167b":"# Plot pie charts indicate extra features\nfig, axs = plt.subplots(nrows=2, ncols=4, figsize=(20, 10))\n\nextras = ['Balcony', 'Walk_In_Closet', 'Fireplace', 'City_Skyline', 'Kitchen_Island', 'Stainless_Appliances', 'Renovated', 'Office_Space']\n\nfor i, extra in enumerate(extras):\n    rows=int(i\/4)\n    cols=i%4\n    pd.value_counts(data[extra]).plot.pie(autopct=\"%.1f%%\", ax=axs[rows][cols])\n\nplt.suptitle('Distribution of extra features')\nplt.tight_layout()","6f5dd9af":"# Correlation Heatmap\nfig, ax = plt.subplots(figsize=(18, 15))\nplt.title('Correlation of residential features')\nsns.heatmap(data.corr(), annot=True, fmt='.1g', linewidths=.3, cmap='YlGnBu')","70e5dc9e":"# Check variances by features\ndecom_features = ['Beds', 'Baths', 'sq.ft', 'Balcony', 'Fireplace', 'Office_Space']\n\nscaler = StandardScaler()\ndata_scaled = scaler.fit_transform(data[decom_features])\npca = PCA(n_components=2)\npca.fit(data_scaled)\nprint('Variance by PCA components: ', pca.explained_variance_ratio_)\nprint('Total Variance by PCA: ', np.round(pca.explained_variance_ratio_.sum(), 3))","7f42739a":"# Process One-Hot Encoding\ndata_ohe = pd.get_dummies(data)\ndata_ohe","598c186a":"# Split datasets\nX = data_ohe.iloc[:, 1:]\ny = data_ohe.iloc[:, 1]\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=11)\n\nprint('Shape of X_train: ', X_train.shape)\nprint('Shape of X_test: ', X_test.shape)\nprint('Shape of y_train: ', y_train.shape)\nprint('Shape of y_test: ', y_test.shape)","cd469adf":"# Utility Function\ndef get_rmse(model):\n    pred = model.predict(X_test)\n    mse = mean_squared_error(y_test , pred)\n    rmse = np.sqrt(mse)\n    print('{0} RMSE: {1}'.format(model.__class__.__name__, np.round(rmse, 3)))\n    return rmse\n\ndef get_rmses(models):\n    rmses = [ ]\n    for model in models:\n        rmse = get_rmse(model)\n        rmses.append(rmse)\n    return rmses","6ff8d45d":"# Utility Function\ndef get_avg_rmse_cv(models):\n    for model in models:\n        rmse_list = np.sqrt(-cross_val_score(model, X, y,\n                                             scoring=\"neg_mean_squared_error\", cv = 5))\n        rmse_avg = np.mean(rmse_list)\n        print('\\n{0} List of RMSE by CV: {1}'.format( model.__class__.__name__, np.round(rmse_list, 3)))\n        print('{0} Average of RMSE by CV: {1}'.format( model.__class__.__name__, np.round(rmse_avg, 3)))","830252cf":"# Create estimators\nlr_reg = LogisticRegression(solver='liblinear')\nridge_reg = Ridge()\nlasso_reg = Lasso()\n\n# Fit, Predict and Evaluate by estimators\nlr_reg.fit(X_train, y_train)\nridge_reg.fit(X_train, y_train)\nlasso_reg.fit(X_train, y_train)\n\nmodels = [lr_reg, ridge_reg, lasso_reg]\nget_rmses(models)","7bee9d84":"# Accuracy Score\nprint('Accuracy Score of Logistic Regression by train set', np.round(lr_reg.score(X_train, y_train), 3))\nprint('Accuracy Score of Logistic Regression by test set', np.round(lr_reg.score(X_test, y_test), 3))","5d0845bc":"# Cross validate for 5 time by each model \nmodels = [lr_reg, ridge_reg, lasso_reg]\nget_avg_rmse_cv(models)","8d88045b":"# Hyperparamter Tuning\ndef print_best_params(model, params):\n    grid_model = GridSearchCV(model, param_grid=params, \n                              scoring='neg_mean_squared_error', cv=5)\n    grid_model.fit(X, y)\n    rmse = np.sqrt(-1* grid_model.best_score_)\n    print('{0} Optimized Average RMSE by CV 5 times : {1}, Best alpha:{2}'.format(model.__class__.__name__,\n                                        np.round(rmse, 4), grid_model.best_params_))\n    return grid_model.best_estimator_\n\nridge_params = { 'alpha':[0.05, 0.1, 1, 5, 8, 10, 12, 15, 20] }\nlasso_params = { 'alpha':[0.001, 0.005, 0.008, 0.05, 0.03, 0.1, 0.5, 1,5, 10] }\nbest_ridge = print_best_params(ridge_reg, ridge_params)\nbest_lasso = print_best_params(lasso_reg, lasso_params)","69cc3a4c":"# Fit for the optimized 'alpha', predict and evalute the models\nlr_reg = LogisticRegression(solver='liblinear')\nridge_reg = Ridge(alpha=0.05)\nlasso_reg = Lasso(alpha=0.01)\n\n# Fit, Predict and Evaluate by estimators\nlr_reg.fit(X_train, y_train)\nridge_reg.fit(X_train, y_train)\nlasso_reg.fit(X_train, y_train)\n\nmodels = [lr_reg, ridge_reg, lasso_reg]\nget_rmses(models)","789bbfe9":"# Fit, predict and evalutate for LighbGBM model\nlgbm_reg = LGBMRegressor(n_estimators=1000, learning_rate=0.05, num_leaves=4, subsample=0.6, colsample_bytree=0.4, reg_lambda=10, n_jobs=-1)\nlgbm_params = {'n_estimators':[1000]}\n\nlgbm_reg.fit(X_train, y_train)\nlgbm_pred = lgbm_reg.predict(X_test)\nbest_lgbm = print_best_params(lgbm_reg, lgbm_params)","35cdc181":"# Plot Feature importance by LGBMRegressor\nfig, ax = plt.subplots(figsize=(10, 12))\nplot_importance(lgbm_reg, ax=ax)","931e7342":"# Decomposition","58091277":"# Visualization","40330bdd":"## LightGBM","e44253f7":"# Outline\n1. Goal: Prediction of residential prices based on various features\n2. Info: We can see results of prediction by not only base estimators but also LighbGBM.","5a04b5bc":"## Hyperparamter Tuning","dff8af85":"## Dataset Overview\n|           Index          |                         Description                         |\n|:------------------------:|:-----------------------------------------------------------:|\n|           Price          | Price (recorded daily)                                      |\n|           Beds           | # of Beds in an apartment. 0 means a studio apt.            |\n|           Baths          | # of baths in an apartment.                                 |\n|           sq.ft          | # of square feet.                                           |\n|           Floor          | Floor                                                       |\n|       Move_in_date       | Date the apartment was available for move in.               |\n|        building_id       | for apartments that had multiple buildings.                 |\n|          unit_id         | The apartment unit number.                                  |\n|            URL           | URL that was scraped.                                       |\n|       Day_Recorded       | Day the row of data was scraped.                            |\n|          Amenity         | Text field describing different apartment features.         |\n|      Apartment Name      | Name of the apartment complex.                              |\n|          Address         | Address of apartment complex.                               |\n|           City           | City the apartment is in.                                   |\n|           Units          | Number of units the apartment complex as a whole has.       |\n|     Northern_Exposure    | 1 if apartment has northern exposure, 0 otherwise.          |\n|     Southern_Exposure    | 1 if apartment has southern exposure, 0 otherwise.          |\n|     Eastern_Exposure     | 1 if apartment has eastern exposure, 0 otherwise            |\n|     Western_Exposure     | 1 if apartment has western exposure, 0 otherwise.           |\n|          Balcony         | 1 if apartment has balcony, 0 otherwise.                    |\n|      Walk_In_Closet      | 1 if apartment has walk in closet, 0 otherwise.             |\n|         Fireplace        | 1 if apartment has fireplace, 0 otherwise.                  |\n|       City_Skyline       | 1 if apartment has city skyline, 0 otherwise.               |\n|      Kitchen_Island      | 1 if apartment has kitchen island, 0 otherwise.             |\n|   Stainless_Appliances   | 1 if apartment has stainless steel appliances, 0 otherwise. |\n|         Renovated        | 1 if apartment has been rennovated, 0 otherwise.            |\n|       Office_Space       | 1 if apartment has office space, 0 otherwise.               |\n|    Days_Till_Available   | Days until you could move in.                               |\n| Day_of_the_week_recorded | What day of the week was the data scraped.                  |\n|         Unique_ID        | Unique ID to identify the same apartment over many days.    |\n|     Estiamted_Vacancy    | # of obvs that day\/ total units for that apartment          |","613a6aa9":"# Import libraries and data","c40491c1":"### Description\nWe could see the better performance for Lasso model. (0.365 --> 0.028)","99a24f56":"# Conclusion\nGenerally, the price of resdiential areas were most affected by the inside features of each apartment than any other features.  \nUnexpectedly, appliances, island of the kitchen and the closet were more lower than I expected.  \nSpecifically, about 96% of apartments are equipped with 'Kitchen Island', but the importance was remarkably low.  \nTherefore, I can say that thesedays people preferr going out for dining to eating away at home.\n\n**Thank you for you reading my Notebook!**  \nIf you have any other opinions or perspectives, don't hesitate and just commment to my notebook","de5c9c7c":"## Basic Estimators","c4e6234f":"### Description\nAs we already saw on the correlation heatmap, beds, sq.ft and baths were important for prediction.  \nAdditionally, 'units' was also as much important as those features.","81c70d3c":"# Data Preprocessing","bd92fa81":"# Split Datasets","98aa2ba4":"# Regression"}}