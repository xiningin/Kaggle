{"cell_type":{"761850e0":"code","4fdbba6c":"code","bd33f8d1":"code","96920c00":"code","42ad7227":"code","12e61809":"code","afba7c55":"code","aec1196e":"code","b098cd58":"code","a0a90fd2":"code","839a2914":"code","c11dfef4":"code","ec5fa999":"code","fa5d58e9":"code","91fb85fa":"code","dab265a8":"code","25d579f8":"code","14fcb3cf":"markdown","b443ca28":"markdown","fc3bf347":"markdown","3deaefeb":"markdown","9498e5d3":"markdown","67fa7376":"markdown","c3315117":"markdown","fcebd529":"markdown"},"source":{"761850e0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4fdbba6c":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np\n\n%matplotlib inline\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","bd33f8d1":"df = pd.read_csv(\"..\/input\/crime-in-vancouver\/crime.csv\")\ndf.head()","96920c00":"df.info()\n","42ad7227":"df.shape","12e61809":"df.YEAR.value_counts().plot(kind=\"bar\", color=[\"salmon\", \"lightblue\"])","afba7c55":"df.isna().sum()\n","aec1196e":"corr_matrix = df.corr()\nplt.figure(figsize=(15, 15))\n\nplt.title(\"Correlation Graph\")\n\ncmap = sns.diverging_palette( 1000, 120, as_cmap=True)\nsns.heatmap(corr_matrix, annot=True, fmt='.2f',  linewidths=.8, cmap='coolwarm');","b098cd58":"from sklearn.preprocessing import StandardScaler\n\ns_sc = StandardScaler()\ncol_to_scale = ['YEAR', 'MONTH', 'DAY', 'MINUTE']\ndf[col_to_scale] = s_sc.fit_transform(df[col_to_scale])","a0a90fd2":"df.head()\n","839a2914":"from sklearn.metrics import accuracy_score, confusion_matrix, precision_score, recall_score, f1_score , classification_report\nimport seaborn as sns\nclasses=['healthy','Un-healthy']\n\ndef print_score(clf, X_train, y_train, X_test, y_test, train=True):\n    if train:\n        pred = clf.predict(X_train)\n        print(\"Train Result:\\n================================================\")\n        print(f\"Accuracy Score: {accuracy_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(\"Classification Report:\", end='')\n        print(f\"\\tPrecision Score: {precision_score(y_train, pred) 100:.2f}%\")\n       # recall=recall_score(y_train, pred) \n        print(f\"\\t\\t\\tRecall Score: {recall_score(y_train, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tF1 score: {f1_score(y_train, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(f\"Confusion Matrix: \\n {confusion_matrix(y_train, pred)}\\n\")\n        \n    elif train==False:\n        pred = clf.predict(X_test)\n        print(\"Test Result:\\n================================================\")        \n        print(f\"Accuracy Score: {accuracy_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        print(\"Classification Report:\", end='')\n        print(f\"\\tPrecision Score: {precision_score(y_test, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tRecall Score: {recall_score(y_test, pred) * 100:.2f}%\")\n        print(f\"\\t\\t\\tF1 score: {f1_score(y_test, pred) * 100:.2f}%\")\n        print(\"_______________________________________________\")\n        sns.heatmap(confusion_matrix(y_test, pred), annot= True, cmap='YlGnBu',fmt = 'g')\n        print(classification_report(y_test,pred))\n        cm=(confusion_matrix(y_test,pred))\n       # ax.xaxis.set_label_position('top')\n        plt.tight_layout()\n        plt.title('Confusion matrix for Decision Tree Model', y = 1.1)\n        plt.ylabel('Actual label')\n        plt.xlabel('Predicted label')\n        plt.show()\n        total = sum(sum(cm))\n        acc = (cm[0, 0] + cm[1, 1]) \/ total\n        sensitivity = cm[0, 0] \/ (cm[0, 0] + cm[0, 1])\n        specificity = cm[1, 1] \/ (cm[1, 0] + cm[1, 1])\n       # print(cm)\n\n        FP = cm.sum(axis=0) - np.diag(cm)  \n        FN = cm.sum(axis=1) - np.diag(cm)\n        TP = np.diag(cm)\n        TN = cm.sum() - (FP + FN + TP)\n\n        FP = FP.astype(float)\n        FN = FN.astype(float)\n        TP = TP.astype(float)\n        TN = TN.astype(float)\n\n        # Sensitivity, hit rate, recall, or true positive rate\n        TPR = TP\/(TP+FN)\n        print('Sensitivity (TPR) : ',TPR)\n        # Specificity or true negative rate\n        TNR = TN\/(TN+FP) \n        print('Specificity (TNR) : ',TNR)\n        # Overall accuracy\n        print(\" Overall accuracy\")\n        ACC = (TP+TN)\/(TP+FP+FN+TN)\n        print('Accuracy : ',ACC)\n        print(\"Accuracy: {:.4f}\".format(acc))\n        print(\"Average Sensitivity: {:.4f}\".format(sensitivity))\n        print(\"Average Specificity: {:.4f}\".format(specificity))\n        print('\\n')\n        \n        conf_matrix=cm\n        print(\"=========================================\")\n        # save confusion matrix and slice into four pieces\n        TP = conf_matrix[1][1]\n        TN = conf_matrix[0][0]\n        FP = conf_matrix[0][1]\n        FN = conf_matrix[1][0]\n        print('True Positives:', TP)\n        print('True Negatives:', TN)\n        print('False Positives:', FP)\n        print('False Negatives:', FN)\n\n        # calculate accuracy\n        conf_accuracy = (float (TP+TN) \/ float(TP + TN + FP + FN))\n\n        # calculate mis-classification\n        conf_misclassification = 1- conf_accuracy\n\n        # calculate the sensitivity\n        conf_sensitivity = (TP \/ float(TP + FN))\n        # calculate the specificity\n        conf_specificity = (TN \/ float(TN + FP))\n\n        # calculate precision\n        conf_precision = (TN \/ float(TN + FP))\n        # calculate f_1 score\n        conf_f1 = 2 * ((conf_precision * conf_sensitivity) \/ (conf_precision + conf_sensitivity))\n        print('-'*50)\n        print(f'Accuracy: {round(conf_accuracy,2)}') \n        print(f'Mis-Classification: {round(conf_misclassification,2)}') \n        print(f'Sensitivity: {round(conf_sensitivity,2)}') \n        print(f'Specificity: {round(conf_specificity,2)}') \n        print(f'Precision: {round(conf_precision,2)}')\n        print(f'f_1 Score: {round(conf_f1,2)}')","c11dfef4":"from sklearn.metrics import roc_curve\nfrom sklearn.metrics import auc\ndef plotting(true,pred):\n    fig,ax=plt.subplots(1,2,figsize=(15,5))\n    precision,recall,threshold = precision_recall_curve(true,pred[:,1])\n    ax[0].plot(recall,precision,'g--')\n    ax[0].set_xlabel('Recall')\n    ax[0].set_ylabel('Precision')\n    ax[0].set_title(\"Average Precision Score : {}\".format(average_precision_score(true,pred[:,1])))\n    fpr,tpr,threshold = roc_curve(true,pred[:,1])\n    ax[1].plot(fpr,tpr)\n    ax[1].set_title(\"AUC Score is: {}\".format(auc(fpr,tpr)))\n    ax[1].plot([0,1],[0,1],'k--')\n    ax[1].set_xlabel('False Positive Rate')\n    ax[1].set_ylabel('True Positive Rate')","ec5fa999":"from sklearn.model_selection import train_test_split\n\nX = df.drop('YEAR', axis=1)\ny = df.YEAR\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)","fa5d58e9":"from sklearn.neighbors import KNeighborsClassifier\n\nknn_classifier = KNeighborsClassifier()\nknn_classifier.fit(X_train, y_train)\n\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=True)\nprint_score(knn_classifier, X_train, y_train, X_test, y_test, train=False)","91fb85fa":"from sklearn.svm import SVC\n\n\nsvm_model = SVC(kernel='rbf', gamma=0.1, C=1.0, probability=True)\nsvm_model.fit(X_train, y_train)","dab265a8":"print_score(svm_model, X_train, y_train, X_test, y_test, train=True)\nprint_score(svm_model, X_train, y_train, X_test, y_test, train=False)","25d579f8":"from sklearn.neural_network import MLPClassifier\nNN=MLPClassifier(hidden_layer_sizes=(10,50),momentum=0.9,solver='sgd',random_state=42)\n               \nNN.fit(X_train, y_train)\n\nprint_score(NN, X_train, y_train, X_test, y_test, train=True)\nprint_score(NN, X_train, y_train, X_test, y_test, train=False) ","14fcb3cf":"Loading the data","b443ca28":"4. Applying machine learning algorithms","fc3bf347":" * # 3. Data Processing\nPerform Feature Standerd Scalling","3deaefeb":"* # 2. Correlation Matrix**","9498e5d3":"# Function to plot ROC and Precision Recall Curve for combination of all models\n","67fa7376":"1. #  2. Decision Tree Classifier ","c3315117":"Standardize features by removing the mean and scaling to unit variance\n\nThe standard score of a sample x is calculated as:\n\nz = (x - u) \/ s","fcebd529":"## 1. K-nearest neighbors"}}