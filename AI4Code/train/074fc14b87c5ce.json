{"cell_type":{"d7720bc8":"code","fa6a43a0":"code","c6602f79":"code","10cbcac1":"code","e9a2a913":"code","afb010b7":"code","ac5a4122":"code","63598825":"code","2bafe501":"code","bb776b6c":"code","347c86f2":"code","d7f7e22b":"code","83126748":"code","3e564a48":"code","96f24710":"code","3e9f063b":"code","40017ed2":"code","fa809200":"code","a59878ea":"code","0f2c46c7":"code","b05d8ab5":"code","9fb3572b":"code","ec525c08":"code","3fdbf1a5":"code","e0bf71f7":"code","72448b1f":"code","ffb328de":"code","c1670f5a":"code","952d1aa9":"code","d3427930":"code","6fd95106":"code","55aa5a45":"code","ff9f75e1":"code","f30a6518":"code","c17d87f1":"code","3ba5d166":"code","9ac0b8b2":"code","a8f9542e":"code","41ddbd04":"code","476d06ef":"code","b390d45b":"code","c03059ae":"code","7dd3c50f":"markdown","a35d5d05":"markdown","361fb56b":"markdown","4c2b382a":"markdown","1c6e479a":"markdown","d06b3db7":"markdown","70a41700":"markdown","caa48b2f":"markdown","730f89f7":"markdown","f3fd30c4":"markdown","14c37349":"markdown","63cb290b":"markdown","24346a09":"markdown","bd0f144d":"markdown","d3d1daca":"markdown"},"source":{"d7720bc8":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","fa6a43a0":"train = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\nx_sub = pd.read_csv('..\/input\/digit-recognizer\/test.csv')","c6602f79":"train.shape","10cbcac1":"x_sub.shape","e9a2a913":"x_sub = x_sub.values # Transforming x_sub into a NumPy array","afb010b7":"y_train = train['label']","ac5a4122":"x_train = train.drop('label', axis=1).values","63598825":"#Not a necessary step, but it`s nice to visualize the data and do a sanity-check\nsingle_image = x_train[0]\nsingle_image = single_image.reshape(28,28)\nplt.imshow(single_image, cmap='gray') #Using gray colormap just because it looks neat","2bafe501":"x_train[0].max()","bb776b6c":"x_train[0].min()","347c86f2":"#Normalizing the data by dividing it by it`s max value. Notice that we do not normilize the labels \nx_train = x_train \/ 255\nx_sub = x_sub \/ 255","d7f7e22b":"x_train[1].max()","83126748":"from tensorflow.keras.utils import to_categorical","3e564a48":"y_train = to_categorical(y_train)","96f24710":"y_train[0]","3e9f063b":"y_train.shape","40017ed2":"x_train.shape","fa809200":"x_train = x_train.reshape(42000,28,28,1)","a59878ea":"x_sub = x_sub.reshape(28000,28,28,1)","0f2c46c7":"x_train.shape","b05d8ab5":"from sklearn.model_selection import train_test_split","9fb3572b":"#Splitting the dataset into training and validation sets\nX_train, X_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.20, random_state=101)","ec525c08":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense, Conv2D, MaxPool2D, Flatten","3fdbf1a5":"model = Sequential()\n\n#Convolutional layer\nmodel.add(Conv2D(filters=32, kernel_size=(4,4), input_shape=(28,28,1), activation='relu'))\n#Pooling level (2,2)\nmodel.add(MaxPool2D())\n\n\n#Flatten (28,28,1) to (784,)\nmodel.add(Flatten())\n\n#Single dense hidden layer of 128 neurons. \nmodel.add(Dense(units=128, activation='relu'))\n\n#Output layer for 10 mutually exclusive classes\nmodel.add(Dense(units=10, activation='softmax'))\n\n#https:\/\/keras.io\/metrics\/\nmodel.compile(loss='categorical_crossentropy',\n              optimizer='adam',\n              metrics=['accuracy']\n)","e0bf71f7":"model.summary()","72448b1f":"from tensorflow.keras.callbacks import EarlyStopping,TensorBoard","ffb328de":"#Training will be stopped if val_loss stops dropping for 2 epochs\nearly_stop = EarlyStopping(monitor='val_loss', patience=2, mode='min')","c1670f5a":"from datetime import datetime","952d1aa9":"#Saving the logs for the TensorBoard\ndate = datetime.now().strftime(\"%Y-%m-%d--%H%M\")","d3427930":"log_directory = 'logs\\\\fit' + '\\\\' + date\n\nboard = TensorBoard(log_dir=log_directory,histogram_freq=1,\n    write_graph=True,\n    write_images=True,\n    update_freq='epoch',\n    profile_batch=2,\n    embeddings_freq=1)","6fd95106":"model.fit(X_train, y_train, epochs=15, validation_data=(X_val, y_val), callbacks=[board,early_stop])","55aa5a45":"model.metrics_names","ff9f75e1":"losses = pd.DataFrame(model.history.history)","f30a6518":"losses.head()","c17d87f1":"losses[['accuracy','val_accuracy']].plot()","3ba5d166":"losses[['loss','val_loss']].plot()","9ac0b8b2":"predictions = pd.DataFrame(model.predict_classes(x_sub))","a8f9542e":"predictions = predictions.reset_index()","41ddbd04":"predictions.columns = ['ImageId','Label']","476d06ef":"predictions['ImageId'] = predictions['ImageId'] + 1","b390d45b":"predictions.head()","c03059ae":"predictions.to_csv(path_or_buf='results.csv', index=False )","7dd3c50f":"* 0 = [1, 0, 0, 0, 0, 0, 0, 0, 0, 0] \n* 1 = [0, 1, 0, 0, 0, 0, 0, 0, 0, 0] \n* 4 = [0, 0, 0, 0, 1, 0, 0, 0, 0, 0] \n* https:\/\/machinelearningmastery.com\/why-one-hot-encode-data-in-machine-learning\/","a35d5d05":" Use ***tensorboard --logdir logs\\fit  ***\nto run Tensorboard, \nthen check http:\/\/localhost:6006\/","361fb56b":"## Evaluating the model","4c2b382a":"## Creating the model","1c6e479a":"x_sub is the test data for predictions, that we will submit","d06b3db7":"## PreProcessing data","70a41700":"## Importing and visualising","caa48b2f":"### One-hot encoding labels","730f89f7":"Right now our training data is 42,000 images stored in 28 by 28 pixel array formation.\n\nWe need to add one more dimension to show we're dealing with 1 RGB channel (since technically the images are in black and white, only showing values from 0-255 on a single channel), a color image would have 3 dimensions.","f3fd30c4":"### Normalizing","14c37349":"### Reshaping","63cb290b":"### Adding Early stopping and TensorBoard","24346a09":"Here is my first attempt to solve the [MNIST](https:\/\/www.kaggle.com\/c\/digit-recognizer) problem using convolutional Netvorks. Please PM me if you have any questions or suggestions, thanks!","bd0f144d":"## Making predictions to submit","d3d1daca":"This part is a bit messy, I could not come up with a better way to output the predictions"}}