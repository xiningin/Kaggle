{"cell_type":{"366fbe17":"code","cef7dea3":"code","52074309":"code","9410d2ba":"code","401be0c4":"code","5dd9575c":"code","60c565d6":"code","f75280c6":"code","0139663f":"code","3b464258":"code","8d298889":"code","f63d75e0":"code","0e5a4126":"code","0bfcdbe1":"code","751f0ca6":"code","eff87cab":"code","0241e856":"code","fde31dc1":"code","68022b2b":"code","0698ea3a":"markdown"},"source":{"366fbe17":"import os\nprint(os.listdir(\"..\/input\/free-spoken-digit-dataset-master\/free-spoken-digit-dataset-master\/\"))","cef7dea3":"data_path = '..\/input\/free-spoken-digit-dataset-master\/free-spoken-digit-dataset-master\/recordings'","52074309":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport librosa\nimport os\nfrom os.path import isdir, join\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom scipy import signal\nfrom scipy.io import wavfile\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences","9410d2ba":"def load_speeches(path):\n    waves = [f for f in os.listdir(path) if f.endswith('.wav')]\n    labels = []\n    samples_rate = []\n    all_waves = []\n    for wav in waves:\n        sample_rate, samples = wavfile.read(join(path,wav))\n        samples_rate.append(sample_rate)\n        labels.append(wav[0])\n        all_waves.append(samples)\n    return all_waves ,samples_rate,labels","401be0c4":"def get_spectrograms(waves):\n    sample_rate = 8000\n    spectros = []\n    freqs = []\n    tims = []\n    for wav in waves:\n        frequencies, times, spectrogram = signal.spectrogram(wav, sample_rate)\n        freqs.append(frequencies)\n        tims.append(times)\n        spectros.append(spectrogram)\n    return freqs,tims,spectros\n        ","5dd9575c":"all_waves,samples_rate,labels = load_speeches(data_path)","60c565d6":"max_sequence_len = max([len(x) for x in all_waves])\nall_waves = np.array(pad_sequences(all_waves, maxlen=max_sequence_len, padding='post'))\n","f75280c6":"freqs,tims,spectros = get_spectrograms(all_waves)","0139663f":"spectros[3].shape","3b464258":"spectros = np.array(spectros)\nspectros = spectros.reshape(2000,129,81,1)","8d298889":"sns.countplot(labels)","f63d75e0":"import keras\nlabels = keras.utils.to_categorical(labels, 10)","0e5a4126":"from sklearn.model_selection import train_test_split\nX, X_test, Y, Y_test = train_test_split(spectros, labels, test_size=0.2, random_state=42)","0bfcdbe1":"from tensorflow.keras.layers import Dense, Dropout, Flatten\nfrom tensorflow.keras import Input, layers\nfrom tensorflow.keras import backend as K\nimport tensorflow as tf","751f0ca6":"X.shape[1:]","eff87cab":"model = tf.keras.models.Sequential([\n  tf.keras.layers.Conv2D(32, (5,5), activation='relu',padding='same', input_shape=(129, 81,1)),\n  tf.keras.layers.Conv2D(32,(5,5), activation='relu',padding='same'),\n  tf.keras.layers.MaxPooling2D(2, 2),\n  tf.keras.layers.Dropout((0.25)),\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n  tf.keras.layers.Conv2D(64, (3,3), activation='relu',padding='same'),\n  tf.keras.layers.MaxPooling2D(pool_size=(2, 2),strides=(2,2)),\n  tf.keras.layers.Dropout((0.25)),\n  tf.keras.layers.Flatten(),\n  tf.keras.layers.Dense(512, activation='relu'),\n  tf.keras.layers.Dropout((0.5)),\n  tf.keras.layers.Dense(10, activation='softmax')\n])","0241e856":"model.compile(optimizer=tf.keras.optimizers.RMSprop(lr=0.001, rho=0.9, epsilon=1e-08, decay=0.0), loss='categorical_crossentropy', metrics=['accuracy'])\n#model.compile(optimizer = tf.keras.optimizers.Adam( epsilon=1e-08), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","fde31dc1":"model.fit(X,Y,batch_size=512,epochs=100,validation_data=(X_test,Y_test))","68022b2b":"\n%matplotlib inline\n#-----------------------------------------------------------\n# Retrieve a list of list results on training and test data\n# sets for each training epoch\n#-----------------------------------------------------------\nhistory = model.history\nacc=history.history['acc']\nval_acc=history.history['val_acc']\nloss=history.history['loss']\nval_loss=history.history['val_loss']\n\nepochs=range(len(acc)) # Get number of epochs\n\n#------------------------------------------------\n# Plot training and validation accuracy per epoch\n#------------------------------------------------\nplt.figure(figsize=(10,7))\nplt.plot(epochs, acc, 'r')\nplt.plot(epochs, val_acc, 'b')\nplt.title('Training and validation accuracy')\nplt.legend(['Training accuracy','Validation accuracy'])\nplt.figure()\n\n#------------------------------------------------\n# Plot training and validation loss per epoch\n#------------------------------------------------\nplt.figure(figsize=(10,7))\nplt.plot(epochs, loss, 'r')\nplt.plot(epochs, val_loss, 'b')\nplt.title('Training and validation loss')\nplt.legend(['Training loss','Validation loss'])\nplt.figure()\nmax(val_acc) #the best validation accuracy the model have got","0698ea3a":"## Dataset : [free spoken digits](https:\/\/www.kaggle.com\/abdelrahmangamil\/freespokendigits)"}}