{"cell_type":{"ca263dbd":"code","0974efb7":"code","ac92d855":"code","554806ac":"code","62994b3f":"code","649b90d0":"code","20f6d8fa":"code","4340e4ca":"code","106e90b3":"code","df94be1e":"markdown"},"source":{"ca263dbd":"import os\nDataset='..\/input\/face-mask-12k-images-dataset\/Face Mask Dataset\/Train'\nData_Dir=os.listdir(Dataset)\nprint(Data_Dir)","0974efb7":"import cv2\nimport numpy as np\nfrom tensorflow.keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelBinarizer\nfrom sklearn.model_selection import train_test_split","ac92d855":"images=[]\nlabels=[]\nimg_rows=112\nimg_cols=112\nfor category in Data_Dir:\n    folder_path=os.path.join(Dataset,category)\n    for img in os.listdir(folder_path):\n        img_path=os.path.join(folder_path,img)\n        img=cv2.imread(img_path)\n        \n        try:\n            #concerting image to grayscale\n            grayscale_img=cv2.cvtColor(img,cv2.COLOR_BGR2GRAY)\n            \n            #resizing the gray scaled images into 56x56 to keep size of the image consistent\n            resized_img=cv2.resize(grayscale_img,(img_rows,img_cols))\n            images.append(resized_img)\n            labels.append(category)\n        except Exception as e:\n            print('Exception: ',e)\n            \nimages=np.array(images)\/255.0\nimages=np.reshape(images,(images.shape[0],img_rows,img_cols,1))\n        \n#perform one hot encoding \nlb=LabelBinarizer()\nlabels=lb.fit_transform(labels)\nlabels=to_categorical(labels)\nlabels=np.array(labels)\n(train_X,test_X,train_y,test_y)=train_test_split(images,labels,test_size=0.25,random_state=0)","554806ac":"num_classes=2\nbatch_size=32","62994b3f":"from keras.models import Sequential\nfrom keras.layers import Dense,Activation,Flatten,Dropout\nfrom keras.layers import Conv2D,MaxPooling2D","649b90d0":"model=Sequential()\nmodel.add(Conv2D(64,(3,3),input_shape=(img_rows,img_cols,1)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Conv2D(128,(3,3)))\nmodel.add(Activation('relu'))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\nmodel.add(Flatten())\nmodel.add(Dropout(0.5))\n\nmodel.add(Dense(64,activation='relu'))\nmodel.add(Dense(num_classes,activation='softmax'))\nprint(model.summary())","20f6d8fa":"from keras.optimizers import Adam\n\nepoch=50\nmodel.compile(loss='categorical_crossentropy',\n             optimizer=Adam(lr=0.001),\n             metrics=['accuracy'])","4340e4ca":"fitted_model=model.fit(\ntrain_X,\ntrain_y,\nepochs=epoch,\nvalidation_split=0.25)","106e90b3":"model.save('fm.h5')","df94be1e":"In order to protect ourselves from the COVID-19 Pandemic, almost every one of us tend to wear a face mask. It becomes increasingly necessary to check if the people in the crowd wear face masks in most public gatherings such as Malls, Theatres, Parks. The development of an AI solution to detect if the person is wearing a face mask and allow their entry would be of great help to the society. In this, a simple Face Mask detection system is built using the Deep Learning technique called as Convolutional Neural Networks (CNN). This CNN Model is built using the TensorFlow framework and the OpenCV library which is highly used for real-time applications. This model can also be used to develop a full-fledged software to scan every person before they can enter the public gathering. Using this model, an accuracy of over 96% is obtained. This can also be used further to achieve even higher levels of accuracy.\n\nMedium Article - Click Here!\n\nData -\nI have used the face mask dataset provided by Prajna Bhandary available at Github\n\nCNN Architecture -\nIn this proposed method, the Face Mask detection model is built using the Sequential API of the keras library. This allows us to create the new layers for our model step by step. The various layers used for our CNN model is described below.\n\nThe first layer is the Conv2D layer with 100 filters and the filter size or the kernel size of 3X3. In this first step, the activation function used is the \u2018ReLu\u2019. This ReLu function stands for Rectified Linear Unit which will output the input directly if is positive, otherwise, it will output zero. The input size is also initialized as 150X150X3 for all the images to be trained and tested using this model\n\nIn the second layer, the MaxPooling2D is used with the pool size of 2X2.\n\nThe next layer is again a Conv2D layer with another 100 filters of the same filter size 3X3 and the activation function used is the \u2018ReLu\u2019. This Conv2D layer is followed by a MaxPooling3=2D layer with pool size 2X2.\n\nIn the next step, we use the Flatten() layer to flatten all the layers into a single 1D layer.\n\nAfter the Flatten layer, we use the Dropout (0.5) layer to prevent the model from overfitting.\n\nFinally, towards the end, we use the Dense layer with 50 units and the activation function as \u2018ReLu\u2019.\n\nThe last layer of our model will be another Dense Layer, with only two units and the activation function used will be the \u2018Softmax\u2019 function. The softmax function outputs a vector which will represent the probability distributions of each of the input units. Here, two input units are used. The softmax function will output a vector with two probability distribution values.\n\nalt text\n\nAfter building the model, we compile the model and define the loss function and optimizer function. In this model, we use the \u2018Adam\u2019 Optimizer and the \u2018Binary Cross Entropy\u2019 as the Loss function for training purpose.\n\nFor the face detection, the Haar Feature-based Cascade Classifiers are used in this experiment. It is is a machine learning object detection algorithm used to identify objects in an image or video and based on the concept of features proposed by Paul Viola and Michael Jones. In this, a cascade function is trained from a lot of positive and negative images. It is then used to detect objects in other images.\n\nThe cascade classifier used for this experiment is the Face Detection Cascade Classifier. In this, a model is pre-trained with frontal facial features is developed and used in this experiment to detect the faces in real-time.\n\nFinally, the CNN model along with the cascade classifier is trained for 30 epochs with two classes, one denoting the class of images with the face masks and the other without face masks."}}