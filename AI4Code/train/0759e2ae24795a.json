{"cell_type":{"ed53732b":"code","276fbc65":"code","94605582":"code","5de8f8f9":"code","0defc4b5":"code","f3579bf7":"code","8c29fadf":"code","72418e82":"code","1b80b381":"code","ef561a61":"code","f6c495d5":"code","f16d551f":"code","4a00bf8c":"code","7d00466b":"markdown","cdcb098f":"markdown","24ef1f72":"markdown","1afb4ed3":"markdown","cb9b7132":"markdown","0ea45f1e":"markdown","18642f3c":"markdown","57a6f98f":"markdown","26ada1c3":"markdown","e123eb53":"markdown","73692b74":"markdown","ff2ba20e":"markdown","709399f6":"markdown","6902c5a5":"markdown"},"source":{"ed53732b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","276fbc65":"#Importing all relevant libraries\n\nimport pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns \n\n#for modeling\nfrom keras.models import Sequential\nfrom keras.layers import Convolution2D ,Activation, Conv2D,MaxPooling2D,Flatten,Dense,Dropout,BatchNormalization\nfrom keras.callbacks import ReduceLROnPlateau\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow import keras\nfrom tensorflow.keras.models import load_model\n\n#for checking accuracy \nfrom sklearn.metrics import confusion_matrix","94605582":"#saving the image directory paths\ntrain_dir = '\/kaggle\/input\/cat-and-dog\/training_set\/training_set'\ntest_dir = '\/kaggle\/input\/cat-and-dog\/test_set\/test_set'\n","5de8f8f9":"#Data Augmentation\n#for training images\ntrain_datagen = ImageDataGenerator(rescale = 1.\/255,rotation_range=40, width_shift_range=0.2, \n                             height_shift_range=0.2, shear_range=0.2, \n                             zoom_range=0.2, horizontal_flip = True, \n                             fill_mode='nearest')\n#for testing images\ntest_datagen = ImageDataGenerator(rescale = 1.\/255)","0defc4b5":"#flow_from_directly is used as we are using a folder with different classes(images)\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,\n        target_size=(64, 64),     #specify the dim of output image\n        batch_size=32,  \n        class_mode='binary')   #we could we have use binary but as we have earlier use categorical loss we will use this\n\ntest_generator = test_datagen.flow_from_directory(\n        test_dir,\n        target_size=(64, 64),     \n        batch_size=32,  \n        class_mode='binary')\n","f3579bf7":"# Modeling using simple CNN \nmodel = Sequential()\nmodel.add(Convolution2D(filters=32, kernel_size=(3, 3), activation='relu', \n                        padding = 'same',input_shape=(64,64,3)))\nmodel.add(MaxPooling2D(pool_size=(2, 2), strides=2))\nmodel.add(Dropout(0.3))  \n\nmodel.add(Flatten())\nmodel.add(Dense(128, kernel_initializer='he_normal', activation='relu'))\nmodel.add(Dense(units =  1, activation='sigmoid'))\n\nmodel.summary()\n","8c29fadf":"#Compiling\nlearning_rate_reduction = ReduceLROnPlateau(monitor='val_acc',\n                                            patience=2,\n                                            verbose=1,\n                                            factor=0.25,\n                                            min_lr=0.000003)\nmodel.compile(optimizer='adam',loss = 'binary_crossentropy',metrics = ['accuracy'])","72418e82":"#now we will fit the model\n#fit_generator is used as we are using an augmented image data set \nprediction = model.fit_generator(train_generator, \n                                 epochs=5,\n                                 validation_data = test_generator,\n                                 callbacks=[learning_rate_reduction]\n                                )\n#specify number of validation steps","1b80b381":"#Plotting train, test accuracy and loss. \nplt.plot(prediction.history['accuracy'], color = 'b')\nplt.plot(prediction.history['val_accuracy'], color = 'r')\nplt.title('Model accuracy')\nplt.ylabel('Accuracy')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower right')\nplt.figure()\n\nplt.plot(prediction.history['loss'], color = 'b')\nplt.plot(prediction.history['val_loss'], color = 'r')\nplt.title('Model loss')\nplt.ylabel('Loss')\nplt.xlabel('Epoch')\nplt.legend(['Train', 'Test'], loc='lower right')\nplt.show()\n\n","ef561a61":"def build_model(hp):  # random search passes this hyperparameter() object \n    model = keras.models.Sequential()\n\n    model.add(Conv2D(hp.Int('input_units',\n                                min_value=32,\n                                max_value=256,\n                                step=32), (3, 3), input_shape=(64,64,3)))\n\n    model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    for i in range(hp.Int('n_layers', 1, 2)):  # adding variation of layers.\n        model.add(Conv2D(hp.Int(f'conv_{i}_units',\n                                min_value=32,\n                                max_value=256,\n                                step=32), (3, 3)))\n        model.add(Activation('relu'))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n\n    model.add(Flatten())\n    for i in range(hp.Int('n_connections', 1, 2)):\n        model.add(Dense(hp.Choice(f'n_nodes',\n                                  values=[128, 256, 512])))\n        model.add(Activation('relu'))\n    model.add(Dense(1))\n    model.add(Activation(\"sigmoid\"))\n\n    model.compile(optimizer=\"adam\",\n                  loss=\"binary_crossentropy\",\n                  metrics=[\"accuracy\"])\n\n    return model\n","f6c495d5":"#creating a tuner object\nfrom kerastuner.tuners import RandomSearch\ntuner = RandomSearch(\n    build_model,\n    objective='val_accuracy',\n    max_trials=2,  # how many model variations to test?\n    executions_per_trial=1,  # how many trials per variation? (same model could perform differently)\n    directory='Dog and Cats Classification',\n    project_name='KerasTuner')","f16d551f":"tuner.search(train_generator,\n             epochs=5,\n             validation_data=test_generator)\n\nprint(tuner.get_best_models()[0].summary())\nprint(tuner.get_best_hyperparameters()[0].values)\n\nmodel = tuner.get_best_models(num_models=1)[0]\nprint (model.summary())\n","4a00bf8c":"#Evaluate the model \nloss, accuracy = model.evaluate(test_generator)\nprint('Loss: ', loss)\nprint('Accuracy: ', accuracy)","7d00466b":"# Model 2 with Keras tuner Hyperparemeter Tuning","cdcb098f":"# Covolution Layers: \n\n\nWhen programming a CNN, the input is a tensor with shape (number of images) x (image height) x (image width) x (input channels). Then after passing through a convolutional layer, the image becomes abstracted to a feature map, with shape (number of images) x (feature map height) x (feature map width) x (feature map channels). A convolutional layer within a neural network should have the following attributes:\n\n* Convolutional kernels defined by a width and height (hyper-parameters).\n* The number of input channels and output channels (hyper-parameter).\n* The depth of the Convolution filter (the input channels) must be equal to the number channels (depth) of the input feature map.\n\nConvolutional layers convolve the input and pass its result to the next layer. This is similar to the response of a neuron in the visual cortex to a specific stimulus. Each convolutional neuron processes data only for its receptive field. Although fully connected feedforward neural networks can be used to learn features as well as classify data, it is not practical to apply this architecture to images. A very high number of neurons would be necessary, even in a shallow (opposite of deep) architecture, due to the very large input sizes associated with images, where each pixel is a relevant variable. For instance, a fully connected layer for a (small) image of size 100 x 100 has 10,000 weights for each neuron in the second layer. The convolution operation brings a solution to this problem as it reduces the number of free parameters, allowing the network to be deeper with fewer parameters. For instance, regardless of image size, tiling regions of size 5 x 5, each with the same shared weights, requires only 25 learnable parameters. By using regularized weights over fewer parameters, the vanishing gradient and exploding gradient problems seen during backpropagation in traditional neural networks are avoided","24ef1f72":"# Pooling Layers:\n\nConvolutional networks may include local or global pooling layers to streamline the underlying computation. Pooling layers reduce the dimensions of the data by combining the outputs of neuron clusters at one layer into a single neuron in the next layer. Local pooling combines small clusters, typically 2 x 2. Global pooling acts on all the neurons of the convolutional layer. In addition, pooling may compute a max or an average. Max pooling uses the maximum value from each of a cluster of neurons at the prior layer. Average pooling uses the average value from each of a cluster of neurons at the prior layer.","1afb4ed3":"# Model 1 using simple CNN model","cb9b7132":"# RandomSearch\n\nIn the model construction, we defined the parameters that are going to be randomly choosed, but we will need some other code that will use this function now. And our objective obviously is to get best accuracy\n","0ea45f1e":"In deep learning, a convolutional neural network (CNN, or ConvNet) is a class of deep neural networks, most commonly applied to analyzing visual imagery. They are also known as shift invariant or space invariant artificial neural networks (SIANN), based on their shared-weights architecture and translation invariance characteristics. They have applications in image and video recognition, recommender systems, image classification, medical image analysis, natural language processing, brain-computer interfaces, and financial time series.","18642f3c":"# Keras Tuner Model Evaluation","57a6f98f":"The Keras Tuner is a library that helps you pick the optimal set of hyperparameters for your TensorFlow program. The process of selecting the right set of hyperparameters for your machine learning (ML) application is called hyperparameter tuning or hypertuning.\n\nHyperparameters are the variables that govern the training process and the topology of an ML model. These variables remain constant over the training process and directly impact the performance of your ML program. Hyperparameters are of two types:\n\n1. **Model hyperparameters:** which influence model selection such as the number and width of hidden layers\n2. **Algorithm hyperparameters:** which influence the speed and quality of the learning algorithm such as the learning rate for Stochastic Gradient Descent (SGD) and the number of nearest neighbors for a k Nearest Neighbors (KNN) classifier","26ada1c3":"# Data Augmentation and Preprocessing","e123eb53":"# Dense Layers:\n\nDense- Dense (fully connected) layers, which perform classification on the features extracted by the convolutional layers and downsampled by the pooling layers. In a dense layer, every node in the layer is connected to every node in the preceding layer.","73692b74":"# Finally we fit our model\n","ff2ba20e":"# Fully Connected Layers:\n\nFully connected layers connect every neuron in one layer to every neuron in another layer. It is in principle the same as the traditional multi-layer perceptron neural network (MLP). The flattened matrix goes through a fully connected layer to classify the images.","709399f6":"# Drop out Layers:\n\nIt is use to avoid overfitting by droping some random parameters form layer.","6902c5a5":"# Importing Libraries"}}