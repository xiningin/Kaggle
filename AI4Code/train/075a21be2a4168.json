{"cell_type":{"1e83189c":"code","f7d144a7":"code","2aa7ce52":"code","162b0412":"code","7ba28ec0":"code","3ddb845d":"code","465bc1ca":"code","67bde42a":"code","cefa32db":"code","39972a7f":"markdown","e6eb9ce4":"markdown","1e23fe4a":"markdown","0855316c":"markdown","9cc74991":"markdown","398fc6fa":"markdown","57d07bf6":"markdown","c6ccc2d9":"markdown","20e37b94":"markdown"},"source":{"1e83189c":"import numpy as np\nimport pandas as pd\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.utils.multiclass import type_of_target\nfrom sklearn.model_selection import GridSearchCV, KFold, StratifiedKFold\n\n\nrandom_state = 1","f7d144a7":"def gridsearch(X, y, model, grid,\n               scoring_functions=None, pipeline=None,\n               best_scoring=True, random_state=None,\n               n_cv_general=10, n_cv_intrain=10, title='None'):\n\n    cv_results_test = np.zeros((n_cv_general, 1))\n    cv_results_generalization = np.zeros((n_cv_general, 1))\n    pred = np.zeros_like(y)\n    bestparams = []\n    cv_results = []\n\n    if type_of_target(y) == 'continuous':\n        kfold_gen = KFold(n_splits=n_cv_general,\n                          random_state=random_state, shuffle=True)\n\n    elif type_of_target(y) == 'multiclass' or 'binary':\n        kfold_gen = StratifiedKFold(n_splits=n_cv_general, shuffle=True,\n                                    random_state=random_state)\n\n    # k Fold cross-validation\n\n    for cv_i, (train_index, test_index) in enumerate(kfold_gen.split(X, y)):\n        x_train, x_test = X[train_index], X[test_index]\n        y_train, y_test = y[train_index], y[test_index]\n\n\n        kfold = KFold(n_splits=n_cv_intrain,\n                      random_state=random_state, shuffle=True)\n\n        estimator = model if pipeline is None else Pipeline(\n            [pipeline, ('clf', model)])\n\n        # Finding optimum hyper-parameter\n\n        grid_search = GridSearchCV(estimator, grid, cv=kfold,\n                                   scoring=scoring_functions, refit=best_scoring,\n                                   return_train_score=False)\n\n        grid_search.fit(x_train, y_train)\n\n        pred[test_index] = grid_search.predict(x_test)\n\n        bestparams.append(grid_search.best_params_)\n\n        grid_search.cv_results_[\n            'final_test_score'] = grid_search.score(x_test, y_test)\n\n        cv_results.append(grid_search.cv_results_)\n\n        cv_results_test[cv_i, 0] = grid_search.cv_results_[\n            'mean_test_score'][grid_search.best_index_]\n        cv_results_generalization[cv_i, 0] = grid_search.cv_results_[\n            'final_test_score']\n\n    results = {}\n    results['Metric'] = [\n        'Score' if scoring_functions is None else scoring_functions]\n    results['Mean_test_score'] = np.mean(\n        cv_results_test, axis=0)\n    results['Std_test_score'] = np.std(\n        cv_results_test, axis=0)\n    results['Mean_generalization_score'] = np.mean(\n        cv_results_generalization, axis=0)\n    results['Std_generalization_score'] = np.std(\n        cv_results_generalization, axis=0)\n\n    return pd.DataFrame(results)\n    ","2aa7ce52":"df = pd.read_csv('..\/input\/wine-quality\/winequalityN.csv')\nclass_labels = (np.unique(df.quality))\ndf.head()","162b0412":"lb = LabelEncoder()\ndf['type'] = lb.fit_transform(df.type)","7ba28ec0":"for col in df.keys():\n    mean = df[col].mean()\n    df[col].fillna(mean, inplace=True)","3ddb845d":"X = (df.iloc[:, :-1]).values\ny = (df.iloc[:, -1]).values","465bc1ca":"clf = AdaBoostClassifier(n_estimators=200,\n                         random_state=random_state, \n                         learning_rate=0.1)","67bde42a":"param_grid = {'clf__learning_rate': [0.025, 0.05, 0.1, 0.5, 1]}","cefa32db":"gridsearch(X=X, y=y,\n           model=clf,\n           grid=param_grid,\n           scoring_functions='accuracy',\n           pipeline=('scaler', StandardScaler()),\n           best_scoring=True,\n           random_state=random_state,\n           n_cv_general=2,\n           n_cv_intrain=2,\n           title='Wine_AdaBoost')","39972a7f":"# About this script\n\n## Author: Seyedsaman Emami\n\n","e6eb9ce4":"In this script, I do not want to talk about the EDA details. I only encode the string feature into binary labels and drop the missing values.\n\nThe focus of this script is to optimize the hyperparameters of the well-known gradient boosting classifier (AdaBoost) [Mason et al, 2000].\n\nTo follow my works, I suggest to follow me on GitHub (https:\/\/github.com\/samanemami)","1e23fe4a":"# Importing Data","0855316c":"\n# Licence: GNU Lesser General Public License v2.1 (LGPL-2.1)\n\n### Author: [Seyedsaman Emami](https:\/\/github.com\/samanemami)\n\nIf you want to have this method or use the outputs of the notebook, you can fork the Notebook as following (copy and Edit Kernel).\n\n\nI tried to keep everything as simple as possible, if you have any doubts or questions, please feel free to ask in the comments.","9cc74991":"# Define the dependant and independent variables\n","398fc6fa":"# Training and optimizing the model","57d07bf6":"# Define the classifier","c6ccc2d9":"# Importing libraries","20e37b94":"# Define the grid"}}