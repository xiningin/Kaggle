{"cell_type":{"2078cc04":"code","17a6486a":"code","5c38c4f7":"code","31dd8ef8":"code","1918dce4":"code","dd026a84":"code","f8d13204":"code","96cca371":"code","5cb598af":"code","9e953c7b":"code","3207b776":"code","c87896b0":"code","ced4f4dd":"code","4f958460":"code","fb70f650":"code","c1067f07":"code","176166b1":"code","e2648099":"markdown","2cfacb43":"markdown","f232cdf4":"markdown","e8ad89c2":"markdown","a83488ab":"markdown","654270b5":"markdown","65d61b76":"markdown","82922552":"markdown","7e29083b":"markdown","801d712c":"markdown"},"source":{"2078cc04":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport matplotlib as mlt\n%matplotlib inline\ndata=pd.read_csv('..\/input\/heart-failure-prediction\/heart.csv')","17a6486a":"data.head()","5c38c4f7":"data.info()","31dd8ef8":"data.shape","1918dce4":"data.dtypes","dd026a84":"data.columns","f8d13204":"data.describe()","96cca371":"#Nous divisons nos donn\u00e9es en 2 ensembles: train et test. Nous allons entrainer notre mod\u00e8le sur train afin de v\u00e9rifier sur test\nfrom sklearn.model_selection import train_test_split\ntrain, test = train_test_split(data,test_size=0.2,random_state= 4)","5cb598af":"train_data_num = train[[\"Age\", \"RestingBP\", \"Cholesterol\", \"MaxHR\", \"Oldpeak\"]]\nfor i in train_data_num.columns:    \n    plt.hist(train_data_num[i])\n    plt.title(i)\n    plt.show()\n    plt.boxplot(train_data_num[i])\n    plt.title(i)\n    plt.show()\n\n\n","9e953c7b":"sns.heatmap(train_data_num.corr())","3207b776":"pd.pivot_table(train, index=\"HeartDisease\", values=[\"Age\", \"RestingBP\", \"Cholesterol\", \"FastingBS\", \"MaxHR\", \"Oldpeak\"])","c87896b0":"train_data_quali = train[['Sex', 'ChestPainType', \"FastingBS\",\n       'RestingECG', 'ExerciseAngina', 'ST_Slope']]","ced4f4dd":"for info in train_data_quali.columns:\n    sns.barplot(x=train_data_quali[info].value_counts().index, y=train_data_quali[info].value_counts()).set_title(info)\n    plt.show()","4f958460":"# Pour entrainer nos mod\u00e8les, il va falloir convertir nos donn\u00e9es qualitatives en donn\u00e9es num\u00e9riques en utilisant get_dummies\n\ntrain = pd.get_dummies(train)\ntest = pd.get_dummies(test)\n","fb70f650":"#V\u00e9rifions que les donn\u00e9es ont bien \u00e9t\u00e9 remplac\u00e9es\ntrain.head(50)","c1067f07":"# C'est le moment\nx_train = train.drop(columns = [\"HeartDisease\"])\ny_train = train[\"HeartDisease\"]\n\nx_test = test.drop(columns = [\"HeartDisease\"])\ny_test = test[\"HeartDisease\"]\n\n","176166b1":"from sklearn.linear_model import LogisticRegression\nimport sklearn\n# En faisant mes recherches, j'ai remarqu\u00e9 que beaucoup de gens utilisaient le param\u00e8tre max_iter \n# de LogisticRegression alors j'ai d\u00e9cid\u00e9 d'en tester quelques uns afin de trouver le nombre qui va \n# maximiser mon r\u00e9sultat (je pense que le plus sera le mieux)\n\n# j'essayais max_iter avec 500 et il y avait des erreurs. Fonctionne avec 1000 et plus. Fonctionne \u00e0 partir de 639. \n# On peut voir que pour ce sc\u00e9nario, max_iter n'a pas d'importance\nfor i in range(1000,20000,2500):\n    Log_Reg = LogisticRegression(max_iter=i)\n    modele=Log_Reg.fit(x_train, y_train)\n    print(\"Pr\u00e9cision train:\",modele.score(x_train, y_train),\"\\n\",\"Pr\u00e9cision test:\",modele.score(x_test,y_test))","e2648099":"On n'a pas vraiment de corr\u00e9lation positive mais il  y a quelques l\u00e9g\u00e8res corr\u00e9lations n\u00e9gatives comme l'\u00e2ge et la fr\u00e9queence cardiaque et la glyc\u00e9mie et le cholesterol","2cfacb43":"**Regardons les corr\u00e9lations entre les diff\u00e9rentes variables num\u00e9riques**","f232cdf4":"On peut commencer \u00e0 tracer le profil d'une personne ayant eu un arr\u00eat cardiaque (ce n'est pas d\u00e9finitif et pas forc\u00e9ment vrai. C'est une premi\u00e8re esquisse): il est g\u00e9n\u00e9ralement plus vieux, a un cholesterol plus faible, il a 3 fois plus de chance d'avoir un taux de glyc\u00e9mie \u00e0 jeun de 120mg\/dl ou plus. Il a une fr\u00e9quance cardiaque maximale faible etc...","e8ad89c2":"**Visualisons nos diff\u00e9rentes donn\u00e9es num\u00e9riques**","a83488ab":"Nous n'avons pas de donn\u00e9es manquantes, ce qui est une bonne nouvelle.\n","654270b5":"**Nous avons les donn\u00e9es suivantes dans notre base de donn\u00e9es**\n\nAge: \u00c2ge lors de la crise cardiaque\n\nSex: Sexe de la personne\n\nChestPainType: Type de douleur \u00e0 la poitrine\n\nRestingBP: Pression art\u00e9rielle au repos (mm Hg)\n\nCholesterol: Cholesterol du patient (mm\/dl)\n\nFastingBS : Glyc\u00e9mie \u00e0 jeun du patient (1 si FastingBS > 120 mg\/dl, 0 sinon)\n\nRestingECG: R\u00e9sultat des \u00e9lectrocardiogrammes au repos (Normal: Normale, ST: Ondes ST-T abnormales (Invesions onde T  et\/ou  augmentaion ou r\u00e9duction de > 0.05 mV des ondes ST), LVH: Hypertrophie probable ou d\u00e9finitive du ventricule gauche selon le crit\u00e8res d'Estes)\n\nMaxHR: Fr\u00e9quence cardiaque maximale (entre 60 et 202 bpm)\n\nExerciseAngina: Angine caus\u00e9e par l'exercice (Y: Oui, N: Non)\n\nOldpeak: oldpeak = ST [Numeric value measured in depression]\n\nST_Slope: the slope of the peak exercise ST segment [Up: upsloping, Flat: flat, Down: downsloping]\n\nHeartDisease: Si le patient avait une maladie cardiaque (1: Oui, 0: Non)\n\n\n","65d61b76":"Voici la fin de mon premier projet Kaggle. J'ai fait un mod\u00e8le basique qui me permet de pr\u00e9dire","82922552":"Nous allons enlever la colonne HeartDisease de test afin que nous puissons faire nos pr\u00e9dictoins avant de comparer nos r\u00e9sultats \u00e0 ceux de cette colonne","7e29083b":"J'ai fait des recherches sur le type de r\u00e9gression \u00e0 utiliser parce qu'il y en a beaucoup et je ne les connais pas toutes. Je suis tomb\u00e9 sur une vid\u00e9o qui explique bri\u00e8vement quelle r\u00e9gression utiliser selon le sc\u00e9nario et dans mon cas, la \"Binary Logistic Regression\" serait la r\u00e9gression \u00e0 effectuer dans mon cas (on cherche une r\u00e9ponse tranch\u00e9e avec seulement deux options: oui on non (https:\/\/youtu.be\/i8tjLQUPc8Y). Cela s'est confirm\u00e9 quand j'ai trouv\u00e9 un pdf de Claremont Graduate University dans lequel il est \u00e9crit que la \"Binary Logistic Regression\" est utilse lorsqu'on a affaire \u00e0 un choix entre deux possibi\u00e9it\u00e9s. http:\/\/wise.cgu.edu\/wp-content\/uploads\/2016\/07\/Introduction-to-Logistic-Regression.pdf","801d712c":"Regardons maintenant les donn\u00e9es qualitatives"}}