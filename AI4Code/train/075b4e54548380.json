{"cell_type":{"02140332":"code","2361bd96":"code","e302eee5":"code","63beaa2e":"code","8867a584":"code","44ad5dbe":"code","3ce14f43":"code","fdc1aa44":"code","5b164fc4":"code","c850cb76":"code","e1f162f0":"code","0b7b54bf":"code","1bb7880d":"code","48d6e804":"code","eea6b979":"code","c1395cb0":"code","0fcfc807":"code","aaacd146":"code","77a1e183":"code","28610334":"code","1a4b4a58":"code","305f9c31":"code","0c6b1bb4":"code","4259388d":"code","4ddd2d09":"code","17ffe2da":"code","0c40cf43":"code","10452c9b":"markdown","4d2a3752":"markdown","c99a0b07":"markdown","e8162610":"markdown","cb464092":"markdown","7357fa6e":"markdown","29d14d73":"markdown","9ec4a60c":"markdown","e9bec760":"markdown","643dbf56":"markdown","342d5e93":"markdown","aecba634":"markdown","f696a845":"markdown","2e02decf":"markdown","5e8bd310":"markdown"},"source":{"02140332":"import os\n\"\"\"\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n\nimport copy\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport cv2\nimport keras\nfrom keras import backend as K\nfrom keras.models import Model, Sequential\nfrom keras.layers import Dense, Dropout, BatchNormalization, Flatten, Input\nfrom keras.layers import Conv2D, Activation, GlobalAveragePooling2D\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing.image import load_img, img_to_array\nfrom keras.applications.resnet50 import preprocess_input, ResNet50\nimport matplotlib\nimport matplotlib.pylab as plt\nimport numpy as np\nimport seaborn as sns\nimport shap\nfrom sklearn.utils import shuffle\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.model_selection import train_test_split","2361bd96":"W = 112 # The default size for ResNet is 224 but resize to .5 to save memory size\nH = 112 # The default size for ResNet is 224 but resize to .5 to save memory size\nlabel_to_class = {\n    'buildings': 0,\n    'forest':    1,\n    'glacier':   2,\n    'mountain':  3,\n    'sea':       4,\n    'street':    5,\n}\nclass_to_label = {v: k for k, v in label_to_class.items()}\nn_classes = len(label_to_class)\n\ndef get_images(dir_name='..\/input\/intel-image-classification\/seg_train\/seg_train', label_to_class=label_to_class):\n    \"\"\"read images \/ labels from directory\"\"\"\n    \n    Images = []\n    Classes = []\n    \n    for label_name in os.listdir(dir_name):\n        cls = label_to_class[label_name]\n        \n        for img_name in os.listdir('\/'.join([dir_name, label_name])):\n            img = load_img('\/'.join([dir_name, label_name, img_name]), target_size=(W, H))\n            img = img_to_array(img)\n            \n            Images.append(img)\n            Classes.append(cls)\n            \n    Images = np.array(Images, dtype=np.float32)\n    Classes = np.array(Classes, dtype=np.float32)\n    Images, Classes = shuffle(Images, Classes, random_state=0)\n    \n    return Images, Classes","e302eee5":"## get images \/ labels\n\nImages, Classes = get_images()\n\nImages.shape, Classes.shape","63beaa2e":"## visualize some images \/ labels\n\nn_total_images = Images.shape[0]\n\nfor target_cls in [0, 1, 2, 3, 4, 5]:\n    \n    indices = np.where(Classes == target_cls)[0] # get target class indices on Images \/ Classes\n    n_target_cls = indices.shape[0]\n    label = class_to_label[target_cls]\n    print(label, n_target_cls, n_target_cls\/n_total_images)\n\n    n_cols = 10 # # of sample plot\n    fig, axs = plt.subplots(ncols=n_cols, figsize=(25, 3))\n\n    for i in range(n_cols):\n\n        axs[i].imshow(np.uint8(Images[indices[i]]))\n        axs[i].axis('off')\n        axs[i].set_title(label)\n\n    plt.show()","8867a584":"## split train \/ test\n\nindices_train, indices_test = train_test_split(list(range(Images.shape[0])), train_size=0.8, test_size=0.2, shuffle=False)\n\nx_train = Images[indices_train]\ny_train = Classes[indices_train]\nx_test = Images[indices_test]\ny_test = Classes[indices_test]\n\nx_train.shape, y_train.shape, x_test.shape, y_test.shape","44ad5dbe":"## to one-hot\n\ny_train = keras.utils.to_categorical(y_train, n_classes)\ny_test = keras.utils.to_categorical(y_test, n_classes)\n\ny_train.shape, y_test.shape","3ce14f43":"## to image data generator\n\ndatagen_train = ImageDataGenerator(\n    preprocessing_function=preprocess_input, # image preprocessing function\n    rotation_range=30,                       # randomly rotate images in the range\n    zoom_range=0.1,                          # Randomly zoom image\n    width_shift_range=0.1,                   # randomly shift images horizontally\n    height_shift_range=0.1,                  # randomly shift images vertically\n    horizontal_flip=True,                    # randomly flip images horizontally\n    vertical_flip=False,                     # randomly flip images vertically\n)\ndatagen_test = ImageDataGenerator(\n    preprocessing_function=preprocess_input, # image preprocessing function\n)","fdc1aa44":"def build_model():\n    \"\"\"build model function\"\"\"\n    \n    # Resnet\n    input_tensor = Input(shape=(W, H, 3)) # To change input shape\n    resnet50 = ResNet50(\n        include_top=False,                # To change output shape\n        weights='imagenet',               # Use pre-trained model\n        input_tensor=input_tensor,        # Change input shape for this task\n    )\n    \n    # fc layer\n    top_model = Sequential()\n    top_model.add(GlobalAveragePooling2D())               # Add GAP for cam\n    top_model.add(Dense(n_classes, activation='softmax')) # Change output shape for this task\n    \n    # model\n    model = Model(input=resnet50.input, output=top_model(resnet50.output))\n    \n    # frozen weights\n    for layer in model.layers[:-10]:\n        layer.trainable = False or isinstance(layer, BatchNormalization) # If Batch Normalization layer, it should be trainable\n        \n    # compile\n    model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n    \n    return model","5b164fc4":"model = build_model()","c850cb76":"model.summary()","e1f162f0":"## finetuning\n\nhistory = model.fit_generator(\n    datagen_train.flow(x_train, y_train, batch_size=32),\n    epochs=5,\n    validation_data=datagen_test.flow(x_test, y_test, batch_size=32),\n)","0b7b54bf":"## plot confusion matrix\n\nx = preprocess_input(copy.deepcopy(x_test))\ny_preds = model.predict(x)\ny_preds = np.argmax(y_preds, axis=1)\ny_trues = np.argmax(y_test, axis=1)\ncm = confusion_matrix(y_trues, y_preds)\n\nfig, ax = plt.subplots(figsize=(7, 6))\n\nsns.heatmap(cm, annot=True, fmt='d', cmap='Blues', cbar_kws={'shrink': .3}, linewidths=.1, ax=ax)\n\nax.set(\n    xticklabels=list(label_to_class.keys()),\n    yticklabels=list(label_to_class.keys()),\n    title='confusion matrix',\n    ylabel='True label',\n    xlabel='Predicted label'\n)\nparams = dict(rotation=45, ha='center', rotation_mode='anchor')\nplt.setp(ax.get_yticklabels(), **params)\nplt.setp(ax.get_xticklabels(), **params)\nplt.show()","1bb7880d":"def superimpose(img, cam):\n    \"\"\"superimpose original image and cam heatmap\"\"\"\n    \n    heatmap = cv2.resize(cam, (img.shape[1], img.shape[0]))\n    heatmap = np.uint8(255 * heatmap)\n    heatmap = cv2.applyColorMap(heatmap, cv2.COLORMAP_JET)\n\n    superimposed_img = heatmap * .5 + img * .5\n    superimposed_img = np.minimum(superimposed_img, 255.0).astype(np.uint8)  # scale 0 to 255  \n    superimposed_img = cv2.cvtColor(superimposed_img, cv2.COLOR_BGR2RGB)\n    \n    return img, heatmap, superimposed_img","48d6e804":"def _plot(model, cam_func, img, cls_true):\n    \"\"\"plot original image, heatmap from cam and superimpose image\"\"\"\n    \n    # for cam\n    x = np.expand_dims(img, axis=0)\n    x = preprocess_input(copy.deepcopy(x))\n\n    # for superimpose\n    img = np.uint8(img)\n\n    # cam \/ superimpose\n    cls_pred, cam = cam_func(model=model, x=x, layer_name=model.layers[-2].name)\n    img, heatmap, superimposed_img = superimpose(img, cam)\n\n    fig, axs = plt.subplots(ncols=3, figsize=(9, 4))\n\n    axs[0].imshow(img)\n    axs[0].set_title('original image')\n    axs[0].axis('off')\n\n    axs[1].imshow(heatmap)\n    axs[1].set_title('heatmap')\n    axs[1].axis('off')\n\n    axs[2].imshow(superimposed_img)\n    axs[2].set_title('superimposed image')\n    axs[2].axis('off')\n\n    plt.suptitle('True label: ' + class_to_label[cls_true] + ' \/ Predicted label : ' + class_to_label[cls_pred])\n    plt.tight_layout()\n    plt.show()","eea6b979":"## Grad-CAM function\n\ndef grad_cam(model, x, layer_name):\n    \"\"\"Grad-CAM function\"\"\"\n    \n    cls = np.argmax(model.predict(x))\n    \n    y_c = model.output[0, cls]\n    conv_output = model.get_layer(layer_name).output\n    grads = K.gradients(y_c, conv_output)[0]\n\n    # Get outputs and grads\n    gradient_function = K.function([model.input], [conv_output, grads])\n    output, grads_val = gradient_function([x])\n    output, grads_val = output[0, :], grads_val[0, :, :, :]\n    \n    weights = np.mean(grads_val, axis=(0, 1)) # Passing through GlobalAveragePooling\n\n    cam = np.dot(output, weights) # multiply\n    cam = np.maximum(cam, 0)      # Passing through ReLU\n    cam \/= np.max(cam)            # scale 0 to 1.0\n\n    return cls, cam","c1395cb0":"_plot(model=model, cam_func=grad_cam, img=Images[0], cls_true=Classes[0])","0fcfc807":"## Grad-CAM++ function\n\ndef grad_cam_plus_plus(model, x, layer_name):\n    \"\"\"Grad-CAM++ function\"\"\"\n    \n    cls = np.argmax(model.predict(x))\n    y_c = model.output[0, cls]\n    conv_output = model.get_layer(layer_name).output\n    grads = K.gradients(y_c, conv_output)[0]\n\n    first = K.exp(y_c) * grads\n    second = K.exp(y_c) * grads * grads\n    third = K.exp(y_c) * grads * grads * grads\n\n    gradient_function = K.function([model.input], [y_c, first, second, third, conv_output, grads])\n    y_c, conv_first_grad, conv_second_grad, conv_third_grad, conv_output, grads_val = gradient_function([x])\n    global_sum = np.sum(conv_output[0].reshape((-1,conv_first_grad[0].shape[2])), axis=0)\n\n    alpha_num = conv_second_grad[0]\n    alpha_denom = conv_second_grad[0] * 2.0 + conv_third_grad[0] * global_sum.reshape((1, 1, conv_first_grad[0].shape[2]))\n    alpha_denom = np.where(alpha_denom != 0.0, alpha_denom, np.ones(alpha_denom.shape))\n    alphas = alpha_num \/ alpha_denom # 0\n\n\n    weights = np.maximum(conv_first_grad[0], 0.0)\n    alpha_normalization_constant = np.sum(np.sum(alphas, axis=0), axis=0) # 0\n    alphas \/= alpha_normalization_constant.reshape((1, 1, conv_first_grad[0].shape[2])) # NAN\n    deep_linearization_weights = np.sum((weights * alphas).reshape((-1, conv_first_grad[0].shape[2])), axis=0)\n\n    cam = np.sum(deep_linearization_weights * conv_output[0], axis=2)\n    cam = np.maximum(cam, 0) # Passing through ReLU\n    cam \/= np.max(cam)       # scale 0 to 1.0  \n\n    return cls, cam","aaacd146":"_plot(model=model, cam_func=grad_cam_plus_plus, img=Images[0], cls_true=Classes[0])","77a1e183":"## Score-CAM function\n\ndef softmax(x):\n    \"\"\"softmax\"\"\"\n    \n    return np.exp(x) \/ np.sum(np.exp(x), axis=1, keepdims=True)\n\ndef score_cam(model, x, layer_name, max_N=-1):\n    \"\"\"Score-CAM function\"\"\"\n\n    cls = np.argmax(model.predict(x))\n    act_map_array = Model(inputs=model.input, outputs=model.get_layer(layer_name).output).predict(x)\n    \n    # extract effective maps\n    if max_N != -1:\n        act_map_std_list = [np.std(act_map_array[0, :, :, k]) for k in range(act_map_array.shape[3])]\n        unsorted_max_indices = np.argpartition(-np.array(act_map_std_list), max_N)[:max_N]\n        max_N_indices = unsorted_max_indices[np.argsort(-np.array(act_map_std_list)[unsorted_max_indices])]\n        act_map_array = act_map_array[:, :, :, max_N_indices]\n\n    input_shape = model.layers[0].output_shape[1:]  # get input shape\n    \n    # 1. upsampled to original input size\n    act_map_resized_list = [cv2.resize(act_map_array[0,:,:,k], input_shape[:2], interpolation=cv2.INTER_LINEAR) for k in range(act_map_array.shape[3])]\n    \n    # 2. normalize the raw activation value in each activation map into [0, 1]\n    act_map_normalized_list = []\n    for act_map_resized in act_map_resized_list:\n        if np.max(act_map_resized) - np.min(act_map_resized) != 0:\n            act_map_normalized = act_map_resized \/ (np.max(act_map_resized) - np.min(act_map_resized))\n        else:\n            act_map_normalized = act_map_resized\n        act_map_normalized_list.append(act_map_normalized)\n        \n    # 3. project highlighted area in the activation map to original input space by multiplying the normalized activation map\n    masked_input_list = []\n    for act_map_normalized in act_map_normalized_list:\n        masked_input = np.copy(x)\n        for k in range(3):\n            masked_input[0, :, :, k] *= act_map_normalized\n        masked_input_list.append(masked_input)\n    masked_input_array = np.concatenate(masked_input_list, axis=0)\n    \n    # 4. feed masked inputs into CNN model and softmax\n    pred_from_masked_input_array = softmax(model.predict(masked_input_array))\n    \n    # 5. define weight as the score of target class\n    weights = pred_from_masked_input_array[:, cls]\n    \n    # 6. get final class discriminative localization map as linear weighted combination of all activation maps\n    cam = np.dot(act_map_array[0, :, :, :], weights)\n    cam = np.maximum(0, cam) # Passing through ReLU\n    cam \/= np.max(cam) # scale 0 to 1.0\n    \n    return cls, cam","28610334":"_plot(model=model, cam_func=score_cam, img=Images[0], cls_true=Classes[0])","1a4b4a58":"## compare Grad-CAM \/ Grad-CAM++ \/ Score-CAM\n\ndef _compare(model, layer_name, target_cls):\n    \"\"\"compare Grad-CAM \/ Grad-CAM++ \/ Score-CAM on target class images\"\"\"\n    \n    indices = np.where(Classes == target_cls)[0]\n    label = class_to_label[target_cls]\n\n    n_cols = 10 # # of sample plot\n\n    fig, axs = plt.subplots(ncols=n_cols, nrows=4, figsize=(25, 9))\n\n    for i in range(n_cols):\n        \n        img = Images[indices[i]]\n        # for cam\n        x = np.expand_dims(img, axis=0)\n        x = preprocess_input(copy.deepcopy(x))\n\n        # original\n        axs[0, i].imshow(np.uint8(img))\n        axs[0, i].set_title(label)\n        axs[0, i].set_xticks([])\n        axs[0, i].set_yticks([])\n        if i == 0:\n            axs[0, i].set_ylabel('Original', rotation=0, ha='right')\n\n        # Grad-CAM\n        cls_pred, cam = grad_cam(model=model, x=x, layer_name=layer_name)\n        _, _, img_grad_cam = superimpose(img, cam)\n        axs[1, i].imshow(img_grad_cam)\n        axs[1, i].set_title('pred: ' + class_to_label[cls_pred])\n        axs[1, i].set_xticks([])\n        axs[1, i].set_yticks([])\n        if i == 0:\n            axs[1, i].set_ylabel('Grad-CAM', rotation=0, ha='right')\n\n        # Grad-CAM++\n        cls_pred, cam = grad_cam_plus_plus(model=model, x=x, layer_name=layer_name)\n        _, _, img_grad_cam_plus_plus = superimpose(img, cam)\n        axs[2, i].imshow(img_grad_cam_plus_plus)\n        axs[2, i].set_title('pred: ' + class_to_label[cls_pred])\n        axs[2, i].set_xticks([])\n        axs[2, i].set_yticks([])\n        if i == 0:\n            axs[2, i].set_ylabel('Grad-CAM++', rotation=0, ha='right')\n\n        # Score-CAM\n        cls_pred, cam = score_cam(model=model, x=x, layer_name=layer_name)\n        _, _, img_score_cam = superimpose(img, cam)\n        axs[3, i].imshow(img_score_cam)\n        axs[3, i].set_title('pred: ' + class_to_label[cls_pred])\n        axs[3, i].set_xticks([])\n        axs[3, i].set_yticks([])\n        if i == 0:\n            axs[3, i].set_ylabel('Score-CAM', rotation=0, ha='right')\n\n    plt.show()","305f9c31":"## buildings\n\n_compare(model=model, layer_name=model.layers[-2].name, target_cls=0)","0c6b1bb4":"## forest\n\n_compare(model=model, layer_name=model.layers[-2].name, target_cls=1)","4259388d":"## glacier\n\n_compare(model=model, layer_name=model.layers[-2].name, target_cls=2)","4ddd2d09":"## mountain\n\n_compare(model=model, layer_name=model.layers[-2].name, target_cls=3)","17ffe2da":"## sea\n\n_compare(model=model, layer_name=model.layers[-2].name, target_cls=4)","0c40cf43":"## street\n\n_compare(model=model, layer_name=model.layers[-2].name, target_cls=5)","10452c9b":"Score-CAM:\n","4d2a3752":"0. Abstract\n\nThis notebook will examine behaviors of each visual explanation methods of deep learning model.\nThe model will train classifying to **_6 classes (buildings, forest, glacier, mountain, sea, street)_** for each images using this datasets.\nThe architecture of the model will be used **_pre-trained ResNet50_** and finetuning the task.\nVisual explanation methods that will be examined are\n\n\\- **_Grad-CAM https:\/\/arxiv.org\/abs\/1610.02391_**  \n\\- **_Grad-CAM++ https:\/\/arxiv.org\/abs\/1710.11063_**  \n\\- **_Score-CAM https:\/\/arxiv.org\/abs\/1910.01279_**","c99a0b07":"11. Compare each visual methods. ","e8162610":"6. Convert images \/ labels to finetuning.","cb464092":"5. Split datasets to train and test.","7357fa6e":"Grad-CAM:\n","29d14d73":"10. Implement Grad-CAM, Grad-CAM++ and Score-CAM. First, implement the function to superimpose original image and heatmap of each cams.","9ec4a60c":"7. Setting ResNet50 model for finetuning.","e9bec760":"Grad-CAM++:","643dbf56":"1. Import libraries.","342d5e93":"2. Setting\n\n\\- Default size (W, H) of images  \n\\- The dictionary to exchange classes and labels  \n\\- The function to getting images \/ labels from directories","aecba634":"3. Getting images \/ labels.","f696a845":"8. Finetuning.","2e02decf":"4. Visualize some images \/ labels for each classes.","5e8bd310":"9. Confirm the result of finetuning."}}