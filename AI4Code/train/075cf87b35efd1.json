{"cell_type":{"3b7cf8a8":"code","b9b23159":"code","f7e5e061":"code","17f62908":"code","016e65a3":"code","3cb2edbd":"code","e91819a9":"code","ac57fbfa":"code","5a287a88":"code","45790dd7":"code","df35259d":"code","11754258":"code","00b490f8":"code","98e0bc7d":"code","f533a1ed":"code","ce024e29":"markdown","54b1d826":"markdown","6ed26cee":"markdown","a7b85b9b":"markdown","788c6665":"markdown","c9176bc0":"markdown","3e83b226":"markdown","3d14cb6c":"markdown","faca765f":"markdown","2432f803":"markdown","9b649371":"markdown","ffe04946":"markdown","d1869625":"markdown","1699ca83":"markdown","f8369c88":"markdown","a2235580":"markdown","2489b77f":"markdown"},"source":{"3b7cf8a8":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9b23159":"data = pd.read_csv('..\/input\/csv-datacsv\/Interview_Dataset_0901_csv.csv')\ndata.head()","f7e5e061":"for col in list(data.columns):\n    print('#----',col,'----#')\n    print(data[col].unique())","17f62908":"data.dtypes","016e65a3":"import re\n\n# test_str = 'qwerty%9.0'\n# re.sub('[^0-9.]+', '', test_str)\n\ndef replace_(str_):\n    \n    str_corr = re.sub('[^0-9.]+', '', str_)\n    \n    return str_corr","3cb2edbd":"test_str = 'qwerty%9.0'\nreplace_(str_=test_str)","e91819a9":"#Applying the UDF to all the values of the requisite column\ndata['Media Flow Corr'] = data['Media Flow'].apply(replace_) \n\n#Imputing nan cases for blank rows\ndata['Media Flow Corr'] = np.where(data['Media Flow Corr']=='',np.nan,data['Media Flow Corr']) \n\n#Conversion into float datatype for numeric aggregations (previously object)\ndata['Media Flow Corr'] = data['Media Flow Corr'].astype(float) ","ac57fbfa":"data['Media Flow Corr'].unique()","5a287a88":"data.isnull().sum()","45790dd7":"data = data[data['Media Flow Corr'].isnull()==False]\ndata.shape","df35259d":"data.head(10)","11754258":"week_group = data.groupby(['Country','Week Number']).agg({'Media Flow Corr':'median'}).reset_index().sort_values(['Week Number'])\nweek_group.rename(columns={'Media Flow Corr' : 'Median Flow'},inplace=True)\nweek_group","00b490f8":"import seaborn as sns\n#'SEA' 'East Coast'\nsns.set_style('darkgrid')\n\nax = sns.lineplot(x=week_group[week_group['Country']=='India']['Week Number'],\n                  y=week_group[week_group['Country']=='India']['Median Flow'],color='r',marker='o')\n\nax = sns.lineplot(x=week_group[week_group['Country']=='SEA']['Week Number'],\n                  y=week_group[week_group['Country']=='SEA']['Median Flow'],color='y',marker='o')\n\nax = sns.lineplot(x=week_group[week_group['Country']=='East Coast']['Week Number'],\n                  y=week_group[week_group['Country']=='East Coast']['Median Flow'],color='b',marker='o')\n\nax.set(title='Median Flow vs Week Number')","98e0bc7d":"verticals_group = data.groupby(['Linked Client Vertical']).agg({'Media Flow Corr':'sum'}).reset_index().sort_values(['Linked Client Vertical'])\nverticals_group.rename(columns={'Media Flow Corr' : 'Total Flow'},inplace=True)\nverticals_group['perc_contri'] = 100 * verticals_group['Total Flow']\/verticals_group['Total Flow'].sum()\nverticals_group.sort_values(['perc_contri'],inplace=True,ascending=False)\nverticals_group","f533a1ed":"import matplotlib.pyplot as plt\n\nfig,axes = plt.subplots(1,1,sharex=False,figsize=(17,5)) \nax = sns.barplot(x=verticals_group['Linked Client Vertical'],y=verticals_group['perc_contri'])","ce024e29":"# END","54b1d826":"#### Insight - There seems to be a increasing trend in overall median flow amount for India except for week 30 & 31. Need larger data set to explore this trend or generalise it. The other countries have very less data points to comment on. ","6ed26cee":"# All special characters have been reduced and the datatype is changed","a7b85b9b":"## 2. Bar plot of total Flow value across verticals of advertisers to guage the profitable verticals","788c6665":"### Insight - The top 4 verticals i.e Food Tech, OTT, Ecomm, Lifestyle have a combined share of ~71% of total Flow, hence, these are the most valuable verticals of customers ","c9176bc0":"## Testing the above UDF before applying dynamically","3e83b226":"# Checking the existence of garbage values in each column present","3d14cb6c":"# Creating the cleaned column for the Media Flow ----> Media Flow Corr","faca765f":"### 1. Line plot of median Flow vs week Number","2432f803":"# Checking the data types of each column (especially Media Flow column)","9b649371":"# Importing data","ffe04946":"# Few other metrics that can be derived : \n\n1. Top 3 clients in the most profitable verticals for the purpose of retention or restrategy purpose\n2. Region wise top & worst performing verticals - To direct the concerned regional teams to focus on the worst verticals as well as reinforce the best performing verticals \n3. Calculate % change w\/w for flow across the slice of regions to guage the performance of each region against each other\n4. ","d1869625":"# Generating insights","1699ca83":"### Note - Since, only 3 records are null for the corrected Media Flow column, we can simply remove the 3 records (~1.7%). But for higher null values (>10%), imputation is the way to go","f8369c88":"### Checking the unique values to determine if the operation has worked","a2235580":"# Defining the UDF for special character removal from the to-be numeric column","2489b77f":"# Null check for all the columns"}}