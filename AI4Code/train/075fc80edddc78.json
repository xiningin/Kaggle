{"cell_type":{"cfa42aac":"code","b31e5c69":"code","d588c19e":"code","dc1bf2e3":"code","3007a89e":"code","c6315087":"code","779806e1":"code","4d5bfc0b":"code","73668a3c":"code","9278bf89":"code","86ee7bc5":"code","28cbae69":"code","ae83617c":"code","6bf42393":"code","83f90471":"code","3383b768":"code","0d3f0522":"code","8ab46a2f":"code","7a7f4f7d":"code","fd98c389":"code","9ae9adf2":"code","a519275d":"code","60e0c439":"code","d5f34f87":"code","57cffabd":"code","4b06ba2d":"code","f5755cf7":"code","f3f85cd9":"code","1196a5ee":"code","dc0acbee":"code","d6c76a6f":"code","d512e517":"code","22121e99":"code","c86e1675":"markdown","69605797":"markdown","3a09ce83":"markdown","34b84b0f":"markdown","ef7b9113":"markdown","8daed3b5":"markdown","54ecc51e":"markdown","1c1a114b":"markdown","cc2f55fa":"markdown","c71154d0":"markdown","25e0db6f":"markdown","9631545a":"markdown"},"source":{"cfa42aac":"import pandas as pd \nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","b31e5c69":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","d588c19e":"rawdata = pd.read_csv('\/kaggle\/input\/absenteeism-at-works\/absenteeism.csv')","dc1bf2e3":"pd.options.display.max_columns = None","3007a89e":"rawdata","c6315087":"df = rawdata.copy()","779806e1":"df.info()","4d5bfc0b":"df = df.drop(['ID'], axis = 1) ","73668a3c":"len(df['Reason for absence'].unique())","9278bf89":"sorted(df['Reason for absence'].unique())","86ee7bc5":"rcol = pd.get_dummies(df['Reason for absence'])","28cbae69":"rcol['check'] = rcol.sum(axis=1)","ae83617c":"rcol['check'].unique() #checking if for sure every person have only one reason ","6bf42393":"rcol = rcol.drop(['check'], axis=1)","83f90471":"rcol = pd.get_dummies(df['Reason for absence'], drop_first = True) #drop reason '0'\nrcol","3383b768":"df = df.drop(['Reason for absence'], axis=1) #drop 'Reason for absence', replace with dummies. \ndf","0d3f0522":"# merging dummies into 4 categories based on reason for abscence\nreasontype1 = rcol.loc[:, 1:14].max(axis=1)\nreasontype2 = rcol.loc[:, 15:17].max(axis=1)\nreasontype3 = rcol.loc[:, 18:21].max(axis=1)\nreasontype4 = rcol.loc[:, 22:28].max(axis=1)","8ab46a2f":"print(reasontype1.sum(), reasontype2.sum(), reasontype3.sum(), reasontype4.sum())","7a7f4f7d":"df = pd.concat([df, reasontype1, reasontype2, reasontype3, reasontype4], axis = 1)\ndf","fd98c389":"column_names = ['Month of absence', 'Day of the week', 'Seasons',\n       'Transportation expense', 'Distance from Residence to Work',\n       'Service time', 'Age', 'Work load Average\/day ', 'Hit target',\n       'Disciplinary failure', 'Education', 'Son', 'Social drinker',\n       'Social smoker', 'Pet', 'Weight', 'Height', 'Body mass index',\n       'Absenteeism time in hours', 'Reason1', 'Reason2', 'Reason3', 'Reason4']\ndf.columns = column_names\ndf","9ae9adf2":"reordered = ['Reason1', 'Reason2', 'Reason3', 'Reason4','Month of absence', 'Day of the week', 'Seasons',\n       'Transportation expense', 'Distance from Residence to Work',\n       'Service time', 'Age', 'Work load Average\/day ', 'Hit target',\n       'Disciplinary failure', 'Education', 'Son', 'Social drinker',\n       'Social smoker', 'Pet', 'Weight', 'Height', 'Body mass index',\n       'Absenteeism time in hours']","a519275d":"df = df[reordered]\ndf","60e0c439":"df_mod1 = df.copy()\ndf_mod1","d5f34f87":"#correlation matrix\ncormatrix = df_mod1.corr()\nplt.subplots(figsize=(8, 8))\nsns.heatmap(cormatrix, vmin=-1, vmax=1, center= 0, cmap= 'coolwarm')","57cffabd":"cols = cormatrix.nlargest(10, 'Absenteeism time in hours')['Absenteeism time in hours'].index\ncorrcoef = np.corrcoef(df_mod1[cols].values.T)\nplt.subplots(figsize=(8, 8))\nsns.heatmap(corrcoef, annot=True,  yticklabels=cols.values, xticklabels=cols.values, vmin=-1, vmax=1, center= 0,  cmap= 'coolwarm')","4b06ba2d":"df_mod2 = df_mod1.copy() ","f5755cf7":"df_mod2 = df_mod2.drop(['Month of absence','Distance from Residence to Work','Body mass index'], axis = 1)","f3f85cd9":"df_mod2['Education'].unique()","1196a5ee":"df_mod2['Education'].value_counts()","dc0acbee":"df_mod2['Education'] = df_mod2['Education'].map({1:0, 2:1, 3:1, 4:1})","d6c76a6f":"df_mod2['Education'].value_counts()","d512e517":"d_pre = df_mod2.copy()\nd_pre","22121e99":"d_pre.to_csv('Absenteeism_preprocessed.csv', index=False)","c86e1675":"rcolumn is new dataframe with 28 columns which contains information about which I wrote above.\n\nTo this data frame we can add another column where it will be sum:","69605797":"Adding to data frame and rename it and then reordering columns because we want to see the reason first:","3a09ce83":"Next column, Reason from Absence - we have to keep in mind that they are represent categories that are equally meaningful so they are categorical nominal variables. We use numbers and provide to them descriptions because using less characters will think the volume of our dataset, it's easier to digest, btw it is called \u201cdatabase theory\u201d.\n\nExtracting distinct values only:","34b84b0f":"After loading a data always I\u2019m exploring it manually. It helps to have some first predictions. Sometimes it helps find some errors - even like importing wrong file \ud83d\ude05 and let us dive in into problem. Jupyter Notebook or JupyterLab dont let us see whole table so I can use:","ef7b9113":"There is no number \u201920\u2019 in the list. That means that nobody left the work because of \u201cExternal causes of morbidity and mortality\u201d (we know from the additional info UCI_ABS_TEXT) phew! We have to change this variables into dummy variables. Dummy variable is an explanatory binary variable that equals 1 - if a certain categorical effect is present 0 - if the same effect is absent\n\nWe our data we will do like this: 1 - if person was absent because of reason 1 0 - if person was absent because any other reason\n\nnext: 1 - if person was absent because of reason 2 0 - if person was absent because any other reason\n\nFortunately I don\u2019t have to do it manually it is possible thanks to panda by simply .get_dummies()","8daed3b5":"In next stage I have to drop column \u20180\u2019 from rcolumn dataframe. I'm doing this to avoid multicollinearity. For n categories we using n-1 dummies so I am dealing with 28 categories so I need only 27 dummies. (https:\/\/www.quora.com\/How-and-why-having-the-same-number-of-dummy-variables-as-categories-is-problematic-in-linear-regression-Dummy-variable-trap-Im-looking-for-a-purely-mathematical-not-intuitive-explanation-Also-please-avoid-using-the)\n\nIn original \u2018dataset\u2019 I still have column called \u2018Reason for absence\u2019, if we will leave it we will have duplication of information which lead to multicollinearity. So lets drop this column from \u2018dataset\u2019. If we will add our \u2018rcolumn\u2019 into \u2018dataset\u2019 that means that we will have additional 27 columns in dataframe. A bit too much. Lets group these variables, this action we call classification. We will group basing on features descriptions: Reson1 1-14 diseases Reason2 15-17 - pregnancy related Reason 3 18 - 21 - poisonings Reason 4 22-28 - light reasons\n\nWe will create new data frame for each group. Thats why we needed to drop column with ID - because we need every individual have only one reason being out of work. So now we want to create a tables with only type of reason\n","54ecc51e":"Now we can see that 611 is undergraduate and only 129 people holds higher degree (graduate, postgraduate, a master or a doctor) so it is not so relevant anymore. We can combine them in single category. We can assign undergraduate as 0 and at least graduate to 1: 1 -> 0 2 -> 1 3 -> 1 4 -> 1","1c1a114b":"ID - individual identification - indicates precisely who has been away during working hours. It is a label variable to distinguish the individuals from one another, not to carry any numeric information.\n\nWe have to drop variable \u201cID\u201d because it harm the estimation.","cc2f55fa":"Dataset: https:\/\/archive.ics.uci.edu\/ml\/datasets\/Absenteeism+at+work here you can download dataset and description to it\n\nAlways we starting with data preprocessing: group of operations that will convert raw data into a format that is easier to understand and useful for further processing and analysis. Also helps organize information in suitable and practical way. It takes the most of the time and it is crucial part of every analytical ask. While preprocessing we make raw dataset usable for machine learning algorithm.","c71154d0":"I called it df_mod1 which stands for modified dataframe version 1. It is very good practice to creating checkpoints - it is help to organize, storing the current version of code so we reducing risk of losing our data at a later stages. We don\u2019t have to do anything with date - month and the day of the week.\n\nLet\u2019s move to next columns: Transportation Expense, Distance, Age, Daily Work Load, BMI - we are not going to manipulate them too.\n\nWhat we have next is:\u2028 \u2018Education\u2019\u2028(high school (1), graduate (2), postgraduate (3), master and doctor (4)) 'Son\u2019 - Number of children \u2018Pet\u2019 - Number of pets Columns \u2018Son\u2019 and \u2018Pet\u2019 we will leave untouched.\n\nWe have to change education into dummy variable. To not scroll down everything lets check what we have in \u2018education\u2019 variable","25e0db6f":"Saving file as csv: ","9631545a":"Creating a checkpoints - an interim save of your work"}}