{"cell_type":{"c4dd1a91":"code","4da7a5ca":"code","6a8ed66d":"code","98db4b87":"code","3fe363f4":"code","5694bf49":"code","9cacfde5":"code","4b566708":"code","6cc90573":"code","f43fe943":"code","ac92d044":"code","1a55642f":"code","360daaf4":"code","6d17595b":"code","cac5feb1":"code","3a7c6e2b":"code","f6e0f6b2":"code","e599b0d9":"code","700c4b70":"code","edabd620":"code","2a5d80af":"code","d9755fa3":"code","63094609":"code","6e2ad59b":"code","12033cc0":"code","4f41ed9e":"code","38ff1560":"code","01168407":"code","de019092":"code","1942ea6f":"code","1b0c97df":"code","18491d8d":"code","b0b0b732":"code","3f0a7865":"code","7256389b":"code","6cbd5c8f":"code","fb8edf00":"code","9be057ac":"code","a7b399bc":"code","34fedd5d":"code","abc1631a":"code","5b74b745":"code","20387184":"code","77e86a38":"code","6b73c4e1":"code","3953bf2e":"code","ba9481cf":"code","5581cea5":"code","a7e60b65":"code","ac73c058":"code","5453505d":"code","bf61021d":"code","9410a918":"code","063b9a39":"code","33e565ad":"code","1fbe4af2":"code","dcf1e981":"code","266d1283":"code","da9e543d":"code","8801a39f":"code","8c451bc9":"code","0ed8f1b9":"code","bd808b7e":"code","71f92d2a":"code","da827777":"code","7e3a3dfb":"code","914ae5e5":"code","ea990d92":"code","4c84deb0":"code","03ed08d1":"code","8058a4ef":"code","66356d7c":"code","6479689a":"code","c45b762e":"code","b8a19cc7":"markdown","06b1027f":"markdown","74aa07ea":"markdown","e855fedf":"markdown","f3edb4eb":"markdown","aba9e878":"markdown","d5fd3331":"markdown","8d7564cf":"markdown","838fd00e":"markdown","b669da76":"markdown","a0e34f1b":"markdown","cbe6d358":"markdown","58a759a0":"markdown"},"source":{"c4dd1a91":"from datetime import datetime\n\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score,confusion_matrix,classification_report,plot_confusion_matrix\n\nimport tensorflow as tf\n\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\n\nimport warnings\nwarnings.filterwarnings('ignore')","4da7a5ca":"df = pd.read_csv('..\/input\/heart-disease-uci\/heart.csv')\n\ndf.sample(5)","6a8ed66d":"df.shape","98db4b87":"df.isna().sum()","3fe363f4":"df.describe().T","5694bf49":"df['sex'].value_counts()","9cacfde5":"df['cp'].value_counts()","4b566708":"sns.countplot('sex', hue = 'target', data = df)\n\nplt.title('Heart Disease Frequency for Gender')\nplt.legend([\"No Disease\", \"Yes Disease\"])\n\nplt.xlabel('Gender (0 = Female, 1 = Male)')\nplt.ylabel('Frequency')\n\nplt.show()","6cc90573":"plt.figure(figsize = (20, 8))\nsns.countplot('age', hue = 'target', data = df)\n\nplt.title('Heart Disease Frequency for Age')\nplt.legend([\"No Disease\", \"Yes Disease\"])\n\nplt.xlabel('Age')\nplt.ylabel('Frequency')\n\nplt.show()","f43fe943":"plt.figure(figsize = (10, 8))\n\nplt.scatter(df['age'], df['chol'], s = 200)\n\nplt.xlabel('Age', fontsize = 20)\nplt.ylabel('Cholestrol', fontsize = 20)\nplt.show()","ac92d044":"features = df.drop('target', axis=1)\n\ntarget = df[['target']]","1a55642f":"features.sample(5)","360daaf4":"target.sample(5)","6d17595b":"categorical_features = features[['sex', 'fbs', 'exang', 'cp', 'ca', 'slope', 'thal', 'restecg']].copy()\n\ncategorical_features.head()","cac5feb1":"numeric_features = features[['age', 'trestbps', 'chol', 'thalach', 'oldpeak']].copy()\n\nnumeric_features.head()","3a7c6e2b":"standardScaler = StandardScaler()\n\nnumeric_features = pd.DataFrame(standardScaler.fit_transform(numeric_features), \n                                columns=numeric_features.columns,\n                                index=numeric_features.index)\n\nnumeric_features.describe()","f6e0f6b2":"processed_features = pd.concat([numeric_features, categorical_features], axis=1,\n                               sort=False)\n\nprocessed_features.head()","e599b0d9":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(processed_features, \n                                                    target, \n                                                    test_size = 0.2, \n                                                    random_state=1)","700c4b70":"x_train.shape, y_train.shape","edabd620":"x_test.shape, y_test.shape","2a5d80af":"x_train, x_val, y_train, y_val = train_test_split(x_train, \n                                                  y_train, \n                                                  test_size=0.15,\n                                                  random_state=10)","d9755fa3":"x_train.shape, x_val.shape, x_test.shape","63094609":"y_train.shape, y_val.shape, y_test.shape","6e2ad59b":"def build_model():\n    \n    inputs = tf.keras.Input(shape=(x_train.shape[1],))\n\n    dense_layer1 = layers.Dense(12, activation='relu')\n    x = dense_layer1(inputs)\n\n    dropout_layer = layers.Dropout(0.3)\n    x = dropout_layer(x)\n    \n    dense_layer2 = layers.Dense(8, activation='relu')\n    x = dense_layer2(x)\n\n    predictions_layer = layers.Dense(1, activation='sigmoid')\n    predictions = predictions_layer(x)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=predictions)\n    \n    model.summary()\n    \n    model.compile(optimizer=tf.keras.optimizers.Adam(0.001),\n                  loss=tf.keras.losses.BinaryCrossentropy(),\n                  metrics=['accuracy', \n                           tf.keras.metrics.Precision(0.5),\n                           tf.keras.metrics.Recall(0.5),])\n    return model","12033cc0":"model = build_model()","4f41ed9e":"dataset_train = tf.data.Dataset.from_tensor_slices((x_train.values, y_train.values))\ndataset_train = dataset_train.batch(16)\n\ndataset_train.shuffle(128)","38ff1560":"num_epochs=100","01168407":"dataset_val = tf.data.Dataset.from_tensor_slices((x_val.values, y_val.values))\ndataset_val = dataset_val.batch(16)","de019092":"model = build_model()\n\ntraining_history = model.fit(dataset_train, epochs=num_epochs, validation_data=dataset_val)","1942ea6f":"training_history.history.keys()","1b0c97df":"train_acc = training_history.history['accuracy']\ntrain_loss = training_history.history['loss']\n\nprecision = training_history.history['precision_1']\nrecall = training_history.history['recall_1']\n\nepochs_range = range(num_epochs)\n\nplt.figure(figsize=(14, 8))\n\nplt.subplot(1, 2, 1)\n\nplt.plot(epochs_range, train_acc, label='Training Accuracy')\nplt.plot(epochs_range, train_loss, label='Training Loss')\n\nplt.title('Accuracy and Loss')\nplt.legend()\n\nplt.subplot(1, 2, 2)\n\nplt.plot(epochs_range, precision, label='Precision')\nplt.plot(epochs_range, recall, label='Recall')\n\nplt.title('Precision and Recall')\nplt.legend()","18491d8d":"score = model.evaluate(x_test, y_test)\n\nscore_df = pd.Series(score, index = model.metrics_names)\n\nscore_df","b0b0b732":"y_pred = model.predict(x_test)\n\ny_pred[:10]","3f0a7865":"y_pred = np.where(y_pred>=0.5, 1, y_pred)\n\ny_pred = np.where(y_pred<0.5, 0, y_pred)","7256389b":"y_pred[:10]","6cbd5c8f":"pred_results = pd.DataFrame({'y_test': y_test.values.flatten(),\n                             'y_pred': y_pred.flatten().astype('int32') }, index = range(len(y_pred)))","fb8edf00":"pred_results.sample(10)","9be057ac":"pd.crosstab(pred_results.y_pred, pred_results.y_test)","a7b399bc":"accuracy_score(y_test, y_pred)","34fedd5d":"precision_score(y_test, y_pred)","abc1631a":"recall_score(y_test, y_pred)","5b74b745":"from sklearn.model_selection import RandomizedSearchCV, GridSearchCV\nfrom sklearn.ensemble import RandomForestClassifier","20387184":"model = RandomForestClassifier()\n# Fit the model to the data\nmodel.fit(x_train, y_train)\nmodel.score(x_test, y_test)","77e86a38":"# Different RandomForestClassifier hyperparameters\nrf_grid = {\"n_estimators\": np.arange(10, 1000, 50),\n           \"max_depth\": [None, 3, 5, 10],\n           \"min_samples_split\": np.arange(2, 20, 2),\n           \"min_samples_leaf\": np.arange(1, 20, 2)}","6b73c4e1":"# Setup random seed\nnp.random.seed(42)\n\n# Setup random hyperparameter search for RandomForestClassifier\nrs_rf = RandomizedSearchCV(RandomForestClassifier(),\n                           param_distributions=rf_grid,\n                           cv=5,\n                           n_iter=20,\n                           verbose=True)\n\n# Fit random hyperparameter search model\nrs_rf.fit(x_train, y_train);","3953bf2e":"# Find the best parameters\nrs_rf.best_params_","ba9481cf":"# Evaluate the randomized search random forest model\nrs_rf.score(x_test, y_test)","5581cea5":"preds = model.predict(x_test)","a7e60b65":"confusion_matrix(y_test,preds)","ac73c058":"n_estimators=[64,100,128,200]\nmax_features= [2,3,4]\nbootstrap = [True,False]\noob_score = [True,False]","5453505d":"param_grid = {'n_estimators':n_estimators,\n             'max_features':max_features,\n             'bootstrap':bootstrap,\n             'oob_score':oob_score} ","bf61021d":"rfc = RandomForestClassifier()\ngrid = GridSearchCV(rfc,param_grid)","9410a918":"grid.fit(x_train,y_train)","063b9a39":"grid.best_params_","33e565ad":"predictions = grid.predict(x_test)","1fbe4af2":"print(classification_report(y_test,predictions))","dcf1e981":"plot_confusion_matrix(grid,x_test,y_test)","266d1283":"model.feature_importances_","da9e543d":"feats = pd.DataFrame(index=processed_features.columns,data=model.feature_importances_,columns=['Importance'])","8801a39f":"feats","8c451bc9":"imp_feats = feats[feats['Importance']>0]","0ed8f1b9":"imp_feats","bd808b7e":"imp_feats = imp_feats.sort_values(\"Importance\")","71f92d2a":"plt.figure(figsize=(14,6),dpi=200)\nsns.barplot(data=imp_feats.sort_values('Importance'),x=imp_feats.sort_values('Importance').index,y='Importance')\n\nplt.xticks(rotation=90);\n","da827777":"from xgboost import XGBClassifier\nclassifier = XGBClassifier()\nclassifier.fit(x_train, y_train)","7e3a3dfb":"y_pred = classifier.predict(x_test)\ncm = confusion_matrix(y_test, y_pred)\nprint(cm)\naccuracy_score(y_test, y_pred)","914ae5e5":"accuracies = cross_val_score(estimator = classifier, X = x_train, y = y_train, cv = 10)\nprint(\"Accuracy: {:.2f} %\".format(accuracies.mean()*100))\nprint(\"Standard Deviation: {:.2f} %\".format(accuracies.std()*100))","ea990d92":"classifier.feature_importances_","4c84deb0":"feats = pd.DataFrame(index=processed_features.columns,data=classifier.feature_importances_,columns=['Importance'])","03ed08d1":"feats","8058a4ef":"imp_feats = feats[feats['Importance']>0]","66356d7c":"imp_feats","6479689a":"imp_feats = imp_feats.sort_values(\"Importance\")","c45b762e":"plt.figure(figsize=(14,6),dpi=200)\nsns.barplot(data=imp_feats.sort_values('Importance'),x=imp_feats.sort_values('Importance').index,y='Importance')\n\nplt.xticks(rotation=90);","b8a19cc7":"Plotting accuracy","06b1027f":"# Data Visualization","74aa07ea":"### Heart Disease classification","e855fedf":"# Random Forest","f3edb4eb":"Importing Libraries","aba9e878":"Prediction","d5fd3331":"Model evaluation","8d7564cf":"### Splitting dataset into training and testing data","838fd00e":"## Applying k-Fold Cross Validation","b669da76":"Building the model","a0e34f1b":"# XGBoost","cbe6d358":"### Splitting the data","58a759a0":"## Making the Confusion Matrix"}}