{"cell_type":{"650c2a88":"code","3ce4d002":"code","70e690ec":"code","8bd2cd0c":"code","333a2fc3":"code","cf9dfa72":"code","0dfd1a5a":"code","f4ef5375":"code","4862e7e0":"code","6036cf79":"code","48e8e89a":"code","066bfeaa":"code","fb670ca1":"code","9e9c70d3":"code","a17c83cf":"markdown","baf60394":"markdown","afe0cdae":"markdown","b2849ac7":"markdown","76f11bc7":"markdown","a92e8ecc":"markdown","d430f78c":"markdown","0f4f052f":"markdown","da0b8e4e":"markdown","d470276a":"markdown","3611ff55":"markdown","e4efddf0":"markdown","fb940d42":"markdown","732a58be":"markdown","3e14f20f":"markdown","87b1d471":"markdown","42b791c8":"markdown"},"source":{"650c2a88":"#Basic libraries\nimport os\nimport glob\nimport numpy as np\nimport pandas as pd\n\n#Visualization libraries\nimport cv2\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib.image as mpimg\n\n#ML libraries\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.preprocessing import OneHotEncoder\n\n#DL libraries\nimport tensorflow as tf\nfrom keras.preprocessing import image\nfrom keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import RMSprop\nfrom keras.layers import Dense, Input, Conv2D, MaxPool2D, Flatten\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\n#Setting a seed\nnp.random.seed(22)\n\n#Ignore warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")","3ce4d002":"#Function for reading the images\ndef get_data(path,label):\n    '''The function returns array of images and their respective label\n        It also resizes the image and gives the color\n        \n        Parameters:\n        1.path-path of the image directory\n        2.label-label for the images '''\n    \n    #Reading the file name of images\n    files=np.array(os.listdir(path))\n    \n    #Adding the user defined labels\n    labels=np.array([label]*len(files))\n    \n    #Read the images using cv2 and resizing the images\n    images=[]\n    for image in files:\n        image=cv2.imread(path+image)\n        image=cv2.resize(image,dsize=(200,200))\n        image=cv2.cvtColor(image,cv2.COLOR_BGR2GRAY)\n        images.append(image)\n        \n    #Converting to array\n    images=np.array(images)\n    \n    return images,labels\n\n#Applying the function and get the images for the normal and pneumonia images for training\nnormal_images,normal_labels=get_data('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/NORMAL\/','normal')\npneumonia_images,pneumonia_labels=get_data('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/train\/PNEUMONIA\/','pneumonia')\n\n#Applying the function and get the images for the normal and pneumonia images for testing\nnormal_images_test,normal_labels_test=get_data('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/NORMAL\/','normal')\npneumonia_images_test,pneumonia_labels_test=get_data('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/test\/PNEUMONIA\/','pneumonia')\n\n\n#Preparing the independent and dependent training set\nX_train=np.append(normal_images,pneumonia_images,axis=0)\ny_train=np.append(normal_labels,pneumonia_labels)\n\n#Preparing the independent and dependent testing set\nX_test=np.append(normal_images_test,pneumonia_images_test,axis=0)\ny_test=np.append(normal_labels_test,pneumonia_labels_test)\n\n#Displaying the shape of data\nprint(\"Image size: \",X_train.shape)\nprint(\"Label size: \",y_train.shape)\n\n#Displaying the number of labels\nprint(\"Labels: \",np.unique(y_train))","70e690ec":"#Storing the path\npath = \"\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/\"\n\n#Setting the labels\nsets = [\"train\", \"test\", \"val\"]\n\n#Creating empty lists to store images\nall_pneumonia = []\nall_normal = []\n\n#Appending the normal and pneumonia images\nfor i in sets:\n    path = os.path.join(path, i)\n    normal = glob.glob(os.path.join(path, \"NORMAL\/*.jpeg\"))\n    pneumonia = glob.glob(os.path.join(path, \"PNEUMONIA\/*.jpeg\"))\n    all_normal.extend(normal)\n    all_pneumonia.extend(pneumonia)","8bd2cd0c":"#Setting up the plot size\nfig,ax=plt.subplots(ncols=7,nrows=2,figsize=(20,7))\n\n#Getting random index points\nindices=np.random.choice(len(X_train),14)\ncounter=0\n\n#Displaying subplots of images with labels\nfor i in range(2):\n    for j in range(7):\n        ax[i,j].set_title(y_train[indices[counter]])\n        ax[i,j].imshow(X_train[indices[counter]],cmap='gray')\n        ax[i,j].get_xaxis().set_visible(False)\n        ax[i,j].get_yaxis().set_visible(False)\n        counter+=1\n\nplt.show()","333a2fc3":"#labelling the output\nlabels=['Normal','Pneumonia']\n\n#Getting the sum of each outcome\ntargets=[len(normal_images),len(pneumonia_images)]\n\n#Plotting the piechart\nplt.style.use('ggplot')\nplt.figure(figsize=(16,9))\nplt.pie(x=targets,labels=labels,autopct=\"%1.1f%%\")\nplt.title(\"Image category distribution\")\nplt.show()","cf9dfa72":"#Setting the figsize\nfig=plt.figure(figsize=(14, 5))\n\n#Setting up the frame for subplots\ncolumns = 5; rows = 2\n\n#Partitioning the dataset\nimages=all_pneumonia[:50]+all_normal[:50]\n\n#Plotting the images\nfor i in range(1, columns*rows +1):\n    img = cv2.imread(images[i])\n    img = cv2.resize(img, (512, 512))\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    edges = cv2.Canny(img, 80, 100)\n    fig.add_subplot(rows, columns, i)\n    plt.imshow(edges)\n    plt.axis(False)","0dfd1a5a":"#Reshaping the dataset by adding a new axis\ny_train=y_train[:,np.newaxis]\ny_test=y_test[:,np.newaxis]\n\n#Initialize onehot encoder\nencode=OneHotEncoder(sparse=False)\n\n#Encoding the images\ny_train_encode=encode.fit_transform(y_train)\ny_test_encode=encode.transform(y_test)","f4ef5375":"#Reshaping the independent data\nX_train=X_train.reshape(X_train.shape[0],X_train.shape[1],X_train.shape[2],1)\nX_test=X_test.reshape(X_test.shape[0],X_test.shape[1],X_test.shape[2],1)","4862e7e0":"#Data augumentation using ImageDataGenerator\ndatagen=ImageDataGenerator(\nrotation_range=10,\nzoom_range=0.1,\nwidth_shift_range=0.1,\nheight_shift_range=0.1)\n\ndatagen.fit(X_train)\n\n#Applying the data augumentation on all training and testing images\ntraingen=datagen.flow(X_train,y_train_encode,batch_size=32)\ntestgen=datagen.flow(X_test,y_test_encode,batch_size=32)","6036cf79":"#Creating a CNN architecture\nmodel=tf.keras.models.Sequential([\n    #Input layer\n    tf.keras.layers.Conv2D(16,(3,3),activation='relu',input_shape=(200,200,1)),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    #Hidden layer 1\n    tf.keras.layers.Conv2D(32,(3,3),activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n   \n    #Hidden layer 2\n    tf.keras.layers.Conv2D(64,(3,3),activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    \n    #Hidden layer 3\n    tf.keras.layers.Conv2D(128,(3,3),activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    #Hidden layer 4\n    tf.keras.layers.Conv2D(256,(3,3),activation='relu'),\n    tf.keras.layers.BatchNormalization(),\n    tf.keras.layers.MaxPooling2D(2,2),\n    tf.keras.layers.Dropout(0.2),\n    \n    #Flatten layer\n    tf.keras.layers.Flatten(),\n    tf.keras.layers.Dense(512,activation='relu'),\n    tf.keras.layers.Dropout(0.7),\n    tf.keras.layers.Dense(128,activation='relu'),\n    tf.keras.layers.Dropout(0.5),\n    tf.keras.layers.Dense(64,activation='relu'),\n    tf.keras.layers.Dropout(0.3),\n    \n    #Output layer\n    tf.keras.layers.Dense(2,activation='sigmoid')\n    \n    \n])\n\n#Display the model summary\nmodel.summary()\n\n\n#Compling the model with loss and optimizer function\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\n\n# Callbacks\ncheckpoint = ModelCheckpoint(filepath='best_weights.hdf5', save_best_only=True, save_weights_only=True)\nlr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=3, verbose=2, mode='max')\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=3, mode='min')","48e8e89a":"#Training the images with CNN model\nhistory=model.fit_generator(traingen,epochs=30,validation_data=(X_test,y_test_encode),callbacks=[checkpoint,early_stop,lr_reduce])","066bfeaa":"#Setting up image size\nplt.figure(figsize=(20,10))\n\n#Plot train and validation accuracy\nplt.title('Accuracy scores')\nplt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.legend(['accuracy','val_acc'])\nplt.show()\n\n#Plot train and validation loss\nplt.figure(figsize=(20,10))\nplt.title('Loss value')\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.legend(['loss','val_loss'])\nplt.show()","fb670ca1":"#predicting the model on test data\npredictions=model.predict(X_test)\n\n#Inverse transform the encoded images\npredictions=encode.inverse_transform(predictions)\n\n#Creating confusion matrix\ncm=confusion_matrix(y_test,predictions)\n\n#Plotting confusion matrix\nlabels=['pneumonia','normal']\nplt.title('Confusion matrix')\nsns.heatmap(cm,cbar=False,xticklabels=labels,yticklabels=labels,fmt='d',annot=True,cmap=plt.cm.Blues)\nplt.xlabel('Predicted')\nplt.ylabel('Actual')\nplt.show()","9e9c70d3":"#Calculating classification metrics\ntn,fp,fn,tp=cm.ravel()\nprecision=tp\/(tp+fp)*100\nrecall=tp\/(tp+fn)*100\nF1score=(2*precision*recall\/(precision+recall))\n\n#Displaying the metrix results\nprint(\"Precision:\",precision)\nprint(\"Recall:\",recall)\nprint(\"F1 score:\",F1score)\n\neval_result=model.evaluate_generator(testgen,624)\nprint(\"Accuracy:{}%\".format(round(eval_result[1]*100,2)))","a17c83cf":">Let's view the X rays of affected and healthy lung and try to extract any visual information\n>First lets view the actual grayscale images, here we have only 2 dimension as the 3rd dimension is absent(colour)","baf60394":"<div class=\"alert alert-block alert-info\">\n<b>\ud83d\udd0dInference:<\/b> <br>\nEdge detection in our application is crucial as we already inferred that the rib bones and lung is pale white and the edges where barely visible. But incase of normal Xrays the bones were clearly visible which is captured clearly in the above visuals\n<\/div","afe0cdae":"* [Pneumonia Prediction: A guide for your first CNN project](https:\/\/www.analyticsvidhya.com\/blog\/2021\/05\/pneumonia-prediction-a-guide-for-your-first-cnn-project\/)\n* [Deep Learning for Detecting Pneumonia from X-ray Images](https:\/\/towardsdatascience.com\/deep-learning-for-detecting-pneumonia-from-x-ray-images-fc9a3d9fdba8)","b2849ac7":"<h3 style=\"background-color:blue;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Preparing the data<\/h3>\n","76f11bc7":"## \ud83e\uddee Getting the data\n\n>We have all the images stored in folders of test, train and val. Now we are going to extract those images as path add a '.jpeg' extension and merge the normal and pneumonia affected lung X-Rays by giving them labels. We then store these information in a dataframe","a92e8ecc":"## \ud83d\udd27 Encoding and Reshaping\n\n>We cant feed the images directly to the neural network, instead we reshape the grayscale images by adding one more dimension. Also we can encode the labels using onehotencoder","d430f78c":"## \ud83d\udcc8 Evaluation of model\n\n>We have built and trained our model with images,time to evaluate with validation data . Intially lets view the loss and accuracy while we trained our model.Post that we predict the labels and view the confusion matrix and classification metrics ","0f4f052f":"## \ud83d\udcf7 Data Augmentation\n\n>Since we got a imbalanced data, lets augment the data and create more images by rotating, zooming and change the width and height. Doing that will help in reducing the bias of model and also generalize it","da0b8e4e":"## \ud83c\udfd7\ufe0f Model Building\n\n>Now its time to build the CNN architecture,following has a 5 layer Conv2d neural network with dropout in 3rd and 4th layer. I have utilized relu function in the hidden layers and sigmoid in the output layer . The model has been compiled with adam optimizer and binary cross entropy as loss function. It is later trained for 30 epochs ","d470276a":"<div class=\"alert alert-block alert-info\">\n<b>\ud83d\udd0dInference:<\/b> <br>\nFrom the pictures we can identify that the pneumonia images have more pale white occupying most of the lung area and the picture of normal lung xray is more dark and visible \n<\/div","3611ff55":"# \ud83d\udc4b Hello Kagglers!\n>There have been many advanced technology in the field of medical sciences.One of the initial breakthrough in medicine is in the diagnosis process. Especially Lungs,Heart.In early days doctor used to manually view the Xray copies and detect whether the patient has any problem or not.Due to the arrival of machine learning the process requires no human intervention and AI has been acing since then\n>\n>In this notebook we are building a similar algorithm for such application where we classify the lung Xrays on whether it has symptom of Pneumonia or not\n>\n>I am also planning to explore more on image dataset in upcoming notebooks using trained models.\n\n## \u2753 What is Pneumonia\n>Pneumonia is a lung infection that can range from mild to so severe that you have to go to the hospital. It happens when an infection causes the air sacs in your lungs (your doctor will call them alveoli) to fill with fluid or pus. That can make it hard for you to breathe in enough oxygen to reach your bloodstream.\n\n## \ud83d\udcdc Causes of Pneumonia\n\n>Bacteria, viruses, or fungi can cause pneumonia.\n>\n> ### Common causes include:\n>* Flu viruses\n>* Cold viruses\n>* RSV virus (the top cause of pneumonia in babies age 1 or younger)\n>* Bacteria called Streptococcus pneumoniae and Mycoplasma pneumoniae\n>* Lifestyle habits, like smoking cigarettes and drinking too much alcohol, can also raise your chances of getting pneumonia.\n> [Credits](https:\/\/www.webmd.com\/lung\/understanding-pneumonia-basics)","e4efddf0":"<div class=\"alert alert-block alert-info\">\n<b>\ud83d\udd0dInference:<\/b> <br>\nWe can declare that we have an unbalanced data where we got a upperhand in pneumonia images and normal pictures are very low. Even though on generalizing that we have less number of normal lungs than pneumonia affected lungs, it is crucial to reduce false positives now<br>\n<br>  \n<b>\ud83d\udca1Solution:<\/b> <br>\n The best solution we have at hand is Data Augmentation, where we can re-sample existing images and create new images by changing the properties of the images \n<\/div","fb940d42":"<h3 style=\"background-color:blue;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Exploratory data analysis<\/h3>\n","732a58be":"<h3 style=\"background-color:blue;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Libraries And Utilities<\/h3>\n","3e14f20f":"<h3 style=\"background-color:blue;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Acknowledgement and References<\/h3>\n","87b1d471":"<h3 style=\"background-color:blue;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Introduction<\/h3>\n","42b791c8":"<h3 style=\"background-color:blue;font-family:newtimeroman;font-size:200%;text-align:center;border-radius: 15px 50px;\">Building model<\/h3>\n"}}