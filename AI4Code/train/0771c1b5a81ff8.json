{"cell_type":{"6d7f1baa":"code","8ec03885":"code","46c55652":"code","f60e1767":"code","624e7166":"code","d0d28ac4":"code","7edbe90b":"code","732d9b1d":"code","7f6cd3cc":"code","8e20511a":"code","91df687e":"code","b974986d":"code","de7db0f8":"code","0398987a":"code","334677a3":"code","a71ee022":"code","76479991":"code","77733db7":"code","e42b13c3":"code","cb7ee0b1":"code","5669a4cf":"markdown","11468e34":"markdown","e42016ae":"markdown"},"source":{"6d7f1baa":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8ec03885":"# Use scikit-learn to grid search the batch size and epochs\nfrom sklearn.model_selection import GridSearchCV\n\nfrom sklearn import metrics\nimport matplotlib.pyplot as plt\n\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom tensorflow.keras.datasets import mnist\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Dense","46c55652":"(xtrain,ytrain),(xtest,ytest)=mnist.load_data()","f60e1767":"plt.imshow(xtrain[1,:,:],cmap='gray');\nprint(\"\\nDigit is -\",ytrain[1])","624e7166":"#Represent Training & Testing samples suitable for #tensorflow backend\nx_train=xtrain.reshape(xtrain.shape[0],784).astype('float32')\nx_test=xtest.reshape(xtest.shape[0],784).astype('float32')","d0d28ac4":"x_train\/=255\nx_test\/=255","7edbe90b":"from tensorflow import keras\n\ny_train = keras.utils.to_categorical(ytrain, 10)\ny_test = keras.utils.to_categorical(ytest, 10)","732d9b1d":"# Function to create model, required for KerasClassifier\ndef create_model():\n    \n    # create model\n    model = Sequential()\n    model.add(Dense(64,activation='relu'))\n    model.add(Dense(32,activation='relu'))\n    model.add(Dense(10, activation='sigmoid'))\n    \n    # Compile model\n    model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n    return model","7f6cd3cc":"# fix random seed for reproducibility\nseed = 7\nnp.random.seed(seed)","8e20511a":"# create model\nmodel = KerasClassifier(build_fn=create_model, verbose=1)","91df687e":"# define the grid search parameters\nbatch_size = [256, 1024]\nepochs     = [5,15]","b974986d":"param_grid = dict(batch_size=batch_size, epochs=epochs)\nparam_grid","de7db0f8":"# grid = GridSearchCV(estimator=model,param_grid=param_grid,cv=2)","0398987a":"from sklearn.model_selection import train_test_split\n\nX_train_sample,X_test,y_train_sample,y_test=train_test_split(x_train,y_train,test_size=0.50,random_state=42)\nnp.shape(X_train_sample),np.shape(y_train_sample),np.shape(X_test),np.shape(y_test)","334677a3":"# grid_result = grid.fit(X_train_sample, y_train_sample)","a71ee022":"# # summarize results\n# print(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\n# means  = grid_result.cv_results_['mean_test_score']\n# stds   = grid_result.cv_results_['std_test_score']\n# params = grid_result.cv_results_['params']\n\n# for mean, stdev, param in zip(means, stds, params):\n#     print(\"%f (%f) with: %r\" % (mean, stdev, param))","76479991":"from sklearn.model_selection import RandomizedSearchCV","77733db7":"grid = RandomizedSearchCV(estimator=model,param_distributions=param_grid,cv=2,n_iter=2)","e42b13c3":"grid_result = grid.fit(X_train_sample, y_train_sample)","cb7ee0b1":"# summarize results\nprint(\"Best: %f using %s\" % (grid_result.best_score_, grid_result.best_params_))\n\nmeans  = grid_result.cv_results_['mean_test_score']\nstds   = grid_result.cv_results_['std_test_score']\nparams = grid_result.cv_results_['params']\n\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","5669a4cf":"# 2. RANDOM SEARCH","11468e34":"## 1. GRID SEARCH","e42016ae":"## <CENTER> HYPERPARAMETER TUNNING"}}