{"cell_type":{"3a0e6bdf":"code","ef33871f":"code","8bc21788":"code","5a198cfd":"code","36d0987f":"code","b2162091":"code","ffb9cef7":"code","6d95c27b":"code","12c8c6ae":"markdown"},"source":{"3a0e6bdf":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)","ef33871f":"# dictionary that contains the different players\n# key = player index, value = Player()\ndico_players = {}\n# The agent\ndef agent(obs_dict, config_dict):\n    \n\n    import numpy as np # linear algebra\n    import pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n    from kaggle_environments.envs.hungry_geese.hungry_geese import Observation, Configuration, Action, row_col, translate\n    \n    class Params:\n        verbose = False\n        \n    class Game_action():\n        # This class contains an action name (North, South, East or West)\n        # and the associated points\n        #\n        # Attributes :\n        #   action (str) : action name \n        #   points (int) : number of points for the action\n        \n        def __init__(self, action):\n            self.action = action\n            self.points = 0\n        \n        def add_points(self,value):\n            self.points += value\n            \n        def get_points(self):\n            return self.points\n        def get_action(self):\n            return self.action\n            \n    class Player():\n        # This class contains a player\n        # A player has 4 Game_actions and 1 last action\n        # \n        # Attributes :\n        #   index (int) : player index\n        #   last_action(str) : last action played\n        #   north, south, east, west (Game_action) : one action with its points\n        \n        def __init__(self, index):\n            self.index = index\n            self.last_action = None\n        \n        def set_north(self,action):\n            self.north = action\n        def set_south(self,action):\n            self.south = action\n        def set_east(self,action):\n            self.east = action\n        def set_west(self,action):\n            self.west = action\n            \n        def set_last(self,action):\n            self.last_action = action\n            \n        def get_north(self):\n            return self.north\n        def get_south(self):\n            return self.south\n        def get_east(self):\n            return self.east\n        def get_west(self):\n            return self.west\n        \n        def get_last(self):\n            return self.last_action\n        \n        def best_action(self):\n            # returns the best actions (with the most points)\n            if self.north.get_points() >= self.south.get_points() and self.north.get_points() >= self.east.get_points() and self.north.get_points() >= self.west.get_points():\n                best_action = self.north\n            elif self.south.get_points() > self.north.get_points() and self.south.get_points() >= self.east.get_points() and self.south.get_points() >= self.west.get_points():\n                best_action = self.south\n            elif self.east.get_points() > self.north.get_points() and self.east.get_points() > self.south.get_points() and self.east.get_points() >= self.west.get_points():\n                best_action = self.east\n            else:\n                best_action = self.west\n            #print(\"-----------------\")\n            #print(self.north.get_points())\n            #print(self.south.get_points())\n            #print(self.east.get_points())\n            #print(self.west.get_points())\n            return best_action.get_action()\n        \n    def distance(row1,col1,row2,col2,n_row,n_col):\n        # gives the Manhattan distance  \n        # from (row1, col1) to (row2, col2)\n        delta_row = min(abs(row2-row1),n_row-abs(row2-row1))\n        delta_col = min(abs(col2-col1),n_col-abs(col2-col1))\n        return delta_row + delta_col\n    \n    def best_dir(row1,col1,row2,col2,n_row,n_col,index):\n        # Adds points if an actions sends you \n        # from (row1, col1) to (row2, col2)\n        delta_row = row2-row1\n        delta_col = col2-col1\n        dist = distance(row1,col1,row2,col2,n_row,n_col)\n        max_dist = (n_row+n_col)\/\/2\n        # gives more points to actions that leads to closer food\n        points = 20*(max_dist-dist+1)\/\/max_dist\n        actions = []\n        if delta_row > 0:\n            if delta_row <= n_row\/\/2:\n                dico_players[index].get_south().add_points(points)\n            else:\n                dico_players[index].get_north().add_points(points)\n        elif delta_row < 0:\n            if abs(delta_row) <= n_row\/\/2:\n                dico_players[index].get_north().add_points(points)\n            else:\n                dico_players[index].get_south().add_points(points)\n        if delta_col > 0:\n            if delta_col <= n_col\/\/2:\n                dico_players[index].get_east().add_points(points)\n            else:\n                dico_players[index].get_west().add_points(points)\n        elif delta_col< 0:\n            if abs(delta_col) <= n_col\/\/2:\n                dico_players[index].get_west().add_points(points)\n            else:\n                dico_players[index].get_east().add_points(points)\n    \n    def no_turn_back(index):\n        # Penalize moves where the goose goes 180\u00b0 backwards\n        if dico_players[index].get_last() == Action.SOUTH.name:\n            dico_players[index].get_north().add_points(-100)\n        elif dico_players[index].get_last() == Action.NORTH.name:\n            dico_players[index].get_south().add_points(-100)\n        elif dico_players[index].get_last() == Action.WEST.name:\n            dico_players[index].get_east().add_points(-100)\n        else:\n            dico_players[index].get_west().add_points(-100)\n\n    def no_collision(observation,player_index,player_head,n_col,n_row):\n        # Penalize moves where the goose hits another goose or itself\n        \n        # list of places with the other geese\n        list_other = []\n        for ind, goose in enumerate(observation.geese):\n            #if ind != player_index:\n            for place in goose:\n                list_other.append(place)\n\n        if translate(player_head,Action.NORTH,n_col,n_row) in list_other:\n            dico_players[player_index].get_north().add_points(-100)\n        if translate(player_head,Action.SOUTH,n_col,n_row) in list_other:\n            dico_players[player_index].get_south().add_points(-100)\n        if translate(player_head,Action.EAST,n_col,n_row) in list_other:\n            dico_players[player_index].get_east().add_points(-100)\n        if translate(player_head,Action.WEST,n_col,n_row) in list_other:\n            dico_players[player_index].get_west().add_points(-100)\n            \n    # Observations and setup\n    observation = Observation(obs_dict)\n    #print(observation)\n    configuration = Configuration(config_dict)\n    #print(configuration)\n    n_col = configuration.columns\n    n_row = configuration.rows\n    player_index = observation.index\n    player_goose = observation.geese[player_index]\n    player_head = player_goose[0]\n    player_row, player_column = row_col(player_head, configuration.columns)\n    \n    # Initialization of dico_players\n    if observation.step == 0:\n        dico_players[observation.index] = Player(player_index)\n    # At each step, create new Game_action for the player (with points = 0)\n    dico_players[player_index].set_north(Game_action(Action.NORTH.name))\n    dico_players[player_index].set_south(Game_action(Action.SOUTH.name))\n    dico_players[player_index].set_east(Game_action(Action.EAST.name))\n    dico_players[player_index].set_west(Game_action(Action.WEST.name))\n    \n    # reward good actions and penalize bad actions\n    for food in observation.food:\n        food_row, food_column = row_col(food, configuration.columns)\n        best_dir(player_row,player_column,food_row,food_column,n_row,n_col,player_index)\n    no_turn_back(player_index)\n    no_collision(observation,player_index,player_head,n_col,n_row)\n    \n    # select the best action\n    action = dico_players[player_index].best_action()\n    \n    # update the last action\n    dico_players[observation.index].set_last(action)\n    \n    if Params.verbose == True:\n        print(action)\n    \n    return action","8bc21788":"# Evaluate agent\n\nfrom kaggle_environments import make, evaluate\n\n# Create the game environment\n# Set debug=True to see the errors if your agent refuses to run\nenv = make(\"hungry_geese\", debug=True)\n\n# Two random agents play one game round\na = env.run([agent,agent,agent,agent])\n\n\n# Show the game\nenv.render(mode=\"ipython\", width=750, height=600)\n\n","5a198cfd":"from kaggle_environments import  evaluate\ndef get_win_percentages(agent1, agent2, n_rounds=20):\n    # Use default Connect Four setup\n    #config = {'rows': 6, 'columns': 7, 'inarow': 4}\n    # Agent 1 goes first (roughly) half the time          \n    outcomes = evaluate(\"hungry_geese\", [agent1, agent2], num_episodes=n_rounds\/\/2)\n    # Agent 2 goes first (roughly) half the time      \n    outcomes += [[b,a] for [a,b] in evaluate(\"hungry_geese\", [agent2, agent1], num_episodes= n_rounds-n_rounds\/\/2)]\n    p1_wins = [True for [a,b] in outcomes if a>b]\n    p2_wins = [True for [a,b] in outcomes if b>a]\n    print(\"Agent 1 Win Percentage:\", np.round(len(p1_wins)\/len(outcomes), 2))\n    print(\"Agent 2 Win Percentage:\", np.round(len(p2_wins)\/len(outcomes), 2))\n    print(\"Number of Invalid Plays by Agent 1:\", outcomes.count([None, 0]))\n    print(\"Number of Invalid Plays by Agent 2:\", outcomes.count([0, None]))\n    print(outcomes)","36d0987f":"# Win percentage\nget_win_percentages(agent1=agent, agent2=\"greedy\")","b2162091":"#help(env)\n#env.observation\nenv.steps","ffb9cef7":"#print(env.name)\n#help(env)\n#help(Observation)\n#help(Configuration)\n#help(Action)\n#help(row_col)","6d95c27b":"# Write agent to file\n\nimport inspect\nimport os\n\ndef write_agent_to_file(function, file):\n    with open(file, \"w\") as f:\n        f.write(\"dico_players = {}\\n\")\n        f.write(inspect.getsource(function))\n        print(function, \"written to\", file)\n\nwrite_agent_to_file(agent, \"submission.py\")","12c8c6ae":"This code describes a simple strategy for the goose\n\nEach action (North, South, East and West) is given a certain amount of points\n\n1) An action that gets you closer to food brings points\n     The closest the food, the more points, with a maximum of 20\n\n2) An action that makes you do a 180\u00b0 flip brings you -100 points\n\n3) An action that makes you collide with another goose brings you -100 points\n\nThe best action is chosen\n\nIt does not use AI, Q learning or other stuffs\n\nPlease upvote if you like it :-)"}}