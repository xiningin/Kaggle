{"cell_type":{"2538780b":"code","15928a7b":"code","970e6f89":"code","eeaedb37":"code","95a3d40c":"code","d3a15190":"code","ed029c24":"code","ed417d41":"code","161cede7":"code","e5ba649c":"code","addfcd83":"markdown","1e271ed8":"markdown","ccc5740f":"markdown","3a6e4254":"markdown","a12cf553":"markdown","a5792e0a":"markdown","32afbe5a":"markdown","006417fb":"markdown","c77e57ef":"markdown","7911b5ec":"markdown","f9f3c092":"markdown","d3177bf6":"markdown","4f072c08":"markdown","19471bff":"markdown","98b58c8b":"markdown","bcd09769":"markdown","3e22a16b":"markdown","fe9bb771":"markdown","71d66380":"markdown"},"source":{"2538780b":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.simplefilter(action='ignore', category=FutureWarning)\n\nfrom pandas.core.common import SettingWithCopyWarning\nwarnings.simplefilter(action=\"ignore\", category=SettingWithCopyWarning)\n\nfrom tqdm import tqdm","15928a7b":"df = pd.read_csv('..\/input\/boston\/listings.csv')","970e6f89":"price_b = []\nfor i in df['price']:\n  price_b.append(float(i[1:].replace(',','')))\ndf['price'] = price_b","eeaedb37":"price_corr = df.corr()['price'].sort_values(ascending = False).head(6)[1:]\nprice_corr","95a3d40c":"price_corr.plot(kind = 'bar', color = 'y');\nplt.xticks(rotation=45);","d3a15190":"a = list(df['street'].values)\nfor i in range(len(a)):\n  df['street'][i] = a[i].split(',')[0]","ed029c24":"a = df.groupby(df['street'])['price'].mean().sort_values(ascending = False).head(5)\na.plot(kind = 'bar', color = 'violet');\nplt.xticks(rotation=45);","ed417d41":"df_re = pd.read_csv('..\/input\/boston\/reviews.csv')\ndf_re\n\n# --------------------- Positive words counting -------------------# \nls_good = []\nfeature_good = ['good', 'clean', 'nice', 'great', 'Great', 'Nice', 'comfortable', 'Good', 'cool', 'Cool', 'Clean', 'enjoyed', 'bien', 'ajustado', 'cozy', 'Cozy']\nfor c in range(68275):\n  n = 0\n  try:\n    for i in df_re['comments'][c].split():\n      if i in feature_good:\n        n += 1\n      else:\n        pass\n  except:\n    n = 0\n  ls_good.append(n)\n\n# --------------------- Negative words counting -------------------# \n\n  ls_bad = []\nfeature_bad = ['bad', 'dirty', 'uncomfortable', 'terrible', 'Bad', 'Dirty', 'Uncomfortable', 'sucio', 'malo', 'inc\u00f3modo']\nfor c in range(68275):\n  n = 0\n  try:\n    for i in df_re['comments'][c].split():\n      if i in feature_bad:\n        n += 1\n      else:\n        pass\n  except:\n    n = 0\n  ls_bad.append(n)\n\n# --------------------- Merging -------------------# \n\ndf_re['counts_good'] = ls_good\ndf_re['counts_bad'] = ls_bad\ndf_re = df_re[['listing_id', 'counts_good', 'counts_bad']]\ndf_re.columns = ['id', 'counts_good', 'counts_bad']\ndf = pd.merge(df, df_re, on = 'id', how = 'left')\n\n# --------------------- Filling Missing Values -------------------# \n\ndf['counts_good'] = df['counts_good'].fillna(-1)\ndf['counts_bad'] = df['counts_bad'].fillna(-1)","161cede7":"review_cols = ['review_scores_accuracy', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_communication', 'review_scores_location', 'review_scores_rating', 'review_scores_value']\n\nfig, ax = plt.subplots(len(review_cols), 2, figsize=(12,24))\n\nfor i in tqdm(range(len(review_cols))):\n  sns.barplot(df['counts_good'], df[review_cols[i]], ax = ax[i, 0])\n  sns.barplot(df['counts_bad'], df[review_cols[i]], ax = ax[i, 1])\n\nplt.tight_layout()\nplt.show()","e5ba649c":"review_cols = ['review_scores_accuracy', 'review_scores_checkin', 'review_scores_cleanliness', 'review_scores_communication', 'review_scores_location', 'review_scores_rating', 'review_scores_value']\n\nfig, ax = plt.subplots(len(review_cols), 2, figsize=(12,24))\n\nfor i in tqdm(range(len(review_cols))):\n  sns.barplot(df['counts_good'], df['price'], ax = ax[i, 0])\n  sns.barplot(df['counts_bad'], df['price'], ax = ax[i, 1])\n\nplt.tight_layout()\nplt.show()","addfcd83":"#### **Result**\n\nBy google map, these streets are near by ocean!\n\nActually, I'm not living in boston(I'm korean). But I can guess that those streets are rich.","1e271ed8":"### **Q1) Which columns are influential?**","ccc5740f":"## **Import Library**","3a6e4254":"### **Q2) Which street is most expensive?**","a12cf553":"## **Feature Engineering**","a5792e0a":"## **Price preprocessing**\n\n*   **Object to Float**","32afbe5a":"- From street column, Extracting Street Name","006417fb":"#### **Preprocessing Street Column**","c77e57ef":"#### **Visualization**","7911b5ec":"- Top 5 Rich Street By Our Data","f9f3c092":"#### **Preprocessing**\n\n*  **Counting Postive & Negative words in Review Data**\n*  **Merging DataFrame**\n*  **Filling Missing Values (-1)**","d3177bf6":"##### **Review values - Word counts**","4f072c08":"### **Q3) Relationship between Review of AIRBNB Data & Host info**\n\nI wondered about relationship between review data and host-info!\n\nAt first, I counted positive & negative words in review data.\n\nAnd merged this data with DataFrame 'df'","19471bff":"##### **Price - Word counts**","98b58c8b":"#### **Visualization**","bcd09769":"#### **Result**\n\nWe can see that both distributions of Review values which are seperated by P&N words counts are different!\n\n*   We can conclude that this data is reliable!\n\nIf you wanna get more customer, you should analyze of review data and make your own strategy.\n\nThere are many bad places that cost more expensive than good places.\nI conclude that those who own airbnb which had bad review should change their place cost!\n","3e22a16b":"#### **Corr of Price Column**","fe9bb771":"## **Data Load**","71d66380":"#### **Result**\n\nIt seems that **area variable** is most important. (We can easily guess)\n\nMaybe Accommodates, Bedrooms, Beds... columns are related to **area & price!**"}}