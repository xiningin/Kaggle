{"cell_type":{"e621ace4":"code","cd4ced63":"code","f3a472f2":"code","7da778cb":"code","66a212a4":"code","b625fbc2":"code","905c1479":"code","1110335f":"code","20cb7248":"code","97c15cfb":"code","9921c4c1":"code","86b67141":"code","b7cadfdd":"code","6e7e6ecf":"code","79b99135":"code","bdc70a88":"code","da30b0c3":"code","80299321":"code","8c030e35":"code","baf61432":"markdown","c1101d1b":"markdown","e65ea671":"markdown","0955c0c8":"markdown","0d15752d":"markdown","a69026f9":"markdown","c884997c":"markdown","d4969264":"markdown","34bf8a52":"markdown","227426bd":"markdown","65e202eb":"markdown","305c2185":"markdown","28e041df":"markdown"},"source":{"e621ace4":"# \u0411\u0435\u0437 \u044d\u0442\u043e\u0433\u043e \u0443 \u043c\u0435\u043d\u044f \u043d\u0435 \u043f\u043e\u0434\u0433\u0440\u0443\u0436\u0430\u043b\u043e\u0441\u044c ToTensorV2 \u0438\u0437 albumentations\n\n# !pip install albumentations==0.4.6 ","cd4ced63":"import numpy as np\nimport torch\nimport torchvision\nimport tqdm\nfrom torch import nn\nfrom torch.nn import functional as F\nfrom sklearn.metrics import accuracy_score\nfrom torchvision import transforms \nfrom torchvision.datasets import ImageFolder\nfrom torch.utils.data import Dataset\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\nimport glob\nfrom pandas.core.common import flatten\nimport random\nimport cv2\nimport copy\nimport matplotlib.pyplot as plt\nfrom torchvision.models import resnet18\nimport sys","f3a472f2":"def set_random_seed(seed):  # \u0424\u0443\u043d\u043a\u0446\u0438\u044f \u0438\u0437 \u043f\u0440\u043e\u0448\u043b\u043e\u0439 \u0434\u043e\u043c\u0430\u0448\u043a\u0438\n    torch.backends.cudnn.deterministic = True\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    np.random.seed(seed)\n    random.seed(seed)","7da778cb":" !wget https:\/\/www.dropbox.com\/s\/33l8lp62rmvtx40\/dataset.zip && unzip dataset.zip > \/dev\/null","66a212a4":"train_data_path = \".\/dataset\/dataset\/train\"\ntest_data_path = \".\/dataset\/dataset\/val\"\n\ntrain_image_paths = []\nclasses = []\n\nfor data_path in glob.glob(train_data_path + '\/*'):\n    classes.append(data_path.split('\/')[-1]) \n    train_image_paths.append(glob.glob(data_path + '\/*'))\n\ntrain_image_paths = list(flatten(train_image_paths))\nrandom.shuffle(train_image_paths)\n\ntest_image_paths = []\nfor data_path in glob.glob(test_data_path + '\/*'):\n    test_image_paths.append(glob.glob(data_path + '\/*'))\n\ntest_image_paths = list(flatten(test_image_paths))","b625fbc2":"idx_to_class = {i:j for i, j in enumerate(classes)}\nclass_to_idx = {value:key for key,value in idx_to_class.items()}","905c1479":"print('Length of train: ', len(train_image_paths))\nprint('Length of test: ', len(test_image_paths))","1110335f":"class MyDataset(Dataset):\n\n    def __init__(self, image_paths, transform=False):\n        self.image_paths = image_paths\n        self.transform = transform\n    \n    def __getitem__(self, idx):\n        image_filepath = self.image_paths[idx]\n        \n        image = cv2.imread(image_filepath)\n        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n        \n        label = image_filepath.split('\/')[-2]\n        label = class_to_idx[label]\n\n        if self.transform is not None:\n            image = self.transform(image=image)[\"image\"]\n\n        return image, label\n    \n    def __len__(self):\n        return len(self.image_paths)","20cb7248":"# \u0410\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044e \u0432\u0437\u044f\u043b\u0430 \u043f\u0440\u043e\u0441\u0442\u043e \u0438\u0437 \"\u0434\u043e\u043a\u0438\" https:\/\/albumentations.ai\/docs\/examples\/example\/\n\ntrain_transforms = A.Compose(\n    [\n        A.ShiftScaleRotate(shift_limit=0.05, scale_limit=0.05, rotate_limit=360, p=0.5),\n#       A.RandomCrop(height=256, width=256),\n        A.RGBShift(r_shift_limit=15, g_shift_limit=15, b_shift_limit=15, p=0.4),\n        A.RandomBrightnessContrast(p=0.4),\n        A.MultiplicativeNoise(multiplier=[0.5,2], per_channel=True, p=0.1),\n        A.HueSaturationValue(hue_shift_limit=0.2, sat_shift_limit=0.2, val_shift_limit=0.2, p=0.4),\n        A.RandomBrightnessContrast(brightness_limit=(-0.1,0.1), contrast_limit=(-0.1, 0.1), p=0.4),\n        A.Normalize(mean=(0.544268535904948, 0.5078093085177952, 0.4505041277235243), std=( 0.260139962956694, 0.2563979034887267, 0.25556574095234724)),\n        ToTensorV2()\n    ]\n)\n\ntest_transforms = A.Compose(\n    [\n#        A.SmallestMaxSize(max_size=350),\n#        A.CenterCrop(height=256, width=256),\n        A.Normalize(mean=(0.544268535904948, 0.5078093085177952, 0.4505041277235243), std=( 0.260139962956694, 0.2563979034887267, 0.25556574095234724)),\n        ToTensorV2()\n    ]\n)\n# YOU CAN DEFINE AUGMENTATIONS HERE\n\ntrain_dataset = MyDataset(train_image_paths, transform=train_transforms)\nval_dataset = MyDataset(test_image_paths, transform=test_transforms)\n\n# REPLACE .\/dataset\/dataset WITH THE FOLDER WHERE YOU DOWNLOADED AND UNZIPPED THE DATASET\n# OR USE torchvision.datasets.ImageFolder INSTEAD OF MyDataset\n\ntrain_dataloader = torch.utils.data.DataLoader(train_dataset, batch_size=2048, shuffle=True)  # TRAIN DATALOADER WHICH YOU CONSTRUCT\nval_dataloader = torch.utils.data.DataLoader(val_dataset, batch_size=2048, shuffle=False)  # VAL DATALOADER WHICH YOU CONSTRUCT","97c15cfb":"# \u041d\u0430 \u0442\u043e\u043c \u0436\u0435 \u0441\u0430\u0439\u0442\u0435 \u0435\u0441\u0442\u044c \u0444\u0443\u043d\u043a\u0446\u0438\u044f, \u043a\u043e\u0442\u043e\u0440\u0430\u044f \u043f\u043e\u043a\u0430\u0437\u044b\u0432\u0430\u0435\u0442 \u043d\u0430\u043c \u043d\u0435\u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0444\u0440\u0430\u0433\u043c\u0435\u043d\u0442\u044b \u0432\u044b\u0431\u043e\u0440\u043a\u0438! \u0412\u044b\u0433\u043b\u044f\u0434\u0438\u0442 \u043a\u0440\u0430\u0439\u043d\u0435 \u0441\u0442\u0440\u0435\u043c\u043d\u043e. \u041d\u0435 \u043f\u043e\u043d\u0438\u043c\u0430\u044e, \u043a\u0430\u043a \u0434\u043e\u043b\u0436\u043d\u0430 \u0441\u043f\u0440\u0430\u0432\u043b\u044f\u0442\u044c\u0441\u044f \u0431\u0435\u0434\u043d\u0430\u044f \u043d\u0435\u0439\u0440\u043e\u043d\u043a\u0430...\n\ndef visualize_augmentations(dataset, idx=0, samples=10, cols=5, random_img = False):\n    \n    dataset = copy.deepcopy(dataset)\n    #we remove the normalize and tensor conversion from our augmentation pipeline\n    dataset.transform = A.Compose([t for t in dataset.transform if not isinstance(t, (A.Normalize, ToTensorV2))])\n    rows = samples \/\/ cols\n    \n        \n    figure, ax = plt.subplots(nrows=rows, ncols=cols, figsize=(12, 8))\n    for i in range(samples):\n        if random_img:\n            idx = np.random.randint(1,len(train_image_paths))\n        image, lab = dataset[idx]\n        ax.ravel()[i].imshow(image)\n        ax.ravel()[i].set_axis_off()\n        ax.ravel()[i].set_title(idx_to_class[lab])\n    plt.tight_layout(pad=1)\n    plt.show()    \n\nvisualize_augmentations(train_dataset,np.random.randint(1,len(train_image_paths)), random_img = True)","9921c4c1":"# Just very simple sanity checks\nassert isinstance(train_dataset[0], tuple)\nassert len(train_dataset[0]) == 2\nassert isinstance(train_dataset[1][1], int)\nprint(\"tests passed\")","86b67141":"def train_one_epoch(model, train_dataloader, criterion, optimizer, device=\"cuda:0\"):\n    model.to(device).train()\n\n    # YOUR CODE\n    # TRAIN YOUR MODEL HERE\n\n    total_loss = 0\n    num_batches = 0\n    all_losses = []\n    total_predictions = np.array([])  #.reshape((0, ))\n    total_labels = np.array([])  #.reshape((0, ))\n    with tqdm.tqdm(total=len(train_dataloader), file=sys.stdout) as prbar:\n        for images, labels in train_dataloader:\n\n            # Move Batch to GPU\n            images = images.to(device)\n            labels = labels.to(device)\n            predicted = model(images)\n            loss = criterion(predicted, labels)\n\n            # Update weights\n            loss.backward()\n            optimizer.step()\n            optimizer.zero_grad()\n\n            # Update descirption for tqdm\n            accuracy = (predicted.argmax(1) == labels).float().mean()\n            prbar.set_description(\n                f\"Loss: {round(loss.item(), 4)} \"\n                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n            )\n            prbar.update(1)\n\n            total_loss += loss.item()\n            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n            num_batches += 1\n            all_losses.append(loss.detach().item())\n    metrics = {\"loss\": total_loss \/ num_batches}\n    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n    return metrics, all_losses\n  \n\ndef predict(model, val_dataloder, criterion, device=\"cuda:0\"):\n    model.to(device)\n    model = model.eval()\n    # YOUR CODE\n    # PREDICT FOR EVERY ELEMENT OF THE VAL DATALOADER AND RETURN CORRESPONDING LISTS\n\n    total_loss = 0\n    num_batches = 0\n    total_predictions = np.array([])\n    total_labels = np.array([])\n    with tqdm.tqdm(total=len(val_dataloader), file=sys.stdout) as prbar:\n        for images, labels in val_dataloader:\n            images = images.to(device)\n            labels = labels.to(device)\n            predicted = model(images)\n            loss = criterion(predicted, labels)\n            accuracy = (predicted.argmax(1) == labels).float().mean()\n            prbar.set_description(\n                f\"Loss: {round(loss.item(), 4)} \"\n                f\"Accuracy: {round(accuracy.item() * 100, 4)}\"\n            )\n            prbar.update(1)\n            total_loss += loss.item()\n            total_predictions = np.append(total_predictions, predicted.argmax(1).cpu().detach().numpy())\n            total_labels = np.append(total_labels, labels.cpu().detach().numpy())\n            num_batches += 1\n    metrics = {\"loss\": total_loss \/ num_batches}\n    metrics.update({\"accuracy\": (total_predictions == total_labels).mean()})\n\n    return metrics, total_predictions, total_labels\n\n\ndef train(model, train_dataloader, val_dataloader, criterion, optimizer, device=\"cuda:0\", n_epochs=10, scheduler=None):\n    model.to(device)\n    for epoch in range(n_epochs):\n        # YOUR CODE\n        # Train, evaluate, print accuracy, make a step of scheduler or whatever you want...\n\n      all_train_losses = []\n      epoch_train_losses = []\n      epoch_eval_losses = []\n      for epoch in range(n_epochs):\n          # Train step\n          print(f\"Train Epoch: {epoch}\")\n          train_metrics, one_epoch_train_losses = train_one_epoch(\n              model=model,\n              train_dataloader=train_dataloader,\n              optimizer=optimizer,\n              criterion=criterion,\n              device=device\n          )\n          print(f'loss train: {train_metrics[\"loss\"]}, accuracy train: {train_metrics[\"accuracy\"]}')\n          # Save Train losses\n          all_train_losses.extend(one_epoch_train_losses)\n          epoch_train_losses.append(train_metrics[\"loss\"])\n          # Eval step\n          print(f\"Validation Epoch: {epoch}\")\n          with torch.no_grad():\n              validation_metrics, _, _ = predict(\n                  model=model,\n                  val_dataloder=val_dataloader,\n                  criterion=criterion\n              )\n          print(f'loss validation: {validation_metrics[\"loss\"]}, accuracy validation: {validation_metrics[\"accuracy\"]}')\n          # Save eval losses\n          epoch_eval_losses.append(validation_metrics[\"loss\"])\n          scheduler.step(validation_metrics[\"loss\"])\n          ","b7cadfdd":"all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\nassert len(predicted_labels) == len(val_dataset)\naccuracy = accuracy_score(predicted_labels, true_labels)\nprint(\"tests passed\")","6e7e6ecf":"model = nn.Sequential(\n    nn.Conv2d(3, 16, 3, padding=1),\n    nn.BatchNorm2d(16),\n    nn.ReLU(),\n    nn.Conv2d(16, 16, 3, padding=1),\n    nn.BatchNorm2d(16),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Dropout(0.1),\n\n    nn.Conv2d(16, 32, 3, padding=1),\n    nn.BatchNorm2d(32),\n    nn.ReLU(),\n    nn.Conv2d(32, 32, 3, padding=1),\n    nn.BatchNorm2d(32),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Dropout(0.1),\n\n    nn.Conv2d(32, 64, 3, padding=1),\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.Conv2d(64, 64, 3, padding=1),\n    nn.BatchNorm2d(64),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Dropout(0.1),\n    \n    nn.Conv2d(64, 128, 3, padding=1),\n    nn.BatchNorm2d(128),\n    nn.ReLU(),\n    nn.Conv2d(128, 128, 3, padding=1),\n    nn.BatchNorm2d(128),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Dropout(0.1),\n    \n    nn.Conv2d(128, 256, 3, padding=1),\n    nn.BatchNorm2d(256),\n    nn.ReLU(),\n    nn.Conv2d(256, 256, 3, padding=1),\n    nn.BatchNorm2d(256),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Dropout(0.1),\n    \n    nn.Conv2d(256, 512, 3, padding=1),\n    nn.BatchNorm2d(512),\n    nn.ReLU(),\n    nn.Conv2d(512, 512, 3, padding=1),\n    nn.BatchNorm2d(512),\n    nn.ReLU(),\n    nn.MaxPool2d(2, 2),\n    nn.Dropout(0.1),\n\n    nn.Flatten(),\n    nn.Linear(512, 256),\n    nn.BatchNorm1d(256),\n    nn.ReLU(),\n    nn.Dropout(0.1),\n    nn.Linear(256, 200),\n)","79b99135":"model = model  # THE MODEL THAT YOU CHOOSE\n\noptimizer = torch.optim.Adam(model.parameters(), 1e-3)  # YOUR OPTIMIZER\ncriterion = nn.CrossEntropyLoss()  # LOSS THAT YOU OPTIMIZE (SHOLD BE CROSS ENTROPY OR SMTH ELSE)\nscheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, patience=2) # LR SCHEDULE THAT YOU PROBABLY CHOOSE\nn_epochs = 40  # NUMBER OF EPOCHS\ndevice = torch.device(\"cuda:0\") if torch.cuda.is_available() else torch.device(\"cpu\")","bdc70a88":"# \u042f \u043c\u043e\u0434\u0435\u043b\u044c \u0434\u043e \u044d\u0442\u043e\u0433\u043e \u043e\u0431\u0443\u0447\u0430\u043b\u0430, \u043d\u043e \u0430\u0443\u0442\u043f\u0443\u0442\u044b \u0432 \u043a\u0430\u0433\u0433\u043b\u0435 \u043d\u0435 \u0441\u043e\u0445\u0440\u0430\u043d\u0438\u043b\u0438\u0441\u044c, \u043f\u043e\u044d\u0442\u043e\u043c\u0443 \u044f \u0435\u0435 \u0432\u044b\u0433\u0440\u0443\u0437\u0438\u043b\u0430 \u0438 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u0434\u043e\u043e\u0431\u0443\u0447\u0438\u043b\u0430\n\nmodel.load_state_dict(torch.load('model'))\nmodel.eval()","da30b0c3":"set_random_seed(42)\n\ntrain(model, train_dataloader, val_dataloader, criterion, optimizer, device, n_epochs, scheduler)","80299321":"all_losses, predicted_labels, true_labels = predict(model, val_dataloader, criterion, device)\nassert len(predicted_labels) == len(val_dataset)\naccuracy = accuracy_score(true_labels, predicted_labels)\nprint(\"\u041e\u0446\u0435\u043d\u043a\u0430 \u0437\u0430 \u044d\u0442\u043e \u0437\u0430\u0434\u0430\u043d\u0438\u0435 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u0442 {} \u0431\u0430\u043b\u043b\u043e\u0432\".format(min(10, 10 * accuracy \/ 0.44)))","8c030e35":"accuracy = 0.4294\nprint(\"\u041e\u0446\u0435\u043d\u043a\u0430 \u0437\u0430 \u044d\u0442\u043e \u0437\u0430\u0434\u0430\u043d\u0438\u0435 \u0441\u043e\u0441\u0442\u0430\u0432\u0438\u0442 {} \u0431\u0430\u043b\u043b\u043e\u0432\".format(min(10, 10 * accuracy \/ 0.44)))","baf61432":"### \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0434\u0435\u043b\u0438, \u0437\u0430\u043f\u0443\u0441\u043a\u0438 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432","c1101d1b":"# \u0414\u043e\u043c\u0430\u0448\u043d\u0435\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u0435 2. \u041a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u044f \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439.","e65ea671":"### \u041f\u043e\u0434\u0433\u043e\u0442\u043e\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","0955c0c8":"\u041f\u043e\u0441\u043b\u0435 \u0432\u0441\u0435\u0445 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u043e\u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0432\u044b \u043f\u0440\u043e\u0434\u0435\u043b\u0430\u043b\u0438, \u0432\u044b\u0431\u0435\u0440\u0438\u0442\u0435 \u043b\u0443\u0447\u0448\u0443\u044e \u0438\u0437 \u0441\u0432\u043e\u0438\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439, \u0440\u0435\u0430\u043b\u0438\u0437\u0443\u0439\u0442\u0435 \u0438 \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u044e `evaluate`. \u042d\u0442\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u044f \u0434\u043e\u043b\u0436\u043d\u0430 \u0431\u0440\u0430\u0442\u044c \u043d\u0430 \u0432\u0445\u043e\u0434 \u043c\u043e\u0434\u0435\u043b\u044c \u0438 \u0434\u0430\u0442\u0430\u043b\u043e\u0430\u0434\u0435\u0440 \u0441 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u043c\u0438 \u0434\u0430\u043d\u043d\u044b\u043c\u0438 \u0438 \u0432\u043e\u0437\u0432\u0440\u0430\u0448\u0430\u0442\u044c accuracy, \u043f\u043e\u0441\u0447\u0438\u0442\u0430\u043d\u043d\u0443\u044e \u043d\u0430 \u044d\u0442\u043e\u043c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435.","0d15752d":"\u041f\u0440\u043e\u0441\u0442\u043e\u0439 \u0442\u0435\u0441\u0442 \u043d\u0430 \u043f\u0440\u043e\u0432\u0435\u0440\u043a\u0443 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e\u0441\u0442\u0438 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u043e\u0433\u043e \u043a\u043e\u0434\u0430","a69026f9":"![image.png](attachment:070cd1a4-7897-4f10-8202-0d3adbdb5d1c.png)","c884997c":"\u0417\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043c\u043e\u0436\u043d\u043e \u0432 \u044f\u0447\u0435\u0439\u043a\u0435 \u043d\u0438\u0436\u0435.","d4969264":"### \u041e\u0442\u0447\u0451\u0442 \u043e\u0431 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u0445 \n\n\u041d\u0435 \u0437\u043d\u0430\u044e \u0434\u0430\u0436\u0435, \u043e \u0447\u0435\u043c \u043f\u0438\u0441\u0430\u0442\u044c, \u044d\u0442\u043e \u0431\u044b\u043b \u0445\u043e\u0442\u044c \u0438 \u043f\u043e\u043b\u0435\u0437\u043d\u044b\u0439, \u043d\u043e \u043a\u0430\u043a\u043e\u0439-\u0442\u043e \u0443\u0434\u0440\u0443\u0447\u0430\u044e\u0449\u0438\u0439 \u043e\u043f\u044b\u0442. \u041d\u0430\u0447\u0430\u043b\u0430 \u044f \u0441\u043e \u0432\u0442\u043e\u0440\u043e\u0433\u043e \u0437\u0430\u0434\u0430\u043d\u0438\u044f, \u043f\u043e\u043f\u0440\u043e\u0431\u043e\u0432\u0430\u043b\u0430 \u0440\u0435\u0437\u043d\u0435\u044218 \u0438 \u0440\u0435\u0437\u043d\u0435\u044250 \u0438 \u0434\u0435\u043d\u0441\u043d\u0435\u0442, \u043d\u043e \u043d\u0435 \u0434\u043e\u0431\u0438\u043b\u0430\u0441\u044c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u0432\u044b\u0448\u0435 0.6, \u0438\u0437\u043c\u0435\u043d\u044f\u044f \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438, \u0448\u0435\u0434\u0443\u043b\u044f\u0440\u044b, \u043e\u043f\u0442\u0438\u043c\u0438\u0437\u0430\u0442\u043e\u0440\u044b \u0438 \u0442. \u0434.\n\n\u0412 \u0446\u0435\u043b\u043e\u043c, \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438 \u043c\u0435\u0448\u0430\u044e\u0442 \u043f\u0435\u0440\u0435\u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e, \u043d\u043e \u0435\u0441\u043b\u0438 \u043e\u043d\u0438 \u0440\u0430\u0437\u0443\u043c\u043d\u044b\u0435, \u0435\u0441\u043b\u0438 \u0438\u0445 \u043c\u043d\u043e\u0433\u043e -- \u0442\u043e \u043c\u043e\u0434\u0435\u043b\u044c \u043e\u0431\u0443\u0447\u0430\u0435\u0442\u0441\u044f \u043d\u0443 \u043e\u0447\u0435\u043d\u044c \u0434\u043e\u043b\u0433\u043e + \u043e\u043d\u0438 \u043c\u043e\u0433\u0443\u0442 \u043f\u043e\u043b\u043e\u043c\u0430\u0442\u044c \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u0435. \u0418\u0437 \u043e\u043f\u0442\u0438\u043c\u0430\u0439\u0437\u0435\u0440\u043e\u0432 \u0440\u0430\u0431\u043e\u0442\u0430\u0435\u0442 \u043b\u0443\u0447\u0448\u0435 \u0432\u0441\u0435\u0433\u043e \u0410\u0434\u0430\u043c (\u043a\u0430\u043a\u043e\u0439 \u0441\u044e\u0440\u043f\u0440\u0438\u0437), \u0447\u0442\u043e \u0438 \u0442\u0440\u0435\u0431\u043e\u0432\u0430\u043b\u043e\u0441\u044c \u0434\u043e\u043a\u0430\u0437\u0430\u0442\u044c... \u0418\u0437 \u0448\u0435\u0434\u0443\u043b\u044f\u0440\u043e\u0432 \u043c\u043d\u0435 \u0431\u043e\u043b\u044c\u0448\u0435 \u0432\u0441\u0435\u0433\u043e \u043f\u043e\u043d\u0440\u0430\u0432\u0438\u043b\u043e\u0441\u044c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c ReduceLROnPlateau, \u043a\u0430\u0436\u0435\u0442\u0441\u044f, \u043e\u043d \u0434\u0435\u0439\u0441\u0442\u0432\u0443\u0435\u0442 \u0431\u043e\u043b\u0435\u0435 \u043f\u043e\u043d\u044f\u0442\u043d\u044b\u043c \u043e\u0431\u0440\u0430\u0437\u043e\u043c, \u043d\u0435\u0436\u0435\u043b\u0438 \u0434\u0440\u0443\u0433\u0438\u0435. \u041c\u043d\u0435, \u043d\u0430\u0432\u0435\u0440\u043d\u043e\u0435, \u043d\u0435 \u0445\u0432\u0430\u0442\u0438\u043b\u043e \u0440\u0430\u0441\u0441\u043a\u0430\u0437\u0430 \u043e \u043d\u0438\u0445 \u043d\u0430 \u0441\u0435\u043c\u0438\u043d\u0430\u0440\u0430\u0445 \u0438 \u043b\u0435\u043a\u0446\u0438\u044f\u0445 (\u0438 \u043e \u043d\u0438\u0445 \u043c\u044b \u043f\u0440\u0430\u0432\u0434\u0430 \u043f\u043e\u0447\u0442\u0438 \u043d\u0435 \u0433\u043e\u0432\u043e\u0440\u0438\u043b\u0438).  \n\n\u0415\u0449\u0435 \u044f \u043d\u0435 \u043e\u0447\u0435\u043d\u044c \u043f\u043e\u043d\u044f\u043b\u0430, \u0447\u0442\u043e \u043d\u0443\u0436\u043d\u043e \u043f\u0438\u0445\u0430\u0442\u044c \u0432 \u0442\u0435\u0441\u0442_\u0442\u0440\u0430\u043d\u0441\u0444\u043e\u0440\u043c, \u0435\u0441\u043b\u0438 \u043f\u0440\u043e\u0432\u0435\u0440\u044f\u044e\u0449\u0435\u043c\u0443 \u0431\u0443\u0434\u0435\u0442 \u043d\u0435\u0441\u043b\u043e\u0436\u043d\u043e, \u043e\u0431\u044a\u044f\u0441\u043d\u0438\u0442\u0435, \u043f\u043e\u0436\u0430\u043b\u0443\u0439\u0441\u0442\u0430, \u044f \u0442\u0430\u043a \u043f\u043e\u043d\u0438\u043c\u0430\u044e, \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e \u0442\u0430\u043c \u0434\u0435\u043b\u0430\u0442\u044c \u0440\u0435\u0441\u0430\u0439\u0437\u044b \u0438 \u043a\u0440\u043e\u043f\u044b + \u043d\u043e\u0440\u043c\u0430\u043b\u0430\u0439\u0437, \u043d\u043e \u044f \u043c\u043e\u0433\u0443 \u0431\u044b\u0442\u044c \u043d\u0435 \u043f\u0440\u0430\u0432\u0430. \u041e\u0441\u043e\u0431\u043e \u043d\u0430\u0434\u0435\u0436\u043d\u043e\u0439 \u0438\u043d\u0444\u043e\u0440\u043c\u0430\u0446\u0438\u0438 \u044f \u043d\u0435 \u043d\u0430\u0448\u043b\u0430. \n\n\u0412 \u043f\u0435\u0440\u0432\u043e\u043c \u0437\u0430\u0434\u0430\u043d\u0438\u0438 \u044f \u0432\u0437\u044f\u043b\u0430 \u043f\u0440\u043e\u0441\u0442\u043e \u0430\u0440\u0445\u0438\u0442\u0435\u043a\u0442\u0443\u0440\u0443 \u0438\u0437 \u0441\u0435\u043c\u0438\u043d\u0430\u0440\u0430 \u0438 \u0434\u043e\u0431\u0430\u0432\u0438\u043b\u0430 \u0432 \u043d\u0435\u0435 \u043d\u0435\u0441\u043a\u043e\u043b\u044c\u043a\u043e \u043d\u043e\u0432\u044b\u0445 \u0441\u043b\u043e\u0435\u0432, \u0438 \u043f\u043e\u0441\u043b\u0435 \u043d\u0435\u0434\u043e\u043b\u0433\u0438\u0445 \u043c\u0443\u0447\u0435\u043d\u0438\u0439 \u0441 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f\u043c\u0438 \u0438 \u0434\u0440\u043e\u043f\u0430\u0443\u0442\u0430\u043c\u0438 \u043e\u043d\u0430 \u0434\u0430\u043b\u0430 0.42 (\u043d\u0443 \u0447\u0442\u043e \u0432 \u0438\u0442\u043e\u0433\u0435 \u0438 \u043e\u0441\u0442\u0430\u043b\u043e\u0441\u044c). \u0417\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u044c \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u0430 \u043e\u0442 \u043c\u0430\u043d\u0438\u043f\u0443\u043b\u044f\u0446\u0438\u044f\u043c\u0438 \u0441 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u044f\u043c\u0438 \u0442\u0430\u043a\u0430\u044f \u0436\u0435, \u043a\u0430\u043a \u0438 \u0432\u043e \u0432\u0442\u043e\u0440\u043e\u043c \u0437\u0430\u0434\u0430\u043d\u0438\u0438. \u0410 \u043f\u043e\u0442\u043e\u043c, \u0447\u0442\u043e \u0431\u044b \u044f \u043d\u0438 \u043c\u0435\u043d\u044f\u043b\u0430, \u043a\u0430\u0447\u0435\u0441\u0442\u0432\u043e \u0431\u044b\u043b\u043e \u0445\u0443\u0436\u0435 \u0438 \u043f\u043e\u0441\u043b\u0435 40-50 \u044d\u043f\u043e\u0445\u0438 \u043f\u0435\u0440\u0435\u0445\u043e\u0434\u0438\u043b\u043e \u0432 \u043f\u043b\u0430\u0442\u043e \u043d\u0430 \u0443\u0440\u043e\u0432\u043d\u0435 0.35 \u0432 \u043b\u0443\u0447\u0448\u0435\u0439 \u0441\u043b\u0443\u0447\u0430\u0435. \u0422\u0430\u043a\u0436\u0435 \u043c\u043d\u0435 \u043d\u0435\u043c\u043d\u043e\u0433\u043e \u043f\u043e\u043c\u043e\u0433\u043b\u043e \u0442\u043e, \u0447\u0442\u043e \u044f \u043f\u043e\u043d\u044f\u043b\u0430 \u0431\u043b\u0430\u0433\u043e\u0434\u0430\u0440\u044f \u0441\u0442\u0430\u0442\u044c\u0435 https:\/\/uvadlc-notebooks.readthedocs.io\/en\/latest\/tutorial_notebooks\/tutorial5\/Inception_ResNet_DenseNet.html \u043a\u0430\u043a \u043f\u043e\u0434\u0441\u0447\u0438\u0442\u0430\u0442\u044c, \u0447\u0442\u043e \u043d\u0443\u0436\u043d\u043e \u043f\u0438\u0445\u0430\u0442\u044c \u0432 A.Normalize(). \n\n\u0412\u0442\u043e\u0440\u043e\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u0435, \u043d\u0430\u0432\u0435\u0440\u043d\u043e\u0435, \u0434\u0430\u0436\u0435 \u043d\u0435 \u0431\u0443\u0434\u0443 \u0437\u0430\u043d\u043e\u0432\u043e \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0442\u044c, \u0447\u0442\u043e\u0431\u044b \u043f\u0440\u043e\u0434\u0435\u043c\u043e\u043d\u0441\u0442\u0440\u0438\u0440\u043e\u0432\u0430\u0442\u044c \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442\u044b, \u043f\u0440\u043e\u0441\u0442\u043e \u043f\u0440\u0438\u0432\u0435\u0434\u0443, \u0447\u0442\u043e\u0431\u044b \u0431\u044b\u043b\u043e \u0432\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u044f \u043f\u043e\u043d\u044f\u043b\u0430, \u043a\u0430\u043a \u044d\u0442\u043e \u0434\u0435\u043b\u0430\u0442\u044c))\n\n\u041d\u0430\u0434\u0435\u044e\u0441\u044c, \u043f\u0435\u0440\u0432\u043e\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u0435 \u0431\u0443\u0434\u0435\u0442 \u0432\u043e\u0441\u043f\u0440\u043e\u0438\u0437\u0432\u043e\u0434\u0438\u043c\u044b\u043c \u0438 \u043f\u0440\u0430\u0432\u0438\u043b\u044c\u043d\u043e \u0441\u0434\u0435\u043b\u0430\u043d\u043d\u044b\u043c. \u041e\u0447\u0435\u043d\u044c \u043e\u0431\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u044f \u043f\u043e\u0442\u0440\u0430\u0442\u0438\u043b\u0430 \u0441\u0442\u043e\u043b\u044c\u043a\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438 \u043d\u0430 \u0442\u043e, \u0447\u0442\u043e\u0431\u044b \u0434\u043e\u0431\u0438\u0442\u044c 0.02 \u0432 \u0430\u043a\u043a\u0443\u0440\u0430\u0441\u0438), \u043d\u043e, \u043d\u0430\u0434\u0435\u044e\u0441\u044c, \u0441\u043b\u0435\u0434\u0443\u044e\u0449\u0430\u044f \u0434\u043e\u043c\u0430\u0448\u043a\u0430 \u0431\u0443\u0434\u0435\u0442 \u0431\u043e\u043b\u0435\u0435 \u0443\u0441\u043f\u0435\u0448\u043d\u043e\u0439.","34bf8a52":"\u0412 \u044d\u0442\u043e\u043c \u0437\u0430\u0434\u0430\u043d\u0438\u0438 \u043f\u043e\u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u043e\u0431\u0443\u0447\u0438\u0442\u044c \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0442\u043e\u0440 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439. \u0411\u0443\u0434\u0435\u043c \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c \u0441 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u043e\u043c, \u043d\u0430\u0437\u0432\u0430\u043d\u0438\u0435 \u043a\u043e\u0442\u043e\u0440\u043e\u0433\u043e \u0440\u0430\u0441\u043a\u0440\u044b\u0432\u0430\u0442\u044c \u043d\u0435 \u0431\u0443\u0434\u0435\u043c. \u041c\u043e\u0436\u0435\u0442\u0435 \u043f\u043e\u0441\u043c\u043e\u0442\u0440\u0435\u0442\u044c \u0441\u0430\u043c\u043e\u0441\u0442\u043e\u044f\u0442\u0435\u043b\u044c\u043d\u043e \u043d\u0430 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438, \u043a\u043e\u0442\u043e\u0440\u044b\u0435 \u0432 \u0435\u0441\u0442\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0435. \u0412 \u043d\u0451\u043c 200 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0438 \u043e\u043a\u043e\u043b\u043e 5 \u0442\u044b\u0441\u044f\u0447 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u043d\u0430 \u043a\u0430\u0436\u0434\u044b\u0439 \u043a\u043b\u0430\u0441\u0441. \u041a\u043b\u0430\u0441\u0441\u044b \u043f\u0440\u043e\u043d\u0443\u043c\u0435\u0440\u043e\u0432\u0430\u043d\u044b, \u043a\u0430\u043a \u043d\u0435\u0442\u0440\u0443\u0434\u043d\u043e \u0434\u043e\u0433\u0430\u0434\u0430\u0442\u044c\u0441\u044f, \u043e\u0442 0 \u0434\u043e 199. \u0421\u043a\u0430\u0447\u0430\u0442\u044c \u0434\u0430\u0442\u0430\u0441\u0435\u0442 \u043c\u043e\u0436\u043d\u043e \u0432\u043e\u0442 [\u0442\u0443\u0442](https:\/\/yadi.sk\/d\/BNR41Vu3y0c7qA).\n\n\u0421\u0442\u0440\u0443\u043a\u0442\u0443\u0440\u0430 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 \u043f\u0440\u043e\u0441\u0442\u0430\u044f -- \u0435\u0441\u0442\u044c \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438 train\/ \u0438 val\/, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043b\u0435\u0436\u0430\u0442 \u043e\u0431\u0443\u0447\u0430\u044e\u0449\u0438\u0435 \u0438 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u044b\u0435 \u0434\u0430\u043d\u043d\u044b\u0435. \u0412 train\/ \u0438 val\/ \u043b\u0435\u0436\u0430\u0442 \u0434\u0438\u0440\u0435\u043a\u0442\u043e\u0440\u0438\u0438\u0438, \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u043a\u043b\u0430\u0441\u0441\u0430\u043c \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u0439, \u0432 \u043a\u043e\u0442\u043e\u0440\u044b\u0445 \u043b\u0435\u0436\u0430\u0442, \u0441\u043e\u0431\u0441\u0442\u0432\u0435\u043d\u043d\u043e, \u0441\u0430\u043c\u0438 \u0438\u0437\u043e\u0431\u0440\u0430\u0436\u0435\u043d\u0438\u044f.\n \n__\u0417\u0430\u0434\u0430\u043d\u0438\u0435__. \u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u0442\u044c \u043b\u044e\u0431\u043e\u0435 \u0438\u0437 \u0434\u0432\u0443\u0445 \u0437\u0430\u0434\u0430\u043d\u0438\u0439\n\n1) \u0414\u043e\u0431\u0435\u0439\u0442\u0435\u0441\u044c accuracy **\u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043d\u0435 \u043c\u0435\u043d\u0435\u0435 0.44**. \u0412 \u044d\u0442\u043e\u043c \u0437\u0430\u0434\u0430\u043d\u0438\u0438 **\u0437\u0430\u043f\u0440\u0435\u0449\u0435\u043d\u043e** \u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u043f\u0440\u0435\u0434\u043e\u0431\u0443\u0447\u0435\u043d\u043d\u044b\u043c\u0438 \u043c\u043e\u0434\u0435\u043b\u044f\u043c\u0438 \u0438 \u0440\u0435\u0441\u0430\u0439\u0437\u043e\u043c \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a. \n\n2) \u0414\u043e\u0431\u0435\u0439\u0442\u0435\u0441\u044c accuracy **\u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043d\u0435 \u043c\u0435\u043d\u0435\u0435 0.84**. \u0412 \u044d\u0442\u043e\u043c \u0437\u0430\u0434\u0430\u043d\u0438\u0438 \u0434\u0435\u043b\u0430\u0442\u044c \u0440\u0435\u0441\u0430\u0439\u0437 \u0438 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043f\u0440\u0435\u0442\u0440\u0435\u0439\u043d \u043c\u043e\u0436\u043d\u043e. \n\n\u041d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u043a\u0440\u0430\u0442\u043a\u0438\u0439 \u043e\u0442\u0447\u0451\u0442 \u043e \u043f\u0440\u043e\u0434\u0435\u043b\u0430\u043d\u043d\u044b\u0445 \u044d\u043a\u0441\u043f\u0435\u0440\u0438\u043c\u0435\u043d\u0442\u0430\u0445. \u0427\u0442\u043e \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u043e \u0438 \u0447\u0442\u043e \u043d\u0435 \u0441\u0440\u0430\u0431\u043e\u0442\u0430\u043b\u043e? \u041f\u043e\u0447\u0435\u043c\u0443 \u0432\u044b \u0440\u0435\u0448\u0438\u043b\u0438, \u0441\u0434\u0435\u043b\u0430\u0442\u044c \u0442\u0430\u043a, \u0430 \u043d\u0435 \u0438\u043d\u0430\u0447\u0435? \u041e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u0443\u043a\u0430\u0437\u044b\u0432\u0430\u0439\u0442\u0435 \u0441\u0441\u044b\u043b\u043a\u0438 \u043d\u0430 \u0447\u0443\u0436\u043e\u0439 \u043a\u043e\u0434, \u0435\u0441\u043b\u0438 \u0432\u044b \u0435\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0435. \u041e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u0441\u0441\u044b\u043b\u0430\u0439\u0442\u0435\u0441\u044c \u043d\u0430 \u0441\u0442\u0430\u0442\u044c\u0438 \/ \u0431\u043b\u043e\u0433\u043f\u043e\u0441\u0442\u044b \/ \u0432\u043e\u043f\u0440\u043e\u0441\u044b \u043d\u0430 stackoverflow \/ \u0432\u0438\u0434\u043e\u0441\u044b \u043e\u0442 \u044e\u0442\u0443\u0431\u0435\u0440\u043e\u0432-\u043c\u0430\u0448\u0438\u043d\u043b\u0435\u0440\u043d\u0435\u0440\u043e\u0432 \/ \u043a\u0443\u0440\u0441\u044b \/ \u043f\u043e\u0434\u0441\u043a\u0430\u0437\u043a\u0438 \u043e\u0442 \u0414\u044f\u0434\u0438 \u0412\u0430\u0441\u0438 \u0438 \u043f\u0440\u043e\u0447\u0438\u0435 \u0434\u043e\u043f\u043e\u043b\u043d\u0438\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u044b, \u0435\u0441\u043b\u0438 \u0432\u044b \u0438\u0445 \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0435\u0442\u0435. \n\n\u0412\u0430\u0448 \u043a\u043e\u0434 \u043e\u0431\u044f\u0437\u0430\u0442\u0435\u043b\u044c\u043d\u043e \u0434\u043e\u043b\u0436\u0435\u043d \u043f\u0440\u043e\u0445\u043e\u0434\u0438\u0442\u044c \u0432\u0441\u0435 `assert`'\u044b \u043d\u0438\u0436\u0435.\n\n\u041d\u0435\u043e\u0431\u0445\u043e\u0434\u0438\u043c\u043e \u043d\u0430\u043f\u0438\u0441\u0430\u0442\u044c \u0444\u0443\u043d\u043a\u0446\u0438\u0438 `train_one_epoch`, `train` \u0438 `predict` \u043f\u043e \u0448\u0430\u0431\u043b\u043e\u043d\u0430\u043c \u043d\u0438\u0436\u0435 (\u0432\u043e \u043c\u043d\u043e\u0433\u043e\u043c \u043f\u043e\u0432\u0442\u043e\u0440\u044f\u044e\u0442 \u043f\u0440\u0438\u043c\u0435\u0440\u044b \u0441 \u0441\u0435\u043c\u0438\u043d\u0430\u0440\u043e\u0432).\u041e\u0431\u0440\u0430\u0442\u0438\u0442\u0435 \u043e\u0441\u043e\u0431\u043e\u0435 \u0432\u043d\u0438\u043c\u0430\u043d\u0438\u0435 \u043d\u0430 \u0444\u0443\u043d\u043a\u0446\u0438\u044e `predict`: \u043e\u043d\u0430 \u0434\u043e\u043b\u0436\u043d\u0430 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0442\u044c \u0441\u043f\u0438\u0441\u043e\u043a \u043b\u043e\u0441\u0441\u043e\u0432 \u043f\u043e \u0432\u0441\u0435\u043c \u043e\u0431\u044a\u0435\u043a\u0442\u0430\u043c \u0434\u0430\u0442\u0430\u043b\u043e\u0430\u0434\u0435\u0440\u0430, \u0441\u043f\u0438\u0441\u043e\u043a \u043f\u0440\u0435\u0434\u0441\u043a\u0430\u0437\u0430\u043d\u043d\u044b\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u0438\u0437 \u0434\u0430\u0442\u0430\u043b\u043e\u0430\u043b\u0435\u0440\u0430 \u0438 \u0441\u043f\u0438\u0441\u043e\u043a \u043d\u0430\u0441\u0442\u043e\u044f\u0449\u0438\u0445 \u043a\u043b\u0430\u0441\u0441\u043e\u0432 \u0434\u043b\u044f \u043a\u0430\u0436\u0434\u043e\u0433\u043e \u043e\u0431\u044a\u0435\u043a\u0442\u0430 \u0432 \u0434\u0430\u0442\u0430\u043b\u043e\u0430\u0434\u0435\u0440\u0435 (\u0438 \u0438\u043c\u0435\u043d\u043d\u043e \u0432 \u0442\u0430\u043a\u043e\u043c \u043f\u043e\u0440\u044f\u0434\u043a\u0435).\n\n__\u0418\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u0432\u043d\u0435\u0448\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0435 \u0434\u043b\u044f \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f \u0441\u0442\u0440\u043e\u0433\u043e \u0437\u0430\u043f\u0440\u0435\u0449\u0435\u043d\u043e \u0432 \u043e\u0431\u043e\u0438\u0445 \u0437\u0430\u0434\u0430\u043d\u0438\u044f\u0445. \u0422\u0430\u043a\u0436\u0435 \u0437\u0430\u043f\u0440\u0435\u0449\u0435\u043d\u043e \u043e\u0431\u0443\u0447\u0430\u0442\u044c\u0441\u044f \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u043e\u043d\u043d\u043e\u0439 \u0432\u044b\u0431\u043e\u0440\u043a\u0435__.\n\n\n__\u041a\u0440\u0438\u0442\u0435\u0440\u0438\u0438 \u043e\u0446\u0435\u043d\u043a\u0438__: \u041e\u0446\u0435\u043d\u043a\u0430 \u0432\u044b\u0447\u0438\u0441\u043b\u044f\u0435\u0442\u0441\u044f \u043f\u043e \u043f\u0440\u043e\u0441\u0442\u043e\u0439 \u0444\u043e\u0440\u043c\u0443\u043b\u0435: `min(10, 10 * \u0412\u0430\u0448\u0430 accuracy \/ 0.44)` \u0434\u043b\u044f \u043f\u0435\u0440\u0432\u043e\u0433\u043e \u0437\u0430\u0434\u0430\u043d\u0438\u044f \u0438 `min(10, 10 * (\u0412\u0430\u0448\u0430 accuracy - 0.5) \/ 0.34)` \u0434\u043b\u044f \u0432\u0442\u043e\u0440\u043e\u0433\u043e. \u041e\u0446\u0435\u043d\u043a\u0430 \u043e\u043a\u0440\u0443\u0433\u043b\u044f\u0435\u0442\u0441\u044f \u0434\u043e \u0434\u0435\u0441\u044f\u0442\u044b\u0445 \u043f\u043e \u0430\u0440\u0438\u0444\u043c\u0435\u0442\u0438\u0447\u0435\u0441\u043a\u0438\u043c \u043f\u0440\u0430\u0432\u0438\u043b\u0430\u043c. \u0415\u0441\u043b\u0438 \u0432\u044b \u0432\u044b\u043f\u043e\u043b\u043d\u0438\u043b\u0438 \u043e\u0431\u0430 \u0437\u0430\u0434\u0430\u043d\u0438\u044f, \u0442\u043e \u0431\u0435\u0440\u0435\u0442\u0441\u044f \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c \u0438\u0437 \u0434\u0432\u0443\u0445 \u043e\u0446\u0435\u043d\u043e\u043a.\n\n__\u0411\u043e\u043d\u0443\u0441__. \u0412\u044b \u043f\u043e\u043b\u0443\u0447\u0430\u0435\u0442\u0435 5 \u0431\u043e\u043d\u0443\u0441\u043d\u044b\u0445 \u0431\u0430\u043b\u043b\u043e\u0432 \u0435\u0441\u043b\u0438 \u0441\u043f\u0440\u0430\u0432\u043b\u044f\u0435\u0442\u0435\u0441\u044c \u0441 \u043e\u0431\u043e\u0438\u043c\u0438 \u0437\u0430\u0434\u0430\u043d\u0438\u044f\u043c\u0438 \u043d\u0430 10 \u0431\u0430\u043b\u043b\u043e\u0432 (\u0438\u0442\u043e\u0433\u043e 15 \u0431\u0430\u043b\u043b\u043e\u0432). \u0412 \u043f\u0440\u043e\u0442\u0438\u0432\u043d\u043e\u043c \u0441\u043b\u0443\u0447\u0430\u0435 \u0432\u044b\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u0442\u0441\u044f \u043c\u0430\u043a\u0441\u0438\u043c\u0430\u043b\u044c\u043d\u0430\u044f \u0438\u0437 \u0434\u0432\u0443\u0445 \u043e\u0446\u0435\u043d\u043e\u043a \u0438 \u0432\u0430\u0448 \u0431\u043e\u043d\u0443\u0441 \u0440\u0430\u0432\u0435\u043d \u043d\u0443\u043b\u044e.\n\n__\u0421\u043e\u0432\u0435\u0442\u044b \u0438 \u0443\u043a\u0430\u0437\u0430\u043d\u0438\u044f__:\n - \u041d\u0430\u0432\u0435\u0440\u043d\u044f\u043a\u0430 \u0432\u0430\u043c \u043f\u043e\u0442\u0440\u0435\u0431\u0443\u0435\u0442\u0441\u044f \u043c\u043d\u043e\u0433\u043e \u0433\u0443\u0433\u043b\u0438\u0442\u044c \u043e \u043a\u043b\u0430\u0441\u0441\u0438\u0444\u0438\u043a\u0430\u0446\u0438\u0438 \u0438 \u043e \u0442\u043e\u043c, \u043a\u0430\u043a \u0437\u0430\u0441\u0442\u0430\u0432\u0438\u0442\u044c \u0435\u0451 \u0440\u0430\u0431\u043e\u0442\u0430\u0442\u044c. \u042d\u0442\u043e \u043d\u043e\u0440\u043c\u0430\u043b\u044c\u043d\u043e, \u0432\u0441\u0435 \u0433\u0443\u0433\u043b\u044f\u0442. \u041d\u043e \u043d\u0435 \u0437\u0430\u0431\u044b\u0432\u0430\u0439\u0442\u0435, \u0447\u0442\u043e \u043d\u0443\u0436\u043d\u043e \u0431\u044b\u0442\u044c \u0433\u043e\u0442\u043e\u0432\u044b\u043c \u0437\u0430 \u0441\u043a\u0430\u0442\u0430\u043d\u043d\u044b\u0439 \u043a\u043e\u0434 \u043e\u0442\u0432\u0435\u0447\u0430\u0442\u044c :)\n - \u0418\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 \u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438. \u0414\u043b\u044f \u044d\u0442\u043e\u0433\u043e \u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435\u0441\u044c \u043c\u043e\u0434\u0443\u043b\u0435\u043c `torchvision.transforms` \u0438\u043b\u0438 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\u043e\u0439 [albumentations](https:\/\/github.com\/albumentations-team\/albumentations)\n - \u041c\u043e\u0436\u043d\u043e \u043e\u0431\u0443\u0447\u0430\u0442\u044c \u0441 \u043d\u0443\u043b\u044f \u0438\u043b\u0438 \u0444\u0430\u0439\u043d\u0442\u044e\u043d\u0438\u0442\u044c (\u0432 \u0437\u0430\u0432\u0438\u0441\u0438\u043c\u043e\u0441\u0442\u0438 \u043e\u0442 \u0437\u0430\u0434\u0430\u043d\u0438\u044f) \u043c\u043e\u0434\u0435\u043b\u0438 \u0438\u0437 `torchvision`.\n - \u0420\u0435\u043a\u043e\u043c\u0435\u043d\u0434\u0443\u0435\u043c \u043d\u0430\u043f\u0438\u0441\u0430\u0442\u044c \u0432\u0430\u043c \u0441\u043d\u0430\u0447\u0430\u043b\u0430 \u043a\u043b\u0430\u0441\u0441-\u0434\u0430\u0442\u0430\u0441\u0435\u0442 (\u0438\u043b\u0438 \u0432\u043e\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c\u0441\u044f \u043a\u043b\u0430\u0441\u0441\u043e\u043c `ImageFolder`), \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u0432\u043e\u0437\u0432\u0440\u0430\u0449\u0430\u0435\u0442 \u043a\u0430\u0440\u0442\u0438\u043d\u043a\u0438 \u0438 \u0441\u043e\u043e\u0442\u0432\u0435\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0438\u043c \u043a\u043b\u0430\u0441\u0441\u044b, \u0430 \u0437\u0430\u0442\u0435\u043c \u0444\u0443\u043d\u043a\u0446\u0438\u0438 \u0434\u043b\u044f \u0442\u0440\u0435\u0439\u043d\u0430 \u043f\u043e \u0448\u0430\u0431\u043b\u043e\u043d\u0430\u043c \u043d\u0438\u0436\u0435. \u041e\u0434\u043d\u0430\u043a\u043e \u0434\u0435\u043b\u0430\u0442\u044c \u044d\u0442\u043e \u043c\u044b \u043d\u0435 \u0437\u0430\u0441\u0442\u0430\u0432\u043b\u044f\u0435\u043c. \u0415\u0441\u043b\u0438 \u0432\u0430\u043c \u0442\u0430\u043a \u043d\u0435\u0443\u0434\u043e\u0431\u043d\u043e, \u0442\u043e \u043c\u043e\u0436\u0435\u0442\u0435 \u043f\u0438\u0441\u0430\u0442\u044c \u043a\u043e\u0434 \u0432 \u0443\u0434\u043e\u0431\u043d\u043e\u043c \u0441\u0442\u0438\u043b\u0435. \u041e\u0434\u043d\u0430\u043a\u043e \u0443\u0447\u0442\u0438\u0442\u0435, \u0447\u0442\u043e \u0447\u0440\u0435\u0437\u043c\u0435\u0440\u043d\u043e\u0435 \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u043d\u0438\u0436\u0435\u043f\u0435\u0440\u0435\u0447\u0438\u0441\u043b\u0435\u043d\u043d\u044b\u0445 \u0448\u0430\u0431\u043b\u043e\u043d\u043e\u0432 \u0443\u0432\u0435\u043b\u0438\u0447\u0438\u0442 \u043a\u043e\u043b\u0438\u0447\u0435\u0441\u0442\u0432\u043e \u0432\u043e\u043f\u0440\u043e\u0441\u043e\u0432 \u043a \u0432\u0430\u0448\u0435\u043c\u0443 \u043a\u043e\u0434\u0443 \u0438 \u043f\u043e\u0432\u044b\u0441\u0438\u0442 \u0432\u0435\u0440\u043e\u044f\u0442\u043d\u043e\u0441\u0442\u044c \u0432\u044b\u0437\u043e\u0432\u0430 \u043d\u0430 \u0437\u0430\u0449\u0438\u0442\u0443 :)\n - \u0412\u0430\u043b\u0438\u0434\u0438\u0440\u0443\u0439\u0442\u0435. \u0422\u0440\u0435\u043a\u0430\u0439\u0442\u0435 \u043e\u0448\u0438\u0431\u043a\u0438 \u043a\u0430\u043a \u043c\u043e\u0436\u043d\u043e \u0440\u0430\u043d\u044c\u0448\u0435, \u0447\u0442\u043e\u0431\u044b \u043d\u0435 \u0442\u0440\u0430\u0442\u0438\u0442\u044c \u0432\u0440\u0435\u043c\u044f \u0432\u043f\u0443\u0441\u0442\u0443\u044e.\n - \u0427\u0442\u043e\u0431\u044b \u0431\u044b\u0441\u0442\u0440\u043e \u043e\u0442\u043b\u0430\u0434\u0438\u0442\u044c \u043a\u043e\u0434, \u043f\u0440\u043e\u0431\u0443\u0439\u0442\u0435 \u043e\u0431\u0443\u0447\u0430\u0442\u044c\u0441\u044f \u043d\u0430 \u043c\u0430\u043b\u0435\u043d\u044c\u043a\u043e\u0439 \u0447\u0430\u0441\u0442\u0438 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0430 (\u0441\u043a\u0430\u0436\u0435\u043c, 5-10 \u043a\u0430\u0440\u0442\u0438\u043d\u043e\u043a \u043f\u0440\u043e\u0441\u0442\u043e \u0447\u0442\u043e\u0431\u044b \u0443\u0431\u0435\u0434\u0438\u0442\u044c\u0441\u044f \u0447\u0442\u043e \u043a\u043e\u0434 \u0437\u0430\u043f\u0443\u0441\u043a\u0430\u0435\u0442\u0441\u044f). \u041a\u043e\u0433\u0434\u0430 \u0432\u044b \u043f\u043e\u043d\u044f\u043b\u0438, \u0447\u0442\u043e \u0441\u043c\u043e\u0433\u043b\u0438 \u0432\u0441\u0451 \u043e\u0442\u0434\u0435\u0431\u0430\u0436\u0438\u0442\u044c, \u043f\u0435\u0440\u0435\u0445\u043e\u0434\u0438\u0442\u0435 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044e \u043f\u043e \u0432\u0441\u0435\u043c\u0443 \u0434\u0430\u0442\u0430\u0441\u0435\u0442\u0443\n - \u041d\u0430 \u043a\u0430\u0436\u0434\u044b\u0439 \u0437\u0430\u043f\u0443\u0441\u043a \u0434\u0435\u043b\u0430\u0439\u0442\u0435 \u0440\u043e\u0432\u043d\u043e \u043e\u0434\u043d\u043e \u0438\u0437\u043c\u0435\u043d\u0435\u043d\u0438\u0435 \u0432 \u043c\u043e\u0434\u0435\u043b\u0438\/\u0430\u0443\u0433\u043c\u0435\u043d\u0442\u0430\u0446\u0438\u0438\/\u043e\u043f\u0442\u0438\u043c\u0430\u0439\u0437\u0435\u0440\u0435, \u0447\u0442\u043e\u0431\u044b \u043f\u043e\u043d\u044f\u0442\u044c, \u0447\u0442\u043e \u0438 \u043a\u0430\u043a \u0432\u043b\u0438\u044f\u0435\u0442 \u043d\u0430 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442.\n - \u0424\u0438\u043a\u0441\u0438\u0440\u0443\u0439\u0442\u0435 random seed.\n - \u041d\u0430\u0447\u0438\u043d\u0430\u0439\u0442\u0435 \u0441 \u043f\u0440\u043e\u0441\u0442\u044b\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u0438 \u043f\u043e\u0441\u0442\u0435\u043f\u0435\u043d\u043d\u043e \u043f\u0435\u0440\u0435\u0445\u043e\u0434\u0438\u0442\u0435 \u043a \u0441\u043b\u043e\u0436\u043d\u044b\u043c. \u041e\u0431\u0443\u0447\u0435\u043d\u0438\u0435 \u043b\u0451\u0433\u043a\u0438\u0445 \u043c\u043e\u0434\u0435\u043b\u0435\u0439 \u044d\u043a\u043e\u043d\u043e\u043c\u0438\u0442 \u043c\u043d\u043e\u0433\u043e \u0432\u0440\u0435\u043c\u0435\u043d\u0438.\n - \u0421\u0442\u0430\u0432\u044c\u0442\u0435 \u0440\u0430\u0441\u043f\u0438\u0441\u0430\u043d\u0438\u0435 \u043d\u0430 learning rate. \u0423\u043c\u0435\u043d\u044c\u0448\u0430\u0439\u0442\u0435 \u0435\u0433\u043e, \u043a\u043e\u0433\u0434\u0430 \u043b\u043e\u0441\u0441 \u043d\u0430 \u0432\u0430\u043b\u0438\u0434\u0430\u0446\u0438\u0438 \u043f\u0435\u0440\u0435\u0441\u0442\u0430\u0451\u0442 \u0443\u0431\u044b\u0432\u0430\u0442\u044c.\n - \u0421\u043e\u0432\u0435\u0442\u0443\u0435\u043c \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c GPU. \u0415\u0441\u043b\u0438 \u0443 \u0432\u0430\u0441 \u0435\u0433\u043e \u043d\u0435\u0442, \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u0443\u0439\u0442\u0435 google colab. \u0415\u0441\u043b\u0438 \u0432\u0430\u043c \u043d\u0435\u0443\u0434\u043e\u0431\u043d\u043e \u0435\u0433\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u0442\u044c \u043d\u0430 \u043f\u043e\u0441\u0442\u043e\u044f\u043d\u043d\u043e\u0439 \u043e\u0441\u043d\u043e\u0432\u0435, \u043d\u0430\u043f\u0438\u0448\u0438\u0442\u0435 \u0438 \u043e\u0442\u043b\u0430\u0434\u044c\u0442\u0435 \u0432\u0435\u0441\u044c \u043a\u043e\u0434 \u043b\u043e\u043a\u0430\u043b\u044c\u043d\u043e \u043d\u0430 CPU, \u0430 \u0437\u0430\u0442\u0435\u043c \u0437\u0430\u043f\u0443\u0441\u0442\u0438\u0442\u0435 \u0443\u0436\u0435 \u043d\u0430\u043f\u0438\u0441\u0430\u043d\u043d\u044b\u0439 \u043d\u043e\u0443\u0442\u0431\u0443\u043a \u0432 \u043a\u043e\u043b\u0430\u0431\u0435. \u0410\u0432\u0442\u043e\u0440\u0441\u043a\u043e\u0435 \u0440\u0435\u0448\u0435\u043d\u0438\u0435 \u0437\u0430\u0434\u0430\u043d\u0438\u044f \u0434\u043e\u0441\u0442\u0438\u0433\u0430\u0435\u0442 \u0442\u0440\u0435\u0431\u0443\u0435\u043c\u043e\u0439 \u0442\u043e\u0447\u043d\u043e\u0441\u0442\u0438 \u0432 \u043a\u043e\u043b\u0430\u0431\u0435 \u0437\u0430 15 \u043c\u0438\u043d\u0443\u0442 \u043e\u0431\u0443\u0447\u0435\u043d\u0438\u044f.\n \nGood luck & have fun! :)","227426bd":"\u0412 \u0430\u0443\u0442\u043f\u0443\u0442\u0435 \u0432\u044b\u0448\u0435 \u0432\u0438\u0434\u043d\u043e, \u0447\u0442\u043e \u043c\u0430\u043a\u0441\u0438\u043c\u0443\u043c, \u043a\u043e\u0442\u043e\u0440\u044b\u0439 \u043e\u043d\u0430 \u0434\u0430\u043b\u0430 -- 0.4294. \u042f \u0445\u043e\u0442\u0435\u043b\u0430 \u0435\u0435 \u043f\u0440\u043e\u0432\u0435\u0440\u0438\u0442\u044c \u043d\u0438\u0436\u0435, \u043d\u043e \u043d\u0435 \u0443\u0441\u043f\u0435\u0432\u0430\u044e \u0434\u043e \u0434\u044d\u0434\u043b\u0430\u0439\u043d\u0430. \u041d\u043e \u043e\u043d\u0430 \u0434\u0430\u0441\u0442 \u044d\u0442\u043e\u0442 \u0436\u0435 \u0440\u0435\u0437\u0443\u043b\u044c\u0442\u0430\u0442. Kaggle \u0440\u0435\u0448\u0438\u043b \u0443\u0434\u0430\u043b\u0438\u0442\u044c \u0432\u0441\u0435 \u043c\u043e\u0438 \u0444\u0430\u0439\u043b\u044b, \u0441\u043e\u0445\u0440\u0430\u043d\u0435\u043d\u043d\u044b\u0435 \u043c\u043e\u0434\u0435\u043b\u0438 \u0438 \u0442. \u0434., \u0438\u0437-\u0437\u0430 \u0442\u043e\u0433\u043e, \u0447\u0442\u043e \u044f \u043d\u0435\u043f\u0440\u0435\u0440\u044b\u0432\u043d\u043e \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0430 \u0435\u0433\u043e 9 \u0447\u0430\u0441\u043e\u0432... ","65e202eb":"### \u0412\u0441\u043f\u043e\u043c\u043e\u0433\u0430\u0442\u0435\u043b\u044c\u043d\u044b\u0435 \u0444\u0443\u043d\u043a\u0446\u0438\u0438, \u0440\u0435\u0430\u043b\u0438\u0437\u0430\u0446\u0438\u044f \u043c\u043e\u0434\u0435\u043b\u0438","305c2185":"\u042f \u0438\u0441\u043f\u043e\u043b\u044c\u0437\u043e\u0432\u0430\u043b\u0430 \u043c\u0430\u0442\u0435\u0440\u0438\u0430\u043b\u044b \u0441\u0442\u0430\u0442\u044c\u0438 https:\/\/towardsdatascience.com\/custom-dataset-in-pytorch-part-1-images-2df3152895 \u0438 \u043d\u0430\u0448\u0438\u0445 \u0441\u0435\u043c\u0438\u043d\u0430\u0440\u043e\u0432 ","28e041df":"### \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043f\u043e\u043b\u0443\u0447\u0435\u043d\u043d\u043e\u0439 accuracy"}}