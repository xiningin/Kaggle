{"cell_type":{"6966e23a":"code","b262aed9":"code","7fff0239":"code","a8169bba":"code","9f75aa27":"code","496813fb":"code","c15608d7":"code","64ed3a49":"code","df5d864b":"code","b7367950":"code","fde7148d":"code","cc0ac470":"code","4d614704":"code","ff521903":"code","8c3dc293":"code","1ea6bbaa":"code","eccd3cdf":"code","da946034":"code","c14db746":"code","37a91c96":"code","72e2600a":"code","6421cb0e":"code","fb85f08e":"code","84a2e69c":"code","1798ff0d":"code","a563013f":"code","88131b6b":"code","2086d007":"code","bd9042ce":"code","44a21d47":"code","562dbf20":"code","d6f55f84":"code","6cdb1283":"code","0353ecfb":"code","a0bd3395":"code","29a7cf7a":"code","215f6e39":"code","55af46cb":"code","9807859e":"code","b53852ad":"code","ef94214e":"code","df47eadb":"code","12d3f043":"code","c4b12775":"code","ac1f4c0c":"code","bc44fe88":"markdown"},"source":{"6966e23a":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt \nimport seaborn as sns ","b262aed9":"df = pd.read_csv('..\/input\/students-performance-in-exams\/Student Performance new.csv')\ndf.head().style.background_gradient(axis=0)","7fff0239":"df.columns","a8169bba":"df.isnull().sum()","9f75aa27":"new_df = pd.get_dummies(df, columns = ['parental level of education','race\/ethnicity','lunch','test preparation course'] ,drop_first= True,prefix = 'Dumy',prefix_sep =\"*\" )\nnew_df.head().style.background_gradient(axis=0)","496813fb":"new_df.describe().style.background_gradient(axis=0)","c15608d7":"# As we see there is no imbalnce data issue to work on it so now will make some data visualization :\nsns.countplot(data = new_df , x = 'sex')","64ed3a49":"plt.figure(figsize=(12,8),dpi =150)\nsns.heatmap(new_df.corr(),annot =True)","df5d864b":"new_df.columns","b7367950":"plt.figure(figsize=(10,8),dpi =150)\nsns.scatterplot(data = new_df , x = 'math percentage',y= 'reading score percentage',hue = 'sex')","fde7148d":"plt.figure(figsize=(10,8),dpi =150)\nsns.scatterplot(data = new_df , x = 'math percentage',y= 'writing score percentage',hue = 'sex')","cc0ac470":"sns.boxplot(data = new_df , x ='sex',y='math percentage')","4d614704":"plt.figure(figsize = (8,6),dpi =150)\nsns.boxplot(data = new_df , x ='sex',y='writing score percentage')","ff521903":"# Now we are going to drop columns to get X and y :\nX = new_df.drop('sex',axis = 1)\ny = new_df['sex']","8c3dc293":"# now we are going to make train test split \nfrom sklearn.model_selection import train_test_split","1ea6bbaa":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.15, random_state=101)","eccd3cdf":"from sklearn.preprocessing import StandardScaler","da946034":"scaler = StandardScaler()","c14db746":"scaler.fit(X_train)","37a91c96":"scaled_x_train = scaler.transform(X_train)\nscaled_x_test = scaler.transform(X_test)","72e2600a":"# now we are going to choose the alghorith that we will work with it : \nfrom sklearn.svm import SVC","6421cb0e":"svc = SVC()\nfrom sklearn.model_selection import GridSearchCV\nparam_grid = {'C':[0.001,0.01,0.1,0.5,1]}\ngrid = GridSearchCV(svc,param_grid)\ngrid.fit(scaled_x_train,y_train)","fb85f08e":"grid.best_params_","84a2e69c":"y_pred = grid.predict(X_test)","1798ff0d":"# Now we wwill import metrics , to see the model working good or not : \nfrom sklearn.metrics import accuracy_score , plot_confusion_matrix , plot_roc_curve , plot_precision_recall_curve , classification_report","a563013f":"svc_accuracy = accuracy_score(y_test,y_pred)\nsvc_accuracy","88131b6b":"print(classification_report(y_test,y_pred))","2086d007":"from sklearn.neighbors import KNeighborsClassifier","bd9042ce":"test_error_rates = []\nfor k in range(1,30):\n    knn_model = KNeighborsClassifier(n_neighbors=k)\n    knn_model.fit(scaled_x_train,y_train)\n    y_prediction = knn_model.predict(X_test)\n    test_error = 1- accuracy_score(y_test , y_prediction)\n    test_error_rates.append(test_error)","44a21d47":"# So now we will choose 15 to be the k _ value :\nplt.plot(range(1,30),test_error_rates)\nplt.ylabel('Error Rate')\nplt.xlabel('K Neigbors')","562dbf20":"model = KNeighborsClassifier(n_neighbors=15)\nmodel.fit(X_train,y_train)","d6f55f84":"y_predictions = model.predict(X_test)","6cdb1283":"print(classification_report(y_test,y_predictions))","0353ecfb":"knn_model_accuracy = accuracy_score(y_test,y_predictions)\nknn_model_accuracy","a0bd3395":"plot_confusion_matrix(model,X_test,y_test)","29a7cf7a":"plot_roc_curve(model,X_test,y_test)","215f6e39":"from sklearn.linear_model import LogisticRegression","55af46cb":"log_model = LogisticRegression()","9807859e":"log_model.fit(scaled_x_train,y_train)","b53852ad":"predections = log_model.predict(scaled_x_test)","ef94214e":"logistic_regression_model_accuracy = accuracy_score(y_test,predections)\nlogistic_regression_model_accuracy","df47eadb":"plot_confusion_matrix(log_model,scaled_x_test,y_test)","12d3f043":"print(classification_report(y_test,predections))","c4b12775":"plot_roc_curve(log_model,scaled_x_test,y_test)","ac1f4c0c":"plot_precision_recall_curve(log_model,scaled_x_test,y_test)","bc44fe88":"# Now i will try 3 Alghorithms ( SVM & KNN & LogisticRegression ) and the best accuracy will be LogisticRegression :"}}