{"cell_type":{"d372e8f3":"code","41a3331e":"code","dd6ca663":"code","b01a62a1":"code","bcaf8e28":"code","41d9e0e0":"code","d6f74fc8":"code","3891614d":"code","1872c4b4":"code","809f2a28":"code","e2f6f5b2":"code","b8ba3de6":"code","89504b44":"code","439d8a5d":"code","f50fa02a":"code","c4ae4a58":"code","6847f110":"code","824d62cc":"code","d0e94cba":"code","ed73c107":"code","66d50c85":"code","07976948":"code","77ac520a":"code","a36c6b20":"code","8c44bff0":"code","ada89105":"code","c2c61078":"code","ba43cac0":"code","b8948e58":"code","7f5e2a1b":"code","d06d92f3":"code","c1ebb053":"code","2c898c42":"code","753febfc":"code","704e1dfa":"code","4d6cf5f4":"code","e9067d5b":"code","a4ee4a41":"code","7bec13be":"code","94308d3c":"code","948ff7ec":"code","c05171a2":"code","2175efc1":"code","b941b45e":"code","74df8ed5":"code","9f8c03f7":"code","05ecbb2f":"code","d12755ed":"code","d081a7fe":"code","53efa377":"code","0608c26b":"code","4a5641ef":"code","37b1f7c6":"code","45182a7f":"code","a53e84f9":"code","0c50eebc":"code","a1aeeeac":"code","d8147ee0":"code","d423317a":"code","a8a363cd":"code","6ee41c58":"code","6d3a9a7e":"code","8815ad55":"code","7005afe4":"code","b933fe11":"code","a8f61fdb":"code","e1a565aa":"code","23637876":"code","a5ceef58":"code","60d657cf":"code","651d8e6a":"code","c7cdab1e":"code","2049372c":"code","65e0d2c1":"code","6c62d9f7":"code","053e9840":"code","0ea939a5":"code","d1e51cb7":"code","9fd552cc":"code","ad6adac8":"code","fc705232":"code","3342a77b":"code","bcd17926":"code","87028174":"code","0e59ef4c":"code","a66fe45d":"markdown","c912cd26":"markdown","78111b02":"markdown","6e0efc42":"markdown","d4cf3342":"markdown","95b4d1bb":"markdown","5f588a3c":"markdown","8913efa1":"markdown","6f19de35":"markdown","52b6356d":"markdown","2559405c":"markdown","1f64f9fc":"markdown","296a9b9f":"markdown","ef7ab800":"markdown","49ade78b":"markdown","2517df3e":"markdown","e2d73463":"markdown","0e551a59":"markdown","39685f12":"markdown","e8874743":"markdown","bb09cbf3":"markdown","72354cda":"markdown","9ce86113":"markdown","ea90f7c3":"markdown","8dd612aa":"markdown","a581d831":"markdown","74c831ee":"markdown","210e3683":"markdown","49ae9baa":"markdown","58160eb5":"markdown","37703f04":"markdown","f8ccaeab":"markdown","070839af":"markdown","6f821617":"markdown","51f8c5e7":"markdown","2ec24839":"markdown"},"source":{"d372e8f3":"import pandas as pd\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')","41a3331e":"train.head(5)","dd6ca663":"test.head(5)","b01a62a1":"train.shape","bcaf8e28":"test.shape","41d9e0e0":"train.info()","d6f74fc8":"test.info()","3891614d":"train.isnull().sum()","1872c4b4":"test.isnull().sum()","809f2a28":"import matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set() # setting seaborn default for plots","e2f6f5b2":"def bar_chart(feature):\n    survived = train[train['Survived']==1][feature].value_counts()\n    dead = train[train['Survived']==0][feature].value_counts()\n    df = pd.DataFrame([survived,dead])\n    df.index = ['Survived','Dead']\n    df.plot(kind='bar',stacked=True, figsize=(10,5))","b8ba3de6":"bar_chart('Sex')","89504b44":"bar_chart('Pclass')","439d8a5d":"bar_chart('SibSp')","f50fa02a":"bar_chart('Parch')","c4ae4a58":"bar_chart('Embarked')","6847f110":"train.head()","824d62cc":"train.head(10)","d0e94cba":"train_test_data = [train, test] # combining train and test dataset\n\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Name'].str.extract(' ([A-Za-z]+)\\.', expand=False)","ed73c107":"train['Title'].value_counts()","66d50c85":"test['Title'].value_counts()","07976948":"title_mapping = {\"Mr\": 0, \"Miss\": 1, \"Mrs\": 2, \n                 \"Master\": 3, \"Dr\": 3, \"Rev\": 3, \"Col\": 3, \"Major\": 3, \"Mlle\": 3,\"Countess\": 3,\n                 \"Ms\": 3, \"Lady\": 3, \"Jonkheer\": 3, \"Don\": 3, \"Dona\" : 3, \"Mme\": 3,\"Capt\": 3,\"Sir\": 3 }\nfor dataset in train_test_data:\n    dataset['Title'] = dataset['Title'].map(title_mapping)","77ac520a":"train.head()","a36c6b20":"test.head()","8c44bff0":"bar_chart('Title')","ada89105":"# delete unnecessary feature from dataset\ntrain.drop('Name', axis=1, inplace=True)\ntest.drop('Name', axis=1, inplace=True)","c2c61078":"train.head()","ba43cac0":"test.head()","b8948e58":"sex_mapping = {\"male\": 0, \"female\": 1}\nfor dataset in train_test_data:\n    dataset['Sex'] = dataset['Sex'].map(sex_mapping)","7f5e2a1b":"bar_chart('Sex')","d06d92f3":"train.head(100)","c1ebb053":"# fill missing age with median age for each title (Mr, Mrs, Miss, Others)\ntrain[\"Age\"].fillna(train.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)\ntest[\"Age\"].fillna(test.groupby(\"Title\")[\"Age\"].transform(\"median\"), inplace=True)","2c898c42":"train.head(30)\ntrain.groupby(\"Title\")[\"Age\"].transform(\"median\")","753febfc":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\n \nplt.show() ","704e1dfa":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","4d6cf5f4":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(20, 30)","e9067d5b":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(30, 40)","a4ee4a41":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","7bec13be":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(40, 60)","94308d3c":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Age',shade= True)\nfacet.set(xlim=(0, train['Age'].max()))\nfacet.add_legend()\nplt.xlim(60)","948ff7ec":"train.info()","c05171a2":"test.info()","2175efc1":"for dataset in train_test_data:\n    dataset.loc[ dataset['Age'] <= 16, 'Age'] = 0,\n    dataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 26), 'Age'] = 1,\n    dataset.loc[(dataset['Age'] > 26) & (dataset['Age'] <= 36), 'Age'] = 2,\n    dataset.loc[(dataset['Age'] > 36) & (dataset['Age'] <= 62), 'Age'] = 3,\n    dataset.loc[ dataset['Age'] > 62, 'Age'] = 4","b941b45e":"train.head()","74df8ed5":"bar_chart('Age')","9f8c03f7":"Pclass1 = train[train['Pclass']==1]['Embarked'].value_counts()\nPclass2 = train[train['Pclass']==2]['Embarked'].value_counts()\nPclass3 = train[train['Pclass']==3]['Embarked'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","05ecbb2f":"for dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].fillna('S')","d12755ed":"train.head()","d081a7fe":"embarked_mapping = {\"S\": 0, \"C\": 1, \"Q\": 2}\nfor dataset in train_test_data:\n    dataset['Embarked'] = dataset['Embarked'].map(embarked_mapping)","53efa377":"# fill missing Fare with median fare for each Pclass\ntrain[\"Fare\"].fillna(train.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntest[\"Fare\"].fillna(test.groupby(\"Pclass\")[\"Fare\"].transform(\"median\"), inplace=True)\ntrain.head(5)","0608c26b":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\n \nplt.show()  ","4a5641ef":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 20)","37b1f7c6":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0, 30)","45182a7f":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'Fare',shade= True)\nfacet.set(xlim=(0, train['Fare'].max()))\nfacet.add_legend()\nplt.xlim(0)","a53e84f9":"for dataset in train_test_data:\n    dataset.loc[ dataset['Fare'] <= 17, 'Fare'] = 0,\n    dataset.loc[(dataset['Fare'] > 17) & (dataset['Fare'] <= 30), 'Fare'] = 1,\n    dataset.loc[(dataset['Fare'] > 30) & (dataset['Fare'] <= 100), 'Fare'] = 2,\n    dataset.loc[ dataset['Fare'] > 100, 'Fare'] = 3","0c50eebc":"train.head()","a1aeeeac":"train.Cabin.value_counts()","d8147ee0":"for dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].str[:1]","d423317a":"Pclass1 = train[train['Pclass']==1]['Cabin'].value_counts()\nPclass2 = train[train['Pclass']==2]['Cabin'].value_counts()\nPclass3 = train[train['Pclass']==3]['Cabin'].value_counts()\ndf = pd.DataFrame([Pclass1, Pclass2, Pclass3])\ndf.index = ['1st class','2nd class', '3rd class']\ndf.plot(kind='bar',stacked=True, figsize=(10,5))","a8a363cd":"cabin_mapping = {\"A\": 0, \"B\": 0.4, \"C\": 0.8, \"D\": 1.2, \"E\": 1.6, \"F\": 2, \"G\": 2.4, \"T\": 2.8}\nfor dataset in train_test_data:\n    dataset['Cabin'] = dataset['Cabin'].map(cabin_mapping)","6ee41c58":"# fill missing Fare with median fare for each Pclass\ntrain[\"Cabin\"].fillna(train.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)\ntest[\"Cabin\"].fillna(test.groupby(\"Pclass\")[\"Cabin\"].transform(\"median\"), inplace=True)","6d3a9a7e":"train[\"FamilySize\"] = train[\"SibSp\"] + train[\"Parch\"] + 1\ntest[\"FamilySize\"] = test[\"SibSp\"] + test[\"Parch\"] + 1","8815ad55":"facet = sns.FacetGrid(train, hue=\"Survived\",aspect=4)\nfacet.map(sns.kdeplot,'FamilySize',shade= True)\nfacet.set(xlim=(0, train['FamilySize'].max()))\nfacet.add_legend()\nplt.xlim(0)","7005afe4":"family_mapping = {1: 0, 2: 0.4, 3: 0.8, 4: 1.2, 5: 1.6, 6: 2, 7: 2.4, 8: 2.8, 9: 3.2, 10: 3.6, 11: 4}\nfor dataset in train_test_data:\n    dataset['FamilySize'] = dataset['FamilySize'].map(family_mapping)","b933fe11":"train.head()","a8f61fdb":"train.head()","e1a565aa":"features_drop = ['Ticket', 'SibSp', 'Parch']\ntrain = train.drop(features_drop, axis=1)\ntest = test.drop(features_drop, axis=1)\ntrain = train.drop(['PassengerId'], axis=1)","23637876":"train_data = train.drop('Survived', axis=1)\ntarget = train['Survived']\n\ntrain_data.shape, target.shape","a5ceef58":"train_data.head(5)","60d657cf":"# Importing Classifier Modules\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.svm import SVC\n\nimport numpy as np","651d8e6a":"train.info()","c7cdab1e":"from sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nk_fold = KFold(n_splits=10, shuffle=True, random_state=0)","2049372c":"clf = KNeighborsClassifier(n_neighbors = 13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","65e0d2c1":"# kNN Score\nround(np.mean(score)*100, 2)","6c62d9f7":"clf = DecisionTreeClassifier()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","053e9840":"# decision tree Score\nround(np.mean(score)*100, 2)","0ea939a5":"clf = RandomForestClassifier(n_estimators=13)\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","d1e51cb7":"# Random Forest Score\nround(np.mean(score)*100, 2)","9fd552cc":"clf = GaussianNB()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","ad6adac8":"# Naive Bayes Score\nround(np.mean(score)*100, 2)","fc705232":"clf = SVC()\nscoring = 'accuracy'\nscore = cross_val_score(clf, train_data, target, cv=k_fold, n_jobs=1, scoring=scoring)\nprint(score)","3342a77b":"round(np.mean(score)*100,2)","bcd17926":"clf = SVC()\nclf.fit(train_data, target)\n\ntest_data = test.drop(\"PassengerId\", axis=1).copy()\nprediction = clf.predict(test_data)","87028174":"submission = pd.DataFrame({\n        \"PassengerId\": test[\"PassengerId\"],\n        \"Survived\": prediction\n    })\n\nsubmission.to_csv('submission.csv', index=False)","0e59ef4c":"submission = pd.read_csv('submission.csv')\nsubmission.head()","a66fe45d":"**Total rows and columns**\n\nWe can see that there are 891 rows and 12 columns in our training dataset.","c912cd26":"## 3. Exploratory data analysis\nPrinting first 5 rows of the train dataset.","78111b02":"The Chart confirms **a person aboarded from C** slightly more likely survived  \nThe Chart confirms **a person aboarded from Q** more likely dead  \nThe Chart confirms **a person aboarded from S** more likely dead","6e0efc42":"### 4.3 Age","d4cf3342":"# Titanic: Machine Learning from Disaster\n### Predict survival on the Titanic\n- Defining the problem statement\n- Collecting the data\n- Exploratory data analysis\n- Feature engineering\n- Modelling\n- Testing","95b4d1bb":"The Chart confirms **a person aboarded with more than 2 parents or children** more likely survived  \nThe Chart confirms ** a person aboarded alone** more likely dead","5f588a3c":"### 4.6 Cabin","8913efa1":"#### Title map\nMr : 0  \nMiss : 1  \nMrs: 2  \nOthers: 3\n","6f19de35":"### 4.2 Sex\n\nmale: 0\nfemale: 1","52b6356d":"## 7. Testing","2559405c":"## 2.Collecting the data\n\ntraining data set and testing data set are given by Kaggle(https:\/\/www.kaggle.com\/c\/titanic\/data)  \n\n### load train, test dataset using Pandas","1f64f9fc":"### 6.2.5 SVM","296a9b9f":"#### 4.3.1 some age is missing\nLet's use Title's median age for missing Age","ef7ab800":"### 6.2.4 Naive Bayes","49ade78b":"### 4.4 Embarked","2517df3e":"The Chart confirms **a person aboarded with more than 2 siblings or spouse** more likely survived  \nThe Chart confirms ** a person aboarded without siblings or spouse** more likely dead","e2d73463":"### 6.2.2 Decision Tree","0e551a59":"### 4.7 FamilySize","39685f12":"The Chart confirms **Women** more likely survivied than **Men**","e8874743":"## 1.Defining the problem statement\nComplete the analysis of what sorts of people were likely to survive.  \nIn particular, we ask you to apply the tools of machine learning to predict which passengers survived the Titanic tragedy.","bb09cbf3":"We can see that *Age* value is missing for many rows. \n\nOut of 891 rows, the *Age* value is present only in 714 rows.\n\nSimilarly, *Cabin* values are also missing in many rows. Only 204 out of 891 rows have *Cabin* values.","72354cda":"### 6.2.1 kNN","9ce86113":"#### 4.4.1 filling missing values","ea90f7c3":"### Data Dictionary\n- Survived: \t0 = No, 1 = Yes  \n- pclass: \tTicket class\t1 = 1st, 2 = 2nd, 3 = 3rd  \t\n- sibsp:\t# of siblings \/ spouses aboard the Titanic  \t\n- parch:\t# of parents \/ children aboard the Titanic  \t\n- ticket:\tTicket number\t\n- cabin:\tCabin number\t\n- embarked:\tPort of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton  ","8dd612aa":"### Bar Chart for Categorical Features\n- Pclass\n- Sex\n- SibSp ( # of siblings and spouse)\n- Parch ( # of parents and children)\n- Embarked\n- Cabin","a581d831":"### import python lib for visualization","74c831ee":"### 4.5 Fare","210e3683":"## 4. Feature engineering\n\nFeature engineering is the process of using domain knowledge of the data  \nto create features (**feature vectors**) that make machine learning algorithms work.  \n\nfeature vector is an n-dimensional vector of numerical features that represent some object.  \nMany algorithms in machine learning require a numerical representation of objects,  \nsince such representations facilitate processing and statistical analysis.","49ae9baa":"more than 50% of 1st class are from S embark  \nmore than 50% of 2nd class are from S embark  \nmore than 50% of 3rd class are from S embark\n\n**fill out missing embark with S embark**","58160eb5":"## 5. Modelling","37703f04":"### 6.2.3 Ramdom Forest","f8ccaeab":"### 6.2 Cross Validation (K-fold)","070839af":"There are 177 rows with missing *Age*, 687 rows with missing *Cabin* and 2 rows with missing *Embarked* information.","6f821617":"#### 4.3.2 Binning\nBinning\/Converting Numerical Age to Categorical Variable  \n\nfeature vector map:  \nchild: 0  \nyoung: 1  \nadult: 2  \nmid-age: 3  \nsenior: 4","51f8c5e7":"The Chart confirms **1st class** more likely survivied than **other classes**  \nThe Chart confirms **3rd class** more likely dead than **other classes**","2ec24839":"### 4.1 Name"}}