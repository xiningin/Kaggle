{"cell_type":{"d833d0f7":"code","61e8abd4":"code","eb982dc8":"code","cb93d9c6":"code","063daf9e":"code","5c158c35":"code","221c6a34":"code","c3d8ba82":"code","91118dc0":"code","95beea7c":"code","f6534b9e":"code","137051ca":"code","d2dce319":"code","e6a2cfcd":"code","c75b7c35":"code","f70d7550":"code","cd3fc71f":"code","d4d2fe61":"code","7fdbcf97":"code","466b10b6":"code","babf3aa9":"code","0a0de1ea":"code","63d244ae":"markdown","f563f7b6":"markdown","2b9e29d0":"markdown","173372e2":"markdown","9d49f9c4":"markdown","9920b79b":"markdown","865e26f5":"markdown","86eee13b":"markdown","83cfa826":"markdown","cbd210ce":"markdown"},"source":{"d833d0f7":"%load_ext autoreload\n%autoreload 2\n\n%matplotlib inline","61e8abd4":"!pip install pyreadr==v0.3.3\n\nimport pyreadr\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","eb982dc8":"%%time\n\n# troque aqui pela localiza\u00e7\u00e3o do dataset na sua m\u00e1quina\nPATH = '\/kaggle\/input\/tennessee-eastman-process-simulation-dataset\/'\n\ntrain_normal_path = PATH+'TEP_FaultFree_Training.RData'\ntrain_faulty_path = PATH+'TEP_Faulty_Training.RData'\n\ntest_normal_path = PATH+'TEP_FaultFree_Testing.RData'\ntest_faulty_path = PATH+'TEP_Faulty_Testing.RData'\n\ntrain_normal_complete = pyreadr.read_r(train_normal_path)['fault_free_training']\n\ntest_faulty_complete = pyreadr.read_r(test_faulty_path)['faulty_testing']","cb93d9c6":"class PCA():\n   \n    ###############\n\n    def __init__ (self, a = 0.9):\n        '''\n        Construtor: fun\u00e7\u00e3o chamada toda vez que um objeto PCA \u00e9 inicializado\n        '''\n        # se 0<=a<1,  'a' indica a fra\u00e7ao de variancia explicada desejada\n        # se a>=1,    'a' indica o numero de componentes desejado\n        self.a = a\n   \n    ###############\n\n    def fit(self, X, conf_Q = 0.99, conf_T2 = 0.99, plot = True):\n        '''\n        Fun\u00e7\u00e3o para treino do modelo\n        '''       \n        # guardando m\u00e9dias e desvios-padr\u00e3o do treino\n        self.mu_train = X.mean(axis=0)\n        self.std_train = X.std(axis=0)        \n       \n        # normalizando dados de treino\n        X = np.array(((X - self.mu_train)\/self.std_train))\n        \n        # calculando a matriz de covari\u00e2ncias dos dados\n        Cx = np.cov(X, rowvar=False)\n        \n        # aplicando decomposi\u00e7\u00e3o em autovalores e autovetores\n        self.L, self.P = np.linalg.eig(Cx)\n        \n        # fra\u00e7\u00f5es da vari\u00e2ncia explicada\n        fv = self.L\/np.sum(self.L)\n        \n        # fra\u00e7\u00f5es da vari\u00e2ncia explicada acumuladas\n        fva = np.cumsum(self.L)\/sum(self.L)\n       \n        # definindo n\u00famero de componentes\n        if self.a>0 and self.a<1:\n            self.a = np.where(fva>self.a)[0][0]+1 \n            \n        # calculando limites de detec\u00e7\u00e3o\n\n        # limite da estat\u00edstica T^2\n        from scipy.stats import f\n        F = f.ppf(conf_T2, self.a, X.shape[0]-self.a)\n        self.T2_lim = ((self.a*(X.shape[0]**2-1))\/(X.shape[0]*(X.shape[0]-self.a)))*F\n        \n        # limite da estat\u00edstica Q\n        theta = [np.sum(self.L[self.a:]**(i)) for i in (1,2,3)]\n        ho = 1-((2*theta[0]*theta[2])\/(3*(theta[1]**2)))\n        from scipy.stats import norm\n        nalpha = norm.ppf(conf_Q)\n        self.Q_lim = (theta[0]*(((nalpha*np.sqrt(2*theta[1]*ho**2))\/theta[0])+1+\n                                ((theta[1]*ho*(ho-1))\/theta[0]**2))**(1\/ho))\n        \n        # calculando T2 e Q para dados de treino\n        \n        # calculando estat\u00edstica T^2\n        T = X@self.P[:,:self.a]\n        self.T2_train = np.array([T[i,:]@np.linalg.inv(np.diag(self.L[:self.a]))@T[i,:].T for i in range(X.shape[0])])\n\n        # calculando estat\u00edstica Q\n        e = X - X@self.P[:,:self.a]@self.P[:,:self.a].T\n        self.Q_train  = np.array([e[i,:]@e[i,:].T for i in range(X.shape[0])])\n        \n        \n        # plotando vari\u00e2ncias explicadas\n        if plot:\n            fig, ax = plt.subplots()\n            ax.bar(np.arange(len(fv)),fv)\n            ax.plot(np.arange(len(fv)),fva)\n            ax.set_xlabel('N\u00famero de componentes')\n            ax.set_ylabel('Vari\u00e2ncia dos dados')\n            ax.set_title('PCA - Vari\u00e2ncia Explicada');\n            \n        ###############\n\n    def plot_train_control_charts(self, fault = None):\n        '''\n        Fun\u00e7\u00e3o para plotar cartas de controle\n        '''        \n        fig, ax = plt.subplots(1,2, figsize=(15,3))\n\n        ax[0].semilogy(self.T2_train,'.')\n        ax[0].axhline(self.T2_lim,ls='--',c='r');\n        ax[0].set_title('Carta de Controle $T^2$')\n        \n        ax[1].semilogy(self.Q_train,'.')\n        ax[1].axhline(self.Q_lim,ls='--',c='r')\n        ax[1].set_title('Carta de Controle Q')\n \n        if fault is not None:\n            ax[0].axvline(fault, c='k')\n            ax[1].axvline(fault, c='k')\n    \n    ###############\n            \n    def predict(self, X):\n        '''\n        Fun\u00e7\u00e3o para teste do modelo\n        '''\n            \n        # normalizando dados de teste (usando os par\u00e2metros do treino!)\n        X = np.array((X - self.mu_train)\/self.std_train)\n\n        # calculando estat\u00edstica T^2\n        T = X@self.P[:,:self.a]\n        self.T2 = np.array([T[i,:]@np.linalg.inv(np.diag(self.L[:self.a]))@T[i,:].T for i in range(X.shape[0])])\n\n        # calculando estat\u00edstica Q\n        e = X - X@self.P[:,:self.a]@self.P[:,:self.a].T\n        self.Q  = np.array([e[i,:]@e[i,:].T for i in range(X.shape[0])])\n        \n        # calculando contribui\u00e7\u00f5es para Q\n        self.c = np.absolute(X*e) \n                \n    ###############\n\n    def plot_control_charts(self, fault = None):\n        '''\n        Fun\u00e7\u00e3o para plotar cartas de controle\n        '''        \n        fig, ax = plt.subplots(1,2, figsize=(15,3))\n\n        ax[0].semilogy(self.T2,'.')\n        ax[0].axhline(self.T2_lim,ls='--',c='r');\n        ax[0].set_title('Carta de Controle $T^2$')\n        \n        ax[1].semilogy(self.Q,'.')\n        ax[1].axhline(self.Q_lim,ls='--',c='r')\n        ax[1].set_title('Carta de Controle Q')\n \n        if fault is not None:\n            ax[0].axvline(fault, c='k')\n            ax[1].axvline(fault, c='k')\n\n    ###############\n            \n    def plot_contributions(self, fault = None, \n                           index = None, \n                           columns = None):\n        '''\n        Fun\u00e7\u00e3o para plotar mapas de contribui\u00e7\u00e3o\n        '''\n        fig, ax = plt.subplots(figsize=(20, 6))\n        \n        c = pd.DataFrame(self.c, \n                         index = index,\n                         columns = columns)\n    \n        sns.heatmap(c, ax = ax, \n                    yticklabels=int(self.c.shape[0]\/10),\n                    cmap = plt.cm.Blues);\n        \n        ax.set_title('Contribui\u00e7\u00f5es parciais para Q')\n        \n        if fault is not None:\n            ax.axhline(y=c.index[fault],\n                       ls='--', c='k')","063daf9e":"df_train = train_normal_complete[(train_normal_complete.simulationRun>=1)&\n                                 (train_normal_complete.simulationRun<5)].iloc[:,3:]\n\ndf_test = train_normal_complete[(train_normal_complete.simulationRun>5)&\n                                (train_normal_complete.simulationRun<10)].iloc[:,3:]","5c158c35":"pca = PCA(a = 0.9)\npca.fit(df_train)","221c6a34":"pca.plot_train_control_charts()","c3d8ba82":"print('Taxa de falsos alarmes no treino\\n--------------')\n\nprint(f'T2: {(pca.T2_train>pca.T2_lim).sum()\/pca.T2_train.shape[0]}')\nprint(f'Q: {(pca.Q_train>pca.Q_lim).sum()\/pca.Q_train.shape[0]}')","91118dc0":"pca.predict(df_test)","95beea7c":"pca.plot_control_charts()\nplt.suptitle('IDV(0)');","f6534b9e":"print('Taxa de falsos alarmes\\n--------------')\n\nprint(f'T2: {(pca.T2>pca.T2_lim).sum()\/pca.T2.shape[0]}')\nprint(f'Q: {(pca.Q>pca.Q_lim).sum()\/pca.Q.shape[0]}')","137051ca":"df_train = train_normal_complete[(train_normal_complete.simulationRun<=10)].iloc[:,3:]","d2dce319":"pca = PCA()\npca.fit(df_train)","e6a2cfcd":"def apply_lag(df, lag=1):\n       \n    from statsmodels.tsa.tsatools import lagmat\n    array_lagged = lagmat(df, maxlag=lag,\n                          trim=\"forward\", original='in')[lag:,:]  \n    new_columns = []\n    for l in range(lag):\n        new_columns.append(df.columns+'_lag'+str(l+1))\n    columns_lagged = df.columns.append(new_columns)\n    index_lagged = df.index[lag:]\n    df_lagged = pd.DataFrame(array_lagged, index=index_lagged,\n                             columns=columns_lagged)\n       \n    return df_lagged \n\ndef filter_noise_ma(df, W=5):\n    \n    import copy\n    \n    new_df = copy.deepcopy(df)\n    \n    for column in df:\n        new_df[column] = new_df[column].rolling(W).mean()\n        \n    return new_df.drop(df.index[:W])\n\ndef t2_q(pca, fault_number=1, simulation=1, filter_noise=False, W_noise=5, lag=False, lag_columns=1):\n    \n    df_test = test_faulty_complete[(test_faulty_complete.faultNumber==fault_number) & \n                               (test_faulty_complete.simulationRun==simulation)].iloc[:,3:]\n    \n    if filter_noise:\n        df_test = filter_noise_ma(df_test, W=W_noise)\n        \n    if lag:\n        df_test = apply_lag(df_test, lag_columns)\n    \n    pca.predict(df_test)\n    \n    return {'T2': (pca.T2[160:]>pca.T2_lim).sum()\/pca.T2[160:].shape[0],\n            'Q': (pca.Q[160:]>pca.Q_lim).sum()\/pca.Q[160:].shape[0]}","c75b7c35":"idv_dict = dict()\n\nfor i in range(1, 21):\n    idv_dict[f'IDV({i})'] = t2_q(pca, fault_number=i, simulation=1)\n    pca.plot_control_charts(fault=160)\n    plt.suptitle(f'IDV({i})');\n    plt.show()\n    pca.plot_contributions(fault=160, columns = df_test.columns)\n    plt.show()\n    \nidv_df = pd.DataFrame(idv_dict).T","f70d7550":"idv_df[(idv_df.T2 < 0.5) | (idv_df.Q < 0.5)]","cd3fc71f":"pca = PCA()\npca.fit(filter_noise_ma(df_train))","d4d2fe61":"idv_dict = dict()\n\nfor i in range(1, 21):\n    idv_dict[f'IDV({i})'] = t2_q(pca, fault_number=i, simulation=1, filter_noise=True)\n    pca.plot_control_charts(fault=160)\n    plt.suptitle(f'IDV({i})');\n    plt.show()\n    pca.plot_contributions(fault=160, columns = df_test.columns)\n    plt.show()\n    \nidv_df = pd.DataFrame(idv_dict).T","7fdbcf97":"idv_df[(idv_df.T2 < 0.5) | (idv_df.Q < 0.5)]","466b10b6":"pca = PCA()\npca.fit(apply_lag(df_train))","babf3aa9":"idv_dict = dict()\n\nfor i in range(1, 21):\n    idv_dict[f'IDV({i})'] = t2_q(pca, fault_number=i, simulation=1, lag=True)\n    pca.plot_control_charts(fault=160)\n    plt.suptitle(f'IDV({i})');\n    plt.show()\n    pca.plot_contributions(fault=160, columns = apply_lag(df_train).columns)\n    plt.show()\n    \nidv_df = pd.DataFrame(idv_dict).T","0a0de1ea":"idv_df[(idv_df.T2 < 0.5) | (idv_df.Q < 0.5)]","63d244ae":"### Melhorou a detec\u00e7\u00e3o de falhas com as colunas de lag\n\nIDV(11) - Temperatura da \u00e1gua de resfriamento do condensador (pertuba\u00e7\u00e3o aleat\u00f3ria) \n\n\nO restante dos erros n\u00e3o tiveram altera\u00e7\u00e3o significativa","f563f7b6":"IDV(3) - Temperatura de alimenta\u00e7\u00e3o de D na corrente 2 (pertuba\u00e7\u00e3o do tipo degrau)  \nIDV(4) - Temperatura de \u00e1gua de resfriamento do reator (pertuba\u00e7\u00e3o do tipo degrau). O T2 n\u00e3o apresenta bem a falha, mas o Q consegue encontrar com muita precis\u00e3o, poss\u00edvelmente porque as altera\u00e7\u00f5es n\u00e3o est\u00e1 dentre as de maior vari\u00e2ncia no treino  \nIDV(5) - Temperatura da \u00e1gua de resfriamento do condensador (pertuba\u00e7\u00e3o do tpo degrau). Apresenta a detec\u00e7\u00e3o da falha logo no in\u00edcio, mas provavelmente devido aos controladores ele retorna ao estado estacion\u00e1rio desejado  \nIDV(9) - Temperatura de alimenta\u00e7\u00e3o de D na corrente 2 (pertuba\u00e7\u00e3o aleat\u00f3ria)  \nIDV(10) - Temperatura de alimenta\u00e7\u00e3o de C na corrente 5 (partuba\u00e7\u00e3o aleat\u00f3ria)  \nIDV(11) - Temperatura da \u00e1gua de resfriamento do condensador (pertuba\u00e7\u00e3o aleat\u00f3ria)    \nIDV(15) - V\u00e1lvula de \u00e1gua para resfriamento do condensador emperrando  \nIDV(16) - ?  \nIDV(19) - ?  \nIDV(20) - ?, apresenta uma natureza oscilat\u00f3ria na percep\u00e7\u00e3o da falha. As vari\u00e1veis que est\u00e3o apresentando maior contribui\u00e7\u00e3o s\u00e3o devido ao compressor, provavelmente a falha est\u00e1 no equipamento ou nos perif\u00e9ricos dele.","2b9e29d0":"## Quest\u00e3o 1\n\nModifique a classe PCA de modo a fazer com que ela calcule as estat\u00edsticas \ud835\udc472 e \ud835\udc44 tamb\u00e9m correspondentes \u00e0 etapa de treino. Plote as cartas de controle correspondentes. Voc\u00ea consegue pensar em alguma utilidade para esse c\u00e1lculo\/visualiza\u00e7\u00e3o?","173372e2":"### Adi\u00e7\u00e3o de vari\u00e1veis atrasadas no tempo","9d49f9c4":"### Filtro de ru\u00eddo","9920b79b":"## Quest\u00e3o 2\n\nAnalise todos os demais cen\u00e1rios de falha, gerando as respectivas cartas de controle e taxas de detec\u00e7\u00e3o para ambas as estat\u00edsticas e o mapa de contribui\u00e7\u00e3o para a estat\u00edstica \ud835\udc44. Identifique quais falhas s\u00e3o mais dif\u00edceis de detectar e em quais delas o desempenho melhora com o uso das t\u00e9cnicas de pr\u00e9-processamento. Dica: como s\u00e3o muitos cen\u00e1rios de falha e os procedimentos s\u00e3o os mesmos para todos eles, recomendo que a an\u00e1lise seja automatizada com la\u00e7os for, por exemplo.","865e26f5":"### Importa\u00e7\u00e3o dos dados","86eee13b":"Plotar os gr\u00e1ficos de controle para dados de treino, assim como as estat\u00edsticas T2 e Q, pode ser utilizado para avaliar o n\u00famero de falsos positivos esperados pelo modelo. Assim como as oscila\u00e7\u00f5es normais de opera\u00e7\u00e3o.","83cfa826":"### Falhas que n\u00e3o foram bem detectadas","cbd210ce":"### Melhorou a detec\u00e7\u00e3o de falhas o filtro de ru\u00eddo\n\nIDV(4) - Temperatura de \u00e1gua de resfriamento do reator (pertuba\u00e7\u00e3o do tipo degrau). Ap\u00f3s o filtro de ru\u00eddo o T2 passou a localizar tamb\u00e9m a falha  \nIDV(11) - Temperatura da \u00e1gua de resfriamento do condensador (pertuba\u00e7\u00e3o aleat\u00f3ria)  \n\n### Piorou a detec\u00e7\u00e3o de falhas.\n\nIDV(14) - apresentou um erro maior no T2. Esse erro est\u00e1 relacionado a v\u00e1lvula de \u00e1gua do reator emperrando, poss\u00edvelmente n\u00e3o foi capaz de localizar o erro pois fazer a m\u00e9dia diminuiu o efeito oscilat\u00f3rio.\n\n### Apresenta ainda baixa detec\u00e7\u00e3o de falha\n\nAs \u00fanicas falhas que n\u00e3o apresentaram falhas preditas satisfatoriamente (minimo 0.9) em uma das duas cartas s\u00e3o:\nIDV(3) - Temperatura de alimenta\u00e7\u00e3o de D na corrente 2 (pertuba\u00e7\u00e3o do tipo degrau)  \nIDV(9) - Temperatura de alimenta\u00e7\u00e3o de D na corrente 2 (pertuba\u00e7\u00e3o aleat\u00f3ria)  \nIDV(15) - V\u00e1lvula de \u00e1gua para resfriamento do condensador emperrando  \nIDV(16) - ?  \nIDV(20) - ?  "}}