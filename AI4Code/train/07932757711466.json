{"cell_type":{"74451bd0":"code","482c2e47":"code","b33aee71":"code","d643bbe6":"code","07d0a4bc":"code","a998d28b":"code","67bbc7ac":"code","a2ec737c":"code","30029e8c":"code","66126e3f":"code","97c6baa8":"code","ea9fc4ce":"code","780a1005":"code","b45cd800":"code","ba8cf39d":"code","9ff9b06d":"code","04ad3ef0":"code","ff97cf06":"code","63eb4642":"code","61765563":"code","cee90ee6":"code","bc4fe42c":"code","d0a93352":"code","60c98ae4":"code","0a064bc2":"code","85a7fdf4":"code","7dcbb6b3":"code","5a96c436":"code","b97ef821":"code","007e2a7b":"markdown","025f6b09":"markdown","666f15a7":"markdown","f53c04e3":"markdown","d167a863":"markdown","ab8b29f4":"markdown","3f70c10a":"markdown","5cd75611":"markdown","58529423":"markdown","b705fcb1":"markdown"},"source":{"74451bd0":"# Importing packages\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ncols = ['CASE_STATUS','EMPLOYMENT_START_DATE','EMPLOYER_NAME',\n        'EMPLOYER_STATE','JOB_TITLE','SOC_NAME','PREVAILING_WAGE','PW_UNIT_OF_PAY']\n\n# Importing the Dataset\ndf18 = pd.read_csv('..\/input\/h1b18.csv', usecols = cols)\ndf17 = pd.read_csv('..\/input\/h1b17.csv', usecols = cols)\ndf16 = pd.read_csv('..\/input\/h1b16.csv')","482c2e47":"# Removing columns that are not necessary from data of df18 and df17\ndf17 = df17[['CASE_STATUS','EMPLOYMENT_START_DATE','EMPLOYER_NAME',\n        'EMPLOYER_STATE','JOB_TITLE','SOC_NAME','PREVAILING_WAGE','PW_UNIT_OF_PAY']]\n\ndf18 = df18[['CASE_STATUS','EMPLOYMENT_START_DATE','EMPLOYER_NAME',\n        'EMPLOYER_STATE','JOB_TITLE','SOC_NAME','PREVAILING_WAGE','PW_UNIT_OF_PAY']]\n\n# Changing the EMPLOYMENT_START_DATE into a year to comply with 2016 data\ndf18['EMPLOYMENT_START_DATE'] = pd.to_datetime(df18['EMPLOYMENT_START_DATE'], format = '%m\/%d\/%y')\ndf18['EMPLOYMENT_START_DATE'] = df18['EMPLOYMENT_START_DATE'].apply(lambda x: x.year)\n\ndf17['EMPLOYMENT_START_DATE'] = pd.to_datetime(df17['EMPLOYMENT_START_DATE'], format = '%Y-%m-%d')\ndf17['EMPLOYMENT_START_DATE'] = df17['EMPLOYMENT_START_DATE'].apply(lambda x: x.year)","b33aee71":"# Only take years 2017 from df17 and years 2018 from df18\ndf17 = df17.loc[df17['EMPLOYMENT_START_DATE'] == 2017, :]\ndf18 = df18.loc[df18['EMPLOYMENT_START_DATE'] == 2018, :]","d643bbe6":"# Change PREVAILING WAGE into yearly wages (Split into Year, Week, Month, Hourly, Bi-weekly)\ndf18['PREVAILING_WAGE'] = df18['PREVAILING_WAGE'].apply(lambda x: str(x).replace(',',''))\ndf18.loc[df18.PREVAILING_WAGE == 0, 'PREVAILING_WAGE'] = np.nan\ndf18.loc[df18.PW_UNIT_OF_PAY == 'Hour', 'PREVAILING_WAGE'] = df18.loc[df18.PW_UNIT_OF_PAY == 'Hour', 'PREVAILING_WAGE'].apply(lambda x:float(x)*1638)\ndf18.loc[df18.PW_UNIT_OF_PAY == 'Week', 'PREVAILING_WAGE'] = df18.loc[df18.PW_UNIT_OF_PAY == 'Week', 'PREVAILING_WAGE'].apply(lambda x:float(x)*52)\ndf18.loc[df18.PW_UNIT_OF_PAY == 'Bi-Weekly', 'PREVAILING_WAGE'] = df18.loc[df18.PW_UNIT_OF_PAY == 'Bi-Weekly', 'PREVAILING_WAGE'].apply(lambda x:float(x)*26)\ndf18.loc[df18.PW_UNIT_OF_PAY == 'Month', 'PREVAILING_WAGE'] = df18.loc[df18.PW_UNIT_OF_PAY == 'Month', 'PREVAILING_WAGE'].apply(lambda x:float(x)*12)\n","07d0a4bc":"df17['PREVAILING_WAGE'] = df17['PREVAILING_WAGE'].apply(lambda x: str(x).replace(',',''))\ndf17.loc[df17.PREVAILING_WAGE == 0, 'PREVAILING_WAGE'] = np.nan\ndf17.loc[df17.PW_UNIT_OF_PAY == 'Hour', 'PREVAILING_WAGE'] = df17.loc[df17.PW_UNIT_OF_PAY == 'Hour', 'PREVAILING_WAGE'].apply(lambda x:float(x)*1638)\ndf17.loc[df17.PW_UNIT_OF_PAY == 'Week', 'PREVAILING_WAGE'] = df17.loc[df17.PW_UNIT_OF_PAY == 'Week', 'PREVAILING_WAGE'].apply(lambda x:float(x)*52)\ndf17.loc[df17.PW_UNIT_OF_PAY == 'Bi-Weekly', 'PREVAILING_WAGE'] = df17.loc[df17.PW_UNIT_OF_PAY == 'Bi-Weekly', 'PREVAILING_WAGE'].apply(lambda x:float(x)*26)\ndf17.loc[df17.PW_UNIT_OF_PAY == 'Month', 'PREVAILING_WAGE'] = df17.loc[df17.PW_UNIT_OF_PAY == 'Month', 'PREVAILING_WAGE'].apply(lambda x:float(x)*12)\n","a998d28b":"# Remove PW_UNIT_OF_PAY \ndf17 = df17[['CASE_STATUS','EMPLOYMENT_START_DATE','EMPLOYER_NAME',\n        'EMPLOYER_STATE','JOB_TITLE','SOC_NAME','PREVAILING_WAGE']]\n\ndf18 = df18[['CASE_STATUS','EMPLOYMENT_START_DATE','EMPLOYER_NAME',\n        'EMPLOYER_STATE','JOB_TITLE','SOC_NAME','PREVAILING_WAGE']]","67bbc7ac":"# Dictionary of all States and Shortened State\nstates = {\"AL\":\"Alabama\",\"AK\":\"Alaska\",\"AZ\":\"Arizona\",\"AR\":\"Arkansas\",\"CA\":\"California\",\"CO\":\"Colorado\",\n          \"CT\":\"Connecticut\",\"DE\":\"Delaware\",\"FL\":\"Florida\",\"GA\":\"Georgia\",\"HI\":\"Hawaii\",\"ID\":\"Idaho\",\n          \"IL\":\"Illinois\",\"IN\":\"Indiana\",\"IA\":\"Iowa\",\"KS\":\"Kansas\",\"KY\":\"Kentucky\",\"LA\":\"Louisiana\",\n          \"ME\":\"Maine\",\"MD\":\"Maryland\",\"MA\":\"Massachusetts\",\"MI\":\"Michigan\",\"MN\":\"Minnesota\",\"MS\":\"Mississippi\",\n          \"MO\":\"Missouri\",\"MT\":\"Montana\",\"NE\":\"Nebraska\",\"NV\":\"Nevada\",\"NH\":\"New Hampshire\",\"NJ\":\"New Jersey\",\n          \"NM\":\"New Mexico\",\"NY\":\"New York\",\"NC\":\"North Carolina\",\"ND\":\"North Dakota\",\"OH\":\"Ohio\",\"OK\":\"Oklahoma\",\n          \"OR\":\"Oregon\",\"PA\":\"Pennsylvania\",\"RI\":\"Rhode Island\",\"SC\":\"South Carolina\",\"SD\":\"South Dakota\",\n          \"TN\":\"Tennessee\",\"TX\":\"Texas\",\"UT\":\"Utah\",\"VT\":\"Vermont\",\"VA\":\"Virginia\",\"WA\":\"Washington\",\n          \"WV\":\"West Virginia\",\"WI\":\"Wisconsin\",\"WY\":\"Wyoming\"}\nstates = dict((v.upper(), k.upper()) for k, v in states.items())\n\n# Remove the city from the WORKSITE \ndf16['WORKSITE'] = df16['WORKSITE'].apply(lambda x: x.split(',')[1])\n# Removing the space infront of the states from WORKSITE\ndf16['WORKSITE'] = df16['WORKSITE'].apply(lambda x: x[1:])\n# Replace Worksite with shortened States\ndf16['WORKSITE'].replace(states, inplace = True)\n# Replace WORKSITE with EMPLOYER_STATE\ndf16.rename(columns={'YEAR':'EMPLOYMENT_START_DATE','WORKSITE':'EMPLOYER_STATE'}, inplace=True)\n\n\n# Removing unnecessary columns of df16\ndf16 = df16[['CASE_STATUS','EMPLOYMENT_START_DATE','EMPLOYER_NAME',\n        'EMPLOYER_STATE','JOB_TITLE','SOC_NAME','PREVAILING_WAGE']]","a2ec737c":"# Combining df16, df17, df18 into one dataframe\ndf = pd.concat([df16,df17,df18])\nprint(df.head())","30029e8c":"# Cleaning the SOC_NAME \ndf['SOC_NAME'] = df['SOC_NAME'].apply(lambda x: str(x).upper())\ndf['SOC_NAME'] = df['SOC_NAME'].apply(lambda x:str(x).replace('COMPUTER SYSTEMS ANALYSTS','COMPUTER SYSTEMS ANALYST'))\n","66126e3f":"# Looking at the number of applications per year \nyear_app = df['EMPLOYMENT_START_DATE'].value_counts()\nprint(year_app)","97c6baa8":"# Bar Chart of the number of applications\nyear_app = year_app.sort_index()\nobama = pd.Series(year_app.values[0:6], index = year_app.index[0:6])\ntrump = pd.Series(year_app.values[6:], index = year_app.index[6:])\n\nfig, ax = plt.subplots()\nplt.bar(obama.index, obama.values, align = 'center', alpha = 0.7,  linewidth=0)\nplt.bar(trump.index, trump.values, align = 'center', alpha = 0.7,  linewidth=0, color = '#FF0000')\nplt.legend(['Obama\\'s Presidency','Trump\\'s Presidency'],loc=2)\nplt.title('The Number of Applications from 2011 to 2018')\nplt.savefig('no of applications.png')","ea9fc4ce":"# Heatmap of U.S. H1B visa applicants\n# Import statements \nfrom plotly.offline import download_plotlyjs, init_notebook_mode, plot, iplot\ninit_notebook_mode(connected=True)\nimport plotly as plotly\nimport plotly.plotly as py\nimport plotly.graph_objs as go\nimport plotly.io as pio\n\n# Organizing by state \ndf_heatmap = df.groupby('EMPLOYER_STATE')['CASE_STATUS'].count()\n\nscl = [\n    [0.0, 'rgb(242,240,247)'],\n    [0.2, 'rgb(218,218,235)'],\n    [0.4, 'rgb(188,189,220)'],\n    [0.6, 'rgb(158,154,200)'],\n    [0.8, 'rgb(117,107,177)'],\n    [1.0, 'rgb(84,39,143)']\n]\n\ndata = [go.Choropleth(\n    colorscale = scl,\n    autocolorscale = False,\n    locations = df_heatmap.index,\n    z = df_heatmap.values.astype(float),\n    locationmode = 'USA-states',\n    marker = go.choropleth.Marker(\n        line = go.choropleth.marker.Line(\n            color = 'rgb(255,255,255)',\n            width = 2\n        )),\n    colorbar = go.choropleth.ColorBar(\n        title = \"\")\n)]\n\nlayout = go.Layout(\n    title = go.layout.Title(\n        text = 'H1B Visa Applicants'\n    ),\n    geo = go.layout.Geo(\n        scope = 'usa',\n        projection = go.layout.geo.Projection(type = 'albers usa'),\n        showlakes = True,\n        lakecolor = 'rgb(255, 255, 255)'),\n)\n\nfig = go.Figure(data = data, layout = layout)\nplotly.tools.set_credentials_file(username='jpar746', api_key='z4DayxsEIqnFEGvEUhPO')\nplotly.offline.iplot(fig, filename = 'd3-cloropleth-map')","780a1005":"# Comparing the number of applications that are accepted or denied (Ignore withdrawn)\naccept_arr = df['CASE_STATUS'].value_counts()\nprint(accept_arr)\naccept_val = list(accept_arr)[0:4]\naccept_label = list(accept_arr.index)[0:4]\n\n# Out of all the applications we can see that only a small percentage are denied (Exactly 2.67%)\ndenied = (accept_arr['DENIED'] \/ df.shape[0]).round(4)\nprint(str(denied*100) + '%')","b45cd800":"# Pie chart of accepted and denied applications \nfig, ax = plt.subplots()\nax.pie(accept_val, explode = (0,0,0,0.25), labels = accept_label, autopct = '%1.1f%%',\n       pctdistance=1.2, labeldistance=1.4, wedgeprops={'alpha':0.7})\nax.axis('equal')\nplt.title('Case Status')\nplt.show()","ba8cf39d":"# Looking at the percentage denied over the years \naccept_per = df.groupby('EMPLOYMENT_START_DATE')['CASE_STATUS'].value_counts()\nyear_per = []\nyear = []\nfor i in range(2011,2019):\n    year_per.append((accept_per.loc[[i,'DENIED'],'DENIED'].values[0] \/ accept_per.loc[[i]].sum())*100)\n    year.append(i)\ndenied_per = pd.Series(year_per, index = year)\nprint(denied_per)","9ff9b06d":"# Scatter plot to look at the increase and decrease in denied applications\nplt.plot(denied_per.index, denied_per.values, 'bo', linestyle='dashed')\nplt.title('Percentage of Denied Applicants')\nplt.xlabel('Year')\nplt.ylabel('% of Denied Applicants')\nplt.show()","04ad3ef0":"uscis = pd.Series([95.7,93.9,92.6,84.5], index=[2015,2016,2017,2018])\nfig, ax = plt.subplots()\nbars = plt.bar(uscis.index, uscis.values, align = 'center', alpha = 0.7)\nplt.xticks([2015,2016,2017,2018])\n# Removing the frame\nfor spine in plt.gca().spines.values():\n    spine.set_visible(False)\n# Removing the small ticks \nax.tick_params(axis=u'both', which=u'both',length=0)\n# Removing Y ticks \nax.set_yticklabels([])\n# Placing the values above the bar \nfor rect in bars:\n        height = rect.get_height()\n        ax.text(rect.get_x() + rect.get_width()\/2., 0.9*height, str(height)+'%',\n                ha='center', va='bottom', color = 'w')\nbars[2].set_color('#FF0000')\nbars[3].set_color('#FF0000')\nplt.title('Percentages of H-1B Accepted')\nplt.savefig('perc of applications.png')\nplt.show()","ff97cf06":"# Looking at 20 companies that provide the most H1B visas\ncommon_co = df['EMPLOYER_NAME'].value_counts()\nprint(common_co[:20])","63eb4642":"# Bar Chart of companies that provide the most H1B visas\ncommon_co_name = list(common_co[0:10].index)\ncommon_co_freq = list(common_co[0:10])\n\ny_pos = np.arange(len(common_co_name))\n\n# Plotting a horizontal bar chart\nfig, ax = plt.subplots()\nbars = plt.barh(y_pos, common_co_freq, align = 'center', alpha = 0.7)\n\n# Labeling the bar chart\nplt.yticks(y_pos, common_co_name)\n\n# Removing the frame for a cleaner visual\nfor spine in plt.gca().spines.values():\n    spine.set_visible(False)\n    \n# Removing the small y ticks\nax.tick_params(axis=u'both', which=u'both',length=0)\n\n# Directly labeling the values of the bar chart \ni = 0\nfor bar in bars:\n    plt.gca().text(bar.get_x() + bar.get_width()-21000, i-0.15, str(int(bar.get_width())), \n                 ha='left', color='w', fontsize=11)\n    i = i+1\n    \n# Removing the x-ticks\nplt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n\n# Setting the title \nplt.title('Companies that provide the most H1B Visas')\nplt.savefig('co of applications.png', bbox_inches='tight')","61765563":"# Number of H-1B Visa Applicants hired by each company in 2015\ndf15 = df[df['EMPLOYMENT_START_DATE']==2015]\nhire15 = df15['EMPLOYER_NAME'].value_counts()\nprint(hire15[0:20])","cee90ee6":"# Bar Chart of companies that provide the most H1B visas in 2015\nhire15_name = list(hire15[0:10].index)\nhire15_freq = list(hire15[0:10])\n\ny_pos = np.arange(len(hire15_name))\n\n# Plotting a horizontal bar chart\nfig, ax = plt.subplots()\nbars = plt.barh(y_pos, hire15_freq, align = 'center', alpha = 0.7)\n\n# Labeling the bar chart\nplt.yticks(y_pos, hire15_name)\n\n# Removing the frame for a cleaner visual\nfor spine in plt.gca().spines.values():\n    spine.set_visible(False)\n    \n# Removing the small y ticks\nax.tick_params(axis=u'both', which=u'both',length=0)\n\n# Directly labeling the values of the bar chart \ni = 0\nfor bar in bars:\n    plt.gca().text(bar.get_x() + bar.get_width()-3650, i-0.15, str(int(bar.get_width())), \n                 ha='left', color='w', fontsize=11)\n    i = i+1\n    \n# Removing the x-ticks\nplt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n\n# Setting the title \nplt.title('Number of H-1B Visa Applicants by each company in 2015')\nplt.savefig('hire15 applications_fi.png', bbox_inches='tight')","bc4fe42c":"# Number of H-1B Visa Applicants hired by each company in 2018\ndf18 = df[df['EMPLOYMENT_START_DATE']==2018]\nhire18 = df18['EMPLOYER_NAME'].value_counts()\nprint(hire18[0:20])","d0a93352":"# Bar Chart of companies that provide the most H1B visas in 2018\nhire18_name = list(hire18[0:10].index)\nhire18_freq = list(hire18[0:10])\n\ny_pos = np.arange(len(hire18_name))\n\n# Plotting a horizontal bar chart\nfig, ax = plt.subplots()\nbars = plt.barh(y_pos, hire18_freq, align = 'center', alpha = 0.7)\n\n# Labeling the bar chart\nplt.yticks(y_pos, hire18_name)\n\n# Removing the frame for a cleaner visual\nfor spine in plt.gca().spines.values():\n    spine.set_visible(False)\n    \n# Removing the small y ticks\nax.tick_params(axis=u'both', which=u'both',length=0)\n\n# Directly labeling the values of the bar chart \ni = 0\nfor bar in bars:\n    plt.gca().text(bar.get_x() + bar.get_width()-1700, i-0.15, str(int(bar.get_width())), \n                 ha='left', color='w', fontsize=11)\n    i = i+1\n    \n# Removing the x-ticks\nplt.tick_params(axis='x', which='both', bottom=False, top=False, labelbottom=False)\n\n# Setting the title \nplt.title('Number of H-1B Visa Applicants by each company in 2018')\nplt.savefig('hire18 applications_f.png', bbox_inches='tight')","60c98ae4":"# The 10 most common types of jobs that H1B visa are granted for\ncommon_type = df['SOC_NAME'].value_counts()\nprint(list(common_type[:10].index))\n# From the first 10 jobs, we can see that majority of these jobs are related to technology (computers)","0a064bc2":"# The 10 most common job titles \ncommon_job = df['JOB_TITLE'].value_counts()\nprint(list(common_job[:10].index))","85a7fdf4":"# Looking at data science roles (related like business analyst, data analyst, data engineer) for H1B Visas\ndata_science_only = df.loc[df['JOB_TITLE']=='DATA SCIENTIST']\nbus_analyst = df.loc[df['JOB_TITLE']=='BUSINESS ANALYST']\ndata_analyst = df.loc[df['JOB_TITLE']=='DATA ANALYST']\ndata_eng = df.loc[df['JOB_TITLE']=='DATA ENGINEER']\ndata_science = pd.concat([data_science_only,bus_analyst,data_analyst,data_eng])\n\n# Number of data science and similar roles h1b visas granted\nprint(data_science.shape[0])","7dcbb6b3":"# Looking at the prevailing wages of data science jobs vs other h1b visa jobs\ndata_science['PREVAILING_WAGE'].describe()\n\n# Non-data science jobs' salaries\nnot_data_science = df[(df['JOB_TITLE'] != 'DATA SCIENTIST | BUSINESS ANALYST | DATA ANALYST | DATA ENGINEER')]\nnot_data_science['PREVAILING_WAGE'].describe()","5a96c436":"# Boxplot for data science and non data science wages\n# Turning values into lists for plotting\ndata_science = data_science.reset_index(drop=True)\nnot_data_science = not_data_science.reset_index(drop=True)\nplot_box_df = pd.concat([not_data_science['PREVAILING_WAGE'],data_science['PREVAILING_WAGE']],\n                        keys=['Not Data Science','Data Science'],axis=1)\n\nsns.boxplot( data = plot_box_df, palette=\"Blues\", showfliers=False)\naxes = plt.gca()\naxes.set_ylim([0,150000])\nplt.title('Wages for Non Data Science and Data Science Jobs')\nplt.show()","b97ef821":"# Location for Data Science jobs (H1B Applicants)\nds_heatmap = data_science.groupby('EMPLOYER_STATE')['CASE_STATUS'].count()\n\nscl = [\n    [0.0, 'rgb(242,240,247)'],\n    [0.2, 'rgb(218,218,235)'],\n    [0.4, 'rgb(188,189,220)'],\n    [0.6, 'rgb(158,154,200)'],\n    [0.8, 'rgb(117,107,177)'],\n    [1.0, 'rgb(84,39,143)']\n]\n\ndata = [go.Choropleth(\n    colorscale = scl,\n    autocolorscale = False,\n    locations = ds_heatmap.index,\n    z = ds_heatmap.values.astype(float),\n    locationmode = 'USA-states',\n    marker = go.choropleth.Marker(\n        line = go.choropleth.marker.Line(\n            color = 'rgb(255,255,255)',\n            width = 2\n        )),\n    colorbar = go.choropleth.ColorBar(\n        title = \"\")\n)]\n\nlayout = go.Layout(\n    title = go.layout.Title(\n        text = 'H1B Data Science Applicants'\n    ),\n    geo = go.layout.Geo(\n        scope = 'usa',\n        projection = go.layout.geo.Projection(type = 'albers usa'),\n        showlakes = True,\n        lakecolor = 'rgb(255, 255, 255)'),\n)\n\nfig = go.Figure(data = data, layout = layout)\nplotly.tools.set_credentials_file(username='jpar746', api_key='z4DayxsEIqnFEGvEUhPO')\nplotly.offline.iplot(fig, filename = 'd3-cloropleth-map')","007e2a7b":"As an aspiring data scientist, I thought that it would be interesting to explore the H-1B application process for data scientist. There were 63,503 applications for data scientists. ","025f6b09":"From the series above, we can see that there are about 500,000 applicants every year. \nWe can also see that there has been a decrease in the number of applications in 2017 and 2018 (Trump's Presidency) The figure below highlights the fall in the number of applicants in Trump's Presidency","666f15a7":"The figure above illustrates the ten companies that have submitted the most number of H-1B Visas. We can observe that the top three companies are all from the technology sector. In fact, most of the companies that apply for H-1B visas are from the technology sector.","f53c04e3":"It appears that the percentage of cases denied is really low. Upon further research, the denied percentage is not indicative of all the applications denied in the H-1B application process. Additional information is provided by the https:\/\/www.uscis.gov\/sites\/default\/files\/USCIS\/Resources\/Reports%20and%20Studies\/Immigration%20Forms%20Data\/BAHA\/non-immigrant-worker-rfe-h-1b-quarterly-data-fy2015-fy2019-q1.pdf\n","d167a863":"This choropleth map highlights the location of applicants. From the figure, we can see that the majority of the H-1B visa applicants are applying from California, New York, and Texas. \n","ab8b29f4":"By comparing the wages for non data science jobs and data science jobs, It appears that there is not a massive difference in the median and mean wage of data science jobs. Both the median appear to be between 60,000 and 80,000. However, the non data science jobs tend to have a larger interquartile range which could be explained by the diverse jobs that other H-1B applicants had.","3f70c10a":"This is a heatmap of the locations of H-1B Data Science Applicants. We can see that majority of these applications are from California, Texax, New Jersey, and New York","5cd75611":"How has Trump's Presidency affected H-1B Visas?","58529423":"The data from the Department of Labor seems to have been collected after an initial screening from the USCIS\nUnited States Citizenship and Immigration Service. The data shown by the USCIS indicates an increase in the\npercentage of rejected applications\n\nhttps:\/\/www.uscis.gov\/sites\/default\/files\/USCIS\/Resources\/Reports%20and%20Studies\/Immigration%20Forms%20Data\/BAHA\/non-immigrant-worker-rfe-h-1b-quarterly-data-fy2015-fy2019-q1.pdf\n","b705fcb1":"## Exploratory Data Analysis of H-1B Visas"}}