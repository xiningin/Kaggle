{"cell_type":{"42fa7127":"code","b1cb8914":"code","2757fb12":"code","634b83f1":"code","ae04ac3b":"code","1ecc4fbc":"code","83912d28":"code","71bf2b27":"code","7636e08f":"code","0628b12e":"code","a8a8beb1":"code","e8f7f37e":"code","0fa11584":"code","a54bafe9":"code","b9bfed00":"code","5ba0ce1c":"code","21285fed":"code","71fdb817":"code","4f778ffc":"code","5945730e":"code","a2526b1c":"code","e5a49da8":"code","fac78e3b":"code","005b6abb":"code","02ed35fd":"code","6f6a55d3":"code","e677e8ef":"code","e3d79c9d":"code","e323a0b9":"code","9b7169ec":"code","08ab12e7":"code","e79d0526":"code","46eb2bc9":"code","b610f7d1":"code","1aaadafb":"code","927abd3c":"code","ac6d1508":"markdown","1592b865":"markdown","5c7d6c4b":"markdown","081b8afd":"markdown","e97f4ea8":"markdown","22d4ef74":"markdown","039b121a":"markdown","b18887f6":"markdown","e6872d2b":"markdown"},"source":{"42fa7127":"import warnings\nwarnings.filterwarnings('ignore')","b1cb8914":"# Import tensorflow \nimport tensorflow as tf\nprint(\"version: \"+tf.__version__)","2757fb12":"# lets see Hello world example\nhello = tf.constant(\"Hello \")\nworld = tf.constant(\"world!\")","634b83f1":"# lets print\nprint(hello+world)","ae04ac3b":"# lets have a look on type of hello and world variables\nprint(type(hello))\nprint(type(world))","1ecc4fbc":"with tf.Session() as sess:\n    print( sess.run(hello+world) ) # concatenation","83912d28":"# lets play with numbers\na = tf.constant(5)\nb = tf.constant(10)\ntype(a)","71bf2b27":"with tf.Session() as sess:\n    print( sess.run(a+b) )","7636e08f":"# A 4X4 Matrix with all values 10\nmatA = tf.fill((4,4),10) \nwith tf.Session() as sess:\n    print( sess.run(matA) )","0628b12e":"# Zero values matrix\nmatB = tf.zeros((2,2))\nwith tf.Session() as sess:\n    print( sess.run(matB) )","a8a8beb1":"# Normal distribution Matrix\nmatN = tf.random_normal((2,2),mean=0,stddev=1.0)\n\nwith tf.Session() as sess:\n    print(sess.run(matN))","e8f7f37e":"# Uniform Random Distribution\nmatU = tf.random_uniform((2,2),minval=10,maxval=100)\nwith tf.Session() as sess:\n    print(sess.run(matU))","0fa11584":"ISess = tf.InteractiveSession()\n\nprint( ISess.run(tf.zeros((5,5)) ) )\n# or\nones = tf.ones((5,5))\nprint( ones.eval() ) \n","a54bafe9":"# Simple Matrix example\nmatS1 = tf.constant([[10,5],\n                    [3, 9]  ])\nmatS2 = tf.constant([[10,5],\n                    [3, 9]  ])\n\nprint( matS1.eval() )\nprint( matS1.get_shape())\n\nprint(tf.matmul(matS1,matS2).eval())","b9bfed00":"tf.get_default_graph","5ba0ce1c":"print( tf.constant(0) )\nprint( tf.constant(0, name=\"c\") )","21285fed":"# Other than default graph\nd = tf.get_default_graph\ng = tf.Graph()\ng","71fdb817":"g is tf.get_default_graph","4f778ffc":"d is tf.get_default_graph","5945730e":"tensorVar = tf.Variable( initial_value=tf.zeros((2,2)) )\n\n# initialize the variables\ninit = tf.global_variables_initializer()\ninit.run()\n\nprint( tensorVar )\nprint(tensorVar.eval())","a2526b1c":"ph = tf.placeholder(tf.float32) \nph","e5a49da8":"matph1 = tf.placeholder(tf.int32, shape=(3,3))\nmatph2 = tf.placeholder(tf.int32, shape=(None,3))\n# None is for no. of rows or examples in dataset\n\nprint(matph1)\nprint(matph2)","fac78e3b":"import numpy as np #for linear algebra \nnp.random.seed(101) # It can be called again to re-seed the generator\ntf.set_random_seed(101)","005b6abb":"rand_a = np.random.uniform(0,100,(5,5))\nrand_b = np.random.uniform(0,100,(5,1))\n\na = tf.placeholder(tf.float32)\nb = tf.placeholder(tf.float32)\n\nadd_op = a+b # tf.add(a,b)\nmult_op = a*b #tf.multiply(a,b)","02ed35fd":"with tf.Session() as sess:\n    s = sess.run( add_op, feed_dict={ a:rand_a, b:rand_b} )\n    print(s)\n    \n    m = sess.run( mult_op, feed_dict={a:rand_a, b:rand_b } )\n    print(m)","6f6a55d3":"n_features = 10\nn_dense_neurons = 3","e677e8ef":"# Placeholder for x\nx = tf.placeholder(tf.float32,(None,n_features))\n\n# Variables for w and b\nb = tf.Variable(tf.zeros([n_dense_neurons]))\n\nW = tf.Variable(tf.random_normal([n_features,n_dense_neurons]))","e3d79c9d":"# Activation func\nxW = tf.matmul(x,W)\nz = tf.add(xW,b)\n# tf.nn.relu() or tf.tanh()\na = tf.sigmoid(z)\n\n# Variable Intialization\ninit = tf.global_variables_initializer()\nwith tf.Session() as sess:\n    sess.run(init)\n    print(sess.run(z,feed_dict={x : np.random.random([1,n_features])}))\n    layer_out = sess.run(a,feed_dict={x : np.random.random([1,n_features])})\n\nprint(layer_out)","e323a0b9":"np.linspace(1,10,10)","9b7169ec":"# Artificial Data\nxdata = np.linspace(0,10,10) + np.random.uniform(-1.5,1.5,10)\nprint(xdata)\nydata = np.linspace(0,10,10) + np.random.uniform(-1.5,1.5,10)\nprint(ydata)","08ab12e7":"m = tf.Variable(0.39)\nb = tf.Variable(0.2)","e79d0526":"# Cost or Residual \n\nerror = 0\nfor x,y in zip(xdata,ydata):\n    y_ = m*x + b\n    error += (y-y_)**2\n\nprint(error)","46eb2bc9":"# optimizer\noptimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\ntrain = optimizer.minimize(error)\ntrain","b610f7d1":"init = tf.global_variables_initializer()\n\nwith tf.Session() as sess:\n    \n    sess.run(init)\n    \n    epochs = 100\n    \n    for i in range(epochs):\n        \n        sess.run(train)\n        \n\n    # Fetch Back Results\n    final_slope , final_intercept = sess.run([m,b])","1aaadafb":"print(final_slope)\nprint(final_intercept)","927abd3c":"import matplotlib.pyplot as plt\n\nx_test = np.linspace(-1,11,10)\ny_pred_plot = final_slope*x_test + final_intercept\n\nplt.plot(x_test,y_pred_plot,'r')\n\nplt.plot(xdata,ydata,'*')\nplt.show()","ac6d1508":"#### Graphs in Tensorflow\nA tf.Graph object defines a namespace for the tf.Operation objects it contains.\n\nA tf.Graph contains two relevant kinds of information:\n\n**Graph structure** The nodes and edges of the graph, indicating how individual operations are composed together, but not prescribing how they should be used. The graph structure is like assembly code: inspecting it can convey some useful information, but it does not contain all of the useful context that source code conveys.\n\n**Graph collections** TensorFlow provides a general mechanism for storing collections of metadata in a tf.Graph. The tf.add_to_collection function enables you to associate a list of objects with a key (where tf.GraphKeys defines some of the standard keys), and tf.get_collection enables you to look up all objects associated with a key. Many parts of the TensorFlow library use this facility: for example, when you create a tf.Variable, it is added by default to collections representing \"global variables\" and \"trainable variables\". When you later come to create a tf.train.Saver or tf.train.Optimizer, the variables in these collections are used as the default arguments.","1592b865":"### Basic Neural Network with Tensorflow ","5c7d6c4b":"### To execute tensors we can also create interactive session\n#### tf.InteractiveSession()\nThis is the exact same as tf.Session() but is targeted for using IPython and Jupyter Notebooks that allows you to add things and use Tensor.eval() and Operation.run() instead of having to do Session.run() every time you want something to be computed.","081b8afd":"**Running Sessions to create Graphs with Feed Dictionaries**","e97f4ea8":"#### Variables\nA TensorFlow variable is the best way to represent shared, persistent state manipulated by your program.\nVariables are manipulated via the **tf.Variable class**\n\nVariable needs to be initialized.\n\nCan hold the values of weights and biases through out the session. ","22d4ef74":"![](http:\/\/)In order to print **hello world!** we need tf session","039b121a":"#### Lets see how matrix will be declared \n    Explore matrix functions by placing curser on tf and (shift+tab)","b18887f6":"#### Full Neural Network Example\n**${y = mx + b}$**\n","e6872d2b":"#### Placeholders\nThey are initially empty and used to feed in the actual training examples. But they need to be declared with datatype and expected shape."}}