{"cell_type":{"f0b15332":"code","ca25f3c5":"code","ceb6f17f":"code","b927e325":"code","c2c7d001":"code","98797445":"code","ada19695":"code","7213bad7":"code","912f1a1d":"code","0ab930ab":"code","0264b43a":"code","c6fa043d":"code","7338999e":"code","8afb06de":"code","6f0d713f":"code","beb79803":"code","66e06065":"code","7fff69c4":"code","a0e673de":"code","4587fee4":"code","45b8cbd4":"code","2f6cd1bc":"code","b92d2661":"code","b64be0fd":"markdown","bab4f1b3":"markdown","8a6ffd16":"markdown","cd8eba93":"markdown","d7706ccd":"markdown","48eb04e4":"markdown","b9dd94f2":"markdown","6c8691ad":"markdown","bca8a5cd":"markdown","170fa689":"markdown"},"source":{"f0b15332":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('darkgrid')\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ca25f3c5":"df=pd.read_csv('..\/input\/online-shoppers-purchasing-intention-dataset\/online_shoppers_intention.csv')","ceb6f17f":"df.shape","b927e325":"df.info()","c2c7d001":"for cols in df.columns:\n    if(df[cols].dtype=='object' or df[cols].dtype=='bool'):\n        print(cols)","98797445":"df['Month'].value_counts()","ada19695":"df['Weekend']=df['Weekend'].replace({True:'Week1',False:'Week0'})\ndf['Revenue']=df['Revenue'].replace({True:'Rev1',False:'Rev0'})\ndf=pd.concat([df,pd.get_dummies(df['Month']),pd.get_dummies(df['VisitorType']),pd.get_dummies(df['Weekend']),pd.get_dummies(df['Revenue'])],axis=1)","7213bad7":"df=df.drop(['Month','VisitorType','Weekend','Revenue','Rev0'],axis=1)","912f1a1d":"df.head()","0ab930ab":"df.info()","0264b43a":"sns.catplot(x=\"Browser\", y=\"BounceRates\", hue=\"Rev1\", data=df)","c6fa043d":"sns.catplot(x=\"Rev1\", y=\"ProductRelated_Duration\", data=df)","7338999e":"from sklearn.feature_selection import mutual_info_classif","8afb06de":"mi_score=mutual_info_classif(df.drop('Rev1',axis=1),df['Rev1'])\nmi_score=pd.Series(mi_score*100,index=df.drop('Rev1',axis=1).columns)\nmi_score=mi_score.sort_values(ascending=False)\nmi_score","6f0d713f":"top_fea=mi_score.index[:9]","beb79803":"from sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler \ndf_sc=StandardScaler().fit_transform(df[top_fea])\nxtr,xte,ytr,yte=train_test_split(df_sc,df['Rev1'],random_state=108,test_size=0.27)\nxtr,xval,ytr,yval=train_test_split(xtr,ytr,random_state=108,test_size=0.27)","66e06065":"import tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers, callbacks","7fff69c4":"model=keras.Sequential([\n    layers.Dense(512,activation='relu',input_shape=(9,)),\n    layers.BatchNormalization(),\n    layers.Dropout(0.27),\n    layers.Dense(978,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(1224,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.32),\n    layers.Dense(1528,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(828,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.27),\n    layers.Dense(428,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.3),\n    layers.Dense(128,activation='relu'),\n    layers.BatchNormalization(),\n    layers.Dropout(0.32),\n    layers.Dense(1,activation='sigmoid')\n])\n\nmodel.compile(optimizer='adam',loss='binary_crossentropy',metrics='accuracy')\n\ncall=callbacks.EarlyStopping(patience=12,min_delta=0.0001,restore_best_weights=True)\nhistory=model.fit(xtr,ytr,batch_size=48,epochs=45,validation_data=(xval,yval),callbacks=call)","a0e673de":"his=pd.DataFrame(history.history)","4587fee4":"his.head()","45b8cbd4":"his.loc[:,['loss','val_loss']].plot()","2f6cd1bc":"his.loc[:,['accuracy','val_accuracy']].plot()","b92d2661":"model.evaluate(xte,yte)","b64be0fd":"# Visualizing the Accuracy  & Loss during\n* Training & Validation ","bab4f1b3":"## Checking the distribution of data","8a6ffd16":"# Converting *non*-Numerical columns to numeric form","cd8eba93":"# Loading and Exploring the dataset to check the following\n#### * Shape of dataset\n#### * Null columns\n#### * Balanced\/Imbalanced dataset\n#### * Categorical\/Numerical columns\n#### * Distribution of data","d7706ccd":"# Evaluating the model","48eb04e4":"# Selecting the most `important` feature","b9dd94f2":"#### Dropping extra columns","6c8691ad":"# Splitting the dataset into:\n* Test\n* Train\n* Validation set","bca8a5cd":"# Building the Artificial-Neural-Net","170fa689":"# `89.24%` accuracy!"}}