{"cell_type":{"d3d7d779":"code","6831b9da":"code","08576718":"code","d8b03b9d":"code","6343d3d2":"code","f2e937b2":"code","8378cd0c":"code","0834e193":"code","8d7b9c91":"code","d822e5d8":"code","215b7d61":"code","1e47fb4c":"code","f2741043":"code","7f1135bd":"code","4a6a05ee":"code","746148d0":"code","1b122c3e":"code","bd9a3fb4":"code","2bca3a5f":"code","7e0c8399":"code","f97ee612":"code","c7163177":"code","6802ff35":"code","f076b020":"code","6ee8eff4":"code","4ae5550b":"code","42317dfa":"code","c49b2ee4":"code","579af1b8":"code","e02f2e73":"code","6dc71c64":"code","246b6871":"code","96c97bee":"code","e139be0c":"markdown","6ed29b0f":"markdown","8b4062b2":"markdown","d19143fa":"markdown","92e4bbd7":"markdown","93e65bd4":"markdown","801662b5":"markdown","629c458c":"markdown","1ca21da2":"markdown","0da534ff":"markdown","37effb2b":"markdown","4e1a18fd":"markdown","9ca0757c":"markdown","a83d9126":"markdown","676331d2":"markdown","d5870cea":"markdown","b7313beb":"markdown","1fec82a8":"markdown","f45338d6":"markdown","b429403a":"markdown","644433b1":"markdown","f6cc32f7":"markdown","aa1774e2":"markdown","5bde87f0":"markdown","315a930c":"markdown","6fcf07ed":"markdown","ff494baa":"markdown","221fe7eb":"markdown","1f974816":"markdown","83e8fabd":"markdown","82d5d464":"markdown","525d3443":"markdown","c6d1578c":"markdown","c8f0bf8d":"markdown","646c117f":"markdown","6510281f":"markdown","8eba47eb":"markdown","c902d57d":"markdown","ba86af1d":"markdown","83d2f519":"markdown","5b5469dd":"markdown","e9ba73a1":"markdown","b32e44f7":"markdown","1260f05a":"markdown","89b566b8":"markdown","6d0f61f0":"markdown","6fa4c83c":"markdown","76c3aa0c":"markdown","445e7636":"markdown","062acfe8":"markdown","c06c72a7":"markdown","aecbac92":"markdown","85683a24":"markdown","40a0b697":"markdown","c8874835":"markdown","5bb6f2e0":"markdown","e490fe3f":"markdown","40e72d7a":"markdown"},"source":{"d3d7d779":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","6831b9da":"df = pd.read_csv('\/kaggle\/input\/heart-attack-analysis-prediction-dataset\/heart.csv')\ndf.head()","08576718":"print(\"No of rows and columns:\", df.shape)","d8b03b9d":"print(df.dtypes)","6343d3d2":"df.sex.astype('category')\ndf.fbs.astype('category')\ndf.restecg.astype('category')\ndf.exng.astype('category')\ndf.slp.astype('category')\ndf.thall.astype('category')\nprint(\"Data type has been changed for categorical variables.\")","f2e937b2":"print(df.isna().sum())","8378cd0c":"df.corr()","0834e193":"print(df.corr().loc['output'])","8d7b9c91":"df.describe()","d822e5d8":"df.caa.value_counts()","215b7d61":"df.loc[df.caa == 4, 'caa'] = 3\ndf.caa.value_counts()","1e47fb4c":"df.thall.value_counts()","f2741043":"from statistics import mode\nmd = mode(df.thall)\ndf.loc[df.thall == 0, 'thall'] = md\ndf.thall.value_counts()","7f1135bd":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\ndf_lc = df[df['output'] == 0]\ndf_hc = df[df['output'] == 1]\n\noutput_label = ['low chance','high chance']\nsns.set_context(\"notebook\")\nsns.set_style(\"darkgrid\")\n\nax = sns.countplot(x='output', data = df)\nax.set_title(\"Chance of people having heart conditions\")\nax.set(xlabel = 'Chance', ylabel = 'No of patients')\nplt.xticks(ticks = [0,1], labels = output_label)\nplt.show()","4a6a05ee":"ag = sns.histplot(data = df, x = 'age', binwidth = 5)\nag.set_title(\"Age distribution\")\nplt.show()","746148d0":"ax = sns.kdeplot(data = df, hue = 'output', bw_adjust = 1, x = 'age', palette = ['tab:cyan', 'tab:green'])\nax.set(xlabel = 'age', ylabel = 'age distribution')\nplt.legend([\"high risk\", \"low risk\"])\nplt.show()","1b122c3e":"hue_color = {0:'black', 1:'red'}\nsex = ['female', 'male']\ng = sns.countplot(data = df, x = 'sex', hue = 'output', palette = hue_color)\nplt.xticks(ticks = [0,1], labels = sex)\nplt.legend(['less chance', 'high chance'])\nplt.show()","bd9a3fb4":"sns.countplot(data = df, x = 'cp', hue = 'output', palette = ['skyblue', 'darkgray'])\nplt.xlabel(\"chest pain type\")\nplt.legend(['less chance', 'high chance'])\nplt.show()","2bca3a5f":"ax = sns.kdeplot(data = df, x = 'trtbps', bw_adjust = 0.9, hue = 'output', palette = ['mediumslateblue', 'yellowgreen'])\nax.set(xlabel = 'resting blood pressure')\nplt.legend(['high chance', 'low chance'])\nplt.show()","7e0c8399":"sns.kdeplot(x = 'chol', data = df, hue = 'output')\nplt.legend(['high chance', 'low chance'])\nplt.xlabel(\"Cholestrol\")\nplt.show()","f97ee612":"x = pd.crosstab(df['fbs'], df['output'])\nx.plot(kind = 'bar', color = ['k', 'grey'])\nplt.xticks(ticks = [0,1], labels = ['False', 'True'], rotation = 0)\nplt.legend(['less chance', 'high chance'])\nplt.show()","c7163177":"x = pd.crosstab(df['restecg'], df['output'])\nx.plot(kind = 'bar', color = ['tab:blue', 'tab:red'])\nplt.legend(['less chance', 'high chance'])\nplt.xticks(rotation = 0)\nplt.show()","6802ff35":"sns.kdeplot(data = df, hue = 'output', x = 'thalachh', bw_adjust = 0.75, palette = ['cornflowerblue', 'turquoise'])\nplt.xlabel(\" Max heart rate achieved\")\nplt.legend(['high risk', 'low risk'])\nplt.show()","f076b020":"x = pd.crosstab(df['exng'], df['output'])\nx.plot(kind = 'bar', color = ['plum', 'mediumpurple'])\nplt.legend(['less chance', 'high chance'])\nplt.xticks(ticks = [0,1], labels = ['no', 'yes'], rotation = 0)\nplt.show()","6ee8eff4":"sns.histplot(data = df, x = 'oldpeak', bins = 10, hue = 'output', stat = 'probability', palette = {0:'c',1:'m'})\nplt.legend(['high risk', 'low risk'])\nplt.show()","4ae5550b":"x = pd.crosstab(df['slp'], df['output'])\nx.plot(kind = 'bar', color = ['tab:purple', 'tab:pink'])\nplt.legend(['less chance', 'high chance'])\nplt.xticks(rotation = 0)\nplt.show()","42317dfa":"x = pd.crosstab(df['caa'], df['output'])\nx.plot(kind = 'bar', color = ['lightcoral', 'skyblue'])\nplt.legend(['less chance', 'high chance'])\nplt.xticks(rotation = 0)\nplt.show()","c49b2ee4":"x = pd.crosstab(df['thall'], df['output'])\nx.plot(kind = 'barh', color = ['bisque', 'darkseagreen'])\nplt.legend(['less chance', 'high chance'])\nplt.xticks(rotation = 0)\nplt.show()","579af1b8":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\n\nX = df.drop(['output'], axis = 1)\ny = df[\"output\"]\nX.head()","e02f2e73":"train_X, val_X, train_y, val_y = train_test_split(X, y, random_state = 0)\nmy_model = RandomForestClassifier(n_estimators = 100, criterion = 'gini', min_samples_split = 4, \n                               max_depth = 6, random_state = 0)","6dc71c64":"my_model.fit(train_X, train_y)\nprediction = my_model.predict(val_X)","246b6871":"accuracy = accuracy_score(val_y, prediction)\nprint(\"Model accuracy:\", round(accuracy*100, 2), \"%\")","96c97bee":"importance = my_model.feature_importances_\nprint(\"Feature importance table\\n\")\n# summarize feature importance\nfor i,v in enumerate(importance):\n    print(X.columns[i], ':', round((v*100),2), '%')","e139be0c":"#### Results and conclusion:\n* We analysed the dataset and understood the correlation between each feature and the target variable.\n* We prepared a data model using the random forest machine learning algorithm for this classification problem.\n* We prepared our data model and found out that almost all features except two played a role in the making our predictions.\n* The most significant factors that contribute towards predictiong the heart attack risk of a patient are:\n  1. Chest pain type\n  2. Maximum heart rate achieved\n  3. ST depression induced by exercise\n  4. Number of major vessels\n  5. Thalassemia blood disorder\n* We tested and validated our data model. **It achieved an accuracy of 88.16%.**","6ed29b0f":"* Checking the dimensions of the dataset","8b4062b2":"*It is observed that there isn't much of a correlation between one's fasting blood sugar and heart condition risk*","d19143fa":"#### Dataset feature details\n\n0. id - Patient id\n\n1. age - Age in years\n\n2. sex - Sex (1 = male; 0 = female)\n\n3. cp - Chest pain type (0 = asymptomatic; 1 = typical angina; 2 = atypical angina; 3 = non-anginal pain)\n\n4. trtbps - Resting blood pressure (in mm Hg on admission to the hospital)\n\n5. chol - Serum cholestoral in mg\/dl\n\n6. fbs - Fasting blood sugar > 120 mg\/dl (1 = true; 0 = false)\n\n7. restecg - Resting electrocardiographic results (0 = normal; 1 = having ST-T wave abnormality; 2 = hypertrophy)\n\n8. thalachh - Maximum heart rate achieved\n\n9. exng - Exercise induced angina (1 = yes; 0 = no)\n\n10. oldpeak - ST depression induced by exercise relative to rest\n\n11. slp - Slope of the peak exercise ST segment (2 = upsloping; 1 = flat; 0 = downsloping)\n\n12. caa - Number of major vessels (0-3) colored by flourosopy\n\n13. thall - Thalassemia blood disorder (1 = fixed defect; 2 = normal;  3 = reversable defect)\n\n14. output - The target variable and predicted attribute (0 = less chance of heart attack; 1 = more chance of heart attack)","92e4bbd7":"### 4. Data modelling using ML","93e65bd4":"* We first explore the target variable and see the count of patients with low risk and high risk of heart attack","801662b5":"*This shows us that* \n* More males are at a low risk but it is comparable. \n* A signifciant no of women are at a high risk compared to the no of women with low risk.\n\n*There seems to be a correlation between sex and heart attack risk even if it isn't a causation.*","629c458c":"#### 10. Exercise induced ST depression","1ca21da2":"* Testing and validating our data model","0da534ff":"#### 8. Max heart rate achieved","37effb2b":"*As the value increases, there seems to be a higher probability of patients having a low risk compared to high risk.*\n\n*There is a linear correlation between the predictor variable and number of major vessels.*","4e1a18fd":"*Strong pearson correlation is observed between the following features and the target variable:*\n1. Age                  \n2. Sex                           \n3. Chest pain type\n4. Max heart rate       \n5. Exercise induced angina       \n6. ST depression caused by exercise\n7. ST segment slope.    \n8. Number of major vessels       \n9. Thalassemia blood disorder","9ca0757c":"#### 6. Fasting blood sugar","a83d9126":"#### 3. Chest pain","676331d2":"##### 2. 'thall'\n  The range of values should be in the range 1-3.","d5870cea":"### 3. Exploratory data analysis","b7313beb":"*Inference:*\n* Patients with resting blood pressure range between 80 and 150 are observed to have a higher chance of being at high risk\n\n*Difficult to establish a correlation even though there might be one.*","1fec82a8":"*Inference:*\n* Patients with max heart rate lesser than 140 are more likely to have a lower risk.\n* Patients with max heart rate greater than 140 are more likely to have a higher risk.\n\n*There is a strong correlation between the max heart rate and risk of having a heart attack*","f45338d6":"### 1. Importing the dataset","b429403a":"#### 2. Sex","644433b1":"#### 1. Age\n   \n   Age distribution","f6cc32f7":"*It is observed that there is an healthy ratio of both types of patients. We can now explore each feature in detail.*","aa1774e2":"* Statistical summary of each column","5bde87f0":"* Extracting the correlation of all the features to the target variable 'output'","315a930c":"It is observed that there are five entries with the value 4 which is outside our range. Since it is outside the maximum value of the range, e have to impute them by replacing them with the max value i.e 3. ","6fcf07ed":"* We now see the importance of each feature in our ML data model using a feature importance table","ff494baa":"#### 13. Thalassemia blood disorder","221fe7eb":"#### 7. Resting electrocardiographic results","1f974816":"*The graph indicates that:* \n* More people lesser than age 55 have a higher risk\n* More people within the age group of 55-70 have a lower risk\n* More people greater than age 70 have a higher risk\n\n*There might be a non linear correlation between age group and heart attack risk for patients*","83e8fabd":"#### 5. Cholestrol","82d5d464":"*Inference - There is a good correlation between these two variables because:* \n* Lower value patients are observed to have a high risk compared to low risk\n* Higher value patients are observed to have a low risk compared ti high risk","525d3443":"* Checking the column names and data type of each column","c6d1578c":"*Inference:*\n* Value 1 and 3: Patients with low risk are more in number\n* Value 2: Patients with high risk are more in number\n\n*There seems to be some correlation between these two variable*","c8f0bf8d":"*The stark difference points that there is a strong correlation between this feature and the target variable.*","646c117f":"#### 9. Exercise induced angina","6510281f":"* Defining our data model","8eba47eb":"#### 11. ST segment slope","c902d57d":"It can now be observed that those five entries have been replaced with value 3.","ba86af1d":"* Training our data model","83d2f519":"#### 12. Number of major vessels","5b5469dd":"The entries with value '0' have been replaced by the mode i.e '2'.","e9ba73a1":"*Inference*\n- For value 0: No significant difference\n- For value 1: Patients with low risk are higher in number\n- For value 2: Patients with high risk are higher in number\n\n*There is a correlation between these two variables.*","b32e44f7":"#### 4. Resting blood pressure","1260f05a":"* Checking if there are any null values","89b566b8":"*There seems to be a significant difference between the count low risk and high risk patients only for value 1. This is might just be a correlation and not a causation.*","6d0f61f0":"* We observe that there are values outside the specified range for the columns 'caa' and 'thall'. Hence, we will have to impute the data of these columns.","6fa4c83c":"*Since this is a classification problem involving multiple categorical and numerical variables, the best machine learning algorithm we can use for preparing our model is the **Random Forest algorithm**.*\n\nTo learn more about the random forest algorithm, you can refer to this link: [Random Forest Classifier](https:\/\/medium.com\/machine-learning-101\/chapter-5-random-forest-classifier-56dc7425c3e1)","76c3aa0c":"*From this we can infer that barring fasting blood sugar and resting electrocardiographic results, all other did contribute towards the final decision tree that was used to make our predictions.*","445e7636":"* Changing the data type of categorical columns","062acfe8":"##### 1. 'caa'\n\n  The values of this column should be in the range of 0-3 as specified above. We first check the count of each  of these values.","c06c72a7":"* Importing the required libraries and tuning our dataset with the required features","aecbac92":"*Inference:* \n* Patients with chest pain type 1, 2, or 3 have a high chance \n* Patients with chest pain type 0 i.e asymptomatic have a low chance\n\n*Linear correlation exists between the two.*","85683a24":"*Inference:*\n* Density of patients with chlestrol roughly greater than 250 and lesser than 150 are mmore or less the same for patients with high and low chance.\n* Patients within the range of 150-250 appx are observed to have a higher chance of having a heart attack\n\n*Hard to predict but there is a chance of a non linear correlation.*","40a0b697":"* Finding the correlation between variables using a correlation table","c8874835":"There are two values of the value 0. Since this is a categorical variable and we have no idea what 0 represents, we replace these two entries with the mode of this feature.","5bb6f2e0":"### 2. Basic data analysis and cleaning","e490fe3f":"## Heart Patient risk analysis using machine learning","40e72d7a":"*The dataset is now clean and ready for further exploratory data analysis of the various features.*"}}