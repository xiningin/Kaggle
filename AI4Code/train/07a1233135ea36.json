{"cell_type":{"d9f3f14e":"code","a841b3ce":"code","3ad29056":"code","5239d44f":"code","93d5fb5e":"code","34466111":"code","36f22e28":"code","58a0f8bc":"code","cd32a418":"code","814440d2":"code","c625e3e0":"code","92ca175e":"code","d0df9fbc":"code","a562d5aa":"code","ca53e939":"code","305ca03f":"code","5ce6bd7b":"code","eab6dda4":"code","5c459ed3":"code","7eac5011":"code","1e60c41e":"code","3c7a9a53":"code","9d02eab8":"code","e8ae351f":"code","87392d2a":"code","26f86e92":"code","55d53e7d":"code","a477b642":"code","40eba491":"code","f33dc710":"code","59ff9d4b":"markdown","a5ea5420":"markdown","f92a247e":"markdown","c1e0001f":"markdown","8e2dd6c5":"markdown","7e03e4e1":"markdown","7121df7a":"markdown","1e8376a0":"markdown","ec3dbb9a":"markdown","5327505e":"markdown","40bb52ad":"markdown","5d8c93f9":"markdown","0ca251da":"markdown","40903467":"markdown","0360a198":"markdown","875f3659":"markdown","6c2a4e6e":"markdown","de0b7078":"markdown","1595f548":"markdown","811ede0c":"markdown","75bf90e0":"markdown"},"source":{"d9f3f14e":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a841b3ce":"import seaborn as sns\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\nsns.set_style('whitegrid')","3ad29056":"df_train = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf_test = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ntrain = df_train.copy()\ntest = df_test.copy()","5239d44f":"print('Train data','\\n')\nprint(train.info(),'\\n')\nprint(train.describe(),'\\n')\n\nprint('Test data','\\n')\nprint(test.info(),'\\n')\nprint(test.describe(),'\\n')\n\nprint('Train data : {}'.format(train.shape))\nprint('Test data : {}'.format(test.shape))","93d5fb5e":"train","34466111":"test","36f22e28":"assert 'PassengerId' in train, 'hi'","58a0f8bc":"def col_counts(col):\n    '''Print the value counts of columns from train and test data.\n    \n    Args:\n        col (str) : name of columns of train and test data\n    \n    Returns:\n       Print :\n           train's column's value counts\n           test column's value counts\n    '''\n    if col in train.columns:\n        print('Train\\'s {} : '.format(col))\n        print(train[col].value_counts(),'\\n')\n    else:\n        print('Train\\'s data does not have {} column.'.format(col))\n        \n    if col in test.columns:\n        print('Test\\'s {} : '.format(col))\n        print(test[col].value_counts())\n    else:\n        print('Test\\'s data does not have {} column.'.format(col))\n\n        \ndef drop_col(data, column):\n    '''Drop column from data.\n    \n    Args:\n        data (dataframe) : dataframe to drop columns on\n        column (list, str) : columns to drop\n        \n    Return :\n        None\n    '''\n    return data.drop(column, inplace = True,axis = 1)\n\n\ndef title_type(row):\n    '''Return str based on the input\n    \n    Args:\n        row (str) : row data that contain the title of the name\n        \n    Return:\n        str : categories for the input \n    '''\n    if row in ['Don', 'Mme',\n       'Major', 'Lady', 'Sir', 'Mlle', 'Col', 'Capt', 'the Countess',\n       'Jonkheer','Dona','Dr','Rev']:\n        # label as rare for titles that are low in counts\n        return 'Rare'\n    elif row == 'Miss':\n        return 'Ms'\n    else:\n        return row\n    \n    \ndef age_diff(row):\n    '''Return the category of age based on input age.\n    \n    Args:\n        row (int) : row data that contain the age\n        \n    ReturnL\n        str : categories of the input age\n    '''\n    if row < 18:\n        return 'Child'\n    elif (row < 60) & (row >=18):\n        return 'Adult'\n    else:\n        return 'Elderly'","cd32a418":"drop_col(train, ['PassengerId', 'Ticket'])\ndrop_col(test, ['PassengerId', 'Ticket'])","814440d2":"col_counts('Survived')","c625e3e0":"# split the name string based on ',' first and then '.'\ntrain['Title'] = train.Name.apply(lambda x : x.split(',')[1].split('.')[0].strip())\ntest['Title'] = test.Name.apply(lambda x : x.split(',')[1].split('.')[0].strip())\n    \ntrain['Title'] = train.Title.apply(title_type)\ntest['Title'] = test.Title.apply(title_type)\n\n# drop 'Name' column\ndrop_col(train, 'Name')\ndrop_col(test,'Name')","92ca175e":"col_counts('Title')","d0df9fbc":"# rename the category\ntrain['Sex'] = train.Sex.map({'male':'Male','female':'Female'})\ntest['Sex'] = test.Sex.map({'male':'Male','female':'Female'})","a562d5aa":"col_counts('Sex')","ca53e939":"# add the number of siblings, spouse, parents, children and the passenger itself\ntrain['Family'] = train.SibSp + train.Parch + 1\ntest['Family'] = test.SibSp + test.Parch + 1\n\n# drop 'SibSp' and 'Parch' columns to prevent repeatative features\ndrop_col(train, ['SibSp','Parch'])\ndrop_col(test, ['SibSp','Parch'])","305ca03f":"col_counts('Family')","5ce6bd7b":"# Divide the family size into 4 categories\ntrain['Family_type'] = pd.cut(train.Family, [0,1,4,7,11], labels = ['Single', 'Small', 'Medium', 'Large'])\ntest['Family_type'] = pd.cut(test.Family, [0,1,4,7,11], labels = ['Single', 'Small', 'Medium', 'Large'])","eab6dda4":"col_counts('Family_type')","5c459ed3":"# divide the age of passengers into 3 different categories\ntrain['Age_cat'] = train.Age.apply(age_diff)\ntest['Age_cat'] = test.Age.apply(age_diff)","7eac5011":"col_counts('Age_cat')","1e60c41e":"# Extract the first alphabert from the cabin name\ntrain['Cabin_floor'] = train.Cabin.apply(lambda x: list(str(x))[0])\ntrain['Cabin_floor'] = train.Cabin_floor.replace('n', np.nan)\n\ntest['Cabin_floor'] = test.Cabin.apply(lambda x: list(str(x))[0])\ntest['Cabin_floor'] = test.Cabin_floor.replace('n', np.nan)\n\n# drop 'Cabin' column\ndrop_col(train,'Cabin')\ndrop_col(test,'Cabin')","3c7a9a53":"col_counts('Cabin_floor')","9d02eab8":"# Preprocessing\nfrom sklearn.preprocessing import OneHotEncoder, LabelEncoder, RobustScaler,StandardScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.compose import ColumnTransformer\n\n# Validation model performance\nfrom sklearn.metrics import confusion_matrix, accuracy_score, classification_report, ConfusionMatrixDisplay, roc_auc_score\n\n# Hyperparameter tuning\nfrom sklearn.model_selection import train_test_split, GridSearchCV, RandomizedSearchCV, cross_val_score\n\n# Model\nfrom sklearn.neighbors import KNeighborsClassifier as KNN\nfrom sklearn.tree import DecisionTreeClassifier, plot_tree\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier, VotingClassifier\nfrom sklearn.linear_model import LogisticRegression, SGDClassifier\nfrom sklearn.svm import LinearSVC, SVC\nfrom xgboost import XGBClassifier\n\nseed = 225","e8ae351f":"y = train['Survived']\nX = train.drop('Survived',axis = 1)","87392d2a":"# define columns for numerical and categorical\nnum_cols = ['Fare']\n\ncat_cols = ['Pclass', 'Sex','Embarked','Title','Family_type','Age_cat']\n\n# pipeline for preprocessing of numerical and categorical data\ncat_transformer = Pipeline(steps = [('Cat_Imputer', SimpleImputer(strategy = 'most_frequent')),('OneHotEncoder',OneHotEncoder(handle_unknown = 'ignore'))])\nnum_transformer = Pipeline(steps = [('Num_Imputer', SimpleImputer(strategy = 'median'))])\n\npreprocessor = ColumnTransformer(transformers = [('num', num_transformer, num_cols), ('cat',cat_transformer, cat_cols)])\n\n# pipeline for modeling\ntitanic_pipeline = Pipeline(steps = [('Preprocessor',preprocessor),('XG', XGBClassifier(random_state = seed))])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = seed)\n\nparams = {'XG__learning_rate' : [0.1,0.2], 'XG__gamma' : [0.001,0.01,1,10],'XG__max_depth' : [4,6,8,10], 'XG__n_estimators' : [400,500]}\n\nsearcher = GridSearchCV(titanic_pipeline,params, cv = 3, verbose = 1, n_jobs = -1 )\n\nsearcher.fit(X_train,y_train)\n\nprint('Best params : {}'.format(searcher.best_params_))\nprint('Best score : {:.2f}'.format(searcher.best_score_))\n\ny_pred_train = searcher.predict(X_train)\ny_pred_test = searcher.predict(X_test)\n\nprint('XGBoost\\'s train score : {:.3f}'.format(accuracy_score(y_train,y_pred_train)))\nprint('XGBoost\\'s test score : {:.3f}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test,y_pred_test))\nprint('XGBoost\\'s roc score : {:.3f}'.format(roc_auc_score(y_test,y_pred_test)))","26f86e92":"# define columns for numerical and categorical\nnum_cols = ['Fare','Age']\n\ncat_cols = ['Pclass', 'Sex','Embarked','Title','Family_type']\n\n# pipeline for preprocessing of numerical and categorical data\ncat_transformer = Pipeline(steps = [('Cat_Imputer', SimpleImputer(strategy = 'most_frequent')),('OneHotEncoder',OneHotEncoder(handle_unknown = 'ignore'))])\nnum_transformer = Pipeline(steps = [('Num_Imputer', SimpleImputer(strategy = 'median'))])\n\npreprocessor = ColumnTransformer(transformers = [('num', num_transformer, num_cols), ('cat',cat_transformer, cat_cols)])\n\n# pipeline for modeling\ntitanic_pipeline = Pipeline(steps = [('Preprocessor',preprocessor),('XG', XGBClassifier(random_state = seed, learning_rate = 0.1))])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = seed)\n\nparams = { 'XG__gamma' : [0.001,0.01,1,10,100,1000],'XG__max_depth' : [2,4,6,8,10], 'XG__n_estimators' : [400,500]}\n\nsearcher_xg = GridSearchCV(titanic_pipeline,params, cv = 3, verbose = 1, n_jobs = -1 )\n\nsearcher_xg.fit(X_train,y_train)\n\nprint('Best params : {}'.format(searcher_xg.best_params_))\nprint('Best score : {:.2f}'.format(searcher_xg.best_score_))\n\ny_pred_train = searcher_xg.predict(X_train)\ny_pred_test = searcher_xg.predict(X_test)\n\nprint('XGBoost\\'s train score : {:.3f}'.format(accuracy_score(y_train,y_pred_train)))\nprint('XGBoost\\'s test score : {:.3f}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test,y_pred_test))\nprint('XGBoost\\'s roc score : {:.3f}'.format(roc_auc_score(y_test,y_pred_test)))","55d53e7d":"num_cols = ['Fare']\n\ncat_cols = ['Pclass', 'Sex','Embarked','Title','Family_type','Age_cat']\n\ncat_transformer = Pipeline(steps = [('Cat_Imputer', SimpleImputer(strategy = 'most_frequent')),('OneHotEncoder',OneHotEncoder(handle_unknown = 'ignore'))])\nnum_transformer = Pipeline(steps = [('Num_Imputer', SimpleImputer(strategy = 'median')), ('Scaler', RobustScaler())])\n\npreprocessor = ColumnTransformer(transformers = [('num', num_transformer, num_cols), ('cat',cat_transformer, cat_cols)])\n\ntitanic_pipeline = Pipeline(steps = [('Preprocessor',preprocessor),('SVC', SVC(random_state = seed))])\n\nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size = 0.3, random_state = seed)\n\nparameters = {'SVC__C':[0.1, 1, 10,100], 'SVC__gamma':[ 0.001, 0.01, 0.1,1,10]}\nsearcher = GridSearchCV(titanic_pipeline, parameters, cv = 5, n_jobs = -1, verbose = 1)\n\nsearcher.fit(X_train,y_train)\n\nprint('Best params : {}'.format(searcher.best_params_))\nprint('Best score : {:.2f}'.format(searcher.best_score_))\n\ny_pred_train = searcher.predict(X_train)\ny_pred_test = searcher.predict(X_test)\n\nprint('SVC\\'s train score : {:.3f}'.format(accuracy_score(y_train,y_pred_train)))\nprint('SVC\\'s test score : {:.3f}'.format(accuracy_score(y_test,y_pred_test)))\nprint(confusion_matrix(y_test, y_pred_test))\nprint(classification_report(y_test,y_pred_test))\nprint('SVC\\'s roc score : {:.3f}'.format(roc_auc_score(y_test,y_pred_test)))","a477b642":"output = searcher_xg.predict(test)","40eba491":"df_test['Survived'] = output\ndf_test = df_test[['PassengerId', 'Survived']]\nprint(df_test.shape)","f33dc710":"df_test.to_csv('submission_2.csv', index=False)","59ff9d4b":"# **Titanic data Modelling**","a5ea5420":"# Data Manipulation and Cleaning","f92a247e":"**Functions used**","c1e0001f":"**XG with Age as numerical**","8e2dd6c5":"**Name**","7e03e4e1":"**Family**","7121df7a":"Divide into 3 stage : Child, Adult, Elderly","1e8376a0":"**Drop Passenger Id and Ticket's columns**","ec3dbb9a":"**XG with Age as categorical**","5327505e":"**Survived**","40bb52ad":"**Extract the title from the name of passenger**","5d8c93f9":"**Age**","0ca251da":"# Import required libraries","40903467":"**Cabin**","0360a198":"**Sex**","875f3659":"# Applying model on test data","6c2a4e6e":"# Import data","de0b7078":"**Features details**\n* survival : Survival\t0 = No, 1 = Yes\n* pclass : Ticket class\t1 = 1st, 2 = 2nd, 3 = 3rd\n* sex\t: Sex\t\n* Age\t: Age in years\t\n* sibsp\t: # of siblings \/ spouses aboard the Titanic\t\n* parch\t: # of parents \/ children aboard the Titanic\t\n* ticket\t: Ticket number\t\n* fare\t: Passenger fare\t\n* cabin\t: Cabin number\t\n* embarked\t: Port of Embarkation\tC = Cherbourg, Q = Queenstown, S = Southampton\n\n**Variable Notes**\n* pclass: A proxy for socio-economic status (SES)\n* 1st = Upper\n* 2nd = Middle\n* 3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way\n* Sibling = brother, sister, stepbrother, stepsister\n* Spouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\n* Parent = mother, father\n* Child = daughter, son, stepdaughter, stepson\n* Some children travelled only with a nanny, therefore parch=0 for them.","1595f548":"# Modelling","811ede0c":"**SVC with Age as categorical**","75bf90e0":"* This notebook is focus on applying algorithm to the train and test data.\n* For the EDA part is located on another notebook\n* Algorithmn I used :\n    1. XGBoost\n    2. SVC"}}