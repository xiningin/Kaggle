{"cell_type":{"efe04f69":"code","05b47cbe":"code","99f7271f":"code","a2206194":"code","9e5854a7":"code","fd5dea49":"code","f5b571d3":"code","39f3c968":"code","35299c4e":"code","610a396d":"markdown","7bb19f81":"markdown","c6b0abff":"markdown"},"source":{"efe04f69":"import pandas as pd\ndf = pd.read_csv('\/kaggle\/input\/creditcardfraud\/creditcard.csv')\n\ndf.head()","05b47cbe":"df.info()","99f7271f":"df.drop('Time',axis=1,inplace=True)","a2206194":"import matplotlib.pyplot as plt\n\nprint('-'*30)\nprint('Total rows in data:',df.shape[0])\nprint('-'*30)\nprint(df.Class.value_counts())\nprint('-'*30)\ndf['Class'].value_counts().plot(kind='barh')","9e5854a7":"from sklearn.decomposition import PCA\n\npca = PCA(n_components=2)\nprincipalComponents = pca.fit_transform(df.drop('Class',axis=1))\n\nprincipalDf = pd.DataFrame(data = principalComponents, \n                           columns = ['principal component 1', 'principal component 2'])\nfinal_df = pd.concat([df['Class'], principalDf],axis=1)\nfinal_df.head()","fd5dea49":"from sklearn.model_selection import train_test_split\nX_train,X_test, y_train,y_test = train_test_split(final_df.drop('Class',axis=1), \n                                                  final_df['Class'],\n                                                  test_size=0.2,\n                                                  random_state=100)","f5b571d3":"from imblearn.over_sampling import SMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom collections import Counter\n\nprint('Distribution of y_train set Before over and under sampling: ', Counter(y_train))\n\nunder = RandomUnderSampler(sampling_strategy=0.002)\nover = SMOTE(sampling_strategy=0.01)\n\nX_train_smote, y_train_smote = under.fit_resample(X_train, y_train)\nX_train_both, y_train_both = over.fit_resample(X_train_smote, y_train_smote)\n\nprint('Distribution of y_train set Before over and under sampling: ', Counter(y_train_both))","39f3c968":"from sklearn.linear_model import SGDClassifier\n#from sklearn.model_selection import cross_val_score\n#from sklearn.pipeline import Pipeline\n\nmodel = SGDClassifier()\nmodel.fit(X_train_both, y_train_both)","35299c4e":"from sklearn.metrics import accuracy_score, classification_report, roc_curve\n\nprediction = model.predict(X_test)\nprint('classification report:', classification_report(prediction, y_test))\nprint('-'*40)\nprint('accuracy_score : ',accuracy_score(prediction, y_test))","610a396d":"## Let's use combination of random undersampling and oversampling approach to deal with imbalanced data. \n## I'll be using support vector machine algo.","7bb19f81":"### Using PCA for dimensionality reduction","c6b0abff":"### From above distribution of output we can conclude it is case of extreme imbalanced data.\n### Imbalanced data are problems because in a two-class problem with a class distribution of 90:10, the performance of the classifier on majority-class examples will count nine times as much as the performance on minority-class(in this case it is almost 99:1).\n"}}