{"cell_type":{"774c4252":"code","5cb25102":"code","a24f040b":"code","5ff0727f":"code","14d9f7c8":"code","bf3dd8d6":"code","f391c0fa":"code","46e632d6":"code","d88a9bbb":"code","8f9940d9":"code","045d810d":"code","366f8ddf":"code","75d139c1":"code","455dfeda":"code","ad74be0e":"code","c324d9ee":"code","cf3c09e1":"code","a0cc920a":"code","5e668e0c":"code","8dc5f68f":"code","6639bd19":"code","e02b5519":"code","d48ac8e5":"code","2300f347":"markdown","69b78fb5":"markdown"},"source":{"774c4252":"import pandas as pd\nimport numpy as np\nimport os\nimport random\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing import text\nfrom keras.preprocessing.sequence import pad_sequences\nfrom keras.models import Sequential\nfrom keras.layers import Embedding, Flatten, Dense, LSTM, Dropout, Bidirectional, Conv1D, MaxPooling1D\nfrom keras.utils import to_categorical\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.metrics import accuracy_score","5cb25102":"random.seed(42)","a24f040b":"df = pd.read_csv(\"\/kaggle\/input\/100k-courseras-course-reviews-dataset\/reviews.csv\")","5ff0727f":"df.head()","14d9f7c8":"df[\"split\"] = df.apply(lambda x: \"train\" if random.randrange(0,100) > 10 else \"valid\", axis=1)","bf3dd8d6":"df[\"split\"].value_counts()","f391c0fa":"df_train = df[df[\"split\"] == \"train\"]\ndf_val = df[df[\"split\"] == \"valid\"]","46e632d6":"tokenizer=Tokenizer(oov_token=\"'oov'\")\ntokenizer.fit_on_texts(df_train['Review'])","d88a9bbb":"maxlen = 200\ntrain_X = pad_sequences(tokenizer.texts_to_sequences(df_train['Review']), maxlen=maxlen)\nval_X = pad_sequences(tokenizer.texts_to_sequences(df_val['Review']), maxlen=maxlen)","8f9940d9":"train_Y = df_train[\"Label\"]\nval_Y = df_val[\"Label\"]\ntrain_Y_cat = to_categorical(df_train[\"Label\"]-1, num_classes=5)\nval_Y_cat = to_categorical(df_val[\"Label\"]-1, num_classes=5)","045d810d":"glove_dir=\"\/kaggle\/input\/glove-global-vectors-for-word-representation\/\"\n\nembedding_index = {}\nf = open(os.path.join(glove_dir,'glove.6B.100d.txt'),encoding='utf8')\nfor line in f:\n    values = line.split()\n    word = values[0]\n    coefs = np.asarray(values[1:],dtype='float32')\n    embedding_index[word] = coefs\nf.close()\nprint('Found %s word vectors ' % len(embedding_index))","366f8ddf":"max_words = len(tokenizer.word_index) + 1\nembedding_dim = 100\nembedding_matrix = np.zeros((max_words,embedding_dim))\n\nfor word, idx in tokenizer.word_index.items():\n    embedding_vector = embedding_index.get(word)\n    if embedding_vector is not None:\n        embedding_matrix[idx]=embedding_vector","75d139c1":"model=Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\nmodel.add(Bidirectional(LSTM(32)))\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dense(1, activation=\"linear\"))\nmodel.compile(optimizer=\"Adam\", loss='mean_squared_error', metrics=['mse'])\nprint(model.summary())","455dfeda":"model.fit(train_X, train_Y, epochs=20, batch_size=256, validation_data=(val_X, val_Y))","ad74be0e":"pred = model.predict(val_X)","c324d9ee":"pred_hard = np.array([round(p[0]) for p in pred])","cf3c09e1":"pred_hard[pred_hard < 1] = 1\npred_hard[pred_hard > 5] = 5","a0cc920a":"np.unique(pred_hard)","5e668e0c":"accuracy_score(val_Y, pred_hard)","8dc5f68f":"model=Sequential()\nmodel.add(Embedding(max_words, embedding_dim, input_length=maxlen, weights=[embedding_matrix], trainable=False))\nmodel.add(Bidirectional(LSTM(32)))\nmodel.add(Dense(16, activation=\"relu\"))\nmodel.add(Dense(5, activation=\"softmax\"))\nmodel.compile(optimizer=\"Adam\", loss='categorical_crossentropy', metrics=['accuracy'])\nprint(model.summary())","6639bd19":"model.fit(train_X, train_Y_cat, epochs=20, batch_size=256, validation_data=(val_X, val_Y_cat))","e02b5519":"pred = model.predict(val_X)","d48ac8e5":"accuracy_score(val_Y, [np.argmax(p)+1 for p in pred])","2300f347":"## Regression","69b78fb5":"## Classification"}}