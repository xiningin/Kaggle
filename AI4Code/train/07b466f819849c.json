{"cell_type":{"1b4cc1d2":"code","88a34d69":"code","0a8a3bea":"code","ca31c417":"code","3671a540":"code","27386582":"code","2daf0f4b":"code","a7cc7943":"code","97ea6ce1":"code","ffab9754":"code","c8bc1f58":"code","06b785b6":"code","13db88d5":"code","44c62161":"code","f3d446cc":"code","068c5bde":"code","98505e6f":"code","5e6f1f04":"code","f5a5e778":"code","9c3aea50":"code","cc667c0b":"code","3748d063":"code","c468faed":"code","77905aa8":"markdown","421bc1bd":"markdown","1477bfc7":"markdown","9a48b6bd":"markdown","26eae74d":"markdown","28e48032":"markdown","abaa94aa":"markdown","2fa93619":"markdown","b14c73ae":"markdown"},"source":{"1b4cc1d2":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.feature_selection import SelectKBest, chi2\n\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","88a34d69":"dataset = pd.read_csv('\/kaggle\/input\/indian-candidates-for-general-election-2019\/LS_2.0.csv')\ndataset.head()","0a8a3bea":"dataset.info()","ca31c417":"dataset.describe()","3671a540":"dataset.shape","27386582":"# rename invalid column names\ndataset = dataset.rename(columns={'CRIMINAL\\nCASES': 'CRIMINAL_CASES', 'GENERAL\\nVOTES': 'GENERAL_VOTES', 'POSTAL\\nVOTES': 'POSTAL_VOTES', 'TOTAL\\nVOTES': 'TOTAL_VOTES', 'OVER TOTAL ELECTORS \\nIN CONSTITUENCY': 'OVER_TOTAL_ELECTORS_IN_CONSTITUENCY', 'OVER TOTAL VOTES POLLED \\nIN CONSTITUENCY': 'OVER_TOTAL_VOTES_POLLED_IN_CONSTITUENCY', 'TOTAL ELECTORS': 'TOTAL_ELECTORS'})\n\n# drop rows with NA values\ndataset = dataset[dataset['GENDER'].notna()]\n\n# replace Nil values with 0\ndataset['ASSETS'] = dataset['ASSETS'].replace(['Nil', '`', 'Not Available'], '0')\ndataset['LIABILITIES'] = dataset['LIABILITIES'].replace(['NIL', '`', 'Not Available'], '0')\ndataset['CRIMINAL_CASES'] = dataset['CRIMINAL_CASES'].replace(['Not Available'], '0')\n\n# clean ASSETS and LIABILITIES column values\ndataset['ASSETS'] = dataset['ASSETS'].map(lambda x: x.lstrip('Rs ').split('\\n')[0].replace(',', ''))\ndataset['LIABILITIES'] = dataset['LIABILITIES'].map(lambda x: x.lstrip('Rs ').split('\\n')[0].replace(',', ''))\n\n# convert ASSETS, LIABILITIES and CRIMINAL_CASES column values into numeric\ndataset['ASSETS'] = dataset['ASSETS'].astype(str).astype(float)\ndataset['LIABILITIES'] = dataset['LIABILITIES'].astype(str).astype(float)\ndataset['CRIMINAL_CASES'] = dataset['CRIMINAL_CASES'].astype(str).astype(int)\n\n# reorder columns\ncols = dataset.columns.tolist()\ncols = cols[0:3] + cols[4:] + cols[3:4]\ndataset = dataset[cols]","2daf0f4b":"dataset.head()\n\ndataset.isna().sum()","a7cc7943":"dataset['PARTY'].value_counts()","97ea6ce1":"# change party of the less frequent parties as Other\n# 'BJP','INC','IND','BSP', 'CPI(M)', 'AITC', 'MNM': high frequent\n# 'TDP', 'VSRCP', 'SP', 'DMK', 'BJD': medium frequent\n\ndataset.loc[~dataset[\"PARTY\"].isin(['BJP','INC','IND','BSP', 'CPI(M)', 'AITC', 'MNM', 'TDP', 'VSRCP', 'SP', 'DMK', 'BJD']), \"PARTY\"] = \"Other\"\ndataset['PARTY'].value_counts()\n","ffab9754":"dataset['CATEGORY'].value_counts()","c8bc1f58":"dataset['EDUCATION'].value_counts()","06b785b6":"# encode education column\nencoded_edu = []\n\n# iterate through each row in the dataset\nfor row in dataset.itertuples():\n    education = row.EDUCATION\n\n    if education == \"Illiterate\":\n        encoded_edu.append(0)\n    elif education == \"Literate\":\n        encoded_edu.append(1)\n    elif education == \"5th Pass\":\n        encoded_edu.append(2)\n    elif education == \"8th Pass\":\n        encoded_edu.append(3)\n    elif education == \"10th Pass\":\n        encoded_edu.append(4)\n    elif education == \"12th Pass\":\n        encoded_edu.append(7)\n    elif education == \"Graduate\":\n        encoded_edu.append(8)\n    elif education == \"Post Graduate\":\n        encoded_edu.append(9)\n    elif education == \"Graduate Professional\":\n        encoded_edu.append(10)\n    elif education == \"Doctorate\":\n        encoded_edu.append(11)\n    else:\n        encoded_edu.append(5)\n\ndataset['EDUCATION'] = encoded_edu\n","13db88d5":"# Preparing feature values\n\ncons_per_state = {}\nvoters_per_state = {}\n\nparty_winningSeats = {}\nparty_criminal = {}\nparty_education = {}\n\nparty_totalCandidates_per_cons = {}\nparty_winningSeats_per_cons = {}\nparty_criminal_per_cons = {}\nparty_education_per_cons = {}\n\nvoters_per_cons = {}\n\n\n# group by state\nsubset = dataset[['STATE', 'CONSTITUENCY', 'TOTAL_ELECTORS']]\ngk = subset.groupby('STATE')\n\n# for each state\nfor name,group in gk:\n    # total constituencies per state\n    cons_per_state[name] = len(group)\n    \n    # total voters per state\n    voters_per_state[name] = group['TOTAL_ELECTORS'].sum()\n\n\n# group by party\nsubset = dataset[['PARTY', 'CONSTITUENCY', 'CRIMINAL_CASES', 'EDUCATION', 'WINNER']]\ngk = subset.groupby('PARTY')\n\n# for each party\nfor name,group in gk:\n    # winning seats by party\n    party_winningSeats[name] = group[group['WINNER'] == 1.0].shape[0]\n    \n    # criminal cases by party\n    party_criminal[name] = group['CRIMINAL_CASES'].sum()\n    \n    # education qualification by party (sum of candidates)\n    party_education[name] = group['EDUCATION'].sum()\n    \n    # group by constituency\n    gk2 = group.groupby('CONSTITUENCY')\n    \n    # for each constituency\n    for name2, group2 in gk2:\n        key = name2 + '_' + name    # cons_party\n        \n        # total candidates by party in constituency\n        party_totalCandidates_per_cons[key] = len(group2)\n        \n        # party winning seats in the constituency\n        party_winningSeats_per_cons[key] = group2[group2['WINNER'] == 1.0].shape[0]\n        \n        # criminal cases by party in the constituency\n        party_criminal_per_cons[key] = group2['CRIMINAL_CASES'].sum()\n\n        # education qualification by party in constituency (sum of candidates)\n        party_education_per_cons[key] = group2['EDUCATION'].sum()\n\n\n# Total voters per constituency\nsubset = dataset[['CONSTITUENCY', 'TOTAL_ELECTORS']]\ngk = subset.groupby('CONSTITUENCY')\n\n# for each constituency\nfor name,group in gk:\n    voters_per_cons[name] = len(group)\n","44c62161":"# Applying feature values\n\n# new feature columns\ntotal_cons_per_state = []\ntotal_voters_per_state = []\ntotal_voters_per_cons = []\n\nwinning_seats_by_party = []\ncriminal_by_party = []\neducation_by_party = []\n\ntotal_candidates_by_party_per_cons = []\nwinning_seats_by_party_per_cons = []\ncriminal_by_party_per_cons = []\neducation_by_party_per_cons = []\n\n\n# iterate through each row in the dataset\nfor row in dataset.itertuples():\n    subkey = row.CONSTITUENCY + '_' + row.PARTY\n\n    total_cons_per_state.append(cons_per_state.get(row.STATE))\n    total_voters_per_state.append(voters_per_state.get(row.STATE))\n    total_voters_per_cons.append(voters_per_cons.get(row.CONSTITUENCY))\n    winning_seats_by_party.append(party_winningSeats.get(row.PARTY))\n    criminal_by_party.append(party_criminal.get(row.PARTY))\n    education_by_party.append(party_education.get(row.PARTY))\n    total_candidates_by_party_per_cons.append(party_totalCandidates_per_cons.get(subkey))\n    winning_seats_by_party_per_cons.append(party_winningSeats_per_cons.get(subkey))\n    criminal_by_party_per_cons.append(party_criminal_per_cons.get(subkey))\n    education_by_party_per_cons.append(party_education_per_cons.get(subkey))\n\n\n# append columns to dataset\ndataset['total_cons_per_state'] = total_cons_per_state\ndataset['total_voters_per_state'] = total_voters_per_state\ndataset['total_voters_per_cons'] = total_voters_per_cons\ndataset['winning_seats_by_party'] = winning_seats_by_party\ndataset['criminal_by_party'] = criminal_by_party\ndataset['education_by_party'] = education_by_party\ndataset['total_candidates_by_party_per_cons'] = total_candidates_by_party_per_cons\ndataset['winning_seats_by_party_per_cons'] = winning_seats_by_party_per_cons\ndataset['criminal_by_party_per_cons'] = criminal_by_party_per_cons\ndataset['education_by_party_per_cons'] = education_by_party_per_cons\n","f3d446cc":"# label encode categorical columns\n\nlblEncoder_state = LabelEncoder()\nlblEncoder_state.fit(dataset['STATE'])\ndataset['STATE'] = lblEncoder_state.transform(dataset['STATE'])\n\nlblEncoder_cons = LabelEncoder()\nlblEncoder_cons.fit(dataset['CONSTITUENCY'])\ndataset['CONSTITUENCY'] = lblEncoder_cons.transform(dataset['CONSTITUENCY'])\n\nlblEncoder_name = LabelEncoder()\nlblEncoder_name.fit(dataset['NAME'])\ndataset['NAME'] = lblEncoder_name.transform(dataset['NAME'])\n\nlblEncoder_party = LabelEncoder()\nlblEncoder_party.fit(dataset['PARTY'])\ndataset['PARTY'] = lblEncoder_party.transform(dataset['PARTY'])\n\nlblEncoder_symbol = LabelEncoder()\nlblEncoder_symbol.fit(dataset['SYMBOL'])\ndataset['SYMBOL'] = lblEncoder_symbol.transform(dataset['SYMBOL'])\n\nlblEncoder_gender = LabelEncoder()\nlblEncoder_gender.fit(dataset['GENDER'])\ndataset['GENDER'] = lblEncoder_gender.transform(dataset['GENDER'])\n\nlblEncoder_category = LabelEncoder()\nlblEncoder_category.fit(dataset['CATEGORY'])\ndataset['CATEGORY'] = lblEncoder_category.transform(dataset['CATEGORY'])\n","068c5bde":"# scaling values into 0-1 range\n\nscaler = MinMaxScaler(feature_range=(0, 1))\nfeatures = [\n    'STATE', 'CONSTITUENCY', 'NAME', 'PARTY', 'SYMBOL', 'GENDER', 'CRIMINAL_CASES', 'AGE', 'CATEGORY', 'EDUCATION', 'ASSETS', 'LIABILITIES', 'GENERAL_VOTES', 'POSTAL_VOTES', 'TOTAL_VOTES', 'OVER_TOTAL_ELECTORS_IN_CONSTITUENCY', 'OVER_TOTAL_VOTES_POLLED_IN_CONSTITUENCY', 'TOTAL_ELECTORS',\n     'total_cons_per_state', 'total_voters_per_state', 'total_voters_per_cons', 'winning_seats_by_party', 'criminal_by_party', 'education_by_party', 'total_candidates_by_party_per_cons', 'winning_seats_by_party_per_cons', 'criminal_by_party_per_cons', 'education_by_party_per_cons'\n]\n\ndataset[features] = scaler.fit_transform(dataset[features])\n","98505e6f":"# separate train features and label\ny = dataset[\"WINNER\"]\nX = dataset.drop(labels=[\"WINNER\"], axis=1)\n","5e6f1f04":"# apply SelectKBest class to extract top most features\nbestfeatures = SelectKBest(score_func=chi2, k=10)\nfit = bestfeatures.fit(X, y)\ndfscores = pd.DataFrame(fit.scores_)\ndfcolumns = pd.DataFrame(X.columns)\n\n# concat two dataframes for better visualization \nfeatureScores = pd.concat([dfcolumns, dfscores], axis=1)\nfeatureScores.columns = ['Specs', 'Score']\nprint(featureScores.nlargest(30, 'Score'))\n","f5a5e778":"# remove unnecessary columns\n\nX.drop(labels=[\"NAME\"], axis=1, inplace=True)\nX.drop(labels=[\"SYMBOL\"], axis=1, inplace=True)\nX.drop(labels=[\"POSTAL_VOTES\"], axis=1, inplace=True)\nX.drop(labels=[\"GENERAL_VOTES\"], axis=1, inplace=True)\n\nX.drop(labels=[\"TOTAL_ELECTORS\"], axis=1, inplace=True)\nX.drop(labels=[\"STATE\"], axis=1, inplace=True)\nX.drop(labels=[\"CONSTITUENCY\"], axis=1, inplace=True)\nX.drop(labels=[\"GENDER\"], axis=1, inplace=True)\nX.drop(labels=[\"criminal_by_party_per_cons\"], axis=1, inplace=True)\nX.drop(labels=[\"total_voters_per_state\"], axis=1, inplace=True)\nX.drop(labels=[\"CRIMINAL_CASES\"], axis=1, inplace=True)\nX.drop(labels=[\"total_cons_per_state\"], axis=1, inplace=True)\nX.drop(labels=[\"EDUCATION\"], axis=1, inplace=True)\nX.drop(labels=[\"education_by_party_per_cons\"], axis=1, inplace=True)\nX.drop(labels=[\"AGE\"], axis=1, inplace=True)\n","9c3aea50":"# split dataset into train and test data\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)\n","cc667c0b":"knn = KNeighborsClassifier()\nknn.fit(X_train, y_train)","3748d063":"knn.predict(X_test)\nprint(\"Testing Accuracy is: \", knn.score(X_test, y_test)*100, \"%\")","c468faed":"figsize=(18,14)\nfig, ax = plt.subplots(figsize=figsize)\nsns.heatmap(dataset.corr(), annot=True, fmt=\".2f\", cmap=\"coolwarm\", ax=ax)\n\n## just to visualize correlated features","77905aa8":"## Label Encoding and Normalization","421bc1bd":"## Train and Test the Model","1477bfc7":"## Creating New Feature Columns","9a48b6bd":"## Reading the Dataset","26eae74d":"## Correlation Matrix","28e48032":"## Spliting Dataset into Training and Testing","abaa94aa":"## Cleaning the Dataset","2fa93619":"## Basic Feature Engineering","b14c73ae":"## Feature Importance"}}