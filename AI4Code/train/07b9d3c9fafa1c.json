{"cell_type":{"ecabffac":"code","088ed749":"code","22b16ebf":"code","735f2dcb":"code","f29f6a24":"code","2f6f4d5b":"code","82a97528":"code","3e51028e":"code","b9304d15":"code","79144342":"code","ca326d5a":"code","067c481b":"code","e343c91f":"code","d79cc763":"code","3b99b7a2":"code","009fc1d9":"code","dd67eec7":"code","ee8704dc":"code","4e0d53ab":"code","365982aa":"code","c91ede55":"code","1e13659d":"code","7c2a3f73":"code","85cae7d8":"code","2a188673":"code","fda1b927":"code","9ff2e528":"code","8a12ed2e":"code","d06a667c":"code","1d3b2cdc":"code","aa7993eb":"code","3213f479":"code","22d4d418":"code","3da8e6ec":"code","bb175263":"code","b4316b44":"code","41a0ddb3":"code","6ffe59ee":"code","00096f92":"code","9c013528":"code","a4fab5d6":"markdown","9316caf2":"markdown","a2d7bc25":"markdown","d3aefaf1":"markdown","f766f030":"markdown","df3e005a":"markdown","4720ea9e":"markdown","412a0f87":"markdown","c5935020":"markdown","f7b682fc":"markdown","b4e05080":"markdown","824683c0":"markdown","85490080":"markdown","48a2be1d":"markdown","33742d79":"markdown","94ac973e":"markdown","145ed15a":"markdown","3e89cd2e":"markdown","97f61c38":"markdown","b4da1ca5":"markdown","df938149":"markdown","d677b2e7":"markdown","148c378e":"markdown","4235f1f8":"markdown","3fdd7574":"markdown","aff831c0":"markdown","656ca903":"markdown","1f718aa7":"markdown","8751f66a":"markdown","559e6fb6":"markdown","0fb19261":"markdown","f09ecc77":"markdown","592ffcbd":"markdown"},"source":{"ecabffac":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom glob import glob\nimport os\nimport matplotlib.gridspec as gridspec\nimport matplotlib.ticker as ticker\nsns.set_style('whitegrid')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')","088ed749":"# reading the data\ndata = pd.read_csv(\"..\/input\/Data_Entry_2017.csv\")\ndata.head()","22b16ebf":"data.shape","735f2dcb":"data.describe()","f29f6a24":"#drop unused columns\ndata = data[['Image Index','Finding Labels','Follow-up #','Patient ID','Patient Age','Patient Gender']]\n\n# removing the rows which have patient_age >100\ntotal = len(data)\nprint('No. of rows before removing rows having age >100 : ',len(data))\ndata = data[data['Patient Age']<100]\nprint('No. of rows after removing rows having age >100 : ',len(data))\nprint('No. of datapoints having age > 100 : ',total-len(data))","2f6f4d5b":"# rows having no. of disease\ndata['Labels_Count'] = data['Finding Labels'].apply(lambda text: len(text.split('|')) if(text != 'No Finding') else 0)","82a97528":"label_counts = data['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)","3e51028e":"#plt.figure(figsize=(20,15))\nsns.FacetGrid(data,hue='Patient Gender',size=5).map(sns.distplot,'Patient Age').add_legend()\nplt.show()","b9304d15":"g = sns.factorplot(x=\"Patient Age\", col=\"Patient Gender\",data=data, kind=\"count\",size=10, aspect=0.8,palette=\"GnBu_d\");\ng.set_xticklabels(np.arange(0,100));\ng.set_xticklabels(step=10);\ng.fig.suptitle('Age distribution by sex',fontsize=22);\ng.fig.subplots_adjust(top=.9)","79144342":"f, axarr = plt.subplots(7, 2, sharex=True,figsize=(15, 20))\npathology_list = ['Cardiomegaly','Emphysema','Effusion','Hernia','Nodule','Pneumothorax','Atelectasis','Pleural_Thickening','Mass','Edema','Consolidation','Infiltration','Fibrosis','Pneumonia']\ndf = data[data['Finding Labels'] != 'No Finding']\ni=0\nj=0\nx=np.arange(0,100,10)\nfor pathology in pathology_list :\n    index = []\n    for k in range(len(df)):\n        if pathology in df.iloc[k]['Finding Labels']:\n            index.append(k)\n    g=sns.countplot(x='Patient Age', hue=\"Patient Gender\",data=df.iloc[index], ax=axarr[i, j])\n    axarr[i, j].set_title(pathology)   \n    g.set_xlim(0,90)\n    g.set_xticks(x)\n    g.set_xticklabels(x)\n    j=(j+1)%2\n    if j==0:\n        i=(i+1)%7\nf.subplots_adjust(hspace=0.3)","ca326d5a":"for pathology in pathology_list :\n    data[pathology] = data['Finding Labels'].apply(lambda x: 1 if pathology in x else 0)","067c481b":"plt.figure(figsize=(15,10))\ngs = gridspec.GridSpec(8,1)\nax1 = plt.subplot(gs[:7, :])\nax2 = plt.subplot(gs[7, :])\ndata1 = pd.melt(data,\n             id_vars=['Patient Gender'],\n             value_vars = list(pathology_list),\n             var_name = 'Category',\n             value_name = 'Count')\ndata1 = data1.loc[data1.Count>0]\ng=sns.countplot(y='Category',hue='Patient Gender',data=data1, ax=ax1, order = data1['Category'].value_counts().index)\nax1.set( ylabel=\"\",xlabel=\"\")\nax1.legend(fontsize=20)\nax1.set_title('X Ray partition (total number = 121120)',fontsize=18);\n\ndata['Nothing']=data['Finding Labels'].apply(lambda x: 1 if 'No Finding' in x else 0)\n\ndata2 = pd.melt(data,\n             id_vars=['Patient Gender'],\n             value_vars = list(['Nothing']),\n             var_name = 'Category',\n             value_name = 'Count')\ndata2 = data2.loc[data2.Count>0]\ng=sns.countplot(y='Category',hue='Patient Gender',data=data2,ax=ax2)\nax2.set( ylabel=\"\",xlabel=\"Number of decease\")\nax2.legend('')\nplt.subplots_adjust(hspace=.5)","e343c91f":"f, (ax1,ax2) = plt.subplots( 2, figsize=(15, 10))\n\ndf = data[data['Follow-up #']<15]\ng = sns.countplot(x='Follow-up #',data=df,palette=\"GnBu_d\",ax=ax1);\n\nax1.set_title('Follow-up distribution');\ndf = data[data['Follow-up #']>14]\ng = sns.countplot(x='Follow-up #',data=df,palette=\"GnBu_d\",ax=ax2);\nx=np.arange(15,100,10)\ng.set_ylim(15,450)\ng.set_xlim(15,100)\ng.set_xticks(x)\ng.set_xticklabels(x)\nf.subplots_adjust(top=1)","d79cc763":"df=data.groupby('Finding Labels').count().sort_values('Patient ID',ascending=False)\ndf1=df[['|' in index for index in df.index]].copy()\ndf2=df[['|' not in index for index in df.index]]\ndf2=df2[['No Finding' not in index for index in df2.index]]\ndf2['Finding Labels']=df2.index.values\ndf1['Finding Labels']=df1.index.values","3b99b7a2":"f, ax = plt.subplots(sharex=True,figsize=(15, 10))\nsns.set_color_codes(\"pastel\")\ng=sns.countplot(y='Category',data=data1, ax=ax, order = data1['Category'].value_counts().index,color='b',label=\"Multiple Pathologies\")\nsns.set_color_codes(\"muted\")\ng=sns.barplot(x='Patient ID',y='Finding Labels',data=df2, ax=ax, color=\"b\",label=\"Simple Pathology\")\nax.legend(ncol=2, loc=\"center right\", frameon=True,fontsize=20)\nax.set( ylabel=\"\",xlabel=\"Number of decease\")\nax.set_title(\"Comparaison between simple or multiple decease\",fontsize=20)      \nsns.despine(left=True)","009fc1d9":"#we just keep groups of pathologies which appear more than 30 times\ndf3=df1.loc[df1['Patient ID']>30,['Patient ID','Finding Labels']]\n\nfor pathology in pathology_list:\n    df3[pathology]=df3.apply(lambda x: x['Patient ID'] if pathology in x['Finding Labels'] else 0, axis=1)\n\ndf3.head(20)","dd67eec7":"#'Hernia' has not enough values to figure here\ndf4=df3[df3['Hernia']>0]  # df4.size == 0\n#remove 'Hernia' from list\npat_list=[elem for elem in pathology_list if 'Hernia' not in elem]\n\nf, axarr = plt.subplots(13, sharex=True,figsize=(10, 140))\ni=0\nfor pathology in pat_list :\n    df4=df3[df3[pathology]>0]\n    if df4.size>0:  #'Hernia' has not enough values to figure here\n        axarr[i].pie(df4[pathology],labels=df4['Finding Labels'], autopct='%1.1f%%')\n        axarr[i].set_title('main desease : '+pathology,fontsize=14)   \n        i +=1\n","ee8704dc":"data = pd.read_csv('..\/input\/Data_Entry_2017.csv')\ndata = data[data['Patient Age']<100] #removing datapoints which having age greater than 100\ndata_image_paths = {os.path.basename(x): x for x in \n                   glob(os.path.join('..', 'input', 'images*', '*', '*.png'))}\nprint('Scans found:', len(data_image_paths), ', Total Headers', data.shape[0])\ndata['path'] = data['Image Index'].map(data_image_paths.get)\ndata['Patient Age'] = data['Patient Age'].map(lambda x: int(x))\ndata.sample(3)","4e0d53ab":"data['Finding Labels'] = data['Finding Labels'].map(lambda x: x.replace('No Finding', ''))\nfrom itertools import chain\nall_labels = np.unique(list(chain(*data['Finding Labels'].map(lambda x: x.split('|')).tolist())))\nall_labels = [x for x in all_labels if len(x)>0]\nprint('All Labels ({}): {}'.format(len(all_labels), all_labels))\nfor c_label in all_labels:\n    if len(c_label)>1: # leave out empty labels\n        data[c_label] = data['Finding Labels'].map(lambda finding: 1.0 if c_label in finding else 0)\ndata.sample(3)","365982aa":"# keep at least 1000 cases\nMIN_CASES = 1000\nall_labels = [c_label for c_label in all_labels if data[c_label].sum()>MIN_CASES]\nprint('Clean Labels ({})'.format(len(all_labels)), \n      [(c_label,int(data[c_label].sum())) for c_label in all_labels])\n","c91ede55":"# since the dataset is very unbiased, we can resample it to be a more reasonable collection\n# weight is 0.04 + number of findings\nsample_weights = data['Finding Labels'].map(lambda x: len(x.split('|')) if len(x)>0 else 0).values + 4e-2\nsample_weights \/= sample_weights.sum()\ndata = data.sample(40000, weights=sample_weights)\n\nlabel_counts = data['Finding Labels'].value_counts()[:15]\nfig, ax1 = plt.subplots(1,1,figsize = (12, 8))\nax1.bar(np.arange(len(label_counts))+0.5, label_counts)\nax1.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax1.set_xticklabels(label_counts.index, rotation = 90)\n","1e13659d":"# creating vector of diseases\ndata['disease_vec'] = data.apply(lambda x: [x[all_labels].values], 1).map(lambda x: x[0])\n","7c2a3f73":"data.iloc[0]['disease_vec']","85cae7d8":"from sklearn.model_selection import train_test_split\ntrain_df, valid_df = train_test_split(data, \n                                   test_size = 0.25, \n                                   random_state = 2018,\n                                   stratify = data['Finding Labels'].map(lambda x: x[:4]))\nprint('train', train_df.shape[0], 'validation', valid_df.shape[0])","2a188673":"from keras.preprocessing.image import ImageDataGenerator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(samplewise_center=True, \n                              samplewise_std_normalization=True, \n                              horizontal_flip = True, \n                              vertical_flip = False, \n                              height_shift_range= 0.05, \n                              width_shift_range=0.1, \n                              rotation_range=5, \n                              shear_range = 0.1,\n                              fill_mode = 'reflect',\n                              zoom_range=0.15)","fda1b927":"def flow_from_dataframe(img_data_gen, in_df, path_col, y_col, **dflow_args):\n    base_dir = os.path.dirname(in_df[path_col].values[0])\n    print('## Ignore next message from keras, values are replaced anyways')\n    df_gen = img_data_gen.flow_from_directory(base_dir, \n                                     class_mode = 'sparse',\n                                    **dflow_args)\n    df_gen.filenames = in_df[path_col].values\n    df_gen.classes = np.stack(in_df[y_col].values)\n    df_gen.samples = in_df.shape[0]\n    df_gen.n = in_df.shape[0]\n    df_gen._set_index_array()\n    df_gen.directory = '' # since we have the full path\n    print('Reinserting dataframe: {} images'.format(in_df.shape[0]))\n    return df_gen\n","9ff2e528":"train_gen = flow_from_dataframe(core_idg, train_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 32)\n\nvalid_gen = flow_from_dataframe(core_idg, valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 256) # we can use much larger batches for evaluation\n# used a fixed dataset for evaluating the algorithm\ntest_X, test_Y = next(flow_from_dataframe(core_idg, \n                               valid_df, \n                             path_col = 'path',\n                            y_col = 'disease_vec', \n                            target_size = IMG_SIZE,\n                             color_mode = 'grayscale',\n                            batch_size = 1024)) # one big batch","8a12ed2e":"t_x, t_y = next(train_gen)\nfig, m_axs = plt.subplots(4, 4, figsize = (16, 16))\nfor (c_x, c_y, c_ax) in zip(t_x, t_y, m_axs.flatten()):\n    c_ax.imshow(c_x[:,:,0], cmap = 'bone', vmin = -1.5, vmax = 1.5)\n    c_ax.set_title(', '.join([n_class for n_class, n_score in zip(all_labels, c_y) \n                             if n_score>0.5]))\n    c_ax.axis('off')","d06a667c":"from keras.applications.mobilenet import MobileNet\nfrom keras.layers import GlobalAveragePooling2D, Dense, Dropout, Flatten\nfrom keras.models import Sequential\nmobilenet_model = MobileNet(input_shape =  t_x.shape[1:], \n                                 include_top = False, weights = None)\nmulti_disease_model = Sequential()\nmulti_disease_model.add(mobilenet_model)\nmulti_disease_model.add(GlobalAveragePooling2D())\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(512))\nmulti_disease_model.add(Dropout(0.5))\nmulti_disease_model.add(Dense(len(all_labels), activation = 'sigmoid'))\nmulti_disease_model.compile(optimizer = 'adam', loss = 'binary_crossentropy',\n                           metrics = ['binary_accuracy', 'mae'])\nmulti_disease_model.summary()","1d3b2cdc":"from keras.callbacks import ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\nweight_path=\"{}_weights.best.hdf5\".format('xray_class')\n\ncheckpoint = ModelCheckpoint(weight_path, monitor='val_loss', verbose=1, \n                             save_best_only=True, mode='min', save_weights_only = True)\n\nearly = EarlyStopping(monitor=\"val_loss\", \n                      mode=\"min\", \n                      patience=3)\ncallbacks_list = [checkpoint, early]","aa7993eb":"multi_disease_model.fit_generator(train_gen, \n                                  steps_per_epoch=100,\n                                  validation_data = (test_X, test_Y), \n                                  epochs = 10, \n                                  callbacks = callbacks_list)","3213f479":"for c_label, s_count in zip(all_labels, 100*np.mean(test_Y,0)):\n    print('%s: %2.2f%%' % (c_label, s_count))","22d4d418":"pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)","3da8e6ec":"from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('barely_trained_net.png')","bb175263":"multi_disease_model.fit_generator(train_gen, \n                                  steps_per_epoch = 100,\n                                  validation_data =  (test_X, test_Y), \n                                  epochs = 5, \n                                  callbacks = callbacks_list)","b4316b44":"# load the best weights\nmulti_disease_model.load_weights(weight_path)","41a0ddb3":"pred_Y = multi_disease_model.predict(test_X, batch_size = 32, verbose = True)","6ffe59ee":"# look at how often the algorithm predicts certain diagnoses \nfor c_label, p_count, t_count in zip(all_labels, \n                                     100*np.mean(pred_Y,0), \n                                     100*np.mean(test_Y,0)):\n    print('%s: Dx: %2.2f%%, PDx: %2.2f%%' % (c_label, t_count, p_count))","00096f92":"from sklearn.metrics import roc_curve, auc\nfig, c_ax = plt.subplots(1,1, figsize = (9, 9))\nfor (idx, c_label) in enumerate(all_labels):\n    fpr, tpr, thresholds = roc_curve(test_Y[:,idx].astype(int), pred_Y[:,idx])\n    c_ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (c_label, auc(fpr, tpr)))\nc_ax.legend()\nc_ax.set_xlabel('False Positive Rate')\nc_ax.set_ylabel('True Positive Rate')\nfig.savefig('trained_net.png')","9c013528":"sickest_idx = np.argsort(np.sum(test_Y, 1)<1)\nfig, m_axs = plt.subplots(4, 2, figsize = (16, 32))\nfor (idx, c_ax) in zip(sickest_idx, m_axs.flatten()):\n    c_ax.imshow(test_X[idx, :,:,0], cmap = 'bone')\n    stat_str = [n_class[:6] for n_class, n_score in zip(all_labels, \n                                                                  test_Y[idx]) \n                             if n_score>0.5]\n    pred_str = ['%s:%2.0f%%' % (n_class[:4], p_score*100)  for n_class, n_score, p_score in zip(all_labels, \n                                                                  test_Y[idx], pred_Y[idx]) \n                             if (n_score>0.5) or (p_score>0.5)]\n    c_ax.set_title('Dx: '+', '.join(stat_str)+'\\nPDx: '+', '.join(pred_str))\n    c_ax.axis('off')\nfig.savefig('trained_img_predictions.png')","a4fab5d6":"### Create a simple model\n\nHere we make a simple model to train using MobileNet as a base and then adding a GAP layer (Flatten could also be added), dropout, and a fully-connected layer to calculate specific features\n","9316caf2":"<h3> 3.3.3 No. of each disease by patient gender <\/h3>","a2d7bc25":"<h3> 3.3.4 Display patient number by Follow-up in details <\/h3>","d3aefaf1":"### ROC Curves\n\nWhile a very oversimplified metric, we can show the ROC curve for each metric\n","f766f030":"<h3> 3.3.6 Plot most important pathologies groups for each desease <\/h3>","df3e005a":"### Continued Training\n\nNow we do a much longer training process to see how the results improve\n","4720ea9e":"### Show a few images and associated predictions","412a0f87":"<h1>1. Business Problem <\/h1>","c5935020":"### First Round\n\nHere we do a first round of training to get a few initial low hanging fruit results\n","f7b682fc":"### Data limitations:\n- 1. The image labels are NLP extracted so there could be some erroneous labels but the NLP labeling accuracy is estimated to be >90%.\n - 2. Very limited numbers of disease region bounding boxes (See BBox_list_2017.csv)\n - .Chest x-ray radiology reports are not anticipated to be publicly shared. Parties who use this public dataset are encouraged to share their \u201cupdated\u201d image labels and\/or new bounding boxes in their own studied later, maybe through manual annotation\n","b4e05080":"<h3> 3.3.2 Disease distribution by age and sex <\/h3>","824683c0":"<h1> 4. Creating data for model <\/h1>","85490080":"<h2> 3.2 Data cleaning <\/h2>","48a2be1d":"#### Observation - Both the gender have almost same distribution","33742d79":"\n### Goal\n\nThe goal is to use a simple model to classify x-ray images in Keras, the notebook how to use the flow_from_dataframe to deal with messier datasets\n","94ac973e":"<h2> 3.1 Data Loading <\/h2>","145ed15a":"<h1> 3. Exploratory Data Analysis <\/h1>","3e89cd2e":"<h3> 3.3.1 Age distribution <\/h3>","97f61c38":"<h2> 1.3 Real World \/ Business Objectives and Constraints <\/h2>","b4da1ca5":"# NIH Chest X-ray Dataset","df938149":"**Class descriptions**\n\nThere are 15 classes (14 diseases, and one for \"No findings\"). Images can be classified as \"No findings\" or one or more disease classes:\n\n- Atelectasis\n- Consolidation\n- Infiltration\n- Pneumothorax\n- Edema\n- Emphysema\n- Fibrosis\n- Effusion\n- Pneumonia\n- Pleural_thickening\n- Cardiomegaly\n-  Nodule Mass\n-  Hernia\n","d677b2e7":"<h2> 3.3 Data analysis <\/h2>","148c378e":"**BBox_list_2017.csv: **Bounding box coordinates. Note: Start at x,y, extend horizontally w pixels, and vertically h pixels\n\n- Image Index: File name\n- Finding Label: Disease type (Class label)\n- Bbox x\n- Bbox y\n- Bbox w\n- Bbox h","4235f1f8":"<h2> 1.1 Description <\/h2>","3fdd7574":"<h3> 3.3.5 ratio between one and multiple disease <\/h3>","aff831c0":"**Data_entry_2017.csv:** Class labels and patient data for the entire dataset\n- Image Index: File name\n- Finding Labels: Disease type (Class label)\n- Follow-up #\n- Patient ID\n- Patient Age\n- Patient Gender\n- View Position: X-ray orientation\n- OriginalImageWidth\n- OriginalImageHeight\n- OriginalImagePixelSpacing_x\n- OriginalImagePixelSpacing_y","656ca903":"Data Source : https:\/\/www.kaggle.com\/nih-chest-xrays\/data\/home <br>\nResearch paper : http:\/\/openaccess.thecvf.com\/content_cvpr_2017\/papers\/Wang_ChestX-ray8_Hospital-Scale_Chest_CVPR_2017_paper.pdf <br>\nResearch paper : https:\/\/lukeoakdenrayner.wordpress.com\/2017\/12\/18\/the-chestxray14-dataset-problems\/ <br>\nResearch paper : https:\/\/arxiv.org\/pdf\/1711.05225.pdf <br>\nBlog : https:\/\/lukeoakdenrayner.wordpress.com\/2018\/01\/24\/chexnet-an-in-depth-review\/","1f718aa7":"<h2> 2.1 Data <\/h2>","8751f66a":"- 1. No strict latency constraints.","559e6fb6":"<h2> 1.2 Source \/ useful links <\/h2>","0fb19261":"### Check Output\n\nHere we see how many positive examples we have of each category\n","f09ecc77":"### File contents\nImage format: 112,120 total images with size 1024 x 1024","592ffcbd":"## National Institutes of Health Chest X-Ray Dataset\n\nChest X-ray exams are one of the most frequent and cost-effective medical imaging examinations available. However, clinical diagnosis of a chest X-ray can be challenging and sometimes more difficult than diagnosis via chest CT imaging. The lack of large publicly available datasets with annotations means it is still very difficult, if not impossible, to achieve clinically relevant computer-aided detection and diagnosis (CAD) in real world medical sites with chest X-rays. One major hurdle in creating large X-ray image datasets is the lack resources for labeling so many images. Prior to the release of this dataset, Openi was the largest publicly available source of chest X-ray images with 4,143 images available.\n\nThis NIH Chest X-ray Dataset is comprised of 112,120 X-ray images with disease labels from 30,805 unique patients. To create these labels, the authors used Natural Language Processing to text-mine disease classifications from the associated radiological reports. The labels are expected to be >90% accurate and suitable for weakly-supervised learning. The original radiology reports are not publicly available but you can find more details on the labeling process in this Open Access paper: \"ChestX-ray8: Hospital-scale Chest X-ray Database and Benchmarks on Weakly-Supervised Classification and Localization of Common Thorax Diseases.\" (Wang et al.)"}}