{"cell_type":{"3352ea49":"code","1aef8fe5":"code","c6a2cbc8":"code","8bd1d24f":"code","2a5b1b01":"code","83f1273a":"code","c51fa1b9":"code","19824a62":"code","bed50164":"code","e69eed7f":"code","4fe9155c":"markdown","80f9162b":"markdown","f105b3a2":"markdown","d7da273c":"markdown","3eecbb44":"markdown","61efa6e1":"markdown","357d3b03":"markdown","bff18c8f":"markdown","f10f1614":"markdown","38d95c73":"markdown","fee9f329":"markdown","209f2952":"markdown","fc71e6b2":"markdown"},"source":{"3352ea49":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split, GridSearchCV\nfrom sklearn.metrics import classification_report, confusion_matrix, precision_recall_curve,average_precision_score\nimport xgboost","1aef8fe5":"df = pd.read_csv(\"..\/input\/creditcardfraud\/creditcard.csv\")\ndf.head()","c6a2cbc8":"np.unique(df.Class, return_counts=True)","8bd1d24f":"# Select feature columns\nselFeatureColumns = ['V1', 'V2', 'V3', 'V4', 'V5', 'V6', 'V7', 'V8',\n       'V9', 'V10', 'V11', 'V12', 'V13', 'V14', 'V15', 'V16', 'V17', 'V18',\n       'V19', 'V20', 'V21', 'V22', 'V23', 'V24', 'V25', 'V26', 'V27', 'V28',\n       'Amount']\n\n# Train-Test Split\nX_train, X_test, y_train, y_test = train_test_split(df[selFeatureColumns], df.Class, test_size=0.5,stratify=df.Class,random_state=42 )","2a5b1b01":"# Parameter grid for XGBoost with below combinations was tried \n# I have pre-selected best estimators obtained from GridSearch\n\nxgb_param_grid = {\n        'min_child_weight': [1],       # [1, 5, 10],\n        'gamma': [1],                  # [0.01, 0.1, 1, 10],\n        'subsample': [1],              # [0.6, 0.8, 1.0],\n        'colsample_bytree': [0.7],     # [0.7, 0.8, 0.9],\n        'max_depth': [3],              # [3 ,5 ,7]\n        'learning_rate' : [0.1],       # [0.01, 0.1, 1, 10],\n        'n_estimators': [200]          # [200,300,400]\n        }\n\nxgb = xgboost.XGBClassifier(random_state=42,scale_pos_weight=577,silent=True, n_jobs=-1)\n\ngs = GridSearchCV(estimator = xgb, param_grid = xgb_param_grid, cv = 3, n_jobs = -1, scoring='recall', refit=True)\n\nmodel = gs.fit(X_train, y_train)","83f1273a":"print(gs.best_params_)\nprint(gs.best_score_)","c51fa1b9":"y_pred = gs.predict(X_test)\nprint(classification_report(y_test,y_pred))","19824a62":"y_score_xg = model.predict_proba(X_test)[:,1]\naverage_precision = average_precision_score(y_test, y_score_xg)\nprecision, recall, _ = precision_recall_curve(y_test, y_score_xg)\nplt.step(recall, precision, color='b', alpha=0.2,\n         where='post')\nplt.fill_between(recall, precision, step='post', alpha=0.2,\n                 color='b')\nplt.xlabel('Recall')\nplt.ylabel('Precision')\nplt.ylim([0.0, 1.05])\nplt.xlim([0.0, 1.0])\nplt.title('2-class XGBoost Precision-Recall curve: AP={0:0.2f}'.format(average_precision))","bed50164":"def plot_confusion_matrix(cm,\n                          target_names,\n                          title='Confusion matrix',\n                          cmap=None,\n                          normalize=True):\n   \n    import matplotlib.pyplot as plt\n    import numpy as np\n    import itertools\n\n    accuracy = np.trace(cm) \/ float(np.sum(cm))\n    misclass = 1 - accuracy\n\n    if cmap is None:\n        cmap = plt.get_cmap('Blues')\n\n    plt.figure(figsize=(8, 6))\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n\n    if target_names is not None:\n        tick_marks = np.arange(len(target_names))\n        plt.xticks(tick_marks, target_names, rotation=45)\n        plt.yticks(tick_marks, target_names)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n\n\n    thresh = cm.max() \/ 1.5 if normalize else cm.max() \/ 2\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        if normalize:\n            plt.text(j, i, \"{:0.2f}%\".format(cm[i, j]*100),\n                     horizontalalignment=\"center\",\n                     color=\"black\" if cm[i, j] > thresh else \"black\")\n        else:\n            plt.text(j, i, \"{:,}\".format(cm[i, j]),\n                     horizontalalignment=\"center\",\n                     color=\"black\" if cm[i, j] > thresh else \"black\")\n\n\n    plt.tight_layout()\n    plt.ylabel('True Class')\n    plt.xlabel('Predicted Class')\n    plt.show()\n    \n# Source - https:\/\/www.kaggle.com\/grfiv4\/plot-a-confusion-matrix","e69eed7f":"cm = confusion_matrix(y_test,y_pred)\nplot_confusion_matrix(cm, normalize= True,target_names = ['Not Fraud', 'Fraud'], title = \"Confusion Matrix\")","4fe9155c":"## Target Class Distribution","80f9162b":"## Data\nThis dataset contains 492 fraudulent transactions out of a total of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\nIt contains only numerical input variables which are the result of a PCA transformation. Unfortunately, due to confidentiality issues, we cannot provide the original features and more background information about the data. Features V1, V2, ... V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. Feature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n\nKey point to note here is that the methods presented below can also be used for anomaly detection or for that matter other supervised (labeled) rare class  prediction use cases as well.","f105b3a2":"## Train-Test Split\nI will use **50-50** train-test split. Surprised? Let me explain why.\n\nSince the dataset contains only 492 (0.172%) fraudulent transactions, if I use the conventional 80-20 (or 70-30) train-test split, it will result in very less positive cases (fraudulent transactions) in the test set for testing.\n\n**Treating this problem as as an actual business case and to instill a high degree of confidence in the model**, I want to show that the model can identify as many fradulent transactions in test set as possible.\nTherefore doing 50-50 split (with stratification) will leave 246 fradulent transactions in the test data to verify the quality of our model against unseen test data.\n\nAnother option could be to use oversampling of the minority class but I will leave it for another discussion.","d7da273c":"## Desired Characteristics of a 'Real-World' Fraud Detection System \n1. **High hit\/success rate** in correctly identifying fraudulent transactions. This is also known as Recall, Sensitivity and True Positive Rate.\n\n2. **Low False Positive Rate or False Alarms**. Basically we do not want to incorrectly categorize many Non-Fradulent cases as being Fraud. Afterall, we would not want to upset large number of genuine customers by wrongly flagging their transactions as being fraud and then requiring to go through additional checks or scrutiny.\n\nLet's see how we can build and design a machine learning backed Fraud Detection System model which can meet above requirements.","3eecbb44":"## Confusion Matrix","61efa6e1":"## Loading Data","357d3b03":"## Libraries and packages","bff18c8f":"## Classfication Summary","f10f1614":"## Hyperparamter Tuning for XGBoost\nI see you asking why XGBoost?\n\n> XGBoost has become a widely used and really popular tool among Kaggle competitors and Data Scientists in industry, as it has been battle tested for production on large-scale problems.\n\nhttps:\/\/www.kdnuggets.com\/2017\/10\/xgboost-top-machine-learning-method-kaggle-explained.html","38d95c73":"Above results are actually quite good, considering we used only 50% of the data for training and reserved the remaining 50% for benchmarking.\n## Key Insights\n***1. Out of total 246 fraud transactions in test set, 198 were correctly categorized as being Fraud. This is 80.49% hit ratio in identifying fraud which is what you would expect from a commercial grade predictive fraud identification system.**\n\n**2. Only 89\/142069 = 0.06% of Non-Fradulent cases are wrongly classfied as Fraud. This is also something we would desire in actual credit scoring so as not to upset large number of genuine customers by wrongly flagging their transactions as being fraud and then requiring to go through additional checks or scrutiny.***","fee9f329":"## XGBClassifier Results\nIf all the options in the above param grid are uncommented and tried, we will get best params as follows.","209f2952":"## Precison-Recall (PR) Curve - Evaluate Model Quality\nPrecision-Recall is a useful measure of success of prediction when the classes are very imbalanced. The precision-recall curve shows the tradeoff between precision and recall for different threshold. \n* High precision relates to a low false positive rate (lesser false alarms generated) \n* High recall relates to a low false negative rate (higher percentage of frauds are identified)\n\nHigh scores for both would imply that the classifier is returning accurate results (high precision), as well as returning a majority of all positive results (high recall).\n\nIn short, for imbalanced classe, we want the area under the PR-curve to be as high as possible (as close to 1 as possible).\n\n**We see the area under PR-curve for our classfier as shown below comes out to be 0.81 which is good for a classfier of this nature**\n\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/2\/26\/Precisionrecall.svg\/350px-Precisionrecall.svg.png)","fc71e6b2":"# **Credit Card Fraud Detection**\nIt is important that credit card companies are able to recognize fraudulent credit card transactions so that customers are not charged for items that they did not purchase.\n\n*It may also be useful to note that the below mentioned modeling process can be applied for **Anomaly Detection** or some other **Rare Class identification** scenarios as well*"}}