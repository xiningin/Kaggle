{"cell_type":{"5ccbc53c":"code","586ae9ed":"code","8b099d87":"code","58408ecf":"code","b53592fa":"code","78f28752":"code","dd4d085b":"code","40446e64":"code","81fbdad7":"code","21514908":"code","6998e260":"code","d2c59306":"code","966b82f1":"code","6cafe542":"code","2b0acd2f":"code","c748fe4c":"code","1ad7eccc":"code","9c6c37d0":"code","8f673ead":"code","6c8cf448":"code","9ada2530":"code","4baaf9c1":"code","df4f92ee":"code","7392c039":"code","2b624222":"code","ba7dce23":"code","97813054":"code","5f50c513":"code","50c2eaee":"code","ae31b3df":"code","faf68e0d":"code","073c05fa":"code","a8e6b0f1":"code","d319f558":"code","17223187":"code","7136442e":"code","408b0581":"code","2a843298":"code","2e4d0cc3":"code","23e2e343":"code","ba02f17f":"code","595ca43d":"code","d9b67c98":"code","fc9254fa":"code","57550a21":"code","d2ab8370":"code","95401a07":"code","e734533d":"markdown","4ae14bd8":"markdown","6804d779":"markdown","b14ae37a":"markdown","6b76a45c":"markdown","5620e9e4":"markdown"},"source":{"5ccbc53c":"import cv2\nimport math\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport tensorflow as tf\n\nimport os\nprint(os.listdir(\"..\/input\"))\nimport warnings\nwarnings.filterwarnings('ignore')\n#%matplotlib inline\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\nwarnings.simplefilter('ignore')\nsns.set(rc={'figure.figsize' : (22, 10)})\nsns.set_style(\"darkgrid\", {'axes.grid' : True})","586ae9ed":"def showImg(img, cmap=None):\n    plt.imshow(img, cmap=cmap, interpolation = 'bicubic')\n    plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    plt.show()","8b099d87":"# read image, prepare it by resizing it to fixed height and converting it to grayscale\nimg1 = cv2.imread('..\/input\/Text1.png') \nshowImg(img1, cmap='gray')","58408ecf":"print(img1.ndim)\nprint(img1.shape)","b53592fa":"img2 = cv2.cvtColor(img1, cv2.COLOR_BGR2GRAY)\nprint(img2.shape)","78f28752":"showImg(img2, cmap='gray')","dd4d085b":"type(img2)","40446e64":"img3 = np.transpose(img2)\nshowImg(img3, cmap='gray')","81fbdad7":"img = np.arange(16).reshape((4,4))\nimg","21514908":"showImg(img, cmap='gray')","6998e260":"def createKernel(kernelSize, sigma, theta):\n    \"create anisotropic filter kernel according to given parameters\"\n    assert kernelSize % 2 # must be odd size\n    halfSize = kernelSize \/\/ 2\n\n    kernel = np.zeros([kernelSize, kernelSize])\n    sigmaX = sigma\n    sigmaY = sigma * theta\n\n    for i in range(kernelSize):\n        for j in range(kernelSize):\n            x = i - halfSize\n            y = j - halfSize\n\n            expTerm = np.exp(-x**2 \/ (2 * sigmaX) - y**2 \/ (2 * sigmaY))\n            xTerm = (x**2 - sigmaX**2) \/ (2 * math.pi * sigmaX**5 * sigmaY)\n            yTerm = (y**2 - sigmaY**2) \/ (2 * math.pi * sigmaY**5 * sigmaX)\n\n            kernel[i, j] = (xTerm + yTerm) * expTerm\n\n    kernel = kernel \/ np.sum(kernel)\n    return kernel","d2c59306":"kernelSize=9\nsigma=4\ntheta=1.5\n#25, 0.8, 3.5","966b82f1":"imgFiltered1 = cv2.filter2D(img3, -1, createKernel(kernelSize, sigma, theta), borderType=cv2.BORDER_REPLICATE)\nshowImg(imgFiltered1, cmap='gray')","6cafe542":"def applySummFunctin(img):\n    res = np.sum(img, axis = 0)    #  summ elements in columns\n    return res","2b0acd2f":"def normalize(img):\n    (m, s) = cv2.meanStdDev(img)\n    m = m[0][0]\n    s = s[0][0]\n    img = img - m\n    img = img \/ s if s>0 else img\n    return img\nimg4 = normalize(imgFiltered1)","c748fe4c":"(m, s) = cv2.meanStdDev(imgFiltered1)\nm[0][0]","1ad7eccc":"summ = applySummFunctin(img4)\nprint(summ.ndim)\nprint(summ.shape)","9c6c37d0":"plt.plot(summ)\nplt.show()","8f673ead":"def smooth(x, window_len=11, window='hanning'):\n#     if x.ndim != 1:\n#         raise ValueError(\"smooth only accepts 1 dimension arrays.\") \n    if x.size < window_len:\n        raise ValueError(\"Input vector needs to be bigger than window size.\") \n    if window_len<3:\n        return x\n    if not window in ['flat', 'hanning', 'hamming', 'bartlett', 'blackman']:\n        raise ValueError(\"Window is on of 'flat', 'hanning', 'hamming', 'bartlett', 'blackman'\") \n    s = np.r_[x[window_len-1:0:-1],x,x[-2:-window_len-1:-1]]\n    #print(len(s))\n    if window == 'flat': #moving average\n        w = np.ones(window_len,'d')\n    else:\n        w = eval('np.'+window+'(window_len)')\n\n    y = np.convolve(w\/w.sum(),s,mode='valid')\n    return y","6c8cf448":"windows=['flat', 'hanning', 'hamming', 'bartlett', 'blackman']\nsmoothed = smooth(summ, 35)\nplt.plot(smoothed)\nplt.show()","9ada2530":"from scipy.signal import argrelmin\nmins = argrelmin(smoothed, order=2)\narr_mins = np.array(mins)","4baaf9c1":"plt.plot(smoothed)\nplt.plot(arr_mins, smoothed[arr_mins], \"x\")\nplt.show()","df4f92ee":"img4.shape","7392c039":"type(arr_mins[0][0])","2b624222":"def crop_text_to_lines(text, blanks):\n    x1 = 0\n    y = 0\n    lines = []\n    for i, blank in enumerate(blanks):\n        x2 = blank\n        print(\"x1=\", x1, \", x2=\", x2, \", Diff= \", x2-x1)\n        line = text[:, x1:x2]\n        lines.append(line)\n        x1 = blank\n    return lines\n    ","ba7dce23":"def display_lines(lines_arr, orient='vertical'):\n    plt.figure(figsize=(30, 30))\n    if not orient in ['vertical', 'horizontal']:\n        raise ValueError(\"Orientation is on of 'vertical', 'horizontal', defaul = 'vertical'\") \n    if orient == 'vertical': \n        for i, l in enumerate(lines_arr):\n            line = l\n            plt.subplot(2, 10, i+1)  # A grid of 2 rows x 10 columns\n            plt.axis('off')\n            plt.title(\"Line #{0}\".format(i))\n            _ = plt.imshow(line, cmap='gray', interpolation = 'bicubic')\n            plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    else:\n            for i, l in enumerate(lines_arr):\n                line = l\n                plt.subplot(40, 1, i+1)  # A grid of 40 rows x 1 columns\n                plt.axis('off')\n                plt.title(\"Line #{0}\".format(i))\n                _ = plt.imshow(line, cmap='gray', interpolation = 'bicubic')\n                plt.xticks([]), plt.yticks([])  # to hide tick values on X and Y axis\n    plt.show()\n    ","97813054":"found_lines = crop_text_to_lines(img3, arr_mins[0])","5f50c513":"found_lines[2]","50c2eaee":"sess = tf.Session()\nfound_lines_arr = []\nwith sess.as_default():\n    for i in range(len(found_lines)-1):\n        found_lines_arr.append(tf.expand_dims(found_lines[i], -1).eval())","ae31b3df":"display_lines(found_lines)","faf68e0d":"def transpose_lines(lines):\n    res = []\n    for l in lines:\n        line = np.transpose(l)\n        res.append(line)\n    return res\n    ","073c05fa":"res_lines = transpose_lines(found_lines)\ndisplay_lines(res_lines, 'horizontal')","a8e6b0f1":"# read image, prepare it by resizing it to fixed height and converting it to grayscale\nimg3_1 = cv2.imread('..\/input\/Text3.png') \nshowImg(img3_1, cmap='gray')","d319f558":"img3_1.shape","17223187":"img3_2 = cv2.cvtColor(img3_1, cv2.COLOR_BGR2GRAY)\nimg3_3 = np.transpose(img3_2)\nk = createKernel(kernelSize, sigma, theta)\nimgFiltered3 = cv2.filter2D(img3_3, -1, k, borderType=cv2.BORDER_REPLICATE)\nimg3_4 = normalize(imgFiltered3)\nsumm3 = applySummFunctin(img3_4)\nsmoothed3 = smooth(summ3, 35)\nmins3 = argrelmin(smoothed3, order=2)\narr_mins3 = np.array(mins3)\nfound_lines3 = crop_text_to_lines(img3_3, arr_mins3[0])\nres_lines3 = transpose_lines(found_lines3)\ndisplay_lines(res_lines3, 'horizontal')","7136442e":"img2 = cv2.imread('..\/input\/Text2.png') \nshowImg(img2, cmap='gray')","408b0581":"img2 = cv2.cvtColor(img2, cv2.COLOR_BGR2GRAY)","2a843298":"# apply filter kernel\nkernel = createKernel(kernelSize, sigma, theta)\n# The function applies an arbitrary linear filter to an image.\n# int ddepth (=-1) - desired depth of the destination image\n# anchor - indicates the relative position of a filtered point within the kernel; \n# default value (-1,-1) means that the anchor is at the kernel center.\n# borderType - pixel extrapolation method:  \n# cv2.BORDER_REPLICATE -  The row or column at the very edge of the original is replicated to the extra border.\nimgFiltered2 = cv2.filter2D(img2, -1, kernel, borderType=cv2.BORDER_REPLICATE).astype(np.uint8)\nshowImg(imgFiltered2, cmap='gray')","2e4d0cc3":"# threshold - If pixel value is greater than a threshold value, it is assigned one value, else it is assigned another value \n# Returns: threshold value computed, destination image\n# adaptiveThreshold(src, dst, maxValue, adaptiveMethod, thresholdType, blockSize (always odd!), C)\nimgThres = cv2.adaptiveThreshold(imgFiltered2, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 2) # or cv2.THRESH_BINARY+cv2.THRESH_OTSU\nshowImg(imgThres, cmap='gray')","23e2e343":"(components, hierarchy) = cv2.findContours(imgThres, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE) # RETR_EXTERNAL or RETR_LIST\nlen(components)","ba02f17f":"# showImg(cv2.drawContours(img2, components, -1, (255,0,0), 3, cv2.LINE_AA, hierarchy, 1 ), cmap='gray')","595ca43d":"res = []\nminArea = 100\nfor c in components:\n    # skip small word candidates\n    if cv2.contourArea(c) < minArea:\n        continue\n    # append bounding box and image of word to result list\n    currBox = cv2.boundingRect(c) # returns (x, y, w, h)\n    (x, y, w, h) = currBox\n    currImg = img1[y:y+h, x:x+w]\n    res.append((currBox, currImg))","d9b67c98":"sns.set(rc={'figure.figsize' : (6, 3)})\n(x1, y1, w1, h1) = res[8][0]\nshowImg(img1[y1:y1+h1, x1:x1+w1], cmap='gray')","fc9254fa":"len(res)","57550a21":"def prepareTextImg(img):\n    \"convert given image to grayscale image (if needed) and resize to desired height\"\n    assert img.ndim in (2, 3)\n    if img.ndim == 3:\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2GRAY)\n    return img","d2ab8370":"def lineSegmentation(img, kernelSize=25, sigma=11, theta=7):\n    img_tmp = np.transpose(prepareTextImg(img))\n    k = createKernel(kernelSize, sigma, theta)\n    imgFiltered = cv2.filter2D(img_tmp, -1, k, borderType=cv2.BORDER_REPLICATE)\n#     imgFiltered = cv2.adaptiveThreshold(imgFiltered2, 255, cv2.ADAPTIVE_THRESH_MEAN_C, cv2.THRESH_BINARY, 5, 2)\n    img_tmp1 = normalize(imgFiltered)\n    summ_pix = np.sum(img_tmp1, axis = 0)    #  summ elements in columns\n    smoothed = smooth(summ_pix, 35)\n    mins = np.array(argrelmin(smoothed, order=2))\n    found_lines = transpose_lines(crop_text_to_lines(img_tmp, mins[0]))\n    return found_lines","95401a07":"# read input images from 'in' directory\nimgFiles = os.listdir('..\/input')\nprint(\"Files found in data dir:{0}\".format(len(imgFiles)))\nfound_lines = []\nfor (i, f) in enumerate(imgFiles):\n    print(\"File #\", i, \" Name: \", f)\n    print('Segmenting words of sample %s'%f)\n    img = cv2.imread('..\/input\/%s'%(f)) \n    tmp_lines = lineSegmentation(img)\n    display_lines(tmp_lines, 'horizontal')\n    found_lines.append(tmp_lines)","e734533d":"## Overview\n\nThis notebook is a first part of full **Offline Handwritten Text Recognition**.     \nSee full system on Github: https:\/\/github.com\/IrinaArmstrong\/HandwrittenTextRecognition\n\n**Offline Handwritten Text Recognition (HTR)** systems transcribe text contained in scanned images into digital text.             \nIn this case, the system is developed to deal with cyrillic alphabet. It also involves full dictionary of the Russian language.\n\nIn general, developed HTR consists of several parts, which are responsible for processing pages with full text (scanned or photographed), dividing them into lines, splitting the resulting lines into words and following recognition of words from them.\n\nFor solve the problem of recognition, it was decided to use Neural Network (NN). It consists of convolutional NN (CNN) layers, recurrent NN (RNN) layers and a final Connectionist Temporal Classification (CTC) layer.\n\nBut in this notebook only the task of page segmentation is highlighted. It was decided to do this in several different ways shown below.","4ae14bd8":"# Method #1.    \nImplementation of scale space technique for word segmentation as proposed by R. Manmatha and N. Srimal. Even though the paper is from 1999, the method still achieves good results, is fast, and is easy to implement. The algorithm takes an image of a line as input and outputs the segmented words.\n\nScale space technique for word segmentation proposed by R. Manmatha: http:\/\/ciir.cs.umass.edu\/pubfiles\/mm-27.pdf","6804d779":"# Method #2. (Does not work)   \nFinding contours and combine then into lines.","b14ae37a":"## Text #3","6b76a45c":"### Imports","5620e9e4":"## Text #1"}}