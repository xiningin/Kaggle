{"cell_type":{"a92e592b":"code","e5be123d":"code","cd3193ac":"code","1c8b68d0":"code","95c4cadf":"code","627eb3b0":"code","18cbd9f9":"code","77321ce4":"code","ee1a2997":"code","4df523e4":"code","202e1b61":"code","53544658":"code","7fbf074d":"code","0fe870e5":"code","52f5866b":"code","17a49c8f":"code","7c18d79d":"code","e144dfdf":"code","763db5d5":"code","6db6d3ad":"code","5c2627b1":"code","6e156d4f":"code","1edf287a":"code","c376e037":"code","754c62ce":"code","bd7e8832":"code","3e3e5ced":"code","503dcedb":"code","2751af15":"code","877d6170":"code","bcd0f2b2":"code","fe404e0a":"code","7762f015":"code","fdc586a3":"code","e91dea10":"code","81f9b2f4":"code","583b2272":"code","bc2e1f27":"code","ad718d03":"code","898b6866":"code","c990b8ae":"code","5caebac6":"code","13e44c9e":"code","8fc712db":"code","89cbde27":"code","93111a4a":"code","45628cae":"code","0f7c77c1":"code","fe57a07f":"code","cab02dec":"code","57571eeb":"code","35742819":"code","7c6c499d":"code","369ea943":"code","a56ec298":"code","82982aff":"code","ef310139":"code","53618aa2":"code","b8784948":"code","ee7daa1c":"code","915a046f":"code","d95cbcd4":"code","af0363b3":"code","ae5dbeca":"code","88cf1169":"code","45912662":"code","5584e1e3":"code","64d4280c":"code","a0a08dc2":"code","66158cbb":"markdown","25a5793d":"markdown","1dcc5c14":"markdown","18f846cd":"markdown","8106e7e6":"markdown","e94be63e":"markdown","7ce13b67":"markdown","bdde9260":"markdown","90fa616f":"markdown","6f49cf76":"markdown","0fb7aac4":"markdown","1b0dfa7d":"markdown","75ae2885":"markdown","ef7455f0":"markdown","b9afb670":"markdown","7b70833c":"markdown","fdf2eca3":"markdown","98ee6fac":"markdown","9868a741":"markdown","a11922db":"markdown","ed85a668":"markdown","f5b33d90":"markdown","bdc78e91":"markdown","ef13e532":"markdown","027d3405":"markdown","53238fa5":"markdown","8f6c10aa":"markdown","9d1204a1":"markdown","0b0594a1":"markdown","dbcc346d":"markdown","18fc407e":"markdown","faf89f85":"markdown","bf097463":"markdown","87c248a5":"markdown","ef4abd99":"markdown","df0bf3af":"markdown","c6735971":"markdown","45855a85":"markdown","75c8edc7":"markdown","f7056bd8":"markdown","8b676f72":"markdown","333755e8":"markdown","4f38144d":"markdown","2a273976":"markdown","637c1e90":"markdown","46911197":"markdown","e489258d":"markdown","f6f7a893":"markdown","912417f9":"markdown","22e0303d":"markdown","5eb1dfa8":"markdown","28745714":"markdown","9e9c6e48":"markdown"},"source":{"a92e592b":"import numpy as np\nimport pandas as pd\nfrom scipy import stats\nimport matplotlib.pyplot as plt\nimport seaborn as sns","e5be123d":"df = pd.read_csv(\"..\/input\/sf-salaries\/Salaries.csv\")","cd3193ac":"df.head()","1c8b68d0":"df.info()","95c4cadf":"df.set_index('Id', inplace=True)\n#to reset index to default use below\n#df.reset_index(inplace=True)","627eb3b0":"df[df['BasePay'].str.contains('[a-zA-Z]') == True]","18cbd9f9":"df[df.duplicated()].head(10)","77321ce4":"df.drop_duplicates(inplace=True)","ee1a2997":"df[df.duplicated()]","4df523e4":"df[df['BasePay'].str.contains('[a-zA-Z]') == True]","202e1b61":"df.drop(index=[148647])['Benefits'].astype(float)","53544658":"df.drop(index=[148647], inplace=True)","7fbf074d":"df['Benefits'] = df['Benefits'].astype(float)","0fe870e5":"df['Benefits']","52f5866b":"df.info()","17a49c8f":"df['BasePay'] = df['BasePay'].astype(float)\ndf['OvertimePay'] = df['OvertimePay'].astype(float)\ndf['OtherPay'] = df['OtherPay'].astype(float)","7c18d79d":"df.info()","e144dfdf":"df.describe()","763db5d5":"df[df['BasePay'] < 0].head(15)","6db6d3ad":"df[df['OvertimePay'] < 0].head()","5c2627b1":"df[df['OtherPay'] < 0].head()","6e156d4f":"df[df['Benefits'] < 0].head()","1edf287a":"df[df['TotalPay'] < 0]","c376e037":"df[df['TotalPayBenefits'] < 0]","754c62ce":"df.drop(index = df[df['BasePay'] < 0].index, inplace=True)\ndf.drop(index = df[df['OvertimePay'] < 0].index, inplace=True)\ndf.drop(index = df[df['OtherPay'] < 0].index, inplace=True)\ndf.drop(index = df[df['Benefits'] < 0].index, inplace=True)\ndf.drop(index = df[df['TotalPay'] < 0].index, inplace=True)\ndf.drop(index = df[df['TotalPayBenefits'] < 0].index, inplace=True)","bd7e8832":"df.describe()","3e3e5ced":"df.isna().sum()","503dcedb":"df[df['Year'] == 2011].isna().sum()","2751af15":"df[df['Year'] == 2013].isna().sum()","877d6170":"df.drop(index=df[(df['Year'] == 2013) & (df['BasePay'].isna())].index, inplace=True)","bcd0f2b2":"df.isna().sum()","fe404e0a":"df.drop(columns=['Notes', 'Agency'], inplace=True)","7762f015":"df.isna().sum()","fdc586a3":"df[df['Year'] == 2011].isna().sum()","e91dea10":"df[df['Year'] == 2014].isna().sum()","81f9b2f4":"df_2011 = df[df['Year'] == 2011].copy()","583b2272":"df_2011.drop(columns=['Benefits', 'Status'], inplace=True)","bc2e1f27":"df_2014 = df[df['Year'] == 2014].copy()","ad718d03":"df_clean = df.copy()","898b6866":"df_clean.isna().sum()","c990b8ae":"df_clean.drop(columns=['Status'], inplace=True)","5caebac6":"df_clean.isna().sum()","13e44c9e":"df_clean['Benefits'].fillna(value=df_clean['Benefits'].mean(), inplace=True)","8fc712db":"df_clean.describe()","89cbde27":"df_clean.info()","93111a4a":"df_clean['JobTitle'] = df_clean['JobTitle'].str.lower()","45628cae":"df_clean.head()","0f7c77c1":"df_clean.isna().sum()","fe57a07f":"no_benefits = (df_clean['Benefits'] == 0)\nno_basepay = (df_clean['BasePay'] == 0)\nno_overtime = (df_clean['OvertimePay'] == 0)\nno_other = (df_clean['OtherPay'] == 0)\nno_total_bene = (df_clean['TotalPayBenefits'] == 0)\nyr_filt = lambda x: df_clean['Year'] == x\nnum_columns = ['BasePay', 'OvertimePay', 'OtherPay', 'Benefits', 'TotalPay', 'TotalPayBenefits']\n","cab02dec":"df_clean[no_benefits].count()","57571eeb":"df_clean[no_benefits & yr_filt(2014)].describe()","35742819":"df_clean[no_benefits & no_overtime & no_other].count()","7c6c499d":"df_clean[~no_benefits & no_overtime & no_other].count()","369ea943":"df_clean.sort_values(by='TotalPayBenefits', ascending=False).head(10)","a56ec298":"df_clean[no_benefits & yr_filt(2014)].sort_values(by='TotalPayBenefits', ascending=False).head(10)","82982aff":"clean_grp_job = df_clean.groupby(by='JobTitle')\nclean_grp_year = df_clean.groupby(by='Year')","ef310139":"clean_grp_job.median()","53618aa2":"clean_grp_job.median().nlargest(10, 'TotalPayBenefits')","b8784948":"clean_grp_year.median()","ee7daa1c":"df_clean.groupby(by=['JobTitle', 'Year']).median().nlargest(10, 'TotalPayBenefits')","915a046f":"clean_grp_job.get_group('account clerk')[num_columns].median()","d95cbcd4":"clean_grp_job.get_group('account clerk')[num_columns].agg(['median', 'mean', 'count'])","af0363b3":"df_clean.columns","ae5dbeca":"df_clean['JobTitle'].value_counts().head(20)","88cf1169":"filt = df_clean['JobTitle'].str.contains('nurse')\ndf_clean[filt]['JobTitle'].value_counts().head(20)","45912662":"df_clean[df_clean['JobTitle'].str.contains('nurse')]['JobTitle'].unique()","5584e1e3":"filt = df_clean[(df_clean['TotalPayBenefits'] > 0)]['TotalPayBenefits']\nnormalized_data = stats.boxcox(filt)\nsns.displot(normalized_data[0])","64d4280c":"filt = df_clean[(df_clean['JobTitle'] == 'special nurse') & (df_clean['TotalPayBenefits'] > 0)]['TotalPayBenefits']\nnormalized_data = stats.boxcox(filt)\nsns.displot(normalized_data[0])","a0a08dc2":"filt = df_clean[(df_clean['JobTitle'] == 'registered nurse') & (df_clean['TotalPayBenefits'] > 0)]['TotalPayBenefits']\nnormalized_data = stats.boxcox(filt)\nsns.displot(normalized_data[0])","66158cbb":"# Cleaning the Data\n\n","25a5793d":"We cast the Benefits series as a 'float' type and assign it to its own object to make the change permanent.","1dcc5c14":"# Summary","18f846cd":"## Creating Dataframes","8106e7e6":"With our numerical columns now all 'float' types, we can use describe() to run aggregate functions on the data.\n\nThe min aggregation shows there are negative values.","e94be63e":"## Aggregation","7ce13b67":"In this notebook I demonstrated how Python can be used to clean data.\n\nWe removed duplicates, dropped rows and columns, used mean imputation to fill NaN values, and created filtered dataframe copies.\n\nWe looked at filtering, sorting, and aggregation tools.\n\nAnd finally, we visualized some of the data.","bdde9260":"# Load Data\n","90fa616f":"For 'registered nurse', we see a trimodal distribution.","6f49cf76":"We'll drop these rows with negative values.","0fb7aac4":"Using mean imputation, we can replace each column's NaN values with the mean of each respective column. \n\nThis prevents the data from being skewed by other types of imputation.","1b0dfa7d":"df.info() tells us there are 13 columns and 148,654 rows.\n\nSome of the numerical columns (BasePay, OvertimePay, OtherPay, Benefits) have an 'object' data type, when we'd be expecting 'float64'.\n\nThe 'object' type will prevent us from using some analytical functions.\n\nIt will be necessary to clean our data before any analysis.","75ae2885":"## NaN values","ef7455f0":"We can combine filters with the operator '&'.","b9afb670":"Here we have the jobs with the most employees.","7b70833c":"\n\nWe load the data and take an inital look.","fdf2eca3":"# Visualizing Data","98ee6fac":"Sorting help us order the data.","9868a741":"Combined with filtering, we can have different data returned.","a11922db":"## Mean Imputation","ed85a668":"Visualizing data allows us to more easily spot and share trends.","f5b33d90":"We'll make all the 'JobTitle' values lowercase to make it easier to search through.","bdc78e91":"We can create a few filters for when a value is zero and create a function to filter by year.\n\nFor functions that use numerical columns, we can create a list.","ef13e532":"With our data clean, we can now analyze it.","027d3405":"Using '\\~', we can get the reverse of a filter. '~no_benefits' selects all observations where benefits does not equal zero.","53238fa5":"Grouping categorical columns allows us to use aggregation functions to find things like the sum or median of numerical columns.","8f6c10aa":"# Cleaning Data using Python\n\nIn this notebook, I use Python to clean the dataset for San Francisco public employee wages.","9d1204a1":"We don't need the columns Notes and Agency, so we'll drop them.\n\nNotes contains no data, and as the dataset is drawn from San Francisco, there is only one unique value for Agency.","0b0594a1":"We use the inplace=True argument to make it permanent.","dbcc346d":"## Filtering","18fc407e":"Our remaining cleaning issues are how to deal with missing Benefits and Status data.\n\nBenefits is only missing for the year 2011, and Status data is only available for the year 2014.\n\nWe'll separate the data into several dataframes:\n\n* df_2011: One dataframe for the year 2011 with the Benefits and Status columns dropped\n* df_2014: One dataframe for the year 2014\n* df_clean: One dataframe with all years, missing Benefits being filled by mean imputation, and the Status column dropped.","faf89f85":"We can set the Id to be the index of our dataset.","bf097463":"There are still NaN values in our columns preventing calculations.","87c248a5":"We can check one of the 'object' columns for strings. The regular expression '[a-zA-Z]' will match alphabetic string characters. \n\nWe find several matching rows that look to be duplicates and contain alphabetic characters when we're expecting numerical.","ef4abd99":"## Duplicates","df0bf3af":"When filtering for negative values we find that there aren't that many.","c6735971":"Here is the distribution of TotalPayBenefits for all jobs.\n\nIt appears to be bimodal with the lower peak on the left end of the distribution.","45855a85":"## Dataset Used\n\nThe [sf-salaries dataset](https:\/\/www.kaggle.com\/kaggle\/sf-salaries) is provided by Kaggle and has a CC0: Public Domain licence.\n\nThe datset is taken from [Transparent California](https:\/\/transparentcalifornia.com\/pages\/about\/) which is managed by the [Nevada Policy Research Institute](https:\/\/www.npri.org\/about\/), an IRS 501(c) (3) organization.","75c8edc7":"row 148647 however, is still in the dataset.","f7056bd8":"## Dropping Columns","8b676f72":"Let's drop those 602 rows where BasePay is NaN. Doing so should not significantly affect our analysis.","333755e8":"Filtering by year, we find that only the year 2011 has no Benefits values entered, and that only in the year 2013 are there some values missing for BasePay.","4f38144d":"We can use filtering to exclude or include data we want to see.","2a273976":"## Droppings Rows","637c1e90":"## Negative Values","46911197":"We narrow the results by filtering for jobs with 'nurse' in their title. ","e489258d":"## Casting Columns","f6f7a893":"Here, the distribution for 'special nurse' is unimodal.","912417f9":"## Sorting","22e0303d":"Doing the same with the columns 'BasePay', 'OvertimePay', and 'OtherPay' changes them to the 'float' type.","5eb1dfa8":"We drop them and find no other duplicates.","28745714":"# Analyze Data","9e9c6e48":"If we remove this row, and try casting the 'Benefits' column as a float, we see it works."}}