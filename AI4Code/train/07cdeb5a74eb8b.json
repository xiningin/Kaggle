{"cell_type":{"01b77337":"code","ca4e9724":"code","46ab399c":"code","23ba18c8":"code","98824a85":"code","5e8a5460":"code","23edaae8":"code","f8e5bc1f":"code","bfc60bcf":"code","ced60461":"code","d55e2b33":"code","3e8764d9":"code","e35b0a4c":"code","d402b12c":"code","88fb187a":"code","8c92cf77":"code","e5eedc01":"code","54264b84":"code","5cba1120":"code","3d99f161":"code","b1a1331f":"code","900f3178":"code","db08e3d5":"code","8f114c1d":"code","1b91134d":"code","ceb52486":"code","079c86a8":"code","a8c9d6e9":"code","5943405c":"code","2dcdc745":"code","ab47b144":"code","76d01f64":"code","09d6ac42":"code","872c5189":"code","6d853279":"code","0fe24e1d":"code","df203c19":"code","b3cd0d7e":"markdown","9bfb7795":"markdown","9d5661f4":"markdown","5d2ee60c":"markdown","0cb4f612":"markdown","5039a991":"markdown","6edee7f1":"markdown","04422d73":"markdown","6af098ec":"markdown","455bffd6":"markdown","720e105e":"markdown","3f0b62e5":"markdown","1349bdad":"markdown","ef1ecf13":"markdown","dd9f5d82":"markdown","9b7e87e8":"markdown","23209017":"markdown","47a9eb40":"markdown","3646ff8b":"markdown","5f06393b":"markdown","5ec55ef9":"markdown","e5d30e24":"markdown","baaa6fd5":"markdown"},"source":{"01b77337":"import os\nimport numpy as np\nimport pandas as pd\nimport seaborn as sns\nfrom time import time\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\npath=\"..\/input\" #For Kaggle\n#path=\"input\"\nprint(os.listdir(path))","ca4e9724":"train = pd.read_csv(path+\"\/train.csv\")\ntest = pd.read_csv(path+\"\/test.csv\")\ntrain.head()","46ab399c":"train.info()\nprint('-'*50)\ntest.info()","23ba18c8":"# Drop PassengerId, Ticket as they are basically Row_identifier(unique ID) type columns\n# Drop Cabin since it has 77%,78% missing data in train,test sets respectively making imputation infeasible\ntrain.drop(columns=['PassengerId','Ticket','Cabin'], axis=1, inplace = True)\ntest.drop(columns=['Ticket','Cabin'], axis=1, inplace = True)\ntrain.info()","98824a85":"fig, axes = plt.subplots(nrows=3, ncols=2, figsize=(15,15))\nsns.countplot(x=\"Survived\", hue=\"Pclass\", data=train, ax=axes[0][0])\nsns.countplot(x=\"Survived\", hue=\"Sex\", data=train, ax=axes[0][1])\nsns.countplot(x=\"Survived\", hue=\"SibSp\", data=train, ax=axes[1][0])\nsns.countplot(x=\"Survived\", hue=\"Parch\", data=train, ax=axes[1][1])\nsns.countplot(x=\"Survived\", hue=\"Embarked\", data=train, ax=axes[2][0])","5e8a5460":"#1. a) Add family_size\ntrain['FamilySize'] = train['SibSp'] + train['Parch'] + 1\ntest['FamilySize'] = test['SibSp'] + test['Parch'] + 1","23edaae8":"#1. b) Add Title\nimport re\ndef getTitle(name):\n    title = re.search('([A-Za-z]+)\\.',name)\n    if title:\n        return title.group(1)\n    return \"\"\n\ntrain['Title'] = train['Name'].apply(getTitle)\ntest['Title'] = test['Name'].apply(getTitle)\npd.crosstab(train['Title'], train['Survived'])","f8e5bc1f":"pd.crosstab(test['Title'], test['Sex'])","bfc60bcf":"#Bucket the Titles into appropriate groups\ntrain['Title']=train['Title'].replace(['Capt','Col','Don','Dr','Jonkheer','Major','Rev','Sir','Dona'],'Rare')\ntrain['Title']=train['Title'].replace('Ms','Miss')\ntrain['Title']=train['Title'].replace(['Mlle','Mme','Lady','Countess'],'Mrs')\npd.crosstab(train['Title'], train['Survived'])","ced60461":"test['Title']=test['Title'].replace(['Capt','Col','Don','Dr','Jonkheer','Major','Rev','Sir','Dona'],'Rare')\ntest['Title']=test['Title'].replace('Ms','Miss')\ntest['Title']=test['Title'].replace(['Mlle','Mme','Lady','Countess'],'Mrs')\npd.crosstab(test['Title'], test['Sex'])","d55e2b33":"# 2a) Fare: Only test set has missing values\ntest['Fare'].fillna(test['Fare'].median(), inplace = True)\n\n# 2b) Age\ntrain['Age'].fillna(train['Age'].median(), inplace = True)\ntest['Age'].fillna(test['Age'].median(), inplace = True)\n\n# 2c) Embarked\ntrain['Embarked'].fillna(train['Embarked'].mode()[0], inplace = True) #replace with the 1st Mode","3e8764d9":"#3.a) Bin feature Fare into groups\nplt.figure(figsize=(50,200))\n#fig, axes2 = plt.subplots(nrows=1, ncols=1, figsize=(50,70))\n#sns.countplot(x=\"Fare\", data=train[train['Survived']==0], ax=axes2[0])\n#sns.countplot(x=\"Fare\", data=train[train['Survived']==1], ax=axes2[0])\n\n#sns.kdeplot(x=\"Fare\", data=train[train['Survived']==0], ax=axes2[0])\n#sns.kdeplot(train['Fare'])\n#sns.countplot(train['Fare'])\nsns.countplot(y=\"Fare\", hue=\"Survived\", data=train)\n#sns.distplot(train['Fare'])\n#sns.countplot(y=\"Fare\", data=train)\n#pd.crosstab(train['Fare'], train['Survived'])","e35b0a4c":"train['Fare_bin'] = pd.cut(train['Fare'],bins=[0,7.125,15.1,30,60,120,1000],\n                           labels=['very_low_fare', 'low_fare', 'medium_fare', \n                                   'moderate_fare', 'high_fare', 'very_high_fare'])\ntest['Fare_bin'] = pd.cut(train['Fare'],bins=[0,7.125,15.1,30,60,120,1000],\n                           labels=['very_low_fare', 'low_fare', 'medium_fare', \n                                   'moderate_fare', 'high_fare', 'very_high_fare'])\npd.crosstab(train['Fare_bin'], train['Survived'])","d402b12c":"#3.b) Bin Age\nplt.figure(figsize=(50,100))\nsns.countplot(y=\"Age\", hue=\"Survived\", data=train)","88fb187a":"#0,12,20,40,60,120\ntrain['Age_bin'] = pd.cut(train['Age'], bins=[0,12,20,40,60,120], \n                          labels=['Child','Teenage','Adult','MiddleAge','ElderAge'])\ntest['Age_bin'] = pd.cut(test['Age'], bins=[0,12,20,40,60,120], \n                          labels=['Child','Teenage','Adult','MiddleAge','ElderAge'])\npd.crosstab(train['Age_bin'], train['Survived'])","8c92cf77":"train = pd.get_dummies(train, columns = [\"Sex\",\"Embarked\",\"Title\",\"Fare_bin\", \"Age_bin\"], prefix_sep='=', \n                             prefix=[\"Sex\",\"Embarked\",\"Title\",\"Fare_bin\", \"Age_bin\"])\ntest = pd.get_dummies(test, columns = [\"Sex\",\"Embarked\",\"Title\",\"Fare_bin\", \"Age_bin\"], prefix_sep='=', \n                             prefix=[\"Sex\",\"Embarked\",\"Title\",\"Fare_bin\", \"Age_bin\"])\ntrain.head()","e5eedc01":"train.drop(columns=['Name','Age','Fare'], axis=1, inplace = True)\ntest.drop(columns=['Name','Age','Fare'], axis=1, inplace = True)","54264b84":"cols = ['Pclass','SibSp','Parch','FamilySize']\ntrain[cols] = train[cols].astype(np.uint8)\ntest[cols] = test[cols].astype(np.uint8)\ntrain['Survived'] = train['Survived'].astype(np.uint8)","5cba1120":"# Need to save this after all pre-processing done for submission\ntest_Pids = test['PassengerId']\ntest.drop(columns=['PassengerId'], axis=1, inplace = True)","3d99f161":"train.info()","b1a1331f":"X = train.drop(columns='Survived')\nY = train['Survived']\n\nskf = StratifiedKFold(n_splits=4,random_state=1)\nfor train_index, test_index in skf.split(X, Y):\n    X_tr, X_val = X.iloc[train_index], X.iloc[test_index]\n    Y_tr, Y_val = Y.iloc[train_index], Y.iloc[test_index]\n    print('Train & Validation sets built.')\n    break","900f3178":"#Define generalized function for Scoring current instance of model & data\n'''\nreturns ::  a)acc: accuracy as computed on Validation set\n            b)exec_time: model build\/fit time\n'''\ndef evaluate(X_tr, Y_tr, X_val, Y_val, params):\n    model = LogisticRegression()\n    #We should use set_params to pass parameters to model object.\n    #This has the advantage over using setattr in that it allows Scikit learn to perform some validation checks on the parameters.\n    model.set_params(**params)\n    \n    start=time()\n    model.fit(X_tr,Y_tr)\n    exec_time = time() - start\n    \n    Y_pred = model.predict(X_val)\n    acc = accuracy_score(Y_val,Y_pred) * 100.0\n    return acc, exec_time","db08e3d5":"C=0.001\niterations = 500\nresults = np.zeros((iterations, 5))\n\nfor i in range(0,iterations):    \n    model_params = {'C':C,'random_state':1}\n    acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n    acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n    results[i] = i+1, C, acc_tr, acc_val, time_val\n    C+=0.005\n\nres_df = pd.DataFrame(  data=results[0:,0:], \n                        index=results[0:,0],\n                        columns=['Sl','C','Train_acc','Val_acc','Build_time'])\nres_df['Sl'] = res_df['Sl'].astype(np.uint16)\nres_df.head()","8f114c1d":"#Find value of C & Train_acc at which Valiation set acuracy is highest.\nres_df[res_df['Val_acc'] == res_df['Val_acc'].max()]","1b91134d":"plt.xlabel('C')\nplt.ylabel('Accuracy')\nplt.title('Train & Validation Set Accuracy w.r.t to Regularization parameter C')\nplt.grid(True)\nplt.plot(res_df['C'], res_df['Train_acc'] , 'r*-') # plotting t, a separately \nplt.plot(res_df['C'], res_df['Val_acc'] , 'b.') # plotting t, a separately","ceb52486":"#tol=1e-6\ntol=1e-10\n#iterations = 50\niterations = 37\nresults = np.zeros((iterations, 5))\n\nfor i in range(0,iterations):    \n    model_params = {'tol':tol,'random_state':1}\n    acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n    acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n    results[i] = i+1, tol, acc_tr, acc_val, time_val\n    #tol*=5\n    tol*=2\n    #print(tol)\n\nres_df_tol = pd.DataFrame(  data=results[0:,0:], \n                        index=results[0:,0],\n                        columns=['Sl','tol','Train_acc','Val_acc','Build_time'])\nres_df_tol['Sl'] = res_df['Sl'].astype(np.uint16)\nres_df_tol.head()","079c86a8":"plt.figure(figsize=(20,5))\nplt.xlabel('tol')\nplt.ylabel('Accuracy')\nplt.title('Train & Validation Set Accuracy w.r.t to Tolerance tol')\nplt.grid(True)\nplt.plot(res_df_tol['tol'], res_df_tol['Train_acc'] , 'r*')\nplt.plot(res_df_tol['tol'], res_df_tol['Train_acc'] , 'y-')\nplt.plot(res_df_tol['tol'], res_df_tol['Val_acc'] , 'b.')\n#plt.plot(res_df_tol['tol'], res_df_tol['Build_time'] , 'g')","a8c9d6e9":"fig, ax = plt.subplots(nrows=2, ncols=1, figsize=(15,10))\n\nax[0].set(xlabel='tol', ylabel='Accuracy')\nax[0].set_title('Train & Validation Set Accuracy w.r.t to Tolerance tol')\nax[0].grid(True)\nax[0].plot(res_df_tol['tol'], res_df_tol['Train_acc'] , 'r*')\nax[0].plot(res_df_tol['tol'], res_df_tol['Train_acc'] , 'y')\nax[0].plot(res_df_tol['tol'], res_df_tol['Val_acc'] , 'b.')\n\nax[1].set(xlabel='tol', ylabel='Model Build Time')\nax[1].set_title('Model Build Time w.r.t to Tolerance tol')\nax[1].grid(True)\nax[1].plot(res_df_tol['tol'], res_df_tol['Build_time'] , 'r*')\nax[1].plot(res_df_tol['tol'], res_df_tol['Build_time'] , 'y')","5943405c":"# 3.1 Variation of tol wrt to the Solver\n\ntol=1e-10\niterations = 37\n\n# There are 5 solvers. For each, we need to see their accuracy on train & validation sets plus their build time.\n# Additionaly, first two columns are Sl & tol. Hence, a total of (5*3) + 2 = 17 columns reqd.\nresults = np.zeros((iterations, 17))\nsolver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n\nfor i in range(0,iterations):    \n    model_params = {'tol':tol,'random_state':1}\n    results[i][0:2] = i+1, tol\n    \n    j = 2 #internal counter for iterating over each of the solver's results values\n    for solver in solver_list:\n        model_params.update({'solver': solver})\n        acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n        acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n        results[i][j:j+3] = acc_tr, acc_val, time_val\n        j+=3\n        \n    tol*=2\n\ncolumns = ['Sl','tol']\nfor solver in solver_list:\n    columns.append('Train_acc_'+solver)\n    columns.append('Val_acc_'+solver)\n    columns.append('Build_time_'+solver)\n\nres_df_solver_tol = pd.DataFrame( data=results[0:,0:], \n                                  index=results[0:,0],\n                                  columns=columns)\nres_df_solver_tol['Sl'] = res_df_solver_tol['Sl'].astype(np.uint16)\nres_df_solver_tol.head()","2dcdc745":"fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15,15))\n\nax[0].set(xlabel='tol', ylabel='Accuracy')\nax[0].set_title('Variation in Training Data Accuracy w.r.t to Tolerance tol for different Solvers')\nax[0].grid(True)\n\ncolour_list = ['r','g','b','c','m']\nfor i in range(0,5):\n    ax[0].plot(res_df_solver_tol['tol'],\n               res_df_solver_tol['Train_acc_'+solver_list[i]],\n               colour_list[i]+'.-', label=solver_list[i])\nax[0].legend()\n\nax[1].set(xlabel='tol', ylabel='Accuracy')\nax[1].set_title('Variation in Validation Data Accuracy w.r.t to Tolerance tol for different Solvers')\nax[1].grid(True)\nfor i in range(0,5):\n    ax[1].plot(res_df_solver_tol['tol'],\n               res_df_solver_tol['Val_acc_'+solver_list[i]] ,\n               colour_list[i]+'.-', label=solver_list[i])    \nax[1].legend()\n    \nax[2].set(xlabel='tol', ylabel='Build_Time')\nax[2].set_title('Variation in Model Build Time w.r.t to Tolerance tol for different Solvers')\nax[2].grid(True)\nfor i in range(0,5):\n    ax[2].plot(res_df_solver_tol['tol'],\n               res_df_solver_tol['Build_time_'+solver_list[i]] ,\n               colour_list[i]+'.-', label=solver_list[i])  \nax[2].legend()\n","ab47b144":"# 3.2 Variation of C wrt to the Solver\n\nC=0.001\niterations = 500\n\n# There are 5 solvers. For each, we need to see their accuracy on train & validation sets plus their build time.\n# Additionaly, first two columns are Sl & C. Hence, a total of (5*3) + 2 = 17 columns reqd.\nresults = np.zeros((iterations, 17))\nsolver_list = ['liblinear', 'newton-cg', 'lbfgs', 'sag', 'saga']\n\nfor i in range(0,iterations):    \n    model_params = {'C':C,'random_state':1}\n    results[i][0:2] = i+1, C\n    \n    j = 2 #internal counter for iterating over each of the solver's results values\n    for solver in solver_list:\n        model_params.update({'solver': solver})\n        acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n        acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n        results[i][j:j+3] = acc_tr, acc_val, time_val\n        j+=3\n        \n    C+=0.005\n\ncolumns = ['Sl','C']\nfor solver in solver_list:\n    columns.append('Train_acc_'+solver)\n    columns.append('Val_acc_'+solver)\n    columns.append('Build_time_'+solver)\n\nres_df_solver_C = pd.DataFrame( data=results[0:,0:], \n                                  index=results[0:,0],\n                                  columns=columns)\nres_df_solver_C['Sl'] = res_df_solver_C['Sl'].astype(np.uint16)\nres_df_solver_C.head()","76d01f64":"fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15,30))\n\nax[0].set(xlabel='C', ylabel='Accuracy')\nax[0].set_title('Variation in Training Data Accuracy w.r.t to Inverse Regularization parameter C for different Solvers')\nax[0].grid(True)\n\ncolour_list = ['r','g','b','c','m']\nfor i in range(0,5):\n    ax[0].plot(res_df_solver_C['C'],\n               res_df_solver_C['Train_acc_'+solver_list[i]],\n               colour_list[i]+'-', label=solver_list[i])\nax[0].legend()\n\nax[1].set(xlabel='C', ylabel='Accuracy')\nax[1].set_title('Variation in Validation Data Accuracy w.r.t to Inverse Regularization parameter C for different Solvers')\nax[1].grid(True)\nfor i in range(0,5):\n    ax[1].plot(res_df_solver_C['C'],\n               res_df_solver_C['Val_acc_'+solver_list[i]] ,\n               colour_list[i]+'-', label=solver_list[i])    \nax[1].legend()\n    \nax[2].set(xlabel='C', ylabel='Build_Time')\nax[2].set_title('Variation in Model Build Time w.r.t to Inverse Regularization parameter C for different Solvers')\nax[2].grid(True)\nfor i in range(0,5):\n    ax[2].plot(res_df_solver_C['C'],\n               res_df_solver_C['Build_time_'+solver_list[i]] ,\n               colour_list[i]+'-', label=solver_list[i])  \nax[2].legend()","09d6ac42":"max_iter=5\niterations = 40\n\n# There are 3 solvers. For each, we need to see their accuracy on train & validation sets plus their build time.\n# Additionaly, first two columns are Sl & C. Hence, a total of (3*3) + 2 = 11 columns reqd.\nresults = np.zeros((iterations, 11))\nsolver_list = ['newton-cg', 'lbfgs', 'sag']\n\nfor i in range(0,iterations):    \n    model_params = {'max_iter':max_iter,'random_state':1}\n    results[i][0:2] = i+1, max_iter\n    \n    j = 2 #internal counter for iterating over each of the solver's results values\n    for solver in solver_list:\n        model_params.update({'solver': solver})\n        acc_val,time_val = evaluate(X_tr, Y_tr, X_val, Y_val, model_params)\n        acc_tr,time_tr = evaluate(X_tr, Y_tr, X_tr, Y_tr, model_params)\n        results[i][j:j+3] = acc_tr, acc_val, time_val\n        j+=3\n        \n    max_iter += 5\n\ncolumns = ['Sl','max_iter']\nfor solver in solver_list:\n    columns.append('Train_acc_'+solver)\n    columns.append('Val_acc_'+solver)\n    columns.append('Build_time_'+solver)\n\nres_df_solver_max_iter = pd.DataFrame( data=results[0:,0:], \n                                  index=results[0:,0],\n                                  columns=columns)\nres_df_solver_max_iter['Sl'] = res_df_solver_max_iter['Sl'].astype(np.uint16)\nres_df_solver_max_iter.head()","872c5189":"fig, ax = plt.subplots(nrows=3, ncols=1, figsize=(15,30))\n\nax[0].set(xlabel='max_iter', ylabel='Accuracy')\nax[0].set_title('Variation in Training Data Accuracy w.r.t to Max Iterations for different Solvers')\nax[0].grid(True)\n\ncolour_list = ['r*-','gv-','bs-']\nfor i in range(0,3):\n    ax[0].plot(res_df_solver_max_iter['max_iter'],\n               res_df_solver_max_iter['Train_acc_'+solver_list[i]],\n               colour_list[i]+'-', label=solver_list[i])\nax[0].legend()\n\nax[1].set(xlabel='max_iter', ylabel='Accuracy')\nax[1].set_title('Variation in Validation Data Accuracy w.r.t to Max Iterations for different Solvers')\nax[1].grid(True)\nfor i in range(0,3):\n    ax[1].plot(res_df_solver_max_iter['max_iter'],\n               res_df_solver_max_iter['Val_acc_'+solver_list[i]] ,\n               colour_list[i]+'-', label=solver_list[i])    \nax[1].legend()\n    \nax[2].set(xlabel='max_iter', ylabel='Build_Time')\nax[2].set_title('Variation in Model Build Time w.r.t to Max Iterations for different Solvers')\nax[2].grid(True)\nfor i in range(0,3):\n    ax[2].plot(res_df_solver_max_iter['max_iter'],\n               res_df_solver_max_iter['Build_time_'+solver_list[i]] ,\n               colour_list[i]+'-', label=solver_list[i])  \nax[2].legend()","6d853279":"# Final values for Log Reg:\nmodel_params = {'C':0.211, 'tol':1e-6, 'solver':'liblinear', 'random_state':1}\nmodel = LogisticRegression()\nmodel.set_params(**model_params)\nmodel.fit(X_tr,Y_tr)\nY_pred = model.predict(X_val)\nacc = accuracy_score(Y_val,Y_pred) * 100.0\nprint('Final Accuracy = {}%'.format(acc))\nresults_logreg = model.predict(test)","0fe24e1d":"submission = pd.DataFrame({\n        \"PassengerId\": test_Pids,\n        \"Survived\": results_logreg})","df203c19":"submission.to_csv(\"try_1_logreg.csv\", index=False)","b3cd0d7e":"#### 3.1 Variation of tol wrt to the Solver","9bfb7795":"### 4. One-hot encode categorical features  \nSex, Embarked, Title, Fare_bin, Age_bin","9d5661f4":"## Import Libaries","5d2ee60c":"## Read Files","0cb4f612":"#### 3.2 Variation of C wrt to the Solver","5039a991":"## Feature Engineering\n\n1. Add feature:  \n    a) FamilySize = Parch + SibSp  \n    b) Title = apply regex ([A-Za-z]+)\\. on Name \n2. Impute Missing values:  \n    a) Fare  \n    b) Age  \n    c) Embarked\n3. Bin feature  \n    a) Fare  \n    b) Age \n4. One-hot encode categorical features  \n    Sex, Embarked, Title, Fare_bin, Age_bin\n5. Drop Unnecessary features  \n    Name, Age, Fare  \n6. Typecast & Reduce Feature size from int64 to np.uint8  \n    Survived, Pclass, SibSp, Parch, FamilySize  \n\n##### Note that Double space(  ) works as newline in Jupyter Markdown .","6edee7f1":"### 5. Drop Unnecessary features  \nName, Age, Fare","04422d73":"Tolerance tol for Logistic regression represents when convergence is achieved for its gradience values in an iteration. Hence, to converge for lower values of tol, more number of iterations are needed at the expense of greater model build time. This is illustrated in Plot-2. \n\nBut, as we see in Plot-1, for a fast simple algorithm like Logistic Regression working on small sets of data, accuracy also increases for smaller values of tol. We see that, accuracy remains more or less constant between tol values of 0 & 0.33 for both sets. The dafult value of 1e-4 is sufficient for this case as further lowering it increases the buil time wihout any appreciable increase in accuracy. On the other hand, accuracy falls of pretty sharply once tol bcomes more than 1.8. Beyond, tol of ~3.4, accuracy again stabilizes in the low ~61%. \n\nBy running for greater values of tol upto tol=20, it was found to remain constant. Again, the tol graph will depend on many other factors like nature of the data & the internal solver, which we will see below.","6af098ec":"**Conclusion:** From the above plots, we can see that the default solver 'liblinear' loses accuracy rapidly with increaseing value of Tolerance(tol). This is countered by having the fastest build speed. For small values of tol, there is no practical difference in accuracy between the solvers. But as tol increases, the other solvers are able to maintain their accuracy with lbfgs & newton-cg remaining almost constant.","455bffd6":"**Conclusion:** As Regularization increases, the solvers have more or less similar performance in terms of accuracy with the liblinear giving the highest accuracy of all for a value of C which is the point where the model is neither under-fitted nor over-fitted. The region surrounding the liblinear peak shows the highest accuracy values for the other solvers too but without a peak. But given the size of the data & the number of iterations fixed at default 100(sag & saga did not converge with the default value), it cannot be concluded which solver is the best by accuracy. But, time wise, we see liblinear is the fastest while stochastic gradient methods(sag\/saga) being the slowest.","720e105e":"#### Create Train & Validation Sets","3f0b62e5":"### 4. Optimizing the max_iterations for a solver \n\nmax_iter : int, default: 100 : Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.\n","1349bdad":"C is the inverse of regularization strength. Hence, smaller values increase regularization & can result in underfitting while as we increase C, model becomes more prone to overfitting.  \nThus we find that, for the train data, model accuracy increases as C value increases. BUT, with increase in C,\nthe accuracy on validation data starts to increase initially before peaking at (0.211, 83.03571429). After that,\nthe effect of overfitting causes the accuracy to decrease. Hence the optimal value of C is 0.211","ef1ecf13":"### 6. Typecast & Reduce Feature size from int64 to np.uint8\nSurvived, Pclass, SibSp, Parch, FamilySize","dd9f5d82":"### 3. Bin feature","9b7e87e8":"### 2. Impute Missing Values  \n\nQ) Replace missing values :Mean or Median ?  \nA) https:\/\/www.quora.com\/What-is-more-accurate-the-median-or-mean  ","23209017":"# Titanic - Logistic Regression Hyperparameter Optimization\n\n**Author:** Arindam Chatterjee  \n**Start Date:** 23rd July, 2018\n\n**Purpose:** The objective of this notebook is to understand how the hyperparameters of an algorithm affect the predictive performance & how tuning them can help us optimize our goal. The goal itself can be simply accuracy or model build time. \n\nSince, this is my first try at Kaggle, I chose the simplest yet most tried out dataset of Titanic & a rather simplistic algorithm in Logistic Regression. I will continue to add new things in the notebook like more algorithms & visualizations whenever I get the time from my office work.","47a9eb40":"### 3. Optimizing the internal solver : \n\n** From sklearn documentation, **  \nsolver : {\u2018newton-cg\u2019, \u2018lbfgs\u2019, \u2018liblinear\u2019, \u2018sag\u2019, \u2018saga\u2019}, \ndefault: \u2018liblinear\u2019 Algorithm to use in the optimization problem.\n\na) For small datasets, \u2018liblinear\u2019 is a good choice, whereas \u2018sag\u2019 and \u2018saga\u2019 are faster for large ones.\n\nb) For multiclass problems, only \u2018newton-cg\u2019, \u2018sag\u2019, \u2018saga\u2019 and \u2018lbfgs\u2019 handle multinomial loss; \u2018liblinear\u2019 is limited to one-versus-rest schemes.\n\nc) \u2018newton-cg\u2019, \u2018lbfgs\u2019 and \u2018sag\u2019 only handle L2 penalty, whereas \u2018liblinear\u2019 and \u2018saga\u2019 handle L1 penalty.\n\nNote that \u2018sag\u2019 and \u2018saga\u2019 fast convergence is only guaranteed on features with approximately the same scale. You can preprocess the data with a scaler from sklearn.preprocessing.\n\nNew in version 0.17: Stochastic Average Gradient descent solver.\n\nNew in version 0.19: SAGA solver.\n\n**LIBLINEAR \u2013 A Library for Large Linear Classification**  \nhttp:\/\/www.csie.ntu.edu.tw\/~cjlin\/liblinear\/\n\n**SAG \u2013 Mark Schmidt, Nicolas Le Roux, and Francis Bach**  \nMinimizing Finite Sums with the Stochastic Average Gradient  \nhttps:\/\/hal.inria.fr\/hal-00860051\/document\n\n**SAGA \u2013 Defazio, A., Bach F. & Lacoste-Julien S. (2014).**  \nSAGA: A Fast Incremental Gradient Method With Support for Non-Strongly Convex Composite Objectives.  \nhttps:\/\/arxiv.org\/abs\/1407.0202\n\n**Hsiang-Fu Yu, Fang-Lan Huang, Chih-Jen Lin (2011). Dual coordinate descent**\nmethods for logistic regression and maximum entropy models. Machine Learning 85(1-2):41-75.  \nhttp:\/\/www.csie.ntu.edu.tw\/~cjlin\/papers\/maxent_dual.pdf\n","3646ff8b":"### 1. Optimizing C","5f06393b":"**Conclusion:** Solver newton-cg appears as the least susceptible to accuracy differences with variation in the maximum number of iterations allowed for convergence, for both train & validation data. Its build time also fluctuates the least & almost follows a parralel line to X-axis. After a certain value of max_iter, the other 2 solvers also have constant accuracy curves. But, sag build time increases consistently with time without any accuracy increase.","5ec55ef9":"### 1. Add Features","e5d30e24":"## Model Build & Optimizations  \n\nThe objective of this step is to visually understand how the different hyperparamaters & random_state affect\nthe outcome of the model ie: its predictive accuracy.   \nWe will initially go through each of them individually even though for most model algorithms, the hyperparameters\nare not independant of each other. The test set used will be constant thrughout the process.\n\nThe below data descriptions are taken from the sklearn documentation in:  \nhttp:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html  \n\n1. C : float, default: 1.0 : Inverse of regularization strength; must be a positive float. Like in support vector machines, smaller values specify stronger regularization.\n2. tol : float, default: 1e-4 : Tolerance for stopping criteria. This tells the algorithm to stop searching for a minimum (or maximum) once some tolerance is achieved, i.e. once it is close enough. \n3. solver : {\u2018newton-cg\u2019, \u2018lbfgs\u2019, \u2018liblinear\u2019, \u2018sag\u2019, \u2018saga\u2019}, default: \u2018liblinear\u2019 Algorithm to use in the optimization problem.\n4. max_iter : int, default: 100 : Useful only for the newton-cg, sag and lbfgs solvers. Maximum number of iterations taken for the solvers to converge.","baaa6fd5":"### 2. Optimzing tol (Tolerance for Stopping Criteria)  \n\ntol = Tolerance for stopping criteria. This tells the algorithm to stop searching for a minimum (or maximum) once some tolerance is achieved, i.e. once it is close enough. tol will change depending on the objective function being minimized\/maximized and the algorithm they use to find the minimum, and thus will depend on the model we are fitting.\n\nFor the newton-cg and lbfgs solvers, the iteration will stop when ``max{|g_i | i = 1, ..., n} <= tol`` where ``g_i`` is the i-th component of the gradient."}}