{"cell_type":{"1b12eb16":"code","dbdc253e":"code","47c16965":"code","33a121bf":"code","10a9c53e":"code","c39fcf11":"code","d8dfa028":"code","b60db659":"code","37b3d0d5":"code","b0e1e49b":"code","440e7b93":"code","206882dd":"code","6201cf67":"code","4de24dca":"code","b4b3e9d1":"code","02c3cce6":"code","8f77a733":"code","e08cda48":"code","d78cb193":"code","a5b1aa58":"code","9feff2cd":"code","1e78d255":"code","4795d47c":"code","0cde9181":"code","589763b7":"code","b1b5f986":"code","02182011":"code","d4314a5b":"code","7bcef891":"code","0167edea":"code","567d797b":"code","b0a88616":"code","315bb719":"code","24a91d6d":"code","652e1eed":"code","c69d14c7":"code","0dfe28da":"code","76617ac0":"code","9e522266":"code","cae229b1":"code","cf92183e":"code","3b0a518f":"code","c3ee634e":"markdown","84596ffb":"markdown","2cd7c1ed":"markdown","cea8ddb4":"markdown","4b9214a2":"markdown","a0df9a9a":"markdown","7007bb3a":"markdown","4e0530fd":"markdown","d364b6fc":"markdown","e1e11b26":"markdown","708645b0":"markdown","2c1b459c":"markdown","c48eb4b7":"markdown","dd18b5f7":"markdown","b8877ae2":"markdown","b0c1c32c":"markdown"},"source":{"1b12eb16":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dbdc253e":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import GridSearchCV","47c16965":"from sklearn.model_selection import train_test_split\n\ntrain = pd.read_csv('..\/input\/titanic\/train.csv')\ntest = pd.read_csv('..\/input\/titanic\/test.csv')\ny = train.Survived\npassengerid = test.PassengerId\n\n#Creating a whole dataset with train and test dataset \ntitanic = train.append(test, ignore_index = True)","33a121bf":"#Saving the train and test inde to split later\ntrain_index = len(train)\ntest_index = len(titanic) - len(test)","10a9c53e":"titanic.head()","c39fcf11":"titanic.info()","d8dfa028":"titanic['Title'] = titanic.Name.apply(lambda x: x.split(',')[1].split('.')[0].strip())","b60db659":"titanic.Title.value_counts()","37b3d0d5":"normalized_title = {\n            'Mr':\"Mr\",\n            'Mrs': \"Mrs\",\n            'Ms': \"Mrs\",\n            'Mme':\"Mrs\",\n            'Mlle':\"Miss\",\n            'Miss':\"Miss\",\n            'Master':\"Master\",\n            'Dr':\"Officer\",\n            'Rev':\"Officer\",\n            'Col':\"Officer\",\n            'Capt':\"Officer\",\n            'Major':\"Officer\",\n            'Lady':\"Royalty\",\n            'Sir':\"Royalty\",\n            'the Countess':\"Royalty\",\n            'Dona':\"Royalty\",\n            'Don':\"Royalty\",\n            'Jonkheer':\"Royalty\"\n            \n}","b0e1e49b":"titanic.Title = titanic.Title.map(normalized_title)","440e7b93":"print(titanic.Title.value_counts())","206882dd":"grouped = titanic.groupby(['Sex','Title','Pclass'])\nprint(grouped.Age.median())","6201cf67":"titanic.Age = grouped.Age.apply(lambda x: x.fillna(x.median()))\ntitanic.isnull().sum()","4de24dca":"#Since fare has only one missing value we will fill it with mean value\ntitanic.Fare = titanic.Fare.fillna(titanic.Fare.mean())\n\n#For the Cabin since it contains large number of missing values we will fill the unnown values as 'U'\ntitanic.Cabin = titanic.Cabin.fillna('U')\n\n#For the Embared we will fill it with the most frequent Embarked value\nmost_Embarked = titanic.Embarked.value_counts().index[0]\ntitanic.Embarked = titanic.Embarked.fillna(most_Embarked)","b4b3e9d1":"titanic.isnull().sum()","02c3cce6":"#We also the add the member along with the famlily count\ntitanic['FamilySize'] = titanic['SibSp'] + titanic['Parch'] + 1","8f77a733":"titanic.FamilySize.head()","e08cda48":"titanic['Cabin'].value_counts()","d78cb193":"titanic.Cabin = titanic.Cabin.map(lambda x: x[0])\ntitanic.Cabin.head()","a5b1aa58":"titanic.select_dtypes('object').columns","9feff2cd":"#Converting the male as 0 and female as 1 using the dictionary and mapping it\ntitanic.Sex = titanic.Sex.map({\"male\":0,\"female\":1})\n\n#Converting the Title ,Cabin, Pclass and Embarked using get_dummies()\ntitle_dummies = pd.get_dummies(titanic.Title , prefix = \"Title\")\ncabin_dummies = pd.get_dummies(titanic.Cabin , prefix = \"Cabin\")\npclass_dummies = pd.get_dummies(titanic.Pclass , prefix =\"Pclass\")\nembarked_dummies = pd.get_dummies(titanic.Embarked , prefix = \"Embarked\")","1e78d255":"#Concatinating dummy columns with main dataset\ntitanic_dummies = pd.concat([titanic , title_dummies,cabin_dummies,\n                             pclass_dummies,embarked_dummies],axis = 1)","4795d47c":"#Dropping the categorical columns in the titanic_dummies\ntitanic_dummies.drop(['Pclass', 'Title', 'Cabin', 'Embarked', 'Name', 'Ticket'],axis = 1,inplace = True)","0cde9181":"titanic_dummies.head()","589763b7":"train_x = titanic_dummies[:train_index]\ntest_x = titanic_dummies[train_index:]","b1b5f986":"#Now converting the Survived column as int\ntrain_x.Survived = train_x.Survived.astype(int)","02182011":"# create X and y for data and target values \nX = train_x.drop('Survived', axis=1).values \ny = train_x.Survived.values","d4314a5b":"train_x.head()","7bcef891":"# create array for test set\nX_test = test_x.drop('Survived', axis=1).values","0167edea":"label = train_x.Survived\ntrain_X , val_X , train_Y , val_Y = train_test_split(train_x , label,test_size = 0.2,shuffle = True)","567d797b":"val_X.shape","b0a88616":"dtrain_X = train_X.drop('Survived',axis = 1)","315bb719":"dval_X = val_X.drop('Survived',axis = 1)","24a91d6d":"#Creating parameters for the tuning of model in grid search\nparams = dict(\n            max_depth = [n for n in range(9,15)],\n            min_samples_split = [n for n in range(4, 11)], \n            min_samples_leaf = [n for n in range(2, 5)],     \n            n_estimators = [n for n in range(10, 60, 10)],\n)","652e1eed":"#Classifer we are using is RandomForest\nmodel_forest = RandomForestClassifier()","c69d14c7":"#Building and fitting the model\nforest_gs = GridSearchCV(param_grid=params,\n                         estimator=model_forest,\n                         cv=5)\n\n#forest_gs.fit(X,y)\n\n#Trying to fit the model with train_test_split train data which is train_X\nforest_gs.fit(dtrain_X,train_Y)","0dfe28da":"forest_gs.best_score_","76617ac0":"forest_gs.best_estimator_","9e522266":"from sklearn.metrics import mean_absolute_error\np = forest_gs.predict(dval_X)\nprint(mean_absolute_error(p,val_Y))","cae229b1":"prediction_Random_forest = forest_gs.predict(X_test)\nprediction_Random_forest","cf92183e":"#storing it in submission file\noutput = pd.DataFrame({\"PassengerId\":passengerid , \"Survived\" : prediction_Random_forest})\noutput.to_csv(\"Submission5.csv\",index = False)","3b0a518f":"output","c3ee634e":"From the above output we can see that Age,Cabin and Fare have some missing values.\nFirst we will try to focus on the age","84596ffb":"# Creating the model","2cd7c1ed":"From the above we see that there are different categories of titles present now we will normalise them into broader category below.","cea8ddb4":"Spliting a training set into training and validation set","4b9214a2":"In the below code we will create a new feature which is total family members count by adding the SibSp and Parch.","a0df9a9a":"In the below cell we will split the Name column into a broad category based on the given and replace the name with that.\nFor example, if the name is Robert,Mr.Jackson then we wil categorize him into Mr. that was present in his name. ","7007bb3a":"Getting the input and storing it as train and test sets","4e0530fd":"The main reason we created title is because we have to fill the missing age.","d364b6fc":"Splitting the dataset as train and test from the titanic using the index we stored before.","e1e11b26":"# Handling with missing values","708645b0":"Now we dont have any missing values. we have to handle the categorical variables.","2c1b459c":"The below is the reference from the https:\/\/medium.com\/i-like-big-data-and-i-cannot-lie\/how-i-scored-in-the-top-9-of-kaggles-titanic-machine-learning-challenge-243b5f45c8e9.","c48eb4b7":"Before creating the model we have convert all our Categorical variables into numerical.Here we will use get_dummies() of pandas to do that work.","dd18b5f7":"There are total of 187 cabin values present including the 'U' (unknown) we filled. Now instead of some alpha numeric value we will simply map it to the first letter of the value.","b8877ae2":"We have filled the Age values in the missing columns now we have to fill the Cabin , Embarked and Fare.","b0c1c32c":"# Feature Engineering"}}