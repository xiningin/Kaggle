{"cell_type":{"bca1107a":"code","64f41849":"code","f242f995":"code","54804b93":"code","9f3ca406":"code","3fc6a469":"code","01d38813":"code","d245c7df":"code","120abf6b":"code","a841c1be":"code","f0ba565a":"code","13ae7671":"code","ad5f69f6":"code","8340e8a0":"code","e9cbf599":"code","32a315d3":"code","8a7c90e0":"code","4915148e":"code","debe148b":"code","b5d7d63e":"code","51604c1c":"code","187b33d3":"code","8d0a063e":"code","3a452652":"code","3d3bbd48":"code","6b93d7fe":"code","dbdcb6d5":"code","a633ce81":"code","987f5190":"code","cf19e117":"code","6924f3b6":"code","acc3fb13":"code","34fcc5b1":"code","1f568fc5":"code","990a01d0":"code","11c5c387":"code","2c82261d":"code","d914a609":"code","1983bf93":"code","601cbdd7":"code","e65dab30":"code","0ca7a770":"code","3b2b307f":"markdown","9bae54d5":"markdown","8ab6d87f":"markdown","91d42e12":"markdown","20ddbe0d":"markdown","20511504":"markdown","92d047be":"markdown","cc2f4d29":"markdown","f49a17ed":"markdown"},"source":{"bca1107a":"import numpy as np \nimport pandas as pd \n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nsns.set_style(\"whitegrid\")\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","64f41849":"training = pd.read_csv(\"..\/input\/titanic\/train.csv\")\ntesting = pd.read_csv(\"..\/input\/titanic\/test.csv\")","f242f995":"training.head()","54804b93":"training.describe()","9f3ca406":"print(training.keys())\nprint(testing.keys())","3fc6a469":"def null_table(training, testing):\n    print(\"Training Data Frame\")\n    print(pd.isnull(training).sum()) \n    print(\" \")\n    print(\"Testing Data Frame\")\n    print(pd.isnull(testing).sum())\n\nnull_table(training, testing)","01d38813":"training.drop(labels = [\"Cabin\", \"Ticket\"], axis = 1, inplace = True)\ntesting.drop(labels = [\"Cabin\", \"Ticket\"], axis = 1, inplace = True)\n\nnull_table(training, testing)","d245c7df":"copy = training.copy()\ncopy.dropna(inplace = True)\nsns.distplot(copy[\"Age\"])","120abf6b":"#the median will be an acceptable value to place in the NaN cells\ntraining[\"Age\"].fillna(training[\"Age\"].median(), inplace = True)\ntesting[\"Age\"].fillna(testing[\"Age\"].median(), inplace = True) \ntraining[\"Embarked\"].fillna(\"S\", inplace = True)\ntesting[\"Fare\"].fillna(testing[\"Fare\"].median(), inplace = True)\n\nnull_table(training, testing)\n","a841c1be":"#can ignore the testing set for now\nsns.barplot(x=\"Sex\", y=\"Survived\", data=training)\nplt.title(\"Distribution of Survival based on Gender\")\nplt.show()\n\ntotal_survived_females = training[training.Sex == \"female\"][\"Survived\"].sum()\ntotal_survived_males = training[training.Sex == \"male\"][\"Survived\"].sum()\n\nprint(\"Total people survived is: \" + str((total_survived_females + total_survived_males)))\nprint(\"Proportion of Females who survived:\") \nprint(total_survived_females\/(total_survived_females + total_survived_males))\nprint(\"Proportion of Males who survived:\")\nprint(total_survived_males\/(total_survived_females + total_survived_males))","f0ba565a":"sns.barplot(x=\"Pclass\", y=\"Survived\", data=training)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Distribution of Survival Based on Class\")\nplt.show()\n\ntotal_survived_one = training[training.Pclass == 1][\"Survived\"].sum()\ntotal_survived_two = training[training.Pclass == 2][\"Survived\"].sum()\ntotal_survived_three = training[training.Pclass == 3][\"Survived\"].sum()\ntotal_survived_class = total_survived_one + total_survived_two + total_survived_three\n\nprint(\"Total people survived is: \" + str(total_survived_class))\nprint(\"Proportion of Class 1 Passengers who survived:\") \nprint(total_survived_one\/total_survived_class)\nprint(\"Proportion of Class 2 Passengers who survived:\")\nprint(total_survived_two\/total_survived_class)\nprint(\"Proportion of Class 3 Passengers who survived:\")\nprint(total_survived_three\/total_survived_class)","13ae7671":"sns.barplot(x=\"Pclass\", y=\"Survived\", hue=\"Sex\", data=training)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\")\n#help(sns.barplot)","ad5f69f6":"sns.barplot(x=\"Sex\", y=\"Survived\", hue=\"Pclass\", data=training)\nplt.ylabel(\"Survival Rate\")\nplt.title(\"Survival Rates Based on Gender and Class\")","8340e8a0":"survived_ages = training[training.Survived == 1][\"Age\"]\nnot_survived_ages = training[training.Survived == 0][\"Age\"]\nplt.subplot(1, 2, 1)\nsns.distplot(survived_ages, kde=False)\nplt.axis([0, 100, 0, 100])\nplt.title(\"Survived\")\nplt.ylabel(\"Proportion\")\nplt.subplot(1, 2, 2)\nsns.distplot(not_survived_ages, kde=False)\nplt.axis([0, 100, 0, 100])\nplt.title(\"Didn't Survive\")\nplt.show()","e9cbf599":"sns.stripplot(x=\"Survived\", y=\"Age\", data=training, jitter=True)","32a315d3":"sns.pairplot(training)","8a7c90e0":"training.sample(5)","4915148e":"testing.sample(5)","debe148b":"training.loc[training[\"Sex\"] == \"male\", \"Sex\"] = 0\ntraining.loc[training[\"Sex\"] == \"female\", \"Sex\"] = 1\n\ntraining.loc[training[\"Embarked\"] == \"S\", \"Embarked\"] = 0\ntraining.loc[training[\"Embarked\"] == \"C\", \"Embarked\"] = 1\ntraining.loc[training[\"Embarked\"] == \"Q\", \"Embarked\"] = 2\n\ntesting.loc[testing[\"Sex\"] == \"male\", \"Sex\"] = 0\ntesting.loc[testing[\"Sex\"] == \"female\", \"Sex\"] = 1\n\ntesting.loc[testing[\"Embarked\"] == \"S\", \"Embarked\"] = 0\ntesting.loc[testing[\"Embarked\"] == \"C\", \"Embarked\"] = 1\ntesting.loc[testing[\"Embarked\"] == \"Q\", \"Embarked\"] = 2","b5d7d63e":"testing.sample(10)","51604c1c":"training[\"FamSize\"] = training[\"SibSp\"] + training[\"Parch\"] + 1\ntesting[\"FamSize\"] = testing[\"SibSp\"] + testing[\"Parch\"] + 1","187b33d3":"training[\"IsAlone\"] = training.FamSize.apply(lambda x: 1 if x == 1 else 0)\ntesting[\"IsAlone\"] = testing.FamSize.apply(lambda x: 1 if x == 1 else 0)","8d0a063e":"for name in training[\"Name\"]:\n    training[\"Title\"] = training[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \nfor name in testing[\"Name\"]:\n    testing[\"Title\"] = testing[\"Name\"].str.extract(\"([A-Za-z]+)\\.\",expand=True)\n    \ntitle_replacements = {\"Mlle\": \"Other\", \"Major\": \"Other\", \"Col\": \"Other\", \"Sir\": \"Other\", \"Don\": \"Other\", \"Mme\": \"Other\",\n          \"Jonkheer\": \"Other\", \"Lady\": \"Other\", \"Capt\": \"Other\", \"Countess\": \"Other\", \"Ms\": \"Other\", \"Dona\": \"Other\", \"Rev\": \"Other\", \"Dr\": \"Other\"}\n\ntraining.replace({\"Title\": title_replacements}, inplace=True)\ntesting.replace({\"Title\": title_replacements}, inplace=True)\n\ntraining.loc[training[\"Title\"] == \"Miss\", \"Title\"] = 0\ntraining.loc[training[\"Title\"] == \"Mr\", \"Title\"] = 1\ntraining.loc[training[\"Title\"] == \"Mrs\", \"Title\"] = 2\ntraining.loc[training[\"Title\"] == \"Master\", \"Title\"] = 3\ntraining.loc[training[\"Title\"] == \"Other\", \"Title\"] = 4\n\ntesting.loc[testing[\"Title\"] == \"Miss\", \"Title\"] = 0\ntesting.loc[testing[\"Title\"] == \"Mr\", \"Title\"] = 1\ntesting.loc[testing[\"Title\"] == \"Mrs\", \"Title\"] = 2\ntesting.loc[testing[\"Title\"] == \"Master\", \"Title\"] = 3\ntesting.loc[testing[\"Title\"] == \"Other\", \"Title\"] = 4","3a452652":"print(set(training[\"Title\"]))","3d3bbd48":"training.sample(5)","6b93d7fe":"from sklearn.svm import SVC, LinearSVC\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier","dbdcb6d5":"from sklearn.metrics import make_scorer, accuracy_score ","a633ce81":"from sklearn.model_selection import GridSearchCV","987f5190":"features = [\"Pclass\", \"Sex\", \"Age\", \"Embarked\", \"Fare\", \"FamSize\", \"IsAlone\", \"Title\"]\nX_train = training[features] #define training features set\ny_train = training[\"Survived\"] #define training label set\nX_test = testing[features] #define testing features set\n#we don't have y_test, that is what we're trying to predict with our model","cf19e117":"from sklearn.model_selection import train_test_split #to create validation data set\n\nX_training, X_valid, y_training, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=0) #X_valid and y_valid are the validation sets","6924f3b6":"svc_clf = SVC() \nsvc_clf.fit(X_training, y_training)\npred_svc = svc_clf.predict(X_valid)\nacc_svc = accuracy_score(y_valid, pred_svc)\n\nprint(acc_svc)","acc3fb13":"svc_clf = SVC() \nsvc_clf.fit(X_training, y_training)\npred_svc = svc_clf.predict(X_valid)\nacc_svc = accuracy_score(y_valid, pred_svc)\n\nprint(acc_svc)","34fcc5b1":"rf_clf = RandomForestClassifier()\nrf_clf.fit(X_training, y_training)\npred_rf = rf_clf.predict(X_valid)\nacc_rf = accuracy_score(y_valid, pred_rf)\n\nprint(acc_rf)","1f568fc5":"logreg_clf = LogisticRegression()\nlogreg_clf.fit(X_training, y_training)\npred_logreg = logreg_clf.predict(X_valid)\nacc_logreg = accuracy_score(y_valid, pred_logreg)\n\nprint(acc_logreg)","990a01d0":"knn_clf = KNeighborsClassifier()\nknn_clf.fit(X_training, y_training)\npred_knn = knn_clf.predict(X_valid)\nacc_knn = accuracy_score(y_valid, pred_knn)\n\nprint(acc_knn)","11c5c387":"gnb_clf = GaussianNB()\ngnb_clf.fit(X_training, y_training)\npred_gnb = gnb_clf.predict(X_valid)\nacc_gnb = accuracy_score(y_valid, pred_gnb)\n\nprint(acc_gnb)","2c82261d":"dt_clf = DecisionTreeClassifier()\ndt_clf.fit(X_training, y_training)\npred_dt = dt_clf.predict(X_valid)\nacc_dt = accuracy_score(y_valid, pred_dt)\n\nprint(acc_dt)","d914a609":"model_performance = pd.DataFrame({\n    \"Model\": [\"SVC\", \"Linear SVC\", \"Random Forest\", \n              \"Logistic Regression\", \"K Nearest Neighbors\", \"Gaussian Naive Bayes\",  \n              \"Decision Tree\"],\n    \"Accuracy\": [acc_svc, acc_linsvc, acc_rf, \n              acc_logreg, acc_knn, acc_gnb, acc_dt]\n})\n\nmodel_performance.sort_values(by=\"Accuracy\", ascending=False)","1983bf93":"rf_clf = RandomForestClassifier()\n\nparameters = {\"n_estimators\": [4, 5, 6, 7, 8, 9, 10, 15], \n              \"criterion\": [\"gini\", \"entropy\"],\n              \"max_features\": [\"auto\", \"sqrt\", \"log2\"], \n              \"max_depth\": [2, 3, 5, 10], \n              \"min_samples_split\": [2, 3, 5, 10],\n              \"min_samples_leaf\": [1, 5, 8, 10]\n             }\n\ngrid_cv = GridSearchCV(rf_clf, parameters, scoring = make_scorer(accuracy_score))\ngrid_cv = grid_cv.fit(X_train, y_train)\n\nprint(\"Our optimized Random Forest model is:\")\ngrid_cv.best_estimator_","601cbdd7":"rf_clf = grid_cv.best_estimator_\n\nrf_clf.fit(X_train, y_train)","e65dab30":"submission_predictions =rf_clf.predict(X_test)","0ca7a770":"submission = pd.DataFrame({\n        \"PassengerId\": testing[\"PassengerId\"],\n        \"Survived\": submission_predictions\n    })\n\nsubmission.to_csv(\"titanic.csv\", index=False)\nprint(submission.shape)","3b2b307f":"## 8. Tuning Parameters with GridSearchCV ","9bae54d5":"## 6. Model Fitting and Predicting","8ab6d87f":"## 4. Plotting and Visualizing Data ","91d42e12":"# 5. Feature Engineering","20ddbe0d":"## 1. Importing Libraries and Packages ","20511504":"## 9. Submission ","92d047be":"## 7. Evaluating Model Performances","cc2f4d29":"## 2. Loading and Viewing Data Set ","f49a17ed":"## 3. Dealing with NaN Values (Imputation) "}}