{"cell_type":{"a1c4647b":"code","048c0c79":"code","ae125a56":"code","e2769d52":"code","28c33389":"code","81635e1d":"code","ef74c42e":"code","0f102aa3":"code","c6dd4de0":"code","e114f04c":"code","e51cacfd":"code","a696dbed":"code","e5a16adc":"code","775063b1":"code","6de4447f":"code","7116c201":"code","7f652137":"code","03f79a77":"code","659f0627":"code","a9af738b":"code","90dd3f0f":"code","de829cba":"code","299022c5":"code","d905b8c2":"code","c6bcc598":"code","6b5dc647":"code","ba34988b":"code","67bc67f5":"code","2387de10":"code","ac398d3b":"code","364eb00c":"code","6ecaa5d4":"code","819828ed":"code","73d952d0":"code","6f6501a4":"code","e265c14f":"code","c3fbb432":"code","ffbc1e7f":"code","f6cd9c2a":"code","52e8db41":"code","a9bc0010":"code","bd1ed7be":"code","381c11b1":"code","833a050d":"code","c188692a":"code","b62c813e":"code","f27c68d5":"code","85a07946":"code","de0cd3d9":"code","5dd5b0b9":"code","66fc86ad":"code","188a8d32":"code","67ae4860":"code","315970a5":"code","e0de8d4d":"code","fe67bbd6":"code","ac17dfb9":"code","49990f26":"code","df777ec6":"code","e157eece":"code","0da878ee":"markdown","88bbbbba":"markdown","31a80387":"markdown","02076e7d":"markdown","16d91b12":"markdown","ccf16d5c":"markdown","74117fca":"markdown","301714a5":"markdown","aae227e4":"markdown","5446bad8":"markdown","7cf6b3f5":"markdown","4da9b810":"markdown","84db4df5":"markdown","63d731af":"markdown","c605accc":"markdown","f1d1b152":"markdown","b3f5e393":"markdown","a68bf941":"markdown","23393e57":"markdown","4f7fff12":"markdown","f2c3ff0c":"markdown","f9df893d":"markdown","68575c29":"markdown","89708a9b":"markdown","8dd4dceb":"markdown","787984ab":"markdown","db4e975b":"markdown","3f2c88b9":"markdown","fd71d111":"markdown","9a5dedc1":"markdown"},"source":{"a1c4647b":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","048c0c79":"# import the libraries\nimport pandas as pd\nimport numpy as np\n\n#visualizations\nimport matplotlib.pyplot as plt\nimport seaborn\n%matplotlib inline\n\n# handle warnings\nimport warnings\nwarnings.filterwarnings(action='ignore',category=DeprecationWarning)\nwarnings.filterwarnings(action='ignore',category=FutureWarning)\n\n# consistent size plots\nfrom pylab import rcParams\nrcParams['figure.figsize'] = (12,5)","ae125a56":"# load a stationary data - Daily total female child birth\nfemale = pd.read_csv('\/kaggle\/input\/time-series-data-1\/DailyTotalFemaleBirths.csv',index_col='Date',\n                    parse_dates=True)\nfemale.index.freq = 'D'\n\n# load a non stationary data - yearly airline passenger dataset\nairline = pd.read_csv('\/kaggle\/input\/time-series-data-1\/airline_passengers.csv',index_col='Month',\n                     parse_dates=True)\n\nairline.index.freq = 'MS'","e2769d52":"pip install pmdarima ","28c33389":"from pmdarima import auto_arima","81635e1d":"#help(auto_arima) ","ef74c42e":"# perform grid search on the stationary dataset\nstepwise_fit1 = auto_arima(female['Births'],error_action='ignore',start_p=0,start_q=0,\n                          max_p=3,max_q=3,m=12,seasonal=False,trace=True,\n                          suppress_warnings=True,stepwise=True)","0f102aa3":"# Retrieve the summary from the grid search \nstepwise_fit1.summary()","c6dd4de0":"stepwise_fit2 =  auto_arima(airline['Thousands of Passengers'],error_action='ignore',\n                           start_p=1,max_p=5,start_q=1,max_q=5,m=12,\n                            suppress_warnings=True,trace=True,seasonal=True,stepwise=True)","e114f04c":"stepwise_fit2.summary()","e51cacfd":"# Import the statsmodels libraries needed\nfrom statsmodels.tsa.stattools import adfuller\nfrom statsmodels.graphics.tsaplots import plot_acf,plot_pacf\nfrom pmdarima import auto_arima\n\n# ETS decomposition\nfrom statsmodels.tsa.seasonal import seasonal_decompose\n\n# time series plotting - check for lags, trend and seasonality\nfrom pandas.plotting import lag_plot\nfrom statsmodels.graphics.tsaplots import month_plot, quarter_plot","a696dbed":"# load the trade data\ntrade = pd.read_csv('\/kaggle\/input\/time-series-data-1\/TradeInventories.csv',index_col='Date',\n                   parse_dates=True)","e5a16adc":"trade.head()","775063b1":"# set the frequency to the datetime index\ntrade.index.freq = 'MS'","6de4447f":"import matplotlib.ticker as ticker\nformatter = ticker.StrMethodFormatter('{x:,.0f}')\n\ntitle = 'Real Manufacturing and Trade Inventories'\nylabel='Chained 2012 Dollars'\nxlabel='' # we don't really need a label here\n\nax = trade['Inventories'].plot(figsize=(12,5),title=title)\nax.autoscale(axis='x',tight=True)\nax.set(xlabel=xlabel, ylabel=ylabel)\nax.yaxis.set_major_formatter(formatter);","7116c201":"decompose = seasonal_decompose(trade['Inventories'],model='additive')","7f652137":"decompose.plot();","03f79a77":"from statsmodels.tsa.stattools import adfuller\n\ndef adf_test(series,title=''):\n    \"\"\"\n    Pass in a time series and an optional title, returns an ADF report\n    \"\"\"\n    print(f'Augmented Dickey-Fuller Test: {title}')\n    result = adfuller(series.dropna(),autolag='AIC') # .dropna() handles differenced data\n    \n    labels = ['ADF test statistic','p-value','# lags used','# observations']\n    out = pd.Series(result[0:4],index=labels)\n\n    for key,val in result[4].items():\n        out[f'critical value ({key})']=val\n        \n    print(out.to_string())          # .to_string() removes the line \"dtype: float64\"\n    \n    if result[1] <= 0.05:\n        print(\"Strong evidence against the null hypothesis\")\n        print(\"Reject the null hypothesis\")\n        print(\"Data has no unit root and is stationary\")\n    else:\n        print(\"Weak evidence against the null hypothesis\")\n        print(\"Fail to reject the null hypothesis\")\n        print(\"Data has a unit root and is non-stationary\")","659f0627":"adf_test(trade['Inventories'],title='Trade Inventories')","a9af738b":"lag_plot(trade['Inventories'])\nplt.title('Lag Plot of Inventories');","90dd3f0f":"stepwise_fit = auto_arima(trade['Inventories'], start_p=0, start_q=0,\n                          max_p=3, max_q=3, m=12,\n                          seasonal=False,\n                          d=None, trace=True,\n                          error_action='ignore',   \n                          suppress_warnings=True,  \n                          stepwise=True)           \n\nstepwise_fit.summary()","de829cba":"from statsmodels.tsa.arima_model import ARIMA,ARIMAResults","299022c5":"len(trade)","d905b8c2":"train_trade = trade.iloc[:252]\ntest_trade = trade.iloc[252:] ","c6bcc598":"model = ARIMA(train_trade['Inventories'],order=(1,1,1))","6b5dc647":"results = model.fit()\nresults.summary()","ba34988b":"start = len(train_trade)\nend = len(train_trade)+len(test_trade)-1 \npredictions = results.predict(start=start,end=end,dynamic=False,typ='levels').rename('ARIMA(1,1,1)')","67bc67f5":"# lets plot the train and test data\ntrain_trade.plot(legend=True)\npredictions.plot(legend=True)","2387de10":"from statsmodels.tools.eval_measures import mse, rmse","ac398d3b":"mse(test_trade['Inventories'],predictions)","364eb00c":"rmse(test_trade['Inventories'],predictions)","6ecaa5d4":"start = len(trade)\nend = len(trade) + 12","819828ed":"# first we will fit the ARIMA model on the entire dataset\nmodel = ARIMA(trade['Inventories'],order=(1,1,1))","73d952d0":"fit = model.fit()\nfit.summary()","6f6501a4":"forecast = fit.predict(start=start,end=end,typ='levels',dynamic=False).rename('ARIMA(1,1,1) Forecast')","e265c14f":"formatter = ticker.StrMethodFormatter('{x:,.0f}')\n\ntitle = 'Real Manufacturing and Trade Inventories'\nylabel='Chained 2012 Dollars'\nxlabel='' # we don't really need a label here\n\nax = trade['Inventories'].plot(figsize=(12,5),title=title,legend=True)\nax = forecast.plot(legend=True)\nax.autoscale(axis='x',tight=True)\nax.set(xlabel=xlabel, ylabel=ylabel)\nax.yaxis.set_major_formatter(formatter);","c3fbb432":"# load specific statsmodel tools \nfrom statsmodels.tsa.statespace.sarimax import SARIMAX","ffbc1e7f":"# load the new dataset on CO2 emission\ndf = pd.read_csv('\/kaggle\/input\/time-series-data-1\/co2_mm_mlo.csv')","f6cd9c2a":"# see the first few of the data\ndf.head()","52e8db41":"df['date'] = pd.to_datetime(dict(year=df['year'],month=df['month'],day=1))","a9bc0010":"df.head()","bd1ed7be":"# set the date to be the index \ndf.set_index('date',inplace=True)\ndf.index.freq = 'MS'\n","381c11b1":"df.head()","833a050d":"df.info()","c188692a":"# plot the co2 emissions\ndf['interpolated'].plot(legend=True,title='CMonthly Mean CO\u2082 Levels (ppm) over Mauna Loa, Hawaii')\nplt.ylabel('parts per Million');","b62c813e":"# decompose into trend and seasonality \nresult =  seasonal_decompose(df['interpolated'],model='additive')","f27c68d5":"result.plot();","85a07946":"# check for stationarity\nadf_test(df['interpolated'],title='CO2 Emission Data')","de0cd3d9":"# use auto arima to determine the best order on this dataset\nstepwise_fit = auto_arima(df['interpolated'],error_action='ignore',seasonal=True,m=12,trace=True)\n","5dd5b0b9":"stepwise_fit.summary()","66fc86ad":"len(df)","188a8d32":"# Set one year for testing\ntrain = df.iloc[:717]\ntest = df.iloc[717:]","67ae4860":"model = SARIMAX(train['interpolated'],order=(2,1,1),seasonal_order=(1,0,1,12))\nresults = model.fit()\nresults.summary()","315970a5":"# Obtain predicted test values\nstart=len(train)\nend=len(train)+len(test)-1\npredictions = results.predict(start=start,end=end,dynamic=False,typ='levels').rename('SARIMA(2,1,1) x (1,0,1,12) Predictions')","e0de8d4d":"from statsmodels.tools.eval_measures import rmse,mse","fe67bbd6":"RMSE = rmse(test['interpolated'],predictions)\nprint(f'Root Mean Squared Error = {RMSE}')","ac17dfb9":"test['interpolated'].mean()","49990f26":"# train on the entire data first\nmodel = SARIMAX(df['interpolated'],order=(2,1,1),seasonal_order=(1,0,1,12))\nresults = model.fit()\nresults.summary()","df777ec6":"start = len(df)\nend = len(df) + 23\nforecast = results.predict(start=start,end=end,dynamic=False,typ='levels').rename('SARIMA(2,1,1)x(1,0,1,12) Forecast')","e157eece":"# Plot predictions against known values\ntitle = 'Monthly Mean CO\u2082 Levels (ppm) over Mauna Loa, Hawaii'\nylabel='parts per million'\nxlabel=''\n\nax = df['interpolated'].plot(legend=True,figsize=(12,6),title=title)\nforecast.plot(legend=True)\nax.autoscale(axis='x',tight=True)\nax.set(xlabel=xlabel, ylabel=ylabel);","0da878ee":"As there is a lag involved, we would still pick the p to be 1 and d to be 1 for differencing as the data is not stationary. Looking at the output of the grid search above, the next best AIC is returned for ARIMA(1,1,1)","88bbbbba":"## Split the data into train and test set\n","31a80387":"So the order to be used is $SARIMAX(2, 1, 1)x(1, 0, 1, 12)$","02076e7d":"There is trend but the seasonal component does not contribute to the behavior of the series.","16d91b12":"## Thank you","ccf16d5c":"Only the feature 'average' has a few null values. These missing values have been imputed and is available under the interpolated column. Hence we will use interpolated for building the $SARIMA$ model. ","74117fca":"Lets run the grid search using pmdarima's auto_arima to figure out the best order for p,d and q on this dataset using AIC as the measurable criterion.","301714a5":"## pmdarima Auto-ARIMA","aae227e4":"## Fit an ARIMA model","5446bad8":"# ARIMA\n## Auto Regressive Integrated Moving Average for Time Series Forecasting\n\nThis is the third notebook on time series starter series. The other two can be accessed via the below links \n- https:\/\/www.kaggle.com\/prakharprasad\/smoothing-holt-winters-forecast\n- https:\/\/www.kaggle.com\/prakharprasad\/time-series-ar-model-stationarity-test\n","7cf6b3f5":"ARIMA is a combination of 3 models.\n1. AR(p) - Autoregression - a regression model that utilizes the dependency between a current observation with the lagged observations at the previous period. \n2. I(d) Integration - uses differencing of observations (subtracting an observation from an observation at a previous time step) in order to make the time series stationary.\n3. MA(q) Moving Average - a model that uses the dependency between a current observation with the residual of the moving average applied to lagged observations. ","4da9b810":"## Evaluate the ARIMA model","84db4df5":"## Forecast into the future","63d731af":"Visualise the seasonality and trend using the month plot in statsmodels.","c605accc":"## Evaluate the model","f1d1b152":"So here we do not have a separate date column. But we can build it using the column on year, month and day.","b3f5e393":"So as per the dickey fuller test, the trade data is non stationary. Hence we will have to make use of the differencing or in other words the Integrated order in the ARIMA model. The lag plot should show a strong linear relationship ie the corrleation between the current observation and lagged observation would be linearly strong. ","a68bf941":"The data is non stationary as per the Augmented Dickey Fuller test. ","23393e57":"## Split the data into train and test set\n","4f7fff12":"## Fit a SARIMA(2,1,1)(1,0,1,12) Model","f2c3ff0c":"We will perform stepwise search  to minimize AIC. With auro arima, grid search can be performed where it tries to minimize the AIC (default metric). More information can be udnerstood with help(auto_arima) ","f9df893d":"# Part-III SARIMA or Seasonal ARIMA\nWhile ARIMA accpets the parameters (p,d,q), seasonal ARIMA accepts additional parameters (P,D,Q)m which specifically describes the seasonal component of the time series. Here, $P$ $D$ $Q$ represent the seasonal regression, differencing, and moving average coefficients and m represents the number of data points or rows in each seasonal cycle.\n\nThe statsmodel implementation of SARIMA is called SARIMAX where X represents that the function also supports the $exogenous$ regressor variables. In this notebook, only the endogenous time series are used. ","68575c29":"## Forecast into the real future","89708a9b":"# Part-II ARMA and ARIMA\n## Putting it all together \n- Load the time series dataset\n- Test for Stationarity using Augmented Dickey Fuller Test\n- ETS decomposition (Error, Trend and Seasonality) \n- Deciding on the best order for ARMA and ARIMA using auto_arima\n- Modeling and Forecast","8dd4dceb":"We will apply the auto arima on the stationary as well as the non stationary and seasonal dataset.","787984ab":"## Obtain the predicted values","db4e975b":"So, the best order for p,d,q is 1,1,1 for the female stationary dataset. Lets repeat this step for the non stationary and seasonal dataset of monthly airline passengers. ","3f2c88b9":"# Part-I Choosing ARIMA Orders (p,d,q)\nHere I just demonstrate how to perform grid search using pmdarima to decide the orders for ARIMA model both for stationary and non stationary dataset. In previous notebooks on test for stationarity and seasonality is already covered. Hence for airline and female birth it is already known that they are seasonal non stationary and stationary respectively. Later in Part-II of this notebook, I will run a mini project on a new dataset where we do not have prior information about whether it is seasonal or not, stationary or not.","fd71d111":"### Import the ARIMA model","9a5dedc1":"There seems to be yearly seasonality in the data. The trend is very visible. "}}