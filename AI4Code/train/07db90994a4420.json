{"cell_type":{"9755db05":"code","cadb7150":"code","33526deb":"code","2bbd69a9":"code","23eb62ab":"code","a3c2fd78":"code","e94ab6ec":"code","bb69559a":"code","1ccc358f":"code","08164aae":"code","6916a53a":"code","d61a837e":"code","6c9cdfe8":"code","16aedc15":"code","bfc1245d":"code","68e3bd5e":"code","e55aba3b":"code","97f38184":"code","8309614c":"code","72860356":"markdown","4e538117":"markdown","44b4028b":"markdown","63f57def":"markdown","c0bf84b8":"markdown","f72057d1":"markdown","8ba93b2d":"markdown","92ddf294":"markdown","eae97102":"markdown","29643d78":"markdown","f3b42198":"markdown","5f57cd66":"markdown","faaeb188":"markdown","67e033b8":"markdown","d7b4b174":"markdown","a521369b":"markdown"},"source":{"9755db05":"import pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno\n\nplt.style.use('dark_background')\n\nfrom pandas.plotting import scatter_matrix\n\nimport warnings\nwarnings.filterwarnings('ignore')","cadb7150":"train_df = pd.read_csv('..\/input\/tabular-playground-series-apr-2021\/train.csv')\ntrain_df.head()","33526deb":"train_df.describe()","2bbd69a9":"missingno.bar(train_df, color='orangered');","23eb62ab":"plt.pie(train_df.Sex.value_counts(), labels=['Male', 'Female'], colors=['orangered', 'lightsalmon'], autopct=\"%1.2f%%\")\nplt.title('Sex Distribution Graph', fontweight='bold', fontsize=18);","a3c2fd78":"def univariate_graph(title, xlabel, x, y, ylabel='Frequency'):\n    plt.bar(x, y, color='orangered')\n    plt.title(title, fontweight='bold', fontsize=14)\n    plt.xlabel(xlabel)\n    plt.ylabel(ylabel)\n    plt.show();","e94ab6ec":"univariate_graph(x=['Survived', 'Not Survived'],\n                y=train_df.Survived.value_counts(),\n                title='Survived Distribution',\n                xlabel='Survived')","bb69559a":"univariate_graph(x=['Lower', 'Upper', 'Middle'],\n                y=train_df.Pclass.value_counts(),\n                title='Pclass Distribution',\n                xlabel='Pclass')","1ccc358f":"plt.hist(train_df.Age, bins=10, color='orangered')\nplt.title('Age Distribution', fontweight='bold', fontsize=14)\nplt.xlabel('Age')\nplt.ylabel('Frequency');","08164aae":"univariate_graph(x=train_df.SibSp.value_counts().index,\n                y=train_df.SibSp.value_counts(),\n                title='Sibling\/Spouse Distribution',\n                xlabel='SibSp')","6916a53a":"univariate_graph(x=train_df.Parch.value_counts().index,\n                y=train_df.Parch.value_counts(),\n                title='Parch Distribution',\n                xlabel='Parch')","d61a837e":"univariate_graph(x=['Southampton', 'Cherbourg', 'Queenstown'],\n                y=train_df.Embarked.value_counts(),\n                title='Embarked Distribution',\n                xlabel='Embarked')","6c9cdfe8":"plt.hist(train_df.Fare, bins=5, color='orangered')\nplt.title('Fare Distribution', fontweight='bold', fontsize=14)\nplt.xlabel('Fare')\nplt.ylabel('Frequency');","16aedc15":"sample_col = [col for col in train_df.columns if pd.api.types.is_numeric_dtype(train_df[col])]\nplt.style.use('dark_background')\ndata = train_df.dropna()\nplt.boxplot(data[sample_col[1:]], patch_artist=True, labels=sample_col[1:])\nplt.title('Outlier Chart', fontsize=24, fontweight='bold');","bfc1245d":"fig, (ax1, ax2, ax3) = plt.subplots(1, 3, figsize=(15, 5))\nax1.boxplot(train_df['SibSp'], patch_artist=True, labels=['SibSp'])\nax1.set_title('SibSp Outlier Chart', fontsize=18, fontweight='bold')\nax2.boxplot(train_df['Parch'], patch_artist=True, labels=['Parch'])\nax2.set_title('Parch Outlier Chart', fontsize=18, fontweight='bold')\ndata = train_df.dropna()\nax3.boxplot(data['Age'], patch_artist=True, labels=['Age'])\nax3.set_title('Age Outlier Chart', fontsize=18, fontweight='bold');","68e3bd5e":"sns.heatmap(train_df.corr(), annot=True, cmap=\"YlOrBr\");","e55aba3b":"plt.bar(['female', 'male'], train_df['Sex'][train_df['Survived'] == 1].value_counts(), width=0.3, color='orangered')\nplt.bar(['female', 'male'], train_df['Sex'][train_df['Survived'] == 0].value_counts().sort_values(), bottom=train_df['Sex'][train_df['Survived'] == 1].value_counts(), width=0.3, color='lightsalmon')\nplt.legend(['Survived', 'NotSurvived'])\nplt.title('Sex Survived Relationship', fontsize=18, fontweight='bold')\nplt.show();","97f38184":"plt.bar(['Upper', 'Middle', 'Lower'], train_df['Pclass'][train_df['Survived'] == 1].value_counts().sort_values(), color='orangered')\nplt.bar(['Upper', 'Middle', 'Lower'], train_df['Pclass'][train_df['Survived'] == 0].value_counts(), color='lightsalmon', bottom=train_df['Pclass'][train_df['Survived'] == 1].value_counts().sort_values())\nplt.title('Pclass Survived Relationship', fontsize=18, fontweight='bold')\nplt.legend(['Survived', 'NotSurvived'])\nplt.show();","8309614c":"plt.bar([0, 1, 2, 3, 4, 8, 5], train_df['SibSp'][train_df['Survived'] == 1].value_counts(), color='orangered')\nplt.bar([0, 1, 2, 3, 4, 8, 5], train_df['SibSp'][train_df['Survived'] == 0].value_counts(), color='lightsalmon', bottom=train_df['SibSp'][train_df['Survived'] == 1].value_counts())\nplt.title('SibSp Survived Relationship', fontsize=18, fontweight='bold')\nplt.legend(['Survived', 'NotSurvived'])\nplt.show();","72860356":"So, we have outlier value in Fare. We have to see more deeply in SibSp and Parch column but seeing the dataset only we can say that it don't have any outlier.","4e538117":"# Variable Notes\npclass: A proxy for socio-economic status (SES)\n1st = Upper\n2nd = Middle\n3rd = Lower\n\nage: Age is fractional if less than 1. If the age is estimated, is it in the form of xx.5\n\nsibsp: The dataset defines family relations in this way...\nSibling = brother, sister, stepbrother, stepsister\nSpouse = husband, wife (mistresses and fianc\u00e9s were ignored)\n\nparch: The dataset defines family relations in this way...\nParent = mother, father\nChild = daughter, son, stepdaughter, stepson\nSome children travelled only with a nanny, therefore parch=0 for them.","44b4028b":"So, most of the passengers on the Titanic are came alone. Some of them are come in couple or sibling while some of them come with their family.","63f57def":"# Data Dictionary\n| Variable | Definition | Key |\n| -------- | ---------- | --- |\n| survival | Survival  |0 = No, 1 = Yes |\n| pclass | Ticket class | 1 = 1st, 2 = 2nd, 3 = 3rd |\n| sex | Sex | |\n| Age | Age in years | |\n| sibsp | # of siblings \/ spouses aboard the Titanic | |\n| parch | # of parents \/ children aboard the Titanic | |\n| ticket | Ticket number | |\n| fare | Passenger fare | |\n| cabin | Cabin number | |\n| embarked | Port of Embarkation | C = Cherbourg, Q = Queenstown, S = Southampton |","c0bf84b8":"# Tabular Playground Series - Apr 2021\nIn this notebook, we perform and analyse the `Titanic Dataset` generated using the CTGAN. We need to create the machine learning model that predict the `Survived` field using the 11 different variables. Evaluation is depend upon the `accuracy` of the model. ","f72057d1":"Yeah!! We found the outlier in the `SibSp`, `Parch` and `Age` when we check these column more closely.","8ba93b2d":"# Exploratory Data Analysis\nIn this section, we perform the Exploratory Data Analysis or EDA to understand the dataset and find the useful patterns within the dataset between the different variables.","92ddf294":"So most of the passenger are going to the `Southampton`.","eae97102":"## Bivariate","29643d78":"# Perform statistics opertaion\nIn this section, we perform the basic statistics operation like mean, standardization, min, max, etc.","f3b42198":"So most of the passengers are from the age 20 to 40 years. But again, passenger with the age below the 0 or 5 is not possible that they are travelling on the ship. We need to handle such case before fitting the model.","5f57cd66":"## Univariate","faaeb188":"One of the weird observation in the dataset is in the Age column, as it had a minimum age of 0.080 which is really not possible. We need to handle this errorness in the dataset and replace it with something else.","67e033b8":"Since, we have lots of missing value in `Cabin` column so filling out with some random value doesnot make a good call. So we going to drop out the column from the dataset and fill the rest of the missing column with the help of the EDA.","d7b4b174":"If you got value from this, and\/or if you think this can be improved, please let me know in the comments. Thanks again for reading. \ud83d\ude4f\n\nFollow me on LinkedIn [@abhishek-vaish](https:\/\/www.linkedin.com\/in\/abhishek-vaish) and Twitter [@abhishekvaish](https:\/\/twitter.com\/abhishek_vaish_)","a521369b":"# Load the Dataset \nIn this section, we import all the useful libraries and load the dataset into the notebook."}}