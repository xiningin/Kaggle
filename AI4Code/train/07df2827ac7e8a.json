{"cell_type":{"cfda0f13":"code","661affbb":"code","ee6a9822":"code","5e46871c":"code","fdf11cf4":"code","885b396b":"code","a7b21d57":"code","4234c413":"code","153db60a":"code","c065ee2b":"code","59761b0f":"code","2b747db9":"code","f1e3579a":"code","f64b13cf":"code","73e16fc6":"code","cc5250ca":"code","27026363":"code","53b185d8":"code","bb12a94f":"code","ebffee07":"code","8f74a574":"code","7e8315bf":"code","768ee119":"code","d88d15fe":"code","0b38a3da":"code","d146d7fd":"code","94c59840":"code","dfae7af2":"markdown","113cd3ad":"markdown","a1c8fd63":"markdown","66730cc9":"markdown","57d2be98":"markdown","c8497c67":"markdown","ea850735":"markdown","7fbed252":"markdown","daa882d1":"markdown","6bde4efb":"markdown","946bce1a":"markdown","f209ca11":"markdown","33835772":"markdown","a48ba196":"markdown","c29dbcfc":"markdown","b249dfe9":"markdown","5bdaa308":"markdown","bfd88a59":"markdown","04942036":"markdown","0129f2dd":"markdown","9300c045":"markdown","174febe2":"markdown","82f24e18":"markdown","46329b6b":"markdown","d9df2922":"markdown","9c062545":"markdown","bc6139b9":"markdown","92291470":"markdown","13148783":"markdown","b16bce19":"markdown","7c9901fb":"markdown","40ee8974":"markdown","809cb952":"markdown","6b1422fe":"markdown","efe66fe3":"markdown","83f0d6a8":"markdown","e1a15c8a":"markdown","332701b3":"markdown"},"source":{"cfda0f13":"import pandas as pd\nimport matplotlib.pyplot as plt\n\n\ndf = pd.read_csv(\"..\/input\/heart-failure-prediction\/heart.csv\")\ndf\n","661affbb":"df.info()","ee6a9822":"df.duplicated().value_counts()","5e46871c":"print(df[\"HeartDisease\"].value_counts())\nlabels = 'Herzkrank', 'nicht Herzkrank'\nsizes = df[\"HeartDisease\"].value_counts()\nexplode = (0, 0.1) \n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, explode=explode, labels=labels, autopct='%1.f%%',\n        shadow=True, startangle=90)\nax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n\nplt.show()\n","fdf11cf4":"numerisch = df.drop(['HeartDisease'], axis=1).select_dtypes('number').columns\n\nkategorisch = df.select_dtypes('object').columns\n\nprint(f'Numerische Felder:  {df[numerisch].columns}')\nprint('\\n')\nprint(f'Kategorische Felder: {df[kategorisch].columns}')","885b396b":"for column in df[numerisch]:\n    plt.figure()\n    df.boxplot([column])","a7b21d57":"for column in kategorisch:\n  \n    plt.hist(df[column])\n    plt.xlabel(column)\n    plt.ylabel(\"H\u00e4ufigkeit\")\n    plt.show()","4234c413":"df.boxplot([\"RestingBP\"])\nRPB =  df[df['RestingBP'] == 0]\nprint(RPB)\n","153db60a":"plt.figure()\ndf = df.drop(df[df.RestingBP== 0].index)\ndf.boxplot([\"RestingBP\"])","c065ee2b":"Chol =  df[df['Cholesterol'] == 0]\nChol = Chol[\"HeartDisease\"]\nHeart = df[df['HeartDisease'] == 1]\nHeart = Heart[\"Cholesterol\"]\nplt.hist(Chol,align='left',bins=range(3))\nplt.xticks(range(2))\nplt.xlabel(\"HeartDisease bei Chol==0\")\nplt.ylabel(\"H\u00e4ufigkeit\")\nplt.show()\n\nplt.hist(df[\"HeartDisease\"],align='left',bins=range(3))\nplt.xticks(range(2))\nplt.xlabel(\"HeartDisease allgemein\")\nplt.ylabel(\"H\u00e4ufigkeit\")\nplt.show()\n\nplt.hist(df[\"Cholesterol\"],align='left',)\nplt.xlabel(\"Cholesterol bei allen\")\nplt.ylabel(\"H\u00e4ufigkeit\")\nplt.show()\n\nplt.hist(Heart,align='left',)\nplt.xlabel(\"Cholesterol bei Heart==1\")\nplt.ylabel(\"H\u00e4ufigkeit\")\nplt.show()","59761b0f":"df = pd.get_dummies(df, drop_first=True)","2b747db9":"df.head()","f1e3579a":"X = df.drop([\"HeartDisease\"], axis=1)\ny = df[\"HeartDisease\"]","f64b13cf":"from sklearn.tree import DecisionTreeClassifier # Import Decision Tree Classifier\nfrom sklearn.model_selection import train_test_split # Import train_test_split function\nfrom sklearn.ensemble import RandomForestClassifier\nacc = 0\nfor x in range(100):\n  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n  # Create Decision Tree classifer object\n  model = DecisionTreeClassifier()\n\n  # Train Decision Tree Classifer\n  model = model.fit(x_train,y_train)\n\n  #Predict the response for test dataset\n  y_pred = model.predict(x_test)\n  #Evaluation using Accuracy score\n  from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n  acc += metrics.accuracy_score(y_test, y_pred)*100\n","73e16fc6":"acc = acc\/100\nprint(\"Bei 100 Versuchen liegt die durchschnittliche Richtigkeit bei: \",acc)","cc5250ca":"from sklearn.metrics import classification_report\nprint(classification_report(y_test,y_pred))","27026363":"\n!pip install pydotplus\nfrom sklearn.tree import export_graphviz\nfrom six import StringIO \nfrom IPython.display import Image  \nimport pydotplus","53b185d8":"features=X.columns\ndot_data = StringIO()\nexport_graphviz(model, out_file=dot_data,filled=True, rounded=True,special_characters=True,feature_names = features,class_names=['0','1'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('heart_set.png')\nImage(graph.create_png())","bb12a94f":"acc = 0\nfor x in range(10):\n  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n  # Create Decision Tree classifer object\n  model = DecisionTreeClassifier(criterion=\"entropy\", max_depth=3)\n\n  # Train Decision Tree Classifer\n  model = model.fit(x_train,y_train)\n\n  #Predict the response for test dataset\n  y_pred = model.predict(x_test)\n  #Evaluation using Accuracy score\n  from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n  acc += metrics.accuracy_score(y_test, y_pred)*100\n  print(metrics.accuracy_score(y_test, y_pred)*100)\n  \n\nprint(\"Durchschnitts Accuracy:\",acc\/10)","ebffee07":"#Better Decision Tree Visualisation\nfrom six import StringIO  \nfrom IPython.display import Image  \nfrom sklearn.tree import export_graphviz\nimport pydotplus\ndot_data = StringIO()\nexport_graphviz(model, out_file=dot_data,filled=True, rounded=True,special_characters=True, feature_names = features,class_names=['0','1'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('heart_set.png')\nImage(graph.create_png())","8f74a574":"for depth in range(1,12):\n  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=1)\n   \n  modelent = RandomForestClassifier(criterion=\"entropy\", max_depth=depth)\n  modelgini = RandomForestClassifier(criterion=\"gini\", max_depth=depth)\n \n  modelent = modelent.fit(x_train,y_train)\n  modelgini = modelgini.fit(x_train,y_train)\n\n  y_pred_ent = modelent.predict(x_test)\n  y_pred_gini = modelgini.predict(x_test)\n  \n  from sklearn import metrics #Import scikit-learn metrics module for accuracy calculation\n\n  \n  print(\"depth \",depth , \":\")\n  print(\"Entropy\\t\\t\\tGini\")\n  print(\"Accuracy: {:0.2f}\".format(metrics.accuracy_score(y_test, y_pred_ent)*100), \"\\tAccuracy: {:0.2f}\".format(metrics.accuracy_score(y_test, y_pred_gini)*100))\n  print(\"F1: {:0.2f}\".format(metrics.f1_score(y_test, y_pred_ent)*100),\"\\t\\tF1: {:0.2f}\".format(metrics.f1_score(y_test, y_pred_ent)*100))\n  print(\"Recall: {:0.2f}\".format(metrics.recall_score(y_test, y_pred_ent)*100), \"\\t\\tRecall: {:0.2f}\".format(metrics.recall_score(y_test, y_pred_gini)*100))\n  print(\"Precision: {:0.2f}\".format(metrics.precision_score(y_test, y_pred_ent)*100), \"\\tPrecision: {:0.2f}\".format(metrics.precision_score(y_test, y_pred_gini)*100))\n  print(\"\")\n  ","7e8315bf":"dfangepasst = df\ndef getestet(row):\n  if row['Cholesterol'] == 0 :\n    return 0\n\n  return 1\ndef istzero(row):\n  if row['Cholesterol']== 0:\n    return None \n  return row['Cholesterol']\ndfangepasst['Cholgetestet']=dfangepasst.apply(lambda row: getestet(row), axis=1)\n\ndfangepasst['Cholesterol'] = dfangepasst.apply(lambda row: istzero(row), axis=1)\ndfangepasst=dfangepasst.fillna(df.mean())\n","768ee119":"X = dfangepasst.drop([\"HeartDisease\"], axis=1)\ny = dfangepasst[\"HeartDisease\"]\nx_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n\nmodel = DecisionTreeClassifier(max_depth=3, criterion=\"entropy\")\n\n\nmodel = model.fit(x_train,y_train)\n\n\ny_pred = model.predict(x_test)\n\nacc = metrics.accuracy_score(y_test, y_pred)*100\nprint(\"Accuracy = \",acc)","d88d15fe":"features=X.columns\ndot_data = StringIO()\nexport_graphviz(model, out_file=dot_data,filled=True, rounded=True,special_characters=True, feature_names = features,class_names=['0','1'])\ngraph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \ngraph.write_png('heartAngepasst_set.png')\nImage(graph.create_png())","0b38a3da":"x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.20,random_state=1)\n\nmodel = RandomForestClassifier(criterion=\"entropy\", max_depth=7)\n\n\nmodel = model.fit(x_train,y_train)\n\n\ny_pred = model.predict(x_test)\nprint(classification_report(y_test,y_pred))\n","d146d7fd":"import seaborn as sns\nfrom sklearn.metrics import confusion_matrix\ncf_matrix = confusion_matrix(y_test, y_pred)\nax = sns.heatmap(cf_matrix, annot=True, cmap='Blues')\n\nax.set_title('Confusion Matrix RandomForest');\nax.set_xlabel('\\nvorhergesagte Werte')\nax.set_ylabel('echte Werte ');\n\n\nax.xaxis.set_ticklabels(['False','True'])\nax.yaxis.set_ticklabels(['False','True'])\n\n\nplt.show()","94c59840":"from sklearn.naive_bayes import GaussianNB\n\nacc = 0\nfor x in range(100):\n  x_train, x_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n  modell = GaussianNB()\n  modell.fit(x_train,y_train) # Berechnung mit Hilfe der Trainingsdaten\n  y_vorhersage = modell.predict(x_test) # mit Testdaten testen\n  acc+= metrics.accuracy_score(y_test, y_vorhersage)*100\nprint(\"Naive Bayes accuracy =\",acc\/100)","dfae7af2":"Aufteilen des Datensatzes in numerische und kategorsische Felder:","113cd3ad":"Wir prunen den Baum, indem wir Tiefe des Baumes testweise auf 3 begrenzen.","a1c8fd63":"Keine leeren oder doppelten Felder, Datensatz sieht vollst\u00e4ndig aus.","66730cc9":"Ausrei\u00dfer finden:","57d2be98":"# 1. Datensatz\n**1.1 Kontext**\n\nHerz-Kreislauf-Erkrankungen sind die f\u00fchrende Todesursache in Deutschland und verursachen insgesamt etwa 40 Prozent aller Sterbef\u00e4lle. Dar\u00fcber hinaus sind sie mit erheblichen individuellen Krankheitsfolgen verbunden und verursachen hohe gesellschaftliche Krankheitskosten. Menschen mit Herz-Kreislauf-Erkrankungen oder mit einem hohen kardiovaskul\u00e4ren Risiko (aufgrund von einem oder mehrerer Risikofaktoren wie Bluthochdruck, Diabetes, Hyperlipid\u00e4mie oder einer bereits bestehenden Erkrankung) ben\u00f6tigen eine fr\u00fchzeitige Erkennung und Behandlung, wobei ein Modell des maschinellen Lernens eine gro\u00dfe Hilfe sein kann.","c8497c67":"Auswertung des Decision-Trees:","ea850735":"Man sieht, dass der Ast bei Cholesterol ca. 50 eine Entscheidung f\u00e4llt. Das liegt daran, dass sehr viele Cholesterol Werte wegen Unvollst\u00e4ndigkeit bei 0 liegen. Das ist eine Verf\u00e4lschung der echten Werte. Darum setzen wir die unvollst\u00e4ndigen Werte auf den Durchschnitt der anderen Werte und f\u00fchren das neue Feature \u201eCholgetestet\u201c ein, welches aussagt, ob die Cholesterol Werte vorhanden sind oder nicht.","7fbed252":"**2.2 \u00dcberpr\u00fcfung der Verteilung der Zielvariable**","daa882d1":"Unsere Evaluations Metriken liegen gr\u00f6\u00dftenteils unter 0,8. Die Gesamtleistung des trainierten Modells ist damit nicht \u00fcberzeugend und bedarf Anpassungen","6bde4efb":"Durch Pruning konnten wir unsere Durschnittsrichtigkeit der Vorhersage um etwa 5% verbessern.","946bce1a":"Die Verteilung der Zielvariable ist sehr ausgeglichen. Das bietet eine gute Grundlage f\u00fcr eine Klassifizierungsanalyse.","f209ca11":"Da die Accuracy von unserem Decicion Tree je nach random State stark variiert (nicht sehr robust), nutzen wir den Random Forest Classifier.\n\nHierbei testen wir auch welche Tiefe und welche Kennzahl die besten Ergebnisse liefert:\n","33835772":"# **3 Datamining**","a48ba196":"# 2. Datenanalyse","c29dbcfc":"**Finale Modellierung und Auswertung des RandomForests**","b249dfe9":"**1.3 Fragestellung und Zielvariable**\n\nIn der vorliegenden Studie haben wir ein bin\u00e4res Klassifizierungsproblem. Unsere Zielvariable ist HeartDisease. Unser Ziel ist es festzustellen, ob jemand auf der Grundlage der Eingabeparameter wie Geschlecht, Alter und verschiedener Testergebnisse wahrscheinlich an einer Herzkrankheit erkranken wird oder nicht. Wir werden eine Reihe von Klassifizierungsmodellen erstellen und die Modelle vergleichen, um die beste Vorhersage zu Herzkrankheiten zu liefern\n","5bdaa308":"**2.3 Datenaufbereitung**","bfd88a59":"In diesem Projekt haben wir versucht, ein bin\u00e4res Klassifizierungsproblem im Datensatz \u00fcber Herzkrankheiten mithilfe von Datenanalysemodellen zu l\u00f6sen. Wir wollten feststellen, ob jemand auf der Grundlage von Eingabeparametern wie Geschlecht, Alter und verschiedenen Testergebnissen wahrscheinlich an einer Herzkrankheit erkrankt ist oder nicht.\nWir haben sowohl das Ziel als auch die Features im Detail analysiert. Wir haben kategoriale Variablen in Dummies umgewandelt, damit wir sie in den Modellen verwenden k\u00f6nnen. Wir haben den Datensatz auf Vollst\u00e4ndigkeit, doppelte Werte, Ausrei\u00dfer und Abh\u00e4ngigkeiten \u00fcberpr\u00fcft. Wir haben das Problem der fehlenden Cholesterinwerte behandelt, um es n\u00e4her an die Wirklichkeit heranzuf\u00fchren. \nWir starteten mit einer Initialanalyse unter 80% Richtigkeit und durch Anpassungen der Parameter und des Modells konnten wir die Ergebnisse konsistent auf 91% steigern. Verglichen mit anderen Methoden, wie z. B. Naive-Bayes, welche im allgemeinen gute Werte liefert, schneidet unser Random-Forest besser ab. Neben der hohen Richtigkeit zeichnet sich unser Modell auch durch eine hervorragende Klassifikationsleistung, bestimmt durch die Konfusionsmatrix, aus. Die Klassifizierungsgenauigkeit allein kann irref\u00fchrend sein. Die Berechnung einer Konfusionsmatrix kann eine bessere Vorstellung davon vermitteln, was das Klassifizierungsmodell richtig macht und welche Arten von Fehlern es begeht.\nInsgesamt haben wir viel mit dem Datensatz und den Datamining Methoden experimentiert, konnten schlie\u00dflich unser Wissen konsolidieren und damit einen Mehrwert f\u00fcr diese Studie schaffen.\n\n \n\n ","04942036":"# 4. Fazit","0129f2dd":"# **Data Mining Projekt Herzkrankheit**","9300c045":"**1.2 Features**\n\nDieser Datensatz enth\u00e4lt 11 Merkmale, die zur Klassifikation einer m\u00f6glichen Herzerkrankung verwendet werden k\u00f6nnen:","174febe2":"Kategorische Spalten in numerische Umwandeln:","82f24e18":"Nun wird nicht nur \u00fcberpr\u00fcft, ob ein Cholesterol Test vorliegt, sondern auch der Wert selbst flie\u00dft in den Entscheidungsbaum ein.","46329b6b":"**Age**: Alter des Patienten [Jahre]\n\n**Sex**: Geschlecht [M: M\u00e4nnlich, F: Weiblich]\n\n**ChestPainType**: Brustschmerz Typen [TA: typische Angina, ATA: untypische Angina, NAP: nicht Angina Schmerzen, ASY: asymptomisch]\n\n**RestingBP**: Blutdruck in Ruhe [mm Hg]\n\n**Cholesterol**: Serumcholesterinspiegel [mm\/dl]\n\n**FastingBS**: Blutzucker n\u00fcchtern [1: FastingBS > 120 mg\/dl, 0: FastingBS <= 120 mg\/dl]\n\n**RestingECG**: ruhende EKG Ergebnisse [Normal: Normal, ST: hat ST-T Wellen Anomalie, LVH: hat LVH]\n\n**MaxHR**: maximaler erreichter Puls [zwischen 60 und 202]\n\n**ExerciseAngina**: Angina [Y: ja, N: nein]\n\n**Oldpeak**: ST-Depression durch k\u00f6rperliche Bet\u00e4tigung im Verh\u00e4ltnis zur Ruhe = ST [Numerischer Wert, gemessen in Depression]\n\n**ST_Slope**: Steigung des ST-Segments der Spitzen\u00fcbung [Up: ST-Hebungen, Flat: gleichbleibend, Down: ST-Senkungen]\n\n**HeartDisease**: Diagnose [1: Herzkrankheit, 0: Normal]\n","d9df2922":"RestingBP ist in einem Fall gleich 0. Das ist biologisch bei einer lebenden Person nicht m\u00f6glich. Man erkennt, dass mehrere Features nicht korrekt sind bzw. fehlen. Daher entfernen wir die Zeile.","9c062545":"**2.1 Datensatz einlesen**","bc6139b9":"Die besten Ergebnisse liefert max_depth = 7. Der Unterschied von Gini zu Entropy macht auf den h\u00f6heren Tiefen kaum einen Unterschied. ","92291470":"Die Darstellung des Decision Trees zeigt eindeutig, dass das Entscheidungsmodell nicht ausbalanciert ist (Overfitting). \nDurch Pruning kann dem entgegengewirkt werden. ","13148783":"Vergleicht man den Naive Bayes, der in der Regel sehr gute Ergebnisse liefert, mit unserem RandomForest-Modell, so f\u00e4llt auf dass die Voraussagen bei uns ca. 5% besser sind. Der Naive Bayes funktioniert am besten, wenn die Features unabh\u00e4ngig voneinander sind. Daraus schlie\u00dfen wir, dass in unserem Datensatz Abh\u00e4ngigkeiten bestehen.","b16bce19":"Initial Decision Tree (ohne Parameter):","7c9901fb":"Bei unserer Diagnose ist es am wichtigsten, dass Menschen mit einer Herzkrankheit richtig diagnostiziert werden (Recall Wert). In unserem Modell werden am h\u00e4ufigsten Menschen, die wirklich eine Herzkrankheit haben auch entsprechend diagnostiziert (True Positive) und gleichzeitig ist die Anzahl der Patienten, die eine Herzkrankheit haben und keine Diagnose erhalten, sehr gering (False Negative). Hierbei d\u00fcrfen die anderen Werte nicht vernachl\u00e4ssigt werden. Denn w\u00fcrde man alle als krank diagnostizieren, w\u00fcrde unsere gerade beschriebene Anforderung auch perfekt erf\u00fcllt werden. In unserem Modell ist der F1 Wert, der genau dieses Problem quantifiziert, nahe bei 1. Der F1-Score kann als gewichteter Durchschnitt der Precision- und Recall-Werte interpretiert werden, wobei ein F1-Score seinen besten Wert bei 1 und seinen schlechtesten Wert bei 0 erreicht. D.h. in diesem Fall, dass auch die negativ diagnostizierten Patienten richtig eingesch\u00e4tzt werden.","40ee8974":"Wir sehen, dass der Gro\u00dfteil der Menschen mit Cholesterol gleich 0 eine Herzkrankheit hat. Aufgrund des gro\u00dfen Einflusses belassen wir es im Datenset.","809cb952":"**Auswertung und Verbesserung der Ergebnisse**","6b1422fe":"Aufteilen der Daten in Input (X) und Output (y):","efe66fe3":"Auf fehlende oder doppelte Eingaben pr\u00fcfen:","83f0d6a8":"**Naive Bayes**","e1a15c8a":"**Projektinhalt**\n\nUntersuchung, Bereinigung und Filterung der Datens\u00e4tze. \n\nUntersuchung mittels Data Mining Werkzeugen (supervised Learning).\n\n**Projektabgabe**\n\nSchriftliche Ausfertigung, ca. 6 - 10 Seiten, Pythonprogramme (per Stick oder per Email)\nSchriftliche Abnahme am 12.01.2022 ab 8:15 Uhr in K007\n\n**Projektzeitraum**\n\n01.12.2021-12.01.2022\n\n**Projektgruppe**\n\nAwan, Saad; Root, Alexander; Schmidt, Alexander","332701b3":"Daten bereinigen:"}}