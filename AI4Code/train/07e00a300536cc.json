{"cell_type":{"7a3563bf":"code","f6114635":"code","63bbfea4":"code","5a15540f":"code","1b8a169e":"code","c13b596b":"code","e3d7ec0e":"code","7a18a307":"code","bbbefe24":"code","2864bb86":"code","8cca1413":"code","38a8a32a":"code","088ad718":"code","9d044c13":"code","2b41fcfd":"code","8061ed11":"code","6a0bd760":"code","659bfeb0":"code","93bd18d5":"markdown","9b7b137c":"markdown","82bd0177":"markdown","dccd9f77":"markdown","1dfcb1cd":"markdown","afc3c0b0":"markdown","f7e4c750":"markdown","03a816c4":"markdown","56e77bcb":"markdown","d2ef1b66":"markdown","a2cd82ab":"markdown","d636094b":"markdown","7bfc08f5":"markdown","2f22f54c":"markdown","42a37eeb":"markdown","3eb87381":"markdown","d3d62322":"markdown","5b56d02b":"markdown","683fba27":"markdown","3f65480b":"markdown","70e0e2a2":"markdown","4114e2a3":"markdown","d12846b7":"markdown","8667a3d4":"markdown","0fbd6a56":"markdown","13907837":"markdown","26185f23":"markdown"},"source":{"7a3563bf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\n\"\"\"\nData Manipulating\n\"\"\"\nimport numpy as np \nimport pandas as pd \n\n\n\"\"\"\nVisualization\n\"\"\"\nimport plotly as py\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.express as px\n\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f6114635":"data = pd.read_csv('\/kaggle\/input\/mushroom-classification\/mushrooms.csv')","63bbfea4":"data.head()","5a15540f":"data.info()","1b8a169e":"data.isnull().sum()","c13b596b":"def converter(df,features):\n    \"\"\"\n    A function that converts features into category\n    \"\"\"\n    for ftr in features:\n        df[ftr] = df[ftr].astype(\"category\")\n    \n    return df","e3d7ec0e":"data = converter(data,data)","7a18a307":"data.head()","bbbefe24":"data.info()","2864bb86":"x = data.drop(\"class\",axis=1)\ny = data[\"class\"]","8cca1413":"def get_dummies(df,features):\n    \n    for ftr in features:\n        \n        df = pd.get_dummies(df,ftr)\n    \n    return df","38a8a32a":"x = get_dummies(x,x)","088ad718":"from sklearn.model_selection import train_test_split\nx_train,x_test,y_train,y_test = train_test_split(x,y,test_size=0.25,random_state=1)","9d044c13":"print(\"Len of x_train is \",len(x_train))\nprint(\"Len of x_test is \",len(x_test))\nprint(\"Len of y_train is \",len(y_train))\nprint(\"Len of y_test is \",len(y_test))","2b41fcfd":"from sklearn.svm import SVC\n\nsvc = SVC(random_state=12)\nsvc.fit(x_train,y_train)\n\nprint(svc.score(x_test,y_test))","8061ed11":"from sklearn.tree import DecisionTreeClassifier\nDTC = DecisionTreeClassifier(random_state=12)\nDTC.fit(x_train,y_train)\n\nprint(DTC.score(x_test,y_test))","6a0bd760":"from sklearn.naive_bayes import GaussianNB\n\nNBC = GaussianNB()\nNBC.fit(x_train,y_train)\nprint(NBC.score(x_test,y_test))","659bfeb0":"from sklearn.ensemble import RandomForestClassifier\n\nRFC = RandomForestClassifier(n_estimators=50,random_state=12)\nRFC.fit(x_train,y_train)\n\nprint(RFC.score(x_test,y_test))","93bd18d5":"# Importing Libraries and The Data\n\nIn this section I am going to import libraries and the data that I will use. In the introduction section I've said which libraries that I will use, but in this section I am going to repeat them.\n\n* For machine learning: SKLearn\n* For visualization: Plotly, missingno\n* For data manipulating : Pandas and Numpy","9b7b137c":"And now I am going to take a look at the data.","82bd0177":"* There are 8124 rows in the dataset.\n* All of the dataset is object (However we will convert them into category)","dccd9f77":"* Our preprocessing is over.","1dfcb1cd":"* There are 23 columns in data. \n* All of the columns are category.","afc3c0b0":"### Decision Tree Classification","f7e4c750":"# Data Overview\n\nIn this section I am going to take an idea about data. In order to do this I am going to use head(),info(),isnull() methods.","03a816c4":"* There is no missing values in the dataset.","56e77bcb":"## Train Test Split\n\nIn this sub-section I am going to split dataframe into two pieces. Train and test. In order to do this I am going to use sklearn library.","d2ef1b66":"And let's look at the lengths of arrays.","a2cd82ab":"### Support Vector Machines Classification","d636094b":"# Result | Best Algorithm for Mushroom Classification\n\nLet's take a look at our scores.\n\nSupport Vector Machines Classifier = %100\nDecision Tree Classifier = %100\nNaive Bayes Classifier = %96\nRandom Forest Classifier = %100\n\nOur scores are great! \n\nAnd at the end of this section we can say: For mushroom classification we can use SVC,DTC or RFC","7bfc08f5":"# Data Preprocessing\n\nIn this section I am going to convert features into category. In order to do this I am going to define a function that helps us.","2f22f54c":"* Naive Bayes score is lower than Decision Tree and Support Vector Machines","42a37eeb":"Our function is so simple. Let's use it.","3eb87381":"I am going to import sklearn modules when I need them so I did not import them","d3d62322":"In appearance there is no change, let's use info method.","5b56d02b":"* Our feature engineering section is over","683fba27":"## Classification Algorithms\n\nIn this section I am going to train classification models however at least for this kernel I am not going to use Grid Search because I think it is so much for this kernel.\n\nIn this section I am going to train these algorithms:\n* Support Vector Machine Classification\n* Decision Tree Classification\n* Naive Bayes Classification\n* Random Forest Classification","3f65480b":"### Random Forest Classification","70e0e2a2":"But before this I am going to split dataframe x and y axis because I do not want to apply get dummies to y axis.","4114e2a3":"### Naive Bayes Classification","d12846b7":"* Our function is ready, let's use it.","8667a3d4":"# Modeling\n\nFinally our main stage has come. In this section I am going to train machine learning models. I am going to start this section with train test split. ","0fbd6a56":"# Introduction\n\nHello people, welcome to my kernel! In this kernel I am going to classify Mushrooms edible or poisonous. In this kernel I am going to use SKLearn for machine learning, Plotly for visualization and Numpy,Pandas for manipulating.\n\nBefore the start, let's take a look at our schedule\n\n# Schedule\n1. Importing Libraries and Data\n1. Data Overview\n1. Data Preprocessing\n1. Feature Engineering\n    * Applying ***get_dummies*** Function For Each Function\n1. Modeling\n    1. Classification Algorithms\n        * Support Vector Machine Classification\n        * Decision Tree Classification\n        * Naive Bayes Classification\n        * Random Forest Classification\n1. Result | Best Algorithm for Mushroom Classification\n1. Conclusion","13907837":"# Feature Engineering\n\nIn this section I am going to apply pandas' get dummies function. As you guess, in order to do this I am going to define a function. Let's do this.","26185f23":"# Conclusion \n\nThanks for your attention. If you like this kernel, I would be glad. "}}