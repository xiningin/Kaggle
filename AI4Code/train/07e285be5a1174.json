{"cell_type":{"ce8d75fc":"code","ad8feab6":"code","4698ad06":"code","42d67510":"code","07640cdf":"code","524cf099":"code","ad3d5d03":"code","286e4b18":"code","e4d75380":"code","27cd2cde":"code","28b4dd1b":"code","01132d58":"code","a6c513d9":"code","5142e2d2":"code","59f0a870":"code","2b7e49a2":"code","76d70f4a":"code","40f82a8a":"code","6228af7c":"code","e63819ca":"code","9859c291":"code","e590c2c0":"code","d4d027e3":"code","e38c0256":"code","1997dc40":"code","36d8ba85":"code","6f8da80c":"code","a1903629":"code","8906e96f":"code","af61ebf7":"code","3004ff74":"code","ddca0455":"code","75af91c9":"code","ee279586":"markdown","3aeb3501":"markdown","7553c1ff":"markdown","4f3b8615":"markdown","f5b24fa2":"markdown","faf74dd6":"markdown","c6aa6518":"markdown","1c97e125":"markdown","5d74ee9d":"markdown","21d9b85e":"markdown","5f3e3b9c":"markdown","7f06b1d6":"markdown","a36057b3":"markdown","03f9b5e8":"markdown","4a82ef51":"markdown","9ef6e0bc":"markdown"},"source":{"ce8d75fc":"#install Apache Spark\n!pip install pyspark --quiet","ad8feab6":"#Generic Libraries\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# -------- PySpark Libraries --------\n\n#Apache Spark Libraries\nimport pyspark\nfrom pyspark.sql import SparkSession\n\n#Apache Spark ML CLassifier Libraries\nfrom pyspark.ml.classification import DecisionTreeClassifier,RandomForestClassifier,NaiveBayes\n\n#Apache Spark Evaluation Library\nfrom pyspark.ml.evaluation import MulticlassClassificationEvaluator\n\n#Apache Spark Features libraries\nfrom pyspark.ml.feature import StandardScaler,StringIndexer\n\n#Apache Spark Pipelin Library\nfrom pyspark.ml import Pipeline\n\n# Apache Spark `DenseVector`\nfrom pyspark.ml.linalg import DenseVector\n\n\n# -------- SciKit Libraries --------\n\n#Data Split Libraries\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.metrics import accuracy_score\n\n#ML Classifier Algorithm Libraries\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.naive_bayes import GaussianNB, MultinomialNB\nfrom sklearn.ensemble import RandomForestClassifier\n\n#Tabulating Data\nfrom tabulate import tabulate\n\n#Garbage\nimport gc","4698ad06":"#Building Spark Session\nspark = (SparkSession.builder\n                  .appName('Apache Spark Beginner Tutorial')\n                  .config(\"spark.executor.memory\", \"1G\")\n                  .config(\"spark.executor.cores\",\"4\")\n                  .getOrCreate())","42d67510":"spark.sparkContext.setLogLevel('INFO')","07640cdf":"spark.version","524cf099":"url = '..\/input\/iris-dataset\/iris.csv'\n\n# PySpark DataFrame\ndata_sprk = spark.read.format(\"csv\").option(\"header\", \"true\").option(\"inferSchema\",\"true\").load(url) \ndata_sprk.cache() #for faster re-use\n\n# SciKit DataFrame\ndata_sk = pd.read_csv(url, header=\"infer\")","ad3d5d03":"#Total records \nprint(\"PySpark - \" , data_sprk.count())\nprint(\"SciKit - \", data_sk.shape)","286e4b18":"#Data Type\n\n#PySpark\nprint(data_sprk.printSchema())\n#SciKit\nprint(data_sk.info())\n","e4d75380":"#Display records\n\n#PySpark\nprint(data_sprk.show(5))\n#SciKit\nprint(data_sk.head())","27cd2cde":"#Records per Species\n\n#PySpark\nprint(data_sprk.groupBy('species').count().show())\n\n#SciKit\nprint(data_sk.groupby('species').size())","28b4dd1b":"#Dataset Summary Stats\n\n#PySpark\nprint(data_sprk.describe().show())\n\n#SciKit\nprint(data_sk.describe().transpose())","01132d58":"# -- PySpark --\nSIndexer = StringIndexer(inputCol='species', outputCol='species_indx')\ndata_sprk = SIndexer.fit(data_sprk).transform(data_sprk)\n\n# -- SciKit --\nlabel_encode = LabelEncoder()\ndata_sk['species'] = label_encode.fit_transform(data_sk['species'])\n\n#Inspect the dataset\nprint(data_sprk.show(5))\nprint(data_sk.head())\n","a6c513d9":"#creating a seperate dataframe with re-ordered columns\ndf_sprk = data_sprk.select(\"species_indx\",\"sepal_length\", \"sepal_width\", \"petal_length\", \"petal_width\")\n\n#Inspect the dataframe\ndf_sprk.show(5)","5142e2d2":"# Define the `input_data` as Dense Vector\ninput_data = df_sprk.rdd.map(lambda x: (x[0], DenseVector(x[1:])))","59f0a870":"# Creating a new Indexed Dataframe\ndf_sprk_indx = spark.createDataFrame(input_data, [\"label\", \"features\"])","2b7e49a2":"#view the indexed dataframe\ndf_sprk_indx.show(5)","76d70f4a":"#Feature & Target Selection - SciKit\nfeatures = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']\ntarget = ['species']\n\nX = data_sk[features]\ny = data_sk[target]","40f82a8a":"# --- PySpark ---\nstdScaler = pyspark.ml.feature.StandardScaler(inputCol=\"features\", outputCol=\"features_scaled\")\nscaler = stdScaler.fit(df_sprk_indx)\ndf_sprk_scaled =scaler.transform(df_sprk_indx)","6228af7c":"# --- SciKit ---\nsc = StandardScaler()\ndf_sk_scaled = sc.fit_transform(X)\ndf_sk_scaled = pd.DataFrame(df_sk_scaled, columns= ['sepal_length', 'sepal_width', 'petal_length', 'petal_width'])","e63819ca":"#Inspect the Scaled Data\nprint(df_sprk_scaled.show(5))\nprint(df_sk_scaled.head())","9859c291":"#Dropping the Features column\ndf_sprk_scaled = df_sprk_scaled.drop(\"features\")","e590c2c0":"#PySpark\ntrain_data_sprk, test_data_sprk = df_sprk_scaled.randomSplit([0.9, 0.1], seed = 12345)\n\n#SciKit\nX_train, X_test, y_train, y_test = train_test_split(df_sk_scaled, y, test_size=0.1, random_state= 1234)\n","d4d027e3":"#Inspect Training Data\nprint(train_data_sprk.show(5))\nprint(X_train.head())","e38c0256":"model = ['Decision Tree','Random Forest','Naive Bayes']\nmodel_results = []","1997dc40":"# -- PySpark --\n\ndtc_sprk = pyspark.ml.classification.DecisionTreeClassifier(labelCol=\"label\", featuresCol=\"features_scaled\")          \ndtc_sprk_model = dtc_sprk.fit(train_data_sprk)                                                        \ndtc_sprk_pred = dtc_sprk_model.transform(test_data_sprk)                                              \n\n#Evaluate Model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\ndtc_sprk_acc = evaluator.evaluate(dtc_sprk_pred)                             ","36d8ba85":"# -- SciKit --\ndtc_sk = DecisionTreeClassifier()\ndtc_sk.fit(X_train,y_train)\ndtc_sk_pred = dtc_sk.predict(X_test)\n\n#Evaluate Model\ndtc_sk_acc = accuracy_score(y_test, dtc_sk_pred)\n","6f8da80c":"# -- PySpark --\nrfc_sprk = pyspark.ml.classification.RandomForestClassifier(labelCol=\"label\", featuresCol=\"features_scaled\", numTrees=10)          \nrfc_sprk_model = rfc_sprk.fit(train_data_sprk)                                                                     \nrfc_sprk_pred = rfc_sprk_model.transform(test_data_sprk)                                                       \n\n#Evaluate the Model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nrfc_sprk_acc = evaluator.evaluate(rfc_sprk_pred)\n                                      ","a1903629":"# -- SciKit --\nrfc_sk = RandomForestClassifier(n_estimators=1000, criterion='entropy', random_state=None, bootstrap=True)\nrfc_sk.fit(X_train,y_train)\nrfc_sk_pred = rfc_sk.predict(X_test)\n\n#Evaluate Model\nrfc_sk_acc = accuracy_score(y_test, rfc_sk_pred)","8906e96f":"# -- PySpark --\nnbc_sprk = pyspark.ml.classification.NaiveBayes(smoothing=1.0,modelType=\"gaussian\", labelCol=\"label\",featuresCol=\"features_scaled\")   \nnbc_sprk_model = nbc_sprk.fit(train_data_sprk)                                                                          \nnbc_sprk_pred = nbc_sprk_model.transform(test_data_sprk)                                                                \n\n#Evaluate the Model\nevaluator = MulticlassClassificationEvaluator(labelCol=\"label\", predictionCol=\"prediction\", metricName=\"accuracy\")\nnbc_sprk_acc = evaluator.evaluate(nbc_sprk_pred)\n                                        ","af61ebf7":"# -- SciKit --\nnbc_sk = GaussianNB()\nnbc_sk.fit(X_train,y_train)\nnbc_sk_pred = nbc_sk.predict(X_test)\n\n#Evaluate Model\nnbc_sk_acc = accuracy_score(y_test, nbc_sk_pred)","3004ff74":"#freeing memory\ngc.collect()","ddca0455":"model_data = [['Decision Tree Classifier', '{:.2%}'.format(dtc_sprk_acc),'{:.2%}'.format(dtc_sk_acc)], \\\n              ['Random Forest Classifier', '{:.2%}'.format(rfc_sprk_acc),'{:.2%}'.format(rfc_sk_acc)], \\\n              ['Naive Bayes (Gaussian)',   '{:.2%}'.format(nbc_sprk_acc),'{:.2%}'.format(nbc_sk_acc)]]","75af91c9":"print (tabulate(model_data, headers=[\"Classifier Models\", \"PySpark Accuracy\", \"SciKit Accuracy\"]))","ee279586":"# PySpark vs SciKit\n\nIn this tuorial notebook we shall try to compare the accuracy of the common classifier models between PySpark & SciKit. The data that we shall be using is the Iris Dataset\n\n**Models to be Compared:**\n* Decision Tree Classifier\n* Naive Bayes\n* Random Forest\n\n\n**A quick summary:**\n\n* Import Libraries\n* Build Spark Session\n* Data Load\n* Data Exploration & Preparation\n* Feature Engineering\n* Data Scaling\n* Data Split\n* Build, Train & Evaluate Model\n* Comparison\n","3aeb3501":"### Random Forest Classifier","7553c1ff":"## Data Exploration & Preparation","4f3b8615":"The Spark model needs two columns: \u201clabel\u201d and \u201cfeatures\u201d and we are not going to do much feature engineering because we want to focus on the mechanics of training the model in Spark. \n\nSo, creating a seperate dataframe with re-ordered columns, then defining an input data using Dense Vector. A Dense Vector is a local vector that is backed by a double array that represents its entry values. In other words, it's used to store arrays of values for use in PySpark.\n","f5b24fa2":"## Build, Train & Evaluate Model\n\nIn this step we will create multiple models, train them on our scaled dataset and then compare their accuracy.","faf74dd6":"**Conclusion** - The SciKit Classifier Models perform slightly better than the PySpark Models.","c6aa6518":"### Decision Tree Classifier","1c97e125":"## Build Spark Session","5d74ee9d":"## Feature Engineering","21d9b85e":"### Naive Bayes","5f3e3b9c":"## Data Scaling","7f06b1d6":"## Comparison","a36057b3":"Inorder for our model to make predictions the Species aka Label column should be a numerical value (models don't like string!). To achieve this we shall use String Indexing on the Species columns","03f9b5e8":"## Data Split\n\nJust like always, before building a model we shall split our scaled dataset into training & test sets. \nTraining Dataset = 90%\nTest Dataset = 10%","4a82ef51":"## Data Load\n\nJust to keep things organized and clear, we will load the data in seperate dataframes","9ef6e0bc":"## Importing Libraries"}}