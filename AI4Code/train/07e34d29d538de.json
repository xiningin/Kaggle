{"cell_type":{"9692a1a9":"code","1f0db2ec":"code","84fd586d":"code","50728aaa":"code","fc0d900a":"code","67de707e":"code","7e86c0e6":"code","a86c61a6":"code","394cc61c":"code","ae174293":"code","282e20c0":"code","65637a88":"code","34d48d81":"code","4aa1b3a8":"code","aa3c1fb1":"code","182fee10":"code","7e6f07ab":"code","86d40c70":"code","7a83ecb8":"code","008a4758":"code","55468315":"code","07142d95":"code","cc68f509":"code","2da430fd":"code","318beffe":"code","6cde09ff":"code","83fcb2a0":"code","550ddbb2":"code","fe7d5983":"code","4a7e9e07":"code","bc02072b":"code","cfd9ac21":"code","7e5e6a13":"code","7381ab0e":"code","d1efb638":"code","ff7bbb8b":"code","3c098267":"code","d9132357":"code","ff3f4e12":"code","eb5d8656":"code","040bc3b5":"code","57a274f1":"code","09a9dc57":"code","a7e1b05d":"code","3d1bc7c5":"code","01bef4ed":"code","123f33fb":"code","c59aeb05":"code","b9c38110":"code","35bcc5db":"code","d526322f":"code","302bab46":"code","03975c4f":"code","42257773":"markdown","cfd81279":"markdown","ebfb1823":"markdown","478ef97e":"markdown","c904aad7":"markdown","32f4d9d8":"markdown","d98d3aa8":"markdown","bf34669f":"markdown","a78b5c69":"markdown","bfc252f9":"markdown","16100239":"markdown","ed1cd79c":"markdown"},"source":{"9692a1a9":"from numpy.random import seed \nseed(888) \nimport tensorflow as tf\ntf.random.set_seed(404)","1f0db2ec":"import os \nfrom IPython.display import clear_output\nimport numpy as np \nimport tensorflow as tf \nimport itertools\n\nimport keras \nfrom keras.datasets import cifar10\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Activation,Dropout\n\nfrom IPython.display import display \nfrom keras.preprocessing.image import array_to_img \nfrom keras.callbacks import TensorBoard\n\nfrom sklearn.metrics import confusion_matrix\n\nfrom time import strftime\n\nimport matplotlib.pyplot as plt\n%matplotlib inline","84fd586d":"LOG_DIR = 'tensorboard_cifar_logs\/'\n\nLABEL_NAMES = ['Plane', 'Car', 'Bird', 'Cat', 'Deer', 'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\nVALIDATION_SIZE = 10000\nSMALL_TRAIN_SIZE = 1000\n\nIMAGE_WIDTH = 32 \nIMAGE_HEIGHT = 32 \nIMAGE_PIXELS = IMAGE_HEIGHT * IMAGE_WIDTH \nCOLOR_CHANNELS = 3 \nTOTAL_INPUTS = IMAGE_PIXELS * COLOR_CHANNELS\n\nNR_CLASSES = 10 ","50728aaa":"(x_train_all, y_train_all), (x_test, y_test) = cifar10.load_data()","fc0d900a":"type(cifar10)\ntype(x_train_all)","67de707e":"x_train_all[0]","7e86c0e6":"pic = array_to_img(x_train_all[0])\ndisplay(pic)","a86c61a6":"y_train_all[7][0]","394cc61c":"LABEL_NAMES[y_train_all[7][0]]","ae174293":"plt.imshow(x_train_all[4])\nplt.xlabel(LABEL_NAMES[y_train_all[4][0]])\nplt.show()","282e20c0":"plt.figure(figsize=(15,5))\n\nfor i in range(10): \n    plt.subplot(1,10,i+1)\n    plt.yticks([])\n    plt.xticks([])\n    plt.xlabel(LABEL_NAMES[y_train_all[i][0]])\n    plt.imshow(x_train_all[i])\n","65637a88":"x_train_all[0].shape","34d48d81":"nr_images, x, y, c = x_train_all.shape\nprint(f'images = {nr_images} \\t| width = {x} \\t| height = {y} \\t| channels = {c}')","4aa1b3a8":"type(x_train_all[0][0][0][0])","aa3c1fb1":"x_train_all, x_test = x_train_all \/ 255.0, x_test \/ 255.0 ","182fee10":"x_train_all.shape","7e6f07ab":"x_train_all = x_train_all.reshape(len(x_train_all), 32*32*3)\nx_train_all.shape","86d40c70":"x_test = x_test.reshape(len(x_test), 32*32*3)\nprint(x_test.shape)","7a83ecb8":"x_train = x_train_all[VALIDATION_SIZE:]\ny_train = y_train_all[VALIDATION_SIZE:] \n\nx_val = x_train_all[:VALIDATION_SIZE]\ny_val = y_train_all[:VALIDATION_SIZE]","008a4758":"x_train_xs = x_train[:SMALL_TRAIN_SIZE]\ny_train_xs = y_train[:SMALL_TRAIN_SIZE]\n","55468315":"model_1 = Sequential([\n    Dense(units=128, input_dim=TOTAL_INPUTS, activation='relu'), \n    Dense(units=64, activation='relu'), \n    Dense(units=16, activation='relu'),\n    Dense(units=10, activation='softmax')\n])\n\nmodel_1.compile(\n    optimizer = 'adam', \n    loss='sparse_categorical_crossentropy', \n    metrics=['accuracy']\n)\n","07142d95":"model_2 = Sequential() \nmodel_2.add(Dropout(0.2, seed=42,input_shape=(TOTAL_INPUTS,)))\nmodel_2.add(Dense(units=128, activation='relu'))\nmodel_2.add(Dense(units=64, activation='relu'))\nmodel_2.add(Dense(units=16, activation='relu'))\nmodel_2.add(Dense(units=10, activation='softmax'))\n\nmodel_2.compile(\n    optimizer = 'adam', \n    loss='sparse_categorical_crossentropy', \n    metrics=['accuracy']\n)\n","cc68f509":"model_3 = Sequential()\nmodel_3.add(Dropout(0.2, seed=42,input_shape=(TOTAL_INPUTS,)))\nmodel_3.add(Dense(units=128, activation='relu'))\nmodel_3.add(Dropout(0.25, seed=42))\nmodel_3.add(Dense(units=64, activation='relu'))\nmodel_3.add(Dense(units=16, activation='relu'))\nmodel_3.add(Dense(units=10, activation='softmax'))\n\nmodel_3.compile(\n    optimizer = 'adam', \n    loss='sparse_categorical_crossentropy', \n    metrics=['accuracy']\n)","2da430fd":"type(model_1)","318beffe":"model_1.summary() ","6cde09ff":"def get_tensorboard(model_name):\n\n    folder_name = f'{model_name} at {strftime(\"%H %M\")}'\n    dir_paths = os.path.join(LOG_DIR, folder_name)\n\n    try:\n        os.makedirs(dir_paths)\n    except OSError as err:\n        print(err.strerror)\n    else:\n        print('Successfully created directory')\n\n    return TensorBoard(log_dir=dir_paths)","83fcb2a0":"class TrainingPlot(keras.callbacks.Callback):\n    \n    # This function is called when the training begins\n    def on_train_begin(self, logs={}):\n        # Initialize the lists for holding the logs, losses and accuracies\n        self.losses = []\n        self.acc = []\n        self.val_losses = []\n        self.val_acc = []\n        self.logs = []\n    \n    # This function is called at the end of each epoch\n    def on_epoch_end(self, epoch, logs={}):\n        \n        # Append the logs, losses and accuracies to the lists\n        self.logs.append(logs)\n        self.losses.append(logs.get('loss'))\n        self.acc.append(logs.get('acc'))\n        self.val_losses.append(logs.get('val_loss'))\n        self.val_acc.append(logs.get('val_acc'))\n        \n        # Before plotting ensure at least 2 epochs have passed\n        if len(self.losses) > 1:\n            \n            # Clear the previous plot\n            clear_output(wait=True)\n            N = np.arange(0, len(self.losses))\n            \n            # You can chose the style of your preference\n            # print(plt.style.available) to see the available options\n            plt.style.use(\"seaborn\")\n            \n            # Plot train loss, train acc, val loss and val acc against epochs passed\n            plt.figure()\n            plt.plot(N, self.losses, label = \"train_loss\")\n            plt.plot(N, self.acc, label = \"train_acc\")\n            plt.plot(N, self.val_losses, label = \"val_loss\")\n            plt.plot(N, self.val_acc, label = \"val_acc\")\n            plt.title(\"Training Loss and Accuracy [Epoch {}]\".format(epoch))\n            plt.xlabel(\"Epoch #\")\n            plt.ylabel(\"Loss\/Accuracy\")\n            plt.legend()\n            plt.show()\n\nplot_losses = TrainingPlot()","550ddbb2":"samples_per_batch = 1000 ","fe7d5983":"%%time \nnr_epochs = 150 \nmodel_1.fit(x_train_xs, y_train_xs, epochs=nr_epochs, batch_size=samples_per_batch,verbose=0, \n           validation_data=(x_val,y_val))","4a7e9e07":"%%time \nnr_epochs = 150 \nmodel_2.fit(x_train_xs, y_train_xs, epochs=nr_epochs, batch_size=samples_per_batch,verbose=0, \n           validation_data=(x_val,y_val))","bc02072b":"%%time \nnr_epochs = 150 \nmodel_3.fit(x_train_xs, y_train_xs, epochs=nr_epochs, batch_size=samples_per_batch,verbose=0, \n           validation_data=(x_val,y_val))","cfd9ac21":"x_val[0].shape","7e5e6a13":"test = np.expand_dims(x_val[0], axis=0) \ntest.shape","7381ab0e":"np.set_printoptions(precision=3)","d1efb638":"model_2.predict(test)","ff7bbb8b":"model_2.predict(x_val) .shape","3c098267":"model_3.predict_classes(test)","d9132357":"y_val[0]","ff3f4e12":"for number in range(10): \n    test_img = np.expand_dims(x_val[number], axis=0)\n    predicted_val = model_3.predict_classes(test_img)[0] \n    print(f'Actual value: {y_val[number][0]} vs. predicted: {predicted_val}')","eb5d8656":"model_3.metrics_names","040bc3b5":"test_loss, test_accuracy = model_3.evaluate(x_test, y_test)\nprint(f'Test loss is {test_loss:0.3} and test accuracy is {test_accuracy:0.1%}')","57a274f1":"predictions = model_3.predict_classes(x_test)\nconf_matrix = confusion_matrix(y_true=y_test, y_pred=predictions)","09a9dc57":"conf_matrix.shape","a7e1b05d":"nr_rows = conf_matrix.shape[0]\nnr_cols = conf_matrix.shape[1]","3d1bc7c5":"conf_matrix.max() ","01bef4ed":"conf_matrix.min() ","123f33fb":"conf_matrix[0]","c59aeb05":"plt.figure(figsize=(7,7), dpi= 200) \nplt.imshow(conf_matrix, cmap=plt.cm.Greens)\nplt.title('Confusion Matrix', fontsize=16) \nplt.ylabel('Actual Labels', fontsize=12)\nplt.xlabel('Predicted Labels', fontsize=12)\n\ntick_marks = np.arange(NR_CLASSES)\nplt.yticks(tick_marks, LABEL_NAMES)\nplt.xticks(tick_marks, LABEL_NAMES)\nplt.colorbar() \n\nfor i, j in itertools.product(range(nr_rows), range(nr_cols)):\n    plt.text(j, i, conf_matrix[i, j], horizontalalignment='center',\n            color='white' if conf_matrix[i, j] > conf_matrix.max()\/2 else 'black')\n    \n    \nplt.show()","b9c38110":"# True Posiives \nnp.diag(conf_matrix)","35bcc5db":"recall = np.diag(conf_matrix) \/ np.sum(conf_matrix, axis=1)\nrecall","d526322f":"precision = np.diag(conf_matrix) \/ np.sum(conf_matrix, axis=0)\nprecision","302bab46":"avg_recall = np.mean(recall)\nprint(f'Model 2 recall score is {avg_recall:.2%}')","03975c4f":"avg_precision = np.mean(precision)\nprint(f'Model 2 precision score is {avg_precision:.2%}')\n\nf1_score = 2 * (avg_precision * avg_recall) \/ (avg_precision + avg_recall)\nprint(f'Model 2 f score is {f1_score:.2%}')","42257773":"# Imports ","cfd81279":"# Evaluation","ebfb1823":"# Tensorboard (visualising learning)","478ef97e":"# Constants ","c904aad7":"# Create Validation Dataset","32f4d9d8":"# Prediction","d98d3aa8":"# Explore the Data","bf34669f":"### Create a small dataset (for illustration)","a78b5c69":"# Get The Data","bfc252f9":"# F\u0131t the Model","16100239":"### Confusion Matrix","ed1cd79c":"# Preproccess Data "}}