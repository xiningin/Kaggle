{"cell_type":{"c2c7fff2":"code","e562f074":"code","c566cca1":"code","ab797a12":"code","6f8ba472":"code","95bf81d0":"code","a560e32e":"code","c58bf6ab":"code","c75c35f5":"code","b560dccb":"code","bbd54a98":"code","55807f75":"code","ade89451":"code","08c1e22f":"code","d18efe48":"code","107af231":"code","bba1d882":"code","6068fb0e":"code","82f76204":"code","ea1cdd91":"code","1843421d":"code","f50d4aab":"code","a7c5d3c8":"code","4dd2c3cf":"code","8e162ef1":"code","6f4cfbd2":"markdown","ecc19a37":"markdown","058155c2":"markdown","4410d927":"markdown","63b5b790":"markdown","e7085402":"markdown","a702995a":"markdown","408b1707":"markdown","e25246dc":"markdown","bb1b7325":"markdown","4c68526e":"markdown","fbeeb667":"markdown","eca505fa":"markdown"},"source":{"c2c7fff2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e562f074":"train_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/train.csv\")\ntest_data = pd.read_csv(\"\/kaggle\/input\/digit-recognizer\/test.csv\")\nprint(f\"Shape of train data : {train_data.shape}\\nShape of test data : {test_data.shape}\")","c566cca1":"train_data.head()","ab797a12":"test_data.head()","6f8ba472":"y_train = train_data[\"label\"]\nx_train = train_data.drop(labels=[\"label\"], axis = 1)","95bf81d0":"y_train","a560e32e":"x_train.shape","c58bf6ab":"plt.figure(figsize=(8,6))\nsns.countplot(y_train)\nplt.xlabel(\"Digit's Classes\")\nplt.ylabel(\"Frequency\")\nplt.title(\"Frequency of Digits\")\nplt.show()","c75c35f5":"for i in range(0,4):\n    plt.subplot(2,2,1)\n    img = x_train.iloc[i].to_numpy() #converting to matrix\n    img = img.reshape((28,28))\n    plt.imshow(img,cmap='gray')\n    plt.axis(\"off\")\n    plt.show()","b560dccb":"# Normalization\nx_train = x_train \/ 255.0\ntest_data = test_data \/ 255.0\nprint(f\"Shape of x_train : {x_train.shape}\\nShape of test_data : {test_data.shape}\")","bbd54a98":"# Reshape\nx_train = x_train.values.reshape(-1,28,28,1)\ntest_data = test_data.values.reshape(-1,28,28,1)\nprint(f\"Shape of x_train : {x_train.shape}\\nShape of test_data : {test_data.shape}\")","55807f75":"# Encoding\nfrom keras.utils.np_utils import to_categorical #converts to one hot encoding\ny_train = to_categorical(y_train, num_classes=10)","ade89451":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(x_train, y_train, test_size = 0.1, random_state=2)\nprint(\"X_train shape : \",X_train.shape)\nprint(\"X_val shape : \",X_val.shape)\nprint(\"Y_train shape: \",Y_train.shape)\nprint(\"Y_val shape : \",Y_val.shape)","08c1e22f":"from sklearn.metrics import confusion_matrix\nimport itertools\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Flatten, Conv2D, MaxPool2D, BatchNormalization, Activation\nfrom keras.optimizers import RMSprop,Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ReduceLROnPlateau","d18efe48":"#CNN\nmodel=Sequential()\n\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\", input_shape=(28,28,1)))\nmodel.add(Conv2D(filters=64, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\nmodel.add(Conv2D(filters=128, kernel_size = (3,3), activation=\"relu\"))\n\nmodel.add(MaxPool2D(pool_size=(2,2)))\nmodel.add(BatchNormalization())    \nmodel.add(Conv2D(filters=256, kernel_size = (3,3), activation=\"relu\"))\n    \nmodel.add(MaxPool2D(pool_size=(2,2)))\n\n#ANN\nmodel.add(Flatten())\nmodel.add(BatchNormalization())\nmodel.add(Dense(512,activation=\"relu\"))\n    \nmodel.add(Dense(10,activation=\"softmax\"))\n    \nmodel.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics=[\"accuracy\"])","107af231":"optimizer = Adam(lr = 0.002, beta_1=0.9, beta_2=0.999)","bba1d882":"model.compile(optimizer=optimizer, loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])","6068fb0e":"datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # dimesion reduction\n        rotation_range=5,  # randomly rotate images in the range 5 degrees\n        zoom_range = 0.1, # Randomly zoom image 10%\n        width_shift_range=0.1,  # randomly shift images horizontally 10%\n        height_shift_range=0.1,  # randomly shift images vertically 10%\n        horizontal_flip=False,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n\ndatagen.fit(X_train)","82f76204":"history = model.fit_generator(datagen.flow(X_train,Y_train, batch_size=128),\n                              epochs = 25, validation_data = (X_val,Y_val), steps_per_epoch=X_train.shape[0] \/\/ 128)","ea1cdd91":"final_loss, final_accuracy = model.evaluate(X_val, Y_val, verbose=0)\nprint(\"Final loss: {0:.4f}, final accuracy: {1:.4f}\".format(final_loss, final_accuracy))","1843421d":"model.summary()","f50d4aab":"plt.plot(history.history['loss'], color='b')\nplt.plot(history.history['val_loss'], color='r')\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Loss\")\nplt.title(\"Validation Loss\")\nplt.show()\nplt.plot(history.history['accuracy'], color='b')\nplt.plot(history.history['val_accuracy'], color='r')\nplt.xlabel(\"Number of Epochs\")\nplt.ylabel(\"Accuracy\")\nplt.title(\"Validation Accuracy\")\nplt.show()","a7c5d3c8":"# Prediction from validation \nY_pred = model.predict(X_val)\nY_pred_class = np.argmax(Y_pred, axis=1) # prediction classes to one hot vectors\nY_true = np.argmax(Y_val, axis=1)\n\nconfusion_matrix = confusion_matrix(Y_true, Y_pred_class)\nf, ax = plt.subplots(figsize=(8,8))\nsns.heatmap(confusion_matrix, annot=True, linewidths=0.01, cmap=\"Greens\", linecolor=\"gray\", fmt=\".1f\", ax=ax)\nplt.xlabel(\"Predicted Label\")\nplt.ylabel(\"True Label\")\nplt.title(\"Confusion Matrix\")\nplt.show()","4dd2c3cf":"for i in range(len(confusion_matrix)):\n    print(\"Class : \",str(i))\n    print(\"Number of Wrong Predictions : \", str(sum(confusion_matrix[i])-confusion_matrix[i][i]), \"out of \"+str(sum(confusion_matrix[i])))\n    print(\"Percentage of True Predictions : {:.2f}%\".format(confusion_matrix[i][i] \/ (sum(confusion_matrix[i])\/100) ))\n    print(\"***********************************************************\")","8e162ef1":"predictions = model.predict_classes(test_data, verbose=0)\n\nsubmissions=pd.DataFrame({\"ImageId\": list(range(1,len(predictions)+1)),\n                         \"Label\": predictions})\nsubmissions.to_csv(\"FEG.csv\", index=False, header=True)","6f4cfbd2":"# Read and Identify Dataset","ecc19a37":"#### Train data is labeled however test data is not.","058155c2":"# CNN","4410d927":"## Normalization - Reshape - Encoding","63b5b790":"#### There is also test data for testing model, so we use validation instead of test.","e7085402":"### Plotting some samples","a702995a":"* As you know, colors take values 0-255 (RGB). In CNN it is better to make them 0-1. That means grey scale. This make our code faster. Also it reduce the effect of illumination's differences.\n* Train and test images (28 x 28). We reshape all data to 28x28x1 3D matrices. Keras needs an extra dimension in the end which correspond to channels. Our images are gray scaled so it use only one channel.\n* Encode labels to one hot vectors : (One hot encoding)\n    * 2 => [0,0,1,0,0,0,0,0,0,0]\n    * 4 => [0,0,0,0,1,0,0,0,0,0]","408b1707":"## Data Augmentation","e25246dc":"#### Data seems to be balanced.","bb1b7325":"## Submission","4c68526e":"## Evaluation","fbeeb667":"# Introduction \n#### Digit Recognition MNIST dataset is kind a hello world activity for practising Convolutional Neural Networks (CNN). In this notebook, I will try to find optimum parameters for CNN model.","eca505fa":"## Split"}}