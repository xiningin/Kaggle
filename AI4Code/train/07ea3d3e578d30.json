{"cell_type":{"f4eabd50":"code","2d7cc348":"code","17adb1f5":"code","ac18d733":"code","4e492b65":"code","1e12a1a4":"code","17b240f7":"code","e08f2bab":"code","58533b58":"markdown","9c8923d5":"markdown","ca8745c0":"markdown"},"source":{"f4eabd50":"import os\nimport gc\nimport numpy as np\nimport pandas as pd\n\nfrom time import time\nfrom time import ctime\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\nfrom tqdm import tqdm_notebook\nfrom tqdm import tqdm\nRANDOM_STATE = 42\n\nimport joblib\nfrom joblib import Parallel, delayed\nimport multiprocessing\nnum_cores = multiprocessing.cpu_count()-1\n\nfrom catboost import CatBoostRegressor, Pool\nimport lightgbm as lgbm\n\nfrom sklearn.metrics import mean_absolute_error\nfrom sklearn.metrics import r2_score\n\nfrom sklearn.model_selection import KFold\nfrom sklearn.feature_selection import SelectFromModel\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\ndef plotfig (ypred, yactual, strtitle, y_max):\n    plt.scatter(ypred, yactual.values.ravel())\n    plt.title(strtitle)\n    plt.plot([(0, 0), (y_max, y_max)], [(0, 0), (y_max, y_max)])\n    plt.xlim(0, y_max)\n    plt.ylim(0, y_max)\n    plt.xlabel('Predicted', fontsize=12)\n    plt.ylabel('Actual', fontsize=12)\n    plt.show()","2d7cc348":"train = pd.read_csv('..\/input\/ingv-tsfresh-7730\/train.csv', sep = ';')\ntrain.set_index('Unnamed: 0', inplace = True)\ntest = pd.read_csv('..\/input\/ingv-tsfresh-7730\/test.csv', sep = ';')\ntest.set_index('Unnamed: 0', inplace = True)","17adb1f5":"train.head()     ","ac18d733":"# from tsfresh import select_features\n# from tsfresh.utilities.dataframe_functions import impute\n# from tsfresh import extract_relevant_features\n# from tsfresh.feature_extraction import settings, extract_features, MinimalFCParameters, EfficientFCParameters, ComprehensiveFCParameters\n\n\n# def features_generator(path_to_file):\n#     signals = pd.read_csv(path_to_file)\n#     seg = int(path_to_file.split('\/')[-1].split('.')[0])\n#     signals['segment_id'] = seg\n    \n#     sel = signals.fillna(0).astype(bool).sum(axis=0) \/ 60001 > 0.5\n#     signals = signals.fillna(0).loc[:,sel]\n\n#     extracted_features = extract_features(signals.iloc[:,:], \n#                                           column_id = 'segment_id', \n#                                           default_fc_parameters=EfficientFCParameters(),\n#                                           n_jobs = 0,\n#                                           disable_progressbar = False,\n#                                           chunksize = None,\n#                                          )\n#     return extracted_features\n\n# %%time\n# train_path_to_signals = 'G:\/Kaggle\/INGV_Volcanic_Eruption_Prediction\/raw_data\/predict-volcanic-eruptions-ingv-oe\/train\/'\n# train_files_list = [os.path.join(train_path_to_signals, file) for file in os.listdir(train_path_to_signals)]\n# rows = Parallel(n_jobs=30)(delayed(features_generator)(ex) for ex in tqdm_notebook(train_files_list[:]))  \n# train_set = pd.concat(rows, axis=0)\n\n# test_path_to_signals = 'G:\/Kaggle\/INGV_Volcanic_Eruption_Prediction\/raw_data\/predict-volcanic-eruptions-ingv-oe\/test\/'\n# test_files_list = [os.path.join(test_path_to_signals, file) for file in os.listdir(test_path_to_signals)]\n# rows = Parallel(n_jobs=30)(delayed(features_generator)(ex) for ex in tqdm_notebook(test_files_list[:]))  \n# test_set = pd.concat(rows, axis=0)","4e492b65":"%%time\n\nY = train['time_to_eruption']\nX = train.drop(['time_to_eruption'], axis = 1)\nX_test = test\n\nn_fold = 3\ncv = KFold(n_splits=n_fold, shuffle=True, random_state=RANDOM_STATE)\n\noof = np.zeros(len(X))\ncat_prediction = np.zeros(len(X_test))\nmae, r2 = [], []\n\nPARAMS = {\n    \n             'random_seed': RANDOM_STATE,\n             'eval_metric': 'MAE',\n             'iterations': 10000,\n             'task_type': 'GPU',\n\n        }\n\nfor fold_n, (train_index, valid_index) in enumerate(cv.split(X)):\n    print('\\nFold', fold_n, 'started at', ctime())\n\n    X_train = X.iloc[train_index,:]\n    X_valid = X.iloc[valid_index,:]\n    \n    Y_train = Y.iloc[train_index]\n    Y_valid = Y.iloc[valid_index]\n          \n    best_model = CatBoostRegressor(**PARAMS, thread_count = -1)  \n    \n    train_dataset = Pool(data=X_train,\n                     label=Y_train,\n                     )\n    \n    eval_dataset = Pool(data=X_valid,\n                    label=Y_valid,\n                    )\n    \n    best_model.fit(train_dataset,\n              use_best_model=True,\n              verbose = False,\n              plot = True,\n              eval_set=eval_dataset,\n              early_stopping_rounds=100)\n\n   \n    y_pred = best_model.predict(Pool(data=X_valid))\n\n    mae.append(mean_absolute_error(Y_valid, y_pred))\n    r2.append(r2_score(Y_valid, y_pred))\n\n    print('MAE: ', mean_absolute_error(Y_valid, y_pred))\n    print('R2: ', r2_score(Y_valid, y_pred))\n\n    cat_prediction += best_model.predict(Pool(data=X_test))\n        \ncat_prediction \/= n_fold\n\nprint('='*45)\nprint('CV mean MAE: {0:.4f}, std: {1:.4f}.'.format(np.mean(mae), np.std(mae)))\nprint('CV mean R2:  {0:.4f}, std: {1:.4f}.'.format(np.mean(r2), np.std(r2)))","1e12a1a4":"plotfig(best_model.predict(X), Y, 'Predicted vs. Actual responses for Catboost', max(Y) + 0.1*max(Y))","17b240f7":"plt.title('Distribution of Train time to eruption (scaled 0 to 1 = max)')\nsns.kdeplot(train['time_to_eruption'] \/ train['time_to_eruption'].max(), color='Red')\nsns.kdeplot(cat_prediction \/ cat_prediction.max(), color='Blue')","e08f2bab":"submission = pd.DataFrame()\nsubmission['segment_id'] = test.index\nsubmission['time_to_eruption'] = cat_prediction\nsubmission.to_csv('submission.csv', header=True, index=False)","58533b58":"### Load prepared dataset","9c8923d5":"### Or create it using the TSFresh lib","ca8745c0":"This is a catboost baseline for prediction time to eruption using the generated dataset with TSFresh https:\/\/tsfresh.readthedocs.io\/en\/latest\/text\/introduction.html. \nI used the EfficientFCParameters() parameter that results in 773 features generation for each sensor signal. Both train and test datasets were processing during 5 days on 30 threads of Ryzen TR 1950X. Finally, we have 7730 features for each observation. The dataset is uploaded as ingv-tsfresh-7730. Let's get better metrics and scores :) "}}