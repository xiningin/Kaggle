{"cell_type":{"2f1fd7b7":"code","5cf56c1c":"code","45370f0c":"code","7648ecc0":"code","f9632166":"code","dc0b28ad":"code","5989dd6b":"code","9c57fe93":"code","309998ec":"code","f994da37":"code","48e6256e":"markdown","9536ded3":"markdown","81b82d62":"markdown","75a2a43d":"markdown","3b4a0965":"markdown","19392f55":"markdown","22dbddeb":"markdown"},"source":{"2f1fd7b7":"import IPython.display as display\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport keras\nimport tensorflow as tf\nfrom tensorflow.keras.layers import *\nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\nfrom tensorflow.keras.optimizers import Adam\nimport os","5cf56c1c":"train_dir = \"\/kaggle\/input\/potato-weed-plants-classification\/Dataset\/train\"\nvalidation_dir = \"\/kaggle\/input\/potato-weed-plants-classification\/Dataset\/val\"","45370f0c":"# Image size that we are going to use\nIMG_SIZE = 128\n# Our images are RGB (3 channels)\nN_CHANNELS = 3\n# Weed + Potato\nN_CLASSES = 2\n# Batch Size\nBATCH_SIZE=16","7648ecc0":"train_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,\n    shear_range=0.2,\n    zoom_range=0.2,\n    rotation_range=20,\n    horizontal_flip=True,\n    vertical_flip=True)\nval_datagen=tf.keras.preprocessing.image.ImageDataGenerator(\n    rescale=1.\/255,)\n# Flow training images in batches of 20 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(IMG_SIZE, IMG_SIZE),  # All images will be resized to 128x128\n        batch_size=BATCH_SIZE,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow validation images in batches of 20 using val_datagen generator\nvalidation_generator = val_datagen.flow_from_directory(\n        validation_dir,\n        target_size=(IMG_SIZE, IMG_SIZE),\n        batch_size=BATCH_SIZE,\n        class_mode='binary',\n        shuffle=False)","f9632166":"base_model = tf.keras.applications.MobileNetV2(input_shape=[128,128, 3], include_top=False)\nbase_model.trainable = False\ninputs = Input(shape=(128,128, 3))\n# We make sure that the base_model is running in inference mode here,\n# by passing `training=False`. This is important for fine-tuning, as you will\n# learn in a few paragraphs.\nx = base_model(inputs, training=False)\n# Convert features of shape `base_model.output_shape[1:]` to vectors\nx = keras.layers.GlobalAveragePooling2D()(x)\n# A Dense classifier with a single unit (binary classification)\noutputs = keras.layers.Dense(1,activation='sigmoid')(x)\nmodel = tf.keras.Model(inputs, outputs)","dc0b28ad":"model.compile(optimizer=keras.optimizers.Adam(),\n              loss=keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=['accuracy'])","5989dd6b":"# No of EPOCHS\nEPOCH=20\n\nhistory=model.fit(train_generator, epochs=EPOCH, validation_data=validation_generator,verbose=2)","9c57fe93":"# Retrieve a list of accuracy results on training and validation data\n# sets for each training epoch\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\n# Retrieve a list of list results on training and validation data\n# sets for each training epoch\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\n# Get number of epochs\nepochs = range(len(acc))\n\n# Plot training and validation accuracy per epoch\nplt.plot(epochs, acc)\nplt.plot(epochs, val_acc)\nplt.title('Training and validation accuracy')\n\nplt.figure()\n\n# Plot training and validation loss per epoch\nplt.plot(epochs, loss)\nplt.plot(epochs, val_loss)\nplt.title('Training and validation loss')","309998ec":"from sklearn.metrics import confusion_matrix,plot_confusion_matrix\nimport itertools\ndef plot_confusion_matrix(cm, classes,\n                        normalize=False,\n                        title='Confusion matrix',\n                        cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    if normalize:\n        cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n        print(\"Normalized confusion matrix\")\n    else:\n        print('Confusion matrix, without normalization')\n\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n            horizontalalignment=\"center\",\n            color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","f994da37":"y_true = validation_generator.classes\ny_pred=model.predict_generator(validation_generator)\ny_pred = np.rint(y_pred)\ncm=confusion_matrix(y_true,y_pred)\n\nclass_names = ['Potato','Weed']\nplot_confusion_matrix(cm=cm, classes=class_names, title='Confusion Matrix')","48e6256e":"## Evaluate Model","9536ded3":"## Train Network ","81b82d62":"## Import libraries\nWe used following libraries\n\n* **Matplotlib**\nTo draw the training progress plot for training accuracy, validation accuracy, training loss and valiadation loss.\n* **Tensoflow&Keras**\nTo design and train Deep Learning Model.\n* **Sklearn**\nTo calculate and draw the  confusion matrix.","75a2a43d":"Tabel 1\n\n>For | No. of Samples\n>--- | ---\n> Training| 336\n> Testing | 75\n\nTabel 2 (Training Data)  \n>Class | No. of Samples\n>--- | ---\n> Potato| 138\n> Weeds | 198\n\nTabel 3 (Testing Data)    \n>Class | No. of Samples\n>--- | ---\n> Potato| 31\n> Weeds | 44","3b4a0965":"## Plot Training Progress","19392f55":"## Design Network","22dbddeb":"## Import and PreProcess Data"}}