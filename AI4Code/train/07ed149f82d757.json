{"cell_type":{"2ee82a0f":"code","d5f20f2f":"code","a83791d9":"code","6d25cee6":"code","7729fdf7":"code","6a84e9b6":"code","dfc636cb":"code","d4b7d9a4":"code","82db07c6":"code","7351e1a9":"code","fef65f2e":"code","749d4df9":"code","893a1997":"code","c27e02ec":"code","da4d8145":"code","e0110d13":"code","b174fbde":"code","2e9e53fb":"code","522604f0":"code","52bed145":"code","6efccb61":"code","26127e68":"code","09da7c4a":"code","4e486992":"code","27591b77":"code","dfa1d8eb":"code","dd8864b3":"code","4972464f":"code","d2a3bea9":"code","22b05820":"code","32974823":"code","ae04dfcf":"code","1fdb229b":"code","77ecdd81":"code","b6dae39d":"code","14e70281":"code","02d818eb":"code","5acd11aa":"code","afabf5bd":"code","99f48767":"code","cf2e5560":"code","5bd20167":"code","93d83199":"code","3ccf4bf0":"code","d91fc841":"code","01f04379":"code","c6421f6d":"code","31452f9e":"code","0f215077":"code","9f905b78":"code","c832ef30":"code","3c5d5e75":"code","e4916aaa":"code","2f77f5ea":"code","418d9b9f":"code","1e5d2903":"code","0db440b7":"code","a27c79e1":"code","244cf5a2":"code","2ec457b3":"code","a372f1ef":"code","392f0c10":"code","68d2d4fe":"code","bfb223c7":"code","89b6df42":"code","11bb5e12":"markdown","0f56cf24":"markdown","44fbbf78":"markdown","3ea3fd68":"markdown","ffae84af":"markdown","93e9e715":"markdown","e94e96af":"markdown","f4beb0dd":"markdown","e666a6ca":"markdown","61ecba4e":"markdown","d45e64dc":"markdown","9b42c13d":"markdown","6f11827c":"markdown","76c6a421":"markdown","d6ebb33e":"markdown","303df446":"markdown","7add058c":"markdown","fcdc1615":"markdown","18e81fec":"markdown","d40a8469":"markdown","d3bdbecc":"markdown","1b7298ff":"markdown","c5967f5c":"markdown","5451b74e":"markdown","e477589c":"markdown","28f5b5f5":"markdown","80557989":"markdown","347424cb":"markdown","6c355c3b":"markdown","b203b01e":"markdown","4e95b1a3":"markdown","e7340164":"markdown","1f009315":"markdown","5db0f284":"markdown","f6cfaf7a":"markdown","4ddb4b6f":"markdown","0e0141db":"markdown","9903361c":"markdown","ca0e0f8a":"markdown"},"source":{"2ee82a0f":"import pandas as pd\nimport numpy as np","d5f20f2f":"trainData = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/train_data.csv\")\n\ncolumns = [\"ID\", \"Age\", \"Work class\", \"fnlwgt\", \"Education\", \"Education.num\",\n           \"Civil status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital gain\",\n            \"Capital loss\", \"Work hours\/week\", \"Country\", \"Income\"]\ntrainData.columns = columns #nome das colunas\n\ntrainData.head(5)","a83791d9":"categoricalColumns = [\"Education\", \"Civil status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Country\", \"Income\"]\n\ntrainData.isna().sum()\n","6d25cee6":"import sklearn as sk\nimport matplotlib.pyplot as plt","7729fdf7":"analysesDf = trainData\nanalysesDf= analysesDf.groupby([\"fnlwgt\", \"Income\"]).size().unstack() #Agrupa entre essas duas colunas\nanalysesDf = analysesDf.sort_values(\"fnlwgt\", ascending = True)\nanalysesDf.plot(kind = \"density\", stacked = True, figsize = (15, 5))\nplt.show()\n","6a84e9b6":"trainData[\"fnlwgt\"].value_counts()","dfc636cb":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Age\", \"Income\"]).size().unstack()\nanalysesDf.sort_values(\"Age\", ascending = True)\nanalysesDf.plot(kind = \"bar\", figsize = (15, 5), title = \"Age\")\nplt.show()","d4b7d9a4":"trainData[\"Age\"].value_counts()","82db07c6":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Education.num\", \"Income\"]).size().unstack().sort_values(\"Education.num\")\nanalysesDf.plot(kind = \"bar\", title = \"Education number\")\nplt.show()\n","7351e1a9":"trainData[\"Education.num\"].value_counts()","fef65f2e":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Capital gain\", \"Income\"]).size().unstack().sort_values(\"Capital gain\")\nanalysesDf.plot(kind = \"bar\", title = \"Capital Gain\", figsize = (20, 5))\nplt.show()","749d4df9":"trainData[\"Capital gain\"].value_counts()","893a1997":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Capital loss\", \"Income\"]).size().unstack().sort_values(\"Capital loss\")\nanalysesDf.plot(kind = \"bar\", title = \"Capital Loss\", figsize = (20, 5))\nplt.show()","c27e02ec":"trainData[\"Capital loss\"].value_counts()","da4d8145":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Work hours\/week\", \"Income\"]).size().unstack().sort_values(\"Work hours\/week\")\nanalysesDf.plot(kind = \"bar\", title = \"Work hours\/week\", figsize = (20,5))\nplt.show()","e0110d13":"trainData[\"Work hours\/week\"].value_counts()","b174fbde":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Work class\", \"Income\"]).size().unstack()\nanalysesDf.plot(kind = \"bar\", title = \"Work class\", figsize = (15, 5))\nplt.show()","2e9e53fb":"trainData[\"Work class\"].value_counts()","522604f0":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Education\", \"Income\"]).size().unstack()\nanalysesDf.plot(kind = \"bar\", title = \"Education\", figsize = (20, 5))\nplt.show()","52bed145":"trainData[\"Education\"].value_counts()","6efccb61":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Civil status\", \"Income\"]).size().unstack()\nanalysesDf.plot(kind = \"bar\", title = \"Civil status\", figsize = (20, 5))\nplt.show()","26127e68":"trainData[\"Civil status\"].value_counts()","09da7c4a":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Occupation\", \"Income\"]).size().unstack()\nanalysesDf.plot(kind = \"bar\", title = \"Occupation\", figsize = (20, 5))\nplt.show()","4e486992":"trainData[\"Occupation\"].value_counts()","27591b77":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Relationship\", \"Income\"]).size().unstack()\nanalysesDf.plot(kind = \"bar\", title = \"Relationship\", figsize = (20, 5))\nplt.show()","dfa1d8eb":"trainData[\"Relationship\"].value_counts()","dd8864b3":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Race\", \"Income\"]).size().unstack()\nanalysesDf.plot(kind = \"bar\", title = \"Race\", figsize = (15, 5))\nplt.show()","4972464f":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Sex\", \"Income\"]).size().unstack()\nanalysesDf.plot(kind = \"bar\", title = \"Sex\", figsize = (20, 5))\nplt.show()","d2a3bea9":"trainData[\"Sex\"].value_counts()","22b05820":"analysesDf = trainData\nanalysesDf = analysesDf.groupby([\"Country\", \"Income\"]).size().unstack()\nanalysesDf.plot(kind = \"bar\", title = \"Country\", figsize = (15, 5))\nplt.show()","32974823":"trainData[\"Country\"].value_counts()","ae04dfcf":"trainData = trainData.drop(columns = [\"fnlwgt\", \"Education\"])\ntrainData = trainData.drop_duplicates()\n","1fdb229b":"trainData[\"Capital gain\"] = trainData[\"Capital gain\"] - trainData[\"Capital loss\"]\ntrainData = trainData.drop(columns = \"Capital loss\")\ntrainData = trainData.rename(columns = {\"Capital gain\": \"Capital\"})\ntrainData.head()","77ecdd81":"trainData.head()","b6dae39d":"income = trainData[\"Income\"]\ntrainData = trainData.drop(columns = \"Income\")","14e70281":"trainData = trainData.drop(columns = \"ID\")","02d818eb":"trainData.head()","5acd11aa":"categoricalColumns = [\"Work class\", \"Civil status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Country\"]\nnumericalColumns = [\"Age\", \"Education.num\", \"Capital\", \"Work hours\/week\"]","afabf5bd":"finalData = trainData[numericalColumns]\nfor col in categoricalColumns:\n    one_hot_encoding = pd.get_dummies(trainData[col], prefix = (col + '_'))\n    finalData = pd.concat([finalData, one_hot_encoding], axis = 1)\n\nfinalData.head()","99f48767":"finalData = finalData.drop(columns = \"Country__Holand-Netherlands\")","cf2e5560":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn import preprocessing","5bd20167":"x = finalData\ny = income\nk_values = [5, 10, 15, 30]\n\nfor k in k_values:\n    knn = KNeighborsClassifier(n_neighbors= k)\n    scores = cross_val_score(knn, x, y, cv = 5)\n    print(\"Scores para k = \", k)\n    print(scores)\n    print(\"Score medio: \", (scores.mean()))\n    print(50* \"-\")","93d83199":"knn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(x, y)","3ccf4bf0":"from sklearn import svm","d91fc841":"degrees = [3, 5]\nfor n in degrees:\n    svc = svm.SVC(degree = n)\n    scores = cross_val_score(svc, x, y, cv = 5)\n    print(\"Scores para n = \", n)\n    print(scores)\n    print(\"Score medio: \", (scores.mean()))\n    print(50* \"-\")\n","01f04379":"svc = svm.SVC(degree = 3)\nsvc.fit(x, y)","c6421f6d":"from sklearn.ensemble import RandomForestClassifier","31452f9e":"forestNumbers = [10, 25, 50, 100, 500]\nfor n in forestNumbers:\n    randomFrst = RandomForestClassifier(n_estimators = n, max_depth = 100)\n    scores = cross_val_score(randomFrst, x, y, cv = 5)\n    print(f\"Scores para {n} arvores\")\n    print(scores)\n    print(\"Score medio: \", (scores.mean()))\n    print(50* \"-\")\n","0f215077":"randomFrst = RandomForestClassifier(n_estimators = 50, max_depth = 100)\nrandomFrst.fit(x, y)","9f905b78":"from sklearn.naive_bayes import GaussianNB","c832ef30":"gNb = GaussianNB()\nscores = cross_val_score(gNb, x, y, cv = 5)\nprint(f\"Scores = {scores}\")\nprint(f\"Score medio = {scores.mean()}\")","3c5d5e75":"from sklearn.naive_bayes import BernoulliNB","e4916aaa":"bNb = BernoulliNB()\nscores = cross_val_score(bNb, x, y, cv = 5)\nprint(f\"Scores = {scores}\")\nprint(f\"Score medio = {scores.mean()}\")","2f77f5ea":"naiveBayes = gNb.fit(x, y)","418d9b9f":"from sklearn.neural_network import MLPClassifier","1e5d2903":"nn_c = MLPClassifier()\nscores = cross_val_score(nn_c, x, y, cv = 5)\nprint(f\"Scores = {scores}\")\nprint(f\"Score medio = {scores.mean()}\")","0db440b7":"nn_c.fit(x, y)","a27c79e1":"finalData.head()","244cf5a2":"testData = pd.read_csv(\"\/kaggle\/input\/adult-pmr3508\/test_data.csv\")\ntestData.columns = [\"ID\", \"Age\", \"Work class\", \"fnlwgt\", \"Education\", \"Education.num\",\n           \"Civil status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Capital gain\",\n            \"Capital loss\", \"Work hours\/week\", \"Country\"]\n\nID = testData.ID\ntestData = testData.dropna()\ntestData = testData.drop(columns = [\"ID\",\"fnlwgt\", \"Education\"])\ntestData[\"Capital gain\"] = testData[\"Capital gain\"] - testData[\"Capital loss\"]\ntestData = testData.rename(columns = {\"Capital gain\": \"Capital\"})\ntestData = testData.drop(columns = \"Capital loss\")\n\ntestData.head()","2ec457b3":"testData.loc[testData[\"Country\"] == \"Holand-netherlands\"]","a372f1ef":"categoricalColumns = [\"Work class\", \"Civil status\", \"Occupation\", \"Relationship\", \"Race\", \"Sex\", \"Country\"]","392f0c10":"finalTestData = testData[numericalColumns]\nfor col in categoricalColumns:\n    one_hot_encoding = pd.get_dummies(testData[col], prefix = (col + '_'))\n    finalTestData = pd.concat([finalTestData, one_hot_encoding], axis = 1)\n\nfinalTestData.head()","68d2d4fe":"knn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(x, y)\npredict = knn.predict(finalTestData)","bfb223c7":"submission = pd.DataFrame()\nsubmission[0] = ID\nsubmission[1] = predict\nsubmission.columns = ['Id', 'income']\nsubmission.head()","89b6df42":"submission.to_csv('submission.csv', index = False)","11bb5e12":"### Fnlwgt","0f56cf24":"### Capital Loss","44fbbf78":"### Race","3ea3fd68":"### Education","ffae84af":"### An\u00e1lise\nA partir da visualiza\u00e7\u00e3o dos dados \u00e9 poss\u00edvel tirar algumas conclus\u00f5es: \n* O final weight n\u00e3o aparenta possuir uma rela\u00e7\u00e3o direta com o sal\u00e1rio do indiv\u00edduo \n\n* Adultos na faixa dos 40~50 anos possuem mais tend\u00eancia a ganharem mais de 50K\n\n* Pessoas que trabalham no setor privado costumam ganhar mais \n\n* Quanto mais escolarizada a pessoa, maior o seu sal\u00e1rio\n\n* O sal\u00e1rio e o educatiom number s\u00e3o diretamente proporcionais\n\n* Pessoas casadas possuem mais tend\u00eancia a ganharem mais de 50K\n\n* Para a feature 'Relationship', h\u00e1 uma certa correla\u00e7\u00e3o, entretanto, ela est\u00e1 diretamente ligada ao estado civil e g\u00eanero do indiv\u00edduo\n\n* Pessoas que trabalham cerca de 40 horas por semana tendem a ganhar mais\n\n    * Entretanto, isso n\u00e3o ocorre de maneira linear.\n    * Horas de trabalho costumam ser a mesma independente do sal\u00e1rio\n* \u00c9 poss\u00edvel observar que as features *Work class*, *Occupation* e *Country* possuem observa\u00e7\u00f5es do tipo **?**\n\nDessa forma, irei remover a coluna 'fnlwgt' por n\u00e3o possuir uma rela\u00e7\u00e3o significante, al\u00e9m disso, irei remover a coluna 'Education' por ser correlacionada \u00e0 coluna 'Education.num', sendo que essa \u00faltima \u00e9 melhor por ser composta por n\u00fameros inteiros. \nAl\u00e9m disso, irei considerar que todas as observa\u00e7\u00f5es que apresentam **?** s\u00e3o equivalentes a \"*others*\", n\u00e3o como um dado faltante.\n\n","93e9e715":"#### 4.2 Bernoulli Naive Bayes","e94e96af":"### 1. KNN","f4beb0dd":"### 2. SVC (Support Vectors Classifier)","e666a6ca":"Portanto, \u00e9 poss\u00edvel observar que o grau da fun\u00e7\u00e3o polinomial referente ao nucleo n\u00e3o gera muita influencia no score do classificador, de forma que iremos fixar o mais simples.","61ecba4e":"Aparentemente, a base de teste n\u00e3o possui nenhum dado faltante","d45e64dc":"## Neural Network Classifier (nn_c)","9b42c13d":"Agora, iremos transformar as features categoricas em r\u00f3tulos numericos a partir do one hot encoding","6f11827c":"#### 4.1 Gaussian Naive Bayes","76c6a421":"### Occupation","d6ebb33e":"### Capital gain","303df446":"## 1.2 Data analyses","7add058c":"# Vendo o melhor classificador\nDiante dos dados e scores obtidos anteriormente, \u00e9 poss\u00edvel de se observar que o melhor classificador obtido foi o knn para k = 10 com um score medio de  0.853","fcdc1615":"### Education num","18e81fec":"## One Hot Encoding","d40a8469":"### Work Class","d3bdbecc":"### Civil Status","1b7298ff":"### Work hours\/week","c5967f5c":"trainData[\"Race\"].value_counts()","5451b74e":"1. KNN\n2. SVC\n3. Random Forest\n4. Naive Bayes\n5. Neural network classifier","e477589c":"## Classificadores","28f5b5f5":"### Relationship","80557989":"\u00c9 not\u00e1vel que esse classificador n\u00e3o foi uma boa escolha se comparado aos outros, mas, dentre os classificadores de Naive Bayes, o que apresentou melhor resultado foi o *Gaussian Naive Bayes*","347424cb":"### Sex","6c355c3b":"Dessa forma, \u00e9 poss\u00edvel observar que os melhores scores s\u00e3o para modelos com 50 e 500 arvores, mas por quest\u00f5es de otimiza\u00e7\u00e3o, irei fixar o modelo com 50 arvores.","b203b01e":"\u00c9 poss\u00edvel de se observar tamb\u00e9m que a coluna ID serve apenas para a identifica\u00e7\u00e3o da pessoa que possui os atributos, podendo ser retirada","4e95b1a3":"## 1.1 Data import","e7340164":"### Country","1f009315":"### 3. Random Forest","5db0f284":"# 1. Imports and Data preparation","f6cfaf7a":"# Submiss\u00e3o","4ddb4b6f":"### 4. Naive Bayes\n* Gaussian Naive Bayes\n* Bernoulli Naive Bayes","0e0141db":"### Age","9903361c":"# Base de teste","ca0e0f8a":"Dessa forma, \u00e9 poss\u00edvel de se ver por meio de cross validation que o valor com maior score foi para k = 10"}}