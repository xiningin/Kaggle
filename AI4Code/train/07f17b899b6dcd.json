{"cell_type":{"a6ced8ca":"code","ebe1094a":"code","7ef6fce8":"code","f3ddd7e6":"code","f880303b":"code","17789ecc":"code","72b3abb3":"code","93a8ac6d":"code","4616f2aa":"code","e4d7dd86":"code","8a14a3ee":"code","74b00505":"code","9c7948d0":"code","bbd13c4e":"code","ac8472fa":"code","df38275d":"code","021ed557":"code","edaab22e":"code","0e892e17":"code","074ca4a6":"code","7917d1bc":"code","7ce307ee":"code","67c29125":"code","543ab29e":"code","935c175d":"code","5b202e2d":"code","5d59db54":"code","0048c333":"code","9b11745b":"code","a5f259d5":"code","20d189ca":"markdown"},"source":{"a6ced8ca":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport keras\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set(style='darkgrid')\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils import to_categorical\nimport cv2 as cv\nfrom keras.layers import Dense, Conv2D, BatchNormalization, Activation\nfrom keras.layers import AveragePooling2D, Input, Flatten\nfrom keras.optimizers import Adam\nfrom keras.callbacks import ModelCheckpoint, LearningRateScheduler\nfrom keras.callbacks import ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.regularizers import l2\nfrom keras import backend as K\nfrom keras.models import Model\nimport cv2 \nfrom tqdm import tqdm\n\nimport os","ebe1094a":"traindf=pd.read_csv(\"\/kaggle\/input\/hackerearth-deep-learning-challenge-dance-forms\/train.csv\")\ntestdf=pd.read_csv(\"\/kaggle\/input\/hackerearth-deep-learning-challenge-dance-forms\/test.csv\")","7ef6fce8":"traindf.head()","f3ddd7e6":"testdf.head()","f880303b":"# to check any null values in the dataset\nfor col in traindf.columns:\n    if traindf[col].isnull().values.any():\n        print(f\"Train Dataset Feature - {col} contains {traindf[col].isna().sum()*100\/traindf[col].sum()}% of Null Values\")\n    \nfor col in testdf.columns:\n    if testdf[col].isnull().values.any():\n        print(f\"Test Dataset Feature - {col} contains {testdf[col].isna().sum()*100\/testdf[col].sum()}% of Null Values\")","17789ecc":"print(traindf[\"target\"].value_counts())\n\nsns.set_style('ticks')\nfig, ax = plt.subplots()\n# the size of A4 paper\nfig.set_size_inches(15, 4)\nsns.countplot(traindf[\"target\"],color='black')","72b3abb3":"train_path = '\/kaggle\/input\/hackerearth-deep-learning-challenge-dance-forms\/train\/'\n\npath = f'{train_path}'    \nfig = plt.figure(figsize = (13, 8))\nimage = cv.imread(path + f'\/362.jpg')\nplt.imshow(image[:, :, ::-1])\nplt.title(\"362.jpg\")\nplt.axis('off')\nplt.show()","93a8ac6d":"class_names =np.unique(traindf['target'])\nclass_names_label = {class_name:i for i, class_name in enumerate(class_names)}\n\nnb_classes = len(class_names)\nprint(class_names)","4616f2aa":"IMAGE_SIZE = (150, 150)\ndataset = train_path\noutput = []\ntrain_images = []\ntrain_labels = []\nfor files in tqdm(os.listdir(dataset)):\n    try:\n        label=class_names_label[traindf.loc[traindf['Image'] == files]['target'].values[0]]\n    except:\n        #do nothing\n        a=1\n    img_path=os.path.join(dataset, files)\n    # Open and resize the img\n    image = cv2.imread(img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, IMAGE_SIZE) \n    # Append the image and its corresponding label to the output\n    train_images.append(image)\n    train_labels.append(label)","e4d7dd86":"IMAGE_SIZE = (150, 150)\ndataset =  '\/kaggle\/input\/hackerearth-deep-learning-challenge-dance-forms\/test\/'\n\noutput = []\ntest_images = []\nfor files in tqdm(os.listdir(dataset)):\n    img_path=os.path.join(dataset, files)\n    # Open and resize the img\n    image = cv2.imread(img_path)\n    image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n    image = cv2.resize(image, IMAGE_SIZE) \n    # Append the image and its corresponding label to the output\n    test_images.append(image)","8a14a3ee":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    plt.xlabel(class_names[train_labels[i]])\nplt.show()","74b00505":"train_images = np.array(train_images, dtype = 'float32')\ntest_images = np.array(test_images, dtype = 'float32')\ntrain_labels = np.array(train_labels, dtype = 'int32')   ","9c7948d0":"from sklearn.model_selection import train_test_split\nx_train,x_val,y_train,y_val=train_test_split(train_images,train_labels,test_size=0.3)","bbd13c4e":"# Normalize data.\nx_train = x_train.astype('float32') \/ 255\nx_test = test_images.astype('float32') \/ 255","ac8472fa":"y_train = keras.utils.to_categorical(y_train, len(class_names))\ny_val = keras.utils.to_categorical(y_val, len(class_names))","df38275d":"print('x_train shape:', x_train.shape)\nprint('y_train shape:', y_train.shape)\nprint('x_val shape:', x_val.shape)\nprint('y_val shape:', y_val.shape)","021ed557":"datagen = ImageDataGenerator(\n    featurewise_center=True,\n    featurewise_std_normalization=True,\n    rotation_range=20,\n    width_shift_range=0.2,\n    height_shift_range=0.2,\n    horizontal_flip=True)","edaab22e":"datagen.fit(x_train)","0e892e17":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D, Flatten, Dense,MaxPooling2D,Dropout\nfrom tensorflow.keras.callbacks import EarlyStopping,ModelCheckpoint\nimport tensorflow as tf\n\nimage_size = x_train.shape[1]\ninputshape = (image_size, image_size, 3)\nbatchsize = 128\nkernel_size = 3\npool_size = 3\nfilters = 64\ndropout = 0.2\nepochs=50\n\nmodel = Sequential([\n        Conv2D(filters=filters, input_shape=inputshape, kernel_size=kernel_size,activation='relu', name='conv_1'),\n        MaxPooling2D(pool_size=(4, 4), name='pool_1'),\n        Dropout(dropout),\n        Conv2D(filters=64, kernel_size=kernel_size, activation='relu', name='conv_2'),\n        MaxPooling2D(pool_size=(4, 4), name='pool_2'),\n        Dropout(dropout),\n        Flatten(name='flatten'),\n        Dense(units=256, activation='relu', name='dense_1'),\n        Dense(units=8, activation='softmax', name='dense_2')\n    ])","074ca4a6":"model.summary()","7917d1bc":"model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy','mae'])\nearly_stopping_callback = EarlyStopping(monitor='val_loss')\nmodel_name=\"Conv2D_basic\"\ncheckpoint_callback = ModelCheckpoint(model_name+'.h5', monitor='val_loss', verbose=1, save_best_only=True, mode='min')\nhistory=model.fit(datagen.flow(x_train, y_train, batch_size=batchsize), epochs=epochs, callbacks=[early_stopping_callback, checkpoint_callback],validation_data=(x_val, y_val))","7ce307ee":"df=pd.DataFrame(history.history)\ndf.head()","67c29125":"loss_plot=df.plot(y=\"loss\",title=\"Loss vs Epoch\")\nloss_plot.set(xlabel=\"Epoch\",ylabel=\"Loss\")","543ab29e":"loss,accuracy,mae=model.evaluate(x_val,y_val)\nprint(loss)\nprint(accuracy*100)\nprint(mae)","935c175d":"pred=model.predict(x_test)","5b202e2d":"prediction=np.argmax(pred, axis = 1)","5d59db54":"prediction","0048c333":"data = pd.DataFrame(prediction,columns=[\"values\"])","9b11745b":"\ndow = {\n    0:\"bharatanatyam\",\n    1:\"kathak\",\n    2:\"kathakali\",\n    3:\"kuchipudi\", \n    4:\"manipuri\", \n    5:\"mohiniyattam\", \n    6:\"odissi\",\n    7:\"sattriya\"\n}\n\ndata[\"dow\"] = data['values'].map(dow)","a5f259d5":"ImageName = np.array(testdf[\"Image\"])\nprediction = np.array(data[\"dow\"])\nsubmission_dataset = pd.DataFrame({'Image': ImageName, 'target': prediction}, columns=['Image', 'target'])\nsubmission_dataset.to_csv('submission_Initial.csv', header=True, index=False) ","20d189ca":"* \/kaggle\/input\/hackerearth-deep-learning-challenge-dance-forms\/train.csv\n* \/kaggle\/input\/hackerearth-deep-learning-challenge-dance-forms\/test.csv\n* \/kaggle\/input\/hackerearth-deep-learning-challenge-dance-forms\/train\/322.jpg"}}