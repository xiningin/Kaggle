{"cell_type":{"ffe1186a":"code","8903be78":"code","bada9640":"code","bf72d257":"code","32db990c":"code","da0122e8":"code","b1c76d94":"code","a817ddc9":"code","b478b425":"code","3c2a2dff":"code","a58f1de9":"code","cf53709e":"code","66cc3164":"code","e60525ba":"code","47fbdc34":"code","c38d3775":"code","34e603e5":"code","c608a164":"code","42c86bcd":"code","8ca11034":"code","615fc955":"code","141dc28c":"code","72f09942":"code","6fbe8e07":"code","431bd357":"code","e1eb1943":"code","690fe66c":"code","d41156d8":"code","ee0556dd":"code","64b449ab":"code","92cf7be8":"code","e5f4d407":"code","c60abcf4":"code","04a29153":"code","4f4ad2ff":"code","66c9d91d":"code","3327d121":"code","4e9fa4d5":"code","17a16a03":"code","081698e5":"code","9dcb8077":"code","67d00c1b":"code","11fd7843":"code","0ffa4cc6":"code","ac8567c0":"code","1c732af7":"code","af3eb586":"code","fa79240c":"code","a8f563e6":"code","3b660130":"code","05dfc6d6":"code","b45eb7a1":"code","b273b8c3":"code","e3457213":"code","32e55a29":"code","6e482a07":"code","c00aebe1":"code","cce80583":"code","63ee9e09":"code","8e0c8eec":"code","5c8a1d1b":"code","123a9247":"code","ab00ec3a":"code","4d87ea49":"code","0f4fc0b5":"code","70ce0995":"code","2a4c9276":"code","11dcd61a":"code","c18d6f73":"code","1e5bc2a0":"code","a89c053b":"code","15c3b682":"code","863668f4":"code","af19cebb":"code","53634fba":"code","f9490209":"code","d9919226":"code","1ae0acb2":"code","9e458867":"code","6f53db0a":"code","d4bef3e1":"code","5b477d06":"code","c993cc2d":"code","07f51685":"code","614a0279":"code","713f2b40":"code","7d57eec5":"code","7d87219e":"code","bca5f254":"code","367648b5":"code","d28cba51":"code","8bb22e3e":"code","bb8be45c":"code","4b920bee":"code","bdcf9bc6":"code","4e337998":"code","f619a6da":"code","df2f37cd":"code","52acd135":"code","688b900b":"code","e6e84980":"code","a7d85497":"code","ccd120ef":"code","c79f229c":"code","82b91561":"code","fc8a7d38":"code","0f269b4d":"code","27f9fb52":"code","ce82e77f":"code","a0889d52":"code","427f79a8":"code","ce3b22a5":"code","395e36d1":"code","c7605870":"code","4d5f1b61":"code","d21730f8":"markdown","54f8452b":"markdown","3e5ea5bd":"markdown","00382a6d":"markdown","48b0b6af":"markdown","f4c3c142":"markdown","37a6389b":"markdown","aff037d4":"markdown","5fcb48d9":"markdown","7b8fbb5c":"markdown","ef087d12":"markdown","d27b64cc":"markdown","99c0c141":"markdown","003f5ffb":"markdown","5624b93c":"markdown","1bbfd7e5":"markdown","f4008079":"markdown","a6e327e5":"markdown","2984857e":"markdown","f93db495":"markdown","423e7e89":"markdown","fb089caa":"markdown","7ba510d9":"markdown","f89c28d3":"markdown","38e99116":"markdown","eea88214":"markdown","6171a850":"markdown","29eff7f2":"markdown","58404a6a":"markdown","0b3d0728":"markdown","a24429b0":"markdown","dbe23dc6":"markdown","f90ef1f7":"markdown","ca6ce1c1":"markdown","07c4b2b0":"markdown","8605c187":"markdown","ca0c0668":"markdown","0ecff947":"markdown","cfc26328":"markdown","05effdd2":"markdown","4cad4a76":"markdown","9e6a6d52":"markdown","fd8c8033":"markdown","da69eba2":"markdown","7e34cab5":"markdown","f5072319":"markdown","8e7037fd":"markdown","82e554a7":"markdown","7ba4cb07":"markdown","6ab90a84":"markdown","e15e2645":"markdown","c1348a67":"markdown","4194b163":"markdown","3a3830aa":"markdown","e4d54bc1":"markdown","92fd4867":"markdown","93cdbbbb":"markdown","2f0362b0":"markdown","9d98c2f6":"markdown","45263d0c":"markdown","10863996":"markdown","f89c2ab7":"markdown","3ce9193e":"markdown","336e45c4":"markdown","1b7019a2":"markdown","14f672cc":"markdown","9d8dcd07":"markdown","87eb04b0":"markdown","104eff82":"markdown","bc2e7d36":"markdown","1c2f359d":"markdown","abe970fa":"markdown","5d757cea":"markdown","48b10887":"markdown","65420731":"markdown","2ffff3e5":"markdown","2599db17":"markdown","765a8175":"markdown","6fb28022":"markdown","086a184d":"markdown","1c2b9386":"markdown","c61e0dd5":"markdown","ceabdad4":"markdown","291271b1":"markdown","187e274b":"markdown","9c0ee86f":"markdown","c32b2f0b":"markdown","1cab34e0":"markdown","85fb30e7":"markdown","e604fde2":"markdown","d4e9344b":"markdown","7924b5f7":"markdown","4c620259":"markdown","00b0ab38":"markdown","68c4c02a":"markdown","ff797367":"markdown","e26792f5":"markdown","de9f5c59":"markdown","776462b2":"markdown","2c26ba12":"markdown","216f0528":"markdown","eece0c0e":"markdown","b757e17b":"markdown","5057d1ba":"markdown","50736a4b":"markdown","44a03bd2":"markdown","d25b78c4":"markdown","17210bdd":"markdown","41ff8d76":"markdown","5c2eb4d5":"markdown","043468cf":"markdown","1917388b":"markdown","17c90694":"markdown","cb0871c9":"markdown","885e64ae":"markdown","8d9bf2e6":"markdown","c48ab95a":"markdown","a4355792":"markdown","3902c41a":"markdown","c18292b5":"markdown","e3f1b9e3":"markdown","37dd7c75":"markdown","d0c5ca1b":"markdown","5b48da3d":"markdown","3740b1ef":"markdown","bf244815":"markdown","0818cebe":"markdown","d7878862":"markdown","478ab68d":"markdown","3872106d":"markdown","9ea52b7a":"markdown","7d42666b":"markdown","3e55882b":"markdown","d8571210":"markdown","9f68014a":"markdown","1acb4d4f":"markdown","577be540":"markdown","0c58e7ef":"markdown","6bad8595":"markdown","2bb64325":"markdown","aca68819":"markdown","def8df62":"markdown","4db85dba":"markdown","c63ab00a":"markdown","9bc32bed":"markdown","7cd133e3":"markdown","277caa18":"markdown","700229ac":"markdown","0210e72d":"markdown","467b9ed6":"markdown","47b0632f":"markdown","f8cadd7c":"markdown","6f658252":"markdown","2506d1ff":"markdown","0a6c0a73":"markdown","697ef3d1":"markdown","a7df335d":"markdown","e432cb58":"markdown","492c164f":"markdown","02f53e89":"markdown","815a2e7f":"markdown","bd9b6074":"markdown","1c42b225":"markdown","61bb66de":"markdown","4a8e8eff":"markdown","647fd893":"markdown","58e68afe":"markdown","49177b50":"markdown","eaa2c67e":"markdown","e1064a8c":"markdown","4d5f8cc5":"markdown","3c9a3aee":"markdown"},"source":{"ffe1186a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, SV file I\/O (e.g. pd.read_csv)\nimport matplotlib as mpl\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport statsmodels.api as sm\nfrom statsmodels.graphics.mosaicplot import mosaic\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.models import Sequential\nfrom keras.layers.core import Dense\nfrom keras.layers import Dropout\nfrom keras.optimizers import Adam","8903be78":"dataframe = pd.read_csv(\"\/kaggle\/input\/ibm-hr-analytics-attrition-dataset\/WA_Fn-UseC_-HR-Employee-Attrition.csv\")","bada9640":"dataframe.head()","bf72d257":"dataframe.columns.values","32db990c":"dataframe.describe()","da0122e8":"dataframe.info()","b1c76d94":"dataframe['Attrition'].value_counts()","a817ddc9":"labels = 'No', 'Yes'\nsizes = [1233, 237]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","b478b425":"dataframe[\"Attrition_dummy\"] = dataframe[\"Attrition\"]\ndataframe.loc[dataframe[\"Attrition\"]==\"Yes\", [\"Attrition_dummy\"]] = 1\ndataframe.loc[dataframe[\"Attrition\"]==\"No\", [\"Attrition_dummy\"]] = 0\ndataframe[\"Attrition_dummy\"] = dataframe[\"Attrition_dummy\"].astype(int)","3c2a2dff":"age_label = [\"~19\", \"20~24\", \"25~29\", \"30~34\", \"35~39\", \"40~44\", \"45~49\", \"50~54\", \"55~59\"]\nage_cate = pd.cut(x=dataframe['Age'], bins=[18, 20, 25, 30, 35, 40, 45, 50, 55, 60], labels=age_label)\ndataframe['age_cate'] = age_cate\nage_frame = dataframe['age_cate'].value_counts().to_frame().sort_index()\nage_frame.index.name = \"age\"\nage_frame[\"num\"] = age_frame[\"age_cate\"]\ndel age_frame[\"age_cate\"]\nage_frame","a58f1de9":"dataframe[\"Age\"].hist(bins=9, grid=False)\nplt.rcParams['font.size'] = 12","cf53709e":"plt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"Age\", data=dataframe)","66cc3164":"feature_Age = dataframe[['Age']]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_Age, test_feature_Age, train_labels, test_labels = train_test_split(feature_Age, attrition)\n\nscaler = StandardScaler()\ntrain_feature_Age = scaler.fit_transform(train_feature_Age)\ntest_feature_Age = scaler.transform(test_feature_Age)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_Age, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_Age, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_Age, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","e60525ba":"dataframe['Gender'].value_counts().to_frame()","47fbdc34":"labels = 'Male', 'Female'\nsizes = [882, 588]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","c38d3775":"group = dataframe.groupby([\"Gender\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","34e603e5":"# data conservation for logistic regression\ndataframe[\"Gender_dummy\"] = dataframe[\"Gender\"]\ndataframe.loc[dataframe[\"Gender\"]==\"Male\", [\"Gender_dummy\"]] = 1\ndataframe.loc[dataframe[\"Gender\"]==\"Female\", [\"Gender_dummy\"]] = 0\ndataframe[\"Gender_dummy\"] = dataframe[\"Gender_dummy\"].astype(int)","c608a164":"feature_Gender = dataframe[['Gender_dummy']]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_Gender, test_feature_Gender, train_labels, test_labels = train_test_split(feature_Gender, attrition)\n\nscaler = StandardScaler()\ntrain_feature_Gender = scaler.fit_transform(train_feature_Gender)\ntest_feature_Gender = scaler.transform(test_feature_Gender)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_Gender, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_Gender, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_Gender, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","42c86bcd":"dataframe['MaritalStatus'].value_counts().to_frame()","8ca11034":"labels = 'Married', 'Single', 'Divorced'\nsizes = [673, 470, 327]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","615fc955":"group = dataframe.groupby([\"MaritalStatus\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 20\nmosaic(group[\"EmployeeCount\"])\nplt.show()","141dc28c":"# data conservation for logistic regression\ndataframe[\"Marital_Single_dummy\"] = dataframe[\"MaritalStatus\"]\ndataframe.loc[dataframe[\"MaritalStatus\"]==\"Single\", [\"Marital_Single_dummy\"]] = 1\ndataframe.loc[dataframe[\"MaritalStatus\"]==\"Married\", [\"Marital_Single_dummy\"]] = 0\ndataframe.loc[dataframe[\"MaritalStatus\"]==\"Divorced\", [\"Marital_Single_dummy\"]] = 0\ndataframe[\"Marital_Single_dummy\"] = dataframe[\"Marital_Single_dummy\"].astype(int)\n\ndataframe[\"Marital_Married_dummy\"] = dataframe[\"MaritalStatus\"]\ndataframe.loc[dataframe[\"MaritalStatus\"]==\"Married\", [\"Marital_Married_dummy\"]] = 1\ndataframe.loc[dataframe[\"MaritalStatus\"]==\"Divorced\", [\"Marital_Married_dummy\"]] = 0\ndataframe.loc[dataframe[\"MaritalStatus\"]==\"Single\", [\"Marital_Married_dummy\"]] = 0\ndataframe[\"Marital_Married_dummy\"] = dataframe[\"Marital_Married_dummy\"].astype(int)","72f09942":"feature_MarritalStatus = dataframe[[\"Marital_Single_dummy\", \"Marital_Married_dummy\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_MarritalStatus, test_feature_MarritalStatus, train_labels, test_labels = train_test_split(feature_MarritalStatus, attrition)\n\nscaler = StandardScaler()\ntrain_feature_MarritalStatus = scaler.fit_transform(train_feature_MarritalStatus)\ntest_feature_MarritalStatus = scaler.transform(test_feature_MarritalStatus)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_MarritalStatus, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_MarritalStatus, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_MarritalStatus, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0].round(3))","6fbe8e07":"education_frame_tmp = dataframe['Education'].value_counts().to_frame().sort_index()\neducation_frame_tmp.index.name = 'response'\neducation_frame_tmp[\"num\"] = education_frame_tmp[\"Education\"]\ndel education_frame_tmp[\"Education\"]\neducation_frame_tmp[\"Education Level\"] = ['Below College', 'College', 'Bachelor', 'Master', 'Doctor']\ncols = [\"Education Level\", \"num\"]\neducation_frame = pd.DataFrame(education_frame_tmp, columns=cols)\n\neducation_frame","431bd357":"labels = 'Below College', 'College', 'Bachelor', 'Master', 'Doctor'\nsizes = [170, 282, 572, 398, 48]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","e1eb1943":"educationframe = dataframe[[\"Education\", \"Attrition\",\"EmployeeCount\"]]\neducationframe.loc[educationframe[\"Education\"]==1, [\"Education\"]] = '1.Below College'\neducationframe.loc[educationframe[\"Education\"]==2, [\"Education\"]] = '2.College'\neducationframe.loc[educationframe[\"Education\"]==3, [\"Education\"]] = '3.Bachelor'\neducationframe.loc[educationframe[\"Education\"]==4, [\"Education\"]] = '4.Master'\neducationframe.loc[educationframe[\"Education\"]==5, [\"Education\"]] = '5.Doctor'\n\ngroup = educationframe.groupby([\"Education\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","690fe66c":"feature_Education = dataframe[[\"Education\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_Education, test_feature_Education, train_labels, test_labels = train_test_split(feature_Education, attrition)\n\nscaler = StandardScaler()\ntrain_feature_Education = scaler.fit_transform(train_feature_Education)\ntest_feature_Education = scaler.transform(test_feature_Education)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_Education, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_Education, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_Education, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","d41156d8":"dataframe[\"DistanceFromHome\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","ee0556dd":"plt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"DistanceFromHome\", data=dataframe)","64b449ab":"feature_DistanceFromHome = dataframe[[\"DistanceFromHome\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_DistanceFromHome, test_feature_DistanceFromHome, train_labels, test_labels = train_test_split(feature_DistanceFromHome, attrition)\n\nscaler = StandardScaler()\ntrain_feature_DistanceFromHome = scaler.fit_transform(train_feature_DistanceFromHome)\ntest_feature_DistanceFromHome = scaler.transform(test_feature_DistanceFromHome)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_DistanceFromHome, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_DistanceFromHome, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_DistanceFromHome, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","92cf7be8":"dataframe[\"Department\"].value_counts().to_frame()","e5f4d407":"labels = 'Research & Development', 'Sales', 'Human Resources'\nsizes = [961, 446, 63]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","c60abcf4":"group = dataframe.groupby([\"Department\", \"Attrition\"]).sum()\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","04a29153":"# data conservation for logistic regression\ndataframe[\"Department_HR_dummy\"] = dataframe[\"Department\"]\ndataframe.loc[dataframe[\"Department\"]==\"Human Resources\", [\"Department_HR_dummy\"]] = 1\ndataframe.loc[dataframe[\"Department\"]==\"Research & Development\", [\"Department_HR_dummy\"]] = 0\ndataframe.loc[dataframe[\"Department\"]==\"Sales\", [\"Department_HR_dummy\"]] = 0\ndataframe[\"Department_HR_dummy\"] = dataframe[\"Department_HR_dummy\"].astype(int)\n\ndataframe[\"Department_Sales_dummy\"] = dataframe[\"Department\"]\ndataframe.loc[dataframe[\"Department\"]==\"Sales\", [\"Department_Sales_dummy\"]] = 1\ndataframe.loc[dataframe[\"Department\"]==\"Research & Development\", [\"Department_Sales_dummy\"]] = 0\ndataframe.loc[dataframe[\"Department\"]==\"Human Resources\", [\"Department_Sales_dummy\"]] = 0\ndataframe[\"Department_HR_dummy\"] = dataframe[\"Department_HR_dummy\"].astype(int)","4f4ad2ff":"feature_Department = dataframe[[\"Department_HR_dummy\", \"Department_Sales_dummy\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_Department, test_feature_Department, train_labels, test_labels = train_test_split(feature_Department, attrition)\n\nscaler = StandardScaler()\ntrain_feature_Department = scaler.fit_transform(train_feature_Department)\ntest_feature_Department = scaler.transform(test_feature_Department)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_Department, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_Department, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_Department, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3), model.coef_[0][1].round(3))","66c9d91d":"dataframe[\"JobRole\"].value_counts().to_frame()","3327d121":"plt.rcParams[\"figure.figsize\"]=(5, 5)\nplt.rcParams['font.size'] = 12\ndataframe[\"JobRole\"].value_counts().to_frame().plot(kind=\"barh\")","4e9fa4d5":"dataframe[\"JobLevel\"].value_counts().to_frame()","17a16a03":"labels = 'Level 1', 'Level 2', 'Level 3', 'Level 4', 'Level 5'\nsizes = [543, 534, 218, 106, 69]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","081698e5":"datafrmae_roleandlevel = dataframe.groupby([\"JobRole\", \"JobLevel\"])[\"EmployeeCount\"].sum().unstack().fillna(0).\\\nsort_values(by=[5, 4, 3, 2, 1], ascending = False)\ndatafrmae_roleandlevel","9dcb8077":"plt.rcParams[\"figure.figsize\"]=(6, 7)\nplt.rcParams['font.size'] = 14\ndatafrmae_roleandlevel.plot(kind=\"barh\", stacked = True)","67d00c1b":"group = dataframe.groupby([\"JobLevel\", \"Attrition\"]).sum()\nplt.rcParams[\"figure.figsize\"]=(12, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","11fd7843":"feature_JobLevel = dataframe[[\"JobLevel\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_JobLevel, test_feature_JobLevel, train_labels, test_labels = train_test_split(feature_JobLevel, attrition)\n\nscaler = StandardScaler()\ntrain_feature_JobLevel = scaler.fit_transform(train_feature_JobLevel)\ntest_feature_JobLevel = scaler.transform(test_feature_JobLevel)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_JobLevel, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_JobLevel, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_JobLevel, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","0ffa4cc6":"dataframe[\"YearsAtCompany\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","ac8567c0":"plt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"YearsAtCompany\", data=dataframe)","1c732af7":"feature_YearsAtCompany = dataframe[[\"YearsAtCompany\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_YearsAtCompany, test_feature_YearsAtCompany, train_labels, test_labels = train_test_split(feature_YearsAtCompany, attrition)\n\nscaler = StandardScaler()\ntrain_feature_YearsAtCompany = scaler.fit_transform(train_feature_YearsAtCompany)\ntest_feature_YearsAtCompany = scaler.transform(test_feature_YearsAtCompany)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_YearsAtCompany, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_YearsAtCompany, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_YearsAtCompany, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","af3eb586":"dataframe[\"NumCompaniesWorked\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","fa79240c":"plt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"NumCompaniesWorked\", data=dataframe)","a8f563e6":"feature_NumCompanies = dataframe[[\"NumCompaniesWorked\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_NumCompanies, test_feature_NumCompanies, train_labels, test_labels = \\\ntrain_test_split(feature_NumCompanies, attrition)\n\nscaler = StandardScaler()\ntrain_feature_NumCompanies = scaler.fit_transform(train_feature_NumCompanies)\ntest_feature_NumCompanies = scaler.transform(test_feature_NumCompanies)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_NumCompanies, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_NumCompanies, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_NumCompanies, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","3b660130":"dataframe[\"TotalWorkingYears\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","05dfc6d6":"plt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"TotalWorkingYears\", data=dataframe)","b45eb7a1":"feature_TotalWorkingYears = dataframe[[\"TotalWorkingYears\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_TotalWorkingYears, test_feature_TotalWorkingYears, train_labels, test_labels =\\\ntrain_test_split(feature_TotalWorkingYears, attrition)\n\nscaler = StandardScaler()\ntrain_feature_TotalWorkingYears = scaler.fit_transform(train_feature_TotalWorkingYears)\ntest_feature_TotalWorkingYears = scaler.transform(test_feature_TotalWorkingYears)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_TotalWorkingYears, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_TotalWorkingYears, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_TotalWorkingYears, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","b273b8c3":"dataframe[\"AvgWorkingYears\"] = dataframe[\"TotalWorkingYears\"]\/dataframe[\"NumCompaniesWorked\"]\ndataframe.loc[dataframe[\"NumCompaniesWorked\"] == 0, \"AvgWorkingYears\"] = None\ndataframe[\"AvgWorkingYears\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","e3457213":"sns.boxplot(x=\"Attrition\", y=\"AvgWorkingYears\", data=dataframe)","32e55a29":"ContinuWorkerYearsMean = dataframe.loc[dataframe[\"NumCompaniesWorked\"] == 0, \"YearsAtCompany\"].mean()\ndataframe.loc[dataframe[\"NumCompaniesWorked\"] == 0, \"AvgWorkingYears\"] = ContinuWorkerYearsMean","6e482a07":"feature_AvgWorkingYears = dataframe[[\"AvgWorkingYears\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_AvgWorkingYears, test_feature_AvgWorkingYears, train_labels, test_labels = train_test_split(feature_AvgWorkingYears, attrition)\n\nscaler = StandardScaler()\ntrain_feature_AvgWorkingYears = scaler.fit_transform(train_feature_AvgWorkingYears)\ntest_feature_AvgWorkingYears = scaler.transform(test_feature_AvgWorkingYears)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_AvgWorkingYears, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_AvgWorkingYears, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_AvgWorkingYears, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","c00aebe1":"dataframe[\"MonthlyIncome\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","cce80583":"plt.rcParams[\"figure.figsize\"]=(6, 4)\nplt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"MonthlyIncome\", data=dataframe)","63ee9e09":"feature_MonthlyIncome = dataframe[[\"MonthlyIncome\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_MonthlyIncome, test_feature_MonthlyIncome, train_labels, test_labels =\\\ntrain_test_split(feature_MonthlyIncome, attrition)\n\nscaler = StandardScaler()\ntrain_feature_MonthlyIncome = scaler.fit_transform(train_feature_MonthlyIncome)\ntest_feature_MonthlyIncome = scaler.transform(test_feature_MonthlyIncome)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_MonthlyIncome, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_MonthlyIncome, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_MonthlyIncome, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","8e0c8eec":"dataframe['StockOptionLevel'].value_counts().to_frame()","5c8a1d1b":"labels = 'Level 0', 'Level 1', 'Level 2', 'Level 3'\nsizes = [631, 596, 158, 85]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","123a9247":"group = dataframe.groupby([\"StockOptionLevel\", \"Attrition\"]).sum()\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","ab00ec3a":"feature_StockOptionLevel = dataframe[[\"StockOptionLevel\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_StockOptionLevel, test_feature_StockOptionLevel, train_labels, test_labels =\\\ntrain_test_split(feature_StockOptionLevel, attrition)\n\nscaler = StandardScaler()\ntrain_feature_StockOptionLevel = scaler.fit_transform(train_feature_StockOptionLevel)\ntest_feature_StockOptionLevel = scaler.transform(test_feature_StockOptionLevel)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_StockOptionLevel, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_StockOptionLevel, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_StockOptionLevel, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","4d87ea49":"dataframe[\"PercentSalaryHike\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","0f4fc0b5":"plt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"PercentSalaryHike\", data=dataframe)","70ce0995":"feature_PercentSalaryHike = dataframe[[\"PercentSalaryHike\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_PercentSalaryHike, test_feature_PercentSalaryHike, train_labels, test_labels =\\\ntrain_test_split(feature_PercentSalaryHike, attrition)\n\nscaler = StandardScaler()\ntrain_feature_PercentSalaryHike = scaler.fit_transform(train_feature_PercentSalaryHike)\ntest_feature_PercentSalaryHike = scaler.transform(test_feature_PercentSalaryHike)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_PercentSalaryHike, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_PercentSalaryHike, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_PercentSalaryHike, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","2a4c9276":"dataframe[\"PerformanceRating\"].value_counts().to_frame()","11dcd61a":"labels = \"3\", \"4\"\nsizes = [1244, 226]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","c18d6f73":"performanceframe = dataframe[[\"PerformanceRating\", \"Attrition\",\"EmployeeCount\"]]\nperformanceframe.loc[performanceframe[\"PerformanceRating\"]==1, [\"PerformanceRating\"]] = '1.Low'\nperformanceframe.loc[performanceframe[\"PerformanceRating\"]==2, [\"PerformanceRating\"]] = '2.Medium'\nperformanceframe.loc[performanceframe[\"PerformanceRating\"]==3, [\"PerformanceRating\"]] = '3.High'\nperformanceframe.loc[performanceframe[\"PerformanceRating\"]==4, [\"PerformanceRating\"]] = '4.Very High'\n\ngroup = performanceframe.groupby([\"PerformanceRating\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(6, 4)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","1e5bc2a0":"feature_PerformanceRating = dataframe[[\"PerformanceRating\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_PerformanceRating, test_feature_PerformanceRating, train_labels, test_labels =\\\ntrain_test_split(feature_PerformanceRating, attrition)\n\nscaler = StandardScaler()\ntrain_feature_PerformanceRating = scaler.fit_transform(train_feature_PerformanceRating)\ntest_feature_PerformanceRating = scaler.transform(test_feature_PerformanceRating)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_PerformanceRating, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_PerformanceRating, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_PerformanceRating, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","a89c053b":"dataframe[\"YearsSinceLastPromotion\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","15c3b682":"plt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"YearsSinceLastPromotion\", data=dataframe)","863668f4":"feature_YearsSinceLastPromotion = dataframe[[\"YearsSinceLastPromotion\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_YearsSinceLastPromotion, test_feature_YearsSinceLastPromotion, train_labels, test_labels =\\\ntrain_test_split(feature_YearsSinceLastPromotion, attrition)\n\nscaler = StandardScaler()\ntrain_feature_YearsSinceLastPromotion = scaler.fit_transform(train_feature_YearsSinceLastPromotion)\ntest_feature_YearsSinceLastPromotion = scaler.transform(test_feature_YearsSinceLastPromotion)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_YearsSinceLastPromotion, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_YearsSinceLastPromotion, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_YearsSinceLastPromotion, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","af19cebb":"involvemnet_frame = dataframe['JobInvolvement'].value_counts().to_frame().sort_index()\ninvolvemnet_frame.index.name = 'response_num'\ninvolvemnet_frame[\"num\"] = involvemnet_frame[\"JobInvolvement\"]\ndel involvemnet_frame[\"JobInvolvement\"]\ninvolvemnet_frame[\"response\"] = [\"Low\", \"Medium\", \"High\", \"Very High\"]\ncols = [\"response\", \"num\"]\ninvolvemnet_frame = pd.DataFrame(involvemnet_frame, columns = cols)\ninvolvemnet_frame","53634fba":"labels = \"Low\", \"Medium\", \"High\", \"Very High\"\nsizes = [83, 375, 868, 144]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","f9490209":"jobinvolveframe = dataframe[[\"JobInvolvement\", \"Attrition\",\"EmployeeCount\"]]\njobinvolveframe.loc[jobinvolveframe[\"JobInvolvement\"]==1, [\"JobInvolvement\"]] = '1.Low'\njobinvolveframe.loc[jobinvolveframe[\"JobInvolvement\"]==2, [\"JobInvolvement\"]] = '2.Medium'\njobinvolveframe.loc[jobinvolveframe[\"JobInvolvement\"]==3, [\"JobInvolvement\"]] = '3.High'\njobinvolveframe.loc[jobinvolveframe[\"JobInvolvement\"]==4, [\"JobInvolvement\"]] = '4.Very High'\n\ngroup = jobinvolveframe.groupby([\"JobInvolvement\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","d9919226":"feature_JobInvolvement = dataframe[[\"JobInvolvement\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_JobInvolvement, test_feature_JobInvolvement, train_labels, test_labels = train_test_split(feature_JobInvolvement, attrition)\n\nscaler = StandardScaler()\ntrain_feature_JobInvolvement = scaler.fit_transform(train_feature_JobInvolvement)\ntest_feature_JobInvolvement = scaler.transform(test_feature_JobInvolvement)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_JobInvolvement, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_JobInvolvement, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_JobInvolvement, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","1ae0acb2":"jobsatisfaction_frame = dataframe['JobSatisfaction'].value_counts().to_frame().sort_index()\njobsatisfaction_frame.index.name = 'response_num'\njobsatisfaction_frame[\"num\"] = jobsatisfaction_frame[\"JobSatisfaction\"]\ndel jobsatisfaction_frame[\"JobSatisfaction\"]\njobsatisfaction_frame[\"response\"] = [\"Low\", \"Medium\", \"High\", \"Very High\"]\ncols = [\"response\", \"num\"]\njobsatisfaction_frame = pd.DataFrame(jobsatisfaction_frame, columns = cols)\njobsatisfaction_frame","9e458867":"labels = \"Low\", \"Medium\", \"High\", \"Very High\"\nsizes = [289, 280, 442, 459]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","6f53db0a":"JobSatisfactionframe = dataframe[[\"JobSatisfaction\", \"Attrition\",\"EmployeeCount\"]]\nJobSatisfactionframe.loc[JobSatisfactionframe[\"JobSatisfaction\"]==1, [\"JobSatisfaction\"]] = '1.Low'\nJobSatisfactionframe.loc[JobSatisfactionframe[\"JobSatisfaction\"]==2, [\"JobSatisfaction\"]] = '2.Medium'\nJobSatisfactionframe.loc[JobSatisfactionframe[\"JobSatisfaction\"]==3, [\"JobSatisfaction\"]] = '3.High'\nJobSatisfactionframe.loc[JobSatisfactionframe[\"JobSatisfaction\"]==4, [\"JobSatisfaction\"]] = '4.Very High'\n\ngroup = JobSatisfactionframe.groupby([\"JobSatisfaction\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","d4bef3e1":"feature_JobSatisfaction = dataframe[[\"JobSatisfaction\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_JobSatisfaction, test_feature_JobSatisfaction, train_labels, test_labels =\\\ntrain_test_split(feature_JobSatisfaction, attrition)\n\nscaler = StandardScaler()\ntrain_feature_JobSatisfaction = scaler.fit_transform(train_feature_JobSatisfaction)\ntest_feature_JobSatisfaction = scaler.transform(test_feature_JobSatisfaction)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_JobSatisfaction, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_JobSatisfaction, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_JobSatisfaction, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","5b477d06":"relationshipsatisfaction_frame = dataframe['RelationshipSatisfaction'].value_counts().to_frame().sort_index()\nrelationshipsatisfaction_frame.index.name = 'response_num'\nrelationshipsatisfaction_frame[\"num\"] = relationshipsatisfaction_frame[\"RelationshipSatisfaction\"]\ndel relationshipsatisfaction_frame[\"RelationshipSatisfaction\"]\nrelationshipsatisfaction_frame[\"response\"] = [\"Low\", \"Medium\", \"High\", \"Very High\"]\ncols = [\"response\", \"num\"]\nrelationshipsatisfaction_frame = pd.DataFrame(relationshipsatisfaction_frame, columns = cols)\nrelationshipsatisfaction_frame","c993cc2d":"labels = \"Low\", \"Medium\", \"High\", \"Very High\"\nsizes = [276, 303, 459, 432]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","07f51685":"RelationshipSatisfactionframe = dataframe[[\"RelationshipSatisfaction\", \"Attrition\",\"EmployeeCount\"]]\nRelationshipSatisfactionframe.loc[RelationshipSatisfactionframe[\"RelationshipSatisfaction\"]==1, \n                                  [\"RelationshipSatisfaction\"]] = '1.Low'\nRelationshipSatisfactionframe.loc[RelationshipSatisfactionframe[\"RelationshipSatisfaction\"]==2, \n                                  [\"RelationshipSatisfaction\"]] = '2.Medium'\nRelationshipSatisfactionframe.loc[RelationshipSatisfactionframe[\"RelationshipSatisfaction\"]==3, \n                                  [\"RelationshipSatisfaction\"]] = '3.High'\nRelationshipSatisfactionframe.loc[RelationshipSatisfactionframe[\"RelationshipSatisfaction\"]==4, \n                                  [\"RelationshipSatisfaction\"]] = '4.Very High'\n\ngroup = RelationshipSatisfactionframe.groupby([\"RelationshipSatisfaction\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","614a0279":"feature_RelationshipSatisfaction = dataframe[[\"RelationshipSatisfaction\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_RelationshipSatisfaction, test_feature_RelationshipSatisfaction, train_labels, test_labels =\\\ntrain_test_split(feature_RelationshipSatisfaction, attrition)\n\nscaler = StandardScaler()\ntrain_feature_RelationshipSatisfaction = scaler.fit_transform(train_feature_RelationshipSatisfaction)\ntest_feature_RelationshipSatisfaction = scaler.transform(test_feature_RelationshipSatisfaction)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_RelationshipSatisfaction, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_RelationshipSatisfaction, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_RelationshipSatisfaction, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","713f2b40":"environmentsatisfaction_frame = dataframe['EnvironmentSatisfaction'].value_counts().to_frame().sort_index()\nenvironmentsatisfaction_frame.index.name = 'response_num'\nenvironmentsatisfaction_frame[\"num\"] = environmentsatisfaction_frame[\"EnvironmentSatisfaction\"]\ndel environmentsatisfaction_frame[\"EnvironmentSatisfaction\"]\nenvironmentsatisfaction_frame[\"response\"] = [\"Low\", \"Medium\", \"High\", \"Very High\"]\ncols = [\"response\", \"num\"]\nenvironmentsatisfaction_frame = pd.DataFrame(environmentsatisfaction_frame, columns = cols)\nenvironmentsatisfaction_frame","7d57eec5":"labels = \"Low\", \"Medium\", \"High\", \"Very High\"\nsizes = [284, 287, 453, 446]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","7d87219e":"EnvironmentSatisfactionframe = dataframe[[\"EnvironmentSatisfaction\", \"Attrition\",\"EmployeeCount\"]]\nEnvironmentSatisfactionframe.loc[EnvironmentSatisfactionframe[\"EnvironmentSatisfaction\"]==1, [\"EnvironmentSatisfaction\"]] = '1.Low'\nEnvironmentSatisfactionframe.loc[EnvironmentSatisfactionframe[\"EnvironmentSatisfaction\"]==2, [\"EnvironmentSatisfaction\"]] = '2.Medium'\nEnvironmentSatisfactionframe.loc[EnvironmentSatisfactionframe[\"EnvironmentSatisfaction\"]==3, [\"EnvironmentSatisfaction\"]] = '3.High'\nEnvironmentSatisfactionframe.loc[EnvironmentSatisfactionframe[\"EnvironmentSatisfaction\"]==4, [\"EnvironmentSatisfaction\"]] = '4.Very High'\n\ngroup = EnvironmentSatisfactionframe.groupby([\"EnvironmentSatisfaction\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","bca5f254":"feature_EnvironmentSatisfaction = dataframe[[\"EnvironmentSatisfaction\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_EnvironmentSatisfaction, test_feature_EnvironmentSatisfaction, train_labels, test_labels =\\\ntrain_test_split(feature_EnvironmentSatisfaction, attrition)\n\nscaler = StandardScaler()\ntrain_feature_EnvironmentSatisfaction = scaler.fit_transform(train_feature_EnvironmentSatisfaction)\ntest_feature_EnvironmentSatisfaction = scaler.transform(test_feature_EnvironmentSatisfaction)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_EnvironmentSatisfaction, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_EnvironmentSatisfaction, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_EnvironmentSatisfaction, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","367648b5":"trainingtimesframe = dataframe[\"TrainingTimesLastYear\"].value_counts().to_frame().sort_index()\ntrainingtimesframe.index.name = \"Training Times Last Year\"\ntrainingtimesframe[\"num\"] = trainingtimesframe[\"TrainingTimesLastYear\"]\ndel trainingtimesframe[\"TrainingTimesLastYear\"]\ntrainingtimesframe","d28cba51":"trainingtimes_series = pd.Series(trainingtimesframe[\"num\"])\nplt.rcParams['font.size'] = 12\ntrainingtimes_series.plot(kind=\"bar\")","8bb22e3e":"plt.rcParams[\"figure.figsize\"]=(6, 4)\nplt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"TrainingTimesLastYear\", data=dataframe)","bb8be45c":"feature_TrainingTimesLastYear = dataframe[[\"TrainingTimesLastYear\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_TrainingTimesLastYear, test_feature_TrainingTimesLastYear, train_labels, test_labels = \\\ntrain_test_split(feature_TrainingTimesLastYear, attrition)\n\nscaler = StandardScaler()\ntrain_feature_TrainingTimesLastYear = scaler.fit_transform(train_feature_TrainingTimesLastYear)\ntest_feature_TrainingTimesLastYear = scaler.transform(test_feature_TrainingTimesLastYear)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_TrainingTimesLastYear, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_TrainingTimesLastYear, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_TrainingTimesLastYear, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","4b920bee":"worklifebalance_frame = dataframe['WorkLifeBalance'].value_counts().to_frame().sort_index()\nworklifebalance_frame.index.name = 'response_num'\nworklifebalance_frame[\"num\"] = worklifebalance_frame[\"WorkLifeBalance\"]\ndel worklifebalance_frame[\"WorkLifeBalance\"]\nworklifebalance_frame[\"response\"] = [\"Low\", \"Medium\", \"High\", \"Very High\"]\ncols = [\"response\", \"num\"]\nworklifebalance_frame = pd.DataFrame(worklifebalance_frame, columns = cols)\nworklifebalance_frame","bdcf9bc6":"labels = \"Low\", \"Medium\", \"High\", \"Very High\"\nsizes = [80, 344, 893, 153]\n\nfig1, ax1 = plt.subplots()\nax1.pie(sizes, labels=labels, autopct='%1.1f%%', startangle=90)\nplt.rcParams['font.size'] = 12\nplt.show()","4e337998":"WorkLifeBalanceframe = dataframe[[\"WorkLifeBalance\", \"Attrition\",\"EmployeeCount\"]]\nWorkLifeBalanceframe.loc[WorkLifeBalanceframe[\"WorkLifeBalance\"]==1, [\"WorkLifeBalance\"]] = '1.Low'\nWorkLifeBalanceframe.loc[WorkLifeBalanceframe[\"WorkLifeBalance\"]==2, [\"WorkLifeBalance\"]] = '2.Medium'\nWorkLifeBalanceframe.loc[WorkLifeBalanceframe[\"WorkLifeBalance\"]==3, [\"WorkLifeBalance\"]] = '3.High'\nWorkLifeBalanceframe.loc[WorkLifeBalanceframe[\"WorkLifeBalance\"]==4, [\"WorkLifeBalance\"]] = '4.Very High'\n\ngroup = WorkLifeBalanceframe.groupby([\"WorkLifeBalance\", \"Attrition\"]).sum()\n\nplt.rcParams[\"figure.figsize\"]=(10, 5)\nplt.rcParams['font.size'] = 14\nmosaic(group[\"EmployeeCount\"])\nplt.show()","f619a6da":"feature_WorkLifeBalance = dataframe[[\"WorkLifeBalance\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_WorkLifeBalance, test_feature_WorkLifeBalance, train_labels, test_labels = train_test_split(feature_WorkLifeBalance, attrition)\n\nscaler = StandardScaler()\ntrain_feature_WorkLifeBalance = scaler.fit_transform(train_feature_WorkLifeBalance)\ntest_feature_WorkLifeBalance = scaler.transform(test_feature_WorkLifeBalance)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_WorkLifeBalance, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_WorkLifeBalance, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_WorkLifeBalance, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","df2f37cd":"dataframe[\"YearsInCurrentRole\"].hist(grid=False)\nplt.rcParams['font.size'] = 12","52acd135":"plt.rcParams['font.size'] = 12\nsns.boxplot(x=\"Attrition\", y=\"YearsInCurrentRole\", data=dataframe)","688b900b":"feature_YearsInCurrentRole = dataframe[[\"YearsInCurrentRole\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_feature_YearsInCurrentRole, test_feature_YearsInCurrentRole, train_labels, test_labels = train_test_split(feature_YearsInCurrentRole, attrition)\n\nscaler = StandardScaler()\ntrain_feature_YearsInCurrentRole = scaler.fit_transform(train_feature_YearsInCurrentRole)\ntest_feature_YearsInCurrentRole = scaler.transform(test_feature_YearsInCurrentRole)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_feature_YearsInCurrentRole, train_labels)\n\nprint(\"Train Accuracy : \", model.score(train_feature_YearsInCurrentRole, train_labels).round(3))\nprint(\"Test Accuracy : \", model.score(test_feature_YearsInCurrentRole, test_labels).round(3))\nprint(\"Coefficient : \", model.coef_[0][0].round(3))","e6e84980":"np.corrcoef(dataframe['Age'], dataframe['TotalWorkingYears'])","a7d85497":"np.corrcoef(dataframe['Age'], dataframe['JobLevel'])","ccd120ef":"np.corrcoef(dataframe['Age'], dataframe['YearsAtCompany'])","c79f229c":"np.corrcoef(dataframe['Age'], dataframe['YearsInCurrentRole'])","82b91561":"np.corrcoef(dataframe['TotalWorkingYears'], dataframe['JobLevel'])","fc8a7d38":"np.corrcoef(dataframe['TotalWorkingYears'], dataframe['YearsAtCompany'])","0f269b4d":"np.corrcoef(dataframe['TotalWorkingYears'], dataframe['YearsInCurrentRole'])","27f9fb52":"np.corrcoef(dataframe['JobLevel'], dataframe['YearsAtCompany'])","ce82e77f":"np.corrcoef(dataframe['JobLevel'], dataframe['YearsInCurrentRole'])","a0889d52":"np.corrcoef(dataframe['YearsAtCompany'], dataframe['YearsInCurrentRole'])","427f79a8":"features = dataframe[[\"Age\", \"Marital_Single_dummy\", \"JobLevel\", \"AvgWorkingYears\", \"MonthlyIncome\", \"StockOptionLevel\",\n                     \"JobInvolvement\", \"JobSatisfaction\", \"EnvironmentSatisfaction\", \"YearsInCurrentRole\"]]\nattrition = dataframe['Attrition_dummy']\n\ntrain_features, test_features, train_labels, test_labels = train_test_split(features, attrition)\n\nscaler = StandardScaler()\ntrain_features = scaler.fit_transform(train_features)\ntest_features = scaler.transform(test_features)\n\nmodel = LogisticRegression()\n\nmodel.fit(train_features, train_labels)\n\nprint(\"\u2460 Train Accuracy : \", model.score(train_features, train_labels).round(3))\nprint(\"\u2461 Test Accuracy : \", model.score(test_features, test_labels).round(3))\nprint(\"\u2462 Coefficients : \", model.coef_.round(3)[0])\nprint(\"\u2463 Confusion Matrix\")\nprint(\"   \", confusion_matrix(test_labels, model.predict(test_features))[0][0], \"  \",\n      confusion_matrix(test_labels, model.predict(test_features))[0][1])\nprint(\"   \", confusion_matrix(test_labels, model.predict(test_features))[1][0], \"  \",\n      confusion_matrix(test_labels, model.predict(test_features))[1][0])\nprint(\"\u2464 Classification Report\")\nprint(classification_report(test_labels, model.predict(test_features)))","ce3b22a5":"model2 = DecisionTreeClassifier(max_depth=3)\n\nmodel2.fit(train_features, train_labels)\n\nprint(\"\u2460 Train Accuracy : \", model2.score(train_features, train_labels).round(3))\nprint(\"\u2461 Test Accuracy : \", model2.score(test_features, test_labels).round(3))\nprint(\"\u2462 Confusion Matrix\")\nprint(\"   \", confusion_matrix(test_labels, model2.predict(test_features))[0][0], \"  \",\n      confusion_matrix(test_labels, model2.predict(test_features))[0][1])\nprint(\"   \", confusion_matrix(test_labels, model2.predict(test_features))[1][0], \"  \",\n      confusion_matrix(test_labels, model2.predict(test_features))[1][0])\nprint(\"\u2463 Classification Report\")\nprint(classification_report(test_labels, model2.predict(test_features)))","395e36d1":"model3 = RandomForestClassifier(n_estimators=100, max_depth=7)\n\nmodel3.fit(train_features, train_labels)\n\nprint(\"\u2460 Train Accuracy : \", model3.score(train_features, train_labels).round(3))\nprint(\"\u2461 Test Accuracy : \", model3.score(test_features, test_labels).round(3))\nprint(\"\u2462 Confusion Matrix\",)\nprint(\"   \", confusion_matrix(test_labels, model3.predict(test_features))[0][0], \"  \",\n      confusion_matrix(test_labels, model3.predict(test_features))[0][1])\nprint(\"   \", confusion_matrix(test_labels, model3.predict(test_features))[1][0], \"  \",\n      confusion_matrix(test_labels, model3.predict(test_features))[1][0])\nprint(\"\u2463 Classification Report\")\nprint(classification_report(test_labels, model3.predict(test_features)))","c7605870":"model4 = Sequential()\n\nmodel4.add(Dense(512, input_dim=features.shape[1], activation=\"relu\"))\nmodel4.add(Dense(512, activation=\"relu\"))\nmodel4.add(Dense(512, activation=\"relu\"))\nmodel4.add(Dense(512, activation=\"relu\"))\nmodel4.add(Dropout(0.2))\n\nmodel4.add(Dense(1, activation=\"sigmoid\"))\n\nmodel4.compile(loss = \"binary_crossentropy\", optimizer=Adam(lr=0.01), metrics=[\"accuracy\"])\n\nprint(\"\u2460 Train Accuracy : \")\nmodel4.fit(train_features, train_labels, batch_size=50, epochs=20, verbose=1)\nprint(\"\")\nprint(\"\u2461 Test Accuracy : \")\nmodel4.evaluate(test_features, test_labels)","4d5f1b61":"print(\"\u2462 Confusion Matrix\",)\npred_labels = tf.cast(model4.predict(test_features) > 0.5, dtype=tf.float32)\npred_labels\nprint(confusion_matrix(test_labels, pred_labels))\nprint(\"\u2463 Classification Report\")\nprint(classification_report(test_labels, pred_labels))","d21730f8":"#### \u2460 Exploratory Data Analysis","54f8452b":"#### \u2460 Exploratory Data Analysis","3e5ea5bd":"#### \u2460 Exploratory Data Analysis","00382a6d":"#### \u2463 Sub-Conclusion","48b0b6af":"**Both \"Job Role\" and \"Job Level\" is important factor. However as folloewd, these are closely connected.**<br\/>\nSales Represintative, Research Sicentist, Laboratory Technician and Human Resources are correspond to mainly Job Level 1, paritialy Job Level 2.<br\/>\nHealthcare Represeintative, Manufacturing Director and Sales Executive are correspond to mainly Job Level 2, partialy Job Level 3( and 4).<br\/>\nResearch Director, Manager are correspond to mainly Job Level 4 and 5, partialy Job Level 3.<br\/>\n\n**So, I should analyze about just \"Job Level\", because it contains 'sequence'.**","f4c3c142":"#### \u2462 Logistic Regression","37a6389b":"### \u2162. 5. (2) Job Satisfaction","aff037d4":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis.","5fcb48d9":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis.","7b8fbb5c":"## \u2162. 5. Effect of Intrinsic Motivation on the Attrition","ef087d12":"# \u2162. Exploratory and Individual Analysis(EDA)\nExploratory data analysis for grasp about dataset. Additionally, finding outlier or missing. <br\/> \nFortunatly, there are not outlier or missing.\n\nIn principle, it is good for consider all variables to practice analysis. But to build final model, I will analyze each dependent variable one-by-one. If certain dependent variable affect independent variable minorly, I can exclude that. And it will be helpful to final analysis. And realistically, company cannot control everything, so must focus on more important factor.<br\/>\nAs followed, I have chosen variables of which **coefficient is under -0.28 or over 0.23** on indvidual logistic regression, if it wasn't accuracy problem. Calculated by Exponential function and Odds Ratio, it means about **25% decrease or increase** of attrition.","d27b64cc":"All models show result sufficient level of accuracy, which are about 85~90%. Overall, we can predict attrition of employ in some degree.<br\/>\nBut view from a different standpoint, other indicator, especially recall(sensitivity) is quite low. (In Decision Tree model, precision is not good, too.) Only analysis using deep layer, a little bit improve. So, It is needed to be careful when predict behavior of employee.","99c0c141":"#### \u2461 Visualization Analysis","003f5ffb":"## \u2163. 1. Checking correlation to prevent Multicollinearity problem\nEventually to set comprehensive model, for now should except variables that can cause Multicollinearity problem.","5624b93c":"#### \u2462 Logistic Regression","1bbfd7e5":"## \u2163. 3. Decision Tree","f4008079":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis.","a6e327e5":"#### \u2460 Age\n- If someone getting more age, the employee would be harder to seek a great change in life.\n\n#### \u2461 Gender\n- It is expected that Gender itself would not affect to attrition.<br\/>\n  But as a basic demographic varables, it is need to analyze.\n\n#### \u2462 Marital Status\n- Marital status combine with support family. For employee, it is one of main cosideration on leave company.\n\n#### \u2463 Education\n- According to labor economics, high level educated group can face to larger labor market.<br\/>\n  So they can choose other companies and decide to resign easily.\n  \n#### \u2464 Distance from Home\n- Long commute time bother employees so much. It can stimulate wants to leave company","2984857e":"### \u2162. 5. (7) Years In Current Role","f93db495":"#### \u2463 Sub-Conclusion","423e7e89":"#### \u2463 Sub-Conclusion","fb089caa":"#### \u2461 Visualization Analysis","7ba510d9":"#### \u2461 Visualization Analysis","f89c28d3":"### 2. (4) Intrinsic Motivation\nThe followings are factor that can prevent empolyee's resignation.<br\/>\nThese are also related with \u300cJob Embeddedness\u300d(links, fit and sacrifice).","38e99116":"### \u2162. 4. (3) Percent of Salary Hike","eea88214":"#### \u2461 Visualization Analysis","6171a850":"# \u2165. Conclusion","29eff7f2":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficients is not sufficient level. It seemed that Percent of Salary Hike affect to attrition only slightly.<br\/>\nSo, I **should not** pick this variable to final analysis.","58404a6a":"#### \u2460 Exploratory Data Analysis","0b3d0728":"#### \u2462 Logistic Regression","a24429b0":"#### \u2461 Visualization Analysis","dbe23dc6":"### 2. (2) Job\u00b7Vocational behavior Characteristic","f90ef1f7":"#### \u2460 Exploratory Data Analysis","ca6ce1c1":"#### \u2461 Visualization Analysis","07c4b2b0":"As result of Correaltion, it **should be exculde 'TotalWorkingYears', 'YearsAtCompany'** for proper analysis.<br\/>\n<br\/>\nFinally, \"Age\", \"Marital_Single_dummy\", \"JobLevel\", \"AvgWorkingYears\", \"MonthlyIncome\", \"StockOptionLevel\", \"JobInvolvement\", \"JobSatisfaction\", \"EnvironmentSatisfaction\", \"YearsInCurrentRole\" are picked to final model.","8605c187":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficient is not sufficient level. It seemed that Number of Worked Companies in past affect to attrition only slightly.<br\/>\nSo, I **should not** pick this variable to final analysis.","ca0c0668":"#### \u2461 Visualization Analysis","0ecff947":"### \u2162. 5. (3) Relationship Satisfaction","cfc26328":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficient is not sufficient level. It seemed that Gender affect to attrition only slightly<br\/>\nSo, I **should not pick** this variable to final analysis.","05effdd2":"#### \u2461 Visualization Analysis","4cad4a76":"#### \u2460 Exploratory Data Analysis","9e6a6d52":"# \u2161. Data and Python Library","fd8c8033":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis.","da69eba2":"#### \u2463 Sub-Conclusion","7e34cab5":"#### \u2462 Logistic Regression","f5072319":"### \u2162. 2. (5)  Distance from Home","8e7037fd":"#### \u2460 Exploratory Data Analysis","82e554a7":"#### \u2462 Logistic Regression","7ba4cb07":"#### \u2460 Exploratory Data Analysis","6ab90a84":"#### \u2462 Logistic Regression","e15e2645":"### \u2162. 3. (4) Number of Worked Companies in past","c1348a67":"#### \u2462 Logistic Regression","4194b163":"#### \u2463 Sub-Conclusion","3a3830aa":"#### \u2462 Logistic Regression","e4d54bc1":"#### \u2461 Visualization Analysis","92fd4867":"#### \u2461 Visualization Analysis","93cdbbbb":"#### \u2462 Logistic Regression","2f0362b0":"#### \u2461 Visualization Analysis","9d98c2f6":"### \u2162. 5. (4) Environment Satisfaction","45263d0c":"#### \u2463 Sub-Conclusion","10863996":"#### \u2463 Sub-Conclusion","f89c2ab7":"#### \u2460 Department\n- If attrition occur at one department much more than others, it is requested that specialized solution\n\n#### \u2461 Job Role \/ Job Level\n- Accoring to \u300cJob Characteristics theory\u300d(Hackman,  Oldham),\u2170)Skill Variety, \u2171)Task Identity, \u2172)Task Significance, \u2173)Autonomy, \u2174)Feedback can reduce absenteeism and turnover. And the factors are related to each job itself.\n\n#### \u2462 Working Years At Company\n- Someone who worked long time at company, can be expected remain.\n\n#### \u2463 Number of Worked Company, \u2464 Total Working Years, and \u2465  Average Working Years at Each Company\n- Employee's tendency to turnover frequently in past, would be valid current,too.\n- 'Average Working Years at Each Company' is a derived variable, which is Total Working Years divided by  Number of Worked Company","3ce9193e":"## \u2162. 3. Effect of Job\u00b7Vocational behavior Characteristic on the Attrition","336e45c4":"### \u2162. 5. (5) Training Times","1b7019a2":"## 2. Set Independant Variables\n\nThe data, \"WA_Fn-UseC_-HR-Employee-Attrition.csv\", which is target of this analysis, has a 35 variables(columns). Among that, I pick 'Attrition' as dependant variable. And pick independant varables and set hypothesis like below.","14f672cc":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis. ","9d8dcd07":"### \u2162. 3. (3) Years at Company","87eb04b0":"#### \u2463 Sub-Conclusion","104eff82":"#### \u2462 Logistic Regression\nFor someone in the first job, calculate 'Average Working Years' by mean of years at company","bc2e7d36":"#### \u2460 Exploratory Data Analysis","1c2f359d":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis.","abe970fa":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis. ","5d757cea":"### \u2162. 2. (1) Age","48b10887":"### \u2162. 2. (4) Education Level","65420731":"#### \u2461 Visualization Analysis","2ffff3e5":"#### \u2463 Sub-Conclusion","2599db17":"#### \u2462 Logistic Regression","765a8175":"#### \u2462 Logistic Regression","6fb28022":"#### \u2460 Exploratory Data Analysis","086a184d":"### \u2162. 5. (6) WorkLifeBalance - other farctor which can have effect on Satisfaction","1c2b9386":"#### \u2461 Visualization Analysis","c61e0dd5":"#### \u2460 Exploratory Data Analysis","ceabdad4":"### \u2460 Exploratory Data Analysis","291271b1":"## \u2162. 1. Dependant variable(Attrition) and set model of analysis","187e274b":"#### \u2461 Visualization Analysis","9c0ee86f":"#### \u2463 Sub-Conclusion","c32b2f0b":"#### \u2460 Job Involvement, \u2461 Job Satisfaction\n- These are typical indicators which correspond to intrinsic motivator.\n\n#### \u2462 Relationship Satisfaction\n- According to \u300cHuman Relation theory\u300d(Mayo, Roethlisberger), sometimes relationship between employees is much more important than monetary factors. (It is discoveried in the Hawthore factory study)\n\n#### \u2463 Environment Satisfaction\n- Well built environment make employee involve their company and job\n\n#### \u2464 Traing Times\n- To satisfy employee's need for growth, company should offer sufficient developement program.\n\n#### \u2465 Work-Life Balence\n- If company request to much time, employee's family will not agree that the employee work at the company continuously.\n\n#### \u2466 Years In Current Role\n- If one person repeat the same work for a long time, it should make the person burn out.","1cab34e0":"#### \u2462 Logistic Regression","85fb30e7":"#### \u2460 Exploratory Data Analysis","e604fde2":"### 2. (1) Personal(Demographic) Characteristics","d4e9344b":" Attrition in company cause cost because the company have to recruit, screen, train and educate for new employee. Additionaly, if not recriut for a long term, remain employee can feel burden. Also, it has a bad influence on group cohesiveness.<br\/>\n However, there can be a lot of factors which affect to attrition, and its make managing the problem complex. So it is important that keep appropriate attrition, and analysis cause of attrition is requested.\n\n Inevitably, I will research about **demographic characteristics** as personel factors. For example, person who prefer stability generally less frequently change the job, so attrition will decrease too. So we cannot ignore influence of personal characteristics to attrition.\n \n Next part is analysis about **job and vocational behavior characteristics**. It can represent employee's awareness and attitude to work.<br\/>\n For instance, if certain department's attirtion occur much more frequently than other's, company have to focus on the department. And it is the same to job role or job level. <br\/>Also, it will be interesting to search about vocational behavior characteristic. We can expect that someone who have worked at company for a long time, would not resign esasily.\n \nAbove all things, I will focus on \"Motivation\".  In this analysis, especially I applicate concept of \"**extrinsic reward**\" and \"**intrinsic motivation**\". In other words, if that two factors are not met employee's needs, the employ will leave the company. <br\/>\nExtrinsic reward is so-called economical\/monetary compensation, for example, income and stock option. Naturally, every people always wants more compenstion.<br\/>\nBut human seek more valuable things, such as meaningful role at their work performence. So there are many theories to explain employee's behavior in the company. For instance, Herzberg's two-factor theory insist that there are motivator and hygiene factor. Hygine factors like salary and benefit just can suppres dissatisfaction, while motivators like worthwhile job can lead positive behavior for organization. <br\/>\nWith these basis, I will analyze the effect of compensation on the Attrition, and the effect of subjective factor on the Attrition.","7924b5f7":"#### \u2463 Sub-Conclusion","4c620259":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the absolute value of coefficient is not sufficient level. It seemed that Education Level affect to attrition only slightly<br\/>\nSo, I **should not pick** this variable to final analysis.","00b0ab38":"#### \u2463 Sub-Conclusion","68c4c02a":"#### \u2460 Exploratory Data Analysis","ff797367":"#### \u2461 Visualization Analysis","e26792f5":"### \u2461 Data Conservation for Logistic Regression\nIt is discrete variable. So, for the analysis, the **Logistic Regression** can be use.<br\/>\nTherefore the occurrence of event \"Attrition\" should be converted \"1\", the other is \"0\".","de9f5c59":"#### \u2460 Exploratory Data Analysis","776462b2":"#### \u2463 Sub-Conclusion","2c26ba12":"## 1. Meaning of Analysis and Direction","216f0528":"#### \u2463 Sub-Conclusion","eece0c0e":"#### \u2461 Visualization Analysis","b757e17b":"#### \u2463 Sub-Conclusion","5057d1ba":"### \u2162. 3. (2) Job Role and Job Level","50736a4b":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis.\n\nBut, the hypothesis which I thinked must be revised.<br\/>Employees tend to work constantly rather than feel boring, take the job stability.","44a03bd2":"#### \u2463 Sub-Conclusion","d25b78c4":"# \u2164. Final Analysis - Deep Learning","17210bdd":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficient is not sufficient level. It seemed that Relationship Satisfaction affect to attrition only slightly.<br\/>\nSo, I **should not** pick this variable to final analysis.","41ff8d76":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the values of both coefficients are not sufficient level. It seemed that what Department affect to attrition only slightly<br\/>\nSo, I **should not** pick this variable to final analysis.","5c2eb4d5":"### \u2162. 4. (4)  Performance Rating\u00b6","043468cf":"#### \u2460 Exploratory Data Analysis","1917388b":"#### \u2463 Sub-Conclusion","17c90694":"#### \u2460 Exploratory Data Analysis","cb0871c9":"#### \u2463 Sub-Conclusion","885e64ae":"## \u2162. 2. Effect of Demographic Characteristic on the Attrition","8d9bf2e6":"On the basis of former analysis, I have made sigmoid model with four hidden layer.","c48ab95a":"#### \u2463 Sub-Conclusion","a4355792":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis.","3902c41a":"## \u2163. 2. Logistic Regression","c18292b5":"#### \u2461 Visualization Analysis","e3f1b9e3":"### \u2162. 3. (1) Department","37dd7c75":"#### \u2462 Logistic Regression","d0c5ca1b":"#### \u2460 Monthly Income\n- Without doubt, income is powerful method to compensate for employee.\n- If emplyoee resign company that offer large income, the employee have to face to big opportunity cost.\n\n#### \u2461 Stock Option Level\n- Company can provide the right of choice to buy stock at fixed price.\n- It makes relationship between company's growth and employee's long-term profit.\n\n#### \u2462 Percent of Salary Hike\n- Increase of income make employee expect larger income of future.\n\n#### \u2463 Performance Rating\n- Result of performance appraisal means degree of acknowledgment about contribution in the company.\n\n#### \u2464 Years Since Last Promotion\n- Personnel congestion is structural problem that makes employees are frustrated at the company","5b48da3d":"## \u2162. 4. Effect of Extrinsic Reward on the Attrition","3740b1ef":"#### \u2460 Exploratory Data Analysis","bf244815":"# \u2163. Final Analysis - Machine Learning","0818cebe":"### \u2162. 5. (1) Job Involvement","d7878862":"### \u2162. 3. (5)  Total Working Years","478ab68d":"### \u2162. 4. (2) Stock Option Level","3872106d":"#### \u2462 Logistic Regression","9ea52b7a":"### \u2162. 4. (5) Years Since Last Promotion","7d42666b":"#### \u2460 Exploratory Data Analysis","3e55882b":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficients is not sufficient level. It seemed that Performance Rating affect to attrition only slightly.<br\/>\nSo, I **should not** pick this variable to final analysis.","d8571210":"### 2. (3) Extrinsic Reward","9f68014a":"#### \u2461 Visualization Analysis","1acb4d4f":"#### \u2463 Sub-Conclusion","577be540":"### \u2162. 2. (3) Marital Status","0c58e7ef":"#### \u2462 Logistic Regression","6bad8595":"#### \u2461 Visualization Analysis","2bb64325":"### \u2163. 1. (2) Variables Excluded","aca68819":"#### \u2461 Visualization Analysis","def8df62":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis.","4db85dba":"#### \u2460 Exploratory Data Analysis","c63ab00a":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficients is not sufficient level. It seemed that Years Since Last Promotion\n affect to attrition only slightly.<br\/>\nSo, I **should not** pick this variable to final analysis.","9bc32bed":"#### \u2461 Visualization Analysis","7cd133e3":"There is no problem of model accuracy, and overfitting, underfitting, too. <br\/>\nAnd the absolute value of coefficient is sufficient level.<br\/>\nSo, I **should pick** this variable to final analysis. ","277caa18":"#### \u2462 Logistic Regression","700229ac":"#### \u2460 Exploratory Data Analysis","0210e72d":"#### \u2462 Logistic Regression","467b9ed6":"#### \u2462 Logistic Regression","47b0632f":"#### \u2461 Visualization Analysis","f8cadd7c":"### \u2162. 4. (1) Monthly Income","6f658252":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficient is not sufficient level. It seemed that Traing Times affect to attrition only slightly.<br\/>\nSo, I **should not** pick this variable to final analysis.","2506d1ff":"# \u2160. Preface","0a6c0a73":"## \u2163. 4.  Random Forest","697ef3d1":"#### \u2461 Visualization Analysis","a7df335d":"#### \u2463 Sub-Conclusion","e432cb58":"#### \u2462 Logistic Regression","492c164f":"#### \u2463 Sub-Conclusion","02f53e89":"### \u2162. 2. (2) Gender","815a2e7f":"#### \u2460 Exploratory Data Analysis","bd9b6074":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficient is not sufficient level. It seemed that Distance from home affect to attrition only slightly<br\/>\nSo, I **should not pick** this variable to final analysis.","1c42b225":"#### \u2460 Exploratory Data Analysis\n(except employee who is in the first job)","61bb66de":"#### \u2463 Sub-Conclusion","4a8e8eff":"### \u2163. 1. (1) Correaltion between Variables that are related to the stream of Time","647fd893":"#### \u2462 Logistic Regression","58e68afe":"#### \u2462 Logistic Regression","49177b50":"### \u2162. 3. (6) Average Working Years at Each Company in past\nBut on the other hand, we can think more meaningful deribed variable. It is the \"Average Working Years at Each Company\", the tendency of employee to stay company. <br\/>","eaa2c67e":"#### \u2462 Logistic Regression","e1064a8c":"#### \u2460 Exploratory Data Analysis","4d5f8cc5":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nIt seemed that only 'Single or not' affect to attrition sufficiently.<br\/>\nSo, I **should pick just 'Single or not'** to final analysis.","3c9a3aee":"There is no problem of model accuracy, and overfitting, underfitting, too.<br\/>\nBut the value of coefficient is not sufficient level. It seemed that Job Satisfaction affect to attrition only slightly.<br\/>\nSo, I **should not** pick this variable to final analysis."}}