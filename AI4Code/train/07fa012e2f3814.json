{"cell_type":{"224f0e36":"code","dbc3bd1f":"code","505199c6":"code","3671efbe":"code","49d721cd":"code","431700a2":"code","d78ffd4b":"code","3481269f":"code","dfe5b0d6":"code","f509d7f4":"code","e424cf8f":"code","1f7de2ec":"code","0f164f3f":"code","979d75e4":"code","ff0e427e":"code","890a7a33":"code","a3025453":"code","10c7c2a7":"code","c30d47c2":"code","fa2c0fdd":"code","6630a6f0":"code","b51106d5":"code","86fa87ce":"code","b1e22b99":"code","f4e09b62":"code","0dc53760":"code","d1baf2cc":"code","bead2916":"code","5e14a3be":"code","5c99c73d":"code","49489020":"code","661d75a3":"code","6cf627b6":"code","e987e366":"code","342cc0e6":"code","28c0c139":"code","6e08b38c":"code","885af309":"code","69c21eb5":"markdown","82066c24":"markdown"},"source":{"224f0e36":"import pandas as pd\nimport numpy as np\nimport re\nimport string\n\ndata = pd.read_csv(\"..\/input\/entity-annotated-corpus\/ner_dataset.csv\", encoding=\"latin1\")","dbc3bd1f":"data = data.fillna(method=\"ffill\")","505199c6":"df1 = pd.DataFrame({ \"Sentence #\":['Sentence: 47960']*6, \n                    \"Word\":['my', 'name', 'is', 'abhishek', 'kumar','.'],  \n                    \"POS\":[None]*6,\n                    \"Tag\":['O','O','O','B-per','I-per','O']})\ndf2 = pd.DataFrame({ \"Sentence #\":['Sentence: 47961']*7, \n                    \"Word\":['my', 'name', 'is', 'ritik', 'kumar','gupta','.'],  \n                    \"POS\":[None]*7,\n                    \"Tag\":['O','O','O','B-per','I-per','I-per','O']})","3671efbe":"data=data.append(df1)\ndata=data.append(df2)","49d721cd":"data.tail()","431700a2":"data.head(20)","d78ffd4b":"words = list(set(data[\"Word\"].values))\nwords.append(\"ENDPAD\")\nn_words = len(words); n_words","3481269f":"tags = list(set(data[\"Tag\"].values))\nn_tags = len(tags); n_tags","dfe5b0d6":"class SentenceGetter(object):\n    \n    def __init__(self, data):\n        self.n_sent = 1\n        self.data = data\n        self.empty = False\n        agg_func = lambda s: [(w, p, t) for w, p, t in zip(s[\"Word\"].values.tolist(),\n                                                           s[\"POS\"].values.tolist(),\n                                                           s[\"Tag\"].values.tolist())]\n        self.grouped = self.data.groupby(\"Sentence #\").apply(agg_func)\n        self.sentences = [s for s in self.grouped]\n    \n    def get_next(self):\n        try:\n            s = self.grouped[\"Sentence: {}\".format(self.n_sent)]\n            self.n_sent += 1\n            return s\n        except:\n            return None","f509d7f4":"getter = SentenceGetter(data)","e424cf8f":"sent = getter.get_next()","1f7de2ec":"print(sent)","0f164f3f":"sentences = getter.sentences","979d75e4":"max_len = 75\nword2idx = {w: i + 1 for i, w in enumerate(words)}\ntag2idx = {t: i for i, t in enumerate(tags)}","ff0e427e":"word2idx[\"Obama\"]","890a7a33":"tag2idx[\"B-geo\"]","a3025453":"from keras.preprocessing.sequence import pad_sequences\n\n# pad the sequence\nX = [[word2idx[w[0]] for w in s] for s in sentences]\nX = pad_sequences(maxlen=max_len, sequences=X, padding=\"post\", value=n_words-1)","10c7c2a7":"# pad the target\ny = [[tag2idx[w[2]] for w in s] for s in sentences]\ny = pad_sequences(maxlen=max_len, sequences=y, padding=\"post\", value=tag2idx[\"O\"])","c30d47c2":"from keras.utils import to_categorical\ny = [to_categorical(i, num_classes=n_tags) for i in y]\nfrom sklearn.model_selection import train_test_split\nX_tr, X_te, y_tr, y_te = train_test_split(X, y, test_size=0.1)","fa2c0fdd":"!pip install git+https:\/\/www.github.com\/keras-team\/keras-contrib.git","6630a6f0":"from keras.models import Model, Input,Sequential\nfrom keras.layers import LSTM, Embedding, Dense, TimeDistributed, Dropout, Bidirectional\nfrom keras_contrib.layers import CRF\nimport keras as k","b51106d5":"model = Sequential()\nmodel.add(Embedding(input_dim=n_words+1, output_dim=200, input_length=max_len))\nmodel.add(Dropout(0.5))\nmodel.add(Bidirectional(LSTM(units=128, return_sequences=True, recurrent_dropout=0.1)))\nmodel.add(TimeDistributed(Dense(n_tags, activation=\"relu\")))\ncrf_layer = CRF(n_tags)\nmodel.add(crf_layer)","86fa87ce":"model.summary()","b1e22b99":"# adam = k.optimizers.Adam(lr=0.0005, beta_1=0.9, beta_2=0.999)\nmodel.compile(optimizer='adam', loss=crf_layer.loss_function, metrics=[crf_layer.accuracy])","f4e09b62":"history = model.fit(X_tr, np.array(y_tr), batch_size=128, epochs=5,\n                    validation_split=0.1, verbose=1)","0dc53760":"hist = pd.DataFrame(history.history)","d1baf2cc":"import matplotlib.pyplot as plt\nplt.style.use(\"ggplot\")\nplt.figure(figsize=(12,12))\nplt.plot(hist[\"crf_viterbi_accuracy\"])\nplt.plot(hist[\"val_crf_viterbi_accuracy\"])\nplt.show()","bead2916":"!pip install seqeval","5e14a3be":"from seqeval.metrics import precision_score, recall_score, f1_score, classification_report","5c99c73d":"test_pred = model.predict(X_te, verbose=1)","49489020":"idx2tag = {i: w for w, i in tag2idx.items()}\n\ndef pred2label(pred):\n    out = []\n    for pred_i in pred:\n        out_i = []\n        for p in pred_i:\n            p_i = np.argmax(p)\n            out_i.append(idx2tag[p_i].replace(\"PAD\", \"O\"))\n        out.append(out_i)\n    return out\n    \npred_labels = pred2label(test_pred)\ntest_labels = pred2label(y_te)","661d75a3":"print(\"F1-score: {:.1%}\".format(f1_score(test_labels, pred_labels)))\n","6cf627b6":"print(classification_report(test_labels, pred_labels))","e987e366":"model.evaluate(X_te, np.array(y_te))","342cc0e6":"i = 1927\np = model.predict(np.array([X_te[i]]))\np = np.argmax(p, axis=-1)\ntrue = np.argmax(y_te[i], -1)\nprint(\"{:15}||{:5}||{}\".format(\"Word\", \"True\", \"Pred\"))\nprint(30 * \"=\")\nfor w, t, pred in zip(X_te[i], true, p[0]):\n    if w != 0:\n        print(\"{:15}: {:5} {}\".format(words[w-1], tags[t], tags[pred]))","28c0c139":"# Custom Tokenizer\nre_tok = re.compile(f'([{string.punctuation}\u201c\u201d\u00a8\u00ab\u00bb\u00ae\u00b4\u00b7\u00ba\u00bd\u00be\u00bf\u00a1\u00a7\u00a3\u20a4\u2018\u2019])')\ndef tokenize(s): return re_tok.sub(r' \\1 ', s).split()","6e08b38c":"test_sentence=\"In the context of prehistory, antiquity and contemporary indigenous peoples, the title may refer to tribal kingship. Germanic kingship is cognate with Indo-European traditions of tribal rulership (c.f. Indic r\u0101jan, Gothic reiks, and Old Irish r\u00ed, etc.).\"\nx_test_sent = pad_sequences(sequences=[[word2idx.get(w, 0) for w in tokenize(test_sentence)]],\n                            padding=\"post\", value=0, maxlen=max_len)","885af309":"p = model.predict(np.array([x_test_sent[0]]))\np = np.argmax(p, axis=-1)\nprint(\"{:15}||{}\".format(\"Word\", \"Prediction\"))\nprint(30 * \"=\")\nfor w, pred in zip(tokenize(test_sentence), p[0]):\n    print(\"{:15}: {:5}\".format(w, tags[pred]))","69c21eb5":"## Setup the CRF-LSTM\nNow we can fit a LSTM-CRF network with an embedding layer.\n\n","82066c24":"## Prepare the data\nNow we introduce dictionaries of words and tags."}}