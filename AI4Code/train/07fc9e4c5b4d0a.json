{"cell_type":{"0bd970b9":"code","43be64ca":"code","55c170b3":"code","7fc845a3":"code","a3f19dfd":"code","7827ea21":"code","50f556b4":"code","abe14df9":"code","3c1b5782":"code","9a123e43":"code","6cbc79e2":"code","5b75329b":"code","3b313b19":"code","bd4028ad":"code","5749f134":"code","e050c07f":"code","cb60b8ca":"code","4410cc6e":"code","ef1efac9":"code","a32eac96":"code","a4a361f1":"code","81620f94":"code","51a2eae3":"code","1d8b91fe":"code","f222e8f9":"code","9d5d7781":"code","20e97c8d":"code","45251db1":"code","4bbb9a0a":"code","4001fbb9":"code","264eb866":"code","d17e73fb":"code","0c9671c4":"code","67962507":"code","cad96fc1":"code","890152ec":"code","c77d5f29":"code","25ffee5b":"code","a968420e":"code","1c2eea0c":"code","081f0030":"code","3055e4ed":"code","43e226bb":"code","2f6d0213":"code","2f0c5d01":"code","567c5b8b":"code","5d339360":"code","d7ab48d8":"code","a668f20e":"code","21350123":"code","395e085d":"code","1b624086":"code","f7701445":"code","e99dd968":"code","b59269aa":"code","cea2f436":"code","c82e9f21":"code","f940650d":"code","4179bb5d":"code","581debac":"code","0a82b982":"code","777fe736":"code","0ad8f7bf":"code","994b5c9c":"code","d541bcba":"code","eb6e1420":"code","31dadac5":"code","2074bed2":"code","d0b31459":"code","5a0bf1dc":"code","04b1b20b":"code","f183ab8c":"code","4fc0398c":"code","d79a1f2c":"code","764cebed":"code","387c4dc6":"code","ca56b1e7":"code","baea2c3e":"code","9d42f0b2":"code","4e3fcdd7":"code","153ab79d":"code","1ca77ae5":"markdown","f7eef8e4":"markdown","1c7897a6":"markdown","92e5258e":"markdown","1db3edce":"markdown","ce570132":"markdown","da7b1391":"markdown","db8d95ed":"markdown","02651d70":"markdown","f3891592":"markdown","8b987491":"markdown","010c31cf":"markdown"},"source":{"0bd970b9":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport gc\nimport json\nimport math\nimport cv2\nimport PIL\nfrom PIL import Image\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.linear_model import LogisticRegression, Ridge\nfrom sklearn.preprocessing import OneHotEncoder\nfrom tqdm import tqdm\nfrom sklearn.decomposition import PCA\nimport os\nimport imagesize\n\n%matplotlib inline","43be64ca":"import os\nprint(os.listdir(\"..\/input\/siim-isic-melanoma-classification\"))","55c170b3":"#Loading Train and Test Data\ntrain = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/train.csv\")\ntest = pd.read_csv(\"..\/input\/siim-isic-melanoma-classification\/test.csv\")\nprint(\"{} images in train set.\".format(train.shape[0]))\nprint(\"{} images in test set.\".format(test.shape[0]))","7fc845a3":"train.head()","a3f19dfd":"test.head()","7827ea21":"np.mean(train.target)","50f556b4":"plt.figure(figsize=(12, 5))\nplt.hist(train['age_approx'].values, bins=200)\nplt.title('Histogram age_approx counts in train')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.show()","abe14df9":"images = []\nfor i, image_id in enumerate(tqdm(train['image_name'].head(10))):\n    im = Image.open(f'..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/{image_id}.jpg')\n    im = im.resize((128, )*2, resample=Image.LANCZOS)\n    images.append(im)\n    ","3c1b5782":"images[0]","9a123e43":"images[1]","6cbc79e2":"images[3]","5b75329b":"plt.figure(figsize=(12, 5))\nplt.hist(test['age_approx'].values, bins=200)\nplt.title('Histogram age_approx counts in test')\nplt.xlabel('Value')\nplt.ylabel('Count')\nplt.show()","3b313b19":"x_train_32 = np.load('..\/input\/siimisic-melanoma-resized-images\/x_train_32.npy')\nx_test_32 = np.load('..\/input\/siimisic-melanoma-resized-images\/x_test_32.npy')","bd4028ad":"x_train_32.shape","5749f134":"x_train_32 = x_train_32.reshape((x_train_32.shape[0], 32*32*3))\nx_train_32.shape","e050c07f":"x_test_32 = x_test_32.reshape((x_test_32.shape[0], 32*32*3))\nx_test_32.shape","cb60b8ca":"y = train.target.values","4410cc6e":"train_oof = np.zeros((x_train_32.shape[0], ))\ntest_preds = 0\ntrain_oof.shape","ef1efac9":"n_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_32)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_32[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_32[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=1, solver='lbfgs', multi_class='multinomial', max_iter=60)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds += model.predict_proba(x_test_32)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()","a32eac96":"print(roc_auc_score(y, train_oof))","a4a361f1":"train_oof_0_2 = np.zeros((x_train_32.shape[0], ))\ntest_preds_0_2 = 0\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_32)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_32[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_32[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=5, solver='lbfgs', multi_class='multinomial', max_iter=80)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof_0_2[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds_0_2 += model.predict_proba(x_test_32)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()\n    \nprint(roc_auc_score(y, train_oof_0_2))","81620f94":"print(roc_auc_score(y, 0.95*train_oof+0.05*train_oof_0_2))","51a2eae3":"train['age_approx'].unique()","1d8b91fe":"train['sex'] = (train['sex'].values == 'male')*1\ntest['sex'] = (test['sex'].values == 'male')*1\ntrain.head()","f222e8f9":"test.head()","9d5d7781":"train['sex'].mean()","20e97c8d":"test['sex'].mean()","45251db1":"train['age_approx'].mean()","4bbb9a0a":"test['age_approx'].mean()","4001fbb9":"train['age_approx'] = train['age_approx'].fillna(train['age_approx'].mean())\ntest['age_approx'] = test['age_approx'].fillna(test['age_approx'].mean())","264eb866":"x_train_32 = np.hstack([x_train_32, train['sex'].values.reshape(-1,1), train['age_approx'].values.reshape(-1,1)])\nx_test_32 = np.hstack([x_test_32, test['sex'].values.reshape(-1,1), test['age_approx'].values.reshape(-1,1)])","d17e73fb":"train_oof_2 = np.zeros((x_train_32.shape[0], ))\ntest_preds_2 = 0\n\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_32)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_32[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_32[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=1, solver='lbfgs', multi_class='multinomial', max_iter=50)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof_2[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds_2 += model.predict_proba(x_test_32)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()","0c9671c4":"print(roc_auc_score(y, train_oof_2))","67962507":"print(roc_auc_score(y, 0.8*train_oof_2+0.2*train_oof))","cad96fc1":"print(roc_auc_score(y, 0.5*train_oof_2+0.5*train_oof))","890152ec":"test_preds.max()","c77d5f29":"test_preds_2.max()","25ffee5b":"train_oof_2_2 = np.zeros((x_train_32.shape[0], ))\ntest_preds_2_2 = 0\n\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_32)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_32[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_32[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=5, solver='lbfgs', multi_class='multinomial', max_iter=80)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof_2_2[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds_2_2 += model.predict_proba(x_test_32)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()","a968420e":"print(roc_auc_score(y, train_oof_2_2))","1c2eea0c":"train['anatom_site_general_challenge'].unique()","081f0030":"test['anatom_site_general_challenge'].unique()","3055e4ed":"train['anatom_site_general_challenge'].mode()","43e226bb":"test['anatom_site_general_challenge'].mode()","2f6d0213":"train['anatom_site_general_challenge'].fillna(train['anatom_site_general_challenge'].mode(), inplace=True)\ntest['anatom_site_general_challenge'].fillna(test['anatom_site_general_challenge'].mode(), inplace=True)","2f0c5d01":"train['anatom_site_general_challenge'] = train['anatom_site_general_challenge'].astype(str)\ntest['anatom_site_general_challenge'] = test['anatom_site_general_challenge'].astype(str)","567c5b8b":"test['anatom_site_general_challenge'].isnull().sum()","5d339360":"x_train_32 = np.hstack([x_train_32, pd.get_dummies(train['anatom_site_general_challenge']).values])\nx_test_32 = np.hstack([x_test_32, pd.get_dummies(test['anatom_site_general_challenge']).values])","d7ab48d8":"train_oof_3 = np.zeros((x_train_32.shape[0], ))\ntest_preds_3 = 0\n\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_32)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_32[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_32[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=1, solver='lbfgs', multi_class='multinomial', max_iter=60)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof_3[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds_3 += model.predict_proba(x_test_32)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()","a668f20e":"print(roc_auc_score(y, train_oof_3))","21350123":"train_oof_4 = np.zeros((x_train_32.shape[0], ))\ntest_preds_4 = 0\n\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_32)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_32[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_32[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=5, max_iter=80)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof_4[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds_4 += model.predict_proba(x_test_32)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()","395e085d":"print(roc_auc_score(y, train_oof_4))","1b624086":"print(roc_auc_score(y, 0.25*train_oof_2+0.25*train_oof+0.25*train_oof_3+0.25*train_oof_4))","f7701445":"1","e99dd968":"im_shape_test = []\nim_shape_train = []\n\nfor i in range(train.shape[0]):\n    im_shape_train.append(imagesize.get('..\/input\/siim-isic-melanoma-classification\/jpeg\/train\/'+train['image_name'][i]+'.jpg'))\nfor i in range(test.shape[0]):\n    im_shape_test.append(imagesize.get('..\/input\/siim-isic-melanoma-classification\/jpeg\/test\/'+test['image_name'][i]+'.jpg'))\n    \n\ntrain['dim'] = im_shape_train\ntest['dim'] = im_shape_test","b59269aa":"train['dim'] == (6000,4000)","cea2f436":"train['dim'] == (1872,1053)","c82e9f21":"(train['dim'] != (6000,4000)) & (train['dim'] != (1872,1053))","f940650d":"train['dim_1'] = (train['dim'] == (6000,4000))\ntrain['dim_1'] = train['dim_1'].values*1\ntrain['dim_2'] = (train['dim'] == (1872,1053))\ntrain['dim_2'] = train['dim_2'].values*1\ntrain['dim_3'] = (train['dim'] != (6000,4000)) & (train['dim'] != (1872,1053))\ntrain['dim_3'] = train['dim_3'].values*1\ntrain['dim_3']","4179bb5d":"test['dim_1'] = (test['dim'] == (6000,4000))\ntest['dim_1'] = test['dim_1'].values*1\ntest['dim_2'] = (test['dim'] == (1872,1053))\ntest['dim_2'] = test['dim_2'].values*1\ntest['dim_3'] = (test['dim'] != (6000,4000)) & (test['dim'] != (1872,1053))\ntest['dim_3'] = test['dim_3'].values*1\ntest['dim_3']","581debac":"x_train_32 = np.hstack([x_train_32, train['dim_1'].values.reshape(-1,1), train['dim_2'].values.reshape(-1,1), train['dim_3'].values.reshape(-1,1)])\nx_test_32 = np.hstack([x_test_32, test['dim_1'].values.reshape(-1,1), test['dim_2'].values.reshape(-1,1), test['dim_3'].values.reshape(-1,1)])","0a82b982":"train_oof_4_2 = np.zeros((x_train_32.shape[0], ))\ntest_preds_4_2 = 0\n\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_32)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_32[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_32[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=0.9, max_iter=50)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof_4_2[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds_4_2 += model.predict_proba(x_test_32)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()\n    \nprint(roc_auc_score(y, train_oof_4_2))","777fe736":"0.8262080489449671","0ad8f7bf":"%%time\npca = PCA(n_components=0.99)\npca.fit(x_train_32)","994b5c9c":"pca.n_components_","d541bcba":"x_train_32 = pca.transform(x_train_32)\nx_test_32 = pca.transform(x_test_32)","eb6e1420":"train_oof_5 = np.zeros((x_train_32.shape[0], ))\ntest_preds_5 = 0\n\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_32)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_32[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_32[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=0.1, max_iter=6)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof_5[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds_5 += model.predict_proba(x_test_32)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()\n    \nprint(roc_auc_score(y, train_oof_5))","31dadac5":"0.7910534268464863","2074bed2":"print(roc_auc_score(y, 0.988*(0.27*train_oof_2+0.27*train_oof+0.27*train_oof_3+0.19*train_oof_4)+0.012*train_oof_5))","d0b31459":"print(roc_auc_score(y, 1.082*(0.99*(0.25*train_oof_2+0.25*train_oof+0.25*train_oof_3+0.25*train_oof_4)+0.01*train_oof_5)-0.082*(train_oof_0_2+train_oof_2_2)\/2))","5a0bf1dc":"x_train_64 = np.load('..\/input\/siimisic-melanoma-resized-images\/x_train_64.npy')\nx_test_64 = np.load('..\/input\/siimisic-melanoma-resized-images\/x_test_64.npy')","04b1b20b":"x_train_64 = x_train_64.reshape((x_train_64.shape[0], 64*64*3))\nx_train_64.shape","f183ab8c":"x_test_64 = x_test_64.reshape((x_test_64.shape[0], 64*64*3))\nx_test_64.shape","4fc0398c":"train_oof_6 = np.zeros((x_train_64.shape[0], ))\ntest_preds_6 = 0\n\n\nn_splits = 5\nkf = KFold(n_splits=n_splits, random_state=137, shuffle=True)\n\nfor jj, (train_index, val_index) in enumerate(kf.split(x_train_64)):\n    print(\"Fitting fold\", jj+1)\n    train_features = x_train_64[train_index]\n    train_target = y[train_index]\n    \n    val_features = x_train_64[val_index]\n    val_target = y[val_index]\n    \n    model = LogisticRegression(C=0.1, max_iter=45)\n    model.fit(train_features, train_target)\n    val_pred = model.predict_proba(val_features)[:,1]\n    train_oof_6[val_index] = val_pred\n    print(\"Fold AUC:\", roc_auc_score(val_target, val_pred))\n    test_preds_6 += model.predict_proba(x_test_64)[:,1]\/n_splits\n    del train_features, train_target, val_features, val_target\n    gc.collect()\n    \nprint(roc_auc_score(y, train_oof_6))","d79a1f2c":"0.8213209504598062","764cebed":"print(roc_auc_score(y, 0.73*(1.1*(0.99*(0.25*train_oof_2+0.25*train_oof+0.25*train_oof_3+0.25*train_oof_4)+0.01*train_oof_5)-0.1*(train_oof_0_2+train_oof_2_2)\/2)+0.27*train_oof_6))","387c4dc6":"print(roc_auc_score(y, 0.9*(0.73*(1.1*(0.99*(0.25*train_oof_2+0.25*train_oof+0.25*train_oof_3+0.25*train_oof_4)+0.01*train_oof_5)-0.1*(train_oof_0_2+train_oof_2_2)\/2)+0.27*train_oof_6)+\n                   0.1*train_oof_4_2))","ca56b1e7":"0.8285058171399994","baea2c3e":"sample_submission = pd.read_csv('..\/input\/siim-isic-melanoma-classification\/sample_submission.csv')\nsample_submission.head()","9d42f0b2":"sample_submission['target'] = 0.9*(0.73*(1.1*(0.99*(0.25*test_preds+0.25*test_preds_2+0.25*test_preds_3+0.25*test_preds_4)+0.015*test_preds_5)- 0.1*(0.5*test_preds_0_2+0.5*test_preds_2_2))+0.27*test_preds_6)+0.1*test_preds_4_2\nsample_submission.to_csv('submission_32x32_64x64_lr.csv', index=False)","4e3fcdd7":"sample_submission['target'].max()","153ab79d":"sample_submission['target'].min()","1ca77ae5":"Let's see what files we have in the input directory:","f7eef8e4":"How about 64x64 images?","1c7897a6":"Taken from raddar's notebook: https:\/\/www.kaggle.com\/raddar\/simple-baseline-revamped","92e5258e":"Now let's make a submission.","1db3edce":"Wow, so we get an 0.82 AUC with just unravelled resized images and a simple Logistic Regression!","ce570132":"## Overview\n\nThe purpose of this kernel is to take a look at the data, come up with some insights, and attempt to create a predictive model or two. This notebook is still **very** raw. I will work on it as my very limited time permits, and hope to expend it in the upcoming days and weeks.\n\n\n## Packages\n\nFirst, let's load a few useful Python packages. This section will keep growing in subsequent versions of this EDA.","da7b1391":"Let's look at the distribution of teh target:","db8d95ed":"Let's take a look at a few images.","02651d70":"Now we will load some of the resized images (32x32 for now) and try to build some simple models. ","f3891592":"Let's now add some non-image features. We can start with sex, and one-hot encode it.","8b987491":"So this is a binary classification problem with highly imbalanced data.","010c31cf":"Let's now look at the distributions of various \"features\""}}