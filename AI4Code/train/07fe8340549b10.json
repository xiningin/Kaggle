{"cell_type":{"e2dcb570":"code","cce31d59":"code","2b1060f2":"code","2e362cad":"code","52a87b48":"code","11fd792c":"code","69462eb2":"code","0c9b6f51":"code","f37502ad":"code","4e657391":"code","149d6033":"code","83df23d8":"code","776d3a1a":"code","177e4e6e":"code","3f473a30":"code","aa11e412":"code","7bbed287":"code","4d0eb3e5":"code","334fd558":"markdown","cb444951":"markdown","bb92efdc":"markdown","7d0f0bd4":"markdown","eca7bd23":"markdown","e9722b38":"markdown","e2630af6":"markdown","fc81003b":"markdown","bf76c9c7":"markdown"},"source":{"e2dcb570":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","cce31d59":"import os\nimport numpy as np\nimport pandas as pd\nfrom sklearn.linear_model import Ridge # Ridge regression model\nimport tensorflow as tf\nfrom wordcloud import STOPWORDS\nfrom sklearn.model_selection import train_test_split,KFold\nimport warnings\nwarnings.filterwarnings(\"ignore\")","2b1060f2":"prev_train_df = pd.read_csv('..\/input\/jigsaw-toxic-comment-classification-challenge\/train.csv')\ntest = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/validation_data.csv')\nsample = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/sample_submission.csv')\ntarget = pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv')","2e362cad":"test=pd.read_csv('..\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv')","52a87b48":"prev_train_df[\"severe_toxic\"] = prev_train_df[\"severe_toxic\"] * 4.5\nprev_train_df[\"threat\"] = prev_train_df[\"threat\"] *5.0\nprev_train_df[\"identity_hate\"] = prev_train_df[\"identity_hate\"] * 4.0\n\nprev_train_df[\"total_toxic\"] = prev_train_df[[\"toxic\", \"severe_toxic\", \"obscene\", \"threat\", \"insult\",\n                                              \"identity_hate\"]].sum(axis = 1).astype(np.int64)","11fd792c":"train_df = prev_train_df[[\"comment_text\", \"total_toxic\"]]","69462eb2":"train_df[\"Comment\"] = train_df['comment_text'].str.replace('[^\\w\\s\\n]','')\ntrain_df.head()","0c9b6f51":"train_df.drop(['comment_text'],axis=1)","f37502ad":"text=train_df.loc[1:70001,['Comment']]\ntarget=train_df.loc[1:70000,['total_toxic']]","4e657391":"train_df['text'] = train_df['Comment'].apply(lambda x:x.lower())","149d6033":"import nltk\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words(\"english\"))","83df23d8":"#removing the stop words from the corpus\ntrain_df['filter1'] =train_df['text'].apply(lambda x:' '.join([word for word in x.split() if word not in (stop_words)]))","776d3a1a":"train_df['filter1']","177e4e6e":"from sklearn.feature_extraction.text import TfidfVectorizer\ntfvec = TfidfVectorizer(analyzer = 'char_wb', ngram_range = (3,5))\ntfv = tfvec.fit_transform(train_df[\"filter1\"])","3f473a30":"X=tfv\nY=train_df['total_toxic']","aa11e412":"rr_model = Ridge(alpha=0.5)\nrr_model.fit(X,Y)","7bbed287":"tfv_comments = tfvec.transform(test[\"text\"])\npred = rr_model.predict(tfv_comments)","4d0eb3e5":"sub = pd.DataFrame()\nsub[\"comment_id\"] = test[\"comment_id\"]\nsub[\"score\"] = pred*200\nsub.to_csv('submission.csv',index=False)\nsub","334fd558":"**Data cleaning--1**","cb444951":"**Libraries Required**","bb92efdc":"**Vectorization**","7d0f0bd4":"**Splitting data into train and test**","eca7bd23":"**Data selection**","e9722b38":"**Datasources**","e2630af6":"**Custom weights to existing columns**","fc81003b":"**Data cleaning --2**","bf76c9c7":"**Ridge modelling**"}}