{"cell_type":{"ee8899b7":"code","dac7a200":"code","5ef0b33a":"code","c23a2310":"code","dc6655ad":"code","4ff67a16":"code","81fe3d99":"code","443a269f":"code","f7102e79":"code","d430f416":"code","b2c65096":"code","01d453db":"code","038fdf26":"code","27af7f9b":"code","278db849":"code","5913eade":"code","ffbe0656":"code","12224b97":"code","bad3c075":"code","13eb0bc3":"code","9bcdb738":"code","35629c0a":"code","08de1d9d":"code","245f1134":"code","ad963464":"code","5b447653":"code","130bf3d1":"code","21f18dbe":"code","38916d81":"code","d19a695e":"code","5b882f02":"code","0af41f92":"code","48de37d9":"code","ec85d1d2":"code","4b485b8c":"code","8b8d6880":"code","92c69599":"code","101efcce":"code","73972c59":"code","cc4034e6":"code","4dda431d":"code","e5699ee8":"code","57071967":"code","dc46436d":"code","28e8747d":"code","20de9970":"code","5c921772":"code","360f41df":"code","c84f1b58":"code","8b88cf42":"code","3bd942f8":"code","faf7c78f":"code","05079562":"code","5e0bb09a":"code","447b8e96":"code","e1a1cf17":"code","f9636924":"code","07d0ba0e":"code","b62ebf8f":"code","07d3cf48":"code","a8ded85e":"code","ac0f1a8b":"code","9890e375":"code","19e5e48e":"code","272a2715":"code","7c292894":"code","6521400b":"code","bdc54756":"code","02e4a5ae":"code","fa8a732b":"code","516cc8a6":"code","3e33911d":"code","a4fd555c":"code","552021d5":"code","6110dfe9":"code","e277bdc3":"code","c64c7c49":"code","4c8c7bb3":"markdown","2117ea99":"markdown","297594d5":"markdown","888922f2":"markdown","49f728a7":"markdown","b843a89d":"markdown","211a4366":"markdown","fd804993":"markdown","14be28b2":"markdown","987c6283":"markdown","f8a4690c":"markdown","81fb3c7f":"markdown","895b8031":"markdown","23a551ab":"markdown","ebf8dc52":"markdown","ca7432b5":"markdown","dec18206":"markdown","73a26c73":"markdown","279cea1f":"markdown"},"source":{"ee8899b7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","dac7a200":"\nimport matplotlib.pyplot as plt \nimport seaborn as sns\n%matplotlib inline \nplt.style.use(\"ggplot\")\nfrom matplotlib import colors\nimport re\nttnc = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntest_set = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_set.info()","5ef0b33a":"ttnc.head(5)","c23a2310":"ttnc.info()","dc6655ad":"test_set.info()","4ff67a16":"ttnc.describe()","81fe3d99":"y_train   = ttnc[\"Survived\"]\nttnc1 = ttnc.drop([\"Survived\"],axis = 1 )\ncombined = ttnc.append(test_set)\ncombined.reset_index(inplace=True)\ncombined.drop(['index'], inplace=True, axis=1)\n\ncombined.head(5)","443a269f":"combined.isnull().sum()","f7102e79":"ttnc.corr()","d430f416":"sns.heatmap(ttnc.corr())","b2c65096":"from sklearn.preprocessing import LabelEncoder\nlabel = LabelEncoder()","01d453db":"plt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\nsns.countplot(x = ttnc[\"Sex\"])\nplt.title(\"x_train\")\nplt.subplot(1,3,2)\nsns.countplot(x = test_set[\"Sex\"])\nplt.title(\"x_test\")\nplt.subplot(1,3,3)\nsns.countplot(x = combined[\"Sex\"])\nplt.title(\"combined\")","038fdf26":"#visualizing pie chart\nfig,ax = plt.subplots(figsize = (10,7))\n#size and explosion\nsize_out =3\nsize_in= 1\nexplode_out = (0.2,0.2)\nexplode_in = (0.3,0.3,0.3,0.3,0.3,0.3)\ncmap = plt.get_cmap(\"tab20c\")\nouter_colors = cmap(np.array([8,0]))\ninner_colors = cmap(np.array([11,10,9,3,2,1]))\npatches1,texts1,autotexts1 = ax.pie(ttnc.groupby([\"Sex\"]).count()[\"Name\"],radius = 3, colors = outer_colors,\n                                   labels =ttnc.groupby([\"Sex\"]).count()[\"Name\"].index, autopct = \"%1.1f%%\",pctdistance =0.85,\n                                   wedgeprops = dict(width = size_out,edgecolor = \"black\"),explode=explode_out)\npatches2, texts2, autotexts2 = ax.pie(ttnc.groupby([\"Sex\",\"Pclass\"]).count().Name,radius = 2, colors =inner_colors,\n                                     labels = [1,2,3,1,2,3],autopct = \"%1.1f%%\",labeldistance = 0.88, pctdistance = 0.55,\n                                     wedgeprops = dict(width = size_in, edgecolor = \"black\"), explode = explode_in)\n#centre circle\ncenter_circle = plt.Circle((0,0),1.5,color = \"black\", fc = \"white\", linewidth = 0)\nfig = plt.gcf()\nplt.gca().add_artist(center_circle)\nfor t in texts1:\n    t.set_size(\"large\")\nfor t in autotexts1:\n    t.set_size(\"large\")\nfor t in texts2:\n    t.set_size(\"large\")\nfor t in autotexts2:\n    t.set_size(\"large\")\n# Setting legend\nax.legend(loc='lower right', bbox_to_anchor=(0.7, 0., 0.5, 0.5), shadow=1,title='Legend',\n          handletextpad=1, labelspacing=0.5 , fontsize='12', labels=['female','male','1. class','2. class', '3. class','1. class','2. class', '3. class'])    \nax.set(aspect=\"equal\", title='Gender Distribution')\nplt.axis('equal')\nplt.show() ","27af7f9b":"plt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\nsns.countplot(x = ttnc[\"Pclass\"])\nplt.title(\"x_train\")\nplt.subplot(1,3,2)\nsns.countplot(x = test_set[\"Pclass\"])\nplt.title(\"x_test\")\nplt.subplot(1,3,3)\nsns.countplot(x = combined[\"Pclass\"])\nplt.title(\"combined\")","278db849":"plt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\nsns.countplot(x = ttnc[\"Embarked\"])\nplt.title(\"x_train\")\nplt.subplot(1,3,2)\nsns.countplot(x = test_set[\"Embarked\"])\nplt.title(\"x_test\")\nplt.subplot(1,3,3)\nsns.countplot(x = combined[\"Embarked\"])\nplt.title(\"combined\")","5913eade":"#filling NaN values with mode of the data\ncombined[\"Embarked\"].fillna(\"S\",inplace = True)","ffbe0656":"figure = plt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\n#ttnc[\"Age\"].plot(kind = \"hist\" )\nsns.histplot(x = ttnc[\"Age\"],kde = True)\nplt.title(\"x_train\")\nplt.subplot(1,3,2)\nsns.histplot(x = test_set[\"Age\"],kde = True)\nplt.title(\"x_test\")\nplt.subplot(1,3,3)\nsns.histplot(x = combined[\"Age\"],kde = True)\nplt.title(\"combined\")\n","12224b97":"# filling null values with age value whose data is similar to missing value data\nage_median = ttnc.groupby([\"Sex\",\"Pclass\",\"Embarked\"]).median()\nage_median_x = age_median.reset_index()[[\"Sex\",\"Pclass\",\"Embarked\",\"Age\"]]\n\ndef age_filler(row):\n    \n    cndtn = ((age_median_x[\"Sex\"]==row[\"Sex\"])&(age_median_x[\"Pclass\"]==row[\"Pclass\"])&(age_median_x[\"Embarked\"]==row[\"Embarked\"]))\n    return age_median_x[cndtn][\"Age\"].values[0]\ncombined[\"Age\"] = combined.apply(lambda row :age_filler(row) if np.isnan(row[\"Age\"])else row[\"Age\"],axis=1)","bad3c075":"#after filling null values\nfigure = plt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\nsns.histplot(x = ttnc[\"Age\"],kde = True)\nplt.title(\"x_train\")\nplt.subplot(1,3,2)\nsns.histplot(x = test_set[\"Age\"],kde = True)\nplt.title(\"x_test\")\nplt.subplot(1,3,3)\nsns.histplot(x = combined[\"Age\"],kde = True)\nplt.title(\"combined\")","13eb0bc3":"combined.groupby([\"Sex\",\"Survived\"])[\"Age\"].mean()","9bcdb738":"plt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\nsns.histplot(ttnc[\"Fare\"], kde = True)\nplt.title(\"x_train\")\nplt.subplot(1,3,2)\nsns.histplot(test_set[\"Fare\"],kde = True)\nplt.title(\"x_test\")\nplt.subplot(1,3,3)\nsns.histplot(combined[\"Fare\"],kde = True)\nplt.title(\"combined\")","35629c0a":"combined[\"Fare\"].fillna(0,inplace = True)","08de1d9d":"#after filling null values\nplt.figure(figsize = (15,5))\nplt.subplot(1,3,1)\nsns.histplot(ttnc[\"Fare\"], kde = True)\nplt.title(\"x_train\")\nplt.subplot(1,3,2)\nsns.histplot(test_set[\"Fare\"],kde = True)\nplt.title(\"x_test\")\nplt.subplot(1,3,3)\nsns.histplot(combined[\"Fare\"],kde = True)\nplt.title(\"combined\")","245f1134":"combined[\"Fare\"].skew()","ad963464":"#Fare festure is skewed so let's apply log algorithm in order to make the distribution near to normal distribution\ncombined[\"Fare\"] = [np.log(x) if x>0 else 0 for x in combined[\"Fare\"]]","5b447653":"combined[\"Fare\"].skew()","130bf3d1":"sns.histplot(combined[\"Fare\"],kde = True)\nplt.title(\"combined\")","21f18dbe":"combined[\"Fare\"] = combined[\"Fare\"].astype(int)","38916d81":"combined.groupby(\"Sex\")[\"Survived\"].value_counts(normalize = True).plot(kind = \"bar\")","d19a695e":"ttnc.groupby(\"Sex\")[\"Survived\"].value_counts(normalize = True).plot(kind = \"pie\")","5b882f02":"combined.groupby([\"Pclass\",\"Sex\"])[\"Survived\"].value_counts(normalize = True).plot(kind = \"bar\")","0af41f92":"combined.groupby([\"Pclass\",\"Sex\"])[\"Survived\"].value_counts().plot(kind = \"bar\")","48de37d9":"combined.groupby(\"Pclass\")[\"Survived\"].value_counts().plot(kind = \"pie\")","ec85d1d2":"combined.groupby(\"Pclass\")[\"Survived\"].value_counts().plot(kind = \"bar\")","4b485b8c":"sns.countplot(x = \"Parch\",data = combined,hue = \"Survived\" )","8b8d6880":"sns.countplot(x = \"SibSp\",data = combined,hue = \"Survived\")","92c69599":"combined[\"Ticket\"] = combined[\"Ticket\"].apply(lambda x: x if x.isdigit() else re.sub(\"\\D\",\"\",x))","101efcce":"def column_add(df):\n    df[\"Fmly_tgthr\"] = df[\"Parch\"] +df[\"SibSp\"] +1\n    df[\"Pclass_sex\"] = df[\"Pclass\"].astype(str) + df[\"Sex\"]\n    #df[\"pclass_sex\"] =  le.fit_transform(df[\"pclass_sex\"])\n    #df[\"Sex\"] =  le.fit_transform(df[\"Sex\"])\n    return \ncolumn_add(combined)","73972c59":"from scipy.stats import pearsonr\npearsonr(combined.loc[:890,\"Survived\"],combined.loc[:890,\"Fmly_tgthr\"])","cc4034e6":"sns.countplot(x = \"Fmly_tgthr\",data = combined,hue = \"Survived\")","4dda431d":"combined[\"Last_name\"]  = combined['Name'].str.extract('([A-Za-z]+)\\,', expand=False)\nlen(combined[\"Last_name\"].unique() )","e5699ee8":"Title_Dictionary = {\n    \"Capt\": \"Officer\",\n    \"Col\": \"Officer\",\n    \"Major\": \"Officer\",\n    \"Jonkheer\": \"Royalty\",\n    \"Don\": \"Royalty\",\n    \"Sir\" : \"Royalty\",\n    \"Dr\": \"Officer\",\n    \"Rev\": \"Officer\",\n    \"the Countess\":\"Royalty\",\n    \"Mme\": \"Mrs\",\n    \"Mlle\": \"Miss\",\n    \"Ms\": \"Mrs\",\n    \"Mr\" : \"Mr\",\n    \"Mrs\" : \"Mrs\",\n    \"Miss\" : \"Miss\",\n    \"Master\" : \"Master\",\n    \"Lady\" : \"Royalty\"\n}\ndef get_titles():\n    # we extract the title from each name\n    combined['Title'] = combined['Name'].map(lambda name:name.split(',')[1].split('.')[0].strip())\n    \n    # a map of more aggregated title\n    # we map each title\n    combined['Title'] = combined.Title.map(Title_Dictionary)\n\n    return combined\ncombined = get_titles()","57071967":"combined[\"Title\"].fillna(\"Royalty\", inplace = True)","dc46436d":"combined.groupby([\"Sex\",\"Title\"])[\"Survived\"].mean().plot(kind = \"bar\")","28e8747d":"sns.countplot(x = \"Fmly_tgthr\",data = combined,hue = \"Survived\")","20de9970":"combined.groupby([\"Sex\",\"Fmly_tgthr\",\"Title\"])[\"Survived\"].mean().plot(kind = \"bar\")","5c921772":"default_family_survival = 0.5\ncombined[\"Family_survival\"] = default_family_survival\nfor _,grp_df in combined.groupby([\"Last_name\",\"Fare\"]):\n         if (len(grp_df) != 1):\n            # A Family group is found.\n            for ind, row in grp_df.iterrows():\n                smax = grp_df.drop(ind)['Survived'].max()\n                smin = grp_df.drop(ind)['Survived'].min()\n                passID = row['PassengerId']\n                if (smax == 1.0):\n                    combined.loc[combined['PassengerId'] == passID, 'Family_survival'] = 1\n                elif (smin==0.0):\n                    combined.loc[combined['PassengerId'] == passID, 'Family_survival'] = 0\n\nprint(\"Number of passengers with family survival information:\", \n     combined.loc[combined['Family_survival']!=0.5].shape[0])","360f41df":"for _ , grp_df in combined.groupby(\"Ticket\"):\n    for ind, row in grp_df.iterrows():\n        if (row[\"Family_survival\"] == 0) | (row[\"Family_survival\"]== 0.5):\n            smax = grp_df.drop(ind)[\"Survived\"].max()\n            smin = grp_df.drop(ind)[\"Survived\"].min()\n            passID = row['PassengerId']\n            if (smax == 1.0):\n                    combined.loc[combined['PassengerId'] == passID, 'Family_survival'] = 1\n            elif (smin==0.0):\n                    combined.loc[combined['PassengerId'] == passID, 'Family_survival'] = 0\n\nprint(\"Number of passengers with family survival information:\", \n      combined.loc[combined['Family_survival']!=0.5].shape[0])","c84f1b58":"#encoding each features as categorical \ndef encoder(df_full,feature, bin_number=5, train_size=891):\n    unique_features = len(list(df_full[feature].unique()))\n    if unique_features > 10:\n            df_full[feature + '_bin'] = pd.qcut(df_full[feature], bin_number)\n            ttnc[feature + '_bin'] = df_full[feature + '_bin'][:train_size]\n            test_set[feature + '_bin'] = df_full[feature + '_bin'][train_size:]\n            label = LabelEncoder()\n            df_full[feature + '_bin_code'] = label.fit_transform(df_full[feature + '_bin'].astype(str))\n            ttnc[feature + '_bin_code'] = df_full[feature + '_bin_code'][:train_size]\n            test_set[feature + '_bin_code'] = df_full[feature + '_bin_code'][train_size:]\n    else:\n        print('Number of unique features is %d, binning not needed. ' % unique_features)\n        # define LabelEncoder instance \n        label = LabelEncoder()\n        # fit and transform the data\n        df_full[feature + '_code'] = label.fit_transform(df_full[feature])\n        # assign the encoded bins to the train and test dataframe\n        ttnc[feature + '_code'] = df_full[feature + '_code'][:train_size]\n        test_set[feature + '_code'] = df_full[feature + '_code'][train_size:]\n        # calculate the statistics for not binned features\n        impact = df_full[[feature, 'Survived']].groupby([feature]).agg(['sum','count','mean']).rename(columns={'sum':'Yes','count':'Total','mean':'In %'})\n    return \n\n","8b88cf42":"encoder(combined,\"Fare\",5,891)\nencoder(combined,\"Age\",5,891)\nencoder(combined,\"Pclass_sex\",5,891)\nencoder(combined,\"Sex\",5,891)\nencoder(combined,\"Title\")\nencoder(combined,\"Embarked\")\nencoder(combined,\"PassengerId\")\nencoder(combined,\"Pclass\")\nencoder(combined,\"Fmly_tgthr\")","3bd942f8":"sns.countplot(x = combined[\"Age_bin_code\"])","faf7c78f":"combined.groupby(\"Age_bin_code\")[\"Survived\"].mean()","05079562":"combined.groupby([\"Sex\",\"Survived\"])[\"Age_bin_code\"].value_counts()","5e0bb09a":"plt.figure(figsize = (20,5))\nsns.catplot(x = \"Age_bin_code\",y = \"Fare\",hue = \"Survived\",data = combined)\nplt.xticks(rotation = 90)\nplt.show()","447b8e96":"plot_age = sns.FacetGrid(combined,col= \"Sex\")\nplot_age.map(sns.countplot,x = combined[\"Age_bin_code\"],hue= combined[\"Survived\"])\nplt.xticks(rotation =90)\nplt.legend()","e1a1cf17":"plot_age = sns.FacetGrid(combined,col= \"Sex\")\nplot_age.map(sns.countplot,x = combined[\"Age_bin_code\"],hue= combined[\"Survived\"])\nplt.xticks(rotation =90)\nplt.xlabel(\"age_category\")\nplt.legend()","f9636924":"combined.columns","07d0ba0e":"combined1 = combined.drop([\"Name\",\"Ticket\",\"Cabin\",\"Survived\",\"Last_name\",'PassengerId','Pclass',\n                          'Sex', 'Age', 'SibSp','Parch','Fare','Embarked','Title','PassengerId_bin','Age_bin',\n                          'Pclass_sex','Fmly_tgthr','Embarked_code'],axis = 1)\nx_train = combined1.iloc[:891]\n\nx_test = combined1.iloc[891:]","b62ebf8f":"combined1.head(5)","07d3cf48":"(x_train.shape,x_test.shape)","a8ded85e":"from sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nsgd_clf = SGDClassifier(loss = \"log\")\nsgd_clf.fit(x_train,y_train)\nlr = LogisticRegression()\nlr.fit(x_train,y_train)\nsvc = SVC(probability = True)\nsvc.fit(x_train,y_train)\ndc =  DecisionTreeClassifier()\ndc.fit(x_train,y_train)\nrf =RandomForestClassifier()\nrf.fit(x_train,y_train)","ac0f1a8b":"rfc_2 = RandomForestClassifier(max_depth= 10,n_estimators = 50,oob_score = True,random_state =42)\nrfc_2.fit(x_train,y_train)","9890e375":"features = pd.DataFrame()\nfeatures['feature'] = x_train.columns\nfeatures['importance'] = rfc_2.feature_importances_\nfeatures.sort_values(by=['importance'], ascending=True, inplace=True)\nfeatures.set_index('feature', inplace=True)\nfeatures.plot(kind='barh', figsize=(25, 25))","19e5e48e":"x_train.head(5)","272a2715":"x_test.head(5)","7c292894":"params ={'n_estimators': [400,450,500,550],\n                                  'bootstrap': [True],\n                                  'max_depth': [15, 20, 25],\n            \n                                  'min_samples_leaf': [2,3,5],\n                                  'min_samples_split': [2,3,4,8]}","6521400b":"from sklearn.model_selection import GridSearchCV\nfrom sklearn.model_selection import RandomizedSearchCV\ngd = GridSearchCV(rf,params,cv = 3)","bdc54756":"gd.fit(x_train,y_train)\ngd.best_score_","02e4a5ae":"gd.best_estimator_","fa8a732b":"rfc_3 = gd.best_estimator_","516cc8a6":"def score(est):\n    s_train = est.score(x_train,y_train)\n    score = cross_val_score(est,x_train,y_train,cv =3,scoring = \"accuracy\")\n    return (\"the r2 for training set is\" ,s_train,\n            \"mean score of cross-validation is\", score.mean())\n","3e33911d":"score(rfc_3)","a4fd555c":"rfc_3.fit(x_train,y_train)","552021d5":"test_score = rfc_3.predict(x_test)","6110dfe9":"prediction = pd.DataFrame({\"PassengerId\":range(892,1310,1),\"Survived\" :test_score})\n#prediction1 = pd.DataFrame({\"PassengerId\":range(892,1310,1),\"Survived\" :test_score1})","e277bdc3":"prediction.to_csv('submission_finalv1.csv', index=False)\n","c64c7c49":"prediction","4c8c7bb3":"## age","2117ea99":"## continuous data","297594d5":"## model","888922f2":"## new features","49f728a7":"## Gender","b843a89d":"we can see that no. of male in 3rd class is significantly huge and 3rd class people faced more diffciulties due to being on lower floor and it is believable that female and children were the priority to rescue, that explains us about man dying in large percentile then women","211a4366":"## parch","fd804993":"## Exploratory analysis","14be28b2":"## Pclass","987c6283":"## Fare","f8a4690c":"## survived","81fb3c7f":"## categorical data","895b8031":"## Embarked","23a551ab":"## SibSp","ebf8dc52":"We can see that male and female whose survived were not so young or old","ca7432b5":"## Feature Encoding","dec18206":"## Ticket","73a26c73":"We can see here that females from 3rd class have higher survival ratio from men, even regardless of class this pattern is consistent","279cea1f":"## Train and test data"}}