{"cell_type":{"3f8b32be":"code","2a4bb357":"code","a75118ed":"code","b12bb207":"code","05a02366":"code","a62351f9":"code","91c7cbe9":"code","a14b83e3":"code","a3de5949":"code","e2724157":"code","a67d318f":"code","d7fe41d7":"code","ac8b4dc5":"code","eaf5fdeb":"code","ea73dca0":"code","bc98ea97":"code","549da7c5":"code","d99c4178":"code","88c3e42f":"code","dda1be46":"code","f5ed8969":"code","479366a9":"code","40daa1b8":"code","7797d7a6":"code","1409b0dd":"code","7de01674":"code","878b0e5a":"code","e0aa1d9e":"code","c77d63a6":"code","6373670e":"code","627eb618":"code","f5a6dced":"code","b127f8f5":"code","7570798d":"code","136ef6ca":"code","c7dfad98":"code","fed8baac":"code","1ec9948d":"code","864c728a":"markdown","f5b15142":"markdown","b0704c72":"markdown","8cb0d847":"markdown","66d25d9b":"markdown","9e965475":"markdown","36084aec":"markdown","95d032c2":"markdown","40acde42":"markdown","4b550200":"markdown","1a1835f2":"markdown","4a9ecc90":"markdown","96486245":"markdown"},"source":{"3f8b32be":"import numpy as np\nimport pandas as pd\n\nimport plotly.express as px\nfrom plotly.subplots import make_subplots\nimport plotly.graph_objs as go\nimport matplotlib.pyplot as plt\n\n\nimport riiideducation","2a4bb357":"types = {\n        'row_id': 'int64', \n        'timestamp': 'int64', \n        'user_id': 'int32', \n        'content_id': 'int16', \n        'content_type_id': 'int8',\n        'task_container_id': 'int16', \n        'user_answer': 'int8', \n        'answered_correctly': 'int8', \n        'prior_question_elapsed_time': 'float32', \n        'prior_question_had_explanation': 'boolean'\n}","a75118ed":"train_df = pd.read_csv(\n    '\/kaggle\/input\/riiid-test-answer-prediction\/train.csv', \n    low_memory=False, \n    nrows=10**6, \n    dtype=types\n)","b12bb207":"train_df.head(10)","05a02366":"train_df.info()","a62351f9":"print('Part of missing values for every column')\nprint(train_df.isnull().sum() \/ len(train_df))","91c7cbe9":"#1 year = 31536000000 ms\nts = train_df['timestamp']\/(31536000000\/12)\nfig = plt.figure(figsize=(12,6))\nts.plot.hist(bins=100)\nplt.title(\"Histogram of timestamp\")\nplt.xticks(rotation=0)\nplt.xlabel(\"Months between this user interaction and the first event completion from that user\")\nplt.show()","a14b83e3":"print(f'Of the {train_df.user_id.nunique()} users in train we have {train_df[train_df.timestamp == 0].user_id.nunique()} users with a timestamp zero row.')","a3de5949":"WIDTH = 800","e2724157":"ds = train_df['user_id'].value_counts().reset_index()\n\nds.columns = [\n    'user_id', \n    'count'\n]\n\nds['user_id'] = ds['user_id'].astype(str) + '-'\nds = ds.sort_values(['count']).tail(40)\n\nfig = px.bar(\n    ds, \n    x='count', \n    y='user_id', \n    orientation='h', \n    title='Top 40 users by number of actions', \n    width=WIDTH,\n    height=900 \n)\n\nfig.show()","a67d318f":"ds = train_df['user_id'].value_counts().reset_index()\n\nds.columns = [\n    'user_id', \n    'count'\n]\n\nds = ds.sort_values('user_id')\n\nfig = px.line(\n    ds, \n    x='user_id', \n    y='count', \n    title='User action distribution', \n    width=WIDTH,\n    height=600 \n)\n\nfig.show()","d7fe41d7":"ds = train_df['content_id'].value_counts().reset_index()\n\nds.columns = [\n    'content_id', \n    'count'\n]\n\nds['content_id'] = ds['content_id'].astype(str) + '-'\nds = ds.sort_values(['count']).tail(40)\n\nfig = px.bar(\n    ds, \n    x='count', \n    y='content_id', \n    orientation='h', \n    title='Top 40 most used content_ids',  \n    width=WIDTH,\n    height=900\n)\n\nfig.show()","ac8b4dc5":"ds = train_df['content_id'].value_counts().reset_index()\n\nds.columns = [\n    'content_id', \n    'count'\n]\n\nds = ds.sort_values('content_id')\n\nfig = px.line(\n    ds, \n    x='content_id', \n    y='count', \n    title='content_id action distribution', \n    width=WIDTH,\n    height=600 \n)\n\nfig.show()","eaf5fdeb":"ds = train_df['content_type_id'].value_counts().reset_index()\n\nds.columns = [\n    'content_type_id', \n    'percent'\n]\n\nds['percent'] \/= len(train_df)\n\nfig = px.pie(\n    ds, \n    names='content_type_id', \n    values='percent', \n    title='Lecures & questions', \n    width=WIDTH,\n    height=500 \n)\n\nfig.show()","ea73dca0":"ds = train_df['task_container_id'].value_counts().reset_index()\n\nds.columns = [\n    'task_container_id', \n    'count'\n]\n\nds['task_container_id'] = ds['task_container_id'].astype(str) + '-'\nds = ds.sort_values(['count']).tail(40)\n\nfig = px.bar(\n    ds, \n    x='count', \n    y='task_container_id', \n    orientation='h', \n    title='Top 40 most useful task_container_ids', \n    width=WIDTH,\n    height=900\n)\n\nfig.show()","bc98ea97":"ds = train_df['task_container_id'].value_counts().reset_index()\n\nds.columns = [\n    'task_container_id', \n    'count'\n]\n\nds = ds.sort_values('task_container_id')\n\nfig = px.line(\n    ds, \n    x='task_container_id', \n    y='count', \n    title='task_container_id action distribution', \n    width=WIDTH,\n    height=600  \n)\n\nfig.show()","549da7c5":"ds = train_df['user_answer'].value_counts().reset_index()\n\nds.columns = [\n    'user_answer', \n    'percent_of_answers'\n]\n\nds['percent_of_answers'] \/= len(train_df)\nds = ds.sort_values(['percent_of_answers'])\n\nfig = px.bar(\n    ds, \n    x='user_answer', \n    y='percent_of_answers', \n    orientation='v', \n    title='Percent of user answers for every option', \n    width=WIDTH,\n    height=400 \n)\n\nfig.show()","d99c4178":"ds = train_df['answered_correctly'].value_counts().reset_index()\n\nds.columns = [\n    'answered_correctly', \n    'percent_of_answers'\n]\n\nds['percent_of_answers'] \/= len(train_df)\nds = ds.sort_values(['percent_of_answers'])\n\nfig = px.pie(\n    ds, \n    names='answered_correctly', \n    values='percent_of_answers', \n    title='Percent of correct answers', \n    width=WIDTH,\n    height=500 \n)\n\nfig.show()","88c3e42f":"fig = make_subplots(rows=3, cols=2)\n\ntraces = [\n    go.Bar(\n        x=[\n            -1, 0, 1\n        ], \n        y=[\n            len(train_df[(train_df['user_answer'] == item) & (train_df['answered_correctly'] == -1)]),\n            len(train_df[(train_df['user_answer'] == item) & (train_df['answered_correctly'] == 0)]),\n            len(train_df[(train_df['user_answer'] == item) & (train_df['answered_correctly'] == 1)])\n        ], \n        name='Option: ' + str(item),\n        text = [\n            str(round(100 * len(train_df[(train_df['user_answer'] == item) & (train_df['answered_correctly'] == -1)]) \/ len(train_df[(train_df['user_answer'] == item)]), 2)) + '%',\n            str(round(100 * len(train_df[(train_df['user_answer'] == item) & (train_df['answered_correctly'] == -0)]) \/ len(train_df[(train_df['user_answer'] == item)]), 2)) + '%',\n            str(round(100 * len(train_df[(train_df['user_answer'] == item) & (train_df['answered_correctly'] == 1)]) \/ len(train_df[(train_df['user_answer'] == item)]), 2)) + '%',\n        ],\n        textposition='auto'\n    ) for item in train_df['user_answer'].unique().tolist()\n]\n\nfor i in range(len(traces)):\n    fig.append_trace(\n        traces[i], \n        (i \/\/ 2) + 1, \n        (i % 2)  + 1\n    )\n\nfig.update_layout(\n    title_text='Percent of correct answers for every option',\n    height=900,\n    width=WIDTH\n)\n\nfig.show()","dda1be46":"fig = px.histogram(\n    train_df, \n    x=\"prior_question_elapsed_time\",\n    nbins=50,\n    title='prior_question_elapsed_time distribution',\n    width=WIDTH,\n    height=500\n)\n\nfig.show()","f5ed8969":"questions = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/questions.csv')","479366a9":"questions.head(10)","40daa1b8":"questions.info()","7797d7a6":"print('Part of missing values for every column')\nprint(questions.isnull().sum() \/ len(questions))","1409b0dd":"questions['tag'] = questions['tags'].str.split(' ')\nquestions = questions.explode('tag')\nquestions = pd.merge(\n    questions, \n    questions.groupby('question_id')['tag'].count().reset_index(), \n    on='question_id'\n)\n\nquestions = questions.drop(['tag_x'], axis=1)\n\nquestions.columns = [\n    'question_id', \n    'bundle_id', \n    'correct_answer', \n    'part', \n    'tags', \n    'tags_number'\n]\n\nquestions = questions.drop_duplicates()","7de01674":"ds = questions['correct_answer'].value_counts().reset_index()\n\nds.columns = [\n    'correct_answer', \n    'number_of_answers'\n]\n\nds['correct_answer'] = ds['correct_answer'].astype(str) + '-'\nds = ds.sort_values(['number_of_answers'])\n\nfig = px.bar(\n    ds, \n    x='number_of_answers', \n    y='correct_answer', \n    orientation='h', \n    title='Number of correct answers per group', \n    width=WIDTH,\n    height=300\n)\n\nfig.show()","878b0e5a":"ds = questions['part'].value_counts().reset_index()\n\nds.columns = [\n    'part', \n    'count'\n]\n\nds['part'] = ds['part'].astype(str) + '-'\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y='part', \n    orientation='h', \n    title='Parts distribution',\n    width=WIDTH,\n    height=400\n)\n\nfig.show()","e0aa1d9e":"ds = questions['tags_number'].value_counts().reset_index()\n\nds.columns = [\n    'tags_number', \n    'count'\n]\n\nds['tags_number'] = ds['tags_number'].astype(str) + '-'\nds = ds.sort_values(['tags_number'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y='tags_number', \n    orientation='h', \n    title='Number tags distribution', \n    width=WIDTH,\n    height=400 \n)\n\nfig.show()","c77d63a6":"check = questions['tags'].str.split(' ').explode('tags').reset_index()\ncheck = check['tags'].value_counts().reset_index()\n\ncheck.columns = [\n    'tag', \n    'count'\n]\n\ncheck['tag'] = check['tag'].astype(str) + '-'\ncheck = check.sort_values(['count']).tail(30)\n\nfig = px.bar(\n    check, \n    x='count', \n    y='tag', \n    orientation='h', \n    title='Top 30 most useful tags', \n    width=WIDTH,\n    height=900 \n)\n\nfig.show()","6373670e":"lectures = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/lectures.csv')\nlectures.head(10)","627eb618":"lectures.info()","f5a6dced":"print('Part of missing values for every column')\nprint(lectures.isnull().sum() \/ len(lectures))","b127f8f5":"ds = lectures['tag'].value_counts().reset_index()\n\nds.columns = [\n    'tag', \n    'count'\n]\n\nds['tag'] = ds['tag'].astype(str) + '-'\nds = ds.sort_values(['count']).tail(40)\n\nfig = px.bar(\n    ds, \n    x='count', \n    y='tag', \n    orientation='h', \n    title='Top 40 lectures by number of tags', \n    height=900, \n    width=WIDTH\n)\n\nfig.show()","7570798d":"ds = lectures['part'].value_counts().reset_index()\n\nds.columns = [\n    'part', \n    'count'\n]\n\nds['part'] = ds['part'].astype(str) + '-'\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y='part', \n    orientation='h', \n    title='Parts distribution', \n    height=400, \n    width=WIDTH\n)\n\nfig.show()","136ef6ca":"ds = lectures['type_of'].value_counts().reset_index()\n\nds.columns = [\n    'type_of', \n    'count'\n]\n\nds = ds.sort_values(['count'])\n\nfig = px.bar(\n    ds, \n    x='count', \n    y='type_of', \n    orientation='h', \n    title='type_of lectures', \n    height=300, \n    width=WIDTH\n)\n\nfig.show()","c7dfad98":"test_ex = pd.read_csv('\/kaggle\/input\/riiid-test-answer-prediction\/example_test.csv')\ntest_ex","fed8baac":"test_ex.info()","1ec9948d":"print('Part of missing values for every column')\nprint(test_ex.isnull().sum() \/ len(test_ex))","864c728a":"Let's look at the data and main columns properties:","f5b15142":"<a id=\"2\"><\/a>\n<h2><center>2. questions.csv<center><h2>","b0704c72":"\n<div class=\"list-group\" id=\"list-tab\" role=\"tablist\">\n<h2 class=\"list-group-item list-group-item-action active\" data-toggle=\"list\" role=\"tab\" aria-controls=\"home\"><center>Quick navigation<\/center><\/h2>\n\n* [1. train.csv](#1)\n* [2. questions.csv](#2)\n* [3. lectures.csv](#3)\n* [4. example_test.csv](#4)","8cb0d847":"**questions.csv**: metadata for the questions posed to users.\n\n* **question_id**: foreign key for the train\/test content_id column, when the content type is question (0).\n\n* **bundle_id**: code for which questions are served together.\n\n* **correct_answer**: the answer to the question. Can be compared with the train **user_answer** column to check if the user was right.\n\n* **part**: the relevant [section of the TOEIC test](https:\/\/www.iibc-global.org\/english\/toeic\/test\/lr\/about\/format.html).\n\n* **tags**: one or more detailed tag codes for the question. The meaning of the tags will not be provided, but these codes are sufficient for clustering the questions together.","66d25d9b":"<a id=\"3\"><\/a>\n<h2><center>3. lectures.csv<center><h2>","9e965475":"The `train.csv` file is too large for kaggle kernel. It will show up a memory error if you try to load it all without specifying types. We will ignore some columns for now to save RAM and load only 1M rows.","36084aec":"**example_test.csv**: Three sample groups of the test set data as it will be delivered by the time-series API. The format is largely the same as **train.csv**. There are two different rows that mirror what information the AI tutor actually has available at any given time, but with the user interactions grouped together for the sake of API performance rather than strictly showing information for a single user at a time. Some questions will appear in the hidden test set that have NOT been presented in the train set, emulating the challenge of quickly adapting to modeling newly introduced questions. Their metadata is still in question.csv as usual.\n\n**prior_group_responses**: (string) provides all of the **user_answer** entries for previous group in a string representation of a list in the first row of the group. All other rows in each group are null. If you are using Python, you will likely want to call **eval** on the non-null rows. Some rows may be null, or empty lists.\n\n**prior_group_answers_correct**: (string) provides all the **answered_correctly** field for previous group, with the same format and caveats as **prior_group_responses**. Some rows may be null, or empty lists.","95d032c2":"<a id=\"4\"><\/a>\n<h2><center>4. example_test.csv<center><h2>","40acde42":"<a id=\"1\"><\/a>\n<h2 ><center>1. train.csv<center><h2>","4b550200":"<h1><center>Riiid! Answer Correctness Prediction. Exploratory Data Analysis.<\/center><\/h1>","1a1835f2":"**lectures.csv**: metadata for the lectures watched by users as they progress in their education.\n\n* **lecture_id**: foreign key for the train\/test content_id column, when the content type is lecture (1).\n\n* **part**: top level category code for the lecture.\n\n* **tag**: one tag codes for the lecture. The meaning of the tags will not be provided, but these codes are sufficient for clustering the lectures together.\n\n* **type_of**: brief description of the core purpose of the lecture","4a9ecc90":"**train.csv**\n\n* **row_id**: (int64) ID code for the row.\n\n* **timestamp**: (int64) the time between the first event from a userand the current one.\n\n* **user_id**: (int32) ID code for the user.\n\n* **content_id**: (int16) ID code for the user interaction.\n\n* **content_type_id**: (int8) 0 if the event was a question being posed to the user, 1 if the event was the user watching a lecture.\n\n* **task_container_id**: (int16) Id code for the batch of questions or lectures. For example, a user might see three questions in a row before seeing the explanations for any of them. Those three would all share a **task_container_id**. Monotonically increasing for each user.\n\n* **user_answer**: (int8) the user's answer to the question, if any. Read -1 as null, for lectures.\n\n* **answered_correctly**: (int8) if the user responded correctly. Read -1 as null, for lectures.\n\n* **prior_question_elapsed_time**: (float32) How long it took a user to answer their previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Note that the time is the total time a user took to solve all the questions in the previous bundle.\n\n* **prior_question_had_explanation**: (bool) Whether or not the user saw an explanation and the correct response(s) after answering the previous question bundle, ignoring any lectures in between. The value is shared across a single question bundle, and is null for a user's first question bundle or lecture. Typically the first several questions a user sees were part of an onboarding diagnostic test where they did not get any feedback.","96486245":"#### In this competition, your challenge is to create algorithms for \"Knowledge Tracing,\" the modeling of student knowledge over time. The goal is to accurately predict how students will perform on future interactions. You will pair your machine learning skills using Riiid\u2019s EdNet data.\n\n\n#### This notebook contains an elementary analysis of given data for a better understanding of the challenges input.\n\n#### Let's check our data in depth before we start this challenge!"}}