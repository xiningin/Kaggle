{"cell_type":{"bba0cf73":"code","bb25a25d":"code","aecdafe9":"code","2bb197aa":"code","faa9e47a":"code","20c33373":"code","2eef1015":"code","5db505b9":"code","580b7a4f":"code","7456f1b4":"code","504b0878":"code","7ad7b386":"code","d0cf9100":"code","38f8ba3c":"code","653544b4":"code","48625693":"code","0f765869":"code","5edc94f5":"code","743c791b":"code","306a4312":"code","ddcd3e7c":"code","f7db1c4a":"code","b655b916":"code","93e00b71":"code","222f3af9":"code","5aac0058":"code","b33ef6ea":"code","6258c93b":"code","4e8e8b67":"code","3fc9fef7":"code","7a4e0d88":"markdown","0554cbf6":"markdown","6361ec70":"markdown","44896784":"markdown","ac542b5c":"markdown","1d7bbaeb":"markdown","93af6e8d":"markdown","e401cbc2":"markdown","dc9d0e2b":"markdown","34a37330":"markdown","0d0b73c8":"markdown"},"source":{"bba0cf73":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.graphics.regressionplots import influence_plot\nimport statsmodels.api as smf\nimport numpy as np","bb25a25d":"#importing data \ncompdata = pd.read_csv('..\/input\/50-startups\/50_Startups.csv')\ncompdata.head()","aecdafe9":"# checking data details and checking for null data.\ncompdata.info()","2bb197aa":"#compareing compete data by grouping by state.\ncompdata.groupby(\"State\").mean()","faa9e47a":"compdata.head()","20c33373":"sns.set_style(style='darkgrid')\nsns.pairplot(compdata)","2eef1015":"# As state is a categorical variable, we are getting dummies to get the values of unique states.\ncompdata = pd.get_dummies(compdata,drop_first= True)","5db505b9":"compdata.head()","580b7a4f":"# Separating the dataset into x and y \nx = compdata.drop(\"Profit\", axis= 1)\ny = compdata[\"Profit\"]","7456f1b4":"# Splitting the dataset into the Training set and Test set\nfrom sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(x,y, test_size = 0.25, random_state = 4)","504b0878":"m1 = smf.OLS(y_train, x_train).fit()","7ad7b386":"m1.summary2()","d0cf9100":"y_train2 = np.sqrt(y_train)","38f8ba3c":"y_train2.head()","653544b4":"m2 = smf.OLS(y_train2,x_train).fit()","48625693":"m2.summary2()","0f765869":"y_train3 = np.log(y_train)","5edc94f5":"y_train3.head()","743c791b":"m3 = smf.OLS(y_train3,x_train).fit()","306a4312":"m3.summary2()","ddcd3e7c":"x_train1 = x_train.drop([\"State_Florida\",\"State_New York\"],axis = 1)","f7db1c4a":"x_train1.head()","b655b916":"m4 = smf.OLS(y_train3,x_train1).fit()","93e00b71":"m4.summary2()","222f3af9":"x_train2 = x_train.drop([\"State_Florida\",\"State_New York\"],axis = 1)","5aac0058":"x_train2.head()","b33ef6ea":"m5 = smf.OLS(y_train,x_train1).fit()","6258c93b":"m5.summary2()","4e8e8b67":"m5.rsquared","3fc9fef7":"data = [{'R Square Values': m1.rsquared, 'AIC':m1.aic}, {'R Square Values': m2.rsquared, 'AIC':m2.aic},{'R Square Values': m3.rsquared, 'AIC':m3.aic}, {'R Square Values': m4.rsquared, 'AIC':m4.aic}, {'R Square Values': m5.rsquared, 'AIC':m5.aic}]\n\n# Lists of dictionaries and row index.\ndf = pd.DataFrame(data, index =['Model without any modification', 'Y transformed using sqrt','Y transformed using natural log','Y -ln with insignificant variables removed','Insignificant values removed with original model'])\n  \n# Print the data\ndf","7a4e0d88":"### Using natural log  function from numpy library to transform Y","0554cbf6":"#### Fitting linear regression model on the  transformed data.","6361ec70":"### Using sqrt function from numpy library to transform Y","44896784":"### removing two states as they are insignificant and building main  model again.","ac542b5c":"### removing two states as they are insignificant and building log model again.","1d7bbaeb":"## Using different transformations on y and validating different models.","93af6e8d":"#### Fitting linear regression model on the  transformed data.","e401cbc2":"#### Fitting linear regression model on the  transformed data.","dc9d0e2b":"### we can see that the model with insignificant state columns removed and transformed using natural log yeilds the best AIC scores, so we can say that this is the best model.","34a37330":"#### Fitting linear regression model on the sqrt transformed data.","0d0b73c8":"#### Fitting linear regression model on the original data."}}