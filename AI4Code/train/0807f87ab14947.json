{"cell_type":{"b2afc671":"code","73173823":"code","791721d2":"code","759a7934":"code","aeeb4b21":"code","706859b0":"code","c23d51e8":"code","563fdf57":"code","21c1d491":"code","c8b98654":"code","c6c597fd":"code","b2a4c5ec":"code","3d9cbd57":"code","11ca3f07":"code","1f432eb6":"code","fc66e53f":"code","385b3ed1":"code","b70bf2ab":"code","2566008a":"markdown","fb91fc0c":"markdown","a13cde60":"markdown","39ecac1b":"markdown","ead20ff5":"markdown","0f1beb58":"markdown","329123ed":"markdown","998ce99e":"markdown","21d8d33f":"markdown","23c0dcb8":"markdown","67c7a8b7":"markdown","91bcb00b":"markdown"},"source":{"b2afc671":"import numpy as np \nimport pandas as pd\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n\ndf =  pd.read_csv('\/kaggle\/input\/stroke-prediction-dataset\/healthcare-dataset-stroke-data.csv')","73173823":"df.describe()","791721d2":"df.head(10)","759a7934":"df.stroke.value_counts() # Dataset is imbalanced","aeeb4b21":"df.drop(\"id\", axis=1, inplace=True)\ndf = df.sample(frac = 1)","706859b0":"\ndf['smoking_status'].replace('Unknown', np.nan, inplace=True)\ndf['bmi'].fillna(df['bmi'].mean(), inplace=True)\ndf['smoking_status'].fillna(df['smoking_status'].mode()[0], inplace = True)\n\n#df.dropna(inplace=True)\n","c23d51e8":"\nfrom sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\n\nlabel_features = ['ever_married','Residence_type']\ndf[label_features] = df[label_features].apply(le.fit_transform)\n","563fdf57":"ohe_features = ['gender','work_type','smoking_status']\nfor feat in ohe_features:\n    df[feat] = pd.Categorical(df[feat])\n    df_dummies = pd.get_dummies(df[feat], prefix = feat + '_encoded',drop_first=True)\n    df.drop(feat, axis=1, inplace=True)\n    df = pd.concat([df, df_dummies], axis=1)\n","21c1d491":"from sklearn.model_selection import train_test_split\n\ntrain_x, test_x, train_y, test_y = train_test_split(df.drop('stroke',axis=1), df['stroke'], test_size=0.33, random_state=42)\n","c8b98654":"from sklearn.preprocessing import StandardScaler\n\nscaler = StandardScaler()\ntrain_x = scaler.fit_transform(train_x)\ntest_x = scaler.transform(test_x)","c6c597fd":"from imblearn.over_sampling import SMOTE\nfrom imblearn.over_sampling import RandomOverSampler\n\nsm = SMOTE(random_state=2)\ntrain_x, train_y = sm.fit_resample(train_x, train_y)\n#os = RandomOverSampler(sampling_strategy = 1)\n#train_x, train_y = os.fit_resample(train_x, train_y)\n\n","b2a4c5ec":"from sklearn import svm\nfrom sklearn.metrics import f1_score, roc_auc_score, confusion_matrix, accuracy_score\n\nsvc = svm.SVC()\nsvc.fit(train_x, train_y)\n\ny_pred = svc.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('SVM\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))","3d9cbd57":"from sklearn.linear_model import LogisticRegression\n\nlog = LogisticRegression(class_weight='balanced')\nlog.fit(train_x, train_y)\n\ny_pred = log.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Logistic Regression\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))","11ca3f07":"from sklearn.naive_bayes import GaussianNB\n\ngnb = GaussianNB()\ngnb.fit(train_x,train_y)\n\ny_pred = gnb.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Gaussian Naive Bayes\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))","1f432eb6":"from sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import GridSearchCV\n\ntree_para = {'criterion':['gini','entropy'],'max_depth':[4,5,6,7,8,9,10,11,12,15,20,30,40,50,70,90,120,150]}\ntree = GridSearchCV(DecisionTreeClassifier(random_state=0,class_weight='balanced'), tree_para, cv=5)\ntree.fit(train_x, train_y)\n\ny_pred = tree.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Decision Tree with Grid Search\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))\n","fc66e53f":"from sklearn.ensemble import RandomForestClassifier\n\nrfc = RandomForestClassifier(random_state=0,class_weight='balanced_subsample')\nrfc.fit(train_x,train_y)\n\ny_pred = rfc.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Random Forest\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))\n","385b3ed1":"from xgboost import XGBClassifier\n\nxgb = XGBClassifier(eval_metric='error',use_label_encoder=False)\nxgb.fit(train_x,train_y)\n\ny_pred = xgb.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('XGB\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))\n","b70bf2ab":"from imblearn.ensemble import BalancedRandomForestClassifier\n\nbrf = BalancedRandomForestClassifier(random_state=42)\nbrf.fit(train_x,train_y)\n\ny_pred = brf.predict(test_x)\nf1 = f1_score(test_y, y_pred,average=None)\nroc = roc_auc_score(test_y, y_pred)\ncm = confusion_matrix(test_y, y_pred) \n\nprint('Balanced Random Forest\\n')\nprint('Confusion matrix: \\n',cm,'\\n')\nprint('Accuracy Score: {:.5f} \\n'.format(accuracy_score(test_y, y_pred)))\nprint('ROC AUC Score: {:.5f} \\n'.format(roc))\nprint('F1: {:.5f} {:.5f} \\n'.format(f1[0], f1[1]))\n","2566008a":"### Label encoding for categorical features with 2 values","fb91fc0c":"### Oversampling\n","a13cde60":"## Train-test split","39ecac1b":"### Data analysis","ead20ff5":"## Test models","0f1beb58":"### Import dataset","329123ed":"### One hot encoding for categorical features with >2 values","998ce99e":"## Encoding","21d8d33f":"#### Treatment of null values\n","23c0dcb8":"### Data cleansing","67c7a8b7":"# Feel free to give your feedback in the comments! :)\n","91bcb00b":"# Stroke prediction\n\nMy goal was to try to improve the very low F1 scores and to compensate the imbalance in the dataset. I'm a beginner so any feedback is much appreciated!"}}