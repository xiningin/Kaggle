{"cell_type":{"45d6a45a":"code","1f8dc882":"code","beb01649":"code","fb254a14":"code","bcb73ed2":"code","7f8d5e54":"code","20cedb6b":"code","c1078e4b":"code","8f417012":"code","5d57df2b":"code","0dcf4e98":"code","7dd87e82":"code","0dc3e658":"code","8049c70a":"code","1a994253":"code","c215730d":"code","ca5d879c":"code","3b3f7e11":"code","1c20518c":"code","fce44453":"code","98b023e3":"code","1537fc7b":"code","543ba40a":"code","9d59e658":"code","af7b9c64":"code","afab9031":"code","89a3ca6c":"code","1b79836e":"code","733e0ea0":"code","edcdd970":"code","9259ed9e":"code","27386583":"code","5b0a1364":"code","2b346485":"code","4f2910b6":"code","49c5992d":"code","f3f36bfc":"markdown","69459d41":"markdown","400ceb6a":"markdown","b3f118c4":"markdown","757deaf4":"markdown","a0260489":"markdown","bc317d19":"markdown","9a54e0c9":"markdown","a8484496":"markdown","8c3b7b90":"markdown","dabd3711":"markdown","3fc1bd86":"markdown","2f4ac301":"markdown","8fab53c6":"markdown","1de8a8a4":"markdown","49bebc99":"markdown","43210b85":"markdown","d02ba07c":"markdown","edfeea20":"markdown","8ed534a6":"markdown","16711063":"markdown","b25afd9b":"markdown","2fdb2648":"markdown","a0ef181a":"markdown","724824b6":"markdown","345b94bd":"markdown","e405735c":"markdown","787cc688":"markdown"},"source":{"45d6a45a":"# data analysis and wrangling\nimport pandas as pd\nimport numpy as np\nimport random as rnd\n# machine learning\nfrom sklearn import tree\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn import metrics\n# visualization\nimport seaborn as sns\nimport matplotlib.pyplot as plt","1f8dc882":"#read in\npd_data = pd.read_csv('..\/input\/weatherAUS.csv')\npd_data.shape","beb01649":"#drop NAN\npd_data=pd_data.dropna(how='any')\nprint(pd_data.shape)","fb254a14":"#drop something column\ndrop_columns_list = ['WindGustDir', 'WindDir9am', 'WindDir3pm','Date','Location','RISK_MM']\npd_data = pd_data.drop(drop_columns_list, axis=1)\nprint(pd_data.shape)\npd_data.head()","bcb73ed2":"#change yes\/no to 1\/0\npd_data['RainToday'].replace({'No':0,'Yes':1},inplace=True)\npd_data['RainTomorrow'].replace({'No':0,'Yes':1},inplace=True)\npd_data.head()","7f8d5e54":"#Task: Split the data into train and test\ntrain_y = pd_data['RainTomorrow'].head(55000)\ntest_y= pd_data['RainTomorrow'].tail(1420)\ntrain_x = pd_data.head(55000).drop(['RainTomorrow'], axis=1)\ntest_x= pd_data.tail(1420).drop(['RainTomorrow'], axis=1)\nprint(train_y.head())\nprint(train_x.head())","20cedb6b":"import graphviz \ndtree=tree.DecisionTreeClassifier(max_depth=3)\ndtree=dtree.fit(train_x,train_y)\ndot_data = tree.export_graphviz(dtree, \n                filled=True, \n                feature_names=list(train_x),\n                class_names=['No rain','rain'],\n                special_characters=True)\ngraph = graphviz.Source(dot_data)  \n","c1078e4b":"graph","8f417012":"#\u4e0d\u540c\u8cc7\u6599\u8207\u7d50\u679c\u7684\u95dc\u806f\u6027\ndtree.feature_importances_\n","5d57df2b":"#\u628a\u8a13\u7df4\u597d\u7684\u6a21\u578b\u5957\u7528\u5230\u6e2c\u8a66\u6578\u64da\npredict_y = dtree.predict(test_x)\npredict_y","0dcf4e98":"#\u8a08\u7b97\u8a13\u7df4\u6578\u64da\u8207\u6e2c\u8a66\u6578\u64da\u7684\u6b63\u78ba\u7387\nfrom sklearn.metrics import accuracy_score\nacc_log = dtree.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_log)\nx=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % x)","7dd87e82":"#test\n#\u6e2c\u8a66\u4e0d\u540c\u7684\u53c3\u6578\uff0c\u767c\u73fe\u4e26\u6c92\u6709\u592a\u5927\u6539\u8b8a\n#for i in range(400,601,5):    \n    \"\"\"dtree=tree.DecisionTreeClassifier(min_samples_split=1000,min_samples_leaf =570)\n    dtree=dtree.fit(train_x,train_y)\n    predict_y = dtree.predict(test_x)\n    x=accuracy_score(test_y, predict_y)\n    print('%d' % i,'test accuracy: %.5f'  %x)\"\"\"","0dc3e658":"#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('max_depth=3 auc: %.5f' % metrics.auc(fpr, tpr))","8049c70a":"tree_train_acc=[]   #\u8a13\u7df4\u6a21\u578b\u5957\u7528\u5230\u8a13\u7df4\u6578\u64da\u7684\u6b63\u78ba\u7387\ntree_test_acc=[]    #\u8a13\u7df4\u6a21\u578b\u5957\u7528\u5230\u6e2c\u8a66\u6578\u64da\u7684\u6b63\u78ba\u7387\ntree_depth=[]       #\u4e0d\u540c\u7684max_depth\n\nfor i in range (2,20):\n    dtree=tree.DecisionTreeClassifier(max_depth=i)\n    dtree=dtree.fit(train_x,train_y)\n    acc_log = dtree.score(train_x, train_y)\n    print('max_depth=%d ' % i,'training accuracy: %.5f' % acc_log)\n    \n    predict_y = dtree.predict(test_x)    \n    X=accuracy_score(test_y, predict_y)\n    print('\\t\\ttest accuracy: %.5f' % X)\n    \n    tree_train_acc.append(acc_log)\n    tree_test_acc.append(X)\n    tree_depth.append(i)\n    ","1a994253":"plt.plot(tree_depth,tree_train_acc,'b', label=\"training accuracy\")\nplt.plot(tree_depth,tree_test_acc,'r', label=\"test accuracy\")\nplt.ylabel('accuracy (%)')\nplt.xlabel('max depth ')\nplt.legend()\nplt.show()","c215730d":"\nbest_depth = tree_depth[tree_test_acc.index(max(tree_test_acc))]\nprint (\"max depth: \", best_depth)\nprint (\"best test accuracy: %.5f\"% max(tree_test_acc))","ca5d879c":"#dtree=tree.DecisionTreeClassifier(max_depth=7)\n#dtree=dtree.fit(train_x,train_y)\n#predict_y = dtree.predict(test_x)\n#X=accuracy_score(test_y, predict_y)\n#print('max_depth=7 test accuracy: %.5f' % X)","3b3f7e11":"#\u6a21\u578b\u8a55\u50f9 auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('max_depth=7 auc: %.5f' % metrics.auc(fpr, tpr))","1c20518c":"# \u4ea4\u53c9\u9a57\u8b49 cross validation \nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import train_test_split\nscores = cross_val_score(dtree,train_x,train_y,cv=5,scoring='accuracy')\n\n# \u8a08\u7b97\u5e73\u5747\u503c\u8207\u6a19\u6e96\u5dee\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","fce44453":"# logistic regression\n\nlogreg = LogisticRegression()\nlogreg = logreg.fit(train_x, train_y)\npredict_y = logreg.predict(test_x)\nacc_log = logreg.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_log)\n\npredict_y =logreg.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)\n\n#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('auc: %.5f' % metrics.auc(fpr, tpr))\n\n#Cross validation\nscores = cross_val_score(logreg,train_x,train_y,cv=5,scoring='accuracy')\n# \u8a08\u7b97Cross validation\u7684\u5e73\u5747\u503c\u8207\u6a19\u6e96\u5dee\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","98b023e3":"# Support Vector Machines\n#\u904b\u7b97\u6642\u9593\u592a\u9577\n'''\nsvc = SVC(gamma='auto',C=0.1,kernel=\"linear\", probability=True)\nsvc.fit(train_x, train_y)\npredict_y= svc.predict(test_x)\nacc_svc = svc.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_svc)\n\npredict_y =svc.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)'''","1537fc7b":"# knn\n\nknn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(train_x, train_y)\npredict_y = knn.predict(test_x)\nacc_knn = knn.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_knn)\n\npredict_y =knn.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)\n\n#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('auc: %.5f' % metrics.auc(fpr, tpr))\n\n#Cross validation\nscores = cross_val_score(knn,train_x,train_y,cv=5,scoring='accuracy')\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","543ba40a":"# Gaussian Naive Bayes\n\ngaussian = GaussianNB()\ngaussian.fit(train_x, train_y)\npredict_y = gaussian.predict(test_x)\nacc_gaussian = gaussian.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_gaussian)\n\npredict_y =gaussian.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)\n\n#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('auc: %.5f' % metrics.auc(fpr, tpr))\n\n#Cross validation\nscores = cross_val_score(gaussian,train_x,train_y,cv=5,scoring='accuracy')\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","9d59e658":"from sklearn.ensemble import RandomForestClassifier\nrdf = RandomForestClassifier(bootstrap=True, n_estimators=1000, max_depth=7)\nrdf.fit(train_x, train_y)  ","af7b9c64":"acc_log = rdf.score(train_x, train_y)\nprint('training accuracy: %.5f' % acc_log)\n\npredict_y =rdf.predict(test_x)\nX=accuracy_score(test_y, predict_y)\nprint('test accuracy: %.5f' % X)\n#auc\nfpr, tpr, thresholds = metrics.roc_curve(test_y, predict_y, pos_label=1)\nprint('auc: %.5f' % metrics.auc(fpr, tpr))\n\n#Cross validation\n#\u904b\u7b97\u6642\u9593\u592a\u9577\n'''scores = cross_val_score(rdf,train_x,train_y,cv=5,scoring='accuracy')\nprint(scores)\nprint('Cross validation: %.5f'%scores.mean())'''","afab9031":"#Parameters:\u6c7a\u5b9a\u6700\u4f73\u7684n_estimators\n#\u76ee\u524d\u53ea\u7b97\u5230n_estimators=256\uff0c\u592a\u5927\u9700\u8981\u6642\u9593\u904e\u9577\n\nfrom sklearn import model_selection, metrics\n\ndef scorer(model, X,  train_y):\n    preds = model.predict(X)\n    return metrics.accuracy_score( train_y, preds)\n\nn_estimators = [1,2,4,8,16,32,64,128, 256]  ## try different n_estimators\ncv_results = []\n\nfor estimator in n_estimators:\n    rf = RandomForestClassifier(n_estimators=estimator)\n    acc = model_selection.cross_val_score(rf, train_x,  train_y, cv=5, scoring=scorer)\n    cv_results.append(acc.mean())","89a3ca6c":"line1= plt.plot(n_estimators, cv_results, 'b', label=\"cross validated accuracy\")\nplt.ylabel('accuracy')\nplt.xlabel('n_estimators')\nplt.legend()\nplt.show()","1b79836e":"best_n_estimators = n_estimators[cv_results.index(max(cv_results))]\nprint (\"best_n_estimators: \", best_n_estimators)\nprint (\"best accuracy: \", max(cv_results))","733e0ea0":"pd_data = pd.read_csv('..\/input\/weatherAUS.csv')\npd_data=pd_data.dropna(how='any')\nprint(pd_data.shape)\n","edcdd970":"drop_columns_list = ['WindGustDir', 'WindDir9am', 'WindDir3pm','Date','Sunshine','RISK_MM']\npd_data = pd_data.drop(drop_columns_list, axis=1)\nprint(pd_data.shape)\n\npd_data['RainToday'].replace({'No':0,'Yes':1},inplace=True)\npd_data['RainTomorrow'].replace({'No':0,'Yes':1},inplace=True)","9259ed9e":"groupbyLocation=pd_data.groupby('Location')\nprint(groupbyLocation.size().sort_values(ascending=False))\n","27386583":"pd_data['Location'] = pd_data['Location'].map( {'Darwin':0,'Perth':1,'Brisbane':2,'MelbourneAirport':3,\n                                                'PerthAirport':4,'SydneyAirport':5,'Watsonia':6,'Mildura':7,\n                                                'MountGambier':8,'NorfolkIsland':9,'Cairns':10,'Townsville':11,\n                                                'WaggaWagga':12,'AliceSprings':13,'Nuriootpa':14,'Hobart':15,\n                                                'Moree':16,'Melbourne':17,'Portland':18,'Woomera':19,\n                                                'Sydney':20,'Sale':21,'CoffsHarbour':22,'Williamtown':23,\n                                                'Canberra':24,'Cobar':25} ).astype(int)\ntrain_y=pd_data['RainTomorrow']\ntrain_x=pd_data.drop(['RainTomorrow'], axis=1)","5b0a1364":"dtree=tree.DecisionTreeClassifier(max_depth=7)\ndtree=dtree.fit(train_x,train_y)\nscores = cross_val_score(dtree,train_x,train_y,cv=5,scoring='accuracy')\nprint(scores)\nprint('average of Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","2b346485":"#Logistic Regression\nlogreg = LogisticRegression()\nlogreg.fit(train_x, train_y)\n\n#Cross validation\nscores = cross_val_score(dtree,train_x,train_y,cv=5,scoring='accuracy')\nprint('Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","4f2910b6":"#knn\nknn = KNeighborsClassifier(n_neighbors = 10)\nknn.fit(train_x, train_y)\n\n#Cross validation\nscores = cross_val_score(knn,train_x,train_y,cv=5,scoring='accuracy')\nprint('Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","49c5992d":"#Gaussian Naive Bayes\ngaussian = GaussianNB()\ngaussian.fit(train_x, train_y)\n#Cross validation\nscores = cross_val_score(gaussian,train_x,train_y,cv=5,scoring='accuracy')\nprint('Cross validation: %.5f'%scores.mean())\nprint('standard deviation of Cross validation: %.5f'%scores.std(ddof=1))","f3f36bfc":"## 1.Dataset\u7c21\u4ecb\n#### \u9019\u500b\u8cc7\u6599\u96c6\u6536\u96c6\u4e86\u5f9e2007\u5e74\u8d77\u6fb3\u6d32\u5404\u5730\u5929\u6c23\u7ad9\u7684\u6c23\u8c61\u8cc7\u6599\uff0c\u5305\u542b\u4eca\u5929\u662f\u5426\u964d\u96e8\u3001\u964d\u96e8\u91cf\u3001\u84b8\u767c\u91cf\u3001\u65e5\u7167\u3001\u4e0d\u540c\u6642\u6bb5\u7684\u98a8\u901f\u8207\u98a8\u5411\u3001\u4e0d\u540c\u6642\u6bb5\u7684\u6eab\u5ea6\u4ee5\u53ca\u660e\u5929\u662f\u5426\u964d\u96e8...\u7b49\u7b49\u4e0d\u540c\u8cc7\u6599\u3002\n\n#### \u7db2\u5740:https:\/\/www.kaggle.com\/jsphyg\/weather-dataset-rattle-package","69459d41":"\n#### 3.2 \u6211\u5011\u8a8d\u70ba\u65e5\u671f\u3001\u5730\u9ede\u90fd\u4e0d\u662f\u5f71\u97ff\u660e\u65e5\u662f\u5426\u6703\u4e0b\u96e8\u7684\u56e0\u7d20\uff0c\u56e0\u6b64\u5c07'Date','Location'\u522a\u9664\u3002\n#### 'WindGustDir', 'WindDir9am', 'WindDir3pm'\u70ba\u98a8\u5411\uff0c\u5206\u7531\u65bc\u662f\u4ee5\u6587\u5b57\u8868\u793a\uff0c\u96e3\u8f49\u63db\u6210\u6578\u5b57\uff0c\u56e0\u6b64\u5728\u6b64\u5148\u4e0d\u8003\u616e\u3002\n#### 'RISK_MM'\u662f\u6c23\u8c61\u5c40\u7d66\u51fa\u7684\u660e\u5929\u96e8\u91cf\u4f30\u8a08\uff0c\u57fa\u672c\u4e0a\u5c31\u662f\u6211\u5011\u8981\u7684\u7d50\u679c\uff0c\u82e5\u5c07\u6b64\u884c\u52a0\u5165\u6703overfitting\uff0c\u6545\u522a\u9664\u3002\n","400ceb6a":"\n### 5.2 knn","b3f118c4":"#### 6.1.2 \u6c7a\u5b9a\u6700\u4f73\u7684n_estimators","757deaf4":"### 6.1 Random Forest","a0260489":"## 8.\u5fc3\u5f97\n#### \u5ed6\u54c1\u745c:\n#### \u611f\u89ba\u8ab2\u7a0b\u6642\u9593\u6709\u9ede\u5c11\uff0c\u5e0c\u671b\u53ef\u4ee5\u7528\u66f4\u591a\u6642\u9593\u5728\u5e36\u7a0b\u5f0f\u7684\u90e8\u5206\uff0c\u96d6\u7136\u539f\u7406\u5f88\u91cd\u8981\uff0c\u4f46\u8b1b\u89e3\u904e\u5927\u6982\u5f8c\u61c9\u8a72\u53ef\u4ee5\u900f\u904e\u81ea\u5b78\u4f86\u5b8c\u6210\uff1b\u800c\u7a0b\u5f0f\u7684\u90e8\u5206\u5c31\u7b97\u4e0d\u592a\u61c2\u539f\u7406\u4e5f\u53ef\u4ee5\u4e0a\u624b\uff0c\u4f46\u9700\u8981\u66f4\u591a\u6b21\u7df4\u7fd2\u624d\u80fd\u627e\u51fa\u554f\u984c\u3002\u9019\u6b21\u5b78\u5230\u7684\u6771\u897f\u5f88\u6709\u8da3\uff0c\u96fb\u8166\u53ef\u4ee5\u76f4\u63a5\u5f15\u7528\u51fd\u5f0f\u5eab\u771f\u7684\u592a\u65b9\u4fbf\u4e86\uff0c\u5e7e\u4e4e\u4e0d\u9700\u8981\u4e86\u89e3\u539f\u7406\u5c31\u53ef\u4ee5\u4f7f\u7528\u3002\u4e5f\u5b78\u5230Git\u8ddfKaggle\u9084\u6709Jupyter notebook\u7684\u7528\u6cd5\uff0c\u4ee5\u5f8c\u6703\u66f4\u6df1\u5165\u5b78\u7fd2\uff0c\u5e0c\u671b\u53ef\u4ee5\u5728\u539f\u672c\u7684\u79d1\u7cfb\u4e0a\u904b\u7528\u3002\n#### \u80e1\u7b46\u52dd:\n#### \u8ab2\u7a0b\u5167\u5bb9\u5f88\u6709\u8da3\u4e5f\u5f88\u5be6\u7528\uff0c\u4e4b\u524d\u5b8c\u5168\u6c92\u6709\u63a5\u89f8\u904e\u76f8\u95dc\u7684\u9818\u57df\uff0c\u4f46\u662f\u5728\u4e00\u500b\u79ae\u62dc\u5167\u8981\u4e86\u89e3\u6a5f\u5668\u5b78\u7fd2\u4ee5\u53capython\u7684\u8ab2\u7a0b\u5167\u5bb9\uff0c\u6211\u89ba\u5f97\u6709\u4e9b\u8a31\u56f0\u96e3\u3002\u7e73\u4ea4\u4f5c\u696d\u6642\u9593\u5ef6\u5f8c\u4e4b\u5f8c\uff0c\u6211\u53ef\u4ee5\u6709\u66f4\u591a\u6642\u9593\u6642\u4f5c\u8207\u601d\u8003\u8ab2\u7a0b\u5167\u5bb9\u3002","bc317d19":"#### 6.2.2 Logistic Regression","9a54e0c9":"### 5.3 Gaussian Naive Bayes","a8484496":"#### 6.1.3 random forest\u7d50\u679c\u89c0\u5bdf\n\u548c\u4f7f\u7528Decision tree\u76f8\u6bd4\uff0crandom forest\u6c92\u6709\u63d0\u9ad8\u6b63\u78ba\u7387\u3002","8c3b7b90":"## 2.\u554f\u984c\u5b9a\u7fa9\n#### \u6839\u64da\u4eca\u5929\u7684\u5404\u7a2e\u6c23\u8c61\u8cc7\u6599\uff0c\u8a13\u7df4\u4e00\u500b\u6a21\u578b\u9810\u6e2c\u6fb3\u6d32\u660e\u5929\u6703\u4e0d\u6703\u4e0b\u96e8\u3002","dabd3711":"#### 6.1.1 \u8a08\u7b97n_estimators=1000\u7684\u60c5\u6cc1","3fc1bd86":"# \u671f\u672b\u5831\u544a\n#### \u7d44\u54e1: \u5ed6\u54c1\u745c\u3001\u80e1\u7b46\u52dd","2f4ac301":"#### 6.2.1 \u628a\u5730\u9ede\u8f49\u70ba\u6578\u5b57","8fab53c6":"\u5f9e\u76ee\u524d\u7684\u7d50\u679c\u53ef\u77e5\uff0c\u5728n_estimators=256\u4ee5\u5167\uff0c\u6b63\u78ba\u7387\u6709\u4e0a\u5347\u7684\u8da8\u52e2\uff0c\u800c\u4e14n_estimators\u8d8a\u5927\uff0c\u4e0a\u5347\u8da8\u52e2\u8d8a\u7de9\u3002\u4f46\u662f\u56e0\u70ba\u8a08\u7b97\u6642\u9593\u7684\u554f\u984c\uff0cn_estimators>256\u7684\u60c5\u6cc1\u66ab\u6642\u4e0d\u8a08\u7b97\u3002","1de8a8a4":"## 7.\u5c0f\u7d50\n\n1.\u6211\u5011\u5617\u8a66\u4f7f\u7528\u5404\u7a2e\u6a21\u578b\u9810\u6e2c\uff0c\u9810\u6e2c\u6e96\u78ba\u5ea6\u90fd\u80fd\u9054\u523080%\u4ee5\u4e0a\u3002\n\n2.\u5404\u500b\u6a21\u578b\u7684auc\u90fd\u5927\u65bc0.7\uff0c\u6709\u4e9b\u6a21\u578b\u53ef\u90540.8\u4ee5\u4e0a\uff0c\u8868\u793a\u4f7f\u7528\u9019\u4e9b\u6a21\u578b\u9810\u6e2c\u300c\u660e\u5929\u662f\u5426\u964d\u96e8\u7684\u6b63\u78ba\u7387\u300d\u90fd\u6bd4\u4e82\u731c\u7684\u7d50\u679c\u4f86\u5f97\u597d\u3002","49bebc99":"#### 6.2.5 \u5c07\u5730\u9ede\u8003\u616e\u9032\u53bb\u7684\u7d50\u679c\u89c0\u5bdf\n\u6b63\u78ba\u7387\u4e26\u6c92\u6709\u63d0\u5347\u3002","43210b85":"\u5f9e\u4e0a\u5716\u53ef\u4ee5\u770b\u51fa\uff0c\u8a13\u7df4\u6578\u64da\u7684\u6b63\u78ba\u7387\u96a8\u8457max_depth\u7684\u589e\u52a0\u800c\u4e0a\u5347\uff0c\u4f46\u662f\u6e2c\u8a66\u6578\u64da\u7684\u6b63\u78ba\u7387\u4e0d\u6703\u3002max_depth=7\u6642\uff0c\u6e2c\u8a66\u6578\u64da\u7684\u6b63\u78ba\u7387\u9054\u5230\u6700\u9ad8\uff0c\u7d04\u7565\u70ba0.86479%\u3002\u6240\u4ee5\u53ef\u4ee5\u8a8d\u5b9amax_depth=7\u6642\u7684\u6a21\u578b\u8f03\u597d\uff0cmax_depth>7\u7684\u6a21\u578b\u6703\u6709overfitting\u7684\u73fe\u8c61\u3002","d02ba07c":"### 6.2 \u5c07\u5730\u9ede\u8003\u616e\u9032\u53bb\n","edfeea20":"#### 3.3 RainToday\u539f\u672c\u7531Yes\/No\u7d44\u6210\uff0c\u5c07\u5176\u6539\u70baYes=1,No=0\n####    \u5c07\u8cc7\u6599\u5206\u6210\u8a13\u7df4Train\u8207\u6e2c\u8a66Test\u90e8\u5206\uff0cTrain\u5360\u4e8655000\u7b46\uff0cTest\u67091420\u7b46\uff0c\u4e26\u628a\u8981\u5f97\u51fa\u7684\u7d50\u679c\u5207\u51fa\u4f86\u3002","8ed534a6":"## 4.\u6a21\u578b\n\n### 4.1 Decision tree","16711063":"#### 6.2.3 knn","b25afd9b":"auc>0.5 \u8868\u793a\u6a21\u578b\u9810\u6e2c\u6bd4\u96a8\u6a5f\u731c\u6e2c\u6e96\u78ba","2fdb2648":"#### 4.1.1 \u6e2c\u8a66\u4e0d\u540cmax_depth\u7684\u6b63\u78ba\u7387","a0ef181a":"## 5.\u4e0d\u540c\u7684\u6a21\u578b\n### 5.1 logistic regression","724824b6":"#### 4.2 Decision tree\u7d50\u679c\u89c0\u5bdf\n1. 3\u5c64\u7684\u6c7a\u7b56\u6a39\u53ef\u4ee5\u670983.6%\u7684\u6b63\u78ba\u7387\u3002\n2. 7\u5c64\u7684\u6c7a\u7b56\u6a39\u7684\u9810\u6e2c\u6b63\u78ba\u7387\u6700\u9ad8\uff0c\u670986.5%\u3002","345b94bd":"## 6.\u5f8c\u7e8c\u5de5\u4f5c\n1. \u4f7f\u7528Random forest \n2. \u5c07\u98a8\u5411\u7684\u8cc7\u6599\u3001\u4e14\u5c07\u65e5\u671f\u8f49\u63db\u6210\u5b63\u7bc0\uff0c\u91cd\u65b0\u52a0\u5165\u8a13\u7df4\u6a21\u578b\u4e2d\uff0c\u78ba\u8a8d\u662f\u5426\u6709\u66f4\u597d\u7684\u7d50\u679c\u3002\n3. \u53ef\u4ee5\u5c07Location\u91cd\u65b0\u52a0\u5165\u8a13\u7df4\u6a21\u578b\uff0c\u9810\u6e2c\u5404\u5730\u9ede\u660e\u5929\u662f\u5426\u964d\u96e8\u3002\n\n(\u8a3b\uff1a\u300c\u5f8c\u7e8c\u5de5\u4f5c\u300d\u662f\u53e3\u982d\u5831\u544a\u6642\u9084\u672a\u5b8c\u6210\u7684\u5de5\u4f5c)\n","e405735c":"#### 6.2.4 Gaussian Naive Bayes","787cc688":"## 3.\u8cc7\u6599\u524d\u8655\u7406\n#### 3.1 \u9996\u5148\u5c07\u6709\u7f3a\u5931\u7684\u5217\u522a\u9664\uff0c\u907f\u514d\u8cc7\u6599\u4e0d\u8db3\u96e3\u4ee5\u9810\u6e2c\u3002\n\n"}}