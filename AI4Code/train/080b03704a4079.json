{"cell_type":{"e5be82ef":"code","4e2e9722":"code","c9071de9":"code","80f98238":"code","d92a8a9b":"code","4d495a5c":"code","0721daef":"code","677b7135":"code","bdc81275":"code","db00f508":"code","d7a5355d":"code","6bc8dc77":"code","0e43f072":"code","a6b34294":"code","a6861528":"code","eedef1df":"code","f4f4072c":"code","d2d5ea2a":"code","c1803934":"code","bb8499ff":"code","83499128":"code","9bc673af":"code","a7cd5391":"code","bfb5c7bc":"code","7dc55e05":"code","09ff3982":"code","82e4f3c0":"markdown","8adb90c7":"markdown","0c165154":"markdown","6b91999d":"markdown","9d96e77b":"markdown","cdef30c0":"markdown","385b0e1a":"markdown","6f19b469":"markdown","eab59859":"markdown","8491cd98":"markdown","13313f95":"markdown","ad448831":"markdown","7f089d71":"markdown","fa703ef0":"markdown","a04ce3e0":"markdown","a2e74f5c":"markdown","4d542c2f":"markdown","74aa972e":"markdown","a6c5e631":"markdown"},"source":{"e5be82ef":"# Basics\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport time\nimport IPython\nimport random\nfrom random import getrandbits\nimport os\n\n# Tensorflow\nimport tensorflow as tf\nfrom tensorflow import keras\nimport tensorflow.keras.layers as layers\nfrom tensorflow.keras import datasets\nfrom tensorflow.keras import callbacks\n\nfrom sklearn.model_selection import train_test_split\n\n# Metrics\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\n\n# Graphs\nimport matplotlib.pyplot as plt\n\nprint(\"Numpy: \" + np.__version__)\nprint(\"Tensorflow: \" + tf.__version__)\nprint(\"Keras: \" + keras.__version__)","4e2e9722":"(train_images, train_labels), (test_images, test_labels) = datasets.cifar10.load_data()\n\n# Normalize pixel values to be between 0 and 1\ntrain_images, test_images = train_images \/ 255.0, test_images \/ 255.0","c9071de9":"class_names = ['Airplane', 'Automobile', 'Bird', 'Cat', 'Deer',\n               'Dog', 'Frog', 'Horse', 'Ship', 'Truck']\n\nplt.figure(figsize=(10, 10))\nfor i in range(25):\n    plt.subplot(5, 5, i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(train_images[i], cmap=plt.cm.binary)\n    # The CIFAR labels happen to be arrays, \n    # which is why you need the extra index\n    plt.xlabel(class_names[train_labels[i][0]])\nplt.show()","80f98238":"model1 = keras.Sequential([\n    # First Convolutional Block\n    layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(32, 32, 3)),\n    layers.MaxPool2D((2, 2)),\n\n    # Second Convolutional Block\n    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n    layers.MaxPool2D((2, 2)),\n\n    # Third Convolutional Block\n    layers.Conv2D(64, (3, 3), activation=\"relu\"),\n\n    # Classifier Head\n    layers.Flatten(),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dense(10)\n])\n\nmodel1.summary()","d92a8a9b":"model1.compile(\n    optimizer=\"adam\",\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\nhistory1 = model1.fit(\n    train_images, train_labels, \n    epochs=10, \n    validation_split=0.2\n)","4d495a5c":"plt.plot(history1.history['accuracy'], label='accuracy')\nplt.plot(history1.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\nplt.show()","0721daef":"model2 = keras.Sequential([\n    # First Convolutional Block\n    layers.Conv2D(32, kernel_size=5, activation=\"relu\", padding='same',\n                  # give the input dimensions in the first layer\n                  # [height, width, color channels(RGB)]\n                  input_shape=[32, 32, 3]),\n    layers.MaxPool2D(),\n\n    # Second Convolutional Block\n    layers.Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n\n    # Third Convolutional Block\n    layers.Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n\n    # Classifier Head\n    layers.Flatten(),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dense(10)\n])\n\nmodel2.summary()","677b7135":"model2.compile(\n    optimizer=\"adam\",\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\nhistory2 = model2.fit(\n    train_images, train_labels, \n    epochs=10, \n    validation_split=0.2\n)","bdc81275":"plt.plot(history2.history['accuracy'], label='accuracy')\nplt.plot(history2.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\nplt.show()","db00f508":"model3 = keras.Sequential([\n    # First Convolutional Block\n    layers.Conv2D(32, kernel_size=5, activation=\"relu\", padding='same',\n                  # give the input dimensions in the first layer\n                  # [height, width, color channels(RGB)]\n                  input_shape=[32, 32, 3]),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Second Convolutional Block\n    layers.Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Third Convolutional Block\n    layers.Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Classifier Head\n    layers.Flatten(),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.Dense(10)\n])\n\nmodel3.summary()","d7a5355d":"model3.compile(\n    optimizer=\"adam\",\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\nhistory3 = model3.fit(\n    train_images, train_labels, \n    epochs=10, \n    validation_split=0.2\n)","6bc8dc77":"plt.plot(history3.history['accuracy'], label='accuracy')\nplt.plot(history3.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.legend(loc='lower right')\nplt.show()","0e43f072":"model4 = keras.Sequential([\n    # First Convolutional Block\n    layers.InputLayer(input_shape=(32, 32, 3)),\n    layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    layers.experimental.preprocessing.RandomRotation(0.2),\n    layers.Conv2D(32, kernel_size=5, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Second Convolutional Block\n    layers.Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Third Convolutional Block\n    layers.Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Classifier Head\n    layers.Flatten(),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    layers.Dense(10)\n])\n\nmodel4.summary()","a6b34294":"model4.compile(\n    optimizer=\"adam\",\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\nhistory4 = model4.fit(\n    train_images, train_labels, \n    epochs=10, \n    validation_split=0.2\n)","a6861528":"plt.plot(history4.history['accuracy'], label='accuracy')\nplt.plot(history4.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()","eedef1df":"model5 = keras.Sequential([\n    # First Convolutional Block\n    layers.Conv2D(32, kernel_size=5, activation=\"relu\", padding='same',\n                  # give the input dimensions in the first layer\n                  # [height, width, color channels(RGB)]\n                  input_shape=[32, 32, 3]),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Second Convolutional Block\n    layers.Conv2D(64, kernel_size=3, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Third Convolutional Block\n    layers.Conv2D(128, kernel_size=3, activation=\"relu\", padding='same'),\n    layers.MaxPool2D(),\n    layers.Dropout(0.3),\n    layers.BatchNormalization(),\n    \n    # Classifier Head\n    layers.Flatten(),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dense(10)\n])\n\nmodel5.summary()","f4f4072c":"model5.compile(\n    optimizer=\"adam\",\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\nhistory5 = model5.fit(\n    train_images, train_labels, \n    epochs=50, \n    validation_split=0.2\n)","d2d5ea2a":"plt.plot(history5.history['accuracy'], label='accuracy')\nplt.plot(history5.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0, 1])\nplt.legend(loc='lower right')\nplt.show()","c1803934":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input","bb8499ff":"base_model = tf.keras.applications.MobileNetV2(\n    input_shape=(32, 32, 3),\n    include_top=False,\n    weights='imagenet'\n)\n\nbase_model.trainable = False","83499128":"base_model.summary()","9bc673af":"model6 = keras.Sequential([\n    layers.InputLayer(input_shape=(32, 32, 3)),\n    \n    # Preprocessing\n    #preprocess_input,\n    \n    # Base Model: Efficient Net\n    base_model,\n    \n    # Classifier Head\n    layers.Flatten(),\n    layers.Dense(64, activation=\"relu\"),\n    layers.Dense(10)\n])\n\nmodel6.summary()","a7cd5391":"model6.compile(\n    optimizer=\"adam\",\n    loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n    metrics=[\"accuracy\"]\n)\n\nhistory6 = model6.fit(\n    train_images, train_labels, \n    epochs=50, \n    validation_split=0.2\n)","bfb5c7bc":"train_labels.shape","7dc55e05":"# Predict\ntrain_pred = model5.predict(train_images)\n#train_pred = train_pred.reshape(-1)\ntrain_pred.shape","09ff3982":"test_loss, test_acc = model5.evaluate(test_images, test_labels, verbose=2)","82e4f3c0":"## B. Evaluate the Test Set","8adb90c7":"## Second Conclusion\n\n* The Drop Layer made the Model generalize better and not overfitting anymore but we probably need to let him train on more epochs.\n* We lost accuracy while implementing and using Augmentation Technics.\n\n---\n\n# 11. Creation of a Model with more epochs\n\nHere, I did some little modifications to my previous model, and added more epochs.","0c165154":"## C. Performances on the Test Set","6b91999d":"---\n\n# 3. Re-Create a Basic CNN from TensorFlow\n\nThis first, and simplest model, come from an architecture found of the website of tensorflow. You can find the model, [and the notebook here](https:\/\/www.tensorflow.org\/tutorials\/images\/cnn).","9d96e77b":"---\n\n# 10. Evaluate Model 4","cdef30c0":"---\n\n# 6. Evaluate Model 2","385b0e1a":"---\n\n# 12. Evaluate Model 5","6f19b469":"---\n\n# 8. Evaluate Model 3","eab59859":"# Predict\ntest_pred = model5.predict(test_images)\ntest_pred = test_pred.reshape(-1)\n\n# Confusion Matrix\ncm_test = confusion_matrix(test_labels, test_pred, normalize='true')\n\n# Graph\nplt.figure(figsize=(12, 7))\nplt.title('Accuracy Score on the Test Set: ' + str(accuracy_score(test_labels, test_pred).round(4)), size=25)\nsns.heatmap(cm_test, annot=True, fmt='.2%', cmap='Blues')\nplt.xlabel('Predicted Values', size=20)\nplt.ylabel('True Values', size=20)\nplt.show()\n\n# To be Continued...","8491cd98":"---\n\n# 4. Evaluate Model 1","13313f95":"## Third Conclusion\n\n* We successfully improved the accuracy of our Model.\n* Taking off the DropOut and BatchNormalization in the head of the Model also helped: 71% -> 75% in 10 epochs\n* Adding more epochs also helped: 10 -> 50\n* Now, let's move on to an other technic: **Transfer Learning**.\n\n---\n\n# 13. Creation of a Model using a Pre-trained Model\n\nFor this model, I tried, for the first time to use a Transfer Learning Technic. For that I used two notebooks:\n* [The notebook from TensorFlow](https:\/\/www.tensorflow.org\/tutorials\/images\/transfer_learning)\n* [The notebook from Kaggle](https:\/\/www.kaggle.com\/ryanholbrook\/data-augmentation)","ad448831":"This last part for plotting a confusion matrix is a failure for now since the output of the CNN isn't the same as the labels. I need to do some research about that.","7f089d71":"## First Conclusion\n * We can see that the second model is overfitting. The validation accuracy isn't following the train accuracy.\n * First, create One Version with DropOut and BatchNormalization Layers.\n * Then, create One Version with Augmentation Techniques.\n \n ---\n \n # 7. Create a Model with DropOut Technics\n \n In this model, I added DropOut and BatchNormalization Layers. The Kaggle Course introducting them [can be found here](https:\/\/www.kaggle.com\/ryanholbrook\/dropout-and-batch-normalization).","fa703ef0":"## Fourth Conclusion\n\n* Our first attempt on using Tranfer Learning was a failure. It is probably due to the small size of our images, while most Big Models to use with transfer learning are trained on bigger images.\n\n---\n\n# 14. Performances on the Test Set\n\nTo check the performance on the test set, we are going to reuse our best model which is the model 5\n\n## A. Performances on the Training Set\n\nplt.xlabel(class_names[train_labels[i][0]])","a04ce3e0":"---\n\n# 9. Create a Model with Augmentation Technics\n\nFor this model, I tried to implement Augmentation Layers. I used two notebooks to learn how to implement them:\n* [The notebook from TensorFlow](https:\/\/www.tensorflow.org\/tutorials\/images\/data_augmentation)\n* [The notebook from Kaggle's Course](https:\/\/www.kaggle.com\/ryanholbrook\/data-augmentation)","a2e74f5c":"---\n\n# 2. Loading Data","4d542c2f":"## Verify Data","74aa972e":"---\n\n# 5. Create a CNN from Kaggle Course\n\nIn this second model, I make the CNN a bit wilder and deeper. I also took the architecture from a tutorial, this one comes from the Kaggle Course, [the notebook can be found here](https:\/\/www.kaggle.com\/ryanholbrook\/custom-convnets).","a6c5e631":"The goal of this notebook is to present simple approaches for classifying images.\n\nI will start with a very simple CNN and make it deeper, and more complex as I move forward. Feel free to leave some comments as I am still a student in ML and I could be doing things with mistakes.\n\n---\n\n# 1. Import Librairies"}}