{"cell_type":{"38839777":"code","7ef19281":"code","a43f30be":"code","1ecf6222":"code","718f59d2":"code","03732f8e":"code","0f1d32e9":"code","2eba2292":"code","87247197":"code","223c18b8":"code","6db4ec8b":"markdown","87dc145c":"markdown","7fc6fd8b":"markdown","c203031e":"markdown","d514a0a6":"markdown","2f19d819":"markdown","7822837e":"markdown","66320363":"markdown","a308b8b5":"markdown","6854a902":"markdown","e12daf8c":"markdown","55bfa5fe":"markdown"},"source":{"38839777":"import numpy as np\nimport pandas as pd\nimport re\nimport csv\nimport sys\nfrom matplotlib import pyplot as plt\n%matplotlib inline\nfrom wordcloud import WordCloud\nimport seaborn as sns","7ef19281":"#df = pd.read_csv(\"data_cafe.csv\") <-- reading directly into a dataframe gives errors, bad formatting?\n#open('data_cafe.csv') # Opening this gives codec errors. needs utf-8 encoding \n#we will use csv.reader:\n\ndata = []\nwith open('..\/input\/data_cafe.csv', encoding=\"utf8\") as File:\n    reader = csv.reader(File, delimiter=';', quotechar=',', quoting=csv.QUOTE_MINIMAL)\n    for row in reader:\n        data.append(row)\n\n#Example of our data::\nprint(data[0]) # column headers\nprint(data[1]) # review 1","a43f30be":"#First row is a list of columns lets copy this and remove it from the data\n\ncols = data[0] # store column headers \ndel data[0] #remove column headers from datalist\n","1ecf6222":"#Check how many rows are abnormal:\nincorrect_rows = 0\nfor row in data:\n    if len(row) != 6:\n        incorrect_rows +=1\n        \nprint(f\"Number of abnormal rows: {incorrect_rows}\")\n#Lets catch these rows and merge the comments columns to form a single element\nfor row in data:\n    if len(row) != 6:\n        rows = len(row) # number of rows it has.\n        row[5:rows+1] = [','.join(row[5:rows+1])]\n        \n#Check how many rows are abnormal after fix:\nincorrect_rows = 0\nfor row in data:\n    if len(row) != 6:\n        incorrect_rows +=1\nprint(f\"Number of abnormal rows after fix: {incorrect_rows}\")","718f59d2":"#cols = data[0] # store column headers             #for reference - did this already above\n#del data[0] #remove column headers from datalist  #for reference - did this already above\n\ndf = pd.DataFrame(data,columns= cols) # create new dataframe\ndf.head()","03732f8e":"#An overview of the dataframe:\ndf.info()\ndf.describe()","0f1d32e9":"\n#noticed that some \"type\" columns contain empty \"  \" cells. lets find these and strip them of whitespace to get \"\".\n#Go through each cafe type and strip all trailing\/leading white space. This will help us later.\nfor i in range(len(df[\"Type\"])):\n    df.loc[i,\"Type\"] = str(df.loc[i,\"Type\"]).strip()","2eba2292":"#Pull a list of unique values\nListOfLocations = df.Location.unique()\ncount = [] #list of corresponding count of cafes\n\nfor city in ListOfLocations:\n    dffilt = df[df.Location == city]\n    count.append(int(len(dffilt.Location)))\n\n\n\n\n    \n#Plot a bar graph to show number of cafes per location using [ListOfLocations] and [count]\n#sns styles - darkgrid\/whitegrid\/dark\/white\nsns.set_style(\"whitegrid\")\nfig = plt.figure(figsize=(9,7))\nax = fig.add_axes([1,1,1,1])\n#ax.bar(ListOfLocations,count,width=1,align='center')\nax.set_xlabel(\"Cities\", weight=\"bold\", fontsize=14)\nax.set_ylabel(\"Number of cafes\", weight=\"bold\", fontsize=14)\nax.set_title(\"Number of cafes in each city\", weight=\"bold\", fontsize=16)\n\nsns.barplot(ListOfLocations,count,ax=ax)\n","87247197":"\ndef locFilteredDf(location): # output a list of cafe types in the city of \"location\" - and ensure datapoints are compatible for wordcloud vis\n    row_droplist = [] # a list of rows to drop as they have blank \"Type\" elements\n    df_loc_cleaned = df # this will be a new df but with empty \" \" elements removed and words formatted correctly for the plot\n    for i in range(0,len(df[\"Type\"])):\n \n        element = df.loc[i,\"Type\"]#store datapoint in \"element\" so we can clean it up and put it back into original df (1 means look at \"type\" col)\n        element = element.strip() #remove leading\/tailing whitespace\n        element = element.replace(\" \",\"\")#remove whitespace inbtween words\n        \n        if element == \"\": # checking if its a blank element\n            row_droplist.append(i) # collect index values for data points with empty \" \" values, to be dropped later \n        else:\n            df_loc_cleaned.loc[i,\"Type\"] = element # store cleaned datapoints into the new dataframe. lets not touch the original\n    \n    df_loc_cleaned = df_loc_cleaned.drop(row_droplist)\n\n    #Now we have all datapoints ready that are associated with given -> location. lets filter \n    df_loc_cleaned = df_loc_cleaned[df_loc_cleaned.Location == location]\n    return df_loc_cleaned #returns a filtered dataframe specific to a location\n\n\n\nfig = plt.figure(figsize=(15,15))\ni = 1\nfor location in ListOfLocations:\n    #print(i) # a counter to show the plots being drawn. at first i thought it was an infinate loop but turns out its a super long loop...\n    Vistext = locFilteredDf(location)['Type'].values.tolist() # This is a list to drop. convert it into a long string with space seperation\n    Vistext_str = ' '.join(Vistext)\n\n    # Create the wordcloud object\n    wordcloudobj = WordCloud(width=600, height=600, margin=0, max_font_size=100, min_font_size=12,\n                       background_color=\"lightyellow\", collocations = False).generate(Vistext_str)  \n         \n    ax = fig.add_subplot(3,4,i)\n    ax.set_title(f\"Types of cafes in {location}\\n ({len(Vistext)} cafes)\")\n\n    ax.axis(\"off\")\n    ax.imshow(wordcloudobj, interpolation='bilinear') # Display the generated image:\n    i += 1\n    \n\n        ","223c18b8":"#A function that:\n#  - takes a list of cities, and for each city:\n#     - sorts the cafe types to pull the top 5 popular ones\n#     - makes a count of how many of each type of cafe\n#     - plots a graph of top cafe type and score\n\n\ndef city2avgScore(locations):\n    num_of_cities = len(locations)\n    plotcountincrement = 1\n    # new df filtering only data relating to city of choice\n    for city in locations:\n        dffilt_city = df[df[\"Location\"] == city] \n\n\n        # pivot table to summarise data and get a count of number of\n        #occurances of cafe type - store as a new dataframe\n        df_toptypes = dffilt_city.pivot_table(index=['Type'], aggfunc='count') \n        # we have number of occurances, now sort. this is a pivot\n        #table to all columns show count \n        df_toptypes = df_toptypes.sort_values(by=\"Score\",ascending=False)\n        #note that \"df_toptypes\" has an index = \"type\". \n        #lets reset the index to have integer index for ease\n\n        # reset index to have ingeger index and \n        #keep the \"type\" column (which used to be the index)\n        df_toptypes = df_toptypes.reset_index(drop=False) \n        # drop all empty types\n        df_toptypes = df_toptypes.drop(df_toptypes[df_toptypes.Type == \"\"].index) \n        # reset index again as we just dropped a row\n        df_toptypes = df_toptypes.reset_index(drop=False) \n\n        # grab the top 5 cafe types and store in a list.\n        #note first row is a blank\n        top5list = df_toptypes.loc[0:4,\"Type\"].tolist() \n\n        # dataframe containing values in column \"Types\" \n        #that match those in the list:\"top5list\" from our chosen city\n        dffilt_city = dffilt_city[dffilt_city[\"Type\"].isin(top5list)]\n\n        #now dffilt_city[\"Type\"] and dffilt_city[\"Score\"] can be used to plot a boxplot. \n        #note the score is normalized to 1. so multiply all score values\n        #by 5 and reset index so we can work with it. \n        \n        #reset the index to ensure incremental index as we will loop through it now\n        dffilt_city = dffilt_city.reset_index(drop=True) \n        for i in range(0,len(dffilt_city[\"Score\"])): # go through each row in the the dataframe \n            dffilt_city.loc[i,\"Score\"] = float(dffilt_city.loc[i,\"Score\"])*5 # replace score with (score*5)\n\n\n        dffilt_city['Score'] = dffilt_city['Score'].astype(float)\n        dffilt_city['Type']  = dffilt_city['Type'].astype(str)\n\n\n        sns.set_style(\"whitegrid\")\n        ax = fig.add_subplot(4,1,plotcountincrement)\n        #adjust subplot spacing\n        fig.subplots_adjust(hspace=0.5)\n        \n        sns.stripplot(x=dffilt_city[\"Type\"], y=dffilt_city[\"Score\"], jitter=0.2, size=4)\n        ax.set_xlabel(\"Cafe Type\", weight=\"bold\", fontsize=10)\n        ax.set_ylabel(\"Score\", weight=\"bold\", fontsize=10)\n        ax.set_title(f\"Score distribution in {city}\", weight=\"bold\", fontsize=16)\n        ax.set_ylim(0, 6)\n\n        plotcountincrement += 1\n\n# from the previous graph we find these cities with the most cafes         \nx =[\"Koln\",\"Nurnberg\"]  \nplt.close(fig)#close previous plot\nfig = plt.figure(figsize=(9,17))\ncity2avgScore(x)\n","6db4ec8b":"Now we have rows, all of the same length, we should be able to load our data into a dataframe now:","87dc145c":"df = pd.DataFrame(data,columns= cols) # create new dataframe\nThe above line throws an error: AssertionError: 6 columns passed, passed data had 7 columns\n\nSeems like one or more of the rows has too many columns...we are expecting 6. lets find it and see whats going on:","7fc6fd8b":"# Cleaning the data\nAs you can see above, the data is in no condition to be ported into a dataframe. We will need to clean this up by\ncopying the column headers (and later use them to create dataframe column headers) and removing them from the data:","c203031e":"# Wordcloud of types of cafes\nWe will now creating a string of words to visualise types of cafes. Data will be pulled from the cafe \"type\" column.\nThere may be cases where words need to be double barrled (vegetarian friendly ), so we replace \" \" with  -. \nWe do this so that wordcloud considers this as one word and not two seperate words.\nWe could use \"df['Type'].values.tolist()\"\" but first we need to clean up the data as there may be blank cells and non double barrel words.\n\nIn essence, we will create a function to loop through each location and create seperate wordcloud graphs for each location\n","d514a0a6":"# Score comparision between top cafe types\n\nNow let us look at the top cafe types in Koln and Nurnburg.\nWe want to produce a refined dataframe with the top 5 popular cafe types for a given city with their correspoinding score. Use this to constuct a stripplot to visualize the spread of scores for each cafe type.\n\nWe need a list of cities with most cafes, i.e the cities we want to analyse and find the top cafe types in each city","2f19d819":"# Count of how many cafes per location:\ndf.describe() shows there are 11 unique locations. lets pull a list of unique values and use it to plot a bar graph showing the number of cafes in each location.","7822837e":"# Partial German Restaurant Review Data\n\"TripAdvisor data collected from numerous german cities\"\n\n\nThis kernel will present an analysis from Kaggle's dataset \"Partial German Restaurant Review Data\".\nWe have a dataset with restaurant data including locations and reviews.\nAbout this file:\nData collected from the following cities in Germany from TripAdvisor:\n\n'Leipzig','Saarbrucken','Stuttgart','Berlin','Hamburg','Konstanz','Heidelberg','Hannover','Munchen','Koln','Nurnberg'\n\nName = name of cafe or restaurant Location = City Type = Bar, Cafe, Origin of cuisine, etc. Score = Number of bubbles \/ 5 Reviews = Number of reviews Comments = The first few initial comments\nLets open this up and view the data as a dataframe (df)\n\nTaking a sample of the data:\n\nName;Location;Type;Score;Reviews;Comments\t\t\t\t\t\t\t\t\nCafe Gloria Leipzig;Leipzig;Cafe;0.8;40;\u00e2\u20ac\u0153Comfortable cafe \u00e2\u20ac\u009d10\/21\/2018 \u00e2\u20ac\u0153Best coffee so far\u00e2\u20ac\u009d06\/13\/2018 \t\t\t\t\nCafe Kandler Im Speck's Hof Or Cafe Kandler An Der Nikolaikirche;Leipzig;German;0.8;102;\u00e2\u20ac\u0153Refreshing break\u00e2\u20ac\u009d \u00e2\u20ac\u0153Excelent cakes and teas\u00e2\u20ac\u009d \t\t\t\t\t\t\t\t\n\nSome points ive noticed:\n- each line seems like they are individual cafes\n- there is a strange placeholder \"\u00e2\u20ac\u0153\" which is useful when it comes to seperation of comments, probably need some encoding\n- there may be multiple comments\n- columns are seperated by \";\"\n\nLets open this csv and see what we can do with the data\n\n","66320363":"From the above, we gain insight into the diversity of different types of cafes as well as which types are most popular. Its interesting to note that Nurnberg has more variety but fewer cafes compared to Koln. But this is only based on that data that has been given to us. \n\n","a308b8b5":"# Analysis\n\nWe have our data loaded in a dataframe.\nFrom df.info we see how many datapoints we will deal with. Also note the type of data: \"non-null object\". From past experience, When attempting to plot in matplotlib later, we will encounter errors. These columns need to be formatted to int() or float() rather than an ambiguous \"object\".\n\nFrom df.describe we gain some insight into our data:\n11 locations (cities) Koln being the most popular, there are many types of cafes which will be an interesting plot and the reviews seem to be scaled to 1 (should be out of 5) \nVery important to note that the data provided is \"incomplete\" as stated. \nSome visualizations ideas: \n\n* Count of how many cafes per location  \n* WordCloud of the types of cafes to see most popular cafe types\n* Choose locations with most cafes and see:\n- top 5 cafe types\n- how many reviews each of those cafe types have\n- how the score compares against wach cafe type. ","6854a902":"Now lets attempt to load our data into a dataframe","e12daf8c":"# Import libraries ","55bfa5fe":"We can see how to score compares against the two cities. On average we see that the cafe types have a high score around 4. \nIts interesting to note the diversity in cafe types and in particular the popularity of Vegetarian friendly cafes which seems\nvery appropriate considering the fact that there is a large population of vegetarians in Germany. \nAround 5.7 million (in 2017 - Source: https:\/\/www.statista.com\/statistics\/651008\/number-of-vegetarians-in-germany\/)\nIt would be interesting to see how the number of vegetarian friendly restaurants compare between different cities around the world"}}