{"cell_type":{"1c00d1fb":"code","df214e7b":"code","453954f0":"code","54d5eb41":"code","4dbc3868":"code","5ff5de8a":"code","73333d8c":"markdown","9f45d1f3":"markdown","ed9ea741":"markdown","4eb70a00":"markdown","a5aeb976":"markdown","12ade5a5":"markdown"},"source":{"1c00d1fb":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","df214e7b":"%matplotlib inline\nimport numpy as np\nimport matplotlib.pyplot as plt\n\n# These paths are unique to Kaggle, obviously. Use your local path or colab path, depending on which you're using.\ntrain_x = np.load('\/kaggle\/input\/f2019-aihw7\/mnist-train-images.npy')\ntrain_y = np.load('\/kaggle\/input\/f2019-aihw7\/mnist-train-labels.npy')\nval_x = np.load('\/kaggle\/input\/f2019-aihw7\/mnist-val-images.npy')\nval_y = np.load('\/kaggle\/input\/f2019-aihw7\/mnist-val-labels.npy')\n\n# Verify that their shapes are what we expect\nprint(\"train_x shape:\", train_x.shape)\nprint(\"train_y shape:\", train_y.shape)\nprint(\"val_x shape:\", val_x.shape)\nprint(\"val_y shape:\", val_y.shape)","453954f0":"fig, (ax1, ax2, ax3) = plt.subplots(nrows=1, ncols=3)\n\n# show each image, and make each title the label\n# these are grayscale images so use appropriate heatmap\nax1.imshow(train_x[4701], cmap=plt.get_cmap('gray'))\nax1.set_title(str(train_y[4701]))\nax2.imshow(train_x[4702], cmap=plt.get_cmap('gray'))\nax2.set_title(str(train_y[4702]))\nax3.imshow(train_x[4703], cmap=plt.get_cmap('gray'))\nax3.set_title(str(train_y[4703]))\n\nfig.show()","54d5eb41":"# print data type\nprint(\"Data type:\", train_x.dtype)\n# just to make sure, print the min\/max too\nprint(\"Data min:\", np.amin(train_x[4701]))\nprint(\"Data max:\", np.amax(train_x[4701]))","4dbc3868":"print(\"Data type:\", train_y.dtype)","5ff5de8a":"fig, ax = plt.subplots()\nax.hist(train_y, bins=range(11))\nax.set_xticks(range(10))\nax.set_title(\"MNIST Training Set Class Distribution\")\n\nfig.show()","73333d8c":"# Exploring MNIST\nJake Lee, TA for COMS4701 Fall 2019\n\n## Introduction\nIn this notebook, we're going to play around with the MNIST dataset a little so that we can understand exactly what we're working with.\n\nLet's start by importing some basic packages and the dataset itself.","9f45d1f3":"Great, looks like we won't have to worry about that.\n\n## Conclusion\n\nThat's all you need to get started! There are some other great descriptions of MNIST out there, here are some of my favorites:\n\n- https:\/\/colah.github.io\/posts\/2014-10-Visualizing-MNIST\/\n- http:\/\/varianceexplained.org\/r\/digit-eda\/\n\nFinally, a fixture in every public notebook: if you enjoyed the writeup, click below to upvote!","ed9ea741":"Cool! We've confirmed that the images look like what we expect, and that the labels match up. You might be surprised that the images seem inverted - that is, it's white strokes on a black background instead of black ink on a white background. This makes more sense if you think about it in terms of pixel values - 255 (white) means there's information there, 0 (black) means it's the background. Some classifiers might care about this, others might not.\n\nSpeaking of pixel values, there are two ways to represent said values - **np.int** (from 0 to 255) or **np.float** (from 0 to 1). Which one is this one?","4eb70a00":"## Visualizing Some Numbers\nWhat's the point of classifying images if we don't know what the images look like? Let's plot some out:","a5aeb976":"Great, we see that it's uint8, ranging from 0 to 255. Keep this in mind - some classifiers **require** that the data be normalized from 0 to 1, or with the mean at 0 with a stddev of 1. The most important part is to stay **consistent**. Your training, validation, and test data all need to be normalized the same way.\n\nWhat about the labels?","12ade5a5":"The labels are also integers - you'll probably end up one-hot encoding this anyways, so this doesn't matter much. See the Sklearn tutorial for more information.\n\n## Class Distribution\n\nWhen performing classification, the makeup of your training data is very important. For instance, if you have 1 image of a dog and 100 images of a cat, no matter how complex your model is, it probably won't do a good job. A balanced class distribution (where each class has an equal number of training examples) is ideal.\n\nSo, is the MNIST training set balanced? We can just look at the labels to find out:"}}