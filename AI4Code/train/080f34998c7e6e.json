{"cell_type":{"819f6100":"code","6497c402":"code","e1e30060":"code","1e78d717":"code","6efcb49a":"code","87217518":"code","e136fb61":"code","091fd372":"code","1db6c076":"code","4158035c":"code","fadf53b9":"code","4da12095":"code","dade4467":"code","7ac14fb0":"code","a6cb040c":"markdown"},"source":{"819f6100":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","6497c402":"df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ndf.describe()","e1e30060":"df.describe(include=['O'])","1e78d717":"X = df.drop('Survived', axis=1)\ny = df[['Survived']]\nX.shape, y.shape","6efcb49a":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33, random_state=42)\n\ny_train = np.ravel(y_train)\ny_test = np.ravel(y_test)","87217518":"from sklearn.pipeline import Pipeline\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import StandardScaler, OneHotEncoder\n\nnumeric_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='median'))])\n    #('scaler', StandardScaler())])\n\ncategorical_transformer = Pipeline(steps=[\n    ('imputer', SimpleImputer(strategy='constant', fill_value='missing')),\n    ('onehot', OneHotEncoder(handle_unknown='ignore'))])","e136fb61":"numeric_features = X_train.select_dtypes(include=['int64', 'float64']).columns\ncategorical_features = X_train.select_dtypes(include=['object']).columns","091fd372":"from sklearn.compose import ColumnTransformer\n\npreprocessor = ColumnTransformer(\n    transformers=[\n        ('num', numeric_transformer, numeric_features),\n        ('cat', categorical_transformer, categorical_features)])","1db6c076":"from sklearn.ensemble import RandomForestClassifier\nrf = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', RandomForestClassifier())])","4158035c":"rf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nrf.score(X_test, y_test)","fadf53b9":"from sklearn.metrics import accuracy_score, log_loss\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.svm import SVC, LinearSVC, NuSVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.discriminant_analysis import QuadraticDiscriminantAnalysis\n\nclassifiers = [\n   # KNeighborsClassifier(3),\n   # SVC(kernel=\"rbf\", C=0.025, probability=True),\n    NuSVC(probability=True),\n    LogisticRegression(),\n    #DecisionTreeClassifier(),\n    RandomForestClassifier(),\n    AdaBoostClassifier(),\n    GradientBoostingClassifier()]\n\nfor classifier in classifiers:\n    pipe = Pipeline(steps=[('preprocessor', preprocessor),\n                      ('classifier', classifier)])\n    pipe.fit(X_train, y_train)   \n    print(classifier)\n    print(\"model score: %.3f\" % pipe.score(X_test, y_test))","4da12095":"param_grid = { \n    'classifier__n_estimators': [200, 500, 700],\n    'classifier__max_features': ['auto', 'sqrt', 'log2'],\n    'classifier__max_depth' : [4,7,9,12],\n    'classifier__criterion' :['gini', 'entropy']}\n\nfrom sklearn.model_selection import GridSearchCV\n\nCV = GridSearchCV(rf, param_grid, n_jobs= 1)\n                  \nCV.fit(X_train, y_train)  \nprint(CV.best_params_)    \nprint(CV.best_score_)","dade4467":"test_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')\ny_pred = rf.predict(test_df)\n\nsubmission = pd.DataFrame({\n        \"PassengerId\": test_df[\"PassengerId\"],\n        \"Survived\": y_pred\n    })\nif submission.shape == (418,2):\n    submission.to_csv('submission.csv', index=False)\n    print('Submission ready')","7ac14fb0":"submission.shape == (418,2)","a6cb040c":"# Tuto sur le pipeline : https:\/\/medium.com\/vickdata\/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf"}}