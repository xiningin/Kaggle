{"cell_type":{"97026700":"code","af9661c5":"code","f797a2d0":"code","b32270c8":"code","e679f8ad":"code","f1ebcd8c":"code","58093e2d":"code","a4f4aaa4":"code","df099536":"markdown","d1d55002":"markdown","e8c65a59":"markdown","c3a8c824":"markdown","5eb7f5bb":"markdown","8b66c828":"markdown","ac97259c":"markdown","9fc9c847":"markdown","ab7d8d71":"markdown","d969c099":"markdown","05f85eb3":"markdown","3173891d":"markdown","67a8e541":"markdown","6cff92eb":"markdown","e14362db":"markdown","50821184":"markdown"},"source":{"97026700":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","af9661c5":"import tensorflow as tf\nmnist = tf.keras.datasets.mnist\n(x_train, y_train),(x_test, y_test) = mnist.load_data()\n# Scaling the data\nx_train, x_test = x_train \/ 255.0, x_test \/ 255.0\n# Keeping 10,000 records from training data as the validation set\nx_val = x_train[-10000:]\ny_val = y_train[-10000:]\nx_train = x_train[:-10000]\ny_train = y_train[:-10000]","f797a2d0":"from matplotlib import pyplot as plt\nplt.imshow(x_train[0, :, :])","b32270c8":"model = tf.keras.models.Sequential([\n  tf.keras.layers.Flatten(input_shape=(28, 28)),\n  # Two Important Parameters number of neurons and the activation function\n  tf.keras.layers.Dense(128, activation='relu'),\n  # it is a regularization technique\n  tf.keras.layers.Dropout(0.2),\n  # The last layer is for multi-class output\n  tf.keras.layers.Dense(10, activation='softmax')\n])","e679f8ad":"model.summary()","f1ebcd8c":"model.compile(optimizer='adam',\n              loss='sparse_categorical_crossentropy',\n              metrics=['accuracy'])\n\nmodel.fit(x_train, y_train, epochs=5)\nmodel.evaluate(x_test, y_test)","58093e2d":"print(\"Fit model on training data\")\nhistory = model.fit(\n    x_train,\n    y_train,\n    batch_size=64,\n    epochs=15,\n    # We pass some validation for\n    # monitoring validation loss and metrics\n    # at the end of each epoch\n    validation_data=(x_val, y_val),\n)","a4f4aaa4":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper left')\nplt.show()","df099536":"Tensors are multi-dimensional arrays with a uniform type (called a dtype)","d1d55002":"# Keras bullding the models","e8c65a59":"# A rank-4 tensor, shape: [3, 2, 4, 5]\n","c3a8c824":"![image.png](attachment:11c4d20b-b3ef-48c2-8a38-a4895b22b74a.png)","5eb7f5bb":"![image.png](attachment:355cfef2-c80c-4df9-bcf6-2400959402d5.png)","8b66c828":"The MNIST database of handwritten digits, available from this page, has a training set of 60,000 examples, and a test set of 10,000 examples. It is a subset of a larger set available from NIST. The digits have been size-normalized and centered in a fixed-size image.\n","ac97259c":"# Building the model","9fc9c847":"![image.png](attachment:443305c7-a713-4dcb-a8be-8e2948b58d2d.png)","ab7d8d71":"![image.png](attachment:aec0bfb7-f6cf-4bd4-9764-9786ad0b082c.png)","d969c099":"![image.png](attachment:193a36e6-b65b-4933-a592-3f0cdfa13c6c.png)","05f85eb3":"# MNIST","3173891d":"# Sequential","67a8e541":"A Sequential model is appropriate for a plain stack of layers where each layer has exactly one input tensor and one output tensor.","6cff92eb":"# Initilization","e14362db":"# Tensor","50821184":"# Visualizing"}}