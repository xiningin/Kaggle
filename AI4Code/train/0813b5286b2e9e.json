{"cell_type":{"336f9354":"code","d93f7fa8":"code","57735aa1":"code","fbe3f566":"code","149df261":"code","1774cc25":"code","52efbeb4":"code","70dcfe62":"code","84a81a85":"code","cd2c01ce":"code","e7e12d48":"code","9aebba0d":"code","4fbc2bff":"code","8816326d":"markdown","64ae4afe":"markdown"},"source":{"336f9354":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt ","d93f7fa8":"#read the data set\ndigits_train = pd.read_csv(\"..\/input\/train.csv\")\ndigits_test = pd.read_csv(\"..\/input\/test.csv\")\nsample = pd.read_csv('..\/input\/sample_submission.csv')","57735aa1":"#head\ndigits_train.head()\n","fbe3f566":"digits_test.head()","149df261":"four = digits_train.iloc[3,1:]\nfour.shape","1774cc25":"\nfour= four.values.reshape(28,28)\nplt.imshow(four,cmap='gray')","52efbeb4":"#visuallise the array\nprint(four[5:-5,5:-5])","70dcfe62":"#avearage values\/distributions of features\ndescription = digits_train.describe()\ndescription","84a81a85":"num_class = len(digits_train.iloc[:,0].unique())","cd2c01ce":"x_train= digits_train.iloc[:,1:]\ny_train=digits_train.iloc[:,0]\n\nx_test = digits_test.values\ny_test=digits_test.iloc[:,0]\n\n#rescaling the feature\nfrom sklearn.preprocessing import scale\nx_train = scale(x_train)\nx_test=scale(x_test)\n\n#print\nprint(x_train.shape)\nprint(x_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","e7e12d48":"import lightgbm as lgb\nprint ('Training lightgbm')\n\nlgtrain = lgb.Dataset(x_train, y_train)\nlgval = lgb.Dataset(x_test, y_test)\n\n# params multiclass\nparams = {\n          \"objective\" : \"multiclass\",           \n          \"max_depth\": -1,\n           \"num_class\":num_class,\n          \"learning_rate\" : 0.0001,                 \n          \"verbosity\" : 1 }\n\nmodel = lgb.train(params, lgtrain, 500, valid_sets=[lgtrain, lgval], early_stopping_rounds=750, verbose_eval=200)","9aebba0d":"# predict results\nresults = model.predict(x_test)\n\n# select the index's with the maximum probability\nresults = np.argmax(results,axis = 1)\n\nresults = pd.Series(results,name=\"Label\")\n\nsubmission = pd.concat([pd.Series(range(1,28001),name = \"ImageId\"),results],axis = 1)\n\nsubmission.to_csv(\"submission.csv\",index=False)","4fbc2bff":"submission.head()","8816326d":"# **PLEASE UPVOTE !!!!!**\n# **If you find this notebook helpful !!! Happy Learning**","64ae4afe":"**Light GBM+Digit recognizer - Tutorial - QUICK Solution - 15-25 Lines of Code **\n\n\n\n# *Handwritten Digit Recognition (MNIST Dataset)*\n\nHistory of Handwritten Digit dataset\nModified National Institute of Standards and Technology database (MNIST dataset) is a large dataset of handwritten digits which is widely used in image processing and machine learning. The set of images in the MNIST database is a combination of two of NIST's databases: Special Database 1 and Special Database 3. Special Database 1 and Special Database 3 consist of digits written by high school students and employees of the United States Census Bureau, respectively.\n\n# *Task*\nClassify the images in 10 class, i.e., [0-9], inclusively.\n\nPlease post comment\/feedback for the same. Thank you "}}