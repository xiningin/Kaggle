{"cell_type":{"5632c6e7":"code","bbe30660":"code","6d4e8e04":"code","4b790923":"code","8c443570":"code","30e2512c":"code","47cfafa1":"code","b1325490":"code","ad322c41":"code","011c7693":"code","c9e80569":"code","ef486662":"code","af2925af":"code","26d8752e":"code","0e9c430d":"code","1ac22f78":"code","64c45289":"code","7b124fe8":"code","9e1a57fd":"code","70590c27":"code","6d3b6901":"code","8791bfe7":"code","3b349fb8":"code","3b1b6a5a":"code","e8cd7c60":"code","e08cb54f":"code","9216bff0":"code","eb5cf2ff":"code","dd429d85":"code","44c53d73":"code","ec4fe837":"code","0cc13258":"code","e7790e33":"code","929341ee":"code","15c32ef3":"code","6811f5b5":"code","fe9d2041":"code","81de3280":"code","b1be378a":"code","4cf7f156":"code","b9413633":"code","cff48551":"code","526f469f":"code","3186ae39":"code","d4542ce3":"code","c209f9ab":"code","07eefdf8":"code","827f8ba9":"code","f176d32a":"code","393a810d":"code","ebea1413":"code","b2282818":"code","b88d6996":"code","bd153397":"code","7f0981a7":"code","6553c68f":"code","685b1f0c":"code","31850e0f":"markdown","80a2c417":"markdown","0139b7cb":"markdown","9b573965":"markdown","0f2bab45":"markdown","a47b7523":"markdown","d020bc07":"markdown"},"source":{"5632c6e7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","bbe30660":"import csv\nimport requests\nimport gc","6d4e8e04":"import seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl","4b790923":"from sklearn.linear_model import Ridge\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom scipy.stats import rankdata","8c443570":"#test=\"test\"\nsample=0.01\ntest=\"final\"","30e2512c":"jigsaw_df = pd.read_csv('..\/input\/jigsaw-toxic-coomens-annotations\/jigsaw_train_hate_annotationprob.csv')\n#jigsaw_df=jigsaw_df.sample(300)\nif test==\"test\":\n    jigsaw_df=jigsaw_df.sample(frac=sample)","47cfafa1":"sns.set_theme(style=\"darkgrid\")","b1325490":"jigsaw_df.head()","ad322c41":"sns.distplot(jigsaw_df[\"neutral_speech_agreement\"])","011c7693":"sns.distplot(jigsaw_df[\"neutral_speech_agreement\"]**(jigsaw_df[\"neutral_speech_agreement\"]+0.00001))","c9e80569":"gc.collect","ef486662":"sns.distplot(jigsaw_df[\"offensive_agreement_rating\"])","af2925af":"gc.collect","26d8752e":"\nsns.distplot(jigsaw_df[\"hate_speech_agreement\"])","0e9c430d":"sns.distplot(jigsaw_df[\"neutral_speech_agreement\"]**jigsaw_df[\"neutral_speech_agreement\"]+jigsaw_df[\"severity_filter\"]*jigsaw_df[\"offensive_agreement_rating\"]+2*jigsaw_df[\"severity_filter\"]*jigsaw_df[\"hate_speech_agreement\"])","1ac22f78":"sns.distplot(jigsaw_df[\"neutral_speech_agreement\"]**jigsaw_df[\"neutral_speech_agreement\"]+jigsaw_df[\"severity_filter\"]*jigsaw_df[\"offensive_agreement_rating\"])","64c45289":"def cutoff (row):\n    if row <0.5:        \n        return 0\n    else:\n        return row","7b124fe8":"jigsaw_df['cutoff_hate']=jigsaw_df['hate_speech_agreement'].apply(lambda x: cutoff(x))\njigsaw_df['cutoff_offensive']=jigsaw_df['offensive_agreement_rating'].apply(lambda x: cutoff(x))","9e1a57fd":"sns.distplot(jigsaw_df[\"neutral_speech_agreement\"]**jigsaw_df[\"neutral_speech_agreement\"]+jigsaw_df['cutoff_offensive'])","70590c27":"sns.distplot(jigsaw_df[\"neutral_speech_agreement\"]**jigsaw_df[\"neutral_speech_agreement\"]+jigsaw_df['cutoff_offensive']+jigsaw_df['cutoff_hate'])","6d3b6901":"sns.distplot((1-jigsaw_df[\"neutral_speech_agreement\"])+jigsaw_df['cutoff_offensive']+jigsaw_df['cutoff_hate'])","8791bfe7":"sns.distplot(1-jigsaw_df[\"neutral_speech_agreement\"])","3b349fb8":"sns.distplot(1-jigsaw_df[\"neutral_speech_agreement\"]+2*jigsaw_df['cutoff_offensive']+3*jigsaw_df['cutoff_hate'])","3b1b6a5a":"comments_to_score=pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/comments_to_score.csv\",index_col=0)\nif test =='test':\n    comments_to_score=comments_to_score.sample(frac=sample)","e8cd7c60":"df_test=pd.read_csv(\"\/kaggle\/input\/jigsaw-toxic-severity-rating\/validation_data.csv\",index_col=0)\nif test =='test':\n    df_test=df_test.sample(frac=sample)","e08cb54f":"df=jigsaw_df.copy()","9216bff0":"df.head()","eb5cf2ff":"#df = df.dropna()","dd429d85":"df['score1']=0.16*df['obscene']+0.32*df['toxic']+1.5*df['threat']+0.64*df['insult']+1.5*df['severe_toxic']+1.5*df['identity_hate']\ndf['score2']=1-jigsaw_df[\"neutral_speech_agreement\"]+1*df['obscene']+1*df['toxic']+1*df['threat']+1*df['insult']+2*df['severe_toxic']+1*df['identity_hate']\ndf['score3']=1-jigsaw_df[\"neutral_speech_agreement\"]+1*df['obscene']+1*df['toxic']+1*df['threat']+1*df['insult']+2*df['severe_toxic']+1.5*df['identity_hate']\ndf['score4']=1*df['obscene']+1*df['toxic']+1*df['insult']+5*df['jigsaw_df_severity']*df['offensive_agreement_rating']+5*df['jigsaw_df_severity']*df['hate_speech_agreement']\ndf['score5']=1-df[\"neutral_speech_agreement\"]+2*df['cutoff_offensive']+3*df['cutoff_hate']\ndf['score6']=((df[\"neutral_speech_agreement\"]+0.1)**(df[\"neutral_speech_agreement\"]+0.01))+df['cutoff_offensive']+df['cutoff_hate']\ndf['score7']=1-jigsaw_df[\"neutral_speech_agreement\"]+0.16*df['obscene']+0.32*df['toxic']+1.5*df['threat']+0.64*df['insult']+1.5*df['severe_toxic']+1.5*df['identity_hate']\ndf['score8']=1-df[\"neutral_speech_agreement\"]+df['cutoff_offensive']+df[\"hate_speech_agreement\"]\ndf['score9']=1-df[\"neutral_speech_agreement\"]+df[\"severity_filter\"]*df[\"offensive_agreement_rating\"]+2*df[\"severity_filter\"]*df[\"hate_speech_agreement\"]\n\n","44c53d73":"df = df.dropna()","ec4fe837":"column_names=['score1','score2', 'score3', 'score4', 'score5', 'score6', 'score7', 'score8','score9']","0cc13258":"from sklearn.model_selection import train_test_split\ntrain, valid = train_test_split(df, test_size=0.20)\n#valid, test = train_test_split(valid, test_size=0.3)","e7790e33":"X_train = train['text'].values\ny_train = train.loc[:,column_names].to_numpy()\n\nvalid_data = valid['text'].values\nvalid_target = valid.loc[:,column_names].to_numpy()\n\nprint(X_train.shape, y_train.shape)\nprint(valid_data.shape, valid_target.shape)","929341ee":"X_less_toxic =df_test.less_toxic.values\nX_more_toxic =df_test.more_toxic.values\nX_comments_to_score =comments_to_score.text.values\n","15c32ef3":"vectorizor = TfidfVectorizer(analyzer='char_wb', max_df=0.8, min_df=1, ngram_range=(1, 5) )","6811f5b5":"#jigsaw_df[\"proposed_score\"]=1-jigsaw_df[\"neutral_speech_agreement\"]+2*jigsaw_df['cutoff_offensive']+3*jigsaw_df['cutoff_hate']","fe9d2041":"%%time\nX = vectorizor.fit_transform(X_train)\n#temp_score = jigsaw_df[\"proposed_score\"].values\ny=np.around ( y_train ,decimals = 3)","81de3280":"print(X.shape,y.shape)","b1be378a":"%%time\nregressor=Ridge(alpha=0.5)\nregressor.fit(X, y)","4cf7f156":"def compare(p1,p2):\n    z=0\n    k=0\n    n=len(p1)\n    for i in range(len(p1)):\n        if p1[i]< p2[i]:\n            z=z+1\n        else:\n            k=k+1\n            #print('nu')\n    print(z\/n)\n    return z\/n","b9413633":"def compare_list(p1,p2):\n\n    for j in range(9):\n            z=0\n            k=0\n            n=len(p1)\n            print(\"score\",j+1,\"score\",j+1,)\n            for i in range(len(p1)):\n                if p1[i][j]< p2[i][j]:\n                    z=z+1\n                else:\n                    k=k+1\n                #print('nu')\n            print(z\/n)\n            #print(\"p1 score\",j,\"p2 score\",j,z\/n)\n    return z\/n","cff48551":"#comments_to_score_set=vectorizor.transform(comments_to_score['text'])\n#preds = reg.predict(X_less_toxic).squeeze().tolist()\n#p1 = predictor.predict(X_less_toxic)\np11 = regressor.predict(vectorizor.transform(X_less_toxic))\n#p2 = predictor.predict(X_more_toxic)\np12 = regressor.predict(vectorizor.transform(X_more_toxic))\n# Validation Accuracy\ncompare_list(p11,p12)","526f469f":"# Get the predictions \nscored_sub=regressor.predict(vectorizor.transform(X_comments_to_score)).squeeze().tolist()","3186ae39":"comments_to_score['scores']=scored_sub","d4542ce3":"scores=pd.DataFrame(comments_to_score['scores'].to_list(), columns=['score1','score2', 'score3', 'score4', 'score5', 'score6', 'score7', 'score8', 'score9'])","c209f9ab":"colnames=scores.columns","07eefdf8":"for col in colnames:\n    rank=\"rank\"+col\n    comments_to_score[rank]=rankdata(scores[col], method='ordinal')\n    #print(rank)","827f8ba9":"comments_to_score.head()","f176d32a":"#comments_to_score.columns\ncols=['rankscore1', 'rankscore2', 'rankscore3',\n       'rankscore4', 'rankscore5', 'rankscore6', 'rankscore7', 'rankscore8',\n       'rankscore9']","393a810d":"comments_to_score['score'] = comments_to_score[cols].sum(axis=1)","ebea1413":"comments_to_score['score'] = comments_to_score['rankscore3']","b2282818":"#comments_to_score['grand_slam_ranks']=rankdata( comments_to_score['score'], method='ordinal')","b88d6996":"#submission=comments_to_score.loc[:,['grand_slam_ranks']]","bd153397":"submission=comments_to_score.loc[:,['score']]","7f0981a7":"#submission.rename(columns={\"grand_slam_ranks\": 'score'}, inplace = True)","6553c68f":"submission.to_csv('submission.csv')","685b1f0c":"submission.head()","31850e0f":"Testing the hypothesis","80a2c417":"**Test a number of scoring proposals. **","0139b7cb":"Load data for toxic-severity rating","9b573965":"in my opinion 0.668 for validation is not bad for an independent model.","0f2bab45":"Interannotators agreement as neutral.","a47b7523":"Cutoff","d020bc07":"@inproceedings{hateoffensive, title = {Automated Hate Speech Detection and the Problem of Offensive Language}, author = {Davidson, Thomas and Warmsley, Dana and Macy, Michael and Weber, Ingmar}, booktitle = {Proceedings of the 11th International AAAI Conference on Web and Social Media}, series = {ICWSM '17}, year = {2017}, location = {Montreal, Canada}, pages = {512-515} }\nthe second dataset has an MIT license\n\nA basic test for a scoring algoritm based on the above dataset\n\nWhy? it is a rich dataset for offensive and hate speech tagging. \nIf the test is ok, the model can be applied directly without the initial toxic dataset. "}}