{"cell_type":{"1f113a72":"code","d4eea802":"code","84b9162a":"code","c4174a8c":"code","9f961645":"code","69b1fbac":"code","f64a6860":"code","fd294d4c":"code","a6e8bd39":"code","507eed1a":"code","5134d32b":"code","b671e11b":"code","ca0cc6ad":"code","1613ad9e":"code","df9b64ff":"code","465508e9":"markdown","6bdafe42":"markdown","8686a123":"markdown","5a2babea":"markdown","d82c3e15":"markdown","291ec73c":"markdown","5804d470":"markdown","92bec164":"markdown","54bf25e3":"markdown","fe4b5a2c":"markdown","23c2ad0e":"markdown"},"source":{"1f113a72":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d4eea802":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras.optimizers import RMSprop\nfrom tensorflow.keras import optimizers\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import preprocessing\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom keras.utils import to_categorical\nfrom keras.models import Model\nfrom keras.layers import Input,Flatten,Dense,Conv2D,ReLU,BatchNormalization,MaxPool2D\nfrom keras.optimizers import Adam\nfrom keras.regularizers import l2\n%matplotlib inline","84b9162a":"pd.set_option('display.expand_frame_repr', False)\npd.set_option('display.max_columns', None)  \npd.set_option('max_rows', None)\ndata = pd.read_csv('..\/input\/digit-recognizer\/train.csv')\ntest = pd.read_csv('..\/input\/digit-recognizer\/test.csv')\nY = data['label'].to_numpy()\ndata = data.drop(columns=['label'])\nX = data.to_numpy()\ntest = test.to_numpy()\nX = X.reshape(-1,28,28,1)\ntest = test.reshape(-1,28,28,1)\nX = X\/255.0\ntest = test\/255.0\nindices = np.random.randint(low=0, high=42000, size=10)\nfor i in indices:\n    plt.figure()\n    plt.imshow(X[i,:,:,0], cmap='gray')\nY = to_categorical(Y, 10)","c4174a8c":"X_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size=0.4)\n","9f961645":"model = tf.keras.models.Sequential([\n     tf.keras.layers.Conv2D(32,(5,5), activation = 'relu', input_shape = (28,28,1)),\n     tf.keras.layers.Conv2D(32,(5,5), activation = 'relu'),\n     tf.keras.layers.MaxPooling2D(2,2),\n\n     tf.keras.layers.Conv2D(64,(3,3), activation = 'relu'),\n     tf.keras.layers.Conv2D(64,(3,3), activation = 'relu'),\n     tf.keras.layers.MaxPooling2D(2,2),\n     tf.keras.layers.Dropout(0.25),    \n     tf.keras.layers.Flatten(),\n     tf.keras.layers.Dense(512, activation='relu'),\n     tf.keras.layers.Dense(512, activation='relu'),\n     tf.keras.layers.Dense(512, activation='relu'),\n     tf.keras.layers.Dense(512, activation='relu'),\n     tf.keras.layers.Dropout(0.5),\n\n     tf.keras.layers.Dense(10 , activation = 'softmax')\n])","69b1fbac":"model.summary()","f64a6860":"model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])","fd294d4c":"from keras.callbacks import ModelCheckpoint   \nfrom keras.callbacks import ReduceLROnPlateau\nreduce_lr = ReduceLROnPlateau(monitor='accuracy', factor=0.5, verbose=1,\n                              patience=3, min_lr=0.00001)","a6e8bd39":"from keras.preprocessing.image import ImageDataGenerator\ntrain_datagen = ImageDataGenerator(\nrotation_range = 45,\nwidth_shift_range= 0.05,\nheight_shift_range= 0.05,\nshear_range = 0.05,\nzoom_range = 0.05,\n#horizontal_flip = True,\n#vertical_flip = True,\nfill_mode = 'nearest'\n)\ntrain_datagen.fit(X_train)\n\nvalidation_datagen = ImageDataGenerator(\nrotation_range = 45,\nwidth_shift_range= 0.05,\nheight_shift_range= 0.05,\nshear_range = 0.05,\nzoom_range = 0.05,\n#horizontal_flip = True,\n#vertical_flip = True,\nfill_mode = 'nearest'\n)\nvalidation_datagen.fit(X_test)","507eed1a":"history = model.fit_generator(train_datagen.flow(X_train, Y_train),epochs=50 ,steps_per_epoch=len(X_train)\/32, validation_data=(validation_datagen.fit(X_test),Y_test),callbacks=[reduce_lr],shuffle=True)","5134d32b":"\nwidth = 12\nheight = 10\nplt.figure(figsize=(width, height))\nplt.xlabel('Epoch Number')\nplt.ylabel(\"Loss Magnitude\")\nplt.plot(history.history['loss'])\nplt.show()","b671e11b":"width = 12\nheight = 10\nplt.figure(figsize=(width, height))\nplt.xlabel('Epoch Number')\nplt.ylabel(\"Accuracy Magnitude\")\nplt.plot(history.history['val_accuracy'])\nplt.show()","ca0cc6ad":"pred = model.predict(test)\npreds = pred.argmax(axis=1)\nimageid = np.arange(1,28001)\noutput = pd.DataFrame({\"ImageId\": imageid,\"Label\": preds})\noutput.to_csv('submissions_IA1.csv', index=False)","1613ad9e":"\nresult= pd.read_csv('..\/input\/digit-recog-score\/submissions1 (1).csv')\nresult=result.drop(columns=['ImageId'],axis=1)\n","df9b64ff":"# DISTRIBUTION \nplt.figure(figsize=(width, height))\n\nax1 = sns.distplot(preds, hist=False, color=\"b\", label=\"New Prediction\")\nsns.distplot(result, hist=False, color=\"g\", label=\"Previous Prediction\" , ax=ax1)\n\n\n\nplt.show()\nplt.close()","465508e9":"# Model Summary","6bdafe42":"# Splitting the data into Training Set and Testing Set","8686a123":"# Building a Sequential Model With 5 Convolution layer and 3 Max Pooling Layer\n","5a2babea":"# Preprocessing Data","d82c3e15":"# Model Compilation","291ec73c":"# Importing Libraries","5804d470":"# Training The Model","92bec164":"# Plotting Accuracy of the traning model","54bf25e3":"# Plotting Loss of the traning model","fe4b5a2c":"# Creating Callbacks","23c2ad0e":"# Image Augmentation"}}