{"cell_type":{"e0d908a5":"code","18697457":"code","88f7b02f":"code","a81b7d6e":"code","ac9dae61":"code","8fe28f65":"code","4be4be4e":"code","67fcb365":"code","0e77048e":"code","177db8d6":"code","de97b664":"markdown","1e6d9507":"markdown","a998dd55":"markdown","5383a831":"markdown","f75fa5eb":"markdown","98c7eb52":"markdown"},"source":{"e0d908a5":"import pandas as pd\nimport numpy as np\nfrom sklearn.model_selection import KFold\nfrom sklearn.metrics import roc_auc_score\nfrom xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom lightgbm import LGBMClassifier\nfrom catboost import CatBoostClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport optuna","18697457":"df=pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/train.csv\")\ndf_test=pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/test.csv\")\nsample_submission=pd.read_csv(\"..\/input\/tabular-playground-series-nov-2021\/sample_submission.csv\")\ntest_df=df_test.copy()\n","88f7b02f":"#taking only useful columns for predictions\nuseful_cols=[c for c in df.columns if c not in (\"id\",\"target\",\"kfold\")]\ndf_test=df_test[useful_cols]","a81b7d6e":"#First we dividing the data into 5 folds so our model won't overfit\nkf=KFold(n_splits=5,random_state=42,shuffle=True)\nfor fold,(train_index,valid_index) in enumerate(kf.split(X=df)):\n    df.loc[valid_index,\"kfold\"]=fold\n    \n    \nfinal_test_pred=[]\nfinal_valid_pred={}\nscores=[]\n\n\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)#training set=4 folds\n    xvalid=df[df.kfold == fold].reset_index(drop=True)#validation set=1 fold\n    xtest=df_test.copy()\n    \n    valid_id=xvalid.id.values.tolist()#since we are shuffiling the data we need to kepp track of the id\n    #test_id=xtest.id.values.tolist()\n    \n    \n    ytrain=xtrain.target\n    yvalid=xvalid.target\n    \n    xtrain=xtrain[useful_cols]#taking only useful columns\n    xvalid=xvalid[useful_cols]\n    \n    #our model\n    model=XGBClassifier(random_state=fold,\n                        predictor=\"gpu_predictor\",\n                        tree_method='gpu_hist')\n    \n    model.fit(xtrain,ytrain)\n    pred_valid=model.predict(xvalid)#predicting on validation set\n    pred_test=model.predict(xtest)#predicting on test set\n    final_test_pred.append(pred_test)#appending the test predictions\n    final_valid_pred.update(dict(zip(valid_id,pred_valid)))#updating the vaid predicions\n    score=roc_auc_score(yvalid,pred_valid)\n    print(score,fold)\n    scores.append(score)#calculating and appendint the scores\n    \n    \n    \nprint(np.mean(scores)) \n#converting our valid predictions to a dataframe\nfinal_valid_pred=pd.DataFrame.from_dict(final_valid_pred,orient='index').reset_index()\nfinal_valid_pred.columns=['id',\"preds_1\"]\nfinal_valid_pred.to_csv('train_pred_1.csv',index=False)\n\n#converting our test predictions to a dataframe\nsample_submission.target=np.mean(np.column_stack(final_test_pred),axis=1)\nsample_submission.columns=['id','preds_1']\nsample_submission.to_csv(\"test_pred_1.csv\",index=False)\n    \n    ","ac9dae61":"kf=KFold(n_splits=5,random_state=42,shuffle=True)\nfor fold,(train_index,valid_index) in enumerate(kf.split(X=df)):\n    df.loc[valid_index,\"kfold\"]=fold\n    \n    \nfinal_test_pred=[]\nfinal_valid_pred={}\nscores=[]\n\n\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)\n    xvalid=df[df.kfold == fold].reset_index(drop=True)\n    xtest=df_test.copy()\n    \n    valid_id=xvalid.id.values.tolist()\n    #test_id=xtest.id.values.tolist()\n    \n    \n    ytrain=xtrain.target\n    yvalid=xvalid.target\n    \n    xtrain=xtrain[useful_cols]\n    xvalid=xvalid[useful_cols]\n    \n    model=LGBMClassifier(device = \"gpu\",\n                    gpu_platform_id=0,\n                     gpu_device_id = 0)\n    \n    model.fit(xtrain,ytrain)\n    pred_valid=model.predict(xvalid)\n    pred_test=model.predict(xtest)\n    final_test_pred.append(pred_test)\n    final_valid_pred.update(dict(zip(valid_id,pred_valid)))\n    score=roc_auc_score(yvalid,pred_valid)\n    print(score,fold)\n    scores.append(score)\n    \n    \n    \nprint(np.mean(scores))    \n    \nfinal_valid_pred=pd.DataFrame.from_dict(final_valid_pred,orient='index').reset_index()\nfinal_valid_pred.columns=['id',\"preds_2\"]\nfinal_valid_pred.to_csv('train_pred_2.csv',index=False)\n\nsample_submission.target=np.mean(np.column_stack(final_test_pred),axis=1)\nsample_submission.columns=['id','preds_2']\nsample_submission.to_csv(\"test_pred_2.csv\",index=False)    \n    ","8fe28f65":"kf=KFold(n_splits=5,random_state=42,shuffle=True)\nfor fold,(train_index,valid_index) in enumerate(kf.split(X=df)):\n    df.loc[valid_index,\"kfold\"]=fold\n    \n    \nfinal_test_pred=[]\nfinal_valid_pred={}\nscores=[]\n\n\n\nfor fold in range(5):\n    xtrain=df[df.kfold != fold].reset_index(drop=True)\n    xvalid=df[df.kfold == fold].reset_index(drop=True)\n    xtest=df_test.copy()\n    \n    valid_id=xvalid.id.values.tolist()\n    #test_id=xtest.id.values.tolist()\n    \n    \n    ytrain=xtrain.target\n    yvalid=xvalid.target\n    \n    xtrain=xtrain[useful_cols]\n    xvalid=xvalid[useful_cols]\n    \n    model=CatBoostClassifier(task_type = \"GPU\")\n    \n    model.fit(xtrain,ytrain)\n    pred_valid=model.predict(xvalid)\n    pred_test=model.predict(xtest)\n    final_test_pred.append(pred_test)\n    final_valid_pred.update(dict(zip(valid_id,pred_valid)))\n    score=roc_auc_score(yvalid,pred_valid)\n    print(score,fold)\n    scores.append(score)\n    \n    \n    \nprint(np.mean(scores))    \n\nfinal_valid_pred=pd.DataFrame.from_dict(final_valid_pred,orient='index').reset_index(\n)\nfinal_valid_pred.columns=['id',\"preds_3\"]\nfinal_valid_pred.to_csv('train_pred_3.csv',index=False)\n\nsample_submission.target=np.mean(np.column_stack(final_test_pred),axis=1)\nsample_submission.columns=['id','preds_3']\nsample_submission.to_csv(\"test_pred_3.csv\",index=False)\n    \n    \n    ","4be4be4e":"#reading the prediction on vaidation set of the 3 model\ndf1=pd.read_csv(\".\/train_pred_1.csv\")\ndf2=pd.read_csv(\".\/train_pred_2.csv\")\ndf3=pd.read_csv(\".\/train_pred_3.csv\")\n\n#reading the prediction of test set of the 3 model\ndf_test1=pd.read_csv(\".\/test_pred_1.csv\")\ndf_test2=pd.read_csv(\".\/test_pred_2.csv\")\ndf_test3=pd.read_csv(\".\/test_pred_3.csv\")\n\n#we are merging the predictions with the original dataframe\n\ndf=df.merge(df1,on=\"id\",how=\"left\")\ndf=df.merge(df2,on=\"id\",how=\"left\")\ndf=df.merge(df3,on=\"id\",how=\"left\")\n\ntest_df=test_df.merge(df1,on=\"id\",how=\"left\")\ntest_df=test_df.merge(df2,on=\"id\",how=\"left\")\ntest_df=test_df.merge(df3,on=\"id\",how=\"left\")\n\n","67fcb365":"def objective(trial):\n    \n    #These are the feature we are goint to use for predictions\n    final_useful_features=['preds_1','preds_2','preds_3']\n\n    kf=KFold(n_splits=5,random_state=42,shuffle=True)\n    for fold,(train_index,valid_index) in enumerate(kf.split(X=df)):\n        df.loc[valid_index,\"kfold\"]=fold\n\n\n    final_pred=[]\n    final_valid_pred={}\n    scores=[]\n\n\n\n    for fold in range(5):\n        xtrain=df[df.kfold != fold].reset_index(drop=True)\n        xvalid=df[df.kfold == fold].reset_index(drop=True)\n        xtest=test_df.copy()\n\n        valid_id=xvalid.id.values.tolist()\n        #test_id=xtest.id.values.tolist()\n\n\n        ytrain=xtrain.target\n        yvalid=xvalid.target\n\n        xtrain=xtrain[final_useful_features]\n        xvalid=xvalid[final_useful_features]\n        xtest=xtest[final_useful_features]\n\n\n        params = {\n            'learning_rate': 0.07853392035787837,\n            'reg_lambda': 1.7549293092194938e-05,\n            'reg_alpha': 14.68267919457715, \n            'subsample': 0.8031450486786944, \n            'colsample_bytree': 0.170759104940733, \n            'max_depth': 3\n        }\n\n        model = XGBClassifier(\n            random_state=fold,\n            n_jobs=4,\n            n_estimators=5000,\n            **params\n        )\n\n        model.fit(xtrain,ytrain)\n        pred_valid=model.predict(xvalid)\n        pred_test=model.predict(xtest)\n        final_pred.append(pred_test)\n        final_valid_pred.update(dict(zip(valid_id,pred_valid)))\n        score=roc_auc_score(yvalid,pred_valid)\n        print(score,fold)\n        scores.append(score)\n    \n    \n    \nprint(np.mean(scores)) \n    \n    ","0e77048e":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objective, n_trials=5)","177db8d6":"sample_submission.target=np.mean(np.column_stack(final_test_pred),axis=1)\nsample_submission.columns=['id','target']\nsample_submission.to_csv(\"my_output1.csv\",index=False)","de97b664":"## xgboost","1e6d9507":"## catboost","a998dd55":"## Import libarires","5383a831":"## lightgbm","f75fa5eb":"## Submission","98c7eb52":"## We are combining 3 diffrent models for our final predictions(xgboost,lightgbm,catboost).This is called model blending"}}