{"cell_type":{"8504e1cb":"code","2db7c31a":"code","568c062d":"code","da1302a3":"code","eec995eb":"code","a95815e1":"code","b4d875d0":"code","17b728ef":"markdown"},"source":{"8504e1cb":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","2db7c31a":"train = pd.read_csv('\/kaggle\/input\/twitter-sentiment-analysis-hatred-speech\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/twitter-sentiment-analysis-hatred-speech\/test.csv')\n# remove the unwanted columns from the train and test\ntest.drop(['id'], axis = 1, inplace = True)\ntrain.drop(['id'], axis = 1, inplace = True)\n\ntest.head()","568c062d":"# wordclod for all the words in train\nfrom wordcloud import WordCloud\nimport matplotlib.pyplot as plt\ntxt = \" \".join(text for text in test['tweet'])\n\nwordcloud = WordCloud(max_font_size = 100, max_words = 50, background_color = 'orange').generate(txt)\n\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()","da1302a3":"# lets remove the stopwords\nimport nltk\nimport re\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\n\ntest = pd.read_csv('\/kaggle\/input\/twitter-sentiment-analysis-hatred-speech\/test.csv')\n# remove the unwanted columns from the train and test\ntest.drop(['id'], axis = 1, inplace = True)\nstop_words = stopwords.words('english')\nstop_words.append('@user')\n\n\ntxt = \" \".join(text for text in test['tweet'])\n\nprint('before -- ',len(txt))\ntxt = txt.split()\nred_txt = []\nfor i in (range(len(txt))):\n    if txt[i] not in stop_words and len(txt[i])>3:\n        red_txt.append(txt[i])\nprint('After===',len(red_txt))\nred_txt = ' '.join(red_txt)\nred_txt = red_txt.split()\n\nhashtags = []\nfor i in red_txt:\n    ht = re.findall(r\"#(\\w+)\", i)\n    hashtags.append(ht)\nhashtags\n\ncomments = sum(hashtags,[])\nfreq = nltk.FreqDist(comments)\nfreq","eec995eb":"df = pd.DataFrame({'tag' : list(freq.keys()),\n                  'counts' : list(freq.values())\n                  })\ntop10 = df.nlargest(10, 'counts')\ntop10","a95815e1":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nplt.figure(figsize=(16,5))\nax = sns.barplot(data=top10, x= \"tag\", y = \"counts\")\nax.set(ylabel = 'counts')\nplt.show()","b4d875d0":"# for a better word cloud\ntop80 = df.nlargest(25, 'counts')\nwords = ' '.join(words for words in top80['tag'])\nwordcloud = WordCloud(max_font_size = 100, max_words = 50, background_color = 'orange').generate(words)\nplt.figure(figsize = (12, 6))\nplt.imshow(wordcloud, interpolation = 'bilinear')\nplt.axis(\"off\")\nplt.show()\n","17b728ef":"Different approach on extracting the hashtag words from a dataframe..."}}