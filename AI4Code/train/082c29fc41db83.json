{"cell_type":{"a0262439":"code","07a4674a":"code","52dcbfa8":"code","07ccb189":"code","25952de1":"code","ef8086ca":"code","ec22c937":"code","0461852a":"code","7ba31784":"code","87c38567":"code","158876da":"code","d92c8172":"code","27b5588f":"code","19ab4fb5":"code","287d2de9":"code","c770c38b":"code","1682795d":"code","418991c5":"code","4deb6b18":"code","c4570c72":"code","fb1346d3":"code","58b197f3":"code","e9d12253":"code","2453e12d":"code","b0a86157":"code","f707b9b1":"code","86632320":"code","f52bbc22":"code","3836f5da":"code","08efa109":"code","1cb44dfc":"code","eafa2253":"code","275e91b3":"code","8d725720":"code","324a692d":"code","8f23d183":"code","837d32e7":"code","c61def81":"code","ac505de4":"code","7411713b":"code","e8f0defc":"code","c35b8978":"code","373920a9":"code","152766c3":"code","b06ba33b":"code","f6ede35b":"code","c9650c31":"code","33861318":"code","56822982":"code","fc4939ec":"code","31e3a52c":"code","cd5b6288":"code","3b5403f9":"code","d16e86a1":"code","ae6f7d35":"code","c264b111":"code","7c12df62":"code","5d3790c2":"code","899fe9e7":"code","804938c3":"code","cd97a25a":"code","f9a5f113":"markdown","5b13b41d":"markdown","1476ec4e":"markdown"},"source":{"a0262439":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","07a4674a":"pd.set_option('display.max_columns', None)","52dcbfa8":"train_data = pd.read_csv(\"\/kaggle\/input\/analytics-vidhya-ltfs-data-science-finhack-3\/Data\/Data\/train_Data.csv\")\ntrain_bureau = pd.read_csv(\"\/kaggle\/input\/analytics-vidhya-ltfs-data-science-finhack-3\/Data\/Data\/train_bureau.csv\")\n\ntest_data = pd.read_csv(\"\/kaggle\/input\/analytics-vidhya-ltfs-data-science-finhack-3\/Data\/Data\/test_Data.csv\")\ntest_bureau = pd.read_csv(\"\/kaggle\/input\/analytics-vidhya-ltfs-data-science-finhack-3\/Data\/Data\/test_bureau.csv\")","07ccb189":"train_bureau = train_bureau.drop_duplicates()\ntest_bureau = test_bureau.drop_duplicates()","25952de1":"train_data['source'] = 'train'\ntest_data['source'] = 'test'\n\ntrain_bureau['source'] = 'train'\ntest_bureau['source'] = 'test'","ef8086ca":"bureau = pd.concat([train_bureau, test_bureau])\ndata = pd.concat([train_data, test_data])","ec22c937":"for col in bureau.columns:\n    if bureau[col].dtype=='object':\n        print(bureau[col].value_counts())\n        print('')","0461852a":"bureau['ACCT-TYPE'] = bureau['ACCT-TYPE'].replace(bureau['ACCT-TYPE'].value_counts()[bureau['ACCT-TYPE'].value_counts()\/bureau.shape[0]*100<3].index, 'Rest')\nbureau['ACCT-TYPE'].value_counts()","7ba31784":"bureau['CONTRIBUTOR-TYPE'] = bureau['CONTRIBUTOR-TYPE'].replace(['HFC', 'MFI', 'FRB',\n       'SFB', 'ARC', 'OFI' ,'CCC'], 'OTHERS')\nbureau['CONTRIBUTOR-TYPE'].value_counts()","87c38567":"bureau['ACCOUNT-STATUS'] = bureau['ACCOUNT-STATUS'].replace(['SUIT FILED (WILFUL DEFAULT)',\n       'Written Off', 'Suit Filed', 'Restructured', 'Settled',\n       'WILFUL DEFAULT', 'Cancelled', 'Sold\/Purchased'], 'Written Off')\nbureau['ACCOUNT-STATUS'].value_counts()","158876da":"bureau.isnull().sum()[bureau.isnull().sum()>0]\/bureau.shape[0]*100","d92c8172":"#drop columns with greater than 20% null values\nbureau.drop(bureau.isnull().sum()[bureau.isnull().sum()\/bureau.shape[0]*100>20].index, axis=1, inplace=True)","27b5588f":"bureau.isnull().sum()[bureau.isnull().sum()>0]\/bureau.shape[0]*100","19ab4fb5":"#can drop hist columns for now\nbureau = bureau.drop(['REPORTED DATE - HIST', 'DPD - HIST', 'CUR BAL - HIST',\n       'AMT OVERDUE - HIST', 'AMT PAID - HIST'], axis=1)","287d2de9":"bureau['DISBURSED-DT'] = pd.to_datetime(bureau['DISBURSED-DT'])\nbureau['DATE-REPORTED'] = pd.to_datetime(bureau['DATE-REPORTED'])\nbureau['DATE-REPORTED'].max(), bureau['DISBURSED-DT'].max()","c770c38b":"bureau['DATE-REPORTED'] = bureau['DATE-REPORTED'].fillna(bureau['DATE-REPORTED'].max())\nbureau['DISBURSED-DT'] = bureau['DISBURSED-DT'].fillna(bureau['DATE-REPORTED'])","1682795d":"bureau.drop('MATCH-TYPE', axis=1, inplace=True)","418991c5":"bureau['CURRENT-BAL'] = bureau['CURRENT-BAL'].apply(lambda x: str(x).replace(',', ''))\nbureau['DISBURSED-AMT\/HIGH CREDIT'] = bureau['DISBURSED-AMT\/HIGH CREDIT'].apply(lambda x: str(x).replace(',', ''))\nbureau['WRITE-OFF-AMT'] = bureau['WRITE-OFF-AMT'].apply(lambda x: str(x).replace(',', ''))","4deb6b18":"#bureau['CURRENT-BAL'] = bureau['CURRENT-BAL'].fillna('0')\nbureau.isnull().sum()","c4570c72":"for col in bureau.columns[-4:-1]:\n    print(col)\n    bureau[col] = bureau[col].replace('nan', 0)\n    bureau[col] = bureau[col].apply(lambda x: float(x))","fb1346d3":"bureau.head()","58b197f3":"bureau = pd.get_dummies(data=bureau, columns=['ACCT-TYPE', 'OWNERSHIP-IND', 'CONTRIBUTOR-TYPE', \n                                    'ACCOUNT-STATUS'])","e9d12253":"bureau.columns","2453e12d":"bureau_data = bureau.groupby(['ID', 'source']).sum().reset_index()\nbureau_data.to_csv('bureau_data.csv', index=False)","b0a86157":"bureau_data.head()","f707b9b1":"df = pd.read_csv('bureau_data.csv')\ndf.head()","86632320":"df.tail()","f52bbc22":"#target variable is \"Top-up Month\"","3836f5da":"# can drop unwanted columns\ndata = data.drop(['Area', 'BranchID', 'City', 'ZiPCODE'], axis=1)","08efa109":"data['DisbursalDate'] = pd.to_datetime(data['DisbursalDate'])\ndata['MaturityDAte'] = pd.to_datetime(data['MaturityDAte'])\ndata['AuthDate'] = pd.to_datetime(data['AuthDate'])","1cb44dfc":"for col in data.columns:\n    if data[col].dtype=='object':\n        print(data[col].value_counts())\n        print('')","eafa2253":"data['State'] = data['State'].replace(data['State'].value_counts()[data['State'].value_counts()\/data.shape[0]*100<3].index, 'Rest')\ndata['State'].value_counts()","275e91b3":"data['PaymentMode'] = data['PaymentMode'].replace(data['PaymentMode'].value_counts()[data['PaymentMode'].value_counts()\/data.shape[0]*100<3].index, 'Rest')\ndata['PaymentMode'].value_counts()","8d725720":"data.isnull().sum()","324a692d":"cat_cols = ['ManufacturerID', 'SupplierID', 'AssetID']\nfor col in cat_cols:\n    print('value counts')\n    print(data[col].value_counts())\n    print('number of unique values', data[col].nunique())\n    print()","8f23d183":"data.drop(['SupplierID', 'AssetID'], axis=1, inplace=True)","837d32e7":"data['ManufacturerID'] = data['ManufacturerID'].replace(data['ManufacturerID'].value_counts()[data['ManufacturerID'].value_counts()\/data.shape[0]*100<3].index, 'Rest')\ndata['ManufacturerID'].value_counts()","c61def81":"data.head()","ac505de4":"data['MonthlyIncome'] = data['MonthlyIncome'].fillna(0)\ndata['SEX'] = data['SEX'].fillna(data['SEX'].mode()[0])\ndata['AGE'] = data['AGE'].fillna(data['AGE'].mode()[0])\ndata['ManufacturerID'] = data['ManufacturerID'].fillna(data['ManufacturerID'].mode()[0])\ndata['MaturityDAte'] = data['MaturityDAte'].fillna(data['MaturityDAte'].mode()[0])","7411713b":"from sklearn.preprocessing import LabelEncoder, StandardScaler","e8f0defc":"data.columns","c35b8978":"le = LabelEncoder()\ncat_cols = ['Frequency', 'InstlmentMode', 'LoanStatus', 'PaymentMode', 'SEX', 'State']\n\nfor col in cat_cols:\n    print(col)\n    data[col] = le.fit_transform(data[col])","373920a9":"num_cols = ['AssetCost', 'AmountFinance', 'DisbursalAmount', 'EMI', 'MonthlyIncome']\n#scaler = StandardScaler()\n\"\"\"for col in num_cols:\n    print(col)\n    data[col] = scaler.fit_transform(np.array(data[col]).reshape(-1,1))\"\"\"\n\nfor col in num_cols:\n    data[col] = np.log(1+data[col])\n    print(col)","152766c3":"data.drop(['DisbursalDate', 'MaturityDAte', 'AuthDate'], axis=1, inplace=True)\ndata.head()","b06ba33b":"data['EMItoIncome'] = data['EMI']\/data['MonthlyIncome']\ndata['AssettoIncome'] = data['AssetCost']\/(data['MonthlyIncome']*12)\ndata['DifferenceAmount'] = data['AmountFinance'] - data['DisbursalAmount']\ndata['YearsOfService'] = 60 - data['AGE']","f6ede35b":"num_cols = ['AssetCost', 'AmountFinance', 'DisbursalAmount', 'EMI', 'MonthlyIncome']\n#scaler = StandardScaler()\n\"\"\"for col in num_cols:\n    print(col)\n    data[col] = scaler.fit_transform(np.array(data[col]).reshape(-1,1))\"\"\"\n\nfor col in num_cols:\n    data[col] = np.log(1+data[col])\n    print(col)","c9650c31":"data.head()","33861318":"data.drop('AGE', 1, inplace=True)","56822982":"data.to_csv('cleaned_data.csv', index=False)","fc4939ec":"final = pd.merge(data, df, on=['ID', 'source'], how='inner')\nfinal.head()","31e3a52c":"train_df = final[final['source']=='train']\ntest_df = final[final['source']=='test']","cd5b6288":"train_df.drop('source',1, inplace=True)\ntest_df.drop(['source', 'Top-up Month'],1, inplace=True)","3b5403f9":"test_df.shape, test_data.shape","d16e86a1":"from sklearn.model_selection import train_test_split\n\ntrain = train_df.drop('ID', 1)\nX = train_df.drop(['ID', 'Top-up Month'], 1)\ny = train_df['Top-up Month']\n\ntrain_X, test_X, train_y ,test_y = train_test_split(X, y, test_size=0.2, random_state=42)\n\ntest = test_df.drop(['ID'], 1)\ntrain_X.shape, train_y.shape, test.shape","ae6f7d35":"from xgboost import XGBClassifier\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom catboost import CatBoostClassifier","c264b111":"!pip install pycaret","7c12df62":"from pycaret.classification import *","5d3790c2":"clf = setup(data = train, target = 'Top-up Month', session_id=123)","899fe9e7":"#best_model = compare_models()","804938c3":"models()","cd97a25a":"cat = create_model('catboost')\nplot_model(cat, plot='feature')\ntest_pred = predict_model(cat, data=test)\nsubm = pd.DataFrame({'ID': test_df['ID'], 'Top-up Month': test_pred['Label']})\nsubm.to_csv('pycaret_catboost.csv', index=False)","f9a5f113":"Can drop MATCH-TYPE, since very few are of secondary type\nfix account status\nfix contributor type","5b13b41d":"# Working on Bureau Data","1476ec4e":"# Working on demographic data"}}