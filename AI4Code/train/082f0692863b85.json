{"cell_type":{"35f00240":"code","4334fcc8":"code","92189ef7":"code","e776fd9b":"code","9eeedab8":"code","ea642a36":"code","41cda484":"code","d64f9c63":"code","f9c8fa0b":"code","af15d3c3":"code","12ca7462":"code","323e3446":"code","a27c3b62":"code","c8c46d98":"code","1b4948c7":"code","d7691034":"code","e62c3726":"code","eb7ad3df":"code","500e622d":"code","04e06d6f":"code","acb4f0ec":"code","af6dd008":"code","195e302d":"code","cb552040":"code","ace73178":"code","bc818ebc":"code","13f6d365":"code","63704897":"code","2d5a1f79":"code","bba6f5ec":"code","326d39ab":"code","f90fe3d2":"code","b111ffc5":"markdown","93ae3c9e":"markdown","52a8dbd9":"markdown","10b842b2":"markdown","3071719e":"markdown","8a2debf5":"markdown","44fd5166":"markdown","a0630a1d":"markdown","c2823830":"markdown","e2a63f6b":"markdown","2baae2cc":"markdown","1897076a":"markdown","171f6f17":"markdown","41fbc718":"markdown","16a367bb":"markdown","53e66262":"markdown","c5ee52d1":"markdown","8c168549":"markdown","c5ba6aa0":"markdown","37c52500":"markdown","e66d7cf9":"markdown","7f37ffdb":"markdown","54ff9b02":"markdown","77298d85":"markdown","0eec6084":"markdown","82e23f63":"markdown"},"source":{"35f00240":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport scipy.stats as stats\nimport matplotlib.pyplot as plt\nimport os\nimport warnings\nwarnings.filterwarnings('ignore')\nimport os\n\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","4334fcc8":"df=pd.read_csv(\"..\/input\/mobile-price-classification\/train.csv\")","92189ef7":"df.info()","e776fd9b":"df.describe()","9eeedab8":"#Se analizan las clases, para saber si es un dataset con clases balanceadas o no\n\nplt.figure(figsize=(8,3))\nsns.countplot(df.price_range)\nplt.title('Class distribution')\nplt.show()","ea642a36":"# Matriz de Correlacion solo para Features\ncorrelacion=df.corr()\nplt.figure(figsize = (22,11))\nsns.set(font_scale=1)\nsns.heatmap(correlacion, annot = True)\nplt.show()","41cda484":"#Estandarizaci\u00f3n de variables continuas.\n\nfrom sklearn.preprocessing import StandardScaler\n\nX=df.drop(\"price_range\",axis=1)\nscaler = StandardScaler()\nscaler.fit(X)\nX=pd.DataFrame(scaler.transform(X),columns=X.columns.values)\n\n","d64f9c63":"X.describe()","f9c8fa0b":"from tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Dense","af15d3c3":"# Numero de clases\nnum_classes = 4\n\ny = df['price_range']\n\n# generar las etiquetas\ny = keras.utils.to_categorical(y, num_classes)\ny","12ca7462":"# tamano de los atributos de entrada\ninput_shape = (20)\n\n# definicion del modelo Perceptron\nmodel = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        #layers.Flatten(),\n        layers.Dense(200, activation=\"relu\"),\n        layers.Dense(num_classes, activation=\"softmax\"),\n    ]\n)\n\n# Construir el modelo y ver la arquitectura\nmodel.build(input_shape)\nmodel.summary()","323e3446":"# Definir los parametros de optimizacion y perdida del modelo (con CrossValidation)\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","a27c3b62":"# ejecutar training\nhistory = model.fit(X, y, epochs=15, batch_size=20, verbose=1, validation_split=0.4)","c8c46d98":"from plotly.subplots import make_subplots\nimport plotly.graph_objects as go\n\nfig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(go.Scatter(\n    y=history.history['loss'],\n    mode='lines+markers',\n    name='training loss'\n), row=1, col=1)\n\nfig.add_trace(go.Scatter(\n    y=history.history['val_loss'],\n    mode='lines+markers',\n    name='validation loss'\n), row=1, col=1)\n\n\nfig.add_trace(go.Scatter(\n    y=history.history['accuracy'],\n    mode='lines+markers',\n    name='training accuracy'\n), row=1, col=2)\n\nfig.add_trace(go.Scatter(\n    y=history.history['val_accuracy'],\n    mode='lines+markers',\n    name='validation accuracy'\n), row=1, col=2)\n\nfig.update_xaxes(title_text='Epoch')\nfig.update_layout(title_text=\"Training History Metrics\")\nfig.show()","1b4948c7":"# tamano de los atributos de entrada\ninput_shape = (3)\n\n# definicion del modelo Perceptron\nmodel2 = keras.Sequential(\n    [\n        keras.Input(shape=input_shape),\n        #layers.Flatten(),\n        layers.Dense(200, activation=\"relu\"),\n        layers.Dense(num_classes, activation=\"softmax\"),\n    ]\n)\n\n# Construir el modelo y ver la arquitectura\nmodel2.build(input_shape)\nmodel2.summary()","d7691034":"# Definir los parametros de optimizacion y perdida del modelo (con CrossValidation)\nmodel2.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])","e62c3726":"# ejecutar training\nX_simplified= X[['battery_power', 'px_height', 'ram']]\nhistory2 = model2.fit(X_simplified, y, epochs=15, batch_size=20, verbose=1, validation_split=0.4)","eb7ad3df":"fig = make_subplots(rows=1, cols=2)\n\nfig.add_trace(go.Scatter(\n    y=history2.history['loss'],\n    mode='lines+markers',\n    name='training loss'\n), row=1, col=1)\n\nfig.add_trace(go.Scatter(\n    y=history2.history['val_loss'],\n    mode='lines+markers',\n    name='validation loss'\n), row=1, col=1)\n\n\nfig.add_trace(go.Scatter(\n    y=history2.history['accuracy'],\n    mode='lines+markers',\n    name='training accuracy'\n), row=1, col=2)\n\nfig.add_trace(go.Scatter(\n    y=history2.history['val_accuracy'],\n    mode='lines+markers',\n    name='validation accuracy'\n), row=1, col=2)\n\nfig.update_xaxes(title_text='Epoch')\nfig.update_layout(title_text=\"Training History Metrics\")\nfig.show()","500e622d":"from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n\ny_pred= model.predict(X)\n\nf, axes = plt.subplots(2, 2, figsize=(10, 10))\naxes = axes.ravel()\nfor i in range(4):\n    disp = ConfusionMatrixDisplay(confusion_matrix(y[:, i],\n                                                   np.rint(y_pred[:, i])),\n                                  display_labels=[0, i])\n    disp.plot(ax=axes[i], values_format='.4g')\n    disp.ax_.set_title(f'class {i}')\n    if i<10:\n        disp.ax_.set_xlabel('')\n    if i%5!=0:\n        disp.ax_.set_ylabel('')\n    disp.im_.colorbar.remove()\n\nplt.subplots_adjust(wspace=0.10, hspace=0.1)\nf.colorbar(disp.im_, ax=axes)\nplt.show()","04e06d6f":"y_pred2= model2.predict(X_simplified)\n\nf, axes = plt.subplots(2, 2, figsize=(10, 10))\naxes = axes.ravel()\nfor i in range(4):\n    disp = ConfusionMatrixDisplay(confusion_matrix(y[:, i],\n                                                   np.rint(y_pred2[:, i])),\n                                  display_labels=[0, i])\n    disp.plot(ax=axes[i], values_format='.4g')\n    disp.ax_.set_title(f'class {i}')\n    if i<10:\n        disp.ax_.set_xlabel('')\n    if i%5!=0:\n        disp.ax_.set_ylabel('')\n    disp.im_.colorbar.remove()\n\nplt.subplots_adjust(wspace=0.10, hspace=0.1)\nf.colorbar(disp.im_, ax=axes)\nplt.show()","acb4f0ec":"divorce=pd.read_csv(\"..\/input\/divorce-predictors-data-set\/divorce.csv\",sep=\";\")","af6dd008":"divorce","195e302d":"divorce.info()","cb552040":"divorce.describe()","ace73178":"#Se analizan las distribuciones\ndivorce.hist(bins=30, figsize=(25,15))\nplt.show()","bc818ebc":"#Se analizan las clases, para saber si es un dataset con clases balanceadas o no\n\nplt.figure(figsize=(8,3))\nsns.countplot(divorce.Class)\nplt.title('Class distribution')\nplt.show()","13f6d365":"# Matriz de Correlacion solo para Features\ncorrelacion=divorce.corr()\nplt.figure(figsize = (30,11))\nsns.set(font_scale=1)\nsns.heatmap(correlacion, annot = False)\nplt.show()","63704897":"#Estandarizaci\u00f3n de variables continuas.\n\nfrom sklearn.preprocessing import StandardScaler\n\nX_div=divorce.drop(\"Class\",axis=1)\nscaler = StandardScaler()\nscaler.fit(X_div)\nX_div=pd.DataFrame(scaler.transform(X_div),columns=X_div.columns.values)","2d5a1f79":"from sklearn.linear_model import Perceptron\nfrom sklearn.model_selection import train_test_split\n\ny=divorce.Class\n\nX_train, X_test, y_train, y_test = train_test_split(X_div, y, test_size=0.33, random_state=42)\n\n# Create and fit a perceptron model (with reproducible\n# random seed)\nmodelP = Perceptron(random_state=42)\nmodelP.fit(X_train, y_train)\n\n# Output the (in sample) mean accuracy score\n# of the classification\nprint(\"%0.3f\" % modelP.score(X_train, y_train))","bba6f5ec":"#Se prueba con el dataset de validaci\u00f3n\nprint(\"%0.3f\" % modelP.score(X_test, y_test))\n","326d39ab":"y_pred= modelP.predict(X_div)\n\nfrom sklearn.metrics import plot_confusion_matrix\n\n# cantidad de decimales\nnp.set_printoptions(precision=2)\nfig, ax = plt.subplots(figsize=(7, 7))\n# Plot non-normalized confusion matrix\ndisp = plot_confusion_matrix(modelP, X_div, y, display_labels=y.unique(),normalize=None,ax=ax)\nplt.title('Confusion matrix')\nplt.show()","f90fe3d2":"#Se imprime el reporte para el dataset completo\n\nfrom sklearn.metrics import classification_report\n\nprint(classification_report(modelP.predict(X_div), y))","b111ffc5":"### 3.1 Matriz de confusi\u00f3n para modelo 1","93ae3c9e":"## Parte 1. Usando Keras","52a8dbd9":"Inicialmente se habia definido 10 epochs y batch size de 250, sin embargo se realizaron dos pruebas, reduciendo el batch size y aumentando los epochs, lo que generan un mejor resultado de accuracy cuando se modifican ambos valores en el training, pero no tan significativas las mejoras para el test. En este caso se definio como valor final 15 epochs y 20 de batch size","10b842b2":"Se comprueba que las columnas ahora tengan media 0 y desviacion de 1","3071719e":"El modelo simplificado, a mi parecer presenta un mejor resultado de forma global, ya que el accuracy entre el training y el test tiene un diferencial muy peque\u00f1o, lo que nos nos puede dar la idea de que el modelo con el dataset completo se estaba sobreajustando ","8a2debf5":"### 2. Implementaci\u00f3n red neuronal de una capa","44fd5166":"### 3.2 Matriz de confusi\u00f3n Modelo 2","a0630a1d":"### 2.2 Implementaci\u00f3n con un dataset simplificado","c2823830":"### 0. Carga del dataset y tratamiento","e2a63f6b":"### 1. An\u00e1lisis exploratorio de datos","2baae2cc":"## Parte 2. Usando Scikitlearn","1897076a":"Se revisa el tipo de datos de cada columna y si hay valores faltantes, que en este caso no los hay","171f6f17":"Se cuenta con un dataset con las clases balancedas. Se procede a analizar las correlaciones existentes, lo que eventualmente nos permite simplificar el modelado","41fbc718":"### 3. Resultados","16a367bb":"Utilice el dataset Mobile Price Classification para predecir la columna price_range.\n\n1. Realice un an\u00e1lisis de los datos de entrada. Utilice gr\u00e1ficos, histogramas, correlaci\u00f3n, ... (3 pts)\n2. Implemente la arquitectura de una red neuronal de 1 sola capa con Keras (3 pts) para predecir price_range\n3. Muestre sus resultados con una matriz de confusi\u00f3n y un reporte (4 pts)","53e66262":"Se podria establecer un modelo reducido, en donde por ejemplo unicamente se utilicen los atributos del 8 al 41, que son los que parecen tener una mayor correlaci\u00f3n con la variable de respuesta.","c5ee52d1":"Se realiza el an\u00e1lisis de datos, se obtendran las estad\u00edsticas b\u00e1sicas por columna, las distribuciones y las correlaciones. Por ultimo se normalizaran los datos para que nos ayuden en el modelado","8c168549":"### 0.Carga del dataset y tratamiento","c5ba6aa0":"Investigue que es el perceptron y utilice el dataset (Divorce Predictors data set Data Set)[https:\/\/archive.ics.uci.edu\/ml\/datasets\/Divorce+Predictors+data+set] para predecir la columna clase: (1) si la pareja est\u00e1 divorciada, (0) si la pareja sigue casada.\n\n1. Realice un an\u00e1lisis de los datos de entrada. Utilice gr\u00e1ficos, histogramas, correlaci\u00f3n, ... (3 pts)\n2. Implemente y Ajuste un Perceptron con Scikitlearn (3 pts)\n3. Muestre sus resultados con una matriz de confusi\u00f3n y un reporte (4pts)","37c52500":"Todos los atributos son valores enteros, que codifican las respuestas. Para un correcto funcionamiento durante el modelado, se procede a estandarizar la base de datos para que tengan una media de 0 y desviaci\u00f3n de 1","e66d7cf9":"### 2.1 Implementaci\u00f3n con todos los atributos","7f37ffdb":"Al obtener resultados buenos a nivel de accuracy, no se procede a simplificar el modelo, es decir se mantiene el modelo con todos los atributos","54ff9b02":"Se revisa el tipo de datos y si hay valores faltantes para darles tratamiento","77298d85":"### 3. Resultados","0eec6084":"### 1. Analisis exploratorio de los datos","82e23f63":"Se puede analizar lo siguiente:\n1. Tenemos muchos atributos que son binarios, indicando que existe o no una caracteristica. \n2. Tenemos varios atributos continuos, que se son estandarizadas para ser utilizados en el enunciado dos. \n3. Las clases en price_range est\u00e1n equilibradas\n4. Los atributos que tienen una mayor correlacion con la variable de respuesta son: ram, battery_power, px_height y px_weigth. Estos ultimos dos tienen una correlacion media entre s\u00ed, por lo que en un modelo simplificado podr\u00edamos escoger solo uno de ellos"}}