{"cell_type":{"341c664a":"code","765e1cd4":"code","1c5eb4d8":"code","2aa3badf":"code","1e3ac8bc":"code","b12931f5":"code","b42de102":"code","c0868612":"code","02256924":"code","6c2a6430":"code","026de170":"code","e834daac":"code","9243411f":"code","a8d65594":"code","622d9662":"code","1f9dd2cf":"code","752dbf4c":"code","5cf4e773":"code","758c3d5c":"code","48427a37":"code","e8e6c19f":"code","bedc0203":"code","cf5c946a":"code","a92a9f2c":"code","58455de8":"code","fb24d865":"code","49c5e3bf":"code","217349fa":"code","39e0dc36":"code","9ae7cf6d":"code","d0c572d3":"code","fe94dd96":"code","47704265":"code","06002eca":"code","8855975f":"code","6ed00f01":"code","f861805c":"code","c3765911":"code","c6b2c742":"code","0a584f8b":"code","16e3503c":"code","65e5bd5a":"code","dd522258":"code","450b7316":"code","c7b8d555":"code","c963eb19":"code","ce2bc539":"code","bb69c172":"code","3b8ee855":"code","6a6bb4ea":"code","ecf726a7":"code","3145eab6":"markdown","6f06ac86":"markdown","4380f002":"markdown","6e739f83":"markdown","5c57e954":"markdown","e5703598":"markdown","c905a7fe":"markdown","b77a413f":"markdown","d7efb295":"markdown","984379fc":"markdown","c6ac2d86":"markdown","8f2d9ea6":"markdown","508f4e97":"markdown","2d2e1259":"markdown","e2bd94a9":"markdown","b28f5b37":"markdown"},"source":{"341c664a":"import gc\nimport numpy as np\nimport scipy as sp\nimport pandas as pd\nfrom pandas import DataFrame, Series\nimport seaborn as sns\nsns.set_style(\"whitegrid\")\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nplt.style.use('ggplot')\n%matplotlib inline\n\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import StratifiedKFold, GroupKFold, KFold, train_test_split\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.preprocessing import quantile_transform\nfrom sklearn.preprocessing import StandardScaler,MinMaxScaler\nfrom category_encoders import OrdinalEncoder, OneHotEncoder, TargetEncoder\nfrom tqdm import tqdm_notebook as tqdm\n\nfrom sklearn.ensemble import GradientBoostingClassifier\nimport lightgbm as lgb\nfrom lightgbm import LGBMClassifier","765e1cd4":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\ninput_path='\/kaggle\/input\/homework-for-students4plus'","1c5eb4d8":"df_train = pd.read_csv(input_path+'\/train.csv', index_col=0, parse_dates=['issue_d','earliest_cr_line'])\ndf_test = pd.read_csv(input_path+'\/test.csv', index_col=0, parse_dates=['issue_d','earliest_cr_line'])\n\ndf_train = df_train[df_train['issue_d'].dt.year >= 2014] #2014\u4ee5\u964d\u306b\u5909\u66f4","2aa3badf":"#\u5916\u90e8\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f\ndf_statelatlong = pd.read_csv(input_path+'\/statelatlong.csv')\ndf_gdp = pd.read_csv(input_path+'\/US_GDP_by_State.csv')\ndf_gdp = df_gdp[df_gdp.year==2015]\ndf_zipcode = pd.read_csv(input_path+'\/free-zipcode-database.csv', dtype={'Zipcode':np.int64})\ndf_zipcode = df_zipcode[['Zipcode','Xaxis','Yaxis','Zaxis']]\n\n#zipcode\u7d50\u5408\ndf_zipcode = df_zipcode.rename(columns={'Zipcode':'zip_code'})\ndf_zipcode['zip_code'] = df_zipcode.zip_code.astype(str).str[:3].astype(np.int64)\ndf_zipcode = df_zipcode[~df_zipcode.duplicated('zip_code')]\ndf_train['zip_code'] = df_train.zip_code.str[:3].astype(np.int64)\ndf_test['zip_code'] = df_test.zip_code.str[:3].astype(np.int64)\ndf_train = pd.merge(df_train,df_zipcode,on='zip_code',how='left')\ndf_test = pd.merge(df_test,df_zipcode,on='zip_code',how='left')\n# State\u3001GDP\u7d50\u5408\ndf_statelatlong = df_statelatlong.rename(columns={'State':'addr_state'})\ndf_gdp = df_gdp.rename(columns={'State':'City'})\ndf_gdp = df_gdp[df_gdp.year==2015]\ndf_train = pd.merge(df_train,df_statelatlong,on='addr_state',how='left')\ndf_test = pd.merge(df_test,df_statelatlong,on='addr_state',how='left')\ndf_train = pd.merge(df_train,df_gdp,on='City',how='left')\ndf_test = pd.merge(df_test,df_gdp,on='City',how='left')","1e3ac8bc":"#histgram\u547c\u3073\u51fa\u3057\u95a2\u6570\ndef checkhist(f,train,test,alp,bns):\n   # plt.figure(figsize=[7,7])\n    train[f].hist(density=True, alpha=alp, bins=bns)\n    # test\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u53ef\u8996\u5316\u3092\u8a18\u5165\u3057\u3066\u307f\u307e\u3057\u3087\u3046\n    test[f].hist(density=True, alpha=alp, bins=bns)\n    plt.xlabel(f)\n    plt.ylabel('density')\n    plt.show()","b12931f5":"#null\u306e\u6570\u3068\u304b\u3092\u51fa\u3059\ndef meta (dataframe):\n    metadata = []\n    for f in dataframe.columns:\n    \n        # Counting null values\n        null = dataframe[f].isnull().sum()\n    \n        # Defining the data type \n        dtype = dataframe[f].dtype\n    \n        # Creating a Dict that contains all the metadata for the variable\n        f_dict = {\n            'varname': f,\n            'nulls':null,\n            'dtype': dtype\n        }\n        metadata.append(f_dict)\n\n    meta = pd.DataFrame(metadata, columns=['varname','nulls', 'dtype'])\n    meta.set_index('varname', inplace=True)\n    meta=meta.sort_values(by=['nulls'],ascending=False)\n    return meta","b42de102":"#\u56db\u5206\u4f4d\u7bc4\u56f2\u3092\u57fa\u6e96\u306b\u5916\u308c\u5024\u3092min,max\u3067\u57cb\u3081\u308b\u95a2\u6570\ndef outlier_iqr(df):\n\n    for i in range(len(df.columns)):\n\n        # \u5217\u3092\u62bd\u51fa\u3059\u308b\n        col = df.iloc[:,i]\n\n        # \u56db\u5206\u4f4d\u6570\n        q1 = col.describe()['25%']\n        q3 = col.describe()['75%']\n        iqr = q3 - q1 #\u56db\u5206\u4f4d\u7bc4\u56f2\n\n        # \u5916\u308c\u5024\u306e\u57fa\u6e96\u70b9\n        outlier_min = q1 - (iqr) * 1.5\n        outlier_max = q3 + (iqr) * 1.5\n\n        # \u7bc4\u56f2\u304b\u3089\u5916\u308c\u3066\u3044\u308b\u5024\u3092\u9664\u304f\n        col[col < 0] = 0 #\u672c\u30c7\u30fc\u30bf\u306e\u307f\n        #col[col < outlier_min] = outlier_min\n        col[col > outlier_max] = outlier_max\n\n    return df","c0868612":"# 99%\u3000\u30d1\u30fc\u30bb\u30f3\u30bf\u30a4\u30eb\u3067\u30af\u30ea\u30c3\u30d4\u30f3\u30b0\ndef clipping(series):\n #   series_filtered = series.copy()    \n    upperbound, lowerbound = np.percentile(series, [1, 99])\n    series = np.clip(series, upperbound, lowerbound)\n    return series","02256924":"#\u6307\u5b9a\u5024\u3067\u30af\u30ea\u30c3\u30d4\u30f3\u30b0\ndef capping(series, min_threshold, max_threshold):\n    series_filtered = series.copy()\n    index_outlier_up = [series_filtered  >= max_threshold]\n    index_outlier_low = [series_filtered <= min_threshold]\n    series_filtered.iloc[index_outlier_up] = max_threshold\n    series_filtered.iloc[index_outlier_low] = min_threshold\n    return series_filtered","6c2a6430":"#\u30d2\u30fc\u30c8\u30de\u30c3\u30d7\ndef heatmap(y_data,x_data):\n    fig, ax = plt.subplots(figsize=(12, 9)) \n    sns.heatmap(pd.concat([y_data,x_data], axis=1).corr(), square=True, vmax=1, vmin=-1, center=0)","026de170":"#X\u3068y\u306b\u5206\u5272\ny_train = df_train.loan_condition #y\u306f\u8cb8\u3057\u5012\u308c\u30d5\u30e9\u30b0\nX_train = df_train.drop(['loan_condition'], axis=1) #x\u306f\u305d\u308c\u4ee5\u5916\n\nX_test = df_test","e834daac":"# dtype\u304cobject\u3068numeric\u306e\u3082\u306e\u306b\u5206\u3051\u308b\ncats = []\nnums = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object' or X_train[col].dtype == 'datetime64[ns]':\n        if col != 'emp_title' :#emp_title\u306fcats\u304b\u3089\u5916\u3059\n            cats.append(col)\n    else:\n      #  if col != 'issue_d':\n        nums.append(col)\n            \n#emp_title\u3060\u3051\u3068\u308a\u3060\u3059\nemp_title_train = X_train.emp_title.copy()\nemp_title_test = X_test.emp_title.copy()\n\n","9243411f":"#\u56db\u5206\u4f4d\u6570\u3092\u5143\u306bclipping\u3057\u3066\u5916\u308c\u5024\u3092\u524a\u9664\nX_train[nums]=outlier_iqr(X_train[nums])\nX_test[nums]=outlier_iqr(X_test[nums])","a8d65594":"# RankGauss\nrg_cols = ['annual_inc','dti','revol_bal']\nX_all = pd.concat([X_train, X_test], axis=0)\n\nfor col in rg_cols:\n    X_all[col] = quantile_transform(np.array(X_all[col].values).reshape(-1,1),\n                                    n_quantiles=200,\n                                    random_state=0,\n                                    output_distribution='normal')\n\n#X_train = X_all.iloc[:X_train.shape[0], :]\n#X_test = X_all.iloc[X_train.shape[0]:, :]    ","622d9662":"# \u5bfe\u6570\u5909\u63db\nlog_cols = ['delinq_2yrs','acc_now_delinq','tot_coll_amt','tot_cur_bal']\n\nfor col in log_cols:\n    X_all[col] = np.log1p(X_all[col])\n\nX_train = X_all.iloc[:X_train.shape[0],:]\nX_test = X_all.iloc[X_train.shape[0]:,:]","1f9dd2cf":"epsilon = 1e-7\n\nX_train['annual_inc\/installment'] = X_train['annual_inc'] \/ X_train['installment']\nX_test['annual_inc\/installment'] = X_test['annual_inc'] \/ X_test['installment']\n\n\nX_train['loan_amnt*installment']=X_train.loan_amnt * X_train.installment  ###\nX_test['loan_amnt*installment']=X_test.loan_amnt * X_test.installment ###\n\n\nX_train['loan_amnt\/annual_inc'] = X_train['loan_amnt'] \/ X_train['annual_inc']\nX_test['loan_amnt\/annual_inc'] = X_test['loan_amnt'] \/ X_test['annual_inc']\n\n\nX_train['tot_coll_amt\/installment'] = X_train['tot_coll_amt'] \/ X_train['installment']\nX_test['tot_coll_amt\/installment'] = X_test['tot_coll_amt'] \/ X_test['installment']\n\n\nX_train['tot_cur_bal\/installment'] = X_train['tot_cur_bal'] \/ X_train['installment']\nX_test['tot_cur_bal\/installment'] = X_test['tot_cur_bal'] \/ X_test['installment']\n\n\nX_train['revol_bal\/installment'] = X_train['revol_bal'] \/ X_train['installment']\nX_test['revol_bal\/installment'] = X_test['revol_bal'] \/ X_test['installment']\n\n\nX_train['dti\/installment'] = X_train['dti'] \/ X_train['installment']\nX_test['dti\/installment'] = X_test['dti'] \/ X_test['installment']\n\n\nX_train['tot_cur_bal\/annual_inc'] = X_train['tot_cur_bal'] \/ X_train['annual_inc']\nX_test['tot_cur_bal\/annual_inc'] = X_test['tot_cur_bal'] \/ X_test['annual_inc']\n\n\nX_train['revol_bal\/annual_inc'] = df_train['revol_bal'] \/ X_train['annual_inc']\nX_test['revol_bal\/annual_inc'] = df_test['revol_bal'] \/ X_test['annual_inc']\n\n\nX_train['dti\/annual_inc'] = X_train['dti'] \/ X_train['annual_inc']\nX_test['dti\/annual_inc'] = X_test['dti'] \/ X_test['annual_inc']\n\n\nX_train['dti\/loan_amnt'] = X_train['dti'] \/ X_train['loan_amnt']\nX_test['dti\/loan_amnt'] = X_test['dti'] \/ X_test['loan_amnt']\n\n\nX_train['loan_amnt*dti\/annual_inc'] = X_train['loan_amnt'] \/ X_train['annual_inc'] * X_train['dti']\nX_test['loan_amnt*dti\/annual_inc'] = X_test['loan_amnt'] \/ X_test['annual_inc'] * X_test['dti']\n\n\nX_train['dti^2\/installment'] = X_train['dti'] \/ X_train['installment'] * X_train['dti']\nX_test['dti^2\/installment'] = X_test['dti'] \/ X_test['installment'] * X_test['dti']\n\n\nX_train['tot_cur_bal*dti\/annual_inc'] = X_train['tot_cur_bal'] \/ X_train['annual_inc'] * X_train['dti']\nX_test['tot_cur_bal*dti\/annual_inc'] = X_test['tot_cur_bal'] \/ X_test['annual_inc'] * X_test['dti']\n\n\nX_train['revol_bal*dti\/annual_inc'] = df_train['revol_bal'] \/ X_train['annual_inc'] * X_train['dti']\nX_test['revol_bal*dti\/annual_inc'] = df_test['revol_bal'] \/ X_test['annual_inc'] * X_test['dti']\n\n\nX_train['dti^2\/annual_inc'] = X_train['dti'] \/ X_train['annual_inc'] * X_train['dti']\nX_test['dti^2\/annual_inc'] = X_test['dti'] \/ X_test['annual_inc'] * X_test['dti']\n\n\nX_train['dti^2\/loan_amnt'] = X_train['dti'] \/ X_train['loan_amnt'] * X_train['dti']\nX_test['dti^2\/loan_amnt'] = X_test['dti'] \/ X_test['loan_amnt'] * X_test['dti']\n\n\nX_train['loan_amnt\/installment']=X_train['loan_amnt'] \/ X_train['installment']\nX_test['loan_amnt\/installment']=X_test['loan_amnt'] \/ X_test['installment']\n\n\nX_train['loan_amnt\/tot_coll_amt']=X_train['loan_amnt'] \/ (X_train['tot_coll_amt'] + epsilon)\nX_test['loan_amnt\/tot_coll_amt']=X_test['loan_amnt'] \/ (X_test['tot_coll_amt'] + epsilon)\n\nX_train['annulal_inc\/loan_amnt']=X_train['annual_inc']\/X_train['loan_amnt']\nX_test['annulal_inc\/loan_amnt']=X_test['annual_inc']\/X_test['loan_amnt']\n\n\nX_train['open_acc\/total_acc']=X_train['open_acc']\/X_train['total_acc']\nX_test['open_acc\/total_acc']=X_test['open_acc']\/X_test['total_acc']\n\nX_train['annulal_inc*loan_amnt']=X_train['annual_inc']\/X_train['loan_amnt'] ###\nX_test['annulal_inc*loan_amnt']=X_test['annual_inc']\/X_test['loan_amnt'] ###\n\nX_train['acc_now_delinq*mths_since_last_delinq']=X_train['mths_since_last_delinq'] * X_train['acc_now_delinq']  ###\nX_test['acc_now_delinq*mths_since_last_delinq']=X_test['mths_since_last_delinq'] * X_test['acc_now_delinq'] ###\n\nX_train['issue_d'] = X_train['issue_d'].map(pd.Timestamp.timestamp).astype(int)\nX_train['earliest_cr_line'] = X_train['earliest_cr_line'].map(pd.Timestamp.timestamp).astype(int)\n\nX_test['issue_d'] = X_test['issue_d'].map(pd.Timestamp.timestamp).astype(int)\nX_test['earliest_cr_line'] = X_test['earliest_cr_line'].map(pd.Timestamp.timestamp).astype(int)\n\nX_train['progress_day'] = X_train['issue_d'] - X_train['earliest_cr_line']\nX_test['progress_day'] = X_test['issue_d'] - X_test['earliest_cr_line']\n\n\nX_train['null'] = X_train.isnull().sum(axis=1)\nX_test['null'] = X_test.isnull().sum(axis=1)\n\n# \u7121\u9650\u5927\u89e3\u6d88\nX_train.replace([np.inf, -np.inf], np.nan, inplace=True)\nX_test.replace([np.inf, -np.inf], np.nan, inplace=True)","752dbf4c":"# dtype\u304cobject\u3068numeric\u306e\u3082\u306e\u306b\u5206\u3051\u308b\ncats = []\nnums = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object' or X_train[col].dtype == 'datetime64[ns]':\n        cats.append(col)\n    else:\n        nums.append(col)","5cf4e773":"heatmap(y_train,X_train[nums])","758c3d5c":"fig, ax = plt.subplots(figsize=(12, 9)) \nsns.heatmap(X_test[nums].corr(), square=True, vmax=1, vmin=-1, center=0)","48427a37":"cats","e8e6c19f":"#emp_length\u306f\u6570\u5024\u30c7\u30fc\u30bf\u306b\u306a\u304a\u3059\nemp_len={'n\/a':0,'< 1 year':1,'1 year':2,'2 years':3,'3 years':4,'4 years':5,'5 years':6,'6 years':7,'7 years':8,'8 years':9,'9 years':10,'10+ years':11}\nX_train.emp_length.replace(emp_len,inplace=True)\nX_train.emp_length=X_train.emp_length.replace(np.nan,0)\nX_test.emp_length.replace(emp_len,inplace=True)\nX_test.emp_length=X_test.emp_length.replace(np.nan,0)\n\nX_train['emp_length'].head()\n","bedc0203":"#initial_list_status\u30920,1\u5909\u63db\ntes.remove('initial_list_status')\nint_status={'w':0,'f':1}\nX_train.initial_list_status.replace(int_status,inplace=True)\nX_test.initial_list_status.replace(int_status,inplace=True)","cf5c946a":"#grade\u3092\u9023\u7d9a\u30c7\u30fc\u30bf\u3078\u5909\u63db\n\nX_train['grade'] = X_train['grade'].replace('A', '0', regex=True)\nX_train['grade'] = X_train['grade'].replace('B', '1', regex=True)\nX_train['grade'] = X_train['grade'].replace('C', '2', regex=True)\nX_train['grade'] = X_train['grade'].replace('D', '3', regex=True)\nX_train['grade'] = X_train['grade'].replace('E', '4', regex=True)\nX_train['grade'] = X_train['grade'].replace('F', '5', regex=True)\nX_train['grade'] = X_train['grade'].replace('G', '6', regex=True)\nX_train['grade'] = X_train['grade'].astype(\"int64\")\n\nX_test['grade'] = X_test['grade'].replace('A', '0', regex=True)\nX_test['grade'] = X_test['grade'].replace('B', '1', regex=True)\nX_test['grade'] = X_test['grade'].replace('C', '2', regex=True)\nX_test['grade'] = X_test['grade'].replace('D', '3', regex=True)\nX_test['grade'] = X_test['grade'].replace('E', '4', regex=True)\nX_test['grade'] = X_test['grade'].replace('F', '5', regex=True)\nX_test['grade'] = X_test['grade'].replace('G', '6', regex=True)\nX_test['grade'] = X_test['grade'].astype(\"int64\")\n","a92a9f2c":"#sub_grade\u3092\u9023\u7d9a\u30c7\u30fc\u30bf\u3078\nX_train['sub_grade']=X_train['sub_grade'].str.split('[A-Z]', expand=True)[1].astype(\"int64\")\nX_train['sub_grade']+=X_train['grade']*6\nX_test['sub_grade']=X_test['sub_grade'].str.split('[A-Z]', expand=True)[1].astype(\"int64\")\nX_test['sub_grade']+=X_test['grade']*6\n","58455de8":"X_train['grade*sub_grade']=(X_train['grade']+1)*X_train['sub_grade']\nX_test['grade*sub_grade']=(X_test['grade']+1)*X_test['sub_grade']\n","fb24d865":"#earliest_cr_line\u3092\u5e74\u3060\u3051\u306b\u5909\u63db\nX_train.earliest_cr_line=pd.to_datetime(X_train.earliest_cr_line).dt.year\nX_test.earliest_cr_line=pd.to_datetime(X_test.earliest_cr_line).dt.year","49c5e3bf":"cate_list = ['grade',\n             'emp_length',\n             'home_ownership',\n             'zip_code',\n             'addr_state',\n          #   'inq_last_6mths',\n             'open_acc',\n             'total_acc'\n            ]\ntarget = 'sub_grade'\n\nX_temp = pd.concat([X_train, y_train], axis=1)\n\nfor col in cate_list:\n\n    summary = X_temp.groupby([col])[target].mean()\n    enc_test = X_test[col].map(summary) \n\n\n    skf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n    enc_train = Series(np.zeros(len(X_train)), index=X_train.index)\n\n    for i, (train_ix, val_ix) in enumerate((skf.split(X_train, y_train))):\n        X_train_, _ = X_temp.iloc[train_ix], y_train.iloc[train_ix]\n        X_val, _ = X_temp.iloc[val_ix], y_train.iloc[val_ix]\n\n        summary = X_train_.groupby([col])[target].mean()\n        enc_train.iloc[val_ix] = X_val[col].map(summary)\n        \n    # target_encoding\u9805\u76ee\u8ffd\u52a0\n    X_train['target_' + col] = enc_train\n    X_test['target_' + col] = enc_test","217349fa":"oes = []\n\nfor col in X_train.columns:\n    if X_train[col].dtype == 'object':\n        oes.append(col)\n        \n        print(col, X_train[col].nunique())","39e0dc36":"oe = OrdinalEncoder(cols=oes, return_df=False)\nX_train[oes] = oe.fit_transform(X_train[oes])\nX_test[oes] = oe.fit_transform(X_test[oes])","9ae7cf6d":"\nX_train['count_addr_state'] = X_train['addr_state'].map(X_train['addr_state'].value_counts())\nX_test['count_addr_state'] = X_test['addr_state'].map(X_test['addr_state'].value_counts())\n\nX_train['count_zip_code'] = X_train['zip_code'].map(X_train['zip_code'].value_counts())\nX_test['count_zip_code'] = X_test['zip_code'].map(X_test['zip_code'].value_counts())\n\nX_train['count_emp_length'] = X_train['emp_length'].map(X_train['emp_length'].value_counts())\nX_test['count_emp_length'] = X_test['emp_length'].map(X_test['emp_length'].value_counts())\n\nX_train['count_title'] = X_train['title'].map(X_train['title'].value_counts())\nX_test['count_title'] = X_test['title'].map(X_test['title'].value_counts())\n\nX_train['count_emp_title'] = X_train['emp_title'].map(X_train['emp_title'].value_counts())\nX_test['count_emp_title'] = X_test['emp_title'].map(X_test['emp_title'].value_counts())","d0c572d3":"#emp_title\u306f\u4e00\u65e6\u30c7\u30fc\u30bf\u304b\u3089\u5916\u3059\nX_train.drop(['emp_title'], axis=1, inplace=True)\nX_test.drop(['emp_title'], axis=1, inplace=True)","fe94dd96":"# \u6b20\u640d\u5024\u3092#\u3067\u57cb\u3081\u308b\nemp_title_train.fillna('#', inplace=True)\nemp_title_test.fillna('#', inplace=True)\n# TfidfVectorizer\nemp_tfidf = TfidfVectorizer(max_features=1000, use_idf=True)\n\n# TfidfVectorizer\u306efit\u51e6\u7406\nTXT_train = emp_tfidf.fit_transform(emp_title_train).tocsr()\nTXT_test = emp_tfidf.transform(emp_title_test).tocsr()","47704265":"# tf-idf \u21d2 \u30e2\u30c7\u30eb\u30b9\u30bf\u30c3\u30ad\u30f3\u30b0\u306b\u3088\u308b\u7279\u5fb4\u91cf\u8ffd\u52a0\n\nfrom sklearn.linear_model import LogisticRegression\n\nskf = StratifiedKFold(n_splits=5, random_state=81, shuffle=True)\nstack_train = np.zeros(len(X_train))\nstack_test = np.zeros(len(X_test))\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_tfidf, y_train_tfidf = TXT_train[train_ix], y_train.values[train_ix]\n    X_val_tfidf, y_val_tfidf = TXT_train[test_ix], y_train.values[test_ix]\n    \n    clf = LogisticRegression(solver='sag')\n    clf.fit(X_train_tfidf, y_train_tfidf)\n    \n    y_pred = clf.predict_proba(X_val_tfidf)[:,1]\n    stack_train[test_ix] = y_pred\n    score = roc_auc_score(y_val_tfidf, y_pred)\n    print('CV Score of Fold_%d is %f' % (i, score))\n    \n    stack_test += clf.predict_proba(TXT_test)[:,1]\n\nstack_test \/= 5","06002eca":"X_train['tfidf_emp_title'] = stack_train\nX_test['tfidf_emp_title'] = stack_test","8855975f":"#\u7279\u5fb4\u91cf\u8ffd\u52a0(sub_grade\u95a2\u9023)\nX_train['dti*sub'] = X_train['dti'] * X_train['sub_grade']\nX_test['dti*sub'] = X_test['dti'] * X_test['sub_grade']\n\nX_train['tcb*sub'] = X_train['tot_cur_bal'] * X_train['sub_grade']  ###\nX_test['tcb*sub'] = X_test['tot_cur_bal'] * X_test['sub_grade']  ###\n\nX_train['instl*sub'] = X_train['installment'] * X_train['sub_grade'] ###\nX_test['instl*sub'] = X_test['installment'] * X_test['sub_grade'] ###\n\nX_train['anlinc*sub'] = X_train['annual_inc'] \/ X_train['sub_grade']\nX_test['anlinc*sub'] = X_test['annual_inc'] \/ X_test['sub_grade']\n\nX_train['loan_amnt*sub'] = X_train['loan_amnt'] * X_train['sub_grade']\nX_test['loan_amnt*sub'] = X_test['loan_amnt'] * X_test['sub_grade']\n\nX_train['tca*sub'] = X_train['tot_coll_amt'] \/ X_train['sub_grade']\nX_test['tca*sub'] = X_test['tot_coll_amt'] \/ X_test['sub_grade']\n\nX_train['r_bal*sub'] = X_train['revol_bal'] \/ X_train['sub_grade']\nX_test['r_bal*sub'] = X_test['revol_bal'] \/ X_test['sub_grade']\n\nX_train['open_acc*sub'] = X_train['open_acc'] \/ X_train['sub_grade']\nX_test['open_acc*sub'] = X_test['open_acc'] \/ X_test['sub_grade']\n\nX_train['loan_amnt*sub*instl'] = X_train['loan_amnt'] * X_train['sub_grade'] * X_train['installment'] ###\nX_test['loan_amnt*sub*instl'] = X_test['loan_amnt'] * X_test['sub_grade'] * X_test['installment'] ###\n\nX_train['home_ownership*sub_grade'] = X_train['home_ownership'] * X_train['sub_grade']\nX_test['home_ownership*sub_grade'] = X_test['home_ownership'] * X_test['sub_grade']\n","6ed00f01":"# \u7279\u5fb4\u91cf\u8ffd\u52a0(grade\u95a2\u9023)\nX_train['dti*gra'] = X_train['dti'] * (X_train['grade']+1) ###\nX_test['dti*gra'] = X_test['dti'] * (X_test['grade']+1) ###\n\nX_train['tcb*gra'] = X_train['tot_cur_bal'] * (X_train['grade']+1)\nX_test['tcb*gra'] = X_test['tot_cur_bal'] * (X_test['grade']+1)\n\nX_train['instl*gra'] = X_train['installment'] * (X_train['grade']+1) ###\nX_test['instl*gra'] = X_test['installment'] * (X_test['grade']+1) ###\n\nX_train['anlinc*gra'] = X_train['annual_inc'] \/ (X_train['grade']+1)\nX_test['anlinc*gra'] = X_test['annual_inc'] \/ (X_test['grade']+1)\n\nX_train['loan_amnt*gra'] = X_train['loan_amnt'] * (X_train['grade']+1) ###\nX_test['loan_amnt*gra'] = X_test['loan_amnt'] * (X_test['grade']+1) ###\n\nX_train['tca*gra'] = X_train['tot_coll_amt'] \/ (X_train['grade']+1)\nX_test['tca*gra'] = X_test['tot_coll_amt'] \/ (X_test['grade']+1)\n\nX_train['r_bal*gra'] = X_train['revol_bal'] \/ (X_train['grade']+1)\nX_test['r_bal*gra'] = X_test['revol_bal'] \/ (X_test['grade']+1)\n\nX_train['open_acc*gra'] = X_train['open_acc'] \/ (X_train['grade']+1)\nX_test['open_acc*gra'] = X_test['open_acc'] \/ (X_test['grade']+1)\n\nX_train['loan_amnt*gra*instl'] = X_train['loan_amnt'] * (X_train['grade']+1) * X_train['installment'] ###\nX_test['loan_amnt*gra*instl'] = X_test['loan_amnt'] * (X_test['grade'] +1)* X_test['installment'] ###\n","f861805c":"'''#\u4e0d\u8981\u306a\u7279\u5fb4\u91cf\u306f\u524a\u9664\ndrop_cols_cat=[\n    'purpose',\n    'issue_d',\n    'home_ownership',\n    'installment',\n    'grade',\n    'grade*sub_grade',\n    'target_grade'\n    \n]\nX_train.drop(drop_cols_cat,axis=1,inplace=True)\nX_test.drop(drop_cols_cat,axis=1,inplace=True)'''","c3765911":"# \u5b66\u7fd2\u7528\u3068\u691c\u8a3c\u7528\u306b\u5206\u5272\u3059\u308b\nX_train_, X_val, y_train_, y_val= train_test_split(X_train, y_train, test_size=0.05, random_state=71)","c6b2c742":"#\u307e\u305a\u306f\u30c1\u30e5\u30fc\u30cb\u30f3\u30b0\u306a\u3057\nscores = []\n\nskf = StratifiedKFold(n_splits=5, random_state=71, shuffle=True)\n\nclf = LGBMClassifier(\n        max_depth=3,\n        learning_rate = 0.02,\n        colsample_bytree=0.7,\n        subsample=0.7,\n        min_split_gain=0,\n        reg_lambda=1,\n        reg_alpha=1,\n        min_child_weight=2,\n        n_estimators=9999,\n        random_state=71,\n        importance_type='gain'\n)","0a584f8b":"%%time\nclf.fit(X_train_, y_train_, early_stopping_rounds=20, eval_metric='auc', eval_set=[(X_val, y_val)])","16e3503c":"clf.booster_.feature_importance(importance_type='gain')","65e5bd5a":"imp = DataFrame(clf.booster_.feature_importance(importance_type='gain'), index = X_train.columns, columns=['importance']).sort_values(['importance'], ascending=False)","dd522258":"fig, ax = plt.subplots(figsize=(5, 8))\nlgb.plot_importance(clf, max_num_features=50, ax=ax, importance_type='gain')","450b7316":"th=1000\n\n#use_col = imp.index[:30] # \u5909\u6570\u91cd\u8981\u5ea6\u3067\u7279\u5fb4\u91cf\u3092\u7d5e\u308a\u8fbc\u3093\u3067\u307f\u307e\u3057\u3087\u3046\n\nuse_col = imp.index[imp.importance > th] #\u95be\u5024\u3092\u5207\u308b\u306a\u308a\u3001sort\u3057\u3066\u5fc5\u8981\u306a\u6570\u306b\u7d5e\u308a\u8fbc\u3080\u306a\u308a\u3059\u308b\u3002","c7b8d555":"X_train_=X_train_[use_col]\nX_train=X_train[use_col]\nX_val=X_val[use_col]\nX_test=X_test[use_col]","c963eb19":"heatmap(y_train,X_train[use_col])","ce2bc539":"#CV Averaging\/kFold Averaging\nscores = []\nlgb_y_pred_train = np.zeros(len(X_train))\nlgb_y_pred_test = np.zeros(len(X_test))\nskf = StratifiedKFold(n_splits=5, random_state=81, shuffle=True)\n\nfor i, (train_ix, test_ix) in tqdm(enumerate(skf.split(X_train, y_train))):\n    X_train_, y_train_ = X_train.values[train_ix], y_train.values[train_ix]\n    X_val, y_val = X_train.values[test_ix], y_train.values[test_ix]\n    \n    \n    clf = LGBMClassifier(\n        max_depth=3,\n        learning_rate = 0.02,\n        colsample_bytree=0.7,\n        subsample=0.7,\n        min_split_gain=0,\n        reg_lambda=1,\n        reg_alpha=1,\n        min_child_weight=2,\n        n_estimators=9999,\n        random_state=71,\n        importance_type='gain'\n                        )\n\n    clf.fit(X_train_, y_train_,\n            early_stopping_rounds=500,\n            verbose=100,\n            eval_metric='auc',\n            eval_set=[(X_val, y_val)]\n           )\n    \n    y_pred = clf.predict_proba(X_val)[:,1]\n    lgb_y_pred_train[test_ix] = y_pred\n    score = roc_auc_score(y_val, y_pred)\n    scores.append(score)\n    lgb_y_pred_test += clf.predict_proba(X_test)[:,1]\n    \n    print('CV Score of Fold_%d is %f' % (i, score))\nlgb_y_pred_test \/= 5\n\n\n\n","bb69c172":"print(np.mean(scores))\nprint(scores)","3b8ee855":"# sample submission\u3092\u8aad\u307f\u8fbc\u3093\u3067\u3001\u4e88\u6e2c\u5024\u3092\u4ee3\u5165\u306e\u5f8c\u3001\u4fdd\u5b58\u3059\u308b\nsubmission = pd.read_csv('..\/input\/homework-for-students4plus\/sample_submission.csv', index_col=0)\n\nsubmission.loan_condition = lgb_y_pred_test #\u3059\u3067\u306bCV Ave\/kFold Ave\u306b\u3066\u5168\u30c7\u30fc\u30bf\u306b\u5bfe\u3059\u308b\u5b66\u7fd2\u6e08\u307f\nsubmission.to_csv('submission5.csv')","6a6bb4ea":"submission.head() # \u307e\u305a\u306f\u521d\u56desubmit\u3057\u3066\u307f\u307e\u3057\u3087\u3046\uff01\u3053\u308c\u304b\u3089\u3053\u306e\u30e2\u30c7\u30eb\u306e\u6539\u5584\u3092\u9032\u3081\u3066\u3044\u304f\u3053\u3068\u306b\u306a\u308a\u307e\u3059\u3002","ecf726a7":"### The end of this notebook ###","3145eab6":"## Count Encoding","6f06ac86":"# 9\uff0e\u63d0\u51fa\u7528\u30d5\u30a1\u30a4\u30eb\u4f5c\u6210","4380f002":"## \u7279\u5fb4\u91cfeng","6e739f83":"# \uff17\uff0e\u7279\u5fb4\u91cf\u8ffd\u52a0(numeric\u00d7object)\uff06\u7d5e\u308a\u8fbc\u307f","5c57e954":"# 1\uff0e\u30c7\u30fc\u30bf\u8aad\u307f\u8fbc\u307f","e5703598":"## \u30a2\u30f3\u30b5\u30f3\u30d6\u30eb","c905a7fe":"# \uff16\uff0e\u30c6\u30ad\u30b9\u30c8\u7279\u5fb4\u91cf","b77a413f":"# \uff13\uff0e\u30c7\u30fc\u30bf\u6e96\u5099","d7efb295":"## Ordinal Encoding","984379fc":"# \uff18\uff0e\u30e2\u30c7\u30eb\u4f5c\u6210","c6ac2d86":"# \uff14\uff0enumeric","8f2d9ea6":"## Target Encoding","508f4e97":"## Light GBM","2d2e1259":"## rankgauss,log","e2bd94a9":"# \uff15\uff0eobject","b28f5b37":"# \uff12\uff0e\u95a2\u6570\u306e\u5b9a\u7fa9"}}