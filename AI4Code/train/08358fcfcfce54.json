{"cell_type":{"f80b2397":"code","3c6722de":"code","a4fe2c59":"code","beaedb0f":"code","ca9260f2":"code","bc451afa":"code","b35e0015":"code","31e38580":"code","7ec529ee":"code","8edc9632":"code","b33910d7":"code","932b18cb":"code","09f4bef3":"code","6d3fca23":"code","8a137541":"code","5fc10a1b":"code","ce9c0c80":"code","949731da":"code","2f48c22b":"code","7424392b":"code","2f2daf3b":"code","aa396ec9":"code","64ec87de":"code","5acd9db0":"code","4e49769c":"code","fc80c053":"code","01ad0f16":"markdown","9145b1ba":"markdown","e58c063c":"markdown","7bc5283f":"markdown","cea6cf2d":"markdown","adf07b05":"markdown","474756be":"markdown","95bf520e":"markdown","4949e54a":"markdown","42f56c19":"markdown","c98369a7":"markdown","5a81deca":"markdown","f732e1f7":"markdown","7231f9c3":"markdown","c0331e6d":"markdown","a547b679":"markdown","350f93ac":"markdown","87d38b09":"markdown","884f109c":"markdown","963e1ba0":"markdown","0778c22d":"markdown"},"source":{"f80b2397":"import os\nimport cv2\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport matplotlib.spines as spines\nimport seaborn as sns\nimport pandas as pd\n\nimport tensorflow as tf\nimport tensorflow.keras as keras\nimport tensorflow.keras.layers as layers\nimport tensorflow.keras.models as models\nimport tensorflow.keras.optimizers as optimizers\nimport tensorflow.keras.losses as losses\nimport tensorflow.keras.callbacks as callbacks","3c6722de":"tf.config.experimental.list_physical_devices('GPU') ","a4fe2c59":"DATASET_PATH = \"..\/input\/bee-vs-wasp\/kaggle_bee_vs_wasp\"\n\nlabel_csv = os.path.join(DATASET_PATH, 'labels.csv')","beaedb0f":"label_df = pd.read_csv(label_csv)\nlabel_df.head(10)","ca9260f2":"print('Number of null values')\nlabel_df.isnull().sum()","bc451afa":"def set_train_type(row):\n    if row['is_validation'] == 0 and row['is_final_validation'] == 0:\n        return 'train'\n    if row['is_validation'] == 1:\n        return 'validation'\n    return 'test'\n\nlabel_df['type'] = label_df.apply(set_train_type, axis=1)\nprint('Number values of each type')\nlabel_df['type'].value_counts()","b35e0015":"insect_cat_counts = label_df[\"label\"].value_counts()\n\nplt.figure(figsize=(7,7))\ng = sns.barplot(x=insect_cat_counts.index, y =insect_cat_counts, color='salmon')\ng.set(title='Number of each category', ylim=[0,6000], yticks=[], ylabel='')\nsns.despine(top=True, right=True, left=True, bottom=False)\n\nfor i in range(4):\n    plt.text(x=i-0.12, y=insect_cat_counts[i] + 150, s=insect_cat_counts[i])\nplt.show()","31e38580":"plt.figure(figsize=(7,7))\ng = sns.countplot(x='label', hue='type', data=label_df, palette=\"pastel\")\ng.set(xlabel='', ylabel='', title=\"Test\/Validation\/Test numbers of each category\")\nsns.despine()\nplt.show()","7ec529ee":"plt.figure(figsize=(7,7))\ng = sns.countplot(x='label', hue='photo_quality', data=label_df, palette=\"pastel\")\ng.set(xlabel='', ylabel='', title=\"Image quality of each category\")\nsns.despine()\nplt.show()","8edc9632":"def display_img(row, pos):\n    #Because path use back slash which is \n    #not compatible for both windows nor linux environment\n    #we will first replace back slash with forward slash\n    fn = row['path'].replace('\\\\', os.sep)\n    fn = os.path.join(DATASET_PATH, fn)\n    #Read image from path\n    img = cv2.imread(fn)\n    #Resize all images with the same size\n    img = cv2.resize(img, (128, 128))\n    #Set RGB color for image\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    #Display image, and set title\n    plt.subplot(4, 5, pos)\n    plt.imshow(img)\n    plt.title(row['label'])\n    #Remove ticks\n    plt.xticks([])\n    plt.yticks([])","b33910d7":"bee = label_df[label_df[\"label\"] == 'bee'].sample(5, random_state=42)\nwasp = label_df[label_df[\"label\"] == 'wasp'].sample(5, random_state=42)\ninsect = label_df[label_df[\"label\"] == 'insect'].sample(5, random_state=42)\nother = label_df[label_df[\"label\"] == 'other'].sample(5, random_state=42)\n\nplt.figure(figsize=(15,10))\npos = 1\n# Display bee\nfor idx, row in bee.iterrows():\n    display_img(row, pos)\n    pos += 1\n# Display wasp    \nfor idx, row in wasp.iterrows():\n    display_img(row, pos)\n    pos += 1\n# Display other insects\nfor idx, row in insect.iterrows():\n    display_img(row, pos)\n    pos += 1\n# Display others\nfor idx, row in other.iterrows():\n    display_img(row, pos)\n    pos += 1\n    \nplt.show()","932b18cb":"label_df['path'] = label_df['path'].str.replace('\\\\', os.sep)\nlabel_df['path'].head()","09f4bef3":"train_df = label_df[label_df['type'] == 'train']\nvalid_df = label_df[label_df['type'] == 'validation']\ntest_df = label_df[label_df['type'] == 'test']","6d3fca23":"TARGET_SIZE = (256, 256)\nSEED = 42","8a137541":"datagen = keras.preprocessing.image.ImageDataGenerator(rescale=1.\/255.)\n\ntrain_datagen = datagen.flow_from_dataframe(train_df, \n                                            directory=DATASET_PATH, \n                                            x_col='path', \n                                            y_col='label',\n                                            target_size=TARGET_SIZE,\n                                            seed=42\n                                           ) \n\nvalid_datagen = datagen.flow_from_dataframe(valid_df,\n                                            directory=DATASET_PATH, \n                                            x_col='path', \n                                            y_col='label',\n                                            target_size=TARGET_SIZE,\n                                            seed=42\n                                           ) \n\ntest_datagen = datagen.flow_from_dataframe(test_df, \n                                           directory=DATASET_PATH, \n                                           x_col='path', \n                                           y_col='label',\n                                           target_size=TARGET_SIZE,\n                                           seed=42\n                                           ) ","5fc10a1b":"n_class = len(label_df['label'].unique())","ce9c0c80":"from tensorflow.keras.initializers import RandomNormal, Constant\n\nmodel = models.Sequential([\n    # Block 1\n    layers.Conv2D(128, 3, padding='same', kernel_regularizer=keras.regularizers.L2(0.001), input_shape=(256,256,3)),\n    layers.Conv2D(128, 3, padding='same', kernel_regularizer=keras.regularizers.L2(0.001)),\n    layers.BatchNormalization(momentum=0.6, \n                              epsilon=0.005, \n                              beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n                              gamma_initializer=Constant(value=0.9)\n                             ),    \n    layers.Activation('relu'),\n    layers.MaxPooling2D(3),\n    layers.Dropout(0.3),\n    \n    # Block 2\n    layers.Conv2D(128, 3, padding='same', kernel_regularizer=keras.regularizers.L2(0.001)),\n    layers.Conv2D(128, 3, padding='same', kernel_regularizer=keras.regularizers.L2(0.001)),\n    layers.BatchNormalization(momentum=0.6, \n                              epsilon=0.005, \n                              beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n                              gamma_initializer=Constant(value=0.9)\n                             ),\n    layers.Activation('relu'),\n    layers.MaxPooling2D(3),\n    layers.Dropout(0.3),\n    \n    # Block 3\n    layers.Conv2D(256, 3, padding='same', kernel_regularizer=keras.regularizers.L2(0.001)),\n    layers.Conv2D(256, 3, padding='same', kernel_regularizer=keras.regularizers.L2(0.001)),\n    layers.BatchNormalization(momentum=0.6, \n                              epsilon=0.005, \n                              beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n                              gamma_initializer=Constant(value=0.9)\n                             ), \n    layers.Activation('relu'),\n    layers.MaxPooling2D(3),\n    layers.Dropout(0.3),\n    \n    # Block 4\n    layers.Conv2D(512, 3, padding='same', kernel_regularizer=keras.regularizers.L2(0.001)),\n    layers.Conv2D(512, 3, padding='same', kernel_regularizer=keras.regularizers.L2(0.001)),\n    layers.BatchNormalization(momentum=0.6, \n                              epsilon=0.005, \n                              beta_initializer=RandomNormal(mean=0.0, stddev=0.05), \n                              gamma_initializer=Constant(value=0.9)\n                             ), \n    layers.Activation('relu'),\n    layers.MaxPooling2D(3),\n    layers.Dropout(0.3),\n\n    # Block 5\n    layers.GlobalAveragePooling2D(),\n    layers.Dense(512, activation='relu', kernel_regularizer=keras.regularizers.L2(0.001)),\n    layers.Dense(n_class, activation='softmax')\n])","949731da":"model.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n              loss=losses.BinaryCrossentropy(),\n              metrics=['accuracy']\n             )","2f48c22b":"early_stopping = callbacks.EarlyStopping(patience=5, restore_best_weights=True)","7424392b":"history = model.fit(train_datagen, \n          validation_data=valid_datagen, \n          callbacks=[early_stopping],\n          batch_size=32,\n          epochs=50,\n         )","2f2daf3b":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(14,5))\nplt.subplot(1, 2, 1)\nplt.plot(acc, label='train acc')\nplt.plot(val_acc, label='valid acc')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(loss, label='train loss')\nplt.plot(val_loss, label='valid loss')\nplt.legend()\n\nplt.show()","aa396ec9":"test_loss, test_acc = model.evaluate(test_datagen, verbose=2)\nprint(\"Test accuracy:\", test_acc)","64ec87de":"resnet50 = keras.applications.ResNet50(include_top=False, input_shape=(256, 256, 3))","5acd9db0":"from tensorflow.keras.initializers import RandomNormal, Constant\n\nmodel = models.Sequential([\n    resnet50,\n    layers.GlobalAveragePooling2D(),\n    layers.Dropout(0.2),\n    layers.Dense(n_class, activation='softmax')\n])\n\nmodel.compile(optimizer=optimizers.Adam(learning_rate=0.0001),\n              loss=losses.BinaryCrossentropy(),\n              metrics=['accuracy']\n             )\nearly_stopping = callbacks.EarlyStopping(patience=5, restore_best_weights=True)\n\nhistory = model.fit(train_datagen, \n          validation_data=valid_datagen, \n          callbacks=[early_stopping],\n          batch_size=32,\n          epochs=50,\n         )","4e49769c":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nplt.figure(figsize=(14,5))\nplt.subplot(1, 2, 1)\nplt.plot(acc, label='train acc')\nplt.plot(val_acc, label='valid acc')\nplt.legend()\n\nplt.subplot(1, 2, 2)\nplt.plot(loss, label='train loss')\nplt.plot(val_loss, label='valid loss')\nplt.legend()\n\nplt.show()","fc80c053":"test_loss, test_acc = model.evaluate(test_datagen, verbose=2)\nprint(\"Test accuracy:\", test_acc)","01ad0f16":"Look like our dataset is separeated into these parts:\n- train: 80%\n- validation: 10%\n- test: 10%\n\nNow let's get intuition with by plotting some useful information","9145b1ba":"Before create training data, we should replace backward slash with current environment default slash as we did while displaying images above","e58c063c":"# Train and evaluate","7bc5283f":"Our dataset is well prepared since there is no missing value, let's move on","cea6cf2d":"Great, let's get train\/validation\/test data separately","adf07b05":"We can see that not only bee and wasp are hard for us to classify but also other insects are hard too, since some of them just take a small portion in image. With others we can clearly see that they absolutely different to bee, wasp, and other insects, hope that with other, we can get the best confidence in prediction.","474756be":"# Data preparation","95bf520e":"**labels.csv** columns description :\n\n- id - ordinal - unique index\n- path - string - relative path to the photo, including extension\n- is_bee - nominal - 1 if there is a bee in the photo\n- is_wasp - nominal - 1 if there is a wasp in the photo\n- is_otherinsect - nominal - 1 if there is other insect prominently in the centre of the photo, but it is not a wasp and not a bee. It might be a fly, but there are other things there too, like beetles\n- is_other - random photos not containing any insects\n- photo_quality - 1 for photos where I have very high confidence that it is bee, wasp, or other. 0 for photos of generally low quality or where I am not very confident that it is - what it says it is. You can use this to initially reduce the size of the training set\n- is_validation - you can use this for your training validation, or you can combine these with the training data and split your training\/validation differently\n- is_final_validation - do NOT use these photos for training - use them to compute your final score. This will enable comparing results by different kagglers. Optionally, if you want to deploy an app to actually serve the model, you can then use these for final training too.","4949e54a":"We will use resnet50 as pretrain model to apply transfer learning","42f56c19":"# Data exploration","c98369a7":"Finally, we will see the quality of images that are collected","5a81deca":"## From scratch","f732e1f7":"## Transfer learning","7231f9c3":"Our above chart indicate that **Wasp** has the most number of image in our dataset, then **Bee**, **Other insect**, and the last is **Other**. Notice that these are the total number of each category include both train and validation and image.","c0331e6d":"As we saw above that train\/validation\/test data are separated into 80\/10\/10, our data for each category also are separedted into same portion. Thank to our author who created also well cleaned our dataset","a547b679":"Let's create datagen, remember to scale all images into same shape since they don't have the same image size, also we have bad quality images, let's try 256 pixel for image size","350f93ac":"We got accuracy 94% by using transfer learning with resnet50, while our sratch model get 89%. Also we only train 10 epochs on transfer learning model, since sratch model take 33 epochs, that means transfer learning get higher accuracy with less epochs.","87d38b09":"Before get some intuition about data, let's generate new column which can help us to quickly know that image is train\/validation\/test\nFrom the description we know that validation image is declared in **is_validation** and test belongs to **is_final_validation**","884f109c":"We will use relularize, dropout, batch norm, and pooling for our scratch model. \nNote that we will not apply data augmentation.","963e1ba0":"We can notice these things:\n- Wasp has the most number of images but it also have the most bad quality images, with bad quality is over 2500 and good quality is about 2000. \n- Bee was collected with most of good images with over 2400 images, and about 600-700 bad quality images.\n- Other insects only contain good quality images.\n- Other animals only contain bad quality images.","0778c22d":"# Visualization"}}