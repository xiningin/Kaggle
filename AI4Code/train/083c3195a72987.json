{"cell_type":{"cd384235":"code","6e706d61":"code","331ab062":"code","1eb79dd8":"code","d3008a7a":"code","7523e12c":"code","25ef73d9":"code","1dffdf10":"code","f1c321b8":"code","df517196":"code","ef59fd5d":"code","8421e4d8":"code","ac1574a9":"code","f0caa140":"code","ca05bf7f":"code","edc7c16e":"code","ff48764c":"code","7cf4fda2":"code","7636baa3":"code","078471cb":"code","47c9eff9":"code","58734af8":"code","eef63e71":"code","dd9ea787":"code","bbb15528":"code","363183fc":"code","8def6326":"code","42238aca":"code","cd8bf742":"code","2e25bde8":"code","0e75412e":"code","67415772":"code","b12f6b45":"code","baa594ae":"markdown","c6ffd244":"markdown","eb0ceaa6":"markdown","70b9d98b":"markdown","afcd245f":"markdown","cc31cbf6":"markdown","876ad0e7":"markdown","08b5790e":"markdown"},"source":{"cd384235":"#libraries\nimport numpy as np\nimport pandas as pd\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import Activation,Dense,Flatten,BatchNormalization,Conv2D,MaxPool2D,Dropout,GlobalAveragePooling2D\nfrom keras.optimizers import Adam\nfrom keras.metrics import categorical_crossentropy\nfrom keras.preprocessing.image import ImageDataGenerator as Imgen\n\nfrom sklearn.metrics import classification_report,confusion_matrix\n\nimport os\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings(action='ignore',category=FutureWarning)\n\n%matplotlib inline\nsns.set_style('darkgrid')\n","6e706d61":"physical_devices = tf.config.experimental.list_physical_devices('GPU')\nprint(\"Num GPUS:\",len(physical_devices))","331ab062":"classes = ['Apple Braeburn',\n 'Apple Crimson Snow',\n 'Apple Golden 1',\n 'Apple Golden 2',\n 'Apple Golden 3',\n 'Apple Granny Smith',\n 'Apple Pink Lady',\n 'Apple Red 1',\n 'Apple Red 2',\n 'Apple Red 3',\n 'Apple Red Delicious',\n 'Apple Red Yellow 1',\n 'Apple Red Yellow 2',\n 'Apricot',\n 'Avocado',\n 'Avocado ripe',\n 'Banana',\n 'Banana Lady Finger',\n 'Banana Red',\n 'Beetroot',\n 'Blueberry',\n 'Cactus fruit',\n 'Cantaloupe 1',\n 'Cantaloupe 2',\n 'Carambula',\n 'Cauliflower',\n 'Cherry 1',\n 'Cherry 2',\n 'Cherry Rainier',\n 'Cherry Wax Black',\n 'Cherry Wax Red',\n 'Cherry Wax Yellow',\n 'Chestnut',\n 'Clementine',\n 'Cocos',\n 'Corn',\n 'Corn Husk',\n 'Cucumber Ripe',\n 'Cucumber Ripe 2',\n 'Dates',\n 'Eggplant',\n 'Fig',\n 'Ginger Root',\n 'Granadilla',\n 'Grape Blue',\n 'Grape Pink',\n 'Grape White',\n 'Grape White 2',\n 'Grape White 3',\n 'Grape White 4',\n 'Grapefruit Pink',\n 'Grapefruit White',\n 'Guava',\n 'Hazelnut',\n 'Huckleberry',\n 'Kaki',\n 'Kiwi',\n 'Kohlrabi',\n 'Kumquats',\n 'Lemon',\n 'Lemon Meyer',\n 'Limes',\n 'Lychee',\n 'Mandarine',\n 'Mango',\n 'Mango Red',\n 'Mangostan',\n 'Maracuja',\n 'Melon Piel de Sapo',\n 'Mulberry',\n 'Nectarine',\n 'Nectarine Flat',\n 'Nut Forest',\n 'Nut Pecan',\n 'Onion Red',\n 'Onion Red Peeled',\n 'Onion White',\n 'Orange',\n 'Papaya',\n 'Passion Fruit',\n 'Peach',\n 'Peach 2',\n 'Peach Flat',\n 'Pear',\n 'Pear 2',\n 'Pear Abate',\n 'Pear Forelle',\n 'Pear Kaiser',\n 'Pear Monster',\n 'Pear Red',\n 'Pear Stone',\n 'Pear Williams',\n 'Pepino',\n 'Pepper Green',\n 'Pepper Orange',\n 'Pepper Red',\n 'Pepper Yellow',\n 'Physalis',\n 'Physalis with Husk',\n 'Pineapple',\n 'Pineapple Mini',\n 'Pitahaya Red',\n 'Plum',\n 'Plum 2',\n 'Plum 3',\n 'Pomegranate',\n 'Pomelo Sweetie',\n 'Potato Red',\n 'Potato Red Washed',\n 'Potato Sweet',\n 'Potato White',\n 'Quince',\n 'Rambutan',\n 'Raspberry',\n 'Redcurrant',\n 'Salak',\n 'Strawberry',\n 'Strawberry Wedge',\n 'Tamarillo',\n 'Tangelo',\n 'Tomato 1',\n 'Tomato 2',\n 'Tomato 3',\n 'Tomato 4',\n 'Tomato Cherry Red',\n 'Tomato Heart',\n 'Tomato Maroon',\n 'Tomato Yellow',\n 'Tomato not Ripened',\n 'Walnut',\n 'Watermelon']","1eb79dd8":"train_datagen = Imgen(preprocessing_function=keras.applications.xception.preprocess_input,shear_range=0.2,zoom_range=0.2,horizontal_flip=True,validation_split=0.2)\n\ntest_datagen = Imgen(preprocessing_function=keras.applications.xception.preprocess_input)","d3008a7a":"x_train,y_train = next(train_ds)","7523e12c":"pred_class = train_ds.class_indices\npred_class = list(pred_class.keys())\nlen(pred_class)","25ef73d9":"#plot function\ndef plot_images(img,labels):\n    plt.figure(figsize=(15,10))\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.imshow(img[i])\n        plt.title(pred_class[np.argmax(labels[i])])\n        plt.axis('off')","1dffdf10":"plot_images(x_train,y_train)","f1c321b8":"from keras.applications.xception import Xception","df517196":"base_model = Xception(include_top=False,\n                        weights='imagenet',\n                        input_shape=(224,224,3)\n                        )\nbase_model.trainable = False","ef59fd5d":"#model\n\nmodel = keras.models.Sequential([\n    \n    base_model,\n    \n    GlobalAveragePooling2D(),\n    \n    Dense(len(pred_class),activation='softmax')\n])","8421e4d8":"model.summary()","ac1574a9":"keras.utils.plot_model(model,\n                      show_shapes=True,\n                      show_dtype=True,\n                      show_layer_names=True)","f0caa140":"model.compile(optimizer=Adam(learning_rate=1e-4),loss='categorical_crossentropy',metrics=['accuracy'])","ca05bf7f":"my_calls = [keras.callbacks.EarlyStopping(monitor='val_accuracy',patience=2),\n            keras.callbacks.ModelCheckpoint(\"Model_VGG.h5\",verbose=1,save_best_only=True)]","edc7c16e":"hist  = model.fit(train_ds,epochs=7,validation_data=val_ds,callbacks=my_calls)","ff48764c":"plt.figure(figsize=(15,6))\n\nplt.subplot(1,2,1)\nplt.plot(hist.epoch,hist.history['accuracy'],label = 'Training')\nplt.plot(hist.epoch,hist.history['val_accuracy'],label = 'validation')\n\nplt.title(\"Accuracy\")\nplt.legend()\n\nplt.subplot(1,2,2)\nplt.plot(hist.epoch,hist.history['loss'],label = 'Training')\nplt.plot(hist.epoch,hist.history['val_loss'],label = 'validation')\n\nplt.title(\"Loss\")\nplt.legend()\nplt.show()","7cf4fda2":"preds = model.predict(test_ds,verbose=1)","7636baa3":"test_ds.classes","078471cb":"preds = [np.argmax(i) for i in preds]","47c9eff9":"pd.DataFrame(preds).value_counts()","58734af8":"pred_class[6]","eef63e71":"classification_report(test_ds.classes,preds)","dd9ea787":"plt.figure(figsize=(50,30))\nsns.heatmap(confusion_matrix(test_ds.classes,preds),annot=True,fmt='d');","bbb15528":"test_img,labels = next(test_ds)","363183fc":"#plot function\ndef test_images(images_arr,labels):\n    plt.figure(figsize=(25,12))\n    for i in range(25):\n        plt.subplot(5,5,i+1)\n        plt.xticks([])\n        plt.yticks([])\n        plt.imshow(images_arr[i])\n        plt.xlabel(\"Actual: {}\".format(pred_class[np.argmax(labels[i])]))\n        plt.ylabel(\"Predicted: {}\".format(pred_class[preds[i]]))","8def6326":"test_images(test_img,labels)","42238aca":"from PIL import Image\nfrom keras.preprocessing import image","cd8bf742":"#preprocess file\ndef prepare_img(path):\n    img = image.load_img(path,target_size=(224,224))\n    img_arr = image.img_to_array(img)\n    img_arr_expnd  = np.expand_dims(img_arr,axis=0)\n    img = keras.applications.mobilenet_v2.preprocess_input(img_arr_expnd)\n    \n    return img","2e25bde8":"plt.imshow(Image.open('..\/input\/fruits\/fruits-360\/test-multiple_fruits\/Bananas(lady_finger)3.jpg'));\n","0e75412e":"prep_img1 = prepare_img('..\/input\/fruits\/fruits-360\/test-multiple_fruits\/Bananas(lady_finger)3.jpg')\nprep_img1.shape","67415772":"pred1 = model.predict(prep_img1)","b12f6b45":"pred_class[np.argmax(pred1)]","baa594ae":"**Visualizing Some**","c6ffd244":"**Getting the Dta**","eb0ceaa6":"**Train**","70b9d98b":"- Classes","afcd245f":"- One batch","cc31cbf6":"## **Model**","876ad0e7":"****Prediction data****","08b5790e":"**Predictions**"}}