{"cell_type":{"f826c942":"code","2073693a":"code","f3df6acd":"code","d31ca511":"code","bd135557":"code","5f7a22ab":"code","08d6d356":"code","9e039675":"code","545bbbc1":"code","e860ec83":"code","8dbc1b86":"code","f5cdc23f":"code","1de602f6":"code","e8ec3830":"code","6b41fadb":"code","b50ad610":"code","5bdf9923":"code","c70148ee":"code","18be3a33":"code","69a5b9e1":"code","abf72300":"code","1ab9cd73":"code","3256c4e6":"code","9f52d856":"code","65e58d8c":"code","3d3d7870":"code","77915742":"code","a07b787d":"code","39f49e8a":"code","a0fb5b72":"code","c6ad164b":"code","27f85c22":"code","24e36b2b":"code","37d06956":"code","a4ab53f6":"code","ea320b14":"code","1f34eb70":"code","df87fcec":"code","2031d7bd":"code","eaa190f3":"code","fecddad4":"code","801d709b":"code","d2cd7ede":"code","cca7b229":"code","033be7b1":"code","d963bf04":"code","f5acdeb5":"code","a731ee21":"code","a1c0c005":"code","81f28696":"code","a831ef14":"code","63e65564":"code","771615e0":"code","d49a23e8":"code","40fffef4":"code","788b9bd2":"code","3cce143b":"code","82e06648":"code","37552e15":"code","d3f23caf":"code","ad3917e7":"code","a30531d6":"code","b8861457":"code","91d831e4":"code","38374af6":"code","dae71806":"code","5ba7f565":"code","3fa817a1":"code","7c5f1e56":"markdown","4aea9ace":"markdown","0a5e4da6":"markdown","4cb0127a":"markdown","225a5a91":"markdown","16bdc7c9":"markdown","1b1d3331":"markdown","a66e3d6d":"markdown","47430558":"markdown","7bcfad90":"markdown","bde21cff":"markdown","de5b2fc2":"markdown","66dbf0e2":"markdown","1a8b6ab2":"markdown","9e1994dc":"markdown","a38b194e":"markdown","d28bcf1a":"markdown","711859ca":"markdown","3e70e175":"markdown","14a28c66":"markdown","cdcdb6c5":"markdown","c95d8019":"markdown","902f0cd6":"markdown","463dab6c":"markdown","8d38cdbf":"markdown","223ebe00":"markdown","7683bba7":"markdown","3c135a80":"markdown","f6616863":"markdown","da3ee0b4":"markdown","a01268da":"markdown","a29bb634":"markdown","93cfb6fb":"markdown","2b2c0835":"markdown","5847fd2b":"markdown","941ce20b":"markdown","d44afdd5":"markdown"},"source":{"f826c942":"from bs4 import BeautifulSoup","2073693a":"soup = BeautifulSoup(open(\"..\/input\/1.html\",encoding=\"utf8\"), \"html.parser\")","f3df6acd":"movie_containers = soup.find_all('div' , class_ = 'review-container')\nprint(type(movie_containers))\nprint(len(movie_containers))","d31ca511":"first_movie = movie_containers[0]\nfirst_movie.a.text","bd135557":"temp = first_movie.span.text","5f7a22ab":"temp","08d6d356":"# Lists to store the scraped data in\nreviews = []\nratings = []\n\n# Extract data from individual movie container\nfor container in movie_containers:\n    \n    #review\n    review = container.a.text\n    reviews.append(review)\n    \n    #rating\n    rating = container.span.text\n    ratings.append(rating)\n   ","9e039675":"import pandas as pd\nimport numpy as np\n\ntest_df = pd.DataFrame({'Review': reviews,'Rating': ratings})\nprint(test_df.info())\ntest_df.head()","545bbbc1":"test_df.loc[:, 'Rating'] = test_df['Rating'].str[6:8]","e860ec83":"test_df.loc[:, 'Rating'] = test_df['Rating'].str.replace('\/', '')\ntest_df.loc[:, 'Review'] = test_df['Review'].str.replace('\\n', '')\ntest_df.loc[:, 'Rating'] = test_df['Rating'].str.replace('-', '')","8dbc1b86":"import re\ndef split_it(rating):\n    return re.sub('[a-zA-Z]+','NaN', rating)","f5cdc23f":"test_df['Rating'] = test_df['Rating'].apply(split_it)","1de602f6":"test_df = test_df[test_df.Rating.str.contains(\"NaN\") == False]","e8ec3830":"test_df['Rating'] = test_df['Rating'].apply(pd.to_numeric)","6b41fadb":"test_df.head()","b50ad610":"import seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline","5bdf9923":"sns.countplot(test_df['Rating'])","c70148ee":"test_df = test_df[test_df.Rating <= 10]","18be3a33":"sns.countplot(test_df['Rating'])","69a5b9e1":"test_df.describe()","abf72300":"test_df['Review']=test_df['Review'].astype(str)\ntest_df['Review Length']=test_df['Review'].apply(len)\n\ng = sns.FacetGrid(data=test_df, col='Rating')\ng.map(plt.hist, 'Review Length', bins=50)","1ab9cd73":"plt.figure(figsize=(10,10))\nsns.boxplot(x='Rating', y='Review Length', data=test_df)","3256c4e6":"from collections import Counter\nfrom nltk.tokenize import RegexpTokenizer\nfrom stop_words import get_stop_words\nimport nltk\nfrom nltk.corpus import stopwords\nfrom nltk import sent_tokenize, word_tokenize","9f52d856":"nltk.download('punkt')","65e58d8c":"a = test_df['Review'].str.lower().str.cat(sep=' ')","3d3d7870":"# removes punctuation,numbers and returns list of words\nb = re.sub('[^A-Za-z]+', ' ', a)","77915742":"#remove all the stopwords from the text\nstop_words = list(get_stop_words('en'))         \nnltk_words = list(stopwords.words('english'))   \nstop_words.extend(nltk_words)\n\nnewStopWords = ['game','thrones', 'bran', 'stark', 'dragons']\nstop_words.extend(newStopWords)","a07b787d":"word_tokens = word_tokenize(b)","39f49e8a":"len(word_tokens)","a0fb5b72":"filtered_sentence = []\nfor w in word_tokens:\n    if w not in stop_words:\n        filtered_sentence.append(w)","c6ad164b":"len(filtered_sentence)","27f85c22":"# Remove characters which have length less than 2  \nwithout_single_chr = [word for word in filtered_sentence if len(word) > 2]\n\n# Remove numbers\ncleaned_data_title = [word for word in without_single_chr if not word.isnumeric()]   ","24e36b2b":"top_N = 100\nword_dist = nltk.FreqDist(cleaned_data_title)\nrslt = pd.DataFrame(word_dist.most_common(top_N),\n                    columns=['Word', 'Frequency'])\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.barplot(x=\"Word\",y=\"Frequency\", data=rslt.head(7))","37d06956":"from wordcloud import WordCloud, STOPWORDS","a4ab53f6":"def wc(data,bgcolor,title):\n    plt.figure(figsize = (100,100))\n    wc = WordCloud(background_color = bgcolor, max_words = 1000,  max_font_size = 50)\n    wc.generate(' '.join(data))\n    plt.imshow(wc)\n    plt.axis('off')","ea320b14":"wc(cleaned_data_title,'black','Most Used Words')","1f34eb70":"from textblob import TextBlob\n\nbloblist_desc = list()\n\ndf_review_str=test_df['Review'].astype(str)","df87fcec":"for row in df_review_str:\n    blob = TextBlob(row)\n    bloblist_desc.append((row,blob.sentiment.polarity, blob.sentiment.subjectivity))\n    df_polarity_desc = pd.DataFrame(bloblist_desc, columns = ['Review','sentiment','polarity'])","2031d7bd":"df_polarity_desc.head()","eaa190f3":"def f(df_polarity_desc):\n    if df_polarity_desc['sentiment'] >= 0:\n        val = \"Positive Review\"\n    elif df_polarity_desc['sentiment'] >= -0.09:\n        val = \"Neutral Review\"\n    else:\n        val = \"Negative Review\"\n    return val","fecddad4":"df_polarity_desc['Sentiment_Type'] = df_polarity_desc.apply(f, axis=1)\n\nplt.figure(figsize=(10,10))\nsns.set_style(\"whitegrid\")\nax = sns.countplot(x=\"Sentiment_Type\", data=df_polarity_desc)","801d709b":"positive_reviews=df_polarity_desc[df_polarity_desc['Sentiment_Type']=='Positive Review']\nnegative_reviews=df_polarity_desc[df_polarity_desc['Sentiment_Type']=='Negative Review']","d2cd7ede":"negative_reviews.head()","cca7b229":"wc(positive_reviews['Review'],'black','Most Used Words')","033be7b1":"wc(negative_reviews['Review'],'black','Most Used Words')","d963bf04":"import string\ndef text_process(review):\n    nopunc=[word for word in review if word not in string.punctuation]\n    nopunc=''.join(nopunc)\n    return [word for word in nopunc.split() if word.lower() not in stopwords.words('english')]","f5acdeb5":"test_df=test_df.dropna(axis=0,how='any')\nrating_class = test_df[(test_df['Rating'] == 1) | (test_df['Rating'] == 10)]\nX_review=rating_class['Review']\ny=rating_class['Rating']","a731ee21":"from sklearn.feature_extraction.text import CountVectorizer\nbow_transformer=CountVectorizer(analyzer=text_process).fit(X_review)","a1c0c005":"X_review = bow_transformer.transform(X_review)","81f28696":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_review, y, test_size=0.3, random_state=101)","a831ef14":"from sklearn.naive_bayes import MultinomialNB\nnb = MultinomialNB()\nnb.fit(X_train, y_train)\npredict=nb.predict(X_test)","63e65564":"from sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nprint(confusion_matrix(y_test, predict))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, predict))\nprint(classification_report(y_test, predict))","771615e0":"rating_positive=test_df['Review'][6]\nrating_positive","d49a23e8":"rating_postive_transformed = bow_transformer.transform([rating_positive])\nnb.predict(rating_postive_transformed)[0]","40fffef4":"rating_negative=test_df['Review'][54]\nrating_negative","788b9bd2":"rating_negative_transformed = bow_transformer.transform([rating_negative])\nnb.predict(rating_negative_transformed)[0]","3cce143b":"ratings_1 = (rating_class['Rating']==1).sum()\nratings_1_indices = np.array(rating_class[rating_class.Rating == 1].index)\n","82e06648":"ratings_10_indices = rating_class[rating_class.Rating == 10].index\n\n\nrandom_normal_indices = np.random.choice(ratings_10_indices, ratings_1, replace = False)\nrandom_normal_indices = np.array(random_normal_indices)\n\nunder_sample_indices = np.concatenate([ratings_1_indices,random_normal_indices])\n\n\n\n","37552e15":"undersample = rating_class.ix[under_sample_indices]\n\nX_undersample = undersample.ix[:, undersample.columns != 'Rating']\ny_undersample = undersample.ix[:, undersample.columns == 'Rating']","d3f23caf":"print(\"Percentage of 10 ratings: \", len(undersample[undersample.Rating == 10])\/len(undersample))\nprint(\"Percentage of 1 ratings: \", len(undersample[undersample.Rating == 1])\/len(undersample))\nprint(\"Total number of examples in resampled data: \", len(undersample))","ad3917e7":"X_review_us = X_undersample['Review']","a30531d6":"X_review_us = bow_transformer.transform(X_review_us)","b8861457":"X_train_us, X_test_us, y_train_us, y_test_us = train_test_split(X_review_us, y_undersample, test_size=0.3, random_state=101)","91d831e4":"nb.fit(X_train_us, y_train_us)\npredict_us=nb.predict(X_test_us)","38374af6":"print(confusion_matrix(y_test_us, predict_us))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test_us, predict_us))\nprint(classification_report(y_test_us, predict_us))","dae71806":"nb.fit(X_train_us, y_train_us)\npredict_entire=nb.predict(X_test)","5ba7f565":"print(confusion_matrix(y_test, predict_entire))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, predict_entire))\nprint(classification_report(y_test, predict_entire))","3fa817a1":"print(confusion_matrix(y_test, predict))\nprint('\\n Accuracy:')\nprint(accuracy_score(y_test, predict))\nprint(classification_report(y_test, predict))","7c5f1e56":"## Let us perform Web Scraping using BeautifulSoup ","4aea9ace":"Let us try to find the ratings of the reviews","0a5e4da6":"Although, our overall accuracy has decreased. We have increased the recall to 90 percent.\nHence our model can classify review with 1 rating better. <br>\nComparing with the original model without undersampling","4cb0127a":"Let us test our model","225a5a91":"Let us look at the top 10 most used words in a review.","16bdc7c9":"We can see that there are some Ratings above 10 that we need to get rid of.","1b1d3331":"Let us try to extract all the reviews and the ratings","a66e3d6d":"We can see that we have cleaned the Ratings and the Reviews\nThere might be some redundency in the cleaning which I will update later","47430558":"We have a 81 percent accuracy but a very recall score indicating that movies with ratings 1's\nare not classified properly this maybe due to a large ratio of positive review. \nHence it has a bad recall.\n","7bcfad90":"After looking at the sentiments I have used the above values. This is a personal perference which you can change according to your choice.","bde21cff":"We can see a reduced accuracy but we have increased the recall now let us try to use this model on the entire data","de5b2fc2":"Let us train a model using Multinomial Naive Bayes as it works great on text.","66dbf0e2":"Let us try to perform analysis on the entire review rather than all the words.\nFor this we make use of the TextBlob","1a8b6ab2":"As we can see that we have a skewed data set and let us try to improve recall by performing undersampling","9e1994dc":"We will now remove the stop words from the reviews","a38b194e":"Let us look at the most used words in all the positive reviews","d28bcf1a":"Let us try to extract the reviews","711859ca":"Let us visualise the most common words","3e70e175":"Let us try to extract all the words and try to perform analysis on it","14a28c66":"We have extracted all the words in the reviews. Let us find the total length","cdcdb6c5":"Let us look at the most used words in all the negative reviews","c95d8019":"Let us look at the descriptions","902f0cd6":"We can see that the most common words are positive indicating how great Game of thrones is!","463dab6c":"Let us look if there is a relation between a review length and a Rating","8d38cdbf":"Let us find the accuracy, precision and recall","223ebe00":"We can see that Reviews with ratings 1 and and 8 are the longest","7683bba7":"We have removed all the stop words and reduced the size by half.","3c135a80":"Importing the required libraries and extracting the Movie reviews and their ratings","f6616863":"We can see that the reviews and ratings require cleaning which we will deal with it later","da3ee0b4":"Let us try to use machine learning and use NLP analytics","a01268da":"Let us try to put all the ratings into a dataframe","a29bb634":"We can see there are 1124 containers consisting of the reviews and the ratings","93cfb6fb":"We will try to perform sentimental analysis and try to classify whether a review is a positive or negative","2b2c0835":"Let us take a look at the html structure ","5847fd2b":"And woah we have scrapped all the reviews and the ratings \nPandas do actualy make our work easier!","941ce20b":"Let us perform cleaning on the reviews and the ratings","d44afdd5":"Let us now train a model \nWe are taking only review with ratings 1 and 10 to perform the analysis to make the analysis more simple."}}