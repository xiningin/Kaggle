{"cell_type":{"ddb8dafb":"code","e281d643":"code","9c010e6d":"code","75094138":"code","288b2707":"code","6aaf660d":"code","12f7be75":"code","feab1923":"code","d824f329":"code","747c4ac9":"code","3db93083":"code","b9858353":"code","e2ec96f8":"code","78627985":"code","7f2f820c":"code","f9b8a4b8":"code","c271ad37":"code","212d280c":"code","8efadb15":"code","d0d793dd":"code","3f970d0c":"code","32d50811":"code","b4a3bb48":"code","ca4f420f":"code","ab454cdc":"code","9808e3e8":"code","390f74a7":"code","f5c0777f":"code","4050c914":"code","849166be":"code","74185f89":"code","e460b7df":"code","52e6dec8":"code","90f9cb88":"code","58e35224":"code","145e0508":"code","7f2e2ee4":"code","64e95c9b":"code","7927bf8c":"code","20ec753b":"code","76b9716a":"code","b88372da":"markdown","67563d32":"markdown","154bb3d1":"markdown","1b362eee":"markdown","281f5f2e":"markdown","204d5824":"markdown","40fab220":"markdown","2f46d14e":"markdown","da44721b":"markdown","0c931c27":"markdown","43be916e":"markdown","cd2c6a0f":"markdown","7a39e357":"markdown","67ea0c5a":"markdown","53e13d12":"markdown","b8df1ac6":"markdown","8c1ca743":"markdown","0177c074":"markdown","6253c84c":"markdown","20058b51":"markdown","ba1d39db":"markdown","7a03734a":"markdown","399a946d":"markdown","9563f6f6":"markdown","47649c85":"markdown","3ecee674":"markdown","82a11d8d":"markdown","17a4a465":"markdown","56c1fc8c":"markdown","bd798d29":"markdown","a63f6063":"markdown","90862b75":"markdown","282c8217":"markdown","1faa185f":"markdown","7955e67a":"markdown","661852fd":"markdown","e676d0a7":"markdown","f6d1e861":"markdown","bce2a5c9":"markdown","3ec57fba":"markdown","03c22363":"markdown","897d43da":"markdown","d7643522":"markdown","fd9ef80b":"markdown","a3721954":"markdown","1e80c3fc":"markdown","7d792c64":"markdown","78908b18":"markdown","17fe04c5":"markdown","aedfc66f":"markdown"},"source":{"ddb8dafb":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.model_selection import train_test_split, StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier, VotingClassifier\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report, confusion_matrix, roc_curve, auc\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\nfrom collections import Counter\nfrom scipy import interp\nimport itertools\n%matplotlib inline\n\nimport warnings\nwarnings.filterwarnings(\"ignore\", category=FutureWarning)","e281d643":"table = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')","9c010e6d":"table.isnull().sum().all()","75094138":"table.head()","288b2707":"table.tail()","6aaf660d":"table.info()","12f7be75":"table.describe()","feab1923":"plt.bar(['Non-Fraud','Fraud'], table['Class'].value_counts(), color=['b','r'])\nplt.xlabel('Class')\nplt.ylabel('Number of transactions')\nplt.annotate('{}\\n({:.4}%)'.format(table['Class'].value_counts()[0], \n                                         table['Class'].value_counts()[0]\/table['Class'].count()*100),\n             (0.20, 0.45), xycoords='axes fraction')\nplt.annotate('{}\\n({:.4}%)'.format(table['Class'].value_counts()[1], \n                                         table['Class'].value_counts()[1]\/table['Class'].count()*100),\n             (0.70, 0.45), xycoords='axes fraction')\nplt.tight_layout()\nplt.show()","d824f329":"plt.scatter(table['Time']\/(60*60), table['Class'])\nplt.xlabel('Time of transaction (in hours)')\nplt.ylabel('Class')\n\nplt.tight_layout()\nplt.show()","747c4ac9":"plt.boxplot(table['Amount'], labels = ['Boxplot'])\nplt.ylabel('Transaction amount')\nplt.plot()\n\namount = table[['Amount']].sort_values(by='Amount')\nq1, q3 = np.percentile(amount,[25,75])\niqr = q3 - q1\nlower_bound = q1 -(1.5 * iqr) \nupper_bound = q3 +(1.5 * iqr)\n\nprint('Number of outliers below the lower bound: ', amount[amount['Amount'] < lower_bound].count()[0],\n     ' ({:.4}%)'.format(amount[amount['Amount'] < lower_bound].count()[0] \/ amount['Amount'].count() * 100))\nprint('Number of outliers above the upper bound: ', amount[amount['Amount'] > upper_bound].count()[0],\n      ' ({:.4}%)'.format(amount[amount['Amount'] > upper_bound].count()[0] \/ amount['Amount'].count() * 100))","3db93083":"table[table['Class']==1].where(table['Amount']>upper_bound).count()['Amount']","b9858353":"plt.scatter(table['Amount'], table['Class'])\nplt.xlabel('Amount')\nplt.ylabel('Class')\nplt.show()","e2ec96f8":"target_0 = table.loc[table['Class'] == 0]\ntarget_1 = table.loc[table['Class'] == 1]\nax1=sns.distplot(target_0[['Amount']], hist=False, color='b', label='Non-fraud')\nax2=sns.distplot(target_1[['Amount']], hist=False, color='r', label='Fraud')\nax1.set_xlim(0, max(table[table['Class']==1]['Amount']))\nax2.set_xlim(0, max(table[table['Class']==1]['Amount']))\nplt.legend()\nplt.xlabel('Amount')\nplt.ylabel('Density of probability')\nplt.show()","78627985":"table.loc[table['Class'] == 1]['Amount'].describe()","7f2f820c":"heatmap = sns.heatmap(table.corr(method='spearman'))","f9b8a4b8":"table.corrwith(table.Class).plot.bar(figsize = (20, 10), title = \"Correlation with class\", fontsize = 15, \n                                     rot = 45, grid = True, color=['blue'])\nplt.show()","c271ad37":"y = table['Class']\nX = table.drop(columns=['Class'])","212d280c":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.3, stratify=y, random_state=42)","8efadb15":"rus = RandomUnderSampler(sampling_strategy='auto', random_state=42, replacement=False)\nX_rus, y_rus = rus.fit_resample(X_train, y_train)","d0d793dd":"plt.bar(['Non-Fraud','Fraud'], [Counter(y_rus)[0], Counter(y_rus)[1]], color=['b','r'])\nplt.xlabel('Class')\nplt.ylabel('Number of transactions')\nplt.annotate('{}'.format(Counter(y_rus)[0]), (0.25, 0.45), xycoords='axes fraction')\nplt.annotate('{}'.format(Counter(y_rus)[1]), (0.75, 0.45), xycoords='axes fraction')\n\nplt.tight_layout()\nplt.show()","3f970d0c":"assert Counter(y_rus)[1] == Counter(y_train)[1] #Checking if they have the same number of fraud cases","32d50811":"ros = RandomOverSampler(sampling_strategy='auto', random_state=42)\nX_ros, y_ros = ros.fit_resample(X_train, y_train)","b4a3bb48":"plt.bar(['Non-Fraud','Fraud'], [Counter(y_ros)[0], Counter(y_ros)[1]], color=['b','r'])\nplt.xlabel('Class')\nplt.ylabel('Number of transactions')\nplt.annotate('{}'.format(Counter(y_ros)[0]), (0.20, 0.45), xycoords='axes fraction')\nplt.annotate('{}'.format(Counter(y_ros)[1]), (0.70, 0.45), xycoords='axes fraction')\n\nplt.tight_layout()\nplt.show()","ca4f420f":"assert Counter(y_ros)[0] == Counter(y_train)[0] #Checking if they have the same number of non-fraud cases","ab454cdc":"smote = SMOTE(sampling_strategy='auto', random_state=42)\nX_smote, y_smote = smote.fit_resample(X_train, y_train)","9808e3e8":"plt.bar(['Non-Fraud','Fraud'], [Counter(y_smote)[0], Counter(y_smote)[1]], color=['b','r'])\nplt.xlabel('Class')\nplt.ylabel('Number of transactions')\nplt.annotate('{}'.format(Counter(y_smote)[0]), (0.20, 0.45), xycoords='axes fraction')\nplt.annotate('{}'.format(Counter(y_smote)[1]), (0.70, 0.45), xycoords='axes fraction')\n\nplt.tight_layout()\nplt.show()","390f74a7":"assert Counter(y_smote)[0] == Counter(y_train)[0] #Checking if they have the same number of non-fraud cases","f5c0777f":"def feature_scaling(X, X_test=X_test):\n    std_scale = StandardScaler().fit(X)\n    X_std = std_scale.transform(X)\n    X_test_std = std_scale.transform(X_test)\n    return X_std, X_test_std","4050c914":"X_rus_std, X_test_rus_std = feature_scaling(X_rus)\nX_ros_std, X_test_ros_std = feature_scaling(X_ros)\nX_smote_std, X_test_smote_std = feature_scaling(X_smote)","849166be":"pca = PCA(n_components=2)\nX_ros_pca = pca.fit_transform(X_ros_std)\nX_smote_pca = pca.fit_transform(X_smote_std)","74185f89":"def plot_2d_space(X, y, label='Classes'):\n    '''Plots the data points in a 2D scatterplot.'''\n    colors = ['blue', 'red']\n    markers = ['o', 's']\n    for l, c, m in zip(np.unique(y), colors, markers):\n        plt.scatter(X[y==l, 0], X[y==l, 1], c=c, label=l, marker=m)\n    plt.title(label)\n    plt.legend(loc='best')\n    plt.show()","e460b7df":"plot_2d_space(X_ros_pca, y_ros, 'Balanced dataset (2 PCA components) using random oversampling')\nplot_2d_space(X_smote_pca, y_smote, 'Balanced dataset (2 PCA components) using SMOTE')","52e6dec8":"classifiers = []\n\nclassifiers.append(('Logistic Regression', LogisticRegression(random_state=42)))\nclassifiers.append(('Naive Bayes', GaussianNB()))\nclassifiers.append(('KNN', KNeighborsClassifier()))\n#classifiers.append(('SVM', SVC(random_state=42, probability=True))) #This one takes a very long time to run!\nclassifiers.append(('Decision Tree', DecisionTreeClassifier(random_state=42)))\nclassifiers.append(('Random Forest', RandomForestClassifier(random_state=42)))\n\n#Ensemble classifier - All classifiers have the same weight\neclf = VotingClassifier(estimators=classifiers, voting='soft', weights=np.ones(len(classifiers)))","90f9cb88":"def plot_confusion_matrix(cm, classes,\n                          normalize=False,\n                          title='Confusion matrix',\n                          cmap=plt.cm.Blues):\n    \"\"\"\n    This function prints and plots the confusion matrix.\n    Normalization can be applied by setting `normalize=True`.\n    \"\"\"\n    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n    plt.title(title)\n    plt.colorbar()\n    tick_marks = np.arange(len(classes))\n    plt.xticks(tick_marks, classes, rotation=45)\n    plt.yticks(tick_marks, classes)\n\n    #if normalize:\n    #    cm = cm.astype('float') \/ cm.sum(axis=1)[:, np.newaxis]\n    #    print(\"Normalized confusion matrix\")\n    #else:\n    #    print('Confusion matrix, without normalization')\n\n    #print(cm)\n\n    thresh = cm.max() \/ 2.\n    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n        plt.text(j, i, cm[i, j],\n                 horizontalalignment=\"center\",\n                 color=\"white\" if cm[i, j] > thresh else \"black\")\n\n    plt.tight_layout()\n    plt.ylabel('True label')\n    plt.xlabel('Predicted label')","58e35224":"from sklearn import svm\nfrom sklearn.metrics import roc_curve, auc\nfrom sklearn.model_selection import StratifiedKFold\nfrom scipy import interp\n\ndef plot_CM_and_ROC_curve(classifier, X_train, y_train, X_test, y_test):\n    '''Plots the ROC curve and the confusion matrix, and calculates AUC, recall and precision.'''\n    \n    name = classifier[0]\n    classifier = classifier[1]\n\n    mean_fpr = np.linspace(0, 1, 100)\n    class_names = ['Non-Fraud', 'Fraud']\n    confusion_matrix_total = [[0, 0], [0, 0]]\n    \n    #Obtain probabilities for each class\n    probas_ = classifier.fit(X_train, y_train).predict_proba(X_test)\n    \n    # Compute ROC curve and area the curve\n    fpr, tpr, thresholds = roc_curve(y_test, probas_[:, 1])\n    roc_auc = auc(fpr, tpr)\n    plt.plot(fpr, tpr, lw=1, alpha=1, color='b', label='ROC (AUC = %0.7f)' % (roc_auc))\n    plt.plot([0, 1], [0, 1], linestyle='--', lw=2, color='r',\n             label='Chance', alpha=.8)\n    plt.xlim([-0.05, 1.05])\n    plt.ylim([-0.05, 1.05])\n    plt.xlabel('False Positive Rate')\n    plt.ylabel('True Positive Rate')\n    plt.title('ROC curve - model: ' + name)\n    plt.legend(loc=\"lower right\")\n    plt.show()\n    \n    #Store the confusion matrix result to plot a table later\n    y_pred=classifier.predict(X_test)\n    cnf_matrix = confusion_matrix(y_test, y_pred)\n    confusion_matrix_total += cnf_matrix\n    \n    #Print precision and recall\n    tn, fp = confusion_matrix_total.tolist()[0]\n    fn, tp = confusion_matrix_total.tolist()[1]\n    accuracy = (tp+tn)\/(tp+tn+fp+fn)\n    precision = tp\/(tp+fp)\n    recall = tp\/(tp+fn)\n    print('Accuracy = {:2.2f}%'.format(accuracy*100))\n    print('Precision = {:2.2f}%'.format(precision*100))\n    print('Recall = {:2.2f}%'.format(recall*100))\n    \n    # Plot confusion matrix\n    plt.figure()\n    plot_confusion_matrix(confusion_matrix_total, classes=class_names, title='Confusion matrix - model: ' + name)\n    plt.show()","145e0508":"for clf in classifiers:\n    plot_CM_and_ROC_curve(clf, X_rus_std, y_rus, X_test_rus_std, y_test)","7f2e2ee4":"plot_CM_and_ROC_curve(('Ensemble model', eclf), X_rus_std, y_rus, X_test_rus_std, y_test)","64e95c9b":"for clf in classifiers:\n    plot_CM_and_ROC_curve(clf, X_ros_std, y_ros, X_test_ros_std, y_test)","7927bf8c":"plot_CM_and_ROC_curve(('Ensemble model', eclf), X_ros_std, y_ros, X_test_ros_std, y_test)","20ec753b":"for clf in classifiers:\n    plot_CM_and_ROC_curve(clf, X_smote_std, y_smote, X_test_smote_std, y_test)","76b9716a":"plot_CM_and_ROC_curve(('Ensemble model', eclf), X_smote_std, y_smote, X_test_smote_std, y_test)","b88372da":"<a id='ros'><\/a>","67563d32":"<a id='EDA'><\/a>","154bb3d1":"Checking If classes are balanced:","1b362eee":"Null elements are not present in the dataset.","281f5f2e":"In addition to that, only 91 out of 31904 outliers are classified as frauds.","204d5824":"<a id='Balancing'><\/a>","40fab220":"Checking If classes are balanced:","2f46d14e":"<a id='models-ros'><\/a>","da44721b":"When we used random undersampling the best model was a simple logistic regression with AUC = 0.9722, recall = 87.16% and precision = 7.94%. The number of false negatives, the worst possible classification regarding frauds, for the logistic regression was 19 out of 148 cases present in the test set. However, we can notice that the ensemble model (a soft voting combination of all simple models with the same weights) was the second best in this case with AUC = 0.9671 and 20 false negative cases, only 1 more than the logistic regression. We can also notice that in all models the number of false positives was pretty high. The best result was with logistic regression (1496 false positive cases). It's good to remember that when we use undersampling method, a lot of information is lost due to discarding part of the observations. Then, it was already expected a not very good result.\n\nWith the random oversampling method, we can verify the true power of ensemble models. Our ensemble model combined the best part of the simple models and could get a very high AUC (0.967), high precision (85.19%) and high recall (77.7%). Looking at the confusion matrix we can see the cases for false negative and false positive as 33 and 20, respectively. The logistic regression was the model with the lowest number of false negatives (only 18) and the random forest was the model with the lowest number of false positives (an astonishing result of only 3!). So, if we try to tweak the weights for each model in the ensemble model, we can achieve an even better result.\n\nThe analysis for SMOTE method is very similar to the random oversampling method. Again, we can see that the ensemble model could get the best parts of all simple models, resulting in a good performance. Once again, tweaking the weights for each simple model might be a way to enhance the result.\n\nAn interesting result is that in all cases of resampling, the highest AUC score among the simple models was using logistic regression. In my opinion, binary classification problems should have at least this model as a benchmark when the objective is to maximize the AUC.","0c931c27":"# Models and Results","43be916e":"## Results using random undersampling","cd2c6a0f":"![](https:\/\/github.com\/alexandrebvd\/udacity-capstone-project-credit-card-fraud-prediction\/blob\/master\/Images\/resampling.png?raw=true)\n\n[Image Source](https:\/\/www.kaggle.com\/rafjaa\/resampling-strategies-for-imbalanced-datasets)","7a39e357":"<a id='rosxsmote'><\/a>","67ea0c5a":"Creating a function to visualize the data distribution after the PCA.","53e13d12":"The dataset has only two classes: fraud or non-fraud. The classes are highly imbalanced with 99.83% of observations belonging to non-fraudulent transactions and only 0.17% of observations labeled as fraudulent. This issue will be adressed later with a method for balancing classes.","b8df1ac6":"Now we can clearly see that new the observations tagged as 1 (fraudulent transactions) are present in different coordinates on the graphs above. This is the SMOTE algorithm works.\n\nAlso, by applying the PCA we can visualize the data in 2D and now we can see that the patterns for fraud and non-fraud transactions are distinct and each class has its own cluster.","8c1ca743":"# Balancing the classes","0177c074":"<a id='rus'><\/a>","6253c84c":"# Table of contents\n- [Exploraroty Data Analysis](#EDA)\n\n- [Balancing the classes](#Balancing)\n\n    - [Random Undersampling](#rus)\n    - [Random Oversampling](#ros) \n    - [SMOTE](#smote)\n        - [Checking the difference between random oversampling and SMOTE](#rosxsmote)\n\n- [Metrics](#metrics)\n\n- [Models and Results](#models)\n    - [Results using random undersampling](#models-rus)\n    - [Results using random oversampling](#models-ros)\n    - [Results using SMOTE](#models-smote)\n\n- [Conclusions](#conclusions)","20058b51":"We are going to test three types of resampling methods: [random undersampling](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/generated\/imblearn.under_sampling.RandomUnderSampler.html#imblearn.under_sampling.RandomUnderSampler), [random oversampling](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/generated\/imblearn.over_sampling.RandomOverSampler.html#imblearn.over_sampling.RandomOverSampler) and [Synthetic Minority Over-sampling (SMOTE)](https:\/\/imbalanced-learn.readthedocs.io\/en\/stable\/generated\/imblearn.over_sampling.SMOTE.html#imblearn.over_sampling.SMOTE). The image below depicts how undersampling and oversampling works and it is very intuitive to understand. SMOTE is similar to oversampling but instead of copying the same original points randomly, the algorithm creates new points close to the original ones.","ba1d39db":"Usually accuracy is the first metric that comes to mind when someone is assessing a model performance. However, we must be careful. The data in this case is highly unbalanced, so accuracy is not a good metric at all. If we created a model that always classifies a transaction as non-fraudulent, we would have an astonishing accuracy of 99.83%! So, what is the solution? We should use other metrics to consider a model as good or bad.\n\nThe metrics to be used will be the [Area Under the ROC curve](https:\/\/en.wikipedia.org\/wiki\/Receiver_operating_characteristic#Area_under_the_curve) (also called AUC), and the [recall and precision](https:\/\/en.wikipedia.org\/wiki\/Precision_and_recall) scores obtained from the confusion matrix.\n\nThe ROC curve is a plot with the true positive rate on the y-axis and false positive rate on the x-axis. The true positive rate answers the question \"When the actual classification is positive, how often does the classifier predict positive?\" and the false positive rate answers the question \"When the actual classification is negative, how often does the classifier incorrectly predict positive?\"\n\nThe AUC shows how good the classifier is in separating the classes. The closer to 1, the better is the classifier.\n\nPrecision answers the question \"what proportion of positive identifications was actually correct?\" and recall answers \"what proportion of actual positives was identified correctly?\"\n\nWith these 3 metrics the we can to tell whether the model performance is good or poor.","7a03734a":"We can see below that all features have very low correlation coefficients among each other, and especially low correlation with the 'Class' feature. This was already expected since the data was processed using PCA.","399a946d":"# Exploratory data analysis","9563f6f6":"The data was collected over the period of 2 days and, apparently, the 'Time' variable isn't a good predictor for frauds. As seen above, the pattern for both non-fradulent and fraudulent transactions seems to be random regarding the hour of the day.","47649c85":"<a id='metrics'><\/a>","3ecee674":"## Results using SMOTE","82a11d8d":"The objective was to create simple and commonly used machine learning models like logistic regression, KNN, random forest and maybe others to compare how they perform regarding the metric chosen (AUC) for the task of predicting fraudulent credit card transactions. After that, I created an ensemble model that combines the predictions provided by the simple models as a way of further enhancing the performance. This work was my capstone project for Udacity nanodegree program. I hope you enjoy it.\n\nYou can find the original repository [here](https:\/\/github.com\/alexandrebvd\/udacity-capstone-project-credit-card-fraud-prediction).","17a4a465":"Transforming all the sets using different types of sampling:","56c1fc8c":"The data was split in train and test sets maintaining the original rate of frauds to non-frauds observations in each set by using 'stratify=y' in the function train_test_split.","bd798d29":"The next two plots show that fraudulent transactions are highly concentrated at smaller values when compared to non-fraudulent transactions.","a63f6063":"## Random undersampling","90862b75":"# Metrics","282c8217":"Because the dataset has many features and our graphs will be 2D, we will reduce the size of the dataset using Principal Component Analysis (PCA). But before using PCA, it is recommended to scale the features.","1faa185f":"<a id='models-smote'><\/a>","7955e67a":"Before balancing the classes we need to split the observations into a training set and a testing set. ***This is extremely important!*** We can only balance the classes after we set some observations aside to be used as a test set! Otherwise, the models might use part of the test data during the training, which will lead to overfitting. Let's be smart and avoid that! :)","661852fd":"A quick explanation of how SMOTE works: it consists of synthesizing elements for the minority class using the existing ones. It randomly chooses a point from the minority class and computes the k-nearest neighbors (default = 5) for this point. The synthetic points are added between the chosen point and its neighbors by choosing a factor between 0 and 1 to multiply the distance. This process can be seen below.","e676d0a7":"<a id='conclusions'><\/a>","f6d1e861":"<a id='smote'><\/a>","bce2a5c9":"## Random oversampling","3ec57fba":"## Results using oversampling","03c22363":"### Checking the difference between random oversampling and SMOTE","897d43da":"The models to be used are shown below. There are also functions to plot the confusion matrix and the ROC curve for the models.","d7643522":"# Conclusions","fd9ef80b":"<a id='models'><\/a>","a3721954":"<a id='models-rus'><\/a>","1e80c3fc":"![](https:\/\/github.com\/alexandrebvd\/udacity-capstone-project-credit-card-fraud-prediction\/blob\/master\/Images\/smote.png?raw=true)\n\n[Image Source](https:\/\/www.kaggle.com\/rafjaa\/resampling-strategies-for-imbalanced-datasets)","7d792c64":"Let's create a function to perform feature scaling because some models need this prior to fitting and we can use it more than one time.","78908b18":"The interquartile range method found 31904 outliers, which represents 11.2% of the observations. Removing them from the dataset would be a bad idea due to the loss of a large amount of information for the machine learning models.","17fe04c5":"## Synthetic Minority Over-sampling (SMOTE)","aedfc66f":"The ensemble model used here is a [soft voting classifier](http:\/\/www.datajango.com\/heterogeneous-ensemble-learning-hard-voting-soft-voting\/) which puts the same weight to all individual classifiers' class probabilities. It was already proven in many competitions that classifiers that combine predictions from more than one single classifier can achieve a better performance."}}