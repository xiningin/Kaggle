{"cell_type":{"7229bed9":"code","a348e060":"code","68404ffd":"code","e3e2cb2b":"code","04f35c5b":"code","6d3d7510":"code","114306ba":"code","c5275923":"code","d37ecc63":"code","1e567841":"code","6c99745d":"code","86dda4fc":"code","a7312981":"code","0229634e":"markdown","9c68a41d":"markdown","c61a2870":"markdown","1a14e07f":"markdown","c5d63ab0":"markdown","4e3b2079":"markdown","d0be39ac":"markdown","3ef933ff":"markdown","96b9e5c3":"markdown"},"source":{"7229bed9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a348e060":"import nltk\nfrom wordcloud import WordCloud\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.linear_model import LogisticRegression\nfrom nltk import word_tokenize\nfrom nltk.stem.porter import PorterStemmer\nimport re\nfrom sklearn.feature_extraction.text import TfidfVectorizer ,ENGLISH_STOP_WORDS\nimport matplotlib.pyplot as plt\nfrom sklearn.model_selection import train_test_split","68404ffd":"df = pd.read_csv('..\/input\/amazon-product-reviews\/Reviews.csv')\n\ndf.head()","e3e2cb2b":"df.drop(['ProductId', 'UserId','ProfileName','HelpfulnessNumerator','HelpfulnessDenominator','Time','Summary'], axis=1)\n","04f35c5b":"rating_prec = df['Score'].value_counts()\/len(df) * 100\nrating_prec","6d3d7510":"txt = ' '.join(review for review in df.Text)\n\nwordcloud = WordCloud(\n            background_color = 'white',\n            max_font_size = 100,\n            max_words = 100,\n            width = 800,\n            height = 500\n            ).generate(txt)\n\n\nplt.imshow(wordcloud,interpolation = 'bilinear')\nplt.axis('off')\nplt.show()","114306ba":"def apply_sentiment(Rating):\n    if(Rating <=2 ):\n        return 0\n    else:\n        return 1","c5275923":"Y = df['Score'].apply(apply_sentiment)","d37ecc63":"vect = TfidfVectorizer(stop_words=ENGLISH_STOP_WORDS, ngram_range=(1, 2), max_features=200, token_pattern=r'\\b[^\\d\\W][^\\d\\W]+\\b').fit(df.Text)\nX = vect.transform(df.Text)\nprint(X)\n","1e567841":"reviews_transformed = pd.DataFrame(X.toarray(), columns=vect.get_feature_names())\nprint('Top 5 rows of the DataFrame: \\n', reviews_transformed.head())","6c99745d":"X_train, X_test, y_train, y_test = train_test_split(reviews_transformed, Y, test_size=0.2, random_state=456)\n","86dda4fc":"log_reg = LogisticRegression().fit(X_train, y_train)\n","a7312981":"y_predicted = log_reg.predict(X_test)\nscore=accuracy_score(y_test,y_predicted)\nprint(f'Accuracy: {round(score*100,2)}%')","0229634e":"# Train\/test split\n","9c68a41d":"# Make word Vector and remove english stop words \n","c61a2870":"# Start to Data Cleaning : Fill Empty Coulmns , Removing Stop Words\n# ","1a14e07f":"What is the distribution of ratings across dataset\n\n","c5d63ab0":"Data Preprocessing transfer score to 0 or 1 for LogisticRegression model","4e3b2079":"Make a wordcloud for text in reviews","d0be39ac":"# Train a Logistic Regression","3ef933ff":"**Also we can increase accuracy if we clean the text by using stemming methods \n# for now if you like the Notebook Please UPVOTE it ","96b9e5c3":"# Predict values and test Accuracy\n"}}