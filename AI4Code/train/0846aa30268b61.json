{"cell_type":{"f0e749d4":"code","5d080487":"code","3d83584d":"code","796d831c":"code","a9f7d9f1":"code","7359e454":"code","16f5a447":"code","83ffc437":"code","2a2630af":"code","14810926":"code","89bfc5f6":"code","36940a56":"code","306f389a":"code","0e22e2ec":"code","2e9544eb":"code","36ee464d":"code","31ce7e3a":"code","00009749":"code","62499cec":"code","70139e48":"code","48e4dbf3":"code","d8800458":"code","afa4d659":"code","13aa17f6":"code","a503871f":"code","544a609e":"code","036e3f19":"code","45782a9f":"code","f89734fe":"code","a53624c5":"code","1b97e7a4":"code","b40d22fd":"code","a3f99806":"code","74c62cff":"code","a9c67d47":"code","dc6adbbe":"code","977c2d63":"code","1b9740a4":"code","96ebd91d":"code","12357d62":"code","a18f51e2":"code","8df3c05f":"code","5d787fac":"code","381d3a23":"code","84c336c2":"code","ae228e2e":"code","a2ef5df9":"code","6ce17507":"code","eab683d1":"code","eb23e1fa":"code","6e79ca9f":"code","695dbafe":"code","30df7f38":"code","8fe31831":"code","f02f98e2":"code","bc02ae78":"code","342f6d1e":"code","47bca4ff":"code","f64ff3b1":"markdown","c6624e33":"markdown","b7e6e1c1":"markdown","155afc06":"markdown","d64cb063":"markdown","982d2fc2":"markdown","6a3beb53":"markdown","c33d73fd":"markdown","e1c6b005":"markdown","8d1ffc2b":"markdown","5cfce161":"markdown","8e29c51d":"markdown","093c247d":"markdown","9c4baa66":"markdown","ffff1038":"markdown","345383d3":"markdown","c0c012a6":"markdown","0533c568":"markdown","0ff20ae0":"markdown","adc3898c":"markdown","f0d2fb67":"markdown","1de02034":"markdown","0ce9bb7e":"markdown","a06c9c3c":"markdown","cd7560eb":"markdown","b2ab8afb":"markdown","70c95570":"markdown","33feb531":"markdown","0e9fe14d":"markdown","c3da3834":"markdown","18c3ffe3":"markdown","aa3b3f71":"markdown","3c434f09":"markdown","caa8e5d0":"markdown","2507d1e6":"markdown","1a51de0d":"markdown","c29136a3":"markdown","8e36bf04":"markdown","d9ed6852":"markdown","1ad3a801":"markdown","eef3ae8f":"markdown","69f61e71":"markdown","dfee593f":"markdown"},"source":{"f0e749d4":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport seaborn as sns","5d080487":"data = pd.read_csv('data_ods_reto.csv')","3d83584d":"data.head()","796d831c":"data.describe()","a9f7d9f1":"data.info()","7359e454":"data[\"output\"].value_counts()","16f5a447":"corr = data.corr()\ncorr","83ffc437":"#Busco las variables cuyo valor absoluto de correlaci\u00f3n es mayor que 0.72\ncorr_value = abs(corr[\"output\"])\ncorr_features = corr_value[corr_value>0.72]\ncorr_features","2a2630af":"sns.heatmap(data.corr(),cmap='coolwarm')","14810926":"#Creamos un nuevo conjunto de datos solamente con las variables m\u00e1s relevantes\nnew_data= data[['TCSC', 'vfleak', 'A2', 'mav','SamEn', 'x3','x4','bCP','bWT']]\ntarget=data['output']\nnew_data.info()\ntarget","89bfc5f6":"#pip install imbalanced-learn","36940a56":"#Para crear una muestra de datos haremos oversampling en un nuevo dataset\nX2=new_data\ny2=target\n\nfrom imblearn.over_sampling import RandomOverSampler, SMOTE\noversample = SMOTE()\nX_os,y_os = oversample.fit_resample(X2, y2)","306f389a":"y_os.value_counts()","0e22e2ec":"X_os.info()","2e9544eb":"# FUNCION AUXILIAR; NO MODIFICAR, SOLO EJECUTAR\nimport matplotlib.pyplot as plt\n\ndef plot_feat1_feat2(feat1,feat2):\n    D = data[(data['output'] != 0)]\n    H = data[(data['output'] == 0)]    \n\n    plt.scatter(D[feat1], D[feat2], label='VF', alpha = 0.20)\n    plt.scatter(H[feat1], H[feat2], label='noVF', alpha = 0.20)\n\n    plt.title(feat1 +\" \"+\"vs\"+\" \"+feat2)\n    plt.xlabel(feat1)\n    plt.ylabel(feat2)\n\n    plt.legend() \n\n    plt.show()","36ee464d":"plot_feat1_feat2('mav','TCSC')","31ce7e3a":"plot_feat1_feat2('x3','TCSC')","00009749":"plot_feat1_feat2('mav','hilb')","62499cec":"plot_feat1_feat2('cvbin','abin')","70139e48":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split\n\nX = data.drop('output',axis=1)\ny = data['output']","48e4dbf3":"seed =   1999 #a\u00f1o de nacimiento\ntest_size =  0.2 #m\u00e1ximo 0.20\n\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state = seed , test_size = test_size,)\n","d8800458":"#Crear clasificador Regresi\u00f3n Log\u00edstica\n# Una l\u00ednea de c\u00f3digo\n#model_1 =  LogisticRegression(solver = 'liblinear')\nmodel_1 = LogisticRegression(C=1, class_weight='balanced', dual=False, fit_intercept=True,\n                   intercept_scaling=1, l1_ratio=None, max_iter=3000,\n                   multi_class='auto', n_jobs=None, penalty='l2',\n                   random_state=1234, solver='liblinear', tol=0.0001, verbose=1,\n                   warm_start=False)\n\n\n# Entrenar el clasificador con las los datos de entrenamiento y las feature\n# Una l\u00ednea de c\u00f3digo\nmodel_1.fit(X_train, y_train)\n","afa4d659":"# Aplicar classif.predict sobre los datos X de test (X_test)\n# Una l\u00ednea de c\u00f3digo\ny_pred = model_1.predict(X_test)\n","13aa17f6":"from sklearn.metrics import classification_report","a503871f":"def mostrar_resultados(y_test, y_pred):\n    \n  print (classification_report(y_test, y_pred))\n\nmostrar_resultados(y_test, y_pred)","544a609e":"from sklearn.metrics import confusion_matrix, plot_confusion_matrix\ndisp = plot_confusion_matrix(model_1, X_test, y_test,cmap=plt.cm.Blues,normalize = 'true')\n","036e3f19":"#----------------------------------------------------------------\n# Para mostrar el resultado de la predicci\u00f3n del clasificador\n# utiliza la siguiente funci\u00f3n auxiliar (NO MODIFICAR)\n\nfrom sklearn.metrics import f1_score\nfrom sklearn.metrics import mean_squared_error\n\ndef print_mse_f1(Y_Real, Y_Pred): \n    rmse = mean_squared_error(y_test, y_pred)\n    f1 = f1_score(y_test, y_pred, average='micro')\n    print('El Mean Squared Error (MSE) del modelo entrenado es:', rmse)\n    print('El F1 score del modelo entrenado es:', f1)\n","45782a9f":"print_mse_f1(y, y_pred)","f89734fe":"from sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.preprocessing import StandardScaler","a53624c5":"scaler = StandardScaler()\nscaler.fit(X)\nscaled_features = scaler.transform(X)\n\ndata2 = pd.DataFrame(scaled_features,columns=X.columns)\ndata2.head()","1b97e7a4":"X_train, X_test, y_train, y_test = train_test_split(X,y, random_state = seed , test_size = test_size,)","b40d22fd":"error_rate = []\n\nfor i in range(1,40):\n    \n    knn = KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train,y_train)\n    pred_i = knn.predict(X_test)\n    error_rate.append(np.mean(pred_i != y_test))","a3f99806":"plt.figure(figsize=(10,6))\nplt.plot(range(1,40),error_rate,color='blue', linestyle='dashed', marker='o',\n         markerfacecolor='red', markersize=10)\nplt.title('Error Rate vs. K Value')\nplt.xlabel('K')\nplt.ylabel('Error Rate');","74c62cff":"knn = KNeighborsClassifier(n_neighbors=13, weights = 'distance')","a9c67d47":"knn.fit(X_train,y_train)\ny_pred = knn.predict(X_test)\nprint(classification_report(y_test,y_pred))","dc6adbbe":"disp = plot_confusion_matrix(knn, X_test, y_test,cmap=plt.cm.Blues,normalize = 'true')","977c2d63":"print_mse_f1 (y,y_pred)","1b9740a4":"from sklearn.ensemble import GradientBoostingClassifier","96ebd91d":"gboost =  GradientBoostingClassifier(n_estimators=100, learning_rate=1.0, max_depth=1, random_state=seed)\n\ngboost.fit(X_train,y_train)\n\ny_pred = gboost.predict(X_test)\nprint(classification_report(y_test,y_pred))\n","12357d62":"disp = plot_confusion_matrix(gboost, X_test, y_test,cmap=plt.cm.Blues,normalize = 'true')","a18f51e2":"print_mse_f1(y, y_pred)","8df3c05f":"from sklearn.ensemble import RandomForestClassifier","5d787fac":"rf = RandomForestClassifier(n_estimators=500, max_depth = 10, max_features = None , random_state=1999, min_samples_leaf=50, min_samples_split=4,\n                             class_weight='balanced', criterion = 'entropy')\nrf.fit(X_train, y_train)\ny_pred = rf.predict(X_test)\nprint(classification_report(y_test,y_pred))","381d3a23":"disp = plot_confusion_matrix(rf, X_test, y_test,cmap=plt.cm.Blues,normalize = 'true')","84c336c2":"print_mse_f1(y, y_pred)","ae228e2e":"from xgboost import XGBClassifier \nfrom sklearn.metrics import accuracy_score","a2ef5df9":"eval_set = [(X_train, y_train),(X_test, y_test)]","6ce17507":"xgb = XGBClassifier(n_estimators=300, max_depth=40)\nxgb.fit(X_train, y_train, eval_set=eval_set)\ny_pred = xgb.predict(X_test)\nprint(classification_report(y_test,y_pred))","eab683d1":"disp = plot_confusion_matrix(xgb, X_test, y_test,cmap=plt.cm.Blues,normalize = 'true')","eb23e1fa":"print_mse_f1(y, y_pred)","6e79ca9f":"data_valid = pd.read_csv('data_ods_valid.csv')","695dbafe":"#################################\n#Funci\u00f3n auxiliar (NO MODIFICAR):\n#################################\n\ndef eval_best_model(final_model, name, dt_valid):\n    Id_key = pd.read_csv('Id_key.csv')\n\n    \n    X_valid = dt_valid  \n    y_valid_pred = final_model.predict(X_valid)\n    \n    submission = pd.DataFrame({ 'Id': Id_key['Id'],\n                                'output': y_valid_pred })\n    submission.to_csv('.\/submission_'+name+'.csv', index = False)\n    return(submission)","30df7f38":"#eval_best_model(nombre_modelo,'nombre equipo', data_valid)","8fe31831":"eval_best_model(model_1,'Roberto Moral', data_valid) # Score -> 0.98211","f02f98e2":"eval_best_model(knn,'Roberto Moral', data_valid) # Score -> 0.97955","bc02ae78":"eval_best_model(gboost,'Roberto Moral', data_valid) # Score -> 0.99425","342f6d1e":"eval_best_model(rf,'Roberto Moral', data_valid) # Score -> 0.98498","47bca4ff":"eval_best_model(xgb,'Roberto Moral', data_valid) # Score -> 0.99808","f64ff3b1":"### 2.1 Muestra los primeros valores del archivo para hacernos una idea del contenido de la tabla con el c\u00f3digo: data.head()","c6624e33":"El dataset tiene s\u00f3lo atributos **num\u00e9ricos**, de los cuales: 26 features son de tipo **float64** y 5 de tipo **int64**. No tiene valores nulos y la variable de salida (output) no est\u00e1 balanceada. Hay un 82% de 1's as\u00ed que ser\u00e1 necesario hacer pruebas con una mmuestra balanceada que se crear\u00e1 m\u00e1s adelante","b7e6e1c1":"\u00a1Enhorabuena! Ya has entrenado tu primer algoritmo de Machine Learning.  Ahora a comparar los resultados de tu modelo con los valores reales usando algunas de las m\u00e9tricas m\u00e1s comunes.  ","155afc06":"Uno de los primeros pasos que debe hacer un Data Scientist es analizar si existen o no relaciones entre las variables y la salida.\n\n-  \u00bfQue m\u00e9todo usar\u00edas para analizar esta relaci\u00f3n?\n-  \u00bfCu\u00e1l de estas variables de entrada est\u00e1 relacionada con la variable de salida **output**, y cu\u00e1l no?\n\n\n**c)** Crea una matriz de correlaci\u00f3n para analizar esta relaci\u00f3n entre las variables.\n\n**Ayuda:** puedes usar los siguientes m\u00e9todos:\n- .corr() \n- .style.background_gradient(cmap='coolwarm')\n\n","d64cb063":"**a)** Utiliza la funci\u00f3n .describe() para analizar la distribuci\u00f3n de los datos","982d2fc2":"\n\n## **3. Analizar dataset:**\n\n![Immune](https:\/\/i.imgur.com\/FBQ64Uz.png)\n\nPara entender la distribuci\u00f3n de los datos, vamos a observar:\n\n- La cantidad de datos (count)\n- La distribuci\u00f3n de los datos mediante cuartiles (25%,50%,75%)\n- Media de los datos (mean)\n- M\u00ednimos y m\u00e1ximos (min, max)\n- Varianza (std)\n- ...\n\n","6a3beb53":"Cuanto m\u00e1s cercano es el valor a 1 o -1, m\u00e1s correlaci\u00f3n (lineal) existe. \n\n- **d)** \u00bfCu\u00e1les son las variables (features) que m\u00e1s se relacionan con la salida (**output**)?","c33d73fd":"## **1. Importa las librer\u00edas necesarias**","e1c6b005":"### 2.2 Variable de salida\n\nLa variable que utilizaremos para clasificar los datos ser\u00e1 **output**. Donde:\n- **1** nos indica que el tratamiento **tiene una VF** \n- **0** nos indica que el tratamiento **no tiene una VF**  \n","8d1ffc2b":"Para cargar los datos, debes subirlos desde la carpeta que tienes en la esquina superior izquierda. Una vez guardados, los almacenaremos en un dataframe llamado **data** ","5cfce161":"Si deseas entender m\u00e1s sobre las m\u00e9tricas aplicadas a algoritmos de clasificaci\u00f3n, consulta el siguiente enlace: [m\u00e9tricas](https:\/\/www.iartificial.net\/precision-recall-f1-accuracy-en-clasificacion\/)\n","8e29c51d":"**5.2)** Utiliza la funci\u00f3n **print_mse_f1** con la predicci\u00f3n obtenida a partir del modelo entrenado para medir el error:","093c247d":"**Comentarios:**","9c4baa66":"**-------- Gradient Boost --------**","ffff1038":"Vamos ahora a descargar las herramientas necesar\u00edas para trabajar. \n\n**Nota:** Recuerda que para ejecutar cada celda (caja) tienes que usar **Shift+Enter**","345383d3":"**g)** Representa gr\u00e1ficamente la relaci\u00f3n entre otras variables que consideres hayan tenido una buena correlaci\u00f3n en la pregunta **c)**","c0c012a6":"**Comentarios:**","0533c568":"**5.1)** Crearemos una matriz de confusi\u00f3n para analizar las predicciones anteriores obtenidas de nuestro clasificador.","0ff20ae0":"**Ejemplo:** eval_best_model('nombre modelo','nombre equipo')","adc3898c":"Representaremos visualmente los datos de manera que:\n- Cada punto simbolice una persona.\n- Un punto naranja representa un paciente **sano** . Por otro lado, un punto azul representa un paciente con **VF**.\n- Los **ejes x** e **y** representan dos variables que queremos **comparar**.","f0d2fb67":" Las variables con m\u00e1s correlaci\u00f3n son estas nueve: TCSC, vfleak, A2, mav, SamEn, x3, x4, bCP, bWT.\n Y con ellas hemos creado un nuevo dataset y hecho oversampling para que los valores de la variable de salida (output) est\u00e9n balanceados.","1de02034":"### 3.1 Analizar las relaciones de las variables del *dataset*","0ce9bb7e":"Escribe ac\u00e1 toda la informaci\u00f3n que consideres relevante de la tabla anterior:\n\n","a06c9c3c":"**Comentarios:**","cd7560eb":"## **4. Clasificaci\u00f3n**\n\nEl clasificador es un algoritmo que nos va a permitir analizar un conjunto de datos y clasificarlos en grupos. \n\nEn Machine Learning se utiliza un clasificador para el an\u00e1lisis de datos en [aprendizaje supervisado](https:\/\/es.wikipedia.org\/wiki\/Aprendizaje_supervisado).\n\n![Clasificaci\u00f3n](https:\/\/static.javatpoint.com\/tutorial\/machine-learning\/images\/classification-algorithm-in-machine-learning.png)\n\n\n\n**Ejemplo**\n- Dado un conjunto de emails, determinar cu\u00e1l es spam y cu\u00e1l no.\n- Dado un conjunto de im\u00e1genes de animales, determinar cu\u00e1les son perros.\n\n**Objetivo**\n- En este reto, queremos lograr predecir o **clasificar** a que grupo de personas le funcionar\u00e1 el tratamiento, es decir queremos separar las personas con VF  (output=1) de las personas a las sanas (output=0). Es un ejercicio de **clasificaci\u00f3n**.\n- A continuaci\u00f3n puede visualizarse la diferencia entre \"clasificaci\u00f3n\" y \"regresi\u00f3n\"\n\n![Clasificaci\u00f3n vs regresi\u00f3n](https:\/\/res.cloudinary.com\/practicaldev\/image\/fetch\/s--c4Lfzdwy--\/c_limit%2Cf_auto%2Cfl_progressive%2Cq_auto%2Cw_880\/https:\/\/thepracticaldev.s3.amazonaws.com\/i\/mjshszqx4fj22hs12vfn.png)\n\n**Implementaci\u00f3n**\n- Crear un conjunto de datos de entrenamiento y un conjunto de datos de test\n- Crear un clasificador mediante un [tipo de algoritmo](https:\/\/www.javatpoint.com\/classification-algorithm-in-machine-learning): *RandomForest, XgBoost, KNN*\n\n- Entrenar el clasificador con los \"datos de entrenamiento\" y de las \"features\" que queremos tener en cuenta para el entrenamiento.\n- Predecir resultados mediante nuestro set de datos de test o mediante nuevos datos.\n- Determinar las conclusiones de los resultados obtenidos en las predicciones, como el % de acierto y precisi\u00f3n obtenida.\n\n\n","b2ab8afb":"**4.2)** Crea el clasificador y entr\u00e9nalo","70c95570":"**4.3)** Usa el modelo que acabas de entrenar en el conjunto de **X_test** para calcular el acierto del modelo:","33feb531":"**4.1)** Crea un conjunto de datos de entrenamiento y un conjunto de datos de test.\n\nIntrucciones: \n\n- **seed:** esta variable ser\u00e1 igual la suma de los a\u00f1os de nacimiento de los participantes. \n  Ejemplo: seed = 1992 + 2000+ 1995 + 1990 = 7977\n\n- **test_size:** no se permite usar m\u00e1s del 20% de datos para crear el test","0e9fe14d":"### 3.2 An\u00e1lisis descriptivo","c3da3834":"## **EVALUACI\u00d3N:**\nCuando termines el reto, utiliza la siguiente funci\u00f3n con el modelo que mejor predicci\u00f3n obtuviste. Los par\u00e1metros de entrada de la funci\u00f3n son:\n\n- Nombre del modelo que deseas entregar\n- Nombre tu equipo\n \n- Kaggle: https:\/\/www.kaggle.com\/t\/25aa5cdc0b4a48babd2e600dfe50de55\n","18c3ffe3":"# 5. Matriz de Confusi\u00f3n\n\nLa Matriz de Confusi\u00f3n es una m\u00e9trica que nos va a permitir conocer el rendimiento y acierto de una clasificaci\u00f3n realizada con Machine Learning.\nPodemos encontrar informaci\u00f3n adicional para entender su objectivo en el siguiente enlace: [ConfusionMatrix](https:\/\/towardsdatascience.com\/understanding-confusion-matrix-a9ad42dcfd62)\n \n![texto alternativo](https:\/\/miro.medium.com\/max\/578\/1*7EYylA6XlXSGBCF77j_rOA.png) ","aa3b3f71":"# 6. Mejorar predicci\u00f3n\n\n\u00bfCrees que puedes mejorar la predicci\u00f3n?\n\nPuedes intentar:\n\n- Optimizar los par\u00e1metros del clasificador\n- Prueba entrenar otro tipo de modelo de [clasificaci\u00f3n](https:\/\/www.javatpoint.com\/classification-algorithm-in-machine-learning): *RandomForest, XgBoost, KNN*","3c434f09":"**b)** Calcula el n\u00famero de personas con VF (**output=1**) y sin VF (**output=0**) que tenemos en la muestra (dataset):","caa8e5d0":"Intenta explicar que ocurre en la funci\u00f3n auxiliar aqu\u00ed:","2507d1e6":"\u00bfQu\u00e9 porcentaje de casos se situa en cada cuadrante? \u00bfEn medicina, es peor un false positive o un false negative? Comenta aqu\u00ed la matriz y responde a las preguntas:","1a51de0d":"## **2. Cargar el dataset**","c29136a3":"Ejemplo para representar informaci\u00f3n de \"2 columnas\" vs \"la que nos interesa predecir\"","8e36bf04":"#### Funci\u00f3n auxiliar para representar gr\u00e1ficas de valores del dataset","d9ed6852":"**-------- XGBoost --------**","1ad3a801":"**Comentarios:** ","eef3ae8f":"<center> <img src=https:\/\/i.imgur.com\/0TSSaqL.png width=\"800\"> <\/center>\n*\n<center> <h1> 3\u00ba Datat\u00f3n de Immune Institute<\/h1> <\/center>\n*\n \n\n**********  \n\n\n**Instrucciones:**\n- Se usar\u00e1 el lenguaje de programaci\u00f3n Python 3.\n- Se usar\u00e1n las librer\u00edas de python: Pandas, MatPlotLib, Numpy, Scikit-learn.\n\n**Mediante este ejercicio, aprenderemos:**\n- Entender y ejecutar Notebooks con Python.\n- Ser capaz de utilizar funciones de Python y librer\u00edas adicionales.\n- Dataset:\n - Obtener el dataset y previsualizar la informaci\u00f3n del dataset.\n - Representar y analizar la informaci\u00f3n del dataset.\n- Crear y entender el concepto de \"*Conjunto de datos de entrenamiento*\" y \"*Conjuntos de datos de test*\"\n- Crear y entender el concepto de \"*Clasificador*\" para analizar los datos,  predecir y obtener conclusiones.\n- Mejorar la predicci\u00f3n.\n\n\n\u00a1Comencemos!","69f61e71":"**-------- Random Forest --------**","dfee593f":"**-------- KNN --------**"}}