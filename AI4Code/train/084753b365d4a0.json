{"cell_type":{"9131a9e9":"code","ce731936":"code","469b8a7f":"code","1d0ff20b":"code","cec3bfe4":"code","a3e9acad":"code","d9d14bb0":"code","2369f382":"code","e7f2bc3b":"code","ff57b17f":"code","56eb085d":"code","23fb9d0c":"code","16901ccd":"code","8b9088d4":"code","96da6f55":"code","5d57c729":"code","337e6710":"code","b57075c8":"code","7908ffc3":"code","b76d634f":"code","3b21427c":"code","0661faf6":"code","01f6f152":"code","d3f40242":"code","2f3710e6":"code","94d00d37":"code","fdfafb8b":"code","a8fc7cab":"code","7dda7ade":"code","8c160a89":"code","0dcbd23d":"code","2c8fdd3a":"code","c2f16bb3":"code","ff48aa46":"code","b8bebed8":"code","4df300b8":"code","1db307e1":"code","5769f009":"code","e5cb12cc":"code","6aba35e8":"code","debdefab":"code","bb210340":"code","01183e56":"code","995d193f":"code","d453138a":"code","c8bf3e8c":"code","007fb66e":"code","9df93254":"code","d2a5b0ab":"code","43f19289":"code","ee9f1dcb":"code","7ff65e6a":"code","b368806d":"code","2a4ace4c":"code","51efa22c":"code","6683bdd6":"markdown","29d5ecdb":"markdown"},"source":{"9131a9e9":"# \u0418\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a\n\nfrom tensorflow.python.keras.models import Sequential\nfrom tensorflow.python.keras.layers import Dense\nfrom tensorflow.python.keras import utils\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom IPython.display import clear_output\nfrom sklearn import tree\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.metrics import precision_score, recall_score\nfrom sklearn.ensemble import RandomForestClassifier\nstyle = \"<style>svg{width:0.1% !important;height:0.1% !important;<\/style>\"\n\nimport pathlib\nimport numpy as np \nimport pandas as pd \nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\nfrom IPython.display import SVG\nfrom graphviz import Source\nfrom IPython.display import display\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \nfrom scipy import stats\nfrom scipy.stats import norm, skew\n\n%matplotlib inline \n\ntry:\n  # %tensorflow_version only exists in Colab.\n  %tensorflow_version 2.x\nexcept Exception:\n  pass\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nprint(tf.__version__)\n\ntf.random.set_seed(123)\n\n# Load the TensorBoard notebook extension.\n%load_ext tensorboard","ce731936":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\ndataTrain = pd.read_csv('..\/input\/titanic\/train.csv')\ndataTest = pd.read_csv('..\/input\/titanic\/test.csv')\ndataTrain.iloc[60:63]","469b8a7f":" dataTrain.shape[0], dataTest.shape[0]","1d0ff20b":"print (dataTrain.shape)\nprint (dataTest.shape)","cec3bfe4":"# \u0421\u043e\u0437\u0434\u0430\u043d\u0438\u0435 \u043a\u043e\u043f\u0438\u0438 \u0442\u0430\u0431\u043b\u0438\u0446 \u0434\u0430\u043d\u043d\u044b\u0445\ntestD = dataTest.copy()\ntrainD = dataTrain.copy()","a3e9acad":"# \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0430 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\ntrain_na = (trainD.isnull().sum() \/ len(trainD)) * 100\ntrain_na = train_na.drop(train_na[train_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :train_na})\nmissing_data.iloc[0:5]","d9d14bb0":"# \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0430 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\ntest_na = (testD.isnull().sum() \/ len(testD)) * 100\ntest_na = test_na.drop(test_na[test_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :test_na})\nmissing_data.iloc[0:5]","2369f382":"# \u0423\u0434\u0430\u043b\u044f\u0435\u043c \u043d\u0435\u043d\u0443\u0436\u043d\u044b\u0435 \u0441\u0442\u043e\u043b\u0431\u0446\u044b\ntrainD.drop([\"PassengerId\", \"Cabin\", \"Name\", \"Ticket\"], axis = 1, inplace = True)\ntestD.drop([\"PassengerId\",\"Cabin\", \"Name\", \"Ticket\"], axis = 1, inplace = True)\nprint (trainD.shape)\nprint (testD.shape)","e7f2bc3b":"# \u041e\u0431\u044a\u0435\u0434\u0438\u043d\u0435\u043d\u0438\u0435 \u0434\u0430\u043d\u043d\u044b\u0445\nallData = pd.concat((trainD, testD)).reset_index(drop=True)\nprint(\"allData size is : {}\".format(allData.shape))","ff57b17f":"sns.distplot(allData['Age'])","56eb085d":"# \u0417\u0430\u043f\u043e\u043b\u043d\u0435\u043d\u0438\u0435 \u043f\u0440\u043e\u043f\u0443\u0449\u0435\u043d\u043d\u044b\u0445 \u0445\u043d\u0430\u0447\u0435\u043d\u0438\u0439\nageMean = allData.Age.mean()\nallData['Embarked'] = allData['Embarked'].fillna(allData.Embarked.mode()[0])\nallData['Fare'] = allData['Fare'].fillna(allData.Fare.mean())\nallData['Age'].iloc[:300] = allData['Age'].iloc[:300].fillna(ageMean-2)\nallData['Age'].iloc[300:600] = allData['Age'].iloc[300:600].fillna(ageMean-1)\nallData['Age'].iloc[600:900] = allData['Age'].iloc[600:900].fillna(ageMean)\nallData['Age'].iloc[900:1200] = allData['Age'].iloc[900:1200].fillna(ageMean+1)\nallData['Age'].iloc[1200:] = allData['Age'].iloc[1200:].fillna(ageMean+2)\n#allData['Age'] = allData['Age'].fillna(allData.Age.mean())\nallData.iloc[60:63]","23fb9d0c":"# \u041f\u0440\u043e\u0432\u0435\u0440\u043a\u0430 \u043d\u0430 \u043e\u0442\u0441\u0443\u0442\u0441\u0442\u0432\u0443\u044e\u0449\u0438\u0435 \u0437\u043d\u0430\u0447\u0435\u043d\u0438\u044f\nallData_na = (allData.isnull().sum() \/ len(allData)) * 100\nallData_na = allData_na.drop(allData_na[allData_na == 0].index).sort_values(ascending=False)\nmissing_data = pd.DataFrame({'Missing Ratio' :allData_na})\nmissing_data.iloc[0:5]","16901ccd":"sns.distplot(allData['Age'])","8b9088d4":"sns.countplot(allData['Sex'])","96da6f55":"sns.countplot(allData['Pclass'])","5d57c729":"TD = trainD.copy()\nTD.drop([\"Survived\"], axis = 1, inplace = True)\nTT = trainD[\"Survived\"]\npd.concat([TD, TT], axis=1).groupby('Sex').Survived.mean().plot(kind='barh').set_xlabel('% survive')\nplt.show()","337e6710":"# \u041a\u0430\u0442\u0435\u0433\u043e\u0440\u0438\u0430\u043b\u044c\u043d\u0430\u044f \u0440\u0430\u0437\u0431\u0438\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\nallData = pd.get_dummies(allData)\nallData.iloc[0:5]","b57075c8":"# \u0420\u0430\u0437\u0431\u0438\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\ntrainValidInput = allData[:len(dataTrain)]\ntrainValidTarget = trainValidInput.pop('Survived')\ntest = allData[len(dataTrain):]\ntest.drop(['Survived'], axis=1, inplace=True)\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(trainValidInput, trainValidTarget, test_size = 0.33, random_state = 42)\nprint (X_train.shape, X_test.shape, y_train.shape, y_test.shape)","7908ffc3":"clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 20)\nclf.fit(X_train,y_train)","b76d634f":"clf.score(X_train,y_train)","3b21427c":"clf.score(X_test,y_test)","0661faf6":"scores_data = pd.DataFrame()\nfor max_depth in range(1, 20):\n    clf = tree.DecisionTreeClassifier(criterion='entropy', max_depth=max_depth)\n    clf.fit(X_train, y_train)\n    train_score = clf.score(X_train, y_train)\n    test_score = clf.score(X_test, y_test)\n    mean_cross_val_score = cross_val_score(clf, X_train, y_train, cv = 5).mean()\n    \n    temp_score_data = pd.DataFrame({'max_depth': [max_depth], 'train_score': [train_score], \n                                    'test_score': [test_score], 'cross_val_score': [mean_cross_val_score]})\n    scores_data = scores_data.append(temp_score_data)\nscores_data.head(3)","01f6f152":"scores_data_long = pd.melt(scores_data, id_vars = ['max_depth'], \n                           value_vars = ['train_score','test_score', 'cross_val_score'], var_name = 'set_type', value_name = 'score')\nscores_data_long.head(3)","d3f40242":"scores_data_long.query('set_type == \"cross_val_score\"').head(5) ","2f3710e6":"sns.lineplot(x='max_depth', y='score', hue='set_type', data = scores_data_long)","94d00d37":"clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 20)","fdfafb8b":"cross_val_score(clf, X_train, y_train, cv = 5).mean()","a8fc7cab":"cross_val_score(clf, X_test, y_test, cv = 5).mean()","7dda7ade":"clf = tree.DecisionTreeClassifier() \nparametrs = {'criterion': ['gini', 'entropy'], 'max_depth': range(1, 30)}\ngrid_search_cv_clf = GridSearchCV(clf, parametrs, cv = 5)","8c160a89":"grid_search_cv_clf.fit(X_train, y_train)","0dcbd23d":"grid_search_cv_clf.best_params_","2c8fdd3a":"best_clf = grid_search_cv_clf.best_estimator_\nbest_clf","c2f16bb3":"best_clf.score(X_test, y_test)","ff48aa46":"y_pred = best_clf.predict(X_test)\nprint (precision_score(y_test, y_pred), recall_score(y_test, y_pred))","b8bebed8":"y_pred","4df300b8":"y_predicted_prob = best_clf.predict_proba(X_test)\npd.Series(y_predicted_prob[:,1]).hist()","1db307e1":"y_pred = np.where(y_predicted_prob[:, 1] > 0.8, 1, 0)\nprint (precision_score(y_test, y_pred), recall_score(y_test, y_pred))","5769f009":"from sklearn.metrics import roc_curve, auc\nfpr, tpr, thresholds = roc_curve(y_test, y_predicted_prob[:,1])\nroc_auc= auc(fpr, tpr)\nplt.figure()\nplt.plot(fpr, tpr, color = 'darkorange', label = 'ROC curve (area = %0.2f)' % roc_auc)\nplt.plot([0, 1], [0, 1], color='navy', linestyle='--')\nplt.xlim([0.0, 1.0])\nplt.ylim([0.0, 1.05])\nplt.xlabel('False Positive Rate')\nplt.ylabel('True Positive Rate')\nplt.title('Receiver operating characteristic example')\nplt.legend(loc = \"lower right\")\nplt.show()","e5cb12cc":"clf = tree.DecisionTreeClassifier(criterion = 'entropy', max_depth = 3, min_samples_split = 100, min_samples_leaf = 10)\nclf.fit(X_train,y_train)","6aba35e8":"graph = Source(tree.export_graphviz(clf, out_file=None,\n                                   feature_names=list(X_train),\n                                   class_names=['Died', 'Survived'],\n                                   filled = True))\ndisplay(SVG(graph.pipe(format='svg')))","debdefab":"clf_rf = RandomForestClassifier()\nparametrs = {'n_estimators': [10,20,30], 'max_depth': [2,5,7,10]}\ngrid_search_cv_clf = GridSearchCV(clf_rf, parametrs, cv=5)\ngrid_search_cv_clf.fit(X_train, y_train)\ngrid_search_cv_clf.best_params_","bb210340":"best_model = grid_search_cv_clf.best_estimator_\nbest_model.score(X_test, y_test)","01183e56":"feature_importances = best_clf.feature_importances_\nfeature_importances_df = pd.DataFrame({'features':list(X_train.columns), \n                                       'feature_importances':  best_clf.feature_importances_})\\\n                        .sort_values(by='feature_importances')\nfeature_importances_df","995d193f":"# \u0420\u0430\u0437\u0431\u0438\u0432\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445\ntrain = allData[:len(dataTrain)]\ntrainTarget = train.pop('Survived')\nX_train, X_test, y_train, y_test = train_test_split(trainValidInput, trainValidTarget, test_size = 0.33, random_state = 42)","d453138a":"X_train.head(3)","c8bf3e8c":"feature_columns = []\nfor feature_name in train.columns.tolist() :\n    feature_columns.append(tf.feature_column.numeric_column(feature_name,dtype=tf.float32))","007fb66e":"# Use entire batch since this is such a small dataset.\nNUM_EXAMPLES = len(y_train)\n\ndef make_input_fn(X, y, n_epochs=None, shuffle=True):\n    def input_fn():\n        dataset = tf.data.Dataset.from_tensor_slices((dict(X), y))\n        if shuffle:\n            dataset = dataset.shuffle(NUM_EXAMPLES)\n        # For training, cycle thru dataset as many times as need (n_epochs=None).    \n        dataset = dataset.repeat(n_epochs)\n        # In memory training doesn't use batching.\n        dataset = dataset.batch(NUM_EXAMPLES)\n        return dataset\n    return input_fn\n\n# Training and evaluation input functions.\ntrain_input_fn = make_input_fn(X_train, y_train)\neval_input_fn = make_input_fn(X_test, y_test, shuffle=False, n_epochs=1)","9df93254":"linear_est = tf.estimator.LinearClassifier(feature_columns)\n# Train model.\nlinear_est.train(train_input_fn, max_steps=100)\n# Evaluation.\nresult = linear_est.evaluate(eval_input_fn)\nprint(pd.Series(result))","d2a5b0ab":"n_batches = 1\nest = tf.estimator.BoostedTreesClassifier(feature_columns,\n                                          n_batches_per_layer=n_batches)\nest.train(train_input_fn, max_steps=100)\nresult = est.evaluate(eval_input_fn)\nprint(pd.Series(result))","43f19289":"pred_dicts = list(est.predict(eval_input_fn))\nprobs = pd.Series([pred['probabilities'][1] for pred in pred_dicts])\n\nprobs.plot(kind='hist', bins=20, title='predicted probabilities')\nplt.show()","ee9f1dcb":"from sklearn.metrics import roc_curve\n\nfpr, tpr, _ = roc_curve(y_test, probs)\nplt.plot(fpr, tpr)\nplt.title('ROC curve')\nplt.xlabel('false positive rate')\nplt.ylabel('true positive rate')\nplt.xlim(0,)\nplt.ylim(0,)\nplt.show()","7ff65e6a":"test_input_fn = make_input_fn(test, test.index, shuffle=False, n_epochs=1)","b368806d":"preds = est.predict(test_input_fn)","2a4ace4c":"preds = [pred['class_ids'][0] for pred in preds]\npd.DataFrame({'PassengerId': dataTest.PassengerId, 'Survived': preds}).to_csv('submission.csv', index=False)\n!head submission.csv","51efa22c":"pd.DataFrame(preds)","6683bdd6":"# \u0417\u0430\u0433\u0440\u0443\u0437\u043a\u0430 \u0438 \u043e\u0431\u0440\u0430\u0431\u043e\u0442\u043a\u0430 \u0434\u0430\u043d\u043d\u044b\u0445","29d5ecdb":"# \u0418\u043c\u043f\u043e\u0440\u0442 \u0431\u0438\u0431\u043b\u0438\u043e\u0442\u0435\u043a"}}