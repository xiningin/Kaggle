{"cell_type":{"2e20dfe6":"code","16836a7d":"code","6cfb283e":"code","21bccb1d":"code","5626023c":"code","56f759e9":"code","e6671a3f":"code","f7729383":"code","be4b5371":"code","75128b6d":"markdown"},"source":{"2e20dfe6":"import os\nimport numpy as np\nimport pandas as pd \nimport random\nimport cv2\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\nimport keras.backend as K\nfrom keras.models import Model, Sequential\nfrom keras.layers import Input, Dense, Flatten, Dropout, BatchNormalization\nfrom keras.layers import Conv2D, SeparableConv2D, MaxPool2D, LeakyReLU, Activation\nfrom keras.optimizers import Adam\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\nimport tensorflow as tf\n\nseed = 42\nnp.random.seed(seed)\ntf.random.set_seed(seed)","16836a7d":"input_path = '..\/input\/pneumonia-data\/chest_xray\/chest_xray\/'\n\nfig, ax = plt.subplots(2, 3, figsize=(15, 7))\nax = ax.ravel()\nplt.tight_layout()\n\nfor i, _set in enumerate(['train', 'val', 'test']):\n    set_path = input_path+_set\n    ax[i].axis('off')\n    ax[i].imshow(plt.imread(set_path+'\/NORMAL\/'+os.listdir(set_path+'\/NORMAL')[0]), cmap='gray')\n    ax[i].set_title('Set: {}, Condition: Normal'.format(_set))\n    ax[i+3].imshow(plt.imread(set_path+'\/PNEUMONIA\/'+os.listdir(set_path+'\/PNEUMONIA')[0]), cmap='gray')\n    ax[i+3].set_title('Set: {}, Condition: Pneumonia'.format(_set))","6cfb283e":"for _set in ['train', 'val', 'test']:\n    n_normal = len(os.listdir(input_path + _set + '\/NORMAL'))\n    n_infect = len(os.listdir(input_path + _set + '\/PNEUMONIA'))\n    print('Set: {}, normal images: {}, pneumonia images: {}'.format(_set, n_normal, n_infect))","21bccb1d":"def process_data(img_dims, batch_size):\n    # Data generation objects\n    train_datagen = ImageDataGenerator(rescale=1.\/255, zoom_range=0.3, vertical_flip=True)\n    test_val_datagen = ImageDataGenerator(rescale=1.\/255)\n    \n    # This is fed to the network in the specified batch sizes and image dimensions\n    train_gen = train_datagen.flow_from_directory(\n    directory=input_path+'train', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n\n    test_gen = test_val_datagen.flow_from_directory(\n    directory=input_path+'test', \n    target_size=(img_dims, img_dims), \n    batch_size=batch_size, \n    class_mode='binary', \n    shuffle=True)\n    \n    # I will be making predictions off of the test set in one batch size\n    # This is useful to be able to get the confusion matrix\n    test_data = []\n    test_labels = []\n\n    for cond in ['\/NORMAL\/', '\/PNEUMONIA\/']:\n        for img in (os.listdir(input_path + 'test' + cond)):\n            img = plt.imread(input_path+'test'+cond+img)\n            img = cv2.resize(img, (img_dims, img_dims))\n            img = np.dstack([img, img, img])\n            img = img.astype('float32') \/ 255\n            if cond=='\/NORMAL\/':\n                label = 0\n            elif cond=='\/PNEUMONIA\/':\n                label = 1\n            test_data.append(img)\n            test_labels.append(label)\n        \n    test_data = np.array(test_data)\n    test_labels = np.array(test_labels)\n    \n    return train_gen, test_gen, test_data, test_labels","5626023c":"img_dims = 150\nepochs = 50\nbatch_size = 32\n\ntrain_gen, test_gen, test_data, test_labels = process_data(img_dims, batch_size)","56f759e9":"inputs = Input(shape=(img_dims, img_dims, 3))\n\n# First conv block\nx = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(inputs)\nx = Conv2D(filters=16, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Second conv block\nx = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=32, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Third conv block\nx = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=64, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\n\n# Fourth conv block\nx = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=128, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = Dropout(rate=0.2)(x)\n\n# Fifth conv block\nx = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = SeparableConv2D(filters=256, kernel_size=(3, 3), activation='relu', padding='same')(x)\nx = BatchNormalization()(x)\nx = MaxPool2D(pool_size=(2, 2))(x)\nx = Dropout(rate=0.2)(x)\n\n# FC layer\nx = Flatten()(x)\nx = Dense(units=512, activation='relu')(x)\nx = Dropout(rate=0.7)(x)\nx = Dense(units=128, activation='relu')(x)\nx = Dropout(rate=0.5)(x)\nx = Dense(units=64, activation='relu')(x)\nx = Dropout(rate=0.3)(x)\n\n# Output layer\noutput = Dense(units=1, activation='sigmoid')(x)\n\n# Creating model and compiling\nmodel = Model(inputs=inputs, outputs=output)\nmodel.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n\n# Callbacks\ncheckpoint = ModelCheckpoint(filepath='.\/best_weights.hdf5', save_best_only=True, save_weights_only=True)\nlr_reduce = ReduceLROnPlateau(monitor='val_loss', factor=0.3, patience=5, verbose=2, mode='max')\nearly_stop = EarlyStopping(monitor='val_loss', min_delta=0.1, patience=10, mode='min')","e6671a3f":"hist = model.fit(\n           train_gen, steps_per_epoch=train_gen.samples \/\/ batch_size, \n           epochs=epochs, validation_data=test_gen, \n           validation_steps=test_gen.samples \/\/ batch_size, callbacks=[checkpoint, lr_reduce])","f7729383":"fig, ax = plt.subplots(1, 2, figsize=(20, 5))\nax = ax.ravel()\n\nfor i, met in enumerate(['accuracy', 'loss']):\n    ax[i].plot(hist.history[met])\n    ax[i].plot(hist.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].grid()\n    ax[i].legend(['train', 'val'])","be4b5371":"from sklearn.metrics import accuracy_score, confusion_matrix\n\npreds = model.predict(test_data)\n\nacc = accuracy_score(test_labels, np.round(preds))*100\ncm = confusion_matrix(test_labels, np.round(preds))\ntn, fp, fn, tp = cm.ravel()\n\nprint('CONFUSION MATRIX ------------------')\nprint(cm)\n\nprint('\\nTEST METRICS ----------------------')\nprecision = tp\/(tp+fp)*100\nrecall = tp\/(tp+fn)*100\nprint('Accuracy:  {}%'.format(round(acc,2)))\nprint('Precision: {}%'.format(round(precision,2)))\nprint('Recall:    {}%'.format(round(recall,2)))\nprint('F1-score:  {}%'.format(round((2*precision*recall\/(precision+recall)),2)))\n\nprint('\\nTRAIN METRIC ----------------------')\nprint('Train acc: {}%'.format(np.round((hist.history['accuracy'][-1])*100, 2)))","75128b6d":"Pneumonia is an infectious and fatal respiratory disease caused by bacteria, fungi, or a virus that infects human lung air sacs with a load full of fluid or pus.\n\n\nChest x-rays are the common method used to diagnose pneumonia and it takes a medical expert to assess the result of the x-ray. The troublesome method of detecting pneumonia leads to loss of life due to improper diagnosis and treatment.\n\nWith the emerging computing power, the development of an automatic pneumonia detection and disease treatment system is now possible, especially if the patient is in a remote area and medical services are limited."}}