{"cell_type":{"a364d74a":"code","52c54fc3":"code","f7fa5437":"code","241cce33":"code","0aca781c":"code","b0987b52":"code","e6b29095":"code","ac0e4b3c":"code","6a76e8b6":"code","a119d220":"code","cf0741e4":"markdown","e73dafe2":"markdown","dc7e0c0a":"markdown","99cd577c":"markdown","9153a1df":"markdown","5cf30301":"markdown","f737d568":"markdown","efeb0794":"markdown","fe79003c":"markdown","287ccfa7":"markdown","a5726e5e":"markdown","2af0d24b":"markdown","5e5f5600":"markdown","4a0a7006":"markdown","2ba30044":"markdown","51b03ab1":"markdown","e0c58552":"markdown","25d5b7d6":"markdown","956e8627":"markdown","0fbc5542":"markdown","bfa5df15":"markdown","b3304623":"markdown","e50e9d94":"markdown","e7848753":"markdown","07097d8f":"markdown"},"source":{"a364d74a":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport plotly.express as px\nimport plotly.graph_objs as go\nimport plotly.figure_factory as ff","52c54fc3":"plays = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/plays.csv\")\ncoverage_preds = pd.read_csv(\"..\/input\/nflcoveragepredictions\/coverage_preds.csv\")\n\nall_dbs = pd.read_csv(\"..\/input\/nflbdbtopplayers\/all_dbs.csv\")\nall_lbs = pd.read_csv(\"..\/input\/nflbdbtopplayers\/all_lbs.csv\")\nall_top = pd.read_csv(\"..\/input\/nflbdbtopplayers\/all_top.csv\")","f7fa5437":"# Bar Chart for KMeans\nx = ['Zone', 'Man']\ny = coverage_preds['kmeans'].value_counts().tolist()\n\nfig = go.Figure(data=[go.Bar(x = x, y = y, hovertext=['Zone Coverage', 'Man Coverage'])])\n\nfig.update_traces(marker_color='rgb(255, 84, 0)', marker_line_color='rgb(20, 21, 25)', marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title_text='Zone Coverage vs Man Coverage [K-Means]')\nfig.show()","241cce33":"# Bar Chart\nx = ['Zone', 'Man']\ny = coverage_preds['mini_kmeans'].value_counts().tolist()\n\nfig = go.Figure(data=[go.Bar(x = x, y = y,\n            hovertext=['Zone Coverage', 'Man Coverage'])])\n\nfig.update_traces(marker_color='rgb(0, 51, 255)', marker_line_color='rgb(20, 21, 25)',\n                  marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title_text='Zone Coverage vs Man Coverage [Mini Batch K-Means]')\nfig.show()","0aca781c":"# Bar Chart\nx = ['Zone', 'Man']\ny = coverage_preds['gmm'].value_counts().tolist()\n\nfig = go.Figure(data=[go.Bar(x = x, y = y,\n            hovertext=['Zone Coverage', 'Man Coverage'])])\n\nfig.update_traces(marker_color='rgb(191, 51, 255)', marker_line_color='rgb(20, 21, 25)',\n                  marker_line_width=1.5, opacity=0.6)\nfig.update_layout(title_text='Zone Coverage vs Man Coverage [Gaussian Mixture Models]')\nfig.show()","b0987b52":"all_top['age'] = all_top['age'].round(1)\nall_top.head(20)","e6b29095":"all_dbs['age'] = all_dbs['age'].round(1)\nall_dbs.rename(columns={'ints':'interceptions'}, inplace=True)\nall_dbs.head(20)","ac0e4b3c":"all_lbs = all_lbs.drop(['ints'], axis=1)\nall_lbs['age'] = all_lbs['age'].round(1)\nall_lbs.head(20)","6a76e8b6":"# ### FOR DEFENSIVE PERFORMANCE BY EVENTS\n# #######################################\n\n# plays = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/plays.csv\")\n# players = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/players.csv\")\n\n# # First, make a list of smaller player names\n# player_names = list(players['displayName'].tolist())\n\n# short_player_names = []\n\n# for i, _ in enumerate(player_names):\n#     short_player_names.append(player_names[i].split()[0][0] + \".\" + player_names[i].split()[1])\n\n# players['displayName'] = short_player_names\n\n# def add_dict_entry(dct, entry, other=None):\n#     \"\"\"\n#     Check if a player is already in the dictionary, if not then add it, if it is, then increment it's value\n#     \"\"\"\n#     if entry in dct:\n#         if not other:\n#             dct[entry] += 1\n#         else:\n#             dct[entry] += other\n#     else:\n#         if not other:\n#             dct[entry] = 1\n#         else:\n#             dct[entry] = other\n#     return dct\n\n# # Now let's parse through the description and get the important data\n# player_intercepted = {}\n# player_fumbles = {}\n# player_incomplete = {}\n# player_sacked = {}\n\n# # Add a custom progress bar to track the progress\n# prog_bar = tqdm(plays['playDescription'], total=len(plays))\n# for desc in prog_bar:\n#     # Deal with INTERCEPTIONS\n#     if \"INTERCEPTED\" in desc:\n#         # The Index of player name is exactly 2 indexes away from the \"INTERCEPTED\" marker\n#         split_desc = desc.split()\n#         name_idx = split_desc.index(\"INTERCEPTED\") + 2\n#         # Add the entry to the intercepted dict\n#         player_intercepted = add_dict_entry(player_intercepted, str(split_desc[name_idx]))\n    \n#     # Deal with FUMBLES\n#     elif \"FUMBLES\" in desc:\n#         if \"FUMBLES,\" in desc:\n#             continue\n#         # The Index of the player who did fumble is just the next one but it's in parenthesis (remove it)\n#         split_desc = desc.split()\n#         name_idx = split_desc.index(\"FUMBLES\") + 1\n#         name = str(split_desc[name_idx][1:-2])\n#         # Add the entry into the fumbles dict\n#         player_fumbles = add_dict_entry(player_fumbles, name)\n    \n#     # Deal with Sacks\n#     elif \"sack\" in desc:\n#         # Split the current description\n#         split = desc.split()\n#         # Set a flag; when \"sack*\" passes, it will be true\n#         flag = False\n#         # Go through all elements of current description\n#         for j, _ in enumerate(split):\n#             prev_item = split[j-1]\n#             current_item = split[j]\n            \n#             # If it's sack, make the flag true\n#             if \"sack\" in current_item:\n#                 flag = True\n            \n#             # If the current word is \"yard*\" and the flag is True (sack* has passed)\n#             # Then get the -ve yardage number (which should be the previous item now) and add into dict\n#             if current_item == \"yards\" or current_item == \"yard\":\n#                 if flag is not True:\n#                     continue\n#                 else:\n#                     try:\n#                         # numb = int(prev_item)\n#                         name = str(split[j+1][1:-2])\n#                         player_sacked = add_dict_entry(player_sacked, name)\n#                     except:\n#                         continue\n\n# # Convert the dictionaries into dataframes, one by one\n# int_players, int_scores = [], []\n# for info in list(player_intercepted.items()):\n#     int_players.append(info[0])\n#     int_scores.append(info[1])\n\n# fum_players, fum_scores = [], []\n# for info in list(player_fumbles.items()):\n#     fum_players.append(info[0])\n#     fum_scores.append(info[1])\n\n# sac_players, sac_scores = [], []\n# for info in list(player_sacked.items()):\n#     sac_players.append(info[0])\n#     sac_scores.append(info[1])\n    \n# intercepted = pd.DataFrame()\n# intercepted['player'] = int_players\n# intercepted['score'] = int_scores\n\n# fumbles = pd.DataFrame()\n# fumbles['player'] = fum_players\n# fumbles['score'] = fum_scores\n\n# sacks = pd.DataFrame()\n# sacks['player'] = sac_players\n# sacks['score'] = sac_scores\n\n# fumbles = fumbles.drop([0]).reset_index(drop=True)\n# sacks = sacks.drop([2]).reset_index(drop=True)\n\n# short_player_names = []\n\n# for i, _ in enumerate(player_names):\n#     short_player_names.append(player_names[i].split()[0][0] + \".\" + player_names[i].split()[1])\n\n# players['displayName'] = short_player_names\n\n# all_pos = ['CB', 'SS', 'FS', 'DB', 'MLB', 'LB', 'OLB', 'ILB', 'S']\n# lbs = ['MLB', 'LB', 'OLB', 'ILB']\n# dbs = ['CB', 'SS', 'FS', 'DB', 'S']\n# all_df = players.loc[players['position'].isin(all_pos)]\n# lbs_df = players.loc[players['position'].isin(lbs)]\n# dbs_df = players.loc[players['position'].isin(dbs)]\n\n# # Player Matching Algorithm that I am trynna make\n# # We first make a big dataframe consisting of players and their scores in fumbles, interceptions and sacks, all in one place.\n# all_scores = pd.DataFrame()\n\n# in_score, in_player = [], []\n# fu_score, fu_player = [], []\n# sa_score, sa_player = [], []\n\n# prog_bar = tqdm(sacks.iterrows(), total=len(sacks))\n\n# for x in prog_bar:\n#     match_fu = False\n#     match_in = False\n    \n#     sa_score.append(x[1]['score'])\n#     sa_player.append(x[1]['player'])\n    \n#     for y in fumbles.iterrows():\n#         if str(x[1]['player']) == str(y[1]['player']):\n#             match_fu = True\n#             fu_score.append(y[1]['score'])\n#             fu_player.append(y[1]['player'])\n    \n#     if match_fu == False:\n#         fu_score.append(0)\n#         fu_player.append(str(x[1]['player']))\n    \n#     for z in intercepted.iterrows():\n#         if str(x[1]['player']) == str(z[1]['player']):\n#             match_in = True\n#             in_score.append(z[1]['score'])\n#             in_player.append(z[1]['player'])\n    \n#     if match_in == False:\n#         in_score.append(0)\n#         in_player.append(str(x[1]['player']))\n        \n# all_scores['player'] = sa_player\n# all_scores['interception'] = in_score\n# all_scores['fumbles'] = fu_score\n# all_scores['sacks'] = sa_score\n\n# def change_height(string):\n#     \"\"\"\n#     string: '6-2', etc\n#     \"\"\"\n#     if \"-\" in string:\n#         string = int(string[0])*12 + int(string[-1])\n#         return string\n#     else:\n#         return int(string)\n    \n# def calc_age(days):\n#     days = str(days)\n#     return int(days[:-14]) \/ (365)\n\n# all_df = all_df.drop_duplicates()\n# lbs_df = lbs_df.drop_duplicates()\n# dbs_df = dbs_df.drop_duplicates()\n\n# all_df['height'] = all_df['height'].apply(change_height)\n# all_df['birthDate'] = pd.to_datetime(all_df['birthDate'])\n# all_df['current_date'] = pd.to_datetime(\"2021-01-06\")\n# all_df['age_days'] = all_df['current_date'] - all_df['birthDate']\n# all_df['age'] = all_df['age_days'].apply(calc_age)\n\n# lbs_df['height'] = lbs_df['height'].apply(change_height)\n# lbs_df['birthDate'] = pd.to_datetime(lbs_df['birthDate'])\n# lbs_df['current_date'] = pd.to_datetime(\"2021-01-06\")\n# lbs_df['age_days'] = lbs_df['current_date'] - lbs_df['birthDate']\n# lbs_df['age'] = lbs_df['age_days'].apply(calc_age)\n\n# dbs_df['height'] = dbs_df['height'].apply(change_height)\n# dbs_df['birthDate'] = pd.to_datetime(dbs_df['birthDate'])\n# dbs_df['current_date'] = pd.to_datetime(\"2021-01-06\")\n# dbs_df['age_days'] = dbs_df['current_date'] - dbs_df['birthDate']\n# dbs_df['age'] = dbs_df['age_days'].apply(calc_age)\n\n# all_df_new = all_df.drop(['birthDate', 'collegeName', 'nflId', 'current_date', 'age_days', 'position'], axis=1)\n\n# lbs_df_new = lbs_df.drop(['birthDate', 'collegeName', 'nflId', 'current_date', 'age_days', 'position'], axis=1)\n\n# dbs_df_new = dbs_df.drop(['birthDate', 'collegeName', 'nflId', 'current_date', 'age_days', 'position'], axis=1)\n\n# # Quick Algo for player matching - LBs\n# players_h = []\n# players_w = []\n# players_a = []\n# names = []\n# interceptions = []\n# fumbles = []\n# sacks = []\n\n# prog_bar = tqdm(all_scores.iterrows(), total=len(all_scores))\n# for player_2 in prog_bar:\n#     for player in lbs_df_new.iterrows():\n#         if str(player[1]['displayName']) == str(player_2[1]['player']):\n#             players_h.append(player[1]['height'])\n#             players_w.append(player[1]['weight'])\n#             players_a.append(player[1]['age'])\n            \n#             names.append(str(player_2[1]['player']))\n#             interceptions.append(player_2[1]['interception'])\n#             fumbles.append(player_2[1]['fumbles'])\n#             sacks.append(player_2[1]['sacks'])\n\n# final_df_lbs = pd.DataFrame()\n# final_df_lbs['name'] = names\n# final_df_lbs['age'] = players_a\n# final_df_lbs['weight'] = players_w\n# final_df_lbs['height'] = players_h\n# final_df_lbs['ints'] = interceptions\n# final_df_lbs['fums'] = fumbles\n# final_df_lbs['sack'] = sacks\n\n# # Quick Algo for player matching - DBs\n# players_h = []\n# players_w = []\n# players_a = []\n# names = []\n# interceptions = []\n# fumbles = []\n# sacks = []\n\n# prog_bar = tqdm(all_scores.iterrows(), total=len(all_scores))\n# for player_2 in prog_bar:\n#     for player in dbs_df_new.iterrows():\n#         if str(player[1]['displayName']) == str(player_2[1]['player']):\n#             players_h.append(player[1]['height'])\n#             players_w.append(player[1]['weight'])\n#             players_a.append(player[1]['age'])\n            \n#             names.append(str(player_2[1]['player']))\n#             interceptions.append(player_2[1]['interception'])\n#             fumbles.append(player_2[1]['fumbles'])\n#             sacks.append(player_2[1]['sacks'])\n\n# final_df_db = pd.DataFrame()\n# final_df_db['name'] = names\n# final_df_db['age'] = players_a\n# final_df_db['weight'] = players_w\n# final_df_db['height'] = players_h\n# final_df_db['ints'] = interceptions\n# final_df_db['fums'] = fumbles\n# final_df_db['sack'] = sacks\n\n# # Quick Algo for player matching - DBs\n# players_h = []\n# players_w = []\n# players_a = []\n# names = []\n# interceptions = []\n# fumbles = []\n# sacks = []\n\n# prog_bar = tqdm(all_scores.iterrows(), total=len(all_scores))\n# for player_2 in prog_bar:\n#     for player in all_df_new.iterrows():\n#         if str(player[1]['displayName']) == str(player_2[1]['player']):\n#             players_h.append(player[1]['height'])\n#             players_w.append(player[1]['weight'])\n#             players_a.append(player[1]['age'])\n            \n#             names.append(str(player_2[1]['player']))\n#             interceptions.append(player_2[1]['interception'])\n#             fumbles.append(player_2[1]['fumbles'])\n#             sacks.append(player_2[1]['sacks'])\n\n# final_df_all = pd.DataFrame()\n# final_df_all['name'] = names\n# final_df_all['age'] = players_a\n# final_df_all['weight'] = players_w\n# final_df_all['height'] = players_h\n# final_df_all['ints'] = interceptions\n# final_df_all['fums'] = fumbles\n# final_df_all['sack'] = sacks\n\n# # Ranking all 3 types (ALL, LBs, DBs) by score\n# # For ALL and LBs -> Total Score; For DBs -> Interceptions only\n\n# # For All\n# final_new_all = final_df_all.copy(deep=True)\n# final_new_all = final_df_all.drop(['fums', 'sack'], axis=1)\n# total_score = []\n# for x in final_df_all.iterrows():\n#     total_score.append(x[1]['ints'] + x[1]['fums'] + x[1]['sack'])\n# final_new_all['score'] = total_score\n\n# # For LBs\n# final_new_lb = final_df_lbs.copy(deep=True)\n# final_new_lb = final_df_lbs.drop(['fums', 'sack'], axis=1)\n# total_score = []\n# for x in final_df_lbs.iterrows():\n#     total_score.append(x[1]['ints'] + x[1]['fums'] + x[1]['sack'])\n# final_new_lb['score'] = total_score\n    \n# # For DBs\n# final_new_db = final_df_db.copy(deep=True)\n# final_new_db = final_new_db.drop(['fums', 'sack'], axis=1)\n\n# # Store the rankings in different csvs\n# all_top_players = final_new_all.sort_values(by='score', ascending=False).head(20).reset_index(drop=True)\n# lbs_top_players = final_new_lb.sort_values(by='score', ascending=False).head(20).reset_index(drop=True)\n# dbs_top_players = final_new_db.sort_values(by='ints', ascending=False).head(20).reset_index(drop=True)\n\n# all_top_players.to_csv(\"all_top.csv\", index=None)\n# lbs_top_players.to_csv(\"all_lbs.csv\", index=None)\n# dbs_top_players.to_csv(\"all_dbs.csv\", index=None)","a119d220":"# ### FOR DEFENSIVE COVERAGE SCHEME PREDICTION\n# ############################################\n\n\n# from sklearn.cluster import KMeans, MiniBatchKMeans\n# from sklearn.mixture import GaussianMixture\n\n# plays = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/plays.csv\")\n# modified_week = pd.read_csv(\"..\/input\/nfl-2021-modified-data\/week_modified_processed.csv\")\n# players = pd.read_csv(\"..\/input\/nfl-big-data-bowl-2021\/players.csv\")\n\n# # Choose features for Unsupervised Learning\n# # Using Secondary defensive backs\n# df_backs = ['CB', 'SS', 'FS', 'DB', 'S']\n# all_pos = ['CB', 'SS', 'FS', 'DB', 'MLB', 'LB', 'OLB', 'ILB', 'S']\n\n# train_data = modified_week.loc[modified_week['position'].isin(all_pos)]\n# train_data = train_data[train_data.columns[30:].tolist()]\n# train_data = train_data.reset_index(drop=True)\n\n# # Before modelling, let's drop NaN and duplicate values\n# train_data = train_data.dropna()\n# train_data = train_data.drop_duplicates()\n# train_data = train_data.reset_index(drop=True)\n\n# # And also do Standardization on the training data\n# train_data_scaled = (train_data - train_data.mean()) \/ (train_data.std())\n# train_data_scaled.head()\n\n# # First Let's try KMeans Clustering on Scaled Training Data\n# kmeans = KMeans(n_clusters=2)\n# kmeans.fit(train_data_scaled)\n\n# # Get the Predictions on Training Data\n# kmeans_preds = kmeans.predict(train_data_scaled)\n# train_data['kmean_cluster'] = kmeans_preds.tolist()\n\n# ones = train_data[train_data['kmean_cluster'].astype(int) == 1]\n# zeros = train_data[train_data['kmean_cluster'].astype(int) == 0]\n\n# # Make a new dataframe with the predictions\n# coverage_predictions = pd.DataFrame()\n# coverage_predictions['kmeans'] = kmeans_preds.tolist()\n\n# # Mini Batch KMeans on training data\n# mini_kmeans = MiniBatchKMeans(n_clusters=2)\n# mini_kmeans.fit(train_data_scaled)\n\n# # Get the Predictions on the training data\n# mini_kmeans_pred = mini_kmeans.predict(train_data_scaled)\n\n# # Add these predictions into the dataframe too\n# coverage_predictions['mini_kmeans'] = mini_kmeans_pred.tolist()\n\n# # Train\n# gm = GaussianMixture(n_components=2)\n# gm.fit(train_data_scaled)\n\n# # Predict\n# gmm_preds = gm.predict(train_data_scaled)\n\n# # Add these predictions into the dataframe too\n# coverage_predictions['gmm'] = gmm_preds.tolist()","cf0741e4":"<h3 style=\"color:gray\">2.3 Linebacker Insights<\/h3>","e73dafe2":"After closer inspection, we found that nearly all of the top players in the above table were linebackers, due to the bias resulting from the vastly larger amount of forced fumbles and sacks than interceptions.\n\nAs a result, we decided it would be best to separate our analysis into two distinct groups: `Defensive Backs` and `Linebackers`.","dc7e0c0a":"We used a simple K-Means algorithm to cluster zone vs. man coverage. First, we cleaned our data by removing duplicate and NaN values. We then standardized our data by subtracting each data value by the mean and dividing by the standard deviation. Next, we used a simple K-Means algorithm with these two clusters. From our model\u2019s output, we counted 14,951 values for man coverage and 64,100 values for zone coverage. \n\n\nOur output had one dataframe for man coverage and another for zone coverage. To better understand the different coverage options, we applied statistical analysis to the set. Through this process, we found a key insight \u2013\u2013 that the average variances in x-direction, y-direction, and speed were much higher in the zone cluster than in the man cluster. We also noted that there was more player movement in the zone cluster than in the man cluster during plays.","99cd577c":"<h1 style=\"color:blue;font-family:'Tahoma'\">Appendix<\/h1>","9153a1df":"<h3 style=\"color:gray\">1.2 Using Mini Batch K-Means for Clustering<\/h3>","5cf30301":"<h1 style=\"color:blue; font-family:'Tahoma';text-align:center\"> Predictive Defense Analysis on NFL Data <\/h1>\n\n<img src=\"https:\/\/cdn.pixabay.com\/photo\/2015\/03\/07\/21\/42\/stadium-663584_1280.jpg\">\n<hr>","f737d568":"Additionally, we chose to cluster with Mini Batch K-means, knowing that this method works well on datasets with more than 10,000 samples. We cleaned the data and ran the predictions with two clusters. Similar to our findings with the simple K-means method, we saw that there were 63,800 values in our zone coverage cluster and 15,251 in our man coverage cluster. ","efeb0794":"<h2 style=\"color:green;font-family:Tahoma\">1. Identifying Zone vs Man Coverage<\/h2>\n\nA fundamental issue to address in this challenge was to identify which coverage types defenses were employing. Traditionally, teams line up in either zone or man coverage. In zone coverage, teams attempt to cover different parts of the field by assigning each player to a zone. Contrastly, in man coverage, each defensive player is responsible for covering one offensive player. \n\nThere are many variations of zone and man coverages, and defenses frequently disguise their coverages to confuse opposing offenses. \n\nSince the data in this challenge was so detailed, we realized that we could use the defensive player data in conjunction with various data science models and statistical analyses to generate predictions about whether the defense was in man or zone coverage. We used unsupervised machine learning in an attempt to classify whether the defense was in man or zone coverage. \n\nTo accomplish this, we generated (with help from some excellent Public Notebooks), new features to determine the variance in distances and relative speeds between defensive and offensive players (`varX`, `varY`, `varS`, `oppVar`, `oppMean`, `mateMean`, `oppDirVar`, `oppDirMean`, `meanOppMateDistRatio`, `varOppMateDistRation`) to better grasp how frequently the defense employed each coverage scheme.\n\nWe then used K-Means, Mini Batch K-Means, and Gaussian Mixture models to classify zone or man coverage, and used our algorithms\u2019 predictions as outputs. As seen below, the models all say the same thing \u2013\u2013 that the defenses primarily employ zone coverage schemes.","fe79003c":"Throughout this challenge, our team did face a few technical challenges worth nothing.","287ccfa7":"<h2 style=\"color:green;font-family:Tahoma\">Conclusion and Technical Challenges<\/h2>","a5726e5e":"<h3 style=\"color:purple\">Preliminary Descriptive Statistics - LINEBACKERS<\/h3>\n<br>\n\n* Median Age: 28.2 years\n* Median Height: 74.0 inches (6\u2019-2\u201d)\n* Median Weight: 245.0 pounds\n\n\n<br>\nLike the defensive backs, the medians and means for linebackers were almost identical, with negligible differences between the two. To avoid redundancy, we only included the medians here.","2af0d24b":"<h3 style=\"color:gray\">1.1 Using K-Means for Clustering<\/h3>","5e5f5600":"<h3 style=\"color:gray\">2.2 Defensive Back Insights<\/h3>\n\nFirst, we subset all defensive backs in our data. We looked at players having the positions `CB`, `SS`, `S`, and `DB`.\n\nAfter building this defensive back subset, we analyzed the data to see what correlated with strong defensive performance. \n\nFirst, we calculated correlations between each player attribute and the number of interceptions, forced fumbles, and sacks. \nSince we are exclusively looking at defensive backs, we decided that it was most important to analyze the attributes that optimized the number of interceptions. Our findings are detailed below.","4a0a7006":"<h4>Major Insights:<\/h4>\n\n1. We found that defensive backs who were **taller than 74 inches** (6\u2019-2\u201d) were **negatively correlated with their number of interceptions** (Correlation = -0.74).\n\n2. We also found that of defensive backs who **weighed more than 215 pounds**, their age was **negatively correlated with their number of sacks** (Correlation = -0.77).\n\n3. Finally, in defensive backs who were **younger than 25 years old**, there was **a slight positive correlation between height and interceptions** (Correlation = 0.37).","2ba30044":"Our analysis on man vs zone coverage was inspired by Andika Rachman's [Notebook on Identifying Coverage Scheme Among Defense Backs](https:\/\/www.kaggle.com\/ar2017\/identifying-coverage-scheme-among-defensive-backs).","51b03ab1":"Building off of the aforementioned parsing algorithm and resultant data, we had a final dataframe with these player statistics: *each player name, height, age, total interceptions, total forced fumbles, and total sacks recorded.* \n\nNow we could model what player attributes contributed to or correlated with certain statistical outcomes. Through this analysis, we aimed to answer \"Is there anything about a player \u2013 for example, their height, weight, experience, speed, or position \u2013 that can be used to predict their performance on defense?\"\n\nKnowing that there existed a large variance between these player attributes (height, weight, and age) across different positions, we decided it would enrich our insights and behoove us to create subsets by position type.","e0c58552":"<h3 style=\"color:purple\">Preliminary Descriptive Statistics - DEFENSIVE BACKS<\/h3>\n<br>\n\n* Median Age: 28.8 years\n* Median Height: 71.0 inches (5\u2019-11\u201d)\n* Median Weight: 200.0 pounds\n\n<br>\nThe medians and the means were almost identical, with negligible differences between the two. To avoid redundancy, we only included the medians here.","25d5b7d6":"When answering \u201cWhat are coverage schemes that the defense employs?\u201d, we were confined to data from three weeks (1, 3, and 5). This was due to memory constraints and various errors in our debugging process. \n\nNevertheless, we still strongly believe that our overall conclusion is accurate and applicable throughout the entire season.\n\nAnother issue our team faced was that the player names in the play descriptions that were fed into the parsing algorithm were in a different convention than the player names in the players.csv file. \nThis caused some player names to not match up when building on the resultant data to create the linebacker and defensive back data frames.\n\nLastly, when we were exploring various correlations between attributes and defensive performance in linebackers and defensive backs, some of our conditional parameters for attributes (height, weight, age) yielded a data frame with less than 10 observations, which could result in some biased correlations. We felt that despite these smaller sample sizes, because the other attributes were relatively close in value, and the data frame was inherently a subset of a subset, the correlations were worth noting.\n\nUltimately, we believe that our analysis is strong, even with these various technical challenges. \nWe are all in agreement that tackling these issues head-on enabled us to all grow as data scientists and sports analytics enthusiasts. \nWe hope that our findings are of use, and welcome any feedback or suggestions.","956e8627":"<h3 style=\"color:gray\">2.1 Parsing Descriptions Text to Evaluate Player Defensive Performance<\/h3>\n\nQuantifying individual players\u2019 defensive performance is a difficult feat that accompanies lots of ambiguity.\nWith this in mind, we decided an effective way to accomplish this was to attribute the number of sacks, forced fumbles, and interceptions to each defensive player, and then use those features to model each player\u2019s performance.\n\nTo do this, we generated an algorithm that parsed through each play description and stored the player\u2019s name and the running count total for each associated feature in a dictionary. \n\nWe transformed the dictionary into a dataframe, and then used this data to uncover insights regarding the top performers. \n\n**Summing up the total number of interceptions, forced fumbles, and sacks, we assigned an effective total defensive score to each player.** \n\nWe then ranked these players in descending order, as seen in the table below:","0fbc5542":"Finally, we used a Gaussian Mixture model to gain more clarity on the differences between the two subpopulations we are looking at: man and zone. \n\nWe built a simple model to generate predictions regarding defensive coverage schemes. Our model found 62,156 plays where zone coverage was used and 16,895 plays where man coverage was used; this finding is in accord with the other modeling methods discussed above.","bfa5df15":"<h4>Major Insights:<\/h4>\n\n1. We found that linebackers **younger than 25** were **negatively correlated with their number of interceptions** (Correlation = -0.87).\n\n2. We also found that the heaviest linebackers\u2019 (**those who weighed 268 pounds or more**) ages were nearly perfectly correlated with their number of sacks (Correlation = 0.95); likewise, their heights were considerably positively correlated with their number of forced fumbles (Correlation = 0.70).","b3304623":"<h3 style=\"color:gray\">1.4 Conclusion<\/h3>\n\nWe learned that teams primarily employ zone defensive schemes, where the players line up further off the ball, allowing more distance between the offensive and defensive players. \n\nHaving broken down each play into subcomponents with detailed information about each player\u2019s directional positions and speed, we were able to build models that classify differences across coverage schemes. \n\nAll three models were in agreement that roughly 80% of plays correspond to one type of coverage scheme and the remaining 20% to another scheme. These findings, coupled with our new generated features, led us to infer that the more frequently employed scheme was zone coverage.","e50e9d94":"Shown below is the list of top 20 Defensive Backs players:","e7848753":"<h3 style=\"color:gray\">1.3 Using Gaussian Mixture Models for Clustering<\/h3>","07097d8f":"<h2 style=\"color:green;font-family:Tahoma\">2. Drawing Insights from Defensive Player Performance Data<\/h2>"}}