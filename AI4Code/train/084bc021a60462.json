{"cell_type":{"ef6a3072":"code","984354b9":"code","d5a08bc5":"code","7f345de3":"code","c9999266":"code","ee05873c":"code","014ee5c3":"code","dd045a6a":"code","f7ed20e3":"code","49116a7f":"code","3aef3023":"code","8d31ea7b":"code","9204bc32":"code","1529489c":"code","36a946ae":"code","d0d945e7":"code","8c2bd405":"code","0ef67a56":"code","0250bbec":"code","036b2992":"code","a94a4954":"code","e4beaff8":"code","5a7ec746":"code","411d97ee":"code","6bf716bc":"code","b11f0dc2":"code","950f5cc8":"code","0588451c":"code","5f553880":"code","b52f2280":"code","ed088e34":"code","41e31e33":"code","04ebf5f9":"code","4980cb73":"code","4d2aa7ab":"code","47484fa0":"code","d08d93aa":"code","523275c8":"code","e587462c":"code","6c197d94":"code","f221bf80":"code","2882a6b8":"markdown","8aedadaa":"markdown","8ad2f5d4":"markdown","66752c8e":"markdown"},"source":{"ef6a3072":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n\"\"\"\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\"\"\"\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","984354b9":"import numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport pydicom\nimport glob\nfrom datetime import datetime\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\nfrom sklearn.decomposition import PCA\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.model_selection import KFold\nfrom sklearn.linear_model import LogisticRegression as LogReg\nfrom sklearn.metrics import log_loss\n\nimport cv2","d5a08bc5":"root_dir = '..\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/'\ndata = pd.read_csv(root_dir + 'train_labels.csv')\n\nto_exclude = [109, 123, 709]\ndata = data[~data['BraTS21ID'].isin(to_exclude)]","7f345de3":"num_samples = data.shape[0]\nnum_positives = np.sum(data['MGMT_value'] == 1)\nnum_negatives = np.sum(data['MGMT_value'] == 0)\ndata.hist(column=\"MGMT_value\")","c9999266":"print(\"Number of samples: \" + str(num_samples))\nprint(\"Number of positive labels: \" + str(num_positives))\nprint(\"Number of negative labels: \" + str(num_negatives))","ee05873c":"y_true = data['MGMT_value'].values\ny_pred = np.array([1]*num_samples)\nbaseline_auc = roc_auc_score(y_true, y_pred)","014ee5c3":"baseline_auc","dd045a6a":"def full_ids(data):\n    zeros = 5 - len(str(data))\n    if zeros > 0:\n        prefix = ''.join(['0' for i in range(zeros)])\n    \n    return prefix+str(data)","f7ed20e3":"data['BraTS21ID_full'] = data['BraTS21ID'].apply(full_ids)\n\n# Add all the paths to the df for easy access\ndata['flair'] = data['BraTS21ID_full'].apply(lambda file_id : root_dir+'train\/'+file_id+'\/FLAIR\/')\ndata['t1w'] = data['BraTS21ID_full'].apply(lambda file_id : root_dir+'train\/'+file_id+'\/T1w\/')\ndata['t1wce'] = data['BraTS21ID_full'].apply(lambda file_id : root_dir+'train\/'+file_id+'\/T1wCE\/')\ndata['t2w'] = data['BraTS21ID_full'].apply(lambda file_id : root_dir+'train\/'+file_id+'\/T2w\/')\ndata","49116a7f":"test_data = pd.read_csv(root_dir + 'sample_submission.csv')\ntest_data['BraTS21ID_full'] = test_data['BraTS21ID'].apply(full_ids)\ntest_data['flair'] = test_data['BraTS21ID_full'].apply(lambda file_id : root_dir+'test\/'+file_id+'\/FLAIR\/')\ntest_data['t1w'] = test_data['BraTS21ID_full'].apply(lambda file_id : root_dir+'test\/'+file_id+'\/T1w\/')\ntest_data['t1wce'] = test_data['BraTS21ID_full'].apply(lambda file_id : root_dir+'test\/'+file_id+'\/T1wCE\/')\ntest_data['t2w'] = test_data['BraTS21ID_full'].apply(lambda file_id : root_dir+'test\/'+file_id+'\/T2w\/')\ntest_data","3aef3023":"def get_image(data):\n    '''\n    Returns the image data as a numpy array.\n    '''  \n    if np.max(data.pixel_array)==0:\n        img = data.pixel_array\n    else:\n        img = data.pixel_array\/np.max(data.pixel_array)\n        img = (img * 255).astype(np.uint8)\n        \n    return img","8d31ea7b":"test_mri_image_data = '\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/train\/00000\/T1w\/Image-25.dcm'","9204bc32":"img_data = pydicom.dcmread(test_mri_image_data)\nimg = get_image(img_data)\nplt.imshow(img, cmap='gray')","1529489c":"def sorted_image_dirs(path: str, sort=True):\n    '''\n    Sorts the list of image directories by image number in a path\n    '''\n    dirs = glob.glob(path+'*')\n    if sort:\n        dirs.sort(key=lambda x: int(x.split('\/')[-1].split('-')[-1].split('.')[0]))\n    \n    return dirs\n\n\ndef get_all_images(path: str, sort=True):\n    '''\n    Returns a list of (non blank) images from a given path (of shape [non_blank_image_count, 512, 512])\n    '''\n    image_dirs = sorted_image_dirs(path, sort)\n    images = []\n    \n    for directory in image_dirs:\n        data = pydicom.dcmread(directory)\n        img = get_image(data)\n        \n        # Exclude the blank images\n        if np.max(img)!=0:\n            images.append(img)\n        else:\n            pass\n    \n    return images\n\ndef show_animation(images: list):\n    '''\n    Displays an animation from the list of images.\n    \n    set: matplotlib.rcParams['animation.html'] = 'jshtml'\n    \n    '''\n    fig = plt.figure(figsize=(6, 6))\n    plt.axis('off')\n    im = plt.imshow(images[0], cmap='gray')\n    \n    def animate_func(i):\n        im.set_array(images[i])\n        return [im]\n    \n    return matplotlib.animation.FuncAnimation(fig, animate_func, frames = len(images), interval = 20)","36a946ae":"\"\"\"\npatient = 10\n\nflair_images = get_all_images(data['flair'][patient])\nprint('No of images:', len(flair_images))\nprint('MGMT: ', data['MGMT_value'][patient])\n\nfig = plt.figure(figsize=(30,30))\n\nc = 1\nfor image in flair_images:\n    ax = fig.add_subplot(len(flair_images)\/\/10+1, 10, c)\n    ax.imshow(image, cmap='gray')\n    c+=1\n    \n    plt.axis('off')\n    \nfig.tight_layout()\n\"\"\"","d0d945e7":"excluded_indexes = np.setdiff1d(list(range(585)), list(data.index))","8c2bd405":"\"\"\"\npd.set_option('mode.chained_assignment', None)\nflattened_image_df = data.copy(deep=True)\nshape_df = data.copy(deep=True)\nMRI_types = ['flair', 't1w', 't1wce', 't2w']\nstart = datetime.now() \nfor img_type in MRI_types:\n    for patient_id in np.setdiff1d(list(range(585)), excluded_indexes):\n        images = get_all_images(data[img_type][patient_id], sort=False)\n        shape_df[img_type][patient_id] = images[0].shape\n        \n        images = np.array(images)\n        flattened_image = np.mean(images, axis=0)\n        flattened_image_df[img_type][patient_id] = flattened_image\n        \n        if patient_id % 40 == 0:\n            print(str(img_type) + \" \" + str(patient_id))\n             \nend = datetime.now()\nduration = end - start\nseconds_elapsed = duration.total_seconds()\nprint(\"Time elapsed: \" + str(seconds_elapsed))\n\nshape_df.to_pickle(\"\/kaggle\/working\/input_image_shapes.p\")\nflattened_image_df.to_pickle(\"\/kaggle\/working\/input_flattened_images.p\")\n\"\"\"","0ef67a56":"\"\"\"\npd.set_option('mode.chained_assignment', None)\nflattened_image_df = test_data.copy(deep=True)\nMRI_types = ['flair', 't1w', 't1wce', 't2w']\nstart = datetime.now() \nfor img_type in MRI_types:\n    for patient_id in list(test_data.index):\n        images = get_all_images(test_data[img_type][patient_id], sort=False)\n        images = np.array(images)\n        flattened_image = np.mean(images, axis=0)\n        flattened_image_df[img_type][patient_id] = flattened_image\n        \n        if patient_id % 10 == 0:\n            print(str(img_type) + \" \" + str(patient_id))\n             \nend = datetime.now()\nduration = end - start\nseconds_elapsed = duration.total_seconds()\nprint(\"Time elapsed: \" + str(seconds_elapsed))\n\n#flattened_image_df.to_pickle(\"\/kaggle\/working\/input_flattened_images.p\")\n\"\"\"","0250bbec":"#shape_df = pd.read_pickle('\/kaggle\/input\/brain-tumour-image-data-zip\/input_image_shapes.p')\n#flattened_image_df = pd.read_pickle('\/kaggle\/input\/brain-tumour-image-data-zip\/input_flattened_images.p')","036b2992":"#from tensorflow.keras.applications.vgg16 import VGG16\n#from tensorflow.keras.applications.inception_v3 import InceptionV3\n#from tensorflow.keras.applications import ResNet50","a94a4954":"device_name = tf.test.gpu_device_name()\nif \"GPU\" not in device_name:\n    print(\"GPU device not found\")\nprint('Found GPU at: {}'.format(device_name))","e4beaff8":"width = 256\nheight = 256","5a7ec746":"pd.set_option('mode.chained_assignment', None)\ndef compute_embeddings(mri_type, batch_size):\n\n    assert mri_type in ['flair', 't1w', 't1wce', 't2w']\n    \n    model_input = np.zeros((batch_size, width, height, 3))\n    raw_data = flattened_image_df[mri_type].values\n    for index in range(batch_size):\n        model_input[index, :, :, 0] = raw_data[index]\n        model_input[index, :, :, 1] = raw_data[index]\n        model_input[index, :, :, 2] = raw_data[index]\n\n    image_embedding = ResNet_model.predict(model_input)\n    image_embedding = image_embedding.reshape([batch_size, -1])\n    \n    entry_index = 0\n    #for patient_id in np.setdiff1d(list(range(585)), excluded_indexes):\n    for patient_id in list(flattened_image_df.index):\n        flattened_image_df[mri_type][patient_id] = image_embedding[entry_index, :]\n        entry_index += 1\n    \n    return","411d97ee":"\"\"\"\n#ResNet_model = ResNet50(input_shape=(width, height, 3), include_top=False, weights=\"imagenet\")\n#ResNet_model = keras.models.load_model(\"\/kaggle\/input\/resnet50-weights\/ResNet50.h5\")\nflattened_image_df['flair'] = flattened_image_df['flair'].apply(lambda x: cv2.resize(x, (width, height)))\nflattened_image_df['t1w'] = flattened_image_df['t1w'].apply(lambda x: cv2.resize(x, (width, height)))\nflattened_image_df['t1wce'] = flattened_image_df['t1wce'].apply(lambda x: cv2.resize(x, (width, height)))\nflattened_image_df['t2w'] = flattened_image_df['t2w'].apply(lambda x: cv2.resize(x, (width, height)))\n\nfor mri_type in ['flair', 't1w', 't1wce', 't2w']:\n    compute_embeddings(mri_type, flattened_image_df.shape[0])\ny = flattened_image_df['MGMT_value'].values.reshape((-1,1))\nX = np.zeros((y.shape[0], len(flattened_image_df['flair'][0]) * 4))\n\nfor index in range(y.shape[0]):\n    data = flattened_image_df.iloc[index]\n    features = np.concatenate((data['flair'], data['t1w'], data['t1wce'], data['t2w']))\n    X[index, :] = features\n    \nX_test = X\n#np.save(\"\/kaggle\/working\/y.npy\", y)\n#np.save(\"\/kaggle\/working\/X_test.npy\", X)\n\"\"\"","6bf716bc":"y = np.load(\"\/kaggle\/input\/d\/nicholasjohnson2020\/brain-tumour-features-resnet50-256\/256_ResNet50_features\/y.npy\")\nX = np.load(\"\/kaggle\/input\/d\/nicholasjohnson2020\/brain-tumour-features-resnet50-256\/256_ResNet50_features\/X.npy\")\nX_test = np.load(\"\/kaggle\/input\/d\/nicholasjohnson2020\/brain-tumour-features-resnet50-256\/256_ResNet50_features\/X_test.npy\")","b11f0dc2":"pca = PCA(n_components = 100)\nX_trim = pca.fit_transform(X)\nX_test_trim = pca.transform(X_test)","950f5cc8":"print(X.shape)\nprint(X_trim.shape)\nprint(X_test.shape)\nprint(X_test_trim.shape)","0588451c":"def plot_hist(hist, last = None):\n    if last == None:\n        last = len(hist.history[\"loss\"])\n    plt.plot(hist.history[\"loss\"][-last:])\n    plt.plot(hist.history[\"val_loss\"][-last:])\n    plt.title(\"model accuracy\")\n    plt.ylabel(\"accuracy\")\n    plt.xlabel(\"epoch\")\n    plt.legend([\"train\", \"validation\"], loc=\"upper left\")\n    plt.show()","5f553880":"saved_X = X","b52f2280":"def l3_res_model(input_shape, no_classes, lr):\n    inputs = tf.keras.Input(shape=input_shape)\n    x = layers.Dense(128, activation='sigmoid')(inputs)\n    x = layers.BatchNormalization()(x)\n    b_1 = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='sigmoid')(b_1)\n    x = layers.BatchNormalization()(x)\n    b_2 = layers.Dropout(0.2)(x)\n    x = layers.Dense(128, activation='sigmoid')(b_2)\n    x = layers.BatchNormalization()(x)\n    b_3 = layers.Dropout(0.2)(x)\n    tot_op = tf.keras.layers.add([b_1, b_2, b_3])\n    outputs = layers.Dense(no_classes, activation='sigmoid')(tot_op)\n    model = tf.keras.Model(inputs, outputs)\n    model.compile(loss='binary_crossentropy', optimizer=tf.keras.optimizers.Adam(learning_rate = lr), metrics=['binary_crossentropy'])\n    return model","ed088e34":"X = X_trim\ninput_dim = X.shape[1]\n\nlosses_NN=[]\nauc_NN=[]\nkf = KFold(n_splits=10)\ntf.random.set_seed(1010)\nnp.random.seed(1010)\n\nfor train_index, test_index in kf.split(X):\n    X_train, X_test = X[train_index], X[test_index]\n    y_train, y_test = y[train_index], y[test_index]\n\n    nnclf = l3_res_model((input_dim,),1,0.00001)\n    hist = nnclf.fit(X_train, y_train, batch_size=64, epochs=50, validation_data=(X_test, y_test), verbose=0)\n    plot_hist(hist, last=20)\n\n    preds = nnclf.predict(X_test) # list of preds per class\n\n    loss = log_loss(np.ravel(y_test), np.ravel(preds))\n    auc = roc_auc_score(y_test[:, 0], preds[:, 0])\n    print('Loss: '+str(loss))\n    print('AUC: '+str(auc))\n    losses_NN.append(loss)\n    auc_NN.append(auc)\n\nprint('Average Loss: '+str(np.average(losses_NN)))\nprint('Average AUC: '+str(np.average(auc_NN)))","41e31e33":"X = X_trim\ninput_dim = X.shape[1]\nweek1_model = l3_res_model((input_dim,),1,0.00001)\nweek1_model.fit(X, y, batch_size=16, epochs=50, verbose=0)","04ebf5f9":"preds = week1_model.predict(X_test_trim)","4980cb73":"submission_file = pd.read_csv(\"\/kaggle\/input\/rsna-miccai-brain-tumor-radiogenomic-classification\/sample_submission.csv\")\nsubmission_file[\"BraTS21ID\"] = submission_file['BraTS21ID'].apply(full_ids)\nsubmission_file[\"MGMT_value\"] = preds\nsubmission_file.to_csv(\"submission.csv\", index=False)","4d2aa7ab":"\"\"\"\nMRI_types = ['flair', 't1w', 't1wce', 't2w']\nfor mri_type in MRI_types:\n    model_input = np.zeros((num_patients, img_width, img_height, 3))\n        for patient_id in range(num_patients):\n            image_array = get_all_images(data[image_type][patient_id], sort=False)\n            image_array = np.array(image_array)\n            print(\"Patient \" + str(patient_id) + \" data shape: \" + str(image_array.shape))\n            flattened_image = np.mean(image_array, axis=0)\n            \n            model_input[patient_id, :, :, 0] = flattened_image\n            model_input[patient_id, :, :, 1] = flattened_image\n            model_input[patient_id, :, :, 2] = flattened_image\n            \n        image_embedding = embedding_model.predict(model_input)\n        image_embedding = image_embedding.reshape([num_patients, -1])\n        \n        for patient_id in range(num_patients):\n            output_df[image_type][patient_id] = image_embedding[patient_id, :]\n\"\"\"","47484fa0":"\"\"\"\nflair_count = shape_df['flair'].value_counts()\nt1w_count = shape_df['t1w'].value_counts()\nt1wce_count = shape_df['t1wce'].value_counts()\nt2w_count = shape_df['t2w'].value_counts()\n\nflair_shapes = list(flair_count.index)\nt1w_shapes = list(t1w_count.index)\nt1wce_shapes = list(t1wce_count.index)\nt2w_shapes = list(t2w_count.index)\nunique_shapes = list(set(flair_shapes + t1w_shapes + t1wce_shapes + t2w_shapes))\nshape_counts = {}\nfor shape in unique_shapes:\n    shape_counts[shape] = 0\nfor shape in flair_shapes:\n    shape_counts[shape] += flair_count[shape]\nfor shape in t1w_shapes:\n    shape_counts[shape] += t1w_count[shape]\nfor shape in t1wce_shapes:\n    shape_counts[shape] += t1wce_count[shape]\nfor shape in t2w_shapes:\n    shape_counts[shape] += t2w_count[shape]\n\"\"\"","d08d93aa":"\"\"\"\ndef compute_embeddings(mri_types, batch_size, output_df, img_width, img_height):\n\n    model_input = np.zeros((batch_size, img_width, img_height, 3))\n    temp_legend = {}\n    entry_index = 0\n    for mri_type in mri_types:\n        for patient_id in np.setdiff1d(list(range(585)), excluded_indexes):\n            if shape_df[mri_type][patient_id] == (img_width, img_height):\n                temp_legend[entry_index] = (mri_type, patient_id)\n                model_input[entry_index, :, :, 0] = flattened_image_df[mri_type][patient_id]\n                model_input[entry_index, :, :, 1] = flattened_image_df[mri_type][patient_id]\n                model_input[entry_index, :, :, 2] = flattened_image_df[mri_type][patient_id]\n                entry_index += 1\n    assert entry_index == batch_size            \n\n    ResNet_model = ResNet50(input_shape=(img_width, img_height,3), include_top=False, weights=\"imagenet\")\n    image_embedding = ResNet_model.predict(model_input)\n    image_embedding = image_embedding.reshape([batch_size, -1])\n    for entry_index in range(batch_size):\n        (mri_type, patient_id) = temp_legend[entry_index]\n        output_df[mri_type][patient_id] = image_embedding[entry_index, :]\n\n    return\n\nstart = datetime.now()      \nMRI_types = ['flair', 't1w', 't1wce', 't2w']\npd.set_option('mode.chained_assignment', None)\n#embedding_df = flattened_image_df.copy(deep=True)\nembedding_df = flattened_image_df\n\nfor (img_width, img_height) in unique_shapes:\n    if (img_width, img_height) == (512, 512):\n        continue\n    compute_embeddings(MRI_types, shape_counts[(img_width, img_height)], embedding_df,\n                       img_width, img_height)\n    print(\"Finished \" + str((img_width, img_height)))\n\n\n    \ncompute_embeddings(['flair', 't1w'], flair_count[(512, 512)] + t1w_count[(512, 512)],\n                   embedding_df, 512, 512)\ncompute_embeddings([\"t1wce\", 't2w'], t1wce_count[(512, 512)] + t2w_count[(512, 512)],\n                   embedding_df, 512, 512)\n\nend = datetime.now()\nduration = end - start\nseconds_elapsed = duration.total_seconds()\nprint(\"Time elapsed: \" + str(seconds_elapsed))\n\nembedding_df.to_pickle(\"\/kaggle\/working\/embeddeding_512.p\")\n\"\"\"","523275c8":"\"\"\"\ndef transform_patient_data_v1(embedding_model, num_patients=num_samples,\n                              img_width=512, img_height=512):\n    \n    pd.set_option('mode.chained_assignment', None)\n    output_df = data.copy(deep=True)\n    \n    MRI_types = ['flair', 't1w', 't1wce', 't2w']\n    for image_type in MRI_types:\n        model_input = np.zeros((num_patients, img_width, img_height, 3))\n        for patient_id in range(num_patients):\n            image_array = get_all_images(data[image_type][patient_id], sort=False)\n            image_array = np.array(image_array)\n            print(\"Patient \" + str(patient_id) + \" data shape: \" + str(image_array.shape))\n            flattened_image = np.mean(image_array, axis=0)\n            \n            model_input[patient_id, :, :, 0] = flattened_image\n            model_input[patient_id, :, :, 1] = flattened_image\n            model_input[patient_id, :, :, 2] = flattened_image\n            \n        image_embedding = embedding_model.predict(model_input)\n        image_embedding = image_embedding.reshape([num_patients, -1])\n        \n        for patient_id in range(num_patients):\n            output_df[image_type][patient_id] = image_embedding[patient_id, :]\n            \n    return output_df\n    \ndef transform_patient_data_v2(patient_id, embedding_model):\n    \n    MRI_types = ['flair', 't1w', 't1wce', 't2w']\n    output_dict = {}\n    \n    for image_type in MRI_types:\n        image_array = get_all_images(data[image_type][patient_id])\n        model_input = np.zeros((len(image_array), image_array[0].shape[0],\n                                image_array[0].shape[1], 3))\n        for i in range(model_input.shape[0]):\n            model_input[i, :, :, 0] = image_array[i]\n            model_input[i, :, :, 1] = image_array[i]\n            model_input[i, :, :, 2] = image_array[i]\n        \n        image_embedding = embedding_model.predict(model_input)\n        image_embedding = image_embedding.reshape([image_embedding.shape[0], -1])\n        image_embedding = np.mean(image_embedding, axis=0)\n        \n        output_dict[image_type] = image_embedding\n\n    return output_dict\n\"\"\"","e587462c":"#scan_width = 512\n#scan_height = 512","6c197d94":"#VGG_model = VGG16(input_shape = (scan_width, scan_height, 3), include_top = False, weights = 'imagenet')\n#Inception_model = InceptionV3(input_shape = (scan_width, scan_height, 3), include_top = False, weights = 'imagenet')\n#ResNet_model = ResNet50(input_shape=(scan_width, scan_height,3), include_top=False, weights=\"imagenet\")","f221bf80":"#start = datetime.now()      \n#VGG_embeddings = transform_patient_data_v2(0, VGG_model)\n#end = datetime.now()\n#duration = end - start\n#seconds_elapsed = duration.total_seconds()\n#print(\"Time elapsed: \" + str(seconds_elapsed))","2882a6b8":"# Baseline AUC (always predict the most common class)","8aedadaa":"This makes sense because the two classes are roughly balanced.","8ad2f5d4":"# First Model","66752c8e":"# Miscellaneous Prototyping"}}