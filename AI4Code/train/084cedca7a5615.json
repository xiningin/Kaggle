{"cell_type":{"a72f205d":"code","17a53c68":"code","d9f711dc":"code","f5d4e840":"code","16a2b4a0":"code","79a68682":"code","2c3cf75d":"code","72cd7449":"code","338e8c9e":"code","7483eac6":"code","ce71a248":"code","18fa3f67":"code","ac9a494b":"code","782ca7a9":"code","63fe45ae":"code","14fc8261":"code","c86f166d":"code","ceaba0bb":"code","96f06fbd":"code","2c8492b9":"code","2e533a5d":"code","5af32a2a":"code","77828034":"code","59c9316a":"code","dd40e158":"code","69ecd45a":"code","ad8aca83":"code","d174cd83":"code","47af9c1d":"code","a2a7794f":"code","a6e6af6f":"code","56a37990":"code","9beaef0f":"code","df0a8dbb":"code","b511b644":"code","960270e7":"code","550d0958":"code","ec103991":"code","6027f55f":"code","f2205ac4":"code","90e11012":"code","eaa5c95d":"code","b2bb5536":"code","61cedf86":"code","1fd1877c":"code","351af977":"code","e78fd94b":"code","e2c2f4d3":"code","e38d78ce":"code","a64c1c4d":"code","18ff5290":"code","06d77afb":"code","1264e321":"code","4afb26b2":"code","7bfb99da":"code","cb95ec37":"code","4faac529":"code","eec3bdd3":"code","2dd1250d":"code","692400e6":"code","2c0a0eac":"code","2bed27fa":"code","2223b64e":"code","f855e85d":"code","c37f39b5":"code","4897bf20":"code","0fc19023":"code","94d1220d":"code","0023bbd2":"markdown","c446a492":"markdown","4438e7fd":"markdown","a548f419":"markdown","b2c5e438":"markdown","8ca017bc":"markdown","607f9b25":"markdown","19af20a7":"markdown","90b0c923":"markdown","e8dfcde2":"markdown","df1496c1":"markdown","cc44e354":"markdown","1e2a0b5b":"markdown","9223bc99":"markdown","f4f11817":"markdown","63990325":"markdown","70988b1e":"markdown","c1281cbe":"markdown","ac3991f7":"markdown","ee07fd91":"markdown","f03235bb":"markdown","d8422071":"markdown","bab1eb33":"markdown","025a4c9d":"markdown","18862d41":"markdown","e7c18f4f":"markdown","7dce8658":"markdown","c36b84ed":"markdown","44ed3bf7":"markdown","75bdef97":"markdown","e31eba53":"markdown","2a5ce6c7":"markdown","ba1dc7c9":"markdown","1714d485":"markdown","a7bb9bb3":"markdown","b48675d9":"markdown"},"source":{"a72f205d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","17a53c68":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\ntrain_data.head()","d9f711dc":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","f5d4e840":"women_survived = train_data.loc[train_data.Sex==\"female\"][\"Survived\"]\nrate_women = sum(women_survived)\/len(women_survived)\n\nprint(\"% of women survived \" , rate_women)","16a2b4a0":"def missing_percentage(df):\n    total = df.isnull().sum().sort_values(ascending=False)\n    percent = round(df.isnull().sum().sort_values(ascending=False) \/ len(df) * 100, 2)\n    return pd.concat([total,percent], axis = 1, keys = ['Total', 'Percent'])","79a68682":"missing_percentage(train_data)","2c3cf75d":"missing_percentage(test_data)","72cd7449":"train_data[train_data.Embarked.isnull()]","338e8c9e":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nsns.set_style('darkgrid')\nfig, ax = plt.subplots(figsize=(16,12),ncols=2)\nax1 = sns.boxplot( x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=train_data, ax=ax[0]);\nax2 = sns.boxplot( x=\"Embarked\", y=\"Fare\", hue=\"Pclass\", data=test_data, ax=ax[1]);","7483eac6":"train_data.Embarked.fillna(\"C\", inplace=True)","ce71a248":"test_data[test_data.Fare.isnull()]","18fa3f67":"test_data[(test_data.Sex == \"male\") & (test_data.Pclass == 3) & (test_data.Embarked == \"S\")]","ac9a494b":"missing_value = test_data[(test_data.Sex == \"male\") & (test_data.Pclass == 3) & (test_data.Embarked == \"S\")].Fare.mean()\ntest_data.Fare.fillna(missing_value, inplace=True)","782ca7a9":"import seaborn as sns\npal = {'male':\"green\", 'female':\"Pink\"}\nsns.set(style=\"darkgrid\")\nplt.subplots(figsize = (15,8))\nax = sns.barplot(x = \"Sex\", \n                 y = \"Survived\", \n                 data=train_data, \n                 palette = pal,\n                 linewidth=5,\n                 order = ['female','male'],\n                 capsize = .05,\n\n                )\n\nplt.title(\"Survived\/Non-Survived Passenger Gender Distribution\", fontsize = 25, loc='center', pad=40)\nplt.ylabel(\"% of passenger survived\", fontsize= 15)\nplt.xlabel(\"Sex\", fontsize=15)","63fe45ae":"import seaborn as sns\npal = {1:\"blue\", 0:\"red\"}\nsns.set(style=\"darkgrid\")\nplt.subplots(figsize=(15,8))\nax = sns.countplot( x= \"Sex\", hue=\"Survived\", data=train_data, linewidth=2, palette=pal)\n\nplt.title(\"Passenger Gender Distribution - Survived vs Not-Survived\", fontsize=25, loc='center')\nplt.ylabel(\"Number of passenger\", fontsize=15)\nplt.xlabel(\"Sex\", fontsize=15)","14fc8261":"temp = train_data[[\"Pclass\",\"Survived\", \"PassengerId\"]].groupby([\"Pclass\",\"Survived\"]).count().reset_index()\ntemp_df = pd.pivot_table(temp, values = 'PassengerId', index = 'Pclass',columns = 'Survived')\ntemp_df.columns = [\"No\", \"Yes\"]\n\ntotal = [i+j for i,j in zip(temp_df[\"No\"], temp_df[\"Yes\"])]\nNo_s = [i\/j * 100 for i,j in zip (temp_df[\"No\"], total)]\nYes_s = [i\/j * 100 for i,j in zip(temp_df[\"Yes\"], total)]\n\nplt.figure(figsize=(15,8))\nplt.bar([\"Upper\", \"Middle\", \"Lower\"], No_s, color=\"Red\", edgecolor=\"white\", width = 0.6)\nplt.bar([\"Upper\", \"Middle\", \"Lower\"], Yes_s, bottom = No_s, color=\"Green\", edgecolor=\"white\", width = 0.6)","c86f166d":"plt.subplots(figsize=(15,8))\nsns.barplot(x=\"Pclass\", y=\"Survived\", linewidth = 6, capsize = .05, errcolor='blue', errwidth = 3,data=train_data)\nplt.title(\"Passenger survival rate - Socio-Economic class\", fontsize=25, pad=40)\nplt.ylabel(\"% of Passenger Survived\", fontsize=15)\nplt.xlabel(\"Socio-economic class\", fontsize=15)\nplt.xticks([0,1,2],[\"Upper\", \"Middle\", \"Lower\"])","ceaba0bb":"plt.figure(figsize=(15,8))\n\nax = sns.kdeplot(train_data.Pclass[train_data.Survived==0],color=\"grey\",shade=True, label=\"not survived\")\nax = sns.kdeplot(train_data.Pclass[train_data.Survived==1],color=\"g\",shade=True, label=\"survived\")\n\nplt.title(\"Passenger survival & non-survival rate - Socio-Economic class\", fontsize=25, pad=40)\nplt.ylabel(\"Percentage\", fontsize=15)\nplt.xlabel(\"Socio Economic Class\", fontsize=15)\nplt.xticks(sorted(train_data.Pclass.unique()), [\"Upper\", \"Middle\", \"Lower\"])","96f06fbd":"plt.figure(figsize=(15,8))\nsns.kdeplot(train_data.Age[train_data.Survived==1], data=train_data, color=\"g\", shade=True, label=\"survived\")\nsns.kdeplot(train_data.Age[train_data.Survived==0], data=train_data, color=\"grey\", shade=True, label=\"Not survieved\")\nplt.title(\"Passenger survival & non-survival rate - Age\", fontsize=25)\nplt.ylabel(\"Percentage\", fontsize=15)\nplt.xlabel(\"Age\", fontsize=15)","2c8492b9":"pal = {1:\"seagreen\", 0:\"grey\"}\ng = sns.FacetGrid( train_data,size=5,row=\"Survived\", col=\"Sex\", hue=\"Survived\", palette=pal)\ng = g.map(plt.hist, \"Age\", edgecolor=\"white\")\ng.fig.suptitle(\"Survived by Age and Sex\", size=25)\nplt.subplots_adjust(top=0.90)","2e533a5d":"g = sns.FacetGrid(train_data, row=\"Embarked\", col=\"Sex\", hue=\"Survived\", palette=pal, size=5)\ng = g.map(plt.hist, \"Age\", edgecolor=\"white\").add_legend();\ng.fig.suptitle(\"Survived by Embarked, Age and Sex\", size=25)\nplt.subplots_adjust(top=0.90)","5af32a2a":"g = sns.FacetGrid(train_data, hue=\"Survived\", col=\"Sex\", palette=pal, margin_titles=True, size=5)\ng = g.map(plt.scatter, \"Fare\", \"Age\", edgecolor=\"white\").add_legend()\ng.fig.suptitle(\"Survived by Sex, Age and Fare\", size=25)\nplt.subplots_adjust(top=0.85)","77828034":"train_data[\"Sex\"] = [1 if i == \"male\" else 0 for i in train_data[\"Sex\"]]","59c9316a":"train_data.corr()","dd40e158":"pd.DataFrame(abs(train_data.corr()[\"Survived\"]).sort_values(ascending=False))[1:]","69ecd45a":"import numpy as np\nmask = np.zeros_like(train_data.corr(),dtype=np.bool)\nmask[np.triu_indices_from(mask)]=True;\nplt.subplots(figsize = (15,12))\nsns.heatmap(train_data.corr(), \n            annot=True,\n            mask = mask,\n            cmap = 'RdBu', ## in order to reverse the bar replace \"RdBu\" with \"RdBu_r\"\n            linewidths=.9, \n            linecolor='white',\n            fmt='.2g',\n            center = 0,\n            square=True)\nplt.title(\"Correlations Among Features\", fontsize = 20, pad = 40);","ad8aca83":"train_data = pd.get_dummies(train_data, columns = ['Pclass', 'Cabin', 'Embarked'], drop_first=False)\ntest_data = pd.get_dummies(test_data, columns = ['Pclass', 'Cabin', 'Embarked'], drop_first=False)","d174cd83":"train_data.head()","47af9c1d":"test_data.head()","a2a7794f":"train_data['family_size'] = train_data.SibSp + train_data.Parch+1\ntest_data['family_size'] = test_data.SibSp + test_data.Parch+1\ntrain_data['is_alone'] = [1 if i < 2 else 0 for i in train_data.family_size] \ntest_data['is_alone'] = [1 if i < 2 else 0 for i in test_data.family_size] ","a6e6af6f":"train_data = pd.concat([train_data[[\"Survived\", \"Age\", \"Sex\",\"SibSp\",\"Parch\"]], train_data.loc[:,\"is_alone\":]], axis=1)\ntest_data = pd.concat([test_data[[\"Age\", \"Sex\"]], test_data.loc[:,\"SibSp\":]], axis=1)","56a37990":"train_data.head()","9beaef0f":"test_data['Sex'] = [1 if i == \"male\" else 0 for i in test_data.Sex]\ntest_data = test_data.drop(test_data.iloc[:, 4:89], axis=1)\ntest_data.head()\n","df0a8dbb":"train_data.loc[train_data[\"Age\"].isnull()]","b511b644":"from sklearn.ensemble import RandomForestRegressor\n\n## writing a function that takes a dataframe with missing values and outputs it by filling the missing values. \ndef completing_age(df):\n    ## gettting all the features except survived\n    age_df = df.loc[:,\"Age\":] \n    \n    temp_train = age_df.loc[age_df.Age.notnull()] ## df with age values\n    temp_test = age_df.loc[age_df.Age.isnull()] ## df without age values\n    \n    y = temp_train.Age.values ## setting target variables(age) in y \n    x = temp_train.loc[:, \"Sex\":].values\n    \n    rfr = RandomForestRegressor(n_estimators=1500, n_jobs=-1)\n    rfr.fit(x, y)\n    \n    predicted_age = rfr.predict(temp_test.loc[:, \"Sex\":])\n    \n    df.loc[df.Age.isnull(), \"Age\"] = predicted_age\n    \n\n    return df\n\n## Implementing the completing_age function in both train and test dataset. \ncompleting_age(train_data)\ncompleting_age(test_data);","960270e7":"train_data.head()","550d0958":"plt.subplots(figsize=(22,10))\nsns.distplot(train_data.Age, bins = 100, kde=True, rug=False, norm_hist=False)","ec103991":"X = train_data.drop([\"Survived\"], axis=1)\ny = train_data[\"Survived\"]","6027f55f":"X","f2205ac4":"y","90e11012":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y , test_size =0.4, random_state=0)","eaa5c95d":"from sklearn.preprocessing import StandardScaler\n\nstd_scaler = StandardScaler()\n\nX_train = std_scaler.fit_transform(X_train)\nX_test = std_scaler.transform(X_test)","b2bb5536":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix, classification_report\n\nlogreg = LogisticRegression(solver='liblinear',penalty= 'l1',random_state = 42)\nlogreg.fit(X_train, y_train)\n\ny_pred = logreg.predict(X_test)\n","61cedf86":"pd.DataFrame(confusion_matrix(y_test, y_pred), columns=[\"Predicted Not-Survived\", \"Predicted Survived\"], index=[\"Not-Survived\", \"Survived\"] )","1fd1877c":"## accuracy_score = (TP+TN) \/ total\n## precision_score = TP \/ (TP+FP)\n## recall_score = TP \/ (TP + FN)\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score\n\nprint(accuracy_score(y_pred, y_test))","351af977":"print(precision_score(y_pred, y_test))","e78fd94b":"print(recall_score(y_pred, y_test))","e2c2f4d3":"from sklearn.model_selection import GridSearchCV, StratifiedShuffleSplit\n\nc_vals = [0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9,1]\n\ncv = StratifiedShuffleSplit(n_splits=10, test_size=0.25)\n\nparam = {\"C\" : c_vals}\n\ngrid = GridSearchCV(estimator=LogisticRegression(),\n                   scoring = 'accuracy',\n                   cv =cv,\n                   param_grid = param,\n                   n_jobs=-1)\n\ngrid.fit(X,y)\n","e38d78ce":"print(grid.best_score_)","a64c1c4d":"print(grid.best_params_)","18ff5290":"print(grid.best_estimator_)","06d77afb":"logreg_grid = grid.best_estimator_\nlogreg_grid.score(X,y)","1264e321":"from sklearn.model_selection import GridSearchCV, StratifiedKFold, StratifiedShuffleSplit\nfrom sklearn.ensemble import RandomForestClassifier\n\nn_estimators = [140,145,150,155,160];\nmax_depth = range(1,10);\ncriterions = ['gini', 'entropy'];\ncv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=15)\n\nparameters = {'n_estimators':n_estimators,\n              'max_depth':max_depth,\n              'criterion': criterions}\n\ngrid = GridSearchCV(estimator=RandomForestClassifier(max_features='auto'),\n                   param_grid=parameters,\n                   cv=cv,\n                   n_jobs=-1)\n\ngrid.fit(X,y)","4afb26b2":"print(grid.best_score_)","7bfb99da":"print(grid.best_params_)","cb95ec37":"print(grid.best_estimator_)","4faac529":"rf_grid = grid.best_estimator_\nrf_grid.score(X,y)","eec3bdd3":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_pred))","2dd1250d":"feature_importance = pd.DataFrame(rf_grid.feature_importances_, columns=[\"importance\"], index=X.columns)\nfeature_importance.sort_values(by=\"importance\", ascending=False)","692400e6":"from sklearn.neighbors import KNeighborsClassifier\nknn_range = range(1,31)\ncv = StratifiedShuffleSplit(n_splits=10, test_size=0.3, random_state=15)\nweight_options = [\"uniform\", \"distance\"]\nparam = {'n_neighbors' : knn_range, 'weights' : weight_options}\ngrid = GridSearchCV(KNeighborsClassifier(), param, cv=cv, verbose=False, n_jobs=-1)\ngrid.fit(X,y)\n","2c0a0eac":"print(grid.best_score_)","2bed27fa":"print(grid.best_params_)","2223b64e":"print(grid.best_estimator_)","f855e85d":"knn_grid = grid.best_estimator_\nprint(knn_grid.score(X,y))","c37f39b5":"print(classification_report(y_pred, y_test))","4897bf20":"all_models = [logreg_grid, knn_grid, rf_grid]\n\nc = {}\nfor i in all_models:\n    a = i.predict(X_test)\n    b = accuracy_score(y_test, a)\n    c[i] = b","0fc19023":"c","94d1220d":"test_prediction = max(c, key=c.get).predict(test_data)\n\ntest_ori_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\nsubmission = pd.DataFrame({\n    \"PassengerId\" : test_ori_data.PassengerId,\n    \"Survived\" : test_prediction\n})\n\nsubmission.PassengerId = submission.PassengerId.astype(int)\nsubmission.Survived = submission.Survived.astype(int)\n\nsubmission.to_csv(\"titanic1_submission.csv\", index=False)","0023bbd2":"There is nothing special about this plot, it might indicate on the posibility that children and infants were the priority.","c446a492":"**Random Forest classifier with GridSearch**","4438e7fd":"# **Creating dummies variable for non-numeric, categorical values**","a548f419":"We can see the data like Cabin is 77% null , with this hight percentage of missing data, I might consider to drop the column instead. Now, I will start to handle those columns with less missing data like \"Embarked\" & \"Fare\", we can check if the the missing values can be estimated or predicted.","b2c5e438":"# **Correlation Matrix and Heatmap**","8ca017bc":"Among the socio economic classes,\n~ upper class : 63% of survivors \n~ Middle class \uff1a 48% of survivors\n~ Lower class : 25% of survivors","607f9b25":"# **Diagram analysis for each important feature and its survival rate**","19af20a7":"**Age and Survived**","90b0c923":"# **Data Modelling**","e8dfcde2":"Using boxplot to observe that Pclass = 1, Fare= 80, embarked is distributed in \"C\". We can assume that Miss Amelie and Mrs. Geroge Nelson were embarked at post \"C\".","df1496c1":"Now, let's check the test data record with Fare is null","cc44e354":"Based on the graph above, it indicates that the passengers'age are mostly within 20 -40.","1e2a0b5b":"Next, I am checking the percentage of the missing data in this dataset:\n","9223bc99":"# **Test prediction for survival**","f4f11817":"The relationship between survival rate and sex ","63990325":"***Sex and Age***","70988b1e":"***Pclass and survived***","c1281cbe":"***Gender and survived***","ac3991f7":"**Logistic Regression**","ee07fd91":"In each class, the survival rate is different as well depending on the socio economic level, passenger with lower socio-economic class has the leat survival rate while upper socio-sconomic class has higher survival rate. ","f03235bb":"The woman survival rate of this tragedy is very high, we will compare with man survival rate later.","d8422071":"Let's understand the data's feature:\n\n* PassengerId - unique id for each passenger who is on board\n* Pclass - indicates passenger class\n* Name - passenger's name\n* Sex - passenger's sex\n* Age - passenger's Age\n* SibSp - number of Siblings\/Spouses Aboard\n* Parch - Number of Parents\/Children Aboard\n* Embarked - implies where the traveler mounted from","bab1eb33":"***Sex, Age and Embarked***","025a4c9d":"**Logistic Regression with GridSearch**","18862d41":"***Correlations***","e7c18f4f":"Based on the plots above, we might be able to observe the age distribution for female and male passengers.","7dce8658":"The grid above clearly demonstrates the three outliers with Fare of over 500, most of the passengers were in the fare range of  100.","c36b84ed":"# **Diagram analysis for combined important features and corresponding survival rate**","44ed3bf7":"**K Nearest Neighbours classifier with Grid Search**","75bdef97":"***Sex, Age and Fare***","e31eba53":"For the non-numeric and non categorical data, we need to convert these data into dummies variables like numbers so that it can be calculated and understood by the machine.","2a5ce6c7":"From this heatmap, we only check with the features which have high correlationship with \"Survived\" (correlation >0.25)\n\nPositive correlation features:\nFare 0.26 \n\nNegative correlation features:\nSex -0.54\nPclass -0.34\n\nFrom the correlations above, it reveals that\n1. people who paid higher fare would likely be sruvived, which means higher socio economic class people were prioritised\n2. if you were a woman, you were likely to be survived\n3. if you were the first class people, you would have better chance to survive, this can be related to the 1st point of most of the survivors were paying higher fare.\n\n","ba1dc7c9":"We use random forest regressor to fill in the missing age values in the table","1714d485":"From the data above, the two passengers are both female, having same Pclass, Ticket number, Fare and Cabin. Based no that we can further predict their Embarked spot based on Pclass, Fare and Cabin. ","a7bb9bb3":"Based on the graphs above, we can observe that most passengers embarked at port S, perhaps the cities nearby port S were highly developed and richer as compared to port port C and post Q, therefore more people there were able to afford cruise.","b48675d9":"Female survival rate is musch higher than male, there are several possibilities:\n1. Most of the men were sacrificed when they tried to stop the cruise from sinking \/ rescue more victims in the cruise\n2. Woman were prioritised and sent to the escaping boats first with the children\n3. \"Gentlemen manner\""}}