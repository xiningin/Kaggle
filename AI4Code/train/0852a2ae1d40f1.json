{"cell_type":{"c1945bf0":"code","44d872ad":"code","2dfbe056":"code","e95415a8":"code","74dd4713":"code","b5134b80":"code","0edf395b":"code","52c18895":"code","7de5d338":"markdown","db6d1b10":"markdown","1b4aeaf6":"markdown","19f3cfb1":"markdown","15107ffb":"markdown","2fb5d352":"markdown","b15b0709":"markdown"},"source":{"c1945bf0":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport os\nfrom sklearn.tree import DecisionTreeRegressor\n\ntrain = pd.read_csv(\"..\/input\/train.csv\")\ntest = pd.read_csv(\"..\/input\/test.csv\")\nstructures = pd.read_csv(\"..\/input\/structures.csv\")\nprint(\"Training Set\")\nprint(\"Columns:\" + str(train.columns))\nprint(train.head())\nprint()\nprint(\"Test Set\")\nprint(test.head())\nprint()\nprint(\"Positional data for each molecule\")\nprint(structures.head())","44d872ad":"def merge_structural_data(df):\n    df = pd.merge(left=df, right=structures, how=\"left\", left_on=[\"molecule_name\",\"atom_index_0\"], right_on=[\"molecule_name\",\"atom_index\"])\n    df = df.rename(index=str, columns={\"x\":\"x_0\", \"y\":\"y_0\", \"z\":\"z_0\"})\n    df = pd.merge(left=df, right=structures, how=\"left\",left_on=[\"molecule_name\",\"atom_index_1\"],right_on=[\"molecule_name\",\"atom_index\"])\n    df = df.rename(index=str, columns={\"x\":\"x_1\", \"y\":\"y_1\", \"z\":\"z_1\",\"atom_x\":\"atom_0\",\"atom_y\":\"atom_1\"})\n    df = df.drop(columns=[\"atom_index_x\",\"atom_index_y\"])\n    return df\n\ndef euclid_dist(df):\n    def dist(row):\n        x_i = (row['x_0'] - row['x_1'])**2\n        y_i = (row['y_0'] - row['y_1'])**2\n        z_i = (row['z_0'] - row['z_1'])**2\n        dist = (x_i + y_i + z_i)**0.5\n        return dist\n    df['distance'] = df.apply(lambda x: dist(x), axis=1)\n    return df\n\ndef num_atoms(df):\n    molecule_sizes = pd.DataFrame(structures['molecule_name'].value_counts()).rename(index=str, columns={\"molecule_name\":\"atom_count\"})\n    molecule_sizes = molecule_sizes.sort_index()\n    molecule_sizes['mol_name'] = molecule_sizes.index\n    df = pd.merge(left=df, right=molecule_sizes, how=\"left\", left_on=\"molecule_name\", right_on=\"mol_name\")\n    df = df.drop(columns=[\"mol_name\"])\n    return df\n    \ndef num_ele(df):\n    for ele in structures['atom'].unique():\n        ele_filtered = structures[structures['atom'] == ele]\n        ele_num = pd.DataFrame(ele_filtered['molecule_name'].value_counts())\n        ele_num = ele_num.rename(columns={'molecule_name':ele})\n        ele_num['mol_nam'] = ele_num.index\n        df = pd.merge(left=df, right=ele_num, how='left', left_on='molecule_name', right_on='mol_nam')\n        df = df.fillna(0)\n    return df\n\ndef type_dummies(df):\n    df = pd.concat([df, pd.get_dummies(df['type'])], axis=1)\n    return df\n\n#This function was taken from: \"https:\/\/www.kaggle.com\/uberkinder\/efficient-metric\"\ndef group_mean_log_mae(y_true, y_pred, groups, floor=1e-9):\n    maes = (y_true-y_pred).abs().groupby(groups).mean()\n    return np.log(maes.map(lambda x: max(x, floor))).mean()","2dfbe056":"train = merge_structural_data(train)\ntest = merge_structural_data(test)\n\ntrain = euclid_dist(train)\ntest = euclid_dist(test)\n\ntrain = num_atoms(train)\ntest = num_atoms(test)\n\ntrain = num_ele(train)\ntest = num_ele(test)\n\ntrain = type_dummies(train)\ntest = type_dummies(test)","e95415a8":"train_plot_data = train.loc[:,['distance','scalar_coupling_constant','type','atom_count']]\nfig, ax = plt.subplots(figsize=(20,12))\nsns.scatterplot(x='distance', y='scalar_coupling_constant', data=train_plot_data, hue='type')","74dd4713":"fig, ax = plt.subplots(figsize=(20,12))\nsns.scatterplot(x='atom_count', y='scalar_coupling_constant', data=train_plot_data, hue='type')","b5134b80":"X_train = train.loc[:,['distance','x_0', 'y_0', 'z_0','x_1', 'y_1', 'z_1','atom_count','1JHC','1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN','H','C', 'N', 'O', 'F']]\ny_train = train.loc[:,'scalar_coupling_constant']\n\nX_test = test.loc[:,['distance','x_0', 'y_0', 'z_0','x_1', 'y_1', 'z_1','atom_count','1JHC','1JHN', '2JHC', '2JHH', '2JHN', '3JHC', '3JHH', '3JHN', 'H','C', 'N', 'O', 'F']]\n\nmodel = DecisionTreeRegressor(random_state = 0)\nmodel.fit(X_train,y_train)\n\ntrain_predictions = model.predict(X_train)\ntest_predictions = model.predict(X_test)","0edf395b":"training_error = group_mean_log_mae(y_train,train_predictions,train['type'])\nprint(\"training error: \" + str(training_error))\n\nfig, ax = plt.subplots(figsize=(10,7))\nsns.scatterplot(y_train, train_predictions)\n\nfor coupl in train['type'].unique():\n    fig, ax = plt.subplots(figsize=(10,7))\n    sns.scatterplot(train_predictions[X_train[coupl] == 1], y_train[X_train[coupl] == 1])\n    plt.title(coupl)\n    plt.show()","52c18895":"test_predictions_df = pd.DataFrame(test_predictions)\ntest_predictions_df['id'] = test['id']\ntest_predictions_df['scalar_coupling_constant'] = test_predictions_df.iloc[:,0]\ntest_predictions_df = test_predictions_df.drop([0],axis=1)\nprint(test_predictions_df.columns)\nprint(test_predictions_df.shape)\ntest_predictions_df.to_csv(\"prediction_file.csv\", index=False)","7de5d338":"<img src=\"https:\/\/i.imgur.com\/1jGXP8L.png\" width=\"500px\">","db6d1b10":"So it seems we have the molecules that the coupling pairs are in, the (x,y,z) position of each atom, the element of each atom in the molecule, and the coupling type, where the type encodes what atom the hydrogen is coupling to and through how many bonds. (e.g. type: 2JHC would mean that a hydrogen \"H\" has coupled through 2 bonds to a Carbon \"C\"). Unfortunately we have no information on the bonds within the molecules so we lose out on bond angles and bond types, however we can try and approximate the bond angles\/types by counting the number of each element in each molecule (more hydrogens to carbons would indicate less double\/triple bonds and vice versa). ","1b4aeaf6":"This is an initial foray into the data provided, and is intended as a benchmark to build off of, with that said, lets begin by importing our data and relevant libraries to get a sense for how it is structured and what information we might be able to glean from it.","19f3cfb1":"We're just going to start off with a basic decision tree regression and then experiment with more sophisticated models in the future.","15107ffb":"While this model does beat out the euclidean distance benchmark, it doesn't beat it by a lot and is very overfit, so we will need to construct more sophisticated descriptors for the molecules to feed into our model. These will descriptors will most likely need to better capture the aspects listed in scalar_coupling_contributions.csv, - more research is required. I will be updating this kernel as I come up with better features, let me know if there's anything obvious I have missed. :)","2fb5d352":"Lets look to see how well our model is fitting to the training data for each coupling type.","b15b0709":"Our model seems to fit quite well to the training set, it is most likely very overfit given the fact the training error is ~-13 and the best models on the leader board only achieved an error of ~-1.7"}}