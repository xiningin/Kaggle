{"cell_type":{"577200d9":"code","ee592fff":"code","9bde08c8":"code","2cdd9f91":"code","c01d0fc4":"code","b4e07898":"code","d19139de":"code","4e971a62":"code","1a7eb826":"code","ba34dc93":"code","51e0a9f1":"code","e77982fe":"code","7dfb24af":"code","a1b3079d":"code","b5cc736d":"code","db29fb23":"code","083dceec":"markdown","ee01a50c":"markdown","ea959649":"markdown","39cd16e9":"markdown","69cc277f":"markdown","61eab1c8":"markdown","5827ff9f":"markdown","c41f095c":"markdown","ee86e8db":"markdown","fd1aaef8":"markdown","7bb19556":"markdown","c52a6a23":"markdown","38afd5a3":"markdown","78e65c2f":"markdown","5fde459d":"markdown","82a9b510":"markdown"},"source":{"577200d9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ee592fff":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pandas as pd\nfrom sklearn.model_selection import train_test_split\n\nfruit= pd.read_csv('..\/input\/fruits\/fruit_data_with_colors _1_.csv')\nfruit.head()\n","9bde08c8":"fruit['fruit_name'].unique()","2cdd9f91":"#examine the null variable\nfruit.isnull().sum()","c01d0fc4":"#replace the missing data by the average of its column\nfruit['mass']=fruit['mass'].fillna(fruit['mass'].mean())\nfruit['height']=fruit['height'].fillna(fruit['height'].mean())","b4e07898":"fruit.isnull().sum()","d19139de":"# plotting a scatter matrix\nfrom matplotlib import cm\nfrom pandas.plotting import scatter_matrix\n\nX = fruit[['height', 'width', 'mass', 'color_score']]\ny = fruit['fruit_label']\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)\n\ncmap = cm.get_cmap('gnuplot')\nscatter =pd.plotting.scatter_matrix(X_train, c= y_train, marker = 'o', s=40, hist_kwds={'bins':15}, figsize=(9,9), cmap=cmap)","4e971a62":"# plotting a 3D scatter plot\nfrom mpl_toolkits.mplot3d import Axes3D\n\nfig= plt.figure(figsize=(10,8))\nax = fig.add_subplot(111, projection = '3d')\nax.scatter(X_train['width'], X_train['height'], X_train['color_score'], c = y_train, marker = 'o', s=100)\nax.set_xlabel('width')\nax.set_ylabel('height')\nax.set_zlabel('color_score')\nplt.show()","1a7eb826":"# For this example, we use the mass, width, and height features of each fruit instance\nX = fruit[['mass', 'width', 'height']]\ny = fruit['fruit_label']\n\n# default is 75% \/ 25% train-test split\nX_train, X_test, y_train, y_test = train_test_split(X, y, random_state=0)","ba34dc93":"from sklearn.neighbors import KNeighborsClassifier\n\nknn = KNeighborsClassifier(n_neighbors = 5)","51e0a9f1":"knn.fit(X_train, y_train)","e77982fe":"knn.score(X_test, y_test)","7dfb24af":"# first example: a small fruit with mass 30g, width 5.3 cm, height 4.5 cm\nfruit_prediction = knn.predict([[30, 5.3, 4.5]])\nfruit_number=fruit_prediction[0]\nif fruit_number == 1:\n    print('apple')\nelif fruit_number==2:\n    print('mandarin')\nelif fruit_number==3:\n    print('lemon')\nelse:\n    print('organge')","a1b3079d":"# second example: 120g, width 7.7 cm, height 8.5 cm\nfruit_prediction = knn.predict([[120, 7.7, 8.5]])\nfruit_number=fruit_prediction[0]\nif fruit_number == 1:\n    print('apple')\nelif fruit_number==2:\n    print('mandarin')\nelif fruit_number==3:\n    print('lemon')\nelse:\n    print('organge')","b5cc736d":"#set the k ranges from 1 to 20\nk_range = range(1,20)\nscores = []\n\nfor k in k_range:\n    knn = KNeighborsClassifier(n_neighbors = k)\n    knn.fit(X_train, y_train)\n    scores.append(knn.score(X_test, y_test))\n\nplt.figure(figsize=(10,8))\nplt.xlabel('k')\nplt.ylabel('accuracy')\nplt.scatter(k_range, scores)\nplt.xticks([0,5,10,15,20])\nplt.show()","db29fb23":"#set the train-test split run from 20 % to 80% \nt = [0.8, 0.7, 0.6, 0.5, 0.4, 0.3, 0.2]\n\nknn = KNeighborsClassifier(n_neighbors = 5)\n\nplt.figure(figsize=(10,8))\n\nfor s in t:\n\n    scores = []\n    for i in range(1,1000):\n        X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 1-s)\n        knn.fit(X_train, y_train)\n        scores.append(knn.score(X_test, y_test))\n    plt.plot(s, np.mean(scores), 'bo')\n\nplt.xlabel('Training set proportion (%)')\nplt.ylabel('accuracy')\nplt.show()","083dceec":"# Use the trained k-NN classifier model to classify new objects","ee01a50c":"# Examining the data","ea959649":"# Train the classifier using the training data","39cd16e9":"# How the choice of the 'k' parameter affect k-NN classification accuracy?","69cc277f":"# How the train\/test split proportion affect k-NN classification accuracy?","61eab1c8":"# Replace the Missing Data","5827ff9f":"# Create classifier object","c41f095c":"Credit: University of Michigan","ee86e8db":"Purpose of this notebook: \nUsing the KNN classication to exam which fruit species base on its mass, width, heigh and color","fd1aaef8":"the higher training set propotion, the better knn-classification accuracy","7bb19556":"# Import Library and load data file","c52a6a23":"The file contains the mass, height, and width of a selection of oranges, lemons and apples. The heights were measured along the core of the fruit. The widths were the widest width perpendicular to the height","38afd5a3":"# Create train-test split","78e65c2f":"k parameter <=5 shows the best accuracy ","5fde459d":"# THE END","82a9b510":"# Estimate the accuracy of the classifier on future data, using the test data"}}