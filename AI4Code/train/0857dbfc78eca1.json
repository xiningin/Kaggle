{"cell_type":{"dcd5cf0e":"code","e0077768":"code","462c36a9":"code","4f439fc1":"code","865bdc48":"code","79108f55":"code","48b01ac5":"code","27f7db7b":"code","67747f85":"code","19ba9b74":"code","6bf58596":"code","7f23b00f":"code","7e4fb5af":"code","507de6b3":"code","6494ebfd":"code","8cc89fe9":"code","e6ef50c0":"code","2c68e230":"code","2717f8d4":"code","fedd6176":"code","09611cc8":"code","22e038da":"code","0d11ff58":"code","829aaad3":"code","6105e4fa":"code","060ad7f1":"code","2858b6dd":"code","e9759d5c":"markdown","6ce29041":"markdown","9abd5c0c":"markdown","934141b9":"markdown","e9d3a263":"markdown","7f0f5234":"markdown","5a8c4a75":"markdown","7c700d59":"markdown","e20a1e40":"markdown","e39ad01c":"markdown","b88b1f42":"markdown","edbd87e1":"markdown","39dc6b67":"markdown","78df961e":"markdown","1c5158bb":"markdown","89381a4a":"markdown","71c14600":"markdown","6562ba87":"markdown","f9bb9743":"markdown","914d5f14":"markdown","8f49903a":"markdown","7c3885c8":"markdown","8dd8f948":"markdown","43833a2a":"markdown","5d37351a":"markdown","699c1aa8":"markdown","661d03ad":"markdown"},"source":{"dcd5cf0e":"# Importing the libraries\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import classification_report\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.naive_bayes import GaussianNB\nfrom pandas.plotting import scatter_matrix\nfrom sklearn.feature_selection import RFE\nfrom sklearn import model_selection\nimport matplotlib.pyplot as plt\nfrom sklearn.svm import SVC\nimport seaborn as sns\nimport pandas as pd\nimport numpy as np","e0077768":"# Importing the dataset  \ndataset = pd.read_csv('..\/input\/Admission_Predict.csv', sep=',')","462c36a9":"dataset.info()","4f439fc1":"dataset = dataset.drop([\"Serial No.\"], axis=1)","865bdc48":"print(dataset.columns)","79108f55":"dataset.rename(columns = {'Chance of Admit ':'Chance of Admit'}, inplace = True)","48b01ac5":"dataset.describe()","27f7db7b":"dataset.head()","67747f85":"dataset.plot(kind='box', subplots=True, layout=(4,3), figsize=(80, 80), sharex=False, sharey=False)\nplt.show()","19ba9b74":"dataset.hist(figsize=(20, 20))\nplt.show()","6bf58596":"sm = scatter_matrix(dataset, alpha=0.2, figsize=(20, 20), diagonal='kde')\n\n# Change label rotation\n[s.xaxis.label.set_rotation(45) for s in sm.reshape(-1)]\n[s.yaxis.label.set_rotation(0) for s in sm.reshape(-1)]\n\n# May need to offset label when rotating to prevent overlap of figure\n[s.get_yaxis().set_label_coords(-0.3,0.5) for s in sm.reshape(-1)]\n\n# Hide all ticks\n[s.set_xticks(()) for s in sm.reshape(-1)]\n[s.set_yticks(()) for s in sm.reshape(-1)]\n\nplt.show()\n","7f23b00f":"correlation = dataset.corr()\nplt.figure(figsize=(14, 12))\nheatmap = sns.heatmap(correlation, annot=True, linewidths=0, vmin=-1, cmap=\"RdBu_r\")","7e4fb5af":"# Create a new dataframe containing only TOEFL Score and GRE Score columns to visualize their co-relations\ntoefl_gre = dataset[['TOEFL Score', 'GRE Score']]\n\n# Initialize a joint-grid with the dataframe, using seaborn library\ngridA = sns.JointGrid(x=\"GRE Score\", y=\"TOEFL Score\", data=toefl_gre, height=6)\n\n# Draws a regression plot in the grid \ngridA = gridA.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\n\n# Draws a distribution plot in the same grid\ngridA = gridA.plot_marginals(sns.distplot)","507de6b3":"cgpa_admit = dataset[['CGPA', 'Chance of Admit']]\ngridB = sns.JointGrid(x=\"Chance of Admit\", y=\"CGPA\", data=cgpa_admit, height=6)\ngridB = gridB.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\ngridB = gridB.plot_marginals(sns.distplot)","6494ebfd":"cgpa_gre = dataset[['CGPA', 'GRE Score']]\ngridB = sns.JointGrid(x=\"GRE Score\", y=\"CGPA\", data=cgpa_gre, height=6)\ngridB = gridB.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\ngridB = gridB.plot_marginals(sns.distplot)","8cc89fe9":"cgpa_toefl = dataset[['CGPA', 'TOEFL Score']]\ngridB = sns.JointGrid(x=\"TOEFL Score\", y=\"CGPA\", data=cgpa_toefl, height=6)\ngridB = gridB.plot_joint(sns.regplot, scatter_kws={\"s\": 10})\ngridB = gridB.plot_marginals(sns.distplot)","e6ef50c0":"fig, axs = plt.subplots(ncols=1,figsize=(10,6))\nsns.barplot(x='TOEFL Score', y='CGPA', data=cgpa_toefl, ax=axs)\nplt.title('TOEFL Score VS CGPA')\n\nplt.tight_layout()\nplt.show()\nplt.gcf().clear()","2c68e230":"fig, axs = plt.subplots(ncols=1,figsize=(20,12))\nsns.barplot(x='CGPA', y='Chance of Admit', data=cgpa_admit, ax=axs)\nplt.title('CGPA VS Chance of Admit')\n\nplt.tight_layout()\nplt.show()\nplt.gcf().clear()","2717f8d4":"# Defining the splits for categories. 0 to 0.49 will be \"Rejected\" result, 0.5 to 1 will be \"Accepted\"\nbins = [0,0.49,1]\n\n\nadmission_labels=[\"Rejected\", \"Accepted\"]\ndataset['admission_categorical'] = pd.cut(dataset['Chance of Admit'], bins=bins, labels=admission_labels, include_lowest=True)\n\ndisplay(dataset.head(n=20))\n\n# Split the data into features and target label\nadmission_raw = dataset['admission_categorical']\nfeatures_raw = dataset.drop(['Chance of Admit', 'admission_categorical'], axis = 1)","fedd6176":"# Import train_test_split\nfrom sklearn.model_selection import train_test_split\n\n# Split the 'features' and 'income' data into training and testing sets\nX_train, X_test, y_train, y_test = train_test_split(features_raw, \n                                                    admission_raw, \n                                                    test_size = 0.2, \n                                                    random_state = 0)\n\n# Show the results of the split\nprint(\"Training set contains {} elements.\".format(X_train.shape[0]))\nprint(\"Test set contains {} elements.\".format(X_test.shape[0]))","09611cc8":"# 10-fold cross validation\n# Test options and evaluation metric\nseed = 7\n# Using metric accuracy to measure performance\nscoring = 'accuracy' \n\n# Spot Check Algorithms\nmodels = []\nmodels.append(('LR', LogisticRegression(solver='saga', multi_class='ovr')))\nmodels.append(('DT', DecisionTreeClassifier(criterion = 'entropy', random_state = 0)))\nmodels.append(('RF', RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)))\nmodels.append(('KNN', KNeighborsClassifier()))\nmodels.append(('NB', GaussianNB()))\nmodels.append(('SVM', SVC(gamma='auto')))\n\n# evaluate each model in turn\nresults = []\nnames = []\nfor name, model in models:\n\tkfold = model_selection.KFold(n_splits=10, random_state=seed)\n\tcv_results = model_selection.cross_val_score(model, X_train, y_train, cv=kfold, scoring=scoring)\n\tresults.append(cv_results)\n\tnames.append(name)\n\tmsg = \"%s: %f (%f)\" % (name, cv_results.mean(), cv_results.std())\n\tprint(msg)","22e038da":"# Compare Algorithms\nfig = plt.figure(\"Algorithms comparison\")\nax = fig.add_subplot(111)\nplt.boxplot(results)\nax.set_xticklabels(names)\nplt.show()","0d11ff58":"# Make predictions on validation dataset\nclassifier = RandomForestClassifier(n_estimators = 100, criterion = 'entropy', random_state = 0)\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(\"###\")\nprint(confusion_matrix(y_test,  y_pred))\nprint(\"###\")\nprint(classification_report(y_test,  y_pred))","829aaad3":"# Make predictions on validation dataset\nclassifier = SVC(gamma='auto')\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(\"####\")\nprint(confusion_matrix(y_test,  y_pred))\nprint(\"###\")\nprint(classification_report(y_test,  y_pred))","6105e4fa":"# Make predictions on validation dataset\nclassifier = KNeighborsClassifier()\nclassifier.fit(X_train, y_train)\ny_pred = classifier.predict(X_test)\nprint(accuracy_score(y_test, y_pred))\nprint(\"###\")\nprint(confusion_matrix(y_test,  y_pred))\nprint(\"###\")\nprint(classification_report(y_test,  y_pred))","060ad7f1":"# Confusion matrix\nlabels = ['Rejected', 'Accepted']\ncm = confusion_matrix(y_test, y_pred, labels)\nfig = plt.figure()\nax = fig.add_subplot(111)\ncax = ax.matshow(cm)\nplt.title('Confusion matrix of the KNN classifier')\nfig.colorbar(cax)\nax.set_xticklabels([''] + labels)\nax.set_yticklabels([''] + labels)\nplt.xlabel('Predicted')\nplt.ylabel('True')\nplt.show()","2858b6dd":"from sklearn.externals import joblib\njoblib.dump(classifier, 'knn_admission.joblib')","e9759d5c":"## Data Preparation","6ce29041":"* CGPA and GRE Score","9abd5c0c":"### Dataframe for specific features","934141b9":"There's an extra space for the column \"Chance of Admit\". Let's get rid of it.","e9d3a263":"When CGPA increase, Chance of Admit also increase.","7f0f5234":"## Predictions","5a8c4a75":"The algorithms we'll be using are : \n* Logistic regression\n* Decision tree\n* Random forest\n* K-Nearest Neighbors (K-NN)\n* Naive bayes\n* Support Vector Machine (SVM)","7c700d59":"### KNN","e20a1e40":"* CGPA and Chance of Admit","e39ad01c":"### Random Forest","b88b1f42":"### SVM","edbd87e1":"### Scatter plot matrix","39dc6b67":"* TOEFL Score and GRE Score","78df961e":"We can display a heat map to see the corelation between features.","1c5158bb":"### Box and whisker plots","89381a4a":"# Save model","71c14600":"Here, we choosed to apply some transforms to convert our regression problem into a classification problem.","6562ba87":"* CGPA and TOEFL Score","f9bb9743":"### Histograms","914d5f14":"### Visualize relationships with bar plots","8f49903a":"## K-fold cross validation","7c3885c8":"### Heat map","8dd8f948":"# Visualize data","43833a2a":"## Splitting the data","5d37351a":"# Training the models","699c1aa8":"We don't need the Searial number feature. ","661d03ad":"The chances of admission are given with two decimal places. We are therefore sure not to have a value like \"0.499\". The data can therefore be separated so that up to 0.49 (less than 50%) the result is \"Rejected\" and from 0.50 to 1, it is \"Accepted\"."}}