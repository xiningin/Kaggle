{"cell_type":{"e426353d":"code","8c949f92":"code","b425e404":"code","df4421d2":"code","0050c951":"code","705ee9cc":"code","7deb5f16":"code","cdb96714":"code","8a2912f6":"code","303bad5c":"code","4ccd77db":"code","29112f2d":"code","6ac1f95c":"code","baf448b2":"code","139a39c2":"code","383dde27":"code","923b601c":"code","166f23e3":"code","7c5fc814":"code","caf34eaf":"code","0cc2bc12":"code","86fb85fa":"code","71268393":"code","cc02f42d":"code","d7d29994":"code","2d12395e":"code","b9d56e38":"code","6e421019":"code","243aa2c7":"code","4b7195f1":"code","5b1f64b2":"code","793d6350":"code","6c30e162":"markdown","0d0250ce":"markdown","f99b9a1d":"markdown","9ba81564":"markdown","1d2e1372":"markdown","0841038d":"markdown","c293eab1":"markdown","4fe880ac":"markdown","192dc548":"markdown","2f1a743f":"markdown","ce7f3563":"markdown","ae705869":"markdown","6eab3e8d":"markdown","4ac95a9d":"markdown","00a3af88":"markdown","942f7809":"markdown","b05bd9dd":"markdown","87a35b50":"markdown","a04e458e":"markdown","bbb03d49":"markdown","5085a038":"markdown","4dbae43e":"markdown","ddaaee6b":"markdown","dc8aafed":"markdown","fce356e2":"markdown","751e608f":"markdown","4251500f":"markdown","dd300270":"markdown","4ca46b62":"markdown","ca411e35":"markdown","50fa16ce":"markdown","13195898":"markdown","7cdb9de9":"markdown","72c2d8c3":"markdown","1a0ae73c":"markdown","000bf6bb":"markdown","370ee4ae":"markdown","ea982751":"markdown","54892c88":"markdown"},"source":{"e426353d":"# Tensorflow installation\n!pip install tensorflow==2.3.0 -q","8c949f92":"# Libraries importation\nimport os # operating system interfaces\nfrom os.path import join\nfrom glob import glob\nimport numpy as np # scientific computing\nimport pandas as pd # data analysis\nimport tensorflow as tf\nfrom kaggle_datasets import KaggleDatasets\nimport matplotlib.pyplot as plt # plots\nimport PIL # image files manipulation\nimport random\n\n# callback to reduce learning rate\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\n\n# opencv to handle images (https:\/\/opencv.org\/releases\/)\nimport cv2 as cv\n\n# print metrics\nfrom sklearn.metrics import accuracy_score, balanced_accuracy_score, roc_auc_score, \\\n    confusion_matrix, precision_score, recall_score, f1_score\nimport seaborn as sns\n\n\ntry:\n    tpu = tf.distribute.cluster_resolver.TPUClusterResolver()\n    print('Device:', tpu.master())\n    tf.config.experimental_connect_to_cluster(tpu)\n    tf.tpu.experimental.initialize_tpu_system(tpu)\n    strategy = tf.distribute.experimental.TPUStrategy(tpu)\nexcept:\n    strategy = tf.distribute.get_strategy()\nprint('Number of replicas:', strategy.num_replicas_in_sync)\n    \nprint(tf.__version__)","b425e404":"AUTOTUNE = tf.data.experimental.AUTOTUNE # automatic paralleling computing\nBATCH_SIZE = 32 * strategy.num_replicas_in_sync\nIMAGE_SIZE = [176, 208]\nEPOCHS = 50 # reduced from 100 because of no significant improvement after 50th epoch","df4421d2":"data_folder = \"..\/input\/alzheimer-mri-4-classes-dataset\/Alzheimer_MRI_4_classes_dataset\"\n\n## images NonDemented\ndf_NonDemented_imgs = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"NonDemented\", \"*\"))),\n    \"y\": 0,\n    \"class\": \"NonDementia\"\n})\nshuffled_non = df_NonDemented_imgs.sample(frac=1)\ntestsize_non = int(0.2 * len(shuffled_non))\n# Test\nnon_test = shuffled_non[:testsize_non]\n# Train and validation\nnon_trainval = shuffled_non[testsize_non:]\ntrainsize_non = int(0.8 * len(non_trainval))\n# Train\nshuffled_non_train = non_trainval[:trainsize_non]\n#Validation\nshuffled_non_val = non_trainval[trainsize_non:]\n\n\n## images VeryMildDemented\ndf_VeryMildDemented_imgs = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"VeryMildDemented\", \"*\"))),\n    \"y\": 1,\n    \"class\": \"VeryMildDementia\"\n})\nshuffled_verymild = df_VeryMildDemented_imgs.sample(frac=1)\ntestsize_verymild = int(0.2 * len(shuffled_verymild))\n\n# Test\nverymild_test = shuffled_verymild[:testsize_verymild]\n\n# Train and validation\nverymild_trainval = shuffled_verymild[testsize_verymild:]\ntrainsize_verymild = int(0.8 * len(verymild_trainval))\n\n# Train\nshuffled_verymild_train = verymild_trainval[:trainsize_verymild]\n\n#Validation\nshuffled_verymild_val = verymild_trainval[trainsize_verymild:]\n\n\n## images MildDemented\ndf_MildDemented_imgs = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"MildDemented\", \"*\"))),\n    \"y\": 2,\n    \"class\": \"MildDementia\"\n})\nshuffled_mild = df_MildDemented_imgs.sample(frac=1)\ntestsize_mild = int(0.2 * len(shuffled_mild))\n\n# Test\nmild_test = shuffled_mild[:testsize_mild]\n\n# Train and validation\nmild_trainval = shuffled_mild[testsize_mild:]\ntrainsize_mild = int(0.8 * len(mild_trainval))\n\n# Train\nshuffled_mild_train = mild_trainval[:trainsize_mild]\n\n#Validation\nshuffled_mild_val = mild_trainval[trainsize_mild:]\n\n## images ModerateDemented\ndf_ModerateDemented_imgs = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"ModerateDemented\", \"*\"))),\n    \"y\": 3,\n    \"class\": \"ModerateDementia\"\n})\nshuffled_moderate = df_ModerateDemented_imgs.sample(frac=1)\ntestsize_moderate = int(0.2 * len(shuffled_moderate))\n\n# Test\nmoderate_test = shuffled_moderate[:testsize_moderate]\n\n# Train and validation\nmoderate_trainval = shuffled_moderate[testsize_moderate:]\ntrainsize_moderate = int(0.8 * len(moderate_trainval))\n\n# Train\nshuffled_moderate_train = moderate_trainval[:trainsize_moderate]\n\n#Validation\nshuffled_moderate_val = moderate_trainval[trainsize_moderate:]\n\n\n## Number of images\nprint(\"TOTAL:\")\nprint(\"# of images with NonDemented Alzheimer =\", len(shuffled_non))\nprint(\"# of images with VeryMildDemented Alzheimer =\", len(shuffled_verymild))\nprint(\"# of images with MildDemented Alzheimer =\", len(shuffled_mild))\nprint(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate))\nprint(\"------------\")\nprint(\"\\nTest:\")\nprint(\"# of images with NonDemented Alzheimer =\", len(non_test))\nprint(\"# of images with VeryMildDemented Alzheimer =\", len(verymild_test))\nprint(\"# of images with MildDemented Alzheimer =\", len(mild_test))\nprint(\"# of images with ModerateDemented Alzheimer =\", len(moderate_test))\nprint(\"------------\")\nprint(\"\\nTraining:\")\nprint(\"# of images with NonDemented Alzheimer =\", len(shuffled_non_train))\nprint(\"# of images with VeryMildDemented Alzheimer =\", len(shuffled_verymild_train))\nprint(\"# of images with MildDemented Alzheimer =\", len(shuffled_mild_train))\nprint(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate_train))\nprint(\"------------\")\nprint(\"\\nValidation:\")\nprint(\"# of images with NonDemented Alzheimer =\", len(shuffled_non_val))\nprint(\"# of images with VeryMildDemented Alzheimer =\", len(shuffled_verymild_val))\nprint(\"# of images with MildDemented Alzheimer =\", len(shuffled_mild_val))\nprint(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate_val))","0050c951":"# show class imbalance in the dataset\n\nheights = [len(shuffled_non), len(shuffled_verymild), len(shuffled_mild), len(shuffled_moderate)]\n\nfig, ax = plt.subplots()\nheight = heights\nbars = ('Non', 'Very Mild', 'Mild', 'Moderate')\ny_pos = np.arange(len(bars))\nplt.bar(y_pos, height)\nplt.xticks(y_pos, bars)\nplt.show()","705ee9cc":"def load_image(fname):\n    \"\"\"\n    Load an image using opencv given its path.\n    \"\"\"\n    # img is a numpy array\n    img = cv.imread(fname)\n    # opencv uses BGR channel order by default\n    # so convert to RGB\n    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n    # resize image\n    resize = (IMAGE_SIZE[0], IMAGE_SIZE[1])\n    img = cv.resize(img, resize)\n    return img\n\ndef hot_array(class_number):\n    ha = [0,0,0,0]\n    ha[class_number] = 1\n    return ha","7deb5f16":"## TRAIN SET\n# concatenate\ntrain_concat = pd.concat([shuffled_mild_train, shuffled_moderate_train, shuffled_non_train, shuffled_verymild_train])\n# shuffle\ntrain_concat = train_concat.sample(frac=1)\n# load image\ntrain_concat[\"X\"] = train_concat[\"X\"].apply(load_image)\n\n# extract label before one hot in order to use for class weights\ny_train_lab = train_concat[\"y\"]\ny_train_lab = np.array(y_train_lab) # convert into a numpy array\n\n# apply one-hot encoding\ntrain_concat[\"y\"] = train_concat[\"y\"].apply(hot_array)\n\n# stack images and labels\nxtrain = np.stack(train_concat[\"X\"])\nytrain = np.stack(train_concat[\"y\"])\n\n\n## VALIDATION SET\nval_concat = pd.concat([shuffled_mild_val, shuffled_moderate_val, shuffled_non_val, shuffled_verymild_val])\nval_concat = val_concat.sample(frac=1)\nval_concat[\"X\"] = val_concat[\"X\"].apply(load_image)\nval_concat[\"y\"] = val_concat[\"y\"].apply(hot_array)\nxval = np.stack(val_concat[\"X\"])\nyval = np.stack(val_concat[\"y\"])","cdb96714":"# plot some images per class\n\nncols = 10\n\nfig, axs = plt.subplots(nrows=4, ncols=ncols, figsize=(20, 10))\n\nfor fname,ax in zip(shuffled_non.loc[:ncols, \"X\"], axs[0,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n\nfor fname,ax in zip(shuffled_verymild.loc[:ncols, \"X\"], axs[1,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n    \nfor fname,ax in zip(shuffled_mild.loc[:ncols, \"X\"], axs[2,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n\nfor fname,ax in zip(shuffled_moderate.loc[:ncols, \"X\"], axs[3,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n\naxs[0,0].set_ylabel(\"Non Dementia\")\naxs[1,0].set_ylabel(\"Very Mild Dementia\")\naxs[2,0].set_ylabel(\"Mild Dementia\")\naxs[3,0].set_ylabel(\"Moderate Dementia\")","8a2912f6":"# Convolutional Block\ndef conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='elu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='elu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ]\n    )\n    \n    return block\n\n# Dense Block\ndef dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='elu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    \n    return block\n\n# Function to build the model\ndef build_model():\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(*IMAGE_SIZE, 3)),\n        \n        tf.keras.layers.Conv2D(16, 3, activation='elu', padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation='elu', padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(4, activation='softmax')\n    ])\n    \n    return model","303bad5c":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [tf.keras.metrics.AUC(name='auc')]\n    \n    model.compile(\n        # choose Adam as the optimizer with initial learning rate = 0.001\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        \n        loss=tf.losses.CategoricalCrossentropy(),\n        metrics=METRICS\n    )","4ccd77db":"checkpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model.h5\",\n                                                    save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=10,\n                                                     restore_best_weights=True)\n\n# reduce the learning rate when there is a plateau and the model is not improving\nreduce_lr = ReduceLROnPlateau(monitor='auc', factor=0.5, verbose=1, mode=\"auto\",\n                              cooldown=5, patience=10, min_lr=0.00001)\n\n# Adding class weights to compensate class imabalance\nclass_weights = { 0: 1,\n                  1: 1.5,\n                  2: 3,\n                  3: 20\n}\n\n# Fit the model\nhistory = model.fit(xtrain, ytrain, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[checkpoint_cb, early_stopping_cb, reduce_lr], validation_data=(xval, yval), class_weight = class_weights)","29112f2d":"fig, ax = plt.subplots(3, 1, figsize=(20, 20))\nax = ax.ravel()\n\nfor i, met in enumerate(['auc', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])\n\nax[2].plot(history.history['lr'])\nax[2].set_title('Model lr')\nax[2].set_xlabel('epochs')\nax[2].set_ylabel('lr')","6ac1f95c":"## TEST SET\ntest_concat = pd.concat([mild_test, moderate_test, non_test, verymild_test])\ntest_concat = test_concat.sample(frac=1)\ntest_concat[\"X\"] = test_concat[\"X\"].apply(load_image)\ntest_concat[\"y\"] = test_concat[\"y\"].apply(hot_array)\nxtest = np.stack(val_concat[\"X\"])\nytest = np.stack(val_concat[\"y\"])","baf448b2":"# evaluation\n_ = model.evaluate(xtest,ytest)","139a39c2":"# Function from Federico Agostini notebooks (slightly modified)\n\ndef print_metrics(model, X, y, cm_labels=\"auto\"):\n    \"\"\"\n    Print the following metrics: accuracy, balanced accuracy, precision, recall, f1.\n    If the model is able to predict probabilities, also auc is calculated.\n    Moreover, the confusion matrix is plotted.\n\n    Parameters\n    ----------\n    model : sklearn estimator\n        Sklearn estimator or similar which implements the method `predict`\n        and optionally `predict_proba`.\n    X : array like\n        Input features.\n    y : array like\n        Target labels.\n    cm_labels : list [default=\"auto\"]\n        Optional labels to be used in the confusion matrix.\n\n    Returns\n    -------\n    metrics : dict\n        Dictionary with the calculated metrics.\n\n    \"\"\"\n    y_pred = model.predict(X)\n    y_pred = np.squeeze(y_pred)\n    y_pred = np.argmax(y_pred,1).astype(int)\n\n    metrics = {\n        \"Accuracy\"    : accuracy_score(y, y_pred),\n        \"Bal Accuracy\": balanced_accuracy_score(y, y_pred),\n        \"Precision\"   : precision_score(y, y_pred, average=\"macro\"),\n        \"Recall\"      : recall_score(y, y_pred, average=\"macro\"),\n        \"f1\"          : f1_score(y, y_pred, average=\"macro\")\n    }\n    # add AUC if the classifier is able to predict probabilities\n    try:\n        y_pred_proba = model.predict_proba(X)\n        metrics[\"AUC\"] = roc_auc_score(y, y_pred_proba, multi_class=\"ovr\", average=\"macro\")\n    except:\n        metrics[\"AUC\"] = np.nan\n    \n    for k,v in metrics.items():\n        print(\"{:12s} = {}\".format(k,v))  \n    print(\"\\n\")\n    \n    # confusion matrix\n    cm = confusion_matrix(y, y_pred, normalize=\"true\")\n    fig, ax = plt.subplots(figsize=(6,6))\n    sns.heatmap(cm, ax=ax, square=True, vmin=0, vmax=1, annot=True, \n                linewidths=.05, fmt=\".2f\", cbar_kws={\"shrink\":.8}, \n                xticklabels=cm_labels, yticklabels=cm_labels)\n    plt.xticks([0.5, 1.5, 2.5, 3.5], ['Non', 'Very Mild', 'Mild', 'Moderate'])\n    plt.yticks([0.5, 1.5, 2.5, 3.5], ['Non', 'Very Mild', 'Mild', 'Moderate'])\n    ax.set_ylabel(\"True\")\n    ax.set_xlabel(\"Predicted\")\n\n    metrics[\"cm\"] = cm\n\n    return metrics","383dde27":"# visualize model metrics\ny_test = ytest.argmax(axis=1)\nmet = print_metrics(model, xtest, y_test)","923b601c":"data_folder = \"..\/input\/alzheimer-mri-ds\/Alzheimer_MRI_ds\/Train\"\n\n## For class: Mild, Non and VeryMild\n\n# Train set\n\n# images NonDemented\ndf_NonDemented_imgs_train = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"NonDemented\", \"[A-D]\",\"*\", \"*\"))),\n    \"y\": 0,\n    \"class\": \"NonDementia\"\n})\n#shuffled_non_train = df_NonDemented_imgs_train.sample(frac=.2814) # reducing its size becuase otherwise the NN classify only one class\nshuffled_non_train = df_NonDemented_imgs_train.sample(frac=1)\n\n# images VeryMildDemented\ndf_VeryMildDemented_imgs_train = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"VeryMildDemented\", \"[A-D]\",\"*\", \"*\"))),\n    \"y\": 1,\n    \"class\": \"VeryMildDementia\"\n})\n#shuffled_verymild_train = df_VeryMildDemented_imgs_train.sample(frac=.4) # reducing its size becuase otherwise the NN classify only one class\nshuffled_verymild_train = df_VeryMildDemented_imgs_train.sample(frac=1)\n\n# images MildDemented\ndf_MildDemented_imgs_train = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"MildDemented\", \"[A-D]\", \"*\", \"*\"))),\n    \"y\": 2,\n    \"class\": \"MildDementia\"\n})\nshuffled_mild_train = df_MildDemented_imgs_train.sample(frac=1)\n\n\n# Validation set\n\n# images NonDemented\ndf_NonDemented_imgs_val = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"NonDemented\", \"E\",\"*\", \"*\"))),\n    \"y\": 0,\n    \"class\": \"NonDementia\"\n})\nshuffled_non_val = df_NonDemented_imgs_val.sample(frac=1)\n\n# images VeryMildDemented\ndf_VeryMildDemented_imgs_val = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"VeryMildDemented\", \"E\",\"*\", \"*\"))),\n    \"y\": 1,\n    \"class\": \"VeryMildDementia\"\n})\nshuffled_verymild_val = df_VeryMildDemented_imgs_val.sample(frac=1)\n\n# images MildDemented\ndf_MildDemented_imgs_val = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"MildDemented\", \"E\", \"*\", \"*\"))),\n    \"y\": 2,\n    \"class\": \"MildDementia\"\n})\nshuffled_mild_val = df_MildDemented_imgs_val.sample(frac=1)\n\n\n## For class Moderate \n# we only have 1 subject for train and validation sets\ndf_ModerateDemented_imgs = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder, \"ModerateDemented\", \"*\", \"*\"))),\n    \"y\": 3,\n    \"class\": \"ModerateDementia\"\n})\nshuffled_moderate = df_ModerateDemented_imgs.sample(frac=1)\ntrainsize_moderate = int(0.8 * len(shuffled_moderate))\n\n# Train\nshuffled_moderate_train = shuffled_moderate[:trainsize_moderate]\n\n#Validation\nshuffled_moderate_val = shuffled_moderate[trainsize_moderate:]\n\n\n# Number of images\nprint(\"Training:\")\nprint(\"# of images with NonDemented Alzheimer =\", len(shuffled_non_train))\nprint(\"# of images with VeryMildDemented Alzheimer =\", len(shuffled_verymild_train))\nprint(\"# of images with MildDemented Alzheimer =\", len(shuffled_mild_train))\nprint(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate_train))\nprint(\"------------\")\nprint(\"Validation:\")\nprint(\"# of images with NonDemented Alzheimer =\", len(df_NonDemented_imgs_val))\nprint(\"# of images with VeryMildDemented Alzheimer =\", len(df_VeryMildDemented_imgs_val))\nprint(\"# of images with MildDemented Alzheimer =\", len(df_MildDemented_imgs_val))\nprint(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate_val))","166f23e3":"def load_image(fname):\n    \"\"\"\n    Load an image using opencv given its path.\n    \"\"\"\n    # img is a numpy array\n    img = cv.imread(fname)\n    # opencv uses BGR channel order by default\n    # so convert to RGB\n    img = cv.cvtColor(img, cv.COLOR_BGR2RGB)\n    # resize image\n    resize = (IMAGE_SIZE[0], IMAGE_SIZE[1])\n    img = cv.resize(img, resize)\n    return img\n\ndef hot_array(class_number):\n    ha = [0,0,0,0]\n    ha[class_number] = 1\n    return ha","7c5fc814":"## TRAIN SET\n# concatenate\ntrain_concat = pd.concat([shuffled_mild_train, shuffled_moderate_train, shuffled_non_train, shuffled_verymild_train])\n# shuffle\ntrain_concat = train_concat.sample(frac=1)\n# load image\ntrain_concat[\"X\"] = train_concat[\"X\"].apply(load_image)\n\n# extract label before one hot in order to use for class weights\ny_train_lab = train_concat[\"y\"]\ny_train_lab = np.array(y_train_lab) # convert into a numpy array\n\n# apply one-hot encoding\ntrain_concat[\"y\"] = train_concat[\"y\"].apply(hot_array)\n\n# stack images and labels\nxtrain = np.stack(train_concat[\"X\"])\nytrain = np.stack(train_concat[\"y\"])\n\n\n## VALIDATION SET\nval_concat = pd.concat([shuffled_mild_val, shuffled_moderate_val, shuffled_non_val, shuffled_verymild_val])\nval_concat = val_concat.sample(frac=1)\nval_concat[\"X\"] = val_concat[\"X\"].apply(load_image)\nval_concat[\"y\"] = val_concat[\"y\"].apply(hot_array)\nxval = np.stack(val_concat[\"X\"])\nyval = np.stack(val_concat[\"y\"])","caf34eaf":"# plot some images per class\n\nncols = 10\n\nfig, axs = plt.subplots(nrows=4, ncols=ncols, figsize=(20, 10))\n\nfor fname,ax in zip(shuffled_non_train.loc[:ncols, \"X\"], axs[0,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n    \nfor fname,ax in zip(shuffled_verymild_train.loc[:ncols, \"X\"], axs[1,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n\nfor fname,ax in zip(shuffled_mild_train.loc[:ncols, \"X\"], axs[2,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n\nfor fname,ax in zip(shuffled_moderate_train.loc[:ncols, \"X\"], axs[3,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n\naxs[0,0].set_ylabel(\"Non Dementia\")\naxs[1,0].set_ylabel(\"Very Mild Dementia\")\naxs[2,0].set_ylabel(\"Mild Dementia\")\naxs[3,0].set_ylabel(\"Moderate Dementia\")","0cc2bc12":"def conv_block(filters):\n    block = tf.keras.Sequential([\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='elu', padding='same'),\n        tf.keras.layers.SeparableConv2D(filters, 3, activation='elu', padding='same'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.MaxPool2D()\n    ]\n    )\n    \n    return block","86fb85fa":"def dense_block(units, dropout_rate):\n    block = tf.keras.Sequential([\n        tf.keras.layers.Dense(units, activation='elu'),\n        tf.keras.layers.BatchNormalization(),\n        tf.keras.layers.Dropout(dropout_rate)\n    ])\n    \n    return block","71268393":"def build_model():\n    model = tf.keras.Sequential([\n        tf.keras.Input(shape=(*IMAGE_SIZE, 3)),\n        \n        tf.keras.layers.Conv2D(16, 3, activation='elu', padding='same'),\n        tf.keras.layers.Conv2D(16, 3, activation='elu', padding='same'),\n        tf.keras.layers.MaxPool2D(),\n        \n        conv_block(32),\n        conv_block(64),\n        \n        conv_block(128),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(256),\n        tf.keras.layers.Dropout(0.2),\n        \n        conv_block(512),\n        tf.keras.layers.Dropout(0.3),\n        \n        tf.keras.layers.Flatten(),\n        dense_block(512, 0.7),\n        dense_block(128, 0.5),\n        dense_block(64, 0.3),\n        \n        tf.keras.layers.Dense(4, activation='softmax')\n    ])\n    \n    return model","cc02f42d":"with strategy.scope():\n    model = build_model()\n\n    METRICS = [tf.keras.metrics.AUC(name='auc')]\n    \n    model.compile(\n        #optimizer='adam',\n        optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n        loss=tf.losses.CategoricalCrossentropy(),\n        metrics=METRICS\n    )","d7d29994":"def exponential_decay(lr0, s):\n    def exponential_decay_fn(epoch):\n        return lr0 * 0.1 **(epoch \/ s)\n    return exponential_decay_fn\n\nexponential_decay_fn = exponential_decay(0.001, 20)\n\nlr_scheduler = tf.keras.callbacks.LearningRateScheduler(exponential_decay_fn)\n\ncheckpoint_cb = tf.keras.callbacks.ModelCheckpoint(\"alzheimer_model2.h5\", save_best_only=True)\n\nearly_stopping_cb = tf.keras.callbacks.EarlyStopping(patience=15, restore_best_weights=True)\n\n# reduce the learning rate when there is a plateau and the model is not improving\nreduce_lr = ReduceLROnPlateau(monitor='auc', factor=0.5, verbose=1, mode=\"auto\",\n                              cooldown=5, patience=10, min_lr=0.00001)\n\n# more pronounced class weights\nclass_weights = { 0: 1,\n                  1: 2,\n                  2: 5,\n                  3: 80\n}\nclass_weights","2d12395e":"history = model.fit(xtrain, ytrain, batch_size=BATCH_SIZE, epochs=EPOCHS, callbacks=[checkpoint_cb, early_stopping_cb, reduce_lr], validation_data=(xval, yval), class_weight = class_weights)","b9d56e38":"fig, ax = plt.subplots(3, 1, figsize=(20, 20))\nax = ax.ravel()\n\nfor i, met in enumerate(['auc', 'loss']):\n    ax[i].plot(history.history[met])\n    ax[i].plot(history.history['val_' + met])\n    ax[i].set_title('Model {}'.format(met))\n    ax[i].set_xlabel('epochs')\n    ax[i].set_ylabel(met)\n    ax[i].legend(['train', 'val'])\n\nax[2].plot(history.history['lr'])\nax[2].set_title('Model lr')\nax[2].set_xlabel('epochs')\nax[2].set_ylabel('lr')","6e421019":"data_folder2 = \"..\/input\/alzheimer-mri-ds\/Alzheimer_MRI_ds\/Test\"\n\n# create a dataframe with columns:\n#    X     -> filepaths of the images\n#    y     -> label encoded class \n#    class -> data class as string\n\n# images NonDemented\ndf_NonDemented_imgs_test = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder2, \"NonDemented\", \"*\", \"*\"))),\n    \"y\": 0,\n    \"class\": \"NonDementia\"\n})\nshuffled_non_test = df_NonDemented_imgs_test.sample(frac=1)\n\n# images VeryMildDemented\ndf_VeryMildDemented_imgs_test = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder2, \"VeryMildDemented\", \"*\", \"*\"))),\n    \"y\": 1,\n    \"class\": \"VeryMildDementia\"\n})\nshuffled_verymild_test = df_VeryMildDemented_imgs_test.sample(frac=1)\n\n# images MildDemented\ndf_MildDemented_imgs_test = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder2, \"MildDemented\", \"*\", \"*\"))),\n    \"y\": 2,\n    \"class\": \"MildDementia\"\n})\nshuffled_mild_test = df_MildDemented_imgs_test.sample(frac=1)\n\n# images ModerateDemented\ndf_ModerateDemented_imgs_test = pd.DataFrame({\n    \"X\": sorted(glob(join(data_folder2, \"ModerateDemented\", \"*\", \"*\"))),\n    \"y\": 3,\n    \"class\": \"ModerateDementia\"\n})\nshuffled_moderate_test = df_ModerateDemented_imgs_test.sample(frac=1)\n\n\nprint(\"Test:\")\nprint(\"# of images with NonDemented Alzheimer =\", len(shuffled_non_test))\nprint(\"# of images with VeryMildDemented Alzheimer =\", len(shuffled_verymild_test))\nprint(\"# of images with MildDemented Alzheimer =\", len(shuffled_mild_test))\nprint(\"# of images with ModerateDemented Alzheimer =\", len(shuffled_moderate_test))","243aa2c7":"# plot some images per class\n\nncols = 10\n\nfig, axs = plt.subplots(nrows=4, ncols=ncols, figsize=(20, 10))\n\nfor fname,ax in zip(shuffled_non_test.loc[:ncols, \"X\"], axs[0,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n    \nfor fname,ax in zip(shuffled_verymild_test.loc[:ncols, \"X\"], axs[1,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n\n\nfor fname,ax in zip(shuffled_mild_test.loc[:ncols, \"X\"], axs[2,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n\nfor fname,ax in zip(shuffled_moderate_test.loc[:ncols, \"X\"], axs[3,:]):\n    im = load_image(fname)\n    ax.imshow(im)\n    ax.set_xticks([])\n    ax.set_yticks([])\n    ax.grid(False)\n    \naxs[0,0].set_ylabel(\"Non Dementia\")\naxs[1,0].set_ylabel(\"Very Mild Dementia\")\naxs[2,0].set_ylabel(\"Mild Dementia\")\naxs[3,0].set_ylabel(\"Moderate Dementia\")\n","4b7195f1":"df_test = pd.concat([shuffled_non_test, shuffled_verymild_test, shuffled_mild_test, shuffled_moderate_test], ignore_index=True)\ndf_test[\"X\"] = df_test[\"X\"].apply(load_image)\ndf_test[\"y\"] = df_test[\"y\"].apply(hot_array)\nX_test = np.stack(df_test[\"X\"])\ny_test = np.stack(df_test[\"y\"])","5b1f64b2":"_ = model.evaluate(X_test,y_test)","793d6350":"# visualize model metrics\ny_test = ytest.argmax(axis=1)\nmet = print_metrics(model, xtest, y_test)","6c30e162":"# Evaluate the Model - 1\n\nIn this section, the model evaluates the data previously saved in the test set. Firstly, the same procedure of concatenation done before for training and validation set is followed, in order to get two vectors of objects **xtest** and **ytest** necessary to evaluate the model. The evaluation uses the method **evaluate**.\nThe loss function and the AUC show excellent values.","0d0250ce":"# *Abstract*\n\nThe model we worked on aims to classify MRI images of the brain through a convolutional neural network, useful to detect four stages of dementia in Alzheimer disease's screening. We started from a robust convolutional architecture, but the model contained some defects regarding the dataset involved to train it. The problems we detected were the incoherent subdivision of training set and testing set, with totally different sections of the brain in the two sets, the unbalance of the images labelled in the four classes to be classified and the confusion matrix far away from being an identity matrix.\n\nWe identified the ones above as limits of the existing model and we worked to fill these gaps, with the knowledge achieved during the course, also trying to get a dataset split with criterion, in order to make the model train with better results. \n\nAfter understanding each line of code, we performed an analysis on the hyperparameters and on the functions that regulate them, and on the initial steps, we tried to get the best combination of external parameters\/hyperparameters\/activation functions that managed to improve (even just a little bit) the existing model. Later, we introduced the code to evaluate the confusion matrix in the testing set and we discovered that even though the loss function and the AUC metric provided great results, the model did not classify the images with great performance. \n\nSubsequently, we totally revolutionised the dataset and the way to load the images, to make it more comfortable with our main objective: improve the model performance. We provided two solutions to get a smarter grouping of the images to be used in the training and testing sets, the first one based on a random splitting of the images, the second one based on a subdivision by subjects. We trained two different models and we evaluated and compared the results, both explained in detail during this Notebook. To overcome the defect of unbalanced dataset, we tried to implement data augmentation on the class with the lowest number of images, performing flip\/cut\/rotation, but also working on the grey scale of the images (brightness\/contrast). As we will discuss further on, this did not increase the evaluation performance of the model and we partially solved the problem of unbalance by assigning class weights during the model training.\n\nWe tried to figure out which kind of dataset splitting could be appropriate for the project\u2019s scope, but we decided to keep both the models. \n\nWe concluded that the job done accomplished our targets, even if the model with the dataset split by subjects has strong internal limitations due to the huge unbalance of the number of subjects in each class. The other one, which we defined as \u201cFirst Try\u201d, met the objectives we initially set ourselves.","f99b9a1d":"# **Second Try: Conclusions**\n\nThe performance of the model on the second dataset isn't great.\n\nThe major problem is that the model cannot predict at all (o poorly, depending on the run) the Moderate class; the reason for this behaviour can be found in the remarkable difference between the number of training images belonging to this class (just 25 images of different section of the same subject) and the number of images of the other classes (variable between 576 and 2048). Another problem is that, having only 2 subjects in the Moderate class, one was used in the train set and the other in the test set, so we have to predict features starting just from one subject, which is very difficult.\n\nWe also tried to perform data augmentation on the moderate class but the result didn't show any improvement, probably because of the difference between the 2 subjects.\n\n# **-----------------------------------------**","9ba81564":"# Visualize Model Metrics - 2\n\nIn this part, ROC AUC metric and loss after each epoch for the training and validation data are shown, it is clearly visible that the model does not converge as before and cannot be precise in the evaluation.","1d2e1372":"# Build the Model - 1\n\nIn these lines of code, the model is built, assembling the different layers.\n\n1. **conv_block** method is defined using **Sequential** method provided by Keras library. In particular, in this convolutional block, two separable 2D convolutions are performed, in order to save computational power. We adjusted the activation function from **relu** to **elu**, since it is more effective in convolutional NN that analyse images. Then a Batch Normalization and a Max Pooling 2D layers are added to the block.\n\n2. **dense_block** method is defined to build the fully connected block, adding a Dense layer (always with **elu** activation function), a Batch Normalization layer and a Dropout layer, useful to black out some network nodes at a rate defined by the argument **dropout_rate**\n\n3. The actual model is defined in the method **build_model**:\n   * **Sequential** method provided by Keras is used to add the layers\n   * Firstly, the input layer is defined, as an image with size decided at the beginning of the code\n   * Then, two 2D separable convolutions are added (always with **elu** activation function), before the Max Pooling 2D layer\n   * Subsequently, three conv_block with increasing number of filters (32, 64, 128) are applied before a Dropout layer\n   * Another conv_block (with 256 filters) is applied, then another Dropout and a Flatten layer\n   * Three dense_block (512, 128, 64 units) and a Dense layer conclude the architecture of the model\n   \nWe believed that the model, built in this way, was perfect for our scope and we did not modify the architecture. We tried to add\/remove some convolutional and dense blocks but the performance of the model decreased or did not have visible improvements.","0841038d":"# **First try: Dataset where training and testing set have been unified and divided again smartly**","c293eab1":"# **What we tried to achieve**\n\nOur aims to improve the model's capability of classifying the four disease classes, were:\n  *  Work on the dataset, as previously anticipated, to **create a better split** of the images and to balance the different classes\n  *  **Improve** the evaluation of the test images\n  * **Enhance** the confusion matrix ","4fe880ac":"# **Introduction to project's strength and weaknesses**\n\nOne of the biggest issues we dealt with while analysing the model was understanding the criterion behind the dataset. It was already subdivided in train set and test set folders but, giving a random look at some images, we discovered that there was a discrepancy between the images of the two sets, since the acquired MRI section of the brain was different, and this was clearly visible. \nThe reason why this happened was that the images into the dataset were ordered by the position of the slice and the train\/test set division was performed by putting a first percentage of images in the train set and the remaining one in the test set.\n\nLooking at the initial project we worked on, the other point, always regarding the dataset, was that it was strongly unbalanced considering the number of available images in the entire set. In fact, Moderate Demented class represented only 1% of the whole dataset, while Non Demented class 50%, and this introduced an important bias in the model training and validation.\n\nIn the code, we also implemented the 4x4 confusion matrix, and we noticed that it could be improved. This was one of the objectives of our work.\n\nA strength point of the model, from our point of view, was how the neural network was implemented and stratified. The layers included offered a great performance in the model training.\n\nTrying to fill these gaps we considered two possible solutions, explained in detail between the lines of codes, based on two different grouping of the images, since we thought that the dataset played a key role and must be exploited wisely to train the convolutional neural network.","192dc548":"We created another dataset to try to solve the problem of the initial subset splitting. This time we ordered the dataset by subjectss. In particular, we managed to merge all the 32 sections for each subject and we subdivided the 6400 total images in 200 subjects. We then split training set and test set by the belonging class and by subjects, so that a 80% of the subjects belonged to the training+validation set and the remaining 20% in the test set, for each class. This was performed because we thought that sections belonging to the same subject are strongly correlated on to the next ones and, in this way, the prediction error can be reduced. These operations have been done directly on the dataset. We tought that the model, in this working dynamics, can be able to classify all the sections of a subject with more precision, but the trade off we faced is an ingent reduction of the samples, indeed the class Moderate Demented had only 64 images, that means two subjects, one in the training set and the other one on the test set. This gives the idea that the model cannot classify correctly the sections of the subjects belonging to Moderate Demented, and it is clearly a limit of this subset division.\n\nThe steps that we followed were exactly the same of the **First Try**, except for some slight changes, due to the architecture of the new dataset. \n\n*Dataset link*: [Alzheimer MRI ds](https:\/\/www.kaggle.com\/marcopinamonti\/alzheimer-mri-ds)","2f1a743f":"# Build the Model - 2\n\nThe model architecture is exactly the same already used, because of the analog considerations about the architecture layers. The CNN is built by the layers, the convolutional blocks and the dense blocks described in the First Try, with the modifications on the activation functions.","ce7f3563":"# Evaluate the Model - 2\n\nIn this part, the new trained model is evaluated: we loaded the images of the testing set, as we previously did in the training set, then we printed some images of the testing set, to show that the images to be classified are very similar to the others used in the training set. Then we generated the vectors containing the images and the labels of the testing set and we evaluated the model: the same steps done in the First Try.","ae705869":"**Concatenate train set and test set**\n\nHere the final concatenation is done, in order to get a training set composed by images from all the classes. In fact, train_concat contains 80% of the 80% of the total images for each class, bacause the training set was defined from the 80% of the training+validation set. \n\nThen, another shuffling is done and to the attribute **X**, that contains all the images paths, is applied the above defined method load_image.\nSubsequently, also the labels are concatenated and the result is converted into an array. Then, both the images and the labels are stacked into xtrain and ytrain vectors.\n\nThe same procedure is followed also for the validation set. Now the vectors containing images and labels are ready, and the most important concept is that both training set and validation set contain the images that, in the original code, were split between training+validation and test set, introducing bias.","6eab3e8d":"**Concatenate train set and test set**\n\nAlso the concatenation is the same we performed in the first part of the project, since the target is to have vectors of objects containing images.","4ac95a9d":"# Visualize the data - 2\n\nIn this part, again we visualize some images of the new training set, above defined.","00a3af88":"**Defining functions to load the images and to perform one-hot encoding**\n\n1. **load_image method** is defined in order to read the paths and load the images directly from their paths, created in the previous section. The final output of the method is, for each path, the image in grey scale, resized by the parameters defined previously, thus ready to enter into the first layer of the neural network.\n\n2. **hot_array** method performs the one hot encoding, generating four normal versors to identify the four classes","942f7809":"**Defining functions to load the images and to perform one-hot encoding**\n\nThe methods are exactly the same we defined in the First Try.","b05bd9dd":"# **First Try: Conclusions**\n\nWe can conclude that with the modifications performed to revolutionize the dataset and the slight modifications on the learning rate scheduler, activation functions and class weights our goal has been reached. The model offers greater performance, the confusion matrix is improved and the dataset has been re-adjusted and balanced.\n\n# **-----------------------------------------------**","87a35b50":"# **Summary: Main differences between the initial project code and the code we provided in our Notebook**\n\nTo achieve our targets we did some essential modifications to the original project's code:\n\n   1. We completely changed the lines of code in which **the images are loaded** (both in First Try and Second Try), in order to make that section **easier to manage**, also in terms of the new datasets that we built\n   2. We changed **Hyperparameters**, such as the Batch Size or the Starting Learning rate\n   3. We changed the **activation functions** of the model, from **relu** to **elu**, in order to make the classification more efficient for the images classes and the optimizer (Adam)\n   4. We added some parts in which we showed the problem of unbalanced dataset\n   5. We changed the **Learning Rate decaying function**, using a reduction of the hyperparameter when the training reaches a zone of plateau, with no significant changes in the metric and in the loss function (instead of exponential decay)\n   6. We introduced the **class weights** to cope with the unbalance problems\n   7. We implemented the **confusion matrix** for both the original code and our two solutions","a04e458e":"# **MRI Alzheimer Classification**\n\nNeural Network to classify MRI images between 4 different classes of Alzheimer:\n   * **Non Demented**\n   * **Very Mild Demented**\n   * **Mild Demented**\n   * **Moderate Demented**","bbb03d49":"***Future Improvements***\n\nIn order to obtain better results, one of the best way is to find a more balanced dataset to use for the training, that has a greater number of subjects especially for the Very Mild and Moderate classes.\n\nFurthermore, a new model can be create to better extract the important feature from each subject, otherwise transfer learning can be applied to try to obtain good results using the second dataset.","5085a038":"Academic Year 2021\/22\n\nMaster Course in Bioengineering \n\n**Deep learning applied to neuroscience and rehabilitation**\n\n>*Group 7*\n>* Davide Bombassei de Bona\n>* Federica Boscolo\n>* Maria Dalle Vacche\n>* Antonio Marittimi\n>* Marco Pinamonti\n\n","4dbae43e":"# Visualize the data - 1\n\nThis section is intended to visualize some of the images contained in the entire dataset. It is clear that in each class, different sections of the brain MRI image are present.","ddaaee6b":"# Set-up\n\nIn this part of the code, the first essential operations have been performed, such as the installation of TensorFlow environment and the import of all the useful libraries: from numpy, necessary to compute scientific calculations, to tensorflow itself, necessary to build the model. Other libraries are pandas, useful to compute data analysis, pyplot, that we used to represent some of the set images and cv2, useful to read and handle the images.\n\nAdditionally, the exception {try - except} cycle was already inserted and it controls whether the TPU is activated or not, managing how to compute the calculations, in parallel or not.","dc8aafed":"In this dataset we built, the original training and testing set folders have been merged, and the images have been divided again between training, testing and validating set randomly, to troubleshoot the heterogeneity of the starting datasets.\n\nThe original dataset contained MRI images of 32 horizontal slices of the brain divided into 4 classes:\n\n  * **Mild Demented**\n  * **Moderate Demented**\n  * **Non Demented**\n  * **Very Mild Demented**\n\nFor each classes there were a different number of subjects:\n\n  * **28 subjects** for the Mild Demented Class\n  * **2 subjects** for the Moderate Demented Class\n  * **100 subjects** for the Non Demented Class\n  * **70 subjects** for the Very Mild Demented Class\n\n*Dataset link*: [Alzheimer MRI 4 classes dataset](https:\/\/www.kaggle.com\/marcopinamonti\/alzheimer-mri-4-classes-dataset)","fce356e2":"# Data Loading - 2\n\nThe data loading was adjusted in order to target the images of the new dataset, reducing also the data size for Non Demented and Mild Demented classes in the training set, otherwise the model indroduces a huge bias towards these two categories, plentiful of subjects with respect to the other two.\nThe images are loaded in the training set and in the validation set, directly from the specific folders, thanks to the structure of the two datasets.\nFor the Moderate Demented class (one subject in training and the other in testing), we were forced to divide the data by images: since we could not have 20% of subjects in the validation set, we performed a division by images (i.e. sections of the same subject).","751e608f":"# **Final Conclusions**\n\nWe concentrated our work on the dataset, trying to fix the innatural division between the train and test set that was  performed in the original data.\n\nIn the first creation of a modified copy of dataset we obtain significant improvement over the original model shown in Amy Jang's notebook, particularly in the correct classification of the minority classes (Very Mild and Moderate Demented), based on the result shown in the confusion matrix.\n\nWith the second dataset we tried to generalize more the model but it was very difficult to obtain good results, probably because of the huge class imbalance.","4251500f":"\nAs we can see, the confusion matrix tells us that the classification performed in the testing set is nearly perfect and the matrix is clearly improved with respect to the original model's one.","dd300270":"# Training the Model - 1\n\nThis passage contains the use of the following functions provided by Keras to set some parameters of the training:\n\n1. **ModelCheckpoint** in order to save the best result of the model during the iterations and to prevent losing the running data\n2. **EarlyStopping** in order to stop the training if similar results are achieved for a number X of subsequent epochs (patience)\n3. **ReduceLROnPlateau** in order to reduce the learning rate when the model is not improving in subsequent iterations\n\nThe weights for the classes are also defined, giving more importance to the class with less data (i.e. Moderate Dementia). This parameter is then used in the model fitting.\n\nThe function **fit** takes as arguments both hyperparameters and parameters, in addition to the callbacks, the class weights and the dataset of training and validation (images and labels). Once this method is called, the training of the model starts, for a number of epochs < 50, as set in the very beginning of the code.\n\nThe argument class_weights is what we adopted to solve the problem of unbalanced datasets. In particular, we tried to perform data augmentation for the class that contains only 64 images, both in terms of flip\/rotation\/cut and contrast\/brightness\/grey scale.\nThis procedure gave poor results, looking at the general performance: this was because the model is built to recognize images (test set) that are in the same format (size\/contrast\/angles) of the ones used in the training set, so that a transformation of the images does not have a good impact on the final evaluation on the test set.","4ca46b62":"# Constant values\n\nIn this part, four parameters are set:\n* **AUTOTUNE**, which controls the optimization of computing power\n* **BATCH SIZE**, which defines the data subset on which to calculate the gradient: after some runs we decided to set the hyperparameter to 32, also dependent on whether the TPU is enabled or not\n* **IMAGE SIZE**, to define the size of the images entering the first layer of the model\n* **EPOCHS**, to set the maximum number of epochs in which to train the model","ca411e35":"**Print Metrics**\n\nThis code fragment was added by looking at a Notebook presented in a lecture and it is useful to build and evaluate the confusion matrix of the model.","50fa16ce":"# Data Loading - 1\n\nWe will be using our modified dataset [Alzheimer MRI 4 classes dataset](https:\/\/www.kaggle.com\/marcopinamonti\/alzheimer-mri-4-classes-dataset).\n\nThe structure of the dataset is the following, in which each class contains all the images that in the original code were split into test and train:\n```\nmain_directory\/\n    class1\/\n        class1_images\n    class2\/\n        class2_images\n```\nIn particular, the import of the images has been totally revolutionized, to make the code more intuitive and easier to handle, also in term of objects created by the different methods used. \nIn particular, data_folder contains the path of the dataset and for every class these steps are followed:\n\n 1. Load of every image's path of the specific class, using DataFrame method and defining: \n   *  **X**=object containing all the images path\n   *  **y**=numerical value of the class\n   *  **class**=string that identifies the class \n 2. Shuffle all the elements loaded\n 3. Define the size of the test set (20% of the total images)\n 4. Split the previously shuffled elements in test set and train+validation set\n 5. Define the train size, as 80% of the train+validation elements defined at step 4\n 6. Split train+validation paths in train and validation (80% and 20% of train+validation paths)\n \nIn the end of this code fragment, the number of images (=paths) for each set and each class is printed and it is clear that the dataset, adjusted in this way, is still too unbalanced, in every dataset subset.","13195898":"> **Show Class Imbalance**\n>\n> In this additional part, we hightlighted once again the unbalance between the images contained in the four classes, a stumbling block to overcome in order to make the model more accurate. Here, an histogram plot of the length of the four classes objects vector is shown.","7cdb9de9":"# Deciding a Metric\n\nThe imbalance between the number of images in each class prevent us from using accuracy. ROC AUC has been used instead. In addition, the ADAM optimizer with initial learning rate of 0.001 and the Cross Entropy Loss have been defined respectively as optimizer and cost function. The build_model method is called and the model is defined as object.","72c2d8c3":"Again, we build the model and we set the optimizer, the initial Learning Rate and the Cross Entropy loss function.","1a0ae73c":"# Visualize Model Metrics and Learning rate evolution\n\nThe three graphs show respectively the trend of AUC, Loss Function and Learning rate over the training epochs. We can notice a great improvement compared to the initial model.","000bf6bb":"# **Second Try: Use a Dataset where train, test and validation sets are divided on subject basis**","370ee4ae":"# Feature Engineering\n\nIn this section, the images are loaded and training, validation and test sets \"ready\" to be given to the layers are created.","ea982751":"# Training the Model - 2\n\nHere the model is trained once again, with the new data loaded, and class weights more emphasized due to the strong unbalance. The callbacks are defined as before and the learning rate function is the one defined in the First Try.\n","54892c88":"# **Original project performance: Where we started from**\n\n*link to the original project: https:\/\/www.kaggle.com\/amyjang\/alzheimer-mri-model-tensorflow-2-3-data-loading*\n\n> **Original Evaluation of the model**\n>\n> **Loss: 1.1943**\n> **AUC: 0.8666**\n\n\n\n\n> **Original Confusion Matrix**\n>\n>   ![image.png](attachment:5e69cd0b-0ca4-4ae3-a418-f5f68e6f5a71.png)\n"}}