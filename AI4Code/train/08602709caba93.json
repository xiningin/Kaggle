{"cell_type":{"863b6e20":"code","2f91581d":"code","b21c9fed":"code","6eecfb94":"code","04a26d49":"code","d2b4636f":"code","fd59a3f6":"code","845ca5fc":"code","d9ed7f78":"code","06bcc85a":"code","6a96de9c":"code","0f3a4fcf":"code","1d4b1e07":"code","e7ad63ed":"code","43ad007b":"markdown","d9108e69":"markdown","44d20c19":"markdown","86142145":"markdown","551aadf1":"markdown","aac81109":"markdown","be6d72b1":"markdown","a5af3dfc":"markdown"},"source":{"863b6e20":"import numpy as np \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport pickle\nimport glob\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import log_loss, classification_report\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames[:5]: #limiting output to 5 files\n        print(os.path.join(dirname, filename))\n","2f91581d":"data_dir = '\/kaggle\/input\/particle-collisions\/'","b21c9fed":"# load a random pickle file to get a glimpse of the data structure\n\npkl_file = open(data_dir+'event112.pkl', 'rb')\neventx = pickle.load(pkl_file)\nprint(eventx.shape)","6eecfb94":"particle_types = {11: \"electron\", 13 : \"muon\", 211:\"pion\", 321:\"kaon\",2212 : \"proton\"}\n\nX = []\ny = []\n\npkl_data = glob.glob(data_dir+'*.pkl')\n\nfor pkl in pkl_data:\n    pkl_file = open(pkl, 'rb')\n    event1 = pickle.load(pkl_file)\n    \n    # get the data and target\n    data,target = event1[0], event1[1]\n    \n    X += [d for d in data]\n    y += [t for t in target]\n","04a26d49":"np.array(y).shape, np.array(X).shape","d2b4636f":"np.ndarray.flatten(np.array(X)).shape","fd59a3f6":"event_df = pd.DataFrame({\n    'particle_Id':y\n})\nevent_df['class'] = event_df['particle_Id'].map(particle_types)\nfor i in range(100):\n  event_df[str(i)] = [x.flatten()[i] for x in X] # flattening the 10x10 images","845ca5fc":"event_df.head()","d9ed7f78":"# Let's check the distribution of the target\nevent_df['class'].value_counts()","06bcc85a":"# Encoding the target variable ('class')\nfrom sklearn.preprocessing import LabelEncoder\n\nencoder = LabelEncoder()\nevent_df['class'] = encoder.fit_transform(event_df['class'])","6a96de9c":"# Split the data into train and test data\ntarget = event_df['class']\nimages = event_df[0:]\n\nX_train, X_test, y_train, y_test = train_test_split(images, target, test_size=0.20, random_state=72)","0f3a4fcf":"clf = RandomForestClassifier(n_estimators=350,\n                             max_depth=7,\n                             random_state=84,\n                             n_jobs=-1\n                            )\nclf.fit(X_train, y_train)","1d4b1e07":"# Log_loss\ny_hat = clf.predict_proba(X_test) # log loss requires predictions as probabilities\nloss = log_loss(y_test, y_hat)\nprint(f'Log_loss: {loss}')","e7ad63ed":"# Classification report\n# This takes class predictions hence we'll have to use .predict()\ny_hat_prime = clf.predict(X_test)\nprint(f'Classification Report: \\n{classification_report(y_test, y_hat_prime, zero_division=False)}')","43ad007b":"### Building a simple classifier\nWe'll train on the images (`features\/column-names 0 to 100`) and the `target (class)`","d9108e69":"#### Loading the data and splitting it into collisions(features) and target\nThere are 5 particle types in the dataset (our target variable)","44d20c19":"# Particle Identification","86142145":"Loading the data into a dataframe for visual representation purposes and basic modelling using ML algorithms. I'll flatten the `10x10` images to reduce dimensionality. So the shape of `X` from above`(1176475, 10, 10)` will be transformed to `(1176475, 100)`","551aadf1":"Each .pkl file contains two columns and ~3822 rows (as seen from the shape of the sample file loaded above): column 1 is a list of 10x10 images while column 2 is the particle type associated with the image.","aac81109":"<p><strong>Kindly leave an upvote <\/strong>if you find this notebook helpful. Good luck<\/p>","be6d72b1":"* The dataset is imbalanced as some particle types are more represented than others, for instance the the `electron` and `muon` have much lower representations in the dataset than others; Feel free to explore techniques of handling imbalanced data such as `Sampling`.\n\n* This is mainly a starter kernel to help you load and do basic preprocessing of the pickle data. You can explore SOTA approaches to computer-vision with `Deep learning`. (if i time allows i'll also make another kernel with this).\n\n* Hope this Kernel helps you in some way. Cheers!","a5af3dfc":"### Performance evaluation"}}