{"cell_type":{"6809c3d5":"code","428c76df":"code","e8f157ab":"code","65b5cf91":"code","4810dbda":"code","951ea189":"code","3f382d45":"code","eabaf1e5":"code","9b408dd5":"code","1b206823":"code","5aefab0a":"code","440629dd":"code","6798b593":"code","70a51dc4":"code","d97cdfa0":"code","5ef854a1":"code","3454e261":"code","62079747":"code","4faeb3db":"code","237149c0":"code","02638d98":"code","0063fdf5":"code","3f895083":"code","ca5957a7":"code","1e575b50":"code","eeaa36c5":"code","6df6d8c0":"code","891ceccf":"code","c9cab1ff":"code","d2f3b523":"code","5149ee62":"code","88a5e470":"code","a8fd7e3a":"code","a78968a6":"code","cd5590f5":"code","75480653":"code","30693436":"code","1784b23e":"code","14f6d60d":"code","4e6f5ca0":"code","7542c033":"code","fdb6ad1a":"code","4ca33f6c":"markdown","1a1e1671":"markdown","0db69b64":"markdown","7290ddc6":"markdown","bea5779a":"markdown","a2930736":"markdown","56282ae8":"markdown","4b4233cd":"markdown","39a90834":"markdown","1aef2d4f":"markdown","a80f6758":"markdown","dcff5dc8":"markdown","38bea0e2":"markdown","a07b4b65":"markdown","2caef257":"markdown","1dc33660":"markdown","3ee26ab5":"markdown","5ebf6a22":"markdown","bdb55bdf":"markdown","5bc5964c":"markdown","c195a1c3":"markdown","25fb3d72":"markdown","efcf8f84":"markdown"},"source":{"6809c3d5":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt # data visualization \n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","428c76df":"data = pd.read_csv('\/kaggle\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv')","e8f157ab":"data.head()","65b5cf91":"data.info()","4810dbda":"data.shape","951ea189":"import seaborn as sns\nsns.set(style='darkgrid')\nsns.catplot(x=\"Churn\", kind=\"count\",edgecolor='.3',data=data)","3f382d45":"print(\"Customer Churn rate is \\n{}\".format(data['Churn'].value_counts('Yes')))","eabaf1e5":"columns = data.columns","9b408dd5":"data[data[columns] == \" \"].count()","1b206823":"data[data['TotalCharges'] == \" \"].Churn","5aefab0a":"data['TotalCharges'] = data[\"TotalCharges\"].replace(\" \", 0).astype('float32')","440629dd":"cat_data = data.select_dtypes(include = 'object').copy()\ncat_data = cat_data.drop(columns='customerID')\ncat_data.head(2)","6798b593":"sns.countplot(data = data, x = 'gender',edgecolor='.3',alpha=0.8)","70a51dc4":"sns.countplot(data = data, x = 'gender',hue='Churn',alpha=0.8)","d97cdfa0":"sns.violinplot(data=cat_data, x='gender', y=data['MonthlyCharges'],palette='pastel')","5ef854a1":"sns.boxenplot(data=cat_data, x='Churn', y=data['tenure'])","3454e261":"num_attr = ['tenure','MonthlyCharges','TotalCharges']\nnum_data = data[num_attr]","62079747":"num_data.hist(bins=15, color='steelblue', edgecolor='black', linewidth=1.0,\n           xlabelsize=8, ylabelsize=8, grid=False)    \nplt.tight_layout(rect=(3, 3, 4.2, 4.2))   ","4faeb3db":"sns.distplot(data['TotalCharges'])","237149c0":"resp = data['TotalCharges']\nresp.skew()","02638d98":"sns.distplot(np.sqrt(data['TotalCharges']))","0063fdf5":"sns.distplot(data['MonthlyCharges'])","3f895083":"num_attributes = ['tenure', 'MonthlyCharges','TotalCharges']\ndata_num = data[num_attributes]","ca5957a7":"sns.scatterplot(x=\"TotalCharges\", y=\"MonthlyCharges\", hue=\"tenure\", data=data)","1e575b50":"attributes = ['MonthlyCharges', 'TotalCharges']\nfor x in attributes:\n    sns.relplot(x='tenure',y=x, kind='line', data=data_num)","eeaa36c5":"cat_data = data.drop(columns=num_attributes)","6df6d8c0":"sns.catplot(x='Churn', y='TotalCharges',hue='gender',kind='bar',edgecolor='.3', data=data)","891ceccf":"g = sns.catplot(x=\"TotalCharges\", y=\"Churn\", row=\"Contract\",\n                kind=\"bar\", orient=\"h\", height=1.5, aspect=4,\n                data=data.query(\"TotalCharges < 3000\"))\n","c9cab1ff":"g = sns.catplot(x=\"MonthlyCharges\", y=\"Churn\", row=\"SeniorCitizen\",\n                kind=\"bar\", orient=\"h\", height=1.5, aspect=4,\n                data=data.query(\"TotalCharges < 3000\"))","d2f3b523":"fig = plt.figure(figsize = (15,10))\n\nax1 = fig.add_subplot(2,3,1)\nsns.countplot(data = data, x = 'Partner', ax=ax1)\n\nax2 = fig.add_subplot(2,3,2)\nsns.countplot(data = data, x = 'Dependents', ax=ax2)\n\nax3 = fig.add_subplot(2,3,3)\nsns.countplot(data = data, x = 'PaperlessBilling', ax=ax3)\n\nax4 = fig.add_subplot(2,3,4)\n#sns.boxplot(data = data, x = 'Partner', y = data['MonthlyCharges'] , ax=ax4)\nsns.violinplot(data = data, x = 'Partner', y = data['MonthlyCharges'] , ax=ax4, palette='pastel')\n\nax5 = fig.add_subplot(2,3,5)\nsns.violinplot(data = data, x = 'Dependents', y = data['MonthlyCharges'], ax=ax5, palette='pastel')\n\nax6 = fig.add_subplot(2,3,6)\nsns.violinplot(data = data, x = 'PaperlessBilling', y = data['MonthlyCharges'], ax=ax6, palette='pastel')\n","5149ee62":"data = data.drop('customerID', axis=1)","88a5e470":"from sklearn.preprocessing import LabelEncoder\n\ndef encoder(df):\n    cat_df = LabelEncoder().fit_transform(df)\n    return cat_df","a8fd7e3a":"data = data.apply(lambda x: encoder(x))\ndata.head()","a78968a6":"from sklearn.metrics import accuracy_score\nfrom sklearn.ensemble import RandomForestClassifier\nfrom xgboost import XGBClassifier","cd5590f5":"n = len(data)\n\nn_val = int(0.2 * n)\nn_test = int(0.2 * n)\nn_train = n - (n_test + n_val)\n\nnp.random.seed(2)\nidx = np.arange(n)\nnp.random.shuffle(idx)\n\ndf_shuffled = data.iloc[idx]\n\ndf_train = df_shuffled.iloc[:n_train].copy()\ndf_val = df_shuffled.iloc[n_train:n_train+n_val].copy()\ndf_test = df_shuffled.iloc[n_train+n_val:].copy()","75480653":"df_train['TotalCharges'] = np.sqrt(data['TotalCharges'])\ndf_val['TotalCharges'] = np.sqrt(data['TotalCharges'])\ndf_test['TotalCharges'] = np.sqrt(data['TotalCharges'])","30693436":"y_train = df_train['Churn']\ny_val = df_val['Churn']\ny_test = df_test['Churn']","1784b23e":"df_train = df_train.drop('Churn', 1)\ndf_val = df_val.drop('Churn', 1)\ndf_test = df_test.drop('Churn', 1)","14f6d60d":"classifiers = [['RandomForest :', RandomForestClassifier()],\n              ['XGB :', XGBClassifier()]]\n\npredictions_df = pd.DataFrame()\npredictions_df['actual_labels'] = y_val","4e6f5ca0":"for name,classifier in classifiers:\n    classifier = classifier\n    classifier.fit(df_train, y_train)\n    predictions = classifier.predict(df_val)\n    predictions_df[name.strip(\" :\")] = predictions\n    print(name, accuracy_score(y_val, predictions).round(2))\n    test_predictions = classifier.predict(df_test)\n    print(\"Test accuracy:\", accuracy_score(y_test, test_predictions).round(2))","7542c033":"from sklearn.ensemble import VotingClassifier\nfrom sklearn.linear_model import LogisticRegression\nfrom catboost import CatBoostClassifier\nfrom sklearn.ensemble import AdaBoostClassifier\n\nclf1 = RandomForestClassifier(n_estimators=1000 , oob_score = True, n_jobs = -1,\n                                  random_state =50, max_features = \"auto\",\n                                  max_leaf_nodes = 30)\nclf2 = CatBoostClassifier(logging_level='Silent')\nclf3 = XGBClassifier()\nclf4 = AdaBoostClassifier()\nvc = VotingClassifier(estimators=[('rf', clf1),('Cat', clf2) ,('xgb', clf3),('Ada', clf4)],voting='soft')\nvc.fit(df_train, y_train)\npredictions = vc.predict(df_val)\nprint(accuracy_score(y_val, predictions))","fdb6ad1a":"test_predictions = vc.predict(df_test)\nprint(accuracy_score(y_test, test_predictions))","4ca33f6c":"Then replace these missing values with 0 as 'TotalCharges' is a continous variable.","1a1e1671":"# Identifying relation b\/n Continous and Categorical\n\n## Churn vs Gender based on TotalCharges spent\n","0db69b64":"### **Now to quantify our target variable, we can say that customer churn rate is 73%!**! \n### That is really low.  \n\n> A typical \u201cgood\u201d churn rate for SaaS companies that target small businesses is 3-5% monthly. The larger the businesses you target, the lower your churn rate has to be as the market is smaller. For an enterprise-level product (talking $X,000-$XX,000 per month), churn should be < 1% monthly. [source](https:\/\/www.cobloom.com\/blog\/churn-rate-how-high-is-too-high)\n\n**So, Let's dig into the data..and get started..**","7290ddc6":"We can see there are 11 blanks in 'TotalCharges' column. Let's check 'Churn' status for these values.","bea5779a":"From above data we can say that data is balanced w.r.t gender. Let's see w.r.t target variable 'Churn'.","a2930736":"## Handling Categorical data","56282ae8":"## But wait, what is Skewed Distribution?\n\n> If one tail is longer than another, the distribution is skewed. These distributions are sometimes called asymmetric or asymmetrical distributions as they don\u2019t show any kind of symmetry. Symmetry means that one half of the distribution is a mirror image of the other half. For example, the normal distribution is a symmetric distribution with no skew. The tails are exactly the same.\n\n## Handle Skewed data\n\nIt is quite evident from the above plot that there is a definite right skew in the distribution. \n\n> If the values of a certain independent variable (feature) are skewed, depending on the model, skewness may violate model assumptions (e.g. logistic regression) or may impair the interpretation of feature importance. We can address skewed variables by transforming them (i.e. applying the same function to each value). Common transformations include square root (sqrt(x)), logarithmic (log(x)), and reciprocal (1\/x). [source](https:\/\/medium.com\/@ODSC\/transforming-skewed-data-for-machine-learning-90e6cc364b0)\n\nLet's apply sqrt function to 'TotalCharges' to understand further.","4b4233cd":"Well, it\u2019s not normally distributed for sure, but is a lot better than what we had before!","39a90834":"### Split the data into train, validation and test sets","1aef2d4f":"# Identifying relation between Continous Variables: ","a80f6758":"## Analysis of remaining discrete variables vs continous variable : 'MonthlyCharges'","dcff5dc8":"From the above violin plot, we can say that mean and distribution of monthly charges w.r.t gender is more are less the same. So, based on count plot and violin plot,'gender' alone may not be a good predictive feature of 'Churn'. ","38bea0e2":"# Tree-Based Models and Voting Classifier","a07b4b65":"Let's see on an average **how long our customers are with us** !!","2caef257":"# **Analysis of Target Variable**\n\nA **Bar Chart** is a good choice when we want to show how a quantity varies among some discrete set of items. In our case, our target variable 'Churn' is discrete.","1dc33660":"Around 10 months, which is not pretty bad ..","3ee26ab5":"# **Plotting univariate distributions**\n\n> A histogram represents the distribution of data by forming bins along the range of the data and then drawing bars to show the number of observations that fall in each bin. [Source - Seaborn Tutorial](https:\/\/seaborn.pydata.org\/tutorial\/distributions.html#plotting-univariate-distributions)","5ebf6a22":"## Churn vs Contract based on TotalCharges spent","bdb55bdf":"> The most convenient way to take a quick look at a univariate distribution in seaborn is the distplot() function. By default, this will draw a histogram and fit a kernel density estimate (KDE).\n [Source - Seaborn Tutorial](https:\/\/seaborn.pydata.org\/tutorial\/distributions.html#plotting-univariate-distributions)","5bc5964c":"# What is Customer Churn?\n\n> Churn rate, in its broadest sense, is a measure of the number of individuals or items moving out of a collective group over a specific period. It is one of two primary factors that determine the steady-state level of customers a business will support. source - wiki","c195a1c3":"## Data Cleaning:\n\nTo check for errors, deal with special values, convert data into di\ufb00erent formats, and perform calculations. These operations are called data cleaning.\n\nLet's check for spaces and blanks in our data.","25fb3d72":"It is not recommended to use the same label encoder for all the features in the data set. It is safe to create a label encoder for each column because each feature varies in terms of the values. That's what we are doing below.","efcf8f84":"## Churn vs SeniorCitizen based on MonthlyCharges spent"}}