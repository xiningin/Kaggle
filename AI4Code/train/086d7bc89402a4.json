{"cell_type":{"b48d03ea":"code","3fa6ab8a":"code","e9d81524":"code","5c328c2f":"code","8b7b9479":"code","2d9b563d":"code","022aa929":"code","825690bb":"code","3c524f07":"code","7ddf101b":"code","3452a14c":"code","4db19c2c":"code","6e195694":"code","48570e24":"code","5b7e946e":"code","bed97d99":"code","54b47378":"code","1792ec8b":"code","03b0a0d9":"code","8503bcf4":"code","faf21517":"code","959cd4af":"code","0b2b17c9":"code","de75d8fb":"code","6d00c5b2":"code","8598dee2":"code","f30b46d7":"code","df4aba09":"code","fb4bc2ef":"code","04790328":"code","db9a6bc4":"code","5d5818ac":"code","538dc380":"code","a2eb78ab":"code","163f5c78":"code","5f465508":"code","f2e1398f":"code","3cab75f5":"code","35166c19":"code","b26d1169":"code","32f10ad0":"code","1d2b4520":"code","dfbfcb00":"code","2d243f6e":"code","eda0a2ef":"code","776e272d":"code","97f160d1":"markdown","4f8c36cb":"markdown","6ff9e759":"markdown","27452c01":"markdown","5203f8eb":"markdown","b04f3c33":"markdown","c4616d63":"markdown","4511c3cc":"markdown","a0d07a48":"markdown","eb3d738e":"markdown","3af155c1":"markdown","f9a3a6fa":"markdown","5e233b40":"markdown","351ad0d8":"markdown","5731799e":"markdown","48f033fb":"markdown","6c622baf":"markdown"},"source":{"b48d03ea":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","3fa6ab8a":"import numpy as np \nimport pandas as pd \nimport seaborn as sns","e9d81524":"data = pd.read_csv(\"\/kaggle\/input\/mercedes-benz-greener-manufacturing\/train.csv\")","5c328c2f":"dtest = pd.read_csv(\"\/kaggle\/input\/mercedes-benz-greener-manufacturing\/test.csv\")","8b7b9479":"# make a list of the variables that contain missing values\nvars_with_na = data.columns[data.isnull().any()].tolist()\nvars_with_na_test = dtest.columns[dtest.isnull().any()].tolist()\nprint (len(vars_with_na), len(vars_with_na_test))","2d9b563d":"train_test_data = [data, dtest]","022aa929":"# list of numerical variables\nfor dataset in train_test_data:\n    num_vars = [var for var in dataset.columns if dataset[var].dtypes != 'O']\n\n    print('Number of numerical variables: ', len(num_vars))","825690bb":"num_vars = [var for var in data.columns if data[var].dtypes != 'O']\nXdatanum = data[num_vars].drop([\"ID\", \"y\"], axis = 1)\nfor var in Xdatanum.columns:\n    if Xdatanum[var].max()>1:\n        print (\"there are value greater than 1\")","3c524f07":"# list of categorical variables\ncat_vars = [var for var in data.columns if data[var].dtypes == 'O']\n\nprint('Number of categorical variables: ', len(cat_vars))\n\n# visualise the numerical variables\ndata[cat_vars].head()","7ddf101b":"import matplotlib.pyplot as plt\n\nfor c in data[cat_vars]:\n    value_counts = data[c].value_counts()\n    fig, ax = plt.subplots(figsize=(10, 5))\n    plt.title('Categorical feature {} - Cardinality {}'.format(c, len(np.unique(data[c]))))\n    plt.xlabel('Feature value')\n    plt.ylabel('Occurences')\n    plt.bar(range(len(value_counts)), value_counts.values)\n    ax.set_xticks(range(len(value_counts)))\n    ax.set_xticklabels(value_counts.index, rotation='vertical')\n    plt.show()","3452a14c":"sns.boxplot(x = data[\"X0\"] , y = \"y\" , data= data)","4db19c2c":"sns.scatterplot(x = data[\"X4\"] , y = \"y\" , data= data)","6e195694":"suspiciousData = []\n\nfor col in data:\n    \n    if len(data[col].unique()) == 1:\n        suspiciousData.append(col)\ndata[suspiciousData].describe()","48570e24":"for dataset in train_test_data:\n\n    dataset = dataset.drop(suspiciousData, 1, inplace = True)","5b7e946e":"dtype_df = data.dtypes.reset_index()\ndtype_df.columns = [\"Count\", \"Column Type\"]\ndtype_df.groupby(\"Column Type\").aggregate('count').reset_index()","bed97d99":"sns.distplot(data[\"y\"])","54b47378":"data[\"y\"].describe()","1792ec8b":"categoricalData = data[cat_vars]\ncategoricalData.info()","03b0a0d9":"for var in cat_vars:\n    fig, ax = plt.subplots(figsize=(10, 5))\n    sns.barplot(x = var, y = \"y\" , data = data)","8503bcf4":"import category_encoders as ce\n\n# Create the encoder itself\nCount_enc = ce.CountEncoder(cols=cat_vars)\n# Fit the encoder using the categorical features \nCount_enc.fit(data[cat_vars], data[\"y\"])\n\ndata = data.join(Count_enc.transform(data[cat_vars]).add_suffix('_count'))\ndtest = dtest.join(Count_enc.transform(dtest[cat_vars]).add_suffix('_count'))","faf21517":"data = data.drop(data[cat_vars], axis = 1)\ndtest = dtest.drop(dtest[cat_vars], axis = 1)","959cd4af":"cat_count = ['X0_count', 'X1_count', 'X2_count', 'X3_count',\n       'X4_count', 'X5_count', 'X6_count', 'X8_count']","0b2b17c9":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(data[cat_count])\ndata[cat_count] = scaler.transform(data[cat_count])\ndtest[cat_count] = scaler.transform(dtest[cat_count])\nprint(scaler.data_max_)","de75d8fb":"data.describe()","6d00c5b2":"#data = data[data[\"y\"] < 220]","8598dee2":"data =  data.drop(\"ID\" , axis = 1)","f30b46d7":"X = data.drop(\"y\" , axis =  1)\ny = data[\"y\"]\nX.shape","df4aba09":"X= X.values\ny = y.values","fb4bc2ef":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y, random_state=0, test_size = 0.2 )","04790328":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\n\nfrom keras import backend as K","db9a6bc4":"batch_size = 150\nepochs =100\n# input image dimensions\nimg_rows, img_cols = 28, 13\n#inputshape = X.shape[1]","5d5818ac":"if K.image_data_format() == 'channels_first':\n    X_train = X_train.reshape(X_train.shape[0], 1, img_rows, img_cols)\n    X_test = X_test.reshape(X_test.shape[0], 1, img_rows, img_cols)\n    input_shape = (1, img_rows, img_cols)\nelse:\n    X_train = X_train.reshape(X_train.shape[0], img_rows, img_cols, 1)\n    X_test = X_test.reshape(X_test.shape[0], img_rows, img_cols, 1)\n    input_shape = (img_rows, img_cols, 1)\n\nX_train = X_train.astype('float32')\nX_test = X_test.astype('float32')\n\nprint('x_train shape:', X_train.shape)\nprint(X_train.shape[0], 'train samples')\nprint(X_test.shape[0], 'test samples')","538dc380":"def r2_keras(y_true, y_pred):\n    SS_res =  K.sum(K.square( y_true - y_pred )) \n    SS_tot = K.sum(K.square( y_true - K.mean(y_true) ) ) \n    return ( 1 - SS_res\/(SS_tot + K.epsilon()) )","a2eb78ab":"import matplotlib.pyplot as plt\n\nplt.imshow(X_train[0].reshape(28,13))","163f5c78":"from keras.layers.normalization import BatchNormalization\n\nmodel = Sequential()\n#model.add(Dense(256, activation='relu', input_dim=366))\nmodel.add(Conv2D(64, (3, 3), activation='relu', input_shape = input_shape))\n#model.add(Conv2D(128, (3, 3), activation='relu'))\n#model.add(Conv2D(64, (3, 3), init='uniform'))\n\nmodel.add(MaxPooling2D(pool_size=(2, 2)))\n\nmodel.add(Flatten())\n\nmodel.add(Dense(512, activation='relu'))\nmodel.add(Dropout(0.1))\n\nmodel.add(Dense(256, activation='relu'))\nmodel.add(Dense(128, activation='relu'))\n\nmodel.add(Dense(1, activation='linear'))\n\n\nmodel.compile(loss='mean_squared_error', # one may use 'mean_absolute_error' as  mean_squared_error\n                  optimizer='adam',\n                  metrics=[r2_keras] # you can add several if needed\n                 )\n\nmodel.summary()","5f465508":"model.fit(X_train, y_train,\n          batch_size=batch_size,\n          epochs=epochs,\n          verbose=2,\n          validation_data=(X_test, y_test))\nscore = model.evaluate(X_test, y_test, verbose=0)","f2e1398f":"print('Test loss:', score)","3cab75f5":"preds = model.predict(X_test)\npreds = preds[:,0]\nplt.scatter(y_test, preds)","35166c19":"residuals = y_test - preds\nsns.distplot(residuals)","b26d1169":"from sklearn.metrics import r2_score\nr2_score(y_test, preds)  ","32f10ad0":"test_data = dtest.drop(\"ID\", axis=1).copy()\n#test_data = dtest[selectedFeatures].copy()\n\nX = test_data.values\nX.shape","1d2b4520":"if K.image_data_format() == 'channels_first':\n    X = X.reshape(X.shape[0], 1, img_rows, img_cols)\n    \n    input_shape = (1, img_rows, img_cols)\nelse:\n    X = X.reshape(X.shape[0], img_rows, img_cols, 1)\n    \n    input_shape = (img_rows, img_cols, 1)\n\nX = X.astype('float32')\n\nprint('X shape:', X.shape)\n\nprint(X.shape[0], 'test samples')","dfbfcb00":"prediction = model.predict(X)","2d243f6e":"prediction = prediction[:,0]","eda0a2ef":"dtest.info()","776e272d":"submission = pd.DataFrame({\n        \"ID\": dtest[\"ID\"],\n        \"y\": prediction\n    })\n\nsubmission.to_csv('submission_5.csv', index=False)","97f160d1":"### Group the Data [train and test]","4f8c36cb":"## Train test split","6ff9e759":"### Check for value greater than 1","27452c01":"# testing","5203f8eb":"### Looking at individual plot\n\n* change the label column","b04f3c33":"### Type of data","c4616d63":"# Define X and y","4511c3cc":"## Categorical data","a0d07a48":"## Outilier","eb3d738e":"## Target analysis","3af155c1":"# Build and train the CNN model","f9a3a6fa":"# visualise the predictions and residuals","5e233b40":"# Feature Scaling","351ad0d8":"### Missing Values\n\n* No missing values","5731799e":"# Count encoder","48f033fb":"### Suspicious data","6c622baf":"### Drop suspicious features"}}