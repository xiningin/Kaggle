{"cell_type":{"958a40a1":"code","63cb2d83":"code","bcb55021":"code","81f12f73":"code","a57d4fd8":"code","ce39f9e5":"code","619894c0":"code","191bae2d":"code","a5e574ea":"code","e85afea9":"code","6738da20":"code","50a32a30":"code","a18f3b20":"code","ed7371f9":"code","41674440":"code","74cecb0a":"code","59b77caa":"code","4f2a3879":"markdown","c8dbbf96":"markdown","330033d9":"markdown","6f1e4d34":"markdown","541f24ed":"markdown","c62e529d":"markdown","7c7c8d40":"markdown"},"source":{"958a40a1":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","63cb2d83":"home_data_file = '..\/input\/house-prices-advanced-regression-techniques\/train.csv'\ntest_data_file = '..\/input\/house-prices-advanced-regression-techniques\/test.csv'","bcb55021":"home_data = pd.read_csv(home_data_file,index_col='Id')\ntest_data = pd.read_csv(test_data_file,index_col='Id')","81f12f73":"home_data.info()","a57d4fd8":"home_data.isnull().sum()","ce39f9e5":"diff_col= set(test_data)-set(home_data)\nhome_data.drop(columns=diff_col,axis = 1, inplace=True)\ntest_data.drop(columns=diff_col,axis = 1, inplace=True)","619894c0":"cols_with_miss_train_data = [col for col in home_data.columns \n                            if home_data[col].isnull().any()]\n\ncols_with_miss_test_data = [col for col in test_data.columns \n                            if test_data[col].isnull().any()]\n\nall_missing_columns = cols_with_miss_train_data + cols_with_miss_test_data\nhome_data.drop(columns=all_missing_columns, axis=1,inplace=True)\ntest_data.drop(columns=all_missing_columns, axis=1,inplace=True)","191bae2d":"filteredColumns = home_data.dtypes[home_data.dtypes == np.object]\nlistOfColumnNames = list(filteredColumns.index)\nlistOfColumnNames","a5e574ea":"home_data.drop(listOfColumnNames, axis=1,inplace=True)\ntest_data.drop(listOfColumnNames, axis=1,inplace=True)","e85afea9":"target_col = 'SalePrice'\ny = home_data[target_col]\ny","6738da20":"X = home_data.select_dtypes(exclude='object')\nX = X.drop(columns=[target_col])\nX","50a32a30":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y)","a18f3b20":"from xgboost.sklearn import XGBRegressor\nparameters = [{\n'n_estimators': list(range(100, 301, 100)), \n'learning_rate': [x \/ 100 for x in range(5, 101, 5)],\n'max_depth':[6,7,8]\n}]\nfrom sklearn.model_selection import GridSearchCV\ngsearch = GridSearchCV(estimator=XGBRegressor(),\n                       param_grid = parameters, \n                       scoring='neg_mean_absolute_error',\n                       n_jobs=4,cv=5)\n\ngsearch.fit(X_train, y_train)\n\ngsearch.best_params_.get('n_estimators'), gsearch.best_params_.get('learning_rate'),gsearch.best_params_.get('max_depth')","ed7371f9":"from sklearn.metrics import mean_absolute_error\n\nf_model = XGBRegressor(n_estimators=gsearch.best_params_.get('n_estimators'),learning_rate = gsearch.best_params_.get('learning_rate'),\n                       max_depth =gsearch.best_params_.get('max_depth'),random_state = 1 )\nf_model.fit(X_train, y_train)\npred = f_model.predict(X_train)\n\nmean_absolute_error(y_train,pred)","41674440":"final_model = XGBRegressor(n_estimators=gsearch.best_params_.get('n_estimators'),learning_rate = gsearch.best_params_.get('learning_rate'),\n                       max_depth =gsearch.best_params_.get('max_depth'),random_state = 1 )\nfinal_model.fit(X, y)\npred = final_model.predict(test_data)","74cecb0a":"test_out = pd.DataFrame({\n    'Id': test_data.index, \n    'SalePrice': pred,\n})","59b77caa":"test_out.to_csv('submission.csv', index=False)","4f2a3879":"# Equal number of columns for two csv files\n","c8dbbf96":"# Print how much missing values\n","330033d9":"# **Path File**","6f1e4d34":"# Get object columns","541f24ed":"# By using panada read csv file","c62e529d":"# Drop missing columns\n","7c7c8d40":"# Get info of csv file\n"}}