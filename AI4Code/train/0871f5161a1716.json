{"cell_type":{"dffd420b":"code","4bf99be8":"code","765b1da8":"code","ab344c77":"code","a2846f45":"code","1808c4db":"code","3774c2aa":"code","13dabe2a":"code","7582b77c":"code","26728fdb":"code","db2ffefb":"code","b190483a":"code","49bc8557":"code","15349380":"code","f28b2ccb":"code","eef90829":"code","9edfaecb":"code","0fa67fb5":"code","bc0ee4f8":"code","917e8ee2":"code","47109123":"code","a8156f20":"code","83aea636":"code","d8a5d0fb":"code","77e2af36":"code","9ed25796":"code","1c332ec9":"code","da426823":"code","f4104341":"code","decee1f8":"code","7f818977":"code","afd5474a":"code","7aefd204":"code","a3b8b79d":"markdown"},"source":{"dffd420b":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport numpy as np","4bf99be8":"df = pd.read_csv(\"\/kaggle\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")","765b1da8":"df.head()","ab344c77":"pd.set_option('display.max_rows',None)\npd.set_option('display.max_columns',None)","a2846f45":"def initial_observation(df):\n    if isinstance(df, pd.DataFrame):\n        total_na = df.isna().sum().sum()\n        print(\"Dimensions : %d rows, %d columns\" % (df.shape[0], df.shape[1]))\n        print(\"Total NA Values : %d \" % (total_na))\n        print(\"%38s %10s     %10s %10s\" % (\"Column Name\", \"Data Type\", \"#Distinct\", \"NA Values\"))\n        col_name = df.columns\n        dtyp = df.dtypes\n        uniq = df.nunique()\n        na_val = df.isna().sum()\n        for i in range(len(df.columns)):\n            print(\"%38s %10s   %10s %10s\" % (col_name[i], dtyp[i], uniq[i], na_val[i]))\n        \n    else:\n        print(\"Expect a DataFrame but got a %15s\" % (type(df)))\n                  \n                       \n              ","1808c4db":"initial_observation(df)","3774c2aa":"# Correlation matrix - linear relation among independent attributes and with the Target attribute\n\nsns.set(style=\"white\")\n\n# Compute the correlation matrix\ncorreln = df.corr()\n\n# Generate a mask for the upper triangle\n#mask = np.zeros_like(correln, dtype=np.bool)\n#mask[np.triu_indices_from(mask)] = True\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(11, 9))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(correln,  cmap=cmap, vmax=.3, #mask=mask,\n            linewidths=.8, cbar_kws={\"shrink\": .9})","13dabe2a":"sns.set()\nsns.pairplot(df, size = 2.5)\nplt.show()","7582b77c":"df[\"alcohol\"].describe()","26728fdb":"plt.boxplot(df[\"alcohol\"])\nplt.show()","db2ffefb":"sns.barplot(df[\"quality\"], df[\"alcohol\"])","b190483a":"sns.barplot(df[\"quality\"], df[\"sulphates\"])","49bc8557":"x = df.drop([\"quality\"], axis = 1)\ny = df[\"quality\"]","15349380":"x.head()","f28b2ccb":"y.head()","eef90829":"from sklearn.model_selection import train_test_split\nX_train, X_val, Y_train, Y_val = train_test_split(x,y)","9edfaecb":"X_train_scaled = X_train.copy()\nX_val_scaled = X_val.copy()\n\nfrom sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscaler.fit(X_train_scaled)\nx_train_scaled_1 = scaler.transform(X_train_scaled)\nx_val_scaled_1 = scaler.transform(X_val_scaled)","0fa67fb5":"print(\"X Train shape:\" , X_train.shape)\nprint(\"X Validation shape:\" ,   X_val.shape)\nprint(\"Y Train shape:\",     Y_train.shape)\nprint( \"Y Validation Shape:\",   Y_val.shape)\n","bc0ee4f8":"from sklearn.ensemble import RandomForestRegressor\nfrom sklearn.model_selection import GridSearchCV","917e8ee2":"rf_parm = dict(n_estimators = [20, 30, 50, 70, 100, 150], max_features = [0.1, 0.2, 0.6, 0.9], max_depth = [10,20,30],min_samples_leaf=[1,10,100, 400, 500, 600],random_state=[0])","47109123":"rc = RandomForestRegressor()\nrf_grid = GridSearchCV(estimator = rc, param_grid = rf_parm)","a8156f20":"rf_grid.fit(x_train_scaled_1,Y_train)","83aea636":"rf_grid.best_score_","d8a5d0fb":"rf_grid.best_params_","77e2af36":"rc_best = RandomForestRegressor(n_estimators = 30,  max_features = 0.6)","9ed25796":"rc_best.fit(x_train_scaled_1, Y_train)\nrc_tr_pred = rc_best.predict(x_train_scaled_1)\nrc_val_pred = rc_best.predict(x_val_scaled_1)","1c332ec9":"from sklearn.metrics import r2_score\n\nprint(r2_score(Y_train, rc_tr_pred))\nprint(r2_score(Y_val, rc_val_pred))","da426823":"from sklearn.ensemble import GradientBoostingRegressor\n\ngbrt = GradientBoostingRegressor(random_state = 42)\ngbrt_grid = GridSearchCV(estimator = gbrt, param_grid = dict(n_estimators = [2, 3, 5, 7, 10, 15, 20, 25], max_depth = [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], learning_rate = [0.001, 0.0001, 0.01, 0.1, 1, 100]))","f4104341":"gbrt_grid.fit(x_train_scaled_1, Y_train)","decee1f8":"print(\"Best Boosting Parameters:\", gbrt_grid.best_params_)\nprint(\"Best Boosting Score:\", gbrt_grid.best_score_)","7f818977":"gbrt_best = GradientBoostingRegressor(learning_rate = 0.1, max_depth = 6, n_estimators = 25, random_state = 42)\ngbrt_best.fit(x_train_scaled_1, Y_train)","afd5474a":"gbrt_best_tr_pred = gbrt_best.predict(x_train_scaled_1)\ngbrt_best_val_pred = gbrt_best.predict(x_val_scaled_1)","7aefd204":"from sklearn.metrics import r2_score\n\nprint(r2_score(Y_train, gbrt_best_tr_pred))\nprint(r2_score(Y_val, gbrt_best_val_pred))","a3b8b79d":"### Random Forest"}}