{"cell_type":{"ee9e4989":"code","bf91ed76":"code","e053768c":"code","5addb202":"code","4fb314b3":"code","3d49fd4d":"code","24d53d9e":"code","7fa58128":"code","8e995e79":"code","bb0d00eb":"code","18a57bab":"code","2d6ff98b":"code","a1cf4641":"code","a5936677":"code","37067037":"code","25508d38":"markdown"},"source":{"ee9e4989":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nimport requests\nfrom bs4 import BeautifulSoup\n\nfrom nltk.probability import FreqDist\nfrom nltk.tokenize import sent_tokenize,word_tokenize\nfrom nltk.corpus import stopwords\nfrom string import punctuation\n\n\n# Any results you write to the current directory are saved as output.","bf91ed76":"#Interchange this url with any other one of choice, as part of number 1\n#articleURL=\"https:\/\/arstechnica.com\/cars\/2018\/10\/honda-will-use-gms-self-driving-technology-invest-2-75-billion\/\"\narticleURL = input(\"Enter your URL: \")","e053768c":"#This block parses the html of the page to separate it from the text\nresponse = requests.get(articleURL)\nresponse.encoding = 'utf-8'\ndata = response.text\nsoup = BeautifulSoup(data, features =\"html.parser\")\nprint(soup)\n","5addb202":"#This block checks to verify the input url contains an article tag\n#It then prints to let the user know if an article tag was or was not found\n\nfor tag in soup.find_all('article'):\n    if(tag.name == 'article'):\n        print(\"Article tag found in your html page\")\n    else:\n        print(\"No article tag found\")\n#soup.find('article').text","4fb314b3":"#returns the same thing as soup.find('article').text\ntext = ' '.join(map(lambda p: p.text, soup.find_all('article')))\nprint(text)\n\n#this block cleans up the text from the above blcok called sents\n#it removes all new line tags and 's so word_sent is cleaner\ntext = text.replace(\"\\n\", \" \")\ntext = text.replace(\"'s\", \"\")\ntext = text.replace(\".\",\". \")\n\nprint(text)","3d49fd4d":"#this just prints text again in ascii\ntext.encode('ascii', 'ignore')\nprint(text)                                               ","24d53d9e":"#this block breaks the article into sentences\nsents = sent_tokenize(text)\nsents","7fa58128":"word_sent = word_tokenize(text.lower())\nword_sent","8e995e79":"_stopwords = set(stopwords.words('english') + list(punctuation))\n_stopwords","bb0d00eb":"# Filter out stopword\nword_sent=[word for word in word_sent if word not in _stopwords]\nword_sent","18a57bab":"freq = FreqDist(word_sent)\nfreq\n","2d6ff98b":"#this block gets the ten most frequently used words\nfrom heapq import nlargest\nnlargest(10, freq, key=freq.get)","a1cf4641":"# We want to create a signifcant score ordered by highest frequency\nfrom collections import defaultdict\nranking = defaultdict(int)\nfor i,sent in enumerate(sents):\n    for w in word_tokenize(sent.lower()):\n        if w in freq:\n            ranking[i] += freq[w]\nranking","a5936677":"# Top 3 Sentences\nsents_idx = nlargest(3, ranking, key=ranking.get)\nsents_idx","37067037":"#this block prints the summarized strings\nformattedOutput = [sents[j] for j in sorted(sents_idx)]\nprint(\"Summary Below: \")\nprint(formattedOutput[0])\nprint(formattedOutput[1])\nprint(formattedOutput[2])","25508d38":"# TL;DR - Automated Gist\n## Find the most important words\n### Word Importance = Word Frequency\n## Compute a significance score for sentences based on words they contain\n### Significant score = Sum(Word Importance)\n## Pick the top most significant sentences\n\n* Retrieve Text\n* Preprocess Text\n* Extract Sentences\n\n#### Source: PluralSight - Natural Langauge Processing"}}