{"cell_type":{"99e73ce8":"code","947bb946":"code","4ffba4f2":"code","558e15d0":"code","9eef11ff":"code","f75c8ccd":"code","4c3e8dbd":"code","3af495b3":"code","bb56ec96":"code","08f9bd54":"markdown","492251c3":"markdown","8e53b4c8":"markdown","24d61ecf":"markdown","f0d31c8a":"markdown","c7df77d9":"markdown","7aa70dd1":"markdown","8a0c9d43":"markdown","5413d1c4":"markdown"},"source":{"99e73ce8":"import pandas as pd\n\nbatch_size = 1\nimage_size = 512\ntta = True\nsubmit = (len(pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')) == 3582)\nenet_type = ['resnet200d']*5\nmodel_path = [\n    '..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold0_cv953.pth',\n    '..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold1_cv955.pth',\n    '..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold2_cv955.pth',\n    '..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold3_cv957.pth',\n    '..\/input\/resnet200d-baseline-benchmark-public\/resnet200d_fold4_cv954.pth'\n]\n# you can save GPU quota using fast sub attached in the last markdown file\nfast_sub = True # False True\nfast_sub_path = '..\/input\/submissions\/submission_RANZCR_CLiP.csv'","947bb946":"import os\nimport sys\nsys.path.append('..\/input\/pytorch-image-models\/pytorch-image-models-master')\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nimport numpy as np\nDEBUG = False\nimport time\nimport cv2\nimport PIL.Image\nfrom sklearn.metrics import accuracy_score\nfrom tqdm.notebook import tqdm\nimport torch\nfrom torch.utils.data import DataLoader, Dataset\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torchvision\nimport torchvision.transforms as transforms\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import CosineAnnealingLR\nimport albumentations\nfrom tqdm.notebook import tqdm\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom pylab import rcParams\nimport timm\nfrom albumentations import *\nfrom albumentations.pytorch import ToTensorV2\n\ndevice = torch.device('cuda') if not DEBUG else torch.device('cpu')\nprint(device)","4ffba4f2":"class RANZCRResNet200D(nn.Module):\n    def __init__(self, model_name='resnet200d', out_dim=11, pretrained=False):\n        super().__init__()\n        self.model = timm.create_model(model_name, pretrained=False)\n        n_features = self.model.fc.in_features\n        self.model.global_pool = nn.Identity()\n        self.model.fc = nn.Identity()\n        self.pooling = nn.AdaptiveAvgPool2d(1)\n        self.fc = nn.Linear(n_features, out_dim)\n\n    def forward(self, x):\n        bs = x.size(0)\n        features = self.model(x)\n        pooled_features = self.pooling(features).view(bs, -1)\n        output = self.fc(pooled_features)\n        return output","558e15d0":"transforms_test = albumentations.Compose([\n    Resize(image_size, image_size),\n    Normalize(\n         mean=[0.485, 0.456, 0.406],\n         std=[0.229, 0.224, 0.225],\n     ),\n    ToTensorV2()\n])","9eef11ff":"class RANZCRDataset(Dataset):\n    def __init__(self, df, mode, transform=None):\n        \n        self.df = df.reset_index(drop=True)\n        self.mode = mode\n        self.transform = transform\n        self.labels = df[target_cols].values\n        \n    def __len__(self):\n        return len(self.df)\n    \n    def __getitem__(self, index):\n        row = self.df.loc[index]\n        img = cv2.imread(row.file_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        \n        if self.transform is not None:\n            res = self.transform(image=img)\n            img = res['image']\n        label = torch.tensor(self.labels[index]).float()\n        if self.mode == 'test':\n            return img\n        else:\n            return img, label","f75c8ccd":"test = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')\ntest['file_path'] = test.StudyInstanceUID.apply(lambda x: os.path.join('..\/input\/ranzcr-clip-catheter-line-classification\/test', f'{x}.jpg'))\ntarget_cols = test.iloc[:, 1:12].columns.tolist()\n\ntest_dataset = RANZCRDataset(test, 'test', transform=transforms_test)\ntest_loader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False,  num_workers=24)","4c3e8dbd":"def inference_func(test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n    LOGITS = []\n    PREDS = []\n    \n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            logits = model(x)\n            LOGITS.append(logits.cpu())\n            PREDS += [logits.sigmoid().detach().cpu()]\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        LOGITS = torch.cat(LOGITS).cpu().numpy()\n    return PREDS\n\ndef tta_inference_func(test_loader):\n    model.eval()\n    bar = tqdm(test_loader)\n    PREDS = []\n    LOGITS = []\n\n    with torch.no_grad():\n        for batch_idx, images in enumerate(bar):\n            x = images.to(device)\n            x = torch.stack([x,x.flip(-1)],0) # hflip\n            x = x.view(-1, 3, image_size, image_size)\n            logits = model(x)\n            logits = logits.view(batch_size, 2, -1).mean(1)\n            PREDS += [logits.sigmoid().detach().cpu()]\n            LOGITS.append(logits.cpu())\n        PREDS = torch.cat(PREDS).cpu().numpy()\n        \n    return PREDS","3af495b3":"submit = False\n\nif submit:\n    test_preds = []\n    for i in range(len(enet_type)):\n        if enet_type[i] == 'resnet200d':\n            print('resnet200d loaded')\n            model = RANZCRResNet200D(enet_type[i], out_dim=len(target_cols))\n            model = model.to(device)\n        model.load_state_dict(torch.load(model_path[i], map_location='cuda:0'))\n        if tta:\n            test_preds += [tta_inference_func(test_loader)]\n        else:\n            test_preds += [inference_func(test_loader)]\n\n    submission = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')\n    submission[target_cols] = np.mean(test_preds, axis=0)\n    submission.to_csv('submission.csv', index=False)\nelse:\n    pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv').to_csv('submission.csv', index=False)","bb56ec96":"# https:\/\/www.kaggle.com\/underwearfitting\/inference-public-only-fast\/output#1006689 @paulo pinto\nif fast_sub:\n    pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv',usecols=[0],index_col=0).join(pd.read_csv(fast_sub_path).set_index('StudyInstanceUID')).fillna(0).to_csv('submission.csv')","08f9bd54":"# * Save GPU quota","492251c3":"# 6. Utils","8e53b4c8":"# 4. Transforms","24d61ecf":"# 3. Model","f0d31c8a":"# 7. Submission","c7df77d9":"# 1. Configuration","7aa70dd1":"# 2. Import","8a0c9d43":"# 5. Datasets","5413d1c4":"# Contents\n\n1. Configuration\n\n2. Used Libraries\n\n3. Define Model\n\n4. Data augmentation(Transforms)\n\n5. Datasets\n\n6. Utils\n\n7. Save Submissions\n\n\n* ref \n  - [Sin's work](https:\/\/www.kaggle.com\/underwearfitting\/resnet200d-public-benchmark-2xtta-lb0-965\/data?scriptVersionId=51087772)\n  - [Ashish Gupta's work](https:\/\/www.kaggle.com\/roydatascience\/resnet200d-public-benchmark-inference-model)"}}