{"cell_type":{"ca263f29":"code","31aa862b":"code","acb4c1c8":"code","4169b020":"code","eab900bc":"code","86e4b3d8":"code","009c549b":"code","d8cb17d8":"code","49424c44":"code","6a2e8693":"code","a19c9c8a":"code","36510931":"code","b5377701":"code","5b25dd01":"code","61a35c98":"code","126c7321":"code","f172c071":"code","6679b980":"code","da3fb314":"code","7ff6e58a":"code","79ec99d7":"code","0ca6798e":"code","ab8f81bd":"code","55a9d173":"code","1cb99377":"code","209f761a":"code","12df4715":"code","2c6b5bb0":"code","f0c00315":"code","4aff6d1f":"code","5f0af840":"code","695623a5":"code","9678f76f":"code","b286d26b":"markdown","b0c8a7d4":"markdown","baf5a0cd":"markdown","da2f6d4b":"markdown","f7adc8a6":"markdown","b9355fe3":"markdown","6f1ba9c2":"markdown","4a4b6d5c":"markdown","3aeae2ac":"markdown","1ae49d16":"markdown","488d107f":"markdown","2e61c5f6":"markdown","835eca4a":"markdown"},"source":{"ca263f29":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","31aa862b":"from warnings import filterwarnings\nfilterwarnings(\"ignore\")\n\nimport matplotlib.pyplot as plt \nimport seaborn as sns \n\nfrom sklearn.metrics import silhouette_score\nfrom sklearn.decomposition import PCA\nfrom sklearn.cluster import KMeans, DBSCAN, Birch\nfrom sklearn.mixture import GaussianMixture","acb4c1c8":"sns.set_style('darkgrid', {\"axes.facecolor\": \".85\"})\nsns.set_context(\"notebook\", font_scale=1.2, rc={\"lines.linewidth\": 1.2})","4169b020":"data = pd.read_csv('..\/input\/customer-segmentation-tutorial-in-python\/Mall_Customers.csv')","eab900bc":"data.shape","86e4b3d8":"data.head()","009c549b":"data.isna().sum()","d8cb17d8":"data.info()","49424c44":"data.describe()","6a2e8693":"X = data.drop(['CustomerID', 'Gender'], axis=1)","a19c9c8a":"# PCA for visualization\npca = PCA(n_components = 2)\npca.fit(X)\nX_pca = pca.transform(X)","36510931":"# plot PCA components\nfig, axs = plt.subplots(figsize=[10,10])\nsns.scatterplot(x=X_pca[:,0],\n                y=X_pca[:,1],\n                edgecolor=None,\n                alpha=0.8,\n                ax=axs)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('Scatter plot')\nplt.show()","b5377701":"pca.explained_variance_ratio_","5b25dd01":"model = DBSCAN(eps=12, min_samples=3)\nlabels = model.fit_predict(X)","61a35c98":"np.unique(labels)","126c7321":"# plot PCA components\nfig, axs = plt.subplots(figsize=[10,10])\nsns.scatterplot(x=X_pca[:,0],\n                y=X_pca[:,1],\n                hue=labels,\n                palette=sns.xkcd_palette(['black', 'greenish teal', 'cyan', 'red pink', 'amber', 'purple', 'red orange']),\n                edgecolor=None,\n                alpha=0.8,\n                ax=axs)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('Clusters')\nplt.show()","f172c071":"inertia = []\nfor n in range(2 , 11):\n    model = KMeans(n_clusters=n, random_state=21, algorithm='elkan')\n    model.fit(X)\n    inertia.append(model.inertia_)","6679b980":"plt.figure(figsize = (12 ,6))\nplt.plot(np.arange(2 , 11) , inertia , 'o', c=sns.xkcd_rgb['red pink'])\nplt.plot(np.arange(2 , 11) , inertia , '-' ,c=sns.xkcd_rgb['greenish teal'], alpha = 0.8)\nplt.xlabel('Number of Clusters') , plt.ylabel('Inertia')\nplt.show()","da3fb314":"model = KMeans(n_clusters=5, random_state= 21, algorithm='elkan')\nmodel.fit(X)\nlabels = model.labels_","7ff6e58a":"# plot PCA components\nfig, axs = plt.subplots(figsize=[10,10])\nsns.scatterplot(x=X_pca[:,0],\n                y=X_pca[:,1],\n                hue=labels,\n                palette=sns.color_palette('husl', 5),\n                edgecolor=None,\n                alpha=0.8,\n                ax=axs)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('Clusters')\nplt.show()","79ec99d7":"model = KMeans(n_clusters=6, random_state= 21, algorithm='elkan')\nmodel.fit(X)\nlabels = model.labels_","0ca6798e":"# plot PCA components\nfig, axs = plt.subplots(figsize=[10,10])\nsns.scatterplot(x=X_pca[:,0],\n                y=X_pca[:,1],\n                hue=labels,\n                palette=sns.color_palette('husl', 6),\n                edgecolor=None,\n                alpha=0.8,\n                ax=axs)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('Clusters')\nplt.show()","ab8f81bd":"score = []\nppl = []\naic = []\nbic = []\nfor n in range(2 , 11):\n    model = GaussianMixture(n_components=n)\n    model.fit(X)\n    score.append(silhouette_score(X, model.predict(X)))\n    ppl.append(np.exp(model.score(X)))\n    aic.append(model.aic(X))\n    bic.append(model.bic(X))","55a9d173":"fig, axs = plt.subplots(2,1, figsize = (12 ,12))\n\n## plot silhouette score\naxs[0].plot(np.arange(2 , 11) , score , 'o', c=sns.xkcd_rgb['red pink'])\naxs[0].plot(np.arange(2 , 11) , score , '-' ,c=sns.xkcd_rgb['greenish teal'], alpha = 0.8)\naxs[0].set_xlabel('Number of Clusters') , axs[0].set_ylabel('Silhouette Score')\n# axs[0].set_title('Silhouette Score')\n\n## plot aic and bic\naxs[1].plot(np.arange(2 , 11) , aic , '-', c=sns.xkcd_rgb['amber'], label='AIC')\naxs[1].plot(np.arange(2 , 11) , bic , '-' ,c=sns.xkcd_rgb['greenish teal'], label='BIC')\naxs[1].set_ylabel('')\naxs[1].set_xlabel('number of clusters')\naxs[1].legend(loc='best')\n\n\n## plot perplexcity\n# axs[2].plot(np.arange(2 , 11) , ppl , '-' ,c=sns.xkcd_rgb['greenish teal'])\n# axs[2].set_ylabel('perplexity')\n# axs[2].set_xlabel('number of clusters')\n\nplt.show()","1cb99377":"model = GaussianMixture(n_components=5)\nmodel.fit(X)\nlabels = model.predict(X)","209f761a":"# plot PCA components\nfig, axs = plt.subplots(figsize=[10,10])\nsns.scatterplot(x=X_pca[:,0],\n                y=X_pca[:,1],\n                hue=labels,\n                palette=sns.color_palette('husl', 5),\n                edgecolor=None,\n                alpha=0.8,\n                ax=axs)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('Clusters')\nplt.show()","12df4715":"# Print Silhouette score for five clusters\nsilhouette_score(X, model.predict(X))","2c6b5bb0":"model = GaussianMixture(n_components=6)\nmodel.fit(X)\nlabels = model.predict(X)","f0c00315":"# plot PCA components\nfig, axs = plt.subplots(figsize=[10,10])\nsns.scatterplot(x=X_pca[:,0],\n                y=X_pca[:,1],\n                hue=labels,\n                palette=sns.color_palette('husl', 6),\n                edgecolor=None,\n                alpha=0.8,\n                ax=axs)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('Clusters')\nplt.show()","4aff6d1f":"# Print Silhouette score for six clusters\nsilhouette_score(X, model.predict(X))","5f0af840":"model = Birch(n_clusters=5)\nmodel.fit(X)\nlabels = model.predict(X)","695623a5":"np.unique(labels)","9678f76f":"# plot PCA components\nfig, axs = plt.subplots(figsize=[10,10])\nsns.scatterplot(x=X_pca[:,0],\n                y=X_pca[:,1],\n                hue=labels,\n                palette=sns.color_palette('husl', 5),\n                edgecolor=None,\n                alpha=0.8,\n                ax=axs)\nplt.xlabel('PC1')\nplt.ylabel('PC2')\nplt.title('Clusters')\nplt.show()","b286d26b":"## Birch","b0c8a7d4":"### Six Clusters","baf5a0cd":"## Algorithms\n\n1.  DBSCAN\n2.  K-Means\n3.  Gaussian Mixture models\n4.  BIRCH","da2f6d4b":"### Five clusters","f7adc8a6":"## EDA","b9355fe3":"## Gaussian Mixtures","6f1ba9c2":"## DBSCAN","4a4b6d5c":"## Import Libraries","3aeae2ac":"### Six clusters","1ae49d16":"## K means","488d107f":"## PCA","2e61c5f6":"### Five clusters","835eca4a":"## References\n\n*  https:\/\/www.mygreatlearning.com\/blog\/dbscan-algorithm\/\n*  https:\/\/blog.floydhub.com\/introduction-to-k-means-clustering-in-python-with-scikit-learn\/\n*  https:\/\/www.analyticsvidhya.com\/blog\/2019\/10\/gaussian-mixture-models-clustering\/\n*  https:\/\/jakevdp.github.io\/PythonDataScienceHandbook\/05.12-gaussian-mixtures.html\n*  https:\/\/dl.acm.org\/doi\/10.1145\/235968.233324\n*  https:\/\/machinelearningmastery.com\/clustering-algorithms-with-python\/"}}