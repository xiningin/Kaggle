{"cell_type":{"ab1d3346":"code","f25e0166":"code","80fdab09":"code","47f9f967":"code","90088f1b":"code","3aa6b9b2":"code","c8e81026":"code","e11abcb2":"code","93b82033":"code","61c6cb1a":"code","17e5fe40":"code","bfaf6d09":"code","e7a77da0":"code","47948499":"code","2799c7ed":"code","40636008":"code","59a6151b":"code","774d0dfe":"code","797d725a":"code","d2780b57":"code","04862997":"code","68815236":"code","ce0498c2":"code","bfe257a4":"code","64b3d1e5":"markdown"},"source":{"ab1d3346":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f25e0166":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt","80fdab09":"\n# loading data\ndata = pd.read_csv('\/kaggle\/input\/Mall_Customers.csv')\ndata.head()","47f9f967":"data.info()","90088f1b":"\ndata.describe().T","3aa6b9b2":"data.isna().sum()","c8e81026":"mall_data = data.copy(deep= True)\nmall_data.head()","e11abcb2":"# drop unnecessary attributes\nmall_data.drop(columns= 'CustomerID', inplace= True)\nmall_data.head()","93b82033":"sns.countplot(x = 'Gender', data = mall_data)\nplt.show()","61c6cb1a":"sns.scatterplot(x = 'Age', y = 'Annual Income (k$)', data = mall_data, hue = 'Gender')\nsns.jointplot(x = 'Age', y = 'Annual Income (k$)', data = mall_data)\nplt.show()","17e5fe40":"sns.scatterplot(x = 'Age', y = 'Spending Score (1-100)', data = mall_data, hue = 'Gender')\nsns.jointplot(x = 'Age', y = 'Spending Score (1-100)', data = mall_data)\nplt.show()","bfaf6d09":"sns.scatterplot(x = 'Annual Income (k$)', y = 'Spending Score (1-100)', data = mall_data, hue = 'Gender')\nsns.jointplot(x = 'Annual Income (k$)', y = 'Spending Score (1-100)', data = mall_data)\nplt.show()","e7a77da0":"\n## preparing the data\nmall_data.iloc[:, [2,3]].head()","47948499":"\n# check data distribution\nplt.style.use('seaborn')\nmall_data.iloc[:, [2,3]].hist(figsize = (14,3))\nplt.show()","2799c7ed":"X = mall_data.iloc[:, [2,3]].values","40636008":"# Finding optimal number of clusters using elbow method\nfrom sklearn.cluster import KMeans\nwcss = []\n\nfor i in range(1,11):\n    kmeans = KMeans(n_clusters= i, init= 'k-means++', random_state= 15)\n    kmeans.fit(X)\n    wcss.append(kmeans.inertia_)","59a6151b":"# visualization for optimal number of clusters\nplt.plot(range(1,11), wcss, marker = 'o',linestyle = 'dashed')\nplt.text(4.9,40000, 'X',bbox=dict(facecolor='red', alpha=0.6) )\nplt.title('Elbow Method')\nplt.xlabel('number of clusters')\nplt.ylabel('wcss')\nplt.show()\n\n# It is clear from the elbow curve, 5 clusters will solve the problem","774d0dfe":"# scaling\nfrom sklearn.preprocessing import StandardScaler\nsc = StandardScaler()\nX = sc.fit_transform(X)","797d725a":"# Training the KMeans model with n_clusters=5\nkmeans_model = KMeans(n_clusters=5, init='k-means++', random_state=42)\ny_kmeans = kmeans_model.fit_predict(X)","d2780b57":"y_kmeans","04862997":"data_segments = pd.concat([mall_data, pd.DataFrame(y_kmeans, columns= ['Segment'])], axis= 1)\ndata_segments.head()","68815236":"\n# customers on segment bases\nplt.style.use('seaborn')\ndata_segments['Segment'].value_counts().plot(kind = 'bar')\nplt.show()","ce0498c2":"# segmentwise customer data based on gender\nsns.relplot(x = 'Annual Income (k$)', y = 'Spending Score (1-100)',kind = 'scatter' ,data = data_segments, hue = 'Gender', col = 'Segment')\nplt.show()","bfe257a4":"\n# Visualising the clusters\nplt.scatter(X[y_kmeans == 0, 0], X[y_kmeans == 0, 1], s = 30, c = 'brown', label = 'Cluster 1')\nplt.scatter(X[y_kmeans == 1, 0], X[y_kmeans == 1, 1], s = 30, c = 'blue', label = 'Cluster 2')\nplt.scatter(X[y_kmeans == 2, 0], X[y_kmeans == 2, 1], s = 30, c = 'green', label = 'Cluster 3')\nplt.scatter(X[y_kmeans == 3, 0], X[y_kmeans == 3, 1], s = 30, c = 'orange', label = 'Cluster 4')\nplt.scatter(X[y_kmeans == 4, 0], X[y_kmeans == 4, 1], s = 30, c = 'red', label = 'Cluster 5')\nplt.scatter(x=kmeans_model.cluster_centers_[:, 0], y=kmeans_model.cluster_centers_[:, 1], s=100, c='black', marker='+', label='Cluster Centers')\nplt.legend()\nplt.title('Clusters of customers')\nplt.xlabel('Annual Income')\nplt.ylabel('Spending Score')\nplt.show()","64b3d1e5":"\n### Possible Segmentations (clusters) :\n- 1. low annual income and low spending score \n- 2. high annual income and low spending score \n- 3. low annual income and high spending score \n- 4. high annual income and high spending score \n- 5. average annual income and average spending score \n\n- conclusion: so finally found best clusters between annual income and spending score so lets build the clustering around it"}}