{"cell_type":{"7d9354ce":"code","7371af39":"code","211b30a9":"code","0b95d70b":"code","46ec9bd0":"code","aa1fe8f9":"code","a463a381":"code","70ecb91f":"code","f2a3cd32":"code","53a8f152":"code","133e446a":"code","0d2da763":"code","5081e8a9":"code","3ccf81f4":"code","cc0dea83":"code","08c89860":"code","38c35c5e":"code","4254ea98":"code","bebd77f1":"code","de7ec849":"code","43f07fde":"code","2d32ebf6":"code","1092e980":"code","d5848b69":"code","6d239185":"code","0f23a5c8":"code","e7464e95":"code","982a956e":"code","812226f8":"code","fd29c557":"code","b3e6aeb5":"code","9a41066d":"code","db733d70":"code","88b5be60":"code","5162010a":"code","9966b0bc":"code","d0938f74":"code","c80012aa":"code","08640825":"code","e7c5e20b":"code","4a7a66a3":"code","788172a9":"code","566bc4a1":"code","d8fe1316":"code","b8ad487f":"code","360bb069":"code","78d876b2":"code","eaaa231e":"code","a914ae19":"code","7f93b656":"code","51c111b2":"markdown","0fc352ef":"markdown","9b487a15":"markdown","db9ca873":"markdown","73395cc0":"markdown","15afe0ed":"markdown","ee2db91f":"markdown"},"source":{"7d9354ce":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt","7371af39":"import io\ndataset = pd.read_csv('..\/input\/car-price-prediction\/CarPrice_Assignment.csv')\n# Dataset is now stored in a Pandas Dataframe","211b30a9":"dataset = dataset.sample(frac=1)","0b95d70b":"dataset.head()","46ec9bd0":"dataset.info()","aa1fe8f9":"dataset.isnull().sum()","a463a381":"dataset.isna().sum()","70ecb91f":"dataset.describe()","f2a3cd32":"dataset.drop(columns='car_ID', inplace=True)\ndataset.drop(columns='CarName', inplace=True)\ndataset.head(10)\n","53a8f152":"dataset = pd.get_dummies(dataset, prefix=['fueltype','aspiration', 'doornumber','carbody', 'drivewheel', 'enginelocation', 'enginetype','cylindernumber', \n                                          'fuelsystem'])","133e446a":"dataset.head()","0d2da763":"dataset.columns","5081e8a9":"y = dataset['price']","3ccf81f4":"y","cc0dea83":"dataset.drop(columns='price', inplace=True)","08c89860":"dataset.head()","38c35c5e":"dataset.shape","4254ea98":"X_train = dataset[:104]","bebd77f1":"Y_train = y[:104]","de7ec849":"X_test = dataset[104:165]","43f07fde":"Y_test = y[104:165]","2d32ebf6":"X_val = dataset[165:]","1092e980":"Y_val = y[165:]","d5848b69":"X_train","6d239185":"mean = X_train.iloc[: , 0:14].mean(axis=0)\nX_train.iloc[: , 0:14] -= mean\nstd = X_train.iloc[:, 0:14].std(axis=0)\nX_train.iloc[: , 0:14] \/= std ","0f23a5c8":"X_train","e7464e95":"val_mean = X_val.iloc[:, 0:14].mean(axis=0)\nval_std = X_val.iloc[:, 0:14].std(axis=0)\nX_val.iloc[:, 0:14] -= val_mean\nX_val.iloc[:, 0:14] \/= val_std","982a956e":"test_mean = X_test.iloc[:, 0:14].mean(axis=0)\ntest_std =  X_test.iloc[:, 0:14].std(axis=0)\nX_test.iloc[:, 0:14] -= test_mean\nX_test.iloc[:, 0:14] \/= test_std\nX_test","812226f8":"X_train.shape[1]","fd29c557":"X_val.shape","b3e6aeb5":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers","9a41066d":"network = Sequential()","db733d70":"network.add(layers.Dense(16, activation='relu', kernel_regularizer =regularizers.l2(0.02),   input_shape=(X_train.shape[1],)))\nnetwork.add(layers.Dense(14, activation='relu', kernel_regularizer =regularizers.l2(0.02)))\nnetwork.add(layers.Dense(8, activation='relu', kernel_regularizer =regularizers.l2(0.02)))\nnetwork.add(layers.Dense(6, activation='relu', kernel_regularizer =regularizers.l2(0.002)))\n# network.add(layers.Dense(4, activation='relu', kernel_regularizer =regularizers.l2(0.002)))\nnetwork.add(layers.Dense(1))","88b5be60":"network.compile(optimizer='rmsprop', loss='mse', metrics='mae')","5162010a":"history = network.fit(X_train,Y_train, batch_size=16, verbose=0, epochs=200, validation_data=(X_val, Y_val))","9966b0bc":"epochs = range(1, 201)","d0938f74":"train_mae = history.history['mae']\nval_mae = history.history['val_mae']","c80012aa":"plt.plot(epochs, train_mae, 'r', label='Training MAE')\nplt.plot(epochs, val_mae, 'g', label='Validation MAE')\nplt.title('Training and Validation loss ')\nplt.xlabel('Epochs')\nplt.ylabel('MAE')\nplt.legend()\nplt.show()","08640825":"train_loss = history.history['loss']\nval_loss = history.history['val_loss']","e7c5e20b":"plt.plot(epochs, train_loss, 'r', label='Training Loss')\nplt.plot(epochs, val_loss, 'g', label='Validation Loss')\nplt.title('Training and Validation loss ')\nplt.xlabel('Epochs')\nplt.ylabel('Loss')\nplt.legend()\nplt.show()","4a7a66a3":"Y_test","788172a9":"network.predict(X_test)","566bc4a1":"test_mse_score, test_mae_score  =network.evaluate(X_test, Y_test)","d8fe1316":"frames = [X_train,X_val ]\nX_train_k_fold = pd.concat(frames)","b8ad487f":"X_train_k_fold.shape","360bb069":"Y_frames = [Y_train, Y_val]\nY_trainKfold = pd.concat(Y_frames)","78d876b2":"Y_trainKfold","eaaa231e":"from tensorflow.keras import regularizers\ndef build_model():\n    model = Sequential()\n    model.add(layers.Dense(16, activation='relu', kernel_regularizer=regularizers.l2(0.02), input_shape=(X_train_k_fold.shape[1],)))\n    model.add(layers.Dense(12, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n    model.add(layers.Dense(8, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n    model.add(layers.Dense(4, activation='relu', kernel_regularizer=regularizers.l2(0.02)))\n    model.add(layers.Dense(1))\n    model.compile(optimizer='adam', loss='mse', metrics=['mae'])\n    return model","a914ae19":"import numpy as np\nk = 2\nnum_val_samples = len(X_train_k_fold) \/\/ k\nnum_epochs = 300\nall_scores = []","7f93b656":"\nfor i in range(k):\n    print('processing fold #', i)\n    val_data = X_train_k_fold[i * num_val_samples: (i + 1) * num_val_samples]\n    val_targets = Y_trainKfold[i * num_val_samples: (i + 1) * num_val_samples]\n    partial_train_data = np.concatenate([X_train_k_fold[:i * num_val_samples],\n                                         X_train_k_fold[(i + 1) * num_val_samples:]], axis=0)\n    partial_train_targets = np.concatenate([Y_trainKfold[:i * num_val_samples],\n                                            Y_trainKfold[(i + 1) * num_val_samples:]],\n                                           axis=0)\n    model = build_model()\n    history = model.fit(partial_train_data, partial_train_targets,\n    epochs=num_epochs, batch_size=30,verbose=0, validation_data=(val_data, val_targets))\n\n    k_Fold_train_loss = history.history['mae']\n    k_Fold_val_loss = history.history['val_mae']\n    epochs = range(1,301)\n    plt.plot(epochs, k_Fold_train_loss, 'r', label='Training MAE')\n    plt.plot(epochs, k_Fold_val_loss, 'g', label='Validation MAE')\n    plt.title('Training and Validation MAE ')\n    plt.xlabel(' Epochs')\n    plt.ylabel('Loss')\n    plt.legend()\n    plt.show()\n    print('Val_MAE:   '+str(k_Fold_val_loss[-1]))\n    print('Predicted Prices:    '+str(model.predict(X_test)))\n    ","51c111b2":"<center> <h1> Thanks \u2764 <\/h1><\/center>","0fc352ef":"Split train and test set","9b487a15":"Build a Model","db9ca873":"<h2> Let's try with K-Fold technique <\/h2>","73395cc0":"Normalization of data","15afe0ed":"Drop car_ID and CarName","ee2db91f":"One hot encoding"}}