{"cell_type":{"6e600a14":"code","61be3f96":"code","1b58e7ea":"code","5ded7445":"code","400cb42b":"code","4ffa71eb":"code","6038d0a0":"code","977ad582":"code","e39eef99":"code","ace89b89":"code","b37f170a":"code","90e4cde5":"code","3c697535":"code","0cf797a6":"code","8d07cc32":"code","01c51863":"code","185f7a0d":"code","4ba1309f":"code","479122d9":"code","9e1faa97":"code","0537ff2b":"code","4571acce":"code","41c54633":"code","311272f0":"code","304419ed":"code","03b00f33":"code","b02100ee":"code","9118c837":"code","38e3a3a8":"code","b902ad84":"code","12ec183c":"code","5ef93bb5":"code","82d1f112":"code","6c899c98":"code","d4431bd2":"code","b8557fa5":"code","a3b3c34f":"code","b545c3e1":"code","36978641":"code","29a8dc1e":"code","7ec7792c":"code","7a6e402a":"code","b3ba92a9":"code","e181e9a2":"code","22a45227":"code","c776f123":"code","fd60177a":"code","fd1fb778":"code","db981c12":"code","e82f101a":"code","6cd6c3a7":"code","434a1941":"code","f07a7dd3":"code","726bc87c":"code","cb773e4a":"code","ec08dbdb":"code","6af1bbbe":"code","69411a53":"code","8a950eb9":"code","bbe328e6":"markdown","7bf6f483":"markdown","961e92c6":"markdown","f2127c1f":"markdown","e49edd5e":"markdown","d86e8404":"markdown","af9cdd6a":"markdown","5d997a2f":"markdown","067c40d8":"markdown","e7c46970":"markdown","682372b6":"markdown","41f24eed":"markdown","3470715d":"markdown","2808a78f":"markdown","74a65a6f":"markdown","3c994d31":"markdown","c18fd9e4":"markdown","59e8fdf3":"markdown","bd34c9a3":"markdown","deb416b9":"markdown","09fb6756":"markdown","fdb66254":"markdown","650722f3":"markdown","a4109cfd":"markdown","afabe691":"markdown"},"source":{"6e600a14":"from IPython.display import Image\nImage(\"..\/input\/cancer\/breast.png\")","61be3f96":"from IPython.display import Image\nImage(\"..\/input\/minions\/minions.jpg\")","1b58e7ea":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsns.set(style=\"whitegrid\")","5ded7445":"df=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","400cb42b":"df.shape # dataset number of rows and number of columns","4ffa71eb":"df.columns # list down the number of the columns","6038d0a0":"df.info()","977ad582":"df.describe(percentiles=[0.1,0.25,0.45,0.55,0.75,0.95])","e39eef99":"plt.plot(df['radius_mean'], df['perimeter_mean'])\nplt.show()","ace89b89":"((df.isnull().sum()\/len(df))*100).sort_values(ascending=True).plot(kind='barh',figsize=(10,10))\nplt.grid(b=True, which='both')","b37f170a":"df['diagnosis'].value_counts().plot(kind='barh', figsize=(10,10))\nplt.grid(b=True, which='both')","90e4cde5":"plt.rcParams['figure.figsize'] = (9, 9)\nlabels=['Benign','Malign']\nplt.pie(df['diagnosis'].value_counts(), explode=(0,0.1), labels=labels,autopct='%1.1f%%', shadow=True)\nplt.title('diagnosis ', fontsize = 20)\nplt.axis('off')\nplt.legend()\nplt.show()","3c697535":"col = \"diagnosis\"\ngrouped = df[col].value_counts().reset_index()\ngrouped = grouped.rename(columns = {col : \"count\", \"index\" : col})\n\n## plot\ntrace = go.Pie(labels=grouped[col], values=grouped['count'], pull=[0.05, 0], marker=dict(colors=[\"#6ad49b\", \"#a678de\"]))\nlayout = go.Layout(title=\"\", height=600, legend=dict(x=0.1, y=1.1))\nfig = go.Figure(data = [trace], layout = layout)\niplot(fig)","0cf797a6":"for i in df.columns:\n    null_rate=df[i].isnull().sum()\/len(df)\n    if null_rate>0:\n        print(\"{}'s null rate {} %'\".format(i, round(null_rate,2)))","8d07cc32":"df.head()","01c51863":"X=df.drop(['diagnosis','Unnamed: 32'], axis=1)\ny=df['diagnosis']","185f7a0d":"from sklearn.preprocessing import StandardScaler\nX_std=StandardScaler().fit_transform(X)","4ba1309f":"from sklearn.decomposition import PCA as sklearnPCA\nsklearn_pca = sklearnPCA(n_components=2)\nY_sklearn = sklearn_pca.fit_transform(X_std)","479122d9":"with plt.style.context('seaborn-whitegrid'):\n    plt.figure(figsize=(10, 10))\n    for lab, col in zip(('M', 'B' ),\n                        ('blue', 'red')):\n        plt.scatter(Y_sklearn[y==lab, 0],\n                    Y_sklearn[y==lab, 1],\n                    label=lab,\n                    c=col)\n    plt.xlabel('Principal Component 1')\n    plt.ylabel('Principal Component 2')\n    plt.legend(loc='upper center')\n    plt.tight_layout()\n    plt.show()","9e1faa97":"df.columns","0537ff2b":"fig=px.scatter_3d(x=df['radius_mean'], y=df['texture_mean'], z=df['area_mean'], size=df['texture_mean'],\n                 hover_data=[df['diagnosis']])\n\nfig.show()","4571acce":"fig=px.scatter(x=df['radius_mean'], y=df['perimeter_mean'], color=df['diagnosis'],size=df['fractal_dimension_worst'], hover_name=df['diagnosis'], \n                size_max=60)\nfig.show()","41c54633":"fig=px.scatter(x=df['radius_mean'], y=df['perimeter_mean'], color=df['diagnosis'],size=df['fractal_dimension_worst'], hover_name=df['diagnosis'], \n                size_max=60)\nfig.show()","311272f0":"fig=px.scatter(x=df['radius_mean'], y=df['smoothness_mean'], color=df['diagnosis'],size=df['fractal_dimension_worst'], hover_name=df['diagnosis'], \n             size_max=20)\nfig.show()","304419ed":"fig=px.scatter(x=df['radius_mean'], y=df['compactness_mean'], color=df['diagnosis'],size=df['fractal_dimension_worst'], hover_name=df['diagnosis'], \n             size_max=20)\nfig.show()","03b00f33":"fig=px.scatter(x=df['radius_mean'], y=df['concavity_mean'], color=df['diagnosis'],size=df['fractal_dimension_worst'], hover_name=df['diagnosis'], \n             size_max=20)\nfig.show()","b02100ee":"plt.figure(figsize=(10,10))\nsns.kdeplot(df['radius_mean'], hue=df['diagnosis'],shade=True, legend=True)\nplt.show()\n\nsns.boxenplot(x=df['diagnosis'], y=df['radius_mean'], hue=df['diagnosis'])\nplt.show()","9118c837":"plt.figure(figsize=(10,10))\nplt.subplot(2,1,1)\nsns.kdeplot(x=df['radius_mean'],hue=df['diagnosis'], shade=True, vertical=False, kernel=str, gridsize=100, legend=True,\n           shade_lowest=True,cbar=True)\nplt.title(\"Radius vs Diagnonis\")\n#plt.xlabel(\"Counts\")\nplt.show()\n\nplt.subplot(2,1,2)\nsns.boxenplot(y=df['radius_mean'],x=df['diagnosis'])\nplt.title(\"Boxenplot\")\n#plt.xlabel(\"Counts\")\nplt.show()","38e3a3a8":"cols=['diagnosis','radius_mean', 'texture_mean', 'perimeter_mean',\n       'area_mean','smoothness_mean', 'compactness_mean', 'concavity_mean',\n       'concave points_mean', 'symmetry_mean', 'fractal_dimension_mean']\nplt.figure(figsize=(10,10))\nsns.pairplot(data=df[cols],hue='diagnosis', palette='RdBu')","b902ad84":"#generate the corellation matrix \ncorr=df.corr().round(2)\n#mask for the upper triangle\nmask=np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)]\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n#define custom colormap\ncmap=sns.diverging_palette(220,10, as_cmap=True)\n\n#draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()\n\n\n\n","12ec183c":"# Generate and visualize the correlation matrix\ncorr = df.corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","5ef93bb5":"# first, drop all \"worst\" columns\ncols = ['radius_worst', \n        'texture_worst', \n        'perimeter_worst', \n        'area_worst', \n        'smoothness_worst', \n        'compactness_worst', \n        'concavity_worst',\n        'concave points_worst', \n        'symmetry_worst', \n        'fractal_dimension_worst']\n\ndf=df.drop(cols, axis=1)","82d1f112":"# then, drop all columns related to the \"perimeter\" and \"area\" attributes\ncols = ['perimeter_mean',\n        'perimeter_se', \n        'area_mean', \n        'area_se']\n\ndf=df.drop(cols, axis=1)\n\n","6c899c98":"# lastly, drop all columns related to the \"concavity\" and \"concave points\" attributes\ncols = ['concavity_mean',\n        'concavity_se', \n        'concave points_mean', \n        'concave points_se']\ndf = df.drop(cols, axis=1)","d4431bd2":"df.columns","b8557fa5":"# Generate and visualize the correlation matrix\ncorr = df.corr().round(2)\n\n# Mask for the upper triangle\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\n\n# Set figure size\nf, ax = plt.subplots(figsize=(20, 20))\n\n# Define custom colormap\ncmap = sns.diverging_palette(220, 10, as_cmap=True)\n\n# Draw the heatmap\nsns.heatmap(corr, mask=mask, cmap=cmap, vmin=-1, vmax=1, center=0,\n            square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)\n\nplt.tight_layout()","a3b3c34f":"diagnosis={'M':1, 'B':0}\ndf['diagnosis']=[diagnosis[x] for x in df['diagnosis']]","b545c3e1":"# Split the data into training and testing sets\nX=df.drop('Unnamed: 32', axis=1)\ny=df['diagnosis']\nX_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","36978641":"y.head()","29a8dc1e":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix","7ec7792c":"import statsmodels.api as sm\nimport statsmodels.formula.api as smf","7a6e402a":"lr=LogisticRegression()\nlr.fit(X_train, y_train)","b3ba92a9":"y_pred=lr.predict(X_train)\n","e181e9a2":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","22a45227":"y_test_pred=lr.predict(x_test)\n","c776f123":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","fd60177a":"cfm=confusion_matrix(y_test, y_test_pred)\ntrueNegative=cfm[0][0]\nfalsePossitive=cfm[0][1]\nfalse_negative=cfm[1][0]\ntruePositive=cfm[1][1]\n\nprint(\"Confusion Matrix\", cfm)\nprint(\"true negative\", trueNegative)\nprint(\"False Positive\", falsePossitive)\nprint(\"false Negative\", false_negative)\nprint(\"True Positive\", truePositive)","fd1fb778":"print(\"correct prediction\", \n      round((trueNegative+truePositive)\/len(y_test_pred)*100, 1),'%')","db981c12":"cfm_df=pd.DataFrame(cfm, range(2), range(2))\nplt.figure(figsize=(10,10))\nsns.heatmap(cfm_df, cmap='Reds', annot=True)\nplt.show()","e82f101a":"pd.crosstab(y_test, y_test_pred, rownames=['True'], colnames=['Predicted'], margins=True)\n","6cd6c3a7":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","434a1941":"y_test_pred_prob=lr.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\n\n","f07a7dd3":"metrics.roc_auc_score(y_test, y_test_pred_prob)\n","726bc87c":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\n","cb773e4a":"plt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","ec08dbdb":"from sklearn.metrics import precision_recall_curve\n","6af1bbbe":"no_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","69411a53":"# predict the test data and show the first 5 predictions\npredict=lr.predict(x_test)\npredict[1:6]","8a950eb9":"#Convert the numericalinto nominal value and check the few result\n\nprediction_nominal=['M' if x<0.1 else 'B' for x in predict ]\nprediction_nominal[1:6]","bbe328e6":"# Dropping less important feature","7bf6f483":"Here we will do that the probability closer to 0 will be labeled as 'M' and 'B' otherwise . And classify them as per stated here","961e92c6":"# Count of cancer type\n* Number of Malign  and Bening is shown below","f2127c1f":"**Obs**- these are the linear relationship ","e49edd5e":"# Visualization\nit is import to see that counts of different type of cancer \n","d86e8404":"# Reading the dataset ","af9cdd6a":"# Correlation Matrix for the most important features","5d997a2f":">Dropping the less important feature ","067c40d8":"**Obs** - These are the scatter diagram ","e7c46970":"# TSNE visualization ","682372b6":"# Visualizing the percentage missing value from dataset","41f24eed":"# Correlation Matrix","3470715d":"# Splitting the dataset ","2808a78f":"n the previous section, we have successfully developed a logistic regression model. This model can take some unlabeled data and effectively assign each observation a probability ranging from 0 to 1. This is the key feature of a logistic regression model. However, for us to evaluate whether the predictions are accurate, the predictions must be encoded so that each instance can be compared directly with the labels in the test data. In other words, instead of numbers between 0 or 1, the predictions should show \"M\" or \"B\", denoting malignant and benign respectively. In our model, a probability of 1 corresponds to the \"Benign\" class, whereas a probability of 0 corresponds to the \"Malignant\" class. Therefore, we can apply a threshhold value of 0.5 to our predictions, assigning all values closer to 0 a label of \"M\" and assigniing all values closer to 1 a label of \"B\".\n\nIf this is confusiing, let's go through this step-by-step.","74a65a6f":"# **The Prediction**","3c994d31":"# Heatmap\nTo find the most correlated features","c18fd9e4":"#  Model Training ","59e8fdf3":"# To find the missing value in dataset","bd34c9a3":"**Obs** - Only one column is missing ","deb416b9":"# Dataset Description \n* **id** - It is the id of the patients those are diagonising the cancer\n* **diagnosis**- When patients are Male or Female.\n* **radius_mean** - The size of the radius is mentioned, depending the sixe of the radius , it is fatal or not\n* **texture_mean** - The mean of the texture is mentioned below.\n* **perimeter_mean** - For uneven size of the tumore, we need the \n* **area_mean** -  The mean area of the tumor is mentioned\n* **smoothness_mean** - The area is smooth or not \n* **compactness_mean** - The area of the tumor is compacted \n* **concavity_mean** - The tumor is concave and whose mean is mentioned. \n* **concave points_mean** - The concave point are mentioned \n* **symmetry_mean** - The symmetric mean of the tumor is mentioned \n* **fractal_dimension_mean** - The fractal dimension is given \n* **radius_se** - The radius is mentioned of the dataset.\n* '**texture_se** -It is mentioned of the dataset\n* '**perimeter_se** -It is mentioned of the dataset\n* '**area_se** -It is mentioned of the dataset\n* '**smoothness_se**- It is mentioned of the dataset\n* '**compactness_se**- It is mentioned of the dataset\n* '**concavity_se**- It is mentioned of the dataset\n* '**concave points_se**- It is mentioned of the dataset\n* '**symmetry_se** -It is mentioned of the dataset\n* '**fractal_dimension_se** -It is mentioned of the dataset\n* '**radius_worst** -It is mentioned of the dataset\n* **texture_worst** -It is mentioned of the dataset\n* **perimeter_worst**-It is mentioned of the dataset\n* **area_worst** -It is mentioned of the dataset\n* **smoothness_worst** -It is mentioned of the dataset\n* **compactness_worst** -It is mentioned of the dataset\n* **concavity_worst**- It is mentioned of the dataset\n* **concave points_worst** -It is mentioned of the dataset\n* **symmetry_worst** -The symmentry worst is mentioned of the dataset\n* **fractal_dimension_worst**- The fractal dimension worst is mentioned of the dataset\n* **Unnamed: 32**- It is mentined of the dataset","09fb6756":">Pairplot helps to plot among the most useful feature","fdb66254":"# Conclusion\n>The accuracy labeled is 92.4% which is good .Though it is not that pretty good but still we can say tha prediction on this kind of dataset with the help of Logistic Regression is easy and effective . Hence it is a kind of achievment","650722f3":"# Table of Content:-\n* Panda\n* Numpy\n* Matplotlib\n* Seaborn\n* Plotly\n* Recomender System\n* Conclusion\n","a4109cfd":"# Here the party begins , bring all the library","afabe691":"# Buble chart"}}