{"cell_type":{"e4651848":"code","3eac8350":"code","d44b42dc":"code","0a359398":"code","73fc9d58":"code","d2ff1c42":"code","27931cd9":"code","c1e77d0b":"code","53cb8c3e":"code","2108851b":"code","f06f83af":"code","a810fafe":"code","6e2698c3":"code","75a7ceee":"code","05ae72a8":"code","1a21d87c":"code","e658afa7":"code","43fdb2f2":"code","abf44981":"code","d13b83ab":"code","5e95eca2":"code","9180b31d":"code","22843f94":"code","3774a18f":"markdown","5a737969":"markdown","34c3a978":"markdown","5efb153e":"markdown","18667a73":"markdown","3d48d393":"markdown"},"source":{"e4651848":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3eac8350":"# Importing libraries\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns","d44b42dc":"# Load dataset and draw shape.\ndataset = pd.read_csv('..\/input\/iris\/Iris.csv')\ndataset.shape","0a359398":"dataset.head()","73fc9d58":"dataset.drop('Id', axis = 1, inplace = True)\ndataset.describe()","d2ff1c42":"dataset.isnull().values.any()","27931cd9":"speciesMap={'Iris-setosa':0,'Iris-versicolor':1,'Iris-virginica':2}\ndataset['Species']=dataset['Species'].map(speciesMap)\ndataset.shape","c1e77d0b":"dataset.head","53cb8c3e":"## Correlation\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n#get correlations of each features in dataset\ncorrmat = dataset.corr()\ntop_corr_features = corrmat.index\nplt.figure(figsize=(20,20))\n#plot heat map\ng=sns.heatmap(dataset[top_corr_features].corr(),annot=True,cmap=\"RdYlGn\")","2108851b":"dataset.hist(figsize=(10,10))","f06f83af":"from sklearn.model_selection import train_test_split\n#(Removed SepalWidth as it doesn't much help in predicting the outcome)\nfeature_columns = ['SepalLengthCm','PetalLengthCm','PetalWidthCm']\npredicted_class = ['Species']\nX = dataset[feature_columns].values\ny = dataset[predicted_class].values","a810fafe":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state =0 )","6e2698c3":"# Standardize train and test sets.\nfrom sklearn.preprocessing import StandardScaler\nsc_X = StandardScaler()\n\nX_train = sc_X.fit_transform(X_train)\nX_test = sc_X.transform(X_test)","75a7ceee":"X_train","05ae72a8":"\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LinearRegression,LogisticRegression, RidgeClassifier\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.svm import SVC, LinearSVC\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis, QuadraticDiscriminantAnalysis\nfrom sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, BaggingClassifier, GradientBoostingClassifier","1a21d87c":"# Create objects of required models.\nmodels = []\nmodels.append((\"LR\",LinearRegression()))\nmodels.append((\"LR\",LogisticRegression()))\nmodels.append((\"GNB\",GaussianNB()))\nmodels.append((\"KNN\",KNeighborsClassifier()))\nmodels.append((\"DecisionTree\",DecisionTreeClassifier()))\nmodels.append((\"LDA\",  LinearDiscriminantAnalysis()))\nmodels.append((\"QDA\",  QuadraticDiscriminantAnalysis()))\nmodels.append((\"AdaBoost\", AdaBoostClassifier()))\nmodels.append((\"SVM Linear\",SVC(kernel=\"linear\")))\nmodels.append((\"SVM RBF\",SVC(kernel=\"rbf\")))\nmodels.append((\"Random Forest\",  RandomForestClassifier()))\nmodels.append((\"Bagging\",BaggingClassifier()))\nmodels.append((\"GradientBoosting\",GradientBoostingClassifier()))\nmodels.append((\"LinearSVC\",LinearSVC()))\nmodels.append((\"Ridge\",RidgeClassifier()))","e658afa7":"results = {}\n#for name,model in models:\n    #kfold = KFold(n_splits=10, random_state=0)\n    #cv_result = cross_val_score(model,X_train,y_train, cv = kfold,scoring = \"accuracy\")\n    #results.append(tuple([name,cv_result.mean(),cv_result.std()]))\n#results.sort(key=lambda x: x[1], reverse = True)    \n#for i in range(len(results)):\n    #print('{:20s} {:2.2f} (+\/-) {:2.2f} '.format(results[i][0] , results[i][1] * 100, results[i][2] * 100))\nfor name,model in models:\n    scores = cross_val_score(model, X_train, y_train.ravel(), cv=5)\n    results[name] = scores","43fdb2f2":" \nfor name, scores in results.items():\n    print(\"%20s | Accuracy: %0.2f%% (+\/- %0.2f%%)\" % (name, 100*scores.mean(), 100*scores.std() * 2))","abf44981":"\nimport xgboost\nclf=xgboost.XGBClassifier()","d13b83ab":"clf=xgboost.XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n              colsample_bynode=1, colsample_bytree=0.5, gamma=0.0,\n              learning_rate=0.1, max_delta_step=0, max_depth=6,\n              min_child_weight=7, missing=None, n_estimators=100, n_jobs=1,\n              nthread=None, objective='binary:logistic', random_state=0,\n              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n              silent=None, subsample=1, verbosity=1)\n\nclf.fit(X_train, y_train)","5e95eca2":"yPredict=clf.predict(X_test)","9180b31d":"from sklearn.metrics import confusion_matrix, accuracy_score\ncf = confusion_matrix(y_test, yPredict)\nprint(cf)\nprint(\"Accuracy = {0:.2f}\".format(accuracy_score(y_test, yPredict)))","22843f94":"# Creating a pickle file for the classifier\nimport pickle\nfilename = 'first-Iris.pkl'\npickle.dump(clf, open(filename, 'wb'))","3774a18f":"**Data PreProcessing**","5a737969":"**Evaluating the model and training the model**","34c3a978":"# **Load dataset**","5efb153e":"**Cleaning the datasets**","18667a73":"**Finalise model and predict performance on test set.**","3d48d393":"**Feature engineering**"}}