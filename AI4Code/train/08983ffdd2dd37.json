{"cell_type":{"ffcb3649":"code","2e513e64":"code","f7c791a3":"code","6d4c2e3a":"code","548c66e8":"code","6313e1e0":"code","3bf3ba78":"code","0e332814":"code","7bffe413":"code","393a8472":"code","eb42bc38":"code","8f5dfb28":"code","80c6dd20":"code","d5e7680b":"code","e7184ca8":"code","ac593282":"code","d15242fc":"code","a51a2ef3":"code","de95c9b7":"code","58d8070a":"code","36157774":"code","b46c4be7":"code","540fd271":"code","e2ac003a":"code","1fa9202a":"code","b62e3fae":"code","058e6539":"code","cc6f726d":"code","02fe124c":"code","08929b0f":"markdown","f13d83b0":"markdown","f7a155b0":"markdown","b52a1d59":"markdown","f02ef1fd":"markdown","61611817":"markdown","0f2ef221":"markdown","e23414ca":"markdown","e614aa6d":"markdown","f5b18099":"markdown","061ade0b":"markdown","2f84f280":"markdown","a92e78b0":"markdown","f9b7050c":"markdown","569050d8":"markdown","0b1fab6e":"markdown"},"source":{"ffcb3649":"import pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport missingno\nimport numpy as np\nfrom sklearn.preprocessing import OneHotEncoder\n# import warnings filter\nfrom warnings import simplefilter\n# ignore all future warnings\nsimplefilter(action='ignore', category=FutureWarning)\n","2e513e64":"dataset=pd.read_csv(\"..\/input\/titanic\/train.csv\")\ndataset.head()\n\n","f7c791a3":"missing_data=missingno.matrix(dataset,figsize = (10,10))\nmissing_data","6d4c2e3a":"sns.set_style('whitegrid')\nsns.countplot(x='Survived',hue='Pclass',data=dataset,palette='rainbow')","548c66e8":"sns.boxplot(x='Pclass',y='Age',data=dataset)","6313e1e0":"dataset['Sex'] = np.where(dataset['Sex'] == 'female', 1, 0)","3bf3ba78":"def impute_age(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age\n    \ndataset['Age'] =dataset[['Age','Pclass']].apply(impute_age,axis=1)","0e332814":"dataset.Age.isnull().sum()","7bffe413":"\ndf_sex_one_hot = pd.get_dummies(dataset['Embarked'], \n                                prefix='Embarked')\n\n\n# Combine the one hot encoded columns with df_con_enc\ndataset= pd.concat([dataset,df_sex_one_hot],axis=1)\n                       \n\n# Drop the original categorical columns (because now they've been one hot encoded)\ndataset=dataset.drop(['Embarked'], axis=1)","393a8472":"dataset.isnull().sum()\n","eb42bc38":"dataset=dataset.drop(['Cabin','Ticket','Name'],axis=1)","8f5dfb28":"dataset.isnull().sum()\ndataset.shape","80c6dd20":"cs=dataset\ncs.to_csv('..\/formulated_train.csv', index=False)\nprint('modified train CSV is ready!')\n","d5e7680b":"test_dataset=pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntest_dataset.head()","e7184ca8":"missing_data=missingno.matrix(test_dataset,figsize = (10,10))\nmissing_data","ac593282":"test_dataset['Sex'] = np.where(test_dataset['Sex'] == 'female', 1, 0)\n\n\ndef impute_age1(cols):\n    Age = cols[0]\n    Pclass = cols[1]\n    \n    if pd.isnull(Age):\n\n        if Pclass == 1:\n            return 37\n\n        elif Pclass == 2:\n            return 29\n\n        else:\n            return 24\n\n    else:\n        return Age\n    \ntest_dataset['Age'] =test_dataset[['Age','Pclass']].apply(impute_age1,axis=1)\n","d15242fc":"# One hot encode the columns in the test data frame (like X_train)\ntest_embarked_one_hot = pd.get_dummies(test_dataset['Embarked'], \n                                       prefix='Embarked')","a51a2ef3":"# Combine the test one hot encoded columns with test\ntest_dataset = pd.concat([test_dataset, \n                  test_embarked_one_hot], axis=1)","de95c9b7":"test_dataset=test_dataset.drop(['Embarked','Name','Cabin','Ticket'], axis=1)\ntest_dataset['Fare'].fillna(np.mean(test_dataset['Fare']), inplace=True)\n","58d8070a":"print(test_dataset.isnull().sum())\n\ntest_dataset.shape","36157774":"#train_df=pd.concat([df['SalePrice'],train_df],axis=1)\ncsv=test_dataset\ncsv.to_csv('..\/formulated_test.csv', index=False)\nprint('modified test CSV is ready!')","b46c4be7":"df=cs #cs is a formulated train dataset\nx=df.drop(['Survived'],axis=1)\n\ny=df['Survived']","540fd271":"from sklearn.model_selection import train_test_split \nfrom sklearn import tree\n\n# Decision Tree Classifier\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n\n                                           \nmodel = tree.DecisionTreeClassifier()\nmodel.fit(x_train,y_train)\n \n\npredictions = model.predict(x_test)\npredictions","e2ac003a":"\nfrom sklearn.metrics import confusion_matrix\n\naccuracy=confusion_matrix(y_test,predictions)\n\nprint(\"confusion_matrix:\",accuracy)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test,predictions)\nprint(\"accuracy_score:\",accuracy)\n","1fa9202a":"\nfrom sklearn.model_selection import RandomizedSearchCV\n\nfrom scipy.stats import randint\n\nest=tree.DecisionTreeClassifier()\nrf_p_dist={'max_depth':[3,5,10,None],\n           \n           'max_features':randint(1,10),\n           'criterion':['entropy','gini'],\n          \n           'min_samples_leaf':randint(1,4),\n           \n        \n    \n        }\ndef hypertunning_rscv(est,p_distr,nbr_iter,x,y):\n    rdmsearch=RandomizedSearchCV(est,param_distributions=p_distr,\n                                 n_jobs=-1,n_iter=nbr_iter,cv=9)\n    rdmsearch.fit(x,y)\n    ht_params=rdmsearch.best_params_\n    ht_score=rdmsearch.best_score_\n    return ht_params,ht_score\n\n\nrf_parameters,rf_ht_score=hypertunning_rscv(est,rf_p_dist,40,x,y)\n\nrf_parameters","b62e3fae":"# after hyper parameter tunning\n\nfrom sklearn.model_selection import train_test_split \nfrom sklearn import tree\n\n# Decision Tree Classifier\n\nx_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=0)\n\n                                           \nmodel = tree.DecisionTreeClassifier(criterion= 'gini',\n                                             max_depth= 3,\n                                             max_features= 9,\n                                             min_samples_leaf= 1,\n                                             splitter='best')\nmodel.fit(x_train,y_train)\n # Cross Validation \n\npredictions = model.predict(x_test)\n#print(\"preddicted value\",pcriterion='gini'redictions)\n#print(len(predictions))\n\nfrom sklearn.metrics import confusion_matrix\n\naccuracy=confusion_matrix(y_test,predictions)\n\nprint(\"confusion_matrix:\",accuracy)\n\nfrom sklearn.metrics import accuracy_score\n\naccuracy=accuracy_score(y_test,predictions)\naccuracy","058e6539":"test_df=csv\n\n\nprediction = model.predict(test_df)\nprediction","cc6f726d":"# Create a submisison dataframe and append the relevant columns\nsubmission = pd.DataFrame()\nsubmission['PassengerId'] = test_df['PassengerId']\nsubmission['Survived'] = prediction # our model predictions on the test dataset\nsubmission.head()\n\n\n# Let's convert our submission dataframe 'Survived' column to ints\nsubmission['Survived'] = submission['Survived'].astype(int)\nprint('Converted Survived column to integers.')\n","02fe124c":"\n\n\n# Are our test and submission dataframes the same length?\nif len(submission) == len(test_df):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submission)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")\n\n# Convert submisison dataframe to csv for submission to csv \n# for Kaggle submisison\nsubmission.to_csv('..\/submission1.csv', index=False)\nprint('Submission CSV is ready!')","08929b0f":"# #Exploring the titanic Dataset\n* Introduction\n* Load and check the dataset\n* Feature Engineering\n* Finding which is the best model\n* Model creation\n* checking accuracy\n* Hyper parameter Tunning\n* Submission\n\n\n\n\n","f13d83b0":"# Model creation\n","f7a155b0":"# checking accuracy","b52a1d59":"#  Introduction\n     This is my first kaggle notebook,In this notebook we going to predict the survival of the people in the titanic disaster.\n","f02ef1fd":"* we have to reduce the type 1and type 2 error for that we need hypertunning our model","61611817":"* In Cabin there are Lots of missing  so we remove the cabin column,Then we dont need Ticket and Name  this are not very important for our model.","0f2ef221":"* Finally our Feature engineering part was over next step we have to develope our model","e23414ca":"* Filling values in the missing area","e614aa6d":"\n* We have to fill the missing age data with the help of box plot in EDA","f5b18099":"* after the hyperparameter tunning false negative little bit reduced and the accuracy was increased","061ade0b":"* We finish the handling  the train dataset now we have to do the same thing to the test data","2f84f280":"# Feature Engineering","a92e78b0":"# Finding which is the best model\n\n* Idid some cross validation then I choose Decission tree","f9b7050c":"# Exploritary Data Analysis","569050d8":"* In the above graph ) represent passanger not survived,One represent passanger survived.The passanger who where in the first class has a high survival rate.","0b1fab6e":"# Load and check the Dataset\nImporting necessary Libraries for our model\n"}}