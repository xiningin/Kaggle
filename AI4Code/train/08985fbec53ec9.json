{"cell_type":{"df654093":"code","232bd483":"code","d9635d4b":"code","ffc715d2":"code","b6ab532f":"code","c223724c":"code","c259d02e":"code","bf4ee999":"code","d185110f":"code","5e85ff94":"code","4c8ac69e":"code","c8900ae5":"code","2d4a2fb7":"code","1f8c752e":"code","16f480a6":"code","a1dba895":"code","7eb52b74":"code","b718a939":"code","d0e97cd1":"code","0e647964":"code","bf823461":"code","0f303457":"code","a86b1051":"code","4d54d72b":"code","b2f5fcbe":"code","7473f74a":"code","951e672c":"code","7831296e":"code","35f91fdc":"code","f1f90fae":"code","125c1d73":"code","03073441":"code","4ad5b31e":"code","ddf1d797":"markdown","42c5c4b5":"markdown","1e7c60bb":"markdown","50092aca":"markdown","ea94eaed":"markdown","26a09293":"markdown","770ee070":"markdown","7b2d3670":"markdown","a2733daf":"markdown","471f6068":"markdown","300dd33b":"markdown","1637d248":"markdown","fed97ef6":"markdown","42ee91b0":"markdown","542cd9f9":"markdown","547a6f6b":"markdown","fb75c909":"markdown","7bdc0e2e":"markdown","2d6a6bc6":"markdown","e14890af":"markdown","784eb1ca":"markdown","91296a56":"markdown","8f230db4":"markdown","299e93cb":"markdown","0815854d":"markdown","b20a9cdd":"markdown","65cba2fa":"markdown"},"source":{"df654093":"#\nimport numpy as np \nimport pandas as pd \nimport random\n\n# folder\nimport os\nimport glob\n\n# image\nfrom PIL import Image\n\n# visu\nimport matplotlib.pyplot as plt\nplt.rc('image', cmap='gray')\nimport seaborn as sns\n\n# sklearn\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import plot_confusion_matrix\n\n#tensorflow\nfrom tensorflow.keras import Sequential\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau\nfrom tensorflow.keras.metrics import Accuracy","232bd483":"categories = [\"NORMAL\", \"PNEUMONIA\"]\ndatasets = [\"train\", \"test\", \"val\"]","d9635d4b":"%%time\n\nwidths = []\nheights = []\n\nfor set_ in datasets:\n    for cat in categories:\n        filelist = glob.glob('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/' + set_ + '\/' + cat + '\/*.jpeg')\n        widths.extend([Image.open(fname).size[0] for fname in filelist])\n        heights.extend([Image.open(fname).size[1] for fname in filelist])\n\nimages_size = pd.DataFrame({\"widths\": widths, \"heights\": heights})\n        \nprint(\"Average image width: \" + f'{images_size[\"widths\"].mean():.2f}')\nprint(\"Average image height: \" + f'{images_size[\"heights\"].mean():.2f}')","ffc715d2":"im_width = int(images_size[\"widths\"].mean()\/10)\nim_height = int(images_size[\"heights\"].mean()\/10)\nprint(\"image width: \" + str(im_width))\nprint(\"image height: \" + str(im_height))","b6ab532f":"%%time\n\ndata = []\ntarget = []\n\nfor set_ in datasets:\n    for cat in categories:\n        filelist = glob.glob('\/kaggle\/input\/chest-xray-pneumonia\/chest_xray\/' + set_ + '\/' + cat + '\/*.jpeg')\n        target.extend([cat for _ in filelist])\n        data.extend([np.array(Image.open(fname).convert('L').resize((im_width, im_height))) for fname in filelist])\n#\ndata_array = np.stack(data, axis=0)","c223724c":"print(data_array.shape)","c259d02e":"pd.concat([pd.DataFrame(pd.DataFrame({\"target\" : target}).value_counts()).rename(columns={0:\"count\"}),\n           pd.DataFrame(pd.DataFrame(target).value_counts()*100\/len(target)).applymap(round).rename(columns={0:\"%\"})], axis=1)","bf4ee999":"fig = plt.figure(figsize=(20,15))\ngs = fig.add_gridspec(4, 4)\n#\nfor line in range(0, 3):\n    for row in range(0, 3):\n        num_image = random.randint(0, data_array.shape[0])\n        ax = fig.add_subplot(gs[line, row])\n        ax.axis('off');\n        ax.set_title(target[num_image])\n        ax.imshow(data_array[num_image]);","d185110f":"X_train, X_test, y_train, y_test = train_test_split(data_array, np.array(target), random_state=43, test_size=0.2, stratify=target)","5e85ff94":"print(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","4c8ac69e":"pd.DataFrame(y_train).value_counts()\/len(y_train)","c8900ae5":"pd.DataFrame(y_test).value_counts()\/len(y_test)","2d4a2fb7":"print(X_train.max())\nprint(X_train.min())","1f8c752e":"X_test_norm = np.round((X_test\/255), 3).copy()\nX_train_norm = np.round((X_train\/255), 3).copy()","16f480a6":"print(X_train_norm.max())\nprint(X_train_norm.min())","a1dba895":"fig = plt.figure(figsize=(20,15))\ngs = fig.add_gridspec(4, 4)\n#\nfor line in range(0, 3):\n    for row in range(0, 3):\n        num_image = random.randint(0, X_train_norm.shape[0])\n        ax = fig.add_subplot(gs[line, row])\n        ax.axis('off');\n        ax.set_title(y_train[num_image])\n        ax.imshow(X_train_norm[num_image]);","7eb52b74":"display(np.array(y_train).shape)\ndisplay(np.unique(y_train))\ndisplay(np.array(y_test).shape)\ndisplay(np.unique(y_test))","b718a939":"encoder = LabelEncoder().fit(y_train)","d0e97cd1":"y_train_cat = encoder.transform(y_train)\ny_test_cat = encoder.transform(y_test)","0e647964":"X_train_norm.shape","bf823461":"X_train_norm = X_train_norm.reshape(-1, 97, 132, 1)\nX_test_norm = X_test_norm.reshape(-1, 97, 132, 1)\nX_train_norm.shape","0f303457":"X_test_norm.shape","a86b1051":"def initialize_model():\n    model = Sequential()\n    model.add(layers.Conv2D(32, (3, 3), activation=\"relu\", input_shape=(im_height, im_width, 1), padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n    model.add(layers.Conv2D(64, (3, 3), activation=\"relu\", padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(2, 2)))\n    model.add(layers.Conv2D(128, (3, 3), activation=\"relu\", padding='same'))\n    model.add(layers.MaxPool2D(pool_size=(3, 3)))\n    model.add(layers.Flatten())\n    model.add(layers.Dense(120, activation='relu'))\n    model.add(layers.Dense(60, activation='relu'))\n    model.add(layers.Dropout(rate=0.2))\n    model.add(layers.Dense(1, activation='sigmoid'))\n\n    return model","4d54d72b":"model = initialize_model()\nmodel.summary()","b2f5fcbe":"def compile_model(model):\n    model.compile(optimizer='adam',\n                  loss='binary_crossentropy',\n                  metrics=['accuracy'])\n    return model","7473f74a":"model = initialize_model()\nmodel = compile_model(model)\ncallback = [EarlyStopping(patience=5, monitor='val_accuracy', restore_best_weights=True),\n            ReduceLROnPlateau(monitor = 'val_loss', patience = 1, factor=0.5, verbose=1)]\n\nhistory = model.fit(X_train_norm, y_train_cat,\n                    batch_size=8,\n                    epochs=1000,\n                    validation_split=0.3,\n                    callbacks=callback)","951e672c":"def plot_history(history, title='', axs=None, exp_name=\"\"):\n    if axs is not None:\n        ax1, ax2 = axs\n    else:\n        f, (ax1, ax2) = plt.subplots(1, 2, figsize=(12, 4))\n    \n    if len(exp_name) > 0 and exp_name[0] != '_':\n        exp_name = '_' + exp_name\n    ax1.plot(history.history['loss'], label='train' + exp_name)\n    ax1.plot(history.history['val_loss'], label='val' + exp_name)\n    #ax1.set_ylim(-0.1, 0.1)\n    ax1.set_title('loss')\n    ax1.legend()\n\n    ax2.plot(history.history['accuracy'], label='train accuracy'  + exp_name)\n    ax2.plot(history.history['val_accuracy'], label='val accuracy'  + exp_name)\n    #ax2.set_ylim(0.9, 1.1)\n    ax2.set_title('Accuracy')\n    ax2.legend()\n    return (ax1, ax2)\n\nplot_history(history, title='', axs=None, exp_name=\"\");","7831296e":"predictions = model.predict(X_test_norm)","35f91fdc":"m = Accuracy()\nm.update_state(y_test_cat, np.round(predictions))\nm.result().numpy()","f1f90fae":"accuracy_score(y_test_cat, np.round(predictions))","125c1d73":"cm = confusion_matrix(y_test_cat, np.round(predictions))\nfig, ax = plt.subplots()\nfig.set_size_inches(12, 8)\nsns.heatmap(cm, annot=True, fmt='d', ax=ax, cmap=plt.cm.Blues, cbar=False)\nax.tick_params(axis='x', labelsize=16)\nax.tick_params(axis='y', labelsize=16)\nax.set_ylabel(\"True\", color=\"royalblue\", fontsize=35, fontweight=700)\nax.set_xlabel(\"Prediction\", color=\"royalblue\", fontsize=35, fontweight=700)\nplt.yticks(rotation=0);","03073441":"acc = (837 + 297) \/ (837 + 297 + 18 + 20)\nacc","4ad5b31e":"fig = plt.figure(figsize=(20,25))\ngs = fig.add_gridspec(8, 4)\n#\nfor row in range(0, 8):\n    for col in range(0, 3):\n        num_image = random.randint(0, X_test_norm.shape[0])\n        ax = fig.add_subplot(gs[row, col])\n        ax.axis('off');\n        ax.set_title(\"Predicted: \" + categories[int(np.round(predictions)[num_image][0])] + \" \/\\n True value: \" + categories[y_test_cat[num_image]])\n        ax.imshow(X_test_norm[num_image]);\nfig.suptitle(\"Predicted label VS True label \\n for the displayed chest X Ray pictures\", fontsize=25, x=0.42);\n#plt.tight_layout;","ddf1d797":"# 6. Results & Evaluation","42c5c4b5":"<b>And now we divide the mean width and mean height of the images by 10:<\/b>","1e7c60bb":"<b>We separate dataset into two sets, one for training and another one for testing and evaluate model. The test set consists in 20% of the dataset and the remaining is for the train set. The class repartition is kept by setting the parameter <\/b>`stratify` <b>to<\/b> `target`.","50092aca":"<b style=\"\">Now we load all the images from the three sets in one single dataframe and before that, we resize images by the lengths described above.<\/b>","ea94eaed":"<b>Here we convert targets from string to numerical values, each category becoming an integer - 0 or 1 - for NORMAL or PNEUMONIA:<\/b>","26a09293":"<b>The dataset is a bit unbalanced, we have 73% of class<\/b>`PNEUMONIA` <b> and 27% of class<\/b> `NORMAL`.","770ee070":"<b>Applying on train, test and validation sets:<\/b>","7b2d3670":"# 3. Train test split","a2733daf":"# 4. Preparing the data","471f6068":"# 2. Loading data","300dd33b":"<b>So we have 5856 tensor images of width 132 and height 97, each pixel being defined by Black (0) or white (255).<\/b>","1637d248":"<b>To ease the convergence of the algorithm, it is usefull to normalize the data. See here what are the maximum and minimum values in the data, and normalize it accordingly (the resulting image intensities should be between 0 and 1).<\/b>","fed97ef6":"<div style=\"display: block; height: 500px; overflow:hidden; text-align:center\">\n     <img src=\"https:\/\/imgur.com\/74higEj.jpg\" style=\"top: 0px;border-radius: 20px; \">\n<\/div>","42ee91b0":"Now, let's define the Convolutional Neural Network.\n\nThe CNN that is composed of:\n\n\u25fc\ufe0f Conv2D layer with 32 filters, a kernel size of (3, 3), the relu activation function, a padding equal to same and the correct input_shape<br>\n\u25fc\ufe0f MaxPooling2D layer with a pool size of (2, 2)<br>\n\u25fc\ufe0f Conv2D layer with 64 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to same<br>\n\u25fc\ufe0f MaxPooling2D layer with a pool size of (2, 2)<br>\n\u25fc\ufe0f Conv2D layer with 128 filters, a kernel size of (3, 3), the relu activation function, and a padding equal to same<br>\n\u25fc\ufe0f MaxPooling2D layer with a pool size of (3, 3)<br>\n\u25fc\ufe0f Flatten layer<br>\n\u25fc\ufe0f dense function with 120 neurons with the relu activation function<br>\n\u25fc\ufe0f dense function with 60 neurons with the relu activation function<br>\n\u25fc\ufe0f dropout layer (with a rate of 0.5), to regularize the network<br>\n\u25fc\ufe0f dense function related to the task: binary classification > `sigmoid`","542cd9f9":"# 5. Convolutionnal neural network","547a6f6b":"# 1. Imports","fb75c909":"<b>So we have an accuracy on unseen data of 97%.<\/b><br>\n<b>Let's plot some random chest-x-ray picture alongside with true label and predicted label to check everything is ok:<\/b>","7bdc0e2e":"<b>Let's compute the average size of the images among all categories and all datasets:<\/b>","2d6a6bc6":"<b>Here again, we can check the normalised pictures randomly:<\/b>","e14890af":"### Expanding dimension for the correct model intput dim","784eb1ca":"<b>Fitting the encoder on train set:<\/b>","91296a56":"## Target encoding","8f230db4":"<b>The deep learning model needs a 4 dimensions tensor to work with. Here we have grayscale pictures with no channel. It means the matrices of our black and white pictures are of shape 3. We need to add an extra dimension so algorithm can accept it.<\/b>","299e93cb":"<b>Let's have a look at several random images and associated label of our dataset:<\/b>","0815854d":"<b>Here I set an early stopping after 5 epochs and set the parameter <\/b>`restore_best_weights` <b> to <\/b> `True` <b>so that the weights of best score on monitored metric - here <\/b>`val_accuracy` <b> (accuracy on test set) - are restored when training stops. This way the model has the best accuracy possible on unseen data.<\/b>","b20a9cdd":"<b>Thank you for reading! if you have any suggestion of improvment or if you find some mistakes please feel free to comment.<\/b><br>\n<b style=\"color:royalblue\">Please upvote if you like the notebook ! \ud83c\udf40\u2604\ufe0f<\/b>","65cba2fa":"<b>There are two categories in three sets:<\/b>"}}