{"cell_type":{"8dc40d27":"code","3db8906a":"code","bf0ccfdc":"code","923bac4b":"code","ea2b84fb":"code","30d09027":"code","0e32bb25":"code","314c7e23":"markdown"},"source":{"8dc40d27":"def phrase_extraction(srctext, trgtext, alignment, first=1):\n    \"\"\"\n    Phrase extraction algorithm.\n    \"\"\"\n    # Convert to a 0-based indexing.\n    if first != 0:\n        alignment = [(x-first, y-first) for x, y in alignment]\n\n    def extract(f_start, f_end, e_start, e_end):\n        if f_end < 0:  # 0-based indexing.\n            return {}\n        # Check if alignement points are consistent.\n        for e,f in alignment:\n            if ((f_start <= f <= f_end) and\n               (e < e_start or e > e_end)):\n                return {}\n\n        # Add phrase pairs (incl. additional unaligned f)\n        # Remark:  how to interpret \"additional unaligned f\"?\n        phrases = set()\n        fs = f_start\n        # repeat-\n        while True:\n            fe = f_end\n            # repeat-\n            while True:\n                # add phrase pair ([e_start, e_end], [fs, fe]) to set E\n                # Need to +1 in range  to include the end-point.\n                src_phrase = \" \".join(srctext[i] for i in range(e_start,e_end+1))\n                trg_phrase = \" \".join(trgtext[i] for i in range(fs,fe+1))\n                # Include more data for later ordering.\n                phrases.add(((e_start, e_end+1), src_phrase, trg_phrase))\n                fe += 1 # fe++\n                # -until fe aligned or out-of-bounds\n                if fe in f_aligned or fe == trglen:\n                    break\n            fs -=1  # fe--\n            # -until fs aligned or out-of- bounds\n            if fs in f_aligned or fs < 0:\n                break\n        return phrases\n\n    # Calculate no. of tokens in source and target texts.\n    srctext = srctext.split()   # e\n    trgtext = trgtext.split()   # f\n    srclen = len(srctext)       # len(e)\n    trglen = len(trgtext)       # len(f)\n    # Keeps an index of which source\/target words are aligned.\n    e_aligned = [i for i,_ in alignment]\n    f_aligned = [j for _,j in alignment]\n\n    bp = set() # set of phrase pairs BP\n    # for e start = 1 ... length(e) do\n    # Index e_start from 0 to len(e) - 1\n    for e_start in range(srclen):\n        # for e end = e start ... length(e) do\n        # Index e_end from e_start to len(e) - 1\n        for e_end in range(e_start, srclen):\n            # \/\/ find the minimally matching foreign phrase\n            # (f start , f end ) = ( length(f), 0 )\n            # f_start \u2208 [0, len(f) - 1]; f_end \u2208 [0, len(f) - 1]\n            f_start, f_end = trglen-1 , -1  #  0-based indexing\n            # for all (e,f) \u2208 A do\n            for e,f in alignment:\n                # if e start \u2264 e \u2264 e end then\n                if e_start <= e <= e_end:\n                    f_start = min(f, f_start)\n                    f_end = max(f, f_end)\n            # add extract (f start , f end , e start , e end ) to set BP\n            phrases = extract(f_start, f_end, e_start, e_end)\n            if phrases:\n                bp.update(phrases)\n    return bp","3db8906a":"def print_phrases(phrases):\n    # Keep track of translations of each phrase in srctext and its\n    # alignement using a dictionary with keys as phrases and values being\n    # a list [e_alignement pair, [f_extractions, ...] ]\n    dlist = {}\n    for p, a, b in phrases:\n        if a in dlist:\n            dlist[a][1].append(b)\n        else:\n            dlist[a] = [p, [b]]\n            \n    # Sort the list of translations based on their length.  Shorter phrases first.\n    for v in dlist.values():\n        v[1].sort(key=lambda x: len(x))\n\n    # Function to help sort according to book example.\n    def ordering(p):\n        k,v = p\n        return v[0]\n\n    for i, p in enumerate(sorted(dlist.items(), key = ordering), 1):\n        k, v = p\n        print(\"({0:2}) {1} {2} \u2014 {3}\".format( i, v[0], k, \" ; \".join(v[1])))","bf0ccfdc":"# 1-based indexing.\nalignments = [\n    [(1,1),(2,2),(3,2),(4,4),(2,3),(5,4),(5,6),(6,3),(7,2)],\n    [(7,8)],\n    [(i,i) for i in range(1,6)],\n]","923bac4b":"for A in alignments:\n    print('Alignment:', A)\n    e_len = max(a[0] for a in A)\n    f_len = max(a[1] for a in A) \n    srctext = ' '.join(map(str, range(1, e_len+1)))\n    print('srctext:', srctext)\n    trgtext = ' '.join(map(str, range(1, f_len+1)))\n    print('trgtext:', trgtext)\n    phrases = phrase_extraction(srctext, trgtext, A)\n    print('Number of phrases:', len(phrases))\n    print_phrases(phrases)\n    print('-----------------------\\n\\n')","ea2b84fb":"A = {(1,1),(2,2),(2,3),(2,4),(3,6),(4,7),(5,10),(6,10),(7,8),(8,8),(9,9)}\nsrctext = 'michael assumes that he will stay in the house'\ntrgtext = 'michael geht davon aus , dass er im haus bleitbt'","30d09027":"phrases = phrase_extraction(srctext, trgtext, A)","0e32bb25":"for p, english, german in phrases:\n    print(f'{german} ||| {english}')","314c7e23":"\n[**Phrase extraction algorithm for statistical machine translation**](https:\/\/stackoverflow.com\/a\/25128809)\n\nhttps:\/\/stackoverflow.com\/a\/25128809"}}