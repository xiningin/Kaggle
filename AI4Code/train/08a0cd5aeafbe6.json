{"cell_type":{"d3dafb00":"code","41f83957":"code","25031161":"code","9d1f83c4":"code","aa96f3ef":"code","5713d3f2":"code","0d926a26":"code","c290c924":"code","3fc67637":"code","81971160":"code","7b7c5491":"code","1ccc5bbd":"code","7fe90bd5":"code","d0e81820":"code","88e66040":"code","c2ebf287":"code","83f8ed30":"code","b6b21ef5":"code","b82c27fa":"markdown","35645530":"markdown","9d9127bc":"markdown","5293c982":"markdown","b2f3877c":"markdown","bd824c80":"markdown","6db5e6d3":"markdown","1222bab2":"markdown","6430a880":"markdown","7fdf40b2":"markdown"},"source":{"d3dafb00":"%matplotlib inline\nimport tensorflow as tf\nfrom tensorflow import keras\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nprint('Tensorflow version:', tf.__version__)","41f83957":"def show(images, n_cols=None):\n    n_cols = n_cols or len(images)\n    n_rows = (len(images) - 1) \/\/ n_cols + 1\n    if images.shape[-1] == 1:\n        images = np.squeeze(images, axis=-1)\n    plt.figure(figsize=(n_cols, n_rows))\n    for index, image in enumerate(images):\n        plt.subplot(n_rows, n_cols, index + 1)\n        plt.imshow(image, cmap=\"binary\")\n        plt.axis(\"off\")","25031161":"(x_train, y_train), (x_test, y_test) = tf.keras.datasets.fashion_mnist.load_data()\nx_train = x_train.astype(np.float32) \/ 255.0\nx_test = x_test.astype(np.float32) \/ 255.0","9d1f83c4":"plt.figure(figsize=(10,10))\nfor i in range(25):\n    plt.subplot(5,5,i+1)\n    plt.xticks([])\n    plt.yticks([])\n    plt.grid(False)\n    plt.imshow(x_train[i], cmap=plt.cm.binary)\nplt.show()","aa96f3ef":"batch_size = 32\n# This dataset fills a buffer with buffer_size elements, \n#then randomly samples elements from this buffer, replacing the selected elements with new elements.\ndataset = tf.data.Dataset.from_tensor_slices(x_train).shuffle(1000)\n#Combines consecutive elements of this dataset into batches.\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)\n#Creates a Dataset that prefetches elements from this dataset","5713d3f2":"num_features = 100\n\ngenerator = keras.models.Sequential([\n    keras.layers.Dense(7 * 7 * 256, input_shape=[num_features]),\n    keras.layers.Reshape([7, 7, 256]),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(128, (5,5), (1,1), padding=\"same\", activation=\"selu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(64, (5,5), (2,2), padding=\"same\", activation=\"selu\"),\n    keras.layers.BatchNormalization(),\n    keras.layers.Conv2DTranspose(1, (5,5), (2,2), padding=\"same\", activation=\"tanh\"),\n])","0d926a26":"noise = tf.random.normal(shape=[1, num_features])\ngenerated_images = generator(noise, training=False)\nshow(generated_images, 1)","c290c924":"discriminator = keras.models.Sequential([\n    keras.layers.Conv2D(64, (5,5), (2,2), padding=\"same\", input_shape=[28, 28, 1]),\n    keras.layers.LeakyReLU(0.2),\n    keras.layers.Dropout(0.3),\n    keras.layers.Conv2D(128, (5,5), (2,2), padding=\"same\"),\n    keras.layers.LeakyReLU(0.2),\n    keras.layers.Dropout(0.3),\n    keras.layers.Conv2D(256, (5,5), (1,1), padding=\"same\"),\n    keras.layers.LeakyReLU(0.2),\n    keras.layers.Dropout(0.3),\n    keras.layers.Flatten(),\n    keras.layers.Dense(1, activation='sigmoid')\n])","3fc67637":"decision = discriminator(generated_images)\nprint(decision)","81971160":"discriminator.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")\ndiscriminator.trainable = False\ngan = keras.models.Sequential([generator, discriminator])\ngan.compile(loss=\"binary_crossentropy\", optimizer=\"rmsprop\")","7b7c5491":"from IPython import display\nfrom tqdm import tqdm\nseed = tf.random.normal(shape=[batch_size, 100])","1ccc5bbd":"from tqdm import tqdm\ndef train_dcgan(gan, dataset, batch_size, num_features, epochs=5):\n    generator, discriminator = gan.layers\n    for epoch in tqdm(range(epochs)):\n        print(\"Epoch {}\/{}\".format(epoch + 1, epochs))\n        for X_batch in dataset:\n            noise = tf.random.normal(shape=[batch_size, num_features])\n            generated_images = generator(noise)\n            X_fake_and_real = tf.concat([generated_images, X_batch], axis=0)\n            y1 = tf.constant([[0.]] * batch_size + [[1.]] * batch_size)\n            discriminator.trainable = True\n            discriminator.train_on_batch(X_fake_and_real, y1)\n            noise = tf.random.normal(shape=[batch_size, num_features])\n            y2 = tf.constant([[1.]] * batch_size)\n            discriminator.trainable = False\n            gan.train_on_batch(noise, y2)\n            # Produce images for the GIF as we go\n        display.clear_output(wait=True)\n        generate_and_save_images(generator, epoch + 1, seed)\n        \n    display.clear_output(wait=True)\n    generate_and_save_images(generator, epochs, seed)","7fe90bd5":"## Source https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan#create_a_gif\ndef generate_and_save_images(model, epoch, test_input):\n  # Notice `training` is set to False.\n  # This is so all layers run in inference mode (batchnorm).\n  predictions = model(test_input, training=False)\n\n  fig = plt.figure(figsize=(10,10))\n\n  for i in range(25):\n      plt.subplot(5, 5, i+1)\n      plt.imshow(predictions[i, :, :, 0] * 127.5 + 127.5, cmap='binary')\n      plt.axis('off')\n\n  plt.savefig('image_at_epoch_{:04d}.png'.format(epoch))\n  plt.show()","d0e81820":"x_train_dcgan = x_train.reshape(-1, 28, 28, 1) * 2. - 1.","88e66040":"batch_size = 32\ndataset = tf.data.Dataset.from_tensor_slices(x_train_dcgan)\ndataset = dataset.shuffle(1000)\ndataset = dataset.batch(batch_size, drop_remainder=True).prefetch(1)","c2ebf287":"%%time\ntrain_dcgan(gan, dataset, batch_size, num_features, epochs=20)","83f8ed30":"noise = tf.random.normal(shape=[batch_size, num_features])\ngenerated_images = generator(noise)\nshow(generated_images, 8)","b6b21ef5":"## Source: https:\/\/www.tensorflow.org\/tutorials\/generative\/dcgan#create_a_gif\nimport imageio\nimport glob\n\nanim_file = 'dcgan.gif'\n\nwith imageio.get_writer(anim_file, mode='I') as writer:\n  filenames = glob.glob('image*.png')\n  filenames = sorted(filenames)\n  last = -1\n  for i,filename in enumerate(filenames):\n    frame = 2*(i)\n    if round(frame) > round(last):\n      last = frame\n    else:\n      continue\n    image = imageio.imread(filename)\n    writer.append_data(image)\n  image = imageio.imread(filename)\n  writer.append_data(image)\n\n#import IPython\ndisplay.Image(filename=anim_file)","b82c27fa":"## Creating Batches of Training Data","35645530":"## Importing Libraries","9d9127bc":"## Generating Synthetic Images with DCGAN","5293c982":"##  Defineing Training Procedure","b2f3877c":"<h2 align=center>Generating Synthetic Images with DCGANs in Keras<\/h2>","bd824c80":"## Loading and Preprocessing the Data","6db5e6d3":"## Building the Generator Network for DCGAN","1222bab2":"## Compiling the Deep Convolutional Generative Adversarial Network (DCGAN)","6430a880":"## Training DCGAN","7fdf40b2":"## Building the Discriminator Network for DCGAN"}}