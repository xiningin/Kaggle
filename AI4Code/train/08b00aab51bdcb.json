{"cell_type":{"09cd5dd2":"code","73b01587":"code","0f170719":"code","83fe71fc":"code","e9a39845":"code","e9c08da9":"code","db914d51":"code","914a2076":"code","d7d749c4":"code","0d0dd6fd":"code","1f541d96":"code","8a95e96b":"code","147ed793":"code","05875d3f":"code","226624ef":"code","3a20bc6b":"code","3e68c57c":"code","88e65dfc":"markdown","5f7e9f6c":"markdown","92bf9f6a":"markdown","0ef33383":"markdown","25304246":"markdown","0ef7d434":"markdown","6237c3af":"markdown","36eec1a6":"markdown"},"source":{"09cd5dd2":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","73b01587":"data=pd.read_csv('\/kaggle\/input\/well-shuffled-news-data\/Fake_True_appended_and_shuffled.csv')","0f170719":"import re\nfrom nltk.corpus import stopwords\nfrom nltk.stem import PorterStemmer\nfrom sklearn.feature_extraction.text import CountVectorizer,TfidfVectorizer","83fe71fc":"sw=set(stopwords.words('english'))\nstemmed_title=[]\nfor i in range(0,len(data['title'])):\n    temp=(re.sub('[^a-zA-z]',' ',data['title'][i]).lower())\n    temp=temp.split()\n    ps=PorterStemmer()\n    temp=[ps.stem(word) for word in temp if not word in sw]\n    temp=' '.join(temp)\n    stemmed_title.append(temp)","e9a39845":"stemmed_title[0] #glance at stemmed text","e9c08da9":"# Vectorizing the stemmed_titles----\n\ncv=CountVectorizer()\nfeatures=cv.fit_transform(stemmed_title).toarray()\nlabel=data['status']","db914d51":"from sklearn.model_selection import cross_val_score\nfrom sklearn.naive_bayes import MultinomialNB\nx=cross_val_score(MultinomialNB(),features,label,cv=5)\nprint(x)\nprint('mean : ',x.mean())","914a2076":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nx_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.1,random_state=0)\nclassifier=MultinomialNB()\nclassifier.fit(x_train,y_train)\ny_pred=classifier.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","d7d749c4":"x_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.2,random_state=0)\nclassifier=MultinomialNB()\nclassifier.fit(x_train,y_train)\ny_pred=classifier.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","0d0dd6fd":"x_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.25,random_state=0)\nclassifier=MultinomialNB()\nclassifier.fit(x_train,y_train)\ny_pred=classifier.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","1f541d96":"x_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.33,random_state=0)\nclassifier=MultinomialNB()\nclassifier.fit(x_train,y_train)\ny_pred=classifier.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","8a95e96b":"tv=TfidfVectorizer()\nfeatures=tv.fit_transform(stemmed_title).toarray()\nlabel=data['status']\n","147ed793":"from sklearn.model_selection import cross_val_score\nx=cross_val_score(MultinomialNB(),features,label,cv=5)\nprint(x)\nprint('mean : ',x.mean())","05875d3f":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nx_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.1,random_state=0)\nclassifier=MultinomialNB()\nclassifier.fit(x_train,y_train)\ny_pred=classifier.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","226624ef":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nx_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.2,random_state=0)\nclassifier=MultinomialNB()\nclassifier.fit(x_train,y_train)\ny_pred=classifier.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","3a20bc6b":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nx_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.25,random_state=0)\nclassifier=MultinomialNB()\nclassifier.fit(x_train,y_train)\ny_pred=classifier.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","3e68c57c":"from sklearn.naive_bayes import MultinomialNB\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import confusion_matrix,classification_report\n\nx_train,x_test,y_train,y_test=train_test_split(features,label,test_size=0.33,random_state=0)\nclassifier=MultinomialNB()\nclassifier.fit(x_train,y_train)\ny_pred=classifier.predict(x_test)\nprint(confusion_matrix(y_test,y_pred))\nprint(classification_report(y_test,y_pred))","88e65dfc":"# Testing on different test_size using MultinomialNB after (CountVectorizer transform)","5f7e9f6c":"# Let's see cross validation score for MultinomialNB---","92bf9f6a":"# Cross validation score for TfidfVectorizer----****","0ef33383":"# Testing on different test_size after (TfidfVectorizer transform)","25304246":"# CountVectorizer","0ef7d434":"# CountVectorizer transform Performed better!","6237c3af":"# Using TfidfVectorizer","36eec1a6":"# Text Cleaning"}}