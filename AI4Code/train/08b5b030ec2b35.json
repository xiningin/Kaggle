{"cell_type":{"f2e01f41":"code","b6afa2e0":"code","ccd1d01a":"code","2884c7ac":"code","8973d3de":"code","5657d1cb":"code","41e2e0a2":"code","3db4fc9d":"code","0083ea5a":"code","2df3d7b6":"code","7d4f566f":"code","a2cd60aa":"markdown","2f995bcf":"markdown","6b456875":"markdown","63176601":"markdown","69fd4dd8":"markdown","2ae049c3":"markdown","5202ce10":"markdown"},"source":{"f2e01f41":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","b6afa2e0":"#Loading Train and Test Data\ntrain = pd.read_csv(\"..\/input\/train.csv\", parse_dates=[\"first_active_month\"])\ntest = pd.read_csv(\"..\/input\/test.csv\", parse_dates=[\"first_active_month\"])\n\nprint(f\"Train set contains {train.shape[0]} observations and {train.shape[1]} variables\")\nprint(f\"Test set contains {test.shape[0]} observations and {test.shape[1]} variables\")\ntrain.head()","ccd1d01a":"dupcheck = len(train) - len(train['card_id'].unique())\nprint(f\"The data contains {dupcheck} duplicate card ids\")","2884c7ac":"plt.figure(figsize = (16, 6))\n\nplt.subplot(121)\nplt.hist(train[\"target\"], bins = 25)\nplt.title(\"Target Variable Histogram\")\n\nplt.subplot(122)\nsns.boxplot(data = train, y = \"target\")\nplt.title(\"Target Variable Boxplot\")\n\nplt.show()\n\ntrain[\"target\"].describe()","8973d3de":"train['first_active_month'].value_counts(normalize = True).sort_index().plot(figsize = (16,4), label = 'Train')\ntest['first_active_month'].value_counts(normalize = True).sort_index().plot(figsize = (16,4), label = 'Test')\nplt.legend()\nplt.title('Frequency of cards by first active month - Train vs Test Set')\nplt.show()","5657d1cb":"train[['first_active_month', 'target']].groupby('first_active_month').agg(np.mean).plot(figsize = (16,4))\nplt.title(\"Average Target Value by Card First Active Month\")\n\n\ntrain[['first_active_month', 'target']].groupby('first_active_month'\n                                               ).agg(np.mean).rolling(5).mean().plot(figsize = (16, 4))\nplt.title(\"5 Periods Average Target Value by Card First Active Month\")","41e2e0a2":"feats = np.arange(1,4)\n\nnrows = len(feats)\nncols = 2\n\nplt.figure(figsize = (15,4.5*len(feats)))\nidxs = np.arange(1,7).reshape(nrows, ncols)\n\nfor idx, i in enumerate(feats):\n    \n    f_name = f\"feature_{i}\"\n    \n    plt.subplot(len(feats), ncols, idxs[idx][0])\n    train[f_name].value_counts(normalize=True).plot(kind = 'bar', color = 'blue', alpha = 0.5)\n    plt.title(f\"Train Set {f_name}\")\n    \n    plt.subplot(len(feats), ncols, idxs[idx][1])\n    train[f_name].value_counts(normalize=True).plot(kind = 'bar', color = 'green', alpha = 0.5)\n    plt.title(f\"Test Set {f_name}\")\n\nplt.suptitle('Features Distribution Across Train and Test Set')","3db4fc9d":"plt.figure(figsize = (16,4))\nsns.boxplot(data = train, x='feature_1', y ='target')","0083ea5a":"plt.figure(figsize = (16,4))\nsns.boxplot(data = train, x='feature_2', y ='target')","2df3d7b6":"plt.figure(figsize = (16,4))\nsns.boxplot(data = train, x='feature_3', y ='target')","7d4f566f":"train.corr()['target'].head(3).plot(kind='bar', color='blue', alpha = 0.5, figsize = (10,4))","a2cd60aa":"The target variable seems to be pretty much normally distributed with some outliers on both sides. We will look at those at a later stage. The boxplot will help use realize that the distribution has the median at 0 and is  pretty much symmetric. \n\nIt's possible tha target variable - the loyalty score - has been standardized by subtracting the mean and dividing by the standard deviation. It's hard to say by just looking at the summary statistics, since we only see the train set.","2f995bcf":"If we look at the first active month, the distribution of cards activated in any given period is identical across train and test set. Which means that the two sets have been properly stratified. There's a peak towards the end of 2017 and a sudden dip in the first two months of 2018.","6b456875":"If we look at how the target variable correlats to threee other plots it can be seen that the highest degree is with feature_1. All three features are inversely correlated the loyalty score.","63176601":"If we look at the other three features across both the train and test set we can see that the two sets are well stratified. **Feature_1** has 5 level with a majority at level 3. **Feature_2** has 3 levels, while **Feature_3** is a binomial one. Haven't read all the discussion, but hard to say what those features are. ","69fd4dd8":"If we look at the loyalty score by the first month the card was active we may notice that this score tends to go up with time, with an increasing trend especially in the last months.\n\n> This means that the cards activated towards mid-end 2017 tend to have  a **higher target value**\n","2ae049c3":"The boxplots would revel that the target variable is well distributed across the level of each of the three features.","5202ce10":"## A glance at the target variable\n\nFirst step is to really understand a bit more about the target variable:\n\n1. How is the variable distributed\n2. To which variables it  correlates the most.\n3. What's the target variable distribution given other indipedent variables."}}