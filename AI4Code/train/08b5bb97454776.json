{"cell_type":{"2b9c8d96":"code","3f1d3957":"code","27f048ac":"code","2589deea":"code","2ac4c55b":"code","2514b77d":"code","3096980f":"code","8e2423d2":"code","63019a44":"code","d6798282":"code","ef5d5243":"code","6d3baa53":"code","32d4bc7c":"code","cf99e302":"code","e37f3fb2":"code","800f5b47":"code","fd457182":"code","f59401ab":"code","8fb8d958":"code","04c3c1a8":"code","7709e0a5":"code","861fc931":"code","85bf8ff3":"code","69535d3d":"code","afb355db":"code","4081a799":"code","30702f77":"code","4e34f028":"markdown","24031ee7":"markdown","6729430a":"markdown","32570b8e":"markdown","66dcd671":"markdown","4ac6d3f2":"markdown","95bbdae7":"markdown","b344214e":"markdown","d41898fb":"markdown","e9a2dde2":"markdown","4714809b":"markdown","ff7c973b":"markdown","a2a329c9":"markdown","7ecf90b7":"markdown","9c72d9d5":"markdown","04c89c6c":"markdown"},"source":{"2b9c8d96":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nfrom IPython.core.interactiveshell import InteractiveShell\nInteractiveShell.ast_node_interactivity = \"all\"","3f1d3957":"data_train = pd.read_csv('\/kaggle\/input\/airline-passenger-satisfaction\/train.csv')\ndata_test = pd.read_csv('\/kaggle\/input\/airline-passenger-satisfaction\/test.csv')","27f048ac":"data_train.info()","2589deea":"from sklearn.preprocessing import LabelEncoder\nlabelencoder = LabelEncoder()\ndata_train['satisfaction'] = labelencoder.fit_transform(data_train['satisfaction'])\ndata_test['satisfaction'] = labelencoder.fit_transform(data_test['satisfaction'])","2ac4c55b":"'How many people satisfacted by Airline:'\ndata_train.groupby('Gender')[['satisfaction']].sum()\n'How many people participated in the study:'\ndata_train.groupby('Gender')[['satisfaction']].count()\n'Percentage of satisfacted people :'\ndata_train.groupby('Gender')[['satisfaction']].sum()\/ data_train.groupby('Gender')[['satisfaction']].count()","2514b77d":"'Satisfaction of people depending on the class:'\ndata_train.groupby('Class')[['satisfaction']].sum()\n'How many people participated in the study:'\ndata_train.groupby('Class')[['satisfaction']].count()\n'Percentage of satisfacted people depending from the class:'\ndata_train.groupby('Class')[['satisfaction']].sum()\/ data_train.groupby('Class')[['satisfaction']].count()","3096980f":"'Percentage of satisfacted people depending from the type of travel:'\ndata_train.groupby('Type of Travel')[['satisfaction']].sum()\/ data_train.groupby('Type of Travel')[['satisfaction']].count()","8e2423d2":"data_dummies=pd.get_dummies(data_train, columns=[\"Gender\",\"Customer Type\",\"Type of Travel\",\"Class\"],drop_first=True)","63019a44":"data_test=pd.get_dummies(data_test, columns=[\"Gender\",\"Customer Type\",\"Type of Travel\",\"Class\"],drop_first=True)","d6798282":"fig, ax = plt.subplots(figsize=(14,14))\nsns.heatmap(data_dummies.corr(), annot=True, square=True, cbar=False, ax=ax, linewidths=0.25);","ef5d5243":"X_train = data_dummies.drop(columns=['Arrival Delay in Minutes', 'Unnamed: 0', 'id', 'satisfaction'])\nX_test = data_test.drop(columns=['Arrival Delay in Minutes', 'Unnamed: 0', 'id', 'satisfaction'])","6d3baa53":"y_train = data_dummies['satisfaction']\ny_test = data_test['satisfaction']","32d4bc7c":"X_train.isnull().sum()","cf99e302":"data_outliers = []\nfor col in X_train.columns:    \n        Q_min = X_train[col].quantile(0.01)\n        Q_max = X_train[col].quantile(0.99)\n        idx = ((X_train[col] < Q_min) | (X_train[col] > Q_max))\n        data_outliers.append(X_train[idx])\n\ndata_outliers = pd.concat(data_outliers)\ndata_cleared = X_train.drop(data_outliers.index.unique())\ny_cleared = y_train.drop(data_outliers.index.unique())","e37f3fb2":"from sklearn.metrics import classification_report\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import roc_auc_score\nfrom sklearn.metrics import roc_curve","800f5b47":"from sklearn.ensemble import AdaBoostClassifier\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.model_selection import RepeatedStratifiedKFold\nfrom numpy import mean\nfrom sklearn.model_selection import GridSearchCV","fd457182":"def models_result(model, X_test, y_test):\n    labels = model.predict(X_test)\n    matrix = confusion_matrix(y_test, labels)\n    sns.heatmap(matrix.T, square=True, annot=True, fmt='d', cbar=False)\n    plt.xlabel('true label')\n    plt.ylabel('predicted label');\n    \n    logit_roc_auc = roc_auc_score(y_test, labels)\n    fpr, tpr, thresholds = roc_curve(y_test, model.predict_proba(X_test)[:,1])\n    plt.figure()\n    plt.plot(fpr, tpr, label='(area = %0.2f)' % logit_roc_auc)\n    plt.plot([0, 1], [0, 1],'r--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.legend(loc=\"lower right\")\n    plt.savefig('Log_ROC')\n    plt.show();\n    \n    print(classification_report(y_test, labels))","f59401ab":"from sklearn.ensemble import RandomForestClassifier\n\nmodel = RandomForestClassifier()\nn_estimators = [50, 75, 100]\nmax_features = ['sqrt', 'log2']\ngrid = dict(n_estimators=n_estimators,max_features=max_features)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_RandomForestClassifier = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\nmodel_RandomForestClassifier = grid_search_RandomForestClassifier.fit(X_train, y_train)\n\nprint(\"Best: %f using %s\" % (model_RandomForestClassifier.best_score_, model_RandomForestClassifier.best_params_))","8fb8d958":"means = model_RandomForestClassifier.cv_results_['mean_test_score']\nstds = model_RandomForestClassifier.cv_results_['std_test_score']\nparams = model_RandomForestClassifier.cv_results_['params']\nfor mean, stdev, param in zip(means, stds, params):\n    print(\"%f (%f) with: %r\" % (mean, stdev, param))","04c3c1a8":"model_RandomForestClassifier_cleared = grid_search_RandomForestClassifier.fit(data_cleared, y_cleared)\nprint(\"Result: %f\" % (model_RandomForestClassifier_cleared.best_score_))","7709e0a5":"models_result(model_RandomForestClassifier, X_test, y_test)","861fc931":"from sklearn.ensemble import BaggingClassifier\n\nmodel = BaggingClassifier(random_state=28)\nn_estimators = [40]\ngrid = dict(n_estimators=n_estimators)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_BaggingClassifier = GridSearchCV(estimator=model, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\nmodel_BaggingClassifier = grid_search_BaggingClassifier.fit(X_train, y_train)\n\nprint(\"Result: %f\" % (model_BaggingClassifier.best_score_))","85bf8ff3":"model_BaggingClassifier_cleared = grid_search_BaggingClassifier.fit(data_cleared, y_cleared)\nprint(\"Result: %f\" % (model_BaggingClassifier_cleared.best_score_))","69535d3d":"models_result(model_BaggingClassifier, X_test, y_test)","afb355db":"ABC = AdaBoostClassifier(DecisionTreeClassifier(max_depth=3),\n                        learning_rate = 1.1,\n                        random_state=42)\n\nn_estimators = [75]\ngrid = dict(n_estimators=n_estimators)\ncv = RepeatedStratifiedKFold(n_splits=10, n_repeats=3, random_state=1)\ngrid_search_ABC = GridSearchCV(estimator=ABC, param_grid=grid, n_jobs=-1, cv=cv, scoring='accuracy',error_score=0)\nmodel_ABC = grid_search_ABC.fit(X_train, y_train)\n\nprint(\"Result: %f\" % (model_ABC.best_score_))","4081a799":"model_ABC_cleared = grid_search_ABC.fit(data_cleared, y_cleared)\nprint(\"Result: %f\" % (model_ABC_cleared.best_score_))","30702f77":"models_result(model_ABC, X_test, y_test)","4e34f028":"And look at type of every column.\n\nMachine learning models require all input and output variables to be numeric.\n\nBecause our data contains categorical data, we must transform it to numbers before we will fit and evaluate a model.\n\nWe have next categorical data:\n- Gender\n- Customer Type\n- Type of Travel\n- Class\n\nFor these columns to use method of Pandas get_dummies.\n\nFor categorical column 'satisfaction' to use LabelEncoder from sklearn:\n\n* neutral or dissatisfied = 0\n* satisfied = 1","24031ee7":"So, people`s satisfaction do not depend from gender.","6729430a":"We use 3 models:\n\n- RandomForestClassifier\n- BaggingClassifier\n- AdaBoostClassifier( with DecisionTreeClassifier)\n\nThe best result gave a model with using RandomForestClassifier = 96,23% accuracy.","32570b8e":"### AdaBoostClassifier ###","66dcd671":"Business travel also promotes to satisfaction.","4ac6d3f2":"<div class=\"alert alert-block alert-warning\">\nCreate one more data without outliers and will be train models on 2 data with a choice of the best.\n<\/div>","95bbdae7":"### Data analysis ###","b344214e":"### RandomForestClassifier ###","d41898fb":"<div class=\"alert alert-block alert-success\">\n    \nThanks to:\n\nauthor of this dataset;\n    \nhttps:\/\/machinelearningmastery.com\/\n        \n### Happy coding ###\n<\/div>","e9a2dde2":"## Train models ##","4714809b":"As we can see there is correlation: 'Departure Delay in Minutes', 'Arrival Delay in Minutes'.\nDrop from data column 'Arrival Delay in Minutes'.\nAlso columns 'Unnamed: 0', 'id' don`t have useful information - drop them too.","ff7c973b":"In this model, we will select hyperparameters for the best result. Then the already selected hyperparameters will be substituted.\n\nWe will iterate over different values for parameters:\n- max_features\n- n_estimators","a2a329c9":"Our data haven`t 'Null'.","7ecf90b7":"We can see that satisfaction depend from class: Business class promotes to satisfaction and not if eco class.","9c72d9d5":"And to use RandomForestClassifier we need choose hyperparameters: max_features = log2, n_estimators = 100","04c89c6c":"### BaggingClassifier ###"}}