{"cell_type":{"faddfc35":"code","b5346cb9":"code","d173ac1f":"code","f337ae00":"code","1e7058a4":"code","421d19ae":"code","266778b6":"code","092a86a8":"code","e85472c9":"code","008a6db5":"code","f854775e":"code","cda622c6":"code","d210fbd6":"code","59248100":"code","2adff341":"code","9cbfa264":"code","791ac5ae":"code","8c5a3d4b":"code","a5594ddc":"code","bb57f745":"code","693f39e4":"code","8612d366":"code","265a83ce":"code","c17b078a":"code","5c6a2938":"code","928674e3":"code","cd0ad2dc":"code","f736a772":"code","fd34993c":"code","591a9ead":"code","8a5a2a97":"code","e7bfebc8":"code","5b26e469":"code","0fd07ca4":"code","687fa6ee":"code","62750359":"code","0481a784":"code","430a743c":"code","4b7fa693":"markdown","b3d4278b":"markdown","63722dbf":"markdown","bf83f0af":"markdown","e2fd0f6c":"markdown","178a8553":"markdown","61760f11":"markdown","2759dc07":"markdown","24ea094b":"markdown","2f6319af":"markdown","11e15394":"markdown","9f4819f2":"markdown","b74a9566":"markdown","c8b242e3":"markdown"},"source":{"faddfc35":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b5346cb9":"# read a JSON file\ndf = pd.read_json(\"..\/input\/university-statistics\/schoolInfo.json\")","d173ac1f":"# show all columns\npd.options.display.max_columns = None","f337ae00":"df.head()","1e7058a4":"df.info()","421d19ae":"# drop columns which have only NaN values\ndf.dropna(axis=1, thresh=1, inplace=True)","266778b6":"# drop columns with only one distinct value\nfor col in df.columns:\n    if len(df[col].unique()) == 1:\n        df.drop(col,inplace=True,axis=1)","092a86a8":"df.head()","e85472c9":"# drop non relevant columns or columns which semantically duplicate other columns in the DataFrame\ndf.drop(['primaryPhoto', 'primaryPhotoThumb', 'sortName', 'urlName', 'aliasNames', 'nonResponderText', 'nonResponder', 'rankingSortRank', 'overallRank', 'rankingRankStatus', 'xwalkId', 'primaryKey'], axis=1, inplace=True)","008a6db5":"df.head()","f854775e":"# print all unique citites with universities\ncity = df['city'].unique()\nprint(sorted(city))","cda622c6":"# number of unique cities\ndf['city'].nunique()","d210fbd6":"df.loc[df['city'] == 'St Louis']","59248100":"df.loc[df['city'] == 'St. Louis']","2adff341":"# St. Louis is misspelled, a dot is missing, we replace the misspelled value with the correct one\ndf.replace('St Louis', 'St. Louis', inplace=True)","9cbfa264":"# we replace Ft. Lauderdale with Fort Lauderdale because\n# in the United States Cities Database table it is Fort Lauderdale\n# and we are going to merge two tables on city names\ndf.replace('Ft. Lauderdale', 'Fort Lauderdale', inplace=True)","791ac5ae":"# show which cities have the most universities\ndf['city'].value_counts().head(10)","8c5a3d4b":"# show which states have the most universities\ndf['state'].value_counts().head(10)","a5594ddc":"# create a new dataframe with the number of universities in each state and plot the graph\ndf_count = df['state'].value_counts().rename_axis('State').reset_index(name='Number of Universities')\n\ndf_count_to_plot = df_count\n\ndf_count_to_plot[\"State\"] = df_count[\"State\"]\ndf_count_to_plot[\"Number of Universities\"] = df_count[\"Number of Universities\"]\n\nimport matplotlib.pyplot as plt\n\nplt.rcParams[\"figure.figsize\"] = (18, 5)\n\ndf_count_to_plot.plot.bar(x='State', rot=45)","bb57f745":"# move the column with university names to the front so the table gets more readable\ndf = df[ ['displayName'] + [ col for col in df.columns if col != 'displayName' ] ]","693f39e4":"# universities with the highest ranking\ndf.sort_values(by=['rankingDisplayScore'], ascending=False).head()","8612d366":"# universities with the highest enrollment\ndf.sort_values(by=['enrollment'], ascending=False).head()","265a83ce":"# universities with the highest tuition\ndf.sort_values(by=['tuition'], ascending=False).head()","c17b078a":"# universities with the highest percent of students receiving aid\ndf.sort_values(by=['percent-receiving-aid'], ascending=False).head()","5c6a2938":"df2 = pd.read_csv(\"..\/input\/united-states-cities-database\/uscities.csv\")","928674e3":"# columns of our United States Cities Database DataFrame\ndf2.columns","cd0ad2dc":"df2","f736a772":"# we see that in the 'city_ascii' column cities have the more universal spelling\ndf2.loc[(df2['city'] != df2['city_ascii'])]","fd34993c":"df2.drop(['city'], axis=1, inplace=True)","591a9ead":"df2.rename(columns={\"city_ascii\": \"city\"}, inplace=True)","8a5a2a97":"# merge two tables on city names, we want citites from the 'university-statistics' table\n# to have longitude and latitude data which we extract from the US Cities Database table\ndf_merged = pd.merge(df, df2, on='city')","e7bfebc8":"df_merged","5b26e469":"# many cities from different states have the same name that's why we have 1604 rows in the merged table\n# we need to keep only cities from both tables which not only share the name,\n# but are also located in the same state\ndf_merged = df_merged.loc[(df_merged['state'] == df_merged['state_id'])]","0fd07ca4":"df_merged.info()","687fa6ee":"import geopandas as gpd\nimport math\nimport folium\nfrom folium import Choropleth, Circle, Marker\nfrom folium.plugins import HeatMap, MarkerCluster","62750359":"# Create a map\nm_1 = folium.Map(location=[42.32,-81.0589], tiles='openstreetmap', zoom_start=3)\n\n# Add points to the map\nfor idx, row in df_merged.iterrows():\n    Marker([row['lat'], row['lng']]).add_to(m_1)\n\n# Display the map\nm_1","0481a784":"# a new DataFrame with the top univiersities by ranking\ndf_top = df_merged.loc[df_merged['rankingDisplayScore'] >90]","430a743c":"# show a map with the top universities by ranking\nm_2 = folium.Map(location=[42.32,-81.0589], tiles='openstreetmap', zoom_start=3)\n\nfor idx, row in df_top.iterrows():\n    Marker([row['lat'], row['lng']]).add_to(m_2)\n\nm_2","4b7fa693":"Interestingly the top 3 universities by students receiving aid are located in the **New York State**.","b3d4278b":"**Chicago** and **New York** have the most universities.","63722dbf":"**Columbia University** is the most expensive one.","bf83f0af":"**University of Central Florida** is the biggest one by enrollment.","e2fd0f6c":"![](https:\/\/images.unsplash.com\/photo-1533854775446-95c4609da544?ixid=MnwxMjA3fDB8MHxwaG90by1wYWdlfHx8fGVufDB8fHx8&ixlib=rb-1.2.1&auto=format&fit=crop&w=1050&q=80)","178a8553":"If you like this notebook, **you may also like**\n\n* [Stack Overflow: Who can help with SQL & Python?](https:\/\/www.kaggle.com\/sergejnuss\/stack-overflow-who-can-help-with-sql-python)\n* [StackOverflow Hits: Typescript, Python, Javascript](https:\/\/www.kaggle.com\/sergejnuss\/stackoverflow-hits-typescript-python-javascript)","61760f11":"# Part 1. Cleaning the Table and Extracting Stats","2759dc07":"We see that the most top universities are located on the **East Coast**, two are in **California** and one in **Chicago**.","24ea094b":"Unsurprisingly **California** and **Texas** as the biggest states have also the most universities.","2f6319af":"# Part 3. Displaying the Map","11e15394":"# Part 2. Merging tables","9f4819f2":"In the first part of this notebook we'll read a **JSON** file and extract statistics on **US universities**. In the second part we'll **merge** our 'university-statistics' table with a bigger table containing **latitude and longitude data** of all American cities which I uploaded to Kaggle from https:\/\/simplemaps.com\/data\/us-cities before. Geospatial information will allow us to put all universities on the **map** in the third part of this work.","b74a9566":"**Princeton University** has the highest ranking.","c8b242e3":"We have 294 rows in the new table, it's 16 rows fewer than in the original university table. We lost about 5% of universities on discrepancies between the two merged tables. Still we have enough relevant information for our interactive map as **longitude and latitude data** was correctly attributed in absolutely most cases."}}