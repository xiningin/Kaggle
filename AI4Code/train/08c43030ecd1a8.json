{"cell_type":{"ccc46b0c":"code","c20db4c1":"code","a433f383":"code","80355223":"code","30b3a716":"code","1d2ae61c":"code","b2705042":"code","58f9f45f":"code","99b17710":"code","40e56e98":"code","dd5f06a9":"code","d99a6ad6":"code","4b878819":"code","5407c556":"code","54ada2d4":"code","5a519c30":"code","bd879511":"code","cf7b340d":"code","97424fc2":"code","4a5b76d4":"code","a35c19f1":"code","19ab8ec7":"code","da56d662":"code","0d32316b":"code","686a792b":"code","08d10ff4":"code","07ad072f":"code","da84cde5":"code","cc192828":"code","d7576ce2":"markdown","39910de3":"markdown","2b8b2503":"markdown","1964d951":"markdown","0f437535":"markdown","eeb528e1":"markdown","1853e49c":"markdown","ba10c3cd":"markdown","58435d2f":"markdown"},"source":{"ccc46b0c":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport scipy.stats as ss # statistical functions\nimport matplotlib.pyplot as plt # plotting\nimport seaborn as sns # pretty plots\nimport math\nimport warnings\n\nfrom collections import Counter\nfrom sklearn.model_selection import train_test_split # data splitting\n\nimport tensorflow as tf  # building NN model\nfrom tensorflow.keras.layers.experimental import preprocessing # input preprocessing\n\n# model evaluation metrics\nfrom sklearn.metrics import accuracy_score, precision_score,recall_score, f1_score,confusion_matrix\n\nwarnings.filterwarnings('ignore')\n","c20db4c1":"print(tf.__version__)","a433f383":"# load the data\ndata = pd.read_csv(\"\/kaggle\/input\/phishing-dataset-for-machine-learning\/Phishing_Legitimate_full.csv\")","80355223":"# list of features\ndata.info()","30b3a716":"# separate the target variable\nlabel = data.pop('CLASS_LABEL')\nids   = data.pop('id')\n\n# list of categorical features\ncategorical_features = [\n    'AtSymbol','TildeSymbol','NoHttps','RandomString','IpAddress','DomainInSubdomains','DomainInPaths',\n    'HttpsInHostname','DoubleSlashInPath','EmbeddedBrandName','ExtFavicon','InsecureForms','RelativeFormAction',\n    'ExtFormAction','AbnormalFormAction','FrequentDomainNameMismatch','FakeLinkInStatusBar','RightClickDisabled',\n    'PopUpWindow','SubmitInfoToEmail','IframeOrFrame','MissingTitle','ImagesOnlyInForm','SubdomainLevelRT',\n    'UrlLengthRT','PctExtResourceUrlsRT','AbnormalExtFormActionR','ExtMetaScriptLinkRT','PctExtNullSelfRedirectHyperlinksRT'\n]\n\n# list of numerical features\nnumerical_features = [x for x in data.columns if x not in categorical_features]\n","1d2ae61c":"print(\"Number of Categorical(Nominal) Features : \",len(categorical_features))\nprint(\"Number of Numerical(Ordianl) Features : \",len(numerical_features))","b2705042":"categorical_data = data[categorical_features]\n\n# change the datatype to categorical for all columns\nfor feature in categorical_data.columns:\n    categorical_data[feature] = categorical_data[feature].astype('category')\n    \n# summary statistics for categorical features\ncategorical_data.describe()\n","58f9f45f":"def conditional_entropy(x,y):\n    \"\"\"\n    Calculates the conditional entropy of two random varibales X and Y\n    wikipedia: https:\/\/en.wikipedia.org\/wiki\/Conditional_entropy\n    \"\"\"\n    \n    y_counter  = Counter(y) # count of all possible y's (the differnt values that the feature can take and their frequency)\n    xy_counter = Counter(list(zip(x,y))) # count of all possible pairs of x and y\n    \n    total_occurences = sum(y_counter.values())\n    entropy = 0.0\n    \n    for xy in xy_counter.keys():\n        p_xy = xy_counter[xy]\/total_occurences\n        p_y  = y_counter[xy[1]]\/total_occurences\n        entropy += p_xy*math.log(p_y\/p_xy,math.e)\n    \n    return entropy","99b17710":"def theils_u(x,y):\n    \"\"\"\n    Calculates the Theil's Uncertainity Coefficient between two random variables X and Y\n    wikipedia: https:\/\/en.wikipedia.org\/wiki\/Uncertainty_coefficient\n    \"\"\"\n    \n    h_xy = conditional_entropy(x,y) # condtitonal entropy of X and Y\n    x_counter = Counter(x) # count of all possible values of X\n    total_occurrences = sum(x_counter.values())\n    p_x = list(map(lambda n: n \/ total_occurrences, x_counter.values())) # probability distribution of X\n    h_x = ss.entropy(p_x)\n    if h_x == 0:\n        return 1\n    else:\n        return (h_x - h_xy) \/ h_x\n    ","40e56e98":"# calculating the coefficient of correlation between `label` and all the categorical features\n\nuc_scores = dict()\n\nfor feature in categorical_features:\n    y  = categorical_data[feature]\n    uc = theils_u(label,y)\n    uc_scores[feature] = uc\n    \n# sort the scores in descending order\nuc_scores = sorted(uc_scores.items(),key=lambda kv: (kv[1],kv[0]),reverse=True)\nfor k,v in uc_scores:\n    print(\"{} : {}\".format(k,v))\n    ","dd5f06a9":"# filter the above features\nfiltered_cats = ['PctExtNullSelfRedirectHyperlinksRT','ExtMetaScriptLinkRT','FrequentDomainNameMismatch','SubmitInfoToEmail']\nfiltered_cat_data = categorical_data[filtered_cats]\n\n# revert the datatype to int32\nfor feature in filtered_cat_data.columns:\n    filtered_cat_data[feature] = filtered_cat_data[feature].astype('int32')     \n\n# sample\nfiltered_cat_data.head()","d99a6ad6":"# analysis of numerical features\n\nnumerical_data = data[numerical_features]\n\n# summary statistics for numerical features\nnumerical_data.describe()","4b878819":"# calculate point biserial coefficient between numerical features and the target variable\n\nrpb_scores = dict()\n\nfor feature in numerical_features:\n    y = numerical_data[feature]\n    rpb = abs(ss.pointbiserialr(y,label).correlation)\n    rpb_scores[feature] = rpb\n    \n# sort the scores in descending order\nrpb_scores = sorted(rpb_scores.items(),key=lambda kv: (kv[1],kv[0]),reverse=True)\nfor k,v in rpb_scores:\n    print(\"{} : {}\".format(k,v))\n    \n    ","5407c556":"# filter the above features\nfiltered_nums = ['NumDash', 'PctNullSelfRedirectHyperlinks', 'NumDots', 'PctExtHyperlinks', 'NumSensitiveWords', 'PathLevel', 'HostnameLength', 'NumDashInHostname', 'NumQueryComponents']\nfiltered_num_data = data[filtered_nums]\n\n","54ada2d4":"# merge the filtered categorical and numerical data\nfiltered_data = pd.concat([filtered_num_data,filtered_cat_data],axis=1)\nfiltered_data['label'] = label","5a519c30":"filtered_data.head()","bd879511":"# splitting the data into train,test and validation\ntrain, test = train_test_split(filtered_data, test_size=0.2)\ntrain, val = train_test_split(train, test_size=0.2)\nprint(len(train), 'train examples')\nprint(len(val), 'validation examples')\nprint(len(test), 'test examples')\n\n","cf7b340d":"def dataframe_to_dataset(dataframe, shuffle=True, batch_size=32):\n    \"\"\"\n    Creates a tensorflow Dataset object from a Pandas Dataframe\n    \"\"\"\n    df = dataframe.copy()\n    labels = df.pop('label') # target varibale\n    ds = tf.data.Dataset.from_tensor_slices((dict(df),labels))\n    if shuffle:\n        ds = ds.shuffle(buffer_size=len(df))\n    ds = ds.batch(batch_size)\n    ds = ds.prefetch(batch_size)\n    return ds\n","97424fc2":"\n# creating datasets\nbatch_size = 256\ntrain_ds = dataframe_to_dataset(train, batch_size=batch_size)\nval_ds = dataframe_to_dataset(val, shuffle=False, batch_size=batch_size)\ntest_ds = dataframe_to_dataset(test, shuffle=False, batch_size=batch_size)","4a5b76d4":"# preprocessing layer generators\n\n# normalization layer for numerical features\ndef get_normalization_layer(feature,dataset):\n    normalizer = preprocessing.Normalization(axis=None)\n    feature_ds = dataset.map(lambda x, y: x[feature])\n    normalizer.adapt(feature_ds)\n    return normalizer\n\n# encoding layer for categorical features to convert class to onehot encodings\ndef get_encoding_layer(feature,dataset,dtype,max_tokens):\n    index = preprocessing.IntegerLookup(max_values=max_tokens,oov_value=-2)\n    feature_ds = dataset.map(lambda x,y : x[feature])\n    index.adapt(feature_ds)\n    encoder = preprocessing.CategoryEncoding(max_tokens = len(index.get_vocabulary()))\n    \n    return lambda feature : encoder(index(feature))\n    ","a35c19f1":"## model preprocessing layers\n\nall_inputs = list()\nencoded_features = list()\n\n# add input layers for the numerical features\nfor header in filtered_nums:\n    numeric_col = tf.keras.Input(shape=(1,), name=header)\n    normalization_layer = get_normalization_layer(header, train_ds)\n    normalized_numeric_col = normalization_layer(numeric_col)\n    all_inputs.append(numeric_col)\n    encoded_features.append(normalized_numeric_col)\n    \n# add input layers for the categorical features\nfor header in filtered_cats:\n    categorical_col = tf.keras.Input(shape=(1,), name=header, dtype='int32')\n    encoding_layer = get_encoding_layer(header, train_ds, dtype='int32',max_tokens=5)\n    encoded_categorical_col = encoding_layer(categorical_col)\n    all_inputs.append(categorical_col)\n    encoded_features.append(encoded_categorical_col)\n\n","19ab8ec7":"# model layers\n\nall_features = tf.keras.layers.concatenate(encoded_features)\n\nx = tf.keras.layers.Dense(32, activation=\"relu\")(all_features)\nx = tf.keras.layers.Dropout(0.5)(x)\noutput = tf.keras.layers.Dense(1)(x)\n\nmodel = tf.keras.Model(all_inputs, output)\nmodel.compile(optimizer='adam',\n              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n              metrics=[\"accuracy\"])\n","da56d662":"tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")","0d32316b":"history = model.fit(train_ds, epochs=500, validation_data=val_ds)","686a792b":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","08d10ff4":"plt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='upper right')\nplt.show()","07ad072f":"# evaluation on test data\nloss, accuracy = model.evaluate(test_ds)\nprint(\"Accuracy\", accuracy)\n","da84cde5":"testy = test['label']\ny_pred = model.predict(test_ds)\nyhat_classes = []\nfor pred in y_pred:\n    if pred > 0:\n        yhat_classes.append(1)\n    else:\n        yhat_classes.append(0)\n        ","cc192828":"# accuracy: (tp + tn) \/ (p + n)\naccuracy = accuracy_score(testy, yhat_classes)\nprint('Accuracy: %f' % accuracy)\n# precision tp \/ (tp + fp)\nprecision = precision_score(testy, yhat_classes)\nprint('Precision: %f' % precision)\n# recall: tp \/ (tp + fn)\nrecall = recall_score(testy, yhat_classes)\nprint('Recall: %f' % recall)\n# f1: 2 tp \/ (2 tp + fp + fn)\nf1 = f1_score(testy, yhat_classes)\nprint('F1 score: %f' % f1)\n\nprint(\"Confusion Matrix : \")\nmatrix = confusion_matrix(testy, yhat_classes)\nprint(matrix)","d7576ce2":"\n\n\n\n\n\n## **Model Evaluation**","39910de3":"\n\n\n## **Model Creation**","2b8b2503":"\n\n### **Feature Analysis**\n#### In the following section, we will separate the categorical and numerical features and analyse them separately","1964d951":"\n### The categorical features with the highest correlation with target variable are\n\n#### '**PctExtNullSelfRedirectHyperlinksRT**', '**FrequentDomainNameMismatch**', '**ExtMetaScriptLinkRT**', '**SubmitInfoToEmail**'","0f437535":"### **Checking Correlation of numerical features with the target variable**\n\n#### The Point Biserial Correlation Coefficient measures the correlation between a dichotomous variable Y and a continous variable X.\n","eeb528e1":"\n### **Pishing** refers to a malicious attempt to acquire a user's personal data by using deceptive emails or webpages.\n### The objective of this notebook is to use machine learning to filter out such pishing webpages from the legitimate ones.\n\n#### **This notebook includes the following**\n\n##### 1. Analysis of the features included in the dataset\n##### 2. Development of an MLP to determine the legitimacy of a webpage\n##### 3. Evaluation of the developed model","1853e49c":"### **Evaluation Metrics**","ba10c3cd":"\n\n### **Checking Correlation of categorical features with the target variable**\n\n#### The Uncertainity Coefficient (Theil's U) which represents the following relation between two nominal random variables X and Y, given X how well can we predict Y.\n\n","58435d2f":"\n### The numerical features with the highest correlation with target varibale are\n\n#### '**NumDash**', '**PctNullSelfRedirectHyperlinks**', '**NumDots**', '**PctExtHyperlinks**', '**NumSenstiveWords**', '**PathLevel**', '**HostnameLength**', '**NumDashInHostname**', '**NumQueryComponents**'"}}