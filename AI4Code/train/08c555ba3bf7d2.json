{"cell_type":{"c448ae72":"code","f01e69c7":"code","db5f7f1f":"code","a3904b3e":"code","bd2f86aa":"code","af56d323":"code","71337628":"code","8a58e0b0":"code","9d243eb5":"code","277b6b44":"code","a7ca1e62":"code","176a2c0e":"code","2e9f0f03":"code","362d534f":"code","28ab6548":"code","3cf684e7":"code","4e572e2f":"code","28285591":"code","366c3033":"code","e6209e5d":"code","678e498f":"code","8d4e2ee8":"code","6d27daa8":"code","4a2d3640":"code","4dfb9cb8":"code","2b7803fa":"code","0fb56a50":"code","243260b6":"code","37b06bc1":"code","0fe78d25":"code","7c2cd3b5":"code","2cb4058a":"code","eed0b5e8":"code","0b4c69b7":"code","982eb315":"code","d234a04d":"code","58109945":"code","0f037b76":"code","52666966":"code","e97c33b1":"code","d395851b":"markdown","614535c5":"markdown","ed6eed89":"markdown","5866c0b2":"markdown","fceb7ff6":"markdown","1d88ab0c":"markdown","d2c14d73":"markdown","dff6843e":"markdown","e544d751":"markdown","e89aaf64":"markdown","7e71b6ee":"markdown","e3e47d9f":"markdown","c48879a5":"markdown","40dfd315":"markdown","0394f18e":"markdown","f1cfb12a":"markdown","121ab254":"markdown","c4f214da":"markdown","d872c09e":"markdown","b6ce9392":"markdown","26795e0a":"markdown","7e3a75e8":"markdown","004f596b":"markdown","4ddb7bba":"markdown","1d522265":"markdown","ba91c6a0":"markdown","85accb8b":"markdown","c07f88da":"markdown","6ffad341":"markdown","fe6ff801":"markdown","dd944b8c":"markdown","35231fbb":"markdown"},"source":{"c448ae72":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\n\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.metrics import log_loss\nfrom category_encoders import CountEncoder\nfrom sklearn.model_selection import KFold\nfrom xgboost import XGBClassifier\nfrom sklearn.multioutput import MultiOutputClassifier\nimport random\n\nimport plotly.express as px\nimport plotly.graph_objects as go\nfrom plotly.subplots import make_subplots\nimport plotly.figure_factory as ff\nfrom plotly.offline import init_notebook_mode, iplot\ninit_notebook_mode(connected=True)\nimport seaborn as sns\n\nimport warnings\nwarnings.filterwarnings('ignore')","f01e69c7":"ROOT = '..\/input\/lish-moa'\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","db5f7f1f":"# training data\ntrain = pd.read_csv(f'{ROOT}\/train_features.csv')\n\n# training data targets\ntarget = pd.read_csv(f'{ROOT}\/train_targets_scored.csv')\n\n# testing data\ntest = pd.read_csv(f'{ROOT}\/test_features.csv')","a3904b3e":"train.head()","bd2f86aa":"target.head()","af56d323":"print(\"No. of rows in training set : {}\".format(train.shape[0]))\nprint('No. of columns in training set : {}'.format(train.shape[1]))\nprint('No. of rows in target set : {}'.format(target.shape[0]))\nprint('No. of columns in target set : {}'.format(target.shape[1]))","71337628":"cols = train.columns\ng_cols = [x for x in cols if x.startswith('g-')]\nc_cols = [x for x in cols if x.startswith('c-')]\nprint(f\"There are {train.shape[1]} columns in training and test set out of which :- \")\nprint(f\"There are {len(g_cols)} columns starting with 'g-' i.e. gene expression features.\")\nprint(f\"There are {len(c_cols)} columns starting with 'c-' i.e. cell viability features.\")\nprint(\"'sig_id', 'cp_type', 'cp_time', 'cp_dose' account for the remaining 4 columns.\")","8a58e0b0":"labels = ['g-','c-','sig_id','cp_type', 'cp_time', 'cp_dose']\nvalues = [len(g_cols), len(c_cols), 1, 1, 1, 1]\n\n# Use `hole` to create a donut-like pie chart\nfig = go.Figure(data=[go.Pie(labels=labels, values=values, hole=.5)])\n\nfig.update_layout(title_text=\"Distribution of columns in train and test features.\")\nfig.show()","9d243eb5":"# Unique values for features\nprint(\"There are {} unique values in 'sig_id' column. So, there are no duplicate rows\".format(train.sig_id.nunique()))\nprint(\"There are {} unique values in 'cp_type' column having values : {}\".format(train.cp_type.nunique(), train.cp_type.unique()))\nprint(\"There are {} unique values in 'cp_time' column having values : {}\".format(train.cp_time.nunique(), train.cp_time.unique()))\nprint(\"There are {} unique values in 'cp_dose' column having values : {}\".format(train.cp_dose.nunique(), train.cp_dose.unique()))","277b6b44":"trt_cp_count = train.cp_type.value_counts()[0]\nctl_vehicle_count = train.cp_type.value_counts()[1]\nprint(f\"In 'cp_type' feature there are {trt_cp_count} records with value 'trt_cp' and {ctl_vehicle_count} records \" \n      + \"with value 'ctl_vehicle'\")","a7ca1e62":"x=train.cp_type.unique()\ny_train=[trt_cp_count,ctl_vehicle_count]\ny_test=[test.cp_type.value_counts()[0], test.cp_type.value_counts()[1]]\n\nfig = go.Figure(data=[\n    go.Bar(name='test', x=x, y=y_test),\n    go.Bar(name='train', x=x, y=y_train)\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.show()","176a2c0e":"print(\"There are {} distinct values for 'cp_time' : {}\".format(train.cp_time.nunique(), train.cp_time.unique()))\nprint('No. of records where cp_time=24 : {}'.format(train[train.cp_time == 24].shape[0]))\nprint('No. of records where cp_time=48 : {}'.format(train[train.cp_time == 48].shape[0]))\nprint('No. of records where cp_time=72 : {}'.format(train[train.cp_time == 72].shape[0]))","2e9f0f03":"x=train.cp_time.unique()\ny_train = [train[train.cp_time == 24].shape[0],train[train.cp_time == 72].shape[0],train[train.cp_time == 48].shape[0]]\ny_test=[test[test.cp_time == 24].shape[0],test[test.cp_time == 72].shape[0],test[test.cp_time == 48].shape[0]]\nfig = go.Figure(data=[\n    go.Bar(name='test', x=x, y=y_test),\n    go.Bar(name='train', x=x, y=y_train)\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.show()","362d534f":"d1_count = train.cp_dose.value_counts()[0]\nd2_count = train.cp_dose.value_counts()[1]\nprint(f\"In 'cp_dose' feature there are {d1_count} records with value 'D1' and {d2_count} records \" \n      + \"with value 'D2'\")","28ab6548":"x=train.cp_dose.unique()\ny_train=[d1_count,d2_count]\ny_test=[test.cp_dose.value_counts()[0], test.cp_dose.value_counts()[1]]\n\nfig = go.Figure(data=[\n    go.Bar(name='test', x=x, y=y_test),\n    go.Bar(name='train', x=x, y=y_train)\n])\n# Change the bar mode\nfig.update_layout(barmode='group')\nfig.show()","3cf684e7":"# distributions of few random g- features\nrandom_g_cols = random.sample(g_cols, 10)\n\nfig = make_subplots(rows=5, cols=2, subplot_titles=random_g_cols)\n\nfig.add_trace(go.Histogram(x=train[random_g_cols[0]], name=random_g_cols[0]), row=1, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[1]], name=random_g_cols[1]), row=1, col=2)\nfig.add_trace(go.Histogram(x=train[random_g_cols[2]], name=random_g_cols[2]), row=2, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[3]], name=random_g_cols[3]), row=2, col=2)\nfig.add_trace(go.Histogram(x=train[random_g_cols[4]], name=random_g_cols[4]), row=3, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[5]], name=random_g_cols[5]), row=3, col=2)\nfig.add_trace(go.Histogram(x=train[random_g_cols[6]], name=random_g_cols[6]), row=4, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[7]], name=random_g_cols[7]), row=4, col=2)\nfig.add_trace(go.Histogram(x=train[random_g_cols[8]], name=random_g_cols[8]), row=5, col=1)\nfig.add_trace(go.Histogram(x=train[random_g_cols[9]], name=random_g_cols[9]), row=5, col=2)\n\nfig.update_layout(\n    title_text='Distribution of a few random Gene Expression features',\n    height = 1200,\n    width=675\n)\n\nfig.show()","4e572e2f":"# distributions of few random c- features\nrandom_c_cols = random.sample(c_cols, 10)\n\nfig = make_subplots(rows=5, cols=2, subplot_titles=random_c_cols)\n\nfig.add_trace(go.Histogram(x=train[random_c_cols[0]], name=random_c_cols[0]), row=1, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[1]], name=random_c_cols[1]), row=1, col=2)\nfig.add_trace(go.Histogram(x=train[random_c_cols[2]], name=random_c_cols[2]), row=2, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[3]], name=random_c_cols[3]), row=2, col=2)\nfig.add_trace(go.Histogram(x=train[random_c_cols[4]], name=random_c_cols[4]), row=3, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[5]], name=random_c_cols[5]), row=3, col=2)\nfig.add_trace(go.Histogram(x=train[random_c_cols[6]], name=random_c_cols[6]), row=4, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[7]], name=random_c_cols[7]), row=4, col=2)\nfig.add_trace(go.Histogram(x=train[random_c_cols[8]], name=random_c_cols[8]), row=5, col=1)\nfig.add_trace(go.Histogram(x=train[random_c_cols[9]], name=random_c_cols[9]), row=5, col=2)\n\nfig.update_layout(\n    title_text='Distribution of a few random Cell Viability features',\n    height = 1200,\n    width=675\n)\n\nfig.show()","28285591":"trt_cp_24 = train[(train.cp_type == 'trt_cp') & (train.cp_time == 24)].shape[0]\ntrt_cp_48 = train[(train.cp_type == 'trt_cp') & (train.cp_time == 48)].shape[0]\ntrt_cp_72 = train[(train.cp_type == 'trt_cp') & (train.cp_time == 72)].shape[0]\nctl_veh_24 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_time == 24)].shape[0]\nctl_veh_48 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_time == 48)].shape[0]\nctl_veh_72 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_time == 72)].shape[0]\n\nrel_df = pd.DataFrame([['trt_cp', trt_cp_24, trt_cp_48, trt_cp_72],\n                       ['ctl_vehicle', ctl_veh_24, ctl_veh_48, ctl_veh_72]], \n                      columns = ['cp_type', '24', '48', '72'])\n\nfig = px.bar(rel_df, x=\"cp_type\", y=[\"24\", \"48\", \"72\"], title=\"Cp_type V\/S Cp_time\")\nfig.show()","366c3033":"trt_cp_d1 = train[(train.cp_type == 'trt_cp') & (train.cp_dose == 'D1')].shape[0]\ntrt_cp_d2 = train[(train.cp_type == 'trt_cp') & (train.cp_dose == 'D2')].shape[0]\nctl_veh_d1 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_dose == 'D1')].shape[0]\nctl_veh_d2 = train[(train.cp_type == 'ctl_vehicle') & (train.cp_dose == 'D2')].shape[0]\n\nrel_df = pd.DataFrame([['trt_cp', trt_cp_d1, trt_cp_d2],\n                       ['ctl_vehicle', ctl_veh_d1, ctl_veh_d2]], \n                      columns = ['cp_type', 'D1', 'D2'])\n\nfig = px.bar(rel_df, x=\"cp_type\", y=['D1', 'D2'], title=\"Cp_type V\/S Cp_dose\")\nfig.show()","e6209e5d":"d1_24 = train[(train.cp_dose == 'D1') & (train.cp_time == 24)].shape[0]\nd1_48 = train[(train.cp_dose == 'D1') & (train.cp_time == 48)].shape[0]\nd1_72 = train[(train.cp_dose == 'D1') & (train.cp_time == 72)].shape[0]\nd2_24 = train[(train.cp_dose == 'D2') & (train.cp_time == 24)].shape[0]\nd2_48 = train[(train.cp_dose == 'D2') & (train.cp_time == 48)].shape[0]\nd2_72 = train[(train.cp_dose == 'D2') & (train.cp_time == 72)].shape[0]\n\nrel_df = pd.DataFrame([['D1', d1_24, d1_48, d1_72],\n                       ['D2', d2_24, d2_48, d2_72]], \n                      columns = ['cp_dose', '24', '48', '72'])\n\nfig = px.bar(rel_df, x=\"cp_dose\", y=[\"24\", \"48\", \"72\"], title=\"Cp_dose V\/S Cp_time\")\nfig.show()","678e498f":"# Correlation b\/w random 40 g- features\n\ng_df = train[random.sample(g_cols, 40)]\nf = plt.figure(figsize=(19, 15))\nplt.matshow(g_df.corr(), fignum=f.number)\nplt.xticks(range(g_df.shape[1]), g_df.columns, fontsize=14, rotation=50)\nplt.yticks(range(g_df.shape[1]), g_df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","8d4e2ee8":"# Correlation b\/w random 40 c- features\n\nc_df = train[random.sample(c_cols, 40)]\nf = plt.figure(figsize=(19, 15))\nplt.matshow(c_df.corr(), fignum=f.number)\nplt.xticks(range(c_df.shape[1]), c_df.columns, fontsize=14, rotation=50)\nplt.yticks(range(c_df.shape[1]), c_df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","6d27daa8":"cols = ['cp_time'] + g_cols + c_cols\nall_columns = []\nfor i in range(0, len(cols)):\n    for j in range(i+1, len(cols)):\n        if abs(train[cols[i]].corr(train[cols[j]])) > 0.9:\n            all_columns.append(cols[i])\n            all_columns.append(cols[j])\n\nall_columns = list(set(all_columns))\nprint('Number of columns: ', len(all_columns))","4a2d3640":"all_cols_df = train[all_columns]\nf = plt.figure(figsize=(19, 15))\nplt.matshow(all_cols_df.corr(), fignum=f.number)\nplt.xticks(range(all_cols_df.shape[1]), all_cols_df.columns, fontsize=14, rotation=50)\nplt.yticks(range(all_cols_df.shape[1]), all_cols_df.columns, fontsize=14)\ncb = plt.colorbar()\ncb.ax.tick_params(labelsize=14)","4dfb9cb8":"target.head()","2b7803fa":"print(\"No. of rows : {}\".format(target.shape[0]))\nprint(\"No. of columns : {}\".format(target.shape[1]))","0fb56a50":"target_copy = target.copy()","243260b6":"# Checking columns for all same values\n\nsame_value_cols = []\ncolwise_sum = ['colwise_sum']\nmoa_df = target_copy.iloc[:, 1:]\nfor col in moa_df.columns:\n    colwise_sum.append(moa_df[col].sum())\n    if moa_df[col].sum() == 0:\n        same_value_cols.append(col)\n        \nprint(f\"There are {len(same_value_cols)} column(s) with all values same.\")\n\n# Append the colwise_sum list as last row to our target dataframe. We will use this row later.\ntarget_copy.loc[len(target_copy)] = colwise_sum","37b06bc1":"# Checking rows for all same values\n\nmoa_df = target_copy.iloc[:-1,1:]\nrowwise_sum = moa_df.sum(axis=1)\nrowsum_zero_idx = []\nfor i, sum in enumerate(rowwise_sum):\n    if sum == 0:\n        rowsum_zero_idx.append(i)\n\nprint(f\"There are {len(rowsum_zero_idx)} drug samples having all same values i.e all zero MoA labels.\")\n\n# Append this rowwise sum to target dataframe. We will use this column later.\ntarget_copy['rowwise_sum'] = rowwise_sum","0fe78d25":"# counting the number of non-zeros\nprint(\"Total number of elements in target set : {}\".format(target.shape[0] * target.shape[1]))\nprint(\"No. of non-zero elements in target set : {}\".format(np.count_nonzero(target)))","7c2cd3b5":"target_copy = target_copy.sort_values('rowwise_sum', ascending=False)\ntemp_df = target_copy.iloc[:50,:]\nfig = px.bar(temp_df, x='sig_id', y='rowwise_sum')\nfig.show()","2cb4058a":"# Number of activations in targets for every sample","eed0b5e8":"# Initialize variables\nSEED = 42\nNFOLDS = 5\nnp.random.seed(SEED)\nROOT = '..\/input\/lish-moa\/'","0b4c69b7":"train = pd.read_csv(ROOT + 'train_features.csv')\ntargets = pd.read_csv(ROOT + 'train_targets_scored.csv')\n\ntest = pd.read_csv(ROOT + 'test_features.csv')\nsub = pd.read_csv(ROOT + 'sample_submission.csv')\n\n# drop id col\nX = train.iloc[:,1:].to_numpy()\nX_test = test.iloc[:,1:].to_numpy()\ny = targets.iloc[:,1:].to_numpy() ","982eb315":"# Build the ML Pipeline\n\nclassifier = MultiOutputClassifier(XGBClassifier(tree_method='gpu_hist'))\n\nclf = Pipeline([('encode', CountEncoder(cols=[0, 2])),\n                ('classify', classifier)\n               ])","d234a04d":"# set parameters for Pipeline classifier\n\nparams = {'classify__estimator__colsample_bytree': 0.6522,\n          'classify__estimator__gamma': 3.6975,\n          'classify__estimator__learning_rate': 0.0503,\n          'classify__estimator__max_delta_step': 2.0706,\n          'classify__estimator__max_depth': 10,\n          'classify__estimator__min_child_weight': 31.5800,\n          'classify__estimator__n_estimators': 166,\n          'classify__estimator__subsample': 0.8639\n         }\n\n_ = clf.set_params(**params)","58109945":"oof_preds = np.zeros(y.shape)\ntest_preds = np.zeros((test.shape[0], y.shape[1]))\noof_losses = []\nkf = KFold(n_splits=NFOLDS)\nfor fn, (trn_idx, val_idx) in enumerate(kf.split(X, y)):\n    print('Starting fold: ', fn)\n    X_train, X_val = X[trn_idx], X[val_idx]\n    y_train, y_val = y[trn_idx], y[val_idx]\n    \n    # drop where cp_type==ctl_vehicle (baseline)\n    ctl_mask = X_train[:,0]=='ctl_vehicle'\n    X_train = X_train[~ctl_mask,:]\n    y_train = y_train[~ctl_mask]\n    \n    clf.fit(X_train, y_train)\n    val_preds = clf.predict_proba(X_val) # list of preds per class\n    val_preds = np.array(val_preds)[:,:,1].T # take the positive class\n    oof_preds[val_idx] = val_preds\n    \n    loss = log_loss(np.ravel(y_val), np.ravel(val_preds))\n    oof_losses.append(loss)\n    preds = clf.predict_proba(X_test)\n    preds = np.array(preds)[:,:,1].T # take the positive class\n    test_preds += preds \/ NFOLDS\n    \nprint(oof_losses)\nprint('Mean OOF loss across folds', np.mean(oof_losses))\nprint('STD OOF loss across folds', np.std(oof_losses))","0f037b76":"# set control train preds to 0\ncontrol_mask = train['cp_type']=='ctl_vehicle'\noof_preds[control_mask] = 0\n\nprint('OOF log loss: ', log_loss(np.ravel(y), np.ravel(oof_preds)))","52666966":"# set control test preds to 0\ncontrol_mask = test['cp_type']=='ctl_vehicle'\ntest_preds[control_mask] = 0","e97c33b1":"# create the submission file\nsub.iloc[:,1:] = test_preds\nsub.to_csv('submission.csv', index=False)","d395851b":"# <h1 align='center'><font color = 'red'> \ud83d\udc8aMechanisms of Action (MoA) Prediction\ud83d\udc8a <\/font><\/h1>\n![](https:\/\/www.uicc.org\/sites\/main\/files\/styles\/uicc_news_main_image\/public\/iStock_PIlls_1024x.jpg?itok=0LOJZO4I)","614535c5":"<a id=\"24\"><\/a>\n## _3.4 Submission_","ed6eed89":"<a id=\"12\"><\/a>\n### _2.4.1 cp_type \/ cp_time_","5866c0b2":"<a id=\"22\"><\/a>\n## _3.2 Train model_","fceb7ff6":"# _<h1 align='center'><font color='orange'>1. Introduction<\/font><\/h1>_\n\n## _Quick Navigation_\n\n* [1. Introduction](#1)\n  * [1.1 About the Competition](#2)\n  * [1.2 Importing relevant packages](#3)\n* [2. EDA](#4)\n  * [2.1 Basic Data Overview](#5)\n  * [2.2 Categories Data Insight](#6)\n    * [2.2.1 cp_type](#7)\n    * [2.2.1 cp_time](#8)\n    * [2.2.1 cp_dose](#9)\n  * [2.3 Gene Expression and Cell Viability features](#10)\n  * [2.4 Multivariate Analysis](#11)\n    * [2.4.1 cptype \/ cp_time](#12)\n    * [2.4.2 cp_type \/ cp_dose](#13)\n    * [2.4.3 cp_time \/ cp_dose](#14)\n  * [2.5 Correlations](#15)\n    * [2.5.1 Correlation b\/w g- features](#16)\n    * [2.5.2 Correlation b\/w c- features](#17)\n    * [2.5.3 High Correlation features](#18)\n  * [2.6 Target Data Analysis](#19)\n* [3. Baseline Model](#20)\n  * [3.1 Import data](#21)\n  * [3.2 Train model](#22)\n  * [3.3 Compute log loss](#23)\n  * [3.4 Submission](#24)","1d88ab0c":"<a id=\"9\"><\/a>\n### _2.2.3 cp_dose_","d2c14d73":"<a id=\"19\"><\/a>\n### _2.6 Target Data Analysis_","dff6843e":"It is clear that our target dataframe is like a sparse matrix having a lot of zeros and only a few ones.<br><br>\nSo lets count the number of ones.","e544d751":"<a id=\"11\"><\/a>\n## _2.4 Multivariate Analysis_\n#### *Now we are going to perform analysis between :*\n- *cp_type \/ cp_time*\n- *cp_type \/ cp_dose*\n- *cp_time \/ cp_dose*","e89aaf64":"<a id=\"17\"><\/a>\n### _2.5.2 Correlation b\/w 'c-' features_","7e71b6ee":"### _2.6.1 Check rows and columns for all same values_","e3e47d9f":"<a id=\"4\"><\/a>\n# _<h1 align='center'><font color='orange'>2. EDA<\/font><\/h1>_\n\n<a id=\"5\"><\/a>\n## _2.1 Basic Data Overview_\nFirst lets see what all files our working directory contains and the data description","c48879a5":"<a id=\"10\"><\/a>\n## _2.3 Gene Expression and Cell Viability features_\n\nIn this section, we will randomly pick a few columns of gene expression(g-) and cell viability(c-) features and gain insight from them.","40dfd315":"### Files -\n- **train_features.csv** - Features for the training set. Features **g- signify gene expression** data, and **c- signify cell viability data**. cp_type indicates samples treated with a compound (cp_vehicle) or with a control perturbation (ctrl_vehicle); control perturbations have no MoAs; cp_time and cp_dose indicate treatment duration (24, 48, 72 hours) and dose (high or low).\n- **train_targets_scored.csv** - The binary MoA targets that are scored.\n- **train_targets_nonscored.csv** - Additional (optional) binary MoA responses for the training data. These are not predicted nor scored.\n- **test_features.csv** - Features for the test data. You must predict the probability of each scored MoA for each row in the test data.\n- **sample_submission.csv** - A submission file in the correct format.","0394f18e":"<a id=\"23\"><\/a>\n## _3.3 Compute log loss_","f1cfb12a":"### <font color='blue'>Thanks for reading this kernel. I hope you gained as much insights from reading it as I got from writing it. If you liked it, an UPVOTE is highly appreciated. If you are interested in more such content, feel free to follow me! ;)<\/font>","121ab254":"### _2.6.3 Top 50 - Drug samples with highest number of MoA labels under them_","c4f214da":"# Work in progress...","d872c09e":"#### This means that target set rows are having more than one non-zero value (since the number of non-zero elements is greater than no. of rows i.e 23814) indicating -> a drug sample can have more than one MoA label.<br><br>\n\n#### Lets look at :-\n- 50 drug samples having most MoA labels under them.","b6ce9392":"#### Lets now find out pairs of features with high correlation.\n\n<a id=\"18\"><\/a>\n### _2.5.3 Features with high correlations_\nHere we will use 0.9 as the threshold value to consider a correlation as a high correlation","26795e0a":"<a id=\"8\"><\/a>\n### _2.2.2 cp_time_","7e3a75e8":"<a id=\"21\"><\/a>\n## _3.1 Import data_","004f596b":"<a id=\"13\"><\/a>\n### _2.4.2 cp_type\/ cp_dose_","4ddb7bba":"<a id=\"15\"><\/a>\n## _2.5 Correlations_\nIn this section, we will look at feature correlations and see some insights :)","1d522265":"<a id=\"20\"><\/a>\n# _<h1 align='center'><font color='orange'>3.Baseline Model<\/font><\/h1>_","ba91c6a0":"### _2.6.2 Non-zero elements_","85accb8b":"<a id=\"2\"><\/a>\n## _1.1 About the Competition_\n\n\n**<font color='red'>Q. What is Mechanism of Action (MoA) of a drug ? And why is it important ?<\/font>**<br><br>\nToday, with the advent of more powerful technologies, drug discovery has changed from the serendipitous approaches of the past to a more targeted model based on an understanding of the underlying biological mechanism of a disease. In this new framework, scientists seek to identify a protein target associated with a disease and develop a molecule that can modulate that protein target. As a shorthand to describe the biological activity of a given molecule, scientists assign a label referred to as mechanism-of-action or MoA for short.\n\n**<font color='red'>Q. How do we determine the MoAs of a new drug?<\/font>**<br><br>\nIn this competition, you will have access to a unique dataset that combines gene expression and cell viability data. The data is based on a new technology that measures simultaneously (within the same samples) human cells\u2019 responses to drugs in a pool of 100 different cell types (thus solving the problem of identifying ex-ante, which cell types are better suited for a given drug). In addition, you will have access to MoA annotations for more than 5,000 drugs in this dataset.\n\n**<font color='red'>Q.How to evaluate the accuracy of a solution?<\/font>**<br><br>\nBased on the MoA annotations, the accuracy of solutions will be evaluated on the average value of the logarithmic loss function applied to each drug-MoA annotation pair.\n\nTo know more about evaluation metric , [click here](https:\/\/www.kaggle.com\/c\/lish-moa\/overview\/evaluation)","c07f88da":"<a id=\"6\"><\/a>\n## _2.2 Categories Data Insight_\n<a id=\"7\"><\/a>\n### _2.2.1 cp_type_","6ffad341":"<a id=\"16\"><\/a>\n### _2.5.1 Correlation b\/w 'g-' features_","fe6ff801":"<a id=\"3\"><\/a>\n## _1.2 Importing relevant packages_","dd944b8c":"### ***It is good to see that both g- and c- features are normally distributed with some features having skewness.<br>(OUTLIERS ALERT!)***","35231fbb":"<a id=\"14\"><\/a>\n### _2.4.3 cp_time\/ cp_dose_"}}