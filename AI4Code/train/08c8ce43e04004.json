{"cell_type":{"704a0f3f":"code","835fb70d":"code","67f54f40":"code","7bc213cc":"code","069ac0f3":"code","7ee4d9cf":"code","d120287a":"code","59c92b8e":"code","2cf8df94":"code","61fd38c8":"code","cb827a40":"code","49fcd6e0":"code","db0df543":"code","8e253008":"code","cd0ebe18":"code","802f528e":"code","0cb73630":"code","e1aa1049":"code","d84236c5":"code","284aa829":"code","f51ec24d":"code","6832bf77":"code","ffb1584d":"code","6d6a24b5":"code","0fa4b2bd":"code","7ffd61bc":"code","81dcb9d5":"code","fac34b79":"code","cdc45d44":"code","fa3459c1":"code","fce741dd":"code","b84157e4":"code","a6ae1b3d":"code","6f9f73dd":"code","78e91b8e":"code","d53c9894":"code","f5fdcb43":"code","622f6fdd":"markdown","7354c8b6":"markdown","bab7b683":"markdown","1f026f69":"markdown","f033b6de":"markdown","568ae5c4":"markdown","74cd1693":"markdown","090f1bf9":"markdown","15b60564":"markdown","a09aff22":"markdown","0d59e603":"markdown","642d70f8":"markdown","6651cdb3":"markdown"},"source":{"704a0f3f":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn import linear_model\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.ensemble import RandomForestRegressor\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n    ","835fb70d":"# Read train data\ntrain = pd.read_csv('\/kaggle\/input\/black-friday\/train.csv')\n\n# Read test data\ntest = pd.read_csv('\/kaggle\/input\/black-friday\/test.csv')","67f54f40":"train.head()","7bc213cc":"train.shape","069ac0f3":"train.info()","7ee4d9cf":"train.isnull().sum()","d120287a":"train.dtypes","59c92b8e":"train.describe()","2cf8df94":"test.head()","61fd38c8":"test.shape","cb827a40":"test.info()","49fcd6e0":"def missing(df):\n    missing_values=df.isnull().sum()\n    missing_percentage=missing_values*100\/len(df['User_ID'])\n    missing_percentage=missing_percentage.sort_values(ascending=False)\n    return missing_percentage","db0df543":"missing(train)","8e253008":"missing(test)","cd0ebe18":"train['Age'].value_counts()","802f528e":"plt.figure(figsize=(10,5))\nsns.countplot(train['Age'])","0cb73630":"plt.figure(figsize=(10,5))\nsns.countplot(train['City_Category'])","e1aa1049":"plt.figure(figsize=(10,5))\nsns.countplot(train['Stay_In_Current_City_Years'])","d84236c5":"train['Occupation'].unique()","284aa829":"train['City_Category'].unique()","f51ec24d":"train['Stay_In_Current_City_Years'].unique()","6832bf77":"print(train['Product_Category_1'].unique())\nprint(train['Product_Category_2'].unique())\nprint(train['Product_Category_3'].unique())","ffb1584d":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import LabelEncoder\ntrain['User_ID'] = train['User_ID'] - 1000000\ntest['User_ID'] = test['User_ID'] - 1000000\n\nenc = LabelEncoder()\ntrain['User_ID'] = enc.fit_transform(train['User_ID'])\ntest['User_ID'] = enc.transform(test['User_ID'])","6d6a24b5":"train['Product_ID'] = train['Product_ID'].str.replace('P00', '')\ntest['Product_ID'] = test['Product_ID'].str.replace('P00', '')\n\nscaler = StandardScaler()\ntrain['Product_ID'] = scaler.fit_transform(train['Product_ID'].values.reshape(-1, 1))\ntest['Product_ID'] = scaler.transform(test['Product_ID'].values.reshape(-1, 1))","0fa4b2bd":"categorical_col = ['Gender', 'City_Category']\nnumerical_col = ['Age', 'Occupation', 'Stay_In_Current_City_Years', 'Product_Category_1', \n           'Product_Category_2', 'Product_Category_3']","7ffd61bc":"train['Age']=train['Age'].replace('0-17',17)\ntrain['Age']=train['Age'].replace('18-25',25)\ntrain['Age']=train['Age'].replace('26-35',35)\ntrain['Age']=train['Age'].replace('36-45',45)\ntrain['Age']=train['Age'].replace('46-50',50)\ntrain['Age']=train['Age'].replace('51-55',55)\ntrain['Age']=train['Age'].replace('55+',60)","81dcb9d5":"test['Age']=test['Age'].replace('0-17',17)\ntest['Age']=test['Age'].replace('18-25',25)\ntest['Age']=test['Age'].replace('26-35',35)\ntest['Age']=test['Age'].replace('36-45',45)\ntest['Age']=test['Age'].replace('46-50',50)\ntest['Age']=test['Age'].replace('51-55',55)\ntest['Age']=test['Age'].replace('55+',60)","fac34b79":"train['Stay_In_Current_City_Years']=train['Stay_In_Current_City_Years'].replace('4+',4)\ntest['Stay_In_Current_City_Years']=test['Stay_In_Current_City_Years'].replace('4+',4)","cdc45d44":"train = train.fillna(0)\ntest = test.fillna(0)","fa3459c1":"# Encoding categorical columns\n\nencoder = LabelEncoder()\n\nfor col in categorical_col:\n    train[col] = encoder.fit_transform(train[col])\n    test[col] = encoder.transform(test[col])","fce741dd":"# Scaling numerical columns\n\nscaler = StandardScaler()\n\nfor col in numerical_col:\n    train[col] = scaler.fit_transform(train[col].values.reshape(-1, 1))\n    test[col] = scaler.transform(test[col].values.reshape(-1, 1))","b84157e4":"train.head()","a6ae1b3d":"X = train.drop(['Purchase'], axis=1)\ny = train[['Purchase']]\nX_test = test\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=42, shuffle=True)","6f9f73dd":"reg=linear_model.LinearRegression()\nlm_model=reg.fit(X_train,y_train)\npred=lm_model.predict(X_val)","78e91b8e":"np.sqrt(mean_squared_error(y_val,pred))","d53c9894":"xgb_reg = XGBRegressor(learning_rate=1.0, max_depth=6, min_child_weight=40, seed=0)\n\nxgb_reg.fit(X_train, y_train)\ny_pred = xgb_reg.predict(X_val)\nrmse = np.sqrt(mean_squared_error(y_pred, y_val))\n\nprint (xgb_reg)","f5fdcb43":"rmse","622f6fdd":"# If you find the kernel useful, upvote it :)","7354c8b6":"**Filling missing values with zero**","bab7b683":"# 2.Xg Boost","1f026f69":"# Encoding","f033b6de":"# EDA","568ae5c4":"**Choose xgboost over linear regression due to less RMSE **","74cd1693":"# Pre-processing****","090f1bf9":"# Importing libraries","15b60564":"**Having alook at test data**","a09aff22":"**Missing values**","0d59e603":"# 1.LinearRegression","642d70f8":"# Training the model","6651cdb3":"**Having a look at train data**"}}