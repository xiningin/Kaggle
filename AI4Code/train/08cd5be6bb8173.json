{"cell_type":{"41e6d4a4":"code","78788566":"code","7db3efeb":"code","39d7a2d9":"code","888c5085":"code","1724d7cd":"code","840c711d":"code","5a57a33b":"code","4c7da970":"code","824070e5":"code","be8dc025":"code","e65aec69":"code","6bc5ca06":"code","02f7bb5e":"code","05c59a73":"code","deadab88":"code","aceb41ae":"code","2c43dc17":"code","c676e5a5":"code","8b51631a":"code","64ce9182":"code","29a175fa":"code","71666a26":"code","0b00b216":"code","1c780636":"code","6a05b1d8":"code","679d20c7":"code","23fba8f2":"code","c875216c":"markdown","895119d6":"markdown"},"source":{"41e6d4a4":"\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nfrom fastai import *\nfrom fastai.vision import *\nfrom torchvision.models import *\n","78788566":"# path = '..\/input\/jovian-pytorch-z2g\/Human protein atlas\/train.csv'\n\npath = '..\/input\/jovian-pytorch-z2g\/Human protein atlas\/'","7db3efeb":"transforms = get_transforms(do_flip = True,flip_vert = True,\n                            max_rotate = 10.0,max_zoom = 1.1,\n                            max_lighting = 0.2,max_warp = 0.2,\n                            p_lighting = 0.75)\n","39d7a2d9":"# transforms = get_transforms","888c5085":"# ImageDataBunch.from_csv??","1724d7cd":"np.random.seed(42) # set random seed so we always get the same validation set\ndata = ImageDataBunch.from_csv(path,folder = 'train', suffix='.png',csv_labels = 'train.csv',\n                              label_delim = ' ',bs = 8)","840c711d":"data.x[0].shape","5a57a33b":"len(data.train_ds.x) \/ 8","4c7da970":"\ndata.show_batch(rows=3, figsize=(12, 9))","824070e5":"def F_score(output, label, threshold=0.2, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-12))\n    recall = torch.mean(TP \/ (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)","be8dc025":"\nlearn = cnn_learner(data, models.resnet50,metrics = [F_score])","e65aec69":"learn.fit_one_cycle(20)\n","6bc5ca06":"# learn.fit(2,lr = 3e-4)","02f7bb5e":"# learn.one_cycle_scheduler\n\npreds,y,losses = learn.get_preds(with_loss=True)\n\ninterp = ClassificationInterpretation(learn,preds,y,losses)\n\n","05c59a73":"interp.plot_multi_top_losses()","deadab88":"def decode_target(target, text_labels=False, threshold=0.5):\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)","aceb41ae":"import gc \ngc.collect()","2c43dc17":"# import pandas as pd","c676e5a5":"subs = pd.read_csv('..\/input\/jovian-pytorch-z2g\/submission.csv')\n\ntest = '..\/input\/jovian-pytorch-z2g\/Human protein atlas\/test'\n\nfrom tqdm import tqdm\n\n\npreds =  []\nfor i in tqdm(subs['Image']):\n    \n    img = open_image(test + '\/' + str(i) + '.png')\n    \n    \n    preds.append(learn.predict(img)[2])\n        ","8b51631a":"import gc\ngc.collect()","64ce9182":"preds[0:2]","29a175fa":"final_preds = [decode_target(i) for i in preds]","71666a26":"final_preds","0b00b216":"subs.head()","1c780636":"subs['Label']  = final_preds","6a05b1d8":"subs.to_csv('sub_7.csv',index = False)","679d20c7":"subs","23fba8f2":"#intepreter\n\n","c875216c":"# Test Data","895119d6":"### Hi everyone !! This is a super quick implementation using fastai.\n\n1. I am using Resnet50 which has got me an F1 score of about 68% training time per epoch is abt 6min\n\n2. Earlier I has tried resnet 34 which had god me an score of 64% training time was 4min\n\n\nnote : all the above experiments were done for 5 epochs becz it takes long for the model to run.\n\nI have not applied any transforms here as this requires a lot of experimentation.\nresults of the transformers will be updated bu tomorrow.\n\n"}}