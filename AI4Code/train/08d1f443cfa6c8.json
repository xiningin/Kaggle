{"cell_type":{"6cfa1955":"code","c881adbe":"code","0350506c":"code","3589bec4":"code","388c7792":"code","aa430823":"code","eeee2934":"code","3c9c9449":"code","f612a5bc":"code","3d7e315f":"code","a3232bda":"code","973a3b04":"code","a68e7581":"code","16f121af":"code","cae1125d":"markdown","3f6edc45":"markdown","d48e1c1b":"markdown","af22e1ae":"markdown","100f3f81":"markdown"},"source":{"6cfa1955":"import os\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n!pip install opencv-contrib-python\nimport cv2\nprint(os.listdir(\"..\/input\"))\nimport matplotlib.pyplot as plt\n%matplotlib inline ","c881adbe":"train_dir = '..\/input\/train_images'\ntrain_imgs = ['..\/input\/train_images\/{}'.format(i) for i in os.listdir(train_dir)]","0350506c":"num_show = 15\ncolumns = 5","3589bec4":"plt.figure(figsize=(25,12))\nfor idx, train_img in enumerate(train_imgs):\n    if idx >= num_show:\n        break\n    \n    temp_img = cv2.imread(train_img, cv2.IMREAD_COLOR)\n    \n    plt.subplot(10 \/ columns + 1, columns, idx + 1)\n    plt.imshow(temp_img)\n    if idx % 5 == 4:\n        plt.show()\n        plt.figure(figsize=(25,12))","388c7792":"clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(16, 16))","aa430823":"plt.figure(figsize=(25,12))\nfor idx, train_img in enumerate(train_imgs):\n    if idx >= num_show:\n        break\n    \n    temp_img = cv2.imread(train_img, cv2.IMREAD_COLOR)        \n    img_lab = cv2.cvtColor(temp_img, cv2.COLOR_BGR2Lab)\n\n    l, a, b = cv2.split(img_lab)\n    img_l = clahe.apply(l)\n    img_clahe = cv2.merge((img_l, a, b))\n\n    img_clahe = cv2.cvtColor(img_clahe, cv2.COLOR_Lab2BGR)\n    \n    plt.subplot(10 \/ columns + 1, columns, idx + 1)\n    plt.imshow(img_clahe)\n    if idx % 5 == 4:\n        plt.show()\n        plt.figure(figsize=(25,12))","eeee2934":"wb = cv2.xphoto.createSimpleWB()\nwb.setP(0.4)","3c9c9449":"plt.figure(figsize=(25,12))\nfor idx, train_img in enumerate(train_imgs):\n    if idx >= num_show:\n        break\n    \n    temp_img = cv2.imread(train_img, cv2.IMREAD_COLOR)        \n    \n    img_wb = wb.balanceWhite(temp_img)\n    \n    plt.subplot(10 \/ columns + 1, columns, idx + 1)\n    plt.imshow(img_wb)\n    if idx % 5 == 4:\n        plt.show()\n        plt.figure(figsize=(25,12))","f612a5bc":"wb2 = cv2.xphoto.createGrayworldWB()\nwb2.setSaturationThreshold(0.90)","3d7e315f":"plt.figure(figsize=(25,12))\nfor idx, train_img in enumerate(train_imgs):\n    if idx >= num_show:\n        break\n    \n    temp_img = cv2.imread(train_img, cv2.IMREAD_COLOR)        \n    \n    img_wb = wb2.balanceWhite(temp_img)\n    \n    plt.subplot(10 \/ columns + 1, columns, idx + 1)\n    plt.imshow(img_wb)\n    if idx % 5 == 4:\n        plt.show()\n        plt.figure(figsize=(25,12))","a3232bda":"wb3 = cv2.xphoto.createLearningBasedWB()\nwb3.setSaturationThreshold(0.99)","973a3b04":"plt.figure(figsize=(25,12))\nfor idx, train_img in enumerate(train_imgs):\n    if idx >= num_show:\n        break\n    \n    temp_img = cv2.imread(train_img, cv2.IMREAD_COLOR)        \n    \n    img_wb = wb3.balanceWhite(temp_img)\n    \n    plt.subplot(10 \/ columns + 1, columns, idx + 1)\n    plt.imshow(img_wb)\n    if idx % 5 == 4:\n        plt.show()\n        plt.figure(figsize=(25,12))","a68e7581":"plt.figure(figsize=(25,12))\nfor idx, train_img in enumerate(train_imgs):\n    if idx >= num_show:\n        break\n    \n    temp_img = cv2.imread(train_img, cv2.IMREAD_COLOR)        \n    \n    img_wb = wb.balanceWhite(temp_img)\n\n    img_lab = cv2.cvtColor(img_wb, cv2.COLOR_BGR2Lab)\n\n    l, a, b = cv2.split(img_lab)\n    res_l = clahe.apply(l)\n    res = cv2.merge((res_l, a, b))\n\n    res = cv2.cvtColor(res, cv2.COLOR_Lab2BGR)\n\n    plt.subplot(10 \/ columns + 1, columns, idx + 1)\n    plt.imshow(res)\n    if idx % 5 == 4:\n        plt.show()\n        plt.figure(figsize=(25,12))","16f121af":"fig=plt.figure(figsize=(32, 128))\nfor idx, train_img in enumerate(train_imgs):\n    if idx >= num_show:\n        break\n    \n    temp_img = cv2.imread(train_img, cv2.IMREAD_COLOR)        \n    \n    img_wb = wb.balanceWhite(temp_img)\n\n    img_lab = cv2.cvtColor(img_wb, cv2.COLOR_BGR2Lab)\n\n    l, a, b = cv2.split(img_lab)\n    res_l = clahe.apply(l)\n    res = cv2.merge((res_l, a, b))\n\n    res = cv2.cvtColor(res, cv2.COLOR_Lab2BGR)\n    fig.add_subplot(15, 2, 2 * idx + 1)\n    plt.imshow(temp_img)\n    fig.add_subplot(15, 2, 2 * idx + 2)\n    plt.imshow(res)\nplt.show()","cae1125d":"# Automatic White Balance\n- Simple\n- Grayworld\n- Learning-based\n\nTheses require __xphoto__ in 'opencv-contrib-python'","3f6edc45":"# CLAHE(Contrast Limited Adaptive Histogram Equalization)\nref: https:\/\/docs.opencv.org\/3.1.0\/d5\/daf\/tutorial_py_histogram_equalization.html","d48e1c1b":"# Compare Original and Pre-processed with CLAHE & SimpleWB","af22e1ae":"# CLAHE & Simple WB","100f3f81":"# To Do\n- Vignetting Correction"}}