{"cell_type":{"8d3389d7":"code","d25ec867":"code","1027b479":"code","8ba6c5bc":"code","81bcb75f":"code","3da162fa":"code","159a8e7d":"code","2abb42df":"code","c3696666":"code","b579a8d7":"code","3dc0e2b9":"code","82d90df9":"code","88db0588":"code","9fec4566":"code","67bf5403":"code","397f0b22":"code","d199cd4b":"code","89ac3f49":"code","b2ebfdd7":"code","3e8e01bf":"code","1f216ab3":"code","392503c2":"code","d028c62e":"code","04021585":"code","8bd45288":"code","de9e0282":"code","1ee3852e":"code","5d1a961f":"code","d1c12ce8":"code","b605e23e":"code","b6d41dbb":"code","74356aa1":"code","55dc2866":"code","15114e15":"code","2edf656c":"code","fdc6c564":"code","12cde96e":"code","a9ef85b1":"code","b11fe8d3":"code","3183e7fb":"code","b0b8da09":"code","0aa1f985":"code","72f53403":"code","6047d775":"code","59eefc84":"code","dd9e8053":"code","9641f794":"markdown","96e538de":"markdown","e8dc8c61":"markdown","71ef5f8a":"markdown","db02b46a":"markdown","e27ba180":"markdown","e15b7698":"markdown","c90559c1":"markdown","886d9c57":"markdown","89ed51a8":"markdown","96b5861e":"markdown","21a8ad3a":"markdown","49f4fb8d":"markdown","d7f51a62":"markdown","b411bcb5":"markdown","d7b31960":"markdown","cf216a07":"markdown","a957b124":"markdown","29398d70":"markdown","431a8ea8":"markdown","200ce4e6":"markdown","2f2717a3":"markdown","060a91af":"markdown","96dc965f":"markdown","8689af39":"markdown","8260d22f":"markdown","d0587e6e":"markdown","d01abc3b":"markdown","4249d736":"markdown","3a2a7b45":"markdown","b0d067d2":"markdown","d5b71853":"markdown","10c5dc01":"markdown","eded2340":"markdown"},"source":{"8d3389d7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np     \nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport sklearn\nimport statsmodels as stats\nfrom sklearn import preprocessing\nfrom sklearn.model_selection import train_test_split \nfrom sklearn.preprocessing import StandardScaler \n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d25ec867":"df = pd.read_csv(\"\/kaggle\/input\/pima-indians-diabetes-database\/diabetes.csv\")\ndf.head()  #load the data","1027b479":"df.dtypes   #the dataset contains continuous\/ numeric data","8ba6c5bc":"df.columns.tolist()  #column list of the dataframe","81bcb75f":"df.info","3da162fa":"df.isnull().any() #checking null values","159a8e7d":"df.isna().any()  #checking NaN\/ missing values","2abb42df":"df.describe() #shows more informations with statistical data","c3696666":"df.hist(figsize=(20,15))","b579a8d7":"sns.countplot(df[\"Pregnancies\"], hue = df[\"Outcome\"])\nplt.title('Number of Pregnancies vs Outcome')","3dc0e2b9":"plt.figure(figsize = (10,10))\nsns.histplot(x =\"Pregnancies\", hue = \"Outcome\",data=df, kde = True,palette=\"ch:s=.25,rot=-.25\")","82d90df9":"sns.countplot(df[\"Glucose\"], hue = df[\"Outcome\"])\nplt.title('Number of Glucose vs Outcome')","88db0588":"plt.figure(figsize = (10,10))\nsns.histplot(x =\"Glucose\", hue = \"Outcome\",data=df, kde = True,palette = \"dark\")","9fec4566":"plt.figure(figsize = (10,10))\nsns.histplot(x =\"BloodPressure\", hue = \"Outcome\",data=df, kde = True,palette = \"flare\")","67bf5403":"plt.figure(figsize = (10,10))\nsns.histplot(x =\"SkinThickness\", hue = \"Outcome\",data=df, kde = True,palette=\"dark\")","397f0b22":"plt.figure(figsize = (10,10))\nsns.histplot(x =\"Insulin\", hue = \"Outcome\",data=df, kde = True, palette=\"dark\")","d199cd4b":"plt.figure(figsize = (10,10))\nsns.histplot(x =\"BMI\", hue = \"Outcome\",data=df, kde = True, palette=\"dark\")","89ac3f49":"plt.figure(figsize = (10,10))\nsns.histplot(x =\"Age\", hue = \"Outcome\",data=df, kde = True,palette=\"Set1\")","b2ebfdd7":"sns.scatterplot(data=df, x=\"Age\", y=\"BloodPressure\",hue = \"Outcome\")","3e8e01bf":"sns.lmplot(data=df, x=\"Age\", y=\"BloodPressure\",hue = \"Outcome\",palette=\"Set2\",col = \"Outcome\")","1f216ab3":"sns.scatterplot(data=df, x=\"Age\", y=\"Glucose\",hue = \"Outcome\")","392503c2":"sns.lmplot(data=df, x=\"Age\", y=\"Glucose\",hue = \"Outcome\",palette=\"Set1\")","d028c62e":"sns.scatterplot(data=df, x=\"Age\", y=\"SkinThickness\",hue = \"Outcome\")","04021585":"sns.lmplot(data=df, x=\"Age\", y=\"SkinThickness\",hue = \"Outcome\",palette=\"Set1\")","8bd45288":"plt.figure(figsize=(20,20))\nsns.set_theme(style=\"darkgrid\")\nsns.pairplot(df,hue =\"Outcome\", height=7)","de9e0282":"corrmat = df.corr()\ncmap = sns.diverging_palette(260,-10,s=50, l=75, n=6, as_cmap=True)\nplt.subplots(figsize=(20,10))\nsns.heatmap(corrmat,cmap= cmap, annot=True, square=True)","1ee3852e":"df['AgeBP'] = df['Age'] + df['BloodPressure']\ndf['AgeGL'] = df['Age'] + df['Glucose']\ndf['AgeTH'] = df['Age'] + df['SkinThickness']\n\ndf","5d1a961f":"df = df.drop(['Age', 'BloodPressure', 'SkinThickness', 'Glucose'], axis=1)\ndf","d1c12ce8":"a1 = sns.boxplot(x=df['Pregnancies']) ","b605e23e":"a2 = sns.boxplot(x=df['Insulin'])","b6d41dbb":"a3 = sns.boxplot(x=df['DiabetesPedigreeFunction'])","74356aa1":"a4 = sns.boxplot(x=df['AgeBP'])","55dc2866":"a5 = sns.boxplot(x=df['AgeGL'])","15114e15":"a6 = sns.boxplot(x=df['AgeTH'])","2edf656c":"plt.figure(figsize=(10,10))\nsns.heatmap(np.abs(df.corr()),annot=True,cmap='viridis_r',fmt=\"0.2f\")","fdc6c564":"X = df.drop([\"Outcome\"],axis=1)\ny = df[\"Outcome\"]","12cde96e":"X","a9ef85b1":"y","b11fe8d3":"from sklearn.model_selection import train_test_split     #data splitting\nX_train, X_test, y_train, y_test = train_test_split(X,y, test_size=0.2, random_state=20)","3183e7fb":"from sklearn.preprocessing import StandardScaler  \nscaler = StandardScaler()  \nscaler.fit(X_train)  \nX_train = scaler.transform(X_train)  \n# apply same transformation to test data\nX_test = scaler.transform(X_test)","b0b8da09":"df","0aa1f985":"from sklearn.metrics import accuracy_score,confusion_matrix\nfrom sklearn.linear_model import LogisticRegression\nlr = LogisticRegression(random_state=21).fit(X_train, y_train)\nlr.score(X_test, y_test)\n\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,lr.predict(X_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,lr.predict(X_test))*100))","72f53403":"from sklearn.ensemble import RandomForestClassifier\nRF=RandomForestClassifier(n_estimators=150, max_depth=25, random_state=25)\nRF.fit(X_train,y_train)\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,RF.predict(X_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,RF.predict(X_test))*100))","6047d775":"from sklearn.svm import SVC\nsvm=SVC()\nsvm.fit(X_train,y_train)\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,svm.predict(X_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,svm.predict(X_test))*100))","59eefc84":"from sklearn.tree import DecisionTreeClassifier\nDTC= DecisionTreeClassifier(criterion='entropy',max_depth=25)\nDTC.fit(X_train,y_train)\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,DTC.predict(X_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,DTC.predict(X_test))*100))","dd9e8053":"from sklearn.ensemble import GradientBoostingClassifier\nGD=GradientBoostingClassifier(max_depth=15)\nGD.fit(X_train,y_train)\n\nprint(\"Train Set Accuracy:\"+str(accuracy_score(y_train,GD.predict(X_train))*100))\nprint(\"Test Set Accuracy:\"+str(accuracy_score(y_test,GD.predict(X_test))*100))","9641f794":"#### Dropping unnecesary columns","96e538de":"#### column list of the dataframe","e8dc8c61":"### Univariate Analysis: Measures of the Central tendency and the Dispersion","71ef5f8a":"## Bivariate Analysis : Finding relationship between two independent variables","db02b46a":"## Exploratory Data Analysis & Data Cleaning","e27ba180":"#### **checking the datatypes**","e15b7698":"#### Number of Pregnancies vs Outcome","c90559c1":"To overcome **Multi colinearity** dependent variables among the independent variables, adding those columns and updating dataframe by adding them. ","886d9c57":"### Correlation Map","89ed51a8":"#### SkinThickness vs Outcome","96b5861e":"#### Age and Glucose Level","21a8ad3a":"##### Glucose vs Outcome","49f4fb8d":"## Feature Engineering","d7f51a62":"## Suport Vector Classifier","b411bcb5":"**Accuracy results of different models on train and test dataset**","d7b31960":"#### Recheck Correlation","cf216a07":"## Outliers Detection \n\nno outliers","a957b124":"### Data Splitting","29398d70":"## Decision Tree Classifier","431a8ea8":"## Logistic Regression","200ce4e6":"#### Age and Skin thickness","2f2717a3":"#### Age vs Outcome","060a91af":"#### Checking Multicolinearity","96dc965f":"#### Checking null and missing values","8689af39":"#### BMI vs Outcome","8260d22f":"#### BloodPressure vs Outcome","d0587e6e":"### Feature Scaling : Standardization","d01abc3b":"## Gradient Boosting Classifier","4249d736":"### Random Forest Classifier","3a2a7b45":"#### Age & Bloodpressure","b0d067d2":"#### Insulin vs Outcome","d5b71853":"Multicolinearity: \n    when an independent variable can be predicted from another independent variable. Here visualization is done with scatterplots and implots. & to show the strength of the rrelationships among the variables, Correlation Map will be plotted.\n\nHere, Bloodpressure is depdendent on Age variable, Similarly, Glocose level and Skin thickness depends on age","10c5dc01":"#### Pairplot","eded2340":"### Count plot & Histograms "}}