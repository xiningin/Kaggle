{"cell_type":{"f5b5d94f":"code","cf5dcf22":"code","adecefcf":"code","82376213":"code","5b7cfec1":"code","8644e2b6":"code","fb38447d":"code","5faa36ad":"code","4fd678f2":"code","4526bfd9":"code","9bd51f7e":"code","a8819441":"code","d6845398":"code","cc8c1add":"code","da687236":"code","4dac1e3f":"code","3c1a2e28":"code","08eb34ed":"code","bd6e9633":"code","67d91f75":"code","378ffa31":"code","2452588d":"code","d7c7fa97":"code","5e7118b6":"code","cf1f264b":"code","cd02653a":"code","69ce2c94":"code","0b140177":"code","19d63677":"code","2f7f3620":"code","58e2b5cd":"code","0163c409":"code","d387a038":"code","8bd96805":"code","9c2ac119":"code","bfec9038":"code","9f8a3505":"code","cb540f2a":"code","9a4d4abf":"code","6f97838f":"code","1a4fa666":"code","046ccdc9":"code","acede9b2":"code","9df6a1ec":"code","6aa591b9":"code","da4bee08":"code","a680c848":"code","aeeb20ba":"code","ec591ee8":"code","276caf9f":"code","e97e6955":"code","3eb79e0f":"code","4297ed2f":"code","9a5eccde":"code","25a0951a":"code","39492bc7":"code","a11a1529":"code","4ba40dcd":"code","3bd914cc":"code","7ce20baa":"code","4024f55e":"code","8298afac":"code","748f1979":"code","a482df52":"code","1346beae":"code","15990135":"code","2e5f9f08":"code","aace72cd":"code","72cdc25d":"code","8710659e":"code","22c1c425":"code","f844022e":"code","aec25425":"code","8a3f6422":"code","01c45e3e":"code","589293fa":"code","3ffb1994":"code","953ac0b8":"code","ca3cb143":"code","b2229a16":"code","24f52481":"code","f3f8fee7":"code","4d32daf2":"code","82ecff12":"code","206571ea":"code","f8616e88":"code","919368b5":"code","f81f27fd":"code","497cb7d4":"code","6801a337":"code","3aa7da67":"code","148bf684":"code","f120f505":"markdown","c99ba9a1":"markdown","5541e8f3":"markdown","7da5c3e4":"markdown","2177fc1d":"markdown"},"source":{"f5b5d94f":"import numpy as np\nimport pandas as pd\nprint('numpy@' + np.__version__ + '\\n' + 'pydata.pandas@' + pd.__version__)","cf5dcf22":"!ls ..\/input\/","adecefcf":"train_df = pd.read_csv('\/kaggle\/input\/ciphertext-challenge-iii\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/ciphertext-challenge-iii\/test.csv')\nsample_sub_df = pd.read_csv('\/kaggle\/input\/ciphertext-challenge-iii\/sample_submission.csv')","82376213":"# Make some room \npd.set_option('display.max_colwidth',122)","5b7cfec1":"train_df.iloc[:50,:]","8644e2b6":"test_df.head(10)","fb38447d":"sample_sub_df.head()","5faa36ad":"sample_sub_df.loc[sample_sub_df['ciphertext_id'] == 'ID_55f57ffd0',:]","4fd678f2":"train_df.shape, test_df.shape","4526bfd9":"train_df.plaintext_id.nunique()","9bd51f7e":"train_df.index.nunique()","a8819441":"test_df.ciphertext_id.nunique()","d6845398":"sample_sub_df.iloc[0,0] in train_df.plaintext_id","cc8c1add":"test_df.iloc[0,0] in train_df.plaintext_id","da687236":"sample_sub_df.loc[0,'ciphertext_id'] in test_df.ciphertext_id ","4dac1e3f":"train_df.info()","3c1a2e28":"train_df.loc[train_df['index'] == 0, :]","08eb34ed":"train_df.iloc[0,1]","bd6e9633":"train_df.insert(1,'length_plaintext_id',train_df['plaintext_id'].apply(lambda i: len(i)-3),allow_duplicates=True)\ntrain_df.insert(3,'length_plaintext',train_df['text'].apply(len),allow_duplicates=True)","67d91f75":"train_df.iloc[:12,:]","378ffa31":"train_df['length_plaintext_id'].unique()","2452588d":"test_df.insert(1,'length_ciphertext_id',test_df['ciphertext_id'].apply(lambda i: len(i)-3),allow_duplicates=True)\ntest_df.insert(3,'length_ciphertext',test_df['ciphertext'].apply(len),allow_duplicates=True)","d7c7fa97":"test_df.iloc[:24,:]","5e7118b6":"test_df['length_ciphertext_id'].unique()","cf1f264b":"bytes('\u2206PQR',encoding='utf-8')","cd02653a":"bytearray(train_df.iloc[7,2],encoding='utf-8')","69ce2c94":"[ch for ix,ch in enumerate('\u00a92019')]","0b140177":"# Series vars\nplaintext_unicode_pts = train_df['text'].apply(lambda string: [ord(ch) for i,ch in enumerate(string)])\nciphertext_unicode_pts = test_df['ciphertext'].apply(lambda string: [ord(ch) for i,ch in enumerate(string)])","19d63677":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\n%matplotlib inline\nsns.set_style('whitegrid')","2f7f3620":"def padws(tx):\n    while len(tx) % 100 != 0: \n        tx += ' '\n    \n    return tx\n\ntrain_df['text'].apply(padws).head()","58e2b5cd":"train_df.insert(4,\n               'pad_plaintext',\n               train_df['text'].apply(padws),\n               allow_duplicates=True)\n\ntrain_df.insert(5,\n               'pad_length_plaintext',\n               train_df['length_plaintext'].apply(lambda l: (((l\/\/100)+1)*100) if l%100 != 0 else l),\n               allow_duplicates=True)\n\ntrain_df.head()","0163c409":"test_df.insert(4,\n               'pad_length_ciphertext',\n               test_df['length_ciphertext'].apply(lambda l: (((l\/\/100)+1)*100) if l%100 != 0 else l),\n               allow_duplicates=True)\ntest_df['pad_length_ciphertext'].head()","d387a038":"np.arange(0, 8000, 500)","8bd96805":"f, ax = plt.subplots(nrows=3,ncols=1,figsize=(24, 32))\n\nax[0].set_title(\"Freq. distribution of length_plaintext\", fontdict={\"fontsize\": 18})\nsns.distplot(train_df['length_plaintext'],\n             rug=True,\n             kde_kws={\n                 \"color\": \"blue\",\n                 \"lw\": 2,\n                 \"label\": \"KDE\"\n             },\n             hist_kws={\n                 \"histtype\": \"bar\",\n                 \"linewidth\": 3,\n                 \"alpha\": 1,\n                 \"color\": \"lightgreen\"\n             },\n             ax=ax[0])\nax[0].set_xticklabels(labels=ax[0].get_xticks(), fontdict={\"fontsize\":18})\nax[0].set_yticklabels(labels=ax[0].get_yticks(), fontdict={\"fontsize\":18})\n\nax[1].set_title(\"Freq. distribution of length_ciphertext w\/o PADDING\", fontdict={\"fontsize\": 18}) # w\/o padding\nsns.distplot(test_df['length_ciphertext'],\n             rug=True,\n             kde_kws={\n                 \"color\": \"blue\",\n                 \"lw\": 2,\n                 \"label\": \"KDE\"\n             },\n             hist_kws={\n                 \"histtype\": \"bar\",\n                 \"linewidth\": 3,\n                 \"alpha\": 1,\n                 \"color\": \"pink\"\n             },\n             ax=ax[1])\nax[1].set_xticklabels(labels=ax[1].get_xticks(), fontdict={\"fontsize\":18})\nax[1].set_yticklabels(labels=ax[1].get_yticks(), fontdict={\"fontsize\":18})\n\nax[2].set_title(\"Freq. distribution of length_ciphertext w\/ PADDING\", fontdict={\"fontsize\": 18}) # w\/ padding\nsns.distplot(test_df['pad_length_ciphertext'],\n             rug=True,\n             kde_kws={\n                 \"color\": \"blue\",\n                 \"lw\": 2,\n                 \"label\": \"KDE\"\n             },\n             hist_kws={\n                 \"histtype\": \"bar\",\n                 \"linewidth\": 3,\n                 \"alpha\": 1,\n                 \"color\": \"pink\"\n             },\n             ax=ax[2])\nax[2].set_xticklabels(labels=ax[2].get_xticks(), fontdict={\"fontsize\":18})\nax[2].set_yticklabels(labels=ax[2].get_yticks(), fontdict={\"fontsize\":18})","9c2ac119":"# Normalized distribution of padded ciphertext length counts \ntest_df['pad_length_ciphertext'].value_counts(normalize=True)","bfec9038":"ciphertexts_cl1 = test_df.loc[test_df['difficulty'] == 1, :].copy()\nprint(ciphertexts_cl1.shape)\nciphertexts_cl1","9f8a3505":"ciphertexts_cl1['pad_length_ciphertext'].value_counts(normalize=True)","cb540f2a":"RS = np.random.RandomState(seed=1224)","9a4d4abf":"sample_cl1 = ciphertexts_cl1.sample(n=5, random_state=RS, axis=0)\nsample_cl1","6f97838f":"save = pd.Series([ch for i,ch in enumerate(sample_cl1.loc[67731, 'ciphertext'])], dtype=np.object)\nsave.value_counts()","1a4fa666":"save.value_counts().index.tolist()","046ccdc9":"def make_save(index):\n    return pd.Series([ch for i,ch in enumerate(sample_cl1.loc[index, 'ciphertext'])], dtype=np.object)\n\nsample_cl1.index.tolist()","acede9b2":"f, ax = plt.subplots(nrows=5,ncols=1,figsize=(18, 40))\n\n\nsave = make_save(67731)\nvc = save.value_counts(ascending=True).index.tolist()\nax[0].set_title(\"Freq. distribution of chars in sample\", fontdict={\"fontsize\": 18})\nsns.countplot(x=save.values.tolist(), data=save, order=vc, orient='v', palette='PuRd', saturation=0.75, dodge=True, ax=ax[0])\nax[0].set_xticklabels(labels=vc, fontdict={\"fontsize\":18})\nax[0].set_yticklabels(labels=ax[0].get_yticks(), fontdict={\"fontsize\":18})\n\nsave = make_save(8219)\nvc = save.value_counts(ascending=True).index.tolist()\nsns.countplot(x=save.values.tolist(), data=save, order=vc, orient='v', palette='PuRd', saturation=0.75, dodge=True, ax=ax[1])\nax[1].set_xticklabels(labels=vc, fontdict={\"fontsize\":18})\nax[1].set_yticklabels(labels=ax[1].get_yticks(), fontdict={\"fontsize\":18})\n\nsave = make_save(44956)\nvc = save.value_counts(ascending=True).index.tolist()\nsns.countplot(x=save.values.tolist(), data=save, order=vc, orient='v', palette='PuRd', saturation=0.75, dodge=True, ax=ax[2])\nax[2].set_xticklabels(labels=vc, fontdict={\"fontsize\":18})\nax[2].set_yticklabels(labels=ax[2].get_yticks(), fontdict={\"fontsize\":18})\n\nsave = make_save(25629)\nvc = save.value_counts(ascending=True).index.tolist()\nsns.countplot(x=save.values.tolist(), data=save, order=vc, orient='v', palette='PuRd', saturation=0.75, dodge=True, ax=ax[3])\nax[3].set_xticklabels(labels=vc, fontdict={\"fontsize\":18})\nax[3].set_yticklabels(labels=ax[3].get_yticks(), fontdict={\"fontsize\":18})\n\nsave = make_save(107305)\nvc = save.value_counts(ascending=True).index.tolist()\nsns.countplot(x=save.values.tolist(), data=save, order=vc, orient='v', palette='PuRd', saturation=0.75, dodge=True, ax=ax[4])\nax[4].set_xticklabels(labels=vc, fontdict={\"fontsize\":18})\nax[4].set_yticklabels(labels=ax[4].get_yticks(), fontdict={\"fontsize\":18})","9df6a1ec":"ax","6aa591b9":"string = sample_cl1.loc[67731, 'ciphertext']\nstring","da4bee08":"from functools import reduce\n\n\n# len is 100, let's break it into 51-49\noutput = []\nfor i,chi in enumerate(string[:51]):\n    if i > len(string[51:])-1:\n        output.append(chi)\n    else:\n        for j,chj in enumerate(string[51:]):\n            if j == i:\n                output.append(chi + chj)\n            continue\n\n\nsave = reduce(lambda a,b: ''.join([a, b]), output)\nprint(save)","a680c848":"assert len(save) == 100\nprint(save[:51])\nprint(save[51:])","aeeb20ba":"output_2 = []\nfor i,chi in enumerate(save[:51]):\n    if i > len(save[51:])-1:\n        output_2.append(chi)\n    else:\n        for j,chj in enumerate(save[51:]):\n            if j == i:\n                output_2.append(chi + chj)\n            continue\n\nsave = reduce(lambda a,b: ''.join([a, b]), output_2)\nprint(save)","ec591ee8":"assert len(save) == 100\nprint(save[:51])\nprint(save[51:])","276caf9f":"output_3 = []\nfor i,chi in enumerate(save[:51]):\n    if i > len(save[51:])-1:\n        output_3.append(chi)\n    else:\n        for j,chj in enumerate(save[51:]):\n            if j == i:\n                output_3.append(chi + chj)\n            continue\n\nsave = reduce(lambda a,b: ''.join([a, b]), output_3)\nprint(save)","e97e6955":"assert len(save) == 100\nprint(save[:51])\nprint(save[51:])","3eb79e0f":"output_4 = []\nfor i,chi in enumerate(save[:51]):\n    if i > len(save[51:])-1:\n        output_4.append(chi)\n    else:\n        for j,chj in enumerate(save[51:]):\n            if j == i:\n                output_4.append(chi + chj)\n            continue\n\nsave = reduce(lambda a,b: ''.join([a, b]), output_4)\nprint(save)","4297ed2f":"output_5 = []\nfor i,chi in enumerate(save[:51]):\n    if i > len(save[51:])-1:\n        output_5.append(chi)\n    else:\n        for j,chj in enumerate(save[51:]):\n            if j == i:\n                output_5.append(chi + chj)\n            continue\n\n\nsave = reduce(lambda a,b: ''.join([a, b]), output_5)\nprint(save)","9a5eccde":"sample_cl1.loc[44956,'ciphertext']","25a0951a":"np.array([{'a':2,'b':5}, {'c':3,'d':1}])","39492bc7":"charspace_cl1 = sorted(set([v for i,v in enumerate(reduce(lambda a,b: '\\n'.join([a, b]), ciphertexts_cl1['ciphertext']))]))\ncharspace_cl1_dict = {}\ncharspace_cl1_dictrev = {}\nfor i,v in enumerate(charspace_cl1):\n    charspace_cl1_dict[v] = i\n    charspace_cl1_dictrev[i] = v\n                                                                       #--- this list is for unicode pt values ---#\nCHAR_REFERENCE = np.array([charspace_cl1_dict, charspace_cl1_dictrev, [ord(k) for k in charspace_cl1_dict.keys()]])\nCHAR_REFERENCE","a11a1529":"sample_cl1.loc[67731,'ciphertext']","4ba40dcd":"test_cip = sample_cl1.loc[67731,'ciphertext']\ntest_cip_arrfy = [vi for i,vi in enumerate(test_cip)]\n\n# check digrams\narr, tuparr = [], []\nfor i,v in enumerate(test_cip_arrfy):\n    if i == len(test_cip_arrfy)-2:\n        break\n    \n    s = test_cip[i] + test_cip[i+1]\n    c = test_cip.count(s,0,-1)\n    if c > 0:\n        arr.append(c)\n        tuparr.append((s,c))\n    \nmax(arr)","3bd914cc":"digram_freqs = pd.Series(tuparr)\ntop_dgms = []\n\nfor t in digram_freqs:\n    if t[1] == 2:\n        top_dgms.append(t[0])\n        \nset(top_dgms)","7ce20baa":"test_cip","4024f55e":"save, save_b = [], [] \nmap_cip_sample = \"\"\n\n\nfor i,v in enumerate(sample_cl1.loc[67731,'ciphertext']):\n    save.append(charspace_cl1_dict[v])\nprint(save)\n    \ndef deshift_with_wrap(v, bias=-4):    \n    if v in (list(range(0, 21)) + [46, 47]): return v # skip punctuation and digits \n    \n    if bias < 0:\n        if v-bias > 73: return v-bias - 74\n        return v-bias\n    else:\n        if v-bias < 0: return v-bias + 74\n        if v-bias > 73: return v-bias - 74\n        return v-bias\n\nsave_b = list(map(deshift_with_wrap, save))\nprint(save_b)\n\nfor i,v in enumerate(save_b):\n    map_cip_sample += charspace_cl1_dictrev[v]\n    \n    \nmap_cip_sample","8298afac":"'abbbM: Ntmj wwmh wwqm sp m$vm nr jpx Fpx!wet'","748f1979":"all_occurr_cip = pd.Series([v for i,v in enumerate(reduce(lambda a,b: '\\n'.join([a, b]), ciphertexts_cl1['ciphertext']))], dtype=np.object)\n\n# sample from train\nsample_train = train_df.loc[train_df['pad_length_plaintext'] == 100, 'text'].sample(n=ciphertexts_cl1.shape[0], random_state=RS, axis=0)\nsample_occurr_plain = pd.Series([v for i,v in enumerate(reduce(lambda a,b: '\\n'.join([a, b]), sample_train))], dtype=np.object)","a482df52":"charspace_trainset = sorted(set([v for i,v in enumerate(reduce(lambda a,b: '\\n'.join([a, b]), train_df['text']))]))\nf, ax = plt.subplots(nrows=2,ncols=1,figsize=(18, 18))\n\n\nvc = all_occurr_cip.value_counts(normalize=True, ascending=True).index.tolist()\nax[0].set_title(\"Freq. distribution of chars in sample\", fontdict={\"fontsize\": 18})\nsns.countplot(x=all_occurr_cip.values.tolist(), data=all_occurr_cip, order=vc,orient='v', palette='PuRd', saturation=0.75, dodge=True, ax=ax[0])\nax[0].set_xticklabels(labels=vc, fontdict={\"fontsize\":18})\nax[0].set_yticklabels(labels=ax[0].get_yticks(), fontdict={\"fontsize\":18})\n\nvc = sample_occurr_plain.value_counts(normalize=True, ascending=True).index.tolist()\nax[1].set_title(\"Freq. distribution of chars in all <=100 charlength plaintexts\", fontdict={\"fontsize\": 18})\nsns.countplot(x=sample_occurr_plain.values.tolist(), data=sample_occurr_plain, order=vc, orient='v', palette='PuRd', saturation=0.75, dodge=True, ax=ax[1])\nax[1].set_xticklabels(labels=vc, fontdict={\"fontsize\":18})\nax[1].set_yticklabels(labels=ax[1].get_yticks(), fontdict={\"fontsize\":18})","1346beae":"# Digram frequency graph \nsample_concat_plain = reduce(lambda a,b: '\\n'.join([a,b]), sample_train)\narr, tuparr = [], []\nfor i,v in enumerate(sample_concat_plain):\n    if i == len(sample_concat_plain)-2:\n        break\n    \n    s = sample_concat_plain[i] + sample_concat_plain[i+1]\n    c = sample_concat_plain.count(s,0,-1)\n    if c > 0:\n        arr.append(c)\n        tuparr.append((s,c))\n    \nprint(max(arr))","15990135":"tuparr","2e5f9f08":"top_digram_freqs = pd.DataFrame(data={\n    #\"main\": tuparr,\n    \"chars\": [t[0] for t in tuparr],\n    \"counts\": [t[1] for t in tuparr]\n})\n\nassert top_digram_freqs.shape[0] == len(tuparr)","aace72cd":"top_digram_freqs.drop_duplicates(inplace=True)\ntop_digram_freqs.sort_values(by=['counts'], axis=0, ascending=False, inplace=True)","72cdc25d":"top_digram_freqs.iloc[:50, 0]","8710659e":"f, ax = plt.subplots(nrows=1,ncols=1,figsize=(18, 9))\n\nvc = top_digram_freqs.iloc[:50, 0].copy()\nax.set_title(\"Freq. distribution of top digrams in all <=100 charlength plaintexts\", fontdict={\"fontsize\": 18})\nsns.barplot(x='chars', y='counts', data=top_digram_freqs.iloc[:50,:], order=vc, orient='v', palette='pink', saturation=0.75, dodge=True, ax=ax)\nax.set_xticklabels(labels=vc, fontdict={\"fontsize\":18}, rotation=30)\nax.set_yticklabels(labels=ax.get_yticks(), fontdict={\"fontsize\":18})","22c1c425":"%%time\n'asdf'+'<BEGIN>'+'qwer'","f844022e":"%%time\n'<BEGIN>'.join(['asdf', 'qwer'])","aec25425":"# Digram frequency graph \nsample_concat_cip = reduce(lambda a,b: '\\n'.join([a, b]), ciphertexts_cl1['ciphertext'])\narr, tuparr = [], []\nfor i,v in enumerate(sample_concat_cip):\n    if i == len(sample_concat_cip)-2:\n        break\n    \n    s = sample_concat_cip[i] + sample_concat_cip[i+1]\n    c = sample_concat_cip.count(s,0,-1)\n    if c > 0:\n        arr.append(c)\n        tuparr.append((s,c))\n    \nprint(max(arr))","8a3f6422":"top_digram_freqs = pd.DataFrame(data={\n    #\"main\": tuparr,\n    \"chars\": [t[0] for t in tuparr],\n    \"counts\": [t[1] for t in tuparr]\n})\nassert top_digram_freqs.shape[0] == len(tuparr)\n\ntop_digram_freqs.drop_duplicates(inplace=True)\ntop_digram_freqs.sort_values(by=['counts'], axis=0, ascending=False, inplace=True)\n\n\nf, ax = plt.subplots(nrows=1,ncols=1,figsize=(18, 9))\n\nvc = top_digram_freqs.iloc[:50, 0].copy()\nax.set_title(\"Freq. distribution of top digrams in all ciphertexts\", fontdict={\"fontsize\": 18})\nsns.barplot(x='chars', y='counts', data=top_digram_freqs.iloc[:50,:], order=vc, orient='v', palette='pink', saturation=0.75, dodge=True, ax=ax)\nax.set_xticklabels(labels=vc, fontdict={\"fontsize\":18}, rotation=30)\nax.set_yticklabels(labels=ax.get_yticks(), fontdict={\"fontsize\":18})","01c45e3e":"# Replacing 's' with 'e'\n#           'd' with 't' \ntest_sent = sample_cl1.loc[44956,'ciphertext']\nprint(test_sent)\nprint('cipher 1 predictions demo')\nreduce(lambda a,b: ''.join([a,b]),['h' if v == 's' else #ok\n                                   #'e' if v == 'd' else\n                                   #'h' if v == 'f' else\n                                   #'o' if v == 'j' else\n                                   #'e' if v == 'i' else\n                                   'a' if v == 'x' else #ok\n                                   'b' if v == 'l' else #ok\n                                   'm' if v == 'p' else #ok\n                                   #'s' if v == 'e' else\n                                   'r' if v == 't' else #ok\n                                   'A' if v == 'B' else #ok\n                                   #'r' if v == 'u' else \n                                   's' if v == 'w' else #ok\n                                   #'r' if v == 'y' else \n                                   #'v' if v == 'r' else \n                                   v for i,v in enumerate(test_sent)])","589293fa":"train_df.columns","3ffb1994":"crack_1 = train_df['text'].str.find(\"Abraham's\")\ncrack_1.value_counts()","953ac0b8":"crack_1.loc[crack_1 == 28].index","ca3cb143":"train_df.iloc[52854, :]","b2229a16":"sample_cl1.index.tolist()","24f52481":"# Trying another with Abraham's blessing\ntest_sent_2 = sample_cl1.loc[25629,'ciphertext']\nprint(test_sent_2)\nprint('cipher 1 predictions demo')\nreduce(lambda a,b: ''.join([a,b]),['h' if v == 's' else #ok\n                                   'e' if v == 'd' else #ok\n                                   't' if v == 'f' else #ok\n                                   'h' if v == 'w' else #ok\n                                   'h' if v == 'g' else #ok\n                                   'a' if v == 'x' else #ok\n                                   'b' if v == 'l' else #ok\n                                   'e' if v == 'p' else #ok\n                                   #'o' if v == 'm' else\n                                   'r' if v == 't' else #ok\n                                   'A' if v == 'B' else #ok\n                                   's' if v == 'i' else #ok\n                                   'i' if v == 'm' else #ok\n                                   #'f' if v == 'b' else \n                                   v for i,v in enumerate(test_sent_2)])","f3f8fee7":"crack_1 = train_df['text'].str.find(\"he '\")\ncrack_1.value_counts()","4d32daf2":"train_df.loc[train_df.loc[crack_1 != -1, :].index.tolist(), 'text']\n\n# Matches with index 79849","82ecff12":"train_df.loc[79849, 'text']","206571ea":"test_sent_3 = sample_cl1.loc[107305,'ciphertext']\nprint(test_sent_3)\nprint('cipher 1 predictions demo')\nreduce(lambda a,b: ''.join([a,b]),['h' if v == 's' else #ok\n                                   'e' if v == 'd' else #ok\n                                   't' if v == 'f' else #ok\n                                   'h' if v == 'w' else #ok\n                                   'h' if v == 'g' else #ok\n                                   'a' if v == 'x' else #ok\n                                   'b' if v == 'l' else #ok\n                                   'e' if v == 'p' else #ok\n                                   'h' if v == 'o' else #ok\n                                   'r' if v == 't' else #ok\n                                   'A' if v == 'B' else #ok\n                                   's' if v == 'i' else #ok\n                                   'i' if v == 'm' else #ok\n                                   't' if v == 'j' else #ok \n                                   v for i,v in enumerate(test_sent_3)])","f8616e88":"crack_1 = train_df['text'].str.find(\"a hair,\")\ncrack_1.value_counts()","919368b5":"train_df.loc[train_df.loc[crack_1 != -1].index.tolist(), :]\n\n# Matches with 80856","f81f27fd":"train_df.loc[80856, 'text']","497cb7d4":"sample_sub_df.head()","6801a337":"test_df.loc[[44956,25629,107305], 'ciphertext_id'].values.tolist()","3aa7da67":"submission = pd.DataFrame(data={\n    'ciphertext_id': test_df.loc[[44956,25629,107305], 'ciphertext_id'].values.tolist(),\n    'index': [52854,79849,80856]\n})\n\nsubmission","148bf684":"# Running out of time ...","f120f505":"_Inspecting ciphertexts with **difficulty = 1**_","c99ba9a1":"_Preliminary Visualizations_","5541e8f3":"> 99.86% of such ciphertexts are within 100 characters length.","7da5c3e4":"Caesar cipher decoding","2177fc1d":"Trying reverse rail-fence transposition"}}