{"cell_type":{"0244bd89":"code","a7a8158d":"code","01d1ff68":"code","25833506":"code","1410aede":"code","ac92a3d0":"code","bbf5d778":"code","dd208b40":"code","65850456":"code","46a30e95":"code","799c097e":"code","dfa4dcbc":"code","46cee01b":"code","356b5b09":"markdown","477e9eed":"markdown"},"source":{"0244bd89":"import os\nimport cv2\nimport glob\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom pathlib import Path\n\n!ls ..\/input\/understanding_cloud_organization\/","a7a8158d":"seed = 1234\nnp.random.seed(seed)\n%matplotlib inline","01d1ff68":"data_path = Path(\"..\/input\/understanding_cloud_organization\/\")\ntrain = pd.read_csv(data_path \/ \"train.csv\")\nsub = pd.read_csv(data_path \/ \"sample_submission.csv\")\n\nprint(\"Number of training samples: \", len(train))\nprint(\"Number of test samples: \", len(sub))","25833506":"def rle_decode(mask_rle, shape=(1400, 2100)):\n    '''\n    mask_rle: run-length as string formatted (start length)\n    shape: (height, width) of array to return \n    Returns numpy array, 1 - mask, 0 - background\n    '''\n    s = mask_rle.split()\n    starts, lengths = [np.asarray(x, dtype=int) for x in (s[0:][::2], s[1:][::2])]\n    starts -= 1\n    ends = starts + lengths\n    img = np.zeros(shape[0]*shape[1], dtype=np.uint8)\n    for lo, hi in zip(starts, ends):\n        img[lo:hi] = 1\n    return img.reshape(shape, order='F')  # Needed to align to RLE direction","1410aede":"train.head()","ac92a3d0":"# Let's clear up some mess\ntrain_images_path = \"..\/input\/understanding_cloud_organization\/train_images\/\"\nvals = train[\"Image_Label\"].str.split(\"_\", expand=True)\ntrain[\"image\"] = vals[0]\ntrain[\"label\"] = vals[1]\ntrain[\"image_path\"] = train_images_path + train[\"image\"]\ntrain.head()","bbf5d778":"# How many null values are there?\nprint(\"Number of null values in the data\")\ntrain.isnull().sum()","dd208b40":"# Unique labels\ntrain[\"label\"].unique()","65850456":"# Distribution of labels\ntrain[\"label\"].value_counts().plot(kind=\"bar\", figsize=(15, 5))\nplt.show()","46a30e95":"# Drop the null values for now\ntrain_clean = train.dropna().reset_index(drop=True)\ntrain_clean.head()","799c097e":"sample_indices = []\nto_select = 4\nfor label in train_clean['label'].unique():\n    label_indices = np.random.choice(train_clean.index[train_clean[\"label\"]==label], size=to_select)\n    sample_indices += label_indices.tolist()","dfa4dcbc":"from skimage.io import imread","46cee01b":"f,ax = plt.subplots(4,4, figsize=(20,10))\nfor i, idx in enumerate(sample_indices):\n    img = imread(train_clean.iloc[idx][\"image_path\"])\n    mask_rle = train_clean.iloc[idx][\"EncodedPixels\"]\n    mask = rle_decode(mask_rle)\n    label = train_clean.iloc[idx][\"label\"]\n    \n    ax[i\/\/4, i%4].imshow(img)\n    ax[i\/\/4, i%4].imshow(mask, alpha=0.5, cmap='gray')\n    ax[i\/\/4, i%4].set_title(label)\n    ax[i\/\/4, i%4].axis('off')\n\nplt.show()","356b5b09":"Maybe I am not sleeping very well. Let me know if you find anything wrong in this analysis. I am unable to digest the fact that all labels have same number of samples ","477e9eed":"That is very strange. Out of `22K` samples, `~11K` don't have encoded pixel values? Interesting!"}}