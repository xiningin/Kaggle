{"cell_type":{"d7ad5812":"code","c6cf4b77":"code","fc38f5b5":"code","815a6b96":"code","301d3364":"code","490b5196":"code","3a16a190":"code","a6fbcc53":"code","37226284":"code","23355130":"code","629e931b":"code","7afe4e75":"code","6518f11b":"code","48ab4d35":"code","e1baf82f":"code","e69c30d1":"code","990a62d3":"code","37ac56d5":"code","650cf3e7":"code","0e689d16":"markdown","84a6e0ee":"markdown","b42d6182":"markdown","5b1bbac6":"markdown","694de27e":"markdown","f58644a2":"markdown","16ec5544":"markdown","4a32ff01":"markdown","7cfa2ded":"markdown","1fec16d0":"markdown","d7cf12ab":"markdown","68a6d819":"markdown","80c4279c":"markdown","c0ea63cd":"markdown","a181b147":"markdown"},"source":{"d7ad5812":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns\nimport matplotlib.pyplot as plt \n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","c6cf4b77":"# load the dataset\ntrain = pd.read_csv(\"..\/input\"+'\/train.csv')\ntest = pd.read_csv(\"..\/input\"+'\/test.csv')\n# Store test ID for output step\n# Drop the 'SalePrice' and 'Id' from the treining datadrame\n# Store 'SalePrice' as the target column y\ntest_ID = test.pop('Id') \ny = train.pop('SalePrice')\ntrain.pop('Id');\ntrain.shape, y.shape, test.shape","fc38f5b5":"#histogram\nsns.distplot(y);","815a6b96":"baseline = np.mean(y)\nprint('Baseline score = ',baseline)","301d3364":"sns.heatmap(train.corr(), square=True, center=0);","490b5196":"# Concatenate Training and Testing lists \n# Fill the NAN values with \"NA\" as a group of not applicable \nlst = [train, test]\nconcat_list = pd.concat(lst)\n# concat_list.shape\nconcat_list = concat_list.fillna('NA')","3a16a190":"# Encode the categorical columns \n# Seperate the Training and Testing lists\nconcat_list = pd.get_dummies(concat_list)\ntrain_Encoded = concat_list.iloc[:len(y),:]\ntest_Encoded = concat_list.iloc[len(y):,:]","a6fbcc53":"# Rescale the columns so we can compare apples with apples \nfrom sklearn.preprocessing import StandardScaler\nss = StandardScaler()\ntrain_Encoded_ss = pd.DataFrame(ss.fit_transform(train_Encoded));\ntest_Encoded_ss = pd.DataFrame(ss.transform(test_Encoded));","37226284":"# Split the Training list to a sub-training and sub-testing lists \nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(train_Encoded_ss,y,shuffle=True)","23355130":"# Initiate Linear Regression model\n# fit it \n# then get the the model score\n# store the model predictions \nfrom sklearn.linear_model import LinearRegression\nreg = LinearRegression()\nreg.fit(X_train,y_train)\nprint('Test Score = ', reg.score(X_test, y_test), 'Train Score = ', reg.score(X_train, y_train))\nreg_y_hat = reg.predict(test_Encoded_ss)\n# # output file \nreg_y_hat = pd.DataFrame(reg_y_hat)\nreg_y_hat.columns=['SalePrice']\nreg_output = pd.concat([test_ID, reg_y_hat], axis=1)\n# reg_output.to_csv()\nreg_output.head()","629e931b":"# Initiate RidgeCV model\n# fit it \n# then get the the model score\n# store the model predictions \nfrom sklearn.linear_model import RidgeCV\nrid = RidgeCV()\nrid.fit(X_train,y_train)\nprint('Test Score = ', rid.score(X_test, y_test), 'Train Score = ', rid.score(X_train,y_train))\nrid_y_hat = rid.predict(test_Encoded_ss)\n# output file \nrid_y_hat = pd.DataFrame(rid_y_hat)\nrid_y_hat.columns=['SalePrice']\nrid_output = pd.concat([test_ID, rid_y_hat], axis=1)\n# rid_output.to_csv()\nrid_output.head()","7afe4e75":"# Initiate LassoCV model\n# fit it \n# then get the the model score\n# store the model predictions \nfrom sklearn.linear_model import LassoCV\nlasso = LassoCV()\nlasso.fit(X_train,y_train)\nprint('Test Score = ', lasso.score(X_test, y_test), 'Train Score = ', lasso.score(X_train, y_train))\nlasso_y_hat = lasso.predict(test_Encoded_ss)\n# output file \n# lasso_y_hat = pd.DataFrame(lasso_y_hat)\n# lasso_y_hat.columns=['SalePrice']\n# lasso_output = pd.concat([test_ID, lass_y_hat], axis=1)\n# lasso_output.head()","6518f11b":"# output file \nlasso_y_hat = pd.DataFrame(lasso_y_hat)\nlasso_y_hat.columns=['SalePrice']\nlasso_output = pd.concat([test_ID, lasso_y_hat], axis=1)\n# lasso_output.to_csv()\nlasso_output.head()","48ab4d35":"from sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn import metrics","e1baf82f":"# Perform 5-fold cross validation\nreg_scores = cross_val_score(reg, X_train, y_train, cv=5);\nprint(\"Cross-validated scores:\", reg_scores);\nprint(\"Mean of Ccoss-validated scores:\", reg_scores.mean());","e69c30d1":"# Perform 5-fold cross validation\nrid_scores = cross_val_score(rid, X_train, y_train, cv=5);\nprint(\"Cross-validated scores:\", rid_scores);\nprint(\"Mean of Ccoss-validated scores:\", rid_scores.mean());","990a62d3":"print('features kept = ',sum(lasso.coef_!=0), 'features eliminated = ',sum(lasso.coef_==0))\nprint('alpha = ',lasso.alpha_)\nprint('the number of folds = ', lasso.cv) # the none means 3 folds by default","37ac56d5":"# Perform 5-fold cross validation\nscores = cross_val_score(lasso, X_train, y_train, cv=5);\nprint(\"Cross-validated scores:\", scores);\nprint(\"Mean of Ccoss-validated scores:\", scores.mean());","650cf3e7":"plt.figure(figsize=(12,10)) \nlass_coef = lasso.coef_\nplt.plot(range(len(train_Encoded_ss.columns)), lass_coef)\nplt.xticks(range(len(train_Encoded_ss.columns)), train_Encoded_ss.columns.values, rotation=60)\nplt.margins(0.02)\nplt.xlabel('Features')\nplt.ylabel('Coefficients')\nplt.show()","0e689d16":"# Problem Statement","84a6e0ee":"# Evaluation and Conceptual Understanding","b42d6182":"# Conclusion and Recommendations","5b1bbac6":"# Data Cleaning and EDA","694de27e":"### Evaluating `Linear Regression with Ridge` model","f58644a2":"### Evaluating `Linear Regression` model","16ec5544":"### Distripution of y values","4a32ff01":"### Evaluating `Linear Regression with Lasso` model","7cfa2ded":"This project is focues on testing the impact of regularzation techniques Lasso and Ridge and compare it with the plain Linear Regression model","1fec16d0":"The plain Linear Regression tend to overfit, becuse it performes perfectly on the training data, but in the test data sometimes it performes worse than the baseline (based on the the training-testing split). This behavior is expected because of the number of features is too large. We need to do regularized regression to solve the overfitting problem.\nTwo regularized regression were tested, Ridge Regression and Lasso Regression. After applying ridge regression slitly improvment were noticed in compare to lasso regression wich shows at least 10% improvment in compare to plain Linear Regression. We concluded that becuse of the large number of features the least valuable features must be elemenated to improve the model. The figure below shows the Lasso's coefficients for each feature, and some looks like they have most significant impact while most were set to weight zero.  Further investigation well be focused on the features with hiest coefficients","d7cf12ab":"### model 3","68a6d819":"### The heatmap of columns correlation","80c4279c":"# Preprocessing and Modeling","c0ea63cd":"### model 2","a181b147":"### model 1"}}