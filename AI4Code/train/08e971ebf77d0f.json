{"cell_type":{"e5b33105":"code","a6ae0d17":"code","836b9282":"code","f17c6738":"code","18f8ec38":"code","70b58d1a":"code","21b8390a":"code","4ad93236":"code","1008eb19":"code","789b91dd":"code","89521b2a":"code","b4367328":"markdown"},"source":{"e5b33105":"import pandas as pd\npd.set_option('display.max_columns', None)\nfrom mlxtend.frequent_patterns import apriori, association_rules\n\ndef check_df(dataframe, head=5):\n    print(\"########## SHAPE ##########\")\n    print(dataframe.shape)\n    print(\"########## TYPES ##########\")\n    print(dataframe.dtypes)\n    print(\"########## HEAD ##########\")\n    print(dataframe.head(head))\n    print(\"########## TAIL ##########\")\n    print(dataframe.tail(head))\n    print(\"########## NA ##########\")\n    print(dataframe.isnull().sum())\n    print(\"########## QUANTILES ##########\")\n    print(dataframe.quantile([0, 0.05, 0.50, 0.95, 0.99, 1]).T)\n\ndef outlier_thresholds(dataframe, variable):\n    quartile1 = dataframe[variable].quantile(0.01)\n    quartile3 = dataframe[variable].quantile(0.99)\n    interquantile_range = quartile3 - quartile1\n    up_limit = quartile3 + 1.5 * interquantile_range\n    low_limit = quartile1 - 1.5 * interquantile_range\n    return low_limit, up_limit\n\ndef replace_with_thresholds(dataframe, variable):\n    low_limit, up_limit = outlier_thresholds(dataframe, variable)\n    dataframe.loc[(dataframe[variable] < low_limit), variable] = low_limit\n    dataframe.loc[(dataframe[variable] > up_limit), variable] = up_limit\n\ndef retail_data_prep(dataframe):\n    dataframe.dropna(inplace=True)\n    dataframe = dataframe[~dataframe[\"Invoice\"].str.contains(\"C\", na=False)]\n    dataframe = dataframe[dataframe[\"Quantity\"] > 0]\n    dataframe = dataframe[dataframe[\"Price\"] > 0]\n    replace_with_thresholds(dataframe, \"Quantity\")\n    replace_with_thresholds(dataframe, \"Price\")\n    return dataframe\n\ndef create_invoice_product_df(dataframe, id=True):\n    if id:\n        return dataframe.groupby(['Invoice', \"StockCode\"])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n    else:\n        return dataframe.groupby(['Invoice', 'Description'])['Quantity'].sum().unstack().fillna(0). \\\n            applymap(lambda x: 1 if x > 0 else 0)\n\ndef check_id(dataframe, stock_code):\n    product_name = dataframe[dataframe[\"StockCode\"] == stock_code][[\"Description\"]].values[0].tolist()\n    print(product_name)\n\ndef create_rules(dataframe, id=True, country=\"France\"):\n    dataframe = dataframe[dataframe['Country'] == country]\n    dataframe = create_invoice_product_df(dataframe, id)\n    frequent_itemsets = apriori(dataframe, min_support=0.01, use_colnames=True)\n    rules = association_rules(frequent_itemsets, metric=\"support\", min_threshold=0.01)\n    return rules\n\ndef arl_recommender(rules_df, product_id, rec_count=1):\n    sorted_rules = rules_df.sort_values(\"lift\", ascending=False)\n    recommendation_list = []\n    for i, product in enumerate(sorted_rules[\"antecedents\"]):\n        for j in list(product):\n            if j == product_id:\n                recommendation_list.append(list(sorted_rules.iloc[i][\"consequents\"])[0])\n\n    return recommendation_list[0:rec_count]","a6ae0d17":"import pandas as pd\npd.pandas.set_option('display.max_columns', 5)\n\ndef create_user_movie_df():\n    import pandas as pd\n    movie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\n    rating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\n    df = movie.merge(rating, how=\"left\", on=\"movieId\")\n    comment_counts = pd.DataFrame(df[\"title\"].value_counts())\n    rare_movies = comment_counts[comment_counts[\"title\"] <= 1000].index\n    common_movies = df[~df[\"title\"].isin(rare_movies)]\n    user_movie_df = common_movies.pivot_table(index=[\"userId\"], columns=[\"title\"], values=\"rating\")\n    return user_movie_df","836b9282":"user_movie_df = create_user_movie_df()","f17c6738":"# Determining the Movies Watched by the User to Suggest\n\nrandom_user = 108170\nrandom_user_df = user_movie_df[user_movie_df.index == random_user]\nmovies_watched = random_user_df.columns[random_user_df.notna().any()].tolist()","18f8ec38":"# Accessing Data and Ids of Other Users Watching Same Movies\n\nmovies_watched_df = user_movie_df[movies_watched]\nuser_movie_count = movies_watched_df.T.notnull().sum()\nuser_movie_count = user_movie_count.reset_index()\nuser_movie_count.columns = [\"userId\", \"movie_count\"]\npercent = len(movies_watched) * 60 \/ 100\nusers_same_movies = user_movie_count[user_movie_count[\"movie_count\"] > percent][\"userId\"]","70b58d1a":"# Determining the Users to be Suggested and the Users Most Similar to the User\n\nfinal_df = pd.concat([movies_watched_df[movies_watched_df.index.isin(users_same_movies.index)],\n                      random_user_df[movies_watched]])\n\ncorr_df = final_df.T.corr().unstack().sort_values().drop_duplicates()\ncorr_df = pd.DataFrame(corr_df, columns=[\"corr\"])\ncorr_df.index.names = ['user_id_1', 'user_id_2']\ncorr_df = corr_df.reset_index()\n\ntop_users = corr_df[(corr_df[\"user_id_1\"] == random_user) & (corr_df[\"corr\"] >= 0.65)][\n    [\"user_id_2\", \"corr\"]].reset_index(drop=True)\n\ntop_users = top_users.sort_values(by='corr', ascending=False)\n\ntop_users.rename(columns={\"user_id_2\": \"userId\"}, inplace=True)\n\nrating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\ntop_users_ratings = top_users.merge(rating[[\"userId\", \"movieId\", \"rating\"]], how='inner')","21b8390a":"# Calculating Weighted Average Recommendation Score and Keeping Top 5 Movies\n\ntop_users_ratings['weighted_rating'] = top_users_ratings['corr'] * top_users_ratings['rating']\n\ntop_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\n\nrecommendation_df = top_users_ratings.groupby('movieId').agg({\"weighted_rating\": \"mean\"})\nrecommendation_df = recommendation_df.reset_index()","4ad93236":"# Let's get weighted_rating greater than 4:\nrecommendation_df[recommendation_df[\"weighted_rating\"] > 4]\nmovies_to_be_recommend = recommendation_df[recommendation_df[\"weighted_rating\"] > 4].sort_values(\"weighted_rating\", ascending=False)[0:5]\n\nmovie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nmovies_to_be_recommend.merge(movie[[\"movieId\", \"title\"]]).index","1008eb19":"###########################################\n# Step 6: Item-Based Recommendation\n###########################################\n\n# Make an item-based suggestion based on the name of the movie that the user has watched with the highest score.\n# Make 10 suggestions with 5 suggestions user-based and 5 suggestions item-based.\n\n# Clue:\n\n# user = 108170\n\n# movie = pd.read_csv('datasets\/movie_lens_dataset\/movie.csv')\n# rating = pd.read_csv('datasets\/movie_lens_dataset\/rating.csv')\n#\n# Receiving the id of the movie with the most recent score from the movies that the user to be recommended gives 5 points:\n# movie_id = rating[(rating[\"userId\"] == user) & (rating[\"rating\"] == 5.0)]. \\\n# sort_values(by=\"timestamp\", ascending=False)[\"movieId\"][0:1].values[0]\n#\n\nuser = 108170\n\nmovie = pd.read_csv('..\/input\/movielens-20m-dataset\/movie.csv')\nrating = pd.read_csv('..\/input\/movielens-20m-dataset\/rating.csv')\n\n# Receiving the id of the movie with the most recent score from the movies that the user to be recommended gives 5 points:\nmovie_id = rating[(rating[\"userId\"] == user) & (rating[\"rating\"] == 5.0)]. \\\n    sort_values(by=\"timestamp\", ascending=False)[\"movieId\"][0:1].values[0]","789b91dd":"def item_based_recommender(movie_name, user_movie_df):\n    movie = user_movie_df[movie_name]\n    return user_movie_df.corrwith(movie).sort_values(ascending=False).head(10)\n\n\nmovies_from_item_based = item_based_recommender(movie[movie[\"movieId\"] == movie_id][\"title\"].values[0], user_movie_df)","89521b2a":"#1 to 6th. 0 has the movie itself. We left him out.\nmovies_from_item_based[1:6]","b4367328":"<h2 style='background:#11489c; border:0; color:white'><center>Hybrid Recommendation Systems<\/center><\/h2>\n\nIt is a study on hybrid recommendation systems, presented in detail and in a functionalized form\n\n<a href=\"https:\/\/ibb.co\/fNjqWSX\"><img src=\"https:\/\/i.ibb.co\/vd0VWBc\/e902a8f8-1343-4987-b5ae-25dc76f32a72.png\" alt=\"e902a8f8-1343-4987-b5ae-25dc76f32a72\" border=\"0\"><\/a>\n\n<h2 style='background:#11489c; border:0; color:white'><center>Business Problem<\/center><\/h2>\n\n* Item-based and for the user whose ID is given\n* User-based recommender methods\n* Make a guess using\n\n<h2 style='background:#11489c; border:0; color:white'><center>About the Dataset<\/center><\/h2>\n\n* The dataset was provided by MovieLens, a movie recommendation service\n\n* It includes the movies and the rating scores made for these movies contains\n\n* It contains 2,000,0263 ratings across 27,278 movies\n\n* This data was created by 138,493 users from January 09, 1995 to March 31, 2015 was created between This data set was published on 17 October 2016 was created\n\n* Users are randomly selected. All selected users voted for at least 20 movies information is available\n\n<h2 style='background:#11489c; border:0; color:white'><center>Variables<\/center><\/h2>\n\n<span style=\"color:blue\">movie.csv<\/span>\n* movieId \u2013 Unique movie number. (UniqueID)\n* title \u2013 Movie name\n\n<span style=\"color:blue\">rating.csv<\/span>\n* userid \u2013 Unique user number. (UniqueID)\n* movieId \u2013 Unique movie number. (UniqueID)\n* rating \u2013 The rating given to the movie by the user\n* timestamp \u2013 Evaluation date"}}