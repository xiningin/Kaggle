{"cell_type":{"0f0b3bfb":"code","ad8347ef":"code","0223f049":"code","e07fb215":"code","8c0e9c44":"code","c6ad747b":"code","1a166379":"code","2f186411":"code","bc8b4032":"code","05e424f5":"code","f5f5f360":"code","a4b2535c":"code","b70ebd79":"code","4121acbd":"code","da4db0dc":"code","17fd6f9a":"code","7f2e1649":"code","12e29b3f":"code","98bcae60":"code","c20bfe2b":"code","5325e5dc":"code","b532d167":"code","3b7e7140":"code","e8d40584":"code","efc3f211":"code","9529f325":"code","435c7b7b":"code","039c174b":"code","eb946e21":"code","832b281b":"code","b2985ef9":"code","3e0217d9":"code","80b34e12":"code","66b2b836":"markdown","75a627c3":"markdown","a916056d":"markdown","d94f45c9":"markdown","20dfe3f7":"markdown","9982c6c5":"markdown","e18bbe1e":"markdown","beae7930":"markdown"},"source":{"0f0b3bfb":"!mkdir -p \/tmp\/concatenated-embeddings","ad8347ef":"!ls \/kaggle\/input\/","0223f049":"# %%python\n\n### Script to concatenate all embeddings based on given model votes\n\n\nimport numpy as np\nimport pandas as pd\nimport pickle\nimport glob\nimport os\nfrom sklearn.preprocessing import normalize\nfrom tqdm.auto import tqdm\n\nmodel_votes = {\n    'v2s-15epochs-800t800':1,\n    'v2m-15epochs-640t640':1,\n    'v2xl-15epochs-512t640':1,\n    'v2m-15epochs-732t732': 1,\n     'v2l-12epochs-720t720': 1\n}\n\nsample_submission = pd.read_csv('..\/input\/landmark-retrieval-2021\/sample_submission.csv')\nIS_PRIVATE = sample_submission.shape[0]!=1129\nprint(IS_PRIVATE)\n\nif not IS_PRIVATE:\n    model_votes = {\n        'v2xl-15n2epochs-720t720':1\n    }\n\n\nmodel_names = list(model_votes.keys())\nmodel_votes = [model_votes[x] for x in model_names]\nsum_votes = sum(model_votes)\nmodel_votes = [x\/sum_votes for x in model_votes]\n\npickle.dump(model_names, open(\"model_names.pkl\", \"wb\"))\npickle.dump(model_votes, open(\"model_votes.pkl\", \"wb\"))\n\nnpy_array_files = glob.glob('..\/input\/glr-precomputed-embed-v2l-12epochs-720t720\/*.npy')\nnpy_array_files = [x.split('\/')[-1] for x in npy_array_files]\n\n\n\nfor file in tqdm(npy_array_files):\n    if 'train' in file:\n        if 'name' not in file:\n            array = []\n            for i,model_name in enumerate(model_names):\n                if model_name=='v2xl-15n2epochs-720t720':\n                    model_name = 'v2xl-15n2epochs'\n                array.append(np.load(f'..\/input\/glr-precomputed-embed-{model_name}\/{file}')*model_votes[i])\n            array = normalize(np.concatenate(array,axis=1),axis=1)\n        else:\n            reference = None\n            for i,model_name in enumerate(model_names):\n                if model_name=='v2xl-15n2epochs-720t720':\n                    model_name = 'v2xl-15n2epochs'\n                array = np.load(f'..\/input\/glr-precomputed-embed-{model_name}\/{file}')\n                if i==0:\n                    reference=array\n                else:\n                    assert (reference==array).sum()==len(reference)\n        np.save('\/tmp\/concatenated-embeddings\/'+file,array)\n#     except:\n#         print(\"Missing file\",file)","e07fb215":"!ls -lth \/tmp\/concatenated-embeddings\/","8c0e9c44":"!du -sh \/tmp\/concatenated-embeddings\/","c6ad747b":"import re\nimport os\nimport numpy as np\nimport pandas as pd\nimport glob\nimport pickle\nfrom tqdm.notebook import tqdm\nfrom sklearn.preprocessing import normalize","1a166379":"sample_submission = pd.read_csv('..\/input\/landmark-retrieval-2021\/sample_submission.csv')\nIS_PRIVATE = sample_submission.shape[0]!=1129\nprint(IS_PRIVATE)","2f186411":"if IS_PRIVATE:\n    test_images = glob.glob('..\/input\/landmark-retrieval-2021\/test\/*\/*\/*\/*.jpg')\n    index_images = glob.glob('..\/input\/landmark-retrieval-2021\/index\/*\/*\/*\/*.jpg')\nelse:\n    test_images = glob.glob('..\/input\/landmark-retrieval-2021\/test\/0\/0\/*\/*.jpg')\n    index_images = glob.glob('..\/input\/landmark-retrieval-2021\/index\/0\/0\/0\/*.jpg')\n\nprint(len(test_images),len(index_images))\n\npickle.dump(test_images, open(\"test_images.pkl\", \"wb\"))\npickle.dump(index_images, open(\"index_images.pkl\", \"wb\"))","bc8b4032":"%%writefile get_embeddings.py\n\nimport sys\nimport tensorflow as tf\nimport tensorflow_hub as tfhub\nfrom sklearn.preprocessing import normalize\nimport pickle\nimport numpy as np\n\nMODEL_IMAGE_SIZE_MAP = {\n    'v2m-15epochs-640t640':640,\n    'v2l-15epochs-512t640':640,\n    'v2m-15epochs-800t800':800,\n    'v2m-15epochs-732t732':732,\n    'v2xl-15n2epochs-720t720':720,\n    'v2s-15epochs-800t800':800,\n    'v2l-10n4epochs-720t720':720,\n    'v2xl-15epochs-512t640':640,\n    'b6-15epochs-800t800':800,\n    'v2l-12epochs-720t720':720\n}\n\nmodel_name = sys.argv[1]\nIMAGE_SIZE = MODEL_IMAGE_SIZE_MAP[model_name]\nIMAGE_SIZE = [IMAGE_SIZE,IMAGE_SIZE]\n\nstrategy = tf.distribute.get_strategy()  \nAUTO = tf.data.experimental.AUTOTUNE\nBATCH_SIZE = 16 * strategy.num_replicas_in_sync\nprint(\"REPLICAS: \", strategy.num_replicas_in_sync)\nTTA = ['rotate0',  'rotate0_lr']\n\ntest_images = pickle.load(open(\"test_images.pkl\",'rb'))\nindex_images = pickle.load(open(\"index_images.pkl\",'rb'))\n\n# Function to decode our images\ndef decode_image(image_data):\n    image = tf.image.decode_jpeg(image_data, channels = 3)\n    image = tf.image.resize(image, IMAGE_SIZE)\n    image = tf.cast(image, tf.float32) \/ 255.0\n    return image\n\n# Function to read our test image and return image\ndef read_image(image):\n    image = tf.io.read_file(image)\n    image = decode_image(image)\n    return image\n\ndef test_time_augmentation(img,tta=None):\n    if tta:\n        if tta[-3:]=='_lr':\n            img = tf.image.flip_left_right(img)\n            tta = tta[:-3]\n\n        if tta[-3:]=='_ud':\n            img = tf.image.flip_up_down(img)\n            tta = tta[:-3]\n    return img\n    \n# Function to get our dataset that read images\ndef get_test_dataset(image_paths,tta=None):\n    dataset = tf.data.Dataset.from_tensor_slices((image_paths))\n    dataset = dataset.map(lambda image_path: read_image(image_path), num_parallel_calls = AUTO)\n    dataset = dataset.map(lambda image: test_time_augmentation(image,tta), num_parallel_calls = AUTO)\n    dataset = dataset.batch(BATCH_SIZE)\n    dataset = dataset.prefetch(AUTO)\n    return dataset\n\n\n### Loading model from zoo\nembed_model = tf.keras.models.load_model(f'..\/input\/google-landmark-model-zoo\/{model_name}.h5', \n                           custom_objects={'KerasLayer': tfhub.KerasLayer})\n\nprint(\"Predicting on image size\",IMAGE_SIZE)\n\nfor i,tta in enumerate(TTA):\n    index_ds = get_test_dataset(index_images,tta)\n    if i==0:\n        index_embeddings = normalize(embed_model.predict(index_ds,verbose=1),axis=1)\n    else:\n        index_embeddings += normalize(embed_model.predict(index_ds,verbose=1),axis=1)\n\nfor i,tta in enumerate(TTA):\n    test_ds = get_test_dataset(test_images,tta)\n    if i==0:\n        test_embeddings = normalize(embed_model.predict(test_ds,verbose=1),axis=1)\n    else:\n        test_embeddings += normalize(embed_model.predict(test_ds,verbose=1),axis=1)\n\nindex_embeddings = normalize(index_embeddings,axis=1)\ntest_embeddings = normalize(test_embeddings,axis=1)\n\nnp.save(f'\/tmp\/{model_name}\/index_embeddings.npy',index_embeddings)\nnp.save(f'\/tmp\/{model_name}\/test_embeddings.npy',test_embeddings)","05e424f5":"model_names = pickle.load(open(\"model_names.pkl\",'rb'))\nmodel_votes = pickle.load(open(\"model_votes.pkl\",'rb'))","f5f5f360":"for model_name in model_names:\n    print(\"Predicting for\",model_name)\n    !mkdir -p \/tmp\/{model_name}\n    !python get_embeddings.py {model_name}","a4b2535c":"%%python\n\nimport numpy as np\nimport pickle\nfrom sklearn.preprocessing import normalize\n\nmodel_names = pickle.load(open(\"model_names.pkl\",'rb'))\nmodel_votes = pickle.load(open(\"model_votes.pkl\",'rb'))\n\nindex_embeddings = []\nfor model_name,vote in zip(model_names,model_votes):\n    index_embeddings.append(np.load(f'\/tmp\/{model_name}\/index_embeddings.npy')*vote)\nindex_embeddings = np.concatenate(index_embeddings,axis=1)\nindex_embeddings = normalize(index_embeddings,axis=1)\nnp.save(f'\/tmp\/index_embeddings.npy',index_embeddings)","b70ebd79":"%%python\n\nimport numpy as np\nimport pickle\nfrom sklearn.preprocessing import normalize\n\nmodel_names = pickle.load(open(\"model_names.pkl\",'rb'))\nmodel_votes = pickle.load(open(\"model_votes.pkl\",'rb'))\n\ntest_embeddings = []\nfor model_name,vote in zip(model_names,model_votes):\n    test_embeddings.append(np.load(f'\/tmp\/{model_name}\/test_embeddings.npy')*vote)\ntest_embeddings = np.concatenate(test_embeddings,axis=1)\ntest_embeddings = normalize(test_embeddings,axis=1)\nnp.save(f'\/tmp\/test_embeddings.npy',test_embeddings)","4121acbd":"for model_name in model_names:\n    !rm -r \/tmp\/{model_name}","da4db0dc":"!du -sh \/tmp\/","17fd6f9a":"import gc\nfrom cuml.neighbors import NearestNeighbors\nmodel_root = '\/tmp\/concatenated-embeddings\/'","7f2e1649":"index_image_ids = [x.split('\/')[-1].split('.')[0] for x in index_images]\ntest_image_ids = [x.split('\/')[-1].split('.')[0] for x in test_images]\nprint(len(index_image_ids),len(test_image_ids))","12e29b3f":"index_embeddings = np.load('\/tmp\/index_embeddings.npy')\nprint(index_embeddings.shape)","98bcae60":"test_embeddings = np.load('\/tmp\/test_embeddings.npy')\nprint(test_embeddings.shape)","c20bfe2b":"train_df = pd.read_csv('..\/input\/glr-validation-metadata\/train.csv')\nlandmark_map = train_df.set_index('id').landmark_id.to_dict()","5325e5dc":"## Find 15*20 neighbours for each index images in batches\nlandmark_knn=15\nindex_distances_file = '\/tmp\/index_distances.dat'\nindex_neighbours_file = '\/tmp\/index_neighbours.dat'\nindex_distances = np.memmap(index_distances_file, dtype='float32', mode='w+', \n                            shape=(len(index_image_ids),landmark_knn*20))\nindex_neighbours = np.memmap(index_neighbours_file, dtype='int32', mode='w+',\n                             shape=(len(index_image_ids),landmark_knn*20))\n\ntest_distances_file = '\/tmp\/test_distances.dat'\ntest_neighbours_file = '\/tmp\/test_neighbours.dat'\ntest_distances = np.memmap(test_distances_file, dtype='float32', mode='w+', \n                            shape=(len(test_image_ids),landmark_knn*20))\ntest_neighbours = np.memmap(test_neighbours_file, dtype='int32', mode='w+',\n                             shape=(len(test_image_ids),landmark_knn*20))\n\nfor part in tqdm(range(20)):\n    train_names = np.load(model_root+f'train-names-{part}.npy')\n    train_embed = np.load(model_root+f'train-predictions-{part}.npy')\n    non_landmark_scores = pd.read_csv(f'..\/input\/glr-non-landmark-scores-for-train-images\/non_landmark_score-{part}.csv',\n                      index_col='id').non_landmark_confidence.to_dict()\n    neighbors_model = NearestNeighbors(n_neighbors = landmark_knn, metric = 'cosine')\n    neighbors_model.fit(train_embed)\n    \n    distances, indices = neighbors_model.kneighbors(index_embeddings)\n    distances = np.abs(distances)\n    func = np.vectorize(lambda x: landmark_map[train_names[x]])\n    neighbours = func(indices)\n    func = np.vectorize(lambda x: non_landmark_scores[train_names[x]])\n    nlr_scores = func(indices)\n    distances = distances-0.4*(1-nlr_scores)\n    start_idx = part*landmark_knn\n    end_idx = (part+1)*landmark_knn\n    index_distances[:,start_idx:end_idx] = distances\n    index_neighbours[:,start_idx:end_idx] = neighbours\n    del indices,distances,neighbours,nlr_scores\n    gc.collect()\n    \n    distances, indices = neighbors_model.kneighbors(test_embeddings)\n    distances = np.abs(distances)\n    func = np.vectorize(lambda x: landmark_map[train_names[x]])\n    neighbours = func(indices)\n    func = np.vectorize(lambda x: non_landmark_scores[train_names[x]])\n    nlr_scores = func(indices)\n    distances = distances-0.4*(1-nlr_scores)\n    start_idx = part*landmark_knn\n    end_idx = (part+1)*landmark_knn\n    test_distances[:,start_idx:end_idx] = distances\n    test_neighbours[:,start_idx:end_idx] = neighbours\n    del train_names, train_embed, neighbors_model,indices,distances,neighbours,nlr_scores\n    gc.collect()","b532d167":"!mkdir -p \/tmp\/index_landmarks\/\n!mkdir -p \/tmp\/test_landmarks\/","3b7e7140":"BATCHSIZE = 10000 # Higher Batchsize -> Faster code, high chances of memory error\nfor start_idx in tqdm(range(0,len(index_distances),BATCHSIZE)):\n    BATCH_distances = index_distances[start_idx:start_idx+BATCHSIZE]\n    BATCH_neighbours = index_neighbours[start_idx:start_idx+BATCHSIZE]\n    names = index_image_ids[start_idx:start_idx+BATCHSIZE]\n\n    BATCH_META = pd.DataFrame(np.stack([BATCH_neighbours.reshape(-1),BATCH_distances.reshape(-1)],\n                                       axis=1),columns=['landmark','distance'])\n    BATCH_META['image_id'] = BATCH_META.index\/\/BATCH_distances.shape[1]\n    BATCH_META['image_id'] = BATCH_META['image_id'].apply(lambda x: names[x])\n    BATCH_META = BATCH_META.sort_values('distance').groupby(['image_id','landmark']).head(2)\n    BATCH_META['confidence'] = 1-BATCH_META['distance']\n    BATCH_META = BATCH_META.groupby(['image_id','landmark']).confidence.sum().sort_values(ascending=False).reset_index()\n    BATCH_META_max = BATCH_META.groupby('image_id').head(1).sort_values(['image_id','landmark'])\n    BATCH_META_max['confidence'] = 0.5\n    BATCH_META = pd.concat([BATCH_META,BATCH_META_max])\n    BATCH_META = BATCH_META.groupby(['image_id','landmark']).confidence.sum().sort_values(ascending=False).reset_index()\n    BATCH_META = BATCH_META.groupby('image_id').head(5).sort_values(['image_id','landmark'])\n    \n    BATCH_META.to_csv(f'\/tmp\/index_landmarks\/index_landmarks_{start_idx}.csv')\n    del BATCH_META,BATCH_META_max\n    gc.collect()","e8d40584":"BATCHSIZE = 10 # Higher Batchsize -> Faster code, high chances of memory error\nfor start_idx in tqdm(range(0,len(test_distances),BATCHSIZE)):\n    BATCH_distances = test_distances[start_idx:start_idx+BATCHSIZE]\n    BATCH_neighbours = test_neighbours[start_idx:start_idx+BATCHSIZE]\n    names = test_image_ids[start_idx:start_idx+BATCHSIZE]\n\n    BATCH_META = pd.DataFrame(np.stack([BATCH_neighbours.reshape(-1),BATCH_distances.reshape(-1)],\n                                       axis=1),columns=['landmark','distance'])\n    BATCH_META['image_id'] = BATCH_META.index\/\/BATCH_distances.shape[1]\n    BATCH_META['image_id'] = BATCH_META['image_id'].apply(lambda x: names[x])\n    BATCH_META = BATCH_META.sort_values('distance').groupby(['image_id','landmark']).head(2)\n    BATCH_META['confidence'] = 1-BATCH_META['distance']\n    BATCH_META = BATCH_META.groupby(['image_id','landmark']).confidence.sum().sort_values(ascending=False).reset_index()\n    BATCH_META_max = BATCH_META.groupby('image_id').head(1).sort_values(['image_id','landmark'])\n    BATCH_META_max['confidence'] = 0.5\n    BATCH_META = pd.concat([BATCH_META,BATCH_META_max])\n    BATCH_META = BATCH_META.groupby(['image_id','landmark']).confidence.sum().sort_values(ascending=False).reset_index()\n    BATCH_META = BATCH_META.groupby('image_id').head(5).sort_values(['image_id','landmark'])\n    BATCH_META.to_csv(f'\/tmp\/test_landmarks\/test_landmarks_{start_idx}.csv')\n    del BATCH_META,BATCH_META_max\n    gc.collect()","efc3f211":"test_landmarks_paths = os.listdir('\/tmp\/test_landmarks\/')\nindex_landmarks_paths = os.listdir('\/tmp\/index_landmarks\/')","9529f325":"index_landmarks = []\nfor index_landmarks_path in tqdm(index_landmarks_paths):\n    index_landmarks.append(pd.read_csv('\/tmp\/index_landmarks\/'+index_landmarks_path,index_col=0))\nindex_landmarks = pd.concat(index_landmarks)\nindex_landmarks.columns = [x+'_index' if x!='landmark' else x for x in index_landmarks.columns]\nprint(index_landmarks.shape)","435c7b7b":"if not IS_PRIVATE:\n    index_landmarks['landmark'] = (index_landmarks['landmark']%10).astype(int)","039c174b":"def db_aug(V, n_neighbors=3):\n    \n    V = normalize(V,axis=1)\n    model = NearestNeighbors(n_neighbors=n_neighbors, metric=\"cosine\")\n    model.fit(V)\n    distances, indices = model.kneighbors(V)\n\n    w = np.power(np.clip(2.0 - distances, 0, 2.0), 0.5)\n    V_tmp = None\n    for i in range(n_neighbors):\n        if V_tmp is None:\n            V_tmp = w[:, i, None]*V[indices[:, i]]\n        else:\n            V_tmp += w[:, i, None]*V[indices[:, i]]\n    V_tmp \/= w.sum(axis=1)[:, None]\n\n    return V_tmp","eb946e21":"all_embeddings = np.concatenate([index_embeddings,test_embeddings])\nall_embeddings = db_aug(all_embeddings, n_neighbors=2)\n# index_embeddings = all_embeddings[:index_embeddings.shape[0]]\ntest_embeddings = all_embeddings[index_embeddings.shape[0]:]\nprint(index_embeddings.shape,test_embeddings.shape)","832b281b":"KNN = min(len(index_embeddings),100)\nneighbors_model = NearestNeighbors(n_neighbors = KNN, metric = 'cosine')\nneighbors_model.fit(index_embeddings)\ndistances, indices = neighbors_model.kneighbors(test_embeddings)\ndistances = np.abs(distances)","b2985ef9":"direct_neighbours = pd.DataFrame(np.stack([np.take(np.array(index_image_ids),indices).reshape(-1),\n                              distances.reshape(-1)],axis=1),columns=['image_id_index','direct_distance'])\ndirect_neighbours['image_id_test'] = np.take(test_image_ids,direct_neighbours.index.values\/\/KNN)\ndirect_neighbours['direct_confidence'] = (1-direct_neighbours.direct_distance.astype(float)).clip(0,1)","3e0217d9":"retrieval_results = []\nfor test_landmarks_path in tqdm(test_landmarks_paths):\n    test_landmarks = pd.read_csv('\/tmp\/test_landmarks\/'+test_landmarks_path,index_col=0)\n    test_image_ids_subset = test_landmarks.image_id.unique()\n    direct_neighbours_subset = direct_neighbours[direct_neighbours.image_id_test.isin(test_image_ids_subset)]\n    if not IS_PRIVATE:\n        test_landmarks['landmark'] = (test_landmarks['landmark']%10).astype(int)\n    test_landmarks.columns = [x+'_test' if x!='landmark' else x for x in test_landmarks.columns]\n    merged_landmarks = pd.merge(test_landmarks,index_landmarks,on='landmark')\n    merged_landmarks['confidence'] = merged_landmarks.apply(lambda row:\n                                                                min(row.confidence_test,row.confidence_index),\n                                                               axis=1)\n    merged_landmarks['bridged_confidence'] = merged_landmarks.confidence\/3\n    merged_landmarks =  merged_landmarks.sort_values(['confidence','confidence_index'],ascending=False).drop_duplicates(\n        ['image_id_test','image_id_index'],keep='first')\n    merged_landmarks = pd.merge(direct_neighbours_subset[['image_id_index','image_id_test','direct_confidence']],\n             merged_landmarks[['image_id_test','image_id_index','bridged_confidence']],\n             on=['image_id_index','image_id_test'],\n            how='outer').fillna(0)\n    merged_landmarks['confidence'] = (merged_landmarks['bridged_confidence'] ** 3) + (merged_landmarks['direct_confidence'] ** 3)\n    merged_landmarks =  merged_landmarks.sort_values(['confidence','bridged_confidence'],ascending=False).drop_duplicates(\n        ['image_id_test','image_id_index'],keep='first')\n    subset = merged_landmarks.groupby('image_id_test').image_id_index.apply(\n        lambda x: \" \".join(x.values)).reset_index()\n    subset.columns = ['id','images']\n    retrieval_results.append(subset)\nretrieval_results = pd.concat(retrieval_results)","80b34e12":"retrieval_results.to_csv('submission.csv',index=False)","66b2b836":"## Finding Bridged Neighbours \n\n### Ensembling direct & bridged neighbours with power average ","75a627c3":"### Documentation - In progress","a916056d":"## Pick top 5 landmarks for each index image","d94f45c9":"## Pick top 300 neighbours from train set for each image in test and index set ","20dfe3f7":"# Part 1: Extracting Embeddings ","9982c6c5":"## Pick top 5 landmarks for each test image","e18bbe1e":"# Part 2: Nearest Neighbour Search","beae7930":"## Finding Direct Neighbours"}}