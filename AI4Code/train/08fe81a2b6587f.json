{"cell_type":{"1861dea7":"code","8cc4e1f6":"code","e8c2aa1e":"code","b6ecb816":"code","879f6035":"code","9df67ca7":"code","1b66a17f":"code","2a5c41db":"code","41095f41":"code","6783a640":"code","b05e5bd3":"code","f79c9000":"code","e8fa3030":"code","578edbeb":"code","14b368ae":"code","3136d664":"code","cfac89b0":"code","23b20860":"markdown","bd4012c4":"markdown","b4aba037":"markdown","c20c006d":"markdown","033e9e6c":"markdown","5b62bdf5":"markdown","e33f7540":"markdown"},"source":{"1861dea7":"#Install TLD Extract Library\n!pip install tldextract -q","8cc4e1f6":"#Generic\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport re\n\n#Extract\nfrom tldextract import extract\n\n#Garbage\nimport gc\n\n#Warnings\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n#SKLearn Libraries\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.metrics import accuracy_score, confusion_matrix,classification_report\nfrom sklearn.feature_extraction.text import TfidfTransformer\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.naive_bayes import MultinomialNB\n\n#WordCloud Generator\nfrom wordcloud import WordCloud,STOPWORDS\n\n#Plotting Library\nimport matplotlib.pyplot as plt\n","e8c2aa1e":"#Load\nurl = '..\/input\/phishing-site-urls\/phishing_site_urls.csv'\ndata = pd.read_csv(url, header='infer')","b6ecb816":"#Custom Explore Function\ndef explore(dataframe):\n    # Shape\n    print(\"Total Records: \", dataframe.shape[0])\n          \n    #Check Missing\/Null\n    x = dataframe.columns[dataframe.isnull().any()].tolist()   \n    if not x:\n        print(\"No Missing\/Null Records\")\n    else:        \n        print(\"Found Missing Records\")","879f6035":"#Explore\nexplore(data)","9df67ca7":"#Custom Function to extract domains\ndef extract_domain(x):\n    tsd, td, tsu = extract(x)\n    y = td + '.' + tsu \n    return td","1b66a17f":"#Extract Domain\ndata['Domain'] = data['URL'].apply(lambda x: extract_domain(x))\n\n#Drop URL Column\ndata.drop('URL', axis=1, inplace=True)\n\n#Re-arranging Columns\ndata = data[['Domain','Label']]","2a5c41db":"#Encode the Polarity Label to convert it into numerical values\nlab_enc = LabelEncoder()\n\n#Applying to the dataset\ndata['Label'] = lab_enc.fit_transform(data['Label'])","41095f41":"#Inspect\ndata.head()","6783a640":"#Splitting the normalized data into train [90%] & test[10%] data\nx_train,x_test,y_train,y_test = train_test_split(data['Domain'], data.Label, test_size=0.1, random_state=0)","b05e5bd3":"# Constructing Pipeline to Extract Features, Transform Count Matrix & then build\/train Model\n\npipe = Pipeline([('vect', CountVectorizer(min_df=0,max_df=1,binary=False,ngram_range=(1,3))),\n                 ('tfidf', TfidfTransformer()),\n                 ('model', MultinomialNB()) ])","f79c9000":"#Train the Model\nmnb_model = pipe.fit(x_train, y_train)","e8fa3030":"# Making Prediction on Test Data & Calculating Accuracy\nmnb_pred = mnb_model.predict(x_test)\nprint(\"Multinomial Naive Bayes Model Accuracy: \",'{:.2%}'.format(accuracy_score(y_test,mnb_pred)))","578edbeb":"# Function to plot word cloud\ndef plot_wordcloud(text, mask=None, max_words=2000, max_font_size=120, figure_size=(12.0,12.0), \n                   title = None, title_size=20, image_color=False):\n\n    wordcloud = WordCloud(background_color='white',\n                    max_words = max_words,\n                    max_font_size = max_font_size, \n                    random_state = 42,\n                    mask = mask)\n    wordcloud.generate(text)\n    \n    plt.figure(figsize=figure_size)\n    if image_color:\n        image_colors = ImageColorGenerator(mask);\n        plt.imshow(wordcloud.recolor(color_func=image_colors), interpolation=\"bilinear\");\n        plt.title(title, fontdict={'size': title_size,  \n                                  'verticalalignment': 'bottom'})\n    else:\n        plt.imshow(wordcloud);\n        plt.title(title, fontdict={'size': title_size, 'color': 'black', \n                                  'verticalalignment': 'top'})\n    plt.axis('off');\n    plt.tight_layout()  \n    \nd = '..\/input\/masks\/masks-wordclouds\/'","14b368ae":"#Creating Seperate Dataframe with Labels & Sampling 1% of the data\ndf_Bad = data[data['Label']==0].sample(frac=0.1, replace=True, random_state=1)\ndf_Good = data[data['Label']==1].sample(frac=0.1, replace=True, random_state=1)","3136d664":"txt = str(df_Bad.Domain)\nplot_wordcloud(txt, max_words=1000, max_font_size=50, \n               title = 'Bad Domain Names', title_size=30)","cfac89b0":"txt = str(df_Good.Domain)\nplot_wordcloud(txt, max_words=1000, max_font_size=50, \n               title = 'Good Domain Names', title_size=30)","23b20860":"## Multinomial Naive Bayes Classifier Model","bd4012c4":"## Word Cloud","b4aba037":"## Data","c20c006d":"## Preprocess\n\nAs part of pre-processing we'll \n\n1. Extract the domain from the URL\n2. Drop URL Column\n3. Re-arrange the columns\n4. Encode the Labels  [0 - Bad, 1 - Good]\n","033e9e6c":"# Phishing URL Classification\n\nIn this notebook, we'll attempt to create a simple Model that will hopefully classify the URL based on its labels (good\/bad). The dataset that we are going to use is [Phishing Site URLs](https:\/\/www.kaggle.com\/taruntiwarihp\/phishing-site-urls). ","5b62bdf5":"## Data Split","e33f7540":"## Libraries"}}