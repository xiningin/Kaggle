{"cell_type":{"b39087b4":"code","cae7271d":"code","e4ea7160":"code","cf7876ba":"code","2a8a42f7":"code","e0e85276":"code","417b9f93":"code","232bc192":"code","9967fec1":"code","0f608e05":"code","7aa16410":"code","3a2a15b4":"code","5ad79d9c":"code","17a677c9":"code","973771d2":"code","83b82ea9":"markdown","ae9f507d":"markdown","096d3c75":"markdown"},"source":{"b39087b4":"import torch\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport pandas as pd\nimport numpy as np\nfrom sklearn.preprocessing import StandardScaler # For Normalization","cae7271d":"device = torch.device(\"cuda\")","e4ea7160":"torch.manual_seed(484)\ntorch.cuda.manual_seed_all(484)","cf7876ba":"x_train = pd.read_csv('\/kaggle\/input\/lol-prediction\/lol.x_train.csv', index_col=0)\ny_train = pd.read_csv('\/kaggle\/input\/lol-prediction\/lol.y_train.csv', index_col=0)\nx_test = pd.read_csv('\/kaggle\/input\/lol-prediction\/lol.x_test.csv', index_col=0)","2a8a42f7":"x_train = np.array(x_train)\ny_train = np.array(y_train)\nx_test = np.array(x_test)\nprint(x_train.shape)\nprint(x_test.shape)","e0e85276":"scaler = StandardScaler() # Normalizer\nx_train = scaler.fit_transform(x_train)\nx_test = scaler.transform(x_test) # Not Fit Transform!\n\nx_train = torch.FloatTensor(x_train)\ny_train = torch.FloatTensor(y_train)\nx_test = torch.FloatTensor(x_test).to(device)","417b9f93":"from torch.utils.data import TensorDataset\nfrom torch.utils.data import DataLoader","232bc192":"train_set = TensorDataset(x_train, y_train)","9967fec1":"data_loader = DataLoader(dataset=train_set,\n                         batch_size=10000,\n                         shuffle=True)","0f608e05":"# DNN \ubaa8\ub378 \uad6c\ucd95\nlinear1 = torch.nn.Linear(48, 32).to(device)\nlinear2=torch.nn.Linear(32,64).to(device)\nlinear3 = torch.nn.Linear(64, 1).to(device)\n\nrelu = torch.nn.LeakyReLU()\nsigmoid = torch.nn.Sigmoid()\ndropout=torch.nn.Dropout(p=0.5)\n\ntorch.nn.init.xavier_uniform_(linear1.weight)\ntorch.nn.init.xavier_uniform_(linear2.weight)\ntorch.nn.init.xavier_uniform_(linear3.weight)\n\n\nmodel = torch.nn.Sequential(linear1, relu, dropout,\n                            linear2, relu, dropout,\n                            linear3, sigmoid)\n\nmodel","7aa16410":"! pip3 install adamp","3a2a15b4":"from adamp import AdamP\ncost = torch.nn.BCELoss().to(device)\noptimizer = AdamP(model.parameters(), lr=1e-2, weight_decay=1e-2)","5ad79d9c":"epochs = 120\nfor epoch in range(1, epochs+1):\n    avg_cost = 0\n    total_batch = len(data_loader)\n\n    for x, y in data_loader: \n        # batch loop\n        x = x.to(device)\n        y = y.to(device)\n\n        optimizer.zero_grad()\n        hypothesis = model(x)\n        cost_val = cost(hypothesis, y)\n        cost_val.backward()\n        optimizer.step()\n\n        avg_cost += cost_val\n    \n    avg_cost \/= total_batch\n\n    if epoch % 10 == 1 or epoch == epochs:\n        print('Epoch {:4d}\/{} Cost: {:.6f}'.format(epoch, epochs, avg_cost.item()))","17a677c9":"with torch.no_grad(): # Don't Calculate Gradient\n    model.eval()\n    x_test = x_test.to(device)\n\n    pred = model(x_test)","973771d2":"pred[pred>=0.5] = 1.0\npred[pred<=0.5] = 0.0\npred = pred.detach().cpu().numpy()\npred = pred.astype(np.uint32)\nid=np.array([i for i in range(pred.shape[0])]).reshape(-1, 1).astype(np.uint32)\nresult=np.hstack([id, pred])\n\nsubmit = pd.DataFrame(result, columns=['id', 'blueWins'])\nsubmit.to_csv('submit.csv', index=False)","83b82ea9":"# AdamP Optimizer\n\uba70\uce60\uc804 \ub124\uc774\ubc84\uc5d0\uc11c \uacf5\uac1c\ud55c \uc2e0\ud1a0\ubd88\uc774 Optimizer\ub97c \uc0ac\uc6a9\ud558\uc600\uc2b5\ub2c8\ub2e4.\n\n[\uad00\ub828\ub9c1\ud06c](https:\/\/clovaai.github.io\/AdamP\/)","ae9f507d":"# baseline v3 (\ubc29\uc5b4):\n\n- \ubaa8\ub378\uad6c\uc870\ub97c 32 -> 32 \uc5d0\uc11c 32 -> 64\ub85c \ubcc0\uacbd\ud558\uc5ec \uaddc\uc81c \uc644\ud654\n- AdamP Optimizer\uc5d0 weight decay\ub97c \uac78\uc5b4 \uaddc\uc81c\n\n99.41% \uc758 \uc815\ud655\ub3c4","096d3c75":"\uac10\uc0ac\ud569\ub2c8\ub2e4."}}