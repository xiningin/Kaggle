{"cell_type":{"babc24d2":"code","f63480c8":"code","92983624":"code","c645b4d1":"code","cfeb9672":"code","2fc2add8":"code","82cde446":"code","e601f946":"code","53acee5d":"code","6e03f6b8":"code","854c94fa":"code","b0bd9dcd":"code","c6211393":"code","0ed61f7b":"code","af3c4d70":"code","795eed5f":"code","6928e239":"markdown","93e9fc3e":"markdown","66e0f7e3":"markdown","4207e7ab":"markdown","887ef243":"markdown","45948096":"markdown","d1eaa7ce":"markdown","90c74e0a":"markdown","7ae05bd4":"markdown"},"source":{"babc24d2":"import os\nimport sys\nfrom tqdm import tqdm, tqdm_notebook\nimport glob\nimport shutil\n\nimport numpy as np\nimport pandas as pd\nimport random\n\nimport matplotlib.pyplot as plt\nimport cv2\n\nimport xml.etree.ElementTree as ET\n\nfrom keras.models import Model\nfrom keras.layers import Input, Dense, Conv2D, Reshape, Flatten\nfrom keras.layers import concatenate, UpSampling2D\nfrom keras.preprocessing.image import image, load_img, ImageDataGenerator\nfrom keras.callbacks import LearningRateScheduler\nfrom keras.optimizers import SGD, Adam\n\nprint(os.listdir(\"..\/input\"))","f63480c8":"img_size = 64\nchannels = 3\nimg_shape = (img_size, img_size, channels)\n\ndim = img_size * img_size * channels     #","92983624":"DIR = os.getcwd()\nDIRimg = \"..\/input\/all-dogs\/all-dogs\"\nDIRanno = \"..\/input\/annotation\/Annotation\"\nDIRout = \"..\/output_images\"","c645b4d1":"def loadImage(fPath, resize = True):\n    img = cv2.imread(fPath)\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)        # BGR to RGB\n    ok = True\n    if resize:\n        xmin,ymin,xmax,ymax = clipImage(fPath)        # clip to square\n        if xmin >= 0:                                 # exist Annotation\n            img = img[ymin:ymax, xmin:xmax, :]        # [h,w,c]\n            # Interpolation method\n            if xmax - xmin > img_size:\n                interpolation = cv2.INTER_AREA            # shrink\n            else:\n                interpolation = cv2.INTER_CUBIC           # expantion\n            img = cv2.resize(img, (img_size, img_size),\n                        interpolation = interpolation)    # resize\n        else:\n            ok = False\n    return ok, img","cfeb9672":"def clipImage(fPath):\n    imgName = os.path.basename(fPath)[:-4].split(\"_\")\n    breed = imgName[0]\n    dog = imgName[1]\n    path = glob.glob(os.path.join(DIRanno, breed + \"*\", breed +\"_\" + dog))\n    if len(path) > 0:\n        tree = ET.parse(path[0])\n        root = tree.getroot()    # get <annotation>\n        size = root.find('size')\n        width = int(size.find('width').text)\n        height = int(size.find('height').text)\n#        objects = root.findall('object')      # ToDo: correspond multi objects\n#        for object in objects:\n        object = root.find('object')\n        bndbox = object.find('bndbox') \n        xmin = int(bndbox.find('xmin').text)\n        ymin = int(bndbox.find('ymin').text)\n        xmax = int(bndbox.find('xmax').text)\n        ymax = int(bndbox.find('ymax').text)\n\n        xmin = max(0, xmin - 4)        # 4 : margin\n        xmax = min(width, xmax + 4)\n        ymin = max(0, ymin - 4)\n        ymax = min(height, ymax + 4)\n\n        w = max(xmax - xmin, ymax - ymin, img_size)   # ideal w\n        \n        if w > min(width, height):\n            xmin = -1; ymin = -1; xmax = -1; ymax = -1;\n        else:\n            w = min(w, width, height)                     # available w\n    \n            if w > xmax - xmin:\n                xmin = min(max(0, xmin - int((w - (xmax - xmin))\/2)), width - w)\n                xmax = xmin + w\n            if w > ymax - ymin:\n                ymin = min(max(0, ymin - int((w - (ymax - ymin))\/2)), height - w)\n                ymax = ymin + w\n\n    else:\n        xmin = -1; ymin = -1; xmax = -1; ymax = -1;       # nothing Annotation\n        \n    return xmin,ymin,xmax,ymax","2fc2add8":"all_fNames = os.listdir(DIRimg)\n\n# train data\nx_train = np.zeros((len(all_fNames),img_size,img_size,3))\nj = 0\nfor i in tqdm(range(len(all_fNames))):\n    path = os.path.join(DIRimg, all_fNames[i])\n#    x_train[i] = loadImage(path)\n    ok, img = loadImage(path)\n    if ok:\n        x_train[j] = img\n        j += 1\n\nprint(j)\nx_train = x_train[:j] \/ 255.","82cde446":"input = Input((10000,))\nx = Dense(2048, activation='elu')(input)\nx = Reshape((8,8,32))(x)\nx = Conv2D(128, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(64, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\nx = Conv2D(32, (3, 3), activation='elu', padding='same')(x)\nx = UpSampling2D((2, 2))(x)\ndecoded = Conv2D(3, (3, 3), activation='sigmoid', padding='same')(x)\n\n# COMPILE\ndecoder = Model(input, decoded)\ndecoder.compile(optimizer=Adam(lr=0.005), loss='binary_crossentropy')\n\n# DISPLAY ARCHITECTURE\ndecoder.summary()","e601f946":"# TRAINING DATA\nids = np.random.randint(0,len(x_train),10000)\n#train_y = x_train[ids, :,:,:].reshape((-1,dim))\ntrain_y = x_train[ids, :,:,:]\ntrain_X = np.eye(10000)","53acee5d":"# TRAIN NETWORK\nlr = 0.01\nbatch = 256; ep = 30; it = 10\nd_loss = []\n\nfor k in range(10):\n    annealer = LearningRateScheduler(lambda x: lr)\n    h = decoder.fit(train_X, train_y, epochs = ep, batch_size = batch,\n                    callbacks=[annealer], verbose=0)\n    d_loss.extend(h.history['loss'])\n    print('Epoch',(k+1)*ep,'\/',ep*it,'  loss =',h.history['loss'][-1], '\/ lr =',lr)\n    if h.history['loss'][-1] \/ h.history['loss'][0] > 0.99: lr = max(lr\/2., 0.0005)\n\nplt.plot(d_loss)\nplt.show()","6e03f6b8":"del x_train, train_y, train_X","854c94fa":"def getDog(ids, mix_rate):\n    imgs = []\n    for id in ids:\n        xx = np.zeros((10000))\n        xx[id] = mix_rate\n        xx[np.random.randint(10000)] = 1.0 - mix_rate\n        imgs.append(decoder.predict(xx.reshape((-1,10000)))[0].reshape(img_shape))\n    return imgs","b0bd9dcd":"def sumple_images(imgs, rows=3, cols=5, figsize=(12,10)):\n    fig, axes = plt.subplots(nrows=rows, ncols=cols, figsize=figsize)\n    for indx, axis in enumerate(axes.flatten()):\n        img = image.array_to_img(imgs[indx])    # ndarray \u2192 PIL\n        imgplot = axis.imshow(img)\n#        axis.set_title(all_fNames[sample_ids[indx]])\n        axis.set_axis_off()\n    plt.tight_layout()","c6211393":"ids = np.random.randint(0,10000, 35)\ng_imgs = getDog(ids, 0.99)\nsumple_images(g_imgs, rows=5, cols=7, figsize=(12,8))","0ed61f7b":"if os.path.exists(DIRout):\n    shutil.rmtree(DIRout)\nif not os.path.exists(DIRout):\n    os.mkdir(DIRout)","af3c4d70":"batch = 64\ne = batch\nid = list(range(10000))\n\nfor s in tqdm(range(0, 10000, batch)):\n    g_imgs = getDog(id[s:e], 0.99)\n    for j in range(batch):\n        img = image.array_to_img(g_imgs[j])    # ndarray \u2192 PIL\n        img.save(os.path.join(DIRout, 'image_' + str(s+j+1).zfill(5) + '.png'))\n        if s+j+1 == 10000:\n            break\n    e += batch\n    \nprint(len(os.listdir(DIRout)))","795eed5f":"shutil.make_archive('images', 'zip', DIRout)","6928e239":"## Train Decoder","93e9fc3e":"## Submit","66e0f7e3":"## Image data loading and clipping Function","4207e7ab":"## Build Decoder","887ef243":"## Generate Dog Images","45948096":"## Delete Training Images","d1eaa7ce":"## Constants","90c74e0a":"## Convert Images to Train Data","7ae05bd4":"## Memorizer_GAN\nI tried to implement Memoraizer_GAN. I feel resistance to this method being GAN.\u3000Rather than generating a \"new\" image, it just seems to be reproducing an image embedded in the network.\u3000This scheme is not Generative \"Adversarial\" Networks. I think it should be classified separately from GAN."}}