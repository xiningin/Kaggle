{"cell_type":{"4eb33169":"code","595e77a1":"code","dc533ad4":"code","f30327c9":"code","815989f2":"code","f654611c":"code","37bc0e93":"code","0e556c92":"markdown","14cf4803":"markdown","c0408024":"markdown","f8a28e22":"markdown","b9c11110":"markdown","15c29ab7":"markdown","3681f779":"markdown"},"source":{"4eb33169":"import numpy as np\nimport pandas as pd\nimport librosa\n\nnp.random.seed(0)","595e77a1":"def load_test_clip(path, start_time, duration=5):\n    return librosa.load(path, offset=start_time, duration=duration)[0]","dc533ad4":"TEST_FOLDER = '..\/input\/birdsong-recognition\/test_audio\/'\ntest_info = pd.read_csv('..\/input\/birdsong-recognition\/test.csv')\ntest_info.head()","f30327c9":"train = pd.read_csv('..\/input\/birdsong-recognition\/train.csv')\nbirds = train['ebird_code'].unique()\nbirds[0:20]","815989f2":"def make_prediction(sound_clip, birds):\n    return np.random.choice(birds)","f654611c":"try:\n    preds = []\n    for index, row in test_info.iterrows():\n        # Get test row information\n        site = row['site']\n        start_time = row['seconds'] - 5\n        row_id = row['row_id']\n        audio_id = row['audio_id']\n\n        # Get the test sound clip\n        if site == 'site_1' or site == 'site_2':\n            sound_clip = load_test_clip(TEST_FOLDER + audio_id + '.mp3', start_time)\n        else:\n            sound_clip = load_test_clip(TEST_FOLDER + audio_id + '.mp3', 0, duration=None)\n\n        # Make the prediction\n        pred = make_prediction(sound_clip, birds)\n\n        # Store prediction\n        preds.append([row_id, pred])\n\n    preds = pd.DataFrame(preds, columns=['row_id', 'birds'])\nexcept:\n    preds = pd.read_csv('..\/input\/birdsong-recognition\/sample_submission.csv')","37bc0e93":"preds.to_csv('submission.csv', index=False)","0e556c92":"# Getting Test Data\n\nThe information on the test audio is given in test.csv. We have outputted that below. The test audio is also contained in the test_audio folder.","14cf4803":"# Possible Birds\n\nThe possible birds can be found in the training set, with the ebird_code feature. Almost all are six letter codes. The first twenty have been outputted below.","c0408024":"# Outputting Submission","f8a28e22":"In this notebook we will import the test data and make a simple prediction.","b9c11110":"# Loading Audio\n\nFirstly, we need to be able to read in five second windows of the test audio. We can do this using librosa. If the audio is from site 3 then we need to whole audio clip, and we can do this by setting duration to None.","15c29ab7":"There are several pieces of information that we are given about the competition and the test set. Two of the important pieces are quoted below.\n\nThe following can be found on the [evaluation page](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/overview\/evaluation):\n> Submissions will be evaluated based on their row-wise micro averaged F1 score.\n> \n> For each row_id\/time window, you need to provide a space separated list of the set of birds that made a call beginning or ending in that time window. If there are no bird calls in a time window, use the code nocall.\n> \n> There are three sites in the test set. Sites 1 and 2 are labeled in 5 second increments, while site 3 was labeled per audio file due to the time consuming nature of the labeling process.\n\nThis explains how we need to structure our submission file. There will be several submissions for each test audio file, split by time windows (5 seconds) - unless they are from site 3.\n\nThe following can be found on the [data page](https:\/\/www.kaggle.com\/c\/birdsong-recognition\/data):\n>The hidden test set audio consists of approximately 150 recordings in mp3 format, each roughly 10 minutes long. The recordings were taken at three separate remote locations. Sites 1 and 2 were labeled in 5 second increments and need matching predictions, but due to the time consuming nature of the labeling process the site 3 files are only labeled at the file level. Accordingly, site 3 has relatively few rows in the test set and needs lower time resolution predictions.\n>\n>Two example soundscapes from another data source are also provided to illustrate how the soundscapes are labeled and the hidden dataset folder structure. The two example audio files are BLKFR-10-CPL_20190611_093000.pt540.mp3 and ORANGE-7-CAP_20190606_093000.pt623.mp3. These soundscapes were kindly provided by Jack Dumbacher of the California Academy of Science's Department of Ornithology and Mammology.\n\nThis is just further information on the test data.","3681f779":"# Making Predictions\n\nWith all of the information we have found so far, it is now possible for us to make predictions. This can be done in different ways depending on your model - for this example we will just be selecting random birds. For each row:\n\n1. Extract the information from test.csv  \n2. Load in the correct clip (using librosa)  \n3. Make a prediction  \n4. Store the prediction  "}}