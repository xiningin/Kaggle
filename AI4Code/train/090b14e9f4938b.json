{"cell_type":{"12226b29":"code","1ce857f9":"code","858200f1":"code","367350ce":"code","e86a0d7e":"code","bf6215c8":"code","cde1ae62":"code","bb50fc21":"code","b5ffb64e":"code","89c57655":"code","15b450d1":"code","6e25d005":"code","286571bb":"code","612ab6b4":"code","b91f3b35":"code","86a9761f":"code","0cc2e717":"code","b4e4c92f":"code","65c18a9e":"code","58f50641":"code","0f8cfb65":"code","c7c95e78":"code","a4c7c491":"code","00fd2060":"code","ba99ba5e":"code","c06a5d40":"code","eff6f398":"code","90724821":"code","437cafd2":"code","4eef4a67":"code","88997719":"code","ea523460":"code","197db825":"code","29178395":"code","51d59761":"code","c91432e5":"code","be1c118d":"code","9bda7e59":"code","645f06c2":"code","cfb74c29":"code","273c128e":"code","f372fa87":"code","d676310b":"code","8aa017a9":"code","ab3ab35a":"code","c2cc4a8e":"code","2b8bf2f3":"code","72d82442":"code","7810c592":"code","05009391":"code","eaf51ac7":"code","c9e69cb1":"code","d1f1f39c":"code","fab52906":"code","db01dc7d":"code","b42940c6":"code","0f92937e":"code","756b6ae4":"code","494a08c3":"code","ceec52c0":"code","ea96c1f9":"code","87eda8b2":"code","b6681a02":"code","6a5831d1":"code","ab38dbb6":"markdown","ec8a0395":"markdown","28173078":"markdown","57cd93f0":"markdown","154802d8":"markdown","bf691df6":"markdown","6bfc543a":"markdown","ce41c3bb":"markdown","6f23225d":"markdown","5ba680d7":"markdown","a3f42c54":"markdown","93aefd34":"markdown","3b1ec3f4":"markdown","4922e303":"markdown","bf3cc4e7":"markdown","fec0d9da":"markdown","50d5fbf9":"markdown","763a70df":"markdown","dbd152f7":"markdown","b839f3c1":"markdown","3f06e78f":"markdown","0b04a81e":"markdown","50810844":"markdown","8991bd26":"markdown","a49ebd1e":"markdown","2602b15d":"markdown","b1e8436c":"markdown","ec6fa90e":"markdown","49baeeb0":"markdown","ad0662ba":"markdown","ed746dff":"markdown","0c406936":"markdown","d10ecd56":"markdown","811391e5":"markdown","41741d4e":"markdown","828fdff0":"markdown","0990e563":"markdown","62af5688":"markdown","6f6d975a":"markdown","8fe1dfe6":"markdown","a0f4fef7":"markdown","adc8f438":"markdown","70b5aa27":"markdown","e03a665b":"markdown","f682bf65":"markdown","f5ad8e07":"markdown","9e1d7ffb":"markdown","55e5f9a0":"markdown","c2e6a272":"markdown","110860fb":"markdown","2c3bf501":"markdown","4b1755ae":"markdown","d68155f7":"markdown","3a64affa":"markdown","642bbcbd":"markdown","34854a67":"markdown","57374759":"markdown","64db8706":"markdown","8f4a8071":"markdown","f0c3ffb7":"markdown","b7abe2ee":"markdown","ad60266f":"markdown","d496e37b":"markdown","8a1c5b35":"markdown","8865842c":"markdown","23551cd4":"markdown","aedd43be":"markdown","63a37037":"markdown","e30301bf":"markdown","10f47e4f":"markdown"},"source":{"12226b29":"# import module\nfrom IPython import display\n\n# display image  from url\ndisplay.Image(url= \"https:\/\/raw.githubusercontent.com\/mojopriest\/mojopriest.github.io\/master\/pratchett.jpg\", width = 600, style= margin-left:auto)","1ce857f9":"# import modules\nimport math\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n#%matplotlib inline\n\nimport seaborn as sns\nimport plotly.express as px\n\n# enable showing all columns and rows\npd.set_option('display.max_columns', None)\npd.set_option('display.max_rows', None)\npd.set_option('display.width', None)\npd.set_option('display.max_colwidth', None)","858200f1":"# upload data to dataframe\ndf = pd.read_csv(\"..\/input\/kaggle-survey-2021\/kaggle_survey_2021_responses.csv\", low_memory = False)\n\n# show dataframe's first three rows\ndf.head(3)","367350ce":"# get dataframe shape\nshape = df.shape\nprint('\\nDataFrame Shape :', shape)\nprint('\\nNumber of rows :', shape[0])\nprint('\\nNumber of columns :', shape[1])","e86a0d7e":"# make a copy of original dataframe\ndf_copy = df.copy()\n\n# select all other rows except the first\ndf_copy = df_copy.tail(25973)","bf6215c8":"# check unique values\ndf_copy['Q15'].unique()","cde1ae62":"# select rows based on existing data\nis_ml = df_copy['Q15'].str.contains('year')\n\n# map values as 0 and 1\nis_ml = is_ml.map({True: 1, False: 0})\n\n# create new dataframe with empty column\ndf_ml = pd.DataFrame(columns=[\"IsML\"])\n\n# create row values for the new column\ndf_ml['IsML'] = np.array(is_ml)\n\n# change all values to integer\n# replace nan values with 0\ndf_ml['IsML'] = df_ml['IsML'].fillna(0).astype(int)\n\ndf_ml.head()","bb50fc21":"# calculate ML user and non-user percentages\nml_perc = df_ml['IsML'].value_counts(normalize=True) * 100\n\nml_perc","b5ffb64e":"# check unique values\ndf_copy['Q1'].unique()","89c57655":"# replace characters\nage_ml = df_copy.Q1.str.replace('-', '.')\nage_ml = age_ml.str.replace('+', '.00')\n\n# create new column\ndf_ml['Age'] = np.array(age_ml)\n\n# the Age column is still in string format\n# convert column datatype to float\ndf_ml[\"Age\"] = df_ml.Age.astype(float)\n\ndf_ml.head()","15b450d1":"# set plot size etc.\nsns.set(rc={'figure.figsize':(16.7,8.27)})\nsns.set(font='sans-serif', palette='colorblind')\n\n# set plot parameters\nplot = sns.countplot(x = 'Age',\n              data = df_ml,\n              order = df_ml['Age'].value_counts().index)\n\n# set plot title etc.\nplot.axes.set_title(\"Kaggle Member Survey 2021: age groups\",fontsize=20)\nplot.set_xlabel(\"Age group\",fontsize=18)\nplot.set_ylabel(\"Number of answers\",fontsize=18)\nplot.tick_params(labelsize=14)\n\n# show plot\nplt.show()","6e25d005":"# calculate age value count percentage\nml_age = df_ml['Age'].value_counts(normalize=True) * 100\n\nml_age","286571bb":"# calculate 'ML=0' and 'ML=1' percentages within age groups\nml_age_group = df_ml.groupby('IsML')['Age'].value_counts(normalize=True) * 100\n\nml_age_group","612ab6b4":"# calculate gender percentage\ngender_perc = df_copy['Q2'].value_counts(normalize=True) * 100\n\ngender_perc","b91f3b35":"# choose rows based on existing data\nis_man = df_copy['Q2'].str.contains('Man')\n\n# map values to 0 and 1\nis_man = is_man.map({True: 1, False: 0})\n\n# create new column\ndf_ml['IsMan'] = np.array(is_man)\n\n# change values to integer\ndf_ml['IsMan'] = df_ml['IsMan'].astype(int)\n\ndf_ml.head()","86a9761f":"# calculate 'ML=0' and 'ML=1' percentages within gender groups\nml_gender_group = df_ml.groupby('IsML')['IsMan'].value_counts(normalize=True) * 100\n\nml_gender_group","0cc2e717":"# check unique locations\ndf_copy['Q3'].unique()","b4e4c92f":"# calculate location percentages\nlocation_perc = df_copy['Q3'].value_counts(normalize=True) * 100\n\n# print first ten list items\nlocation_perc[:10]","65c18a9e":"# check unique location count\nlocation_count = df_copy['Q3'].value_counts()\n\n# print first three list items\nlocation_count[:3]","58f50641":"# print last three list items\nlocation_count[-3:]","0f8cfb65":"# replace selected strings\ndf_ml['Location'] = df_copy['Q3'].replace(['United States of America'],'United States')\ndf_ml['Location'] = df_ml['Location'].replace(['Viet Nam'],'Vietnam')\ndf_ml['Location'] = df_ml['Location'].replace(['United Kingdom of Great Britain and Northern Ireland'],'United Kingdom')\ndf_ml['Location'] = df_ml['Location'].replace(['Iran, Islamic Republic of...'],'Iran')\ndf_ml['Location'] = df_ml['Location'].replace(['Republic of Korea'],'South Korea')\ndf_ml['Location'] = df_ml['Location'].replace(['I do not wish to disclose my location'],'Other')\ndf_ml['Location'] = df_ml['Location'].replace(to_replace='\\(', value=\"\", regex=True)\ndf_ml['Location'] = df_ml['Location'].replace(to_replace='\\)', value=\"\", regex=True)\ndf_ml['Location'] = df_ml['Location'].replace(['Hong Kong S.A.R.'],'Hong Kong')\ndf_ml.fillna('Other', inplace=True)","c7c95e78":"# check unique locations\ndf_ml['Location'].unique()","a4c7c491":"# calculate location percentages\nlist_1 = df_ml['Location'].value_counts(normalize=True) * 100\n\n# percentages to dataframe\ndf_location_temp = list_1.to_frame()\n\n# reset index\ndf_location_temp.reset_index(inplace = True) \n\n# rename columns\ndf_location_temp.rename(columns = {'index':'Location', 'Location': 'Location_Perc'}, inplace = True) \n\n# round values to one decimal\ndf_location_temp['Location_Perc'] = df_location_temp['Location_Perc'].round(decimals=1)\n\ndf_location_temp.head()","00fd2060":"# new dataframe with users having ML experience (IsML == 1)\ndf_is_ml = df_ml[df_ml['IsML'] == 1]\n\ndf_is_ml.head()","ba99ba5e":"# calculate location percentages\nlist_2 = df_is_ml['Location'].value_counts(normalize=True) * 100\n\n# percentages to dataframe\ndf_location_temp_two = list_2.to_frame()\n\n# reset index\ndf_location_temp_two.reset_index(inplace = True) \n\n# rename columns\ndf_location_temp_two.rename(columns = {'index':'Location', 'Location': 'Location_IsML'}, inplace = True) \n\n# round values to one decimal\ndf_location_temp_two['Location_IsML'] = df_location_temp_two['Location_IsML'].round(decimals=1)\n\ndf_location_temp_two.head()","c06a5d40":"# merge dataframes\ndf_ml_location = pd.merge(df_location_temp, df_location_temp_two, on=['Location'],how = 'left')\n\ndf_ml_location.head()","eff6f398":"# calculate new column value\ndf_ml_location['ML_Surplus'] = (df_ml_location['Location_IsML'] - df_ml_location['Location_Perc'])\n\ndf_ml_location.tail()","90724821":"# calculate value counts per country (IsML = 1)\nis_ml_count = df_is_ml['Location'].value_counts()\n\n# make new list\nlist_mlcount = is_ml_count.tolist()\n\n# flatten the list\nlist_mlcount = np.array(list_mlcount).flatten()\n\n# create new column\ndf_ml_location['IsML_Count'] = np.array(list_mlcount)\n\ndf_ml_location.head()","437cafd2":"# new dataframe with no ML experience users (IsML == 0)\ndf_not_ml = df_ml[df_ml['IsML'] == 0]\n\n# calculate value counts per country (IsML = 0)\nnot_ml_count = df_not_ml['Location'].value_counts()\n\n# make new list\nlist_notml = not_ml_count.tolist()\n\n# flatten the list\nlist_notml = np.array(list_notml).flatten()\n\n# create new column\ndf_ml_location['NotML_Count'] = np.array(list_notml)\n\ndf_ml_location.head()","4eef4a67":"# calculate total count\ndf_ml_location['ML_Total_Count'] = (df_ml_location['IsML_Count'] + df_ml_location['NotML_Count'])","88997719":"# calculate percentage of ML users (IsML == 1)\ndf_ml_location['IsML_Perc'] = (df_ml_location['IsML_Count'] \/ df_ml_location['ML_Total_Count']) * 100\n\n# round values to one decimal\ndf_ml_location['IsML_Perc'] = df_ml_location['IsML_Perc'].round(decimals=1)\n\n# calculate percentage of ML non-users (IsML == 0)\n# this is by no means necessary, but rather the oolumn is created for clarity\ndf_ml_location['NotML_Perc'] = (df_ml_location['NotML_Count'] \/ df_ml_location['ML_Total_Count']) * 100\n\n# round values to one decimal\ndf_ml_location['NotML_Perc'] = df_ml_location['NotML_Perc'].round(decimals=1)\n\ndf_ml_location.head()","ea523460":"ml_perc.round(decimals=1)","197db825":"# drop row with now specific residence data (Other)\ndf_ml_location = df_ml_location.drop([2])","29178395":"# sort countries by IsML_Perc column value from highest to lowest\ndf_ml_location = df_ml_location.sort_values(by ='IsML_Perc', ascending=False)\n\n# create new dataframe for plotting\n# select first ten rows\ndf_ml_location_plot_one = df_ml_location.iloc[:10,:]\n\ndf_ml_location_plot_one.head(10)","51d59761":"# plot figure\n# define parameters\nfig = px.bar(df_ml_location_plot_one, x='Location', y='IsML_Perc', text = 'IsML_Perc',\n            hover_data= ['IsML_Count'], color= 'IsML_Perc')\n\n# set graphics\nfig.data[0].marker.line.width = 0.5\nfig.data[0].marker.line.color = \"black\"\n\nfig.update_traces(texttemplate='%{text}', textposition='outside')\nfig.update_layout(uniformtext_mode='hide')  \n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n# set annotations\nannotations = []\n\n# data source\nannotations.append(dict(xref='paper', yref='paper', x=0.88, y=-0.12,\n                              xanchor='center', yanchor='top',\n                              text='Data: Kaggle Member Survey 2021',\n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\n# set plot title\nfig.update_layout(\n    title='<b>Kaggle Member Survey 2021<\/b>:<br>ML method knowledge percentage per location (highest)',\n                font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\n# set axis titles etc.\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n\nfig.update_yaxes(title_text='Percentage')\nfig.update_xaxes(title_text='Location')\n\nfig.update_layout(coloraxis_colorbar=dict(\n    title=\"ML skill percentage\"    \n))\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_xaxes(title_font=dict(size=14))\n\n# show figure\nfig.show()","c91432e5":"# create new dataframe for plotting\n# select last ten rows\ndf_ml_location_plot_two = df_ml_location.iloc[-10: ,:]\n\ndf_ml_location_plot_two.head(10)","be1c118d":"# plot figure\n# define parameters\nfig = px.bar(df_ml_location_plot_two, x='Location', y='IsML_Perc', text = 'IsML_Perc',\n            hover_data= ['IsML_Count'], color= 'IsML_Perc')\n\n# set graphics\nfig.data[0].marker.line.width = 0.5\nfig.data[0].marker.line.color = \"black\"\n\nfig.update_traces(texttemplate='%{text}', textposition='outside')\nfig.update_layout(uniformtext_mode='hide')  \n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n# set annotations\nannotations = []\n\n# data source\nannotations.append(dict(xref='paper', yref='paper', x=0.88, y=-0.20,\n                              xanchor='center', yanchor='top',\n                              text='Data: Kaggle Member Survey 2021',\n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\n# set plot title\nfig.update_layout(\n    title='<b>Kaggle Member Survey 2021<\/b>:<br>ML method knowledge percentage per location (lowest)',\n                font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\n# set axis titles etc.\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n\nfig.update_yaxes(title_text='Percentage')\nfig.update_xaxes(title_text='Location')\n\nfig.update_layout(coloraxis_colorbar=dict(\n    title=\"ML skill percentage\"    \n))\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_xaxes(title_font=dict(size=14))\n\n# show figure\nfig.show()","9bda7e59":"# get population dataset\n# Original dataset is included in Our World In Data project\nurl_two = \"https:\/\/covid.ourworldindata.org\/data\/ecdc\/locations.csv\"\n\n# upload dataset as pandas dataframe\ndf_population = pd.read_csv(url_two)\n\n# drop columns irrelevant to task at hand\ncols = ['countriesAndTerritories', 'population_year', 'continent']\ndf_population = df_population.drop(cols, axis=1)\n\n# rename columns\ndf_population.rename(columns = {'location':'Location', \n                                'population':'Population'}, inplace = True) \n\ndf_population.head(10)","645f06c2":"# change column datatype\ndf_population['Population'] = df_population['Population'].astype(str)\n\n# show datatypes\ndf_population.dtypes","cfb74c29":"# compare the location data between two dataframes\ndf_ml_location[~df_ml_location['Location'].isin(df_population['Location'])]","273c128e":"# merge the two dataframes\ndf_ml_population = pd.merge(df_ml_location, df_population, how='left')\n\n# get dataframe shape\nshape = df_ml_population.shape\nprint('\\nDataFrame Shape :', shape)\nprint('\\nNumber of rows :', shape[0])\nprint('\\nNumber of columns :', shape[1])","f372fa87":"# show rows with nan values\ndf_ml_population[df_ml_population.isna().any(axis=1)]","d676310b":"# update row value\n# row is selected by its index number (10)\ndf_ml_population.loc[10,['Population']] = ['7500700']","8aa017a9":"# convert values to float and after that to integer\ndf_ml_population['Population'] = df_ml_population['Population'].astype(float) \ndf_ml_population['Population'] = df_ml_population['Population'].astype(int) \n\n# show datatypes\ndf_ml_population.dtypes","ab3ab35a":"# sort by Population column value from highest to lowest\ndf_ml_population = df_ml_population.sort_values(by ='Population', ascending=False)\n\ndf_ml_population.head(10)","c2cc4a8e":"# calculate percentage\ndf_ml_population['ML_Per_Population'] = (df_ml_population['IsML_Count'] \/ df_ml_population['Population']) * 100\n\ndf_ml_population.head(10)","2b8bf2f3":"# sort countries by ML_Per_Population\ndf_ml_population = df_ml_population.sort_values(by ='ML_Per_Population', ascending=False)\n\n# create new dataframe for plotting\n# select first ten rows\ndf_ml_population_plot_one = df_ml_population.iloc[:10,:]","72d82442":"# plot figure\n# define parameters\nfig = px.bar(df_ml_population_plot_one, x='Location', y='ML_Per_Population', text = 'IsML_Count',\n            hover_data=['ML_Per_Population'], color= 'ML_Per_Population')\n\n# set graphics\nfig.data[0].marker.line.width = 0.5\nfig.data[0].marker.line.color = \"black\"\n\nfig.update_traces(texttemplate='%{text}', textposition='outside')\nfig.update_layout(uniformtext_mode='hide')  \n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n# set annotations\nannotations = []\n\n# data source\nannotations.append(dict(xref='paper', yref='paper', x=0.88, y=-0.20,\n                              xanchor='center', yanchor='top',\n                              text='Data: Kaggle Member Survey 2021',\n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\n# set plot title\nfig.update_layout(\n    title='<b>Kaggle Member Survey 2021<\/b>:<br>ML method knowledge percentage per population (highest)',\n                font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\n# set axis titles etc.\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n\nfig.update_yaxes(title_text='Percentage')\nfig.update_xaxes(title_text='Location')\n\nfig.update_layout(coloraxis_colorbar=dict(\n    title=\"ML per population\"    \n))\n\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_xaxes(title_font=dict(size=14))\n\n# show figure\nfig.show()","7810c592":"# create new dataframe for plotting\n# select last ten rows\ndf_ml_population_plot_two = df_ml_population.iloc[-10: ,:]","05009391":"# plot figure\n# define parameters\nfig = px.bar(df_ml_population_plot_two, x='Location', y='ML_Per_Population', text = 'IsML_Count',\n            hover_data=['ML_Per_Population'], color= 'ML_Per_Population')\n\n# set graphics\nfig.data[0].marker.line.width = 0.5\nfig.data[0].marker.line.color = \"black\"\n\nfig.update_traces(texttemplate='%{text}', textposition='outside')\nfig.update_layout(uniformtext_mode='hide')  \n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n# set annotations\nannotations = []\n\n# data source\nannotations.append(dict(xref='paper', yref='paper', x=0.88, y=-0.20,\n                              xanchor='center', yanchor='top',\n                              text='Data: Kaggle Member Survey 2021',\n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\n# set plot title\nfig.update_layout(\n    title='<b>Kaggle Member Survey 2021<\/b>:<br>ML method knowledge percentage per population (lowest)',\n                font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\n# set axis titles etc.\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n\nfig.update_yaxes(title_text='Percentage')\nfig.update_xaxes(title_text='Location')\n\nfig.update_layout(coloraxis_colorbar=dict(\n    title=\"ML per population\"    \n))\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_xaxes(title_font=dict(size=14))\n\n# show figure\nfig.show()","eaf51ac7":"# calculate column average value\nml_count_average = df_ml_population['ML_Total_Count'].mean()\n\nml_count_average","c9e69cb1":"# create new dataframe based on column value condition\ndf_ml_population_plot_three = df_ml_population.loc[df_ml_population['ML_Total_Count'] >= ml_count_average]\n\n# get dataframe shape\nshape = df_ml_population_plot_three.shape\nprint('\\nDataFrame Shape :', shape)\nprint('\\nNumber of rows :', shape[0])\nprint('\\nNumber of columns :', shape[1])","d1f1f39c":"df_ml_population_plot_three.head(14)","fab52906":"# select first ten rows\ndf_ml_population_plot_three = df_ml_population_plot_three.iloc[:10,:]","db01dc7d":"# plot figure\n# define parameters\nfig = px.bar(df_ml_population_plot_three, x='Location', y='ML_Per_Population', text = 'IsML_Count',\n            hover_data=['ML_Per_Population'], color= 'ML_Per_Population')\n\n# set graphics\nfig.data[0].marker.line.width = 0.5\nfig.data[0].marker.line.color = \"black\"\n\nfig.update_traces(texttemplate='%{text}', textposition='outside')\nfig.update_layout(uniformtext_mode='hide')  \n\nfig.update_layout(\n    yaxis=dict(\n        showline=True,\n        linecolor='rgb(204, 204, 204)',\n        linewidth=2,\n        ticks='outside',\n        tickfont=dict(\n            family='Arial',\n            size=12,\n            color='rgb(82, 82, 82)',\n        )))\n\n# set annotations\nannotations = []\n\n# data source\nannotations.append(dict(xref='paper', yref='paper', x=0.88, y=-0.20,\n                              xanchor='center', yanchor='top',\n                              text='Data: Kaggle Member Survey 2021',\n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\n# set plot title\nfig.update_layout(\n    title='<b>Kaggle Member Survey 2021<\/b>:<br>ML method knowledge percentage per population (385+ respondents)',\n                font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\n# set axis titles etc.\nfig.update_xaxes(showgrid=False)\nfig.update_yaxes(showgrid=True, gridwidth=1, gridcolor='LightGrey')\n\nfig.update_yaxes(title_text='Percentage')\nfig.update_xaxes(title_text='Location')\n\nfig.update_layout(coloraxis_colorbar=dict(\n    title=\"ML per population\"    \n))\n\nfig.update_yaxes(title_font=dict(size=14))\nfig.update_xaxes(title_font=dict(size=14))\n\n# show figure\nfig.show()","b42940c6":"# get population dataset\n# original dataset by Kaggle member Paul Mooney\nurl_three = \"..\/input\/latitude-and-longitude-for-every-country-and-state\/world_country_and_usa_states_latitude_and_longitude_values.csv\"\n\n# create dataframe\ndf_coordinates = pd.read_csv(url_three)\n\n# select columns\ndf_coordinates = df_coordinates.loc[:,['latitude', 'longitude', 'country']]\n\n# rename columns\ndf_coordinates.rename(columns = {'latitude':'Lat', 'longitude': 'Long', 'country': 'Location'}, inplace = True)\n\ndf_coordinates.head()","0f92937e":"# compare the location data between two dataframes\ndf_ml_population[~df_ml_population['Location'].isin(df_coordinates['Location'])]","756b6ae4":"# merge the two dataframes\ndf_ml_map = pd.merge(df_ml_population, df_coordinates, how='left')\n\n# get dataframe shape\nshape = df_ml_map.shape\nprint('\\nDataFrame Shape :', shape)\nprint('\\nNumber of rows :', shape[0])\nprint('\\nNumber of columns :', shape[1])","494a08c3":"# show rows with nan values\ndf_ml_map[df_ml_map.isna().any(axis=1)]","ceec52c0":"# get column max value\nmax_ml = df_ml_map[\"IsML_Count\"].max()\n\nmax_ml","ea96c1f9":"# plot figure\nfig = px.choropleth(df_ml_map, locations=\"Location\",\n                    projection=\"natural earth\", locationmode=\"country names\", title=\"<b>Kaggle Member Survey 2021<\/b>:<br>ML knowledge per respondents\", color=\"IsML_Count\",\n                    template=\"plotly\", color_continuous_scale=\"peach\",range_color=[0,max_ml] )\n\nannotations = []\n\n# source\nannotations.append(dict(xref='paper', yref='paper', x=0.88, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Data: Kaggle Member Survey 2021',\n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_layout(coloraxis_colorbar=dict(\n    title=\"ML skills\"    \n))\n\nfig.show()","87eda8b2":"# get column max value\nmax_population = df_ml_map[\"ML_Per_Population\"].max()\n\nmax_population","b6681a02":"# calculate value\nmax_map = max_population * 10000\n\nmax_map","6a5831d1":"# plot figure\n# color value is modified before plotting\nfig = px.choropleth(df_ml_map, locations=\"Location\",\n                    projection=\"natural earth\", locationmode=\"country names\", title=\"<b>Kaggle Member Survey 2021<\/b>:<br>ML knowledge per population\", \n                    color= df_ml_map[\"ML_Per_Population\"] * 10000, template=\"plotly\", color_continuous_scale=\"peach\",range_color=[0,max_map] )\n\nannotations = []\n\n# source\nannotations.append(dict(xref='paper', yref='paper', x=0.88, y=-0.07,\n                              xanchor='center', yanchor='top',\n                              text='Data: Kaggle Member Survey 2021',\n                              font=dict(family='arial narrow',\n                                        size=8,\n                                        color='rgb(96,96,96)'),\n                              showarrow=False))\n\nfig.update_layout(annotations=annotations)\n\nfig.update_layout(\n    font=dict(family='calibri',\n                                size=12,\n                                color='rgb(64,64,64)'))\n\nfig.update_layout(coloraxis_colorbar=dict(\n    title=\"ML skills\"    \n))\n\n\nfig.show()","ab38dbb6":"As we can see, India is indeed the global hotspot when ML knowledge on Kaggle is concerned. Also, my conscience started to hurt again because of the color of Finland.\n\nJust for comparison, with the final globe we will use the per capita **ML_Per_Population** column value as criterion, after we first seek out the maximum value (Singapore) in the column.","ec8a0395":"As we are interested in specific locations with highest ML knowledge percentage, we will sort all locations by their machine learning skills and then select the ten highest ML percentages. For plotting purposes, we will also create a separate dataframe **df_ml_location_plot_one**.","28173078":"The result - here deliberately showing the tail end of our dataframe - does not really differ from previous results. The percentage of Kaggle members with ML knowledge and overall member percentage on Kaggle is very much similar regardless of the individual place of reside.\n\nNext we will take another approach and analyze the same thing by using the value counts per individual location. In this case the results should however be taken with a pinch of digital salt, since we know beforehand that there is for example some 170 times more data on Kaggle members from India compared to their peers residing in Ethiopia.","57cd93f0":"Finally, we add the total number of Kaggle members grouped by their place of reside. ","154802d8":"It seems that only the youngest age group (18-21) of people who answered the survey has a slight increase in *lacking* ML method knowledge compared to the percentage of the age group. Among \"non-ML\" Kaggle members, the proportion of 18-21-olds is about 25 percent whereas their overall percentage of all Kaggle members is slightly less (about 19 percent). \n\nHowever we can generally conclude that ***on Kaggle age is not a major defining factor when it comes to ML method knowledge***. As mentioned, ***people arriving at Kaggle are most likely following their topic of interest and are therefore often \"pre-equipped\" with at least some ML knowledge***.\n\n<br><br>\n******","bf691df6":"Perhaps the most notable thing here is that even the individual location with relatively lowest percentage of ML skilled members (Ukraine) has a percentage of 73.2, which is in fact significantly high. \n\nLet's see this data further to plot form.","6bfc543a":"We will need to select only users with ML experience. Again for clarity's sake we will do this in a separate dataframe **df_is_ml**.","ce41c3bb":"### 2. Data Exploration <a class=\"anchor\" id=\"chapter_2\"><\/a>","6f23225d":"\nAs we are to plot graphics based on specific place of reside, it seems legitimate to drop the \"Other\" row from our dataset, so let's start with that before continuing. As we know, the row in question is located in row index number 2, we will use that information as our condition.","5ba680d7":"As null values (NaN) were about to be added, let's check if this actually happened.","a3f42c54":"Being a Finnish person myself, I definitely felt a pinch in my conscience when first taking a look at the country data. As I missed the survey deadline myself and only countries or territories with 50 respondents received their own location tag *(see Kaggle dataset appendix \"Survey Methodology\")*, I unwittingly may have with my non-actions erased my own country from the unique locations list. On the other hand, analyzing self-created data could also be considered as a bias, like writing a review of your own novel, so I will soldier on with the data at hand.\n\nNext we will check the percentages of different unique locations and print out the top ten locations based on value count.","93aefd34":"### 6. Population and ML <a class=\"anchor\" id=\"chapter_6\"><\/a>\n\nTo answer this question we need world population data, so let's start with that. It is notable though that this sort of population data can never be fully accurate, since it is based on national census data. In fact, in population-rich large countries such as China or India, any census data is basically old on arrival because of the sheer scale of the task, with census data compiling lasting often for years rather than months. \n\nThe population data we are going to use in our dataframe **df_population** is retrieved from **Our World In Data** (*link:* __[Our World In Data](https:\/\/ourworldindata.org\/)__) open source project.","3b1ec3f4":"We can see that ***over 76 percent of Kaggle members included in the survey dataset have at least some experience on ML methods***. To me this is as such an important discovery since it suggests that ***people on Kaggle either already possess ML method knowledge on arrival or start to acquire it right after that***. \n\nIt would definitely be interesting to see if the time spent on Kaggle has something to do with ML knowledge. Unfortunately there was no data in the survey for example about the exact time people have been affiliated with Kaggle, so there is no meaningful way of learning more details on this.\n\nConsidering the nature of Kaggle as data-oriented community, the widespread ML knowledge level is probably not a big surprise though. In similar manner there are hordes of sports enthusiasts on their own fan sites, metalheads on heavy rock online forums etc. \n\nRegarding the research question, this fact does make the dataset inevitably biased, since there is significantly more data on ML experienced people. However, since this is the existing reality on Kaggle and the analysis is all about Kaggle members, furthermore this aspect will not be considered as a deficiency. \n\n<br><br>\n******","4922e303":"It would be interesting to know more about machine learning knowledge within particular age group, so let's see those figures next.","bf3cc4e7":"As the population data is now in numeric form, we can sort the dataframe based on population.","fec0d9da":"At least in countries with most Kaggle members the figures are pretty much identical. As we can see, for example Japan's overall share of Kaggle members is 3.5 percent, and their portion of ML knowledgeable members on Kaggle is 3.6 percent, which is well in the range of any statistical error.\n\nNext we subtract the **Location_isML** column value from **Location_Perc** column value and store the result to a new column **ML_Surplus**. If the new column value is positive, it means that the user ML knowledge in that specific location surpasses the same location's overall relative member representation on Kaggle i.e. creating an \"ML surplus\".","50d5fbf9":"As we can see, Kaggle members with ML method knowledge are divided similarly to overall gender percentage. Among those with no ML experience, the percentage of men decreased from 80 percent to 74 percent, which indicates that **among women and other \"not-men\" gender choices the lack of ML method knowledge is slightly more common**. However the change in percentages is not radically different.\n\n<br><br>\n******","763a70df":"#### 1.4 Research question <a class=\"anchor\" id=\"chapter_1_4\"><\/a>\n\nIn last year's Kaggle Survey competition I basically analyzed where Kaggle users are *not* from, what age are they *not* etc. This year - already preoccupied with the above themes concerning machine learning - I decided to go for a slightly different approach. \n\n***My main point of interest in this notebook is the 15th question (Q15) in the survey (\"For how many years have you used machine learning methods?\")***. I was intrigued by the fact that *there were no additional questions regarding specific purposes of people using ML*. Secondly, ***the first answer option (\"I do not use machine learning methods\") seemed to me like a potential \"digital divide\", defined here as lack of adequate physical, economical, educational etc. resources to information technology.*** \n\nIf the use of various AI and ML applications is to rapidly increase in the near future as it seems, those on the other side of that divide will inevitably \"sink\" or be defined as \"0\" for example by any job recruit ML application compared to those getting \"1\" in the same appraisal. Also, the programmed machine learning application would - being completely unaware of it - be guilty of applicant favoritism based on its own existence. (\"*My name is ML. Do you know me or how I work? No? Ok, next applicant, please.*\")\n\nBased on all this, ***my research question is to find out if there are common factors between Kaggle members not familiar with machine learning methods***. Conversely, ***I will also search for potential similarities in Kaggle users with at least some ML methods experience*** by their own admission. To attain this, I will deliberately create the aforementioned digital divide and classify Kaggle members as \"0\" and \"1\" when it comes to ML knowledge.\n\nThat's already a full plate so let's start enjoying, or *itadakimasu*, as they say in Japan before delicious meal.\n<br>\n<br>\n***November 5th, 2021***<br>\n***Jari Peltola***\n\n<br><br>\n******","dbd152f7":"# Learning about machine learning: Kaggle member survey 2021 analysis","b839f3c1":"Now we have Kaggle members divided in ones and zeroes based on their self-reported ML experience. First it would be interesting to know the percentage of Kaggle people familiar with ML methods.","3f06e78f":"The next plot will be all about locations with lowest value in **IsML_Perc** column, so we will need to select those values instead and create new dataframe **df_ml_location_plot_two**.","0b04a81e":"Now we know that our new location column is lacking Hong Kong population data. This does not however prevent us from merging the two dataframes, but we know already that null values will be created in the Hong Kong row in the process. \n\nNext a new dataframe **df_ml_population** is created based on Kaggle member individual location data and our new population data. Left merge here means that all 64 locations included in our Kaggle survey data (left) are included, but *only data about those specific Kaggle locations* is retrieved from the larger population dataframe (right). \n\nTo make sure we got it right, we also check that the merged dataframe still consists of 64 rows.","50810844":"For clarity, a new dataframe **df_location_temp** with the unique locations as index is created.","8991bd26":"#### 1.1 The possibilities of ML <a class=\"anchor\" id=\"chapter_1_1\"><\/a>\n\nThis notebook and particularly its research question first came to being thanks to my Japanese language studies as I was watching the Japanese drama series *Japan Sinks: People of Hope* (*Nippon Chinbotsu: Kibo no Hito*) the other night (*link:* __[series Wikipedia article](https:\/\/en.wikipedia.org\/wiki\/Japan_Sinks:_People_of_Hope)__). The series - as its revealing title suggests - is the latest reboot of the 1973 disaster novel by **Sakyo Komatsu** with the same title (*link:* __[novel Wikipedia article](https:\/\/en.wikipedia.org\/wiki\/Japan_Sinks)__).\n\nAs a published novelist myself,  my original motive for learning more about data analysis was strictly personal: I was in the middle of writing a new book and needed information no one else seemed to be in possession of. Thanks to for example the well-constructed Kaggle crash courses, I now know a little something also about machine learning (ML) methods. \n\nHowever I noticed that even in the updated *Japan Sinks* drama series rendition, in the story analyzing and modeling geological data is something almost magical, something only a handful of dedicated specialists can do. Most people in the series still rely on either Japanese government or journalists and news agencies to passively receive fateful information about the future of their sinking homeland (*not a spoiler thanks to series title*).\n\nContrary to this, as Kaggle has effectively proven with its own existence over the past few years, ***skills concerning different aspects of data analysis can actually have an empowering effect***. Instead of relying on others for facts and hypotheses, people can now do it all themselves. When put in professional use, these methods may potentially lead to for example life-saving machine learning and artificial intelligence (AI) applications for better breast cancer screening (*link:* __[Forbes article](https:\/\/www.forbes.com\/sites\/jenniferhicks\/2021\/10\/06\/heres-how-artificial-intelligence-can-help-predict-breast-cancer-risk\/?sh=351a9dbd4bec)__).\n\nThus in my mind there's no doubt that machine learning can be applied in numerous ways that significantly benefit peoples' lives. To me the value of Kaggle lies in the fact that ***increasing data analysis and machine learning knowledge also increases the ability for critical thinking i.e. recognizing misinformation, deliberately biased interpretations and falsely applied methods***. As the recent COVID-19 vaccination discourse has effectively proved to be true, even these skills may end up being of life-saving nature. \n","a49ebd1e":"#### 1.2 The limits of ML <a class=\"anchor\" id=\"chapter_1_2\"><\/a>\n\nOne of the most talked about recent topics concerning data science has been about setting international regulations for using AI and ML as well as safeguards on applications considered as \"risky\" (*link:* __[AP News article](https:\/\/apnews.com\/article\/artificial-intelligence-technology-business-europe-ursula-von-der-leyen-19ec99f8a970fe14a99a84d52017ec22)__). Also, there is the existing debate on the \"inbound\" limits of AI and computers in general. As **Robert J. Marks** argued to **Larry Linenschmidt** in his podcast episode (*link:* __[podcast article](https:\/\/mindmatters.ai\/2020\/08\/six-limitations-of-artificial-intelligence-as-we-know-it\/)__), these limitations are as following:\n<br><br>\n- ***Computers (and AI) are limited to algorithms.***<br>\n- ***Computers are faster than before but not more intelligent.***<br>\n- ***Computers only make use of data which they\u2019ve been presented.***<br>\n- ***Computers don\u2019t experience things or make judgements.***<br> \n- ***Computers do exactly what they were programmed to do.***<br>\n\nIf one thinks about for example the case of *Japan Sinks*, more than often in the series plot AI and ML possess almost supernatural powers similar to what electricity was once considered to have, or what nuclear technology made people imagine in 1950s classic sci-fi stories (*some half of all Marvel's superheroes seem to have been created by different nuclear accidents*). \n\n***This mental image of AI and ML as a \u201cgo-to-solution\u201d to every possible problem is largely fictional. Yet this line of thinking has a profound effect on what people expect AI and ML to do for them in reality.*** As another example, just think about the mental image of flying cars. Although no such inventions have so far existed in reality, many people are genuinely disappointed that this feature of flying is not included in their current commuter vehicles as a default setting.","2602b15d":"The second globe presentation is a bit more evenly distributed regarding hotspots, telling us that on Kaggle ML method knowledge is indeed spread relatively globally. Most of Africa is however deprived of this, along with my home country Finland. As noted earlier, this may in part be because of the threshold of 50 respondents used in the Kaggle survey for gaining individual location tag.\n\n<br><br>\n******","b1e8436c":"It seems that there are no naming issues, so we can move on by merging the two dataframes and checking null values. As a precaution we also check the dataframe shape, which should still consist of 64 rows.","ec6fa90e":"Now we can find out the user percentanges divided by ML knowledge and gender.","49baeeb0":"The numbers above bars in the plot are derived from the **IsML_Count** column to describe how many individual Kaggle members are actually included in the figure. As suspected, the most populous countries\/regions are not among the top selection.\n\nIn similar manner, next we plot the smallest **ML_Per_Population** values and create a separate dataframe **df_ml_population_plot_two** for this purpose.","ad0662ba":"### 5. ML and Location <a class=\"anchor\" id=\"chapter_5\"><\/a>\n\nLet's take a look at whether the place of reside (column **Q3**) will make any difference regarding our research question.","ed746dff":"No unexpected null values or other issues showed up so we're \"OK to go\", as **Ellie Arroway** proclaimed in the modern sci-fi classic *Contact*. As we are producing an analysis based on Kaggle member survey, next the Kaggle members with ML knowledge will be projected on a digital globe. The maximum value of the color range will be set to match the maximum value in the **IsML_Count** column (5699), which is the number of ML knowledgeable Kaggle members in India.","0c406936":"Next we will modify the original survey data before bringing it in to our own dataframe. For better compatibility as well as readability, some individual country names are replaced with new versions. Also, the \"Other\" and \"I do not wish to disclose my location\" options in the original data are both combined under \"Other\". ","d10ecd56":"Apparently we also stepped right into political hornet's nest in our analysis. ***The population data we use does not include specific value regarding Hong Kong, since it includes only countries***. However the Kaggle survey has the location data as \"place of residence\", as the term goes. \n\nAs we are talking about one row only, the Hong Kong number of residents (7500700, estimated) is next added manually to the dataframe after first retrieving the value from the Hong Kong dedicated Wikipedia page: (*link:* __[Hong Kong Wikipedia article](https:\/\/en.wikipedia.org\/wiki\/Hong_Kong)__) \n\nThis is by no means ideal a method, but for our purposes this can be considered as a sufficient one-off task. In addition, we should probably also subtract the same number of people from China's population, but since it would not profoundly alter China's population and we know that census data in general is never totally accurate, we'll leave it for now.  ","811391e5":"After importing the modules, we upload the survey data to a dataframe **df**.","41741d4e":"Let find out more about the size of different age groups in visual form.","828fdff0":"Of course, everything we see above is based on Kaggle member survey data only. ***What would happen for example if we combined this data with world population data and calculated ML method familiarity based on that? Where in the world is machine learning knowledge on relatively highest level?***\n\n<br><br>\n******","0990e563":"When the whole location population is concerned, China falls second to last in relative ML knowledge. Of course the same would happen in any similar comparison because of the sheer relative size of Chinese population.\n\nOne other possibility would be to apply some sort of threshold similar to what was done in the original dataset regarding individual locations (50 survey entries were required for attaining individual location tag). Next, *only locations with higher than average number of ML method related answers to the 2021 Kaggle member survey* are selected for further analysis. After selecting the locations, their population and ML knowledge will be further made into visual presentation.\n\nTo begin with, this average number of respondents is needed, so we will print that. The column we are interested in this case is **ML_Total_Count**, since it includes the answers both from ML knowledgeable and non-ML Kaggle members. ","62af5688":"#### 8.1 The present of ML <a class=\"anchor\" id=\"chapter_8_1\"><\/a>\n\nThe question of who (which location or country) holds the \"ML throne\" on Kaggle can be answered in different ways, and the answer is dependent on the method used, as we saw before. Region-wise, as as working hypothesis, for example the relatively high ML knowledge in Australia compared to New Zealand or any nearby regions may be affected by the large community of Chinese etc. students living in Australia. After all, in the Kaggle survey the place of residence was under inquiry instead of nationality, so no further analysis on the subject matter was in this case possible.\n\nIt is also good to remember that in many cases the location-specific data in the Kaggle survey was based on a relatively small number of members even with the threshold of 50 individual members per individual location. Also, everyone included in the survey did not necessarily answer the question about ML knowledge.\n\nConcluding the analysis, we can argue the following based on our data:\n\n- ***There is no significant correlation between ML knowledge and the age, gender or place of reside of a particular Kaggle member***.\n- ***A Kaggle member has a 76.5 percent average probability of being ML knowledgeable regardless of the aforementioned personal details.***\n\nThus on global scale - remembering our research question about \"ML divide\" - one could actually argue that this divide is widest when Kaggle members and \"non-Kaggle people\" are compared. ","6f6d975a":"As a precautionary measure, it would be good to know if our new dataset includes all the 64 locations included in our unique Kaggle locations. We can do this by comparing the two **Location** columns in our two dataframes.\n\nFor this I will use the \".isin\" feature, which predictably checks whether a string or value in dataframe A is included also in dataframe B. However, since we are interested in locations that are *not included* in the **Our World In Data** set, the tilde character (~) is thrown into the mix. It effectively renders the query to something like \".isnotin\".","8fe1dfe6":"In this case we are interested only in *whether* a Kaggle member uses machine learning methods, not *how long* those methods have been in use. Therefore it is practical to create a new column with value \"0\" if the person does not possess ML experience and \"1\" if he or she is familiar with the subject matter. \n\nThere are several ways (lambda function etc.) for doing this, but in this case I will make use of the original unique answer choices we just printed. As the string \"year\" is included only in answers with ML experience, those answers will be mapped as \"1\" based on the string. \n\nFurthermore, I would still like to keep the answers with null values (nan) in ML experience column because of the data included in other columns. Here I will also make the general assumption that no one answering the Kaggle survey wanted to keep their true ML experience as a secret, and map those null values as \"0\" as well.\n\n***In some special cases hiding one's ML abilities may actually be necessary***. After the latest Taliban takeover, in Afghanistan hundreds of girls and women continue to learn coding online and in hidden makeshift classrooms (*link:* __[Al Jazeera article about Afghanistan](https:\/\/www.aljazeera.com\/news\/2021\/10\/29\/afghanistan-girls-coding-underground-taliban-education?sf153637013=1)__). As one Afghan woman described her situation in the article: \u201c*when online, you can be locked at home and explore the virtual world without any hesitation, without worrying about geographical boundaries. That\u2019s the beauty of technology.*\u201d \n\nTaking a look at the other columns while keeping in mind the research question, ***the member age, gender and location columns would seem to provide us most potentially interesting information***. As for other columns, for example ***social media use may not be a question of personal choice, since the access to some social media platforms is restricted in certain parts of the world*** (*link:* __[Al Jazeera article about Belarus](https:\/\/www.aljazeera.com\/news\/2021\/10\/29\/belarus-classifies-social-media-channels-as-extremist?sf153665818=1)__).\n\nAlso, ***income as a universal criterion would not work since the value of money is different depending on location***. For example, the GDP per capita in Ethiopia is 2772 USD (*link:* __[Ethiopia Wikipedia article](https:\/\/en.wikipedia.org\/wiki\/Ethiopia)__), whereas the same figure in Norway (*link:* __[Norway Wikipedia article](https:\/\/en.wikipedia.org\/wiki\/Norway)__) is 64856 USD, rendering the two figures basically incomparable with each other. \n\nAs for occupation, without any analysis a strong hypothesis can be made for example about the positive correlation of data scientists and machine learning knowledge. Thus studying this feature feels like writing a young adult novel *The Adventures of Captain Obvious*, so it's better to move on.\n\nThe different questions regarding software applications would indeed give us a more clear conception on ML knowledgeable members since the applications in question are used in machine learning. However, as our research question concerns the divide between \"ML members\" and \"non-ML members\", those survey answers are in our case less relevant. \n\nThe survey dataset does include an abundance of different kinds of data, so for clarity's sake I will next create a new dataframe **df_ml** with **IsML** as its first column.  ","a0f4fef7":"### 1. Introduction <a class=\"anchor\" id=\"chapter_1\"><\/a>","adc8f438":"For clarity, we also create another column with value counts of those Kaggle members with no ML experience. Let's start by creating a similar dataframe as before, but in this time we select only those users with value \"0\" in the **IsML** column.","70b5aa27":"As the total number of survey answers was 25973, we can quickly count that one percent of answers equals roughly to about 260 members. Excluding the \"Other\" location, only 23 countries in the world have a proportion bigger than one percent among Kaggle survey answers. Taking a look the two value counts below, we can see that number of answers ranges from 43 (Iraq and Ethiopia) to 7434 (India).","e03a665b":"As the same data divided by percentage shows, some two thirds of Kaggle members who took part in the survey are of age 35 years or less.  ","f682bf65":"Our first point of interest in the dataframe is the aforementioned **Q15** column. Let's see the unique values in it. ","f5ad8e07":"#### 8.2 The future of ML <a class=\"anchor\" id=\"chapter_8_2\"><\/a>\n\nThis of course raises the following question concerning the future:\n\n- ***If more people should become aware of Kaggle (and other similar ML online communities) and join in, would this by itself have more effect on overall population ML knowledge than the individual features included in the current member survey data? In other words, is Kaggle membership actually the very threshold we were just looking for when \"ML divide\" is concerned?***\n\nA good starting point would be to further study the significance of Kaggle membership and ML knowledge more closely. For example, as suggested earlier:\n\n- ***Future surveys could include more detailed questions for example about how long an individual member has been affiliated with Kaggle. That data could then be compared with answers concerning specific ML method knowledge and the timeline of possessing that knowledge.***\n\nShould the analysis prove that these two features indeed correlate with each other, an argument could be made that a significant portion of Kaggle members have gained their ML skills thanks to joining the Kaggle community in the first place. Or one might ask people directly something like \"*What Kaggle courses have you taken or plan to take?* \". \n\nRegarding future courses, a more exploratory question could inquire Kagglers for example if there are any new course topics they would be interested in. This whole wider theme of *why* people chose to join Kaggle in the first place is to me perhaps the most intriguing aspect that has not been a specific topic of inquiry in Kaggle surveys so far.\n\nAs we started this data journey from Japan, it seems that the people there didn't just actually wait for the whole place to sink. Again this was not major news since it is hard to find a nation with more creative people full of unique ideas than Japan. Recently a local start-up company developed a hoverbike which uses machine learning in stabilizing the vehicle (*link:* \n__[BBC article](https:\/\/www.bbc.com\/news\/technology-59065674)__). Cars may still not fly, but now there is something to fly over them. As the analyst interviewed by the BBC said regarding the project, \"*things that once seemed like science fiction are becoming more tangible every year* \".\n\n\n\n*Arigato gozaimashita* and thank you for your time.\n\n<br><br>\n***Jari Peltola***<br>\n***Finland***<br>\n\n<br><br>\n******\n","9e1d7ffb":"#### 1.3 The ethical dimension of ML <a class=\"anchor\" id=\"chapter_1_3\"><\/a>\n\nThere is also the ethical aspect of applying AI and ML. Because flying cars are not available, let's imagine a logistical ML application designed for transferring groups of people from place A to place B. For example in commuting or post-pandemic travel industry, well-functioning global logistics undoubtedly result in better customer satisfaction as well as in various cost savings (fuel and energy consumption etc.).\n\n*But what happened if the very same application would be given the task on how to efficiently transfer people to concentration camp facilities?*\n\nProbably the application would calculate most direct routes, efficient hubs and correct connections without any problem, since the data would not include the actual experience or moral context of the task. There would be no need for the computer to defend its actions, since the computer would only do exactly what it was programmed to do. However, only in slightly different words, the very same argument were presented - not by a computer but by a human defendant - in the Nuremberg trial (*link:* __[Nuremberg trial article](https:\/\/famous-trials.com\/Nuremberg)__):\n\n**\"*I was given this assignment which I could not refuse.*\"** \n**(Fritz Sauckel, Chief of Slave Labor Recruitment)**\n\nMoreover, presented only with logistical data, an AI judge application would probably have concluded that the very defendant was not guilty, since the AI app would not have found any procedural errors. Based on this, we can conclude that there can be both positive and negative aspects regarding the use of AI and ML. ***The decision of how and when ML applications are used still falls in the hands of the people***, no matter how evolved a system we are talking about. After all, ***the computer cannot refuse the task it is given***.\n\nThe appropriate role of humans in all this is not to imitate AI and ML strengths but, rather, compensate their weaknesses. In the end computing power is all about calculations, but that\u2019s not how human brain or human life in general works. This was effectively proven for example by the protagonist **Arthur Dent** in **Douglas Adams's** novel *The Hitchhiker\u2019s Guide To Galaxy*, when Arthur crashed the most powerful computer in the universe by giving it the menial task of making a decent cup of tea. Our thinking, laced sometimes with mere suspicions and vague speculations, does not comply with the rigid terms of machine learning, and neither should this be the case. In the end, ***it is the people who came up with machine learning, not the other way***.\n\n**But what was the specific research question that came to my mind while watching** \n***Japan Sinks ?*** ","55e5f9a0":"As even the maximum value of this column is very small, all the values in the column will next be multiplied by ten thousand. After that, these values will create the map color definition value scale.\n\nThis is mainly to make the mouse hover-on values more readable in the map. Instead of near-zero decimals, that value will now be roughly set between zero and 22. Also, as all this will be done *while plotting our globe only*, none of our actions will have an effect on the actual dataframe row content.\n\nThe maximum value we will use in color scheme is the following:","c2e6a272":"Just like we did earlier with the **Our World In Data** locations, next we check if our existing Kaggle location data is consistent with locations included in the new coordinates dataframe.","110860fb":"### 4. ML and Gender <a class=\"anchor\" id=\"chapter_4\"><\/a>\n\nLet's take a closer look at ML knowledge when gender (column **Q2**) is considered. First we need the overall gender percentages of Kaggle members according to survey answers.","2c3bf501":"Almost 80 percent of people answering the survey defined themselves as men, as we can see. Earlier we found out that over 75 percent of Kaggle members possess some level of ML method knowledge. Next we will find out the correlation between gender and ML knowledge. The \"Nonbinary\" and \"Prefer to self-describe\" choices combined make about 0.5 percent of total answers, and together with \"Prefer not to say\" the percentage of these three choices is about 2 percent of all answers.\n\nBased on this, next the gender data will be remodeled in our dataframe to a column **IsMan** with binary values 0 and 1. Again we can attain this by making use of the string data in survey answers.","4b1755ae":"Based on this, as a condition, only locations with a value 385 or higher in the **ML_Total_Count** column will be included in the new dataframe **df_ml_population_plot_three**. We will also check how many rows i.e. locations we are actually talking about.","d68155f7":"### 8. Conclusion <a class=\"anchor\" id=\"chapter_8\"><\/a>","3a64affa":"It's always good to know the overall shape (number of rows and columns) of the dataframe right from the start.","642bbcbd":"Since we now have the total count in our dataframe, we can calculate ML knowledgeable as well as \"non-ML\" member percentages per individual location.","34854a67":"To preserve the original dataframe as such, next we make a copy of it and call it rather unimaginatively **df_copy**. As we don't need the actual survey questions in our analysis, we also select the 25973 *last* rows from the survey dataset, leaving the first row including questions out. ","57374759":"Right now we don't need population as numeric value, so we temporarily convert it into an object. This is by any means not necessary, but merging dataframes sometimes affects numeric decimal value formats, thus making them harder to read. When numeric values are required later, we can easily transform back again.","64db8706":"In the original dataset, age groups are in format \"xx-yy\". This does not enable treating them as what they actually are: numerical entities.\n\nBy changing the \"-\" character to a common dot, age groups become decimal figures in format \"xx.yy\". Finally, by replacing the \"+\" character with double zero in the \"70+\" category, all groups will maintain their preferred order also after the transformation. \n\nFor clarity's sake, we will store the freshly formatted column values in our dataframe as **Age** and change all the column values to numeric format. ","8f4a8071":"\n**TABLE OF CONTENTS**<br>\n\n* [1. Introduction](#chapter_1)\n    - [1.1 The possibilities of ML](#chapter_1_1)\n    - [1.2 The limits of ML](#chapter_1_2)\n    - [1.3 The ethical dimension of ML](#chapter_1_3)\n    - [1.4 Research question](#chapter_1_4)\n* [2. Data Exploration](#chapter_2)\n* [3. ML and Age](#chapter_3)\n* [4. ML and Gender](#chapter_4)\n* [5. ML and Location](#chapter_5)\n* [6. Population and ML](#chapter_6)\n* [7. ML Goes Global](#chapter_7) \n* [8. Conclusion](#chapter_8)\n    - [8.1 The present of ML](#chapter_8_1)\n    - [8.2 The future of ML](#chapter_8_2)","f0c3ffb7":"As we can see, in the group of locations with 385 or more respondents, Spain comes on top with most ML skilled Kaggle members per population. As a general notion, we could see that ***the results we get on any queries based on ML method knowledge are directly dependent on the method used in attaining them. As noted in the beginning, the computer only does exactly as it was told to do.***\n\nIf we come back to survey data, as the final population-related visual representation in this notebook we will create a world map based on the number of ML knowledgeable Kaggle members living in different regions.\n\n<br><br>\n******","b7abe2ee":"Next we can calculate location percentage based on users with ML experience. The result is dataframe **df_location_temp_two** including member location and ML knowledge percentage as columns.","ad60266f":"Let's make visual presentations of locations with highest percentage in **isML_Perc column**. We know that our \"base values\" to compare any results with are about 76.5 percent for ML knowledge users and 23.5 percent for non-ML users, as this information was attained before.","d496e37b":"As before, for plotting we will first sort the values and then create a separate dataframe **df_ml_population_plot_one**.","8a1c5b35":"### 3. ML and Age <a class=\"anchor\" id=\"chapter_3\"><\/a>\n\nNext we take a look at the age column **Q1** in the survey.","8865842c":"### 7. ML Goes Global <a class=\"anchor\" id=\"chapter_7\"><\/a>\n\nTo do this, specific country\/region coordinates are required. The source we can get the necessary data from is... ***Kaggle***, thanks to **Paul Mooney** (*link:* __[Paul Mooney's Kaggle profile](https:\/\/www.kaggle.com\/paultimothymooney)__) and his carefully constructed dataset available for everyone to make use of.\n","23551cd4":"Next we calculate the per capita percentage of ML method knowledge based on population and store the values in new column **ML_Per_Population**. After that we will make visual presentations on the top and bottom values as two separate plots.","aedd43be":"A bit earlier we transformed our population values to objects (string), so now is a good time to reformat them to numeric again. Next we will convert the population values to numeric (float), and since no decimals are required, we will further convert the .float values as integers (.int). ","63a37037":"Suddenly, we are left with only fourteen locations. Let's plot the top ten of these locations by using the **ML_Per_Population** column value as criterion, with the highest value on top of the pile. The number above each bar will be retrieved from the **IsML_Count** column.","e30301bf":"Finally, the dataframes **df_location_temp** and **df_location_temp_two** are merged to a newly created **df_ml_location** dataframe by using the identical **Location** column included in both dataframes. The **Location_Perc** column will include the overall percentage of Kaggle members per location, whereas **Location_IsML** column will tell us the percentage of Kaggle members with ML knowledge in that same location.","10f47e4f":"Even before creating any plots, we can see that most of the **Location_Perc** as well as **ML_Total_Count** column values are low. This means that we are talking about relatively small amount of Kaggle members. For example, in this comparison the location on top position has a total of 35 Kaggle members who answered the ML skills question in the first place. From that amount, 29 people (82.9 percent) informed having some sort of ML experience. Thus a number of Kaggle members equal to one classroom full of enthusiastic ML students basically carried the whole nation with them to top position.\n\nHowever, this was again more or less the expected result, since we knew already that ML knowledge is evenly distributed among Kaggle members regardless of their place of reside. Because of this, ***a single Kaggle member with ML skills is statistically more significant in locations with less amount of total Kaggle members*** i.e. the least represented individual locations included in the survey dataset.\n\nIn the plot below, the hover-on mouse data shows values in columns **Location**, **IsML_Perc** and **IsML_Count**."}}