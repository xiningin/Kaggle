{"cell_type":{"000847e3":"code","20b2b5e1":"code","88f4fa0a":"code","a3a8e1d3":"code","8d0bd464":"code","7acc9e16":"code","97892292":"code","07c0695c":"code","f6f33719":"code","f2c5b079":"code","66a8027f":"code","b813bbb2":"code","c76fa46c":"code","351a1ae8":"code","8aad3e2f":"code","80630a89":"code","be64d7c3":"code","3c86a220":"code","bbdb0e15":"code","4fb1b549":"code","b22733e6":"code","6139d49c":"code","0fd0059c":"code","e6611153":"code","a3e32474":"code","4208da87":"code","5117533f":"code","a5a851e9":"code","5b58d7a9":"code","65208267":"code","693672ed":"code","bf0c0a3d":"code","c3569b10":"code","9389a832":"code","3cdef36e":"code","b4546ed9":"code","89769a3b":"code","b428d7ee":"code","e9280c16":"code","df6feeb0":"code","eca7c93e":"code","1310b3db":"code","eb2805a7":"code","8ea08d27":"code","a495368d":"code","5ca19ab2":"code","54d685d3":"code","406862f1":"code","cf54e186":"code","c22e1057":"code","180aafea":"code","a9fe335a":"code","e782000d":"code","e514d213":"code","335a20f8":"markdown","d08384f1":"markdown","2cae7676":"markdown","ce07b21a":"markdown","fb7eac98":"markdown","b4e2e048":"markdown","d3e24900":"markdown","6883cad3":"markdown","7e420fc7":"markdown","fa7dfa1e":"markdown","196c9aaf":"markdown","7a4d4abf":"markdown"},"source":{"000847e3":"import sys, os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set_style('whitegrid')\n%matplotlib inline\nimport warnings\nwarnings.filterwarnings('ignore')\nimport sklearn.metrics as skm\nimport sklearn.model_selection as skms\nimport sklearn.preprocessing as skp\nimport random, os\nimport librosa, IPython\nimport librosa.display as lplt\nfrom skimage.io import imread\nseed = 12\nnp.random.seed(seed)","20b2b5e1":"trainPath = '\/kaggle\/input\/audio-speech-sentiment\/TRAIN\/'\ntestPath = '\/kaggle\/input\/audio-speech-sentiment\/TEST\/'\ndf_base = pd.read_csv('\/kaggle\/input\/audio-speech-sentiment\/TRAIN.csv')\ndf_base.head()","88f4fa0a":"print(\"Dataset has\",df_base.shape[0],\"samples\")\nprint(\"Count of Positive and Negative samples\")\ndf_base['Class'].value_counts().reset_index()","a3a8e1d3":"sample_rate = 44100\ndef loadAudio(fp):\n    return librosa.load(fp, res_type='kaiser_fast', duration=2.5, offset=0.5, sr=sample_rate)","8d0bd464":"def scanFeatures(path, avgFeat=0):\n    features = []\n    minFeat = sys.maxsize\n    maxFeat = 0\n    files = sorted(os.listdir(path))\n    print(\"Scanning\", path)\n\n    for i, fp in enumerate(files):\n        X, sr = loadAudio(os.path.join(path, fp))\n\n        f = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n        f = librosa.amplitude_to_db(f, ref=np.max)\n\n        shapeY = f.shape[1]\n        if shapeY < minFeat:\n            minFeat = shapeY\n\n        if shapeY > maxFeat:\n            maxFeat = shapeY\n\n        features.append(f)\n    if avgFeat == 0:\n        avgFeat = int((minFeat+maxFeat)\/2)\n    feat_mat = np.zeros((len(files), f.shape[0], avgFeat))\n    for i, x in enumerate(features):\n        xWidth = min(x.shape[1],avgFeat)\n        feat_mat[i, :, :xWidth] = x[:,:xWidth]\n    return feat_mat, files","7acc9e16":"f_dim = 128\ntrain_data, train_files = scanFeatures(trainPath, f_dim)\ntest_data, test_files = scanFeatures(testPath, train_data.shape[1])\nprint(train_data.shape)\nprint(test_data.shape)","97892292":"def saveImg(f, fp):\n    f = np.flip(f, axis=0)\n    plt.figure()\n    plt.axis('off')\n    plt.imsave(fp, f, format='png')\n    plt.clf()","07c0695c":"def saveFeatureToImage(path, saveDir, avgFeat=0):\n    global sample_rate\n    files = sorted(os.listdir(path))\n    print(\"Scanning\", path)\n\n    for i, fp in enumerate(files):\n        X, sr = loadAudio(os.path.join(path, fp))\n\n        f = librosa.feature.melspectrogram(y=X, sr=sample_rate)\n        f = librosa.amplitude_to_db(f, ref=np.max)\n\n        img = np.zeros((f.shape[0], avgFeat))\n        xWidth = min(f.shape[1],avgFeat)\n        img[:, :xWidth] = f[:,:xWidth]\n        fname = os.path.join(saveDir, fp.split('.')[0] + '.png')\n        saveImg(img, fname)","f6f33719":"f_dim = 128\ntrain_img_dir = '.\/train_images'\ntest_img_dir = '.\/test_images'\nif not os.path.exists(train_img_dir):\n    os.mkdir(train_img_dir)\n    saveFeatureToImage(trainPath, train_img_dir, f_dim)\nif not os.path.exists(test_img_dir):\n    os.mkdir(test_img_dir)\n    saveFeatureToImage(testPath, test_img_dir, train_data.shape[1])","f2c5b079":"def scanImgFeatures(path):\n    features = []\n    files = sorted(os.listdir(path))\n    for x in files:\n        fp = os.path.join(path, x)\n        img = imread(fp)[:,:,:3]\/255.0\n        features.append(img)\n    return np.array(features), files","66a8027f":"if os.path.exists(train_img_dir):\n    train_data_img, train_files_img = scanImgFeatures(train_img_dir)\nif os.path.exists(test_img_dir):\n    test_data_img, test_files_img = scanImgFeatures(test_img_dir)\n    plt.imshow(test_data_img[0])\n    plt.show()","b813bbb2":"def getPathLabels(p):\n    return [df_base[df_base['Filename'] == x].iloc[0,1] for x in p]","c76fa46c":"train_labels = getPathLabels(train_files)","351a1ae8":"audio_fp = '\/kaggle\/input\/audio-speech-sentiment\/TRAIN\/1.wav'\naudio_data, sr = loadAudio(audio_fp)\naudio_data, _ = librosa.effects.trim(audio_data)","8aad3e2f":"# play sample file\nIPython.display.Audio(audio_data, rate=sr)","80630a89":"# plot sample file\nplt.figure(figsize=(15,5))\nlplt.waveplot(audio_data)\nplt.show()","be64d7c3":"# Default FFT window size\nn_fft = 2048 # window size\nhop_length = 512 # window hop length for STFT\n\nstft = librosa.stft(audio_data, n_fft=n_fft, hop_length=hop_length)\nstft_db = librosa.amplitude_to_db(stft, ref=np.max)\n\nplt.figure(figsize=(12,4))\nlplt.specshow(stft, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()\nplt.title(\"Spectrogram with amplitude\")\nplt.show()\n\nplt.figure(figsize=(12,4))\nlplt.specshow(stft_db, sr=sr, x_axis='time', y_axis='log', cmap='cool')\nplt.colorbar()\nplt.title(\"Spectrogram with decibel log\")\nplt.show()","3c86a220":"melspec = librosa.feature.melspectrogram(audio_data, sr=sample_rate)\nmelspec_db = librosa.amplitude_to_db(melspec, ref=np.max)\n\nplt.figure(figsize=(12,4))\nlplt.specshow(melspec, sr=sr, x_axis='time', y_axis='hz')\nplt.colorbar()\nplt.title(\"Spectrogram with amplitude\")\nplt.show()\n\nplt.figure(figsize=(12,4))\nlplt.specshow(melspec_db, sr=sr, x_axis='time', y_axis='log', cmap='cool')\nplt.colorbar()\nplt.title(\"Spectrogram with decibel log\")\nplt.show()","bbdb0e15":"# map labels to index\nlabel_index = dict()\nindex_label = dict()\nfor i, x in enumerate(df_base['Class'].unique()):\n    label_index[x] = i\n    index_label[i] = x\nprint(label_index)\nprint(index_label)","4fb1b549":"# update labels in df to index\ntrain_labels_idx = [label_index[l] for l in train_labels]\ntrain_labels_idx[::10]","b22733e6":"# shuffle samples\ndf_shuffle = df_base.sample(frac=1, random_state=seed).reset_index(drop=True)","6139d49c":"# remove irrelevant columns\ndf_shuffle.drop(['Filename'], axis=1, inplace=True)\ndf_y = df_shuffle.pop('Class')\n\n# split into train dev and test\ny_train, y_test = skms.train_test_split(df_y, train_size=0.8, random_state=seed, stratify=df_y)","0fd0059c":"print(f\"Train set has {y_train.shape[0]} records out of {len(df_shuffle)} which is {round(y_train.shape[0]\/len(df_shuffle)*100)}%\")\nprint(f\"Test set has {y_test.shape[0]} records out of {len(df_shuffle)} which is {round(y_test.shape[0]\/len(df_shuffle)*100)}%\")","e6611153":"# stratified split check\nprint(y_train.value_counts())\nprint(y_test.value_counts())","a3e32474":"# divide train_data into X_train and X_test\nX_train = train_data[y_train.index.tolist(), :, :]\nX_test = train_data[y_test.index.tolist(), :, :]\nX_test.shape","4208da87":"# divide train_data_img into X_train_img and X_test_img\nX_train_img = train_data_img[y_train.index.tolist(), :, :]\nX_test_img = train_data_img[y_test.index.tolist(), :, :]\nX_test_img.shape","5117533f":"y_train = np.array([train_labels_idx[x] for x in y_train.index.tolist()])\ny_test = np.array([train_labels_idx[x] for x in y_test.index.tolist()])\ny_train[::10]","a5a851e9":"# scale features\nscaler = skp.MinMaxScaler()\nX_train = scaler.fit_transform(X_train.reshape(-1, X_train.shape[-1])).reshape(X_train.shape)\nX_test = scaler.transform(X_test.reshape(-1, X_test.shape[-1])).reshape(X_test.shape)\ntest_data = scaler.transform(test_data.reshape(-1, test_data.shape[-1])).reshape(test_data.shape)\nprint(X_train.shape)","5b58d7a9":"import tensorflow as tf\nprint(\"TF version:-\", tf.__version__)\nimport keras as k\nfrom keras import backend as K\ntf.random.set_seed(seed)","65208267":"bestModelPath = '.\/best_model.hdf5'\nACCURACY_THRESHOLD = 0.98\n\nclass myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True\n\nacc_callback = myCallback()\n\n\ndef trainModel(model, epochs, optimizer, vb=1):\n    cbs = [#k.callbacks.ReduceLROnPlateau(patience=5, verbose=1), \n           k.callbacks.ModelCheckpoint(filepath=bestModelPath, monitor='val_loss', verbose=1, save_best_only=True)]\n    batch_size = 64\n    callback = myCallback()\n    model.compile(optimizer=optimizer,\n                  loss='sparse_categorical_crossentropy',\n                  metrics='accuracy'\n    )\n    return model.fit(X_train, y_train, \n#                      validation_data=(X_test, y_test), \n                     epochs=epochs, verbose=vb,\n                     validation_split=0.2,\n                     batch_size=batch_size, callbacks=cbs)\n\ndef plotHistory(history):\n    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n    pd.DataFrame(history.history).plot(figsize=(12,6))\n    plt.show()","693672ed":"model_1 = k.models.Sequential([\n    k.layers.Conv1D(256, 8, padding='same', activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n#     k.layers.Conv1D(256, 8, padding='same', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Dropout(0.2),\n    k.layers.MaxPooling1D(pool_size=(8)),\n    k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n#     k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n#     k.layers.Conv1D(128, 8, padding='same', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Dropout(0.2),\n    k.layers.MaxPooling1D(pool_size=(5)),\n#     k.layers.Conv1D(64, 8, padding='same', activation='relu'),\n    k.layers.Conv1D(64, 8, padding='same', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Flatten(),\n#     k.layers.Dense(64, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n])\nprint(model_1.summary())\nmodel_1_history = trainModel(model=model_1, epochs=50, optimizer='adam', vb=0)","bf0c0a3d":"plotHistory(model_1_history)","c3569b10":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","9389a832":"model_2 = k.models.Sequential([\n    k.layers.Conv1D(256, 5, activation='relu', input_shape=(X_train.shape[1], X_train.shape[2])),\n    k.layers.BatchNormalization(),\n    k.layers.Dropout(0.3),\n    k.layers.MaxPooling1D(pool_size=(2)),\n    k.layers.Conv1D(128, 3, activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Dropout(0.3),\n    k.layers.MaxPooling1D(pool_size=(3)),\n    k.layers.Conv1D(64, 3, activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Flatten(),\n    k.layers.Dense(32, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n])\nprint(model_2.summary())\nmodel_2_history = trainModel(model=model_2, epochs=100, optimizer='adam', vb=0)","3cdef36e":"plotHistory(model_2_history)","b4546ed9":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","89769a3b":"model_3 = k.models.Sequential([\n    k.layers.Bidirectional(k.layers.LSTM(256, return_sequences=True), input_shape=(X_train.shape[1], X_train.shape[2])),\n\n    k.layers.Bidirectional(k.layers.LSTM(128, return_sequences=False)),\n\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dropout(0.2),\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dropout(0.2),\n    k.layers.Dense(32, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n])\nprint(model_3.summary())\nmodel_3_history = trainModel(model=model_3, epochs=100, optimizer='rmsprop', vb=0)","b428d7ee":"plotHistory(model_3_history)","e9280c16":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","df6feeb0":"# make features 3D with last dim as 1 for 1DConv\nX_train = np.expand_dims(X_train, axis=3)\nX_test = np.expand_dims(X_test, axis=3)\nX_train.shape","eca7c93e":"model_4 = k.models.Sequential([\n    k.layers.Conv2D(256, (5,5), activation='relu', input_shape=(X_train.shape[1], X_train.shape[2], 1)),\n    k.layers.BatchNormalization(),\n    k.layers.MaxPooling2D(pool_size=(2)),\n    k.layers.Dropout(0.3),\n    k.layers.Conv2D(128, (3,3), activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.MaxPooling2D(pool_size=(2)),\n    k.layers.Dropout(0.3),\n    k.layers.Conv2D(64, (3,3), padding='valid', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Flatten(),\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n\n])\nprint(model_4.summary())\nmodel_4_history = trainModel(model=model_4, epochs=50, optimizer='adam', vb=0)","1310b3db":"plotHistory(model_4_history)","eb2805a7":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","8ea08d27":"inputShape = (X_train.shape[1], X_train.shape[2], 1)\nmodel_5 = k.models.Sequential([\n    k.layers.TimeDistributed(k.layers.Conv1D(256, 5), input_shape=inputShape),\n    k.layers.TimeDistributed(k.layers.BatchNormalization()),\n    k.layers.TimeDistributed(k.layers.MaxPooling1D((2))),\n    k.layers.TimeDistributed(k.layers.Dropout(0.3)),\n\n    k.layers.TimeDistributed(k.layers.Conv1D(128, 3), input_shape=inputShape),\n    k.layers.TimeDistributed(k.layers.BatchNormalization()),\n    k.layers.TimeDistributed(k.layers.MaxPooling1D((2))),\n    k.layers.TimeDistributed(k.layers.Dropout(0.3)),\n    k.layers.TimeDistributed(k.layers.Flatten())\n\n], name=\"conv_3d7\")\n\nmodel_5.add(k.layers.Bidirectional(k.layers.LSTM(256, return_sequences=True)))\nmodel_5.add(k.layers.Dropout(0.3))\n\nmodel_5.add(k.layers.Bidirectional(k.layers.LSTM(128)))\nmodel_5.add(k.layers.Dropout(0.3))\n\nmodel_5.add(k.layers.Dense(64, activation='relu'))\nmodel_5.add(k.layers.Dropout(0.3))\n\nmodel_5.add(k.layers.Dense(len(index_label), activation='softmax'))\n\nprint(model_5.summary())\nmodel_5_history = trainModel(model=model_5, epochs=100, optimizer='adam', vb=0)","a495368d":"plotHistory(model_5_history)","5ca19ab2":"# evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","54d685d3":"modelPath = '.\/best_model.hdf5'\nACCURACY_THRESHOLD = 0.95\n\nclass myCallback(k.callbacks.Callback):\n    def on_epoch_end(self, epoch, logs={}):\n        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):\n            print(\"\\n\\nStopping training as we have reached %2.2f%% accuracy!\" %(ACCURACY_THRESHOLD*100))   \n            self.model.stop_training = True\n\nacc_callback = myCallback()\n\ncbs = [#k.callbacks.ReduceLROnPlateau(patience=3, verbose=1), \n       k.callbacks.ModelCheckpoint(filepath=modelPath, monitor='val_loss', verbose=1, save_best_only=True)]\n\ndef trainImgModel(model, epochs, optimizer, vb=1):\n    batch_size = 64\n    callback = myCallback()\n    model.compile(optimizer=optimizer,\n                  loss='sparse_categorical_crossentropy',\n                  metrics='accuracy'\n    )\n    return model.fit(X_train_img, y_train, \n                     validation_data=(X_test_img, y_test), epochs=epochs, verbose=vb,\n                     batch_size=batch_size, callbacks=cbs)\n\ndef plotHistory(history):\n    print(\"Max. Validation Accuracy\",max(history.history[\"val_accuracy\"]))\n    pd.DataFrame(history.history).plot(figsize=(12,6))\n    plt.show()","406862f1":"model_6 = k.models.Sequential([\n    k.layers.Conv2D(256, 3, activation='relu', input_shape=(128, 128, 3)),\n    k.layers.BatchNormalization(),\n    k.layers.MaxPooling2D(pool_size=(2)),\n    k.layers.Dropout(0.2),\n    k.layers.Conv2D(128, 3, activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.MaxPooling2D(pool_size=(2)),\n    k.layers.Dropout(0.2),\n    k.layers.Conv2D(64, 3, padding='same', activation='relu'),\n    k.layers.BatchNormalization(),\n    k.layers.Flatten(),\n    k.layers.Dense(64, activation='relu'),\n    k.layers.Dense(len(index_label), activation='softmax'),\n\n])\nprint(model_6.summary())\nmodel_6_history = trainImgModel(model=model_6, epochs=100, optimizer='rmsprop', vb=0)","cf54e186":"plotHistory(model_6_history)","c22e1057":"# model evaluation\ntest_loss, test_acc  = k.models.load_model(bestModelPath).evaluate(X_test_img, y_test, batch_size=128)\nprint(\"The test Loss is :\",test_loss)\nprint(\"The test Accuracy is :\",test_acc*100)","180aafea":"# test_data = np.expand_dims(test_data, axis=3)","a9fe335a":"predictions = np.argmax(k.models.load_model(bestModelPath).predict(test_data_img), axis=1)\npredictions","e782000d":"df_sub = pd.DataFrame({\n    'Filename': test_files,\n    'Class': list(map(lambda x:index_label[x], predictions))\n})\ndf_sub.head()","e514d213":"submission_file = 'submission.csv'\ndf_sub.to_csv(submission_file, index=False)","335a20f8":"## Model using Image Data","d08384f1":"# Split Train & Test Sets","2cae7676":"## Encode Genre Label","ce07b21a":"# Model Building","fb7eac98":"### About the dataset","b4e2e048":"# Data Preparation\n","d3e24900":"### MelSpec -> Images","6883cad3":"# Data Visualization","7e420fc7":"### MelSpec -> Array","fa7dfa1e":"## Scale the Features","196c9aaf":"# Audio Sentiment Analysis\n\nThe aim of this challenge is to read the audio (.wav) files and classify them into 3 sentiments (Positive, Neutral, or Negative).\n\nSentiments:-\n- Positive\n- Negative\n- Neutral\n\nWe will be applying following Ensemble Algorithms:-\n\n- NN with Tensorflow\n\n# Reading & Understanding Data\n## Importing Libraries","7a4d4abf":"### Loading Dataset"}}