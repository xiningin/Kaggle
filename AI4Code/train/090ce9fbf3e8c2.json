{"cell_type":{"a6d80b84":"code","f80afcbf":"code","f1a9a431":"code","630c3d41":"code","35924827":"code","fc4a3034":"code","94ce9c20":"code","ad1a1a7f":"code","532a25d0":"code","0546e885":"code","14fc5bce":"code","82e610ce":"code","84c92220":"code","b6086153":"code","9e0cc359":"code","bafd6c40":"code","49bd03f8":"code","d20f0073":"markdown","135f3a49":"markdown","8e472ba4":"markdown","590db9f2":"markdown","370b49c1":"markdown","99eea4e4":"markdown","a6847dd0":"markdown","b062d58f":"markdown","d7192bc8":"markdown"},"source":{"a6d80b84":"import numpy as np\nimport pandas as pd\nimport re\n\nfrom sklearn.ensemble import RandomForestClassifier","f80afcbf":"train_data = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_data = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","f1a9a431":"train_data.isna().sum()","630c3d41":"test_data.isna().sum()","35924827":"train_data['Name'] = train_data['Name'].apply(lambda x: x.lower())\n\ntrain_data['Title'] = None\n\nfor i, row in train_data.iterrows():\n    try:\n        train_data.loc[i, 'Title'] = re.search(r\"mr\\.|miss\\.|mrs\\.\", row['Name']).group(0)\n    except AttributeError:\n        train_data.loc[i, 'Title'] = 'none'\n\ntrain_data.head()","fc4a3034":"#do the same for the test data\ntest_data['Name'] = test_data['Name'].apply(lambda x: x.lower())\n\ntest_data['Title'] = None\n\nfor i, row in test_data.iterrows():\n    try:\n        test_data.loc[i, 'Title'] = re.search(r\"mr\\.|miss\\.|mrs\\.\", row['Name']).group(0)\n    except AttributeError:\n        test_data.loc[i, 'Title'] = 'none'","94ce9c20":"#get mean age per title in the training data\nmean_ages = train_data.groupby('Title')['Age'].mean().to_dict()\nmean_ages","ad1a1a7f":"train_data['Age'] = train_data.apply(lambda row: mean_ages[row['Title']] if np.isnan(row['Age']) else row['Age'], axis=1)\ntest_data['Age'] = test_data.apply(lambda row: mean_ages[row['Title']] if np.isnan(row['Age']) else row['Age'], axis=1)\n\nmost_freq = train_data['Embarked'].mode()[0]\ntrain_data['Embarked'].fillna(value=most_freq, inplace=True)\n\nmean_value_fare = test_data['Fare'].mean()\ntest_data['Fare'].fillna(value=mean_value_fare, inplace=True)\n\ntrain_data.isna().sum()","532a25d0":"#set aside continuous variables\ndf_other_train = train_data[['Age', 'SibSp', 'Parch', 'Fare']]\ndf_other_test = test_data[['Age', 'SibSp', 'Parch', 'Fare']]","0546e885":"train_data_cat = train_data[['Pclass','Sex','Embarked','Title']] \ntest_data_cat = test_data[['Pclass','Sex','Embarked','Title']]","14fc5bce":"df_train = pd.DataFrame()\nfor variable in list(train_data_cat.columns):\n    enc = pd.get_dummies(train_data[variable], prefix = variable)\n    df_train= pd.concat([df_train, enc], axis = 1)\n\ndf_train = pd.concat([df_train, df_other_train], axis=1)\ndf_train = pd.concat([df_train, train_data['Survived']], axis = 1)\ndf_train.head()","82e610ce":"df_test = pd.DataFrame()\nfor variable in list(test_data_cat.columns):\n    enc = pd.get_dummies(test_data[variable], prefix = variable)\n    df_test = pd.concat([df_test, enc], axis = 1)\n\ndf_test = pd.concat([df_test, df_other_test], axis=1)\ndf_test.head()","84c92220":"X_train = df_train.drop(['Survived'], axis=1)\ny_train = df_train['Survived']\n\nX_test = df_test\n\n#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)","b6086153":"def RFC(X_train, X_test, y_train, n_estimators=500, random_state=42):\n    clf = RandomForestClassifier(n_estimators=n_estimators, random_state=random_state)\n    clf.fit(X_train, y_train)\n    y_pred = clf.predict(X_test)\n    return y_pred\n    #print(accuracy_score(y_test, y_pred))","9e0cc359":"y_pred = RFC(X_train, X_test, y_train)","bafd6c40":"to_submit = pd.DataFrame(data = {'PassengerId': test_data['PassengerId'], 'Survived': y_pred})\nto_submit.set_index('PassengerId', inplace=True)\nlen(to_submit)","49bd03f8":"to_submit.to_csv('submission_4.csv')","d20f0073":"### feature engineering\n\nBelow I will attempt a feature engineering where I create a new variable `title` based on the information under the `Name` column.","135f3a49":"### one-hot encodings\nThe code below conducts one-hot encodings to all the categorical variables.","8e472ba4":"### import data","590db9f2":"### save the predictions as a csv file","370b49c1":"### summary\nThe generated predictions had as high as 76% accuracy, which is a decent first step but not great. I will keep experimenting with other algorithms and try creating different featrues to improve the accuracy.","99eea4e4":"### filling nan values\n\nBased on the mean age per title, I will fill the NaN values under the `Age` column in the training & test data. I will also fill the `Embarked` column in the training set based on the mode (most frequent value) and the `Fare` column in the test set with the overall mean.","a6847dd0":"### model generation\nAs the first attempt, I will try a random forest classifier (with 500 trees).","b062d58f":"## Titanic passenger analysis","d7192bc8":"### required packages"}}