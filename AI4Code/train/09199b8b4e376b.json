{"cell_type":{"5b9b1d7c":"code","d3a47487":"code","b54ac272":"code","f45770e2":"code","3ab0dcd4":"code","4e1060bb":"code","f8ed5172":"code","a2f7815e":"code","20cc7f63":"code","7778b276":"code","a65dc04f":"code","590039dc":"code","a92000e0":"code","bc272eb6":"code","9ccab879":"code","7e09db2c":"code","66aad277":"code","892fedb8":"code","6faab7c8":"code","9e319253":"code","f7975704":"code","651b003c":"code","5295e162":"code","dfe37ee3":"code","6b614241":"code","af56bbf6":"code","1f6501b4":"code","3adb3fea":"code","43143c42":"code","fac1f744":"code","71c62215":"code","b15bb757":"code","e61c20d4":"code","be04495f":"code","5431a550":"code","2a825b7a":"code","883b4958":"code","907d820c":"code","e49b9438":"code","0674c91a":"code","67d0441f":"code","25ba2ec8":"code","5863b3b3":"code","bfea94a5":"code","a66afd8c":"code","a70cd91a":"code","056d9f19":"code","eab60ae9":"code","340d398d":"code","a2adef26":"code","5008b0db":"code","7669f6ea":"code","49b22070":"code","e9d30229":"code","0a19c0b4":"code","e7f0f51e":"code","b1068814":"code","41890b0e":"code","8263ce82":"code","b0f252a0":"code","c0591a50":"code","3e344780":"code","591ad124":"code","39c66f4f":"markdown","da0e4b84":"markdown","b6ce244e":"markdown","c59f256c":"markdown","05695ddb":"markdown","c6b2375e":"markdown","861083a3":"markdown","d78cd5ca":"markdown","1619855b":"markdown","8bccc23e":"markdown","5875b012":"markdown","c0c8effb":"markdown","ff302288":"markdown","a8d5f99e":"markdown","133a56d1":"markdown","ac1b3347":"markdown","63238ac8":"markdown","9e7c7df1":"markdown","e07a6128":"markdown","8c98416a":"markdown","24dd250c":"markdown","80fb52a9":"markdown","5a891c4d":"markdown","9d6d4514":"markdown","60dcac03":"markdown"},"source":{"5b9b1d7c":"import numpy as np\nimport pandas as pd\nfrom numpy import log\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom matplotlib import gridspec\nimport matplotlib\nfrom matplotlib.colors import ListedColormap\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.svm import SVC\nfrom sklearn.metrics import confusion_matrix\nfrom sklearn.metrics import classification_report\n\nimport math\nfrom collections import Counter\nimport pandas_profiling as pp\nimport scipy.stats as stats\n\n#configuration settings\n%matplotlib inline\nsns.set(color_codes=True)\n","d3a47487":"titanic_survival_test_df = pd.read_csv(\"..\/input\/titanic\/test.csv\")\ntitanic_survival_training_df = pd.read_csv(\"..\/input\/titanic\/train.csv\")","b54ac272":"#view the top 5 records for the training set\ntitanic_survival_training_df.head(5)","f45770e2":"#view the top 5 records for the test set\ntitanic_survival_test_df.head(5)","3ab0dcd4":"#profile report generation\npp.ProfileReport(titanic_survival_training_df)","4e1060bb":"pp.ProfileReport(titanic_survival_test_df)","f8ed5172":"titanic_survival_training_df = titanic_survival_training_df.drop([\"Name\", \"Cabin\", \"Embarked\", \"Ticket\", \"Age\"], axis=1)\ntitanic_survival_test_df = titanic_survival_test_df.drop([\"Name\", \"Cabin\", \"Embarked\", \"Ticket\", \"Age\"], axis=1)","a2f7815e":"titanic_survival_training_df.head()","20cc7f63":"titanic_survival_test_df.head()","7778b276":"#check the shape of the records to know how many records are in the training dataset\ntitanic_survival_training_df.shape","a65dc04f":"# Check for rows containing duplicate data in the training set\nduplicate_rows_df = titanic_survival_training_df[titanic_survival_training_df.duplicated()]\nprint(\"Number of duplicate rows: \", duplicate_rows_df.shape)","590039dc":"# Finding the null values in the training set.\ntitanic_survival_training_df.isnull().sum()","a92000e0":"# Finding the null values in the test set.\ntitanic_survival_test_df.isnull().sum()","bc272eb6":"#Filling the missing value in the training set\ntitanic_survival_test_df['Fare'].fillna((titanic_survival_test_df['Fare'].mean()), inplace=True)","9ccab879":"# Finding the null values in the test set.\ntitanic_survival_test_df.isnull().sum()","7e09db2c":"#plotting a boxplot\nsns.boxplot(x=titanic_survival_training_df[\"Fare\"])","66aad277":"titanic_survival_training_df.boxplot(column=['Fare'], by=[\"Survived\"])","892fedb8":"#proportion of the 'Survived' variable\nsurvived_vc = titanic_survival_training_df['Survived'].value_counts()\nsurvived_df = survived_vc.rename_axis('survived').reset_index(name='counts')\nsurvived_df","6faab7c8":"#ploting a pie chart and a bar graph\n# Define the labels\nsurvived_label =  '0', '1'\n\n#Choose which proportion to explode\nsurvived_explode = (0,0.1)\n\n# Create the container which will hold the subplots\nsurvived_fig = plt.figure(figsize = (25,12))\n\n# Create a frame using gridspec\ngs = gridspec.GridSpec(6,7)\n\n# Create subplots to visualize the pie chart\npie_ax01 = plt.subplot(gs[0:,:-3])\npie_ax01.set_title(label=\"Survival Rate\",fontdict={\"fontsize\":25})\npie_ax01.pie(survived_df[\"counts\"],\n            explode = survived_explode,\n            autopct = \"%1.1f%%\",\n            shadow = True,\n            startangle = 90,\n            textprops ={\"fontsize\":22})\npie_ax01.legend(survived_label, loc = 0, fontsize = 18, ncol=2)\n\n# Set subplot to visualize the bargraph\nbar_ax01 = plt.subplot(gs[:6,4:])\nsurvived_label_list = survived_df[\"survived\"]\nsurvived_freq = survived_df[\"counts\"]\nindex = np.arange(len(survived_label_list))\nwidth = 1\/1.5\n\nbar_ax01.set_title(label=\"Survival Rate\",fontdict={\"fontsize\":25})\nbar_ax01.set_xlabel(xlabel=\"Survived\",fontdict={\"fontsize\":25})\nbar_ax01.set_ylabel(ylabel=\"Count\",fontdict={\"fontsize\":25})\nbar_ax01.set_xticklabels(survived_label_list,rotation=\"vertical\",fontdict={\"fontsize\":25})\nbar_ax01.bar(survived_label_list,survived_freq,width,color=\"blue\")\n\nplt.tight_layout(pad=5)","9e319253":"# Checking for imbalance in the target variable\ndef balance_calc(data, unit='natural'):\n    base = {\n        'shannon' : 2.,\n        'natural' : math.exp(1),\n        'hartley' : 10.\n    }\n    if len(data) <= 1:\n        return 0\n    \n    counts = Counter()\n    \n    for d in data:\n        counts[d] += 1\n    \n    ent = 0\n    \n    probs = [float(c) \/ len(data) for c in counts.values()]\n    for p in probs:\n        if p > 0.:\n            ent -= p * math.log(p, base[unit])\n            \n    return ent\/math.log(len(data))","f7975704":"balance_calc(titanic_survival_training_df[\"Survived\"],'shannon')","651b003c":"#plotting a histogram with a fitted normal distribution\nsns.distplot(titanic_survival_training_df[\"Survived\"], fit=stats.norm, color='red', kde = False)","5295e162":"#skewness\ntitanic_survival_training_df[\"Survived\"].skew(axis = 0)","dfe37ee3":"#kurtosis\ntitanic_survival_training_df[\"Survived\"].kurt()","6b614241":"#Finding the relations between the variables.\nplt.figure(figsize = (20,10))\ncorrelation = titanic_survival_training_df.corr()\nsns.heatmap(correlation, cmap='BrBG', annot=True)\ncorrelation","af56bbf6":"titanic_survival_training_df.head()","1f6501b4":"#training set and test set\nX = titanic_survival_training_df.iloc[:, [6]].values\ny = titanic_survival_training_df.iloc[:, 1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","3adb3fea":"# Fitting SVM to the training set\nsvm_fare_model = SVC(kernel='rbf', random_state=0)\nsvm_fare_model.fit(X_train, y_train)","43143c42":"# Predicting the test set results\ny_pred = svm_fare_model.predict(X_test)","fac1f744":"# Accuracy score\nsvm_fare_model.score(X_train, y_train)","71c62215":"# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","b15bb757":"print(classification_report(y_test, y_pred))","e61c20d4":"#training set and test set\nX = titanic_survival_training_df.iloc[:, [2]].values\ny = titanic_survival_training_df.iloc[:, 1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","be04495f":"# Fitting SVM to the training set\nsvm_class_model = SVC(kernel='rbf', random_state=0)\nsvm_class_model.fit(X_train, y_train)","5431a550":"# Predicting the test set results\ny_pred = svm_class_model.predict(X_test)","2a825b7a":"# Accuracy score\nsvm_class_model.score(X_train, y_train)","883b4958":"# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","907d820c":"print(classification_report(y_test, y_pred))","e49b9438":"#training set and test set\nX = titanic_survival_training_df.iloc[:, [4,5]].values\ny = titanic_survival_training_df.iloc[:, 1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","0674c91a":"# Fitting SVM to the training set\nsvm_sp_model = SVC(kernel='rbf', random_state=0)\nsvm_sp_model.fit(X_train, y_train)","67d0441f":"# Predicting the test set results\ny_pred = svm_sp_model.predict(X_test)","25ba2ec8":"# Accuracy score\nsvm_sp_model.score(X_train, y_train)","5863b3b3":"# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","bfea94a5":"print(classification_report(y_test, y_pred))","a66afd8c":"#Encoding the 'Sex' variable\n#Frequency encoding\nfe = titanic_survival_training_df.groupby('Sex').size()\/len(titanic_survival_training_df)\ntitanic_survival_training_df.loc[:,'Sex_Enc'] = titanic_survival_training_df['Sex'].map(fe)\ntitanic_survival_training_df.sample(5)","a70cd91a":"#training set and test set\nX = titanic_survival_training_df.iloc[:, [7]].values\ny = titanic_survival_training_df.iloc[:, 1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","056d9f19":"# Fitting SVM to the training set\nsvm_sex_model = SVC(kernel='rbf', random_state=0)\nsvm_sex_model.fit(X_train, y_train)","eab60ae9":"# Predicting the test set results\ny_pred = svm_sex_model.predict(X_test)","340d398d":"# Accuracy score\nsvm_sex_model.score(X_train, y_train)","a2adef26":"# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","5008b0db":"print(classification_report(y_test, y_pred))","7669f6ea":"titanic_survival_training_df.sample(5)","49b22070":"#training set and test set\nX = titanic_survival_training_df.iloc[:, [2,4,5,7]].values\ny = titanic_survival_training_df.iloc[:, 1].values\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.20, random_state=0)","e9d30229":"# Fitting SVM to the training set\nsvm_all_model = SVC(kernel='rbf', random_state=0)\nsvm_all_model.fit(X_train, y_train)","0a19c0b4":"# Predicting the test set results\ny_pred = svm_all_model.predict(X_test)","e7f0f51e":"# Accuracy score\nsvm_all_model.score(X_train, y_train)","b1068814":"# Making the Confusion Matrix\ncm = confusion_matrix(y_test, y_pred)\ncm","41890b0e":"print(classification_report(y_test, y_pred))","8263ce82":"titanic_survival_test_df.head()","b0f252a0":"#Encoding the 'Sex' variable in the test set\n#Frequency encoding\nfe = titanic_survival_test_df.groupby('Sex').size()\/len(titanic_survival_test_df)\ntitanic_survival_test_df.loc[:,'Sex_Enc'] = titanic_survival_test_df['Sex'].map(fe)\ntitanic_survival_test_df.sample(5)","c0591a50":"X_test2 = titanic_survival_test_df.iloc[:, [1,3,4,6]].values","3e344780":"# Predicting the test set results using the svm_all_model\ny_pred = svm_all_model.predict(X_test2)","591ad124":"y_pred","39c66f4f":"The skewness of the target variable (Survived), as indicated above is greater than zero. Hence, the data is __positively skewed__ and given that the value of skewness (__0.478523__) lies between -0.5 and 0.5, the data is fairly symmetrical. \n\nThe data has __platykurtic kurtosis__ since the kurtosis value __-1.7750__ is less than __3__. As seen in the histogram plot above, the distribution is short, the peak is low and the tail is thin. This means that the data lack outliers","da0e4b84":"__Prediction of survived based on the sex__","b6ce244e":"From the heatmap above we can see that the survival of the passengers onboard was dependent on the fare that the passenger paid.","c59f256c":"# Exploratory Data Analysis (EDA)","05695ddb":"The accuracy of the model has improved from __66.29%__ to __78.65%__. \n\nThere are __141__ accurate predictions and __38__ wrong predictions, which is a great improvement from the previous models. \n\nFrom the classification report we can see that the model is __84%__ confident in predicting the passengers that __did not survive__. It is __71%__ confident when it comes to the prediction of the passengers that __survived__, which is also a great improvement.\n\nThis shows that the sex of the passengers is a strong predictor on whether the passengers survived or not","c6b2375e":"The target variable is imbalanced because the value obtained of __0.1414398__ is below __0.5__. We can also see in the pie chart and bar graph above that there is an imbalance in the dataset","861083a3":"## Support Vector Machine","d78cd5ca":"__Missing or null values__","1619855b":"__Dropping Irrelevant Columns__","8bccc23e":"__Detecting Outliers__","5875b012":"As seen above there are no duplicate rows","c0c8effb":"__Prediction of survived based on fare__","ff302288":"__Data Description__\n\nThe file has the structure below:\n\n| Column Name | Description | Type | Sample Values |\n| --- | --- | --- | --- |\n| PassengerId | ID of the passengers in the titanic ship | Int | Integer numbers i.e 1,2,3... |\n| Survived | Indicates whether a passenger survived or not | Int | Binary numbers, 1=Yes, 0=No |\n| Pclass | Ticket class of the passengers | Int | 1=1st, 2=2nd, 3=3rd |\n| Name | Names of the passengers | Str | Strings |\n| Sex | The gender of the passengers | Str | male, female |\n| Age | The age of the passengers | Int | Integer numbers |\n| SibSp | Number of siblings \/ spouses aboard the Titanic | Int | Integer numbers |\n| Parch | Number of parents \/ children aboard the Titanic | Int | Integer numbers |\n| Ticket | Ticket numbers | Int | ticket numbers |\n| Fare | Passenger fare | Int\/floats | 21,24... |\n| Cabin | Cabin number | Str | A6, D56.. |\n| Embarked | Port of Embarkation | Str | C=Cherbourg, Q=Queenstown, S=Southampton |","a8d5f99e":"__Prediction of survived based on various features__","133a56d1":"__Importing the required libraries__","ac1b3347":"# Problem Statement","63238ac8":"The accuracy of the model is __65.45%__ and there are __125__ accurate predictions and __54__ wrong predictions. Also from the classification report we can see that the model is __95%__ confident in predicting the passengers that __did not survive__. However, it is __30%__ confident when it comes to the prediction of the passengers that __survived__","9e7c7df1":"The accuracy of the model has improved from __65.45%__ to __66.99%__. \n\nThere are __128__ accurate predictions and __51__ wrong predictions, which is an improvement from the previous model. \n\nFrom the classification report we can see that the model is __87%__ confident in predicting the passengers that __did not survive__. It is __46%__ confident when it comes to the prediction of the passengers that __survived__, which is an improvement","e07a6128":"__Loading the data into a dataframe__","8c98416a":"The accuracy of the model has reduced from __66.99%__ to __66.29%__. \n\nThere are __124__ accurate predictions and __55__ wrong predictions, which shows that the performance of the model has reduced in comparison to the previous model. \n\nFrom the classification report we can see that the model is __93%__ confident in predicting the passengers that __did not survive__. It is __32%__ confident when it comes to the prediction of the passengers that __survived__.","24dd250c":"Build a model that predicts the survival of passengers on the titanic","80fb52a9":"__Prediction of survived based on the passenger class__","5a891c4d":"### Exploring the target variable (Survived)","9d6d4514":"__Prediction of survived based on sibsp and parch__","60dcac03":"The accuracy of the model has improved from __78.65%__ to __80.76%__.\n\nI noted that the accuracy of the model reduced to __65%__ when fare was added, indicating that it's not a good predictor of whether the passengers survived or not. Also the passengers' class highly correlates with the fare.\n\nThere are __143__ accurate predictions and __36__ wrong predictions, which is a great improvement from the previous models. \n\nFrom the classification report we can see that the model is __87%__ confident in predicting the passengers that __did not survive__. It is __68%__ confident when it comes to the prediction of the passengers that __survived__, which is also a great improvement.\n\nHence; passengers' class, sex, number of siblings, spouses, parents and children are strong predictors of the survived column."}}