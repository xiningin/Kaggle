{"cell_type":{"b086b057":"code","5da3d7f4":"code","68221b43":"code","9e2bd9c8":"code","b9724f71":"code","dfd46541":"code","892372fc":"code","aa118a15":"code","5de5cca0":"code","0ce337e2":"code","6dfa7310":"code","4d326c91":"code","45a2cf50":"code","cba030c5":"code","461173dc":"code","69327945":"code","496c5ecf":"code","9146570f":"code","95f25b38":"code","9ed0fed4":"code","c4a807cc":"code","50274084":"markdown","e9cb191d":"markdown","fc6a1b56":"markdown","fbce790a":"markdown"},"source":{"b086b057":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n!pip install NRCLex","5da3d7f4":"#load all required packages\n#general data handling and processing\nimport pandas as pd\nimport numpy as np\n#text data processing and sentiment analysis tools\nimport nltk\nfrom nltk.sentiment.vader import SentimentIntensityAnalyzer\nsia = SentimentIntensityAnalyzer()\nfrom nrclex import NRCLex\n\n#visualization\nimport matplotlib.pyplot as plt\n\n","68221b43":"#import data\nabc = pd.read_csv('\/kaggle\/input\/million-headlines\/abcnews-date-text.csv')","9e2bd9c8":"#take a look at the structure and basic information of this dataset\nabc.info()\n#identify missing values from the dataset\nabc.isnull().sum() ","b9724f71":"#change publish_date column to datetime as it is currently integer\nabc['publish_date'] = pd.to_datetime(abc['publish_date'], format='%Y%m%d') ","dfd46541":"#create polarity scores\nabc['senti_score'] = abc['headline_text'].apply(lambda headline: sia.polarity_scores(headline))\n\n#extract compound scores to a new column\nabc['compound']  = abc['senti_score'].apply(lambda score_dict: score_dict['compound'])\n\n#create a new column for sentiment labels \nabc['senti_label'] = abc['compound'].apply(lambda c: 'positive' if c >=0.05 else 'neutral' if c>-0.05 else 'negative')\n\n#counts of sentiment labels\nabc['senti_label'].value_counts()","892372fc":"#calculate the average compound scores per month and per year respectively\nyearly_averages = abc.resample('A',on='publish_date').mean()\nmonthly_averages = abc.resample('M',on='publish_date').mean()","aa118a15":"monthly_averages.head(5)","5de5cca0":"#visualization of vader sentiment scores\nplt.figure(figsize=(20,10))\nplt.plot(yearly_averages.index,yearly_averages['compound'],  color='olive', linewidth=2, linestyle='dashed', label='Yearly mean compound scores')\nplt.plot(monthly_averages.index, monthly_averages['compound'], color = 'blue', linewidth=2, label='Monthly mean compound scores')\nplt.legend()\nplt.show()","0ce337e2":"#function to retrieve nrc affect frequencies\ndef emotion_freq(headline):\n    res1 = {'anger': 0.0, 'fear': 0.0, 'negative': 0.0, 'positive': 0.0, 'sadness': 0.0, 'trust': 0.0, 'anticipation': 0.0, 'joy': 0.0, 'disgust': 0.0, 'surprise': 0.0}\n    headline = NRCLex(headline)\n    freq = headline.affect_frequencies\n    for k, fq in freq.items():\n      res1[k] = res1.get(k, 0.0) + fq\n    return res1\n\n#function to calculate word count in each headline\ndef word_count(row):\n    row = nltk.word_tokenize(row)\n    cnt = len(row)\n    return cnt","6dfa7310":"#create a new dataset without vader analysis\nabc_nrc = abc.iloc[:,0:2].copy()","4d326c91":"#retrieve affect frequencies in each headline\nabc_nrc['emo_freq']=abc_nrc['headline_text'].apply(emotion_freq)","45a2cf50":"#take a look at our new column with affected frequencies\nabc_nrc.head()","cba030c5":"#extract out the emotions to new columns for further analysis\nabc_nrc = pd.concat((abc_nrc.drop(['emo_freq'],axis=1), abc_nrc['emo_freq'].apply(pd.Series)), axis=1)","461173dc":"#calculate word count in each headline\nabc_nrc['word_count']=abc_nrc['headline_text'].apply(word_count)","69327945":"abc_nrc.head()","496c5ecf":"#normalize emotion frequencies by having it divided by word counts in each headline\nemotions = ['anger','fear','negative','positive','sadness','trust','anticipation','joy','disgust','surprise']\nfor emotion in emotions:\n    abc_nrc[emotion] = abc_nrc[emotion]\/abc_nrc['word_count']","9146570f":"#now we have our dataframe as below\nabc_nrc.head()","95f25b38":"nrc_yearly_averages = abc_nrc.resample('A',on='publish_date').mean()\nnrc_monthly_averages = abc_nrc.resample('M',on='publish_date').mean()","9ed0fed4":"for emotion in emotions:\n    plt.figure(figsize=(20,10))\n    plt.plot(nrc_yearly_averages.index,nrc_yearly_averages[emotion], color='orange', linewidth=2, linestyle='dashed', label='Yearly average scores')\n    plt.plot(nrc_monthly_averages.index, nrc_monthly_averages[emotion], color = 'tab:blue', linewidth=2, label='Monthly average scores')\n    plt.title('{} Sentiment of ABC News Headlines'.format(emotion.title()), fontsize=15)\n    plt.legend()\n    plt.show()","c4a807cc":"x= nrc_yearly_averages.index\ny= [nrc_yearly_averages[emotion].tolist() for emotion in emotions]\nplt.figure(figsize=(20,10))\nplt.stackplot(x,y, colors=('#1f77b4',\n                          '#ff7f0e',\n                          '#2ca02c',\n                          '#d62728',\n                          '#9467bd',\n                          '#8c564b',\n                          '#e377c2',\n                          '#7f7f7f',\n                          '#bcbd22',\n                          '#17becf'), labels=emotions)\nplt.legend()\nplt.show()","50274084":"This graph indicates that there might be a cycle in the sentiment of news headlines as there are two peaks-around 2003 and 2015, and two troughs - in 2010 and end of 2019. \nIt's worth looking into the topics in those years to understand the peaks and troughs in sentiment.There could be major events happening around those times which had made the media change their sentiment. \n \n\n### [NRC Emotion Lexicon](https:\/\/saifmohammad.com\/WebPages\/NRC-Emotion-Lexicon.htm#:~:text=The%20NRC%20Emotion%20Lexicon%20is,sentiments%20(negative%20and%20positive).)\n\nNext, I will be using [NRCLex package](https:\/\/pypi.org\/project\/NRCLex\/) to further detect emotions in news headlines. ","e9cb191d":"The above result shows that nearly half of the news headlines are neutral. While in the other half, there are more negative headlines identified than positive ones. \n\n#### Visualizations of sentiments over the years","fc6a1b56":"### NLTK VADER\n\nFirstly, I'using NLTK VADER package to perform a sentiment analysis and plot it to see the change over the years. \nAccording to [Schumacher (2019)](https:\/\/opendatagroup.github.io\/data%20science\/2019\/03\/21\/preprocessing-text.html#:~:text=The%20general%20rule%20for%20whether,improve%20performance%2C%20do%20not%20lemmatize.&text=For%20example%2C%20a%20popular%20sentiment,not%20be%20stemmed%20or%20lemmatized), \"VADER, has different ratings depending on the form of the word and therefore the input should not be stemmed or lemmatized.\" I decided not to stem or lemmatize the words for this sentiment analysis. \n\nI will be using thresholds values of -0.05 and 0.05, based on \"About the Scoring\" section on [this github page](https:\/\/github.com\/cjhutto\/vaderSentiment). If compound score is larger than 0.05, the headline will be classified as positive; if compound score is smaller than -0.05 it will be negative. ","fbce790a":"Anger, fear and negative are going downward. "}}