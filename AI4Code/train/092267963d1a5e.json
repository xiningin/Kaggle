{"cell_type":{"ee0d4227":"code","4c177eb2":"code","0df9f345":"code","13506b36":"code","4900ac41":"code","38ded9f5":"code","f2cd377f":"code","04f4a36a":"code","9e97cdf8":"code","a063a0b0":"code","e4d8cc71":"code","0a6c9be1":"code","4d5901c0":"code","2a5206e9":"code","57ed08cb":"code","68839107":"code","0e61715c":"code","f1ac9a0e":"code","8269e045":"code","67bbf75f":"code","b87641c5":"code","85ca6f4f":"code","01bee210":"code","2885e9a6":"markdown","c672b5eb":"markdown","93218dec":"markdown","c5d6ef3b":"markdown","38f7a8d5":"markdown","51a21c5a":"markdown","ec36af49":"markdown","d75863a7":"markdown","7cef23f0":"markdown","99a47a9b":"markdown"},"source":{"ee0d4227":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n","4c177eb2":"# importing libraries\nimport numpy as np \nimport pandas as pd \nimport nltk\n##nltk.download('stopwords') - for jupyter notebook\nfrom nltk.corpus import stopwords\nstop_words = set(stopwords.words('english'))\nfrom nltk.tokenize import word_tokenize\nfrom nltk.stem import PorterStemmer\nfrom nltk.stem.wordnet import WordNetLemmatizer\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.naive_bayes import GaussianNB\nfrom sklearn.metrics import confusion_matrix,classification_report,accuracy_score","0df9f345":"db = pd.read_csv('..\/input\/kindle-reviews\/kindle_reviews.csv')\ndb = db.head(100000)","13506b36":"db_needed = db[['reviewText','overall']]\ndb_needed.head()","4900ac41":"db_needed.groupby('overall').describe()","38ded9f5":"db_needed.info()","f2cd377f":"#removing rows with no reviews\ndb_needed = db_needed[db_needed['reviewText'].notna()]\ndb_needed.info()","04f4a36a":"db_needed.head()","9e97cdf8":"#tokenization\ndb_needed['reviewText_t'] = db_needed['reviewText'].apply(word_tokenize)\ndb_needed.head()","a063a0b0":"# removing punctuation marks\nimport string\n#nltk.download('punkt') - to add for jupyer notebook\ndb_needed['reviewText_wo_punctuation'] = db_needed['reviewText_t'].apply(lambda x: [char for char in x if char not in string.punctuation])\ndb_needed.head()\n","e4d8cc71":"#removing stop words\ndb_needed['reviewText_filtered'] = db_needed['reviewText_wo_punctuation'].apply(lambda x: [word for word in x if not word in stop_words])\ndb_needed.head()","0a6c9be1":"ps = PorterStemmer()\ndb_needed['reviewText_s'] = db_needed['reviewText_filtered'].apply(lambda x: ' '.join([ps.stem(i) for i in x]))\ndb_needed.head()","4d5901c0":"lemma = WordNetLemmatizer()\ndb_needed['reviewText_l'] = db_needed['reviewText_s'].apply(lambda x: ' '.join([lemma.lemmatize(i) for i in x]))\ndb_needed.head()","2a5206e9":"X = db_needed['reviewText_s']\ny = db_needed['overall']","57ed08cb":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=10)\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","68839107":"X_train.head()","0e61715c":"vector = CountVectorizer()\n\n#it 'learns' the vocabulary and builds a matrix:\nvector.fit(X_train) \nX_train_matrix = vector.transform(X_train)\n","f1ac9a0e":"#apply same on test database\nX_test_matrix = vector.transform(X_test)\nX_test_matrix","8269e045":"from sklearn.feature_extraction.text import TfidfTransformer\n\ntfidf_transformer = TfidfTransformer()\ntfidf_transformer.fit(X_train_matrix)\ntfidf_transformer.transform(X_train_matrix)","67bbf75f":"from sklearn.naive_bayes import MultinomialNB\nNBayes = MultinomialNB()\nNBayes.fit(X_train_matrix, y_train)","b87641c5":"y_predicted = NBayes.predict(X_test_matrix)","85ca6f4f":"from sklearn import metrics\nmetrics.accuracy_score(y_test, y_predicted)\n#0.5642","01bee210":"metrics.confusion_matrix(y_test, y_predicted)","2885e9a6":"This database contains reviews of Kindle works, each work having a short and long review, and a general overall rating. I will be focusing firstly on the long review variable, and trying to predict the overall rating class by using the words used to describe it.\n\nThe steps I'll be applying will be:\n- tokenization\n- removing of stopwords and punctuation marks\n- stemming (or lemmatizing)\n- train-test split\n- vectorization\n- normalizing\n- use of multinomial Naive Bayes for classification\n\nFuture ideas for improvement can be:\n- a grouping of the ratings in good\/bad \n- new algorithms to be used instead of NB\n\nFirstly, let's import the libraries, have a look at the data and keep only the variables I'll need for the moment: ","c672b5eb":"Let's move on to the Naive Bayes model:","93218dec":"Keeping a subset of 100000 rows because it takes a large amount of time to run:","c5d6ef3b":"Let's make predictions on the test matrix database:","38f7a8d5":"The top ratings, 4 and 5, are the most applied ratings.\nLet's clean up by removing lines with empty reviews, and then tokenize, remove punctuation marks and the words used most often that won't help in classification:","51a21c5a":"Now I will continue to use the stemmed variable and split the data into train and test databases, before  transforming these reviews that are now stemmed into vectors that can be used by the Naive Bayes algorithm::\n","ec36af49":"Now let's normalise train and test databases:","d75863a7":"Check accuracy score and confusion matrix:","7cef23f0":"Let's also lemmatize and watch how the words transform from the first column to the last, before deleting the unnecessary columns:","99a47a9b":"Now, let's move on to stemming:"}}