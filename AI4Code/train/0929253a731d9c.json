{"cell_type":{"eaf69e24":"code","3fff326c":"code","c73be8e3":"code","8666d8ce":"code","296b6045":"code","66d1089c":"code","70708ba6":"code","0832fee0":"code","c21d2864":"code","28f30f97":"code","afe2e9c0":"code","c58ffd7f":"code","d575736a":"code","ac5269d6":"code","357b4be1":"code","2dd084bd":"code","e44a098b":"code","1c5e110b":"code","6297e2d6":"code","eaa5be75":"code","ef137408":"code","a6d94b4b":"code","a7489dfd":"code","4f3ba3b1":"code","9d284a92":"code","2864e5ba":"code","791d8368":"code","455f270e":"code","6cad9e97":"code","d26e3050":"code","d2c1e63e":"code","c5492c81":"markdown","731cf9bd":"markdown","40995e64":"markdown","65a8e0cc":"markdown","fce81fe0":"markdown","414455d2":"markdown","9599e7e5":"markdown","b601fe31":"markdown","5b3cedc9":"markdown","35cf4ed2":"markdown","1ea823bb":"markdown","dba172b3":"markdown","564d2556":"markdown","5f49f114":"markdown","56fccb67":"markdown","987b816f":"markdown","410b29b5":"markdown","34de7b02":"markdown","6d42ee00":"markdown"},"source":{"eaf69e24":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport warnings\n%matplotlib inline\nwarnings.filterwarnings('ignore')\n\n\nimport plotly.offline as py\nimport plotly.graph_objs as go\nfrom plotly.offline import init_notebook_mode\ninit_notebook_mode(connected=False)\nimport cufflinks as cf\npy.offline.init_notebook_mode(connected = True)\ncf.go_offline()","3fff326c":"df = pd.read_csv('..\/input\/blackfriday\/BlackFriday.csv')\ndf.head()","c73be8e3":"df.describe().T","8666d8ce":"df.shape","296b6045":"df.isnull().sum()","66d1089c":"df.info()","70708ba6":"#Impute Missing data using median of the column:\ndef impute_nan(df, variable, median):\n    df[variable] = df[variable].fillna(median)\n    \n#Calculate median:\nmedian = df.Product_Category_2.median()\n\n#Call the function:\nimpute_nan(df, 'Product_Category_2', median)","0832fee0":"#Same for the Product_Category_3 Column:\nmedian = df.Product_Category_3.median()\n\n#Call the function:\nimpute_nan(df, 'Product_Category_3', median)\n\n#check for updation:\ndf.isnull().sum()","c21d2864":"# distplot for purchase\nplt.style.use('fivethirtyeight')\nplt.figure(figsize=(13, 7))\nsns.distplot(df['Purchase'], bins=25)","28f30f97":"# Pie chart - To view the average purchase based on Gender:\n\nimport plotly.express as px\npurchase_gender = df.groupby('Gender')['Gender'].value_counts()\ncolors = ['#E1396C', '#000080']\n\ntrace = go.Pie(labels = purchase_gender.index, values = purchase_gender,\n            marker = dict(colors = colors, \n                           line = dict(color = '#000000', width = 2)))\nlayout = go.Layout(title = \"Average Purchase Based On Gender\",width = 500,height=500)\nfig = go.Figure(data = [trace], layout = layout)\npy.iplot(fig, filename = 'pie_chart_subplots')","afe2e9c0":"# DISTRIBUTION OF AGE COLUMN:\n\nsns.countplot(df['Age'], palette = 'pastel')\nplt.title('Distribution of Age', fontsize = 20)\nplt.xlabel('Different Categories of Age', fontsize = 20)\nplt.ylabel('Count')\nplt.show()","c58ffd7f":"#Pie chart - Average purchase based on AGE:\n\nfrom plotly.subplots import make_subplots\npurchase_age = df.groupby('Age')['Age'].value_counts()\ncolors = ['#E1396C', '#000080']\n\ntrace = go.Pie(labels = purchase_age.index, values = purchase_age,\n            marker = dict(colors = colors, \n                           line = dict(color = '#000000', width = 2)))\nlayout = go.Layout(title = \"Average Purchase Based On Age\",width = 500,height=500)\nfig = go.Figure(data = [trace], layout = layout)\npy.iplot(fig, filename = 'pie_chart_subplots')","d575736a":"#Average Purchase Based on Occupation:\n\npurchase_occupation = df['Occupation'].value_counts();\nplt.figure(figsize = (16,16));\nplt.bar(purchase_occupation.index, purchase_occupation.values, color ='g');\nplt.xticks(purchase_occupation.index);\nplt.xlabel('Occupation Types');\nplt.ylabel('Count of people');\nplt.title('Average Purchase Based on Occupation');","ac5269d6":"#Average Purchase based on Marital Status:\n\npurchase_marital_status= df.groupby(['Gender', 'Marital_Status'])['Gender'].value_counts()\n#colors = ['#E1396C', '#000080']\n\ntrace = go.Pie(labels = purchase_marital_status.index, values = purchase_marital_status,\n            marker = dict( \n                           line = dict(color = '#000000', width = 2)))\nlayout = go.Layout(title = \"Average Purchase Based On Marital Status\",width = 500,height=500)\nfig = go.Figure(data = [trace], layout = layout)\npy.iplot(fig, filename = 'pie_chart_subplots')\npurchase_marital_status.unstack(level=1).plot(kind='bar');","357b4be1":"#Average Purchase BASED ON City:\n\npurchase_city = df.groupby('City_Category')['City_Category'].value_counts()\ncolors = ['#999900', '#FF0000', '#000080']\n\ntrace = go.Pie(labels = purchase_city.index, values = purchase_city, pull=[0, 0.1, 0],\n            marker = dict(colors = colors, \n                           line = dict(color = '#000000', width = 2)))\nlayout = go.Layout(title = \"Average Purchase Based On City\",width = 500,height=500)\nfig = go.Figure(data = [trace], layout = layout)\npy.iplot(fig, filename = 'pie_chart_subplots')\n    ","2dd084bd":"df['combine_gender_marital'] = df.apply(lambda x:'%s_%s' % (x['Gender'],x['Marital_Status']),axis=1)\nprint(df['combine_gender_marital'].unique())\n","e44a098b":"sns.countplot(df['Age'], hue=df['combine_gender_marital'], color = 'orange')","1c5e110b":"df.sum()[[\"Product_Category_1\", \"Product_Category_2\", \"Product_Category_3\"]].plot.bar(title=\"Products sold\", color=\"grey\")\nsns.despine()","6297e2d6":"df.groupby([\"Occupation\"]).mean()[[\"Product_Category_1\", \"Product_Category_2\", \"Product_Category_3\"]].plot.line(title=\"Gender&Product\")\nsns.despine()","eaa5be75":"df.groupby([\"City_Category\"]).mean()[[\"Product_Category_1\", \"Product_Category_2\", \"Product_Category_3\"]].plot.bar(title=\"Gender&Product\")\nsns.despine()","ef137408":"sns.countplot(df['Product_Category_1'], hue=df['combine_gender_marital'])","a6d94b4b":"sns.countplot(df['Product_Category_2'], hue=df['combine_gender_marital'], color='blue')","a7489dfd":"sns.countplot(df['Product_Category_3'], hue=df['combine_gender_marital'], color='green')","4f3ba3b1":"corr = df.corr()\nplt.figure(figsize=(14,7))\nsns.heatmap(corr, annot=True, cmap='coolwarm')","9d284a92":"# encoding values using dict\ngender_dict = {'F':0, 'M':1}\ndf['Gender'] = df['Gender'].apply(lambda x: gender_dict[x])","2864e5ba":"# to improve the metric use one hot encoding\n# label encoding\ncols = ['Age', 'City_Category', 'Stay_In_Current_City_Years']\nfrom sklearn.preprocessing import LabelEncoder\nle = LabelEncoder()\nfor col in cols:\n    df[col] = le.fit_transform(df[col])","791d8368":"df.head()","455f270e":"X = df.drop(columns=['User_ID', 'Product_ID', 'Purchase', 'combine_gender_marital'], axis=1)\ny = df['Purchase']","6cad9e97":"from sklearn.model_selection import cross_val_score, train_test_split\nfrom sklearn.metrics import mean_squared_error\ndef train(model, X, y):\n    # train-test split\n    x_train, x_test, y_train, y_test = train_test_split(X, y, random_state=42, test_size=0.25)\n    model.fit(x_train, y_train)\n    \n    # predict the results\n    pred = model.predict(x_test)\n    \n    # cross validation\n    cv_score = cross_val_score(model, X, y, scoring='neg_mean_squared_error', cv=5)\n    cv_score = np.abs(np.mean(cv_score))\n    \n    print(\"Results\")\n    print(\"MSE:\", np.sqrt(mean_squared_error(y_test, pred)))\n    print(\"CV Score:\", np.sqrt(cv_score))","d26e3050":"from sklearn.ensemble import ExtraTreesRegressor\nmodel = ExtraTreesRegressor(n_jobs=-1)\ntrain(model, X, y)\nfeatures = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)\nfeatures.plot(kind='bar', title='Feature Importance')","d2c1e63e":"from sklearn.ensemble import GradientBoostingRegressor\nmodel = GradientBoostingRegressor()\ntrain(model, X, y)\nfeatures = pd.Series(model.feature_importances_, X.columns).sort_values(ascending=False)\nfeatures.plot(kind='bar', title='Feature Importance')","c5492c81":"<center><h1 style=\"font-size:420%;\"><b style=\"color:orange;\">BLACK FRIDAY SALES - DATA ANALYSIS<\/b><\/h1><\/center>","731cf9bd":"<h1 style=\"font-size:250%;\"><b style=\"color:red;\">MODEL BUILDING<\/b><\/h1>","40995e64":"<h1 style=\"font-size:250%;\"><b style=\"color:red;\">DESCRIPTIVE STATISTICS OF DATA<\/b><\/h1>","65a8e0cc":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q11. HANDLING CATEGORICAL FEATURES<\/b><\/p>","fce81fe0":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q6. AVERAGE PURCHASE BASED ON MARITAL_STATUS COLUMN<\/b><\/p>","414455d2":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q4. AVERAGE PURCHASE BASED ON AGE COLUMN<\/b><\/p>","9599e7e5":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q9. VISUALIZATION OF PRODUCT CATEGORIES<\/b><\/p>","b601fe31":"<center><img src=\"https:\/\/encrypted-tbn0.gstatic.com\/images?q=tbn:ANd9GcQKKyUv8yrJZuNyyP5nx9Jal8hWAh7GnUYsNw&usqp=CAU\" \n     width=\"800\" \n     height=\"500\" \/><\/center>\n","5b3cedc9":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q10. CORRELATION MATRIX<\/b><\/p>","35cf4ed2":"<h1 style=\"font-size:250%;\"><b style=\"color:red;\">IMPORT AND LOAD DATA<\/b><\/h1>","1ea823bb":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q5. AVERAGE PURCHASE BASED ON OCCUPATION COLUMN<\/b><\/p>","dba172b3":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q2. DISTRIBUTION OF TARGET COLUMN<\/b><\/p>","564d2556":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q1. HANDLE THE MISSING VALUES<\/b><\/p>","5f49f114":"<h1 style=\"font-size:250%;\"><b style=\"color:red;\">DATA VISUALIZATION<\/b><\/h1>","56fccb67":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q3. AVERAGE PURCHASE BASED ON GENDER COLUMN<\/b><\/p>","987b816f":"<p style=\"font-size:150%;\">\nThe dataset used in this analysis contains information of transactions in a store on Black Friday, including customers demographical features and transaction details. In this analysis I will do two things. Firstly I will explore the data and find some correlations between differents elements, so I can get some insights for future marketing strategies. On top of that I will also use regression method to predict future purchase.<\/p>","410b29b5":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q8. VISUALIZATION OF GENDER AND AGE COLUMN TOGETHER<\/b><\/p>","34de7b02":"<p style=\"font-size:150%;\"><b style=\"color:green;\">Q7. AVERAGE PURCHASE BASED ON CITY COLUMN<\/b><\/p>","6d42ee00":"<h1 style=\"font-size:250%;\"><b style=\"color:red;\">DATA CLEANING<\/b><\/h1>"}}