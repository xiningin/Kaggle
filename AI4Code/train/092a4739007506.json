{"cell_type":{"a5f7fb0c":"code","ab6e5754":"code","4d567616":"code","61c76062":"code","50b3c083":"code","28bda294":"code","710b54fa":"code","9877f861":"code","7db13b63":"code","c05b9a6f":"code","ed660f1b":"code","1a716f98":"code","6990e8eb":"code","2ef0b3e9":"code","dd63d77c":"code","74b0e0ae":"code","eb6bfc3e":"code","5dd3173d":"code","a96dca6c":"code","13790469":"code","3b1e18f3":"code","9a6f789a":"code","61f21b8d":"code","35398536":"code","e72e4496":"code","2f840355":"code","79811b70":"code","7e76db53":"code","3a6595d2":"code","200be2f7":"code","f8380bde":"code","048049f8":"code","e8584cc8":"code","5e82a6d9":"code","5ed30b8d":"code","2ce11d79":"code","b767690c":"code","054fa9e5":"code","6947e563":"code","09ef5d83":"code","3edb80d7":"code","faa5bbed":"code","13ea7a11":"code","57d19f4d":"code","c35ddf00":"code","0900e286":"code","c2a8cf02":"code","42ab57b7":"code","ccd3b489":"code","8c6a9050":"code","26e791db":"code","d8e06700":"code","bc9e8905":"code","8440651f":"code","b3ab8153":"code","5f12bb9c":"code","b5016fb9":"code","6a517756":"code","4307cd99":"code","ef790fa4":"code","571f7408":"code","ddd39a1e":"code","3cb6c214":"code","3e7560c2":"code","62c061af":"code","844d62e1":"code","9e58bfc3":"code","496b2437":"code","b4e41854":"code","45f95e29":"code","16d57bb8":"code","c2060f45":"code","a833643b":"code","898f3787":"code","f1ccd89d":"markdown","9c90a763":"markdown","e517dbc9":"markdown","de68d429":"markdown","aaca6e3e":"markdown","97a89905":"markdown","076b7f4b":"markdown","8462f095":"markdown","76f550fd":"markdown","1f48a09e":"markdown","031945a6":"markdown","eaec953d":"markdown","a208c0ac":"markdown","fddbd13e":"markdown","6ac44b5e":"markdown","49f9e39b":"markdown","7e68d542":"markdown","6c2e74df":"markdown","5fde2cf6":"markdown","7cb4ff61":"markdown","2ef66741":"markdown","8d58b879":"markdown","3194bbbd":"markdown","b958c71c":"markdown","29b5a7ae":"markdown","70bbba9c":"markdown","f85e1243":"markdown","33cc0384":"markdown","126ef985":"markdown","47d48676":"markdown","8ee55fd7":"markdown","f5812421":"markdown","15a61dde":"markdown","fe6c2742":"markdown","dd071812":"markdown","1bbb829c":"markdown"},"source":{"a5f7fb0c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport random\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom wordcloud import WordCloud, ImageColorGenerator\n\n%matplotlib inline\nrandom.seed(42)\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","ab6e5754":"main_df = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/COVID19_open_line_list.csv')\ncolumns = list(main_df.columns)\ncolumns.sort()\npd.DataFrame(columns)","4d567616":"main_df.ID.count()","61c76062":"for i in columns:\n    print(i)\n    try:\n        main_df[i] = main_df[i].str.lower()\n    except:\n        pass\n    #print(main_df[i].unique())\n    #print('#'*15)","50b3c083":"main_df_ = pd.read_csv('\/kaggle\/input\/novel-corona-virus-2019-dataset\/COVID19_line_list_data.csv')\ncolumns = list(main_df_.columns)\ncolumns.sort()\npd.DataFrame(columns)","28bda294":"main_df_.id.count()","710b54fa":"for i in columns:\n    print(i)\n    try:\n        main_df_[i] = main_df_[i].str.lower()\n    except:\n        pass\n    #print(main_df[i].unique())\n    #print('#'*15)","9877f861":"main_df.age.unique()","7db13b63":"filtered_df = main_df[main_df.age.str.contains('(-|\\.|[a-z])', regex=True) != True]\nfiltered_df.age.unique()","c05b9a6f":"filtered_df['age'].isnull().count()","ed660f1b":"filtered_df['age'] = pd.to_numeric(filtered_df['age'])\nfiltered_df['age'][filtered_df['age'].isnull()] = filtered_df['age'].mean()\n\nfiltered_df.age.describe()","1a716f98":"filtered_df['outcome'].value_counts()","6990e8eb":"filtered_df = filtered_df[filtered_df['outcome'] != 'critical condition, intubated as of 14.02.2020']\nfiltered_df = filtered_df[filtered_df['outcome'] != '05.02.2020']\n\nfiltered_df['outcome'][filtered_df['outcome'] == 'died'] = 'high_risk'\nfiltered_df['outcome'][filtered_df['outcome'] == 'death'] = 'high_risk'\nfiltered_df['outcome'][filtered_df['outcome'] == 'discharged'] = 'low_risk'\nfiltered_df['outcome'][filtered_df['outcome'] == 'discharge'] = 'low_risk'\n\nfiltered_df['outcome'][filtered_df['outcome'] == 'stable'] = 'low_risk'\nfiltered_df['outcome'][filtered_df['outcome'] == 'recovered'] = 'low_risk'\n\nfiltered_df['outcome'][filtered_df['outcome'].isnull()] = 'unknown'\n\nfiltered_df['outcome'].value_counts()","2ef0b3e9":"filtered_df['sex'].value_counts(), filtered_df['sex'].isnull().value_counts()","dd63d77c":"\nfiltered_df['sex'][filtered_df['sex'].isnull()] = 'unknown'\nfiltered_df['sex'].value_counts()","74b0e0ae":"main_df_.age.unique()","eb6bfc3e":"filtered_df_ = main_df_.copy()\nfiltered_df_.age","5dd3173d":"filtered_df_['id'][filtered_df_['age'].isnull()].count()","a96dca6c":"filtered_df_['age'][filtered_df_['age'].isnull()] = filtered_df_['age'].mean()\n\nfiltered_df_.age.describe()","13790469":"filtered_df_['death'].value_counts()","3b1e18f3":"filtered_df_['death'][filtered_df_['death']!='0'] = 'high_risk'\nfiltered_df_['death'][filtered_df_['death']!='high_risk'] = 'low_risk'\nfiltered_df_['death'].value_counts()\n\nfiltered_df_['outcome'] = filtered_df_['death']\n\nfiltered_df_['outcome'][filtered_df_['outcome'].isnull()] = 'unknown'","9a6f789a":"filtered_df_['gender'].value_counts(), filtered_df_['gender'].isnull().value_counts()","61f21b8d":"filtered_df_['gender'][filtered_df_['gender'].isnull()] = 'unknown'\nfiltered_df_['gender'].value_counts()","35398536":"filtered_df_['sex'] = filtered_df_['gender']\n#filtered_df_.drop('gender', axis=1, inplace=True)\nfiltered_df_.head(5)","e72e4496":"filtered_df_['symptoms'] = filtered_df_['symptom']\n#filtered_df_.drop('symptom', axis=1, inplace=True)\nfiltered_df_","2f840355":"result = pd.concat([filtered_df,filtered_df_])\nresult","79811b70":"filtered_df = result","7e76db53":"summ_str = str(result['summary'].unique())\nsumm_str = summ_str.replace(\"'\",'')\nsumm_str = summ_str.replace('nan ','')\nsumm_str = summ_str.replace('\\n',',')\nsumm_str = summ_str.replace('[',',')\nsumm_str = summ_str.replace(']',',')\nsumm_str = summ_str.replace(', ',',')\nsumm_str = summ_str.replace(';','')\nsumm_str = summ_str.replace(',',' ')\nsumm_str = summ_str.replace('\/',' ')\nsumm_str = summ_str.replace('-',' ')\nsumm_str = summ_str.replace('.',' ')\nsumm_str = summ_str.replace('(',' ')\nsumm_str = summ_str.replace(')',' ')\nfor i in range(10):\n    summ_str = summ_str.replace(str(i),' ')\nsumm_str = summ_str.replace('ing ',' ')\nsumm_str = summ_str.replace('ness ',' ')\nsumm_str = summ_str.replace(' new ',' ')\nsumm_str = summ_str.replace(' confirmed ',' ')\nsumm_str = summ_str.replace(' covid ',' ')\nsumm_str = summ_str.replace(' onset',' ')\nsumm_str = summ_str.replace(' went',' ')\nsumm_str = summ_str.replace(' imported',' ')\nsumm_str = summ_str.replace(' symptom',' ')\nsumm_str = summ_str.replace(' singapore',' ')\nsumm_str = summ_str.replace(' korea',' ')\nsumm_str = summ_str.replace(' hong',' ')\nsumm_str = summ_str.replace(' kong',' ')\nsumm_str = summ_str.replace(' japan',' ')\nsumm_str = summ_str.replace(' south',' ')\nsumm_str = summ_str.replace(' wuhan',' ')\nsumm_str = summ_str.replace(' hokkaido',' ')\nsumm_str = summ_str.replace(' arrived',' ')\nsumm_str = summ_str.replace(' returned',' ')\nsumm_str = summ_str.replace(' visited',' ')\nsumm_str = summ_str.replace(' male',' ')\nsumm_str = summ_str.replace(' female',' ')\nsumm_str = summ_str.replace(' ncid',' ')\nsumm_str = summ_str.replace(' germany',' ')\nsumm_str = summ_str.replace(' france',' ')\nsumm_str = summ_str.replace(' taiwan',' ')\nsumm_str = summ_str.replace(' thailand',' ')\nsumm_str = summ_str.replace(' spain',' ')\nsumm_str = summ_str.replace(' china',' ')\nsumm_str = summ_str.replace(' italy',' ')\nsumm_str = summ_str.replace(' tianjin',' ')\nsumm_str = summ_str.replace(' yunnan',' ')\nsumm_str = summ_str.replace(' shaanxi',' ')\nsumm_str = summ_str.replace(' nagoya',' ')\nsumm_str = summ_str.replace(' malaysia',' ')\nsumm_str = summ_str.replace('patient patient',' ')\nsumm_str = summ_str.replace('s ',' ')\nsumm_set = summ_str.split(' ')\nsumm_set = summ_set[:]\nsumm_set = set(summ_set)\n\nwordcloud = WordCloud(max_words=300, background_color=\"white\").generate(summ_str)\nplt.figure(figsize=(13,7))\nplt.imshow(wordcloud, interpolation='spline16')\nplt.axis(\"off\")\nplt.show()","3a6595d2":"symp_str = str(result['symptoms'].unique())\nsymp_str = symp_str.replace(\"'\",'')\nsymp_str = symp_str.replace('nan ','')\nsymp_str = symp_str.replace('\\n',',')\nsymp_str = symp_str.replace('[',',')\nsymp_str = symp_str.replace(']',',')\nsymp_str = symp_str.replace(', ',',')\nsymp_str = symp_str.replace(';','')\nsymp_str = symp_str.replace(',',' ')\nsymp_str = symp_str.replace('ing ',' ')\nsymp_str = symp_str.replace('ness ',' ')\nsymp_str = symp_str.replace('s ',' ')\nsymp_str = symp_str.replace(' los ',' ')\nsymp_str = symp_str.replace(' feaver ',' ')\nsymp_str = symp_str.replace(' feve\\\\\\\\ ',' ')\nsymp_str = symp_str.replace(' in ',' ')\nsymp_str = symp_str.replace(' of ',' ')\nsymp_str = symp_str.replace(' with ',' ')\nsymp_str = symp_str.replace(' ye ',' ')\nsymp_set = symp_str.split(' ')\nsymp_set = symp_set[:]\nsymp_set = set(symp_set)\n\nwordcloud = WordCloud(max_words=300, background_color=\"white\").generate(symp_str)\nplt.figure(figsize=(13,7))\nplt.imshow(wordcloud, interpolation='spline16')\nplt.axis(\"off\")\nplt.show()","200be2f7":"symp_set","f8380bde":"discard_list = ['',\n 'a',\n 'abdominal',\n 'ach',\n 'and',\n 'body',\n 'breath',\n 'chest',\n 'diarrhea',\n 'diarrheoa',\n 'diarrhoea',\n 'dizzi',\n 'esophageal',\n 'eventually',\n 'eye',\n 'feel',\n 'feversore',\n 'flu-like',\n 'heart',\n 'high',\n 'joint',\n 'lack',\n 'lesion',\n 'limb',\n 'mild',\n 'mouth',\n 'left',\n 'muscle',\n 'muscular',\n 'nasal',\n 'nose',\n 'no',\n 'of',\n 'on',\n 'other',\n 'pharyngalgia',\n 'pharyngeal',\n 'pharyngiti',\n 'pharynx',\n 'rhinorrhea',\n 'rhinorrhoea',\n 'short',\n 'showed',\n 'similar',\n 'sneeze',\n 'tight',\n 'throatfatiguevomit',\n 'to',\n 'ye']\nfor i in discard_list:\n    symp_set.discard(i)\nsymp_set","048049f8":"add_list =['chill','diarrh','dizz','esophag','flu','musc','pharyn','rhinorrh']\nfor i in add_list:\n    symp_set.add(i)\nsymp_set","e8584cc8":"for i in ['low_risk','high_risk','unknown']:\n    print('OUTCOME: '+i)\n    temp_df = filtered_df[filtered_df['outcome']==i]\n    print(temp_df.outcome.value_counts())\n    symp_str = str(temp_df['symptoms'].unique())\n    symp_str = symp_str.replace(\"'\",'')\n    symp_str = symp_str.replace(',',' ')\n    symp_str = symp_str.replace('.',' ')\n    symp_str = symp_str.replace('nan',' ')\n    wordcloud = WordCloud(max_words=300, background_color=\"white\").generate(symp_str)\n    plt.figure(figsize=(13,7))\n    plt.imshow(wordcloud, interpolation='spline16')\n    plt.axis(\"off\")\n    plt.show()","5e82a6d9":"featured_df = pd.DataFrame(filtered_df['age'])\n\nfeatured_df['sex'] = filtered_df['sex']\nfeatured_df = pd.concat([pd.get_dummies(featured_df['sex'], prefix='gender'), \n                        featured_df['age']\n                      ], axis=1)\n\nfiltered_df['symptoms'][filtered_df['symptoms'].isnull()] = 'None'\nfeatured_df['symptoms'] = filtered_df['symptoms']\nfor i in symp_set:\n    #print(i)\n    featured_df['has_'+i] = 0\n    featured_df['has_'+i][featured_df['symptoms'].str.contains(i)] = 1\nfeatured_df['has_asymptomatic'][featured_df['symptoms'].isnull()] = 1\nfeatured_df.drop('symptoms',axis=1,inplace=True)\n\nfeatured_df['outcome'] = filtered_df['outcome']\n\n#featured_df = featured_df.dropna()\nfeatured_columns = list(featured_df.columns)\nfeatured_df","5ed30b8d":"featured_df.to_csv('COVID19-age-gender-symptoms-outcome.csv')","2ce11d79":"df_concat = featured_df[featured_df['outcome'] != 'unknown']\ndf_concat","b767690c":"model_features = list(df_concat.columns)\nmodel_features","054fa9e5":"df_concat.outcome.value_counts().plot(kind=\"bar\")","6947e563":"df_concat.outcome.value_counts()","09ef5d83":"pearsoncorr = pd.concat([df_concat, \n            pd.get_dummies(df_concat['outcome'], prefix='outcome')\n          ], axis=1).corr()\n\n#fig, ax = plt.subplots(figsize=(15*5,7*5))    \n\n#sns.heatmap(pearsoncorr, annot=True, ax=ax)","3edb80d7":"m = pearsoncorr.min().isnull()\nm","faa5bbed":"for i in zip(list(m.axes[0]),list(m)):\n    if i[1]:\n        print(i)\n        df_concat.drop(i[0], axis=1, inplace=True)","13ea7a11":"df_concat","57d19f4d":"pearsoncorr = pd.concat([df_concat, \n            pd.get_dummies(df_concat['outcome'], prefix='outcome')\n          ], axis=1).corr()\n\nfig, ax = plt.subplots(figsize=(15*5,7*5))    \n\nsns.heatmap(pearsoncorr, annot=True, ax=ax)","c35ddf00":"model_features = list(df_concat.columns)\nX_inputs = df_concat[model_features[:-1]]\nX_inputs","0900e286":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(df_concat[model_features[-1:]])\nY_outputs = le.transform(df_concat[model_features[-1:]])\n\nY_outputs = pd.get_dummies(df_concat[model_features[-1:]], prefix='outcome')\nY_outputs","c2a8cf02":"Y_outputs.shape, Y_outputs.sum()#,np.array(Y_outputs)","42ab57b7":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=0)\nX_inputs, Y_outputs = ros.fit_resample(X_inputs, np.array(Y_outputs))","ccd3b489":"pd.DataFrame(Y_outputs)","8c6a9050":"#Y_outputs = np.array([i.argmax() for i in Y_outputs])\n#Y_outputs\n#for i in Y_outputs:\n#    print(i)","26e791db":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nrs = 0\nmins_s = 2\nmax_depth = 24\n\nmodel = tree.DecisionTreeClassifier(max_depth = max_depth,min_samples_leaf=mins_s, random_state=rs,\n                                        criterion= 'entropy',splitter='best')\n\n# Train\nmodel.fit(X_inputs, Y_outputs)\nmodel.score(X_inputs, Y_outputs)\n        ","d8e06700":"model.get_depth()","bc9e8905":"model","8440651f":"classes = list(le.classes_)\nclasses","b3ab8153":"from sklearn.tree import export_graphviz\nexport_graphviz(model, out_file='tree_age_sex_symptoms.dot', feature_names = list(X_inputs.columns),\n                class_names = classes,\n                rounded = True, proportion = False, precision = 2, filled = True)","5f12bb9c":"!dot -Tpng tree_age_sex_symptoms.dot -o tree_age_sex_symptoms.png -Gdpi=128","b5016fb9":"from IPython.display import Image\nImage(filename = 'tree_age_sex_symptoms.png')","6a517756":"df_concat = featured_df.copy()\ndf_concat.drop(['gender_female',\n 'gender_male',\n 'gender_unknown',\n 'age'], axis=1, inplace=True)\ndf_concat","4307cd99":"pearsoncorr = pd.concat([df_concat, \n            pd.get_dummies(df_concat['outcome'], prefix='outcome')\n          ], axis=1).corr()\n\nfig, ax = plt.subplots(figsize=(15*5,7*5))    \n\nsns.heatmap(pearsoncorr, annot=True, ax=ax)","ef790fa4":"model_features = list(df_concat.columns)\nmodel_features","571f7408":"X_inputs = df_concat[model_features[:-1]]\nX_inputs","ddd39a1e":"from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit(df_concat[model_features[-1:]])\nY_outputs = le.transform(df_concat[model_features[-1:]])\n\nY_outputs = pd.get_dummies(df_concat[model_features[-1:]], prefix='outcome')\nY_outputs","3cb6c214":"Y_outputs.shape, Y_outputs.sum(),np.array(Y_outputs)","3e7560c2":"from imblearn.over_sampling import RandomOverSampler\nros = RandomOverSampler(random_state=0)\nX_inputs, Y_outputs = ros.fit_resample(X_inputs, np.array(Y_outputs))","62c061af":"pd.DataFrame(Y_outputs)","844d62e1":"Y_outputs = np.array([i.argmax() for i in Y_outputs])\nY_outputs","9e58bfc3":"from sklearn.ensemble import RandomForestClassifier\nfrom sklearn import tree\nrs = 0\nmins_s = 125\nmax_depth = 24\nmax_acc = 0\n\nmodel = tree.DecisionTreeClassifier(max_depth = max_depth,min_samples_leaf=mins_s, random_state=rs,\n                                        criterion= 'entropy',splitter='best')\n\n# Train\nmodel.fit(X_inputs, Y_outputs)\nmodel.score(X_inputs, Y_outputs)\n","496b2437":"model.get_depth()","b4e41854":"classes = list(le.classes_)\nclasses","45f95e29":"from sklearn.tree import export_graphviz\nexport_graphviz(model, out_file='tree_symptoms_risk.dot', feature_names = list(X_inputs.columns),\n                class_names = classes,\n                rounded = True, proportion = False, precision = 2, filled = True)","16d57bb8":"!dot -Tpng tree_symptoms_risk.dot -o tree_symptoms_risk.png -Gdpi=128","c2060f45":"from IPython.display import Image\nImage(filename = 'tree_symptoms_risk.png')","a833643b":"\nfiltered_df[['age','sex','symptoms','outcome']][filtered_df['symptoms'].str.contains('cold')]","898f3787":"symptoms = ['fever', 'cough', 'sore', 'pneumonia', 'myalgia', 'cold']\n\nfor word in symptoms:\n    print('#'*30)\n    print('WORD:'+word)\n    temp_df = filtered_df[filtered_df['symptoms'].str.contains(word)]\n    print(temp_df.outcome.value_counts())\n    try:\n        print('Ages histogram')\n        temp_df.age.plot.hist()\n    except:\n        pass\n    for i in ['sex','symptoms','outcome']:\n        print('#'*15)\n        print('WORD:'+word)\n        print('COLUMN:'+i)\n        symp_str = str(temp_df[i].unique())\n        symp_str = symp_str.replace(\"'\",'')\n        symp_str = symp_str.replace(',',' ')\n        symp_str = symp_str.replace('.',' ')\n        #print(symp_str)\n        try:\n            wordcloud = WordCloud(max_words=300, background_color=\"white\").generate(symp_str)\n            plt.figure(figsize=(13,7))\n            plt.imshow(wordcloud, interpolation='spline16')\n            plt.axis(\"off\")\n            plt.show()\n        except:\n            pass\n    for word_ in symptoms:\n        if word_ != word:\n            print('#'*30)\n            print('WORDS:'+word+' AND '+word_)\n            temp_df_ = temp_df[temp_df['symptoms'].str.contains(word_)]\n            print('Outcome counts')\n            print(temp_df.outcome.value_counts())\n            try:\n                print('Age histogram')\n                temp_df_.age.plot.hist()\n            except:\n                pass\n            for i in ['sex','symptoms','outcome']:\n                print('WORDS:'+word+' AND '+word_)\n                print('COLUMN:'+i)\n                print(i)\n                symp_str = str(temp_df_[i].unique())\n                symp_str = symp_str.replace(\"'\",'')\n                symp_str = symp_str.replace(',',' ')\n                symp_str = symp_str.replace('.',' ')\n                #print(symp_str)\n                try:\n                    wordcloud = WordCloud(max_words=300, background_color=\"white\").generate(symp_str)\n                    plt.figure(figsize=(13,7))\n                    plt.imshow(wordcloud, interpolation='spline16')\n                    plt.axis(\"off\")\n                    plt.show()\n                except:\n                    pass","f1ccd89d":"# Plot correlations","9c90a763":"# What are the frequent words in the'symptoms' column based on the values of the 'outcome' column?","e517dbc9":"# How would it be if age and gender is droped out but the outcome 'unknown' is added?","de68d429":"## Rebalance dataset","aaca6e3e":"# Decision Tree - age, gender, symptoms -> outcome","97a89905":"The objective of this notebook is to explore the data by plotting word clouds, correlation matrixes and interpretable tree views through features as age, gender and symptoms of COVID-19 and the risk of death of the infected person based on records where the person lives or dies as \"low_risk\" and \"high_risk\" labels.\n\nThere is a word cloud for the patient summary without some popular words of COVID-19 context such as \"Wuhan\" or \"China\" in a way to allow a view not to the origin of this pandemic but focusing on the patient condition.\n\nThere are some word clouds for the patient symptoms with adjustment to match some words variations (see stemming).\n\nThere are some correlation matrixes before each plotted tree. The trees parameters and the data was adjusted in a way not to get the highest accuracy but to create simple, small and interpretable trees.\n\nOne-hot-encoding was applied to the distinct words in symptoms column so each word column was given the prefix \"has_\" and value 1 if the symptoms text contains the word, otherwise 0. Some words was adjusted to match its varitions like the column \"has_musc\" for \"muscular\" or \"muscle\" words occurency (see stemming).","076b7f4b":"# Symptoms dataset with age, gender and known outcome information","8462f095":"# So what are the frequent words in symptoms when it contains 'fever', 'cough', 'sore', 'pneumonia', 'myalgia' and 'cold'  values mixed in it?","76f550fd":"## Clear 'sex' column\n\nSet 'unknown' where data is null.","1f48a09e":"# What are the frequent words in the 'symptoms' column?","031945a6":"# How would be the new correlations?","eaec953d":"# How would a tree model be able to fit to the outcome through age, gender and symptoms in an interpretable way?","a208c0ac":"# What are the correlations between gender, age, symptoms and the outcome information?","fddbd13e":"# How would a tree model fit the outcome through the symptoms in an interpretable way?","6ac44b5e":"### Some cleaning and stemming","49f9e39b":"Unbalanced data spotted","7e68d542":"## Clear 'outcome' column\n\nReplace outcomes with 'died' and 'death' for 'high_risk', then 'discharged', 'discharge', 'stable' and 'recovered' for 'low_risk'.\n\nSet 'unknown' where its null.","6c2e74df":"# What are the frequent words in the 'summary' column about the patient condition?","5fde2cf6":"# Create new dataset only with age, sex and symptoms columns","7cb4ff61":"### List data columns","2ef66741":"# Tree visualization trhough age, gender and symptoms columns to the outcome","8d58b879":"## Clear 'gender' column rename to 'sex'","3194bbbd":"# Clean some columns from both datasets and match them","b958c71c":"# Tree visualization through symptoms columns to the outcome","29b5a7ae":"# Read datasets and lowercase data","70bbba9c":"# Word clouds","f85e1243":"## Translate death to 'high_risk' value","33cc0384":"Remove unused columns","126ef985":"There are a lot of unused columns as we are dealing only with data with known outcome.","47d48676":"# Is the dataset balanced?","8ee55fd7":"## COVID19_line_list_data.csv\n## Clear 'age' column","f5812421":"## Make 'outcome' column","15a61dde":"# Concatenate datasets","fe6c2742":"## COVID19_open_line_list.csv\n## Clear 'age' column\n\nRemove rows without numerical age data. Replace null ages with age column mean.","dd071812":"LabelEncoder classes will be used ahead.","1bbb829c":"## Translate death to 'high_risk' value"}}