{"cell_type":{"9839d296":"code","7ee49c5a":"code","4fb9ed2c":"code","18e03aaf":"code","730e1e3e":"code","81dab0d3":"code","a6cb85c2":"code","a677a624":"code","8e2c11fe":"code","79b8da20":"code","be058b65":"code","690668e4":"code","723e34fc":"code","06158814":"code","adb16626":"code","5d45028b":"code","6e207348":"code","05176f94":"code","4a94b30b":"code","29901669":"code","4fe83766":"code","dfef95a7":"code","2a692c31":"markdown","20a2295d":"markdown","bddade52":"markdown","bac8253f":"markdown","8f2bda6e":"markdown","efbaa706":"markdown","f7c57c17":"markdown","628d86b5":"markdown","6e8c7048":"markdown","6a63320a":"markdown","5a28b6ea":"markdown","b51a478b":"markdown","181d9663":"markdown"},"source":{"9839d296":"### This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","7ee49c5a":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\nfrom catboost import CatBoostRegressor\nfrom sklearn.preprocessing import OrdinalEncoder","4fb9ed2c":"train_data=pd.read_csv('..\/input\/30-days-of-ml\/train.csv')\ntest_data=pd.read_csv('..\/input\/30-days-of-ml\/test.csv')","18e03aaf":"train_data","730e1e3e":"train_data.describe()","81dab0d3":"train_data.isnull().sum()","a6cb85c2":"train_data.duplicated().sum()","a677a624":"train_data['target']","8e2c11fe":"sns.histplot(train_data['target'])\nplt.title('Target Visualization');","79b8da20":"sns.boxplot(train_data['target'])","be058b65":"#Data Distributions\nplt.figure(figsize=(25, 25))\nfor i, col in enumerate(list(train_data.columns)):\n    plt.subplot(7, 4, i+1)\n    sns.histplot(train_data[col], kde=True, bins=10)","690668e4":"train_data.info()","723e34fc":"train_data['cat0']","06158814":"cat_features=['cat0','cat1','cat2','cat3','cat4','cat5','cat6','cat7','cat8','cat9']\nfor col in cat_features:\n    encoder = OrdinalEncoder()\n    train_data[col] = encoder.fit_transform(np.array(train_data[col]).reshape(-1, 1))","adb16626":"cor_mat= train_data[:].corr()\nmask = np.array(cor_mat)\nmask[np.tril_indices_from(mask)] = False\nfig=plt.gcf()\nfig.set_size_inches(40,20)\nsns.heatmap(data=cor_mat,mask=mask,square=True,annot=True,cbar=True);","5d45028b":"Y=np.log1p(train_data['target']) # I used log due to Skeweness in the target column\nX=train_data.drop(['id','cont2','target'],axis=1)","6e207348":"X_train, X_valid, y_train, y_valid = train_test_split(X,Y, train_size=0.8, test_size=0.2,random_state=0)","05176f94":"catbmodel = CatBoostRegressor(\n                          iterations=6800,\n                          learning_rate=0.93,\n                          loss_function=\"RMSE\",\n                          random_state=42,\n                          verbose=0,\n                          thread_count=4,\n                          depth=1,\n                          l2_leaf_reg=3.28,\n                         )\ncatbmodel.fit(X_train, y_train,\n              eval_set=[(X_train, y_train), (X_valid, y_valid)],\n              early_stopping_rounds=100)","4a94b30b":"pred=catbmodel.predict(X_valid)\nprint(np.sqrt(mean_squared_error(abs(np.expm1(pred)),np.expm1(y_valid))))","29901669":"for col in cat_features:\n    encoder = OrdinalEncoder()\n    test_data[col] = encoder.fit_transform(np.array(test_data[col]).reshape(-1, 1))","4fe83766":"pred=np.expm1(catbmodel.predict(test_data.drop(['id','cont2'],axis=1)))\npred","dfef95a7":"output = pd.DataFrame({'id':test_data.id,\n                       'target': pred})\noutput.to_csv('submission.csv', index=False)\n\nprint(\"Your submission was successfully saved!\")","2a692c31":"# Loading Data","20a2295d":"### If you find this notebook Helpful upvote it and share your thoughts with me","bddade52":"# Data Encoding","bac8253f":"# Correlation","8f2bda6e":"# CatBoostRegressor Model","efbaa706":"* No Missing Data","f7c57c17":"* cont2 is negatively correlated with cont12,cont11,cont10,cont9 , cont8,cont7,cont5 i will drop it","628d86b5":"# Generating Submission File","6e8c7048":"# Testing","6a63320a":"# Data Visualization","5a28b6ea":"# Importing libraries","b51a478b":"# Data Spliting","181d9663":"* No Duplicates"}}