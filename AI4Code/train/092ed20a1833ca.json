{"cell_type":{"5a7e0300":"code","e9cf56c1":"code","42304835":"code","d2df662c":"code","e53a2705":"code","77614321":"code","f4251fb6":"code","a85fb1f8":"code","0eeda974":"code","42146093":"code","ed08198f":"code","6feae3fe":"code","dd6f83f6":"code","d09f9b17":"code","afb57d4e":"code","902b5086":"code","ac05e257":"code","c3264de2":"code","95f99532":"code","e3ebb0fb":"code","a1a2a26e":"code","5ebd8d85":"code","64c43e29":"code","91637b2c":"code","ffa2f61e":"code","36afdd7f":"code","414397da":"code","97a9d723":"code","3eb2c20e":"code","192b31c9":"code","732d0645":"code","a18400b9":"code","7c097ff9":"code","1b4590cc":"code","c9d9db31":"code","94aba1a4":"code","aa2ecb59":"code","9a0c7458":"code","7923561f":"code","47cc7364":"code","bb466032":"markdown","b7e15813":"markdown","8b343544":"markdown","c8ad82ab":"markdown","79919ec7":"markdown","5633a6c5":"markdown","eda7112e":"markdown","6667a32d":"markdown","ddfe91cc":"markdown","ac2f64ad":"markdown","137b0b40":"markdown","8d7b7053":"markdown","dfd69380":"markdown","baed6af0":"markdown","136da322":"markdown","eb3a9b04":"markdown","eb498e3b":"markdown","eef0cb67":"markdown"},"source":{"5a7e0300":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","e9cf56c1":"import numpy as np\nimport pandas as pd\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport matplotlib\nimport plotly.express as px\nimport re\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.compose import ColumnTransformer\nfrom IPython.display import Markdown, display","42304835":"train_df = pd.read_csv('\/kaggle\/input\/titanic\/train.csv')\ntest_df = pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","d2df662c":"train_df.columns","e53a2705":"test_df.columns","77614321":"print('Missing Values in Train data')\nprint(train_df.isnull().sum())\nprint('-'*20)\nprint('Missing Values in Test data')\nprint(test_df.isnull().sum())","f4251fb6":"train_df = train_df.drop(['Cabin'], axis=1)\ntest_df = test_df.drop(['Cabin'], axis=1)","a85fb1f8":"train_df['Age'] = train_df['Age'].fillna(train_df['Age'].mean())\ntest_df['Age'] = test_df['Age'].fillna(test_df['Age'].mean())","0eeda974":"train_df['Embarked'].mode()","42146093":"train_df['Embarked'] = train_df['Embarked'].fillna('S')","ed08198f":"sns.displot(train_df['Fare'], bins=30)","6feae3fe":"test_df['Fare'] = test_df['Fare'].fillna(train_df['Fare'].mode()[0])","dd6f83f6":"print('Missing Values in Train data')\nprint(train_df.isnull().sum())\nprint('-'*20)\nprint('Missing Values in Test data')\nprint(test_df.isnull().sum())","d09f9b17":"train_df['Family'] = train_df['SibSp'] + train_df['Parch']\ntest_df['Family'] = test_df['SibSp'] + test_df['Parch']\ntrain_df = train_df.drop(['SibSp', 'Parch'], axis=1)\ntest_df = test_df.drop(['SibSp', 'Parch'], axis=1)","afb57d4e":"cols = ['Fare', 'Age']\nfor col in cols:\n    train_df[col] = train_df[col].astype('int32')\n    test_df[col] = test_df[col].astype('int32')","902b5086":"titles_train = []\nfor i in range(0, len(train_df['Name'])):\n    title = (train_df.loc[i, 'Name'].split(', ')[1]).split(' ')[0]\n    titles_train.append(title)\n\ntitles_test = []\nfor i in range(0, len(test_df['Name'])):\n    title = (test_df.loc[i, 'Name'].split(', ')[1]).split(' ')[0]\n    titles_test.append(title)\n    \ntrain_df['Title'] = titles_train\ntest_df['Title'] = titles_test\n\ntrain_df = train_df.drop(['Name'], axis=1)\ntest_df = test_df.drop(['Name'], axis=1)","ac05e257":"# Get Ticket prefix values\nc = -1\ntick = {}\nfor i in range(len(train_df['Ticket'])):\n    c += 1\n    match = re.search('^[a-zA-Z]+', train_df.loc[i, 'Ticket'])\n    if match:\n        tick[c] = match.group()","c3264de2":"tick = pd.Series(tick)\ntick_prefix_train = []\nfor i in range(len(train_df['Ticket'])):\n    match = re.search('^[a-zA-Z]+', train_df.loc[i,'Ticket'])\n    if match:\n        tick_prefix_train.append(match.group())\n    else:\n        tick_prefix_train.append('Null')\n        \ntick_prefix_test = []\nfor i in range(len(test_df['Ticket'])):\n    match = re.search('^[a-zA-Z]+', test_df.loc[i, 'Ticket'])\n    if match:\n        tick_prefix_test.append(match.group())\n    else:\n        tick_prefix_test.append('Null')","95f99532":"train_df['Ticket_prefix'] = tick_prefix_train\ntest_df['Ticket_prefix'] = tick_prefix_test","e3ebb0fb":"train_df = train_df.drop(['Ticket'], axis=1)\ntest_df = test_df.drop(['Ticket'], axis=1)","a1a2a26e":"train_df.head()","5ebd8d85":"def meanEncoding(column):\n    new_smooth_name = column + '_smean_encod'\n    mean = train_df['Survived'].mean()\n    agg = train_df.groupby(column)['Survived'].agg(['count', 'mean'])\n    counts = agg['count']\n    means = agg['mean']\n    weight = 100\n    smooth = (counts*mean + weight*mean)\/(counts + weight)\n    train_df.loc[:, new_smooth_name] = train_df[column].map(smooth)\n    test_df.loc[:, new_smooth_name] = test_df[column].map(smooth)","64c43e29":"meanEncoding('Ticket_prefix')\nmeanEncoding('Title')","91637b2c":"print('Missing Values in Train data')\nprint(train_df.isnull().sum())\nprint('-'*20)\nprint('Missing Values in Test data')\nprint(test_df.isnull().sum())","ffa2f61e":"test_df['Ticket_prefix_smean_encod'] = test_df['Ticket_prefix_smean_encod'].fillna(train_df['Ticket_prefix_smean_encod'].mean())\ntest_df['Title_smean_encod'] = test_df['Title_smean_encod'].fillna(train_df['Title_smean_encod'].mean())","36afdd7f":"print('Missing Values in Train data')\nprint(train_df.isnull().sum())\nprint('-'*20)\nprint('Missing Values in Test data')\nprint(test_df.isnull().sum())","414397da":"# Sex\ntrain_df['Sex_female'] = pd.get_dummies(train_df.Sex, prefix='Sex')['Sex_female']\ntrain_df['Sex_male'] = pd.get_dummies(train_df.Sex, prefix='Sex')['Sex_male']\ntest_df['Sex_female'] = pd.get_dummies(test_df.Sex, prefix='Sex')['Sex_female']\ntest_df['Sex_male'] = pd.get_dummies(test_df.Sex, prefix='Sex')['Sex_male']","97a9d723":"# Pclass\ntrain_df['Pclass_1'] = pd.get_dummies(train_df.Pclass, prefix='Pclass')['Pclass_1']\ntrain_df['Pclass_2'] = pd.get_dummies(train_df.Pclass, prefix='Pclass')['Pclass_2']\ntrain_df['Pclass_3'] = pd.get_dummies(train_df.Pclass, prefix='Pclass')['Pclass_3']\n\ntest_df['Pclass_1'] = pd.get_dummies(test_df.Pclass, prefix='Pclass')['Pclass_1']\ntest_df['Pclass_2'] = pd.get_dummies(test_df.Pclass, prefix='Pclass')['Pclass_2']\ntest_df['Pclass_3'] = pd.get_dummies(test_df.Pclass, prefix='Pclass')['Pclass_3']","3eb2c20e":"# Embarked\ntrain_df['Embarked_C'] = pd.get_dummies(train_df.Embarked, prefix='Embarked')['Embarked_C']\ntrain_df['Embarked_Q'] = pd.get_dummies(train_df.Embarked, prefix='Embarked')['Embarked_Q']\ntrain_df['Embarked_S'] = pd.get_dummies(train_df.Embarked, prefix='Embarked')['Embarked_S']\n\ntest_df['Embarked_C'] = pd.get_dummies(test_df.Embarked, prefix='Embarked')['Embarked_C']\ntest_df['Embarked_Q'] = pd.get_dummies(test_df.Embarked, prefix='Embarked')['Embarked_Q']\ntest_df['Embarked_S'] = pd.get_dummies(test_df.Embarked, prefix='Embarked')['Embarked_S']","192b31c9":"train_df.columns","732d0645":"test_Id = test_df.PassengerId\ndrop_features = ['PassengerId', 'Pclass', 'Sex', 'Embarked', 'Title', 'Ticket_prefix']\ntrain_df = train_df.drop(drop_features, axis=1)\ntest_df = test_df.drop(drop_features, axis=1)","a18400b9":"train_survived = train_df['Survived']\ntrain_df = train_df.drop(['Survived'], axis=1)\ntrain_df['Survived'] = train_survived","7c097ff9":"train_df.head()","1b4590cc":"fig, ax = plt.subplots(figsize=(12, 10))\nmy_c = sns.diverging_palette(20, 220, as_cmap=True)\nmask = np.triu(train_df.corr())\nsns.heatmap(train_df.corr(), cmap=my_c, linewidths=1.5, ax=ax, annot=True, mask=mask)","c9d9db31":"from sklearn.model_selection import train_test_split\n\nX = train_df.iloc[:,:-1]\ny = train_df.iloc[:,-1]\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=28)","94aba1a4":"from sklearn.preprocessing import MinMaxScaler\nmin_max_scaler = MinMaxScaler()\nX_train = min_max_scaler.fit_transform(X_train)\nX_test = min_max_scaler.fit_transform(X_test)\ntest_df = min_max_scaler.fit_transform(test_df)","aa2ecb59":"from sklearn.ensemble import GradientBoostingClassifier\ngbc = GradientBoostingClassifier(n_estimators = 2000, learning_rate=0.001, max_depth=2, random_state=28).fit(X_train, y_train)","9a0c7458":"y_pred = gbc.predict(X_test)\naccuracy_score(y_pred, y_test)","7923561f":"y_pred = gbc.predict(test_df)","47cc7364":"submission = pd.DataFrame({'PassengerID': test_Id, 'Survived':y_pred})\nsubmission.to_csv('submission.csv', index=False)","bb466032":"### Splitting Data","b7e15813":"### Column Transformations","8b343544":"### Import Necessary Libraries","c8ad82ab":"#### Ticket","79919ec7":"### Correlation","5633a6c5":"#### SibSp and Parch","eda7112e":"### Submission","6667a32d":"#### Fare and Age","ddfe91cc":"#### One Hot Encoding for **Sex**, **Embarked** and **Pclass** features","ac2f64ad":"### Data Preprocessing","137b0b40":"### Categorical Encoding","8d7b7053":"There are some values in test set which weren't mapped to the smooth values","dfd69380":"As we see:\n* 20% **Age** values are missing -> replace missing values by mean of **Age** feature\n* 77% **Cabin** values are missing -> we should drop this feature\n* Missing values of **Embarked** and **Fare** are small","baed6af0":"#### 2. XGBoost","136da322":"#### Missing Values","eb3a9b04":"### Models","eb498e3b":"#### Name","eef0cb67":"#### Mean Encoding for Ticket_prefix and Title columns"}}