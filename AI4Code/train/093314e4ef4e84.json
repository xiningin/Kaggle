{"cell_type":{"fae0eb7b":"code","77cdc83d":"code","fdc9ace4":"code","2dfd968e":"code","ee876c67":"code","a98279b7":"code","dea6dd0d":"code","718e7e56":"code","9930e8c8":"code","7c4acd0f":"code","470e1fe7":"code","b8868f83":"code","4f89c872":"code","9d6b39a6":"code","2b3d9661":"code","08d843bc":"code","3affea54":"code","2980c468":"code","0be73258":"code","fd83aeaf":"markdown","f65e62f9":"markdown","02424163":"markdown","3200e08b":"markdown","281375cf":"markdown","be13e282":"markdown","ea21bb98":"markdown","768c2316":"markdown","e5acaca9":"markdown","7224bac5":"markdown","078c0e4a":"markdown","e5cb3a5d":"markdown","13c69abf":"markdown","d02c750d":"markdown","a4b858b7":"markdown","2f65c598":"markdown","9e69dcae":"markdown","1343fe46":"markdown","aca5b829":"markdown","6575fa80":"markdown","3ab2e62e":"markdown","450e3650":"markdown","51546a4f":"markdown","fe7a72d8":"markdown","b554f989":"markdown","c0056af6":"markdown","05c7cd7c":"markdown","91555a0c":"markdown"},"source":{"fae0eb7b":"# Python libraries\nimport pandas as pd\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt \nimport seaborn as sns\nfrom datetime import datetime\nimport lightgbm as lgbm\nfrom sklearn.preprocessing import StandardScaler, LabelEncoder\nfrom sklearn.model_selection import GridSearchCV, RandomizedSearchCV, cross_val_score, train_test_split\nfrom sklearn.metrics import precision_score, roc_auc_score, recall_score, confusion_matrix, roc_curve, precision_recall_curve, accuracy_score\nfrom scipy.stats import randint as sp_randint\nfrom scipy.stats import uniform as sp_uniform\nimport warnings\nimport plotly.offline as py\npy.init_notebook_mode(connected=True)\nimport plotly.graph_objs as go\nimport plotly.tools as tls\nimport plotly.figure_factory as ff\n\nwarnings.filterwarnings('ignore')\n\nfrom contextlib import contextmanager\n\n@contextmanager\ndef timer(title):\n    t0 = time.time()\n    yield\n    print(\"{} - done in {:.0f}s\".format(title, time.time() - t0))","77cdc83d":"#Read\ndata = pd.read_csv('..\/input\/creditcard.csv')","fdc9ace4":"display(data.head())\ndisplay(data.describe())\ndisplay(data.shape)\ndisplay(data.info())","2dfd968e":"plt.style.use('ggplot') # Using ggplot2 style visuals \n\nf, ax = plt.subplots(figsize=(11, 15))\n\nax.set_facecolor('#fafafa')\nax.set(xlim=(-5, 5))\nplt.ylabel('Variables')\nplt.title(\"Overview Data Set\")\nax = sns.boxplot(data = data.drop(columns=['Amount', 'Class', 'Time']), \n  orient = 'h', \n  palette = 'Set2')","ee876c67":"fraud = data[(data['Class'] != 0)]\nnormal = data[(data['Class'] == 0)]\n\ntrace = go.Pie(labels = ['Normal', 'Fraud'], values = data['Class'].value_counts(), \n               textfont=dict(size=15), opacity = 0.8,\n               marker=dict(colors=['lightskyblue','gold'], \n                           line=dict(color='#000000', width=1.5)))\n\n\nlayout = dict(title =  'Distribution of target variable')\n           \nfig = dict(data = [trace], layout=layout)\npy.iplot(fig)","a98279b7":"# Def plot distribution\ndef plot_distribution(data_select) : \n    figsize =( 15, 8)\n    sns.set_style(\"ticks\")\n    s = sns.FacetGrid(data, hue = 'Class',aspect = 2.5, palette ={0 : 'lime', 1 :'black'})\n    s.map(sns.kdeplot, data_select, shade = True, alpha = 0.6)\n    s.set(xlim=(data[data_select].min(), data[data_select].max()))\n    s.add_legend()\n    s.set_axis_labels(data_select, 'proportion')\n    s.fig.suptitle(data_select)\n    plt.show()","dea6dd0d":"#plot_distribution('V1')\n#plot_distribution('V2')\n#plot_distribution('V3')\nplot_distribution('V4')\n#plot_distribution('V5')\n#plot_distribution('V6')\n#plot_distribution('V7')\n#plot_distribution('V8')\nplot_distribution('V9')\n#plot_distribution('V10')\nplot_distribution('V11')\nplot_distribution('V12')\nplot_distribution('V13')\n#plot_distribution('V14')\n#plot_distribution('V15')\n#plot_distribution('V16')\n#plot_distribution('V17')\n#plot_distribution('V18')\nplot_distribution('V19')\n#plot_distribution('V20')\n#plot_distribution('V21')\n#plot_distribution('V22')\n#plot_distribution('V23')\nplot_distribution('V24')\n#plot_distribution('V25')\nplot_distribution('V26')\n#plot_distribution('V27')\n#plot_distribution('V28')","718e7e56":"# Correlation matrix \nf, (ax1, ax2) = plt.subplots(1,2,figsize =( 18, 8))\ncorr = data.corr()\nmask = np.zeros_like(corr, dtype=np.bool)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap((data.loc[data['Class'] ==1]).corr(), vmax = .8, square=True, ax = ax1, cmap = 'afmhot', mask=mask);\nax1.set_title('Fraud')\nsns.heatmap((data.loc[data['Class'] ==0]).corr(), vmax = .8, square=True, ax = ax2, cmap = 'YlGnBu', mask=mask);\nax2.set_title('Normal')\nplt.show()","9930e8c8":"# Normalization Amount\nfrom sklearn.preprocessing import StandardScaler\ndata['nAmount'] = StandardScaler().fit_transform(data['Amount'].values.reshape(-1,1))","7c4acd0f":"# Drop useless variables\ndata = data.drop(['Amount','Time'],axis=1)","470e1fe7":"# def X and Y\ny = np.array(data.Class.tolist())\ndata = data.drop('Class', 1)\nX = np.array(data.as_matrix())","b8868f83":"# Train_test split\nrandom_state = 42\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.20, random_state = random_state, stratify = y)","4f89c872":"def model_performance(model) : \n    #Conf matrix\n    conf_matrix = confusion_matrix(y_test, y_pred)\n    trace1 = go.Heatmap(z = conf_matrix  ,x = [\"0 (pred)\",\"1 (pred)\"],\n                        y = [\"0 (true)\",\"1 (true)\"],xgap = 2, ygap = 2, \n                        colorscale = 'Viridis', showscale  = False)\n\n    #Show metrics\n    tp = conf_matrix[1,1]\n    fn = conf_matrix[1,0]\n    fp = conf_matrix[0,1]\n    tn = conf_matrix[0,0]\n    Accuracy  =  ((tp+tn)\/(tp+tn+fp+fn))\n    Precision =  (tp\/(tp+fp))\n    Recall    =  (tp\/(tp+fn))\n    F1_score  =  (2*(((tp\/(tp+fp))*(tp\/(tp+fn)))\/((tp\/(tp+fp))+(tp\/(tp+fn)))))\n\n    show_metrics = pd.DataFrame(data=[[Accuracy , Precision, Recall, F1_score]])\n    show_metrics = show_metrics.T\n\n    colors = ['gold', 'lightgreen', 'lightcoral', 'lightskyblue']\n    trace2 = go.Bar(x = (show_metrics[0].values), \n                   y = ['Accuracy', 'Precision', 'Recall', 'F1_score'], text = np.round_(show_metrics[0].values,4),\n                    textposition = 'auto',\n                   orientation = 'h', opacity = 0.8,marker=dict(\n            color=colors,\n            line=dict(color='#000000',width=1.5)))\n    \n    #Roc curve\n    model_roc_auc = round(roc_auc_score(y_test, y_score) , 3)\n    fpr, tpr, t = roc_curve(y_test, y_score)\n    trace3 = go.Scatter(x = fpr,y = tpr,\n                        name = \"Roc : \" + str(model_roc_auc),\n                        line = dict(color = ('rgb(22, 96, 167)'),width = 2), fill='tozeroy')\n    trace4 = go.Scatter(x = [0,1],y = [0,1],\n                        line = dict(color = ('black'),width = 1.5,\n                        dash = 'dot'))\n    \n    # Precision-recall curve\n    precision, recall, thresholds = precision_recall_curve(y_test, y_score)\n    trace5 = go.Scatter(x = recall, y = precision,\n                        name = \"Precision\" + str(precision),\n                        line = dict(color = ('lightcoral'),width = 2), fill='tozeroy')\n    \n    #Feature importance\n    coefficients  = pd.DataFrame(eval(model).feature_importances_)\n    column_data   = pd.DataFrame(list(data))\n    coef_sumry    = (pd.merge(coefficients,column_data,left_index= True,\n                              right_index= True, how = \"left\"))\n    coef_sumry.columns = [\"coefficients\",\"features\"]\n    coef_sumry    = coef_sumry.sort_values(by = \"coefficients\",ascending = False)\n    coef_sumry = coef_sumry[coef_sumry[\"coefficients\"] !=0]\n    trace6 = go.Bar(x = coef_sumry[\"features\"],y = coef_sumry[\"coefficients\"],\n                    name = \"coefficients\",\n                    marker = dict(color = coef_sumry[\"coefficients\"],\n                                  colorscale = \"Viridis\",\n                                  line = dict(width = .6,color = \"black\")))\n    \n    #Cumulative gain\n    pos = pd.get_dummies(y_test).as_matrix()\n    pos = pos[:,1] \n    npos = np.sum(pos)\n    index = np.argsort(y_score) \n    index = index[::-1] \n    sort_pos = pos[index]\n    #cumulative sum\n    cpos = np.cumsum(sort_pos) \n    #recall\n    recall = cpos\/npos \n    #size obs test\n    n = y_test.shape[0] \n    size = np.arange(start=1,stop=369,step=1) \n    #proportion\n    size = size \/ n \n    #plots\n    model = model\n    trace7 = go.Scatter(x = size,y = recall,\n                        name = \"Lift curve\",\n                        line = dict(color = ('gold'),width = 2), fill='tozeroy') \n    \n    #Subplots\n    fig = tls.make_subplots(rows=4, cols=2, print_grid=False, \n                          specs=[[{}, {}], \n                                 [{}, {}],\n                                 [{'colspan': 2}, None],\n                                 [{'colspan': 2}, None]],\n                          subplot_titles=('Confusion Matrix',\n                                        'Metrics',\n                                        'ROC curve'+\" \"+ '('+ str(model_roc_auc)+')',\n                                        'Precision - Recall curve',\n                                        'Cumulative gains curve',\n                                        'Feature importance',\n                                        ))\n    \n    fig.append_trace(trace1,1,1)\n    fig.append_trace(trace2,1,2)\n    fig.append_trace(trace3,2,1)\n    fig.append_trace(trace4,2,1)\n    fig.append_trace(trace5,2,2)\n    fig.append_trace(trace6,4,1)\n    fig.append_trace(trace7,3,1)\n    \n    fig['layout'].update(showlegend = False, title = '<b>Model performance report<\/b><br>'+str(model),\n                        autosize = False, height = 1500,width = 830,\n                        plot_bgcolor = 'rgba(240,240,240, 0.95)',\n                        paper_bgcolor = 'rgba(240,240,240, 0.95)',\n                        margin = dict(b = 195))\n    fig[\"layout\"][\"xaxis2\"].update((dict(range=[0, 1])))\n    fig[\"layout\"][\"xaxis3\"].update(dict(title = \"false positive rate\"))\n    fig[\"layout\"][\"yaxis3\"].update(dict(title = \"true positive rate\"))\n    fig[\"layout\"][\"xaxis4\"].update(dict(title = \"recall\"), range = [0,1.05])\n    fig[\"layout\"][\"yaxis4\"].update(dict(title = \"precision\"), range = [0,1.05])\n    fig[\"layout\"][\"xaxis5\"].update(dict(title = \"Percentage contacted\"))\n    fig[\"layout\"][\"yaxis5\"].update(dict(title = \"Percentage positive targeted\"))\n    fig.layout.titlefont.size = 14\n    \n    py.iplot(fig)","9d6b39a6":"%%time\nlgbm_clf = lgbm.LGBMClassifier(n_estimators=100, random_state = 42)\n\nlgbm_clf.fit(X_train, y_train)\nlgbm_clf.fit(X_train, y_train)\ny_pred = lgbm_clf.predict(X_test)\ny_score = lgbm_clf.predict_proba(X_test)[:,1]","2b3d9661":"model_performance('lgbm_clf')","08d843bc":"fit_params = {\"early_stopping_rounds\" : 50, \n             \"eval_metric\" : 'binary', \n             \"eval_set\" : [(X_test,y_test)],\n             'eval_names': ['valid'],\n             'verbose': 0,\n             'categorical_feature': 'auto'}\n\nparam_test = {'learning_rate' : [0.01, 0.02, 0.03, 0.04, 0.05, 0.08, 0.1, 0.2, 0.3, 0.4],\n              'n_estimators' : [100, 200, 300, 400, 500, 600, 800, 1000, 1500, 2000, 3000, 5000],\n              'num_leaves': sp_randint(6, 50), \n              'min_child_samples': sp_randint(100, 500), \n              'min_child_weight': [1e-5, 1e-3, 1e-2, 1e-1, 1, 1e1, 1e2, 1e3, 1e4],\n              'subsample': sp_uniform(loc=0.2, scale=0.8), \n              'max_depth': [-1, 1, 2, 3, 4, 5, 6, 7],\n              'colsample_bytree': sp_uniform(loc=0.4, scale=0.6),\n              'reg_alpha': [0, 1e-1, 1, 2, 5, 7, 10, 50, 100],\n              'reg_lambda': [0, 1e-1, 1, 5, 10, 20, 50, 100]}\n\n#number of combinations\nn_iter = 2 #(replace 2 by 200, 90 minutes)\n\n#intialize lgbm and lunch the search\nlgbm_clf = lgbm.LGBMClassifier(random_state=random_state, silent=True, metric='None', n_jobs=4)\ngrid_search = RandomizedSearchCV(\n    estimator=lgbm_clf, param_distributions=param_test, \n    n_iter=n_iter,\n    scoring='accuracy',\n    cv=5,\n    refit=True,\n    random_state=random_state,\n    verbose=True)\n\ngrid_search.fit(X_train, y_train, **fit_params)\nprint('Best score reached: {} with params: {} '.format(grid_search.best_score_, grid_search.best_params_))\n\nopt_parameters =  grid_search.best_params_\n\nclf_sw = lgbm.LGBMClassifier(**lgbm_clf.get_params())\n#Optimal parameter\nclf_sw.set_params(**opt_parameters)","3affea54":"%%time\nlgbm_clf = lgbm.LGBMClassifier(boosting_type='gbdt', class_weight=None,\n        colsample_bytree=0.5112837457460335, importance_type='split',\n        learning_rate=0.02, max_depth=7, metric='None',\n        min_child_samples=195, min_child_weight=0.01, min_split_gain=0.0,\n        n_estimators=3000, n_jobs=4, num_leaves=44, objective=None,\n        random_state=42, reg_alpha=2, reg_lambda=10, silent=True,\n        subsample=0.8137506311449016, subsample_for_bin=200000,\n        subsample_freq=0)\n\nlgbm_clf.fit(X_train, y_train)\nlgbm_clf.fit(X_train, y_train)\ny_pred = lgbm_clf.predict(X_test)\ny_score = lgbm_clf.predict_proba(X_test)[:,1]","2980c468":"model_performance('lgbm_clf')","0be73258":"scores = cross_val_score(lgbm_clf, X, y, scoring = 'f1', cv=5)\ntrace = go.Table(\n    header=dict(values=['<b>F1 score mean<b>', '<b>F1 score std<b>'],\n                line = dict(color='#7D7F80'),\n                fill = dict(color='#a1c3d1'),\n                align = ['center'],\n                font = dict(size = 15)),\n    cells=dict(values=[np.round(scores.mean(),6),\n                       np.round(scores.std(),6)],\n               line = dict(color='#7D7F80'),\n               fill = dict(color='#EDFAFF'),\n               align = ['center'], font = dict(size = 15)))\n\nlayout = dict(width=800, height=500, title = 'Cross validation - 5 folds [F1 score]', font = dict(size = 15))\nfig = dict(data=[trace], layout=layout)\npy.iplot(fig, filename = 'styled_table')","fd83aeaf":"![](http:\/\/image.noelshack.com\/fichiers\/2019\/02\/1\/1546870493-random-search.jpg)","f65e62f9":"To find the best hyperparameters, we'll use Random Search CV.\n\nRandom search is a technique where random combinations of the hyperparameters are used to find the best solution for the built model. \nGenerally RS is more faster and accurate than GridSearchCV who calculate all possible combinations. With Random Grid we specify the number of combinations that we want","02424163":"## <a id='4.3'>4.3. LightGBM - After RandomizedSearchCV<\/a>","3200e08b":"----------\n**LightGBM + Plotly **\n=====================================\n\n* **F1 score - test  : 0.862**\n* **F1 score - CV    : 0.821**\n\n***Vincent Lugat***\n\n*November 2018*\n\n----------","281375cf":"## <a id='1.1'>1.1. Load libraries<\/a>","be13e282":"# <a id='#2'>2. Prepare dataset<\/a>","ea21bb98":"## <a id='2.2'>2.2. Drop useless variables<\/a>","768c2316":"![](http:\/\/image.noelshack.com\/fichiers\/2019\/06\/1\/1549285917-0000000000000000000.png)\n\n** LightGBM** is a gradient boosting framework that uses tree based learning algorithms. It is designed to be distributed and efficient with the following advantages:\n\n* Faster training speed and higher efficiency.\n* Lower memory usage.\n* Better accuracy.\n* Support of parallel and GPU learning.\n* Capable of handling large-scale data.","e5acaca9":"## <a id='4.2'>4.2. LightGBM - RandomizedSearchCV to optimise hyperparameters<\/a>","7224bac5":"## <a id='1.6'>1.6. Correlation matrix<\/a>","078c0e4a":"# <a id='#1'>1. Load libraries and read the data<\/a>","e5cb3a5d":"## <a id='#2.1'>2.1. Normalization Amount<\/a>","13c69abf":"![](http:\/\/image.noelshack.com\/fichiers\/2018\/45\/7\/1541947949-1-1-1-card.png)\n\n\n-------------------\n\n- <a href='#1'>1. Load libraries and read the data<\/a>  \n\n     - <a href='#1.1'>1.1. Load libraries<\/a>\n     - <a href='#1.2'>1.2. Read the data<\/a>\n     - <a href='#1.3'>1.3. Head, describe, shape and info<\/a>\n     - <a href='#1.4'>1.4. Target distribution<\/a>\n     - <a href='#1.5'>1.5. Features distribution<\/a>\n     - <a href='#1.6'>1.6. Correlation matrix<\/a>\n     \n- <a href='#2'>2. Prepare dataset<\/a>\n\n     - <a href='#2.1'>2.1. Normalization Amount<\/a>\n     - <a href='#2.2'>2.2. Drop useless variables<\/a>\n     - <a href='#2.3'>2.3. Define (X, y)<\/a>\n     - <a href='#2.4'>2.4. Stratified train-test split<\/a>\n     \n- <a href='#3'>3. Define model performance<\/a>\n\n- <a href='#4'>4. LightGBM Model<\/a>\n\n    - <a href='#4.1'>4.1. LightGBM - Before RandomizedSearchCV<\/a>\n    - <a href='#4.2'>4.2. LightGBM - RandomizedSearchCV to optimise hyperparameters (soon!)<\/a>\n    - <a href='#4.3'>4.3. LightGBM - After RandomizedSearchCV<\/a>\n    - <a href='#4.4'>4.4. LightGBM - Cross Validation - 5 folds [F1 score]<\/a>\n    \n- <a href='#5'>5. Reference<\/a>\n\n-------------------\n","d02c750d":"## <a id='2.4'>2.4. Stratified train test split<\/a>","a4b858b7":"* **LightGBM : Hyperparameters ** :\n\n    * learning_rate : This determines the impact of each tree on the final outcome. GBM works by starting with an initial estimate which is updated using the output of each tree. The learning parameter controls the magnitude of this change in the estimates\n    * n_estimators : number of trees (or rounds)\n    * num_leaves : number of leaves in full tree, default: 31\n    * min_child_samples : minimal number of data in one leaf. Can be used to deal with over-fitting\n    * min_child_weight : minimal sum hessian in one leaf.\n    * subsample : randomly select part of data without resampling\n    * max_depth : It describes the maximum depth of tree. This parameter is used to handle model overfitting.\n    * colsample_bytree : LightGBM will randomly select part of features on each iteration if colsample_bytree smaller than 1.0. For example, if you set it to 0.8, LightGBM will select 80% of features before training each tree\n    * reg_alpha : regularization\n    * reg_lambda : regularization\n    \n    * early_stopping_rounds : This parameter can help you speed up your analysis. Model will stop training if one metric of one validation data doesn\u2019t improve in last early_stopping_round rounds. This will reduce excessive iterations","2f65c598":"# <a id='3'>3. Define model performance<\/a>","9e69dcae":"## <a id='1.4'>1.4. Target distribution<\/a>","1343fe46":"**Thank you all ! Merci \u00e0 tous ! :)**","aca5b829":"## <a id='4.1'>4.1. LightGBM - Before RandomizedSearchCV<\/a>","6575fa80":"## <a id='1.3'>1.3. Head, describe, shape and info<\/a>","3ab2e62e":"## <a id='4'>4. LightGBM Model<\/a>","450e3650":"## <a id='4.4'>4.4. LightGBM - Cross validation - 5 folds [F1 score]<\/a>","51546a4f":"https:\/\/www.kaggle.com\/pavanraj159 (plotly master)","fe7a72d8":"To measure the performance of a model, we need several elements :\n\nThis part is essential\n\n* **Confusion matrix** : also known as the error matrix, allows visualization of the performance of an algorithm :\n\n    * true positive (TP) : Diabetic correctly identified as diabetic\n    * true negative (TN) : Healthy correctly identified as healthy\n    * false positive (FP) : Healthy incorrectly identified as diabetic\n    * false negative (FN) : Diabetic incorrectly identified as healthy\n\n![](https:\/\/image.noelshack.com\/fichiers\/2018\/20\/5\/1526651914-cs-heezweaa5hp7.jpg)\n\n* **Metrics ** :\n\n    * Accuracy : (TP +TN) \/ (TP + TN + FP +FN)\n    * Precision : TP \/ (TP + FP)\n    * Recall : TP \/ (TP + FN)\n    * F1 score : 2 x ((Precision x Recall) \/ (Precision + Recall))\n\n* **Roc Curve** : The ROC curve is created by plotting the true positive rate (TPR) against the false positive rate (FPR) at various threshold settings.\n\n![](http:\/\/image.noelshack.com\/fichiers\/2019\/06\/1\/1549284841-0-0-0-0-0-0-0-0-0-0.png)\n\n* **Precision Recall Curve** :  shows the tradeoff between precision and recall for different threshold","b554f989":"## <a id='1.5'>1.5. Features distribution<\/a>","c0056af6":"## <a id='2.3'>2.3. Define (X, y)<\/a>","05c7cd7c":"## <a id='5'>5. Reference<\/a>","91555a0c":"## <a id='1.2'>1.2. Read the data<\/a>"}}