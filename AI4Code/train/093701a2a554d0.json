{"cell_type":{"1ed80213":"code","a9d5a060":"markdown"},"source":{"1ed80213":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\nfrom tqdm import tqdm\nimport numpy as np\nimport pandas as pd\nimport os\nimport lightgbm as lgb\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.metrics import roc_auc_score\nimport time\nimport gc\nfrom sklearn import neighbors\nfrom sklearn import metrics, preprocessing\nfrom sklearn.feature_selection import VarianceThreshold\n\n###############################################################################\n################################## Data\n###############################################################################\ntrain = pd.read_csv('..\/input\/train.csv')\ntest = pd.read_csv('..\/input\/test.csv')\n\nX = train.iloc[:,1:257]\nX_test = test.iloc[:,1:257]\nY = train.iloc[:,257]\n\ncols = [c for c in train.columns if c not in ['id', 'target']]\n\ncols.remove('wheezy-copper-turtle-magic')\n\nprediction = np.zeros(len(test))\n\nscaler = preprocessing.StandardScaler()\n\nscaler.fit(X)\nX = scaler.transform(X)\nX_test = scaler.transform(X_test)\n\noof = np.zeros(len(train))\nst = time.time()\nfor i in tqdm(range(512)):\n    if i%5==0: print('Model : ',i, 'Time : ', time.time()-st)\n\n    x = train[train['wheezy-copper-turtle-magic']==i]\n    x_test = test[test['wheezy-copper-turtle-magic']==i]\n    y = Y[train['wheezy-copper-turtle-magic']==i]\n    idx = x.index\n    idx_test = x_test.index\n    x.reset_index(drop=True,inplace=True)\n    x_test.reset_index(drop=True,inplace=True)\n    y.reset_index(drop=True,inplace=True)\n    \n    clf = lgb.LGBMRegressor()\n    clf.fit(x[cols],y)\n    important_features = [i for i in range(len(cols)) if clf.feature_importances_[i] > 0] \n    cols_important = [cols[i] for i in important_features]\n    \n    sel = VarianceThreshold(threshold=1.5).fit(x[cols])\n    train3 = sel.transform(x[cols])\n    test3 = sel.transform(x_test[cols]) #on peut mettre cols_important aussi\n    n_folds=10\n    skf = StratifiedKFold(n_splits=n_folds, random_state=42)\n    for train_index, valid_index in skf.split(train3, y):\n        # KNN\n#         clf = neighbors.KNeighborsClassifier(n_neighbors  =7, p=2, weights ='distance')\n#         clf.fit(train3[train_index], y[train_index])\n#         oof[idx[valid_index]] = clf.predict_proba(train3[valid_index])[:,1]\n#         prediction[idx_test] += clf.predict_proba(test3)[:,1] \/ 25.0\n            param = {\n            'n_jobs' : -1,\n            'boosting': 'gbdt',\n            'learning_rate': 0.05,\n            #'max_depth': 24,\n            'metric': 'auc',\n            #'num_leaves': 454,\n            'objective': 'binary',\n            #'subsample': 0.94\n            }\n\n            train_dataset = lgb.Dataset(train3[train_index], y[train_index])\n            val_dataset = lgb.Dataset(train3[valid_index], y[valid_index])\n            \n            clf = lgb.train(param, train_dataset, valid_sets=[train_dataset, val_dataset], verbose_eval=False,\n                              num_boost_round=5000, early_stopping_rounds=250)\n            \n            oof[idx[valid_index]] = clf.predict(train3[valid_index], num_iteration=clf.best_iteration)\n            prediction[idx_test] += clf.predict(test3, num_iteration=clf.best_iteration) \/ n_folds\n            \n    print(i, 'oof auc : ', roc_auc_score(Y[idx], oof[idx]))\n        \nprint('total auc : ',roc_auc_score(train['target'],oof))\n\nsub = pd.read_csv('..\/input\/sample_submission.csv')\nsub['target'] = prediction\nsub.to_csv('submission.csv',index=False)","a9d5a060":"This kernel is a modification of https:\/\/www.kaggle.com\/nvnnghia\/512-knn-10-with-lgb-feature-selection . \nI replaced the K-NN models by LGBM models. "}}