{"cell_type":{"28c01503":"code","9d2cd585":"code","b66c5988":"code","1b5e6473":"code","6ccfcee5":"code","07b820a3":"code","2be1ef1b":"code","9b058846":"code","4ff8337e":"code","bd5ca550":"code","c303f422":"code","4eea8daa":"code","b6ff05d4":"code","24102754":"code","b0619331":"code","9a2dac65":"code","ee8ec668":"code","ac27b0d5":"code","89cfd6e3":"code","4ffa1bfb":"code","f07e0801":"code","cbbf36e2":"code","bedc09b1":"code","c7e3705f":"code","505fe22a":"code","3d5fba47":"code","7f083ca4":"code","9d4cca15":"code","83e0057c":"code","4e622e9f":"code","f871e320":"code","80850673":"code","a2479a5b":"code","29e4c804":"markdown","63225f7a":"markdown","4b92c02a":"markdown","7715b945":"markdown","fa355b10":"markdown","0f07401a":"markdown","c09f4d12":"markdown","dcd1d1ac":"markdown","eac86d80":"markdown","995f9447":"markdown","81806e19":"markdown","db7ddee8":"markdown","123b0de5":"markdown","20bc82b8":"markdown","215b71f3":"markdown"},"source":{"28c01503":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.svm import SVR as sk_SVR\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.metrics import mean_squared_error\nfrom lightgbm import LGBMRegressor\nimport cuml\nimport cupy as cp\nfrom cuml.linear_model import LinearRegression\nfrom cuml.linear_model import ElasticNet\nfrom cuml.svm import SVR as cu_SVR\nfrom sklearn.ensemble import RandomForestRegressor\nfrom xgboost import XGBRegressor\nfrom sklearn.preprocessing import StandardScaler\nimport time\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","9d2cd585":"sales_train = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/sales_train.csv')\nitem_categories = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/item_categories.csv')\nitems = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/items.csv')\nshops = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/shops.csv')\ntest = pd.read_csv('..\/input\/competitive-data-science-predict-future-sales\/test.csv')\n","b66c5988":"sales_train.head(5)","1b5e6473":"sales_train.describe()","6ccfcee5":"sales_train.info()","07b820a3":"# Check Missing Data\nsales_train.isna().sum()","2be1ef1b":"#reformat the data\nsales_train = sales_train.groupby(['date_block_num', 'shop_id', 'item_id']).agg({'item_price':'mean','item_cnt_day':'sum'}).reset_index()\n# disp The Data\nsales_train.head(5)","9b058846":"plt.figure(figsize=(12,8))\ndataplot = sns.heatmap(sales_train.corr(), cmap=\"YlGnBu\", annot=True)\nplt.show()","4ff8337e":"# Prepare The Test Data as Training Data\ntest['date_block_num'] = 34\ntest_data=test[['date_block_num','shop_id','item_id']]\ntest_data.head()","bd5ca550":"item_price=dict(sales_train.groupby('item_id')['item_price'].last().reset_index().values)\ntest_data['item_price']=test_data.item_id.map(item_price)\nprint(test_data)\nprint(sales_train)","c303f422":"# Fill Missing Features in Testing Data\ntest_data['item_price'] = test_data['item_price'].fillna(test_data['item_price'].median())\nprint(test_data)","4eea8daa":"# There Are Too Many Records, i'll Take Sample\n# i'll take a small Sample Because SVM Takes Very loooooooooooooooooooooooooooooong Time\nsales_train = sales_train.sample(frac = .3,random_state=98) \nprint(sales_train)","b6ff05d4":"# to Save All accuracies\nperformance = pd.DataFrame(columns=['Model Name','RMSE','Time'],)","24102754":"sc = StandardScaler()","b0619331":"X = np.array(sales_train.drop(['item_cnt_day'], axis =1 ))\nY = np.array(sales_train.iloc[:,4])\nX = sc.fit_transform(X)\nX_train, X_test, Y_train, Y_test = train_test_split(X, Y, test_size = 0.25, random_state = 25 )","9a2dac65":"%%time\nstart_time = time.time()\n# Define The Model\nregressor = LinearRegression()\n# Fitting The Model\nregressor.fit(X_train,Y_train)\n#Prediction The Test Set Results\ny_pred = regressor.predict(X_test)\n# Calculate The RMSE\nrmse = mean_squared_error(Y_test,y_pred,squared=False)\ntotal_time= time.time() - start_time\nrmse","ee8ec668":"newResult = {'Model Name':'linear_sklearn','RMSE':rmse,'Time':total_time}\nperformance = performance.append(newResult,ignore_index=True)\nperformance","ac27b0d5":"%%time\nstart_time = time.time()\n#Define The Model\ndt_regressor = DecisionTreeRegressor()\n#Fitting The Data\ndt_regressor.fit(X_train,Y_train)\n#Test on Testing Data\ndt_pred = dt_regressor.predict(X_test)\n#Calculate The Error\nrmse = mean_squared_error(Y_test,dt_pred,squared=False)\ntotal_time= time.time() - start_time\nrmse","89cfd6e3":"newResult = {'Model Name':'dt_regressor','RMSE':rmse,'Time':total_time}\nperformance = performance.append(newResult,ignore_index=True)\nperformance","4ffa1bfb":"%%time\nstart_time = time.time()\nRFR = RandomForestRegressor()\nRFR.fit(X_train,Y_train)\n#Test on Testing Data\nRFR_pred = RFR.predict(X_test)\n#Calculate The Error\nrmse = mean_squared_error(Y_test,RFR_pred,squared=False)\ntotal_time= time.time() - start_time\nrmse","f07e0801":"newResult = {'Model Name':'RandomForestRegressor','RMSE':rmse,'Time':total_time}\nperformance = performance.append(newResult,ignore_index=True)\nperformance","cbbf36e2":"%%time\nstart_time = time.time()\nlgbm = LGBMRegressor(n_estimators=100)\nlgbm.fit(X_train,Y_train)\n#Test on Testing Data\nlgbm_pred = lgbm.predict(X_test)\n#Calculate The Error\nrmse = mean_squared_error(Y_test,lgbm_pred,squared=False)\ntotal_time= time.time() - start_time\nrmse","bedc09b1":"newResult = {'Model Name':'lgbm','RMSE':rmse,'Time':total_time}\nperformance = performance.append(newResult,ignore_index=True)\nperformance","c7e3705f":"%%time\nstart_time = time.time()\nXGB = XGBRegressor(n_estimators=100, learning_rate=0.03, n_jobs=8) \nXGB.fit(X_train, Y_train) # Your code here\ny_pred = XGB.predict(X_test)\nrmse = mean_squared_error(Y_test,y_pred,squared=False)\ntotal_time= time.time() - start_time\nrmse","505fe22a":"newResult = {'Model Name':'XGB','RMSE':rmse,'Time':total_time}\nperformance = performance.append(newResult,ignore_index=True)\nperformance","3d5fba47":"X_train, X_test, Y_train, Y_test  = cp.array(X_train),cp.array(X_test),cp.array(Y_train),cp.array(Y_test)","7f083ca4":"%%time\nstart_time = time.time()\nlr = LinearRegression(fit_intercept = True, normalize = False,\n                      algorithm = \"eig\")\n\nreg = lr.fit(X_train,Y_train)\nlinear_cuml_preds = lr.predict(X_test)\nrmse = mean_squared_error(np.array(Y_test.get()),np.array(linear_cuml_preds.get()),squared=False)\ntotal_time= time.time() - start_time\nrmse","9d4cca15":"newResult = {'Model Name':'linear_cuml','RMSE':rmse,'Time':total_time}\nperformance = performance.append(newResult,ignore_index=True)\nperformance","83e0057c":"%%time\nstart_time = time.time()\nenet = ElasticNet(alpha = 0.1, l1_ratio=0.5)\nreg = enet.fit(X_train,Y_train)\nenet_cuml_preds = enet.predict(X_test)\nrmse = mean_squared_error(np.array(Y_test.get()),np.array(enet_cuml_preds.get()),squared=False)\ntotal_time= time.time() - start_time\nrmse\n","4e622e9f":"newResult = {'Model Name':'elasticNet_cuml','RMSE':rmse,'Time':total_time}\nperformance = performance.append(newResult,ignore_index=True)\nperformance","f871e320":"%%time\nstart_time = time.time()\nreg = cu_SVR(kernel='linear', gamma='scale', epsilon=0.1,verbose= 6)\nreg = reg.fit(X_train,Y_train)\nsvr_cuml_preds = reg.predict(X_test)\nrmse = mean_squared_error(np.array(Y_test.get()),np.array(svr_cuml_preds.get()),squared=False)\ntotal_time= time.time() - start_time\nrmse","80850673":"newResult = {'Model Name':'SVR_cuml','RMSE':rmse,'Time':total_time}\nperformance = performance.append(newResult,ignore_index=True)\nperformance","a2479a5b":"sns.set_style(\"darkgrid\", {\"grid.color\": \".6\", \"grid.linestyle\": \":\"})\nplt.figure(figsize=[16,6])\n\nplt.subplot(1, 2, 1) # row 1, col 2 index 1\nplt.title(\"Models' RMSE (Less is Better)\")\nsns.barplot(x='Model Name',y='RMSE',data=performance,)\nplt.xticks(rotation=\"90\")\n\nplt.subplot(1, 2, 2) # row 1, col 2 index 2\nplt.title(\"Models' Training and Evaluating Time (Less is Better)\")\nsns.barplot(x='Model Name',y='Time',data=performance,)\nplt.xticks(rotation=\"90\")\n","29e4c804":"***it's taking too much time, i'll use it with cuml***","63225f7a":"## **SVR**","4b92c02a":"# Using SkLearn","7715b945":"## **Linear Reg**","fa355b10":"## **Random Forest**","0f07401a":"## **Linear Reg**","c09f4d12":"# **Using CUML**\nSklearn is Slow Bcoz it Works on CPU So, I'll Try To Use CUML which Runs On GPU","dcd1d1ac":"## **Decision Tree**","eac86d80":"## **XGBoost**","995f9447":"## **ElasticNet**","81806e19":"# **Ensemble Models**","db7ddee8":"> %%time\n> #Define The Model\n> svr = sk_SVR(kernel='linear',cache_size=5000,C=10,verbose=6)\n> #Fitting The Data\n> svr.fit(X_train,Y_train)\n> #Test on Testing Data\n> svr_pred = svr.predict(X_test)\n> #Calculate The Error\n> rmse = mean_squared_error(Y_test,svr_pred,squared=False)\n> accuracies['svr_sklearn'] = rmse\n> rmse","123b0de5":"# **Visualize Results**","20bc82b8":"## **SVR**","215b71f3":"## **LightGBM** "}}