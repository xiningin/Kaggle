{"cell_type":{"442d4533":"code","b6b5b102":"code","9a3a73c8":"code","69ae7239":"code","05a69643":"code","87bd38ac":"code","d01c3633":"code","1edaf28f":"code","776ba944":"code","ff950ae2":"code","9182c64a":"code","53c7c99d":"code","b4a26f27":"code","525f3857":"code","b5cc2726":"code","8f0ef622":"code","1c559ca9":"code","a46e004e":"code","5d9633a6":"markdown","6e4278fd":"markdown","1f4c6125":"markdown","6d1ee090":"markdown","57dc83b4":"markdown","66798989":"markdown","72d1d2ea":"markdown","50708cad":"markdown","92782f1b":"markdown","6c4c688d":"markdown","845af3e9":"markdown","c572393e":"markdown","721cc420":"markdown","e50faf81":"markdown","53fc2eef":"markdown","b8256707":"markdown","08369050":"markdown","2bbb638b":"markdown","bf8f1689":"markdown","c049bd13":"markdown","a18f2147":"markdown","6a73d076":"markdown","1787e17f":"markdown","45945ae0":"markdown"},"source":{"442d4533":"import numpy as np\nimport pandas as pd\nimport re\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom nltk import word_tokenize\nfrom collections import defaultdict\nfrom nltk.stem import WordNetLemmatizer\nimport string\nfrom sklearn.feature_extraction.text import TfidfVectorizer","b6b5b102":"train=pd.read_csv('..\/input\/nlp-getting-started\/train.csv')\ntest=pd.read_csv('..\/input\/nlp-getting-started\/test.csv')","9a3a73c8":"train.head()","69ae7239":"train=train.drop('keyword',1)\ntrain=train.drop('location',1)\n\ntest=test.drop('keyword',1)\ntest=test.drop('location',1)","05a69643":"y_train=train.iloc[:,-1]\nx_train=train.iloc[:,:-1]","87bd38ac":"ps=PorterStemmer()\nlemmatizer=WordNetLemmatizer()","d01c3633":"def atcontain(text):\n    ar=[]\n    text=text.split()\n    for t in text:\n        if(\"@\" in t):\n            ar.append(\"TAGSOMEBODY\")\n        else:\n            ar.append(t)\n    return \" \".join(ar)\n    \n\ndef dataclean(data):\n    corpus=[]\n    for i in range(data.shape[0]):\n        tweet=data.iloc[i,-1]\n        tweet=atcontain(tweet)\n        tweet=re.sub(r'http\\S+', '', tweet)\n        tweet=re.sub('[^a-zA-z]',\" \",tweet)\n        tweet=tweet.lower()\n        tweet=word_tokenize(tweet)\n#         tweet=[ps.stem(word) for word in tweet if word not in stopwords.words('english')]\n        tweet=[lemmatizer.lemmatize(word) for word in tweet if word not in stopwords.words('english')]\n        tweet=[word for word in tweet if word not in set(string.punctuation)]\n        tweet=\" \".join(tweet)\n        corpus.append(tweet)\n    return corpus","1edaf28f":"x_corpus_train=dataclean(x_train)\nx_corpus_test=dataclean(test)","776ba944":"dic=defaultdict(int)\nfor text in x_corpus_train:\n    text=text.split()\n    for word in text:\n        dic[word]=dic[word]+1","ff950ae2":"sorted_data=sorted(dic.items(), key=lambda x:x[1],reverse=True)\nsorted_data[:20]","9182c64a":"cv=TfidfVectorizer(max_features=8000)","53c7c99d":"x_train_vector=cv.fit_transform(x_corpus_train).toarray()\nx_test_vector=cv.transform(x_corpus_test).toarray()","b4a26f27":"from sklearn.naive_bayes import MultinomialNB\nmodel=MultinomialNB()\nmodel.fit(x_train_vector,y_train)\nprint(model.score(x_train_vector,y_train))\ny_pred=model.predict(x_test_vector)\ny_pred","525f3857":"from sklearn.ensemble import RandomForestClassifier\nrfc=RandomForestClassifier(random_state=4,n_estimators=500,warm_start=True,max_depth=6,min_samples_leaf=2,max_features='auto',min_samples_split=3)\nrfc.fit(x_train_vector,y_train)\nprint(rfc.score(x_train_vector,y_train))\ny_pred=rfc.predict(x_test_vector)","b5cc2726":"from xgboost import XGBClassifier\nxgb=XGBClassifier()\nxgb.fit(x_train_vector,y_train,early_stopping_rounds=5, \n             eval_set=[(x_train_vector,y_train)], \n             verbose=False)\nprint(xgb.score(x_train_vector,y_train))\ny_pred=xgb.predict(x_test_vector)","8f0ef622":"from sklearn.linear_model import LogisticRegression\nreg=LogisticRegression()\nreg.fit(x_train_vector,y_train)\nprint(reg.score(x_train_vector,y_train))\ny_pred=reg.predict(x_test_vector)\ny_pred","1c559ca9":"from sklearn.linear_model import PassiveAggressiveClassifier\npassive=PassiveAggressiveClassifier()\npassive.fit(x_train_vector,y_train)\nprint(passive.score(x_train_vector,y_train))\ny_pred=passive.predict(x_test_vector)\ny_pred","a46e004e":"submission=pd.read_csv('..\/input\/nlp-getting-started\/sample_submission.csv')\nsubmission['target']=y_pred\nsubmission.to_csv('submission.csv',index=False)","5d9633a6":"<h3 style=\"font-family: Futura; color:blue \"><b>5. PassiveAggressiveClassifier<\/b><\/h3><br>","6e4278fd":"<h3 style=\"font-family: Futura; color:blue \"><b>1. Naive Bayes<\/b><\/h3><br>","1f4c6125":"<h1>Check out my other Notebooks<\/h1><font size='4'>\n<a href=\"https:\/\/www.kaggle.com\/vishalvanpariya\/top-5-on-leaderboard\" target=\"_blank\">House Price<\/a><br>\n<a href=\"https:\/\/www.kaggle.com\/vishalvanpariya\/data-explanation-titanic\" target=\"_blank\">Titanic EDA<\/a><br>\n<a href=\"https:\/\/www.kaggle.com\/vishalvanpariya\/titanic-top-6\" target=\"_blank\">Titanic Notebook<\/a><br>\n<a href=\"https:\/\/www.kaggle.com\/vishalvanpariya\/nlp-for-beginners\" target=\"_blank\">NLP<\/a><br><font>","6d1ee090":"<font size='3' style=\"font-family: Futura\">Sorting values through frequency of word<\/font>","57dc83b4":"<h3 style=\"font-family: Futura; color:blue \"><b>3. XGBoost<\/b><\/h3><br>","66798989":"<font size='3' style=\"font-family: Futura\">let's have important data from Dataframe<\/font>","72d1d2ea":"<h1><font size=\"+3.5\" color=\"blue\" style=\"font-family: Futura\"><center>Natural Langauge Processing<\/center><\/font><\/h1>","50708cad":"* [<font size='3' style=\"font-family: Futura\">1.Importing Important Libraries<\/font>](#1)\n* [<font size='3' style=\"font-family: Futura\">2.Importing Data<\/font>](#2)\n* [<font size='3' style=\"font-family: Futura\">3.Data Cleaning<\/font>](#3)\n* [<font size='3' style=\"font-family: Futura\">4.Feature Scalling<\/font>](#4)\n* [<font size='3' style=\"font-family: Futura\">5.Modeling<\/font>](#5)\n* [<font size='3' style=\"font-family: Futura\">6.Submission<\/font>](#6)","92782f1b":"<font size='3' style=\"font-family: Futura\">\n<b style=\"color:blue\">Use Of Liberaries:<\/b><br><br>\n    &emsp;&emsp;<b style=\"color:green\">1. Numpy :<\/b> we will use it for maths opration<br>\n    &emsp;&emsp;<b style=\"color:green\">2. Pandas :<\/b> Data Handling<br>\n    &emsp;&emsp;<b style=\"color:green\">3. re :<\/b> Regular Expression<br>\n    &emsp;&emsp;<b style=\"color:green\">4. Stopwords :<\/b> Remove Stopwords<br>\n    &emsp;&emsp;<b style=\"color:green\">5. PorterStemmer :<\/b> For Stemming<br>\n    &emsp;&emsp;<b style=\"color:green\">6. word_tokenize :<\/b> For work token<br>\n    &emsp;&emsp;<b style=\"color:green\">7. defaultdict :<\/b> For dictionary<br>\n    &emsp;&emsp;<b style=\"color:green\">8. WordNetLemmatizer :<\/b> For word lemmatize<br>\n    &emsp;&emsp;<b style=\"color:green\">9. String :<\/b> For string oprations<br>\n    &emsp;&emsp;<b style=\"color:green\">10. TfidfVectorizer :<\/b> Vecterization<br>\n<\/font>","6c4c688d":"<font size='3' style=\"font-family: Futura; color:green\">Data Cleaned<\/font>","845af3e9":"<h3 style=\"font-family: Futura; color:blue \"><b>2. Randomforest<\/b><\/h3><br>","c572393e":"<h2 style=\"font-family: Futura; color:green \"><b>2. Import Data<\/b><\/h2><br><a id='2'><\/a>","721cc420":"<font size='3' style=\"font-family: Futura\">In current genreation NLP is going heigher and higher everyday. So many bigtech companies are using NLP im there product. like <a href=\"https:\/\/google.com\">Google<\/a> in Google assistant, <a href=\"https:\/\/apple.com\">Apple<\/a> in siri, <a href=\"https:www.amazon.com\">Amazon<\/a> in Alexa, <a href='https:\/\/microsoft.com'>Microsoft<\/a> and so on.<\/font>","e50faf81":"<font size='3' style=\"font-family: Futura\">\n<b style=\"color:green\">id<\/b> - a unique identifier for each tweet<br>\n    <b style=\"color:green\">text<\/b> - the text of the tweet<br>\n<b style=\"color:green\">location<\/b> - the location the tweet was sent from (may be blank)<br>\n<b style=\"color:green\">keyword<\/b> - a particular keyword from the tweet (may be blank)<br>\n<b style=\"color:green\">target<\/b> - in train.csv only, this denotes whether a tweet is about a real disaster (1) or not (0)<br>\n<\/font>","53fc2eef":"<font size='3' style=\"font-family: Futura\">Here I am going to explain Natural Langauge Processing. I have learn lot of thing from good Youtube channels and so many blogs which i sharing here which will help you also. <a href=\"https:\/\/www.youtube.com\/playlist?list=PLZoTAELRMXVMdJ5sqbCK2LiM0HhQVWNzm\">NLP Basic(Youtube)<\/a> and <a href=\"https:\/\/towardsdatascience.com\/your-guide-to-natural-language-processing-nlp-48ea2511f6e1\">Blog<\/a> this site and channle both helping me so much to learn Data Science and Machine learnig. Here i am using some diffrent approch for presentation which i learn from this <a href='https:\/\/www.kaggle.com\/vishalvanpariya\/house-pricing-ultimate-guide\/edit'>kernel<\/a>.<\/font>","b8256707":"<h2 style=\"font-family: Futura; color:green \"><b>1. Libraries<\/b><\/h2><br><a id='1'><\/a>","08369050":"<h2 style=\"font-family: Futura; color:blue;\">Overview<\/h2>","2bbb638b":"<h3 style=\"font-family: Futura; color:blue \"><b>4. Logistic Regression<\/b><\/h3><br>","bf8f1689":"<font size='3' style=\"font-family: Futura\"><b style=\"color:green\">Creating data clean function:<\/b><br>\n    in this function we are going remove puctuationa,stopword and changing to lower case<br>\n    i have commented one line in function which is for porter stemmer, i commented it because it is decresing model accuracy\n<\/font>","c049bd13":"<h2 style=\"font-family: Futura; color:green \"><b>3. Data Cleaning<\/b><\/h2><br><a id='3'><\/a>","a18f2147":"<h2 style=\"font-family: Futura; color:green \"><b>5. Modeling<\/b><\/h2><br><a id='5'><\/a>","6a73d076":"<h2 style=\"font-family: Futura; color:green \"><b>6. Submission<\/b><\/h2><br><a id='6'><\/a>","1787e17f":"<font size='3' style=\"font-family: Futura\">Let's delete keyword and location<\/font>","45945ae0":"<h2 style=\"font-family: Futura; color:green \"><b>4. Feature Scalling<\/b><\/h2><br><a id='4'><\/a>"}}