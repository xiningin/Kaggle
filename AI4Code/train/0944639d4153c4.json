{"cell_type":{"d8ff29b2":"code","eb608bef":"code","36d49ade":"code","8f0c73b8":"code","bb6453e8":"code","291a23ff":"code","809307e0":"code","cbb0a7f6":"code","5239d7dd":"code","888a07f5":"code","693a0767":"code","b31dc7eb":"code","edee0444":"code","de85ee47":"markdown","20ef504f":"markdown","9fe7d7dc":"markdown","74dbb9ca":"markdown","78283905":"markdown"},"source":{"d8ff29b2":"import fastai\nfrom fastai.vision import *","eb608bef":"PATH = Path('..\/input\/severstal-steel-defect-detection\/')\nIMAGES = PATH\/'train_images'\n\ndef prepare_SteelDefectDet(path):\n    df = pd.read_csv(path\/'train.csv')\n    df['filename'] = df.ImageId_ClassId.map(lambda s: s.split('_')[0])\n    return df\n\ndf = prepare_SteelDefectDet(PATH)\ndf.head()","36d49ade":"imgs_tmpl = ['000789191.jpg','00d7ae946.jpg','01d590c5f.jpg','01e501f99.jpg','023353d24.jpg',\\\n              '031614d60.jpg','03395a3da.jpg','063b5dcbe.jpg','06a86ee90.jpg','07cb85a8d.jpg','07e8fca73.jpg',\\\n              '08e21ba66.jpg','047681252.jpg','092c1f666.jpg','0a3bbea4d.jpg','0a46cc4bf.jpg','0a65bd8d4.jpg',\\\n              '0a76ac9b8.jpg','0b3a0fabe.jpg','0b50b417a.jpg','0d0c21687.jpg','0d22de6d4.jpg','0e09ff3bd.jpg',\\\n              '0e3ade070.jpg','0d0c21687.jpg','0d22de6d4.jpg','0ef4bff49.jpg','0faa71251.jpg','0fac62a3e.jpg',\\\n              '100de36e9.jpg','109fbcecf.jpg','110e63bfa.jpg']\nlen(imgs_tmpl)","8f0c73b8":"files = df.filename.unique()\n\ndf_trn = pd.DataFrame({'filename': [f for f in files if f not in imgs_tmpl][:50] + imgs_tmpl,\n                       'label': ['0'] * 50 + ['1'] * len(imgs_tmpl)})\ndf_trn.head()","bb6453e8":"SZ = 384\ndata = ImageDataBunch.from_df(IMAGES, df=df_trn, ds_tfms=get_transforms(), bs=8, size=SZ)\ndata.show_batch()","291a23ff":"learn = cnn_learner(data, models.resnet18, metrics=accuracy).mixup()\nlearn.fit_one_cycle(1)\nlearn.unfreeze()\nlearn.fit_one_cycle(5)\nlearn.show_results()","809307e0":"def prepare_test_ds_dl(data_path, files=None, labels=None,\n                       tfms=None, img_size=None, extension='.jpg'):\n    if files is None:\n        files = [str(f) for f in data_path\/('*'+extension)]\n    if labels is None:\n        labels = [Path(f).parent.name for f in files]\n    # Once create data bunch\n    tmp_data = ImageDataBunch.from_lists(data_path, files, labels, valid_pct=0, ds_tfms=tfms, size=img_size)\n    # Create dataloader again so that it surely set `shuffle=False`\n    dl = torch.utils.data.DataLoader(tmp_data.train_ds, batch_size=tmp_data.batch_size, shuffle=False)\n    dl = DeviceDataLoader(dl, tmp_data.device)\n    return tmp_data.train_ds, dl\n\ntest_ds, test_dl = prepare_test_ds_dl(IMAGES, files=[IMAGES\/f for f in files],\n                                      labels=['1' if f in imgs_tmpl else '0' for f in files], img_size=SZ)","cbb0a7f6":"def predict_ext_dl(model, data_loader):\n    preds, ys = [], []\n    for X, y in data_loader:\n        with torch.no_grad():\n            out = model(X).softmax(1).cpu().detach().numpy()\n            preds.append(out)\n        ys.append(y)\n    preds = np.concatenate(preds)\n    ys   = np.concatenate(ys)\n    return preds, ys\n\npreds, ys = predict_ext_dl(learn.model, test_dl)","5239d7dd":"from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, roc_auc_score\nyhat = np.argmax(preds, axis=-1)\nprint(f'acc = {accuracy_score(yhat, ys)}')\nprint(f'precision = {precision_score(yhat, ys)}')\nprint(f'recall = {recall_score(yhat, ys)}')\nprint(f'F1 = {f1_score(yhat, ys)}')\nprint(f'AUC = {roc_auc_score(ys, yhat)}')","888a07f5":"def plot_predictions(yhat):\n    fig, axs = plt.subplots(3, 4, figsize=(24, 8))\n    for i, (ax, x_i) in enumerate(zip(axs.flat, np.where(yhat)[0])):\n        ax.imshow(plt.imread(IMAGES\/files[x_i]))\n        ax.set_title(f'{x_i}th: p(y=1)={preds[x_i, 1]:.2f} p(y=0)={preds[x_i, 0]:.2f}')\n\nplot_predictions(yhat)","693a0767":"yhat_for_sure = [1 if pred[1] > 0.95 else 0 for pred in preds]\nplot_predictions(yhat_for_sure)","b31dc7eb":"img_tmpl = np.array(files)[np.where(yhat_for_sure)[0]]\nprint(len(img_tmpl))\nwith open('possible_train_texture_images.txt', 'w') as f:\n    f.writelines('\\n'.join(img_tmpl))","edee0444":"! cat possible_train_texture_images.txt","de85ee47":"## If we just use usual argmax to get result...","20ef504f":"Here you are.","9fe7d7dc":"This doesn't look good.\n\n## Pick ones that we are sure\n\nNow we want results with which model is very sure about predictions. Otherwise it might be confused with defect pattern as texture.","74dbb9ca":"OK It should happen, we have much more non-texture samples labeled as '0' than '1' textures.","78283905":"# Detecting steels with texture, a little more for sure\n\nThis notebook is [fast.ai](https:\/\/www.fast.ai) version of [Detector steels with texture by @ateplyuk](https:\/\/www.kaggle.com\/ateplyuk\/detector-steels-with-texture).\nFirst of all, thanks to @ateplyuk!\n\nBy using [fast.ai](https:\/\/www.fast.ai) library, we might be doing better finding textures:\n![texture](https:\/\/github.com\/ushur\/Severstal-Steel-Defect-Detection\/blob\/master\/Texture.jpg?raw=true)"}}