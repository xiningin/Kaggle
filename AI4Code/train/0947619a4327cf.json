{"cell_type":{"2aad1f8a":"code","84869483":"code","e16a922b":"code","3e5b8398":"code","8be7761c":"code","6fc0b104":"code","d879c6d8":"code","ae066601":"code","ff773dc5":"code","53d7d574":"code","5dc36b8e":"code","760d2251":"code","daae9a3a":"code","da3240ca":"code","0f6e4b3b":"code","b99cbdb2":"code","ef30ba61":"code","8de0c0da":"code","765d23b2":"code","c9fe383d":"code","7b3f309c":"code","0e2a668a":"code","c1c35c48":"code","e04abe83":"code","685dca37":"code","20d8429b":"code","d5de6f3a":"code","48026bf2":"code","8c6c77cd":"code","6c09d231":"code","2bcfa63a":"code","1596901b":"code","8abd2459":"code","380637f4":"code","20d9335f":"code","b3b9dd87":"code","44922963":"code","a48dcedd":"code","7060bf2e":"code","f8dfbaf6":"code","b163e0ef":"code","0f03542a":"markdown","b83c8c17":"markdown","e6769c27":"markdown","451a14cb":"markdown","d128cb93":"markdown"},"source":{"2aad1f8a":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport os\nimport sklearn\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.naive_bayes import MultinomialNB\nfrom sklearn.metrics import accuracy_score","84869483":"# Extract features\nimport os, shutil\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rescale=1.\/255)\nimg_width = 224\nimg_height = 224\nbatch_size = 32\n# Instantiate convolutional base\n\nfrom keras.applications import ResNet50\n\nconv_base = ResNet50(weights='imagenet',\n                 include_top=False,\n                 input_shape=(img_width, img_height, 3))  # 3 = number of channels in RGB pictures\ndef extract_features(directory, sample_count):\n   features = np.zeros(shape=(sample_count, 7, 7, 2048))  # Must be equal to the output of the convolutional base\n   labels = np.zeros(shape=(sample_count,10))\n   # Preprocess data\n   generator = datagen.flow_from_directory(directory,\n                                           target_size=(img_width,img_height),\n                                           batch_size = batch_size,\n                                           class_mode='categorical')\n   # Pass data through convolutional base\n   i = 0\n   for inputs_batch, labels_batch in generator:\n       features_batch = conv_base.predict(inputs_batch)\n       features[i * batch_size: (i + 1) * batch_size] = features_batch\n       labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n       i += 1\n       if i * batch_size >= sample_count:\n           break\n   return features, labels\n\ntrain_size = 1088\nvalidation_size = 256","e16a922b":"train_features, train_labels = extract_features('..\/input\/10-monkey-species\/training\/training\/', train_size)  # Agree with our small dataset size\nvalidation_features, validation_labels = extract_features('..\/input\/10-monkey-species\/validation\/validation\/', validation_size)","3e5b8398":"features = np.concatenate((train_features, validation_features))","8be7761c":"labels_train= []\nfor i in range(len(train_labels)):\n    labels_train.append(np.argmax(train_labels[i])) \n    \nlabels_valid= []\nfor i in range(len(validation_labels)):\n    labels_valid.append(np.argmax(validation_labels[i])) ","6fc0b104":"labels = np.concatenate((labels_train, labels_valid))","d879c6d8":"X_train, y_train = features.reshape(1344,7*7*2048),labels\n\nx_train,x_test,y_train,y_test = train_test_split(X_train,y_train,test_size = 0.2,random_state = 42)\n\nnb = MultinomialNB()\nnb.fit(x_train, y_train)","ae066601":"pred = nb.predict(x_test)","ff773dc5":"accuracy_score(y_test,pred)","53d7d574":"# Extract features\nimport os, shutil\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\n\ndatagen = ImageDataGenerator(rescale=1.\/255,horizontal_flip=True,shear_range=0.2,zoom_range=0.2)\nimg_width = 224\nimg_height = 224\nbatch_size = 32\n# Instantiate convolutional base\nfrom keras.applications import InceptionV3\n\nconv_base = InceptionV3(weights='imagenet',\n                 include_top=False,\n                 input_shape=(img_width, img_height, 3))  # 3 = number of channels in RGB pictures\ndef extract_features(directory, sample_count):\n   features = np.zeros(shape=(sample_count, 5,5, 2048))  # Must be equal to the output of the convolutional base\n   labels = np.zeros(shape=(sample_count,10))\n   # Preprocess data\n   generator = datagen.flow_from_directory(directory,\n                                           target_size=(img_width,img_height),\n                                           batch_size = batch_size,\n                                           class_mode='categorical')\n   # Pass data through convolutional base\n   i = 0\n   for inputs_batch, labels_batch in generator:\n       features_batch = conv_base.predict(inputs_batch)\n       features[i * batch_size: (i + 1) * batch_size] = features_batch\n       labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n       i += 1\n       if i * batch_size >= sample_count:\n           break\n   return features, labels\n\ntrain_size = 1088\nvalidation_size = 256","5dc36b8e":"train_features, train_labels = extract_features('..\/input\/10-monkey-species\/training\/training\/', train_size)  # Agree with our small dataset size\nvalidation_features, validation_labels = extract_features('..\/input\/10-monkey-species\/validation\/validation\/', validation_size)","760d2251":"features = np.concatenate((train_features, validation_features))","daae9a3a":"labels_train= []\nfor i in range(len(train_labels)):\n    labels_train.append(np.argmax(train_labels[i])) \n    \nlabels_valid= []\nfor i in range(len(validation_labels)):\n    labels_valid.append(np.argmax(validation_labels[i])) ","da3240ca":"labels = np.concatenate((labels_train, labels_valid))","0f6e4b3b":"X_train, y_train = features.reshape(1344,5*5*2048), labels\n\nx_train,x_test,y_train,y_test = train_test_split(X_train,y_train,test_size = 0.2,random_state = 42)\n\nnb = MultinomialNB()\nnb.fit(x_train, y_train)","b99cbdb2":"pred = nb.predict(x_test)","ef30ba61":"accuracy_score(y_test,pred)","8de0c0da":"# Extract features\nimport os, shutil\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rescale=1.\/255,horizontal_flip=True,shear_range=0.2,zoom_range=0.2)\nimg_width = 224\nimg_height = 224\nbatch_size = 32\n# Instantiate convolutional base\nfrom keras.applications import VGG19\n\nconv_base = VGG19(weights='imagenet',\n                 include_top=False,\n                 input_shape=(img_width, img_height, 3))  # 3 = number of channels in RGB pictures\ndef extract_features(directory, sample_count):\n   features = np.zeros(shape=(sample_count, 7,7,512))  # Must be equal to the output of the convolutional base\n   labels = np.zeros(shape=(sample_count,10))\n   # Preprocess data\n   generator = datagen.flow_from_directory(directory,\n                                           target_size=(img_width,img_height),\n                                           batch_size = batch_size,\n                                           class_mode='categorical')\n   # Pass data through convolutional base\n   i = 0\n   for inputs_batch, labels_batch in generator:\n       features_batch = conv_base.predict(inputs_batch)\n       features[i * batch_size: (i + 1) * batch_size] = features_batch\n       labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n       i += 1\n       if i * batch_size >= sample_count:\n           break\n   return features, labels\n\ntrain_size = 1088\nvalidation_size = 256","765d23b2":"train_features, train_labels = extract_features('..\/input\/10-monkey-species\/training\/training\/', train_size)  # Agree with our small dataset size\nvalidation_features, validation_labels = extract_features('..\/input\/10-monkey-species\/validation\/validation\/', validation_size)","c9fe383d":"features = np.concatenate((train_features, validation_features))","7b3f309c":"labels_train= []\nfor i in range(len(train_labels)):\n    labels_train.append(np.argmax(train_labels[i])) \n    \nlabels_valid= []\nfor i in range(len(validation_labels)):\n    labels_valid.append(np.argmax(validation_labels[i])) ","0e2a668a":"labels = np.concatenate((labels_train, labels_valid))","c1c35c48":"X_train, y_train = features.reshape(1344,7*7*512), labels\n\nx_train,x_test,y_train,y_test = train_test_split(X_train,y_train,test_size = 0.2,random_state = 42)\n\nnb = MultinomialNB()\nnb.fit(x_train, y_train)","e04abe83":"pred = nb.predict(x_test)","685dca37":"accuracy_score(y_test,pred)","20d8429b":"# Extract features\nimport os, shutil\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rescale=1.\/255,horizontal_flip=True,shear_range=0.2,zoom_range=0.2)\nimg_width = 224\nimg_height = 224\nbatch_size = 32\n# Instantiate convolutional base\nfrom keras.applications import InceptionResNetV2\n\n\nconv_base = InceptionResNetV2(weights='imagenet',\n                 include_top=False,\n                 input_shape=(img_width, img_height, 3))  # 3 = number of channels in RGB pictures\n\ndef extract_features(directory, sample_count):\n   features = np.zeros(shape=(sample_count, 5,5,1536))  # Must be equal to the output of the convolutional base\n   labels = np.zeros(shape=(sample_count,10))\n   # Preprocess data\n   generator = datagen.flow_from_directory(directory,\n                                           target_size=(img_width,img_height),\n                                           batch_size = batch_size,\n                                           class_mode='categorical')\n   # Pass data through convolutional base\n   i = 0\n   for inputs_batch, labels_batch in generator:\n       features_batch = conv_base.predict(inputs_batch)\n       features[i * batch_size: (i + 1) * batch_size] = features_batch\n       labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n       i += 1\n       if i * batch_size >= sample_count:\n           break\n   return features, labels\n\ntrain_size = 1088\nvalidation_size = 256","d5de6f3a":"train_features, train_labels = extract_features('..\/input\/10-monkey-species\/training\/training\/', train_size)  # Agree with our small dataset size\nvalidation_features, validation_labels = extract_features('..\/input\/10-monkey-species\/validation\/validation\/', validation_size)","48026bf2":"features = np.concatenate((train_features, validation_features))","8c6c77cd":"labels_train= []\nfor i in range(len(train_labels)):\n    labels_train.append(np.argmax(train_labels[i])) \n    \nlabels_valid= []\nfor i in range(len(validation_labels)):\n    labels_valid.append(np.argmax(validation_labels[i])) ","6c09d231":"labels = np.concatenate((labels_train, labels_valid))","2bcfa63a":"X_train, y_train = features.reshape(1344,5*5*1536), labels\n\nx_train,x_test,y_train,y_test = train_test_split(X_train,y_train,test_size = 0.2,random_state = 42)\n\nnb = MultinomialNB()\nnb.fit(x_train, y_train)","1596901b":"pred = nb.predict(x_test)","8abd2459":"accuracy_score(y_test,pred)","380637f4":"# Extract features\nimport os, shutil\nimport numpy as np\nfrom keras.preprocessing.image import ImageDataGenerator\ndatagen = ImageDataGenerator(rescale=1.\/255,horizontal_flip=True,shear_range=0.2,zoom_range=0.2)\nimg_width = 224\nimg_height = 224\nbatch_size = 32\n# Instantiate convolutional base\nfrom keras.applications import MobileNetV2\n\n\nconv_base = MobileNetV2(weights='imagenet',\n                 include_top=False,\n                 input_shape=(img_width, img_height, 3))  # 3 = number of channels in RGB pictures\n\ndef extract_features(directory, sample_count):\n   features = np.zeros(shape=(sample_count, 7,7,1280))  # Must be equal to the output of the convolutional base\n   labels = np.zeros(shape=(sample_count,10))\n   # Preprocess data\n   generator = datagen.flow_from_directory(directory,\n                                           target_size=(img_width,img_height),\n                                           batch_size = batch_size,\n                                           class_mode='categorical')\n   # Pass data through convolutional base\n   i = 0\n   for inputs_batch, labels_batch in generator:\n       features_batch = conv_base.predict(inputs_batch)\n       features[i * batch_size: (i + 1) * batch_size] = features_batch\n       labels[i * batch_size: (i + 1) * batch_size] = labels_batch\n       i += 1\n       if i * batch_size >= sample_count:\n           break\n   return features, labels\n\ntrain_size = 1088\nvalidation_size = 256","20d9335f":"train_features, train_labels = extract_features('..\/input\/10-monkey-species\/training\/training\/', train_size)  # Agree with our small dataset size\nvalidation_features, validation_labels = extract_features('..\/input\/10-monkey-species\/validation\/validation\/', validation_size)","b3b9dd87":"features = np.concatenate((train_features, validation_features))","44922963":"labels_train= []\nfor i in range(len(train_labels)):\n    labels_train.append(np.argmax(train_labels[i])) \n    \nlabels_valid= []\nfor i in range(len(validation_labels)):\n    labels_valid.append(np.argmax(validation_labels[i])) ","a48dcedd":"labels = np.concatenate((labels_train, labels_valid))","7060bf2e":"X_train, y_train = features.reshape(1344,7*7*1280), labels\n\nx_train,x_test,y_train,y_test = train_test_split(X_train,y_train,test_size = 0.2,random_state = 42)\n\nnb = MultinomialNB()\nnb.fit(x_train, y_train)","f8dfbaf6":"pred = nb.predict(x_test)","b163e0ef":"accuracy_score(y_test,pred)","0f03542a":"## Using ResNet50","b83c8c17":"## Using VGG19","e6769c27":"## Using InceptionV3","451a14cb":"## Using InceptionResNetV2","d128cb93":"## Using MobileNetV2"}}