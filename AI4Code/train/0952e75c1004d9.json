{"cell_type":{"ea8fd043":"code","1ba12448":"code","3a1673e8":"code","46e5aede":"code","7b4beb5a":"code","e499cf9f":"code","0263b945":"code","91630a79":"code","db2041f8":"code","f3beef6f":"code","5df5b5be":"code","8c872bf3":"code","cd691d2d":"code","84d89a74":"code","95d318ed":"code","7e80adcd":"code","f3e59901":"code","0a866ced":"code","d29755da":"code","7a6fc754":"code","8008a17f":"code","644ed0a5":"code","f1980192":"markdown","0d4189fe":"markdown","d964c766":"markdown","02b6477b":"markdown","ea8902f0":"markdown","1018583a":"markdown","267870df":"markdown","f9b9e899":"markdown","048a63c9":"markdown","713f8131":"markdown","7f671b93":"markdown"},"source":{"ea8fd043":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session\n","1ba12448":"train_data = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nprint(len(train_data))\ntrain_data.head()","3a1673e8":"test_data = pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")\ntest_data.head()","46e5aede":"train_data.info()","7b4beb5a":"train_data.describe()","e499cf9f":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\ncolumns = ['Pclass', 'Sex','Embarked','SibSp', 'Parch','Survived']\n\nplt.figure(figsize=(16, 14))\nsns.set(font_scale= 1.2)\nsns.set_style('ticks')\n\nfor i, feature in enumerate(columns):\n    plt.subplot(3, 3, i+1)\n    sns.countplot(data=train_data, x=feature, hue='Survived', palette='Paired')\n    \nsns.despine()","0263b945":"auxage = pd.cut(train_data['Age'], 4)\nfig, axs = plt.subplots(figsize=(8, 4))\nsns.countplot(x=auxage, hue='Survived', data=train_data)\nsns.despine()","91630a79":"women = train_data.loc[train_data.Sex == 'female'][\"Survived\"]\nrate_women = sum(women)\/len(women)\nmen = train_data.loc[train_data.Sex == 'male'][\"Survived\"]\nrate_men = sum(men)\/len(men)\n\nprint(\"% of women who survived:\", rate_women)\nprint(\"% of men who survived:\", rate_men)","db2041f8":"train_data['FamilySize'] = train_data['SibSp'] + train_data['Parch']\ntrain_data.drop(['SibSp','Parch'], axis = 1, inplace = True)\n\ntest_data['FamilySize'] = test_data['SibSp'] + test_data['Parch']\ntest_data.drop(['SibSp','Parch'], axis = 1, inplace = True)\n\nfig, axs = plt.subplots(figsize=(15, 5))\nsns.countplot(x='FamilySize', hue='Survived', data=train_data)\nsns.despine()","f3beef6f":"train_data.columns","5df5b5be":"train_data.isna().sum()","8c872bf3":"test_data.isna().sum()","cd691d2d":"train_data['Age'] = train_data['Age'].fillna(round(train_data.Age.median()))\ntest_data['Age'] = test_data['Age'].fillna(round(test_data.Age.median()))","84d89a74":"def EncodeAge(age):\n    \"\"\"\n    Encode age into 4 types:\n    [0,20): type 0\n    [20,40): type 1\n    [40, 60): type 2\n    [60, 80]: type 3\n    \"\"\"\n    if age in list(range(0,20)):\n        return 0\n    elif age in list(range(20,40)):\n        return 1\n    elif age in list(range(40,60)):\n        return 2\n    else:\n        return 3\n    \ntrain_data['Age'] = train_data['Age'].apply(EncodeAge)\ntest_data['Age'] = test_data['Age'].apply(EncodeAge)","95d318ed":"def EncodeFamilySize(size):\n    \"\"\"\n    Encode family size into 4 types:\n    0: type 0 (alone)\n    1-3: type 1 (small)\n    4-6: type 2 (medium)\n    6-10: type 3 (large)\n    \"\"\"\n    if size == 0:\n        return 0\n    elif size in list(range(1,4)):\n        return 1\n    elif size in list(range(4,6)):\n        return 2\n    else:\n        return 3\n    \ntrain_data['FamilySize'] = train_data['FamilySize'].apply(EncodeFamilySize)\ntest_data['FamilySize'] = test_data['FamilySize'].apply(EncodeFamilySize)","7e80adcd":"features = [\"Pclass\", \"Sex\", \"Age\", \"Embarked\", \"FamilySize\"]\ny = train_data[\"Survived\"]\nX = pd.get_dummies(train_data[features]) #similar OneHotEncoder\nX_test = pd.get_dummies(test_data[features])\nX","f3e59901":"from sklearn.preprocessing import StandardScaler\n\nX = StandardScaler().fit_transform(X)\nX_test = StandardScaler().fit_transform(X_test)","0a866ced":"from sklearn.ensemble import BaggingClassifier\nfrom sklearn.tree import DecisionTreeClassifier\n\nmodel = BaggingClassifier(\n    base_estimator=DecisionTreeClassifier(),\n    random_state=0,\n)\nfor parameter in model.get_params():\n    print(parameter)\n","d29755da":"from sklearn.model_selection import GridSearchCV\n\nparameters = {    \n    'n_estimators': [50,70,80,150,160,170,175,180],\n    'max_features': [3, 4, 5, 6, 7, 8],\n    'max_samples': [200, 400, 600, 800],\n    #'base_estimator__max_leaf_nodes':[10, 15], \n    #'base_estimator__max_depth':[3, 4, 5, 6]\n}\nmodel_grid = GridSearchCV(model, parameters, n_jobs=2, cv=5)\nmodel_grid.fit(X, y)\naccuracy = model_grid.score(X, y)\naccuracy","7a6fc754":"model_grid.best_params_","8008a17f":"best_model = model_grid.best_estimator_\nbest_model","644ed0a5":"predictions = best_model.predict(X_test)\n\noutput = pd.DataFrame({'PassengerId': test_data.PassengerId, 'Survived': predictions})\noutput.to_csv('my_submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","f1980192":"Checking missing value:","0d4189fe":"# Explore dataset","d964c766":"# Preprocessing","02b6477b":"## Family size","ea8902f0":"# Create model using GridSearchCV","1018583a":"## Age","267870df":"## Others","f9b9e899":"We will use these features: \"Pclass\", \"Sex\", \"Age\", \"Embarked\", \"FamilySize\"","048a63c9":"## Ratio of men\/women who survived","713f8131":"# Prediction","7f671b93":"Filling missing value by median, then encode it into 4 bins"}}