{"cell_type":{"17755299":"code","1f64a906":"code","d0264911":"code","bc25d553":"code","a627061c":"code","fed74f11":"code","ff079af8":"code","b652ea8d":"code","2d245144":"code","975a1dac":"code","65c21f02":"code","e7c5855d":"code","94181579":"code","7ff821b8":"code","0f5a3ce2":"code","53fe951d":"code","013849c2":"code","75e6fbe8":"code","97150df5":"code","b3662aab":"code","23f9db0c":"code","5a19fff1":"code","8c3f41f1":"code","e1dc46d8":"code","fb43a355":"code","bdfcd1d8":"code","b2f924bc":"code","35961100":"code","c3670958":"code","0c675943":"code","544c71d3":"code","9a4fd2da":"code","496e5e5a":"markdown","91616685":"markdown","643dbf87":"markdown","6d9e9296":"markdown","04282e64":"markdown","b709b0fa":"markdown","5fba96ed":"markdown","09b3e733":"markdown"},"source":{"17755299":"import os\n\nimport tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\n\nimport tensorflow.keras as k\n\nimport matplotlib.pyplot as plt\nimport numpy as np","1f64a906":"#download the dataset if you don't have it\nif(not os.path.exists('cats_and_dogs_filtered.zip')):\n    !wget --no-check-certificate \\\n      https:\/\/storage.googleapis.com\/mledu-datasets\/cats_and_dogs_filtered.zip \\\n      -O cats_and_dogs_filtered.zip\n    \n    !unzip cats_and_dogs_filtered.zip","d0264911":"# Directory with our training pictures\ntrain_dir = 'cats_and_dogs_filtered\/train'\n\ntrain_cat_dir = os.path.join(train_dir,'cats')\ntrain_dog_dir = os.path.join(train_dir,'dogs')\n\n# Directory with our validation pictures\nvalidation_dir = 'cats_and_dogs_filtered\/validation'\nval_cat_dir = os.path.join(validation_dir,'cats')\nval_dog_dir = os.path.join(validation_dir,'dogs')","bc25d553":"print(tf.__version__)\nprint(tf.config.list_physical_devices())","a627061c":"def build_model():\n    model = k.models.Sequential([\n        # Note the input shape is the desired size of the image 300x300 with 3 bytes color\n        # This is the first convolution\n        k.layers.Conv2D(16, kernel_size=(6,6), activation= 'elu', input_shape=(300, 300, 3)),\n        k.layers.MaxPooling2D(2, 2),\n        k.layers.BatchNormalization(),\n        k.layers.Dropout(0.2),\n        # The second convolution\n        k.layers.Conv2D(32, (3,3), activation='elu'),\n        k.layers.MaxPooling2D(2,2),\n        k.layers.BatchNormalization(),\n        k.layers.Dropout(0.2),\n        # The third convolution\n        k.layers.Conv2D(64, (3,3), activation='elu'),\n        k.layers.MaxPooling2D(2,2),\n        k.layers.BatchNormalization(),\n        k.layers.Dropout(0.2),\n        # The fourth convolution\n        k.layers.Conv2D(128, (3,3), activation='elu'),\n        k.layers.MaxPooling2D(2,2),\n        k.layers.BatchNormalization(),\n        k.layers.Dropout(0.2),\n        #The fifth convolution\n        k.layers.Conv2D(128, (3,3), activation='elu'),\n        k.layers.MaxPooling2D(2,2),\n        k.layers.BatchNormalization(),\n        k.layers.Dropout(0.2),\n        # Flatten the results to feed into a DNN\n        k.layers.GlobalAveragePooling2D(),\n        #k.layers.Flatten(),\n        # 512 neuron hidden layer\n        k.layers.Dense(32, activation='elu'),\n        # Only 1 output neuron. It will contain a value from 0-1 where 0 for 1 class ('horses') and 1 for the other ('humans')\n        k.layers.Dense(1, activation='sigmoid')\n    ])\n\n    return model\nmodel = build_model()\nmodel.summary()\n  ","fed74f11":"model.compile(loss='binary_crossentropy',\n              #optimizer= SGD(lr=1e-4,momentum=0.9, nesterov=True),\n              #optimizer=RMSprop(lr=1e-4),\n              optimizer = 'Adam',\n              metrics=['accuracy'])\n","ff079af8":"# All images will be rescaled by 1.\/255\ntrain_datagen = ImageDataGenerator(rescale=1.\/255.)\n\nvalidation_datagen = ImageDataGenerator(rescale=1.\/255.)\n\n# Flow training images in batches of 128 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(300, 300),  # All images will be resized to 150x150\n        batch_size=128,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow training images in batches of 128 using train_datagen generator\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_dir,  # This is the source directory for training images\n        target_size=(300, 300),  # All images will be resized to 150x150\n        batch_size=256,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')","b652ea8d":"from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n#if(not os.path.exists('weights\/')):\n#  os.mkdir('weights\/')\n\n#file = 'weights\/weights-improvement-{epoch:02d}-{val_accuracy:.2f}.hdf5'\n\ncallbacks = [\n  EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=20,\n    verbose=1,\n    mode=\"max\",\n    restore_best_weights=True,\n  )\n]\n\n\n\nhistory = model.fit(\n    x = train_generator,\n    epochs=100,\n    shuffle = True,\n    validation_data = validation_generator,\n    verbose = 1,\n    callbacks = callbacks\n)","2d245144":"def plot_results(history):\n    acc,val_acc = history.history['accuracy'],history.history['val_accuracy']\n    loss,val_loss = history.history['loss'],history.history['val_loss']\n\n    epochs = range(len(acc))\n\n    plt.plot(epochs, acc, 'bo', c = 'b' ,label='Training accuracy')\n    plt.plot(epochs, val_acc, 'b', c = 'r', label='Validation accuracy')\n    plt.title('Training and validation accuracy')\n    plt.legend()\n\n    plt.figure()\n\n    plt.plot(epochs, loss, 'bo', c = 'b', label='Training Loss')\n    plt.plot(epochs, val_loss, 'b', c = 'r', label='Validation Loss')\n    plt.title('Training and validation loss')\n    plt.legend()\n\n    plt.show()\n    \nplot_results(history)","975a1dac":"#model.load_weights('weights-improvement-47-0.73.hdf5')\nmodel.evaluate(train_generator)\nmodel.evaluate(validation_generator)","65c21f02":"from matplotlib.pyplot import imread\nimport random\n\nn_rows = 5\nn_cols = 5\n\nimg_cats = [os.path.join(train_cat_dir,i) for i in os.listdir(train_cat_dir)]\nimg_dogs = [os.path.join(train_dog_dir,i) for i in os.listdir(train_dog_dir)]\n\nall_imgs = img_cats + img_dogs\n\nrandom_imgs_to_sample = random.sample(all_imgs, n_rows * n_cols)\n\nplt.figure(figsize=(30,30))\nplt.title(\"Random images from the dataset, try to find patters to aplly augmentation\")\n\nfor i in range(0,n_rows*n_cols):\n  \n    plt.subplot(n_rows,n_cols,i+1)\n    path = random_imgs_to_sample[i]\n    img = imread(path)\n    plt.imshow(img\/255)\n\n    plt.plot()\n","e7c5855d":"# All images will be rescaled by 1.\/255\ntrain_datagen = ImageDataGenerator(\n      #featurewise_center = True,\n      #featurewise_std_normalization\t = True,\n      rescale=1.\/255.,\n      rotation_range=50,\n      shear_range=0.4,\n      zoom_range=0.4,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(\n    rescale=1.\/255.\n  )\n\n# Flow training images in batches of 128 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(300, 300),  # All images will be resized to 150x150\n        batch_size= 128,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow training images in batches of 128 using train_datagen generator\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_dir,  # This is the source directory for training images\n        target_size=(300, 300),  # All images will be resized to 150x150\n        batch_size=32,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')","94181579":"model = build_model()\n\nmodel.compile(loss='binary_crossentropy',\n              #optimizer= SGD(lr=1e-4,momentum=0.9, nesterov=True),\n              #optimizer=RMSprop(lr=1e-4),\n              optimizer = 'Adam',\n              metrics=['accuracy'])\n","7ff821b8":"callbacks = [\n  EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=20,\n    verbose=1,\n    mode=\"max\",\n    restore_best_weights=True,\n  )\n]\n\nhistory = model.fit(\n    x = train_generator,\n    epochs=100,\n    shuffle = True,\n    validation_data = validation_generator,\n    verbose = 1,\n    callbacks = callbacks\n)\n","0f5a3ce2":"plot_results(history)","53fe951d":"model.evaluate(train_generator)\nmodel.evaluate(validation_generator)","013849c2":"!wget --no-check-certificate \\\n    https:\/\/storage.googleapis.com\/mledu-datasets\/inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5 \\\n    -O inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5","75e6fbe8":"# Import the inception model  \nfrom tensorflow.keras.applications.inception_v3 import InceptionV3","97150df5":"model = InceptionV3(\n    include_top = False,\n    input_shape = (300,300,3),\n    weights = 'inception_v3_weights_tf_dim_ordering_tf_kernels_notop.h5'\n)","b3662aab":"#model.summary()\nimport keras\nfrom keras.utils.vis_utils import plot_model\n\nprint(\"This model have \" + str(len(model.layers)) + \" layers\")\nplot_model(model, show_shapes=True, show_layer_names=True)","23f9db0c":"for layer in model.layers:\n  layer.trainable = False\n\nx = np.sum([tmp.trainable for tmp in model.layers])\nprint(\"trainable layers = \" + str(x))\n\nlast_layer = model.get_layer('mixed7')\nprint(last_layer.name)\nprint(last_layer.output)","5a19fff1":"out = k.layers.Flatten()(last_layer.output)\nout = k.layers.Dropout(0.4)(out)\nout = k.layers.Dense(512, activation = 'relu')(out)\nout = k.layers.Dropout(0.4)(out)\nout = k.layers.Dense(256, activation = 'relu')(out)\nout = k.layers.Dropout(0.4)(out)\nout = k.layers.Dense(1, activation = 'sigmoid')(out)\n\nmodel = k.models.Model(inputs = model.input , outputs = out )","8c3f41f1":"model.compile(loss='binary_crossentropy',\n              optimizer = 'Adam',\n              #optimizer=RMSprop(lr=1e-4),\n              metrics=['accuracy'])","e1dc46d8":"# All images will be rescaled by 1.\/255\ntrain_datagen = ImageDataGenerator(\n      #featurewise_center = True,\n      #featurewise_std_normalization\t = True,\n      rescale=1.\/255.,\n      rotation_range=50,\n      shear_range=0.4,\n      zoom_range=0.4,\n      horizontal_flip=True,\n      fill_mode='nearest')\n\nvalidation_datagen = ImageDataGenerator(\n    rescale=1.\/255.\n  )\n\n# Flow training images in batches of 128 using train_datagen generator\ntrain_generator = train_datagen.flow_from_directory(\n        train_dir,  # This is the source directory for training images\n        target_size=(300, 300),  # All images will be resized to 150x150\n        batch_size= 128,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')\n\n# Flow training images in batches of 128 using train_datagen generator\nvalidation_generator = validation_datagen.flow_from_directory(\n        validation_dir,  # This is the source directory for training images\n        target_size=(300, 300),  # All images will be resized to 150x150\n        batch_size=32,\n        # Since we use binary_crossentropy loss, we need binary labels\n        class_mode='binary')","fb43a355":"from tensorflow.keras.callbacks import EarlyStopping\n\ncallbacks = [\n  EarlyStopping(\n    monitor=\"val_accuracy\",\n    patience=8,\n    verbose=1,\n    mode=\"max\",\n    restore_best_weights=True,\n  )\n]\n\nhistory = model.fit(\n    x = train_generator,\n    epochs=100,\n    shuffle = True,\n    validation_data = validation_generator,\n    verbose = 1,\n    callbacks = callbacks\n)","bdfcd1d8":"def plot_results(history):\n  acc = history.history['accuracy']\n  val_acc = history.history['val_accuracy']\n  loss = history.history['loss']\n  val_loss = history.history['val_loss']\n\n  epochs = range(len(acc))\n\n  plt.plot(epochs, acc, 'bo', c = 'b' ,label='Training accuracy')\n  plt.plot(epochs, val_acc, 'b', c = 'r', label='Validation accuracy')\n  plt.title('Training and validation accuracy')\n  plt.legend()\n\n  plt.figure()\n\n  plt.plot(epochs, loss, 'bo', c = 'b', label='Training Loss')\n  plt.plot(epochs, val_loss, 'b', c = 'r', label='Validation Loss')\n  plt.title('Training and validation loss')\n  plt.legend()\n\n  plt.show()\n\nplot_history(history)","b2f924bc":"import numpy as np\nfrom google.colab import files\nfrom keras.preprocessing import image\n\nuploaded = files.upload()\n\nfor fn in uploaded.keys():\n\n  path = '\/content\/' + fn\n  img = image.load_img(path,target_size=(300,300))\n  x = image.img_to_array(img)\n  x = np.expand_dims(x,axis=0)\n\n  print(x.shape)\n\n  images = np.vstack([x])\n\n\n  classes = model.predict(images,batch_size=10)\n\n  print(classes[0])","35961100":"from tensorflow.keras.preprocessing.image import load_img,img_to_array\n\npath = '\/content\/' + 'test_image.jpg'\nimg = load_img(path,target_size=(300,300))\nx = img_to_array(img)\nx = np.expand_dims(x,axis=0)\/255\n\nimages = np.vstack([x])\n\n\nclasses = model.predict(images,batch_size=1)\n\nprint(classes[0])","c3670958":"model.save('dogg_recognized')","0c675943":"from google.colab import files","544c71d3":"files.download('\/content\/dogg_recognized')","9a4fd2da":"model.save_weights('dog')","496e5e5a":"## Training without Augmentation","91616685":"## Let's build a Small Network","643dbf87":"## Let's use Transfer Learning\n\n> I'm using Inception here","6d9e9296":"## With Augmentation included","04282e64":"## As we can see, this generalization can be easily improved\n\n> After training this simple model, let's inspect the data searching patterns to decide which augmentation techniques to use.\n","b709b0fa":"> Conclusion:\n  \n  1. Many of them are shaped to the left and right, so use horizontal flit.\n  2. Their faces are also inclinded to several directions as with their bodys, consider to use shear and rotation\n  3. Some have more zoom than others, use zoom\n  4. The brightness as also a litlle variance, add some\n\n\n> Additionally try to use this:\n   1. featurewise_std_normalization: Boolean. Divide inputs by std of the dataset, feature-wise.\n   2. samplewise_std_normalization: Boolean. Divide each input by its std.","5fba96ed":"## Import the following libraries","09b3e733":"Finally we add the densely connected layers. \n\nNote that, because we are dealing with a two-class classification problem, i.e. a *binary classification problem*, we will end our network with a [*sigmoid* activation](https:\/\/wikipedia.org\/wiki\/Sigmoid_function), so that the output of our network will be a single scalar between 0 and 1, encoding the probability that the current image is class 1 (as opposed to class 0)."}}