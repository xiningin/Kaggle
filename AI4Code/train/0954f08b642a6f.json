{"cell_type":{"a246a726":"code","b594763e":"code","59bbea55":"code","472ae472":"code","1e2f80d1":"code","d78a18cb":"code","2bc48c11":"code","2cc90449":"code","e19d2d68":"code","9abe0b78":"code","9262e4ff":"code","196cb03d":"code","bf8d36b3":"code","73514867":"markdown","023233e3":"markdown"},"source":{"a246a726":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport matplotlib.pyplot as plt\nfrom glob import glob\n\nfrom plotly.offline import init_notebook_mode, iplot, plot\nimport plotly as py\ninit_notebook_mode(connected=True)\nimport plotly.graph_objs as go\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b594763e":"train_dir = '\/kaggle\/input\/louisiana-flood-2016\/train\/'\nvalid_dir = '\/kaggle\/input\/louisiana-flood-2016\/test\/'\ntrain_csv = '\/kaggle\/input\/louisiana-flood-2016\/train.csv'\nvalid_csv = '\/kaggle\/input\/louisiana-flood-2016\/test.csv'","59bbea55":"train_df = pd.read_csv(train_csv)\nvalid_df = pd.read_csv(valid_csv)","472ae472":"train_df.shape, train_df.head()","1e2f80d1":"valid_df.shape, valid_df.head()","d78a18cb":"trainDataDbn = {'Normal':train_df['Normal'].value_counts().values[0],\n                'Flooded':train_df['Flooded'].value_counts().values[1],\n                'Not flooded': train_df['Flooded'].value_counts().values[0] - train_df['Normal'].value_counts().values[0]}\ntrainDataDbn","2bc48c11":"fig = {\n  \"data\": [\n    {\n      \"values\": list(trainDataDbn.values()),\n      \"labels\": list(trainDataDbn.keys()),\n      \"hoverinfo\":\"label+percent\",\n      \"hole\": .3,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Training Data Distribution\",\n        \"annotations\": [\n            { \"font\": { \"size\": 20},\n              \"showarrow\": False,\n              \"text\": \"Number of Images\",\n                \"x\": 1,\n                \"y\": 1\n            },\n        ]\n    }\n}\niplot(fig)","2cc90449":"validDataDbn = {'Normal':valid_df['Normal'].value_counts().values[0],\n                'Flooded':valid_df['Flooded'].value_counts().values[1],\n                'Not flooded': valid_df['Flooded'].value_counts().values[0] - valid_df['Normal'].value_counts().values[0]}\nvalidDataDbn","e19d2d68":"fig = {\n  \"data\": [\n    {\n      \"values\": list(validDataDbn.values()),\n      \"labels\": list(validDataDbn.keys()),\n      \"hoverinfo\":\"label+percent\",\n      \"hole\": .3,\n      \"type\": \"pie\"\n    },],\n  \"layout\": {\n        \"title\":\"Validation Data Distribution\",\n        \"annotations\": [\n            { \"font\": { \"size\": 20},\n              \"showarrow\": False,\n              \"text\": \"Number of Images\",\n                \"x\": 1,\n                \"y\": 1\n            },\n        ]\n    }\n}\niplot(fig)","9abe0b78":"normal_imgs = train_df[train_df['Normal']==1]\nnormal_imgs['Image ID'].values[:5]","9262e4ff":"print(\"Train Images\")\nfig=plt.figure(figsize=(15, 10))\ncolumns = 2; rows = 5\nfor i in range(0, columns*rows, 2):\n    fig.add_subplot(rows,columns,i+1)\n    before_img = train_dir+normal_imgs['Image ID'].values[i]\n    plt.imshow(plt.imread(before_img))\n    plt.title(\"Before\/After flood\")\n    fig.add_subplot(rows,columns,i+2)\n    flood_img = glob(train_dir+normal_imgs['Image ID'].values[i].split('.')[0]+'_*')\n    plt.imshow(plt.imread(flood_img[0]))\n    ftitle = 'Flooded' if flood_img[0].split('_')[-1]=='1.png' else 'Not flooded'\n    plt.title(ftitle)","196cb03d":"normal_imgs = valid_df[valid_df['Normal']==1]\nnormal_imgs['Image ID'].values[:5]","bf8d36b3":"print(\"Valid Images\")\nfig=plt.figure(figsize=(15, 10))\ncolumns = 2; rows = 5\nfor i in range(0, columns*rows, 2):\n    fig.add_subplot(rows,columns,i+1)\n    before_img = valid_dir+normal_imgs['Image ID'].values[i]\n    plt.imshow(plt.imread(before_img))\n    plt.title(\"Before\/After flood\")\n    fig.add_subplot(rows,columns,i+2)\n    flood_img = glob(valid_dir+normal_imgs['Image ID'].values[i].split('.')[0]+'_*')\n    plt.imshow(plt.imread(flood_img[0]))\n    ftitle = 'Flooded' if flood_img[0].split('_')[-1]=='1.png' else 'Not flooded'\n    plt.title(ftitle)","73514867":"## Data distribution","023233e3":"## Samples"}}