{"cell_type":{"21951e84":"code","3ac333ae":"code","600b5fc5":"code","90a8c6cd":"code","780e9439":"code","1698f587":"code","d17cc882":"code","ef08a07e":"code","bca0424a":"code","28790421":"code","1b0af4d1":"code","abb785d2":"code","f2feb9bc":"code","509dc2cd":"code","25752d33":"code","27320dc0":"code","68140290":"code","09990124":"code","77bbeff1":"code","32b5509d":"code","621fd544":"code","7d589b96":"code","d676f27d":"code","73a0047d":"code","5e7eb309":"code","a29a245b":"code","bee78641":"code","77d1f2cb":"code","5050e2c6":"code","11b1feba":"code","78dd723d":"code","832b05b0":"code","16e8cf6e":"code","2b7fd401":"code","09eb04db":"code","193da1bb":"code","5d0a67d4":"code","cf10f2f6":"code","f2a7bf2e":"markdown","e6544276":"markdown","9bea1a01":"markdown","d4eb8fda":"markdown","5c15a054":"markdown","e6440de0":"markdown","dfd97780":"markdown","aa8c127d":"markdown","06473524":"markdown","d2fa64fe":"markdown","3d46e4ed":"markdown","cbd678e9":"markdown","0227c208":"markdown","68bb4280":"markdown","2bf09700":"markdown","067db3e6":"markdown","fc90f5c0":"markdown","89575d40":"markdown","cfbc82cc":"markdown","3626ac7e":"markdown","4d382094":"markdown","ce369c00":"markdown"},"source":{"21951e84":"import numpy as np\nimport pandas as pd\nimport os\nimport matplotlib.pyplot as plt\nimport soundfile as sf\nimport librosa\nimport librosa.display\nimport IPython.display as display","3ac333ae":"import torch\nimport torchaudio\nfrom pathlib import Path\nfrom torch.utils.data import Dataset, DataLoader\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim","600b5fc5":"def plot_signal_and_spectogram(data_array, samplerate):\n    fig, axs = plt.subplots(1, 2, figsize=(22, 5))\n    fig.subplots_adjust(hspace = .1, wspace=.2)\n    axs = axs.ravel()\n    x = range(len(data_array))\n    y = data_array\n    axs[0].plot(x, y)\n    axs[0].grid()\n    axs[1].specgram(data_array,Fs=samplerate, mode='psd', scale='dB')\n    axs[0].set_title('Signal')\n    axs[0].set_xlabel('Sample')\n    axs[0].set_ylabel('Amplitude')\n    axs[1].set_title('Spectogram')\n    axs[1].set_xlabel('Time')\n    axs[1].set_ylabel('Frequency')\n    plt.grid()\n    \ndef listen_example(file):\n    return display.Audio(path+'audio\/audio\/'+file)\n\ndef get_file_list(category):\n    file_list = data[data['category']==category]['filename'].to_list()\n    return file_list","90a8c6cd":"path = '\/kaggle\/input\/environmental-sound-classification-50\/'\npath_audio = path+'audio\/audio\/'\nos.listdir(path)","780e9439":"data = pd.read_csv(path+'esc50.csv')","1698f587":"print('number of samples:', len(data))\nprint('number of wave files:', len(os.listdir(path+'audio\/audio')))","d17cc882":"data.head()","ef08a07e":"file = '1-101296-A-19.wav'\ndata_array, samplerate = sf.read(path_audio+file)","bca0424a":"print('data array:', data_array)\nprint('number of data values:', len(data_array))\nprint('samplerate:', samplerate)","28790421":"display.Audio(path+'audio\/audio\/'+file)","1b0af4d1":"plot_signal_and_spectogram(data_array, samplerate)","abb785d2":"data['category'].unique()","f2feb9bc":"frogs = get_file_list('frog')\nlisten_example(frogs[0])","509dc2cd":"data_array, samplerate = sf.read(path_audio+frogs[0])\nplot_signal_and_spectogram(data_array, samplerate)","25752d33":"insects = get_file_list('insects')\nlisten_example(insects[1])","27320dc0":"data_array, samplerate = sf.read(path_audio+insects[0])\nplot_signal_and_spectogram(data_array, samplerate)","68140290":"waters = get_file_list('pouring_water')\nlisten_example(waters[0])","09990124":"data_array, samplerate = sf.read(path_audio+waters[0])\nplot_signal_and_spectogram(data_array, samplerate)","77bbeff1":"mouse_clicks = get_file_list('mouse_click')\nlisten_example(mouse_clicks[0])","32b5509d":"data_array, samplerate = sf.read(path_audio+mouse_clicks[0])\nplot_signal_and_spectogram(data_array, samplerate)","621fd544":"crying_babies = get_file_list('crying_baby')\nlisten_example(crying_babies[1])","7d589b96":"data_array, samplerate = sf.read(path_audio+crying_babies[1])\nplot_signal_and_spectogram(data_array, samplerate)","d676f27d":"sirens = get_file_list('siren')\nlisten_example(sirens[2])","73a0047d":"data_array, samplerate = sf.read(path_audio+sirens[2])\nplot_signal_and_spectogram(data_array, samplerate)","5e7eb309":"crickets = get_file_list('crickets')\nlisten_example(crickets[0])","a29a245b":"data_array, samplerate = sf.read(path_audio+crickets[0])\nplot_signal_and_spectogram(data_array, samplerate)","bee78641":"class DataGenerator(Dataset):\n    def __init__(self, path, kind='train'):\n        if kind=='train':\n            files = Path(path).glob('[1-3]-*')\n        if kind=='val':\n            files = Path(path).glob('4-*')\n        if kind=='test':\n            files = Path(path).glob('5-*')\n        \n        self.items = [(str(file), file.name.split('-')[-1].replace('.wav', '')) for file in files]\n        self.length = len(self.items)\n        \n    def __getitem__(self, index):\n        filename, label = self.items[index]\n        data_tensor, rate = torchaudio.load(filename)\n        return (data_tensor, int(label))\n    \n    def __len__(self):\n        return self.length","77d1f2cb":"test_data = DataGenerator(path_audio)\ndata_tensor, label = list(test_data)[0]","5050e2c6":"test_data.length","11b1feba":"print('data_tensor:', data_tensor)\nprint('data_tensor shape:', data_tensor.shape)\nprint('label:', label)","78dd723d":"test_loader = DataLoader(test_data, batch_size=16, shuffle=True)","832b05b0":"len(test_loader.dataset)","16e8cf6e":"batch_size = 64\n\ntrain_data = DataGenerator(path_audio, kind='train')\nval_data = DataGenerator(path_audio, kind='val')\ntest_data = DataGenerator(path_audio, kind='test')\n\ntrain_loader = DataLoader(train_data, batch_size=batch_size, shuffle=True)\nval_loader = DataLoader(val_data, batch_size=batch_size, shuffle=True)\ntest_loader = DataLoader(test_data, batch_size=batch_size, shuffle=True)","2b7fd401":"class SimpleCnn(nn.Module):\n    def __init__(self):\n        super(SimpleCnn, self).__init__()\n        self.conv1 = nn.Conv1d(100, 128, kernel_size=5, stride=4)\n        self.bn1 = nn.BatchNorm1d(128)\n        self.pool1 = nn.MaxPool1d(4)\n        self.conv2 = nn.Conv1d(128, 128, 3)\n        self.bn2 = nn.BatchNorm1d(128)\n        self.pool2 = nn.MaxPool1d(4)\n        self.conv3 = nn.Conv1d(128, 256, 3)\n        self.bn3 = nn.BatchNorm1d(256)\n        self.pool3 = nn.MaxPool1d(4)\n        self.conv4 = nn.Conv1d(256, 512, 3)\n        self.bn4 = nn.BatchNorm1d(512)\n        self.pool4 = nn.MaxPool1d(4)\n        self.fc1 = nn.Linear(512, 50)\n        \n    def forward(self, x):\n        x = x.unsqueeze(-1).view(-1, 100, 2205)\n        x = self.conv1(x)\n        x = F.relu(self.bn1(x))\n        x = self.pool1(x)\n        x = self.conv2(x)\n        x = F.relu(self.bn2(x))\n        x = self.pool2(x)\n        x = self.conv3(x)\n        x = F.relu(self.bn3(x))\n        x = self.pool3(x)\n        x = self.conv4(x)\n        x = F.relu(self.bn4(x))\n        x = self.pool4(x)\n        x = x.squeeze(-1)\n        x = self.fc1(x)\n        return x","09eb04db":"device = torch.device('cpu')\nmodel = SimpleCnn()\nmodel.to(device)","193da1bb":"optimizer = optim.Adam(model.parameters(), lr=0.001)","5d0a67d4":"def train(model, optimizer, loss_fn, train_loader, val_loader, epochs=2, device='cpu'):\n    for epoch in range(epochs):\n        training_loss = 0.0\n        valid_loss = 0.0\n        model.train()\n        for batch in train_loader:\n            optimizer.zero_grad()\n            inputs, targets = batch\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n            output = model(inputs)\n            loss = loss_fn(output, targets)\n            loss.backward()\n            optimizer.step()\n            training_loss += loss.data.item()*inputs.size(0)\n        training_loss \/= len(train_loader.dataset)\n        \n        model.eval()\n        num_correct = 0\n        num_examples = 0\n        for batch in val_loader:\n            inputs, targets = batch\n            inputs = inputs.to(device)\n            targets = targets.to(device)\n            output = model(inputs)\n            loss = loss_fn(output, targets)\n            valid_loss += loss.data.item()*inputs.size(0)\n            correct = torch.eq(torch.max(F.softmax(output, dim=1), dim=1)[1], targets)\n            num_correct += torch.sum(correct).item()\n            num_examples += correct.shape[0]\n        valid_loss \/= len(val_loader.dataset)\n        \n        print('Epoch: {}, Training Loss: {:.2f}, Validation Loss: {:.2f}, '\n              'accuracy = {:.2f}'.format(epoch+1, training_loss, valid_loss, num_correct\/num_examples))","cf10f2f6":"train(model, optimizer, nn.CrossEntropyLoss(), train_loader, val_loader, epochs=20, device=device)","f2a7bf2e":"There are 50 categories with each 40 samples:","e6544276":"## Siren","9bea1a01":"# Data Generator\nWe define a data generator to load the data on demand.","d4eb8fda":"# Libraries\nWe use some standard libraries and packages of the pytorch library.","5c15a054":"# Load Data","e6440de0":"# Data Loader\nBased on the data generator we are able to define a [data loader object](https:\/\/pytorch.org\/docs\/stable\/data.html).","dfd97780":"# Model\nWe build a simple CNN model.","aa8c127d":"## Crying Baby","06473524":"# Functions\nWe define some helper functions.","d2fa64fe":"## Frog","3d46e4ed":"# Intro\nWelcome to the [Environmental Sound Classification (ESC)](https:\/\/www.kaggle.com\/mmoreaux\/environmental-sound-classification-50) dataset.\n\n![](https:\/\/i.ibb.co\/hmGkz66\/signal-spectogram.png)\n\n<font size=\"4\"><span style=\"color: royalblue;\">Please vote the notebook up if it helps you. Feel free to leave a comment above the notebook. Thank you. <\/span><\/font>","cbd678e9":"# EDA","0227c208":"# Overview","68bb4280":"## Pouring Water","2bf09700":"# Train, Validation And Test Data\nThe dataset ist divided into 5 parts by the feature fold. We can use ist to define the train, validation and test data. For train we use the samples with the fold label 1,2 and 3, for validation 4 and for test data label 5.","067db3e6":"# Path","fc90f5c0":"## Crickets","89575d40":"## Insects","cfbc82cc":"Test data generator:","3626ac7e":"## Mouse Click","4d382094":"# Listen To The Music","ce369c00":"# Sample File"}}