{"cell_type":{"b6c3a7b2":"code","8ff05d39":"code","8e88ea29":"code","bfb34b06":"code","7b094f39":"code","0899f0f4":"code","6413e378":"code","97dd0b53":"code","040965b8":"code","19e47e15":"code","514cd974":"code","9cbe5457":"code","9dddcfc9":"code","cbc4b1ab":"code","869bb3cc":"code","702b657c":"markdown","3f03ad06":"markdown","6853ee33":"markdown","cae0ce54":"markdown","2b4e773a":"markdown","01a5623e":"markdown","a0c07c50":"markdown","57fd7635":"markdown","cc43188a":"markdown","a44cca5e":"markdown","cd1e7dc5":"markdown","1efc3e6d":"markdown","98bf41fd":"markdown","b5070312":"markdown","2d81fb34":"markdown","b1654997":"markdown","65a7a138":"markdown","9e880ada":"markdown","aa7d5aea":"markdown"},"source":{"b6c3a7b2":"import numpy as np\nimport cv2\nimport matplotlib.pyplot as plt\nimport os\nimport sklearn\nimport glob\nimport keras\nimport pandas as pd\nfrom keras.callbacks import ModelCheckpoint,ReduceLROnPlateau\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.models import Sequential,load_model\nfrom keras.layers import Dense, Dropout, Activation, Flatten\nfrom keras.layers import Conv2D, MaxPooling2D\nfrom keras.optimizers import SGD, Adam\nfrom sklearn.model_selection import train_test_split\n\n%matplotlib inline","8ff05d39":"pic_size = 64\nbatch_size = 64\nepochs =50\n\nmap_characters={0: 'abraham_grampa_simpson', 1: 'agnes_skinner', 2: 'apu_nahasapeemapetilon', 3: 'barney_gumble', \n                4: 'bart_simpson', 5: 'carl_carlson', 6: 'charles_montgomery_burns', 7: 'chief_wiggum', \n                8: 'cletus_spuckler', 9: 'comic_book_guy', 10: 'disco_stu', 11: 'edna_krabappel', 12: 'fat_tony',\n                13: 'gil', 14: 'groundskeeper_willie', 15: 'homer_simpson', 16: 'kent_brockman', 17: 'krusty_the_clown', \n                18: 'lenny_leonard', 19: 'lionel_hutz', 20: 'lisa_simpson', 21: 'maggie_simpson', 22: 'marge_simpson',\n                23: 'martin_prince', 24: 'mayor_quimby', 25: 'milhouse_van_houten', 26: 'miss_hoover', 27: 'moe_szyslak', \n                28: 'ned_flanders', 29: 'nelson_muntz', 30: 'otto_mann', 31: 'patty_bouvier', 32: 'principal_skinner', \n                33: 'professor_john_frink', 34: 'rainier_wolfcastle', 35: 'ralph_wiggum', 36: 'selma_bouvier', \n                37: 'sideshow_bob', 38: 'sideshow_mel', 39: 'snake_jailbird', 40: 'troy_mcclure', 41: 'waylon_smithers'}","8e88ea29":"cwd=os.getcwd()\ndirectory=os.listdir(path)\nmap_characters={}\nfor i in range(0,len(directory)):\n    map_characters[i]=directory[i]","bfb34b06":"#SELF\ndef load_data_set(path):\n    pics, labels = [], []\n    reverse_dict = {v:k for k,v in map_characters.items()}\n    plt.gcf().set_size_inches(2,2)\n    for i in map_characters.values():\n        for pic in glob.glob(path+'\\\\'+i+'\\\\*.jpg'):\n            temp = cv2.imread(pic)\n            temp = cv2.resize(temp, (pic_size,pic_size)).astype('float32') \/ 255.\n            pics.append(temp)\n            labels.append(reverse_dict[i])\n    X_test = np.array(pics)\n    y_test = np.array(labels)\n    y_test = keras.utils.to_categorical(y_test,len(map_characters))\n    print(\"Test set\", X_test.shape, y_test.shape)\n    return X_test, y_test","7b094f39":"X_train, y_train = load_data_set(\"train\")","0899f0f4":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.5)","6413e378":"def create_model(input_shape):\n  \n    model = Sequential()\n    model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\", input_shape=input_shape))\n    model.add(Conv2D(32, (3, 3), padding='same', activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n    model.add(Conv2D(64, (3, 3), padding='same', activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.25))\n\n    model.add(Conv2D(256, (3, 3), padding='same', activation=\"relu\")) \n    model.add(Conv2D(256, (3, 3), padding='same', activation=\"relu\"))\n    model.add(MaxPooling2D(pool_size=(2, 2)))\n    model.add(Dropout(0.2))\n\n    model.add(Flatten())\n    model.add(Dense(1024, activation=\"relu\"))\n    model.add(Dropout(0.5))\n    model.add(Dense(len(map_characters), activation=\"softmax\"))#number of classes #softmax turn class into probability\n    #model.load_weights('Simpsons Challenge RGB.hdf5')\n    model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])#usually adam is great in most time\n    return model","97dd0b53":"def augmentedData_ReduceLR(model,X_train, X_valid, y_train, y_valid):\n    datagen = ImageDataGenerator(\n        featurewise_center=False,  # set input mean to 0 over the dataset\n        samplewise_center=False,  # set each sample mean to 0\n        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n        samplewise_std_normalization=False,  # divide each input by its std\n        zca_whitening=False,  # apply ZCA whitening\n        rotation_range=10,  # randomly rotate images in the range (degrees, 0 to 180)\n        width_shift_range=0.1,  # randomly shift images horizontally (fraction of total width)\n        height_shift_range=0.1,  # randomly shift images vertically (fraction of total height)\n        zoom_range=0.1,\n        horizontal_flip=True,  # randomly flip images\n        vertical_flip=False)  # randomly flip images\n    datagen.fit(X_train)\n    filepath=\"Simpsons Challenge RGB.hdf5\"\n    reduce_lr = ReduceLROnPlateau(monitor='val_loss',patience=3,verbose=1,factor=0.5,min_lr=0.00001)\n    checkpoint = ModelCheckpoint(filepath, monitor='val_accuracy', verbose=1, save_best_only=True, mode='max')\n    history = model.fit_generator(datagen.flow(X_train, y_train,\n                                     batch_size=batch_size),\n                                    steps_per_epoch=X_train.shape[0] \/\/ batch_size,\n                                    epochs=epochs,\n                                    callbacks= [checkpoint,reduce_lr],\n                                    validation_data=(X_valid, y_valid))\n    return model,history","040965b8":"input_shape=(pic_size,pic_size,3)\nmodel=create_model(input_shape)\nmodel,history= augmentedData_ReduceLR(model,X_train, X_valid, y_train, y_valid)  ","19e47e15":"#model.summary()","514cd974":"plt.plot(history.history['accuracy'])\nplt.plot(history.history['val_accuracy'])\nplt.title('model accuracy')\nplt.ylabel('accuracy')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()\n\nplt.plot(history.history['loss'])\nplt.plot(history.history['val_loss'])\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['train', 'test'], loc='best')\nplt.show()\nloss,acc = model.evaluate(X_valid, y_valid)#get evaluate result\n    \nprint('Test loss:', loss)\nprint('accuracy:', acc)","9cbe5457":"model = load_model('Simpsons Challenge RGB.hdf5')","9dddcfc9":"def load_test_set(path):\n    pics, y_id = [], []\n    reverse_dict = {v:k for k,v in map_characters.items()}\n    for pic in glob.glob(path+'\\\\*.jpg'):\n        char_name=pic.split('\\\\')[1]\n        temp = cv2.imread(pic)    \n        temp = cv2.resize(temp, (pic_size,pic_size)).astype('float32') \/ 255.\n        y_id.append(char_name)\n        pics.append(temp)\n    X_test = np.array(pics)\n    y_test = np.array(y_id)\n    print(\"Test set\", X_test.shape, y_test.shape)\n    return X_test, y_test","cbc4b1ab":"X_test,y_id = load_test_set(\"test\")\ny_pred = model.predict_classes(X_test)\nid_col=[i for i in range(1,len(X_test)+1)]\ny_pred=[map_characters[i] for i in y_pred]","869bb3cc":"#del submission2\nsubmission = pd.DataFrame()\nsubmission['Id'] = y_id\nsubmission['Category'] =pd.Series(y_pred)\nsubmission.to_csv('submission.csv', index=False)","702b657c":"Use can also use os to get the files in the path and map the into dictionary","3f03ad06":"see layer in the model","6853ee33":"# Augmented Pictures","cae0ce54":"# TEST prediction","2b4e773a":"Use laod model<br>\nUse load model if you just want to see the prediction provided by the last time model .","01a5623e":"Welcome to my notebook.I am JC-CHIEH.Below is my notebook.It goes step by step which include import package ,labeling training data set, build model , augmented data, training model,plot diagram,test data set, predict data.\n<br>\n**Notice! My notebook runs data on my local computer**","a0c07c50":"laod data set method \nread jpg file from the path and resize ,nnormalize each of pic (it's good for computer to calculate from 0~1 rather and 0~255)and for being appended to pics list ,and also append i in map_character to labels list [](http:\/\/)","57fd7635":"# Import Package","cc43188a":"[Simpsons Challenge |Kaggle](https:\/\/www.kaggle.com\/c\/simpsons-challenge-gft\/overview)","a44cca5e":"# Build model","cd1e7dc5":"# Plot diagram","1efc3e6d":"**Model **<BR>\nIt is mainly based on a six-layer convolutional neural network (CNN), which activates the neuron to conduct to the next neuron with the RELU activation function. Through the six-layer CNN, use a certain number of CNNs to capture the features and contours of the image, and then connect the CNN of the previous layer of CNN as the input value, and then use a certain number of CNNs (that is, through different CNNs' Arrays  with different weights, which can capture different features), capture features and contours of features and contours, that is, higher-dimensional features or features that are highly correlated but not intended captured.\nAmong them, every two layers of CNN are subsequently connected to a pooling layer (MaxPooling). The purpose is to block out relatively low-information information, achieve the purpose of greatly reducing the dimensionality, and also have an anti-interference effect.\nThen connect the DropOut layer after the pooling layer, so that in each training, not all neurons will be trained. The advantage of DropOut is that the model of the model has Generalization and is not sensitive to the training data set.  To avoid overfitting, then connect the Flatten layer , and then connect to the fully connected layer, because the input image information in CNN is three-dimensional (RGB), and usually the information of the fully connected layer is One-dimensional, through the middle transition layer Flatten layer, to do the middle degree processing. Finally, after connecting DropOut, connect to the output layer to output the model prediction results.","98bf41fd":"# Labeling training data and normalization","b5070312":"**Due to directly assigning list like y_id will lead to index error ,use Series to concatenate the prediction.\nFinally output csv file with no index setting.**","2d81fb34":"Load the model's weight to be current model base weight if last time training is stop or interrupt .<br>\nif you dont have entire time to complete all the epoch setting in the hyper parameters ,you can use *load model* to let you to continue training last time training model.<br>\nBut the training data of the history are just acquired by the current training time,which means you can't get the last time training data of the history. So I advise you to train model at once.","b1654997":"# initialize hyper parameters","65a7a138":"plot the training time of the history","9e880ada":"Split data into two part .One for training the other for validation.","aa7d5aea":"Use callbacks function \n* ReduceLROnPlateau <br>\nReduceLROnPlateau reduces learning rate when a metric has stopped improving.\nDue to the high learning rate in the early stage, when the model no longer has a good learning rate, by reducing the learning rate (LR, learning rate), trying to avoid letting the learning result not falling outside the optimal solution domain(local optimum) as much as possible.\n\n* ModelCheckpoint<br>\nModelCheckPoint will check the status of the verification results after each training of the model. When the status of the verification results in improvement, it will store the weight and information of the model, which can avoid the over-fitting of the model through training with a large number of data sets. \n<br><br>\nUse Augmented data\n* ImageDataGenerator<BR>\nThe advantage of augmented data is that data set data can be converted to obtain more data set data.<BR>\nEX: Adjust the degree of image rotation, image enlargement and reduction, horizontal flip, height and width offset<BR>\nBy augmenting the data, the model can have more data to train on the predicted target, so that it has enough information to obtain more features and patterns of the predicted target."}}