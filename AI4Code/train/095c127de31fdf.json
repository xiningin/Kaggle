{"cell_type":{"83c4341f":"code","1e8ebced":"code","b27e6b7c":"code","d240c4df":"code","cb457351":"code","73277448":"code","68c7e0d8":"code","418dd21b":"code","b793ec9f":"code","5f619934":"code","ac1e0e13":"code","5571a808":"code","9a24fa47":"code","178d21a1":"code","bd70ccfc":"code","641bfe3b":"code","835f2fc7":"code","115697c9":"code","b3476b60":"code","b1ea3edb":"code","a92fd213":"code","781c3351":"code","a953963a":"code","a5519138":"code","52c187ad":"code","e38e554c":"code","6b780227":"code","9a4b8cc5":"code","bb2cd0dd":"code","26cde5e7":"code","b311728d":"code","a4e977b3":"code","d0fe1279":"code","276bc69d":"code","7de663a0":"code","37707d0b":"code","6a4138b5":"code","859b5c28":"code","f0be3a33":"code","5e851970":"code","a7dcbebe":"code","327a02d7":"code","7fb05726":"code","572dfc3f":"code","34caf199":"code","c8ddecb6":"code","bb08b49a":"code","b37bcd7e":"code","e2f2d5c1":"code","6cbf11f5":"code","894e27bb":"code","cb81e648":"code","cf892717":"code","f1295061":"markdown","3c543086":"markdown","0b0f8447":"markdown","f02d6977":"markdown","061a5025":"markdown","6177d977":"markdown","af0a4d90":"markdown","a2c6a2d8":"markdown","3d939839":"markdown","e936d4e4":"markdown","f4a8b4e2":"markdown","4a18a646":"markdown","715aa526":"markdown","c1a926be":"markdown","547e69e6":"markdown","84529ab8":"markdown","225615a6":"markdown","b72d26cb":"markdown","c2fac9e8":"markdown","bcba1d34":"markdown","224080b9":"markdown","55ee40dc":"markdown","deabbb08":"markdown","9f418f65":"markdown","328fc53a":"markdown","a16d3c2a":"markdown","a27e5fa3":"markdown","8405f1de":"markdown","3dd14c29":"markdown","4404b917":"markdown","760e1fd3":"markdown","ec5f8ed2":"markdown","764db426":"markdown","a0b1be85":"markdown","e3cd2bff":"markdown","e8364382":"markdown","3cde0932":"markdown","06f5a5ac":"markdown"},"source":{"83c4341f":"!pip install feature-engine","1e8ebced":"# data manipulation\nimport pandas as pd\nimport numpy as np\nimport re\n\n# to make custom estimators\nfrom sklearn.base import BaseEstimator, TransformerMixin\nfrom sklearn.preprocessing import FunctionTransformer\n\n# to make pipelines\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.pipeline import make_pipeline\n\n# Model_Selection\nfrom sklearn.model_selection import train_test_split, cross_val_score, KFold, GridSearchCV\n\n# ML algorithms \nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestClassifier\n\n# correlation\nfrom sklearn.feature_selection import SelectKBest, f_classif, chi2\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\n# plot graphics\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\n# Feature engineer \nfrom feature_engine.selection import DropFeatures\nfrom feature_engine.encoding import OneHotEncoder\nfrom feature_engine.outliers import Winsorizer, ArbitraryOutlierCapper\nfrom feature_engine.imputation import (AddMissingIndicator,MeanMedianImputer, CategoricalImputer)\n","b27e6b7c":"#nice setup for graphics cause why not: pretty blue and another pretty blue\ncolors = ['#06344d', '#00b2ff']\nsns.set(palette = colors, font = 'Serif', style = 'white', \n        rc = {'axes.facecolor':'#f1f1f1', 'figure.facecolor':'#f1f1f1'})","d240c4df":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))","cb457351":"df = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\",index_col=0)\n\nx = df.drop('Survived',axis=1)\ny = df.Survived","73277448":"x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=0.3, random_state = 42)","68c7e0d8":"class Fill_na_transf(BaseEstimator, TransformerMixin):\n    \"\"\"Fills NA with fill_na value\"\"\"\n    \n    def __init__(self,fill_na):\n        self.fill_na = fill_na\n    \n    def fit(self, x:pd.DataFrame ,y:pd.Series=None):\n        return self\n    \n    def transform(self,x:pd.DataFrame):\n        x = x.copy()\n        x = x.replace(np.nan, self.fill_na)\n        return x\n\nclass Cabin_code(BaseEstimator, TransformerMixin):\n    \"\"\"Create column with first character of the first Cabin and how many cabins\"\"\"\n    \n    def __init__(self):\n        pass\n    def fit(self, x:pd.DataFrame ,y:pd.Series=None):\n        return self\n    \n    def transform(self,x:pd.DataFrame):\n        x = x.copy()\n        x['Cabin_code'] = x['Cabin'].apply(lambda x: x[0])\n        x['Cabin_Size'] = x['Cabin'].apply(lambda x: len(x.split(\" \")))\n        return x\n\nclass Mapper(BaseEstimator, TransformerMixin):\n    \"\"\"Create column with first character of the first Cabin and how many cabins\"\"\"\n    \n    def __init__(self,features:list,map_dict:dict):\n        \n        if not isinstance(features,list):\n            raise ValueError('Features should be a list')\n            \n        self.features = features\n        self.map_dict = map_dict\n        pass\n    \n    def fit(self, x:pd.DataFrame ,y:pd.Series=None):\n        return self\n    \n    def transform(self,x:pd.DataFrame):\n        x = x.copy()\n        for feature in self.features:\n            x[feature] = x[feature].map(self.map_dict)\n        return x\n    \n#dict for enconding \"Sex\"\nsex_map = {'male':1,\n          'female':0,\n          '?':-999}\n\nclass Get_title(BaseEstimator, TransformerMixin):\n    \"\"\"Create column with title from 'Name' \"\"\"\n    \n    def __init__(self):\n        pass\n    \n    def fit(self, x:pd.DataFrame ,y:pd.Series=None):\n        return self\n    \n    def transform(self,x:pd.DataFrame, y:pd.Series=None):\n        x = x.copy()\n        x['Title'] = x['Name'].apply(return_title)\n        return x\n\nclass Get_family(BaseEstimator, TransformerMixin):\n    \"\"\"Create column with title from 'Name' \"\"\"\n    \n    def __init__(self):\n        pass\n    \n    def fit(self, x:pd.DataFrame ,y:pd.Series=None):\n        return self\n    \n    def transform(self,x:pd.DataFrame, y:pd.Series=None):\n        x = x.copy()\n        x['Family'] = x['Name'].apply(return_family)\n        return x\n\ndef return_title(passenger):\n    line = passenger\n    if re.search('Mrs', line):\n        return 'Mrs'\n    elif re.search('Mr', line):\n        return 'Mr'\n    elif re.search('Miss', line):\n        return 'Miss'\n    elif re.search('Master', line):\n        return 'Master'\n    else:\n        return 'Other'\n\ndef return_family(passanger):\n    line = passanger\n    return line['Name'].iloc[0].split(',')[0]\n    \ndef corrige_type(df):\n    df=df.copy()\n    df['Pclass']=df['Pclass'].astype('int')\n    df['Sex']=df['Sex'].astype('')","418dd21b":"x_train.head(2)","b793ec9f":"x_train.isnull().sum().sort_values(ascending=False).head()","5f619934":"#basic pre processing \npipe_preproc = make_pipeline(\n                        Fill_na_transf(fill_na=\"?\"),\n                        Cabin_code(),\n                        Get_title(),\n                        Mapper(features=['Sex'],map_dict = sex_map),\n                        DropFeatures(features_to_drop=['Name','Ticket','Cabin']))","ac1e0e13":"#apply the pipeline transformations in the train dataset\nx_eda = pipe_preproc.fit_transform(x_train)","5571a808":"#apply the pipeline transformations in whole x (features) dataframe\nx1 = pipe_preproc.fit_transform(x)","9a24fa47":"x_eda.head(2)","178d21a1":"num_var = ['Pclass','Age','SibSp','Parch','Fare','Cabin_Size']\ncat_var = ['Sex','Cabin_code','Embarked','Title']\ntarget = ['Survived']","bd70ccfc":"x_eda.info()","641bfe3b":"x_eda[cat_var].nunique().sort_values(ascending=False).plot.bar(figsize=(12,5))","835f2fc7":"x_train.nunique()","115697c9":"#creating the plot \"frames\"\nfig, ax = plt.subplots(nrows = 1, ncols = 4, figsize = (15, 7), constrained_layout = True)\n\n#filling the frames with the bars\nfor i, col in enumerate(cat_var): \n    sns.histplot(data = x_eda, x = col, hue = y_train, ax = ax[i])","b3476b60":"plt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda, x = 'Sex', hue = y_train)\nplt.title('Var \"Sex\" distribuition')\nplt.show()","b1ea3edb":"plt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda, x = 'Cabin_code', hue = y_train)\nplt.title('Var \"Cabin_code\" distribuition')\nplt.show()","a92fd213":"plt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda, x = 'Embarked', hue = y_train)\nplt.title('Var \"Embarked\" distribuition')\nplt.show()","781c3351":"x_eda_emb = x_eda.copy()\nx_eda_emb['Embarked'] = x_eda_emb['Embarked'].replace('?', np.nan)\n\n#checking the correlation between pclass and fare\nsns.violinplot(x_eda_emb['Embarked'],x_eda[x_eda['Fare']<x_eda['Fare'].quantile(0.95)]['Fare'])\nplt.title('Violin plot: Embarked x Fare')\nplt.show()","a953963a":"plt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda, x = 'Title', hue = y_train)\nplt.title('Var \"Title\" distribuition')\nplt.show()","a5519138":"#creating the plot \"frames\"\nfig, ax = plt.subplots(nrows = 1, ncols = 6, figsize = (15, 7), constrained_layout = True)\nx_eda2 = x_eda.replace('?', -15)\n\nhist_num_vars = [x for x in num_var if x not in [\"Age\"]]\n#filling the frames with the bars\nfor i, col in enumerate(num_var): \n    sns.histplot(data = x_eda2, x = col, hue = y_train, ax = ax[i])","52c187ad":"plt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda, x = 'Pclass', hue = y_train)\nplt.title('Var \"Pclass\" distribuition')\nplt.show()","e38e554c":"plt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda, x = 'Fare', hue = y_train)\nplt.title('Var \"Fare\" distribuition')\nplt.show()","6b780227":"from feature_engine.outliers import ArbitraryOutlierCapper\n\ncapper = ArbitraryOutlierCapper(max_capping_dict={'Fare': 100})\nx_eda_fare = capper.fit_transform(x_eda)\n\nplt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda_fare, x = 'Fare', hue = y_train)\nplt.title('Var \"Fare\" distribuition')\nplt.show()","9a4b8cc5":"x_eda_age = x_eda.replace('?', -15)\n\nplt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda_age, x = 'Age', hue = y_train)\nplt.title('Var \"Age\" distribuition')\nplt.show()","bb2cd0dd":"x_eda[x_eda['Age']=='?'].iloc[:,2:3].join(y_train).groupby('Survived').count()","26cde5e7":"#creating the plot \"frames\"\nfig, ax = plt.subplots(nrows = 1, ncols = 2, figsize = (15, 7), constrained_layout = True)\n\n#filling the frames with the bars\nfor i, col in enumerate(['SibSp','Parch']): \n    sns.histplot(data = x_eda, x = col, hue = y_train, ax = ax[i])","b311728d":"plt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda, x = 'SibSp', hue = y_train)\nplt.title('Distribui\u00e7\u00e3o da var SibSp')\nplt.show","a4e977b3":"plt.subplots(figsize=(15,8))\nsns.histplot(data = x_eda, x = 'Parch', hue = y_train)\nplt.title('Distribui\u00e7\u00e3o da var Parch')\nplt.show","d0fe1279":"# passangers with 5 parent\/child on board\nx_train[x_train['Parch']==5].join(y_train)","276bc69d":"# passangers with 4 siblings grouped by \"Survived\"\nx_train[x_train['SibSp']==4].iloc[:,4:5].join(y_train).groupby(\"Survived\").count()","7de663a0":"plt.plot(x_train[['SibSp','Age']].groupby(\"SibSp\").mean())\nplt.title('Age mean for each value of SibSp')\nplt.xlabel('SibSp')\nplt.ylabel('Age mean')\nplt.show()","37707d0b":"plt.subplots(figsize=(15,8))\nsns.violinplot(x_train['SibSp'],x_train['Age'])\nplt.axhline(y=0)\nplt.axhline(y=16)\nplt.title('SibSp x Age violion plot - hlines for childhood')\nplt.xlabel('SibSp')\nplt.ylabel('Age')\nplt.show()","6a4138b5":"# Age mean for passangers with 4 siblings\nx_train[x_train['SibSp']==4]['Age'].mean()","859b5c28":"x_eda1= x_eda.copy()\nx_eda1['Fare'] =  x_eda1['Fare'].replace(0,1)\nx_eda1['Fare'] = np.log(x_eda1['Fare']) \n\nplt.subplots(figsize = (15, 7))\nsns.histplot(data = x_eda1, x = \"Fare\", hue = y_train)","f0be3a33":"def find_frequent_labels(df, var, rare_perc):\n    # function finds the labels that are shared by more than\n    # a certain % of the ocurrences in the dataset\n  \n    df = df.copy()\n    tmp = df.groupby(var)[var].count() \/ len(df)\n    return tmp[tmp > rare_perc].index","5e851970":"for var in ['Sex','Embarked', 'Cabin_code', 'Title','Pclass']:\n    # find the frequent categories\n    frequent_ls = find_frequent_labels(x_eda, var, 0.05)\n    print(var, frequent_ls)\n    print()","a7dcbebe":"sns.histplot(data = y_train)","327a02d7":"df.info()","7fb05726":"# we can see how much (%) of each column is missing \nfaltantes_percentual = (x_train.isnull().sum() \/ len(df.iloc[:,0])*100).sort_values(ascending=False)\nfaltantes_percentual","572dfc3f":"missing_feat = ['Cabin', 'Age', 'Embarked']\n(x_train[missing_feat].isnull().sum()\n    \/len(df.iloc[:,0])).sort_values(\n    ascending=False).plot.bar(figsize=(10, 4))\n\nplt.ylabel('Percentage of missing data')\nplt.title('% of missing data per variable')\nplt.axhline(y=0.5, color='red', linestyle='-')\nplt.show()","34caf199":"plt.rcParams['figure.figsize']=(15,8)\nfor var in ['Age','Fare']:\n    sns.boxplot(data=x_train, x=var)\n    plt.title(f'Boxplot of {var}')\n    plt.show()","c8ddecb6":"x_eda3 = x_eda.copy()\nx_eda3['Age'] = x_eda['Age'].replace('?', np.nan)\n\n# identifying quantile = 95%\nfor x in ['Age', 'Fare']:\n    print(x,x_eda3[x].quantile(0.95))","bb08b49a":"# quantiles approach\na = x_train[x_train['Age']>55].index\nb = x_train[x_train['Fare']>108.9].index\nc=[]\nfor x in a:\n    if x in b:\n        c.append(x)\nprint('outliers in Age and Fare at same time:',c)","b37bcd7e":"# 3 sigma limit\nage_upper_limit = x_train['Age'].mean() + 3*x_train['Age'].std()\nage_lower_limit = x_train['Age'].mean() - 3*x_train['Age'].std()\nprint('Age',age_upper_limit, age_lower_limit)\n\n# 3 sigma limit\nage_upper_limit = x_train['Fare'].mean() + 3*x_train['Fare'].std()\nage_lower_limit = x_train['Fare'].mean() - 3*x_train['Fare'].std()\nprint('Fare',age_upper_limit, age_lower_limit)","e2f2d5c1":"# make a copy to be manipulated\nx_eda_corr = x_eda.copy()\n# replace the missing marker \"?\" for NaN in Age\nx_eda_corr['Age'] = x_eda_corr['Age'].replace('?', np.nan)\n# transform column 'Age' into float \nx_eda_corr['Age'] = x_eda_corr['Age'].astype('float')\n\n#plot\nfig=plt.figure(figsize=(10,7))\naxis=sns.heatmap(x_eda_corr.corr(method='spearman'), annot=True, linewidths=3, square=True, cmap='Blues', fmt=\".0%\",)\nplt.title(\"Spearman's coef heatmap\")\nplt.show()","6cbf11f5":"#checking the correlation between pclass and fare\nsns.violinplot(x_eda['Pclass'],x_eda[x_eda['Fare']<x_eda['Fare'].quantile(0.95)]['Fare'])\nplt.title('Violin plot de Fare por Pclass')","894e27bb":"#checking the correlation between pclass and fare\nsns.violinplot(x_eda['Pclass'],x_eda['Fare'])","cb81e648":"#checking the correlation between pclass and fare\nsns.violinplot(x_eda['Title'],x_eda[x_eda['Fare']<x_eda['Fare'].quantile(0.95)]['Fare'])\nplt.title('Scatter: Title x Fare')\nplt.show()","cf892717":"#basic pre processing \npipe_2 = make_pipeline(\n                        MeanMedianImputer(imputation_method='mean', variables=['Age']),\n                        Fill_na_transf(fill_na='?'),\n                        Cabin_code(),\n                        Get_title(),\n                        Mapper(features=['Sex'],map_dict = sex_map),\n                        OneHotEncoder(top_categories = 3, variables=['Cabin_code','Title','Embarked']),\n                        DropFeatures(features_to_drop=['Name','Ticket','Cabin']))\n\nx_eda_ = pipe_2.fit_transform(x_train)\n\n# f-classif correlation\nalgoritmo = SelectKBest(score_func=f_classif, k=10)\nbest_k_features = algoritmo.fit_transform(x_eda_,y_train)\n\nscores_fclassif = pd.DataFrame(algoritmo.scores_,x_eda_.columns)\n\n#print results\nprint(scores_fclassif.sort_values(by=0, ascending=False).head(10))","f1295061":"Define features type:","3c543086":"## Understanding the columns","0b0f8447":"## Rare Labels","f02d6977":"Passangers with a lot of siblings most likely are children traveling in family. Let's check that assumption:","061a5025":"Setting all values over 100 to the max limit of 100:","6177d977":"A pipeline for preprocessing de data: \n\n1. filling missing data with \"?\"; \n2. create columns with the cabin code and size; \n3. create a column with the title in the name;\n4. Encode \"Sex\" to 1 for male and 0 for female;\n5. drop useless features.","af0a4d90":"# Custom Transformers","a2c6a2d8":"# Outliers","3d939839":"That seems to be true for passangers with 3 or more siblings.","e936d4e4":"Target is somewhat imbalanced.","f4a8b4e2":"That is confirmed and might explain why C has higher survival rate.","4a18a646":"How the Dataset looks like:","715aa526":"## F-classif correlation","c1a926be":"Children survived most. The fisrt bar to the left represents missing data. The missing data seems to carry predictive value.","547e69e6":"C show higher survival rate and S and Q show lower survival rate. Are the C port also richer, paying higher for their fares? \nLet's check it out:","84529ab8":"# Correla\u00e7\u00e3o","225615a6":"## Spearman correlation","b72d26cb":"### Target","c2fac9e8":"# Load Data","bcba1d34":" If you can read portuguese, i wrote an article about this EDA at: https:\/\/medium.com\/@mmansur\/mais-uma-an%C3%A1lise-do-titanic-ningu%C3%A9m-aguenta-mais-isso-pt-1-eda-4fa4d9e2944c","224080b9":"Passengers with more than 1 for SibSp and Parch seems to have higher survival rate.","55ee40dc":"In the set of data, the better the Pclass (1>2>3), higher the survival rate.","deabbb08":"It reinforces what Pclass suggest: the richer the passanger, lower is the death rate.","9f418f65":"Rare labels are classes with few unique occurences. Let's identify the classes responsible for more than 5% of all occurrences.","328fc53a":"### Categorical","a16d3c2a":"## Variables Distribution","a27e5fa3":"## Cardinality of Categorical Vars","8405f1de":"# Exploratory Data Analysis","3dd14c29":"#### Numerical Features","4404b917":"Male seems to be at higher risk of dieing.","760e1fd3":"Miss and Mrs, associated to women, have higher survival rate, which makes sense with 'Sex' distribution.","ec5f8ed2":"## Distribution transformation","764db426":"How many unique occurrences in each categorical feature: ","a0b1be85":"## Dealing with NaN and object type columns","e3cd2bff":"- `PassangerId` - numerical ID, works as an Index. Doesn't have value for the model we're going to built.\n- `Survived` - boolean var meaning (0 = did not survived, 1 = survived)\n- `Pclass` - travel class, being 1st class the most luxurious and expensive and 3rd class the most cheap\n- `Name` - passanger's names and names their relatives in parenthesis\n- `SibSp` - how many siblings the passanger had in titanic\n- `Parch` -  how many parents\/childs the passanger had on board\n- `Ticket` - ticket's code, doesn't have value for the model we're going to built.\n- `Fare` - how much the ticket cost\n- `Embarked` - Port of embarkation: C = Cherbourg, Q = Queenstown, S = Southampton ","e8364382":"Missing cabin code data seems to be related to higher death rate.","3cde0932":"Except from \"Age\", all the features have skewed distributions. Let's apply log transformation to Fare to make it more Gaussian-like.","06f5a5ac":"Count missing values:"}}