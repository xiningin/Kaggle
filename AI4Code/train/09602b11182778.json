{"cell_type":{"818caaf7":"code","b9cf7f30":"code","2a1ae9f9":"code","9283b73c":"code","c4769907":"code","f8531ff7":"code","73f380a6":"code","8309f2b9":"code","b384e3c1":"code","2c2dac10":"markdown","5501e664":"markdown","cd7949d5":"markdown"},"source":{"818caaf7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","b9cf7f30":"#get df\ndf = pd.read_csv('\/kaggle\/input\/orderbrushing\/order_brush_order.csv')\ndf[:2]","2a1ae9f9":"#get general idea of data\ndf.shopid.nunique(), df.orderid.nunique()","9283b73c":"#get overall concentrate rate\ndf_sum = df.groupby('shopid').agg({'userid':'nunique','orderid':'nunique'}).reset_index()\ndf_sum['concentrate_rate_est'] = df_sum['orderid']\/ df_sum['userid']","c4769907":"#filter out those with one transaction\ndf_sum_f1 = df_sum[df_sum.userid > 1]\n\n#filter out those with concentrate_rate_est == 1 (means each transaction have unique id)\ndf_sum_f2 = df_sum_f1[df_sum_f1.concentrate_rate_est > 1]\n\nlen(df_sum_f1), len(df_sum_f2)","f8531ff7":"#we have 3,659 shops that we can investigate further. \n#only get transaction for these shops\ndf_filter_1 = df[df.shopid.isin(df_sum_f2.shopid.unique())]\nlen(df_filter_1), df_filter_1.shopid.nunique()","73f380a6":"#function to get \nimport numpy as np\nimport tqdm\n\n#select shop with multiple transaction per hour\ndef multiple_tranc_perH(shop_transaction):\n    \n    #return df\n    return_df = pd.DataFrame()\n    \n    #add index - easier to remove duplicates\n    shop_transaction['index'] = shop_transaction.index\n    \n    #convert column to datetime\n    shop_transaction['event_time'] = pd.to_datetime(shop_transaction['event_time'])\n    \n    #order transaction by time\n    shop_transaction = shop_transaction.sort_values('event_time')\n    \n    \n    #populate value in time dif column\n    for i, item in enumerate(shop_transaction['event_time']):\n        \n        #processing, get ratio\n        if i == 0:\n            pass\n        else:\n            start_time = pd.to_datetime(shop_transaction['event_time'].iloc[i-1])\n            end_time = start_time +  np.timedelta64(1, 'h')\n            transc_perH = shop_transaction[(shop_transaction.event_time >= start_time) &\n                                          (shop_transaction.event_time <= end_time)]\n            \n            try:\n                ratio = transc_perH.orderid.nunique()\/transc_perH.userid.nunique()\n            except ZeroDivisionError:\n                ratio = 0\n\n            \n            if ratio >= 3:\n                print(start_time,end_time,ratio,transc_perH.orderid.nunique())\n                #add_start_time_col\n                transc_perH['start_time'] = start_time\n                transc_perH['ratio'] = ratio\n                return_df = pd.concat([return_df,transc_perH])\n            \n    return return_df\n\n","8309f2b9":"import tqdm\n\ntemp_df = pd.DataFrame()\nfor shops in tqdm.tqdm(df_filter_1.shopid.unique()):\n    print(shops)\n    shop_transaction = df_filter_1[df_filter_1.shopid == shops]\n\n    try:\n        sub_df = multiple_tranc_perH(shop_transaction)\n        temp_df = pd.concat([temp_df,sub_df])\n    except Exception as e:\n        print(e)\n        pass","b384e3c1":"#all events with order brushing\n#may contain duplicates - duplicates means all are same, except for start_time\ntemp_df[temp_df.shopid == 181009364]","2c2dac10":"# Order Brushing\n***\n- What is it? - Technique employed by seller to boost the item rating\/ seller\n- How to detect? - Concentrate rate(number of orders in an hour\/ number of unique buyers in an hour) > 3\n","5501e664":"### Loop, get shops with order_brushing","cd7949d5":"### Remove shops based on their overall transaction summary\n- Remove those with only one transaction\n- Remove those that has orderid\/userid ratio of 1 (means each transaction has unique user)"}}