{"cell_type":{"c482e0e4":"code","4637c492":"code","5b50f653":"code","cc044344":"code","f05c3d1c":"code","7f2ab063":"code","d44ddab8":"code","5906bac9":"code","4e8c78ae":"code","84ca0380":"code","a6ca5b5c":"code","3c85caf7":"code","a98ad166":"code","a5787c28":"code","461c620a":"code","2c1e8407":"code","f4b90dea":"code","fb69665e":"code","0bfac72f":"code","613d4c8e":"code","a0815293":"markdown","9bdd9912":"markdown","b1583884":"markdown","c926a1a7":"markdown","094347e1":"markdown","d4257a70":"markdown","08d59dbc":"markdown","ecfaf474":"markdown","e7cbae65":"markdown","61d449f8":"markdown","5d869824":"markdown","4e533526":"markdown"},"source":{"c482e0e4":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n\nsns.set_style(\"whitegrid\")\nplt.style.use(\"fivethirtyeight\")","4637c492":"USAhousing = pd.read_csv('\/kaggle\/input\/usa-housing\/USA_Housing.csv')\nUSAhousing.head()","5b50f653":"USAhousing.info()","cc044344":"USAhousing.describe()","f05c3d1c":"USAhousing.columns","7f2ab063":"sns.pairplot(USAhousing)","d44ddab8":"sns.distplot(USAhousing['Price'])","5906bac9":"sns.heatmap(USAhousing.corr(), annot=True)","4e8c78ae":"X = USAhousing[['Avg. Area Income', 'Avg. Area House Age', 'Avg. Area Number of Rooms',\n               'Avg. Area Number of Bedrooms', 'Area Population']]\ny = USAhousing['Price']","84ca0380":"from sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)","a6ca5b5c":"from sklearn import metrics\nfrom sklearn.model_selection import cross_val_score\n\ndef cross_val(model):\n    pred = cross_val_score(model, X, y, cv=10)\n    return pred.mean()\n\ndef print_evaluate(true, predicted):  \n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    print('MAE:', mae)\n    print('MSE:', mse)\n    print('RMSE:', rmse)\n    print('R2 Square', r2_square)\n    \ndef evaluate(true, predicted):\n    mae = metrics.mean_absolute_error(true, predicted)\n    mse = metrics.mean_squared_error(true, predicted)\n    rmse = np.sqrt(metrics.mean_squared_error(true, predicted))\n    r2_square = metrics.r2_score(true, predicted)\n    return mae, mse, rmse, r2_square","3c85caf7":"from sklearn.preprocessing import StandardScaler\nfrom sklearn.pipeline import Pipeline\n\npipeline = Pipeline([\n    ('std_scalar', StandardScaler())\n])\n\nX_train = pipeline.fit_transform(X_train)\nX_test = pipeline.transform(X_test)","a98ad166":"from sklearn.linear_model import LinearRegression\n\nlin_reg = LinearRegression(normalize=True)\nlin_reg.fit(X_train,y_train)","a5787c28":"# print the intercept\nprint(lin_reg.intercept_)","461c620a":"coeff_df = pd.DataFrame(lin_reg.coef_, X.columns, columns=['Coefficient'])\ncoeff_df","2c1e8407":"pred = lin_reg.predict(X_test)","f4b90dea":"plt.scatter(y_test, pred)","fb69665e":"sns.distplot((y_test - pred), bins=50);","0bfac72f":"test_pred = lin_reg.predict(X_test)\ntrain_pred = lin_reg.predict(X_train)\n\nprint('Test set evaluation:\\n_____________________________________')\nprint_evaluate(y_test, test_pred)\nprint('====================================')\nprint('Train set evaluation:\\n_____________________________________')\nprint_evaluate(y_train, train_pred)","613d4c8e":"results_df = pd.DataFrame(data=[[\"Linear Regression\", *evaluate(y_test, test_pred) , cross_val(LinearRegression())]], \n                          columns=['Model', 'MAE', 'MSE', 'RMSE', 'R2 Square', \"Cross Validation\"])\nresults_df","a0815293":"## Predictions from our Model\n\nLet's grab predictions off our test set and see how well it did!","9bdd9912":"## Training a Linear Regression Model\n\nLet's now begin to train out regression model! We will need to first split up our data into an X array that contains the features to train on, and a y array with the target variable, in this case the Price column. We will toss out the Address column because it only has text info that the linear regression model can't use.\n\n### X and y arrays","b1583884":"# Exploratory Data Analysis (EDA)\n\nLet's create some simple plots to check out the data!","c926a1a7":"## Model Evaluation\n\nLet's evaluate the model by checking out it's coefficients and how we can interpret them.","094347e1":"# 1. Linear Regression","d4257a70":"# Import Libraries","08d59dbc":"Interpreting the coefficients:\n\n- Holding all other features fixed, a 1 unit increase in **Avg. Area Income** is associated with an **increase of \\$21.52**.\n- Holding all other features fixed, a 1 unit increase in **Avg. Area House Age** is associated with an **increase of \\$164883.28**.\n- Holding all other features fixed, a 1 unit increase in **Avg. Area Number of Rooms** is associated with an **increase of \\$122368.67**.\n- Holding all other features fixed, a 1 unit increase in **Avg. Area Number of Bedrooms** is associated with an **increase of \\$2233.80**.\n- Holding all other features fixed, a 1 unit increase in **Area Population** is associated with an **increase of \\$15.15**.\n\nDoes this make sense? Probably not because I made up this data.","ecfaf474":"**Residual Histogram**","e7cbae65":"## Regression Evaluation Metrics\n\n\nHere are three common evaluation metrics for regression problems:\n\n**Mean Absolute Error** (MAE) is the mean of the absolute value of the errors:\n\n$$\\frac 1n\\sum_{i=1}^n|y_i-\\hat{y}_i|$$\n\n**Mean Squared Error** (MSE) is the mean of the squared errors:\n\n$$\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2$$\n\n**Root Mean Squared Error** (RMSE) is the square root of the mean of the squared errors:\n\n$$\\sqrt{\\frac 1n\\sum_{i=1}^n(y_i-\\hat{y}_i)^2}$$\n\nComparing these metrics:\n\n- **MAE** is the easiest to understand, because it's the average error.\n- **MSE** is more popular than MAE, because MSE \"punishes\" larger errors, which tends to be useful in the real world.\n- **RMSE** is even more popular than MSE, because RMSE is interpretable in the \"y\" units.\n\nAll of these are **loss functions**, because we want to minimize them.","61d449f8":"# Preparing Data For Linear Regression\nLinear regression is been studied at great length, and there is a lot of literature on how your data must be structured to make best use of the model.\n\nAs such, there is a lot of sophistication when talking about these requirements and expectations which can be intimidating. In practice, you can uses these rules more as rules of thumb when using Ordinary Least Squares Regression, the most common implementation of linear regression.\n\nTry different preparations of your data using these heuristics and see what works best for your problem.\n\n- **Linear Assumption.** Linear regression assumes that the relationship between your input and output is linear. It does not support anything else. This may be obvious, but it is good to remember when you have a lot of attributes. You may need to transform data to make the relationship linear (e.g. log transform for an exponential relationship).\n- **Remove Noise.** Linear regression assumes that your input and output variables are not noisy. Consider using data cleaning operations that let you better expose and clarify the signal in your data. This is most important for the output variable and you want to remove outliers in the output variable (y) if possible.\n- **Remove Collinearity.** Linear regression will over-fit your data when you have highly correlated input variables. Consider calculating pairwise correlations for your input data and removing the most correlated.\n- **Gaussian Distributions.** Linear regression will make more reliable predictions if your input and output variables have a Gaussian distribution. You may get some benefit using transforms (e.g. log or BoxCox) on you variables to make their distribution more Gaussian looking.\n- **Rescale Inputs:** Linear regression will often make more reliable predictions if you rescale input variables using standardization or normalization.","5d869824":"### Check out the Data","4e533526":"## Train Test Split\n\nNow let's split the data into a training set and a testing set. We will train out model on the training set and then use the test set to evaluate the model."}}