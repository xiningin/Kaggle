{"cell_type":{"4ee33879":"code","f0f2a78d":"code","75e706e6":"code","47c0bd36":"code","9d5e5d83":"code","5f8062b0":"code","0b6fab23":"code","e29a8873":"code","bfa0d2f1":"code","8b8abc18":"markdown","a636faf8":"markdown","e35e98c0":"markdown","ed074019":"markdown","7f4acc36":"markdown","67a76cda":"markdown","24e78ce1":"markdown","b3713fd3":"markdown","b868e2d9":"markdown","fc334bfc":"markdown","dac32206":"markdown","7f3b71db":"markdown","c0311ec7":"markdown","27fcccd3":"markdown","9ee1495e":"markdown","74d9d78f":"markdown","eb85e408":"markdown"},"source":{"4ee33879":"# Including usual required libraries\nimport pandas as pd\nimport numpy as np\nimport sys\nimport matplotlib.pyplot as plt\nfrom itertools import combinations, groupby\nfrom collections import Counter\nfrom IPython.display import display","f0f2a78d":"# Read data set from CSV file\ndata = pd.read_csv('..\/input\/BreadBasket_DMS.csv')\n# Initial snapshot\ndisplay(data.head(10))","75e706e6":"items = data['Item'].value_counts().index\nitem_frequency = data['Item'].value_counts().values\nplt.figure(figsize=(12,6))\nplt.xlabel('Items', fontsize='15')\nplt.ylabel('Frequency', fontsize='15')\nplt.title('Top 10 Selling Items', fontsize='15')\nplt.bar(items[:10],item_frequency[:10], width = 0.7, color=\"gray\",linewidth=0.4)\nplt.show()","47c0bd36":"#### A. Helper functions to the main association rules function #### \n# Returns frequency counts for items and item pairs\ndef freq(iterable):\n    if type(iterable) == pd.core.series.Series:\n        return iterable.value_counts().rename(\"freq\")\n    else: \n        return pd.Series(Counter(iterable)).rename(\"freq\")\n\n    \n# Returns number of unique orders\ndef order_count(order_item):\n    return len(set(order_item.index))\n\n\n# Returns generator that yields item pairs, one at a time\ndef get_item_pairs(order_item):\n    order_item = order_item.reset_index().as_matrix()\n    for order_id, order_object in groupby(order_item, lambda x: x[0]):\n        item_list = [item[1] for item in order_object]\n              \n        for item_pair in combinations(item_list, 2):\n            yield item_pair\n            \n\n# Returns frequency and support associated with item\ndef merge_item_stats(item_pairs, item_stats):\n    return (item_pairs\n                .merge(item_stats.rename(columns={'freq': 'freqA', 'support': 'supportA'}), left_on='item_A', right_index=True)\n                .merge(item_stats.rename(columns={'freq': 'freqB', 'support': 'supportB'}), left_on='item_B', right_index=True))\n\n\n# Returns name associated with item\ndef merge_item_name(rules, item_name):\n    columns = ['itemA','itemB','freqAB','supportAB','freqA','supportA','freqB','supportB', \n               'confidenceAtoB','confidenceBtoA','lift']\n    rules = (rules\n                .merge(item_name.rename(columns={'item_name': 'itemA'}), left_on='item_A', right_on='item_id')\n                .merge(item_name.rename(columns={'item_name': 'itemB'}), left_on='item_B', right_on='item_id'))\n    return rules[columns]","9d5e5d83":"#### B. Association rules function ####\ndef association_rules(order_item, min_support):\n\n    print(\"Starting order_item: {:22d}\".format(len(order_item)))\n\n\n    # Calculate item frequency and support\n    item_stats             = freq(order_item).to_frame(\"freq\")\n    item_stats['support']  = item_stats['freq'] \/ order_count(order_item)\n\n\n    # Filter from order_item items below min support \n    qualifying_items       = item_stats[item_stats['support'] >= min_support].index\n    order_item             = order_item[order_item.isin(qualifying_items)]\n\n    print(\"Items with support >= {}: {:15d}\".format(min_support, len(qualifying_items)))\n    print(\"Remaining order_item: {:21d}\".format(len(order_item)))\n\n\n    # Filter from order_item orders with less than 2 items\n    order_size             = freq(order_item.index)\n    qualifying_orders      = order_size[order_size >= 2].index\n    order_item             = order_item[order_item.index.isin(qualifying_orders)]\n\n    print(\"Remaining orders with 2+ items: {:11d}\".format(len(qualifying_orders)))\n    print(\"Remaining order_item: {:21d}\".format(len(order_item)))\n\n\n    # Recalculate item frequency and support\n    item_stats             = freq(order_item).to_frame(\"freq\")\n    item_stats['support']  = item_stats['freq'] \/ order_count(order_item)\n\n\n    # Get item pairs generator\n    item_pair_gen          = get_item_pairs(order_item)\n\n\n    # Calculate item pair frequency and support\n    item_pairs              = freq(item_pair_gen).to_frame(\"freqAB\")\n    item_pairs['supportAB'] = item_pairs['freqAB'] \/ len(qualifying_orders)\n\n    print(\"Item pairs: {:31d}\".format(len(item_pairs)))\n\n\n    # Filter from item_pairs those below min support\n    item_pairs              = item_pairs[item_pairs['supportAB'] >= min_support]\n\n    print(\"Item pairs with support >= {}: {:10d}\\n\".format(min_support, len(item_pairs)))\n\n\n    # Create table of association rules and compute relevant metrics\n    item_pairs = item_pairs.reset_index().rename(columns={'level_0': 'item_A', 'level_1': 'item_B'})\n    item_pairs = merge_item_stats(item_pairs, item_stats)\n    \n    item_pairs['confidenceAtoB'] = item_pairs['supportAB'] \/ item_pairs['supportA']\n    item_pairs['confidenceBtoA'] = item_pairs['supportAB'] \/ item_pairs['supportB']\n    item_pairs['lift']           = item_pairs['supportAB'] \/ (item_pairs['supportA'] * item_pairs['supportB'])\n    \n    \n    # Return association rules sorted by lift in descending order\n    return item_pairs.sort_values('lift', ascending=False)","5f8062b0":"#Transforming original dataframe into the expected format: Series\norders_series = data.set_index('Transaction')['Item']\n#Display series as dataframe for cosmetic purposes\ndisplay(pd.DataFrame(orders_series.head(10))) ","0b6fab23":"#Generates rules from the itemsets that meet the minium threshold\nrules = association_rules(orders_series, 0.01)","e29a8873":"#Show output sorted by lift\ndisplay(rules.head(5))","bfa0d2f1":"display(rules.sort_values('confidenceBtoA', ascending=False).head(10))","8b8abc18":"### Measures of association:\nAfter our item sets are generated we have to determine which associations are strong and which ones are weak. (Again if you would like to read in more detail I about the measure [Click Here](http:\/\/michael.hahsler.net\/research\/association_rules\/measures.html#)[3]:\n\n**Support**: This determines the probability of an item-set by dividing the item-set occurrences over the total number of qualifying orders (orders with 2 or more transactions in them). Therefore, Support is the probability of an item-set occurring in transactions which have more than 2 items and it can be expressed as follows: Support(X and Y) = P( X \u2229 Y )\n\n**Confidence**: Confidence goes a step further in and expresses the probability of having an item X given that Y was already purchased: P( Y | X ) and is calculated as follows: Conf( X -> Y) = supp(X - > Y)\/supp(X) = P( Y | X ). Because P( Y | X ) does not imply P( X | Y ) then the lift metric needs to be introduced.\n\n**Lift**:  Lift allowes us to quantify the relationship between  P( Y | X ) and P( X | Y ) as follows: \n\nLift(X \u21d2 Y ) = lift( Y \u21d2 X ) = conf( X \u21d2 Y )\/supp( Y ) = conf( Y \u21d2 X )\/supp( X ) = P( X \u2229 Y )\/P( X )*P( Y ) \n\nIf Lift equal or greater than 1,  items are said to be compliments.[3]\n\n\n\n","a636faf8":"### Business insight?\nRight!  Before we implement the algorithm just for the sake of showing off our skills, what is our goal? As discussed previously we are here to determine up-sell opportunities. Let's start with some general questions as a framework: What sort of relationships do we wish to discover? and then, naturally: how would discovering such relationships help the business owner's bottom line? for now, let's keep these in the back of our mind.\n\nLet's ask something little more specific, shall we? \n\n*Can we get rid of a product 'X' because it is sold infrequently?* If the business owner wishes to get rid of a product in order to save any cost and overhead associated with it but unknowingly is getting rid of a product that is part of an item set 'X' and 'Y' where both X and Y are complements, it might not be as straightforward since it may impact other products.","e35e98c0":"### **Content**:\n1. MBA: Market Basket Analysis\n1. Business insight?\n1. Data Exploration\n1. Input Dataset\n1. What does the data look like?\n1. Association Rule Mining\n1. Apriori\n1. Measures of association\n1. Data trasnformation \n1. Data Mining\n1. Discoveries and Interpretation:\n1. References","ed074019":"### **Motivation**:\n\nI hope that together, we can learn the basics of association rule mining through this implementation of the apriori algorithm. Additionally, I will make this analysis as business oriented as possible so that we can potentially discover business insights hidden within the data.","7f4acc36":" ### Finding our candidate itemsets: Apriori algorithm\n Quick explanation: The algorithm is used to generate candidate that we will evaluate later on. The apriori approach is used to iterate through the items and find all the frequent itemsets that meet your standard of frequent.\n \n Not so quick explanation: This 2 itemset implementation using python generators was done by 'datath\u00e8que' and you can find more about it [here](https:\/\/www.kaggle.com\/datatheque\/association-rules-mining-market-basket-analysis)","67a76cda":"### Data Exploration : \nLet's do an initial exploration to see what the data looks like and if we can think of some rules that might be intuitive. After all, if we were to analyze McDonald's transactional data, would you be thrilled to find out that burgers are related to fries?","24e78ce1":"### Market Basket Analysis (MBA)\n\nIn the retail sector, this analysis is used to discover patterns and relationships within transactions and transaction **items-sets** (Items frequently bought together).  From all the sources I have read online, IBM puts it best:\n\n> \"Market Basket Analysis is used to increase marketing effectiveness and to improve cross-sell and up-sell opportunities by making the right offer to the right customer. For a retailer, good promotions translate into increased revenue and profits. The objectives of the market basket analysis models are to identify the next product that the customer might be interested to purchase or to browse.\"  [Learn more][1](https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSCJHT_1.0.0\/com.ibm.swg.ba.cognos.pci_oth.1.0.0.doc\/c_pci_retail_mba.html)\n\nThe reason I like this explanation is that the intent of running the analysis is clear: \"to improve cross-sell and up-sell opportunities. With this specific goal in mind, we can ask the right questions, which is what drives insight.\n","b3713fd3":"#### References\n1. [1] Market Basket Analysis URL: https:\/\/www.ibm.com\/support\/knowledgecenter\/en\/SSCJHT_1.0.0\/com.ibm.swg.ba.cognos.pci_oth.1.0.0.doc\/c_pci_retail_mba.html\n1. [2] Association Rule Mining\/Market Basket Analysis - URL: https:\/\/www.kaggle.com\/datatheque\/association-rules-mining-market-basket-analysis\n1. [3] Michael Hahsler, A Probabilistic Comparison of Commonly Used Interest Measures for Association Rules, 2015, URL: http:\/\/michael.hahsler.net\/research\/association_rules\/measures.html","b868e2d9":"### What does the data look like?\nWhat is the frequency of the top selling items?","fc334bfc":"### Discoveries and Interpretation:\nAs we would expect there are several itemsets that contain the frequently sold item. However, note that these do not have a lift greater than 1 (except for coffee and toast). We can interpret this as follows:\n\nItemsets in the form {'Coffee', ' X ' }: Most of these items have a large amount of 'confidenceBtoA' or in other words, given that a customer has bought item X there is a high probability that a customer would buy coffee as well.  But this is not true the other way around. Buying coffee does not imply buying any other item as 'confidanceAtoB' is usually less than 0.1. \n\nPotential business solution:  There is a simple potential solution to this problem, simply at the point of sale, for anyone buying coffee and not buying anything else the bakery may want to offer an incentive or promotion to get a secondary item, preferably an item that already has relatively high 'confidanceAtoB' which indicates it is relatively more frequent than others, therefore, increasing the effectiveness of the promotion.\n\nItemsets with lift greater than 1: I personally find these very interesting. {Hot chocolate, Cookies}, {Sandwhich, Sandwhich}, {Hot Chocolate, Cake}, {Coffee, Toast}. Bundling these itemsets together in the form of a combo with a discount could be very useful for the business owner in my opinion. The only variation I would suggest to this strategy would be in the case of {Sandwhich, Sandwhich}. I would suggest pairing these two items together with beverages since it seems reasonable that the customers that buy this item set would also be a little thirsty. \n\nLet me know how you would implement these discoveries in the comment section.\n\nCamilo,\n","dac32206":"### Input Dataset","7f3b71db":"### Data Transformation:\nOur program is expecting the data in the type of a series. A series is basically a single column dataframe containing the transaction Item indexed by the transaction number. We can accomplish that as follows:","c0311ec7":"#### Displaying output data: Sorted by lift\n","27fcccd3":"### Data Mining:","9ee1495e":"#### Sorted by confidenceBtoA:","74d9d78f":"### Association Rule Mining (ARM)\n An association rule is an implication expression of the form X\u2192Y, where X and Y are disjoint itemsets [1]. \n Association rules can be created with any number *n* of *K* Items. However, in this particular application due to the size of the transactions and quantity of significant items, we will consider an itemsets of size 2.","eb85e408":" # Market Basket Analysis  - Association Rule Mining (ARM) - Apriori"}}