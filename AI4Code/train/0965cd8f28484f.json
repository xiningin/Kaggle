{"cell_type":{"6ac35406":"code","49c20385":"code","a85754ac":"code","157682b2":"code","756aa961":"code","eafccc98":"code","284efa15":"code","e066f1d4":"code","0746d12d":"code","463fd05a":"code","931f8bc7":"code","285331d0":"code","a6a2bbd6":"code","1b207569":"code","d03ec481":"code","542b2cff":"code","d26bae4c":"code","010604dc":"code","6ed502c0":"code","362a728a":"code","18d86015":"code","9c2cfd80":"code","7dc1c51d":"code","f22c55f9":"code","f8abac75":"code","b3b51c5b":"code","13929be5":"code","2316f75b":"code","f3cda27c":"code","60474708":"code","b34f7491":"code","e5912a25":"code","1228dcc9":"code","12b07835":"code","a7acc129":"code","366faf3f":"code","3b81d319":"code","74ed2e59":"code","4128f135":"code","ad44d580":"code","3917ba1a":"code","657f65aa":"markdown","4063c7d6":"markdown","51e43852":"markdown","e9d73f12":"markdown","92101fa9":"markdown"},"source":{"6ac35406":"import os\nimport shutil\nfrom random import shuffle","49c20385":"BASE_DIR = '..\/input\/basicshapes\/shapes\/shapes'\nshapes= os.listdir(BASE_DIR)\nshapes","a85754ac":"#Create the paths of train set and test set\nTRAIN_DIR = '.\/train_set'\nTEST_DIR = '.\/test_set'","157682b2":"#Create a dictionary with the file names for each directory \"shape\" (under \"shapes\" directory)\nshapes_dict = {shape:os.listdir(os.path.join(BASE_DIR,shape))for shape in shapes}\n","756aa961":"#Shuffle the filenames for each shape\nfor item in shapes_dict:\n  shuffle(shapes_dict[item])","eafccc98":"if os.path.exists(TRAIN_DIR):\n    print(\"pass\")\nelse:\n    for shape, list_filenames in shapes_dict.items():\n        os.makedirs(os.path.join(TRAIN_DIR,shape))\n        os.makedirs(os.path.join(TEST_DIR, shape))\n        for item in list_filenames[:80]:\n            shutil.copy(os.path.join(BASE_DIR,shape,item), os.path.join(TRAIN_DIR,shape,item))\n        for item in list_filenames[80:]:\n            shutil.copy(os.path.join(BASE_DIR,shape,item), os.path.join(TEST_DIR,shape,item))\n    ","284efa15":"#Verification \nfor shape in shapes:\n  print(\"The number of imagefiles in the original sub directory of {} is: {}\".format(shape,len(os.listdir(os.path.join(BASE_DIR,shape)))))\n  print(\"The number of imagefiles in the sub train set of {} is: {}\".format(shape, len(os.listdir(os.path.join(TRAIN_DIR,shape)))))\n  print(\"The number of imagefiles in the sub test set of {} is: {}\".format(shape, len(os.listdir(os.path.join(TEST_DIR,shape)))))\n  print(\"*******************************************************************\")","e066f1d4":"import matplotlib.pyplot as plt\nfrom matplotlib.image import imread\nimport numpy as np\nimport pandas as pd","0746d12d":"# Visualization of some images from trai_set(Circles)\nimages_circles = os.listdir(os.path.join(TRAIN_DIR,'circles'))\nrandom_circles = [np.random.choice(images_circles) for i in range(36)]\n%matplotlib inline\nplt.figure(figsize=(20,10))\n\nfor i in range(36):\n  plt.subplot(6,6,i+1)\n  img= imread(os.path.join(TRAIN_DIR,'circles',random_circles[i]))\n  plt.imshow(img)\nplt.tight_layout()","463fd05a":"#Visualization of some images from train set (Squares)\nimages_squares = os.listdir(os.path.join(TRAIN_DIR,'squares'))\nrandom_squares = [np.random.choice(images_squares)for i in range(36)]\nplt.figure(figsize=(20,10))\nfor i in range(36):\n  plt.subplot(6,6,i+1)\n  img= imread(os.path.join(TRAIN_DIR,'squares',random_squares[i]))\n  plt.imshow(img)\nplt.tight_layout()","931f8bc7":"#Visualization of some images from train set (triangles)\nimages_triangles = os.listdir(os.path.join(TRAIN_DIR,'triangles'))\nrandom_triangles = [np.random.choice(images_triangles)for i in range(36)]\nplt.figure(figsize=(20,10))\nfor i in range(36):\n  plt.subplot(6,6,i+1)\n  img= imread(os.path.join(TRAIN_DIR,'triangles',random_triangles[i]))\n  plt.imshow(img)\nplt.tight_layout()","285331d0":"#Checking the shape\n\nimg_c_shapes1=[]\nimg_c_shapes2=[]\nfor image in (images_circles):\n  img= imread(os.path.join(TRAIN_DIR, 'circles', image))\n  shape1= img.shape[0]\n  shape2= img.shape[1]\n  img_c_shapes1.append(shape1)\n  img_c_shapes2.append(shape2)\nprint((int(np.mean(img_c_shapes1)), int(np.mean(img_c_shapes2))))\n\nimg_s_shapes1=[]\nimg_s_shapes2=[]\nfor image in (images_squares):\n  img= imread(os.path.join(TRAIN_DIR, 'squares', image))\n  shape1= img.shape[0]\n  shape2= img.shape[1]\n  img_s_shapes1.append(shape1)\n  img_s_shapes2.append(shape2)\nprint((int(np.mean(img_s_shapes1)), int(np.mean(img_s_shapes2))))\n\nimg_t_shapes1=[]\nimg_t_shapes2=[]\nfor image in (images_triangles):\n  img= imread(os.path.join(TRAIN_DIR,'triangles', image))\n  shape1= img.shape[0]\n  shape2= img.shape[1]\n  img_t_shapes1.append(shape1)\n  img_t_shapes2.append(shape2)\nprint((int(np.mean(img_t_shapes1)), int(np.mean(img_t_shapes2))))\n","a6a2bbd6":"#Checking the number of channels\n\nimage= imread(os.path.join(TRAIN_DIR, 'circles', random_circles[2]))\nimage.shape\n","1b207569":"#Checking the pixels values\nfrom keras.preprocessing import image\nimg_path= os.path.join(TRAIN_DIR, 'circles',random_circles[2])\nimg_gen= image.load_img(img_path)\nimg_tensor= image.img_to_array(img_gen)\nimg_tensor","d03ec481":"from keras import models\nfrom keras.models import Sequential\nfrom keras.layers import Dense, Conv2D, MaxPooling2D,Dropout,Flatten\nfrom keras.callbacks import ModelCheckpoint\nfrom keras.preprocessing.image import ImageDataGenerator\nfrom keras.preprocessing import image\nimport tensorflow as tf\n","542b2cff":"# Model initialization\nmodel= Sequential()\n\n# 1st Convolution\nmodel.add(Conv2D(filters= 32, kernel_size=(3,3), input_shape=(28,28,3), activation=tf.nn.leaky_relu))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\n\n# Second Convolution\nmodel.add(Conv2D(filters = 32, kernel_size=(3,3), activation=tf.nn.leaky_relu))\nmodel.add(MaxPooling2D(pool_size=(2,2)))\nmodel.add(Dropout(rate=0.5))\n\n\n#Flatten\nmodel.add(Flatten())\n\n#Add fully connected layers\nmodel.add(Dense(units=512,activation = tf.nn.leaky_relu))\nmodel.add(Dropout(rate=0.5))\nmodel.add(Dense(units=256, activation= tf.nn.leaky_relu))\nmodel.add(Dropout(rate=0.5))\n#Add output layer\n\nmodel.add(Dense(units=3, activation=\"softmax\"))\n","d26bae4c":"model.summary()","010604dc":"# compile the model\nmodel.compile(optimizer=\"adam\",\n              loss=\"categorical_crossentropy\",\n              metrics= [\"accuracy\"])","6ed502c0":"#Create the generators so that the model could read the images from the directories\n\ntrain_datagen= ImageDataGenerator(rescale= 1\/.255)\ntest_datagen= ImageDataGenerator(rescale= 1\/.255)\n\ntrain_set= train_datagen.flow_from_directory(TRAIN_DIR,\n                                            batch_size=32,\n                                            target_size=(28,28),\n                                            class_mode= 'categorical')\ntest_set = test_datagen.flow_from_directory(TEST_DIR,\n                                           batch_size=8,\n                                           target_size= (28,28),\n                                           class_mode= 'categorical')","362a728a":"#Using the callback ModelCheckpoint to store the best weights \ncheckpointer= ModelCheckpoint(filepath= \".\/best_weights.hdf5\",\n                             verbose=1,\n                             monitor=\"val_accuracy\",\n                             save_best_only= True)\n","18d86015":"history= model.fit(train_set,\n                   epochs=100,\n                   batch_size= 40,\n                   validation_data= test_set,\n                   validation_batch_size=10,\n                   callbacks=[checkpointer])","9c2cfd80":"df= pd.DataFrame(history.history)\ndf_loss= df[[\"loss\",\"val_loss\"]]\ndf_accuracy= df[[\"accuracy\",\"val_accuracy\"]]","7dc1c51d":"df_loss.plot()","f22c55f9":"df_accuracy.plot()","f8abac75":"#Charging the model with the best weights\nmodel.load_weights('.\/best_weights.hdf5')\n\n#store the best model for later use \nmodel.save('.\/model_shapes_cnn.h5')","b3b51c5b":"results = model.evaluate(test_set, verbose=0)\nprint(\"Loss: {:.2f}\".format(results[0]))\nprint(\"Accuracy: {:.0f}%\".format(results[1]*100))\n","13929be5":"#Choose a 1st random image from test_set (triangles class)\ntest_samples_triangles = os.listdir(os.path.join(TEST_DIR,'triangles'))\nimg_path= os.path.join(TEST_DIR,'triangles',test_samples_triangles[2])\n\n#transforming the image (like our generator did)\n#using keras.preprocessing.image (already (above): form keras.preprocessing import image)\nimage_gen= image.load_img(img_path)\nimage_tensor= image.img_to_array(image_gen)\nimage_tensor","2316f75b":"print(image_tensor.shape)\n","f3cda27c":"#for predictions we should have as input, an image with 4 dimensions (1,28,28,3),\n#as the input of the trained model (the images generated by the generators)\nimage_tensor= np.expand_dims(image_tensor,axis=0)\n#we, also, should rescale the image\nimage_tensor= image_tensor\/255","60474708":"plt.imshow(image_tensor[0])","b34f7491":"#Choose a 2nd random image from test_set (circles class)\ntest_samples_circles = os.listdir(os.path.join(TEST_DIR,'circles'))\nimg_path2= os.path.join(TEST_DIR,'circles',test_samples_circles[4])\nimage_gen_two= image.load_img(img_path2)\n\n#visualization\n\nimage_tensor_2= image.img_to_array(image_gen_two)\nimage_tensor_2= np.expand_dims(image_tensor_2,axis=0)\nimage_tensor_2= image_tensor_2\/255\nplt.imshow(image_tensor_2[0]);","e5912a25":"#Choose a 3rd random image from test_set (squares class)\ntest_samples_squares = os.listdir(os.path.join(TEST_DIR,'squares'))\nimg_path3= os.path.join(TEST_DIR,'squares',test_samples_squares[3])\nimage_gen_three= image.load_img(img_path3)\n\n#visualization\nimage_tensor_3= image.img_to_array(image_gen_three)\nimage_tensor_3= np.expand_dims(image_tensor_3, axis=0)\nimage_tensor_3 = image_tensor_3\/255\nplt.imshow(image_tensor_3[0]); #plt.imshow (accepts 3 dimensions (28,28,3))","1228dcc9":"#Prediction\n\nx1= image.img_to_array(image_gen)\nx1= np.expand_dims(x1, axis=0)\nx1= x1\/.255\n\nx2= image.img_to_array(image_gen_two)\nx2= np.expand_dims(x2,axis=0)\nx2=x2\/.255\n\nx3= image.img_to_array(image_gen_three)\nx3 = np.expand_dims(x3,axis=0)\nx3= x3\/255\n\nimages= np.vstack([x1,x2,x3])\nclasses= np.argmax(model.predict(images, batch_size=10),axis=1)","12b07835":"print(\"the predictions for the random : triangle(class 2),\\\ncircle(class 0) and square(class 1) from test_set are: \\n {} \".format(classes))","a7acc129":"from keras.models import Model\n\n#extract the outputs of the 5 top layers (before Flatten)\nlayers_outputs= [layer.output for layer in model.layers[:5]]\n\n#create a model that retuns these outputs, given the input of the model\nactivation_model= Model(inputs= model.input, outputs= layers_outputs)","366faf3f":"#we will use the three random images (that we already used for predictions): see step4\n#to extract the intermediate activations\nactivations_predicted= activation_model.predict(image_tensor)","3b81d319":"#extract the first layer (Recall: Conv2D,using 32 filters, padding= \"valid\", input_size=-28,28,3)\nactivation_first_layer=activations_predicted[0]\n#we notice that, effectively, because of the defaultpadding \"valid\", the size becomes (26,26),\n#and 32 channels (filters)\nprint(activation_first_layer.shape)","74ed2e59":"#we will visualize for example the 5th channel \"after applying the learned 5th filter\" on the \n#input image\n\nplt.matshow(activation_first_layer[0,:,:,5]);","4128f135":"#we will visualize 2 channels of the 1st activation\nfor i in range (7,9):\n    plt.matshow(activation_first_layer[0,:,:,i])","ad44d580":"#visualization of each channel in each intermediate activation (of the 5 top layers)\nlayer_names= []\n\nfor layer in model.layers[:3]:\n    layer_names.append(layer.name)\nprint(layer_names)","3917ba1a":"images_per_row = 12\n\nfor layer_name, layer_activation in zip(layer_names, activations_predicted): \n    n_features = layer_activation.shape[3] \n    size = layer_activation.shape[1] \n    n_cols = n_features \/\/ images_per_row \n    display_grid = np.zeros((size * n_cols, images_per_row * size))\n    for col in range(n_cols): \n        for row in range(images_per_row):\n            channel_image = layer_activation[0,\n                                             :, :,\n                                             col * images_per_row + row]\n            channel_image -= channel_image.mean() \n            channel_image \/= channel_image.std()\n            channel_image *= 64\n            channel_image += 128\n            channel_image = np.clip(channel_image, 0, 255).astype('uint8')\n            display_grid[col * size : (col + 1) * size, \n                         row * size : (row + 1) * size] = channel_image\n    scale = 1. \/ size\n    plt.figure(figsize=(scale * display_grid.shape[1],\n                        scale * display_grid.shape[0]))\n    plt.title(layer_name)\n    plt.grid(False)\n    plt.imshow(display_grid, aspect='auto', cmap='viridis')","657f65aa":"## **Step_5: Visualizing intermediate activations: Convolutional layers**","4063c7d6":"## **Step_4: Predictions using our trained model**","51e43852":"## **Step_1: Creation of train_set & test_set**","e9d73f12":"## **Step_2: Data Exploration**","92101fa9":"## **Step_3: Buiding & training the model**"}}