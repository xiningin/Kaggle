{"cell_type":{"f8f99c0a":"code","5f04d2e4":"code","1b4cd033":"code","6ead2d5a":"code","54f31641":"code","ca2de47e":"code","a0dda993":"code","660fa9ec":"code","e990ab7c":"code","450d8856":"code","985f8b00":"code","8dbee016":"code","8ec30aec":"code","3f815ee3":"code","3aa9a43e":"code","11f7938b":"code","262ea337":"code","9dd6682e":"code","cfebcddb":"code","a55224d0":"code","a7f75f20":"code","aea64772":"code","d77b2585":"markdown","218e05f7":"markdown","783ec603":"markdown","e7ec689d":"markdown","149c2fb3":"markdown","290451b7":"markdown"},"source":{"f8f99c0a":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\n#for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#    for filename in filenames:\n#        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5f04d2e4":"import tensorflow as tf\nfrom tensorflow.keras.preprocessing.image import img_to_array, ImageDataGenerator\nimport matplotlib.pyplot as plt","1b4cd033":"train_csv = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/train.csv\")\ntrain_csv.head()","6ead2d5a":"test_csv = pd.read_csv(\"\/kaggle\/input\/plant-pathology-2020-fgvc7\/test.csv\")\ntest_csv.head()","54f31641":"image = plt.imread('\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/Train_0.jpg')\nplt.imshow(image)\nprint(image.shape)","ca2de47e":"def image_resize(img, size = (None, None), ratio=3):\n    if size[0] is None:\n        resize_ratio = ratio\n        resize_height = int(img.shape[0]\/resize_ratio)\n        resize_width = int(img.shape[1]\/resize_ratio)\n        print(f\"height: {resize_height}, width: {resize_width}\")\n    else:\n        resize_height = size[0]\n        resize_width = size[1]\n\n    img_resize = tf.image.resize(img, [resize_height,resize_width]).numpy()\n    img_resize = img_resize.astype(np.uint8)\n    return(img_resize)","a0dda993":"plt.figure(1, figsize=(10,10))\nplt.subplot(221)\nplt.imshow(image_resize(image, ratio = 3))\n\nplt.subplot(222)\nplt.imshow(image_resize(image, ratio = 4))\nplt.show()\n\nplt.subplot(223)\nplt.imshow(image_resize(image, ratio = 5))\n\nplt.subplot(224)\nplt.imshow(image_resize(image, ratio = 6))\nplt.show()","660fa9ec":"img_height = 227\nimg_width = 341\nplt.imshow(image_resize(image, size=(img_height, img_width)))","e990ab7c":"train_resized = []\n\nfor img_id in train_csv['image_id'].to_list():\n    image = plt.imread(f'\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/{img_id}.jpg')\n    train_resized.append(image_resize(image, (img_height, img_width)))\n\nprint(len(train_resized))\n\ntest_resized = []\n\nfor img_id in test_csv['image_id'].to_list():\n    image = plt.imread(f'\/kaggle\/input\/plant-pathology-2020-fgvc7\/images\/{img_id}.jpg')\n    test_resized.append(image_resize(image, (img_height, img_width)))\n\nprint(len(test_resized))","450d8856":"x_train = np.ndarray(shape = (len(train_resized), img_height, img_width, 3), dtype=np.float32)\nx_test = np.ndarray(shape = (len(test_resized), img_height, img_width, 3), dtype=np.float32)\n\nfor i in range(len(train_resized)):\n    x_train[i] = img_to_array(train_resized[i])\n\nfor i in range(len(test_resized)):\n    x_test[i] = img_to_array(test_resized[i])\n\nx_train = x_train\/255\nx_test = x_test\/255\n\nprint(x_train.shape)\nprint(x_test.shape)","985f8b00":"y_train = train_csv.iloc[:,1:]\ny_train.head()","8dbee016":"from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Conv2D, Dense, Flatten, Dropout\nfrom tensorflow.keras.applications import InceptionResNetV2\n\nresnet = InceptionResNetV2(weights='imagenet', include_top=False, pooling='avg')\n\nmodel = Sequential()\nmodel.add(resnet)\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(64, activation='relu'))\nmodel.add(Dense(y_train.shape[1], activation='softmax'))\n\nmodel.layers[0].trainable = False\n\nmodel.summary()","8ec30aec":"model.compile(loss=\"categorical_crossentropy\", optimizer=\"adam\", metrics='accuracy')","3f815ee3":"from sklearn.model_selection import train_test_split\n\ntrain_x, val_x, train_y, val_y = train_test_split(x_train, y_train, test_size = 0.2)\n\nprint(train_x.shape)\nprint(train_y.shape)\n\nprint(val_x.shape)\nprint(val_y.shape)\n","3aa9a43e":"datagen = ImageDataGenerator(rotation_range=25,\n                             shear_range=.20,\n                             zoom_range=.20,\n                             width_shift_range=.20,\n                             height_shift_range=.20,\n                             horizontal_flip=True,\n                             vertical_flip=True\n                            )\n\n#train_datagen = datagen.flow(rain, y_train, batch_size=42, seed=42)\n\nbatch_size = 24\ndatagen_without_aug = ImageDataGenerator()\n\ntrain_datagen = datagen_without_aug.flow(train_x, train_y, batch_size=batch_size)\n\nval_datagen = datagen_without_aug.flow(val_x, val_y, batch_size=batch_size)","11f7938b":"callback = tf.keras.callbacks.EarlyStopping(monitor='loss', patience=3)\nhistory = model.fit_generator(train_datagen, \n                              epochs=6,\n                              steps_per_epoch=train_x.shape[0]\/\/batch_size,\n                              validation_data = val_datagen,\n                              validation_steps = val_x.shape[0]\/\/batch_size,\n                              callbacks = [callback]\n                   )","262ea337":"history_df = pd.DataFrame(history.history)\nhistory_df.head()","9dd6682e":"plt.plot(history_df.index, history_df['accuracy'])\nplt.plot(history_df.index, history_df['val_accuracy'])\nplt.show()","cfebcddb":"plt.plot(history_df.index, history_df['loss'])\nplt.plot(history_df.index, history_df['val_loss'])\nplt.show()","a55224d0":"y_preds = model.predict(x_test)","a7f75f20":"y_preds","aea64772":"res = pd.DataFrame()\nres['image_id'] = test_csv['image_id']\nres['healthy'] = y_preds[:, 0]\nres['multiple_diseases'] = y_preds[:, 1]\nres['rust'] = y_preds[:, 2]\nres['scab'] = y_preds[:, 3]\nres.to_csv('submission.csv', index=False)","d77b2585":"### **Resizing the train and test images** ","218e05f7":"**Exploring the image resize ratios**\n\nSelecting the lowest possible, helps in limiting the GPU memory usage in kaggle kernels.\n\n*BTW thanks for the free GPUs @kaggle.*","783ec603":"### Adding image augmentation and training","e7ec689d":"**Input data**","149c2fb3":"### Predicting on the test dataset and preparing the submission","290451b7":"### **Creating model**\n\nUsing the Resnet50 architecture."}}