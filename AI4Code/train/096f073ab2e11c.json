{"cell_type":{"f2224734":"code","e321c029":"code","0bf0cdb7":"code","54ae4c37":"code","f5ae91f6":"code","e4968cec":"code","ca183192":"code","e60b8c0a":"code","300b3d87":"code","8e9d4854":"code","e94e52e8":"code","c98314bd":"code","36347e3a":"code","7a8baa8a":"code","7a4fe310":"code","cbac9a44":"code","8354c93f":"code","d855a9fc":"code","db7be13c":"code","cae691e5":"code","e1992ed3":"code","68308880":"markdown","61b7cdad":"markdown"},"source":{"f2224734":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\npd.set_option('display.max_columns',10)\npd.set_option('display.max_rows',10)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\ndata = pd.read_csv('..\/input\/youtube-new\/INvideos.csv')\ncategory_data = pd.read_json('..\/input\/youtube-new\/IN_category_id.json')","e321c029":"df = pd.DataFrame(data)\nprint(df.columns)","0bf0cdb7":"print(df.info())","54ae4c37":"print(df.isnull().any())","f5ae91f6":"df = df.drop(['description'], axis = 1)\nprint(df.columns)","e4968cec":"df['trending_date'] = pd.to_datetime(df['trending_date'], format = '%y.%d.%m').dt.date\nprint(df['trending_date'])","ca183192":"#print(df['publish_time'])\npublish_time = pd.to_datetime(df['publish_time'], format = '%Y-%m-%dT%H:%M:%S.%fZ')\nprint(df['publish_time'])\n","e60b8c0a":"df['publish_date'] = publish_time.dt.date\ndf['publish_time'] = publish_time.dt.time\ndf['publish_hour'] = publish_time.dt.hour\n\nprint(df.columns)","300b3d87":"print(df[['publish_date','publish_time','publish_hour']])","8e9d4854":"print(category_data['items'][0])","e94e52e8":"categories = {category['id']: category['snippet']['title'] for category in category_data['items']}\ndf.insert(4, 'category', df['category_id'].astype(str).map(categories))\nprint(df.columns)","c98314bd":"df['like_Perc'] = (df['likes'] \/ (df['likes'] + df['dislikes']))\nprint(df['like_Perc'])","36347e3a":"df['dislike_Perc'] = 1 - df['like_Perc']\nprint(df['dislike_Perc'])","7a8baa8a":"df_last = df.drop_duplicates(subset = ['video_id'] , keep = 'last' , inplace = False) \ndf_first = df.drop_duplicates(subset = ['video_id'] , keep = 'first' , inplace = False)","7a4fe310":"print('Total number of videos in original datasets are :', (df.shape[0]))\nprint('Total number of videos in dataset df_last : ', (df_last.shape[0]))\nprint('Total number of videos in dataset df_first: ', (df_first.shape[0]))","cbac9a44":"df['Difference_in_days'] = (df['trending_date'] - df['publish_date'])\/np.timedelta64(1 , 'D')\ndf['Difference_in_days'] = df['Difference_in_days'].astype('int')\nprint(df['Difference_in_days'])","8354c93f":"print(df.isnull().sum())","d855a9fc":"print(df['category'].unique())","db7be13c":"df.loc[(df['Difference_in_days'] < 1), 'Difference_in_days'] = 1\ndf['views_per_day'] = df['views'].astype('int')\/df['Difference_in_days']\nprint(df.head(3))","cae691e5":"df['category'].fillna('Nonprofits & Activism', inplace = True)\ndf[df[\"category_id\"]  == 29]","e1992ed3":"print(df.isnull().sum())","68308880":"We will see if there is any columns in which values are null or not.","61b7cdad":"All columns are completely filled except description, which is also not very important columns, so we going to drop it."}}