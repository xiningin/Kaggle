{"cell_type":{"7a0b8ca7":"code","511610ef":"code","1008b60b":"code","f5be00f2":"code","7aeb100a":"code","42503b88":"code","b353760e":"code","1fd403a5":"code","9a37d552":"code","ead9d637":"code","fed633cd":"code","d3118fe6":"code","5d208049":"code","d5e782fe":"code","7520311d":"code","55400868":"code","8dc0da45":"code","37b1e175":"code","f7c3f64e":"code","7e92845a":"code","e80ee07d":"code","a0218bda":"code","a09ec6ae":"code","ce90b3bf":"code","9b1e1929":"code","31dd50b5":"code","32b555f6":"code","e17ce1f7":"code","c7d21071":"code","e34caf45":"code","efc3f9f0":"code","7ce340df":"code","fbee8df2":"code","4dcd009b":"code","e1d8e275":"code","57efaeef":"code","2727df2b":"code","2b198aef":"code","906fef56":"code","673c6c80":"code","c15bfe41":"code","8645e1c9":"code","076caa26":"code","0c42f7ea":"code","406c2cf9":"markdown","c69ea262":"markdown","f4b664f5":"markdown","08c525b8":"markdown","b3099576":"markdown","68821fd1":"markdown","8823427a":"markdown","8731f7e9":"markdown","99bbb792":"markdown","75cf8dd3":"markdown","51b51257":"markdown","3bad1f15":"markdown","faeaa62d":"markdown","c5494794":"markdown","051e8d81":"markdown","9adb46c3":"markdown","31d330f7":"markdown","98b3fc34":"markdown","b887caab":"markdown","7cc12d83":"markdown","14456fef":"markdown","8e37d9ef":"markdown","204c52f5":"markdown","1ea0b73c":"markdown","78cbf3a3":"markdown","5d5685cf":"markdown","c8551951":"markdown","2381189f":"markdown","80c6ef21":"markdown","6b19b411":"markdown","3216f479":"markdown","e44a460a":"markdown","9e93cc7f":"markdown","5acc6425":"markdown","21221fa6":"markdown","eb7b5c4b":"markdown"},"source":{"7a0b8ca7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","511610ef":"import pandas as pd\nimport numpy as np\nimport matplotlib.pylab as plt\nplt.style.use('bmh')\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn.model_selection import cross_val_score, cross_val_predict\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.preprocessing import scale\n\nfrom sklearn.linear_model import LinearRegression, Ridge, RidgeCV\nfrom sklearn.ensemble import GradientBoostingRegressor\n\npd.set_option('display.max_columns', None)","1008b60b":"import pandas as pd\n\n# Read the data\ntrain = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\nprint('train shape:', train.shape, '\\n', 'test shape:', test.shape)\ntrain.head()","f5be00f2":"# Check Null Value\ntrain_null = train.isnull().sum().to_frame().reset_index().rename(columns={\"index\": \"Col_Name\", 0:\"train\"})\ntest_null = test.isnull().sum().to_frame().reset_index().rename(columns={\"index\": \"Col_Name\", 0:\"test\"})\n\n# Null Value Percentage\ntrain_null_percentage = (train.isnull().sum() * 100 \/ len(train)).to_frame().reset_index().rename(columns={\"index\": \"Col_Name\", 0:\"train_percentage\"})\ntest_null_percentage = (test.isnull().sum() * 100 \/ len(test)).to_frame().reset_index().rename(columns={\"index\": \"Col_Name\", 0:\"test_percentage\"})","7aeb100a":"df_concat = pd.concat([train_null['Col_Name'], train_null['train'], train_null_percentage['train_percentage'], test_null['test'], test_null_percentage['test_percentage']], axis=1)\ndf_concat[(df_concat['train_percentage']>15)].sort_values(['train','test'], ascending=False)","42503b88":"# train and test dataset in an array\n\ndatasets = [train, test]","b353760e":"# Drop the features which have high no of null values and having timestamp in them.\n\nfeature_drop = ['PoolQC', 'MiscFeature', 'Fence', 'FireplaceQu', 'LotFrontage', 'GarageYrBlt', 'MoSold', 'YrSold', \n                'LowQualFinSF', 'MiscVal', 'PoolArea']\n\nfor df in datasets:\n    df.drop(feature_drop, axis=1, inplace=True)","1fd403a5":"# If the house has no Alley, it will have missing value , so just fill NaNs.\n\nfor df in datasets:\n    df.loc[df['Alley'].isnull(), 'Alley'] = 'NoAlley'","9a37d552":"# If a house has no garage, it will have missing value on the 'Garage related' features, so just fill NaNs with 'NoGarage'.\n\nfor df in datasets:\n    df.loc[df['GarageCond'].isnull(), 'GarageCond'] = 'NoGarage'\n    df.loc[df['GarageQual'].isnull(), 'GarageQual'] = 'NoGarage'\n    df.loc[df['GarageType'].isnull(), 'GarageType'] = 'NoGarage'\n    df.loc[df['GarageFinish'].isnull(), 'GarageFinish'] = 'NoGarage'","ead9d637":"# If a house has no basement, it will have missing value on the 'basement related' features, so just fill NaNs with 'NoBsmt'. \n\nfor df in datasets:   \n    df.loc[df['BsmtExposure'].isnull(), 'BsmtExposure'] = 'NoBsmt'\n    df.loc[df['BsmtFinType2'].isnull(), 'BsmtFinType2'] = 'NoBsmt'\n    df.loc[df['BsmtCond'].isnull(), 'BsmtCond'] = 'NoBsmt'\n    df.loc[df['BsmtQual'].isnull(), 'BsmtQual'] = 'NoBsmt'\n    df.loc[df['BsmtFinType1'].isnull(), 'BsmtFinType1'] = 'NoBsmt'","fed633cd":"# Masonry veneer feature: just fill with 'None' if there is no Masonry veneer.  \n\nfor df in datasets:  \n    df.loc[df['MasVnrType'].isnull(), 'MasVnrType'] = 'None'\n    df.loc[df['MasVnrArea'].isnull(), 'MasVnrArea'] = 0","d3118fe6":"# Electrical is the categorical column hence fill it with mode\n\ntrain['Electrical'].fillna(train['Electrical'].mode()[0], inplace=True)","5d208049":"# other numerical and categorical missing value columns\n# fill numrical with 0\n# fill categorcial with Mode value.\n\ntest_numeric_missing = ['BsmtFullBath', 'BsmtHalfBath', 'BsmtFinSF1', 'BsmtFinSF2', 'BsmtUnfSF', 'GarageArea', 'GarageCars', 'TotalBsmtSF']\ntest_categorical_missing = ['MSZoning', 'Functional', 'Utilities', 'Exterior1st', 'Exterior2nd', 'KitchenQual', 'SaleType']\n\nfor i in test_numeric_missing:\n    test[i].fillna(0, inplace=True)\nfor j in test_categorical_missing:\n    test[j].fillna(test[j].mode()[0], inplace=True)","d5e782fe":"# After imputing all missing values\n# Check the missing values again for datasets\n\nmissing_numeric = pd.concat([train.isnull().sum(), test.isnull().sum()], axis=1, keys=['train', 'test'])\nmissing_numeric = missing_numeric[(missing_numeric['train']>0) | (missing_numeric['test']>0)]\nmissing_numeric.sort_values(by=['train', 'test'], ascending=False)","7520311d":"train.select_dtypes(exclude=[object]).describe()","55400868":"print(train['SalePrice'].describe(), '\\n')\nprint('Before Transformation Skew: ', train['SalePrice'].skew())\n\ntarget = np.log1p(train['SalePrice'])\nprint('Log Transformation Skew: ', target.skew())","8dc0da45":"plt.rcParams['figure.figsize'] = (12, 5)\ntarget_log_tran = pd.DataFrame({'before transformation':train['SalePrice'], 'log transformation': target})\ntarget_log_tran.hist()","37b1e175":"## Checking the skewness for the numerical values\n## Pointing out the features whose Skewness is greater than 0.8\n\nskewness = pd.DataFrame({'Skewness':train.select_dtypes(exclude=[object]).skew()})\n\nprint(skewness[skewness['Skewness']>0.8].sort_values(by='Skewness'), '\\n')  \nprint(skewness[skewness['Skewness']>0.8].sort_values(by='Skewness').index.tolist())","f7c3f64e":"skews = ['2ndFlrSF', 'BsmtUnfSF', 'GrLivArea', '1stFlrSF', 'MSSubClass', 'TotalBsmtSF', 'WoodDeckSF', 'BsmtFinSF1', 'OpenPorchSF', \n         'MasVnrArea', 'EnclosedPorch', 'BsmtHalfBath', 'ScreenPorch', 'BsmtFinSF2', 'KitchenAbvGr', '3SsnPorch', 'LotArea']\nfor df in datasets:\n    for s in skews:\n        df[s] = np.log1p(df[s])","7e92845a":"numeric_data_select = train[['SalePrice', 'OverallQual', 'GrLivArea', 'GarageArea', 'GarageCars', 'TotalBsmtSF', '1stFlrSF', \n                             'FullBath', 'TotRmsAbvGrd', 'YearBuilt', 'YearRemodAdd', 'MasVnrArea', 'Fireplaces', 'BsmtFinSF1',\n                            'WoodDeckSF', '2ndFlrSF', 'OpenPorchSF', 'HalfBath', 'LotArea', 'BsmtFullBath', 'BsmtUnfSF']]\n\ncorr = numeric_data_select.corr()\nplt.figure(figsize=(12, 12))\nmask = np.zeros_like(corr)\nmask[np.triu_indices_from(mask)] = True\nsns.heatmap(corr, vmax=1, square=True, annot=True, mask=mask, cbar=False, linewidths=0.1)\nplt.xticks(rotation=45)","e80ee07d":"cust_corr = corr[(corr>=.9) | (corr <= .1)]\nmask = np.zeros_like(cust_corr)\nmask[np.triu_indices_from(mask)] = True\nwith sns.axes_style(\"white\"):\n    f, ax = plt.subplots(figsize=(25, 10))\n    ax = sns.heatmap(cust_corr, mask=mask, cmap='Greens', vmax=.3, square=True, annot=True,linewidths=0.1, annot_kws={'size':10})","a0218bda":"# Ascending Correaltion\n\ncorr = train.select_dtypes(exclude=[object]).corr()\nprint(corr['SalePrice'].sort_values(ascending=False).head(8))","a09ec6ae":"# Descending Correlation \n\nprint(corr['SalePrice'].sort_values(ascending=False).tail(8))","ce90b3bf":"plt.figure(figsize=(18,5))\ntrain.drop(['SalePrice', 'Id'], axis=1).boxplot()\nplt.xticks(rotation=70)","9b1e1929":"print('Train Shape Before :',train.shape )\nQ1_train = train.quantile(0.25)\nQ3_train = train.quantile(0.75)\nIQR_train = Q3_train - Q1_train\ntrain = train[~((train < (Q1_train - 1.5 * IQR_train)) |(train > (Q3_train + 1.5 * IQR_train))).any(axis=1)]\nprint('Train Shape After :',train.shape )","31dd50b5":"print('Test Shape Before :',test.shape )\nQ1_test = test.quantile(0.25)\nQ3_test = test.quantile(0.75)\nIQR_test = Q3_test - Q1_test\ntest = test[~((test < (Q1_test - 1.5 * IQR_test)) |(test > (Q3_test + 1.5 * IQR_test))).any(axis=1)]\nprint('Test Shape After :',test.shape )","32b555f6":"#sns.pairplot(numeric_data_select, size=2)","e17ce1f7":"plt.rcParams['figure.figsize'] = (12, 4)\nplt.subplot(121)\nsns.boxplot(train['OverallQual'], target)","c7d21071":"plt.subplot(121)\nplt.scatter(train['GrLivArea'], train['SalePrice'])\nplt.xlabel('GrLivArea')\nplt.ylabel('SalePrice')\nplt.subplot(122)\nplt.scatter(train['GarageArea'], train['SalePrice'])\nplt.xlabel('GarageArea')\nplt.ylabel('SalePrice')","e34caf45":"plt.subplot(121)\nplt.scatter(train['TotalBsmtSF'], train['SalePrice'])\nplt.xlabel('TotalBsmtSF')\nplt.ylabel('SalePrice')\n\nplt.subplot(122)\nplt.scatter(train['MasVnrArea'], train['SalePrice'])\nplt.xlabel('MasVnrArea')\nplt.ylabel('SalePrice')","efc3f9f0":"plt.subplot(121)\nsns.boxplot(train['Fireplaces'], train['SalePrice'])\n\nplt.subplot(122)\nplt.scatter(train['YearBuilt'], train['SalePrice'])\nplt.xlabel('YearBuilt')","7ce340df":"plt.subplot(121)\nplt.scatter(train['BsmtFinSF1'], train['SalePrice'])\nplt.xlabel('BsmtFinSF1')\nplt.ylabel('SalePrice')\n\nplt.subplot(122)\nplt.scatter(train['WoodDeckSF'], train['SalePrice'])\nplt.xlabel('WoodDeckSF')\nplt.ylabel('SalePrice')","fbee8df2":"categorical_data = train.select_dtypes(include=[object])\ncategorical_data.describe()","4dcd009b":"plt.rcParams['figure.figsize'] = (12, 7)\nplt.subplot(221)\nsns.boxplot(train['ExterQual'], target)\nplt.subplot(222)\nsns.boxplot(train['BsmtQual'], target)\nplt.subplot(223)\nsns.boxplot(train['BsmtExposure'], target)\nplt.subplot(224)\nsns.boxplot(train['GarageFinish'], target)","e1d8e275":"plt.subplot(221)\nsns.boxplot(train['CentralAir'], target)\nplt.subplot(222)\nsns.boxplot(train['KitchenQual'], target)","57efaeef":"train_ExterQual_dummy = pd.get_dummies(train['ExterQual'], prefix='ExterQual')\ntest_ExterQual_dummy = pd.get_dummies(test['ExterQual'], prefix='ExterQual')\n\ntrain_BsmtQual_dummy = pd.get_dummies(train['BsmtQual'], prefix='BsmtQual')\ntest_BsmtQual_dummy = pd.get_dummies(test['BsmtQual'], prefix='BsmtQual')\n\ntrain_BsmtExposure_dummy = pd.get_dummies(train['BsmtExposure'], prefix='BsmtExposure')\ntest_BsmtExposure_dummy = pd.get_dummies(test['BsmtExposure'], prefix='BsmtExposure')\n\ntrain_GarageFinish_dummy = pd.get_dummies(train['GarageFinish'], prefix='GarageFinish')\ntest_GarageFinish_dummy = pd.get_dummies(test['GarageFinish'], prefix='GarageFinish')\n\ntrain_SaleCondition_dummy = pd.get_dummies(train['SaleCondition'], prefix='SaleCondition')\ntest_SaleCondition_dummy = pd.get_dummies(test['SaleCondition'], prefix='SaleCondition')\n\ntrain_CentralAir_dummy = pd.get_dummies(train['CentralAir'], prefix='CentralAir')\ntest_CentralAir_dummy = pd.get_dummies(test['CentralAir'], prefix='CentralAir')\n\ntrain_KitchenQual_dummy = pd.get_dummies(train['KitchenQual'], prefix='KitchenQual')\ntest_KitchenQual_dummy = pd.get_dummies(test['KitchenQual'], prefix='KitchenQual')","2727df2b":"# Define a model evaluation function by outputing R2 score and mean squared error. (using 10-fold cross validation)\n    \ndef model_eval(model):\n    model_fit = model.fit(X, y)\n    R2 = cross_val_score(model_fit, X, y, cv=10 , scoring='r2').mean()\n    MSE = -cross_val_score(lr, X, y, cv=10 , scoring='neg_mean_squared_error').mean()\n    print('For', model,'\\n','- R2 Score:', R2, '|', 'MSE:', MSE,'\\n')","2b198aef":"data = train.select_dtypes(exclude=[object])\ny = np.log1p(data['SalePrice'])\nX = data.drop(['Id', 'SalePrice'], axis=1)\nX = pd.concat([X, train_ExterQual_dummy, train_BsmtQual_dummy, train_GarageFinish_dummy, train_BsmtExposure_dummy,\n              train_SaleCondition_dummy, train_CentralAir_dummy, train_KitchenQual_dummy], axis=1)","906fef56":"lr = LinearRegression()\nri = Ridge(alpha=0.1, normalize=False)\nricv = RidgeCV(cv=5)\ngdb = GradientBoostingRegressor(n_estimators=200)","673c6c80":"for model in [lr, ri, ricv, gdb]:\n    model_eval(model)","c15bfe41":"test_id = test['Id']\ntest = test.select_dtypes(exclude=[object])#.drop('Id', axis=1)\ntest = pd.concat([test, test_ExterQual_dummy, test_BsmtQual_dummy, test_GarageFinish_dummy, test_BsmtExposure_dummy,\n              test_SaleCondition_dummy, test_CentralAir_dummy, test_KitchenQual_dummy], axis=1)","8645e1c9":"pred = ri.predict(test)\n\npred = np.expm1(pred)\nprediction = pd.DataFrame({'Id':test_id, 'SalePrice':pred})\nprediction.to_csv('Prediction1.csv', index=False)\nprediction.head()","076caa26":"pred_2 = lr.predict(test)\n\npred_2 = np.expm1(pred_2)\nprediction = pd.DataFrame({'Id':test_id, 'SalePrice':pred_2})\nprediction.to_csv('Prediction1.csv', index=False)\nprediction.head()","0c42f7ea":"pred_3 = gdb.predict(test)\n\npred_3 = np.expm1(pred_3)\nprediction = pd.DataFrame({'Id':test_id, 'SalePrice':pred_3})\nprediction.to_csv('Prediction1.csv', index=False)\nprediction.head()","406c2cf9":"#  Numeric Data","c69ea262":"## Sales Price keep on increasingly with quality standards.Hence increasing the quality would increase in price.\n ","f4b664f5":"# Creating dummy variables","08c525b8":"### Using Log Transformation `SalesPrice` get close to normal distribution. ","b3099576":"# Garage Area and Living Area show the linear growth wrt to Sales","68821fd1":"# Loading data","8823427a":"# Creating object of different Model","8731f7e9":"# HeapMap Visualization","99bbb792":"# Checking Normal Distribution of Independent Value using Skewness","75cf8dd3":"TotalBsmtSF: Total square feet of basement area\n\nMasVnrArea: Masonry veneer area in square feet","51b51257":"# Train Model: adding dummy variables","3bad1f15":"# Adding the dummy variables to dataset","faeaa62d":"## OverallQual: Rates the overall material and finish of the house\n\n       10\tVery Excellent\n       9\tExcellent\n       8\tVery Good\n       7\tGood\n       6\tAbove Average\n       5\tAverage\n       4\tBelow Average\n       3\tFair\n       2\tPoor\n       1\tVery Poor","c5494794":"### As the rate of missing value is very high we would delete these columns","051e8d81":"# Normal Distribution of `SalePrice` using Skewness","9adb46c3":"Fireplaces: Number of fireplaces\n\nYearBuilt: Original construction date","31d330f7":"# Pairplot Visualization","98b3fc34":"# Model building","b887caab":"# Categorical Data Operations","7cc12d83":"# Impute Missing Values","14456fef":"# Calling the Models","8e37d9ef":"BsmtFinSF1: Type 1 finished square feet\n\nWoodDeckSF: Wood deck area in square feet","204c52f5":"# Predicting the values","1ea0b73c":"# Outlier Treatment","78cbf3a3":"CentralAir: Central air conditioning\n\n       N\tNo\n       Y\tYes\n       \nKitchenQual: Kitchen quality\n\n       Ex\tExcellent\n       Gd\tGood\n       TA\tTypical\/Average\n       Fa\tFair\n       Po\tPoor","5d5685cf":"## There is no more missing values left","c8551951":"# Problem Statement: \n### Predict sales prices and practice feature engineering, RFs, and gradient boosting","2381189f":"# Missing Values","80c6ef21":"# Importing Libraries","6b19b411":"# Log Tranformation of Numerical features","3216f479":"# Correlations w.r.t `SalePrice`","e44a460a":"# Removing Outlier Treatment using InterQuartile Range","9e93cc7f":"# More no of fireplace leads to high Sales Price\n# Likewise Newlybuild houses are more costly","5acc6425":"GrLivArea: Above grade (ground) living area square feet\n\nGarageArea: Size of garage in square feet","21221fa6":"ExterQual: Evaluates the quality of the material on the exterior \n\t\t\n       Ex\tExcellent\n       Gd\tGood\n       TA\tAverage\/Typical\n       Fa\tFair\n       Po\tPoor\n       \nBsmtQual: Evaluates the height of the basement\n\n       Ex\tExcellent (100+ inches)\t\n       Gd\tGood (90-99 inches)\n       TA\tTypical (80-89 inches)\n       Fa\tFair (70-79 inches)\n       Po\tPoor (<70 inches\n       NA\tNo Basement\n       \nBsmtExposure: Refers to walkout or garden level walls\n\n       Gd\tGood Exposure\n       Av\tAverage Exposure (split levels or foyers typically score average or above)\t\n       Mn\tMimimum Exposure\n       No\tNo Exposure\n       NA\tNo Basement\n       \nGarageFinish: Interior finish of the garage\n\n       Fin\tFinished\n       RFn\tRough Finished\t\n       Unf\tUnfinished\n       NA\tNo Garage","eb7b5c4b":"# Visualization of Distribution before and after using Log "}}