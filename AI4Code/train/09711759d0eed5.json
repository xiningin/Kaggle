{"cell_type":{"b08e87f4":"code","c3e452da":"code","41c6d63c":"code","713613b2":"code","a1b3811b":"code","8900367d":"code","fb21546f":"code","1d3c0082":"code","c02d242a":"code","9919bff4":"code","7a8780dd":"code","8c8f1e21":"code","796eddd1":"code","1ef4c64a":"code","83d67161":"code","6415eb44":"code","26f01386":"code","a1526118":"code","25a043ed":"code","0457075e":"code","6418a095":"markdown","864ef52f":"markdown","00d8be5e":"markdown","c77e5493":"markdown"},"source":{"b08e87f4":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport json\nimport os\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\n# import os\n# for dirname, _, filenames in os.walk('\/kaggle\/input'):\n#     for filename in filenames:\n#         print(os.path.join(dirname, filename))\n\n# main json file >>> \/kaggle\/input\/wlasl-processed\/WLASL_v0.3.json\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","c3e452da":"main_path = '\/kaggle\/input\/wlasl-processed\/'\nwlas_df = pd.read_json(main_path + 'WLASL_v0.3.json')","41c6d63c":"wlas_df.head()","713613b2":"wlas_df.shape","a1b3811b":"def get_videos_ids(json_list):\n    \"\"\"\n    function to check if the video id is available in the dataset\n    and return the viedos ids of the current instance\n    \n    input: instance json list\n    output: list of videos_ids\n    \n    \"\"\"\n    videos_list = []    \n    for ins in json_list:\n        video_id = ins['video_id']\n        if os.path.exists(f'{main_path}videos\/{video_id}.mp4'):\n            videos_list.append(video_id)\n    return videos_list","8900367d":"def get_json_features(json_list):\n    \"\"\"\n    function to check if the video id is available in the dataset\n    and return the viedos ids and url or any other featrue of the current instance\n    \n    input: instance json list\n    output: list of videos_ids\n    \n    \"\"\"\n    videos_ids = []\n    videos_urls = []\n    for ins in json_list:\n        video_id = ins['video_id']\n        video_url = ins['url']\n        if os.path.exists(f'{main_path}videos\/{video_id}.mp4'):\n            videos_ids.append(video_id)\n            videos_urls.append(video_url)\n    return videos_ids, videos_urls","fb21546f":"with open(main_path+'WLASL_v0.3.json', 'r') as data_file:\n    json_data = data_file.read()\n\ninstance_json = json.loads(json_data)","1d3c0082":"get_videos_ids(instance_json[0]['instances'])[0]","c02d242a":"len(get_videos_ids(instance_json[0]['instances']))","9919bff4":"wlas_df['videos_ids'] = wlas_df['instances'].apply(get_videos_ids)","7a8780dd":"features_df = pd.DataFrame(columns=['gloss', 'video_id', 'url'])\nfor row in wlas_df.iterrows():\n#     print(row[1][1])\n    ids, urls = get_json_features(row[1][1])\n    word = [row[1][0]] * len(ids)\n    df = pd.DataFrame(list(zip(word, ids, urls)), columns = features_df.columns)\n    features_df = features_df.append(df, ignore_index=True)","8c8f1e21":"features_df.index.name = 'index'\nfeatures_df","796eddd1":"features_df.to_csv('features_df.csv', index=False)","1ef4c64a":"wlas_df.head()","83d67161":"wlas_df['samples_num'] = wlas_df['videos_ids'].apply(len)","6415eb44":"wlas_df.head()","26f01386":"print(\"minimum number of samples for a word:\", wlas_df['samples_num'].min())\nprint(\"maximum number of samples for a word:\", wlas_df['samples_num'].max())","a1526118":"words_sample_counts = wlas_df[['gloss', 'samples_num']].groupby('samples_num').agg({\"gloss\":['count', ', '.join]})","25a043ed":"words_sample_counts","0457075e":"# the words that have two samples\nwords_sample_counts.loc[2].values[1]","6418a095":"## Task Dataframe","864ef52f":"## 3. Dataset Classes analysis","00d8be5e":"## 2. Extract the available videos list from the dataset","c77e5493":"## 1. Load WLAS Dataset"}}