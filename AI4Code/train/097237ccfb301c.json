{"cell_type":{"c285594d":"code","b055378e":"code","4556e85c":"code","3716a164":"code","fd0d221f":"code","3cf2bb8b":"code","38d198a9":"code","4aa01161":"code","a167a44f":"code","f4892254":"code","2c20b527":"code","7d089a90":"code","02e4a3d7":"code","427e8976":"code","90e22183":"markdown","b9c735bf":"markdown","e14c8533":"markdown","5173ee3b":"markdown","aaf4f3c9":"markdown","6bc86e8b":"markdown","dfa89b9a":"markdown","a672d6c6":"markdown","ae65046c":"markdown"},"source":{"c285594d":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","b055378e":"wholesale_all = pd.read_csv('..\/input\/wholesale-customers-data-set\/Wholesale customers data.csv')\n\nwholesale_all.info()","4556e85c":"wholesale_all.head()","3716a164":"wholesale = wholesale_all.drop(['Channel','Region'], axis=1)\nwholesale_all.groupby(['Channel', 'Region']).agg(['mean', 'std']).round(1)","fd0d221f":"import matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize=(15,10))\nsns.boxplot(x='variable', y='value', data=wholesale.melt())\n\nplt.show()","3cf2bb8b":"sns.pairplot(wholesale, diag_kind='kde')\n\nplt.show()","38d198a9":"from scipy.stats import boxcox, probplot, norm, shapiro\n\nshapiro_test = {}\nplt.figure(figsize=(15, 10))\nfor i in range(0,6):\n    ax = plt.subplot(2,3,i+1)\n    probplot(x = wholesale[wholesale.columns[i]], dist=norm, plot=ax)\n    plt.title(wholesale.columns[i])\n    shapiro_test[wholesale.columns[i]] = shapiro(wholesale[wholesale.columns[i]])\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","4aa01161":"import numpy as np\n\nwholesale_log = np.log(wholesale)\n\nshapiro_test = {}\n\nplt.figure(figsize=(15, 10))\nfor i in range(6):\n    ax = plt.subplot(2,3,i+1)\n    probplot(x = wholesale_log[wholesale_log.columns[i]], dist=norm, plot=ax)\n    plt.title(wholesale_log.columns[i])\n    shapiro_test[wholesale.columns[i]] = shapiro(wholesale[wholesale.columns[i]])\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","a167a44f":"from scipy.stats import boxcox\n\nshapiro_test = {}\nlambdas = {}\n\nplt.figure(figsize=(15, 10))\nplt.title('BoxCox Transformation')\nfor i in range(6):\n    ax = plt.subplot(2,3,i+1)\n    x, lbd = boxcox(wholesale[wholesale.columns[i]])\n    probplot(x = x, dist=norm, plot=ax)\n    plt.title(wholesale.columns[i])\n    shapiro_test[wholesale.columns[i]] = shapiro(x)\n    lambdas[wholesale.columns[i]] = lbd\n    \nplt.show()\n\npd.DataFrame(shapiro_test, index=['Test Statistic', 'p-value']).transpose()","f4892254":"pd.DataFrame.from_dict(lambdas, orient='index', columns=['lambda'])","2c20b527":"from sklearn.preprocessing import PowerTransformer, StandardScaler\n\nbc = PowerTransformer(method='box-cox')\nwholesale_boxcox = bc.fit_transform(wholesale)\n\nsc = StandardScaler()\nwholesale_processed = sc.fit_transform(wholesale_boxcox)\n\nwholesale_processed_df = pd.DataFrame(wholesale_processed, columns=wholesale.columns)\nwholesale_processed_df","7d089a90":"sns.pairplot(wholesale_processed_df, diag_kind='kde')\n\nplt.show()","02e4a3d7":"from sklearn.cluster import KMeans\n\nsse = {}\n\nfor k in range(2,11):\n    kmeans = KMeans(n_clusters = k, random_state=123)\n    cluster_labels = kmeans.fit_predict(wholesale_processed_df)\n    sse[k] = kmeans.inertia_\n   \nplt.figure(figsize=(10,5))\nplt.title('Elbow Plot')\nsns.pointplot(x = list(sse.keys()), y = list(sse.values()))\n\nplt.show()","427e8976":"kmeans = KMeans(n_clusters=3, random_state=123)\nkmeans.fit(wholesale_processed_df)\n\nwholesale = wholesale.assign(segment = kmeans.labels_)\n\nkmeans_3_means = wholesale.groupby('segment').mean()\n\nkmeans = KMeans(n_clusters=4, random_state=123)\nkmeans.fit(wholesale_processed_df)\n\nwholesale = wholesale.assign(segment = kmeans.labels_)\n\nkmeans_4_means = wholesale.groupby('segment').mean()\n\nplt.figure(figsize=(14,6))\nplt.subplot(1,2,1)\nsns.heatmap(kmeans_3_means.T, cmap='Blues')\n\nplt.subplot(1,2,2)\nsns.heatmap(kmeans_4_means.T, cmap='Blues')\n\nplt.show()","90e22183":"## Customer Segmentation\n\nIn the following customers will be segmented according to their annual spending using KMeans.\n\n* Data Exploration\n* Requirements Check\n* Data Preparation\n* Model development","b9c735bf":"The Log-Transformation is also not satisfactorily. Let's try BoxCox transformation:","e14c8533":"## Data Preparation","5173ee3b":"The elbow is by 3 clusters so we try the kmeans with 3 and 4 clusters.","aaf4f3c9":" All the variable are statistically significant non normally distributed.\n \n Let's try the Logarithmic Transformation:","6bc86e8b":"## Requirements Check","dfa89b9a":"## Data Exploration","a672d6c6":"As the distributions are skewed a transformation must be found to normalise the data.","ae65046c":"## Model Development"}}