{"cell_type":{"56c5fe5f":"code","2e2d182a":"code","97bf090b":"code","8c973109":"code","c0894d5a":"code","79994e79":"code","54c1ca5c":"code","7b17d291":"code","6d5f727a":"code","a296576a":"code","38e0c5ea":"code","7719c812":"code","2351a8af":"code","01b9884b":"code","586858cb":"code","8e800cf5":"code","09f7decd":"code","34db53e3":"code","71c4ebfd":"code","57928a03":"code","1b5d9682":"code","e1479d32":"code","265a852e":"code","14670834":"code","c4f8e17a":"code","bf2a5bd4":"markdown","4e81a591":"markdown","a21e7f88":"markdown","d5c2318e":"markdown","9a4c597d":"markdown","6c066759":"markdown","ef539ccf":"markdown"},"source":{"56c5fe5f":"import numpy as np\nimport pandas as pd\n\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import train_test_split\n\nfrom sklearn.linear_model import LogisticRegression","2e2d182a":"data = pd.read_csv('..\/input\/food-preferences\/Food_Preference.csv')","97bf090b":"data","8c973109":"data.drop(['Timestamp', 'Participant_ID'], axis=1, inplace=True)","c0894d5a":"data","79994e79":"data.info()","54c1ca5c":"data.dropna(axis=0, inplace=True)\ndata.reset_index(drop=True, inplace=True)","7b17d291":"data['Age']","6d5f727a":"age_bins = pd.qcut(data['Age'], q=2, labels=[0, 1])","a296576a":"pd.concat([data['Age'], age_bins], axis=1)","38e0c5ea":"data['Age'] = age_bins","7719c812":"data","2351a8af":"categorical_features = ['Gender', 'Nationality', 'Food', 'Juice', 'Dessert']","01b9884b":"def get_uniques(df, columns):\n    return {column: list(df[column].unique()) for column in columns}","586858cb":"get_uniques(data, categorical_features)","8e800cf5":"binary_features = ['Gender', 'Food', 'Juice']\n\nordinal_features = ['Dessert']\n\nnominal_features = ['Nationality']","09f7decd":"def binary_encode(df, column, positive_label):\n    df = df.copy()\n    df[column] = df[column].apply(lambda x: 1 if x == positive_label else 0)\n    return df","34db53e3":"def ordinal_encode(df, column, ordering):\n    df = df.copy()\n    df[column] = df[column].apply(lambda x: ordering.index(x))\n    return df","71c4ebfd":"def onehot_encode(df, column):\n    df = df.copy()\n    dummies = pd.get_dummies(df[column])\n    df = pd.concat([df, dummies], axis=1)\n    df.drop(column, axis=1, inplace=True)\n    return df","57928a03":"data = binary_encode(data, 'Gender', 'Male')\ndata = binary_encode(data, 'Food', 'Traditional food')\ndata = binary_encode(data, 'Juice', 'Fresh Juice')\n\ndessert_ordering = ['No', 'Maybe', 'Yes']\ndata = ordinal_encode(data, 'Dessert', dessert_ordering)\n\ndata = onehot_encode(data, 'Nationality')","1b5d9682":"data","e1479d32":"y = data['Age']\nX = data.drop('Age', axis=1)","265a852e":"scaler = MinMaxScaler()\n\nX = scaler.fit_transform(X)","14670834":"X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.7)","c4f8e17a":"model = LogisticRegression()\nmodel.fit(X_train, y_train)\nmodel.score(X_test, y_test)","bf2a5bd4":"# Data Every Day  \n\nThis notebook is featured on Data Every Day, a YouTube series where I train models on a new dataset each day.  \n\n***\n\nCheck it out!  \nhttps:\/\/youtu.be\/r0eaUpurifA","4e81a591":"# Preprocessing","a21e7f88":"## Encoding","d5c2318e":"# Getting Started","9a4c597d":"# Training","6c066759":"## Missing Values","ef539ccf":"## Scaling and Splitting"}}