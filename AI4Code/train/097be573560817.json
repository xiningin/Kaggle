{"cell_type":{"45916f8e":"code","82ae5887":"code","415476c2":"code","c275c6e2":"code","b1d2dce8":"code","2418dc7f":"code","3c389fee":"code","5eaaa4f6":"code","0a1611f4":"code","b792af54":"code","0239a2de":"code","c5921fff":"code","54c87c7b":"code","4759f64f":"code","e0dc6135":"code","afe443c2":"code","e694c1e0":"code","5fd7288f":"code","5a9a3aca":"code","40cceb8b":"code","20fc5fde":"code","2a498281":"code","a144cea6":"code","f5162645":"code","1edfdf89":"code","9cd2b6dd":"code","62f14185":"code","f1f7ae41":"code","2ec2dead":"code","a4c68dc3":"code","7c21c69c":"code","0e45b77e":"code","335d2d72":"code","e6c0f9b6":"code","f8a8cd3c":"code","4a136a62":"code","c1ba9ee4":"code","29d8b754":"code","a70604ea":"code","c3943867":"code","675768f0":"code","08e05300":"code","abfdc5de":"code","8001cfd8":"code","661b38a3":"code","a27e3c1c":"code","08ef4381":"code","20a0572c":"code","a4ff5fbb":"code","8463bcf7":"code","91e978f9":"code","cbee4fdc":"code","0ae60812":"code","bd747fdc":"markdown","bfcf4b1f":"markdown","1dede8fb":"markdown","3b96da11":"markdown","f0f98a89":"markdown","0a183f3e":"markdown"},"source":{"45916f8e":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\nimport warnings\nwarnings.filterwarnings('ignore')","82ae5887":"import pandas as pd\nimport numpy as np\nfrom statistics import mode","415476c2":"# Read train data\ntrain = pd.read_csv('\/kaggle\/input\/janatahack-machine-learning-for-banking\/train_fNxu4vz.csv')\n\n# Have a first look at train data\nprint('Train shape:', train.shape)","c275c6e2":"# Have a look at first 5 data observations\ntrain.head()","b1d2dce8":"# Have a look at last 5 data observations\ntrain.tail()","2418dc7f":"train['Length_Employed'] = train['Length_Employed'].str.replace('<','')\ntrain['Length_Employed'] = train['Length_Employed'].str.replace('+','')\ntrain['Length_Employed'] = train['Length_Employed'].str.replace('year','')\ntrain['Length_Employed'] = train['Length_Employed'].str.replace('s','')","3c389fee":"train.isnull().mean().sort_values(ascending = False)","5eaaa4f6":"# Read test data\ntest = pd.read_csv('\/kaggle\/input\/janatahack-machine-learning-for-banking\/test_fjtUOL8.csv')\n\n# Have a first look at test data\nprint('Test shape:', test.shape)","0a1611f4":"# Have a look at train and test columns\nprint('Train columns:', train.columns.tolist())\nprint('Test columns:', test.columns.tolist())","b792af54":"# Load our plotting libraries\nimport matplotlib.pyplot as plt\nimport seaborn as sns","0239a2de":"# Countplot for 'Interest_Rate' variable\nsns.countplot(train['Interest_Rate'])","c5921fff":"# Let's calculate the mean of our target\nround(np.mean(train['Interest_Rate']), 2)","54c87c7b":"# Convert to numeric\ntrain[\"Loan_Amount_Requested\"] = train[\"Loan_Amount_Requested\"].str.replace(\",\", \"\")\ntrain[\"Loan_Amount_Requested\"] = pd.to_numeric(train[\"Loan_Amount_Requested\"])\ntest[\"Loan_Amount_Requested\"] = test[\"Loan_Amount_Requested\"].str.replace(\",\", \"\")\ntest[\"Loan_Amount_Requested\"] = pd.to_numeric(test[\"Loan_Amount_Requested\"])","4759f64f":"test['Length_Employed'] = test['Length_Employed'].str.replace('<','')\ntest['Length_Employed'] = test['Length_Employed'].str.replace('+','')\ntest['Length_Employed'] = test['Length_Employed'].str.replace('year','')\ntest['Length_Employed'] = test['Length_Employed'].str.replace('s','')","e0dc6135":"# Predict!\n#test['Interest_Rate'] = logisticRegression.predict(pd.get_dummies(test['Gender']))","afe443c2":"# Write test predictions for final submission\n#test[['Loan_ID', 'Interest_Rate']].to_csv('First_Prediction.csv', index = False)","e694c1e0":"# Excuse me, can we have a plot please?!\nsns.heatmap(train.isnull(), yticklabels = False, cbar = False, cmap = 'plasma')","5fd7288f":"train.describe(include = 'all')","5a9a3aca":"fig = plt.figure(figsize=(12,8))\nsns.countplot(train['Length_Employed'])","40cceb8b":"fig = plt.figure(figsize=(12,8))\nsns.countplot(train['Home_Owner'])","20fc5fde":"fig = plt.figure(figsize=(12,8))\nsns.countplot(train['Income_Verified'])","2a498281":"fig = plt.figure(figsize=(15,8))\nsns.countplot(train['Purpose_Of_Loan'])","a144cea6":"# Plot 'Debt_To_Income' histogram\ntrain['Debt_To_Income'].hist(bins = 50, color = 'blue')","f5162645":"# Plot 'Annual_Income' histogram\ntrain['Annual_Income'].hist(bins = 50, color = 'blue')","1edfdf89":"# Plot 'Months_Since_Deliquency' histogram\ntrain['Months_Since_Deliquency'].hist(bins = 50, color = 'blue')","9cd2b6dd":"# Plot 'Inquiries_Last_6Mo' histogram\ntrain['Inquiries_Last_6Mo'].hist(bins = 50, color = 'blue')","62f14185":"plt.figure(figsize = (15,10))\nax = sns.heatmap(train.corr(), annot = True)\nbottom, top = ax.get_ylim()\nax.set_ylim(bottom + 0.5, top - 0.5)","f1f7ae41":"feature_num = train.select_dtypes(include=[np.number])\nfeature_num.columns","2ec2dead":"feature_cat = train.select_dtypes(include=[np.object])\nfeature_cat.columns","a4c68dc3":"df = [train, test]","7c21c69c":"for dataset in df:\n    dataset.drop(['Loan_ID'], axis=1, inplace=True)","0e45b77e":"train[\"Length_Employed\"].fillna('NaN', inplace=True)\ntest[\"Length_Employed\"].fillna('NaN', inplace=True)\n\ntrain[\"Home_Owner\"].fillna('NaN', inplace=True)\ntest[\"Home_Owner\"].fillna('NaN', inplace=True)\n\ntrain[\"Income_Verified\"].fillna('NaN', inplace=True)\ntest[\"Income_Verified\"].fillna('NaN', inplace=True)\n\ntrain[\"Purpose_Of_Loan\"].fillna('NaN', inplace=True)\ntest[\"Purpose_Of_Loan\"].fillna('NaN', inplace=True)\n\ntrain[\"Gender\"].fillna('NaN', inplace=True)\ntest[\"Gender\"].fillna('NaN', inplace=True)\n\ntrain[\"Annual_Income\"].fillna(train[\"Annual_Income\"].mean(), inplace=True)\ntest[\"Annual_Income\"].fillna(test[\"Annual_Income\"].mean(), inplace=True)\n\ntrain[\"Months_Since_Deliquency\"].fillna(0, inplace=True)\ntest[\"Months_Since_Deliquency\"].fillna(0, inplace=True)","335d2d72":"test.isnull().sum().sort_values(ascending = False)","e6c0f9b6":"test.shape","f8a8cd3c":"test.isnull().sum().sort_values(ascending = False)","4a136a62":"train.shape","c1ba9ee4":"full = pd.concat([train, test])\nfull.shape","29d8b754":"full = pd.get_dummies(full, drop_first=True)\nfull.shape","a70604ea":"train = full.iloc[: 164309, :]\ntest = full.iloc[164309: , :]\ntest","c3943867":"from sklearn.model_selection import train_test_split\n\n# Here is out local validation scheme!\nX_train, X_test, y_train, y_test = train_test_split(train.drop(['Interest_Rate'], axis = 1), \n                                                    train['Interest_Rate'], test_size = 0.2, \n                                                    random_state = 2)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","675768f0":"# We'll use a logistic regression model again, but we'll go to something more fancy soon! \nfrom sklearn.linear_model import LogisticRegression\nlogisticRegression = LogisticRegression(max_iter = 10000)\nlogisticRegression.fit(X_train, y_train)\n","08e05300":"# Predict!\npredictions = logisticRegression.predict(X_test)\n# Print our preditions\nprint(predictions)","abfdc5de":"# Check mean\nround(np.mean(predictions), 2)","8001cfd8":"from sklearn.model_selection import KFold\n\n# Set our robust cross-validation scheme!\nkf = KFold(n_splits = 5, random_state = 2)","661b38a3":"from sklearn.model_selection import cross_val_score\n\n# Print our CV accuracy estimate:\n#print(cross_val_score(logisticRegression, X_test, y_test, cv = kf).mean())\ncross_val_score(logisticRegression, train.drop(['Interest_Rate'], axis = 1),train['Interest_Rate'], cv = kf).mean()","a27e3c1c":"from sklearn.ensemble import RandomForestClassifier\n\n#Initialize randomForest\nrandomForest = RandomForestClassifier(random_state = 2)","08ef4381":"# Define our optimal randomForest algo\nrandomForestFinalModel = RandomForestClassifier(random_state = 2, criterion = 'gini', \n                                                max_depth = 7, max_features = 'auto', n_estimators = 300)","20a0572c":"# Fit the model to the training set\nrandomForestFinalModel.fit(X_train, y_train)","a4ff5fbb":"# Predict!\npredictions = randomForestFinalModel.predict(X_test)","8463bcf7":"# Predict!\ntest['Interest_Rate'] = randomForestFinalModel.predict(test.drop(['Interest_Rate'], axis = 1))","91e978f9":"submission_sample = pd.read_csv('\/kaggle\/input\/janatahack-machine-learning-for-banking\/sample_submission_HSqiq1Q.csv')","cbee4fdc":"dataset = pd.DataFrame({\n    'Loan_ID': submission_sample['Loan_ID'],\n    'Interest_Rate': test['Interest_Rate']\n})","0ae60812":"dataset.to_csv('output.csv', index = False)","bd747fdc":"OK! The rule of thumb is that it is better to impute the missing values rather than ditch the features altogether. After all, there is still some info hidden in these features... After the following analysis, we will conclude that we can easily impute these missing values.","bfcf4b1f":"Hello everyone. Below is my approach to 'Machine Learning for Banking' posted as a competition at Analytics Vidhya which got me a rank 336 in the leaderboard.\n\nI hope any experienced person would have some great tips\/suggestions for me about my approach and I request you to please comment below about the same. It would be really helpful.","1dede8fb":"Number_Open_Accounts and Total_Accounts are highly correlated. But fortunately the correlations are pretty low, so we don't have to worry about high multicollinearity! ","3b96da11":"Quite informative, well, apart from the NaNs, but a good idea here would be to examine each feature separately, given that they are not too many!","f0f98a89":"Let's remember what happens with missing values...","0a183f3e":"# Problem Statement:\nThe process, defined as \u2018risk-based pricing\u2019, uses a sophisticated algorithm that leverages different determining factors of a loan applicant. Selection of significant factors will help develop a prediction algorithm which can estimate loan interest rates based on clients\u2019 information. On one hand, knowing the factors will help consumers and borrowers to increase their credit worthiness and place themselves in a better position to negotiate for getting a lower interest rate. On the other hand, this will help lending companies to get an immediate fixed interest rate estimation based on clients information. Here, your goal is to use a training dataset to predict the loan rate category (1 \/ 2 \/ 3) that will be assigned to each loan in our test set."}}