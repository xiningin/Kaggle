{"cell_type":{"80923761":"code","c65d446c":"code","822cecf8":"code","a140fb7d":"code","b8e4f487":"code","e0b34ff1":"code","f2e3721d":"code","067f7191":"code","be859184":"code","83c3efc4":"code","68506624":"code","b30a3299":"code","940d7e87":"code","97e11d8c":"code","5b890123":"code","a88625f9":"code","addcec25":"code","634920b2":"code","36a53c56":"code","6f37555d":"code","95ff6031":"code","124c62e7":"code","85249f4b":"code","ce25c3d6":"code","7ba31f7e":"code","2eb5e3db":"code","b482e47d":"code","e3b708e3":"code","d97b77e3":"code","914af13e":"code","5a590668":"code","9cdc0e42":"code","e1934251":"code","629d62c1":"code","59890af3":"code","9ccdf5a7":"code","0ad8b9d4":"code","fb0d1831":"code","20d392bb":"code","8d15bb61":"code","b1a83547":"code","56bd1321":"code","3219c257":"code","d1b05796":"code","12bb7e76":"code","5c658203":"code","7fd22009":"code","ece0dbc1":"code","fc31308b":"code","820305df":"code","a0e69651":"code","8e600148":"code","6bb5a706":"code","e46bc804":"code","45cdb641":"code","c8cbc2ae":"code","784ce821":"code","36449c25":"code","719d2cc8":"code","961fcb6c":"code","cd7f7959":"code","db78b629":"code","125f7a59":"code","40b0aa5a":"code","fc92bcc8":"code","f681d596":"code","875ea7dd":"code","e03b6843":"code","8249d112":"markdown","ee951e67":"markdown","dc3ae88e":"markdown","71f76370":"markdown","1f2cd8d7":"markdown","d6666344":"markdown","5c5544b0":"markdown","2ca5dcf4":"markdown","5f6a4427":"markdown","6faf92ec":"markdown"},"source":{"80923761":"import os","c65d446c":"input_data_path=os.path.join('..','input','data')\nstored_data_path = os.path.join('..','input','resnet-weights')\ncsv_filename='Data_Entry_2017.csv'","822cecf8":"import pandas as pd","a140fb7d":"all_xray_df = pd.read_csv(os.path.join(input_data_path,csv_filename))\nmask = all_xray_df['Finding Labels']!='No Finding' # set all 'No Finiding' labels to 0 and rest to 1\nctr = 0\nfor i in range(mask.shape[0]):\n    if mask[i]==0:\n        ctr+=1\n    if ctr%5==0:\n        mask[i]=1  # select every 5th 'No Finding' label\n# No Finding class reduced to 20%\nall_xray_df = all_xray_df[mask].copy(deep=True)","b8e4f487":"from glob import glob","e0b34ff1":"all_image_paths = {os.path.basename(f): f  for f in glob(os.path.join(input_data_path,'images*','*','*.png'))   }  \n# create a dict mapping image names to their path\nprint('Scans found:', len(all_image_paths), ', Total Headers', all_xray_df.shape[0])\nall_xray_df['path'] = all_xray_df['Image Index'].map(all_image_paths.get)\nall_xray_df.sample(3)","f2e3721d":"import matplotlib.pyplot as plt","067f7191":"# print the 15 most common labels in the column 'Finding Labels'\nlabel_counts = all_xray_df['Finding Labels'].value_counts()[:15]\nprint((label_counts))","be859184":"import numpy as np","83c3efc4":"fig, ax = plt.subplots(1,1,figsize = (12, 8))\nax.bar(np.arange(len(label_counts))+0.5, label_counts)\nax.set_xticks(np.arange(len(label_counts))+0.5)\n_ = ax.set_xticklabels(label_counts.index, rotation = 90)","68506624":"all_labels=set()\n# create a set of the names of all diseases","b30a3299":"def sep_diseases(x):\n    list_diseases=x.split('|')\n    for item in list_diseases:\n        all_labels.add(item)\n    return list_diseases","940d7e87":"# Since the image may contain multiple disease labels\n# Create a list of all disesases and append a new column named output to the x_ray dataframe\nall_xray_df['disease_vec']=all_xray_df['Finding Labels'].apply(sep_diseases)","97e11d8c":"all_labels=list(all_labels)\nall_labels.remove('No Finding')\nall_labels.sort()","5b890123":"disease_freq={}\nfor sample in all_xray_df['disease_vec']:\n    for disease in sample:\n        if disease in disease_freq:\n            disease_freq[disease]+=1\n        else:\n            disease_freq[disease]=1\nprint(disease_freq)","a88625f9":"fig,ax=plt.subplots(1,1,figsize=(12,8))\nplt.xticks(range(15),list(disease_freq.keys()), rotation = 90)\nfreq = np.array(list(disease_freq.values()))\npercent = freq\/np.sum(freq)\nax.bar(range(15),list(percent))","addcec25":"for label in all_labels:\n    all_xray_df[label]=all_xray_df['disease_vec'].apply(lambda x: float(label in x))","634920b2":"# Glimpse of the pre-processed dataframe\nall_xray_df.loc[:,'disease_vec':]","36a53c56":"from sklearn.model_selection import train_test_split","6f37555d":"# 15% of the data will be used for testing of model performance\n# random state is set so as to get the same split everytime\ntrain_df, test_df = train_test_split(all_xray_df,test_size = 0.15, random_state = 2020)\nprint('Number of training examples:', train_df.shape[0])\nprint('Number of validation examples:', test_df.shape[0])","95ff6031":"# execute just once\ntrain_df.to_csv('train_df.csv',index=False)\ntest_df.to_csv('test_df.csv',index=False)","124c62e7":"# once saved , use the following statements to load train and test dataframes subsequently\ntrain_df = pd.read_csv(os.path.join(stored_data_path,'train_df.csv'))\ntest_df = pd.read_csv(os.path.join(stored_data_path,'test_df.csv'))","85249f4b":"from tensorflow.keras.preprocessing.image import ImageDataGenerator","ce25c3d6":"#creating an Image Data generator\nIMG_SIZE = (128, 128)\ncore_idg = ImageDataGenerator(rescale=1.0\/255.0, validation_split = 0.06)","7ba31f7e":"# obtaing the training images using the above generator\ntrain_gen = core_idg.flow_from_dataframe(\n        dataframe=train_df,\n        directory=None,\n        x_col='path',\n        y_col=all_labels,\n        target_size=(128, 128),\n        batch_size=64,\n        class_mode='raw',\n        classes=all_labels,\n        shuffle=True,\n        color_mode = \"grayscale\",\n        subset='training')","2eb5e3db":"# obtaing the validation images using the above generator\nvalid_gen = core_idg.flow_from_dataframe(\n        dataframe=train_df,\n        directory=None,\n        x_col='path',\n        y_col=all_labels,\n        target_size=(128, 128),\n        batch_size=64,\n        class_mode='raw',\n        classes=all_labels,\n        shuffle=False,\n        color_mode = \"grayscale\",\n        subset='validation')","b482e47d":"def compute_freq(ground_labels):\n    num_samples = ground_labels.shape[0]\n    pos_samples = np.sum(ground_labels,axis=0)\n    neg_samples = num_samples-pos_samples\n    pos_samples = pos_samples\/float(num_samples)\n    neg_samples = neg_samples\/float(num_samples)\n    return pos_samples, neg_samples","e3b708e3":"import tensorflow.keras.backend as K","d97b77e3":"freq_pos , freq_neg = compute_freq(train_gen.labels)\nprint(freq_pos)\nprint(freq_neg)","914af13e":"# assign negative class frequency as positive class weights and vice versa\nweights_pos = K.constant(freq_neg,dtype='float32')\nweights_neg = K.constant(freq_pos,dtype='float32')\nepsilon=1e-7","5a590668":"# weighted loss function to handle class imbalance\ndef weighted_loss(y_true, y_pred):\n    loss = 0.0\n    loss_pos = -1 * K.sum( weights_pos * y_true * K.log(y_pred + epsilon), axis=-1)\n    loss_neg = -1 * K.sum( weights_neg * (1 - y_true) * K.log(1 - y_pred + epsilon) ,axis=-1)\n    return (loss_pos+loss_neg)\/len(all_labels)","9cdc0e42":"from tensorflow.keras import Model\nfrom tensorflow.keras.regularizers import l2\nfrom tensorflow.keras.layers import  Conv2D, BatchNormalization, Activation, Input, AveragePooling2D, Dense, Dropout, Flatten","e1934251":"def resnet_layer(inputs,\n                 num_filters=16,\n                 kernel_size=3,\n                 strides=1,\n                 activation='relu',\n                 batch_normalization=True,\n                 conv_first=True):\n    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n\n    # Arguments\n        inputs (tensor): input tensor from input image or previous layer\n        num_filters (int): Conv2D number of filters\n        kernel_size (int): Conv2D square kernel dimensions\n        strides (int): Conv2D square stride dimensions\n        activation (string): activation name\n        batch_normalization (bool): whether to include batch normalization\n        conv_first (bool): conv-bn-activation (True) or\n            bn-activation-conv (False)\n\n    # Returns\n        x (tensor): tensor as input to the next layer\n    \"\"\"\n    conv = Conv2D(num_filters,\n                  kernel_size=kernel_size,\n                  strides=strides,\n                  padding='same',\n                  kernel_initializer='he_normal',\n                  kernel_regularizer=l2(1e-4))\n\n    x = inputs\n    if conv_first:\n        x = conv(x)\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n    else:\n        if batch_normalization:\n            x = BatchNormalization()(x)\n        if activation is not None:\n            x = Activation(activation)(x)\n        x = conv(x)\n    return x","629d62c1":"import tensorflow as tf","59890af3":"def resnet_v2(input_shape, depth,num_classes):\n    \"\"\"ResNet Version 2 Model builder [b]\n\n    Stacks of (1 x 1)-(3 x 3)-(1 x 1) BN-ReLU-Conv2D or also known as\n    bottleneck layer\n    First shortcut connection per layer is 1 x 1 Conv2D.\n    Second and onwards shortcut connection is identity.\n    At the beginning of each stage, the feature map size is halved (downsampled)\n    by a convolutional layer with strides=2, while the number of filter maps is\n    doubled. Within each stage, the layers have the same number filters and the\n    same filter map sizes.\n    Features maps sizes:\n    conv1  : 32x32,  16\n    stage 0: 32x32,  64\n    stage 1: 16x16, 128\n    stage 2:  8x8,  256\n\n    # Arguments\n        input_shape (tensor): shape of input image tensor\n        depth (int): number of core convolutional layers\n        num_classes (int): number of classes (CIFAR10 has 10)\n\n    # Returns\n        model (Model): Keras model instance\n    \"\"\"\n    if (depth - 2) % 9 != 0:\n        raise ValueError('depth should be 9n+2 (eg 56 or 110 in [b])')\n    # Start model definition.\n    num_filters_in = 16\n    num_res_blocks = int((depth - 2) \/ 9)\n\n    inputs = Input(shape=input_shape)\n    # v2 performs Conv2D with BN-ReLU on input before splitting into 2 paths\n    x = resnet_layer(inputs=inputs,\n                     num_filters=num_filters_in,\n                     conv_first=True)\n\n    # Instantiate the stack of residual units\n    for stage in range(3):\n        for res_block in range(num_res_blocks):\n            activation = 'relu'\n            batch_normalization = True\n            strides = 1\n            if stage == 0:\n                num_filters_out = num_filters_in * 4\n                if res_block == 0:  # first layer and first stage\n                    activation = None\n                    batch_normalization = False\n            else:\n                num_filters_out = num_filters_in * 2\n                if res_block == 0:  # first layer but not first stage\n                    strides = 2    # downsample\n\n            # bottleneck residual unit\n            y = resnet_layer(inputs=x,\n                             num_filters=num_filters_in,\n                             kernel_size=1,\n                             strides=strides,\n                             activation=activation,\n                             batch_normalization=batch_normalization,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_in,\n                             conv_first=False)\n            y = resnet_layer(inputs=y,\n                             num_filters=num_filters_out,\n                             kernel_size=1,\n                             conv_first=False)\n            if res_block == 0:\n                # linear projection residual shortcut connection to match\n                # changed dims\n                x = resnet_layer(inputs=x,\n                                 num_filters=num_filters_out,\n                                 kernel_size=1,\n                                 strides=strides,\n                                 activation=None,\n                                 batch_normalization=False)\n            x = tf.keras.layers.add([x, y])\n\n        num_filters_in = num_filters_out\n\n    # Add classifier on top.\n    # v2 has BN-ReLU before Pooling\n    x = BatchNormalization()(x)\n    x = Activation('relu',name='last_activation_layer')(x)\n    x = AveragePooling2D(pool_size=8)(x)\n    y = Flatten()(x)\n    outputs = Dense(num_classes,\n                    activation='sigmoid',\n                    kernel_initializer='he_normal')(y)\n\n    # Instantiate model.\n    model = Model(inputs=inputs, outputs=outputs)\n    return model","9ccdf5a7":"multi_disease_model = resnet_v2((128,128,1),(9*6)+2,len(all_labels))\nmulti_disease_model.compile(optimizer = 'adam', loss = weighted_loss)\nmulti_disease_model.summary()","0ad8b9d4":"from tensorflow.keras.callbacks import ModelCheckpoint\ncheckpoint = ModelCheckpoint(\"resnet_weights_latest{epoch:02d}.h5\", verbose=1, save_weights_only = True)","fb0d1831":"initial_epoch = 0\nepochs = 30","20d392bb":"# start the training\nhist = multi_disease_model.fit(train_gen, initial_epoch = initial_epoch, epochs = epochs, callbacks = [checkpoint])","8d15bb61":"# save the loss on training set for all epochs\nnp.save('loss'+str(epochs)+'.npy',np.array(hist.history['loss']))","b1a83547":"import matplotlib.pyplot as plt\n%matplotlib inline","56bd1321":"val_loss = []\nfor i in range(30):\n    multi_disease_model.load_weights(os.path.join(stored_data_path,'weights_epoch_%02d.h5'%(i+1)))\n    cur_loss = multi_disease_model.evaluate(valid_gen, verbose = 1)\n    val_loss.append(cur_loss)\nnp.save('validation_loss.npy',np.array(val_loss))","3219c257":"training_loss = np.load(os.path.join(stored_data_path,'training_loss.npy'))\nval_loss = np.load(os.path.join(stored_data_path,'validation_loss.npy'))","d1b05796":"# plot loss on training and validation set\nfig , axis = plt.subplots(1,1,figsize = (9,6))\naxis.plot(range(1,training_loss.shape[0]+1),training_loss,label=\"training loss\")\naxis.plot(range(1,val_loss.shape[0]+1),val_loss,label=\"validation loss\")\naxis.legend()\nplt.xticks(range(1,training_loss.shape[0]+1))\nplt.xlabel('epoch')\nplt.ylabel('loss')\nplt.title('Loss')\nplt.show()\nfig.savefig('loss.png')","12bb7e76":"from sklearn.metrics import roc_curve, auc","5c658203":"def print_roc_curve(gen, model,filename):\n    pred_labels = model.predict(gen, verbose = 1)\n    fig, ax = plt.subplots(1,1, figsize = (9, 9))\n    auc_list = []\n    for (idx, class_label) in enumerate(all_labels):\n        fpr, tpr, thresholds = roc_curve(gen.labels[:,idx].astype(int), pred_labels[:,idx])\n        cur_auc = auc(fpr,tpr)\n        auc_list.append(cur_auc)\n        ax.plot(fpr, tpr, label = '%s (AUC:%0.2f)'  % (class_label, cur_auc))\n    ax.legend()\n    ax.set_xlabel('False Positive Rate')\n    ax.set_ylabel('True Positive Rate')\n    fig.savefig(filename)\n    auc_list = np.array(auc_list)\n    return auc_list","7fd22009":"auc_epochs = []","ece0dbc1":"print(\"Epoch 5\")\nmulti_disease_model.load_weights(os.path.join(stored_data_path,\"weights_epoch_05.h5\"))\nauc_5 = print_roc_curve(valid_gen, multi_disease_model,'val_set_roc_curve_epoch_05.png')\nauc_epochs.append(auc_5)","fc31308b":"print(\"Epoch 10\")\nmulti_disease_model.load_weights(os.path.join(stored_data_path,\"weights_epoch_10.h5\"))\nauc_10 = print_roc_curve(valid_gen, multi_disease_model,'val_set_roc_curve_epoch_10.png')\nauc_epochs.append(auc_10)","820305df":"print(\"Epoch 15\")\nmulti_disease_model.load_weights(os.path.join(stored_data_path,\"weights_epoch_15.h5\"))\nauc_15 = print_roc_curve(valid_gen, multi_disease_model,'val_set_roc_curve_epoch_15.png')\nauc_epochs.append(auc_15)","a0e69651":"print(\"Epoch 20\")\nmulti_disease_model.load_weights(os.path.join(stored_data_path,\"weights_epoch_20.h5\"))\nauc_20 = print_roc_curve(valid_gen, multi_disease_model,'val_set_roc_curve_epoch_20.png')\nauc_epochs.append(auc_20)","8e600148":"print(\"Epoch 25\")\nmulti_disease_model.load_weights(os.path.join(stored_data_path,\"weights_epoch_25.h5\"))\nauc_25 = print_roc_curve(valid_gen, multi_disease_model,'val_set_roc_curve_epoch_25.png')\nauc_epochs.append(auc_25)","6bb5a706":"print(\"Epoch 30\")\nmulti_disease_model.load_weights(os.path.join(stored_data_path,\"weights_epoch_30.h5\"))\nauc_30 = print_roc_curve(valid_gen, multi_disease_model,'val_set_roc_curve_epoch_30.png')\nauc_epochs.append(auc_30)","e46bc804":"auc_epochs =np.array(auc_epochs)\nx_labels = [5,10,15,20,25,30]\nfig , axis = plt.subplots(1,1,figsize = (9,6))\naxis.plot(x_labels,np.mean(auc_epochs,axis = 1),label=\"mean\")\naxis.plot(x_labels,np.median(auc_epochs,axis = 1),label=\"median\")\naxis.plot(x_labels,np.min(auc_epochs,axis = 1),label=\"min\")\naxis.plot(x_labels,np.max(auc_epochs,axis = 1),label=\"max\")\naxis.legend()\nplt.xticks(x_labels)\nplt.show()","45cdb641":"print(np.mean(auc_epochs,axis = 1))\nprint(np.median(auc_epochs,axis = 1))\nprint(np.min(auc_epochs,axis = 1))\nprint(np.max(auc_epochs,axis = 1))","c8cbc2ae":"# from the above graph, we can infer that the model generalises well at epoch 20\n# hence, we use model weights corresponding to epoch 20 for testing","784ce821":"test_idg = ImageDataGenerator(rescale=1.0\/255.0)\ntest_gen = test_idg.flow_from_dataframe(\n        dataframe=test_df,\n        directory=None,\n        x_col='path',\n        y_col=all_labels,\n        target_size=(128, 128),\n        batch_size=64,\n        classes=all_labels,\n        class_mode='raw',\n        color_mode = \"grayscale\",\n        shuffle=False)","36449c25":"multi_disease_model.load_weights(os.path.join(stored_data_path,\"weights_epoch_20.h5\"))\nauc_test = print_roc_curve(test_gen, multi_disease_model,'test_set_roc_curve.png')","719d2cc8":"np.save(\"test_set_auc.npy\",auc_test)\nprint(auc_test)","961fcb6c":"print(\"Model performance on Test data\")\nprint(\"min auc =\",np.min(auc_test))\nprint(\"max auc =\",np.max(auc_test))\nprint(\"mean auc = \",np.mean(auc_test))\nprint(\"median auc = \",np.median(auc_test))","cd7f7959":"from tensorflow.keras.preprocessing.image import img_to_array\nimport cv2","db78b629":"multi_disease_model.load_weights('..\/input\/resnet-weights\/weights_epoch_20.h5')\npred_test = multi_disease_model.predict(test_gen, verbose = 1)","125f7a59":"img_idx = [] #list of random indices\nimg_path = [] # list of random image paths corresponding to the above indices\nall_idx = list(range(test_df.shape[0])) \nfor i in range(len(all_labels)):\n    idx = np.random.choice(np.argsort(pred_test[:,i])[-100:])\n    print(idx,end=\" \")\n    img_idx.append(idx)\n    img_path.append(test_df.path.iloc[idx])","40b0aa5a":"img_array = []\nfor i in range(len(all_labels)) :\n  cur_path = img_path[i]\n  img = cv2.imread(cur_path,0)\n  img = cv2.resize(img,IMG_SIZE)\n  img_array.append(img_to_array(img,dtype='float32'))\nimg_array = np.array(img_array)\nprint(img_array.shape)","fc92bcc8":"def find_target_layer():\n  for layer in reversed(multi_disease_model.layers):\n    if len(layer.output_shape) == 4:\n      return layer.name","f681d596":"from tensorflow.keras import Model","875ea7dd":"def gen_heatmap(input_image,target_class):\n    target_layer = multi_disease_model.get_layer(find_target_layer())\n    gradModel = Model(inputs = [multi_disease_model.inputs],\n                      outputs = [target_layer.output, multi_disease_model.output])\n    with tf.GradientTape() as tape:\n        convOutputs, pred = gradModel(input_image)\n        loss = pred[:,target_class]\n    grads = tape.gradient(loss, convOutputs)           \n    # use automatic differentiation to compute the gradients\n    \n    castConvOutputs = tf.cast(convOutputs > 0, \"float32\")\n    castGrads = tf.cast(grads > 0, \"float32\")\n    guidedGrads = castConvOutputs * castGrads * grads  \n    # compute the guided gradients\n    \n    convOutputs = convOutputs[0]\n    guidedGrads = guidedGrads[0]\n    weights = tf.reduce_mean(guidedGrads, axis=(0, 1))\n    cam = tf.reduce_sum(tf.multiply(weights, convOutputs), axis=-1)\n    heatmap = cv2.resize(cam.numpy(), IMG_SIZE)\n    numer = heatmap - np.min(heatmap)\n    denom = (heatmap.max() - heatmap.min()) + epsilon  # normalize the heatmap such that all values lie in the range\n    heatmap = numer \/ denom                            # [0, 1], scale the resulting values to the range [0, 255]\n    heatmap = (heatmap * 255).astype(\"uint8\")          # and then convert to an unsigned 8-bit integer\n    return heatmap","e03b6843":"fig, axs = plt.subplots(4, 4,figsize=(16,16))\ni = 0\nj = 0\nfor k in range(len(all_labels)):\n    idx = img_idx[k]\n    target = np.argmax(pred_test[idx,:]) # select target class as the one with highest probability\n    heatmap = gen_heatmap(img_array[k:k+1],target)\n    axs[i,j].imshow(img_array[k,:,:,0].astype(\"uint8\"))\n    axs[i,j].imshow(heatmap,alpha=0.5)\n    axs[i,j].set_title(all_labels[target]+\" : \"+str(pred_test[idx,target]))\n    j+=1\n    if j==4:\n        i += 1\n        j = 0\nfig.savefig(\"xray_samples.png\")","8249d112":"## Visualising training","ee951e67":"## Splitting the dataset","dc3ae88e":"## Undersampling the majority class (\"No finding\" class)","71f76370":"## Visualisation","1f2cd8d7":"## Basic definitions","d6666344":"## Heat map using Grad Cam","5c5544b0":"## Creating model using Keras Functional Model","2ca5dcf4":"## Pre Processing","5f6a4427":"## Testing","6faf92ec":"## This work has been inspired from :\n\nhttps:\/\/www.kaggle.com\/kmader\/train-simple-xray-cnn\n\nhttps:\/\/www.coursera.org\/learn\/ai-for-medical-diagnosis\/home\/welcome\n\nhttps:\/\/www.pyimagesearch.com\/2020\/03\/09\/grad-cam-visualize-class-activation-maps-with-keras-tensorflow-and-deep-learning\/\n\n### The results and weights of this notebook are uploaded here : \nhttps:\/\/www.kaggle.com\/abhinavjain02\/resnet-weights"}}