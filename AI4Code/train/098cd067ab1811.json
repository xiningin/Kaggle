{"cell_type":{"dbdd244f":"code","534e6f83":"code","892cecac":"code","94fa567c":"code","cb2e1013":"code","32424391":"code","55a8be39":"code","cecc25b5":"code","8cf9d24a":"markdown","b4cad7dc":"markdown","34e8310d":"markdown","e24e718c":"markdown","1430d38b":"markdown","6e6562cc":"markdown"},"source":{"dbdd244f":"!pip install seaborn==0.11.1","534e6f83":"import pandas as pd \nimport numpy as np \nimport matplotlib.pyplot as plt\nimport seaborn as sns ","892cecac":"df_train = pd.read_csv(\"..\/input\/bri-data-hackathon-pa\/train.csv\")\ntarget_col = 'Best Performance'\nfeature_cols = df_train.drop(target_col, axis = 1).columns\n\n#simple cleaning\ndf_train.loc[df_train['GPA'] > 4.0, 'GPA'] = np.NaN\ndf_train.loc[df_train['GPA'] < 2.5, 'GPA'] = np.NaN\n","94fa567c":"displayed_cols = ['job_duration_in_current_person_level', 'person_level',\n                  'GPA', 'age',\n                 'Last_achievement_%', 'Achievement_above_100%_during3quartal']\n\nfig, ax = plt.subplots(3, 2, figsize=(18,15))\n\nfor col_index, col in enumerate(displayed_cols):\n    i = int(col_index \/ 2)\n    j = col_index % 2\n    sns.ecdfplot(ax=ax[i,j], data=df_train, x=col, hue=target_col)\n    \nplt.tight_layout()","cb2e1013":"df_train['dummy_col'] = 1\ndf_0 = df_train.loc[df_train[target_col] == 0]\ndf_1 = df_train.loc[df_train[target_col] == 1]","32424391":"def get_cumsum_mae(col_inspected):\n    cumsum_0 = df_0.groupby([col_inspected])[['dummy_col']].count().cumsum()\n    cumsum_0 = (cumsum_0 \/ len(df_0)).reset_index()\n    cumsum_1 = df_1.groupby([col_inspected])[['dummy_col']].count().cumsum()\n    cumsum_1 = (cumsum_1 \/ len(df_1)).reset_index()\n\n    cumsum_compare = cumsum_0.merge(cumsum_1, how = 'outer', on = col_inspected, suffixes=('_0', '_1')).\\\n                        sort_values(col_inspected).reset_index(drop = True).fillna(method='ffill').fillna(0)\n    return np.mean(np.abs(cumsum_compare['dummy_col_0'] - cumsum_compare['dummy_col_1']))","55a8be39":"df_features = pd.DataFrame()\ndf_features['feature_name'] = feature_cols\ndf_features['cumsum_diff_mean'] = df_features['feature_name'].map(get_cumsum_mae)\ndf_features.sort_values('cumsum_diff_mean', ascending = False)","cecc25b5":"displayed_cols = ['job_duration_in_current_branch', 'Last_achievement_%',\n                  'sick_leaves', 'job_level']\n\nfig, ax = plt.subplots(2, 2, figsize=(18,15))\n\nfor col_index, col in enumerate(displayed_cols):\n    i = int(col_index \/ 2)\n    j = col_index % 2\n    sns.ecdfplot(ax=ax[i,j], data=df_train, x=col, hue=target_col)\n    \nplt.tight_layout()","8cf9d24a":"Notebook ini di buat untuk melanjutkan thread mengenai label yang terlihat acak dan tidak berpola:\n\n1. [Restart Competition!](https:\/\/www.kaggle.com\/c\/bri-data-hackathon-people-analytic\/discussion\/208362)\n2. [Label Best Performance total random ?](https:\/\/www.kaggle.com\/c\/bri-data-hackathon-people-analytic\/discussion\/208348)\n\nApakah masih terjadi di data baru? \n* Ya masih terjadi (menurut saya, tapi mohon koreksi ya jika salah) \n\nDari mana inspeksi nya? \n* Coba kita plot distribusi yang label 0 dan 1 masing\" feature yuk. di sini saya pakai ecdf\n\nBacaan lebih lanjut mengenai ECDF \n* [What, Why, and How to Read Empirical CDF](https:\/\/towardsdatascience.com\/what-why-and-how-to-read-empirical-cdf-123e2b922480) (Semoga bermanfaat)\n\nApa impact nya jika label nya random? \n1. Mau fit model bagaimana pun, nilai data test tidak akan tinggi\" karena data tidak berpola\n2. Pemenang kompetisi ini juga akan random juga\n3. Yang terpenting adalah kita dapat belajar dan dapat ilmu baru mengenai pattern recognition dari data kompetisi dan melihat progress hari demi hari atas usaha kita. tapi itu tidak dapat di capai jika data nya seperti ini\n\nApa saran kedepan? \n1. Gunakan data asli, jika panitia cuma resuffle data test supaya tidak terjadi yang ini ([Data Test: 1000 baris terakhir adalah Best Performance = 1](https:\/\/www.kaggle.com\/c\/bri-data-hackathon-people-analytic\/discussion\/208270)) hanya menyelesaikan masalah tidak ada leaderboard yang score 1, tapi tidak membuat kompetisi ini seru dan bermakna (dan berguna bahkan __jika penyelenggara ingin mengaplikasikan nya__) \n\n**Tapi ini cuma obsevasi kecil dari saya, mungkin saya yang salah menafsirkan, mohon koreksi nya ya**","b4cad7dc":"ternyata feature yang paling menjadi pembeda antara Label 0 dan Label 0 adalah `job_duration_in_current_branch` , dan `Last_achievement_%` tapi itu hanya sekitar 1% (maksimal luas 100% jika feature sangat menjadi pembeda) \n","34e8310d":"Sangat sulit kemungkinan nya jika data asli memiliki distribusi seperti ini \n\n**tapi mohon masukan dan koreksi nya jika approach keliru dan ternyata label nya tidak random sama sekali**","e24e718c":"![](https:\/\/static.skaip.org\/img\/emoticons\/180x180\/f6fcff\/bow.gif \"bow\")","1430d38b":"mari kita plot lagi top 2 dan worst 2 nya ya","6e6562cc":"sebaran data nya sangat similar\n\nuntuk mengukur nya saya akan hitung approksimasi luas daerah dari selisih grafik warna biru (Label 0) dan orange (Label 1)"}}