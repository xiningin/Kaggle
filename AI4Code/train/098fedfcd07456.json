{"cell_type":{"3eef434f":"code","c54875a5":"code","c74f4a56":"code","f4b23a04":"code","e2f3b0b9":"code","cfac47bb":"code","ee3813b6":"code","61c564b0":"code","bc6c471e":"code","13317a8d":"code","a2e98572":"code","65e4a83d":"code","88d4e7a4":"code","3e4ecbf1":"code","3ceabc7e":"code","c8f4b7e2":"code","03d3f3dd":"code","9dedb91c":"code","3e2819ff":"markdown","5a4abc29":"markdown","e88cba45":"markdown","0c9b7162":"markdown","6b6d8e7e":"markdown","8aa44310":"markdown","a8d4a0cd":"markdown","27f758bd":"markdown","dfbc2e23":"markdown","286b1581":"markdown","76858cb9":"markdown","89494142":"markdown","692d18a0":"markdown"},"source":{"3eef434f":"from IPython.display import Image\nImage(\"..\/input\/cnnimag1\/CNN_Image1.png\")","c54875a5":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.datasets import fashion_mnist\nfrom  tensorflow.keras.utils import to_categorical,plot_model \nimport tensorflow as tf\n## Sometimes it takes Longer Just to Confirm all is done . \nprint(\"Import Done\")","c74f4a56":"mnist = tf.keras.datasets.mnist # Object of the MNIST dataset\n(xtrain, ytrain),(xtest, ytest) = mnist.load_data() # Load data\n## Lets Look at the Shape of Train and Test Dataset \nprint(xtrain.shape)\nprint(ytrain.shape)\nprint(xtest.shape)\nprint(ytest.shape)","f4b23a04":"idx=2\nplt.imshow(xtrain[idx], cmap=\"gray\") # Import the image\nprint(ytrain[idx])\nplt.show() # Plot the image","e2f3b0b9":"fig,axes= plt.subplots(nrows=4,ncols=5,figsize=(12,6))\naxes=axes.flatten()\nfor i,ax in zip(range(20),axes):\n    ax.imshow(xtrain[i],cmap='gray')\n    ax.set_title(ytrain[i])\n    ax.axis('off')\nplt.show()","cfac47bb":"print(xtrain.shape)\nprint(xtest.shape)\nxtrain=xtrain.reshape(60000,28,28,1)\nxtest=xtest.reshape(10000,28,28,1)\nprint(xtrain.shape)\nprint(xtest.shape)","ee3813b6":"# Scaling down Data\nxtrain=xtrain\/255\nxtest=xtest\/255","61c564b0":"## Idx is just a value can be changed from any value between 0 -59999 there are total 60,000 Image \nidx=10\nplt.imshow(xtrain[idx].reshape(28,28), cmap=\"gray\") # Import the image\nplt.title(ytrain[idx])  ## Put the Title of the Image . \nplt.show() # Plot the image","bc6c471e":"# Printing the ytest and ytrain output labels\nprint(ytest)\nprint(ytrain)","13317a8d":"## Printing Shape before and After the One Hot Encoding\nprint(ytrain.shape)\nprint(ytest.shape)\nytrain=to_categorical(ytrain)\nytest=to_categorical(ytest)\nprint(ytrain.shape)\nprint(ytest.shape)","a2e98572":"# Printing the labels for first 10 columns after one hot encoding . \nytrain[0:10]","65e4a83d":"from tensorflow.keras import models,layers\nfrom keras.layers import Dense, Dropout, Flatten ,BatchNormalization\n# Create Sequential Models\nmodel=models.Sequential()\n## Add the Layers for Convocalation \nmodel.add(layers.Conv2D(filters=10,kernel_size=(2,2),input_shape=(28,28,1),activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.10))\n## Add Second Conventional Layer to Model\nmodel.add(layers.Conv2D(filters=12,kernel_size=(2,2),activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.10))\nmodel.add(layers.Conv2D(filters=20,kernel_size=(2,2),activation='relu'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2)))\n#model.add(Dropout(0.10))\n## Adding Max Pooling Layer\n\n\n## Flattne Layer\nmodel.add(layers.Flatten())\n#model.add(Dropout(0.10))\n### Classification Segemention to the  \nmodel.add(layers.Dense(150,activation='relu'))\n#model.add(Dropout(0.10))\nmodel.add(layers.Dense(100,activation='relu'))\n#model.add(Dropout(0.10))\nmodel.add(layers.Dense(50,activation='relu'))\n#model.add(Dropout(0.10))\n########Output layer for \nmodel.add(layers.Dense(10,activation='softmax'))\n\n","88d4e7a4":"## Printing the Model \nplot_model(model)","3e4ecbf1":"## Printing the Summary of Model \nmodel.summary()","3ceabc7e":"# Model Compilation\n\nmodel.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])\nmodel.summary()","c8f4b7e2":"# Here we are fitting \nhistory=model.fit(xtrain, ytrain, epochs=22,batch_size=1000,verbose=True,validation_data=(xtest, ytest))","03d3f3dd":"plt.plot(history.history['accuracy'], label='accuracy')\nplt.plot(history.history['val_accuracy'], label = 'val_accuracy')\nplt.xlabel('Epoch')\nplt.ylabel('Accuracy')\nplt.ylim([0.5, 1])\nplt.title(\"Showing the Train Vs Test Accuracy\")\nplt.legend(loc='lower right')\n\ntest_loss, test_acc = model.evaluate(xtest,  ytest, verbose=2)","9dedb91c":"## Classification Report\nfrom sklearn.metrics import classification_report\ny_pred= model.predict_classes(xtest)\ny_pred2=to_categorical(y_pred)\n\nprint(classification_report(ytest,y_pred2))","3e2819ff":"# Importing Dataset in train and test .","5a4abc29":"# Let's Look at all the image the reason 20 image is printed to 0-9 the first set does not have all the images","e88cba45":"# Showing the Image of Number with their labels the Labels are stored in ytrain ","0c9b7162":"# The Image are reshaped to 28,28 as gray scale image expect 2*2 Matrix and we reshaped this earlier to \n1. To print we are just reshaping this back to 28 * 28 \n1. cmap=gray is required for printing the gray scale image the steps is required for only gray scale image.\n1. By Default imshow expects a colour image cmap is not required for colour image\n1. The print is show there is no change in data happend after scaling down . ","6b6d8e7e":"# Building the Fully Connected Neural Network . \n1. The First Layer is sequential layer \n1. Filter is no of Filter using for every layer different or same filter can be used . \n1. Here filter size is choosen as 2*2 we can change this to higher or lower value . \n1. For Higher Accuracy the filter size(Kernel_size) should be lower this would increase the training time which will come at the cost of accuracy . \n1. Activation function is relu which will take either positive value and conver 0 to all negative value . \n1. Flatten layer is pre-requisite for all CNN network where the 2 array is changed to 1 day array none of values are lost in this step.\n1. We have added Dense layer this can vary from dataset to dataset .\n1. For Output layer the activation function is softmax this is multiclass classification function for binary class sigmoid is preferred choice. ","8aa44310":"# We are fitting the Model here\n1. Epochs indicates the number of passes of the entire training dataset need back and forth.\n1. The batch size is the amount of samples you feed in your network \n1. Validattion data determines how your data showed be partitioned into training and validation sets.","a8d4a0cd":"## Domain Neural Network Using Convolutional neural network\n1.  98% Accuracy with CNN in Classifing 60,000 Images\n1. Objective : Classifying hand written Images .\n1. More information on dataset can be found here . http:\/\/yann.lecun.com\/exdb\/mnist\/\n1. There are 60,000 Train and 10000 Test Images train images have labels .","27f758bd":"# Thanks for completing ,If you like please UpVote.\n1. I feel i am still early learner all your comments are wellcome.\n1. Please click on name to view my profile\n* Notebook created by <a href = \"https:\/\/www.linkedin.com\/in\/narendrasharma\/\">Narendra Sharma<\/a>\n<hr>\n","dfbc2e23":"## Reshaping the image for CNN for gray scale image\n1. The images are added with added 1 byte for CNN .\n1. For Colour Image this steps is not required . ","286b1581":"# Let's Look at Train test Accuracy . \n1. Using the History inbuilt function we can test and train accuracy . ","76858cb9":"# One Hot Encoding \n1. ytrain and ytest has the output columns or labels \n1. For all CNN output columns with Multiclass this step is same \n1. This is not as same normal one hot encoding in machine learning the encoding will Create columns equal to no of Class . \n1. The steps are boiler plate code and can be copied for all cnn problem with multi class. ","89494142":"# Model Compliation . \n1. Optimizer is Adman update network weights iterative based in training data\n1. Categorical crossentropy is a loss function that is used in multi-class classification tasks\n1. Accuracy is one metric for evaluating classification models. Informally, accuracy is the fraction of predictions our model got right","692d18a0":"# Sclaing down the Image in 0 -1 the max value of image is 255 so dividing it by 255\n1. The output for Train and Test is would be between 0 -1 \n1. The step is not applicable for ytest or ytrain as they just contains the label"}}