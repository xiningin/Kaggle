{"cell_type":{"45d57413":"code","cd385a11":"code","6ea3ddce":"code","29bd4e7d":"code","f73bea9e":"code","4f8cc085":"code","8fd78e5e":"code","89237c91":"code","93a46558":"code","8fd189c9":"code","e11b0bfd":"code","32ad68c0":"code","feddf659":"code","fe82be42":"code","5490d51d":"code","7bf69bc0":"code","18ea12f2":"code","8fe30daf":"code","58d253e6":"code","831feda4":"code","a79a8842":"code","57740a2d":"code","ae13a78d":"code","845dcffa":"code","1b81a2ad":"code","d7e51eea":"code","1d8b9205":"code","e0c43f18":"code","d9d798ee":"code","96e9feb5":"code","3d68bfb0":"code","17e009a4":"code","83873f99":"code","91a72163":"code","6acf00c0":"code","bc3400f3":"code","362463be":"code","5b0132e8":"code","74284f93":"code","f0d53c10":"code","7878b43e":"code","c5459105":"code","414d3d7e":"code","648db591":"code","60f0a4cd":"code","6b849001":"code","b90ae8d2":"code","658ae9b9":"code","55adde35":"code","29531e33":"code","7e10f509":"code","d6abadfe":"code","6fac2e9c":"code","3cbe9dc7":"code","5e079404":"code","4ce69e69":"code","cb41f639":"code","7068bfcd":"code","9a36643c":"code","57ebd86a":"code","310dd6e3":"code","76dd8676":"code","f634768c":"code","aef0ad62":"code","7ba5fa88":"code","02deaede":"code","53e37903":"code","d673c9fd":"code","0df7d8fc":"code","e16b83b3":"code","e4879eac":"code","52a5aa9c":"code","391c71e0":"code","4d0bdf72":"code","2f668691":"code","43995ccb":"code","f9ac3480":"code","7f4ff0a9":"code","01380cee":"code","99612bfe":"code","c91bfb49":"code","ea61fed4":"code","db6b3659":"code","afc8dc22":"code","c02cb18a":"code","eb2481d4":"code","b07a520d":"code","9d1bbcf0":"code","9915c820":"code","3bc491ff":"code","56ce6e4c":"code","d8fe85d7":"code","e06cf046":"code","20734770":"code","df503a94":"code","5e9db5ac":"code","f49e2eff":"code","fb31fa68":"code","5c0a34bb":"code","d0df4025":"code","2e237b48":"markdown","ba251ed7":"markdown","342fd390":"markdown","ef0530ac":"markdown","aea46278":"markdown","c7d98541":"markdown","439491cf":"markdown","e48d12fc":"markdown","8020b4d2":"markdown"},"source":{"45d57413":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","cd385a11":"import pandas as pd\nimport numpy as np\nimport seaborn as sns\nimport matplotlib.pyplot as plt\n%matplotlib inline\n\n# Importing the dataset\ndf = pd.read_csv('\/kaggle\/input\/berlin-airbnb-data\/listings_summary.csv')\n","6ea3ddce":"df.columns","29bd4e7d":"df.head()","f73bea9e":"df","4f8cc085":"df.isnull().sum()","8fd78e5e":"df.info()","89237c91":"# let's drop  the unnesessary columns, it can vary and may sometime impact our \n# accuracy also, so be cautious while ddoing so\ndf.drop(['listing_url', 'scrape_id', 'last_scraped', 'experiences_offered', 'neighborhood_overview',\n        'transit', 'access', 'interaction', 'house_rules',\n       'thumbnail_url', 'medium_url', 'picture_url', 'xl_picture_url',\n       'host_about', 'host_id', 'host_url', 'host_name', 'host_since', 'host_location',\n       'host_acceptance_rate', 'host_thumbnail_url', 'host_picture_url', 'host_neighbourhood', 'host_listings_count',\n       'host_total_listings_count', 'host_verifications',\n       'host_has_profile_pic', 'host_identity_verified', 'street',\n       'neighbourhood', 'neighbourhood_cleansed', 'host_is_superhost',\n       'city', 'state', 'zipcode', 'market', 'weekly_price', 'monthly_price', \n       'smart_location', 'country_code', 'country','calendar_updated', 'has_availability',\n       'availability_30', 'availability_60', 'availability_90', 'instant_bookable',\n       'availability_365', 'calendar_last_scraped', 'number_of_reviews', 'is_location_exact',\n       'first_review', 'last_review', 'requires_license','maximum_nights',\n       'license', 'jurisdiction_names', 'require_guest_profile_picture', 'require_guest_phone_verification',\n       'review_scores_rating', 'review_scores_accuracy', 'review_scores_cleanliness',\n       'review_scores_checkin', 'review_scores_communication', 'review_scores_location', 'review_scores_value',\n       'calculated_host_listings_count', 'reviews_per_month', 'is_business_travel_ready', 'minimum_nights'],\n        axis=1, inplace=True)","93a46558":"# Checking whether there is any repeated or duplicate values\ndf.duplicated().sum()","8fd189c9":"# Checking the missing values \ndf.isnull().sum()","e11b0bfd":"# Setting 'id' as an index\ndf = df.set_index('id')","32ad68c0":"# Since above we found that there are many missing values in some columns\n# so dropping the columns with extremely high missing values\ndf.drop(['space', 'notes', 'square_feet', 'host_response_time', 'host_response_rate'],\n       axis = 1, inplace = True)","feddf659":"df.isna().sum()","fe82be42":"# Still we can see that there is many missing values in some columns so now\n# we will fill some of these missing values of columns\n# So lets replace the NaNs in bathrooms and bedrooms with 1 \ndf.bathrooms.fillna(1, inplace = True)\ndf.bedrooms.fillna(1, inplace = True)\n\n# we can replace the NaNa in beds by neighbour column 'accomodate'\n#df.beds.fillna(df['accomodates'], inplace = True)\n","5490d51d":"df.head()","7bf69bc0":"df['beds'].isnull().sum()","18ea12f2":"#we can replace the NaNa in beds by neighbour column 'accomodate'\ndf.beds.fillna(df['accommodates'], inplace = True)","8fe30daf":"# Communities deployment \nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nplt.figure(figsize = (10,5))\nsns.countplot(y = df['neighbourhood_group_cleansed'], order = df.neighbourhood_group_cleansed.value_counts().index)\nplt.xlabel(\"Quantity of listings\", fontsize = 'medium')\nplt.ylabel('')\nplt.title(\"Communities deployment\", fontsize = 'large')","58d253e6":"df['neighbourhood_group_cleansed']","831feda4":"df.neighbourhood_group_cleansed.value_counts().index","a79a8842":"# Property type deployment - TOP-10 types\nplt.figure(figsize = (15,5))\nsns.countplot(df['property_type'], order = df.property_type.value_counts().iloc[:10].index)\nplt.xlabel(\"\")\nplt.ylabel(\"Quantity of listings\", fontsize = 'large')\nplt.title(\"Property type\")","57740a2d":"# Room type deployment\nplt.figure(figsize = (5,5))\nsns.countplot(df['room_type'], order = df.room_type.value_counts(normalize = True).index)","ae13a78d":"# Cleaning (replace '$') and formatig price-related columns\ndf.price = df.price.str.replace('$', '').str.replace(',', '').astype(float)\n#df.security_deposit = df.security_deposit.str.replace('$', '').str.replace(',', '').astype(float)\n","845dcffa":"df.security_deposit = df.security_deposit.str.replace('$', '').str.replace(',', '').astype(float)\n","1b81a2ad":"df.cleaning_fee = df.cleaning_fee.str.replace('$', '').str.replace(',', '').astype(float)\ndf.extra_people = df.extra_people.str.replace('$', '').str.replace(',', '').astype(float)\n\n# NaNs in security_deposit and cleaning_fee seem to be 0\n#df.security_deposit.filna(0, inplace = True)\n#df.cleaning_fee.fillna(0, inplace = True)\n","d7e51eea":"# As we already have seen that there is NaNs in security_deposit and cleaning_fee\n# so lets fill them\ndf.security_deposit.fillna(0, inplace = True)\ndf.cleaning_fee.fillna(0, inplace = True)\n","1d8b9205":"df['security_deposit'].isnull().sum()","e0c43f18":"df['cleaning_fee'].isna().sum()","d9d798ee":"# Checking suspiciously low prices\nprint(df[(['price', 'name'])][df.price<10])","96e9feb5":"# Dropping rows with price < 8$\ndf = df.drop(df[df.price<8].index)","3d68bfb0":"# Now cheecking the price greater than $8 but less than 10\nprint(df[(['price', 'name'])][df.price<10])","17e009a4":"# Checking suspiciously high prices \ndf['price'].plot(kind = 'box', xlim = (0,600),vert = False, figsize = (16,1))","83873f99":"# Since high price are not  affordable for everyone so dropping the extremely \n# high price\n\ndf = df.drop(df[df.price > 380].index)","91a72163":"df.isnull().sum()","6acf00c0":"print(df[(['price', 'name'])][(df.price<80) & (df.price>20)])","bc3400f3":"# Extract number that may contain info re square of rooms from 'description' \n#columns (contains, 's\/m\/S\/M')\ndf['room_size'] = df['description'].str.extract(\"(\\d{2,3}\\s[smSM])\", expand = True)\ndf['room_size'] = df['room_size'].str.replace(\"\\D\", \"\").astype(float)\nrv = len(df) - df['room_size'].isna().sum()\nprint('Real values in \"room_size\" column:   ', rv)\nprint('Real values in \"room_size\" column (%):   ', round(rv\/len(df)*100, 1), '%')\n\n\n# (C) This cell of code was taken from the original research, done by Britta Bettendorf","362463be":"# Extract numbers that may contain info re square of rooms from 'name' columns\n# (contains 's\/m\/S\/M')\n\ndf['room_size_name'] = df['name'].str.extract(\"(\\d{2,3}\\s[smSM])\", expand = True)\ndf['room_size_name'] = df['room_size_name'].str.replace(\"\\D\", \"\").astype(float)\n\nrv = len(df) - df['room_size_name'].isna().sum()\nprint('Real values in \"room_size_name\" column:    ', rv)\nprint('Real values in \"room_size_name\" column(%):    ', round(rv\/len(df)*100, 1), '%')","5b0132e8":"df.room_size.fillna(0, inplace = True)","74284f93":"# Updatig column 'room_size' with values extracted from column 'name'\ndf.loc[df['room_size'] == 0, 'room_size'] = df['room_size_name']","f0d53c10":"# We don't needit any more\ndf.drop(['room_size_name'], axis = 1, inplace = True)","7878b43e":"# Checking suspiciously low sizes\nprint(df[(['room_size', 'name'])][(df.room_size < 10)])","c5459105":"# Dropping rows with  suspiciously low sizes\ndf = df.drop(df[df.room_size < 10].index)","414d3d7e":"# Checking suspiciously high sizes\ndf['room_size'].plot(kind = 'box', vert = False, figsize = (16,1))","648db591":"print(df[(['room_size', 'name'])][df.room_size > 250])","60f0a4cd":"# Dropping values of suspiciously high sizes\ndf.loc[df['room_size'] > 250, 'room_size'] = ''\ndf.room_size.replace(to_replace = '', value = np.nan, inplace = True)","6b849001":"# Wehave NaN's in our column, 2\/3 of all values\ndf.room_size.isna().sum()","b90ae8d2":"df.isna().sum()","658ae9b9":"# New df for further regression\ndf_temp = df[['neighbourhood_group_cleansed', 'accommodates', 'bathrooms', 'bedrooms',\n             'beds', 'price', 'security_deposit', 'cleaning_fee', 'guests_included',\n             'extra_people', 'room_size']]","55adde35":"print(df_temp.shape)\ndf_temp.head(10).transpose()","29531e33":"# Taking care of categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\ncategorical_cols = ['neighbourhood_group_cleansed']\ndf_temp[categorical_cols] = df_temp[categorical_cols].apply(lambda col: labelencoder_X.fit_transform(col.astype(str)))\ndf_temp.head(10).transpose()","7e10f509":"df['neighbourhood_group_cleansed'].unique().sum()","d6abadfe":"# Arranging datasets by existence of 'room_size' value\n\ntrain_set = df_temp[df_temp['room_size'].notnull()]\ntest_set = df_temp[df_temp['room_size'].isnull()]\n\n# Arranging X-taining and X-testing datasets\nX_train = train_set.drop('room_size', axis = 1)\nX_test = test_set.drop('room_size', axis = 1)\n\n# Arranging y-training datasets \ny_train = train_set['room_size']","6fac2e9c":"# Regression Model\nfrom sklearn.ensemble import RandomForestRegressor\nregressor = RandomForestRegressor(n_estimators = 300, random_state = 123)\nregressor.fit(X_train, y_train)\n\n# Predicting the Test set results\ny_pred = regressor.predict(X_test)","3cbe9dc7":"y_pred","5e079404":"# Introduction of predicted data to the main dataset 'df'\ny_pred = pd.DataFrame(y_pred)\ny_pred.columns = ['room_size']","4ce69e69":"temp_id = pd.DataFrame(X_test.index)\ntemp_id.columns = ['temp_id']\n\ny_pred = pd.concat([y_pred, temp_id], axis = 1)\ny_pred.set_index(['temp_id'], inplace = True)\n\ndf_pred = pd.concat([X_test, y_pred], axis = 1)\ndf_pred.head()","cb41f639":"df_pred.shape","7068bfcd":"train_set.shape","9a36643c":"df_temp = pd.DataFrame()\ndf_temp = pd.concat([df_pred, train_set], axis = 0)\nprint(df_temp.shape)\ndf_temp.head().transpose()","57ebd86a":"df_temp.head(10)","310dd6e3":"df_temp.head(10).transpose()","76dd8676":"X_test","f634768c":"X_train","aef0ad62":"y_pred","7ba5fa88":"train_set","02deaede":"test_set","53e37903":"df_temp","d673c9fd":"y_pred","0df7d8fc":"# Checking again suspiciously low sizes\nprint(df_temp[(['room_size'])][(df_temp.room_size<10)])","e16b83b3":"# Checking suspiciously high sizes\ndf_temp['room_size'].plot(kind = 'box', vert = False, figsize = (16,1))","e4879eac":"print(df.shape)","52a5aa9c":"df.head()","391c71e0":"df.head(2).transpose()","4d0bdf72":"print(df_temp.shape)\ndf_temp.head().transpose()","2f668691":"df = df[['property_type', 'amenities', 'cancellation_policy']]\nprint(df.shape)\ndf.isna().sum()","43995ccb":"df = pd.concat([df, df_temp], axis = 1)\nprint(df.shape)\ndf.head(3).transpose()","f9ac3480":"# Checking whether there is a null value or not in df\ndf.isna().sum()","7f4ff0a9":"import tensorflow as tf","01380cee":"# Let's explore amenities\npd.set_option('display.max_colwidth', -1)\ndf.amenities.head(5)","99612bfe":"# Let's introduce new column with score of amenities\ndf['amen_score'] = df['amenities'].str.count(',') + 1","c91bfb49":"# We don't need it any more\ndf.drop(['amenities'], axis = 1, inplace = True)","ea61fed4":"df['amen_score']","db6b3659":"df.head().transpose()","afc8dc22":"df.isna().sum()","c02cb18a":"# A separate copy for TF\ndf_tf = df.copy()","eb2481d4":"# Taking care of categorical data\nfrom sklearn.preprocessing import LabelEncoder\nlabelencoder_X = LabelEncoder()\ncategorical_cols = ['property_type', 'cancellation_policy']\ndf[categorical_cols] = df[categorical_cols].apply(lambda col: labelencoder_X.fit_transform(col.astype(str)))\ndf.head(10).transpose()","b07a520d":"# Creating DV and IV sets\nX = df.drop('price', axis = 1)\ny = df['price']\n\n# Splitting the dataset into the training set and test set\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.25, random_state = 123)","9d1bbcf0":"# Gradient Boosting Regression\nfrom sklearn.ensemble import GradientBoostingRegressor\nregressor = GradientBoostingRegressor(n_estimators = 100, max_depth = 3, min_samples_split = 2,\n                                      learning_rate = 0.1)\nregressor.fit(X_train, y_train)\n\n# Predicting the test set results\ny_pred = regressor.predict(X_test)\n\n# Finding the mean_sqaured error (MSE)\nfrom sklearn.metrics import mean_squared_error\nmse = mean_squared_error(y_test, y_pred)\n\n# Finding the r2 score or the variance (R2)\nfrom sklearn.metrics import r2_score\nr2 = r2_score(y_test, y_pred)\n\n# Applying k-fold Cross Validation\nfrom sklearn.model_selection import cross_val_score\naccuracies = cross_val_score(estimator = regressor, X = X_test, y = y_test, cv = 10)\n\n# Printing metrics \nprint(\"RMSE Error:\", round(np.sqrt(mse), 2))\nprint(\"R2 Score:\", round(r2, 4))\nprint(\"Mean Accuracy:\", round(accuracies.mean(), 2))\nprint(\"Std Deviation:\", round(accuracies.std(), 4))","9915c820":"import tensorflow as tf","3bc491ff":"# Creating DV and IV sets\nX_tf = df_tf.drop('price', axis = 1)\ny_tf = df_tf['price']\n\n# Splitting the datasets into the Training set and Test set\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X_tf, y_tf, test_size = 0.25,\n                                                   random_state = 123)","56ce6e4c":"# Feature columns\nproperty_type = tf.feature_column.categorical_column_with_hash_bucket('property_type', hash_bucket_size=50)\ncancellation_policy = tf.feature_column.categorical_column_with_hash_bucket('cancellation_policy', hash_bucket_size=10)\nneighbourhood_group_cleansed = tf.feature_column.numeric_column('neighbourhood_group_cleansed')\naccommodates = tf.feature_column.numeric_column('accommodates')\nbathrooms = tf.feature_column.numeric_column('bathrooms')\nbedrooms = tf.feature_column.numeric_column('bedrooms')\nbeds = tf.feature_column.numeric_column('beds')\nsecurity_deposit = tf.feature_column.numeric_column('security_deposit')\ncleaning_fee = tf.feature_column.numeric_column('cleaning_fee')\nguests_included = tf.feature_column.numeric_column('guests_included')\nroom_size = tf.feature_column.numeric_column('room_size')\namen_score = tf.feature_column.numeric_column('amen_score')","d8fe85d7":"emb_property_type = tf.feature_column.embedding_column(property_type, dimension = 33)\nemb_cancellation_policy = tf.feature_column.embedding_column(cancellation_policy, dimension = 5)","e06cf046":"feat_cols = [emb_property_type, emb_cancellation_policy, neighbourhood_group_cleansed, accommodates, bathrooms,\n            bedrooms, beds, security_deposit, cleaning_fee, guests_included, room_size, amen_score]\n","20734770":"# Input function\nfrom tensorflow_core.estimator import inputs\ninput_func =  tf.compat.v1.estimator.inputs.pandas_input_fn(x=X_train,y=y_train,batch_size=100,num_epochs=1000,shuffle=True)","df503a94":"# Creating and training model\nmodel = tf.estimator.DNNRegressor(hidden_units = [12,12,12], feature_columns = feat_cols)\n","5e9db5ac":"model.train(input_fn = input_func, steps = 1000)","f49e2eff":"pred_input_func = tf.compat.v1.estimator.inputs.pandas_input_fn(x = X_test, batch_size = 10, num_epochs = 1, shuffle = False)","fb31fa68":"predictions = list(model.predict(pred_input_func))","5c0a34bb":"y_pred = []\nfor i in predictions:\n    y_pred.append(i['predictions'][0])","d0df4025":"from sklearn.metrics import mean_squared_error\ntf_mse = mean_squared_error(y_test, y_pred)\nprint(\"MSE Error:\", round(tf_mse, 2))\nprint(\"RMSE Error:\", round(np.sqrt(tf_mse), 2))","2e237b48":"so we can see that there is no NaNs in cleaning_fee and security deposit now","ba251ed7":"Above output indicates that there is no duplicate values in our dataset after deleting the unnecessary columns","342fd390":"**Tensor Flow DNN_Regressor**","ef0530ac":"**Amenities score introduction**","aea46278":"**'price' and other money related columns**","c7d98541":"**Extracting and Working out data re room size**","439491cf":"Let's drop the columns that are not necessary","e48d12fc":"**Gradient Boosting**","8020b4d2":"*Every columns is now non empty*"}}