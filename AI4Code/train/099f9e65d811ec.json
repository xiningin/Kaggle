{"cell_type":{"05b39289":"code","3435e61a":"code","8b2b7d32":"code","fa8e0989":"code","fbc36df0":"code","6beba3b9":"markdown"},"source":{"05b39289":"# Based on https:\/\/www.kaggle.com\/markwijkhuizen\/petfinder-cats-and-dogs-inference-naive-baseline\n\n# Hacky way of loading YOLOV5 offline, don't try this at home\n# Add YOLOV5 master to cache\n!cp -R '\/kaggle\/input\/yolov5\/torch\/root\/.cache\/torch' '\/root\/.cache\/torch'\n# Add Ultralytics (whatever this is) to the config folder\n!cp -R '\/kaggle\/input\/yolov5\/ultralytics\/root\/.config\/Ultralytics' '\/root\/.config\/Ultralytics'\n\nimport sys\nsys.path.append('..\/input\/timm-pytorch-image-models\/pytorch-image-models-master')\nsys.path.append('\/kaggle\/input')\n\nimport torch\nfrom timm import create_model\nfrom timm.data.mixup import Mixup\nimport imageio\nimport gc\nfrom sklearn.metrics import mean_squared_error\nfrom fastai.vision.all import *\n\nset_seed(1, reproducible=True)\nBATCH_SIZE = 32\nNEED_TRAIN = False\n\nclean_dataset_path = Path('..\/input\/pawpularity-train-manipulated01')\nclean_dataset_path.ls()\n\ndataset_path = Path('..\/input\/petfinder-pawpularity-score-clean')\ndataset_path.ls()\n\ndataset_path2 = Path('..\/input\/petfinder-pawpularity-score\/')\ndataset_path2.ls()\n\ntrain_df = pd.read_csv(clean_dataset_path\/'pawpularity_train_manipulated.csv')\ntrain_df.head()\n\ntrain_df['path'] = train_df['Id'].map(lambda x:str(dataset_path\/'train'\/x)+'.jpg')\n\n# Drop Metadata and ID\ndropped = ['Id', 'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory',\n       'Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur']\ntrain_df = train_df.drop(columns=dropped)\n\ntrain_df = train_df.sample(frac=1).reset_index(drop=True) #shuffle dataframe\n\nfeatures = ['Pawpularity',\n        'cat', 'dog', 'neither']\n\ntrain_df[features] = train_df[features].astype('int')\ntrain_df.head()\n\nlen_df = len(train_df)\nprint(f\"There are {len_df} images\")\n\ntrain_df['Pawpularity'].hist(figsize = (10, 5))\nprint(f\"The mean Pawpularity score is {train_df['Pawpularity'].mean()}\")\nprint(f\"The median Pawpularity score is {train_df['Pawpularity'].median()}\")\nprint(f\"The standard deviation of the Pawpularity score is {train_df['Pawpularity'].std()}\")\n\nprint(f\"There are {len(train_df['Pawpularity'].unique())} unique values of Pawpularity score\")\n\ntrain_df['norm_score'] = train_df['Pawpularity']\/100\ntrain_df['norm_score']\n\nim = Image.open(train_df['path'][1])\nwidth, height = im.size\nprint(width,height)\n\nim\n\nif not os.path.exists('\/root\/.cache\/torch\/hub\/checkpoints\/'):\n    os.makedirs('\/root\/.cache\/torch\/hub\/checkpoints\/')\n!cp '..\/input\/swin-transformer\/swin_large_patch4_window7_224_22kto1k.pth' '\/root\/.cache\/torch\/hub\/checkpoints\/swin_large_patch4_window7_224_22kto1k.pth'\n\nseed=12\nset_seed(seed, reproducible=True)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms = True\n\n#Sturges' rule\nnum_bins = int(np.floor(1+np.log2(len(train_df))))\nnum_bins\n\ntrain_df['bins'] = pd.cut(train_df['norm_score'], bins=num_bins, labels=False)\ntrain_df['bins'].hist()\n\n#from sklearn.model_selection import KFold\nfrom sklearn.model_selection import StratifiedKFold\n\ntrain_df['fold'] = -1\n\nN_FOLDS = 10\nstrat_kfold = StratifiedKFold(n_splits=N_FOLDS, random_state=seed, shuffle=True)\nfor i, (_, train_index) in enumerate(strat_kfold.split(train_df.index, train_df['bins'])):\n    train_df.iloc[train_index, -1] = i\n    \ntrain_df['fold'] = train_df['fold'].astype('int')\n\ntrain_df.fold.value_counts().plot.bar()\n\ntrain_df[train_df['fold']==0].head()\n\ntrain_df[train_df['fold']==0]['bins'].value_counts()\n\ntrain_df[train_df['fold']==1]['bins'].value_counts()","3435e61a":"def petfinder_rmse(input,target):\n    return 100*torch.sqrt(F.mse_loss(F.sigmoid(input.flatten()), target))\n\ndef get_data(fold):\n    train_df_f = train_df.copy()\n    # add is_valid for validation fold\n    train_df_f['is_valid'] = (train_df_f['fold'] == fold)\n    \n    # It looks if seed of RandomSplitter is set, it reduce the score. So we don't set seed here\n    splitter = RandomSplitter(0.2)\n    # Change RandomSplitter to IndexSplitter\n    splitter = IndexSplitter(splitter(range(len(train_df)))[1])\n    dls = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                get_x=ColReader('path'),\n                get_y=ColReader('norm_score'),\n                splitter=splitter,\n                item_tfms=Resize(224), #pass in item_tfms\n                batch_tfms=setup_aug_tfms([Flip()])\n               )\n    paw_dls = dls.dataloaders(train_df_f, \n                          bs=BATCH_SIZE,\n                          num_workers=8,\n                          seed=seed)\n    \n    return paw_dls, splitter\n\ndef get_learner(fold_num):\n    data, splitter = get_data(fold_num)\n    \n    model = create_model('swin_large_patch4_window7_224', pretrained=True, num_classes=data.c)\n\n    learn = Learner(data, model, loss_func=BCEWithLogitsLossFlat(), opt_func = partial(OptimWrapper, opt=torch.optim.AdamW), metrics=petfinder_rmse, cbs=[MixUp(0.4)]).to_fp16()\n    \n    return learn, splitter","8b2b7d32":"def add_labels(df):\n    df[['cat', 'dog', 'neither']] = 0\n    ohe = []\n    for idx, path in zip(itertools.count(), df['path'].values):\n        img = imageio.imread(path)\n        result = yolov5(img)\n        labels = result.pandas().xyxy[0]['name'].values\n        found_label = False\n        for label in labels:\n            if label == 'cat':\n                ohe.append([1,0,0])\n                found_label = True\n                break\n            elif label == 'dog':\n                ohe.append([0,1,0])\n                found_label = True\n                break\n        if not found_label:\n            ohe.append([0,0,1])\n            \n    df[['cat', 'dog', 'neither']] = ohe\n    return df\n\nyolov5 = torch.hub.load('ultralytics\/yolov5', 'yolov5x6')","fa8e0989":"test_df = pd.read_csv(dataset_path2\/'test.csv')\ntest_df.head()\n\nif len(test_df) != 8:\n    NEED_TRAIN = True\n\ntest_df['Pawpularity'] = [1]*len(test_df)\ntest_df['path'] = test_df['Id'].map(lambda x:str(dataset_path2\/'test'\/x)+'.jpg')\ntest_df = test_df.drop(columns=dropped)\nadd_labels(test_df)\n\ntrain_df['norm_score'] = train_df['Pawpularity']\/100","fbc36df0":"# Clear Yolov5 model\ntorch.cuda.empty_cache()\ngc.collect()\n\nif NEED_TRAIN:\n    all_preds = []\n    train_df['pred'] = -1\n\n    for i in range(N_FOLDS):\n\n        print(f'Fold {i} results')\n\n        learn, splitter = get_learner(fold_num=i)\n\n        learn.fit_one_cycle(5, 2e-5, cbs=[SaveModelCallback(), EarlyStoppingCallback(monitor='petfinder_rmse', comp=np.less, patience=2)]) \n\n        learn.recorder.plot_loss()\n\n        learn.export(f'model_fold_{i}.pkl')\n\n        dls = DataBlock(blocks=(ImageBlock, RegressionBlock),\n                    get_x=ColReader('path'),\n                    get_y=ColReader('norm_score'),\n                    splitter=RandomSplitter(0.2),\n                    item_tfms=Resize(224), #pass in item_tfms\n                    batch_tfms=setup_aug_tfms([Flip()])\n                   )\n\n        paw_dls = dls.dataloaders(train_df, \n                              bs=BATCH_SIZE,\n                              num_workers=8,\n                          seed=seed)\n        \n        test_dl = paw_dls.test_dl(test_df)\n\n        preds, _ = learn.tta(dl=test_dl, n=5, beta=0)\n\n        all_preds.append(preds)\n        \n        val_idx = splitter(range(len(train_df)))[1]\n        val_df = train_df.loc[val_idx]\n        val_pred, _ = learn.tta(dl=paw_dls.test_dl(val_df), n=5, beta=0)\n        print(val_df['Pawpularity'][:5], val_pred[:5])\n        score = mean_squared_error(val_df['Pawpularity'], val_pred*100, squared=False)\n        print(f'Fold {i} | Score: {score}')\n        # Save prediction of validation as pred\n        train_df.loc[val_idx, 'pred'] = val_pred*100\n\n        del learn\n\n        torch.cuda.empty_cache()\n\n        gc.collect()\n        \n        #Only run one fold for public train as we don't have so many GPU time\n        if len(test_df) == 8:\n            break\n    if len(test_df) == 8:\n        cv_score = mean_squared_error(train_df.loc[train_df['pred']!=-1, 'Pawpularity'], \n                                      train_df.loc[train_df['pred']!=-1, 'pred'], squared=False)\n        print(f'CV Score: {cv_score}')\n\nif NEED_TRAIN:\n    all_preds, np.mean(np.stack(all_preds*100))\n\nsample_df = pd.read_csv(dataset_path2\/'sample_submission.csv')\nif NEED_TRAIN:\n    preds = np.mean(np.stack(all_preds), axis=0)\n    sample_df['Pawpularity'] = preds*100\nsample_df.to_csv('submission.csv',index=False)\n\nif not NEED_TRAIN:\n    pd.read_csv('submission.csv').head()","6beba3b9":"**PublicScore\u306f17.82846\u3067\u3059\u3002**\n\n**PrivateScore\u306f17.06212\u3067\u3059\u3002**"}}