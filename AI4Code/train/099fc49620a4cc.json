{"cell_type":{"e53e1279":"code","dcf00582":"code","3edb9036":"code","44ba72b4":"code","9e085170":"code","03631d21":"code","75fd1931":"code","274c5aa1":"code","50a29567":"code","ce1f8f70":"code","e6dea68d":"code","126601cd":"code","9aeb5004":"code","81f2aaf3":"code","056e6b6e":"code","e188ca8b":"code","16dfb39c":"code","13bdfaf5":"code","b5c5a543":"code","cd4721d9":"code","4d1b51b9":"code","64a96118":"code","955dfacc":"code","54fc8dfa":"code","52cd966a":"code","9e17e1d3":"code","bfa84d54":"code","775c9b62":"markdown","fb0737f6":"markdown","75b55d43":"markdown","396b5765":"markdown","31630fd2":"markdown","c852b668":"markdown","5b0c246f":"markdown","5d8ec3dd":"markdown","ed19d7d5":"markdown","bdeda6de":"markdown","67a6fb1f":"markdown","6d34f47f":"markdown","d249050c":"markdown","c066960c":"markdown"},"source":{"e53e1279":"import json\n\nimport pandas as pd\nimport numpy as np\nimport plotly.express as px\nimport tensorflow.keras.layers as L\nimport tensorflow as tf\nfrom sklearn.model_selection import train_test_split\nimport matplotlib.pyplot as plt","dcf00582":"tf.random.set_seed(19)\nnp.random.seed(19)","3edb9036":"# This will tell us the columns we are predicting\npred_cols = ['reactivity', 'deg_Mg_pH10', 'deg_Mg_50C', 'deg_pH10', 'deg_50C']","44ba72b4":"y_true = tf.random.normal((32, 68, 3))\ny_pred = tf.random.normal((32, 68, 3))","9e085170":"def MCRMSE(y_true, y_pred):\n    colwise_mse = tf.reduce_mean(tf.square(y_true - y_pred), axis=1)\n    return tf.reduce_mean(tf.sqrt(colwise_mse), axis=1)","03631d21":"def gru_layer(hidden_dim, dropout):\n    return L.Bidirectional(L.GRU(\n        hidden_dim, dropout=dropout, return_sequences=True, kernel_initializer='orthogonal'))","75fd1931":"def pandas_list_to_array(df):\n    \"\"\"\n    Input: dataframe of shape (x, y), containing list of length l\n    Return: np.array of shape (x, l, y)\n    \"\"\"\n    \n    return np.transpose(\n        np.array(df.values.tolist()),\n        (0,2, 1)\n    )","274c5aa1":"def preprocess_inputs(df, token2int, cols=['sequence', 'structure', 'predicted_loop_type','seq_loop']):\n    return pandas_list_to_array(\n        df[cols].applymap(lambda seq: [token2int[x] for x in seq])\n    )","50a29567":"def addExtraCol(df):\n    seq_list=list(df['sequence'])\n    pre_list=list(df['predicted_loop_type'])\n    seq_loop_list=[]\n    for i in range(len(seq_list)):\n        tmp=''\n        for j in range(len(seq_list[i])):\n            tmp=tmp+merged_seq[seq_list[i][j]+pre_list[i][j]]\n        seq_loop_list.append(tmp)\n\n    df['seq_loop']=seq_loop_list\n    return df","ce1f8f70":"data_dir = '\/kaggle\/input\/stanford-covid-vaccine\/'\ntrain = pd.read_json(data_dir + 'train.json', lines=True)\ntest = pd.read_json(data_dir + 'test.json', lines=True)\nsample_df = pd.read_csv(data_dir + 'sample_submission.csv')","e6dea68d":"Sequence=['A', 'G', 'U', 'C']\nPredicted_loop_types= ['S','M','I','B','H','E','X']\nchars='abcdefghijklmnopqrstuvwxyz12'\nmerged_seq={}\ni=0\nfor s in Sequence:\n    for p in Predicted_loop_types:\n        merged_seq[s+p]=chars[i]\n        i=i+1\n        \nprint(merged_seq)","126601cd":"train.head()","9aeb5004":"train.shape","81f2aaf3":"train = train.query(\"signal_to_noise >= 1\")\ntrain.shape","056e6b6e":"train=addExtraCol(train)\ntrain.head()","e188ca8b":"# We will use this dictionary to map each character to an integer\n# so that it can be used as an input in keras\ntoken2int = {x:i for i, x in enumerate('().ACGUBEHIMSX')}\nprint(len(token2int))\n\ni=14\nfor k,v in merged_seq.items():\n    token2int[v]=i\n    i=i+1\n    \n    \nprint(token2int)\n\ntrain_inputs = preprocess_inputs(train, token2int)\ntrain_labels = pandas_list_to_array(train[pred_cols])","16dfb39c":"train_inputs.shape","13bdfaf5":"x_train, x_val, y_train, y_val = train_test_split(\n    train_inputs, train_labels, test_size=.1, random_state=34, stratify=train.SN_filter)","b5c5a543":"test=addExtraCol(test)\npublic_df = test.query(\"seq_length == 107\")\nprivate_df = test.query(\"seq_length == 130\")\n\n\npublic_inputs = preprocess_inputs(public_df, token2int)\nprivate_inputs = preprocess_inputs(private_df, token2int)","cd4721d9":"def build_model(embed_size, \n                seq_len=107, \n                pred_len=68, \n                dropout=0.4, \n                sp_dropout=0.2,\n                embed_dim=200, \n                hidden_dim=256, \n                n_layers=3):\n    \n    inputs = L.Input(shape=(seq_len, 4))\n    embed = L.Embedding(input_dim=embed_size, output_dim=embed_dim)(inputs)\n    \n    reshaped = tf.reshape(\n        embed, shape=(-1, embed.shape[1],  embed.shape[2] * embed.shape[3])\n    )\n    hidden = L.SpatialDropout1D(sp_dropout)(reshaped)\n    \n    for x in range(n_layers):\n        hidden = gru_layer(hidden_dim, dropout)(hidden)\n    \n    # Since we are only making predictions on the first part of each sequence, \n    # we have to truncate it\n    truncated = hidden[:, :pred_len]\n    out = L.Dense(5, activation='linear')(truncated)\n    \n    model = tf.keras.Model(inputs=inputs, outputs=out)\n    model.compile(tf.optimizers.Adam(learning_rate=0.0025,\n    beta_1=0.8,\n    beta_2=0.999,\n    epsilon=1e-07), loss=MCRMSE)\n    \n    return model","4d1b51b9":"tf.keras.backend.clear_session()\nmodel = build_model(embed_size=len(token2int))\nmodel.summary()","64a96118":"history = model.fit(\n    x_train, y_train,\n    #sample_weight=x_train_sn,\n    validation_data=(x_val, y_val),\n    batch_size=64,\n    epochs=70,\n    verbose=2,\n    callbacks=[\n        tf.keras.callbacks.ReduceLROnPlateau(patience=5),\n        tf.keras.callbacks.ModelCheckpoint('model.h5')\n    ]\n)","955dfacc":"fig = px.line(\n    history.history, y=['loss', 'val_loss'],\n    labels={'index': 'epoch', 'value': 'MCRMSE'}, \n    title='Training History')\nfig.show()","54fc8dfa":"# Caveat: The prediction format requires the output to be the same length as the input,\n# although it's not the case for the training data.\nmodel_public = build_model(seq_len=107, pred_len=107, embed_size=len(token2int))\nmodel_private = build_model(seq_len=130, pred_len=130, embed_size=len(token2int))\n\nmodel_public.load_weights('model.h5')\nmodel_private.load_weights('model.h5')","52cd966a":"public_preds = model_public.predict(public_inputs)\nprivate_preds = model_private.predict(private_inputs)","9e17e1d3":"preds_ls = []\n\nfor df, preds in [(public_df, public_preds), (private_df, private_preds)]:\n    for i, uid in enumerate(df.id):\n        single_pred = preds[i]\n\n        single_df = pd.DataFrame(single_pred, columns=pred_cols)\n        single_df['id_seqpos'] = [f'{uid}_{x}' for x in range(single_df.shape[0])]\n\n        preds_ls.append(single_df)\n\npreds_df = pd.concat(preds_ls)\npreds_df.head()","bfa84d54":"submission = sample_df[['id_seqpos']].merge(preds_df, on=['id_seqpos'])\nsubmission.to_csv('submission.csv', index=False)","775c9b62":"Public and private sets have different sequence lengths, so we will preprocess them separately and load models of different tensor shapes. This is possible because RNN models can accept sequences of varying lengths as inputs.","fb0737f6":"## Load and preprocess data","75b55d43":"Public and private sets have different sequence lengths, so we will preprocess them separately and load models of different tensor shapes.","396b5765":"## Build and train model\n\nWe will train a bi-directional GRU model. It has three layer and has dropout. To learn more about RNNs, LSTM and GRU, please see [this blog post](https:\/\/colah.github.io\/posts\/2015-08-Understanding-LSTMs\/).","31630fd2":"**Adding new coolum seq_loop which pairwise string of sequence and predicted loop type**","c852b668":"For each sample, we take the predicted tensors of shape (107, 5) or (130, 5), and convert them to the long format (i.e. $629 \\times 107, 5$ or $3005 \\times 130, 5$):","5b0c246f":"## Helper functions and useful variables","5d8ec3dd":"## Evaluate training history\n\nLet's use Plotly to quickly visualize the training and validation loss throughout the epochs.","ed19d7d5":"## Load models and make predictions","bdeda6de":"## Set seed to ensure reproducibility","67a6fb1f":"**This is based on [this notebook](https:\/\/www.kaggle.com\/xhlulu\/openvaccine-simple-gru-model) by [xhlulu](https:\/\/www.kaggle.com\/xhlulu) and added few functions. Here I have combined 2 new features, sequence and predicted loop type.**\n\n**Example: Sequence='xyz...' predicte_loop_type='abc....' then new feature is 'xaybzc...' where xa,yb, zc is tokenized. This could have potential positive impact in training if merged sequence have better correlation with the reactivity and deg_* variables. In coming days I will be experimenting with more merge feature.**","6d34f47f":"\n[](http:\/\/)","d249050c":"**Sequence has 4 unique chracters and predicted loop types contains 7 unique character. We can use characters abcde....xyz12 to reprsent 28 characters**","c066960c":"## Post-processing and submit"}}