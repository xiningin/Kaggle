{"cell_type":{"cb3bc689":"code","240d45bb":"code","f969d9e7":"code","92e0a6c5":"code","05a608c6":"code","e0297789":"code","f8021594":"code","065fb8ab":"code","878181e1":"code","5cb254bd":"code","88c53acb":"code","d337be50":"code","e82b63a8":"code","220f8eb9":"code","1077ea19":"code","19db3275":"code","bddf8923":"code","3ff970b8":"code","b90feed1":"markdown","f2bc6856":"markdown","30441d33":"markdown","df150289":"markdown","88fe7c7a":"markdown","923772a4":"markdown","806b5477":"markdown","353f18a9":"markdown","39f65f76":"markdown","16f849da":"markdown","6b12777a":"markdown","6b15c62d":"markdown","16a16b79":"markdown","3812162a":"markdown","498e6609":"markdown","aeac4e1f":"markdown","76ac3ac4":"markdown","ae826705":"markdown","81c5ded8":"markdown","53724743":"markdown","de613136":"markdown","d320042a":"markdown","209a14b8":"markdown","9ec84a71":"markdown","62fb0948":"markdown","5872fe58":"markdown","d6a56ac9":"markdown","f7a06b88":"markdown","83c67aa3":"markdown","b60af4d4":"markdown","a5758c5c":"markdown","6604b8f3":"markdown","762834e1":"markdown","7a78c6cd":"markdown","af8b81ab":"markdown","b657cf7a":"markdown","143ed1e9":"markdown","73439635":"markdown","be5bb1df":"markdown","c9b33388":"markdown","448d8999":"markdown","8aee4ee3":"markdown","563e6110":"markdown"},"source":{"cb3bc689":"from tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D\nfrom tensorflow.keras.layers import Activation, Dense, Flatten, Dropout\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.callbacks import ModelCheckpoint\nfrom tensorflow.keras import backend as K\nfrom tensorflow.keras.preprocessing.image import array_to_img, img_to_array, load_img\nfrom sklearn.datasets import load_files\nimport matplotlib.image as mpimg\nimport numpy as np\n%matplotlib inline\nimport matplotlib.pyplot as plt\nfrom keras.utils import np_utils","240d45bb":"img = mpimg.imread('..\/input\/fruits\/fruits-360\/Training\/Apple Red 1\/101_100.jpg')\nprint(img.shape)\nplt.imshow(img)","f969d9e7":"img = mpimg.imread('..\/input\/fruits\/fruits-360\/Training\/Cherry Wax Black\/101_100.jpg')\nprint(img.shape)\nplt.imshow(img)","92e0a6c5":"import os, os.path\ntrain_categories = []\ntrain_samples = []\nfor i in os.listdir(\"..\/input\/fruits\/fruits-360\/Training\/\"):\n    train_categories.append(i)\n    train_samples.append(len(os.listdir(\"..\/input\/fruits\/fruits-360\/Training\/\"+ i)))\n\ntest_categories = []\ntest_samples = []\nfor i in os.listdir(\"..\/input\/fruits\/fruits-360\/Test\/\"):\n    test_categories.append(i)\n    test_samples.append(len(os.listdir(\"..\/input\/fruits\/fruits-360\/Test\/\"+ i)))\n\n    \nprint(\"Count of Fruits in Training set:\", sum(train_samples))\nprint(\"Count of Fruits in Set set:\", sum(test_samples))","05a608c6":"figure_size = plt.rcParams[\"figure.figsize\"]\nfigure_size[0] = 40\nfigure_size[1] = 20\nplt.rcParams[\"figure.figsize\"] = figure_size\nindex = np.arange(len(train_categories))\nplt.bar(index, train_samples)\nplt.xlabel('Fruits', fontsize=25)\nplt.ylabel('Count of Fruits', fontsize=25)\nplt.xticks(index, train_categories, fontsize=15, rotation=90)\nplt.title('Distrubution of Fruits with counts in Training Set', fontsize=35)\nplt.show()","e0297789":"index2 = np.arange(len(test_categories))\nplt.bar(index2, test_samples)\nplt.xlabel('Fruits', fontsize=25)\nplt.ylabel('Count of Fruits', fontsize=25)\nplt.xticks(index2, test_categories, fontsize=15, rotation=90)\nplt.title('Distrubution of Fruits with counts in Test Set', fontsize=35)\nplt.show()","f8021594":"train_dir = '..\/input\/fruits\/fruits-360\/Training\/'\ntest_dir = '..\/input\/fruits\/fruits-360\/Test\/'\n\ndef load_dataset(data_path):\n    data_loading = load_files(data_path)\n    files_add = np.array(data_loading['filenames'])\n    targets_fruits = np.array(data_loading['target'])\n    target_labels_fruits = np.array(data_loading['target_names'])\n    return files_add,targets_fruits,target_labels_fruits\n    \nx_train, y_train,target_labels = load_dataset(train_dir)\nx_test, y_test,_ = load_dataset(test_dir)","065fb8ab":"no_of_classes = len(np.unique(y_train))\nno_of_classes","878181e1":"y_train = np_utils.to_categorical(y_train,no_of_classes)\ny_test = np_utils.to_categorical(y_test,no_of_classes)\ny_train[0]","5cb254bd":"x_test,x_valid = x_test[7000:],x_test[:7000]\ny_test,y_vaild = y_test[7000:],y_test[:7000]\nprint('Vaildation X : ',x_valid.shape)\nprint('Vaildation y :',y_vaild.shape)\nprint('Test X : ',x_test.shape)\nprint('Test y : ',y_test.shape)","88c53acb":"def convert_image_to_array_form(files):\n    images_array=[]\n    for file in files:\n        images_array.append(img_to_array(load_img(file)))\n    return images_array\n\nx_train = np.array(convert_image_to_array_form(x_train))\nprint('Training set shape : ',x_train.shape)\n\nx_valid = np.array(convert_image_to_array_form(x_valid))\nprint('Validation set shape : ',x_valid.shape)\n\nx_test = np.array(convert_image_to_array_form(x_test))\nprint('Test set shape : ',x_test.shape)\n\nprint('1st training image shape ',x_train[0].shape)\n","d337be50":"x_train = x_train.astype('float32')\/255\nx_valid = x_valid.astype('float32')\/255\nx_test = x_test.astype('float32')\/255","e82b63a8":"def tensorflow_based_model():\n    model = Sequential() #step 1\n    model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same')) #step2\n    model.add(Activation('relu'))  # step3\n    model.add(MaxPooling2D(pool_size=2)) #step4\n    model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same')) #repeating step 2 and step3 but with more filters of 32\n    model.add(MaxPooling2D(pool_size=2)) #repeating step 4 again\n    model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same')) #repeating step 2 and step3 but with more filters of 64\n    model.add(MaxPooling2D(pool_size=2)) #repeating step 4 again\n    model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same')) #repeating step 2 and step3 but with more filters of 64\n    model.add(MaxPooling2D(pool_size=2)) #repeating step 4 again\n    model.add(Dropout(0.3)) # step5\n    model.add(Flatten()) #step 6\n    model.add(Dense(150)) #step 7\n    model.add(Activation('relu')) # setp 3\n    model.add(Dropout(0.4)) # step 5\n    model.add(Dense(81,activation = 'softmax')) # setp3 and step7. but this time, we are using activation function as softmax (if we train on two classes then we set sigmoid)\n    return model #function returning the value when we call it","220f8eb9":"model = tensorflow_based_model() # here we are calling the function of created model\nmodel.compile(loss='categorical_crossentropy', optimizer='rmsprop', metrics=['accuracy']) ","1077ea19":"history = model.fit(x_train,y_train,\n        batch_size = 32,\n        epochs=30,\n        validation_data=(x_valid, y_vaild),\n        verbose=2, shuffle=True)","19db3275":"acc_score = model.evaluate(x_test, y_test) #we are starting to test the model here\nprint('\\n', 'Test accuracy:', acc_score[1])","bddf8923":"predictions = model.predict(x_test)\nfig = plt.figure(figsize=(16, 9))\nfor i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n    ax.imshow(np.squeeze(x_test[idx]))\n    pred_idx = np.argmax(predictions[idx])\n    true_idx = np.argmax(y_test[idx])\n    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n                 color=(\"green\" if pred_idx == true_idx else \"red\"))","3ff970b8":"plt.figure(1)  \nplt.subplot(211)  \nplt.plot(history.history['acc'])  \nplt.plot(history.history['val_acc'])  \nplt.title('model accuracy')  \nplt.ylabel('accuracy')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.subplot(212)  \nplt.plot(history.history['loss'])  \nplt.plot(history.history['val_loss'])  \nplt.title('model loss')  \nplt.ylabel('loss')  \nplt.xlabel('epoch')  \nplt.legend(['train', 'test'], loc='upper left')  \nplt.show()","b90feed1":"<b> <h3> Inputs : <\/h3><\/b>  Inputs are the data that we feed into machine learning like in this project images are the inputs. ","f2bc6856":"<b> <h3> Validation Data <\/h3><\/b>  We use validation data while training the model. We use this data to evalaute the performance that how the model perform on training time.","30441d33":"# Vector of the ytrain first record","df150289":"# Sample images","88fe7c7a":"# Visualization with prediction \n- We are using the trained model and getting predictions on the test data\n- Outside the bracket are the predictions names of the fruits\n- Inside the bracket are the true label names of the fruits","923772a4":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>Data Preprocessing<\/strong><\/center><\/h2>\n        \n<\/div>","806b5477":"- <h5> After converting the images into arrays form, the features\/pixels ranges are from 0 to 255. We are scalling the features\/pixels from 0-255 to 0-1 range.<\/h5>\n- <h5> Why we are doing this?<\/h5>\n- <h5> By doing this, we can reduce the training time. Because we can also feed the same features but when the model will train so it take more time by calculating the values from 0-255 than 0-1. That is why we are scalling the features.<\/h5>","353f18a9":"# Features scalling from 0-255 to 0-1","39f65f76":"- <h3> Till now the data is just images. We need to convert them into arrays form for the training and testing because machine learning model only undertsand the numeric data so we have to convert the images into arrays form. <\/h3>","16f849da":"<h4>To install the python library is very easy<\/h4>\n- pip install name_of_library \n<h5> Like if you wanted to install tensorflow? <\/h5>\n- pip install tensforflow","6b12777a":"# Classes of fruits","6b15c62d":"# Accuracy score on the test data","16a16b79":"<h4> We are uisng the following versions of the libraries:<\/h4>\n\n- numpy == 1.18.5 \n\n- tensorflow ==1.7.0\n\n- keras == 2.4.3\n\n- matplotlib ==3.3.2\n","3812162a":"<div class=\"alert alert-block alert-danger\">  \n    <h1><strong>\ud83d\udc68\u200d\ud83d\udcbb Getting Started with Image\/fruits Recognition \ud83d\udc4d<\/strong><\/h1>\n    <i><\/i>\n<\/div>","498e6609":"<h4> Step 1<\/h4>\n- We are calling base Sequancial model for training and for further tuning of parameters on image data. We must call it when we work on the keras, tensorflow based libraries.\n\n<h4> Step 2<\/h4>\n- Conv2D is 2D convolutional layer(where filters are applied to original image with specific features map to reduce the number of features), Conv2D layer create the convolution kernel(fixed size of boxes to apply on the image like below in the example gif) that take input of 16 filters which help to produce a tensor of outputs. We are giving input of the image with size of 100 width and 100 height and 3 is the channel for RGB.\n<img src=\"https:\/\/miro.medium.com\/max\/1320\/1*DTTpGlhwkctlv9CYannVsw.gif\">\n\n\n<h4> Step 3<\/h4>\n- Activation function is node that is put at the end of all layers of neural network model or in between neural network layers. Activation function help to decide which neuron should be pass and which neuron should fire. So activation function of node defines the output of that node given an input or set of inputs. \n<img src=\"https:\/\/missinglink.ai\/wp-content\/uploads\/2018\/11\/activationfunction-1.png\">\n\n<h4> Step 4<\/h4>\n- Maxpooling is a pooling operation that calculates maximum value in each patch of each feature map. It takes the value from input vectors and prepare the vector for the next layers.\n<img src=\"https:\/\/developers.google.com\/machine-learning\/practica\/image-classification\/images\/maxpool_animation.gif\">\n\n<h4> Step 5<\/h4>\n- Droupout layer drop some neurons from previous layers. why we apply this? We apply this to avoid the overfitting problems. In overfitting, model give good accuracy on training time but not good on testing time.\n<img src=\"https:\/\/drek4537l1klr.cloudfront.net\/elgendy\/v-3\/Figures\/Img_01-04A_171.gif\">\n\n<h4> Step 6<\/h4>\n- Flatten layer convert the 2D array into 1D array of all features.\n<img src=\"https:\/\/sds-platform-private.s3-us-east-2.amazonaws.com\/uploads\/73_blog_image_1.png\">\n\n<h4> Step 7<\/h4>\n- Dense layer reduce the outputs by getting inputs from Faltten layer. Dense layer use all the inputs of previous layer neurons and perform calculations and send 150 outputs\n","aeac4e1f":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>Importing Python Libraries \ud83d\udcd5 \ud83d\udcd7 \ud83d\udcd8 \ud83d\udcd9<\/strong><\/center><\/h2>\n        \n<\/div>","76ac3ac4":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>Loading the data \ud83d\udcc1 \ud83d\udcc2 and Spliting the dataset into training and testing with label names<\/strong><\/center><\/h2>\n        \n<\/div>","ae826705":"<div class=\"alert alert-block alert-info\">  \n<h1><strong>Introduction<\/strong><\/h1>\n    <p>Computer vision methods and strategies can help to recognize the fruits with some basic\nfeatures like the color of fruits, intensity of fruits ,shape of fruits and texture of the\nfruits. The term \"recognize\" is to predict the name of the fruit. In this project, we are going to use 81 different fruits claases. We will train the model using tensorflow. <\/p>\n    <br>\n        <hr>\n      <b>Problem description: <\/b> \n    <hr>\n<ul>\n    <li>To build a robust system to recognize the fruits according to the color of fruits, intensity of fruits ,shape of fruits and texture of the\nfruits.<\/li>\n<\/ul>\n\n\n<hr>\n<b>Evolution measures: <\/b> \n<hr>\n<ul>\n<p> After training the model, we will apply the evaluation measures to check that how the model is getting predictions. We will use the following evaluation measures to evaluate the performance of the model:<\/p>\n    <li>Accuracy<\/li>\n    <li>Plots of training and validation scores<\/li>\n<\/ul>\n<hr>\n<b>Technical Approach<\/b>\n<hr>\n<p>We are using python language in the implementations and Jupyter Notebook that support the machine learning and data science projects. We will build tensorflow based model. We will use Fruits360 dataset. The dataset providers provide the training and test data separately. After training on the model, we will evaluate the model to check the performance of trained model.<\/p>\n \n<hr>\n<b>Source of Data: <\/b> \n<hr> \n <a href=\"https:\/\/data.mendeley.com\/datasets\/rp73yg93n8\/1\">https:\/\/data.mendeley.com\/datasets\/rp73yg93n8\/1<\/a>\n   \n<\/div>","81c5ded8":"- We are splitting the test data into validation data. Validation data will be used while training the model to check the performance during training and test data will be used after training the model.","53724743":"# <img src=\"https:\/\/i.ytimg.com\/vi\/AArJbDKEaQM\/maxresdefault.jpg\">","de613136":"- Exploration of data is not neccessory for training the model but its a good practice to look at the dataset so that we can analyse that what type of data we are using and how we can handle it.","d320042a":"# Distrubution of Fruits with counts in Test Set","209a14b8":"# Visualization the loss and accuracy with respect to epochs\n- We are looking at the history of the model of each epoch as we trained our model on 30 epochs.\n- Blue line shows the training accuarcy and also the training loss.\n- Orange line shows the Testing accuarcy and also the testing loss.\n- Accuracy and loss on the train and test data start from zero and finally close to 1 (100%).","9ec84a71":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>Exploratory data analysis \ud83d\udd0e \ud83d\udcca<\/strong><\/center><\/h2>\n        \n<\/div>","62fb0948":"- Libraries are important and we call them to perform the different actions on our data and for training the models.\n- Its a first step to load the library to perform the specific task","5872fe58":"- Accuracy is the number of correctly recognized images from all the images. \n- For example, if the trained model recognize the 90 images correct and 10 images wrong from total of 100 images then the accuracy score will be 90%. \n- Accuracy= Total number of correct predictions\/Total number of predictions","d6a56ac9":"<div class=\"alert alert-block alert-success\">  \n<h1><center><strong>Conclusion \ud83d\udcdd<\/strong><\/center><\/h1>\n    <p>\n<li>We used the fruits360 dataset and explored the data with different ways.<\/li>\n        <li>We prepared the the images data and extract the features.<\/li>\n          <li>We trained model based on tensorflow with all settings. <\/li>\n        <li>We evaluated thye model with accuracy and look at the performance of the model with plots.<\/li>\n         <li>If you are interested to work on any image based project, prepare the data as we prepared in this project and there could be some changes in the code like number of classes or loss function.<\/li>\n            <li>We worked on the classification problem and sepcifically we call it multi class classification because we are using in total 81 classes of fruits.<\/li>\n        <\/p>\n<\/div>","f7a06b88":"<h1> We need to do all the above configurations to train the model. If we will not set all settings correctly then we could not get the desired results.<\/h1>","83c67aa3":"- First we are calling the model\n- We are using 81 classes so we set loss as \"categorical_crossentropy\". We use loss as \"binary_crossentropy\" for two classes. \n- Optimizer is a function that used to change the features of neural network such as learning rate (how the model learn with features) in order to reduce the losses. So the learning rate of neural network to reduce the losses is defined by optimizer. \n- We are setting metrics=accuracy because we are going to caluclate the percentage of correct predictions over all predictions on the validation set","b60af4d4":"# Distrubution of Fruits with counts in Training Set","a5758c5c":"- 81 are labels\/classes which are the names of fruits because we are using fruits of 81 types.","6604b8f3":"# Now, we have to divide the validation set into test and validation set","762834e1":"<h4>How we can install the libraries in python?<\/h4>","7a78c6cd":"<b> <h3> Testing Data <\/h3><\/b>  We use testing data after training the model. We use this data to evalaute the performance that how the model perform after training. So in this way first we get predictions from the trained model without giving the labels and then we compare the true labels with predictions and get the performance of th model..","af8b81ab":"<b> <h3> Training Data <\/h3><\/b>  We use training data when we train the models. We feed train data to machine learning and deep learning models so that model can learn from the data.","b657cf7a":"# Training the model with parameter tuning\n- We are feeding the training data and validation data to start training of model.\n* We set the following parameters:\n- Batch size =32 so the model take 80 images in each iteration and train them. Batch size is a term used in machine learning and refers to the number of training examples utilized in one iteration. \n- Epochs =30 so the model will train on the data 30 times.Epoch is a term used in machine learning and indicates the number of passes of the entire training dataset the machine learning algorithm has completed.\n- We can choose batch_size, and epochs as we want so the good practice is to set some values and train the model if the model will not give the good results we can change it and then try again for the training of the model. We can repeat this process many time untill we will not get the good results and this process called as parameter tuning.","143ed1e9":"<div class=\"alert alert-block alert-info\">  \n    <p>\n<h1>I hope you like my efforts for Kaggle Community. Thanks \ud83d\ude0d<\/h1>\n        <\/p>\n<\/div>","73439635":"<div class=\"alert alert-block alert-danger\">  \n<h2><center><strong>Implementing Tensorflow based model for training \ud83e\uddea<\/strong><\/center><\/h2>   \n<\/div>","be5bb1df":"- We are loading all training and testing data \n- Saving inputs\/images in x_train of training data and saving labels in y_train\n- Saving inputs\/images in x_test of testing data and saving labels in y_test","c9b33388":"- As we know that we are using 81 classes\/labels, so we created a vector of 81 values. \n- We can see that there is only 1 and all are zero's that is showing a label of first image.","448d8999":"<b> <h3> Labels : <\/h3><\/b>  Labels are the targets like in this project names of the fruits are labels. ","8aee4ee3":"# Model compilation","563e6110":"# Training and Testing data Information"}}