{"cell_type":{"6c99b421":"code","f8747beb":"code","4b701aaf":"code","980ca065":"code","5c463bb1":"code","59e8656f":"code","0425efa5":"code","69b475ff":"code","ab544efd":"code","8533c27b":"code","fa0d1d29":"code","48350850":"code","adb98f5b":"code","fed98a45":"code","3d3d0d58":"code","20593960":"code","efb84dda":"code","1596b2cd":"code","8784d92a":"code","bfefadd3":"code","45c644c8":"code","409470b6":"code","3a1732a6":"code","d6c51f8c":"code","fff1e027":"code","4dabb6e3":"code","08926769":"code","bbeb64cb":"code","ed823ead":"code","ec62af13":"code","d16e0d2b":"code","065220ee":"code","72cd6f76":"code","7d3d0d78":"code","9a0a6022":"code","85f479f3":"code","fffe19a6":"code","81903c79":"code","95014441":"code","59a45944":"code","5fb7e346":"code","e52f39a5":"code","10739e36":"code","7bc9218d":"code","025e495d":"code","d4e8565f":"code","7b2f4657":"code","753f8e81":"code","214780be":"code","d3810e65":"code","9a6e28fc":"code","4136eeec":"code","fb7406d5":"code","92463789":"code","fcac6e45":"markdown","cca45d9d":"markdown","9a650a8e":"markdown","d73fad4f":"markdown","1b508ebd":"markdown","5abd24fe":"markdown","a6672cb0":"markdown","e6c1442c":"markdown","81bfe333":"markdown","7e1a78d9":"markdown","626b9d17":"markdown","b133af1a":"markdown","573ad85f":"markdown","915701f5":"markdown","1eb44c49":"markdown","82874283":"markdown","513c0d22":"markdown"},"source":{"6c99b421":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","f8747beb":"id_train=pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")\nid_test=pd.read_csv(\"\/kaggle\/input\/titanic\/test.csv\")","4b701aaf":"id_train.head()","980ca065":"id_train.drop([\"Name\",\"PassengerId\",'Cabin'],axis=1,inplace=True)\nid_test.drop([\"Name\",'Cabin'],axis=1,inplace=True)\n\nprint(id_train.isnull().sum())\nid_test.isnull().sum()","5c463bb1":"print(id_train.Sex.value_counts())\nprint(id_test.Sex.value_counts())\n\nid_train['Sex']=id_train['Sex'].replace(['male','female'],[1,0])\nid_test['Sex']=id_test['Sex'].replace(['male','female'],[1,0])","59e8656f":"print(id_train.info())\nprint(id_test.info())","0425efa5":"id_train.describe()\n\n## includez only non object type column","69b475ff":"id_train.describe(include=['O'])","ab544efd":"id_train['Pclass'].value_counts()\n\n## many passengers were in the 3rd class\n## and less in 1st class","8533c27b":"## lets see the survival rate with sex,SidSp, Parch and plcass with survived","fa0d1d29":"id_train[['Sex','Survived']].groupby(['Sex']).mean().sort_values(by='Survived')\n\n## 0 is female\n## 1 is male","48350850":"id_train[['SibSp','Survived']].groupby(['SibSp']).mean().sort_values(by='Survived',ascending=False)\n\n## less the number of siblings onboard, more the probability of survival","adb98f5b":"id_train[['Parch','Survived']].groupby(['Parch']).mean().sort_values(by='Survived',ascending=False)\n\n## more the children : less the survival probability","fed98a45":"id_train[['Pclass','Survived']].groupby(['Pclass']).mean().sort_values(by='Survived',ascending=False)\n\n## better the class : more the survival chances","3d3d0d58":"import seaborn as sns\nimport matplotlib.pyplot as plt\n\nv = sns.FacetGrid(id_train,col='Survived')\nv.map(plt.hist,'Age',bins=15)","20593960":"v = sns.FacetGrid(id_train,row='Survived',col='Pclass')\nv.map(plt.hist,'Age',bins=15)","efb84dda":"\nv = sns.FacetGrid(id_train,col='Embarked')\nv.map(sns.pointplot,'Pclass','Survived','Sex',palette='deep')\nv.add_legend()\n\n## 0 is female\n## 1 is male","1596b2cd":"v=sns.FacetGrid(id_train,col='Embarked',row='Survived')\nv.map(sns.barplot,'Sex','Fare')","8784d92a":"## from above observations, Age and Cabin have null value.\n## lets fill those Na values by mean\n\nid_train['Age'].fillna(id_train['Age'].mean(),inplace=True)\nid_test['Age'].fillna(id_test['Age'].median(),inplace=True)","bfefadd3":"id_train.drop(\"Ticket\",axis=1,inplace=True)\nid_test.drop(\"Ticket\",axis=1,inplace=True)","45c644c8":"id_train.head()","409470b6":"## lets see the different age bands survival\n\nid_train['ageband'] = pd.cut(id_train['Age'],5)\nid_train[['ageband','Survived']].groupby('ageband').mean()","3a1732a6":"## lets convert the ages into groups for id_train\ndataset=id_train\ndataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\ndataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\ndataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\ndataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\ndataset.loc[ dataset['Age'] > 64, 'Age']\n\nid_train=dataset\nid_train.head()","d6c51f8c":"## lets convert the ages into groups for id_test \ndataset=id_test\ndataset.loc[ dataset['Age'] <= 16, 'Age'] = 0\ndataset.loc[(dataset['Age'] > 16) & (dataset['Age'] <= 32), 'Age'] = 1\ndataset.loc[(dataset['Age'] > 32) & (dataset['Age'] <= 48), 'Age'] = 2\ndataset.loc[(dataset['Age'] > 48) & (dataset['Age'] <= 64), 'Age'] = 3\ndataset.loc[ dataset['Age'] > 64, 'Age']\n\nid_test=dataset\nid_test.head()","fff1e027":"id_train.drop('ageband',axis=1,inplace=True)","4dabb6e3":"## lets create a new column of family size\n\nid_train['family'] = id_train['Parch'] + id_train['SibSp'] + 1 \n\n## for idtest\nid_test['family'] = id_test['Parch'] + id_test['SibSp'] + 1 \n\nid_train[['family','Survived']].groupby(\"family\").mean()","08926769":"id_train.head()","bbeb64cb":"## if family is there : means ge is not alone\n\n\nid_train['alone']=0\n\nid_train.loc[id_train['family']==1,'alone']=1\n\nid_train[['alone','Survived']].groupby(\"alone\").mean()","ed823ead":"## for idtest\n\n## if family is there : means ge is not alone\n\nid_test['alone']=0\n\nid_test.loc[id_test['family']==1,'alone']=1\n\n","ec62af13":"id_train = id_train.drop(['Parch', 'SibSp', 'family'], axis=1)\nid_test = id_test.drop(['Parch', 'SibSp', 'family'], axis=1)","d16e0d2b":"## embarked col has null values\n## fill the na values with the most occurening embarking port\n\nprint(id_train['Embarked'].value_counts())\nid_train['Embarked'] = id_train['Embarked'].fillna(('S'))","065220ee":"id_train[['Embarked','Survived']].groupby([\"Embarked\"]).mean()","72cd6f76":"## lets replace S:0; C:1; Q:2 in Embarked ports\n\nid_train['Embarked'] = id_train['Embarked'].replace(['S','C','Q'],[0,1,2])\nid_train['Embarked'].value_counts()","7d3d0d78":"## lets replace S:0; C:1; Q:2 in Embarked ports in idtest\n\nid_test['Embarked'] = id_test['Embarked'].replace(['S','C','Q'],[0,1,2])\nid_test['Embarked'].value_counts()","9a0a6022":"id_train.head()","85f479f3":"id_test.head()","fffe19a6":"## lets create the band price for fare\n\nid_train['fareband'] = pd.qcut(id_train['Fare'],4)\n\nid_train[['fareband','Survived']].groupby([\"fareband\"]).mean()","81903c79":"dataset=id_train\n\ndataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\ndataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\ndataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\ndataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\ndataset['Fare'] = dataset['Fare'].astype(int)\n\nid_train = dataset\n\nid_train.drop(\"fareband\",axis=1,inplace=True)\n\nid_train.head()","95014441":"\n## theres null value in idtest['Fare']\nid_test['Fare'].fillna(id_test['Fare'].mean(),inplace=True)\n\n## fareband for idtest\n\ndataset=id_test\n\ndataset.loc[ dataset['Fare'] <= 7.91, 'Fare'] = 0\ndataset.loc[(dataset['Fare'] > 7.91) & (dataset['Fare'] <= 14.454), 'Fare'] = 1\ndataset.loc[(dataset['Fare'] > 14.454) & (dataset['Fare'] <= 31), 'Fare']   = 2\ndataset.loc[ dataset['Fare'] > 31, 'Fare'] = 3\ndataset['Fare'] = dataset['Fare'].astype(int)\n\nid_test = dataset\nid_test.head()","59a45944":"xtrain = id_train.drop('Survived',axis=1)\nytrain = id_train['Survived']\nxtest = id_test.drop(\"PassengerId\",axis=1).copy()\n\nxtrain.shape, ytrain.shape,xtest.shape","5fb7e346":"from sklearn.linear_model import LogisticRegression\n\nlogreg = LogisticRegression()\nlogreg.fit(xtrain,ytrain)\ny_pred = logreg.predict(xtest)\n\nlog_score=logreg.score(xtrain,ytrain)\nlog_score","e52f39a5":"coeff_df = pd.DataFrame(id_train.columns.delete(0))\ncoeff_df[\"Correlation\"] = pd.Series(logreg.coef_[0])\n\ncoeff_df.sort_values(by='Correlation', ascending=False)","10739e36":"from sklearn.svm import SVC, LinearSVC\n\nsvc=SVC()\nsvc.fit(xtrain,ytrain)\ny_pred = svc.predict(xtest)\n\nsvc_score=svc.score(xtrain,ytrain)\nsvc_score","7bc9218d":"from sklearn.neighbors import KNeighborsClassifier\n\nknn=KNeighborsClassifier(n_neighbors=3)\nknn.fit(xtrain,ytrain)\ny_pred = knn.predict(xtest)\n\nknn_score=knn.score(xtrain,ytrain)\nknn_score","025e495d":"from sklearn.naive_bayes import GaussianNB\n\ngauss = GaussianNB()\ngauss.fit(xtrain,ytrain)\ny_pred = gauss.predict(xtest)\n\ngauss_score=gauss.score(xtrain,ytrain)\ngauss_score","d4e8565f":"\n\nsvc=LinearSVC()\nsvc.fit(xtrain,ytrain)\ny_pred=svc.predict(xtest)\n\nlin_svc_score=svc.score(xtrain,ytrain)\nlin_svc_score","7b2f4657":"from sklearn.linear_model import SGDClassifier\n\nsgd=SGDClassifier()\nsgd.fit(xtrain,ytrain)\ny_pred = sgd.predict(xtest)\n\nsgd_score=sgd.score(xtrain,ytrain)\nsgd_score","753f8e81":"from sklearn.tree import DecisionTreeClassifier\n\ndt = DecisionTreeClassifier()\ndt.fit(xtrain,ytrain)\ny_pred = dt.predict(xtest)\n\ndt_score=dt.score(xtrain,ytrain)\ndt_score","214780be":"from sklearn.ensemble import RandomForestClassifier\n\nrf = RandomForestClassifier()\nrf.fit(xtrain,ytrain)\ny_pred_rf = rf.predict(xtest)\n\nrf_score=rf.score(xtrain,ytrain)\nrf_score","d3810e65":"xtrain.shape","9a6e28fc":"from tensorflow import keras\n\nmodel = keras.Sequential([\n    \n    ## reshaping the input entries\n    keras.layers.Dense(50, input_shape=(6,), activation='relu'),  \n    keras.layers.Dropout(0.50),    ## to avoid overfitting and underfiting\n\n    ## creating the hidden layer\n    keras.layers.Dense(100,activation='relu'),\n    keras.layers.Dropout(0.70),    ##  to avoid overfitting and underfiting\n    \n    keras.layers.Dense(150,activation='relu'),\n    keras.layers.Dropout(0.70),     ## to avoid overfitting and underfiting\n \n    \n    ## final neural layer\n    keras.layers.Dense(1,activation='sigmoid')\n    \n])\n\n\nmodel.compile(optimizer='adam',\n             loss='binary_crossentropy',  ## since output in 0 or 1\n             metrics=['accuracy'])","4136eeec":"model.fit(xtrain,ytrain,epochs=100)\n\ny_pred_cnn = model.predict(xtest)\n\ncnn_score = model.evaluate(xtrain,ytrain)[1]\ncnn_score","fb7406d5":"models = pd.DataFrame({\n    'Model': ['Support Vector Machines', 'KNN', 'Logistic Regression', \n              'Random Forest', 'Naive Bayes', \n              'Stochastic Gradient Decent', 'Linear SVC', \n              'Decision Tree',\"CNN\"],\n    'Score': [svc_score, knn_score, log_score, \n              rf_score, gauss_score, \n              sgd_score, lin_svc_score, dt_score,cnn_score]})\nmodels.sort_values(by='Score', ascending=False)","92463789":"submission = pd.DataFrame({\n        \"PassengerId\": id_test[\"PassengerId\"],\n        \"Survived\": y_pred_rf\n    })\n\nsubmission = submission.to_csv('submission.csv',index=False)\n\n\n\n\n","fcac6e45":"## SGD","cca45d9d":"## Decision Tree","9a650a8e":"## Linear SVC","d73fad4f":"## KNN","1b508ebd":"## CNN Model","5abd24fe":"#  **lets visualize the data**","a6672cb0":"## RandomForest","e6c1442c":"## Naive Bayes","81bfe333":"## Observation\n1. Higher fare paying people have more chances of survival","7e1a78d9":"## lets do the survived vs age with respect to pclass","626b9d17":"## Logistic regression","b133af1a":"observation from above :\n1. infants (age<=6) have high survival chances\n2. Oldest passengers (age>75) survived.\n3. age group between (15-30) survived less.\n","573ad85f":"Random Forest has the highest accuracy.\nso we will submit the y_predicted value using random forest model","915701f5":"## SVC","1eb44c49":"# Model Development","82874283":"## Observation\n\n1. Overall, Females have high survival chances.\n2. Males of pclass 2 in Embarked==\"C\" have higher survival chances than females in that category.","513c0d22":"From above graph :\nPclass==1 : survived the most."}}