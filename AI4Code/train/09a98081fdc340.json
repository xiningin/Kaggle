{"cell_type":{"f9bbc98f":"code","94ca1153":"code","b951ab69":"code","30776958":"code","c75d6b9f":"code","f72e3e99":"code","eb9850f0":"code","c2d2f9b2":"code","a18e04b6":"code","a4316a06":"code","8c841909":"code","91cb88c7":"code","8630e7c6":"code","26ea8111":"code","5dc1df87":"code","f1ded958":"code","65820b64":"code","39a6496d":"code","55261931":"code","9fcc5eba":"code","3c4254c4":"code","7ec983a5":"code","f554bc59":"code","84d08d0e":"code","7fc7bae7":"code","9e3b87cc":"code","5eb70f98":"code","76ea2163":"code","370206d5":"code","69dbffbd":"code","c95e4928":"code","210c33dc":"code","e5674c2c":"code","1abad838":"code","31b29298":"code","e85e8d4d":"code","40c9ade0":"markdown","c2e6e8e2":"markdown","f48268da":"markdown","dca0aefd":"markdown","dfdb8273":"markdown","0e84c12d":"markdown","1dd38c7f":"markdown","aaa1fadf":"markdown","7c082dcd":"markdown","3abc79e4":"markdown","a37d7ffa":"markdown","891bf4e6":"markdown","99a8f258":"markdown","9c1e3a71":"markdown","2cd96e44":"markdown","4f28069b":"markdown","e199ffe5":"markdown","42bfcaf6":"markdown","2c8fd8aa":"markdown","c49afdf1":"markdown"},"source":{"f9bbc98f":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nimport keras\nfrom keras import Sequential\nfrom keras.layers import LSTM, Bidirectional, Dense, Embedding, Dropout\nfrom keras.preprocessing.text import Tokenizer\nfrom keras.preprocessing.sequence import pad_sequences\n\nfrom nltk.corpus import stopwords\nfrom nltk import word_tokenize\nfrom nltk.stem import PorterStemmer\n\nimport re\nfrom string import punctuation\n\nfrom wordcloud import WordCloud","94ca1153":"df = pd.read_csv(\"..\/input\/fake-news\/train.csv\", index_col = 'id')","b951ab69":"df.head()","30776958":"df.isnull().sum()","c75d6b9f":"df = df.dropna()","f72e3e99":"df.shape","eb9850f0":"df['whole_text'] = df['title'] + \" \" + df['text']","c2d2f9b2":"df.head()","a18e04b6":"stop_words = stopwords.words('english')\nps = PorterStemmer()","a4316a06":"def preprocess(text):\n\n    text = re.sub('[^a-zA-Z]', ' ', text)\n    text = text.lower().split()\n    text = [ps.stem(word) for word in text if word not in stop_words]\n    text = ' '.join(text)\n    text = ''.join(p for p in text if p not in punctuation)\n    \n    return text","8c841909":"df['clean'] = df['whole_text'].apply(preprocess)","91cb88c7":"df['clean'][0]","8630e7c6":"plt.figure(figsize = (8, 8))\nsns.countplot(y = y)","26ea8111":"plt.figure(figsize=(20,20))\nwordCloud = WordCloud(max_words = 1000 , width = 1600 , height = 800 , stopwords = stop_words).generate(\" \".join(df[df[\"label\"] == 0][\"clean\"]))\nplt.imshow(wordCloud, interpolation = 'bilinear')","5dc1df87":"plt.figure(figsize=(20,20))\nwordCloud = WordCloud(max_words = 1000 , width = 1600 , height = 800 , stopwords = stop_words).generate(\" \".join(df[df[\"label\"] == 1][\"clean\"]))\nplt.imshow(wordCloud, interpolation = 'bilinear')","f1ded958":"y = df['label'] # Target Column\n\ndf = df.drop(['label', 'author'], axis = 1)","65820b64":"X_train = df['clean']\n\ny_train = np.asarray(y)","39a6496d":"vocab_size = 20000\nembedding_dim = 120\n\ntokenizer = Tokenizer(num_words = vocab_size)\ntokenizer.fit_on_texts(X_train)\ntrain_sequences = tokenizer.texts_to_sequences(X_train)","55261931":"padded_train = pad_sequences(train_sequences,maxlen = 40, padding = 'post', truncating = 'post')","9fcc5eba":"model = Sequential()\nmodel.add(Embedding(vocab_size, embedding_dim))\nmodel.add(Bidirectional(LSTM(128)))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.3))\nmodel.add(Dense(1, activation='sigmoid'))\nmodel.summary()","3c4254c4":"model.compile(optimizer='adam', loss = 'binary_crossentropy', metrics = ['accuracy'])","7ec983a5":"history = model.fit(padded_train, y_train, batch_size = 64, validation_split = 0.1, epochs = 5)","f554bc59":"df_test = pd.read_csv(\"..\/input\/fake-news\/test.csv\")\n\ntest_id = df_test['id']","84d08d0e":"df_test = df_test.drop(['id', 'author'], axis = 1)\ndf_test.head()","7fc7bae7":"df_test.shape","9e3b87cc":"df_test['whole_text'] = df_test['title'] + \" \" + df_test['text']","5eb70f98":"df_test.fillna(method = 'ffill', inplace = True)","76ea2163":"df_test.isnull().sum()","370206d5":"df_test['clean'] = df_test['whole_text'].apply(preprocess)","69dbffbd":"X_test = df_test['clean']","c95e4928":"test_sequences = tokenizer.texts_to_sequences(X_test)\npadded_test = pad_sequences(test_sequences,maxlen = 40, truncating = 'post') ","210c33dc":"pred = model.predict_classes(padded_test)\n\npred","e5674c2c":"sub=[]\nfor i in pred:\n    sub.append(i[0])","1abad838":"submission = pd.DataFrame({'id':test_id, 'label':sub})\nsubmission.shape","31b29298":"submission.head()","e85e8d4d":"submission.to_csv('submission.csv',index=False)","40c9ade0":"## Submission File","c2e6e8e2":"- id: unique id for each row of the news article\n- title: the title of the news article\n- author: author of the news article\n- text: the text of the article\n- label: a label that marks the article as fake or real (Target Column)\n        1: Fake \n        0: Real\n\n","f48268da":"## Testing Dataset and Pre-Processing","dca0aefd":"## Reading Dataset","dfdb8273":"## Conclusion","0e84c12d":"# Contents","1dd38c7f":"## Introduction","aaa1fadf":"WordCloud for Fake News","7c082dcd":"WordCloud for Real News","3abc79e4":"## Data Pre-Processing","a37d7ffa":"Thanks for reading. I hope you find the notebook insightful. If you have any questions or suggestions, feel free to write them down in the comment section.\n","891bf4e6":"- Introduction\n- Dataset\n- Importing Libraries\n- Reading Dataset\n- Data Pre-Processing\n- Visualization\n- Building Model\n- Training Model\n- Testing Data Pre-Processing\n- Submission File\n- Conclusion\n","99a8f258":"## Importing Libraries","9c1e3a71":"## Training the Model","2cd96e44":"## Building Model","4f28069b":"## Prediction","e199ffe5":"In the following notebook, we will develop a machine learning model to identify when an article might be fake news. We will be using LSTM to build the model.","42bfcaf6":"### train.csv: A full training dataset with the following attributes:\n","2c8fd8aa":"## Dataset","c49afdf1":"## Visualization"}}