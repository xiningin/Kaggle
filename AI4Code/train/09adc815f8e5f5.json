{"cell_type":{"f52ecd94":"code","d04996ce":"code","39057ce7":"code","28eeca70":"code","a9441f4c":"code","def22cfe":"code","e3914726":"code","6269f76a":"markdown","fea46e10":"markdown","d37c480e":"markdown","d2dd7f2a":"markdown","482b95f7":"markdown","f0d5de8a":"markdown"},"source":{"f52ecd94":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport sklearn.ensemble as se\nimport xgboost as xgb\nfrom sklearn.metrics import mean_absolute_error\nimport sklearn.model_selection as sm\nfrom sklearn.impute import SimpleImputer\nfrom sklearn.preprocessing import OneHotEncoder, MinMaxScaler\nfrom sklearn.pipeline import Pipeline\nfrom sklearn.compose import ColumnTransformer\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","d04996ce":"def assess(y_true,y_pred):\n    score = np.sqrt(np.mean(np.power(np.log(y_pred)-np.log(y_true),2)))\n    return score\ndef assess_no_avg(y_true,y_pred):\n    score = np.sqrt(np.power(np.log(y_pred)-np.log(y_true),2))\n    return score","39057ce7":"train_set = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest_set = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')\ntotal_set = pd.concat([train_set,test_set])\nprint(train_set.shape,test_set.shape,total_set.shape)\nprint(train_set.columns)\nprint(train_set.dtypes)\nprint(train_set['SaleCondition'])","28eeca70":"plt.hist(train_set['SalePrice'],bins=50)\nplt.show()","a9441f4c":"X_train,X_valid,y_train,y_valid = sm.train_test_split(train_set.iloc[:,:-1],train_set.iloc[:,-1],test_size=0.3,random_state=12356)\nprint(X_train.shape,X_valid.shape,y_train.shape,y_valid.shape)\nX_train.head()","def22cfe":"numerical_features = X_train.select_dtypes(include='number').columns.tolist()\ncategorical_features = X_train.select_dtypes(exclude='number').columns.tolist()\n\nnumeric_pipeline = Pipeline(steps=[('impute',SimpleImputer(strategy='mean')),('scale',MinMaxScaler())])\ncategorical_pipeline = Pipeline(steps=[('impute',SimpleImputer(strategy='most_frequent')),('one-hot',OneHotEncoder(handle_unknown='ignore',sparse=False))])\nnumeric_pipeline.fit_transform(X_train.select_dtypes(include='number'))\ncategorical_pipeline.fit_transform(X_train.select_dtypes(exclude='number'))\nfull_processor = ColumnTransformer(transformers=[\n    ('number', numeric_pipeline, numerical_features),\n    ('category', categorical_pipeline, categorical_features)\n])\nregr_GB = se.GradientBoostingRegressor(n_estimators=1000)\nGBT_pipeline = Pipeline(steps=[('preprocess',full_processor),('model',regr_GB)])","e3914726":"GBT_pipeline.fit(X_train,y_train)\nprint(assess(y_valid,GBT_pipeline.predict(X_valid)))\nprint(mean_absolute_error(y_valid,GBT_pipeline.predict(X_valid)))\n\npredictions = GBT_pipeline.predict(test_set)\ny_test_dict = {'Id' : test_set['Id'],'SalePrice' : predictions}\ny_test_df = pd.DataFrame(y_test_dict)\nprint(y_test_df)\ny_test_df.to_csv('\/kaggle\/working\/house-prices-advanced-regression-techniques.csv',columns=['Id','SalePrice'],index=False)","6269f76a":"# Set up pipelines","fea46e10":"# histogram of final sale prices","d37c480e":"# Run pipeline for fit and score","d2dd7f2a":"# Define assessment RMSE function","482b95f7":"# split training set into training and sample eval","f0d5de8a":"# Read in"}}