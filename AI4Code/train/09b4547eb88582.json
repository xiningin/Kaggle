{"cell_type":{"8bd692d3":"code","f5c858ed":"code","a385039d":"code","25b336bf":"code","4e2d6024":"code","d2b26ace":"code","bce723e2":"code","042c5927":"code","da5e8b2f":"code","e69896be":"code","764ed3f4":"code","fa67034f":"code","627ac5da":"code","a33e0333":"code","9064fcd7":"code","1dacdb64":"code","df703b96":"code","183917e3":"markdown","2dd95475":"markdown","1e3f6776":"markdown","98b938d3":"markdown"},"source":{"8bd692d3":"import numpy as np \nimport pandas as pd\nfrom sklearn import *\nfrom sklearn.metrics import f1_score,make_scorer\nimport lightgbm as lgb\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport time\nimport xgboost as xgb\nfrom catboost import Pool,CatBoostRegressor\nimport datetime\nimport gc","f5c858ed":"GROUP_BATCH_SIZE = 4000\nWINDOWS = [10, 50]\n\n\nBASE_PATH = '\/kaggle\/input\/liverpool-ion-switching'\nDATA_PATH = '\/kaggle\/input\/data-without-drift'\nRFC_DATA_PATH = '\/kaggle\/input\/ion-shifted-rfc-proba'\nMODELS_PATH = '\/kaggle\/input\/ensemble-models'","a385039d":"%%time\n\ndef create_rolling_features(df):\n    for window in WINDOWS:\n        df[\"rolling_mean_\" + str(window)] = df['signal'].rolling(window=window).mean()\n        df[\"rolling_std_\" + str(window)] = df['signal'].rolling(window=window).std()\n        df[\"rolling_var_\" + str(window)] = df['signal'].rolling(window=window).var()\n        df[\"rolling_min_\" + str(window)] = df['signal'].rolling(window=window).min()\n        df[\"rolling_max_\" + str(window)] = df['signal'].rolling(window=window).max()\n        df[\"rolling_min_max_ratio_\" + str(window)] = df[\"rolling_min_\" + str(window)] \/ df[\"rolling_max_\" + str(window)]\n        df[\"rolling_min_max_diff_\" + str(window)] = df[\"rolling_max_\" + str(window)] - df[\"rolling_min_\" + str(window)]\n\n    df = df.replace([np.inf, -np.inf], np.nan)    \n    df.fillna(0, inplace=True)\n    return df\n\n\ndef create_features(df, batch_size):\n    \n    df['group'] = df.groupby(df.index\/\/batch_size, sort=False)['signal'].agg(['ngroup']).values\n    df['group'] = df['group'].astype(np.uint16)\n    for window in WINDOWS:    \n        df['signal_shift_pos_' + str(window)] = df.groupby('group')['signal'].shift(window).fillna(0)\n        df['signal_shift_neg_' + str(window)] = df.groupby('group')['signal'].shift(-1 * window).fillna(0)\n        \n    df['signal_2'] = df['signal'] ** 2\n    return df   ","25b336bf":"## reading data\ntrain = pd.read_csv(f'{DATA_PATH}\/train_clean.csv', dtype={'time': np.float32, 'signal': np.float32, 'open_channels':np.int32})\ntest  = pd.read_csv(f'{DATA_PATH}\/test_clean.csv', dtype={'time': np.float32, 'signal': np.float32})\nsub  = pd.read_csv(f'{BASE_PATH}\/sample_submission.csv', dtype={'time': np.float32})\n\n# loading and adding shifted-rfc-proba features\ny_train_proba = np.load(f\"{RFC_DATA_PATH}\/Y_train_proba.npy\")\ny_test_proba = np.load(f\"{RFC_DATA_PATH}\/Y_test_proba.npy\")\n\nfor i in range(11):\n    train[f\"proba_{i}\"] = y_train_proba[:, i]\n    test[f\"proba_{i}\"] = y_test_proba[:, i]\n\n    \ntrain = create_rolling_features(train)\ntest = create_rolling_features(test)   \n    \n## normalizing features\ntrain_mean = train.signal.mean()\ntrain_std = train.signal.std()\ntrain['signal'] = (train.signal - train_mean) \/ train_std\ntest['signal'] = (test.signal - train_mean) \/ train_std\n\n\nprint('Shape of train is ',train.shape)\nprint('Shape of test is ',test.shape)","4e2d6024":"## create features\n\nbatch_size = GROUP_BATCH_SIZE\n\ntrain = create_features(train, batch_size)\ntest = create_features(test, batch_size)\n\ncols_to_remove = ['time','signal','open_channels','batch','batch_index','batch_slices','batch_slices2', 'group']\ncols = [c for c in train.columns if c not in cols_to_remove]\nX_train = train[cols]\ny = train['open_channels']\nX_test = test[cols]\n","d2b26ace":"##from sklearn.model_selection import train_test_split\n##X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.40, random_state=101)\n##converting to np arrays\nX_train = X_train.values\ny_train = y.values\nX_test = X_test.values","bce723e2":"del train\ndel test\ngc.collect()","042c5927":"import keras\nfrom keras.models import Sequential\nfrom keras.layers import Conv1D\nfrom keras.layers import Bidirectional\nfrom keras.layers import Input\nfrom keras.layers import GRU\nfrom keras.layers import Dense\nfrom keras.layers import LSTM\nfrom keras.layers import Dropout\nfrom keras.wrappers.scikit_learn import KerasClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder","da5e8b2f":"#Scaling and onehot encoding\nfrom sklearn.preprocessing import MinMaxScaler\nonh = OneHotEncoder(sparse=False)\nsc = MinMaxScaler(feature_range = (0,1))\nX_train = sc.fit_transform(X_train)\nX_test = sc.fit_transform(X_test)\ny_train = y_train.reshape(len(y_train),1)\ny_train = onh.fit_transform(y_train)\n\nprint('Shape of X_train is ',X_train.shape)\nprint('Shape of y_train is ',y_train.shape)\nprint('Shape of X_test is ',X_test.shape)","e69896be":"##for converting input into 3D data\nX_train= X_train.reshape((X_train.shape[0],X_train.shape[1],1))\nX_test= X_test.reshape((X_test.shape[0],X_test.shape[1],1))","764ed3f4":"#build and compile model\ndef build_clf(optimizer):\n    model = Sequential()\n    model.add(Conv1D(128,16, strides=6, activation='relu', input_shape = (X_train.shape[1],X_train.shape[2])))\n    model.add(LSTM(256,return_sequences=True))\n    model.add(Dropout(0.2))\n    model.add(LSTM(256))\n    model.add(Dropout(0.2))\n    model.add(Dense(128, activation='relu',kernel_initializer='uniform'))\n    model.add(Dense(128, activation='relu',kernel_initializer='uniform'))\n    model.add(Dense(128, activation='relu',kernel_initializer='uniform'))\n    model.add(Dense(units = 11, activation='softmax', kernel_initializer='uniform'))\n    model.compile(optimizer=optimizer, loss = 'categorical_crossentropy', metrics =['accuracy'])\n    model.summary()\n    return model","fa67034f":"#compile and fit model--96.25 rmsprop, 96.71--adadelta\nmodel = build_clf('adam')\nmodel.fit(X_train, y_train,epochs = 10, batch_size=256)                        ","627ac5da":"# Prediction and reversing One Hot Encoding\ny_pred=model.predict(X_test)\ny_pred =onh.inverse_transform(y_pred)\ny_pred.max() #Should be 10","a33e0333":"# making submission\nsub = pd.read_csv('..\/input\/liverpool-ion-switching\/sample_submission.csv')\nsub.iloc[:,1] = y_pred[:,0]\nsub.to_csv('submission.csv',index=False,float_format='%.4f')","9064fcd7":"from tensorflow.keras.layers import Dense\nfrom tensorflow.keras import Input, Model\n\n","1dacdb64":"##Tuning parameters to find best choice for model using Grid Search\n#from keras.wrappers.scikit_learn import KerasClassifier\n#from sklearn.model_selection import GridSearchCV\n#scorer = make_scorer(f1_score, average = 'weighted')\n#model = KerasClassifier(build_fn = build_clf)\n#parameters = {'batch_size': [500,10000], 'epochs': [5, 200],'optimizer': ['adam', 'rmsprop','nadam','adadelta']}\n#grid_search = GridSearchCV(estimator = model,param_grid = parameters,scoring = scorer,cv = 3, return_train_score= True)\n#grid_search = grid_search.fit(X_train, y_train)","df703b96":"#best_parameters = grid_search.best_params_\n#best_accuracy = grid_search.best_score_\n#best_parameters\n\n#Grid Search for multiclass classification failed","183917e3":"<a id=\"id5\"><\/a> <br> \n# 2. Model 1-- Conv1D+LSTM layer\n","2dd95475":"#most successful model was 1 Conv1D layer 2 LSTMs and 3 Dense layers","1e3f6776":"## 3. Model 2 -- Temporal Convolutional Network(TCN)","98b938d3":"## 1. Data Processing -- features"}}