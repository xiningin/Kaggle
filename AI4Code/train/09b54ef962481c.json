{"cell_type":{"34dd7167":"code","e9b489d2":"code","2d38ad4c":"code","eb62b0f2":"code","c7b5805b":"code","a9e2b42f":"code","aee7c9d7":"code","31cb70af":"code","ae35d3df":"code","9d9780b8":"code","9f461df7":"code","842f0198":"code","4694858d":"code","7a37b22b":"code","34816f2c":"code","9e7ec8de":"code","12a30e1c":"code","2a1aeef6":"code","fdfbb6d9":"code","6b58ac50":"code","7d83b74e":"code","90386549":"markdown","cd5feee0":"markdown","93cfdc27":"markdown","eb14dafe":"markdown","36082c17":"markdown","152159ac":"markdown","fb36e390":"markdown","aa1885a2":"markdown"},"source":{"34dd7167":"!pip -qq install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio===0.7.2 -f https:\/\/download.pytorch.org\/whl\/torch_stable.html","e9b489d2":"!pip -qq install split-folders tqdm","2d38ad4c":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm\nimport tensorflow as tf\n\nimport splitfolders\nimport os\nimport random\nimport shutil\n\n### Make prettier the prints ###\nfrom colorama import Fore, Style\nc_ = Fore.CYAN\nm_ = Fore.MAGENTA\nr_ = Fore.RED\nb_ = Fore.BLUE\ny_ = Fore.YELLOW\ng_ = Fore.GREEN\nw_ = Fore.WHITE\n\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\nfrom torch.utils.data import DataLoader, Dataset\n\nprint(\"Pytorch Version: \",torch.__version__)\nprint(\"Torchvision Version \",torchvision.__version__)","eb62b0f2":"seed = 42\nprint(f'setting everything to seed {seed}')\nrandom.seed(seed)\nos.environ['PYTHONHASHSEED'] = str(seed)\nnp.random.seed(seed)\ntorch.manual_seed(seed)\ntorch.cuda.manual_seed(seed)\ntorch.backends.cudnn.deterministic = True","c7b5805b":"#https:\/\/www.pythoncentral.io\/how-to-recursively-copy-a-directory-folder-in-python\/\n\ndef copyDirectory(src, dest):\n    try:\n        shutil.copytree(src, dest)\n    # Directories are the same\n    except shutil.Error as e:\n        print('Directory not copied. Error: %s' % e)\n    # Any error saying that the directory doesn't exist\n    except OSError as e:\n        print('Directory not copied. Error: %s' % e)","a9e2b42f":"root = '..\/input\/rock-classification\/Dataset'\nfor class_name in os.listdir(root):\n    for rock_name in os.listdir(os.path.join(root, class_name)):\n        folder_path = os.path.join(os.path.join(root, class_name), rock_name)\n        copyDirectory(folder_path, f\"Dataset\/{folder_path.split('\/')[-1]}\")","aee7c9d7":"def del_corrupted_images(path):\n    del_count = 0\n    for folder in os.listdir(path):\n        folder_path = os.path.join(path, folder)\n        for filename in tqdm(os.listdir(folder_path)):\n            filepath = os.path.join(folder_path, filename)\n            try:\n                fileobject = open(filepath, 'rb')\n                is_ok = tf.compat.as_bytes('JFIF') in fileobject.peek(10)\n            finally:\n                fileobject.close()\n            if not is_ok:\n                del_count += 1\n                os.remove(filepath)\n    print(\"\\n\\nDeleted %d images\" % del_count)\n\ndel_corrupted_images('.\/Dataset')","31cb70af":"splitfolders.fixed(\".\/Dataset\", output=\".\/SplitDataset\", seed=1337, fixed=20, group_prefix=None, oversample=True) ","ae35d3df":"TRANSFORMS = transforms.Compose(\n                                    [transforms.RandomResizedCrop(224),\n                                    transforms.RandomHorizontalFlip(),\n                                    transforms.ToTensor(),\n                                    transforms.Normalize([0.485, 0.456, 0.406],[0.229, 0.224, 0.225])]\n                                )","9d9780b8":"# Loading the datasets and plot some images from train split\ntrain_dataset = datasets.ImageFolder('.\/SplitDataset\/train',transform = TRANSFORMS)\nimage,label = train_dataset[15]\nplt.imshow(image.permute(2,1,0))\nplt.show()\nprint(label, train_dataset.classes[label])","9f461df7":"# Loading the datasets and plot some images from validation split\nval_dataset = datasets.ImageFolder('.\/SplitDataset\/val',transform = TRANSFORMS)\nimage,label = val_dataset[15]\nplt.imshow(image.permute(2,1,0))\nplt.show()\nprint(label, val_dataset.classes[label])","842f0198":"print(train_dataset.classes)\nprint('\\ndataset size: ', len(train_dataset))","4694858d":"class_names = train_dataset.classes\n\nfor i in 0, 10, 100, 200, 500:\n    img,label = train_dataset[i]\n    plt.title(f'Label: {label}, Class {class_names[label]}')\n    plt.imshow(img.permute(2,1,0))\n    plt.show()","7a37b22b":"labels = train_dataset.targets\n_,labels_count = np.unique(labels, return_counts=True)\nlabels_count","34816f2c":"# Data Distribution plot\nplt.figure(figsize=(8, 4))\nplt.title('Data distribution')\nplt.bar(class_names, labels_count, width=.5, color = ['C0', 'C1', 'C2', 'C3', 'C4', 'C5', 'C6'])\nplt.show()","9e7ec8de":"#size of dataset\ndataset_size = len(train_dataset)\ndistribution_perc = 100*labels_count\/dataset_size\n\nfor class_name, count, distrib in zip(class_names,labels_count,distribution_perc):\n    print(f'{class_name} {distrib:.2f}% - {r_}{count} Images')\n    print(Style.RESET_ALL)\nprint('\\nTotal Images:',dataset_size,'Images')","12a30e1c":"batch_size = 64\n\ntrain_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle=True)\nvalid_loader = DataLoader(val_dataset, batch_size = batch_size, shuffle=True)","2a1aeef6":"model = models.resnext101_32x8d(pretrained=True)\n\n# view last input channels\nin_features = model.fc.in_features\n\n#lock previous layer\nfor param in model.parameters():\n    param.requires_grad = False\n\nmodel.fc = nn.Linear(in_features=2048, out_features=7)\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\") \nmodel = model.to(device)\n\n# loss function\ncriteration = nn.CrossEntropyLoss()\noptimizer = optim.Adam(model.parameters(), lr = 0.001)\n\nmax_score = 0\n# param.requires_grad = False\nfor epoch in range(20):\n    print(f'\\n-----epoch {epoch+1}-----')\n    number_corect = 0\n    sum_loss = 0\n    val_cor = 0\n    model.train()\n    for datas, targets in train_loader:\n        datas = datas.to(device)\n        targets = targets.to(device)\n        optimizer.zero_grad()\n        #predict\n        outputs = model(datas)\n        #update model\n        loss = criteration(outputs, targets)\n        #update model\n        loss.backward()\n        optimizer.step()\n        #compute metrics\n        max_index = outputs.max(dim=1)[1]\n        sum_loss += loss.item()\n        number_corect += (max_index == targets.data).sum()\n\n    model.eval()\n    with torch.no_grad():\n        for datas, targets in valid_loader:\n            datas = datas.to(device)\n            targets = targets.to(device)\n            #predict\n            outputs = model(datas)\n            #compute metrics\n            max_index = outputs.max(dim=1)[1]\n            val_cor += (max_index == targets.data).sum()\n\n    #print metrics\n    loss = sum_loss \/ len(train_loader)\n    accuracy = 100.0*number_corect \/ len(train_dataset)\n    accuracy_val = 100.0*val_cor \/ len(val_dataset)\n    print(f'Loss {loss}, \\nAccuracy {accuracy}, \\nVal Accuracy {accuracy_val}')\n\n    if max_score < accuracy_val:\n        max_score = accuracy_val\n        torch.save(model.state_dict(), f'.\/model.pth')\n        print(f'{y_}Improvement in score. Model saved!')\n        print(Style.RESET_ALL)","fdfbb6d9":"model.load_state_dict(torch.load('.\/model.pth'))","6b58ac50":"# reference https:\/\/discuss.pytorch.org\/t\/how-to-find-test-accuracy-after-training\/88962\ndef check_accuracy(loader, model):\n    num_correct = 0\n    num_samples = 0\n    model.eval() \n    with torch.no_grad():\n        for x, y in loader:\n            x = x.to(device=device)\n            y = y.to(device=device)\n            \n            scores = model(x)\n            _, predictions = scores.max(1)\n            num_correct += (predictions == y).sum()\n            num_samples += predictions.size(0)\n        \n        print(f'Got {num_correct} \/ {num_samples} with accuracy {float(num_correct)\/float(num_samples)*100:.2f}') \n    model.train()","7d83b74e":"check_accuracy(valid_loader, model)","90386549":"# Seed Everything","cd5feee0":"# Deleting Corrupted Images","93cfdc27":"# Simple Vizualization","eb14dafe":"# Train-Val Split","36082c17":"# Evaluation","152159ac":"# Making class-wise folders ","fb36e390":"# Importing libraries","aa1885a2":"# Model"}}