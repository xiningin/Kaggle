{"cell_type":{"44026f80":"code","74363e67":"code","4bc9168e":"code","e53aaa53":"code","0d05d839":"code","f68b1b95":"code","e02dbdfb":"code","71ab1cdb":"code","589612e4":"code","e1413684":"code","ae51bd15":"code","dc13126b":"code","223a8b3f":"code","526b07f1":"code","8d5be899":"code","9028a07f":"code","d5794941":"code","bc26a956":"code","8b3f63fb":"code","8d1ecd7f":"code","9077614c":"code","6411b22e":"code","0a57f3c7":"code","4499c770":"code","c60ed290":"code","02467cae":"code","32771219":"markdown","3fb1bc66":"markdown","6069e23d":"markdown","0f23e6d8":"markdown","f5f1a5b6":"markdown","2c98f601":"markdown","f69b9c27":"markdown","2d917243":"markdown","e55a3f17":"markdown","f04b2276":"markdown","0a088d7f":"markdown","6c55b9e4":"markdown","7db1a4a2":"markdown","002e829d":"markdown","775fa7e7":"markdown","cf910e6f":"markdown","9ab977a1":"markdown","68634fac":"markdown","dff89588":"markdown","8ed7a3d9":"markdown","83c0ddd0":"markdown","81967fb3":"markdown","e20fe98b":"markdown","216bd92f":"markdown","1c071f01":"markdown","c82caace":"markdown","be7fdc3e":"markdown","acbdab64":"markdown","498a0b5d":"markdown","6a455fe0":"markdown","95f0696e":"markdown","fa898548":"markdown","0ece122e":"markdown","b13e52f8":"markdown","5aef59e3":"markdown","f9d719cc":"markdown"},"source":{"44026f80":"!pip install quick-ml","74363e67":"import tensorflow as tf","4bc9168e":"import quick_ml","e53aaa53":"! wget https:\/\/download.microsoft.com\/download\/3\/E\/1\/3E1C3F21-ECDB-4869-8368-6DEBA77B919F\/kagglecatsanddogs_3367a.zip -O catsdogs.zip","0d05d839":"!unzip \/kaggle\/working\/catsdogs.zip","f68b1b95":"!rm catsdogs.zip","e02dbdfb":"from quick_ml.tfrecords_maker import create_tfrecord_labeled","71ab1cdb":"from quick_ml.tfrecords_maker import get_addrs_labels","589612e4":"DATA_DIR = '\/kaggle\/working\/PetImages'","e1413684":"addrs, labels = get_addrs_labels(DATA_DIR)","ae51bd15":"output_filename = 'train.tfrecords'\ncreate_tfrecord_labeled(addrs, labels, output_filename, IMAGE_SIZE = (192,192))","dc13126b":"from quick_ml.tfrecords_maker import create_split_tfrecords_data","223a8b3f":"outfile1name = 'training.tfrecords'\noutfile2name = 'validation.tfrecords'\n\n#create_split_tfrecords_data(DATA_DIR, outfile1name, outfile2name, split_size_ratio = 0.7, IMAGE_SIZE = (192,192))","526b07f1":"from quick_ml.tfrecords_maker import create_tfrecord_unlabeled\nfrom quick_ml.tfrecords_maker import get_addrs_ids","8d5be899":"Unlabeled_Data_Dir = '\/kaggle\/working\/PetImages\/Cat'\naddrs, ids = get_addrs_ids(Unlabeled_Data_Dir)","9028a07f":"out_filename = 'unlabeled.tfrecords'\ncreate_tfrecord_unlabeled(out_filename, addrs, ids, IMAGE_SIZE = (192,192))","d5794941":"from quick_ml.visualize_and_check_data import check_one_image_and_label","bc26a956":"from quick_ml.begin_tpu import get_labeled_tfrecord_format\n\ndictionary_labeled = \"{ 'image' : tf.io.FixedLenFeature([], tf.string), 'label' : tf.io.FixedLenFeature([], tf.int64) }\"\nIMAGE_SIZE = \"192,192\"\n\nget_labeled_tfrecord_format(dictionary_labeled, IMAGE_SIZE)","8b3f63fb":"tfrecord_filename = '\/kaggle\/working\/train.tfrecords'\n\n\ncheck_one_image_and_label(tfrecord_filename)","8d1ecd7f":"from quick_ml.visualize_and_check_data import check_batch_and_labels","9077614c":"tfrecord_filename = '\/kaggle\/working\/train.tfrecords'\nn_examples = 15\ngrid_rows = 3\ngrid_columns = 5\ngrid_size = (10,10)\n\n\ncheck_batch_and_labels(tfrecord_filename, n_examples, grid_rows, grid_columns, grid_size)","6411b22e":"from quick_ml.visualize_and_check_data import check_one_image_and_id","0a57f3c7":"from quick_ml.begin_tpu import get_unlabeled_tfrecord_format\n\ndictionary_unlabeled = \"{ 'image' : tf.io.FixedLenFeature([], tf.string), 'idnum' : tf.io.FixedLenFeature([], tf.string) }\"\nIMAGE_SIZE = \"192,192\"\n\nget_unlabeled_tfrecord_format(dictionary_unlabeled, IMAGE_SIZE)","4499c770":"tfrecord_filename = '\/kaggle\/working\/unlabeled.tfrecords'\n\n\ncheck_one_image_and_id(tfrecord_filename)","c60ed290":"from quick_ml.visualize_and_check_data import check_batch_and_ids","02467cae":"tfrecord_filename = '\/kaggle\/working\/unlabeled.tfrecords'\nn_examples = 15\ngrid_rows = 3\ngrid_columns = 5\ngrid_size = (10,10)\n\n\ncheck_batch_and_ids(tfrecord_filename, n_examples, grid_rows, grid_columns, grid_size)","32771219":"Remove the zip file.","3fb1bc66":"unzip the contents of the zip file to obtain the dataset directory folder.","6069e23d":"Mention the file 1 name, file 2 name, split_size_ratio & image_size. <br>\nPlease refer to the documentation for create_split_tfrecords_data on https:\/\/www.quickml.info\/making-custom-datasets-tfrecords","0f23e6d8":"Unlabeled data is required for testing purposes. After training a model, you'd love to test out your model on the test dataset. To generate test dataset, test.tfrecords, which contains ids and the images rather than labels and images, we'll be using **create_tfrecord_unlabeled** instead of *create_tfrecord_labeled* & **get_addrs_ids** instead of *get_addrs_labels*. <br><br>\nVisit https:\/\/www.quickml.info\/making-custom-datasets-tfrecords. Scroll down to Unlabeled Data section and learn more about this.","f5f1a5b6":"## II. Create Unlabeled TFRecords Dataset","2c98f601":"#### III.I Labeled TFRecords Data File","f69b9c27":"### I.II Split the Labeled Data","2d917243":"Link to quick_ml documentation -> https:\/\/gitlab.com\/antoreep_jana\/quick_ml\/-\/blob\/master\/README.md","e55a3f17":"For reading the Dataset (Labeled or Unlabeled), you need to have the TFRecords Format of the Dataset. <br>\n<br>\nFor reading unlabeled TFRecords Dataset, use **get_unlabeled_tfrecord_format** function present at **begin_tpu** module of **quick_ml** package. <br>\nFor labeled TFRecords File, you need two variables. <br>\n1. dictionary_unlabeled <br>\n2. IMAGE_SIZE <br>\n\n\"dictionary_unlabeled\" should be assigned the dictionary of Unlabeled TFRecord Data which we can obtain by scrolling above by referencing to the location where we saved the format. <br>\nIMAGE_SIZE should be assigned the Image dimensions in the form of string. The Format should be \"dim1,dim2\". <br>\nAny deviation for the variable names or their format of value assignment, it will lead to errors while calling get_unlabeled_tfrecord_format(). <br>\nFollow the code cell below to know more.","f04b2276":"### I.I Convert entire Labeled Data to TfRecords Dataset","0a088d7f":"You might sometimes need to visualize the tfrecords dataset generated or obtained from 3rd party. quick_ml supports visualizing data for both Labeled TFRecords & Unlabeled TFRecords.","6c55b9e4":"## III. Visualizing the Dataset (TFRecords)","7db1a4a2":"### Installing quick_ml","002e829d":"Note :- Please **do not** waste TPU compute hours for generating TFRecords. TFRecords generation is performed by CPU.","775fa7e7":"# Official Website -> [quick_ml](https:\/\/www.quickml.info)","cf910e6f":"## Summary -> <br>\nIn this notebook, we'll learn how to generate TFRecords Dataset using quick_ml. As of now, quick_ml supports data generation for Image Classification Tasks. Further support will be gradually added.","9ab977a1":"### You can use Google Colab Notebooks for Dataset creation. Obtain the datasets from Google Colab by downloading. Upload the TFRecords Dataset on Kaggle as Public Dataset. Use them as input in Kaggle Kernels.","68634fac":"This will be asked while reading of the tfrecords dataset. Make sure you don't lose it else you'll have to repeat the process of tfrecords dataset creation and save the Format.","dff89588":"Split the dataset in a certain defined ratio. <br>","8ed7a3d9":"We have finally obtained the Labeled Dataset.","83c0ddd0":"##### Check one image and its idnum","81967fb3":"##### Check a batch of images along with their labels in a grid","e20fe98b":"Our dataset follows the format of <br>\ndata folder| <br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |-> Class 1 folder<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |-> Class 2 folder<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |-> Class 3 folder<br>\n&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;  |-> Class 4 folder<br><br>\n\nand is labeled data. We'll be using the section of Labeled Data and Part (a) on the page, https:\/\/www.quickml.info\/making-custom-datasets-tfrecords, and follow the instructions. <br>\nHere, create_tfrecord_labeled() will be used to generated TFRecords Dataset. <br>\nget_addrs_labels() is used to obtain the addresses and labels of the files in the dataset.","216bd92f":"### Obtain the Dataset (Cats & Dogs Dataset)","1c071f01":"For reading the Dataset (Labeled or Unlabeled), you need to have the TFRecords Format of the Dataset. <br>\n<br>\nFor reading labeled TFRecords Dataset, use **get_labeled_tfrecord_format** function present at **begin_tpu** module of **quick_ml** package. <br>\nFor labeled TFRecords File, you need two variables. <br>\n1. dictionary_labeled <br>\n2. IMAGE_SIZE <br>\n\n\"dictionary_labeled\" should be assigned the dictionary of Labeled TFRecord Data which we can obtain by scrolling above by referencing to the location where we saved the format. <br>\nIMAGE_SIZE should be assigned the Image dimensions in the form of string. The Format should be \"dim1,dim2\". <br>\nAny deviation for the variable names or their format of value assignment, it will lead to errors while calling get_labeled_tfrecord_format(). <br>\nFollow the code cell below to know more.","c82caace":"##### Check any one image and its corresponding label","be7fdc3e":"#### III.II Unlabeled TFRecords Data File","acbdab64":"##### Check a batch of images and their idnums","498a0b5d":"Learn more here -> https:\/\/www.quickml.info\/visualize-check-data","6a455fe0":"## Necessary Imports\n\nPlease maintain the order of imports, i.e., tensorflow then quick_ml","95f0696e":"The previous method generated a single, tfrecords file. <br>\nHowever, it is an usual practice to generate two parts of the labeled data, training & validation. <br>\nTo achieve the same, quick_ml provides create_split_tfrecords_data(). Learn more [here](https:\/\/www.quickml.info\/making-custom-datasets-tfrecords).","fa898548":"After tfrecords are successfully made, you will receive the Labeled TFRecord Format. <br>\n\nSave the Labeled TFRecord Format somewhere like in the cell below as a markdown text. eg. <br>\n\n{\n\t\t\t'image' : tf.io.FixedLenFeature([], tf.string),\n\t\t\t'label' : tf.io.FixedLenFeature([], tf.int64)\n\t\t\t}","0ece122e":"## I. Create Labeled TFRecords Dataset","b13e52f8":"Obtain the unlabeled TFRecords Format from the output. As above, save the unlabeled data format in a markdown or anywhere where you can reference it at a later stage. <br>\n**Unlabeled Data Format** -> <br>\n{\n\t\t\t'image' : tf.io.FixedLenFeature([], tf.string),\n\t\t\t'idnum' : tf.io.FixedLenFeature([], tf.string)\n\t\t\t}","5aef59e3":"Obtaining the cats & dogs dataset. Naming the downloaded file as catsdogs.zip","f9d719cc":"Not running this code cell on kaggle kernel as the disk space isn't sufficient to support. You can use Google Colab Notebooks for Dataset creation. Obtain the datasets from Google Colab by downloading. Upload the TFRecords Dataset on Kaggle as Public Dataset. Use them as input in Kaggle Kernels."}}