{"cell_type":{"4202e696":"code","3a8a5a62":"code","5b666569":"code","f933568d":"code","403adc3e":"code","e7104dad":"code","e376aeed":"code","12270f46":"code","303cddaa":"code","1c5d9d5c":"code","be94dc85":"code","5d5d622e":"code","c0bb3336":"code","c7299b30":"code","e30132bb":"code","b576bccb":"code","1342abd4":"code","b2f65724":"code","e9a1e533":"code","f7a435e5":"code","b32678dd":"code","2f7a09e7":"code","e0b452c8":"code","a0b5e88e":"code","0cea5fa8":"code","5b538ff8":"code","be067f03":"code","33979d70":"code","9149afd4":"code","f101fff2":"code","6de316f3":"code","6a779704":"code","9fef411c":"code","9e0ab220":"code","323ee2cc":"code","e6ef33e3":"code","72bb523b":"code","cc2aba92":"code","a74f0912":"code","62243713":"code","82e96b92":"code","3471380a":"markdown","7cf4d4f7":"markdown","dd2928cb":"markdown","2aed454a":"markdown","74c06db6":"markdown","7c2105f7":"markdown","51a3398f":"markdown","829753e0":"markdown","74b31385":"markdown"},"source":{"4202e696":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3a8a5a62":"!pip install tf-nightly","5b666569":"import os\n\nimport numpy as np\n\nimport matplotlib.pyplot as plt","f933568d":"import tensorflow as tf\nprint(tf.__version__)","403adc3e":"! unzip \/kaggle\/input\/platesv2\/plates.zip\n","e7104dad":"! ls \n","e376aeed":"import tensorflow_datasets as tfds\ntfds.disable_progress_bar()","12270f46":"image_size = (200, 200)\nbatch_size = 10","303cddaa":"raw_train = tf.keras.preprocessing.image_dataset_from_directory(\n    \"plates\/train\",\n    validation_split=0.3,\n    subset=\"training\",\n    seed=1307,\n    image_size=image_size,\n    batch_size=batch_size,\n)\nraw_validation = tf.keras.preprocessing.image_dataset_from_directory(\n    \"plates\/train\",\n    validation_split=0.3,\n    subset=\"validation\",\n    seed=1307,\n    image_size=image_size,\n    batch_size=batch_size,\n)\n","1c5d9d5c":"raw_train","be94dc85":"raw_validation","5d5d622e":"import matplotlib.pyplot as plt\n\nplt.figure(figsize=(10, 10))\nfor images, labels in raw_train.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(images[i].numpy().astype(\"uint8\"))\n        plt.title(int(labels[i]))\n        plt.axis(\"off\")","c0bb3336":"IMG_SIZE = 200 # All images will be resized to 160x160\n\ndef format_example(image, label):\n    image = tf.cast(image, tf.float32)\n    image = (image\/127.5) - 1\n    image = tf.image.resize(image, (IMG_SIZE, IMG_SIZE))\n    return image, label","c7299b30":"train = raw_train.map(format_example)\nvalidation = raw_validation.map(format_example)","e30132bb":"train","b576bccb":"validation","1342abd4":"BATCH_SIZE = 32\nSHUFFLE_BUFFER_SIZE = 20","b2f65724":"train_batches = train.shuffle(SHUFFLE_BUFFER_SIZE).batch(BATCH_SIZE)\nvalidation_batches = validation.batch(BATCH_SIZE)\n","e9a1e533":"train_batches","f7a435e5":"validation_batches","b32678dd":"def plotImages(images_arr):\n    fig, axes = plt.subplots(1, 5, figsize=(20,20))\n    axes = axes.flatten()\n    for img, ax in zip( images_arr, axes):\n        ax.imshow(img)\n        ax.axis('off')\n    plt.tight_layout()\n    plt.show()","2f7a09e7":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n","e0b452c8":"image_gen_train = ImageDataGenerator(\n                    rescale=1.\/255,\n                    rotation_range=15,\n                    width_shift_range=.1,\n                    height_shift_range=.1,\n                    horizontal_flip=True,\n                    zoom_range=0.1, \n                    brightness_range=[0.8,1.0]\n                    )","a0b5e88e":"PATH =  'plates'\ntrain_ds = os.path.join(PATH, 'train')\ntrain_ds","0cea5fa8":"train_data_gen = image_gen_train.flow_from_directory(batch_size=batch_size,\n                                                     directory=train_ds,\n                                                     shuffle=True,\n                                                     target_size=(IMG_SIZE, IMG_SIZE),\n                                                     class_mode='binary', \n)","5b538ff8":"sample_train, _ = next(train_data_gen)\nplotImages(sample_train[:5])","be067f03":"IMG_SHAPE = (IMG_SIZE, IMG_SIZE, 3)\n\n# Create the base model from the pre-trained model MobileNet V2\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n","33979d70":"base_model.trainable = False","9149afd4":"# Let's take a look at the base model architecture\nbase_model.summary()","f101fff2":"image_batch = sample_train[:batch_size]\nimage_batch.shape","6de316f3":"feature_batch = base_model(image_batch)\nprint(feature_batch.shape)","6a779704":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","9fef411c":"prediction_layer = tf.keras.layers.Dense(1)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","9e0ab220":"model = tf.keras.Sequential([\n  base_model,\n  global_average_layer,\n  prediction_layer\n])","323ee2cc":"base_learning_rate = 0.0001\nmodel.compile(optimizer=tf.optimizers.RMSprop(lr=base_learning_rate),\n              loss=tf.losses.BinaryCrossentropy(from_logits=True),\n              metrics=[tf.metrics.BinaryAccuracy(threshold=0.0, name='accuracy')])","e6ef33e3":"model.summary()","72bb523b":"len(model.trainable_variables)\n","cc2aba92":"initial_epochs = 10\nvalidation_steps=20\n\n","a74f0912":"test_datagen = ImageDataGenerator()\ntest_generator = test_datagen.flow_from_directory(  \n        'plates',\n        classes=['test'],\n        target_size = (IMG_SIZE, IMG_SIZE),\n        batch_size = 1,\n        shuffle = False,        \n        class_mode = None)  ","62243713":"sub_df = pd.read_csv('..\/input\/platesv2\/sample_submission.csv')\nsub_df.head()","82e96b92":"sub_df.to_csv('sub.csv', index=False)\nprint('done!!!')","3471380a":"# Install TensorFlow 2\n","7cf4d4f7":"## Compile the model","dd2928cb":"# Resize the images\n","2aed454a":"# Feature extraction","74c06db6":"# Import Data","7c2105f7":"# Create the base model from the pre-trained convnets","51a3398f":"## Display images","829753e0":"## Add a classification head","74b31385":"# Data preprocessing\n\n## Data download"}}