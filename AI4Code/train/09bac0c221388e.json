{"cell_type":{"99c24dcf":"code","31e16928":"code","2ac34077":"code","89c510e2":"code","8e75edef":"code","a6de5f11":"markdown","b60c109b":"markdown","419367f7":"markdown","84cf9592":"markdown","73529496":"markdown","9ce60dc0":"markdown","7cb2cf12":"markdown","dbb03cd1":"markdown","184c3d12":"markdown","aa041e42":"markdown","50773391":"markdown","524771f1":"markdown","8bac3d2a":"markdown","76aca5da":"markdown","db73ab2a":"markdown"},"source":{"99c24dcf":"import spacy\nimport textwrap\nfrom spacy.lang.en.stop_words import STOP_WORDS\nfrom string import punctuation\nfrom heapq import nlargest\npunctuation += '\\n' \nstopwords = list(STOP_WORDS)\n\nreduction_rate = 0.1  #Shows how small the output summary should be compared with the input\n","31e16928":"text = \"\"\"I saw ABC back in Neuro-Oncology Clinic today. He comes in for an urgent visit because of increasing questions about what to do next for his anaplastic astrocytoma.\nWithin the last several days, he has seen you in clinic and once again discussed whether or not to undergo radiation for his left temporal lesion. The patient has clearly been extremely ambivalent about this therapy for reasons that are not immediately apparent. It is clear that his MRI is progressing and that it seems unlikely at this time that anything other than radiation would be particularly effective. Despite repeatedly emphasizing this; however, the patient still is worried about potential long-term side effects from treatment that frankly seem unwarranted at this particular time.\nAfter seeing you in clinic, he and his friend again wanted to discuss possible changes in the chemotherapy regimen. They came in with a list of eight possible agents that they would like to be administered within the next two weeks. They then wanted another MRI to be performed and they were hoping that with the use of this type of approach, they might be able to induce another remission from which he can once again be spared radiation.\nFrom my view, I noticed a man whose language has deteriorated in the week since I last saw him. This is very worrisome. Today, for the first time, I felt that there was a definite right facial droop as well. Therefore, there is no doubt that he is becoming symptomatic from his growing tumor. It suggests that he is approaching the end of his compliance curve and that the things may rapidly deteriorate in the near future.\nEmphasizing this once again, in addition, to recommending steroids I once again tried to convince him to undergo radiation. Despite an hour, this again amazingly was not possible. It is not that he does not want treatment, however. Because I told him that I did not feel it was ethical to just put him on the radical regimen that him and his friend devised, we compromised and elected to go back to Temodar in a low dose daily type regimen. We would plan on giving 75 mg\/sq m everyday for 21 days out of 28 days. In addition, we will stop thalidomide 100 mg\/day. If he tolerates this for one week, we then agree that we would institute another one of the medications that he listed for us. At this stage, we are thinking of using Accutane at that point.\nWhile I am very uncomfortable with this type of approach, I think as long as he is going to be monitored closely that we may be able to get away with this for at least a reasonable interval. In the spirit of compromise, he again consented to be evaluated by radiation and this time, seemed more resigned to the fact that it was going to happen sooner than later. I will look at this as a positive sign because I think radiation is the one therapy from which he can get a reasonable response in the long term.\nI will keep you apprised of followups. If you have any questions or if I could be of any further assistance, feel free to contact me.\"\"\"","2ac34077":"nlp_pl = spacy.load('en_core_web_sm')     #process original text according with the Spacy nlp pipeline for english\ndocument = nlp_pl(text)                   #doc object\n\ntokens = [token.text for token in document] #tokenized text\n\nword_frequencies = {}\nfor word in document:\n    if word.text.lower() not in stopwords:\n        if word.text.lower() not in punctuation:\n            if word.text not in word_frequencies.keys():\n                word_frequencies[word.text] = 1\n            else:\n                word_frequencies[word.text] += 1\n\nmax_frequency = max(word_frequencies.values())\nprint(max_frequency)\n\nfor word in word_frequencies.keys():\n    word_frequencies[word] = word_frequencies[word]\/max_frequency\n\nprint(word_frequencies)","89c510e2":"sentence_tokens = [sent for sent in document.sents]\n\ndef get_sentence_scores(sentence_tok, len_norm=True):\n  sentence_scores = {}\n  for sent in sentence_tok:\n      word_count = 0\n      for word in sent:\n          if word.text.lower() in word_frequencies.keys():\n              word_count += 1\n              if sent not in sentence_scores.keys():\n                  sentence_scores[sent] = word_frequencies[word.text.lower()]\n              else:\n                  sentence_scores[sent] += word_frequencies[word.text.lower()]\n      if len_norm:\n        sentence_scores[sent] = sentence_scores[sent]\/word_count\n  return sentence_scores\n                \nsentence_scores = get_sentence_scores(sentence_tokens,len_norm=False)        #sentence scoring without lenght normalization\nsentence_scores_rel = get_sentence_scores(sentence_tokens,len_norm=True)     #sentence scoring with length normalization","8e75edef":"def get_summary(sentence_sc, rate):\n  summary_length = int(len(sentence_sc)*rate)\n  summary = nlargest(summary_length, sentence_sc, key = sentence_sc.get)\n  final_summary = [word.text for word in summary]\n  summary = ' '.join(final_summary)\n  return summary\n\nprint(\"Lenghty description: \"+ get_summary(sentence_scores, reduction_rate))\nprint(\"Concise: \"+ get_summary(sentence_scores_rel, reduction_rate))","a6de5f11":"<img src= \"https:\/\/images.pexels.com\/photos\/6801648\/pexels-photo-6801648.jpeg?auto=compress&cs=tinysrgb&dpr=2&h=650&w=940\" alt =\"Document\" style='width: 1050px;'>","b60c109b":"Based on the output type, document summarization can be:\n\n* Extractive: the summary is extracted from the input text. The output is usually the concatenation of the most important sentences of the original text.\n\n* Abstractive: the summary is generated. This means that we use the original text to learn internal representations and then we use such representations to generate new text. The output is original, not a combination\/concatenation of the input sentences.\n\n* Mixed: produce an abstractive summary after identifying an extractive intermediate state or they can choose which approach to use (eg: pointer models) based on the particulars of the text.\n","419367f7":"# What is Document Summarization?","84cf9592":"# Summarization Methods and Implementation","73529496":"Here we utilize the SpaCy NLP pipeline for English, which is very handy because it returns a Doc object that contains the already tokenized and preprocessed text, split into words and sentences.","9ce60dc0":"## Frequency-Based Sentence Scoring","7cb2cf12":"<img src= \"https:\/\/miro.medium.com\/max\/875\/1*SM41ES3n-q71Xn8zCIdRMw.png\" alt =\"Document\" style='width: 1000px;'>","dbb03cd1":"> This approach is the most facile and most straightforward one. Here we utilize information theory to assign each sentence of the input with a score that is predicated on relative frequencies. A high value for a sentence betokens that its content is liable to be informative.","184c3d12":"We have plenty of summarization algorithms today. Assessing which one is the best is a chance hit, though. First of all, there is no clear consensus on which metrics to utilize to evaluate these systems. Moreover, the best summarization technique is highly dependent on the domain and the type of text you are intrigued with summarizing.","aa041e42":"Text Summarization is a **Natural Language Processing** (NLP) task in which we try to create a summary starting from a textual input like books, articles, news.\n\nWhen the source is a document (in our case a clinical document \ud83d\udcdd and like discharge letters) it is calles document summarization.","50773391":"The final summary is made with the nlargest function from heapq module, which efficiently returns the **k sentences with the highest score**.","524771f1":"I already mentioned how extractive summarization is essentially based on **sentence scoring**. Therefore, we need to find a way to give an **importance score** to each sentence, so that we can include in the summary the most important ones. To give each sentence a score, we **sum the relative word frequencies** in each sentence and then we create a dictionary that pairs the sentences and their scores.","8bac3d2a":"As we expected, the **first output shows verbose and content-heavy sentences**, while the **second one is much more concise**. The second summary withal inclines to focus more on what is going well with the patient, omitting consequential information about what the doctor is worried about.","76aca5da":"# Summarizing Medical Documents using spacy","db73ab2a":"WE will be using **spacy**, a fantastic library designed to implement standard NLP pipelines expeditiously and smoothly, we can implement this with a few lines of code."}}