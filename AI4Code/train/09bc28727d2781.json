{"cell_type":{"2f753f3c":"code","b69f45f0":"code","fa06ad7f":"code","b177db94":"code","96b4767c":"code","52bb8602":"code","915fa1b1":"code","d54615d2":"code","55f4c881":"code","fe676230":"code","2c37d4c3":"code","50f9b842":"code","35e9f5be":"code","1aebffad":"code","47f0d941":"code","046a1931":"code","9447526a":"code","42255d66":"code","134b81ad":"code","49d4f55b":"code","fa2f9bc1":"code","e15c7b4e":"code","eda300f0":"code","4b84c8dd":"code","194ac948":"code","0d475021":"code","a18e07c0":"code","37de18f2":"markdown","1cc8a499":"markdown","c0031185":"markdown","dbf6a26a":"markdown","8f78f490":"markdown","13b11685":"markdown","f3627654":"markdown","f8681e83":"markdown","9cb3b148":"markdown","1fd88cdb":"markdown","b61cca53":"markdown","207e53ee":"markdown","1181a627":"markdown","ac0fd97d":"markdown","1bc6bcb1":"markdown"},"source":{"2f753f3c":"!pip install -U efficientnet","b69f45f0":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.metrics import roc_curve,auc,classification_report,confusion_matrix\nimport matplotlib.pyplot as plt\nfrom PIL import Image\nimport cv2\nimport tensorflow.keras\nimport json\nfrom tensorflow.keras.models import Sequential\nfrom tensorflow.keras.layers import Conv2D,MaxPooling2D,Dense,Flatten,Dropout  \nfrom tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint,ReduceLROnPlateau\nfrom tensorflow.keras.models import Model\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import models\nfrom tensorflow.keras.optimizers import Adam,SGD,RMSprop,Adamax\nfrom tensorflow.keras.models import Model, Sequential\nfrom tensorflow.keras.callbacks import ReduceLROnPlateau\nfrom sklearn.model_selection import StratifiedKFold\nfrom efficientnet.keras import EfficientNetB3\nfrom random import shuffle\nfrom tqdm import tqdm  \nimport scipy\nimport skimage\nfrom skimage.transform import resize\nimport random\nimport os","fa06ad7f":"df = pd.read_csv('\/kaggle\/input\/cassava-leaf-disease-classification\/train.csv')\ndf.head(5)","b177db94":"with open('\/kaggle\/input\/cassava-leaf-disease-classification\/label_num_to_disease_map.json') as f:\n    mapping = json.loads(f.read())\n    print(mapping)","96b4767c":"df['label'].value_counts()","52bb8602":"def visualize(img_list):\n    rows = 3\n    cols = 3\n\n    plt.figure(figsize=(18, 10))\n\n    for i in range(rows*cols):\n        plt.subplot(10\/cols+1, cols, i+1)\n        r = np.random.randint(len(img_list))\n        img_path = \"\/kaggle\/input\/cassava-leaf-disease-classification\/train_images\/\" + str(img_list[r])\n        img = cv2.imread(img_path)\n        img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n        plt.xticks([])\n        plt.yticks([])\n        plt.title(str(img_list[r]))\n        plt.imshow(img)\n       \n\n    plt.tight_layout()\n    plt.show()","915fa1b1":"cbb_df = df[df['label'].isin([0])]\ncbb_img_list = list(df['image_id'])\n\nvisualize(cbb_img_list)","d54615d2":"cbb_df = df[df['label'].isin([1])]\ncbb_img_list = list(df['image_id'])\n\nvisualize(cbb_img_list)","55f4c881":"cbb_df = df[df['label'].isin([2])]\ncbb_img_list = list(df['image_id'])\n\nvisualize(cbb_img_list)","fe676230":"cbb_df = df[df['label'].isin([3])]\ncbb_img_list = list(df['image_id'])\n\nvisualize(cbb_img_list)","2c37d4c3":"cbb_df = df[df['label'].isin([4])]\ncbb_img_list = list(df['image_id'])\n\nvisualize(cbb_img_list)","50f9b842":"BATCH_SIZE = 16\nTARGET_SIZE = 224\nBASE_DIR = \"\/kaggle\/input\/cassava-leaf-disease-classification\/\"\nEPOCHS = 10","35e9f5be":"def preprocess(image):\n    #Converting to numpy array from numpy tensor with rank 3\n    image = np.array(image, dtype=np.uint8)\n    #Gaussian Blur\n    gaussian_blur = cv2.GaussianBlur(image,(5,5),0)\n    img = np.asarray(gaussian_blur, dtype=np.float64)\n    return img","1aebffad":"#Converting labels to string to use sparse class mode\ndf.label = df.label.astype('str')","47f0d941":"from tensorflow.keras.preprocessing.image import ImageDataGenerator\n#Training  Augumentation\ndatagen = ImageDataGenerator(rescale=1.0\/255,\n                             featurewise_center=True,\n                             featurewise_std_normalization=True,\n                             rotation_range=30,\n                             width_shift_range=0.3,\n                             height_shift_range=0.3,\n                             shear_range=15.0,\n                             zoom_range=0.2,\n                             horizontal_flip=True,\n                             brightness_range=[0.2, 0.8],\n                             validation_split=0.2,\n                             fill_mode='nearest',\n                             preprocessing_function=preprocess)\n\n\ntrain_datagen = datagen.flow_from_dataframe(df,\n                                            directory = os.path.join(BASE_DIR, \"train_images\"),\n                                            subset = \"training\",\n                                            x_col = \"image_id\",\n                                            y_col = \"label\",\n                                            target_size = (TARGET_SIZE, TARGET_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"sparse\")\n\n#Validation\nvalidation_datagen = ImageDataGenerator(rescale=1.0\/255,\n                                        validation_split=0.2,\n                                       preprocessing_function=preprocess)\n\n\nvalid_datagen = validation_datagen.flow_from_dataframe(df,\n                                            directory = os.path.join(BASE_DIR, \"train_images\"),\n                                            subset = \"validation\",\n                                            x_col = \"image_id\",\n                                            y_col = \"label\",\n                                            target_size = (TARGET_SIZE, TARGET_SIZE),\n                                            batch_size = BATCH_SIZE,\n                                            class_mode = \"sparse\")","046a1931":"#He Uniform Initializer for Dense Layer\nimport tensorflow as tf\ndef my_init(shape, dtype=None):\n    initializer = tf.keras.initializers.he_uniform(seed = 1)\n    return initializer(shape, dtype=dtype)\n","9447526a":"base_model = EfficientNetB3(weights = 'imagenet', include_top=False, input_shape = (TARGET_SIZE, TARGET_SIZE, 3), pooling=None)\n\nbase_output = base_model.output\npooling_layer = layers.GlobalAveragePooling2D()(base_output)\nDense1 = layers.Dense(256, activation = \"relu\", kernel_initializer=my_init)(pooling_layer)\nBN1 = layers.BatchNormalization()(Dense1)\ndropout = layers.Dropout(0.2)(BN1)\nmodel = layers.Dense(5, activation=\"softmax\")(dropout)\n\nmodel = models.Model(base_model.input, model)\n\nmodel.compile(optimizer = 'adam', \n              loss = \"sparse_categorical_crossentropy\", \n              metrics=[\"acc\"])\nmodel.summary()","42255d66":"from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n\nfilepath = \"model.h5\"\n    \ncallbacks = [ReduceLROnPlateau(monitor='val_loss', patience=1, verbose=1, factor=0.1),\n             EarlyStopping(monitor='val_loss', patience=2),\n             ModelCheckpoint(filepath=filepath, monitor='val_loss', save_best_only=True)]","134b81ad":"history = model.fit(train_datagen, epochs = EPOCHS, validation_data = valid_datagen, callbacks=callbacks)","49d4f55b":"plt.style.use(\"ggplot\")\nplt.figure()\nN = 8\nplt.plot(np.arange(0, 8), history.history[\"acc\"], label=\"train_acc\")\nplt.plot(np.arange(0, 8), history.history[\"val_acc\"], label=\"val_acc\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()\n","fa2f9bc1":"plt.style.use(\"ggplot\")\nplt.figure()\nN = 8\nplt.plot(np.arange(0, 8), history.history[\"loss\"], label=\"train_loss\")\nplt.plot(np.arange(0, 8), history.history[\"val_loss\"], label=\"val_loss\")\nplt.title(\"Accuracy\")\nplt.xlabel(\"Epoch #\")\nplt.ylabel(\"Loss\/Accuracy\")\nplt.legend(loc=\"upper left\")\nplt.show()\n","e15c7b4e":"layer_outputs = [layer.output for layer in model.layers[1:15]]\n\n# This is image of a Rose flower from our dataset. All of the visualizations in this cell are of this image.\ntest_image = BASE_DIR+'test_images\/2216849948.jpg'","eda300f0":"from keras.models import Model\nimport numpy as np\nim=[]\nlayer_outputs = [layer.output for layer in model.layers]\nactivation_model = Model(inputs=model.input, outputs=layer_outputs)\nimage=cv2.imread(test_image)\nimage_from_array = Image.fromarray(image, 'RGB')\nsize_image = image_from_array.resize((224, 224))\nim.append(np.array(size_image))\nfv=np.array(im)\nfv = fv.astype('float32')\/255\nactivations = activation_model.predict(fv)\n \ndef display_activation(activations, col_size, row_size, act_index): \n    activation = activations[act_index]\n    activation_index=0\n    fig, ax = plt.subplots(row_size, col_size, figsize=(row_size*4.5,col_size*2.5))\n    for row in range(0,row_size):\n        for col in range(0,col_size):\n            ax[row][col].imshow(activation[0, :, :, activation_index], cmap='gray')\n            activation_index += 1","4b84c8dd":"display_activation(activations, 4, 6, 1)","194ac948":"display_activation(activations, 4, 6, 3)","0d475021":"display_activation(activations, 4, 6, 5)","a18e07c0":"display_activation(activations, 4, 6, 6)","37de18f2":"### Visualize Disease Types","1cc8a499":"### Class 3 : Cassava Mosiac Disease (CMD)","c0031185":"### Model Inspection \n\nIn this step we have visualized the activation layers of the model","dbf6a26a":"So, lets map the label number to actual names i.e., disease types","8f78f490":"### Class 4 : Healthy Leaves","13b11685":"There is a huge class imbalance and in it Cassava Mosaic Disease has majority of samples which is more than 6 times to other diseases.","f3627654":"### Class 0 : Cassava Bacterial Blight (CBB)","f8681e83":"### Import Libraries","9cb3b148":"### Class 1 : Cassava Brown Streak Disease (CBSD)","1fd88cdb":"### Data Augmentation","b61cca53":"### Class 2 : Cassava Green Mottle (CGM)","207e53ee":"### Image Pre-processing","1181a627":"### Defining Hyperparameters","ac0fd97d":"## Defining Model","1bc6bcb1":"### Target Distribution\n"}}