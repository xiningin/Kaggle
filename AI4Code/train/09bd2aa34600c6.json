{"cell_type":{"b45f5e22":"code","319996ff":"code","101bd768":"code","5f3c09d4":"code","374b2e6a":"code","7212fe5b":"code","1acf47f4":"code","95c48898":"code","58949933":"code","f90f1180":"code","a39cb98b":"code","2f729690":"code","683c028c":"code","0392f2b9":"code","6d53cf11":"code","c30556bc":"code","a024f1eb":"code","87e3153c":"code","a3f211c6":"code","32fd8aec":"code","63cbb48e":"code","14ebc4cb":"code","ff1c3471":"code","ad912c7e":"code","16ee9bc9":"code","0a36e49d":"code","024d101e":"code","1c88061f":"code","01c35bd4":"markdown","9fda0307":"markdown","f9022737":"markdown","9a59aec7":"markdown","eeb1f506":"markdown","46710f3e":"markdown","76968f04":"markdown","354c5843":"markdown","53c9a526":"markdown"},"source":{"b45f5e22":"# packages\n\n# standard\nimport numpy as np\nimport pandas as pd\nimport time\n\n# plots\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom statsmodels.graphics.mosaicplot import mosaic\n\n# machine learning tools\nimport h2o\nfrom h2o.estimators import H2OGradientBoostingEstimator","319996ff":"# load data + first glance\ndf_train = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/train.csv')\ndf_test = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/test.csv')\ndf_sub = pd.read_csv('..\/input\/tabular-playground-series-jun-2021\/sample_submission.csv')\n\n# first glance (training data)\ndf_train.head()","101bd768":"# dimensions\nprint('Train Set:', df_train.shape)\nprint('Test Set :', df_test.shape)","5f3c09d4":"# structure\ndf_train.info()","374b2e6a":"# basic stats\/plot\nprint(df_train.target.value_counts())\ndf_train.target.value_counts().sort_index().plot(kind='bar')\nplt.grid()\nplt.show()","7212fe5b":"# plot sorted\ndf_train.target.value_counts().plot(kind='bar')\nplt.grid()\nplt.show()","1acf47f4":"# extract features from column names\nfeatures = df_train.columns.tolist()\nfeatures.remove('id')\nfeatures.remove('target')","95c48898":"# basic summary stats\npd.set_option('display.max_columns', None) # show all columns\ndf_train[features].describe()","58949933":"# plot all features in one plot\ndf_train.boxplot(column=features, figsize=(16,6))\nplt.xticks(rotation=90)\nplt.title('Boxplot of features')\nplt.show()","f90f1180":"# correlation of features\ncorr_pearson = df_train[features].corr(method='pearson')\nplt.figure(figsize=(12,12))\nsns.heatmap(corr_pearson, annot=False, cmap='RdYlGn', vmin=-1, vmax=+1)\nplt.title('Pearson Correlation')\nplt.show()","a39cb98b":"print('Maximum correlation:', np.round(corr_pearson[corr_pearson!=1].max().max(),5))\nprint('Minimum correlation:', np.round(corr_pearson[corr_pearson!=1].min().min(),5))","2f729690":"# create data frame to store all results\nn_features = len(features)\ncor_stats = pd.DataFrame(data=np.zeros((n_features**2,4)), columns=['x','y','corr','sel'])\ncor_stats.x = cor_stats.x.astype(str)\ncor_stats.y = cor_stats.y.astype(str)\n\n# calc and store all correlations in data frame\ncount = 1 # count correlations exceeding threshold\nrow = 0\nfor i in range(n_features):\n    var_i = features[i]\n    for j in range(n_features):\n        var_j = features[j]            \n        cor_x = df_train[var_i].corr(df_train[var_j])\n        # store results\n        cor_stats.loc[row,'x'] = var_i\n        cor_stats.loc[row,'y'] = var_j\n        cor_stats.loc[row,'corr'] = cor_x\n        if (i>j):\n            cor_stats.loc[row,'sel'] = 1 # we use this to later remove redundancies\n                \n        row = row + 1\n\n# remove redundancies\ncor_stats = cor_stats[cor_stats.sel==1] # only select \"i > j\" cases\ncor_stats = cor_stats.drop(['sel'], axis=1)\n# sort by correlation (descending)\ncor_stats = cor_stats.sort_values(by=['corr'], ascending=False)\ncor_stats = cor_stats.reset_index(drop=True)","683c028c":"# show top 10 correlations\ncor_stats.head(10)","0392f2b9":"# select predictors\npredictors = features\nprint('Number of predictors: ', len(predictors))","6d53cf11":"# start H2O\nh2o.init(max_mem_size='12G', nthreads=4) # Use maximum of 12 GB RAM and 4 cores","c30556bc":"# upload data frames in H2O environment\nt1 = time.time()\ntrain_hex = h2o.H2OFrame(df_train)\ntest_hex = h2o.H2OFrame(df_test)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))\n\n# force categorical target\ntrain_hex['target'] = train_hex['target'].asfactor()","a024f1eb":"# fit Gradient Boosting model\nn_cv = 5\n\nfit_GBM = H2OGradientBoostingEstimator(ntrees=750,\n                                       max_depth=6,\n                                       min_rows=25,\n                                       learn_rate=0.01, # default: 0.1\n                                       sample_rate=1,\n                                       col_sample_rate=0.5,\n                                       nfolds=n_cv,\n                                       score_each_iteration=True,\n                                       stopping_metric='logloss',\n                                       stopping_rounds=5,\n                                       stopping_tolerance=0.0001,\n                                       seed=999)\n# train model\nt1 = time.time()\nfit_GBM.train(x=predictors,\n              y='target',\n              training_frame=train_hex)\nt2 = time.time()\nprint('Elapsed time [s]: ', np.round(t2-t1,2))","87e3153c":"# show cross validation metrics\nfit_GBM.cross_validation_metrics_summary()","a3f211c6":"# show scoring history - training vs cross validations\nfor i in range(n_cv):\n    cv_model_temp = fit_GBM.cross_validation_models()[i]\n    df_cv_score_history = cv_model_temp.score_history()\n    my_title = 'CV ' + str(1+i) + ' - Scoring History'\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.training_logloss, \n                c='blue', label='training')\n    plt.scatter(df_cv_score_history.number_of_trees,\n                y=df_cv_score_history.validation_logloss, \n                c='darkorange', label='validation')\n    plt.title(my_title)\n    plt.xlabel('Number of Trees')\n    plt.ylabel('logloss')\n    plt.ylim(1.5,2.5)\n    plt.legend()\n    plt.grid()\n    plt.show()","32fd8aec":"# variable importance\nfit_GBM.varimp_plot(25)","63cbb48e":"# predict on train set\npred_train_GBM = fit_GBM.predict(train_hex).as_data_frame()\n# add ground truth\npred_train_GBM['target'] = train_hex['target'].as_data_frame()\npred_train_GBM.head()","14ebc4cb":"# predicted frequencies\nclasses = ['Class_1', 'Class_2', 'Class_3',\n           'Class_4', 'Class_5', 'Class_6',\n           'Class_7', 'Class_8', 'Class_9']\n\npred_train_GBM[classes].sum()","ff1c3471":"# actual frequencies\ndf_train.target.value_counts().sort_index()","ad912c7e":"# confusion matrix - training data\nconf_train = pd.crosstab(pred_train_GBM.target, pred_train_GBM.predict)\nsns.heatmap(conf_train, cmap='Blues',\n            annot=True, fmt='d',\n            vmin=0, vmax=40000,\n            linecolor='black',\n            linewidths=0.1)\nplt.title('Confusion Matrix - Training')\nplt.show()","16ee9bc9":"# predict on test set\npred_test_GBM = fit_GBM.predict(test_hex).as_data_frame()\npred_test_GBM","0a36e49d":"# submission\ndf_sub_GBM = df_sub.copy()\ndf_sub_GBM.Class_1 = pred_test_GBM.Class_1\ndf_sub_GBM.Class_2 = pred_test_GBM.Class_2\ndf_sub_GBM.Class_3 = pred_test_GBM.Class_3\ndf_sub_GBM.Class_4 = pred_test_GBM.Class_4\ndf_sub_GBM.Class_5 = pred_test_GBM.Class_5\ndf_sub_GBM.Class_6 = pred_test_GBM.Class_6\ndf_sub_GBM.Class_7 = pred_test_GBM.Class_7\ndf_sub_GBM.Class_8 = pred_test_GBM.Class_8\ndf_sub_GBM.Class_9 = pred_test_GBM.Class_9\ndf_sub_GBM","024d101e":"# export submission\ndf_sub_GBM.to_csv('submission_GBM.csv', index=False)","1c88061f":"# multi-dimensional visualization of submission\nsns.pairplot(df_sub_GBM[classes],\n             diag_kws = {'alpha': 1.0},\n             plot_kws = {'alpha': 0.1})\nplt.show()","01c35bd4":"### Evaluate Predictions on Training Data","9fda0307":"#### We observe only very weak correlations between the features...","f9022737":"#### Let's extract the highest correlations:","9a59aec7":"### Predict on test set","eeb1f506":"<a id='3'><\/a>\n# Fit Model","46710f3e":"<a id='1'><\/a>\n# Target Exploration","76968f04":"<a id='2'><\/a>\n# Features","354c5843":"# Table of Contents\n* [Target Exploration](#1)\n* [Features](#2)\n* [Fit Model](#3)\n* [Evaluate Model](#4)","53c9a526":"<a id='4'><\/a>\n# Evaluate Model"}}