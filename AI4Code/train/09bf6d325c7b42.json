{"cell_type":{"faab682a":"code","300a6864":"code","c0d1da0d":"code","1da584d7":"code","5f2e7b82":"code","212eb936":"code","0e0f53fb":"code","d40df011":"code","9b3255cc":"code","e0b1e8a4":"code","148d0eac":"code","dcb5d3f7":"code","77859ac3":"code","dfabfb25":"code","b5fba4b1":"code","ce569978":"code","54593fdb":"code","549626e3":"code","b4e5b34b":"code","28a461c0":"code","e2d11189":"code","dec79e6a":"code","309f1485":"code","ede4104b":"code","0229f04c":"code","359e8626":"code","10f76668":"code","a143ebb8":"code","60b01c34":"code","c3e488d5":"code","0d97d352":"code","6e34a2bf":"code","20dd4df1":"code","f3a388dd":"code","e6f1534d":"code","f3aa9f11":"code","51fb17a7":"code","0fdf6f0d":"code","1c8774b3":"code","f371db39":"code","811ec1fd":"code","4b317232":"code","973f3624":"code","fb4513fd":"code","88f37d88":"code","eea36dd1":"code","6291cbaa":"code","3f516624":"code","651f12db":"code","1e08547a":"code","e7c7987b":"code","832df4b8":"code","59b37052":"code","8e0a6e89":"code","e0b7eaea":"code","55c8328f":"code","5d9a8403":"code","81cc997f":"code","64900cd9":"markdown","d8e0c143":"markdown","6e3cbc99":"markdown","a6d529a0":"markdown","d3122a8b":"markdown","21fa9993":"markdown","63787451":"markdown","7f2a9f57":"markdown","4a9e8f95":"markdown","d431dbc4":"markdown","9344826a":"markdown","21954fe8":"markdown","dfcd1acc":"markdown","ac1c8b7d":"markdown","f537923a":"markdown","d1c51c3c":"markdown","545e0705":"markdown","7a28d7ab":"markdown","fd7ac3e5":"markdown","54e1824d":"markdown","267553a8":"markdown","aab7c609":"markdown","1ce89b50":"markdown","575c3fc0":"markdown","83a7500d":"markdown","c204ea3e":"markdown","8064b20f":"markdown","98ba8cdb":"markdown","c8d1aeb3":"markdown","a3b427fa":"markdown","e44fe637":"markdown","668ac391":"markdown","3b06fec1":"markdown","c75a506a":"markdown","9019a7b3":"markdown","f61da39e":"markdown","cc98de5c":"markdown","4844af35":"markdown","28d6c82a":"markdown","84b0b1d7":"markdown","9837c02e":"markdown","32958673":"markdown","61583946":"markdown","9f101b57":"markdown","8ce4425b":"markdown","498a36be":"markdown","aae4a74e":"markdown","4487726d":"markdown","e9b74fd3":"markdown","634f3a5b":"markdown","87795bd8":"markdown","aadba672":"markdown","7722a4c8":"markdown","e5058241":"markdown","78fc1f32":"markdown","cb618a1c":"markdown","9fd246d2":"markdown","9dc8be3e":"markdown","a461aae8":"markdown","83a05e86":"markdown"},"source":{"faab682a":"import numpy as np              # Arrays\nimport pandas as pd             # Dataframes","300a6864":"# Leitura do arquivo de extens\u00e3o .csv para TREINO\nDadosBase = pd.read_csv(\"\/kaggle\/input\/sentiment-analysis-pmr3508\/data_train.csv\")","c0d1da0d":"DadosBase.head() # Exibi\u00e7\u00e3o da tabela de dados de TREINO","1da584d7":"print('Tamanho da Base de Dados de TREINO (linhas, colunas):', DadosBase.shape)","5f2e7b82":"DadosBase.info() # Verifica\u00e7\u00e3o de quantas observa\u00e7\u00f5es h\u00e1 por atributo","212eb936":"DadosBase.isnull().sum() # Verifica\u00e7\u00e3o de que atributos t\u00eam dados faltantes e quantos s\u00e3o","0e0f53fb":"# Verifica\u00e7\u00e3o de quantas observa\u00e7\u00f5es s\u00e3o positivas dentre todas\nDadosBase.loc[:,'positive'].value_counts()","d40df011":"# Verifica\u00e7\u00e3o da exist\u00eancia de observa\u00e7\u00f5es duplicadas\nDadosBase.loc[DadosBase.duplicated(subset='review', keep=False)==True].sort_values(by='review').head(14)","9b3255cc":"# Remo\u00e7\u00e3o de eventuais duplicatas com dados repetidos\nDadosBase = DadosBase.drop_duplicates(subset='review', keep='first')","e0b1e8a4":"print('Tamanho da Base de Dados de TREINO (linhas, colunas):', DadosBase.shape)","148d0eac":"# Verifica\u00e7\u00e3o de quantas observa\u00e7\u00f5es s\u00e3o positivas dentre todas\nDadosBase.loc[:,'positive'].value_counts()","dcb5d3f7":"# Separa\u00e7\u00e3o entre atributo de classifica\u00e7\u00e3o Y e atributos de entrada X\nDadosBaseY = np.array(DadosBase.loc[:,'positive'].tolist())  # Atributo de interesse\nDadosBaseX = DadosBase.loc[:,'review'].tolist()              # Atributos para an\u00e1lise","77859ac3":"DadosBaseX[17] # Verifica\u00e7\u00e3o de uma das observa\u00e7\u00f5es dos atributos para an\u00e1lise","dfabfb25":"DadosBaseY[17] # Verifica\u00e7\u00e3o de uma das observa\u00e7\u00f5es dos atributos de interesse","b5fba4b1":"# Biblioteca para filtrar (limpar) o texto, padronizando o banco de dados\n!pip install ftfy\n!pip install gensim","ce569978":"# Bibliotecas para o processamento de textos\nfrom ftfy import fix_text\nimport string\nimport re\nfrom gensim.test.utils import common_texts","54593fdb":"# Fun\u00e7\u00e3o para filtrar (limpar) o texto\ndef clean(text):\n    txt = text.replace(\"<br \/>\",\" \") # Retirada de tags\n    txt = fix_text(txt) # Conserto de Mojibakes (Ver https:\/\/pypi.org\/project\/ftfy\/)\n    txt = txt.lower()                # Passagem de tudo para min\u00fasculo\n    txt = txt.translate(str.maketrans('', '', string.punctuation)) # Retirada de toda a pontua\u00e7\u00e3o\n    txt = txt.replace(\" \u2014 \", \" \")    # Retirada de h\u00edfens\n    txt = re.sub(\"\\d+\", ' <number> ', txt) # Coloca\u00e7\u00e3o de um token especial para os n\u00fameros\n    txt = re.sub(' +', ' ', txt)     # Dele\u00e7\u00e3o de espa\u00e7os extras\n    return txt","549626e3":"%%time\n# Aplica\u00e7\u00e3o da fun\u00e7\u00e3o para filtrar (limpar) o texto\nDadosBaseX = [clean(x) for x in DadosBaseX]","b4e5b34b":"DadosBaseX[17] # Verifica\u00e7\u00e3o de uma das observa\u00e7\u00f5es dos atributos para an\u00e1lise","28a461c0":"# Armazenagem dos textos como vetores de palavras\nDadosBaseX = [x.split() for x in DadosBaseX]","e2d11189":"# Modelo pr\u00e9-treinado de Deep Learning para transformar textos em embeddings (vetores)\nfrom gensim.models.doc2vec import Doc2Vec, TaggedDocument","dec79e6a":"# Leitura do arquivo doc2vec\nd2v = Doc2Vec.load(\"\/kaggle\/input\/sentiment-analysis-pmr3508\/doc2vec\")","309f1485":"# A fun\u00e7\u00e3o \"most_similar\" procura palavras similares no banco de dados\nd2v.wv.most_similar(positive=['award'])","ede4104b":"# Fun\u00e7\u00e3o para obter representa\u00e7\u00f5es vetoriais\ndef emb(txt, model, normalize=False): \n    model.random.seed(42)\n    x=model.infer_vector(txt, steps=20)\n    \n    if normalize: return(x\/np.sqrt(x@x))\n    else: return(x)","0229f04c":"%%time\n# Aplica\u00e7\u00e3o da fun\u00e7\u00e3o para converter cada resenha em vetores de mesmo tamanho\nDadosBaseX = [emb(x, d2v) for x in DadosBaseX] \nDadosBaseX = np.array(DadosBaseX)","359e8626":"print('Tamanho da Base de Dados de TREINO (linhas, colunas):', DadosBaseX.shape)","10f76668":"# Bibliotecas para Machine Learning e NLP\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.neural_network import MLPClassifier\nfrom sklearn.model_selection import RandomizedSearchCV\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import roc_auc_score\nfrom scipy.stats import loguniform as sp_loguniform","a143ebb8":"%%time\n# Modelo de Rede Neural com 1 camada oculta\nmlp1l = MLPClassifier(early_stopping=True)\n\n# Hiperpar\u00e2metros a serem otimizados\nhyperParams = {'hidden_layer_sizes': [(2**i) for i in np.arange(1,10)],\n               'activation': ['identity', 'logistic', 'tanh', 'relu'],\n               'alpha': sp_loguniform(0.000001, 0.1),\n               'learning_rate': ['constant','adaptive']}\n\n# Busca de Hiperpar\u00e2metros\nclf_v1_mlp1l = RandomizedSearchCV(mlp1l, hyperParams, scoring='roc_auc', n_iter=35, cv=2, n_jobs=-1, random_state=0, verbose=2)\nsearchParams = clf_v1_mlp1l.fit(DadosBaseX, DadosBaseY)","60b01c34":"# Verifica\u00e7\u00e3o dos melhores par\u00e2metros e seus respectivos scores\nsearchParams.best_params_, searchParams.best_score_","c3e488d5":"%%time\n# Treinamento do primeiro classificador usando os hiperpar\u00e2metros ideais\nbestActivation = searchParams.best_params_[\"activation\"]\nbestAlpha = searchParams.best_params_[\"alpha\"]\nbestHLSizes = searchParams.best_params_[\"hidden_layer_sizes\"]\nbestLearningRate = searchParams.best_params_[\"learning_rate\"]\n\nmlp1l = MLPClassifier(early_stopping=True, activation=bestActivation, alpha=bestAlpha, hidden_layer_sizes=bestHLSizes, learning_rate=bestLearningRate)\nmlp1l.fit(DadosBaseX, DadosBaseY)","0d97d352":"%%time\n# Modelo de Rede Neural com 2 camadas ocultas\nmlp2l = MLPClassifier(early_stopping=True)\n\n# Hiperpar\u00e2metros a serem otimizados\nhyperParams = {'hidden_layer_sizes': [(2**i, 2**j) for i in np.arange(1,10) for j in np.arange(1,10)],\n               'activation': ['identity', 'logistic', 'tanh', 'relu'],\n               'alpha': sp_loguniform(0.000001, 0.1),\n               'learning_rate': ['constant','adaptive']}\n\n# Busca de Hiperpar\u00e2metros\nclf_v2_mlp2l = RandomizedSearchCV(mlp2l, hyperParams, scoring='roc_auc', n_iter=35, cv=2, n_jobs=-1, random_state=0, verbose=2)\nsearchParams = clf_v2_mlp2l.fit(DadosBaseX, DadosBaseY)","6e34a2bf":"# Verifica\u00e7\u00e3o dos melhores par\u00e2metros e seus respectivos scores\nsearchParams.best_params_, searchParams.best_score_","20dd4df1":"%%time\n# Treinamento do segundo classificador usando os hiperpar\u00e2metros ideais\nbestActivation = searchParams.best_params_[\"activation\"]\nbestAlpha = searchParams.best_params_[\"alpha\"]\nbestHLSizes = searchParams.best_params_[\"hidden_layer_sizes\"]\nbestLearningRate = searchParams.best_params_[\"learning_rate\"]\n\nmlp2l = MLPClassifier(early_stopping=True, activation=bestActivation, alpha=bestAlpha, hidden_layer_sizes=bestHLSizes, learning_rate=bestLearningRate)\nmlp2l.fit(DadosBaseX, DadosBaseY)","f3a388dd":"# Biblioteca para desenvolvimento e treinamento de redes neurais\nimport tensorflow as tf\n# Configura\u00e7\u00e3o das seeds para reprodutibilidade\ntf.random.set_seed(42)","e6f1534d":"# Importa\u00e7\u00e3o de funcionalidades do Tensorflow\nfrom tensorflow.keras import Sequential, regularizers\nfrom tensorflow.keras.layers import Dense\nfrom tensorflow.python.framework import ops\nfrom tensorflow.keras.callbacks import EarlyStopping","f3aa9f11":"import random \n\nn_iter=100\n\nneurons=[]\nreg=[]\n\n# Sorteio de valores aleat\u00f3rios para os hiperpar\u00e2metros\nfor i in range(n_iter):\n    h1=random.randrange(25, 100, 1)\n    h2=random.randrange(20, h1, 1)\n    neurons.append((h1, h2))\n    \n    l1=random.choice([0, 1e-15, 1e-10, 1e-5, 1e-3, 1e-2, 1e-1])\n    l2=random.choice([0, 1e-15, 1e-10, 1e-5, 1e-3, 1e-2, 1e-1])\n    reg.append((l1, l2))\n    \n    \n# Cria\u00e7\u00e3o de DataFrame para realizar n_iter combina\u00e7\u00f5es de hiperpar\u00e2metros para fazer a busca aleat\u00f3ria na RandomSearch\nhypParams = {'neurons': neurons, 'reg': reg, 'epochs': n_iter*[None], 'auc': n_iter*[None]}\nhypParams = pd.DataFrame(hypParams)\nhypParams = hypParams[['neurons', 'reg', 'epochs', 'auc']]\n\nhypParams.head() # Exibi\u00e7\u00e3o da tabela de dados","51fb17a7":"# Fun\u00e7\u00e3o para instanciar modelos de redes neurais do Keras prontos para serem treinados\ndef create_model(neurons=(10,10), reg=(.001, .001)):\n    \n    ops.reset_default_graph() # \u00e9 importante resetar os grafos das redes neurais j\u00e1 criadas para n\u00e3o tornam o processo muito lento\n    \n    # Cria\u00e7\u00e3o de modelo\n    model = Sequential()\n    model.add(Dense(neurons[0], input_shape=(DadosBaseX.shape[1],), activation='relu', \n                    kernel_regularizer=regularizers.l1_l2(l1=reg[0], l2=reg[1]), \n                    bias_regularizer=regularizers.l1_l2(l1=reg[0], l2=reg[1])))\n    model.add(Dense(neurons[1], activation='relu', \n                    kernel_regularizer=regularizers.l1_l2(l1=reg[0], l2=reg[1]), \n                    bias_regularizer=regularizers.l1_l2(l1=reg[0], l2=reg[1])))\n    model.add(Dense(1, activation='sigmoid', \n                    kernel_regularizer=regularizers.l1_l2(l1=reg[0], l2=reg[1]), \n                    bias_regularizer=regularizers.l1_l2(l1=reg[0], l2=reg[1])))\n    \n    # Compila\u00e7\u00e3o\n    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=[tf.keras.metrics.AUC()])\n    return model","0fdf6f0d":"# Divis\u00e3o dos dados para treino e para teste\nX_train1, X_test, Y_train1, Y_test = train_test_split(DadosBaseX,DadosBaseY,test_size=0.25,random_state=42)","1c8774b3":"%%time\nfor j in range(n_iter):\n    model = create_model(hypParams.loc[j,'neurons'], hypParams.loc[j,'reg'])\n    \n    es = EarlyStopping(monitor='val_auc', patience=10)\n    \n    history = model.fit(X_train1, Y_train1, \n                        validation_data=(X_test,Y_test), \n                        validation_split=.25,\n                        epochs=50, \n                        batch_size=96, \n                        shuffle=True, \n                        verbose=False,\n                        callbacks=[es]) \n    \n    hypParams.loc[j,'epochs'] = len(history.history['val_auc'])\n    hypParams.loc[j,'auc'] = history.history['val_auc'][-1]\n\n    #Progresso\n    if (j+1)%int(n_iter\/10)==0: print('{:.2f}% concluded.'.format(100*(j+1)\/n_iter))\n    else: pass","f371db39":"# Verifica\u00e7\u00e3o das melhores combina\u00e7\u00f5es de hiperpar\u00e2metros\nhypParams = hypParams.iloc[np.argsort(hypParams.loc[:,'auc']),:]\nhypParams.tail(10)","811ec1fd":"# Melhores valores de combina\u00e7\u00e3o de hiperpar\u00e2metros\nneurons = hypParams.iloc[-1,0]\nreg = hypParams.iloc[-1,1]\nepochs = hypParams.iloc[-1,2]\n\n# Cria\u00e7\u00e3o do modelo\nmlptf = create_model(neurons, reg)\n\n# Treinamento do modelo com os dados de TREINO e os melhores hiperpar\u00e2metros\nmlptf.fit(DadosBaseX, DadosBaseY,\n          validation_split=0,\n          epochs=epochs,\n          batch_size=110,\n          shuffle=True,\n          verbose=False)","4b317232":"# Leitura do arquivo de extens\u00e3o .csv para TESTE\nDadosBaseTeste = pd.read_csv(\"\/kaggle\/input\/sentiment-analysis-pmr3508\/data_test1.csv\")","973f3624":"DadosBaseTeste.head() # Exibi\u00e7\u00e3o da tabela de dados de TESTE","fb4513fd":"print('Tamanho da Base de Dados de TESTE (linhas, colunas):', DadosBaseTeste.shape)","88f37d88":"DadosBaseTeste.info() # Verifica\u00e7\u00e3o de quantas observa\u00e7\u00f5es h\u00e1 por atributo","eea36dd1":"# Verifica\u00e7\u00e3o da exist\u00eancia de observa\u00e7\u00f5es duplicadas\nDadosBaseTeste.loc[DadosBaseTeste.duplicated(subset='review', keep=False)==True].sort_values(by='review').head(14)","6291cbaa":"%%time\n# Remo\u00e7\u00e3o de eventuais duplicatas com dados repetidos\nDadosBaseTeste = DadosBaseTeste.drop_duplicates(subset='review', keep='first')\n\n# Separa\u00e7\u00e3o entre atributo de classifica\u00e7\u00e3o Y e atributos de entrada X\nDadosBaseTesteY = np.array(DadosBaseTeste.loc[:,'positive'].tolist())  # Atributo de interesse\nDadosBaseTesteX = DadosBaseTeste.loc[:,'review'].tolist()              # Atributos para an\u00e1lise\n\n# Aplica\u00e7\u00e3o da fun\u00e7\u00e3o para filtrar (limpar) o texto\nDadosBaseTesteX = [clean(x) for x in DadosBaseTesteX]\n\n# Armazenagem dos textos como vetores de palavras\nDadosBaseTesteX = [x.split() for x in DadosBaseTesteX]\n\n# Aplica\u00e7\u00e3o da fun\u00e7\u00e3o para converter cada resenha em vetores de mesmo tamanho\nDadosBaseTesteX = [emb(x, d2v) for x in DadosBaseTesteX] \nDadosBaseTesteX = np.array(DadosBaseTesteX)","3f516624":"# Compara\u00e7\u00e3o dos modelos treinados, por meio da performance AUC\naucs = []\naucs.append(roc_auc_score(DadosBaseTesteY, mlp1l.predict_proba(DadosBaseTesteX)[:,1]))\naucs.append(roc_auc_score(DadosBaseTesteY, mlp2l.predict_proba(DadosBaseTesteX)[:,1]))\naucs.append(roc_auc_score(DadosBaseTesteY, mlptf.predict(DadosBaseTesteX).squeeze()))\n\nprint('AUC --- SciKit com 1 camada oculta : {:.4f}'.format(aucs[0]))\nprint('AUC --- SciKit com 2 camadas ocultas : {:.4f}'.format(aucs[1]))\nprint('AUC --- TensorFlow\/Keras : {:.4f}'.format(aucs[2]))","651f12db":"# Determina\u00e7\u00e3o do melhor modelo\nmodelosTreinados = [mlp1l,mlp2l,mlptf]\nid_best = np.argmax(aucs)\nmodel_best = modelosTreinados[id_best]","1e08547a":"# Leitura do arquivo de extens\u00e3o .csv para TESTE final de submiss\u00e3o\nDadosBaseSub = pd.read_csv(\"\/kaggle\/input\/sentiment-analysis-pmr3508\/data_test2_X.csv\")","e7c7987b":"DadosBaseSub.head() # Exibi\u00e7\u00e3o da tabela de dados de TESTE final de submiss\u00e3o","832df4b8":"print('Tamanho da Base de Dados de TESTE final de submiss\u00e3o (linhas, colunas):', DadosBaseSub.shape)","59b37052":"DadosBaseSub.info() # Verifica\u00e7\u00e3o de quantas observa\u00e7\u00f5es h\u00e1 por atributo","8e0a6e89":"# Verifica\u00e7\u00e3o da exist\u00eancia de observa\u00e7\u00f5es duplicadas\nDadosBaseSub.loc[DadosBaseSub.duplicated(subset='review', keep=False)==True].sort_values(by='review').head(14)","e0b7eaea":"%%time\n# Remo\u00e7\u00e3o de eventuais duplicatas com dados repetidos\n# DadosBaseSub = DadosBaseSub.drop_duplicates(subset='review', keep='first')\n\n# Separa\u00e7\u00e3o dos atributos de entrada X\nDadosBaseSubX = DadosBaseSub.loc[:,'review'].tolist()              # Atributos para an\u00e1lise\n\n# Aplica\u00e7\u00e3o da fun\u00e7\u00e3o para filtrar (limpar) o texto\nDadosBaseSubX = [clean(x) for x in DadosBaseSubX]\n\n# Armazenagem dos textos como vetores de palavras\nDadosBaseSubX = [x.split() for x in DadosBaseSubX]\n\n# Aplica\u00e7\u00e3o da fun\u00e7\u00e3o para converter cada resenha em vetores de mesmo tamanho\nDadosBaseSubX = [emb(x, d2v) for x in DadosBaseSubX] \nDadosBaseSubX = np.array(DadosBaseSubX)","55c8328f":"# Predi\u00e7\u00e3o do atributo de classifica\u00e7\u00e3o\npredict = []\n# SciKit com 1 camada oculta\nif id_best == 0:\n    predict = model_best.predict_proba(DadosBaseSubX)[:,1]\n# SciKit com 2 camadas ocultas\nelif id_best == 1:\n    predict = model_best.predict_proba(DadosBaseSubX)[:,1]\n# TensorFlow\/Keras\nelif id_best == 2:\n    predict = model_best.predict(DadosBaseSubX).squeeze()","5d9a8403":"# Consolida\u00e7\u00e3o do Array em DataFrame\nsubmission = pd.DataFrame({'positive': predict})\nsubmission.head() # Exibi\u00e7\u00e3o da tabela de predi\u00e7\u00f5es do atributo de classifica\u00e7\u00e3o","81cc997f":"# Exporta\u00e7\u00e3o do DataFrame como arquivo de extens\u00e3o .csv\nsubmission.to_csv(\"submission.csv\", index = True, index_label = 'Id')","64900cd9":"Verifica-se se h\u00e1 dados duplicados.","d8e0c143":"Exibe-se a tabela de dados para familiariza\u00e7\u00e3o com os atributos envolvidos.","6e3cbc99":"**3.2** Duas camadas ocultas","a6d529a0":"Verificam-se os melhores par\u00e2metros.","d3122a8b":"# **PMR3508 - Aprendizado de M\u00e1quina e Reconhecimento de Padr\u00f5es**","21fa9993":"Aplica-se o algoritmo definido como melhor modelo para a predi\u00e7\u00e3o final a ser submetida.","63787451":"Treina-se o classificador do modelo de Rede Neural de uma camada oculta, a partir dos hiperpar\u00e2metros ideais encontrados.","7f2a9f57":"Por fim, a predi\u00e7\u00e3o \u00e9 salva no arquivo de extens\u00e3o .csv.","4a9e8f95":"Em seguida, verifica-se a quantidade de dados por atributo, a fim de constatar se todos os valores possuem igual quantidade.","d431dbc4":"# **6. Submiss\u00e3o:**\n\nOutra base de dados \u00e9 aplicada para a avalia\u00e7\u00e3o do classificador a ser submetida.\n\nLeem-se os dados da base fornecida.","9344826a":"Removeram-se 96 observa\u00e7\u00f5es duplicadas.\n\nSegue-se com a separa\u00e7\u00e3o da base de dados nos textos e em seus respectivos marcadores.","21954fe8":"Utiliza-se um modelo pr\u00e9-treinado de Deep Learning, chamado Doc2Vec, para as transforma\u00e7\u00f5es dos textos em embeddings (vetores).","dfcd1acc":"Importam-se bibliotecas relevantes.","ac1c8b7d":"Constata-se que os textos referentes \u00e0s resenhas n\u00e3o s\u00e3o uma string \"limpa\". Elas podem conter tags como \"< br >\" ou h\u00edfens. Para filtrar os textos, a fim de padronizar o banco de dados, \u00e9 utilizada a fun\u00e7\u00e3o definida por Felipe Polo, a qual utiliza principalmente a biblioteca ftfy para converter \"Unicode ruim para Unicode bom\".","f537923a":"O modelo converte cada uma das resenhas em vetores do mesmo tamanho, facilitando o aprendizado para a predi\u00e7\u00e3o.\n\nCom o objetivo de testar a transforma\u00e7\u00e3o dos textos, utiliza-se a fun\u00e7\u00e3o \"most_similar\" para procurar palavras similares dentro do banco de dados.","d1c51c3c":"Dividem-se os dados.","545e0705":"Tratam-se os dados, removendo dados duplicados, filtrando os textos, armazenando os textos como vetores de palavras e convertendo as resenhas em vetores de mesmo tamanho.","7a28d7ab":"Combinam-se os hiperpar\u00e2metros na RandomSearch.","fd7ac3e5":"Constata-se, portanto, que o DataFrame \u00e9 composto por apenas dois atributos (colunas) e por 24984 resenhas distintas de filmes (linhas). Os atributos s\u00e3o divididos em \"review\", correspondente \u00e0 resenha, e o seu label correspondente variando de 0 e 1, para negativo e positivo, respectivamente. Isto \u00e9, se a avalia\u00e7\u00e3o do filme possui um sentimento positivo, seu label correspondente \u00e9 1. Al\u00e9m disso, observa-se tamb\u00e9m que a base de dados \u00e9 dividida aproximadamente \u00e0 metade, em rela\u00e7\u00e3o aos n\u00fameros de resenhas positivas e negativas.","54e1824d":"Exibe-se a tabela de dados para familiariza\u00e7\u00e3o com os atributos envolvidos.","267553a8":"Como primeiro referencial, a base de dados fornecida tem a seguinte quantidade de dados.","aab7c609":"A propor\u00e7\u00e3o da divis\u00e3o da base de dados, em rela\u00e7\u00e3o aos n\u00fameros de resenhas positivas e negativas, passa a ser a seguinte.","1ce89b50":"Obt\u00eam-se as dez melhores combina\u00e7\u00f5es de hiperpar\u00e2metros.","575c3fc0":"Constata-se que os scores s\u00e3o bastante pr\u00f3ximos, com varia\u00e7\u00f5es do resultado dependendo dos valores selecionados pelo \"RandomSearch\". Por conseguinte, o algoritmo define o melhor modelo em sua predi\u00e7\u00e3o final para a submiss\u00e3o.","83a7500d":"Treina-se o classificador do modelo de Rede Neural de duas camadas ocultas, a partir dos hiperpar\u00e2metros ideais encontrados.","c204ea3e":"Como segundo referencial, a base de dados fornecida passa a ter a seguinte quantidade de dados.","8064b20f":"Exibe-se a tabela de dados para familiariza\u00e7\u00e3o com os atributos envolvidos.","98ba8cdb":"A fun\u00e7\u00e3o de filtragem dos textos foi bem sucedida e sua aplica\u00e7\u00e3o pode ser constatada por meio da remo\u00e7\u00e3o dos par\u00e2metros desnecess\u00e1rios. Como resultado, os dados se encontram padronizados.\n\nEm seguida, os textos s\u00e3o armazenados como vetores de palavras.","c8d1aeb3":"# **2. Tratamento dos Dados:**\n\nVerifica-se se h\u00e1 dados duplicados.","a3b427fa":"Verificam-se os melhores par\u00e2metros.","e44fe637":"* **neurons:** representa\u00e7\u00e3o dos n\u00fameros de neur\u00f4nios de cada camada oculta, respectivamente;\n* **reg:** representa\u00e7\u00e3o dos valores referentes \u00e0s regulariza\u00e7\u00f5es;\n* **epochs:** representa\u00e7\u00e3o do n\u00famero de \u00e9pocas a serem guardadas posteriormente pelo early stopping.\n\nEm seguida, iniciam-se os modelos de Redes Neurais do Keras.","668ac391":"Deste modo, quando se busca a palavra \"award\", constata-se que a fun\u00e7\u00e3o retorna as palavras com valor mais pr\u00f3ximo. Para o caso exemplificado, retornam-se premia\u00e7\u00f5es de cinema e TV, bem como termos que comp\u00f5em premia\u00e7\u00f5es, como \"nomination\" ou \"academy\".\n\nA continua\u00e7\u00e3o, utiliza-se outra fun\u00e7\u00e3o definida por Felipe Polo, na base de treino, para obter representa\u00e7\u00f5es vetoriais.","3b06fec1":"Aplica-se a fun\u00e7\u00e3o na base de dados fornecida.","c75a506a":"Define-se a fun\u00e7\u00e3o de filtragem dos textos.","9019a7b3":"Para precisar a quantidade de dados faltantes por atributo, prossegue-se como a seguir.","f61da39e":"Para que a qualidade da predi\u00e7\u00e3o possa ser mensurada e comparada com os valores reais, deve-se gerar um arquivo de extens\u00e3o .csv que possa ser comparado ao de outros algoritmos. Para tal, cria-se um novo DataFrame a ser povoado com as predi\u00e7\u00f5es obtidas.","cc98de5c":"A classe \"sklearn.neural_network.MLPClassifier\" habilita a implementa\u00e7\u00e3o de um classificador MLP. Como ponto chave, essa classe apresenta um par\u00e2metro chamado \"early stopping\". Esse par\u00e2metro representa uma parada precoce que evita o overfitting. Quando treinando a partir da base de dados por um m\u00e9todo iterativo, como o descida do gradiente, o aprendizado \u00e9 melhorado at\u00e9 certo ponto. Quando passado esse ponto, o ajuste dos par\u00e2metros do modelo aos dados de treinamento vem \u00e0s custas de um aumento no erro de generaliza\u00e7\u00e3o. O par\u00e2metro ent\u00e3o separa 10% da base de treino para testar o modelo a cada 10 itera\u00e7\u00f5es. Se a pontua\u00e7\u00e3o de valida\u00e7\u00e3o n\u00e3o estiver melhorando a cada itera\u00e7\u00e3o, \u00e9 encerrado o treinamento.\n\nPara os c\u00e1lculos dos par\u00e2metros do modelo de MLP, utiliza-se o \"sklearn.model_selection.RandomizedSearchCV\". De modo a evitar o consider\u00e1vel custo computacional do \"GridSearchCV\", o \"RandomizedSearchCV\" utiliza um n\u00famero fixo de configura\u00e7\u00f5es de hiperpar\u00e2metros e \u00e9 amostrado a partir de distribui\u00e7\u00f5es de probabilidade especificadas.\n\n**3.1** Uma camada oculta","4844af35":"Em seguida, verifica-se a quantidade de dados por atributo, a fim de constatar se todos os valores possuem igual quantidade.","28d6c82a":"Treina-se uma Rede Neural com duas camadas ocultas e otimizam-se seus hiperpar\u00e2metros, buscando maximizar a AUC (ROC) durante a valida\u00e7\u00e3o.\n\nPor meio da rotina a seguir, cria-se um DataFrame para realizar combina\u00e7\u00f5es de hiperpar\u00e2metros na RandomSearch.","84b0b1d7":"**Escola Polit\u00e9cnica da Universidade de S\u00e3o Paulo**","9837c02e":"Tratam-se os dados, filtrando os textos, armazenando os textos como vetores de palavras e convertendo as resenhas em vetores de mesmo tamanho.","32958673":"Comparam-se os modelos, a partir da performance AUC.","61583946":"Como terceiro referencial, a base de dados fornecida passa a ter a seguinte quantidade de dados.","9f101b57":"Treina-se o modelo com os dados e com os melhores hiperpar\u00e2metros obtidos.","8ce4425b":"Leem-se os dados da base fornecida.","498a36be":"Verifica-se se h\u00e1 dados duplicados.","aae4a74e":"Como primeiro referencial, a base de dados fornecida tem a seguinte quantidade de dados.","4487726d":"# **5. Compara\u00e7\u00e3o entre Modelos:**\n\nO comparativo entre modelos se d\u00e1 a partir da performance AUC, em um novo conjunto de dados de teste. Para tal, deve-se proceder com o mesmo tratamento de dados desenvolvido anteriormente, removendo dados duplicados, filtrando os textos, armazenando os textos como vetores de palavras e convertendo as resenhas em vetores de mesmo tamanho.\n\nLeem-se os dados da base fornecida.","e9b74fd3":"Exibe-se o mesmo exemplo de observa\u00e7\u00e3o dos atributos, para verificar a exist\u00eancia de caracteres a serem modificados.","634f3a5b":"**Professor:** Fabio Gagliardi Cozman\n\n**Aluno:** Maur\u00edcio Moreira de Avelar Alchorne\n\n**N\u00famero USP:** 9833350","87795bd8":"\u00c9 vantajoso remover os dados duplicados.","aadba672":"Aplica-se a fun\u00e7\u00e3o de obten\u00e7\u00e3o de representa\u00e7\u00f5es vetoriais na base de dados fornecida.","7722a4c8":"Como primeiro referencial, a base de dados fornecida tem a seguinte quantidade de dados.","e5058241":"Em seguida, verifica-se a quantidade de dados por atributo, a fim de constatar se todos os valores possuem igual quantidade.","78fc1f32":"Exibe-se um exemplo de observa\u00e7\u00e3o dos atributos, para verificar a exist\u00eancia de caracteres a serem modificados.","cb618a1c":"# **3. Redes Neurais com Scikit-Learn:**\n\nAs Redes Neurais s\u00e3o elaboradas por meio da biblioteca Scikit-Learn. Das duas propostas, a primeira ter\u00e1 apenas uma camada oculta e a segunda ter\u00e1 duas camadas ocultas.\n\nImportam-se bibliotecas relevantes.","9fd246d2":"# **Objetivo:**\n\nTem-se como objetivos:\n\n* utilizar o modelo pr\u00e9-treinado Doc2Vec para criar embeddings para os textos do conjunto de treino (data_train.csv), obtendo os numpy arrays (X_train, y_train), seguindo as orienta\u00e7\u00f5es do notebook \"analise-de-sentimentos.ipynb\";\n\n* treinar duas redes neurais, utilizando a implementa\u00e7\u00e3o do Scikit-Learn para predi\u00e7\u00e3o da vari\u00e1vel target, sendo que a primeira tem uma camada oculta e a segunda tem duas camadas ocultas (utiliza-se valida\u00e7\u00e3o cruzada -> + grid \/ random search <- para escolher o n\u00famero \u00f3timo de neur\u00f4nios em cada uma das camadas ocultas, al\u00e9m de ajustar o hiperpar\u00e2metro de regulariza\u00e7\u00e3o L2, maximizando AUC (ROC) durante a valida\u00e7\u00e3o e utilizando a op\u00e7\u00e3o \"Early Stopping\");\n\n* treinar uma rede neural com duas camadas ocultas, utilizando Tensorflow e otimizando seus hiperpar\u00e2metros para maximiza\u00e7\u00e3o da AUC (ROC) durante a valida\u00e7\u00e3o (i.e. n\u00famero de neur\u00f4nios e regulariza\u00e7\u00e3o), seguindo orienta\u00e7\u00f5es do notebook \"tensorflow-keras.ipynb\";\n\n* abrir o conjunto de teste 1 (data_test1.csv) e comparar a performance (AUC) de todos os classificadores nesse conjunto;\n\n* abrir o conjunto de teste 2 (data_test2_X.csv), escolher o melhor modelo e submeter as probabilidades preditas para cada linha desse conjunto para avalia\u00e7\u00e3o na Leaderboard.","9dc8be3e":"# **1. Conhecimento dos Dados:**\n\nO processo de an\u00e1lise dos dados a serem trabalhados se inicia com a familiariza\u00e7\u00e3o com os atributos dispon\u00edveis.\n\nImportam-se bibliotecas relevantes para o tratamento dos dados.","a461aae8":"# **4. Redes Neurais com TensorFlow (OP\u00c7\u00c3O B):**\n\nTensorflow \u00e9 uma biblioteca aplicada em t\u00e9cnicas de aprendizado de m\u00e1quina que habilita o desenvolvimento e o treinamento de Redes Neurais. Como anteriormente, continua-se utilizando como refer\u00eancia o notebook desenvolvido por Felipe Polo.\n\nImportam-se bibliotecas relevantes.","83a05e86":"# **Introdu\u00e7\u00e3o:**\n\nO trabalho desenvolvido a seguir procura explorar a utiliza\u00e7\u00e3o de Redes Neurais para a classifica\u00e7\u00e3o de textos, de acordo com o sentimento que eles transmitem (positivo ou negativo).\n\nComo considera\u00e7\u00f5es importantes, os textos utilizados s\u00e3o avalia\u00e7\u00f5es de filmes do iMDb, \u00e9 utilizado um modelo pr\u00e9-treinado de Deep Learning chamado Doc2Vec para a realiza\u00e7\u00e3o das transforma\u00e7\u00f5es dos textos em embeddings (vetores) e, por fim, Redes Neurais MLP s\u00e3o treinadas e usadas para a classifica\u00e7\u00e3o dos textos."}}