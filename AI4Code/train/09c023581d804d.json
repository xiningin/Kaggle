{"cell_type":{"bd62b63f":"code","aa7921b4":"code","fb73c0e0":"code","e36e3982":"code","c438c0b8":"code","735da1c8":"code","249443c3":"code","23772d3a":"code","c85e9784":"code","b59de73a":"code","5accc027":"code","0d6e1c1d":"code","3c9a52ce":"code","9d5f5b3f":"code","cd35c974":"code","a577b063":"code","25d4cf70":"markdown","bdf5f810":"markdown","4d8283d8":"markdown","f5eb5158":"markdown","76e07162":"markdown","3ffc61d1":"markdown"},"source":{"bd62b63f":"import os\nbase_dir = \"..\/input\/dogs-vs-cats\/\"\n\ntrain_link = os.path.join(base_dir, \"train.zip\")\ntest_link = os.path.join(base_dir, \"test1.zip\")\n\n# ..\/input\/dogs-vs-cats-redux-kernels-edition\/test.zip\nimport zipfile\nwith zipfile.ZipFile(train_link,\"r\") as z:\n z.extractall()\nwith zipfile.ZipFile(test_link,\"r\") as z:\n z.extractall()\n","aa7921b4":"import numpy as np\nimport tensorflow as tf\nimport pandas as pd\nimport os\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow.keras\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator,load_img\nfrom tensorflow.keras.preprocessing import image\nfrom tensorflow.keras.utils import to_categorical\nfrom tensorflow.keras.layers import Dense, Activation, Dropout, Flatten, Conv2D, MaxPooling2D\nfrom keras.models import load_model\nfrom keras.models import Sequential\nfrom keras.layers import Conv2D,MaxPooling2D, Dropout,Flatten,Dense,Activation, BatchNormalization\nfrom sklearn.model_selection import train_test_split","fb73c0e0":"#B\u01b0\u1edbc 2: X\u00e1c \u0111\u1ecbnh c\u00e1c thu\u1ed9c t\u00ednh h\u00ecnh \u1ea3nh - K\u00edch th\u01b0\u1edbc, chi\u1ec1u\nImage_Channels=3\nImage_Width=224\nImage_Height=224\nImage_Size=(Image_Width,Image_Height)\n\ntrain_link  = \"..\/working\/train\"\ntest_link  = \"..\/working\/test1\"","e36e3982":"# B\u01b0\u1edbc 3: Chu\u1ea9n b\u1ecb b\u1ed9 d\u1eef li\u1ec7u\nfilenames=os.listdir(train_link)\n\ncategories=[]\nfor f_name in filenames:\n    category=f_name.split('.')[0]\n    if category=='dog':\n        categories.append(1)\n    else:\n        categories.append(0)\n\ndf=pd.DataFrame({\n    'filename':filenames,\n    'category':categories\n})\n","c438c0b8":"#B\u01b0\u1edbc 4: \u0110\u1ecbnh ngh\u0129a callbacks v\u00e0 learning rate\nearly_stopping = tf.keras.callbacks.EarlyStopping(\n    monitor = 'val_accuracy', \n    mode = 'auto',\n    verbose = 1, \n    patience = 4\n    )\nmodel_checkpoint = tf.keras.callbacks.ModelCheckpoint(\n    filepath = \"checkpoint.h5\",\n    monitor = 'val_accuracy', \n    save_best_only = True, \n    mode = 'auto'\n    )\n\ncallbacks = [early_stopping, model_checkpoint]","735da1c8":"# B\u01b0\u1edbc 5: Qu\u1ea3n l\u00fd d\u1eef li\u1ec7u - chia t\u1eadp vali v\u00e0 train\ndf[\"category\"] = df[\"category\"].replace({0:'cat',1:'dog'})\ntrain_df,validate_df = train_test_split(df,test_size=0.25,\n  random_state=42)\n\ntrain_df = train_df.reset_index(drop=True)\nvalidate_df = validate_df.reset_index(drop=True)\n\nbatch_size=32 \n","249443c3":"#B\u01b0\u1edbc 6: Generate t\u1eadp d\u1eef li\u1ec7u v\u00e0 \u0111i\u1ec1u ch\u1ec9nh\ntrain_datagen = ImageDataGenerator(rescale=1.0\/255.0, width_shift_range=0.1, height_shift_range=0.1, horizontal_flip=True)\nval_datagen = ImageDataGenerator(rescale=1.0\/255.0)\n\ntrain_generator = train_datagen.flow_from_dataframe(train_df,train_link,x_col='filename',y_col='category',class_mode='binary', batch_size=batch_size, target_size=Image_Size)\nvalidation_generator = val_datagen.flow_from_dataframe(validate_df,train_link,x_col='filename',y_col='category',class_mode='binary', batch_size=batch_size, target_size=Image_Size)\n","23772d3a":"#B\u01b0\u1edbc 7: Build model khi CH\u01afA C\u00d3 MODEL (kh\u00f4ng load model)\n\n\nmodel = Sequential()\n\nmodel.add(Conv2D(64, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block1_conv1', input_shape=(224, 224, 3)))\nmodel.add(Conv2D(64, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block1_conv2'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block1_maxpool'))\n\nmodel.add(Conv2D(128, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block2_conv1'))\nmodel.add(Conv2D(128, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block2_conv2'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block2_maxpool'))\n\nmodel.add(Conv2D(256, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block3_conv1'))\nmodel.add(Conv2D(256, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block3_conv2'))\nmodel.add(Conv2D(256, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block3_conv3'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block3_maxpool'))\n\nmodel.add(Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block4_conv1'))\nmodel.add(Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block4_conv2'))\nmodel.add(Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block4_conv3'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block4_maxpool'))\n\nmodel.add(Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block5_conv1'))\nmodel.add(Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block5_conv2'))\nmodel.add(Conv2D(512, (3,3), activation=\"relu\", padding=\"same\", kernel_initializer='he_uniform', name='block5_conv3'))\nmodel.add(MaxPooling2D(pool_size=(2,2), strides=(2,2), name='block5_maxpool'))\n\nmodel.add(Flatten())\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dense(4096, activation='relu'))\nmodel.add(Dense(1, activation='sigmoid'))\n","c85e9784":"#B\u01b0\u1edbc 8: compile v\u00e0 \u0111\u00e1nh gi\u00e1 - KH\u00d4NG CH\u1ea0Y KHI D\u00d9NG MODEL LOAD L\u1ea0I\nopt=tf.keras.optimizers.SGD(learning_rate=0.001,momentum=0.9) \n\nmodel.compile(optimizer=opt,\n              loss='binary_crossentropy',\n              metrics=['accuracy'])\n\nmodel.summary()","b59de73a":"#B\u01b0\u1edbc 9: Fit model (training) - CH\u1ea0Y KHI LOAD MODEL \u0111\u1ec3 ki\u1ec3m tra accuracy hi\u1ec7n t\u1ea1i r\u1ed3i t\u1eaft \u0111i\nhistory = model.fit_generator(generator=train_generator, \n                              steps_per_epoch=len(train_generator), \n                              validation_data=validation_generator, \n                              validation_steps=len(validation_generator), \n                              epochs=2, \n                              verbose=1,\n                              callbacks=callbacks)","5accc027":"#B\u01b0\u1edbc 10.5: Load l\u1ea1i model:\nmodel = load_model(\"..\/input\/latest-model\/latest_model.h5\")","0d6e1c1d":"#B\u01b0\u1edbc 10: L\u01b0u m\u00f4 h\u00ecnh -->.weight\nmodel.save(\"latest_model1.h5\")","3c9a52ce":"#B\u01b0\u1edbc 11: Chu\u1ea9n b\u1ecb d\u1eef li\u1ec7u th\u1eed nghi\u1ec7m\ntest_link=\".\/test1\"\ntest_filenames = os.listdir(test_link)","9d5f5b3f":"#B\u01b0\u1edbc 12: D\u1ef1 \u0111o\u00e1n k\u1ebft qu\u1ea3 tr\u00ean 1 s\u1ed1 \u1ea3nh\n\ndog_counter = 0 \ncat_counter  = 0\n\nfor file in test_filenames:\n    img = image.load_img(test_link + \"\/\" + file, target_size=(224,224))\n    x = cv2.imread(test_link + \"\/\" + file)\n    x = cv2.resize(x, Image_Size)\n   \n    classes = model.predict(np.expand_dims(x, axis=0))[0]\n        \n    if classes == 0:\n      plt.xlabel(\"cat\")\n      plt.imshow(img)\n      plt.show()\n      cat_counter += 1\n    else:\n      plt.xlabel(\"dog\")\n      plt.imshow(img)\n      plt.show()\n      dog_counter += 1\n        \n    if(cat_counter==10): break\n\n      \nprint(\"Total Dogs :\",dog_counter)\nprint(\"Total Cats :\",cat_counter)","cd35c974":"#B\u01b0\u1edbc 13: Test 1 \u1ea3nh truy\u1ec1n v\u00e0o - CH\u1ea0Y N\u1ebeU MU\u1ed0N TEST 1 \u1ea2NH = TAY\ndef predict_(link):\n    image = cv2.imread(link)\n    image = cv2.resize(image, (224,224))\n    preds = model.predict(np.expand_dims(image, axis=0))[0]\n    plt.imshow(image)\n    plt.show()\n    if preds==0:\n            print(\"Predicted Label:Cat\")\n    else:\n            print(\"Predicted Label: Dog\")\n        \n        \npredict_(\"..\/input\/testcase\/dog.5732.jpg\")","a577b063":"#B\u01b0\u1edbc 14: \u0110\u00e1nh gi\u00e1 t\u1ec9 l\u1ec7 ch\u00ednh x\u00e1c - SAU KHI TRAIN N EPOCHS (KH\u00d4NG D\u00d9NG N\u1ebeU LOAD MODEL)\nimport sys\n\n# Plot diagnostic learning curves\ndef summarize_diagnostics(history):\n\n    plt.plot(history.history['accuracy'])\n    plt.plot(history.history['val_accuracy'])\n    plt.title('model accuracy')\n    plt.ylabel('accuracy')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\n\n    plt.plot(history.history['loss'])\n    plt.plot(history.history['val_loss'])\n    plt.title('model loss')\n    plt.ylabel('loss')\n    plt.xlabel('epoch')\n    plt.legend(['train', 'val'], loc='upper left')\n    plt.show()\n\n# Learning curves\nsummarize_diagnostics(history)","25d4cf70":"Callbacks d\u1eebng l\u1ea1i sau 4 v\u00f2ng v\u1edbi val_accuracy t\u0103ng qu\u00e1 \u00edt v\u00e0 l\u01b0u l\u1ea1i model t\u1ed1t nh\u1ea5t","bdf5f810":"Unzip file d\u1eef li\u1ec7u t\u1eeb kaggle g\u1ed3m 25000 \u1ea3nh ch\u00f3 m\u00e8o","4d8283d8":"H\u00e0m t\u00e1ch d\u1ef1 li\u1ec7u ra th\u00e0nh validation set v\u00e0 train set, t\u1ec9 l\u1ec7 1:4","f5eb5158":"B\u1eaeT \u0110\u1ea6U CH\u1ea0Y T\u1eea \u0110\u00c2Y: Import c\u00e1c th\u01b0 vi\u1ec7n","76e07162":"\u0110\u00e1nh label cho d\u1eef li\u1ec7u, 0 l\u00e0 m\u00e8o; 1 l\u00e0 ch\u00f3\n","3ffc61d1":"\u0110i\u1ec1u ch\u1ec9nh \u0111\u1ed9 ch\u00ednh x\u00e1c, cho ph\u00e9p xoay \u1ea3nh, rescale, zoom, etc; resize \u1ea3nh v\u1ec1 ImageSize"}}