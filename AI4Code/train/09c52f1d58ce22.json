{"cell_type":{"dcc37d27":"code","34fc669e":"code","a5158342":"code","aa37882e":"code","94222f6a":"code","ae61fdb8":"code","d1f54269":"code","14428fe0":"code","b517ba0e":"code","0880ed4d":"code","10de2c23":"code","2da7784a":"code","3d7a17c8":"code","5a8e3812":"code","fa786c41":"code","db8266e6":"code","546c72fb":"code","a5aeb14b":"code","e63c1c83":"code","f3f0c544":"code","340d627e":"code","fef6ee74":"code","e48305ba":"code","df954b9e":"code","a8625f90":"code","cb9f501c":"code","a2d552c7":"code","89fc840b":"code","92649b63":"code","15aa4563":"code","bf05ec2f":"markdown","63323361":"markdown","3a407ce6":"markdown","83978df7":"markdown","69dfd038":"markdown","feeef931":"markdown","25a481b3":"markdown","1a3e26be":"markdown","8ef87c9d":"markdown","b9f2b38e":"markdown","04a54dec":"markdown","9b8b4c7a":"markdown","96c3c821":"markdown","11dd71cd":"markdown","b976f9ba":"markdown"},"source":{"dcc37d27":"import os\nimport numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom sklearn.decomposition import PCA\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.cluster import KMeans\nfrom keras.utils import Sequence\nfrom keras import Model\nfrom keras.optimizers import Adam\nfrom keras.losses import mean_absolute_error, mean_squared_error","34fc669e":"paths = []\nfor root, subdirs, files in os.walk('..\/input\/osic-random-slices-from-lung-regions\/image_slice'):\n    for file in files:\n        if os.path.splitext(file)[1].lower() in ('.npz'):\n             paths.append(os.path.join(root, file))","a5158342":"class ImageGenerator(Sequence):\n    def __init__(self, paths, batch_size=64, random_state=None):\n        self._paths = paths\n        self._batch_size = batch_size\n        self._random = np.random.RandomState(random_state)\n        \n    def __len__(self):\n        return len(self._paths) \/\/ self._batch_size\n    \n    def __getitem__(self, idx):\n        paths = self._random.choice(self._paths, size=self._batch_size)\n        imgs = np.expand_dims([np.load(p, allow_pickle=True)['arr_0'].tolist()['slice'] for p in paths], axis=-1) \/ 1_000\n        return imgs, imgs","aa37882e":"data_gen = ImageGenerator(paths, random_state=43)","94222f6a":"batch = data_gen[0]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[0][8*i + j, ..., 0])\nplt.show();","ae61fdb8":"from tensorflow.keras.layers import (\n    Dense, Dropout, Activation, Flatten, Input, BatchNormalization, UpSampling2D, Add, Conv2D, AveragePooling2D, LeakyReLU\n)\n\nfrom tensorflow.keras import Model\nfrom tensorflow.keras.optimizers import Nadam\n\ndef get_encoder(shape=(512, 512, 1)):\n    def res_block(x, n_features):\n        _x = x\n        x = BatchNormalization()(x)\n        x = LeakyReLU()(x)\n    \n        x = Conv2D(n_features, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n        x = Add()([_x, x])\n        return x\n    \n    inp = Input(shape=shape)\n    \n    # 64\n    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(inp)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    x = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    \n    # 32\n    x = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(3):\n        x = res_block(x, 128)\n    x = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    \n    # 16\n    x = Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(3):\n        x = res_block(x, 256)\n    x = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    \n    # 64\n    x = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(3):\n        x = res_block(x, 128)\n    x = AveragePooling2D(pool_size=(2, 2), strides=(2, 2))(x)\n    \n    # 8\n    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    for _ in range(2):\n        x = res_block(x, 32)    \n    \n    # 8\n    x = Conv2D(1, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n    return Model(inp, x)\n\n\n\ndef get_decoder(shape=(8, 8, 1)):\n    inp = Input(shape=shape)\n\n    # 8\n    x = UpSampling2D((2, 2))(inp)\n    x = Conv2D(256, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    # 16\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(128, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    # 32\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(64, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n\n    x = UpSampling2D((2, 2))(x)\n    x = Conv2D(32, kernel_size=(3, 3), strides=(1, 1), padding='same')(x)\n    x = BatchNormalization()(x)\n    x = LeakyReLU()(x)\n    \n    x = Conv2D(1, kernel_size=(1, 1), strides=(1, 1), padding='same')(x)\n    return Model(inp, x)","d1f54269":"encoder = get_encoder((64, 64, 1))\ndecoder = get_decoder((4, 4, 1))\n\ninp = Input((64, 64, 1))\ne = encoder(inp)\nd = decoder(e)\nmodel = Model(inp, d)","14428fe0":"encoder.summary()","b517ba0e":"decoder.summary()","0880ed4d":"model.compile(optimizer=Adam(lr=3*1e-3), loss='mae')\nmodel.summary()","10de2c23":"data_gen = ImageGenerator(paths, random_state=43, batch_size=512)\nmodel.fit_generator(data_gen, steps_per_epoch=len(data_gen), epochs=5)","2da7784a":"x_encode = encoder.predict_generator(data_gen, verbose=1)","3d7a17c8":"e_samples, x_samples = [], []\nfor i in range(25):\n    x, _ = data_gen[i]\n    _x = encoder.predict(x)\n    e_samples.extend(_x.tolist())\n    x_samples.extend(x.tolist())","5a8e3812":"e_stack, x_stack = np.array(e_samples), np.array(x_samples)","fa786c41":"x_encode = x_encode.reshape((-1, 16))","db8266e6":"scaler = StandardScaler()\nx_scale = scaler.fit_transform(x_encode)\n\npca = PCA()\nx_pca = pca.fit_transform(x_scale)\nsample_pca = pca.transform(scaler.transform(e_stack.reshape((-1, 16))))","546c72fb":"kmeans = KMeans(n_clusters=10)\nx_c = kmeans.fit_predict(x_pca)\nsample_c = kmeans.predict(sample_pca.astype(x_pca.dtype))","a5aeb14b":"plt.figure(figsize=(10,8))\nplt.plot(1 - pca.explained_variance_ratio_);","e63c1c83":"plt.figure(figsize=(10,8))\nplt.plot(x_pca[:, 0], x_pca[:, 1], '.', alpha=0.1);\nplt.plot(sample_pca[:, 0], sample_pca[:, 1], '.', alpha=0.1);","f3f0c544":"import random\ncolor = [\"#\"+''.join([random.choice('0123456789ABCDEF') for j in range(6)]) for i in range(10)]\n\nplt.figure(figsize=(10,8))\n\nfor c in range(10):\n    subset = x_pca[x_c==c]\n    plt.plot(subset[:, 0], subset[:, 1], '.', alpha=0.1, color=color[c]);","340d627e":"x = x_stack[sample_c == 0]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","fef6ee74":"x = x_stack[sample_c == 1]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","e48305ba":"x = x_stack[sample_c == 2]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","df954b9e":"x = x_stack[sample_c == 3]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","a8625f90":"x = x_stack[sample_c == 4]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","cb9f501c":"x = x_stack[sample_c == 5]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","a2d552c7":"x = x_stack[sample_c == 6]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","89fc840b":"x = x_stack[sample_c == 7]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","92649b63":"x = x_stack[sample_c == 8]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","15aa4563":"x = x_stack[sample_c == 9]\n\nidx = np.random.randint(0, len(x), size=64)\nbatch = x[idx]\n\nfig, ax = plt.subplots(8, 8, figsize=(16, 16))\n\nfor i, _ax in enumerate(ax):\n    for j, __ax in enumerate(_ax):\n        __ax.imshow(batch[8*i + j, ..., 0])\nplt.show();","bf05ec2f":"## Cluster 9","63323361":"## Cluster 6","3a407ce6":"## Dataset\n\nI use my [dataset of random lung 64x64 slices](https:\/\/www.kaggle.com\/miklgr500\/osic-random-slices-from-lung-regions), lung slice help autoencoder detect lung features and realise attention idea for autoencoder. ","83978df7":"## Cluster 3","69dfd038":"## Cluster 5","feeef931":"## Reference:\n* [Image2Vec: AutoEncoder](https:\/\/www.kaggle.com\/miklgr500\/image2vec-autoencoder)\n* [[OSIC] Random slices from lung regions](https:\/\/www.kaggle.com\/miklgr500\/osic-random-slices-from-lung-regions)","25a481b3":"## Cluster 0","1a3e26be":"## Cluster 1","8ef87c9d":"## PCA decomposition","b9f2b38e":"## AutoEncoder\n![](https:\/\/upload.wikimedia.org\/wikipedia\/commons\/2\/28\/Autoencoder_structure.png)\nPipeline released in this kernel is very simple:\n\n* train encoder and used one for translate image in vector\n* visulize results vectors used PCA decomposition algorithm","04a54dec":"## Conclusion \nOn this notebook shows that using using lung slice attempt neural networks extracting features with lung property. ","9b8b4c7a":"## Cluster 8","96c3c821":"## Cluster 2","11dd71cd":"## Cluster 4","b976f9ba":"## Cluster 7"}}