{"cell_type":{"a39bc48e":"code","643d6518":"code","566492e1":"code","285d581e":"code","cc7c18bf":"code","9cbe8584":"code","7facf0c8":"code","096a2f70":"code","eec42885":"code","b84c65d9":"code","58e74b98":"code","1d5c05ae":"code","7a7441e9":"code","ce884911":"code","95a6d11c":"markdown","a1ea1012":"markdown","49294ab8":"markdown","3697cd3b":"markdown","06eeeb10":"markdown","e848af02":"markdown"},"source":{"a39bc48e":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\nimport os\n\n\nfrom sklearn.model_selection import StratifiedShuffleSplit, train_test_split\nfrom sklearn.impute import  SimpleImputer, MissingIndicator\nfrom sklearn.pipeline import make_pipeline, Pipeline, FeatureUnion\nfrom sklearn.preprocessing import RobustScaler, QuantileTransformer, KBinsDiscretizer, StandardScaler\n\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nfrom sklearn.metrics import roc_auc_score\n\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nfrom tensorflow.keras import regularizers\n\nimport datatable as dt\n\n","643d6518":"if 'KAGGLE_CONTAINER_NAME' in os.environ:\n    train = dt.fread('..\/input\/tabular-playground-series-sep-2021\/train.csv').to_pandas()\n    test = dt.fread('..\/input\/tabular-playground-series-sep-2021\/test.csv').to_pandas().set_index('id')\nelse:\n    train = dt.fread('.\/train.csv').to_pandas()\n    test = dt.fread('.\/test.csv').to_pandas().set_index('id')\ny = train['claim']\ntrain.drop(columns=['claim', 'id'], inplace=True)\n","566492e1":"def reduce_memory_usage(df, verbose=True):\n    numerics = [\"int8\", \"int16\", \"int32\", \"int64\", \"float16\", \"float32\", \"float64\"]\n    if isinstance(df, pd.Series):\n        start_mem = df.memory_usage() \/ 1024 ** 2\n    else:\n        start_mem = df.memory_usage().sum() \/ 1024 ** 2\n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == \"int\":\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)\n            else:\n                if (\n                    c_min > np.finfo(np.float16).min\n                    and c_max < np.finfo(np.float16).max\n                ):\n                    df[col] = df[col].astype(np.float16)\n                elif (\n                    c_min > np.finfo(np.float32).min\n                    and c_max < np.finfo(np.float32).max\n                ):\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)\n    if isinstance(df, pd.Series):\n        end_mem = df.memory_usage() \/ 1024 ** 2\n    else:\n        end_mem = df.memory_usage().sum() \/ 1024 ** 2\n\n    if verbose:\n        print(\n            \"Mem. usage decreased to {:.2f} Mb ({:.1f}% reduction)\".format(\n                end_mem, 100 * (start_mem - end_mem) \/ start_mem\n            )\n        )\n    return df","285d581e":"train['missing'] = train.isnull().sum(axis=1)\ntest['missing'] = test.isnull().sum(axis=1)\n\n\nX_train, Y_train = reduce_memory_usage(train), reduce_memory_usage(y.to_frame())\nX_train = X_train.copy()  # reduce fragmentation\n","cc7c18bf":"\nnumeric_column_transform = make_pipeline(\n    SimpleImputer(missing_values=np.nan, strategy='median'),\n    QuantileTransformer(n_quantiles=1000, output_distribution='uniform'),\n    KBinsDiscretizer(n_bins=128, encode='ordinal',strategy='uniform')\n)\n\ninput_pipeline = FeatureUnion([\n    ('features', numeric_column_transform),\n    #('missing', MissingIndicator()),\n]\n)\n\n","9cbe8584":"X_train = input_pipeline.fit_transform(X_train)\nx_train, x_test, y_train, y_test = train_test_split(X_train, Y_train.values, shuffle=True, stratify=Y_train.values, test_size=0.1)","7facf0c8":"stacked_model = keras.models.load_model('..\/input\/tpspretrained\/stacked_model.h5')","096a2f70":"# make a prediction with a stacked model\ndef predict_stacked_model(model, inputX):\n    # prepare input data\n    X = [inputX for _ in range(len(model.input))]\n    # make prediction\n    return model.predict(X, verbose=0)","eec42885":"from sklearn.calibration import calibration_curve\nfrom sklearn.isotonic import IsotonicRegression as IR\n\n\np_train = predict_stacked_model(stacked_model, X_train)\nir = IR(out_of_bounds = 'clip')\nir.fit(p_train.flatten(), Y_train.values.flatten())\np_calibrated = ir.transform(p_train.flatten())","b84c65d9":"fraction_of_positives, mean_predicted_value = calibration_curve(Y_train.values, p_train, n_bins=20)\nplt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Not calibrated\")\nfraction_of_positives, mean_predicted_value = calibration_curve(Y_train.values, p_calibrated, n_bins=20)\nplt.plot(mean_predicted_value, fraction_of_positives, \"s-\", label=\"Calibrated\")\nplt.plot()","58e74b98":"test_preds = predict_stacked_model(stacked_model, x_test)\ncalibrated_test_preds = ir.transform(test_preds.flatten())\nprint(f'ROC AUC: {roc_auc_score(y_test, test_preds)}')\nprint(f'ROC AUC calibrated: {roc_auc_score(y_test, calibrated_test_preds)}')","1d5c05ae":"transformed_x = input_pipeline.transform(test)\npreds= predict_stacked_model(stacked_model, transformed_x)\n","7a7441e9":"preds = ir.transform(preds.flatten())","ce884911":"pd.DataFrame({'id': test.index, 'claim': preds.flatten()}).to_csv('nn_residual_ensemble_calibrated.csv', index=False)","95a6d11c":"## Let's check how ROC changed","a1ea1012":"## Import IsotonicRegression, train on train set predictions vs train target","49294ab8":"## Let's plot charts","3697cd3b":"## Make predictions on test set and transform before submitting","06eeeb10":"## Load pretrained model","e848af02":"## Missing values: Normalize for NN, missing values indicator as features"}}