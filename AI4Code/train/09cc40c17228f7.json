{"cell_type":{"6b8b345f":"code","58c0011f":"code","a4f83a95":"code","b7ad850b":"code","59f69f66":"code","b060db48":"code","17f0e660":"markdown","049f31ea":"markdown","d9977c41":"markdown","8f305ed0":"markdown","5380ea2d":"markdown","c56ceb15":"markdown","19461901":"markdown"},"source":{"6b8b345f":"import random\n\nhistory_v1 = []\nhistory_v2 = []\nhistory_v3 = []\n\n# define an objective function\n# normally, you would put something like a machine learning algorithm here\n# and the parameters would be its hyperparameters\n# returned value would be the loss or whatever you are trying to optimize\ndef objective(args):\n    v1 = args['v1']\n    v2 = args['v2']\n    v3 = args['v3']\n    history_v1.append(v1)\n    history_v2.append(v2)\n    history_v3.append(v3)\n    result = random.uniform(v2,v3)\/v1\n    return result\n\n# define a search space\nfrom hyperopt import hp\n\nspace = {\n    'v1': hp.uniform('v1', 0.5,1.5),\n    'v2': hp.uniform('v2', 0.5,1.5),\n    'v3': hp.uniform('v3', 0.5,1.5),\n}\n\n# minimize the objective over the space\nfrom hyperopt import fmin, tpe, space_eval\nbest = fmin(objective, space, algo=tpe.suggest, max_evals=1000)\n\nprint(best)","58c0011f":"import pandas as pd\n\ndf_histories = pd.DataFrame()\ndf_histories[\"v1\"] = history_v1\ndf_histories[\"v2\"] = history_v2\ndf_histories[\"v3\"] = history_v3\ndf_histories.head()\n","a4f83a95":"df_histories.plot()","b7ad850b":"df_histories[\"v1\"].plot()","59f69f66":"df_histories[\"v2\"].plot()","b060db48":"df_histories[\"v3\"].plot()","17f0e660":"All together it looks like a mess:","049f31ea":"There was a question on [StackOverflow](https:\/\/stackoverflow.com\/questions\/63252552\/hyperopt-list-of-values-per-hyperparameter\/63427170) about using HyperOpt to optimize multiple variables. I posted a short answer and made this kernel to see myself for more details.\n\nA small made up function with 3 variables to optimize:\n\n- v1: this should minimize for optimal value\n- v2: this should minimize for optimal value\n- v3: this should maximize for optimal value\n\nThey all have the same value space to explore: uniform floats from 0.5 to 1.5. So all values between 0.5 to 1.5.\n","d9977c41":"V2: should be minimized","8f305ed0":"The above shows the optimizer finishing with the v1 near the maximum, and v2 and v3 near the minimum, as expected.\n\nBut what does it look like over the iterations, how does Hyperopt vary the parameters?","5380ea2d":"V1 alone, the one that should be maximized:","c56ceb15":"What can I say? It seems to be focusing on the optimal area for each variable but in sort of phases, where it spikes outside the optimal area. \n\nI would have expected more focus on the \"optimal\" area over time but seems not so much. I suppose it is good in a sense, to explore the value space more thoroughly over time. There might also be some relation between the different values as well.\n\nAnd what is the \"Bayesian\" part of it? If you have any idea how it fits into these \"pictures\", very happy to hear :)","19461901":"V3: should also be minimized"}}