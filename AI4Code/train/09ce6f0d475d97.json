{"cell_type":{"7725d3f8":"code","52788c98":"code","ee6df792":"code","14efd722":"code","8c95975e":"code","2e121e6a":"code","8da77a4b":"code","ba87f1c4":"code","3333f269":"code","d844684a":"code","1e180e30":"code","af4f4483":"code","ca3453ee":"code","1aa1e11c":"code","b57598e4":"code","7909447e":"code","6e88511e":"code","eea46943":"code","eb32f4c2":"code","7c89129d":"code","a3dedc7b":"code","625204e3":"code","b2e6cd4a":"code","2c8929bc":"markdown","89d79082":"markdown","22dd6997":"markdown","93af95fb":"markdown","14f08d5b":"markdown","670aceaa":"markdown","52075fce":"markdown","4adbb856":"markdown","75c5374f":"markdown","cacd1155":"markdown","e32531e7":"markdown","5cb56d65":"markdown"},"source":{"7725d3f8":"import os\nimport json\nfrom pprint import pprint\nfrom copy import deepcopy\n\nimport numpy as np\nimport pandas as pd\nfrom tqdm.notebook import tqdm\nimport re","52788c98":"#Helper Functions by https:\/\/www.kaggle.com\/xhlulu\/cord-19-eda-parse-json-and-generate-clean-csv\n\ndef format_name(author):\n    middle_name = \" \".join(author['middle'])\n    \n    if author['middle']:\n        return \" \".join([author['first'], middle_name, author['last']])\n    else:\n        return \" \".join([author['first'], author['last']])\n\n\ndef format_affiliation(affiliation):\n    text = []\n    location = affiliation.get('location')\n    if location:\n        text.extend(list(affiliation['location'].values()))\n    \n    institution = affiliation.get('institution')\n    if institution:\n        text = [institution] + text\n    return \", \".join(text)\n\ndef format_authors(authors, with_affiliation=False):\n    name_ls = []\n    \n    for author in authors:\n        name = format_name(author)\n        if with_affiliation:\n            affiliation = format_affiliation(author['affiliation'])\n            if affiliation:\n                name_ls.append(f\"{name} ({affiliation})\")\n            else:\n                name_ls.append(name)\n        else:\n            name_ls.append(name)\n    \n    return \", \".join(name_ls)\n\ndef format_body(body_text):\n    texts = [(di['section'], di['text']) for di in body_text]\n    texts_di = {di['section']: \"\" for di in body_text}\n    \n    for section, text in texts:\n        texts_di[section] += text\n\n    body = \"\"\n\n    for section, text in texts_di.items():\n        body += section\n        body += \"\\n\\n\"\n        body += text\n        body += \"\\n\\n\"\n    \n    return body\n\ndef format_bib(bibs):\n    if type(bibs) == dict:\n        bibs = list(bibs.values())\n    bibs = deepcopy(bibs)\n    formatted = []\n    \n    for bib in bibs:\n        bib['authors'] = format_authors(\n            bib['authors'], \n            with_affiliation=False\n        )\n        formatted_ls = [str(bib[k]) for k in ['title', 'authors', 'venue', 'year']]\n        formatted.append(\", \".join(formatted_ls))\n\n        \n    return \"; \".join(formatted)\n\n\ndef load_files(dirname):\n    filenames = os.listdir(dirname)\n    raw_files = []\n\n    for filename in tqdm(filenames):\n        filename = dirname + filename\n        file = json.load(open(filename, 'rb'))\n        raw_files.append(file)\n    \n    return raw_files\n\ndef generate_clean_df(all_files):\n    cleaned_files = []\n    \n    for file in tqdm(all_files):\n        features = [\n            file['paper_id'],\n            file['metadata']['title'],\n            format_authors(file['metadata']['authors']),\n            format_authors(file['metadata']['authors'], \n                           with_affiliation=True),\n            format_body(file['abstract']),\n            format_body(file['body_text']),\n            format_bib(file['bib_entries']),\n            file['metadata']['authors'],\n            file['bib_entries']\n        ]\n\n        cleaned_files.append(features)\n\n    col_names = ['paper_id', 'title', 'authors',\n                 'affiliations', 'abstract', 'text', \n                 'bibliography','raw_authors','raw_bibliography']\n\n    clean_df = pd.DataFrame(cleaned_files, columns=col_names)\n    clean_df = clean_df.drop(['raw_authors', 'raw_bibliography'], axis=1)\n    clean_df.head()\n    \n    return clean_df","ee6df792":"pmc_dir = '\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/pmc_custom_license\/pmc_custom_license\/'\npmc_files = load_files(pmc_dir)\npmc_df = generate_clean_df(pmc_files)\nprint(pmc_df.shape)\npmc_df.head()","14efd722":"biorxiv_dir = '\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/biorxiv_medrxiv\/biorxiv_medrxiv\/'\nbiorxiv_files = load_files(biorxiv_dir)\nbiorxiv_df = generate_clean_df(biorxiv_files)\nprint(biorxiv_df.shape)\nbiorxiv_df.head()","8c95975e":"noncomm_dir=\"\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/noncomm_use_subset\/noncomm_use_subset\/\"\nnoncomm_files = load_files(noncomm_dir)\nnoncomm_df = generate_clean_df(noncomm_files)\nprint(noncomm_df.shape)\nnoncomm_df.head()","2e121e6a":"comm_dir=\"\/kaggle\/input\/CORD-19-research-challenge\/2020-03-13\/comm_use_subset\/comm_use_subset\/\"\ncomm_files = load_files(comm_dir)\ncomm_df = generate_clean_df(comm_files)\nprint(comm_df.shape)\ncomm_df.head()","8da77a4b":"#Function to find list of all titles with the occurence of provided word in the text\ndef wordcount(df,word):\n    word_dict={}\n    for i in range(len(df[\"text\"])):\n        if word in df[\"text\"][i].lower():\n            if df[\"title\"][i]==\"\":\n                word_dict[df[\"paper_id\"][i]]=sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), df[\"text\"][i],re.IGNORECASE))\n            else:\n                word_dict[df[\"title\"][i]]=sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), df[\"text\"][i],re.IGNORECASE))\n            \n    return {k: v for k, v in sorted(word_dict.items(), key=lambda item: item[1],reverse = True)}","ba87f1c4":"biorxiv_dict=wordcount(biorxiv_df,\"transmission\")\nprint(\"Occurence of word 'transmission' in papers of biorxiv_medrxiv folder\")\n{k: biorxiv_dict[k] for k in list(biorxiv_dict)[:10]}","3333f269":"comm_dict=wordcount(comm_df,\"transmission\")\nprint(\"Occurence of word 'transmission' in papers of comm_use_subset folder\")\n{k: comm_dict[k] for k in list(comm_dict)[:10]}","d844684a":"comm_dict=wordcount(comm_df,\"drug\")\nprint(\"Occurence of word 'drug' in papers of comm_use_subset folder\")\n{k: comm_dict[k] for k in list(comm_dict)[:10]}","1e180e30":"noncomm_dict=wordcount(noncomm_df,\"drug\")\nprint(\"Occurence of word 'drug' in papers of noncomm_use_subset folder\")\n{k: noncomm_dict[k] for k in list(noncomm_dict)[:10]}","af4f4483":"comm_dict=wordcount(comm_df,\"vaccine\")\nprint(\"Occurence of word 'vaccine' in papers of comm_use_subset folder\")\n{k: comm_dict[k] for k in list(comm_dict)[:10]}","ca3453ee":"all_df=pmc_df.copy()\nall_df=all_df.append(biorxiv_df)\nall_df=all_df.append(noncomm_df)\nall_df=all_df.append(comm_df)\nprint(all_df.shape)\nall_df.head()","1aa1e11c":"all_df.insert(7,'tags',\"\")\nall_df.head()","b57598e4":"possible_tags=['transmission','incubation','environmental stability','risks factors','infections','genetics','origin','evolution','geographic','livestock',\n              'socioeconomic','ai','clinical trials','social science','vaccines','therapeutics','surveillance','diagnostics','pharmaceutical','non-pharmaceutical']","7909447e":"for i, row in tqdm(all_df.iterrows()):\n    tag={}\n    for i in possible_tags:\n        tag[i]=0\n    for word in possible_tags:\n        if word in row[\"text\"].lower():\n            tag[word]=sum(1 for _ in re.finditer(r'\\b%s\\b' % re.escape(word), row[\"text\"],re.IGNORECASE))\n    tag={k: v for k, v in sorted(tag.items(), key=lambda item: item[1],reverse = True)}\n    tag={k: tag[k] for k in list(tag)[:5]}\n    tags=\"\"\n    for i in tag.items():\n        if i[1]!=0:\n            tags+=i[0]+\", \"\n    tags=tags[:-2]\n    row['tags']=tags","6e88511e":"all_df.head()","eea46943":"def find_papers_from_tags(df,tags):\n    \"\"\"\n    if you want to find paper with multiple tags please send them in a comma seperated way\n    e.g \"infections,origin,vaccines\"\n    \"\"\"    \n    new_df=pd.DataFrame(columns=[\"paper_id\",\"title\",\"authors\",\"affiliations\",\"abstract\",\"text\",\"bibliography\",\"tags\"])\n    tags=tags.split(\",\")\n    for i, row in tqdm(df.iterrows()):\n        for tag in tags:\n            if tag in row['tags']:\n                new_df=new_df.append(row)\n                break\n    return new_df","eb32f4c2":"new_df=find_papers_from_tags(all_df,\"origin\")\nprint(new_df.shape)\nnew_df.head()","7c89129d":"new_df=find_papers_from_tags(all_df,\"infections,origin,vaccines\")\nprint(new_df.shape)\nnew_df.head()","a3dedc7b":"def find_papers_from_all_tags(df,tags):\n    \"\"\"\n    if you want to find paper with multiple tags please send them in a comma seperated way\n    e.g \"infections,origin,vaccines\"\n    \"\"\"    \n    new_df=pd.DataFrame(columns=[\"paper_id\",\"title\",\"authors\",\"affiliations\",\"abstract\",\"text\",\"bibliography\",\"tags\"])\n    tags=tags.split(\",\")\n    for i, row in tqdm(df.iterrows()):\n        found_all=True\n        for tag in tags:\n            if tag not in row['tags']:\n                found_all=False\n        if found_all:    \n            new_df=new_df.append(row)\n    return new_df","625204e3":"new_df=find_papers_from_all_tags(all_df,\"origin\")\nprint(new_df.shape)\nnew_df.head()","b2e6cd4a":"new_df=find_papers_from_all_tags(all_df,\"infections,origin,vaccines\")\nprint(new_df.shape)\nnew_df.head()","2c8929bc":"# About\n\nIn this notebook i have made the following functions to help researchers find the research paper they are looking for\n\nFollowing are the functions that i have made so far\n\n1. wordcount\n\nThis fuction gives the page titles along with the frequency of the word given in the function\n\n\n\nFor the next two functions i have added a column 'tags' that i populate with some sample tags from a list, the list of tags can be increased to broaden the search\n\n\n2. find_papers_from_tags\n\nThis function returns the papers with atleast one of the tag\/tags given in the function\n\n3. find_papers_from_all_tags\n\nThis function returns the papers with all of the tag\/tags given in the function\n\n\n","89d79082":"##  **Helper Functions**\n\nThese are the functions that are used to convert JSON to a pd.Dataframe Object ","22dd6997":"#  **Function to get a dictionary of pair of Titles\/PaperID with the occurence of the word sent in the function**\n\n**This function can be used to find the right research paper according more occurence of the key word one wishes to find**","93af95fb":"> **Populating 'tags' column**\n\nPopulating 13202 rows","14f08d5b":"**wordcount(biorxiv_df,\"transmission\")**\n\n\nFrom the biorxiv folder, the word \"transmission\" has the following occurence\n\n{ \n'Mapping a viral phylogeny onto outbreak trees to improve host transmission inference': 110,\n\n'Quantifying transmission of emerging zoonoses: 3 Using mathematical models to maximize the value of surveillance data 4 5 6 7': 81,\n\n'Stochastic challenges to interrupting helminth transmission': 71,\n\n\"International travelers and genomics uncover a 'hidden' Zika outbreak\": 50,\n\n'Title: Feasibility of controlling 2019-nCoV outbreaks by isolation of cases and contacts': 46,\n\n'D R A F T Inferring transmission trees to guide targeting of interventions against visceral leishmaniasis and post-kala-azar dermal leishmaniasis': 45,\n\n'Estimating the Relative Probability of Direct Transmission between Infectious Disease Patients': 42,\n\n'Estimating number of global importations of COVID-19 from Wuhan, risk of transmission outside mainland China and COVID-19 introduction index between countries outside mainland China': 39,\n\n'Early dynamics of transmission and control of COVID-19: a mathematical modelling study': 39,\n\n'Characterizing the transmission and identifying the control strategy for COVID-19 through epidemiological modeling': 39,\n\n'Real-time monitoring the transmission potential of COVID-19 in Singapore, February 2020': 38,\n\n'Stochastic dynamics of an epidemics with recurrent spillovers from an endemic reservoir': 35,\n\n...\n\n}","670aceaa":"# **Putting Data from all files and folders in dataframes**\n\nA single dataframe contains all papers and their text from a specific folder","52075fce":"# **Function to find paper with all of the tags given**\n\nNow if we want to get the research papers having all tag or tags gove we can easily get them from the following function\n\nAnd it will only return the papers which has all the tags you mention","4adbb856":"We can add more tags here in the array to broaden our search","75c5374f":"#  **Tagging all the research papers in the single dataframe**\n\nAll articles have upto 5 tags so that researchers can easily look for the research paper according to the tag they are looking for","cacd1155":"> **Adding \"tags\" Column**","e32531e7":"#  **Function to find paper with atleast one of the tags given**\n\n\n\nNow if we want to get the research papers having any tag or tags we can easily get them from the following function\n\nAnd it will only return the papers which has atleast one of the tags you mention","5cb56d65":"# **Puttin all files from all folders in a single dataframe**"}}