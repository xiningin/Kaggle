{"cell_type":{"198d4b80":"code","cb4622dc":"code","1c8512fb":"code","5ff0d956":"code","804540ad":"code","e08a1706":"code","e55b4d7d":"code","60d6dde5":"code","ba2d4738":"code","49e27e31":"code","4bc9fc39":"code","3369ab96":"code","0b57a420":"code","fc9a9b52":"code","2c2ba285":"code","b629a18c":"markdown","110ea6ac":"markdown","6ce8f187":"markdown","22b7c526":"markdown","c5b9ece7":"markdown","22d0a299":"markdown","be83375d":"markdown","7691276d":"markdown","11e0d27b":"markdown","544d57f5":"markdown","ac42d7a1":"markdown","95c3ae09":"markdown","a32a8a13":"markdown","1a938090":"markdown","2bdf3941":"markdown","1631d1fa":"markdown"},"source":{"198d4b80":"#\u00a0The usual imports\nimport pandas as pd\nimport missingno as msno\nimport pandas_profiling as pdp\nimport seaborn as sns\nfrom wordcloud import WordCloud\nimport matplotlib.pylab as plt\n%matplotlib inline","cb4622dc":"DATA_PATH = \"..\/input\/BreadBasket_DMS.csv\"","1c8512fb":"df = pd.read_csv(DATA_PATH)","5ff0d956":"df.sample(5)","804540ad":"print(f\"The data start at {df.Date.min()} and ends at {df.Date.max()}\")","e08a1706":"pdp.ProfileReport(df)","e55b4d7d":"msno.matrix(df)","60d6dde5":"#\u00a0Construct a timestamp colum using the Data and Time ones, then drop them.\ndf[\"tms\"] = pd.to_datetime(df[\"Date\"] + \" \" + df[\"Time\"])\ndf = df.drop([\"Date\", \"Time\"], axis=1)","ba2d4738":"#\u00a0To answer this question, I will create a word cloud.\nw = WordCloud().generate_from_frequencies(df.Item.value_counts().to_dict())\nplt.imshow(w)","49e27e31":"df.Item.value_counts().nlargest(5).plot(kind='bar')","4bc9fc39":"df.groupby(df.tms.dt.year).Item.value_counts().nlargest(2).plot(kind='bar')","3369ab96":"(df.groupby(df.Transaction)\n   .Item.count()\n   .value_counts(normalize=True)\n   .mul(100).plot(kind='bar'))","0b57a420":"df.groupby(df.tms.dt.date).Transaction.nunique().plot()","fc9a9b52":"(df.assign(dow=df.tms.dt.dayofweek, date=df.tms.dt.date)\n   .groupby(\"date\").agg({\"Transaction\": \"nunique\", \"dow\": \"first\"})\n   .reset_index()\n   .groupby(\"dow\")\n   .Transaction\n   .mean()\n   .plot(kind='bar'))","2c2ba285":"# I am filtering out October and April months since the data only contain \n#\u00a0few days from these.\n(df.assign(month=df.tms.dt.month, date=df.tms.dt.date)\n   .groupby(\"date\").agg({\"Transaction\": \"nunique\", \"month\": \"first\"})\n   .reset_index()\n   .loc[lambda df: ~df.month.isin([10, 4]), :]\n   .groupby(\"month\")\n   .Transaction\n   .mean()\n   .plot(kind='bar'))","b629a18c":"#\u00a0Most sold item per year","110ea6ac":"Let's find out in the this EDA notebook. \n\n<img src=\"https:\/\/proxy.duckduckgo.com\/iu\/?u=https%3A%2F%2Fi.onthe.io%2Fvllkyt4rad3nb02n1.4302d110.png&f=1\" \nalt=\"Image of some bread\" height=480 width=480>","6ce8f187":"That's it for today. I hope you have enjoyed this notebook. Time to get a cup of coffee and some cookies. :)\n\n<img src=\"https:\/\/opensource.com\/sites\/default\/files\/lead-images\/coffee_python.jpg\" height=480 width=480>","22b7c526":"# Extract timestamp","c5b9ece7":"#\u00a0Load and quickly explore data","22d0a299":"> #\u00a0Number of purchases per transcation?","be83375d":"#\u00a0Average number of transactions per month","7691276d":"It is coffee for the two years.","11e0d27b":"People buy more things on average on Saturdays closely followed by Fridays\n(notice that pandas assigns the index 0 to Monday and 6 to Sunday).","544d57f5":"Most people buy (more than 35%) one item.","ac42d7a1":"# Average number of transactions per day of week","95c3ae09":"People buy, on average, more things in November. Notice that the data only covers 5 months of the year so results might differ if the other months were added. ","a32a8a13":"#\u00a0So what do people buy?","1a938090":"# Evolution of transactions per day","2bdf3941":"It seems there are some weekly and monthly periodicity.\nLet's explore these more in details.","1631d1fa":"#\u00a0Top 5 most sold items"}}