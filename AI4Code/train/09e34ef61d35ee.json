{"cell_type":{"00324d53":"code","1f5bb31d":"code","4cb89773":"code","30e47b04":"code","f6280c0f":"code","192db598":"code","7a43e97f":"code","77cd5240":"code","5bb4357a":"code","a85d6611":"code","4422551b":"code","70f07b5e":"code","9a2fe59e":"markdown","d08ad48c":"markdown","5ea44bfb":"markdown","dc761cde":"markdown","b0bde033":"markdown"},"source":{"00324d53":"# import lybraries\nimport cv2\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np","1f5bb31d":"# Helper functions\n\n# show an image\ndef imShow(path):\n\n    %matplotlib inline\n\n    image = cv2.imread(path)\n    height, width = image.shape[:2]\n    resized_image = cv2.resize(image,(3*width, 3*height), interpolation = cv2.INTER_CUBIC)\n\n    fig = plt.gcf()\n    fig.set_size_inches(18, 10)\n    plt.axis(\"off\")\n    plt.imshow(cv2.cvtColor(resized_image, cv2.COLOR_BGR2RGB))\n    plt.show()","4cb89773":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport numpy as np","30e47b04":"class BatchNormalization(tf.keras.layers.BatchNormalization):\n    \"\"\"\n    \"Frozen state\" and \"inference mode\" are two separate concepts.\n    `layer.trainable = False` is to freeze the layer, so the layer will use\n    stored moving `var` and `mean` in the \"inference mode\", and both `gama`\n    and `beta` will not be updated !\n    \"\"\"\n    def call(self, x, training=False):\n        if not training:\n            training = tf.constant(False)\n        training = tf.logical_and(training, self.trainable)\n        return super().call(x, training)\n\ndef convolutional(input_layer, filters_shape, downsample=False, activate=True, bn=True, activate_type='leaky'):\n    if downsample:\n        input_layer = tf.keras.layers.ZeroPadding2D(((1, 0), (1, 0)))(input_layer)\n        padding = 'valid'\n        strides = 2\n    else:\n        strides = 1\n        padding = 'same'\n\n    conv = tf.keras.layers.Conv2D(filters=filters_shape[-1], kernel_size = filters_shape[0], strides=strides, padding=padding,\n                                  use_bias=not bn, kernel_regularizer=tf.keras.regularizers.l2(0.0005),\n                                  kernel_initializer=tf.random_normal_initializer(stddev=0.01),\n                                  bias_initializer=tf.constant_initializer(0.))(input_layer)\n\n    if bn: conv = BatchNormalization()(conv)\n    if activate == True:\n        if activate_type == \"leaky\":\n            conv = tf.nn.leaky_relu(conv, alpha=0.1)\n        elif activate_type == \"mish\":\n            conv = mish(conv)\n    return conv\n\ndef mish(x):\n    return x * tf.math.tanh(tf.math.softplus(x))\n    # return tf.keras.layers.Lambda(lambda x: x*tf.tanh(tf.math.log(1+tf.exp(x))))(x)\n\ndef residual_block(input_layer, input_channel, filter_num1, filter_num2, activate_type='leaky'):\n    short_cut = input_layer\n    conv = convolutional(input_layer, filters_shape=(1, 1, input_channel, filter_num1), activate_type=activate_type)\n    conv = convolutional(conv       , filters_shape=(3, 3, filter_num1,   filter_num2), activate_type=activate_type)\n\n    residual_output = short_cut + conv\n    return residual_output\n\ndef route_group(input_layer, groups, group_id):\n    convs = tf.split(input_layer, num_or_size_splits=groups, axis=-1)\n    return convs[group_id]\n\ndef upsample(input_layer):\n    return tf.image.resize(input_layer, (input_layer.shape[1] * 2, input_layer.shape[2] * 2), method='bilinear')\n\n","f6280c0f":"def cspdarknet53(input_data):\n\n    input_data = convolutional(input_data, (3, 3,  3,  32), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 32,  64), downsample=True, activate_type=\"mish\")\n\n    route = input_data\n    route = convolutional(route, (1, 1, 64, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n    for i in range(1):\n        input_data = residual_block(input_data,  64,  32, 64, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n\n    input_data = tf.concat([input_data, route], axis=-1)\n    input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 64, 128), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 128, 64), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 128, 64), activate_type=\"mish\")\n    for i in range(2):\n        input_data = residual_block(input_data, 64,  64, 64, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 64, 64), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n    input_data = convolutional(input_data, (3, 3, 128, 256), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 256, 128), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 256, 128), activate_type=\"mish\")\n    for i in range(8):\n        input_data = residual_block(input_data, 128, 128, 128, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 128, 128), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n    route_1 = input_data\n    input_data = convolutional(input_data, (3, 3, 256, 512), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 512, 256), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 512, 256), activate_type=\"mish\")\n    for i in range(8):\n        input_data = residual_block(input_data, 256, 256, 256, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 256, 256), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n    route_2 = input_data\n    input_data = convolutional(input_data, (3, 3, 512, 1024), downsample=True, activate_type=\"mish\")\n    route = input_data\n    route = convolutional(route, (1, 1, 1024, 512), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 1024, 512), activate_type=\"mish\")\n    for i in range(4):\n        input_data = residual_block(input_data, 512, 512, 512, activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 512, 512), activate_type=\"mish\")\n    input_data = tf.concat([input_data, route], axis=-1)\n\n    input_data = convolutional(input_data, (1, 1, 1024, 1024), activate_type=\"mish\")\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n    input_data = convolutional(input_data, (3, 3, 512, 1024))\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n\n    input_data = tf.concat([tf.nn.max_pool(input_data, ksize=13, padding='SAME', strides=1), tf.nn.max_pool(input_data, ksize=9, padding='SAME', strides=1)\n                            , tf.nn.max_pool(input_data, ksize=5, padding='SAME', strides=1), input_data], axis=-1)\n    input_data = convolutional(input_data, (1, 1, 2048, 512))\n    input_data = convolutional(input_data, (3, 3, 512, 1024))\n    input_data = convolutional(input_data, (1, 1, 1024, 512))\n\n    return route_1, route_2, input_data","192db598":"def YOLOv4(input_layer, NUM_CLASS):\n    route_1, route_2, conv = cspdarknet53(input_layer)\n\n    route = conv\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = upsample(conv)\n    route_2 = convolutional(route_2, (1, 1, 512, 256))\n    conv = tf.concat([route_2, conv], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n\n    route_2 = conv\n    conv = convolutional(conv, (1, 1, 256, 128))\n    conv = upsample(conv)\n    route_1 = convolutional(route_1, (1, 1, 256, 128))\n    conv = tf.concat([route_1, conv], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 256, 128))\n    conv = convolutional(conv, (3, 3, 128, 256))\n    conv = convolutional(conv, (1, 1, 256, 128))\n    conv = convolutional(conv, (3, 3, 128, 256))\n    conv = convolutional(conv, (1, 1, 256, 128))\n\n    route_1 = conv\n    conv = convolutional(conv, (3, 3, 128, 256))\n    conv_sbbox = convolutional(conv, (1, 1, 256, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n\n    conv = convolutional(route_1, (3, 3, 128, 256), downsample=True)\n    conv = tf.concat([conv, route_2], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv = convolutional(conv, (1, 1, 512, 256))\n\n    route_2 = conv\n    conv = convolutional(conv, (3, 3, 256, 512))\n    conv_mbbox = convolutional(conv, (1, 1, 512, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n\n    conv = convolutional(route_2, (3, 3, 256, 512), downsample=True)\n    conv = tf.concat([conv, route], axis=-1)\n\n    conv = convolutional(conv, (1, 1, 1024, 512))\n    conv = convolutional(conv, (3, 3, 512, 1024))\n    conv = convolutional(conv, (1, 1, 1024, 512))\n    conv = convolutional(conv, (3, 3, 512, 1024))\n    conv = convolutional(conv, (1, 1, 1024, 512))\n\n    conv = convolutional(conv, (3, 3, 512, 1024))\n    conv_lbbox = convolutional(conv, (1, 1, 1024, 3 * (NUM_CLASS + 5)), activate=False, bn=False)\n\n    return [conv_sbbox, conv_mbbox, conv_lbbox]","7a43e97f":"def decode(conv_output, output_size, NUM_CLASS, STRIDES, ANCHORS, i=0, XYSCALE=[1,1,1]):\n    batch_size = tf.shape(conv_output)[0]\n    conv_output = tf.reshape(conv_output, (batch_size, output_size, output_size, 3, 5 + NUM_CLASS))\n\n    conv_raw_dxdy, conv_raw_dwdh, conv_raw_conf, conv_raw_prob = tf.split(conv_output, (2, 2, 1, NUM_CLASS), axis=-1)\n\n    xy_grid = tf.meshgrid(tf.range(output_size), tf.range(output_size))\n    xy_grid = tf.expand_dims(tf.stack(xy_grid, axis=-1), axis=2)  # [gx, gy, 1, 2]\n    xy_grid = tf.tile(tf.expand_dims(xy_grid, axis=0), [batch_size, 1, 1, 3, 1])\n\n    xy_grid = tf.cast(xy_grid, tf.float32)\n\n    pred_xy = (tf.reshape(tf.sigmoid(conv_raw_dxdy), (-1, 2)) * XYSCALE[i] - 0.5 * (XYSCALE[i] - 1) + tf.reshape(xy_grid, (-1, 2))) * STRIDES[i]\n    pred_xy = tf.reshape(pred_xy, (batch_size, output_size, output_size, 3, 2))\n    pred_wh = (tf.exp(conv_raw_dwdh) * ANCHORS[i])\n    pred_xywh = tf.concat([pred_xy, pred_wh], axis=-1)\n\n    pred_conf = tf.sigmoid(conv_raw_conf)\n    pred_prob = tf.sigmoid(conv_raw_prob)\n\n    pred_prob = pred_conf * pred_prob\n\n    pred_prob = tf.reshape(pred_prob, (batch_size, -1, NUM_CLASS))\n    pred_xywh = tf.reshape(pred_xywh, (batch_size, -1, 4))\n    return pred_xywh, pred_prob","77cd5240":"!wget https:\/\/github.com\/AlexeyAB\/darknet\/releases\/download\/darknet_yolo_v3_optimal\/yolov4.weights","5bb4357a":"def load_weights(model, weights_file):\n    \n    layer_size = 110\n    output_pos = [93, 101, 109]\n    wf = open(weights_file, 'rb')\n    major, minor, revision, seen, _ = np.fromfile(wf, dtype=np.int32, count=5)\n\n    j = 0\n    for i in range(layer_size):\n        conv_layer_name = 'conv2d_%d' % i if i > 0 else 'conv2d'\n        bn_layer_name = 'batch_normalization_%d' %j if j > 0 else 'batch_normalization'\n\n        conv_layer = model.get_layer(conv_layer_name)\n        filters = conv_layer.filters\n        k_size = conv_layer.kernel_size[0]\n        in_dim = conv_layer.input_shape[-1]\n\n        if i not in output_pos:\n            # darknet weights: [beta, gamma, mean, variance]\n            bn_weights = np.fromfile(wf, dtype=np.float32, count=4 * filters)\n            # tf weights: [gamma, beta, mean, variance]\n            bn_weights = bn_weights.reshape((4, filters))[[1, 0, 2, 3]]\n            bn_layer = model.get_layer(bn_layer_name)\n            j += 1\n        else:\n            conv_bias = np.fromfile(wf, dtype=np.float32, count=filters)\n\n        # darknet shape (out_dim, in_dim, height, width)\n        conv_shape = (filters, in_dim, k_size, k_size)\n        conv_weights = np.fromfile(wf, dtype=np.float32, count=np.product(conv_shape))\n        # tf shape (height, width, in_dim, out_dim)\n        conv_weights = conv_weights.reshape(conv_shape).transpose([2, 3, 1, 0])\n\n        if i not in output_pos:\n            conv_layer.set_weights([conv_weights])\n            bn_layer.set_weights(bn_weights)\n        else:\n            conv_layer.set_weights([conv_weights, conv_bias])\n\n    # assert len(wf.read()) == 0, 'failed to read all data'\n    wf.close()","a85d6611":"def filter_boxes(box_xywh, scores, score_threshold=0.4, input_shape = tf.constant([416,416])):\n    scores_max = tf.math.reduce_max(scores, axis=-1)\n\n    mask = scores_max >= score_threshold\n    class_boxes = tf.boolean_mask(box_xywh, mask)\n    pred_conf = tf.boolean_mask(scores, mask)\n    class_boxes = tf.reshape(class_boxes, [tf.shape(scores)[0], -1, tf.shape(class_boxes)[-1]])\n    pred_conf = tf.reshape(pred_conf, [tf.shape(scores)[0], -1, tf.shape(pred_conf)[-1]])\n\n    box_xy, box_wh = tf.split(class_boxes, (2, 2), axis=-1)\n\n    input_shape = tf.cast(input_shape, dtype=tf.float32)\n\n    box_yx = box_xy[..., ::-1]\n    box_hw = box_wh[..., ::-1]\n\n    box_mins = (box_yx - (box_hw \/ 2.)) \/ input_shape\n    box_maxes = (box_yx + (box_hw \/ 2.)) \/ input_shape\n    boxes = tf.concat([\n        box_mins[..., 0:1],  # y_min\n        box_mins[..., 1:2],  # x_min\n        box_maxes[..., 0:1],  # y_max\n        box_maxes[..., 1:2]  # x_max\n    ], axis=-1)\n    # return tf.concat([boxes, pred_conf], axis=-1)\n    return (boxes, pred_conf)\n\ndef image_preprocess(image, target_size, gt_boxes=None):\n    ih, iw    = target_size\n    h,  w, _  = image.shape\n\n    scale = min(iw\/w, ih\/h)\n    nw, nh  = int(scale * w), int(scale * h)\n    image_resized = cv2.resize(image, (nw, nh))\n\n    image_paded = np.full(shape=[ih, iw, 3], fill_value=128.0)\n    dw, dh = (iw - nw) \/\/ 2, (ih-nh) \/\/ 2\n    image_paded[dh:nh+dh, dw:nw+dw, :] = image_resized\n    image_paded = image_paded \/ 255.\n\n    if gt_boxes is None:\n        return image_paded\n\n    else:\n        gt_boxes[:, [0, 2]] = gt_boxes[:, [0, 2]] * scale + dw\n        gt_boxes[:, [1, 3]] = gt_boxes[:, [1, 3]] * scale + dh\n        return image_paded, gt_boxes","4422551b":"from keras import backend as K\nK.clear_session()\nSTRIDES = [8, 16, 32] \nANCHORS = [12,16, 19,36, 40,28, 36,75, 76,55, 72,146, 142,110, 192,243, 459,401]\nNUM_CLASS = 1\nXYSCALE = [1.2, 1.1, 1.05]\nweights = \"\/kaggle\/working\/yolov4.weights\"\ninput_size = 416\n\ninput_layer = tf.keras.layers.Input([input_size, input_size, 3])\nfeature_maps = YOLOv4(input_layer, NUM_CLASS)\nbbox_tensors = []\nprob_tensors = []\n\nfor i, fm in enumerate(feature_maps):\n    if i == 0:\n        output_tensors = decode(fm, input_size \/\/ 8, NUM_CLASS, STRIDES, ANCHORS, i, XYSCALE)\n    elif i == 1:\n        output_tensors = decode(fm, input_size \/\/ 16, NUM_CLASS, STRIDES, ANCHORS, i, XYSCALE)\n    else:\n        output_tensors = decode(fm, input_size \/\/ 32, NUM_CLASS, STRIDES, ANCHORS, i, XYSCALE)\n    bbox_tensors.append(output_tensors[0])\n    prob_tensors.append(output_tensors[1])\n\n\npred_bbox = tf.concat(bbox_tensors, axis=1)\npred_prob = tf.concat(prob_tensors, axis=1)\n\nboxes, pred_conf = filter_boxes(pred_bbox, pred_prob, score_threshold=0.2, input_shape=tf.constant([input_size, input_size]))\npred = tf.concat([boxes, pred_conf], axis=-1)\n\nmodel = tf.keras.Model(input_layer, pred)\nload_weights(model, weights)  \nmodel.save(\"\/kaggle\/working\/\")","70f07b5e":"model.summary()","9a2fe59e":"# **YOLO**\n\nSince it has been proposed in 2016, YOLO has been the fastest and most used One Shot architecture for object detection.\nThe last version v4 is composed of a CNN \"backbone\" called Darknet, a \"neck\" composed of Spatial Pyramid Pooling and Path Aggregation Network, and the same \"head\" of YOLOv3 which compute both the box regression and classification. \n","d08ad48c":"# STEP 1: BUILD A YOLO MODEL","5ea44bfb":"# STEP 4: READ THE PLATE","dc761cde":"# STEP 3: TRAIN THE MODEL","b0bde033":"# STEP 2: GET DATA\nGoogle image"}}