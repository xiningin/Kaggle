{"cell_type":{"6bf369a6":"code","b02185f7":"code","031e5f89":"code","b69ca431":"code","5155d6bc":"code","90a53983":"code","4d981656":"code","dff82c30":"code","d93f8971":"code","6c777d32":"code","09d17b65":"code","b1bcd366":"markdown","9894ce38":"markdown","87bcddea":"markdown","4e9eeed3":"markdown","b33e1186":"markdown","2a6ae41f":"markdown","2196c93b":"markdown","ee0c4c06":"markdown","8a7b5659":"markdown","b55d4f1a":"markdown","66dad260":"markdown"},"source":{"6bf369a6":"import numpy as np\nimport os\nimport shutil\nimport PIL\nimport tensorflow as tf\nimport tensorflow_datasets as tfds\nimport matplotlib.pyplot as plt\nfrom tensorflow.keras.layers import Dense, Activation,Dropout,BatchNormalization, Input\nfrom tensorflow.keras import regularizers\nfrom tensorflow.keras.models import Model, load_model\nfrom tensorflow.keras.optimizers import Adam, Adamax\nfrom sklearn.metrics import confusion_matrix, classification_report\nimport seaborn as sns\nsns.set_style('darkgrid')\nimport logging\nlogging.getLogger(\"tensorflow\").setLevel(logging.ERROR)","b02185f7":"def tr_plot(tr_data, start_epoch):\n    #Plot the training and validation data\n    tacc=tr_data.history['accuracy']\n    tloss=tr_data.history['loss']\n    vacc=tr_data.history['val_accuracy']\n    vloss=tr_data.history['val_loss']\n    Epoch_count=len(tacc)+ start_epoch\n    Epochs=[]\n    for i in range (start_epoch ,Epoch_count):\n        Epochs.append(i+1)   \n    index_loss=np.argmin(vloss)#  this is the epoch with the lowest validation loss\n    val_lowest=vloss[index_loss]\n    index_acc=np.argmax(vacc)\n    acc_highest=vacc[index_acc]\n    plt.style.use('fivethirtyeight')\n    sc_label='best epoch= '+ str(index_loss+1 +start_epoch)\n    vc_label='best epoch= '+ str(index_acc + 1+ start_epoch)\n    fig,axes=plt.subplots(nrows=1, ncols=2, figsize=(20,8))\n    axes[0].plot(Epochs,tloss, 'r', label='Training loss')\n    axes[0].plot(Epochs,vloss,'g',label='Validation loss' )\n    axes[0].scatter(index_loss+1 +start_epoch,val_lowest, s=150, c= 'blue', label=sc_label)\n    axes[0].set_title('Training and Validation Loss')\n    axes[0].set_xlabel('Epochs')\n    axes[0].set_ylabel('Loss')\n    axes[0].legend()\n    axes[1].plot (Epochs,tacc,'r',label= 'Training Accuracy')\n    axes[1].plot (Epochs,vacc,'g',label= 'Validation Accuracy')\n    axes[1].scatter(index_acc+1 +start_epoch,acc_highest, s=150, c= 'blue', label=vc_label)\n    axes[1].set_title('Training and Validation Accuracy')\n    axes[1].set_xlabel('Epochs')\n    axes[1].set_ylabel('Accuracy')\n    axes[1].legend()\n    plt.tight_layout\n    #plt.style.use('fivethirtyeight')\n    plt.show()\n","031e5f89":"def print_in_color(txt_msg,fore_tupple,back_tupple,):\n    #prints the text_msg in the foreground color specified by fore_tupple with the background specified by back_tupple \n    #text_msg is the text, fore_tupple is foregroud color tupple (r,g,b), back_tupple is background tupple (r,g,b)\n    rf,gf,bf=fore_tupple\n    rb,gb,bb=back_tupple\n    msg='{0}' + txt_msg\n    mat='\\33[38;2;' + str(rf) +';' + str(gf) + ';' + str(bf) + ';48;2;' + str(rb) + ';' +str(gb) + ';' + str(bb) +'m' \n    print(msg .format(mat), flush=True)\n    print('\\33[0m', flush=True) # returns default print color to back to black\n    return","b69ca431":"train_dir=r'..\/input\/ds-x45k-3-classification\/train\/train'\ntest_dir=r'..\/input\/ds-x45k-3-classification\/test\/test'","5155d6bc":"img_path = r'..\/input\/ds-x45k-3-classification\/test\/test\/covid-19\/COVID-114.png'\nimg=plt.imread(img_path)\nprint ('Image shape = ', img.shape)\nplt.imshow(img, cmap='gray')","90a53983":"\nimg_shape=(299,299,3) # \nimg_size=(img_shape[0], img_shape[1])\ntrain_ds=tf.keras.preprocessing.image_dataset_from_directory( train_dir, image_size=img_size, seed=123, batch_size=32, validation_split=.02,\n                                                               shuffle=True, subset='training', labels='inferred', label_mode='int')\nvalid_ds=tf.keras.preprocessing.image_dataset_from_directory( train_dir, image_size=img_size, seed=123, batch_size=32, validation_split=.02,\n                                                               shuffle=True, subset='validation',labels='inferred', label_mode='int' )\ntest_ds=tf.keras.preprocessing.image_dataset_from_directory(test_dir, image_size=img_size, shuffle=False, batch_size=32, labels='inferred',\n                                                             label_mode='int') # set shuffle=False to keep file order\nclass_names=train_ds.class_names\nprint ('class names are: ', class_names)\nclass_count=len(class_names)\n","4d981656":"plt.figure(figsize=(20,20))\nfor images, labels in train_ds.take(1):\n    for i in range (25):\n        plt.subplot(5,5,i +1)\n        img=images[i]\/255  \n        plt.title(class_names[labels[i]], color='blue', fontsize=12)\n        plt.imshow(img)\n        plt.axis('off')\n    plt.show()\n","dff82c30":"input=Input(shape=img_shape)\nx=tf.keras.applications.EfficientNetB3(include_top=False, weights=\"imagenet\", pooling='max')(input) \nx=tf.keras.layers.BatchNormalization(axis=-1, momentum=0.99, epsilon=0.001 )(x)\nx = Dense(256, kernel_regularizer = regularizers.l2(l = 0.016),activity_regularizer=regularizers.l1(0.006),\n                bias_regularizer=regularizers.l1(0.006) ,activation='relu')(x)\nx=Dropout(rate=.4, seed=123)(x)        \noutput=Dense(class_count, activation='softmax')(x)\nmodel=Model(inputs=input, outputs=output)\nmodel.compile(Adamax(learning_rate=.001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])","d93f8971":"rlronp=tf.keras.callbacks.ReduceLROnPlateau( monitor=\"val_loss\", factor=0.5,  patience=1, verbose=1)\nestop=tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=3, verbose=1,  restore_best_weights=True)\nepochs=10\nhistory=model.fit( train_ds, validation_data=valid_ds, epochs=epochs, verbose=1, callbacks=[rlronp, estop])\n  ","6c777d32":"tr_plot(history, 0)","09d17b65":"ytrue=[]\nfor images, label in test_ds:   \n    for e in label:\n        ytrue.append(class_names[e]) # list of class names associated with each image file in test dataset         \nypred=[]\nerrors=0\ncount=0\npreds=model.predict(test_ds, verbose=1) # predict on the test data\nfor i, p in enumerate(preds):\n    count +=1\n    index=np.argmax(p) # get index of prediction with highest probability\n    klass=class_names[index] \n    ypred.append(klass)    \n    if klass != ytrue[i]:\n        errors +=1\nacc= (count-errors)* 100\/count\nfor i in range(len(ytrue)):\n    print (ytrue[i], ypred[i])\nmsg=f'there were {count-errors} correct predictions in {count} tests for an accuracy of {acc:6.2f} % '\nprint_in_color(msg, (0,255,255), (55,65,80)) \nypred=np.array(ypred)\nytrue=np.array(ytrue)\nif class_count<= 30: # if more than 30 classes plot will be unreadable so do not make it\n        # create a confusion matrix \n        cm = confusion_matrix(ytrue, ypred )\n        if class_count<8:\n            fig_width=8\n            fig_height=8\n        else:\n            fig_width= int(class_count * .5)\n            fig_height= int(class_count * .5)\n        plt.figure(figsize=(fig_width, fig_height))\n        sns.heatmap(cm, annot=True, vmin=0, fmt='g', cmap='Blues', cbar=False)       \n        plt.xticks(np.arange(class_count)+.5, class_names, rotation= 90)\n        plt.yticks(np.arange(class_count)+.5, class_names, rotation=0)\n        plt.xlabel(\"Predicted\")\n        plt.ylabel(\"Actual\")\n        plt.title(\"Confusion Matrix\")\n        plt.show()\nclr = classification_report(ytrue, ypred, target_names=class_names)\nprint(\"Classification Report:\\n----------------------\\n\", clr)    ","b1bcd366":"### input an image to get the shape","9894ce38":"### define the directories ","87bcddea":"### define function to print text in RGB foreground and background colors","4e9eeed3":"### plot the training data","b33e1186":"### create the model","2a6ae41f":"### create reduce learning rate on plateau callback , early stopping callback then train the model","2196c93b":"### show some training images- Note with shuffle=False test images remain in original order","ee0c4c06":"# Note where I print out the values of ytrue and y pred you will see that when ytrue is normal, the prediction ypred is covid-19\n# and where ytrue is covid-19 ypred is always normal. So I believe the test set is MISLABELED!!!!!!!!!!!!!!\n# To check I ran a different notebook using data frames rather than image_dataset_from_directory. Found exactly the same problem.\n# I downloaded the dataset to my computer but switched the names in the test directory and the results are as they should be\n# so this verifies the mislabeling.","8a7b5659":"### create a function to plot training data from model.fit","b55d4f1a":"### make predictions on test set, compute accuracy and create classification report and confusion matrix","66dad260":"### create the Datasets"}}