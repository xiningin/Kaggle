{"cell_type":{"15019caf":"code","a661daaa":"code","20eca5a5":"code","0c9dd0ea":"code","ebc34d08":"code","bb3bbad2":"code","56d2e986":"code","9291f56e":"code","d3c068b2":"code","d7e64250":"code","0e44bcd9":"code","e5cf8e00":"code","74c9422e":"code","9ea33a76":"code","7b865721":"code","8e504026":"code","78ce23fe":"code","7ee67582":"code","b8b9920a":"code","ac5bd8b0":"code","39f4a627":"code","baa25b14":"code","f44ef903":"code","97ff5bff":"code","c0694f22":"code","ed2e1805":"code","80a79f2f":"code","967079ea":"code","ba1277cd":"code","f6bd201e":"code","7b2b5d63":"code","16ea97aa":"code","5e89c384":"code","02235231":"code","74b2f348":"code","bc54a222":"code","19ded303":"code","1171dd4d":"code","c0d09d63":"code","dbc06ca3":"code","e8b62999":"code","1db9a974":"code","4d0cb9ea":"code","562fc148":"code","60bc2e65":"code","14a574ca":"code","47770718":"code","7a1c5521":"code","683a644f":"code","116cc4a2":"code","bbda6dee":"code","d28f024a":"code","1294f515":"code","5bd33c83":"code","a85dc989":"code","2e17fe6b":"code","7ae2a77d":"code","aa92d80c":"code","993ca648":"code","ecc8eba7":"code","f0c73cf9":"code","2f75bd5b":"code","050cbf5d":"code","9822ddd9":"code","22a547c9":"code","23930dd9":"code","472515c5":"code","003b7c08":"code","9c0ae46e":"code","aada1291":"code","3493cdfb":"code","f9171b33":"code","48157d95":"code","4ca49a3b":"code","93536fcb":"code","27c57a56":"code","d0eb213b":"code","bf011eee":"code","3a4addf5":"code","430b5b2d":"code","4324358f":"code","3308dab1":"code","979493b1":"code","ce12d01e":"code","28db04cd":"code","8bffee21":"code","8cc32a1f":"code","d418bd58":"code","60e274e8":"code","6ffd9fc8":"code","4ebabc66":"code","07e2c182":"code","840409ae":"code","23259cff":"markdown","f15f5f9d":"markdown","6b6ce202":"markdown","df6c6cc6":"markdown","e6ea50a8":"markdown","90179e45":"markdown","bdd11705":"markdown","aac12d13":"markdown","5d412f63":"markdown","28d177d8":"markdown","10eb28eb":"markdown","20053623":"markdown","86cbfc6f":"markdown","83649428":"markdown","4d1a5c14":"markdown","d3f7aa8e":"markdown","21149b9c":"markdown","351cf20e":"markdown","63bff531":"markdown","ca11118c":"markdown","de1a5138":"markdown","51283060":"markdown","38e19826":"markdown","e62afd6d":"markdown","aa13d5f6":"markdown"},"source":{"15019caf":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nnp.random.seed(1337)\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","a661daaa":"import tensorflow as tf\nimport matplotlib.pyplot as plt\nimport PIL\nimport pathlib\nimport cv2\nfrom tensorflow.keras import layers\nfrom sklearn.model_selection import KFold, StratifiedKFold\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nimport glob\nimport csv\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import classification_report","20eca5a5":"print(tf.__version__)","0c9dd0ea":"#path_data = '..\/input\/brain-mri-images-for-brain-tumor-detection\/brain_tumor_dataset'\npath_test = '..\/input\/brain-tumor-classification-mri\/Testing'\npath_data = '..\/input\/brain-tumor-classification-mri\/Training'\n\n\npath_test = pathlib.Path(path_test)\npath_data = pathlib.Path(path_data)\nprint(path_data)\n\nimage_count = len(list(path_data.glob('*\/*.jpg')))\nprint(image_count)\ntest_image_count = len(list(path_test.glob('*\/*.jpg')))\nprint(test_image_count)","ebc34d08":"tumors = list(path_data.glob('glioma_tumor\/*'))\nprint(tumors[1])\nimg1 = PIL.Image.open(str(tumors[0]))\nimg1","bb3bbad2":"not_tumors = list(path_data.glob('no_tumor\/*'))\nimg2 = PIL.Image.open(str(not_tumors[0]))\nimg2","56d2e986":"img_opencv = cv2.imread(str(not_tumors[0]))\nprint(img_opencv.shape)\nimg_opencv1 = cv2.imread(str(tumors[0]))\nprint(img_opencv1.shape)","9291f56e":"batch = 32\nimg_height = 250\nimg_width = 250","d3c068b2":"train = tf.keras.preprocessing.image_dataset_from_directory(\npath_data,\nvalidation_split = 0.2,\nsubset = 'training',\nseed = 42,\nimage_size  =(img_height,img_width),\nbatch_size = batch)","d7e64250":"val = tf.keras.preprocessing.image_dataset_from_directory(\npath_data,\nvalidation_split = 0.2,\nsubset = 'validation',\nseed = 42,\nimage_size = (img_height,img_width),\nbatch_size = batch)","0e44bcd9":"test = tf.keras.preprocessing.image_dataset_from_directory(\npath_test,\nseed = 42,\nimage_size = (img_height,img_width),\nbatch_size = batch)","e5cf8e00":"print(train.class_names)\nprint(val.class_names)\nprint(test.class_names)","74c9422e":"classes = train.class_names\nplt.figure(figsize = (10,10))\nfor img,label in train.take(1):\n    for i in range(9):\n        ax = plt.subplot(3, 3, i + 1)\n        plt.imshow(img[i].numpy().astype(\"uint8\"))\n        plt.title(classes[label[i]],\n                  fontdict = {'fontsize': '19',\n                              'color': 'white'}\n                 )\n        ","9ea33a76":"for image_batch, labels_batch in train:\n  print(image_batch.shape)\n  print(labels_batch.shape)\n  break","7b865721":"AUTOTUNE = tf.data.AUTOTUNE\n\ntrain = train.prefetch(buffer_size=AUTOTUNE)\nval = val.prefetch(buffer_size=AUTOTUNE)\ntest = test.prefetch(buffer_size=AUTOTUNE)","8e504026":"help(test.as_numpy_iterator())","78ce23fe":"def prediction_label_comparison(model,test):\n    #Retrieve a batch of images from the test set\n    image_batch, label_batch = test.as_numpy_iterator().next()\n    prediction = model.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        predict.append(pred)\n    predict = np.array(predict)\n\n    #print('Predictions:\\n',predictions)#.numpy())\n    print('Labels:\\n', label_batch)\n    print('Predictions:\\n',predict)\n    '''\n    print(predictions.shape)\n    print(label_batch.shape)\n    print(predict.shape)\n    '''\n\n    plt.figure(figsize=(10, 10))\n    for i in range(9):\n      ax = plt.subplot(3, 3, i + 1)\n      plt.imshow(image_batch[i].astype(\"uint8\"))\n      plt.title(classes[predict[i]],fontdict = {'fontsize': '14',\n                                  'color': 'white'})\n      plt.axis(\"off\")\n    return label_batch , predict","7ee67582":"def test_tumor(list_test_path,model):\n    # sunflower_url = 'https:\/\/'\n    # sunflower_path = tf.keras.utils.get_file('name of file', origin=sunflower_url)\n    for path_name in list_test_path:\n        test_img_path = path_name\n\n\n        test_image = tf.keras.preprocessing.image.load_img(\n            test_img_path, target_size=(img_height, img_width)\n        )\n        test_array = tf.keras.preprocessing.image.img_to_array(test_image)\n        test_array = tf.expand_dims(test_array, 0) # Create a batch\n\n        predictions = model.predict(test_array)\n        score = tf.nn.softmax(predictions[0])\n\n        print(\n            \"This image most likely belongs to {} with a {:.2f} percent confidence.\"\n            .format(classes[np.argmax(score)], 100 * np.max(score))\n        )","b8b9920a":"def csv_builder(path_data,label_names):\n    df = pd.DataFrame(columns = ['images','labels'])\n    for name in label_names:\n        BASE_DIR = str(path_data)+'\/'\n        #train_folder_glioma = BASE_DIR+'glioma_tumor\/'\n        train_folder_name = BASE_DIR+name+'\/'\n\n        #train_annotation = BASE_DIR+'annotated_train_data\/'\n\n        files_in_train = sorted(os.listdir(train_folder_name))\n        #files_in_annotated = sorted(os.listdir(train_annotation))\n\n        image_names =[i for i in files_in_train]\n\n        \n        for x in image_names:\n            df = df.append({'images':train_folder_name+str(x),'labels':name},ignore_index=True)\n            #df = df.append({'images':str(x),'labels':name},ignore_index=True)\n\n        #df['images']=[train_folder_glioma+str(x) for x in image_names]\n        #df['labels']=[train_annotation+str(x) for x in images]\n        #pd.to_csv('files_path.csv', header=None)\n    return df","ac5bd8b0":"def model_inputs(model2,train,val,test):\n    num_classes = 4\n    epochs = 15\n    model2.fit(\n        train,\n        validation_data=val,\n        epochs=epochs,\n        #callbacks = callback,\n        shuffle=False,\n        verbose = 0\n    )\n    results = model2.evaluate(test)\n    return results[0],results[1] , model","39f4a627":"def cross_validation(n_splits,final_csv,test_csv,img_width,img_height,model):\n    final_loss = 0\n    final_acc = 0\n\n    '''\n    Seperating a dataframe for testing data\n    '''\n    ##\n    final_csv = final_csv.sample(frac=1)\n    ##\n    Y = final_csv[['labels']]\n    n = len(Y)\n    kf = KFold(n_splits = 5)\n    #skf = StratifiedKFold(n_splits = 5, random_state = 7, shuffle = True) \n    idg = ImageDataGenerator(#width_shift_range=0.1,\n#                          height_shift_range=0.1,\n#                          zoom_range=0.3,\n#                          fill_mode='nearest',\n#                          horizontal_flip = True,\n                         rescale=1.\/255)\n    \n    \n    \n    \n    print('Performing cross validation...')\n    test = idg.flow_from_dataframe(test_csv,\n                                       x_col = \"images\",\n                                       y_col = \"labels\",\n                                       class_mode = \"sparse\",\n                                       shuffle = True,\n                                      target_size = (img_width,img_height),\n                                      verbose = 0)#,subset='validation')\n#     test = tf.keras.preprocessing.image_dataset_from_directory(path_test,\n#                                                                    seed = 42,\n#                                                                    image_size = (img_height,img_width),\n#                                                                    batch_size = 32)\n\n    for train_index, val_index in kf.split(np.zeros(n),Y):\n        training_data = final_csv.iloc[train_index]\n        validation_data = final_csv.iloc[val_index]\n        train = idg.flow_from_dataframe(training_data,\n                                        x_col = \"images\",\n                                        y_col = \"labels\",\n                                        class_mode = \"sparse\",\n                                        shuffle = True,\n                                        subset='training',\n                                       target_size = (img_width,img_height),\n                                       verbose = 0)\n        val = idg.flow_from_dataframe(validation_data,\n                                      x_col = \"images\",\n                                      y_col = \"labels\",\n                                      class_mode = \"sparse\",\n                                      shuffle = True,\n                                     target_size = (img_width,img_height),\n                                     verbose = 0)\t\n        \n#         if pretrained == 1:\n#             # Create the base model from the pre-trained model MobileNet V2\n#             image_size = (img_width,img_height)\n#             IMG_SHAPE = image_size + (3,)\n#             base_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n#                                                            include_top=False,\n#                                                            weights='imagenet')\n\n#             base_model.trainable = False\n#             ##\n#             image_batch, label_batch = next(iter(train))\n#             feature_batch = base_model(image_batch)\n#             print(feature_batch.shape)\n#             ##\n#             global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\n#             feature_batch_average = global_average_layer(feature_batch)\n#             ##\n#             prediction_layer = tf.keras.layers.Dense(4)\n#             prediction_batch = prediction_layer(feature_batch_average)\n#             ##\n#             preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input\n#             ##\n#             inputs = tf.keras.Input(shape=(250, 250, 3))\n#             #x = data_augmentation(inputs)\n#             x = preprocess_input(inputs)\n#             x = base_model(x, training=False)\n#             x = global_average_layer(x)\n#             x = tf.keras.layers.Dropout(0.2)(x)\n#             x = tf.keras.layers.Flatten()(x)\n#             x = tf.keras.layers.Dense(1280,activation='relu')(x)\n#             outputs = prediction_layer(x)\n#             model = tf.keras.Model(inputs, outputs)\n#             ##\n#             base_learning_rate = 0.0001\n#             model.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n#                           loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n#                           metrics=['accuracy'])\n#             ##\n            \n        \n        '''\n        Passing the preprocessed data for model training\n        '''\n        loss,acc,returned_model = model_inputs(model,train,val,test)\n        final_loss += loss\n        final_acc += acc\n    return final_loss\/n_splits , final_acc\/n_splits , returned_model\n   ","baa25b14":"normalization_layer = tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\nconv_layer_32 = tf.keras.layers.Conv2D(32,(3,3),activation='relu')\nconv_layer_64 = tf.keras.layers.Conv2D(64,3,activation='relu')\nconv_layer_16 = tf.keras.layers.Conv2D(16,3,activation='relu')\nmax_pool = tf.keras.layers.MaxPooling2D()\ncallback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=5)","f44ef903":"data_augmentation = tf.keras.Sequential(\n  [\n    normalization_layer,\n    tf.keras.layers.experimental.preprocessing.RandomFlip(\"horizontal\"),\n    #tf.keras.layers.experimental.preprocessing.RandomRotation(0.1),\n    tf.keras.layers.experimental.preprocessing.RandomZoom(0.1),\n    #tf.keras.layers.experimental.preprocessing.RandomContrast(0.1),\n    #tf.keras.layers.experimental.preprocessing.RandomCrop(170,170)  \n  ]\n)","97ff5bff":"# IMG_SIZE = 180\n\n# resize_and_rescale = tf.keras.Sequential([\n#   tf.keras.layers.experimental.preprocessing.Resizing(IMG_SIZE, IMG_SIZE),\n#   tf.keras.layers.experimental.preprocessing.Rescaling(1.\/255)\n# ])\n# result = resize_and_rescale(img_opencv)\n# _ = plt.imshow(result)","c0694f22":"plt.figure(figsize=(10, 10))\nimg_array = tf.keras.preprocessing.image.img_to_array(img_opencv)\nimg_array = tf.expand_dims(img_array,0)\nfor i in range(9):\n  augmented_image = data_augmentation(img_array)\n  ax = plt.subplot(3, 3, i + 1)\n  plt.imshow(augmented_image[0])\n  plt.axis(\"off\")","ed2e1805":"num_classes = 4\n\nmodel = tf.keras.Sequential([\n  normalization_layer,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes)\n])","80a79f2f":"model.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])\n","967079ea":"history = model.fit(\n    train,\n    validation_data=val,\n    epochs= 3,\n    callbacks = callback,\n    shuffle=False\n)\neff_epochs = len(history.history['loss'])","ba1277cd":"acc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = 10\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(eff_epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n                              'color': 'white'})\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n                              'color': 'white'})\nplt.show()","f6bd201e":"model.summary()","7b2b5d63":"results = model.evaluate(test)\nprint(\"test loss, test acc:\", results)","16ea97aa":"list_of_paths = ['..\/input\/brain-tumor-classification-mri\/Testing\/pituitary_tumor\/image(20).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/no_tumor\/image(11).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/meningioma_tumor\/image(120).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/glioma_tumor\/image(16).jpg',\n                '..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y100.JPG']\ntest_tumor(list_of_paths,model)","5e89c384":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","02235231":"print(classification_report(labels_entire, pred_entire, target_names=classes))","74b2f348":"num_classes = 4\n\nmodel2 = tf.keras.Sequential([\n  #data_augmentation,\n  normalization_layer,\n  #tf.keras.layers.Conv2D(32,3,activation='relu'),\n  conv_layer_32,\n  layers.MaxPooling2D(pool_size=(2,2)),\n  conv_layer_32,\n  layers.MaxPooling2D(pool_size=(2,2)),\n  layers.Flatten(),\n  layers.Dense(32, activation='relu'),\n  layers.Dropout(0.25),\n  layers.Dense(num_classes,activation='softmax')\n])","bc54a222":"model2.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","19ded303":"epochs = 50\nhistory = model2.fit(\n  train,\n  validation_data=val,\n  epochs=epochs,\n  callbacks = callback,\n  shuffle=False\n)","1171dd4d":"model2.summary()","c0d09d63":"eff_epochs = len(history.history['loss'])\nacc = history.history['accuracy']\nval_acc = history.history['val_accuracy']\nepochs = 10\n\nloss = history.history['loss']\nval_loss = history.history['val_loss']\n\nepochs_range = range(eff_epochs)\n\nplt.figure(figsize=(8, 8))\nplt.subplot(1, 2, 1)\nplt.plot(epochs_range, acc, label='Training Accuracy')\nplt.plot(epochs_range, val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n                              'color': 'white'})\n\nplt.subplot(1, 2, 2)\nplt.plot(epochs_range, loss, label='Training Loss')\nplt.plot(epochs_range, val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n                              'color': 'white'})\nplt.show()","dbc06ca3":"results = model2.evaluate(test)\nprint(\"test loss, test acc:\", results)","e8b62999":"list_of_paths = ['..\/input\/brain-tumor-classification-mri\/Testing\/pituitary_tumor\/image(20).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/no_tumor\/image(11).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/meningioma_tumor\/image(120).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/glioma_tumor\/image(16).jpg',\n                '..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y100.JPG']\ntest_tumor(list_of_paths,model2)","1db9a974":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model2.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","4d0cb9ea":"print(classification_report(labels_entire, pred_entire, target_names=classes))","562fc148":"# Create the base model from the pre-trained model MobileNet V2\nimage_size = (img_width,img_height)\nIMG_SHAPE = image_size + (3,)\nbase_model = tf.keras.applications.MobileNetV2(input_shape=IMG_SHAPE,\n                                               include_top=False,\n                                               weights='imagenet')\n\nbase_model.trainable = False","60bc2e65":"image_batch, label_batch = next(iter(train))\nfeature_batch = base_model(image_batch)\nprint(feature_batch.shape)","14a574ca":"base_model.summary()","47770718":"global_average_layer = tf.keras.layers.GlobalAveragePooling2D()\nfeature_batch_average = global_average_layer(feature_batch)\nprint(feature_batch_average.shape)","7a1c5521":"prediction_layer = tf.keras.layers.Dense(4)\nprediction_batch = prediction_layer(feature_batch_average)\nprint(prediction_batch.shape)","683a644f":"preprocess_input = tf.keras.applications.mobilenet_v2.preprocess_input","116cc4a2":"help(preprocess_input)","bbda6dee":"inputs = tf.keras.Input(shape=(250, 250, 3))\n#x = data_augmentation(inputs)\nx = preprocess_input(inputs)\nx = base_model(x, training=False)\nx = global_average_layer(x)\nx = tf.keras.layers.Dropout(0.2)(x)\nx = tf.keras.layers.Flatten()(x)\nx = tf.keras.layers.Dense(1280,activation='relu')(x)\noutputs = prediction_layer(x)\nmodel3 = tf.keras.Model(inputs, outputs)","d28f024a":"base_learning_rate = 0.0001\nmodel3.compile(optimizer=tf.keras.optimizers.Adam(lr=base_learning_rate),\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","1294f515":"len(model.trainable_variables)","5bd33c83":"initial_epochs = 10\n\nloss0, accuracy0 = model3.evaluate(val)\nprint(\"initial loss: {:.2f}\".format(loss0))\nprint(\"initial accuracy: {:.2f}\".format(accuracy0))","a85dc989":"history_base = model3.fit(train,\n                         epochs=initial_epochs,\n                         validation_data=val,\n                         shuffle=False\n                        )","2e17fe6b":"model3.summary()","7ae2a77d":"acc = history_base.history['accuracy']\nval_acc = history_base.history['val_accuracy']\n\nloss = history_base.history['loss']\nval_loss = history_base.history['val_loss']\n\nplt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.legend(loc='lower right')\nplt.ylabel('Accuracy')\nplt.ylim([min(plt.ylim()),1])\nplt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n                              'color': 'white'})\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\n\n\nplt.plot(val_loss, label='Validation Loss')\nplt.legend(loc='upper right')\nplt.ylabel('Cross Entropy')\nplt.ylim([0,1.0])\nplt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n                              'color': 'white'})\nplt.xlabel('epoch')\nplt.show()","aa92d80c":"list_of_paths = ['..\/input\/brain-tumor-classification-mri\/Testing\/pituitary_tumor\/image(20).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/no_tumor\/image(11).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/meningioma_tumor\/image(120).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/glioma_tumor\/image(16).jpg',\n                '..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y100.JPG',\n                '..\/input\/brain-mri-images-for-brain-tumor-detection\/no\/14 no.jpg']\ntest_tumor(list_of_paths,model)","993ca648":"result = model3.evaluate(test)\nprint(result)","ecc8eba7":"base_model.trainable = True\n# Let's take a look to see how many layers are in the base model\nprint(\"Number of layers in the base model: \", len(base_model.layers))\n\n# Fine-tune from this layer onwards\nfine_tune_at = 100\n\n#Attempting to fine tune more layers\nmore_layer = 50\n\n\n\n#Freeze all the layers before the `fine_tune_at` layer\nfor layer in base_model.layers[:fine_tune_at]:\n  layer.trainable =  False","f0c73cf9":"model3.compile(loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              optimizer = tf.keras.optimizers.Adam(lr=base_learning_rate\/10),\n              metrics=['accuracy'])","2f75bd5b":"model3.summary()","050cbf5d":"len(model3.trainable_variables)","9822ddd9":"fine_tune_epochs = 10\ntotal_epochs =  initial_epochs + fine_tune_epochs\n\nhistory_fine = model3.fit(train,\n                         epochs=total_epochs,\n                         initial_epoch=history_base.epoch[-1],\n                         validation_data=val)","22a547c9":"acc += history_fine.history['accuracy']\nval_acc += history_fine.history['val_accuracy']\n\nloss += history_fine.history['loss']\nval_loss += history_fine.history['val_loss']","23930dd9":"plt.figure(figsize=(8, 8))\nplt.subplot(2, 1, 1)\nplt.plot(acc, label='Training Accuracy')\nplt.plot(val_acc, label='Validation Accuracy')\nplt.ylim([0.8, 1])\nplt.plot([initial_epochs-1,initial_epochs-1],\n          plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='lower right')\nplt.title('Training and Validation Accuracy',fontdict = {'fontsize': '14',\n                              'color': 'white'})\n\nplt.subplot(2, 1, 2)\nplt.plot(loss, label='Training Loss')\nplt.plot(val_loss, label='Validation Loss')\nplt.ylim([0, 1.0])\nplt.plot([initial_epochs-1,initial_epochs-1],\n         plt.ylim(), label='Start Fine Tuning')\nplt.legend(loc='upper right')\nplt.title('Training and Validation Loss',fontdict = {'fontsize': '14',\n                              'color': 'white'})\nplt.xlabel('epoch')\nplt.show()","472515c5":"loss, accuracy = model3.evaluate(test)\nprint('Test accuracy :', accuracy)","003b7c08":"list_of_paths = ['..\/input\/brain-tumor-classification-mri\/Testing\/pituitary_tumor\/image(20).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/no_tumor\/image(11).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/meningioma_tumor\/image(120).jpg',\n                '..\/input\/brain-tumor-classification-mri\/Testing\/glioma_tumor\/image(16).jpg',\n                '..\/input\/brain-mri-images-for-brain-tumor-detection\/yes\/Y100.JPG']\ntest_tumor(list_of_paths,model)","9c0ae46e":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model3.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","aada1291":"labels_entire.shape","3493cdfb":"pred_entire.shape","f9171b33":"print(classification_report(labels_entire, pred_entire, target_names=classes))","48157d95":"path_data","4ca49a3b":"label_names = os.listdir(path_data)\nlabel_names","93536fcb":"final_csv = csv_builder(path_data,label_names)\nfinal_csv","27c57a56":"final_csv.to_csv('files_path.csv', header=None)","d0eb213b":"path_of_csv = '.\/files_path.csv'","bf011eee":"test_csv = csv_builder(path_test,label_names)\ntest_csv","3a4addf5":"test_csv = test_csv.sample(frac=1)\ntest_csv","430b5b2d":"k = 5","4324358f":"num_classes = 4\n\nmodel = tf.keras.Sequential([\n  normalization_layer,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  conv_layer_32,\n  max_pool,\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dense(num_classes,activation='softmax')\n])\nmodel.compile(\n  optimizer='adam',\n  loss=tf.losses.SparseCategoricalCrossentropy(from_logits=True),\n  metrics=['accuracy'])","3308dab1":"loss,acc,model = cross_validation(k,final_csv,test_csv,img_width,img_height,model = model)","979493b1":"print(loss,acc)","ce12d01e":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","28db04cd":"print(classification_report(labels_entire, pred_entire, target_names=classes))","8bffee21":"num_classes = 4\n\nmodel2 = tf.keras.Sequential([\n  #data_augmentation,\n  normalization_layer,\n  #tf.keras.layers.Conv2D(32,3,activation='relu'),\n  layers.Conv2D(32,(3,3),activation='relu'),\n  layers.MaxPooling2D(),#pool_size=(2,2)),\n  layers.Conv2D(32,(3,3),activation='relu'),\n  layers.MaxPooling2D(),#pool_size=(2,2)),\n  layers.Flatten(),\n  layers.Dense(128, activation='relu'),\n  layers.Dropout(0.25),\n  layers.Dense(num_classes,activation='softmax')\n])\nmodel2.compile(optimizer='adam',\n              loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n              metrics=['accuracy'])","8cc32a1f":"loss,acc,model2 = cross_validation(k,final_csv,test_csv,img_width,img_height,model = model2)\nprint(loss,acc)","d418bd58":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model2.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","60e274e8":"print(classification_report(labels_entire, pred_entire, target_names=classes))","6ffd9fc8":"model3 = tf.keras.Sequential([normalization_layer,\n                                  conv_layer_32,\n                                  max_pool,\n                                  #layers.MaxPooling2D(pool_size=(2,2)),\n                                  conv_layer_32,\n                                  max_pool,\n                                  #layers.MaxPooling2D(pool_size=(2,2)),\n                                  layers.Flatten(),\n                                  layers.Dense(128, activation='relu'),\n                                  #layers.Dropout(0.25),\n                                  layers.Dense(num_classes,activation='softmax')\n                                 ])\nmodel3.compile(optimizer='adam',\n                   loss=tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True),\n                   metrics=['accuracy'])","4ebabc66":"loss,acc,model3 = cross_validation(k,final_csv,test_csv,img_width,img_height,model3)\nprint(loss,acc)","07e2c182":"labels_entire = []\npred_entire = []\nfor image_batch,label_batch in test.as_numpy_iterator():\n    prediction = model3.predict_on_batch(image_batch).flatten()\n\n    # Apply a sigmoid since our model returns logits\n    predictions = tf.nn.sigmoid(prediction).numpy()\n\n    n = 0\n    predict = []\n    while n<=(predictions.shape[0]-4):\n        pred = np.argmax(predictions[n:n+4]) #Returns the index of the largest element in the selected subarray\n        n+=4\n        pred_entire.append(pred)\n    for el in label_batch:\n        labels_entire.append(el)\npred_entire = np.array(pred_entire)\nlabels_entire = np.array(labels_entire)\nprint(pred_entire)\nprint(labels_entire)","840409ae":"print(classification_report(labels_entire, pred_entire, target_names=classes))","23259cff":"# First Model\n<a id='first_model'><\/a>","f15f5f9d":"# Helper Functions\n<a id='helper'><\/a>\n<a id ='compare'><\/a>","6b6ce202":"## Cross Validation on Third Model","df6c6cc6":"## Cross Validation on [Second Model](#second_model)","e6ea50a8":"Link to the [Dataset being used](https:\/\/www.kaggle.com\/sartajbhuvaji\/brain-tumor-classification-mri)<br>\nReference Tutorial for general code: [Image Classification Tutorial](https:\/\/www.tensorflow.org\/tutorials\/images\/classification)","90179e45":"### Checking effects of the data augmentation","bdd11705":"## Fine Tuning the model\n<a id='fine_tune'><\/a>","aac12d13":"# Using k-fold cross validation","5d412f63":"### References for model:<br>\nModel 2: Obtained from a [Kaggle notebook](https:\/\/www.kaggle.com\/chityeaung\/brain-tumor-classification) by [chityeaung](https:\/\/www.kaggle.com\/chityeaung)<br>\nModel 1 and 3 taken from Tensorflow tutorials:<br>\n[Image Classification Tutorial](https:\/\/www.tensorflow.org\/tutorials\/images\/classification)<br>\n[Transfer Learning Tutorial](https:\/\/www.tensorflow.org\/tutorials\/images\/transfer_learning)","28d177d8":"Changing the number of trainable layers doesn't affect the test accuracy too much. ","10eb28eb":"### Defining number of folds","20053623":"prediction_label_comparison is defined [here](#compare)","86cbfc6f":"### Now this csv file can be used to create a kfold split in the training data","83649428":"#### Image of a brain with tumor","4d1a5c14":"# Third Model\n### Using a pretrained model: MobileNetV2\n<a id = 'third_model'><\/a>","d3f7aa8e":"Adding a data augmentation layer to add more images to the training data by simply modifying the existing images in ways such as flipping them or making similar random transformations to the training data.","21149b9c":"### Creating Testing Validation and Testing Sets","351cf20e":"### Reference article for the k-fold cross validation: [Link](https:\/\/medium.com\/the-owl\/k-fold-cross-validation-in-keras-3ec4a3a00538)\n### Building a .csv file for the images along with their labels: [Reference](https:\/\/datascience.stackexchange.com\/questions\/49094\/how-to-transform-a-folder-of-images-into-csv-file)","63bff531":"# Model Building","ca11118c":"# Preparing dataset","de1a5138":"# Importing Libraries","51283060":"### Functions csv_builder() and cross_validation() have been defined in the [helper functions](#helper)","38e19826":"## Cross validation on the [first model](#first_model)","e62afd6d":"#### Image of a brain with no tumor","aa13d5f6":"# Second Model\n<a id = 'second_model'><\/a>"}}