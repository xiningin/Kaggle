{"cell_type":{"d38c6443":"code","321e1eb0":"code","323ffde7":"code","f285337c":"code","357f13bd":"code","3963ecd2":"code","14a05b53":"code","bfdbcafc":"code","7af7aa43":"code","6f2fe87d":"code","58339423":"code","dc122dd6":"code","e5ecdde6":"code","7f91eafb":"code","58fabed1":"code","f147431b":"code","44fbb65c":"code","50315a15":"code","7e1be2c1":"code","2d9e9ac1":"code","9cae80c8":"code","bc40195b":"code","cb9f3bf7":"markdown","fec19b80":"markdown","e62cabab":"markdown","0f064e5e":"markdown","54467ced":"markdown","19db4859":"markdown","2c51c561":"markdown","32175984":"markdown","0813e5fc":"markdown","e538d90d":"markdown","cceeaa8e":"markdown","ceccb605":"markdown","bfa4d5d2":"markdown","978c62a8":"markdown","784e9689":"markdown","06d768d4":"markdown","83d94620":"markdown","7ad4a586":"markdown","e2c4cf2f":"markdown","604a3ec4":"markdown","3dc0d1ab":"markdown","4c220f09":"markdown","81c9271a":"markdown","63d63e41":"markdown","8ca49e9d":"markdown","672c21a2":"markdown"},"source":{"d38c6443":"# importando os principais m\u00f3dulos que usaremos ao longo da aula\n\nimport numpy as np\nimport pandas as pd\nimport matplotlib\nimport matplotlib.pyplot as plt\n\nimport sklearn.datasets\nimport sklearn.preprocessing\nimport sklearn.pipeline\nimport sklearn.model_selection\nimport sklearn.metrics\n\nimport sklearn.linear_model\nimport sklearn.tree\nimport sklearn.ensemble\nimport sklearn.neural_network\nimport sklearn.svm\nimport sklearn.neighbors\n\nfrom tensorflow import keras\n\nimport optuna","321e1eb0":"print(np.__version__)\nprint(pd.__version__)\nprint(matplotlib.__version__)\nprint(sklearn.__version__)\nprint(keras.__version__)\nprint(optuna.__version__)","323ffde7":"from IPython.display import YouTubeVideo\nYouTubeVideo(\"w0NDlRuTkVw\")","f285337c":"digits = sklearn.datasets.load_digits()\n\nX, y = digits.data, digits.target\n\n#normalizando os pixels\nX = X\/256\n\nprint(digits.DESCR)","357f13bd":"X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, \n                                                                            test_size=0.2, \n                                                                            random_state=0)","3963ecd2":"m = sklearn.linear_model.LogisticRegression(penalty='none', max_iter = 200)","14a05b53":"results = sklearn.model_selection.cross_val_score(m, X_train, y_train, scoring='accuracy')\nresults","bfdbcafc":"results.mean()","7af7aa43":"# especificando modelos \n\nmodelos = [\n    \n    sklearn.linear_model.LogisticRegression(),\n    sklearn.tree.DecisionTreeClassifier(),\n    sklearn.ensemble.RandomForestClassifier(),\n    sklearn.ensemble.GradientBoostingClassifier(),\n    sklearn.neighbors.KNeighborsClassifier(),\n    sklearn.svm.LinearSVC(),\n    sklearn.svm.SVC()  \n    \n]\n\n#lista para guardar resultados\nresults = [0]*len(modelos)\n\nprint('Modelo: m\u00e9dia, desvio-padr\u00e3o\\n-------------------')\n\nfor i in range(len(modelos)):\n    \n    # efetuando a valida\u00e7\u00e3o cruzada!\n    results[i] = sklearn.model_selection.cross_val_score(modelos[i], \n                                                         X_train, y_train, \n                                                         cv=10, \n                                                         scoring='accuracy',\n                                                         n_jobs=-1)\n    \n    # imprimindo resultados\n    print(f'{modelos[i].__class__.__name__}: {results[i].mean():.3}, {results[i].std():.3}')\n\n# plotando resultados\nfig, ax = plt.subplots()\nax.boxplot(results)\n\n# formatando gr\u00e1fico\nax.set_xticklabels([modelos[i].__class__.__name__ for i in range(len(modelos))], \n                   rotation = 45, ha=\"right\")\nax.set_ylabel(\"Acur\u00e1cia\")\nax.set_title('Compara\u00e7\u00e3o entre modelos de classifica\u00e7\u00e3o');","6f2fe87d":"print('Acur\u00e1cias\\n--------------')\n\nfor m in modelos:\n    m.fit(X_train, y_train)\n    print(f'{m.__class__.__name__}: {sklearn.metrics.accuracy_score(y_test, m.predict(X_test)):.3}')","58339423":"# adaptado de https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_learning_curve.html\n\n# especificando modelos \n\nmodelos = [\n    \n    sklearn.linear_model.LogisticRegression(),\n    sklearn.tree.DecisionTreeClassifier(),\n    sklearn.ensemble.RandomForestClassifier(),\n    sklearn.ensemble.GradientBoostingClassifier(),\n    sklearn.neighbors.KNeighborsClassifier(),\n    sklearn.svm.LinearSVC(),\n    sklearn.svm.SVC()  \n    \n]\n\nfig, ax = plt.subplots(3,3,figsize=(16,10))\n\nfor i in range(len(modelos)):\n    \n    # calculando a curva de aprendizado!\n    train_sizes, train_scores, test_scores = sklearn.model_selection.learning_curve(modelos[i], \n                                                                                    X_train, y_train, \n                                                                                    cv=5, \n                                                                                    scoring='accuracy',\n                                                                                    n_jobs=-1)\n    \n    # m\u00e9dias e desvios-padr\u00e3o dos resultados da valida\u00e7\u00e3o cruzada (para cada ponto da curva)\n    train_scores_mean = np.mean(train_scores, axis=1)\n    train_scores_std = np.std(train_scores, axis=1)\n    test_scores_mean = np.mean(test_scores, axis=1)\n    test_scores_std = np.std(test_scores, axis=1)\n    \n    # plotando curva correspondente ao treino\n    ax.ravel()[i].plot(train_sizes, train_scores_mean, label=\"Treino\")\n    ax.ravel()[i].fill_between(train_sizes, train_scores_mean - train_scores_std,\n                               train_scores_mean + train_scores_std, alpha=0.1)\n    \n    # plotando curva correspondente ao teste\n    ax.ravel()[i].plot(train_sizes, test_scores_mean, label=\"Valida\u00e7\u00e3o cruzada\")\n    ax.ravel()[i].fill_between(train_sizes, test_scores_mean - test_scores_std,\n                               test_scores_mean + test_scores_std, alpha=0.1)\n    \n    # formatando gr\u00e1fico\n    ax.ravel()[i].set_title(modelos[i].__class__.__name__)\n    ax.ravel()[i].set_ylabel('Acur\u00e1cia')\n    ax.ravel()[i].set_xlabel('N\u00famero de amostras de treino')\n    ax.ravel()[i].legend(loc=\"best\")\n    \nax.ravel()[-2].axis('off')\nax.ravel()[-1].axis('off')\n\nfig.tight_layout();","dc122dd6":"# adaptado de https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_validation_curve.html\n\n# definindo os valores de par\u00e2metros a serem testados\nparam_range = [0.5, 1, 2.5, 5, 10, 20, 30, 50]\n\n# definindo o modelo\nm = sklearn.linear_model.LogisticRegression(max_iter=200)\n\n# calculando a curva de valida\u00e7\u00e3o!\ntrain_scores, test_scores = sklearn.model_selection.validation_curve(m, X_train, y_train, \n                                                                     param_name=\"C\", \n                                                                     param_range=param_range,\n                                                                     scoring=\"accuracy\", \n                                                                     n_jobs=-1)\n\n# m\u00e9dias e desvios-padr\u00e3o dos resultados da valida\u00e7\u00e3o cruzada (para cada ponto da curva)\ntrain_scores_mean = np.mean(train_scores, axis=1)\ntrain_scores_std = np.std(train_scores, axis=1)\ntest_scores_mean = np.mean(test_scores, axis=1)\ntest_scores_std = np.std(test_scores, axis=1)\n\n# plotando curva correspondente ao treino\nplt.plot(param_range, train_scores_mean, label=\"Treino\")\nplt.fill_between(param_range, train_scores_mean - train_scores_std,\n                 train_scores_mean + train_scores_std, alpha=0.1)\n\n# plotando curva correspondente ao teste\nplt.plot(param_range, test_scores_mean, label=\"Valida\u00e7\u00e3o cruzada\")\nplt.fill_between(param_range, test_scores_mean - test_scores_std,\n                 test_scores_mean + test_scores_std, alpha=0.1)\n\n# formatando gr\u00e1fico\nplt.title(\"Curva de Valida\u00e7\u00e3o - Regress\u00e3o Log\u00edstica\")\nplt.xlabel('C')\nplt.ylabel(\"Acur\u00e1cia\")\nplt.legend(loc=\"best\");","e5ecdde6":"dataset = sklearn.datasets.load_iris()\n\nX, y = dataset.data, dataset.target\n\nprint(dataset.DESCR)","7f91eafb":"X_train, X_test, y_train, y_test = sklearn.model_selection.train_test_split(X, y, \n                                                                            test_size=0.1, \n                                                                            random_state=0)","58fabed1":"# fun\u00e7\u00e3o objetivo para otimiza\u00e7\u00e3o de hiperpar\u00e2metros\ndef objetivo(trial):\n\n    # colocaremos dois modelos pra brigar: MLP e RF\n    classifier_name = trial.suggest_categorical(\"classifier\", [\"MLP\", \"RandomForest\"])\n    \n    if classifier_name == 'MLP':\n        \n        # hiperpar\u00e2metros de busca para o MLP\n        mlp_hidden_size = trial.suggest_int(\"mlp_hidden_size\", 2,400)\n        mlp_lr = trial.suggest_float(\"mlp_lr\", 1e-3, 2e-1, log = True)\n        mlp_momentum = trial.suggest_float(\"mlp_momentum\", 0.8, 1, log = True)\n        mlp_batch_size = trial.suggest_int(\"mlp_batch_size\", 8, 32)\n        \n        # montando a rede MLP\n        def m_keras():\n\n            m_keras = keras.models.Sequential()\n            m_keras.add(keras.layers.Dense(mlp_hidden_size, \n                                           activation = 'relu', \n                                           input_dim = X_train.shape[1]))\n            m_keras.add(keras.layers.Dense(dataset.target_names.shape[0], \n                                           activation = 'softmax'))\n            sgd = keras.optimizers.SGD(lr = mlp_lr, \n                                       momentum = mlp_momentum, \n                                       nesterov = True)\n            m_keras.compile(optimizer=sgd,\n                            loss='categorical_crossentropy',\n                            metrics=['accuracy'])\n            \n            return m_keras\n        \n        # modelo MLP\n        \n        # wrapper para adequar o modelo keras \u00e0 interface do sklearn\n        mlp = keras.wrappers.scikit_learn.KerasClassifier(m_keras, \n                                                          epochs = 50, \n                                                          batch_size = mlp_batch_size)\n        \n        # montando uma pipeline com pr\u00e9-processamento+modelo\n        m = sklearn.pipeline.Pipeline([('scaler', sklearn.preprocessing.StandardScaler()), \n                                       ('mlp', mlp)])\n        \n    else:\n\n        # hiperpar\u00e2metros de busca para o RF\n        rf_min_samples_leaf = trial.suggest_int(\"rf_min_samples_leaf\", 1, 10)\n        rf_max_depth = trial.suggest_int(\"rf_max_depth\", 2, 32, log = True)\n        rf_n_estimators = trial.suggest_int(\"rf_n_estimators\", 10,100)\n        \n        # modelo RF\n        m = sklearn.ensemble.RandomForestClassifier(max_depth = rf_max_depth, \n                                                    min_samples_leaf = rf_min_samples_leaf, \n                                                    n_estimators = rf_n_estimators)\n\n    # retornando acur\u00e1cia\n    acuracias = sklearn.model_selection.cross_val_score(m, X_train, y_train, n_jobs = -1, cv = 3)\n    acuracia = acuracias.mean()\n    return acuracia","f147431b":"study = optuna.create_study(direction=\"maximize\")\nstudy.optimize(objetivo, n_trials = 100)","44fbb65c":"study.best_params","50315a15":"if study.best_params['classifier'] == 'MLP':\n\n    def m_keras():\n\n        m_keras = keras.models.Sequential()\n        m_keras.add(keras.layers.Dense(study.best_params['mlp_hidden_size'], \n                                       activation = 'relu', input_dim=X_train.shape[1]))\n        m_keras.add(keras.layers.Dense(dataset.target_names.shape[0], \n                                       activation = 'softmax'))\n        sgd = keras.optimizers.SGD(lr = study.best_params['mlp_lr'], \n                                   momentum = study.best_params['mlp_momentum'], \n                                   nesterov = True)\n        m_keras.compile(optimizer = sgd,\n                  loss='categorical_crossentropy',\n                  metrics=['accuracy'])\n\n        return m_keras\n\n    mlp = keras.wrappers.scikit_learn.KerasClassifier(m_keras, \n                                                      epochs = 50, verbose = 0,\n                                                      batch_size = study.best_params['mlp_batch_size'])\n\n    m = sklearn.pipeline.Pipeline([('scaler', sklearn.preprocessing.StandardScaler()), \n                                   ('mlp', mlp)])\n\nelse:\n    \n    m = sklearn.ensemble.RandomForestClassifier(max_depth = study.best_params['rf_max_depth'], \n                                                min_samples_leaf = study.best_params['rf_min_samples_leaf'], \n                                                n_estimators = study.best_params['rf_n_estimators'])\n\nprint(f'Acur\u00e1cias da valida\u00e7\u00e3o cruzada: {sklearn.model_selection.cross_val_score(m, X_train, y_train)}')\n\nm.fit(X_train, y_train)\nprint(f'Acur\u00e1cia do teste: {sklearn.metrics.accuracy_score(y_test, m.predict(X_test)):.3}')","7e1be2c1":"optuna.visualization.plot_optimization_history(study)","2d9e9ac1":"optuna.visualization.plot_slice(study)","9cae80c8":"optuna.visualization.plot_contour(study, params=['mlp_lr','mlp_hidden_size','mlp_batch_size'])","bc40195b":"optuna.visualization.plot_parallel_coordinate(study)","cb9f3bf7":"**M\u00e3o na massa 2!**\n\n* Automatize alguma das explora\u00e7\u00f5es de hiperpar\u00e2metros que voc\u00ea efetuou nas aulas passadas (florestas aleat\u00f3rias da [Aula 1](https:\/\/www.kaggle.com\/afrniomelo\/epv-peq-aula-1-regress-o) ou redes neurais da [Aula 3](https:\/\/www.kaggle.com\/afrniomelo\/epv-peq-aula-3-classifica-o)).","fec19b80":"A valida\u00e7\u00e3o $k$-fold foi efetuada com $k=5$, o default da fun\u00e7\u00e3o `cross_val_score`, o que pode ser modificado por meio do fornecimento de um argumento adicional `cv`.\n\nAs acur\u00e1cias variam bastante de itera\u00e7\u00e3o para itera\u00e7\u00e3o. Isso indica que a escolha do conjunto de valida\u00e7\u00e3o, nesse caso, influencia o resultado. Para uma m\u00e9trica global menos dependente dessa escolha, podemos tirar a m\u00e9dia das $k$ itera\u00e7\u00f5es:","e62cabab":"* A curva de aprendizado possibilita que verifiquemos os graus de sobreajuste dos modelos. Os modelos baseados em \u00e1rvore (`DecisionTree`, `RandomForest` e `GradientBoosting`), por exemplo, sobreajustam bastante, ainda que atinjam resultados bons (principalmente os dois \u00faltimos). J\u00e1 a regress\u00e3o log\u00edstica apresenta baix\u00edssimo sobreajuste.\n\n* Um plat\u00f4 ao final da curva indica que o modelo n\u00e3o se beneficiaria muito da adi\u00e7\u00e3o de dados no conjunto de treinamento (ao contr\u00e1rio de modelos que apresentem tend\u00eancia mais crescente).","0f064e5e":"A seguir, montamos o modelo escolhido e o avaliamos nos dados de teste:","54467ced":"## Escola Piloto Virtual - PEQ\/COPPE\/UFRJ\n## Data Science e Machine Learning na Pr\u00e1tica - Introdu\u00e7\u00e3o e Aplica\u00e7\u00f5es na Ind\u00fastria de Processos\n\nEste notebook \u00e9 referente \u00e0 aula 5 do curso e trata de tr\u00eas t\u00e9cnicas importantes que n\u00e3o foram utilizadas nos estudos de caso das aulas anteriores:\n\n* [Valida\u00e7\u00e3o cruzada](https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html);\n* [Curvas de aprendizado](https:\/\/en.wikipedia.org\/wiki\/Learning_curve_(machine_learning));\n* [Sintoniza\u00e7\u00e3o de hiperpar\u00e2metros](https:\/\/en.wikipedia.org\/wiki\/Hyperparameter_optimization).","19db4859":"Separando em treino\/teste:","2c51c561":"**M\u00e3o na massa 1!**\n\n* Escolha um problema de regress\u00e3o de sua prefer\u00eancia (voc\u00ea pode procurar no [Kaggle](https:\/\/www.kaggle.com\/datasets), [sklearn.datasets](https:\/\/scikit-learn.org\/stable\/datasets\/index.html), [UCI Repository](https:\/\/archive.ics.uci.edu\/ml\/index.php), usar algum relacionado a seu trabalho, etc.) e reproduza os procedimentos apresentados acima:\n    * Compara\u00e7\u00e3o em diagrama de caixa entre v\u00e1rios modelos, utilizando valida\u00e7\u00e3o cruzada;\n    * Tra\u00e7ado de curvas de aprendizado para os v\u00e1rios modelos;\n    * Tra\u00e7ado de curvas de valida\u00e7\u00e3o para hiperpar\u00e2metro(s) selecionado(s).\n\nDica: por conta da natureza do problema (regress\u00e3o e n\u00e3o mais classifica\u00e7\u00e3o), voc\u00ea precisar\u00e1 utilizar outros modelos e m\u00e9tricas de avalia\u00e7\u00e3o.","32175984":"Pronto!!\n\nNa otimiza\u00e7\u00e3o efetuada acima, o algoritmo avaliou v\u00e1rias combina\u00e7\u00f5es de hiperpar\u00e2metros (sugeridas pelo objeto `trial`) e guardou a melhor no atributo `best_params`:","0813e5fc":"# Valida\u00e7\u00e3o cruzada\n\nA [valida\u00e7\u00e3o cruzada](https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html) \u00e9 uma estrat\u00e9gia para atenuar o efeito da arbitrariedade da escolha do conjunto de valida\u00e7\u00e3o. A ideia b\u00e1sica \u00e9 efetuar v\u00e1rias rodadas de treinamento de modo que todas as amostras sejam utilizadas tanto para treinamento quanto para valida\u00e7\u00e3o. \u00c9 particularmente \u00fatil quando o conjunto de dados \u00e9 pequeno, j\u00e1 que reduz o ru\u00eddo de amostragem.\n\nExistem diversos tipos de valida\u00e7\u00e3o cruzada. Aqui ser\u00e1 descrita a valida\u00e7\u00e3o $k$-fold, em que:\n\n1. divide-se aleatoriamente o conjunto de treinamento em $k$ conjuntos mutuamente exclusivos e do mesmo tamanho;\n2. realizam-se $k$ treinamentos, cada um deles utilizando para valida\u00e7\u00e3o um dos $k$ conjuntos definidos na etapa 1.\n\nA figura a seguir ilustra bem a valida\u00e7\u00e3o $k$-fold:\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/b\/b5\/K-fold_cross_validation_EN.svg\" width=\"600\" height=\"600\"\/>\n\nA valida\u00e7\u00e3o $k$-fold s\u00f3 \u00e9 aplic\u00e1vel a conjuntos compostos por amostras [independentes e identicamente distribu\u00eddas](https:\/\/en.wikipedia.org\/wiki\/Independent_and_identically_distributed_random_variables).\n\nLembrando que \u00e9 boa pr\u00e1tica manter um conjunto de teste separado para que seja usado apenas ao final da modelagem (ou seja, ap\u00f3s todas as eventuais rodadas de valida\u00e7\u00e3o cruzada), como uma \"prova final\".\n\nIlustraremos a valida\u00e7\u00e3o cruzada utilizando o conjunto de dados `digits`, dispon\u00edvel nativamente no m\u00f3dulo `sklearn.datasets`. \u00c9 uma esp\u00e9cie de vers\u00e3o reduzida do [MNIST](https:\/\/en.wikipedia.org\/wiki\/MNIST_database).","e538d90d":"Os dados `X_train` e `y_train` ser\u00e3o usados para efetuar a valida\u00e7\u00e3o cruzada, enquanto `X_test` e `y_test` s\u00e3o reservados para um teste final.\n\nNa pr\u00f3xima c\u00e9lula, instanciaremos um modelo simples conhecido como [regress\u00e3o log\u00edstica](https:\/\/en.wikipedia.org\/wiki\/Logistic_regression). Apesar do nome enganoso, o modelo serve para problemas de *classifica\u00e7\u00e3o*, n\u00e3o de regress\u00e3o. \u00c9 equivalente a uma rede neural sem camadas ocultas composta de um \u00fanico neur\u00f4nio com fun\u00e7\u00e3o de ativa\u00e7\u00e3o log\u00edstica na camada de sa\u00edda.","cceeaa8e":"* O argumento da fun\u00e7\u00e3o objetivo deve ser um objeto da classe [Trial](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.trial.Trial.html#optuna.trial.Trial), respons\u00e1vel por fornecer sugest\u00f5es de par\u00e2metros, dentre outras tarefas.\n* Ao longo da fun\u00e7\u00e3o objetivo, o objeto `trial` pode fornecer sugest\u00f5es de par\u00e2metros por meio de qualquer um dos seguintes m\u00e9todos:\n    * [suggest_categorical()](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.trial.Trial.html#optuna.trial.Trial.suggest_categorical);\n    * [suggest_discrete_uniform()](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.trial.Trial.html#optuna.trial.Trial.suggest_discrete_uniform);\n    * [suggest_float()](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.trial.Trial.html#optuna.trial.Trial.suggest_float);\n    * [suggest_int()](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.trial.Trial.html#optuna.trial.Trial.suggest_int);\n    * [suggest_loguniform()](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.trial.Trial.html#optuna.trial.Trial.suggest_loguniform);\n    * [suggest_uniform()](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.trial.Trial.html#optuna.trial.Trial.suggest_uniform).\n* Para tornar poss\u00edvel a utiliza\u00e7\u00e3o dos recursos e estrutura de modelagem do `scikit-learn` tamb\u00e9m com a rede MLP, foi utilizado um [wrapper do Keras para o scikit-learn](https:\/\/www.tensorflow.org\/api_docs\/python\/tf\/keras\/wrappers\/scikit_learn).\n* A classe [Pipeline](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.pipeline.Pipeline.html) foi usada para definir um estimador composto constitu\u00eddo de duas etapas (`scaler`, para efetuar a normaliza\u00e7\u00e3o, e `mlp`, com o modelo em si). Pipelines s\u00e3o \u00fateis porque possibilitam a aplica\u00e7\u00e3o da valida\u00e7\u00e3o cruzada nas diferentes etapas de maneira consistente, evitando o [vazamento de informa\u00e7\u00e3o](https:\/\/en.wikipedia.org\/wiki\/Leakage_(machine_learning)) dos dados de treino para os dados de valida\u00e7\u00e3o a cada itera\u00e7\u00e3o $k$.\n* A fun\u00e7\u00e3o acima n\u00e3o foi elaborada de forma rigorosa, com pondera\u00e7\u00f5es cuidadosas sobre as melhores escolhas para as faixas dos hiperpar\u00e2metros, etc. \u00c9 apenas um exemplo simples para entendermos a mec\u00e2nica da coisa.\n\nAp\u00f3s a defini\u00e7\u00e3o da fun\u00e7\u00e3o objetivo, devemos criar um objeto da classe [Study](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.study.Study.html#optuna.study.Study) a partir da fun\u00e7\u00e3o [creat_study](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.create_study.html) e fornecer a fun\u00e7\u00e3o objetivo ao m\u00e9todo [optimize](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/generated\/optuna.study.Study.html#optuna.study.Study.optimize) para efetuar a otimiza\u00e7\u00e3o:","ceccb605":"Nas suas aplica\u00e7\u00f5es da vida real, as visualiza\u00e7\u00f5es podem indicar quais hiperpar\u00e2metros s\u00e3o realmente relevantes e quais faixas s\u00e3o mais interessantes de investigar, possibilitando que voc\u00ea reformule a fun\u00e7\u00e3o objetivo e rode a otimiza\u00e7\u00e3o novamente, refinando a busca.","bfa4d5d2":"* Lembre-se de que o hiperpar\u00e2metro `C` indica o inverso da for\u00e7a da regulariza\u00e7\u00e3o. Portanto, quanto maior o valor de `C`, menos regularizado \u00e9 o modelo. A figura acima indica que os resultados melhoram conforme se aumenta `C`. Ao analis\u00e1-la, uma analista chegaria \u00e0 conclus\u00e3o de que \u00e9 melhor n\u00e3o aplicar regulariza\u00e7\u00e3o e especificaria o hiperpar\u00e2metro `penalty = 'none'`. \n\n* Como as curvas s\u00e3o pr\u00f3ximas em toda a extens\u00e3o do gr\u00e1fico, podemos concluir que o grau de sobreajuste n\u00e3o \u00e9 significativo (por isso a regulariza\u00e7\u00e3o n\u00e3o ajuda, j\u00e1 que ela \u00e9 uma estrat\u00e9gia justamente para diminuir sobreajuste).\n\n* Para baixos valores de `C`, tanto as m\u00e9tricas de treino quanto de valida\u00e7\u00e3o t\u00eam valores baixos, o que caracteriza *subajuste*. \n\n* Tome cuidado: quando h\u00e1 mais de um hiperpar\u00e2metro a ser ajustado, a an\u00e1lise do efeito de apenas um deles pode ser enganosa, j\u00e1 que a rela\u00e7\u00e3o expressa em uma curva de valida\u00e7\u00e3o pode ser completamente diferente para outras combina\u00e7\u00f5es dos demais hiperpar\u00e2metros. De qualquer forma, trata-se de uma ferramenta \u00fatil para verificar faixas hiperparam\u00e9tricas em que possa ocorrer subajuste e sobreajuste.","978c62a8":"Separando em treino\/teste:","784e9689":"# Curvas de aprendizado\n\n[Curvas de aprendizado](https:\/\/en.wikipedia.org\/wiki\/Learning_curve_(machine_learning)) exibem a rela\u00e7\u00e3o entre o desempenho de um modelo e o n\u00famero de amostras do conjunto de treinamento.\n\nAbaixo utilizamos a fun\u00e7\u00e3o [learning_curve](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.learning_curve.html) para plotar as curvas de aprendizado dos modelos analisados na se\u00e7\u00e3o anterior. Cada ponto em uma curva resulta de um procedimento de valida\u00e7\u00e3o cruzada.","06d768d4":"## Sintoniza\u00e7\u00e3o autom\u00e1tica\n\nPara demonstrar a sintoniza\u00e7\u00e3o autom\u00e1tica de hiperpar\u00e2metros, utilizaremos o [conjunto de dados Iris de Fisher](https:\/\/pt.wikipedia.org\/wiki\/Conjunto_de_dados_flor_Iris) (j\u00e1 conhecido de um exerc\u00edcio da [Aula 2](https:\/\/www.kaggle.com\/afrniomelo\/epv-peq-aula-2-detec-o-de-falhas)):","83d94620":"Belo resultado!\n\nA `Optuna` fornece v\u00e1rios m\u00e9todos de visualiza\u00e7\u00e3o dos resultados da otimiza\u00e7\u00e3o por meio do m\u00f3dulo [optuna.visualization](https:\/\/optuna.readthedocs.io\/en\/stable\/reference\/visualization\/index.html):","7ad4a586":"Para efetuar a sintoniza\u00e7\u00e3o, \u00e9 comum que se utilize uma das classes do m\u00f3dulo [sklearn.model_selection](https:\/\/scikit-learn.org\/stable\/modules\/classes.html#module-sklearn.model_selection) para otimiza\u00e7\u00e3o de hiperpar\u00e2metros: [GridSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.GridSearchCV.html) ou [RandomizedSearchCV](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.RandomizedSearchCV.html). A primeira efetua uma busca exaustiva ao longo de todas as combina\u00e7\u00f5es de poss\u00edveis hiperpar\u00e2metros especificados pelo usu\u00e1rio. A segunda \u00e9 parecida, por\u00e9m a busca \u00e9 feita com apenas algumas combina\u00e7\u00f5es selecionadas aleatoriamente. Ambas utilizam valida\u00e7\u00e3o cruzada para an\u00e1lise de desempenho (por isso `CV` ao final do nome).\n\nAs duas classes descritas s\u00e3o \u00fateis, mas n\u00e3o fornecem uma estrat\u00e9gia inteligente de busca: simplesmente avaliam algumas combina\u00e7\u00f5es e indicam qual forneceu o melhor resultado.\n\nNesta aula, utilizaremos a biblioteca [Optuna](https:\/\/optuna.org\/), que implementa algoritmos de [otimiza\u00e7\u00e3o bayesiana](https:\/\/en.wikipedia.org\/wiki\/Bayesian_optimization) para estrat\u00e9gias inteligentes e eficientes de explora\u00e7\u00e3o do espa\u00e7o de busca. Na otimiza\u00e7\u00e3o bayesiana, constr\u00f3i-se um modelo de probabilidades para a fun\u00e7\u00e3o objetivo e esse modelo \u00e9 usado para estimar as combina\u00e7\u00f5es de hiperpar\u00e2metros mais promissoras. Para detalhes, cheque [AKIBA *et al.* (2019)](https:\/\/arxiv.org\/abs\/1907.10902).\n\nPara utilizar a `Optuna`, o primeiro passo \u00e9 definir uma fun\u00e7\u00e3o objetivo que efetue o treinamento e retorne uma medida de desempenho a ser maximizada. N\u00e3o necessariamente o treinamento precisa ficar restrito a um \u00fanico modelo: podemos avaliar v\u00e1rios modelos, inclusive de bibliotecas diferentes. \n\nNa fun\u00e7\u00e3o objetivo abaixo, dois modelos s\u00e3o avaliados em uma mesma otimiza\u00e7\u00e3o: florestas aleat\u00f3rias do `scikit-learn` e redes neurais MLP do `keras`.","e2c4cf2f":"Considerando o treinamento com a a totalidade do conjunto `X_train, y_train` e usando apenas o conjunto de teste para avalia\u00e7\u00e3o, o modelo `SVC` se destaca ainda mais.\n\nEm todos os modelos, os hiperpar\u00e2metros utilizados foram os default especificados pelo `scikit-learn`. Mas essa compara\u00e7\u00e3o n\u00e3o \u00e9 totalmente justa: sabemos, por exemplo, que a regress\u00e3o log\u00edstica sem regulariza\u00e7\u00e3o tem resultado melhor neste caso do que o default (com regulariza\u00e7\u00e3o $L_2$).\n\nPara investigar mais a fundo as diferen\u00e7as entre os modelos, \u00e9 \u00fatil analisar como os seguintes efeitos afetam os desempenhos:\n\n* o tamanho do conjunto de treinamento; \n* as diversas combina\u00e7\u00f5es de hiperpar\u00e2metros.\n\nEsses ser\u00e3o os temas das duas pr\u00f3ximas se\u00e7\u00f5es.","604a3ec4":"# Sintoniza\u00e7\u00e3o de hiperpar\u00e2metros\n\n[Sintoniza\u00e7\u00e3o de hiperpar\u00e2metros](https:\/\/en.wikipedia.org\/wiki\/Hyperparameter_optimization) \u00e9 o procedimento de ajustar os hiperpar\u00e2metros de um modelo de modo a maximizar sua capacidade de generaliza\u00e7\u00e3o.\n\nNas \u00faltimas aulas efetuamos alguns exerc\u00edcios de sintoniza\u00e7\u00e3o manual. Nessa estrat\u00e9gia, n\u00f3s, seres humanos, avaliamos por tentativa e erro algumas combina\u00e7\u00f5es de hiperpar\u00e2metros que nossas intui\u00e7\u00f5es indicam ser razo\u00e1veis. \u00c9 uma estrat\u00e9gia simples, mas muito usada na pr\u00e1tica, j\u00e1 que a intui\u00e7\u00e3o \u00e9 uma importante caracter\u00edstica humana que as m\u00e1quinas (ainda) n\u00e3o possuem.\n\nUma maneira simples de incrementar essa intui\u00e7\u00e3o \u00e9 visualizando algumas *curvas de valida\u00e7\u00e3o*.\n\n## Curvas de valida\u00e7\u00e3o\n\n[Curvas de valida\u00e7\u00e3o](https:\/\/scikit-learn.org\/stable\/auto_examples\/model_selection\/plot_validation_curve.html) exibem a rela\u00e7\u00e3o entre desempenho do modelo e algum hiperpar\u00e2metro selecionado.\n\nNa c\u00e9lula abaixo, \u00e9 plotada a curva de valida\u00e7\u00e3o para o modelo `LogisticRegression` em rela\u00e7\u00e3o ao hiperpar\u00e2metro `C` no conjunto `digits`:","3dc0d1ab":"Para esse estudo de caso, a regress\u00e3o log\u00edstica sem regulariza\u00e7\u00e3o tem melhor desempenho. Por isso, o argumento `penalty` foi especificado como `none`.\n\nAbaixo efetuamos a valida\u00e7\u00e3o cruzada. Para tal, a fun\u00e7\u00e3o [cross_val_score](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.model_selection.cross_validate.html) aceita um modelo, os dados `X` e `y` e a m\u00e9trica de avalia\u00e7\u00e3o:","4c220f09":"* O gr\u00e1fico acima \u00e9 um [diagrama de caixa](https:\/\/pt.wikipedia.org\/wiki\/Diagrama_de_caixa), em que os dados s\u00e3o apresentados da seguinte maneira:\n\n<img src=\"https:\/\/upload.wikimedia.org\/wikipedia\/commons\/thumb\/c\/c9\/Elements_of_a_boxplot_pt.svg\/1280px-Elements_of_a_boxplot_pt.svg.png\" width=\"400\" height=\"400\"\/>\n\n* Os melhores modelos foram [SVC](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.svm.SVC.html) e [KNeighborsClassifier](https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.neighbors.KNeighborsClassifier.html).\n\n* Aplicando os modelos no conjunto de teste:","81c9271a":"Para a playlist do curso completo, clique [aqui](https:\/\/www.youtube.com\/playlist?list=PLvr45Arc0UpzsRhzq3q4_KmZcm0utwvvB).","63d63e41":"# Conclus\u00e3o\n\nEsta aula foi um pouco diferente das demais. Cada uma das aulas anteriores teve como t\u00edtulo um problema cl\u00e1ssico de aprendizado (regress\u00e3o, detec\u00e7\u00e3o de falhas, classifica\u00e7\u00e3o ou clusteriza\u00e7\u00e3o) e constituiu-se de uma esp\u00e9cie de narrativa em que o problema foi resolvido por meio da aplica\u00e7\u00e3o de um modelo (florestas aleat\u00f3rias, PCA, redes neurais ou $k$-means) a estudos de caso selecionados. \n\nNesse aula, aprendemos de forma mais livre um conjunto de t\u00e9cnicas aplic\u00e1veis a v\u00e1rias situa\u00e7\u00f5es pr\u00e1ticas. A [valida\u00e7\u00e3o cruzada](https:\/\/scikit-learn.org\/stable\/modules\/cross_validation.html) \u00e9 apropriada para conjuntos de dados pequenos e atenua o efeito do ru\u00eddo de amostragem nas avalia\u00e7\u00f5es do desempenho. [Curvas de aprendizado](https:\/\/en.wikipedia.org\/wiki\/Learning_curve_(machine_learning)) s\u00e3o interessantes para medir a quantidade de dados necess\u00e1ria para generaliza\u00e7\u00e3o e para checar a ocorr\u00eancia de subajuste e sobreajuste. A [sintoniza\u00e7\u00e3o de hiperpar\u00e2metros](https:\/\/en.wikipedia.org\/wiki\/Hyperparameter_optimization) \u00e9 uma metodologia para maximizar o desempenho dos modelos por meio do ajuste de sua estrutura matem\u00e1tica.\n\n\u00c9 isso. O curso est\u00e1 quase no fim. Nos vemos na \u00faltima aula!!!!","8ca49e9d":"# Videoaula\n\nEste notebook \u00e9 explicado em detalhes ao longo da seguinte videoaula:","672c21a2":"## Comparando modelos\n\nA valida\u00e7\u00e3o cruzada \u00e9 particularmente adequada para uma compara\u00e7\u00e3o justa entre os desempenhos de v\u00e1rios modelos (de naturezas diferentes, ou um mesmo modelo com diferentes hiperpar\u00e2metros).\n\nAbaixo, calculamos os desempenhos de v\u00e1rios modelos utilizando a valida\u00e7\u00e3o cruzada:"}}