{"cell_type":{"4d691440":"code","89c9a715":"code","d60065e7":"code","b2efc85d":"code","f1ba3745":"code","814c8fad":"code","7954e3ee":"code","b33c85b4":"code","21ffde87":"code","2851a6ba":"code","c09f773c":"code","b5bcb612":"markdown","f64a8faa":"markdown","b7ad02f1":"markdown","09c68c30":"markdown","4eb2dde4":"markdown","49105866":"markdown","a24af152":"markdown","a82711f9":"markdown","4985d153":"markdown","b083cf64":"markdown","418034c8":"markdown"},"source":{"4d691440":"import numpy as np\nimport pandas as pd\nimport cv2\n\nimport json\nimport datetime as dt\nfrom tqdm import tqdm\n\nimport ast\nimport math\nfrom glob import glob\nimport glob\nfrom sklearn.preprocessing import LabelEncoder\nfrom keras.utils.np_utils import to_categorical\nfrom multiprocessing.dummy import Pool\nfrom keras.models import load_model\nimport time\nimport keras\nimport random\n\nfrom skimage.draw import draw\nimport matplotlib.pyplot as plt\nimport matplotlib.style as style\n%matplotlib inline\n%config InlineBackend.figure_format = 'retina'\n\nimport os\nprint(os.listdir(\"..\/input\/mobilenetfile\"))\nprint(os.listdir(\".\/\"))","89c9a715":"def f2cat(filename: str) -> str:\n    return filename.split('.')[0]\n\nclass Simplified():\n    def __init__(self, input_path='.\/input'):\n        self.input_path = input_path\n\n    def list_all_categories(self):\n        files = os.listdir(os.path.join(self.input_path, 'train_simplified'))\n        return sorted([f2cat(f) for f in files], key=str.lower)\n\n    def read_training_csv(self, category, nrows=None, usecols=None, drawing_transform=False):\n        df = pd.read_csv(os.path.join(self.input_path, 'train_simplified', category + '.csv'),\n                         nrows=nrows, parse_dates=['timestamp'], usecols=usecols)\n        if drawing_transform:\n            df['drawing'] = df['drawing'].apply(json.loads)\n        return df","d60065e7":"# shuffle csv \ub9cc\ub4e0\uc801\uc774 \uc5c6\ub2e4\uba74 \uc8fc\uc11d \ud480\uace0 \uc2e4\ud589 #\n\n# PATH = '..\/input\/quickdraw-doodle-recognition'\n\n# start = dt.datetime.now()\n# s = Simplified(PATH)\n# NCSVS = 100\n# categories = s.list_all_categories()\n# print(len(categories))\n\n# for y, cat in tqdm(enumerate(categories)):\n#     df = s.read_training_csv(cat, nrows=30000)\n#     df['y'] = y\n#     df['cv'] = (df.key_id \/\/ 10 ** 7) % NCSVS\n#     for k in range(NCSVS):\n#         filename = 'train_k{}.csv'.format(k)\n#         chunk = df[df.cv == k]\n#         chunk = chunk.drop(['key_id'], axis=1)\n#         if y == 0:\n#             chunk.to_csv(filename, index=False)\n#         else:\n#             chunk.to_csv(filename, mode='a', header=False, index=False)\n\n# for k in tqdm(range(NCSVS)):\n#     filename = 'train_k{}.csv'.format(k)\n#     if os.path.exists(filename):\n#         df = pd.read_csv(filename)\n#         df['rnd'] = np.random.rand(len(df))\n#         df = df.sort_values(by='rnd').drop('rnd', axis=1)\n#         df.to_csv(filename + '.gz', compression='gzip', index=False)\n#         os.remove(filename)\n# print(df.shape)\n\n# end = dt.datetime.now()\n# print('Latest run {}.\\nTotal time {}s'.format(end, (end - start).seconds))","b2efc85d":"INPUT_DIR = '..\/input\/quickdraw-doodle-recognition\/'\nBASE_SIZE = 256\n\n# Cross Validation\uc744 \uc704\ud574 \ucd94\uac00\ndef split_train_val(): \n    ALL_FILES = glob.glob('..\/input\/shuffle-csvs\/*.csv.gz')\n    VALIDATION_FILE = '..\/input\/shuffle-csvs\/train_k'+str(int(random.random()*93))+'.csv.gz'\n    ALL_FILES.remove(VALIDATION_FILE)\n    np.random.seed(seed=1987)\n    return ALL_FILES, VALIDATION_FILE\n\n\ndef apk(actual, predicted, k=3):\n    \"\"\"\n    Source: https:\/\/github.com\/benhamner\/Metrics\/blob\/master\/Python\/ml_metrics\/average_precision.py\n    \"\"\"\n    if len(predicted) > k:\n        predicted = predicted[:k]\n\n    score = 0.0\n    num_hits = 0.0\n\n    for i, p in enumerate(predicted):\n        if p in actual and p not in predicted[:i]:\n            num_hits += 1.0\n            score += num_hits \/ (i + 1.0)\n\n    if not actual:\n        return 0.0\n\n    return score \/ min(len(actual), k)\n\ndef mapk(actual, predicted, k=3):\n    \"\"\"\n    Source: https:\/\/github.com\/benhamner\/Metrics\/blob\/master\/Python\/ml_metrics\/average_precision.py\n    \"\"\"\n    return np.mean([apk(a, p, k) for a, p in zip(actual, predicted)])\n\n\ndef preds2catids(predictions):\n    return pd.DataFrame(np.argsort(-predictions, axis=1)[:, :3], columns=['a', 'b', 'c'])\n\ndef f2cat(filename: str) -> str:\n    return filename.split('.')[0]\n\ndef list_all_categories():\n    files = os.listdir(os.path.join(INPUT_DIR, 'train_simplified'))\n    return sorted([f2cat(f) for f in files], key=str.lower)\n\n\ndef plot_batch(x):    \n    cols = 4\n    rows = 6\n    fig, axs = plt.subplots(nrows=rows, ncols=cols, sharex=True, sharey=True, figsize=(18, 18))\n    for i in range(rows):\n        for k in range(0,3):\n            ax = axs[i, k]\n            ax.imshow(x[i, :, :, k], cmap=plt.cm.gray)\n            ax.axis('off')\n        ax = axs[i, 3]\n        ax.imshow(x[i, :, :], )\n        ax.axis('off')\n    fig.tight_layout()\n    plt.show();","f1ba3745":"AUGMENTATION = True\nSTEPS = 200\nBATCH_SIZE = 400\nEPOCHS = 10\nNCATS = 340\nLEARNING_RATE = 0.002\n\nIMG_SHAPE = (128,128,3)\nIMG_SIZE = IMG_SHAPE[0]","814c8fad":"def draw_cv2(raw_strokes, size=256, lw=6, augmentation = False):\n    img = np.zeros((BASE_SIZE, BASE_SIZE, 3), np.uint8)\n    for t, stroke in enumerate(raw_strokes):\n        points_count = len(stroke[0]) - 1\n        grad = 255\/\/points_count\n        for i in range(len(stroke[0]) - 1):\n            _ = cv2.line(img, (stroke[0][i], stroke[1][i]), (stroke[0][i + 1], stroke[1][i + 1]), (255, 255 - min(t,10)*13, max(255 - grad*i, 20)), lw)\n    if size != BASE_SIZE:\n        img = cv2.resize(img, (size, size))\n    if augmentation:\n        if random.random() > 0.5:\n            img = np.fliplr(img)\n    return img","7954e3ee":"def image_generator(size, batchsize, lw=6, augmentation = False):\n    while True:\n        for filename in ALL_FILES:\n            for df in pd.read_csv(filename, chunksize=batchsize):\n                df['drawing'] = df['drawing'].apply(eval)\n                x = np.zeros((len(df), size, size,3))\n                for i, raw_strokes in enumerate(df.drawing.values):\n                    x[i] = draw_cv2(raw_strokes, size=size, lw=lw, augmentation = augmentation)\n                x = x \/ 255.\n                x = x.reshape((len(df), size, size, 3)).astype(np.float32)\n                y = keras.utils.to_categorical(df.y, num_classes=NCATS)\n                yield x, y\n\ndef valid_generator(valid_df, size, batchsize, lw=6):\n    while(True):\n        for i in range(0,len(valid_df),batchsize):\n            chunk = valid_df[i:i+batchsize]\n            x = np.zeros((len(chunk), size, size,3))\n            for i, raw_strokes in enumerate(chunk.drawing.values):\n                x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n            x = x \/ 255.\n            x = x.reshape((len(chunk), size, size,3)).astype(np.float32)\n            y = keras.utils.to_categorical(chunk.y, num_classes=NCATS)\n            yield x,y\n        \ndef test_generator(test_df, size, batchsize, lw=6):\n    for i in range(0,len(test_df),batchsize):\n        chunk = test_df[i:i+batchsize]\n        x = np.zeros((len(chunk), size, size,3))\n        for i, raw_strokes in enumerate(chunk.drawing.values):\n            x[i] = draw_cv2(raw_strokes, size=size, lw=lw)\n        x = x \/ 255.\n        x = x.reshape((len(chunk), size, size, 3)).astype(np.float32)\n        yield x\n        \n\nALL_FILES, VALIDATION_FILE = split_train_val()\ntrain_datagen = image_generator(size=IMG_SIZE, batchsize=BATCH_SIZE, augmentation = AUGMENTATION)\n\nvalid_df = pd.read_csv(VALIDATION_FILE)\nvalid_df['drawing'] = valid_df['drawing'].apply(eval)\nvalidation_steps = len(valid_df)\/\/BATCH_SIZE\nvalid_datagen = valid_generator(valid_df, size=IMG_SIZE, batchsize=BATCH_SIZE)","b33c85b4":"single_class_df = valid_df[valid_df['y'] == 2]\nsingle_class_gen = valid_generator(single_class_df, size=IMG_SIZE, batchsize=BATCH_SIZE)\nx, y = next(single_class_gen)\nplot_batch(x)","21ffde87":"from keras.layers import Conv2D, MaxPooling2D\nfrom keras.layers import Dense, Dropout, Flatten, Activation\nfrom keras.metrics import categorical_accuracy, top_k_categorical_accuracy, categorical_crossentropy\nfrom keras.models import Sequential\nfrom keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\nfrom keras.optimizers import Adam\nfrom keras.applications.mobilenet import MobileNet\nfrom keras.applications.mobilenet import preprocess_input\nfrom keras.models import load_model\n\ndef top_3_accuracy(y_true, y_pred):\n    return keras.metrics.top_k_categorical_accuracy(y_true, y_pred, k=3)\n\nreducer = ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=5)\ncheckpointer = ModelCheckpoint(filepath='mobileNet_ckpt.hdf5', verbose=2, save_best_only=True)\nmodel = load_model('..\/input\/mobilenetfile\/mobileNet.hdf5', custom_objects = {'top_3_accuracy':top_3_accuracy})\nopt = Adam(lr = LEARNING_RATE)\nmodel.compile(optimizer = opt, loss = 'categorical_crossentropy', metrics = ['accuracy', top_3_accuracy])\nmodel.summary()","2851a6ba":"history = model.fit_generator(train_datagen,\n                              steps_per_epoch=STEPS,\n                              epochs=EPOCHS,\n                              verbose=2,\n                              validation_data=valid_datagen,\n                              validation_steps=validation_steps,\n                              callbacks=[checkpointer,reducer])\nmodel.save('mobileNet.hdf5')","c09f773c":"submission_df = pd.read_csv(os.path.join(INPUT_DIR, 'test_simplified.csv'))\nsubmission_df['drawing'] = submission_df['drawing'].apply(eval)\nsubmission_datagen = test_generator(submission_df, size=IMG_SIZE, batchsize=BATCH_SIZE)\nsubmission_predictions = model.predict_generator(submission_datagen, math.ceil(len(submission_df)\/BATCH_SIZE))\ncats = list_all_categories()\nid2cat = {k: cat.replace(' ', '_') for k, cat in enumerate(cats)}\ntop3 = preds2catids(submission_predictions)\ntop3cats = top3.replace(id2cat)\nsubmission_df['word'] = top3cats['a'] + ' ' + top3cats['b'] + ' ' + top3cats['c']\nsubmission = submission_df[['key_id', 'word']]\nsubmission.to_csv('submission.csv', index=False)","b5bcb612":"### 2. Image Encoding","f64a8faa":"## \ud83d\udcbb Predictive Modeling\n### 1. Learning and data Hyper parameters","b7ad02f1":"### 3. Data generators\nShuffle\ud55c \ub370\uc774\ud130 \ud30c\uc77c\ub4e4\uc744 \ud558\ub098\ub85c \ud1b5\ud569\ud574\uc11c generator\uc5d0 \uc0ac\uc6a9","09c68c30":"## \ud83d\udce5 Shuffle CSVs and Load Data\n### 1. Shuffle CSVs\n<a href=\"https:\/\/kaggle.com\/gaborfodor\/shuffle-csvs\">beluga<\/a> \ub2d8\uc758 \ucf54\ub4dc\ub97c \ucc38\uace0\ud588\uc2b5\ub2c8\ub2e4.","4eb2dde4":"## \ud83d\udcd1 Import Libraries","49105866":"### 5. Model definition","a24af152":"### 2. Load Data\n<a href=\"https:\/\/www.kaggle.com\/echomil\/mobilenet-126x126x3-100k-per-class\">Pawel Mieloch<\/a> \ub2d8\uc758 \ucf54\ub4dc\ub97c \ucc38\uace0\ud588\uc2b5\ub2c8\ub2e4.","a82711f9":"## \ud83d\udcbb Result","4985d153":"## Quick, Draw! Doodle Recognition\n\n#### _ 2019 Winter Coding _ \uc774\uae30\uc778\n\n1. \ud504\ub808\uc784\uc6cc\ud06c\n   - Keras\ub97c \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n   - Tensorflow \uc5ed\uc2dc \uc0ac\uc6a9\ud560 \uc904 \uc54c\uc9c0\ub9cc, Keras\uac00 \ubaa8\ub378 \uad6c\ucd95\uc5d0 \ud6e8\uc52c \ud3b8\ub9ac\ud558\uae30 \ub54c\ubb38\uc5d0 \uc9e7\uc740 \uc2dc\uac04 \ub0b4\uc5d0 \ubaa8\ub378\uc744 \ud14c\uc2a4\ud2b8\ud558\ub294\ub370 \uc801\ud569\ud558\ub2e4\uace0 \uc0dd\uac01\ud588\uc2b5\ub2c8\ub2e4.\n2. \ub370\uc774\ud130\n   - \ud559\uc2b5 \ub370\uc774\ud130\uc14b\uc740 \ucd1d 340\uac1c\uc758 \ud074\ub798\uc2a4\ub97c \uac00\uc9c0\uace0 \uc788\uace0, \uac01 \ud074\ub798\uc2a4\ubcc4\ub85c 10,000\uac1c\uc758 \ub370\uc774\ud130\ub97c \uac00\uc9c0\uace0 \uc788\uc2b5\ub2c8\ub2e4.\n   - Overfitting\uc744 \ubc29\uc9c0\ud558\uace0 \ud559\uc2b5\ub370\uc774\ud130\ub97c \ucd5c\ub300\ud55c \ud65c\uc6a9\ud558\uae30 \uc704\ud574\uc11c \ud074\ub798\uc2a4\ubcc4 CSV \ud30c\uc77c\ub4e4\uc744 Shuffle\ud574\uc11c \uc0ac\uc6a9\ud588\uace0, \uc774\ub97c Training\uc5d0 \uc0ac\uc6a9\ud560 \ub54c\ub294 Cross-Validation \ubc29\uc2dd\uc744 \uc801\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n   - \ud558\ub4dc\uc6e8\uc5b4\uc758 \uc81c\ud55c\uc73c\ub85c \ud559\uc2b5\uc5d0 simplified dataset\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n   - \ub370\uc774\ud130\uc5d0\ub294 stroke\uac00 \uae30\ub85d\ub418\uc5b4\uc788\ub294\ub370, \ud559\uc2b5\uc5d0 \uc0ac\uc6a9\ud558\uae30 \uc704\ud574\uc11c 3\uac00\uc9c0 encoding\uc744 \ubc14\ud0d5\uc73c\ub85c \uc804\ucc98\ub9ac\ub97c \ud588\uc2b5\ub2c8\ub2e4.\n     1. stroke \uc5ec\ubd80 \uae30\uc900 : stroke\uac00 \ub41c \ubd80\ubd84\uc740 255, \uc544\ub2c8\uba74 0\n     2. stroke \uc2dc\uac04 \uae30\uc900 : \ubcf4\ud1b5 \uc724\uacfd\uc744 \uba3c\uc800 \uadf8\ub9ac\uace0 \ub514\ud14c\uc77c\ud55c \ubd80\ubd84\uc744 \ub098\uc911\uc5d0 \uadf8\ub9bd\ub2c8\ub2e4. \uadf8\ub798\uc11c \uccab\ubc88\uc9f8 stroke\uc5d0 255\ub97c \uc8fc\uace0, 125\uac00 \ub420 \ub54c \uae4c\uc9c0 \ub2e4\uc74c stroke\ub294 13\uc529 \uac12\uc744 \uac10\uc18c\uc2dc\ucf30\uc2b5\ub2c8\ub2e4.\n     3. \uac01 stroke\uc5d0\uc11c\uc758 \uc2dc\uac04 \uae30\uc900 : \uac01 stroke\uc5d0\uc11c point\uac00 \ucc0d\ud78c \uc2dc\uac04\uc744 \uae30\uc900\uc73c\ub85c \uac00\uc911\uce58\ub97c \uc900\ub2e4\uba74, stroke\uc758 \ubc29\ud5a5\uc744 \uc54c \uc218 \uc788\uc2b5\ub2c8\ub2e4. \uccab\ubc88\uc9f8 point\ub294 255\ub97c, \uadf8\ub9ac\uace0 \uadf8 \ub2e4\uc74c\ubd80\ud130 20\uc774 \ub420 \ub54c\uae4c\uc9c0 \uac10\uc18c\uc2dc\ucf30\uc2b5\ub2c8\ub2e4.\n3. \ubaa8\ub378\n   - keras.application \ud328\ud0a4\uc9c0\uc758 MobileNet\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.\n   - \uce90\uae00 \ucee4\ub110\uc5d0\uc11c\ub9cc \uc791\uc5c5\ud574\uc57c\ud558\ub294 \uc870\uac74\uc774\uc5c8\uace0, \ucd5c\ub300\ud55c \uac00\ubcbc\uc6b0\uba74\uc11c \uc131\ub2a5\uc774 \uc88b\uc740 \ubaa8\ub378\uc744 \uc120\ud0dd\ud574\uc57c\ud588\uace0, MobileNet\uacfc ResNet18\uc774 \ud6c4\ubcf4\uc600\uc2b5\ub2c8\ub2e4. \uc77c\uc8fc\uc77c\uac04 \ud29c\ub2dd\uc744 \ud558\uba74\uc11c \ud559\uc2b5\ud574\ubcf8 \uacb0\uacfc ResNet18\ubcf4\ub2e4\ub294 MobileNet\uc758 \uc131\ub2a5\uc774 \ub192\uac8c \ub098\uc640\uc11c \ucd5c\uc885\uc801\uc73c\ub85c MobileNet\uc744 \uc0ac\uc6a9\ud588\uc2b5\ub2c8\ub2e4.","b083cf64":"### 6. Training","418034c8":"### 4.Visualization of image encoding"}}