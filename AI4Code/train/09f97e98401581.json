{"cell_type":{"3456b8ef":"code","c6f140dc":"code","b01b5b2f":"code","4a74046e":"code","f1336926":"code","a65ecba7":"code","3bb762f0":"code","0ac72520":"code","0abd14b2":"code","c010810f":"code","c56ed125":"code","3f2b6fd1":"code","253bb3d2":"code","de33f924":"code","342e13b5":"code","c67510fe":"code","f061bee4":"code","8940bfa4":"code","97f69349":"code","0dd67f09":"code","ea8d93e8":"code","5a08fab8":"code","9fa3a226":"code","afeea3e2":"code","d93de51f":"code","e2d7db96":"code","729bb058":"code","ebe6517c":"code","d2dccb61":"code","a0d5f735":"code","c4c875b3":"code","da81e880":"code","f7564aa0":"code","7bac6648":"code","c43feeac":"code","4f621fdf":"code","8de1a958":"code","fc43851e":"code","68383ffb":"code","1d1a17c6":"markdown","42af4b44":"markdown"},"source":{"3456b8ef":"!pip install -U xgboost","c6f140dc":"import pandas as pd\nimport os\nimport numpy as np\nimport seaborn as sns\nimport xgboost as xgb\nimport datetime\nimport matplotlib.pyplot as plt\nfrom sklearn.multioutput import MultiOutputRegressor\nfrom sklearn.preprocessing import LabelEncoder","b01b5b2f":"def smape(actual, predicted):\n    a = np.abs(np.array(actual) - np.array(predicted))\n    b = np.array(actual) + np.array(predicted)\n    \n    return 2 * np.mean(np.divide(a, b, out=np.zeros_like(a), where=b!=0, casting='unsafe'))","4a74046e":"def baseline(y_test):\n    # step = len(y_test.columns)\n    y_actual = np.array(y_test)[1:,0]\n    y_pred = np.array(y_test)[:-1,0]\n    # y_pred = np.repeat(np.array(y_test['PM2.5(t)'][:-1]), step, axis=0).reshape(-1, step)\n    score = smape(y_actual, y_pred)\n    print('baseline sampe: ', score)","f1336926":"# \u751f\u6210\u5355\u4e2a\u7ad9\u70b9\u7684\u6570\u636e\u96c6\n\ndef generate_station_dataset(data, labels, station, n_in=1, n_out=1, dropnan=True):\n    \n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = data\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('%s(t-%d)' % (df.columns[j], i)) for j in range(n_vars)]\n    \n    # forecast sequence (t, t+1, ... t+n)\n    label_idx = list()\n    for idx, label in enumerate(data.columns):\n        if label in labels:\n            label_idx.append(idx)\n    for i in range(0, n_out):\n        if i == 0:\n            cols.append(df[labels].shift(-i))\n            names += [('%s(t)' % (df.columns[j])) for j in label_idx]\n        else:\n            cols.append(df[labels].shift(-i))\n            names += [('%s(t+%d)' % (df.columns[j], i)) for j in label_idx]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    print(agg.isnull().any())\n    if dropnan:\n        agg.dropna(inplace=True)\n    X = agg[agg.columns[:-n_out*len(labels)]]\n    y = agg[agg.columns[-n_out*len(labels):]]\n\n    return X, y","a65ecba7":"# \u751f\u6210\u5e26id\u7684\u5355\u4e2a\u7ad9\u70b9\u7684\u6570\u636e\u96c6\n\ndef generate_station_dataset_with_id(data, labels, station_id, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = data\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('%s(t-%d)' % (df.columns[j], i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    label_idx = list()\n    for idx, label in enumerate(data.columns):\n        if label in labels:\n            label_idx.append(idx)\n    for i in range(0, n_out):\n        if i == 0:\n            cols.append(df[labels].shift(-i))\n            names += [('%s(t)' % (df.columns[j])) for j in label_idx]\n        else:\n            cols.append(df[labels].shift(-i))\n            names += [('%s(t+%d)' % (df.columns[j], i)) for j in label_idx]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n        \n    X, y = agg[agg.columns[:-n_out*len(labels)]].copy(), agg[agg.columns[-n_out*len(labels):]].copy()\n    X['station'] = [station_id]*len(X)\n    \n    agg = pd.concat([X,y], axis=1)\n\n    return agg\n\n# \u9010\u7ad9\u70b9\u751f\u6210\u6570\u636e\u96c6\u540e\u62fc\u63a5\n\ndef generate_dataset(data, labels, n_in=1, n_out=1, dropnan=True):\n    stations = data.loc[:,'station']\n#     station_ids = encoder.transform(stations)\n    dataset = None\n    for idx, station in enumerate(np.unique(stations)):\n#         print(station)\n        data_block = data[data['station']==station].drop('station', axis=1)\n        dataset_block = generate_station_dataset_with_id(data_block, labels, idx, n_in, n_out, dropnan)\n        \n        if dataset is None:\n            dataset = dataset_block\n        else:\n            dataset = dataset.append(dataset_block)\n    X, y = dataset[dataset.columns[:-n_out*len(labels)]], dataset[dataset.columns[-n_out*len(labels):]]\n    \n    return X, y","3bb762f0":"# \u751f\u6210\u5e26\u6240\u6709\u7ad9\u70b9\u7279\u5f81\u7684\u6570\u636e\u96c6\n\ndef generate_full_station_dataset_with_id(data, labels, station_id, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = data\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('%s(t-%d)' % (df.columns[j], i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    label_idx = list()\n    for idx, label in enumerate(data.columns):\n        if label in labels:\n            label_idx.append(idx)\n    for i in range(0, n_out):\n        if i == 0:\n            cols.append(df[labels].shift(-i))\n            names += [('%s(t)' % (df.columns[j])) for j in label_idx]\n        else:\n            cols.append(df[labels].shift(-i))\n            names += [('d%s(t+%d)' % (df.columns[j], i)) for j in label_idx]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n        \n    X, y = agg[agg.columns[:-n_out*len(labels)]].copy(), agg[agg.columns[-n_out*len(labels):]].copy()\n    X['station'] = [station_id]*len(X)\n    \n    agg = pd.concat([X,y], axis=1)\n\n    return agg\n\ndef generate_full_dataset(data, labels, n_in=1, n_out=1, dropnan=True):\n    stations = data.loc[:,'station']\n#     station_ids = encoder.transform(stations)\n    dataset = None\n    for idx, station in enumerate(np.unique(stations)):\n#         print(station)\n        data_block = data[data['station']==station].drop('station', axis=1)\n        dataset_block = generate_full_station_dataset_with_id(data_block, labels, idx, n_in, n_out, dropnan)\n        \n        if dataset is None:\n            dataset = dataset_block\n        else:\n            dataset = dataset.append(dataset_block)\n    X, y = dataset[dataset.columns[:-n_out*len(labels)]], dataset[dataset.columns[-n_out*len(labels):]]\n    \n    return X, y","0ac72520":"dir = '..\/input\/beijing-multisite-airquality-data-data-set\/PRSA_Data_20130301-20170228\/'\nfiles = os.listdir(dir)\ndata_all = pd.DataFrame()\nfor idx, f in enumerate(files):\n    df = pd.read_csv(dir+f, index_col=0)\n    df['station'] = f.strip('.csv').split('_')[2]\n    if idx == 0:\n        data_all = df\n    else:\n        data_all = pd.concat([data_all, df])","0abd14b2":"data_all.drop('wd', axis=1, inplace=True)","c010810f":"from sklearn.preprocessing import LabelEncoder\n\ndata_all['wd'].fillna(value='NAN', inplace = True)\nencoder.fit(data_all['wd'])\ndata_all['wd'] = encoder.transform(data_all['wd'])\nencoder.fit(data_all['station'])\ndata_all['station'] = encoder.transform(data_all['station'])","c56ed125":"data_all.interpolate(inplace=True, limit_direction='both')","3f2b6fd1":"data_all.isnull().any()","253bb3d2":"data_all.reset_index(inplace=True,drop=True)","de33f924":"data_all","342e13b5":"grouped = data_all.groupby([\"year\",\"month\",\"day\",\"hour\"])\n\nfor g in grouped:\n    subdf = g[1]\n    subdf.sort_values('station')\n    row,names = list(),list()\n    for idx, r in subdf.iterrows():\n        row.append(r)\n        names += [('%s_%s_'%(r.station,r.index[i])) for i in range(len(r.index))]\n        s = pd.Series(index=names, data=row)\n    print(names)\n    break\n#     print(subdf)","c67510fe":"features = ['station', 'PM2.5', 'PM10', 'SO2', 'NO2', 'CO', 'O3', 'TEMP', 'PRES', 'DEWP']\n\ndata_train = data_all.loc[data_all.year <= 2016][features].copy()\ndata_test = data_all.loc[data_all.year > 2016][features].copy()","f061bee4":"print(data_train.shape)\nprint(data_test.shape)","8940bfa4":"# \u751f\u6210\u5355\u4e2a\u7ad9\u70b9\u7684\u6570\u636e\u96c6\n\ndef generate_station_dataset_t(data, labels, n_in=1, n_out=1, dropnan=True):\n    n_vars = 1 if type(data) is list else data.shape[1]\n    df = data\n    cols, names = list(), list()\n    # input sequence (t-n, ... t-1)\n    for i in range(n_in, 0, -1):\n        cols.append(df.shift(i))\n        names += [('%s(t-%d)' % (df.columns[j], i)) for j in range(n_vars)]\n    # forecast sequence (t, t+1, ... t+n)\n    label_idx = list()\n    for idx, label in enumerate(data.columns):\n        if label in labels:\n            label_idx.append(idx)\n    for i in range(0, n_out):\n        if i == 0:\n            cols.append(df[labels].shift(-i))\n            names += [('%s(t)' % (df.columns[j])) for j in label_idx]\n        else:\n            cols.append(df[labels].shift(-i))\n            names += [('d%s(t+%d)' % (df.columns[j], i)) for j in label_idx]\n    # put it all together\n    agg = pd.concat(cols, axis=1)\n    agg.columns = names\n    # drop rows with NaN values\n    if dropnan:\n        agg.dropna(inplace=True)\n        \n    X, y = agg[agg.columns[:-n_out*len(labels)]].copy(), agg[agg.columns[-n_out*len(labels):]].copy()\n#     X['station'] = [station_id]*len(X)\n\n    return X, y","97f69349":"data_aoti_train = data_train[data_train['station']=='Aotizhongxin'].drop('station', axis=1)\ndata_aoti_test = data_test[data_test['station']=='Aotizhongxin'].drop('station', axis=1)\nX_train, y_train = generate_station_dataset_t(data_aoti_train, n_in=24, n_out=12, labels=['PM2.5','PM10','SO2','NO2','CO','O3','TEMP','PRES','DEWP'])\nX_test, y_test = generate_station_dataset_t(data_aoti_test, n_in=24, n_out=12, labels=['PM2.5','PM10','SO2','NO2','CO','O3','TEMP','PRES','DEWP'])","0dd67f09":"X_test, y_test = generate_dataset(data_test,  n_in=24, n_out=12, labels=['PM2.5','PM10','SO2','NO2','CO','O3','TEMP','PRES','DEWP'])\nX_train, y_train = generate_dataset(data_train, n_in=24, n_out=12, labels=['PM2.5','PM10','SO2','NO2','CO','O3','TEMP','PRES','DEWP'])","ea8d93e8":"X_train","5a08fab8":"y_test","9fa3a226":"X_test.drop('station', inplace=True, axis=1)\nX_train.drop('station', inplace=True, axis=1)","afeea3e2":"model = MultiOutputRegressor(xgb.XGBRegressor(n_estimators=100, random_state=666, max_depth=4, tree_method='gpu_hist')).fit(X_train, y_train[y_train.columns[:9]], verbose=True)","d93de51f":"from random import randint\n\ndef iter_predict(model, X_test, y_test, n_features, if_station=False):\n    gt = list()\n    pred = list()\n    \n    if if_station:\n        station = X_test['station'].copy()\n    for i in range(12):\n        y_pred = model.predict(X_test)\n        # drop late data\n        if if_station:\n            X_test.drop('station', inplace=True, axis=1)\n        X_test = X_test.shift(-n_features, axis=1)\n        # add predicted data\n        X_test[X_test.columns[-n_features:]] = y_pred\n        if if_station:\n            X_test['station'] = station\n        sample_gt = list()\n        sample_pred = list()\n        for j in range(20):\n            idx = randint(0,len(y_test)-1)\n            sample_gt.append(y_test[y_test.columns[i*n_features]].tolist()[idx])\n            sample_pred.append(y_pred[idx,0])\n        gt.append(sample_gt)\n        pred.append(sample_pred)\n        print('iter %d: smape=%f'%(i, smape(y_test[y_test.columns[i*n_features]], y_pred[:,0])))\n        \n    return np.array(gt), np.array(pred)","e2d7db96":"gt, pred = iter_predict(model, X_test, y_test, 9)","729bb058":"plt.plot(range(12), gt[:,0])\nplt.plot(range(12), pred[:,0])","ebe6517c":"plt.plot(range(12), gt[:,1])\nplt.plot(range(12), pred[:,1])","d2dccb61":"plt.plot(range(12), gt[:,5])\nplt.plot(range(12), pred[:,5])","a0d5f735":"print(gt[:5])\nprint(pred[:5])","c4c875b3":"iter_predict(model, X_test, y_test, 9)","da81e880":"!pip install joblib","f7564aa0":"import joblib\n\njoblib.dump(model, 'Xgboost.model')","7bac6648":"y_pred = model.predict(X_test)","c43feeac":"from bokeh.plotting import figure\nfrom bokeh.io import show, output_notebook\np = figure(title=\"Prediction\", x_axis_label='x', y_axis_label='y', width=1100, height=400)\np.line(range(len(y_pred)), y_pred[:,0], legend_label=\"pred(t)\", line_width=2, line_color='yellow')\n# p.line(range(1,len(y_pred)), y_pred[:-1,1], legend_label=\"pred(t+1)\", line_width=2, line_color='blue')\np.line(range(11,len(y_pred)), y_pred[:-11,11], legend_label=\"pred(t+11)\", line_width=2, line_color='blue')\np.line(range(4,len(y_pred)), y_pred[:-4,4], legend_label=\"pred(t+4)\", line_width=2, line_color='green')\np.line(range(len(y_test)), np.array(y_test)[:,0], legend_label=\"ground truth\", line_width=2, line_color='red')\noutput_notebook()\nshow(p)","4f621fdf":"from catboost import CatBoostRegressor","8de1a958":"cat_model = CatBoostRegressor(iterations=40, depth=5,learning_rate=0.1, loss_function='MultiRMSE',logging_level='Verbose')","fc43851e":"cat_model.fit(X_train,y_train[y_train.columns[:9]],eval_set=(X_test, y_test[y_test.columns[:9]]),plot=True)","68383ffb":"iter_predict(cat_model, X_test, y_test, 9)","1d1a17c6":"# CatBoost","42af4b44":"## \u76ee\u524d\u7279\u5f81\n* \u5f53\u524d\u7ad9\u70b9\u5386\u53f224\u5c0f\u65f6\u6570\u636e\n* \u5f53\u524d\u7ad9\u70b9\u6700\u8fd1\u6c14\u8c61\u7ad924\u5c0f\u65f6\u6c14\u8c61\u6570\u636e\n* \u8003\u8651\u6dfb\u52a0\u68af\u5ea6\u6570\u636e"}}