{"cell_type":{"f15ba03e":"code","39a422e6":"code","ee02c9ec":"code","4b32e397":"code","3b3caac9":"code","545f7e43":"code","81c97f8d":"code","2c50fc91":"code","c8ae3add":"code","0e1c3aa5":"code","32499306":"code","47ec374d":"code","e8896dab":"code","f1b664c2":"code","4c4f862c":"code","3d067cf5":"code","a3f2d61f":"code","ca0e800d":"code","ef9befbd":"code","ea53bafc":"code","9e1392be":"code","5e2a2199":"markdown"},"source":{"f15ba03e":"!pip install -q -U git+https:\/\/github.com\/mljar\/mljar-supervised.git@master\n!pip install -q -U matplotlib==3.1.3 ","39a422e6":"from supervised import AutoML","ee02c9ec":"import pandas as pd\nimport numpy as np\n\n\nimport seaborn as sns\nsns.set_style(\"whitegrid\", {'axes.grid' : False})\nimport os\nfrom tqdm.notebook import tqdm\nimport gc\nfrom lightgbm import LGBMClassifier\nfrom sklearn.model_selection import train_test_split\nimport seaborn as sns; sns.set()\n%matplotlib inline\nfrom matplotlib import pyplot as plt\nfrom sklearn.model_selection import ParameterGrid\nfrom sklearn.metrics import accuracy_score,mean_squared_error,auc\nfrom sklearn import metrics","4b32e397":"TARGET_COL = \"diabetes_mellitus\"\ndf = pd.read_csv(\"..\/input\/widsdatathon2021\/TrainingWiDS2021.csv\")\nprint(df.shape)\ntest = pd.read_csv(\"..\/input\/widsdatathon2021\/UnlabeledWiDS2021.csv\")\nprint(test.shape)\ndf['label']='train'\ntest['label']='test'\nframes = [df,test]\njoin_df = pd.concat(frames, keys=['x', 'y'])\nassert len(join_df) == len(df) + len(test)\nlst = join_df.isna().sum()\/len(join_df)\np = pd.DataFrame(lst)\np.reset_index(inplace=True)\np.columns = ['a','b']\nlow_count = p[p['b']>0.8]\ntodelete=low_count['a'].values\njoin_df.drop(todelete,axis=1,inplace=True)\njoin_df.head()","3b3caac9":"def reduce_mem_usage(df, verbose=True):\n    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n    start_mem = df.memory_usage().sum() \/ 1024**2    \n    for col in df.columns:\n        col_type = df[col].dtypes\n        if col_type in numerics:\n            c_min = df[col].min()\n            c_max = df[col].max()\n            if str(col_type)[:3] == 'int':\n                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n                    df[col] = df[col].astype(np.int8)\n                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n                    df[col] = df[col].astype(np.int16)\n                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n                    df[col] = df[col].astype(np.int32)\n                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n                    df[col] = df[col].astype(np.int64)  \n            else:\n                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n                    df[col] = df[col].astype(np.float16)\n                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n                    df[col] = df[col].astype(np.float32)\n                else:\n                    df[col] = df[col].astype(np.float64)    \n    end_mem = df.memory_usage().sum() \/ 1024**2\n    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) \/ start_mem))\n    return df","545f7e43":"join_df.drop(['Unnamed: 0','encounter_id'],inplace=True,axis=1)\nnumerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n\nnewdf = join_df.select_dtypes(include=numerics)\nnumeric_cols = newdf.columns\n\n# Need to do column by column due to memory constraints\ncategorical_cols =  ['elective_surgery','hospital_id','icu_id',\n 'ethnicity', 'gender', 'hospital_admit_source', 'icu_admit_source', 'icu_stay_type', 'icu_type','aids','cirrhosis','hepatic_failure','immunosuppression',\n 'leukemia','lymphoma','solid_tumor_with_metastasis','elective_surgery','apache_post_operative','arf_apache','fio2_apache','gcs_unable_apache','gcs_eyes_apache',\n 'gcs_motor_apache','gcs_verbal_apache','intubated_apache','ventilated_apache','solid_tumor_with_metastasis']\nfor i, v in tqdm(enumerate(categorical_cols)):\n    join_df[v] = join_df[v].fillna(join_df[v].value_counts().index[0])\nfor i, v in tqdm(enumerate([numeric_cols])):\n    join_df[v] =join_df.groupby(['ethnicity','gender'], sort=False)[v].apply(lambda x: x.fillna(x.mean()))\njoin_df[categorical_cols].isna().sum()","81c97f8d":"from sklearn.preprocessing import OrdinalEncoder\n\n# In loop to minimize memory use\nfor i, v in tqdm(enumerate(categorical_cols)):\n    join_df[v] = OrdinalEncoder(dtype=\"int\").fit_transform(join_df[[v]])\n    \n\ngc.collect()\n\ntrain = join_df[join_df['label']==\"train\"]\npredict = join_df[join_df['label']=='test']\n\ntrain.reset_index(inplace=True)\ntrain.drop(['level_0','level_1','label'],inplace=True,axis =1 )\n\npredict.reset_index(inplace=True)\npredict.drop(['level_0','level_1','diabetes_mellitus','label'],inplace=True,axis=1)\nfeatures = train.columns\nnum_feature = [col for col in features if col not in categorical_cols]\n","2c50fc91":"num_feature = [col for col in features if col not in categorical_cols and train[col].dtype != 'object']\ndrop_columns=[]\ncorr = train[num_feature].corr()\n# Drop highly correlated features \ncolumns = np.full((corr.shape[0],), True, dtype=bool)\n\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >=0.999 :\n            if columns[j]:\n                columns[j] = False\n                print('FEAT_A: {} FEAT_B: {} - Correlation: {}'.format(train[num_feature].columns[i] , train[num_feature].columns[j], corr.iloc[i,j]))\n        elif corr.iloc[i,j] <= -0.995:\n            if columns[j]:\n                columns[j] = False","c8ae3add":"drop_columns = train[num_feature].columns[columns == False].values\nprint('drop_columns',len(drop_columns),drop_columns)","0e1c3aa5":"train.drop(drop_columns,inplace=True,axis =1 )\npredict.drop(drop_columns,inplace=True,axis =1 )\ntrain[TARGET_COL].value_counts()\/len(train)","32499306":"from sklearn.model_selection import train_test_split\nfrom sklearn.utils import resample\ndf_majority = train[train['diabetes_mellitus']==0]\ndf_minority = train[train['diabetes_mellitus']==1]\n\ndf_minority_upsampled = resample(df_minority, \n                                 replace=True,     # sample with replacement\n                                 n_samples=83798,    # to match majority class\n                                 random_state= 303) # reproducible results\n \n# Combine majority class with upsampled minority class\ndf_upsampled = pd.concat([df_majority, df_minority_upsampled])\n \n# Display new class counts\ndf_upsampled.diabetes_mellitus.value_counts()\ntrain = df_upsampled","47ec374d":"X_train, X_test, y_train, y_test = train_test_split(\n     train[[c for c in train if TARGET_COL != c]], train[TARGET_COL], test_size=0.20, random_state=42)\nprint(X_train.shape,X_test.shape)","e8896dab":"X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.20, random_state=42)","f1b664c2":"X_train.head()","4c4f862c":"X=train[[c for c in train if TARGET_COL != c]]\ny=train[TARGET_COL]\nautoml = AutoML(mode=\"Compete\",total_time_limit=4*3600)\nautoml.fit(X, y)","3d067cf5":"predict","a3f2d61f":"Final=automl.predict_all(predict)\n","ca0e800d":"test[TARGET_COL] = Final['prediction_1']\ntest[[\"encounter_id\",\"diabetes_mellitus\"]].to_csv(\"submission.csv\",index=False)","ef9befbd":"predictions = automl.predict_all(X_valid)\n","ea53bafc":"print(\"Test MSE:\", mean_squared_error(y_valid, predictions['prediction_1'],squared=False))","9e1392be":"automl.report()","5e2a2199":"# Fast AutoMlJar"}}