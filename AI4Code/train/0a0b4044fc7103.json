{"cell_type":{"32af79b0":"code","eb5eb796":"code","4fa1e39c":"code","a75c85e0":"code","0f89b07a":"code","51578c57":"code","768a1f8d":"code","c65de577":"code","72d87222":"code","6d4af551":"code","5b0b9f67":"code","09c210ec":"code","3ed30910":"code","214a72a7":"code","813f4208":"code","26861a66":"code","304f5baa":"code","252d4c23":"code","ed36833c":"code","c8d93125":"code","612119b0":"code","943672d2":"code","d72d3777":"code","8c892292":"code","5e4876cb":"code","7434db7d":"code","a3566b98":"code","931a339a":"code","ecf4b58f":"code","50453dbf":"code","d6890fca":"code","5d6272fd":"code","d41bb5fc":"code","79907b16":"code","a8e890fd":"code","ea5030a0":"code","d13500c3":"code","11f242d9":"code","0940deb1":"code","005b73de":"code","4772a645":"code","9032c852":"code","1f35e47c":"code","e344abc3":"code","94d89129":"code","e8b343aa":"code","ec670234":"code","8ff579b8":"code","081b44f9":"code","e1367358":"code","a8c5c0d8":"code","68b315b7":"code","0f72d7a6":"code","2aba45bb":"code","b710f06d":"code","9cdd9449":"code","1902e673":"markdown","b69348e8":"markdown","9aa77c54":"markdown","a519fdf1":"markdown","8b995076":"markdown","74b275a7":"markdown","a8a09968":"markdown","a86728e4":"markdown","3ecbeb5f":"markdown","fdf28cf0":"markdown","fddbdb80":"markdown","d6a35162":"markdown","8a81bfe0":"markdown","5c547dd1":"markdown","59c6243e":"markdown","34877eb0":"markdown"},"source":{"32af79b0":"import pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom matplotlib import rcParams\nimport seaborn as sb\nfrom collections import Counter\nimport warnings\nwarnings.filterwarnings(\"ignore\")\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.svm import SVC\nfrom sklearn.tree import DecisionTreeClassifier\nfrom sklearn.ensemble import RandomForestClassifier,GradientBoostingClassifier,VotingClassifier\nfrom sklearn.naive_bayes import GaussianNB,MultinomialNB\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.neural_network import MLPClassifier\nfrom xgboost import XGBClassifier\nfrom sklearn.linear_model import SGDClassifier\nfrom sklearn.naive_bayes import BernoulliNB\nfrom xgboost import XGBClassifier\nfrom sklearn.preprocessing import LabelEncoder,normalize,MinMaxScaler\nfrom sklearn.metrics import f1_score\nfrom sklearn.model_selection import train_test_split,cross_val_score\nfrom sklearn.metrics import confusion_matrix,roc_auc_score,roc_curve\nimport seaborn as sns","eb5eb796":"import tensorflow as tf\n\n# GPU device Check.\ndevice_name = tf.test.gpu_device_name()\nif device_name == '\/device:GPU:0':\n    print('Found GPU at: {}'.format(device_name))\nelse:\n    raise SystemError('GPU device not found')","4fa1e39c":"import torch\n\n# If there's a GPU available...\nif torch.cuda.is_available():    \n\n    # PyTorch use the GPU.    \n    device = torch.device(\"cuda\")\n\n    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n\n    print('We will use the GPU:', torch.cuda.get_device_name(0))\n\n# If not...\nelse:\n    print('No GPU available, using the CPU instead.')\n    device = torch.device(\"cpu\")","a75c85e0":"# Reading data\ntrain = pd.read_csv('..\/input\/higgs-boson\/training.zip')\ntest = pd.read_csv('..\/input\/higgs-boson\/test.zip')","0f89b07a":"train.head()","51578c57":"test.head()","768a1f8d":"print(train.columns.values,'\\n')\nprint(test.columns.values)","c65de577":"train = train.drop(['Weight'], axis=1)","72d87222":"print(train['Label'].value_counts())\n\nrcParams['figure.figsize'] = 10,5\nsb.barplot(x = train['Label'].value_counts().index, y = train['Label'].value_counts().values)\nplt.title('Label counts')\nplt.show()","6d4af551":"# getting dummy variables column\n\nenc = LabelEncoder()\n\ntrain['Label'] = enc.fit_transform(train['Label'])\ntrain.head()","5b0b9f67":"y = train[\"Label\"]\nX = train\nX_test = test","09c210ec":"X.set_index(['EventId'],inplace = True)\nX_test.set_index(['EventId'],inplace = True)\nX = X.drop(['Label'], axis=1)\n\nX.head()","3ed30910":"X_test.head()","214a72a7":"train.describe()","813f4208":"# #Normalizing\n\n# no = 1\n\n# X[\"PRI_jet_all_pt\"]=((X[\"PRI_jet_all_pt\"]-X[\"PRI_jet_all_pt\"].min())\/(X[\"PRI_jet_all_pt\"].max()-X[\"PRI_jet_all_pt\"].min()))*no\n# X_test[\"PRI_jet_all_pt\"]=((X_test[\"PRI_jet_all_pt\"]-X_test[\"PRI_jet_all_pt\"].min())\/(X_test[\"PRI_jet_all_pt\"].max()-X_test[\"DER_mass_MMC\"].min()))*no\n\n# X[\"PRI_jet_subleading_pt\"]=((X[\"PRI_jet_subleading_pt\"]-X[\"PRI_jet_subleading_pt\"].min())\/(X[\"PRI_jet_subleading_pt\"].max()-X[\"PRI_jet_subleading_pt\"].min()))*no\n# X_test[\"PRI_jet_subleading_pt\"]=((X_test[\"PRI_jet_subleading_pt\"]-X_test[\"PRI_jet_subleading_pt\"].min())\/(X_test[\"PRI_jet_subleading_pt\"].max()-X_test[\"PRI_jet_subleading_pt\"].min()))*no\n\n# X[\"PRI_jet_leading_pt\"]=((X[\"PRI_jet_leading_pt\"]-X[\"PRI_jet_leading_pt\"].min())\/(X[\"PRI_jet_leading_pt\"].max()-X[\"PRI_jet_leading_pt\"].min()))*no\n# X_test[\"PRI_jet_leading_pt\"]=((X_test[\"PRI_jet_leading_pt\"]-X_test[\"PRI_jet_leading_pt\"].min())\/(X_test[\"PRI_jet_leading_pt\"].max()-X_test[\"PRI_jet_leading_pt\"].min()))*no\n\n# X[\"PRI_met_sumet\"]=((X[\"PRI_met_sumet\"]-X[\"PRI_met_sumet\"].min())\/(X[\"PRI_met_sumet\"].max()-X[\"PRI_met_sumet\"].min()))*no\n# X_test[\"PRI_met_sumet\"]=((X_test[\"PRI_met_sumet\"]-X_test[\"PRI_met_sumet\"].min())\/(X_test[\"PRI_met_sumet\"].max()-X_test[\"PRI_met_sumet\"].min()))*no\n\n# X[\"DER_sum_pt\"]=((X[\"DER_sum_pt\"]-X[\"DER_sum_pt\"].min())\/(X[\"DER_sum_pt\"].max()-X[\"DER_sum_pt\"].min()))*no\n# X_test[\"DER_sum_pt\"]=((X_test[\"DER_sum_pt\"]-X_test[\"DER_sum_pt\"].min())\/(X_test[\"DER_sum_pt\"].max()-X_test[\"DER_sum_pt\"].min()))*no\n\n# X[\"DER_mass_jet_jet\"]=((X[\"DER_mass_jet_jet\"]-X[\"DER_mass_jet_jet\"].min())\/(X[\"DER_mass_jet_jet\"].max()-X[\"DER_mass_jet_jet\"].min()))*no\n# X_test[\"DER_mass_jet_jet\"]=((X_test[\"DER_mass_jet_jet\"]-X_test[\"DER_mass_jet_jet\"].min())\/(X_test[\"DER_mass_jet_jet\"].max()-X_test[\"DER_mass_jet_jet\"].min()))*no\n\n# X[\"DER_pt_h\"]=((X[\"DER_pt_h\"]-X[\"DER_pt_h\"].min())\/(X[\"DER_pt_h\"].max()-X[\"DER_pt_h\"].min()))*no\n# X_test[\"DER_pt_h\"]=((X_test[\"DER_pt_h\"]-X_test[\"DER_pt_h\"].min())\/(X_test[\"DER_pt_h\"].max()-X_test[\"DER_pt_h\"].min()))*no\n\n# X[\"DER_mass_vis\"]=((X[\"DER_mass_vis\"]-X[\"DER_mass_vis\"].min())\/(X[\"DER_mass_vis\"].max()-X[\"DER_mass_vis\"].min()))*no\n# X_test[\"DER_mass_vis\"]=((X_test[\"DER_mass_vis\"]-X_test[\"DER_mass_vis\"].min())\/(X_test[\"DER_mass_vis\"].max()-X_test[\"DER_mass_vis\"].min()))*no\n\n# X[\"DER_mass_transverse_met_lep\"]=((X[\"DER_mass_transverse_met_lep\"]-X[\"DER_mass_transverse_met_lep\"].min())\/(X[\"DER_mass_transverse_met_lep\"].max()-X[\"DER_mass_transverse_met_lep\"].min()))*no\n# X_test[\"DER_mass_transverse_met_lep\"]=((X_test[\"DER_mass_transverse_met_lep\"]-X_test[\"DER_mass_transverse_met_lep\"].min())\/(X_test[\"DER_mass_transverse_met_lep\"].max()-X_test[\"DER_mass_transverse_met_lep\"].min()))*no\n\n# X[\"DER_mass_MMC\"]=((X[\"DER_mass_MMC\"]-X[\"DER_mass_MMC\"].min())\/(X[\"DER_mass_MMC\"].max()-X[\"DER_mass_MMC\"].min()))*no\n# X_test[\"DER_mass_MMC\"]=((X_test[\"DER_mass_MMC\"]-X_test[\"DER_mass_MMC\"].min())\/(X_test[\"DER_mass_MMC\"].max()-X_test[\"DER_mass_MMC\"].min()))*no\n\n\n# X.head()","26861a66":"# # normalize the data attributes\n# X = X.apply(lambda x: (x - np.mean(x)) \/ (np.max(x) - np.min(x)))\n\n# X_test = X_test.apply(lambda x: (x - np.mean(x)) \/ (np.max(x) - np.min(x)))\n\n\n# X.head()","304f5baa":"#Normalizing\n\nfrom sklearn.preprocessing import normalize\n\nX = normalize(X)\nX_test = normalize(X_test)","252d4c23":"# print(X.isnull().sum(),'\\n')\n# print(X_test.isnull().sum())","ed36833c":"#X = X.replace(-999.000,np.nan)\n#X.head()","c8d93125":"#X_test = X_test.replace(-999.000,np.nan)","612119b0":"#X_test.head()","943672d2":"#X = X.replace(-999.000,0)\n#X_test = X_test.replace(-999.000,0)\n#X.head()","d72d3777":"#print(X.isnull().sum(),'\\n')\n#print(X_test.isnull().sum())","8c892292":"#X.fillna(X.median(), inplace=True)\n#X_test.fillna(X_test.median(), inplace=True)\n\n#X.head()","5e4876cb":"#X.tail(1000)","7434db7d":"X_train,X_test,y_train,y_test = train_test_split(X,y,random_state = 10,test_size=0.2,shuffle =True)","a3566b98":"logistic_regression= LogisticRegression()\nlogistic_regression.fit(X_train,y_train)\ny_pred=logistic_regression.predict(X_test)","931a339a":"# fit the model on the whole dataset\nrandom_forest = RandomForestClassifier()\n\nrandom_forest.fit(X_train, y_train)","ecf4b58f":"decisionTreeModel = DecisionTreeClassifier(criterion= 'entropy',\n                                           max_depth = None, \n                                           splitter='best', \n                                           random_state=10)\n\ndecisionTreeModel.fit(X_train,y_train)","50453dbf":"# gradientBoostingModel = GradientBoostingClassifier(loss = 'deviance',\n#                                                    learning_rate = 0.01,\n#                                                    n_estimators = 100,\n#                                                    max_depth = 30,\n#                                                    random_state=10)\n\n# gradientBoostingModel.fit(X_train,y_train)","d6890fca":"KNeighborsModel = KNeighborsClassifier(n_neighbors = 7,\n                                       weights = 'distance',\n                                      algorithm = 'brute')\n\nKNeighborsModel.fit(X_train,y_train)","5d6272fd":"# SGDClassifier = SGDClassifier(loss = 'hinge', \n#                               penalty = 'l1',\n#                               learning_rate = 'optimal',\n#                               random_state = 10, \n#                               max_iter=100)\n\n# SGDClassifier.fit(X_train,y_train)","d41bb5fc":"# SVClassifier = SVC(kernel= 'linear',\n#                    degree=3,\n#                    max_iter=10000,\n#                    C=2, \n#                    random_state = 55)\n\n# SVClassifier.fit(X_train,y_train)","79907b16":"bernoulliNBModel = BernoulliNB(alpha=0.1)\nbernoulliNBModel.fit(X_train,y_train)","a8e890fd":"gaussianNBModel = GaussianNB()\ngaussianNBModel.fit(X_train,y_train)","ea5030a0":"XGB_Classifier = XGBClassifier()\nXGB_Classifier.fit(X_train, y_train)","d13500c3":"#evaluation Details\nmodels = [logistic_regression, random_forest, decisionTreeModel, KNeighborsModel, \n            bernoulliNBModel, gaussianNBModel, XGB_Classifier]\n\nfor model in models:\n    print(type(model).__name__,' Train Score is   : ' ,model.score(X_train, y_train))\n    print(type(model).__name__,' Test Score is    : ' ,model.score(X_test, y_test))\n    \n    y_pred = model.predict(X_test)\n    print(type(model).__name__,' F1 Score is      : ' ,f1_score(y_test,y_pred))\n    print('--------------------------------------------------------------------------')","11f242d9":"y_pred = XGB_Classifier.predict(X_test)","0940deb1":"import seaborn as sn\n\nconfusion_matrix = pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'])\nsn.heatmap(confusion_matrix, annot=True)","005b73de":"from sklearn.metrics import accuracy_score,classification_report\n\nprint(accuracy_score(y_test,y_pred).round(4)*100,'\\n')\n\nprint(pd.crosstab(y_test,y_pred),'\\n')\n\nprint(classification_report(y_test,y_pred),'\\n')","4772a645":"X_test.shape","9032c852":"test.shape","1f35e47c":"test_to_pred = normalize(test)","e344abc3":"test_predict = XGB_Classifier.predict(test_to_pred)","94d89129":"test.reset_index(inplace = True)\ntest.head()","e8b343aa":"predict = test['EventId']","ec670234":"test_predict = pd.Series(test_predict)","8ff579b8":"predict = pd.concat([predict,test_predict], axis=1)","081b44f9":"predict.rename(columns={0: \"Class\"},inplace=True)","e1367358":"predict = predict.replace(1,'s')\npredict = predict.replace(0,'b')","a8c5c0d8":"predict['RankOrder'] = predict['Class'].argsort().argsort() + 1 # +1 to start at 1","68b315b7":"predict = predict[['EventId', 'RankOrder','Class']]","0f72d7a6":"predict.to_csv(\"submission.csv\",index=False)","2aba45bb":"predict.tail(200)","b710f06d":"print(predict.RankOrder.min())\nprint(predict.RankOrder.max())","9cdd9449":"sb.countplot(predict.Class)","1902e673":"1- Logistic Regression Model","b69348e8":"6- Stochastic Gradient Descent Model","9aa77c54":"10- XGBoost Model","a519fdf1":"8- Bernoulli Naive Bayes Model","8b995076":"3- Decision Tree Model","74b275a7":"Data Preparation","a8a09968":"9- Gaussian Naive Bayes Model","a86728e4":"5- Nearest Neighbors Model","3ecbeb5f":"7- Support Vector Machine Model","fdf28cf0":"2- Random Forest Model","fddbdb80":"Read data","d6a35162":"4- Gradient Boosting Model","8a81bfe0":"Prediction","5c547dd1":"I will use XGBClassifier Model","59c6243e":"**Models evaluation**","34877eb0":"train shape: 100 rows \u00d7 33 columns\n\ntest shape: 5 rows \u00d7 31 columns"}}