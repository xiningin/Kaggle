{"cell_type":{"02c7b320":"code","dc911778":"code","f7dd0c40":"code","955b1157":"code","08f457bb":"code","a71d3755":"code","2ea83cf3":"code","aad8f253":"code","c4ff4092":"code","81185ee6":"code","910fb8de":"code","b2c92cb7":"code","9258c1e3":"code","7a292f36":"code","903758b4":"code","39a9e6e2":"code","70280992":"code","b789984c":"code","9a6660cd":"code","27e676d3":"code","7247ae02":"code","cbe2ccce":"code","6c3111b8":"code","a68d309e":"code","e77a7403":"code","3f0bc4ea":"code","1f08027e":"code","66326fec":"code","31d0a571":"code","814d9a47":"code","faae38b9":"code","599b6593":"code","709948b6":"code","51c7b5bc":"code","5e47eecb":"code","c61c5c50":"code","12c79095":"code","d8723e5e":"code","40ce0d01":"code","e78de2aa":"code","06fcb618":"code","b002fbd2":"code","d804c629":"code","43956c74":"code","6746f542":"code","431bc5df":"code","06beece6":"code","eb711159":"code","0b85556f":"code","e58963ea":"code","643eb628":"code","999e35c5":"code","d0aa6c65":"code","05f3a33f":"code","0ab529f4":"code","a2e3f752":"code","b2cf5a5b":"code","7aa4d9c8":"code","d6a7bf28":"code","e193f7d3":"code","d5beca81":"code","dcb60083":"code","670d0209":"code","ea2283ab":"code","104adb9e":"code","099b2cc1":"code","d4cfd21e":"code","b3715726":"code","293eba78":"code","1d061629":"code","7d731bca":"code","bc3ee3a4":"code","8577757f":"code","77d06c99":"code","74b24b9a":"code","acebac69":"code","2fe0ab35":"code","bbed33a6":"code","7af74a2a":"code","ab3ff3f4":"code","020e0c87":"code","ffbbb03d":"code","4ca8acfd":"code","50a643aa":"code","adae856c":"code","e3015c62":"code","f39eced2":"code","c9563a3f":"code","f305894b":"code","60974402":"code","3bf11415":"code","c008ed83":"code","bf32d6ef":"code","6c11f02b":"code","f42e44f6":"code","33b8677b":"code","b8ab1c48":"code","41a107ea":"code","1f152bb1":"code","4c8b6fb5":"code","7b4062c8":"code","bdaa9754":"code","64ca8607":"code","cf913cdc":"code","3c4dafd9":"code","14e71522":"code","012ac98b":"code","c25cab91":"code","10095c0c":"code","99be6156":"code","a12f2bfa":"code","5ef5c96d":"code","d500d043":"code","3837d3cc":"code","424d3e2a":"code","f9d48973":"code","c22de9a0":"code","05235580":"code","bf944e88":"code","f3113673":"code","f9bdbe12":"code","d34732e9":"code","5d33ae37":"code","f1c38bdb":"code","ee19f8ce":"code","f0f2c643":"code","46757ee8":"code","3e2bc89a":"code","22a4d6e4":"code","c2eecefb":"code","ea94911b":"code","9120a047":"code","e0793c38":"code","fd3068f4":"code","333aa519":"code","2c3c5444":"code","15b7bdfe":"code","33e1c283":"code","efdc7ccb":"code","0cf5299a":"code","978d3f1a":"code","dfa323e7":"code","3a0c087b":"code","45915b4d":"code","dac2358f":"code","93b82b1f":"code","666ca3d4":"code","6f9f82d5":"code","9bbc30fe":"code","aebd2fc1":"code","d9e7e258":"code","617e8f36":"code","6b1340b2":"code","ac982a69":"code","bfe17c2d":"code","2af31a8c":"code","a4630493":"code","47432db3":"code","c0f8b1c2":"code","7da951ca":"code","8d441b36":"code","da05291f":"code","afba6091":"code","b395c7e2":"code","904f9fad":"code","e4befc9d":"code","5784a082":"code","11a86316":"code","c3a962bb":"code","3ca07c40":"code","8891b918":"code","3e426c17":"code","2de88970":"code","4b470c12":"code","7ff03fb5":"code","f57bf7f1":"code","b344e54d":"code","4f9235b1":"code","a8612e34":"code","3b8bea44":"code","5522ae6c":"code","ba7a8627":"code","ba2e4124":"code","0cfc26e4":"code","e6374c28":"code","56d9c11f":"code","bf184fc8":"code","03396075":"code","4d8244c1":"code","5bb029de":"code","fae7536c":"code","868cb56b":"code","65904d4c":"code","df16f00f":"code","3c2a5046":"code","a609922f":"code","a802c93a":"code","cc7d4e30":"code","2b1965d1":"code","893e8370":"code","57573740":"code","f961669e":"code","e52924bf":"code","c3928ad4":"code","b32d5891":"code","e1cc66b4":"code","6f7aceeb":"code","dbc61034":"code","26124586":"code","72b763ec":"code","732ba96b":"code","c1c5dc0b":"code","85dd27ef":"code","aec56a0a":"code","ec24689a":"code","99d43fb8":"code","337fee51":"code","98688a83":"code","8b36e812":"code","9610d971":"code","89f686a8":"code","dcf68d83":"code","6de067e1":"code","e605fb34":"code","ef63017e":"code","2e7d7e28":"code","1dec443a":"code","4c945b07":"code","a91c061f":"code","6b2176c1":"code","a7d458c2":"code","41bc2f2c":"code","5424dc06":"code","13d80713":"code","f89787ee":"code","c9baa3a1":"code","a5bce50a":"code","ed351dfe":"code","a68b8fa9":"code","24ba4eb6":"code","bac33487":"code","2966d124":"code","a42703dd":"code","c5b6a7c8":"code","ef418c3b":"code","2868a556":"code","9e438e3f":"code","9b558e93":"code","98004aaf":"code","70f97858":"code","c1ee941e":"code","9034c52f":"code","af2bf011":"code","eda4bcfc":"code","6189f501":"code","daedb12d":"code","f413db2a":"code","dfda89e4":"code","a69bdfbe":"code","3ee1567c":"code","651f2d7f":"code","b7061561":"code","a74a444c":"code","2252db23":"code","8eb980e8":"code","b0c304a6":"code","faed3f83":"code","3193d89d":"code","1767fde0":"code","74a3a399":"code","a700e481":"code","3c91ccb6":"code","98b16ba2":"code","0f0c156d":"code","916d4d0c":"code","d588ce3b":"code","e35f82b1":"code","a5e2f4a4":"code","53541d43":"code","560df9d2":"code","dec296b9":"code","1e128bb4":"code","58f7d070":"code","1ce68aef":"code","d65eff24":"code","80297fc9":"code","1f9ba89c":"code","ba7198d9":"code","1d67e495":"code","2918bbdc":"code","fc6a271d":"code","c1aa26d1":"code","253cb86f":"code","0f9a1581":"code","13e71693":"code","9c9105bf":"code","97d502a8":"code","72878ec8":"code","a04a7d5c":"code","e9b3f3a4":"code","871dfbe5":"code","2c4fa619":"code","1463df77":"code","3eb3bb70":"code","93414016":"code","77c2d415":"code","2cdab47a":"code","bc45f696":"code","30b5fcff":"code","85b98fcd":"code","01953132":"code","d875d0d8":"code","64210fb4":"code","96f6c353":"code","f317e050":"code","f3fd8008":"code","3ae74ff3":"code","bbe5c3d7":"code","16aa2f8a":"code","1823acad":"code","863e7ef7":"code","b0c4a7f7":"code","bf001d38":"code","1f4a4386":"code","0cdd261c":"code","84538fd9":"code","d068f349":"code","e43e42af":"code","5eb85225":"code","8e78d4a0":"code","bc9adc9f":"code","79907cba":"code","c22fdde8":"code","ea7ca2b2":"code","a6120663":"code","34ec6254":"code","973c7cb0":"code","94e32db4":"code","f86e807a":"code","4a4a561a":"code","77179d05":"code","c24c4f66":"code","444aaee0":"code","b7027522":"code","3f1a834d":"code","366954af":"code","e952b673":"code","51e190d2":"code","40a07e40":"code","3d5961b2":"code","0cce0228":"code","31ce35f8":"code","8a9ad093":"code","e8a7011a":"code","2e00ed8f":"code","a2dfed30":"code","eeb7e5b3":"code","3ef54daa":"code","4d263636":"code","cbe91798":"code","b422e2c5":"code","9e74dc8b":"code","c1989e01":"code","4dad0762":"code","aa54717b":"code","4292d9fa":"code","57951909":"code","42e73e44":"code","c0a3945d":"code","261e19a3":"code","393788e5":"code","51f4295b":"code","a03b4a40":"code","ebcb3def":"code","a026ef52":"code","c7be087e":"code","ca22707e":"code","f888810a":"code","a3f31eb1":"code","5ecd3605":"code","4517ebf2":"code","404109c3":"code","95fb837a":"code","53bd6f3b":"code","4a8dc70d":"code","a2ad6328":"code","a5464787":"code","c1ddcc0b":"code","806ec351":"code","39bb3ed7":"code","85a312ac":"code","68de6b53":"code","dba38735":"code","c6b166c1":"code","e0bf2dc1":"code","f701b97f":"code","3ba7c26e":"code","f00e85ca":"code","ac88c908":"code","0f46ea1b":"code","7771574e":"code","432cfc50":"code","6fa3090a":"code","d234635f":"code","2c61b3b4":"code","7d8bdc12":"code","1fd13c1b":"code","5bed501c":"code","d3467aa9":"code","45fc7cfb":"code","2a2628d9":"code","692e75a7":"code","ee52ce8d":"code","c6920734":"code","955673c3":"code","f9054657":"code","3ab77fd1":"code","37bad3ac":"code","8f9bf059":"code","afeea0b6":"code","c7350a4e":"code","6203c38c":"code","faf57d2a":"code","deb9c144":"code","06498d15":"code","43660209":"code","0655e60b":"code","1798db57":"code","b547ca57":"code","d6083dc1":"code","bdd5219a":"code","6c6958f8":"code","f5478798":"code","7299fc5b":"code","1169a986":"code","1e7f652b":"code","5303e502":"code","d813ebb4":"code","87aef179":"code","2f999589":"code","d1532d4c":"code","612d137a":"code","2981a3a2":"code","393ab002":"code","cade8ca9":"code","79815851":"code","eb0f541e":"code","4ac5947d":"code","0aef4744":"code","0f670d2c":"code","978150ae":"code","aea0f8d0":"code","222c373a":"code","3360c53f":"code","13af9be4":"code","e99361bb":"code","58a0adb5":"code","d3935171":"code","156ae99b":"code","8462800c":"code","49ae1d74":"code","985de78c":"code","b153e0d2":"code","d151e789":"code","03307295":"code","7716f7e9":"code","f77c2c0e":"code","04353824":"code","d9ee2396":"code","7d9c5cb2":"code","da978fc7":"code","55ba36c4":"code","0294bcd5":"code","783a4704":"code","8333c477":"code","bbc10c64":"code","8d2ad021":"code","19eee886":"code","60db8b9a":"code","55e0cf1a":"code","7caa9478":"code","3c6bd8ec":"code","841ca54e":"code","8a5b64a7":"code","3b96475f":"code","7bab9729":"code","a1848adf":"code","9b31aa1b":"code","b07a4275":"code","ee2fdce5":"code","4e2a6dc3":"code","67768ca9":"code","a6247b89":"code","ca581641":"code","a026db24":"code","f34468ac":"code","f59bc43e":"code","fb3504ab":"code","37073123":"code","0bc8e152":"code","7d73048a":"code","d5a512c6":"code","247bc650":"code","ce1ec6a8":"code","7ec11e58":"code","41dd1465":"code","e1200b83":"code","58c397b6":"code","779bab4a":"code","e10bc8ae":"code","b889d23f":"code","bf87d4fe":"code","6e51a41f":"code","67ccc3a2":"code","5cbddafd":"code","6fc859d6":"code","5b9162b0":"code","27021009":"code","96b56a50":"code","b58c656e":"code","bbbf5f34":"code","36ec13f2":"code","731f3567":"code","16ecbfc6":"code","bbf3f5d2":"code","e4f30aab":"code","8a125acb":"code","35884b7a":"code","1e5ed2a5":"code","09d48713":"code","4fe27bfd":"code","1112a8ee":"code","0324d8eb":"code","71de36de":"code","cc72c8ba":"code","ab892611":"code","5bbcf3df":"code","377a25a3":"code","b197eb6d":"code","edca1671":"code","ee25210b":"code","9ae64ffe":"code","b1b772fb":"code","ecf33772":"code","88e299d8":"code","88656bd8":"code","24ec4311":"code","0b67e41b":"code","b925cf9a":"code","2c8ad224":"code","0fea34ad":"code","f8eed1e9":"code","e6f3e969":"code","5e1dba5c":"code","2caf3673":"code","bebca4f5":"code","f786be0e":"code","2a9c8007":"code","af76f641":"code","4b4084ad":"code","1115a6f6":"code","ff76a656":"code","387c0e6f":"code","432a2db3":"code","48fd464f":"code","ccccff07":"code","cfa1ce1c":"code","b1fa58e2":"code","7a65c1b2":"code","26b28653":"code","c4ea6207":"code","2812a4e8":"code","a1f86fea":"code","9128be2d":"code","f44fd2e3":"code","94f156b3":"code","df1d2419":"code","5026d377":"code","0bcbc923":"code","df5ac4bf":"code","649dec5e":"code","1a8d7552":"code","fb072b47":"code","7230f09e":"code","b839f71c":"code","7eaed8ac":"code","0859149a":"code","223f8c9b":"code","2e3d212c":"code","e62294ba":"code","41e08ccc":"code","39a469b8":"code","44469761":"code","23f5f702":"code","e3f54ae0":"code","61c870bc":"code","cc4d86f2":"code","f28fdb28":"code","ea63976d":"code","036bc744":"code","f390e235":"code","0c56689b":"code","89d84450":"code","a8eb8601":"code","3ac7f9fc":"code","ae5da14f":"code","f74c270b":"code","3ca4e81e":"code","be2ac573":"code","a7cfa43a":"code","26a7a44d":"code","eef244a9":"code","d6160ef1":"code","ee453485":"code","03b1b308":"code","4c6f82f7":"code","503136be":"markdown","4e2ef29b":"markdown","14e5a0a6":"markdown","ee3db65c":"markdown","74788f71":"markdown","67ce79f4":"markdown","2494a42f":"markdown","0f9b8ec9":"markdown","9adb1555":"markdown","f6c2cd95":"markdown","2cb75617":"markdown","a0b0b76d":"markdown","85aa3886":"markdown","8f223df6":"markdown","60a14cdb":"markdown","d0320620":"markdown","82f600ed":"markdown","14c7dac2":"markdown","169304e2":"markdown","18a4da8b":"markdown","d35f2126":"markdown","d45a6d4a":"markdown","a4296f39":"markdown","00c4dcdb":"markdown","965f48ec":"markdown","420efbb1":"markdown","a7240cf1":"markdown","7f87a4ed":"markdown","ea89736f":"markdown","229d9e64":"markdown","6cce5c02":"markdown","a8adae9f":"markdown","2baae25b":"markdown","3bc569c7":"markdown","006c7dae":"markdown","3021fdf9":"markdown","7e8d8105":"markdown","7191823f":"markdown","48427b71":"markdown","a5402fd1":"markdown","720a0f24":"markdown","d83aea1e":"markdown","115cb3ac":"markdown","cad78f63":"markdown","bbe317b8":"markdown","c962864f":"markdown","78922087":"markdown","7edc9bf0":"markdown","e763db3c":"markdown","2784ce6d":"markdown","35d409a7":"markdown","8f096306":"markdown","e6d176cf":"markdown","5ba6510f":"markdown","7fc2f8fe":"markdown","56497b52":"markdown","64654713":"markdown","f8aceabc":"markdown","78441c78":"markdown","21495428":"markdown","17a2ce98":"markdown","053e9a37":"markdown","46e25928":"markdown","38e835a2":"markdown","f6729103":"markdown","ca0fadce":"markdown","6e3c9c58":"markdown","62853fdd":"markdown","b0bbf0ee":"markdown","7cc3e73c":"markdown","fff37ead":"markdown","193dbf0a":"markdown","fd3746dd":"markdown","0ea1b959":"markdown","2f175c72":"markdown","cac7c86f":"markdown","36b8e186":"markdown","1901c7ba":"markdown","3a75609c":"markdown","a2c3f88f":"markdown","67f23fa7":"markdown","137679f4":"markdown","9347bf01":"markdown","7b81e25d":"markdown","11adf821":"markdown","5bb5152d":"markdown","3b7e09b2":"markdown","51638516":"markdown","05bf7a2e":"markdown","f7b88b5e":"markdown","167d25ab":"markdown","ea609e0b":"markdown","f40f70bd":"markdown","f2596c47":"markdown","fa2b57ad":"markdown","fe90f82a":"markdown","810bf5ac":"markdown","bd7c68aa":"markdown","fe612cb7":"markdown","2ba45eda":"markdown","53d3c10c":"markdown","d4d37098":"markdown","f34b360a":"markdown","4a5b4258":"markdown","743afff4":"markdown","eb13366f":"markdown","5dee049f":"markdown","fa7be03e":"markdown","1169e81b":"markdown","6c7c81b4":"markdown","42f29866":"markdown","2729b971":"markdown","d82c6aa1":"markdown","3c3149ba":"markdown","048306d4":"markdown","252acf1e":"markdown","ba8e5838":"markdown","2f669c35":"markdown","7433a62a":"markdown","8f358217":"markdown","42cd6bd5":"markdown","e3cae109":"markdown","c140f075":"markdown","2cfe7f6e":"markdown","b2fea2c9":"markdown","691a7bad":"markdown","310b10e3":"markdown","6a2ea954":"markdown","9176d8bc":"markdown","594d75b0":"markdown","c5e56d0a":"markdown","bfb9198f":"markdown","85fe9f51":"markdown","56e92179":"markdown","922a3a67":"markdown","f978c20e":"markdown","9f2d84da":"markdown","85cefe03":"markdown","b232323c":"markdown","4dc07719":"markdown","0a9bc9b6":"markdown","3b950bb4":"markdown","d40e8533":"markdown","618fc5a5":"markdown","2b612337":"markdown","672a202d":"markdown","aafe6948":"markdown","914273a8":"markdown","1c3edd8e":"markdown","ed6f24ed":"markdown","b6c18a58":"markdown","f02033bc":"markdown","a2e67c89":"markdown","c9e1a338":"markdown","be59c340":"markdown","7b82b755":"markdown","e468e73c":"markdown","768d1217":"markdown","7bf09cd3":"markdown","59f80fdb":"markdown","bd94a801":"markdown","a19881ad":"markdown","bf1ba7db":"markdown","dea9c445":"markdown","23279c65":"markdown","d304e753":"markdown","e1e64351":"markdown","ef16eafc":"markdown","89baed20":"markdown"},"source":{"02c7b320":"#Importing the required libraries\nimport numpy as np\nimport pandas as pd\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\n\nfrom sklearn import metrics\nfrom sklearn import preprocessing\n\nfrom scipy.stats import kurtosis\nfrom scipy.stats import skew\n\nfrom sklearn.preprocessing import StandardScaler\nfrom sklearn.preprocessing import PowerTransformer\n\nfrom sklearn.tree    import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score,recall_score\n\n# GridSearchCV to find optimal min_samples_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV\n\n# Importing random forest classifier from sklearn library\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.linear_model import LogisticRegression\nimport statsmodels.api as sm\nfrom sklearn.neighbors import KNeighborsClassifier\n\n#Importing the libraries for XGBoost.\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance\n\n# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","dc911778":"#Suppress warnings\nimport warnings\nwarnings.filterwarnings('ignore')","f7dd0c40":"import time","955b1157":"#To display a max of 40 columns of the dataframe\npd.set_option('display.max_columns',40)","08f457bb":"#Reading the dataset to the dataframe df\ndf = pd.read_csv(\"\/kaggle\/input\/creditcardfraud\/creditcard.csv\")","a71d3755":"#Head of the dataset\ndf.head()","2ea83cf3":"#Dimension of the dataframe\ndf.shape","aad8f253":"#More information of the data type of the features.\ndf.info()","c4ff4092":"df.describe()","81185ee6":"#Checking the timeline of the transactions present in the dataframe\nmax(df['Time'])\/(60*60)","910fb8de":"classes=df['Class'].value_counts()\nnormal_share=classes[0]\/df['Class'].count()*100\nfraud_share=classes[1]\/df['Class'].count()*100","b2c92cb7":"# Create a bar plot for the number and percentage of fraudulent vs non-fraudulent transcations\ndist_df = pd.DataFrame({'Percentage':[normal_share,fraud_share]},index=['Normal','Fraudulent'])\nsns.barplot(x=dist_df.index,y=dist_df['Percentage'],palette='RdYlGn')\nplt.title('Fraudulent vs Non-Fraudulent')\nplt.show()","9258c1e3":"dist_df","7a292f36":"# Create a scatter plot to observe the distribution of classes with time\nsns.scatterplot(x=df['Time'],y=df['Class'])\nplt.show()","903758b4":"# Create a scatter plot to observe the distribution of classes with Amount\nsns.scatterplot(x=df['Class'],y=df['Amount'])\nplt.show()","39a9e6e2":"# Drop unnecessary columns\ndf.drop(['Time'],axis=1,inplace=True)","70280992":"sns.boxplot(y=df['Amount'])\nplt.show()","b789984c":"df.loc[df['Amount']>=10000]","9a6660cd":"df.loc[df['Amount']>=10000]['Amount'].count()","27e676d3":"#Before removing the records\ndf.shape","7247ae02":"df = df.loc[df['Amount']<10000]","cbe2ccce":"#We can recheck the stats for the amount column now again, after removing the Outliers.\nprint(df['Amount'].describe())","6c3111b8":"fig, ax = plt.subplots(1, 2, figsize=(18,4))\n\n#plt.subplot(121)\nsns.distplot(df[df['Class']==0]['Amount'],bins=50, ax=ax[0], color='brown')\nax[0].set_title('Amount distribution for Non-fraudulent transactions', fontsize=10)\n\n#plt.subplot(122)\nsns.distplot(df[df['Class']==1]['Amount'],bins=50, ax=ax[1], color='purple')\nax[1].set_title('Amount distribution for fraudulent transactions', fontsize=10)","a68d309e":"#Finding the Min-Max values for fraudulent and valid transactions after the Outlier Removal.\nprint('Min amount for a fraudulent transaction:', df[df['Class']==1]['Amount'].min())\nprint('Max amount for a fraudulent transaction:', df[df['Class']==1]['Amount'].max())\nprint('Min amount for a valid transaction:', df[df['Class']==0]['Amount'].min())\nprint('Max amount for a valid transaction:', df[df['Class']==0]['Amount'].max())","e77a7403":"print('No of transactions where amount is 0 for fraudulent transactions:', \n      df[(df['Class']==1) & (df['Amount']==0)].shape[0])\nprint('No of transactions where amount is 0 for valid transactions:', \n      df[(df['Class']==0) & (df['Amount']==0)].shape[0])","3f0bc4ea":"plt.figure(figsize=(17,8))\nsns.heatmap(round(df.corr(),2),annot=True,cmap='Blues')\nplt.show()","1f08027e":"#Maintaining a copy of the dataframe\ndf_copy1 = df.copy()","66326fec":"X = df.drop(['Class'],axis=1)\ny= df['Class']","31d0a571":"#Number of Class 1 records\nlen(y.loc[y==1])","814d9a47":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X,y,train_size=0.7,test_size=0.3,random_state=100)","faae38b9":"X_train.shape","599b6593":"X_test.shape","709948b6":"y_train.shape","51c7b5bc":"y_test.shape","5e47eecb":"X_test_copy = X_test.copy()","c61c5c50":"y_test_copy = y_test.copy()","12c79095":"len(y_train.loc[y==1])","d8723e5e":"len(y_test.loc[y==1])","40ce0d01":"# Defining a function that can be useful for violin plot\ndef pltViolin(subpltnum,colName,dfObj,hueCol=None):\n    if ',' in str(subpltnum):\n        nums=str(subpltnum).split(',')\n        plt.subplot(int(nums[0]),int(nums[1]),int(nums[2]))\n    else:\n        plt.subplot(subpltnum)\n    if hueCol==None:\n        sns.violinplot(y=colName,data=dfObj)\n    else:\n        sns.violinplot(y=colName,data=dfObj,hue=hueCol)\n    \n# Defining a function that can be useful for Bar plot\ndef pltBar(subpltnum,xCol,yCol,dfObj):\n    if ',' in str(subpltnum):\n        nums=str(subpltnum).split(',')\n        plt.subplot(int(nums[0]),int(nums[1]),int(nums[2]))\n    else:\n        plt.subplot(subpltnum)\n    sns.barplot(x=xCol,y=yCol,data=dfObj)\n\n# Defining a function that can be useful for Reg plot\ndef pltReg(subpltnum,xCol,yCol,dfObj):\n    if ',' in str(subpltnum):\n        nums=str(subpltnum).split(',')\n        plt.subplot(int(nums[0]),int(nums[1]),int(nums[2]))\n    else:\n        plt.subplot(subpltnum)\n    sns.regplot(x=xCol,y=yCol,data=dfObj)\n\n# Defining a function that can be useful for box plot\ndef pltBox(subpltnum,xCol,yCol,dfObj,hueCol=None):\n    if ',' in str(subpltnum):\n        nums=str(subpltnum).split(',')\n        plt.subplot(int(nums[0]),int(nums[1]),int(nums[2]))\n    else:\n        plt.subplot(subpltnum)\n    if hueCol==None:\n        sns.boxplot(x=xCol,y=yCol,data=dfObj)\n    else:\n        sns.boxplot(x=xCol,y=yCol,data=dfObj,hue=hueCol)\n        \ndef pltCount(subpltnum,colName,dfObj,hueCol=None,orderCol=None):\n    if ',' in str(subpltnum):\n        nums=str(subpltnum).split(',')\n        plt.subplot(int(nums[0]),int(nums[1]),int(nums[2]))\n    else:\n        plt.subplot(subpltnum)\n\n    if hueCol==None:\n        if orderCol == None:\n            sns.countplot(x=colName,data=dfObj)\n        else:\n            sns.countplot(x=colName,data=dfObj,order=dfObj[orderCol].value_counts().index)\n    else:\n        if orderCol == None:\n            sns.countplot(x=colName,data=dfObj,hue=hueCol)\n        else:\n            sns.countplot(x=colName,data=dfObj,hue=hueCol,order=dfObj[orderCol].value_counts().index)","e78de2aa":"# plot the histogram of a variable from the dataset to see the skewness","06fcb618":"plt.figure(figsize=(16,20))\n\nsubplotNum = \"4,2,\"\npltNum = 1\ncolNumSuf = 1\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n    pltBox(pltNo,'Class',col,df)\n    \n    pltNum = pltNum + 1\n\n    plt.subplot(4,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    \n    pltNum = pltNum + 1","b002fbd2":"plt.figure(figsize=(16,20))\n\nsubplotNum = \"4,2,\"\npltNum = 1\ncolNumSuf = 5\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n    pltBox(pltNo,'Class',col,df)\n    \n    pltNum = pltNum + 1\n\n    plt.subplot(4,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    \n    pltNum = pltNum + 1","d804c629":"plt.figure(figsize=(16,20))\n\nsubplotNum = \"4,2,\"\npltNum = 1\ncolNumSuf = 9\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n    pltBox(pltNo,'Class',col,df)\n    \n    pltNum = pltNum + 1\n\n    plt.subplot(4,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    \n    pltNum = pltNum + 1","43956c74":"plt.figure(figsize=(16,20))\n\nsubplotNum = \"4,2,\"\npltNum = 1\ncolNumSuf = 13\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n    pltBox(pltNo,'Class',col,df)\n    \n    pltNum = pltNum + 1\n\n    plt.subplot(4,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    \n    pltNum = pltNum + 1","6746f542":"plt.figure(figsize=(16,20))\n\nsubplotNum = \"4,2,\"\npltNum = 1\ncolNumSuf = 17\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n    pltBox(pltNo,'Class',col,df)\n    \n    pltNum = pltNum + 1\n\n    plt.subplot(4,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    \n    pltNum = pltNum + 1","431bc5df":"plt.figure(figsize=(16,20))\n\nsubplotNum = \"4,2,\"\npltNum = 1\ncolNumSuf = 21\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n    pltBox(pltNo,'Class',col,df)\n    \n    pltNum = pltNum + 1\n\n    plt.subplot(4,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    \n    pltNum = pltNum + 1","06beece6":"plt.figure(figsize=(16,20))\n\nsubplotNum = \"4,2,\"\npltNum = 1\ncolNumSuf = 25\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n    pltBox(pltNo,'Class',col,df)\n    \n    pltNum = pltNum + 1\n\n    plt.subplot(4,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    \n    pltNum = pltNum + 1","eb711159":"X_train_Summary = pd.DataFrame(X_train.columns.to_list(), columns =['Variables'])","0b85556f":"X_train_Summary['min'] = -100000\nX_train_Summary['max'] = -100000\nX_train_Summary['skew'] = -100000\nX_train_Summary['kurtosis'] = -100000\n\nfor col in X_train.columns.to_list():\n    X_train_Summary.loc[X_train_Summary.Variables == col,'min'] = np.round(X_train[col].min())\n    X_train_Summary.loc[X_train_Summary.Variables == col,'max'] = np.round(X_train[col].max())\n    X_train_Summary.loc[X_train_Summary.Variables == col,'skew'] = np.round(skew(X_train[col]),2)\n    X_train_Summary.loc[X_train_Summary.Variables == col,'kurtosis'] = np.round(kurtosis(X_train[col]),2)","e58963ea":"X_train_Summary","643eb628":"train_num_std = ['Amount']\ntrain_num_yjt = X_train.columns","999e35c5":"yj_trans = PowerTransformer(method='yeo-johnson')\nscaler   = StandardScaler()","d0aa6c65":"# standardization of Amount feature\nX_train[train_num_std] = scaler.fit_transform(X_train[train_num_std].values)\nX_test[train_num_std] = scaler.transform(X_test[train_num_std].values)","05f3a33f":"# power transform\nX_train[train_num_yjt] = yj_trans.fit_transform(X_train[train_num_yjt].values)\nX_test[train_num_yjt] = yj_trans.transform(X_test[train_num_yjt].values)","0ab529f4":"X_train_Summary_pw = pd.DataFrame(X_train.columns.to_list(), columns =['Variables'])","a2e3f752":"X_train_Summary_pw['min'] = -100000\nX_train_Summary_pw['max'] = -100000\nX_train_Summary_pw['skew'] = -100000\nX_train_Summary_pw['kurtosis'] = -100000\n\nfor col in X_train.columns.to_list():\n    X_train_Summary_pw.loc[X_train_Summary_pw.Variables == col,'min'] = np.round(X_train[col].min())\n    X_train_Summary_pw.loc[X_train_Summary_pw.Variables == col,'max'] = np.round(X_train[col].max())\n    X_train_Summary_pw.loc[X_train_Summary_pw.Variables == col,'skew'] = np.round(skew(X_train[col]),2)\n    X_train_Summary_pw.loc[X_train_Summary_pw.Variables == col,'kurtosis'] = np.round(kurtosis(X_train[col]),2)","b2cf5a5b":"X_train_Summary_pw","7aa4d9c8":"plt.figure(figsize=(16,10))\n\nsubplotNum = \"2,2,\"\npltNum = 1\ncolNumSuf = 1\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n\n    plt.subplot(2,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    pltNum = pltNum + 1","d6a7bf28":"plt.figure(figsize=(16,10))\n\nsubplotNum = \"2,2,\"\npltNum = 1\ncolNumSuf = 5\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n\n    plt.subplot(2,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    pltNum = pltNum + 1","e193f7d3":"plt.figure(figsize=(16,10))\n\nsubplotNum = \"2,2,\"\npltNum = 1\ncolNumSuf = 9\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n\n    plt.subplot(2,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    pltNum = pltNum + 1","d5beca81":"plt.figure(figsize=(16,10))\n\nsubplotNum = \"2,2,\"\npltNum = 1\ncolNumSuf = 13\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n\n    plt.subplot(2,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    pltNum = pltNum + 1","dcb60083":"plt.figure(figsize=(16,10))\n\nsubplotNum = \"2,2,\"\npltNum = 1\ncolNumSuf = 17\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n\n    plt.subplot(2,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    pltNum = pltNum + 1","670d0209":"plt.figure(figsize=(16,10))\n\nsubplotNum = \"2,2,\"\npltNum = 1\ncolNumSuf = 21\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n\n    plt.subplot(2,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    pltNum = pltNum + 1","ea2283ab":"plt.figure(figsize=(16,10))\n\nsubplotNum = \"2,2,\"\npltNum = 1\ncolNumSuf = 25\n\nfor i in range(0,4):\n    col = \"V\" + str(colNumSuf)\n    colNumSuf = colNumSuf + 1\n    \n    pltNo = subplotNum + str(pltNum)\n\n    plt.subplot(2,2,pltNum)\n    sns.distplot(X_train[col],bins=50)\n    plt.xlabel(col + ', Skewness: ' + str(np.round(skew(X_train[col]),2)) + ', Kurtosis: ' + str(np.round(kurtosis(X_train[col]),2)))\n    pltNum = pltNum + 1","104adb9e":"#Backup of X_train\nX_train_copy = X_train.copy()","099b2cc1":"y_train.shape","d4cfd21e":"X_train.shape","b3715726":"from sklearn.tree    import DecisionTreeClassifier\nfrom sklearn.metrics import classification_report,confusion_matrix,accuracy_score,precision_score,recall_score","293eba78":"decision_tree = DecisionTreeClassifier(max_depth=5)\ndecision_tree.fit(X_train,y_train)","1d061629":"y_train_pred_DT = decision_tree.predict(X_train).astype(int)","7d731bca":"decision_tree.score(X_train,y_train)","bc3ee3a4":"# Printing classification report\nprint(classification_report(y_train, y_train_pred_DT))","8577757f":"confusion1 = confusion_matrix(y_train,y_train_pred_DT)","77d06c99":"confusion1","74b24b9a":"# Predicted     not_fraudulent    fraudulent\n# Actual\n# not_fraudulent    199016            11\n# fraudulent            66           266","acebac69":"TP = confusion1[1,1] # true positive \nTN = confusion1[0,0] # true negatives\nFP = confusion1[0,1] # false positives\nFN = confusion1[1,0] # false negatives","2fe0ab35":"#Sensitivity\nTP \/ float(TP+FN)","bbed33a6":"#Specificity\nTN \/ float(TN+FP)","7af74a2a":"#Precision\nTP \/ float(TP+FP)","ab3ff3f4":"# GridSearchCV to find optimal min_samples_split\nfrom sklearn.model_selection import KFold\nfrom sklearn.model_selection import GridSearchCV","020e0c87":"start = time.time()\n# Create the parameter grid \nparam_grid = {\n    'max_depth': range(5, 15, 5),\n    'min_samples_leaf': range(50, 150, 50),\n    'min_samples_split': range(50, 150, 50),\n    'criterion': [\"entropy\", \"gini\"]\n}\n\nn_folds = 3\n\n# Instantiate the grid search model\ndtree = DecisionTreeClassifier()\ngrid_search = GridSearchCV(estimator = dtree,param_grid = param_grid,cv = n_folds,verbose = 1)\n\n# Fit the grid search to the data\ngrid_search.fit(X_train,y_train)\n\nend = time.time()\nelapsed = end - start","ffbbb03d":"elapsed \/ 60","4ca8acfd":"# printing the optimal accuracy score and hyperparameters\nprint(\"best accuracy\", grid_search.best_score_)\nprint(grid_search.best_estimator_)","50a643aa":"# model with optimal hyperparameters\ndt_opt = DecisionTreeClassifier(criterion = \"gini\", \n                                  random_state = 100,\n                                  max_depth=5, \n                                  min_samples_leaf=50,\n                                  min_samples_split=50)\ndt_opt.fit(X_train,y_train)","adae856c":"y_train_pred_DT1 = dt_opt.predict(X_train).astype(int)","e3015c62":"# Printing classification report\nprint(classification_report(y_train, y_train_pred_DT1))","f39eced2":"confusion2 = confusion_matrix(y_train,y_train_pred_DT1)","c9563a3f":"TP = confusion2[1,1] # true positive \nTN = confusion2[0,0] # true negatives\nFP = confusion2[0,1] # false positives\nFN = confusion2[1,0] # false negatives","f305894b":"confusion2","60974402":"#Sensitivity\nTP \/ float(TP+FN)","3bf11415":"#Specificity\nTN \/ float(TN+FP)","c008ed83":"#Precision\nTP \/ float(TP+FP)","bf32d6ef":"# Importing random forest classifier from sklearn library\nfrom sklearn.ensemble import RandomForestClassifier","6c11f02b":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_depth': range(2, 15, 5)}\n# instantiate the model\nrf = RandomForestClassifier()\n# fit tree on training data\nrf = GridSearchCV(rf, parameters,cv=n_folds,scoring=\"recall\",return_train_score=True)\nrf.fit(X_train,y_train)\nend = time.time()","f42e44f6":"(end - start)\/60","33b8677b":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","b8ab1c48":"# plotting accuracies with max_depth\nplt.figure()\nplt.plot(scores[\"param_max_depth\"], \n         scores[\"mean_train_score\"], \n         label=\"training recall\")\nplt.plot(scores[\"param_max_depth\"], \n         scores[\"mean_test_score\"], \n         label=\"test recall\")\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","41a107ea":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'n_estimators': range(500, 1500, 500)}\n# instantiate the model (note we are specifying a max_depth)\nrf = RandomForestClassifier(max_depth=7)\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds,scoring=\"recall\",return_train_score=True)\nrf.fit(X_train,y_train)\nend = time.time()\n#print(\"Time took for the Hyperparameter tuning:\",((end-start)\/60))","1f152bb1":"(end - start)\/60","4c8b6fb5":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","7b4062c8":"# plotting accuracies with n_estimators\nplt.figure()\nplt.plot(scores[\"param_n_estimators\"], \n         scores[\"mean_train_score\"], \n         label=\"test accuracy\")\nplt.plot(scores[\"param_n_estimators\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","bdaa9754":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_features': [4, 8, 14, 20, 24]}\n# instantiate the model\nrf = RandomForestClassifier(max_depth=7)\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train,y_train)\nend = time.time()","64ca8607":"(end - start)\/60","cf913cdc":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","3c4dafd9":"# plotting accuracies with max_features\nplt.figure()\nplt.plot(scores[\"param_max_features\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_max_features\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"max_features\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","14e71522":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'min_samples_leaf': range(100,300,50)}\n# instantiate the model\nrf = RandomForestClassifier()\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train,y_train)\nend = time.time()\n(end-start)\/60","012ac98b":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","c25cab91":"# plotting accuracies with min_samples_leaf\nplt.figure()\nplt.plot(scores[\"param_min_samples_leaf\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_min_samples_leaf\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"min_samples_leaf\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","10095c0c":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'min_samples_split': range(100, 300, 50)}\n# instantiate the model\nrf = RandomForestClassifier()\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train,y_train)\nend = time.time()\n(end-start)\/60","99be6156":" # scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","a12f2bfa":"# plotting accuracies with min_samples_split\nplt.figure()\nplt.plot(scores[\"param_min_samples_split\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_min_samples_split\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"min_samples_split\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","5ef5c96d":"rf = RandomForestClassifier(n_estimators=500,max_depth=7,max_features=13,min_samples_leaf=75,min_samples_split=150)\nrf.fit(X_train,y_train)","d500d043":"y_train_pred_rf = rf.predict(X_train)","3837d3cc":"accuracy_score(y_train,y_train_pred_rf)","424d3e2a":"confusion3 = confusion_matrix(y_train,y_train_pred_rf)","f9d48973":"TP = confusion3[1,1] # true positive \nTN = confusion3[0,0] # true negatives\nFP = confusion3[0,1] # false positives\nFN = confusion3[1,0] # false negatives","c22de9a0":"confusion3","05235580":"#Sensitivity\nTP \/ float(TP + FN)","bf944e88":"#Specificity\nTN \/ float(TN + FP)","f3113673":"#Precision\nTP \/ float(TP+FP)","f9bdbe12":"X_test.shape","d34732e9":"y_test.shape","5d33ae37":"y_test_pred_rf = rf.predict(X_test)","f1c38bdb":"accuracy_score(y_test,y_test_pred_rf)","ee19f8ce":"confusion4 = confusion_matrix(y_test,y_test_pred_rf)","f0f2c643":"TP = confusion4[1,1] # true positive \nTN = confusion4[0,0] # true negatives\nFP = confusion4[0,1] # false positives\nFN = confusion4[1,0] # false negatives","46757ee8":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","3e2bc89a":"#Specificity\nTN \/ float(TN + FP)","22a4d6e4":"#Precision\nTP \/ float(TP+FP)","c2eecefb":"from sklearn.linear_model import LogisticRegression","ea94911b":"logreg = LogisticRegression()","9120a047":"import statsmodels.api as sm","e0793c38":"model1 = sm.GLM(y_train,(sm.add_constant(X_train)),family=sm.families.Binomial())\nmodel1.fit().summary()","fd3068f4":"X_train_logreg = X_train.copy()","333aa519":"X_train_logreg.drop(['Amount'],axis=1,inplace=True)","2c3c5444":"X_train_logreg.columns","15b7bdfe":"model2 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel2.fit().summary()","33e1c283":"X_train_logreg.drop(['V15'],axis=1,inplace=True)","efdc7ccb":"model3 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel3.fit().summary()","0cf5299a":"X_train_logreg.drop(['V17'],axis=1,inplace=True)","978d3f1a":"model4 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel4.fit().summary()","dfa323e7":"X_train_logreg.drop(['V24'],axis=1,inplace=True)","3a0c087b":"model5 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel5.fit().summary()","45915b4d":"X_train_logreg.drop(['V11'],axis=1,inplace=True)","dac2358f":"model6 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel6.fit().summary()","93b82b1f":"X_train_logreg.drop(['V5'],axis=1,inplace=True)","666ca3d4":"model7 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel7.fit().summary()","6f9f82d5":"X_train_logreg.drop(['V26'],axis=1,inplace=True)","9bbc30fe":"model8 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel8.fit().summary()","aebd2fc1":"X_train_logreg.drop(['V20'],axis=1,inplace=True)","d9e7e258":"model9 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel9.fit().summary()","617e8f36":"X_train_logreg.drop(['V27'],axis=1,inplace=True)","6b1340b2":"model10 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel10.fit().summary()","ac982a69":"X_train_logreg.drop(['V28'],axis=1,inplace=True)","bfe17c2d":"model11 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel11.fit().summary()","2af31a8c":"X_train_logreg.drop(['V18'],axis=1,inplace=True)","a4630493":"model12 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel12.fit().summary()","47432db3":"X_train_logreg.drop(['V25'],axis=1,inplace=True)","c0f8b1c2":"model12 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel12.fit().summary()","7da951ca":"X_train_logreg.drop(['V23'],axis=1,inplace=True)","8d441b36":"model12 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel12.fit().summary()","da05291f":"X_train_logreg.drop(['V9'],axis=1,inplace=True)","afba6091":"model12 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel12.fit().summary()","b395c7e2":"X_train_logreg.drop(['V2'],axis=1,inplace=True)","904f9fad":"model12 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nmodel12.fit().summary()","e4befc9d":"X_train_logreg.drop(['V6'],axis=1,inplace=True)","5784a082":"model12 = sm.GLM(y_train,(sm.add_constant(X_train_logreg)),family=sm.families.Binomial())\nresult = model12.fit()\nresult.summary()","11a86316":"# Check for the VIF values of the feature variables. \nfrom statsmodels.stats.outliers_influence import variance_inflation_factor","c3a962bb":"# Create a dataframe that will contain the names of all the feature variables that w used before and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_logreg.columns\nvif['VIF'] = [variance_inflation_factor(X_train_logreg.values, i) for i in range(X_train_logreg.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","3ca07c40":"y_df_logreg = pd.DataFrame(data=y_train.values,columns=['y_train'])","8891b918":"y_df_logreg.head()","3e426c17":"#X_train_logreg\ny_train_pred_logreg = result.predict(sm.add_constant(X_train_logreg)).values.reshape(-1)","2de88970":"y_train_pred_logreg[:10]","4b470c12":"y_df_logreg['y_train_pred_logreg'] = y_train_pred_logreg","7ff03fb5":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_df_logreg[i]= y_df_logreg.y_train_pred_logreg.map(lambda x: 1 if x > i else 0)\ny_df_logreg.head()","f57bf7f1":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['probability','accuracy','sensitivity','specificity'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(y_df_logreg.y_train, y_df_logreg[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","b344e54d":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='probability', y=['accuracy','sensitivity','specificity'])\nplt.show()","4f9235b1":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df1 = pd.DataFrame( columns = ['probability','precision','recall'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(y_df_logreg.y_train, y_df_logreg[i] )\n    total1=sum(sum(cm1))\n    prec = cm1[1,1]\/(cm1[1,1]+cm1[0,1])\n    rec = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df1.loc[i] =[ i ,prec, rec]\nprint(cutoff_df1)","a8612e34":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df1.plot.line(x='probability', y=['precision','recall'])\nplt.show()","3b8bea44":"y_df_logreg['Final_predicted'] = y_df_logreg.y_train_pred_logreg.map( lambda x: 1 if x > 0.1 else 0)\ny_df_logreg.head()","5522ae6c":"final_confusion = confusion_matrix(y_df_logreg['y_train'],y_df_logreg['Final_predicted'])\nprint(final_confusion)","ba7a8627":"TP = final_confusion[1,1] # true positive \nTN = final_confusion[0,0] # true negatives\nFP = final_confusion[0,1] # false positives\nFN = final_confusion[1,0] # false negatives","ba2e4124":"#Sensitivity \/ Recall\nTP \/ float(TP+FN)","0cfc26e4":"#Precision\nTP \/ float(TP + FP)","e6374c28":"#Specificity\nTN \/ float(TN + FP)","56d9c11f":"X_train_logreg_cols = list(X_train_logreg.columns)","bf184fc8":"#Building the test dataset with the relevant columns of our logistic regression model\nX_test_logreg = X_test[X_train_logreg_cols]","03396075":"#X_test_logreg\ny_test","4d8244c1":"#X_train_logreg\ny_test_pred_logreg = result.predict(sm.add_constant(X_test_logreg)).values.reshape(-1)","5bb029de":"y_df_logreg_test = pd.DataFrame(data=y_test.values,columns=['y_test'])","fae7536c":"y_df_logreg_test['y_test_prob'] = y_test_pred_logreg","868cb56b":"y_df_logreg_test['final_predicted'] = y_df_logreg_test.y_test_prob.map( lambda x: 1 if x > 0.1 else 0)","65904d4c":"final_confusion_test = confusion_matrix(y_df_logreg_test['y_test'],y_df_logreg_test['final_predicted'])","df16f00f":"final_confusion_test","3c2a5046":"TP = final_confusion_test[1,1] # true positive \nTN = final_confusion_test[0,0] # true negatives\nFP = final_confusion_test[0,1] # false positives\nFN = final_confusion_test[1,0] # false negatives","a609922f":"#Sensitivity \/ Recall\nTP \/ float(TP+FN)","a802c93a":"#Precision\nTP \/ float(TP + FP)","cc7d4e30":"#Specificity\nTN \/ float(TN + FP)","2b1965d1":"from sklearn.neighbors import KNeighborsClassifier","893e8370":"start = time.time()\nknn=KNeighborsClassifier(n_neighbors=5)\nknn.fit(X_train,y_train)\nend = time.time()\n(end-start)\/60","57573740":"y_train_pred_knn = knn.predict(X_train)","f961669e":"recall_score(y_train,y_train_pred_knn)","e52924bf":"confusion_knn = confusion_matrix(y_train,y_train_pred_knn)","c3928ad4":"TP = confusion_knn[1,1] # true positive \nTN = confusion_knn[0,0] # true negatives\nFP = confusion_knn[0,1] # false positives\nFN = confusion_knn[1,0] # false negatives","b32d5891":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","e1cc66b4":"#Specificity\nTN \/ float(TN + FP)","6f7aceeb":"#Precision\nTP \/ float(TP + FP)","dbc61034":"#Importing the libraries for XGBoost.\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance","26124586":"#!nvidia-smi","72b763ec":"#dtrain = xgb.DMatrix(X_train,label=y_train)\n#dtest  = xgb.DMatrix(X_test,label=y_test)","732ba96b":"#import time\n#setting tree and tree depth\n#num_round = 50\n#maxdepth = 8\n#param = {\n#  'colsample_bylevel': 1,\n#  'colsample_bytree': 1,\n#  'gamma': 0,\n#  'learning_rate': 0.1, \n#  'random_state': 1010,\n#  'objective': 'multi:softmax', \n#  'num_class': 7, \n#}","c1c5dc0b":"#param['tree_method'] = 'gpu_hist'\n#param['grow_policy'] = 'depthwise'\n#param['max_depth'] = maxdepth\n#param['max_leaves'] = 0\n#param['verbosity'] = 0\n#param['gpu_id'] = 0\n#param['updater'] = 'grow_gpu_hist'\n#param['predictor'] = 'gpu_predictor'\n#param['eval_metric'] = 'auc'\n\n#gpu_result = {} \n#start_time = time.time()\n# Training with the above parameters\n#xgb_model = xgb.train(param, dtrain, num_round, evals=[(dtest, 'test')], evals_result=gpu_result, verbose_eval=20)\n\n#print(\"GPU Training Time: %s seconds\" % (str(time.time() - start_time)))","85dd27ef":"#!nvidia-smi","aec56a0a":"import time","ec24689a":"xgb_model = XGBClassifier()","99d43fb8":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_depth': range(2, 20, 5)}\n# instantiate the model\nxgb_model = XGBClassifier()\n# fit tree on training data\nxgb_model1 = GridSearchCV(xgb_model, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nxgb_model1.fit(X_train,y_train)\nend = time.time()\n(end-start)\/60","337fee51":"cv_results = pd.DataFrame(xgb_model1.cv_results_)","98688a83":"cv_results","8b36e812":"# plotting accuracies with max_depth\nplt.figure()\nplt.plot(cv_results[\"param_max_depth\"], \n         cv_results[\"mean_train_score\"], \n         label=\"training recall\")\nplt.plot(cv_results[\"param_max_depth\"], \n         cv_results[\"mean_test_score\"], \n         label=\"test recall\")\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","9610d971":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'n_estimators': range(100, 800, 300)}\n# instantiate the model (note we are specifying a max_depth)\nxgb_model = XGBClassifier(max_depth=4)\n# fit tree on training data\nxgb_model1 = GridSearchCV(xgb_model, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nxgb_model1.fit(X_train,y_train)\nend = time.time()\n(end-start)\/60","89f686a8":"cv_results = pd.DataFrame(xgb_model1.cv_results_)","dcf68d83":"cv_results","6de067e1":"# plotting accuracies with n_estimators\nplt.figure()\nplt.plot(cv_results[\"param_n_estimators\"], \n         cv_results[\"mean_test_score\"], \n         label=\"test recall\")\nplt.plot(cv_results[\"param_n_estimators\"], \n         cv_results[\"mean_train_score\"], \n         label=\"train recall\")\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","e605fb34":"start = time.time()\n# hyperparameter tuning with XGBoost\n# creating a KFold object \nfolds = 3\n# specify range of hyperparameters\nparam_grid = {'learning_rate': [0.2, 0.6], \n             'subsample': [0.3, 0.6, 0.9]}          \n\n# specify model\nxgb_model = XGBClassifier(max_depth=4, n_estimators=100)\n\n# set up GridSearchCV()\nmodel_cv = GridSearchCV(estimator = xgb_model, \n                        param_grid = param_grid, \n                        scoring= 'recall', \n                        cv = folds,  \n                        verbose = 1,\n                        return_train_score=True)  \nmodel_cv.fit(X_train,y_train)\nend = time.time()\n(end-start)\/60","ef63017e":"# cv results\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results","2e7d7e28":"# convert parameters to int for plotting on x-axis\ncv_results['param_learning_rate'] = cv_results['param_learning_rate'].astype('float')\ncv_results['param_subsample'] = cv_results['param_subsample'].astype('float')\ncv_results.head()","1dec443a":"#plotting\nplt.figure(figsize=(16,6))\nparam_grid = {'learning_rate': [0.2, 0.6], \n             'subsample': [0.3, 0.6, 0.9]} \nfor n, subsample in enumerate(param_grid['subsample']):\n    # subplot 1\/n\n    plt.subplot(1,len(param_grid['subsample']), n+1)\n    df = cv_results[cv_results['param_subsample']==subsample]\n\n    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n    plt.xlabel('learning_rate')\n    plt.ylabel('recall')\n    plt.title(\"subsample={0}\".format(subsample))\n    plt.ylim([0.60, 1])\n    plt.legend(['test score', 'train score'], loc='upper left')\n    plt.xscale('log')","4c945b07":"# chosen hyperparameters\n# 'objective':'binary:logistic' outputs probability rather than label, which we need for auc\nparams = {'learning_rate': 0.2,\n          'max_depth': 4, \n          'n_estimators':100,\n          'subsample':0.3,\n         'objective':'binary:logistic'}\n\n# fit model on training data\nmodel = XGBClassifier(params = params)\nmodel.fit(X_train,y_train)","a91c061f":"# predict\ny_pred = model.predict_proba(X_train)\ny_pred[:10]","6b2176c1":"import sklearn","a7d458c2":"# roc_auc\nauc = sklearn.metrics.roc_auc_score(y_train, y_pred[:, 1])\nauc","41bc2f2c":"xgb_df = pd.DataFrame(y_pred[:, 1],columns=[\"Predicted_probability\"])","5424dc06":"xgb_df['Churn'] = y_train.values","13d80713":"xgb_df","f89787ee":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    xgb_df[i]= xgb_df.Predicted_probability.map(lambda x: 1 if x > i else 0)\nxgb_df.head()","c9baa3a1":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['probability','accuracy','sensitivity','specificity'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(xgb_df.Churn, xgb_df[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","a5bce50a":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='probability', y=['accuracy','sensitivity','specificity'])\nplt.show()","ed351dfe":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df1 = pd.DataFrame( columns = ['probability','precision','recall'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(xgb_df.Churn, xgb_df[i] )\n    total1=sum(sum(cm1))\n    prec = cm1[1,1]\/(cm1[1,1]+cm1[0,1])\n    rec = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df1.loc[i] =[ i ,prec, rec]\nprint(cutoff_df1)","a68b8fa9":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df1.plot.line(x='probability', y=['precision','recall'])\nplt.show()","24ba4eb6":"#Selecting the cut-off probability as 0.4 and predicting for Churn.\nxgb_df['Final_predicted'] = xgb_df.Predicted_probability.map( lambda x: 1 if x > 0.1 else 0)\nxgb_df.head()","bac33487":"y_pred_test = model.predict_proba(X_test)\ny_pred_test[:10]","2966d124":"xgb_test_df_ca = pd.DataFrame(y_pred_test[:, 1],columns=[\"Predicted_probability\"])","a42703dd":"xgb_test_df_ca['y_test'] = y_test.values","c5b6a7c8":"xgb_test_df_ca","ef418c3b":"#Selecting the cut-off probability as 0.4 and predicting for Churn.\nxgb_test_df_ca['Final_predicted'] = xgb_test_df_ca.Predicted_probability.map( lambda x: 1 if x > 0.1 else 0)\nxgb_test_df_ca.head()","2868a556":"confusion_xgb = confusion_matrix(xgb_test_df_ca['y_test'],xgb_test_df_ca['Final_predicted'])\nconfusion_xgb","9e438e3f":"TP = confusion_xgb[1,1] # true positive \nTN = confusion_xgb[0,0] # true negatives\nFP = confusion_xgb[0,1] # false positives\nFN = confusion_xgb[1,0] # false negatives","9b558e93":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","98004aaf":"#Specificity\nTN \/ float(TN + FP)","70f97858":"#Precision\nTP \/ float(TP + FP)","c1ee941e":"from imblearn.over_sampling import ADASYN","9034c52f":"#Initialising the ADASYN object\nada = ADASYN(sampling_strategy='minority',random_state=101)","af2bf011":"#fit_resample on the train sets to produce the new resampled sets.\nX_train_ada,y_train_ada = ada.fit_resample(X_train,y_train)","eda4bcfc":"X_train_ada.shape","6189f501":"y_train_ada.shape","daedb12d":"X_train_ada = pd.DataFrame(X_train_ada,columns=X_train.columns)","f413db2a":"y_train_ada = pd.DataFrame(y_train_ada,columns=['Fraud'])","dfda89e4":"#Data Inbalance check for the Converted column.\nyes=y_train_ada[y_train_ada['Fraud']==1]['Fraud'].value_counts()\nno=y_train_ada[y_train_ada['Fraud']==0]['Fraud'].value_counts()\n\nconverted=np.array((yes\/len(y_train_ada))*100) \nnot_converted=np.array((no\/len(y_train_ada))*100) \nstat_summ=pd.DataFrame({'Percentage':[converted[0],not_converted[0]]},index=['Fraud','Not_Fraud'])\nsns.barplot(x=stat_summ.index,y=stat_summ['Percentage'],palette='RdYlGn')\nplt.title('Check on the data imbalance')\nplt.show()","a69bdfbe":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.feature_selection import RFE","3ee1567c":"logreg = LogisticRegression()\nrfe = RFE(logreg,17)\nrfe = rfe.fit(X_train_ada,y_train_ada)","651f2d7f":"cols = X_train_ada.columns[rfe.support_]\ncols","b7061561":"X_train_ada_lr = X_train_ada[cols]","a74a444c":"model1 = sm.GLM(y_train_ada,(sm.add_constant(X_train_ada_lr)),family=sm.families.Binomial())\nmodel1.fit().summary()","2252db23":"# Create a dataframe that will contain the names of all the feature variables that w used before and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_ada_lr.columns\nvif['VIF'] = [variance_inflation_factor(X_train_ada_lr.values, i) for i in range(X_train_ada_lr.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","8eb980e8":"X_train_ada_lr.drop(['V10'],axis=1,inplace=True)","b0c304a6":"model2 = sm.GLM(y_train_ada,(sm.add_constant(X_train_ada_lr)),family=sm.families.Binomial())\nmodel2.fit().summary()","faed3f83":"# Create a dataframe that will contain the names of all the feature variables that w used before and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_ada_lr.columns\nvif['VIF'] = [variance_inflation_factor(X_train_ada_lr.values, i) for i in range(X_train_ada_lr.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","3193d89d":"X_train_ada_lr.drop(['V17'],axis=1,inplace=True)","1767fde0":"model3 = sm.GLM(y_train_ada,(sm.add_constant(X_train_ada_lr)),family=sm.families.Binomial())\nmodel3.fit().summary()","74a3a399":"# Create a dataframe that will contain the names of all the feature variables that w used before and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_ada_lr.columns\nvif['VIF'] = [variance_inflation_factor(X_train_ada_lr.values, i) for i in range(X_train_ada_lr.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","a700e481":"X_train_ada_lr.drop(['V14'],axis=1,inplace=True)","3c91ccb6":"model4 = sm.GLM(y_train_ada,(sm.add_constant(X_train_ada_lr)),family=sm.families.Binomial())\nresult = model4.fit()\nresult.summary()","98b16ba2":"# Create a dataframe that will contain the names of all the feature variables that w used before and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_ada_lr.columns\nvif['VIF'] = [variance_inflation_factor(X_train_ada_lr.values, i) for i in range(X_train_ada_lr.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","0f0c156d":"y_df_logreg_ada = pd.DataFrame(data=y_train_ada.values,columns=['y_train_ada'])","916d4d0c":"#y_train_pred_logreg_ada\ny_train_pred_logreg_ada = result.predict(sm.add_constant(X_train_ada_lr)).values.reshape(-1)","d588ce3b":"y_train_pred_logreg_ada[:10]","e35f82b1":"y_df_logreg_ada.shape","a5e2f4a4":"y_train_pred_logreg_ada.shape","53541d43":"y_df_logreg_ada['y_train_pred'] = y_train_pred_logreg_ada","560df9d2":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    y_df_logreg_ada[i]= y_df_logreg_ada.y_train_pred.map(lambda x: 1 if x > i else 0)\ny_df_logreg_ada.head()","dec296b9":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['probability','accuracy','sensitivity','specificity'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(y_df_logreg_ada.y_train_ada, y_df_logreg_ada[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","1e128bb4":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='probability', y=['accuracy','sensitivity','specificity'])\nplt.show()","58f7d070":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df1 = pd.DataFrame( columns = ['probability','precision','recall'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(y_df_logreg_ada.y_train_ada, y_df_logreg_ada[i] )\n    total1=sum(sum(cm1))\n    prec = cm1[1,1]\/(cm1[1,1]+cm1[0,1])\n    rec = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df1.loc[i] =[ i ,prec, rec]\nprint(cutoff_df1)","1ce68aef":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df1.plot.line(x='probability', y=['precision','recall'])\nplt.show()","d65eff24":"X_train_ada_cols = list(X_train_ada_lr.columns)","80297fc9":"#Building the test dataset with the relevant columns of our logistic regression model\nX_test_logreg = X_test[X_train_ada_cols]","1f9ba89c":"X_test_logreg.shape","ba7198d9":"y_test.shape","1d67e495":"#X_train_logreg\ny_test_pred_logreg = result.predict(sm.add_constant(X_test_logreg)).values.reshape(-1)","2918bbdc":"y_df_logreg_test = pd.DataFrame(data=y_test.values,columns=['y_test'])","fc6a271d":"y_df_logreg_test['y_test_prob'] = y_test_pred_logreg","c1aa26d1":"y_df_logreg_test['final_predicted'] = y_df_logreg_test.y_test_prob.map( lambda x: 1 if x > 0.5 else 0)","253cb86f":"final_confusion_test = confusion_matrix(y_df_logreg_test['y_test'],y_df_logreg_test['final_predicted'])","0f9a1581":"final_confusion_test","13e71693":"TP = final_confusion_test[1,1] # true positive \nTN = final_confusion_test[0,0] # true negatives\nFP = final_confusion_test[0,1] # false positives\nFN = final_confusion_test[1,0] # false negatives","9c9105bf":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","97d502a8":"#Specificity\nTN \/ float(TN + FP)","72878ec8":"#Precision\nTP \/ float(TP + FP)","a04a7d5c":"X_train_ada.shape","e9b3f3a4":"y_train_ada.shape","871dfbe5":"X_train_ada_new = X_train_ada.copy()","2c4fa619":"X_train_ada_new['Fraud'] = y_train_ada['Fraud']","1463df77":"X_train_ada_fraud = X_train_ada_new.loc[X_train_ada_new['Fraud']==1]","3eb3bb70":"X_train_ada_non_fraud = X_train_ada_new.loc[X_train_ada_new['Fraud']==0]","93414016":"X_train_ada_fraud.shape","77c2d415":"X_train_ada_non_fraud.shape","2cdab47a":"X_train_ada_fraud = X_train_ada_fraud.sample(frac=1)","bc45f696":"X_train_ada_non_fraud = X_train_ada_non_fraud.sample(frac=1)","30b5fcff":"X_train_ada_fraud = X_train_ada_fraud[:50000]\nX_train_ada_non_fraud = X_train_ada_non_fraud[:50000]","85b98fcd":"frames = [X_train_ada_fraud,X_train_ada_non_fraud]\nX_train_ada_final = pd.concat(frames)","01953132":"X_train_ada_final = X_train_ada_final.sample(frac=1)","d875d0d8":"X_train_ada_final","64210fb4":"X_train_ada_sampled = X_train_ada_final.drop(['Fraud'],axis=1)\ny_train_ada_sampled = X_train_ada_final['Fraud']","96f6c353":"from sklearn.ensemble import RandomForestClassifier","f317e050":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_depth': range(2, 15, 3)}\n# instantiate the model\nrf = RandomForestClassifier()\n# fit tree on training data\nrf = GridSearchCV(rf, parameters,cv=n_folds,scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_ada_sampled,y_train_ada_sampled)\nend = time.time()","f3fd8008":"print(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","3ae74ff3":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","bbe5c3d7":"# plotting accuracies with max_depth\nplt.figure()\nplt.plot(scores[\"param_max_depth\"], \n         scores[\"mean_train_score\"], \n         label=\"training recall\")\nplt.plot(scores[\"param_max_depth\"], \n         scores[\"mean_test_score\"], \n         label=\"test recall\")\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","16aa2f8a":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'n_estimators': range(200, 1500, 500)}\n# instantiate the model (note we are specifying a max_depth)\nrf = RandomForestClassifier(max_depth=6)\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds,scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_ada_sampled,y_train_ada_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","1823acad":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","863e7ef7":"# plotting accuracies with n_estimators\nplt.figure()\nplt.plot(scores[\"param_n_estimators\"], \n         scores[\"mean_train_score\"], \n         label=\"test accuracy\")\nplt.plot(scores[\"param_n_estimators\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","b0c4a7f7":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_features': [4, 8, 14, 20, 24]}\n# instantiate the model\nrf = RandomForestClassifier(max_depth=6)\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_ada_sampled,y_train_ada_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","bf001d38":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","1f4a4386":"# plotting accuracies with max_features\nplt.figure()\nplt.plot(scores[\"param_max_features\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_max_features\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"max_features\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","0cdd261c":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'min_samples_leaf': range(50,300,50)}\n# instantiate the model\nrf = RandomForestClassifier()\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_ada_sampled,y_train_ada_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","84538fd9":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","d068f349":"# plotting accuracies with min_samples_leaf\nplt.figure()\nplt.plot(scores[\"param_min_samples_leaf\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_min_samples_leaf\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"min_samples_leaf\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","e43e42af":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'min_samples_split': range(100, 300, 50)}\n# instantiate the model\nrf = RandomForestClassifier()\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_ada_sampled,y_train_ada_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","5eb85225":" # scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","8e78d4a0":"# plotting accuracies with min_samples_split\nplt.figure()\nplt.plot(scores[\"param_min_samples_split\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_min_samples_split\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"min_samples_split\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","bc9adc9f":"rf = RandomForestClassifier(n_estimators=200,max_depth=6,max_features=5,min_samples_leaf=250,min_samples_split=500)\nrf.fit(X_train_ada_sampled,y_train_ada_sampled)","79907cba":"y_train_pred_rf_ada = rf.predict(X_train_ada_sampled)","c22fdde8":"accuracy_score(y_train_ada_sampled,y_train_pred_rf_ada)","ea7ca2b2":"confusion = confusion_matrix(y_train_ada_sampled,y_train_pred_rf_ada)","a6120663":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","34ec6254":"confusion","973c7cb0":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","94e32db4":"#Specificity\nTN \/ float(TN + FP)","f86e807a":"#Precision\nTP \/ float(TP+FP)","4a4a561a":"X_test.shape","77179d05":"y_test.shape","c24c4f66":"y_test_pred_rf_ada = rf.predict(X_test)","444aaee0":"accuracy_score(y_test,y_test_pred_rf_ada)","b7027522":"confusion_rf = confusion_matrix(y_test,y_test_pred_rf_ada)","3f1a834d":"confusion_rf","366954af":"TP = confusion_rf[1,1] # true positive \nTN = confusion_rf[0,0] # true negatives\nFP = confusion_rf[0,1] # false positives\nFN = confusion_rf[1,0] # false negatives","e952b673":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","51e190d2":"#Specificity\nTN \/ float(TN + FP)","40a07e40":"#Precision\nTP \/ float(TP+FP)","3d5961b2":"#Importing the libraries for XGBoost.\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance","0cce0228":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_depth': range(2, 20, 5)}\n# instantiate the model\nxgb_model = XGBClassifier()\n# fit tree on training data\nxgb_model1 = GridSearchCV(xgb_model, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nxgb_model1.fit(X_train_ada_sampled,y_train_ada_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","31ce35f8":"cv_results = pd.DataFrame(xgb_model1.cv_results_)\ncv_results","8a9ad093":"# plotting accuracies with max_depth\nplt.figure()\nplt.plot(cv_results[\"param_max_depth\"], \n         cv_results[\"mean_train_score\"], \n         label=\"training recall\")\nplt.plot(cv_results[\"param_max_depth\"], \n         cv_results[\"mean_test_score\"], \n         label=\"test recall\")\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","e8a7011a":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'n_estimators': range(100, 1000, 200)}\n# instantiate the model (note we are specifying a max_depth)\nxgb_model = XGBClassifier(max_depth=4)\n# fit tree on training data\nxgb_model1 = GridSearchCV(xgb_model, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nxgb_model1.fit(X_train_ada_sampled,y_train_ada_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","2e00ed8f":"cv_results = pd.DataFrame(xgb_model1.cv_results_)\ncv_results","a2dfed30":"# plotting accuracies with n_estimators\nplt.figure()\nplt.plot(cv_results[\"param_n_estimators\"], \n         cv_results[\"mean_test_score\"], \n         label=\"test recall\")\nplt.plot(cv_results[\"param_n_estimators\"], \n         cv_results[\"mean_train_score\"], \n         label=\"train recall\")\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","eeb7e5b3":"start = time.time()\n# hyperparameter tuning with XGBoost\n# creating a KFold object \nfolds = 3\n# specify range of hyperparameters\nparam_grid = {'learning_rate': [0.2,0.4,0.6], \n             'subsample': [0.3, 0.6, 0.9]}          \n\n# specify model\nxgb_model = XGBClassifier(max_depth=4, n_estimators=100)\n# set up GridSearchCV()\nmodel_cv = GridSearchCV(estimator = xgb_model, \n                        param_grid = param_grid, \n                        scoring= 'recall', \n                        cv = folds,  \n                        verbose = 1,\n                        return_train_score=True)  \nmodel_cv.fit(X_train_ada_sampled,y_train_ada_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","3ef54daa":"# cv results\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results","4d263636":"# convert parameters to int for plotting on x-axis\ncv_results['param_learning_rate'] = cv_results['param_learning_rate'].astype('float')\ncv_results['param_subsample'] = cv_results['param_subsample'].astype('float')\ncv_results.head()","cbe91798":"#plotting\nplt.figure(figsize=(16,6))\nparam_grid = {'learning_rate': [0.2, 0.6], \n             'subsample': [0.3, 0.6, 0.9]} \nfor n, subsample in enumerate(param_grid['subsample']):\n    # subplot 1\/n\n    plt.subplot(1,len(param_grid['subsample']), n+1)\n    df = cv_results[cv_results['param_subsample']==subsample]\n\n    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n    plt.xlabel('learning_rate')\n    plt.ylabel('recall')\n    plt.title(\"subsample={0}\".format(subsample))\n    plt.ylim([0.995, 1])\n    plt.legend(['test score', 'train score'], loc='upper left')\n    plt.xscale('log')","b422e2c5":"# chosen hyperparameters\n# 'objective':'binary:logistic' outputs probability rather than label, which we need for auc\nparams = {'learning_rate': 0.2,\n          'max_depth': 4, \n          'n_estimators':100,\n          'subsample':0.3,\n         'objective':'binary:logistic'}\n\n# fit model on training data\nmodel = XGBClassifier(params = params)\nmodel.fit(X_train_ada_sampled,y_train_ada_sampled)","9e74dc8b":"# predict\ny_pred = model.predict_proba(X_train_ada_sampled)\ny_pred[:10]","c1989e01":"import sklearn","4dad0762":"# roc_auc\nauc = sklearn.metrics.roc_auc_score(y_train_ada_sampled, y_pred[:, 1])\nauc","aa54717b":"xgb_df = pd.DataFrame(y_pred[:, 1],columns=[\"Predicted_probability\"])","4292d9fa":"xgb_df['Churn'] = y_train_ada_sampled.values","57951909":"xgb_df","42e73e44":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    xgb_df[i]= xgb_df.Predicted_probability.map(lambda x: 1 if x > i else 0)\nxgb_df.head()","c0a3945d":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['probability','accuracy','sensitivity','specificity'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(xgb_df.Churn, xgb_df[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","261e19a3":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df.plot.line(x='probability', y=['accuracy','sensitivity','specificity'])\nplt.show()","393788e5":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df1 = pd.DataFrame( columns = ['probability','precision','recall'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(xgb_df.Churn, xgb_df[i] )\n    total1=sum(sum(cm1))\n    prec = cm1[1,1]\/(cm1[1,1]+cm1[0,1])\n    rec = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df1.loc[i] =[ i ,prec, rec]\nprint(cutoff_df1)","51f4295b":"# Let's plot accuracy sensitivity and specificity for various probabilities.\ncutoff_df1.plot.line(x='probability', y=['precision','recall'])\nplt.show()","a03b4a40":"#Selecting the cut-off probability as 0.4 and predicting for Churn.\nxgb_df['Final_predicted'] = xgb_df.Predicted_probability.map( lambda x: 1 if x > 0.55 else 0)\nxgb_df.head()","ebcb3def":"#Function to plot for the Reciever Operating Characteristics (ROC) and to find out the AUC.\ndef draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC curve (area = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic example')\n    plt.legend(loc=\"lower right\")\n    plt.show()\n\n    return None","a026ef52":"fpr, tpr, thresholds = metrics.roc_curve(xgb_df['Churn'],xgb_df['Final_predicted'], drop_intermediate = False )","c7be087e":"draw_roc(xgb_df['Churn'],xgb_df['Final_predicted'])","ca22707e":"y_pred_test = model.predict_proba(X_test)\ny_pred_test[:10]","f888810a":"xgb_test_df = pd.DataFrame(y_pred_test[:, 1],columns=[\"Predicted_probability\"])","a3f31eb1":"xgb_test_df['y_test'] = y_test.values","5ecd3605":"xgb_test_df.head()","4517ebf2":"#Selecting the cut-off probability as 0.4 and predicting for Churn.\nxgb_test_df['Final_predicted'] = xgb_test_df.Predicted_probability.map( lambda x: 1 if x > 0.55 else 0)\nxgb_test_df.head()","404109c3":"confusion_xgb = confusion_matrix(xgb_test_df['y_test'],xgb_test_df['Final_predicted'])\nconfusion_xgb","95fb837a":"TP = confusion_xgb[1,1] # true positive \nTN = confusion_xgb[0,0] # true negatives\nFP = confusion_xgb[0,1] # false positives\nFN = confusion_xgb[1,0] # false negatives","53bd6f3b":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","4a8dc70d":"#Specificity\nTN \/ float(TN + FP)","a2ad6328":"#Precision\nTP \/ float(TP + FP)","a5464787":"start = time.time()\n\n#\nrf_ro = RandomForestClassifier(class_weight={0:0.001, 1:0.999},n_jobs=1)\n\nparams = {\n        'max_depth': range(2, 14, 2)\n}\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n\nrf_ro = GridSearchCV(estimator = rf_ro,\n                    cv=folds,\n                    param_grid=params,\n                    scoring='roc_auc',\n                    n_jobs=-1,\n                    verbose=1)\n\n# fit\nrf_ro.fit(X_train, y_train)\n\nend = time.time()\n\nprint('I took:',np.round((end-start)\/60,2),' minutes to complete !!')","c1ddcc0b":"start = time.time()\n\n#\nrf_ro = RandomForestClassifier(max_depth=4, class_weight={0:0.001, 1:0.999},n_jobs=1)\n\nparams = {\n        'n_estimators': range(200, 801, 200)\n}\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n\nrf_ro = GridSearchCV(estimator = rf_ro,\n                    cv=folds,\n                    param_grid=params,\n                    scoring='roc_auc',\n                    n_jobs=-1,\n                    verbose=1)\n\n# fit\nrf_ro.fit(X_train, y_train)\n\nend = time.time()\n\nprint('I took:',np.round((end-start)\/60,2),' minutes to complete !!')","806ec351":"rf_ro.best_params_","39bb3ed7":"start = time.time()\n\n#\nrf_ro3 = RandomForestClassifier(max_depth=4,\n                               n_estimators=200,\n                               class_weight={0:0.001, 1:0.999},\n                               n_jobs=1)\n\nparams = {\n        'max_features': range(5,21,5)\n}\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n\nrf_ro3 = GridSearchCV(estimator = rf_ro3,\n                    cv=folds,\n                    param_grid=params,\n                    scoring='roc_auc',\n                    n_jobs=-1,\n                    verbose=1)\n\n# fit\nrf_ro3.fit(X_train, y_train)\n\nend = time.time()\n\nprint('I took:',np.round((end-start)\/60,2),' minutes to complete !!')","85a312ac":"rf_ro3.best_params_","68de6b53":"start = time.time()\n\n#\nrf_ro4 = RandomForestClassifier(max_depth=4,\n                               n_estimators=200,\n                               max_features=10,\n                               class_weight={0:0.001, 1:0.999},\n                               n_jobs=1)\n\nparams = {\n        'min_samples_leaf': range(5, 21, 5)\n}\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n\nrf_ro4 = GridSearchCV(estimator = rf_ro4,\n                    cv=folds,\n                    param_grid=params,\n                    scoring='roc_auc',\n                    n_jobs=-1,\n                    verbose=1)\n\n# fit\nrf_ro4.fit(X_train, y_train)\n\nend = time.time()\n\nprint('I took:',np.round((end-start)\/60,2),' minutes to complete !!')","dba38735":"rf_ro4.best_params_","c6b166c1":"start = time.time()\n\n#\nrf_ro5 = RandomForestClassifier(max_depth=4,\n                               n_estimators=200,\n                               max_features=10,\n                               min_samples_leaf=15,\n                               class_weight={0:0.001, 1:0.999},\n                               n_jobs=1)\n\nparams = {\n        'min_samples_split': range(10, 101, 20)\n}\n\nfolds = StratifiedKFold(n_splits = 5, shuffle = True, random_state = 100)\n\nrf_ro5 = GridSearchCV(estimator = rf_ro5,\n                    cv=folds,\n                    param_grid=params,\n                    scoring='roc_auc',\n                    n_jobs=-1,\n                    verbose=1)\n\n# fit\nrf_ro5.fit(X_train, y_train)\n\nend = time.time()\n\nprint('I took:',np.round((end-start)\/60,2),' minutes to complete !!')","e0bf2dc1":"rf_ro5.best_params_","f701b97f":"rf_roTuned = RandomForestClassifier(max_depth=4,\n                               n_estimators=200,\n                               max_features=10,\n                               min_samples_leaf=15,\n                               min_samples_split=90,\n                               class_weight={0:0.001, 1:0.999},\n                               n_jobs=1,\n                               random_state = 100)","3ba7c26e":"rf_roTuned.fit(X_train, y_train)\n\ny_train_pred = rf_roTuned.predict(X_train)\ny_test_pred = rf_roTuned.predict(X_test)","f00e85ca":"# Printing classification report\nprint(classification_report(y_train, y_train_pred))\nprint(metrics.accuracy_score(y_train, y_train_pred))\n# find precision score and recall score\nprecisionScore = precision_score(y_train, y_train_pred)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_train, y_train_pred)\nprint('Recall score is:',recallScore)","ac88c908":"# Printing classification report\nprint(classification_report(y_test, y_test_pred))\nprint(metrics.accuracy_score(y_test, y_test_pred))\n# find precision score and recall score\nprecisionScore = precision_score(y_test, y_test_pred)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_test, y_test_pred)\nprint('Recall score is:',recallScore)","0f46ea1b":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train, y_train_pred)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","7771574e":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_test, y_test_pred)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","432cfc50":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","6fa3090a":"# Storing all metics in the model metrics data frame\ntrainAccuracy = metrics.accuracy_score(y_train, y_train_pred)\ntrainPrecision = precision_score(y_train, y_train_pred)\ntrainRecall = recall_score(y_train, y_train_pred)\ntestAccuracy = metrics.accuracy_score(y_test, y_test_pred)\ntestPrecision = precision_score(y_test, y_test_pred)\ntestRecall = recall_score(y_test, y_test_pred)\n\nhyperparams = 'max_depth=4,n_estimators=200,max_features=10,min_samples_leaf=15,min_samples_split=90'\n#Adding metrics into the dataframe\ndfAllModelMetrics.loc[dfAllModelMetrics.shape[0]] = ['Random_Forest_RandomOversampling_Tuned', hyperparams, \n                TN, FP, FN, TP,\n                trainAccuracy,trainPrecision,trainRecall,\n                testAccuracy,testPrecision,testRecall]","d234635f":"dfAllModelMetrics.head()","2c61b3b4":"import warnings\nwarnings.filterwarnings(\"ignore\")\n\n\nsmotesampl = SMOTE(random_state=0)\nX_train_smote, y_train_smote = smotesampl.fit_resample(X_train, y_train)\n# Artificial minority samples and corresponding minority labels from SMOTE are appended\n# below X_train and y_train respectively\n# So to exclusively get the artificial minority samples from SMOTE, we do\nX_train_smote_1 = X_train_smote[X_train.shape[0]:]\n\nX_train_1 = X_train.to_numpy()[np.where(y_train==1.0)]\nX_train_0 = X_train.to_numpy()[np.where(y_train==0.0)]\n\n\nplt.rcParams['figure.figsize'] = [20, 20]\nfig = plt.figure()\n\nplt.subplot(3, 1, 1)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.legend()\n\nplt.subplot(3, 1, 2)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.scatter(X_train_smote_1[:X_train_1.shape[0], 0], X_train_smote_1[:X_train_1.shape[0], 1],\n            label='Artificial SMOTE Class-1 Examples')\nplt.legend()\n\nplt.subplot(3, 1, 3)\nplt.scatter(X_train_1[:, 0], X_train_1[:, 1], label='Actual Class-1 Examples')\nplt.scatter(X_train_0[:X_train_1.shape[0], 0], X_train_0[:X_train_1.shape[0], 1], label='Actual Class-0 Examples')\nplt.legend()","7d8bdc12":"print('After OverSampling, the shape of train_X: {}'.format(X_train_smote.shape))\nprint('After OverSampling, the shape of train_y: {} \\n'.format(y_train_smote.shape))\n\nprint(\"After OverSampling, counts of label '1': {}\".format(sum(y_train_smote==1)))\nprint(\"After OverSampling, counts of label '0': {}\".format(sum(y_train_smote==0)))","1fd13c1b":"#Creating dataframe from resampled data\nX_train_smote_res=pd.DataFrame(data=X_train_smote[0:,0:],\n                               index=[i for i in range(X_train_smote.shape[0])],\n                               columns=X_train.columns)\n\ny_train_smote_res=pd.DataFrame(data=y_train_smote,\n                               index=[i for i in range(y_train_smote.shape[0])],\n                               columns=['Class'])","5bed501c":"#Taking backup of the data to use for different models\nX_train_smote_res_bkup = X_train_smote_res.copy()\ny_train_smote_res_bkup = y_train_smote_res.copy()","d3467aa9":"# Logistic regression model\nlogm1 = sm.GLM(y_train_smote_res,(sm.add_constant(X_train_smote_res)), family = sm.families.Binomial())\nlogm1.fit().summary()","45fc7cfb":"X_train_smote_res = X_train_smote_res.drop(['V23'], axis = 1)","2a2628d9":"# Logistic regression model\nlogm1 = sm.GLM(y_train_smote_res,(sm.add_constant(X_train_smote_res)), family = sm.families.Binomial())\nlogm1.fit().summary()","692e75a7":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_smote_res.columns\nvif['VIF'] = [variance_inflation_factor(X_train_smote_res.values, i) for i in range(X_train_smote_res.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","ee52ce8d":"# Using RFE for feature selection\nlogreg = LogisticRegression()\nrfe = RFE(logreg, 15)             # running RFE with 15 variables as output\nrfe = rfe.fit(X_train_smote_res, y_train_smote_res)","c6920734":"list(zip(X_train_smote_res.columns, rfe.support_, rfe.ranking_))","955673c3":"# Lets create a list with rfe support columns list\ncol = X_train_smote_res.columns[rfe.support_]","f9054657":"# Applying logistic regression on RFE supported features\nX_train_smote_res = sm.add_constant(X_train_smote_res[col])\nLR2 = sm.GLM(y_train_smote_res,X_train_smote_res, family = sm.families.Binomial())\nres = LR2.fit()\nres.summary()","3ab77fd1":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_smote_res[col].columns\nvif['VIF'] = [variance_inflation_factor(X_train_smote_res[col].values, i) for i in range(X_train_smote_res[col].shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","37bad3ac":"# Dropping one by one progressively and rechecking VIF and subsequently dropping\n# X_train_smote_res = X_train_smote_res.drop(['V10','V17','V14','V12','const'], axis = 1)\nX_train_smote_res = X_train_smote_res.drop(['V12'], axis = 1)","8f9bf059":"# Create a dataframe that will contain the names of all the feature variables and their respective VIFs\nvif = pd.DataFrame()\nvif['Features'] = X_train_smote_res.columns\nvif['VIF'] = [variance_inflation_factor(X_train_smote_res.values, i) for i in range(X_train_smote_res.shape[1])]\nvif['VIF'] = round(vif['VIF'], 2)\nvif = vif.sort_values(by = \"VIF\", ascending = False)\nvif","afeea0b6":"# Applying logistic regression on RFE supported features\nX_train_smote_res = sm.add_constant(X_train_smote_res)\nlogReg_Final = sm.GLM(y_train_smote_res,X_train_smote_res, family = sm.families.Binomial())\nres = logReg_Final.fit()\nres.summary()","c7350a4e":"# Lets predict churn on Train data\ny_train_smote_res_pred = res.predict(X_train_smote_res).values.reshape(-1)","6203c38c":"# Lets create a data frame with Original Class values and predicted Class probability values \ny_train_smote_res_pred_final = pd.DataFrame({'Class':y_train_smote_res['Class'], 'Class_Prob':y_train_smote_res_pred})\ny_train_smote_res_pred_final.head()","faf57d2a":"# Precison - recall curve\np, r, thresholds = precision_recall_curve(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.Class_Prob)\nplt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.grid(b=None, which='major', axis='both')\nplt.show()","deb9c144":"# Lets see how the predicted va;lues turn out with 50% probability cut off\ny_train_smote_res_pred_final['predicted'] = y_train_smote_res_pred_final.Class_Prob.map(lambda x: 1 if x > 0.39 else 0)\n\n# Let's see the head\ny_train_smote_res_pred_final.head()","06498d15":"# Let's check the overall accuracy.\nprint(metrics.accuracy_score(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.predicted))\n# find precision score and recall score\nprecisionScore = precision_score(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.predicted)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.predicted)\nprint('Recall score is:',recallScore)","43660209":"# Lets find out F1 score\nf1Score = 2 * (precisionScore * recallScore)\/(precisionScore + recallScore)\nprint('F1 Score is:',f1Score)","0655e60b":"# Creating a function to draw ROC curve\ndef draw_roc( actual, probs ):\n    fpr, tpr, thresholds = metrics.roc_curve( actual, probs,\n                                              drop_intermediate = False )\n    auc_score = metrics.roc_auc_score( actual, probs )\n    plt.figure(figsize=(5, 5))\n    plt.plot( fpr, tpr, label='ROC (AUC) = %0.2f)' % auc_score )\n    plt.plot([0, 1], [0, 1], 'k--')\n    plt.xlim([0.0, 1.0])\n    plt.ylim([0.0, 1.05])\n    plt.xlabel('False Positive Rate or [1 - True Negative Rate]')\n    plt.ylabel('True Positive Rate')\n    plt.title('Receiver operating characteristic ROC')\n    plt.legend(loc=\"lower right\")\n    plt.grid(b=None, which='major', axis='both')\n    plt.show()\n\n    return None","1798db57":"fpr, tpr, thresholds = metrics.roc_curve( y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.Class_Prob, drop_intermediate = False )\n","b547ca57":"# Lets call the ROC plot fucnction on our model.\ndraw_roc(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.Class_Prob)","d6083dc1":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.predicted)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","bdd5219a":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","6c6958f8":"# Let's calculate some advanced metrics like sensitivity, specificity etc of our logistic regression model\nprint('Sensitivity or recall of the model is:',np.round(TP \/ float(TP+FN),2))\nprint('Specificity of the model is:',np.round(TN \/ float(TN+FP),2))\nprint('False Positive Rate for model is:',np.round(FP\/ float(TN+FP),2))\nprint('Positive predictive value or precision is:',np.round(TP \/ float(TP+FP),2))\nprint('Negative predictive value is:',np.round(TN \/ float(TN+ FN),2))","f5478798":"X_test.columns","7299fc5b":"cols = X_train_smote_res.drop('const',axis=1).columns","1169a986":"X_test_lr = X_test[cols]\nX_test_lr.head()","1e7f652b":"# lets predict churn on Test data\nX_test_lr = sm.add_constant(X_test_lr)\ny_test_smote_res_pred = res.predict(X_test_lr).values.reshape(-1)","5303e502":"y_test_smote_res_pred[:10]","d813ebb4":"# Creating a data frame with original churn values and predicted churn probability values\ny_test_smote_res_pred_final = pd.DataFrame({'Class':y_test, 'Class_Prob':y_test_smote_res_pred})\ny_test_smote_res_pred_final.head()","87aef179":"# We will take same 0,5 as probability cut off on test set as well as this is the probability we have choosen on train set as well\ny_test_smote_res_pred_final['predicted'] = y_test_smote_res_pred_final.Class_Prob.map(lambda x: 1 if x > 0.41 else 0)\n\n# Let's see the head\ny_test_smote_res_pred_final.head()","2f999589":"# Let's check the overall accuracy.\nprint('Accuracy:',metrics.accuracy_score(y_test_smote_res_pred_final.Class, y_test_smote_res_pred_final.predicted))\n# find precision score and recall score\nprecisionScore = precision_score(y_test_smote_res_pred_final.Class, y_test_smote_res_pred_final.predicted)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_test_smote_res_pred_final.Class, y_test_smote_res_pred_final.predicted)\nprint('Recall score is:',recallScore)","d1532d4c":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_test_smote_res_pred_final.Class, y_test_smote_res_pred_final.predicted)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","612d137a":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","2981a3a2":"# Let's calculate some advanced metrics like sensitivity, specificity etc of our logistic regression model\nprint('Sensitivity or recall of the model is:',np.round(TP \/ float(TP+FN),2))\nprint('Specificity of the model is:',np.round(TN \/ float(TN+FP),2))\nprint('False Positive Rate for model is:',np.round(FP\/ float(TN+FP),2))\nprint('Positive predictive value or precision is:',np.round(TP \/ float(TP+FP),2))\nprint('Negative predictive value is:',np.round(TN \/ float(TN+ FN),2))","393ab002":"# Lets call the ROC plot fucnction on our model.\ndraw_roc(y_test_smote_res_pred_final.Class, y_test_smote_res_pred_final.Class_Prob)","cade8ca9":"# Creating a data frame to store metrics of all the models for easy comparision later \ndfAllModelMetrics = pd.DataFrame(columns=['ModelName','Hyperparams',\n                                          'TestTN','TestFP','TestFN','TestTP',\n                                          'TrainAccuracy','TrainPrecision','TrainRecall',\n                                          'TestAccuracy','TestPrecision','TestRecall'])","79815851":"# Storing all metics in the model metrics data frame\ntrainAccuracy = metrics.accuracy_score(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.predicted)\ntrainPrecision = precision_score(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.predicted)\ntrainRecall = recall_score(y_train_smote_res_pred_final.Class, y_train_smote_res_pred_final.predicted)\ntestAccuracy = metrics.accuracy_score(y_test_smote_res_pred_final.Class, y_test_smote_res_pred_final.predicted)\ntestPrecision = precision_score(y_test_smote_res_pred_final.Class, y_test_smote_res_pred_final.predicted)\ntestRecall = recall_score(y_test_smote_res_pred_final.Class, y_test_smote_res_pred_final.predicted)\n\n#Adding metrics into the dataframe\ndfAllModelMetrics.loc[dfAllModelMetrics.shape[0]] = ['LogisticRegression_SMOTE', '', \n                TN, FP, FN, TP,\n                trainAccuracy,trainPrecision,trainRecall,\n                testAccuracy,testPrecision,testRecall]","eb0f541e":"# Visualizing the metrics dataframe\ndfAllModelMetrics","4ac5947d":"X_train_smote_res_rf = X_train_smote_res_bkup.copy()\nX_test_smote_res_rf = X_test.copy()\ny_train_smote_res_rf = y_train_smote_res_bkup.copy()\ny_test_smote_res_rf = y_test.copy()","0aef4744":"# Running the random forest with default parameters.\nrfc = RandomForestClassifier(class_weight='balanced')\n\n# fit\nrfc.fit(X_train_smote_res_rf,y_train_smote_res_rf)\n\n# Making predictions\ny_train_pred = rfc.predict(X_train_smote_res_rf)\ny_test_pred = rfc.predict(X_test_smote_res_rf)","0f670d2c":"# Printing classification report\nprint(classification_report(y_train_smote_res_rf, y_train_pred))\nprint(metrics.accuracy_score(y_train_smote_res_rf, y_train_pred))\n# find precision score and recall score\nprecisionScore = precision_score(y_train_smote_res_rf, y_train_pred)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_train_smote_res_rf, y_train_pred)\nprint('Recall score is:',recallScore)","978150ae":"# Printing classification report\nprint(classification_report(y_test_smote_res_rf, y_test_pred))\nprint(metrics.accuracy_score(y_test_smote_res_rf, y_test_pred))\n# find precision score and recall score\nprecisionScore = precision_score(y_test_smote_res_rf, y_test_pred)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_test_smote_res_rf, y_test_pred)\nprint('Recall score is:',recallScore)","aea0f8d0":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_test_smote_res_rf, y_test_pred)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","222c373a":"trainAccuracy = metrics.accuracy_score(y_train_smote_res_rf, y_train_pred)\ntrainPrecision = precision_score(y_train_smote_res_rf, y_train_pred)\ntrainRecall = recall_score(y_train_smote_res_rf, y_train_pred)\ntestAccuracy = metrics.accuracy_score(y_test_smote_res_rf, y_test_pred)\ntestPrecision = precision_score(y_test_smote_res_rf, y_test_pred)\ntestRecall = recall_score(y_test_smote_res_rf, y_test_pred)\n\nTP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives\n\ndfAllModelMetrics.loc[dfAllModelMetrics.shape[0]] = ['RandomForest_SMOTE_Default', '', \n                TN, FP, FN, TP,\n                trainAccuracy,trainPrecision,trainRecall,\n                testAccuracy,testPrecision,testRecall]","3360c53f":"dfAllModelMetrics.head()","13af9be4":"from imblearn.over_sampling import SMOTE","e99361bb":"#Initialising the ADASYN object\nsmotesampl = SMOTE(sampling_strategy='minority',random_state=101)","58a0adb5":"#fit_resample on the train sets to produce the new resampled sets.\nX_train_smote,y_train_smote = smotesampl.fit_resample(X_train,y_train)","d3935171":"X_train_smote.shape","156ae99b":"y_train_smote.shape","8462800c":"X_train_smote = pd.DataFrame(X_train_smote,columns=X_train.columns)","49ae1d74":"y_train_smote = pd.DataFrame(y_train_smote,columns=['Fraud'])","985de78c":"#Data Inbalance check for the Converted column.\nyes=y_train_smote[y_train_smote['Fraud']==1]['Fraud'].value_counts()\nno=y_train_smote[y_train_smote['Fraud']==0]['Fraud'].value_counts()\n\nconverted=np.array((yes\/len(y_train_smote))*100) \nnot_converted=np.array((no\/len(y_train_smote))*100) \nstat_summ=pd.DataFrame({'Percentage':[converted[0],not_converted[0]]},index=['Fraud','Not_Fraud'])\nplt.figure(figsize=(5,5))\nsns.barplot(x=stat_summ.index,y=stat_summ['Percentage'],palette='RdYlGn')\nplt.title('Check on the data imbalance')\nplt.show()","b153e0d2":"X_train_smote.shape","d151e789":"y_train_smote.shape","03307295":"X_train_smote_new = X_train_smote.copy()","7716f7e9":"X_train_smote_new['Fraud'] = y_train_smote['Fraud']","f77c2c0e":"X_train_smote_fraud = X_train_smote_new.loc[X_train_smote_new['Fraud']==1]","04353824":"X_train_smote_non_fraud = X_train_smote_new.loc[X_train_smote_new['Fraud']==0]","d9ee2396":"X_train_smote_fraud.shape","7d9c5cb2":"X_train_smote_non_fraud.shape","da978fc7":"X_train_smote_fraud = X_train_smote_fraud.sample(frac=1)","55ba36c4":"X_train_smote_non_fraud = X_train_smote_non_fraud.sample(frac=1)","0294bcd5":"X_train_smote_fraud = X_train_smote_fraud[:50000]\nX_train_smote_non_fraud = X_train_smote_non_fraud[:50000]","783a4704":"frames = [X_train_smote_fraud,X_train_smote_non_fraud]\nX_train_smote_final = pd.concat(frames)","8333c477":"X_train_smote_final = X_train_smote_final.sample(frac=1)","bbc10c64":"X_train_smote_final","8d2ad021":"X_train_smote_sampled = X_train_smote_final.drop(['Fraud'],axis=1)\ny_train_smote_sampled = X_train_smote_final['Fraud']","19eee886":"from sklearn.ensemble import RandomForestClassifier","60db8b9a":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_depth': range(2, 12, 3)}\n# instantiate the model\nrf = RandomForestClassifier()\n# fit tree on training data\nrf = GridSearchCV(rf, parameters,cv=n_folds,scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_smote_sampled,y_train_smote_sampled)\nend = time.time()","55e0cf1a":"print(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","7caa9478":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","3c6bd8ec":"# plotting accuracies with max_depth\nplt.figure(figsize=(5,5))\nplt.plot(scores[\"param_max_depth\"], \n         scores[\"mean_train_score\"], \n         label=\"training recall\")\nplt.plot(scores[\"param_max_depth\"], \n         scores[\"mean_test_score\"], \n         label=\"test recall\")\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","841ca54e":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'n_estimators': range(200, 900, 200)}\n# instantiate the model (note we are specifying a max_depth)\nrf = RandomForestClassifier(max_depth=8)\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds,scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_smote_sampled,y_train_smote_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","8a5b64a7":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","3b96475f":"# plotting accuracies with n_estimators\nplt.figure(figsize=(5,5))\nplt.plot(scores[\"param_n_estimators\"], \n         scores[\"mean_train_score\"], \n         label=\"test accuracy\")\nplt.plot(scores[\"param_n_estimators\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","7bab9729":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_features': [4, 8, 14, 20, 24]}\n# instantiate the model\nrf = RandomForestClassifier(max_depth=8,\n                            n_estimators=200)\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_smote_sampled,y_train_smote_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","a1848adf":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","9b31aa1b":"# plotting accuracies with max_features\nplt.figure(figsize=(5,5))\nplt.plot(scores[\"param_max_features\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_max_features\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"max_features\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","b07a4275":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'min_samples_leaf': range(50,300,50)}\n# instantiate the model\nrf = RandomForestClassifier(max_depth=8,\n                            n_estimators=200,\n                            max_features=14)\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_smote_sampled,y_train_smote_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","ee2fdce5":"# scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","4e2a6dc3":"# plotting accuracies with min_samples_leaf\nplt.figure(figsize=(5,5))\nplt.plot(scores[\"param_min_samples_leaf\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_min_samples_leaf\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"min_samples_leaf\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","67768ca9":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'min_samples_split': range(100, 300, 50)}\n# instantiate the model\nrf = RandomForestClassifier(max_depth=8,\n                            n_estimators=200,\n                            max_features=14,\n                            min_samples_leaf=150)\n# fit tree on training data\nrf = GridSearchCV(rf, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nrf.fit(X_train_smote_sampled,y_train_smote_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","a6247b89":" # scores of GridSearch CV\nscores = rf.cv_results_\npd.DataFrame(scores).head()","ca581641":"# plotting accuracies with min_samples_split\nplt.figure(figsize=(5,5))\nplt.plot(scores[\"param_min_samples_split\"], \n         scores[\"mean_train_score\"], \n         label=\"training accuracy\")\nplt.plot(scores[\"param_min_samples_split\"], \n         scores[\"mean_test_score\"], \n         label=\"test accuracy\")\nplt.xlabel(\"min_samples_split\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","a026db24":"rf = RandomForestClassifier(n_estimators=200,\n                            max_depth=8,\n                            max_features=14,\n                            min_samples_leaf=150,\n                            min_samples_split=200)\nrf.fit(X_train_smote_sampled,y_train_smote_sampled)","f34468ac":"y_train_pred_rf_smote = rf.predict(X_train_smote_sampled)","f59bc43e":"accuracy_score(y_train_smote_sampled,y_train_pred_rf_smote)","fb3504ab":"# Printing classification report\nprint(classification_report(y_train_smote_sampled, y_train_pred_rf_smote))\nprint(metrics.accuracy_score(y_train_smote_sampled, y_train_pred_rf_smote))\n# find precision score and recall score\nprecisionScore = precision_score(y_train_smote_sampled, y_train_pred_rf_smote)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_train_smote_sampled, y_train_pred_rf_smote)\nprint('Recall score is:',recallScore)","37073123":"# Confusion matrix \nconfusion = metrics.confusion_matrix(y_train_smote_sampled,y_train_pred_rf_smote)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","0bc8e152":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","7d73048a":"confusion","d5a512c6":"X_test.shape","247bc650":"y_test.shape","ce1ec6a8":"y_test_pred_rf_smote = rf.predict(X_test)","7ec11e58":"# Printing classification report\nprint(classification_report(y_test, y_test_pred_rf_smote))\nprint(metrics.accuracy_score(y_test, y_test_pred_rf_smote))\n# find precision score and recall score\nprecisionScore = precision_score(y_test, y_test_pred_rf_smote)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_test, y_test_pred_rf_smote)\nprint('Recall score is:',recallScore)","41dd1465":"# Confusion matrix \nconfusion_rf_smote = metrics.confusion_matrix(y_test, y_test_pred_rf_smote)\nprint(confusion_rf_smote)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion_rf_smote, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","e1200b83":"TP = confusion_rf_smote[1,1] # true positive \nTN = confusion_rf_smote[0,0] # true negatives\nFP = confusion_rf_smote[0,1] # false positives\nFN = confusion_rf_smote[1,0] # false negatives","58c397b6":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","779bab4a":"#Specificity\nTN \/ float(TN + FP)","e10bc8ae":"#Precision\nTP \/ float(TP+FP)","b889d23f":"# Storing all metics in the model metrics data frame\ntrainAccuracy = metrics.accuracy_score(y_train_smote_sampled, y_train_pred_rf_smote)\ntrainPrecision = precision_score(y_train_smote_sampled, y_train_pred_rf_smote)\ntrainRecall = recall_score(y_train_smote_sampled, y_train_pred_rf_smote)\ntestAccuracy = metrics.accuracy_score(y_test, y_test_pred_rf_smote)\ntestPrecision = precision_score(y_test, y_test_pred_rf_smote)\ntestRecall = recall_score(y_test, y_test_pred_rf_smote)\n\nparams = 'n_estimators=200,max_depth=8,max_features=14,min_samples_leaf=150,min_samples_split=200'\n#Adding metrics into the dataframe\ndfAllModelMetrics.loc[dfAllModelMetrics.shape[0]] = ['Random_Forest_SMOTE_Tuned', params, \n                TN, FP, FN, TP,\n                trainAccuracy,trainPrecision,trainRecall,\n                testAccuracy,testPrecision,testRecall]\n\ndfAllModelMetrics.head()","bf87d4fe":"X_train_smote_sampled.shape","6e51a41f":"y_train_smote_sampled.shape","67ccc3a2":"#Importing the libraries for XGBoost.\nimport xgboost as xgb\nfrom xgboost import XGBClassifier\nfrom xgboost import plot_importance","5cbddafd":"import time","6fc859d6":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'max_depth': range(2, 20, 4)}\n# instantiate the model\nxgb_model = XGBClassifier()\n# fit tree on training data\nxgb_model1 = GridSearchCV(xgb_model, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nxgb_model1.fit(X_train_smote_sampled,y_train_smote_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","5b9162b0":"cv_results = pd.DataFrame(xgb_model1.cv_results_)","27021009":"cv_results","96b56a50":"# plotting accuracies with max_depth\nplt.figure(figsize=(5,5))\nplt.plot(cv_results[\"param_max_depth\"], \n         cv_results[\"mean_train_score\"], \n         label=\"training recall\")\nplt.plot(cv_results[\"param_max_depth\"], \n         cv_results[\"mean_test_score\"], \n         label=\"test recall\")\nplt.xlabel(\"max_depth\")\nplt.ylabel(\"recall\")\nplt.legend()\nplt.show()","b58c656e":"start = time.time()\n# specify number of folds for k-fold CV\nn_folds = 3\n# parameters to build the model on\nparameters = {'n_estimators': range(100, 900, 200)}\n# instantiate the model (note we are specifying a max_depth)\nxgb_model = XGBClassifier(max_depth=6)\n# fit tree on training data\nxgb_model1 = GridSearchCV(xgb_model, parameters, cv=n_folds, scoring=\"recall\",return_train_score=True)\nxgb_model1.fit(X_train_smote_sampled,y_train_smote_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","bbbf5f34":"cv_results = pd.DataFrame(xgb_model1.cv_results_)","36ec13f2":"cv_results","731f3567":"# plotting accuracies with n_estimators\nplt.figure(figsize=(5,5))\nplt.plot(cv_results[\"param_n_estimators\"], \n         cv_results[\"mean_test_score\"], \n         label=\"test recall\")\nplt.plot(cv_results[\"param_n_estimators\"], \n         cv_results[\"mean_train_score\"], \n         label=\"train recall\")\nplt.xlabel(\"n_estimators\")\nplt.ylabel(\"Recall\")\nplt.legend()\nplt.show()","16ecbfc6":"start = time.time()\n# hyperparameter tuning with XGBoost\n# creating a KFold object \nfolds = 3\n# specify range of hyperparameters\nparam_grid = {'learning_rate': [0.1, 0.2, 0.3, 0.4], \n             'subsample': [0.3, 0.6, 0.9]}          \n\n# specify model\nxgb_model = XGBClassifier(max_depth=6,\n                          n_estimators=300)\n\n# set up GridSearchCV()\nmodel_cv = GridSearchCV(estimator = xgb_model, \n                        param_grid = param_grid, \n                        scoring= 'recall', \n                        cv = folds,  \n                        verbose = 1,\n                        return_train_score=True)  \nmodel_cv.fit(X_train_smote_sampled,y_train_smote_sampled)\nend = time.time()\nprint(\"Amount of time taken for the above query in minutes:\",round((end-start)\/60 ,2))","bbf3f5d2":"# cv results\ncv_results = pd.DataFrame(model_cv.cv_results_)\ncv_results","e4f30aab":"# convert parameters to int for plotting on x-axis\ncv_results['param_learning_rate'] = cv_results['param_learning_rate'].astype('float')\ncv_results['param_subsample'] = cv_results['param_subsample'].astype('float')\ncv_results.head()","8a125acb":"cv_results['mean_test_score'].value_counts()","35884b7a":"cv_results['mean_train_score'].value_counts()","1e5ed2a5":"#plotting\nplt.figure(figsize=(16,6))\nparam_grid = {'learning_rate': [0.1, 0.2, 0.3, 0.4], \n             'subsample': [0.3, 0.6, 0.9]} \nfor n, subsample in enumerate(param_grid['subsample']):\n    # subplot 1\/n\n    plt.subplot(1,len(param_grid['subsample']), n+1)\n    df = cv_results[cv_results['param_subsample']==subsample]\n\n    plt.plot(df[\"param_learning_rate\"], df[\"mean_test_score\"])\n    plt.plot(df[\"param_learning_rate\"], df[\"mean_train_score\"])\n    plt.xlabel('learning_rate')\n    plt.ylabel('recall')\n    plt.title(\"subsample={0}\".format(subsample))\n    plt.ylim([0.60, 1])\n    plt.legend(['test score', 'train score'], loc='upper left')\n    plt.xscale('log')","09d48713":"# chosen hyperparameters\n# 'objective':'binary:logistic' outputs probability rather than label, which we need for auc\nparams = {'learning_rate':0.1,\n          'max_depth':6, \n          'n_estimators':300,\n          'subsample':0.3,\n         'objective':'binary:logistic'}\n\n# fit model on training data\nmodel = XGBClassifier(params = params)\nmodel.fit(X_train_smote_sampled,y_train_smote_sampled)","4fe27bfd":"# predict\ny_pred = model.predict_proba(X_train_smote_sampled)\ny_pred[:10]","1112a8ee":"import sklearn","0324d8eb":"# roc_auc\nauc = sklearn.metrics.roc_auc_score(y_train_smote_sampled, y_pred[:, 1])\nauc","71de36de":"xgb_df = pd.DataFrame(y_pred[:, 1],columns=[\"Predicted_probability\"])","cc72c8ba":"xgb_df['Churn'] = y_train_smote_sampled.values","ab892611":"xgb_df","5bbcf3df":"# Let's create columns with different probability cutoffs \nnumbers = [float(x)\/10 for x in range(10)]\nfor i in numbers:\n    xgb_df[i]= xgb_df.Predicted_probability.map(lambda x: 1 if x > i else 0)\nxgb_df.head()","377a25a3":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df = pd.DataFrame( columns = ['probability','accuracy','sensitivity','specificity'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(xgb_df.Churn, xgb_df[i] )\n    total1=sum(sum(cm1))\n    accuracy = (cm1[0,0]+cm1[1,1])\/total1\n    \n    speci = cm1[0,0]\/(cm1[0,0]+cm1[0,1])\n    sensi = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df.loc[i] =[ i ,accuracy,sensi,speci]\nprint(cutoff_df)","b197eb6d":"# Let's plot accuracy sensitivity and specificity for various probabilities.\nplt.figure(figsize=(5,5))\ncutoff_df.plot.line(x='probability', y=['accuracy','sensitivity','specificity'])\nplt.show()","edca1671":"# Now let's calculate accuracy sensitivity and specificity for various probability cutoffs.\ncutoff_df1 = pd.DataFrame( columns = ['probability','precision','recall'])\nfrom sklearn.metrics import confusion_matrix\n\n# TP = confusion[1,1] # true positive \n# TN = confusion[0,0] # true negatives\n# FP = confusion[0,1] # false positives\n# FN = confusion[1,0] # false negatives\n\nnum = [0.0,0.1,0.2,0.3,0.4,0.5,0.6,0.7,0.8,0.9]\nfor i in num:\n    cm1 = confusion_matrix(xgb_df.Churn, xgb_df[i] )\n    total1=sum(sum(cm1))\n    prec = cm1[1,1]\/(cm1[1,1]+cm1[0,1])\n    rec = cm1[1,1]\/(cm1[1,0]+cm1[1,1])\n    cutoff_df1.loc[i] =[ i ,prec, rec]\nprint(cutoff_df1)","ee25210b":"# Let's plot accuracy sensitivity and specificity for various probabilities.\nplt.figure(figsize=(5,5))\ncutoff_df1.plot.line(x='probability', y=['precision','recall'])\nplt.show()","9ae64ffe":"#Selecting the cut-off probability as 0.4 and predicting for Churn.\nxgb_df['Final_predicted'] = xgb_df.Predicted_probability.map( lambda x: 1 if x > 0.4 else 0)\nxgb_df.head()","b1b772fb":"y_pred_test = model.predict_proba(X_test)\ny_pred_test[:10]","ecf33772":"xgb_test_df = pd.DataFrame(y_pred_test[:, 1],columns=[\"Predicted_probability\"])","88e299d8":"xgb_test_df['y_test'] = y_test.values","88656bd8":"xgb_test_df","24ec4311":"#Selecting the cut-off probability as 0.4 and predicting for Churn.\nxgb_test_df['Final_predicted'] = xgb_test_df.Predicted_probability.map( lambda x: 1 if x > 0.4 else 0)\nxgb_test_df.head()","0b67e41b":"# Printing classification report\nprint(classification_report(y_test, xgb_test_df.Final_predicted))\nprint(metrics.accuracy_score(y_test, xgb_test_df.Final_predicted))\n# find precision score and recall score\nprecisionScore = precision_score(y_test, xgb_test_df.Final_predicted)\nprint('Precision score is:',precisionScore)\nrecallScore = recall_score(y_test, xgb_test_df.Final_predicted)\nprint('Recall score is:',recallScore)","b925cf9a":"confusion_xgb = confusion_matrix(xgb_test_df['y_test'],xgb_test_df['Final_predicted'])\nconfusion_xgb","2c8ad224":"TP = confusion_xgb[1,1] # true positive \nTN = confusion_xgb[0,0] # true negatives\nFP = confusion_xgb[0,1] # false positives\nFN = confusion_xgb[1,0] # false negatives","0fea34ad":"# Confusion matrix \nconfusion_xgb = confusion_matrix(xgb_test_df['y_test'],xgb_test_df['Final_predicted'])\nprint(confusion_xgb)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion_xgb, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","f8eed1e9":"#Sensitivity \/ Recall\nTP \/ float(TP + FN)","e6f3e969":"#Specificity\nTN \/ float(TN + FP)","5e1dba5c":"#Precision\nTP \/ float(TP + FP)","2caf3673":"# Storing all metics in the model metrics data frame\ntrainAccuracy = metrics.accuracy_score(y_train_smote_sampled, y_train_pred_rf_smote)\ntrainPrecision = precision_score(y_train_smote_sampled, y_train_pred_rf_smote)\ntrainRecall = recall_score(y_train_smote_sampled, y_train_pred_rf_smote)\ntestAccuracy = metrics.accuracy_score(y_test, y_test_pred_rf_smote)\ntestPrecision = precision_score(y_test, y_test_pred_rf_smote)\ntestRecall = recall_score(y_test, y_test_pred_rf_smote)\n\nparams = 'n_estimators=200,max_depth=8,max_features=14,min_samples_leaf=150,min_samples_split=200'\n#Adding metrics into the dataframe\ndfAllModelMetrics.loc[dfAllModelMetrics.shape[0]] = ['Random_Forest_SMOTE_Tuned', params, \n                TN, FP, FN, TP,\n                trainAccuracy,trainPrecision,trainRecall,\n                testAccuracy,testPrecision,testRecall]\n\ndfAllModelMetrics.head()","bebca4f5":"import matplotlib.pyplot as plt\nplt.rcParams.update({'figure.max_open_warning':0})\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN\nfrom imblearn.combine import SMOTETomek,SMOTEENN\n\nimport lightgbm as lgb\n\nimport xgboost as xgb\nfrom xgboost.sklearn import XGBClassifier\n\n\nfrom sklearn.metrics import roc_auc_score,classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n!pip install bayesian-optimization\nfrom bayes_opt import BayesianOptimization","f786be0e":"y_train_df = pd.DataFrame(y_train)","2a9c8007":"# Scaling weight = Ratio of number of 0's to 1's so it can scale the weight of 1's\nscale_pos_weight_factor = y_train[y_train_df.Class==0].shape[0] \/ y_train[y_train_df.Class==1].shape[0]","af76f641":"def xgb_best_params(X,y,opt_params,init_points=10, optimization_round=5, n_folds=3, random_seed=0, cv_estimators=600): \n    # prepare dataset\n    training_data = xgb.DMatrix(X, y)\n    \n    def xgb_run(learning_rate,max_depth,min_child_weight,gamma,subsample,colsample_bytree,reg_alpha,reg_lambda):\n        params = {'objective':'binary:logistic','n_estimators':cv_estimators,'scale_pos_weight':scale_pos_weight_factor ,'early_stopping_round':int(cv_estimators\/20), 'metric':'auc'}\n        params[\"gamma\"] = gamma\n        params['subsample'] = subsample\n        params['colsample_bytree'] = colsample_bytree\n        params['max_depth'] = int(round(max_depth))\n        params['reg_alpha'] = reg_alpha\n        params['reg_lambda'] = reg_lambda\n        params['min_child_weight'] = int(min_child_weight)\n        params['learning_rate'] = learning_rate\n        cv_result = xgb.cv(params, training_data, nfold=n_folds, seed=random_seed ,stratified=True,shuffle=True ,verbose_eval =int(cv_estimators\/20),num_boost_round=cv_estimators, metrics='auc')\n\n        return cv_result['test-auc-mean'].max()\n    \n    \n    params_finder = BayesianOptimization(xgb_run, opt_params, random_state=100)\n    # optimize\n    params_finder.maximize(init_points=init_points, n_iter=optimization_round)\n\n    # return best parameters\n    return params_finder.max","4b4084ad":"folds = 3\n\nbounds = {\n    'learning_rate': (0.002, 0.2),\n    'max_depth':(1,20),\n    'min_child_weight':(1,100),\n    'gamma':(0,1),\n    'subsample':(0.1,1),\n    'colsample_bytree':(0.1,0.8),\n    'reg_alpha':(0.1,20),\n    'reg_lambda':(0.1,20)\n}","1115a6f6":"#a = []\n#while(1):\n#    a.append('1000000')","ff76a656":"best_params= []\ncv_estimators = [500]\noptimization_round = 10\ninit_points = 10\nrandom_seed = 0\n    \n    \nfor cv_estimator in cv_estimators:\n    opt_params = xgb_best_params(X, y,bounds, init_points=init_points, optimization_round=optimization_round, n_folds=folds, random_seed=random_seed, cv_estimators=cv_estimator)\n    opt_params['params']['iteration'] = cv_estimator\n    opt_params['params']['fold'] = folds\n    opt_params['params']['auc'] = opt_params['target']\n    best_params.append(opt_params['params'])\n","387c0e6f":"max_auc = 0\nmax_auc_index = -1\nfor idx in range(0,len(best_params)):\n  if best_params[idx]['auc'] > max_auc:\n    max_auc = best_params[idx]['auc']\n    max_auc_index = idx\n\nxgb_best_params = best_params[max_auc_index]\n\nprint('***** PARAMETERS WITH TOP AUC SCORE *****')\nfor key in xgb_best_params:\n  print(key,':',xgb_best_params[key])","432a2db3":"xgb_best_params","48fd464f":"xgb_tuned_params = xgb_best_params.copy()\ndel xgb_tuned_params['auc']\nxgb_tuned_params['metric'] = 'auc'\nxgb_tuned_params['max_depth'] = int(xgb_tuned_params['max_depth'])\nxgb_tuned_params['min_child_weight'] = int(xgb_tuned_params['min_child_weight'])","ccccff07":"training_data = xgb.DMatrix(X_train, y_train)\nxgb_tuned_model = xgb.train(xgb_tuned_params,training_data)","cfa1ce1c":"xgb_train_data = xgb.DMatrix(X_train[X.columns])\ny_train_pred_bo_xgb = xgb_tuned_model.predict(xgb_train_data)","b1fa58e2":"xgb_test_data = xgb.DMatrix(X_test[X.columns])\ny_test_pred_bo_xgb = xgb_tuned_model.predict(xgb_test_data)","7a65c1b2":"print(roc_auc_score(y_train,y_train_pred_bo_xgb))","26b28653":"print(roc_auc_score(y_test,y_test_pred_bo_xgb))","c4ea6207":"# Lets create a data frame with Original Class values and predicted Class probability values \ny_train_pred_bo_xgb_final = pd.DataFrame({'Class':y_train, 'Class_Prob':y_train_pred_bo_xgb})\ny_test_pred_bo_xgb_final = pd.DataFrame({'Class':y_test, 'Class_Prob':y_test_pred_bo_xgb})\ny_train_pred_bo_xgb_final.head()","2812a4e8":"# Precison - recall curve\np, r, thresholds = precision_recall_curve(y_train_pred_bo_xgb_final.Class, y_train_pred_bo_xgb_final.Class_Prob)\nplt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.grid(b=None, which='major', axis='both')\nplt.show()","a1f86fea":"# Lets see how the predicted values turn out with 42% probability cut off\ny_train_pred_bo_xgb_final['Class_Pred'] = y_train_pred_bo_xgb_final.Class_Prob.map(lambda x: 1 if x > 0.42 else 0)\ny_test_pred_bo_xgb_final['Class_Pred'] = y_test_pred_bo_xgb_final.Class_Prob.map(lambda x: 1 if x > 0.42 else 0)","9128be2d":"# Confusion matrix for training\nconfusion = metrics.confusion_matrix(y_train_pred_bo_xgb_final.Class, y_train_pred_bo_xgb_final.Class_Pred)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","f44fd2e3":"# Confusion matrix for test\nconfusion = metrics.confusion_matrix(y_test_pred_bo_xgb_final.Class, y_test_pred_bo_xgb_final.Class_Pred)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","94f156b3":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","df1d2419":"# Storing all metics in the model metrics data frame\ntrainAccuracy = metrics.accuracy_score(y_train_pred_bo_xgb_final.Class, y_train_pred_bo_xgb_final.Class_Pred)\ntrainPrecision = precision_score(y_train_pred_bo_xgb_final.Class, y_train_pred_bo_xgb_final.Class_Pred)\ntrainRecall = recall_score(y_train_pred_bo_xgb_final.Class, y_train_pred_bo_xgb_final.Class_Pred)\ntestAccuracy = metrics.accuracy_score(y_test_pred_bo_xgb_final.Class, y_test_pred_bo_xgb_final.Class_Pred)\ntestPrecision = precision_score(y_test_pred_bo_xgb_final.Class, y_test_pred_bo_xgb_final.Class_Pred)\ntestRecall = recall_score(y_test_pred_bo_xgb_final.Class, y_test_pred_bo_xgb_final.Class_Pred)\n\n#Adding metrics into the dataframe\ndfAllModelMetrics.loc[dfAllModelMetrics.shape[0]] = ['XGB_Bayesian_Optimization_Tuned', str(xgb_tuned_params), \n                TN, FP, FN, TP,\n                trainAccuracy,trainPrecision,trainRecall,\n                testAccuracy,testPrecision,testRecall]","5026d377":"dfAllModelMetrics.head()","0bcbc923":"import matplotlib.pyplot as plt\nplt.rcParams.update({'figure.max_open_warning':0})\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom imblearn.under_sampling import RandomUnderSampler\nfrom imblearn.over_sampling import RandomOverSampler,SMOTE, ADASYN\nfrom imblearn.combine import SMOTETomek,SMOTEENN\nimport lightgbm as lgb\n\n#import xgboost as xgb\n#from xgboost.sklearn import XGBClassifier\n\n\nfrom sklearn.metrics import roc_auc_score,classification_report\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\n#!pip install bayesian-optimization\nfrom bayes_opt import BayesianOptimization\nimport lightgbm as lgb","df5ac4bf":"y_train_df = pd.DataFrame(y_train)\n# Scaling weight = Ratio of number of 0's to 1's so it can scale the weight of 1's\nscale_pos_weight_factor = y_train[y_train_df.Class==0].shape[0] \/ y_train[y_train_df.Class==1].shape[0]\nprint('scale_pos_weight_factor value:',scale_pos_weight_factor)","649dec5e":"def lightgbm_best_params(X, y,opt_params,init_points=10, optimization_round=5, n_folds=3, random_seed=0, cv_estimators=500): \n    # prepare dataset\n    training_data = lgb.Dataset(X_train, y_train)\n    \n    def lightgbm_run(max_depth,\n                     num_leaves,\n                     #colsample_bytree,\n                     reg_alpha,  #also called lambdal1\n                     reg_lambda, # also called lambdal2\n                     min_child_samples, #Minimum number of data needed in a child (leaf).\n                     learning_rate,\n                     feature_fraction\n                     ): \n        params = {'objective':'binary',\n                  'n_estimators':cv_estimators, #Number of boosted trees to fit.\n                  'early_stopping_round':int(cv_estimators\/20),\n                  'metric':'auc',\n                  'subsample_freq':5, #Frequence of subsample - Need to understand more (<=0 means no enable.)\n                  'bagging_seed':42,\n                  'verbosity':-1,\n                  'num_threads':20,\n                  #Not using class_weight as per documentation; since class_weight is for multi class classification. For binary classification\n                  #can use is_unbalance = True OR scale_pos_weight parameter. Using is_unbalance\n                  'is_unbalance':True \n                  }\n        params['max_depth'] = int(round(max_depth))\n        params['num_leaves'] = int(round(num_leaves))\n        #params['colsample_bytree'] = colsample_bytree\n        params['reg_alpha'] = reg_alpha\n        params['reg_lambda'] = reg_lambda\n        params['min_child_samples'] = int(min_child_samples) \n        # params['min_data_in_leaf'] = int(min_data_in_leaf)\n        params['learning_rate'] = learning_rate\n        params['feature_fraction'] = max(min(feature_fraction, 1), 0)\n        cv_result = lgb.cv(params,\n                           training_data,\n                           nfold=n_folds,\n                           seed=random_seed,\n                           stratified=True,\n                           metrics=['auc'])\n\n        print('cv_result',cv_result)\n        return max(cv_result['auc-mean'])\n    \n    \n    params_finder = BayesianOptimization(lightgbm_run, opt_params, random_state=100)\n    # optimize\n    params_finder.maximize(init_points=init_points, n_iter=optimization_round)\n\n    # return best parameters\n    return params_finder.max","1a8d7552":"bounds = {\n    'max_depth':(3,40),\n    'num_leaves':(25, 4000), #Maximum tree leaves for base learners.\n    #'colsample_bytree':(0.1,0.8),\n    'reg_alpha':(0.1,20),\n    'reg_lambda':(0.1,20),\n    'min_child_samples':(50, 4000),\n    'learning_rate': (0.002, 0.2),\n    'feature_fraction':(0.1,1) #Alias colsample_bytree, sub_feature -> helps reduce overfitting and increase speed, let me use only 10 to 80% of features\n}","fb072b47":"best_params= []\ncv_estimators = [200,400,600,800,1000]\noptimization_round = 10\ninit_points = 10\nrandom_seed = 0\nfolds = 3","7230f09e":"for cv_estimator in cv_estimators:\n    opt_params = lightgbm_best_params(X_train,\n                                 y_train,\n                                 bounds,\n                                 init_points=init_points,\n                                 optimization_round=optimization_round,\n                                 n_folds=folds,\n                                 random_seed=random_seed,\n                                 cv_estimators=cv_estimator)\n    print(opt_params)\n    opt_params['params']['iteration'] = cv_estimator\n    opt_params['params']['fold'] = folds\n    opt_params['params']['auc'] = opt_params['target']\n    best_params.append(opt_params['params'])\n    print('best_params as of now:',best_params)","b839f71c":"max_auc = 0\nmax_auc_index = -1\nfor idx in range(0,len(best_params)):\n  if best_params[idx]['auc'] > max_auc:\n    max_auc = best_params[idx]['auc']\n    max_auc_index = idx\n\ngbm_best_params = best_params[max_auc_index]\n\nprint('***** PARAMETERS WITH TOP AUC SCORE *****')\nfor key in gbm_best_params:\n  print(key,':',gbm_best_params[key])","7eaed8ac":"gbm_tuned_params = gbm_best_params.copy()\ndel gbm_tuned_params['auc']\ngbm_tuned_params['metric'] = 'auc'\ngbm_tuned_params['max_depth'] = int(gbm_tuned_params['max_depth'])\ngbm_tuned_params['num_leaves'] = int(gbm_tuned_params['num_leaves'])\ngbm_tuned_params['min_child_samples'] = int(gbm_tuned_params['min_child_samples'])","0859149a":"training_data = lgb.Dataset(X_train, y_train)\ngbm_tuned_model = lgb.train(gbm_tuned_params,training_data)","223f8c9b":"y_train_pred_bo_gbm = gbm_tuned_model.predict(X_train)\ny_test_pred_bo_gbm = gbm_tuned_model.predict(X_test)","2e3d212c":"print(roc_auc_score(y_train,y_train_pred_bo_gbm))","e62294ba":"print(roc_auc_score(y_test,y_test_pred_bo_gbm))","41e08ccc":"# Lets create a data frame with Original Class values and predicted Class probability values \ny_train_pred_bo_gbm_final = pd.DataFrame({'Class':y_train, 'Class_Prob':y_train_pred_bo_gbm})\ny_test_pred_bo_gbm_final = pd.DataFrame({'Class':y_test, 'Class_Prob':y_test_pred_bo_gbm})\ny_train_pred_bo_gbm_final.head()","39a469b8":"# Precison - recall curve\np, r, thresholds = precision_recall_curve(y_train_pred_bo_gbm_final.Class, y_train_pred_bo_gbm_final.Class_Prob)\nplt.plot(thresholds, p[:-1], \"g-\")\nplt.plot(thresholds, r[:-1], \"r-\")\nplt.grid(b=None, which='major', axis='both')\nplt.show()","44469761":"# Lets see how the predicted values turn out with 2% probability cut off (0.02)\ny_train_pred_bo_gbm_final['Class_Pred'] = y_train_pred_bo_gbm_final.Class_Prob.map(lambda x: 1 if x > 0.02 else 0)\ny_test_pred_bo_gbm_final['Class_Pred'] = y_test_pred_bo_gbm_final.Class_Prob.map(lambda x: 1 if x > 0.02 else 0)","23f5f702":"# Confusion matrix for training\nconfusion = metrics.confusion_matrix(y_train_pred_bo_gbm_final.Class, y_train_pred_bo_gbm_final.Class_Pred)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","e3f54ae0":"# Confusion matrix for test\nconfusion = metrics.confusion_matrix(y_test_pred_bo_gbm_final.Class, y_test_pred_bo_gbm_final.Class_Pred)\nprint(confusion)\n\nplt.figure(figsize=(3,2))\nsns.heatmap(confusion, annot=True, xticklabels = [\"No\", \"Yes\"] , yticklabels = [\"No\", \"Yes\"],fmt='.0f')\nplt.ylabel('True label')\nplt.xlabel('Predicted label')","61c870bc":"TP = confusion[1,1] # true positive \nTN = confusion[0,0] # true negatives\nFP = confusion[0,1] # false positives\nFN = confusion[1,0] # false negatives","cc4d86f2":"# Storing all metics in the model metrics data frame\ntrainAccuracy = metrics.accuracy_score(y_train_pred_bo_gbm_final.Class, y_train_pred_bo_gbm_final.Class_Pred)\ntrainPrecision = precision_score(y_train_pred_bo_gbm_final.Class, y_train_pred_bo_gbm_final.Class_Pred)\ntrainRecall = recall_score(y_train_pred_bo_gbm_final.Class, y_train_pred_bo_gbm_final.Class_Pred)\ntestAccuracy = metrics.accuracy_score(y_test_pred_bo_gbm_final.Class, y_test_pred_bo_gbm_final.Class_Pred)\ntestPrecision = precision_score(y_test_pred_bo_gbm_final.Class, y_test_pred_bo_gbm_final.Class_Pred)\ntestRecall = recall_score(y_test_pred_bo_gbm_final.Class, y_test_pred_bo_gbm_final.Class_Pred)\n\n#Adding metrics into the dataframe\ndfAllModelMetrics.loc[dfAllModelMetrics.shape[0]] = ['LightGBM_Bayesian_Optimization_Tuned', str(gbm_tuned_params), \n                TN, FP, FN, TP,\n                trainAccuracy,trainPrecision,trainRecall,\n                testAccuracy,testPrecision,testRecall]","f28fdb28":"dfAllModelMetrics.head()","ea63976d":"xgb_test_df_ca.head()","036bc744":"X_test_copy.head()","f390e235":"cost_analysis_df = xgb_test_df_ca.copy()","0c56689b":"cost_analysis_df['Amount'] = X_test_copy['Amount'].values","89d84450":"#Final cost analsys dataframe after combining the df having y_test and pred values with the Amount column.\ncost_analysis_df.head()","a8eb8601":"#We can drop the probability column which is not needed.\ncost_analysis_df.drop(['Predicted_probability'],axis=1,inplace=True)","3ac7f9fc":"cost_analysis_df.head()","ae5da14f":"confusion_cost_analysis = confusion_matrix(cost_analysis_df['y_test'],cost_analysis_df['Final_predicted'])","f74c270b":"confusion_cost_analysis","3ca4e81e":"TP = confusion_cost_analysis[1,1] # true positive \nTN = confusion_cost_analysis[0,0] # true negatives\nFP = confusion_cost_analysis[0,1] # false positives\nFN = confusion_cost_analysis[1,0] # false negatives","be2ac573":"Total_fraud_predictions = TP + FP\nTotal_fraud_predictions","a7cfa43a":"def confusion_col(s):\n    if(s['y_test']==1 and s['Final_predicted']==1):\n        return 'TP'\n    elif(s['y_test']==0 and s['Final_predicted']==0):\n        return 'TN'\n    if(s['y_test']==0 and s['Final_predicted']==1):\n        return 'FP'\n    elif(s['y_test']==1 and s['Final_predicted']==0):\n        return 'FN'","26a7a44d":"cost_analysis_df['Confusion_label'] = cost_analysis_df.apply(confusion_col,axis=1)","eef244a9":"cost_analysis_df.head()","d6160ef1":"total_amnt_crct_pred = cost_analysis_df.loc[(cost_analysis_df['Confusion_label']=='TP'),'Amount'].sum()\ntotal_amnt_crct_pred","ee453485":"total_amnt_incrct_pred = cost_analysis_df.loc[(cost_analysis_df['Confusion_label']=='FN'),'Amount'].sum()\ntotal_amnt_incrct_pred","03b1b308":"Total_savings = round(total_amnt_crct_pred - ((Total_fraud_predictions * 10 ) + total_amnt_incrct_pred),3)","4c6f82f7":"print(Total_savings)","503136be":"_______________________________________________________________________","4e2ef29b":"We can see 27 transactions which is fraudulent but amount is 0. <font color='red'>Need to see what exactly this means and reason why someone would a $0 transaction<\/font>","14e5a0a6":"#### Tuning min_samples_leaf","ee3db65c":"We will go forward with 150 samples per leaf.","74788f71":"### If we have to reduce the False negatives, we might have to decrease the probability cut off to much lesser than 0.41; however this may cause some legitimate transactions to be treated as fraud","67ce79f4":"### - Logistic Regression on Imbalanced Dataset","2494a42f":"We can see that the class imbalance problem has been addressed now with same percentage of total records present now for both the classes.","0f9b8ec9":"Random Forest model seems to be a pretty good model on our sampled train set. Lets evaluate now on test set.","9adb1555":"#### MIN_SAMPLES_SPLIT","f6c2cd95":"#### If we choose all values with more than 39% as cutoff for class prediction then the accuracy and Recall scores are good but Precision score is very poor.\n#### Precision on test data has dropped drastically. Lets check why.","2cb75617":"We can see the p-values are in comparable range(<0.05) now and hence all values are significant. Also all the VIF values are in range less than 5 indicating no multi collinearity present within. Hence model4 is our final logisitc Regression model with which we can check for the metrics now.","a0b0b76d":"#### N ESTIMATORS","85aa3886":"There are only 8 records with transaction amount greater than or equal to 10,000 Euros. We will go ahead and remove these records.","8f223df6":"Hence the final savings made with our model is around 8580.03 Euros provided the call charges is in Euros.","60a14cdb":"#### Using class_weight based on Fraud and legitimate transaction counts","d0320620":"#### Card Fraud - An Inside Edge\nThe global general purpose brands-American Express, Diners Club\/Discover, JCB, Mastercard, Visa, and UnionPay-combined for `$33.731` trillion or 83.12 percentage of total worldwide card volume (purchases and cash) in 2018.\nGross fraud for the global brand cards amounted to `$24.86` billion in 2018, an increase of 16.9% over `$21.27` billion the previous year.\nThe global brand cards combined to account for 89.26 percentage of gross fraud losses worldwide for all cards in 2018, up from 88.75 percentage the prior year.\nIn three years (2023), total payment card volume worldwide is projected to reach `$57.080` trillion and gross card fraud is projected to reach `$35.67` billion.<br>\nIssuer losses occurred when criminals took over valid accounts, cards were lost or stolen or counterfeited, new accounts were opened with the intent to commit fraud, accounts were opened using a mix of valid and bogus information (synthetic fraud), cardholders or their family members made purchases and then disputed the charges (friendly fraud), and a few smaller categories.\n\nAccount takeover and synthetic fraud losses grew in 2018, helped by the abundance of personally identifiable information (PII) available for sale on the dark web. Both are madle easier for criminals by new credit account applications that originate from mobile devices. Data breaches can provide 100 percentage of the information needed for an account takeover. The theft of healthcare records, which are rich in PII, are a particular problem. Criminals purchase PII, gain access to a valid account, change key details, and have a new card mailed to a different address. Account takeovers can result in a quick loss to fraud.\n![card_fraud_1.PNG](attachment:card_fraud_1.PNG)","82f600ed":"# <font color='red'>Logistic Regression with SMOTE<\/font>","14c7dac2":"Maxmimum depth around 7 would be a good choice for our trees in the randdom forest model.","169304e2":"We can create a function `confusion_col` to create a column marking the status of prediction for each record in test.","18a4da8b":"We dropped the `Time` feature from our dataframe, as said above since there are no value adds this feature presents here. Moreover we couldnt find any time dependent pattern present for the fraudulent transactions.","d35f2126":"We can see that all the features in the dataframe are numeric variables. Hence there is no need for conversion from categorical to numeric here in this case. <br>\nAlso, we can see that, out of the 31 features, 28 features(V1-V28) are the PCA transformed variables as mentioned in the problem statement, hence we dont know which are the base features here. <br>\nThere are no NULL values present in any of the features,hence no need of any NULL value handling required here. <br>\n<b> Since all are numeric values we can go ahead and check for the initial stats of the features.","d45a6d4a":"V9 and V11 look better","a4296f39":"From the above barplot we can see that, there is clear class imbalance present in the dataset where most of the records are non-fraudulent transactions. <br>\n`dist_df` dataframe shows the percentage details for the same. There are only 0.172% of fraudulent records present in the dataset.","00c4dcdb":"#### <u>MIN_SAMPLES_SPLIT","965f48ec":"### <font color = 'purple'> <b> `XGBOOST ON IMBALANCED DATASET-TEST` <\/b> <br>\n`Precision`            -> 76% <br>\n`Recall`\/`Sensitivity` -> 86% <br>\n`Specificity`          -> 99.9% ","420efbb1":"100 estimators seems to be a good parameter so that the recall is in similar range on train and test. Further with the increase in the n-estimators we can clearly see some overfitting on the train set.","a7240cf1":"<font color = 'purple'> <b> `RANDOM FOREST ON BALANCED DATASET WITH XGB -TRAIN` <\/b> <br>\n`Specificity`          -> 97% <br>\n`Precision`            -> 99%\n    ","7f87a4ed":"<font color = 'purple'> <b> `RANDOM FOREST ON BALANCED DATASET WITH ADASYN -TRAIN` <\/b> <br>\n`Recall`\/`Sensitivity` -> 93% <br>\n`Specificity`          -> 97% <br>\n`Precision`            -> 97%\n    ","ea89736f":"We can see that with more no of estimators the recall value is touching 1 indicating clear overfitting. Hence to avoid this, we will select n_estimators to be around 100 only.","229d9e64":"We know that there are many hyper parameters for the Random Forest Classifier. We can start by tuning each hyper parameter seprately and find out the best set of values for each parameter so that we can go ahead and build the final Random forest classifier with these parameters.","6cce5c02":"We can see that with the Logistic Regression model on our imbalanced dataset performed better in terms of the Recall with a 10% increase in the value but on compromise on the precision value which was higher with our Random Forest Model. Specificity as a metric we are not concerned here since we are looking for predicting the fraudulent cases as priority.","a8adae9f":"### COST BENEFIT ANALYSIS","2baae25b":"<font color = 'purple'> <b> `LOGISTIC REGRESSION ON IMBALANCED DATASET-TRAIN` <\/b> <br>\n`Precision`            -> 79% <br>\n`Recall`\/`Sensitivity` -> 80% <br>\n`Specificity`          -> 99.9% ","3bc569c7":"We can see that 47.99 hours hence the transactions are of 2 days.","006c7dae":"<font color = 'purple'> <b> `LOGISTIC REGRESSION ON IMBALANCED DATASET-TEST` <\/b> <br>\n`Precision`            -> 77% <br>\n`Recall`\/`Sensitivity` -> 79% <br>\n`Specificity`          -> 99.9% ","3021fdf9":"### - XGBoost on ADASYN dataset","7e8d8105":"### Credit Card Fraud Detection\n","7191823f":"#####  Hyper parameter tuning for Random Forest","48427b71":"We can see that currently we are having 398054 records with us after performing the SMOTE. Since the output of SMOTE is an nd array we can convert it back to dataframes. Further we can check what is the distribution of classes right now.","a5402fd1":"#### We can see that all the metrics are in accpetable range, so lets proceed to predict class on test data","720a0f24":"# <font color='red'>Random Forest with oversampling using class weight<\/font>","d83aea1e":"### Precision formula is TP\/(TP+FP) - Since there is class imbalance in test dataset, though 'No' in Test set has been predicted correctly 92% of the time, the count of 8% incorrectly predicted as 'Yes' (6876) far outnumber the number of True positives (143). This is the reason precision is low.","115cb3ac":"### <font color = 'purple'> <b> `RANDOM FOREST with HYPERPARAMETER TUNING ON IMBALANCED DATASET-TEST` <\/b> <br>\n`Precision`            -> 83% <br>\n`Recall`\/`Sensitivity` -> 69% <br>\n`Specificity`          -> 99.9% ","cad78f63":"#### Accuracy, Precision, recall all are above 80% , so lets go ahead and find other metrics","bbe317b8":"0.5 seems to be a good cut-off probability after checking for the precision-recall tradeoff and the sensitivity-specificity values.","c962864f":"We can see that all the metrics - recall\/sensitivity, specificity and precision with the XGBOOST model on ADASYN balanced dataset is almost similar to our random forest model. While offering great metrics on the recall, there is serious trade off with the precision with which the class 1 data points are predicted.","78922087":"### <font color = 'purple'> <b> `RANDOM FOREST with HYPERPARAMETER TUNING ON IMBALANCED DATASET-TRAIN` <\/b> <br>\n`Precision`            -> 87% <br>\n`Recall`\/`Sensitivity` -> 69% <br>\n`Specificity`          -> 99.9% ","7edc9bf0":"Both train and test scores are in similar range throught out the range of values for max_depth. Hence we will select max_depth around 6,so that it wont overfit much on the train set.","e763db3c":"#### MIN_SAMPLES_LEAF","2784ce6d":"_______________________________________________________________________","35d409a7":"Hence we have completed with the data preparation and cleaning for our data and the train dataset is ready with `X_train`.","8f096306":"__________________________________","e6d176cf":"## <u> Models with Imbalanced Dataset","5ba6510f":"We can see that the class imbalance problem has been addressed now with same percentage of total records present now for both the classes.","7fc2f8fe":"Class 0 which is the non fraudulent transactions have happened for the amounts ranging from 0 to as high as 25000 Euros(Considering the dataset is of transactions of European Card Holders). When we can clearly state transactions more than say, 15000 as outliers, most of the non-fraudulent transactions are in range of 0 to 10000. <br>\n<b> At the same time, fraudulent transactions have happened only for smaller amounts - 0 to 5000 Euros. This might be because of the fact that there is increased chance of higher value transactions to be constantly reviewed.","56497b52":"Total amount of correct predictions made: TP x Cost of each transaction which is correctly predicted. <br> In other terms total amount of correct predictions would be summed amount where y_test and predicted value both are 1.","64654713":"Max depth around 6 would be a good measure where the train and test recall metrics are close enough.","f8aceabc":"### <font color = 'purple'> <b> `XGBOOST ON BALANCED DATASET WITH ADASYN -TEST` <\/b> <br>\n`Recall`\/`Sensitivity` -> 93% <br>\n`Specificity`          -> 97% <br>\n`Precision`            -> 6% <br> ","78441c78":"#### F1 score is also looking good","21495428":"##### Hyper parameter tuning for Random Forest","17a2ce98":"#### Dataset Details\n<hr>The dataset contains transactions made by credit cards in September 2013 by European cardholders.\nThis dataset presents transactions that occurred in two days, where we have 492 frauds out of 284,807 transactions. The dataset is highly unbalanced, the positive class (frauds) account for 0.172% of all transactions.\n\nIt contains only numerical input variables which are the result of a PCA transformation.Due to confidentiality issues,the original features and more background information about the data are not provided. Features V1, V2, \u2026 V28 are the principal components obtained with PCA, the only features which have not been transformed with PCA are 'Time' and 'Amount'. Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. The feature 'Amount' is the transaction Amount, this feature can be used for example-dependant cost-senstive learning. <br> <b> \nFeature 'Class' is the response variable and it takes value 1 in case of fraud and 0 otherwise.\n    <hr>","053e9a37":"Max features around 13 seems to be a good value for Recall in both train and test and hence we can go ahead with that.","46e25928":"#### Lets check accuracy and other metrics on this preidcted churn values","38e835a2":"#### Understanding and Defining Fraud\nCredit card fraud is any dishonest act and behaviour to obtain information without the proper authorization from the account holder for financial gain. Among different ways of frauds, Skimming is the most common one, which is the way of duplicating of information located on the magnetic strip of the card.  Apart from this, the other ways are:\n\n- Manipulation\/alteration of genuine cards <br>\n- Creation of counterfeit cards<br>\n- Stolen\/lost credit cards<br>\n- Fraudulent telemarketing\n\n<hr>","f6729103":"We can see a high recall rate in all the cases. Hence we can go with lower values learning rate of 0.2 and subsample of 0.3.","ca0fadce":"### <font color = 'purple'> <b> `RANDOM FOREST ON BALANCED DATASET WITH ADASYN -TEST` <\/b> <br>\n`Recall`\/`Sensitivity` -> 93% <br>\n`Specificity`          -> 97% <br>\n`Precision`            -> 5% <br> \n<font color = 'black'> We can see that we are getting a similar recall specificity values with the randome forest model on test set similar to the train set. But there is a serious trade off between precision and recall, hence compromising on the precision to a greater extend.   ","6e3c9c58":"##### <u>MAX DEPTH","62853fdd":"______________________________________","b0bbf0ee":"#### MAX_FEATURES","7cc3e73c":"https:\/\/www.researchgate.net\/post\/What_is_the_acceptable_range_of_skewness_and_kurtosis_for_normal_distribution_of_data\n\nIt depends on mainly the sample size. Most software packages that compute the skewness and kurtosis, also compute their standard error.\nBoth\nS = skewness\/SE(skewness)\nand\nK = kurtosis\/SE(kurtosis)\nare, under the null hypothesis of normality, roughly standard normal distributed.\nThus, when |S| > 1.96 the skewness is significantly (alpha=5%) different from zero; the same for |K| > 1.96 and the kurtosis.\nTo manually compute the standard errors, see the formulae for the variance of skewness and kurtosis (https:\/\/en.wikipedia.org\/wiki\/Skewness, https:\/\/en.wikipedia.org\/wiki\/Kurtosis ) and take the square root.","fff37ead":"### Splitting the data into train & test data","193dbf0a":"Out of all the models listed above, with the metric Recall in consideration, we could find a couple of good models from the list. Among these some of the models especially the one built on ADASYN and SMOTE are having a recall value, but with a serious trade-off on the precision value. Since we are selecting a good model which predicts fraudulent transactions as much as possible but also with a good precision, we can shortlist a couple of models (which are as highlighted bold). <br>\nOut of these three models, we can further narrow down and select the XGBoost model ran on unbalanced dataset which offers the below given metric - <br>\n - Recall - 86%\n - Precision - 76%\n - Specificity - 99.9%","fd3746dd":"The maximum value now is 8790, but still we could see a need to standardise the Amount column, since this is in not in same range of the columns V1-V28.\n\nWe can also observe that there are some transactions with an amount of 0.","0ea1b959":"### - Random Forest on ADASYN Dataset","2f175c72":"<hr>\nFor many banks, retaining high profitable customers is the number one business goal. Banking fraud, however, poses a significant threat to this goal for different banks. In terms of substantial financial losses, trust and credibility, this is a concerning issue to both banks and customers alike.\n<br>\n<b>It has been estimated by Nilson report that by 2020 the banking frauds would account to $30 billion worldwide. With the rise in digital payment channels, the number of fraudulent transactions is also increasing with new and different ways.<\/b> <br>\nIn the banking industry, credit card fraud detection using machine learning is not just a trend but a necessity for them to put proactive monitoring and fraud prevention mechanisms in place. Machine learning is helping these institutions to reduce time-consuming manual reviews, costly chargebacks and fees, and denials of legitimate transactions.\n<hr>","cac7c86f":"We can see that XGBoost seems to perform well subjected to the Recall metric with 86% on test as compared to the KNN,Logistic Regression and even Random Forest model but there is a clear trade off between the precision and recall values here. To avoid possible overfitting on the data we selected the cut off probability of 0.1 on the test dataset as well which we selected based on the metrics on train sets. The precision we got is around 76% which is to the lower side in comparison with the Random Forest and KNN models.","36b8e186":"Here we will observe the distribution of our classes","1901c7ba":"#### Tuning min_samples_split","3a75609c":"# <font color='red'>XGBOOST on SMOTE Dataset<\/font>","a2c3f88f":"##### Hyper parameter tuning for Random Forest","67f23fa7":"#### MAX DEPTH","137679f4":"From the above scatter plot between the Class and Time indicates a the fraudulent transactions have happened throughout the given time frame there are no fixed time patterns followed by these fraudulent transactions indicating that the `Time` feature is not an important feature in our dataframe hence can be removed.","9347bf01":"We can combine all the hyper parameter values which we got in the previous steps and build our random forest model with that and observe the metrics which the model is offering on train and test.","7b81e25d":"<font color = 'purple'> <b> `RANDOM FOREST ON BALANCED DATASET WITH ADASYN -TEST` <\/b> <br>\n`Recall`\/`Sensitivity` -> 89% <br>\n`Specificity`          -> 99% <br>\n`Precision`            -> 17% <br> \n<font color = 'black'> We can see that we are getting a similar recall specificity values with the randome forest model on test set similar to the train set. But there is a serious trade off between precision and recall, hence compromising on the precision to a greater extend.   ","11adf821":"Learning rate around 0.1 and subsample around 0.3 seems to be a good value.","5bb5152d":"Except V4 other 3 components V1 to V3 have high skewness and kurtosis. So we need to perform steps to mitigate skewness","3b7e09b2":"### Sampling the TRAIN data with SMOTE","51638516":"Now we can go ahead and check for the amount feature. With the Amount vs Class scatter plot we could observe there are pretty some outliers present for the `Amount` feature. Hence we can observe for this with a Boxplot and remove those by making sure we are not removing any important records.","05bf7a2e":"Till now we worked on the imbalanced dataset and build models on top of that. After the split, we know we had only 332 of class 1 samples in our train dataset and just 160 samples in our test dataset. We could get a better recall with ensemble models such as XGBoost and Random Forest on the imbalanced dataset while the linear model such as Logistic Regression was little bit underperforming. Hence now we can go ahead with balancing the dataset with approaches such as SMOTE and build models on top of that.","f7b88b5e":"#### The VIF values are all in accpetable cutoff range, so we can proceed to predict the churn on both train and test data and find accuracy and other measures to see how th modle is performing","167d25ab":"<b>`xgb_test_df_ca`<\/b> is the final dataframe we have, containing the y_test values,predicted probability and the predicted y values selected using cut-off probability for the <b>`XGBoost model on Imbalanced dataset`<\/b>. <br>\nAlso, we are having a copy of both X_test and y_test.","ea609e0b":"#### <u>MAX_FEATURES","f40f70bd":"Till now we worked on the imbalanced dataset and build models on top of that. After the split, we know we had only 332 of class 1 samples in our train dataset and just 160 samples in our test dataset. We could get a better recall with ensemble models such as XGBoost and Random Forest on the imbalanced dataset while the linear model such as Logistic Regression was little bit underperforming. Hence now we can go ahead with balancing the dataset with approaches such as ADASYN and build models on top of that.","f2596c47":"Here in our model1 we can see there are many features with p-value more than 0.05. We can remove these one by one and observe what changes are happening in the model. <br> To start with we can remove, `Amount` feature and see.","fa2b57ad":"#### MIN_SAMPLES_SPLIT","fe90f82a":"### Shuffling and sampling the train set to produce a new train set from the ADASYN datapoints.","810bf5ac":"All values seems to be within the range of VIF 5 hence no multi-collinear features. Hence model12 is our final logistic regression model with which we can predict now on train and test sets.","bd7c68aa":"We can see that XGBoost seems to perform well subjected to the Recall metric with 91% on test as compared to Logistic Regression and even Random Forest model but there is a clear trade off between the precision and recall values here. To avoid possible overfitting on the data we selected the cut off probability of 0.1 on the test dataset as well which we selected based on the metrics on train sets. The precision we got is around 8.5% which is to the lower side in comparison with the Random Forest and KNN models.","fe612cb7":"### - Logistic Regression on ADASYN Dataset","2ba45eda":"#### Tuning max_depth","53d3c10c":"### <font color = 'purple'> <b> `KNN ON IMBALANCED DATASET-TRAIN WITH DEFAULT n_neighbors = 5` <\/b> <br>\n`Precision`            -> 93% <br>\n`Recall`\/`Sensitivity` -> 79% <br>\n`Specificity`          -> 99.9% ","d4d37098":"#### N ESTIMATORS","f34b360a":"V18 and V19 do not have high skewness","4a5b4258":"We can observe the distributions for these features now after successfully applying the Yeo-Johnson Transformations.","743afff4":"#### We can see in the above plot that ROC curve is inclined towards top left corner, which means we have a balanced TPR and FPR. The AUC is 0.97 which is good","eb13366f":"<font color = 'purple'> <b> `XGBOOST ON SMOTE OVERSAMPLED DATASET-TEST` <\/b> <br>\n`Precision`            -> 8.5% <br>\n`Recall`\/`Sensitivity` -> 91% <br>\n`Specificity`          -> 98.1% ","5dee049f":"In the heatmap, we are not interested in the correlation between features of V1-V28 since we already know these are PCA transformed variables and hence wont be correlated. Some features like V7 and V20 are somewhat averagely correlated with the Amount feature. There are no columns to be found very correlated with our target variable Class.","fa7be03e":"### - Decision Tree on Imbalanced Dataset","1169e81b":"#### Using all the hyperparameter values","6c7c81b4":"Max depth around 4 would be a good measure where the train and test recall metrics are close enough.","42f29866":"n_estimators around 500 would be a good choice where the recall values between train and test are much closer.","2729b971":"X_train_Summary shows all the variables in our dataframe along with their min,max values and skewness and kurtosis values. We cann see some of the variables are highly skewed which needs to be mitigated. <br>\nHence we can go ahead with the Power Transfomer function which can be used to normlise the data and mitigate skewness.\nWe can either go wuth Box-Cox approach or Yeo Johnson for this. <br>\nBut Box-Cox requires input data to be strictly positive, while Yeo-Johnson supports both positive or negative data, hence we can go ahead with this. <br>\nThe Amount feature alone we can apply StandardScaling as discussed above.","d82c6aa1":"### Print the class distribution after applying SMOTE ","3c3149ba":"Hence, out of the 492 class 1 records, we are having 332 in our train set while 160 in the test set.","048306d4":"We can see from the above plots for sensitivity-specificity and precision-recall that cut-off probability can be taken as 0.1.","252acf1e":"Both train and test scores are in similar range throught out the range of values for max_depth. Hence we will select max_depth around 8,so that it wont overfit much on the train set.","ba8e5838":"##### Predictions on TEST ","2f669c35":"Random Forest model seems to be a pretty good model on our sampled train set. Lets evaluate now on test set.","7433a62a":"The best estimators for the decision tree we got are criterion='gini',max_depth=5,min_samples_leaf=50, min_samples_split=50","8f358217":"We can combine all the hyper parameter values which we got in the previous steps and build our random forest model with that and observe the metrics which the model is offering on train and test.","42cd6bd5":"We will go forward with 250 samples per leaf.","e3cae109":"We will select max_features of 5.","c140f075":"Models in hand and corresponding metrics on TEST set. <br>\n\n|  | Model Details | Recall\/Sensitivity | Precision | Specificity |\n| --- | --- | --- | --- | --- |\n| Imbalanced | Decision Tree | 63% | 86% | 99.9% |\n| Imbalanced | Random Forest | 69% | 83% | 99.9% |\n| Imbalanced | Logistic Regression | 79% | 77% | 99.9% |\n| Imbalanced | KNN with n-neighbors=5 | 79% | 93% | 99.9% |\n|<b> Imbalanced |<b> XGBoost |<b> 86% |<b> 76% |<b> 99.9% |\n| Balanced with ADASYN | Logistic Regression | 93% | 2% | 86% |\n| Balanced with ADASYN | Random Forest | 93% | 5% | 97% |\n| Balanced with ADASYN | XGBoost | 93% | 6% | 97% |\n| Random OverSampling | Random Forest | 89% | 16% | 99% |\n| Balanced with SMOTE | Logistic Regression | 89% | 2% | 91% |\n| Balanced with SMOTE | Random Forest | 89% | 18% | 99% |\n| Balanced with SMOTE | XGBoost | 91% | 9% | 98% |\n|<b> Bayesian Optimisation |<b> XGBoost |<b> 79% |<b> 78% |<b> 99% |\n|<b> Bayesian Optimisation |<b> Light GBM |<b> 81% |<b> 78% |<b> 99% |","2cfe7f6e":"We can see that currently we are having 398092 records with us after performing the ADASYN. Since the output of ADASYN is an nd array we can convert it back to dataframes. Further we can check what is the distribution of classes right now.","b2fea2c9":"### <font color='brown'>Lets create a data frame to store model name, model metrics, we can keep appending this after every new model built and check this in the end to see which model is giving better results","691a7bad":"#### MAX_FEATURES","310b10e3":"We can combine all the hyper parameter values which we got in the previous steps and build our random forest model with that and observe the metrics which the model is offering on train and test.","6a2ea954":"## Data Understanding","9176d8bc":"We will go ahead with max_depth of 4.","594d75b0":"We will select max_features of 14","c5e56d0a":"#### Precision and recall meet at 0.39","bfb9198f":"## Exploratory Data Analysis","85fe9f51":"### - KNN on Imbalanced Dataset","56e92179":"Learning rate around 0.2 and subsample around 0.3 seems to be a good value.","922a3a67":"Similarly total amount of incorrect predictions made: FN x Cost of each transaction which is incorrectly predicted,are those which are actually of class 1 i.e. y_test=1 but our model incorrectly predicted as non-fraudulent i.e. predicted value 0.\n","f978c20e":"### We see a decent precision and recall score. Lets add this metrics to the dataframe","9f2d84da":"#### MAX DEPTH","85cefe03":"### Shuffling and sampling the train set to produce a new train set from the SMOTE datapoints.","b232323c":"We could see the recall is almost in similar range through out the range of n_estimator values. Hence n_estimator to be taken around 200.","4dc07719":"### - XGBOOST on Imbalanced Dataset","0a9bc9b6":"We can see that, <b><u> the decision tree on unbalanced dataset even without hyperparameter tuning<\/u><\/b> gave us a score of 99.99% (but possibly overfitting). Also since the data is inbalanced and we are interested on the Class 1, we have checked for the precision-recall and sensitivity-specificity values for the same and below are the details -> <br>\n`Precision`            -> 96% <br>\n`Recall`\/`Sensitivity` -> 80% <br>\n`Specificity`          -> 99.9% ","3b950bb4":"#### MIN_SAMPLES_LEAF","d40e8533":"We know that the features in hand are PCA transformed features and we are not aware of what are the native features for the same. Hence while removing the insignificant features in our Logistic Regression model, we need to take a call based on only the p-value and the VIF. We can go ahead with this and check and built model each time.","618fc5a5":"# <font color='red'>Random Forest Default model with SMOTE (No Tuning)<\/font>","2b612337":"### - Random Forest on Imbalanced Dataset","672a202d":"#### Tuning max_features","aafe6948":"#### Tuning n_estimators","914273a8":"We can see that, the values of precision and recall have slightly improved with Random Forest compared with the Decision tree. \nAlso the metrics on train and test seems to be close enough indicating there is no overfitting present. <br>But still the recall value is less. Hence we can go ahead with other models and check what they are offering.","1c3edd8e":"V13 and V15 do not have any skewness","ed6f24ed":"We can see the p-values are in comparable range(<0.05) now and hence all values are significant. We can go ahead and check for VIF factor now and see whether multi-collinearity is present between these features. We will preserve the V7 factor here which is having slightly higher p-value but not that high enough than the significant boundary condition value.","b6c18a58":"300 estimators seems to be a good parameter so that the recall is in similar range on train and test. Further with the increase in the n-estimators we can clearly see some overfitting on the train set.","f02033bc":"# <font color='purple'>Bayesian Optimization with lightGBM<\/font>","a2e67c89":"We could see the recall is almost in similar range through out the range of n_estimator values from 200 to 600 and there is only a slight increase after. Hence n_estimator to be taken around 200.","c9e1a338":"# <font color='purple'>Bayesian Optimization - XGB<\/font>","be59c340":"#### Lets create confusion matrix and check","7b82b755":"With decision tree we can find that, by hyperparameter tuning we effectively tried controlling the overfitting issue but in the cost of reduced sensitivity\/recall. <br>\nWith the default parameters and max_depth as 5 we got convincingly good precision of 96% and sensitivity of 80%. But with hyper parameter tuning even though we controlled the overfitting and got a good accuracy, we were not able to predict the fraudulent transactions with a better accuracy. We got a sinsitivity of just 63% only, while precision is around 86%. <br> We can go ahead and try with other models. <br>\n\n### <font color = 'purple'> <b> `DECISION_TREE with TUNING ON IMBALANCED DATASET` <\/b> <br>\n`Precision`            -> 86% <br>\n`Recall`\/`Sensitivity` -> 63% <br>\n`Specificity`          -> 99.9% ","e468e73c":"# <font color='purple'>SMOTE - Using this technique for handling imbalance and then evaluating different models<\/font>","768d1217":"From the Boxplot we could see there are some outliers present. Initially from Scatter, we thought maybe 15,000 might be a good cap, but from here, we think 10,000 might be good cap. To concrete this, let us check how many transactions have happened in these two days for amount value greater than or equal to 10,000. <br>\n<b> NOTE: Even if we remove these records, we won't be ending up removing any of the 0.172% of the fraudulent transactions, since we clearly saw from the scatterplot that, all the fraudulent transactions were for the value less than 5000 approx.","7bf09cd3":"From the above, we can see that the features V1-V28 are the PCA transformed variables and hence are in present in the similar scale. <br>\nFor the time feature, we can see minimum value is 0 and max is 172792. From the problem statement we know that <b> Feature 'Time' contains the seconds elapsed between each transaction and the first transaction in the dataset. <\/b>. So we can cross verify whether the dataset is containing only the transactions of 2 days as mentioned in the problem statement or more. We can check for this in the next cell. <br>\nConcering the `Amount` feature, we can see the minimum value is 0 and 75th percentage is 77.16 but the maximum is 25691, hence indicating clear presence of Outliers which we need to deal with. <br>\nThe target variable with us is `Class`.","59f80fdb":"#### <u>Min_Samples_Leaf","bd94a801":"We can see that there are around 2,84807 records in the dataframe where each record indicating a credit card transaction and 31 features in hand.","a19881ad":"### Sampling the TRAIN data with ADASYN","bf1ba7db":"#####  Hyper parameter tuning for Decision Tree","dea9c445":"### <font color = 'purple'> <b> `LOGISTIC REGRESSION ON BALANCED DATASET WITH ADASYN -TEST` <\/b> <br>\n`Recall`\/`Sensitivity` -> 93% <br>\n`Specificity`          -> 86% ","23279c65":"#### <U>N_ESTIMATORS","d304e753":"### <font color='red'>Reusable plotting functions:<\/font> Defining some help functions useful for plotting later","e1e64351":"As we have seen, to handle the class imbalance we went with ADASYN which added on sample points for minority and hence we built a logistic Regression model on top of that. Even though the model gave very good performance in the train set and some of the metrics in test set as well, we wont be going ahead with this model since this model had so many misclassifications. The model offered good Recall metric of 93% but on the cost of compromising on the precision very much. Infact most of the records where falsely classified as fraudulent cases hence compromising on the Precision.","ef16eafc":"# <font color='red'>Random Forest on SMOTE Dataset<\/font>","89baed20":"### The P-values are all zero, so we can proceed to check VIF"}}