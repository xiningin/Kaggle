{"cell_type":{"f3bd1b80":"code","eadd10e8":"code","92d33916":"code","3b3afdfb":"code","f1eb1805":"code","2ee7b592":"code","d27c9685":"code","99111e53":"code","7476d51b":"code","1f27b525":"code","dc8cd40e":"code","7082a939":"code","a3518084":"code","0d73643c":"code","ce1f1da8":"code","21217999":"code","72438723":"code","a2f07c73":"code","97a4e93b":"code","871f5966":"code","b6931c4b":"code","9b0bc091":"markdown","3540ee29":"markdown","5170d64f":"markdown","541a5cbe":"markdown","9b0042bf":"markdown","d3291a33":"markdown","e93f6104":"markdown","c3f49bfc":"markdown","dd59ef5a":"markdown","8522880e":"markdown","8da0f41f":"markdown"},"source":{"f3bd1b80":"!pip install -q tensorflow==2.7.0","eadd10e8":"import pandas as pd\nimport numpy as np\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom tensorflow.keras import layers\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.metrics import confusion_matrix, classification_report, accuracy_score\nfrom sklearn.model_selection import StratifiedKFold","92d33916":"train = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/train.csv\")\ntrain.head()","3b3afdfb":"train.shape","f1eb1805":"test = pd.read_csv(\"\/kaggle\/input\/nlp-getting-started\/test.csv\")\ntest.head()","2ee7b592":"train.location.value_counts()","d27c9685":"train.isnull().sum()","99111e53":"test.isnull().sum()","7476d51b":"train[\"keyword\"].replace(np.NAN, \"\", inplace=True)\ntrain[\"location\"].replace(np.NAN, \"\", inplace=True)\ntest[\"keyword\"].replace(np.NAN, \"\", inplace=True)\ntest[\"location\"].replace(np.NAN, \"\", inplace=True)","1f27b525":"train.isnull().sum()","dc8cd40e":"test.isnull().sum()","7082a939":"len(test[\"keyword\"])","a3518084":"contents = []\nfor data in [train, test]:\n    for i in range(data.shape[0]):\n        item = data.iloc[i]\n        sentence = item[\"keyword\"] + \" \" + item[\"text\"] + \" \" + item[\"location\"]\n        contents.append(sentence.lower())","0d73643c":"train_contents = contents[:len(train)]\ntest_contents = contents[len(train):]","ce1f1da8":"train[\"X\"] = train_contents\ntest[\"X\"] = test_contents","21217999":"vocab_size = 10000\ntext_vectorizer = layers.TextVectorization(max_tokens=vocab_size, output_mode=\"tf-idf\", ngrams=2)\n# Index the bigrams and learn the TF-IDF weights via `adapt()`\n\nwith tf.device(\"CPU\"):\n    # A bug that prevents this from running on GPU for now.\n    text_vectorizer.adapt(contents)","72438723":"class BinaryCrossEntropy(tf.keras.losses.Loss):\n\n    def __init__(self, postive_rate = 0.5):\n        super().__init__()\n        self.negative_weights = postive_rate\n        self.positive_weights = 1 - postive_rate\n        \n    def call(self, y_true, y_pred):\n        print(y_true, y_pred)\n        y_true = tf.cast(y_true, y_pred.dtype)\n        pos = self.positive_weights * y_true * tf.math.log(y_pred + tf.keras.backend.epsilon())\n        neg = self.negative_weights * (1.0 - y_true) * tf.math.log(1.0 - y_pred + tf.keras.backend.epsilon())\n        return -(pos + neg)","a2f07c73":"def get_model():\n    inputs = layers.Input(shape=(None, ), dtype=\"string\")\n    x = text_vectorizer(inputs)\n    x = layers.Dense(32, activation=\"relu\")(x)\n    x = layers.Dropout(0.5)(x)\n    outputs = layers.Dense(1, activation=\"sigmoid\")(x)\n    return keras.Model(inputs=inputs, outputs=outputs)","97a4e93b":"model = get_model()\nkeras.utils.plot_model(model, show_shapes=True)","871f5966":"index = 1\nmodels = []\ntf.keras.backend.clear_session()\nfor train_indices, val_indices in StratifiedKFold(5, shuffle=True, random_state=42).split(train, train[\"target\"]):\n    print(\"Fold %d\" %(index))\n    train_features, train_targets = train.iloc[train_indices][\"X\"], train.iloc[train_indices][\"target\"]\n    validation_features, validation_targets = train.iloc[val_indices][\"X\"], train.iloc[val_indices][\"target\"]\n    model_checkpoint_path = \"model%d.tf\"%(index)\n    model = get_model()\n    loss = BinaryCrossEntropy(train_targets.mean())\n    adam = tf.keras.optimizers.Adam(3e-4)\n    model.compile(loss=loss, optimizer=adam, metrics=[\"accuracy\"])\n    early_stop = tf.keras.callbacks.EarlyStopping(patience=10)\n    recuce_Lr = tf.keras.callbacks.ReduceLROnPlateau(patience=2)\n    model_checkpoint = tf.keras.callbacks.ModelCheckpoint(model_checkpoint_path, monitor=\"val_accuracy\", save_best_only=True, save_weights_only=True)\n    history = model.fit(train_features, train_targets, validation_data=(validation_features, validation_targets), epochs=100, callbacks=[early_stop, model_checkpoint])\n    pd.DataFrame(history.history).plot(kind=\"line\")\n    plt.title(\"Performance of Fold %d\"%(index))\n    plt.show()\n    model.load_weights(model_checkpoint_path)\n    y_val_pred = np.array(model.predict(validation_features) > 0.5, dtype=\"int\").reshape(-1)\n    cm = confusion_matrix(validation_targets, y_val_pred)\n    sns.heatmap(cm, annot=True)\n    plt.show()\n    print(\"Classification Report: \\n\")\n    print(classification_report(validation_targets, y_val_pred))\n    acc_score = accuracy_score(validation_targets, y_val_pred)\n    print(\"Accuracy Score: %.2f\"%(acc_score))\n    models.append(model)\n    index += 1","b6931c4b":"y_test = np.mean([model.predict(test[\"X\"]).reshape(-1) for model in models], axis=0)\ny_test = np.array(y_test > 0.5, dtype=int)\nsubmission = pd.DataFrame({\"id\": test[\"id\"], \"target\": y_test})\nsubmission.to_csv(\"submission.csv\", index=False)","9b0bc091":"### Text Classification Model","3540ee29":"## Table of Contents\n- [1. Overview](#1.)\n- [2. Import Packages and Datasets](#2.)\n- [3. Data Wrangling](#3.)\n- [4. Exploratory Data Analysis & Data Preprocessing](#4.)\n- [5. Model Development](#5.)\n- [6. Submission](#6.)","5170d64f":"<a id=\"6.\"><\/a>\n## 6. Submission","541a5cbe":"<a id=\"5.\"><\/a>\n## Model Development","9b0042bf":"### BinaryCrossEntropy with weights \nUse this version of BinaryCrossEntropy to solve class imbalance problem.","d3291a33":"<a id=\"1.\"><\/a>\n## 1. Overview\nIn this notebook I will build a Disaster Tweets Classification Model using TF-IDF vectorization in Keras.","e93f6104":"# Disaster Tweets Classification: TF-IDF","c3f49bfc":"<a id=\"2.\"><\/a>\n## 2. Import Packages and Datasets ","dd59ef5a":"### TF-IDF Vectorization","8522880e":"<a id=\"4.\"><\/a>\n## 4. Exploratory Data Analysis & Data Preprocessing\n- Tokenize Texts\n- Show Staticstic info of texts","8da0f41f":"<a id=\"3.\"><\/a>\n## 3. Data Wrangling\nLet's see null values for each column."}}