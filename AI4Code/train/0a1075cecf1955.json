{"cell_type":{"de75cedb":"code","b9eb3285":"code","9f6ccebd":"code","7481d225":"code","62caf6d4":"code","62fa3f86":"code","945a2a56":"code","35ab31d1":"code","556a3ec2":"code","624cb6ce":"code","17dcad46":"code","a2802f1d":"code","b4ee238b":"code","6eac1bf9":"code","5a4ed088":"code","a1152304":"code","050381d0":"code","4775a7a8":"code","3a3c39c1":"code","e626d165":"code","c16c8583":"code","e1119609":"code","ab4835ae":"code","a14a0164":"code","37e0da99":"code","c41116ff":"markdown","af78133f":"markdown","b1b489dd":"markdown","155a57c4":"markdown","6e17af0e":"markdown","839a28c3":"markdown","f1f64149":"markdown","c2dda3bb":"markdown","1ac2e917":"markdown","c092be8f":"markdown"},"source":{"de75cedb":"import os\n\nimport pandas as pd\nimport matplotlib.pyplot as plt\nfrom matplotlib.pyplot import imread\nimport numpy as np\nimport seaborn as sns\nimport cv2\nimport random\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score\nfrom tqdm import tqdm\n\nimport torch\nfrom torch import from_numpy\nimport torch.nn as nn\nimport torchvision\nimport torchvision.models as models\nfrom torchvision import models as tvmodels\nfrom torch.utils.data import Dataset, DataLoader\nfrom torchvision import transforms, utils\nfrom torchvision.models import resnet\nimport torch.nn.functional as F\nimport albumentations as A\nfrom albumentations.pytorch import ToTensorV2\n\nfrom torch.cuda.amp import autocast, GradScaler","b9eb3285":"# lets read all the images\n# The label for Anime is 0 and for Cartoon, it is 1\n\nanime_path = '..\/input\/anime-and-cartoon-image-classification\/Training Data\/Anime\/'\ncartoon_path = '..\/input\/anime-and-cartoon-image-classification\/Training Data\/Cartoon\/'\n\nhor_size = []\nver_size = []\nlabel = []","9f6ccebd":"for folder in os.scandir(anime_path):\n    for file in os.scandir(anime_path + folder.name):\n        img = cv2.imread(anime_path + folder.name + '\/' + file.name)\n        hor_size.append(img.shape[0])\n        ver_size.append(img.shape[1])\n        label.append(0)\n        \nfor folder in os.scandir(cartoon_path):\n    for file in os.scandir(cartoon_path + folder.name):\n        img = cv2.imread(cartoon_path + folder.name + '\/' + file.name)\n        hor_size.append(img.shape[0])\n        ver_size.append(img.shape[1])\n        label.append(1)","7481d225":"size_data = pd.DataFrame({'hor_size': hor_size, 'ver_size': ver_size, 'label' : label})","62caf6d4":"plt.figure(figsize=(5, 5))\nsns.countplot(data=size_data, x='label');","62fa3f86":"fig, ax = plt.subplots(ncols=2, figsize=(15,5))\nsns.histplot(data=size_data['hor_size'], ax=ax[0])\nsns.histplot(data=size_data['ver_size'], ax=ax[1])","945a2a56":"sns.scatterplot(x = 'hor_size', y = 'ver_size', data=size_data, marker = \".\")","35ab31d1":"num_class=2 #0 for anime and 1 for cartoon\n\nlearning_rate = 0.00005\ntraining_epochs = 30\nbt_size = 20\nnum_wk=4\n\n#imagenet mean & std\nimg_mean = [0.485, 0.456, 0.406]\nimg_std = [0.229, 0.224, 0.225]\n\nimg_size = 224 #to use resnext50\n\ndev = 'cuda:0'","556a3ec2":"def get_img(path):\n    im_bgr = cv2.imread(path, cv2.IMREAD_COLOR)\n    im_rgb = im_bgr[:, :, ::-1]\n    #im_rgb = cv2.resize(im_rgb, (224, 224))\n    im_rgb = np.array(im_rgb, dtype='float32')\n    im_rgb \/= 255\n    return im_rgb","624cb6ce":"Img = []\nlabel = []\n\n#data reading\nfor folder in os.scandir(anime_path):\n    for file in os.scandir(anime_path + folder.name):\n        img = get_img(anime_path + folder.name + '\/' + file.name)\n        Img.append(img)\n        label.append(0)\n        \nfor folder in os.scandir(cartoon_path):\n    for file in os.scandir(cartoon_path + folder.name):\n        img = get_img(cartoon_path + folder.name + '\/' + file.name)\n        Img.append(img)\n        label.append(1)\n    \n#To np array\nImg = np.array(Img)\nlabel = np.array(label)","17dcad46":"# lets plot 5 random images\n\nlabels = {0:'Anime', 1:'Cartoon'}\n\nfor i in range(5):\n    n = random.randint(0, len(label))\n    plt.figure()\n    plt.title(labels[label[n]])\n    plt.imshow(Img[n])","a2802f1d":"# lets take 80% of the data for training\n# 10% for validating and 10% for testing\nX_train, X_val, y_train, y_val = train_test_split(Img, label, test_size=0.2, stratify=label, shuffle=True)\nX_val, X_test, y_val, y_test = train_test_split(X_val, y_val, test_size=0.5, stratify=y_val)","b4ee238b":"class ACDataset(Dataset):\n    def __init__(self, x_array, y_array, transform = None):\n        super(ACDataset, self).__init__()\n\n        self.x = x_array\n        self.y = y_array\n        self.transform = transform\n        \n        \n    def __getitem__(self, index):\n        img = self.transform(image=self.x[index])['image']\n        return img, self.y[index]\n\n    def __len__(self):\n        return len(self.y)","6eac1bf9":"train_trans = A.Compose([\n    A.Resize(224,224),\n    A.HorizontalFlip(p=0.5),\n    A.ShiftScaleRotate(p=0.5),\n    A.Normalize(img_mean, img_std),\n    ToTensorV2(),\n])\n\nval_trans = A.Compose([\n    A.Resize(224,224),\n    A.Normalize(img_mean, img_std),\n    ToTensorV2(),\n])\n\ntest_trans = A.Compose([\n    A.Resize(224,224),\n    A.Normalize(img_mean, img_std),\n    ToTensorV2(),\n])","5a4ed088":"#dataset\ntrain_ds = ACDataset(X_train, y_train, train_trans)\nval_ds = ACDataset(X_val, y_val, val_trans)\n\n#dataloader\ntrain_dl = DataLoader(\n        train_ds,\n        batch_size=bt_size,\n        shuffle=True,        \n        num_workers=num_wk,\n    )\nval_dl = DataLoader(\n        val_ds, \n        batch_size=bt_size,\n        num_workers=num_wk,\n        shuffle=False\n    )","a1152304":"def val_one_epoch(model, loss, data_loader, device):\n    model.eval()\n    \n    preds_all = []\n    targets_all = []\n    loss_sum = 0\n    sample_num = 0\n    \n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs, targets) in pbar:\n        imgs = imgs.to(device).float()\n        targets = targets.to(device).long()\n        \n        preds = model(imgs)\n        preds_all += [torch.argmax(preds, 1).detach().cpu().numpy()]\n        targets_all += [targets.detach().cpu().numpy()]\n        \n        cost = loss(preds, targets)\n        \n        loss_sum += cost.item()*targets.shape[0]\n        sample_num += targets.shape[0]\n    \n    preds_all = np.concatenate(preds_all)\n    targets_all = np.concatenate(targets_all)\n    print('accuracy = {:.4f}'.format((preds_all==targets_all).mean()))\n    \n    return (preds_all==targets_all).mean(), loss_sum\/sample_num\n\n\ndef train_one_epoch(model, loss, optim, data_loader, device):\n    model.train()\n    #scaler = GradScaler()\n    preds_all = []\n    targets_all = []\n    loss_sum = 0\n    sample_num = 0\n    \n    pbar = tqdm(enumerate(data_loader), total=len(data_loader))\n    for step, (imgs, targets) in pbar:\n        imgs = imgs.to(device).float()\n        targets = targets.to(device).long()\n        optim.zero_grad()\n        \n        with autocast():\n            preds = model(imgs)\n            cost = loss(preds, targets)\n            \n        #scaler.scale(cost).backward()\n        #scaler.step(optim)\n        #scaler.update()\n        cost.backward()\n        optim.step()\n        \n        preds_all += [torch.argmax(preds, 1).detach().cpu().numpy()]\n        targets_all += [targets.detach().cpu().numpy()]\n        loss_sum += cost.item()*targets.shape[0]\n        sample_num += targets.shape[0]\n        \n\n        \n    preds_all = np.concatenate(preds_all)\n    targets_all = np.concatenate(targets_all)  \n       \n    return (preds_all==targets_all).mean(), loss_sum\/sample_num","050381d0":"ac_resnext50 = nn.Sequential(\n    models.resnext50_32x4d(pretrained=True),\n    nn.Linear(1000, num_class)\n)","4775a7a8":"device = torch.device(dev)\n\nmodel = ac_resnext50.to(device)\nloss = nn.CrossEntropyLoss().to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n\nacc_train_cnt = []\nloss_train_cnt = []\n\nacc_val_cnt = []\nloss_val_cnt = []","3a3c39c1":"for epochs in range(training_epochs):\n    (acc, losses) = train_one_epoch(model, loss, optimizer, train_dl, device)\n    acc_train_cnt.append(acc)\n    loss_train_cnt.append(losses)\n    \n    with torch.no_grad():\n        (acc, losses) = val_one_epoch(model, loss, val_dl, device)\n    acc_val_cnt.append(acc)\n    loss_val_cnt.append(losses)\n    torch.save(model.state_dict(),'acres_{}'.format(epochs))\n    \nprint('Train finished')","e626d165":"loss_df = pd.DataFrame({'train': loss_train_cnt, 'val': loss_train_cnt})\nacc_df = pd.DataFrame({'train': acc_train_cnt, 'val': acc_val_cnt})","c16c8583":"#loss progress\nax = sns.lineplot(data=loss_df)\n\nplt.title('Loss progress', fontsize=20)\nplt.ylabel('Loss', fontsize=14)\nplt.xlabel('Epochs', fontsize=14)\nplt.legend(fontsize=12, loc='best')\nplt.show()","e1119609":"#acc progress\nax = sns.lineplot(data=acc_df)\n\nplt.title('Acc progress', fontsize=20)\nplt.ylabel('Acc', fontsize=14)\nplt.xlabel('Epochs', fontsize=14)\nplt.legend(fontsize=12, loc='best')\nplt.show()","ab4835ae":"test_ds = ACDataset(X_test, y_test, test_trans)\ntest_dl = DataLoader(dataset = test_ds, batch_size = bt_size, num_workers = num_wk, shuffle = False)","a14a0164":"acc_val_cnt = np.array(acc_val_cnt)\nacc_idx = np.argsort(acc_val_cnt)\nacc_idx = acc_idx[::-1]\n\nmodel_num = acc_idx[0]","37e0da99":"model.load_state_dict(torch.load('.\/acres_{}'.format(model_num)))\nacc, loss = val_one_epoch(model, loss, test_dl, device)\n\n#final accuracy\nprint(\"test accuray = \", acc)","c41116ff":"The images vary in size. Since the ResNeXt50 requires (224,224) for the input size, we should resize them.","af78133f":"# **Data Loading**","b1b489dd":"# **Training**","155a57c4":"# **Data Processing**","6e17af0e":"# **Model Settings**","839a28c3":"# **Imports**","f1f64149":"# **Loss & Acc Check**","c2dda3bb":"# **Data Analysis**\n\nBefore loading the data, let's check the size of the images.\n\nSome parts of the code is from [here](https:\/\/www.kaggle.com\/kanakmittal\/89-accuracy-implemented-from-scratch-author)","1ac2e917":"# **Prediction**","c092be8f":"# **Parameter Setting**"}}