{"cell_type":{"78ae41c1":"code","95d7a4c9":"code","53e1bfc9":"code","29fb3202":"code","2500048d":"code","699154a4":"code","ab3b2902":"code","25df04e4":"code","fb7f7cc8":"code","e2736d98":"code","09caf9dd":"code","332e66a4":"code","d3906827":"code","9198e242":"code","f71968ba":"code","56acbe3a":"code","573ffd04":"code","690a1130":"code","d76359c5":"code","d90d259e":"code","7cb8f6b3":"code","3aae4214":"code","31444022":"markdown","b90ae00e":"markdown","bc1ace8c":"markdown","fad1dbc8":"markdown","fd02cb6f":"markdown","bae0feef":"markdown","d2bb17e3":"markdown"},"source":{"78ae41c1":"#import the relevant libraries\n\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pickle\nimport math\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import mean_squared_error\n","95d7a4c9":"#Read the auto-mpg dataset\ninput_data = pd.read_csv(\"..\/input\/autompg\/auto-mpg.csv\") \ninput_data.head()","53e1bfc9":"# 1 Shape\ninput_data.shape","29fb3202":"# 2 Datatypes: \ninput_data.dtypes","2500048d":"# Dropping invalid rows in horsepower column, it can either done using df.attribute or df['attribute']\n\nfor column in ['horsepower']:\n    #input_data[column] = input_data[column].str.replace('?','')\n    input_data[column] = pd.to_numeric(input_data[column], errors = 'coerce')\ninput_data[input_data['horsepower'].isna()]\ninput_data.dropna(axis = 0,inplace = True)","699154a4":"input_data.dtypes","ab3b2902":"len(input_data['car name'].unique())","25df04e4":"# 3 Missing Values: \ninput_data.info()","fb7f7cc8":"#4 zero variance column needs to be removed. \n\nfor col in input_data:\n    print(col, input_data[col].value_counts().count())\n    \n#Since none of the column is invariant","e2736d98":"#5 Range of numbers in each column: Check if the column values within the dataset are in the same magnitude\nfor i in input_data.columns:\n    print(\" Range of {} min {}, max {}\" .format(i, min(input_data[i]), max(input_data[i])))","09caf9dd":"# 6 Relationship between features & the target\ninput_data.corr()","332e66a4":"plt.figure(figsize=(16, 6))\nsns.heatmap(input_data.corr(), annot=True);","d3906827":"# car_name column does not have any impact on the target column, so drop the car_name\ninput_data.drop(['car name'], axis = 1, inplace = True)\ninput_data.head()","9198e242":"# create the \"features and target\" data sets\nX = input_data.drop('mpg',axis=1)\ny = input_data['mpg']","f71968ba":"# visualize each feature against mpg\nfor col in X.columns:\n    input_data.plot.scatter(x='mpg', y=col)","56acbe3a":"# create the \"features and target\" data sets\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\nprint(X_train.shape, X_test.shape, y_train.shape, y_test.shape)","573ffd04":"# create and fit a linear regression model\nlm_input_data = LinearRegression()\nauto_mpg_model = lm_input_data.fit(X_train, y_train)\n\n# computing yhat (ie predictions) using X_test (ie test data)\nyhat = auto_mpg_model.predict(X_test)\nyhat = [round(x,1) for x in yhat]\nprint('\\nfirst 20 training preds:\\n\\n', yhat[:20])","690a1130":"# simple function to compare actual and predicted values\ndef compare_prediction(y, yhat):\n    comp_matrix = pd.DataFrame(zip(y, yhat), columns = ['Actual', 'Predicted'])\n    comp_matrix['Err'] = abs(comp_matrix['Actual']-comp_matrix['Predicted'])\n    comp_matrix['PctErr'] = comp_matrix['Err']\/comp_matrix['Actual'] * 100\n    mean_value = np.mean(comp_matrix['PctErr'])\n    return comp_matrix, mean_value","d76359c5":"# compare actual and predicted values\ncomp_matrix, mean = compare_prediction(y_test, yhat)\nprint(\"Model prediction comparison and mean error:\", comp_matrix, mean)\naccuracy = round((100-mean),2)\nprint('Model accuracy =', accuracy)","d90d259e":"# Compare MSE and RMSE\nMSE = mean_squared_error(y_test, yhat)\nRMSE = math.sqrt(MSE)\nprint(f'Mean Squared Error : {MSE}, Root Mean Squared Error : {RMSE}')\nprint('Mean Squared Error : %d' %MSE, 'Root Mean Squared Error : %d'%RMSE)","7cb8f6b3":"# save auto_mpg_model as per analysis\nmodel_file = open('auto_mpg_model.pkl','wb')\npickle.dump(auto_mpg_model, model_file)\nmodel_file.close()","3aae4214":"# reload the model from disk and check if it is saved properly.\nmodel_file = open('auto_mpg_model.pkl', 'rb')\nlr_model = pickle.load(model_file)\nmodel_file.close()\nprint(lr_model)","31444022":"### Insights \/ Sanity Check Conclusions\u00b6\n\n1. **Shape and data sufficiency: Check if there are sufficient rows of data for an ML problem**\n    1. **INSIGHT:** Shape of the data is (399, 9). i.e., dataset contains ~400 observations, which is much greater than number of columns (9). Hence we can apply ML techniques rather than statistical rule-based approach.\n\n\n2. **Datatypes: Check whether all the columns in the given dataset is numeric**\n    1. **INSIGHT:** `Dtype` indicates that all columns except horsepower are numeric, in order to build an ML model we need to convert horsepower to numeric\n\n\n3. **Missing Values: Check whether there are missing values**\n    1. **INSIGHT:** `Non-Null Count` indicates there are no missing values in the dataset\n\n\n4. **Zero-variance: Check if there are any zero variance column in the dataset**\n    1. **INSIGHT:** No zero-variance columns found in the dataset\n\n\n5. **Range of numbers in each column: Check if the column values within the dataset are in the same magnitude**\n    1. **INSIGHT:** Each column has numbers within the same magnitude\n    \n\n6. **Correlation: Check correlation between feature columns & target**\n    1. **INSIGHT:**  0.00 - 0.20 very weak correlation. No features exists\n    2. **INSIGHT:**  0.20 - 0.40 have weak correlation. No features exists\n    3. **INSIGHT:**  0.40 - 0.60 have Good Correlation - `acceleration`, `model year`, `origin`\n    4. **INSIGHT:**  0.60 - 0.80 Strong correlation - `cylinder`, `displacement`, `horse power`\n    5. **INSIGHT:**  0.80 - 1.0 very strong correlation - `weight` \n\n\n***Note:*** *absolute values of correlations were considered*\n\nConclusions are drawn after plotting the features against target using  heatmap & scatter plot. \n\n**This concludes the sanity checking and we can now proceed to EDA and preprocessing.**","b90ae00e":"### Develop an ML Model\n\nDeveloping an ML model involves a number of steps.\n\nLet us adopt the following Machine Learning Pipeline:\n\n1. Sanity Check\n2. EDA\/Preprocessing\n3. Feature Engineering\n4. Model Building\n5. Model Saving\n6. Model Deployment\n\nOnce the model is deployed, the pipeline extends to include the below steps:\n\n7. Model in Production\n8. Observe model behaviour\n9. Obtain updated datasets\n10. Redo steps 1..9 if required\n\n_Note: these extended steps are not covered in this exercise_\n","bc1ace8c":"### EDA\/Preprocessing\n_(Based on the insights from the sanity check, we can now determine how to process the data.)_\n\n#### Checklist of STANDARD EDA items\n\n1. Strategy for missing data\n    1. Action: horsepower has six missing values, drop these rows\n    2. Action: convert horsepower to numeric\n    \n    \n2. Convert categorical to numeric\n    origin, cylinders, model year are categorical but already numeric\n    \n    \n3. Dimensionality reduction\/Drop the identified columns\n    1. Action: Drop the carname column \n    \n    \n4. Check for Outliers, Normalize data in columns to fit a range (*Optional*)\n    1. Action: As per Insights 5A there are no Outliers ----NOT DONE\n\n### Approach:\nAs there is a strong correlation between features and target we will consider all the 7 numeric columns to build our ML model","fad1dbc8":"##  Auto mpg, Model Creation and Saving","fd02cb6f":"# Auto MPG Model Deployment\nSo far, we have analyzed the given dataset, computed the accuracy of the model. The next step is to deploy the model in production.\n\nFor this we will be developing a Flask web application. This application will load the model, allow users to enter various automobile characteristics and obtain mpg predictions. This web application cannot be run on Kaggle - you need to run it on your local system or on a platform like Heroku.\n\nComplete code has been uploaded onto github at https:\/\/github.com\/saigeethachandrashekar\/auto-mpg.git.\n\nPlease clone the repo - this contains the dataset, the code required for building and saving the model on to your local system. Code for a Flask app is provided for deploying the model on your local machine. The app can also be deployed on Heroku - the requirements.txt and Procfile are also provided for this.","bae0feef":"## Sanity Check\n\n1. Shape and data sufficiency: Check if there are sufficient rows of data for an ML problem\n2. Datatypes: Check whether all the columns in the given dataset is numeric\n3. Missing Values: Check whether there are missing values\n4. Zero-variance: Check if there are any zero variance column in the dataset\n5. Range of numbers in each column: Check if the column values within the dataset are in the same magnitude\n6. Correlation: Check correlation between feature columns & target\n","d2bb17e3":"# Welcome to this Kaggle notebook!\n\nThis notebook is intended for beginners of machine learning. I have used a machine learning pipeline to build a linear regression model to predict the mileage of an automobile given its various characteristics.\n\nI have also created a simple Flask web application for model deployment. You can deploy this in your local machine or in Heroku (the Procfile, requirements.txt are also provided).\n\nThe complete codebase is available in github at https:\/\/github.com\/saigeethachandrashekar\/auto-mpg.git"}}