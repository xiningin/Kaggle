{"cell_type":{"876460c0":"code","2160c4b7":"code","42aeb7cb":"code","71ff1e04":"code","64d79c24":"code","04ce1192":"code","7af68d9b":"code","8be6c141":"code","89997ec9":"code","01cf4c2e":"code","7e0a6e24":"code","05a8b69e":"code","499c158d":"code","e236fa3f":"code","fd9ae4b7":"code","4a37ed5b":"code","d8643f21":"code","88b151af":"code","5640f8e4":"code","2be22469":"code","1af53ebd":"code","e821251d":"code","0383ce1a":"code","ba123d72":"code","f338b66a":"code","73485a37":"code","ec8684f6":"code","c4366a54":"code","99845446":"code","474f0c1e":"code","bb499de4":"code","4824b528":"code","32d470c6":"code","2ccead07":"code","9b8dfe0c":"code","028351d9":"code","e8f2cbc9":"code","f8aaf680":"code","b97fa61a":"code","1576def2":"code","374c0486":"code","11d14ead":"code","b5d543a8":"code","772177d4":"code","1712a47e":"code","14112ca8":"code","908859b7":"code","6005727e":"code","6572af14":"code","15eb2604":"code","844fddf1":"code","06094892":"code","ea0a6fe4":"code","601561a2":"code","f0527f5a":"code","47358946":"code","f85aff1d":"code","12c35eb9":"code","459c1bbb":"code","9a70badd":"code","41c09c40":"code","649df1cf":"code","a61348be":"code","d3ca46e9":"markdown","32ca3cd6":"markdown","666dbad9":"markdown","d0174563":"markdown","33f4d33c":"markdown","268cd599":"markdown","29fd5b66":"markdown","5c1f52fc":"markdown","376ff765":"markdown","e94c8c50":"markdown","04a583a8":"markdown","2233ab31":"markdown","ccbe394a":"markdown","94880641":"markdown","ca54738b":"markdown","d55f609d":"markdown","2ad9305b":"markdown","fd528e7b":"markdown","38326f26":"markdown","3749e667":"markdown","1efe03b1":"markdown","d2662f4e":"markdown","3e27bbcd":"markdown","872aed35":"markdown","99523a30":"markdown","1c10be19":"markdown","66cc2d41":"markdown","6cb27e77":"markdown","62326ceb":"markdown","fac513e0":"markdown","e2db39cc":"markdown","6e12e59c":"markdown","90562c07":"markdown"},"source":{"876460c0":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","2160c4b7":"import warnings \nwarnings.filterwarnings('ignore')\n\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.preprocessing import PowerTransformer\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import r2_score\nfrom sklearn.metrics import mean_squared_error\nfrom sklearn.feature_selection import RFE\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.preprocessing import LabelEncoder\nimport statsmodels.api as sm\nfrom pandas.plotting import autocorrelation_plot\nfrom statsmodels.stats.outliers_influence import variance_inflation_factor\nfrom yellowbrick.regressor import ResidualsPlot\nfrom statsmodels.graphics import tsaplots\n\n\npd.set_option('max_rows',None)\npd.set_option('display.max_columns',100)\n\n%matplotlib inline","42aeb7cb":"# Loading the data\n\npath = r'\/kaggle\/input\/bike-sharing-using-linear-regression\/day.csv'\n\nbike = pd.read_csv(path,parse_dates=['dteday'])\n\nbike.head()","71ff1e04":"bike.shape","64d79c24":"bike.info()","04ce1192":"bike.describe()","7af68d9b":"# Renaming the columns\n\nbike.rename(columns = {'hum':'Humidity','yr':'Year','temp':'Temperature','weathersit':'Weather','holiday':'Holiday','cnt':'Count','mnth':'Month','season':'Season'},inplace=True)\n\nbike.head()","8be6c141":"# Plotting the DistPlot for windspeed\n\nfig = plt.figure(figsize=(10,5))\nfig.add_subplot(121)\nsns.distplot(bike['windspeed'])\nplt.title('Windspeed',fontsize=20)\n\nfig.add_subplot(122)\npt = PowerTransformer()\ntransformed = pt.fit_transform(bike[['windspeed']])\nsns.distplot(transformed)\nplt.title('Transformed-Windspeed')\nplt.show()","89997ec9":"# Humidity Variable\n\nfig = plt.figure(figsize=(10,5))\nfig.add_subplot(121)\nsns.distplot(bike['Humidity'])\nplt.title('Humidity',fontsize=20)\n\nfig.add_subplot(122)\npt = PowerTransformer()\ntransformed = pt.fit_transform(bike[['Humidity']])\nsns.distplot(transformed)\nplt.title('Transformed-Humidity')\nplt.show()","01cf4c2e":"# Temperature Variable\n\nfig = plt.figure(figsize=(10,5))\nfig.add_subplot(121)\nsns.distplot(bike['Temperature'])\nplt.title('Temperature',fontsize=20)\n\nfig.add_subplot(122)\npt = PowerTransformer()\ntransformed = pt.fit_transform(bike[['Temperature']])\nsns.distplot(transformed)\nplt.title('Transformed-Temperature')\nplt.show()","7e0a6e24":"for i in ['Season','Month','weekday','Weather']:\n    print('---------------------------')\n    print(bike[i].name)\n    print()\n    print(bike[i].value_counts())\n    print()","05a8b69e":"def Season_to_text(x):\n    if x==1:\n        return 'Spring'\n    if x==2:\n        return 'Summer'\n    if x==3:\n        return 'Fall'\n    else:\n        return 'Winter'\n\n    \ndef weather_sit(x):\n    if x==1:\n        return 'Clear'\n    elif x==2:\n        return 'Mist'\n    elif x==3:\n        return 'Light_Rain'\n    else:\n        return 'Heavy_Rain'\n\ndays = {0:'Sunday',1:'Monday',2:'Tuesday',3:'Wednesday',4:'Thursday',5:'Friday',6:'Saturday'}\nmonths = {1:'Jan',2:'Feb',3:'Mar',4:'Apr',5:'May',6:'Jun',7:'Jul',8:'Aug',9:'Sept',10:'Oct',11:'Nov',12:'Dec'}\n\n    \nbike.Season = bike.Season.apply(Season_to_text)\nbike.Weather = bike.Weather.apply(weather_sit)\nbike.weekday = bike.weekday.apply(lambda x : days.get(x))\nbike.Month = bike.Month.apply(lambda x:months.get(x))","499c158d":"bike.head()","e236fa3f":"bike.Season = bike.Season.apply(lambda x: {'Spring':'Winter','Summer':'Spring','Fall':'Summer','Winter':'Fall'}.get(x))\n\nbike.head()","fd9ae4b7":"# Plotting the boxplot for the categorical variables\n\nplt.figure(figsize=(15,20))\nfor i,j in enumerate(['Season','Weather','Month','Year']):\n    plt.subplots_adjust(wspace=0.2,hspace=0.5)\n    plt.subplot(3,2,i+1)\n    sns.boxplot(data=bike,x=j,y='Count')\n    plt.title(j +' vs '+ bike.Count.name,fontsize=25)\n    plt.xticks(fontsize=15)\n    plt.yticks(fontsize=15)\nplt.show()","4a37ed5b":"# Plotting the boxplot for the categorical variables\n\nplt.figure(figsize=(20,10),linewidth=0.15,)\nfor i,j in enumerate(['Month','weekday']):\n    plt.subplot(2,2,i+1)\n    sns.boxenplot(data=bike,x=j,y='Count',hue='Year')\n    plt.title(j +' vs '+ bike.Count.name,fontsize=25)\nplt.show()","d8643f21":"# Plotting the boxplot for the categorical variables\n\nplt.figure(figsize=(10,10),linewidth=0.55)\nfor i,j in enumerate(['Season','Month']):\n    plt.subplots_adjust(wspace=0.2,hspace=0.3)\n    plt.subplot(2,1,i+1)\n    sns.barplot(data=bike,x=j,y='Count',hue='Weather')\n    plt.title(j +' vs '+ bike.Count.name,fontsize=25)\n    plt.legend(loc='best')\n    plt.xticks(fontsize=10)\n    plt.yticks(fontsize=10)\nplt.show()","88b151af":"# Creating dummy variables on the data set\n\nbike1 = pd.get_dummies(bike,drop_first=True)","5640f8e4":"bike2=bike1.copy()","2be22469":"# Checking the pairplot \n\nplt.figure(figsize=(20,30))\nsns.pairplot(data=bike2,x_vars=['Temperature','casual','registered','Humidity','windspeed','atemp'],y_vars=['Count','atemp'])\nplt.show()","1af53ebd":"# Getting the correlation matrix\n\nbike2[['Temperature','casual','registered','Humidity','windspeed','Count','atemp']].corr().round(2)","e821251d":"# Plotting the heatmap\n\nplt.figure(figsize=(20,10))\nsns.heatmap(bike2[['Temperature','casual','registered','Humidity','windspeed','Count','atemp']].corr().round(2),annot=True,center=0.3,linewidths=0.5)\nplt.show()","0383ce1a":"# Removing the redundant and unnecessary variables \n\nbike2.drop(columns=['instant','dteday','atemp','casual','registered'],inplace=True)","ba123d72":"bike2.info()","f338b66a":"# Plotting the heatmap\n\nplt.figure(figsize=(20,20))\nsns.heatmap(bike2.corr().round(2),annot=True,cmap='RdYlGn',center=0.2)\nplt.show()","73485a37":"# Splitting the dataset into train and test \n\nnp.random.seed(0)\ntrain,test = train_test_split(bike2,train_size=0.7,test_size=0.3,random_state=100)","ec8684f6":"train.head()","c4366a54":"# Rescaling the train and test\n\nvar = ['Humidity','windspeed','Temperature','Count']\n\nscaler = MinMaxScaler()\n\ntrain[var] = scaler.fit_transform(train[var])\n\ntest[var] = scaler.transform(test[var])","99845446":"# Dividing train and test into their corresponsing X and Y variables\n\n# Train\ny_train = train.pop('Count')\nx_train = train\n\n# Test\ny_test = test.pop('Count')\nx_test = test","474f0c1e":"print('Shape of x_train :',x_train.shape)\nprint('Shape of y_train :',y_train.shape)","bb499de4":"print('Shape of x_test :',x_test.shape)\nprint('Shape of y_test :',y_test.shape)","4824b528":"# Model 1 - with all the predictors\n\nx_train_sm = sm.add_constant(x_train)\n\nlr = sm.OLS(y_train,x_train_sm).fit()\n\nlr.summary()","32d470c6":"# Initiating the model using sklearn.linear_model\n\nlm = LinearRegression()\n\nlm.fit(x_train,y_train)","2ccead07":"# rfe variable taking 15 top features\n\nrfe = RFE(lm,15)\nrfe=rfe.fit(x_train,y_train)","9b8dfe0c":"# Making the dataframe to choose the important features\n\ndf = pd.DataFrame(columns=['Features','Support','Rank'])\ndf['Features'] = x_train.columns\ndf['Support'] = rfe.support_\ndf['Rank'] = rfe.ranking_\n\n# Sorting the dataframe \ndf","028351d9":"# Taking the valid columns for model building after doing rfe\n\ncol = x_train.columns[rfe.support_]\n\nprint(col)","e8f2cbc9":"# Building the Model 2\n\nx_train_sm = sm.add_constant(x_train[col])\n\nlr = sm.OLS(y_train,x_train_sm).fit()\n\ny_train_pred = lr.predict(x_train_sm)\n\nlr.summary()","f8aaf680":"# Function for the VIF values\n\ndef vif(x=x_train):\n    VIF = pd.DataFrame(columns=['Features','VIF'])\n    VIF['Features'] = x.columns\n    VIF['VIF']  = [ variance_inflation_factor(x.values,i) for i in range(x.shape[1])]\n    return VIF.sort_values(by='VIF',ascending=False)\n","b97fa61a":"# VIF Check\n\nvif(x_train[col])","1576def2":"x = x_train[col]\n\nx = x_train[col].drop(columns=['Humidity'])\n\nvif(x)","374c0486":"x = x_train[col]\n\nx = x_train[col].drop(columns=['Humidity','Season_Summer'])\n\nvif(x)","11d14ead":"# Building the model 3\n\nx_train_sm = sm.add_constant(x)\n\nlr = sm.OLS(y_train,x_train_sm).fit()\n\ny_train_pred = lr.predict(x_train_sm)\n\nlr.summary()","b5d543a8":"# lm 4 \n\nx = x_train[col]\n\nx = x_train[col].drop(columns=['Humidity','Season_Summer','Season_Spring'])\n\nvif(x)","772177d4":"# Building the model 4\n\nx_train_sm = sm.add_constant(x)\n\nlr = sm.OLS(y_train,x_train_sm).fit()\n\ny_train_pred = lr.predict(x_train_sm)\n\nlr.summary()","1712a47e":"# lm5 \n\nx = x_train[col]\n\nx = x_train[col].drop(columns=['Humidity','Season_Spring','Season_Summer','Month_Nov'])\n\nvif(x)","14112ca8":"# Building the model 5\n\nx_train_sm = sm.add_constant(x)\n\nlr = sm.OLS(y_train,x_train_sm).fit()\n\ny_train_pred = lr.predict(x_train_sm)\n\nlr.summary()","908859b7":"# lm 6\n\nx = x_train[col]\n\nx = x_train[col].drop(columns=['Humidity','Season_Summer','Season_Spring','Month_Nov','Month_Dec'])\n\nvif(x)","6005727e":"# Building the model 6\n\nx_train_sm = sm.add_constant(x)\n\nlr = sm.OLS(y_train,x_train_sm).fit()\n\ny_train_pred = lr.predict(x_train_sm)\n\nlr.summary()","6572af14":"# lm 7\nx = x_train[col]\n\nx = x_train[col].drop(columns=['Humidity','windspeed','Season_Summer','Season_Spring','Month_Nov','Month_Dec','Month_Jan','Month_Sept'])\n\n\n# VIF Check\n\nvif(x)","15eb2604":"# Building the model 7\n\nx_train_sm = sm.add_constant(x)\n\nlr = sm.OLS(y_train,x_train_sm).fit()\n\ny_train_pred = lr.predict(x_train_sm)\n\nlr.summary()","844fddf1":"# Calculating predicted values of y\n\ny_train_pred = lr.predict(x_train_sm)","06094892":"res= y_train - y_train_pred\n\n\n# Creating the Distplot for errors\nplt.figure(figsize=(10,6))\nsns.distplot(res,bins=20)\nplt.title('Errors',fontsize=25)\nplt.show()","ea0a6fe4":"# Making Predictions\n\nX = x_test[x.columns]\nX_test_sm = sm.add_constant(X)\ny_test_pred = lr.predict(X_test_sm)","601561a2":"x_test.shape\ny_test.shape","f0527f5a":"# Model Evaluation\n\nplt.figure(figsize=(10,8))\nsns.scatterplot(x=y_test,y=y_test_pred,color='r')\nplt.title('y_test vs y_test_pred',fontsize=25)\nplt.xlabel('y_test',fontsize=20)\nplt.ylabel('y_test_pred',fontsize=20)\nplt.show()","47358946":"# R2 score \n\nprint('Train R-square : ',round(r2_score(y_train,y_train_pred),3))\nprint('Test R-square :',round(r2_score(y_test,y_test_pred),3))","f85aff1d":"# Calculating R2 and adjusted R2 values for training dataset\n\nresiduals_train = lr.resid\n\nrss_train = sum(res**2)\n\ntss_train = sum((y_train - np.mean(y_train))**2)\n\nr2_train = 1-rss_train\/tss_train\n\nn = x_train.shape[0]\n\np = len(x.columns)\n\nadj_r2_train = 1 - ((1-r2_train)*(n-1))\/(n-p-1)\n\nprint('R2 value for the training data',round(r2_train,3))\nprint('Adjusted R2 value for the training data',round(adj_r2_train,3))","12c35eb9":"# Calculating R2 and adjusted R2 values for test dataset\n\nresiduals_test = y_test - y_test_pred\n\nrss_value = sum(residuals_test**2)\n\ntss_value = sum((y_test - np.mean(y_test))**2)\n\nr2_test_value = 1-rss_value\/tss_value\n\nprint('R2 value for test data :',round(r2_test_value,3))\n\nn = X.shape[0]\n\np = len(X.columns)\n\nadj_r2_test = 1 - ((1-r2_test_value)*(n-1))\/(n-p-1)\n\nprint('Adjusted R2 value for test data :',round(adj_r2_test,3))","459c1bbb":"# RMSE value\n\nrmse = np.sqrt(mean_squared_error(y_train,y_train_pred))\n\nprint('RMSE Value :',rmse)","9a70badd":"# Normal distribution of error terms\n\nres = lr.resid\n\nplt.figure(figsize=(20,10))\n\nfig = sm.qqplot(res,fit=True,line='r')\n\nplt.title('Theoretical Qunatiles vs Normal Distribution of residuals')\n\nplt.show()","41c09c40":"# Residual plot to check Homoscedasticity\n\nfrom yellowbrick.regressor import ResidualsPlot\nplt.figure(figsize=(10,5))\n\nlm = LinearRegression()\n\nvis = ResidualsPlot(lm).fit(x,y_train)\n\nvis.score(X,y_test)\n\nvis.poof()\n\nplt.show()","649df1cf":"# Autocorrelation check\n\nfrom statsmodels.graphics import tsaplots\n\nfig = tsaplots.plot_acf(lr.resid,alpha=0.05)\n\nplt.show()","a61348be":"# Checking the coefficients\n\nlr.params","d3ca46e9":"## We can see that the equation of our best fitted line is:\n\n$ Count = 0.249814 +  Year \\times 0.233609 - Holiday \\times 0.087450 + Temperature \\times 0.421300 - Season_Winter \\times 0.153368 - Month_Jul \\times 0.082596 - Weather_Light_Rain \\times 0.286816 - Weather_Mist \\times 0.078421 $ ","32ca3cd6":"### RFE Method","666dbad9":"### <font color='purple'>Comments :<\/font>\n- The categorical variables in the dataset days are Month, Season, year(ordinal), Weekday and Weather Situation.  \n- When the boxplot is plotted between the count (i.e., dependant variable) and Year, it was observed that the demand increases as the year increases.  \n- In the case of the plotting the graph between the weather and count, it can be observed that the demand is actually getting affected due to weather conditions and clear weather has the highest demand. \n- By plotting the month vs count on the boxplot, it can be observed that the demand is slightly low for January, February and from March the demand starts to increase. \n- When the boxplot is plotted for the Seasons vs count, Winter has the lowest number of sales with summer being the highest. \n\n- From the bar graphs it is clear that the demand is minimum in the winters on the days when there was light rain. So, one of the factors inflicting the demand can be cold weather with rain. In the month of July, the mist weather situation has the higher demand than clear weather situation and also the demand is high even when the weather is light rainy. ","d0174563":"### <font color='purple'>Comment :<\/font>\nRFE is used for the feature selection and after using it, the model which we get seems to be pretty good model where all the features seems to be significant but there can be the chances of multicollinearity. Hence, we need to determine it to get the adequate model for predictions.","33f4d33c":"## Modelling","268cd599":"=========================================\nDataset characteristics\n=========================================\t\nday.csv have the following fields:\n\t\n\t- instant: record index\n\t- dteday : date\n\t- season : season (1:spring, 2:summer, 3:fall, 4:winter)\n\t- yr : year (0: 2018, 1:2019)\n\t- mnth : month ( 1 to 12)\n\t- holiday : weather day is a holiday or not \n\t- weekday : day of the week\n\t- workingday : if day is neither weekend nor holiday is 1, otherwise is 0.\n\t+ weathersit : \n\t\t- 1: Clear, Few clouds, Partly cloudy, Partly cloudy\n\t\t- 2: Mist + Cloudy, Mist + Broken clouds, Mist + Few clouds, Mist\n\t\t- 3: Light Snow, Light Rain + Thunderstorm + Scattered clouds, Light Rain + Scattered clouds\n\t\t- 4: Heavy Rain + Ice Pallets + Thunderstorm + Mist, Snow + Fog\n\t- temp : temperature in Celsius\n\t- atemp: feeling temperature in Celsius\n\t- hum: humidity\n\t- windspeed: wind speed\n\t- casual: count of casual users\n\t- registered: count of registered users\n\t- cnt: count of total rental bikes including both casual and registered","29fd5b66":"### <font color='purple'>Comment :<\/font>\nThere are still few variables like Month_Nov which show insignificance due to high p-values so let's drop these predictors one by one.","5c1f52fc":"### R2  and  Adjusted R2  values for test data","376ff765":"### <font color='purple'>Comment :<\/font>\nFrom the plots between Count and the numeric variables it can be seen that there is a very weak correlation between the Temperature and Count.Other variables like atemp and Temperature are highly correlated. Similarly, count has some weak correlations with casual and high corr with registered.","e94c8c50":"## Residual Aanlysis","04a583a8":"# Interpretation of Coefficients:\n\n**Temperature** : A coefficient value of \u20180.421300\u2019 indicate that a unit increase in Temperature variable, increases the bike sharing demand by 0.421300 units.\n\n**Weather_Light_Rain** : A coefficient value of \u2018-0.286816\u2019 indicate that, a unit increase in Weather_Light_Rain variable, decreases the bike sharing demand by 0.286816 units.\n\n**Year**: A coefficient value of \u20180.233609\u2019 indicate that a unit increase in Year variable, increases the bike sharing demand by 0.233609 units.\n\n**Season_Winter**: A coefficient value of \u2018-0.153368\u2019 indicate that a unit increase in Season_Winter variable decreases the bike sharing demand by 0.153368 units.\n\n\n**Holiday**: A coefficient value of \u2018-0.087450\u2019 indicate that a unit increase in Holiday variable decreases the bike sharing demand by 0.087450 units.\n\n**Weather_Mist**: A coefficient value of \u2018-0.078421\u2019 indicate that a unit increase in Weather_Mist variable decreases the bike sharing demand by 0.078421 units.\n\n**Month_Jul**: A coefficient value of \u2018-0.082596\u2019 indicate that a unit increase in Month_Jul variable decreases the bike sharing demand by 0.082596 units.\n\n**Const**: The Constant value of \u20180.249814\u2019 indicate that, in the absence of all other predictor variables (i.e. when x1,x2...xn =0), The bike rental can still increase by 0.249814 units.","2233ab31":"### <font color='purple'>Comment :<\/font>\nThere are few variables which show insignificance due to high p-values so let's drop these predictors one by one.","ccbe394a":"# Model Evaluation ","94880641":"### <font color='purple'>Comment :<\/font> \nThere is no such kind of pattern can be seen from the residual plot. So, we can conclude that variance is constant throughout.","ca54738b":"### <font color='purple'>Comment :<\/font>\nIn the data set it can be observed that Month column and Seasons column doesn't match so it would be better to rectify Season column.","d55f609d":"### <font color='purple'>Comment :<\/font> \nThe VIF values as well as the p-values are now significant enough to say that the model is good for prediction.","2ad9305b":"### Converting the Categorical columns","fd528e7b":"### <font color='purple'>Comment : <\/font>\nSome of the variables like humidity and windspeed has the mean greater than the medians.So we can conclude that these numeric variables are skewed.","38326f26":"# Bike Sharing using linear regression","3749e667":"### <font color='purple'>Comment :<\/font>\nThe VIF values are now less than 5 and now let's build our model and see if the predictors are significant or not by checking their p-values","1efe03b1":"### <font color='purple'>Comment :<\/font> \nAfter removing the Season_Summer, VIF values improved and are now less than 5. There are still insignificant features with high p - values and it will be good to drop those values also. ","d2662f4e":"### <font color='purple'>Comment :<\/font> \nThe model has all the features with the acceptable p-value ranges as well as the VIF values are also less than 5. Hence this model can be used for the predictions as the feature are less than the model 6 and the difference between in the r2 value and adjusted r2 is quite closer. F-statistic value and p-value is also looking good.","3e27bbcd":"# Rescaling the train and test","872aed35":"## Manual selection of feature on the basis of VIF and p-Values","99523a30":"## Dividing the Data into train and Test","1c10be19":"### <font color='purple'>Comment :<\/font>\nNow that we have the VIF values, it will be easier to detect the multicolinearity. From the data frame it can be seen temperature and humidity has the highest VIF values, so drop one of them to see if we can improve the other variable.","66cc2d41":"### <font color='purple'>Comment : <\/font>\nThere are no missing values in the dataset.","6cb27e77":"## Problem Statement\n\nA bike-sharing system is a service in which bikes are made available for shared use to individuals on a short term basis for a price or free. Many bike share systems allow people to borrow a bike from a \"dock\" which is usually computer-controlled wherein the user enters the payment information, and the system unlocks it. This bike can then be returned to another dock belonging to the same system.\n\nA US bike-sharing provider BoomBikes has recently suffered considerable dips in their revenues due to the ongoing Corona pandemic. The company is finding it very difficult to sustain in the current market scenario. So, it has decided to come up with a mindful business plan to be able to accelerate its revenue as soon as the ongoing lockdown comes to an end, and the economy restores to a healthy state.\n\nIn such an attempt, BoomBikes aspires to understand the demand for shared bikes among the people after this ongoing quarantine situation ends across the nation due to Covid-19. They have planned this to prepare themselves to cater to the people's needs once the situation gets better all around and stand out from other service providers and make huge profits.\n\nThey have contracted a consulting company to understand the factors on which the demand for these shared bikes depends. Specifically, they want to understand the factors affecting the demand for these shared bikes in the American market. The company wants to know:\n\n- Which variables are significant in predicting the demand for shared bikes.\n- How well those variables describe the bike demands?\n\nBased on various meteorological surveys and people's styles, the service provider firm has gathered a large dataset on daily bike demands across the American market based on some factors.\n\n\n## Business Goal\n\nYou are required to model the demand for shared bikes with the available independent variables. It will be used by the management to understand how exactly the demands vary with different features. They can accordingly manipulate the business strategy to meet the demand levels and meet the customer's expectations. Further, the model will be a good way for management to understand the demand dynamics of a new market.\n\n\n\n","62326ceb":"# Data Preparation","fac513e0":"### Categorical Columns\n\n1. Season\n2. Month\n3. Weekday\n4. Weather Situation","e2db39cc":"## Assumptions Check","6e12e59c":"## Final Model","90562c07":"### <font color='purple'>Comment :<\/font>\nAfter dropping the humidity variable there are values still there with high VIF values. So let's drop Season Summer and check for the better values. "}}