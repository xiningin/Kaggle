{"cell_type":{"92f1c89f":"code","0e7ae6b0":"code","e447908f":"code","2d17f1d5":"code","11219bc2":"code","17508c3e":"code","b43b5111":"code","ddd2cae6":"code","c2e5a2ba":"code","dbb0b933":"code","bc2b742a":"code","6af24ef8":"code","a7acae90":"code","5735b468":"code","c5e35df3":"code","66e9e4b9":"code","3765e91f":"code","c582dd82":"code","246f0d92":"code","a39dea96":"code","7f3a146f":"code","c41b2278":"code","dd293934":"code","4790214b":"code","41ec1bda":"code","6fb9a8e0":"code","9ea7c107":"code","9c8bcddb":"code","5ab40552":"code","296e9eb2":"code","d1c394ec":"code","7a590623":"code","084d56cf":"code","2640a239":"code","5c9bfafb":"code","5f3cda51":"markdown","cfb718a4":"markdown","06dd9f53":"markdown","8aebc767":"markdown","557e9e4e":"markdown","6667f555":"markdown","7ec3f740":"markdown","96b0fe63":"markdown","c7e9d893":"markdown","db75be88":"markdown"},"source":{"92f1c89f":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom sklearn.preprocessing import LabelEncoder\nfrom sklearn.preprocessing import Normalizer\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.svm import SVR\nfrom sklearn.ensemble import AdaBoostRegressor, RandomForestRegressor, BaggingRegressor, GradientBoostingRegressor\nfrom sklearn.metrics import mean_squared_error, r2_score\nfrom sklearn.model_selection import cross_val_score, StratifiedKFold, learning_curve, RandomizedSearchCV\nfrom sklearn.model_selection import GridSearchCV\n\nfrom xgboost import XGBRegressor\nfrom lightgbm import LGBMRegressor\n\nfrom vecstack import stacking\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","0e7ae6b0":"train=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv', index_col='Id')\ntest=pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv', index_col='Id')","e447908f":"def missing_vals(df):\n    missing=df.isnull().sum()\n    missing=missing[missing>0]\n    missing.sort_values(inplace=True, ascending=False)\n    \n    missing.plot.bar(figsize=(12,10))\n    plt.xlabel('Columns with missing values')\n    plt.ylabel('Number of missing values')\n \n\nmissing_vals(train)","2d17f1d5":"def fill_missing_vals(df):\n    missing=df.isnull().sum()\n    missing=missing[missing > 0]\n    for column_name in list(missing.index):  # .df.index puts all the column nmaes in missing variable into single quotes\n        if df[column_name].dtype=='object':   # hence easier to call them using []\n            df[column_name].fillna(df[column_name].value_counts().index[0], inplace=True)\n        elif df[column_name].dtype == 'int64' or 'int16' or 'float64' or 'float16':\n            df[column_name].fillna(df[column_name].median(), inplace = True)","11219bc2":"fill_missing_vals(train)\ntrain.isnull().sum().max()","17508c3e":"missing_vals(test)","b43b5111":"fill_missing_vals(test)\ntest.isnull().sum().max()","ddd2cae6":"train1=train.copy()\ntest1=test.copy()","c2e5a2ba":"def encode(df):\n    object_col_ind=[]\n    for i in range(df.shape[1]):\n        if df.iloc[:,i].dtype =='object':\n            object_col_ind.append(i)\n        else:\n            pass\n    label = LabelEncoder()\n    for i in object_col_ind:\n        df.iloc[:,i]=label.fit_transform(df.iloc[:,i])\n\n","dbb0b933":"encode(train)\nencode(test)\nprint(\"Train Dtype counts: \\n{}\".format(train.dtypes.value_counts()))\nprint(\"Test Dtype counts: \\n{}\".format(test.dtypes.value_counts()))","bc2b742a":"corr_mat = train[[\"SalePrice\",\"MSSubClass\",\"MSZoning\",\"LotFrontage\",\"LotArea\", \"BldgType\",\n                       \"OverallQual\", \"OverallCond\",\"YearBuilt\", \"BedroomAbvGr\", \"PoolArea\", \"GarageArea\",\n                       \"SaleType\", \"MoSold\"]].corr()\n\nf, ax = plt.subplots(figsize=(16, 8))\nsns.heatmap(corr_mat, vmax=1 , square=True)","6af24ef8":"f,ax=plt.subplots(figsize=(14,8))\nsns.lineplot(train['YearBuilt'], train['SalePrice'],c='green')","a7acae90":"f,ax=plt.subplots(figsize=(14,8))\nsns.lineplot(train['OverallQual'], train['SalePrice'],c='red')","5735b468":"f,ax=plt.subplots(figsize=(12,8))\nsns.distplot(train['SalePrice'])","c5e35df3":"X=train.drop('SalePrice', axis=1)\ny =train['SalePrice']","66e9e4b9":"X_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2)","3765e91f":"def rmse(y,y_pred):\n    return np.sqrt(mean_squared_error(np.log(y),np.log(y_pred)))","c582dd82":"g_boost = GradientBoostingRegressor( n_estimators=6000, learning_rate=0.01,\n                                     max_depth=5, max_features='sqrt',\n                                     min_samples_leaf=15, min_samples_split=10,\n                                     loss='ls', random_state =2\n                                   )\n\ny_pred = cross_val_score(g_boost, X, y, cv=10, n_jobs=-1)\ny_pred.mean()","246f0d92":"g_boost.fit(X,y)\ngbm_pred = g_boost.predict(test)\nprint(r2_score(g_boost.predict(X),y))\nprint(rmse(g_boost.predict(X),y))","a39dea96":"xg_boost = XGBRegressor( learning_rate=0.05,\n                         n_estimators=1000,\n                         max_depth=4, min_child_weight=1,\n                         gamma=1, subsample=0.9,\n                         colsample_bytree=0.2,\n                         objective='reg:squarederror', nthread=-1,\n                         scale_pos_weight=1, seed=7,\n                         reg_alpha=0.00006\n                       )\n\n\ny_pred = cross_val_score(xg_boost, X, y, cv=5, n_jobs=-1)\ny_pred.mean()","7f3a146f":"eval_set=[(X_test,y_test)]  #to prevent overfitting\nxg_boost.fit(X,y,eval_set=eval_set,eval_metric='error',verbose=False)\nxgb_pred=xg_boost.predict(test)\nprint(rmse(xg_boost.predict(X_test),y_test))","c41b2278":"'''param={'learning_rate':[0.01,0.02,0.04],'max_depth':[3,4,5],'subsample':[0.7,0.8,0.9],\n      'gamma':[1,3,5],'n_estimators':[5000,1000,3000]}\n\ngd_cv=GridSearchCV(estimator=xg_boost,param_grid=param,n_jobs=-1,cv=5,scoring='neg_mean_squared_error')\ngd_cv.fit(X,y)'''","dd293934":"'''best_parameters = gd_cv.best_params_\nprint(best_parameters)'''","4790214b":"'''submissionxgb = pd.DataFrame()\n\nsubmissionxgb['Id'] = np.array(test.index)\nsubmissionxgb['SalePrice'] = xgb_pred\nsubmissionxgb.to_csv('submissionxgb.csv', index=False)'''","41ec1bda":"random_forest = RandomForestRegressor(n_estimators=1200,\n                                      max_depth=15,\n                                      min_samples_split=5,\n                                      min_samples_leaf=5,\n                                      max_features=None,\n                                      random_state=482,\n                                      oob_score=True\n                                     )\n\ny_pred = cross_val_score(random_forest, X, y, cv=5, n_jobs=-1)\ny_pred.mean()","6fb9a8e0":"random_forest.fit(X,y)\nrf_pred=random_forest.predict(test)\nprint(rmse(random_forest.predict(X),y))","9ea7c107":"models=[g_boost,random_forest,xg_boost]","9c8bcddb":"S_train, S_test = stacking(models,\n                           X_train, y_train, X_test,\n                           regression=True,\n                           mode='oof_pred_bag',\n                           metric=rmse,\n                           n_folds=5,\n                           random_state=25,\n                           verbose=2\n                          )","5ab40552":"xgb_lev2 = XGBRegressor(learning_rate=0.05, \n                        n_estimators=500,\n                        max_depth=3,\n                        n_jobs=-1,\n                        random_state=17\n                       )\n\n# Fit the 2nd level model on the output of level 1\nxgb_lev2.fit(S_train, y_train)","296e9eb2":"stacked_pred = xgb_lev2.predict(S_test)\nprint(\"RMSE of Stacked Model: {}\".format(rmse(y_test,stacked_pred)))","d1c394ec":"y1_pred_L1 = models[0].predict(test)\ny2_pred_L1 = models[1].predict(test)\ny3_pred_L1 = models[2].predict(test)\nS_test_L1 = np.c_[y1_pred_L1, y2_pred_L1, y3_pred_L1]","7a590623":"test_stacked_pred = xgb_lev2.predict(S_test_L1)","084d56cf":"submission = pd.DataFrame()\n\nsubmission['Id'] = np.array(test.index)\nsubmission['SalePrice'] = test_stacked_pred","2640a239":"submission.to_csv('submission.csv', index=False)","5c9bfafb":"submission","5f3cda51":"# Random Forest","cfb718a4":"# Filling all missing values","06dd9f53":"## Defining Evaluation Metric","8aebc767":"# XGBoost","557e9e4e":"## GBM","6667f555":"# Visualizing the Data","7ec3f740":"# Modelling","96b0fe63":"# Stacking","c7e9d893":"# Encoding Categorical Variables","db75be88":"# Finding cols with missing values"}}