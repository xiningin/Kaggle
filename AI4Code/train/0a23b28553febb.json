{"cell_type":{"b69d70a9":"code","e1420e75":"code","dc72a46f":"code","b2b9de2a":"code","244c277c":"code","c6963d1c":"code","15c05f0e":"code","d53189a7":"code","a666565a":"code","2db41eae":"code","667a9521":"code","2cc6e9b5":"code","c5bcda9b":"code","f5c231aa":"code","de21db91":"code","c51888e5":"code","7121263c":"code","e680f37e":"code","efe204d5":"code","c9fff1f0":"code","75bf468c":"code","269f29c8":"code","b2bdd2fa":"code","28174eae":"code","111335ba":"code","68a8bbc9":"code","022ea7fb":"code","51119c8e":"code","3e5055f5":"code","d6054461":"code","30a90feb":"code","fba96734":"code","fdee1fb1":"code","fced9091":"code","3dcb8dcc":"code","14b2724f":"code","135b8d8a":"code","1c320b7d":"code","4774a55b":"code","7c37fd5a":"code","c4500ac9":"code","92e26bf4":"code","3670971a":"code","3eb08243":"code","759a9bc8":"code","4d0c09a0":"code","24c455c3":"code","f05bb2f7":"code","b49729ac":"code","366902d5":"code","fc12c10d":"code","c1b33637":"code","db172815":"code","3a6fcc67":"code","d8760b06":"code","eaec7bcd":"code","c269d19a":"code","8f54c9a4":"code","96a46008":"code","f55ded28":"code","b386e2ed":"code","677f43d3":"code","a0f02ca6":"code","c404d241":"code","6dd904ab":"code","1cbbce52":"code","1c7a1d60":"code","0169af88":"code","0ea00eb6":"code","38bb388c":"code","d93a1060":"code","519f03cd":"code","0853f44a":"code","35ec6f37":"code","4e29ed17":"code","368bb27e":"code","1e6c3671":"code","a6ab93a3":"markdown","9e1433c0":"markdown","797556a4":"markdown","1304c27d":"markdown","de8435b1":"markdown","0d741ec0":"markdown","866bf7bc":"markdown","79f10326":"markdown","e1d48781":"markdown","f944d9e0":"markdown","95234867":"markdown","6b0d2c59":"markdown","921078f3":"markdown","de99ccce":"markdown","6db1a3f7":"markdown","5a5da557":"markdown","02a14025":"markdown","3cf7d614":"markdown","ee7388c7":"markdown","b3a86331":"markdown","700452de":"markdown","fffc82a1":"markdown","fe77a260":"markdown","ef848879":"markdown","58452059":"markdown","6f6a583e":"markdown","868bd8bc":"markdown","eed92fcb":"markdown","fa7fa4f3":"markdown","7d87bc48":"markdown","f6e3a9e7":"markdown","156a6fe8":"markdown","e8b1571f":"markdown","d78a8703":"markdown","da9484a7":"markdown","d3f9be9b":"markdown","ea533157":"markdown","1b79b7a9":"markdown","31dcad5c":"markdown","65f0df79":"markdown","5bf8a253":"markdown","297e0f7d":"markdown","3a93677a":"markdown","0a1ba376":"markdown","06e25d77":"markdown","56586a5b":"markdown","033f149a":"markdown","eeeb15ef":"markdown","0f60f274":"markdown","bf53501f":"markdown","5b2bfdad":"markdown","4dbc0f56":"markdown","0ccd1acb":"markdown","2365e744":"markdown","9911348e":"markdown","db6df9b7":"markdown","7fc11ea1":"markdown","df923e24":"markdown","8255b012":"markdown","d6e1787b":"markdown","028b5d63":"markdown","2c3583f2":"markdown","01b2c21c":"markdown","fdcc3b0d":"markdown","7cde0445":"markdown","4709710c":"markdown"},"source":{"b69d70a9":"# Importing all required libraries\nimport numpy as np \nimport pandas as pd\nimport seaborn as sns\nfrom scipy import stats\nfrom ml_metrics import rmse\nimport matplotlib.pyplot as plt\nimport matplotlib.ticker as mticker\nfrom matplotlib.font_manager import FontProperties\n\n# Sci-kit learn tools required:\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.preprocessing import MinMaxScaler\nfrom sklearn.model_selection import StratifiedKFold, KFold, cross_val_score\nfrom sklearn.linear_model import LogisticRegression, LinearRegression, Lasso, Ridge\nfrom sklearn.ensemble import GradientBoostingRegressor, AdaBoostRegressor, RandomForestRegressor\nfrom sklearn.neural_network import MLPRegressor\nfrom sklearn.discriminant_analysis import LinearDiscriminantAnalysis\nfrom sklearn.tree import DecisionTreeRegressor\nfrom sklearn.svm import SVR\n\n# CatBoost\nfrom catboost import CatBoostRegressor, Pool, cv\n\n# LightGBM\nfrom lightgbm import LGBMRegressor\n\n# XGBoost\nimport xgboost as xgb\nfrom xgboost import XGBClassifier, XGBRegressor, plot_importance\n\n# Pytorch \nimport torch\nfrom torch import nn, optim\nfrom torch.utils.data import TensorDataset, DataLoader\nimport torch.nn.functional as F\nfrom torch.autograd import Variable\nimport torch.utils.data as Data\n\n# Optuna\nimport optuna\nfrom optuna import Trial\nfrom optuna.samplers import TPESampler\n\n# Importing the ensemble builder\nfrom mlens.ensemble import SuperLearner\n\n# Setting the styles\nsns.set_theme('notebook')\nsns.set_style('darkgrid')\nsns.set_palette('bright')\n%matplotlib inline\nfontsize = 12\nfont = FontProperties(size=fontsize, style='italic')\npd.set_option('display.max_columns', 500)","e1420e75":"def setup_seed(seed):\n    np.random.seed(seed)                       \n    torch.manual_seed(seed)                    \n    torch.cuda.manual_seed(seed)               \n    torch.cuda.manual_seed_all(seed)           \n    torch.backends.cudnn.deterministic = True  \n\nsetup_seed(42)","dc72a46f":"df = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/train.csv')\ndf.info()","b2b9de2a":"cols_with_missing_data = df.isna().sum().sort_values(ascending=False)\ncols_with_missing_data.head(20)","244c277c":"def removing_missing_data(df=df):\n    \"\"\"\n    Function to remove missing data and drop the Id column.\n    \"\"\"\n    # removing the NaNs in our categorical variables data\n    list_to_be_replaced = ['PoolQC', 'MiscFeature', 'Alley', 'Fence', 'FireplaceQu', 'GarageCond', 'GarageType', \n                           'GarageFinish', 'GarageQual', 'BsmtFinType2', 'BsmtExposure', 'BsmtQual', 'BsmtCond', \n                           'BsmtFinType1', 'Electrical', 'MSZoning',  'Utilities', 'Functional', 'KitchenQual',\n                           'Exterior1st', 'Exterior2nd', 'SaleType']\n    \n    for i in list_to_be_replaced:\n        if i in (df.columns): df[i] = np.where(df[i].isna(), 'NA', df[i])\n        else: pass\n\n    # Masonry type has 'None' rather than 'NA'\n    df['MasVnrType'] = np.where(df['MasVnrType'].isna(), 'None', df['MasVnrType'])\n\n    # Removing missing data from the numerical variables data\n    missing_data_is_zero = ['LotFrontage', 'MasVnrArea', 'BsmtFinSF2', 'BsmtUnfSF', 'TotalBsmtSF', 'GarageCars', \n                            'GarageArea', 'BsmtFinSF1', 'BsmtFullBath', 'BsmtHalfBath']\n    for i in missing_data_is_zero:\n        if i in df.columns: df[i] = np.where(df[i].isna(), 0, df[i])\n\n    # Replacing year the garage was built with the year the house was built:\n    if 'GarageYrBlt' in df.columns: df['GarageYrBlt'] = np.where(df['GarageYrBlt'].isna(), df['YearBuilt'], df['GarageYrBlt'])\n\n    # Let's also remove the Id column while we're at it:\n    if 'Id' in df.columns: df.drop('Id', axis=1, inplace=True)\n\n# Running the function:\nremoving_missing_data(df=df)","c6963d1c":"# Taking total living area and dividing by the sum of the nunmber of rooms, bathrooms, and kitchens. \ndf[\"SqFtPerRoom\"] = df[\"GrLivArea\"] \/ (df[\"TotRmsAbvGrd\"] + df[\"FullBath\"] + df[\"HalfBath\"] + df[\"KitchenAbvGr\"])","15c05f0e":"# Creating  a list with the names of all the columns with numeric data and remove the ID column\nnum_variables = df.select_dtypes([np.number]).columns.tolist()\n\n# Calculating the correlations:\ncorrelations = df[num_variables].corr();\n# Building a large figure\nplt.figure(figsize=(5,10))\n# Creating my heatmap:\nheatmap = sns.heatmap(correlations[['SalePrice']].sort_values(by=['SalePrice'],ascending=False),\n            vmin=-1,\n            cmap='coolwarm',\n            annot=True,\n            fmt=\".1%\");\nheatmap.set_ylabel(\"Variable\", fontproperties=font)\nheatmap.set_title(\"Variables' correlation with sale price\\n\", fontsize=14, fontweight='bold');","d53189a7":"def create_z_scores(df=df):\n    \"\"\"\n    Function to create my z-scores and identify the outliers.\n    \"\"\"\n    # First we need to ensure the columns that do not contain outliers are not affected:\n    non_num_var = ['YearBuilt', 'OverallQual', 'OverallCond', 'YearBuilt', 'YearRemodAdd', \n                   'KitchenAbvGr', 'BedroomAbvGr', 'BsmtHalfBath', 'SalePrice']\n    outlier_cols = set(num_variables) - set(non_num_var)\n    outlier_cols = list(outlier_cols.copy()) \n    # now we have a list of the columns that may contain outliers\n\n    # Let's calculate the z-score for every item in the df:\n    z_score = (df[outlier_cols] - df[outlier_cols].mean())\/df[outlier_cols].std()\n    \n    # And find all the outliers by column:\n    outliers = z_score[z_score > 3].count().sort_values(ascending=False)\n\n    return outlier_cols, outliers, z_score\n\noutlier_cols, outliers, z_score = create_z_scores(df=df)","a666565a":"# Defining a function to add values to my bar graphs:\n\ndef add_value_labels(ax, labels=None, legend=None, fontsize=fontsize, label_format=\"{:,.0f}\", spacing=1):\n    \"\"\"\n    Function to add labels to the end of each bar in a bar chart.\n    - ax (matplotlib.axes.Axes): the matplotlib object containing the axes of the plot to annotate.\n    - labels (list): the labels explicitly given to the function\n    - fontsize (int): chosen fontsize of the label \n    - spacing (int): the distance between the labels and the bars\n    \"\"\"\n    \n    # For each bar: Place a label\n    for count, rect in enumerate(ax.patches):\n        # Get X and Y placement of label from rect.\n        y_value = rect.get_height()\n        x_value = rect.get_x() + rect.get_width() \/ 2\n\n        # Number of points between bar and label:\n        space = spacing\n        # Vertical alignment for positive values:\n        va = 'bottom'\n\n        # If value of bar is negative, place label below bar\n        if y_value < 0:\n            # Invert space to place label below\n            space *= -1\n            # Vertically align label at top\n            va = 'top'\n\n        if labels is None:\n            # Use Y value as label and format number\n            label = label_format.format(y_value)\n        else:\n            label = label_format.format(labels[count])\n\n        # Create annotation\n        ax.annotate(\n            label,                          # Use `label` as label\n            (x_value, y_value),             # Place label at end of the bar\n            xytext=(0, space),              # Vertically shift label by `space`\n            textcoords=\"offset points\",     # Interpret `xytext` as offset in points\n            fontsize=fontsize,              # Font size\n            ha='center',                    # Horizontally center label\n            va=va)                          # Vertically align label","2db41eae":"def draw_bar_chart(x, y, title=None, x_axis_label=None, x_tick_rotation=0, alignment=\"center\",\n                   y_axis_label=None, y_tick_labels_format='{:,.0f}', y_scaling=1, y_axis_limits=None, \n                   add_num_labels=False, num_labels=None, legend=None, label_format=\"{:,.0f}\", \n                   figsize=(20,6)\n                  ):\n    \"\"\"\n    Draws a bar chart of selected variables\n    - x (list, dict): variable column name from your df\n    - y (list, dict): target column name from your df\n    - title (str): chart title\n    - x_axis_label (str): title of x-acis\n    - x_tick_rotation (int): rotation of x-axis labels in degrees\n    - y_axis_label (str): title of y-axis\n    - y_tick_labels_format (text format): format of y-axis labels \n    - y_scaling (int): scaling of y-axis labels, i.e. '000s, millions\n    - y_axis_limits (tuple): scale of the y-axis\n    - figsize (tuple of int\/float): figure size\n    returns: seaborn bar chart axis\n    \"\"\"\n    \n    # Chart the outputs\n    fig, ax1 = plt.subplots(nrows=1, ncols=1, figsize=figsize)\n    sns.barplot(x=x, y=y)\n    # Set title\n    ax1.set_title(title, fontsize=14, fontweight='bold')\n    # Set the y-axis label\n    ax1.set_ylabel(y_axis_label, fontproperties=font)\n    # Format the y-axis labels\n    ax1.set_ylim(y_axis_limits)\n    y_tick_loc = ax1.get_yticks().tolist() # Setting the y-tick labels\n    ax1.yaxis.set_major_locator(mticker.FixedLocator(y_tick_loc))\n    ax1.set_yticklabels([y_tick_labels_format.format(x\/y_scaling) for x in y_tick_loc])\n    # Set the x-axis label\n    ax1.set_xlabel(x_axis_label, fontproperties=font)\n    # Format the x-axis labels\n    ax1.set_xticklabels(labels=[t.get_text() for t in ax1.get_xticklabels()], rotation=x_tick_rotation, horizontalalignment=alignment);\n    \n    # Add value labels above bars:\n    if add_num_labels == True:\n        add_value_labels(ax=ax1, labels=num_labels, label_format=label_format)\n    \n    # Adding a legend to explain what the numbers are, if not the y value\n    if legend is not None:\n        ax1.text(x=0.99, y=0.97, s=legend, fontsize=fontsize, fontproperties=font, \n                 ha='right', va='top', transform=ax1.transAxes)\n    return ax1","667a9521":"# Now let's graph the number of items with a z-score greater than 3 for each metric:\ndraw_bar_chart(x=outliers.keys(), y=outliers, title='Number of outliers by variable\\n', \n               x_axis_label='Variable', x_tick_rotation=45, alignment='right',\n               y_axis_label='Number of outliers', y_tick_labels_format='{:,.0f}', \n               add_num_labels=True, figsize=(20,6)\n              );","2cc6e9b5":"def replace_outliers(outlier_cols=outlier_cols, num_variables=num_variables, outliers=outliers, df=df):\n    # First up let's drop the three variables that are not useful from our dataframe...\n    drop_me = []\n    for idx, outlier in enumerate(outliers):\n        if outlier > 40:\n            drop_me.append(outliers.keys()[idx])\n    print(\"Dropping from the data:\",drop_me)\n    df.drop(drop_me, axis=1, inplace=True)\n\n    # ...and remove them from our outlier columns and our numerical variables while we're at it\n    drop_me.append('MSSubClass')\n    outlier_cols = [i for i in outlier_cols if i not in drop_me]\n    num_variables = [i for i in num_variables if i not in drop_me]\n\n    # Let's change the MSSubClass to strings so it is treated as a categorical variable:\n    df['MSSubClass'] = df.MSSubClass.astype(str)\n\n    # Let's replace all outliers (defined as having a z-score greater than 3) with the maximum non-outlier figure:\n    max_z_score = 3\n    for i in outlier_cols:\n        max_value = df[i].mean() + max_z_score*(df[i].std())\n        df.loc[df[i] > max_value, i] = max_value\n    \n    return drop_me\n\ndrop_me = replace_outliers(outliers=outliers, df=df)","c5bcda9b":"# Saving our correlations from before:\ncorrelations_old = correlations[num_variables].copy()\ncorrelations_old.drop(drop_me, axis=0, inplace=True)\n\n# Creating  a list with the names of all the columns with numerical data\nnum_variables = df.select_dtypes([np.number]).columns.tolist()\n\n# Calculating the new correlations:\ncorrelations_new = df[num_variables].corr();\n\n# Checking the difference between the two correlations:\ndelta_corr = correlations_new['SalePrice'] - correlations_old['SalePrice']\n\n# Removing elements with no change:\nto_drop = delta_corr[delta_corr == 0].index\ndelta_corr.drop(to_drop, inplace=True)\ndelta_corr.sort_values(ascending=False, inplace=True)","f5c231aa":"draw_bar_chart(x=delta_corr.index, y=delta_corr, title='Change in correlations\\n', \n               x_axis_label='Variable', x_tick_rotation=45, alignment='right',\n               y_axis_label='Change in correlation (%pts)', y_tick_labels_format='{:0.0%}', \n               add_num_labels=True, label_format=\"{:0.1%}\", figsize=(20,6)\n              );","de21db91":"# Recalculating the correlations:\ncorrelations = df[num_variables].corr();\n# Building a large figure\nplt.figure(figsize=(26,14))\n# Creating my heatmap:\nheatmap = sns.heatmap(correlations,\n            vmin=-1,\n            cmap='coolwarm',\n            annot=True,\n            fmt=\".0%\");\nheatmap.set_ylabel(\"Variable\", fontproperties=font)\nheatmap.set_title(\"Variables' correlation\\n\", fontsize=14, fontweight='bold');","c51888e5":"# Feature selection class to eliminate multicollinearity\nclass MultiCollinearityEliminator():\n    \n    # Class constructor\n    def __init__(self, df, target, threshold):\n        self.df = df\n        self.target = target\n        self.threshold = threshold\n\n    # Method to create and return the feature correlation matrix dataframe\n    def createCorrMatrix(self, include_target=False):\n        # Checking we should include the target in the correlation matrix\n        if (include_target == False):\n            df_temp = self.df.drop([self.target], axis =1)\n            \n            # Setting method to Pearson to prevent issues in case the default method for df.corr() gets changed.\n            # Setting min_period to 30 for the sample size to be statistically significant (normal) according to central limit theorem.\n            corrMatrix = df_temp.corr(method='pearson', min_periods=30).abs()\n        \n        # Target is included to create the series of feature to target correlation. - Please refer the notes under the \n        # print statement to understand why we create the series of feature to target correlation\n        elif (include_target == True):\n            corrMatrix = self.df.corr(method='pearson', min_periods=30).abs()\n        return corrMatrix\n\n    # Method to create and return the feature to target correlation matrix dataframe\n    def createCorrMatrixWithTarget(self):\n        \"\"\"After obtaining the list of correlated features, this method will help to view which variables (in the list of correlated features) \n        are least correlated with the target. This way, out of the list of correlated features, we can ensure to eliminate the feature that is \n        least correlated with the target. This not only helps to sustain the predictive power of the model but also helps in reducing model complexity.\"\"\"\n        \n        # Obtaining the correlation matrix of the dataframe (along with the target)\n        corrMatrix = self.createCorrMatrix(include_target = True)                           \n        # Creating the required dataframe, then dropping the target row and sorting by the value of correlation with target (in asceding order)\n        corrWithTarget = pd.DataFrame(corrMatrix.loc[:,self.target]).drop([self.target], axis = 0).sort_values(by = self.target)                    \n        #print(\"corrWithTarget is:\\n\",corrWithTarget, '\\n')\n        return corrWithTarget\n\n    # Method to create and return the list of correlated features\n    def createCorrelatedFeaturesList(self):\n        # Obtaining the correlation matrix of the dataframe (without the target)\n        corrMatrix = self.createCorrMatrix(include_target = False)                          \n        colCorr = []\n        # Iterating through the columns of the correlation matrix dataframe\n        for column in corrMatrix.columns:\n            # Iterating through the values (row wise) of the correlation matrix dataframe\n            for idx, row in corrMatrix.iterrows():                                            \n                if(row[column]>self.threshold) and (row[column]<1):\n                    # Adding the features that are not already in the list of correlated features\n                    if (idx not in colCorr):\n                        colCorr.append(idx)\n                    if (column not in colCorr):\n                        colCorr.append(column)\n        to_print = \"\"\n        for idx, feat in enumerate(colCorr):\n            if idx == 0: to_print += \" - \"+feat\n            else: to_print += \", \"+feat\n        if colCorr == []: print(\"No more correlated features!\")\n        else: print(\"Correlated features are:\\n\",to_print)\n        return colCorr\n\n    # Method to eliminate the least important features from the list of correlated features\n    def deleteFeatures(self, colCorr):\n        # Obtaining the feature to target correlation matrix dataframe\n        corrWithTarget = self.createCorrMatrixWithTarget()                                  \n        deleted_columns = []\n        for idx, row in corrWithTarget.iterrows():\n            #print(\"idx is: \",idx, '\\n')\n            if (idx in colCorr):\n                self.df = self.df.drop(idx, axis = 1)\n                print(\"Deleting: \"+idx+\"\\n\")\n                deleted_columns.append(idx)\n                break\n        return self.df, deleted_columns\n\n    # Method to run automatically eliminate multicollinearity\n    def autoEliminateMulticollinearity(self):\n        # Obtaining the list of correlated features\n        colCorr = self.createCorrelatedFeaturesList()                                       \n        while colCorr != []:\n            # Obtaining the dataframe after deleting the feature (from the list of correlated features) that is least correlated with the taregt\n            self.df, deleted_columns = self.deleteFeatures(colCorr)\n            # Obtaining the list of correlated features\n            colCorr = self.createCorrelatedFeaturesList()                                     \n        return self.df, deleted_columns","7121263c":"threshold = 0.65\nmce = MultiCollinearityEliminator(df=df, target='SalePrice', threshold=threshold)\ndf, deleted_columns = mce.autoEliminateMulticollinearity()","e680f37e":"# Creating  a list with the names of all the columns with numeric data and remove the ID column\nnum_variables = df.select_dtypes([np.number]).columns.tolist()\n# Recalculating the correlations:\ncorrelations = df[num_variables].corr();\n# Draw the heatmap\nplt.figure(figsize=(5,10))\nheatmap = sns.heatmap(correlations[['SalePrice']].sort_values(by=['SalePrice'],ascending=False),\n            vmin=-1,\n            cmap='coolwarm',\n            annot=True,\n            fmt=\".1%\");\nheatmap.set_ylabel(\"Variable\", fontproperties=font)\nheatmap.set_title(\"Variables' correlation with sale price\\n\", fontsize=14, fontweight='bold');","efe204d5":"# Dropping variables with correlations less than 20%\nmin_correlation = 0.2\ndelete_me = []\nfor i in range(0, len(correlations)):\n    if correlations['SalePrice'][i] < min_correlation: delete_me.append(correlations['SalePrice'].keys()[i])\nprint(\"Dropping the following variables from the data with correlation below \"+str(\"{:.0%}\".format(min_correlation))+\":\\n\",delete_me)\ndf.drop(delete_me, axis=1, inplace=True)","c9fff1f0":"def graph_overview(column, title, x_label_format='{:,.0f}', y_label_format='{:,.0f}', continuous=False, rotation=0, alignment='center'):\n    \"\"\"\n    Short function to return a count and distribution plot of the metric. \n    - column (string) is the column name of the metric to be analysed\n    - title (string) title of the graph\n    - continuous (bool) whether the variable is continuous\n    - returns two charts \n    \"\"\"\n    \n    # Format the fonts\n    font = FontProperties(size=fontsize, style='italic')\n    \n    # Set the figure up\n    fig, (ax1,ax2) = plt.subplots(ncols=2, nrows=1, figsize=(24,6))\n    \n    if continuous:\n        # Histogram\n        graph1 = sns.histplot(x=df[column], ax=ax1)\n        ax1.set_title(title+' histogram\\n', fontsize=14, fontweight='bold')\n        \n        # Scatterplot\n        slope, intercept, r_value, pv, se = stats.linregress(x=df[column], y=df['SalePrice'])\n        graph2 = sns.regplot(data=df, x=column, y='SalePrice', ci=99, ax=ax2, \n                             line_kws={\"color\": \"red\", 'label':\"y={:,.0f}x+{:,.0f}\".format(slope,intercept)}, \n                            ).legend(loc=\"best\")\n        ax2.set_title(title+' vs. sale price\\n', fontsize=14, fontweight='bold')\n        ax2.legend()\n        \n        # Setting the x-tick labels\n        x_tick_labels = ax1.get_xticks().tolist()\n        # Setting the x-tick label locations\n        ax1.xaxis.set_major_locator(mticker.FixedLocator(x_tick_labels)) \n        ax2.xaxis.set_major_locator(mticker.FixedLocator(x_tick_labels)) \n        # Setting the x-label format\n        ax1.set_xticklabels([x_label_format.format(x) for x in x_tick_labels]) \n        ax2.set_xticklabels([x_label_format.format(x) for x in x_tick_labels])\n    \n    else:\n        # Setting the order the graphs category labels\n        x_labels = df[column].value_counts().keys() \n        \n        # Countplot\n        graph1 = sns.countplot(x=df[column], ax=ax1, order=x_labels)\n        ax1.set_title(title+' count\\n', fontsize=14, fontweight='bold')\n        add_value_labels(ax1, spacing=2)  # Adds the values above the bars\n        \n        # Boxplot\n        graph2 = sns.boxplot(data=df, x=column, y='SalePrice', ax=ax2, order=x_labels)#, orient='h')\n        ax2.set_title(title+' by sale price\\n', fontsize=14, fontweight='bold')\n        \n        # Setting x-tick labels\n        ax1.set_xticklabels(labels=x_labels, rotation=rotation, horizontalalignment=alignment)\n        ax2.set_xticklabels(labels=x_labels, rotation=rotation, horizontalalignment=alignment)\n        \n    # Setting axis labels    \n    ax1.set_xlabel(title, fontproperties=font)\n    ax1.set_ylabel('Count', fontproperties=font)\n    ax2.set_xlabel(title, fontproperties=font)\n    ax2.set_ylabel('Sale price ($K)', fontproperties=font) \n    \n    # Setting y-tick labels\n    y_tick_labels_1 = ax1.get_yticks().tolist() # Setting the y-tick labels\n    ax1.yaxis.set_major_locator(mticker.FixedLocator(y_tick_labels_1)) # Setting the y-tick label locations\n    ax1.set_yticklabels([y_label_format.format(x) for x in y_tick_labels_1]) # Setting the y-label format\n    \n    y_tick_loc_2 = ax2.get_yticks().tolist() # Setting the y-tick labels\n    ax2.yaxis.set_major_locator(mticker.FixedLocator(y_tick_loc_2))\n    ax2.set_yticklabels([y_label_format.format(x\/1000) for x in y_tick_loc_2])","75bf468c":"graph_overview('HalfBath', 'Half bathrooms above grade', continuous=False)","269f29c8":"df['HalfBath'] = np.where(df['HalfBath'] == 1.8915328556074589, 1, df['HalfBath'])","b2bdd2fa":"graph_overview('LotFrontage', 'Lot frontage', continuous=True)","28174eae":"df.drop('LotFrontage', axis=1, inplace=True)","111335ba":"graph_overview('BsmtUnfSF', 'Unfinished basement (sqft)', continuous=True)","68a8bbc9":"df.drop('BsmtUnfSF', axis=1, inplace=True)","022ea7fb":"graph_overview('WoodDeckSF', 'Wooden deck (sqft)', continuous=True)","51119c8e":"graph_overview('OpenPorchSF', 'Open porch (sqft)', continuous=True)","3e5055f5":"def remove_correlated_weak_predictors(df=df, target='SalePrice', strong_pred_level=0.5):\n    \"\"\"\n    Function to remove weak predictive variables which have greater correlation with strong predictors than target\n    - df (dataframe): dataframe object\n    - target (str): target variable\n    - strong_pred_level (float): level of correlation at which a variable is defined as a strong predictor\n    returns: list of strong predictors\n    \"\"\"\n    \n    # Selecting the strong predictors:\n    strong_predictors = []\n    for idx, var in enumerate(correlations[target]):\n        if var >= strong_pred_level: strong_predictors.append(correlations[target].keys()[idx])\n    strong_predictors.remove(target)\n    print(\"Strong predictors are:\", strong_predictors)\n\n    # Re-calculating our numerical variables:\n    num_variables = df.select_dtypes([np.number]).columns.tolist()\n\n    # Checking which of the numerical variables have correlations with the strong predictors higher than sale price:\n    for variable in num_variables:\n        # What is the variable's correlation with sale price?\n        sale_price_corr = correlations.SalePrice[variable]\n        #print(variable+\"'s correlation with sale price is:\\t\"+str(\"{:.0%}\".format(sale_price_corr)))\n\n        # Calculating the variables correlation with each of the strong predictors\n        strong_var_predictor_corrs = []\n        for strong_predictor in strong_predictors:\n            if variable in strong_predictors: pass\n            else: strong_var_predictor_corrs.append(correlations[variable][strong_predictor])\n\n        # Removing variables where correlation with a strong predictor is higher than with sale price\n        for idx, svp in enumerate(strong_var_predictor_corrs):\n            if sale_price_corr < svp:\n                output1 = str(\"{:.0%}\".format(sale_price_corr))\n                output2 = str(\"{:.0%}\".format(svp))\n                output3 = strong_predictors[idx]\n                print(\"Dropping \"+variable+\" as correlation of \"+output1\n                      +\" with target (\"+target+\") is lower than \"+output2\n                      +\" correlation with strong predictor, \"+output3)\n                if variable in df.columns: df.drop(variable, axis=1, inplace=True)\n    \n    return strong_predictors","d6054461":"strong_predictors = remove_correlated_weak_predictors(df=df, target='SalePrice', strong_pred_level=0.5);","30a90feb":"# Adding sale price back in and recalculating the correlations:\ncorrelations = df.corr();\n# Draw the heatmap\nplt.figure(figsize=(5,6))\nheatmap = sns.heatmap(correlations[['SalePrice']].sort_values(by=['SalePrice'],ascending=False),\n            vmin=-1,\n            cmap='coolwarm',\n            annot=True,\n            fmt=\".1%\");\nheatmap.set_ylabel(\"Variable\", fontproperties=font)\nheatmap.set_title(\"Variables' correlation with sale price\\n\", fontsize=14, fontweight='bold');","fba96734":"num_variables = df.select_dtypes([np.number]).columns.tolist()\nnum_variables.remove('SalePrice')\nprint(\"There are \"+str(len(num_variables))+\" numerical variables. These are:\",num_variables)","fdee1fb1":"cat_variables = df.columns.tolist()\ncat_variables = [i for i in cat_variables if i not in num_variables]\ncat_variables.remove('SalePrice')\nprint(\"Number of categorical variables: \"+str(len(cat_variables)))","fced9091":"# Create empty lists\ncat_variables_range = []\nrange_low = []\n\n# Set number of occurences required to be included in the analysis below:\nmin_occurences = 100\n\n# Add the difference between the dearest and cheapest groups of variables to our empty list\nfor i in cat_variables:\n    # Create a series with the category grouped by median sale price\n    group_prices = df.groupby(i)['SalePrice'].median().sort_values()\n    \n    # Remove the categories with fewer than x occurences \n    to_drop = []\n    for count, j in enumerate(group_prices):\n        item = group_prices.keys()[count]\n        count = len(df[df[i]==item])\n        if count < min_occurences:\n            to_drop.append(item)\n    \n    # Now dropping all the items\n    group_prices.drop(labels=to_drop, axis=0, inplace=True)\n    \n    # Find the range in price between the highest and lowest price:\n    if len(group_prices)<2:\n        price_range = 0\n        range_low.append(0)\n    else:\n        price_range = group_prices[-1] - group_prices[0]\n        # Find the lowest number of properties in the highest or lowest priced category\n        low = float('inf')\n        check = [0,-1]\n        for k in check:\n            count = len(df[df[i]==group_prices.keys()[k]])\n            if count < low:\n                low = count\n        range_low.append(low)\n    \n    # Add to our lists:\n    cat_variables_range.append(price_range)\n\n# Create a dataframe with the categorical names:\ncat_var_df = pd.DataFrame({'Variable': cat_variables,'SalePriceRange': cat_variables_range, 'Low':range_low})\ncat_var_df.sort_values(by='SalePriceRange', axis=0, ascending=False, inplace=True)\ncat_var_df.reset_index(inplace=True, drop=True)","3dcb8dcc":"draw_bar_chart(x = cat_var_df['Variable'], y=cat_var_df['SalePriceRange'], title=\"Range of sale prices by categorical variable\\n\", \n               x_axis_label=\"\\nCategory\", x_tick_rotation=90, y_axis_label=\"Sale price range ($K)\", y_scaling=1000,\n               add_num_labels=True, num_labels=cat_var_df['Low'], legend='NB: Annotations above bars refer to\\n lowest number of occurences in range'\n              );","14b2724f":"def remove_low_occurances(df=df, low_occurence=50, cat_variables=cat_variables):\n    # Defining a function to replace the variables with few occurences as \n    # 'Other', with the exception of neighbourhood\n    cat_variables.remove('Neighborhood')\n    for i in cat_variables:\n        variable_occ = df[i].value_counts()\n        for j, k in zip(variable_occ, variable_occ.keys()):\n            if j < low_occurence:\n                df[i] = np.where(df[i] == k, 'Other', df[i])\n    cat_variables.append('Neighborhood')\n    \n    # Remove variables without more than a single item with more than the required number of occurences:\n    var_to_remove = cat_var_df.loc[cat_var_df['Low'] < min_occurences, 'Variable'].iloc[:]\n    df.drop(labels=var_to_remove, axis=1, inplace=True)\n    print(\"Variables to be removed are:\\n\",var_to_remove)\n    return df, cat_variables, var_to_remove\n\ndf, cat_variables, var_to_remove = remove_low_occurances(df=df, low_occurence=50, cat_variables=cat_variables)","135b8d8a":"top_cat_var = cat_var_df[cat_var_df['SalePriceRange']>100000]\ntop_cat_var = top_cat_var['Variable'].tolist()\nfor variable in top_cat_var:\n    if variable == 'Neighborhood': graph_overview(variable, variable, rotation=45, alignment='right')\n    else: graph_overview(variable, variable)","1c320b7d":"med_cat_var = cat_var_df[cat_var_df['SalePriceRange']>50000]\nmed_cat_var = med_cat_var['Variable'].tolist()\nmed_cat_var = [x for x in med_cat_var if x not in top_cat_var]\nfor variable in med_cat_var:\n    if variable == 'Neighborhood': graph_overview(variable, variable, rotation=45, alignment='right')\n    else: graph_overview(variable, variable)","4774a55b":"cat_variables = cat_var_df[cat_var_df['SalePriceRange']>50000]\ncat_variables = cat_variables['Variable'].tolist()\nprint(\"Number of categorical variables is:\",len(cat_variables))","7c37fd5a":"# Setting up the initial charts:\nfig, (ax1, ax2) = plt.subplots(nrows=1, ncols=2, figsize=(24, 6))  # sharex=True\n\ngraph1 = sns.histplot(x=df['SalePrice'], ax=ax1)\ngraph2 = sns.histplot(x=df['SalePrice'], ax=ax2, log_scale=True)\n\n# Setting up axis 1\nax1.set_title(\"Sale price distribution\\n\", fontsize=14, fontweight='bold')\nax1.set_xlabel(\"Sale price ($K)\", fontproperties=font)\nax1.set_ylabel('Count', fontproperties=font);\nx_tick_labels_1 = ax1.get_xticks().tolist() # Setting the y-tick labels\nax1.xaxis.set_major_locator(mticker.FixedLocator(x_tick_labels_1)) # Setting the x-tick label locations\nax1.set_xticklabels([\"{:,.0f}\".format(x\/1000) for x in x_tick_labels_1]); # Setting the x-label format\n\n# Setting up axis 2\nax2.set_title(\"Sale price distribution - log transformed\\n\", fontsize=14, fontweight='bold')\nax2.set_xlabel(\"Sale price - log transformed ($K)\", fontproperties=font)\nax2.set_ylabel('Count', fontproperties=font);\nx_tick_labels_2 = ax2.get_xticks().tolist() # Setting the y-tick labels\nax2.xaxis.set_major_locator(mticker.FixedLocator(x_tick_labels_2)) # Setting the x-tick label locations\nax2.set_xticklabels([\"{:,.0f}\".format(x\/1000) for x in x_tick_labels_2]); # Setting the x-label format","c4500ac9":"log_transform_target = False\nnn_log_transform_target = False","92e26bf4":"def scale_data_and_define_features(df=df, scale_data=True, incl_target=True, \n                                   num_variables=num_variables, cat_variables=cat_variables):\n    \"\"\"\n    Function to create our variables for training and testing via scaling\n    \"\"\"\n    # Scaling the data\n    scaler = MinMaxScaler()\n\n    # Defining our model features:\n    model_features = [*num_variables, *cat_variables]\n\n    # Find variables not in model_features:\n    to_drop = []\n    for column in df.columns:\n        if column not in model_features: to_drop.append(column)\n    \n    # Remove sale price and then drop from the df\n    if incl_target: to_drop.remove('SalePrice')\n    df.drop(to_drop, axis=1, inplace=True)\n\n    # Defining our target:\n    if incl_target: \n        if log_transform_target and nn_log_transform_target: \n            y = np.log(df['SalePrice'])\n            y_nn = np.log(df['SalePrice'])\n        elif nn_log_transform_target: \n            y = df['SalePrice']\n            y_nn = np.log(df['SalePrice'])\n        else: y = y_nn = df['SalePrice']\n\n    # Scaling the feature data:\n    if scale_data:\n        X_num = pd.DataFrame(data=scaler.fit_transform(df[num_variables]), columns=num_variables)\n        X = pd.concat([X_num, df[cat_variables]], axis=1, join=\"outer\", ignore_index=False)\n    else:\n        X = df[model_features]\n    \n    if incl_target: return X, y, y_nn, df, model_features\n    else: return X, df, model_features\n\nX, y, y_nn, df, model_features = scale_data_and_define_features(df=df, scale_data=True)","3670971a":"# Defining our random state:\nrandom_state = 42","3eb08243":"# Setting our train:test split\ntest_size = 0.3\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=test_size, \n                                                  random_state=random_state)\n#if nn_log_transform_target: \nX_train, X_val, y_train_nn, y_val_nn = train_test_split(X, y_nn, test_size=test_size, \n                                                        random_state=random_state)","759a9bc8":"# One hot encoding:\nX_ohe = pd.get_dummies(X.copy(), columns = cat_variables, prefix = cat_variables)\nX_train_ohe = pd.get_dummies(X_train.copy(), columns = cat_variables, prefix = cat_variables)\nX_val_ohe = pd.get_dummies(X_val.copy(), columns = cat_variables, prefix = cat_variables)","4d0c09a0":"# 1. Cross validate model with Kfolds\nfolds = 5\nkfold = KFold(n_splits=folds, shuffle=True, random_state=random_state)\n\n# 2. Switches\nmodels_dict = {\"CatBoost\": True, \n               \"XGBoost\": True, \n               \"LightGBM\": True, \n               \"GradientBoosting\": True, \n               \"MLP\": True, \n               \"LDA\": True, \n               \"AdaBoost\": True, \n               \"LogReg\": True, \n               \"SVR\": True, \n               \"Ridge\": True, \n               \"Lasso\": True, \n               \"RandomForest\": True,\n              }\n\n# 3. List of accuracies\naccuracies = []\nregressors = {}\nmodels = {}\nmodel_list = []\n\n# 4. Trials list\ntrials_dict = {\"CatBoost\": 50, \"XGBoost\": 100, \"LightGBM\": 500, \"GradientBoosting\": 100, \"MLP\": 100, \"LDA\": 100, \n               \"AdaBoost\": 100, \"LogReg\": 50, \"SVR\": 500, \"Ridge\": 100, \"Lasso\": 100, \"RandomForest\": 50,\n               \"ensemble\": 50, \"Pytorch\": 10}\n\n# 5. Turning off the warnings\noptuna.logging.set_verbosity(optuna.logging.WARNING)","24c455c3":"# Switch for CatBoost using OHE or categorical features:\ncb_ohe = True\n\n# Setting the pools for training and testing\nif cb_ohe: \n    pool_train = Pool(X_train_ohe, y_train, cat_features = None)\n    pool_val = Pool(X_val_ohe, y_val, cat_features = None)\n    X_val_cb = X_val_ohe\nelse:\n    pool_train = Pool(X_train, y_train, cat_features = cat_variables)\n    pool_val = Pool(X_val, y_val, cat_features = cat_variables)\n    X_val_cb = X_val\n\n# Setting the hyperparameters\ncb_params = {\n    \"iterations\": 10000,\n    \"learning_rate\": 0.01,\n    \"loss_function\": 'RMSE',\n    \"eval_metric\": 'RMSE',\n    \"random_state\": random_state,\n}\n\ncb_fit_params = {\n    \"eval_set\": pool_val,\n    \"plot\": False,\n    \"use_best_model\": True,\n    \"verbose\": False,\n    \"early_stopping_rounds\": 200,\n}","f05bb2f7":"def cb_tune(trial):\n    # Setting the hyperparameters\n    cb_params = {\n        \"learning_rate\": trial.suggest_uniform('learning_rate', 0.0000001, 0.1),\n        \"depth\": trial.suggest_int(\"depth\", 2, 8),\n        \"l2_leaf_reg\": trial.suggest_int(\"l2_leaf_reg\", 1, 9),\n        \"min_child_samples\": trial.suggest_int(\"min_child_samples\", 0, 9),\n        \"iterations\": 10000,\n        \"random_state\": random_state,\n        \"loss_function\": 'RMSE',\n    }\n    \n    # Setting up the model, fitting it and making our predictions:\n    cb_model = CatBoostRegressor(**cb_params)\n    cb_model.fit(pool_train, **cb_fit_params)\n    cb_pred = cb_model.predict(X_val_cb)    \n    if log_transform_target: cb_acc = rmse(actual=np.exp(y_val), predicted=np.exp(cb_pred))\n    else: cb_acc = rmse(actual=y_val, predicted=cb_pred)\n    return cb_acc\n\n# Create and optimise the study\ncb_study = optuna.create_study()\nif models_dict['CatBoost']: \n    cb_study.optimize(cb_tune, n_trials=trials_dict['CatBoost'], show_progress_bar=True)\n    cb_acc = cb_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'\n          .format(cb_study.best_trial.value, cb_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    cb_params = cb_study.best_params\n    cb_model = CatBoostRegressor(**cb_params, random_state=random_state, verbose=False)\n    cb_model.fit(pool_train, **cb_fit_params)\n    cb_pred = cb_model.predict(X_val_cb)\n\n    # Calculating model score:\n    if log_transform_target: cb_acc = rmse(actual=np.exp(y_val), predicted = np.exp(cb_pred))\n    else: cb_acc = rmse(actual=y_val, predicted = cb_pred)\n    print(\"Tuned CatBoost model RMSE is: $\"+str(\"{:,.0f}\".format(cb_acc)))\n    print(\"Tuned CatBoost model percentage error is: \"+str(\"{:,.5f}\".format(cb_acc\/y_val.mean())))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(cb_acc)\n    regressors[\"CatBoost\"] = CatBoostRegressor(**cb_params, random_state=random_state, verbose=False)\n    models[\"CatBoost\"] = cb_model\n    model_list.append(cb_model)","b49729ac":"def lgbm_tune(trial):\n    # Setting the hyperparameters\n    lgbm_params = {\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n        \"num_leaves\": trial.suggest_int(\"num_leaves\", 2, 3000),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 10, 1000),\n        \"learning_rate\": trial.suggest_uniform('learning_rate', 0.0000001, 0.1),\n        \"min_child_samples\": trial.suggest_int('min_child_samples', 3, 200),\n        \"random_state\": random_state,\n        \"verbose\": -1,\n    }\n    \n    # Setting the fitting parameters\n    lgbm_fit_params = {\n        \"X\": X_train_ohe, \n        \"y\": y_train, \n        \"eval_set\": (X_val_ohe, y_val), \n        \"eval_metric\": \"rmse\",\n        \"verbose\": -1,\n    }\n    \n    # Setting up our model\n    lgbm_model = LGBMRegressor(**lgbm_params)\n    \n    # Setting up the model, fitting it and making our predictions:\n    lgbm_model.fit(**lgbm_fit_params)\n    lgbm_pred = lgbm_model.predict(X_val_ohe)\n    if log_transform_target: lgbm_acc = rmse(actual = np.exp(y_val), predicted = np.exp(lgbm_pred))\n    else: lgbm_acc = rmse(actual = y_val, predicted = lgbm_pred)\n    \n    return lgbm_acc\n\nif models_dict['LightGBM']: \n    # Create and optimise the study\n    optuna.logging.set_verbosity(optuna.logging.WARNING)\n    lgbm_study = optuna.create_study()\n    lgbm_study.optimize(lgbm_tune, n_trials=trials_dict[\"LightGBM\"], show_progress_bar=True)\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'\n          .format(lgbm_study.best_trial.value, lgbm_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    lgbm_params = lgbm_study.best_params\n    lgbm_model = LGBMRegressor(**lgbm_params, random_state=random_state)\n    lgbm_model.fit(X_train_ohe, y_train)\n    lgbm_pred = lgbm_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: lgbm_acc = rmse(actual=np.exp(y_val), predicted=np.exp(lgbm_pred))\n    else: lgbm_acc = rmse(actual=y_val, predicted=lgbm_pred)\n    print(\"Tuned LightGBM model RMSE is: $\"+str(\"{:,.0f}\".format(lgbm_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(lgbm_acc)\n    regressors[\"LightGBM\"] = LGBMRegressor(**lgbm_params)\n    models[\"LightGBM\"] = lgbm_model\n    model_list.append(lgbm_model)","366902d5":"# Setting up the model:\ndef xgb_tune(trial):\n    # List of hyperparameters to try:\n    boosting_list = ['gbtree', 'gblinear']\n    \n    xgb_params = {\n        #\"boosting_type\": trial.suggest.categorical(\"boosting_type\", boosting_list)\n        \"n_estimators\": trial.suggest_int('n_estimators', 100, 2000),\n        \"max_depth\": trial.suggest_int('max_depth', 2, 15),\n        \"reg_alpha\": trial.suggest_int('reg_alpha', 0, 5),\n        \"reg_lambda\": trial.suggest_int('reg_lambda', 0, 5), \n        \"gamma\": trial.suggest_int('gamma', 0, 5),\n        \"learning_rate\": trial.suggest_loguniform('learning_rate', 0.01, 0.5),\n        \"colsample_bytree\": trial.suggest_discrete_uniform('colsample_bytree', 0.1, 1, 0.01),\n        \"subsample\": trial.suggest_discrete_uniform('subsample', 0.6, 0.9, 0.1),\n        \"eval_metric\": 'rmse',\n        \"objective\": 'reg:squarederror',\n        \"use_label_encoder\": False, \n        \"random_state\": random_state,\n    }  \n    \n    # Set up the model:\n    xgb_model = XGBRegressor(**xgb_params)\n    xgb_model.fit(X_train_ohe, y_train)\n    xgb_pred = xgb_model.predict(X_val_ohe)\n    \n    # Calculate the accuracy\n    if log_transform_target: xgb_acc = rmse(actual = np.exp(y_val), predicted = np.exp(xgb_pred))\n    else: xgb_acc = rmse(actual = y_val, predicted = xgb_pred)\n    \n    return xgb_acc\n\nif models_dict['XGBoost']: \n    # Create and optimise the study:\n    optuna.logging.set_verbosity(optuna.logging.WARNING)\n    xgb_study = optuna.create_study()\n    xgb_study.optimize(xgb_tune, n_trials=trials_dict['XGBoost'], show_progress_bar=True)\n    xgb_acc = xgb_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'.format(\n        xgb_study.best_trial.value, xgb_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    xgb_params = xgb_study.best_params\n    xgb_model = XGBRegressor(**xgb_params, random_state=random_state)\n    xgb_model.fit(X_train_ohe, y_train)\n    xgb_pred = xgb_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: xgb_acc = rmse(actual=np.exp(y_val), predicted=np.exp(xgb_pred))\n    else: xgb_acc = rmse(actual=y_val, predicted=xgb_pred)\n    print(\"Tuned XGBoost model RMSE is: $\"+str(\"{:,.0f}\".format(xgb_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(xgb_acc)\n    regressors[\"XGBoost\"] = XGBRegressor(**xgb_params)\n    models[\"XGBoost\"] = xgb_model\n    model_list.append(xgb_model)","fc12c10d":"def gbr_tune(trial):\n    # Setting our hyperparameters\n    gbr_params = {\n        \"max_depth\": trial.suggest_int(\"max_depth\", 2, 10),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 1, 300),\n        \"learning_rate\": trial.suggest_uniform('learning_rate', 0.00001, 1),\n        \"min_samples_leaf\": trial.suggest_int('min_samples_leaf', 1, 19, 3),\n        \"max_features\": trial.suggest_uniform('max_features', 0.1, 1.0),\n        \"random_state\": random_state\n    }\n    \n    # Setting up our model:\n    gbr = GradientBoostingRegressor(**gbr_params)\n    gbr.fit(X_train_ohe, y_train)\n    gbr_pred = gbr.predict(X_val_ohe)\n\n    # Calculating model scores:\n    if log_transform_target: gbr_acc = rmse(actual = np.exp(y_val), predicted = np.exp(gbr_pred))\n    else: gbr_acc = rmse(actual = y_val, predicted = gbr_pred)\n\n    return gbr_acc\n\nif models_dict['GradientBoosting']: \n    # Turning off the warnings\n    optuna.logging.set_verbosity(optuna.logging.WARNING)\n    # Create and optimise the study\n    gbr_study = optuna.create_study()\n    gbr_study.optimize(gbr_tune, n_trials=trials_dict['GradientBoosting'], show_progress_bar=True)\n    gbr_acc = gbr_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'.format(\n        gbr_study.best_trial.value, gbr_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    gbr_params = gbr_study.best_params\n    gbr_model = GradientBoostingRegressor(**gbr_params, random_state=random_state)\n    gbr_model.fit(X_train_ohe, y_train)\n    gbr_pred = gbr_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: gbr_acc = rmse(actual=np.exp(y_val), predicted=np.exp(gbr_pred))\n    else: gbr_acc = rmse(actual=y_val, predicted=gbr_pred)\n    print(\"Tuned Gradient Boosting model RMSE is: $\"+str(\"{:,.0f}\".format(gbr_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(gbr_acc)\n    regressors[\"GradientBoosting\"] = GradientBoostingRegressor(**gbr_params)\n    models[\"GradientBoosting\"] = gbr_model\n    model_list.append(gbr_model)","c1b33637":"def mlp_tune(trial):\n    mlp_params = {\n        \"learning_rate_init\": trial.suggest_uniform(\"learning_rate_init\", 0.01, 0.5),\n        \"hidden_layer_sizes\": trial.suggest_int('hidden_layer_sizes', 8, 126),\n        \"max_iter\": trial.suggest_int('max_iter', 1000, 5000),\n        \"random_state\": random_state,\n    }\n    \n    # Setting up the regressor:\n    mlp = MLPRegressor(**mlp_params)\n    mlp.fit(X_train_ohe, y_train)\n    mlp_pred = mlp.predict(X_val_ohe)\n\n    # Calculating model scores:\n    if log_transform_target: mlp_acc = rmse(actual = np.exp(y_val), predicted = np.exp(mlp_pred))\n    else: mlp_acc = rmse(actual = y_val, predicted = mlp_pred)\n\n    return mlp_acc\n\nif models_dict['MLP']: \n    # Create and optimise the study\n    mlp_study = optuna.create_study()\n    mlp_study.optimize(mlp_tune, n_trials=trials_dict['MLP'], show_progress_bar=True)\n    mlp_acc = mlp_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'.format(mlp_study.best_trial.value, mlp_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    mlp_params = mlp_study.best_params\n    mlp_model = MLPRegressor(**mlp_params, random_state=random_state)\n    mlp_model.fit(X_train_ohe, y_train)\n    mlp_pred = mlp_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: mlp_acc = rmse(actual=np.exp(y_val), predicted=np.exp(mlp_pred))\n    else: mlp_acc = rmse(actual=y_val, predicted=mlp_pred)\n    print(\"Tuned MLP model RMSE is: $\"+str(\"{:,.0f}\".format(mlp_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(mlp_acc)\n    regressors[\"MLP\"] = MLPRegressor(**mlp_params)\n    models[\"MLP\"] = mlp_model\n    model_list.append(mlp_model)","db172815":"if models_dict['LDA']: \n    # Instantiate and fit our model\n    lda_model = LinearDiscriminantAnalysis()\n    lda_model.fit(X_train_ohe, y_train)\n    lda_pred = lda_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: lda_acc = rmse(actual=np.exp(y_val), predicted=np.exp(lda_pred))\n    else: lda_acc = rmse(actual=y_val, predicted=lda_pred)\n    print(\"LDA model RMSE is: $\"+str(\"{:,.0f}\".format(lda_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(lda_acc)\n    regressors[\"LDA\"] = LinearDiscriminantAnalysis()\n    models[\"LDA\"] = lda_model\n    model_list.append(lda_model)","3a6fcc67":"if models_dict['LogReg']: \n    # Instantiate the model\n    logreg_model = LogisticRegression(random_state=random_state, max_iter=2000)\n    logreg_model.fit(X_train_ohe, y_train)\n    logreg_pred = logreg_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: logreg_acc = rmse(actual=np.exp(y_val), predicted=np.exp(logreg_pred))\n    else: logreg_acc = rmse(actual=y_val, predicted=logreg_pred)\n    print(\"Logistic regression model RMSE is: $\"+str(\"{:,.0f}\".format(logreg_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(logreg_acc)\n    regressors[\"LogReg\"] = LogisticRegression(random_state=random_state, max_iter=2000)\n    models[\"LogReg\"] = logreg_model\n    model_list.append(logreg_model)","d8760b06":"def ada_tune(trial):\n    # Setting our hyperparameters\n    ada_losses = ['linear', 'square', 'exponential']\n    ada_params = {\n        \"loss\": trial.suggest_categorical(\"loss\", ada_losses),\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 25, 100),\n        \"learning_rate\": trial.suggest_uniform(\"learning_rate\", 0.01, 1),\n        \"random_state\": random_state,\n    }\n    \n    ada_model = AdaBoostRegressor(**ada_params)\n    ada_model.fit(X_train_ohe, y_train)\n    ada_pred = ada_model.predict(X_val_ohe)\n    ada_acc = rmse(y_val, ada_pred)\n    return ada_acc\n\nif models_dict['AdaBoost']: \n    # Create and optimise the study\n    ada_study = optuna.create_study()\n    ada_study.optimize(ada_tune, n_trials=trials_dict['AdaBoost'], show_progress_bar=True)\n    ada_acc = ada_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'.format(\n        ada_study.best_trial.value, ada_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    ada_params = ada_study.best_params\n    ada_model = AdaBoostRegressor(**ada_params, random_state=random_state)\n    ada_model.fit(X_train_ohe, y_train)\n    ada_pred = ada_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: ada_acc = rmse(actual=np.exp(y_val), predicted=np.exp(ada_pred))\n    else: ada_acc = rmse(actual=y_val, predicted=ada_pred)\n    print(\"Tuned AdaBoost model RMSE is: $\"+str(\"{:,.0f}\".format(ada_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(ada_acc)\n    regressors[\"AdaBoost\"] = AdaBoostRegressor(**ada_params)\n    models[\"AdaBoost\"] = ada_model\n    model_list.append(ada_model)","eaec7bcd":"def svr_tune(trial):\n    # Setting our hyperparameters:\n    svr_kernels = [\"linear\", \"poly\", \"rbf\", \"sigmoid\"]\n    \n    svr_params = {\n        \"kernel\": trial.suggest_categorical(\"kernel\", svr_kernels),\n        \"shrinking\": trial.suggest_categorical(\"shrinking\", [True, False]),\n        \"degree\": trial.suggest_int(\"degree\", 2, 5),\n        \"max_iter\": trial.suggest_int(\"max_iter\", 1000, 5000),\n        \"epsilon\": trial.suggest_uniform(\"epsilon\", 0.01, 1),\n        \"tol\": trial.suggest_uniform(\"tol\", 0.01, 500),\n        \"C\": trial.suggest_uniform(\"C\", 0.5, 10),\n        \"verbose\": False, \n    }\n    \n    # Setting up the regressor:\n    svr = SVR(**svr_params)\n    svr.fit(X_train_ohe, y_train)\n    svr_pred = svr.predict(X_val_ohe)\n\n    # Calculate the scores\n    svr_acc = rmse(y_val, svr_pred)\n\n    return svr_acc\n\nif models_dict['SVR']: \n    # Create and optimise the study\n    svr_study = optuna.create_study()\n    svr_study.optimize(svr_tune, n_trials=trials_dict['SVR'], show_progress_bar=True)\n    svr_acc = svr_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'.format(\n        svr_study.best_trial.value, svr_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    svr_params = svr_study.best_params\n    svr_model = SVR(**svr_params)\n    svr_model.fit(X_train_ohe, y_train)\n    svr_pred = svr_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: svr_acc = rmse(actual=np.exp(y_val), predicted=np.exp(svr_pred))\n    else: svr_acc = rmse(actual=y_val, predicted=svr_pred)\n    print(\"Tuned SVR model RMSE is: $\"+str(\"{:,.0f}\".format(svr_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(svr_acc)\n    regressors[\"SVR\"] = SVR(**svr_params)\n    models[\"SVR\"] = svr_model\n    model_list.append(svr_model)","c269d19a":"def ridge_tune(trial):\n    ridge_params = {\n        \"alpha\": trial.suggest_float(\"alpha\", 0.001, 1),\n        \"tol\": trial.suggest_float(\"tol\", 0.1, 0.9),\n        \"random_state\": random_state,\n    }\n    \n    # Setting up the regressor:\n    ridge = Ridge(**ridge_params)\n    ridge.fit(X_train_ohe, y_train)\n    ridge_pred = ridge.predict(X_val_ohe)\n\n    # Calculate the scores\n    ridge_acc = rmse(y_val, ridge_pred)\n\n    return ridge_acc\n\nif models_dict['Ridge']: \n    # Create and optimise the study\n    ridge_study = optuna.create_study()\n    ridge_study.optimize(ridge_tune, n_trials=trials_dict['Ridge'], show_progress_bar=True)\n    ridge_acc = ridge_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'.format(\n        ridge_study.best_trial.value, ridge_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    ridge_params = ridge_study.best_params\n    ridge_model = Ridge(**ridge_params)\n    ridge_model.fit(X_train_ohe, y_train)\n    ridge_pred = ridge_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: ridge_acc = rmse(actual=np.exp(y_val), predicted=np.exp(ridge_pred))\n    else: ridge_acc = rmse(actual=y_val, predicted=ridge_pred)\n    print(\"Tuned Ridge model RMSE is: $\"+str(\"{:,.0f}\".format(ridge_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(ridge_acc)\n    regressors[\"Ridge\"] = Ridge(**ridge_params)\n    models[\"Ridge\"] = ridge_model\n    model_list.append(ridge_model)","8f54c9a4":"def lasso_tune(trial):\n    lasso_params = {\n        \"alpha\": trial.suggest_float(\"alpha\", 0.01, 1),\n        \"max_iter\": trial.suggest_int(\"max_iter\", 10000, 50000),\n        \"random_state\": random_state,\n    }\n    \n    # Setting up the regressor:\n    lasso = Lasso(**lasso_params)\n    lasso.fit(X_train_ohe, y_train)\n    lasso_pred = lasso.predict(X_val_ohe)\n\n    # Calculate the scores\n    lasso_acc = rmse(y_val, lasso_pred)\n\n    return lasso_acc\n\nif models_dict['Lasso']: \n    # Create and optimise the study\n    lasso_study = optuna.create_study()\n    lasso_study.optimize(lasso_tune, n_trials=trials_dict['Lasso'], show_progress_bar=True)\n    lasso_acc = lasso_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'.format(\n        lasso_study.best_trial.value, lasso_study.best_trial.params)+\"\\n\")\n    \n    # Setting up the regressor:\n    lasso_params = lasso_study.best_params\n    lasso_model = Lasso(**lasso_params)\n    lasso_model.fit(X_train_ohe, y_train)\n    lasso_pred = lasso_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: lasso_acc = rmse(actual=np.exp(y_val), predicted=np.exp(lasso_pred))\n    else: lasso_acc = rmse(actual=y_val, predicted=lasso_pred)\n    print(\"Tuned Lasso model RMSE is: $\"+str(\"{:,.0f}\".format(lasso_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(lasso_acc)\n    regressors[\"Lasso\"] = Lasso(**lasso_params)\n    models[\"Lasso\"] = lasso_model\n    model_list.append(lasso_model)","96a46008":"def rf_tune(trial):\n    rf_params = {\n        \"n_estimators\": trial.suggest_int(\"n_estimators\", 50, 200),\n        \"max_depth\": trial.suggest_int(\"max_depth\", 5, 12),\n        \"min_samples_leaf\": trial.suggest_int(\"min_samples_leaf\", 3, 6),\n        \"max_features\": trial.suggest_int(\"max_features\", 5, 126),\n        \"random_state\": random_state,\n    }\n    \n    # Setting up the regressor:\n    rf = RandomForestRegressor(**rf_params)\n    rf.fit(X_train_ohe, y_train)\n    rf_pred = rf.predict(X_val_ohe)\n\n    # Calculate the scores\n    rf_acc = rmse(y_val, rf_pred)\n\n    return rf_acc\n\nif models_dict['RandomForest']: \n    # Create and optimise the study\n    rf_study = optuna.create_study()\n    rf_study.optimize(rf_tune, n_trials=trials_dict['Lasso'], show_progress_bar=True)\n    rf_acc = rf_study.best_trial.value\n    print('Best trial score: ${:,.0f}\\nwith parameters: {}'.format(\n        rf_study.best_trial.value, rf_study.best_trial.params)+\"\\n\")\n    # Setting up the regressor:\n    rf_params = rf_study.best_params\n    rf_model = RandomForestRegressor(**rf_params)\n    rf_model.fit(X_train_ohe, y_train)\n    rf_pred = rf_model.predict(X_val_ohe)\n\n    # Calculating model score:\n    if log_transform_target: rf_acc = rmse(actual=np.exp(y_val), predicted=np.exp(rf_pred))\n    else: rf_acc = rmse(actual=y_val, predicted=rf_pred)\n    print(\"Tuned random forest model RMSE is: $\"+str(\"{:,.0f}\".format(rf_acc)))\n    \n    # Adding the scores and regressions to our lists:\n    accuracies.append(rf_acc)\n    regressors[\"RandomForest\"] = RandomForestRegressor(**rf_params)\n    models[\"RandomForest\"] = rf_model\n    model_list.append(rf_model)","f55ded28":"# Models to compare:\nmodel_names = []\nfor model, boolean in models_dict.items():\n    if boolean: model_names.append(model)\n\naccuracies = np.array(accuracies)\n\n# Draw the bar charts\ndraw_bar_chart(x=model_names, y=accuracies, title=\"Model performance - RMSE\\n\", x_axis_label=\"\\nModel\", x_tick_rotation=0, \n               y_axis_label=\"RMSE ($K)\", y_scaling=1000, add_num_labels=True, figsize=(20,6), label_format=\"{:,.1f}\",\n               num_labels=accuracies\/1000, legend=None, #y_axis_limits=(0,45000)\n              );","b386e2ed":"%%time\n\n# Appending each classifier's results to a list\ncv_results = []\nfor model, regressor in regressors.items():\n    cv_results.append(-cross_val_score(regressor, X=X_ohe, y=y, scoring=\"neg_root_mean_squared_error\", \n                                       cv=kfold, n_jobs=-1, verbose=0))\n    print(\"Cross-validation complete for: \\t\"+str(model))\n\n# Calculating the mean performance and standard deviation for comparison later:\ncv_means = []\ncv_std = []\nfor cv_result in cv_results:\n    cv_means.append(cv_result.mean())\n    cv_std.append(cv_result.std())\n\ncv_res = pd.DataFrame({\"CV_means\":cv_means,\"CV_std\": cv_std,\"Model\":model_names})","677f43d3":"draw_bar_chart(x=cv_res[\"Model\"], y=cv_res[\"CV_means\"], title=\"Model performance - RMSE\\n\", \n               x_axis_label=\"\\nModel\", x_tick_rotation=0, y_axis_label=\"RMSE ($K)\", y_scaling=1000,\n               add_num_labels=True, figsize=(20,6), label_format=\"{:,.1f}\",\n               num_labels=cv_res[\"CV_means\"]\/1000, legend=None, #y_axis_limits=(20e3,80e3)\n              );\ndraw_bar_chart(x=cv_res[\"Model\"], y=cv_res[\"CV_std\"], title=\"Model stability - standard deviation\\n\", \n               x_axis_label=\"\\nModel\", x_tick_rotation=0, y_axis_label=\"Standard deviation ($K)\", y_scaling=1000,\n               add_num_labels=True, figsize=(20,6), label_format=\"{:,.1f}\",\n               num_labels=cv_res[\"CV_std\"]\/1000, legend=None, #y_axis_limits=(3e3,8.5e3)\n              );","a0f02ca6":"def scatter_text(x, y, text_column, data, title, xlabel, ylabel):\n    # Creating the figure:\n    fig, ax = plt.subplots(ncols=1, nrows=1, figsize=(24,8))\n\n    # Create the scatter plot    \n    p1 = sns.scatterplot(x=x, y=y, data=data, ax=ax, s=100, legend=False)\n    \n    # Set title\n    ax.set_title(title, fontsize=14, fontweight='bold')\n    \n    # Creating the axis labels:\n    ax.set_xlabel(xlabel, fontproperties=font)\n    ax.set_ylabel(ylabel, fontproperties=font)\n    \n    # Setting label ticks size:\n    plt.yticks(fontsize=12)\n    plt.xticks(fontsize=12)\n    \n    # Formatting the y-axis labels\n    y_tick_loc = ax.get_yticks().tolist() # Setting the y-tick labels\n    ax.yaxis.set_major_locator(mticker.FixedLocator(y_tick_loc))\n    ax.set_yticklabels([\"{:,.0f}\".format(x\/1000) for x in y_tick_loc])\n\n    # Formatting the y-axis labels\n    x_tick_loc = ax.get_xticks().tolist() # Setting the x-tick labels\n    ax.xaxis.set_major_locator(mticker.FixedLocator(x_tick_loc))\n    ax.set_xticklabels([\"{:,.0f}\".format(x\/1000) for x in x_tick_loc])\n\n    # Add text besides each point\n    for line in range(0,data.shape[0]):\n         p1.text(data[x][line]+50, data[y][line], \n                 data[text_column][line], \n                 horizontalalignment='left', \n                 size='small', \n                 color='black',\n                )    \n    return p1\n\n# Draw the scatter chart:\nscatter_text(x='CV_std', \n             y='CV_means', \n             text_column='Model', \n             data=cv_res, \n             title='Model performance vs. stability\\n', \n             ylabel='Model mean CV score ($K)',\n             xlabel='Model standard deviation ($K)');","c404d241":"# Calling the test data:\ntest = pd.read_csv('..\/input\/house-prices-advanced-regression-techniques\/test.csv')\n\n# Saving the Id column for later:\nId = test['Id']\n\n# Remove variables from the test dataframe that aren't model features:\nfor col in test.columns:\n    if col not in df.columns:\n        test.drop(col, axis=1, inplace=True)\n\n# Removing the missing data from the test set:\nremoving_missing_data(df=test)\n        \n# Creating the z-scores in the test df to remove outliers:\noutlier_cols_test, outliers_test, z_score_test = create_z_scores(df=test)\n\n# Replacing the outliers with a value equal to a z-score of 3:\nreplace_outliers(outlier_cols=outlier_cols_test, outliers=outliers_test, df=test)\n\n# remove variables from the categorical variables that were taken out above\nfor var in var_to_remove:\n    if var in cat_variables: cat_variables.remove(var)\n\n# Remove occurences of variables from the test set that have been removed from the df set already:\nfor idx, cat_var in enumerate(cat_variables):\n    test_occurences = list(test[cat_variables[idx]].value_counts().keys())\n    df_occurences = list(df[cat_variables[idx]].value_counts().keys())\n    for test_occ in test_occurences:\n        if test_occ in df_occurences:\n            pass\n        else:\n            test[cat_var] = np.where(test[cat_var] == test_occ, 'Other', test[cat_var])","6dd904ab":"X_test, test, model_features = scale_data_and_define_features(df=test, scale_data=True, incl_target=False, num_variables=num_variables, cat_variables=cat_variables)","1cbbce52":"# Creating our one hot encoded variables:\nX_test_ohe = pd.get_dummies(X_test, columns = cat_variables, prefix = cat_variables)","1c7a1d60":"# Creating our predictions for each model:\npredictions_df = pd.DataFrame()\nfor model, boolean in models_dict.items():\n    if model == \"CatBoost\" and boolean:\n        if cb_ohe: predictions_df[model] = cb_model.predict(X_test_ohe)\n        else: predictions_df[model] = cb_model.predict(X_test)\n    else:\n        if boolean: predictions_df[model] = models[model].predict(X_test_ohe)\n\n            # And transform them if that's what we want!\nif log_transform_target: predictions_df = np.exp(predictions_df)","0169af88":"fig, ax = plt.subplots(nrows=1, ncols=1, figsize=(20,6))\nsns.boxplot(data=predictions_df[models]);\nax.set_title(\"Model predictions\\n\", fontsize=14, fontweight='bold')\nax.set_xlabel(\"Model\", fontproperties=font)\nax.set_ylabel('Sale price predictions ($K)', fontproperties=font);\n# Setting y-tick labels\ny_tick_labels_1 = ax.get_yticks().tolist() # Setting the y-tick labels\nax.yaxis.set_major_locator(mticker.FixedLocator(y_tick_labels_1)) # Setting the y-tick label locations\nax.set_yticklabels([\"{:,.0f}\".format(x\/1000) for x in y_tick_labels_1]); # Setting the y-label format","0ea00eb6":"def scorer(actual, predicted):\n    return rmse(actual=actual, predicted=predicted)","38bb388c":"%%time\n\n# Set up our superlearner with folds \nensemble = SuperLearner(folds=folds, \n                        random_state=random_state, \n                        scorer=scorer,\n                        #sample_size=len(X),\n                        verbose=True,\n                       )\nensemble.add(model_list)\n\n# Adding our metalearner\nensemble.add_meta(LinearRegression())\n\n# Now to fit the model on the training data\nensemble.fit(X_train_ohe, y_train)\n\n# Make the predictions using the validation data:\nensemble_predictions = ensemble.predict(X_val_ohe)\nensemble_acc = rmse(actual = y_val, predicted = ensemble_predictions)\nensemble_per_cent = ensemble_acc\/y_val.mean()\nprint(\"\\nEnsemble model RMSE is: $\"+str(\"{:,.0f}\".format(ensemble_acc)))\nprint(\"Ensemble model percentage error is: \"+str(\"{:,.5f}\".format(ensemble_per_cent))+\"\\n\")","d93a1060":"# Creating a dictionary of the models from which to refer when tuning the Superlearner\nmodel_dict = {}\nfor idx, model in enumerate(model_names):\n    model_dict[model] = model_list[idx]\n    \n# Setting up a dictionary of the possible head models:\nhead_dict = {'CatBoost': CatBoostRegressor(random_state=random_state, iterations=2000, verbose=False),\n             \"LinearRegression\": LinearRegression(),\n            }","519f03cd":"def superlearner_tune(trial):\n    # Setting up our blank model names\n    models_to_add = []\n    \n    # List the models to use in the ensemble\n    model_list = list(model_dict.keys())\n    \n    # List the models to be used in the head\n    head_list = list(head_dict.keys())\n    \n    # Varying the number of models:\n    n_models = trial.suggest_int(\"n_models\", 2, len(model_list))\n    for i in range(n_models):\n        model_item = trial.suggest_categorical('model_{}'.format(i), model_list)\n        if model_item not in models_to_add:\n            models_to_add.append(model_item)\n    \n    # Instantiate the ensemble model:\n    ensemble = SuperLearner(folds=folds, random_state=random_state, shuffle=False, \n                            scorer=scorer, sample_size=len(X))\n    \n    # Add all the models to the ensemble:\n    models = [model_dict[item] for item in models_to_add]\n    ensemble.add(models)\n    \n    # Cycle through possible 'heads'\n    head = trial.suggest_categorical('head', head_list)\n    ensemble.add_meta(head_dict[head])\n        \n    return ensemble\n\ndef objective(trial):\n    model = superlearner_tune(trial)\n    model.fit(X_ohe, y)\n    sl_pred = model.predict(X_ohe)\n    sl_acc = scorer(y, sl_pred)\n    return sl_acc","0853f44a":"%%time\n# Creating our sampler\nsampler = TPESampler(seed=random_state)\n\n# creating the study:\nensemble_study = optuna.create_study(direction=\"minimize\", sampler=sampler)\n\n# Optimising our study:\nensemble_study.optimize(objective, n_trials=trials_dict['ensemble'], timeout=7200, show_progress_bar=True)","35ec6f37":"# Define the best parameters of the study:\nensemble_params = ensemble_study.best_params\nhead = ensemble_params['head']\ndel ensemble_params['head'], ensemble_params['n_models']\nensemble_models = list()\nfor key, value in ensemble_params.items():\n    if value not in ensemble_models:\n        ensemble_models.append(value)\n\nprint(\"Head model is: \"+str(head))\nprint(\"Component models are: \"+str(ensemble_models))","4e29ed17":"model_structure_override = False\nif model_structure_override:\n    head = \"LinearRegression\"\n    ensemble_models = [\"Ridge\", \"Lasso\", \"AdaBoost\", \"MLP\"]","368bb27e":"%%time\n\n# Instantiate our optimised ensemble model:\nensemble = SuperLearner(folds=folds, random_state=random_state)\n\n# Add the models from the result above to the ensemble:\nfinal_models = [model_dict[item] for item in ensemble_models]\nensemble.add(final_models)\n\n# Add the meta model from the above:\nensemble.add_meta(head_dict[head])\n\n# Fit the optimised ensemble model:\nensemble.fit(X_train_ohe, y_train)\n\n# Make the final predictions:\nensemble_pred = ensemble.predict(X_val_ohe)\n\n# Calculating model score:\nif log_transform_target: ensemble_acc = rmse(actual=np.exp(y_val), predicted=np.exp(ensemble_pred))\nelse: ensemble_acc = rmse(actual=y_val, predicted=ensemble_pred)\nprint(\"Tuned ensemble model RMSE is: $\"+str(\"{:,.0f}\".format(ensemble_acc)))\nprint(\"Tuned ensemble model percentage error is: \"+str(\"{:,.5f}\".format(ensemble_acc\/y_val.mean()))+\"\\n\")","1e6c3671":"ensemble_test_predictions = ensemble.predict(X_test_ohe)\nsubmission = pd.DataFrame({\"Id\": Id, \"SalePrice\": ensemble_test_predictions})\nsubmission.to_csv(\"ensemble_model_submission.csv\", index=False)","a6ab93a3":"### 3.4.3. Unfinished basement (sqft)","9e1433c0":"For the **categorical variables**, we should change the missing data to 'NA' (e.g. in the case of 'GarageCond'), though there are some special cases where the data are missing and should be changed to 'None', e.g. 'MasVnrType'.\n\nFor the **numerical variables** we should replace these with zero (e.g. 'LotFrontage') but in the case of 'GarageYrBlt', we will replace with the year the house was built (i.e. 'HouseBuilt').","797556a4":"## 3.5. Removing variables with weaker correlation with sale price than other strong predictors\nThere are a number of variables which are weak predictors of sale price and owe their correlation to the fact that they have reasonably high correlations with good predictors of sale price. For example, open porch has a 32% correlation with sale price but has a 33% correlation with grade living area, which is a strong (i.e. 70%+) predictor of sale price. \n\nI will therefore build a short function which selects the strong predictors and then removes functions with a correlation with these strong predictors which is stronger than their correlation with sale price.","1304c27d":"## 3.4. Review of remaining numerical variables\nLet's redo the heatmap and see which variables should be included as features.","de8435b1":"So let's now review how the correlations between SalePrice and the numerical variables have changed as a result of this work.","0d741ec0":"So these variables should be much more useful features and LotArea clearly is much better. ","866bf7bc":"## 7.2. LightGBM","79f10326":"## 7.9. Support vector regressor","e1d48781":"## 4.1. Review of categorical variables\nLet's have a quick look at all the variables that purport to have an impact larger than 100K dollars on sale price. ","f944d9e0":"### 3.4.2. Lot frontage","95234867":"### 3.4.1. Half bathrooms above grade","6b0d2c59":"## 7.11. Lasso regressor","921078f3":"Through playing with the models below that log transformation improves the accuracy of the neural network in particular. So let's include a switch below which turns log_transformation on or off for the inputs of the models. ","de99ccce":"## 6.2. One hot encoding\nWe need to use one hot encoding for the categorical features for the XGBoost and Pytorch models. ","6db1a3f7":"These all appear to be credible features, so let's delete the others as less useful and see how many features we now have for our model.","5a5da557":"## 7.8. AdaBoost","02a14025":"There still appears to be a huge amount of noise in this variable, which makes it unsuitable as a feature. So we should remove it. ","3cf7d614":"## 9.3. Creating output for submission\nAnd now to output the CSV for submission.","ee7388c7":"Now let's analyse how stable each model is using cross-validation.","b3a86331":"# 8. Reviewing model performance\nLet's take a quick look at each of our models and see how they perform with the validation dataset.","700452de":"### 3.4.5. Open porch (sqft)","fffc82a1":"Now, let's create a simple override, just in case we want to trial other model structures:","fe77a260":"Now at this point we need to make our predictions using CatBoost, i.e. pre-one hot encoding. ","ef848879":"Let's visualise our predictions:","58452059":"Calling the datasets and returning the initial information on the training set:","6f6a583e":"# 3. Numerical variables","868bd8bc":"### 3.4.4. Wooden deck (sqft)","eed92fcb":"## 7.12. Random forest regressor","fa7fa4f3":"# Housing market regression","7d87bc48":"So we need to get a sense of which of these variables are good predictors of SalePrice. Let's compare the categorical variables with the largest difference between their highest category and their lowest. We should remove all categories with fewer than 50 occurences as these will be subject to sample size error otherwise. ","f6e3a9e7":"## 7.4. Gradient boosting regressor","156a6fe8":"## 9.1. Building a simple ensemble model\nLet's build a simple stacking ensemble.","e8b1571f":"## 9.2. Tuning the Superlearner\nThis is super slow so go and make a nice cup of tea and come back later...","d78a8703":"## 7.5. Multi-layer perceptron regressor","da9484a7":"So there are several factors which are correlated (40%+) with sale price. There are also several features which appear to have good correlation, but the data may require cleaning. Let's see how many outliers there are in each variable, defining 'outlier' as a datum with a z-score of greater than 3. ","d3f9be9b":"Looks like there are some rogue numbers in here. Changing the 1.89s to 1s.","ea533157":"## 7.7. Logistic regression","1b79b7a9":"# 7. Building our models\nLet's set up some input assumptions for our models:\n1. the number of folds for cross validation; \n2. a list of switches on whether or not to include the models in our analysis (XGBoost takes a long time to train, for example);\n3. a list of the accuracies and regressors to use later;\n4. a list of all the trial numbers in a single place so it's easy to control how long this section takes to run; and\n5. tuning off the warnings on optuna.","31dcad5c":"## 3.6. Final numerical variables\nSo our final numerical variables are:","65f0df79":"## 7.1. CatBoost regressor","5bf8a253":"It looks like our seemingly most accurate models (the gradient boosted trees) are the models which have overfitted the most! Let's use a scatter chart to see if there is a better way of visualising this. ","297e0f7d":"And our final correlation looks like:","3a93677a":"Let's explore which of these categorical variables could be used at features in our model. A few initial thoughts:\n1. There are a number variables without 2 categories of at least the required number of items, so we should not use these as features for our model.\n2. Within each of the variables, there will be categories that have too few occurences to be useful. We should therefore change these to be 'Other'. \n\nLet's build three functions to:\n1. remove the variables highlighted in item 1. above;  \n2. change the small number of occurences to 'Other' (with the exception of neighbourhood); and \n3. produce graphs to review the output of this work.\n\nLet's review each of the variables that appears to have over a USD100K impact on the sale price. ","0a1ba376":"All these elements appear to have a clear impact on sale price. What about those categories between 50-100K?","06e25d77":"## 7.10. Ridge model","56586a5b":"# 1. Importing the required libraries","033f149a":"# 5. Final pre-processing\nGiven how skewed the `SalePrice` data are, we should consider a log-transform of these to give a more Gaussian distribution which should improve the predictive power of the neural network (see at the bottom of this notebook) in particular. ","eeeb15ef":"And then produce the final outputs:","0f60f274":"Dropping all variables with correlations below certain threshold.","bf53501f":"## 7.3. XGBoost","5b2bfdad":"## 7.6. Linear discriminant analysis","4dbc0f56":"## 2.1. Dealing with missing data\nWhich variables have missing data? ","0ccd1acb":"# 2. Exploratory data analysis","2365e744":"So we have 79 variables from which to select features for our model. These are a mix of numeric and categorical, so let's start with the correlation between the numeric data and 'SalePrice' to see which variables we should focus on. ","9911348e":"## 3.3. Removing variables exhibiting multicollinearity\nThere are a number of reasons we should not include variables that are highly correlated with one another as features in our models: \n1. it leads to overfitting;\n2. it adds unnecessary complexity to our models; and\n3. cleaning the data is time consuming and removing variables speeds up this process.\n\nSo let's build a heatmap of the correlation of all the features.","db6df9b7":"## 3.2. Removing outliers in the numeric variables","7fc11ea1":"# 9. Making our predictions\n\nFirst, we need to complete the same feature engineering on the `test` set as we undertook on the `df` data. ","df923e24":"So there are three variables for which the overwhelming majority of data are zero, and hence any non-zero items are defined as 'outliers'. As as result, these variables will not be useful features for our model and we should exclude them. \n\nThe 'MSSubClass' is in fact a categorical variable disguised as a numerical one, so we should convert these to strings. \n\nThe remainder of the outliers above are therefore just that: outliers we should remove to reduce the skewness of our dataset.","8255b012":"Most of the above over 20% should be included, but let's review those with correlations between 20-40% to ensure they do not require further cleaning. ","d6e1787b":"So let's remove any variables with a collineation of over 65%, starting with the one which is least correlated with sale price.","028b5d63":"# 4. Review the categorical variables","2c3583f2":"## 3.1. Creating our own features\nOne way of reducing the number of features (which simplifies processing and reduces overfitting) is to combine some variables into a new feature. One way to do this is to create a new feature called `SqFtPerRoom` which calculates the average size of the house's rooms and may replace other features later. ","01b2c21c":"Let's build a heatmap of the simple correlation between all the features and SalePrice. ","fdcc3b0d":"There are also a large number of categorical features to be analysed:","7cde0445":"Far too noisy! Delete.","4709710c":"# 6. Pre-modelling data processing\n## 6.1. Train and test split and scaling the data\nLet's:\n1. Define our model features; \n2. Delete columns in the df not in our model features;\n3. Scale the numerical data to ensure all features have the same initial importance;\n4. Set our random state to ensure repeatability; \n5. Log transform our target; and \n6. Define our train:test split."}}