{"cell_type":{"14390bb7":"code","20f8b0b5":"code","c8aab70f":"code","9d937d13":"code","311b3080":"code","9af2b816":"code","6d15a8db":"code","9e408e2f":"code","bb88873d":"code","e3831486":"code","cd9364cf":"code","8c287091":"code","fbe16c22":"code","ded006d6":"code","44dd1cfa":"code","4af2db1e":"code","290e9ce2":"code","013a8db1":"code","8024cf2f":"code","3f126243":"code","241b7414":"code","e1e0ada2":"code","094b1b07":"code","bac70747":"code","c67b91eb":"code","dc5395f2":"code","10ff5ad8":"code","35837598":"code","1f21b27c":"code","834180c4":"code","edf31e1e":"code","8d49507d":"code","ae84879f":"code","c7770b34":"code","2fcf73da":"code","d3856b9e":"code","1c1ab59c":"code","183b247f":"code","49d0baa3":"code","b5d7172d":"code","366e8971":"code","96a53bf9":"code","b5dd92cb":"code","e6fba3ea":"code","3a975bd5":"code","6c8f500a":"code","039fcc77":"code","22d8d66d":"code","b0d2e5a0":"code","8ecf3773":"code","dc290bd4":"code","de3f7438":"code","82777e4e":"code","58ab865d":"code","13c9d0be":"code","69adf2bb":"code","c40f7995":"code","cd203720":"code","f902517d":"code","3fa00959":"code","2fd9ab29":"code","79dfd5c9":"code","8edc95ea":"code","ca82259b":"code","d0aef316":"code","66cc32d0":"code","2991c497":"code","2681fe78":"code","fa2af710":"code","a7cb2715":"code","f286a735":"code","29c0a98d":"code","07af814c":"code","7e4b56e3":"code","8f3b3900":"code","a66dcb46":"code","a3429ec0":"code","b1fb9659":"code","97dc54e8":"code","c6ad2a8d":"code","963df624":"code","1349cede":"code","0c6af64d":"code","bb44113a":"code","44f3b8d2":"code","eca5de85":"code","42a721f6":"code","e6149ec0":"code","96486bc3":"code","d41fc23e":"code","62e9dd20":"code","9775df52":"code","79c14c89":"code","c58e593e":"code","7d735b81":"code","54fa1383":"code","b92fa600":"code","e902f07b":"code","19d9d7a7":"code","0a2d78b1":"code","76e9ef94":"code","d7696dcf":"code","2d78f550":"code","3f5aa45c":"code","285074ad":"code","cffd4a30":"code","5a89563a":"code","96440cc8":"code","fe3e9bbb":"code","009e47da":"code","42b8a117":"code","5bbee3ac":"code","1a123076":"code","61b1b0ed":"code","f6421820":"code","c5798b59":"code","ae67784e":"code","a7a4ad4d":"code","c5f7ffa5":"code","d7c2b93b":"code","31ae02a3":"code","a1b19e08":"code","71c6e5f8":"markdown","a2ec1725":"markdown","cf147a1f":"markdown","aded1b16":"markdown","f3072702":"markdown","f5c43560":"markdown","07a69b36":"markdown","6c8dfb1e":"markdown","f78217ed":"markdown","7d3f722d":"markdown","f08786ef":"markdown","b12c908f":"markdown","a550278d":"markdown","97f78e30":"markdown","6610d1d4":"markdown","0b50b336":"markdown","0d15789a":"markdown","2be2584e":"markdown","f1e6b9d4":"markdown","1d6ad2be":"markdown","ef4f0e9e":"markdown","54bab14f":"markdown","516286ab":"markdown","9621b6b8":"markdown","57a6d87d":"markdown","8759fa63":"markdown","413148fd":"markdown","0a4d6781":"markdown","e6f29b4e":"markdown","3651bcb2":"markdown","17aeaf7c":"markdown","4de0175f":"markdown","ed43ff30":"markdown","0bc3a7d9":"markdown","8e44d140":"markdown","f37af692":"markdown","537dd2be":"markdown","3622164c":"markdown","6b328090":"markdown","34d17004":"markdown","f0b1fb2b":"markdown","622b095f":"markdown","18cb92ca":"markdown","1a750802":"markdown","1e49a1eb":"markdown","9432ccf2":"markdown","21b4bd98":"markdown","0d3cd151":"markdown","ee06703c":"markdown","87b480c3":"markdown","3a933e7b":"markdown","e33a9065":"markdown","ab0eb2b2":"markdown","be0e3694":"markdown","57704622":"markdown","e50b55dc":"markdown","a96e2ba3":"markdown","f69cddba":"markdown","ca7e2ae1":"markdown","c8b2b8b5":"markdown","09c95b0e":"markdown","94d57780":"markdown","af8b168c":"markdown","27b330b1":"markdown","fe33652e":"markdown","1581ea20":"markdown","1d1868f5":"markdown","534275be":"markdown","99dc6990":"markdown","c70d6e4a":"markdown","cadc3128":"markdown","cad89bb9":"markdown","7764c247":"markdown","75550adb":"markdown","147b0c10":"markdown","3c26e818":"markdown","3a0900b1":"markdown","d5900b19":"markdown","1efa53c7":"markdown","cb35136f":"markdown","99ed0505":"markdown","e7e5e80e":"markdown","e6490bb4":"markdown","94a10276":"markdown","f37d2458":"markdown","d012ef17":"markdown","c6624114":"markdown","23cc52c1":"markdown"},"source":{"14390bb7":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","20f8b0b5":"# path to your csv file\npath_train = \"\/kaggle\/input\/titanic\/train.csv\"\npath_test = \"\/kaggle\/input\/titanic\/test.csv\"","c8aab70f":"df_train = pd.read_csv(path_train)\ndf_test = pd.read_csv(path_test)","9d937d13":"df_train.head()","311b3080":"df_train.head(n=10)","9af2b816":"df_train.tail()","6d15a8db":"df_train.tail(n=15)","9e408e2f":"df_train.columns","bb88873d":"len(df_train.columns)","e3831486":"len(df_train)","cd9364cf":"df_train.shape","8c287091":"df_train.dtypes","fbe16c22":"df_train[\"Sex\"] = df_train[\"Sex\"].astype(\"category\")","ded006d6":"df_train.info()","44dd1cfa":"df_train.dtypes","4af2db1e":"### Your Code here\nlen(df_test)","290e9ce2":"df_test.shape","013a8db1":"df_train.describe()","8024cf2f":"df_train.describe(include=np.object)","3f126243":"df_train.describe(include='all')  ","241b7414":"### Your Code Here\ndf_test.describe()","e1e0ada2":"df_train.plot.scatter('Age', 'Fare')\n","094b1b07":"df_train.hist(column=[\"Age\", \"Fare\"])","bac70747":"df_train[\"Age\"].hist()","c67b91eb":"df_train[\"Age\"].hist(bins=100)","dc5395f2":"df_train.boxplot(column=[\"Age\", \"Fare\"])","10ff5ad8":"df_train.boxplot(column=\"Age\")","35837598":"df_train.boxplot(column=\"Age\", by=\"Sex\")","1f21b27c":"df_train.isnull()","834180c4":"# number of null values in each column\ndf_train.isnull().sum()","edf31e1e":"# proportion of null values in each column\ndf_train.isnull().sum() \/ len(df_train)","8d49507d":"# Example of removing all column with NULL value, but we don't want to do this for this case\ndf_train.dropna(axis=1)","ae84879f":"# remove specific colum only with NULL value (Cabin)\ndf_train_clean = df_train.drop(columns=[\"Cabin\"])\ndf_train_clean","c7770b34":"# Example of removing all rows with NULL value, but we don't want to do this for this case\ndf_train_clean.dropna(axis=0)","2fcf73da":"# Example of removing row with NULL value on a specific column\ndf_train_clean = df_train_clean.dropna(axis=0, subset=[\"Embarked\"])\ndf_train_clean","d3856b9e":"# number of null values in each column\ndf_train_clean.isnull().sum()","1c1ab59c":"# we use mean value to fill NA\nmean_values = df_train_clean.mean()\nmean_values","183b247f":"df_train_clean = df_train_clean.fillna(mean_values)\ndf_train_clean","49d0baa3":"# number of null values in each column\ndf_train_clean.isnull().sum()","b5d7172d":"### Your code here\n# Solution task 3\nmean_values = df_train_clean.mean()\ndf_test_clean = df_test.fillna(mean_values)\n","366e8971":"df_train_clean.boxplot(column=\"Age\")","96a53bf9":"df_train_clean[\"Age\"].describe()","b5dd92cb":"q1 = 22\nq3 = 35\niqr = q3 - q1\nprint(\"Q1 :\", q1)\nprint(\"Q3 :\", q3)\nprint(\"IQR :\", iqr)","e6fba3ea":"lower_th = q1 - (1.5 * iqr)\nupper_th = q3 + (1.5 * iqr)","3a975bd5":"print(\"lower_th :\", lower_th)\nprint(\"upper_th :\", upper_th)","6c8f500a":"def is_outlier(x, lower_th, upper_th):\n    if (x < lower_th) or (x > upper_th):\n        return True\n    else:\n        return False","039fcc77":"df_train_clean[\"Age\"].apply(lambda x : is_outlier(x, lower_th, upper_th))","22d8d66d":"# See the observations that the \"Age\" is outliers\ndf_train_clean[df_train_clean[\"Age\"].apply(lambda x : is_outlier(x, lower_th, upper_th))]","b0d2e5a0":"df_train_no_outliers = df_train_clean[df_train_clean[\"Age\"].apply(lambda x : not is_outlier(x, lower_th, upper_th))]\ndf_train_no_outliers","8ecf3773":"mean_value = df_train_clean[\"Age\"].mean()\nmean_value","dc290bd4":"df_train_no_outliers = df_train_clean.copy()\ndf_train_no_outliers[\"Age\"] = df_train_no_outliers[\"Age\"].apply(lambda x : mean_value if is_outlier(x, lower_th, upper_th) else x)\ndf_train_no_outliers","de3f7438":"df_train_no_outliers.boxplot(column=\"Age\")","82777e4e":"# Your code here\n\n# Solution task 4\n\n# Check the data\ndf_test_clean.describe()\n\n# calculate the IQR\nq1 = 22\nq3 = 35\niqr = q3 - q1\nlower_th_test = q1 - (1.5 * iqr)\nupper_th_test = q3 + (1.5 * iqr)\n\n# calculate the mean\nmean_value = df_test_clean[\"Age\"].mean()\n\n# change the outlier \ndf_test_no_outliers = df_test_clean.copy()\ndf_test_no_outliers[\"Age\"] = df_test_no_outliers[\"Age\"].apply(lambda x : mean_value if is_outlier(x, lower_th, upper_th) else x)\ndf_test_no_outliers\n","58ab865d":"df_train_clean = df_train_no_outliers.copy()","13c9d0be":"groupby_sex = df_train_clean.groupby(\"Sex\")","69adf2bb":"groupby_sex.mean()","c40f7995":"groupby_sex.count()","cd203720":"groupby_sex_survived = df_train_clean.groupby([\"Sex\", \"Survived\"])","f902517d":"groupby_sex_survived.mean()","3fa00959":"groupby_sex_survived.count()","2fd9ab29":"gb_sex_count = groupby_sex.count()[\"PassengerId\"]\ngb_sex_count","79dfd5c9":"gb_sex_count.plot(kind='bar', \n                  title='Number of passenger by gender', \n                  ylabel='Number of passenger',\n                  xlabel='Gender')","8edc95ea":"gb_sex_surv_count = groupby_sex_survived.count()[\"PassengerId\"]\ngb_sex_surv_count","ca82259b":"gb_sex_surv_count.plot(kind='bar', \n                  title='Number of passenger by gender', \n                  ylabel='Number of passenger',\n                  xlabel='(Gender, Survived)')","d0aef316":"# Aggregate by gender\npd.crosstab(index=df_train_clean[\"Sex\"], columns=\"count\")","66cc32d0":"# Cross table Sex-Survived\npd.crosstab(index=df_train_clean[\"Sex\"], columns=df_train_clean[\"Survived\"])","2991c497":"# Cross table Sex-Survived, with gender mean as the value\npd.crosstab(index=df_train_clean[\"Sex\"], \n            columns=df_train_clean[\"Survived\"], \n            values=df_train_clean[\"Age\"],\n            aggfunc=\"mean\")","2681fe78":"# Example using pivot to make the same result as crosstab above\npd.pivot_table(data=df_train_clean,\n              index=\"Sex\",\n              columns=\"Survived\",\n              values=\"Age\",\n              aggfunc=\"mean\")","fa2af710":"# Your code here\n# Solution task 5\ndf_test_clean = df_test_no_outliers.copy()\n\ngroupby_sex_survived = df_test_clean.groupby([\"Sex\", \"Pclass\"])[['PassengerId']]\ngroupby_sex_survived.count()\n","a7cb2715":"df_numeric = df_train_clean[[\"Fare\", \"Age\"]]\ndf_numeric","f286a735":"corr = df_numeric.corr()\ncorr","29c0a98d":"import seaborn as sn\nimport matplotlib.pyplot as plt","07af814c":"sn.heatmap(corr, annot=True)\nplt.show()","7e4b56e3":"corr = df_train_clean.corr()","8f3b3900":"# sn.heatmap(corr, annot=True)\n# plt.show()","a66dcb46":"df_train_clean.Pclass.value_counts().plot(kind = 'bar')","a3429ec0":"df_crosstab = pd.crosstab(index = df_train_clean.Pclass, \n           columns = df_train_clean.Sex,\n           values = df_train_clean.PassengerId,\n           aggfunc = 'count')\ndf_crosstab.plot(kind = 'bar')","b1fb9659":"df_train_clean.Age.describe()","97dc54e8":"# define the function given sex and age to return the person type\ndef get_person_type(passenger):\n   \n    sex,age = passenger\n    #comparing the age\n    if age < 16:\n        person_type =  'child'\n    else:\n        person_type =  sex\n\n    return person_type","c6ad2a8d":"df_train_clean['person_type'] = df_train_clean[['Sex', 'Age']].apply(get_person_type, axis = 1)","963df624":"df_train_clean.person_type.value_counts(normalize = True)*100.0","1349cede":"df_train_clean.head()","0c6af64d":"df_crosstab = pd.crosstab(index = df_train_clean.Pclass, \n           columns = df_train_clean.person_type,\n           values = df_train_clean.PassengerId,\n           aggfunc = 'count')\ndf_crosstab","bb44113a":"df_crosstab.plot(kind = 'bar')","44f3b8d2":"df_train_clean['Family'] = df_train_clean['SibSp'] + df_train_clean['Parch']","eca5de85":"df_train_clean.Family.value_counts()","42a721f6":"df_train_clean.groupby('Family')['Pclass'].value_counts(normalize = True).unstack().plot(kind = 'bar', stacked = True)","e6149ec0":"df_train_clean['Alone'] = df_train_clean.Family == 0","96486bc3":"df_train_clean['Alone'].value_counts(normalize = True)*100.0","d41fc23e":"df_crosstab = pd.crosstab(index = df_train_clean.Pclass, \n           columns = df_train_clean.Alone,\n           values = df_train_clean.PassengerId,\n           aggfunc = 'count')\ndf_crosstab.plot(kind = 'bar')","62e9dd20":"df_train_clean.Survived.value_counts()","9775df52":"# use normalize = True to get the ratio instead of real value count\ndf_train_clean.Survived.value_counts(normalize = True)","79c14c89":"df_train_clean.Survived.value_counts(normalize = True).plot(kind = 'bar')","c58e593e":"df_pivot = df_train_clean.pivot_table(index = 'person_type', columns = 'Survived', values = 'PassengerId', aggfunc = 'count')\ndf_pivot","7d735b81":"df_pivot.plot(kind = 'bar')","54fa1383":"df_pivot = df_train_clean.pivot_table(index = 'Pclass', columns = 'Survived', values = 'PassengerId', aggfunc = 'count')\ndf_pivot.plot(kind = 'bar')","b92fa600":"# Your code here\n","e902f07b":"# Your code here\n\n","19d9d7a7":"x_train = df_train_clean[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Family', 'Alone']].values\ny_train = df_train_clean[['Survived']].values","0a2d78b1":"# Your code here\n","76e9ef94":"from sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import confusion_matrix","d7696dcf":"# Build a Logistic Regression Model\nmodel_lr = LogisticRegression()","2d78f550":"# Train LR model with train data\nmodel_lr.fit(x_train, y_train)","3f5aa45c":"# Make a prediction from test data\n# Attention: below is wrong code\ny_predict = model_lr.predict(x_train)\n\n## it should Be:\n# y_predict = model_lr.predict(x_test)","285074ad":"# # Put the prediction into original data\n# df_test['y_predict'] = y_predict","cffd4a30":"# # Let's see how it goes\n# df_test[['PassengerId', 'y_predict', 'Survived']].head(10)","5a89563a":"# Create a confusion matrix\n# Attention: below is wrong code\ntn, fp, fn, tp = confusion_matrix(y_train, y_train).ravel()\n\n# # it should Be\n# tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()","96440cc8":"# calculate the metrics\naccuracy = (tp + tn) \/ (tp + tn + fp + fn) \nprecision = tp \/ (tp+fn)\nrecall = tp \/ (tp+fp)\nf1 = (2 * precision * recall) \/ (precision + recall)\n","fe3e9bbb":"print(\"Accuracy: \\t\", accuracy)\nprint(\"Precision: \\t\", precision)\nprint(\"Recall: \\t\", recall)\nprint(\"F1: \\t\\t\", f1)","009e47da":"from sklearn import tree","42b8a117":"# Build the model\n# Your code here ","5bbee3ac":"# Train LR model with train data\n# Your code here ","1a123076":"# Make a prediction from test data\n# Your code here ","61b1b0ed":"# Create a confusion matrix\n# Your code here \n\n\n# calculate the metrics\n# Your code here ","f6421820":"print(\"Accuracy: \\t\", accuracy)\nprint(\"Precision: \\t\", precision)\nprint(\"Recall: \\t\", recall)\nprint(\"F1: \\t\\t\", f1)","c5798b59":"# Solution task 1\n# len(df_test), df_test.shape","ae67784e":"# # Solution task 2\n# df_test.describe()","a7a4ad4d":"# # Solution task 3\n# mean_values = df_train_clean.mean()\n# df_test_clean = df_test.fillna(mean_values)\n","c5f7ffa5":"# # Solution task 4\n\n# # Check the data\n# df_test_clean.describe()\n\n# # calculate the IQR\n# q1 = 22\n# q3 = 35\n# iqr = q3 - q1\n# lower_th_test = q1 - (1.5 * iqr)\n# upper_th_test = q3 + (1.5 * iqr)\n\n# # calculate the mean\n# mean_value = df_test_clean[\"Age\"].mean()\n\n# # change the outlier \n# df_test_no_outliers = df_test_clean.copy()\n# df_test_no_outliers[\"Age\"] = df_test_no_outliers[\"Age\"].apply(lambda x : mean_value if is_outlier(x, lower_th, upper_th) else x)\n# df_test_no_outliers\n","d7c2b93b":"# # Solution task 5\n# df_test_clean = df_test_no_outliers.copy()\n\n# groupby_sex_survived = df_test_clean.groupby([\"Sex\", \"Survived\"])\n# groupby_sex_survived.count()\n","31ae02a3":"# # Solution task 6\n# df_test_clean = df_test_no_outliers.copy()\n# df_test_clean['Family'] = df_test_clean['SibSp'] + df_test_clean['Parch']\n\n# df_test_clean['Alone'] = df_test_clean.Family == 0\n# df_test_clean['Alone'].value_counts(normalize = True)*100.0\n","a1b19e08":"# # Solution task 7\n# x_test = df_test_clean[['PassengerId', 'Pclass', 'Age', 'SibSp', 'Parch', 'Fare', 'Family', 'Alone']].values\n# y_test = df_test_clean[['Survived']].values\n\n# # Solution task 8\n# # Build the model\n# model_dt = tree.DecisionTreeClassifier()\n\n# # Train LR model with train data\n# model_dt.fit(x_train, y_train)\n\n# # Make a prediction from test data\n# y_predict = model_dt.predict(x_test)\n\n# # Create a confusion matrix\n# tn, fp, fn, tp = confusion_matrix(y_test, y_predict).ravel()\n\n# # calculate the metrics\n# accuracy = (tp + tn) \/ (tp + tn + fp + fn) \n# precision = tp \/ (tp+fn)\n# recall = tp \/ (tp+fp)\n# f1 = (2 * precision * recall) \/ (precision + recall)\n\n\n# print(\"Accuracy: \\t\", accuracy)\n# print(\"Precision: \\t\", precision)\n# print(\"Recall: \\t\", recall)\n# print(\"F1: \\t\\t\", f1)","71c6e5f8":"# Getting More Insight from the Data","a2ec1725":"We can also set more bins so that we can see the distribution in more detail","cf147a1f":"We must remember that correlation is only exist for numerical column, so we need to select numerical column first. In our dataset, we only have 2 numerical columns. They are `Fare` and `Age`","aded1b16":"This will be usefull if we want to know the statistics of each group. For example, we want to know the statistics of each gender","f3072702":"### How many people did take first class vs the other class?","f5c43560":"### Task 6b. create feature `family_size` on `df_train_clean` & `df_test_clean`\n\ncondition: \n- small_family (value: 1): 1-2 people\n- medium_family (value: 2): 3-4 people\n- big_family (value: 3): > 4 people","07a69b36":"# Split Dataset\n\ny_label: `\/kaggle\/input\/titanic\/gender_submission.csv`","6c8dfb1e":"To calculate the number of NULL value in each column, we can use two methods\n- isna() \/ isnull() : return boolean if a cell is NULL or not\n- sum() : return sum of each column","f78217ed":"### Task 8. train a decision tree model\n\nYou can use this code to build the model `tree.DecisionTreeClassifier()`","7d3f722d":"# Train Decision Tree Model\ndoc: https:\/\/scikit-learn.org\/stable\/modules\/tree.html","f08786ef":"## Data Preview","b12c908f":"So, we can get\n- Q1 = 22\n- Q3 = 35\n\nNow, we need to calculate IQR = Q3 - Q1","a550278d":"Basically, pivot table have the same return as crosstab. We can use crosstab or pivot based on our preference","97f78e30":"We can also make barplot using these groupby","6610d1d4":"We can check the columns of the dataset by using `columns`, this attribute contains a column indexes. We can also use this attribute to know the number of columns in a dataset by calculating the length of the column indexes using function`len()`","0b50b336":"### Task 6a. create feature `Family` and `Alone` on `df_test_clean`\n","0d15789a":"# Handling NULL values","2be2584e":"EDA will help us to identify errors, detect outliers or anomalous events, find interesting relations among the variables, as well as better understand patterns within the data. In order to understand the data better, sometimes we need to dig deeper by asking more questions about the data. ","f1e6b9d4":"We can also group them by other column. For example here we want to know the distribution of passenger age by their gender","1d6ad2be":"You can check the some rows of your data by using methods `head()` and `tail()`. `head()` will allow you to see 5 first rows, and `tail()` will allow you to see 5 last rows. If you want to see more, you can change argument `n` to a number that you like","ef4f0e9e":"# Understanding the dataset","54bab14f":"### Task 3. Handle null value by changing the value with mean on `df_test`\n\ncreate a variable `df_test_clean`","516286ab":"We can handle outliers by doing one of these two\n- Deleting rows with outliers\n- Fill outliers with a value. We will fill them using mean value here as an example","9621b6b8":"### How was the distribution of people travelling alone vs with family?","57a6d87d":"To know basic statistic of each colum, we can use method `describe()`. DEfault setting will return the basic statistics of numeric columns.\nThose statistics are :\n- count : number of non missing values\n- mean : average of the column\n- std : standard deviation\n- min : minimum value\n- 25% : quartile 1 \/ 25% lowest data\n- 50% : quartile 2 \/ median \/ 50% data\n- 75% : quartile 3 \/ 75% data\n- max : maximum value","8759fa63":"### What class did the big family mostly take?","413148fd":"# Data Aggregation","0a4d6781":"Create a function to mark the outliers","e6f29b4e":"### How was the gender distribution per class?","3651bcb2":"Asumption of Logistic Regression model\n1. Assumption #1: The Response Variable is Binary\n2. Assumption #2: The Observations are Independent\n3. Assumption #3: There is No Multicollinearity Among Explanatory Variables\n4. Assumption #4: There are No Extreme Outliers\n5. Assumption #5: There is a Linear Relationship Between Explanatory Variables and the Logit of the Response Variable\n6. Assumption #6: The Sample Size is Sufficiently Large\n\nsource: https:\/\/www.statology.org\/assumptions-of-logistic-regression\/\n\n\n## Let's assume our data meets the assumption","17aeaf7c":"If we want to include all data type, we can use argument `df.describe(include='all')`","4de0175f":"## Handling outliers","ed43ff30":"### Was there any child?","0bc3a7d9":"You can change the dtype of the dataset by using method `astype()`\n\nFor example, if you want to change column `Sex` to category then you can follow the code below:","8e44d140":"## Histogram","f37af692":"We can also choose aggregate function other than count, for example sum and mean of a value","537dd2be":"As an example, we will identify outliers in column Age. First, we will calculate Q1, Q3, and IQR. We can get Q1 and Q3 by using `describe()`","3622164c":"## Boxplot","6b328090":"Another way to check the number of rows and number of column at once is using `shape`. It will return a tuple with 2 elements, first element is number of rows in the dataset and second element is number of columns","34d17004":"### Task 1. Check the len and shape of `df_test`","f0b1fb2b":"## Fill NULL value with mean","622b095f":"To check distributions of a column, you can use 2 diagrams\n- Histogram : `hist()`\n- Boxplot : `boxplot()`","18cb92ca":"### Fill outliers with mean value","1a750802":"# Checking distribution of data","1e49a1eb":"We can also make it individually by plotting directly from the column","9432ccf2":"If we want to see the basic statistic of object data type, we can use argument `include=np.object`. This will return\n- count : number of non missing values\n- unique : number of unique values\n- top : value with the highest occurrence\n- freq : freq of the highest occurrence value","21b4bd98":"## Pivot Table","0d3cd151":"To load csv dataset, we use function `pd.read_csv`. Pandas also provide functions to load data from other formats, such as excel data dan SPSS.","ee06703c":"Data aggregation is the process of gathering data and presenting it in a summarized format. The data may be gathered from multiple data sources with the intent of combining these data sources into a summary for data analysis. This is a crucial step, since the accuracy of insights from data analysis depends heavily on the amount and quality of data used. It is important to gather high-quality accurate data and a large enough amount to create relevant results. Data aggregation is useful for everything from finance or business strategy decisions to product, pricing, operations, and marketing strategies. (Source : [www.import.io](https:\/\/www.import.io\/post\/what-is-data-aggregation-industry-examples\/))","87b480c3":"## Group by","3a933e7b":"To load the dataset, first we need to make sure the path to the dataset. Please remember that you should put the path as the string and match the name because string is case sensitive. To import and analyze dataset, we use __pandas__. __pandas__ is a fast, powerful, flexible and easy to use open source data analysis and manipulation tool, built on top of the Python programming language.'\n\nIts official documentation introduces itself as the \"fundamental high-level building block for doing practical, real world data analysis in Python\", and strive to do so by implementing many of the key data manipulation functionalities in R. This makes `pandas` a core member of many Python-based scientific computing environments.","e33a9065":"We can make histogram from  the dataframe directly","ab0eb2b2":"## Basic statistics","be0e3694":"## Data types","57704622":"## 1. What were the passengers type? (age, gender ..)","e50b55dc":"## Identify outlier","a96e2ba3":"In pandas, there are multiple datatypes. Pandas will define a datatypes for each column autoomatically when importing the data. But sometimes, but it not always right so we need to define them by ourself\n\nPandas datatypes:\n- object : Text or mixed numeric and non-numeric values\n- int64 : Integer numbers\n- float64 : Floating point numbers\n- bool : True\/False values\n- datetime64 : Date and time values\n- timedelta[ns] : Differences between two datetimes\n- category : Finite list of text values\n\nTo know data type of each column, we can use method `dtypes`","f69cddba":"__How to handle Null values__\n- Remove rows or columns with null values\n- Fill with constant value. Examples:\n    - Fill with 0\n    - Fill with central tendency of the data. Such as mean, median, mode.\n    - Fill with the first or last value (often found in time series data)\n- Fill with dynamic value. Example:\n    - Fill with mean, median, or mode of the related category label\n    - Fill with previous or next data (often found in time series data)\n    - Fill with mean, median, or mode of k previous or k next data (often found in time series data)\n- Fill with machine learning model\n    - Regression (knn, linear regression, cart, random forest)\n    - Classification (knn, logistic regression, cart, random forest)\n    - Time series model\n    - Clustering (we can utilized the centroid of clusters)\n    \nHere we will give two simple example how to handle NULL value\n- Remove rows or columns with NULL values\n- Fill with constant value","ca7e2ae1":"We learn here that the correlation between `Age` and `Fare` is low and almost zero. So we can say that Age and Fare almost don't have any correlation linearly\n\nWe can also create a correlation heatmap to visualize the correlation","c8b2b8b5":"### Calculate the metrics","09c95b0e":"# Handling Outlier","94d57780":"### Task 4. Handle outlier by changing the value with mean on `df_test`\n\ncreate a variable `df_test_no_outliers`","af8b168c":"## 2. How many people did survive?","27b330b1":"### Task 2. check the mean and standard deviation of Age in Dataset df_test","fe33652e":"__What to do when you find any Null values?__\n- Inspect why is that missing?\n    - Is it because of the data is not recorded?\n    - Is it because the object is not exist?\n    - Is it because the object doesn't have the characteristics?\n- What is the type of the missing data?\n- How many data is missing?","1581ea20":"After that, we can create lower threshold and upper threshold","1d1868f5":"To know the number of rows, we can also use `len()` function. We just need to put the dataset as the input of the function","534275be":"# Modelling: Using Logistic Regression\ndoc: https:\/\/scikit-learn.org\/stable\/modules\/generated\/sklearn.linear_model.LogisticRegression.html","99dc6990":"# Solutions","c70d6e4a":"Here, we will learn some methods to do data aggregation\n- Group by\n- Cross-Table\n- Pivot table","cadc3128":"# Correlation","cad89bb9":"## Cross-table","7764c247":"## Number of columns and rows","75550adb":"# Importing dataset","147b0c10":"### How big the family size of the passenger?","3c26e818":"### Who were mostly survived? First class vs other class?","3a0900b1":"### Task 7: create `x_test`, and `y_test` using `df_test_clean`","d5900b19":"In statistics, correlation or dependence is any statistical relationship, whether causal or not, between two random variables or bivariate data. In the broadest sense correlation is any statistical association, though it commonly refers to the degree to which a pair of variables are linearly related. Familiar examples of dependent phenomena include the correlation between the height of parents and their offspring, and the correlation between the price of a good and the quantity the consumers are willing to purchase, as it is depicted in the so-called demand curve ([wikipedia](https:\/\/en.wikipedia.org\/wiki\/Correlation_and_dependence)).\n\nThe minimum value of correlation is -1 and maximum value is 1. Negative correlation between A and B means that if A increase, B will decrease and vice versa. Positive correlation between A and B means that if A increase, then B will also increase and vice versa. Correlation 0 between A and B means that A and B is not correlated linearly","1efa53c7":"In statistics, an outlier is a data point that differs significantly from other observations (wikipedia). In practice, determining if such observation is outlier or not is a subjective exercise. And the way how to handle outlier is different case by case. The simplest way that we will try today are filling outlier with mean value and removing outlier","cb35136f":"## Remove rows or column with NULL values","99ed0505":"As explained above, identifying outliers could be objective. Here we will try a way to define outliers by using formula IQR*1.5\n\nThis formula is basically related to boxplot that we learnt above. In boxplot, there are some dots in the edge of each whiskers which visualize outliers. We can identify outliers by looking for observations that fulfill one of these two conditions\n- < Q1 - (IQR*1.5)\n- \\> Q3 + (IQR*1.5)","e7e5e80e":"There are 3 clumns with NULL values\n- Cabin have the most NULL values (77%). We will remove this column\n- Embarked have 2 NULL values only. We will remove rows with NULL values in this column\n- We will fill NULL value in Age using average","e6490bb4":"### Deleting rows","94a10276":"We can also put multiple column as the index","f37d2458":"### Who were mostly survived? Male \/ Female \/ Children?","d012ef17":"Boxplot is a diagram that can serve you the basic statistics in one picture. This diagram conclude all min, Q1, median, Q2, and max. By seeing those statistics, we can conclude the general distribution of a data\n\n![Boxplot](https:\/\/miro.medium.com\/max\/700\/1*NRlqiZGQdsIyAu0KzP7LaQ.png)","c6624114":"### Task 5. Check how many passenger were on the first class accoridng to the sex (gender) on`df_test`\n\nuse `df_test_clean`\n\nYou can use `group by`, `cross-table`, or `pivot table` ","23cc52c1":"If we want to plot one column only, we can add `column` argument"}}