{"cell_type":{"d245376c":"code","3ffaf146":"code","d8aed6c1":"code","678dbe6a":"code","7dd27a50":"code","97100037":"code","a06deb3b":"code","86c0d816":"code","7f5f4bad":"code","44f2bc38":"code","86e38733":"code","ce187d55":"code","17014880":"code","4556b646":"code","d39a6fcf":"code","ab23e926":"code","d55bf956":"code","6ede921c":"code","a248b819":"code","e10f5590":"code","487fb45e":"code","0ea8b617":"code","c6ab6787":"code","9c6407bc":"code","bf5b06a0":"code","911c3217":"code","dba7edbd":"code","245325db":"code","af36186d":"code","9e32a4e6":"code","36a6d774":"code","ecb04260":"code","e86bbb49":"code","255a4ca6":"code","a127f97e":"code","7564fca0":"code","f7f7be2c":"code","1e1d4b1c":"code","00e2c174":"code","7b777ce8":"code","6ae7b16e":"code","0bc031b2":"code","b3916cce":"code","8e3bf1be":"code","407d917b":"code","96f1ca34":"code","9c0ba6e6":"code","529688f7":"code","83b633a0":"code","fdb7644c":"code","1fbfc32c":"code","31c56ae2":"code","6edc8c81":"code","bfa57c10":"code","9498b020":"code","c1a837da":"code","ff1db735":"code","abfc50af":"code","cad04aa1":"code","077dbca9":"code","b79d5d8a":"code","6ec86ab2":"code","340bdbc7":"code","5f1f1966":"code","f2810b0d":"code","419d67b1":"code","502ac218":"code","1e532e14":"code","12b2e3c7":"code","47284060":"code","b49086c2":"code","c5f183bf":"code","01b64ea2":"code","35581ec9":"code","ccc3be35":"code","c2cab457":"code","986eb6d5":"code","2e64e7a6":"code","fee3b74a":"code","b7d6b254":"code","2ac17330":"code","12273d93":"code","2eef7d2b":"code","f07b9633":"code","69b02e15":"code","506f3f41":"code","775ed786":"code","54628373":"code","1555c665":"code","fd1d3289":"code","a7b24817":"code","7bd844b9":"code","efb537cd":"code","87f74bfa":"code","7dcce192":"code","3d522311":"code","f83f0e64":"code","808758b9":"code","f4076754":"code","8ded9792":"code","f5fa2379":"code","d1c11a1e":"code","86c80288":"code","4909e314":"code","7cbc2cbe":"code","dba8c96d":"code","237dce68":"code","6b534144":"code","20cd3e31":"code","96b499f2":"code","031b96fd":"code","29162454":"code","321ee5a6":"code","6f6e1c3d":"code","c6a6f856":"code","5444f7ae":"code","df90a800":"code","9273591d":"code","bd6192ee":"code","3af81b4e":"code","7e6c7222":"markdown","978af39b":"markdown","0da1ad66":"markdown","a77ffd59":"markdown","1190fcc3":"markdown","ba62778d":"markdown","b82413b1":"markdown","da1a13b0":"markdown","3b8bfe54":"markdown","dccbd26b":"markdown","068b6bba":"markdown","64b66a39":"markdown","9db3c362":"markdown","1d63e2b7":"markdown","f1bea0e5":"markdown","5994a0cc":"markdown","23c3a395":"markdown","fb265db6":"markdown","4693c484":"markdown","2864f30a":"markdown","ed7148c9":"markdown","fda24ba6":"markdown","eb975a88":"markdown","8bd9ae53":"markdown","398772af":"markdown","cf571eee":"markdown","852e076b":"markdown","2bde999d":"markdown","9afa84ea":"markdown","b0ada631":"markdown","a29fc031":"markdown","fba8c039":"markdown","a8f883c6":"markdown","44fd82bc":"markdown","6b79dbe2":"markdown","befb52e4":"markdown","f6a614cd":"markdown","d3cd5cd2":"markdown","70d89022":"markdown","7414ec7e":"markdown","d66d0db1":"markdown","57ba5e5f":"markdown","e219b75f":"markdown","63b9745e":"markdown","95217cc8":"markdown","42f0288a":"markdown","de99b406":"markdown","308c76ae":"markdown","2e5df96b":"markdown","04fba9f6":"markdown","8a8e1efd":"markdown","58c68d33":"markdown","7b0650aa":"markdown","26736961":"markdown","fef07033":"markdown","8949ab34":"markdown","f4b59df1":"markdown","bd92f93c":"markdown","86ca737f":"markdown","1d44e02d":"markdown","74343cff":"markdown","c44ce25e":"markdown","952fd392":"markdown","85db4410":"markdown","0d8866da":"markdown","85b75e78":"markdown","91a52c95":"markdown","41554cb7":"markdown","75095b1d":"markdown","c0817f00":"markdown","8f3bb70f":"markdown","6edc555c":"markdown","0674a7da":"markdown","74d0b6c8":"markdown","d164e20f":"markdown","5d8be695":"markdown","e2dd487b":"markdown","0e8a0590":"markdown","d721476c":"markdown","23d6308b":"markdown","937dda17":"markdown","aaec2af2":"markdown","973f8a2b":"markdown","f48d0da1":"markdown","1b0b4359":"markdown","7bc68e19":"markdown","6e9f97a0":"markdown","cd8b7b3c":"markdown","a8c80a6e":"markdown","8514aaa2":"markdown","092e187a":"markdown","b4dcd4dc":"markdown","73eaf33b":"markdown","1d1ee77b":"markdown","2573721b":"markdown"},"source":{"d245376c":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","3ffaf146":"import numpy as np\nimport pandas as pd\n\nimport seaborn as sns\nsns.set_theme(style=\"darkgrid\")\n\nimport matplotlib.pyplot as plt\n\nimport warnings\nwarnings.filterwarnings(\"ignore\")","d8aed6c1":"dataset = pd.read_csv('\/kaggle\/input\/weather-dataset-rattle-package\/weatherAUS.csv')","678dbe6a":"dataset","7dd27a50":"dataset.info()","97100037":"dataset.isnull().sum()","a06deb3b":"dataset.describe()","86c0d816":"import missingno as msno\nmsno.matrix(dataset)","7f5f4bad":"msno.bar(dataset, sort= 'descending')","44f2bc38":"categorical = [i for i in dataset.columns if dataset[i].dtype=='object']\ncategorical","86e38733":"numerical = [i for i in dataset.columns if dataset[i].dtype=='float64']\nnumerical","ce187d55":"dataset[categorical].isnull().sum()","17014880":"dataset['Date'] = pd.to_datetime(dataset['Date'])","4556b646":"dataset['Day'] = dataset['Date'].dt.day\ndataset.Day","d39a6fcf":"dataset['Month'] = dataset['Date'].dt.month\ndataset.Month","ab23e926":"dataset['Year'] = dataset['Date'].dt.year\ndataset.Year","d55bf956":"dataset.head()","6ede921c":"dataset.Location.unique()","a248b819":"dataset.Location.nunique()","e10f5590":"dataset.Location.value_counts()","487fb45e":"plt.style.use(\"classic\")\nsns.countplot(data=dataset, x=\"Location\")\nplt.grid(linewidth = 0.7)\nplt.show()","0ea8b617":"dataset.WindGustDir.unique()","c6ab6787":"dataset.WindGustDir.value_counts()","9c6407bc":"dataset['WindGustDir'].fillna(dataset['WindGustDir'].mode()[0], inplace=True)","bf5b06a0":"dataset.WindGustDir.isnull().sum()","911c3217":"plt.style.use(\"classic\")\nsns.countplot(data=dataset, x=\"WindGustDir\")\nplt.grid(linewidth = 0.7)\nplt.show()","dba7edbd":"dataset.WindDir9am.unique()","245325db":"dataset.WindDir9am.value_counts()","af36186d":"dataset['WindDir9am'].fillna(dataset['WindDir9am'].mode()[0], inplace=True)","9e32a4e6":"dataset.WindDir9am.isnull().sum()","36a6d774":"plt.style.use(\"classic\")\nsns.countplot(data=dataset, x=\"WindDir9am\")\nplt.grid(linewidth = 0.7)\nplt.show()","ecb04260":"dataset.WindDir3pm.unique()","e86bbb49":"dataset.WindDir3pm.value_counts()","255a4ca6":"dataset['WindDir3pm'].fillna(dataset['WindDir3pm'].mode()[0], inplace=True)","a127f97e":"dataset.WindDir3pm.isnull().sum()","7564fca0":"plt.style.use(\"classic\")\nsns.countplot(data=dataset, x=\"WindDir3pm\")\nplt.grid(linewidth = 0.7)\nplt.show()","f7f7be2c":"dataset.RainToday.unique()","1e1d4b1c":"dataset.RainToday.value_counts()","00e2c174":"dataset['RainToday'].fillna(dataset['RainToday'].mode()[0], inplace=True)","7b777ce8":"dataset.RainToday.isnull().sum()","6ae7b16e":"plt.style.use(\"classic\")\nsns.countplot(data=dataset, x=\"RainToday\")\nplt.grid(linewidth = 0.7)\nplt.show()","0bc031b2":"dataset.RainTomorrow.unique()","b3916cce":"dataset.RainTomorrow.value_counts()","8e3bf1be":"dataset['RainTomorrow'].fillna(dataset['RainTomorrow'].mode()[0], inplace=True)","407d917b":"dataset.RainTomorrow.isnull().sum()","96f1ca34":"plt.style.use(\"classic\")\nsns.countplot(data=dataset, x=\"RainTomorrow\")\nplt.grid(linewidth = 0.7)\nplt.show()","9c0ba6e6":"dataset[categorical].isnull().sum()","529688f7":"dataset[numerical].isnull().sum()","83b633a0":"for i in dataset:\n    if dataset[i].dtype=='float64':\n        dataset[i].replace(to_replace=np.nan, value=dataset[i].median(), inplace=True)\n    else:\n        continue","fdb7644c":"dataset.isnull().sum()","1fbfc32c":" plt.style.use('fivethirtyeight')\n# Compute the correlation matrix\ncorr = dataset.corr()\n\n# Generate a mask for the upper triangle\nmask = np.triu(np.ones_like(corr, dtype=bool))\n\n# Set up the matplotlib figure\nf, ax = plt.subplots(figsize=(8, 8))\n\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(230, 20, as_cmap=True)\n\n# Draw the heatmap with the mask and correct aspect ratio\nsns.heatmap(corr, mask=mask, cmap=cmap, vmax=.3, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","31c56ae2":"plt.figure(figsize=(14,12))\nax = sns.heatmap(corr, square=True, annot=True, fmt='.2f')\nax.set_xticklabels(ax.get_xticklabels(), rotation=90)          \nplt.show()","6edc8c81":"#  plot Numerical Data\na = 4  # number of rows\nb = 4  # number of columns\nc = 1  # initialize plot counter\nfig = plt.figure(figsize=(35,32))\nfor i in dataset:\n    if dataset[i].dtype=='float64':\n        plt.subplot(a, b, c)\n        sns.distplot(dataset[i])\n        c = c+1\n    else:\n        continue\nplt.tight_layout()\nplt.show()       ","bfa57c10":"#Soure: https:\/\/www.kaggle.com\/momincks\/rain-tomorrow-in-aus-by-xgboostclassifier : Do check him out.\n\ndf_dateplot = dataset.iloc[-950:,:]\nplt.figure(figsize=[20,5])\nplt.plot(df_dateplot['Date'],df_dateplot['MinTemp'],color='blue',linewidth=1, label= 'MinTemp')\nplt.plot(df_dateplot['Date'],df_dateplot['MaxTemp'],color='red',linewidth=1, label= 'MaxTemp')\nplt.fill_between(df_dateplot['Date'],df_dateplot['MinTemp'],df_dateplot['MaxTemp'], facecolor = '#EBF78F')\nplt.title('MinTemp vs MaxTemp by Date')\nplt.legend(loc='lower left', frameon=False)\nplt.show()","9498b020":"df_dateplot = dataset.iloc[-950:,:]\nplt.figure(figsize=[20,5])\nplt.plot(df_dateplot['Date'],df_dateplot['Rainfall'],color='violet', linewidth=2, label= 'Rainfall')\nplt.legend(loc='upper left', frameon=False)\nplt.title('Rainfall by Date')\nplt.show()","c1a837da":"df_dateplot = dataset.iloc[-950:,:]\nplt.figure(figsize=[20,5])\nplt.plot(df_dateplot['Date'],df_dateplot['WindGustSpeed'],color='violet', linewidth=2, label= 'WindGustSpeed')\nplt.legend(loc='upper left', frameon=False)\nplt.title('WindGustSpeed by Date')\nplt.show()","ff1db735":"df_dateplot = dataset.iloc[-950:,:]\nplt.figure(figsize=[20,5])\nplt.plot(df_dateplot['Date'],df_dateplot['WindSpeed9am'],color='blue', linewidth=2, label= 'WindSpeed9am')\nplt.plot(df_dateplot['Date'],df_dateplot['WindSpeed3pm'],color='green', linewidth=2, label= 'WindSpeed3pm')\nplt.legend(loc='upper left', frameon=False)\nplt.title('WindSpeed9am vs WindSpeed3pm by Date')\nplt.show()","abfc50af":"df_dateplot = dataset.iloc[-950:,:]\nplt.figure(figsize=[20,5])\nplt.plot(df_dateplot['Date'],df_dateplot['Humidity9am'],color='blue', linewidth=2, label= 'Humidity9am')\nplt.plot(df_dateplot['Date'],df_dateplot['Humidity3pm'],color='green', linewidth=2, label= 'Humidity3pm')\nplt.legend(loc='upper left', frameon=False)\nplt.title('Humidity9am vs Humidity3pm by Date')\nplt.show()","cad04aa1":"df_dateplot = dataset.iloc[-950:,:]\nplt.figure(figsize=[20,5])\nplt.plot(df_dateplot['Date'],df_dateplot['Pressure9am'],color='blue', linewidth=2, label= 'Pressure9am')\nplt.plot(df_dateplot['Date'],df_dateplot['Pressure3pm'],color='green', linewidth=2, label= 'Pressure3pm')\nplt.legend(loc='upper left', frameon=False)\nplt.title('Pressure9am vs Pressure3pm by Date')\nplt.show()","077dbca9":"df_dateplot = dataset.iloc[-950:,:]\nplt.figure(figsize=[20,5])\nplt.plot(df_dateplot['Date'],df_dateplot['Cloud9am'],color='blue', linewidth=2, label= 'Cloud9am')\nplt.plot(df_dateplot['Date'],df_dateplot['Cloud3pm'],color='green', linewidth=2, label= 'Cloud3pm')\nplt.legend(loc='upper left', frameon=False)\nplt.title('Cloud9am vs Cloud3pm by Date')\nplt.show()","b79d5d8a":"df_dateplot = dataset.iloc[-950:,:]\nplt.figure(figsize=[20,5])\nplt.plot(df_dateplot['Date'],df_dateplot['Temp9am'],color='blue', linewidth=2, label= 'Temp9am')\nplt.plot(df_dateplot['Date'],df_dateplot['Temp3pm'],color='green', linewidth=2, label= 'Temp3pm')\nplt.legend(loc='lower left', frameon=False)\nplt.title('Temp9am vs Temp3pm by Date')\nplt.show()","6ec86ab2":"dataset.drop(['Date'], axis=1, inplace=True)\ncategorical.remove('Date')","340bdbc7":"plt.figure(figsize=[25,15])\ndataset.boxplot(column= ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm'])\nplt.xticks(rotation=45)\nplt.show()","5f1f1966":"for i in dataset:\n    if dataset[i].dtype=='float64':\n        q1 = dataset[i].quantile(0.25)\n        q3 = dataset[i].quantile(0.75)\n        iqr = q3-q1\n        Lower_tail = q1 - 1.5 * iqr\n        Upper_tail = q3 + 1.5 * iqr\n        med = np.median(dataset[i])\n        for j in dataset[i]:\n            if j > Upper_tail or j < Lower_tail:\n                dataset[i] = dataset[i].replace(j, med)\n    else:\n        continue","f2810b0d":"plt.figure(figsize=[25,15])\ndataset.boxplot(column= ['MinTemp', 'MaxTemp', 'Rainfall', 'Evaporation', 'Sunshine', 'WindGustSpeed', 'WindSpeed9am', 'WindSpeed3pm', 'Humidity9am', 'Humidity3pm', 'Pressure9am', 'Pressure3pm', 'Cloud9am', 'Cloud3pm', 'Temp9am', 'Temp3pm'])\nplt.xticks(rotation=45)\nplt.show()","419d67b1":"sns.pairplot(data=dataset)\nplt.show()","502ac218":"from sklearn.preprocessing import LabelEncoder","1e532e14":"le =  LabelEncoder()\nfor i in dataset:\n    if dataset[i].dtype=='object':\n        dataset[i] = le.fit_transform(dataset[i])\n    else:\n        continue","12b2e3c7":"dataset.info()","47284060":"dataset.head()","b49086c2":"x = dataset.drop('RainTomorrow', axis=1).values\ny = dataset['RainTomorrow']","c5f183bf":"from sklearn.model_selection import train_test_split\n\nx_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state=0)","01b64ea2":"from imblearn.over_sampling import BorderlineSMOTE\nfrom imblearn.under_sampling import RandomUnderSampler\n\nfrom imblearn.pipeline import Pipeline\n\nfrom collections import Counter","35581ec9":"over = BorderlineSMOTE(sampling_strategy=0.3)\nunder = RandomUnderSampler(sampling_strategy=0.6)\n\nsteps = [('o', over), ('u', under)]","ccc3be35":"pipeline = Pipeline(steps=steps)\n\n# transform the dataset\nx_sm, y_sm = pipeline.fit_resample(x_train, y_train)\n\nprint(Counter(y_train))\nprint(Counter(y_sm))","c2cab457":"# Names of the independent variables\nfeature_names = list(dataset.drop('RainTomorrow', axis=1).columns)\n\n# Concatenate resampling train sets and test sets to build the new dataframe \nnew_x = np.concatenate((x_sm, x_test))\nnew_y = np.concatenate((y_sm, y_test))\n\n#New DataFrame with sampling data\nsm_dataset = pd.DataFrame(np.column_stack([new_y, new_x]), columns=['RainTomorrow'] + feature_names)\nsm_dataset.head()","986eb6d5":"cols = ['Location','WindGustDir','WindDir9am','WindDir3pm','RainToday','RainTomorrow','Day','Month','Year']\nfor i in cols:\n    sm_dataset[i] = sm_dataset[i].astype(int)\nsm_dataset.head()","2e64e7a6":"# Start and connect to a local H2O cluster\nimport h2o\nh2o.init(nthreads = -1)","fee3b74a":"weather = h2o.H2OFrame(sm_dataset)","b7d6b254":"weather","2ac17330":"#Convert 'Location','WindGustDir','WindDir9am','WindDir3pm','RainToday' and 'RainTomorrow' to categorical values\nweather['Location'] = weather['Location'].asfactor()\nweather['WindGustDir'] = weather['WindGustDir'].asfactor()\nweather['WindDir9am'] = weather['WindDir9am'].asfactor()\nweather['WindDir3pm'] = weather['WindDir3pm'].asfactor()\nweather['RainToday'] = weather['RainToday'].asfactor()\nweather['RainTomorrow'] = weather['RainTomorrow'].asfactor()","12273d93":"# Define features (or predictors) manually\nfeatures = ['Location','MinTemp','MaxTemp','Rainfall','Evaporation','Sunshine','WindGustDir','WindGustSpeed','WindDir9am','WindDir3pm','WindSpeed9am','WindSpeed3pm','Humidity9am','Humidity3pm','Pressure9am','Pressure3pm','Cloud9am','Cloud3pm','Temp9am','Temp3pm','RainToday','Day','Month','Year']","2eef7d2b":"# Split the H2O data frame into training\/test sets\n# so we can evaluate out-of-bag performance\nweather_split = weather.split_frame(ratios = [0.8], seed = 1234)\n\nweather_train = weather_split[0] # using 80% for training\nweather_test = weather_split[1]  # using the rest 20% for out-of-bag evaluation","f07b9633":"weather_train.shape","69b02e15":"weather_test.shape","506f3f41":"# Build a Generalized Linear Model (GLM) with default settings\n\n# Import the function for GLM\nfrom h2o.estimators.glm import H2OGeneralizedLinearEstimator\n\n# Set up GLM for binary classification\nglm_default = H2OGeneralizedLinearEstimator(family = 'binomial', model_id = 'glm_default', keep_cross_validation_predictions = True, nfolds =5, fold_assignment = \"stratified\", balance_classes=True)\n\n# Use .train() to build the model\nglm_default.train(x = features, \n                  y = 'RainTomorrow', \n                  training_frame = weather_train)","775ed786":"# Check the model performance on training dataset\nglm_default","54628373":"plt.figure(figsize=(5,5))\nvariable = glm_default.varimp_plot()\nplt.show()","1555c665":"performace = glm_default.model_performance(train=True)\nperformace.plot()","fd1d3289":"coef = glm_default.std_coef_plot()\nplt.yticks(size=6)\nplt.tight_layout()\nplt.show()","a7b24817":"# Check the model performance on test dataset\nglm_default.model_performance(weather_test)","7bd844b9":"performace = glm_default.model_performance(weather_test)\nperformace.plot()","efb537cd":"# Use GLM model to make predictions\nyhat_test_glm = glm_default.predict(weather_test)\nyhat_test_glm.head(5)","87f74bfa":"# Build a Distributed Random Forest (DRF) model with default settings\n\n# Import the function for DRF\nfrom h2o.estimators.random_forest import H2ORandomForestEstimator\n\n# Set up DRF for classification\n# Add a seed for reproducibility\ndrf_default = H2ORandomForestEstimator(model_id = 'drf_default', seed = 1234, keep_cross_validation_predictions = True, nfolds =5, fold_assignment = \"stratified\", balance_classes=True)\n\n# Use .train() to build the model\ndrf_default.train(x = features, \n                  y = 'RainTomorrow', \n                  training_frame = weather_train)","7dcce192":"# Check the DRF model summary\ndrf_default","3d522311":"plt.figure(figsize=(5,5))\nvariable = drf_default.varimp_plot()\nplt.show()","f83f0e64":"performace = drf_default.model_performance(train=True)\nperformace.plot()","808758b9":"# Check the model performance on test dataset\ndrf_default.model_performance(weather_test)","f4076754":"performace = drf_default.model_performance(weather_test)\nperformace.plot()","8ded9792":"# Use DRF model to make predictions\nyhat_test_drf = drf_default.predict(weather_test)\nyhat_test_drf.head(5)","f5fa2379":"# Build a Gradient Boosting Machines (GBM) model with default settings\n\n# Import the function for GBM\nfrom h2o.estimators.gbm import H2OGradientBoostingEstimator\n\n# Set up GBM for classification\n# Add a seed for reproducibility\ngbm_default = H2OGradientBoostingEstimator(model_id = 'gbm_default', seed = 1234, keep_cross_validation_predictions = True, nfolds =5, fold_assignment = \"stratified\", balance_classes=True)\n\n# Use .train() to build the model\ngbm_default.train(x = features, \n                  y = 'RainTomorrow', \n                  training_frame = weather_train)","d1c11a1e":"# Check the GBM model summary\ngbm_default","86c80288":"plt.figure(figsize=(5,5))\nvariable = gbm_default.varimp_plot()\nplt.show()","4909e314":"performace = gbm_default.model_performance(train=True)\nperformace.plot()","7cbc2cbe":"# Check the model performance on test dataset\ngbm_default.model_performance(weather_test)","dba8c96d":"performace = gbm_default.model_performance(weather_test)\nperformace.plot()","237dce68":"# Use GBM model to make predictions\nyhat_test_gbm = gbm_default.predict(weather_test)\nyhat_test_gbm.head(5)","6b534144":"# Build a Deep Learning (Deep Neural Networks, DNN) model with default settings\n\n# Import the function for DNN\nfrom h2o.estimators.deeplearning import H2ODeepLearningEstimator\n\n# Set up DNN for regression\ndnn_default = H2ODeepLearningEstimator(model_id = 'dnn_default', keep_cross_validation_predictions = True, nfolds =5,fold_assignment='stratified', balance_classes=True)\n\n# (not run) Change 'reproducible' to True if you want to reproduce the results\n# The model will be built using a single thread (could be very slow)\n# dnn_default = H2ODeepLearningEstimator(model_id = 'dnn_default', reproducible = True)\n\n# Use .train() to build the model\ndnn_default.train(x = features, \n                  y = 'RainTomorrow', \n                  training_frame = weather_train)","20cd3e31":"# Check the DNN model summary\ndnn_default","96b499f2":"plt.figure(figsize=(5,5))\nvariable = dnn_default.varimp_plot()\nplt.show()","031b96fd":"performace = dnn_default.model_performance(train=True)\nperformace.plot()","29162454":"# Check the model performance on test dataset\ndnn_default.model_performance(weather_test)","321ee5a6":"performace = dnn_default.model_performance(weather_test)\nperformace.plot()","6f6e1c3d":"# Use DNN model to make predictions\nyhat_test_dnn = dnn_default.predict(weather_test)\nyhat_test_dnn.head(5)","c6a6f856":"# Import the function for StackedEnsemble\nfrom h2o.estimators.stackedensemble import H2OStackedEnsembleEstimator\n\n# Set up Stacked Ensemble\nensemble = H2OStackedEnsembleEstimator(model_id = \"my_ensemble\",\n                                       base_models = [glm_default, drf_default, gbm_default, dnn_default])\n\n# use .train to start model stacking\n# GLM as the default metalearner\nensemble.train(x = features, \n               y = 'RainTomorrow', \n               training_frame = weather_train)","5444f7ae":"# Check the Stacked model summary\nensemble","df90a800":"# Check the model performance on test dataset\nensemble.model_performance(weather_test)","9273591d":"performace = ensemble.model_performance(weather_test)\nperformace.plot()","bd6192ee":"# Use Stacked Ensemble to make predictions\nyhat_test_ensemble = ensemble.predict(weather_test)\nyhat_test_ensemble.head(5)","3af81b4e":"print('GLM model (AUC) : ', glm_default.model_performance(weather_test).auc())\nprint('DRF model (AUC) : ', drf_default.model_performance(weather_test).auc())\nprint('GBM model (AUC) : ', gbm_default.model_performance(weather_test).auc())\nprint('DNN model (AUC) : ', dnn_default.model_performance(weather_test).auc())\nprint('Stacked Ensembles (AUC) : ', ensemble.model_performance(weather_test).auc())","7e6c7222":"\ud83d\udccc Builds gradient boosted classification trees, and gradient boosted regression trees on a parsed data set. The default distribution function will guess the model type based on the response column type run properly the response column must be an numeric for \u201cgaussian\u201d or an enum for \u201cbernoulli\u201d or \u201cmultinomial\u201d.","978af39b":"\ud83d\udccc We can see that the number of unique values in WindDir3pm variable is 16 and NaN values.","0da1ad66":"### **Table of Contents:**\n1. [Importing Libraries](#1)<a href='1' ><\/a> <br>\n2. [Importing Dataset](#2)<a href='2' ><\/a> <br>\n3. [Taking care of Missing Values](#3)<a href='3' ><\/a> <br>\n    3.1. [Visualizing Missing Values](#3.1)<a href='3.1' ><\/a> <br>\n    3.2. [Categorical Data](#3.2)<a href='3.2' ><\/a> <br>\n    3.3. [Numerical Data](#3.3)<a href='3.3' ><\/a> <br>\n4. [Data Visualization and Analysis](#4)<a href='4' ><\/a> <br>\n    4.1. [Heat Map Correlation](#4.1)<a href='4.1' ><\/a> <br> \n    4.2. [Distribution Plot](#4.2)<a href='4.2' ><\/a> <br>\n    4.3. [Date Plot](#4.3)<a href='4.3' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; a. [MinTemp and MaxTemp](#4.3.1)<a href='4.3.1' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; b. [Rainfall](#4.3.2)<a href='4.3.2' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; c. [WindGustSpeed](#4.3.3)<a href='4.3.3' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; d. [WindSpeed9am and WindSpeed3pm](#4.3.4)<a href='4.3.4' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; e. [Humidity9am and Humidity3pm](#4.3.5)<a href='4.3.5' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; f. &nbsp;[Pressure9am and Pressure3am](#4.3.6)<a href='4.3.6' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; g. [Cloud9am and Cloud3am](#4.3.7)<a href='4.3.7' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; h. [Temp9am and Temp3pm](#4.3.8)<a href='4.3.8' ><\/a> <br>\n    4.4. [Outliers](#4.4)<a href='4.4' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; a. [Detection](#4.4.1)<a href='4.4.1' ><\/a> <br>\n    &nbsp;&nbsp;&nbsp;&nbsp; b. [Removal](#4.4.2)<a href='4.4.2' ><\/a> <br>\n    4.5. [Pair Plot](#4.5)<a href='4.5' ><\/a> <br>\n5. [Data Preprocessing](#5)<a href='5' ><\/a> <br>\n    5.1. [Label Encoding](#5.1)<a href='5.1' ><\/a> <br>\n    5.2. [Splitting data into Train and Test Set](#5.2)<a href='5.2' ><\/a> <br>\n    5.3. [BorderlineSMOTE and RandomUnderSampler](#5.3)<a href='5.3' ><\/a> <br>\n6. [H2O](#6)<a href='6' ><\/a> <br>\n    6.1. [H2OGeneralizedLinearEstimator](#6.1)<a href='6.1' ><\/a> <br>\n    6.2. [H2ORandomForestEstimator](#6.2)<a href='6.2' ><\/a> <br>\n    6.3. [H2OGradientBoostingEstimator](#6.3)<a href='6.3' ><\/a> <br>\n    6.4. [H2ODeepLearningEstimator](#6.4)<a href='6.4' ><\/a> <br>\n    6.5. [H2OStackedEnsembleEstimator](#6.5)<a href='6.5' ><\/a> <br>\n7. [Conclusion](#7)<a href='7' ><\/a> <br>","a77ffd59":"## **Distribution Plot** <a id='4.2' ><\/a>","1190fcc3":"\ud83d\udccc We can see that the number of unique values in RainTomorrow variable is 2 and NaN values.","ba62778d":"\ud83d\udccc As I mentioned in the above plots, that Dec-Jan are months when the temperature is high but these are the months when the difference between temperature around 9am and 3pm is less as compare to the months of Jun-Aug when the difference is high.","b82413b1":"### Location ","da1a13b0":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           background-color:Beige;\n           font-size:110%;\n           letter-spacing:0.5px\">\n\n<p style=\"padding: 10px;\n              color:black;\">\n    \nHello Kagglers, <br>\n\nIn this notebook, I am going to predict whether it is going to rain in australia. But, first I am going to do deal with missing values in the dataset and then perform exploratory data analysis and learn more about the features. Then, I am going to use H2O classification models on our dataset and select the best performing one. <br>\n    So, let's get started.\n<\/p>\n<\/div> ","3b8bfe54":"\ud83d\udccc We can see that the number of unique values in RainToday variable is 2 and NaN values.","dccbd26b":"\ud83d\udccc There are no missing values in Location but let's visualize the unique values in it. ","068b6bba":"\ud83d\udccc Builds a stacked ensemble (aka \u201csuper learner\u201d) machine learning method that uses two or more H2O learning algorithms to improve predictive performance. It is a loss-based supervised learning method that finds the optimal combination of a collection of prediction algorithms.This method supports regression and binary classification.","64b66a39":"### Removal <a id='4.4.2' ><\/a>","9db3c362":"### Humidity9am and Humidity3pm <a id='4.3.5' ><\/a>","1d63e2b7":"## **Label Encoding** <a id='5.1'><\/a>","f1bea0e5":"### Detection <a id='4.4.1' ><\/a>","5994a0cc":"\ud83d\udccc Missing values in numerical data.","23c3a395":"### Cloud9am and Cloud3am <a id='4.3.7' ><\/a>","fb265db6":"## **H2ODeepLearningEstimator** <a id = '6.4'><\/a>","4693c484":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '5'><\/a>\n    \n    Data Preprocessing \n<\/div>","2864f30a":"\ud83d\udccc An outlier is an observation that lies an abnormal distance from other values in a random sample from a population.","ed7148c9":"\ud83d\udccc The above command *df.describe()* helps us to view the statistical properties of numerical variables. It excludes character variables.","fda24ba6":"\ud83d\udccc We have 145460 rows and 23 columns in our dataset. <br>\n\ud83d\udccc We can see that the dataset contains mixture of *categorical* and *numerical* variables. <br>\n\ud83d\udccc Also, there are some missing values in the dataset. Let's check it out. ","eb975a88":"\ud83d\udccc From the above plot, we can see that *Cloud9am*, *Cloud3pm*, *Evaporation*, and *Sunshine* have a lot of missing values.","8bd9ae53":"\ud83d\udccc Random undersampling involves randomly selecting examples from the majority class to delete from the training dataset. <br>\n\ud83d\udccc This has the effect of reducing the number of examples in the majority class in the transformed version of the training dataset. This process can be repeated until the desired class distribution is achieved, such as an equal number of examples for each class.","398772af":"\ud83d\udccc Cloud is the same at 5 all-around years but, there are certain months when it falls or rises. ","cf571eee":"\ud83d\udccc Replacing the missing values with the most frequent values.","852e076b":"\ud83d\udccc We can see that there are no missing values present now in our dataset. ","2bde999d":"### WindGustDir ","9afa84ea":"\ud83d\udccc Above plot shows that the *MinTemp* and *MaxTemp* relatively increases and decreases every year. <br>\n\ud83d\udccc The weather conditions are always opposite in the two hemispheres. As, the Australia is situated in the southern hemisphere. The seasons are bit different. <br>\n\ud83d\udccc As you can see that, December to February is summer; March to May is autumn; June to August is winter; and September to November is spring.","b0ada631":"### MinTemp and MaxTemp <a id='4.3.1' ><\/a>","a29fc031":"## **Visualizing Missing Values** <a id='3.1' ><\/a>","fba8c039":"\ud83d\udccc Now, I am going to encode categorical data. Label encode will convert target labels with value between 0 and n_classes-1.","a8f883c6":"### RainTomorrow","44fd82bc":"\ud83d\udccc Replacing the missing values with the most frequent values.","6b79dbe2":"\ud83d\udccc Imputing missing values in numerical data with the median.","befb52e4":"## **Outliers** <a id='4.4' ><\/a>","f6a614cd":"\ud83d\udccc Build a supervised Deep Neural Network model Builds a feed-forward multilayer artificial neural network on an H2OFrame.","d3cd5cd2":"\ud83d\udccc Wow! There are lot of missing values in our dataset.","70d89022":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '7'><\/a>\n\n    Conclusion\n<\/div>","7414ec7e":"\ud83d\udccc Pressure is high around the months of Jun-Aug and around Dec-Jan you can see that the pressure is low. <br>\n\ud83d\udccc In a low pressure area the rising air cools and this is likely to condense water vapour and form clouds, and consequently rain. <br>","d66d0db1":" <div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n     Welcome\n<\/div>","57ba5e5f":"\ud83d\udccc After detecting, we are using Median Imputation to take care of outliers. In this technique, we replace the extreme values with median values. <br>\n\ud83d\udccc It is represented by the formula IQR = Q3 \u2212 Q1. The lines of code below calculate and print the interquartile range for each of the variables in the dataset. <br>\n\ud83d\udccc It is advised to not use mean values as they are affected by outliers.","e219b75f":"From above correlation map we can see that: <br>\n\ud83d\udccc *MinTemp* and *MaxTemp* features are highly correlated (correlation coefficient = 0.73). <br>\n\ud83d\udccc *MinTemp* and *Temp9am* features are highly correlated (correlation coefficient = 0.90). <br>\n\ud83d\udccc *MinTemp* and *Temp3pm* features are highly correlated (correlation coefficient = 0.70). <br>\n\ud83d\udccc *MaxTemp* and *Temp9am* features are highly correlated (correlation coefficient = 0.88). <br>\n\ud83d\udccc *MaxTemp* and *Temp3pm* features are highly correlated (correlation coefficient = 0.97). <br>\n\ud83d\udccc *Pressure9am* and *Pressure3pm* features are highly correlated (correlation coefficient = 0.96). <br>\n\ud83d\udccc *Temp9am* and *Temp3pm* features are highly correlated (correlation coefficient = 0.85).","63b9745e":"## **H2OGradientBoostingEstimator** <a id = '6.3'><\/a>","95217cc8":"\ud83d\udccc Above plot shows that our data seems imbalance. We will take care of it later.","42f0288a":"\ud83d\udccc Being situated in southern hemisphere, the majority of rainfall occurs between December and March. <br>\n\ud83d\udccc As you can see from above plot, we can see that Dec-Jan does get a lot of rainfall but there are months like Jun-Jul when rainfall occurs too.","de99b406":"\ud83d\udccc Converting Date into datetime and then splitting it into Day, Month and Year columns.","308c76ae":"### Temp9am and Temp3pm <a id='4.3.8' ><\/a>","2e5df96b":"### WindDir9am ","04fba9f6":"<div style=\"color:black;\n           display:fill;\n           border-radius:5px;\n           border:2px solid DodgerBlue;\n           background-color:white;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\">\n    \n    Thank You!\n<\/div>","8a8e1efd":"\ud83d\udccc Replacing the missing values with the most frequent values.","58c68d33":"\ud83d\udccc H2O from Python is a tool for rapidly turning over models, doing data munging, and building applications in a fast, scalable environment without any of the mental anguish about parallelism and distribution of work.","7b0650aa":"## **Numerical Data** <a id='3.2' ><\/a>","26736961":"## **H2ORandomForestEstimator** <a id = '6.2'><\/a>","fef07033":"## **BorderlineSMOTE and RandomUnderSampler** <a id='5.3'><\/a>","8949ab34":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '6'><\/a>\n\n    H2O \n<\/div>","f4b59df1":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='1'><\/a>\n    \n    Importing Libraries \n<\/div>","bd92f93c":"\ud83d\udccc Replacing the missing values with the most frequent values.","86ca737f":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n            letter-spacing:0.5px\"> <a id='4'><\/a>\n    \n    Data Visualization and Analysis \n<\/div>","1d44e02d":"## **Date Plot** <a id='4.3' ><\/a>","74343cff":"\ud83d\udccc From above distribution plot, we can see that certain features are same around few parts of x-axis like WindSpeed9am and WindSpeed3pm is same at 15-20 etc.  <br>","c44ce25e":"### RainToday","952fd392":"\ud83d\udccc Builds a Random Forest Model on an H2OFrame.","85db4410":"## **H2OStackedEnsembleEstimator** <a id = '6.5'><\/a>","0d8866da":"\ud83d\udccc As you can see, *object* data type is converted to *int64* data type.","85b75e78":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '2'><\/a>\n    \n    Importing Dataset \n<\/div>","91a52c95":"## **Heat Map Correlation** <a id='4.1' ><\/a>","41554cb7":"### Rainfall <a id='4.3.2' ><\/a>","75095b1d":"### WindSpeed9am and WindSpeed3pm <a id='4.3.4' ><\/a>","c0817f00":"\ud83d\udccc As you can see there are no missing values now.","8f3bb70f":"<div style=\"color:white;\n           display:fill;\n           border-radius:5px;\n           background-color:LightSlateGray;\n           font-size:150%;\n           text-align:center;\n           letter-spacing:0.5px\"> <a id = '3'><\/a>\n\n    Taking care of Missing Values \n<\/div>","6edc555c":"### Pressure9am and Pressure3am <a id='4.3.6' ><\/a>","0674a7da":"\ud83d\udccc *WindSpeed9am* and *WindSpeed3pm* are relatively same around certain months.","74d0b6c8":"### WindDir3pm","d164e20f":"## **Splitting data into Train and Test Set** <a id='5.2'><\/a>","5d8be695":"\ud83d\udccc Replacing the missing values with the most frequent values.","e2dd487b":"\ud83d\udccc From the above graphs, we can see that the outliers in our dataset have been taken care of.","0e8a0590":"\ud83d\udccc Comparison of Model Performance on Test Data","d721476c":"\ud83d\udccc From the above dataset, we can see that our Encoded features have become float type. Let's convert them into int type.","23d6308b":"\ud83d\udccc From above plot we can see that the Humidity is high around Jun-Jul and also during that time, there is good difference between humidity around 9am and 3pm. ","937dda17":"### WindGustSpeed <a id='4.3.3' ><\/a>","aaec2af2":"\ud83d\udccc We can see that the number of unique values in Location variable is 49.","973f8a2b":"\ud83d\udccc BorderlineSMOTE is a popular extension to SMOTE involves selecting those instances of the minority class that are misclassified, such as with a k-nearest neighbor classification model. <br>\n\ud83d\udccc Instead of generating new synthetic examples for the minority class blindly, we would expect the Borderline-SMOTE method to only create synthetic examples along the decision boundary between the two classes.","f48d0da1":"\ud83d\udccc Splitting our dataset in Categorical and Numerical values.","1b0b4359":"\ud83d\udccc We can see that the number of unique values in WindGustDir variable is 16 and NaN values.","7bc68e19":"## **Categorical Data** <a id='3.2' ><\/a>","6e9f97a0":"### Date ","cd8b7b3c":"\ud83d\udccc We can see that the number of unique values in WindDir9am variable is 16 and NaN values.","a8c80a6e":"\ud83d\udccc We are going to plot features with datetime. Here, I am going to use date from last 3 years.","8514aaa2":"\ud83d\udccc In this notebook, we are using Box Plot to detect the outliers of each features in our dataset, where any point above or below the whiskers represent an outlier. This is also known as \u201cUnivariate method\u201d as here we are using one variable outlier analysis. <br>","092e187a":"## **H2OGeneralizedLinearEstimator** <a id = '6.1'><\/a>","b4dcd4dc":"## Pair Plot <a id='4.5' ><\/a>","73eaf33b":"\ud83d\udccc Build a Generalized Linear Model Fit a generalized linear model, specified by a response variable, a set of predictors, and a description of the error distribution.","1d1ee77b":"\ud83d\udccc After dealing with missing values in the dataset and extensive data analysis of the features. I got to know more about how features are correlated to each other. <br>\n\ud83d\udccc I implemented BorderlineSMOTE and RandomUnderSampler techniques on our features to deal with the imbalance data. <br>\n\ud83d\udccc Then, I used different classification models from H2O to see how it performs on the dataset. I got pretty good results with AUC, precision, and recall score. <br>\n\ud83d\udccc With that, I concluded that the Stacked Ensembles model is the best fit for our dataset. But, as I have used default parameters for our models. So, the other models could be tuned and make the other models better.","2573721b":"\ud83d\udccc In Australia, wind speed is usually moderate. But, from above plot we can see that Dec-Feb is the windiest months."}}