{"cell_type":{"804c5bd9":"code","08802411":"code","b8368f7c":"code","b7f89176":"code","fe0173d1":"code","d6bfbde0":"code","e50fe948":"markdown","b03a1f76":"markdown"},"source":{"804c5bd9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport pandas as pd\nimport numpy as np\nimport time,sys,datetime\nimport os,requests,math,string,itertools,fractions,heapq,collections,re,array,bisect\nfrom sqlalchemy import create_engine\nfrom dateutil.relativedelta import relativedelta\nimport seaborn as sns\nimport matplotlib.pyplot as plt\nimport matplotlib as mpl\n%matplotlib inline\npd.set_option('display.max_columns', 500)\nimport matplotlib.dates as mdates\n\nfrom sklearn.cluster import DBSCAN\nfrom sklearn import metrics\nfrom sklearn.datasets.samples_generator import make_blobs\nfrom sklearn.preprocessing import StandardScaler\n\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\nseed = 11389\n","08802411":"df = pd.read_csv('..\/input\/dataset_X.csv')\n","b8368f7c":"df.head()","b7f89176":"df.describe()","fe0173d1":"dft = pd.DataFrame(StandardScaler().fit_transform(df.drop(['id'], axis = 1)))\ndft.describe()","d6bfbde0":"db = DBSCAN(eps=0.3, min_samples=100).fit(dft.sample(100000, random_state=0))\ncollections.Counter(db.labels_)","e50fe948":"## Idea: Request values in different clusters to start\n\n1. Cluster the points\n2. Choose K points from each of N cluster\n3. Request values for these KxN points only\n4. Use active learning to decide which more points to get","b03a1f76":"# Conclusion\nNo clusters found. The features seem to cover the space uniformly. Like a Monte Carlo over the function in question."}}