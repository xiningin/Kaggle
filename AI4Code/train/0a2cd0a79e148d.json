{"cell_type":{"9a754893":"code","3f483074":"code","1fc2e144":"code","24a4e233":"code","6b5ba4d3":"code","c86c6aca":"code","870f1d89":"code","f82ae64d":"code","8cb72521":"code","0bfc615c":"code","f10aa663":"code","8256c450":"code","b02c90a4":"code","745e3f89":"code","4217ceff":"code","6aba7761":"code","17ada2de":"markdown","805ee9db":"markdown","96eb4130":"markdown","30ca090e":"markdown","d10a6819":"markdown","9f95e59f":"markdown","2adea9be":"markdown","ed472db4":"markdown","636dd29d":"markdown","de26e49d":"markdown","9bb7dfa0":"markdown","190317cc":"markdown","f246d80f":"markdown"},"source":{"9a754893":"import os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","3f483074":"import numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nfrom sklearn.model_selection import cross_val_predict\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.ensemble import RandomForestRegressor\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.metrics import accuracy_score\nfrom sklearn.metrics import r2_score\n\nimport matplotlib.pyplot as plt","1fc2e144":"df = pd.read_csv(\"\/kaggle\/input\/tmdb-movie-metadata\/tmdb_5000_movies.csv\")\ndf.head()","24a4e233":"df['profitable'] = df.revenue > df.budget\ndf['profitable'] = df['profitable'].astype(int)\n\nregression_target = 'revenue'\nclassification_target = 'profitable'\n\ndf['profitable'].value_counts()","6b5ba4d3":"df = df.replace([np.inf, -np.inf], np.nan)\ndf = df.dropna(how=\"any\")\ndf.shape","c86c6aca":"continuous_covariates = ['budget', 'popularity', 'runtime', 'vote_count', 'vote_average']\noutcomes_and_continuous_covariates = continuous_covariates + [regression_target, classification_target]\nplotting_variables = ['budget', 'popularity', regression_target]\n\naxes = pd.plotting.scatter_matrix(df[plotting_variables], alpha=0.15, \\\n       color=(0,0,0), hist_kwds={\"color\":(0,0,0)}, facecolor=(1,0,0))\nplt.show()\nprint(df[outcomes_and_continuous_covariates].skew())","870f1d89":"for covariate in ['budget', 'popularity', 'runtime', 'vote_count', 'revenue']:\n    df[covariate] = df[covariate].apply(lambda x: np.log10(1+x))\nprint(df[outcomes_and_continuous_covariates].skew())","f82ae64d":"df.to_csv(\"movies_clean.csv\")","8cb72521":"import warnings\nwarnings.filterwarnings(\"ignore\")\ndf = pd.read_csv('movies_clean.csv')","0bfc615c":"# Define all covariates and outcomes from `df`.\nregression_target = 'revenue'\nclassification_target = 'profitable'\nall_covariates = ['budget', 'popularity', 'runtime', 'vote_count', 'vote_average']\n\nregression_outcome = df[regression_target]\nclassification_outcome = df[classification_target]\ncovariates = df[all_covariates]\n\n# Instantiate all regression models and classifiers.\nlinear_regression = LinearRegression()\nlogistic_regression = LogisticRegression()\nforest_regression = RandomForestRegressor(max_depth=4, random_state=0)\nforest_classifier = RandomForestClassifier(max_depth=4, random_state=0)","f10aa663":"def correlation(estimator, X, y):\n    predictions = estimator.fit(X, y).predict(X)\n    return r2_score(y, predictions)\n    \ndef accuracy(estimator, X, y):\n    predictions = estimator.fit(X, y).predict(X)\n    return accuracy_score(y, predictions)","8256c450":"from sklearn.model_selection import cross_val_score\nlinear_regression_scores = cross_val_score(linear_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nforest_regression_scores = cross_val_score(forest_regression, covariates, regression_outcome, cv=10, scoring=correlation)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(linear_regression_scores, forest_regression_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Regression Score\")\nplt.ylabel(\"Forest Regression Score\")\n\n# Show the plot.\nplt.show()","b02c90a4":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Classification Score\")\nplt.ylabel(\"Forest Classification Score\")\n\n# Show the plot.\nplt.show()","745e3f89":"positive_revenue_df = df[df[\"revenue\"] > 0]\n\nregression_outcome = positive_revenue_df[regression_target]\nclassification_outcome = positive_revenue_df[classification_target]\ncovariates = positive_revenue_df[all_covariates]\n\nlinear_regression = LinearRegression()\nlogistic_regression = LogisticRegression()\nforest_regression = RandomForestRegressor(max_depth=4, random_state=0)\nforest_classifier = RandomForestClassifier(max_depth=4, random_state=0)\nlinear_regression_scores = cross_val_score(linear_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nforest_regression_scores = cross_val_score(forest_regression, covariates, regression_outcome, cv=10, scoring=correlation)\nlogistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\nnp.mean(forest_regression_scores)","4217ceff":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome, cv=10, scoring=accuracy)\n\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Regression Score\")\nplt.ylabel(\"Forest Regression Score\")\n\nplt.show();\n\nforest_classifier.fit(positive_revenue_df[all_covariates], positive_revenue_df[classification_target])\nsorted(list(zip(all_covariates, forest_classifier.feature_importances_)), key=lambda tup: tup[1])","6aba7761":"logistic_regression_scores = cross_val_score(logistic_regression, covariates, classification_outcome, cv=10, scoring=accuracy)\nforest_classification_scores = cross_val_score(forest_classifier, covariates, classification_outcome,cv=10, scoring=accuracy)\n\n# Plot Results\nplt.axes().set_aspect('equal', 'box')\nplt.scatter(logistic_regression_scores, forest_classification_scores)\nplt.plot((0, 1), (0, 1), 'k-')\n\nplt.xlim(0, 1)\nplt.ylim(0, 1)\nplt.xlabel(\"Linear Classification Score\")\nplt.ylabel(\"Forest Classification Score\")\n\n# Show the plot.\nplt.show()\n# Print the importance of each covariate in the random forest classification.\nforest_classifier.fit(positive_revenue_df[all_covariates], classification_outcome)\nfor row in zip(all_covariates, forest_classifier.feature_importances_,):\n        print(row)","17ada2de":"we will compute the cross-validated performance for the linear and random forest regression models.","805ee9db":"It appears that the variables `budget`, `popularity`, `runtime`, `vote_count`, and `revenue` are all right-skewed. In this exercise, we will transform these variables to eliminate this skewness. Specifically, we will use the `np.log10()` method. Because some of these variable values are exactly 0, we will add a small positive value to each to ensure it is defined; this is necessary because log(0) is negative infinity.","96eb4130":"In this part, we will primarily use the two models we recently discussed: linear\/logistic regression and random forests to perform prediction and classification. We will use these methods to predict revenue, and we will use logistic regression to classify whether a movie was profitable.\n\nNow, we will instantiate regression and classification models. Code is provided that prepares the covariates and outcomes we will use for data analysis.","30ca090e":"We saw that predicting revenue was only moderately successful. It might be the case that predicting movies that generated precisely no revenue is difficult. In the next three exercises, we will exclude these movies, and rerun the analyses to determine if the fits improve. In this exercise, we will rerun the regression analysis for this subsetted dataset.","d10a6819":"We will compute cross-validated performance for the linear and random forest classification models for positive revenue movies only.","9f95e59f":"First, we will import several libraries. `scikit-learn` (**sklearn**) contains helpful statistical models, and we'll use the `matplotlib.pyplot` library for visualizations. Of course, we will use `numpy` and `pandas` for data manipulation throughout.","2adea9be":"We will define the regression and classification outcomes. Specifically, we will use the `revenue` column as the target for regression. For classification, we will construct an indicator of profitability for each movie.","ed472db4":"Some variables in the dataset are already numeric and perhaps useful for regression and classification. In this exercise, we will store the names of these variables for future use. We will also take a look at some of the continuous variables and outcomes by plotting each pair in a scatter plot. Finally, we will evaluate the skew of each variable.","636dd29d":"We will compute cross-validated performance for the linear and random forest classification models.","de26e49d":"We will now create two functions that compute a model's score. For regression models, we will use correlation as the score. For classification models, we will use accuracy as the score.","9bb7dfa0":"Let's now save our dataset.","190317cc":"We will compute the cross-validated performance for the linear and random forest regression models for positive revenue movies only.","f246d80f":"For simplicity, we will proceed by analyzing only the rows without any missing data. Now, we will remove rows with any infinite or missing values."}}