{"cell_type":{"cbecb4ad":"code","8931ed93":"code","22b0ff2c":"code","ed61ed10":"code","3c8a7a38":"code","11750427":"code","cf062d09":"code","35d7dde5":"code","6d9c8e5f":"code","3d54746c":"code","b7c8013a":"code","8efe40e4":"code","cfdde8a7":"code","159053cd":"code","f66e18ca":"code","62bfb8ec":"code","ad52d550":"code","63004871":"code","8771e8ba":"code","677fd57b":"code","c64d8207":"code","d8189b02":"code","5b77c6ea":"code","f581df0b":"markdown","adce068f":"markdown","4d21babb":"markdown","3a6dd8aa":"markdown","db480f94":"markdown"},"source":{"cbecb4ad":"#Importing packages for the necessary purposes\n\n# Data manipulation\/analysis\nimport numpy as np\nimport keras \nimport pandas as pd\nimport tensorflow as tf\n\n# Text preprocessing\nimport re\nimport nltk\nimport string\nfrom bs4 import BeautifulSoup\nfrom nltk.corpus import stopwords\nfrom nltk.stem.porter import PorterStemmer\nfrom keras.preprocessing.sequence import pad_sequences\nfrom tensorflow.keras.preprocessing.text import Tokenizer\nfrom tensorflow.keras.preprocessing.sequence import pad_sequences\n\n# Modelling\nfrom keras.models import Model\nfrom keras.layers import Dense, Input, Dropout, LSTM, Activation,Flatten,Bidirectional,GlobalMaxPool1D\nfrom keras.layers.embeddings import Embedding\nfrom keras.preprocessing import sequence\nfrom keras.initializers import glorot_uniform\n\n# Visualisation\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nsns.set(style=\"whitegrid\", context='talk')","8931ed93":"import pandas as pd\ndata = pd.read_csv('..\/input\/imdb-dataset-of-50k-movie-reviews\/IMDB Dataset.csv')\nprint(data.head())","22b0ff2c":"data.describe()","ed61ed10":"#Convering sentiment values to either 0 or 1\n# Positive = 1 and negative = 0\n\ndef convert_sentiment(word):\n    if word == 'positive':\n        new_value = 1\n    else:\n        new_value = 0    \n    return new_value\n\ndata['new_sentiment'] = data['sentiment'].apply(convert_sentiment)","3c8a7a38":"#Removing punctutation. We use string.punctuation in python which consists of !\"#$%&\\'()*+,-.\/:;<=>?@[\\\\]^_{|}~`\ndef remove_punctuation(text):\n    return text.translate(str.maketrans('', '', string.punctuation))\n\ndata['without_punctuation'] = data['review'].apply(lambda text: remove_punctuation(text))","11750427":"#Removing stopwords\nstopword_list=nltk.corpus.stopwords.words('english')\ndef remove_stopwords(text):\n    return \" \".join([word for word in str(text).split() if word not in stopword_list])\n\ndata[\"without_stop\"] = data['without_punctuation'].apply(lambda text: remove_stopwords(text))","cf062d09":"#Stemming\nstemmer = PorterStemmer()\ndef stem_words(text):\n    return \" \".join([stemmer.stem(word) for word in text.split()])\n\ndata['stemmed'] = data['without_stop'].apply(lambda text: stem_words(text))","35d7dde5":"#Removing URLs\ndef remove_url(text):\n    url = re.compile(r'https?:\/\/\\S+|www\\.\\S+')\n    return url.sub(r'', text)\n\ndata['no_url'] = data['stemmed'].apply(lambda text: remove_url(text))","6d9c8e5f":"#Removing html strips\ndef remove_html(text):\n    return BeautifulSoup(text, \"lxml\").text\n\ndata['no_html'] = data['no_url'].apply(lambda text: remove_html(text))","3d54746c":"#Converting to lower case\ndata['final_reviews'] = data['no_html'].str.lower()","b7c8013a":"#Finding max and min length of reviews to decide on a suitable length to implement padding\nmeasurer = np.vectorize(len)\nmax_len = measurer(data['final_reviews']).max(axis=0)\nmin_len = measurer(data['final_reviews']).min(axis=0)\nmean_len = measurer(data['final_reviews']).mean(axis=0)\n\nprint(max_len)\nprint(min_len)\nprint(mean_len)\n","8efe40e4":"#Finding the number of positive and negative sentiment values available\ndata['new_sentiment'].value_counts()","cfdde8a7":"#Since we have a balanced dataset, we can proceed to split the dataset with 80% of data in the train dataset and 20% of data in the test dataset.\nReview_train=data.final_reviews[:40000]\nS_train=data.new_sentiment[:40000]\n\nReview_test=data.final_reviews[40000:]\nS_test=data.new_sentiment[40000:]","159053cd":"#Tokenization \n#We also specify the max number of words in the dictionary and a token to represent words that are out of the vocabulary\/dictionary (OOV)\n\nvocab_size= 4000\ntokenizer = Tokenizer(num_words = vocab_size, oov_token=\"<OOV>\")\ntokenizer.fit_on_texts(Review_train)\ntokenizer.fit_on_texts(Review_test)","f66e18ca":"#Representing each review in terms of the numbers that represent each word in it\nR_train_input = tokenizer.texts_to_sequences(Review_train)\nR_test_input = tokenizer.texts_to_sequences(Review_test)","62bfb8ec":"#Inserting padding for sequences\nmaxlen = 700\nR_train_input = pad_sequences(R_train_input, maxlen=maxlen, padding = 'post')\nR_test_input = pad_sequences(R_test_input, maxlen=maxlen, padding = 'post')","ad52d550":"#Converting the data column into an array to make further implementations easier\nR_train = np.array(R_train_input)\nS_train = np.array(S_train)\nR_test = np.array(R_test_input)\nS_test = np.array(S_test)","63004871":"#Simple model\nembedding_dim =32\nmodel = keras.Sequential([\n    Embedding(vocab_size, embedding_dim, input_length=maxlen),\n    Flatten(),\n    Dense(100, activation='relu'),\n    Dropout(0.5),\n    Dense(1, activation='sigmoid')])\n\nmodel.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel.summary()","8771e8ba":"num_epochs = 20\nmodel.fit(R_train, S_train, epochs=num_epochs,batch_size = 64, validation_split=0.1, shuffle=True)","677fd57b":"model.evaluate(R_test, S_test, batch_size=64)","c64d8207":"#Multiple directional lstm model\nembedding_dim = 32\nmodel_multiple_bidi_lstm = tf.keras.Sequential([\n    tf.keras.layers.Embedding(vocab_size,embedding_dim, input_length=maxlen),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim, return_sequences=True)),\n    tf.keras.layers.Bidirectional(tf.keras.layers.LSTM(embedding_dim)),\n    tf.keras.layers.Dense(1, activation='sigmoid')])\n\nmodel_multiple_bidi_lstm.compile(loss='binary_crossentropy',optimizer='adam',metrics=['accuracy'])\nmodel_multiple_bidi_lstm.summary()","d8189b02":"num_epochs = 5\nmodel_multiple_bidi_lstm.fit(R_train, S_train, epochs=num_epochs,batch_size = 64, validation_split=0.1, shuffle=True)","5b77c6ea":"model_multiple_bidi_lstm.evaluate(R_test, S_test, batch_size=64)","f581df0b":"# **Processing text to be inputted into a model**","adce068f":"# **Creating the model**\n\n* Simple model \n* LSTM\n* Bidirectional LSTM\n","4d21babb":"# **Spitting data into the train and test datasets**","3a6dd8aa":"#  **Preprocessing of text**","db480f94":"# **Importing and understanding data**"}}