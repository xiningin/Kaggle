{"cell_type":{"e60b4573":"code","4c12559d":"code","159188c0":"code","09142e11":"code","fd00f04c":"code","2455cfc5":"code","f4df0ea3":"code","034c20d4":"code","7f7329d5":"code","835f10a4":"code","be512ee0":"code","c7203112":"code","70685cb4":"code","977a0858":"code","e6c4694b":"code","afb1fc6e":"code","1fd77db7":"code","2139e37f":"code","8316db69":"code","82b16f60":"code","48358353":"code","19a76bd5":"code","14db6b63":"code","266e1e3d":"code","71320b2f":"code","0b2be043":"code","96519f22":"code","91b0b7ed":"code","5b2de34f":"code","06be32ec":"code","e1bcaf2a":"code","f34240fa":"code","13dafedb":"code","d52a6a3f":"code","43dfe53d":"code","0c045d19":"code","98b19b51":"code","d2442711":"code","47eec2f2":"code","2ba1213d":"code","609739f9":"code","85e129da":"code","df0cce42":"code","d3625ebf":"code","ed0a6d94":"code","0f14b662":"code","82c3377a":"code","0703d121":"code","f2779e0a":"code","31d02b07":"code","0821a234":"code","6d8d3866":"code","439e236b":"code","63944457":"code","0daeea90":"code","bf62965f":"code","e24c5b1d":"code","cc9dc061":"code","3fabc46d":"code","0c5b6fc2":"code","b9a25b4c":"code","30927a5f":"code","dc61cb52":"code","d6f65985":"code","87d61aea":"code","eda64251":"code","6d3bcc01":"code","a970ff26":"code","c964a1c0":"code","45475bdc":"code","fbf47a66":"code","3133209e":"code","69aea044":"code","87179ae6":"markdown","17716495":"markdown","abfa2a14":"markdown","30e869b2":"markdown","3afb0a53":"markdown","49239870":"markdown","c2902a53":"markdown"},"source":{"e60b4573":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","4c12559d":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline","159188c0":"train_data = pd.read_csv(\"\/kaggle\/input\/used-cars-price-prediction\/train-data.csv\", na_values = [\"null bhp\"])\ntest_data = pd.read_csv(\"\/kaggle\/input\/used-cars-price-prediction\/test-data.csv\", na_values = [\"null bhp\"])","09142e11":"train_data.head()","fd00f04c":"train_data.info()","2455cfc5":"plt.figure(figsize = (16,8))\nsns.countplot(x = train_data['Location'])","f4df0ea3":"plt.figure(figsize = (16,8))\nsns.countplot(x = train_data['Location'], hue = train_data[\"Fuel_Type\"])","034c20d4":"plt.figure(figsize = (16,8))\nsns.boxplot(x=\"Location\", y = \"Price\", data = train_data)","7f7329d5":"train_data.isnull().sum()","835f10a4":"# Deleting New_Price column since it has too many null values\n\ntrain_data.drop(\"New_Price\", axis = 1, inplace = True)","be512ee0":"train_data.isnull().sum()","c7203112":"train_data.corr()","70685cb4":"# removing Unnamed: 0 since it has no role\n\ntrain_data.drop(\"Unnamed: 0\", axis = 1, inplace = True)","977a0858":"train_data[\"Seats\"].value_counts()","e6c4694b":"# since most of the cars have 5 Seats, we will fill the null values in Seats columns as \"5\"\n\ntrain_data[\"Seats\"].fillna(train_data[\"Seats\"].value_counts().values[0], inplace = True)","afb1fc6e":"train_data.isnull().sum()","1fd77db7":"def convert_power_data(val):\n    if not pd.isnull(val):\n        return float(val.split(' ')[0])\n    return val\n\ntrain_data[\"Power\"] = train_data[\"Power\"].apply(lambda val: convert_power_data(val))","2139e37f":"plt.figure(figsize = (16,8))\nsns.scatterplot(x = train_data[\"Location\"], y = train_data[\"Price\"])","8316db69":"plt.figure(figsize = (16,8))\nsns.scatterplot(x = train_data[\"Power\"], y = train_data[\"Price\"])","82b16f60":"train_data[\"Power\"].mean()","48358353":"train_data[\"Power\"].fillna(train_data[\"Power\"].mean(), inplace = True)","19a76bd5":"def convert_engine_data(val):\n    if not pd.isnull(val):\n        return float(val.split(' ')[0])\n    return val\n\ntrain_data[\"Engine\"] = train_data[\"Engine\"].apply(lambda val: convert_power_data(val))","14db6b63":"plt.figure(figsize = (16,8))\nsns.scatterplot(x = train_data[\"Engine\"], y = train_data[\"Price\"])","266e1e3d":"train_data[\"Engine\"].fillna(train_data[\"Engine\"].median(), inplace = True)","71320b2f":"def convert_mileage_data(val):\n    if not pd.isnull(val):\n        return float(val.split(' ')[0])\n    return val\n\ntrain_data[\"Mileage\"] = train_data[\"Mileage\"].apply(lambda val: convert_power_data(val))","0b2be043":"train_data.dropna(inplace = True)","96519f22":"train_data.info()","91b0b7ed":"# Dropping Name Column\n\ntrain_data.drop([\"Name\", \"Location\"], axis = 1, inplace = True)","5b2de34f":"train_data.head()","06be32ec":"import datetime\ntrain_data['Total Years'] = datetime.datetime.now().year - train_data[\"Year\"]","e1bcaf2a":"train_data.head()","f34240fa":"train_data.drop('Year', axis = 1, inplace = True)","13dafedb":"train_data[\"Price\"] = train_data[\"Price\"] * 100000","d52a6a3f":"train_data.columns","43dfe53d":"cat_features = ['Fuel_Type', 'Transmission', 'Owner_Type']\nout_features = 'Price'","0c045d19":"from sklearn.preprocessing import LabelEncoder\n\nlbl_encoders = {}\nlbl_encoders[\"Fuel_Type\"] = LabelEncoder()\nlbl_encoders[\"Fuel_Type\"].fit_transform(train_data[\"Fuel_Type\"])","98b19b51":"lbl_encoders = {}\nfor features in cat_features:\n    lbl_encoders[features] = LabelEncoder()\n    train_data[features] = lbl_encoders[features].fit_transform(train_data[features])","d2442711":"train_data","47eec2f2":"### stacking and converting into tensors\n\ncat_features = np.stack([train_data[\"Fuel_Type\"], train_data[\"Transmission\"], train_data[\"Owner_Type\"]], axis = 1)\ncat_features","2ba1213d":"import torch\ncat_features = torch.tensor(cat_features, dtype = torch.int64)\ncat_features","609739f9":"cont_features = []\nfor i in train_data.columns:\n    if i in ['Fuel_Type', 'Transmission', 'Owner_Type', 'Price']:\n        pass\n    else:\n        cont_features.append(i)\n        \ncont_features","85e129da":"cont_features = np.stack([train_data[i].values for i in cont_features], axis = 1)\ncont_features = torch.tensor(cont_features, dtype = torch.float)\ncont_features","df0cce42":"cont_features.dtype","d3625ebf":"y=torch.tensor(train_data['Price'].values,dtype=torch.float).reshape(-1,1)\ny","ed0a6d94":"cat_features.shape, cont_features.shape, y.shape","0f14b662":"cat_dims = [train_data[i].nunique() for i in [\"Fuel_Type\", \"Transmission\", \"Owner_Type\"]]\ncat_dims","82c3377a":"embedding_dim = [(i, min(50, (i+1) \/\/ 2)) for i in cat_dims]\nembedding_dim","0703d121":"import torch\nimport torch.nn as nn\n\nembed_rep = nn.ModuleList([nn.Embedding(i,e) for i,e in embedding_dim])\n\nembed_rep","f2779e0a":"embedding_value = []\nfor ind, e in enumerate(embed_rep):\n    embedding_value.append(e(cat_features[:, ind]))\n    \nembedding_value","31d02b07":"z = torch.cat(embedding_value, 1)\nz","0821a234":"drpout = nn.Dropout(0.4)\nz = drpout(z)\nz","6d8d3866":"class UsedCarPricePredictionNN(nn.Module):\n    def __init__(self, cat_dim, n_cont, layers, out_sz, p=0.5):\n        super().__init__()\n        embedded_dim = [(i, min(50, (i+1) \/\/ 2)) for i in cat_dim]\n        self.embd_list = nn.ModuleList([nn.Embedding(inp, out) for inp, out in embedded_dim])\n        self.drpout = nn.Dropout(p)\n        self.batchnorm = nn.BatchNorm1d(n_cont)\n        \n        layerslist = []\n        n_emb = sum([out for inp, out in embedded_dim])\n        n_in = n_emb + n_cont\n        \n        for i in layers:\n            layerslist.append(nn.Linear(n_in, i))\n            layerslist.append(nn.ReLU(inplace = True))\n            layerslist.append(nn.BatchNorm1d(i))\n            layerslist.append(nn.Dropout(p))\n            n_in = i\n        layerslist.append(nn.Linear(layers[-1], out_sz))\n        \n        self.layers = nn.Sequential(* layerslist)\n        \n        \n    def forward(self, x_cat, x_cont):\n        embeddings = []\n        for i, e in enumerate(self.embd_list):\n            embeddings.append(e(x_cat[:,i]))\n        x = torch.cat(embeddings, 1)\n        x = self.drpout(x)\n        \n        x_cont = self.batchnorm(x_cont)\n        \n        x = torch.cat([x, x_cont], axis=1)\n        \n        x = self.layers(x)\n        \n        return x\n        \n        ","439e236b":"torch.manual_seed(100)\n\nmodel = UsedCarPricePredictionNN(cat_dims, 6, [100, 50], 1, p = 0.4)","63944457":"model","0daeea90":"loss_function = nn.MSELoss()\noptimizer = torch.optim.Adam(model.parameters(), lr = 0.05)","bf62965f":"cat_features.shape, cont_features.shape, y.shape","e24c5b1d":"batch_size=6000\ntest_size=int(batch_size*0.15)\ntrain_categorical=cat_features[:batch_size-test_size]\ntest_categorical=cat_features[batch_size-test_size:batch_size]\ntrain_cont=cont_features[:batch_size-test_size]\ntest_cont=cont_features[batch_size-test_size:batch_size]\ny_train=y[:batch_size-test_size]\ny_test=y[batch_size-test_size:batch_size]","cc9dc061":"len(train_categorical),len(test_categorical),len(train_cont),len(test_cont),len(y_train),len(y_test)","3fabc46d":"epochs=2400\nfinal_losses=[]\nfor i in range(epochs):\n    i=i+1\n    y_pred=model(train_categorical,train_cont)\n    loss=torch.sqrt(loss_function(y_pred,y_train)) ### RMSE\n    final_losses.append(loss)\n    if i%100==1:\n        print(\"Epoch number: {} and the loss : {}\".format(i,loss.item()))\n    optimizer.zero_grad()\n    loss.backward()\n    optimizer.step()","0c5b6fc2":"plt.plot(range(epochs), final_losses)\nplt.ylabel('RMSE Loss')\nplt.xlabel('epoch');","b9a25b4c":"y_pred=\"\"\nwith torch.no_grad():\n    y_pred=model(test_categorical,test_cont)\n    loss=torch.sqrt(loss_function(y_pred,y_test))\nprint('RMSE: {}'.format(loss))","30927a5f":"data_verify=pd.DataFrame(y_test.tolist(),columns=[\"Test\"])","dc61cb52":"data_predicted=pd.DataFrame(y_pred.tolist(),columns=[\"Prediction\"])","d6f65985":"final_output=pd.concat([data_verify,data_predicted],axis=1)\nfinal_output['Difference']=final_output['Test']-final_output['Prediction']\nfinal_output.head()","87d61aea":"final_output = final_output \/ (100000)","eda64251":"final_output","6d3bcc01":"torch.save(model,'SalePrice.pt')","a970ff26":"torch.save(model.state_dict(),'PriceWeights.pt')","c964a1c0":"cat_size=[4,2,4]\nmodel1=UsedCarPricePredictionNN(cat_size,6,[100,50],1,p=0.4)","45475bdc":"model1.load_state_dict(torch.load('PriceWeights.pt'))","fbf47a66":"model1.eval()","3133209e":"catee = np.array([1,1,0])\nconti = np.array([4.1000e+04, 1.9670e+01, 1.5820e+03, 1.2620e+02, 5.0000e+00, 6.0000e+00])\n\ncatee = torch.tensor(catee.reshape(1,3), dtype = torch.int64)\nconti = torch.tensor(conti.reshape(1,6), dtype= torch.float)","69aea044":"model1(catee, conti)","87179ae6":"# Training for 2400 epochs","17716495":"# Loading model and Predicting a value","abfa2a14":"# Saving the model","30e869b2":"* Train Test Split","3afb0a53":"# Evaluating","49239870":"# Creating neural network using PyTorch","c2902a53":"# Doing Embedded Encoding for Categorical Data"}}