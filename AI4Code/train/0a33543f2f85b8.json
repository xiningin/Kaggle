{"cell_type":{"de16afb9":"code","42971d36":"code","3e31ce47":"code","39e28968":"code","0bfa32f2":"code","853b96e8":"code","2131cde3":"code","49e0da21":"code","21a164c3":"code","31092dc2":"code","dfa797f9":"code","8bc8252d":"code","675e8bf6":"code","389f64c1":"code","7a2778ae":"code","0c891a7b":"code","4d71c6a1":"code","454f4c96":"code","29e7cb15":"code","9af3485c":"code","178e4a76":"code","33ed8044":"code","f3181bbc":"code","ece5106c":"code","43e559f4":"code","6bb5657e":"code","392f70cd":"code","77f7149a":"code","3a10087d":"code","0f2fd37c":"code","3104d337":"code","b9980ca8":"code","8d2c6797":"code","b3d2ceec":"code","441d141f":"code","57a9052f":"code","c0bf8015":"code","7b0ad20c":"code","84f7f27c":"code","8738ce19":"code","6beabc7b":"code","b1c68dad":"code","9a5884a7":"code","c37fa9a2":"code","465f1d6f":"code","049ee0f1":"code","65fa514f":"code","f280a2db":"code","99119434":"code","1e5c8615":"code","e8f69028":"code","b2e17ceb":"code","fe48e46c":"code","939de800":"code","c57bb2ca":"code","e7815700":"code","415584a9":"code","0d85c07a":"code","a0327630":"code","77fc8cc9":"code","62272ce3":"code","ddc10bec":"code","d9b5a31f":"code","29461d95":"code","25285701":"code","f4a64b27":"code","10a7e2ac":"code","9c2b0467":"code","09ff9381":"code","fb5c2609":"code","84893a1e":"code","b9762906":"code","e3536f41":"code","0a061825":"code","50b415e4":"code","027caa7c":"code","30b29b89":"code","7b855530":"code","4ebfa5ff":"code","6554ed3e":"code","3c53f062":"code","54982fe0":"code","3d68788f":"code","91df5a50":"code","1aa72056":"code","f651dbd3":"code","09f54334":"code","f7381015":"code","18b7e520":"code","3dcd55b7":"markdown","85bd14bb":"markdown","4ce83a25":"markdown","a22eb8fd":"markdown","a8cec9fc":"markdown","21b83fda":"markdown","e805ea90":"markdown","92b57925":"markdown","61bfa411":"markdown","a35183e8":"markdown","04af2941":"markdown","227292c7":"markdown","a24e7ae5":"markdown","09360d43":"markdown","86765977":"markdown","cd414198":"markdown","22c5fc9a":"markdown","132952a2":"markdown","83e50fcd":"markdown","ce7c4def":"markdown","7f4718bd":"markdown","3ec98eb3":"markdown"},"source":{"de16afb9":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","42971d36":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n\nfrom pandas import plotting\n\n#plotly \nimport plotly.offline as py\nimport plotly.graph_objects as go\nfrom plotly.offline import init_notebook_mode, iplot\nfrom plotly import tools\ninit_notebook_mode(connected=True)\nimport plotly.figure_factory as ff\nimport plotly.express as px\n\nfrom sklearn.preprocessing import StandardScaler\n\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn import preprocessing\nfrom sklearn import neighbors\nfrom sklearn.metrics import confusion_matrix,classification_report,precision_score\nfrom sklearn.model_selection import train_test_split\n\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf\n\nsns.set(style=\"whitegrid\")","3e31ce47":"df=pd.read_csv('..\/input\/breast-cancer-wisconsin-data\/data.csv')\ndf.head()","39e28968":"df=df.drop('Unnamed: 32', axis=1)","0bfa32f2":"df.columns","853b96e8":"diagnosis={'M':1, 'B':0}\ndf['diagnosis']=[diagnosis[x] for x in df['diagnosis']]","2131cde3":"from scipy import stats\n","49e0da21":"r, p=stats.pearsonr(df.radius_mean, df.diagnosis)\nprint(r)\nprint(p)","21a164c3":"cor_df=pd.DataFrame(columns=['r','p-value'])\nfor col in df:\n   # print(col)\n    if pd.api.types.is_numeric_dtype(df[col]):\n        r, p=stats.pearsonr(df.diagnosis, df[col])\n        cor_df.loc[col]=[r, p]\ncor_df","31092dc2":"cor_df.sort_values(by=['p-value'], ascending=False)","dfa797f9":"col=['symmetry_se', 'texture_se']\nX=df.drop(col, axis=1)\ny=df['diagnosis']\nX_train, x_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","8bc8252d":"from sklearn import metrics\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report, confusion_matrix,ConfusionMatrixDisplay\nimport statsmodels.api as sm\nimport statsmodels.formula.api as smf","675e8bf6":"lr=LogisticRegression()\nlr.fit(X_train, y_train)","389f64c1":"y_pred=lr.predict(X_train)","7a2778ae":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","0c891a7b":"y_test_pred=lr.predict(x_test)","4d71c6a1":"lr_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",lr_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","454f4c96":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=lr.classes_)\ndisp.plot() ","29e7cb15":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","9af3485c":"y_test_pred_prob=lr.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\nmetrics.roc_auc_score(y_test, y_test_pred_prob)\n","178e4a76":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","33ed8044":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Logistic Regression\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","f3181bbc":"from sklearn.neighbors import KNeighborsClassifier\n","ece5106c":"error_rate=[]\n\nfor i in range(1,11):\n    knn=KNeighborsClassifier(n_neighbors=i)\n    knn.fit(X_train, y_train)\n    pred=knn.predict(x_test)\n    error_rate.append(np.mean(pred!=y_test))\n    \nplt.figure(figsize=(15,10))\nplt.plot(range(1,11), error_rate,marker='o', markersize=9)","43e559f4":"knn=KNeighborsClassifier(n_neighbors=3)\nknn.fit(X_train, y_train)","6bb5657e":"y_pred=knn.predict(X_train)\n","392f70cd":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","77f7149a":"y_test_pred=knn.predict(x_test)","3a10087d":"knn_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",knn_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","0f2fd37c":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=knn.classes_)\ndisp.plot() ","3104d337":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","b9980ca8":"y_test_pred_prob=knn.predict_proba(x_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\nmetrics.roc_auc_score(y_test, y_test_pred_prob)","8d2c6797":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title","b3d2ceec":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=knn.predict_proba(x_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Knn\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","441d141f":"from sklearn.svm import SVC\nfrom sklearn import metrics\nfrom sklearn.preprocessing import StandardScaler\nscaler = StandardScaler()\nscaler.fit(X)\nX = scaler.transform(X)","57a9052f":"from sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1)","c0bf8015":"svc=SVC() #Default hyperparameters\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","7b0ad20c":"svc=SVC(kernel='linear')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","84f7f27c":"svc=SVC(kernel='rbf')\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_test)\nprint('Accuracy Score:')\nprint(metrics.accuracy_score(y_test,y_pred))","8738ce19":"kernel=['linear', 'rbf', 'poly', 'sigmoid']\nfor i in kernel:\n    svc=SVC(kernel=i)\n    svc.fit(X_train,y_train)\n    y_pred=svc.predict(X_test)\n    print(\"{} :- {} \".format(i, metrics.accuracy_score(y_test,y_pred)))","6beabc7b":"from sklearn.model_selection import cross_val_score    \nsvc=SVC(kernel=\"rbf\")\nscores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)\nprint(\"-------------------\")\nprint(scores.mean())","b1c68dad":"from sklearn.model_selection import cross_val_score    \nsvc=SVC(kernel=\"poly\")\nscores = cross_val_score(svc, X, y, cv=10, scoring='accuracy') #cv is cross validation\nprint(scores)\nprint(\"-------------------\")\nprint(scores.mean())","9a5884a7":"C_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='rbf', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(range(1,26), acc_score)\nprint(acc_score)","c37fa9a2":"C_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='poly', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(range(1,26), acc_score)\nprint(acc_score)","465f1d6f":"C_range=list(range(1,26))\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='sigmoid', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(range(1,26), acc_score)\nprint(acc_score)","049ee0f1":"C_range=[0.001, 0.01, 0.1, 1.0, 10]\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='poly', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(C_range, acc_score)\nprint(acc_score)","65fa514f":"C_range=[0.001, 0.01, 0.1, 1.0, 10]\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='rbf', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(C_range, acc_score)\nprint(acc_score)","f280a2db":"C_range=[0.001, 0.01, 0.1, 1.0, 10]\nacc_score=[]\nfor c in C_range:\n    svc = SVC(kernel='sigmoid', C=c)\n    scores = cross_val_score(svc, X, y, cv=10, scoring='accuracy')\n    acc_score.append(scores.mean())\nplt.plot(C_range, acc_score)\nprint(acc_score)","99119434":"svc=SVC(kernel='poly', C=1.0) #Default hyperparameters\nsvc.fit(X_train,y_train)\ny_pred=svc.predict(X_train)","1e5c8615":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","e8f69028":"y_test_pred=svc.predict(X_test)","b2e17ceb":"svc_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",svc_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","fe48e46c":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=svc.classes_)\ndisp.plot()","939de800":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","c57bb2ca":"y_test_pred_prob=lr.predict_proba(X_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\nmetrics.roc_auc_score(y_test, y_test_pred_prob)","e7815700":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","415584a9":"from sklearn.tree import DecisionTreeClassifier\n","0d85c07a":"X=df.drop(col, axis=1)\ny=df['diagnosis']\nX_train, X_test, y_train, y_test=train_test_split(X, y, test_size=0.3, random_state=10)","a0327630":"clf_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=0)\n\n\n# fit the model\nclf_gini.fit(X_train, y_train)","77fc8cc9":"y_pred_gini = clf_gini.predict(X_train)","62272ce3":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred_gini))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred_gini))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred_gini))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred_gini))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred_gini))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred_gini))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred_gini))","ddc10bec":"y_test_pred= clf_gini.predict(X_test)","d9b5a31f":"dc_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",dc_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","29461d95":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=clf_gini.classes_)\ndisp.plot()","25285701":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","f4a64b27":"y_test_pred_prob=clf_gini.predict_proba(X_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\nmetrics.roc_auc_score(y_test, y_test_pred_prob)","10a7e2ac":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='Logistic Regression')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","9c2b0467":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Decision Tree\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","09ff9381":"# print the scores on training and test set\n\nprint('Training set score: {:.4f}'.format(clf_gini.score(X_train, y_train)))\n\nprint('Test set score: {:.4f}'.format(clf_gini.score(X_test, y_test)))","fb5c2609":"plt.figure(figsize=(12,8))\n\nfrom sklearn import tree\n\ntree.plot_tree(clf_gini.fit(X_train, y_train)) ","84893a1e":"clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n\n\n# fit the model\nclf_en.fit(X_train, y_train)","b9762906":"error_rate=[]\nfor i in range(1,11):\n    clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n\n\n    # fit the model\n    clf_en.fit(X_train, y_train)\n    pred=clf_en.predict(X_test)\n    error_rate.append(np.mean(pred!=y_test))\n    \nplt.figure(figsize=(15,10))\nplt.plot(range(1,11), error_rate,marker='o', markersize=9)\n    ","e3536f41":"clf_en = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=0)\n\n\n# fit the model\nclf_en.fit(X_train, y_train)","0a061825":"y_pred=clf_en.predict(X_train)","50b415e4":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","027caa7c":"y_test_pred=clf_en.predict(X_test)\n","30b29b89":"dc_en_acc=metrics.accuracy_score(y_test, y_test_pred)\nprint(\"Accuracy Score:-\",dc_en_acc)\nprint(\"F1 Score:-\", metrics.f1_score(y_test, y_test_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_test, y_test_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_test, y_test_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_test, y_test_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_test, y_test_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_test, y_test_pred))","7b855530":"cfm=confusion_matrix(y_test, y_test_pred)\ndisp = ConfusionMatrixDisplay(confusion_matrix=cfm,\n                               display_labels=clf_en.classes_)\ndisp.plot()","4ebfa5ff":"from sklearn.metrics import classification_report\nprint(classification_report(y_test, y_test_pred))","6554ed3e":"y_test_pred_prob=clf_gini.predict_proba(X_test)[:,1]\ny_test_pred_prob\n\nfrom sklearn.metrics import roc_curve\nmetrics.roc_auc_score(y_test, y_test_pred_prob)","3c53f062":"fpr, tpr,thresholds=roc_curve(y_test,y_test_pred_prob)\nplt.figure(figsize=(10,10))\nplt.plot([0,1],[0,1],'k--')\nplt.plot(fpr, tpr, label='DEcision Tree with Entropy')\nplt.xlabel(\"fpr (False Possitive rate)\")\nplt.ylabel(\"tpr-(True Positive rate)\")\nplt.title(\"ROC_AUC\")\nplt.show()","54982fe0":"from sklearn.metrics import precision_recall_curve\nno_skill=len(y==1)\/len(y)\ny_test_prob=lr.predict_proba(X_test)[:,1]\nplt.figure(figsize=(10,8))\nplt.plot([0,1],[no_skill, no_skill], label=\"No Skill\")\nprecision, recall,_ =precision_recall_curve(y_test, y_test_prob)\nplt.plot(recall, precision, marker='',label=\"Decision Tree with Entropy\")\nplt.xlabel(\"Recall\")\nplt.ylabel(\"Precision\")\nplt.title(\"Recall-Precision Curve\")\nplt.legend()\nplt.show()","3d68788f":"# split data into training and testing sets\n\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.33, random_state = 42)","91df5a50":"# import Random Forest classifier\n\nfrom sklearn.ensemble import RandomForestClassifier\n\n\n\n# instantiate the classifier \n\nrfc = RandomForestClassifier(random_state=0)\n\n\n\n# fit the model\n\nrfc.fit(X_train, y_train)","1aa72056":"y_pred = rfc.predict(X_train)\n","f651dbd3":"print(\"Accuracy Score:-\", metrics.accuracy_score(y_train, y_pred))\nprint(\"F1 Score:-\", metrics.f1_score(y_train, y_pred))\nprint(\"Average Precision Score:-\", metrics.average_precision_score(y_train, y_pred))\nprint(\"Log Loss:-\", metrics.log_loss(y_train, y_pred))\nprint(\"Precision Score:-\", metrics.precision_score(y_train, y_pred))\nprint(\"Recall Score:-\", metrics.recall_score(y_train, y_pred))\nprint(\"ROC-AUC Score:-\", metrics.roc_auc_score(y_train, y_pred))","09f54334":"corr=df.corr()","f7381015":"columns = np.full((corr.shape[0],), True, dtype=bool)\nfor i in range(corr.shape[0]):\n    for j in range(i+1, corr.shape[0]):\n        if corr.iloc[i,j] >= 0.9:\n            if columns[j]:\n                columns[j] = False\nselected_columns = df.columns[columns]\ndf = df[selected_columns]","18b7e520":"selected_columns = selected_columns[1:].to_numpy()\n# importing the statsmodels\nimport statsmodels.api as sm\n\n# defing the backward elimination\n\ndef backwardElimination(x, Y, sl, columns):\n    numVars = len(x[0])\n    for i in range(0, numVars):\n        regressor_OLS = sm.OLS(Y, x).fit()\n        maxVar = max(regressor_OLS.pvalues).astype(float)\n        if maxVar > sl:\n            for j in range(0, numVars - i):\n                if (regressor_OLS.pvalues[j].astype(float) == maxVar):\n                    x = np.delete(x, j, 1)\n                    columns = np.delete(columns, j)\n                    \n    regressor_OLS.summary()\n    return x, columns\n\nSL = 0.05\ndata_modeled, selected_columns = backwardElimination(df.iloc[:,1:].values, df.iloc[:,0].values, SL, selected_columns)","3dcd55b7":"* As we can see that the acuraccy score for Linear KERNAL is very well . SInce the we are getting higher accuracy , \n* it can be due to overfitting using LINEAR kernel.\n* But as it is clear that using the \"rbf\" and \"sigmoid\" will function well and produces the 99% accuracy.\n","85bd14bb":"# Conclusion:-\n* It is quite clear that it is overfitting\n* SO we are not gonna use this kernel\n* Look at the other kernels","4ce83a25":"# Determine the least significant variable to remove at each step\nThe least significant variable is a variable that:\n* Has the highest p-value in the model, or\n* Its elimination from the model causes the lowest drop in R2, or\n* Its elimination from the model causes the lowest increase in RSS (Residuals Sum of Squares) compared to other predictors.\n# Choose a stopping rule\nThe stopping rule is satisfied when all remaining variables in the model have a p-value smaller than some pre-specified threshold.\nWhen we reach this state, backward elimination will terminate and return the current step\u2019s model.\n# Where backward stepwise is better\n* Starting with the full model has the advantage of considering the effects of all variables simultaneously.\n* This is especially important in case of collinearity (when variables in a model are correlated which each other) because backward stepwise may be forced to keep them all in the model unlike forward selection where none of them might be entered\n* Unless the number of candidate variables > sample size (or number of events), use a backward stepwise approach.\n\n> https:\/\/quantifyinghealth.com\/stepwise-selection\/","a22eb8fd":"# Import Library","a8cec9fc":"# Visualize decision-trees","21b83fda":"# Backward stepwise\n* Backward stepwise selection (or backward elimination) is a variable selection method which:\n* Begins with a model that contains all variables under consideration (called the Full Model)\n* Then starts removing the least significant variables one after the other\n* Until a pre-specified stopping rule is reached or until no variable is left in the model\n* From Full model we eliminate the least important features.","e805ea90":"# SVC -Support Vector Classifier","92b57925":"Next, we compare the correlation between features and remove one of two features that have a correlation higher than 0.9","61bfa411":"# Conclusion \n* These are overfit model\n* We need more features to remove","a35183e8":"# Decision Tree Classifier with criterion entropy\u00b6","04af2941":"# Decision Tree Clasifiers","227292c7":"# Linear kernel","a24e7ae5":"# Random Forest Classifiers","09360d43":"# Performing K-fold cross validation with different kernels","86765977":"# RBF kernel","cd414198":"* Now, the dataset has only those columns with correlation less than 0.9\n* Next we will be selecting the columns based on how they affect the p-value. We are the removing the column diagnosis because it is the column we are trying to predict","22c5fc9a":"# Conclusion:-\nAs we can see that the optimum K in KNN we get is K=3.","132952a2":"# Conclusion:\n* As we can see that as C value increase the accuracy is increasing respective of the KERNEl\n* Since C is the hyperparameter\n* As C increase the Overfitting occurs.\n* A C decreases the underfitting occures.","83e50fcd":"# K-NN","ce7c4def":"# Conclusion: \n* As we can see that in my previsous notebook the accuracy was 76%, while in this case the accuracy is 87.43%.\n* It is observed that removing the two feature help ub increasing the accuracy of the dataset using KNN model as prediction\n* Log Loss is decreased as it was 8.482 and now it is 4.33\n* ROC-AUC is improved , now it is 0.846 , which is much better than previous results in last notbook","7f4718bd":"# What we can do ??\nwe have two options\n* remove the feature which have correlation more than 0.9\n* Another one is backward stepwise","3ec98eb3":"# Logistic Regresion"}}