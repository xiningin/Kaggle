{"cell_type":{"86b0dde1":"code","b5232e0f":"code","b96cdcad":"code","76cb47f3":"code","c84b2f82":"code","422046ec":"code","35c241b1":"code","15c8306a":"code","bde098ec":"code","a50ff3c6":"code","336c83f9":"code","ee3abbfe":"code","98890ef1":"code","81464078":"code","c5a365b5":"code","736dd05b":"code","8328fac9":"code","8f80d4db":"markdown","1b024ebf":"markdown","19e61508":"markdown","a5e0e8ef":"markdown","59205ab0":"markdown","58f0d994":"markdown","59f9cd7c":"markdown","379bd7bf":"markdown","df152464":"markdown","4e4e4de5":"markdown"},"source":{"86b0dde1":"#Cree un nuevo kernel porque el otro me estaba dando MUCHOS problemas 16\/11\/2019\n#Generative Adversarial Network (GAN)\nimport numpy as np\nimport operator\nfrom functools import reduce\nfrom keras.models import Sequential, Model\nfrom keras.layers import * # Dense, Conv2D, Flatten, Dropout, LeakyRelu\nfrom keras.optimizers import Adam, SGD\nfrom keras.utils.vis_utils import plot_model\nfrom keras_preprocessing.image import ImageDataGenerator\nfrom keras.models import load_model\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm\nimport pathlib\nimport shutil\nfrom imageio import imsave\nimport os\n\n\nprint(os.listdir(\"..\/input\"))","b5232e0f":"dir_img = '..\/input\/stanford-dogs-dataset\/images\/Images\/'\ndir_ann = \"..\/input\/stanford-dogs-dataset\/annotations\/Annotation\/\"\nforma = (64, 64, 3) #forma de la imagen 64*64 pixeles en 3 canales\nBatch = 32 #estaba entre 32 64 u 128, se eligio 32 para que el num batch sea significativo\nlatent_dim = 100 #numero de nodos usados en el input del generador, se eligio 100 para que no sea tan alto o tan bajo\nepoch = 80 #tarda bastante, le voy a poner 2 para el commit pero idealmente queremos entre 80 y 150\n#a mayor cantidad de epochs, mejor para el entrenamiento \nnum_batch = 20579 \/\/ Batch \/\/ 2  #se baja el numero de batch\nprint(num_batch)","b96cdcad":"datagen = ImageDataGenerator( \n    horizontal_flip = True,\n    rotation_range = 20,\n    width_shift_range = 0.2,\n    height_shift_range = 0.2,\n    preprocessing_function = lambda X: (X-127.5)\/127.5\n) #Generar batches de tensor image data con aumentacion en tiempo real, la data se loopea\ndata_loader=datagen.flow_from_directory(\n    dir_img,\n    target_size = forma[:-1], \n    class_mode = None,\n    batch_size = Batch)","76cb47f3":"def generar(n_pruebas=Batch):\n    return next(data_loader)[:n_pruebas], np.ones((n_pruebas, 1))*0.9","c84b2f82":"def mostrar(ary, rows, cols):\n    plt.figure(figsize=(cols*3, rows*3))\n    for row in range(rows):\n        for col in range(cols):\n            plt.subplot(rows, cols, row*cols+col+1)\n            img = (ary[row*cols+col, :] + 1) \/ 2\n            plt.axis('off')\n            plt.title(f'{row*cols+col}')\n            plt.imshow(img)\n    plt.show()","422046ec":"data, y = generar()\nprint('shape of data:', data.shape) # => (32, 64, 64, 3) forma de las imagenes\nprint('min, max of data:', data.min(), data.max()) # 0.0 1.0\nprint('shape of y', y.shape) # (32, 1)\nprint('min, max of y', y.min(), y.max()) # 1.0 1.0\nprint('head 5 of y', y[:5]) # [[1.] [1.] ...]\n\nmostrar(data,2, 5)","35c241b1":"#discriminador\ndef crear_discriminador():\n    model = Sequential()\n    model.add(Conv2D(32, kernel_size=4, strides=2, padding='same', input_shape=(64,64,3)))\n    model.add(LeakyReLU(0.2))\n    model.add(Conv2D(64, kernel_size=4, strides=2, padding='same'))\n    model.add(LeakyReLU(0.2))\n    model.add(Conv2D(128, kernel_size=4, strides=2, padding='same'))\n    model.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    model.add(LeakyReLU(0.2))\n    model.add(Conv2D(256, kernel_size=4, strides=2, padding='same'))\n    model.add(BatchNormalization(momentum=0.1, epsilon=1e-05))\n    model.add(LeakyReLU(0.2))\n    model.add(Conv2D(1, kernel_size=4, strides=1, padding='same'))\n    model.add(Flatten())\n    model.add(Dense(units=1, activation='sigmoid'))\n    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=0.0005, beta_1=0.5))\n    return model\n\n\ndiscriminator = crear_discriminador()\ndiscriminator.summary()","15c8306a":"#generador con tanh preprocesado -1 a 1\ndef crear_generador():\n    struct_ = (64, 8, 8)\n    n_nodes = reduce(operator.mul, struct_) \n    print(f'dim generador input={n_nodes}')\n    model = Sequential([\n        Dense(n_nodes, activation='relu', input_shape=(latent_dim,)),\n        Reshape((*struct_[1:], struct_[0])),\n        BatchNormalization(momentum=0.8),\n        \n        #subir a 16*16\n        UpSampling2D(),\n        Conv2D(struct_[0], kernel_size=3, padding='same'),\n        Activation('relu'),\n        BatchNormalization(momentum=0.8),\n        #a 32*32\n        UpSampling2D(),\n        Conv2D(struct_[0]\/\/2, kernel_size=3, padding='same'),\n        Activation('relu'),\n        BatchNormalization(momentum=0.8),\n        #a 64*64\n        UpSampling2D(),\n        Conv2D(struct_[0]\/\/4, kernel_size=3, padding='same'),\n        Activation('relu'),\n        BatchNormalization(momentum=0.8),\n        Conv2D(3, kernel_size=3, padding='same'),\n        Activation('tanh'),\n    ])\n\n    return model\n\n\ngenerator = crear_generador()\ngenerator.summary()","bde098ec":"# puntos latentes para generador\ndef generar_puntos(latent_dim, n_pruebas):\n    ruido = np.random.uniform(-1, 1, (n_pruebas, latent_dim))\n    return ruido","a50ff3c6":"# generar falsas\ndef generar_falsas(g_model, latent_dim, n_pruebas):\n    x_input = generar_puntos(latent_dim, n_pruebas)\n    #predecir output\n    X = g_model.predict(x_input)\n    y = np.zeros((n_pruebas, 1))\n    return X, y","336c83f9":"# prueba output\nX, y = generar_falsas(generator, latent_dim, 8)\nmostrar(X, 2, 4)","ee3abbfe":"#GAN\ndef crear_gan(generator, discriminator):\n    discriminator_fijo = Model(inputs=discriminator.inputs, outputs=discriminator.outputs)\n    discriminator_fijo.trainable = False\n    model = Sequential([InputLayer(input_shape=(latent_dim,)), generator, discriminator_fijo])\n    opt = Adam(lr=0.0005, beta_1=0.5)\n    model.compile(loss='binary_crossentropy', optimizer=opt)\n    return model\n\ngan = crear_gan(generator, discriminator)\ngan.summary()","98890ef1":"# Entrenamiento de los modelos\ndef ent_discriminador():\n    #reales random\n    X_real, y_real = generar(Batch\/\/2)\n    loss_real = discriminator.train_on_batch(X_real, y_real)\n    #falsas\n    X_fake, y_fake = generar_falsas(generator, latent_dim, Batch\/\/2)\n    loss_fake = discriminator.train_on_batch(X_fake, y_fake)\n    return (loss_real+loss_fake)*0.5\n\ndef ent_gan(num_loop=1):\n    X = generar_puntos(latent_dim, Batch)\n    y = np.ones((Batch, 1))*0.9\n    for i in range(num_loop):\n        loss = gan.train_on_batch(X, y)\n    return loss","81464078":"# Entrenarlos a todos\nhistory = np.zeros((epoch, num_batch, 2))\nperrosenEpoch = np.zeros((epoch, *forma))\n\nfor i in tqdm(range(epoch), desc='epoch'):\n    data_loader.reset()\n    pbar_batch = tqdm(range(num_batch), desc='batch')\n    \n    for j in pbar_batch:\n        d_loss = ent_discriminador()\n        g_loss = ent_gan()\n        pbar_batch.set_description(f'{i:>2}, d_loss:{d_loss:.2}, g_loss:{g_loss:.2}')\n        history[i, j, :] = d_loss, g_loss\n        \n    generadas = generar_falsas(generator, latent_dim, 5)[0]\n    mostrar(generadas, 1, 5)\n    perrosenEpoch[i, :] = generadas[0,:]","c5a365b5":"# generando\nlatent_points = generar_puntos(latent_dim, 10000)\nX = generator.predict(latent_points)\nprint(X.shape, X[0].min(), X[0].max())\n\nmostrar(X, 2, 4)","736dd05b":"#output\nimgs = [((img+1) * 127.5).astype(np.uint8) for img in X]\nnp.array(imgs).min(), np.array(imgs).max()\nimgdir = pathlib.Path('images')\nif not imgdir.exists():\n    imgdir.mkdir()\n\nfor n in range(len(imgs)):\n    imsave(imgdir\/f'doggo_{n}.png', imgs[n])\n    \nshutil.make_archive('images', 'zip', 'images')","8328fac9":"#Como son muchos objetos para un commit, borrar\n!rm -rf images\n!ls","8f80d4db":"**Arquitectura Modelo Generador**","1b024ebf":"**Generar Finales y Resultados**","19e61508":"Generacion de imagenes falsas para la prueba","a5e0e8ef":"**Arquitectura Modelo Discriminador**","59205ab0":"**Procesamiento de Imagenes y Preprocesamiento de Datos**","58f0d994":"Procesamiento de datos\nes decir, informacion de las fotos y mostrar","59f9cd7c":"**Inicio y Ajustes**","379bd7bf":"**Generative Adversarial Network** DCGAN","df152464":"**Proyecto 2 Juan Montenegro, Ivan Loscher**\nReferencias:\nhttps:\/\/keras.io\/preprocessing\/image\/\nhttps:\/\/machinelearningmastery.com\/how-to-develop-a-generative-adversarial-network-for-an-mnist-handwritten-digits-from-scratch-in-keras\/\nhttps:\/\/github.com\/eriklindernoren\/Keras-GAN\/blob\/master\/dcgan\/dcgan.py\n","4e4e4de5":"**Entrenamiento**"}}