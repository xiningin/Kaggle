{"cell_type":{"94821fd8":"code","ceba3231":"code","51d201e5":"code","31dc064e":"code","113d096f":"code","8d9cf3a5":"code","e22141bb":"code","08c592f9":"code","908fd694":"code","3cd5dbdb":"code","8eff1d25":"code","8cbdabd5":"code","d70b2148":"code","34a1ed6b":"code","5a6ae5a0":"code","eb7ab624":"code","6ca761de":"code","a497ffa1":"code","a3bd1c97":"code","fd1ee20e":"code","06e98477":"code","ccb75227":"code","f49263c9":"code","98ad3b51":"code","bd523e93":"markdown","1e3f56a7":"markdown","c7dc54f4":"markdown","8c56a4c0":"markdown","fc7b9bde":"markdown","d8f3382f":"markdown","2f252e5b":"markdown","7f92b32d":"markdown","28995b2c":"markdown","d369bcf8":"markdown"},"source":{"94821fd8":"import pandas as pd\nimport numpy as np\nimport spacy\nimport re\nfrom time import time","ceba3231":"df = pd.read_csv('..\/input\/womens-ecommerce-clothing-reviews\/Womens Clothing E-Commerce Reviews.csv')\ndf.head()","51d201e5":"df = df[['Title', 'Review Text']] #I only want to use the text based values, so I modify the dataframe\ndf.head()","31dc064e":"df.isnull().sum() #finding the null values","113d096f":"df = df.dropna().reset_index(drop=True) #and dropping them \ndf.isnull().sum() ","8d9cf3a5":"df.shape","e22141bb":"nlp = spacy.load(\"en_core_web_sm\", disable=['ner', 'parser'])","08c592f9":"def cleaning(doc): #the lemmatizing function\n    txt = [token.lemma_ for token in doc if not token.is_stop]\n    if len(txt) > 2:\n        return ' '.join(txt)","908fd694":"brief_cleaning = (re.sub(\"[^A-Za-z']+\", ' ', str(row)).lower() for row in df['Review Text'])","3cd5dbdb":"t = time()\n\ntxt = [cleaning(doc) for doc in nlp.pipe(brief_cleaning, batch_size=5000, n_threads=-1)]\n\nprint('Time to clean up everything: {} mins'.format(round((time() - t) \/ 60, 2)))","8eff1d25":"df_clean = pd.DataFrame({'clean': txt})\ndf_clean = df_clean.dropna().drop_duplicates()\ndf_clean.shape","8cbdabd5":"df_clean.head() ","d70b2148":"import gensim \nfrom gensim.models import Word2Vec","34a1ed6b":"sent = [row.split() for row in df_clean['clean']] #splitting the columns into the correct format","5a6ae5a0":"print(sent[:10])","eb7ab624":"t = time()\n\nmodel = Word2Vec(sent, min_count=1,size= 50,workers=3, window =3, sg = 1)\n\nprint('Time to train the model: {} mins'.format(round((time() - t) \/ 60, 2)))","6ca761de":"model.wv.most_similar(positive=[\"dress\"])","a497ffa1":"model.wv.most_similar(positive=[\"jumper\"])","a3bd1c97":"model.wv.most_similar(positive=[\"skirt\"])","fd1ee20e":"model.wv.most_similar(positive=[\"favorite\"])","06e98477":"model.wv.most_similar(positive=[\"favourite\"])","ccb75227":"model.wv.similarity(\"little\", 'petite')","f49263c9":"model.wv.similarity(\"pencil\", 'skirt')","98ad3b51":"model.wv.doesnt_match(['skirt', 'dress', 'book'])","bd523e93":"## Finally we are able to get some insights out of our model","1e3f56a7":"Most smilar words:","c7dc54f4":"## Word2Vec practice with Clothing review Data","8c56a4c0":"Which one doesn't fit?","fc7b9bde":"Training the model:","d8f3382f":"Let's first import all the necessary libraries and read our datafile","2f252e5b":"And finally importing the Word2Vec model","7f92b32d":"And this will be the final clean text data we are going to be wokring with.","28995b2c":"Let's load Spacy for to lemmatize and clean our text (this will not work with dirtier, more unruly data).","d369bcf8":"How similar are two words?"}}