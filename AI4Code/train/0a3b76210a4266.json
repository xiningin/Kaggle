{"cell_type":{"fd305f78":"code","ad6aafd3":"code","069682b7":"code","884f5f10":"code","7d857016":"code","d0ff9d63":"code","b65ffbe6":"code","7f047ab5":"code","23535a97":"code","939a77fa":"code","f99db3f1":"code","cf0895fc":"code","4cd4a683":"code","2dab6c4d":"code","4f8edd8f":"code","2ec01c69":"code","6d1523f5":"code","ec905db4":"code","ca609c8a":"code","35900dae":"code","74c855ee":"code","38b8848c":"code","604cb5be":"code","b3444c7f":"code","2c0e4d07":"code","2263f13c":"code","e431b20e":"code","c163f71e":"code","8e39458d":"code","77f235d8":"code","3a943d6d":"code","63d998e2":"code","13d13e57":"code","6d1a48d1":"code","b9790dec":"markdown","52f2a9b7":"markdown","373065c9":"markdown","407775f9":"markdown","bbb1aa8f":"markdown","dbf1ce25":"markdown","f239c371":"markdown","48f9ba2e":"markdown"},"source":{"fd305f78":"import numpy as np \nimport pandas as pd \nimport os\nfrom sklearn.cluster import KMeans\nfrom tqdm import tqdm\nfrom sklearn.preprocessing import LabelEncoder\nfrom collections import Counter, defaultdict\nfrom sklearn.utils import check_random_state","ad6aafd3":"seed = 35#32\nnfold = 5","069682b7":"# First, installing the dependencies\n!pip install -U ..\/input\/kerasapplications\/Keras_Applications-1.0.8-py3-none-any.whl\n!pip install ..\/input\/qubvel\/efficientnet-1.0.0-py3-none-any.whl\n!pip install ..\/input\/qubvel\/image_classifiers-1.0.0-py3-none-any.whl\n\n# Now, installing segmentation_models (short for 'sm')\n!pip install ..\/input\/qubvel-segmentation-model-keras-v101\/segmentation_models-master\n\n# sm can work with both Keras and Tensorflow.\n# By default, it look for keras.\n# But, with Keras, it's giving error during the import. \n# So, we will be using Tensorflow as the backend for sm.\n%env SM_FRAMEWORK=tf.keras","884f5f10":"import numpy as np\nimport pandas as pd \nimport cv2\nimport os\nimport matplotlib.pyplot as plt\n\nfrom keras import backend as K\nfrom keras.callbacks import CSVLogger, ModelCheckpoint, LearningRateScheduler, EarlyStopping, ReduceLROnPlateau\n\nimport keras\nimport json\nfrom tqdm import tqdm\nfrom segmentation_models.losses import bce_jaccard_loss\nfrom segmentation_models.metrics import iou_score\nimport gc\nfrom segmentation_models import Unet\nimport segmentation_models  as sm\nfrom sklearn.model_selection import train_test_split\nfrom keras.utils import Sequence\nfrom keras.optimizers import Adam\nimport warnings\nwarnings.filterwarnings('ignore')\nprint(os.listdir('..\/input'))\n\nOUTPUT_DIR = '.\/'\nif not os.path.exists(OUTPUT_DIR):\n    os.makedirs(OUTPUT_DIR)\n    \nfrom pathlib import Path\nimport ast\nfrom PIL import Image  ","7d857016":"ctr = pd.read_csv('..\/input\/ranzcr-clip-lung-contours\/RANZCR_CLiP_lung_contours.csv')\ntrain = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/train.csv')\ntest = pd.read_csv('..\/input\/ranzcr-clip-catheter-line-classification\/sample_submission.csv')","d0ff9d63":"DIMENSION =  (512, 512) #(128, 128)  #\nIMG_HEIGHT, IMG_WIDTH = DIMENSION\n\nBACKBONE = 'seresnet34'\nTRAIN_PATH = '..\/input\/ranzcr-clip-catheter-line-classification\/train\/'\nTEST_PATH = '..\/input\/ranzcr-clip-catheter-line-classification\/test\/'\n# all_images = os.listdir(TRAIN_PATH)\n# all_images = [Path(e).stem for e in all_images]","b65ffbe6":"def load_mask(StudyInstanceUID):\n    img = cv2.imread(TRAIN_PATH+StudyInstanceUID+'.jpg',1)\n    ctr_left = ast.literal_eval(ctr.loc[ctr.StudyInstanceUID==StudyInstanceUID,'left_lung_contour'].values[0])\n    ctr_right = ast.literal_eval(ctr.loc[ctr.StudyInstanceUID==StudyInstanceUID,'right_lung_contour'].values[0])\n    img = cv2.drawContours(img, np.array([[np.array(x) for x in ctr_left]]), 0, (255,255,255), 1)\n    img = cv2.drawContours(img, np.array([[np.array(x) for x in ctr_right]]), 0, (255,255,255), 1)\n#     img = np.where(img>=255, 1.0, 0.0)\n    return img","7f047ab5":"StudyInstanceUID = '1.2.826.0.1.3680043.8.498.10000428974990117276582711948006105617'# train.loc[0,'StudyInstanceUID']\nimg = cv2.imread(TRAIN_PATH+StudyInstanceUID+'.jpg',1)\nmask_img = load_mask(StudyInstanceUID)\nfix, ax = plt.subplots(2,2, figsize=(10,10))\nfor i in range(2):\n    ax[i,0].imshow(img)\n    ax[i,1].imshow(mask_img)\n    ax[i,0].axis('off')\n    ax[i,1].axis('off')\nplt.show()","23535a97":"plt.imshow(cv2.imread('..\/input\/ranzcr-clip-lung-contours\/train_lung_masks\/train_lung_masks\/1.2.826.0.1.3680043.8.498.10000428974990117276582711948006105617.jpg'))\nplt.show()","939a77fa":"from time import time","f99db3f1":"start = time()\nfor tra_idx in tqdm(range(len(train))):\n    StudyInstanceUID = train.loc[tra_idx,'StudyInstanceUID']\n    #img = cv2.imread(TRAIN_PATH+StudyInstanceUID+'.jpg',1)\n    mask_img = load_mask(StudyInstanceUID)\n    cv2.imwrite('.\/train_ctrlung\/'+StudyInstanceUID+'.jpg', mask_img)\nprint('draw contours time =',time()-start)","cf0895fc":"model = Unet(backbone_name=BACKBONE, encoder_weights='imagenet', activation='sigmoid', classes=1, input_shape=(IMG_HEIGHT, IMG_WIDTH, 3))\n\nmodel.load_weights('..\/input\/unet-lung-mask-512\/unet_lungseg_512_12-0.075.hdf5')\nmodel.summary()","4cd4a683":"def mask2ctr(img,im):\n    img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n    img = 1 - img.astype(np.float32)\n    img = np.where(img>=0.5, 1, 0) \n    img = img.astype(np.uint8)\n    img = cv2.cvtColor(img, cv2.COLOR_RGB2GRAY)\n    #\u8150\u8680\n    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (2, 2))\n    ctr = cv2.erode(img, kernel)\n    \n    ctr = img - ctr\n    ctr=Image.fromarray(ctr) \n    ctr = 255 * np.array(ctr).astype('uint8')\n    ctr = cv2.cvtColor(ctr, cv2.COLOR_GRAY2RGB)\n    \n    im = im.astype(np.float32) * 255\n    ctr_img = ctr + im[0,:,:,:]\n    ctr_img = ctr_img.astype(np.float32) \/ 255\n    \n    return ctr,ctr_img\n","2dab6c4d":"from PIL import Image  \n\nSIUID = test.loc[1234,'StudyInstanceUID']\nim = cv2.imread(TEST_PATH+SIUID+'.jpg') \nim = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\nim = im.astype(np.float32) # \/ 255.\nim = cv2.resize(im, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_LANCZOS4)\nim1 = (im - np.min(im)) \/ (np.max(im) - np.min(im))\nim = im1.reshape(1,IMG_WIDTH, IMG_HEIGHT, -1)\n\ny_hat = model.predict(im)\ny_hat = y_hat.squeeze(0)\n_, ctr_img = mask2ctr(y_hat,im)\n\n# fix, ax = plt.subplots(1,2, figsize=(20,10))\n# ax[0,0].imshow(im)\n# ax[0,1].imshow(ctr)\n# plt.show()    ","4f8edd8f":"print(im.mean())\nplt.imshow(im[0,:,:,:])\nplt.show()","2ec01c69":"# im = im.astype(np.float32) * 255\n# ctr_img = ctr + im[0,:,:,:]\n# ctr_img = ctr_img.astype(np.float32) \/ 255\n\n# ctr =  ctr.astype(np.float32)  \/ 255.\n# ctr_img = ctr + im[0,:,:,:]\n# ctr_img = (ctr_img - np.min(ctr_img)) \/ (np.max(ctr_img) - np.min(ctr_img))","6d1523f5":"print(ctr_img.mean())\nplt.imshow(ctr_img)\nplt.show()","ec905db4":"for idx in tqdm(range(len(test))):\n    SIUID = test.loc[idx,'StudyInstanceUID']\n    im = cv2.imread(TEST_PATH+SIUID+'.jpg',-1)\n    im = cv2.cvtColor(im, cv2.COLOR_BGR2RGB)\n    im = im.astype(np.float32) # \/ 255.\n    im = cv2.resize(im, dsize=(IMG_WIDTH, IMG_HEIGHT), interpolation=cv2.INTER_LANCZOS4)\n    im = (im - np.min(im)) \/ (np.max(im) - np.min(im))\n    im = im.reshape(1,IMG_WIDTH, IMG_HEIGHT, -1)\n    y_hat = model.predict(im)\n    y_hat = y_hat.squeeze(0)\n    _, y_ctr = mask2ctr(y_hat,im)\n    cv2.imwrite('.\/test_ctrlung\/'+SIUID+'.jpg', y_ctr)","ca609c8a":"class RepeatedStratifiedGroupKFold():\n\n    def __init__(self, n_splits=5, n_repeats=1, random_state=None):\n        self.n_splits = n_splits\n        self.n_repeats = n_repeats\n        self.random_state = random_state\n        \n    def split(self, X, y=None, groups=None):\n        k = self.n_splits\n        def eval_y_counts_per_fold(y_counts, fold):\n            y_counts_per_fold[fold] += y_counts\n            std_per_label = []\n            for label in range(labels_num):\n                label_std = np.std(\n                    [y_counts_per_fold[i][label] \/ y_distr[label] for i in range(k)]\n                )\n                std_per_label.append(label_std)\n            y_counts_per_fold[fold] -= y_counts\n            return np.mean(std_per_label)\n            \n        rnd = check_random_state(self.random_state)\n        for repeat in range(self.n_repeats):\n            labels_num = np.max(y) + 1\n            y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n            y_distr = Counter()\n            for label, g in zip(y, groups):\n                y_counts_per_group[g][label] += 1\n                y_distr[label] += 1\n\n            y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n            groups_per_fold = defaultdict(set)\n        \n            groups_and_y_counts = list(y_counts_per_group.items())\n            rnd.shuffle(groups_and_y_counts)\n\n            for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n                best_fold = None\n                min_eval = None\n                for i in range(k):\n                    fold_eval = eval_y_counts_per_fold(y_counts, i)\n                    if min_eval is None or fold_eval < min_eval:\n                        min_eval = fold_eval\n                        best_fold = i\n                y_counts_per_fold[best_fold] += y_counts\n                groups_per_fold[best_fold].add(g)\n            \n            all_groups = set(groups)\n            for i in range(k):\n                train_groups = all_groups - groups_per_fold[i]\n                test_groups = groups_per_fold[i]\n\n                train_indices = [i for i, g in enumerate(groups) if g in train_groups]\n                test_indices = [i for i, g in enumerate(groups) if g in test_groups]\n\n                yield train_indices, test_indices","35900dae":"# let's first concat all the labels \n# e.g 00000000010   \ntarget_cols = train.drop(['StudyInstanceUID', 'PatientID'],axis=1).columns.values.tolist()\ntargets = train[target_cols].astype(str)\n# create a new col to store the label\ntrain['combined_tar'] = ''\nfor i in tqdm(range(targets.shape[1])):\n    train['combined_tar'] += targets.iloc[:,i]\n# take a look at it\ntrain.combined_tar.value_counts()","74c855ee":"train['combined_tar'] = LabelEncoder().fit_transform(train['combined_tar'])\nlen(train['combined_tar'].unique())","38b8848c":"target_cols","604cb5be":"targets","b3444c7f":"X=train.values\ny=targets.values","2c0e4d07":"y.shape","2263f13c":"train['fold'] = -1\nrskf = RepeatedStratifiedGroupKFold(n_splits=nfold, random_state=seed)\nfor i, (train_idx, valid_idx) in enumerate(rskf.split(train, train.combined_tar, train.PatientID)): #(df, targets, group)\n    train.loc[valid_idx, 'fold'] = int(i)\n\n# !pip install \/kaggle\/input\/iterative-stratification\/iterative-stratification-master\/\n# from iterstrat.ml_stratifiers import MultilabelStratifiedKFold\n# mskf = MultilabelStratifiedKFold(n_splits=nfold, random_state=seed)\n# for i, (train_idx, valid_idx) in enumerate(mskf.split(X,y)): #(df, targets, group)\n#     train.loc[valid_idx, 'fold'] = int(i)","e431b20e":"train.query('fold==0').combined_tar.value_counts()","c163f71e":"train.query('fold==1').combined_tar.value_counts()","8e39458d":"train.query('fold==2').combined_tar.value_counts()","77f235d8":"np.intersect1d(train.query('fold==0').PatientID.unique(), train.query('fold==1').PatientID.unique())","3a943d6d":"np.intersect1d(train.query('fold==1').PatientID.unique(), train.query('fold==2').PatientID.unique())","63d998e2":"np.intersect1d(train.query('fold==2').PatientID.unique(), train.query('fold==3').PatientID.unique())","13d13e57":"train.drop('combined_tar', axis=1)\n","6d1a48d1":"train.drop('combined_tar', axis=1).to_csv('train_ctrlung_rskfolds.csv', index=False)","b9790dec":"# Augmentation of lung mask","52f2a9b7":"## Sanity Check\nYou wanna make sure this split makes sense. We can do that by checking the stratification and groups.","373065c9":"V2: \u65e0\u6570\u636e\u6cc4\u9732\u7684\u5206\u5c42KFOLD\u5212\u5206         \nV3: mask_contour\u6570\u636e\u589e\u5f3a\u7684debug         \nV4: \u8f93\u51fa\u8bad\u7ec3\u96c6\u548cpublic\u6d4b\u8bd5\u96c6\u7684mask_contour,\u4f46\u6ca1\u6709\u5212\u5206CV","407775f9":"## Split folds\nIdeas:\n1. make sure that the labels are stratified\n2. one patient's images are grouped in one fold","bbb1aa8f":"## Save final CSV","dbf1ce25":"No patient has appeared in two folds.","f239c371":"## Params","48f9ba2e":"It seems that the label is very nicely stratified. Now let's check groups."}}