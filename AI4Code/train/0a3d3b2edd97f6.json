{"cell_type":{"4b16ac52":"code","041b2fdf":"code","1447f5fd":"code","b9cf80ad":"code","87a0e717":"code","4886b30e":"code","5a209468":"code","b5617d7d":"code","62013bf5":"code","e29bd846":"code","53ab2bd8":"code","40d64d76":"code","b3357508":"code","76da2256":"code","c774f678":"code","18756efa":"code","7ba21a9d":"code","f938fa18":"code","695558f1":"code","2ba9fb8a":"code","d585579c":"code","5dbee8cb":"code","cf83065b":"code","2793c3c5":"code","a3460f6d":"code","918a038c":"code","166b863e":"code","d89f17ca":"code","4284081d":"code","84b0d403":"code","79a5f4a3":"code","3005e3cf":"code","74c7614b":"code","07ae1673":"code","7be5de1c":"code","0bb8ebb4":"code","7d91cdae":"code","e7727e84":"code","99f00431":"code","be25c25b":"code","95c46a9a":"code","30b72a20":"code","9f74e442":"code","8f5b7757":"code","5b43199e":"code","5f1e6276":"code","07c2261c":"code","e7c4c64a":"code","ab9ba6ab":"code","0db2a5b3":"code","ef8be108":"code","fe5bb7ac":"code","b08e787d":"code","abeaa3e0":"code","b38c5b1b":"code","7d664673":"code","d0cd8902":"code","f13c0d9b":"code","3ca50cc7":"code","aa13d978":"code","62d4e2b8":"code","b23227ea":"code","4ec7ae51":"code","04dc1f37":"code","25224e5c":"code","b44d683e":"code","4d60bb20":"code","203d9c4c":"code","1308e106":"code","ec435997":"code","e370f05e":"code","650d9643":"code","f16abdb1":"code","171c7fda":"code","f60f5e20":"code","94f5d6d1":"code","8f0d1a96":"markdown","156e3a21":"markdown","cceb0877":"markdown","d764132c":"markdown","48581d3b":"markdown","914f0a10":"markdown","64e7a65b":"markdown","4111b0e1":"markdown","56e607b1":"markdown","ef145052":"markdown","b4f7759b":"markdown","09ad4eb9":"markdown","02f0731d":"markdown","8fa23b5e":"markdown","731473ca":"markdown","f0b092df":"markdown","3e81e0e8":"markdown","16fa06da":"markdown","19dbec39":"markdown","113dc4c6":"markdown","b5ef3a5c":"markdown","da4bb855":"markdown","df6b6e04":"markdown","65e0fcb8":"markdown","f3d802f6":"markdown","31cf2f77":"markdown","6467e053":"markdown","0bf2a76f":"markdown","b0ed24f6":"markdown","bafec8b7":"markdown","3ca5df8f":"markdown","7efc20f4":"markdown","bf39a7f1":"markdown","dae0cbbb":"markdown","43afeae4":"markdown","76c5045b":"markdown","76dd1583":"markdown","cedc3e6b":"markdown","f2134230":"markdown","18914b9a":"markdown","7949f7af":"markdown"},"source":{"4b16ac52":"# Data frame manipulation packages {pandas, numpy, math}\nimport pandas as pd\nimport numpy as np\nimport math\n# Data visualization packages {matplotlib, seaborn, plotly}\npd.plotting.register_matplotlib_converters()\nimport matplotlib\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nimport plotly.express as px\nimport plotly.graph_objects as go\nimport plotly.figure_factory as ff\nimport matplotlib.ticker as ticker  # for formatting axis tick marks (e.g. as percentages)\nfrom matplotlib.colors import ListedColormap, LinearSegmentedColormap   # for creating custom colormaps\n# Statistical models\nimport sklearn\nfrom sklearn import linear_model\n\nprint(\"Setup Complete\")\npd.set_option('display.max_columns', 30)  # increases max number of columns shown to 30","041b2fdf":"### [Dataset \"df_ID\"] School ID and School Name\ndf_ID = pd.read_csv(\"..\/input\/201819-nys-public-school-data\/Institution Grouping.csv\")\ndf_ID.info()","1447f5fd":"# This shows the number of occurences for every type of \"GROUP_NAME\"\n# because we need to filter for individual school data while excluding district level data and others.\ndf_ID.GROUP_NAME.value_counts().sort_values()","b9cf80ad":"# Filter for data on individual schools, rather than districts and other categories.\ndf_ID = df_ID.loc[df_ID.GROUP_NAME=='Public School']\ncdf_ID = df_ID.drop(columns=['GROUP_CODE'])\n\ndf_ID.shape","87a0e717":"### [\"df_ela\"] Preparing English Language Arts (ELA) Test Results\ndf_ela  = pd.read_csv(\"..\/input\/201819-nys-public-school-data\/Annual EM ELA.csv\", na_values=['s']) # replace all 's' (suppressed data) with NaN\ndf_ela.info()","4886b30e":"df_ela = df_ela.loc[df_ela.YEAR == 2019]                         # filter for 2018-19 school year results\ndf_ela = df_ela.loc[df_ela.ASSESSMENT_NAME != \"ELA3_8\"]          # remove \"ELA3_8\" as it does not contain useful information\ndf_ela.MEAN_SCORE = df_ela.MEAN_SCORE.replace(0,np.nan)          # replace scores of 0 with NaN because those scores are not applicable\ndf_ela = df_ela.rename(columns={'NUM_TESTED':'NUM_TESTED_VALID', # NUM_TESTED_VALID is a more accurate name for number of tested students with valid scores\n                                'NOT_TESTED':'NUM_INVALID'})     # NUM_INVALID is a more accurate name for number of tested students with no valid score\ndf_ela.shape","5a209468":"# Select the releveant columns\ndf_ela = df_ela.loc[:, ['ENTITY_CD','ENTITY_NAME','ASSESSMENT_NAME','SUBGROUP_NAME','NUM_TESTED_VALID','NUM_INVALID','PER_PROF','MEAN_SCORE']]\ndf_ela.head(5)","b5617d7d":"# Number of unique entities (schools\/districts\/...\/statewide)\ndf_ela.ENTITY_NAME.unique().size","62013bf5":"# Number of unique school\/district entities for each ELA test grade\ndf_ela.groupby('ASSESSMENT_NAME').ENTITY_NAME.unique().agg([len])","e29bd846":"### [\"df_ela3\"] Assign grade 3 ELA results to a separate data frame\ndf_ela3 = df_ela.loc[df_ela.ASSESSMENT_NAME=='ELA3']\ndf_ela3.head(5)\n#df_ela4 = df_ela.loc[df_ela.ASSESSMENT_NAME=='ELA4']\n#df_ela5 = df_ela.loc[df_ela.ASSESSMENT_NAME=='ELA5']\n#df_ela6 = df_ela.loc[df_ela.ASSESSMENT_NAME=='ELA6']\n#df_ela7 = df_ela.loc[df_ela.ASSESSMENT_NAME=='ELA7']\n#df_ela8 = df_ela.loc[df_ela.ASSESSMENT_NAME=='ELA8']","53ab2bd8":"### [\"df_ela_NYS\"] Separate statewide summary data to its own data frame\n# i.e. this data summarizes performance of each demographic subgroup across all New York State Public Schools\ndf_ela_NYS = df_ela.loc[df_ela.ENTITY_NAME==\"All Public Schools\"]\ndf_ela_NYS.shape","40d64d76":"### [\"df_demo\"] Preparing School Demographic Data\ndf_demo = pd.read_csv(\"..\/input\/201819-nys-public-school-data\/Demographic Factors.csv\", )\ndf_demo.info()","b3357508":"# Filter for 2018-19 school year results\ndf_demo = df_demo.loc[df_demo.YEAR == 2019]\n\n# Select columns with desired demographic data.\n# Percentage data was chosen over student counts because it's easier to compare percentages between schools.\ndf_demo = df_demo.loc[:,['ENTITY_CD','ENTITY_NAME','PER_ELL','PER_AM_IND','PER_BLACK','PER_HISP','PER_ASIAN','PER_WHITE','PER_Multi',\n                         'NUM_AM_IND','NUM_BLACK','NUM_HISP','NUM_ASIAN','NUM_WHITE','NUM_Multi','PER_SWD',\n                      'PER_FEMALE','PER_MALE','PER_ECDIS','PER_MIGRANT','PER_HOMELESS','PER_FOSTER','PER_ARMED']]\n\n# Excluded columns: 'YEAR','NUM_ELL','NUM_SWD','NUM_FEMALE','NUM_MALE','NUM_ECDIS','NUM_MIGRANT','NUM_HOMELESS','NUM_FOSTER','NUM_ARMED'\n\ndf_demo.shape","76da2256":"df_demo.head()","c774f678":"### [df_frpl] Preparing Free and Reduced Price Lunch Data\ndf_frpl = pd.read_csv(\"..\/input\/201819-nys-public-school-data\/Free Reduced Price Lunch.csv\")\ndf_frpl.info()","18756efa":"# Filter for 2018-19 school year results\ndf_frpl = df_frpl.loc[df_frpl.YEAR == 2019]\n\n# Add calculated column for percentage of student with free OR reduced price lunch\ndf_frpl[\"PER_FREE_OR_REDUCED\"] = df_frpl.PER_FREE_LUNCH + df_frpl.PER_REDUCED_LUNCH\n\n# Identify percentages over 100% for free or reduced price lunch students\nprint(\"Number of entities with percentages over 100% for free or reduced price lunch: {}\".format(df_frpl.loc[df_frpl.PER_FREE_OR_REDUCED>100].shape[0]))\nprint(df_frpl.loc[df_frpl.PER_FREE_OR_REDUCED >100].loc[:,\"PER_FREE_OR_REDUCED\"].value_counts())\n\n# Replace percentages over 100% with 100%\ndf_frpl.PER_FREE_OR_REDUCED = df_frpl.PER_FREE_OR_REDUCED.map(lambda x: 100 if x > 100 else x)\nif df_frpl.loc[df_frpl.PER_FREE_OR_REDUCED>100].shape[0] == 0: print(\"Those percentages have been set to 100%\")\n\n# Select columns to keep\ndf_frpl = df_frpl.loc[:, ['ENTITY_CD','ENTITY_NAME','PER_FREE_LUNCH','PER_REDUCED_LUNCH','PER_FREE_OR_REDUCED']]\n\ndf_frpl.shape","7ba21a9d":"df_frpl.head(5)","f938fa18":"### [df_exp_pp] Preparing Expenditure per Pupil Data\ndf_exp_pp = pd.read_csv(\"..\/input\/201819-nys-public-school-data\/Expenditures per Pupil.csv\")\ndf_exp_pp.info()","695558f1":"# Drop YEAR column because all rows are 2019 data\ndf_exp_pp.YEAR.value_counts()\ndf_exp_pp = df_exp_pp.drop(columns=['YEAR'])","2ba9fb8a":"# Drop PUPIL_COUNT_TOT since it has the same information covered by enrollment data\ndf_exp_pp = df_exp_pp.drop(columns=['PUPIL_COUNT_TOT'])\n\ndf_exp_pp.head(5)","d585579c":"### [Dataset] Preparing Student Enrollment Data\ndf_enroll = pd.read_csv(\"..\/input\/201819-nys-public-school-data\/BEDS Day Enrollment.csv\")\ndf_enroll.info()","5dbee8cb":"df_enroll.tail()","cf83065b":"# Filter for 2018-19 school year data\ndf_enroll = df_enroll.loc[df_enroll.YEAR == 2019]\n\n# Rename grade columns, e.g. from '1' to 'GRADE_1'\nfor grade in range(1, 13):\n    df_enroll = df_enroll.rename(columns={str(grade):\"GRADE_\"+str(grade)})\n\n# Convert KFULL column to contain the sum of both KFULL and KHALF\ndf_enroll.KFULL += df_enroll.KHALF\n\n# Rename 'KFULL', 'K12', 'UGE', and 'UGS' columns\ndf_enroll = df_enroll.rename(columns={'KFULL':'K','K12':'K-12','UGE':'UNGRADED_K-6','UGS':'UNGRADED_7-12'})\n\n# Drop unnecessary columns\ndf_enroll = df_enroll.drop(columns=['YEAR','PKHALF','PKFULL','KHALF'])\n\n# Create calculated column to sum 3-8\ndf_enroll['3-8']   = df_enroll.loc[:,'GRADE_3':'GRADE_8'].sum(axis=1)\n\n# Create calculated column to sum PK-12\ndf_enroll['STUDENT_COUNT'] = df_enroll['K-12'] + df_enroll.PK\n\ndf_enroll.loc[df_enroll.ENTITY_CD==10100010014]","2793c3c5":"# Check if K-12 accurately adds all the relevant columns\nprint(\"Is K-12 adding all columns correctly? {}\".format(df_enroll.loc[:,'K':'UNGRADED_7-12'].sum().sum() == df_enroll.loc[:,'K-12'].sum()))","a3460f6d":"# Make ENTITY_CD the index for all DataFrames except df_ela\ndf_ID     = df_ID.set_index('ENTITY_CD')\ndf_frpl   = df_frpl.set_index('ENTITY_CD')\ndf_exp_pp = df_exp_pp.set_index('ENTITY_CD')\ndf_demo   = df_demo.set_index('ENTITY_CD')\ndf_enroll = df_enroll.set_index('ENTITY_CD')","918a038c":"# Merge df_ID and df_ela3 on ENTITY_CD\ndf = df_ela3.join(df_ID, on='ENTITY_CD', lsuffix='_ela3', rsuffix='_ID', how='outer')\n# Only keep rows for Public Schools\ndf = df.loc[df.GROUP_NAME=='Public School']\n\n# Merge df_frpl on ENTITY_CD\ndf = df.join(df_frpl, on='ENTITY_CD', lsuffix='_df1', rsuffix='_frpl', how='outer')\n# Only keep rows for Public Schools\ndf = df.loc[df.GROUP_NAME=='Public School']\n\n# Merge df_exp_pp on ENTITY_CD\ndf = df.join(df_exp_pp, on='ENTITY_CD', lsuffix='_df2', rsuffix='_exp_pp', how='outer')\n# Only keep rows for Public Schools\ndf = df.loc[df.GROUP_NAME=='Public School']\n\n# Merge df_demo on ENTITY_CD\ndf = df.join(df_demo, on='ENTITY_CD', lsuffix='_df3', rsuffix='_demo', how='outer')\n# Only keep rows for Public Schools\ndf = df.loc[df.GROUP_NAME=='Public School']\n\n# Merge df_enroll on ENTITY_CD\ndf = df.join(df_enroll, on='ENTITY_CD', lsuffix='_df4', rsuffix='_enroll', how='outer')\n# Only keep rows for Public Schools\ndf = df.loc[df.GROUP_NAME=='Public School']\n\ndf.shape","166b863e":"# Drop duplicate ENTITY_NAME columns\ndf = df.drop(columns=['ENTITY_NAME_ela3','ENTITY_NAME_df2','ENTITY_NAME_exp_pp','ENTITY_NAME_enroll'])","d89f17ca":"df.columns","4284081d":"# Create log transformation for PUPIL_COUNT_TOT, FED_STATE_LOCAL_EXP, PER_FED_STATE_LOCAL_EXP to help normalize the distributions\ndf['LN_STUDENT_COUNT']           = np.log(df.STUDENT_COUNT.replace(0, np.nan))\ndf['LN_FED_STATE_LOCAL_EXP']     = np.log(df.FED_STATE_LOCAL_EXP.replace(0, np.nan))\ndf['LN_PER_FED_STATE_LOCAL_EXP'] = np.log(df.PER_FED_STATE_LOCAL_EXP.replace(0, np.nan))","84b0d403":"# Create a column that recognizes if a school is in New York City\n# A school is in New York City if the first digit of ENTITY_CD is '3'\n\n# First, add back leading 0's to the ENTITY_CD values so that they are 12 digits long\ndf['ENTITY_CD'] = df.ENTITY_CD.astype('str')\ndf['ENTITY_CD'] = df.ENTITY_CD.map(lambda x: x.zfill(12))\n\n# Create new column 'NYC' that outputs 'Yes' if ENTITY_CD starts with '3'\ndf['NYC'] = ['Yes' if x[0] == '3' else 'No' for x in df.ENTITY_CD]","79a5f4a3":"### Save a csv file of the Master Data Frame\ndf.to_csv('test.csv')","3005e3cf":"### Show the Master Data Frame\ndf","74c7614b":"# % of NA values in each column\ndf.isna().sum()\/df.shape[0]*100","07ae1673":"# Number of NA values in each column\ndf.isna().sum()","7be5de1c":"# Number of non-NA values in each column\ndf.notna().sum()","0bb8ebb4":"# Number of public schools in the master dataset\ndf.ENTITY_CD.unique().size","7d91cdae":"# Number of schools have data on free and reduced price lunch participation\ndf[pd.notnull(df.PER_FREE_OR_REDUCED)].ENTITY_CD.unique().size","e7727e84":"# Number of schools that have demographic data\ndf[pd.notnull(df.PER_ELL)].ENTITY_CD.unique().size","99f00431":"# Number of schools with data on federal and state expenditure (total and per student)\ndf[pd.notnull(df.PER_FED_STATE_LOCAL_EXP)].ENTITY_CD.unique().size","be25c25b":"# Number of schools that administered the ELA3 test in 2019\ndf.loc[df.SUBGROUP_NAME=='All Students'].ENTITY_CD.unique().size","95c46a9a":"# Number of schools that report results for the ELA3 test in 2019\ndf[pd.notnull(df.MEAN_SCORE)].ENTITY_CD.unique().size","30b72a20":"# The df_ela_NYS DataFrame was created when pulling original ELA data for all grades using the following code (you can also find it in the setup section)\n# df_ela_NYS = df_ela.loc[df_ela.ENTITY_NAME==\"All Public Schools\"]\ndf_ela_NYS.head(6).sort_values(by=\"ASSESSMENT_NAME\").iloc[:,2:].style.hide_index().set_precision(0)","9f74e442":"# ELA 3 results across New York State public schools\ndf_ela_NYS.loc[df_ela_NYS.ASSESSMENT_NAME=='ELA3',['SUBGROUP_NAME','NUM_TESTED_VALID','NUM_INVALID','MEAN_SCORE','PER_PROF']].sort_values(by='PER_PROF',ascending=False)","8f5b7757":"# ELA 8 results across New York State public schools\ndf_ela_NYS.loc[df_ela_NYS.ASSESSMENT_NAME=='ELA8',['SUBGROUP_NAME','NUM_TESTED_VALID','NUM_INVALID','MEAN_SCORE','PER_PROF']].sort_values(by='PER_PROF',ascending=False)","5b43199e":"# Filter on SUBGROUP == 'All Students' and schools that disclosed an average ELA3 test score\ndf_all = df.loc[df.SUBGROUP_NAME=='All Students']\ndf_all = df_all[pd.notnull(df_all.MEAN_SCORE)].reset_index(drop=True) # Reset the index numbers\ndf_all.shape","5f1e6276":"df_all.head()","07c2261c":"# Histogram of STUDENT_COUNT at schools that disclosed ELA3 test results\nplt.figure(figsize=(11,6))\nsns.set_style('dark')\nsns.distplot(a=np.clip(df_all.STUDENT_COUNT,0,1600), kde=False, bins=range(0,1701,100))\n\n# Format x-ticks and y-ticks\nplt.xticks(range(0,1601,200), size=12)\nplt.xlim(0,1650)\nplt.yticks(size=12)\n\n# Summary statistics\nplt.axvline(df_all.STUDENT_COUNT.median(),0,1, color='black', label='Median = {}'.format(int(df_all.STUDENT_COUNT.median())), ls=\"--\", alpha=0.84)\n#plt.axvline(df_all.STUDENT_COUNT.mean(),0,1, color='royalblue', label='Mean = {}'.format(int(df_all.STUDENT_COUNT.mean())), ls=\"-\", alpha=0.95, lw=1.5)\nplt.axvline(df_all.STUDENT_COUNT.quantile(q=0.25),0,1, color='slategrey', label='25th %ile', ls=\"--\", alpha=0.85)\nplt.axvline(df_all.STUDENT_COUNT.quantile(q=0.75),0,1, color='slategrey', label='75th %ile', ls=\"--\", alpha=0.85)\nplt.legend(fontsize=12, facecolor='white')\n\n# Chart and axes titles\nplt.title('Histogram of total student count at schools that disclosed ELA3 test results', size=15)\nplt.ylabel('Number of public schools', size=12)\nplt.xlabel('Number of enrolled students', size=12)","e7c4c64a":"# Historgram of GRADE_3 student count at schools that disclosed ELA3 test results\nplt.figure(figsize=(11,6))\nsns.set_style('dark')\nsns.distplot(a=np.clip(df_all.GRADE_3,0,340), kde=False, bins=range(0,361,20))\n\n# Format x-ticks and y-ticks\nplt.xticks(range(0,341,20), size=12)\nplt.xlim(0,345)\nplt.yticks(size=12)\n\n# Summary statistics\nplt.axvline(df_all.GRADE_3.median(),0,1, color='black', label='Median = {}'.format(int(df_all.GRADE_3.median())), ls=\"--\", alpha=0.85)\n#plt.axvline(df_all.GRADE_3.mean(),0,1, color='royalblue', label='Mean = {}'.format(int(df_all.GRADE_3.mean())), ls=\"-\", alpha=0.95, lw=1.5)\nplt.axvline(df_all.GRADE_3.quantile(q=0.25),0,1, color='slategrey', label='25th %ile', ls=\"--\", alpha=0.85)\nplt.axvline(df_all.GRADE_3.quantile(q=0.75),0,1, color='slategrey', label='75th %ile', ls=\"--\", alpha=0.85)\nplt.legend(fontsize=12, facecolor='white')\n\n# Chart and axes titles\nplt.title('Histogram of 3rd grade student count at schools that disclosed ELA3 test results', size=15)\nplt.ylabel('Number of public schools', size=12)\nplt.xlabel('Number of enrolled 3rd grade students', size=12)","ab9ba6ab":"# Histogram of MEAN_SCORE: school average test score on English Language Arts 3rd grade exam\nplt.figure(figsize=(11,6))\nsns.set_style('dark')\nfig = sns.distplot(a=np.clip(df_all.MEAN_SCORE,560,640),kde=False, bins=range(560,641,5))\n\n# Format x-ticks and y-ticks\nplt.xlim(560,640)\nplt.xticks(range(560,641,10), size=12)\nplt.yticks(size=12)\n\n# Summary statistics\nplt.axvline(df_all.MEAN_SCORE.median(),0,1, color='black', label='Median = {}'.format(int(df_all.MEAN_SCORE.median())), ls=\"--\", alpha=0.85)\n#plt.axvline(df_all.MEAN_SCORE.mean(),0,1, color='royalblue', label='Mean = {}%'.format(int(df_all.MEAN_SCORE.mean())), ls=\"-\", alpha=0.95, lw=1.5)\nplt.axvline(df_all.MEAN_SCORE.quantile(q=0.25),0,1, color='slategrey', label='25th %ile', ls=\"--\", alpha=0.85)\nplt.axvline(df_all.MEAN_SCORE.quantile(q=0.75),0,1, color='slategrey', label='75th %ile', ls=\"--\", alpha=0.85)\nplt.legend(fontsize=12, facecolor='white')\n\n# Chart and axes titles\nplt.ylabel('Number of public schools', size=12)\nplt.xlabel('School average ELA3 score', size=12)\nplt.title('Histogram - NY Schools by Average ELA3 Score', size=15)","0db2a5b3":"print('School Average ELA 3 Scores - Summary Statistics')\nprint('Median: {}'.format(df_all.MEAN_SCORE.median()))\nprint('Average: {}'.format(df_all.MEAN_SCORE.mean()))\nprint('Standard Deviation: {}'.format(df_all.MEAN_SCORE.std()))","ef8be108":"# Variables for correlation matrix. I excluded highly correlated variables with very similar information.\nvariables = df_all.loc[:,['MEAN_SCORE','STUDENT_COUNT','PER_FED_STATE_LOCAL_EXP','PER_ELL',\n                           'PER_AM_IND','PER_BLACK','PER_HISP','PER_ASIAN','PER_WHITE','PER_Multi','PER_SWD','PER_MALE','PER_ECDIS','PER_MIGRANT',\n                           'PER_HOMELESS','PER_FOSTER','PER_ARMED']]\ncorr1 = variables.corr()\n# Generate custom diverging colormap\ncmap = sns.diverging_palette(20, 240, as_cmap=True)\n# Figure size and title\nplt.figure(figsize=(12,12))\nplt.title('Correlation Matrix')\n# Draw the heatmap\nsns.heatmap(corr1, cmap=cmap, vmax=1, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5})","fe5bb7ac":"# Correlation matrix filtered for the highest and lowest correlations: |r| > 0.3\nfiltered_corr1 = corr1[((corr1 >= .3) | (corr1 <= -.3)) & (corr1 !=1.000)]\n\n# figure size, style and title\nplt.figure(figsize=(13,13))\nsns.set_style('darkgrid')\nplt.title('Correlation Matrix: |r| > 0.3')\n# Generate a custom diverging colormap\ncmap = sns.diverging_palette(20, 240, as_cmap=True)\n# Draw the heatmap\nsns.heatmap(filtered_corr1, cmap=cmap, vmax=1, center=0, square=True, linewidths=.5, cbar_kws={\"shrink\": .5}, annot=True)","b08e787d":"n_variables = math.sqrt(corr1.unstack().sort_values().count())\nprint(\"There are {} variables in the correlation matrices\".format(n_variables))\n# print(\"We expect to see {} correlation pairs\".format(math.comb(n_variables,2))) # this is available in Python 3.8\ncorr1_values = corr1.unstack().sort_values().drop_duplicates().iloc[0:-1] # remove the last row because it is var1 correlation with var1","abeaa3e0":"corr1_values.head(30).reset_index().rename(columns={'level_0':'Var1','level_1':'Var2',0:'Correlation'})","b38c5b1b":"corr1_values.sort_values(ascending=False).head(30).reset_index().rename(columns={'level_0':'Var1','level_1':'Var2',0:'Correlation'})","7d664673":"# Histogram of PER_ECDIS: percent of economically disadvantaged students at a school\nplt.figure(figsize=(11,6))\nsns.set_style('dark')\nfig = sns.distplot(a=df_all.PER_ECDIS,kde=False, bins=20)\n\n# Format x-ticks and y-ticks\nplt.xlim(0,100)\nplt.xticks(range(0,101,10), size=12)\nfig.xaxis.set_major_formatter(ticker.PercentFormatter(100))  \nplt.yticks(size=12)\n\n# Summary statistics\nplt.axvline(df_all.PER_ECDIS.median(),0,1, color='black', label='Median = {}%'.format(int(df_all.PER_ECDIS.median())), ls=\"--\", alpha=0.85)\n#plt.axvline(df_all.PER_ECDIS.mean(),0,1, color='royalblue', label='Mean = {}%'.format(int(df_all.PER_ECDIS.mean())), ls=\"-\", alpha=0.95, lw=1.5)\nplt.axvline(df_all.PER_ECDIS.quantile(q=0.25),0,1, color='slategrey', label='25th %ile', ls=\"--\", alpha=0.85)\nplt.axvline(df_all.PER_ECDIS.quantile(q=0.75),0,1, color='slategrey', label='75th %ile', ls=\"--\", alpha=0.85)\nplt.legend(fontsize=12, facecolor='white')\n\n# Chart and axes titles\nplt.ylabel('Number of public schools', size=12)\nplt.xlabel('Proportion of a school\\'s students that are economically disadvantaged', size=12)\nplt.title('Histogram - NY Schools by Economic Disadvantage', size=15)","d0cd8902":"# Calculate how many public students are economically disadvantaged across all grades\ndf_ECDIS_calc = df.PER_ECDIS * df.STUDENT_COUNT \/ 100\nprint(\"In the dataset of public schools:\")\nprint(\"There are {} public school students\".format(int(df.STUDENT_COUNT.sum())))\nprint(\"Of these, there are {} economically disadvantaged students\".format(int(df_ECDIS_calc.sum())))\nprint(\"As a proportion, {}% of students are economically disadvantaged\".format(round(df_ECDIS_calc.sum() \/ df.STUDENT_COUNT.sum()*100,2)))","f13c0d9b":"# Create plot\nplt.figure(figsize=(12,10))\nsns.set_style('whitegrid')\nfig = sns.regplot(x=df_all.PER_ECDIS, y=df_all.MEAN_SCORE, scatter_kws={'alpha':0.3,'s':50,'color':'steelblue','linewidth':0},\n            line_kws={'color': 'midnightblue'}, x_jitter=0.4, y_jitter=0.4)\n\n# Specify x-axis tick marks and set tick font size\nplt.xticks(range(0,101,10), size=12)\nplt.xlim(0,100)\nplt.yticks(size=12)\n\n# Format x-axis as a percentage\nfig.xaxis.set_major_formatter(ticker.PercentFormatter(100))  \n\n# add chart labels\nplt.xlabel('Percent of a school\\'s students that are economically disadvantaged',fontsize=13)\nplt.ylabel('School average test score (Grade 3 English Language Arts)',fontsize=13)\nplt.title('NY State Public Schools - 3rd Grade Test Scores vs. Economic Disadvantage', fontsize=18)","3ca50cc7":"# Calculate the slope using sklearn\ntemp_reg = linear_model.LinearRegression()\ntemp_reg.fit(np.array(df_all.PER_ECDIS).reshape(-1,1), df_all.MEAN_SCORE)\nprint(\"slope: %s\" % (temp_reg.coef_))\nprint(\"intercept: %s\" % (temp_reg.intercept_))","aa13d978":"### Create a table\nfig = ff.create_table(pd.DataFrame({\n    'Grade 3 English Language Arts':['Test Score','Performance for Grade Level'], \n    'Level 1':['532-582','Well Below Proficiency'], # Students performing at this level<br>are *well below proficient* in<br>standards for their grade.\n    'Level 2':['583-601','Partially Proficient'], # Students performing at this level<br>are *partially proficient* in<br>standards for their grade.\n    'Level 3':['602-628','Proficient'], # Students performing at this level<br>are *proficient* in standards<br>for their grade.\n    'Level 4':['629-654','Excels Beyond Grade Standards'] # Students performing at this level<br>*excel* in standards for their<br>grade.\n}))\n\nfig.layout.width = 1150\nfig.show()","62d4e2b8":"# Calculate a new column based on the performance table above\ndf_all['PERF_LEVEL'] = pd.cut(df_all.MEAN_SCORE, bins=[532,582,601,628,654], labels=['Level 1','Level 2','Level 3','Level 4'], include_lowest=True)\ndf_all.PERF_LEVEL","b23227ea":"# Set chart size and style\nplt.figure(figsize=(12,10))\nsns.set_style('white')\n\n# Create the chart\nfig = sns.regplot(x=df_all.PER_ECDIS, y=df_all.MEAN_SCORE, scatter_kws={'alpha':0.33,'s':50,'color':'steelblue','linewidth':0},\n            line_kws={'color': 'midnightblue','lw':2,'alpha':0.7}, ci=None, x_jitter=0.4, y_jitter=0.4) # remove confidence interval and add jitter\n\n# Add horizontal regions to denote proficiency\nplt.axhspan(628.5, 654, label='Level 4 (Excels)', color='green', alpha=0.2, lw=0)\nplt.axhspan(601.5, 628.5, label='Level 3 (Proficient)', color='darkslateblue', alpha=0.2, lw=0)\nplt.axhspan(582.5, 601.5, label='Level 2 (Partially Proficient)', color='orange', alpha=0.2, lw=0)\nplt.axhspan(532, 582.5, label='Level 1 (Well Below Proficient)', color='red',alpha=0.2,lw=0)\n\n\n# Add vertical lines to show x-axis distribution\n#plt.axvline(df_all.PER_ECDIS.median(),0,1, color='black', label='Median = {}% economically disadvantaged'.format(int(df_all.PER_ECDIS.median())), ls=\"--\", alpha=0.85)\n#plt.axvline(df_all.PER_ECDIS.quantile(q=0.25),0,1, color='slategrey', label='25th %ile', ls=\"--\", alpha=0.85)\n#plt.axvline(df_all.PER_ECDIS.quantile(q=0.75),0,1, color='slategrey', label='75th %ile', ls=\"--\", alpha=0.85)\n\n# Add legend\nplt.legend(fontsize='large',title_fontsize='x-large',title='School Avg. Proficiency',facecolor='white',\n          loc='best', bbox_to_anchor=(1,1))\n\n# Format x-axis and y-axis\nplt.xticks(range(0,101,10), size=12)\nfig.xaxis.set_major_formatter(ticker.PercentFormatter(100))\nplt.yticks(size=12)\nplt.xlim(0,100)\nplt.ylim(532,654)\n\n# Add chart labels\nplt.xlabel('Percent of a school\\'s students that are economically disadvantaged (%)',fontsize=13)\nplt.ylabel('School average test score (Grade 3 English Language Arts)',fontsize=13)\nplt.title('NY State Public Schools - 3rd Grade Test Scores vs. Economic Disadvantage', fontsize=18)","4ec7ae51":"# Count the number of schools in each performance level\ndistribution_PER_ECDIS = pd.DataFrame({\n    'Level 1 (Well Below Proficient)':[df_all.loc[df_all.PERF_LEVEL=='Level 1'].shape[0]],\n    'Level 2 (Partially Proficient)':[df_all.loc[df_all.PERF_LEVEL=='Level 2'].shape[0]],\n    'Level 3 (Proficient)':[df_all.loc[df_all.PERF_LEVEL=='Level 3'].shape[0]],\n    'Level 4 (Excels)':[df_all.loc[df_all.PERF_LEVEL=='Level 4'].shape[0]]})\ndistribution_PER_ECDIS.style.hide_index()","04dc1f37":"# Cut PER_ECDIS continuous data into 5 equal categorical bins\ndf_all['categorical_PER_ECDIS'] = pd.cut(df_all.PER_ECDIS, bins=range(0,101,20), include_lowest=True)\ndf_all.categorical_PER_ECDIS.value_counts().sort_index(ascending=False)","25224e5c":"# (first 4 columns) Use grouping to identify how many schools in each categorical_PER_ECDIS are in each PERF_LEVEL\ndist_cat_PER_ECDIS = df_all.groupby(['categorical_PER_ECDIS','PERF_LEVEL']).MEAN_SCORE.count().unstack().sort_index(ascending=False)\ndist_cat_PER_ECDIS.columns = dist_cat_PER_ECDIS.columns.astype(str)\ndist_cat_PER_ECDIS\n\n# (last 5 columns) Calculate the percentage distribution of PERF_LEVEL within each categorical_PER_ECDIS category\ndist_cat_PER_ECDIS['Total'] = dist_cat_PER_ECDIS.iloc[:,0:4].sum(axis=1)\ndist_cat_PER_ECDIS['Level 1 (%)'] = round(100 * dist_cat_PER_ECDIS['Level 1'] \/ dist_cat_PER_ECDIS['Total'], 1)\ndist_cat_PER_ECDIS['Level 2 (%)'] = round(100 * dist_cat_PER_ECDIS['Level 2'] \/ dist_cat_PER_ECDIS['Total'], 1)\ndist_cat_PER_ECDIS['Level 3 (%)'] = round(100 * dist_cat_PER_ECDIS['Level 3'] \/ dist_cat_PER_ECDIS['Total'], 1)\ndist_cat_PER_ECDIS['Level 4 (%)'] = round(100 * dist_cat_PER_ECDIS['Level 4'] \/ dist_cat_PER_ECDIS['Total'], 1)\ndist_cat_PER_ECDIS","b44d683e":"# Function for modifying preset colormaps\ndef cmap_map(function, cmap):\n    \"\"\" Applies function (which should operate on vectors of shape 3: [r, g, b]), on colormap cmap.\n    This routine will break any discontinuous points in a colormap.\n    \"\"\"\n    cdict = cmap._segmentdata\n    step_dict = {}\n    # Firt get the list of points where the segments start or end\n    for key in ('red', 'green', 'blue'):\n        step_dict[key] = list(map(lambda x: x[0], cdict[key]))\n    step_list = sum(step_dict.values(), [])\n    step_list = np.array(list(set(step_list)))\n    # Then compute the LUT, and apply the function to the LUT\n    reduced_cmap = lambda step : np.array(cmap(step)[0:3])\n    old_LUT = np.array(list(map(reduced_cmap, step_list)))\n    new_LUT = np.array(list(map(function, old_LUT)))\n    # Now try to make a minimal segment definition of the new LUT\n    cdict = {}\n    for i, key in enumerate(['red','green','blue']):\n        this_cdict = {}\n        for j, step in enumerate(step_list):\n            if step in step_dict[key]:\n                this_cdict[step] = new_LUT[j, i]\n            elif new_LUT[j,i] != old_LUT[j, i]:\n                this_cdict[step] = new_LUT[j, i]\n        colorvector = list(map(lambda x: x + (x[1], ), this_cdict.items()))\n        colorvector.sort()\n        cdict[key] = colorvector\n\n    return matplotlib.colors.LinearSegmentedColormap('colormap',cdict,1024)","4d60bb20":"# Create custom colormap\ncolors = ['red','orange','darkslateblue','green']\ncm = LinearSegmentedColormap.from_list(\"Proficiency Colormap\",colors)\n# Make the colormap colors lighter\nlight_cm = cmap_map(lambda x: x\/1.5 + 1\/3, cm)\n\n# Create a horizontal stacked bar chart showing the relationship between household income and 3rd grade english language arts proficiency\nfig = dist_cat_PER_ECDIS.iloc[:,-4:].plot(kind='barh', stacked=True, figsize=(12,7), fontsize=13, xlim=(0,100), cmap=light_cm)\n\n# Move legend outside plot and reverse order of appearance of the categories\nhandles, labels = fig.get_legend_handles_labels()\nlabels = [x[:7] for x in labels]\nfig.legend(handles[::-1], labels[::-1], title='School Avg. Proficiency', loc='best', bbox_to_anchor=(1, 1), fontsize='large', title_fontsize='large', edgecolor='black')\n\n# Set x-tick labels\nfig.set_xticklabels(['0%','','','','','100%'])\n\n# Set y-tick labels\nfig.tick_params(axis='y',pad=100)\nfig.set_yticklabels(['80 to 100%\\neconomically\\ndisadvantaged', '60 to 80%\\neconomically\\ndisadvantaged',\n                     '40 to 60%\\neconomically\\ndisadvantaged', '20 to 40%\\neconomically\\ndisadvantaged', '0 to 20%\\neconomically\\ndisadvantaged'],\n                      fontdict=dict(horizontalalignment='left'))\n\n# Xemove x-axis gridlines\nfig.grid(axis='y',b=True)\n\n# Set y-axis title and chart title\nplt.ylabel(\"\")\nplt.title('Distribution of ELA3 Performance based on Economic Disadvantage', fontsize=16)","203d9c4c":"# Set chart size and style\nplt.figure(figsize=(12,10))\nsns.set_style('whitegrid')\n\n# Create the chart\nfig = sns.regplot(x=df_all.PER_ECDIS, y=df_all.PER_PROF, scatter_kws={'alpha':0.3,'s':50,'color':'steelblue','linewidth':0},\n            line_kws={'color': 'midnightblue'}, x_jitter=0.3, y_jitter=0.3)\n\n# Specify x-axis and y-axis tick marks\nplt.xticks(range(0,101,10), size=12)\nplt.xlim(0,100)\nplt.yticks(size=12)\nplt.ylim(0,100)\n\n# Format x-axis and y-axis as percentages\nfig.xaxis.set_major_formatter(ticker.PercentFormatter(100))  \nfig.yaxis.set_major_formatter(ticker.PercentFormatter(100))  \n\n\n# add chart labels\nplt.xlabel('Percent of a school\\'s students that are economically disadvantaged',fontsize=13)\nplt.ylabel('Percent of proficient studenta',fontsize=13)\nplt.title('NY State Public Schools - 3rd Grade English Proficiency vs. Economic Disadvantage', fontsize=18)","1308e106":"# Calculate the slope using sklearn\ntemp_reg = linear_model.LinearRegression()\ntemp_reg.fit(np.array(df_all.PER_ECDIS).reshape(-1,1), df_all.PER_PROF)\nprint(\"slope: %s\" % (temp_reg.coef_))\nprint(\"intercept: %s\" % (temp_reg.intercept_))","ec435997":"# Racial breakdown of New York State Public Schools in the ELA3 test dataset\ndf_race = df_all.loc[:,['STUDENT_COUNT','NUM_AM_IND','NUM_BLACK','NUM_HISP','NUM_ASIAN','NUM_WHITE','NUM_Multi']]\n\n# Calculate if any students are not classified many students of  each race ~approximately~\ndf_race['Unclassified'] = df_race['STUDENT_COUNT'] - df_race.iloc[:,-5:].sum(axis=1)\n\n# Add a 'Total' row to the bottom of the Data Frame\n#df_all_races.append(df_all_races.sum(numeric_only=True), ignore_index=True)\ndf_race.loc['Total']= df_race.sum(numeric_only=True, axis=0)\n\ndf_race","e370f05e":"# Table of totals\ndf_race.iloc[-1:,-7:].rename(columns={'NUM_WHITE':'White','NUM_HISP':'Hispanic','NUM_BLACK':'Black','NUM_ASIAN':'Asian','NUM_Multi':'Multiracial','NUM_AM_IND':'American Indian'})","650d9643":"# Transposed for pie charts, excluding those who are unclassified\ndf_race_pie = df_race.iloc[-1:,-7:-1].rename(columns={'NUM_WHITE':'White','NUM_HISP':'Hispanic','NUM_BLACK':'Black','NUM_ASIAN':'Asian',\n                                                      'NUM_Multi':'Multiracial','NUM_AM_IND':'American Indian'}\n                                            ).transpose().rename_axis('Race').reset_index().sort_values(by='Total',ascending=False)\ndf_race_pie","f16abdb1":"# Plotly express pie chart\nfig = px.pie(df_race_pie, values='Total', names='Race')\nfig.update_traces(textposition='inside', textinfo='percent+label') \nfig.show()","171c7fda":"# Matplotlib pie chart\nplt.pie(df_race.iloc[-1:,-7:-1])","f60f5e20":"# create figure using plotly express\nfig = px.scatter(df_all, y='MEAN_SCORE', x='PER_ECDIS',color='PER_WHITE',size='NUM_TESTED_VALID',symbol='NYC',\n                 opacity=0.3, size_max=20, range_x=[-3,103], range_y=[557,635], color_continuous_scale='Plasma',\n                 height = 600,\n                 hover_name='ENTITY_NAME_ID',hover_data=['NUM_TESTED_VALID'],\n                 title='New York State Public Schools - 3rd Grade Test Scores vs. Economic Disadvantage',\n                 labels={'MEAN_SCORE':'Avg Test Score','PER_ECDIS':'% Economically Disadvantaged','PER_WHITE':'% White','NUM_TESTED_VALID':'Students Tested','NYC':'NYC School'},\n                 trendline='ols')\n# format colorbar\nfig.update_layout(coloraxis=dict(cmin=0, cmax=100),\n                 coloraxis_colorbar=dict(len=0.77, ticks=\"outside\",ticksuffix=\"%\", borderwidth=1, title_font_size=13, yanchor=\"bottom\", y=0))\n\n# format and move symbol legend slightly to the left\nfig.update_layout(legend=dict(y=1, borderwidth=1, title_font_size=13))\n\n# format x-axis\nfig.update_layout(xaxis=dict(ticksuffix='%'))\n\n# set font color to black\nfig.update_layout(font=dict(color=\"black\"))\n\nfig.show()","94f5d6d1":"# create figure using plotly express\nfig = px.scatter(df_all, y='MEAN_SCORE', x='PER_WHITE',color='PER_ECDIS',size='NUM_TESTED_VALID',symbol='NYC',\n                 opacity=0.3, size_max=20, range_x=[103,-3], range_y=[557,635], color_continuous_scale=px.colors.sequential.Plasma[::-1],\n                 height=600,\n                 hover_name='ENTITY_NAME_ID',hover_data=['NUM_TESTED_VALID'],\n                 title='New York State Public Schools - 3rd Grade Test Scores vs. Race ',\n                 labels={'MEAN_SCORE':'Avg Test Score','PER_ECDIS':'% Economically<br>Disadvantaged','PER_WHITE':'% White','NUM_TESTED_VALID':'Students Tested','NYC':'NYC School'},\n                 trendline='ols')\n# format colorbar\nfig.update_layout(coloraxis=dict(cmin=0, cmax=100), colorscale=dict(sequential='greys'),\n                 coloraxis_colorbar=dict(ticks=\"outside\",ticksuffix=\"%\", borderwidth=1, title_font_size=13, \n                                         len=0.77, yanchor=\"bottom\", y=0))\n\n# format and move symbol legend slightly to the left\nfig.update_layout(legend=dict(y=1, borderwidth=1, title_font_size=13))\n\n# format and reverse x-axis\nfig.update_layout(xaxis=dict(ticksuffix='%'))\n\n# set font color to black\nfig.update_layout(font=dict(color=\"black\"))\n\nfig.show()","8f0d1a96":"The table above shows summary statistics for the English Language Arts (ELA) standardized tests administered across New York public schools in 2019. It shows the number of New York students that took the test, including the number that had valid scores and the number that had invalid scores (i.e. scores that were excluded from the data). In total, around 200,000 students took the ELA test in each grade, with more valid scores in the lower grades. Generally, the percent that scored \"proficient\" was around 40-50% of the grade, with the average score intentionally centered on 600.\n\n**While ELA results are reported for Grade 3 through Grade 8, I only focus on Grade 3 results to keep my analysis simple**. I intuitively believe that performance trends found among Grade 3 students will probably persist through later grades of schooling, as research has shown that early school performance is a predictor for later school performance.\n\nTo quickly test this, let's see if there's similarity between the ELA3 and ELA8 test performances of various demographic subgroups:","156e3a21":"### Correlation matrix\n\nHere is a correlation matrix \/ heatmap of all the continuous variables I'm interested in. Blue indicates positive correlation while red indicates negative correlation.","cceb0877":"## Analysis of all NY schools that disclosed 3rd Grade English Language Arts test results","d764132c":"The scatterplot above shows an obvious negative trend. On average, as proportion of economically disadvantaged students increases by 10%, average test scores decrease by about 1.7\n\nBut, how big is the difference between a test score of 590 and 610? What does this mean for a student's learning outcomes?\n\nTo understand the context, it helps to refer to the New York State Education Department's [English Language and Arts performance guidelines](http:\/\/www.p12.nysed.gov\/irs\/ela-math\/). The table below shows the proficiency levels that correpond to test scores on the 3rd Grade ELA test.","48581d3b":"## Merging Datasets\nIn this section, I combine all the datasets into a single Data Frame.","914f0a10":"The variables most positively correlated with average ELA3 scores are:\n* Percent of Asian students (0.31)\n* Percent of White students (0.16)","64e7a65b":"Here's the head of the dataframe containing 2,449 public schools with valid ELA3 test score data.","4111b0e1":"## Racial Distribution in New York State Public Schools\n\nRacial segregation in public schools has been a major issue for New York, and especially New York City, for many years. ","56e607b1":"Comparing the 3rd Grade and 8th Grade tables, we can see there is some difference in how demographic subgroups performed. However, the changes are minor.","ef145052":"In the chart above, I've switch how race and economic disadvantage are represented. Percentage of white students is now on the x-axis, whereas the previous chart represented it by data point color. Color now represents percentage of economically disadvantage students.\n\n### Similarities and differences:\n* Compared to the previous chart, the trend between race and average test score is less obvious than the trend between economic disadvantage and average test score\n* Similar to the previous chart, there is a clear negative relationship between percentage of white students and percentage of economically disadvantage students\n    * However, it's interesting to note that the least economically disadvantaged schools are between 60%-90% white. The schools that are above 90% white appear to have more economically disadvantaged students and lower average test scores.\n    \n**New observations:**\n* The two trendlines indicate that there is a more significant relationship between race and test scores for NYC schools compared to non-NYC schools\n    * The slope of the trendline for NYC schools is relatively steeper, but still less steep than the two trendlines in the previous graph\n    * The slope of the trendline for non-NYC schools is much flatter and less significant than all other trendlines\n* The clustering of data points on the left-most and right-most sides of the chart suggest the segregation of New York public schools","b4f7759b":"The correlation matrix below only shows correlation values < 0.3 or > 0.3 for easier viewing. Only two variables - Percent Economically Disadvantaged and Percent Asian - show up as being correlated with MEAN_SCORE in the figure below.","09ad4eb9":"The median 3rd grade enrollment of 71 is 6.4 times smaller than the median school enrollment. This is also not unexpected.","02f0731d":"The stacked bar chart below separates schools into five categories of economic disadvantage. For example, the top category represents schools with between 0% and 20% of the student population being economically disadvantaged. For this category, roughly 90% of schools have an average test score that reflects Level 3 proficiency. By contrast, for schools where 80% to 100% of students are economically disadvantaged, less than 20% of schools have an average test score that reflects Level 3 proficiency. As mentioned above, Level 3 proficiency is the desired proficiency level to be on par with 3rd Grade expectations.\n\n","8fa23b5e":"## Number of schools reporting data in each field","731473ca":"# -- Summary Analysis --","f0b092df":"# -- Preparation --\n\n## Setup Python packages\nLoad the necessary Python packages. Matplotlib, Seaborn and Plotly are used for data visualizations. Plotly and Plotly Express are used for interative charts.","3e81e0e8":"### Distribution of average ELA3 test scores","16fa06da":"### Is there a relationship between economic disadvantage and test scores?\nLet's start by seeing if there is a linear relationship between proportion of students that are economically disadvantaged and the average performance on the ELA3 standardized test.","19dbec39":"The chart above visualizes the data with the performance level ranges. We can see that most schools have an average test score that reflects Level 2 or Level 3 performance. As such, there are many schools where the average test score is Level 2 or below, meaning the average student is not proficient for 3rd grade English. Let's examine the number of schools within each performance level.","113dc4c6":"## Using multiple variables to predict school performance\n\nNow it's time to compare the following variables and see if they can work together:\n* Economic disadvantage\n* Race\n* NYC vs. non-NYC","b5ef3a5c":"The median school enrollment is 457 students. This is within expectations.","da4bb855":"The chart above is interactive and displays three new variables:\n1. ***Size*** represents the number of 3rd grade students tested\n2. ***Color*** represents that number of white students as a percentage of the whole school's population (i.e. all grades)\n3. ***Shape*** represents whether the school is located in a New York City school district (diamond) or not (circle)\n\nMousing over a data point will display the school's name and it's corresponding data. Clicking on the legend for \"NYC School\" will filter the data to show only New York City schools, only non-New York City schools or both.\n\n### Some notable trends:\n* Schools with more non-white students have more economically disadvantaged students\n* Schools with more economically disadvantaged students have lower average test scores\n\n**Interestingly, there is a significant difference between NYC schools and non-NYC schools:**\n* NYC schools have more non-white students AND more economically disadvantaged students\n    * Most NYC schools are majority non-white and majority economically disadvantaged\n    * Non-NYC schools are evenly spread across various levels of economic disadvantage\n* NYC schools have higher average test scores, after accounting for econonomic disadvantage\n    * The trendline for NYC schools is roughly 8-10 points higher than the trendline for non-NYC schools\n    * The two trendlines have similar slopes, suggesting that economic disadvantage has similar effect on both NYC and non-NYC schools\n","df6b6e04":"## Summary data across all New York State public schools","65e0fcb8":"# --- Prediction Algorithm ---","f3d802f6":"# ***WORK IN PROGRESS***","31cf2f77":"Things I want to show in this section\n* Race vs. test score across NY State\n* Racial makeup on NY State\n* Racial makeup vs. economic disadvantage","6467e053":"## NYC vs. Non-NYC Public Schools","0bf2a76f":"The two tables below list the 30 most negatively and positively correlated variables. As before, I'm particularly interested in correlation with MEAN_SCORE, because that is the indicator of academic performance.","b0ed24f6":"### Student enrollment numbers","bafec8b7":"* 4,725 public schools total <br>\n* 4,719 disclosed demographic data <br>\n* 4,683 disclosed federal and state expenditure per student <br>\n* 2,468 administered the 3rd grade English Language Arts (ELA) test in 2019 <br>\n* 2,449 disclosed average test scores for the 3rd grade English Language Arts (ELA) test <br>\n  *Note: there must be at least 5 valid test results for a school to disclose average test scores; 19 schools did not meet this criteria*\n\n**My analysis below is focused on the the ELA 3rd Grade test, with a sample size of 2,449 schools.**","3ca5df8f":"This is histogram is as expected, since the standardized test scores are intentionally centered on 600.","7efc20f4":"We can see that the median school in our ELA3 dataset has 61% of students that are economically disadvantaged.\n\nTo verify this, I found around 199,486 students are economically disadvantaged out of a total of around 1,241,667 students. Thus, an estimated 60.6% of public school students are economically disadvantaged. This aligns with our statistic about the median school in our sample.\n\nThis is also not a normal distribution. As the percentage of economically disadvantaged students increases, the count also increases. This shows that there is a concentration of schools that have near 100% economically disadvantaged students.","bf39a7f1":"# --- Start of Detailed Analysis ---","dae0cbbb":"## Load and prepare datasets\nIn this section, I load multiple datasets from .csv files downloaded from the government website. After loading the data, I create various filters to select the rows and columns of interest (e.g. I'm only looking at the 2018-19 school year). I also add calculated fields such as totals (e.g. enrollment total calculated by summing enrollment in each grade).\n\nThe code below loads and prepares the following datasets in order:\n* School ID and School Name\n* English Language Arts Scores (Standardized Test)\n* School Demographic Data\n* School Free and Reduced Price Lunch Data\n* Federal\/State\/Local School Expenditure\n* School Enrollment by Grade","43afeae4":"Looking at the table above, AAPIs and Not Economically Disadvantaged students have the highest proficiency percentages (71%, 68%), while Migrant and English Language Learners have the lowest proficiency percentages (16%, 20%).\n\n**Let's compare these ELA3 results to the ELA8 results for the same demographic subgroups below:**\n\nAAPIs and Not Economically Disadvantaged students maintain the highest proficiency percentages (70%, 61%), while English Language Learners and Foster Care have the lowest proficiency percentages (4%, 10%).","76c5045b":"The variables most negatively correlated with average ELA3 scores are:\n* Percent of economically disadvantaged students (-0.52)\n* Percent of students with disabilities (-0.28)\n* Percent of English language learners (-0.24)\n* Percent of homeless students (-0.23)\n* Percent of Black students (-0.20)\n* Percent of Hispanic students (-0.20)\n* Percent of students in foster care (-0.16)","76dd1583":"## Economic Disadvantage in New York State Public Schools","cedc3e6b":"The scatterplot below tells a similar story to the charts above. This time, we see how percentage of economically disadvantaged students is negatively correlated to the percentage of students that demonstrated proficiency in the ELA3 test. The regression trendline suggest that on average, as percentage of economically disadvantaged students increases by 10%, proportion of proficient students decreases by 3.86%","f2134230":"# 2019 New York standardized test performance by demographic\n\n<br>\n\n![Kids%20%28cut%29.jpg](attachment:Kids%20%28cut%29.jpg)\n\nLet's explore educational equity and inequity in New York state. For those new to the term, the basis of \"educational equity\" is to ensure that every student is provided the resources, opportunities and support needed to succeed in their schooling, regardless of their household income, race, gender, disability or other demographic factors. Besides equity, there are many related education issues, for example, school segregation, school funding, standardized testing, curriculums, and affirmative action. Rather than tackle all these topics today, my focal question is:\n\n**Are the public school students of New York, in all their diverse groups, succeeding at school?**\n\nEach year, the New York State Department of Education releases [data](https:\/\/data.nysed.gov\/downloads.php) on its 4,400 public schools, including standardized test scores and demographic information. Using this data, we can start to understand whether all groups are succeeding equally, and if not, to what extent is school performance influenced by demographic factors. Since the data available is school-by-school, rather than student-by-student, I'll reframe my question of interest:\n\n**How many public schools are succeeding in New York and who is attending them?**\n\nAt the end, I will test whether we can predict the performance of a school using an algorithm based on demographic features of the student body.\n\n# -- Process Overview --\n1. Import Python packages\n2. Load datasets and filter for relevant data\n3. Merge datasets together\n4. Create calculated fields and perform data transformation\n5. Analyze summary data like test score distribution and student enrollment\n6. Analyze relationship between test scores and economic disadvantage\n7. Analyse relationship between test scores and race\n8. Analyse relationship between test scores and NYC vs. non-NYC\n9. Analyse multiple relationships together\n10. Use model selection to create a machine learning algorithm","18914b9a":"## Calculating and Transforming Columns\nIn this section, I create new and useful fields from the original fields. For example, I use the first digit of the school's ENTITY_ID to create a field that indicates whether a school is in New York City or outside New York City. After this, the table shown below is the \"Master\" Data Frame that I will use for my analysis.","7949f7af":"Using the performance levels provided by the New York State Education Department, we can see that students who score 602 and above would be considered proficient by 3rd grade English standards. Any score of 601 and below would represent partial proficiency or less."}}