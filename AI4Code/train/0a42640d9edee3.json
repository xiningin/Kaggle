{"cell_type":{"288fafda":"code","5b494b8d":"code","7397df66":"code","508d3f2b":"code","88b2a370":"code","045996ec":"code","0574c90a":"code","29973a54":"code","dc357b5d":"code","2dbdc1db":"code","9edcfc4a":"code","4eba0325":"code","853675c0":"code","cb7f47ea":"code","4355baf1":"markdown"},"source":{"288fafda":"import os\nimport re\nimport json\nimport pandas as pd\nimport numpy as np\n\nimport matplotlib.pyplot as plt\n%matplotlib inline\nimport seaborn as sns\nsns.set(style=\"whitegrid\")\nfrom wordcloud import WordCloud, STOPWORDS\nimport plotly.graph_objects as go\n\nimport warnings\nwarnings.filterwarnings('ignore')\n\nfrom tqdm import tqdm","5b494b8d":"path = '..\/input\/coleridgeinitiative-show-us-the-data\/train\/'\nfor f in os.listdir(path):\n    f = open(path+f)\n    \n    sample = json.load(f)\n    break\n    \nsample[0]","7397df66":"for i, s in enumerate(sample):\n    print(s['section_title'])\n    \n    if (i>5):\n        break","508d3f2b":"train=pd.read_csv('..\/input\/coleridgeinitiative-show-us-the-data\/train.csv')\nsubmit = pd.read_csv('..\/input\/coleridgeinitiative-show-us-the-data\/sample_submission.csv')\ntest=submit[['Id']]\n\ntrain.shape, test.shape","88b2a370":"train.head()","045996ec":"def clean_text(txt):\n    return re.sub('[^A-Za-z0-9]+', ' ', str(txt).lower()).strip()\n\ndef get_train_text(filename):\n    path = '..\/input\/coleridgeinitiative-show-us-the-data\/train\/' + filename + '.json'\n    df = pd.read_json(path)\n    \n    text = ' '.join(df['text'])\n    return text\n\ndef get_test_text(filename):\n    path = '..\/input\/coleridgeinitiative-show-us-the-data\/test\/' + filename + '.json'\n    df = pd.read_json(path)\n    \n    text = ' '.join(df['text'])\n    return text","0574c90a":"for i in tqdm(range(len(train))):\n    filename = train.loc[i,'Id']\n    train.loc[i,'text'] = clean_text(get_train_text(filename))\n    \nfor i in range(len(test)):\n    filename = test.loc[i,'Id']\n    test.loc[i,'text'] = get_test_text(filename)","29973a54":"for i in range(len(train)):\n    label = train.loc[i,'cleaned_label']\n    text = train.loc[i,'text']\n    \n    if (label in text):\n        train.loc[i,'is_present']=1\n    else:\n        train.loc[i,'is_present']=0","dc357b5d":"train['is_present'].value_counts()","2dbdc1db":"dataset_labels = train['cleaned_label'].unique()","9edcfc4a":"for i in range(len(test)):\n    text = clean_text(test.loc[i,'text'])\n    \n    prediction_labels=[]\n    for label in dataset_labels:\n        if (label in text):\n            prediction_labels.append(label)\n            \n    test.loc[i,'PredictionString'] = '|'.join(prediction_labels)","4eba0325":"test","853675c0":"submit['PredictionString'] = test['PredictionString']\nsubmit","cb7f47ea":"submit.to_csv('submission.csv',index=False)","4355baf1":"Building an algorithm that can discern what datasets have been used by publications"}}