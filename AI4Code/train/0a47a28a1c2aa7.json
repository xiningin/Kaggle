{"cell_type":{"68ed3ed0":"code","da37a059":"code","4a0a6dff":"code","9b3029be":"code","bf5899d8":"code","f4f84d2f":"code","2b833b1f":"code","f1eaae68":"code","ca12950b":"code","6d3e0fa7":"code","38b81b4b":"code","ffb844c7":"code","564be992":"code","d546f6c9":"code","70bd5da9":"markdown","f9684dab":"markdown","02775434":"markdown","bcc0f6c2":"markdown","8aabf067":"markdown","35295ab3":"markdown","6aa0ad73":"markdown","e1dd6bca":"markdown","14a38234":"markdown","74466a6d":"markdown","d0109dcc":"markdown","9831a180":"markdown","1d544f91":"markdown"},"source":{"68ed3ed0":"# Imported Libraries\nimport pandas as pd\nimport seaborn as sns\nimport numpy as np\nimport matplotlib.pyplot as plt\nfrom sklearn.preprocessing import StandardScaler, RobustScaler\nfrom scipy import interp\nfrom sklearn import metrics\nfrom sklearn.metrics import auc, roc_curve, average_precision_score, f1_score, precision_recall_curve, confusion_matrix\nfrom sklearn.model_selection import StratifiedKFold\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.model_selection import train_test_split, RandomizedSearchCV\nfrom imblearn.over_sampling import ADASYN, SMOTE, RandomOverSampler\nfrom imblearn.pipeline import make_pipeline\n\ndf  = pd.read_csv('..\/input\/creditcardfraud\/creditcard.csv')    \ndf.head()\n","da37a059":"import seaborn as sns\n\n#sns.set_theme(style=\"darkgrid\")\nsns.countplot(x='Class', data=df,palette=\"Set3\")","4a0a6dff":"df.describe()","9b3029be":"std_scaler = StandardScaler()\nrob_scaler = RobustScaler()\n\ndf['scaled_amount'] = rob_scaler.fit_transform(df['Amount'].values.reshape(-1,1))\ndf['scaled_time'] = rob_scaler.fit_transform(df['Time'].values.reshape(-1,1))\ndf.drop(['Time','Amount'], axis=1, inplace=True)\nscaled_amount = df['scaled_amount']\nscaled_time = df['scaled_time']\n\ndf.drop(['scaled_amount', 'scaled_time'], axis=1, inplace=True)\ndf.insert(0, 'scaled_amount', scaled_amount)\ndf.insert(1, 'scaled_time', scaled_time)\n\n#Split the data into x and y variables\n\nX = df.drop('Class', axis=1)\ny = df['Class']\n\ndf.head()\n","bf5899d8":"SK= StratifiedKFold(n_splits=5, random_state=None, shuffle=False)\nfor train_index, test_index in SK.split(X, y):\n    Xtrain, Xtest = X.iloc[train_index], X.iloc[test_index]\n    ytrain, ytest = y.iloc[train_index], y.iloc[test_index]\n\ntrain_unique_label, train_counts_label = np.unique(ytrain, return_counts=True)\ntest_unique_label, test_counts_label = np.unique(ytest, return_counts=True)\nprint('Label Distributions in ytrain and ytest: \\n')\nprint(train_counts_label\/len(ytrain))\nprint(test_counts_label\/len(ytest))\n","f4f84d2f":"LW = 2\nRANDOM_STATE = 42\n\nclass DummySampler:\n    def sample(self, X, y):\n        return X, y\n\n    def fit(self, X, y):\n        return self\n\n    def fit_resample(self, X, y):\n        return self.sample(X, y)\n    \nlog_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100]}\nrand_log_reg = RandomizedSearchCV(LogisticRegression(solver='liblinear'), log_reg_params, n_iter=4)\nsamplers = [\n    ['Standard', DummySampler()],\n    ['ADASYN', ADASYN( )],\n    ['ROS', RandomOverSampler()],\n    ['SMOTE', SMOTE()],]\n\npipelines = [['{}'.format(sampler[0]),make_pipeline(sampler[1], rand_log_reg )] for sampler in samplers ]\nreport_list = pd.DataFrame( index = ['f1', 'precision', 'recall',' average_precision' ],columns =[sampler[0] for sampler in samplers])\n\nfig, axs = plt.subplots(1, 2, figsize=(15,10))\nfig1, axs1 = plt.subplots(2, 2, figsize=(22,12))\ntitle_cm= [sampler[0] for sampler in samplers]\nfor (idx, (name, pipeline)), ax1 in zip(enumerate(pipelines,0), axs1.flat):\n    pipeline.fit(Xtrain, ytrain)\n    best_clf = rand_log_reg.best_estimator_\n    yhat= best_clf.predict_proba(Xtest)\n    ypred0 = best_clf.decision_function(Xtest)\n    ypred = best_clf.predict(Xtest)\n    fpr, tpr, thresholds = roc_curve(ytest, yhat[:,1])\n    roc_auc = auc(fpr, tpr)\n    f1 = f1_score(ytest,ypred)\n    pr, re, thresholds = precision_recall_curve(ytest, yhat[:,1])\n    pr_auc = auc(re, pr)\n    report_list.iloc[[0],[idx]] = [f1]\n    report_list.iloc[[1],[idx]] = [metrics.precision_score(ytest, ypred)]\n    report_list.iloc[[2],[idx]] = [metrics.recall_score(ytest, ypred)]\n    report_list.iloc[[3],[idx]] = [average_precision_score(ytest, yhat[:,1])]    \n    axs[1].plot(pr, re, linestyle='-', label=r'%s (area = %0.3f )' % (name, pr_auc),lw=LW)\n    axs[0].plot(fpr, tpr, label='{} (area = %0.3f)'.format(name) % roc_auc, lw=LW)\n# confusion_matrix\n    cm_nn = confusion_matrix(ytest,ypred)\n    sns.heatmap(cm_nn, ax=ax1,annot=True,robust=True,fmt='g' ,cmap=\"Reds\", cbar=False)\n    ax1.set_title(title_cm[idx], fontsize=14)\n\naxs[0].plot([0, 1], [0, 1], linestyle='--', lw=LW, color='k', label='Luck')\n# make nice plotting\nxlabel= ['False Positive Rate', 'Recall']\nylabel= ['True Positive Rate', 'Precision']\ntitle = ['Receiver operating characteristisc (ROC)', 'Precision-Recall Curve ']\nfor i, ax in  enumerate(axs.flat, 0):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    ax.spines['left'].set_position(('outward', 10))\n    ax.spines['bottom'].set_position(('outward', 10))\n    ax.axis(xmin=0,xmax=1)\n    ax.axis(ymin=0,ymax=1)\n    ax.set_xlabel(xlabel[i])\n    ax.set_ylabel(ylabel[i])\n    ax.set_title(title[i])\n    ax.legend(loc=\"lower right\")\n\nplt.show()\n","2b833b1f":"report_list","f1eaae68":"from imblearn.under_sampling import RandomUnderSampler, TomekLinks, EditedNearestNeighbours \n","ca12950b":"log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100]}\nrand_log_reg = RandomizedSearchCV(LogisticRegression(solver='liblinear'), log_reg_params, n_iter=4)\nsamplers = [\n    ['Standard', DummySampler()],\n    ['Under', RandomUnderSampler()],\n    ['TomekLinks', TomekLinks()],\n    ['EditedNN', EditedNearestNeighbours()],]\n\npipelines = [['{}'.format(sampler[0]),make_pipeline(sampler[1], rand_log_reg )] for sampler in samplers ]\nreport_list = pd.DataFrame( index = ['f1', 'precision', 'recall',' average_precision' ],columns =[sampler[0] for sampler in samplers])\n\nfig, axs = plt.subplots(1, 2, figsize=(15,10))\nfig1, axs1 = plt.subplots(2, 2, figsize=(22,12))\ntitle_cm= [sampler[0] for sampler in samplers]\nfor (idx, (name, pipeline)), ax1 in zip(enumerate(pipelines,0), axs1.flat):\n    pipeline.fit(Xtrain, ytrain)\n    best_clf = rand_log_reg.best_estimator_\n    yhat= best_clf.predict_proba(Xtest)\n    ypred0 = best_clf.decision_function(Xtest)\n    ypred = best_clf.predict(Xtest)\n    fpr, tpr, thresholds = roc_curve(ytest, yhat[:,1])\n    roc_auc = auc(fpr, tpr)\n    f1 = f1_score(ytest,ypred)\n    pr, re, thresholds = precision_recall_curve(ytest, yhat[:,1])\n    pr_auc = auc(re, pr)\n    report_list.iloc[[0],[idx]] = [f1]\n    report_list.iloc[[1],[idx]] = [metrics.precision_score(ytest, ypred)]\n    report_list.iloc[[2],[idx]] = [metrics.recall_score(ytest, ypred)]\n    report_list.iloc[[3],[idx]] = [average_precision_score(ytest, yhat[:,1])]    \n    axs[1].plot(pr, re, linestyle='-', label=r'%s (area = %0.3f )' % (name, pr_auc),lw=LW)\n    axs[0].plot(fpr, tpr, label='{} (area = %0.3f)'.format(name) % roc_auc, lw=LW)\n# confusion_matrix\n    cm_nn = confusion_matrix(ytest,ypred)\n    sns.heatmap(cm_nn, ax=ax1,annot=True,robust=True,fmt='g' ,cmap=\"Reds\", cbar=False)\n    ax1.set_title(title_cm[idx], fontsize=14)\n\naxs[0].plot([0, 1], [0, 1], linestyle='--', lw=LW, color='k', label='Luck')\n# make nice plotting\nxlabel= ['False Positive Rate', 'Recall']\nylabel= ['True Positive Rate', 'Precision']\ntitle = ['Receiver operating characteristisc (ROC)', 'Precision-Recall Curve ']\nfor i, ax in  enumerate(axs.flat, 0):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    ax.spines['left'].set_position(('outward', 10))\n    ax.spines['bottom'].set_position(('outward', 10))\n    ax.axis(xmin=0,xmax=1)\n    ax.axis(ymin=0,ymax=1)\n    ax.set_xlabel(xlabel[i])\n    ax.set_ylabel(ylabel[i])\n    ax.set_title(title[i])\n    ax.legend(loc=\"lower right\")\n\nplt.show()\n","6d3e0fa7":"report_list","38b81b4b":"log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100]}\nrand_log_reg = RandomizedSearchCV(LogisticRegression(solver='liblinear'), log_reg_params, n_iter=4)\nSamplersOverUnder = [\n    ['Standard', [DummySampler(),DummySampler()]],\n    ['SMOTE+RandomUnder', [ RandomUnderSampler(), SMOTE()]],\n    ['SMOTE+TomekLinks', [TomekLinks(),SMOTE()  ]],\n    ['SMOTE+EditedNN', [EditedNearestNeighbours(), SMOTE(),  ]],]\npipelines = [ ['{}'.format(samplerOvUn[0]), make_pipeline(samplerOvUn[1][0],samplerOvUn[1][1], rand_log_reg )] for samplerOvUn in SamplersOverUnder ]\nreport_list = pd.DataFrame( index = ['f1', 'precision', 'recall',' average_precision' ],columns =[sampler[0] for sampler in SamplersOverUnder])\n\nfig, axs = plt.subplots(1, 2, figsize=(15,10))\nfig1, axs1 = plt.subplots(2, 2, figsize=(22,12))\ntitle_cm= [sampler[0] for sampler in SamplersOverUnder]\nfor (idx, (name, pipeline)), ax1 in zip(enumerate(pipelines,0), axs1.flat):\n    pipeline.fit(Xtrain, ytrain)\n    best_clf = rand_log_reg.best_estimator_\n    yhat= best_clf.predict_proba(Xtest)\n    ypred0 = best_clf.decision_function(Xtest)\n    ypred = best_clf.predict(Xtest)\n    fpr, tpr, thresholds = roc_curve(ytest, yhat[:,1])\n    roc_auc = auc(fpr, tpr)\n    f1 = f1_score(ytest,ypred)\n    pr, re, thresholds = precision_recall_curve(ytest, yhat[:,1])\n    pr_auc = auc(re, pr)\n    report_list.iloc[[0],[idx]] = [f1]\n    report_list.iloc[[1],[idx]] = [metrics.precision_score(ytest, ypred)]\n    report_list.iloc[[2],[idx]] = [metrics.recall_score(ytest, ypred)]\n    report_list.iloc[[3],[idx]] = [average_precision_score(ytest, yhat[:,1])]    \n    axs[1].plot(pr, re, linestyle='-', label=r'%s (area = %0.3f )' % (name, pr_auc),lw=LW)\n    axs[0].plot(fpr, tpr, label='{} (area = %0.3f)'.format(name) % roc_auc, lw=LW)\n# confusion_matrix\n    cm_nn = confusion_matrix(ytest,ypred)\n    sns.heatmap(cm_nn, ax=ax1,annot=True,robust=True,fmt='g' ,cmap=\"Reds\", cbar=False)\n    ax1.set_title(title_cm[idx], fontsize=14)\n\naxs[0].plot([0, 1], [0, 1], linestyle='--', lw=LW, color='k', label='Luck')\n# make nice plotting\nxlabel= ['False Positive Rate', 'Recall']\nylabel= ['True Positive Rate', 'Precision']\ntitle = ['Receiver operating characteristisc (ROC)', 'Precision-Recall Curve ']\nfor i, ax in  enumerate(axs.flat, 0):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    ax.spines['left'].set_position(('outward', 10))\n    ax.spines['bottom'].set_position(('outward', 10))\n    ax.axis(xmin=0,xmax=1)\n    ax.axis(ymin=0,ymax=1)\n    ax.set_xlabel(xlabel[i])\n    ax.set_ylabel(ylabel[i])\n    ax.set_title(title[i])\n    ax.legend(loc=\"lower right\")\n\nplt.show()\n","ffb844c7":"report_list","564be992":"log_reg_params = {\"penalty\": ['l1', 'l2'], 'C': [0.01, 0.1, 1, 10, 100]}\nrand_log_reg = RandomizedSearchCV(LogisticRegression(solver='liblinear'), log_reg_params, n_iter=4)\n\nSamplersOverUnder = [\n    ['Standard', [DummySampler(),DummySampler()]],\n    ['ADASYN+RandomUnder', [ADASYN(sampling_strategy=0.3), RandomUnderSampler()]],\n    ['ADASYN+TomekLinks', [ADASYN(sampling_strategy=0.3),  TomekLinks()]],\n    ['ADASYN+EditedNN', [ADASYN(sampling_strategy=0.3),  EditedNearestNeighbours()]],]\npipelines = [ ['{}'.format(samplerOvUn[0]), make_pipeline(samplerOvUn[1][0],samplerOvUn[1][1], rand_log_reg )] for samplerOvUn in SamplersOverUnder ]\nreport_list = pd.DataFrame( index = ['f1', 'precision', 'recall',' average_precision' ],columns =[sampler[0] for sampler in SamplersOverUnder])\n\nfig, axs = plt.subplots(1, 2, figsize=(15,10))\nfig1, axs1 = plt.subplots(2, 2, figsize=(22,12))\ntitle_cm= [sampler[0] for sampler in SamplersOverUnder]\nfor (idx, (name, pipeline)), ax1 in zip(enumerate(pipelines,0), axs1.flat):\n    pipeline.fit(Xtrain, ytrain)\n    best_clf = rand_log_reg.best_estimator_\n    yhat= best_clf.predict_proba(Xtest)\n    ypred = best_clf.predict(Xtest)\n    fpr, tpr, thresholds = roc_curve(ytest, yhat[:,1])\n    roc_auc = auc(fpr, tpr)\n    f1 = f1_score(ytest,ypred)\n    pr, re, thresholds = precision_recall_curve(ytest, yhat[:,1])\n    pr_auc = auc(re, pr)\n    report_list.iloc[[0],[idx]] = [f1]\n    report_list.iloc[[1],[idx]] = [metrics.precision_score(ytest, ypred)]\n    report_list.iloc[[2],[idx]] = [metrics.recall_score(ytest, ypred)]\n    report_list.iloc[[3],[idx]] = [average_precision_score(ytest, yhat[:,1])]    \n    axs[1].plot(pr, re, linestyle='-', label=r'%s (area = %0.3f )' % (name, pr_auc),lw=LW)\n    axs[0].plot(fpr, tpr, label='{} (area = %0.3f)'.format(name) % roc_auc, lw=LW)\n# confusion_matrix\n    cm_nn = confusion_matrix(ytest,ypred)\n    sns.heatmap(cm_nn, ax=ax1,annot=True,robust=True,fmt='g' ,cmap=\"Reds\", cbar=False)\n    ax1.set_title(title_cm[idx], fontsize=14)\n\naxs[0].plot([0, 1], [0, 1], linestyle='--', lw=LW, color='k', label='Luck')\n# make nice plotting\nxlabel= ['False Positive Rate', 'Recall']\nylabel= ['True Positive Rate', 'Precision']\ntitle = ['Receiver operating characteristisc (ROC)', 'Precision-Recall Curve ']\nfor i, ax in  enumerate(axs.flat, 0):\n    ax.spines['top'].set_visible(False)\n    ax.spines['right'].set_visible(False)\n    ax.get_xaxis().tick_bottom()\n    ax.get_yaxis().tick_left()\n    ax.spines['left'].set_position(('outward', 10))\n    ax.spines['bottom'].set_position(('outward', 10))\n    ax.axis(xmin=0,xmax=1)\n    ax.axis(ymin=0,ymax=1)\n    ax.set_xlabel(xlabel[i])\n    ax.set_ylabel(ylabel[i])\n    ax.set_title(title[i])\n    ax.legend(loc=\"lower right\")\n\nplt.show()\n","d546f6c9":"report_list","70bd5da9":"# Benchmarking data sampling techniques for Credit Card Fraud Detection\n\nIf you found this Kernel helpful please up vote it since it will keep me motivated to perform more in-depth reserach towards this subject. If you have some feedback and question don't forget to comment below.\n\n\n## **Introduction** \n\nThis repository is going to show how I have used a HIGHLY unbalanced dataset \u2014 the Credit Card Fraud Detection dataset \u2014 from Kaggle. The target variables are 0 \u2014 for non fraudulent, and 1 \u2014 for fraudulent. The positive class 1 (fraudulent) accounts for only 0.17% of the whole dataset. How am I going to sample data for modelling when there is so much imbalance?\n\nIn this project, several implemented data sampling algorithms are used in conjunction with a classifier in order to examine the improvement of the classifier\u2019s output quality.\n\nData sampling algorithms change the composition of the training dataset to improve the performance of a standard machine learning algorithm on an imbalanced classification problem.\n\nThere are perhaps three main types of data sampling techniques; we will implement the following methods:\n\n**Data Oversamplinug:**\n* Random Oversampling\n* SMOTE\n* ADASYN\n\n**Data Undersampling:**\n* Random Undersampling\n* Tomek Links\n* Edited Nearest Neighbors\n\n**Combined Oversampling and Undersampling:**\n* SMOTE and Random Undersampling\n* SMOTE and Tomek Links\n* SMOTE and Edited Nearest Neighbors\n* ADASYN and Random Undersampling\n* ADASYN and Tomek Links\n* ADASYN and Edited Nearest Neighbors\n\n### Outline:\n\n1. Data preparation and visualization\n\n2. Benchmark over-sampling methods\n\n3. Benchmark under-sampling methods\n\n4. Benchmark over+under methods\n\n **Note**: For testing purposes, although we are splitting the data when implementing Random UnderSampling or OverSampling techniques, we want to test our models on the original testing set not on the testing set created by either of these techniques.\n\n### Data preparation and visualization\n\nThis dataset is a highly unbalanced dataset, meaning the target classes are unbalanced Class = 0,1 0 = Non-fraud 1 = Fraud\n","f9684dab":"1. **SMOTE + [ Random Undersampling, Tomek Links, Edited Nearest Neighbors]**","02775434":"**We can see that Edited Nearest Neighbors performs much better in predicting the frauds in our dataset with the Precision-Recall Curve (AUPRC) being 0.8 on the test data. And more, it is the best result in our tests.**","bcc0f6c2":"We will first scale the columns comprise of Time and Amount. So we shall standardise the \"Amount\" and \"Time\" data, since all the other columns have been obtained through PCA.","8aabf067":"Now, spit the data into train and test data. Why?\n\nFor testing purposes, although we are splitting the data when implementing Random UnderSampling or OverSampling techniques, we want to test our models on the original testing set not on the testing set created by either of these techniques.","35295ab3":"The folds are made by preserving the percentage of samples for each class.","6aa0ad73":"**In this case, we can see a modest lift in Area Under the Precision-Recall Curve (AUPRC) performance from 0.74 with no transforms to about 0.79 with ADASYN and SMOTE. More, we notice an improvement in the detection of fraud.**","e1dd6bca":"## Benchmark of the combination of over- and under-sampling algorithms\n\nAlmost any oversampling method can be combined with almost any undersampling technique. But, in this phase of the project, we will implement examples of popular combinations of over and undersampling.\n* SMOTE and Random Undersampling\n* SMOTE and Tomek Links\n* SMOTE and Edited Nearest Neighbors\n* ADASYN and Random Undersampling\n* ADASYN and Tomek Links\n* ADASYN and Edited Nearest Neighbors\n","14a38234":"## Benchmark under-sampling methods\n\nUndersampling involves deleting examples from the majority class, such as randomly or using an algorithm to carefully choose which examples to delete.\n\nIn this section we will implement a 3 methods of undersampling to resolve this imbalanced dataset issue:\n\n* Random Undersampling\n* Tomek Links\n* Edited Nearest Neighbors\n","74466a6d":"2. **ADASYN+[ Random Undersampling, Tomek Links, Edited Nearest Neighbors]**","d0109dcc":"**Conclusion**\n\nFraud Detection System is mostly concerned with increasing True Positives it must also consider to be precise in this detection by reducing the number of False Positive. So, the key metrics AUPRC and  recall are considered as a first step for identifying the best sampling strategy. EditedNN and ADASYN+RandomUnder have the highest observed AUPRC of 0.8 with logistic regression classifier. However, it offered very little precision. \nThis means that while most of the fraudulent transactions are detected by the system it also falsely flagged several genuine transactions as fraudulent. \n","9831a180":"## Benchmark over-sampling methods\n\nOversampling methods involves duplicating examples of the minority class or synthesizing new examples from the minority class from existing examples.\n\nI will attempt to perform 3 methods of Oversampling to resolve this imbalanced dataset issue:\n* Random Oversampling\n* SMOTE\n* ADASYN\n\nFor classification Models we choose logistic regression.\n","1d544f91":"We can see that the data are highly unbalanced, meaning the data in class variable of 0 is very high compared to the class variable of 1\n"}}