{"cell_type":{"177a5798":"code","e12eca86":"code","2de65956":"code","a043f78a":"code","3f76760f":"code","bd5e7ebd":"code","12936743":"code","4919c677":"code","57503cb2":"code","30001c6e":"markdown","b1593471":"markdown","b6b4de35":"markdown","021fd8cc":"markdown","229d45b1":"markdown","0b4577c3":"markdown","48c5af75":"markdown","4ba2a9d8":"markdown","17b5efe0":"markdown"},"source":{"177a5798":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n        \n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","e12eca86":"df = pd.read_csv(\"\/kaggle\/input\/mushroom-classification\/mushrooms.csv\")\n# print(df.head())\nprint(\"Shape: \", df.shape)\n# print(df.columns)\n\n","2de65956":"\nfrom sklearn import preprocessing\n\nlabelencoder=preprocessing.LabelEncoder()\nfor column in df.columns:\n    df[column] = labelencoder.fit_transform(df[column])\n    \nprint(df.head())\n","a043f78a":"\nX = df[['cap-shape', 'cap-surface', 'cap-color', 'bruises', 'odor',\n       'gill-attachment', 'gill-spacing', 'gill-size', 'gill-color',\n       'stalk-shape', 'stalk-root', 'stalk-surface-above-ring',\n       'stalk-surface-below-ring', 'stalk-color-above-ring',\n       'stalk-color-below-ring', 'veil-type', 'veil-color', 'ring-number',\n       'ring-type', 'spore-print-color', 'population', 'habitat']]\nY = df[\"class\"]\n\n# X_dummy = pd.get_dummies(X) #convert letters in numerical values\n# X_dummy.shape \n    \n# print(\"all data features:\",X.shape,\"\\n\",X)\n# print(\"column con etiquetas:\",Y.shape,\"\\n\",Y)\n    ","3f76760f":"from sklearn.model_selection import train_test_split\nx_train, x_test, y_train, y_test = train_test_split(X, Y, test_size=0.33, random_state=42)\n\nprint(\"x_train:\",x_train.shape,\"\\n\",x_train)\nprint(\"x_test:\",x_test.shape,\"\\n\",x_test)\nprint(\"y_train:\",y_train.shape,\"\\n\",y_train)\nprint(\"y_test:\",y_test.shape,\"\\n\",y_test)","bd5e7ebd":"from sklearn.ensemble import RandomForestClassifier\n\nclassifier=RandomForestClassifier(n_estimators= 100,max_features = 'sqrt',max_samples = 0.66 , bootstrap=True, random_state=42)\nclassifier.fit(x_train, y_train)\n\ny_pred=classifier.predict(x_test)\n","12936743":"# check precision, recall, F1 etc.\n\nfrom sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n\nprint(\"RESULTATS RANDOM FOREST CLASSIFIER\\n \")\n\nprint(\"Accuracy RandomForest:\",accuracy_score(y_test, y_pred) )\nprint(\"\\nmatrix confusion:\\n \",confusion_matrix(y_test,y_pred) )\nprint(\"\\nrecall y F1:\\n\", classification_report(y_test,y_pred) )\n","4919c677":"from sklearn.neural_network import MLPClassifier\nfrom sklearn.metrics import mean_squared_error\n\nclassifier_red= MLPClassifier(hidden_layer_sizes=(100,100,25),solver=\"sgd\", max_iter=1000) # accuracy=0.999\n# classifier_red= MLPClassifier(hidden_layer_sizes=(4,2),solver=\"sgd\", max_iter=1000) # accuracy=0.5\n\nclassifier_red.fit(x_train, y_train)\n\ny_pred_red=classifier_red.predict(x_test)\n\nprint(\"RESULTATS RED NEURONALES\\n \")\n\nprint(\"Accuracy Red:\",accuracy_score(y_test, y_pred_red) )\nprint(\"\\nmatrix confusion:\\n \",confusion_matrix(y_test,y_pred_red) )\nprint(\"\\nrecall y F1:\\n\", classification_report(y_test,y_pred_red) )\nprint(\"Quadratic error Red:\",mean_squared_error(y_test, y_pred_red) )","57503cb2":"print('hello wolrd')","30001c6e":"Dataset loading and visualisacion\n1st column = etiquetas","b1593471":"Con el RandomForestClassifier:\n\nSi hidden_layer_sizes=(4,2), accuracy = 0.5 (aproximadamente)\n\nSi hidden_layer_sizes=(100,100,25), accuracy = 1.","b6b4de35":"Conclusion:\n\nPara este dataset, los dos classificadores pueden darnos una precisi\u00f3n maxima en la classificacion de los champignones, aunque la red neuronal sea un poquito menos precisa.\n\nSin embargo, en este ejemplo el RandomForestClassifier es mas eficaz mas rapidamente, sin necessidad de muchos arboles. Mientras que la red neuronal necessita muchas neuronas para ser realmente precisa, y el tratamiento toma mas tiempo.\n\nEntonces en este caso, si ten\u00eda que elegir, elegir\u00eda el classificador RandomForest para resolver este problema.\n","021fd8cc":"Conversion lettras to numeros","229d45b1":"Random split del dataset para entrenar un classificador: 2\/3 para entrenar, 1\/3 para probar\n\nx_train = [5443 rows x 22 columns] ; x_test = [2681 rows x 22 columns]\n\ny_train = 5443 x 1 ; y_test = 2681","0b4577c3":"Separacion del dataset: \n\nX = attributes\/features = data sin la primera columna que contiene las etiquetas = [8124 rows x 22 columns]\n\nY = label\/etiquetas = solo una columna con las etiquetas = 8124x1\n","48c5af75":"Red neuronales: \n\n22 Inputs (los 22 champignones attributes)\n\n3 capas intermedias (ocultas) : las dos primeras con 100 neuronas cada una y la ultima con 25 neuronas : hidden_layer_sizes=(100,100,25)\n\nHay una sola neuronna de output para classificar si el champignon es comestible o no (0 o 1)\n\ntypo de activacion = default = 'relu'\n\nciclos de entrenamientos = 1000 iteraciones, this determines the number of epochs (how many times each data point will be used)\n\n\u2018sgd\u2019 refers to stochastic gradient descent\n","4ba2a9d8":"Con el RandomForestClassifier:\n\nSin \"random_state=42\", \n\nAccuracy = 0.998 for n_estimators= 1;\nAccuracy = 0.999 for n_estimators= 2;\ny siempre Accuracy = 1 for more estimators\n\nCon \"random_state=42\", Accuracy = 1 siempre\n","17b5efe0":"RandomForestClassifier como en el pdf de la clase, y con los parametros sigientes:\n\nn_estimators = 100 = 100 arboles in the forest, the result is an average of thoses 100 estimators\n\nmax_samples = (0.66)*nb_fila_del_dataset , filas tomadas de manera random para entrenar un estimator (random_state=42)\n\nmax_features = 'sqrt' = same as 'auto' as default (quedamos sqrt(nb_attributes) en cada sub_tablas, como en el pdf de la clase)\n\n"}}