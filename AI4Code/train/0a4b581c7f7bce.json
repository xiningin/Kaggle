{"cell_type":{"fe60a480":"code","f04d9c75":"code","fdfa2383":"code","2de5ddb4":"code","cd1143e3":"code","8d17744a":"code","c46f2174":"code","c55fb1d8":"code","a16547fa":"code","9d7a61a7":"code","6a0c2093":"code","d5b6da79":"code","ee7bfc2f":"code","7b2d2c1a":"code","c14c327d":"code","ae00875a":"markdown","f59bd7f2":"markdown","f983408e":"markdown","c022c215":"markdown","275b5de4":"markdown"},"source":{"fe60a480":"# Basic incantations.  I'll add the others as they're needed.\nimport pandas as pd\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns","f04d9c75":"# Create DFs for all the .CSV files.\n# In Kaggle kernels, input data files are available in the \"..\/input\/\" directory. \n# This one has already been loaded with the data for the competition.\n# Any results you write to the current directory are saved as output.\n\nsample_submission = pd.read_csv('..\/input\/sample_submission.csv')\ntest_features = pd.read_csv('..\/input\/test_features.csv')\ntrain_features = pd.read_csv('..\/input\/train_features.csv')\ntrain_labels = pd.read_csv('..\/input\/train_labels.csv')","fdfa2383":"def cleanup1(X):\n    \"\"\"\n    Minimal viable cleaning.\n    \n    This function gets the data in minimal working order for a logistic \n    regression. I fill up NANs (which appear only in the categorcial\n    features), change datetime objects to numbers, drop one useless \n    feature and standardize the datatypes.\n    \n    Parameters\n    ----------\n    X : pandas.DataFrame (DF)\n        Original, full-featured DF (train_features or test_features)\n    \n    Returns\n    ----------\n    X2 : pandas.DataFrame\n        Cleaned DF\n    \"\"\"\n \n    # Make a clean copy, to ensure we're not changing the original DF\n    X2 = X.copy()\n    \n    # Looking at all the features with missing values, it looks like those\n    # features are all categorical variables where 'unknown' would be a\n    # category we can work with.  I'll replace the NANs accordingly.\n    X2 = X2.fillna('unknown')\n    \n    # Regression on dates won't work.  Instead, I'll turn the \n    # date_recorded column into the number of years since 2000\n    # (the earliest date in the training date is from ~2002, and the\n    # latest from 2013.)\n    dates = pd.to_datetime(X2.date_recorded)\n    year2000 = pd.to_datetime('2000-01-01')\n    years = [i.days\/365 for i in (dates - year2000)]\n    X2.date_recorded = years\n    \n    # region_code and district_code are int64, but they should really be\n    # treated as categories (and there's only 20-30 classes in each).\n    # I'll cast them as strings instead.\n    X2.region_code = X2.region_code.astype('str')\n    X2.district_code = X2.district_code.astype('str')\n    \n    # recorded_by has only one value everywhere, and is therefore useless\n    X2 = X2.drop(columns='recorded_by')\n    \n    # To prevent data conversion warnings, I'll turn all the numerical\n    # features (except id) into float64.\n    \n    # Also, some columns contained bool values and NANs.  \n    # (e.g., public_meeting, permit)\n    # I replaced the NANs with strings, which created a problem for later\n    # operations that don't like heterogeneous datatypes within a single\n    # column. I'll prevent this problem by casting those two features as str.\n    \n    type_dict = {'amount_tsh':'float64',\n                 'date_recorded':'float64',\n                 'gps_height':'float64',\n                 'longitude':'float64',\n                 'latitude':'float64',\n                 'num_private':'float64',\n                 'population':'float64',\n                 'construction_year':'float64',\n                 'public_meeting':'str',\n                 'permit':'str'}\n    \n    X2 = X2.astype(dtype = type_dict)\n    \n    return X2","2de5ddb4":"from sklearn.impute import MissingIndicator\n\ndef cleanup2(X):\n    \"\"\"\n    Fixes the numerical features. \n    \n    \n    Each feature has different specific problems, but they usually have\n    garbage values (usually zero) that should really be read as NANs.\n    \n    I want to fix those values, but I also want to take note of the \n    datapoints where they happened.  I do this because I assume that \n    missing values tell us something about the well that our model\n    might be able to pick up later.\n    \n    \n    Parameters\n    ----------\n    X : pandas.DataFrame\n        DF with raw numerical features\n    \n    Returns\n    ----------\n    X2 : pandas.DataFrame\n         DF with cleaned numerical features and a new matrix of former\n         garbage locations within those features.\n    \n    \"\"\"\n    \n    \n    # Make a clean copy, to ensure we're not changing the original DF\n    X2 = X.copy()\n    \n    # I make a list of the numerical columns and a dict of their \n    # garbage values that really should be nulls\n    numericals = ['amount_tsh',\n                    'date_recorded',\n                    'gps_height',\n                    'longitude',\n                    'latitude',\n                    'num_private',\n                    'population',\n                    'construction_year']\n\n    null_values = {'amount_tsh':0,\n                     'date_recorded':0,\n                     'gps_height':0,\n                     'longitude':0,\n                     'latitude':-2.000000e-08,\n                     'num_private':0,\n                     'population':0,\n                     'construction_year':0}\n\n    # I replace all garbage values with NANs.\n    for feature, null in null_values.items():\n        X2[feature] = X2[feature].replace(null, np.nan)\n\n    # construction_year occasionally claims years far in the future, and \n    # could presumably also contain years way in the past.  I'll turn anything\n    # not between 1960 and 2019 into a NAN.\n    X2['construction_year'] = [i if 1960 < i < 2019 else np.nan for i in X2['construction_year']]\n    \n    \n    # Creating indicator columns.\n    # ---------------------------------------------------------------\n    # These columns mark the locations of all the NANs \n    # in the numericals. Note that MissingIndicator returns a numpy array.\n    \n    indicator = MissingIndicator()\n    trash_array = indicator.fit_transform(X2[numericals]) # Bool array\n    trash_array = trash_array.astype('float64')     # Float64 array\n\n    # Create a titles for the columns in num_trashmarker\n    trashy_names = [numericals[i] + '_trash' for i in indicator.features_]\n\n    # Create num_trashmarker\n    trash_df = pd.DataFrame(trash_array, columns=trashy_names)\n\n    # I add trash_df to X2\n    X2 = pd.concat([X2,trash_df], sort=False, axis=1)\n    \n    \n    # Fixing the numerical columns.\n    # ---------------------------------------------------------------\n    # Whenever possible, a good replacement value for a NAN is the \n    # mean or median value for the geographic region around it.\n\n    # Replaces the NANs in a ward with the mean of the other rows in that \n    # same ward. If all the rows in a ward are NANs, though, they remain.\n    for feature in numericals:\n        replacements = X2.groupby('ward')[feature].transform('mean')\n        X2[feature] = X2[feature].fillna(replacements)\n\n    # Replaces the NANs in a region with the mean of the other rows in that \n    # same region (which are much larger than wards)\n    for feature in numericals:\n        replacements = X2.groupby('region')[feature].transform('mean')\n        X2[feature] = X2[feature].fillna(replacements)\n    \n    # Replaces any remaining NANs with the median value for the whole dataset\n    for feature in numericals:\n        replacements = X2[feature].median() # Single number, not array\n        X2[feature] = X2[feature].fillna(replacements)\n    \n    return X2","cd1143e3":"def cleanup3(X):\n    \"\"\"\n    Fixes the categorical features. \n    \n    \n    Each feature has different specific problems, but they usually have\n    garbage values (usually 'unknown') that should really be read as NANs.\n    \n    This function cleans up garbage, clusters together different labels\n    that should be equivalent but are coded differently (e.g., different\n    spellings of the same thing), and removes labels with so few members\n    that they're unlikely to be informative.\n    \n    \n    Parameters\n    ----------\n    X : pandas.DataFrame\n        DF with raw categorical features, except for the changes\n        already included in cleanup1.\n    \n    Returns\n    ----------\n    X2 : pandas.DataFrame\n         DF with cleaned categorical features.\n    \n    \"\"\"\n    \n    # Make a clean copy, to ensure we're not changing the original DF\n    X2 = X.copy()\n    \n    # Create list of categorical features\n    categoricals = X2.select_dtypes(exclude='number').columns.tolist()\n\n    # Make all strings lowercase, to collapse together some of the categories\n    X2[categoricals] = X2[categoricals].applymap(lambda x: x.lower())\n\n    # Replace common NAN values\n    nan_list = ['not known','unknown','none','-','##','not kno','unknown installer']\n    X2 = X2.replace(nan_list, np.nan)\n\n    # Any feature values with fewer than 100 rows gets turned into a NAN\n    for feature in X2[categoricals]:\n        # Determine which feature values to keep\n        to_keep = X2[feature].value_counts()[X2[feature].value_counts() > 100].index.tolist()\n        # Turn those into NANs (using a copy, to prevent warnings)\n        feature_copy = X2[feature].copy()\n        feature_copy[~feature_copy.isin(to_keep)] = np.nan\n        X2[feature] = feature_copy\n\n    # Fix all NANs\n    X2[categoricals] = X2[categoricals].fillna('other')\n    \n    \n    return X2","8d17744a":"from sklearn.preprocessing import RobustScaler\ndef cleanup4(X):\n    \"\"\"\n    Gets rid of mostly useless features, adds a couple of engineered ones,\n    and standardizes the numericals. \n    \n    Parameters\n    ----------\n    X : pandas.DataFrame\n        DF cleaned with cleanup 1-3\n    \n    Returns\n    ----------\n    X2 : pandas.DataFrame\n    \n    \"\"\"\n    \n    # Make a clean copy, to ensure we're not changing the original DF\n    X2 = X.copy()\n    \n    garbage = ['longitude','latitude','construction_year_trash',\n              'latitude_trash','gps_height_trash',\n               'extraction_type_group','extraction_type_class',\n               'region_code','waterpoint_type_group','source_type',\n              'payment_type','quality_group','quantity_group']\n    \n    X2 = X2.drop(columns=garbage)\n    \n    X2['age'] = X2['date_recorded'] - X2['construction_year']\n\n    numericals = ['amount_tsh',\n                    'date_recorded',\n                    'gps_height',\n                    'num_private',\n                    'population',\n                    'construction_year',\n                    'age']\n\n    scaler = RobustScaler()\n    nums_scaled = scaler.fit_transform(X2[numericals])\n    nums_scaled = pd.DataFrame(nums_scaled, columns=numericals)\n    X2[numericals] = nums_scaled\n    \n    return X2","c46f2174":"# X_train is the matrix of features that will go into the logistic regression.\n# It exists at various points as a dataframe or numpy array\nX_train = cleanup1(train_features)\ny_train = train_labels['status_group']\n\n# This command produces a series of the categorical features, calculates their cardinality\n# (number of unique values), sorts the features by cardinality, extracts the feature names\n# (indices), turns those indexes into a list, and takes all but the 6 with highest cardinality. \ncols_to_keep = X_train.select_dtypes(exclude='number').nunique().sort_values().index.tolist()[:-6]\nX_train = X_train[cols_to_keep]","c55fb1d8":"# In this cell I define a pipeline that will one-hot encode X_train, then\n# feed it to the logistic regression.\n\nfrom sklearn.preprocessing import OneHotEncoder\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.pipeline import make_pipeline\n\n# The parameters of the regression were chosen by \n# trial and error with GridSearchCV in a separate notebook.\npipe = make_pipeline(\n    OneHotEncoder(categories='auto'),\n    LogisticRegression(solver='lbfgs', multi_class='ovr',\n                      max_iter=500))","a16547fa":"%%time\npipe.fit(X_train,y_train)","9d7a61a7":"from sklearn.metrics import accuracy_score\n\n# What's the accuracy of this prediction, measured against the training dataset?\ny_pred = pipe.predict(X_train)\naccuracy_score(y_train, y_pred)","6a0c2093":"from category_encoders.target_encoder import TargetEncoder\ndef target_encode_cats(X, X_train, cats, train_labels):\n    \"\"\"\n    Target encodes a DF of categorical features, based on the three\n    component vectors of y_true.  Target encoding is designed to work with\n    binary labels; in order to make it work with a vector that has three\n    values, I target encode against a binary version of each and then\n    concatenate the results.\n\n    Parameters\n    ----------\n    X : pandas.DataFrame\n        Dataset to be fixed\n        \n    cats : List of categorical columns to encode\n\n    train_labels : pandas.DataFrame\n                    The vector of training labels\n\n    Returns\n    ----------\n    X2 : pandas.DataFrame\n            Fixed vector\n\n    \"\"\"\n    # Make a clean copy, to ensure we're not changing the original DF\n    X2 = X.copy()\n    \n    y_true = train_labels['status_group']\n    y_works = [1.0 if x == 'functional' else 0.0 for x in y_true]\n    y_broken = [1.0 if x == 'non functional' else 0.0 for x in y_true]\n    y_repair = [1.0 if x == 'functional needs repair' else 0.0 for x in y_true]\n\n    y_vectors = [y_works, y_broken, y_repair]\n    X_TE_all = []\n\n    # We want to create encoding based on the training features and \n    # labels, but apply this encoding to any vector (such as X_test)\n    for i in [1,2,3]:\n        # Make an encoder\n        TE = TargetEncoder()\n        \n        # Fit it to the training data\n        TE.fit(X=X_train[cats], y=y_vectors[i-1])\n\n        # Transform the cat columns in X\n        X_TE = TE.transform(X2[cats])\n        \n        # Give them custom names, so that the columns encoded against\n        # each target vector have a different name\n        X_TE = X_TE.rename(columns=(lambda x: x + '_TE' + str(i)))\n        X_TE_all.append(X_TE)\n\n    new_cats = pd.concat(X_TE_all, sort=False, axis=1)\n    \n    X2 = X2.drop(columns=cats)\n    X2 = pd.concat([X2,new_cats], sort=False, axis=1)\n    \n    return X2","d5b6da79":"categoricals = ['funder',\n                     'installer',\n                     'wpt_name',\n                     'basin',\n                     'subvillage',\n                     'region',\n                     'district_code',\n                     'lga',\n                     'ward',\n                     'public_meeting',\n                     'scheme_management',\n                     'scheme_name',\n                     'permit',\n                     'extraction_type',\n                     'management',\n                     'management_group',\n                     'payment',\n                     'water_quality',\n                     'quantity',\n                     'source',\n                     'source_class',\n                     'waterpoint_type',]","ee7bfc2f":"# Use all the cleanup steps\nX_train_temp = cleanup4(cleanup3(cleanup2(cleanup1(train_features))))\nX_train_new = target_encode_cats(X=X_train_temp, \n                                 X_train=X_train_temp, \n                                 cats=categoricals, \n                                 train_labels=train_labels)","7b2d2c1a":"%%time\nfrom xgboost import XGBClassifier\nmodelxgb = XGBClassifier(objective = 'multi:softmax', booster = 'gbtree', nrounds = 'min.error.idx', \n                      num_class = 3, maximize = False, eval_metric = 'merror', eta = .1,\n                      max_depth = 14, colsample_bytree = .4)\n\ny_true = train_labels['status_group']\nmodelxgb.fit(X_train_new, y_true)","c14c327d":"# Test on training data\nfrom sklearn.metrics import accuracy_score\ny_pred = modelxgb.predict(X_train_new)\naccuracy_score(y_true, y_pred)","ae00875a":"# A more complex model\nThis time around I used all the cleanup steps and gradient boosting instead of logistic regression.  Instead of one-hot encoding like before, I opted for target encoding even though it's normally designed to work with only two categories of y-values.  To get around that limitation, I created three different y vectors that reflect whether each of the possible y-values is present or not, and trained a target encoder on each one. ","f59bd7f2":"# Cleanup functions\nI packaged my cleanup process into several functions, so that I could apply them selectively while iterating and access data at several levels of cleanup.","f983408e":"A few years ago, the Tanzanian Ministry of Water conducted a survey of tens of thousands of water pumps that had been installed around the country over the years.  The Ministry knew what kind of pumps existed, which organizations had installed them, and how they were managed.  The survey added one last important detail to the existing knowledge: did the pumps still work?  \n\nThe Ministry's data about the pumps and their status was collected into a dataset and organized into a competition by [DrivenData](https:\/\/www.drivendata.org\/competitions\/7\/pump-it-up-data-mining-the-water-table\/), a platform that organizes data science competitions around problems with \nhumanitarian impact.  Predictive analytics on this dataset could allow the Ministry to know in advance which pumps are most likely to be non-functional, so that they can triage their repair efforts.  It's hard to find much simpler examples of how a good predictive model can directly save time and money.","c022c215":"# Baseline Regression\nBefore doing anything more complicated, I wanted to run the simplest possible model.  So I processed the data with cleanup1 and ran a logistic regression using only categorical features (and excluding the top 6 with the highest cardinality).","275b5de4":"XGBoost is a bit overfit to the training data, but still managed a solid 80% when tested against the test data in the competition. My experince with this competition (like that of my classmates) was that the majority of the value we added came through good feature cleaning and occasional feature engineering.  Hyperparameter tweaks managed to change people's scores only marginally, and frequently would lead to worse results than had been achieved with simpler models.  We knew intellectually that more complex models don't always lead to better results, but this competition really drove the point home viscerally.  Now we _really_ know."}}