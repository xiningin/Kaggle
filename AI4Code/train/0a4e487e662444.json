{"cell_type":{"53ddba04":"code","8dfc2f12":"code","b8be6932":"code","f3f6d02f":"code","3138fc70":"code","7627d123":"code","acb9ac11":"code","3d15fd34":"code","8254e4bb":"code","02ef8466":"code","b36c0416":"code","89fabd5c":"code","bc0f7d7f":"code","4a346da9":"code","03e16c09":"code","279502bf":"code","58907648":"code","0edb5067":"code","825310cd":"code","c0da17fa":"code","6a9bed08":"code","fa54d379":"code","8030a9cb":"code","ea021373":"code","efe9a57f":"code","03f21e37":"code","637feaff":"code","25315b46":"code","f541f28a":"code","aec5c3c2":"code","9f8ea256":"code","a02c84bf":"code","0b3fa351":"code","c1a1be20":"code","02a76c3d":"code","c47cb0c7":"code","6af21ee8":"code","2bc02dfd":"code","fc05df06":"code","c75870b9":"code","afa492e1":"code","0449c89f":"code","640f2489":"code","329dde8c":"code","187695ec":"code","044115cf":"code","08333394":"code","22f6e3d5":"code","6559f6cd":"code","b8fd5282":"code","1b993c1e":"code","a6a86971":"code","dae5c465":"code","8b85c709":"code","2e6f12d5":"code","97e302e8":"code","9de137cc":"code","a470cbfc":"code","1ce75fb6":"code","6c2b69a1":"code","779a5f30":"code","c795ff76":"code","071355e8":"code","1712d37b":"code","e2ba63c8":"code","4253e9a8":"code","9f877815":"code","1e5f4855":"code","812633a8":"markdown","26d1fe9f":"markdown","ea0b1228":"markdown","96ffaa26":"markdown","30f14e41":"markdown","d216b992":"markdown","bc2cff11":"markdown","38f430b4":"markdown","25613beb":"markdown","bc1248cf":"markdown"},"source":{"53ddba04":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 5GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","8dfc2f12":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\n!pip install ppscore\n!pip install lazypredict","b8be6932":"train = pd.read_csv(\"\/kaggle\/input\/titanic\/train.csv\")","f3f6d02f":"train.head()","3138fc70":"import ppscore as pps","7627d123":"pps.matrix(train)","acb9ac11":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')\nplt.show()","3d15fd34":"sns.set_style('whitegrid')","8254e4bb":"sns.countplot(x=train['Survived'],data=train,hue='Sex')\nplt.show()","02ef8466":"sns.countplot(x=train['Survived'],data=train,hue='Pclass')\nplt.show()","b36c0416":"sns.distplot(train['Age'].dropna(),kde=True,bins=30)","89fabd5c":"train.info()","bc0f7d7f":"sns.countplot(x='SibSp',data=train)","4a346da9":"train[\"Fare\"].hist(bins=70,figsize=(10,4))\nplt.show()","03e16c09":"sns.boxplot(x='Pclass',y='Age',data=train)","279502bf":"def impute_age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n    if pd.isnull(Age):\n        if Pclass==1:\n            return 37\n        elif Pclass==2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age","58907648":"train['Age']=train[[\"Age\",\"Pclass\"]].apply(impute_age,axis=1)","0edb5067":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')\nplt.show()","825310cd":"train.drop('Cabin',inplace=True,axis=1)","c0da17fa":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')\nplt.show()","6a9bed08":"train.dropna(inplace=True)","fa54d379":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')\nplt.show()","8030a9cb":"sex=pd.get_dummies(train['Sex'])\nsex","ea021373":"sex=pd.get_dummies(train['Sex'],drop_first=True)\nsex","efe9a57f":"embark =pd.get_dummies(train['Embarked'],drop_first=True)\nembark","03f21e37":"train=pd.concat([train,sex,embark],axis=1)","637feaff":"train.head()","25315b46":"import re\nl=[]\nx=0\nfor i in train[\"Name\"]:\n    if(str(i).find(\"Mr.\")>0 or str(i).find(\"Mrs.\")>0):\n        l.append(1)\n    else:\n        l.append(0)\n    print(l[x],i)\n    x+=1","f541f28a":"train['Maritial_Status'] = l","aec5c3c2":"train.head()","9f8ea256":"train.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)","a02c84bf":"train.head()\ny=train[\"Survived\"]","0b3fa351":"x=train.drop(\"Survived\",axis=1)","c1a1be20":"import lazypredict\nimport sys","02a76c3d":"from lazypredict.Supervised import LazyClassifier\nfrom sklearn.model_selection import train_test_split\n\nX_train, X_test, y_train, y_test = train_test_split(x, y,test_size=.4,random_state =23)\nclf = LazyClassifier(verbose=0,ignore_warnings=True, custom_metric=None)\nmodels,predictions = clf.fit(X_train, X_test, y_train, y_test)\nmodels","c47cb0c7":"from sklearn.preprocessing import StandardScaler\nscaler=StandardScaler()","6af21ee8":"scaler.fit(train)\nscaled_features=scaler.transform(train)\ntrain=pd.DataFrame(scaled_features,columns=train.columns)\ntrain.head()","2bc02dfd":"from sklearn.model_selection import train_test_split as tits","fc05df06":"x_train,x_test,y_train,y_test=tits(x,y,test_size=0.2,random_state=23)","c75870b9":"from sklearn.linear_model import LogisticRegression as lr","afa492e1":"logmodel=lr()","0449c89f":"logmodel.fit(x_train,y_train)","640f2489":"predictions =logmodel.predict(x_test)","329dde8c":"from sklearn.metrics import classification_report as cr","187695ec":"print(cr(y_test,predictions))","044115cf":"test=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","08333394":"test.isna().sum()","22f6e3d5":"test['Age']=test[[\"Age\",\"Pclass\"]].apply(impute_age,axis=1)","6559f6cd":"test.drop('Cabin',inplace=True,axis=1)","b8fd5282":"sex=pd.get_dummies(test['Sex'])\nsex","1b993c1e":"sex=pd.get_dummies(test['Sex'],drop_first=True)\nsex","a6a86971":"embark =pd.get_dummies(test['Embarked'],drop_first=True)\nembark","dae5c465":"test=pd.concat([test,sex,embark],axis=1)","8b85c709":"def impute_age(cols):\n    Age=cols[0]\n    Pclass=cols[1]\n    if pd.isnull(Age):\n        if Pclass==1:\n            return 37\n        elif Pclass==2:\n            return 29\n        else:\n            return 24\n    else:\n        return Age","2e6f12d5":"import re\nl=[]\nxx=0\nfor i in test[\"Name\"]:\n    if(str(i).find(\"Mr.\")>0 or str(i).find(\"Mrs.\")>0):\n        l.append(1)\n    else:\n        l.append(0)\n    print(l[xx],i)\n    xx+=1","97e302e8":"test['Maritial_Status'] = l","9de137cc":"test.drop(['Sex','Embarked','Name','Ticket'],axis=1,inplace=True)","a470cbfc":"x.head()","1ce75fb6":"test.head()","6c2b69a1":"from sklearn.ensemble import RandomForestClassifier\nrdmf = RandomForestClassifier(n_estimators=100,max_depth=5, criterion='entropy')\nrdmf.fit(x,y)","779a5f30":"scaler.fit(test)\nscaled_features=scaler.transform(test)\ntest=pd.DataFrame(scaled_features,columns=test.columns)\ntest.head()","c795ff76":"from xgboost import XGBClassifier\nxgb = XGBClassifier()\nxgb.fit(x,y)","071355e8":"test['Fare'] = test['Fare'].fillna((test['Fare'].mean()))","1712d37b":"predictions =rdmf.predict(test)","e2ba63c8":"ft=pd.read_csv('\/kaggle\/input\/titanic\/test.csv')","4253e9a8":"predi = pd.DataFrame(predictions, columns=['predictions'])\npredi.head()","9f877815":"data = [ft[\"PassengerId\"], predi[\"predictions\"]]\nheaders = [\"PassengerId\", \"Survived\"]\nfinal = pd. concat(data, axis=1, keys=headers)","1e5f4855":"final.to_csv(\"res1.csv\",index=False)","812633a8":"After a lot of experimenting I went with the random forest model as it gave the best accuracy.","26d1fe9f":"<a id=\"section4\"><\/a>\n## Building the Feature Engineering Machine\n\n### [Back To Table of Contents](#toc_section)\n","ea0b1228":"<a id=\"section2\"><\/a>\n## Exploring the data\n\n### [Back To Table of Contents](#toc_section)","96ffaa26":"<a id=\"toc_section\"><\/a>\n## Table of Contents\n* [Importing all the Required Libraries](#section1)\n* [Exploring the Data](#section2)\n* [Visualizing given dataset](#section3)\n* [Building the Feature Engineering Machine](#section4)\n* [Modelling](#section13)","30f14e41":"<a id=\"section1\"><\/a>\n## Importing the libraries\n\n### [Back To Table of Contents](#toc_section)","d216b992":"Male and Female are multicollinear columns. We don't want multicollinearity in the dataset as it is bad for the model as it will make the multicollinear columns as a whole more statistically significant and reduce the significance of other columns in the model.","bc2cff11":"Kaggle doesn't support ppscore. But **I would highly advise everyone to use ppscore** which is a much better alternative to the same old correlation. Because there are a lot of trends which ppscore captures which correlation fails to do.","38f430b4":"<a id=\"section3\"><\/a>\n## Visualizing given dataset\n\n### [Back To Table of Contents](#toc_section)","25613beb":"<a id=\"section13\"><\/a>\n# Modelling\n### [Back To Table of Contents](#toc_section)","bc1248cf":"We see that there is a lot of null values here!"}}