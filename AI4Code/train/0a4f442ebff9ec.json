{"cell_type":{"f64eed69":"code","582930ae":"code","8658bae1":"code","c26958ca":"code","8105ec02":"code","e5089e08":"code","9a136501":"code","16008752":"code","3514c843":"code","cc1302fe":"code","5140c9c3":"code","cd6e4e1c":"code","4cbd88f4":"code","d789f809":"code","a93d4da8":"code","ee7abe8f":"code","f0c97b7d":"code","cf9aed08":"code","9458148b":"code","fe2ecba2":"code","9c08a6ef":"code","9a715bc8":"markdown","d9d25b30":"markdown","edec7334":"markdown","c3972a6b":"markdown","9c4baa8f":"markdown","dec1eab3":"markdown","0cee2087":"markdown","29509ad3":"markdown"},"source":{"f64eed69":"import os\nprint(os.listdir('\/kaggle\/input\/fer2013'))","582930ae":"train_path = '\/kaggle\/input\/fer2013\/train'\nval_path = '\/kaggle\/input\/fer2013\/test'","8658bae1":"import matplotlib.pyplot as plt\ndef plot_images(img_dir, top=10):\n    all_img_dirs = os.listdir(img_dir)\n    img_files = [os.path.join(img_dir, file) for file in all_img_dirs][:5]\n  \n    plt.figure(figsize=(10, 10))\n  \n    for idx, img_path in enumerate(img_files):\n        plt.subplot(5, 5, idx+1)\n    \n        img = plt.imread(img_path)\n        plt.tight_layout()         \n        plt.imshow(img, cmap='gray') ","c26958ca":"plot_images(train_path+'\/angry')","8105ec02":"plot_images(train_path+'\/disgust')","e5089e08":"plot_images(train_path+'\/fear')","9a136501":"plot_images(train_path+'\/happy')","16008752":"plot_images(train_path+'\/neutral')","3514c843":"plot_images(train_path+'\/sad')","cc1302fe":"plot_images(train_path+'\/surprise')","5140c9c3":"from tensorflow.keras.preprocessing.image import ImageDataGenerator \nfrom tensorflow.keras.utils import to_categorical, plot_model\nfrom tensorflow.keras import models, layers, regularizers","cd6e4e1c":"emotion_labels = sorted(os.listdir(train_path))\nprint(emotion_labels)","4cbd88f4":"batch_size = 64\ntarget_size = (48,48)\n\ntrain_datagen = ImageDataGenerator(rescale=1.\/255)\nval_datagen   = ImageDataGenerator(rescale=1.\/255)\n\ntrain_generator = train_datagen.flow_from_directory(\n        train_path,\n        target_size=target_size,\n        batch_size=batch_size,\n        color_mode=\"grayscale\",\n        class_mode='categorical',\n        shuffle=True)\n\nval_generator = val_datagen.flow_from_directory(\n        val_path,\n        target_size=target_size,\n        batch_size=batch_size,\n        color_mode=\"grayscale\",\n        class_mode='categorical')","d789f809":"input_shape = (48,48,1) # img_rows, img_colums, color_channels\nnum_classes = 7","a93d4da8":"# Build Model\nmodel = models.Sequential()\n\nmodel.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same', input_shape=input_shape)) #, data_format='channels_last', kernel_regularizer=regularizers.l2(0.01)))\nmodel.add(layers.Conv2D(32, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(64, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.Conv2D(128, kernel_size=(3, 3), activation='relu', padding='same'))\nmodel.add(layers.MaxPooling2D(pool_size=(2, 2), strides=(2, 2)))\n\nmodel.add(layers.Flatten())\n\nmodel.add(layers.Dense(512, activation='relu'))\nmodel.add(layers.Dense(64, activation='relu'))\n\nmodel.add(layers.Dense(num_classes, activation='softmax'))\n\nmodel.summary()","ee7abe8f":"# Compile Model\nmodel.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy']) ","f0c97b7d":"num_epochs = 100\nSTEP_SIZE_TRAIN = train_generator.n\/\/train_generator.batch_size\nSTEP_SIZE_VAL   = val_generator.n\/\/val_generator.batch_size","cf9aed08":"# Train Model\nhistory = model.fit(train_generator, steps_per_epoch=STEP_SIZE_TRAIN, epochs=num_epochs, verbose=1, validation_data=val_generator, validation_steps=STEP_SIZE_VAL)","9458148b":"# Save Model\nmodels.save_model(model, 'fer2013_cnn.h5') ","fe2ecba2":"# Evaluate Model\nscore = model.evaluate_generator(val_generator, steps=STEP_SIZE_VAL) \nprint('Test loss: ', score[0])\nprint('Test accuracy: ', score[1])","9c08a6ef":"# Show Train History\nkeys=history.history.keys()\nprint(keys)\n\ndef show_train_history(hisData,train,test): \n    plt.plot(hisData.history[train])\n    plt.plot(hisData.history[test])\n    plt.title('Training History')\n    plt.ylabel(train)\n    plt.xlabel('Epoch')\n    plt.legend(['train', 'test'], loc='upper left')\n    plt.show()\n\nshow_train_history(history, 'loss', 'val_loss')\nshow_train_history(history, 'accuracy', 'val_accuracy')","9a715bc8":"## Dataset : [FER-2013](https:\/\/www.kaggle.com\/msambare\/fer2013)\n![fer2013](https:\/\/miro.medium.com\/max\/602\/1*slyZ64ftG12VU4VTEmSfBQ.png)","d9d25b30":"## Evaluate Model","edec7334":"## Save Model","c3972a6b":"# Facial Expression Recognition (Emotion Detection)","9c4baa8f":"## Data Generator","dec1eab3":"## Build Model","0cee2087":"## Show Training History","29509ad3":"## Train Model"}}