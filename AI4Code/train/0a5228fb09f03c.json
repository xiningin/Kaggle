{"cell_type":{"7c3d786c":"code","9ae0659a":"code","170d2cdd":"code","7ae5868d":"code","ed645b95":"code","5b02d906":"code","42124d22":"code","a0ec0487":"code","d9d303c9":"code","d43502c3":"code","5428f056":"code","7a52c2b5":"code","ed18d8fc":"code","38e0a71e":"markdown","02f2776a":"markdown","8ddc5593":"markdown","698d6d4e":"markdown","9ef900a2":"markdown","cbc636b7":"markdown","5ee4fd97":"markdown","449a15fb":"markdown","57820238":"markdown","fb51cc52":"markdown","0cb198b5":"markdown","ec4ccae8":"markdown","ae63bfec":"markdown","811597b9":"markdown"},"source":{"7c3d786c":"import matplotlib.pyplot as plt \nimport pandas as pd \nimport numpy as np \nimport seaborn as sns \nimport warnings\n\nwarnings.filterwarnings(\"ignore\")\n","9ae0659a":"df = pd.read_csv('\/kaggle\/input\/breast-cancer-wisconsin-data\/data.csv')\nprint(df.head)","170d2cdd":"print(df.info()) ","7ae5868d":"copied_data = df.dropna(axis=1)","ed645b95":"from sklearn.preprocessing import LabelBinarizer \n\n\nencoder = LabelBinarizer()\nfeature = copied_data['diagnosis']\nencoded_feature = encoder.fit_transform(feature)\ncopied_data['diagnosis'] = encoded_feature\nmost_correlated = copied_data.corr().abs()['diagnosis'].sort_values(ascending=False)\n\n#We will chose top 10 most correlated features\nmost_correlated = most_correlated[:10]\ntraining_set = copied_data.loc[:, most_correlated.index]\nprint(most_correlated)\n","5b02d906":"sns.catplot(x=\"diagnosis\", y=\"radius_mean\", data=training_set)\nplt.show()","42124d22":"for feature in training_set.columns.values:\n    sns.catplot(x='diagnosis', y=feature, data=training_set)\n    ","a0ec0487":"plt.figure(figsize=(10, 10))\nsns.heatmap(training_set.corr(), annot=True, fmt='.0%')","d9d303c9":"corr_matrix = copied_data.corr()\nprint(corr_matrix['diagnosis'])","d43502c3":"from sklearn.preprocessing import StandardScaler \nfrom sklearn.model_selection import train_test_split\n\nlabels = training_set['diagnosis']\nnew_training_set = training_set.drop('diagnosis', axis=1)\n\nX_train, X_test, y_train, y_test = train_test_split(new_training_set, labels, test_size=0.2, random_state=0)\n\nscaler = StandardScaler()\nX_train = scaler.fit_transform(X_train)\nX_test = scaler.fit_transform(X_test)\n","5428f056":"from sklearn.linear_model import LogisticRegression \nfrom sklearn.ensemble import RandomForestClassifier \nfrom sklearn.tree import DecisionTreeClassifier \nfrom sklearn.model_selection import cross_val_score\n\nmodels = {'Logistic':LogisticRegression(), 'forest':RandomForestClassifier(n_estimators=10, criterion='gini', random_state=0),\n         'tree':DecisionTreeClassifier(criterion='gini', random_state=0)}\n\ntrained_models = list()\n\nfor value in models.values():\n    model = value\n    model.fit(X_train, y_train)\n    acc = cross_val_score(model, X_train, y_train, scoring='accuracy', cv=10)\n    print(acc.mean())\n    trained_models.append(model)","7a52c2b5":"from sklearn.metrics import confusion_matrix \n\npredictions = trained_models[0].predict(X_test)\nconf_matrix = confusion_matrix(y_test, predictions)\n\ndataframe = pd.DataFrame(conf_matrix)\nsns.heatmap(dataframe, annot=True, cbar=None, cmap=\"Reds\")\nplt.title(\"Confusion Matrix\"), plt.tight_layout()\nplt.ylabel(\"True Class\"), plt.xlabel(\"Predicted Class\")\nplt.show()","ed18d8fc":"accuracy = (dataframe[0][0] + dataframe[1][1]) \/ (dataframe[0][1] + dataframe[1][0]+ dataframe[0][0] + dataframe[1][1]) \nprint('Test accuracy:', accuracy)","38e0a71e":"This is my first attempt in machine learning and data science fields. I tried to apply what i learned in books and courses. So if there's an anomaly or somethink i was wrong on , please let me now. So let's jump to our problem.  \n\n","02f2776a":"# One hot encode the diagnosis \n\nI will encode the diagnosis feature into a binary one : 1 for malignant 0 for benign in order to determine the most correlated features. ","8ddc5593":"# Load data and take a quick look","698d6d4e":"Hummmm. As you can see there isn't interesting correlations here. Let's move to the next step. ","9ef900a2":"# Training the model","cbc636b7":"# Preprocessing the training set\n\nWe will apply feature scalling and split our data","5ee4fd97":"Okay so it's obvious that the larger the radius is the higher the possibility of the tumor to be malignant\nDon't forget malignant is encoded to 1 !","449a15fb":"# Visualizing ","57820238":"Now we have 31 feature to analyse .I don't think that it's wise to analyse them one by one. So my approach is to define the most correlated features with our target(diagnosis) and then visualise them. ","fb51cc52":"Hum.. Nice! Our classifier is doing pretty well on data it has never seen! \nLet's calculate the accuracy using the formula:\naccuracy = (True Positive + True Negative) \/ (True Positive + True Negative + False Positive + False Negative)\n","0cb198b5":"# Accuracy on test set\n\nWill choose the confusion matrics to calculate the accuracy on test data.","ec4ccae8":"As you can see all the selected features are positively correlated to our target. Now we will check negatively correlated features.","ae63bfec":"Okay so based on the results, i will choose the logistic regression model.","811597b9":"The last column is totaly empty so let's drop it.\n"}}