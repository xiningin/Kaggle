{"cell_type":{"40b55291":"code","fed6af25":"code","b2323b26":"code","9b08efa8":"code","0fa1f6b7":"code","ae6e650d":"code","653749cf":"code","3b7f7f0e":"code","f38cf409":"code","c55c5dae":"code","9abcaf39":"code","73a5b852":"code","26797ab3":"code","c5190ad4":"code","c8755c2f":"code","ba3a5e89":"code","a214f5ff":"code","dd3d15f3":"markdown","b9dbb452":"markdown","b08e4d89":"markdown","b722b2cf":"markdown","153d85a0":"markdown","a929ff37":"markdown","ec924c94":"markdown","ad782f71":"markdown","ddfced8e":"markdown","2ab7eee8":"markdown","58789e90":"markdown","36cf433c":"markdown","0b456009":"markdown"},"source":{"40b55291":"import numpy as np\nimport pandas as pd","fed6af25":"df=pd.read_csv('..\/input\/sartorius-cell-instance-segmentation\/train.csv',nrows=1)","b2323b26":"df","9b08efa8":"df.annotation","0fa1f6b7":"en_pix=list(df.annotation)","ae6e650d":"en_pix","653749cf":"print(len(en_pix[0].split(' ')))\nen_pix[0].split(' ')","3b7f7f0e":"rle = list(map(int, en_pix[0].split(' ')))\nrle","f38cf409":"pixel,pixel_count = [],[]\n[pixel.append(rle[i]) if i%2==0 else pixel_count.append(rle[i]) for i in range(0, len(rle))]\nprint('pixel starting points:\\n',pixel)\nprint('pixel counting:\\n', pixel_count)","c55c5dae":"rle_pixels = [list(range(pixel[i],pixel[i]+pixel_count[i])) for i in range(0, len(pixel))]\nprint('rle_pixels\\n:', rle_pixels)","9abcaf39":"rle_mask_pixels = sum(rle_pixels,[]) \nprint('rle mask pixels:\\n', rle_mask_pixels)","73a5b852":"import matplotlib.pyplot as plt\nimport cv2","26797ab3":"plt.imshow(cv2.imread('..\/input\/sartorius-cell-instance-segmentation\/train\/0030fd0e6378.png'))","c5190ad4":"mask_img = np.zeros((520*704,1), dtype=int)","c8755c2f":"mask_img[rle_mask_pixels] = 255","ba3a5e89":"l,b=cv2.imread('..\/input\/sartorius-cell-instance-segmentation\/train\/0030fd0e6378.png').shape[0],cv2.imread('..\/input\/sartorius-cell-instance-segmentation\/train\/0030fd0e6378.png').shape[1]\nmask = np.reshape(mask_img, (b, l)).T","a214f5ff":"plt.imshow(mask)","dd3d15f3":"# How to understand annotations \/ encoded pixels ?","b9dbb452":"**Shape of RGB image is (704,520,3). It means there are 704 X 520 = 3,66,080 locations.Its corresponding mask (704,520) is not given, instead they gave us EncodedPixels.**\n","b08e4d89":"So, at these locations, input image should be masked. Lets take a black mask and make it white at these pixel locations.\n\nLoad and display the input image:","b722b2cf":"This is given Encoded Pixels, lets generate a mask using it.\n\nFirst lets split these numbers at space using split function:","153d85a0":"Now lets convert list of lists into a single list,","a929ff37":"Reshape the array into input image size","ec924c94":"Lets convert these strings into integers using map function","ad782f71":"Lets generate masked pixel locations where exactly the mask is there using above 2 lists.","ddfced8e":"**In the first image 0030fd0e6378 we have annotations as 118145 6 118849 7 119553 8 120257 8 120961 9 121665 10 122369 12 123074 13 123778 14 124482 15 12518... which means take 6 pixels starting from 118145 , take 7 pixels starting from 118849 , take 8 pixels starting from 119553 ....so on**","2ab7eee8":"lets understand how to generate masks, if EncodedPixels are given instead of mask images.","58789e90":"First number is starting pixel and next number is count from that starting pixel. Lets bring them into 2 seperate lists","36cf433c":"Lets replace the above mentioned locations (rle_mask_pixels) with white pixels(255).","0b456009":"Lets display the final mask image:"}}