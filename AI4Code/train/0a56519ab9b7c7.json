{"cell_type":{"ba962039":"code","8d84291b":"code","f2912b8d":"code","8639ba06":"code","865157f7":"code","cf645b5c":"code","6daca88e":"code","5f693bc8":"code","038cdac2":"code","523bf947":"code","793a5faa":"code","600ad79d":"code","a346d564":"code","fa9a4f52":"code","e787d3ac":"code","be460918":"code","043f8ae4":"code","b5597add":"code","0152f7c8":"code","b11f779a":"code","e5f46456":"code","6928f6d8":"code","1f49b464":"code","92df346b":"code","81d16948":"code","30b95065":"code","3013be15":"code","1eb51feb":"code","77933599":"code","09c49bd2":"code","0ebac3e0":"code","2984611c":"code","3543d719":"code","a709f635":"code","7604d6d8":"code","76285ead":"code","aac06dae":"code","6718472a":"code","31b1a4de":"code","854eac28":"code","d67a85b3":"code","ee98ac3c":"code","7896f2c2":"code","76365aa4":"code","8c44f35f":"code","de541f0f":"code","db66f70c":"code","270be4e5":"code","c58cff36":"code","694c79f5":"code","8243558c":"code","ae8303a2":"code","44d05fca":"code","40f64d5b":"code","9fbf6edc":"code","7d3e8d33":"code","067bb6ec":"code","6c640870":"code","c0d29335":"code","58c801c9":"code","ddf1a708":"code","8f97f092":"code","238d9d95":"code","9eb210c4":"code","3cd0179a":"code","d4286095":"code","9f1c6342":"code","5a2d3011":"code","56362585":"code","fbc98b74":"code","358956e5":"code","6e89687b":"code","b5943c00":"code","e9987708":"code","189af091":"code","7d6d13c5":"code","f2adaee3":"code","16d1e586":"code","bf29111a":"markdown","8274d4b0":"markdown","32fa3067":"markdown","bed53fec":"markdown","c8295a45":"markdown","942aeee6":"markdown"},"source":{"ba962039":"import numpy as np\nimport pandas as pd","8d84291b":"df_churn = pd.read_csv(\"..\/input\/telco-customer-churn\/WA_Fn-UseC_-Telco-Customer-Churn.csv\")\ndf_churn.head()","f2912b8d":"df_churn.columns","8639ba06":"df_churn.isnull().any()","865157f7":"df_churn['InternetService'].unique()","cf645b5c":"df_churn.dtypes","6daca88e":"df_churn_drop = df_churn.drop(['customerID','gender','SeniorCitizen','Partner','tenure','InternetService','DeviceProtection','OnlineSecurity','OnlineBackup','TechSupport','StreamingTV','StreamingMovies'],axis=1)\ndf_churn_drop.isnull().any()","5f693bc8":"df_churn_drop.dtypes","038cdac2":"df_churn_drop['PhoneService'].unique()","523bf947":"df_churn_drop.shape","793a5faa":"df_churn_Drop = df_churn_drop.drop(df_churn_drop[df_churn_drop['PhoneService'] == 'No'].index)\ndf_churn_Drop['PhoneService'].unique()","600ad79d":"df_churn_Drop.shape","a346d564":"df_churn_DROP = df_churn_Drop.drop(['PhoneService'],axis = 1)\ndf_churn_DROP.dtypes","fa9a4f52":"df_churn_clean = df_churn_DROP #df_churn_DROP for check real value","e787d3ac":"df_churn_DROP['PaymentMethod'].unique()","be460918":"df_churn_DROP['Contract'].unique()","043f8ae4":"df_churn_clean['Dependents'] = pd.factorize(df_churn_clean['Dependents'])[0]\ndf_churn_clean['MultipleLines'] = pd.factorize(df_churn_clean['MultipleLines'])[0]\ndf_churn_clean['Contract'] = pd.factorize(df_churn_clean['Contract'])[0]\ndf_churn_clean['PaperlessBilling'] = pd.factorize(df_churn_clean['PaperlessBilling'])[0]\ndf_churn_clean['PaymentMethod'] = pd.factorize(df_churn_clean['PaymentMethod'])[0]\ndf_churn_clean['TotalCharges'] = pd.factorize(df_churn_clean['TotalCharges'])[0]\ndf_churn_clean['Churn'] = pd.factorize(df_churn_clean['Churn'])[0]\ndf_churn_clean.dtypes","b5597add":"df_churn_clean['TotalCharges'].unique()","0152f7c8":"df_churn_clean.describe()","b11f779a":"df_churn_clean.groupby('Churn')['Churn'].count()","e5f46456":"y = df_churn_clean['Churn'].values \nX = df_churn_clean.drop(['Churn'],axis = 1).values","6928f6d8":"len(y)","1f49b464":"len(X)","92df346b":"from sklearn.model_selection import train_test_split \nX_train, X_test, y_train, y_test = train_test_split(X,y,test_size=0.2,random_state=0)","81d16948":"X_train.shape","30b95065":"y_train.shape","3013be15":"X_test.shape","1eb51feb":"y_test.shape","77933599":"from sklearn.preprocessing import MinMaxScaler #normalization\nfrom sklearn.ensemble import RandomForestClassifier #classifier\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.pipeline import Pipeline\nfrom imblearn.under_sampling import RandomUnderSampler #imbalanced\n#from sklearn.feature_selection import SelectKBest\n#from sklearn.feature_selection import f_classif\n\n#Imbalanced\nundersample = RandomUnderSampler(sampling_strategy='majority') \nX_res, y_res = undersample.fit_resample(X_train, y_train)\n\n#Pipeline\nclf = Pipeline([ \n    ('scaler',MinMaxScaler(feature_range=(0,1))), #normalization\n    #('feature_selection',SelectKBest(f_classif)), #select feature\n    ('classification',RandomForestClassifier(random_state=0))#classifier\n])\n\n\n#Tune GridSearchCV\nparams = { \n    #'feature_selection__k':[3,5,7],\n    'classification__n_estimators': [10,20,50,100,500],\n    #'classification__min_samples_leaf' : [1,2,4,8,16],\n    'classification__max_features' : ['sqrt',0.5,0.8],\n    #'classification__criterion': ['gini','entropy'],\n}\n\nbest_clf = GridSearchCV(clf, params, cv=10)\n\nbest_clf.fit(X_res, y_res)","09c49bd2":"best_clf.best_params_","0ebac3e0":"acc = best_clf.best_score_\nprint(\"10CV accuracy: \"+str(acc))","2984611c":"yp = best_clf.predict(X_test)\nacc = sum(yp == y_test)\/len(y_test)\nprint(\"Test Training accuracy: \"+str(acc))","3543d719":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ntarget_names = ['Churn', 'Not Churn']\nC = confusion_matrix(y_test,yp) \nC = C \/ C.astype(np.float).sum(axis=1)*100\nsns.heatmap(C, annot=True, fmt=\"f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\nplt.ylabel(\"True Label\")\nplt.xlabel(\"Predicted Label\")\nplt.show()","a709f635":"df = pd.read_csv(\"..\/input\/plenoi-mail\/MAIL.csv\", header = None)\ndf_test = pd.read_csv(\"..\/input\/plenoi-mail\/MAIL_test.csv\", header = None)\ndf_test.head()","7604d6d8":"df.shape","76285ead":"df_test.shape","aac06dae":"df.isnull().sum().sum()","6718472a":"df.describe()","31b1a4de":"df.groupby(0)[0].count()","854eac28":"#train\nX_train = df.drop([0],axis=1).values\ny_train = df[0].values\n#test\nX_test = df_test.drop([0],axis=1).values\ny_test = df_test[0].values","d67a85b3":"len(X_train)","ee98ac3c":"len(y_train)","7896f2c2":"from sklearn.preprocessing import MinMaxScaler #normalization\nfrom sklearn.svm import SVC  #classifier\nfrom imblearn.under_sampling import RandomUnderSampler #imbalanced\nfrom sklearn.model_selection import GridSearchCV \nfrom sklearn.pipeline import Pipeline\nfrom sklearn.feature_selection import SelectKBest\nfrom sklearn.feature_selection import f_classif\n\n#Imbalanced\nundersample = RandomUnderSampler(sampling_strategy='majority') \nX_res, y_res = undersample.fit_resample(X_train, y_train)\n\n#Pipeline\nclf = Pipeline([ \n    ('scaler',MinMaxScaler(feature_range=(0,1))), #normalization\n    ('feature_selection',SelectKBest(f_classif)), #select feature\n    ('classification',SVC(random_state=0))#classifier\n])\n\n\n#Tune GridSearchCV\nparams = { \n    'feature_selection__k':[3,5,7],\n    'classification__C': [1,2,4,8,16,32],\n    'classification__gamma' :[0.05,0.01,0,1,2,4,8,16,32]\n}\nbest_clf = GridSearchCV(clf, params, cv=10)\n\nbest_clf.fit(X_res, y_res)","76365aa4":"best_clf.best_params_","8c44f35f":"acc = best_clf.best_score_\nprint(\"10CV accuracy: \"+str(acc))","de541f0f":"yp = best_clf.predict(X_test)\nacc = sum(yp == y_test)\/len(y_test)\nprint(\"Test Training accuracy: \"+str(acc))","db66f70c":"from sklearn.metrics import confusion_matrix\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ntarget_names = ['0', '1']\nC = confusion_matrix(y_test,yp) \nC = C \/ C.astype(np.float).sum(axis=1)*100\nsns.heatmap(C, annot=True, fmt=\"f\",cmap=\"GnBu\",xticklabels=target_names, yticklabels=target_names)\nplt.ylabel(\"True Label\")\nplt.xlabel(\"Predicted Label\")\nplt.show()","270be4e5":"df = pd.read_csv(\"..\/input\/red-wine-quality-cortez-et-al-2009\/winequality-red.csv\")\ndf.head()","c58cff36":"df.shape","694c79f5":"df.groupby(\"quality\")[\"quality\"].count()","8243558c":"df_sel = df[(df['quality']==5) | (df['quality']==6) | (df['quality']==7)]\ndf_sel.shape","ae8303a2":"df_sel.isnull().any()","44d05fca":"df_sel.dtypes","40f64d5b":"df_sel.describe()","9fbf6edc":"df_sel.groupby('quality')['quality'].count()","7d3e8d33":"Xo = df_sel.drop(['quality'], axis=1).values\nyo = df_sel['quality'].values","067bb6ec":"Xo.shape","6c640870":"yo.shape","c0d29335":"labelnames = ['Quality: 5', 'Quality: 6', 'Quality: 7']\nyo[yo==5] = 0\nyo[yo==6] = 1\nyo[yo==7] = 2","58c801c9":"#TRAIN and TEST split from all data\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(Xo, yo, test_size=0.2, random_state=0) ","ddf1a708":"#TRAIN and VALOD split from train data\nfrom sklearn.model_selection import train_test_split\nX_train, X_val, y_train, y_val = train_test_split(X_train, y_train, test_size=0.2, random_state=0)","8f97f092":"X_train.shape","238d9d95":"y_train.shape","9eb210c4":"X_val.shape","3cd0179a":"y_val.shape","d4286095":"from imblearn.over_sampling import SMOTE\nsm = SMOTE(random_state=0)\nX_res, y_res = sm.fit_resample(X_train, y_train)\n\nfrom sklearn.preprocessing import MinMaxScaler\nscl = MinMaxScaler()\nscl.fit(X_res)\nX_train_norm = scl.transform(X_res) #train\nX_val_norm = scl.transform(X_val) #val\nX_test_norm = scl.transform(X_test) #test","9f1c6342":"X_train_norm.shape","5a2d3011":"y_res","56362585":"len(y_res)","fbc98b74":"num_label = len(np.unique(y_res)) \nytrain_multi = (np.arange(num_label) == y_res[:,None]).astype(np.float32) #train\nyval_multi = (np.arange(num_label) == y_val[:,None]).astype(np.float32) #val\nytest_multi = (np.arange(num_label) == y_test[:,None]).astype(np.float32) #test","358956e5":"ytrain_multi.shape","6e89687b":"sample_size, input_size = X_train_norm.shape","b5943c00":"import tensorflow as tf\ndef create_model(input_size, num_label):\n    tf.random.set_seed(0)\n    tf.compat.v1.reset_default_graph() # Clear Model\n    model = tf.keras.models.Sequential([\n      tf.keras.layers.Dense(64, activation='relu', input_shape=(input_size,)),\n      tf.keras.layers.Dense(64, activation='relu'),\n      tf.keras.layers.Dense(32, activation='relu'),\n      tf.keras.layers.Dense(32, activation='relu'),\n      tf.keras.layers.Dense(16, activation='relu'),\n      tf.keras.layers.Dense(8, activation='relu'),\n      tf.keras.layers.Dropout(0.3),\n      tf.keras.layers.Dense(num_label, activation='softmax')    \n    ])\n    return model","e9987708":"model = create_model(input_size, num_label)\nmodel.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\ntrain_acc = list()\nval_acc = list()\nfor i in range(0,250):\n  history = model.fit(X_train_norm, ytrain_multi, epochs= 2, batch_size = sample_size, validation_data= (X_val_norm, yval_multi))\n  tmp_avg = np.mean(history.history['loss'])\n  tmp_avg_val = np.mean(history.history['val_loss'])\n  train_acc.append(tmp_avg)\n  val_acc.append(tmp_avg_val)","189af091":"import matplotlib.pyplot as plt\nimport seaborn as sns\nsns.set()\nplt.figure(num=None, figsize=(16, 8), dpi=90, facecolor='w', edgecolor='k')\nplt.plot()\nplt.plot(train_acc)\nplt.plot(val_acc)\nplt.title('model loss')\nplt.ylabel('loss')\nplt.xlabel('epoch')\nplt.legend(['Train', 'Val'], loc='upper left')\nplt.show()","7d6d13c5":"yp = model.predict(X_test_norm)\nyp = np.argmax(yp, 1)\nsum(yp == y_test)\/len(y_test)","f2adaee3":"import numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\ndef make_confusion_matrix(cf,\n                          group_names=None,\n                          categories='auto',\n                          count=True,\n                          percent=True,\n                          cbar=True,\n                          xyticks=True,\n                          xyplotlabels=True,\n                          sum_stats=True,\n                          figsize=None,\n                          cmap='Blues',\n                          title=None):\n    '''\n    This function will make a pretty plot of an sklearn Confusion Matrix cm using a Seaborn heatmap visualization.\n    Arguments\n    ---------\n    cf:            confusion matrix to be passed in\n    group_names:   List of strings that represent the labels row by row to be shown in each square.\n    categories:    List of strings containing the categories to be displayed on the x,y axis. Default is 'auto'\n    count:         If True, show the raw number in the confusion matrix. Default is True.\n    normalize:     If True, show the proportions for each category. Default is True.\n    cbar:          If True, show the color bar. The cbar values are based off the values in the confusion matrix.\n                   Default is True.\n    xyticks:       If True, show x and y ticks. Default is True.\n    xyplotlabels:  If True, show 'True Label' and 'Predicted Label' on the figure. Default is True.\n    sum_stats:     If True, display summary statistics below the figure. Default is True.\n    figsize:       Tuple representing the figure size. Default will be the matplotlib rcParams value.\n    cmap:          Colormap of the values displayed from matplotlib.pyplot.cm. Default is 'Blues'\n                   See http:\/\/matplotlib.org\/examples\/color\/colormaps_reference.html\n                   \n    title:         Title for the heatmap. Default is None.\n    '''\n\n\n    # CODE TO GENERATE TEXT INSIDE EACH SQUARE\n    blanks = ['' for i in range(cf.size)]\n\n    if group_names and len(group_names)==cf.size:\n        group_labels = [\"{}\\n\".format(value) for value in group_names]\n    else:\n        group_labels = blanks\n\n    if count:\n        group_counts = [\"{0:0.0f}\\n\".format(value) for value in cf.flatten()]\n    else:\n        group_counts = blanks\n\n    if percent:\n        group_percentages = [\"{0:.2%}\".format(value) for value in (cf\/cf.astype(np.float).sum(axis=0)).flatten()]\n    else:\n        group_percentages = blanks\n\n    box_labels = [f\"{v1}{v2}{v3}\".strip() for v1, v2, v3 in zip(group_labels,group_counts,group_percentages)]\n    box_labels = np.asarray(box_labels).reshape(cf.shape[0],cf.shape[1])\n\n\n    # CODE TO GENERATE SUMMARY STATISTICS & TEXT FOR SUMMARY STATS\n    if sum_stats:\n        #Accuracy is sum of diagonal divided by total observations\n        accuracy  = np.trace(cf) \/ float(np.sum(cf))\n\n        #if it is a binary confusion matrix, show some more stats\n        if len(cf)==2:\n            #Metrics for Binary Confusion Matrices\n            precision = cf[1,1] \/ sum(cf[:,1])\n            recall    = cf[1,1] \/ sum(cf[1,:])\n            f1_score  = 2*precision*recall \/ (precision + recall)\n            stats_text = \"\\n\\nAccuracy={:0.3f}\\nPrecision={:0.3f}\\nRecall={:0.3f}\\nF1 Score={:0.3f}\".format(\n                accuracy,precision,recall,f1_score)\n        else:\n            stats_text = \"\\n\\nAccuracy={:0.3f}\".format(accuracy)\n    else:\n        stats_text = \"\"\n\n\n    # SET FIGURE PARAMETERS ACCORDING TO OTHER ARGUMENTS\n    if figsize==None:\n        #Get default figure size if not set\n        figsize = plt.rcParams.get('figure.figsize')\n\n    if xyticks==False:\n        #Do not show categories if xyticks is False\n        categories=False\n\n\n    # MAKE THE HEATMAP VISUALIZATION\n    plt.figure(figsize=figsize)\n    sns.heatmap(cf,annot=box_labels,fmt=\"\",cmap=cmap,cbar=cbar,xticklabels=categories,yticklabels=categories)\n\n    if xyplotlabels:\n        plt.ylabel('True label')\n        plt.xlabel('Predicted label' + stats_text)\n    else:\n        plt.xlabel(stats_text)\n    \n    if title:\n        plt.title(title)","16d1e586":"from sklearn.metrics import confusion_matrix\ncf_matrix = confusion_matrix(y_test, yp)\nmake_confusion_matrix(cf_matrix, cmap='Blues', categories=labelnames)","bf29111a":"**Preprocessing**","8274d4b0":"| ![image.png](attachment:68c7e366-9d45-47ff-838c-0c1c38dc08cb.png) &nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;&nbsp;          |        <em><font size=5>Department of Modern Management and <br> Information Technology <\/font><\/em><br>  <font size=3>College of Arts, Media and Technology,<br> Chiang Mai University<br><\/font> Midterm Examination, Academic Year 2021 <br> Business Data Mining 954471\n|:- |-: \n|<strong>October 18th, 2021 8:00 - 23:59 <\/strong>| <strong>(Total 35 Points) <\/strong>\n\n<b>Name_________________Namphueng__Auawatcharo__________ Student ID_________622110186___________________________<\/b>\n\nInstructions: \n\n-\tThis exam is worth 35% of your final grade.\n-\tThis exam consists of 5 Questions\n-\tFinish this exam, download it as .ipynb file and send it to my FB messenger.\n-\tWrite your student ID as filename. \n-\tAllow anything.\n-\t<b>Please do this exam alone and be honest to yourself. <\/b>\n-\tThe time allowed students to leave the testing room after the exam is open to copy it.\n-\tStudents who cheat in any way will be prosecuted by the CMU regulation BE 2554, which governs student behavior and describes discipline during the exam period. The proctor must report any suspected cheating to the director.\n<br>\n\n### <em>Score Sheet:<\/em>\n|<font size=3> Question|<font size=3> Full Mark|<font size=3> Student\u2019s Mark|\n|:- |:-:|:-:\n<font size=3> Q1 |<font size=3> 5|\n<font size=3> Q2 |<font size=3> 5|\n<font size=3> Q3 |<font size=3> 5|\n<font size=3> Total|<font size=3> 15|\n\n\n\n\n\n\n","32fa3067":"# **Q2.**\n####  Create Model to predict the spam mail utilizing feature selection method. (Column 0 = Label)\n<b><font color=red>The difference of Train and Test accuracy must be lower than 10% to get full score.<\/font><\/b>","bed53fec":"# **Q3.**\n#### Create Deep Learning Model to predict the quality of wine. Our model will focus only on wine with quality of 5, 6, 7 (quality = label)\n<b><font color=red>The difference of Train and Test accuracy must be lower than 10% to get full score.<\/font><\/b>","c8295a45":"# **Q1**\n#### Create Model to predict the Telco customer churn (Churn = Label).\n<b><font color=red>The difference of Train and Test accuracy must be lower than 10% to get full score.<\/font><\/b>","942aeee6":"**Training**"}}