{"cell_type":{"c3e91b81":"code","855691d6":"code","138d58e5":"code","cdbd1e2e":"code","742a2071":"code","5052fe04":"code","3fef12bb":"code","af543f6e":"code","3471406e":"code","1a378a7e":"code","b9256c5f":"code","fba32b30":"code","f5ba3d7b":"code","9fefaafa":"code","303bc441":"code","89d7ea4e":"markdown","d95138ca":"markdown","498c7bab":"markdown","89791aeb":"markdown","84cdf77a":"markdown","9d023b30":"markdown","a2b9bf1d":"markdown","0876c3e8":"markdown","a7e57567":"markdown","519f391b":"markdown","513ce375":"markdown"},"source":{"c3e91b81":"! pip install --upgrade pip\n! pip install hvplot","855691d6":"import os\nimport operator\nimport functools\nimport itertools\nimport collections\nimport difflib\nfrom toolz.curried import *\n\nimport param\nimport pandas as pd\nimport geopandas as gpd\nimport numpy as np\nimport holoviews as hv\nimport geoviews as gv\nimport holoviews as hv\nimport hvplot.pandas\n\n\nhv.extension('bokeh')","138d58e5":"height = 275\nwidth = 576","cdbd1e2e":"# Import\nmultipleChoiceResponses = pd.read_csv(os.path.join('..','input','kaggle-survey-2018','multipleChoiceResponses.csv'), \n                                      skiprows=[1], \n                                      low_memory=False)\\\n                            .infer_objects() # Dataset\n\nSurveySchema = pd.read_csv(os.path.join('..','input','kaggle-survey-2018','SurveySchema.csv')) #Questions\nworld = gpd.read_file(gpd.datasets.get_path('naturalearth_lowres')) #Download map coordinates\n\nusIncome = pd.read_csv(os.path.join('..','input','us-income-data','Data USA - Bar Chart of Wage Distribution in the United States.csv'), \n                                      low_memory=False)\\\n                            .infer_objects() # Dataset","742a2071":"education_key = {'Master\u2019s degree':6,\n                'Bachelor\u2019s degree':4,\n                'Doctoral degree':10,\n                'Some college\/university study without earning a bachelor\u2019s degree':1,\n                'Professional degree':4,\n                'I prefer not to answer':np.nan,\n                'No formal education past high school':0}","5052fe04":"#Map\nuser_map =  world.merge(multipleChoiceResponses.loc[:,['Q3','Q4']]\\\n                                                    .assign(Q4 = lambda x: x.Q4.replace(education_key))\\\n                                                    .groupby('Q3').count()\\\n                                                    .reset_index()\\\n                                                    .rename(columns={'Q3':'Country', 'Q4':\"Users\"})\\\n                                                    .assign(Country= lambda x:  x.Country.apply(lambda y: difflib.get_close_matches(y, \n                                                                                                                                    world.name, \n                                                                                                                                    n=1, \n                                                                                                                                    cutoff=0.25)[0])), \n                                                            left_on='name', right_on='Country', how='left')\\\n                 .fillna(0)\\\n                 .replace('Antarctica', np.nan)\\\n                 .dropna()\\\n                 .pipe(partial(gv.Polygons, vdims=['Users','name']))\\\n                 .opts(height=int(round(height*1.25,0)), width=int(round(width*1,0)),\n                       cmap='Greys', logz=False,\n                       title= \"Number of Data Scientists\",\n                       colorbar=True, \n                       line_color='black',\n                       fontsize={'title': 16, 'labels': 14, 'xticks': 12, 'yticks': 12},\n                       xaxis=None, yaxis=None,\n                       line_width=1.5,\n                       padding=0.1,\n                       colorbar_position='right',\n                       colorbar_opts={'title':'Persons','title_text_baseline':'bottom'},\n                       tools=['hover'])\n\nuser_map","3fef12bb":"#Map\nincome_map =  world.merge(multipleChoiceResponses.loc[:,['Q3','Q9']]\\\n                                                    .assign(Q9 = lambda x: x.Q9\\\n                                                                            .astype(str)\\\n                                                                            .apply(lambda y: pd.to_numeric(''.join(y.split(\"-\")[0]), errors='coerse'))\\\n                                                                            .replace(0,np.nan))\\\n                                                    .groupby('Q3').median()\\\n                                                    .reset_index()\\\n                                                    .rename(columns={'Q3':'Country', 'Q9':\"Users\"})\\\n                                                    .assign(Country= lambda x:  x.Country.apply(lambda y: difflib.get_close_matches(y, \n                                                                                                                                    world.name, \n                                                                                                                                    n=1, \n                                                                                                                                    cutoff=0.25)[0])), \n                                                            left_on='name', right_on='Country', how='left')\\\n                 .fillna(0)\\\n                 .replace('Antarctica', np.nan)\\\n                 .dropna()\\\n                 .pipe(partial(gv.Polygons, vdims=['Users','name']))\\\n                 .opts(height=int(round(height*1.25,0)), width=int(round(width*1,0)),\n                       cmap='YlOrRd', logz=False,\n                       title= \"Median Income\",\n                       colorbar=True, \n                       line_color='black',\n                       fontsize={'title': 16, 'labels': 14, 'xticks': 12, 'yticks': 12},\n                       xaxis=None, yaxis=None,\n                       line_width=1.5,\n                       padding=0.1,\n                       colorbar_position='right',\n                       colorbar_opts={'title':'$1000','title_text_baseline':'bottom'},\n                       tools=['hover'])\n\nincome_map","af543f6e":"#Map\ncoding_map =  world.merge(multipleChoiceResponses.loc[:,['Q3','Q24']]\\\n                                                .assign(Q24 = lambda x: x.Q24\\\n                                                                        .astype(str)\\\n                                                                        .str.split('-| ')\\\n                                                                        .apply(lambda y: np.max([float(i) if i.isdigit() else 0 for i in y])))\\\n                                                    .replace(0,np.nan)\\\n                                                    .groupby('Q3').mean()\\\n                                                    .reset_index()\\\n                                                    .rename(columns={'Q3':'Country', 'Q24':\"Coding Experience\"})\\\n                                                    .assign(Country= lambda x:  x.Country.apply(lambda y: difflib.get_close_matches(y, \n                                                                                                                                    world.name, \n                                                                                                                                    n=1, \n                                                                                                                                    cutoff=0.25)[0])), \n                                                            left_on='name', right_on='Country', how='left')\\\n                 .fillna(0)\\\n                 .replace('Antarctica', np.nan)\\\n                 .dropna()\\\n                 .pipe(partial(gv.Polygons, vdims=['Coding Experience','name']))\\\n                 .opts(height=int(round(height*1.25,0)), width=int(round(width*1,0)),\n                       cmap='kgy', logz=True,\n                       title= \"Mean Years Coding Experience\",\n                       colorbar=True, \n                       line_color='black',\n                       fontsize={'title': 16, 'labels': 14, 'xticks': 12, 'yticks': 12},\n                       xaxis=None, yaxis=None,\n                       line_width=1.5,\n                       padding=0.1,\n                       colorbar_position='right',\n                       colorbar_opts={'title':'Years','title_text_baseline':'bottom'},\n                       tools=['hover'])\n\ncoding_map","3471406e":"#Map\neducation_map =  world.merge(multipleChoiceResponses.loc[:,['Q3','Q4']]\\\n                                                    .assign(Q4 = lambda x: x.Q4.replace(education_key))\\\n                                                    .groupby('Q3').mean()\\\n                                                    .reset_index()\\\n                                                    .rename(columns={'Q3':'Country', 'Q4':\"Users\"})\\\n                                                    .assign(Country= lambda x:  x.Country.apply(lambda y: difflib.get_close_matches(y, \n                                                                                                                                    world.name, \n                                                                                                                                    n=1, \n                                                                                                                                    cutoff=0.25)[0])), \n                                                            left_on='name', right_on='Country', how='left')\\\n                 .fillna(0)\\\n                 .replace('Antarctica', np.nan)\\\n                 .dropna()\\\n                 .pipe(partial(gv.Polygons, vdims=['Users','name']))\\\n                 .opts(height=int(round(height*1.25,0)), width=int(round(width*1,0)),\n                       cmap='YlGnBu', logz=False,\n                       title= \"Mean Years Education\",\n                       colorbar=True, \n                       line_color='black',\n                       fontsize={'title': 16, 'labels': 14, 'xticks': 12, 'yticks': 12},\n                       xaxis=None, yaxis=None,\n                       line_width=1.5,\n                       padding=0.1,\n                       colorbar_position='right',\n                       colorbar_opts={'title':'Years','title_text_baseline':'bottom'},\n                       tools=['hover'])\\\n                .redim.range(Users=(4, 6))\n\neducation_map","1a378a7e":"# Income Spread\nquantiles =     multipleChoiceResponses.loc[:,['Q4','Q9']]\\\n                                        .assign(Q9 = lambda x: x.Q9\\\n                                                                .astype(str)\\\n                                                                .str.split('-| ')\\\n                                                                .apply(lambda y: np.mean([i for i in \n                                                                                  [np.float(i) if i.isdigit() else 0 for i in y] if i>0])),\n                                                Q4 = lambda x: x.Q4.replace(education_key))\\\n                                        .dropna()\\\n                                        .groupby('Q4').Q9.agg({'0.25_l': partial(np.quantile, q=0.25), \n                                                               '0.1_l': partial(np.quantile, q=0.40), \n                                                               '0.01_l': partial(np.quantile, q=0.49),\n                                                               '0.01_u': partial(np.quantile, q=0.51),\n                                                               '0.1_u': partial(np.quantile, q=0.60), \n                                                               '0.25_u': partial(np.quantile, q=0.75),\n                                                              '0.01_m': partial(np.quantile, q=0.5), \n                                                              '0.1_m': partial(np.quantile, q=0.5), \n                                                              '0.25_m': partial(np.quantile, q=0.5),})\\\n                                        .reset_index()\\\n                                        .melt(id_vars='Q4').assign(quantile = lambda x: x.variable.str.split('_',  n=-1, expand=False).apply(lambda y: y[0]),\n                                                                    bound = lambda x: x.variable.str.split('_',  n=-1, expand=False).apply(lambda y: y[-1]))\\\n                                        .drop(columns=['variable'])\\\n                                        .pivot_table(index=['Q4','quantile'], columns='bound',values='value')\\\n                                        .reset_index()\\\n                                        .iloc[::-1,:]\\\n                                        .dropna()\\\n                                        .assign(l = lambda x: np.abs(x.l - x.m),\n                                                u = lambda x: np.abs(x.u - x.m),\n                                                quantile = lambda x: x.loc[:,'quantile']\\\n                                                                      .apply(lambda y: f'{pipe(y, float, partial(operator.mul, 100), partial(round,ndigits=0), int)}%'))\n\n\nlayout_ = quantiles.pipe(hv.Dataset)\\\n        .to(hv.Spread, kdims='Q4',vdims=['m','u','l'], group='quantile').overlay()\\\n        .redim.range(Q4=(0, 12), m=(0, 100))\\\n        .options({'Spread': dict(color=hv.Cycle(['#fbfdee','#419bdd','#01002B']), line_width=0)})\n\nreversed_ = pipe(layout_, \n                 collections.OrderedDict, \n                 lambda d: [d[n].relabel(n) for n in reversed(d.keys())], \n                 partial(reduce,operator.mul))\\\n            .opts(title='Incomes with Education', \n                  height=int(round(height*1.25,0)), width=int(round(width*1.5,0)),\n                  legend_position='right')\\\n            .redim.label(m='Income in $1000', Q4='Years Education')\n\nreversed_","b9256c5f":"regression_key={'Q1':'Female',\n                'Q2': 'Age (Yrs)',\n                'Q3':'Country',\n                'Q4': 'Education (Yrs)',\n                'Q4_2': 'Education_2',\n                'Q8': 'Work Experience (Yrs)',\n                'Q24': 'Coding Experience (Yrs)',\n                'Q46':'Time spent modelling',\n                'Q23':'Time spent coding',\n                'Q9': 'Income'}\n\neducation_key = {'Master\u2019s degree':6,\n                'Bachelor\u2019s degree':4,\n                'Doctoral degree':8,\n                'Some college\/university study without earning a bachelor\u2019s degree':2,\n                'Professional degree':4,\n                'I prefer not to answer':np.nan,\n                'No formal education past high school':0}\n\nc = multipleChoiceResponses.loc[:,['Q3','Q9']]\\\n                        .assign(Q9 = lambda x: x.Q9.astype(str)\\\n                                                    .str.split('-| ')\\\n                                                    .apply(lambda y: np.mean([i for i in \n                                                                      [np.float(i) if i.isdigit() else 0 for i in y] if i>10])))\ng = c.groupby('Q3').Q9.median()\ne = g.apply(lambda x: (x - g['United States of America'])\/g['United States of America']).add(1)\n\nregression_data = multipleChoiceResponses.loc[:,regression_key.keys()]\\\n                                        .assign(Q1 = lambda x: x.Q1.replace({'Female':1, 'Male':0, 'Prefer not to say':np.nan, 'Prefer to self-describe':np.nan}),\n                                                Q2 = lambda x: x.Q2.astype(str)\\\n                                                                    .str.split('-| ')\\\n                                                                    .apply(lambda y: np.mean([i for i in \n                                                                                      [np.float(i) if i.isdigit() else 0 for i in y] if i>0])),\n                                                Q4 = lambda x: x.Q4.replace(education_key),\n                                                Q8 = lambda x: x.Q8.astype(str)\\\n                                                                    .str.split('-| ')\\\n                                                                    .apply(lambda y: np.mean([i for i in \n                                                                                      [np.float(i) if i.isdigit() else 0 for i in y] if i>0])),\n                                                Q24 = lambda x: x.Q24.astype(str)\\\n                                                                        .str.split('-| ')\\\n                                                                        .apply(lambda y: np.mean([i for i in \n                                                                                          [np.float(i) if i.isdigit() else 0 for i in y] if i>0])),\n                                                Q46 = lambda x: x.Q46.astype(str)\\\n                                                                        .str.split('-| ')\\\n                                                                        .apply(lambda y: np.mean([i for i in \n                                                                                          [np.float(i) if i.isdigit() else 0 for i in y] if i>0])),\n                                                Q23= lambda x: x.Q23.astype(str)\\\n                                                                    .str.split('%')\\\n                                                                    .apply(lambda y: np.mean([i for i in \n                                                                                      [np.float(i) if i.isdigit() else 0 for i in y] if i>0])),\n                                                Q9 = lambda x: x.Q9.astype(str)\\\n                                                                    .str.split('-| ')\\\n                                                                    .apply(lambda y: np.mean([i for i in \n                                                                                      [np.float(i) if i.isdigit() else 0 for i in y] if i>0])))\\\n                                            .assign(Q9 = lambda x: x.apply(lambda y: y.Q9\/e[y.Q3], 1),\n                                                    Q4_2 = lambda x: x.Q4.pow(2))\n\nregression_data_drop = regression_data.fillna(regression_data.median(0))\nX_frame = regression_data_drop.drop(columns=['Q9','Q3','Q23','Q46']).assign(Constant = 1).astype(np.float)\nX = X_frame.values\ny = regression_data_drop.Q9.apply(np.log).astype(np.float).values\n\nweights = regression_data_drop.Q1.value_counts()#.reset_index(drop=True)\n\nweights = ((weights - np.max(weights))\/np.max(weights) + 1)\n\nW = np.diag(regression_data_drop.Q1.apply(lambda x: weights[x],0).astype(np.float).values)\n\nbeta = np.linalg.inv(X.T @ W @ X) @ X.T @ W @ y *100\n\npd.DataFrame(beta, \n             index=X_frame.columns,\n             columns=['Variables']).T\\\n.drop(columns=['Constant','Q4_2'])\\\n.rename(columns=regression_key)\\\n.hvplot.bar()\\\n.opts(cmap='Blues', \n      ylabel='% Percent increase in salary', title='Effect of Variables on Income',\n      bar_width=0.5,\n      height=int(round(height*1.25,0)), width=int(round(width*1,0)),)","fba32b30":"# Work Heatmap\nwork_heatmap =          multipleChoiceResponses.loc[:,['Q5','Q7']]\\\n                                                .replace({'I am a student':np.nan, # Filter ambiguouis categories\n                                                          'Other':np.nan,\n                                                          'I never declared a major':np.nan})\\\n                                                .dropna()\\\n                                                .assign(Q5=lambda x: x.Q5.apply(lambda y: ''.join(y.split('(')[0])))\\\n                                                .assign(Q5=lambda x: x.Q5.apply(lambda y: ''.join(y.split(',')[0])))\\\n                                                .assign(Q7=lambda x: x.Q7.apply(lambda y: ''.join(y.split('\/')[-1])))\\\n                                                .assign(Count=1)\\\n                                                .groupby(['Q5','Q7'])['Count'].sum()\\\n                                                .reset_index()\\\n                                                .sort_values('Count', ascending=False)\\\n                                                .hvplot.heatmap(x='Q7', y='Q5', C='Count')\\\n                                                .opts(width=int(round(width*1.25,0)),height=int(round(height*1.5,0)),\n                                                      xrotation=45,\n                                                      ylabel='Education',\n                                                      xlabel='Sector',\n                                                      title='Number of Data Science Professionals',\n                                                      cmap='YlOrRd',\n                                                      logz=True,\n                                                      fontsize={'title': 16, 'labels': 14, 'xticks': 10, 'yticks': 10},\n                                                      colorbar_opts={'title':'Number','title_text_baseline':'bottom'})\n\nwork_heatmap","f5ba3d7b":"# Distribution Plot\ndatascience_income = multipleChoiceResponses.Q9\\\n                        .astype(str)\\\n                        .apply(lambda x: pd.to_numeric(''.join(x.split(\"-\")[0]), errors='coerse'))\\\n                        .replace(0,np.nan)\\\n                        .dropna()\\\n                        .where(lambda x: x < 200,200)\\\n                        .hvplot.kde(label='All Data Scientists')\\\n                        .opts(xlabel='Income (USD) $1000',  \n                              fill_alpha=0, \n                              line_dash='dashed', line_width=5,\n                              bandwidth=0.35)\n\n# us_income = hv.VLine(56, label='US Median Income',).opts(color='black',\n#                                      line_width=3,\n#                                      fontsize={'title': 16, 'labels': 14, 'xticks': 12, 'yticks': 12},\n#                                      line_color='#ff5e00') *\\\n#                     hv.Text(70,0.006,'US Median Income', rotation=90, fontsize=12.5).opts(color='#ff5e00')\n\nus_income = usIncome.where(lambda x: x.year==2016).dropna()\\\n    .assign(num = lambda x: x.num_ppl_moe\/np.sum( x.num_ppl_moe))\\\n    .assign(wage = lambda x: x.wage_bin_name.str.extract('(\\d+)').astype(float))\\\n    .loc[:,['wage','num']]\\\n    .pipe(lambda x: x.sample(n=10000, replace=True, weights=x.num))\\\n    .hvplot.kde(y='wage', label='US Population')\\\n    .opts(bandwidth=0.25)\n\nincome_distribution = datascience_income * us_income\n\nincome_distribution.opts(title='Distribution of Data Science Incomes')","9fefaafa":"# Programming Language\nlanguage_data = multipleChoiceResponses.loc[:,['Q46','Q23', 'Q17', 'Q9']].dropna()\\\n                .assign(Q9 = lambda x: x.Q9.apply(lambda y: pd.to_numeric(''.join(y.split(\"-\")[0]), errors='coerse')))\\\n                .assign(Q46 = lambda x: x.Q46.apply(lambda y: pd.to_numeric(''.join(y.split(\"-\")[0]), errors='coerse')))\\\n                .assign(Q23 = lambda x: x.Q23.apply(lambda y: pd.to_numeric(''.join(y.split(\"%\")[0]), errors='coerse')))\\\n                .assign(Q17 = lambda x: x.Q17.apply(lambda y: ''.join(y.split(\"\/\")[0])))\\\n                .replace(['Ruby','PHP','SAS','Go'], \n                         [np.nan, np.nan, np.nan, np.nan])\\\n                .assign(Count=1)\\\n                .dropna()\\\n                .groupby('Q17').agg({'Q46':'mean',\n                                      'Q23':'mean', \n                                      'Q9':'median', \n                                      'Count': 'sum'})\\\n                .assign(Count=lambda x: x.Count.apply(np.sqrt).add(10))\\\n                .reset_index()\n\nlanguage_points=language_data.hvplot.scatter(y='Q46', x='Q23',\n                                    c='Q9', cmap='kgy', colorbar=True,\n                                    s='Count', marker= 'square')\\\n                                .opts(width=int(round(width*1.5,0)),height=int(round(height*1.5,0)),\n                                      padding=0.25,\n                                      line_color='white',\n                                      line_width=2.5,\n                                      fontsize={'title': 16, 'labels': 14, 'xticks': 12, 'yticks': 12},\n                                      colorbar_opts={'title':\"$1000\",'title_text_baseline':'bottom'},)\\\n                                .redim(Q23='% Time spent Coding \u2328', \n                                       Q46='% Time spent Modeling \ud83d\udcca')\n\nlanguage_labels=language_data.hvplot.labels(y='Q46', x='Q23', text='Q17')\\\n                                .opts(yoffset=4, text_color='#ff5e00')\n\nsize_data =     language_data.loc[:,['Count', 'Q23', 'Q46']]\\\n                .assign(Size = lambda x: x.Count.subtract(10).pow(2))\\\n                .describe()\\\n                .drop(index=['count', 'mean','std'])\\\n                .assign(Q46=lambda x: x.Q46.mean())\\\n                .assign(Q23 = pipe(range(10,60, 10), list))\n\nsize_points =   size_data.hvplot.scatter(x='Q46', y='Q23', \n                                c='grey',\n                                s='Count', marker= 'square')\\\n                .opts(padding=0.1, yaxis=None, xaxis=None,\n                      height=int(round(height*1.5,0)),width=int(round(width*0.15,0)))\n\nsize_labels =   size_data\\\n                .assign(Size = lambda x: x.Size\\\n                                            .pipe(partial(round, ndigits=0))\\\n                                            .astype(int))\\\n                .hvplot.labels(x='Q46', y='Q23', \n                                 text='Size', title='Users')\\\n                .opts(padding=0.1, yoffset=2.5,\n                      yaxis=None, xaxis=None)\n\nprogramming_plot = (language_points*language_labels + size_points * size_labels)\\\n                    .opts(title='Programming Languages')\\\n                    .cols(2)\n\nprogramming_plot","303bc441":"functions =    {'Q11_Part_2': 'Modelling',#'Build and\/or run a machine learning',\n                 'Q11_Part_3': 'Infrasturcture',#'Build and\/or run the data infrastructure',\n                 'Q11_Part_4': 'Analytics',#'Build prototypes to explore applying machine',\n                 'Q11_Part_5': 'Research'}#'Do research that advances the state of the art methods'}\n\nfunction_bar = multipleChoiceResponses.loc[:,functions.keys()]\\\n                .rename(columns=functions)\\\n                .count(0)\\\n                .sort_values()\\\n                .reset_index()\\\n                .rename(columns={0:'Number of Data Scientists'})\\\n                .hvplot.bar(c='Number of Data Scientists')\\\n                .opts(width=int(round(width*1.5,0)),height=int(round(height*1,0)),\n                      title='Data Science Function in the Business', \n                      xlabel='',\n                      bar_width=0.5,\n                      padding=0.5,\n                      fontsize={'title': 16, 'labels': 14, 'xticks': 12, 'yticks': 12},\n                      invert_axes=True, cmap='YlOrRd')\nfunction_bar","89d7ea4e":"What we aimed to explore in this graph, was not only income of users with years of education, but also the distribution of income and the years of education increased.  Based on this graph it appears that not only does income appear correlated with education, but also the variance in that income appears to decrease as persons become more educated.  ","d95138ca":"Similar to these findings, users on the platform in the USA appear to be the most educated- many with Masters Degrees and PHD's.  European users are also highly educated with the average years of educations reaching as many as 6 years.  ","498c7bab":"What is really fascinating about this survey is the ammount of experience persons on the platform have.  While the income of users in USD is by no means a complete picture of persons Purchasing Parity accross countries, it does appear that income and experience is highly correlated, when comparing the experience and income of users in the USA and Australia.  ","89791aeb":"Thanks so much for giving this kernel a review. Would love thoughts and comments. Would be super interesting to see what other people have done and how these results change over time.  ","84cdf77a":"While the regression model used in this bar chart is by no means the only or most comprehensive sudy design, it does provide some shocking indication of a possible gap in pay between male and female users.  This is worsened by the fact that the survey seems to feature a disproportionate number of males.  ","9d023b30":"Based on the responses from the survey, users on the platform appear concentrated with backgrounds in Computer Science in the Technology industry. This is not super suprises, but may be an interesting result to track in future surbeys to track the adoption of roles in the data sciences in other industries.  ","a2b9bf1d":"While income in USD is by no means a complete picture of the Purchasing Power of persons in those countries, it appears users in the USA and Australia are the highest earners on the platform.  ","0876c3e8":"In this plot we did some kernel density estimation to compare the distribution of user incomes to those in the broader US population.  Based on the survey, it may have been better to filter US respondants in making this comparison.  One challenge with this dataset is many users are students, who have declared to income.  ","a7e57567":"The aim of this kernel is to uncover the key drivers of data science income around the world.  While the Kaggle Annual Users survey is by no means a complete and representational platform given its popularity and accessiblity around the world- it does give some amazing insight on the industry and the people who comprise it.  ","519f391b":"I thought this was an interesting plot, to identify what languages are popular or favour different kinds of work.  It appears Julia programmers love modelling, Scaler programmers love coding and popular languages like R and Python are nice in-betweens.  ","513ce375":"Based on the survery, a vast majority of Kaggle users appear concentrated in the USA and India, with strong support Chine and parts of Europe.  "}}