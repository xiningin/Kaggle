{"cell_type":{"1d271d61":"code","908e4d48":"code","c16b3ccf":"code","10d9d969":"code","704e842d":"code","d161e7e5":"code","05f06347":"code","bfce4d62":"code","28097366":"code","c2b253ea":"code","e789b9d7":"code","dea841d7":"code","b547ecfb":"code","4985d884":"code","2ac762fa":"code","09de3ba9":"code","e4e61b4c":"code","ecfa9578":"code","fd533e81":"code","40de92a5":"code","dfb1878e":"code","6e3b5bd2":"code","b1e51d96":"code","bfba33ea":"code","1cc156b2":"code","0a0dde4d":"code","6072efe1":"code","59f310e7":"code","eb2e78f5":"code","1f111886":"code","977ede0c":"code","89c072a3":"code","dc1e560b":"code","e730d06d":"code","5e35cba3":"code","4f4d61a3":"code","26e221de":"code","00d6f299":"code","3f74e870":"code","d246ff85":"code","7f19a5b0":"code","cdc35d19":"code","0d5bbeea":"code","0bde7234":"code","287748d4":"code","e82b5d08":"code","e23db3c3":"code","24bf2958":"code","d8670668":"code","cc65eed7":"code","eca4332a":"code","0039cb65":"code","dd103e29":"code","9f1e5f67":"code","8f60f5ab":"code","08fa65ab":"code","5d98c3df":"code","7d57e09e":"code","247a9d2a":"code","beaa81c3":"code","2fff2638":"code","301b08ef":"code","82fa1f43":"code","32b7b4fd":"code","6db1e2b9":"code","6555edde":"code","45b2e29e":"code","1c7cc37b":"code","61137ff2":"code","4a6bb567":"code","9d68a340":"code","05bde16a":"code","09eee5df":"code","020eae64":"code","8cf38da8":"code","4611abb8":"code","3b37385d":"code","134122ab":"code","f9a65095":"code","396026bc":"code","0814c93f":"code","aeaaaa75":"code","98a248c2":"code","dee8e7ff":"code","2a1ed135":"code","71a9e9d8":"code","cca8dfd7":"code","36f80110":"code","615d6424":"code","a7e4d4b2":"code","ff101c75":"code","af375679":"code","e3350ea9":"code","4a76bbe3":"code","fc19424a":"code","d9fa1bb2":"code","451a18f6":"code","c7c52c8a":"code","abc65184":"code","20431345":"code","343c3992":"code","ac6d3aad":"code","b8adc19d":"code","e1f367b6":"code","529a0bfe":"code","63083609":"code","c57b469d":"code","c524840d":"code","d474c5bf":"code","e7322970":"code","58fd96e5":"code","f436e676":"code","65c09441":"code","db1e98d1":"code","492a181e":"code","f721137d":"code","ef3adc17":"code","2c1af6ca":"code","88b2079d":"code","33f1f7c1":"code","df526485":"code","17eb049c":"code","5fc31f0e":"code","52e1f87f":"code","1a0ffaf8":"code","e1100ddc":"code","4b8e48fc":"code","1fc2f22d":"code","b80f9bb9":"code","7712f6a5":"code","5edb249a":"code","b38420f3":"code","9cf7da9e":"code","7675357f":"code","d6352112":"code","7c2e06ed":"code","987929eb":"code","b28bdc28":"code","5a3c05f8":"code","c4075fac":"code","7960f34d":"code","be220caa":"code","9e2edba3":"code","ac78cd6a":"code","ed30e67a":"code","7ab54dbc":"code","debf466a":"code","e6eadec3":"code","bab781ae":"code","e2f45a6e":"code","1f5ef31a":"code","83b1b557":"code","6d46a38c":"code","db8b654c":"code","f06496fa":"code","4e01b912":"code","84063a86":"code","3b393e7e":"code","d341c389":"code","d55e7d0e":"code","22f647fd":"code","492fcb7e":"code","0933e21f":"code","952a8691":"code","feba4cbf":"code","44f75dbd":"code","9b4af320":"code","86dd6ff2":"code","dcba142a":"code","e525a6bb":"code","1e5404ac":"code","6f2bf3a0":"code","934260c5":"code","862482e1":"code","41972bdf":"code","591cf814":"code","e5cbdb62":"code","9466ca18":"code","9cedbe26":"code","06da5450":"code","6e17e137":"code","664f18a4":"code","63a6c86f":"code","b6cb7a71":"code","b25b3d30":"code","a0d67fb8":"markdown","c545cc97":"markdown","80b2cdca":"markdown","8d072d3e":"markdown","60c73069":"markdown","934461f0":"markdown","a9ad08c6":"markdown","d397e08c":"markdown","3912a7cc":"markdown","85ef620c":"markdown","ad1c45e7":"markdown","ee8397eb":"markdown","b83c8012":"markdown","cf38f32f":"markdown","849eb3fe":"markdown","bccebac1":"markdown","ecc681d8":"markdown","2dfe6827":"markdown","0013fc53":"markdown","02c63525":"markdown","81912f6a":"markdown","c3fb0f78":"markdown","e1ce280f":"markdown","590f867f":"markdown","201b4042":"markdown","7ca1973a":"markdown","af538afc":"markdown","d629de3a":"markdown","81d5ebe8":"markdown","21aa9256":"markdown","2c60321e":"markdown","d7cbb0bc":"markdown","f0d24bd7":"markdown","1d15a90b":"markdown","19439d2e":"markdown","acaa3431":"markdown","9c4cd42c":"markdown","b0c46dae":"markdown","77fd5bc8":"markdown","8b2c6a61":"markdown","5e697739":"markdown","4edc8091":"markdown","d7c5d314":"markdown","ebc93e00":"markdown","71a338c1":"markdown","c8a44bd7":"markdown","7399311f":"markdown","51b209a5":"markdown","ad8e3bb8":"markdown","645d7f98":"markdown","c56c6b6b":"markdown","a8b75e26":"markdown","514dfa7c":"markdown","aec0873e":"markdown","13983738":"markdown","560d038d":"markdown"},"source":{"1d271d61":"import warnings\nwarnings.filterwarnings('ignore')\n\nimport math, datetime\n\nimport numpy as np \nimport pandas as pd\npd.set_option('display.max_columns', None)\n\nimport seaborn as sns\nfrom matplotlib import pyplot as plt\n%matplotlib inline\n\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression\nfrom sklearn.metrics import accuracy_score, r2_score, mean_squared_error, mean_absolute_error\nfrom sklearn.preprocessing import LabelEncoder, OneHotEncoder\nfrom sklearn.model_selection import GridSearchCV","908e4d48":"train = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/train.csv')\ntest = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/test.csv')","c16b3ccf":"train.tail()","10d9d969":"print('train shape',train.shape)\nprint('test shape',test.shape)\nprint('duplicated rows',train.duplicated().sum())\nprint('train -> number of columns with missing values',train.isnull().any().sum())\nprint('test -> number of columns with missing values',test.isnull().any().sum())","704e842d":"df = pd.concat([train.drop('SalePrice', axis=1), test]).reset_index(drop=True)\ny = train['SalePrice']\ndf.shape","d161e7e5":"import seaborn as sns\nplt.figure(figsize=(12,6))\nsns.heatmap(data=df.isnull(),cmap=\"viridis\")\nplt.show()","05f06347":"df.isnull().sum().sort_values(ascending=False).head(10)","bfce4d62":"df_null = df.isnull().sum()\nnull_cols = df_null[df_null>1000].index.tolist()\ndf = df.drop(null_cols, axis=1)\ndf.shape","28097366":"nan_values = pd.DataFrame(df.isnull().sum().sort_values(ascending=False))\nnan_values = nan_values[nan_values.iloc[:,0]>0]\n\nfig, ax = plt.subplots(figsize = (16, 6))\nmy_cmap = plt.get_cmap(\"RdBu\")\nax.bar(nan_values.index, nan_values.iloc[:,0], color=my_cmap(nan_values.iloc[:,0]))\nplt.xticks(rotation=30)\nplt.show()","c2b253ea":"df['MSZoning'].value_counts(dropna=False).head()","e789b9d7":"# getting the missing values\nnan_index = df[df['MSZoning'].isnull()]['MSZoning'].index\n\n# fill the NaN values\ndf.loc[nan_index,'MSZoning'] = 'RL'","dea841d7":"# encode as numerical values\ndf['MSZoning'] = LabelEncoder().fit_transform(df['MSZoning'])","b547ecfb":"df['Utilities'].value_counts(dropna=False).head()","4985d884":"# getting the missing values\nnan_index = df[df['Utilities'].isnull()]['Utilities'].index\n\n# fill the NaN values\ndf.loc[nan_index,'Utilities'] = 'AllPub'","2ac762fa":"# encode as numerical values\ndf['Utilities'] = LabelEncoder().fit_transform(df['Utilities'])","09de3ba9":"df['Exterior1st'].value_counts(dropna=False).head()","e4e61b4c":"# getting the missing values\nnan_index = df[df['Exterior1st'].isnull()]['Exterior1st'].index\n\n# fill the NaN values\ndf.loc[nan_index,'Exterior1st'] = 'VinylSd'","ecfa9578":"df['Exterior2nd'].value_counts(dropna=False).head()","fd533e81":"# getting the missing values\nnan_index = df[df['Exterior2nd'].isnull()]['Exterior2nd'].index\n\n# fill the NaN values\ndf.loc[nan_index,'Exterior2nd'] = 'VinylSd'","40de92a5":"# encode as numerical values\ndf['Exterior1st'] = LabelEncoder().fit_transform(df['Exterior1st'])\ndf['Exterior2nd'] = LabelEncoder().fit_transform(df['Exterior2nd'])","dfb1878e":"df['BsmtFinSF1'].value_counts(dropna=False).head()","6e3b5bd2":"# getting the missing values\nnan_index = df[df['BsmtFinSF1'].isnull()]['BsmtFinSF1'].index\nprint(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'BsmtFinSF1'] = 0.0","b1e51d96":"df['BsmtFinSF2'].value_counts(dropna=False).head()","bfba33ea":"# getting the missing values\nnan_index = df[df['BsmtFinSF2'].isnull()]['BsmtFinSF2'].index\nprint(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'BsmtFinSF2'] = 0.0","1cc156b2":"df['BsmtUnfSF'].value_counts(dropna=False).head()","0a0dde4d":"# getting the missing values\nnan_index = df[df['BsmtUnfSF'].isnull()]['BsmtUnfSF'].index\nprint(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'BsmtUnfSF'] = df['BsmtUnfSF'].median()","6072efe1":"df['Electrical'].value_counts(dropna=False).head()","59f310e7":"# getting the missing values\nnan_index = df[df['Electrical'].isnull()]['Electrical'].index\nprint(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'Electrical'] = 'SBrkr'","eb2e78f5":"# encode as numerical values\ndf['Electrical'] = LabelEncoder().fit_transform(df['Electrical'])","1f111886":"df['KitchenQual'].value_counts(dropna=False).head()","977ede0c":"# getting the missing values\nnan_index = df[df['KitchenQual'].isnull()]['KitchenQual'].index\nprint(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'KitchenQual'] = 'TA'","89c072a3":"# encode as numerical values\ndf['KitchenQual'] = LabelEncoder().fit_transform(df['KitchenQual'])","dc1e560b":"df['GarageCars'].value_counts(dropna=False).head()","e730d06d":"# getting the index of the missing values\nnan_index = df[df['GarageCars'].isnull()]['GarageCars'].index\n# print(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'GarageCars'] = 2.0","5e35cba3":"df['GarageArea'].value_counts(dropna=False).head()","4f4d61a3":"# getting the index of the missing values\nnan_index = df[df['GarageArea'].isnull()]['GarageArea'].index\nprint(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'GarageArea'] = df['GarageArea'].median()","26e221de":"df['SaleType'].value_counts(dropna=False).head()","00d6f299":"# getting the index of the missing values\nnan_index = df[df['SaleType'].isnull()]['SaleType'].index\nprint(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'SaleType'] = 'WD'","3f74e870":"# encode as numerical values\ndf['SaleType'] = LabelEncoder().fit_transform(df['SaleType'])","d246ff85":"df['BsmtHalfBath'].value_counts(dropna=False).head()","7f19a5b0":"# getting the missing values\nnan_index = df[df['BsmtHalfBath'].isnull()]['BsmtHalfBath'].index\nprint(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'BsmtHalfBath'] = 0.0","cdc35d19":"df['Functional'].value_counts(dropna=False).head()","0d5bbeea":"# getting the missing values\nnan_index = df[df['Functional'].isnull()]['Functional'].index\n\n# fill the NaN values\ndf.loc[nan_index,'Functional'] = 'Typ'","0bde7234":"# encode as numerical values\ndf['Functional'] = LabelEncoder().fit_transform(df['Functional'])","287748d4":"df['TotalBsmtSF'].value_counts(dropna=False).head()","e82b5d08":"# getting the missing values\nnan_index = df[df['TotalBsmtSF'].isnull()]['TotalBsmtSF'].index\n# print(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index,'TotalBsmtSF'] = df['TotalBsmtSF'].median()","e23db3c3":"df['BsmtFullBath'].value_counts(dropna=False).head()","24bf2958":"# getting the missing values\nnan_index = df[df['BsmtFullBath'].isnull()]['BsmtFullBath'].index\n# print(nan_index)\n\n# fill the NaN values\ndf.loc[nan_index[0],'BsmtFullBath'] = 0.0\ndf.loc[nan_index[1],'BsmtFullBath'] = 1.0","d8670668":"df['MasVnrArea'].value_counts(dropna=False).head()","cc65eed7":"# getting the missing values\nnan_index = df[df['MasVnrArea'].isnull()]['MasVnrArea'].index\n\n# fill the NaN values\ndf.loc[nan_index,'MasVnrArea'] = 0.0","eca4332a":"df['BsmtCond'].value_counts(dropna=False).head()","0039cb65":"# getting the missing values\nnan_index = df[df['BsmtCond'].isnull()]['BsmtCond'].index\n\n# fill the NaN values\ndf.loc[nan_index,'BsmtCond'] = 'TA'","dd103e29":"# encode as numerical values\ndf['BsmtCond'] = LabelEncoder().fit_transform(df['BsmtCond'])","9f1e5f67":"df['BsmtFinType2'].value_counts(dropna=False).head()","8f60f5ab":"# getting the missing values\nnan_index = df[df['BsmtFinType2'].isnull()]['BsmtFinType2'].index\n\n# fill the NaN values\ndf.loc[nan_index,'BsmtFinType2'] = 'Unf'","08fa65ab":"# encode as numerical values\ndf['BsmtFinType2'] = LabelEncoder().fit_transform(df['BsmtFinType2'])","5d98c3df":"df['GarageQual'].value_counts(dropna=False).head()","7d57e09e":"# getting the missing values\nnan_index = df[df['GarageQual'].isnull()]['GarageQual'].index\n\n# fill the NaN values\ndf.loc[nan_index,'GarageQual'] = 'TA'","247a9d2a":"# encode as numerical values\ndf['GarageQual'] = LabelEncoder().fit_transform(df['GarageQual'])","beaa81c3":"df['GarageCond'].value_counts(dropna=False).head()","2fff2638":"# getting the missing values\nnan_index = df[df['GarageCond'].isnull()]['GarageCond'].index\n\n# fill the NaN values\ndf.loc[nan_index,'GarageCond'] = 'TA'","301b08ef":"# encode as numerical values\ndf['GarageCond'] = LabelEncoder().fit_transform(df['GarageCond'])","82fa1f43":"# Encoding values except null ones\nseries = df['MasVnrType']\nlabel_encoder = LabelEncoder()\ndf['MasVnrType'] = pd.Series(\n    label_encoder.fit_transform(series[series.notnull()]),\n    index=series[series.notnull()].index\n)","32b7b4fd":"df['MasVnrType'].value_counts(dropna=False).head()","6db1e2b9":"# Features with null values\ndf_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'MasVnrType']\n\n# df without null values\ndf_with = df[df['MasVnrType'].notnull()]\n# df with null values\ndf_without = df[df['MasVnrType'].isnull()]\n\n# Drop features that will not be used for predicting null values\ndf_with.drop(null_cols, axis=1, inplace=True)\ndf_without.drop(null_cols, axis=1, inplace=True)","6555edde":"# categorical columns in the dataframe\ncategorical_columns = list(set(df_with.columns) - set(df_with._get_numeric_data().columns))\n\n# encode as numerical values\nfor col in categorical_columns:\n    if col != 'MasVnrType':\n        df_with[col] = LabelEncoder().fit_transform(df_with[col])\n        df_without[col] = LabelEncoder().fit_transform(df_without[col])","45b2e29e":"# Nan values were predicted based on independent variables using Random Forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_with = df_with.drop(['MasVnrType'], axis=1)\ny_with = df_with['MasVnrType']\nX_without = df_without.drop(['MasVnrType'], axis=1)\nX_with.head()\n\nrfModel = RandomForestClassifier()\nrfModel.fit(X_with, y_with)\n\ngeneratedValues = rfModel.predict(X = X_without)\nnp.round(generatedValues, 0)[:10]","1c7cc37b":"# replace null values with predicted ones\nind = df[df['MasVnrType'].isnull()]['MasVnrType'].index\ndf.loc[ind,'MasVnrType'] = np.round(generatedValues, 0)","61137ff2":"df['MasVnrType'].value_counts(dropna=False)","4a6bb567":"# Encoding values except null ones\nseries = df['BsmtQual']\nlabel_encoder = LabelEncoder()\ndf['BsmtQual'] = pd.Series(\n    label_encoder.fit_transform(series[series.notnull()]),\n    index=series[series.notnull()].index\n)","9d68a340":"df['BsmtQual'].value_counts(dropna=False)","05bde16a":"# Features with null values\ndf_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'BsmtQual']\n\n# df without null values\ndf_with = df[df['BsmtQual'].notnull()]\n# df with null values\ndf_without = df[df['BsmtQual'].isnull()]\n\n# Drop features that will not be used for predicting null values\ndf_with.drop(null_cols, axis=1, inplace=True)\ndf_without.drop(null_cols, axis=1, inplace=True)","09eee5df":"# categorical columns in the dataframe\ncategorical_columns = list(set(df_with.columns) - set(df_with._get_numeric_data().columns))\n\n# encode as numerical values\nfor col in categorical_columns:\n    if col != 'BsmtQual':\n        df_with[col] = LabelEncoder().fit_transform(df_with[col])\n        df_without[col] = LabelEncoder().fit_transform(df_without[col])","020eae64":"# Nan values were predicted based on independent variables using Random Forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_with = df_with.drop(['BsmtQual'], axis=1)\ny_with = df_with['BsmtQual']\nX_without = df_without.drop(['BsmtQual'], axis=1)\nX_with.head()\n\nrfModel = RandomForestClassifier()\nrfModel.fit(X_with, y_with)\n\ngeneratedValues = rfModel.predict(X = X_without)\nnp.round(generatedValues, 0)[:10]","8cf38da8":"# replace null values with predicted ones\nind = df[df['BsmtQual'].isnull()]['BsmtQual'].index\ndf.loc[ind,'BsmtQual'] = np.round(generatedValues, 0)","4611abb8":"df['BsmtQual'].value_counts(dropna=False)","3b37385d":"# Encoding values except null ones\nseries = df['BsmtExposure']\nlabel_encoder = LabelEncoder()\ndf['BsmtExposure'] = pd.Series(\n    label_encoder.fit_transform(series[series.notnull()]),\n    index=series[series.notnull()].index\n)","134122ab":"df['BsmtExposure'].value_counts(dropna=False)","f9a65095":"# Features with null values\ndf_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'BsmtExposure']\n\n# df without null values\ndf_with = df[df['BsmtExposure'].notnull()]\n# df with null values\ndf_without = df[df['BsmtExposure'].isnull()]\n\n# Drop features that will not be used for predicting null values\ndf_with.drop(null_cols, axis=1, inplace=True)\ndf_without.drop(null_cols, axis=1, inplace=True)","396026bc":"# categorical columns in the dataframe\ncategorical_columns = list(set(df_with.columns) - set(df_with._get_numeric_data().columns))\n\n# encode as numerical values\nfor col in categorical_columns:\n    if col != 'BsmtExposure':\n        df_with[col] = LabelEncoder().fit_transform(df_with[col])\n        df_without[col] = LabelEncoder().fit_transform(df_without[col])","0814c93f":"# Nan values were predicted based on independent variables using Random Forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_with = df_with.drop(['BsmtExposure'], axis=1)\ny_with = df_with['BsmtExposure']\nX_without = df_without.drop(['BsmtExposure'], axis=1)\nX_with.head()\n\nrfModel = RandomForestClassifier()\nrfModel.fit(X_with, y_with)\n\ngeneratedValues = rfModel.predict(X = X_without)\nnp.round(generatedValues, 0)[:10]","aeaaaa75":"# replace null values with predicted ones\nind = df[df['BsmtExposure'].isnull()]['BsmtExposure'].index\ndf.loc[ind,'BsmtExposure'] = np.round(generatedValues, 0)","98a248c2":"df['BsmtExposure'].value_counts(dropna=False)","dee8e7ff":"# Encoding values except null ones\nseries = df['BsmtFinType1']\nlabel_encoder = LabelEncoder()\ndf['BsmtFinType1'] = pd.Series(\n    label_encoder.fit_transform(series[series.notnull()]),\n    index=series[series.notnull()].index\n)","2a1ed135":"df['BsmtFinType1'].value_counts(dropna=False)","71a9e9d8":"# Features with null values\ndf_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'BsmtFinType1']\n\n# df without null values\ndf_with = df[df['BsmtFinType1'].notnull()]\n# df with null values\ndf_without = df[df['BsmtFinType1'].isnull()]\n\n# Drop features that will not be used for predicting null values\ndf_with.drop(null_cols, axis=1, inplace=True)\ndf_without.drop(null_cols, axis=1, inplace=True)","cca8dfd7":"# categorical columns in the dataframe\ncategorical_columns = list(set(df_with.columns) - set(df_with._get_numeric_data().columns))\n\n# encode as numerical values\nfor col in categorical_columns:\n    if col != 'BsmtFinType1':\n        df_with[col] = LabelEncoder().fit_transform(df_with[col])\n        df_without[col] = LabelEncoder().fit_transform(df_without[col])","36f80110":"# Nan values were predicted based on independent variables using Random Forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_with = df_with.drop(['BsmtFinType1'], axis=1)\ny_with = df_with['BsmtFinType1']\nX_without = df_without.drop(['BsmtFinType1'], axis=1)\nX_with.head()\n\nrfModel = RandomForestClassifier()\nrfModel.fit(X_with, y_with)\n\ngeneratedValues = rfModel.predict(X = X_without)\nnp.round(generatedValues, 0)[:10]","615d6424":"# replace null values with predicted ones\nind = df[df['BsmtFinType1'].isnull()]['BsmtFinType1'].index\ndf.loc[ind,'BsmtFinType1'] = np.round(generatedValues, 0)","a7e4d4b2":"df['BsmtFinType1'].value_counts(dropna=False)","ff101c75":"# Encoding values except null ones\nseries = df['GarageType']\nlabel_encoder = LabelEncoder()\ndf['GarageType'] = pd.Series(\n    label_encoder.fit_transform(series[series.notnull()]),\n    index=series[series.notnull()].index\n)","af375679":"df['GarageType'].value_counts(dropna=False)","e3350ea9":"# Features with null values\ndf_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'GarageType']\n\n# df without null values\ndf_with = df[df['GarageType'].notnull()]\n# df with null values\ndf_without = df[df['GarageType'].isnull()]\n\n# Drop features that will not be used for predicting null values\ndf_with.drop(null_cols, axis=1, inplace=True)\ndf_without.drop(null_cols, axis=1, inplace=True)","4a76bbe3":"# categorical columns in the dataframe\ncategorical_columns = list(set(df_with.columns) - set(df_with._get_numeric_data().columns))\n\n# encode as numerical values\nfor col in categorical_columns:\n    if col != 'GarageType':\n        df_with[col] = LabelEncoder().fit_transform(df_with[col])\n        df_without[col] = LabelEncoder().fit_transform(df_without[col])","fc19424a":"# Nan values were predicted based on independent variables using Random Forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_with = df_with.drop(['GarageType'], axis=1)\ny_with = df_with['GarageType']\nX_without = df_without.drop(['GarageType'], axis=1)\nX_with.head()\n\nrfModel = RandomForestClassifier()\nrfModel.fit(X_with, y_with)\n\ngeneratedValues = rfModel.predict(X = X_without)\nnp.round(generatedValues, 0)[:10]","d9fa1bb2":"# replace null values with predicted ones\nind = df[df['GarageType'].isnull()]['GarageType'].index\ndf.loc[ind,'GarageType'] = np.round(generatedValues, 0)","451a18f6":"df['GarageType'].value_counts(dropna=False)","c7c52c8a":"df['GarageYrBlt'].value_counts(dropna=False).head()","abc65184":"# Features with null values\ndf_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'GarageYrBlt']\n\n# df without null values\ndf_with = df[df['GarageYrBlt'].notnull()]\n# df with null values\ndf_without = df[df['GarageYrBlt'].isnull()]\n\n# Drop features that will not be used for predicting null values\ndf_with.drop(null_cols, axis=1, inplace=True)\ndf_without.drop(null_cols, axis=1, inplace=True)","20431345":"# categorical columns in the dataframe\ncategorical_columns = list(set(df_with.columns) - set(df_with._get_numeric_data().columns))\n\n# encode as numerical values\nfor col in categorical_columns:\n    if col != 'GarageYrBlt':\n        df_with[col] = LabelEncoder().fit_transform(df_with[col])\n        df_without[col] = LabelEncoder().fit_transform(df_without[col])","343c3992":"# Nan values were predicted based on independent variables using Random Forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_with = df_with.drop(['GarageYrBlt'], axis=1)\ny_with = df_with['GarageYrBlt']\nX_without = df_without.drop(['GarageYrBlt'], axis=1)\nX_with.head()\n\nrfModel = RandomForestClassifier()\nrfModel.fit(X_with, y_with)\n\ngeneratedValues = rfModel.predict(X = X_without)\nnp.round(generatedValues, 0)[:10]","ac6d3aad":"# replace null values with predicted ones\nind = df[df['GarageYrBlt'].isnull()]['GarageYrBlt'].index\ndf.loc[ind,'GarageYrBlt'] = np.round(generatedValues, 0)","b8adc19d":"df['GarageYrBlt'].value_counts(dropna=False).head()","e1f367b6":"# Encoding values except null ones\nseries = df['GarageFinish']\nlabel_encoder = LabelEncoder()\ndf['GarageFinish'] = pd.Series(\n    label_encoder.fit_transform(series[series.notnull()]),\n    index=series[series.notnull()].index\n)","529a0bfe":"df['GarageFinish'].value_counts(dropna=False)","63083609":"# Features with null valuesdf_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'GarageFinish']\n\n# df without null values\ndf_with = df[df['GarageFinish'].notnull()]\ndf_without = df[df['GarageFinish'].isnull()]\n\n# Drop features that will not be used for predicting null values\ndf_with.drop(null_cols, axis=1, inplace=True)\ndf_without.drop(null_cols, axis=1, inplace=True)","c57b469d":"# categorical columns in the dataframe\ncategorical_columns = list(set(df_with.columns) - set(df_with._get_numeric_data().columns))\n\n# encode as numerical values\nfor col in categorical_columns:\n    if col != 'GarageFinish':\n        df_with[col] = LabelEncoder().fit_transform(df_with[col])\n        df_without[col] = LabelEncoder().fit_transform(df_without[col])","c524840d":"# Nan values were predicted based on independent variables using Random Forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_with = df_with.drop(['GarageFinish'], axis=1)\ny_with = df_with['GarageFinish']\nX_without = df_without.drop(['GarageFinish'], axis=1)\nX_with.head()\n\nrfModel = RandomForestClassifier()\nrfModel.fit(X_with, y_with)\n\ngeneratedValues = rfModel.predict(X = X_without)\nnp.round(generatedValues, 0)[:10]","d474c5bf":"# replace null values with predicted ones\nind = df[df['GarageFinish'].isnull()]['GarageFinish'].index\ndf.loc[ind,'GarageFinish'] = np.round(generatedValues, 0)","e7322970":"df['GarageFinish'].value_counts(dropna=False)","58fd96e5":"df['LotFrontage'].value_counts(dropna=False).head()","f436e676":"df_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'LotFrontage']\nnull_cols","65c09441":"# Features with null valuesdf_null = df.isnull().sum()\ndf_null = df.isnull().sum()\nnull_cols = [i for i in df_null[df_null>0].index if i != 'LotFrontage']\n\n# df without null values\ndf_with = df[df['LotFrontage'].notnull()]\ndf_without = df[df['LotFrontage'].isnull()]\n\n# Drop features that will not be used for predicting null values\ndf_with.drop(null_cols, axis=1, inplace=True)\ndf_without.drop(null_cols, axis=1, inplace=True)","db1e98d1":"# categorical columns in the dataframe\ncategorical_columns = list(set(df_with.columns) - set(df_with._get_numeric_data().columns))\n\n# encode as numerical values\nfor col in categorical_columns:\n    if col != 'LotFrontage':\n        df_with[col] = LabelEncoder().fit_transform(df_with[col])\n        df_without[col] = LabelEncoder().fit_transform(df_without[col])","492a181e":"# Nan values were predicted based on independent variables using Random Forest.\nfrom sklearn.ensemble import RandomForestClassifier\n\nX_with = df_with.drop(['LotFrontage'], axis=1)\ny_with = df_with['LotFrontage']\nX_without = df_without.drop(['LotFrontage'], axis=1)\nX_with.head()\n\nrfModel = RandomForestClassifier()\nrfModel.fit(X_with, y_with)\n\ngeneratedValues = rfModel.predict(X = X_without)\nnp.round(generatedValues, 0)[:10]","f721137d":"ind = df[df['LotFrontage'].isnull()]['LotFrontage'].index\ndf.loc[ind,'LotFrontage'] = np.round(generatedValues, 0)","ef3adc17":"df['LotFrontage'].value_counts(dropna=False).head()","2c1af6ca":"print('number of columns with missing values',df.isnull().any().sum())","88b2079d":"# distinguishing numerical variables from categorical ones.\ndf_obj = df.select_dtypes('object')\nprint('object shape ',df_obj.shape)\ndf_num = df.select_dtypes(['int64','float64'])\nprint('num shape ',df_num.shape)","33f1f7c1":"# encode as numerical values\nfor col in df_obj:\n    df_obj[col] = LabelEncoder().fit_transform(df_obj[col])","df526485":"for col in df_num[df_num.notnull()]:\n    unique_vals = df_num[col].value_counts()\n    nr_values = len(unique_vals)\n    if nr_values < 15:\n        df_obj = pd.concat([df_obj, df_num[col].astype('object')], axis=1)\n        df_num = df_num.drop(col, axis=1)","17eb049c":"df_obj.head()","5fc31f0e":"df_num.head()","52e1f87f":"print('object shape ',df_obj.shape)\nprint('num shape ',df_num.shape)","1a0ffaf8":"def box_plot(df, label):\n    fig, ax = plt.subplots(figsize = (10, 1))\n    # rectangular box plot\n    bplot = ax.boxplot(df,\n                           vert=False,  # vertical box alignment\n                           notch=True,  # notch shape\n                           patch_artist=True,  # fill with color\n                           labels=[label]  # will be used to label x-ticks\n                          )\n    # fill with colors\n    colors = ['pink', 'lightblue', 'lightgreen']\n    for box in (bplot):\n        for patch, color in zip(bplot['boxes'], colors):\n            patch.set_facecolor(color)\n\n\n    whiskers_1 = bplot['whiskers'][0].get_xdata()[1]\n    whiskers_2 = bplot['whiskers'][0].get_xdata()[0]\n    median = bplot['medians'][0].get_xdata()[0]\n    whiskers_3 = bplot['whiskers'][1].get_xdata()[0]\n    whiskers_4 = bplot['whiskers'][1].get_xdata()[1]\n    \n    ax.text(whiskers_1, 1.15, f\"{whiskers_1}\", ha='center', va='center', color='b', size=13)\n    ax.text(whiskers_2, 1.25, f\"{whiskers_2}\", ha='center', va='center', color='b', size=13)\n    ax.text(median, 0.7, f\"{median}\", ha='center', va='center', color='b', size=13)\n    ax.text(whiskers_3, 1.25, f\"{whiskers_3}\", ha='center', va='center', color='b', size=13)\n    ax.text(whiskers_4, 1.15, f\"{whiskers_4}\", ha='center', va='center', color='b', size=13)\n\n\n    ax.xaxis.grid(True)\n    plt.show()\n\n    outliers = bplot['fliers'][0].get_xdata()\n#     print(sorted(outliers))","e1100ddc":"box_plot(df_num['LotFrontage'], 'LotFrontage')","4b8e48fc":"# test data\ndf_num[1460:][df_num[1460:]['LotFrontage'] > 200].index","1fc2f22d":"# train data\noutliers_index = df_num[:1460][df_num[:1460]['LotFrontage'] > 200].index\noutliers_index","b80f9bb9":"# drop outliers in train data, but not test data\ndf_num = df_num.drop(outliers_index, axis=0)\ndf_obj = df_obj.drop(outliers_index, axis=0)\ny = y.drop(outliers_index, axis=0)","7712f6a5":"box_plot(df_num['LotArea'], 'LotArea')","5edb249a":"# test data\ndf_num[1460:][df_num[1460:]['LotArea'] > 57000].index","b38420f3":"# train data\noutliers_index = df_num[:1460][df_num[:1460]['LotArea'] > 57000].index\noutliers_index","9cf7da9e":"# drop outliers in train data, but not test data\ndf_num = df_num.drop(outliers_index, axis=0)\ndf_obj = df_obj.drop(outliers_index, axis=0)\ny = y.drop(outliers_index, axis=0)","7675357f":"box_plot(df_num['YearBuilt'], 'YearBuilt')","d6352112":"# test data\ndf_num[1460:][df_num[1460:]['YearBuilt'] < 1879].index","7c2e06ed":"# train data\noutliers_index = df_num[:1460][df_num[:1460]['YearBuilt'] < 1879].index\noutliers_index","987929eb":"# drop outliers in train data, but not test data\ndf_num = df_num.drop(outliers_index, axis=0)\ndf_obj = df_obj.drop(outliers_index, axis=0)\ny = y.drop(outliers_index, axis=0)","b28bdc28":"box_plot(df_num['MasVnrArea'], 'MasVnrArea')","5a3c05f8":"# test data\ndf_num[1460:][df_num[1460:]['MasVnrArea'] > 1300].index","c4075fac":"# train data\noutliers_index = df_num[:1460][df_num[:1460]['MasVnrArea'] > 1300].index\noutliers_index","7960f34d":"# drop outliers in train data, but not test data\ndf_num = df_num.drop(outliers_index, axis=0)\ndf_obj = df_obj.drop(outliers_index, axis=0)\ny = y.drop(outliers_index, axis=0)","be220caa":"box_plot(df_num['BsmtUnfSF'], 'BsmtUnfSF')","9e2edba3":"# test data\ndf_num[1460:][df_num[1460:]['BsmtUnfSF'] > 2140].index","ac78cd6a":"# train data\noutliers_index = df_num[:1460][df_num[:1460]['BsmtUnfSF'] > 2140].index\noutliers_index","ed30e67a":"# drop outliers in train data, but not test data\ndf_num = df_num.drop(outliers_index, axis=0)\ndf_obj = df_obj.drop(outliers_index, axis=0)\ny = y.drop(outliers_index, axis=0)","7ab54dbc":"box_plot(df_num['2ndFlrSF'], '2ndFlrSF')","debf466a":"# test data\ndf_num[1460:][df_num[1460:]['2ndFlrSF'] > 1870].index","e6eadec3":"# train data\noutliers_index = df_num[:1460][df_num[:1460]['2ndFlrSF'] > 1870].index\noutliers_index","bab781ae":"# drop outliers in train data, but not test data\ndf_num = df_num.drop(outliers_index, axis=0)\ndf_obj = df_obj.drop(outliers_index, axis=0)\ny = y.drop(outliers_index, axis=0)","e2f45a6e":"box_plot(df_num['3SsnPorch'], '3SsnPorch')","1f5ef31a":"# test data\ndf_num[1460:][df_num[1460:]['3SsnPorch'] > 360].index","83b1b557":"# train data\noutliers_index = df_num[:1460][df_num[:1460]['3SsnPorch'] > 360].index\noutliers_index","6d46a38c":"# drop outliers in train data, but not test data\ndf_num = df_num.drop(outliers_index, axis=0)\ndf_obj = df_obj.drop(outliers_index, axis=0)\ny = y.drop(outliers_index, axis=0)","db8b654c":"df = pd.concat([df_num, df_obj], axis=1)","f06496fa":"#  to select highly correlated features\ndef correlation(dataset, threshold):\n    col_corr = set()  # Set of all the names of correlated columns\n    corr_matrix = dataset.corr()\n    for i in range(len(corr_matrix.columns)):\n        for j in range(i):\n            if abs(corr_matrix.iloc[i, j]) > threshold:\n                colname = corr_matrix.columns[i]  # getting the name of column\n                col_corr.add(colname)\n    return col_corr","4e01b912":"corr_features = correlation(df, 0.85)\ncorr_features","84063a86":"df = df.drop(corr_features, axis=1)","3b393e7e":"df.head()","d341c389":"### It will zero variance features\nfrom sklearn.feature_selection import VarianceThreshold\nvar_thres=VarianceThreshold(threshold=0)\nvar_thres.fit(df)\n# X.columns[var_thres.get_support()]\n\nconstant_columns = [column for column in df.columns\n                    if column not in df.columns[var_thres.get_support()]]\nconstant_columns\n# print(len(constant_columns))","d55e7d0e":"from sklearn.preprocessing import MinMaxScaler\nscaler = MinMaxScaler()\nscale_col = ['YearBuilt', 'YearRemodAdd', 'GarageYrBlt', 'YrSold']\ndf[scale_col] = scaler.fit_transform(df[scale_col])","22f647fd":"#Considering price should be postive, no trans needed\ny = np.log(y)","492fcb7e":"df = df.sort_values(by='Id')\nX = df[df['Id'] < 1461]\nX = X.drop('Id', axis=1)\n\nX_kaggle = df[df['Id'] >= 1461]\nX_kaggle = X_kaggle.drop('Id', axis=1)\n\nprint(X.shape)\nprint(y.shape)\nprint(X_kaggle.shape)","0933e21f":"X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n\nprint(X_train.shape)\nprint(X_test.shape)\nprint(y_train.shape)\nprint(y_test.shape)","952a8691":"def evaluate_model(model):\n    y_train_pred = model.predict(X_train)\n    y_test_pred = model.predict(X_test)\n    \n    RMSE_train = math.sqrt(mean_squared_error(y_train, y_train_pred))\n    RMSE_test = math.sqrt(mean_squared_error(y_test, y_test_pred))\n    # Model Accuracy\n    print('The Accuracy  on the training dataset is: {:.1%}'.format(model.score(X_train, y_train)))\n    print('The Accuracy  on the testing dataset is: {:.1%}'.format(model.score(X_test, y_test)))\n    print(\"\")\n    # The Root Mean Squared Error (RMSE)\n    print('The RMSE  on the training dataset is: {:.8}'.format(RMSE_train))\n    print('The RMSE  on the testing dataset is: {:.8}'.format(RMSE_test))\n    \n    return RMSE_train, RMSE_test","feba4cbf":"parameters = {'fit_intercept':[True,False], 'normalize':[True,False], 'copy_X':[True, False]}\nlr = GridSearchCV(LinearRegression(), param_grid=parameters, scoring='r2', cv=5)\nresults = lr.fit(X_train, y_train)","44f75dbd":"RMSE_train_lr, RMSE_test_lr = evaluate_model(lr)","9b4af320":"from sklearn.tree import DecisionTreeRegressor\nparameters = {'criterion':[\"mse\", \"friedman_mse\", \"mae\", \"poisson\"], 'splitter':[\"best\",\"random\"]}\ndt = GridSearchCV(DecisionTreeRegressor(), param_grid=parameters, scoring='r2', cv=5)\ndt_result = dt.fit(X_train, y_train)","86dd6ff2":"RMSE_train_dt, RMSE_test_dt = evaluate_model(dt)","dcba142a":"from sklearn.svm import SVR\nparameters = {'C':[0.1, 0.5, 1, 10, 100]}\nsvr = GridSearchCV(SVR(), param_grid=parameters, scoring='r2', cv=5)\nsvr_result = svr.fit(X_train, y_train)","e525a6bb":"RMSE_train_svr, RMSE_test_svr = evaluate_model(svr)","1e5404ac":"from sklearn.linear_model import Ridge, Lasso","6f2bf3a0":"parameters = {'solver':[\"auto\", \"svd\", \"cholesky\", \"lsqr\", \"sparse_cg\", \"sag\", \"saga\"]}\nridge = GridSearchCV(Ridge(), param_grid=parameters, scoring='r2', cv=5)\nridge_result = ridge.fit(X_train, y_train)","934260c5":"RMSE_train_ridge, RMSE_test_ridge = evaluate_model(ridge)","862482e1":"parameters = {'selection':[\"cyclic\", \"random\"]}\nlasso = GridSearchCV(Lasso(), param_grid=parameters, scoring='r2', cv=5)\nlasso_result = lasso.fit(X_train, y_train)","41972bdf":"RMSE_train_lasso, RMSE_test_lasso = evaluate_model(lasso)","591cf814":"from sklearn.linear_model import ElasticNet\n\nparameters = {'alpha':[0.001, 0.0001, 1e-05]}\nen = GridSearchCV(ElasticNet(), parameters, cv=5, \n                    scoring='neg_root_mean_squared_error')\nen_result = en.fit(X_train,y_train)","e5cbdb62":"RMSE_train_en, RMSE_test_en = evaluate_model(en)","9466ca18":"from sklearn.ensemble import GradientBoostingRegressor\ngbr = GradientBoostingRegressor(alpha=0.9,\n                                      learning_rate=0.01, loss='huber',\n                                      max_depth=13, max_features=0.1, min_samples_split=110,\n                                      n_estimators=10000, n_iter_no_change=100, random_state=42)\ngbr_result = gbr.fit(X_train, y_train)","9cedbe26":"RMSE_train_gbr, RMSE_test_gbr = evaluate_model(gbr)","06da5450":"df_models_acc = pd.DataFrame({\n    'Model': ['lr', 'dt', 'svr', 'ridge', 'lasso', 'en', 'gbr'],\n    'RMSE_Train': [RMSE_train_lr, RMSE_train_dt, RMSE_train_svr, RMSE_train_ridge, \n                       RMSE_train_lasso, RMSE_train_en, RMSE_train_gbr],\n    'RMSE_Test': [RMSE_test_lr, RMSE_test_dt, RMSE_test_svr, RMSE_test_ridge, \n                       RMSE_test_lasso, RMSE_test_en, RMSE_test_gbr],\n})\ndf_models_acc.sort_values(by='RMSE_Test')","6e17e137":"sample_submission = pd.read_csv('\/kaggle\/input\/house-prices-advanced-regression-techniques\/sample_submission.csv')\nsample_submission.head()","664f18a4":"submission = sample_submission.drop('SalePrice', axis=1)\n\n# GradientBoostingRegressor\ny_pred_kaggle = np.exp(gbr.predict(X_kaggle))\nsubmission['SalePrice'] = y_pred_kaggle\nsubmission.head()","63a6c86f":"# Are our test and submission dataframes the same length?\nif len(submission) == len(sample_submission):\n    print(\"Submission dataframe is the same length as test ({} rows).\".format(len(submission)))\nelse:\n    print(\"Dataframes mismatched, won't be able to submit to Kaggle.\")","b6cb7a71":"# Convert submisison dataframe to csv for submission to csv for Kaggle submisison\nsubmission.to_csv('House_Prices_Submission.csv', index=False)\nprint('Submission CSV is ready!')","b25b3d30":"# Check the submission csv to make sure it's in the right format\nsubmissions_check = pd.read_csv(\"House_Prices_Submission.csv\")\nsubmissions_check.head()","a0d67fb8":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.20 GarageCond\n    <\/h4>\n<\/div>","c545cc97":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.19 GarageQual\n    <\/h4>\n<\/div>","80b2cdca":"<a id='31'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        3.1 Missing Values\n   <\/h3>\n<\/div>","8d072d3e":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        YearBuilt\n    <\/h4>\n<\/div>","60c73069":"<a id='1'><\/a>\n<div class=\"alert alert-block alert-danger\">\n<h2>1 Importing packages<\/h2>\n<\/div>","934461f0":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.2 Utilities\n    <\/h4>\n<\/div>","a9ad08c6":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.2.5 ElasticNet\n    <\/h4>\n<\/div>","d397e08c":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        2ndFlrSF\n    <\/h4>\n<\/div>","3912a7cc":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.7 Electrical\n    <\/h4>\n<\/div>","85ef620c":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3SsnPorch\n    <\/h4>\n<\/div>","ad1c45e7":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.28 LotFrontage\n    <\/h4>\n<\/div>","ee8397eb":"Goal\n\nIt is your job to predict the sales price for each house. For each Id in the test set, you must predict the value of the SalePrice variable. ","b83c8012":"<a id='5'><\/a>\n<div class=\"alert alert-block alert-danger\">\n    <h2>\n        5. Submission\n    <\/h2>\n<\/div>","cf38f32f":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.21 MasVnrType\n    <\/h4>\n<\/div>","849eb3fe":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.4 BsmtFinSF1\n    <\/h4>\n<\/div>","bccebac1":"<a id='42'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.2 Running Machine Learning Models\n   <\/h3>\n<\/div>","ecc681d8":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.6 GradientBoostingRegressor\n    <\/h4>\n<\/div>","2dfe6827":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.6 BsmtUnfSF\n    <\/h4>\n<\/div>","0013fc53":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.3 SVR\n    <\/h4>\n<\/div>","02c63525":"<a id='41'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        4.1 Separate the dataset into train and test\n   <\/h3>\n<\/div>","81912f6a":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        BsmtUnfSF\n    <\/h4>\n<\/div>","c3fb0f78":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.26 GarageYrBlt\n    <\/h4>\n<\/div>","e1ce280f":"## Index\n\n<a href='#1'>1 Importing packages<\/a><br>\n<a href='#2'>2 Read CSV train\/test files into DataFrame<\/a><br>\n<a href='#3'>3 Data Preprocessing<\/a><br>\n<blockquote>\n<a href='#31'>3.1 Missing Values<\/a><br>\n<a href='#32'>3.2 Distinguishing numerical variables from categorical ones<\/a><br>\n<a href='#33'>3.3 Drop Outliers<\/a><br>\n<a href='#34'>3.4 Drop Features Using Pearson Correlation<\/a><br>\n<\/blockquote>\n<a href='#4'>4. Regressions and Results<\/a><br>\n<blockquote>\n<a href='#41'>4.1 Separate the dataset into train and test<\/a><br>\n<a href='#42'>4.2 Running Machine Learning Models<\/a><br>\n<\/blockquote>\n<a href='#5'>5. Submission<\/a><br>","590f867f":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.17 BsmtCond\n    <\/h4>\n<\/div>","201b4042":"<a id='34'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        3.4 Drop Features Using Pearson Correlation\n   <\/h3>\n<\/div>","7ca1973a":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        LotFrontage\n    <\/h4>\n<\/div>","af538afc":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.14 TotalBsmtSF\n    <\/h4>\n<\/div>","d629de3a":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.18 BsmtFinType2\n    <\/h4>\n<\/div>","81d5ebe8":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.27 GarageFinish\n    <\/h4>\n<\/div>","21aa9256":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.15 BsmtFullBath\n    <\/h4>\n<\/div>","2c60321e":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.4 Ridge, Lasso\n    <\/h4>\n<\/div>","d7cbb0bc":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.25 GarageType\n    <\/h4>\n<\/div>","f0d24bd7":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.23 BsmtExposure\n    <\/h4>\n<\/div>","1d15a90b":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.5 BsmtFinSF2\n    <\/h4>\n<\/div>","19439d2e":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.24 BsmtFinType1\n    <\/h4>\n<\/div>","acaa3431":"<a id='2'><\/a>\n<div class=\"alert alert-block alert-danger\">\n   <h2>\n    2 Read CSV train\/test files into DataFrame\n    <\/h2>\n<\/div>","9c4cd42c":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.7 Model_Selection - Final\n    <\/h4>\n<\/div>","b0c46dae":"<a id='33'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        3.3 Drop Outliers\n   <\/h3>\n<\/div>","77fd5bc8":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.11 SaleType\n    <\/h4>\n<\/div>","8b2c6a61":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.2 DecisionTreeRegressor\n    <\/h4>\n<\/div>","5e697739":"<a id='35'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        3.5 Check zero variance features\n   <\/h3>\n<\/div>","4edc8091":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        4.2.1 LinearRegression\n    <\/h4>\n<\/div>","d7c5d314":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.8 KitchenQual\n    <\/h4>\n<\/div>","ebc93e00":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.1 MSZoning\n    <\/h4>\n<\/div>","71a338c1":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.13 Functional\n    <\/h4>\n<\/div>","c8a44bd7":"<a id='4'><\/a>\n<div class=\"alert alert-block alert-danger\">\n   <h2>\n    4. Regressions and Results\n    <\/h2>\n<\/div>","7399311f":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.10 GarageArea\n    <\/h4>\n<\/div>","51b209a5":"<a id='32'><\/a>\n<div class=\"alert alert-block alert-info\">\n   <h3>\n        3.2 Distinguishing numerical variables from categorical ones\n   <\/h3>\n<\/div>","ad8e3bb8":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.16 MasVnrArea\n    <\/h4>\n<\/div>","645d7f98":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        MasVnrArea\n    <\/h4>\n<\/div>","c56c6b6b":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        LotArea\n    <\/h4>\n<\/div>","a8b75e26":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.22 BsmtQual\n    <\/h4>\n<\/div>","514dfa7c":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.9 GarageCars\n    <\/h4>\n<\/div>","aec0873e":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.3 Exterior1st & Exterior2st\n    <\/h4>\n<\/div>","13983738":"<div class=\"alert alert-block alert-success\">\n    <h4>\n        3.1.12 BsmtHalfBath\n    <\/h4>\n<\/div>","560d038d":"<a id='3'><\/a>\n<div class=\"alert alert-block alert-danger\">\n   <h2>\n    3 Data Preprocessing\n    <\/h2>\n<\/div>"}}