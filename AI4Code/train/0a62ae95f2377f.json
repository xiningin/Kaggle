{"cell_type":{"cd039fe8":"code","75fec1f1":"code","bf2746b8":"code","907ae52d":"code","003a3d4e":"code","a250fef9":"code","9099e253":"code","55b8e0da":"code","9a3dd8ba":"code","aefacb50":"code","00334fbf":"code","4b9be43b":"code","2c6d920a":"code","8aedc9cb":"code","7dd44ad4":"code","11809cff":"code","40da3451":"code","7cc73374":"code","1fcb03e3":"code","98e14662":"code","f37cc4a4":"code","db81b9b4":"code","e03c064f":"code","5af5ce04":"code","8f5c9a50":"code","5a3f397f":"code","d5c32af6":"markdown"},"source":{"cd039fe8":"import numpy as np\nimport os\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport tensorflow as tf\nfrom tensorflow.keras import layers\nfrom tensorflow.keras.preprocessing.image import ImageDataGenerator\nfrom tensorflow.keras.applications import vgg16 \nfrom tensorflow.keras.applications import mobilenet_v2\nfrom tensorflow.keras.models import Model\nfrom sklearn.metrics import confusion_matrix,classification_report","75fec1f1":"train_path=\"..\/input\/chest-xray-pneumonia\/chest_xray\/train\"\ntest_path=\"..\/input\/chest-xray-pneumonia\/chest_xray\/test\"","bf2746b8":"train_gen=ImageDataGenerator(\n\nrotation_range=20,\nzoom_range=0.15,\nwidth_shift_range=0.2,\nheight_shift_range=0.2,\nshear_range=0.15,\nhorizontal_flip=True,\nfill_mode=\"nearest\",\npreprocessing_function=vgg16.preprocess_input,\nvalidation_split=0.1)\n\ntest_gen=ImageDataGenerator(preprocessing_function=vgg16.preprocess_input)","907ae52d":"train_image=train_gen.flow_from_directory(\n\ndirectory=train_path,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='training'\n)\n","003a3d4e":"val_images = train_gen.flow_from_directory(\n    directory=train_path,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=True,\n    seed=42,\n    subset='validation'\n)","a250fef9":"test_images = test_gen.flow_from_directory(\n    directory=test_path,\n    target_size=(224, 224),\n    color_mode='rgb',\n    class_mode='binary',\n    batch_size=32,\n    shuffle=False,\n    seed=42\n)","9099e253":"base_model=VGG16(input_shape=(224,224,3),weights=\"imagenet\",include_top=False,pooling=\"avg\")\nfor layer in base_model.layers:\n    layer.trainable=False","55b8e0da":"input=base_model.input\n\nx=layers.Flatten()(base_model.output)\nx=layers.Dense(128,activation=\"relu\")(x)\noutput=layers.Dense(1,activation=\"sigmoid\")(x)\n\nmodel=Model(input,output)\nprint(model.summary())","9a3dd8ba":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","aefacb50":"h=model.fit(train_image,validation_data=val_images,epochs=100,callbacks=[tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ])","00334fbf":"import plotly.express as px\nfig=px.line(h.history,\n           y=[\"loss\",\"val_loss\"],\n           labels={\"index\":\"epochs\",\"value\":\"loss\"},\n           title=\"train & val loss\")\nfig.show()","4b9be43b":"fig=px.line(h.history,\n           y=[\"accuracy\",\"val_accuracy\"],\n           labels={\"index\":\"epochs\",\"value\":\"acc\"},\n           title=\"train & val acc\")\nfig.show()","2c6d920a":"def evaluate_model(model,test_data):\n    \n    result=model.evaluate(test_data,verbose=0)\n    loss=result[0]\n    accuracy=result[1]\n    \n    print(\"test loss: {:.5f}\".format(loss))\n    print(\"test acc: {:.2f}\".format(accuracy*100))\n    \n    y_pred=np.squeeze((model.predict(test_data)>=0.5).astype(np.int))\n    cm=confusion_matrix(test_data.labels,y_pred)\n    clr = classification_report(test_data.labels, y_pred, target_names=[\"NEGATIVE\", \"POSITIVE\"])\n    \n    plt.figure(figsize=(6, 6))\n    sns.heatmap(cm, annot=True, fmt='g', vmin=0, cmap='Blues', cbar=False)\n    plt.xticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n    plt.yticks(ticks=np.arange(2) + 0.5, labels=[\"NEGATIVE\", \"POSITIVE\"])\n    plt.xlabel(\"Predicted\")\n    plt.ylabel(\"Actual\")\n    plt.title(\"Confusion Matrix\")\n    plt.show()\n    \n    print(\"Classification Report:\\n----------------------\\n\", clr)","8aedc9cb":"evaluate_model(model,test_images)","7dd44ad4":"base_model=tf.keras.applications.MobileNetV2(input_shape=(224,224,3),weights=\"imagenet\",include_top=False,pooling=\"avg\")\nfor layer in base_model.layers:\n    layer.trainable=False","11809cff":"input=base_model.input\n\nx=layers.Flatten()(base_model.output)\nx=layers.Dense(128,activation=\"relu\")(x)\nx=layers.Dropout(0.5)(x)\noutput=layers.Dense(1,activation=\"sigmoid\")(x)\n\nmodel=Model(input,output)\nprint(model.summary())","40da3451":"model.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","7cc73374":"h=model.fit(train_image,validation_data=val_images,epochs=100,callbacks=[tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ])","1fcb03e3":"fig=px.line(h.history,\n           y=[\"loss\",\"val_loss\"],\n           labels={\"index\":\"epochs\",\"value\":\"loss\"},\n           title=\"train & val loss\")\nfig.show()","98e14662":"fig=px.line(h.history,\n           y=[\"accuracy\",\"val_accuracy\"],\n           labels={\"index\":\"epochs\",\"value\":\"acc\"},\n           title=\"train & val acc\")\nfig.show()","f37cc4a4":"evaluate_model(model,test_images)","db81b9b4":"input=layers.Input(shape=(224,224,3))\n\nx=layers.Conv2D(16,3,activation=\"relu\")(input)\nx=layers.BatchNormalization()(x)\nx=layers.Conv2D(16,3,activation=\"relu\")(x)\nx=layers.BatchNormalization()(x)\nx=layers.MaxPool2D((2,2))(x)\n\n\nx=layers.Conv2D(32,3,activation=\"relu\")(x)\nx=layers.BatchNormalization()(x)\nx=layers.Conv2D(32,3,activation=\"relu\")(x)\nx=layers.BatchNormalization()(x)\nx=layers.MaxPool2D((2,2))(x)\n\nx=layers.Conv2D(64,3,activation=\"relu\")(x)\nx=layers.BatchNormalization()(x)\nx=layers.Conv2D(64,3,activation=\"relu\")(x)\nx=layers.BatchNormalization()(x)\nx=layers.MaxPool2D((2,2))(x)\n\nx=layers.Conv2D(128,3,activation=\"relu\")(x)\nx=layers.BatchNormalization()(x)\nx=layers.Conv2D(128,3,activation=\"relu\")(x)\nx=layers.BatchNormalization()(x)\nx=layers.MaxPool2D((2,2))(x)\n\nx=layers.Flatten()(x)\nx=layers.Dropout(0.5)(x)\nx=layers.Dense(128,activation=\"relu\")(x)\nx=layers.Dropout(0.5)(x)\nx=layers.Dense(64,activation=\"relu\")(x)\nx=layers.Dropout(0.5)(x)\noutput=layers.Dense(1,activation=\"sigmoid\")(x)\n\nmodel=tf.keras.Model(input,output)\n\nmodel.compile(optimizer=\"adam\",loss=\"binary_crossentropy\",metrics=[\"accuracy\"])","e03c064f":"h=model.fit(train_image,validation_data=val_images,epochs=100,callbacks=[tf.keras.callbacks.EarlyStopping(\n            monitor='val_loss',\n            patience=3,\n            restore_best_weights=True\n        )\n    ])","5af5ce04":"fig=px.line(h.history,\n           y=[\"loss\",\"val_loss\"],\n           labels={\"index\":\"epochs\",\"value\":\"loss\"},\n           title=\"train & val loss\")\nfig.show()","8f5c9a50":"fig=px.line(h.history,\n           y=[\"accuracy\",\"val_accuracy\"],\n           labels={\"index\":\"epochs\",\"value\":\"acc\"},\n           title=\"train & val acc\")\nfig.show()","5a3f397f":"evaluate_model(model,test_images)\n","d5c32af6":"#part2"}}