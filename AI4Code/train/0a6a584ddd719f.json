{"cell_type":{"663d224a":"code","b1a738ae":"code","9a67e7f6":"code","63f99cfd":"code","bc4284b3":"code","4a99f68a":"code","7d95c2ba":"code","a0336945":"code","5c524dbe":"code","70d43d21":"code","cda64943":"code","fae5494f":"code","338f9fd6":"code","64a27b1c":"code","e08e174f":"code","0479d8b7":"code","8182034c":"code","7c321416":"code","f9eb4797":"code","a0b6b2db":"code","6897ba64":"code","e5e4e147":"code","8768e398":"code","7b1f86a5":"code","1f8d332e":"code","40e83d6a":"code","063602b9":"code","3da413b7":"code","910c30e3":"code","a3de671b":"code","3e9210bc":"code","879dab0e":"code","218d116f":"code","ed31a613":"code","1c585a7a":"code","ec22cb7b":"code","c372b2ee":"code","51161eb3":"code","628cf572":"code","03b768ec":"code","0a3f4fb5":"code","b7380cf5":"code","0a1f32bf":"code","1cf6386e":"code","f9a3ed55":"code","1230ff90":"code","a0ad0432":"code","2970c3a7":"code","57d4b4e6":"code","7d793d42":"code","f17f96e9":"code","8e9954c6":"code","da03a454":"code","b257f708":"code","084bc503":"code","47ab4ff1":"code","99c619e9":"code","2928896c":"code","9002e9b3":"code","c0420a55":"code","c3a2e2c2":"code","a46b1ca6":"code","4072567e":"code","4c50e608":"code","083fd9ac":"code","d139f54d":"code","fc967b68":"code","e8f014af":"code","ec1d2e96":"code","0a6c6203":"code","6a811b65":"code","e26f521d":"code","36be3626":"code","c7de0d55":"code","812b87e7":"markdown","b693be3f":"markdown","71cbc597":"markdown","78be7faa":"markdown","8419784d":"markdown","550f0d25":"markdown","ec13a837":"markdown","51ad206c":"markdown","c331e8ce":"markdown","28842ccd":"markdown","be3bca83":"markdown","ca85bc55":"markdown","e4a8785c":"markdown","5dea0824":"markdown","f3c467a7":"markdown","5478f9e3":"markdown","1ec17209":"markdown","33db4f0e":"markdown","aeb81969":"markdown","88ee487b":"markdown","7c230813":"markdown","29adcd35":"markdown","9ae981a4":"markdown","a5e5a672":"markdown","91e114b2":"markdown","dfcaf8b6":"markdown"},"source":{"663d224a":"# !conda install scikit-learn=0.22.1 -y","b1a738ae":"# !conda install -c conda-forge somoclu -y","9a67e7f6":"import numpy as np\nimport matplotlib.pyplot as plt\n# plt.style.use('ggplot')\n\ndef plot_dt(tree, feature_names, class_names):\n    \"\"\"Fun\u00e7\u00e3o criada para a visualiza\u00e7\u00e3o da \u00e1rvore de decis\u00e3o gerada \n    \"\"\"\n    from sklearn.tree import plot_tree\n    \n    fig, ax = plt.subplots(1, 1, figsize=(10, 10))\n    plot_tree(tree, ax = ax, feature_names=feature_names, class_names=class_names)\n\ndef plot_dendrogram(model, **kwargs):\n    \"\"\"Fun\u00e7\u00e3o para a gera\u00e7\u00e3o de um dendograma de um modelo sklearn.cluster.AgglomerativeClustering\n    \n    See:\n        Fun\u00e7\u00e3o retirada da documenta\u00e7\u00e3o oficial do scikit-learn\n    \"\"\"\n    from scipy.cluster.hierarchy import dendrogram\n    \n    plt.title('Agrupamento hier\u00e1rquico')\n    \n    counts = np.zeros(model.children_.shape[0])\n    n_samples = len(model.labels_)\n    for i, merge in enumerate(model.children_):\n        current_count = 0\n        for child_idx in merge:\n            if child_idx < n_samples:\n                current_count += 1  # leaf node\n            else:\n                current_count += counts[child_idx - n_samples]\n        counts[i] = current_count\n\n    linkage_matrix = np.column_stack([model.children_, model.distances_,\n                                      counts]).astype(float)\n\n    # Plot the corresponding dendrogram\n    dendrogram(linkage_matrix, **kwargs)\n    plt.xlabel(\"\u00cdndice dos dados (Em parenteses representam a quantidade de elementos no grupo).\")\n    plt.show()\n    \n\ndef plot_cm(cm_sklearn, labels):\n    \"\"\"Fun\u00e7\u00e3o para gerar matriz de confus\u00e3o\n    \"\"\"\n    \n    import seaborn as sn\n    \n    df_cm = pd.DataFrame(cm_sklearn, index = [i for i in labels], columns = [i for i in labels])\n    plt.figure(figsize = (10,7))\n    sn.heatmap(df_cm, annot=True)\n    \n# Configura\u00e7\u00e3o das classes\nfrom sklearn import preprocessing\n\nle = preprocessing.LabelEncoder()\n_ = le.fit([\"d\", \"h\", \"o\", \"s\"])","63f99cfd":"# importando a fun\u00e7\u00e3o para calcular a matriz de confus\u00e3o\nfrom sklearn.metrics import confusion_matrix","bc4284b3":"import numpy as np\nimport pandas as pd","4a99f68a":"train_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/dataAt\/ml-aplicado-dados-espacial\/master\/src\/metodos-supervisionados\/dados\/forest_type\/training.csv')\ntest_data = pd.read_csv('https:\/\/raw.githubusercontent.com\/dataAt\/ml-aplicado-dados-espacial\/master\/src\/metodos-supervisionados\/dados\/forest_type\/testing.csv')","7d95c2ba":"data_columns = ['b1', 'b2', 'b3', 'b4', 'b5', 'b6', 'b7', 'b8', 'b9']","a0336945":"x_train = train_data[data_columns]\ny_train = train_data['class']","5c524dbe":"x_test = test_data[data_columns]\ny_test = test_data['class']","70d43d21":"## Definindo classes presentes no conjunto de dados\nclass_names = y_train.unique().tolist()\nclass_names","cda64943":"import numpy as np\nimport pandas as pd\nfrom plotnine import *\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.metrics import confusion_matrix, cohen_kappa_score, accuracy_score","fae5494f":"knn = KNeighborsClassifier()","338f9fd6":"knn.fit(x_train, y_train)","64a27b1c":"y_pred = knn.predict(x_test)","e08e174f":"# Calculando o \u00edndice Kappa\ncohen_kappa_score(y_pred, y_test)","0479d8b7":"# Calculando o Score\naccuracy_score(y_pred, y_test)","8182034c":"resultados = {'Kappa': [], 'k': [], 'Score': []}\nfor k_value in range(1, 15):\n    resultados['k'].append(k_value)\n    \n    neigh = KNeighborsClassifier(n_neighbors=k_value)\n    neigh.fit(x_train, y_train)\n    \n    y_pred = neigh.predict(x_test)\n    \n    resultados['Kappa'].append(cohen_kappa_score(y_pred, y_test))\n    resultados['Score'].append(accuracy_score(y_pred, y_test))\n\nresultados = pd.DataFrame(resultados)\n\n# Visualizando os resultados\nresultados.head()","7c321416":"# Transformando os dados em long para facilitar o plot\nresultados = resultados.melt('k', var_name = 'Medidas')","f9eb4797":"(\n    ggplot(resultados, aes(x = 'k', y = 'value', color = 'Medidas'))\n        + geom_line()\n        + theme_bw()\n        + facet_grid('~Medidas', space = 'free_y', scales = 'free')\n        + scale_x_continuous(breaks = np.arange(1, 17))\n        + labs(\n            title = 'M\u00e9tricas de avalia\u00e7\u00e3o - KNN',\n            x = 'Quantidade de vizinhos (K)',\n            y = 'Acur\u00e1cia'\n        )\n)","a0b6b2db":"knn = KNeighborsClassifier(n_neighbors=2)\nknn.fit(x_train, y_train)\ny_pred = knn.predict(x_test)","6897ba64":"# Calculando o \u00edndice Kappa\ncohen_kappa_score(y_pred, y_test)","e5e4e147":"# Calculando o Score\naccuracy_score(y_pred, y_test)","8768e398":"# Resultados do KNN\ny_pred = knn.predict(x_test)\nknn_cm = confusion_matrix(y_test, y_pred)\nplot_cm(knn_cm, \"dhos\")","7b1f86a5":"from sklearn.tree import DecisionTreeClassifier","1f8d332e":"clf = DecisionTreeClassifier()","40e83d6a":"clf = clf.fit(x_train, y_train)","063602b9":"y_pred = clf.predict(x_test)","3da413b7":"# Calculando o \u00edndice Kappa\ncohen_kappa_score(y_pred, y_test)","910c30e3":"# Calculando o Score\naccuracy_score(y_test, y_pred)","a3de671b":"plot_dt(clf, data_columns, class_names)","3e9210bc":"# Com a \u00e1rvore cortada, fa\u00e7amos todo o processo de avalia\u00e7\u00e3o e visualiza\u00e7\u00e3o de dados.\nclf = DecisionTreeClassifier(max_depth=2)\nclf = clf.fit(x_train, y_train)\ny_pred = clf.predict(x_test)","879dab0e":"# Calculando o \u00edndice Kappa\ncohen_kappa_score(y_pred, y_test)","218d116f":"# Calculando o Score\naccuracy_score(y_test, y_pred)","ed31a613":"plot_dt(clf, data_columns, class_names)","1c585a7a":"# Resultados da \u00e1rvore de decis\u00e3o\ny_pred = clf.predict(x_test)\nclf_cm = confusion_matrix(y_test, y_pred)\nplot_cm(clf_cm, \"dhos\")","ec22cb7b":"from keras.layers import Dense\nfrom keras.models import Sequential\nfrom sklearn.preprocessing import OneHotEncoder, StandardScaler","c372b2ee":"enc = OneHotEncoder()\n\ny_train_factor = enc.fit_transform(train_data['class'].values[:, np.newaxis]).toarray()\ny_test_factor = enc.fit_transform(test_data['class'].values[:, np.newaxis]).toarray()","51161eb3":"n_features = x_train.shape[1]\nn_classes = y_train_factor.shape[1]","628cf572":"model = Sequential(name='Modelo1')\nmodel.add(Dense(4, input_dim=n_features, activation='relu'))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(n_classes, activation='softmax'))","03b768ec":"model.compile(loss='categorical_crossentropy', \n                      optimizer='adam', \n                      metrics=['accuracy'])","0a3f4fb5":"model.summary()","b7380cf5":"history = model.fit(x_train, y_train_factor,\n                         batch_size=5,\n                         epochs=85,\n                         verbose=1,\n                         validation_data=(x_test, y_test_factor),)","0a1f32bf":"model.evaluate(x_test, y_test_factor, verbose=0)","1cf6386e":"history = pd.DataFrame(history.history)","f9a3ed55":"history.plot()","1230ff90":"# Resultados da RNA N\u00famero de \u00e9pocas 85\ny_pred = model.predict_classes(x_test)\nmodel_cm = confusion_matrix(le.transform(y_test.map(lambda x: x.strip())), y_pred)\nplot_cm(model_cm, \"dhos\")","a0ad0432":"# Varia\u00e7\u00e3o do n\u00famero de \u00e9pocas\nmodel = Sequential(name='Modelo2')\nmodel.add(Dense(4, input_dim=n_features, activation='relu'))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(n_classes, activation='softmax'))","2970c3a7":"model.compile(loss='categorical_crossentropy', \n                      optimizer='adam', \n                      metrics=['accuracy'])","57d4b4e6":"model.summary()","7d793d42":"history = model.fit(x_train, y_train_factor,\n                         batch_size=5,\n                         epochs=48,\n                         verbose=1,\n                         validation_data=(x_test, y_test_factor),)","f17f96e9":"model.evaluate(x_test, y_test_factor, verbose=0)","8e9954c6":"history = pd.DataFrame(history.history)\nhistory.plot()","da03a454":"# Resultados da RNA N\u00famero de \u00e9pocas 48\ny_pred = model.predict_classes(x_test)\nmodel_cm = confusion_matrix(le.transform(y_test.map(lambda x: x.strip())), y_pred)\nplot_cm(model_cm, \"dhos\")","b257f708":"# Varia\u00e7\u00e3o do n\u00famero de \u00e9pocas\nmodel = Sequential(name='Modelo3')\nmodel.add(Dense(4, input_dim=n_features, activation='relu'))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(n_classes, activation='softmax'))","084bc503":"model.compile(loss='categorical_crossentropy', \n                      optimizer='adam', \n                      metrics=['accuracy'])","47ab4ff1":"model.summary()","99c619e9":"history = model.fit(x_train, y_train_factor,\n                         batch_size=5,\n                         epochs=100,\n                         verbose=1,\n                         validation_data=(x_test, y_test_factor),)","2928896c":"model.evaluate(x_test, y_test_factor, verbose=0)","9002e9b3":"history = pd.DataFrame(history.history)\nhistory.plot()","c0420a55":"# Resultados da RNA N\u00famero de \u00e9pocas 100\ny_pred = model.predict_classes(x_test)\nmodel_cm = confusion_matrix(le.transform(y_test.map(lambda x: x.strip())), y_pred)\nplot_cm(model_cm, \"dhos\")","c3a2e2c2":"# Varia\u00e7\u00e3o do n\u00famero de camadas\nmodel = Sequential(name='Modelo4')\nmodel.add(Dense(4, input_dim=n_features, activation='relu'))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(40, activation='relu'))\nmodel.add(Dense(n_classes, activation='softmax'))","a46b1ca6":"model.compile(loss='categorical_crossentropy', \n                      optimizer='adam', \n                      metrics=['accuracy'])","4072567e":"model.summary()","4c50e608":"history = model.fit(x_train, y_train_factor,\n                         batch_size=5,\n                         epochs=48,\n                         verbose=1,\n                         validation_data=(x_test, y_test_factor),)","083fd9ac":"model.evaluate(x_test, y_test_factor, verbose=0)","d139f54d":"history = pd.DataFrame(history.history)\nhistory.plot()","fc967b68":"# Resultados da RNA N\u00famero camadas\n# 4 Camadas ocultas com fun\u00e7\u00e3o ReLU e Softmax\ny_pred = model.predict_classes(x_test)\nmodel_cm = confusion_matrix(le.transform(y_test.map(lambda x: x.strip())), y_pred)\nplot_cm(model_cm, \"dhos\")","e8f014af":"# Varia\u00e7\u00e3o do n\u00famero da camada final com fun\u00e7\u00e3o ReLU\nmodel = Sequential(name='Modelo5')\nmodel.add(Dense(4, input_dim=n_features, activation='relu'))\nmodel.add(Dense(10,activation='relu'))\nmodel.add(Dense(20, activation='relu'))\nmodel.add(Dense(n_classes, activation='relu'))","ec1d2e96":"model.compile(loss='categorical_crossentropy', \n                      optimizer='adam', \n                      metrics=['accuracy'])","0a6c6203":"model.summary()","6a811b65":"history = model.fit(x_train, y_train_factor,\n                         batch_size=5,\n                         epochs=48,\n                         verbose=1,\n                         validation_data=(x_test, y_test_factor),)","e26f521d":"model.evaluate(x_test, y_test_factor, verbose=0)","36be3626":"history = pd.DataFrame(history.history)\nhistory.plot()","c7de0d55":"# Resultados da RNA N\u00famero camadas\n# 4 Camadas ocultas com fun\u00e7\u00e3o ReLU e Softmax\ny_pred = model.predict_classes(x_test)\nmodel_cm = confusion_matrix(le.transform(y_test.map(lambda x: x.strip())), y_pred)\nplot_cm(model_cm, \"dhos\")","812b87e7":"No `scikit-learn` o algoritmo de \u00e1rvore de decis\u00e3o \u00e9 oferecido atrav\u00e9s da classe `sklearn.tree.DecisionTreeClassifier`.\nBasta definir `inst\u00e2ncia` e treinar o modelo.","b693be3f":"Certo, o modelo est\u00e1 pronto para ser treinado, fa\u00e7amos isto com o m\u00e9todo `fit`.","71cbc597":"O processo de treinamento de um algoritmo supervisionado, exige a exist\u00eancia de amostras j\u00e1 rotuladas sobre os dados, ou seja, para cada conjunto de entrada que ser\u00e1 mapeado pelo algoritmo j\u00e1 deve existir uma resposta.\n\nAl\u00e9m disto, para a valida\u00e7\u00e3o da generaliza\u00e7\u00e3o do algoritmo, \u00e9 necess\u00e1rio um conjunto de dados que ainda n\u00e3o tenha sido apresentado para o algoritmo, para que ent\u00e3o, a generaliza\u00e7\u00e3o de seu conhecimento seja assegurada. Este conjunto de dados foi dividido em dados de `treino` e `teste` previamente, pelo criador dos dados.\n\nAbaixo, o conjunto de dados carregado \u00e9 separado em valores de `x`, que representam as entradas para o algoritmo, e valores `y`, que representam os valores desejados que s\u00e3o esperados do algoritmo retornar.","78be7faa":"J\u00e1 temos o algoritmo knn treinado e pronto para realizar a classifica\u00e7\u00e3o de outros dados. Para testar, utilizamos o m\u00e9todo `predict` paras os dados de testes, que como citado, foram previamente separados.","8419784d":"Com a \u00e1rvore treinada, fa\u00e7amos a gera\u00e7\u00e3o das m\u00e9tricas de avalia\u00e7\u00e3o do modelo.","550f0d25":"Este algoritmo necessita da defini\u00e7\u00e3o de um valor de `K`, mas a utiliza\u00e7\u00e3o acima n\u00e3o possui tal defini\u00e7\u00e3o.\n\nCaso o valor de `K` n\u00e3o seja especificado, utiliza-se o valor de `K` igual a 5. Por\u00e9m, n\u00e3o h\u00e1 certeza de que este \u00e9 o melhor valor de `K` para nosso conjunto de dados.\n\nA defini\u00e7\u00e3o deste valor pode n\u00e3o ser algo f\u00e1cil, h\u00e1 bibliografias por exemplo, que recomendam que o valor de `K` sejam iguais a sqrt(n), onde n \u00e9 a quantidade de amostras nos dados.\n\nNo nosso caso, vamos fazer v\u00e1rios testes para buscar o melhor valor de `K`. Cada teste consiste no treinamento do algoritmo com o valor de `K` diferente, sendo que este v\u00e1ria de 1 \u00e0 30.","ec13a837":"### Redes Neurais Artificiais (RNA)\n<hr style=\"border: 1px solid #0984e3;\">\n\nEsta se\u00e7\u00e3o apresenta a utiliza\u00e7\u00e3o de `Redes Neurais Artificiais` atrav\u00e9s da biblioteca de `Deep Learning` Keras.\n\nPara iniciar, todos os pacotes necess\u00e1rios para a utiliza\u00e7\u00e3o do algoritmo s\u00e3o importados.","51ad206c":"Utilizar as m\u00e9tricas para avaliar a qualidade dos resultados apresentados pelo algoritmo.","c331e8ce":"### K-Nearest Neighbors (KNN)\n<hr style=\"border: 1px solid #0984e3;\">\n\nEsta se\u00e7\u00e3o apresenta a utiliza\u00e7\u00e3o do algoritmo `K-Nearest Neighbors (KNN)` atrav\u00e9s da biblioteca de *machine learning* scikit-learn\n\nPara iniciar, todos os pacotes necess\u00e1rios para a utiliza\u00e7\u00e3o do algoritmo s\u00e3o importados.","28842ccd":"Para realizar o treinamento basta utilizamos o m\u00e9todo `fit`, como feito no `KNN`.","be3bca83":"Definindo as vari\u00e1veis para o armazenamento dos dados de tipos de florestas.","ca85bc55":"Ap\u00f3s a constru\u00e7\u00e3o do modelo, vamos fazer sua `materializa\u00e7\u00e3o` atrav\u00e9s do m\u00e9todo `compile`.","e4a8785c":"No `scikit-learn` o algoritmo KNN \u00e9 oferecido atrav\u00e9s da classe `sklearn.neighbors.KNeighborsClassifier`. Para come\u00e7ar sua utiliza\u00e7\u00e3o, basta fazer a `inst\u00e2ncia` e treinar o modelo.\n\nFa\u00e7a inicialmente a inst\u00e2ncia da classe do KNN.","5dea0824":"Vejamos o resumo do modelo que foi gerado","f3c467a7":"Com a inst\u00e2ncia feita, \u00e9 necess\u00e1rio utilizar o m\u00e9todo `fit` para que o algoritmo seja treinado.","5478f9e3":"Os resultados n\u00e3o foram ruins, o que \u00e9 interessante.","1ec17209":"**Problema**: a \u00e1rvore gerada est\u00e1 muito complexa, tem muitas decis\u00f5es sendo tomadas.\n\n**Causa**: sinal de **overfitting**, onde a \u00e1rvore de decis\u00e3o n\u00e3o grava caracter\u00edsticas gerais dos dados, mas sim, as caracter\u00edsticas especificas dos dados.\n\n**Solu\u00e7\u00e3o**: realizar um `corte` na \u00e1rvore e limitar sua profundidade a 2.","33db4f0e":"Agora, com o hist\u00f3rico do treinamento que foi gerado, vamos criar uma visualiza\u00e7\u00e3o dos resultados.","aeb81969":"Com os pacotes carregados, inicialmente fa\u00e7a a convers\u00e3o dos dados categ\u00f3ricos que est\u00e3o presentes no conjunto de dados. Tal convers\u00e3o \u00e9 necess\u00e1ria para que os modelos de rede neural gerados pelo `Keras` consigam entender que os dados possuem o tipo categ\u00f3rico.","88ee487b":"Agora, vamos recuperar algumas informa\u00e7\u00f5es do conjunto de dados, sendo elas, a quantidade de atributos e classes presentes nos dados.","7c230813":"### \u00c1rvore de decis\u00e3o\n<hr style=\"border: 1px solid #0984e3;\">\n\nEsta se\u00e7\u00e3o apresenta a utiliza\u00e7\u00e3o do algoritmo `\u00c1rvore de decis\u00e3o` atrav\u00e9s da biblioteca de *machine learning* scikit-learn\n\nPara iniciar, todos os pacotes necess\u00e1rios para a utiliza\u00e7\u00e3o do algoritmo s\u00e3o importados.","29adcd35":"## Descri\u00e7\u00e3o dos dados utilizados\n\n<hr style=\"border: 1px solid #0984e3;\">\n\nNeste *notebook* foram utilizados dois conjuntos de dados para avaliar os algoritmos de classifica\u00e7\u00e3o e agrupamento. A base de dados utilizada nos m\u00e9todos supervisionados foi retirada do site [UCI](https:\/\/archive.ics.uci.edu\/ml\/datasets\/Forest+type+mapping#), tais dados foram usados no artigo publicado por [Johnson et al., (2012)](https:\/\/www.tandfonline.com\/doi\/full\/10.1080\/01431161.2011.629637?scroll=top&needAccess=true), denominado \"*Using geographically weighted variables for image classification*\", no qual utilizou-se os \u00edndices espectrais para classificar dois tipos de \u00e1rvores, *Cryptomeria japonica* (Sugi) e *Chamaecyparis obtusa* (Hinoki), e um tipo de floresta. A \u00e1rea de estudo apresentada na Figura 1 compreende a \u00e1rea florestal da prefeitura de Ibaraki do Jap\u00e3o. \n\n#### \u00c1rea de estudo\n\n<figure>\n  <img src=\"https:\/\/raw.githubusercontent.com\/dataAt\/ml-aplicado-dados-espacial\/master\/src\/img\/study_area.png\" alt=\"logo\">\n  <figcaption> Figura 1: Localiza\u00e7\u00e3o da \u00e1rea de estudo<\/figcaption>\n<\/figure>\n\n<br><br>\nAs imagens apresentadas acima foram imageadas pelo sensor ASTER a bordo do sat\u00e9lite Terra, nos per\u00edodos de Setembro de 2010, Mar\u00e7o de 2011 e Maio de 2011, respectivamente. \n\n`Observa\u00e7\u00e3o`: Os exemplos apresentados neste documento s\u00e3o feitos utilizando as bibliotecas [scikit-learn](https:\/\/scikit-learn.org\/stable\/), [keras](https:\/\/keras.io\/) e [Somoclu](https:\/\/github.com\/peterwittek\/somoclu)\n\n## M\u00e9tricas de avalia\u00e7\u00e3o dos modelos\n\n- \u00cdndice Kappa: Utilizado para medir o grau de concord\u00e2ncia entre amostras.\n- Score: Porcentagem de elementos classificados corretamente.\n\n## Aprendizado supervisionado\n\nEsta se\u00e7\u00e3o apresenta exemplos de t\u00e9cnicas de aprendizado de m\u00e1quina supervisionados. Para os exemplos foi feita a utiliza\u00e7\u00e3o dos dados gerados no artigo [Using geographically weighted variables for image classification](https:\/\/www.tandfonline.com\/doi\/full\/10.1080\/01431161.2011.629637).","9ae981a4":"![](http:\/\/cs231n.github.io\/assets\/nn1\/neural_net2.jpeg)","a5e5a672":"No plot gerado, foi poss\u00edvel perceber que a quantidade de elementos que nos traz os melhores resultados de predi\u00e7\u00e3o \u00e9 2, desta forma podemos fazer a aplica\u00e7\u00e3o do m\u00e9todo KNN utilizando `k` igual a 2.","91e114b2":"Tendo o modelo treinado, fa\u00e7amos a avalia\u00e7\u00e3o do modelo com o m\u00e9todo `evaluate`.","dfcaf8b6":"O modelo de rede neural criado possui 4 camadas, sendo elas:\n   - 1\u00b0 Camada: Entrada dos dados;\n   - 2\u00b0 Camada: Camada oculta;\n   - 3\u00b0 Camada: Camada oculta;\n   - 4\u00b0 Camada: Camada de sa\u00edda (Classifica\u00e7\u00e3o).\n   \nO modelo gerado \u00e9 igual ao exibido na Figura abaixo, retiradas das [notas de aula - CS231n](http:\/\/cs231n.github.io\/convolutional-networks\/)"}}