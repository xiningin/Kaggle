{"cell_type":{"33688fd2":"code","01fd7781":"code","f44ac18b":"code","2197021a":"code","964e7346":"code","8d061136":"code","0f9b837e":"code","29c8c64a":"code","10196b80":"code","8f489bbc":"code","cc3212ff":"code","5a175131":"code","a38a8a08":"code","3d782b41":"code","b51eb373":"markdown"},"source":{"33688fd2":"import sys\nsys.path.append(\"..\/input\/timm-pytorch-image-models\/pytorch-image-models-master\")","01fd7781":"import warnings\nimport sklearn.exceptions\nwarnings.filterwarnings('ignore', category=DeprecationWarning)\nwarnings.filterwarnings('ignore', category=FutureWarning)\nwarnings.filterwarnings(\"ignore\", category=sklearn.exceptions.UndefinedMetricWarning)\n\n# General\nimport tqdm.notebook as tqdm\nimport time\nimport math\nfrom sklearn import datasets\nfrom sklearn import model_selection\nfrom collections import defaultdict\nimport pandas as pd\nimport numpy as np\nimport os\nimport math\nimport pickle\nimport re\nimport shutil\nimport random\nimport gc\nimport cv2\nimport PIL\nimport glob\ngc.enable()\npd.set_option('display.max_columns', None)\n\n# Visialisation\nimport matplotlib.pyplot as plt\n%matplotlib inline\n# Image Aug\nimport albumentations\nfrom albumentations.pytorch.transforms import ToTensorV2\n\n# Deep Learning\nfrom torch.utils.data import Dataset, DataLoader\nfrom torch.optim.lr_scheduler import CosineAnnealingWarmRestarts, OneCycleLR, CosineAnnealingLR\nimport torch\nimport torchvision\nimport timm\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.optim as optim\nfrom torch.nn.parameter import Parameter\nfrom torch.nn.utils.rnn import pack_padded_sequence, pad_sequence\nfrom torch.optim import SGD, Adam, AdamW\n#Metrics\nfrom sklearn.metrics import accuracy_score\n# Device Optimization\nif torch.cuda.is_available():\n    device = torch.device('cuda')\nelse:\n    device = torch.device('cpu')\n    \nprint(f'Using device: {device}')","f44ac18b":"csv_dir = '..\/input\/animal-imbalance-classification'\ntrain_dir = '..\/input\/animal-imbalance-classification\/train.csv'\ntrain_img_dir = '..\/input\/animal-imbalance-classification\/train_images\/'\ntest_img_dir = '..\/input\/animal-imbalance-classification\/test_images\/'\nMODEL_PATH = \"..\/input\/baseline-effb0-train\/\"\n\n#train_file_path = '..\/input\/pawpular-folds\/train_5folds.csv'\nsample_sub_file_path = os.path.join(csv_dir, 'sample_submission.csv')","2197021a":"TRAIN_FOLDS = [0, 1, 2, 3, 4]\n\nclass CFG:\n    seed = 42 # seed\u5024\n    num_workers = 2 #\u4e26\u5217\u5b9f\u884c\u3059\u308b\u6570\n    batch_size = 256 #\u30d0\u30c3\u30c1\u30b5\u30a4\u30ba\n    epochs = 2 #\u30a8\u30dd\u30c3\u30af\u6570\n    size = 64 # \u30ea\u30b5\u30a4\u30ba\u3057\u305f\u5f8c\u306e\u753b\u50cf\u306e\u30b5\u30a4\u30ba\n    model_lr = 1e-3 # \u5b66\u7fd2\u7387\n    T_max = 10 # \u6700\u5927\u30a4\u30c6\u30ec\u30fc\u30b7\u30e7\u30f3\u6570\n    min_lr = 1e-7 # \u5b66\u7fd2\u7387\u306e\u6700\u5c0f\u5024\n    weight_decay = 1e-3 # \u5b66\u7fd2\u6e1b\u8870\u5024\n    max_grad_norm = 1000 # \u52fe\u914d\u306e\u6700\u5927\u30ce\u30eb\u30e0\n    print_freq = 1000 # \u5b66\u7fd2\u7d50\u679c\u3092\u8868\u793a\u3059\u308b\u983b\u5ea6\n    device = \"cuda\" if torch.cuda.is_available() else \"cpu\" # CPU of GPU\n    MODEL_NAME = \"tf_efficientnet_b0_ns\" # \u30e2\u30c7\u30eb\u540d\n    Version = \"V1\" # model save\u6642\u306eversion\n    class_num = 10\n    params = {\n    'epochs': 2,\n    'num_fold': len(TRAIN_FOLDS),\n    'scheduler_name': 'CosineAnnealingWarmRestarts',\n    'T_0': 5,\n    'T_max': 5,\n    'T_mult': 1,\n    'min_lr': 1e-7,\n    'max_lr': 1e-4\n}","964e7346":"def init_logger(log_file='train.log'):\n    \"\"\"Output Log.\"\"\"\n    from logging import getLogger, INFO, FileHandler,  Formatter,  StreamHandler\n    logger = getLogger(__name__)\n    logger.setLevel(INFO)\n    handler1 = StreamHandler()\n    handler1.setFormatter(Formatter(\"%(message)s\"))\n    handler2 = FileHandler(filename=log_file)\n    handler2.setFormatter(Formatter(\"%(message)s\"))\n    logger.addHandler(handler1)\n    logger.addHandler(handler2)\n    return logger\n\n\ndef seed_torch(seed=42):\n    \"\"\"Fixed seed value.\"\"\"\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n\n\nLOGGER = init_logger()\nseed_torch(seed=CFG.seed)","8d061136":"def asMinutes(s):\n    \"\"\"Convert Seconds to Minutes.\"\"\"\n    m = math.floor(s \/ 60)\n    s -= m * 60\n    return '%dm %ds' % (m, s)\n\n\ndef timeSince(since, percent):\n    \"\"\"Accessing and Converting Time Data.\"\"\"\n    now = time.time()\n    s = now - since\n    es = s \/ (percent)\n    rs = es - s\n    return '%s (remain %s)' % (asMinutes(s), asMinutes(rs))\n\nclass AverageMeter(object):\n    \"\"\"Computes and stores the average and current value.\"\"\"\n    def __init__(self):\n        self.reset()\n\n    def reset(self):\n        self.val = 0\n        self.avg = 0\n        self.sum = 0\n        self.count = 0\n\n    def update(self, val, n=1):\n        self.val = val\n        self.sum += val * n\n        self.count += n\n        self.avg = self.sum \/ self.count\n","0f9b837e":"class TestDataset(Dataset):\n    \"\"\"Dataset used for inference.\"\"\"\n    def __init__(self, df, transform=None):\n        self.df = df\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.df)\n\n    def __getitem__(self, idx):\n        image_path = self.df.image_id[idx]\n        #\u30ab\u30e9\u30fc\u306b\u3057\u3066\u308b\n        image_path = test_img_dir + image_path\n        image = np.array(PIL.Image.open(image_path))\n\n        if self.transform:\n            augmented = self.transform(image=image)\n            image = augmented['image']\n\n        return image","29c8c64a":"IMG_MEAN = [0.485, 0.456, 0.406]\nIMG_STD = [0.229, 0.224, 0.225]\n\ndef get_transforms(*, data, size):\n\n    if data == 'train':\n        return albumentations.Compose([\n            albumentations.Resize(size,size),\n            albumentations.Normalize(\n                mean=IMG_MEAN,\n                std=IMG_STD,\n            ),\n            albumentations.HorizontalFlip(p=0.5),\n            albumentations.VerticalFlip(p=0.5),\n            albumentations.Rotate(limit=180, p=0.7),\n            albumentations.ShiftScaleRotate(\n                shift_limit = 0.1, scale_limit=0.1, rotate_limit=45, p=0.5\n            ),\n            albumentations.HueSaturationValue(\n                hue_shift_limit=0.2, sat_shift_limit=0.2,\n                val_shift_limit=0.2, p=0.5\n            ),\n            albumentations.RandomBrightnessContrast(\n                brightness_limit=(-0.1, 0.1),\n                contrast_limit=(-0.1, 0.1), p=0.5\n            ),\n            \n            ToTensorV2(), # Tensor\u578b\u306b\u5909\u63db\n        ])\n\n    elif data == 'valid':\n        return albumentations.Compose([\n            albumentations.Resize(size,size),\n            albumentations.Normalize(\n                mean=IMG_MEAN,\n                std=IMG_STD,\n            ),\n            ToTensorV2(),\n        ])","10196b80":"class BaseModel(nn.Module):\n    def __init__(\n        self, model_name=CFG.MODEL_NAME, n_class=10, pretrained=False\n    ):\n        super().__init__()\n        self.backbone = timm.create_model(\n            model_name, pretrained=pretrained, num_classes = 0)\n        \n        self.in_features = self.backbone.num_features\n        self.head = nn.Sequential(\n                    nn.Linear(self.in_features, 1024),\n                    nn.ReLU(),\n                    nn.Dropout(),\n                    nn.Linear(1024, 512),\n                    nn.Dropout(),\n                    nn.Linear(512, n_class)\n                    )\n\n    def forward(self, x):\n        x = self.backbone(x)\n        x = self.head(x)\n        output = x\n        return output","8f489bbc":"def inference(test, class_num=CFG.class_num, n=1):\n    model = BaseModel(CFG.MODEL_NAME, class_num, pretrained=False)\n\n    model.load_state_dict(torch.load(f'{MODEL_PATH}\/{CFG.MODEL_NAME}_fold{n}_{CFG.Version}.pth')) # \u91cd\u307f\u306e\u8aad\u307f\u8fbc\u307f\n    model.to(CFG.device)\n    \n    test_dataset = TestDataset(test, transform=get_transforms(data='valid', size=CFG.size))\n    test_loader = DataLoader(test_dataset, batch_size=CFG.batch_size, shuffle=False, num_workers=CFG.num_workers)\n    \n    all_predicts = []\n    model.eval() # \u63a8\u8ad6\u30e2\u30fc\u30c9\n    with torch.no_grad(): # \u52fe\u914d\u306e\u8a08\u7b97\u3092\u3057\u306a\u3044\n        for i, (images) in tqdm.tqdm(enumerate(test_loader), total=len(test_loader)):\n            images = images.to(CFG.device)\n            y_preds = model(images)\n            predicts = y_preds.softmax(1).to(\"cpu\").numpy().argmax(1)\n            all_predicts.append(predicts)\n    \n    predicts = np.concatenate(all_predicts)\n        \n    return predicts","cc3212ff":"submit = pd.read_csv(sample_sub_file_path)","5a175131":"predicts = inference(submit, class_num=CFG.class_num, n=0)","a38a8a08":"submit[\"label\"] = predicts\nsubmit.to_csv('submission.csv', index=False) # csv\u3092\u66f8\u304d\u51fa\u3059","3d782b41":"submit","b51eb373":"# fold1\u306e\u30e2\u30c7\u30eb\u4f7f\u3063\u3066\u307e\u3059"}}