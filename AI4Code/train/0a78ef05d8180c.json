{"cell_type":{"a0982ed3":"code","5500576b":"code","0c3f2a4f":"code","97d90781":"code","498a1ab7":"code","80099713":"code","0c455b00":"code","61fa3b1d":"code","bac2e9c8":"code","c85f9359":"code","54c2de8e":"code","81f02eb3":"code","7dd79c52":"code","682ebc29":"code","43583f79":"code","99fba5ef":"code","4aea380f":"code","89cf5ca0":"code","e1e975cd":"code","79792942":"code","0e8b9f12":"markdown","f9a92f19":"markdown","6618ac93":"markdown","e9e7ffe2":"markdown"},"source":{"a0982ed3":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","5500576b":"df = pd.read_csv('\/kaggle\/input\/twitter-sentiment-analysis-hatred-speech\/train.csv')\ndf.head()","0c3f2a4f":"df.label.value_counts(ascending = False)","97d90781":"import nltk\nimport re\nfrom nltk.stem import WordNetLemmatizer\nfrom nltk.corpus import stopwords\nimport matplotlib.pyplot as plt\nimport seaborn as sns","498a1ab7":"#Data have some inpredictiable and useless character and also there are puncutations are present so will remove using Natural language preprocessing library and also we will remove stopwords.\nlem=WordNetLemmatizer()\n\ncorpus = []\nfor i in range(0, len(df)):\n    review = re.sub('[^a-zA-Z]', ' ', df['tweet'][i]) #Instead of Punctuations it just replacing with \" \".\n    review = review.lower() #Lowering each sentence\n    review = review.split() #After lowering and replacing puntucation will split the words\n    review = [lem.lemmatize(word) for word in review if not word in stopwords.words('english')] # Here we will drop words which are present in stopwords like ['can't,they,we,here,there].\n    review = ' '.join(review)\n    corpus.append(review) #All sentences are collect in corpus.","80099713":"corpus[7]","0c455b00":"# Creating the TF-IDF model\nfrom sklearn.feature_extraction.text import TfidfVectorizer #Using TFIDF vectorizer we will convert document in vector form.\ncv = TfidfVectorizer(max_features = 7777,ngram_range = (1,3))\nx= cv.fit_transform(corpus).toarray()\nx","61fa3b1d":"x.shape","bac2e9c8":"y = df.loc[:,['label']]\ny","c85f9359":"# Train Test Split\n\nfrom sklearn.model_selection import train_test_split\nX_train, X_test, y_train, y_test = train_test_split(x, y, test_size = 0.20, random_state = 0)\nprint('Training data:{}'.format(X_train.shape))\nprint('Test data:{}'.format(X_test.shape))","54c2de8e":"cv.get_feature_names()[:20]","81f02eb3":"cv.get_params()","7dd79c52":"count_df = pd.DataFrame(X_train, columns=cv.get_feature_names())\n\ncount_df","682ebc29":"from sklearn.naive_bayes import MultinomialNB\nclf=MultinomialNB()\nclf.fit(X_train,y_train)\ny_predicted = clf.predict(X_test)\nscore = clf.score(X_test,y_test)\nprint(score)","43583f79":"from sklearn.metrics import confusion_matrix\n\n#Confusion Matrix\n# Compute confusion matrix\ncnf_matrix = confusion_matrix(y_test, y_predicted)\nnp.set_printoptions(precision=2)\ncnf_matrix","99fba5ef":"test = pd.read_csv('\/kaggle\/input\/twitter-sentiment-analysis-hatred-speech\/test.csv')\ntest.head()","4aea380f":"text_corpus = []\nfor i in range(0, len(test)):\n    review = re.sub('[^a-zA-Z]', ' ', test['tweet'][i])\n    review = review.lower()\n    review = review.split()\n    review = [lem.lemmatize(word) for word in review if not word in stopwords.words('english')]\n    review = ' '.join(review)\n    text_corpus.append(review)","89cf5ca0":"# Creating the TF-IDF model\nfrom sklearn.feature_extraction.text import TfidfVectorizer\ntest_cv = TfidfVectorizer(max_features = 7777,ngram_range = (1,3))\nx= test_cv.fit_transform(text_corpus).toarray()\nx","e1e975cd":"test_df = pd.DataFrame(x, columns=test_cv.get_feature_names())\n\ntest_df","79792942":"test_y = clf.predict(test_df)\ntest_y","0e8b9f12":"# 2. Import Data","f9a92f19":"# 3. Data Cleaning and preprocessing","6618ac93":"# 1.Import Libarries","e9e7ffe2":"# 4.Built model"}}