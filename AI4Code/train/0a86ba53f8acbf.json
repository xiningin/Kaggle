{"cell_type":{"265132dd":"code","ed649a4e":"code","79e4c735":"code","46942a79":"code","b4b4f204":"code","89770fbf":"code","161fa7b8":"code","81270035":"code","9ced86b5":"code","f6e39c0e":"code","de0c8e4c":"code","55fc99d8":"code","ac18585e":"code","7f8eb791":"code","db632cc9":"code","6a55efa9":"code","84597666":"code","8efac12f":"code","b99804b9":"code","22b7de29":"code","d845c6d8":"code","32859de2":"code","3aa3410c":"code","4d083e69":"code","ed1a9b8d":"code","e368024a":"code","9cf89628":"code","6cac65c0":"code","d49145a1":"code","9c537bb0":"code","00fff5fd":"code","58780347":"code","ed869bc9":"code","33e8742a":"code","86c8a0bf":"code","ed4b3d75":"markdown","3047e771":"markdown","45d6b9be":"markdown","82c075fa":"markdown","3f1b2fb6":"markdown","cf5aa4df":"markdown","fbcdccdf":"markdown","af6746b4":"markdown","490dabb5":"markdown","0eccdc94":"markdown","233a70ba":"markdown","b74d7b87":"markdown","f8b06dd3":"markdown","c209441b":"markdown","3a161a2f":"markdown","ff779e56":"markdown","615c2c84":"markdown","2ac940d1":"markdown","d1c0c207":"markdown","b6840f05":"markdown","fa40a9f0":"markdown","bb9c98b3":"markdown","1d621425":"markdown","7e56bb90":"markdown"},"source":{"265132dd":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python Docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\nimport seaborn as sns \nimport matplotlib.pyplot as plt\n\n# Input data files are available in the read-only \"..\/input\/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (\/kaggle\/working\/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to \/kaggle\/temp\/, but they won't be saved outside of the current session","ed649a4e":"df = pd.read_csv('\/kaggle\/input\/heart-disease-uci\/heart.csv')\ndf.head()","79e4c735":"df.shape","46942a79":"df.dtypes","b4b4f204":"df.isnull().any()","89770fbf":"sns.countplot(x='target',data=df)\nplt.show()","161fa7b8":"## lower traingluar mask as correlation matrix is symmetric \nplt.figure(figsize=(10,10)) ## setting the size of the plot \nlower_triangle_mask  = np.zeros_like(df.corr())## a matrix of 0s whcih has same shape as df.corr()\nlower_triangle_mask[np.triu_indices_from(lower_triangle_mask)]  = True ## setting the lower triangle indices to 1 for our mask \nsns.heatmap(df.corr()*100 , mask = lower_triangle_mask , cmap = 'RdBu_r',fmt='.0f',annot=True)\nplt.show()","81270035":"## now we create a new feature exercise intensity which gives us the differnce between the estimated\n## maximum heart rate and the maximum heart rate actually achieved which is thalach column \ndf['exercise_intensity'] = 220 -df['age'] - df['thalach']\n## plot of this variable to see if it really helps us predict heart disease \nsns.swarmplot(x='target',y='exercise_intensity',data=df,color='0.2')\nsns.violinplot(x='target',y='exercise_intensity',data=df)\nplt.show()","9ced86b5":"df.loc[df['exercise_intensity'] < 20,'exercise_intensity'] = 1\ndf.loc[df['exercise_intensity'] >= 20,'exercise_intensity'] = 0","f6e39c0e":"## exercise intensity countplot \nsns.barplot(x='exercise_intensity',y='target',data=df)\nplt.show()","de0c8e4c":"sns.countplot(x='exang',hue='target',data=df)\nplt.show()\nsns.countplot(x='cp',hue='target',data=df)\nplt.show()","55fc99d8":"df.loc[ (df.cp == 0)|(df.exang == 1) ,'angina_combined'] = 0\ndf.loc[(df.cp != 0)|(df.exang == 0),'angina_combined' ] = 1 \nsns.countplot(x='angina_combined',hue='target',data=df)\nplt.show()","ac18585e":"g = sns.FacetGrid(row='slope',col='target',data=df)\ng.map_dataframe(sns.histplot,'oldpeak',bins=15)\nplt.show()","7f8eb791":"df.loc[(df.oldpeak <= 2 )& (df.slope == 0) ,'ST_dep'] = 1\ndf.loc[(df.oldpeak > 2) & (df.slope == 0 ),'ST_dep'] = 0\ndf.loc[(df.oldpeak <= 2) & (df.slope == 1),'ST_dep'] = 0\ndf.loc[(df.oldpeak > 2) & (df.slope == 1),'ST_dep'] = 0\ndf.loc[(df.oldpeak <= 2) & (df.slope == 2),'ST_dep'] = 1\ndf.loc[(df.oldpeak > 2) & (df.slope == 2),'ST_dep'] = 0","db632cc9":"sns.countplot(x='ST_dep',hue='target',data=df)\nplt.show()","6a55efa9":"sns.countplot(x='sex',hue='target',data=df)\nplt.show()","84597666":"g=sns.FacetGrid(data=df,row='target',col='sex')\ng.map_dataframe(sns.histplot,'age',bins=40)\nplt.show()","8efac12f":"df.loc[df.sex==0,'age_sex']=1\ndf.loc[(df.sex == 1) &(df.age <= 40),'age_sex']= 1\ndf.loc[(df.sex == 1) &(df.age > 40)&(df.age <= 50),'age_sex']=1\ndf.loc[(df.sex == 1) &(df.age > 50)&(df.age <= 60),'age_sex']=0\ndf.loc[(df.sex == 1) &(df.age > 60),'age_sex']=0","b99804b9":"sns.countplot(x='age_sex',hue='target',data=df)\nplt.show()","22b7de29":"sns.countplot(x='restecg',hue='target',data=df)\nplt.show()","d845c6d8":"f = sns.FacetGrid(data=df,col='ca')\nf.map_dataframe(sns.countplot,'restecg' , hue='target')\nf.add_legend()\nplt.show()","32859de2":"df.loc[(df.ca == 0 )& (df.restecg == 0) , 'ca_new'] = 1\ndf.loc[(df.ca == 0) & (df.restecg == 1) , 'ca_new']  = 1\ndf.loc[(df.ca == 1) & (df.restecg == 0) , 'ca_new'] = 0\ndf.loc[(df.ca == 1) & (df.restecg == 1) , 'ca_new'] = 0.5\ndf.loc[(df.ca == 2) & (df.restecg == 0) , 'ca_new'] = 0\ndf.loc[(df.ca == 2) & (df.restecg == 1), 'ca_new'] = 0.5\ndf.loc[(df.ca == 3) & (df.restecg == 0) , 'ca_new'] = 0\ndf.loc[(df.ca == 3) & (df.restecg == 1) , 'ca_new'] = 0.5\ndf.loc[(df.ca == 4) & (df.restecg == 0) , 'ca_new'] = 1\ndf.loc[(df.ca == 4) & (df.restecg == 1) , 'ca_new'] = 1\ndf.loc[df.restecg == 2 ,'ca_new'] = 0","3aa3410c":"df","4d083e69":"y = df.target\nX =df.drop(['age','sex','cp','trestbps','chol','fbs','exang','oldpeak','slope','thalach','restecg','ca','target'],axis=1)\nX_final = pd.get_dummies(X,columns=['thal'])\nX_final","ed1a9b8d":"from sklearn.model_selection import train_test_split\nfrom sklearn.ensemble import RandomForestClassifier\nfrom sklearn.model_selection import cross_val_score\nfrom sklearn.linear_model import LogisticRegression \nfrom sklearn.metrics import accuracy_score\nfrom sklearn.neighbors import KNeighborsClassifier\nfrom sklearn.model_selection import GridSearchCV\nfrom sklearn.svm import SVC \nX_train , X_test , y_train , y_test = train_test_split(X_final,y,test_size = 0.2,random_state = 12)","e368024a":"knn_2 = KNeighborsClassifier() \nparam_grid = {\"n_neighbors\": np.arange(1, 25)}\nknn_gscv = GridSearchCV(knn_2, param_grid, cv=5)\nknn_gscv.fit(X_train, y_train)","9cf89628":"knn_gscv.best_params_","6cac65c0":"print(\"cross_val_score\",cross_val_score(KNeighborsClassifier(n_neighbors=9),X_train,y_train,cv=5,scoring='accuracy').mean())\nfinal_knn = KNeighborsClassifier(n_neighbors=9)\nfinal_knn.fit(X_train,y_train)\nprint(\"test_score\",accuracy_score(final_knn.predict(X_test),y_test))","d49145a1":"param_grid = {'C': [0.1,1, 10, 100], 'gamma': [1,0.1,0.01,0.001],'kernel': ['rbf', 'poly', 'sigmoid']}\ngrid = GridSearchCV(SVC(),param_grid,refit=True,verbose=2)\ngrid.fit(X_train,y_train)","9c537bb0":"grid.best_params_","00fff5fd":"print(\"cross_val_score\",cross_val_score(SVC(C = 10 , gamma = 0.01 , kernel ='rbf'),X_train,y_train,cv=5,scoring='accuracy').mean())\nSVM_final = SVC(C = 10 , gamma = 0.01 , kernel ='rbf')\nSVM_final.fit(X_train,y_train)\nprint(\"test_score\",accuracy_score(SVM_final.predict(X_test),y_test))","58780347":"scores = cross_val_score(LogisticRegression(),X_train,y_train,cv=5,scoring='accuracy')\nprint(\"cross_val_score\",scores.mean())\nlog_final = LogisticRegression()\nlog_final.fit(X_train,y_train)\nprint(\"test_Score\",accuracy_score(log_final.predict(X_test),y_test))","ed869bc9":"## Function to get the correct number of estimators \ndef get_score(param):\n    scores = cross_val_score(RandomForestClassifier(param,random_state = 0),X_train,y_train,cv=5,scoring='accuracy')\n    return scores.mean()","33e8742a":"dic = {x : get_score(x) for x in [100,200,300,400,500,600,700]}\nplt.plot(dic.keys(),dic.values())\nplt.show()","86c8a0bf":"rf_final = RandomForestClassifier( 100,random_state = 0)\nrf_final.fit(X_train,y_train)\nprint(\"cross_val_score\",get_score(100))\nprint(\"test_score\",accuracy_score(rf_final.predict(X_test),y_test))","ed4b3d75":"### KNN","3047e771":"From the countplots it can be seen that if you are a male then it's not exactly clear whether you have heart disease or not <br>\n\nIf we research a little we find out that Age , Gender and heart disease are realted and men can develop heart disease at younger ages and after 65 the risk for men and women becomes the same <br>\nReference : https:\/\/wa.kaiserpermanente.org\/healthAndWellness\/index.jhtml?item=%2Fcommon%2FhealthAndWellness%2Fconditions%2FheartDisease%2FageAndGender.html\n<br>\n\nWe can combine age and sex to create a new feature age_sex which would be better predictor of heart disease for men using a facet grid <br>\n* sex = 0 then quite clearly you have a high risk for heart disease \n* males under the age of 40 also have a high risk for heart disease in this dataset\n* males between 40 and 50 also are at high risk  \n* surprisingly , males above 50 have a low risk for heart disease \n\n\n","45d6b9be":"Cp (chest pain) is the variable with highest correlation with target <br> \nReading the Data description , \n\n* 0- typical angina<br>\n* 1- atypical angina<br>\n* 2- non-anginal pain <br>\n* 3- asymptomatic<br>\n\n So it is related to exang which is exercise induced angina , We can combine these two into one feature , grouping the types of angina  which have high risk of heart disease into one group and the types which have less risk of heart disease into another group  ","82c075fa":"### Random Forests ","3f1b2fb6":"* Cholestrol (chol) and resting blood pressure (trestbps) have all values concentrated within the 220-270 and 120 above range which are high values for blood pressure and cholestrol already . Values of cholestrol above 240 are considered to be risky for heart disease and values above 130 for blood pressure . Almost all the values here are above these thresholds . So I decided to drop these two features\n* Age and Sex have been combined and we have used age feature in exrecise intensity as well so we can drop those two \n* Exang and cp can also be dropped as we have that information in angina_combined , oldpeak and slope are also dropped for the same reason \n* Thalach has been used in exercise intensity so we will drop it \n* fbs(fasting blood sugar) is a highly imbalanced variable and almost all the data points have fbs = 0 .We will drop this feature \n","cf5aa4df":"### SVM ","fbcdccdf":"Plot shows that if ca = 0  then even people with normal ecg have high risk which confirms the research . We can combine rest ecg results and the ca variable to make ca_new ","af6746b4":"### Thalach and Exercise intensity ","490dabb5":"## EDA - Exploratory Data Analysis and Feature engineering","0eccdc94":"* Exercise induced angina and typical angina can be grouped together as both have low risk of heart disease\n* Atypical angina , asymptomatic and non anginal pain can be grouped together as they have high risk of heart disease","233a70ba":"### Chest Pain (cp) and Angina induced pain ","b74d7b87":"## Modelling and hyperparameter tuning ","f8b06dd3":" We can safely remove both exang and cp from our feature set as we have combined the information provided by both of them into one feature ","c209441b":"* Value 0: normal\n* Value 1: having ST-T wave abnormality (T wave inversions and\/or ST elevation or depression of > 0.05 mV)\n* Value 2: showing probable or definite left ventricular hypertrophy by Estes' criteria\n\nFor value 0 , risk of heart disease is 50-50 and a little research about that tells us why . Ecg results in rest state cannot detect asymptomatic blockages in the arteries . But we know that ca(number of blood vessels colored by flouroscopy) tells us if such a blcokage exists . For lower values of ca like 0 it may be that the arteries are blocked and ecg is still normal \n\nRef : https:\/\/choosingwiselycanada.org\/ecg-electrocardiogram\/#:~:text=However%2C%20it%20does%20not%20show,ECG%20or%20cardiac%20imaging%20test.\n\nWe can confirm this with the plot below ","3a161a2f":"### Sex and Age ","ff779e56":"#### 1. Train-Test split","615c2c84":"### Oldpeak and Slope ","2ac940d1":"1. As we can see from the heatmap , The correlation values are not that high between any of the variables . The highest value is -58 between slope and oldpeak and the target variable has highest correlation with cp(chest pain) \n\n2. **Thalach is the only variable in the dataset which has comparatively high correlations** with many variables like target , slope , age , oldpeak , exang  and cp . This looks like an important variable in the dataset .According to the data description , thalach is maximum heart rate achieved \n\nA Quick google search reveals that maximum heart rate achieved is linked to exercise intensity and can be estimated by the formula  220 - Age \n\nReference : https:\/\/www.mayoclinic.org\/healthy-lifestyle\/fitness\/in-depth\/exercise-intensity\/art-20046887#:~:text=You%20can%20calculate%20your%20maximum,beat%20per%20minute%20during%20exercise.","d1c0c207":"### Features to be dropped ","b6840f05":"We can drop oldpeak and slope now from the dataset ","fa40a9f0":"### Rest ecg results and blocked arteries(ca)","bb9c98b3":"* **If exercise_intensity is less than 20 then we can say the chance of getting heart disease is high** and there's also a high chance the person doesnt have exercise induced angina . THerefore we could use that to modify exercise_intensity so that it takes value 1 when less than 20 and value 0 otherwise\n\nThis would capture information stored in thalach perfectly ","1d621425":"Oldpeak is another feature which has a decent amount of correlation with the target variable . Data Description tells us it is  the ST depression induced by exercise relative to rest . Slope has high correlation with this variable and we can combine the two into one variable using a Facet Grid \n\n* Slope = 0 and oldpeak <= 2  implies a higher risk of heart disease \n* Slope = 0 and oldpeak > 2 implies low risk for heart disease \n* Slope = 1 and oldpeak <= 2 implies low risk for heart disease\n* Slope = 1 and oldpeak > 2 implies low risk for heart disease\n* Slope = 2 and oldpeak <= 2 implies high risk for heart disease\n* Slope = 2 and oldpeak > 2 implies low risk for heart disease","7e56bb90":"### Logistic Regression "}}