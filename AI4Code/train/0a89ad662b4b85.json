{"cell_type":{"0a2e7781":"code","b6e140b6":"code","6e9e2322":"code","e0a64f71":"code","585e33a5":"code","44b2b247":"code","8ee424a1":"code","8ae40724":"code","dad4d87e":"code","2208c0b6":"code","d03a2cf9":"code","ba3f9da1":"code","d570d7bd":"code","42a485c4":"code","e893dcd0":"code","d8ad46f8":"code","2c56df3c":"code","92d0f7de":"code","045f1ef3":"code","804d9594":"code","18b4cb68":"code","3e8980d4":"code","bdf62274":"code","a9e54234":"code","12db7062":"code","81d719a0":"code","5b781a9f":"code","803e5c78":"code","db1a37f3":"code","08ef10e5":"markdown","fb11fbab":"markdown","4e8a65b5":"markdown","e1b51c57":"markdown","1f126859":"markdown","03671500":"markdown","ee5befee":"markdown","5e054a6f":"markdown","fba30187":"markdown","dfb8f45e":"markdown","2391b477":"markdown","1bf0ac60":"markdown","1cbbfd10":"markdown","8c1d2c55":"markdown","1813b2b2":"markdown","f2d11aee":"markdown","b6f1d845":"markdown","65882497":"markdown"},"source":{"0a2e7781":"from google.colab import drive\ndrive.mount('\/content\/drive')","b6e140b6":"!pip install fastai2 -q\n!pip install scikit-multilearn -q\n!pip install arff -q","6e9e2322":"import os\nimport numpy as np\nimport pandas as pd\nfrom pathlib import Path\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nfrom skmultilearn.model_selection import IterativeStratification\nfrom sklearn.metrics import recall_score\n# from skmultilearn.model_selection import iterative_train_test_split\nfrom fastai2.vision import *\nfrom fastai2.vision.all import *\nfrom fastai2.vision.widgets import *\nfrom fastai2.basics import *\nfrom sklearn.metrics import f1_score","e0a64f71":"# DATA_DIR = '..\/input\/jovian-pytorch-z2g\/Human protein atlas'\n# TRAIN_DIR = DATA_DIR + '\/train'                           \n# TEST_DIR = DATA_DIR + '\/test'                             \n# TRAIN_CSV = DATA_DIR + '\/train.csv'                       \n# TEST_CSV = '..\/input\/jovian-pytorch-z2g\/submission.csv' ","585e33a5":"#Google Collab\nDATA_DIR = '\/content\/Human protein atlas'\nTRAIN_DIR = DATA_DIR + '\/train'                           # Contains training images\nTEST_DIR = DATA_DIR + '\/test'                             # Contains test images\nTRAIN_CSV = DATA_DIR + '\/train.csv'                       # Contains real labels for training images\nTEST_CSV = '\/content\/submission.csv'                      # Contains dummy labels for test image\nmodel = '\/content\/drive\/My Drive\/model\/proteinfast_b0_12x001_001'","44b2b247":"\n# fnames = get_image_files(TRAIN_DIR)\n# ds = Datasets(fnames, tfms=Pipeline([PILImage.create, Resize(256), ToTensor]))\n# dl = TfmdDL(ds, bs=32,after_batch=[IntToFloatTensor],drop_last=True)\n\n# mean, std = 0., 0.\n# for b in progress_bar(dl):\n#   mean += b[0].mean((0,2,3))\n#   std += b[0].std((0,2,3))\n\n# print((mean\/len(fnames)))\n# print(std\/len(fnames))","8ee424a1":"#this code is used to check the GPU in google collab, so we can adjust the batch size based on the GPU memory\n!nvidia-smi -l 1","8ae40724":"SEED = 13\nnfolds = 5\ndef seed_everything(seed):\n    random.seed(seed)\n    os.environ['PYTHONHASHSEED'] = str(seed)\n    np.random.seed(seed)\n    torch.manual_seed(seed)\n    torch.cuda.manual_seed(seed)\n    torch.backends.cudnn.deterministic = True\n    torch.backends.cudnn.benchmark = True\nseed_everything(SEED)","dad4d87e":"#Helper Functions\n\nclass FocalLoss(BaseLoss):       \n    def __init__(self, *args, axis=-1, floatify=True, thresh=0.5, **kwargs):\n        super().__init__(nn.BCEWithLogitsLoss, *args, axis=axis, floatify=floatify, is_2d=False, **kwargs)\n        self.thresh = thresh\n        self.alpha = alpha = 1\n        self.gamma = gamma = 2\n        self.logits = logits =True\n        self.reduce = reduce\n        \n    def decodes(self, x):    return x>self.thresh\n    def activation(self, x): return torch.sigmoid(x)\n\n    def forward(self, inputs, targets):\n#         inputs = nn.LogSigmoid(imputs)\n        if self.logits:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        else:\n            BCE_loss = F.binary_cross_entropy_with_logits(inputs, targets, reduction='none')\n        pt = torch.exp(-BCE_loss)\n        F_loss = self.alpha * (1-pt)**self.gamma * BCE_loss\n\n        if self.reduce:\n            return torch.mean(F_loss)\n        else:\n            return F_loss\n\ndef encode_label(label):\n    target = torch.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1.\n    return target\n\ndef decode_target(target, text_labels=False, threshold=0.5):\n    result = []\n    for i, x in enumerate(target):\n        if (x >= threshold):\n            if text_labels:\n                result.append(labels[i] + \"(\" + str(i) + \")\")\n            else:\n                result.append(str(i))\n    return ' '.join(result)\n\ndef encode_array(label):\n    target = np.zeros(10)\n    for l in str(label).split(' '):\n        target[int(l)] = 1\n    return target\ndef encode_test(label):\n    target = [0,0,0,0,0,0,0,0,0,0]\n    return target\n\ndef F_score(output, label, threshold=0.5, beta=1):\n    prob = output > threshold\n    label = label > threshold\n\n    TP = (prob & label).sum(1).float()\n    TN = ((~prob) & (~label)).sum(1).float()\n    FP = (prob & (~label)).sum(1).float()\n    FN = ((~prob) & label).sum(1).float()\n\n    precision = torch.mean(TP \/ (TP + FP + 1e-12))\n    recall = torch.mean(TP \/ (TP + FN + 1e-12))\n    F2 = (1 + beta**2) * precision * recall \/ (beta**2 * precision + recall + 1e-12)\n    return F2.mean(0)\n\n#from https:\/\/www.kaggle.com\/iafoss\/pretrained-resnet34-with-rgby-0-460-public-lb\n\ndef sigmoid_np(x):\n    return 1.0\/(1.0 + np.exp(-x))\n\ndef F1_soft(preds,targs,th=0.0,d=25.0):\n    preds = sigmoid_np(d*(preds - th))\n    targs = targs.astype(np.float)\n    score = 2.0*(preds*targs).sum(axis=0)\/((preds+targs).sum(axis=0) + 1e-6)\n    return score\n\ndef fit_val(x,y):\n    params = np.zeros(len(labels))\n    wd = 1e-5\n    error = lambda p: np.concatenate((F1_soft(x,y,p) - 1.0,\n                                      wd*p), axis=None)\n    p, success = opt.leastsq(error, params)\n    return p\n\n","2208c0b6":"labels = {\n    0: 'Mitochondria',\n    1: 'Nuclear bodies',\n    2: 'Nucleoli',\n    3: 'Golgi apparatus',\n    4: 'Nucleoplasm',\n    5: 'Nucleoli fibrillar center',\n    6: 'Cytosol',\n    7: 'Plasma membrane',\n    8: 'Centrosome',\n    9: 'Nuclear speckles'\n}","d03a2cf9":"\ndf_test = pd.read_csv(TEST_CSV)\ndf_test['imgPath'] = df_test.apply(lambda x : os.path.join(TEST_DIR,str(x['Image'])+'.png'),axis=1)\n","ba3f9da1":"indexes = {v:k for k,v in labels.items()}","d570d7bd":"def create_split(nfolds=5):\n    df = pd.read_csv(TRAIN_CSV).sort_values(\"Image\").reset_index(drop=True)\n    df['imgPath'] = df.apply(lambda x : os.path.join(TRAIN_DIR,str(x['Image'])+'.png'),axis=1)\n    submission = pd.read_csv(TEST_CSV)\n    submission['imgPath'] = submission.apply(lambda x : os.path.join(TEST_DIR,str(x['Image'])+'.png'),axis=1)\n    split_df = pd.get_dummies(df.Label.str.split(' ').explode())\n    split_df = split_df.groupby(split_df.index).sum()\n    X, y = split_df.index.values, split_df.values\n    k_fold = IterativeStratification(n_splits=nfolds, order=3)\n    splits = list(k_fold.split(X, y))\n    fold_splits = np.zeros(df.shape[0]).astype(np.int)\n    for i in range(nfolds):\n        fold_splits[splits[i][1]]=i\n    df['Split'] = fold_splits\n    df_folds = []\n    for fold in range(nfolds):\n        df_fold = df.copy()\n        df_fold['is_valid'] = False\n        df_fold.loc[df_fold.Split==fold,'is_valid'] = True\n        df_folds.append(df_fold)\n    return df_folds\n#Create a list of Dfs\ndfs = create_split()","42a485c4":"# imagenet_stats = ([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\nsize = 512\ndef get_x(r): return r['imgPath']\ndef get_y(r): return r['Label'].split(' ')\n\ndef splitter(df):\n    train = df.index[~df['is_valid']].to_list()\n    valid = df.index[df['is_valid']].to_list()\n    return train, valid\n\ndblock = DataBlock(blocks=(ImageBlock, MultiCategoryBlock),\n                    get_x = get_x, \n                    get_y = get_y,\n                    item_tfms=Resize(size),\n                    splitter=splitter, \n                    batch_tfms=[Normalize.from_stats([0.0025, 0.0017, 0.0017], [0.0040, 0.0030, 0.0047]),\n                              *aug_transforms(mult=1.0, \n                                      do_flip=True, \n                                      flip_vert=True,\n                                      max_rotate=45.0, \n                                      max_zoom= 1.2, \n                                      max_lighting=0.1, \n                                      max_warp=0.1, \n                                      p_affine=0.1, \n                                      p_lighting=0.1, \n                                      xtra_tfms=None, \n                                      size=size, \n                                      mode='bilinear', \n                                      pad_mode='reflection', \n                                      align_corners=True, \n                                      min_scale=1.0)])","e893dcd0":"# #######################################epoch \ttrain_loss \tvalid_loss \taccuracy_multi \tF_score \tf1_score \ttime\n# arch1 = xresnet50(n_out=10)           #  3 \t     0.246077 \t 0.242087 \t  0.905596 \t    0.521767 \t0.470186 \t03:18\n# arch2 = xse_resnet50(n_out=10)        #  3  \t 0.272805 \t 0.264964 \t  0.895393  \t0.439709 \t0.374226 \t03:29\n# arch3 = xse_resnext50_deep(n_out=10)  #  3  \t 0.257749 \t 0.254541 \t  0.902160  \t0.478620 \t0.427855 \t03:15\n# arch4 = xse_resnext50_deeper(n_out=10)#  3  \t 0.274632 \t 0.266044 \t  0.895211  \t0.432996 \t0.376255 \t03:12\n# arch5 = xse_resnext34_deeper(n_out=10)#  3  \t 0.239569 \t 0.234023 \t  0.909422  \t0.549067 \t0.508727 \t03:05\n","d8ad46f8":"#T\narch = xresnet50(n_out=10, pretrained=False )\ndf = dfs[0]# next already\ndls = dblock.dataloaders(df, bs=8)\nlearn = Learner(dls, arch, metrics=[partial(accuracy_multi, thresh=0.5),partial(F_score, threshold=0.5),F1ScoreMulti(), RecallMulti()]) #No focalloss\nlearn.load('model')\nlearn.dls = dblock.dataloaders(df, bs=8)","2c56df3c":"learn.lr_find()","92d0f7de":"learn.clip = 1\nlr = 0.001\nlearn.fit_one_cycle(12, lr=slice(lr\/1000, lr\/100, lr))\n","045f1ef3":"learn.save(model'+_12ep')\n","804d9594":"dl = learn.dls.test_dl(df_test)\npred = learn.get_preds(dl=dl, reorder = False)\n","18b4cb68":"predictions = [decode_target(x, threshold=0.35) for x in pred[0]] # Get predicitons using the treshold\n","3e8980d4":"predict=pred[0].numpy()","bdf62274":"stats= pd.DataFrame(predict)","a9e54234":"stats.to_csv('foldx.csv', index=False)","12db7062":"submission_df = pd.read_csv(TEST_CSV)\nsubmission_df.Label = predictions\nsub_fname = 'fastai2_foldx.csv'\nsubmission_df.to_csv(sub_fname, index=False)","81d719a0":"!pip install jovian --upgrade --quiet","5b781a9f":"import jovian","803e5c78":"project_name='protein2-fastai-focalloss'","db1a37f3":"jovian.commit(project=project_name, environment=None)","08ef10e5":"**I have tried many learning rates**\n*  Started using 1e-3 (8 epochs) Image 128\n*  Trained using 1e-3 (12 epochs) Image 256\n*  Trained for 12 epochs (1e-7)\n*  Trained for another 12 epochs (1e-8)","fb11fbab":"**Saved the model for each trainning - very important.\n\nI lost a lot of time because I was training all at once and my internet \/ computer \/ kaggle \/ collab \/ something always got wrong and I had to start all from beggining**","4e8a65b5":"**I started using a loop to run the 5 folds, but was taking forever, so I moved to Collab and run 2 folds in parallel using 2 G accounts.\nSo I create the model (usually load the already trainned model and keep trainning using the new Image size and batch size**","e1b51c57":"**Fastai2 has to be installed in kaggle\/collab, so internet has to be on\nThe scikit multilearn to split the data. I dont remember were arff was needed.**","1f126859":"**This is the code I used to get the mean and std of the figures, good practive when transfer learning is not in use**","03671500":"**Ths is the code used to download and use the Google Collab GPUs**","ee5befee":"**I have made my own Focal loss which has been described to works better with multiclassification of imbalanced data.\nAlthough I spent a lot of time reading fastai and pytorch source code to make my own loss, it didnt helped much in the end, so I finish not using it**","5e054a6f":"**Fastai function to find the learning rate of the last layer (freezing all others)**","fba30187":"I have tested this models using 4 epochs using the same leraning rate to choose the best candidate xresnet50","dfb8f45e":"# Get predictions","2391b477":"## **Data block**\nDatablock is how fastai deal with the data to form the dataloader to the leraner.\nI started trainning with smaller images (128, 256 and lastly 512)\nI used the get_x and get_y functions from the https:\/\/www.kaggle.com\/bismillahkani\/protein-classification-using-fastai2\nNot many transformations were applied in my dataset (I starting testing without many transformations and after training a fold I didnt want to re-train, so I keept the same) - Probably a mistake, given that was overfitted ","1bf0ac60":"## **Split data for cross validation**\n**This function split the dataset and create a list of datasets**","1cbbfd10":"## Trainning loop\n\n* Define model\n* Run loop\n* Save Results","8c1d2c55":"**Its a good idea to save everything (model and data and code) in the Gdrive, save me a lot of time**","1813b2b2":"**I saved all predictions not decoded in CSV so I could average them to make the submission**","f2d11aee":"# Zero to GANs course competition using FASTAI2\n### 8th place in public leaderboard and 18th in the private\n","b6f1d845":"**I use cross validation of 5 folds. Divide the data set in 5 different 80% training and 20% validation\nIt is important to keep all the same for everytime we run the code, thats why this code below is important**","65882497":"To get the predictions I had to use reorder = False, as I was getting my data Shuffled all the time.\n"}}