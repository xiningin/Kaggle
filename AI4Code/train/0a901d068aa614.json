{"cell_type":{"83c139f6":"code","7725d35a":"code","173a3184":"code","fd992086":"code","bb77b285":"code","6302c768":"code","db9cd378":"code","43bc3bb6":"code","e171c749":"code","b37693ac":"code","27467c1c":"code","5dd1f00a":"code","7cf3567a":"code","907ab52a":"code","eb7c6795":"code","1329596d":"code","760cbe8c":"code","53ff07ef":"code","05def230":"code","f7e7ac09":"code","bbc32444":"code","0e62a053":"code","54651961":"code","2ee14a94":"code","04788c1b":"code","f9f86f7e":"code","0fe38d91":"code","0c91ec47":"code","ab8d12ce":"code","6cc62156":"code","101eebe1":"code","6723e4ae":"code","91912084":"code","3e4e9a00":"code","0572d034":"code","bc8eb2f9":"code","9885b3c3":"code","d45d8b5f":"code","5b6923fd":"code","1d58cc3e":"code","5a35f5e1":"code","5f3af305":"code","e8632901":"code","1c5ba433":"code","1bad37c6":"code","c6082e02":"code","1a21c278":"code","a612b0cb":"code","522dac55":"markdown","774bd708":"markdown","58c8cf5a":"markdown","c1cd2067":"markdown","de02b196":"markdown","bbeac664":"markdown","4987f6a1":"markdown","32cef114":"markdown","afbbff7c":"markdown","e0fdd78f":"markdown","36665a3d":"markdown","a6aacb92":"markdown","1b96ceaa":"markdown","db1138a5":"markdown","e15d7fe1":"markdown","8b6dabdc":"markdown","a7df8060":"markdown","6d61ccd9":"markdown","2b9f23e7":"markdown","343f9e67":"markdown","c1df94d4":"markdown","046c1043":"markdown","e280ae9f":"markdown","c8592428":"markdown","f4a0c5b8":"markdown","60e834ef":"markdown","43c1f2fb":"markdown"},"source":{"83c139f6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# Any results you write to the current directory are saved as output.","7725d35a":"import json\nimport matplotlib.pyplot as plt\nfrom tqdm import tqdm_notebook as tqdm","173a3184":"from itertools import islice\n\nnq_train_jsonl = \"\/kaggle\/input\/tensorflow2-question-answering\/simplified-nq-train.jsonl\"\n\nwith open(nq_train_jsonl, \"r\") as f:\n    for line in islice(f, 1):\n        train =json.loads(line)","fd992086":"train.keys()","bb77b285":"train['annotations']","6302c768":"train['annotations'][0]['long_answer']","db9cd378":"data_list = []\nwith open(nq_train_jsonl, \"r\") as f:\n    for line in tqdm(f):\n        data = json.loads(line)\n        long_ans = data['annotations'][0]['long_answer']\n        if long_ans['end_token'] - long_ans['start_token'] > 10000:\n            data_list.append(data)","43bc3bb6":"len(data_list)","e171c749":"# save\nwith open(\".\/very-long-answer-nq-train.jsonl\", \"w\")as f:\n    for l in data_list:\n        json.dump(l, f)\n        f.write(\"\\n\")","b37693ac":"df = pd.DataFrame.from_dict(data_list)\ndf.head()","27467c1c":"# annotations data to column\ndf[\"yes_no_answer\"] = df[\"annotations\"].apply(lambda q: q[0][\"yes_no_answer\"])\n\ndf[\"long_answer_end\"] = df[\"annotations\"].apply(lambda q: q[0][\"long_answer\"][\"end_token\"])\ndf[\"long_answer_start\"] = df[\"annotations\"].apply(lambda q: q[0][\"long_answer\"][\"start_token\"])\ndf[\"long_answer_length\"] = df.loc[:,\"long_answer_end\":\"long_answer_start\"].diff(axis=1)[\"long_answer_start\"].abs()","5dd1f00a":"def apply_ans_end(entry):\n    if len(entry)==0:\n        return None\n    return  entry[0][\"end_token\"]\n\ndef apply_ans_start(entry):\n    if len(entry)==0:\n        return None\n    return  entry[0][\"start_token\"]\n\ndf[\"short_answers\"] = df[\"annotations\"].apply(lambda q: q[0][\"short_answers\"])\ndf[\"short_answer_end\"] = df[\"short_answers\"].apply(apply_ans_end)\ndf[\"short_answer_start\"] = df[\"short_answers\"].apply(apply_ans_start)\ndf[\"short_answer_length\"] = df.loc[:,\"short_answer_end\":\"short_answer_start\"].diff(axis=1)[\"short_answer_start\"].abs()","7cf3567a":"# question_text\ndf[\"head_word\"] = df[\"question_text\"].apply(lambda q:q.split()[0])","907ab52a":"df.head()","eb7c6795":"from IPython.core.display import HTML","1329596d":"df['document_url'][0]","760cbe8c":"def get_answer_text(s, is_short=False):\n    if is_short:\n        beg = int(s['short_answer_start'])\n        end = int(s['short_answer_end'])\n    else:\n        beg = int(s['long_answer_start'])\n        end = int(s['long_answer_end'])\n        \n    if beg is not None and end is not None:\n        return \" \".join(s['document_text'].split(\" \")[beg:end])\n    else:\n        return None","53ff07ef":"# long answer\nHTML(get_answer_text(df.iloc[0]))","05def230":"# short answer\nHTML(get_answer_text(df.iloc[0], True))","f7e7ac09":"df[\"short_answer_length\"].describe()","bbc32444":"df[\"short_answer_length\"].plot.hist()","0e62a053":"df[\"short_answer_length\"].value_counts()","54651961":"df[\"yes_no_answer\"].value_counts()","2ee14a94":"max_idx = df[\"short_answer_length\"].idxmax()","04788c1b":"print(df.iloc[max_idx])","f9f86f7e":"print(df.iloc[max_idx]['document_url'])","0fe38d91":"df.iloc[max_idx]['question_text']","0c91ec47":"# short ans\nHTML(get_answer_text(df.iloc[max_idx], True))","ab8d12ce":"get_answer_text(df.iloc[max_idx], True)","6cc62156":"# long ans \nHTML(get_answer_text(df.iloc[max_idx], False))","101eebe1":"max_long = df[\"long_answer_length\"].idxmax()","6723e4ae":"df.iloc[max_long]","91912084":"print(df.iloc[max_long]['document_url'])\nprint(df.iloc[max_long]['question_text'])","3e4e9a00":"# long ans \nHTML(get_answer_text(df.iloc[max_long]))","0572d034":"df[\"question_text\"].str.split()","bc8eb2f9":"from collections import Counter\ncnt = Counter()\nfor item in df[\"question_text\"].str.split().to_list():\n    cnt.update(item)\ncnt.most_common(50)","9885b3c3":"# count head word\nplt.figure(figsize=(10,8),dpi=100)\nplt.rcParams[\"font.size\"] = 6\n\ndf.head_word.value_counts().plot(kind='bar')","d45d8b5f":"df.head_word.value_counts().head(20)","5b6923fd":"pd.set_option(\"display.max_colwidth\", 100)","1d58cc3e":"df[df[\"head_word\"]==\"list\"][[\"question_text\", \"document_url\", \"long_answer_start\", \"long_answer_end\"]] \\\n.sort_values(by=[\"document_url\", \"long_answer_start\"])","5a35f5e1":"df[df[\"head_word\"]==\"xbox\"][[\"question_text\", \"document_url\", \"long_answer_start\", \"long_answer_end\"]] \\\n.sort_values(by=[\"document_url\", \"long_answer_start\"])","5f3af305":"df[df[\"head_word\"]==\"cities\"][[\"question_text\", \"document_url\", \"long_answer_start\", \"long_answer_end\"]] \\\n.sort_values(by=[\"document_url\", \"long_answer_start\"])","e8632901":"df['document_url'].str.contains('=List_of_', regex=True).describe()","1c5ba433":"df['document_url'].nunique()","1bad37c6":"df['question_text'].nunique()","c6082e02":"df.groupby(['document_url']) \\\n.count()[['long_answer_length', 'short_answer_length']] \\\n.sort_values(by = 'long_answer_length', ascending=False) \\\n.head(10)","1a21c278":"df.groupby(['document_url']).count()['long_answer_length'].hist(bins=19, grid=False)","a612b0cb":"df.groupby(['document_url']).count()['long_answer_length'].value_counts()","522dac55":"This `document_text` is [List of the highest major summits of North America](https:\/\/en.wikipedia.org\/\/w\/index.php?title=List_of_the_highest_major_summits_of_North_America&amp;oldid=835916791) at Wikipendia\n","774bd708":"# Convert to DataFrame","58c8cf5a":"# count question_text\ncount word","c1cd2067":"## max long_answer_length","de02b196":"### long answer","bbeac664":"### long answer","4987f6a1":"## yes_no_answer","32cef114":"Electron configurations of the elements (data page) : https:\/\/en.wikipedia.org\/\/w\/index.php?title=Electron_configurations_of_the_elements_(data_page)","afbbff7c":"### short answer","e0fdd78f":"# Retrive very long answer data\nRetrive train data that contains `long_answer` which have very long token (>10000)","36665a3d":"## Save results","a6aacb92":"# EDA\n## short answer","1b96ceaa":"# TL;DR\n\n* Most of the data that has very long answer's document is the article like `List_of_...`\n    * `long_answer` is the span of long list in the document\n    * `short_answer` is the one of the cell in the list\n* Some documents (`document_text`) are linked to multiple questions (`question_text`)\n    * linked questions are unique\n    * but some questions have the same `long_answer` span","db1138a5":"## max short_answer_length","e15d7fe1":"# count head word of question_text ","8b6dabdc":"## nunique","a7df8060":"### short answer","6d61ccd9":"## head word: list","2b9f23e7":"### long answer","343f9e67":"List of Xbox 360 games https:\/\/en.wikipedia.org\/\/w\/index.php?title=List_of_Xbox_360_games\n\ndivided into two pages now\n* https:\/\/en.wikipedia.org\/wiki\/List_of_Xbox_360_games_(A\u2013L)\n* https:\/\/en.wikipedia.org\/wiki\/List_of_Xbox_360_games_(M\u2013Z)","c1df94d4":"# count document_url like \"List_of_xx\"","046c1043":" * one document, one question : 254\/340 = 75% \n * one document, multiple question : 25% \n \n Some documents are linked to multiple questions.\n \n ***\n\n \n Note:\n \n * If you considered about Wikipedia Revision history (like `&amp;oldid=XXX`) , more documents are linked to multiple questions.\n     * For example, [List_of_Xbox_360_games_compatible_with_Xbox_One](https:\/\/en.wikipedia.org\/\/w\/index.php?title=List_of_Xbox_360_games_compatible_with_Xbox_One) is old version of [List_of_backward_compatible_games_for_Xbox_One](https:\/\/en.wikipedia.org\/\/w\/index.php?title=List_of_backward_compatible_games_for_Xbox_One)\n     * https:\/\/en.wikipedia.org\/w\/index.php?title=List_of_backward_compatible_games_for_Xbox_One&action=history","e280ae9f":"## head word: cities","c8592428":"## head word: xbox","f4a0c5b8":"## View very long answer data","60e834ef":"`list`, `xbox` ,`cities` is not *interrogative word* (what, when, who, how, which).","43c1f2fb":"# Check data keys"}}