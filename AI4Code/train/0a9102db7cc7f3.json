{"cell_type":{"62126cd6":"code","f4c6bf96":"code","d8995de8":"code","a9497b80":"code","43c4b64e":"code","9168138b":"code","11a61181":"code","f3c9778a":"code","1b3bd785":"code","00ae55b0":"code","bf04d81b":"code","df57dd4a":"code","3f6ddaac":"code","80347e72":"code","cf15a702":"code","4cc19bc3":"code","4747d20b":"code","96939c48":"code","27a734a6":"code","f2e9ac28":"code","c4b0708e":"code","c49bff56":"code","4e66229a":"code","ddd8c0ea":"code","009b4e3f":"code","7745ece6":"code","f9067b9f":"code","b12c2895":"code","268d5beb":"code","160bfe5d":"code","500ddeff":"code","74690490":"code","51a11c86":"code","e9c3ed0f":"code","175f442b":"code","97eca939":"code","92bafa5f":"code","4a7933de":"code","f791c291":"code","5c81f5ff":"code","88accdfa":"code","faa069d0":"code","a37008e2":"code","d940ed00":"markdown","5867eea1":"markdown","7868bf04":"markdown","20dfa38f":"markdown","ea3d5b11":"markdown","69444dd2":"markdown","67d4ab3a":"markdown","2a4a6cae":"markdown","2b5db232":"markdown","a759c9c5":"markdown","eb2d838e":"markdown","1eed275e":"markdown"},"source":{"62126cd6":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle\/python docker image: https:\/\/github.com\/kaggle\/docker-python\n# For example, here's several helpful packages to load in \n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I\/O (e.g. pd.read_csv)\n\n# Input data files are available in the \"..\/input\/\" directory.\n# For example, running this (by clicking run or pressing Shift+Enter) will list the files in the input directory\n\nimport os\nprint(os.listdir(\"..\/input\"))\n\n# Any results you write to the current directory are saved as output.","f4c6bf96":"import matplotlib.pyplot as plt\nimport seaborn as sns\n%matplotlib inline\nfrom sklearn.feature_extraction import FeatureHasher\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LogisticRegression\nfrom sklearn.metrics import classification_report\nfrom sklearn.metrics import confusion_matrix","d8995de8":"train = pd.read_csv(\"..\/input\/metro-bike-share-trip-data.csv\")","a9497b80":"print ('There are',len(train.columns),'columns:')\nfor x in train.columns:\n    print(x+' ',end=',')","43c4b64e":"train.head()","9168138b":"train.tail()","11a61181":"print(\"Number of columns (features) in the given dataset is :\",train.shape[1])\nprint(\"Number of rows (entries) in the given dataset is :\",train.shape[0])","f3c9778a":"train.info()","1b3bd785":"train_na = (train.isnull().sum()*100)\/len(train)\nprint(\"Percentage of Missing Data in each feature:\")\ntrain_na.sort_values(ascending=False)","00ae55b0":"sns.heatmap(train.isnull(),yticklabels=False,cbar=False,cmap='viridis')","bf04d81b":"train = train.dropna()","df57dd4a":"fig, ax = plt.subplots()\nax.scatter(train['Passholder Type'], train['Duration'])\nplt.ylabel('Duration (in seconds)', fontsize=13)\nplt.xlabel('PassHolder Type', fontsize=13)\nplt.show()","3f6ddaac":"l = []\nimport math \ndegrees_to_radians = math.pi\/180.0\ndef distance_on_unit_sphere(lat1, long1, lat2, long2):\n    phi1 = (90.0 - lat1)*degrees_to_radians\n    phi2 = (90.0 - lat2)*degrees_to_radians\n    \n    theta1 = long1*degrees_to_radians\n    theta2 = long2*degrees_to_radians\n    \n    a = ((math.sin(phi1)*math.sin(phi2)*math.cos(theta1 - theta2)) +(math.cos(phi1)*math.cos(phi2)))\n    if a>1:\n        a=0.999999\n    dis = math.acos( a )\n    return dis*6373\nfor i in range(97825):\n    l.append(distance_on_unit_sphere(train['Starting Station Latitude'].iloc[i],\n                                     train['Starting Station Longitude'].iloc[i],\n                                     train['Ending Station Latitude'].iloc[i],\n                                     train['Ending Station Longitude'].iloc[i]))","80347e72":"temp = pd.DataFrame(data=[train['Duration'],\n                               train['Starting Station Latitude'],\n                               train['Starting Station Longitude'],\n                               train['Ending Station Latitude'],\n                               train['Ending Station Longitude'],\n                               train['Plan Duration']],\n                               index=['Duration',\n                                      'Starting Station Latitude',\n                                      'Starting Station Longitude',\n                                      'Ending Station Latitude',\n                                      'Ending Station Longitude',\n                                      'Plan Duration'])","cf15a702":"distance = pd.DataFrame({'Distance':l})","4cc19bc3":"new_train = temp.T","4747d20b":"print(\"Shape of new train \",new_train.shape)\nprint (\"Shape of distance \",distance.shape)","96939c48":"new_train = new_train.reset_index(drop=True)","27a734a6":"new_train = pd.concat([distance,\n                       new_train,\n                       pd.get_dummies(data=train['Passholder Type']).reset_index(),\n                       pd.get_dummies(data=train['Trip Route Category'],drop_first=True).reset_index()],\n                       axis=1)","f2e9ac28":"new_train = new_train.drop('index',axis=1)\nnew_train.info()","c4b0708e":"print(\"There are 3 different types of Passholder : \")\ntrain['Passholder Type'].value_counts()","c49bff56":"X1 = new_train.drop(columns=['Flex Pass','Monthly Pass','Walk-up','Plan Duration'])\ny1 = new_train['Walk-up']","4e66229a":"X_train,X_test,y_train,y_test = train_test_split(X1,y1,test_size=0.33)","ddd8c0ea":"lr = LogisticRegression()","009b4e3f":"lr.fit(X_train,y_train)","7745ece6":"pred1 = lr.predict(X_test)","f9067b9f":"print(classification_report(y_test,pred1))","b12c2895":"print(confusion_matrix(y_test,pred1))","268d5beb":"X2 = new_train.drop(columns=['Flex Pass','Monthly Pass','Walk-up','Plan Duration'])\ny2 = new_train['Monthly Pass']\nX_train,X_test,y_train,y_test = train_test_split(X2,y2,test_size=0.33)","160bfe5d":"from sklearn.ensemble import RandomForestClassifier","500ddeff":"clf = RandomForestClassifier()","74690490":"clf.fit(X_train,y_train)","51a11c86":"pred2 = clf.predict(X_test)\n# pred2 = clf2.predict(X_test)","e9c3ed0f":"print(classification_report(y_test,pred2))","175f442b":"print(confusion_matrix(y_test,pred2))","97eca939":"X3 = new_train.drop(columns=['Flex Pass','Monthly Pass','Walk-up','Plan Duration'])\ny3 = new_train['Flex Pass']\nX_train,X_test,y_train,y_test = train_test_split(X3,y3,test_size=0.33)","92bafa5f":"print(X3.head())","4a7933de":"from sklearn.tree import DecisionTreeClassifier","f791c291":"clf2 = DecisionTreeClassifier()","5c81f5ff":"clf2.fit(X_train,y_train)","88accdfa":"pred3 = clf2.predict(X_test)","faa069d0":"print(classification_report(y_test,pred3))","a37008e2":"print(confusion_matrix(y_test,pred3))","d940ed00":"### Conclusion\nWe find that the decision tree classifier is fairly accurate for deciding whether a user holds a flex pass or not. Now, it would be interesting to examine which features of the data set have the strongest effect on the classification.","5867eea1":"Creating a new dataframe distance having the newly calculated distances under the Distance column","7868bf04":"# From below here, I modified the training data to remove obious correlations between Flex Pass, Monthly Pass, Walk-up and Plan Duration\n\n## USING LOGISTIC REGRESSION TO PREDICT WHETHER PASSHOLDER TYPE IS \"Walk-up\" OR \"Not\"","20dfa38f":"# DROPPING NULL VALUES.\nSince the dataset features such as Starting Station ID,Starting Station Latitude,Starting Station Longitude,Ending Station ID,Ending Station Latitude ,Ending Station Longitude,Bike ID ,Plan Duration,Starting Lat-Long,Ending Lat-Long contains some null values. So before moving on further with the dataset we need to drop null values so that these null values can create problems while moving forward.","ea3d5b11":"# LOADING LA METRO-BIKE-SHARE-TRIP-DATASET","69444dd2":"# USING RANDOM FOREST CLASSIFIER TO PREDICT WHETHER THE PASSHOLDER TYPE IS \"Monthly Pass\" OR \"Not\"","67d4ab3a":"### Modification of Kernel by another Kaggle User ### \nI looked through some datasets and kernels and found this one interesting. For some predictions near the end, the score achieved was always 100%, which seemed unusually high. I noticed that the data used for the predictions was 100% correlated due to some generated features being mutually exclusive. Here is a different take on the predictions, where the correlations are removed.\n","2a4a6cae":"# IMPORTING LIBRARIES","2b5db232":"# DISTANCE CALCULATION\nUsing the Starting Station Latitude and Longitude and Ending Station Latitude and Longitude we can calculate the distance travelled by the user. This extra feature calculated can be used to fit into the model as it can help in improving the predicting ability of the model.","a759c9c5":"Adding all the important features to a temporary dataframe temp ","eb2d838e":"# USING DECISION TREE CLASSIFIER TO PREDICT WHETHER THE PASSHOLDER TYPE IS \"Flex Pass\" OR \"Not\"","1eed275e":"# DATA EXPLORATION"}}