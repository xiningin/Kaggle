{"cell_type":{"15450612":"code","36304663":"code","223dcc74":"code","d8b79ff6":"code","fbbd59f1":"code","b9445661":"code","8264316b":"code","15177242":"code","b07bdd97":"code","226c0fa8":"code","8761a661":"code","44604936":"code","9d83deae":"code","ad33ea13":"code","049ed10c":"code","654cfdb9":"markdown"},"source":{"15450612":"! pip install neptune-client==0.4.132","36304663":"import numpy as np\nimport pandas as pd\nimport matplotlib.pyplot as plt\nimport os , time , re\nimport cv2\n\nimport torch\nimport torch.nn as nn\nimport torch.nn.init as init\n\nimport torch.nn.functional as F\nimport torch.optim as optim\n\n#from skimage import io , transform\nfrom torch.utils.data import Dataset , DataLoader\nfrom torchvision import transforms , utils , datasets\n\ndevice = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\ndevice\n\ntry:\n    from torch.hub import load_state_dict_from_url\nexcept ImportError:\n    from torch.utils.model_zoo import load_url as load_state_dict_from_url\n    \nimport neptune\n\nneptune.init(project_qualified_name='manickavela\/computer-vision', # change this to your `workspace_name\/project_name`\n             api_token='eyJhcGlfYWRkcmVzcyI6Imh0dHBzOi8vdWkubmVwdHVuZS5haSIsImFwaV91cmwiOiJodHRwczovL3VpLm5lcHR1bmUuYWkiLCJhcGlfa2V5IjoiN2JhMDRjODUtZjk1Ni00M2JjLWI3ZTctYTg5NmFlOGNlOTNmIn0=', # change this to your api token\n            )\n\n","223dcc74":"#Hyperparameters\n\n#n_epochs = 3\n#batch_train = 64\n#batch_test  = 1000\n\nbatch_size=16\n\nlearning_rate = 1e-4 \nmomentum = 0.9\n#log_interval = 10            #printing logs after an interval\n\nrandom_seed = 32\n#torch.backends.cudnn.enabled = False\ntorch.manual_seed(random_seed)","d8b79ff6":"import os\nlabels = os.listdir('\/kaggle\/input\/mura-dataset\/dataset\/train')","fbbd59f1":"train_path = []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/mura-dataset\/dataset\/train'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        train_path.append(os.path.join(dirname,filename))\n        \nvalid_path = []\nimport os\nfor dirname, _, filenames in os.walk('\/kaggle\/input\/mura-dataset\/dataset\/valid'):\n    for filename in filenames:\n        #print(os.path.join(dirname, filename))\n        valid_path.append(os.path.join(dirname,filename))","b9445661":"enum = enumerate(labels)\nLabelToClass = dict((b,a) for a,b in enum)\nLabelToClass","8264316b":"from PIL import Image , ImageOps  \n#PIL_image = Image.fromarray(ndarray_image)\nclass ChestDataset(Dataset) :\n    def __init__(self,path,train=True,transform=None):\n        self.train=train\n        self.data_path = path\n        self.transform = transform\n    \n    def __len__(self) :\n        return len(self.data_path)\n    \n    def __getitem__(self,idx) :\n        img_path = self.data_path[idx]\n        \n        image = Image.open(img_path).convert('RGB')\n                        \n        #if len(image.shape) < 3 :\n        #    image = image[:,:,np.newaxis]            #Adding th egrey channel\n        #print(image.shape)    \n        #image = cv2.equalizeHist(image)\n        #print(img_path)\n        #image = Image.fromarray(image)                            #Ndarray to PIL image\n        #image = ImageOps.equalize(image) \n        \n        if self.train == True :\n            label = re.search('\/train\/(.*)\/',img_path).group(1)\n        elif self.train == False :\n            label = re.search('\/valid\/(.*)\/',img_path).group(1)\n            \n        label = LabelToClass[label]\n        label = torch.as_tensor(label)\n        \n        if self.transform :\n            image = self.transform(image)\n        \n        sample = {'image' :image ,'label':label , 'path' :img_path}\n        return sample","15177242":"transform = transforms.Compose([transforms.Resize((512,512)),\n#                                transforms.CenterCrop(224),\n                                transforms.ToTensor(),\n                                transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                                     std=[0.229, 0.224, 0.225])])","b07bdd97":"train_ds = ChestDataset(path=train_path,train=True,transform=transform)\nvalid_ds = ChestDataset(path=valid_path,train=False,transform=transform)","226c0fa8":"train_loader = torch.utils.data.DataLoader(train_ds,batch_size=batch_size,shuffle=True)\nvalid_loader = torch.utils.data.DataLoader(valid_ds,batch_size=batch_size,shuffle=True)","8761a661":"class Fire(nn.Module) :\n    def __init__(self,inplanes,squeeze_planes,expand1x1_planes,expand3x3_planes) :\n        super(Fire,self).__init__()\n        self.inplanes = inplanes\n        self.squeeze = nn.Conv2d(inplanes,squeeze_planes,kernel_size=1)\n        self.squeeze_activation = nn.ReLU(inplace=True)\n        self.expand1x1 = nn.Conv2d(squeeze_planes,expand1x1_planes,kernel_size=1)\n        self.expand1x1_activation = nn.ReLU(inplace=True)\n        \n        self.expand3x3 = nn.Conv2d(squeeze_planes,expand3x3_planes,kernel_size=3,padding=1)\n        self.expand3x3_activation = nn.ReLU(inplace=True)\n        \n    def forward(self,x) :\n        x = self.squeeze_activation(self.squeeze(x))\n        return torch.cat([\n            self.expand1x1_activation(self.expand1x1(x)),\n            self.expand3x3_activation(self.expand3x3(x))\n        ])","44604936":"class SqueezeNet(nn.Module) :\n    def __init__(self,version='1_0',num_classes=1000) :\n        super(SqueezeNet,self).__init__()\n        self.num_classes = num_classes\n        \n        if version =='1_0' :\n            self.features = nn.Sequential(\n                nn.Conv2d(3, 96, kernel_size=7, stride=2),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(96, 16, 64, 64),\n                Fire(128, 16, 64, 64),\n                Fire(128, 32, 128, 128),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(256, 32, 128, 128),\n                Fire(256, 48, 192, 192),\n                Fire(384, 48, 192, 192),\n                Fire(384, 64, 256, 256),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(512, 64, 256, 256),\n            )\n            \n        elif version == '1_1':\n            self.features = nn.Sequential(\n                nn.Conv2d(3, 64, kernel_size=3, stride=2),\n                nn.ReLU(inplace=True),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(64, 16, 64, 64),\n                Fire(128, 16, 64, 64),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(128, 32, 128, 128),\n                Fire(256, 32, 128, 128),\n                nn.MaxPool2d(kernel_size=3, stride=2, ceil_mode=True),\n                Fire(256, 48, 192, 192),\n                Fire(384, 48, 192, 192),\n                Fire(384, 64, 256, 256),\n                Fire(512, 64, 256, 256),\n            )\n            \n            final_conv = nn.Conv2d(512,self.num_classes,kernel_size=1)\n            self.classifier = nn.Sequential(\n                nn.Dropout(p=0.5),\n                final_conv,\n                nn.ReLU(inplace=True),\n                nn.AdaptiveAvgPool2d((1,1))\n            )\n            \n            for m in self.modules():\n                if isinstance(m, nn.Conv2d):\n                    if m is final_conv:\n                        init.normal_(m.weight, mean=0.0, std=0.01)\n                    else:\n                        init.kaiming_uniform_(m.weight)\n                    if m.bias is not None:\n                        init.constant_(m.bias, 0)\n                    \n    def forward(self, x: torch.Tensor):\n        x = self.features(x)\n        x = self.classifier(x)\n        return torch.flatten(x, 1)\n        \ndef squeezenet1_1(pretrained: bool = False, **kwargs):\n    return SqueezeNet(version='1_1',num_classes=7, **kwargs)\n    ","9d83deae":"\nnetwork = squeezenet1_0().to(device)\ncriterion = nn.CrossEntropyLoss()\n\noptimizer = optim.Adam(network.parameters(),lr = learning_rate)\n#optimizer = optim.SGD(network.parameters(),lr = learning_rate,momentum=momentum , weight_decay=1e-4)\n\n\n#neptune.create_experiment('MURA Squeeznet1_0',params={'Learning Rate':learning_rate,'Model architecture ':'SqueezeNet1_0','Epoch':50,\n#                                                 'Optimizer':'Adam','Criterion':'Cross Entropy Loss','Batch Size':batch_size\n#                                                  ,'image_height' : 512 , 'image_width' : 512,'pretrained ' : False})","ad33ea13":"network","049ed10c":"%%time\ntrain_count = 0\ntest_count = 0\n\ntrain_losses = []\nvalid_losses = []\naccuracy_train = []\naccuracy_valid = []\n\ncorrect_train = 0\ncorrect_test = 0\n\n#neptune.log_metric('Epoch',20)\nvalid_loss_min = 100\n\nfor epoch in range(1,50) :\n    \n    since = time.time()\n    \n    train_loss = 0.0\n    valid_loss = 0.0\n\n    train_acc = 0.0\n    valid_acc = 0.0\n\n    correct_train = 0\n    correct_test = 0\n\n    #Training\n    network.train()\n    print('Training...')\n    size = 0\n    for i,data in enumerate(train_loader) :\n        \n        \n        inputs, labels = data['image'] , data['label']\n        inputs = inputs.to(device)\n        labels = labels.to(device)\n\n        optimizer.zero_grad() \n        output = network(inputs)\n\n        loss = criterion(output,labels)\n\n        loss.backward()\n        optimizer.step()\n\n        train_loss += loss.item()*inputs.size(0)\n\n        pred = output.data.max(1,keepdim=True)[1]\n        correct_train += pred.eq(labels.data.view_as(pred)).sum() \n        size += len(pred)\n        train_acc = correct_train\/size          #len(pred) has \n\n        if i%10 == 0 : \n            print('Batches : ',i) \n\n        accuracy_train.append(train_acc)\n        train_losses.append(loss.item())\n\n        #neptune.log_metric('train_loss',loss.item())\n        #neptune.log_metric('train_acc',train_acc)\n\n        train_count = i\n    \n    #Validataion\n    print('Validating...')\n    size = 0\n    network.eval()\n    with torch.no_grad() : \n        for i,data in enumerate(valid_loader) :\n            print('Batches : ',i) \n       \n            target = data['label']\n            data = data['image']\n\n            data = data.to(device)\n            target = target.to(device)\n            output = network(data)\n\n            loss = criterion(output,target)\n\n            valid_loss += loss.item()*data.size(0)\n\n            pred = output.data.max(1,keepdim=True)[1] \n            correct_test += pred.eq(target.data.view_as(pred)).sum() \n            size += len(pred)\n            valid_acc = correct_test\/size\n\n            accuracy_valid.append(valid_acc)\n            valid_losses.append(loss.item())\n        \n            #neptune.log_metric('valid_loss',loss.item())\n            #neptune.log_metric('valid_acc',valid_acc)\n\n            test_count = i\n\n    train_loss = train_loss\/len(train_loader.sampler)\n    valid_loss = valid_loss\/len(valid_loader.sampler)\n\n\n    #neptune.log_metric('train_loss_epoch',train_loss)\n    #neptune.log_metric('valid_loss_epoch',valid_loss)\n    #neptune.log_metric('train_acc_epoch',train_acc)\n    #neptune.log_metric('valid_acc_epoch',valid_acc)\n    \n   \n    time_elapsed = time.time() - since\n    print('Batch {:.0f} Completed : {:.0f}m {:.0f}s'.format(epoch+1,time_elapsed \/\/60 , time_elapsed%60))\n    print('Epoch: {} \\tTraining Loss: {:.6f} \\tValidation Loss: {:.6f}'.format(  \n        epoch+1, train_loss, valid_loss))","654cfdb9":"# **SqueezeNet**"}}