{"cell_type":{"4abc502c":"code","98ba5414":"code","4f87f680":"code","4025d4cc":"code","5a2747e0":"code","02dea27a":"code","04181785":"code","f57160ac":"code","0e336f8e":"code","3174bfaa":"code","a71dbc16":"code","b1223f54":"code","f882a469":"code","31ae0553":"code","4d365f6d":"code","6b3374dd":"markdown","1a4d972d":"markdown","c6f869b5":"markdown","0d0fbaa5":"markdown","1bf5536a":"markdown","5a670cfa":"markdown","89e4d4a8":"markdown","f4a4880d":"markdown","01188064":"markdown"},"source":{"4abc502c":"import os\nimport spacy\nimport torch\nimport numpy as np\nimport pandas as pd\n\nfrom torch import nn\nfrom pathlib import Path\nfrom tqdm.notebook import tqdm\nfrom sklearn.metrics import mean_squared_error\nfrom torch.utils.data import Dataset, DataLoader\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.linear_model import LinearRegression, Ridge","98ba5414":"BATCH_SIZE = 64\nRANDOM_STATE = 41\nFEATURES_SIZE = 300\nnlp = spacy.load('en_core_web_lg')","4f87f680":"COMPETITION_DATA_PATH = Path('..\/input\/commonlitreadabilityprize')\nTRAIN_DATA_PATH = COMPETITION_DATA_PATH \/ 'train.csv'\nTEST_DATA_PATH = COMPETITION_DATA_PATH \/ 'test.csv'","4025d4cc":"train_data = pd.read_csv(TRAIN_DATA_PATH)\ntest_data = pd.read_csv(TEST_DATA_PATH)\ntrain_data, valid_data = train_test_split(train_data, test_size=0.1, random_state=RANDOM_STATE)\n\nprint(f'Length of train data: {len(train_data)}')\nprint(f'Length of valid data: {len(valid_data)}')\nprint(f'Length of test data: {len(test_data)}')","5a2747e0":"def create_features(text_excerpts):\n    with nlp.disable_pipes():\n        features = np.vstack([nlp(text).vector for text in tqdm(text_excerpts)])\n    return features\n\ndef create_targets(targets):\n    targets = targets.reshape(-1, 1).astype(np.float32)\n    return targets\n\n\nX_train = create_features(train_data['excerpt'].tolist())\ny_train = create_targets(train_data['target'].to_numpy())\nX_valid = create_features(valid_data['excerpt'].tolist())\ny_valid = create_targets(valid_data['target'].to_numpy())\n\nprint(f'Shapes: X_train {X_train.shape}, X_valid: {X_valid.shape}, y_train: {y_train.shape}, y_valid: {y_valid.shape}')","02dea27a":"class TrainingDataset(Dataset):\n    def __init__(self, features, targets):\n        self.features = features\n        self.targets = targets\n    \n    def __len__(self):\n        return len(self.features)\n    \n    def __getitem__(self, idx):\n        return self.features[idx], self.targets[idx]\n    \n\nclass PredictionDataset(Dataset):\n    def __init__(self, text_excerpts):\n        self.text_excerpts = text_excerpts\n    \n    def __len__(self):\n        return len(self.text_excerpts)\n    \n    def __getitem__(self, idx):\n        with nlp.disable_pipes():\n            text = self.text_excerpts[idx]\n        X = nlp(text).vector\n        return X","04181785":"class Model(nn.Module):\n    def __init__(self):\n        super(Model, self).__init__()\n        self.linear = nn.Sequential(\n            nn.Linear(FEATURES_SIZE, FEATURES_SIZE),\n            nn.Dropout(p=0.2),\n            nn.ReLU(),\n            nn.Linear(FEATURES_SIZE, 1), \n        )  \n    def forward(self, x):\n        x = self.linear(x)\n        return x","f57160ac":"train_dataset = TrainingDataset(features=X_train, targets=y_train)\nvalid_dataset = TrainingDataset(features=X_valid, targets=y_valid)\ntest_dataset = PredictionDataset(text_excerpts=test_data['excerpt'])\n\ntrain_dataloader = DataLoader(dataset=train_dataset, batch_size=BATCH_SIZE, shuffle=True)\nvalid_dataloader = DataLoader(dataset=valid_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)","0e336f8e":"loss_fn = nn.MSELoss(reduction='mean')\nmodel = Model()\noptimizer = torch.optim.SGD(params=model.parameters(), lr=0.01, momentum=0.9, nesterov=True)","3174bfaa":"def train_one_epoch(dataloader, model, optimizer):\n    model.train()\n    total_loss = 0\n    for batch_num, batch in enumerate(dataloader):\n        # Forward pass\n        X, y = batch\n        y_pred = model(X)\n        loss = loss_fn(y, y_pred)\n        total_loss += np.sqrt(loss.item())\n        # Backprop\n        optimizer.zero_grad()\n        loss.backward()\n        optimizer.step()\n    average_loss = total_loss \/ (batch_num + 1)\n    return average_loss\n\ndef validate_one_epoch(dataloader, model):\n    model.eval()\n    with torch.no_grad():\n        total_loss = 0\n        for batch_num, batch in enumerate(dataloader):\n            # Forward pass\n            X, y = batch\n            y_pred = model(X)\n            loss = loss_fn(y, y_pred)\n            total_loss += np.sqrt(loss.item())\n        average_loss = total_loss \/ (batch_num + 1)\n    return average_loss\n\ndef predict(dataloader, model):\n    model.eval()\n    with torch.no_grad():\n        y_preds = []\n        for batch_num, X in enumerate(dataloader):\n            y_pred = model(X)\n            y_preds.append(y_pred.cpu().detach().numpy())\n    y_preds = np.vstack(y_preds)\n    return y_preds","a71dbc16":"class EarlyStopping:\n    def __init__(self, patient_epochs=2):\n        self.best_valid_loss = np.inf\n        self.best_epoch = -1\n        self.patient_epochs = patient_epochs\n    \n    def should_stop(self, current_epoch, current_valid_loss):\n        if current_valid_loss < self.best_valid_loss:\n            self.best_valid_loss = current_valid_loss\n            self.best_epoch = current_epoch\n        return True if current_epoch > self.best_epoch + self.patient_epochs else False\n\nearly_stopping = EarlyStopping(patient_epochs=50)","b1223f54":"for epoch_num in range(500):\n    train_loss = train_one_epoch(dataloader=train_dataloader, model=model, optimizer=optimizer)\n    valid_loss = validate_one_epoch(dataloader=valid_dataloader, model=model)\n    if early_stopping.should_stop(current_epoch=epoch_num, current_valid_loss=valid_loss):\n        print(f'Exiting At epoch: {epoch_num}, train_loss: {train_loss}, valid_loss: {valid_loss}')\n        break\n    if epoch_num % 50 == 0:\n        print(f'At epoch: {epoch_num}, train_loss: {train_loss}, valid_loss: {valid_loss}')","f882a469":"regressor = Ridge().fit(X_train, y_train)\nsklearn_error = mean_squared_error(regressor.predict(X_valid), y_valid)\nprint(f'Sklearn Error: {sklearn_error: .3f}')","31ae0553":"valid_test_dataset = PredictionDataset(text_excerpts=valid_data['excerpt'].tolist())\nvalid_test_dataloader = DataLoader(dataset=valid_test_dataset, batch_size=BATCH_SIZE, shuffle=False)\npytorch_error = mean_squared_error(predict(valid_test_dataloader, model), valid_data['target'].tolist())\nprint(f'Pytorch Error: {pytorch_error: .3f}')","4d365f6d":"test_dataset = PredictionDataset(text_excerpts=test_data['excerpt'].tolist())\ntest_dataloader = DataLoader(dataset=test_dataset, batch_size=BATCH_SIZE, shuffle=False)\ntest_data['target'] = predict(test_dataloader, model)\ntest_data[['id','target']].to_csv('submission.csv', index=False)","6b3374dd":"# Spacy Feature extraction\nAll Credits to Sumit Kumar @anaverageengineer https:\/\/www.kaggle.com\/anaverageengineer\/comlrp-baseline-for-complete-beginners","1a4d972d":"# Create Model, Optimizer and Loss function","c6f869b5":"# Comparison with Sklearn to make sure the model is sensible","0d0fbaa5":"# Training and Evaluation loop","1bf5536a":"# Create datasets and dataloaders","5a670cfa":"# Model definition","89e4d4a8":"# Datasets and Dataloaders definition","f4a4880d":"# Make submission","01188064":"# Objective\nThe objective of this notebook is to build a Regression model in Pytorch and make sure it words by comparing it with Sklearn's regression model. Once this works, we can set this up as a baseline and  we can do better by:\n1. Improving the model architecture (for example by adding more layers)\n2. Changing the Input features\n3. Express our creativity by defining a novel model architecture"}}