{"cell_type":{"17645117":"code","ac6a641a":"code","f90c3e4f":"code","69e50675":"code","29eeaed7":"code","293bc8f5":"code","8723816a":"code","d30f27b2":"code","991f920c":"code","fe99c027":"code","4f39b714":"code","8fb52307":"code","be1e7aaa":"code","31114e26":"code","9bd9e0a1":"code","406c8ae6":"code","a1bfa5cc":"code","c44f2e50":"code","85296974":"code","79a1bb14":"code","d4c2bc02":"code","6c7d8141":"code","732a015a":"code","da5dfa70":"code","8847c2d0":"markdown","019ad51e":"markdown","6b720499":"markdown","e74e31a6":"markdown","ae974dfa":"markdown","635156c4":"markdown","dbefa1fe":"markdown","d2f4fde3":"markdown","580ad672":"markdown","0de48d03":"markdown","8a9c1868":"markdown","8a100624":"markdown","2da7191c":"markdown","92df03d9":"markdown"},"source":{"17645117":"import numpy as np \nimport pandas as pd\nfrom matplotlib import pyplot as plt\nimport seaborn as sns","ac6a641a":"train_set = pd.read_csv('..\/input\/train-and-test-set\/train.csv')\ntest_set = pd.read_csv('..\/input\/train-and-test-set\/test.csv')","f90c3e4f":"train_set.head()","69e50675":"train_set.info()","29eeaed7":"test_set.head()","293bc8f5":"test_set.info()","8723816a":"sns.violinplot(x = 'Sex', y = 'Age', hue = 'Survived', data = train_set, split = True)\nplt.show","d30f27b2":"sns.countplot('Sex', data = train_set, hue = 'Survived')\nplt.show()","991f920c":"# Filling the empty colomns with the mean\nfor t_set in [train_set, test_set]:\n    t_set['Age'].fillna(t_set['Age'].mean(), inplace=True)\n    t_set['Fare'].fillna(t_set['Fare'].mean(), inplace=True)\n    t_set['Embarked'].fillna(t_set['Embarked'].mode()[0], inplace=True)","fe99c027":"train_set.info()","4f39b714":"test_set.info()","8fb52307":"for dataset in [train_set, test_set]:\n    dataset['Title'] = dataset.Name.str.extract(' ([A-Za-z]+)\\.', expand=False)\n\n# We can check the survival of people with different titles.\npd.crosstab(train_set['Title'], train_set['Survived'])","be1e7aaa":"for dataset in [train_set, test_set]:\n    dataset['Title'] = dataset['Title'].replace(['Lady', 'Countess','Capt', 'Col', 'Don', 'Dr', 'Major', 'Sir', 'Jonkheer', 'Dona'], 'Rare')\n\n    dataset['Title'] = dataset['Title'].replace('Mlle', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Ms', 'Miss')\n    dataset['Title'] = dataset['Title'].replace('Mme', 'Mrs')","31114e26":"# Checking the survivle of different titles\npd.crosstab(train_set['Title'], train_set['Survived'])","9bd9e0a1":"title_mapping = {\"Mr\": 1, \"Miss\": 2, \"Mrs\": 3, \"Master\": 4, \"Rare\": 5, \"Rev\": 6}\nfor dataset in [train_set, test_set]:\n    dataset['Title'] = dataset['Title'].map(title_mapping)\n    dataset['Title'] = dataset['Title'].fillna(0)","406c8ae6":"for dataset in [train_set, test_set]:\n    dataset['Sex'] = dataset['Sex'].map({\"female\": 1, \"male\": 2})\n    dataset['Sex'] = dataset['Sex'].fillna(0)","a1bfa5cc":"for dataset in [train_set, test_set]:\n    dataset['Embarked'] = dataset['Embarked'].map({\"C\": 1, \"Q\": 2, \"S\": 3})\n    dataset['Embarked'] = dataset['Embarked'].fillna(0)","c44f2e50":"for cat in ['Cabin', 'Name', 'PassengerId', 'Ticket']:\n    train_set = train_set.drop(cat, axis=1)\n    test_set = test_set.drop(cat, axis=1)","85296974":"train_set.head()","79a1bb14":"test_set.head()","d4c2bc02":"for dataset in [train_set, test_set]:\n    dataset['Age_grps'] = pd.cut(dataset['Age'], bins=[0,12,24,50,120], labels=[1, 2, 3, 4])\n    dataset['Fare_bin'] = pd.cut(dataset['Fare'], bins=[-10,0,15,50,100,750], labels=[1, 2, 3, 4, 5])","6c7d8141":"for cat in ['Fare', 'Age']:\n    train_set = train_set.drop(cat, axis=1)\n    test_set = test_set.drop(cat, axis=1)","732a015a":"train_x = train_set.drop('Survived', axis=1)\ntrain_y = train_set['Survived']","da5dfa70":"train_x.head()","8847c2d0":"# Finally dividing the training set","019ad51e":"# Please upvote if you find this notebook helpfull in any way","6b720499":"# Exploring the Dataset","e74e31a6":"# Replacing some of the mis-spelled and rarely used titles","ae974dfa":"# Now you can train a good model on the above training sets and easily get into top 10%","635156c4":"# Now lets see how our dataset have transformed","dbefa1fe":"# Now our training algorithms perform better on numbers rather than alphabets so we will replace different catagories with numbers","d2f4fde3":"# We will drop the coloumns which we will not be using further","580ad672":"# Lets divide the age and fare coloumns into groups, doing this we will avoid overfitting and get better accuracy","0de48d03":"# Importing the Basic libraries","8a9c1868":"# Checking our Dataset again","8a100624":"# As we can see some of the colomns in train and test set are missing so we either need to remove those entries or fill them","2da7191c":"# Extracting the titles from the names","92df03d9":"# Getting access to the Dataset"}}